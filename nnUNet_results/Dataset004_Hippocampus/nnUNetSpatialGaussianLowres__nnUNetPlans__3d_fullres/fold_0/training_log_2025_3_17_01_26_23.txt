
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-17 01:26:23.364561: do_dummy_2d_data_aug: False 
2025-03-17 01:26:23.366568: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2025-03-17 01:26:23.375007: The split file contains 5 splits. 
2025-03-17 01:26:23.378010: Desired fold for training: 0 
2025-03-17 01:26:23.381010: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2025-03-17 01:26:29.803473: unpacking dataset... 
2025-03-17 01:26:30.126233: unpacking done... 
2025-03-17 01:26:31.467275:  
2025-03-17 01:26:31.472418: Epoch 0 
2025-03-17 01:26:31.474986: Current learning rate: 0.01 
2025-03-17 01:26:38.927222: train_loss -0.2226 
2025-03-17 01:26:38.933243: val_loss -0.5367 
2025-03-17 01:26:38.936255: Pseudo dice [np.float32(0.6826), np.float32(0.7347)] 
2025-03-17 01:26:38.940297: Epoch time: 7.46 s 
2025-03-17 01:26:38.943352: Yayy! New best EMA pseudo Dice: 0.7085999846458435 
2025-03-17 01:26:39.523623:  
2025-03-17 01:26:39.528681: Epoch 1 
2025-03-17 01:26:39.531665: Current learning rate: 0.00991 
2025-03-17 01:26:46.061174: train_loss -0.7285 
2025-03-17 01:26:46.067200: val_loss -0.7992 
2025-03-17 01:26:46.070738: Pseudo dice [np.float32(0.8543), np.float32(0.8429)] 
2025-03-17 01:26:46.073771: Epoch time: 6.54 s 
2025-03-17 01:26:46.076332: Yayy! New best EMA pseudo Dice: 0.722599983215332 
2025-03-17 01:26:46.711953:  
2025-03-17 01:26:46.716603: Epoch 2 
2025-03-17 01:26:46.719222: Current learning rate: 0.00982 
2025-03-17 01:26:53.239501: train_loss -0.7985 
2025-03-17 01:26:53.245677: val_loss -0.8242 
2025-03-17 01:26:53.248750: Pseudo dice [np.float32(0.8754), np.float32(0.8573)] 
2025-03-17 01:26:53.252379: Epoch time: 6.53 s 
2025-03-17 01:26:53.255436: Yayy! New best EMA pseudo Dice: 0.7369999885559082 
2025-03-17 01:26:53.922545:  
2025-03-17 01:26:53.928137: Epoch 3 
2025-03-17 01:26:53.931736: Current learning rate: 0.00973 
2025-03-17 01:27:00.449337: train_loss -0.8147 
2025-03-17 01:27:00.456398: val_loss -0.8228 
2025-03-17 01:27:00.459913: Pseudo dice [np.float32(0.8762), np.float32(0.8594)] 
2025-03-17 01:27:00.462426: Epoch time: 6.53 s 
2025-03-17 01:27:00.466495: Yayy! New best EMA pseudo Dice: 0.7501000165939331 
2025-03-17 01:27:01.177438:  
2025-03-17 01:27:01.183002: Epoch 4 
2025-03-17 01:27:01.186586: Current learning rate: 0.00964 
2025-03-17 01:27:07.690407: train_loss -0.8202 
2025-03-17 01:27:07.697516: val_loss -0.8298 
2025-03-17 01:27:07.700560: Pseudo dice [np.float32(0.8806), np.float32(0.8649)] 
2025-03-17 01:27:07.704114: Epoch time: 6.51 s 
2025-03-17 01:27:07.707257: Yayy! New best EMA pseudo Dice: 0.7623000144958496 
2025-03-17 01:27:08.527626:  
2025-03-17 01:27:08.533792: Epoch 5 
2025-03-17 01:27:08.537396: Current learning rate: 0.00955 
2025-03-17 01:27:15.051726: train_loss -0.8279 
2025-03-17 01:27:15.058361: val_loss -0.8284 
2025-03-17 01:27:15.061994: Pseudo dice [np.float32(0.8788), np.float32(0.8629)] 
2025-03-17 01:27:15.065099: Epoch time: 6.52 s 
2025-03-17 01:27:15.068206: Yayy! New best EMA pseudo Dice: 0.7731999754905701 
2025-03-17 01:27:15.723235:  
2025-03-17 01:27:15.728256: Epoch 6 
2025-03-17 01:27:15.731774: Current learning rate: 0.00946 
2025-03-17 01:27:22.227759: train_loss -0.8349 
2025-03-17 01:27:22.233918: val_loss -0.8343 
2025-03-17 01:27:22.237005: Pseudo dice [np.float32(0.8838), np.float32(0.8653)] 
2025-03-17 01:27:22.240582: Epoch time: 6.51 s 
2025-03-17 01:27:22.243637: Yayy! New best EMA pseudo Dice: 0.78329998254776 
2025-03-17 01:27:22.876759:  
2025-03-17 01:27:22.882282: Epoch 7 
2025-03-17 01:27:22.884792: Current learning rate: 0.00937 
2025-03-17 01:27:29.376793: train_loss -0.8364 
2025-03-17 01:27:29.384988: val_loss -0.8342 
2025-03-17 01:27:29.390073: Pseudo dice [np.float32(0.8818), np.float32(0.8681)] 
2025-03-17 01:27:29.393140: Epoch time: 6.5 s 
2025-03-17 01:27:29.396192: Yayy! New best EMA pseudo Dice: 0.7925000190734863 
2025-03-17 01:27:30.042228:  
2025-03-17 01:27:30.047749: Epoch 8 
2025-03-17 01:27:30.050838: Current learning rate: 0.00928 
2025-03-17 01:27:36.554936: train_loss -0.8392 
2025-03-17 01:27:36.560544: val_loss -0.8407 
2025-03-17 01:27:36.564129: Pseudo dice [np.float32(0.8877), np.float32(0.871)] 
2025-03-17 01:27:36.567200: Epoch time: 6.51 s 
2025-03-17 01:27:36.570251: Yayy! New best EMA pseudo Dice: 0.8011999726295471 
2025-03-17 01:27:37.226663:  
2025-03-17 01:27:37.232265: Epoch 9 
2025-03-17 01:27:37.234828: Current learning rate: 0.00919 
2025-03-17 01:27:43.731511: train_loss -0.8443 
2025-03-17 01:27:43.738036: val_loss -0.8359 
2025-03-17 01:27:43.740548: Pseudo dice [np.float32(0.8858), np.float32(0.8671)] 
2025-03-17 01:27:43.744067: Epoch time: 6.51 s 
2025-03-17 01:27:43.748085: Yayy! New best EMA pseudo Dice: 0.8087000250816345 
2025-03-17 01:27:44.375165:  
2025-03-17 01:27:44.381188: Epoch 10 
2025-03-17 01:27:44.383702: Current learning rate: 0.0091 
2025-03-17 01:27:50.899981: train_loss -0.8464 
2025-03-17 01:27:50.906241: val_loss -0.8424 
2025-03-17 01:27:50.909298: Pseudo dice [np.float32(0.89), np.float32(0.8746)] 
2025-03-17 01:27:50.912320: Epoch time: 6.53 s 
2025-03-17 01:27:50.915970: Yayy! New best EMA pseudo Dice: 0.816100001335144 
2025-03-17 01:27:51.556510:  
2025-03-17 01:27:51.562568: Epoch 11 
2025-03-17 01:27:51.565642: Current learning rate: 0.009 
2025-03-17 01:27:58.073024: train_loss -0.849 
2025-03-17 01:27:58.079152: val_loss -0.8416 
2025-03-17 01:27:58.082259: Pseudo dice [np.float32(0.891), np.float32(0.8717)] 
2025-03-17 01:27:58.084819: Epoch time: 6.52 s 
2025-03-17 01:27:58.088391: Yayy! New best EMA pseudo Dice: 0.8226000070571899 
2025-03-17 01:27:58.725977:  
2025-03-17 01:27:58.732118: Epoch 12 
2025-03-17 01:27:58.735190: Current learning rate: 0.00891 
2025-03-17 01:28:05.232258: train_loss -0.8506 
2025-03-17 01:28:05.238122: val_loss -0.8328 
2025-03-17 01:28:05.241654: Pseudo dice [np.float32(0.8829), np.float32(0.8616)] 
2025-03-17 01:28:05.245165: Epoch time: 6.51 s 
2025-03-17 01:28:05.248179: Yayy! New best EMA pseudo Dice: 0.8276000022888184 
2025-03-17 01:28:06.048481:  
2025-03-17 01:28:06.053069: Epoch 13 
2025-03-17 01:28:06.055583: Current learning rate: 0.00882 
2025-03-17 01:28:12.587646: train_loss -0.8523 
2025-03-17 01:28:12.593207: val_loss -0.8396 
2025-03-17 01:28:12.596731: Pseudo dice [np.float32(0.89), np.float32(0.8694)] 
2025-03-17 01:28:12.599638: Epoch time: 6.54 s 
2025-03-17 01:28:12.603195: Yayy! New best EMA pseudo Dice: 0.8327999711036682 
2025-03-17 01:28:13.240808:  
2025-03-17 01:28:13.245322: Epoch 14 
2025-03-17 01:28:13.248336: Current learning rate: 0.00873 
2025-03-17 01:28:19.780472: train_loss -0.8535 
2025-03-17 01:28:19.787035: val_loss -0.8456 
2025-03-17 01:28:19.790051: Pseudo dice [np.float32(0.8933), np.float32(0.8746)] 
2025-03-17 01:28:19.793571: Epoch time: 6.54 s 
2025-03-17 01:28:19.797083: Yayy! New best EMA pseudo Dice: 0.8378999829292297 
2025-03-17 01:28:20.461703:  
2025-03-17 01:28:20.467225: Epoch 15 
2025-03-17 01:28:20.470742: Current learning rate: 0.00864 
2025-03-17 01:28:27.013327: train_loss -0.857 
2025-03-17 01:28:27.018961: val_loss -0.8457 
2025-03-17 01:28:27.022055: Pseudo dice [np.float32(0.8925), np.float32(0.876)] 
2025-03-17 01:28:27.024625: Epoch time: 6.55 s 
2025-03-17 01:28:27.029271: Yayy! New best EMA pseudo Dice: 0.8424999713897705 
2025-03-17 01:28:27.687048:  
2025-03-17 01:28:27.692564: Epoch 16 
2025-03-17 01:28:27.696075: Current learning rate: 0.00855 
2025-03-17 01:28:34.210081: train_loss -0.8562 
2025-03-17 01:28:34.216244: val_loss -0.8427 
2025-03-17 01:28:34.219345: Pseudo dice [np.float32(0.8926), np.float32(0.8704)] 
2025-03-17 01:28:34.222955: Epoch time: 6.52 s 
2025-03-17 01:28:34.226101: Yayy! New best EMA pseudo Dice: 0.8464000225067139 
2025-03-17 01:28:34.883920:  
2025-03-17 01:28:34.889517: Epoch 17 
2025-03-17 01:28:34.893594: Current learning rate: 0.00846 
2025-03-17 01:28:41.475995: train_loss -0.8584 
2025-03-17 01:28:41.482629: val_loss -0.8503 
2025-03-17 01:28:41.486205: Pseudo dice [np.float32(0.8961), np.float32(0.8785)] 
2025-03-17 01:28:41.489255: Epoch time: 6.59 s 
2025-03-17 01:28:41.492324: Yayy! New best EMA pseudo Dice: 0.8504999876022339 
2025-03-17 01:28:42.166121:  
2025-03-17 01:28:42.171151: Epoch 18 
2025-03-17 01:28:42.174683: Current learning rate: 0.00836 
2025-03-17 01:28:48.773191: train_loss -0.8595 
2025-03-17 01:28:48.779266: val_loss -0.8467 
2025-03-17 01:28:48.782828: Pseudo dice [np.float32(0.8929), np.float32(0.8763)] 
2025-03-17 01:28:48.786380: Epoch time: 6.61 s 
2025-03-17 01:28:48.789428: Yayy! New best EMA pseudo Dice: 0.8539000153541565 
2025-03-17 01:28:49.449693:  
2025-03-17 01:28:49.453741: Epoch 19 
2025-03-17 01:28:49.456822: Current learning rate: 0.00827 
2025-03-17 01:28:55.955304: train_loss -0.8599 
2025-03-17 01:28:55.961405: val_loss -0.8545 
2025-03-17 01:28:55.964964: Pseudo dice [np.float32(0.9009), np.float32(0.8797)] 
2025-03-17 01:28:55.968593: Epoch time: 6.51 s 
2025-03-17 01:28:55.971692: Yayy! New best EMA pseudo Dice: 0.8575999736785889 
2025-03-17 01:28:56.776106:  
2025-03-17 01:28:56.782148: Epoch 20 
2025-03-17 01:28:56.785716: Current learning rate: 0.00818 
2025-03-17 01:29:03.303134: train_loss -0.8632 
2025-03-17 01:29:03.309313: val_loss -0.8504 
2025-03-17 01:29:03.313074: Pseudo dice [np.float32(0.8977), np.float32(0.8782)] 
2025-03-17 01:29:03.315622: Epoch time: 6.53 s 
2025-03-17 01:29:03.319216: Yayy! New best EMA pseudo Dice: 0.8605999946594238 
2025-03-17 01:29:04.016078:  
2025-03-17 01:29:04.022189: Epoch 21 
2025-03-17 01:29:04.025279: Current learning rate: 0.00809 
2025-03-17 01:29:10.543173: train_loss -0.8634 
2025-03-17 01:29:10.549731: val_loss -0.8495 
2025-03-17 01:29:10.552748: Pseudo dice [np.float32(0.8966), np.float32(0.8762)] 
2025-03-17 01:29:10.555255: Epoch time: 6.53 s 
2025-03-17 01:29:10.559329: Yayy! New best EMA pseudo Dice: 0.8632000088691711 
2025-03-17 01:29:11.194169:  
2025-03-17 01:29:11.199376: Epoch 22 
2025-03-17 01:29:11.202922: Current learning rate: 0.008 
2025-03-17 01:29:17.714002: train_loss -0.8646 
2025-03-17 01:29:17.720654: val_loss -0.845 
2025-03-17 01:29:17.724686: Pseudo dice [np.float32(0.8934), np.float32(0.873)] 
2025-03-17 01:29:17.728211: Epoch time: 6.52 s 
2025-03-17 01:29:17.730864: Yayy! New best EMA pseudo Dice: 0.8651999831199646 
2025-03-17 01:29:18.361903:  
2025-03-17 01:29:18.367981: Epoch 23 
2025-03-17 01:29:18.371083: Current learning rate: 0.0079 
2025-03-17 01:29:24.887602: train_loss -0.8668 
2025-03-17 01:29:24.893756: val_loss -0.8448 
2025-03-17 01:29:24.897371: Pseudo dice [np.float32(0.8925), np.float32(0.874)] 
2025-03-17 01:29:24.900933: Epoch time: 6.53 s 
2025-03-17 01:29:24.904464: Yayy! New best EMA pseudo Dice: 0.8669999837875366 
2025-03-17 01:29:25.525605:  
2025-03-17 01:29:25.531121: Epoch 24 
2025-03-17 01:29:25.534629: Current learning rate: 0.00781 
2025-03-17 01:29:32.052377: train_loss -0.8666 
2025-03-17 01:29:32.059464: val_loss -0.845 
2025-03-17 01:29:32.063017: Pseudo dice [np.float32(0.8921), np.float32(0.8738)] 
2025-03-17 01:29:32.066082: Epoch time: 6.53 s 
2025-03-17 01:29:32.069667: Yayy! New best EMA pseudo Dice: 0.8686000108718872 
2025-03-17 01:29:32.700717:  
2025-03-17 01:29:32.706355: Epoch 25 
2025-03-17 01:29:32.709899: Current learning rate: 0.00772 
2025-03-17 01:29:39.212435: train_loss -0.8674 
2025-03-17 01:29:39.219030: val_loss -0.8525 
2025-03-17 01:29:39.222090: Pseudo dice [np.float32(0.8982), np.float32(0.8817)] 
2025-03-17 01:29:39.225136: Epoch time: 6.51 s 
2025-03-17 01:29:39.228173: Yayy! New best EMA pseudo Dice: 0.8707000017166138 
2025-03-17 01:29:39.862160:  
2025-03-17 01:29:39.867230: Epoch 26 
2025-03-17 01:29:39.870777: Current learning rate: 0.00763 
2025-03-17 01:29:46.370394: train_loss -0.8683 
2025-03-17 01:29:46.377470: val_loss -0.8486 
2025-03-17 01:29:46.380540: Pseudo dice [np.float32(0.8943), np.float32(0.8774)] 
2025-03-17 01:29:46.383646: Epoch time: 6.51 s 
2025-03-17 01:29:46.387694: Yayy! New best EMA pseudo Dice: 0.8722000122070312 
2025-03-17 01:29:47.028059:  
2025-03-17 01:29:47.032099: Epoch 27 
2025-03-17 01:29:47.036707: Current learning rate: 0.00753 
2025-03-17 01:29:53.542769: train_loss -0.8683 
2025-03-17 01:29:53.548900: val_loss -0.8509 
2025-03-17 01:29:53.551955: Pseudo dice [np.float32(0.8978), np.float32(0.8795)] 
2025-03-17 01:29:53.555502: Epoch time: 6.51 s 
2025-03-17 01:29:53.560636: Yayy! New best EMA pseudo Dice: 0.8738999962806702 
2025-03-17 01:29:54.352904:  
2025-03-17 01:29:54.359058: Epoch 28 
2025-03-17 01:29:54.362151: Current learning rate: 0.00744 
2025-03-17 01:30:00.861722: train_loss -0.8692 
2025-03-17 01:30:00.867392: val_loss -0.8526 
2025-03-17 01:30:00.871476: Pseudo dice [np.float32(0.8972), np.float32(0.8819)] 
2025-03-17 01:30:00.874559: Epoch time: 6.51 s 
2025-03-17 01:30:00.877614: Yayy! New best EMA pseudo Dice: 0.8754000067710876 
2025-03-17 01:30:01.551906:  
2025-03-17 01:30:01.555422: Epoch 29 
2025-03-17 01:30:01.558932: Current learning rate: 0.00735 
2025-03-17 01:30:08.071807: train_loss -0.8708 
2025-03-17 01:30:08.077442: val_loss -0.8516 
2025-03-17 01:30:08.080477: Pseudo dice [np.float32(0.8972), np.float32(0.8799)] 
2025-03-17 01:30:08.085023: Epoch time: 6.52 s 
2025-03-17 01:30:08.087591: Yayy! New best EMA pseudo Dice: 0.876800000667572 
2025-03-17 01:30:08.729503:  
2025-03-17 01:30:08.736130: Epoch 30 
2025-03-17 01:30:08.739697: Current learning rate: 0.00725 
2025-03-17 01:30:15.264019: train_loss -0.8696 
2025-03-17 01:30:15.269112: val_loss -0.8461 
2025-03-17 01:30:15.273197: Pseudo dice [np.float32(0.8957), np.float32(0.8729)] 
2025-03-17 01:30:15.276898: Epoch time: 6.53 s 
2025-03-17 01:30:15.279438: Yayy! New best EMA pseudo Dice: 0.8774999976158142 
2025-03-17 01:30:15.925903:  
2025-03-17 01:30:15.931960: Epoch 31 
2025-03-17 01:30:15.935099: Current learning rate: 0.00716 
2025-03-17 01:30:22.459326: train_loss -0.8719 
2025-03-17 01:30:22.465940: val_loss -0.8483 
2025-03-17 01:30:22.469005: Pseudo dice [np.float32(0.8967), np.float32(0.8764)] 
2025-03-17 01:30:22.472079: Epoch time: 6.53 s 
2025-03-17 01:30:22.475144: Yayy! New best EMA pseudo Dice: 0.8784000277519226 
2025-03-17 01:30:23.121840:  
2025-03-17 01:30:23.127972: Epoch 32 
2025-03-17 01:30:23.131495: Current learning rate: 0.00707 
2025-03-17 01:30:29.657072: train_loss -0.8725 
2025-03-17 01:30:29.664249: val_loss -0.8497 
2025-03-17 01:30:29.668955: Pseudo dice [np.float32(0.8965), np.float32(0.8787)] 
2025-03-17 01:30:29.672504: Epoch time: 6.54 s 
2025-03-17 01:30:29.676616: Yayy! New best EMA pseudo Dice: 0.8792999982833862 
2025-03-17 01:30:30.322723:  
2025-03-17 01:30:30.331369: Epoch 33 
2025-03-17 01:30:30.335936: Current learning rate: 0.00697 
2025-03-17 01:30:36.854638: train_loss -0.8726 
2025-03-17 01:30:36.861186: val_loss -0.8461 
2025-03-17 01:30:36.864733: Pseudo dice [np.float32(0.8955), np.float32(0.8737)] 
2025-03-17 01:30:36.867255: Epoch time: 6.53 s 
2025-03-17 01:30:36.870824: Yayy! New best EMA pseudo Dice: 0.8798999786376953 
2025-03-17 01:30:37.528422:  
2025-03-17 01:30:37.532861: Epoch 34 
2025-03-17 01:30:37.535872: Current learning rate: 0.00688 
2025-03-17 01:30:44.052448: train_loss -0.8748 
2025-03-17 01:30:44.059542: val_loss -0.855 
2025-03-17 01:30:44.063230: Pseudo dice [np.float32(0.8994), np.float32(0.8819)] 
2025-03-17 01:30:44.066282: Epoch time: 6.52 s 
2025-03-17 01:30:44.069814: Yayy! New best EMA pseudo Dice: 0.8809000253677368 
2025-03-17 01:30:44.732209:  
2025-03-17 01:30:44.737736: Epoch 35 
2025-03-17 01:30:44.741275: Current learning rate: 0.00679 
2025-03-17 01:30:51.251167: train_loss -0.8766 
2025-03-17 01:30:51.257245: val_loss -0.8482 
2025-03-17 01:30:51.260314: Pseudo dice [np.float32(0.8963), np.float32(0.8767)] 
2025-03-17 01:30:51.263375: Epoch time: 6.52 s 
2025-03-17 01:30:51.266920: Yayy! New best EMA pseudo Dice: 0.8815000057220459 
2025-03-17 01:30:52.089225:  
2025-03-17 01:30:52.095288: Epoch 36 
2025-03-17 01:30:52.098897: Current learning rate: 0.00669 
2025-03-17 01:30:58.782215: train_loss -0.8737 
2025-03-17 01:30:58.789294: val_loss -0.8497 
2025-03-17 01:30:58.792812: Pseudo dice [np.float32(0.8958), np.float32(0.8782)] 
2025-03-17 01:30:58.796322: Epoch time: 6.69 s 
2025-03-17 01:30:58.799339: Yayy! New best EMA pseudo Dice: 0.8820000290870667 
2025-03-17 01:30:59.447438:  
2025-03-17 01:30:59.453052: Epoch 37 
2025-03-17 01:30:59.457079: Current learning rate: 0.0066 
2025-03-17 01:31:06.149759: train_loss -0.8774 
2025-03-17 01:31:06.155341: val_loss -0.853 
2025-03-17 01:31:06.159399: Pseudo dice [np.float32(0.8991), np.float32(0.882)] 
2025-03-17 01:31:06.162441: Epoch time: 6.7 s 
2025-03-17 01:31:06.165513: Yayy! New best EMA pseudo Dice: 0.8828999996185303 
2025-03-17 01:31:06.816941:  
2025-03-17 01:31:06.822989: Epoch 38 
2025-03-17 01:31:06.826034: Current learning rate: 0.0065 
2025-03-17 01:31:13.358714: train_loss -0.8763 
2025-03-17 01:31:13.364280: val_loss -0.8452 
2025-03-17 01:31:13.368832: Pseudo dice [np.float32(0.8943), np.float32(0.8732)] 
2025-03-17 01:31:13.371871: Epoch time: 6.54 s 
2025-03-17 01:31:13.375396: Yayy! New best EMA pseudo Dice: 0.8830000162124634 
2025-03-17 01:31:14.049376:  
2025-03-17 01:31:14.054889: Epoch 39 
2025-03-17 01:31:14.058402: Current learning rate: 0.00641 
2025-03-17 01:31:20.566766: train_loss -0.8761 
2025-03-17 01:31:20.572318: val_loss -0.8516 
2025-03-17 01:31:20.576273: Pseudo dice [np.float32(0.8987), np.float32(0.8796)] 
2025-03-17 01:31:20.579861: Epoch time: 6.52 s 
2025-03-17 01:31:20.582935: Yayy! New best EMA pseudo Dice: 0.8835999965667725 
2025-03-17 01:31:21.265369:  
2025-03-17 01:31:21.271514: Epoch 40 
2025-03-17 01:31:21.274581: Current learning rate: 0.00631 
2025-03-17 01:31:27.778424: train_loss -0.8779 
2025-03-17 01:31:27.784673: val_loss -0.8558 
2025-03-17 01:31:27.787983: Pseudo dice [np.float32(0.9012), np.float32(0.8834)] 
2025-03-17 01:31:27.791035: Epoch time: 6.51 s 
2025-03-17 01:31:27.794623: Yayy! New best EMA pseudo Dice: 0.8845000267028809 
2025-03-17 01:31:28.512936:  
2025-03-17 01:31:28.518985: Epoch 41 
2025-03-17 01:31:28.523022: Current learning rate: 0.00622 
2025-03-17 01:31:35.040332: train_loss -0.878 
2025-03-17 01:31:35.045957: val_loss -0.854 
2025-03-17 01:31:35.049023: Pseudo dice [np.float32(0.8992), np.float32(0.882)] 
2025-03-17 01:31:35.053097: Epoch time: 6.53 s 
2025-03-17 01:31:35.056176: Yayy! New best EMA pseudo Dice: 0.8851000070571899 
2025-03-17 01:31:35.685741:  
2025-03-17 01:31:35.691320: Epoch 42 
2025-03-17 01:31:35.693922: Current learning rate: 0.00612 
2025-03-17 01:31:42.199123: train_loss -0.8798 
2025-03-17 01:31:42.205145: val_loss -0.8523 
2025-03-17 01:31:42.207945: Pseudo dice [np.float32(0.8975), np.float32(0.8816)] 
2025-03-17 01:31:42.212185: Epoch time: 6.51 s 
2025-03-17 01:31:42.214730: Yayy! New best EMA pseudo Dice: 0.8855000138282776 
2025-03-17 01:31:42.853560:  
2025-03-17 01:31:42.859124: Epoch 43 
2025-03-17 01:31:42.861671: Current learning rate: 0.00603 
2025-03-17 01:31:49.357102: train_loss -0.8796 
2025-03-17 01:31:49.363692: val_loss -0.8493 
2025-03-17 01:31:49.367251: Pseudo dice [np.float32(0.8975), np.float32(0.8779)] 
2025-03-17 01:31:49.370285: Epoch time: 6.5 s 
2025-03-17 01:31:49.373320: Yayy! New best EMA pseudo Dice: 0.885699987411499 
2025-03-17 01:31:50.160806:  
2025-03-17 01:31:50.164849: Epoch 44 
2025-03-17 01:31:50.169439: Current learning rate: 0.00593 
2025-03-17 01:31:56.698549: train_loss -0.8809 
2025-03-17 01:31:56.704564: val_loss -0.8517 
2025-03-17 01:31:56.708576: Pseudo dice [np.float32(0.8979), np.float32(0.8805)] 
2025-03-17 01:31:56.712088: Epoch time: 6.54 s 
2025-03-17 01:31:56.715595: Yayy! New best EMA pseudo Dice: 0.8860999941825867 
2025-03-17 01:31:57.345488:  
2025-03-17 01:31:57.350962: Epoch 45 
2025-03-17 01:31:57.355055: Current learning rate: 0.00584 
2025-03-17 01:32:03.875912: train_loss -0.8829 
2025-03-17 01:32:03.882011: val_loss -0.8488 
2025-03-17 01:32:03.885597: Pseudo dice [np.float32(0.8973), np.float32(0.8767)] 
2025-03-17 01:32:03.888105: Epoch time: 6.53 s 
2025-03-17 01:32:03.891201: Yayy! New best EMA pseudo Dice: 0.8862000107765198 
2025-03-17 01:32:04.518008:  
2025-03-17 01:32:04.523544: Epoch 46 
2025-03-17 01:32:04.527053: Current learning rate: 0.00574 
2025-03-17 01:32:11.051668: train_loss -0.8811 
2025-03-17 01:32:11.057311: val_loss -0.8513 
2025-03-17 01:32:11.060377: Pseudo dice [np.float32(0.8976), np.float32(0.8793)] 
2025-03-17 01:32:11.064436: Epoch time: 6.53 s 
2025-03-17 01:32:11.067500: Yayy! New best EMA pseudo Dice: 0.8863999843597412 
2025-03-17 01:32:11.697574:  
2025-03-17 01:32:11.702596: Epoch 47 
2025-03-17 01:32:11.706109: Current learning rate: 0.00565 
2025-03-17 01:32:18.240485: train_loss -0.8838 
2025-03-17 01:32:18.247050: val_loss -0.8516 
2025-03-17 01:32:18.249562: Pseudo dice [np.float32(0.8976), np.float32(0.8797)] 
2025-03-17 01:32:18.253584: Epoch time: 6.54 s 
2025-03-17 01:32:18.256606: Yayy! New best EMA pseudo Dice: 0.8866000175476074 
2025-03-17 01:32:18.877849:  
2025-03-17 01:32:18.883364: Epoch 48 
2025-03-17 01:32:18.886874: Current learning rate: 0.00555 
2025-03-17 01:32:25.404711: train_loss -0.8844 
2025-03-17 01:32:25.410311: val_loss -0.8474 
2025-03-17 01:32:25.413862: Pseudo dice [np.float32(0.8968), np.float32(0.8763)] 
2025-03-17 01:32:25.416856: Epoch time: 6.53 s 
2025-03-17 01:32:26.015997:  
2025-03-17 01:32:26.022568: Epoch 49 
2025-03-17 01:32:26.026189: Current learning rate: 0.00546 
2025-03-17 01:32:32.529601: train_loss -0.884 
2025-03-17 01:32:32.537297: val_loss -0.8524 
2025-03-17 01:32:32.540836: Pseudo dice [np.float32(0.8998), np.float32(0.8796)] 
2025-03-17 01:32:32.544400: Epoch time: 6.51 s 
2025-03-17 01:32:32.582983: Yayy! New best EMA pseudo Dice: 0.886900007724762 
2025-03-17 01:32:33.229262:  
2025-03-17 01:32:33.235276: Epoch 50 
2025-03-17 01:32:33.238786: Current learning rate: 0.00536 
2025-03-17 01:32:39.730777: train_loss -0.8848 
2025-03-17 01:32:39.737455: val_loss -0.8477 
2025-03-17 01:32:39.741042: Pseudo dice [np.float32(0.8972), np.float32(0.8746)] 
2025-03-17 01:32:39.743548: Epoch time: 6.5 s 
2025-03-17 01:32:40.502172:  
2025-03-17 01:32:40.507742: Epoch 51 
2025-03-17 01:32:40.512325: Current learning rate: 0.00526 
2025-03-17 01:32:47.034644: train_loss -0.8838 
2025-03-17 01:32:47.040327: val_loss -0.8493 
2025-03-17 01:32:47.045987: Pseudo dice [np.float32(0.8965), np.float32(0.8785)] 
2025-03-17 01:32:47.051064: Epoch time: 6.53 s 
2025-03-17 01:32:47.652152:  
2025-03-17 01:32:47.656173: Epoch 52 
2025-03-17 01:32:47.659687: Current learning rate: 0.00517 
2025-03-17 01:32:54.179724: train_loss -0.8845 
2025-03-17 01:32:54.185777: val_loss -0.851 
2025-03-17 01:32:54.189353: Pseudo dice [np.float32(0.8989), np.float32(0.879)] 
2025-03-17 01:32:54.191804: Epoch time: 6.53 s 
2025-03-17 01:32:54.195909: Yayy! New best EMA pseudo Dice: 0.8870999813079834 
2025-03-17 01:32:54.839009:  
2025-03-17 01:32:54.844918: Epoch 53 
2025-03-17 01:32:54.848427: Current learning rate: 0.00507 
2025-03-17 01:33:01.370720: train_loss -0.8864 
2025-03-17 01:33:01.376825: val_loss -0.8463 
2025-03-17 01:33:01.380476: Pseudo dice [np.float32(0.8947), np.float32(0.8766)] 
2025-03-17 01:33:01.383531: Epoch time: 6.53 s 
2025-03-17 01:33:01.988320:  
2025-03-17 01:33:01.994341: Epoch 54 
2025-03-17 01:33:01.997850: Current learning rate: 0.00497 
2025-03-17 01:33:08.514225: train_loss -0.8871 
2025-03-17 01:33:08.520243: val_loss -0.8506 
2025-03-17 01:33:08.524252: Pseudo dice [np.float32(0.8978), np.float32(0.8801)] 
2025-03-17 01:33:08.527764: Epoch time: 6.53 s 
2025-03-17 01:33:08.529994: Yayy! New best EMA pseudo Dice: 0.8870999813079834 
2025-03-17 01:33:09.164850:  
2025-03-17 01:33:09.170420: Epoch 55 
2025-03-17 01:33:09.172969: Current learning rate: 0.00487 
2025-03-17 01:33:15.694822: train_loss -0.8872 
2025-03-17 01:33:15.700872: val_loss -0.8464 
2025-03-17 01:33:15.703893: Pseudo dice [np.float32(0.8948), np.float32(0.876)] 
2025-03-17 01:33:15.706444: Epoch time: 6.53 s 
2025-03-17 01:33:16.302834:  
2025-03-17 01:33:16.308400: Epoch 56 
2025-03-17 01:33:16.312026: Current learning rate: 0.00478 
2025-03-17 01:33:22.813524: train_loss -0.8875 
2025-03-17 01:33:22.820625: val_loss -0.8493 
2025-03-17 01:33:22.823747: Pseudo dice [np.float32(0.8973), np.float32(0.8801)] 
2025-03-17 01:33:22.827785: Epoch time: 6.51 s 
2025-03-17 01:33:23.420330:  
2025-03-17 01:33:23.425893: Epoch 57 
2025-03-17 01:33:23.429952: Current learning rate: 0.00468 
2025-03-17 01:33:29.952066: train_loss -0.8878 
2025-03-17 01:33:29.958162: val_loss -0.8478 
2025-03-17 01:33:29.961774: Pseudo dice [np.float32(0.8952), np.float32(0.8778)] 
2025-03-17 01:33:29.965330: Epoch time: 6.53 s 
2025-03-17 01:33:30.571008:  
2025-03-17 01:33:30.576641: Epoch 58 
2025-03-17 01:33:30.579211: Current learning rate: 0.00458 
2025-03-17 01:33:37.081061: train_loss -0.8882 
2025-03-17 01:33:37.088207: val_loss -0.8496 
2025-03-17 01:33:37.091272: Pseudo dice [np.float32(0.8962), np.float32(0.879)] 
2025-03-17 01:33:37.095330: Epoch time: 6.51 s 
2025-03-17 01:33:37.868431:  
2025-03-17 01:33:37.874454: Epoch 59 
2025-03-17 01:33:37.876968: Current learning rate: 0.00448 
2025-03-17 01:33:44.517429: train_loss -0.8897 
2025-03-17 01:33:44.523980: val_loss -0.8453 
2025-03-17 01:33:44.528010: Pseudo dice [np.float32(0.8934), np.float32(0.8773)] 
2025-03-17 01:33:44.531581: Epoch time: 6.65 s 
2025-03-17 01:33:45.132633:  
2025-03-17 01:33:45.137184: Epoch 60 
2025-03-17 01:33:45.140275: Current learning rate: 0.00438 
2025-03-17 01:33:51.646420: train_loss -0.889 
2025-03-17 01:33:51.652575: val_loss -0.8405 
2025-03-17 01:33:51.656142: Pseudo dice [np.float32(0.8917), np.float32(0.8721)] 
2025-03-17 01:33:51.658174: Epoch time: 6.51 s 
2025-03-17 01:33:52.255514:  
2025-03-17 01:33:52.259589: Epoch 61 
2025-03-17 01:33:52.263673: Current learning rate: 0.00429 
2025-03-17 01:33:58.747770: train_loss -0.8883 
2025-03-17 01:33:58.754880: val_loss -0.8516 
2025-03-17 01:33:58.758489: Pseudo dice [np.float32(0.8995), np.float32(0.8797)] 
2025-03-17 01:33:58.760999: Epoch time: 6.49 s 
2025-03-17 01:33:59.365814:  
2025-03-17 01:33:59.371374: Epoch 62 
2025-03-17 01:33:59.374927: Current learning rate: 0.00419 
2025-03-17 01:34:05.851838: train_loss -0.8917 
2025-03-17 01:34:05.858983: val_loss -0.8444 
2025-03-17 01:34:05.862073: Pseudo dice [np.float32(0.8944), np.float32(0.8746)] 
2025-03-17 01:34:05.865617: Epoch time: 6.49 s 
2025-03-17 01:34:06.494204:  
2025-03-17 01:34:06.499774: Epoch 63 
2025-03-17 01:34:06.502323: Current learning rate: 0.00409 
2025-03-17 01:34:12.960784: train_loss -0.8928 
2025-03-17 01:34:12.966151: val_loss -0.8494 
2025-03-17 01:34:12.970182: Pseudo dice [np.float32(0.8965), np.float32(0.8801)] 
2025-03-17 01:34:12.973821: Epoch time: 6.47 s 
2025-03-17 01:34:13.599022:  
2025-03-17 01:34:13.604041: Epoch 64 
2025-03-17 01:34:13.607563: Current learning rate: 0.00399 
2025-03-17 01:34:20.064936: train_loss -0.8914 
2025-03-17 01:34:20.071087: val_loss -0.8442 
2025-03-17 01:34:20.073639: Pseudo dice [np.float32(0.8944), np.float32(0.8751)] 
2025-03-17 01:34:20.077777: Epoch time: 6.47 s 
2025-03-17 01:34:20.687035:  
2025-03-17 01:34:20.692682: Epoch 65 
2025-03-17 01:34:20.696262: Current learning rate: 0.00389 
2025-03-17 01:34:27.193181: train_loss -0.8942 
2025-03-17 01:34:27.199316: val_loss -0.8477 
2025-03-17 01:34:27.201359: Pseudo dice [np.float32(0.896), np.float32(0.878)] 
2025-03-17 01:34:27.205937: Epoch time: 6.51 s 
2025-03-17 01:34:27.807353:  
2025-03-17 01:34:27.812924: Epoch 66 
2025-03-17 01:34:27.817000: Current learning rate: 0.00379 
2025-03-17 01:34:34.292044: train_loss -0.8942 
2025-03-17 01:34:34.298656: val_loss -0.8465 
2025-03-17 01:34:34.301741: Pseudo dice [np.float32(0.8941), np.float32(0.8778)] 
2025-03-17 01:34:34.305438: Epoch time: 6.48 s 
2025-03-17 01:34:35.063542:  
2025-03-17 01:34:35.069064: Epoch 67 
2025-03-17 01:34:35.072580: Current learning rate: 0.00369 
2025-03-17 01:34:41.556730: train_loss -0.8941 
2025-03-17 01:34:41.563288: val_loss -0.8448 
2025-03-17 01:34:41.565853: Pseudo dice [np.float32(0.8934), np.float32(0.8763)] 
2025-03-17 01:34:41.569373: Epoch time: 6.49 s 
2025-03-17 01:34:42.179630:  
2025-03-17 01:34:42.185226: Epoch 68 
2025-03-17 01:34:42.187844: Current learning rate: 0.00359 
2025-03-17 01:34:48.670864: train_loss -0.8955 
2025-03-17 01:34:48.677028: val_loss -0.8513 
2025-03-17 01:34:48.680636: Pseudo dice [np.float32(0.8992), np.float32(0.8803)] 
2025-03-17 01:34:48.684324: Epoch time: 6.49 s 
2025-03-17 01:34:49.285274:  
2025-03-17 01:34:49.290806: Epoch 69 
2025-03-17 01:34:49.294322: Current learning rate: 0.00349 
2025-03-17 01:34:55.787611: train_loss -0.8954 
2025-03-17 01:34:55.792660: val_loss -0.8486 
2025-03-17 01:34:55.796207: Pseudo dice [np.float32(0.8977), np.float32(0.8772)] 
2025-03-17 01:34:55.799736: Epoch time: 6.5 s 
2025-03-17 01:34:56.405680:  
2025-03-17 01:34:56.412307: Epoch 70 
2025-03-17 01:34:56.414882: Current learning rate: 0.00338 
2025-03-17 01:35:02.912722: train_loss -0.896 
2025-03-17 01:35:02.917792: val_loss -0.8507 
2025-03-17 01:35:02.921896: Pseudo dice [np.float32(0.8998), np.float32(0.8786)] 
2025-03-17 01:35:02.925483: Epoch time: 6.51 s 
2025-03-17 01:35:03.533284:  
2025-03-17 01:35:03.539304: Epoch 71 
2025-03-17 01:35:03.542809: Current learning rate: 0.00328 
2025-03-17 01:35:10.015981: train_loss -0.8939 
2025-03-17 01:35:10.021610: val_loss -0.8448 
2025-03-17 01:35:10.025697: Pseudo dice [np.float32(0.8947), np.float32(0.8759)] 
2025-03-17 01:35:10.028780: Epoch time: 6.48 s 
2025-03-17 01:35:10.648340:  
2025-03-17 01:35:10.653857: Epoch 72 
2025-03-17 01:35:10.657368: Current learning rate: 0.00318 
2025-03-17 01:35:17.141699: train_loss -0.8949 
2025-03-17 01:35:17.147279: val_loss -0.853 
2025-03-17 01:35:17.151260: Pseudo dice [np.float32(0.8991), np.float32(0.882)] 
2025-03-17 01:35:17.154341: Epoch time: 6.49 s 
2025-03-17 01:35:17.157876: Yayy! New best EMA pseudo Dice: 0.8871999979019165 
2025-03-17 01:35:17.848060:  
2025-03-17 01:35:17.854102: Epoch 73 
2025-03-17 01:35:17.857155: Current learning rate: 0.00308 
2025-03-17 01:35:24.332735: train_loss -0.8967 
2025-03-17 01:35:24.338825: val_loss -0.848 
2025-03-17 01:35:24.342363: Pseudo dice [np.float32(0.8963), np.float32(0.8783)] 
2025-03-17 01:35:24.345944: Epoch time: 6.49 s 
2025-03-17 01:35:24.349060: Yayy! New best EMA pseudo Dice: 0.8871999979019165 
2025-03-17 01:35:25.163296:  
2025-03-17 01:35:25.167333: Epoch 74 
2025-03-17 01:35:25.170878: Current learning rate: 0.00297 
2025-03-17 01:35:31.657229: train_loss -0.8973 
2025-03-17 01:35:31.663391: val_loss -0.8486 
2025-03-17 01:35:31.666441: Pseudo dice [np.float32(0.8971), np.float32(0.8795)] 
2025-03-17 01:35:31.668996: Epoch time: 6.49 s 
2025-03-17 01:35:31.673055: Yayy! New best EMA pseudo Dice: 0.8873000144958496 
2025-03-17 01:35:32.315917:  
2025-03-17 01:35:32.324552: Epoch 75 
2025-03-17 01:35:32.329145: Current learning rate: 0.00287 
2025-03-17 01:35:38.819348: train_loss -0.8985 
2025-03-17 01:35:38.825494: val_loss -0.8479 
2025-03-17 01:35:38.829073: Pseudo dice [np.float32(0.8967), np.float32(0.8787)] 
2025-03-17 01:35:38.831612: Epoch time: 6.5 s 
2025-03-17 01:35:38.835675: Yayy! New best EMA pseudo Dice: 0.8873999714851379 
2025-03-17 01:35:39.481112:  
2025-03-17 01:35:39.486683: Epoch 76 
2025-03-17 01:35:39.490290: Current learning rate: 0.00277 
2025-03-17 01:35:45.984092: train_loss -0.8975 
2025-03-17 01:35:45.989715: val_loss -0.8497 
2025-03-17 01:35:45.993907: Pseudo dice [np.float32(0.8975), np.float32(0.8799)] 
2025-03-17 01:35:45.997142: Epoch time: 6.5 s 
2025-03-17 01:35:46.000178: Yayy! New best EMA pseudo Dice: 0.887499988079071 
2025-03-17 01:35:46.640345:  
2025-03-17 01:35:46.646455: Epoch 77 
2025-03-17 01:35:46.649574: Current learning rate: 0.00266 
2025-03-17 01:35:53.146622: train_loss -0.8977 
2025-03-17 01:35:53.153780: val_loss -0.8472 
2025-03-17 01:35:53.156854: Pseudo dice [np.float32(0.8968), np.float32(0.8764)] 
2025-03-17 01:35:53.159935: Epoch time: 6.51 s 
2025-03-17 01:35:53.767250:  
2025-03-17 01:35:53.773367: Epoch 78 
2025-03-17 01:35:53.776452: Current learning rate: 0.00256 
2025-03-17 01:36:00.265215: train_loss -0.8989 
2025-03-17 01:36:00.271303: val_loss -0.8495 
2025-03-17 01:36:00.274354: Pseudo dice [np.float32(0.8981), np.float32(0.8791)] 
2025-03-17 01:36:00.277386: Epoch time: 6.5 s 
2025-03-17 01:36:00.280914: Yayy! New best EMA pseudo Dice: 0.887499988079071 
2025-03-17 01:36:00.941373:  
2025-03-17 01:36:00.946942: Epoch 79 
2025-03-17 01:36:00.950518: Current learning rate: 0.00245 
2025-03-17 01:36:07.419525: train_loss -0.8994 
2025-03-17 01:36:07.424609: val_loss -0.848 
2025-03-17 01:36:07.429206: Pseudo dice [np.float32(0.8975), np.float32(0.8792)] 
2025-03-17 01:36:07.431713: Epoch time: 6.48 s 
2025-03-17 01:36:07.435765: Yayy! New best EMA pseudo Dice: 0.8876000046730042 
2025-03-17 01:36:08.096273:  
2025-03-17 01:36:08.101786: Epoch 80 
2025-03-17 01:36:08.105297: Current learning rate: 0.00235 
2025-03-17 01:36:14.569217: train_loss -0.8991 
2025-03-17 01:36:14.573858: val_loss -0.8455 
2025-03-17 01:36:14.576946: Pseudo dice [np.float32(0.8965), np.float32(0.8763)] 
2025-03-17 01:36:14.580017: Epoch time: 6.47 s 
2025-03-17 01:36:15.364814:  
2025-03-17 01:36:15.370828: Epoch 81 
2025-03-17 01:36:15.374336: Current learning rate: 0.00224 
2025-03-17 01:36:21.853245: train_loss -0.9002 
2025-03-17 01:36:21.859324: val_loss -0.8515 
2025-03-17 01:36:21.861713: Pseudo dice [np.float32(0.8995), np.float32(0.8804)] 
2025-03-17 01:36:21.865737: Epoch time: 6.49 s 
2025-03-17 01:36:21.869258: Yayy! New best EMA pseudo Dice: 0.8877000212669373 
2025-03-17 01:36:22.551116:  
2025-03-17 01:36:22.557163: Epoch 82 
2025-03-17 01:36:22.560955: Current learning rate: 0.00214 
2025-03-17 01:36:29.028078: train_loss -0.8997 
2025-03-17 01:36:29.033666: val_loss -0.8489 
2025-03-17 01:36:29.037907: Pseudo dice [np.float32(0.8979), np.float32(0.8788)] 
2025-03-17 01:36:29.041924: Epoch time: 6.48 s 
2025-03-17 01:36:29.045522: Yayy! New best EMA pseudo Dice: 0.8877999782562256 
2025-03-17 01:36:29.675134:  
2025-03-17 01:36:29.679147: Epoch 83 
2025-03-17 01:36:29.681658: Current learning rate: 0.00203 
2025-03-17 01:36:36.152816: train_loss -0.9002 
2025-03-17 01:36:36.158859: val_loss -0.8453 
2025-03-17 01:36:36.162920: Pseudo dice [np.float32(0.8959), np.float32(0.8763)] 
2025-03-17 01:36:36.166442: Epoch time: 6.48 s 
2025-03-17 01:36:36.748013:  
2025-03-17 01:36:36.753570: Epoch 84 
2025-03-17 01:36:36.756123: Current learning rate: 0.00192 
2025-03-17 01:36:43.221627: train_loss -0.9032 
2025-03-17 01:36:43.227284: val_loss -0.8451 
2025-03-17 01:36:43.231838: Pseudo dice [np.float32(0.8954), np.float32(0.8768)] 
2025-03-17 01:36:43.234436: Epoch time: 6.47 s 
2025-03-17 01:36:43.813461:  
2025-03-17 01:36:43.817502: Epoch 85 
2025-03-17 01:36:43.821583: Current learning rate: 0.00181 
2025-03-17 01:36:50.307543: train_loss -0.9019 
2025-03-17 01:36:50.313562: val_loss -0.8471 
2025-03-17 01:36:50.317070: Pseudo dice [np.float32(0.8956), np.float32(0.8795)] 
2025-03-17 01:36:50.320078: Epoch time: 6.49 s 
2025-03-17 01:36:50.913766:  
2025-03-17 01:36:50.917797: Epoch 86 
2025-03-17 01:36:50.921341: Current learning rate: 0.0017 
2025-03-17 01:36:57.384767: train_loss -0.9022 
2025-03-17 01:36:57.390839: val_loss -0.8422 
2025-03-17 01:36:57.393925: Pseudo dice [np.float32(0.8932), np.float32(0.8751)] 
2025-03-17 01:36:57.396946: Epoch time: 6.47 s 
2025-03-17 01:36:57.980685:  
2025-03-17 01:36:57.986747: Epoch 87 
2025-03-17 01:36:57.989822: Current learning rate: 0.00159 
2025-03-17 01:37:04.459144: train_loss -0.9025 
2025-03-17 01:37:04.465744: val_loss -0.8463 
2025-03-17 01:37:04.469322: Pseudo dice [np.float32(0.8967), np.float32(0.8769)] 
2025-03-17 01:37:04.471882: Epoch time: 6.48 s 
2025-03-17 01:37:05.067692:  
2025-03-17 01:37:05.073258: Epoch 88 
2025-03-17 01:37:05.077353: Current learning rate: 0.00148 
2025-03-17 01:37:11.532421: train_loss -0.9017 
2025-03-17 01:37:11.537985: val_loss -0.8484 
2025-03-17 01:37:11.541022: Pseudo dice [np.float32(0.8973), np.float32(0.8798)] 
2025-03-17 01:37:11.544549: Epoch time: 6.46 s 
2025-03-17 01:37:12.295264:  
2025-03-17 01:37:12.300776: Epoch 89 
2025-03-17 01:37:12.304287: Current learning rate: 0.00137 
2025-03-17 01:37:18.785566: train_loss -0.9036 
2025-03-17 01:37:18.791698: val_loss -0.8491 
2025-03-17 01:37:18.795758: Pseudo dice [np.float32(0.8981), np.float32(0.8797)] 
2025-03-17 01:37:18.798804: Epoch time: 6.49 s 
2025-03-17 01:37:19.375485:  
2025-03-17 01:37:19.381015: Epoch 90 
2025-03-17 01:37:19.384554: Current learning rate: 0.00126 
2025-03-17 01:37:25.869561: train_loss -0.9016 
2025-03-17 01:37:25.875227: val_loss -0.8497 
2025-03-17 01:37:25.878767: Pseudo dice [np.float32(0.8978), np.float32(0.8795)] 
2025-03-17 01:37:25.882297: Epoch time: 6.5 s 
2025-03-17 01:37:26.452999:  
2025-03-17 01:37:26.458580: Epoch 91 
2025-03-17 01:37:26.461699: Current learning rate: 0.00115 
2025-03-17 01:37:32.939663: train_loss -0.9028 
2025-03-17 01:37:32.946744: val_loss -0.8475 
2025-03-17 01:37:32.950364: Pseudo dice [np.float32(0.8966), np.float32(0.8782)] 
2025-03-17 01:37:32.953929: Epoch time: 6.49 s 
2025-03-17 01:37:33.526690:  
2025-03-17 01:37:33.531729: Epoch 92 
2025-03-17 01:37:33.535884: Current learning rate: 0.00103 
2025-03-17 01:37:40.010274: train_loss -0.9021 
2025-03-17 01:37:40.015885: val_loss -0.8476 
2025-03-17 01:37:40.018420: Pseudo dice [np.float32(0.8968), np.float32(0.88)] 
2025-03-17 01:37:40.022999: Epoch time: 6.48 s 
2025-03-17 01:37:40.610427:  
2025-03-17 01:37:40.617018: Epoch 93 
2025-03-17 01:37:40.621128: Current learning rate: 0.00091 
2025-03-17 01:37:47.089901: train_loss -0.9035 
2025-03-17 01:37:47.095556: val_loss -0.8482 
2025-03-17 01:37:47.099620: Pseudo dice [np.float32(0.8978), np.float32(0.8798)] 
2025-03-17 01:37:47.102185: Epoch time: 6.48 s 
2025-03-17 01:37:47.704700:  
2025-03-17 01:37:47.710746: Epoch 94 
2025-03-17 01:37:47.714329: Current learning rate: 0.00079 
2025-03-17 01:37:54.188515: train_loss -0.9037 
2025-03-17 01:37:54.194564: val_loss -0.8473 
2025-03-17 01:37:54.198095: Pseudo dice [np.float32(0.8974), np.float32(0.8775)] 
2025-03-17 01:37:54.201151: Epoch time: 6.48 s 
2025-03-17 01:37:54.791597:  
2025-03-17 01:37:54.797109: Epoch 95 
2025-03-17 01:37:54.800622: Current learning rate: 0.00067 
2025-03-17 01:38:01.242816: train_loss -0.9054 
2025-03-17 01:38:01.248925: val_loss -0.8497 
2025-03-17 01:38:01.251467: Pseudo dice [np.float32(0.8991), np.float32(0.8805)] 
2025-03-17 01:38:01.256050: Epoch time: 6.45 s 
2025-03-17 01:38:01.259127: Yayy! New best EMA pseudo Dice: 0.8878999948501587 
2025-03-17 01:38:01.886076:  
2025-03-17 01:38:01.892090: Epoch 96 
2025-03-17 01:38:01.896103: Current learning rate: 0.00055 
2025-03-17 01:38:08.355048: train_loss -0.9047 
2025-03-17 01:38:08.361212: val_loss -0.8497 
2025-03-17 01:38:08.364745: Pseudo dice [np.float32(0.899), np.float32(0.8794)] 
2025-03-17 01:38:08.367772: Epoch time: 6.47 s 
2025-03-17 01:38:08.371313: Yayy! New best EMA pseudo Dice: 0.8880000114440918 
2025-03-17 01:38:09.159933:  
2025-03-17 01:38:09.166094: Epoch 97 
2025-03-17 01:38:09.169679: Current learning rate: 0.00043 
2025-03-17 01:38:15.655788: train_loss -0.9048 
2025-03-17 01:38:15.662798: val_loss -0.8452 
2025-03-17 01:38:15.666562: Pseudo dice [np.float32(0.8968), np.float32(0.8759)] 
2025-03-17 01:38:15.669631: Epoch time: 6.5 s 
2025-03-17 01:38:16.252153:  
2025-03-17 01:38:16.257674: Epoch 98 
2025-03-17 01:38:16.261186: Current learning rate: 0.0003 
2025-03-17 01:38:22.745451: train_loss -0.9064 
2025-03-17 01:38:22.751534: val_loss -0.8464 
2025-03-17 01:38:22.755073: Pseudo dice [np.float32(0.8964), np.float32(0.878)] 
2025-03-17 01:38:22.758165: Epoch time: 6.49 s 
2025-03-17 01:38:23.340607:  
2025-03-17 01:38:23.346714: Epoch 99 
2025-03-17 01:38:23.350729: Current learning rate: 0.00016 
2025-03-17 01:38:29.852305: train_loss -0.9061 
2025-03-17 01:38:29.857419: val_loss -0.8409 
2025-03-17 01:38:29.862113: Pseudo dice [np.float32(0.8921), np.float32(0.8749)] 
2025-03-17 01:38:29.865191: Epoch time: 6.51 s 
2025-03-17 01:38:30.503917: Training done. 
2025-03-17 01:38:30.538917: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2025-03-17 01:38:30.545918: The split file contains 5 splits. 
2025-03-17 01:38:30.551918: Desired fold for training: 0 
2025-03-17 01:38:30.556917: This split has 208 training and 52 validation cases. 
2025-03-17 01:38:30.562918: predicting hippocampus_017 
2025-03-17 01:38:30.567923: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2025-03-17 01:38:30.670367: predicting hippocampus_019 
2025-03-17 01:38:30.676368: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2025-03-17 01:38:30.719875: predicting hippocampus_033 
2025-03-17 01:38:30.725877: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2025-03-17 01:38:30.751876: predicting hippocampus_035 
2025-03-17 01:38:30.758876: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2025-03-17 01:38:30.783931: predicting hippocampus_037 
2025-03-17 01:38:30.790931: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2025-03-17 01:38:30.816931: predicting hippocampus_049 
2025-03-17 01:38:30.823931: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2025-03-17 01:38:30.849930: predicting hippocampus_052 
2025-03-17 01:38:30.856930: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2025-03-17 01:38:30.879438: predicting hippocampus_065 
2025-03-17 01:38:30.886438: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2025-03-17 01:38:30.913438: predicting hippocampus_083 
2025-03-17 01:38:30.920439: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2025-03-17 01:38:30.949438: predicting hippocampus_088 
2025-03-17 01:38:30.955438: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2025-03-17 01:38:34.507283: predicting hippocampus_090 
2025-03-17 01:38:34.514788: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2025-03-17 01:38:34.562788: predicting hippocampus_092 
2025-03-17 01:38:34.576792: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2025-03-17 01:38:34.637300: predicting hippocampus_095 
2025-03-17 01:38:34.653300: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2025-03-17 01:38:34.725806: predicting hippocampus_107 
2025-03-17 01:38:34.732806: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2025-03-17 01:38:34.775809: predicting hippocampus_108 
2025-03-17 01:38:34.784321: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2025-03-17 01:38:34.819319: predicting hippocampus_123 
2025-03-17 01:38:34.826321: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2025-03-17 01:38:34.863320: predicting hippocampus_125 
2025-03-17 01:38:34.871325: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2025-03-17 01:38:34.933831: predicting hippocampus_157 
2025-03-17 01:38:34.941833: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2025-03-17 01:38:34.977833: predicting hippocampus_164 
2025-03-17 01:38:34.985339: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2025-03-17 01:38:35.063339: predicting hippocampus_169 
2025-03-17 01:38:35.070341: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2025-03-17 01:38:35.096846: predicting hippocampus_175 
2025-03-17 01:38:35.103848: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2025-03-17 01:38:35.133846: predicting hippocampus_185 
2025-03-17 01:38:35.139848: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2025-03-17 01:38:35.166848: predicting hippocampus_190 
2025-03-17 01:38:35.174850: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2025-03-17 01:38:35.206356: predicting hippocampus_194 
2025-03-17 01:38:35.213358: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2025-03-17 01:38:35.239356: predicting hippocampus_204 
2025-03-17 01:38:35.245356: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2025-03-17 01:38:35.274359: predicting hippocampus_205 
2025-03-17 01:38:35.280865: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2025-03-17 01:38:35.308864: predicting hippocampus_210 
2025-03-17 01:38:35.314864: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2025-03-17 01:38:35.341864: predicting hippocampus_217 
2025-03-17 01:38:35.347864: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2025-03-17 01:38:35.373866: predicting hippocampus_219 
2025-03-17 01:38:35.380373: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2025-03-17 01:38:35.406372: predicting hippocampus_229 
2025-03-17 01:38:35.413373: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2025-03-17 01:38:35.439372: predicting hippocampus_244 
2025-03-17 01:38:35.447374: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2025-03-17 01:38:35.474375: predicting hippocampus_261 
2025-03-17 01:38:35.480881: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2025-03-17 01:38:35.524881: predicting hippocampus_264 
2025-03-17 01:38:35.529881: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2025-03-17 01:38:35.556884: predicting hippocampus_277 
2025-03-17 01:38:35.564884: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2025-03-17 01:38:35.609389: predicting hippocampus_280 
2025-03-17 01:38:35.616391: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2025-03-17 01:38:35.646389: predicting hippocampus_286 
2025-03-17 01:38:35.653389: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2025-03-17 01:38:35.697896: predicting hippocampus_288 
2025-03-17 01:38:35.705896: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2025-03-17 01:38:35.750896: predicting hippocampus_289 
2025-03-17 01:38:35.757896: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2025-03-17 01:38:35.784409: predicting hippocampus_296 
2025-03-17 01:38:35.791409: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2025-03-17 01:38:35.818409: predicting hippocampus_305 
2025-03-17 01:38:35.825409: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2025-03-17 01:38:35.851409: predicting hippocampus_308 
2025-03-17 01:38:35.856410: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2025-03-17 01:38:35.882917: predicting hippocampus_317 
2025-03-17 01:38:35.887919: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2025-03-17 01:38:35.914918: predicting hippocampus_327 
2025-03-17 01:38:35.920920: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2025-03-17 01:38:35.946917: predicting hippocampus_330 
2025-03-17 01:38:35.952919: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2025-03-17 01:38:35.980425: predicting hippocampus_332 
2025-03-17 01:38:35.985426: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2025-03-17 01:38:36.013425: predicting hippocampus_338 
2025-03-17 01:38:36.019425: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2025-03-17 01:38:36.066428: predicting hippocampus_349 
2025-03-17 01:38:36.071428: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2025-03-17 01:38:36.096934: predicting hippocampus_350 
2025-03-17 01:38:36.102935: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2025-03-17 01:38:36.128934: predicting hippocampus_356 
2025-03-17 01:38:36.134936: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2025-03-17 01:38:36.160934: predicting hippocampus_358 
2025-03-17 01:38:36.166939: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2025-03-17 01:38:36.193443: predicting hippocampus_374 
2025-03-17 01:38:36.198444: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2025-03-17 01:38:36.226443: predicting hippocampus_394 
2025-03-17 01:38:36.232445: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2025-03-17 01:38:39.850423: Validation complete 
2025-03-17 01:38:39.856423: Mean Validation Dice:  0.8922837824947139 
