
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-07 20:44:19.805050: do_dummy_2d_data_aug: False 
2024-12-07 20:44:19.812013: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-07 20:44:19.820189: The split file contains 5 splits. 
2024-12-07 20:44:19.820189: Desired fold for training: 0 
2024-12-07 20:44:19.826713: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-07 20:44:25.538483: unpacking dataset... 
2024-12-07 20:44:25.872118: unpacking done... 
2024-12-07 20:44:26.903287:  
2024-12-07 20:44:26.908389: Epoch 0 
2024-12-07 20:44:26.911440: Current learning rate: 0.01 
2024-12-07 20:44:33.926175: train_loss -0.4457 
2024-12-07 20:44:33.931245: val_loss -0.8006 
2024-12-07 20:44:33.935301: Pseudo dice [np.float32(0.8563), np.float32(0.8509)] 
2024-12-07 20:44:33.938349: Epoch time: 7.02 s 
2024-12-07 20:44:33.940915: Yayy! New best EMA pseudo Dice: 0.853600025177002 
2024-12-07 20:44:34.439680:  
2024-12-07 20:44:34.444773: Epoch 1 
2024-12-07 20:44:34.448335: Current learning rate: 0.00991 
2024-12-07 20:44:40.583985: train_loss -0.837 
2024-12-07 20:44:40.589618: val_loss -0.8399 
2024-12-07 20:44:40.593167: Pseudo dice [np.float32(0.888), np.float32(0.8742)] 
2024-12-07 20:44:40.596246: Epoch time: 6.14 s 
2024-12-07 20:44:40.599305: Yayy! New best EMA pseudo Dice: 0.8564000129699707 
2024-12-07 20:44:41.139167:  
2024-12-07 20:44:41.144733: Epoch 2 
2024-12-07 20:44:41.147788: Current learning rate: 0.00982 
2024-12-07 20:44:47.273553: train_loss -0.8648 
2024-12-07 20:44:47.281661: val_loss -0.8393 
2024-12-07 20:44:47.286767: Pseudo dice [np.float32(0.8885), np.float32(0.8736)] 
2024-12-07 20:44:47.290319: Epoch time: 6.13 s 
2024-12-07 20:44:47.292858: Yayy! New best EMA pseudo Dice: 0.8587999939918518 
2024-12-07 20:44:47.863864:  
2024-12-07 20:44:47.870445: Epoch 3 
2024-12-07 20:44:47.874029: Current learning rate: 0.00973 
2024-12-07 20:44:53.995572: train_loss -0.8809 
2024-12-07 20:44:54.001647: val_loss -0.8468 
2024-12-07 20:44:54.004703: Pseudo dice [np.float32(0.8973), np.float32(0.8796)] 
2024-12-07 20:44:54.007250: Epoch time: 6.13 s 
2024-12-07 20:44:54.010826: Yayy! New best EMA pseudo Dice: 0.8618000149726868 
2024-12-07 20:44:54.560742:  
2024-12-07 20:44:54.566827: Epoch 4 
2024-12-07 20:44:54.570369: Current learning rate: 0.00964 
2024-12-07 20:45:00.686331: train_loss -0.8942 
2024-12-07 20:45:00.691932: val_loss -0.8388 
2024-12-07 20:45:00.695506: Pseudo dice [np.float32(0.8927), np.float32(0.875)] 
2024-12-07 20:45:00.698537: Epoch time: 6.13 s 
2024-12-07 20:45:00.700571: Yayy! New best EMA pseudo Dice: 0.8640000224113464 
2024-12-07 20:45:01.387854:  
2024-12-07 20:45:01.392917: Epoch 5 
2024-12-07 20:45:01.395451: Current learning rate: 0.00955 
2024-12-07 20:45:07.530156: train_loss -0.9049 
2024-12-07 20:45:07.535223: val_loss -0.8331 
2024-12-07 20:45:07.538774: Pseudo dice [np.float32(0.8903), np.float32(0.8721)] 
2024-12-07 20:45:07.541828: Epoch time: 6.14 s 
2024-12-07 20:45:07.544906: Yayy! New best EMA pseudo Dice: 0.8657000064849854 
2024-12-07 20:45:08.093780:  
2024-12-07 20:45:08.098837: Epoch 6 
2024-12-07 20:45:08.102387: Current learning rate: 0.00946 
2024-12-07 20:45:14.234777: train_loss -0.9128 
2024-12-07 20:45:14.240382: val_loss -0.8345 
2024-12-07 20:45:14.242929: Pseudo dice [np.float32(0.8922), np.float32(0.8731)] 
2024-12-07 20:45:14.245464: Epoch time: 6.14 s 
2024-12-07 20:45:14.247999: Yayy! New best EMA pseudo Dice: 0.8673999905586243 
2024-12-07 20:45:14.801165:  
2024-12-07 20:45:14.806759: Epoch 7 
2024-12-07 20:45:14.809813: Current learning rate: 0.00937 
2024-12-07 20:45:20.944115: train_loss -0.9189 
2024-12-07 20:45:20.950719: val_loss -0.8352 
2024-12-07 20:45:20.953263: Pseudo dice [np.float32(0.8954), np.float32(0.874)] 
2024-12-07 20:45:20.956803: Epoch time: 6.14 s 
2024-12-07 20:45:20.959330: Yayy! New best EMA pseudo Dice: 0.8690999746322632 
2024-12-07 20:45:21.518060:  
2024-12-07 20:45:21.523667: Epoch 8 
2024-12-07 20:45:21.526721: Current learning rate: 0.00928 
2024-12-07 20:45:27.663661: train_loss -0.9259 
2024-12-07 20:45:27.668722: val_loss -0.8364 
2024-12-07 20:45:27.671784: Pseudo dice [np.float32(0.8942), np.float32(0.8772)] 
2024-12-07 20:45:27.674824: Epoch time: 6.15 s 
2024-12-07 20:45:27.678369: Yayy! New best EMA pseudo Dice: 0.8708000183105469 
2024-12-07 20:45:28.246647:  
2024-12-07 20:45:28.252708: Epoch 9 
2024-12-07 20:45:28.255243: Current learning rate: 0.00919 
2024-12-07 20:45:34.372908: train_loss -0.9289 
2024-12-07 20:45:34.380641: val_loss -0.8357 
2024-12-07 20:45:34.383201: Pseudo dice [np.float32(0.8944), np.float32(0.8761)] 
2024-12-07 20:45:34.386769: Epoch time: 6.13 s 
2024-12-07 20:45:34.388803: Yayy! New best EMA pseudo Dice: 0.8722000122070312 
2024-12-07 20:45:34.934518:  
2024-12-07 20:45:34.939573: Epoch 10 
2024-12-07 20:45:34.943123: Current learning rate: 0.0091 
2024-12-07 20:45:41.063765: train_loss -0.9342 
2024-12-07 20:45:41.068827: val_loss -0.8282 
2024-12-07 20:45:41.071361: Pseudo dice [np.float32(0.8914), np.float32(0.8732)] 
2024-12-07 20:45:41.075428: Epoch time: 6.13 s 
2024-12-07 20:45:41.077971: Yayy! New best EMA pseudo Dice: 0.8733000159263611 
2024-12-07 20:45:41.617150:  
2024-12-07 20:45:41.622742: Epoch 11 
2024-12-07 20:45:41.626293: Current learning rate: 0.009 
2024-12-07 20:45:47.737078: train_loss -0.9365 
2024-12-07 20:45:47.744218: val_loss -0.8312 
2024-12-07 20:45:47.748794: Pseudo dice [np.float32(0.8943), np.float32(0.8761)] 
2024-12-07 20:45:47.751333: Epoch time: 6.12 s 
2024-12-07 20:45:47.755385: Yayy! New best EMA pseudo Dice: 0.8744000196456909 
2024-12-07 20:45:48.303303:  
2024-12-07 20:45:48.308888: Epoch 12 
2024-12-07 20:45:48.311425: Current learning rate: 0.00891 
2024-12-07 20:45:54.416329: train_loss -0.939 
2024-12-07 20:45:54.422407: val_loss -0.8241 
2024-12-07 20:45:54.425456: Pseudo dice [np.float32(0.8911), np.float32(0.8707)] 
2024-12-07 20:45:54.429003: Epoch time: 6.11 s 
2024-12-07 20:45:54.431554: Yayy! New best EMA pseudo Dice: 0.8751000165939331 
2024-12-07 20:45:55.125183:  
2024-12-07 20:45:55.130252: Epoch 13 
2024-12-07 20:45:55.132782: Current learning rate: 0.00882 
2024-12-07 20:46:01.237606: train_loss -0.9434 
2024-12-07 20:46:01.242680: val_loss -0.8258 
2024-12-07 20:46:01.246730: Pseudo dice [np.float32(0.8929), np.float32(0.8731)] 
2024-12-07 20:46:01.249792: Epoch time: 6.11 s 
2024-12-07 20:46:01.252857: Yayy! New best EMA pseudo Dice: 0.8758999705314636 
2024-12-07 20:46:01.805827:  
2024-12-07 20:46:01.811393: Epoch 14 
2024-12-07 20:46:01.813948: Current learning rate: 0.00873 
2024-12-07 20:46:07.942516: train_loss -0.9462 
2024-12-07 20:46:07.948631: val_loss -0.8256 
2024-12-07 20:46:07.951195: Pseudo dice [np.float32(0.8905), np.float32(0.8729)] 
2024-12-07 20:46:07.954751: Epoch time: 6.14 s 
2024-12-07 20:46:07.957806: Yayy! New best EMA pseudo Dice: 0.8765000104904175 
2024-12-07 20:46:08.521103:  
2024-12-07 20:46:08.526161: Epoch 15 
2024-12-07 20:46:08.528719: Current learning rate: 0.00864 
2024-12-07 20:46:14.644889: train_loss -0.948 
2024-12-07 20:46:14.650511: val_loss -0.8243 
2024-12-07 20:46:14.653063: Pseudo dice [np.float32(0.8925), np.float32(0.8728)] 
2024-12-07 20:46:14.656630: Epoch time: 6.12 s 
2024-12-07 20:46:14.659683: Yayy! New best EMA pseudo Dice: 0.8770999908447266 
2024-12-07 20:46:15.227592:  
2024-12-07 20:46:15.233196: Epoch 16 
2024-12-07 20:46:15.235727: Current learning rate: 0.00855 
2024-12-07 20:46:21.353114: train_loss -0.9501 
2024-12-07 20:46:21.357711: val_loss -0.8208 
2024-12-07 20:46:21.362275: Pseudo dice [np.float32(0.8902), np.float32(0.8712)] 
2024-12-07 20:46:21.364816: Epoch time: 6.13 s 
2024-12-07 20:46:21.367349: Yayy! New best EMA pseudo Dice: 0.8773999810218811 
2024-12-07 20:46:21.950262:  
2024-12-07 20:46:21.956323: Epoch 17 
2024-12-07 20:46:21.958858: Current learning rate: 0.00846 
2024-12-07 20:46:28.088569: train_loss -0.9517 
2024-12-07 20:46:28.094205: val_loss -0.8255 
2024-12-07 20:46:28.097782: Pseudo dice [np.float32(0.8928), np.float32(0.8751)] 
2024-12-07 20:46:28.100850: Epoch time: 6.14 s 
2024-12-07 20:46:28.103390: Yayy! New best EMA pseudo Dice: 0.8780999779701233 
2024-12-07 20:46:28.677874:  
2024-12-07 20:46:28.682930: Epoch 18 
2024-12-07 20:46:28.685462: Current learning rate: 0.00836 
2024-12-07 20:46:34.810486: train_loss -0.9533 
2024-12-07 20:46:34.815559: val_loss -0.8259 
2024-12-07 20:46:34.819117: Pseudo dice [np.float32(0.8945), np.float32(0.8746)] 
2024-12-07 20:46:34.822169: Epoch time: 6.13 s 
2024-12-07 20:46:34.825726: Yayy! New best EMA pseudo Dice: 0.8787000179290771 
2024-12-07 20:46:35.387426:  
2024-12-07 20:46:35.393524: Epoch 19 
2024-12-07 20:46:35.396065: Current learning rate: 0.00827 
2024-12-07 20:46:41.521161: train_loss -0.9537 
2024-12-07 20:46:41.527241: val_loss -0.8282 
2024-12-07 20:46:41.530298: Pseudo dice [np.float32(0.8959), np.float32(0.8767)] 
2024-12-07 20:46:41.533365: Epoch time: 6.13 s 
2024-12-07 20:46:41.535928: Yayy! New best EMA pseudo Dice: 0.8794999718666077 
2024-12-07 20:46:42.099755:  
2024-12-07 20:46:42.104825: Epoch 20 
2024-12-07 20:46:42.107365: Current learning rate: 0.00818 
2024-12-07 20:46:48.223905: train_loss -0.9551 
2024-12-07 20:46:48.231065: val_loss -0.8142 
2024-12-07 20:46:48.235626: Pseudo dice [np.float32(0.8893), np.float32(0.8692)] 
2024-12-07 20:46:48.238158: Epoch time: 6.12 s 
2024-12-07 20:46:48.912068:  
2024-12-07 20:46:48.917143: Epoch 21 
2024-12-07 20:46:48.919678: Current learning rate: 0.00809 
2024-12-07 20:46:55.040545: train_loss -0.957 
2024-12-07 20:46:55.046155: val_loss -0.8205 
2024-12-07 20:46:55.048689: Pseudo dice [np.float32(0.8917), np.float32(0.8724)] 
2024-12-07 20:46:55.052761: Epoch time: 6.13 s 
2024-12-07 20:46:55.055822: Yayy! New best EMA pseudo Dice: 0.8797000050544739 
2024-12-07 20:46:55.597669:  
2024-12-07 20:46:55.603746: Epoch 22 
2024-12-07 20:46:55.607311: Current learning rate: 0.008 
2024-12-07 20:47:01.728229: train_loss -0.9591 
2024-12-07 20:47:01.733820: val_loss -0.8166 
2024-12-07 20:47:01.736912: Pseudo dice [np.float32(0.8894), np.float32(0.8708)] 
2024-12-07 20:47:01.740460: Epoch time: 6.13 s 
2024-12-07 20:47:01.742992: Yayy! New best EMA pseudo Dice: 0.879800021648407 
2024-12-07 20:47:02.286879:  
2024-12-07 20:47:02.291942: Epoch 23 
2024-12-07 20:47:02.294992: Current learning rate: 0.0079 
2024-12-07 20:47:08.440595: train_loss -0.96 
2024-12-07 20:47:08.445205: val_loss -0.8125 
2024-12-07 20:47:08.449246: Pseudo dice [np.float32(0.8881), np.float32(0.8696)] 
2024-12-07 20:47:08.452322: Epoch time: 6.15 s 
2024-12-07 20:47:08.956465:  
2024-12-07 20:47:08.962041: Epoch 24 
2024-12-07 20:47:08.965094: Current learning rate: 0.00781 
2024-12-07 20:47:15.084716: train_loss -0.961 
2024-12-07 20:47:15.089795: val_loss -0.8183 
2024-12-07 20:47:15.092853: Pseudo dice [np.float32(0.8914), np.float32(0.8738)] 
2024-12-07 20:47:15.096937: Epoch time: 6.13 s 
2024-12-07 20:47:15.099467: Yayy! New best EMA pseudo Dice: 0.8799999952316284 
2024-12-07 20:47:15.649424:  
2024-12-07 20:47:15.655000: Epoch 25 
2024-12-07 20:47:15.660093: Current learning rate: 0.00772 
2024-12-07 20:47:21.788955: train_loss -0.9612 
2024-12-07 20:47:21.794050: val_loss -0.8138 
2024-12-07 20:47:21.797599: Pseudo dice [np.float32(0.8892), np.float32(0.871)] 
2024-12-07 20:47:21.800663: Epoch time: 6.14 s 
2024-12-07 20:47:21.803204: Yayy! New best EMA pseudo Dice: 0.8799999952316284 
2024-12-07 20:47:22.345492:  
2024-12-07 20:47:22.352078: Epoch 26 
2024-12-07 20:47:22.356669: Current learning rate: 0.00763 
2024-12-07 20:47:28.485273: train_loss -0.9628 
2024-12-07 20:47:28.491352: val_loss -0.8136 
2024-12-07 20:47:28.494915: Pseudo dice [np.float32(0.89), np.float32(0.8714)] 
2024-12-07 20:47:28.497452: Epoch time: 6.14 s 
2024-12-07 20:47:28.499981: Yayy! New best EMA pseudo Dice: 0.8801000118255615 
2024-12-07 20:47:29.046184:  
2024-12-07 20:47:29.051777: Epoch 27 
2024-12-07 20:47:29.054319: Current learning rate: 0.00753 
2024-12-07 20:47:35.174697: train_loss -0.9635 
2024-12-07 20:47:35.180297: val_loss -0.8179 
2024-12-07 20:47:35.183374: Pseudo dice [np.float32(0.8912), np.float32(0.8736)] 
2024-12-07 20:47:35.185911: Epoch time: 6.13 s 
2024-12-07 20:47:35.189958: Yayy! New best EMA pseudo Dice: 0.880299985408783 
2024-12-07 20:47:35.879371:  
2024-12-07 20:47:35.884970: Epoch 28 
2024-12-07 20:47:35.887501: Current learning rate: 0.00744 
2024-12-07 20:47:42.006538: train_loss -0.9659 
2024-12-07 20:47:42.012142: val_loss -0.8114 
2024-12-07 20:47:42.016193: Pseudo dice [np.float32(0.8889), np.float32(0.8709)] 
2024-12-07 20:47:42.019264: Epoch time: 6.13 s 
2024-12-07 20:47:42.531633:  
2024-12-07 20:47:42.537200: Epoch 29 
2024-12-07 20:47:42.540252: Current learning rate: 0.00735 
2024-12-07 20:47:48.659807: train_loss -0.9653 
2024-12-07 20:47:48.665926: val_loss -0.8214 
2024-12-07 20:47:48.671019: Pseudo dice [np.float32(0.8946), np.float32(0.8762)] 
2024-12-07 20:47:48.674576: Epoch time: 6.13 s 
2024-12-07 20:47:48.677114: Yayy! New best EMA pseudo Dice: 0.8808000087738037 
2024-12-07 20:47:49.229267:  
2024-12-07 20:47:49.234331: Epoch 30 
2024-12-07 20:47:49.236857: Current learning rate: 0.00725 
2024-12-07 20:47:55.352381: train_loss -0.9663 
2024-12-07 20:47:55.357463: val_loss -0.8172 
2024-12-07 20:47:55.361015: Pseudo dice [np.float32(0.8926), np.float32(0.8734)] 
2024-12-07 20:47:55.364558: Epoch time: 6.12 s 
2024-12-07 20:47:55.367607: Yayy! New best EMA pseudo Dice: 0.8809999823570251 
2024-12-07 20:47:55.920642:  
2024-12-07 20:47:55.925705: Epoch 31 
2024-12-07 20:47:55.928243: Current learning rate: 0.00716 
2024-12-07 20:48:02.062672: train_loss -0.9664 
2024-12-07 20:48:02.068300: val_loss -0.809 
2024-12-07 20:48:02.071879: Pseudo dice [np.float32(0.8892), np.float32(0.8687)] 
2024-12-07 20:48:02.073908: Epoch time: 6.14 s 
2024-12-07 20:48:02.603060:  
2024-12-07 20:48:02.609165: Epoch 32 
2024-12-07 20:48:02.612745: Current learning rate: 0.00707 
2024-12-07 20:48:08.742720: train_loss -0.9675 
2024-12-07 20:48:08.747815: val_loss -0.8181 
2024-12-07 20:48:08.751868: Pseudo dice [np.float32(0.8934), np.float32(0.8745)] 
2024-12-07 20:48:08.754951: Epoch time: 6.14 s 
2024-12-07 20:48:08.757494: Yayy! New best EMA pseudo Dice: 0.8810999989509583 
2024-12-07 20:48:09.315820:  
2024-12-07 20:48:09.320890: Epoch 33 
2024-12-07 20:48:09.324444: Current learning rate: 0.00697 
2024-12-07 20:48:15.446835: train_loss -0.9685 
2024-12-07 20:48:15.451920: val_loss -0.8155 
2024-12-07 20:48:15.456463: Pseudo dice [np.float32(0.8912), np.float32(0.8733)] 
2024-12-07 20:48:15.459530: Epoch time: 6.13 s 
2024-12-07 20:48:15.462064: Yayy! New best EMA pseudo Dice: 0.8812000155448914 
2024-12-07 20:48:16.020285:  
2024-12-07 20:48:16.026360: Epoch 34 
2024-12-07 20:48:16.028893: Current learning rate: 0.00688 
2024-12-07 20:48:22.152993: train_loss -0.9693 
2024-12-07 20:48:22.158130: val_loss -0.8127 
2024-12-07 20:48:22.161695: Pseudo dice [np.float32(0.8891), np.float32(0.8723)] 
2024-12-07 20:48:22.164751: Epoch time: 6.13 s 
2024-12-07 20:48:22.695935:  
2024-12-07 20:48:22.702528: Epoch 35 
2024-12-07 20:48:22.706122: Current learning rate: 0.00679 
2024-12-07 20:48:28.825471: train_loss -0.9695 
2024-12-07 20:48:28.831595: val_loss -0.8135 
2024-12-07 20:48:28.834642: Pseudo dice [np.float32(0.8914), np.float32(0.8729)] 
2024-12-07 20:48:28.838194: Epoch time: 6.13 s 
2024-12-07 20:48:28.840732: Yayy! New best EMA pseudo Dice: 0.8812999725341797 
2024-12-07 20:48:29.545175:  
2024-12-07 20:48:29.550760: Epoch 36 
2024-12-07 20:48:29.553309: Current learning rate: 0.00669 
2024-12-07 20:48:35.671747: train_loss -0.9709 
2024-12-07 20:48:35.677329: val_loss -0.8151 
2024-12-07 20:48:35.681420: Pseudo dice [np.float32(0.8927), np.float32(0.8747)] 
2024-12-07 20:48:35.684024: Epoch time: 6.13 s 
2024-12-07 20:48:35.687571: Yayy! New best EMA pseudo Dice: 0.8815000057220459 
2024-12-07 20:48:36.251820:  
2024-12-07 20:48:36.256895: Epoch 37 
2024-12-07 20:48:36.260461: Current learning rate: 0.0066 
2024-12-07 20:48:42.382724: train_loss -0.9708 
2024-12-07 20:48:42.387859: val_loss -0.8096 
2024-12-07 20:48:42.391422: Pseudo dice [np.float32(0.8899), np.float32(0.8714)] 
2024-12-07 20:48:42.394491: Epoch time: 6.13 s 
2024-12-07 20:48:42.931083:  
2024-12-07 20:48:42.936171: Epoch 38 
2024-12-07 20:48:42.938697: Current learning rate: 0.0065 
2024-12-07 20:48:49.071683: train_loss -0.9709 
2024-12-07 20:48:49.079308: val_loss -0.8108 
2024-12-07 20:48:49.083878: Pseudo dice [np.float32(0.8894), np.float32(0.8716)] 
2024-12-07 20:48:49.086930: Epoch time: 6.14 s 
2024-12-07 20:48:49.614785:  
2024-12-07 20:48:49.619846: Epoch 39 
2024-12-07 20:48:49.623413: Current learning rate: 0.00641 
2024-12-07 20:48:55.781286: train_loss -0.9721 
2024-12-07 20:48:55.786374: val_loss -0.8125 
2024-12-07 20:48:55.789922: Pseudo dice [np.float32(0.8919), np.float32(0.8737)] 
2024-12-07 20:48:55.792986: Epoch time: 6.17 s 
2024-12-07 20:48:56.329850:  
2024-12-07 20:48:56.336462: Epoch 40 
2024-12-07 20:48:56.339507: Current learning rate: 0.00631 
2024-12-07 20:49:02.459828: train_loss -0.973 
2024-12-07 20:49:02.465953: val_loss -0.8098 
2024-12-07 20:49:02.468488: Pseudo dice [np.float32(0.8908), np.float32(0.8722)] 
2024-12-07 20:49:02.473063: Epoch time: 6.13 s 
2024-12-07 20:49:03.006552:  
2024-12-07 20:49:03.012142: Epoch 41 
2024-12-07 20:49:03.015198: Current learning rate: 0.00622 
2024-12-07 20:49:09.148912: train_loss -0.973 
2024-12-07 20:49:09.153974: val_loss -0.8074 
2024-12-07 20:49:09.157559: Pseudo dice [np.float32(0.8897), np.float32(0.8705)] 
2024-12-07 20:49:09.160110: Epoch time: 6.14 s 
2024-12-07 20:49:09.667361:  
2024-12-07 20:49:09.672473: Epoch 42 
2024-12-07 20:49:09.675021: Current learning rate: 0.00612 
2024-12-07 20:49:15.795733: train_loss -0.9728 
2024-12-07 20:49:15.801317: val_loss -0.8055 
2024-12-07 20:49:15.804911: Pseudo dice [np.float32(0.8899), np.float32(0.8697)] 
2024-12-07 20:49:15.807457: Epoch time: 6.13 s 
2024-12-07 20:49:16.325325:  
2024-12-07 20:49:16.330904: Epoch 43 
2024-12-07 20:49:16.333447: Current learning rate: 0.00603 
2024-12-07 20:49:22.448704: train_loss -0.9739 
2024-12-07 20:49:22.454283: val_loss -0.8096 
2024-12-07 20:49:22.456848: Pseudo dice [np.float32(0.8923), np.float32(0.8712)] 
2024-12-07 20:49:22.460416: Epoch time: 6.13 s 
2024-12-07 20:49:23.106087:  
2024-12-07 20:49:23.113178: Epoch 44 
2024-12-07 20:49:23.116760: Current learning rate: 0.00593 
2024-12-07 20:49:29.234025: train_loss -0.9745 
2024-12-07 20:49:29.239646: val_loss -0.8105 
2024-12-07 20:49:29.242735: Pseudo dice [np.float32(0.8922), np.float32(0.8737)] 
2024-12-07 20:49:29.245791: Epoch time: 6.13 s 
2024-12-07 20:49:29.764742:  
2024-12-07 20:49:29.769837: Epoch 45 
2024-12-07 20:49:29.772915: Current learning rate: 0.00584 
2024-12-07 20:49:35.889772: train_loss -0.9743 
2024-12-07 20:49:35.895856: val_loss -0.8177 
2024-12-07 20:49:35.898906: Pseudo dice [np.float32(0.8946), np.float32(0.8762)] 
2024-12-07 20:49:35.902473: Epoch time: 6.13 s 
2024-12-07 20:49:35.905515: Yayy! New best EMA pseudo Dice: 0.8817999958992004 
2024-12-07 20:49:36.443450:  
2024-12-07 20:49:36.448538: Epoch 46 
2024-12-07 20:49:36.452597: Current learning rate: 0.00574 
2024-12-07 20:49:42.572009: train_loss -0.9749 
2024-12-07 20:49:42.578122: val_loss -0.8123 
2024-12-07 20:49:42.580662: Pseudo dice [np.float32(0.8924), np.float32(0.8737)] 
2024-12-07 20:49:42.583208: Epoch time: 6.13 s 
2024-12-07 20:49:42.587261: Yayy! New best EMA pseudo Dice: 0.8819000124931335 
2024-12-07 20:49:43.129249:  
2024-12-07 20:49:43.134345: Epoch 47 
2024-12-07 20:49:43.137422: Current learning rate: 0.00565 
2024-12-07 20:49:49.258969: train_loss -0.9758 
2024-12-07 20:49:49.266592: val_loss -0.8099 
2024-12-07 20:49:49.271718: Pseudo dice [np.float32(0.8916), np.float32(0.8726)] 
2024-12-07 20:49:49.274804: Epoch time: 6.13 s 
2024-12-07 20:49:49.277850: Yayy! New best EMA pseudo Dice: 0.8820000290870667 
2024-12-07 20:49:49.818579:  
2024-12-07 20:49:49.823649: Epoch 48 
2024-12-07 20:49:49.826188: Current learning rate: 0.00555 
2024-12-07 20:49:55.952710: train_loss -0.9759 
2024-12-07 20:49:55.958349: val_loss -0.8121 
2024-12-07 20:49:55.960915: Pseudo dice [np.float32(0.8918), np.float32(0.8753)] 
2024-12-07 20:49:55.963455: Epoch time: 6.14 s 
2024-12-07 20:49:55.965995: Yayy! New best EMA pseudo Dice: 0.882099986076355 
2024-12-07 20:49:56.516779:  
2024-12-07 20:49:56.521856: Epoch 49 
2024-12-07 20:49:56.524415: Current learning rate: 0.00546 
2024-12-07 20:50:02.640601: train_loss -0.9758 
2024-12-07 20:50:02.645671: val_loss -0.8146 
2024-12-07 20:50:02.649218: Pseudo dice [np.float32(0.8932), np.float32(0.8757)] 
2024-12-07 20:50:02.651752: Epoch time: 6.12 s 
2024-12-07 20:50:02.686709: Yayy! New best EMA pseudo Dice: 0.8823000192642212 
2024-12-07 20:50:03.233914:  
2024-12-07 20:50:03.238986: Epoch 50 
2024-12-07 20:50:03.242043: Current learning rate: 0.00536 
2024-12-07 20:50:09.375281: train_loss -0.9767 
2024-12-07 20:50:09.380420: val_loss -0.8085 
2024-12-07 20:50:09.383997: Pseudo dice [np.float32(0.8925), np.float32(0.8728)] 
2024-12-07 20:50:09.387062: Epoch time: 6.14 s 
2024-12-07 20:50:09.389616: Yayy! New best EMA pseudo Dice: 0.8823999762535095 
2024-12-07 20:50:09.939808:  
2024-12-07 20:50:09.945927: Epoch 51 
2024-12-07 20:50:09.949021: Current learning rate: 0.00526 
2024-12-07 20:50:16.074003: train_loss -0.9772 
2024-12-07 20:50:16.078611: val_loss -0.8076 
2024-12-07 20:50:16.082686: Pseudo dice [np.float32(0.8901), np.float32(0.872)] 
2024-12-07 20:50:16.085755: Epoch time: 6.13 s 
2024-12-07 20:50:16.742012:  
2024-12-07 20:50:16.747089: Epoch 52 
2024-12-07 20:50:16.749630: Current learning rate: 0.00517 
2024-12-07 20:50:22.860863: train_loss -0.9768 
2024-12-07 20:50:22.865930: val_loss -0.8088 
2024-12-07 20:50:22.868999: Pseudo dice [np.float32(0.8921), np.float32(0.8724)] 
2024-12-07 20:50:22.872571: Epoch time: 6.12 s 
2024-12-07 20:50:23.394119:  
2024-12-07 20:50:23.399721: Epoch 53 
2024-12-07 20:50:23.402786: Current learning rate: 0.00507 
2024-12-07 20:50:29.529824: train_loss -0.977 
2024-12-07 20:50:29.534396: val_loss -0.8104 
2024-12-07 20:50:29.538452: Pseudo dice [np.float32(0.8911), np.float32(0.8745)] 
2024-12-07 20:50:29.541521: Epoch time: 6.14 s 
2024-12-07 20:50:30.056664:  
2024-12-07 20:50:30.061729: Epoch 54 
2024-12-07 20:50:30.064262: Current learning rate: 0.00497 
2024-12-07 20:50:36.194043: train_loss -0.9777 
2024-12-07 20:50:36.200660: val_loss -0.8107 
2024-12-07 20:50:36.204244: Pseudo dice [np.float32(0.8918), np.float32(0.8745)] 
2024-12-07 20:50:36.206789: Epoch time: 6.14 s 
2024-12-07 20:50:36.209341: Yayy! New best EMA pseudo Dice: 0.8823999762535095 
2024-12-07 20:50:36.769061:  
2024-12-07 20:50:36.774644: Epoch 55 
2024-12-07 20:50:36.777193: Current learning rate: 0.00487 
2024-12-07 20:50:42.895990: train_loss -0.9784 
2024-12-07 20:50:42.901116: val_loss -0.8047 
2024-12-07 20:50:42.905183: Pseudo dice [np.float32(0.8899), np.float32(0.8704)] 
2024-12-07 20:50:42.908717: Epoch time: 6.13 s 
2024-12-07 20:50:43.423551:  
2024-12-07 20:50:43.430117: Epoch 56 
2024-12-07 20:50:43.433736: Current learning rate: 0.00478 
2024-12-07 20:50:49.561619: train_loss -0.9789 
2024-12-07 20:50:49.569240: val_loss -0.8076 
2024-12-07 20:50:49.573829: Pseudo dice [np.float32(0.8918), np.float32(0.8735)] 
2024-12-07 20:50:49.576906: Epoch time: 6.14 s 
2024-12-07 20:50:50.090805:  
2024-12-07 20:50:50.095894: Epoch 57 
2024-12-07 20:50:50.098440: Current learning rate: 0.00468 
2024-12-07 20:50:56.214298: train_loss -0.9786 
2024-12-07 20:50:56.220417: val_loss -0.8032 
2024-12-07 20:50:56.224001: Pseudo dice [np.float32(0.8898), np.float32(0.8708)] 
2024-12-07 20:50:56.226549: Epoch time: 6.12 s 
2024-12-07 20:50:56.743680:  
2024-12-07 20:50:56.748762: Epoch 58 
2024-12-07 20:50:56.751304: Current learning rate: 0.00458 
2024-12-07 20:51:02.878603: train_loss -0.9795 
2024-12-07 20:51:02.884765: val_loss -0.8009 
2024-12-07 20:51:02.888840: Pseudo dice [np.float32(0.8897), np.float32(0.8694)] 
2024-12-07 20:51:02.892384: Epoch time: 6.14 s 
2024-12-07 20:51:03.420604:  
2024-12-07 20:51:03.425721: Epoch 59 
2024-12-07 20:51:03.428269: Current learning rate: 0.00448 
2024-12-07 20:51:09.570886: train_loss -0.9796 
2024-12-07 20:51:09.576498: val_loss -0.8075 
2024-12-07 20:51:09.579594: Pseudo dice [np.float32(0.8918), np.float32(0.8734)] 
2024-12-07 20:51:09.582657: Epoch time: 6.15 s 
2024-12-07 20:51:10.248585:  
2024-12-07 20:51:10.253664: Epoch 60 
2024-12-07 20:51:10.256203: Current learning rate: 0.00438 
2024-12-07 20:51:16.377038: train_loss -0.9804 
2024-12-07 20:51:16.382096: val_loss -0.8092 
2024-12-07 20:51:16.385651: Pseudo dice [np.float32(0.8927), np.float32(0.8741)] 
2024-12-07 20:51:16.389221: Epoch time: 6.13 s 
2024-12-07 20:51:16.911622:  
2024-12-07 20:51:16.917210: Epoch 61 
2024-12-07 20:51:16.919734: Current learning rate: 0.00429 
2024-12-07 20:51:23.037338: train_loss -0.9807 
2024-12-07 20:51:23.042411: val_loss -0.8022 
2024-12-07 20:51:23.046010: Pseudo dice [np.float32(0.8887), np.float32(0.8701)] 
2024-12-07 20:51:23.049078: Epoch time: 6.13 s 
2024-12-07 20:51:23.574056:  
2024-12-07 20:51:23.579657: Epoch 62 
2024-12-07 20:51:23.582699: Current learning rate: 0.00419 
2024-12-07 20:51:29.704298: train_loss -0.9802 
2024-12-07 20:51:29.709393: val_loss -0.8031 
2024-12-07 20:51:29.712976: Pseudo dice [np.float32(0.8913), np.float32(0.8716)] 
2024-12-07 20:51:29.716026: Epoch time: 6.13 s 
2024-12-07 20:51:30.243334:  
2024-12-07 20:51:30.249415: Epoch 63 
2024-12-07 20:51:30.251946: Current learning rate: 0.00409 
2024-12-07 20:51:36.369289: train_loss -0.9806 
2024-12-07 20:51:36.374911: val_loss -0.8111 
2024-12-07 20:51:36.377961: Pseudo dice [np.float32(0.8943), np.float32(0.8748)] 
2024-12-07 20:51:36.381509: Epoch time: 6.13 s 
2024-12-07 20:51:36.911263:  
2024-12-07 20:51:36.916831: Epoch 64 
2024-12-07 20:51:36.919372: Current learning rate: 0.00399 
2024-12-07 20:51:43.040464: train_loss -0.9811 
2024-12-07 20:51:43.045536: val_loss -0.8038 
2024-12-07 20:51:43.049082: Pseudo dice [np.float32(0.8906), np.float32(0.8721)] 
2024-12-07 20:51:43.052167: Epoch time: 6.13 s 
2024-12-07 20:51:43.575040:  
2024-12-07 20:51:43.580610: Epoch 65 
2024-12-07 20:51:43.583157: Current learning rate: 0.00389 
2024-12-07 20:51:49.704330: train_loss -0.9808 
2024-12-07 20:51:49.711432: val_loss -0.7979 
2024-12-07 20:51:49.716529: Pseudo dice [np.float32(0.8875), np.float32(0.8691)] 
2024-12-07 20:51:49.719588: Epoch time: 6.13 s 
2024-12-07 20:51:50.246131:  
2024-12-07 20:51:50.251190: Epoch 66 
2024-12-07 20:51:50.253743: Current learning rate: 0.00379 
2024-12-07 20:51:56.372456: train_loss -0.9817 
2024-12-07 20:51:56.379051: val_loss -0.7969 
2024-12-07 20:51:56.382120: Pseudo dice [np.float32(0.8862), np.float32(0.8694)] 
2024-12-07 20:51:56.385183: Epoch time: 6.13 s 
2024-12-07 20:51:56.916778:  
2024-12-07 20:51:56.921836: Epoch 67 
2024-12-07 20:51:56.924900: Current learning rate: 0.00369 
2024-12-07 20:52:03.056851: train_loss -0.9821 
2024-12-07 20:52:03.062457: val_loss -0.8066 
2024-12-07 20:52:03.065502: Pseudo dice [np.float32(0.8923), np.float32(0.8734)] 
2024-12-07 20:52:03.067532: Epoch time: 6.14 s 
2024-12-07 20:52:03.742246:  
2024-12-07 20:52:03.747292: Epoch 68 
2024-12-07 20:52:03.749847: Current learning rate: 0.00359 
2024-12-07 20:52:09.884466: train_loss -0.9825 
2024-12-07 20:52:09.890039: val_loss -0.8053 
2024-12-07 20:52:09.893095: Pseudo dice [np.float32(0.8911), np.float32(0.8727)] 
2024-12-07 20:52:09.895637: Epoch time: 6.14 s 
2024-12-07 20:52:10.435298:  
2024-12-07 20:52:10.440351: Epoch 69 
2024-12-07 20:52:10.442897: Current learning rate: 0.00349 
2024-12-07 20:52:16.566967: train_loss -0.982 
2024-12-07 20:52:16.572552: val_loss -0.7994 
2024-12-07 20:52:16.576137: Pseudo dice [np.float32(0.8881), np.float32(0.8696)] 
2024-12-07 20:52:16.578676: Epoch time: 6.13 s 
2024-12-07 20:52:17.117890:  
2024-12-07 20:52:17.122973: Epoch 70 
2024-12-07 20:52:17.126017: Current learning rate: 0.00338 
2024-12-07 20:52:23.245591: train_loss -0.9824 
2024-12-07 20:52:23.251253: val_loss -0.7965 
2024-12-07 20:52:23.254320: Pseudo dice [np.float32(0.8872), np.float32(0.8682)] 
2024-12-07 20:52:23.257884: Epoch time: 6.13 s 
2024-12-07 20:52:23.792072:  
2024-12-07 20:52:23.798678: Epoch 71 
2024-12-07 20:52:23.802240: Current learning rate: 0.00328 
2024-12-07 20:52:29.926714: train_loss -0.9828 
2024-12-07 20:52:29.932344: val_loss -0.8086 
2024-12-07 20:52:29.935429: Pseudo dice [np.float32(0.8928), np.float32(0.8735)] 
2024-12-07 20:52:29.938504: Epoch time: 6.13 s 
2024-12-07 20:52:30.473928:  
2024-12-07 20:52:30.480021: Epoch 72 
2024-12-07 20:52:30.483619: Current learning rate: 0.00318 
2024-12-07 20:52:36.609122: train_loss -0.9833 
2024-12-07 20:52:36.615213: val_loss -0.8006 
2024-12-07 20:52:36.618257: Pseudo dice [np.float32(0.889), np.float32(0.8702)] 
2024-12-07 20:52:36.621816: Epoch time: 6.14 s 
2024-12-07 20:52:37.155984:  
2024-12-07 20:52:37.162074: Epoch 73 
2024-12-07 20:52:37.165130: Current learning rate: 0.00308 
2024-12-07 20:52:43.287356: train_loss -0.983 
2024-12-07 20:52:43.293453: val_loss -0.8013 
2024-12-07 20:52:43.295511: Pseudo dice [np.float32(0.8905), np.float32(0.8718)] 
2024-12-07 20:52:43.299543: Epoch time: 6.13 s 
2024-12-07 20:52:43.837641:  
2024-12-07 20:52:43.842724: Epoch 74 
2024-12-07 20:52:43.845263: Current learning rate: 0.00297 
2024-12-07 20:52:49.967600: train_loss -0.9831 
2024-12-07 20:52:49.974719: val_loss -0.8032 
2024-12-07 20:52:49.979336: Pseudo dice [np.float32(0.8915), np.float32(0.8725)] 
2024-12-07 20:52:49.982953: Epoch time: 6.13 s 
2024-12-07 20:52:50.654989:  
2024-12-07 20:52:50.660578: Epoch 75 
2024-12-07 20:52:50.663626: Current learning rate: 0.00287 
2024-12-07 20:52:56.786420: train_loss -0.9837 
2024-12-07 20:52:56.792034: val_loss -0.7987 
2024-12-07 20:52:56.794573: Pseudo dice [np.float32(0.8891), np.float32(0.8703)] 
2024-12-07 20:52:56.798654: Epoch time: 6.13 s 
2024-12-07 20:52:57.334661:  
2024-12-07 20:52:57.340238: Epoch 76 
2024-12-07 20:52:57.342783: Current learning rate: 0.00277 
2024-12-07 20:53:03.461259: train_loss -0.9834 
2024-12-07 20:53:03.467876: val_loss -0.7986 
2024-12-07 20:53:03.471941: Pseudo dice [np.float32(0.8891), np.float32(0.8717)] 
2024-12-07 20:53:03.475510: Epoch time: 6.13 s 
2024-12-07 20:53:04.012508:  
2024-12-07 20:53:04.018095: Epoch 77 
2024-12-07 20:53:04.021136: Current learning rate: 0.00266 
2024-12-07 20:53:10.154887: train_loss -0.9838 
2024-12-07 20:53:10.160504: val_loss -0.8037 
2024-12-07 20:53:10.175787: Pseudo dice [np.float32(0.8921), np.float32(0.8737)] 
2024-12-07 20:53:10.179332: Epoch time: 6.14 s 
2024-12-07 20:53:10.719059:  
2024-12-07 20:53:10.725126: Epoch 78 
2024-12-07 20:53:10.728174: Current learning rate: 0.00256 
2024-12-07 20:53:16.853674: train_loss -0.9844 
2024-12-07 20:53:16.858294: val_loss -0.7971 
2024-12-07 20:53:16.861834: Pseudo dice [np.float32(0.8888), np.float32(0.8691)] 
2024-12-07 20:53:16.865408: Epoch time: 6.13 s 
2024-12-07 20:53:17.405895:  
2024-12-07 20:53:17.411508: Epoch 79 
2024-12-07 20:53:17.414581: Current learning rate: 0.00245 
2024-12-07 20:53:23.527292: train_loss -0.9844 
2024-12-07 20:53:23.532366: val_loss -0.8016 
2024-12-07 20:53:23.534900: Pseudo dice [np.float32(0.8902), np.float32(0.8716)] 
2024-12-07 20:53:23.539459: Epoch time: 6.12 s 
2024-12-07 20:53:24.081379:  
2024-12-07 20:53:24.087473: Epoch 80 
2024-12-07 20:53:24.090532: Current learning rate: 0.00235 
2024-12-07 20:53:30.216661: train_loss -0.9843 
2024-12-07 20:53:30.222747: val_loss -0.805 
2024-12-07 20:53:30.226298: Pseudo dice [np.float32(0.8928), np.float32(0.8747)] 
2024-12-07 20:53:30.228824: Epoch time: 6.14 s 
2024-12-07 20:53:30.772344:  
2024-12-07 20:53:30.778898: Epoch 81 
2024-12-07 20:53:30.782466: Current learning rate: 0.00224 
2024-12-07 20:53:36.908013: train_loss -0.9848 
2024-12-07 20:53:36.913162: val_loss -0.8 
2024-12-07 20:53:36.916725: Pseudo dice [np.float32(0.8899), np.float32(0.8713)] 
2024-12-07 20:53:36.919263: Epoch time: 6.14 s 
2024-12-07 20:53:37.463028:  
2024-12-07 20:53:37.468631: Epoch 82 
2024-12-07 20:53:37.471175: Current learning rate: 0.00214 
2024-12-07 20:53:43.588433: train_loss -0.985 
2024-12-07 20:53:43.593499: val_loss -0.8029 
2024-12-07 20:53:43.598578: Pseudo dice [np.float32(0.8921), np.float32(0.8728)] 
2024-12-07 20:53:43.601129: Epoch time: 6.13 s 
2024-12-07 20:53:44.257489:  
2024-12-07 20:53:44.265081: Epoch 83 
2024-12-07 20:53:44.267618: Current learning rate: 0.00203 
2024-12-07 20:53:50.390381: train_loss -0.9849 
2024-12-07 20:53:50.397022: val_loss -0.8056 
2024-12-07 20:53:50.401119: Pseudo dice [np.float32(0.8929), np.float32(0.8746)] 
2024-12-07 20:53:50.405161: Epoch time: 6.13 s 
2024-12-07 20:53:50.916776:  
2024-12-07 20:53:50.923356: Epoch 84 
2024-12-07 20:53:50.925896: Current learning rate: 0.00192 
2024-12-07 20:53:57.034428: train_loss -0.9848 
2024-12-07 20:53:57.039510: val_loss -0.8009 
2024-12-07 20:53:57.045130: Pseudo dice [np.float32(0.8897), np.float32(0.8718)] 
2024-12-07 20:53:57.048196: Epoch time: 6.12 s 
2024-12-07 20:53:57.561996:  
2024-12-07 20:53:57.568095: Epoch 85 
2024-12-07 20:53:57.570637: Current learning rate: 0.00181 
2024-12-07 20:54:03.685651: train_loss -0.9849 
2024-12-07 20:54:03.691274: val_loss -0.808 
2024-12-07 20:54:03.694874: Pseudo dice [np.float32(0.8937), np.float32(0.8759)] 
2024-12-07 20:54:03.697949: Epoch time: 6.12 s 
2024-12-07 20:54:04.204759:  
2024-12-07 20:54:04.210831: Epoch 86 
2024-12-07 20:54:04.213908: Current learning rate: 0.0017 
2024-12-07 20:54:10.349047: train_loss -0.9849 
2024-12-07 20:54:10.356186: val_loss -0.7976 
2024-12-07 20:54:10.359236: Pseudo dice [np.float32(0.8901), np.float32(0.8703)] 
2024-12-07 20:54:10.362333: Epoch time: 6.14 s 
2024-12-07 20:54:10.869907:  
2024-12-07 20:54:10.874956: Epoch 87 
2024-12-07 20:54:10.877487: Current learning rate: 0.00159 
2024-12-07 20:54:17.006677: train_loss -0.9855 
2024-12-07 20:54:17.013305: val_loss -0.8 
2024-12-07 20:54:17.017385: Pseudo dice [np.float32(0.8911), np.float32(0.8731)] 
2024-12-07 20:54:17.020448: Epoch time: 6.14 s 
2024-12-07 20:54:17.526149:  
2024-12-07 20:54:17.531209: Epoch 88 
2024-12-07 20:54:17.533741: Current learning rate: 0.00148 
2024-12-07 20:54:23.660071: train_loss -0.9855 
2024-12-07 20:54:23.666709: val_loss -0.7994 
2024-12-07 20:54:23.670255: Pseudo dice [np.float32(0.8896), np.float32(0.8719)] 
2024-12-07 20:54:23.672803: Epoch time: 6.13 s 
2024-12-07 20:54:24.179161:  
2024-12-07 20:54:24.185726: Epoch 89 
2024-12-07 20:54:24.189288: Current learning rate: 0.00137 
2024-12-07 20:54:30.305377: train_loss -0.9854 
2024-12-07 20:54:30.311043: val_loss -0.7978 
2024-12-07 20:54:30.314103: Pseudo dice [np.float32(0.8881), np.float32(0.8699)] 
2024-12-07 20:54:30.316133: Epoch time: 6.13 s 
2024-12-07 20:54:30.827793:  
2024-12-07 20:54:30.832862: Epoch 90 
2024-12-07 20:54:30.835403: Current learning rate: 0.00126 
2024-12-07 20:54:36.951980: train_loss -0.9851 
2024-12-07 20:54:36.959094: val_loss -0.8006 
2024-12-07 20:54:36.962136: Pseudo dice [np.float32(0.8903), np.float32(0.8718)] 
2024-12-07 20:54:36.965217: Epoch time: 6.12 s 
2024-12-07 20:54:37.611727:  
2024-12-07 20:54:37.616793: Epoch 91 
2024-12-07 20:54:37.619838: Current learning rate: 0.00115 
2024-12-07 20:54:43.739627: train_loss -0.9855 
2024-12-07 20:54:43.744702: val_loss -0.8038 
2024-12-07 20:54:43.747240: Pseudo dice [np.float32(0.8936), np.float32(0.8745)] 
2024-12-07 20:54:43.751293: Epoch time: 6.13 s 
2024-12-07 20:54:44.257052:  
2024-12-07 20:54:44.264157: Epoch 92 
2024-12-07 20:54:44.267216: Current learning rate: 0.00103 
2024-12-07 20:54:50.384249: train_loss -0.9851 
2024-12-07 20:54:50.389324: val_loss -0.8058 
2024-12-07 20:54:50.392877: Pseudo dice [np.float32(0.892), np.float32(0.8748)] 
2024-12-07 20:54:50.397496: Epoch time: 6.13 s 
2024-12-07 20:54:50.912210:  
2024-12-07 20:54:50.917811: Epoch 93 
2024-12-07 20:54:50.920847: Current learning rate: 0.00091 
2024-12-07 20:54:57.042838: train_loss -0.986 
2024-12-07 20:54:57.047901: val_loss -0.8028 
2024-12-07 20:54:57.052470: Pseudo dice [np.float32(0.8907), np.float32(0.8735)] 
2024-12-07 20:54:57.055529: Epoch time: 6.13 s 
2024-12-07 20:54:57.562520:  
2024-12-07 20:54:57.569132: Epoch 94 
2024-12-07 20:54:57.572177: Current learning rate: 0.00079 
2024-12-07 20:55:03.695334: train_loss -0.9857 
2024-12-07 20:55:03.701413: val_loss -0.8043 
2024-12-07 20:55:03.704979: Pseudo dice [np.float32(0.8924), np.float32(0.8738)] 
2024-12-07 20:55:03.708567: Epoch time: 6.13 s 
2024-12-07 20:55:04.215508:  
2024-12-07 20:55:04.220560: Epoch 95 
2024-12-07 20:55:04.223089: Current learning rate: 0.00067 
2024-12-07 20:55:10.351213: train_loss -0.9864 
2024-12-07 20:55:10.357817: val_loss -0.7995 
2024-12-07 20:55:10.360876: Pseudo dice [np.float32(0.8898), np.float32(0.8715)] 
2024-12-07 20:55:10.363932: Epoch time: 6.14 s 
2024-12-07 20:55:10.876581:  
2024-12-07 20:55:10.882195: Epoch 96 
2024-12-07 20:55:10.884732: Current learning rate: 0.00055 
2024-12-07 20:55:17.006993: train_loss -0.9863 
2024-12-07 20:55:17.013105: val_loss -0.799 
2024-12-07 20:55:17.015640: Pseudo dice [np.float32(0.8904), np.float32(0.8708)] 
2024-12-07 20:55:17.019697: Epoch time: 6.13 s 
2024-12-07 20:55:17.534532:  
2024-12-07 20:55:17.540116: Epoch 97 
2024-12-07 20:55:17.542670: Current learning rate: 0.00043 
2024-12-07 20:55:23.667825: train_loss -0.9862 
2024-12-07 20:55:23.672907: val_loss -0.7913 
2024-12-07 20:55:23.676468: Pseudo dice [np.float32(0.8868), np.float32(0.8677)] 
2024-12-07 20:55:23.679037: Epoch time: 6.14 s 
2024-12-07 20:55:24.195969:  
2024-12-07 20:55:24.201042: Epoch 98 
2024-12-07 20:55:24.203585: Current learning rate: 0.0003 
2024-12-07 20:55:30.324391: train_loss -0.9855 
2024-12-07 20:55:30.330458: val_loss -0.805 
2024-12-07 20:55:30.334025: Pseudo dice [np.float32(0.8925), np.float32(0.8742)] 
2024-12-07 20:55:30.337086: Epoch time: 6.13 s 
2024-12-07 20:55:31.005100:  
2024-12-07 20:55:31.011205: Epoch 99 
2024-12-07 20:55:31.014260: Current learning rate: 0.00016 
2024-12-07 20:55:37.136837: train_loss -0.9859 
2024-12-07 20:55:37.142436: val_loss -0.8025 
2024-12-07 20:55:37.145500: Pseudo dice [np.float32(0.8907), np.float32(0.8728)] 
2024-12-07 20:55:37.148591: Epoch time: 6.13 s 
2024-12-07 20:55:37.713315: Training done. 
2024-12-07 20:55:37.752155: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-07 20:55:37.756102: The split file contains 5 splits. 
2024-12-07 20:55:37.764888: Desired fold for training: 0 
2024-12-07 20:55:37.771845: This split has 208 training and 52 validation cases. 
2024-12-07 20:55:37.771845: predicting hippocampus_017 
2024-12-07 20:55:37.771845: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-07 20:55:37.882107: predicting hippocampus_019 
2024-12-07 20:55:37.895608: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-07 20:55:37.898215: predicting hippocampus_033 
2024-12-07 20:55:37.914172: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-07 20:55:37.924638: predicting hippocampus_035 
2024-12-07 20:55:37.924638: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-07 20:55:37.932210: predicting hippocampus_037 
2024-12-07 20:55:37.932210: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-07 20:55:37.945967: predicting hippocampus_049 
2024-12-07 20:55:37.945967: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-07 20:55:37.962061: predicting hippocampus_052 
2024-12-07 20:55:37.978097: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-07 20:55:37.985889: predicting hippocampus_065 
2024-12-07 20:55:37.993802: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-07 20:55:37.993802: predicting hippocampus_083 
2024-12-07 20:55:38.013917: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-07 20:55:38.025665: predicting hippocampus_088 
2024-12-07 20:55:38.025665: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-07 20:55:41.665848: predicting hippocampus_090 
2024-12-07 20:55:41.704414: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-07 20:55:41.728209: predicting hippocampus_092 
2024-12-07 20:55:41.733961: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-07 20:55:41.749727: predicting hippocampus_095 
2024-12-07 20:55:41.753733: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-07 20:55:41.769505: predicting hippocampus_107 
2024-12-07 20:55:41.773511: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-07 20:55:41.789280: predicting hippocampus_108 
2024-12-07 20:55:41.795032: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-07 20:55:41.810796: predicting hippocampus_123 
2024-12-07 20:55:41.814801: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-07 20:55:41.830564: predicting hippocampus_125 
2024-12-07 20:55:41.836572: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-07 20:55:41.858081: predicting hippocampus_157 
2024-12-07 20:55:41.864088: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-07 20:55:41.881855: predicting hippocampus_164 
2024-12-07 20:55:41.885862: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-07 20:55:41.923133: predicting hippocampus_169 
2024-12-07 20:55:41.929143: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-07 20:55:41.946907: predicting hippocampus_175 
2024-12-07 20:55:41.952655: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-07 20:55:41.968417: predicting hippocampus_185 
2024-12-07 20:55:41.974426: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-07 20:55:41.988185: predicting hippocampus_190 
2024-12-07 20:55:41.992190: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-07 20:55:42.005957: predicting hippocampus_194 
2024-12-07 20:55:42.011967: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-07 20:55:42.023726: predicting hippocampus_204 
2024-12-07 20:55:42.029739: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-07 20:55:42.041496: predicting hippocampus_205 
2024-12-07 20:55:42.047252: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-07 20:55:42.065020: predicting hippocampus_210 
2024-12-07 20:55:42.069024: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-07 20:55:42.082786: predicting hippocampus_217 
2024-12-07 20:55:42.088795: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-07 20:55:42.102553: predicting hippocampus_219 
2024-12-07 20:55:42.106560: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-07 20:55:42.120324: predicting hippocampus_229 
2024-12-07 20:55:42.126073: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-07 20:55:42.140093: predicting hippocampus_244 
2024-12-07 20:55:42.145845: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-07 20:55:42.161611: predicting hippocampus_261 
2024-12-07 20:55:42.165617: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-07 20:55:42.185383: predicting hippocampus_264 
2024-12-07 20:55:42.191133: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-07 20:55:42.204894: predicting hippocampus_277 
2024-12-07 20:55:42.210903: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-07 20:55:42.228667: predicting hippocampus_280 
2024-12-07 20:55:42.234678: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-07 20:55:42.246438: predicting hippocampus_286 
2024-12-07 20:55:42.252187: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-07 20:55:42.273959: predicting hippocampus_288 
2024-12-07 20:55:42.277964: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-07 20:55:42.297728: predicting hippocampus_289 
2024-12-07 20:55:42.303477: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-07 20:55:42.317238: predicting hippocampus_296 
2024-12-07 20:55:42.321242: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-07 20:55:42.335001: predicting hippocampus_305 
2024-12-07 20:55:42.341008: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-07 20:55:42.354774: predicting hippocampus_308 
2024-12-07 20:55:42.360781: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-07 20:55:42.374543: predicting hippocampus_317 
2024-12-07 20:55:42.380293: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-07 20:55:42.394055: predicting hippocampus_327 
2024-12-07 20:55:42.398060: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-07 20:55:42.411820: predicting hippocampus_330 
2024-12-07 20:55:42.415824: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-07 20:55:42.429583: predicting hippocampus_332 
2024-12-07 20:55:42.433590: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-07 20:55:42.447354: predicting hippocampus_338 
2024-12-07 20:55:42.453363: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-07 20:55:42.471128: predicting hippocampus_349 
2024-12-07 20:55:42.476879: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-07 20:55:42.488635: predicting hippocampus_350 
2024-12-07 20:55:42.494647: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-07 20:55:42.508405: predicting hippocampus_356 
2024-12-07 20:55:42.512411: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-07 20:55:42.524167: predicting hippocampus_358 
2024-12-07 20:55:42.530176: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-07 20:55:42.547940: predicting hippocampus_374 
2024-12-07 20:55:42.551686: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-07 20:55:42.567452: predicting hippocampus_394 
2024-12-07 20:55:42.573464: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-07 20:55:46.069607: Validation complete 
2024-12-07 20:55:46.069607: Mean Validation Dice:  0.8808723199081563 
