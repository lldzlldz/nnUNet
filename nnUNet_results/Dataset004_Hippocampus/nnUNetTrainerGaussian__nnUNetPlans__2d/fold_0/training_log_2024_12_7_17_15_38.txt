
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-07 17:15:38.897469: do_dummy_2d_data_aug: False 
2024-12-07 17:15:38.902179: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-07 17:15:38.908903: The split file contains 5 splits. 
2024-12-07 17:15:38.911902: Desired fold for training: 0 
2024-12-07 17:15:38.914276: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 366, 'patch_size': [56, 40], 'median_image_size_in_voxels': [50.0, 35.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-07 17:15:45.531982: unpacking dataset... 
2024-12-07 17:15:45.743868: unpacking done... 
2024-12-07 17:15:46.701286:  
2024-12-07 17:15:46.705354: Epoch 0 
2024-12-07 17:15:46.708673: Current learning rate: 0.01 
2024-12-07 17:15:56.670465: train_loss -0.1335 
2024-12-07 17:15:56.677250: val_loss -0.4676 
2024-12-07 17:15:56.679788: Pseudo dice [np.float32(0.5596), np.float32(0.4869)] 
2024-12-07 17:15:56.683352: Epoch time: 9.97 s 
2024-12-07 17:15:56.685882: Yayy! New best EMA pseudo Dice: 0.5231999754905701 
2024-12-07 17:15:57.342964:  
2024-12-07 17:15:57.348553: Epoch 1 
2024-12-07 17:15:57.351093: Current learning rate: 0.00991 
2024-12-07 17:16:06.510886: train_loss -0.6061 
2024-12-07 17:16:06.516055: val_loss -0.7793 
2024-12-07 17:16:06.520018: Pseudo dice [np.float32(0.8582), np.float32(0.846)] 
2024-12-07 17:16:06.522978: Epoch time: 9.17 s 
2024-12-07 17:16:06.525693: Yayy! New best EMA pseudo Dice: 0.5561000108718872 
2024-12-07 17:16:07.238910:  
2024-12-07 17:16:07.244282: Epoch 2 
2024-12-07 17:16:07.247353: Current learning rate: 0.00982 
2024-12-07 17:16:16.495332: train_loss -0.8363 
2024-12-07 17:16:16.502452: val_loss -0.8 
2024-12-07 17:16:16.506089: Pseudo dice [np.float32(0.871), np.float32(0.8586)] 
2024-12-07 17:16:16.509435: Epoch time: 9.26 s 
2024-12-07 17:16:16.511962: Yayy! New best EMA pseudo Dice: 0.5870000123977661 
2024-12-07 17:16:17.244810:  
2024-12-07 17:16:17.250223: Epoch 3 
2024-12-07 17:16:17.252761: Current learning rate: 0.00973 
2024-12-07 17:16:26.508027: train_loss -0.8682 
2024-12-07 17:16:26.513278: val_loss -0.7953 
2024-12-07 17:16:26.517339: Pseudo dice [np.float32(0.8707), np.float32(0.8569)] 
2024-12-07 17:16:26.519852: Epoch time: 9.26 s 
2024-12-07 17:16:26.523513: Yayy! New best EMA pseudo Dice: 0.6147000193595886 
2024-12-07 17:16:27.243402:  
2024-12-07 17:16:27.248604: Epoch 4 
2024-12-07 17:16:27.251186: Current learning rate: 0.00964 
2024-12-07 17:16:36.525738: train_loss -0.8856 
2024-12-07 17:16:36.530150: val_loss -0.7951 
2024-12-07 17:16:36.532891: Pseudo dice [np.float32(0.8724), np.float32(0.8585)] 
2024-12-07 17:16:36.538010: Epoch time: 9.28 s 
2024-12-07 17:16:36.543262: Yayy! New best EMA pseudo Dice: 0.6396999955177307 
2024-12-07 17:16:37.403797:  
2024-12-07 17:16:37.409910: Epoch 5 
2024-12-07 17:16:37.412144: Current learning rate: 0.00955 
2024-12-07 17:16:46.699312: train_loss -0.8977 
2024-12-07 17:16:46.704948: val_loss -0.7895 
2024-12-07 17:16:46.707523: Pseudo dice [np.float32(0.872), np.float32(0.8567)] 
2024-12-07 17:16:46.711074: Epoch time: 9.3 s 
2024-12-07 17:16:46.714287: Yayy! New best EMA pseudo Dice: 0.6621999740600586 
2024-12-07 17:16:47.426962:  
2024-12-07 17:16:47.434019: Epoch 6 
2024-12-07 17:16:47.437051: Current learning rate: 0.00946 
2024-12-07 17:16:56.673921: train_loss -0.9063 
2024-12-07 17:16:56.680028: val_loss -0.7878 
2024-12-07 17:16:56.683583: Pseudo dice [np.float32(0.873), np.float32(0.8557)] 
2024-12-07 17:16:56.687135: Epoch time: 9.25 s 
2024-12-07 17:16:56.690178: Yayy! New best EMA pseudo Dice: 0.6823999881744385 
2024-12-07 17:16:57.428334:  
2024-12-07 17:16:57.433410: Epoch 7 
2024-12-07 17:16:57.436492: Current learning rate: 0.00937 
2024-12-07 17:17:06.691097: train_loss -0.9131 
2024-12-07 17:17:06.697513: val_loss -0.781 
2024-12-07 17:17:06.702638: Pseudo dice [np.float32(0.8714), np.float32(0.8544)] 
2024-12-07 17:17:06.706404: Epoch time: 9.26 s 
2024-12-07 17:17:06.708944: Yayy! New best EMA pseudo Dice: 0.7005000114440918 
2024-12-07 17:17:07.434303:  
2024-12-07 17:17:07.439370: Epoch 8 
2024-12-07 17:17:07.442441: Current learning rate: 0.00928 
2024-12-07 17:17:16.826883: train_loss -0.9188 
2024-12-07 17:17:16.834555: val_loss -0.7809 
2024-12-07 17:17:16.839106: Pseudo dice [np.float32(0.8725), np.float32(0.8556)] 
2024-12-07 17:17:16.842161: Epoch time: 9.39 s 
2024-12-07 17:17:16.844695: Yayy! New best EMA pseudo Dice: 0.7167999744415283 
2024-12-07 17:17:17.550998:  
2024-12-07 17:17:17.556578: Epoch 9 
2024-12-07 17:17:17.559107: Current learning rate: 0.00919 
2024-12-07 17:17:26.719224: train_loss -0.9231 
2024-12-07 17:17:26.725839: val_loss -0.7772 
2024-12-07 17:17:26.743635: Pseudo dice [np.float32(0.8727), np.float32(0.8537)] 
2024-12-07 17:17:26.747227: Epoch time: 9.17 s 
2024-12-07 17:17:26.750798: Yayy! New best EMA pseudo Dice: 0.7315000295639038 
2024-12-07 17:17:27.466677:  
2024-12-07 17:17:27.472764: Epoch 10 
2024-12-07 17:17:27.475305: Current learning rate: 0.0091 
2024-12-07 17:17:36.639419: train_loss -0.927 
2024-12-07 17:17:36.645548: val_loss -0.7728 
2024-12-07 17:17:36.649645: Pseudo dice [np.float32(0.8699), np.float32(0.8534)] 
2024-12-07 17:17:36.652183: Epoch time: 9.17 s 
2024-12-07 17:17:36.655722: Yayy! New best EMA pseudo Dice: 0.7444999814033508 
2024-12-07 17:17:37.365032:  
2024-12-07 17:17:37.370650: Epoch 11 
2024-12-07 17:17:37.373201: Current learning rate: 0.009 
2024-12-07 17:17:46.570701: train_loss -0.9306 
2024-12-07 17:17:46.578348: val_loss -0.771 
2024-12-07 17:17:46.581612: Pseudo dice [np.float32(0.8707), np.float32(0.8528)] 
2024-12-07 17:17:46.584149: Epoch time: 9.21 s 
2024-12-07 17:17:46.586702: Yayy! New best EMA pseudo Dice: 0.7562000155448914 
2024-12-07 17:17:47.302493:  
2024-12-07 17:17:47.308119: Epoch 12 
2024-12-07 17:17:47.310665: Current learning rate: 0.00891 
2024-12-07 17:17:56.467979: train_loss -0.934 
2024-12-07 17:17:56.473603: val_loss -0.7689 
2024-12-07 17:17:56.476140: Pseudo dice [np.float32(0.8698), np.float32(0.8533)] 
2024-12-07 17:17:56.478670: Epoch time: 9.17 s 
2024-12-07 17:17:56.483222: Yayy! New best EMA pseudo Dice: 0.766700029373169 
2024-12-07 17:17:57.327535:  
2024-12-07 17:17:57.334629: Epoch 13 
2024-12-07 17:17:57.337729: Current learning rate: 0.00882 
2024-12-07 17:18:06.434464: train_loss -0.9364 
2024-12-07 17:18:06.441163: val_loss -0.7689 
2024-12-07 17:18:06.443702: Pseudo dice [np.float32(0.8706), np.float32(0.8542)] 
2024-12-07 17:18:06.446234: Epoch time: 9.11 s 
2024-12-07 17:18:06.448759: Yayy! New best EMA pseudo Dice: 0.7763000130653381 
2024-12-07 17:18:07.180843:  
2024-12-07 17:18:07.186437: Epoch 14 
2024-12-07 17:18:07.188972: Current learning rate: 0.00873 
2024-12-07 17:18:16.279284: train_loss -0.9395 
2024-12-07 17:18:16.286893: val_loss -0.7695 
2024-12-07 17:18:16.291499: Pseudo dice [np.float32(0.873), np.float32(0.8548)] 
2024-12-07 17:18:16.294541: Epoch time: 9.1 s 
2024-12-07 17:18:16.297594: Yayy! New best EMA pseudo Dice: 0.785099983215332 
2024-12-07 17:18:17.040223:  
2024-12-07 17:18:17.045305: Epoch 15 
2024-12-07 17:18:17.047834: Current learning rate: 0.00864 
2024-12-07 17:18:26.099950: train_loss -0.9419 
2024-12-07 17:18:26.105029: val_loss -0.7641 
2024-12-07 17:18:26.107557: Pseudo dice [np.float32(0.8707), np.float32(0.853)] 
2024-12-07 17:18:26.112104: Epoch time: 9.06 s 
2024-12-07 17:18:26.115142: Yayy! New best EMA pseudo Dice: 0.7926999926567078 
2024-12-07 17:18:26.838441:  
2024-12-07 17:18:26.845587: Epoch 16 
2024-12-07 17:18:26.848655: Current learning rate: 0.00855 
2024-12-07 17:18:36.045868: train_loss -0.9434 
2024-12-07 17:18:36.051957: val_loss -0.7609 
2024-12-07 17:18:36.055048: Pseudo dice [np.float32(0.8696), np.float32(0.8519)] 
2024-12-07 17:18:36.057603: Epoch time: 9.21 s 
2024-12-07 17:18:36.061174: Yayy! New best EMA pseudo Dice: 0.7994999885559082 
2024-12-07 17:18:36.842107:  
2024-12-07 17:18:36.847217: Epoch 17 
2024-12-07 17:18:36.850268: Current learning rate: 0.00846 
2024-12-07 17:18:46.204602: train_loss -0.9459 
2024-12-07 17:18:46.209777: val_loss -0.764 
2024-12-07 17:18:46.214915: Pseudo dice [np.float32(0.871), np.float32(0.8538)] 
2024-12-07 17:18:46.220561: Epoch time: 9.36 s 
2024-12-07 17:18:46.227661: Yayy! New best EMA pseudo Dice: 0.8058000206947327 
2024-12-07 17:18:46.941926:  
2024-12-07 17:18:46.946975: Epoch 18 
2024-12-07 17:18:46.949510: Current learning rate: 0.00836 
2024-12-07 17:18:56.116304: train_loss -0.9477 
2024-12-07 17:18:56.122499: val_loss -0.7609 
2024-12-07 17:18:56.127589: Pseudo dice [np.float32(0.8711), np.float32(0.8537)] 
2024-12-07 17:18:56.130146: Epoch time: 9.18 s 
2024-12-07 17:18:56.134769: Yayy! New best EMA pseudo Dice: 0.8115000128746033 
2024-12-07 17:18:56.848745:  
2024-12-07 17:18:56.853805: Epoch 19 
2024-12-07 17:18:56.856438: Current learning rate: 0.00827 
2024-12-07 17:19:06.240715: train_loss -0.9489 
2024-12-07 17:19:06.248536: val_loss -0.7627 
2024-12-07 17:19:06.253108: Pseudo dice [np.float32(0.8733), np.float32(0.8528)] 
2024-12-07 17:19:06.258758: Epoch time: 9.39 s 
2024-12-07 17:19:06.263835: Yayy! New best EMA pseudo Dice: 0.8166000247001648 
2024-12-07 17:19:07.113702:  
2024-12-07 17:19:07.118772: Epoch 20 
2024-12-07 17:19:07.121832: Current learning rate: 0.00818 
2024-12-07 17:19:16.277773: train_loss -0.9508 
2024-12-07 17:19:16.283711: val_loss -0.7581 
2024-12-07 17:19:16.290128: Pseudo dice [np.float32(0.8702), np.float32(0.8531)] 
2024-12-07 17:19:16.297312: Epoch time: 9.16 s 
2024-12-07 17:19:16.302052: Yayy! New best EMA pseudo Dice: 0.8210999965667725 
2024-12-07 17:19:17.037925:  
2024-12-07 17:19:17.042972: Epoch 21 
2024-12-07 17:19:17.045508: Current learning rate: 0.00809 
2024-12-07 17:19:26.131036: train_loss -0.952 
2024-12-07 17:19:26.136950: val_loss -0.7557 
2024-12-07 17:19:26.141358: Pseudo dice [np.float32(0.8701), np.float32(0.8514)] 
2024-12-07 17:19:26.146439: Epoch time: 9.09 s 
2024-12-07 17:19:26.148815: Yayy! New best EMA pseudo Dice: 0.8251000046730042 
2024-12-07 17:19:26.824890:  
2024-12-07 17:19:26.830018: Epoch 22 
2024-12-07 17:19:26.832721: Current learning rate: 0.008 
2024-12-07 17:19:36.013404: train_loss -0.9534 
2024-12-07 17:19:36.018529: val_loss -0.7555 
2024-12-07 17:19:36.022612: Pseudo dice [np.float32(0.8697), np.float32(0.8526)] 
2024-12-07 17:19:36.027240: Epoch time: 9.19 s 
2024-12-07 17:19:36.032452: Yayy! New best EMA pseudo Dice: 0.8287000060081482 
2024-12-07 17:19:36.701515:  
2024-12-07 17:19:36.706590: Epoch 23 
2024-12-07 17:19:36.709644: Current learning rate: 0.0079 
2024-12-07 17:19:45.732985: train_loss -0.9546 
2024-12-07 17:19:45.739123: val_loss -0.7577 
2024-12-07 17:19:45.743249: Pseudo dice [np.float32(0.8698), np.float32(0.8538)] 
2024-12-07 17:19:45.746816: Epoch time: 9.03 s 
2024-12-07 17:19:45.750449: Yayy! New best EMA pseudo Dice: 0.8320000171661377 
2024-12-07 17:19:46.444629:  
2024-12-07 17:19:46.450205: Epoch 24 
2024-12-07 17:19:46.453280: Current learning rate: 0.00781 
2024-12-07 17:19:55.759990: train_loss -0.9557 
2024-12-07 17:19:55.765614: val_loss -0.7568 
2024-12-07 17:19:55.768156: Pseudo dice [np.float32(0.8701), np.float32(0.8546)] 
2024-12-07 17:19:55.773246: Epoch time: 9.32 s 
2024-12-07 17:19:55.778389: Yayy! New best EMA pseudo Dice: 0.835099995136261 
2024-12-07 17:19:56.481302:  
2024-12-07 17:19:56.486364: Epoch 25 
2024-12-07 17:19:56.488898: Current learning rate: 0.00772 
2024-12-07 17:20:05.791603: train_loss -0.9567 
2024-12-07 17:20:05.798518: val_loss -0.7551 
2024-12-07 17:20:05.802082: Pseudo dice [np.float32(0.8707), np.float32(0.8525)] 
2024-12-07 17:20:05.806652: Epoch time: 9.31 s 
2024-12-07 17:20:05.809705: Yayy! New best EMA pseudo Dice: 0.8377000093460083 
2024-12-07 17:20:06.492964:  
2024-12-07 17:20:06.498014: Epoch 26 
2024-12-07 17:20:06.501123: Current learning rate: 0.00763 
2024-12-07 17:20:15.495829: train_loss -0.9579 
2024-12-07 17:20:15.501488: val_loss -0.7534 
2024-12-07 17:20:15.505061: Pseudo dice [np.float32(0.8707), np.float32(0.8528)] 
2024-12-07 17:20:15.511689: Epoch time: 9.0 s 
2024-12-07 17:20:15.516822: Yayy! New best EMA pseudo Dice: 0.8400999903678894 
2024-12-07 17:20:16.198329:  
2024-12-07 17:20:16.203386: Epoch 27 
2024-12-07 17:20:16.206434: Current learning rate: 0.00753 
2024-12-07 17:20:25.264218: train_loss -0.9586 
2024-12-07 17:20:25.272081: val_loss -0.7551 
2024-12-07 17:20:25.275155: Pseudo dice [np.float32(0.8714), np.float32(0.8534)] 
2024-12-07 17:20:25.279777: Epoch time: 9.07 s 
2024-12-07 17:20:25.282839: Yayy! New best EMA pseudo Dice: 0.8422999978065491 
2024-12-07 17:20:25.984746:  
2024-12-07 17:20:25.990303: Epoch 28 
2024-12-07 17:20:25.992836: Current learning rate: 0.00744 
2024-12-07 17:20:35.044564: train_loss -0.9597 
2024-12-07 17:20:35.049632: val_loss -0.7509 
2024-12-07 17:20:35.054711: Pseudo dice [np.float32(0.8704), np.float32(0.8516)] 
2024-12-07 17:20:35.058780: Epoch time: 9.06 s 
2024-12-07 17:20:35.065002: Yayy! New best EMA pseudo Dice: 0.8442000150680542 
2024-12-07 17:20:35.883318:  
2024-12-07 17:20:35.886863: Epoch 29 
2024-12-07 17:20:35.890895: Current learning rate: 0.00735 
2024-12-07 17:20:44.922073: train_loss -0.9606 
2024-12-07 17:20:44.929692: val_loss -0.7549 
2024-12-07 17:20:44.932328: Pseudo dice [np.float32(0.8717), np.float32(0.8529)] 
2024-12-07 17:20:44.937559: Epoch time: 9.04 s 
2024-12-07 17:20:44.940139: Yayy! New best EMA pseudo Dice: 0.8460000157356262 
2024-12-07 17:20:45.625149:  
2024-12-07 17:20:45.630747: Epoch 30 
2024-12-07 17:20:45.633302: Current learning rate: 0.00725 
2024-12-07 17:20:54.671441: train_loss -0.9612 
2024-12-07 17:20:54.677607: val_loss -0.7511 
2024-12-07 17:20:54.681176: Pseudo dice [np.float32(0.8696), np.float32(0.8541)] 
2024-12-07 17:20:54.684766: Epoch time: 9.05 s 
2024-12-07 17:20:54.688889: Yayy! New best EMA pseudo Dice: 0.847599983215332 
2024-12-07 17:20:55.382838:  
2024-12-07 17:20:55.387890: Epoch 31 
2024-12-07 17:20:55.390424: Current learning rate: 0.00716 
2024-12-07 17:21:04.442051: train_loss -0.9618 
2024-12-07 17:21:04.447274: val_loss -0.7554 
2024-12-07 17:21:04.452954: Pseudo dice [np.float32(0.8715), np.float32(0.8548)] 
2024-12-07 17:21:04.455492: Epoch time: 9.06 s 
2024-12-07 17:21:04.458022: Yayy! New best EMA pseudo Dice: 0.8492000102996826 
2024-12-07 17:21:05.156154:  
2024-12-07 17:21:05.161244: Epoch 32 
2024-12-07 17:21:05.164854: Current learning rate: 0.00707 
2024-12-07 17:21:14.182823: train_loss -0.9627 
2024-12-07 17:21:14.188987: val_loss -0.7548 
2024-12-07 17:21:14.193077: Pseudo dice [np.float32(0.8718), np.float32(0.8543)] 
2024-12-07 17:21:14.195715: Epoch time: 9.03 s 
2024-12-07 17:21:14.199790: Yayy! New best EMA pseudo Dice: 0.8504999876022339 
2024-12-07 17:21:14.889714:  
2024-12-07 17:21:14.895836: Epoch 33 
2024-12-07 17:21:14.898404: Current learning rate: 0.00697 
2024-12-07 17:21:23.845938: train_loss -0.9631 
2024-12-07 17:21:23.852150: val_loss -0.7536 
2024-12-07 17:21:23.857235: Pseudo dice [np.float32(0.871), np.float32(0.8549)] 
2024-12-07 17:21:23.859821: Epoch time: 8.96 s 
2024-12-07 17:21:23.863907: Yayy! New best EMA pseudo Dice: 0.8518000245094299 
2024-12-07 17:21:24.571782:  
2024-12-07 17:21:24.576329: Epoch 34 
2024-12-07 17:21:24.579383: Current learning rate: 0.00688 
2024-12-07 17:21:33.660852: train_loss -0.9638 
2024-12-07 17:21:33.667444: val_loss -0.7522 
2024-12-07 17:21:33.673598: Pseudo dice [np.float32(0.871), np.float32(0.8537)] 
2024-12-07 17:21:33.678692: Epoch time: 9.09 s 
2024-12-07 17:21:33.682750: Yayy! New best EMA pseudo Dice: 0.8528000116348267 
2024-12-07 17:21:34.395906:  
2024-12-07 17:21:34.401962: Epoch 35 
2024-12-07 17:21:34.405028: Current learning rate: 0.00679 
2024-12-07 17:21:43.461657: train_loss -0.9646 
2024-12-07 17:21:43.467745: val_loss -0.7522 
2024-12-07 17:21:43.472892: Pseudo dice [np.float32(0.871), np.float32(0.854)] 
2024-12-07 17:21:43.478508: Epoch time: 9.07 s 
2024-12-07 17:21:43.482579: Yayy! New best EMA pseudo Dice: 0.8537999987602234 
2024-12-07 17:21:44.178626:  
2024-12-07 17:21:44.183180: Epoch 36 
2024-12-07 17:21:44.186231: Current learning rate: 0.00669 
2024-12-07 17:21:53.214881: train_loss -0.9649 
2024-12-07 17:21:53.221654: val_loss -0.7507 
2024-12-07 17:21:53.225229: Pseudo dice [np.float32(0.8706), np.float32(0.853)] 
2024-12-07 17:21:53.230346: Epoch time: 9.04 s 
2024-12-07 17:21:53.235464: Yayy! New best EMA pseudo Dice: 0.8546000123023987 
2024-12-07 17:21:54.085329:  
2024-12-07 17:21:54.090894: Epoch 37 
2024-12-07 17:21:54.093438: Current learning rate: 0.0066 
2024-12-07 17:22:03.093753: train_loss -0.9657 
2024-12-07 17:22:03.101537: val_loss -0.7521 
2024-12-07 17:22:03.104626: Pseudo dice [np.float32(0.8702), np.float32(0.8532)] 
2024-12-07 17:22:03.109233: Epoch time: 9.01 s 
2024-12-07 17:22:03.114318: Yayy! New best EMA pseudo Dice: 0.8553000092506409 
2024-12-07 17:22:03.820714:  
2024-12-07 17:22:03.825793: Epoch 38 
2024-12-07 17:22:03.828314: Current learning rate: 0.0065 
2024-12-07 17:22:12.841648: train_loss -0.9663 
2024-12-07 17:22:12.847803: val_loss -0.75 
2024-12-07 17:22:12.852932: Pseudo dice [np.float32(0.8717), np.float32(0.8527)] 
2024-12-07 17:22:12.857519: Epoch time: 9.02 s 
2024-12-07 17:22:12.860585: Yayy! New best EMA pseudo Dice: 0.8560000061988831 
2024-12-07 17:22:13.579808:  
2024-12-07 17:22:13.585382: Epoch 39 
2024-12-07 17:22:13.587919: Current learning rate: 0.00641 
2024-12-07 17:22:22.584881: train_loss -0.967 
2024-12-07 17:22:22.592584: val_loss -0.7487 
2024-12-07 17:22:22.596264: Pseudo dice [np.float32(0.871), np.float32(0.8523)] 
2024-12-07 17:22:22.601488: Epoch time: 9.01 s 
2024-12-07 17:22:22.604047: Yayy! New best EMA pseudo Dice: 0.8565999865531921 
2024-12-07 17:22:23.309838:  
2024-12-07 17:22:23.314893: Epoch 40 
2024-12-07 17:22:23.317943: Current learning rate: 0.00631 
2024-12-07 17:22:32.320690: train_loss -0.9672 
2024-12-07 17:22:32.327550: val_loss -0.7483 
2024-12-07 17:22:32.331110: Pseudo dice [np.float32(0.87), np.float32(0.8531)] 
2024-12-07 17:22:32.335173: Epoch time: 9.01 s 
2024-12-07 17:22:32.338724: Yayy! New best EMA pseudo Dice: 0.8571000099182129 
2024-12-07 17:22:33.016140:  
2024-12-07 17:22:33.021215: Epoch 41 
2024-12-07 17:22:33.023746: Current learning rate: 0.00622 
2024-12-07 17:22:42.014588: train_loss -0.9678 
2024-12-07 17:22:42.019706: val_loss -0.7478 
2024-12-07 17:22:42.024795: Pseudo dice [np.float32(0.8704), np.float32(0.8527)] 
2024-12-07 17:22:42.029926: Epoch time: 9.0 s 
2024-12-07 17:22:42.034991: Yayy! New best EMA pseudo Dice: 0.8575000166893005 
2024-12-07 17:22:42.718626:  
2024-12-07 17:22:42.724251: Epoch 42 
2024-12-07 17:22:42.727310: Current learning rate: 0.00612 
2024-12-07 17:22:51.730408: train_loss -0.9682 
2024-12-07 17:22:51.736695: val_loss -0.7473 
2024-12-07 17:22:51.739250: Pseudo dice [np.float32(0.8706), np.float32(0.8525)] 
2024-12-07 17:22:51.743314: Epoch time: 9.01 s 
2024-12-07 17:22:51.746859: Yayy! New best EMA pseudo Dice: 0.8579000234603882 
2024-12-07 17:22:52.449567:  
2024-12-07 17:22:52.454626: Epoch 43 
2024-12-07 17:22:52.458199: Current learning rate: 0.00603 
2024-12-07 17:23:01.413567: train_loss -0.9689 
2024-12-07 17:23:01.418704: val_loss -0.7498 
2024-12-07 17:23:01.422303: Pseudo dice [np.float32(0.8712), np.float32(0.8548)] 
2024-12-07 17:23:01.424859: Epoch time: 8.96 s 
2024-12-07 17:23:01.429974: Yayy! New best EMA pseudo Dice: 0.8583999872207642 
2024-12-07 17:23:02.132765:  
2024-12-07 17:23:02.137840: Epoch 44 
2024-12-07 17:23:02.140899: Current learning rate: 0.00593 
2024-12-07 17:23:11.185566: train_loss -0.9691 
2024-12-07 17:23:11.190196: val_loss -0.7458 
2024-12-07 17:23:11.195318: Pseudo dice [np.float32(0.8705), np.float32(0.8526)] 
2024-12-07 17:23:11.198414: Epoch time: 9.05 s 
2024-12-07 17:23:11.201983: Yayy! New best EMA pseudo Dice: 0.8586999773979187 
2024-12-07 17:23:12.009724:  
2024-12-07 17:23:12.014789: Epoch 45 
2024-12-07 17:23:12.017371: Current learning rate: 0.00584 
2024-12-07 17:23:20.974655: train_loss -0.9695 
2024-12-07 17:23:20.982533: val_loss -0.7453 
2024-12-07 17:23:20.986579: Pseudo dice [np.float32(0.8697), np.float32(0.8535)] 
2024-12-07 17:23:20.990144: Epoch time: 8.97 s 
2024-12-07 17:23:20.992744: Yayy! New best EMA pseudo Dice: 0.859000027179718 
2024-12-07 17:23:21.686912:  
2024-12-07 17:23:21.694005: Epoch 46 
2024-12-07 17:23:21.697099: Current learning rate: 0.00574 
2024-12-07 17:23:30.691995: train_loss -0.9696 
2024-12-07 17:23:30.697335: val_loss -0.7483 
2024-12-07 17:23:30.702463: Pseudo dice [np.float32(0.8711), np.float32(0.8541)] 
2024-12-07 17:23:30.706531: Epoch time: 9.01 s 
2024-12-07 17:23:30.709109: Yayy! New best EMA pseudo Dice: 0.8593999743461609 
2024-12-07 17:23:31.356814:  
2024-12-07 17:23:31.361894: Epoch 47 
2024-12-07 17:23:31.364439: Current learning rate: 0.00565 
2024-12-07 17:23:40.370040: train_loss -0.9703 
2024-12-07 17:23:40.375169: val_loss -0.746 
2024-12-07 17:23:40.380402: Pseudo dice [np.float32(0.8708), np.float32(0.8525)] 
2024-12-07 17:23:40.383052: Epoch time: 9.01 s 
2024-12-07 17:23:40.388248: Yayy! New best EMA pseudo Dice: 0.8596000075340271 
2024-12-07 17:23:41.052187:  
2024-12-07 17:23:41.057232: Epoch 48 
2024-12-07 17:23:41.059766: Current learning rate: 0.00555 
2024-12-07 17:23:50.041194: train_loss -0.9706 
2024-12-07 17:23:50.047263: val_loss -0.7463 
2024-12-07 17:23:50.049800: Pseudo dice [np.float32(0.8716), np.float32(0.8528)] 
2024-12-07 17:23:50.055918: Epoch time: 8.99 s 
2024-12-07 17:23:50.060061: Yayy! New best EMA pseudo Dice: 0.8598999977111816 
2024-12-07 17:23:50.759136:  
2024-12-07 17:23:50.764722: Epoch 49 
2024-12-07 17:23:50.767768: Current learning rate: 0.00546 
2024-12-07 17:23:59.742709: train_loss -0.9709 
2024-12-07 17:23:59.749342: val_loss -0.7452 
2024-12-07 17:23:59.754493: Pseudo dice [np.float32(0.8701), np.float32(0.852)] 
2024-12-07 17:23:59.759587: Epoch time: 8.98 s 
2024-12-07 17:23:59.786240: Yayy! New best EMA pseudo Dice: 0.8600000143051147 
2024-12-07 17:24:00.468846:  
2024-12-07 17:24:00.473913: Epoch 50 
2024-12-07 17:24:00.476470: Current learning rate: 0.00536 
2024-12-07 17:24:09.457452: train_loss -0.9712 
2024-12-07 17:24:09.462566: val_loss -0.7416 
2024-12-07 17:24:09.466149: Pseudo dice [np.float32(0.8702), np.float32(0.8515)] 
2024-12-07 17:24:09.470205: Epoch time: 8.99 s 
2024-12-07 17:24:09.472735: Yayy! New best EMA pseudo Dice: 0.8600999712944031 
2024-12-07 17:24:10.158859:  
2024-12-07 17:24:10.163988: Epoch 51 
2024-12-07 17:24:10.166519: Current learning rate: 0.00526 
2024-12-07 17:24:19.163147: train_loss -0.9717 
2024-12-07 17:24:19.168773: val_loss -0.7455 
2024-12-07 17:24:19.172842: Pseudo dice [np.float32(0.871), np.float32(0.8536)] 
2024-12-07 17:24:19.176426: Epoch time: 9.01 s 
2024-12-07 17:24:19.179506: Yayy! New best EMA pseudo Dice: 0.8603000044822693 
2024-12-07 17:24:19.981984:  
2024-12-07 17:24:19.988552: Epoch 52 
2024-12-07 17:24:19.993110: Current learning rate: 0.00517 
2024-12-07 17:24:28.938423: train_loss -0.972 
2024-12-07 17:24:28.944041: val_loss -0.7449 
2024-12-07 17:24:28.948167: Pseudo dice [np.float32(0.8693), np.float32(0.8542)] 
2024-12-07 17:24:28.953411: Epoch time: 8.96 s 
2024-12-07 17:24:28.956979: Yayy! New best EMA pseudo Dice: 0.8604000210762024 
2024-12-07 17:24:29.642897:  
2024-12-07 17:24:29.649461: Epoch 53 
2024-12-07 17:24:29.653064: Current learning rate: 0.00507 
2024-12-07 17:24:38.590387: train_loss -0.9724 
2024-12-07 17:24:38.598009: val_loss -0.7435 
2024-12-07 17:24:38.600545: Pseudo dice [np.float32(0.8705), np.float32(0.8524)] 
2024-12-07 17:24:38.605628: Epoch time: 8.95 s 
2024-12-07 17:24:38.610739: Yayy! New best EMA pseudo Dice: 0.8604999780654907 
2024-12-07 17:24:39.302567:  
2024-12-07 17:24:39.308169: Epoch 54 
2024-12-07 17:24:39.311227: Current learning rate: 0.00497 
2024-12-07 17:24:48.310890: train_loss -0.9726 
2024-12-07 17:24:48.316523: val_loss -0.7429 
2024-12-07 17:24:48.321111: Pseudo dice [np.float32(0.8696), np.float32(0.853)] 
2024-12-07 17:24:48.324193: Epoch time: 9.01 s 
2024-12-07 17:24:48.330837: Yayy! New best EMA pseudo Dice: 0.8605999946594238 
2024-12-07 17:24:49.025784:  
2024-12-07 17:24:49.031393: Epoch 55 
2024-12-07 17:24:49.034445: Current learning rate: 0.00487 
2024-12-07 17:24:57.971559: train_loss -0.9729 
2024-12-07 17:24:57.977677: val_loss -0.7424 
2024-12-07 17:24:57.981736: Pseudo dice [np.float32(0.8703), np.float32(0.8524)] 
2024-12-07 17:24:57.986443: Epoch time: 8.95 s 
2024-12-07 17:24:57.989521: Yayy! New best EMA pseudo Dice: 0.8607000112533569 
2024-12-07 17:24:58.686929:  
2024-12-07 17:24:58.692000: Epoch 56 
2024-12-07 17:24:58.695041: Current learning rate: 0.00478 
2024-12-07 17:25:07.780075: train_loss -0.9734 
2024-12-07 17:25:07.785690: val_loss -0.741 
2024-12-07 17:25:07.788229: Pseudo dice [np.float32(0.8701), np.float32(0.8524)] 
2024-12-07 17:25:07.790815: Epoch time: 9.09 s 
2024-12-07 17:25:07.795932: Yayy! New best EMA pseudo Dice: 0.8607000112533569 
2024-12-07 17:25:08.486866:  
2024-12-07 17:25:08.492439: Epoch 57 
2024-12-07 17:25:08.495508: Current learning rate: 0.00468 
2024-12-07 17:25:17.498199: train_loss -0.9733 
2024-12-07 17:25:17.503450: val_loss -0.7449 
2024-12-07 17:25:17.508630: Pseudo dice [np.float32(0.8697), np.float32(0.8546)] 
2024-12-07 17:25:17.511177: Epoch time: 9.01 s 
2024-12-07 17:25:17.517895: Yayy! New best EMA pseudo Dice: 0.8608999848365784 
2024-12-07 17:25:18.202952:  
2024-12-07 17:25:18.208574: Epoch 58 
2024-12-07 17:25:18.212143: Current learning rate: 0.00458 
2024-12-07 17:25:27.158380: train_loss -0.9735 
2024-12-07 17:25:27.166017: val_loss -0.7417 
2024-12-07 17:25:27.169590: Pseudo dice [np.float32(0.8709), np.float32(0.852)] 
2024-12-07 17:25:27.174196: Epoch time: 8.96 s 
2024-12-07 17:25:27.178784: Yayy! New best EMA pseudo Dice: 0.8608999848365784 
2024-12-07 17:25:27.878617:  
2024-12-07 17:25:27.883698: Epoch 59 
2024-12-07 17:25:27.886745: Current learning rate: 0.00448 
2024-12-07 17:25:36.858421: train_loss -0.9739 
2024-12-07 17:25:36.863529: val_loss -0.7398 
2024-12-07 17:25:36.868610: Pseudo dice [np.float32(0.8695), np.float32(0.8514)] 
2024-12-07 17:25:36.872677: Epoch time: 8.98 s 
2024-12-07 17:25:37.534807:  
2024-12-07 17:25:37.540389: Epoch 60 
2024-12-07 17:25:37.543933: Current learning rate: 0.00438 
2024-12-07 17:25:46.531229: train_loss -0.9743 
2024-12-07 17:25:46.537975: val_loss -0.7395 
2024-12-07 17:25:46.543036: Pseudo dice [np.float32(0.8693), np.float32(0.8516)] 
2024-12-07 17:25:46.548122: Epoch time: 9.0 s 
2024-12-07 17:25:47.361459:  
2024-12-07 17:25:47.366524: Epoch 61 
2024-12-07 17:25:47.370098: Current learning rate: 0.00429 
2024-12-07 17:25:56.305690: train_loss -0.9743 
2024-12-07 17:25:56.311836: val_loss -0.7414 
2024-12-07 17:25:56.315927: Pseudo dice [np.float32(0.8694), np.float32(0.8525)] 
2024-12-07 17:25:56.321010: Epoch time: 8.94 s 
2024-12-07 17:25:56.992565:  
2024-12-07 17:25:56.999151: Epoch 62 
2024-12-07 17:25:57.002689: Current learning rate: 0.00419 
2024-12-07 17:26:05.962922: train_loss -0.9746 
2024-12-07 17:26:05.968532: val_loss -0.7399 
2024-12-07 17:26:05.973606: Pseudo dice [np.float32(0.8697), np.float32(0.8511)] 
2024-12-07 17:26:05.978149: Epoch time: 8.97 s 
2024-12-07 17:26:06.656452:  
2024-12-07 17:26:06.662560: Epoch 63 
2024-12-07 17:26:06.666614: Current learning rate: 0.00409 
2024-12-07 17:26:15.655429: train_loss -0.9749 
2024-12-07 17:26:15.662151: val_loss -0.7392 
2024-12-07 17:26:15.665730: Pseudo dice [np.float32(0.8698), np.float32(0.8513)] 
2024-12-07 17:26:15.670805: Epoch time: 9.0 s 
2024-12-07 17:26:16.330938:  
2024-12-07 17:26:16.335995: Epoch 64 
2024-12-07 17:26:16.339538: Current learning rate: 0.00399 
2024-12-07 17:26:25.278253: train_loss -0.9752 
2024-12-07 17:26:25.286927: val_loss -0.7403 
2024-12-07 17:26:25.293538: Pseudo dice [np.float32(0.87), np.float32(0.8535)] 
2024-12-07 17:26:25.297124: Epoch time: 8.95 s 
2024-12-07 17:26:25.978099:  
2024-12-07 17:26:25.984158: Epoch 65 
2024-12-07 17:26:25.987721: Current learning rate: 0.00389 
2024-12-07 17:26:34.897976: train_loss -0.9756 
2024-12-07 17:26:34.903064: val_loss -0.7385 
2024-12-07 17:26:34.908130: Pseudo dice [np.float32(0.8695), np.float32(0.8516)] 
2024-12-07 17:26:34.912213: Epoch time: 8.92 s 
2024-12-07 17:26:35.579661:  
2024-12-07 17:26:35.585232: Epoch 66 
2024-12-07 17:26:35.588789: Current learning rate: 0.00379 
2024-12-07 17:26:44.540466: train_loss -0.9759 
2024-12-07 17:26:44.546070: val_loss -0.7364 
2024-12-07 17:26:44.550643: Pseudo dice [np.float32(0.8685), np.float32(0.851)] 
2024-12-07 17:26:44.555715: Epoch time: 8.96 s 
2024-12-07 17:26:45.225899:  
2024-12-07 17:26:45.231480: Epoch 67 
2024-12-07 17:26:45.235032: Current learning rate: 0.00369 
2024-12-07 17:26:54.180257: train_loss -0.9759 
2024-12-07 17:26:54.186921: val_loss -0.7378 
2024-12-07 17:26:54.193045: Pseudo dice [np.float32(0.869), np.float32(0.8512)] 
2024-12-07 17:26:54.197684: Epoch time: 8.95 s 
2024-12-07 17:26:54.886919:  
2024-12-07 17:26:54.892980: Epoch 68 
2024-12-07 17:26:54.896534: Current learning rate: 0.00359 
2024-12-07 17:27:03.902112: train_loss -0.9761 
2024-12-07 17:27:03.909199: val_loss -0.7367 
2024-12-07 17:27:03.912295: Pseudo dice [np.float32(0.8679), np.float32(0.8523)] 
2024-12-07 17:27:03.917382: Epoch time: 9.02 s 
2024-12-07 17:27:04.740089:  
2024-12-07 17:27:04.746162: Epoch 69 
2024-12-07 17:27:04.750213: Current learning rate: 0.00349 
2024-12-07 17:27:13.706597: train_loss -0.9765 
2024-12-07 17:27:13.713693: val_loss -0.7382 
2024-12-07 17:27:13.717259: Pseudo dice [np.float32(0.8692), np.float32(0.8536)] 
2024-12-07 17:27:13.722334: Epoch time: 8.97 s 
2024-12-07 17:27:14.415281:  
2024-12-07 17:27:14.420874: Epoch 70 
2024-12-07 17:27:14.424439: Current learning rate: 0.00338 
2024-12-07 17:27:23.368037: train_loss -0.9766 
2024-12-07 17:27:23.374136: val_loss -0.7376 
2024-12-07 17:27:23.379218: Pseudo dice [np.float32(0.8689), np.float32(0.8527)] 
2024-12-07 17:27:23.384325: Epoch time: 8.95 s 
2024-12-07 17:27:24.082530:  
2024-12-07 17:27:24.088102: Epoch 71 
2024-12-07 17:27:24.091168: Current learning rate: 0.00328 
2024-12-07 17:27:33.040276: train_loss -0.9767 
2024-12-07 17:27:33.046389: val_loss -0.738 
2024-12-07 17:27:33.051464: Pseudo dice [np.float32(0.8693), np.float32(0.8523)] 
2024-12-07 17:27:33.055513: Epoch time: 8.96 s 
2024-12-07 17:27:33.749814:  
2024-12-07 17:27:33.755383: Epoch 72 
2024-12-07 17:27:33.758435: Current learning rate: 0.00318 
2024-12-07 17:27:42.683603: train_loss -0.9771 
2024-12-07 17:27:42.688801: val_loss -0.736 
2024-12-07 17:27:42.691475: Pseudo dice [np.float32(0.8698), np.float32(0.8504)] 
2024-12-07 17:27:42.696669: Epoch time: 8.93 s 
2024-12-07 17:27:43.372756:  
2024-12-07 17:27:43.378833: Epoch 73 
2024-12-07 17:27:43.381364: Current learning rate: 0.00308 
2024-12-07 17:27:52.345433: train_loss -0.9773 
2024-12-07 17:27:52.350560: val_loss -0.7367 
2024-12-07 17:27:52.355641: Pseudo dice [np.float32(0.8683), np.float32(0.8524)] 
2024-12-07 17:27:52.359708: Epoch time: 8.97 s 
2024-12-07 17:27:53.028691:  
2024-12-07 17:27:53.033761: Epoch 74 
2024-12-07 17:27:53.037308: Current learning rate: 0.00297 
2024-12-07 17:28:02.016217: train_loss -0.9775 
2024-12-07 17:28:02.022304: val_loss -0.7394 
2024-12-07 17:28:02.027418: Pseudo dice [np.float32(0.8695), np.float32(0.8534)] 
2024-12-07 17:28:02.032468: Epoch time: 8.99 s 
2024-12-07 17:28:02.703374:  
2024-12-07 17:28:02.709446: Epoch 75 
2024-12-07 17:28:02.713505: Current learning rate: 0.00287 
2024-12-07 17:28:11.656286: train_loss -0.9775 
2024-12-07 17:28:11.661903: val_loss -0.7329 
2024-12-07 17:28:11.666983: Pseudo dice [np.float32(0.8662), np.float32(0.8516)] 
2024-12-07 17:28:11.672071: Epoch time: 8.95 s 
2024-12-07 17:28:12.356943:  
2024-12-07 17:28:12.361988: Epoch 76 
2024-12-07 17:28:12.365543: Current learning rate: 0.00277 
2024-12-07 17:28:21.319520: train_loss -0.9777 
2024-12-07 17:28:21.325627: val_loss -0.7357 
2024-12-07 17:28:21.329697: Pseudo dice [np.float32(0.8702), np.float32(0.8505)] 
2024-12-07 17:28:21.334819: Epoch time: 8.96 s 
2024-12-07 17:28:22.147447:  
2024-12-07 17:28:22.153022: Epoch 77 
2024-12-07 17:28:22.157074: Current learning rate: 0.00266 
2024-12-07 17:28:31.059290: train_loss -0.9779 
2024-12-07 17:28:31.066967: val_loss -0.7343 
2024-12-07 17:28:31.074119: Pseudo dice [np.float32(0.8684), np.float32(0.8522)] 
2024-12-07 17:28:31.080791: Epoch time: 8.91 s 
2024-12-07 17:28:31.778000:  
2024-12-07 17:28:31.783558: Epoch 78 
2024-12-07 17:28:31.787608: Current learning rate: 0.00256 
2024-12-07 17:28:40.712876: train_loss -0.978 
2024-12-07 17:28:40.718970: val_loss -0.7358 
2024-12-07 17:28:40.723017: Pseudo dice [np.float32(0.8695), np.float32(0.8519)] 
2024-12-07 17:28:40.726581: Epoch time: 8.93 s 
2024-12-07 17:28:41.434310:  
2024-12-07 17:28:41.440408: Epoch 79 
2024-12-07 17:28:41.442940: Current learning rate: 0.00245 
2024-12-07 17:28:50.450480: train_loss -0.9782 
2024-12-07 17:28:50.457267: val_loss -0.7377 
2024-12-07 17:28:50.462343: Pseudo dice [np.float32(0.8699), np.float32(0.8534)] 
2024-12-07 17:28:50.470311: Epoch time: 9.02 s 
2024-12-07 17:28:51.128803:  
2024-12-07 17:28:51.133870: Epoch 80 
2024-12-07 17:28:51.137912: Current learning rate: 0.00235 
2024-12-07 17:29:00.091501: train_loss -0.9786 
2024-12-07 17:29:00.098583: val_loss -0.7364 
2024-12-07 17:29:00.101665: Pseudo dice [np.float32(0.8695), np.float32(0.8523)] 
2024-12-07 17:29:00.106227: Epoch time: 8.96 s 
2024-12-07 17:29:00.802366:  
2024-12-07 17:29:00.807976: Epoch 81 
2024-12-07 17:29:00.810515: Current learning rate: 0.00224 
2024-12-07 17:29:09.818602: train_loss -0.9786 
2024-12-07 17:29:09.825352: val_loss -0.7359 
2024-12-07 17:29:09.830951: Pseudo dice [np.float32(0.8692), np.float32(0.8517)] 
2024-12-07 17:29:09.835503: Epoch time: 9.02 s 
2024-12-07 17:29:10.511298:  
2024-12-07 17:29:10.516362: Epoch 82 
2024-12-07 17:29:10.519927: Current learning rate: 0.00214 
2024-12-07 17:29:19.537289: train_loss -0.9786 
2024-12-07 17:29:19.544783: val_loss -0.7378 
2024-12-07 17:29:19.547916: Pseudo dice [np.float32(0.8708), np.float32(0.8529)] 
2024-12-07 17:29:19.553007: Epoch time: 9.03 s 
2024-12-07 17:29:20.215471:  
2024-12-07 17:29:20.221039: Epoch 83 
2024-12-07 17:29:20.223577: Current learning rate: 0.00203 
2024-12-07 17:29:29.195266: train_loss -0.9789 
2024-12-07 17:29:29.201364: val_loss -0.7336 
2024-12-07 17:29:29.206448: Pseudo dice [np.float32(0.8687), np.float32(0.8526)] 
2024-12-07 17:29:29.212190: Epoch time: 8.98 s 
2024-12-07 17:29:29.870702:  
2024-12-07 17:29:29.876793: Epoch 84 
2024-12-07 17:29:29.880356: Current learning rate: 0.00192 
2024-12-07 17:29:38.797530: train_loss -0.9789 
2024-12-07 17:29:38.806244: val_loss -0.7344 
2024-12-07 17:29:38.812856: Pseudo dice [np.float32(0.8696), np.float32(0.8523)] 
2024-12-07 17:29:38.816411: Epoch time: 8.93 s 
2024-12-07 17:29:39.625390:  
2024-12-07 17:29:39.630444: Epoch 85 
2024-12-07 17:29:39.634494: Current learning rate: 0.00181 
2024-12-07 17:29:48.634776: train_loss -0.9789 
2024-12-07 17:29:48.640391: val_loss -0.7329 
2024-12-07 17:29:48.645495: Pseudo dice [np.float32(0.8682), np.float32(0.8518)] 
2024-12-07 17:29:48.653152: Epoch time: 9.01 s 
2024-12-07 17:29:49.312553:  
2024-12-07 17:29:49.317609: Epoch 86 
2024-12-07 17:29:49.320143: Current learning rate: 0.0017 
2024-12-07 17:29:58.282562: train_loss -0.9792 
2024-12-07 17:29:58.289645: val_loss -0.7331 
2024-12-07 17:29:58.294775: Pseudo dice [np.float32(0.8689), np.float32(0.8506)] 
2024-12-07 17:29:58.299859: Epoch time: 8.97 s 
2024-12-07 17:29:58.915855:  
2024-12-07 17:29:58.922457: Epoch 87 
2024-12-07 17:29:58.924988: Current learning rate: 0.00159 
2024-12-07 17:30:07.863530: train_loss -0.9792 
2024-12-07 17:30:07.870337: val_loss -0.7364 
2024-12-07 17:30:07.875520: Pseudo dice [np.float32(0.8698), np.float32(0.8518)] 
2024-12-07 17:30:07.880610: Epoch time: 8.95 s 
2024-12-07 17:30:08.523758:  
2024-12-07 17:30:08.530861: Epoch 88 
2024-12-07 17:30:08.533917: Current learning rate: 0.00148 
2024-12-07 17:30:17.482989: train_loss -0.9794 
2024-12-07 17:30:17.488149: val_loss -0.7345 
2024-12-07 17:30:17.493345: Pseudo dice [np.float32(0.8707), np.float32(0.8516)] 
2024-12-07 17:30:17.498678: Epoch time: 8.96 s 
2024-12-07 17:30:18.159769:  
2024-12-07 17:30:18.164839: Epoch 89 
2024-12-07 17:30:18.168378: Current learning rate: 0.00137 
2024-12-07 17:30:27.064548: train_loss -0.9796 
2024-12-07 17:30:27.070675: val_loss -0.7353 
2024-12-07 17:30:27.077302: Pseudo dice [np.float32(0.8705), np.float32(0.852)] 
2024-12-07 17:30:27.081970: Epoch time: 8.9 s 
2024-12-07 17:30:27.725640:  
2024-12-07 17:30:27.732240: Epoch 90 
2024-12-07 17:30:27.735788: Current learning rate: 0.00126 
2024-12-07 17:30:36.670799: train_loss -0.9797 
2024-12-07 17:30:36.677411: val_loss -0.7335 
2024-12-07 17:30:36.682485: Pseudo dice [np.float32(0.8695), np.float32(0.851)] 
2024-12-07 17:30:36.688600: Epoch time: 8.95 s 
2024-12-07 17:30:37.321817:  
2024-12-07 17:30:37.327389: Epoch 91 
2024-12-07 17:30:37.329948: Current learning rate: 0.00115 
2024-12-07 17:30:46.234731: train_loss -0.9799 
2024-12-07 17:30:46.242370: val_loss -0.7356 
2024-12-07 17:30:46.248965: Pseudo dice [np.float32(0.869), np.float32(0.8531)] 
2024-12-07 17:30:46.252516: Epoch time: 8.91 s 
2024-12-07 17:30:46.892428:  
2024-12-07 17:30:46.897499: Epoch 92 
2024-12-07 17:30:46.902059: Current learning rate: 0.00103 
2024-12-07 17:30:55.838044: train_loss -0.9799 
2024-12-07 17:30:55.844668: val_loss -0.7343 
2024-12-07 17:30:55.849763: Pseudo dice [np.float32(0.8706), np.float32(0.8511)] 
2024-12-07 17:30:55.854846: Epoch time: 8.95 s 
2024-12-07 17:30:56.653789:  
2024-12-07 17:30:56.658857: Epoch 93 
2024-12-07 17:30:56.662406: Current learning rate: 0.00091 
2024-12-07 17:31:05.606360: train_loss -0.9799 
2024-12-07 17:31:05.611949: val_loss -0.7371 
2024-12-07 17:31:05.617025: Pseudo dice [np.float32(0.8705), np.float32(0.8536)] 
2024-12-07 17:31:05.622102: Epoch time: 8.95 s 
2024-12-07 17:31:06.247455:  
2024-12-07 17:31:06.252504: Epoch 94 
2024-12-07 17:31:06.257561: Current learning rate: 0.00079 
2024-12-07 17:31:15.233178: train_loss -0.9801 
2024-12-07 17:31:15.238825: val_loss -0.7356 
2024-12-07 17:31:15.243402: Pseudo dice [np.float32(0.8702), np.float32(0.8514)] 
2024-12-07 17:31:15.248481: Epoch time: 8.99 s 
2024-12-07 17:31:15.910224:  
2024-12-07 17:31:15.915793: Epoch 95 
2024-12-07 17:31:15.919355: Current learning rate: 0.00067 
2024-12-07 17:31:24.840320: train_loss -0.9803 
2024-12-07 17:31:24.846977: val_loss -0.7338 
2024-12-07 17:31:24.852122: Pseudo dice [np.float32(0.869), np.float32(0.851)] 
2024-12-07 17:31:24.857213: Epoch time: 8.93 s 
2024-12-07 17:31:25.501884:  
2024-12-07 17:31:25.507945: Epoch 96 
2024-12-07 17:31:25.512017: Current learning rate: 0.00055 
2024-12-07 17:31:34.452896: train_loss -0.9804 
2024-12-07 17:31:34.459542: val_loss -0.7311 
2024-12-07 17:31:34.464222: Pseudo dice [np.float32(0.8677), np.float32(0.8503)] 
2024-12-07 17:31:34.468286: Epoch time: 8.95 s 
2024-12-07 17:31:35.132036:  
2024-12-07 17:31:35.137132: Epoch 97 
2024-12-07 17:31:35.140716: Current learning rate: 0.00043 
2024-12-07 17:31:44.052556: train_loss -0.9803 
2024-12-07 17:31:44.058684: val_loss -0.732 
2024-12-07 17:31:44.063766: Pseudo dice [np.float32(0.8671), np.float32(0.8512)] 
2024-12-07 17:31:44.067326: Epoch time: 8.92 s 
2024-12-07 17:31:44.719575:  
2024-12-07 17:31:44.725642: Epoch 98 
2024-12-07 17:31:44.728698: Current learning rate: 0.0003 
2024-12-07 17:31:53.649522: train_loss -0.9804 
2024-12-07 17:31:53.657178: val_loss -0.7347 
2024-12-07 17:31:53.661736: Pseudo dice [np.float32(0.8697), np.float32(0.8509)] 
2024-12-07 17:31:53.666849: Epoch time: 8.93 s 
2024-12-07 17:31:54.342269:  
2024-12-07 17:31:54.347886: Epoch 99 
2024-12-07 17:31:54.350949: Current learning rate: 0.00016 
2024-12-07 17:32:03.314986: train_loss -0.9804 
2024-12-07 17:32:03.321619: val_loss -0.7347 
2024-12-07 17:32:03.327273: Pseudo dice [np.float32(0.8705), np.float32(0.8517)] 
2024-12-07 17:32:03.332395: Epoch time: 8.97 s 
2024-12-07 17:32:04.003981: Training done. 
2024-12-07 17:32:04.035865: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-07 17:32:04.051526: The split file contains 5 splits. 
2024-12-07 17:32:04.055640: Desired fold for training: 0 
2024-12-07 17:32:04.055640: This split has 208 training and 52 validation cases. 
2024-12-07 17:32:04.067174: predicting hippocampus_017 
2024-12-07 17:32:04.072398: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-07 17:32:04.208748: predicting hippocampus_019 
2024-12-07 17:32:04.224381: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-07 17:32:04.316952: predicting hippocampus_033 
2024-12-07 17:32:04.318698: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-07 17:32:04.397017: predicting hippocampus_035 
2024-12-07 17:32:04.412679: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-07 17:32:04.490930: predicting hippocampus_037 
2024-12-07 17:32:04.490930: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-07 17:32:04.569187: predicting hippocampus_049 
2024-12-07 17:32:04.569187: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-07 17:32:04.647675: predicting hippocampus_052 
2024-12-07 17:32:04.663665: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-07 17:32:04.726635: predicting hippocampus_065 
2024-12-07 17:32:04.742663: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-07 17:32:04.805471: predicting hippocampus_083 
2024-12-07 17:32:04.805471: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-07 17:32:04.883912: predicting hippocampus_088 
2024-12-07 17:32:04.898405: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-07 17:32:07.876536: predicting hippocampus_090 
2024-12-07 17:32:07.888565: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-07 17:32:08.014873: predicting hippocampus_092 
2024-12-07 17:32:08.026632: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-07 17:32:08.111506: predicting hippocampus_095 
2024-12-07 17:32:08.129027: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-07 17:32:08.232613: predicting hippocampus_107 
2024-12-07 17:32:08.241875: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-07 17:32:08.336169: predicting hippocampus_108 
2024-12-07 17:32:08.344183: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-07 17:32:08.446760: predicting hippocampus_123 
2024-12-07 17:32:08.452772: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-07 17:32:08.539266: predicting hippocampus_125 
2024-12-07 17:32:08.552096: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-07 17:32:08.696375: predicting hippocampus_157 
2024-12-07 17:32:08.702045: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-07 17:32:08.759333: predicting hippocampus_164 
2024-12-07 17:32:08.779087: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-07 17:32:08.934148: predicting hippocampus_169 
2024-12-07 17:32:08.940156: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-07 17:32:09.010709: predicting hippocampus_175 
2024-12-07 17:32:09.010709: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-07 17:32:09.086908: predicting hippocampus_185 
2024-12-07 17:32:09.092919: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-07 17:32:09.159971: predicting hippocampus_190 
2024-12-07 17:32:09.165978: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-07 17:32:09.230968: predicting hippocampus_194 
2024-12-07 17:32:09.243992: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-07 17:32:09.308172: predicting hippocampus_204 
2024-12-07 17:32:09.313921: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-07 17:32:09.388505: predicting hippocampus_205 
2024-12-07 17:32:09.399924: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-07 17:32:09.463236: predicting hippocampus_210 
2024-12-07 17:32:09.471404: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-07 17:32:09.551613: predicting hippocampus_217 
2024-12-07 17:32:09.557620: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-07 17:32:09.615084: predicting hippocampus_219 
2024-12-07 17:32:09.620836: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-07 17:32:09.687752: predicting hippocampus_229 
2024-12-07 17:32:09.699767: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-07 17:32:09.770489: predicting hippocampus_244 
2024-12-07 17:32:09.776237: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-07 17:32:09.829403: predicting hippocampus_261 
2024-12-07 17:32:09.845414: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-07 17:32:09.965163: predicting hippocampus_264 
2024-12-07 17:32:09.971259: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-07 17:32:10.034196: predicting hippocampus_277 
2024-12-07 17:32:10.046026: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-07 17:32:10.144300: predicting hippocampus_280 
2024-12-07 17:32:10.160279: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-07 17:32:10.223115: predicting hippocampus_286 
2024-12-07 17:32:10.233483: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-07 17:32:10.317537: predicting hippocampus_288 
2024-12-07 17:32:10.323014: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-07 17:32:10.395978: predicting hippocampus_289 
2024-12-07 17:32:10.406506: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-07 17:32:10.482039: predicting hippocampus_296 
2024-12-07 17:32:10.489636: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-07 17:32:10.560692: predicting hippocampus_305 
2024-12-07 17:32:10.566705: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-07 17:32:10.631307: predicting hippocampus_308 
2024-12-07 17:32:10.640377: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-07 17:32:10.724545: predicting hippocampus_317 
2024-12-07 17:32:10.730291: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-07 17:32:10.802280: predicting hippocampus_327 
2024-12-07 17:32:10.807286: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-07 17:32:10.872301: predicting hippocampus_330 
2024-12-07 17:32:10.878310: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-07 17:32:10.950593: predicting hippocampus_332 
2024-12-07 17:32:10.954598: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-07 17:32:11.025037: predicting hippocampus_338 
2024-12-07 17:32:11.032260: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-07 17:32:11.123075: predicting hippocampus_349 
2024-12-07 17:32:11.131086: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-07 17:32:11.206113: predicting hippocampus_350 
2024-12-07 17:32:11.210117: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-07 17:32:11.287270: predicting hippocampus_356 
2024-12-07 17:32:11.295021: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-07 17:32:11.395759: predicting hippocampus_358 
2024-12-07 17:32:11.401741: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-07 17:32:11.474529: predicting hippocampus_374 
2024-12-07 17:32:11.480279: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-07 17:32:11.565092: predicting hippocampus_394 
2024-12-07 17:32:11.571099: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-07 17:32:15.062019: Validation complete 
2024-12-07 17:32:15.062019: Mean Validation Dice:  0.855448698853323 
