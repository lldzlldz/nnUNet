
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-24 06:37:48.163656: do_dummy_2d_data_aug: False 
2025-02-24 06:37:48.183637: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2025-02-24 06:37:48.192637: The split file contains 5 splits. 
2025-02-24 06:37:48.195637: Desired fold for training: 0 
2025-02-24 06:37:48.198637: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2025-02-24 06:37:54.482127: unpacking dataset... 
2025-02-24 06:37:55.295370: unpacking done... 
2025-02-24 06:37:57.392837:  
2025-02-24 06:37:57.397846: Epoch 0 
2025-02-24 06:37:57.401857: Current learning rate: 0.01 
2025-02-24 06:38:04.759405: train_loss -0.5901 
2025-02-24 06:38:04.765634: val_loss -0.8195 
2025-02-24 06:38:04.769184: Pseudo dice [np.float32(0.8726), np.float32(0.8591)] 
2025-02-24 06:38:04.772232: Epoch time: 7.37 s 
2025-02-24 06:38:04.776435: Yayy! New best EMA pseudo Dice: 0.8658000230789185 
2025-02-24 06:38:05.241681:  
2025-02-24 06:38:05.246699: Epoch 1 
2025-02-24 06:38:05.250207: Current learning rate: 0.00996 
2025-02-24 06:38:11.773124: train_loss -0.8285 
2025-02-24 06:38:11.778217: val_loss -0.8374 
2025-02-24 06:38:11.781769: Pseudo dice [np.float32(0.8866), np.float32(0.8715)] 
2025-02-24 06:38:11.784292: Epoch time: 6.53 s 
2025-02-24 06:38:11.790361: Yayy! New best EMA pseudo Dice: 0.8672000169754028 
2025-02-24 06:38:12.313780:  
2025-02-24 06:38:12.318791: Epoch 2 
2025-02-24 06:38:12.322301: Current learning rate: 0.00993 
2025-02-24 06:38:18.886692: train_loss -0.8468 
2025-02-24 06:38:18.892324: val_loss -0.8415 
2025-02-24 06:38:18.896846: Pseudo dice [np.float32(0.8901), np.float32(0.8736)] 
2025-02-24 06:38:18.900433: Epoch time: 6.57 s 
2025-02-24 06:38:18.903472: Yayy! New best EMA pseudo Dice: 0.8686000108718872 
2025-02-24 06:38:19.449690:  
2025-02-24 06:38:19.455775: Epoch 3 
2025-02-24 06:38:19.460055: Current learning rate: 0.00989 
2025-02-24 06:38:25.992170: train_loss -0.8562 
2025-02-24 06:38:25.998869: val_loss -0.8431 
2025-02-24 06:38:26.002400: Pseudo dice [np.float32(0.8927), np.float32(0.8759)] 
2025-02-24 06:38:26.005478: Epoch time: 6.54 s 
2025-02-24 06:38:26.009077: Yayy! New best EMA pseudo Dice: 0.870199978351593 
2025-02-24 06:38:26.538284:  
2025-02-24 06:38:26.544336: Epoch 4 
2025-02-24 06:38:26.547391: Current learning rate: 0.00986 
2025-02-24 06:38:33.040276: train_loss -0.8656 
2025-02-24 06:38:33.046037: val_loss -0.842 
2025-02-24 06:38:33.049625: Pseudo dice [np.float32(0.8919), np.float32(0.8756)] 
2025-02-24 06:38:33.052655: Epoch time: 6.5 s 
2025-02-24 06:38:33.055809: Yayy! New best EMA pseudo Dice: 0.8715000152587891 
2025-02-24 06:38:33.713098:  
2025-02-24 06:38:33.719126: Epoch 5 
2025-02-24 06:38:33.721640: Current learning rate: 0.00982 
2025-02-24 06:38:40.239704: train_loss -0.8725 
2025-02-24 06:38:40.245835: val_loss -0.8492 
2025-02-24 06:38:40.249455: Pseudo dice [np.float32(0.898), np.float32(0.8798)] 
2025-02-24 06:38:40.252504: Epoch time: 6.53 s 
2025-02-24 06:38:40.255030: Yayy! New best EMA pseudo Dice: 0.8733000159263611 
2025-02-24 06:38:40.772532:  
2025-02-24 06:38:40.778576: Epoch 6 
2025-02-24 06:38:40.781649: Current learning rate: 0.00978 
2025-02-24 06:38:47.275087: train_loss -0.8758 
2025-02-24 06:38:47.280178: val_loss -0.8467 
2025-02-24 06:38:47.283218: Pseudo dice [np.float32(0.8966), np.float32(0.8773)] 
2025-02-24 06:38:47.287760: Epoch time: 6.5 s 
2025-02-24 06:38:47.291816: Yayy! New best EMA pseudo Dice: 0.8745999932289124 
2025-02-24 06:38:47.816534:  
2025-02-24 06:38:47.822152: Epoch 7 
2025-02-24 06:38:47.824692: Current learning rate: 0.00975 
2025-02-24 06:38:54.324707: train_loss -0.8812 
2025-02-24 06:38:54.330800: val_loss -0.8486 
2025-02-24 06:38:54.333862: Pseudo dice [np.float32(0.8985), np.float32(0.8782)] 
2025-02-24 06:38:54.337393: Epoch time: 6.51 s 
2025-02-24 06:38:54.340576: Yayy! New best EMA pseudo Dice: 0.8759999871253967 
2025-02-24 06:38:54.871420:  
2025-02-24 06:38:54.876939: Epoch 8 
2025-02-24 06:38:54.880451: Current learning rate: 0.00971 
2025-02-24 06:39:01.393056: train_loss -0.8833 
2025-02-24 06:39:01.398836: val_loss -0.845 
2025-02-24 06:39:01.402887: Pseudo dice [np.float32(0.8959), np.float32(0.8758)] 
2025-02-24 06:39:01.405973: Epoch time: 6.52 s 
2025-02-24 06:39:01.409578: Yayy! New best EMA pseudo Dice: 0.8769999742507935 
2025-02-24 06:39:01.946669:  
2025-02-24 06:39:01.952709: Epoch 9 
2025-02-24 06:39:01.956298: Current learning rate: 0.00968 
2025-02-24 06:39:08.472414: train_loss -0.8892 
2025-02-24 06:39:08.477974: val_loss -0.8453 
2025-02-24 06:39:08.481510: Pseudo dice [np.float32(0.8962), np.float32(0.8781)] 
2025-02-24 06:39:08.484530: Epoch time: 6.53 s 
2025-02-24 06:39:08.488096: Yayy! New best EMA pseudo Dice: 0.878000020980835 
2025-02-24 06:39:08.998897:  
2025-02-24 06:39:09.004965: Epoch 10 
2025-02-24 06:39:09.008020: Current learning rate: 0.00964 
2025-02-24 06:39:15.486825: train_loss -0.8927 
2025-02-24 06:39:15.493359: val_loss -0.8503 
2025-02-24 06:39:15.496873: Pseudo dice [np.float32(0.9001), np.float32(0.8788)] 
2025-02-24 06:39:15.501427: Epoch time: 6.49 s 
2025-02-24 06:39:15.504953: Yayy! New best EMA pseudo Dice: 0.8791999816894531 
2025-02-24 06:39:16.026531:  
2025-02-24 06:39:16.032696: Epoch 11 
2025-02-24 06:39:16.035736: Current learning rate: 0.0096 
2025-02-24 06:39:22.527199: train_loss -0.8942 
2025-02-24 06:39:22.533321: val_loss -0.8447 
2025-02-24 06:39:22.536913: Pseudo dice [np.float32(0.8974), np.float32(0.8764)] 
2025-02-24 06:39:22.539962: Epoch time: 6.5 s 
2025-02-24 06:39:22.543503: Yayy! New best EMA pseudo Dice: 0.8798999786376953 
2025-02-24 06:39:23.199266:  
2025-02-24 06:39:23.204836: Epoch 12 
2025-02-24 06:39:23.208404: Current learning rate: 0.00957 
2025-02-24 06:39:29.709268: train_loss -0.8962 
2025-02-24 06:39:29.715353: val_loss -0.8443 
2025-02-24 06:39:29.718973: Pseudo dice [np.float32(0.8971), np.float32(0.8746)] 
2025-02-24 06:39:29.721550: Epoch time: 6.51 s 
2025-02-24 06:39:29.725605: Yayy! New best EMA pseudo Dice: 0.8805000185966492 
2025-02-24 06:39:30.251954:  
2025-02-24 06:39:30.257500: Epoch 13 
2025-02-24 06:39:30.260607: Current learning rate: 0.00953 
2025-02-24 06:39:36.755091: train_loss -0.897 
2025-02-24 06:39:36.761562: val_loss -0.8407 
2025-02-24 06:39:36.765089: Pseudo dice [np.float32(0.8952), np.float32(0.8741)] 
2025-02-24 06:39:36.767658: Epoch time: 6.5 s 
2025-02-24 06:39:36.771733: Yayy! New best EMA pseudo Dice: 0.8809000253677368 
2025-02-24 06:39:37.300749:  
2025-02-24 06:39:37.306372: Epoch 14 
2025-02-24 06:39:37.310932: Current learning rate: 0.00949 
2025-02-24 06:39:43.802644: train_loss -0.9018 
2025-02-24 06:39:43.807801: val_loss -0.8432 
2025-02-24 06:39:43.811342: Pseudo dice [np.float32(0.8971), np.float32(0.8755)] 
2025-02-24 06:39:43.814964: Epoch time: 6.5 s 
2025-02-24 06:39:43.817473: Yayy! New best EMA pseudo Dice: 0.8815000057220459 
2025-02-24 06:39:44.349301:  
2025-02-24 06:39:44.354874: Epoch 15 
2025-02-24 06:39:44.358392: Current learning rate: 0.00946 
2025-02-24 06:39:50.858435: train_loss -0.9033 
2025-02-24 06:39:50.865491: val_loss -0.8422 
2025-02-24 06:39:50.870697: Pseudo dice [np.float32(0.897), np.float32(0.8754)] 
2025-02-24 06:39:50.873348: Epoch time: 6.51 s 
2025-02-24 06:39:50.877406: Yayy! New best EMA pseudo Dice: 0.8819000124931335 
2025-02-24 06:39:51.410813:  
2025-02-24 06:39:51.416825: Epoch 16 
2025-02-24 06:39:51.420835: Current learning rate: 0.00942 
2025-02-24 06:39:57.913993: train_loss -0.9035 
2025-02-24 06:39:57.919558: val_loss -0.8441 
2025-02-24 06:39:57.922584: Pseudo dice [np.float32(0.8988), np.float32(0.8759)] 
2025-02-24 06:39:57.926204: Epoch time: 6.5 s 
2025-02-24 06:39:57.929948: Yayy! New best EMA pseudo Dice: 0.8824999928474426 
2025-02-24 06:39:58.470555:  
2025-02-24 06:39:58.477088: Epoch 17 
2025-02-24 06:39:58.480113: Current learning rate: 0.00939 
2025-02-24 06:40:04.951501: train_loss -0.9062 
2025-02-24 06:40:04.957669: val_loss -0.8424 
2025-02-24 06:40:04.961217: Pseudo dice [np.float32(0.8966), np.float32(0.8764)] 
2025-02-24 06:40:04.964271: Epoch time: 6.48 s 
2025-02-24 06:40:04.967351: Yayy! New best EMA pseudo Dice: 0.8828999996185303 
2025-02-24 06:40:05.498974:  
2025-02-24 06:40:05.505101: Epoch 18 
2025-02-24 06:40:05.508173: Current learning rate: 0.00935 
2025-02-24 06:40:12.004072: train_loss -0.9075 
2025-02-24 06:40:12.009678: val_loss -0.8405 
2025-02-24 06:40:12.013325: Pseudo dice [np.float32(0.8963), np.float32(0.8754)] 
2025-02-24 06:40:12.016847: Epoch time: 6.51 s 
2025-02-24 06:40:12.020407: Yayy! New best EMA pseudo Dice: 0.8831999897956848 
2025-02-24 06:40:12.554013:  
2025-02-24 06:40:12.560091: Epoch 19 
2025-02-24 06:40:12.563611: Current learning rate: 0.00931 
2025-02-24 06:40:19.094574: train_loss -0.9096 
2025-02-24 06:40:19.099755: val_loss -0.8475 
2025-02-24 06:40:19.105351: Pseudo dice [np.float32(0.9007), np.float32(0.8808)] 
2025-02-24 06:40:19.108912: Epoch time: 6.54 s 
2025-02-24 06:40:19.111526: Yayy! New best EMA pseudo Dice: 0.883899986743927 
2025-02-24 06:40:19.803774:  
2025-02-24 06:40:19.808882: Epoch 20 
2025-02-24 06:40:19.811405: Current learning rate: 0.00928 
2025-02-24 06:40:26.320333: train_loss -0.9099 
2025-02-24 06:40:26.326892: val_loss -0.8445 
2025-02-24 06:40:26.330470: Pseudo dice [np.float32(0.8984), np.float32(0.8779)] 
2025-02-24 06:40:26.333514: Epoch time: 6.52 s 
2025-02-24 06:40:26.337226: Yayy! New best EMA pseudo Dice: 0.8844000101089478 
2025-02-24 06:40:26.877559:  
2025-02-24 06:40:26.883115: Epoch 21 
2025-02-24 06:40:26.886143: Current learning rate: 0.00924 
2025-02-24 06:40:33.370788: train_loss -0.9114 
2025-02-24 06:40:33.376803: val_loss -0.8407 
2025-02-24 06:40:33.380815: Pseudo dice [np.float32(0.8964), np.float32(0.8768)] 
2025-02-24 06:40:33.384337: Epoch time: 6.49 s 
2025-02-24 06:40:33.388129: Yayy! New best EMA pseudo Dice: 0.8845999836921692 
2025-02-24 06:40:33.909281:  
2025-02-24 06:40:33.914797: Epoch 22 
2025-02-24 06:40:33.918313: Current learning rate: 0.0092 
2025-02-24 06:40:40.393750: train_loss -0.9125 
2025-02-24 06:40:40.399893: val_loss -0.8402 
2025-02-24 06:40:40.404029: Pseudo dice [np.float32(0.8961), np.float32(0.8765)] 
2025-02-24 06:40:40.407635: Epoch time: 6.49 s 
2025-02-24 06:40:40.411236: Yayy! New best EMA pseudo Dice: 0.8847000002861023 
2025-02-24 06:40:40.929690:  
2025-02-24 06:40:40.935762: Epoch 23 
2025-02-24 06:40:40.939369: Current learning rate: 0.00917 
2025-02-24 06:40:47.421707: train_loss -0.9141 
2025-02-24 06:40:47.428275: val_loss -0.8398 
2025-02-24 06:40:47.431842: Pseudo dice [np.float32(0.897), np.float32(0.8759)] 
2025-02-24 06:40:47.435374: Epoch time: 6.49 s 
2025-02-24 06:40:47.438958: Yayy! New best EMA pseudo Dice: 0.8848999738693237 
2025-02-24 06:40:47.952747:  
2025-02-24 06:40:47.958263: Epoch 24 
2025-02-24 06:40:47.961781: Current learning rate: 0.00913 
2025-02-24 06:40:54.444671: train_loss -0.9146 
2025-02-24 06:40:54.451194: val_loss -0.8415 
2025-02-24 06:40:54.457710: Pseudo dice [np.float32(0.8981), np.float32(0.8778)] 
2025-02-24 06:40:54.462220: Epoch time: 6.49 s 
2025-02-24 06:40:54.466239: Yayy! New best EMA pseudo Dice: 0.885200023651123 
2025-02-24 06:40:54.988534:  
2025-02-24 06:40:54.993575: Epoch 25 
2025-02-24 06:40:54.997108: Current learning rate: 0.0091 
2025-02-24 06:41:01.490728: train_loss -0.9178 
2025-02-24 06:41:01.496796: val_loss -0.8379 
2025-02-24 06:41:01.500839: Pseudo dice [np.float32(0.8966), np.float32(0.875)] 
2025-02-24 06:41:01.504364: Epoch time: 6.5 s 
2025-02-24 06:41:01.507986: Yayy! New best EMA pseudo Dice: 0.8852999806404114 
2025-02-24 06:41:02.026747:  
2025-02-24 06:41:02.032787: Epoch 26 
2025-02-24 06:41:02.035824: Current learning rate: 0.00906 
2025-02-24 06:41:08.537600: train_loss -0.9185 
2025-02-24 06:41:08.543728: val_loss -0.8331 
2025-02-24 06:41:08.547821: Pseudo dice [np.float32(0.8926), np.float32(0.8717)] 
2025-02-24 06:41:08.550884: Epoch time: 6.51 s 
2025-02-24 06:41:09.037048:  
2025-02-24 06:41:09.042582: Epoch 27 
2025-02-24 06:41:09.046186: Current learning rate: 0.00902 
2025-02-24 06:41:15.525016: train_loss -0.9187 
2025-02-24 06:41:15.531081: val_loss -0.8421 
2025-02-24 06:41:15.534719: Pseudo dice [np.float32(0.8994), np.float32(0.8785)] 
2025-02-24 06:41:15.538768: Epoch time: 6.49 s 
2025-02-24 06:41:15.542429: Yayy! New best EMA pseudo Dice: 0.8853999972343445 
2025-02-24 06:41:16.217708:  
2025-02-24 06:41:16.221723: Epoch 28 
2025-02-24 06:41:16.225743: Current learning rate: 0.00899 
2025-02-24 06:41:22.708815: train_loss -0.9187 
2025-02-24 06:41:22.715420: val_loss -0.8415 
2025-02-24 06:41:22.719512: Pseudo dice [np.float32(0.8985), np.float32(0.8794)] 
2025-02-24 06:41:22.722545: Epoch time: 6.49 s 
2025-02-24 06:41:22.726136: Yayy! New best EMA pseudo Dice: 0.885699987411499 
2025-02-24 06:41:23.246237:  
2025-02-24 06:41:23.252303: Epoch 29 
2025-02-24 06:41:23.256390: Current learning rate: 0.00895 
2025-02-24 06:41:29.731519: train_loss -0.9192 
2025-02-24 06:41:29.737627: val_loss -0.8384 
2025-02-24 06:41:29.741187: Pseudo dice [np.float32(0.8971), np.float32(0.8759)] 
2025-02-24 06:41:29.744733: Epoch time: 6.49 s 
2025-02-24 06:41:29.747768: Yayy! New best EMA pseudo Dice: 0.8858000040054321 
2025-02-24 06:41:30.279070:  
2025-02-24 06:41:30.285136: Epoch 30 
2025-02-24 06:41:30.288200: Current learning rate: 0.00891 
2025-02-24 06:41:36.780862: train_loss -0.9192 
2025-02-24 06:41:36.787045: val_loss -0.8434 
2025-02-24 06:41:36.791178: Pseudo dice [np.float32(0.8998), np.float32(0.88)] 
2025-02-24 06:41:36.794704: Epoch time: 6.5 s 
2025-02-24 06:41:36.798271: Yayy! New best EMA pseudo Dice: 0.8862000107765198 
2025-02-24 06:41:37.325396:  
2025-02-24 06:41:37.330372: Epoch 31 
2025-02-24 06:41:37.333851: Current learning rate: 0.00888 
2025-02-24 06:41:43.819283: train_loss -0.9222 
2025-02-24 06:41:43.825428: val_loss -0.8388 
2025-02-24 06:41:43.829533: Pseudo dice [np.float32(0.8978), np.float32(0.8783)] 
2025-02-24 06:41:43.833552: Epoch time: 6.49 s 
2025-02-24 06:41:43.837067: Yayy! New best EMA pseudo Dice: 0.8863999843597412 
2025-02-24 06:41:44.366199:  
2025-02-24 06:41:44.372319: Epoch 32 
2025-02-24 06:41:44.375823: Current learning rate: 0.00884 
2025-02-24 06:41:50.857846: train_loss -0.9233 
2025-02-24 06:41:50.863445: val_loss -0.8351 
2025-02-24 06:41:50.866982: Pseudo dice [np.float32(0.8943), np.float32(0.8745)] 
2025-02-24 06:41:50.870647: Epoch time: 6.49 s 
2025-02-24 06:41:51.367869:  
2025-02-24 06:41:51.374461: Epoch 33 
2025-02-24 06:41:51.378009: Current learning rate: 0.0088 
2025-02-24 06:41:57.871310: train_loss -0.9235 
2025-02-24 06:41:57.877350: val_loss -0.8399 
2025-02-24 06:41:57.881063: Pseudo dice [np.float32(0.8974), np.float32(0.879)] 
2025-02-24 06:41:57.884093: Epoch time: 6.5 s 
2025-02-24 06:41:58.380984:  
2025-02-24 06:41:58.385996: Epoch 34 
2025-02-24 06:41:58.389512: Current learning rate: 0.00877 
2025-02-24 06:42:04.870733: train_loss -0.9241 
2025-02-24 06:42:04.876367: val_loss -0.8378 
2025-02-24 06:42:04.879891: Pseudo dice [np.float32(0.8966), np.float32(0.8784)] 
2025-02-24 06:42:04.882909: Epoch time: 6.49 s 
2025-02-24 06:42:04.886498: Yayy! New best EMA pseudo Dice: 0.8865000009536743 
2025-02-24 06:42:05.639473:  
2025-02-24 06:42:05.645511: Epoch 35 
2025-02-24 06:42:05.647909: Current learning rate: 0.00873 
2025-02-24 06:42:12.127045: train_loss -0.9247 
2025-02-24 06:42:12.132732: val_loss -0.8411 
2025-02-24 06:42:12.136302: Pseudo dice [np.float32(0.8986), np.float32(0.8787)] 
2025-02-24 06:42:12.138845: Epoch time: 6.49 s 
2025-02-24 06:42:12.142905: Yayy! New best EMA pseudo Dice: 0.8866999745368958 
2025-02-24 06:42:12.824891:  
2025-02-24 06:42:12.830405: Epoch 36 
2025-02-24 06:42:12.833914: Current learning rate: 0.00869 
2025-02-24 06:42:19.325175: train_loss -0.9261 
2025-02-24 06:42:19.330746: val_loss -0.839 
2025-02-24 06:42:19.334814: Pseudo dice [np.float32(0.8971), np.float32(0.8783)] 
2025-02-24 06:42:19.338390: Epoch time: 6.5 s 
2025-02-24 06:42:19.342053: Yayy! New best EMA pseudo Dice: 0.8867999911308289 
2025-02-24 06:42:19.885214:  
2025-02-24 06:42:19.891735: Epoch 37 
2025-02-24 06:42:19.895250: Current learning rate: 0.00866 
2025-02-24 06:42:26.398839: train_loss -0.9241 
2025-02-24 06:42:26.404448: val_loss -0.8361 
2025-02-24 06:42:26.407995: Pseudo dice [np.float32(0.8977), np.float32(0.8765)] 
2025-02-24 06:42:26.411085: Epoch time: 6.51 s 
2025-02-24 06:42:26.414768: Yayy! New best EMA pseudo Dice: 0.8867999911308289 
2025-02-24 06:42:26.966945:  
2025-02-24 06:42:26.973012: Epoch 38 
2025-02-24 06:42:26.976156: Current learning rate: 0.00862 
2025-02-24 06:42:33.443177: train_loss -0.9261 
2025-02-24 06:42:33.448902: val_loss -0.8346 
2025-02-24 06:42:33.451955: Pseudo dice [np.float32(0.8966), np.float32(0.8761)] 
2025-02-24 06:42:33.455494: Epoch time: 6.48 s 
2025-02-24 06:42:33.958628:  
2025-02-24 06:42:33.963664: Epoch 39 
2025-02-24 06:42:33.967176: Current learning rate: 0.00858 
2025-02-24 06:42:40.442292: train_loss -0.9277 
2025-02-24 06:42:40.447335: val_loss -0.8337 
2025-02-24 06:42:40.451971: Pseudo dice [np.float32(0.8948), np.float32(0.8764)] 
2025-02-24 06:42:40.455016: Epoch time: 6.48 s 
2025-02-24 06:42:40.968941:  
2025-02-24 06:42:40.973972: Epoch 40 
2025-02-24 06:42:40.978049: Current learning rate: 0.00855 
2025-02-24 06:42:47.468048: train_loss -0.9287 
2025-02-24 06:42:47.474207: val_loss -0.8321 
2025-02-24 06:42:47.477243: Pseudo dice [np.float32(0.8941), np.float32(0.8745)] 
2025-02-24 06:42:47.480295: Epoch time: 6.5 s 
2025-02-24 06:42:47.989335:  
2025-02-24 06:42:47.994861: Epoch 41 
2025-02-24 06:42:47.998381: Current learning rate: 0.00851 
2025-02-24 06:42:54.475843: train_loss -0.9289 
2025-02-24 06:42:54.481412: val_loss -0.8342 
2025-02-24 06:42:54.484459: Pseudo dice [np.float32(0.8958), np.float32(0.8749)] 
2025-02-24 06:42:54.488029: Epoch time: 6.49 s 
2025-02-24 06:42:54.975886:  
2025-02-24 06:42:54.980953: Epoch 42 
2025-02-24 06:42:54.984496: Current learning rate: 0.00847 
2025-02-24 06:43:01.471124: train_loss -0.9293 
2025-02-24 06:43:01.476710: val_loss -0.8326 
2025-02-24 06:43:01.479720: Pseudo dice [np.float32(0.8951), np.float32(0.8755)] 
2025-02-24 06:43:01.482756: Epoch time: 6.5 s 
2025-02-24 06:43:02.120186:  
2025-02-24 06:43:02.124768: Epoch 43 
2025-02-24 06:43:02.128326: Current learning rate: 0.00844 
2025-02-24 06:43:08.619622: train_loss -0.9281 
2025-02-24 06:43:08.625647: val_loss -0.8308 
2025-02-24 06:43:08.629665: Pseudo dice [np.float32(0.8946), np.float32(0.8736)] 
2025-02-24 06:43:08.633178: Epoch time: 6.5 s 
2025-02-24 06:43:09.125327:  
2025-02-24 06:43:09.130396: Epoch 44 
2025-02-24 06:43:09.133443: Current learning rate: 0.0084 
2025-02-24 06:43:15.621362: train_loss -0.9299 
2025-02-24 06:43:15.626492: val_loss -0.8365 
2025-02-24 06:43:15.630499: Pseudo dice [np.float32(0.8969), np.float32(0.8781)] 
2025-02-24 06:43:15.634016: Epoch time: 6.5 s 
2025-02-24 06:43:16.121522:  
2025-02-24 06:43:16.127095: Epoch 45 
2025-02-24 06:43:16.130142: Current learning rate: 0.00836 
2025-02-24 06:43:22.614138: train_loss -0.9308 
2025-02-24 06:43:22.619689: val_loss -0.8359 
2025-02-24 06:43:22.623248: Pseudo dice [np.float32(0.8967), np.float32(0.8767)] 
2025-02-24 06:43:22.625790: Epoch time: 6.49 s 
2025-02-24 06:43:23.123298:  
2025-02-24 06:43:23.128870: Epoch 46 
2025-02-24 06:43:23.131924: Current learning rate: 0.00833 
2025-02-24 06:43:29.604731: train_loss -0.9322 
2025-02-24 06:43:29.610433: val_loss -0.8362 
2025-02-24 06:43:29.614526: Pseudo dice [np.float32(0.8983), np.float32(0.8792)] 
2025-02-24 06:43:29.617594: Epoch time: 6.48 s 
2025-02-24 06:43:30.101896:  
2025-02-24 06:43:30.107414: Epoch 47 
2025-02-24 06:43:30.110931: Current learning rate: 0.00829 
2025-02-24 06:43:36.613715: train_loss -0.9325 
2025-02-24 06:43:36.619355: val_loss -0.8344 
2025-02-24 06:43:36.622890: Pseudo dice [np.float32(0.8953), np.float32(0.8768)] 
2025-02-24 06:43:36.625077: Epoch time: 6.51 s 
2025-02-24 06:43:37.112667:  
2025-02-24 06:43:37.118182: Epoch 48 
2025-02-24 06:43:37.123195: Current learning rate: 0.00825 
2025-02-24 06:43:43.605054: train_loss -0.9341 
2025-02-24 06:43:43.610694: val_loss -0.8296 
2025-02-24 06:43:43.613232: Pseudo dice [np.float32(0.8949), np.float32(0.8748)] 
2025-02-24 06:43:43.617265: Epoch time: 6.49 s 
2025-02-24 06:43:44.110779:  
2025-02-24 06:43:44.117296: Epoch 49 
2025-02-24 06:43:44.119803: Current learning rate: 0.00822 
2025-02-24 06:43:50.608038: train_loss -0.933 
2025-02-24 06:43:50.613649: val_loss -0.8363 
2025-02-24 06:43:50.617182: Pseudo dice [np.float32(0.8984), np.float32(0.8789)] 
2025-02-24 06:43:50.620308: Epoch time: 6.5 s 
2025-02-24 06:43:51.155431:  
2025-02-24 06:43:51.162086: Epoch 50 
2025-02-24 06:43:51.165634: Current learning rate: 0.00818 
2025-02-24 06:43:57.655199: train_loss -0.9337 
2025-02-24 06:43:57.660882: val_loss -0.8375 
2025-02-24 06:43:57.664459: Pseudo dice [np.float32(0.8994), np.float32(0.8801)] 
2025-02-24 06:43:57.667534: Epoch time: 6.5 s 
2025-02-24 06:43:58.304172:  
2025-02-24 06:43:58.309690: Epoch 51 
2025-02-24 06:43:58.312199: Current learning rate: 0.00814 
2025-02-24 06:44:04.810912: train_loss -0.9328 
2025-02-24 06:44:04.816982: val_loss -0.8368 
2025-02-24 06:44:04.820027: Pseudo dice [np.float32(0.8978), np.float32(0.8787)] 
2025-02-24 06:44:04.822614: Epoch time: 6.51 s 
2025-02-24 06:44:04.826127: Yayy! New best EMA pseudo Dice: 0.8870000243186951 
2025-02-24 06:44:05.358541:  
2025-02-24 06:44:05.363550: Epoch 52 
2025-02-24 06:44:05.367061: Current learning rate: 0.00811 
2025-02-24 06:44:11.833138: train_loss -0.933 
2025-02-24 06:44:11.838734: val_loss -0.8332 
2025-02-24 06:44:11.842360: Pseudo dice [np.float32(0.8975), np.float32(0.8765)] 
2025-02-24 06:44:11.845409: Epoch time: 6.48 s 
2025-02-24 06:44:11.849012: Yayy! New best EMA pseudo Dice: 0.8870000243186951 
2025-02-24 06:44:12.384098:  
2025-02-24 06:44:12.389220: Epoch 53 
2025-02-24 06:44:12.393262: Current learning rate: 0.00807 
2025-02-24 06:44:18.873548: train_loss -0.9335 
2025-02-24 06:44:18.879131: val_loss -0.8308 
2025-02-24 06:44:18.882250: Pseudo dice [np.float32(0.8963), np.float32(0.8756)] 
2025-02-24 06:44:18.885292: Epoch time: 6.49 s 
2025-02-24 06:44:19.383086:  
2025-02-24 06:44:19.388644: Epoch 54 
2025-02-24 06:44:19.392263: Current learning rate: 0.00803 
2025-02-24 06:44:25.902184: train_loss -0.9341 
2025-02-24 06:44:25.906802: val_loss -0.8349 
2025-02-24 06:44:25.910869: Pseudo dice [np.float32(0.8959), np.float32(0.878)] 
2025-02-24 06:44:25.914050: Epoch time: 6.52 s 
2025-02-24 06:44:26.407454:  
2025-02-24 06:44:26.413515: Epoch 55 
2025-02-24 06:44:26.416525: Current learning rate: 0.008 
2025-02-24 06:44:32.885928: train_loss -0.9348 
2025-02-24 06:44:32.892030: val_loss -0.8277 
2025-02-24 06:44:32.895088: Pseudo dice [np.float32(0.8922), np.float32(0.8722)] 
2025-02-24 06:44:32.898691: Epoch time: 6.48 s 
2025-02-24 06:44:33.400707:  
2025-02-24 06:44:33.405727: Epoch 56 
2025-02-24 06:44:33.408736: Current learning rate: 0.00796 
2025-02-24 06:44:39.883016: train_loss -0.938 
2025-02-24 06:44:39.888594: val_loss -0.8277 
2025-02-24 06:44:39.892242: Pseudo dice [np.float32(0.8939), np.float32(0.8747)] 
2025-02-24 06:44:39.895297: Epoch time: 6.48 s 
2025-02-24 06:44:40.386664:  
2025-02-24 06:44:40.392241: Epoch 57 
2025-02-24 06:44:40.395810: Current learning rate: 0.00792 
2025-02-24 06:44:46.901206: train_loss -0.9362 
2025-02-24 06:44:46.906871: val_loss -0.8311 
2025-02-24 06:44:46.910434: Pseudo dice [np.float32(0.895), np.float32(0.876)] 
2025-02-24 06:44:46.912997: Epoch time: 6.51 s 
2025-02-24 06:44:47.403678:  
2025-02-24 06:44:47.409229: Epoch 58 
2025-02-24 06:44:47.413294: Current learning rate: 0.00789 
2025-02-24 06:44:53.907721: train_loss -0.9365 
2025-02-24 06:44:53.912843: val_loss -0.8345 
2025-02-24 06:44:53.915978: Pseudo dice [np.float32(0.8981), np.float32(0.878)] 
2025-02-24 06:44:53.920108: Epoch time: 6.5 s 
2025-02-24 06:44:54.560033:  
2025-02-24 06:44:54.565619: Epoch 59 
2025-02-24 06:44:54.570711: Current learning rate: 0.00785 
2025-02-24 06:45:01.051582: train_loss -0.9371 
2025-02-24 06:45:01.057679: val_loss -0.8292 
2025-02-24 06:45:01.061740: Pseudo dice [np.float32(0.8948), np.float32(0.8738)] 
2025-02-24 06:45:01.064280: Epoch time: 6.49 s 
2025-02-24 06:45:01.569058:  
2025-02-24 06:45:01.574069: Epoch 60 
2025-02-24 06:45:01.577578: Current learning rate: 0.00781 
2025-02-24 06:45:08.056473: train_loss -0.9371 
2025-02-24 06:45:08.062146: val_loss -0.8385 
2025-02-24 06:45:08.064657: Pseudo dice [np.float32(0.9008), np.float32(0.8795)] 
2025-02-24 06:45:08.068222: Epoch time: 6.49 s 
2025-02-24 06:45:08.563784:  
2025-02-24 06:45:08.569358: Epoch 61 
2025-02-24 06:45:08.571905: Current learning rate: 0.00777 
2025-02-24 06:45:15.071741: train_loss -0.9367 
2025-02-24 06:45:15.077842: val_loss -0.8298 
2025-02-24 06:45:15.080876: Pseudo dice [np.float32(0.8945), np.float32(0.8749)] 
2025-02-24 06:45:15.084418: Epoch time: 6.51 s 
2025-02-24 06:45:15.581647:  
2025-02-24 06:45:15.586669: Epoch 62 
2025-02-24 06:45:15.590191: Current learning rate: 0.00774 
2025-02-24 06:45:22.075047: train_loss -0.9374 
2025-02-24 06:45:22.081116: val_loss -0.8259 
2025-02-24 06:45:22.083620: Pseudo dice [np.float32(0.8928), np.float32(0.8737)] 
2025-02-24 06:45:22.087632: Epoch time: 6.49 s 
2025-02-24 06:45:22.592421:  
2025-02-24 06:45:22.597441: Epoch 63 
2025-02-24 06:45:22.600955: Current learning rate: 0.0077 
2025-02-24 06:45:29.095468: train_loss -0.9381 
2025-02-24 06:45:29.101108: val_loss -0.8302 
2025-02-24 06:45:29.104835: Pseudo dice [np.float32(0.8953), np.float32(0.8753)] 
2025-02-24 06:45:29.108357: Epoch time: 6.5 s 
2025-02-24 06:45:29.602334:  
2025-02-24 06:45:29.607354: Epoch 64 
2025-02-24 06:45:29.610870: Current learning rate: 0.00766 
2025-02-24 06:45:36.112812: train_loss -0.9387 
2025-02-24 06:45:36.118432: val_loss -0.8373 
2025-02-24 06:45:36.121469: Pseudo dice [np.float32(0.8994), np.float32(0.8812)] 
2025-02-24 06:45:36.124993: Epoch time: 6.51 s 
2025-02-24 06:45:36.624637:  
2025-02-24 06:45:36.629651: Epoch 65 
2025-02-24 06:45:36.633160: Current learning rate: 0.00763 
2025-02-24 06:45:43.116683: train_loss -0.9377 
2025-02-24 06:45:43.122291: val_loss -0.8331 
2025-02-24 06:45:43.125873: Pseudo dice [np.float32(0.8966), np.float32(0.8774)] 
2025-02-24 06:45:43.127984: Epoch time: 6.49 s 
2025-02-24 06:45:43.631411:  
2025-02-24 06:45:43.636022: Epoch 66 
2025-02-24 06:45:43.639075: Current learning rate: 0.00759 
2025-02-24 06:45:50.106741: train_loss -0.9371 
2025-02-24 06:45:50.112469: val_loss -0.826 
2025-02-24 06:45:50.116054: Pseudo dice [np.float32(0.8934), np.float32(0.8745)] 
2025-02-24 06:45:50.119091: Epoch time: 6.48 s 
2025-02-24 06:45:50.762627:  
2025-02-24 06:45:50.767647: Epoch 67 
2025-02-24 06:45:50.771163: Current learning rate: 0.00755 
2025-02-24 06:45:57.258359: train_loss -0.9406 
2025-02-24 06:45:57.264444: val_loss -0.8329 
2025-02-24 06:45:57.267584: Pseudo dice [np.float32(0.8968), np.float32(0.8782)] 
2025-02-24 06:45:57.271137: Epoch time: 6.5 s 
2025-02-24 06:45:57.779481:  
2025-02-24 06:45:57.784492: Epoch 68 
2025-02-24 06:45:57.788008: Current learning rate: 0.00751 
2025-02-24 06:46:04.287149: train_loss -0.94 
2025-02-24 06:46:04.293052: val_loss -0.8323 
2025-02-24 06:46:04.296585: Pseudo dice [np.float32(0.8976), np.float32(0.8788)] 
2025-02-24 06:46:04.299644: Epoch time: 6.51 s 
2025-02-24 06:46:04.819019:  
2025-02-24 06:46:04.824577: Epoch 69 
2025-02-24 06:46:04.827625: Current learning rate: 0.00748 
2025-02-24 06:46:11.303156: train_loss -0.9394 
2025-02-24 06:46:11.308209: val_loss -0.8301 
2025-02-24 06:46:11.311727: Pseudo dice [np.float32(0.8958), np.float32(0.8781)] 
2025-02-24 06:46:11.315235: Epoch time: 6.48 s 
2025-02-24 06:46:11.822583:  
2025-02-24 06:46:11.828108: Epoch 70 
2025-02-24 06:46:11.831617: Current learning rate: 0.00744 
2025-02-24 06:46:18.296944: train_loss -0.9407 
2025-02-24 06:46:18.303307: val_loss -0.832 
2025-02-24 06:46:18.306377: Pseudo dice [np.float32(0.8973), np.float32(0.8769)] 
2025-02-24 06:46:18.309915: Epoch time: 6.48 s 
2025-02-24 06:46:18.815883:  
2025-02-24 06:46:18.820894: Epoch 71 
2025-02-24 06:46:18.824406: Current learning rate: 0.0074 
2025-02-24 06:46:25.332337: train_loss -0.9382 
2025-02-24 06:46:25.338453: val_loss -0.8269 
2025-02-24 06:46:25.341548: Pseudo dice [np.float32(0.8935), np.float32(0.8748)] 
2025-02-24 06:46:25.344625: Epoch time: 6.52 s 
2025-02-24 06:46:25.849577:  
2025-02-24 06:46:25.855094: Epoch 72 
2025-02-24 06:46:25.858605: Current learning rate: 0.00737 
2025-02-24 06:46:32.338784: train_loss -0.9405 
2025-02-24 06:46:32.344447: val_loss -0.8321 
2025-02-24 06:46:32.347548: Pseudo dice [np.float32(0.8979), np.float32(0.878)] 
2025-02-24 06:46:32.351118: Epoch time: 6.49 s 
2025-02-24 06:46:32.853942:  
2025-02-24 06:46:32.859994: Epoch 73 
2025-02-24 06:46:32.863579: Current learning rate: 0.00733 
2025-02-24 06:46:39.349738: train_loss -0.9396 
2025-02-24 06:46:39.354751: val_loss -0.837 
2025-02-24 06:46:39.358770: Pseudo dice [np.float32(0.8997), np.float32(0.8795)] 
2025-02-24 06:46:39.362280: Epoch time: 6.5 s 
2025-02-24 06:46:39.873114:  
2025-02-24 06:46:39.878251: Epoch 74 
2025-02-24 06:46:39.881833: Current learning rate: 0.00729 
2025-02-24 06:46:46.507375: train_loss -0.9409 
2025-02-24 06:46:46.512961: val_loss -0.8317 
2025-02-24 06:46:46.515983: Pseudo dice [np.float32(0.8969), np.float32(0.8788)] 
2025-02-24 06:46:46.519523: Epoch time: 6.63 s 
2025-02-24 06:46:47.022925:  
2025-02-24 06:46:47.028481: Epoch 75 
2025-02-24 06:46:47.031029: Current learning rate: 0.00725 
2025-02-24 06:46:53.517227: train_loss -0.9403 
2025-02-24 06:46:53.522820: val_loss -0.8293 
2025-02-24 06:46:53.526839: Pseudo dice [np.float32(0.8952), np.float32(0.8762)] 
2025-02-24 06:46:53.529373: Epoch time: 6.49 s 
2025-02-24 06:46:54.035315:  
2025-02-24 06:46:54.040839: Epoch 76 
2025-02-24 06:46:54.043346: Current learning rate: 0.00722 
2025-02-24 06:47:00.514173: train_loss -0.9411 
2025-02-24 06:47:00.519857: val_loss -0.8288 
2025-02-24 06:47:00.523903: Pseudo dice [np.float32(0.8957), np.float32(0.875)] 
2025-02-24 06:47:00.526992: Epoch time: 6.48 s 
2025-02-24 06:47:01.039519:  
2025-02-24 06:47:01.045523: Epoch 77 
2025-02-24 06:47:01.049534: Current learning rate: 0.00718 
2025-02-24 06:47:07.535924: train_loss -0.9403 
2025-02-24 06:47:07.541539: val_loss -0.8306 
2025-02-24 06:47:07.545133: Pseudo dice [np.float32(0.8948), np.float32(0.8767)] 
2025-02-24 06:47:07.548198: Epoch time: 6.5 s 
2025-02-24 06:47:08.064702:  
2025-02-24 06:47:08.070766: Epoch 78 
2025-02-24 06:47:08.073830: Current learning rate: 0.00714 
2025-02-24 06:47:14.575179: train_loss -0.9423 
2025-02-24 06:47:14.580702: val_loss -0.8325 
2025-02-24 06:47:14.583811: Pseudo dice [np.float32(0.8972), np.float32(0.8775)] 
2025-02-24 06:47:14.587837: Epoch time: 6.51 s 
2025-02-24 06:47:15.101356:  
2025-02-24 06:47:15.106870: Epoch 79 
2025-02-24 06:47:15.110382: Current learning rate: 0.0071 
2025-02-24 06:47:21.591829: train_loss -0.9412 
2025-02-24 06:47:21.596918: val_loss -0.8267 
2025-02-24 06:47:21.600445: Pseudo dice [np.float32(0.8949), np.float32(0.8759)] 
2025-02-24 06:47:21.603549: Epoch time: 6.49 s 
2025-02-24 06:47:22.121895:  
2025-02-24 06:47:22.127411: Epoch 80 
2025-02-24 06:47:22.130921: Current learning rate: 0.00707 
2025-02-24 06:47:28.602850: train_loss -0.9418 
2025-02-24 06:47:28.608941: val_loss -0.8267 
2025-02-24 06:47:28.613500: Pseudo dice [np.float32(0.8944), np.float32(0.8747)] 
2025-02-24 06:47:28.617017: Epoch time: 6.48 s 
2025-02-24 06:47:29.138404:  
2025-02-24 06:47:29.143951: Epoch 81 
2025-02-24 06:47:29.147550: Current learning rate: 0.00703 
2025-02-24 06:47:35.626041: train_loss -0.9435 
2025-02-24 06:47:35.631621: val_loss -0.8276 
2025-02-24 06:47:35.635207: Pseudo dice [np.float32(0.8942), np.float32(0.8743)] 
2025-02-24 06:47:35.637232: Epoch time: 6.49 s 
2025-02-24 06:47:36.293668:  
2025-02-24 06:47:36.299678: Epoch 82 
2025-02-24 06:47:36.302687: Current learning rate: 0.00699 
2025-02-24 06:47:42.788238: train_loss -0.9423 
2025-02-24 06:47:42.794866: val_loss -0.831 
2025-02-24 06:47:42.797878: Pseudo dice [np.float32(0.8967), np.float32(0.8763)] 
2025-02-24 06:47:42.800922: Epoch time: 6.49 s 
2025-02-24 06:47:43.290434:  
2025-02-24 06:47:43.295448: Epoch 83 
2025-02-24 06:47:43.298959: Current learning rate: 0.00696 
2025-02-24 06:47:49.771069: train_loss -0.9423 
2025-02-24 06:47:49.776671: val_loss -0.8349 
2025-02-24 06:47:49.780206: Pseudo dice [np.float32(0.8977), np.float32(0.8788)] 
2025-02-24 06:47:49.783248: Epoch time: 6.48 s 
2025-02-24 06:47:50.269311:  
2025-02-24 06:47:50.274324: Epoch 84 
2025-02-24 06:47:50.277833: Current learning rate: 0.00692 
2025-02-24 06:47:56.755929: train_loss -0.9449 
2025-02-24 06:47:56.762510: val_loss -0.8308 
2025-02-24 06:47:56.766068: Pseudo dice [np.float32(0.8974), np.float32(0.8776)] 
2025-02-24 06:47:56.768677: Epoch time: 6.49 s 
2025-02-24 06:47:57.253758:  
2025-02-24 06:47:57.258853: Epoch 85 
2025-02-24 06:47:57.262894: Current learning rate: 0.00688 
2025-02-24 06:48:03.755147: train_loss -0.9433 
2025-02-24 06:48:03.760732: val_loss -0.8352 
2025-02-24 06:48:03.764333: Pseudo dice [np.float32(0.9001), np.float32(0.8801)] 
2025-02-24 06:48:03.767409: Epoch time: 6.5 s 
2025-02-24 06:48:04.260394:  
2025-02-24 06:48:04.265405: Epoch 86 
2025-02-24 06:48:04.268917: Current learning rate: 0.00684 
2025-02-24 06:48:10.755156: train_loss -0.9425 
2025-02-24 06:48:10.760722: val_loss -0.8308 
2025-02-24 06:48:10.763784: Pseudo dice [np.float32(0.8956), np.float32(0.878)] 
2025-02-24 06:48:10.766324: Epoch time: 6.5 s 
2025-02-24 06:48:11.260686:  
2025-02-24 06:48:11.266202: Epoch 87 
2025-02-24 06:48:11.268709: Current learning rate: 0.0068 
2025-02-24 06:48:17.748717: train_loss -0.9442 
2025-02-24 06:48:17.754911: val_loss -0.8305 
2025-02-24 06:48:17.758492: Pseudo dice [np.float32(0.8962), np.float32(0.8789)] 
2025-02-24 06:48:17.761548: Epoch time: 6.49 s 
2025-02-24 06:48:18.252438:  
2025-02-24 06:48:18.258020: Epoch 88 
2025-02-24 06:48:18.261105: Current learning rate: 0.00677 
2025-02-24 06:48:24.763813: train_loss -0.9444 
2025-02-24 06:48:24.770598: val_loss -0.8297 
2025-02-24 06:48:24.773148: Pseudo dice [np.float32(0.8974), np.float32(0.8759)] 
2025-02-24 06:48:24.776709: Epoch time: 6.51 s 
2025-02-24 06:48:25.265088:  
2025-02-24 06:48:25.270648: Epoch 89 
2025-02-24 06:48:25.274694: Current learning rate: 0.00673 
2025-02-24 06:48:31.758172: train_loss -0.9446 
2025-02-24 06:48:31.764704: val_loss -0.8287 
2025-02-24 06:48:31.768218: Pseudo dice [np.float32(0.8958), np.float32(0.8765)] 
2025-02-24 06:48:31.772228: Epoch time: 6.49 s 
2025-02-24 06:48:32.410683:  
2025-02-24 06:48:32.415696: Epoch 90 
2025-02-24 06:48:32.419209: Current learning rate: 0.00669 
2025-02-24 06:48:38.884671: train_loss -0.9438 
2025-02-24 06:48:38.889760: val_loss -0.832 
2025-02-24 06:48:38.893381: Pseudo dice [np.float32(0.8973), np.float32(0.879)] 
2025-02-24 06:48:38.896932: Epoch time: 6.47 s 
2025-02-24 06:48:39.383838:  
2025-02-24 06:48:39.388539: Epoch 91 
2025-02-24 06:48:39.392601: Current learning rate: 0.00665 
2025-02-24 06:48:45.876416: train_loss -0.9448 
2025-02-24 06:48:45.883102: val_loss -0.8351 
2025-02-24 06:48:45.886635: Pseudo dice [np.float32(0.8993), np.float32(0.8802)] 
2025-02-24 06:48:45.889695: Epoch time: 6.49 s 
2025-02-24 06:48:45.892789: Yayy! New best EMA pseudo Dice: 0.8871999979019165 
2025-02-24 06:48:46.425361:  
2025-02-24 06:48:46.430406: Epoch 92 
2025-02-24 06:48:46.433958: Current learning rate: 0.00662 
2025-02-24 06:48:52.919117: train_loss -0.9449 
2025-02-24 06:48:52.923697: val_loss -0.828 
2025-02-24 06:48:52.928280: Pseudo dice [np.float32(0.8967), np.float32(0.8756)] 
2025-02-24 06:48:52.930896: Epoch time: 6.49 s 
2025-02-24 06:48:53.424768:  
2025-02-24 06:48:53.430416: Epoch 93 
2025-02-24 06:48:53.433956: Current learning rate: 0.00658 
2025-02-24 06:48:59.907327: train_loss -0.944 
2025-02-24 06:48:59.912409: val_loss -0.828 
2025-02-24 06:48:59.915940: Pseudo dice [np.float32(0.8949), np.float32(0.8764)] 
2025-02-24 06:48:59.919504: Epoch time: 6.48 s 
2025-02-24 06:49:00.413561:  
2025-02-24 06:49:00.419082: Epoch 94 
2025-02-24 06:49:00.421088: Current learning rate: 0.00654 
2025-02-24 06:49:06.902425: train_loss -0.9452 
2025-02-24 06:49:06.908099: val_loss -0.8284 
2025-02-24 06:49:06.912147: Pseudo dice [np.float32(0.8972), np.float32(0.8768)] 
2025-02-24 06:49:06.915201: Epoch time: 6.49 s 
2025-02-24 06:49:07.412287:  
2025-02-24 06:49:07.417801: Epoch 95 
2025-02-24 06:49:07.421311: Current learning rate: 0.0065 
2025-02-24 06:49:13.941236: train_loss -0.9442 
2025-02-24 06:49:13.948375: val_loss -0.8298 
2025-02-24 06:49:13.951409: Pseudo dice [np.float32(0.8974), np.float32(0.8769)] 
2025-02-24 06:49:13.954944: Epoch time: 6.53 s 
2025-02-24 06:49:14.445729:  
2025-02-24 06:49:14.450759: Epoch 96 
2025-02-24 06:49:14.452912: Current learning rate: 0.00647 
2025-02-24 06:49:20.952311: train_loss -0.9453 
2025-02-24 06:49:20.958868: val_loss -0.8237 
2025-02-24 06:49:20.961974: Pseudo dice [np.float32(0.8918), np.float32(0.8734)] 
2025-02-24 06:49:20.965532: Epoch time: 6.51 s 
2025-02-24 06:49:21.473779:  
2025-02-24 06:49:21.478305: Epoch 97 
2025-02-24 06:49:21.481866: Current learning rate: 0.00643 
2025-02-24 06:49:27.960761: train_loss -0.9458 
2025-02-24 06:49:27.966042: val_loss -0.8243 
2025-02-24 06:49:27.970053: Pseudo dice [np.float32(0.8934), np.float32(0.8733)] 
2025-02-24 06:49:27.972559: Epoch time: 6.49 s 
2025-02-24 06:49:28.619971:  
2025-02-24 06:49:28.624987: Epoch 98 
2025-02-24 06:49:28.627493: Current learning rate: 0.00639 
2025-02-24 06:49:35.098274: train_loss -0.9465 
2025-02-24 06:49:35.103872: val_loss -0.8292 
2025-02-24 06:49:35.107576: Pseudo dice [np.float32(0.8961), np.float32(0.8769)] 
2025-02-24 06:49:35.110612: Epoch time: 6.48 s 
2025-02-24 06:49:35.607904:  
2025-02-24 06:49:35.611993: Epoch 99 
2025-02-24 06:49:35.616043: Current learning rate: 0.00635 
2025-02-24 06:49:42.098332: train_loss -0.9468 
2025-02-24 06:49:42.104918: val_loss -0.8365 
2025-02-24 06:49:42.107573: Pseudo dice [np.float32(0.8994), np.float32(0.882)] 
2025-02-24 06:49:42.111716: Epoch time: 6.49 s 
2025-02-24 06:49:42.649703:  
2025-02-24 06:49:42.653718: Epoch 100 
2025-02-24 06:49:42.657223: Current learning rate: 0.00631 
2025-02-24 06:49:49.133572: train_loss -0.9478 
2025-02-24 06:49:49.140136: val_loss -0.8225 
2025-02-24 06:49:49.143203: Pseudo dice [np.float32(0.8921), np.float32(0.8741)] 
2025-02-24 06:49:49.146244: Epoch time: 6.48 s 
2025-02-24 06:49:49.645741:  
2025-02-24 06:49:49.652260: Epoch 101 
2025-02-24 06:49:49.655776: Current learning rate: 0.00628 
2025-02-24 06:49:56.143399: train_loss -0.9459 
2025-02-24 06:49:56.148413: val_loss -0.8297 
2025-02-24 06:49:56.152479: Pseudo dice [np.float32(0.8961), np.float32(0.8791)] 
2025-02-24 06:49:56.156089: Epoch time: 6.5 s 
2025-02-24 06:49:56.652622:  
2025-02-24 06:49:56.657719: Epoch 102 
2025-02-24 06:49:56.661055: Current learning rate: 0.00624 
2025-02-24 06:50:03.153630: train_loss -0.9458 
2025-02-24 06:50:03.159815: val_loss -0.8287 
2025-02-24 06:50:03.163359: Pseudo dice [np.float32(0.8962), np.float32(0.876)] 
2025-02-24 06:50:03.166471: Epoch time: 6.5 s 
2025-02-24 06:50:03.662014:  
2025-02-24 06:50:03.667035: Epoch 103 
2025-02-24 06:50:03.670543: Current learning rate: 0.0062 
2025-02-24 06:50:10.148047: train_loss -0.9468 
2025-02-24 06:50:10.153680: val_loss -0.8285 
2025-02-24 06:50:10.157324: Pseudo dice [np.float32(0.8965), np.float32(0.8773)] 
2025-02-24 06:50:10.159834: Epoch time: 6.49 s 
2025-02-24 06:50:10.655817:  
2025-02-24 06:50:10.661363: Epoch 104 
2025-02-24 06:50:10.664960: Current learning rate: 0.00616 
2025-02-24 06:50:17.147080: train_loss -0.9458 
2025-02-24 06:50:17.153206: val_loss -0.8284 
2025-02-24 06:50:17.157252: Pseudo dice [np.float32(0.8961), np.float32(0.8765)] 
2025-02-24 06:50:17.159773: Epoch time: 6.49 s 
2025-02-24 06:50:17.663293:  
2025-02-24 06:50:17.668867: Epoch 105 
2025-02-24 06:50:17.672411: Current learning rate: 0.00612 
2025-02-24 06:50:24.175153: train_loss -0.9477 
2025-02-24 06:50:24.180799: val_loss -0.8352 
2025-02-24 06:50:24.183351: Pseudo dice [np.float32(0.8999), np.float32(0.8817)] 
2025-02-24 06:50:24.187398: Epoch time: 6.51 s 
2025-02-24 06:50:24.830205:  
2025-02-24 06:50:24.835833: Epoch 106 
2025-02-24 06:50:24.839384: Current learning rate: 0.00609 
2025-02-24 06:50:31.325370: train_loss -0.9484 
2025-02-24 06:50:31.331109: val_loss -0.8327 
2025-02-24 06:50:31.334166: Pseudo dice [np.float32(0.8977), np.float32(0.8795)] 
2025-02-24 06:50:31.337717: Epoch time: 6.5 s 
2025-02-24 06:50:31.836826:  
2025-02-24 06:50:31.842350: Epoch 107 
2025-02-24 06:50:31.844855: Current learning rate: 0.00605 
2025-02-24 06:50:38.313648: train_loss -0.9493 
2025-02-24 06:50:38.319731: val_loss -0.8326 
2025-02-24 06:50:38.323271: Pseudo dice [np.float32(0.8991), np.float32(0.8805)] 
2025-02-24 06:50:38.326799: Epoch time: 6.48 s 
2025-02-24 06:50:38.330357: Yayy! New best EMA pseudo Dice: 0.8873000144958496 
2025-02-24 06:50:38.869594:  
2025-02-24 06:50:38.874637: Epoch 108 
2025-02-24 06:50:38.878685: Current learning rate: 0.00601 
2025-02-24 06:50:45.346284: train_loss -0.9486 
2025-02-24 06:50:45.351950: val_loss -0.8273 
2025-02-24 06:50:45.354995: Pseudo dice [np.float32(0.8949), np.float32(0.8779)] 
2025-02-24 06:50:45.358533: Epoch time: 6.48 s 
2025-02-24 06:50:45.851862:  
2025-02-24 06:50:45.857379: Epoch 109 
2025-02-24 06:50:45.860889: Current learning rate: 0.00597 
2025-02-24 06:50:52.350612: train_loss -0.9494 
2025-02-24 06:50:52.358186: val_loss -0.826 
2025-02-24 06:50:52.361734: Pseudo dice [np.float32(0.896), np.float32(0.8768)] 
2025-02-24 06:50:52.364275: Epoch time: 6.5 s 
2025-02-24 06:50:52.863323:  
2025-02-24 06:50:52.868875: Epoch 110 
2025-02-24 06:50:52.871915: Current learning rate: 0.00593 
2025-02-24 06:50:59.360616: train_loss -0.9496 
2025-02-24 06:50:59.366871: val_loss -0.8265 
2025-02-24 06:50:59.370449: Pseudo dice [np.float32(0.894), np.float32(0.8749)] 
2025-02-24 06:50:59.373991: Epoch time: 6.5 s 
2025-02-24 06:50:59.873297:  
2025-02-24 06:50:59.878321: Epoch 111 
2025-02-24 06:50:59.882188: Current learning rate: 0.0059 
2025-02-24 06:51:06.362743: train_loss -0.9503 
2025-02-24 06:51:06.368408: val_loss -0.8285 
2025-02-24 06:51:06.371529: Pseudo dice [np.float32(0.8961), np.float32(0.8767)] 
2025-02-24 06:51:06.375083: Epoch time: 6.49 s 
2025-02-24 06:51:06.869400:  
2025-02-24 06:51:06.875463: Epoch 112 
2025-02-24 06:51:06.878497: Current learning rate: 0.00586 
2025-02-24 06:51:13.384594: train_loss -0.9498 
2025-02-24 06:51:13.390765: val_loss -0.8308 
2025-02-24 06:51:13.394819: Pseudo dice [np.float32(0.8976), np.float32(0.8781)] 
2025-02-24 06:51:13.397896: Epoch time: 6.52 s 
2025-02-24 06:51:13.889989:  
2025-02-24 06:51:13.895002: Epoch 113 
2025-02-24 06:51:13.898512: Current learning rate: 0.00582 
2025-02-24 06:51:20.383205: train_loss -0.9497 
2025-02-24 06:51:20.388266: val_loss -0.8289 
2025-02-24 06:51:20.391778: Pseudo dice [np.float32(0.8962), np.float32(0.8773)] 
2025-02-24 06:51:20.395787: Epoch time: 6.49 s 
2025-02-24 06:51:21.036705:  
2025-02-24 06:51:21.042227: Epoch 114 
2025-02-24 06:51:21.045744: Current learning rate: 0.00578 
2025-02-24 06:51:27.512079: train_loss -0.9481 
2025-02-24 06:51:27.517785: val_loss -0.8298 
2025-02-24 06:51:27.521327: Pseudo dice [np.float32(0.8971), np.float32(0.8779)] 
2025-02-24 06:51:27.524371: Epoch time: 6.48 s 
2025-02-24 06:51:28.017696:  
2025-02-24 06:51:28.022707: Epoch 115 
2025-02-24 06:51:28.026219: Current learning rate: 0.00574 
2025-02-24 06:51:34.510135: train_loss -0.9522 
2025-02-24 06:51:34.515700: val_loss -0.8229 
2025-02-24 06:51:34.518309: Pseudo dice [np.float32(0.8953), np.float32(0.8739)] 
2025-02-24 06:51:34.522377: Epoch time: 6.49 s 
2025-02-24 06:51:35.023021:  
2025-02-24 06:51:35.028578: Epoch 116 
2025-02-24 06:51:35.031612: Current learning rate: 0.0057 
2025-02-24 06:51:41.520429: train_loss -0.9485 
2025-02-24 06:51:41.526487: val_loss -0.8329 
2025-02-24 06:51:41.530063: Pseudo dice [np.float32(0.8984), np.float32(0.8794)] 
2025-02-24 06:51:41.533591: Epoch time: 6.5 s 
2025-02-24 06:51:42.041810:  
2025-02-24 06:51:42.047385: Epoch 117 
2025-02-24 06:51:42.051430: Current learning rate: 0.00567 
2025-02-24 06:51:48.530590: train_loss -0.9497 
2025-02-24 06:51:48.537117: val_loss -0.8222 
2025-02-24 06:51:48.540699: Pseudo dice [np.float32(0.8935), np.float32(0.8743)] 
2025-02-24 06:51:48.544228: Epoch time: 6.49 s 
2025-02-24 06:51:49.054239:  
2025-02-24 06:51:49.060304: Epoch 118 
2025-02-24 06:51:49.063868: Current learning rate: 0.00563 
2025-02-24 06:51:55.548681: train_loss -0.9486 
2025-02-24 06:51:55.554809: val_loss -0.8263 
2025-02-24 06:51:55.558854: Pseudo dice [np.float32(0.8962), np.float32(0.8762)] 
2025-02-24 06:51:55.561896: Epoch time: 6.49 s 
2025-02-24 06:51:56.061202:  
2025-02-24 06:51:56.066717: Epoch 119 
2025-02-24 06:51:56.070227: Current learning rate: 0.00559 
2025-02-24 06:52:02.548524: train_loss -0.9512 
2025-02-24 06:52:02.554139: val_loss -0.8304 
2025-02-24 06:52:02.557680: Pseudo dice [np.float32(0.8986), np.float32(0.8791)] 
2025-02-24 06:52:02.561248: Epoch time: 6.49 s 
2025-02-24 06:52:03.063634:  
2025-02-24 06:52:03.068647: Epoch 120 
2025-02-24 06:52:03.071658: Current learning rate: 0.00555 
2025-02-24 06:52:09.556316: train_loss -0.9502 
2025-02-24 06:52:09.560873: val_loss -0.8232 
2025-02-24 06:52:09.564998: Pseudo dice [np.float32(0.8938), np.float32(0.8743)] 
2025-02-24 06:52:09.568021: Epoch time: 6.49 s 
2025-02-24 06:52:10.072577:  
2025-02-24 06:52:10.078096: Epoch 121 
2025-02-24 06:52:10.081614: Current learning rate: 0.00551 
2025-02-24 06:52:16.553247: train_loss -0.9499 
2025-02-24 06:52:16.559405: val_loss -0.8308 
2025-02-24 06:52:16.563455: Pseudo dice [np.float32(0.897), np.float32(0.8778)] 
2025-02-24 06:52:16.567055: Epoch time: 6.48 s 
2025-02-24 06:52:17.222730:  
2025-02-24 06:52:17.228269: Epoch 122 
2025-02-24 06:52:17.231785: Current learning rate: 0.00547 
2025-02-24 06:52:23.724545: train_loss -0.9507 
2025-02-24 06:52:23.730585: val_loss -0.8348 
2025-02-24 06:52:23.734568: Pseudo dice [np.float32(0.8998), np.float32(0.8809)] 
2025-02-24 06:52:23.738087: Epoch time: 6.5 s 
2025-02-24 06:52:24.236162:  
2025-02-24 06:52:24.241721: Epoch 123 
2025-02-24 06:52:24.245768: Current learning rate: 0.00544 
2025-02-24 06:52:30.731519: train_loss -0.9508 
2025-02-24 06:52:30.737653: val_loss -0.8249 
2025-02-24 06:52:30.741189: Pseudo dice [np.float32(0.8948), np.float32(0.8749)] 
2025-02-24 06:52:30.744237: Epoch time: 6.5 s 
2025-02-24 06:52:31.243438:  
2025-02-24 06:52:31.247502: Epoch 124 
2025-02-24 06:52:31.251060: Current learning rate: 0.0054 
2025-02-24 06:52:37.725607: train_loss -0.949 
2025-02-24 06:52:37.731186: val_loss -0.8289 
2025-02-24 06:52:37.734760: Pseudo dice [np.float32(0.8964), np.float32(0.8777)] 
2025-02-24 06:52:37.738395: Epoch time: 6.48 s 
2025-02-24 06:52:38.245007:  
2025-02-24 06:52:38.251024: Epoch 125 
2025-02-24 06:52:38.253531: Current learning rate: 0.00536 
2025-02-24 06:52:44.724813: train_loss -0.9503 
2025-02-24 06:52:44.729857: val_loss -0.8327 
2025-02-24 06:52:44.733425: Pseudo dice [np.float32(0.8983), np.float32(0.8795)] 
2025-02-24 06:52:44.739511: Epoch time: 6.48 s 
2025-02-24 06:52:45.241684:  
2025-02-24 06:52:45.247200: Epoch 126 
2025-02-24 06:52:45.250710: Current learning rate: 0.00532 
2025-02-24 06:52:51.741060: train_loss -0.9497 
2025-02-24 06:52:51.748626: val_loss -0.828 
2025-02-24 06:52:51.751255: Pseudo dice [np.float32(0.8962), np.float32(0.8765)] 
2025-02-24 06:52:51.755817: Epoch time: 6.5 s 
2025-02-24 06:52:52.253439:  
2025-02-24 06:52:52.259010: Epoch 127 
2025-02-24 06:52:52.262576: Current learning rate: 0.00528 
2025-02-24 06:52:58.753351: train_loss -0.9508 
2025-02-24 06:52:58.758382: val_loss -0.8268 
2025-02-24 06:52:58.762018: Pseudo dice [np.float32(0.8953), np.float32(0.8776)] 
2025-02-24 06:52:58.765558: Epoch time: 6.5 s 
2025-02-24 06:52:59.274075:  
2025-02-24 06:52:59.279104: Epoch 128 
2025-02-24 06:52:59.283305: Current learning rate: 0.00524 
2025-02-24 06:53:05.761615: train_loss -0.9508 
2025-02-24 06:53:05.766663: val_loss -0.8329 
2025-02-24 06:53:05.770739: Pseudo dice [np.float32(0.8993), np.float32(0.8793)] 
2025-02-24 06:53:05.774247: Epoch time: 6.49 s 
2025-02-24 06:53:06.274596:  
2025-02-24 06:53:06.280621: Epoch 129 
2025-02-24 06:53:06.284130: Current learning rate: 0.0052 
2025-02-24 06:53:12.769805: train_loss -0.952 
2025-02-24 06:53:12.775824: val_loss -0.8323 
2025-02-24 06:53:12.779331: Pseudo dice [np.float32(0.8985), np.float32(0.8804)] 
2025-02-24 06:53:12.782871: Epoch time: 6.5 s 
2025-02-24 06:53:12.785928: Yayy! New best EMA pseudo Dice: 0.8873999714851379 
2025-02-24 06:53:13.477616:  
2025-02-24 06:53:13.482766: Epoch 130 
2025-02-24 06:53:13.486315: Current learning rate: 0.00517 
2025-02-24 06:53:19.970978: train_loss -0.952 
2025-02-24 06:53:19.976156: val_loss -0.8278 
2025-02-24 06:53:19.980725: Pseudo dice [np.float32(0.8959), np.float32(0.8775)] 
2025-02-24 06:53:19.983782: Epoch time: 6.49 s 
2025-02-24 06:53:20.493045:  
2025-02-24 06:53:20.499128: Epoch 131 
2025-02-24 06:53:20.501756: Current learning rate: 0.00513 
2025-02-24 06:53:26.968617: train_loss -0.9494 
2025-02-24 06:53:26.974172: val_loss -0.8256 
2025-02-24 06:53:26.976698: Pseudo dice [np.float32(0.8958), np.float32(0.8755)] 
2025-02-24 06:53:26.980725: Epoch time: 6.48 s 
2025-02-24 06:53:27.485711:  
2025-02-24 06:53:27.491755: Epoch 132 
2025-02-24 06:53:27.494263: Current learning rate: 0.00509 
2025-02-24 06:53:33.989683: train_loss -0.9522 
2025-02-24 06:53:33.995279: val_loss -0.8296 
2025-02-24 06:53:33.998905: Pseudo dice [np.float32(0.8964), np.float32(0.8779)] 
2025-02-24 06:53:34.002434: Epoch time: 6.5 s 
2025-02-24 06:53:34.505867:  
2025-02-24 06:53:34.510908: Epoch 133 
2025-02-24 06:53:34.515039: Current learning rate: 0.00505 
2025-02-24 06:53:41.024820: train_loss -0.9525 
2025-02-24 06:53:41.032050: val_loss -0.8265 
2025-02-24 06:53:41.036131: Pseudo dice [np.float32(0.8959), np.float32(0.8767)] 
2025-02-24 06:53:41.039173: Epoch time: 6.52 s 
2025-02-24 06:53:41.541916:  
2025-02-24 06:53:41.547527: Epoch 134 
2025-02-24 06:53:41.550580: Current learning rate: 0.00501 
2025-02-24 06:53:48.031823: train_loss -0.9525 
2025-02-24 06:53:48.037926: val_loss -0.8301 
2025-02-24 06:53:48.042102: Pseudo dice [np.float32(0.8973), np.float32(0.877)] 
2025-02-24 06:53:48.045148: Epoch time: 6.49 s 
2025-02-24 06:53:48.558661:  
2025-02-24 06:53:48.564677: Epoch 135 
2025-02-24 06:53:48.567181: Current learning rate: 0.00497 
2025-02-24 06:53:55.050221: train_loss -0.9505 
2025-02-24 06:53:55.055824: val_loss -0.8287 
2025-02-24 06:53:55.058363: Pseudo dice [np.float32(0.8963), np.float32(0.8763)] 
2025-02-24 06:53:55.062411: Epoch time: 6.49 s 
2025-02-24 06:53:55.568890:  
2025-02-24 06:53:55.573902: Epoch 136 
2025-02-24 06:53:55.577419: Current learning rate: 0.00493 
2025-02-24 06:54:02.075104: train_loss -0.9519 
2025-02-24 06:54:02.081368: val_loss -0.8264 
2025-02-24 06:54:02.085023: Pseudo dice [np.float32(0.8956), np.float32(0.8776)] 
2025-02-24 06:54:02.088085: Epoch time: 6.51 s 
2025-02-24 06:54:02.595971:  
2025-02-24 06:54:02.601536: Epoch 137 
2025-02-24 06:54:02.605078: Current learning rate: 0.00489 
2025-02-24 06:54:09.104306: train_loss -0.9547 
2025-02-24 06:54:09.110348: val_loss -0.8284 
2025-02-24 06:54:09.114138: Pseudo dice [np.float32(0.8966), np.float32(0.8781)] 
2025-02-24 06:54:09.117168: Epoch time: 6.51 s 
2025-02-24 06:54:09.772585:  
2025-02-24 06:54:09.777596: Epoch 138 
2025-02-24 06:54:09.782607: Current learning rate: 0.00485 
2025-02-24 06:54:16.257395: train_loss -0.9521 
2025-02-24 06:54:16.263464: val_loss -0.8295 
2025-02-24 06:54:16.267071: Pseudo dice [np.float32(0.8955), np.float32(0.8773)] 
2025-02-24 06:54:16.270185: Epoch time: 6.49 s 
2025-02-24 06:54:16.777967:  
2025-02-24 06:54:16.784088: Epoch 139 
2025-02-24 06:54:16.787625: Current learning rate: 0.00482 
2025-02-24 06:54:23.283995: train_loss -0.9508 
2025-02-24 06:54:23.289581: val_loss -0.8295 
2025-02-24 06:54:23.293144: Pseudo dice [np.float32(0.8974), np.float32(0.8768)] 
2025-02-24 06:54:23.296687: Epoch time: 6.51 s 
2025-02-24 06:54:23.803601:  
2025-02-24 06:54:23.809693: Epoch 140 
2025-02-24 06:54:23.812730: Current learning rate: 0.00478 
2025-02-24 06:54:30.316740: train_loss -0.9525 
2025-02-24 06:54:30.322800: val_loss -0.8292 
2025-02-24 06:54:30.326442: Pseudo dice [np.float32(0.8991), np.float32(0.8783)] 
2025-02-24 06:54:30.329614: Epoch time: 6.51 s 
2025-02-24 06:54:30.836320:  
2025-02-24 06:54:30.841971: Epoch 141 
2025-02-24 06:54:30.845023: Current learning rate: 0.00474 
2025-02-24 06:54:37.324170: train_loss -0.9532 
2025-02-24 06:54:37.329722: val_loss -0.8291 
2025-02-24 06:54:37.332756: Pseudo dice [np.float32(0.8979), np.float32(0.8781)] 
2025-02-24 06:54:37.336385: Epoch time: 6.49 s 
2025-02-24 06:54:37.845588:  
2025-02-24 06:54:37.851122: Epoch 142 
2025-02-24 06:54:37.854152: Current learning rate: 0.0047 
2025-02-24 06:54:44.346376: train_loss -0.951 
2025-02-24 06:54:44.352448: val_loss -0.8226 
2025-02-24 06:54:44.356095: Pseudo dice [np.float32(0.8946), np.float32(0.8732)] 
2025-02-24 06:54:44.359129: Epoch time: 6.5 s 
2025-02-24 06:54:44.864601:  
2025-02-24 06:54:44.870683: Epoch 143 
2025-02-24 06:54:44.874251: Current learning rate: 0.00466 
2025-02-24 06:54:51.379444: train_loss -0.9525 
2025-02-24 06:54:51.385987: val_loss -0.8239 
2025-02-24 06:54:51.389995: Pseudo dice [np.float32(0.8946), np.float32(0.8751)] 
2025-02-24 06:54:51.393503: Epoch time: 6.51 s 
2025-02-24 06:54:51.901980:  
2025-02-24 06:54:51.907531: Epoch 144 
2025-02-24 06:54:51.910060: Current learning rate: 0.00462 
2025-02-24 06:54:58.385540: train_loss -0.9519 
2025-02-24 06:54:58.390577: val_loss -0.8237 
2025-02-24 06:54:58.394601: Pseudo dice [np.float32(0.8942), np.float32(0.8743)] 
2025-02-24 06:54:58.398183: Epoch time: 6.48 s 
2025-02-24 06:54:58.905574:  
2025-02-24 06:54:58.911654: Epoch 145 
2025-02-24 06:54:58.915221: Current learning rate: 0.00458 
2025-02-24 06:55:05.393816: train_loss -0.9546 
2025-02-24 06:55:05.398888: val_loss -0.8247 
2025-02-24 06:55:05.402432: Pseudo dice [np.float32(0.8961), np.float32(0.8754)] 
2025-02-24 06:55:05.405951: Epoch time: 6.49 s 
2025-02-24 06:55:06.062916:  
2025-02-24 06:55:06.067927: Epoch 146 
2025-02-24 06:55:06.071436: Current learning rate: 0.00454 
2025-02-24 06:55:12.561098: train_loss -0.9517 
2025-02-24 06:55:12.568708: val_loss -0.8315 
2025-02-24 06:55:12.571875: Pseudo dice [np.float32(0.8991), np.float32(0.8816)] 
2025-02-24 06:55:12.574690: Epoch time: 6.5 s 
2025-02-24 06:55:13.083254:  
2025-02-24 06:55:13.088803: Epoch 147 
2025-02-24 06:55:13.092374: Current learning rate: 0.0045 
2025-02-24 06:55:19.601062: train_loss -0.9538 
2025-02-24 06:55:19.607764: val_loss -0.8302 
2025-02-24 06:55:19.611329: Pseudo dice [np.float32(0.8966), np.float32(0.8778)] 
2025-02-24 06:55:19.616014: Epoch time: 6.52 s 
2025-02-24 06:55:20.128155:  
2025-02-24 06:55:20.133711: Epoch 148 
2025-02-24 06:55:20.137242: Current learning rate: 0.00446 
2025-02-24 06:55:26.625697: train_loss -0.9548 
2025-02-24 06:55:26.631235: val_loss -0.8257 
2025-02-24 06:55:26.635762: Pseudo dice [np.float32(0.8971), np.float32(0.8769)] 
2025-02-24 06:55:26.638817: Epoch time: 6.5 s 
2025-02-24 06:55:27.148127:  
2025-02-24 06:55:27.153672: Epoch 149 
2025-02-24 06:55:27.156223: Current learning rate: 0.00442 
2025-02-24 06:55:33.639688: train_loss -0.9549 
2025-02-24 06:55:33.643752: val_loss -0.8293 
2025-02-24 06:55:33.647307: Pseudo dice [np.float32(0.8971), np.float32(0.8776)] 
2025-02-24 06:55:33.650856: Epoch time: 6.49 s 
2025-02-24 06:55:34.195854:  
2025-02-24 06:55:34.201389: Epoch 150 
2025-02-24 06:55:34.204952: Current learning rate: 0.00438 
2025-02-24 06:55:40.696579: train_loss -0.9544 
2025-02-24 06:55:40.703188: val_loss -0.8244 
2025-02-24 06:55:40.706784: Pseudo dice [np.float32(0.8964), np.float32(0.8754)] 
2025-02-24 06:55:40.709824: Epoch time: 6.5 s 
2025-02-24 06:55:41.216096:  
2025-02-24 06:55:41.222163: Epoch 151 
2025-02-24 06:55:41.225272: Current learning rate: 0.00434 
2025-02-24 06:55:47.732210: train_loss -0.9555 
2025-02-24 06:55:47.738890: val_loss -0.8317 
2025-02-24 06:55:47.743456: Pseudo dice [np.float32(0.8988), np.float32(0.8796)] 
2025-02-24 06:55:47.747030: Epoch time: 6.52 s 
2025-02-24 06:55:48.256849:  
2025-02-24 06:55:48.262378: Epoch 152 
2025-02-24 06:55:48.265888: Current learning rate: 0.0043 
2025-02-24 06:55:54.757410: train_loss -0.9553 
2025-02-24 06:55:54.764042: val_loss -0.8229 
2025-02-24 06:55:54.767580: Pseudo dice [np.float32(0.8935), np.float32(0.8729)] 
2025-02-24 06:55:54.770627: Epoch time: 6.5 s 
2025-02-24 06:55:55.427129:  
2025-02-24 06:55:55.432213: Epoch 153 
2025-02-24 06:55:55.435740: Current learning rate: 0.00427 
2025-02-24 06:56:01.927351: train_loss -0.9565 
2025-02-24 06:56:01.932462: val_loss -0.8263 
2025-02-24 06:56:01.935974: Pseudo dice [np.float32(0.8963), np.float32(0.8762)] 
2025-02-24 06:56:01.939557: Epoch time: 6.5 s 
2025-02-24 06:56:02.454023:  
2025-02-24 06:56:02.459573: Epoch 154 
2025-02-24 06:56:02.462612: Current learning rate: 0.00423 
2025-02-24 06:56:08.970086: train_loss -0.9545 
2025-02-24 06:56:08.975695: val_loss -0.8383 
2025-02-24 06:56:08.979288: Pseudo dice [np.float32(0.9024), np.float32(0.8836)] 
2025-02-24 06:56:08.982327: Epoch time: 6.52 s 
2025-02-24 06:56:09.499033:  
2025-02-24 06:56:09.504591: Epoch 155 
2025-02-24 06:56:09.507144: Current learning rate: 0.00419 
2025-02-24 06:56:15.983632: train_loss -0.9563 
2025-02-24 06:56:15.989725: val_loss -0.8256 
2025-02-24 06:56:15.993861: Pseudo dice [np.float32(0.896), np.float32(0.8764)] 
2025-02-24 06:56:15.996887: Epoch time: 6.48 s 
2025-02-24 06:56:16.511948:  
2025-02-24 06:56:16.516973: Epoch 156 
2025-02-24 06:56:16.521052: Current learning rate: 0.00415 
2025-02-24 06:56:23.005749: train_loss -0.9551 
2025-02-24 06:56:23.011922: val_loss -0.8285 
2025-02-24 06:56:23.015456: Pseudo dice [np.float32(0.8987), np.float32(0.8785)] 
2025-02-24 06:56:23.018497: Epoch time: 6.49 s 
2025-02-24 06:56:23.531544:  
2025-02-24 06:56:23.536558: Epoch 157 
2025-02-24 06:56:23.540067: Current learning rate: 0.00411 
2025-02-24 06:56:30.058388: train_loss -0.9547 
2025-02-24 06:56:30.064507: val_loss -0.8285 
2025-02-24 06:56:30.068158: Pseudo dice [np.float32(0.8973), np.float32(0.8784)] 
2025-02-24 06:56:30.070678: Epoch time: 6.53 s 
2025-02-24 06:56:30.589610:  
2025-02-24 06:56:30.595214: Epoch 158 
2025-02-24 06:56:30.598766: Current learning rate: 0.00407 
2025-02-24 06:56:37.103607: train_loss -0.9539 
2025-02-24 06:56:37.109689: val_loss -0.8255 
2025-02-24 06:56:37.113260: Pseudo dice [np.float32(0.8955), np.float32(0.8763)] 
2025-02-24 06:56:37.116296: Epoch time: 6.51 s 
2025-02-24 06:56:37.634697:  
2025-02-24 06:56:37.639783: Epoch 159 
2025-02-24 06:56:37.643307: Current learning rate: 0.00403 
2025-02-24 06:56:44.120496: train_loss -0.955 
2025-02-24 06:56:44.126683: val_loss -0.8255 
2025-02-24 06:56:44.130280: Pseudo dice [np.float32(0.896), np.float32(0.8756)] 
2025-02-24 06:56:44.133410: Epoch time: 6.49 s 
2025-02-24 06:56:44.650086:  
2025-02-24 06:56:44.655602: Epoch 160 
2025-02-24 06:56:44.659112: Current learning rate: 0.00399 
2025-02-24 06:56:51.150136: train_loss -0.9555 
2025-02-24 06:56:51.157287: val_loss -0.8246 
2025-02-24 06:56:51.160906: Pseudo dice [np.float32(0.894), np.float32(0.8755)] 
2025-02-24 06:56:51.164021: Epoch time: 6.5 s 
2025-02-24 06:56:51.825482:  
2025-02-24 06:56:51.830995: Epoch 161 
2025-02-24 06:56:51.834505: Current learning rate: 0.00395 
2025-02-24 06:56:58.325526: train_loss -0.9552 
2025-02-24 06:56:58.331222: val_loss -0.8303 
2025-02-24 06:56:58.334821: Pseudo dice [np.float32(0.8977), np.float32(0.8778)] 
2025-02-24 06:56:58.337354: Epoch time: 6.5 s 
2025-02-24 06:56:58.851296:  
2025-02-24 06:56:58.856940: Epoch 162 
2025-02-24 06:56:58.861017: Current learning rate: 0.00391 
2025-02-24 06:57:05.362172: train_loss -0.9538 
2025-02-24 06:57:05.367338: val_loss -0.83 
2025-02-24 06:57:05.370401: Pseudo dice [np.float32(0.8983), np.float32(0.8802)] 
2025-02-24 06:57:05.374438: Epoch time: 6.51 s 
2025-02-24 06:57:05.892764:  
2025-02-24 06:57:05.898286: Epoch 163 
2025-02-24 06:57:05.901822: Current learning rate: 0.00387 
2025-02-24 06:57:12.385123: train_loss -0.9556 
2025-02-24 06:57:12.391223: val_loss -0.825 
2025-02-24 06:57:12.394748: Pseudo dice [np.float32(0.8935), np.float32(0.875)] 
2025-02-24 06:57:12.398386: Epoch time: 6.49 s 
2025-02-24 06:57:12.916241:  
2025-02-24 06:57:12.921991: Epoch 164 
2025-02-24 06:57:12.925533: Current learning rate: 0.00383 
2025-02-24 06:57:19.427199: train_loss -0.9569 
2025-02-24 06:57:19.433395: val_loss -0.8215 
2025-02-24 06:57:19.436951: Pseudo dice [np.float32(0.8931), np.float32(0.8739)] 
2025-02-24 06:57:19.440022: Epoch time: 6.51 s 
2025-02-24 06:57:19.955027:  
2025-02-24 06:57:19.960036: Epoch 165 
2025-02-24 06:57:19.963548: Current learning rate: 0.00379 
2025-02-24 06:57:26.462165: train_loss -0.9566 
2025-02-24 06:57:26.467777: val_loss -0.8239 
2025-02-24 06:57:26.470816: Pseudo dice [np.float32(0.8944), np.float32(0.8758)] 
2025-02-24 06:57:26.474413: Epoch time: 6.51 s 
2025-02-24 06:57:26.981899:  
2025-02-24 06:57:26.987440: Epoch 166 
2025-02-24 06:57:26.990486: Current learning rate: 0.00375 
2025-02-24 06:57:33.466929: train_loss -0.9547 
2025-02-24 06:57:33.472530: val_loss -0.8332 
2025-02-24 06:57:33.476571: Pseudo dice [np.float32(0.8985), np.float32(0.8794)] 
2025-02-24 06:57:33.480122: Epoch time: 6.49 s 
2025-02-24 06:57:33.990505:  
2025-02-24 06:57:33.995514: Epoch 167 
2025-02-24 06:57:33.998524: Current learning rate: 0.00371 
2025-02-24 06:57:40.494073: train_loss -0.9562 
2025-02-24 06:57:40.500604: val_loss -0.8285 
2025-02-24 06:57:40.504263: Pseudo dice [np.float32(0.8979), np.float32(0.879)] 
2025-02-24 06:57:40.507299: Epoch time: 6.5 s 
2025-02-24 06:57:41.016781:  
2025-02-24 06:57:41.024277: Epoch 168 
2025-02-24 06:57:41.026834: Current learning rate: 0.00367 
2025-02-24 06:57:47.519237: train_loss -0.9565 
2025-02-24 06:57:47.525295: val_loss -0.8304 
2025-02-24 06:57:47.528834: Pseudo dice [np.float32(0.9), np.float32(0.8785)] 
2025-02-24 06:57:47.532542: Epoch time: 6.5 s 
2025-02-24 06:57:48.190922:  
2025-02-24 06:57:48.196505: Epoch 169 
2025-02-24 06:57:48.199540: Current learning rate: 0.00363 
2025-02-24 06:57:54.681384: train_loss -0.9563 
2025-02-24 06:57:54.687484: val_loss -0.8301 
2025-02-24 06:57:54.691061: Pseudo dice [np.float32(0.9), np.float32(0.8811)] 
2025-02-24 06:57:54.694108: Epoch time: 6.49 s 
2025-02-24 06:57:54.697748: Yayy! New best EMA pseudo Dice: 0.8873999714851379 
2025-02-24 06:57:55.248605:  
2025-02-24 06:57:55.254265: Epoch 170 
2025-02-24 06:57:55.258312: Current learning rate: 0.00359 
2025-02-24 06:58:01.731061: train_loss -0.9569 
2025-02-24 06:58:01.737158: val_loss -0.8258 
2025-02-24 06:58:01.739706: Pseudo dice [np.float32(0.896), np.float32(0.8776)] 
2025-02-24 06:58:01.743750: Epoch time: 6.48 s 
2025-02-24 06:58:02.254334:  
2025-02-24 06:58:02.259874: Epoch 171 
2025-02-24 06:58:02.262384: Current learning rate: 0.00355 
2025-02-24 06:58:08.747866: train_loss -0.9568 
2025-02-24 06:58:08.754602: val_loss -0.8249 
2025-02-24 06:58:08.758674: Pseudo dice [np.float32(0.8958), np.float32(0.8764)] 
2025-02-24 06:58:08.762226: Epoch time: 6.5 s 
2025-02-24 06:58:09.271329:  
2025-02-24 06:58:09.277991: Epoch 172 
2025-02-24 06:58:09.281554: Current learning rate: 0.00351 
2025-02-24 06:58:15.769761: train_loss -0.9557 
2025-02-24 06:58:15.775837: val_loss -0.8304 
2025-02-24 06:58:15.779496: Pseudo dice [np.float32(0.8984), np.float32(0.8798)] 
2025-02-24 06:58:15.782548: Epoch time: 6.5 s 
2025-02-24 06:58:16.296775:  
2025-02-24 06:58:16.302293: Epoch 173 
2025-02-24 06:58:16.305800: Current learning rate: 0.00346 
2025-02-24 06:58:22.798133: train_loss -0.9563 
2025-02-24 06:58:22.804236: val_loss -0.8253 
2025-02-24 06:58:22.808296: Pseudo dice [np.float32(0.8959), np.float32(0.878)] 
2025-02-24 06:58:22.810824: Epoch time: 6.5 s 
2025-02-24 06:58:23.322151:  
2025-02-24 06:58:23.328172: Epoch 174 
2025-02-24 06:58:23.330683: Current learning rate: 0.00342 
2025-02-24 06:58:29.842351: train_loss -0.9576 
2025-02-24 06:58:29.847476: val_loss -0.8237 
2025-02-24 06:58:29.851043: Pseudo dice [np.float32(0.8943), np.float32(0.8768)] 
2025-02-24 06:58:29.854641: Epoch time: 6.52 s 
2025-02-24 06:58:30.367429:  
2025-02-24 06:58:30.373531: Epoch 175 
2025-02-24 06:58:30.376590: Current learning rate: 0.00338 
2025-02-24 06:58:36.862686: train_loss -0.9567 
2025-02-24 06:58:36.868811: val_loss -0.8304 
2025-02-24 06:58:36.871844: Pseudo dice [np.float32(0.8989), np.float32(0.8799)] 
2025-02-24 06:58:36.875366: Epoch time: 6.5 s 
2025-02-24 06:58:37.533905:  
2025-02-24 06:58:37.539447: Epoch 176 
2025-02-24 06:58:37.542960: Current learning rate: 0.00334 
2025-02-24 06:58:44.035250: train_loss -0.9556 
2025-02-24 06:58:44.040844: val_loss -0.8291 
2025-02-24 06:58:44.044439: Pseudo dice [np.float32(0.8949), np.float32(0.8774)] 
2025-02-24 06:58:44.048069: Epoch time: 6.5 s 
2025-02-24 06:58:44.559061:  
2025-02-24 06:58:44.564496: Epoch 177 
2025-02-24 06:58:44.568009: Current learning rate: 0.0033 
2025-02-24 06:58:51.045546: train_loss -0.9555 
2025-02-24 06:58:51.051650: val_loss -0.8224 
2025-02-24 06:58:51.054679: Pseudo dice [np.float32(0.8939), np.float32(0.8759)] 
2025-02-24 06:58:51.057725: Epoch time: 6.49 s 
2025-02-24 06:58:51.572948:  
2025-02-24 06:58:51.579965: Epoch 178 
2025-02-24 06:58:51.582973: Current learning rate: 0.00326 
2025-02-24 06:58:58.080772: train_loss -0.9551 
2025-02-24 06:58:58.086489: val_loss -0.8235 
2025-02-24 06:58:58.090535: Pseudo dice [np.float32(0.8947), np.float32(0.8756)] 
2025-02-24 06:58:58.094100: Epoch time: 6.51 s 
2025-02-24 06:58:58.609122:  
2025-02-24 06:58:58.614245: Epoch 179 
2025-02-24 06:58:58.617754: Current learning rate: 0.00322 
2025-02-24 06:59:05.109838: train_loss -0.9561 
2025-02-24 06:59:05.115529: val_loss -0.8253 
2025-02-24 06:59:05.119110: Pseudo dice [np.float32(0.8958), np.float32(0.8764)] 
2025-02-24 06:59:05.122169: Epoch time: 6.5 s 
2025-02-24 06:59:05.639739:  
2025-02-24 06:59:05.645265: Epoch 180 
2025-02-24 06:59:05.648776: Current learning rate: 0.00318 
2025-02-24 06:59:12.161939: train_loss -0.9573 
2025-02-24 06:59:12.166569: val_loss -0.8333 
2025-02-24 06:59:12.171111: Pseudo dice [np.float32(0.9002), np.float32(0.8805)] 
2025-02-24 06:59:12.173661: Epoch time: 6.52 s 
2025-02-24 06:59:12.695283:  
2025-02-24 06:59:12.700293: Epoch 181 
2025-02-24 06:59:12.703813: Current learning rate: 0.00314 
2025-02-24 06:59:19.203433: train_loss -0.9565 
2025-02-24 06:59:19.208996: val_loss -0.8207 
2025-02-24 06:59:19.211506: Pseudo dice [np.float32(0.8936), np.float32(0.8738)] 
2025-02-24 06:59:19.215078: Epoch time: 6.51 s 
2025-02-24 06:59:19.730830:  
2025-02-24 06:59:19.736361: Epoch 182 
2025-02-24 06:59:19.739913: Current learning rate: 0.0031 
2025-02-24 06:59:26.232546: train_loss -0.9581 
2025-02-24 06:59:26.238212: val_loss -0.82 
2025-02-24 06:59:26.241817: Pseudo dice [np.float32(0.8928), np.float32(0.8747)] 
2025-02-24 06:59:26.244879: Epoch time: 6.5 s 
2025-02-24 06:59:26.766644:  
2025-02-24 06:59:26.772727: Epoch 183 
2025-02-24 06:59:26.775779: Current learning rate: 0.00306 
2025-02-24 06:59:33.249593: train_loss -0.9578 
2025-02-24 06:59:33.255413: val_loss -0.8315 
2025-02-24 06:59:33.258968: Pseudo dice [np.float32(0.8988), np.float32(0.8802)] 
2025-02-24 06:59:33.262023: Epoch time: 6.48 s 
2025-02-24 06:59:33.931631:  
2025-02-24 06:59:33.937202: Epoch 184 
2025-02-24 06:59:33.939732: Current learning rate: 0.00302 
2025-02-24 06:59:40.430201: train_loss -0.9565 
2025-02-24 06:59:40.436257: val_loss -0.8226 
2025-02-24 06:59:40.439783: Pseudo dice [np.float32(0.8953), np.float32(0.8743)] 
2025-02-24 06:59:40.442813: Epoch time: 6.5 s 
2025-02-24 06:59:40.956386:  
2025-02-24 06:59:40.961941: Epoch 185 
2025-02-24 06:59:40.964976: Current learning rate: 0.00297 
2025-02-24 06:59:47.468105: train_loss -0.9582 
2025-02-24 06:59:47.474178: val_loss -0.8243 
2025-02-24 06:59:47.477701: Pseudo dice [np.float32(0.8956), np.float32(0.8759)] 
2025-02-24 06:59:47.480803: Epoch time: 6.51 s 
2025-02-24 06:59:47.998576:  
2025-02-24 06:59:48.004722: Epoch 186 
2025-02-24 06:59:48.008276: Current learning rate: 0.00293 
2025-02-24 06:59:54.479567: train_loss -0.9576 
2025-02-24 06:59:54.486142: val_loss -0.8256 
2025-02-24 06:59:54.490186: Pseudo dice [np.float32(0.8954), np.float32(0.8762)] 
2025-02-24 06:59:54.493210: Epoch time: 6.48 s 
2025-02-24 06:59:55.019008:  
2025-02-24 06:59:55.024144: Epoch 187 
2025-02-24 06:59:55.027314: Current learning rate: 0.00289 
2025-02-24 07:00:01.506223: train_loss -0.957 
2025-02-24 07:00:01.511280: val_loss -0.8248 
2025-02-24 07:00:01.515822: Pseudo dice [np.float32(0.8952), np.float32(0.876)] 
2025-02-24 07:00:01.519876: Epoch time: 6.49 s 
2025-02-24 07:00:02.037144:  
2025-02-24 07:00:02.042180: Epoch 188 
2025-02-24 07:00:02.045690: Current learning rate: 0.00285 
2025-02-24 07:00:08.533414: train_loss -0.9575 
2025-02-24 07:00:08.538969: val_loss -0.8223 
2025-02-24 07:00:08.542535: Pseudo dice [np.float32(0.8933), np.float32(0.876)] 
2025-02-24 07:00:08.545657: Epoch time: 6.5 s 
2025-02-24 07:00:09.061201:  
2025-02-24 07:00:09.066765: Epoch 189 
2025-02-24 07:00:09.070456: Current learning rate: 0.00281 
2025-02-24 07:00:15.637435: train_loss -0.9594 
2025-02-24 07:00:15.642977: val_loss -0.8301 
2025-02-24 07:00:15.647021: Pseudo dice [np.float32(0.8975), np.float32(0.8787)] 
2025-02-24 07:00:15.650597: Epoch time: 6.58 s 
2025-02-24 07:00:16.172987:  
2025-02-24 07:00:16.177528: Epoch 190 
2025-02-24 07:00:16.181107: Current learning rate: 0.00277 
2025-02-24 07:00:22.847498: train_loss -0.9583 
2025-02-24 07:00:22.853598: val_loss -0.8194 
2025-02-24 07:00:22.856632: Pseudo dice [np.float32(0.8939), np.float32(0.875)] 
2025-02-24 07:00:22.860160: Epoch time: 6.67 s 
2025-02-24 07:00:23.522962:  
2025-02-24 07:00:23.528546: Epoch 191 
2025-02-24 07:00:23.531588: Current learning rate: 0.00273 
2025-02-24 07:00:30.190763: train_loss -0.9582 
2025-02-24 07:00:30.196425: val_loss -0.8313 
2025-02-24 07:00:30.199555: Pseudo dice [np.float32(0.899), np.float32(0.88)] 
2025-02-24 07:00:30.203154: Epoch time: 6.67 s 
2025-02-24 07:00:30.726099:  
2025-02-24 07:00:30.731162: Epoch 192 
2025-02-24 07:00:30.734701: Current learning rate: 0.00268 
2025-02-24 07:00:37.238773: train_loss -0.9587 
2025-02-24 07:00:37.244824: val_loss -0.8277 
2025-02-24 07:00:37.248372: Pseudo dice [np.float32(0.8982), np.float32(0.8795)] 
2025-02-24 07:00:37.251433: Epoch time: 6.51 s 
2025-02-24 07:00:37.768490:  
2025-02-24 07:00:37.774045: Epoch 193 
2025-02-24 07:00:37.778081: Current learning rate: 0.00264 
2025-02-24 07:00:44.249123: train_loss -0.958 
2025-02-24 07:00:44.255686: val_loss -0.8297 
2025-02-24 07:00:44.259255: Pseudo dice [np.float32(0.8976), np.float32(0.8783)] 
2025-02-24 07:00:44.262493: Epoch time: 6.48 s 
2025-02-24 07:00:44.786671:  
2025-02-24 07:00:44.791704: Epoch 194 
2025-02-24 07:00:44.794970: Current learning rate: 0.0026 
2025-02-24 07:00:51.264265: train_loss -0.9584 
2025-02-24 07:00:51.269856: val_loss -0.8305 
2025-02-24 07:00:51.273406: Pseudo dice [np.float32(0.8988), np.float32(0.8789)] 
2025-02-24 07:00:51.276455: Epoch time: 6.48 s 
2025-02-24 07:00:51.799076:  
2025-02-24 07:00:51.804651: Epoch 195 
2025-02-24 07:00:51.807680: Current learning rate: 0.00256 
2025-02-24 07:00:58.304672: train_loss -0.9576 
2025-02-24 07:00:58.310771: val_loss -0.8233 
2025-02-24 07:00:58.313911: Pseudo dice [np.float32(0.8955), np.float32(0.8765)] 
2025-02-24 07:00:58.317485: Epoch time: 6.51 s 
2025-02-24 07:00:58.841057:  
2025-02-24 07:00:58.846571: Epoch 196 
2025-02-24 07:00:58.849076: Current learning rate: 0.00252 
2025-02-24 07:01:05.332166: train_loss -0.9585 
2025-02-24 07:01:05.337822: val_loss -0.8279 
2025-02-24 07:01:05.343427: Pseudo dice [np.float32(0.898), np.float32(0.8788)] 
2025-02-24 07:01:05.348444: Epoch time: 6.49 s 
2025-02-24 07:01:05.874672:  
2025-02-24 07:01:05.879739: Epoch 197 
2025-02-24 07:01:05.883271: Current learning rate: 0.00248 
2025-02-24 07:01:12.368684: train_loss -0.9587 
2025-02-24 07:01:12.374890: val_loss -0.8185 
2025-02-24 07:01:12.380930: Pseudo dice [np.float32(0.8945), np.float32(0.8751)] 
2025-02-24 07:01:12.384043: Epoch time: 6.5 s 
2025-02-24 07:01:12.905135:  
2025-02-24 07:01:12.911201: Epoch 198 
2025-02-24 07:01:12.914258: Current learning rate: 0.00243 
2025-02-24 07:01:19.408340: train_loss -0.9582 
2025-02-24 07:01:19.415365: val_loss -0.8236 
2025-02-24 07:01:19.418409: Pseudo dice [np.float32(0.8943), np.float32(0.877)] 
2025-02-24 07:01:19.421449: Epoch time: 6.5 s 
2025-02-24 07:01:20.089182:  
2025-02-24 07:01:20.095311: Epoch 199 
2025-02-24 07:01:20.097816: Current learning rate: 0.00239 
2025-02-24 07:01:26.598125: train_loss -0.9595 
2025-02-24 07:01:26.603719: val_loss -0.8258 
2025-02-24 07:01:26.607289: Pseudo dice [np.float32(0.8968), np.float32(0.8785)] 
2025-02-24 07:01:26.610345: Epoch time: 6.51 s 
2025-02-24 07:01:27.165973:  
2025-02-24 07:01:27.171072: Epoch 200 
2025-02-24 07:01:27.174588: Current learning rate: 0.00235 
2025-02-24 07:01:33.652746: train_loss -0.9588 
2025-02-24 07:01:33.658358: val_loss -0.8301 
2025-02-24 07:01:33.661929: Pseudo dice [np.float32(0.8994), np.float32(0.88)] 
2025-02-24 07:01:33.664984: Epoch time: 6.49 s 
2025-02-24 07:01:34.192869:  
2025-02-24 07:01:34.197886: Epoch 201 
2025-02-24 07:01:34.201397: Current learning rate: 0.00231 
2025-02-24 07:01:40.682527: train_loss -0.958 
2025-02-24 07:01:40.688184: val_loss -0.8231 
2025-02-24 07:01:40.691355: Pseudo dice [np.float32(0.8955), np.float32(0.8753)] 
2025-02-24 07:01:40.694998: Epoch time: 6.49 s 
2025-02-24 07:01:41.215590:  
2025-02-24 07:01:41.222105: Epoch 202 
2025-02-24 07:01:41.224614: Current learning rate: 0.00226 
2025-02-24 07:01:47.735079: train_loss -0.96 
2025-02-24 07:01:47.740150: val_loss -0.8248 
2025-02-24 07:01:47.743719: Pseudo dice [np.float32(0.8961), np.float32(0.8772)] 
2025-02-24 07:01:47.746159: Epoch time: 6.52 s 
2025-02-24 07:01:48.274339:  
2025-02-24 07:01:48.279864: Epoch 203 
2025-02-24 07:01:48.283379: Current learning rate: 0.00222 
2025-02-24 07:01:54.760837: train_loss -0.9596 
2025-02-24 07:01:54.766918: val_loss -0.8317 
2025-02-24 07:01:54.771009: Pseudo dice [np.float32(0.8996), np.float32(0.8808)] 
2025-02-24 07:01:54.774063: Epoch time: 6.49 s 
2025-02-24 07:01:55.299484:  
2025-02-24 07:01:55.305070: Epoch 204 
2025-02-24 07:01:55.308118: Current learning rate: 0.00218 
2025-02-24 07:02:01.800234: train_loss -0.9588 
2025-02-24 07:02:01.806227: val_loss -0.8257 
2025-02-24 07:02:01.809796: Pseudo dice [np.float32(0.8972), np.float32(0.8769)] 
2025-02-24 07:02:01.812351: Epoch time: 6.5 s 
2025-02-24 07:02:02.339520:  
2025-02-24 07:02:02.345041: Epoch 205 
2025-02-24 07:02:02.348556: Current learning rate: 0.00214 
2025-02-24 07:02:08.826850: train_loss -0.9595 
2025-02-24 07:02:08.832009: val_loss -0.8277 
2025-02-24 07:02:08.835529: Pseudo dice [np.float32(0.8972), np.float32(0.8767)] 
2025-02-24 07:02:08.838159: Epoch time: 6.49 s 
2025-02-24 07:02:09.479102:  
2025-02-24 07:02:09.485172: Epoch 206 
2025-02-24 07:02:09.488743: Current learning rate: 0.00209 
2025-02-24 07:02:15.986588: train_loss -0.9597 
2025-02-24 07:02:15.992332: val_loss -0.8234 
2025-02-24 07:02:15.995907: Pseudo dice [np.float32(0.8962), np.float32(0.8775)] 
2025-02-24 07:02:15.998990: Epoch time: 6.51 s 
2025-02-24 07:02:16.493630:  
2025-02-24 07:02:16.499185: Epoch 207 
2025-02-24 07:02:16.502699: Current learning rate: 0.00205 
2025-02-24 07:02:22.997857: train_loss -0.9603 
2025-02-24 07:02:23.003165: val_loss -0.8312 
2025-02-24 07:02:23.007184: Pseudo dice [np.float32(0.8982), np.float32(0.8811)] 
2025-02-24 07:02:23.009695: Epoch time: 6.5 s 
2025-02-24 07:02:23.516608:  
2025-02-24 07:02:23.522165: Epoch 208 
2025-02-24 07:02:23.524177: Current learning rate: 0.00201 
2025-02-24 07:02:30.002744: train_loss -0.9591 
2025-02-24 07:02:30.008879: val_loss -0.8248 
2025-02-24 07:02:30.012445: Pseudo dice [np.float32(0.8957), np.float32(0.8769)] 
2025-02-24 07:02:30.015494: Epoch time: 6.49 s 
2025-02-24 07:02:30.512373:  
2025-02-24 07:02:30.517827: Epoch 209 
2025-02-24 07:02:30.520864: Current learning rate: 0.00196 
2025-02-24 07:02:37.019295: train_loss -0.961 
2025-02-24 07:02:37.024885: val_loss -0.8279 
2025-02-24 07:02:37.028897: Pseudo dice [np.float32(0.8992), np.float32(0.8789)] 
2025-02-24 07:02:37.032413: Epoch time: 6.51 s 
2025-02-24 07:02:37.035924: Yayy! New best EMA pseudo Dice: 0.887499988079071 
2025-02-24 07:02:37.570807:  
2025-02-24 07:02:37.575817: Epoch 210 
2025-02-24 07:02:37.579328: Current learning rate: 0.00192 
2025-02-24 07:02:44.067739: train_loss -0.9598 
2025-02-24 07:02:44.074392: val_loss -0.8245 
2025-02-24 07:02:44.077454: Pseudo dice [np.float32(0.8963), np.float32(0.878)] 
2025-02-24 07:02:44.081011: Epoch time: 6.5 s 
2025-02-24 07:02:44.573865:  
2025-02-24 07:02:44.579402: Epoch 211 
2025-02-24 07:02:44.582412: Current learning rate: 0.00188 
2025-02-24 07:02:51.051868: train_loss -0.9599 
2025-02-24 07:02:51.056986: val_loss -0.8157 
2025-02-24 07:02:51.060585: Pseudo dice [np.float32(0.8917), np.float32(0.8712)] 
2025-02-24 07:02:51.064144: Epoch time: 6.48 s 
2025-02-24 07:02:51.563334:  
2025-02-24 07:02:51.568352: Epoch 212 
2025-02-24 07:02:51.570861: Current learning rate: 0.00184 
2025-02-24 07:02:58.055357: train_loss -0.9598 
2025-02-24 07:02:58.061409: val_loss -0.8234 
2025-02-24 07:02:58.064477: Pseudo dice [np.float32(0.8958), np.float32(0.8763)] 
2025-02-24 07:02:58.067584: Epoch time: 6.49 s 
2025-02-24 07:02:58.565698:  
2025-02-24 07:02:58.572217: Epoch 213 
2025-02-24 07:02:58.574724: Current learning rate: 0.00179 
2025-02-24 07:03:05.069220: train_loss -0.9616 
2025-02-24 07:03:05.074866: val_loss -0.8236 
2025-02-24 07:03:05.078415: Pseudo dice [np.float32(0.8959), np.float32(0.8772)] 
2025-02-24 07:03:05.080936: Epoch time: 6.5 s 
2025-02-24 07:03:05.721485:  
2025-02-24 07:03:05.726495: Epoch 214 
2025-02-24 07:03:05.730007: Current learning rate: 0.00175 
2025-02-24 07:03:12.220957: train_loss -0.9599 
2025-02-24 07:03:12.226568: val_loss -0.8268 
2025-02-24 07:03:12.230154: Pseudo dice [np.float32(0.8965), np.float32(0.8799)] 
2025-02-24 07:03:12.233690: Epoch time: 6.5 s 
2025-02-24 07:03:12.728322:  
2025-02-24 07:03:12.733350: Epoch 215 
2025-02-24 07:03:12.735966: Current learning rate: 0.0017 
2025-02-24 07:03:19.217319: train_loss -0.9609 
2025-02-24 07:03:19.222371: val_loss -0.8146 
2025-02-24 07:03:19.225881: Pseudo dice [np.float32(0.8915), np.float32(0.8732)] 
2025-02-24 07:03:19.229913: Epoch time: 6.49 s 
2025-02-24 07:03:19.720338:  
2025-02-24 07:03:19.725851: Epoch 216 
2025-02-24 07:03:19.729363: Current learning rate: 0.00166 
2025-02-24 07:03:26.227118: train_loss -0.9611 
2025-02-24 07:03:26.232697: val_loss -0.8281 
2025-02-24 07:03:26.236203: Pseudo dice [np.float32(0.8983), np.float32(0.8806)] 
2025-02-24 07:03:26.239214: Epoch time: 6.51 s 
2025-02-24 07:03:26.729238:  
2025-02-24 07:03:26.734785: Epoch 217 
2025-02-24 07:03:26.738401: Current learning rate: 0.00162 
2025-02-24 07:03:33.213905: train_loss -0.9613 
2025-02-24 07:03:33.219980: val_loss -0.8215 
2025-02-24 07:03:33.224111: Pseudo dice [np.float32(0.894), np.float32(0.8758)] 
2025-02-24 07:03:33.226635: Epoch time: 6.48 s 
2025-02-24 07:03:33.721781:  
2025-02-24 07:03:33.726758: Epoch 218 
2025-02-24 07:03:33.730270: Current learning rate: 0.00157 
2025-02-24 07:03:40.206980: train_loss -0.9615 
2025-02-24 07:03:40.213084: val_loss -0.8258 
2025-02-24 07:03:40.216749: Pseudo dice [np.float32(0.8971), np.float32(0.8785)] 
2025-02-24 07:03:40.220325: Epoch time: 6.49 s 
2025-02-24 07:03:40.709066:  
2025-02-24 07:03:40.714604: Epoch 219 
2025-02-24 07:03:40.717635: Current learning rate: 0.00153 
2025-02-24 07:03:47.217166: train_loss -0.9605 
2025-02-24 07:03:47.222430: val_loss -0.8259 
2025-02-24 07:03:47.225954: Pseudo dice [np.float32(0.8956), np.float32(0.8781)] 
2025-02-24 07:03:47.229013: Epoch time: 6.51 s 
2025-02-24 07:03:47.719987:  
2025-02-24 07:03:47.725563: Epoch 220 
2025-02-24 07:03:47.729110: Current learning rate: 0.00148 
2025-02-24 07:03:54.218359: train_loss -0.9597 
2025-02-24 07:03:54.224560: val_loss -0.8254 
2025-02-24 07:03:54.228627: Pseudo dice [np.float32(0.8969), np.float32(0.8778)] 
2025-02-24 07:03:54.231668: Epoch time: 6.5 s 
2025-02-24 07:03:54.726191:  
2025-02-24 07:03:54.731790: Epoch 221 
2025-02-24 07:03:54.735333: Current learning rate: 0.00144 
2025-02-24 07:04:01.206783: train_loss -0.9596 
2025-02-24 07:04:01.212873: val_loss -0.8263 
2025-02-24 07:04:01.215917: Pseudo dice [np.float32(0.8973), np.float32(0.8785)] 
2025-02-24 07:04:01.221577: Epoch time: 6.48 s 
2025-02-24 07:04:01.718433:  
2025-02-24 07:04:01.723447: Epoch 222 
2025-02-24 07:04:01.726958: Current learning rate: 0.00139 
2025-02-24 07:04:08.210526: train_loss -0.9611 
2025-02-24 07:04:08.216062: val_loss -0.8296 
2025-02-24 07:04:08.219095: Pseudo dice [np.float32(0.898), np.float32(0.8791)] 
2025-02-24 07:04:08.223108: Epoch time: 6.49 s 
2025-02-24 07:04:08.864058:  
2025-02-24 07:04:08.869601: Epoch 223 
2025-02-24 07:04:08.873169: Current learning rate: 0.00135 
2025-02-24 07:04:15.368439: train_loss -0.9614 
2025-02-24 07:04:15.374020: val_loss -0.8269 
2025-02-24 07:04:15.377569: Pseudo dice [np.float32(0.8969), np.float32(0.879)] 
2025-02-24 07:04:15.380620: Epoch time: 6.5 s 
2025-02-24 07:04:15.866550:  
2025-02-24 07:04:15.873069: Epoch 224 
2025-02-24 07:04:15.875575: Current learning rate: 0.0013 
2025-02-24 07:04:22.354985: train_loss -0.9611 
2025-02-24 07:04:22.361141: val_loss -0.8297 
2025-02-24 07:04:22.364192: Pseudo dice [np.float32(0.8976), np.float32(0.8798)] 
2025-02-24 07:04:22.367228: Epoch time: 6.49 s 
2025-02-24 07:04:22.859327:  
2025-02-24 07:04:22.864356: Epoch 225 
2025-02-24 07:04:22.867987: Current learning rate: 0.00126 
2025-02-24 07:04:29.345267: train_loss -0.9608 
2025-02-24 07:04:29.351410: val_loss -0.824 
2025-02-24 07:04:29.353988: Pseudo dice [np.float32(0.8967), np.float32(0.8771)] 
2025-02-24 07:04:29.357505: Epoch time: 6.49 s 
2025-02-24 07:04:29.855038:  
2025-02-24 07:04:29.860690: Epoch 226 
2025-02-24 07:04:29.864268: Current learning rate: 0.00121 
2025-02-24 07:04:36.364958: train_loss -0.9621 
2025-02-24 07:04:36.371046: val_loss -0.8214 
2025-02-24 07:04:36.375070: Pseudo dice [np.float32(0.896), np.float32(0.8765)] 
2025-02-24 07:04:36.378114: Epoch time: 6.51 s 
2025-02-24 07:04:36.870054:  
2025-02-24 07:04:36.875571: Epoch 227 
2025-02-24 07:04:36.879084: Current learning rate: 0.00117 
2025-02-24 07:04:43.373585: train_loss -0.9632 
2025-02-24 07:04:43.378634: val_loss -0.8222 
2025-02-24 07:04:43.382218: Pseudo dice [np.float32(0.8951), np.float32(0.8755)] 
2025-02-24 07:04:43.385762: Epoch time: 6.5 s 
2025-02-24 07:04:43.887550:  
2025-02-24 07:04:43.893620: Epoch 228 
2025-02-24 07:04:43.896658: Current learning rate: 0.00112 
2025-02-24 07:04:50.362494: train_loss -0.9615 
2025-02-24 07:04:50.367601: val_loss -0.8268 
2025-02-24 07:04:50.371632: Pseudo dice [np.float32(0.8994), np.float32(0.8795)] 
2025-02-24 07:04:50.374175: Epoch time: 6.47 s 
2025-02-24 07:04:50.868531:  
2025-02-24 07:04:50.874603: Epoch 229 
2025-02-24 07:04:50.877133: Current learning rate: 0.00108 
2025-02-24 07:04:57.353746: train_loss -0.962 
2025-02-24 07:04:57.359811: val_loss -0.8262 
2025-02-24 07:04:57.362947: Pseudo dice [np.float32(0.8959), np.float32(0.8771)] 
2025-02-24 07:04:57.366500: Epoch time: 6.49 s 
2025-02-24 07:04:57.858708:  
2025-02-24 07:04:57.864236: Epoch 230 
2025-02-24 07:04:57.867792: Current learning rate: 0.00103 
2025-02-24 07:05:04.351169: train_loss -0.9612 
2025-02-24 07:05:04.357248: val_loss -0.8296 
2025-02-24 07:05:04.360303: Pseudo dice [np.float32(0.8983), np.float32(0.8804)] 
2025-02-24 07:05:04.363343: Epoch time: 6.49 s 
2025-02-24 07:05:05.004392:  
2025-02-24 07:05:05.010452: Epoch 231 
2025-02-24 07:05:05.013505: Current learning rate: 0.00098 
2025-02-24 07:05:11.490916: train_loss -0.9599 
2025-02-24 07:05:11.496040: val_loss -0.828 
2025-02-24 07:05:11.500098: Pseudo dice [np.float32(0.8968), np.float32(0.8776)] 
2025-02-24 07:05:11.503139: Epoch time: 6.49 s 
2025-02-24 07:05:12.000448:  
2025-02-24 07:05:12.005464: Epoch 232 
2025-02-24 07:05:12.009008: Current learning rate: 0.00094 
2025-02-24 07:05:18.482553: train_loss -0.9616 
2025-02-24 07:05:18.488602: val_loss -0.8231 
2025-02-24 07:05:18.492190: Pseudo dice [np.float32(0.8953), np.float32(0.8764)] 
2025-02-24 07:05:18.495216: Epoch time: 6.48 s 
2025-02-24 07:05:18.986617:  
2025-02-24 07:05:18.992647: Epoch 233 
2025-02-24 07:05:18.996158: Current learning rate: 0.00089 
2025-02-24 07:05:25.491304: train_loss -0.9621 
2025-02-24 07:05:25.496403: val_loss -0.8297 
2025-02-24 07:05:25.500436: Pseudo dice [np.float32(0.8989), np.float32(0.8801)] 
2025-02-24 07:05:25.503963: Epoch time: 6.5 s 
2025-02-24 07:05:25.994351:  
2025-02-24 07:05:25.999365: Epoch 234 
2025-02-24 07:05:26.002876: Current learning rate: 0.00084 
2025-02-24 07:05:32.478600: train_loss -0.9629 
2025-02-24 07:05:32.484172: val_loss -0.8234 
2025-02-24 07:05:32.487753: Pseudo dice [np.float32(0.896), np.float32(0.877)] 
2025-02-24 07:05:32.490292: Epoch time: 6.48 s 
2025-02-24 07:05:32.983275:  
2025-02-24 07:05:32.986284: Epoch 235 
2025-02-24 07:05:32.989794: Current learning rate: 0.00079 
2025-02-24 07:05:39.468833: train_loss -0.9635 
2025-02-24 07:05:39.473968: val_loss -0.8168 
2025-02-24 07:05:39.477502: Pseudo dice [np.float32(0.8911), np.float32(0.8718)] 
2025-02-24 07:05:39.481018: Epoch time: 6.49 s 
2025-02-24 07:05:39.973096:  
2025-02-24 07:05:39.979160: Epoch 236 
2025-02-24 07:05:39.982295: Current learning rate: 0.00075 
2025-02-24 07:05:46.477680: train_loss -0.9626 
2025-02-24 07:05:46.482742: val_loss -0.8271 
2025-02-24 07:05:46.486311: Pseudo dice [np.float32(0.8977), np.float32(0.8784)] 
2025-02-24 07:05:46.489440: Epoch time: 6.5 s 
2025-02-24 07:05:46.979556:  
2025-02-24 07:05:46.985087: Epoch 237 
2025-02-24 07:05:46.988629: Current learning rate: 0.0007 
2025-02-24 07:05:53.481447: train_loss -0.9626 
2025-02-24 07:05:53.487579: val_loss -0.8216 
2025-02-24 07:05:53.490690: Pseudo dice [np.float32(0.8944), np.float32(0.876)] 
2025-02-24 07:05:53.493765: Epoch time: 6.5 s 
2025-02-24 07:05:53.986997:  
2025-02-24 07:05:53.993512: Epoch 238 
2025-02-24 07:05:53.997024: Current learning rate: 0.00065 
2025-02-24 07:06:00.478623: train_loss -0.9628 
2025-02-24 07:06:00.484197: val_loss -0.8261 
2025-02-24 07:06:00.487768: Pseudo dice [np.float32(0.8973), np.float32(0.8771)] 
2025-02-24 07:06:00.490915: Epoch time: 6.49 s 
2025-02-24 07:06:00.985125:  
2025-02-24 07:06:00.990188: Epoch 239 
2025-02-24 07:06:00.993784: Current learning rate: 0.0006 
2025-02-24 07:06:07.475479: train_loss -0.9619 
2025-02-24 07:06:07.480548: val_loss -0.8282 
2025-02-24 07:06:07.484661: Pseudo dice [np.float32(0.8973), np.float32(0.8779)] 
2025-02-24 07:06:07.488222: Epoch time: 6.49 s 
2025-02-24 07:06:08.134037:  
2025-02-24 07:06:08.140056: Epoch 240 
2025-02-24 07:06:08.142563: Current learning rate: 0.00055 
2025-02-24 07:06:14.647094: train_loss -0.9617 
2025-02-24 07:06:14.652680: val_loss -0.8267 
2025-02-24 07:06:14.656237: Pseudo dice [np.float32(0.8964), np.float32(0.8768)] 
2025-02-24 07:06:14.659273: Epoch time: 6.51 s 
2025-02-24 07:06:15.160033:  
2025-02-24 07:06:15.165044: Epoch 241 
2025-02-24 07:06:15.168556: Current learning rate: 0.0005 
2025-02-24 07:06:21.666338: train_loss -0.9627 
2025-02-24 07:06:21.671976: val_loss -0.8233 
2025-02-24 07:06:21.674516: Pseudo dice [np.float32(0.8954), np.float32(0.8768)] 
2025-02-24 07:06:21.679094: Epoch time: 6.51 s 
2025-02-24 07:06:22.176138:  
2025-02-24 07:06:22.182657: Epoch 242 
2025-02-24 07:06:22.185163: Current learning rate: 0.00045 
2025-02-24 07:06:28.664601: train_loss -0.963 
2025-02-24 07:06:28.670652: val_loss -0.8209 
2025-02-24 07:06:28.674286: Pseudo dice [np.float32(0.8962), np.float32(0.8765)] 
2025-02-24 07:06:28.677353: Epoch time: 6.49 s 
2025-02-24 07:06:29.179334:  
2025-02-24 07:06:29.185404: Epoch 243 
2025-02-24 07:06:29.189012: Current learning rate: 0.0004 
2025-02-24 07:06:35.678384: train_loss -0.962 
2025-02-24 07:06:35.684479: val_loss -0.8244 
2025-02-24 07:06:35.688073: Pseudo dice [np.float32(0.8963), np.float32(0.8771)] 
2025-02-24 07:06:35.691112: Epoch time: 6.5 s 
2025-02-24 07:06:36.191715:  
2025-02-24 07:06:36.196727: Epoch 244 
2025-02-24 07:06:36.199739: Current learning rate: 0.00035 
2025-02-24 07:06:42.697048: train_loss -0.9618 
2025-02-24 07:06:42.702134: val_loss -0.8272 
2025-02-24 07:06:42.704453: Pseudo dice [np.float32(0.8971), np.float32(0.8786)] 
2025-02-24 07:06:42.708836: Epoch time: 6.51 s 
2025-02-24 07:06:43.213567:  
2025-02-24 07:06:43.220086: Epoch 245 
2025-02-24 07:06:43.222593: Current learning rate: 0.0003 
2025-02-24 07:06:49.693152: train_loss -0.9631 
2025-02-24 07:06:49.698165: val_loss -0.8285 
2025-02-24 07:06:49.701678: Pseudo dice [np.float32(0.8985), np.float32(0.8794)] 
2025-02-24 07:06:49.705690: Epoch time: 6.48 s 
2025-02-24 07:06:50.208359:  
2025-02-24 07:06:50.213912: Epoch 246 
2025-02-24 07:06:50.216450: Current learning rate: 0.00024 
2025-02-24 07:06:56.710051: train_loss -0.9626 
2025-02-24 07:06:56.715874: val_loss -0.8243 
2025-02-24 07:06:56.718697: Pseudo dice [np.float32(0.896), np.float32(0.8773)] 
2025-02-24 07:06:56.722322: Epoch time: 6.5 s 
2025-02-24 07:06:57.225501:  
2025-02-24 07:06:57.231054: Epoch 247 
2025-02-24 07:06:57.234097: Current learning rate: 0.00019 
2025-02-24 07:07:03.741127: train_loss -0.9624 
2025-02-24 07:07:03.746282: val_loss -0.8251 
2025-02-24 07:07:03.750847: Pseudo dice [np.float32(0.8963), np.float32(0.8771)] 
2025-02-24 07:07:03.753411: Epoch time: 6.52 s 
2025-02-24 07:07:04.397519:  
2025-02-24 07:07:04.402540: Epoch 248 
2025-02-24 07:07:04.405557: Current learning rate: 0.00013 
2025-02-24 07:07:10.888645: train_loss -0.9636 
2025-02-24 07:07:10.894238: val_loss -0.8236 
2025-02-24 07:07:10.897787: Pseudo dice [np.float32(0.8945), np.float32(0.8753)] 
2025-02-24 07:07:10.900314: Epoch time: 6.49 s 
2025-02-24 07:07:11.404308:  
2025-02-24 07:07:11.409864: Epoch 249 
2025-02-24 07:07:11.412915: Current learning rate: 7e-05 
2025-02-24 07:07:17.882097: train_loss -0.9626 
2025-02-24 07:07:17.889187: val_loss -0.823 
2025-02-24 07:07:17.892219: Pseudo dice [np.float32(0.8959), np.float32(0.8756)] 
2025-02-24 07:07:17.894763: Epoch time: 6.48 s 
2025-02-24 07:07:18.451038: Training done. 
2025-02-24 07:07:18.512039: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2025-02-24 07:07:18.522038: The split file contains 5 splits. 
2025-02-24 07:07:18.527043: Desired fold for training: 0 
2025-02-24 07:07:18.533045: This split has 208 training and 52 validation cases. 
2025-02-24 07:07:18.537548: predicting hippocampus_017 
2025-02-24 07:07:18.543554: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2025-02-24 07:07:18.631555: predicting hippocampus_019 
2025-02-24 07:07:18.638741: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2025-02-24 07:07:18.669739: predicting hippocampus_033 
2025-02-24 07:07:18.675739: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2025-02-24 07:07:18.695738: predicting hippocampus_035 
2025-02-24 07:07:18.701740: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2025-02-24 07:07:18.722739: predicting hippocampus_037 
2025-02-24 07:07:18.728745: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2025-02-24 07:07:18.749859: predicting hippocampus_049 
2025-02-24 07:07:18.756858: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2025-02-24 07:07:18.777860: predicting hippocampus_052 
2025-02-24 07:07:18.783860: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2025-02-24 07:07:18.805857: predicting hippocampus_065 
2025-02-24 07:07:18.812862: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2025-02-24 07:07:18.836864: predicting hippocampus_083 
2025-02-24 07:07:18.842373: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2025-02-24 07:07:18.866374: predicting hippocampus_088 
2025-02-24 07:07:18.872374: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2025-02-24 07:07:22.823155: predicting hippocampus_090 
2025-02-24 07:07:22.830670: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2025-02-24 07:07:22.880175: predicting hippocampus_092 
2025-02-24 07:07:22.887175: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2025-02-24 07:07:22.936180: predicting hippocampus_095 
2025-02-24 07:07:22.942688: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2025-02-24 07:07:22.990688: predicting hippocampus_107 
2025-02-24 07:07:22.997688: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2025-02-24 07:07:23.047195: predicting hippocampus_108 
2025-02-24 07:07:23.054195: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2025-02-24 07:07:23.102195: predicting hippocampus_123 
2025-02-24 07:07:23.109196: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2025-02-24 07:07:23.153705: predicting hippocampus_125 
2025-02-24 07:07:23.160707: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2025-02-24 07:07:23.215705: predicting hippocampus_157 
2025-02-24 07:07:23.223707: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2025-02-24 07:07:23.256220: predicting hippocampus_164 
2025-02-24 07:07:23.263218: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2025-02-24 07:07:23.355725: predicting hippocampus_169 
2025-02-24 07:07:23.363726: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2025-02-24 07:07:23.390725: predicting hippocampus_175 
2025-02-24 07:07:23.397727: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2025-02-24 07:07:23.423727: predicting hippocampus_185 
2025-02-24 07:07:23.430729: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2025-02-24 07:07:23.458236: predicting hippocampus_190 
2025-02-24 07:07:23.464236: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2025-02-24 07:07:23.492235: predicting hippocampus_194 
2025-02-24 07:07:23.499237: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2025-02-24 07:07:23.528238: predicting hippocampus_204 
2025-02-24 07:07:23.536240: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2025-02-24 07:07:23.565747: predicting hippocampus_205 
2025-02-24 07:07:23.573745: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2025-02-24 07:07:23.601745: predicting hippocampus_210 
2025-02-24 07:07:23.607745: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2025-02-24 07:07:23.635750: predicting hippocampus_217 
2025-02-24 07:07:23.642258: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2025-02-24 07:07:23.670256: predicting hippocampus_219 
2025-02-24 07:07:23.677256: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2025-02-24 07:07:23.705256: predicting hippocampus_229 
2025-02-24 07:07:23.711256: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2025-02-24 07:07:23.739259: predicting hippocampus_244 
2025-02-24 07:07:23.745769: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2025-02-24 07:07:23.790767: predicting hippocampus_261 
2025-02-24 07:07:23.796767: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2025-02-24 07:07:23.841280: predicting hippocampus_264 
2025-02-24 07:07:23.849279: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2025-02-24 07:07:23.877278: predicting hippocampus_277 
2025-02-24 07:07:23.884278: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2025-02-24 07:07:23.932283: predicting hippocampus_280 
2025-02-24 07:07:23.940786: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2025-02-24 07:07:23.966789: predicting hippocampus_286 
2025-02-24 07:07:23.973789: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2025-02-24 07:07:24.019789: predicting hippocampus_288 
2025-02-24 07:07:24.026793: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2025-02-24 07:07:24.075297: predicting hippocampus_289 
2025-02-24 07:07:24.083297: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2025-02-24 07:07:24.112297: predicting hippocampus_296 
2025-02-24 07:07:24.118299: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2025-02-24 07:07:24.146805: predicting hippocampus_305 
2025-02-24 07:07:24.154806: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2025-02-24 07:07:24.182806: predicting hippocampus_308 
2025-02-24 07:07:24.189806: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2025-02-24 07:07:24.219805: predicting hippocampus_317 
2025-02-24 07:07:24.226811: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2025-02-24 07:07:24.253317: predicting hippocampus_327 
2025-02-24 07:07:24.260319: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2025-02-24 07:07:24.288317: predicting hippocampus_330 
2025-02-24 07:07:24.296318: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2025-02-24 07:07:24.324317: predicting hippocampus_332 
2025-02-24 07:07:24.330321: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2025-02-24 07:07:24.357827: predicting hippocampus_338 
2025-02-24 07:07:24.364825: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2025-02-24 07:07:24.409825: predicting hippocampus_349 
2025-02-24 07:07:24.416826: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2025-02-24 07:07:24.443338: predicting hippocampus_350 
2025-02-24 07:07:24.449340: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2025-02-24 07:07:24.478338: predicting hippocampus_356 
2025-02-24 07:07:24.487339: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2025-02-24 07:07:24.517339: predicting hippocampus_358 
2025-02-24 07:07:24.525338: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2025-02-24 07:07:24.554847: predicting hippocampus_374 
2025-02-24 07:07:24.562848: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2025-02-24 07:07:24.591847: predicting hippocampus_394 
2025-02-24 07:07:24.599848: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2025-02-24 07:07:28.254378: Validation complete 
2025-02-24 07:07:28.260379: Mean Validation Dice:  0.4865023456218153 
