2024-12-12 18:55:23.245433: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.33 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-12 18:55:23.250436: self.oversample_foreground_percent 0.3333333333333333 
2024-12-12 18:55:23.253944: do_dummy_2d_data_aug: False 
2024-12-12 18:55:23.257943: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-12 18:55:23.260445: The split file contains 5 splits. 
2024-12-12 18:55:23.263453: Desired fold for training: 0 
2024-12-12 18:55:23.265454: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-12 18:55:29.401704: unpacking dataset... 
2024-12-12 18:55:29.608828: unpacking done... 
2024-12-12 18:55:30.603536:  
2024-12-12 18:55:30.607601: Epoch 0 
2024-12-12 18:55:30.611618: Current learning rate: 0.01 
2024-12-12 18:55:38.035378: train_loss -0.2074 
2024-12-12 18:55:38.039948: val_loss -0.4914 
2024-12-12 18:55:38.043062: Pseudo dice [np.float32(0.6382), np.float32(0.1265)] 
2024-12-12 18:55:38.046118: Epoch time: 7.43 s 
2024-12-12 18:55:38.048649: Yayy! New best EMA pseudo Dice: 0.3822999894618988 
2024-12-12 18:55:38.586560:  
2024-12-12 18:55:38.592091: Epoch 1 
2024-12-12 18:55:38.595221: Current learning rate: 0.00991 
2024-12-12 18:55:45.115292: train_loss -0.6801 
2024-12-12 18:55:45.121378: val_loss -0.7784 
2024-12-12 18:55:45.123946: Pseudo dice [np.float32(0.8376), np.float32(0.837)] 
2024-12-12 18:55:45.127504: Epoch time: 6.53 s 
2024-12-12 18:55:45.130555: Yayy! New best EMA pseudo Dice: 0.4277999997138977 
2024-12-12 18:55:45.724029:  
2024-12-12 18:55:45.729114: Epoch 2 
2024-12-12 18:55:45.731671: Current learning rate: 0.00982 
2024-12-12 18:55:52.239181: train_loss -0.7944 
2024-12-12 18:55:52.244345: val_loss -0.8175 
2024-12-12 18:55:52.247406: Pseudo dice [np.float32(0.8674), np.float32(0.8584)] 
2024-12-12 18:55:52.250452: Epoch time: 6.52 s 
2024-12-12 18:55:52.252980: Yayy! New best EMA pseudo Dice: 0.47130000591278076 
2024-12-12 18:55:52.877568:  
2024-12-12 18:55:52.883109: Epoch 3 
2024-12-12 18:55:52.885621: Current learning rate: 0.00973 
2024-12-12 18:55:59.377375: train_loss -0.8134 
2024-12-12 18:55:59.382939: val_loss -0.8271 
2024-12-12 18:55:59.385993: Pseudo dice [np.float32(0.8809), np.float32(0.8625)] 
2024-12-12 18:55:59.389218: Epoch time: 6.5 s 
2024-12-12 18:55:59.391767: Yayy! New best EMA pseudo Dice: 0.5113999843597412 
2024-12-12 18:55:59.994845:  
2024-12-12 18:55:59.999911: Epoch 4 
2024-12-12 18:56:00.003491: Current learning rate: 0.00964 
2024-12-12 18:56:06.492525: train_loss -0.8182 
2024-12-12 18:56:06.498174: val_loss -0.8292 
2024-12-12 18:56:06.501229: Pseudo dice [np.float32(0.881), np.float32(0.862)] 
2024-12-12 18:56:06.504274: Epoch time: 6.5 s 
2024-12-12 18:56:06.507891: Yayy! New best EMA pseudo Dice: 0.5473999977111816 
2024-12-12 18:56:07.255445:  
2024-12-12 18:56:07.260481: Epoch 5 
2024-12-12 18:56:07.263334: Current learning rate: 0.00955 
2024-12-12 18:56:13.735354: train_loss -0.8267 
2024-12-12 18:56:13.740368: val_loss -0.8295 
2024-12-12 18:56:13.744502: Pseudo dice [np.float32(0.8791), np.float32(0.8651)] 
2024-12-12 18:56:13.747547: Epoch time: 6.48 s 
2024-12-12 18:56:13.750635: Yayy! New best EMA pseudo Dice: 0.5799000263214111 
2024-12-12 18:56:14.337366:  
2024-12-12 18:56:14.342377: Epoch 6 
2024-12-12 18:56:14.345388: Current learning rate: 0.00946 
2024-12-12 18:56:20.848785: train_loss -0.8313 
2024-12-12 18:56:20.853811: val_loss -0.8334 
2024-12-12 18:56:20.857617: Pseudo dice [np.float32(0.8838), np.float32(0.8687)] 
2024-12-12 18:56:20.860659: Epoch time: 6.51 s 
2024-12-12 18:56:20.864187: Yayy! New best EMA pseudo Dice: 0.609499990940094 
2024-12-12 18:56:21.458136:  
2024-12-12 18:56:21.463745: Epoch 7 
2024-12-12 18:56:21.467860: Current learning rate: 0.00937 
2024-12-12 18:56:27.972776: train_loss -0.8357 
2024-12-12 18:56:27.978380: val_loss -0.8328 
2024-12-12 18:56:27.981447: Pseudo dice [np.float32(0.8834), np.float32(0.8641)] 
2024-12-12 18:56:27.984519: Epoch time: 6.51 s 
2024-12-12 18:56:27.987604: Yayy! New best EMA pseudo Dice: 0.6359000205993652 
2024-12-12 18:56:28.643871:  
2024-12-12 18:56:28.649004: Epoch 8 
2024-12-12 18:56:28.652064: Current learning rate: 0.00928 
2024-12-12 18:56:35.181054: train_loss -0.8423 
2024-12-12 18:56:35.186676: val_loss -0.8407 
2024-12-12 18:56:35.189740: Pseudo dice [np.float32(0.888), np.float32(0.8732)] 
2024-12-12 18:56:35.193351: Epoch time: 6.54 s 
2024-12-12 18:56:35.195880: Yayy! New best EMA pseudo Dice: 0.6603999733924866 
2024-12-12 18:56:35.908633:  
2024-12-12 18:56:35.913647: Epoch 9 
2024-12-12 18:56:35.916657: Current learning rate: 0.00919 
2024-12-12 18:56:42.425894: train_loss -0.8413 
2024-12-12 18:56:42.431512: val_loss -0.845 
2024-12-12 18:56:42.434620: Pseudo dice [np.float32(0.8904), np.float32(0.8757)] 
2024-12-12 18:56:42.437801: Epoch time: 6.52 s 
2024-12-12 18:56:42.440876: Yayy! New best EMA pseudo Dice: 0.682699978351593 
2024-12-12 18:56:43.029930:  
2024-12-12 18:56:43.034941: Epoch 10 
2024-12-12 18:56:43.037952: Current learning rate: 0.0091 
2024-12-12 18:56:49.533078: train_loss -0.8439 
2024-12-12 18:56:49.538205: val_loss -0.8443 
2024-12-12 18:56:49.541790: Pseudo dice [np.float32(0.8919), np.float32(0.8756)] 
2024-12-12 18:56:49.544834: Epoch time: 6.5 s 
2024-12-12 18:56:49.547874: Yayy! New best EMA pseudo Dice: 0.7027999758720398 
2024-12-12 18:56:50.177771:  
2024-12-12 18:56:50.183814: Epoch 11 
2024-12-12 18:56:50.186325: Current learning rate: 0.009 
2024-12-12 18:56:56.691058: train_loss -0.848 
2024-12-12 18:56:56.696639: val_loss -0.8331 
2024-12-12 18:56:56.699877: Pseudo dice [np.float32(0.8805), np.float32(0.8681)] 
2024-12-12 18:56:56.703399: Epoch time: 6.51 s 
2024-12-12 18:56:56.706446: Yayy! New best EMA pseudo Dice: 0.7199000120162964 
2024-12-12 18:56:57.301445:  
2024-12-12 18:56:57.307017: Epoch 12 
2024-12-12 18:56:57.310626: Current learning rate: 0.00891 
2024-12-12 18:57:03.806779: train_loss -0.8505 
2024-12-12 18:57:03.812939: val_loss -0.8417 
2024-12-12 18:57:03.815977: Pseudo dice [np.float32(0.8915), np.float32(0.8696)] 
2024-12-12 18:57:03.821014: Epoch time: 6.51 s 
2024-12-12 18:57:03.825552: Yayy! New best EMA pseudo Dice: 0.7360000014305115 
2024-12-12 18:57:04.582277:  
2024-12-12 18:57:04.587837: Epoch 13 
2024-12-12 18:57:04.590399: Current learning rate: 0.00882 
2024-12-12 18:57:11.094087: train_loss -0.8516 
2024-12-12 18:57:11.100678: val_loss -0.842 
2024-12-12 18:57:11.104223: Pseudo dice [np.float32(0.8905), np.float32(0.871)] 
2024-12-12 18:57:11.107840: Epoch time: 6.51 s 
2024-12-12 18:57:11.111434: Yayy! New best EMA pseudo Dice: 0.7505000233650208 
2024-12-12 18:57:11.721770:  
2024-12-12 18:57:11.727340: Epoch 14 
2024-12-12 18:57:11.729930: Current learning rate: 0.00873 
2024-12-12 18:57:18.222015: train_loss -0.8525 
2024-12-12 18:57:18.227625: val_loss -0.8439 
2024-12-12 18:57:18.231687: Pseudo dice [np.float32(0.8911), np.float32(0.8734)] 
2024-12-12 18:57:18.235292: Epoch time: 6.5 s 
2024-12-12 18:57:18.237798: Yayy! New best EMA pseudo Dice: 0.7635999917984009 
2024-12-12 18:57:20.367538:  
2024-12-12 18:57:20.374644: Epoch 15 
2024-12-12 18:57:20.381432: Current learning rate: 0.00864 
2024-12-12 18:57:30.682054: train_loss -0.8526 
2024-12-12 18:57:30.687396: val_loss -0.8496 
2024-12-12 18:57:30.691409: Pseudo dice [np.float32(0.8931), np.float32(0.8802)] 
2024-12-12 18:57:30.694925: Epoch time: 10.32 s 
2024-12-12 18:57:30.698430: Yayy! New best EMA pseudo Dice: 0.7759000062942505 
2024-12-12 18:57:31.344697:  
2024-12-12 18:57:31.351212: Epoch 16 
2024-12-12 18:57:31.354725: Current learning rate: 0.00855 
2024-12-12 18:57:38.092315: train_loss -0.8527 
2024-12-12 18:57:38.098467: val_loss -0.8459 
2024-12-12 18:57:38.102012: Pseudo dice [np.float32(0.8931), np.float32(0.8732)] 
2024-12-12 18:57:38.104544: Epoch time: 6.75 s 
2024-12-12 18:57:38.108591: Yayy! New best EMA pseudo Dice: 0.7867000102996826 
2024-12-12 18:57:38.756907:  
2024-12-12 18:57:38.762503: Epoch 17 
2024-12-12 18:57:38.766560: Current learning rate: 0.00846 
2024-12-12 18:57:45.400202: train_loss -0.855 
2024-12-12 18:57:45.405795: val_loss -0.844 
2024-12-12 18:57:45.409345: Pseudo dice [np.float32(0.8932), np.float32(0.8726)] 
2024-12-12 18:57:45.412895: Epoch time: 6.64 s 
2024-12-12 18:57:45.415936: Yayy! New best EMA pseudo Dice: 0.7962999939918518 
2024-12-12 18:57:46.056509:  
2024-12-12 18:57:46.063025: Epoch 18 
2024-12-12 18:57:46.067534: Current learning rate: 0.00836 
2024-12-12 18:57:52.697407: train_loss -0.856 
2024-12-12 18:57:52.703493: val_loss -0.8525 
2024-12-12 18:57:52.707071: Pseudo dice [np.float32(0.8987), np.float32(0.8797)] 
2024-12-12 18:57:52.710585: Epoch time: 6.64 s 
2024-12-12 18:57:52.713602: Yayy! New best EMA pseudo Dice: 0.8055999875068665 
2024-12-12 18:57:53.436420:  
2024-12-12 18:57:53.441959: Epoch 19 
2024-12-12 18:57:53.445562: Current learning rate: 0.00827 
2024-12-12 18:58:00.134978: train_loss -0.858 
2024-12-12 18:58:00.141120: val_loss -0.8548 
2024-12-12 18:58:00.144137: Pseudo dice [np.float32(0.8978), np.float32(0.8834)] 
2024-12-12 18:58:00.147727: Epoch time: 6.7 s 
2024-12-12 18:58:00.151236: Yayy! New best EMA pseudo Dice: 0.8141000270843506 
2024-12-12 18:58:00.945383:  
2024-12-12 18:58:00.948895: Epoch 20 
2024-12-12 18:58:00.952908: Current learning rate: 0.00818 
2024-12-12 18:58:07.622880: train_loss -0.8592 
2024-12-12 18:58:07.628546: val_loss -0.8529 
2024-12-12 18:58:07.632059: Pseudo dice [np.float32(0.8992), np.float32(0.8816)] 
2024-12-12 18:58:07.636416: Epoch time: 6.68 s 
2024-12-12 18:58:07.638922: Yayy! New best EMA pseudo Dice: 0.8216999769210815 
2024-12-12 18:58:08.551291:  
2024-12-12 18:58:08.557367: Epoch 21 
2024-12-12 18:58:08.560429: Current learning rate: 0.00809 
2024-12-12 18:58:15.189135: train_loss -0.8609 
2024-12-12 18:58:15.197657: val_loss -0.8494 
2024-12-12 18:58:15.201190: Pseudo dice [np.float32(0.8967), np.float32(0.8777)] 
2024-12-12 18:58:15.205748: Epoch time: 6.64 s 
2024-12-12 18:58:15.209258: Yayy! New best EMA pseudo Dice: 0.8282999992370605 
2024-12-12 18:58:15.829268:  
2024-12-12 18:58:15.834783: Epoch 22 
2024-12-12 18:58:15.838336: Current learning rate: 0.008 
2024-12-12 18:58:22.465180: train_loss -0.8594 
2024-12-12 18:58:22.470506: val_loss -0.8466 
2024-12-12 18:58:22.475052: Pseudo dice [np.float32(0.8936), np.float32(0.8755)] 
2024-12-12 18:58:22.478591: Epoch time: 6.64 s 
2024-12-12 18:58:22.482140: Yayy! New best EMA pseudo Dice: 0.833899974822998 
2024-12-12 18:58:23.102497:  
2024-12-12 18:58:23.107530: Epoch 23 
2024-12-12 18:58:23.111161: Current learning rate: 0.0079 
2024-12-12 18:58:29.736164: train_loss -0.8631 
2024-12-12 18:58:29.742065: val_loss -0.8513 
2024-12-12 18:58:29.745577: Pseudo dice [np.float32(0.8973), np.float32(0.8794)] 
2024-12-12 18:58:29.748713: Epoch time: 6.63 s 
2024-12-12 18:58:29.752240: Yayy! New best EMA pseudo Dice: 0.8392999768257141 
2024-12-12 18:58:30.361855:  
2024-12-12 18:58:30.366872: Epoch 24 
2024-12-12 18:58:30.370381: Current learning rate: 0.00781 
2024-12-12 18:58:37.007263: train_loss -0.8635 
2024-12-12 18:58:37.013881: val_loss -0.843 
2024-12-12 18:58:37.018003: Pseudo dice [np.float32(0.8916), np.float32(0.8743)] 
2024-12-12 18:58:37.021052: Epoch time: 6.65 s 
2024-12-12 18:58:37.025090: Yayy! New best EMA pseudo Dice: 0.8436999917030334 
2024-12-12 18:58:37.640750:  
2024-12-12 18:58:37.646826: Epoch 25 
2024-12-12 18:58:37.649886: Current learning rate: 0.00772 
2024-12-12 18:58:44.275239: train_loss -0.8652 
2024-12-12 18:58:44.281437: val_loss -0.8503 
2024-12-12 18:58:44.285042: Pseudo dice [np.float32(0.8969), np.float32(0.8782)] 
2024-12-12 18:58:44.288298: Epoch time: 6.63 s 
2024-12-12 18:58:44.291603: Yayy! New best EMA pseudo Dice: 0.8481000065803528 
2024-12-12 18:58:44.907861:  
2024-12-12 18:58:44.913879: Epoch 26 
2024-12-12 18:58:44.917384: Current learning rate: 0.00763 
2024-12-12 18:58:51.546202: train_loss -0.8647 
2024-12-12 18:58:51.551792: val_loss -0.8533 
2024-12-12 18:58:51.555961: Pseudo dice [np.float32(0.8985), np.float32(0.882)] 
2024-12-12 18:58:51.559529: Epoch time: 6.64 s 
2024-12-12 18:58:51.562062: Yayy! New best EMA pseudo Dice: 0.8522999882698059 
2024-12-12 18:58:52.171056:  
2024-12-12 18:58:52.175785: Epoch 27 
2024-12-12 18:58:52.179293: Current learning rate: 0.00753 
2024-12-12 18:58:58.816536: train_loss -0.8654 
2024-12-12 18:58:58.821739: val_loss -0.8535 
2024-12-12 18:58:58.825746: Pseudo dice [np.float32(0.8994), np.float32(0.8819)] 
2024-12-12 18:58:58.828768: Epoch time: 6.65 s 
2024-12-12 18:58:58.832293: Yayy! New best EMA pseudo Dice: 0.8561000227928162 
2024-12-12 18:58:59.448085:  
2024-12-12 18:58:59.453642: Epoch 28 
2024-12-12 18:58:59.456660: Current learning rate: 0.00744 
2024-12-12 18:59:06.105139: train_loss -0.8672 
2024-12-12 18:59:06.111376: val_loss -0.852 
2024-12-12 18:59:06.115108: Pseudo dice [np.float32(0.898), np.float32(0.8801)] 
2024-12-12 18:59:06.117909: Epoch time: 6.66 s 
2024-12-12 18:59:06.121440: Yayy! New best EMA pseudo Dice: 0.8593999743461609 
2024-12-12 18:59:06.891584:  
2024-12-12 18:59:06.897140: Epoch 29 
2024-12-12 18:59:06.900687: Current learning rate: 0.00735 
2024-12-12 18:59:13.540191: train_loss -0.8662 
2024-12-12 18:59:13.545321: val_loss -0.8454 
2024-12-12 18:59:13.549357: Pseudo dice [np.float32(0.8917), np.float32(0.875)] 
2024-12-12 18:59:13.552907: Epoch time: 6.65 s 
2024-12-12 18:59:13.555943: Yayy! New best EMA pseudo Dice: 0.8618000149726868 
2024-12-12 18:59:14.208148:  
2024-12-12 18:59:14.214705: Epoch 30 
2024-12-12 18:59:14.218343: Current learning rate: 0.00725 
2024-12-12 18:59:20.836073: train_loss -0.8673 
2024-12-12 18:59:20.841622: val_loss -0.8476 
2024-12-12 18:59:20.845667: Pseudo dice [np.float32(0.8952), np.float32(0.8755)] 
2024-12-12 18:59:20.848684: Epoch time: 6.63 s 
2024-12-12 18:59:20.851728: Yayy! New best EMA pseudo Dice: 0.8641999959945679 
2024-12-12 18:59:21.478024:  
2024-12-12 18:59:21.484061: Epoch 31 
2024-12-12 18:59:21.487574: Current learning rate: 0.00716 
2024-12-12 18:59:28.106241: train_loss -0.8691 
2024-12-12 18:59:28.112422: val_loss -0.8535 
2024-12-12 18:59:28.116005: Pseudo dice [np.float32(0.8988), np.float32(0.8821)] 
2024-12-12 18:59:28.119577: Epoch time: 6.63 s 
2024-12-12 18:59:28.122631: Yayy! New best EMA pseudo Dice: 0.8668000102043152 
2024-12-12 18:59:28.754828:  
2024-12-12 18:59:28.761143: Epoch 32 
2024-12-12 18:59:28.764679: Current learning rate: 0.00707 
2024-12-12 18:59:35.414388: train_loss -0.8704 
2024-12-12 18:59:35.419650: val_loss -0.8526 
2024-12-12 18:59:35.422835: Pseudo dice [np.float32(0.8966), np.float32(0.883)] 
2024-12-12 18:59:35.427824: Epoch time: 6.66 s 
2024-12-12 18:59:35.430331: Yayy! New best EMA pseudo Dice: 0.8690999746322632 
2024-12-12 18:59:36.082648:  
2024-12-12 18:59:36.088665: Epoch 33 
2024-12-12 18:59:36.092674: Current learning rate: 0.00697 
2024-12-12 18:59:42.724194: train_loss -0.8703 
2024-12-12 18:59:42.730403: val_loss -0.8503 
2024-12-12 18:59:42.733445: Pseudo dice [np.float32(0.8977), np.float32(0.8781)] 
2024-12-12 18:59:42.737584: Epoch time: 6.64 s 
2024-12-12 18:59:42.740688: Yayy! New best EMA pseudo Dice: 0.8709999918937683 
2024-12-12 18:59:43.367440:  
2024-12-12 18:59:43.372474: Epoch 34 
2024-12-12 18:59:43.376020: Current learning rate: 0.00688 
2024-12-12 18:59:50.007726: train_loss -0.8689 
2024-12-12 18:59:50.013402: val_loss -0.8514 
2024-12-12 18:59:50.016965: Pseudo dice [np.float32(0.8975), np.float32(0.8802)] 
2024-12-12 18:59:50.020553: Epoch time: 6.64 s 
2024-12-12 18:59:50.024089: Yayy! New best EMA pseudo Dice: 0.8727999925613403 
2024-12-12 18:59:50.659102:  
2024-12-12 18:59:50.665184: Epoch 35 
2024-12-12 18:59:50.668720: Current learning rate: 0.00679 
2024-12-12 18:59:57.306881: train_loss -0.8697 
2024-12-12 18:59:57.312941: val_loss -0.8535 
2024-12-12 18:59:57.316454: Pseudo dice [np.float32(0.8993), np.float32(0.8824)] 
2024-12-12 18:59:57.319471: Epoch time: 6.65 s 
2024-12-12 18:59:57.323495: Yayy! New best EMA pseudo Dice: 0.8745999932289124 
2024-12-12 18:59:57.970084:  
2024-12-12 18:59:57.976600: Epoch 36 
2024-12-12 18:59:57.980109: Current learning rate: 0.00669 
2024-12-12 19:00:04.622056: train_loss -0.872 
2024-12-12 19:00:04.627684: val_loss -0.8557 
2024-12-12 19:00:04.631224: Pseudo dice [np.float32(0.9003), np.float32(0.8834)] 
2024-12-12 19:00:04.635249: Epoch time: 6.65 s 
2024-12-12 19:00:04.638310: Yayy! New best EMA pseudo Dice: 0.8762999773025513 
2024-12-12 19:00:05.432096:  
2024-12-12 19:00:05.437609: Epoch 37 
2024-12-12 19:00:05.441119: Current learning rate: 0.0066 
2024-12-12 19:00:12.080086: train_loss -0.8734 
2024-12-12 19:00:12.086298: val_loss -0.8511 
2024-12-12 19:00:12.089327: Pseudo dice [np.float32(0.8978), np.float32(0.8795)] 
2024-12-12 19:00:12.093888: Epoch time: 6.65 s 
2024-12-12 19:00:12.096441: Yayy! New best EMA pseudo Dice: 0.8774999976158142 
2024-12-12 19:00:12.741159:  
2024-12-12 19:00:12.746200: Epoch 38 
2024-12-12 19:00:12.749240: Current learning rate: 0.0065 
2024-12-12 19:00:19.384626: train_loss -0.8729 
2024-12-12 19:00:19.390183: val_loss -0.8454 
2024-12-12 19:00:19.394238: Pseudo dice [np.float32(0.8921), np.float32(0.875)] 
2024-12-12 19:00:19.397403: Epoch time: 6.64 s 
2024-12-12 19:00:19.400967: Yayy! New best EMA pseudo Dice: 0.8780999779701233 
2024-12-12 19:00:20.036532:  
2024-12-12 19:00:20.041945: Epoch 39 
2024-12-12 19:00:20.046086: Current learning rate: 0.00641 
2024-12-12 19:00:26.677071: train_loss -0.8722 
2024-12-12 19:00:26.683247: val_loss -0.8546 
2024-12-12 19:00:26.686813: Pseudo dice [np.float32(0.8993), np.float32(0.8832)] 
2024-12-12 19:00:26.689860: Epoch time: 6.64 s 
2024-12-12 19:00:26.692899: Yayy! New best EMA pseudo Dice: 0.8794000148773193 
2024-12-12 19:00:27.341659:  
2024-12-12 19:00:27.347273: Epoch 40 
2024-12-12 19:00:27.350393: Current learning rate: 0.00631 
2024-12-12 19:00:33.996906: train_loss -0.8747 
2024-12-12 19:00:34.003136: val_loss -0.8504 
2024-12-12 19:00:34.007210: Pseudo dice [np.float32(0.8954), np.float32(0.8799)] 
2024-12-12 19:00:34.010394: Epoch time: 6.66 s 
2024-12-12 19:00:34.013434: Yayy! New best EMA pseudo Dice: 0.880299985408783 
2024-12-12 19:00:34.663860:  
2024-12-12 19:00:34.670895: Epoch 41 
2024-12-12 19:00:34.674404: Current learning rate: 0.00622 
2024-12-12 19:00:41.310482: train_loss -0.8743 
2024-12-12 19:00:41.316333: val_loss -0.8546 
2024-12-12 19:00:41.319948: Pseudo dice [np.float32(0.8994), np.float32(0.8823)] 
2024-12-12 19:00:41.323543: Epoch time: 6.65 s 
2024-12-12 19:00:41.327088: Yayy! New best EMA pseudo Dice: 0.8812999725341797 
2024-12-12 19:00:41.945103:  
2024-12-12 19:00:41.951635: Epoch 42 
2024-12-12 19:00:41.955144: Current learning rate: 0.00612 
2024-12-12 19:00:48.580735: train_loss -0.8752 
2024-12-12 19:00:48.586317: val_loss -0.8485 
2024-12-12 19:00:48.589828: Pseudo dice [np.float32(0.8954), np.float32(0.8794)] 
2024-12-12 19:00:48.593834: Epoch time: 6.64 s 
2024-12-12 19:00:48.596946: Yayy! New best EMA pseudo Dice: 0.8819000124931335 
2024-12-12 19:00:49.217976:  
2024-12-12 19:00:49.223492: Epoch 43 
2024-12-12 19:00:49.227001: Current learning rate: 0.00603 
2024-12-12 19:00:55.860792: train_loss -0.8757 
2024-12-12 19:00:55.866878: val_loss -0.8499 
2024-12-12 19:00:55.870555: Pseudo dice [np.float32(0.8965), np.float32(0.879)] 
2024-12-12 19:00:55.874114: Epoch time: 6.64 s 
2024-12-12 19:00:55.877695: Yayy! New best EMA pseudo Dice: 0.8824999928474426 
2024-12-12 19:00:56.500355:  
2024-12-12 19:00:56.506874: Epoch 44 
2024-12-12 19:00:56.510386: Current learning rate: 0.00593 
2024-12-12 19:01:03.150674: train_loss -0.8782 
2024-12-12 19:01:03.156296: val_loss -0.8495 
2024-12-12 19:01:03.159913: Pseudo dice [np.float32(0.8987), np.float32(0.8787)] 
2024-12-12 19:01:03.163486: Epoch time: 6.65 s 
2024-12-12 19:01:03.167253: Yayy! New best EMA pseudo Dice: 0.8830999732017517 
2024-12-12 19:01:03.937266:  
2024-12-12 19:01:03.942832: Epoch 45 
2024-12-12 19:01:03.946876: Current learning rate: 0.00584 
2024-12-12 19:01:10.583780: train_loss -0.8772 
2024-12-12 19:01:10.590882: val_loss -0.8518 
2024-12-12 19:01:10.594393: Pseudo dice [np.float32(0.8989), np.float32(0.8782)] 
2024-12-12 19:01:10.598444: Epoch time: 6.65 s 
2024-12-12 19:01:10.601491: Yayy! New best EMA pseudo Dice: 0.8837000131607056 
2024-12-12 19:01:11.288129:  
2024-12-12 19:01:11.293666: Epoch 46 
2024-12-12 19:01:11.297177: Current learning rate: 0.00574 
2024-12-12 19:01:17.939819: train_loss -0.8778 
2024-12-12 19:01:17.947920: val_loss -0.8477 
2024-12-12 19:01:17.953007: Pseudo dice [np.float32(0.895), np.float32(0.877)] 
2024-12-12 19:01:17.955563: Epoch time: 6.65 s 
2024-12-12 19:01:17.960147: Yayy! New best EMA pseudo Dice: 0.883899986743927 
2024-12-12 19:01:18.574571:  
2024-12-12 19:01:18.580107: Epoch 47 
2024-12-12 19:01:18.583668: Current learning rate: 0.00565 
2024-12-12 19:01:25.300302: train_loss -0.8792 
2024-12-12 19:01:25.305948: val_loss -0.8505 
2024-12-12 19:01:25.310497: Pseudo dice [np.float32(0.8967), np.float32(0.8786)] 
2024-12-12 19:01:25.313536: Epoch time: 6.73 s 
2024-12-12 19:01:25.317573: Yayy! New best EMA pseudo Dice: 0.8842999935150146 
2024-12-12 19:01:26.104752:  
2024-12-12 19:01:26.110268: Epoch 48 
2024-12-12 19:01:26.113883: Current learning rate: 0.00555 
2024-12-12 19:01:32.785217: train_loss -0.8778 
2024-12-12 19:01:32.790273: val_loss -0.8551 
2024-12-12 19:01:32.794379: Pseudo dice [np.float32(0.8994), np.float32(0.8846)] 
2024-12-12 19:01:32.798211: Epoch time: 6.68 s 
2024-12-12 19:01:32.801951: Yayy! New best EMA pseudo Dice: 0.8849999904632568 
2024-12-12 19:01:33.531521:  
2024-12-12 19:01:33.537063: Epoch 49 
2024-12-12 19:01:33.540568: Current learning rate: 0.00546 
2024-12-12 19:01:40.195747: train_loss -0.8781 
2024-12-12 19:01:40.201827: val_loss -0.8523 
2024-12-12 19:01:40.205884: Pseudo dice [np.float32(0.8989), np.float32(0.883)] 
2024-12-12 19:01:40.209486: Epoch time: 6.67 s 
2024-12-12 19:01:40.250493: Yayy! New best EMA pseudo Dice: 0.8855999708175659 
2024-12-12 19:01:40.886906:  
2024-12-12 19:01:40.893517: Epoch 50 
2024-12-12 19:01:40.896058: Current learning rate: 0.00536 
2024-12-12 19:01:47.568172: train_loss -0.8787 
2024-12-12 19:01:47.574264: val_loss -0.8459 
2024-12-12 19:01:47.577892: Pseudo dice [np.float32(0.8945), np.float32(0.8764)] 
2024-12-12 19:01:47.581995: Epoch time: 6.68 s 
2024-12-12 19:01:48.235547:  
2024-12-12 19:01:48.241062: Epoch 51 
2024-12-12 19:01:48.244575: Current learning rate: 0.00526 
2024-12-12 19:01:54.893948: train_loss -0.8816 
2024-12-12 19:01:54.900126: val_loss -0.8555 
2024-12-12 19:01:54.903695: Pseudo dice [np.float32(0.9005), np.float32(0.8831)] 
2024-12-12 19:01:54.907259: Epoch time: 6.66 s 
2024-12-12 19:01:54.910790: Yayy! New best EMA pseudo Dice: 0.8862000107765198 
2024-12-12 19:01:55.530349:  
2024-12-12 19:01:55.536946: Epoch 52 
2024-12-12 19:01:55.539480: Current learning rate: 0.00517 
2024-12-12 19:02:02.176612: train_loss -0.8811 
2024-12-12 19:02:02.182146: val_loss -0.847 
2024-12-12 19:02:02.185757: Pseudo dice [np.float32(0.8956), np.float32(0.8765)] 
2024-12-12 19:02:02.188868: Epoch time: 6.65 s 
2024-12-12 19:02:02.931746:  
2024-12-12 19:02:02.937262: Epoch 53 
2024-12-12 19:02:02.940772: Current learning rate: 0.00507 
2024-12-12 19:02:09.568856: train_loss -0.8789 
2024-12-12 19:02:09.574494: val_loss -0.8508 
2024-12-12 19:02:09.578116: Pseudo dice [np.float32(0.8971), np.float32(0.8791)] 
2024-12-12 19:02:09.583732: Epoch time: 6.64 s 
2024-12-12 19:02:09.586765: Yayy! New best EMA pseudo Dice: 0.8863999843597412 
2024-12-12 19:02:10.217072:  
2024-12-12 19:02:10.223338: Epoch 54 
2024-12-12 19:02:10.227350: Current learning rate: 0.00497 
2024-12-12 19:02:16.892511: train_loss -0.8828 
2024-12-12 19:02:16.898509: val_loss -0.8416 
2024-12-12 19:02:16.903520: Pseudo dice [np.float32(0.8896), np.float32(0.8747)] 
2024-12-12 19:02:16.907027: Epoch time: 6.68 s 
2024-12-12 19:02:17.473514:  
2024-12-12 19:02:17.478527: Epoch 55 
2024-12-12 19:02:17.483541: Current learning rate: 0.00487 
2024-12-12 19:02:23.983450: train_loss -0.8834 
2024-12-12 19:02:23.988505: val_loss -0.854 
2024-12-12 19:02:23.993585: Pseudo dice [np.float32(0.8984), np.float32(0.884)] 
2024-12-12 19:02:23.997128: Epoch time: 6.51 s 
2024-12-12 19:02:24.001275: Yayy! New best EMA pseudo Dice: 0.8865000009536743 
2024-12-12 19:02:24.607138:  
2024-12-12 19:02:24.613226: Epoch 56 
2024-12-12 19:02:24.617859: Current learning rate: 0.00478 
2024-12-12 19:02:31.107993: train_loss -0.882 
2024-12-12 19:02:31.114046: val_loss -0.8555 
2024-12-12 19:02:31.118146: Pseudo dice [np.float32(0.9009), np.float32(0.883)] 
2024-12-12 19:02:31.122205: Epoch time: 6.5 s 
2024-12-12 19:02:31.125271: Yayy! New best EMA pseudo Dice: 0.8870000243186951 
2024-12-12 19:02:31.728341:  
2024-12-12 19:02:31.734858: Epoch 57 
2024-12-12 19:02:31.738370: Current learning rate: 0.00468 
2024-12-12 19:02:38.211028: train_loss -0.8842 
2024-12-12 19:02:38.216593: val_loss -0.849 
2024-12-12 19:02:38.221136: Pseudo dice [np.float32(0.8954), np.float32(0.8793)] 
2024-12-12 19:02:38.224185: Epoch time: 6.48 s 
2024-12-12 19:02:38.227735: Yayy! New best EMA pseudo Dice: 0.8870999813079834 
2024-12-12 19:02:38.833150:  
2024-12-12 19:02:38.838728: Epoch 58 
2024-12-12 19:02:38.842803: Current learning rate: 0.00458 
2024-12-12 19:02:45.326142: train_loss -0.8828 
2024-12-12 19:02:45.332296: val_loss -0.8489 
2024-12-12 19:02:45.336349: Pseudo dice [np.float32(0.8963), np.float32(0.8788)] 
2024-12-12 19:02:45.340433: Epoch time: 6.49 s 
2024-12-12 19:02:45.342989: Yayy! New best EMA pseudo Dice: 0.8870999813079834 
2024-12-12 19:02:45.955498:  
2024-12-12 19:02:45.961639: Epoch 59 
2024-12-12 19:02:45.965150: Current learning rate: 0.00448 
2024-12-12 19:02:52.441546: train_loss -0.884 
2024-12-12 19:02:52.447607: val_loss -0.848 
2024-12-12 19:02:52.451716: Pseudo dice [np.float32(0.8959), np.float32(0.8788)] 
2024-12-12 19:02:52.455809: Epoch time: 6.49 s 
2024-12-12 19:02:52.458858: Yayy! New best EMA pseudo Dice: 0.8870999813079834 
2024-12-12 19:02:53.229003:  
2024-12-12 19:02:53.235019: Epoch 60 
2024-12-12 19:02:53.239034: Current learning rate: 0.00438 
2024-12-12 19:02:59.699390: train_loss -0.8861 
2024-12-12 19:02:59.704970: val_loss -0.8502 
2024-12-12 19:02:59.709423: Pseudo dice [np.float32(0.8971), np.float32(0.8788)] 
2024-12-12 19:02:59.712995: Epoch time: 6.47 s 
2024-12-12 19:02:59.716545: Yayy! New best EMA pseudo Dice: 0.8871999979019165 
2024-12-12 19:03:00.333538:  
2024-12-12 19:03:00.340106: Epoch 61 
2024-12-12 19:03:00.344191: Current learning rate: 0.00429 
2024-12-12 19:03:06.819089: train_loss -0.8841 
2024-12-12 19:03:06.825751: val_loss -0.8475 
2024-12-12 19:03:06.829328: Pseudo dice [np.float32(0.8955), np.float32(0.8773)] 
2024-12-12 19:03:06.832879: Epoch time: 6.49 s 
2024-12-12 19:03:07.407974:  
2024-12-12 19:03:07.413630: Epoch 62 
2024-12-12 19:03:07.417671: Current learning rate: 0.00419 
2024-12-12 19:03:13.907685: train_loss -0.8869 
2024-12-12 19:03:13.915149: val_loss -0.8474 
2024-12-12 19:03:13.919184: Pseudo dice [np.float32(0.8946), np.float32(0.8763)] 
2024-12-12 19:03:13.922233: Epoch time: 6.5 s 
2024-12-12 19:03:14.508628:  
2024-12-12 19:03:14.514205: Epoch 63 
2024-12-12 19:03:14.519330: Current learning rate: 0.00409 
2024-12-12 19:03:21.001806: train_loss -0.8867 
2024-12-12 19:03:21.010970: val_loss -0.8475 
2024-12-12 19:03:21.016049: Pseudo dice [np.float32(0.8951), np.float32(0.8791)] 
2024-12-12 19:03:21.019593: Epoch time: 6.49 s 
2024-12-12 19:03:21.594451:  
2024-12-12 19:03:21.599993: Epoch 64 
2024-12-12 19:03:21.603689: Current learning rate: 0.00399 
2024-12-12 19:03:28.087653: train_loss -0.8855 
2024-12-12 19:03:28.093850: val_loss -0.853 
2024-12-12 19:03:28.097416: Pseudo dice [np.float32(0.9008), np.float32(0.8808)] 
2024-12-12 19:03:28.099957: Epoch time: 6.49 s 
2024-12-12 19:03:28.117233: Yayy! New best EMA pseudo Dice: 0.8873999714851379 
2024-12-12 19:03:28.731988:  
2024-12-12 19:03:28.738031: Epoch 65 
2024-12-12 19:03:28.742146: Current learning rate: 0.00389 
2024-12-12 19:03:35.238143: train_loss -0.887 
2024-12-12 19:03:35.242996: val_loss -0.8466 
2024-12-12 19:03:35.248063: Pseudo dice [np.float32(0.8941), np.float32(0.8782)] 
2024-12-12 19:03:35.250605: Epoch time: 6.51 s 
2024-12-12 19:03:35.839512:  
2024-12-12 19:03:35.844523: Epoch 66 
2024-12-12 19:03:35.848536: Current learning rate: 0.00379 
2024-12-12 19:03:42.342804: train_loss -0.8876 
2024-12-12 19:03:42.348452: val_loss -0.8498 
2024-12-12 19:03:42.351486: Pseudo dice [np.float32(0.8966), np.float32(0.8793)] 
2024-12-12 19:03:42.354542: Epoch time: 6.5 s 
2024-12-12 19:03:42.934682:  
2024-12-12 19:03:42.940294: Epoch 67 
2024-12-12 19:03:42.943357: Current learning rate: 0.00369 
2024-12-12 19:03:49.431833: train_loss -0.8883 
2024-12-12 19:03:49.438471: val_loss -0.8456 
2024-12-12 19:03:49.442026: Pseudo dice [np.float32(0.8944), np.float32(0.8757)] 
2024-12-12 19:03:49.445083: Epoch time: 6.5 s 
2024-12-12 19:03:50.031949:  
2024-12-12 19:03:50.037546: Epoch 68 
2024-12-12 19:03:50.040553: Current learning rate: 0.00359 
2024-12-12 19:03:56.519472: train_loss -0.8897 
2024-12-12 19:03:56.524590: val_loss -0.8478 
2024-12-12 19:03:56.528100: Pseudo dice [np.float32(0.8937), np.float32(0.8808)] 
2024-12-12 19:03:56.531605: Epoch time: 6.49 s 
2024-12-12 19:03:57.290316:  
2024-12-12 19:03:57.294859: Epoch 69 
2024-12-12 19:03:57.297887: Current learning rate: 0.00349 
2024-12-12 19:04:03.802303: train_loss -0.8897 
2024-12-12 19:04:03.807822: val_loss -0.853 
2024-12-12 19:04:03.811334: Pseudo dice [np.float32(0.9001), np.float32(0.883)] 
2024-12-12 19:04:03.813384: Epoch time: 6.51 s 
2024-12-12 19:04:03.817921: Yayy! New best EMA pseudo Dice: 0.8876000046730042 
2024-12-12 19:04:04.530943:  
2024-12-12 19:04:04.537463: Epoch 70 
2024-12-12 19:04:04.540975: Current learning rate: 0.00338 
2024-12-12 19:04:11.059160: train_loss -0.8896 
2024-12-12 19:04:11.064705: val_loss -0.8481 
2024-12-12 19:04:11.067745: Pseudo dice [np.float32(0.896), np.float32(0.8787)] 
2024-12-12 19:04:11.070790: Epoch time: 6.53 s 
2024-12-12 19:04:11.743929:  
2024-12-12 19:04:11.749465: Epoch 71 
2024-12-12 19:04:11.752099: Current learning rate: 0.00328 
2024-12-12 19:04:18.260869: train_loss -0.8899 
2024-12-12 19:04:18.265954: val_loss -0.8543 
2024-12-12 19:04:18.268992: Pseudo dice [np.float32(0.9008), np.float32(0.8832)] 
2024-12-12 19:04:18.272589: Epoch time: 6.52 s 
2024-12-12 19:04:18.275644: Yayy! New best EMA pseudo Dice: 0.8880000114440918 
2024-12-12 19:04:18.898470:  
2024-12-12 19:04:18.903514: Epoch 72 
2024-12-12 19:04:18.906617: Current learning rate: 0.00318 
2024-12-12 19:04:25.371505: train_loss -0.8913 
2024-12-12 19:04:25.377618: val_loss -0.8441 
2024-12-12 19:04:25.381512: Pseudo dice [np.float32(0.8938), np.float32(0.8767)] 
2024-12-12 19:04:25.384591: Epoch time: 6.47 s 
2024-12-12 19:04:25.969614:  
2024-12-12 19:04:25.975191: Epoch 73 
2024-12-12 19:04:25.977748: Current learning rate: 0.00308 
2024-12-12 19:04:32.442927: train_loss -0.8899 
2024-12-12 19:04:32.449446: val_loss -0.8441 
2024-12-12 19:04:32.451954: Pseudo dice [np.float32(0.8934), np.float32(0.8752)] 
2024-12-12 19:04:32.455466: Epoch time: 6.47 s 
2024-12-12 19:04:33.043134:  
2024-12-12 19:04:33.048726: Epoch 74 
2024-12-12 19:04:33.051753: Current learning rate: 0.00297 
2024-12-12 19:04:39.545488: train_loss -0.8898 
2024-12-12 19:04:39.552170: val_loss -0.8514 
2024-12-12 19:04:39.554675: Pseudo dice [np.float32(0.8983), np.float32(0.8814)] 
2024-12-12 19:04:39.558721: Epoch time: 6.5 s 
2024-12-12 19:04:40.147942:  
2024-12-12 19:04:40.153044: Epoch 75 
2024-12-12 19:04:40.155601: Current learning rate: 0.00287 
2024-12-12 19:04:46.672602: train_loss -0.8899 
2024-12-12 19:04:46.678255: val_loss -0.8473 
2024-12-12 19:04:46.682444: Pseudo dice [np.float32(0.895), np.float32(0.8794)] 
2024-12-12 19:04:46.685526: Epoch time: 6.53 s 
2024-12-12 19:04:47.560704:  
2024-12-12 19:04:47.565717: Epoch 76 
2024-12-12 19:04:47.569230: Current learning rate: 0.00277 
2024-12-12 19:04:54.059927: train_loss -0.8932 
2024-12-12 19:04:54.067099: val_loss -0.8457 
2024-12-12 19:04:54.070169: Pseudo dice [np.float32(0.8945), np.float32(0.8781)] 
2024-12-12 19:04:54.072711: Epoch time: 6.5 s 
2024-12-12 19:04:54.755399:  
2024-12-12 19:04:54.760458: Epoch 77 
2024-12-12 19:04:54.763530: Current learning rate: 0.00266 
2024-12-12 19:05:01.241444: train_loss -0.8927 
2024-12-12 19:05:01.247030: val_loss -0.8508 
2024-12-12 19:05:01.250148: Pseudo dice [np.float32(0.8978), np.float32(0.8809)] 
2024-12-12 19:05:01.253279: Epoch time: 6.49 s 
2024-12-12 19:05:01.844383:  
2024-12-12 19:05:01.849961: Epoch 78 
2024-12-12 19:05:01.853003: Current learning rate: 0.00256 
2024-12-12 19:05:08.350646: train_loss -0.8915 
2024-12-12 19:05:08.356233: val_loss -0.8504 
2024-12-12 19:05:08.359263: Pseudo dice [np.float32(0.8984), np.float32(0.8796)] 
2024-12-12 19:05:08.362299: Epoch time: 6.51 s 
2024-12-12 19:05:08.956765:  
2024-12-12 19:05:08.961796: Epoch 79 
2024-12-12 19:05:08.964200: Current learning rate: 0.00245 
2024-12-12 19:05:15.436364: train_loss -0.8931 
2024-12-12 19:05:15.441802: val_loss -0.8413 
2024-12-12 19:05:15.444424: Pseudo dice [np.float32(0.8918), np.float32(0.8731)] 
2024-12-12 19:05:15.447952: Epoch time: 6.48 s 
2024-12-12 19:05:16.040711:  
2024-12-12 19:05:16.045754: Epoch 80 
2024-12-12 19:05:16.049775: Current learning rate: 0.00235 
2024-12-12 19:05:22.543579: train_loss -0.8934 
2024-12-12 19:05:22.550667: val_loss -0.8522 
2024-12-12 19:05:22.553240: Pseudo dice [np.float32(0.8991), np.float32(0.8809)] 
2024-12-12 19:05:22.556270: Epoch time: 6.5 s 
2024-12-12 19:05:23.150738:  
2024-12-12 19:05:23.155658: Epoch 81 
2024-12-12 19:05:23.159100: Current learning rate: 0.00224 
2024-12-12 19:05:29.639677: train_loss -0.8939 
2024-12-12 19:05:29.645705: val_loss -0.8514 
2024-12-12 19:05:29.648725: Pseudo dice [np.float32(0.8983), np.float32(0.8822)] 
2024-12-12 19:05:29.652240: Epoch time: 6.49 s 
2024-12-12 19:05:30.248852:  
2024-12-12 19:05:30.254452: Epoch 82 
2024-12-12 19:05:30.258038: Current learning rate: 0.00214 
2024-12-12 19:05:36.750987: train_loss -0.8946 
2024-12-12 19:05:36.756098: val_loss -0.8489 
2024-12-12 19:05:36.759610: Pseudo dice [np.float32(0.8966), np.float32(0.8806)] 
2024-12-12 19:05:36.762644: Epoch time: 6.5 s 
2024-12-12 19:05:37.320981:  
2024-12-12 19:05:37.326066: Epoch 83 
2024-12-12 19:05:37.328624: Current learning rate: 0.00203 
2024-12-12 19:05:43.813260: train_loss -0.8959 
2024-12-12 19:05:43.818909: val_loss -0.8486 
2024-12-12 19:05:43.822473: Pseudo dice [np.float32(0.897), np.float32(0.8794)] 
2024-12-12 19:05:43.825510: Epoch time: 6.49 s 
2024-12-12 19:05:44.545569:  
2024-12-12 19:05:44.550700: Epoch 84 
2024-12-12 19:05:44.553761: Current learning rate: 0.00192 
2024-12-12 19:05:51.011539: train_loss -0.8948 
2024-12-12 19:05:51.017140: val_loss -0.8487 
2024-12-12 19:05:51.020189: Pseudo dice [np.float32(0.8971), np.float32(0.8793)] 
2024-12-12 19:05:51.023231: Epoch time: 6.47 s 
2024-12-12 19:05:51.580248:  
2024-12-12 19:05:51.585290: Epoch 85 
2024-12-12 19:05:51.588287: Current learning rate: 0.00181 
2024-12-12 19:05:58.075127: train_loss -0.8957 
2024-12-12 19:05:58.082761: val_loss -0.848 
2024-12-12 19:05:58.088946: Pseudo dice [np.float32(0.8956), np.float32(0.8787)] 
2024-12-12 19:05:58.093032: Epoch time: 6.5 s 
2024-12-12 19:05:58.707537:  
2024-12-12 19:05:58.713109: Epoch 86 
2024-12-12 19:05:58.715660: Current learning rate: 0.0017 
2024-12-12 19:06:05.190241: train_loss -0.897 
2024-12-12 19:06:05.196265: val_loss -0.8501 
2024-12-12 19:06:05.199027: Pseudo dice [np.float32(0.8979), np.float32(0.8806)] 
2024-12-12 19:06:05.201576: Epoch time: 6.48 s 
2024-12-12 19:06:05.205658: Yayy! New best EMA pseudo Dice: 0.8880000114440918 
2024-12-12 19:06:05.794187:  
2024-12-12 19:06:05.799814: Epoch 87 
2024-12-12 19:06:05.802870: Current learning rate: 0.00159 
2024-12-12 19:06:12.265790: train_loss -0.8975 
2024-12-12 19:06:12.271091: val_loss -0.852 
2024-12-12 19:06:12.274664: Pseudo dice [np.float32(0.8999), np.float32(0.8823)] 
2024-12-12 19:06:12.277744: Epoch time: 6.47 s 
2024-12-12 19:06:12.280792: Yayy! New best EMA pseudo Dice: 0.8883000016212463 
2024-12-12 19:06:12.873267:  
2024-12-12 19:06:12.878361: Epoch 88 
2024-12-12 19:06:12.881401: Current learning rate: 0.00148 
2024-12-12 19:06:19.357521: train_loss -0.8986 
2024-12-12 19:06:19.362537: val_loss -0.8523 
2024-12-12 19:06:19.365045: Pseudo dice [np.float32(0.8982), np.float32(0.8819)] 
2024-12-12 19:06:19.368568: Epoch time: 6.48 s 
2024-12-12 19:06:19.372091: Yayy! New best EMA pseudo Dice: 0.8884999752044678 
2024-12-12 19:06:19.969790:  
2024-12-12 19:06:19.974810: Epoch 89 
2024-12-12 19:06:19.977824: Current learning rate: 0.00137 
2024-12-12 19:06:26.456948: train_loss -0.8966 
2024-12-12 19:06:26.464522: val_loss -0.8455 
2024-12-12 19:06:26.469612: Pseudo dice [np.float32(0.8949), np.float32(0.8762)] 
2024-12-12 19:06:26.472665: Epoch time: 6.49 s 
2024-12-12 19:06:27.027255:  
2024-12-12 19:06:27.032326: Epoch 90 
2024-12-12 19:06:27.035336: Current learning rate: 0.00126 
2024-12-12 19:06:33.538628: train_loss -0.8976 
2024-12-12 19:06:33.545328: val_loss -0.8488 
2024-12-12 19:06:33.548410: Pseudo dice [np.float32(0.8961), np.float32(0.8801)] 
2024-12-12 19:06:33.551488: Epoch time: 6.51 s 
2024-12-12 19:06:34.107950:  
2024-12-12 19:06:34.112963: Epoch 91 
2024-12-12 19:06:34.116475: Current learning rate: 0.00115 
2024-12-12 19:06:40.590497: train_loss -0.8984 
2024-12-12 19:06:40.595589: val_loss -0.8502 
2024-12-12 19:06:40.598696: Pseudo dice [np.float32(0.8983), np.float32(0.8811)] 
2024-12-12 19:06:40.601753: Epoch time: 6.48 s 
2024-12-12 19:06:41.317078:  
2024-12-12 19:06:41.323162: Epoch 92 
2024-12-12 19:06:41.326239: Current learning rate: 0.00103 
2024-12-12 19:06:47.798667: train_loss -0.8976 
2024-12-12 19:06:47.804350: val_loss -0.8504 
2024-12-12 19:06:47.807918: Pseudo dice [np.float32(0.8981), np.float32(0.8815)] 
2024-12-12 19:06:47.810946: Epoch time: 6.48 s 
2024-12-12 19:06:48.371778:  
2024-12-12 19:06:48.376798: Epoch 93 
2024-12-12 19:06:48.380310: Current learning rate: 0.00091 
2024-12-12 19:06:54.863925: train_loss -0.8984 
2024-12-12 19:06:54.869517: val_loss -0.8418 
2024-12-12 19:06:54.872677: Pseudo dice [np.float32(0.8908), np.float32(0.8758)] 
2024-12-12 19:06:54.876274: Epoch time: 6.49 s 
2024-12-12 19:06:55.440206:  
2024-12-12 19:06:55.445249: Epoch 94 
2024-12-12 19:06:55.448027: Current learning rate: 0.00079 
2024-12-12 19:07:01.929237: train_loss -0.8981 
2024-12-12 19:07:01.934803: val_loss -0.8418 
2024-12-12 19:07:01.937834: Pseudo dice [np.float32(0.8927), np.float32(0.8742)] 
2024-12-12 19:07:01.940872: Epoch time: 6.49 s 
2024-12-12 19:07:02.500687:  
2024-12-12 19:07:02.505700: Epoch 95 
2024-12-12 19:07:02.509213: Current learning rate: 0.00067 
2024-12-12 19:07:08.996412: train_loss -0.8978 
2024-12-12 19:07:09.002187: val_loss -0.8507 
2024-12-12 19:07:09.005750: Pseudo dice [np.float32(0.899), np.float32(0.8806)] 
2024-12-12 19:07:09.008260: Epoch time: 6.5 s 
2024-12-12 19:07:09.566104:  
2024-12-12 19:07:09.571117: Epoch 96 
2024-12-12 19:07:09.573625: Current learning rate: 0.00055 
2024-12-12 19:07:16.071115: train_loss -0.8985 
2024-12-12 19:07:16.077171: val_loss -0.8506 
2024-12-12 19:07:16.079905: Pseudo dice [np.float32(0.8988), np.float32(0.8812)] 
2024-12-12 19:07:16.083487: Epoch time: 6.51 s 
2024-12-12 19:07:16.646039:  
2024-12-12 19:07:16.652054: Epoch 97 
2024-12-12 19:07:16.655563: Current learning rate: 0.00043 
2024-12-12 19:07:23.134661: train_loss -0.8986 
2024-12-12 19:07:23.139400: val_loss -0.8459 
2024-12-12 19:07:23.142447: Pseudo dice [np.float32(0.8947), np.float32(0.8784)] 
2024-12-12 19:07:23.145494: Epoch time: 6.49 s 
2024-12-12 19:07:23.714735:  
2024-12-12 19:07:23.720306: Epoch 98 
2024-12-12 19:07:23.723920: Current learning rate: 0.0003 
2024-12-12 19:07:30.195780: train_loss -0.8997 
2024-12-12 19:07:30.201339: val_loss -0.8458 
2024-12-12 19:07:30.204886: Pseudo dice [np.float32(0.8952), np.float32(0.8774)] 
2024-12-12 19:07:30.207917: Epoch time: 6.48 s 
2024-12-12 19:07:30.774926:  
2024-12-12 19:07:30.779941: Epoch 99 
2024-12-12 19:07:30.782953: Current learning rate: 0.00016 
2024-12-12 19:07:37.245138: train_loss -0.9001 
2024-12-12 19:07:37.250734: val_loss -0.8448 
2024-12-12 19:07:37.254324: Pseudo dice [np.float32(0.8945), np.float32(0.8766)] 
2024-12-12 19:07:37.256914: Epoch time: 6.47 s 
2024-12-12 19:07:38.051361: Training done. 
2024-12-12 19:07:38.086275: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-12 19:07:38.093273: The split file contains 5 splits. 
2024-12-12 19:07:38.100615: Desired fold for training: 0 
2024-12-12 19:07:38.107126: This split has 208 training and 52 validation cases. 
2024-12-12 19:07:38.113126: predicting hippocampus_017 
2024-12-12 19:07:38.118166: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-12 19:07:38.210815: predicting hippocampus_019 
2024-12-12 19:07:38.217324: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-12 19:07:38.256395: predicting hippocampus_033 
2024-12-12 19:07:38.262899: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-12 19:07:38.287918: predicting hippocampus_035 
2024-12-12 19:07:38.292918: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-12 19:07:38.316983: predicting hippocampus_037 
2024-12-12 19:07:38.323487: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-12 19:07:38.349041: predicting hippocampus_049 
2024-12-12 19:07:38.354549: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-12 19:07:38.379135: predicting hippocampus_052 
2024-12-12 19:07:38.385275: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-12 19:07:38.410091: predicting hippocampus_065 
2024-12-12 19:07:38.417400: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-12 19:07:38.441538: predicting hippocampus_083 
2024-12-12 19:07:38.449067: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-12 19:07:38.474109: predicting hippocampus_088 
2024-12-12 19:07:38.481109: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-12 19:07:41.921685: predicting hippocampus_090 
2024-12-12 19:07:41.928225: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-12 19:07:41.971502: predicting hippocampus_092 
2024-12-12 19:07:41.977821: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-12 19:07:42.021514: predicting hippocampus_095 
2024-12-12 19:07:42.028026: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-12 19:07:42.087112: predicting hippocampus_107 
2024-12-12 19:07:42.115648: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-12 19:07:42.178705: predicting hippocampus_108 
2024-12-12 19:07:42.193721: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-12 19:07:42.255799: predicting hippocampus_123 
2024-12-12 19:07:42.272307: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-12 19:07:42.315857: predicting hippocampus_125 
2024-12-12 19:07:42.321856: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-12 19:07:42.400935: predicting hippocampus_157 
2024-12-12 19:07:42.408444: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-12 19:07:42.441478: predicting hippocampus_164 
2024-12-12 19:07:42.448989: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-12 19:07:42.538556: predicting hippocampus_169 
2024-12-12 19:07:42.545063: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-12 19:07:42.577589: predicting hippocampus_175 
2024-12-12 19:07:42.584091: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-12 19:07:42.614630: predicting hippocampus_185 
2024-12-12 19:07:42.621633: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-12 19:07:42.649677: predicting hippocampus_190 
2024-12-12 19:07:42.657189: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-12 19:07:42.687228: predicting hippocampus_194 
2024-12-12 19:07:42.694732: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-12 19:07:42.726269: predicting hippocampus_204 
2024-12-12 19:07:42.733269: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-12 19:07:42.760305: predicting hippocampus_205 
2024-12-12 19:07:42.767817: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-12 19:07:42.795343: predicting hippocampus_210 
2024-12-12 19:07:42.802346: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-12 19:07:42.830872: predicting hippocampus_217 
2024-12-12 19:07:42.837383: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-12 19:07:42.865910: predicting hippocampus_219 
2024-12-12 19:07:42.873412: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-12 19:07:42.902438: predicting hippocampus_229 
2024-12-12 19:07:42.910948: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-12 19:07:42.939476: predicting hippocampus_244 
2024-12-12 19:07:42.946988: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-12 19:07:42.975512: predicting hippocampus_261 
2024-12-12 19:07:42.982516: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-12 19:07:43.028058: predicting hippocampus_264 
2024-12-12 19:07:43.034566: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-12 19:07:43.064092: predicting hippocampus_277 
2024-12-12 19:07:43.070099: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-12 19:07:43.115649: predicting hippocampus_280 
2024-12-12 19:07:43.122648: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-12 19:07:43.152177: predicting hippocampus_286 
2024-12-12 19:07:43.158688: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-12 19:07:43.205223: predicting hippocampus_288 
2024-12-12 19:07:43.220736: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-12 19:07:43.264776: predicting hippocampus_289 
2024-12-12 19:07:43.271778: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-12 19:07:43.300303: predicting hippocampus_296 
2024-12-12 19:07:43.307813: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-12 19:07:43.336909: predicting hippocampus_305 
2024-12-12 19:07:43.344414: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-12 19:07:43.373445: predicting hippocampus_308 
2024-12-12 19:07:43.380451: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-12 19:07:43.410981: predicting hippocampus_317 
2024-12-12 19:07:43.417491: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-12 19:07:43.446519: predicting hippocampus_327 
2024-12-12 19:07:43.454024: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-12 19:07:43.482049: predicting hippocampus_330 
2024-12-12 19:07:43.500075: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-12 19:07:43.550143: predicting hippocampus_332 
2024-12-12 19:07:43.557657: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-12 19:07:43.589048: predicting hippocampus_338 
2024-12-12 19:07:43.596561: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-12 19:07:43.641030: predicting hippocampus_349 
2024-12-12 19:07:43.648044: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-12 19:07:43.679615: predicting hippocampus_350 
2024-12-12 19:07:43.687125: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-12 19:07:43.716654: predicting hippocampus_356 
2024-12-12 19:07:43.724157: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-12 19:07:43.754198: predicting hippocampus_358 
2024-12-12 19:07:43.763709: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-12 19:07:43.791735: predicting hippocampus_374 
2024-12-12 19:07:43.801245: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-12 19:07:43.830780: predicting hippocampus_394 
2024-12-12 19:07:43.838290: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-12 19:07:47.399380: Validation complete 
2024-12-12 19:07:47.404893: Mean Validation Dice:  0.8921404382068822 
