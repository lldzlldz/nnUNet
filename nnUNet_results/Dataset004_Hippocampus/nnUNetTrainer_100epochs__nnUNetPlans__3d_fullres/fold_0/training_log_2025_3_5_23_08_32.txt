
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-05 23:08:32.351640: do_dummy_2d_data_aug: False 
2025-03-05 23:08:32.354640: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2025-03-05 23:08:32.364638: The split file contains 5 splits. 
2025-03-05 23:08:32.369637: Desired fold for training: 0 
2025-03-05 23:08:32.373639: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2025-03-05 23:08:38.919985: unpacking dataset... 
2025-03-05 23:08:39.116986: unpacking done... 
2025-03-05 23:08:41.138990:  
2025-03-05 23:08:41.144535: Epoch 0 
2025-03-05 23:08:41.148048: Current learning rate: 0.01 
2025-03-05 23:08:48.645900: train_loss -0.2004 
2025-03-05 23:08:48.651498: val_loss -0.4776 
2025-03-05 23:08:48.654508: Pseudo dice [np.float32(0.3066), np.float32(0.5773)] 
2025-03-05 23:08:48.658020: Epoch time: 7.51 s 
2025-03-05 23:08:48.660905: Yayy! New best EMA pseudo Dice: 0.44190001487731934 
2025-03-05 23:08:49.121569:  
2025-03-05 23:08:49.126080: Epoch 1 
2025-03-05 23:08:49.129092: Current learning rate: 0.00991 
2025-03-05 23:08:55.777256: train_loss -0.6109 
2025-03-05 23:08:55.782821: val_loss -0.7973 
2025-03-05 23:08:55.785923: Pseudo dice [np.float32(0.8535), np.float32(0.844)] 
2025-03-05 23:08:55.788962: Epoch time: 6.66 s 
2025-03-05 23:08:55.792601: Yayy! New best EMA pseudo Dice: 0.48260000348091125 
2025-03-05 23:08:56.310476:  
2025-03-05 23:08:56.316995: Epoch 2 
2025-03-05 23:08:56.320502: Current learning rate: 0.00982 
2025-03-05 23:09:03.014307: train_loss -0.7919 
2025-03-05 23:09:03.021021: val_loss -0.8071 
2025-03-05 23:09:03.023733: Pseudo dice [np.float32(0.8593), np.float32(0.848)] 
2025-03-05 23:09:03.027256: Epoch time: 6.7 s 
2025-03-05 23:09:03.031900: Yayy! New best EMA pseudo Dice: 0.5196999907493591 
2025-03-05 23:09:03.581087:  
2025-03-05 23:09:03.587601: Epoch 3 
2025-03-05 23:09:03.590107: Current learning rate: 0.00973 
2025-03-05 23:09:10.242548: train_loss -0.8102 
2025-03-05 23:09:10.247878: val_loss -0.8185 
2025-03-05 23:09:10.251967: Pseudo dice [np.float32(0.871), np.float32(0.8562)] 
2025-03-05 23:09:10.255015: Epoch time: 6.66 s 
2025-03-05 23:09:10.258450: Yayy! New best EMA pseudo Dice: 0.554099977016449 
2025-03-05 23:09:10.788056:  
2025-03-05 23:09:10.793574: Epoch 4 
2025-03-05 23:09:10.796082: Current learning rate: 0.00964 
2025-03-05 23:09:17.424975: train_loss -0.822 
2025-03-05 23:09:17.430039: val_loss -0.8321 
2025-03-05 23:09:17.434059: Pseudo dice [np.float32(0.8813), np.float32(0.866)] 
2025-03-05 23:09:17.437195: Epoch time: 6.64 s 
2025-03-05 23:09:17.440711: Yayy! New best EMA pseudo Dice: 0.5860999822616577 
2025-03-05 23:09:18.100073:  
2025-03-05 23:09:18.105691: Epoch 5 
2025-03-05 23:09:18.108226: Current learning rate: 0.00955 
2025-03-05 23:09:24.720074: train_loss -0.8276 
2025-03-05 23:09:24.726173: val_loss -0.8208 
2025-03-05 23:09:24.729763: Pseudo dice [np.float32(0.8702), np.float32(0.8605)] 
2025-03-05 23:09:24.732827: Epoch time: 6.62 s 
2025-03-05 23:09:24.735873: Yayy! New best EMA pseudo Dice: 0.6140000224113464 
2025-03-05 23:09:25.245636:  
2025-03-05 23:09:25.250728: Epoch 6 
2025-03-05 23:09:25.254237: Current learning rate: 0.00946 
2025-03-05 23:09:31.868402: train_loss -0.8321 
2025-03-05 23:09:31.874703: val_loss -0.8365 
2025-03-05 23:09:31.878993: Pseudo dice [np.float32(0.885), np.float32(0.8701)] 
2025-03-05 23:09:31.882497: Epoch time: 6.62 s 
2025-03-05 23:09:31.885508: Yayy! New best EMA pseudo Dice: 0.6403999924659729 
2025-03-05 23:09:32.405917:  
2025-03-05 23:09:32.412046: Epoch 7 
2025-03-05 23:09:32.415559: Current learning rate: 0.00937 
2025-03-05 23:09:39.044616: train_loss -0.8376 
2025-03-05 23:09:39.049731: val_loss -0.8359 
2025-03-05 23:09:39.053271: Pseudo dice [np.float32(0.8869), np.float32(0.868)] 
2025-03-05 23:09:39.055288: Epoch time: 6.64 s 
2025-03-05 23:09:39.059946: Yayy! New best EMA pseudo Dice: 0.6640999913215637 
2025-03-05 23:09:39.590245:  
2025-03-05 23:09:39.595306: Epoch 8 
2025-03-05 23:09:39.598860: Current learning rate: 0.00928 
2025-03-05 23:09:46.227101: train_loss -0.841 
2025-03-05 23:09:46.233671: val_loss -0.8399 
2025-03-05 23:09:46.237230: Pseudo dice [np.float32(0.8864), np.float32(0.8717)] 
2025-03-05 23:09:46.240320: Epoch time: 6.64 s 
2025-03-05 23:09:46.243877: Yayy! New best EMA pseudo Dice: 0.6855999827384949 
2025-03-05 23:09:46.781603:  
2025-03-05 23:09:46.786617: Epoch 9 
2025-03-05 23:09:46.791129: Current learning rate: 0.00919 
2025-03-05 23:09:53.410799: train_loss -0.8409 
2025-03-05 23:09:53.415382: val_loss -0.8405 
2025-03-05 23:09:53.419433: Pseudo dice [np.float32(0.8882), np.float32(0.8724)] 
2025-03-05 23:09:53.422981: Epoch time: 6.63 s 
2025-03-05 23:09:53.426019: Yayy! New best EMA pseudo Dice: 0.7049999833106995 
2025-03-05 23:09:53.943628:  
2025-03-05 23:09:53.950141: Epoch 10 
2025-03-05 23:09:53.953655: Current learning rate: 0.0091 
2025-03-05 23:10:00.541129: train_loss -0.844 
2025-03-05 23:10:00.546717: val_loss -0.8392 
2025-03-05 23:10:00.550747: Pseudo dice [np.float32(0.8874), np.float32(0.8708)] 
2025-03-05 23:10:00.554287: Epoch time: 6.6 s 
2025-03-05 23:10:00.557802: Yayy! New best EMA pseudo Dice: 0.7224000096321106 
2025-03-05 23:10:01.083983:  
2025-03-05 23:10:01.090034: Epoch 11 
2025-03-05 23:10:01.094142: Current learning rate: 0.009 
2025-03-05 23:10:07.689801: train_loss -0.846 
2025-03-05 23:10:07.695352: val_loss -0.8395 
2025-03-05 23:10:07.700045: Pseudo dice [np.float32(0.8888), np.float32(0.8716)] 
2025-03-05 23:10:07.703645: Epoch time: 6.61 s 
2025-03-05 23:10:07.707204: Yayy! New best EMA pseudo Dice: 0.7382000088691711 
2025-03-05 23:10:08.228930:  
2025-03-05 23:10:08.235509: Epoch 12 
2025-03-05 23:10:08.239166: Current learning rate: 0.00891 
2025-03-05 23:10:14.843276: train_loss -0.8486 
2025-03-05 23:10:14.848858: val_loss -0.8448 
2025-03-05 23:10:14.852518: Pseudo dice [np.float32(0.8912), np.float32(0.8752)] 
2025-03-05 23:10:14.856044: Epoch time: 6.61 s 
2025-03-05 23:10:14.859627: Yayy! New best EMA pseudo Dice: 0.7526999711990356 
2025-03-05 23:10:15.537316:  
2025-03-05 23:10:15.542877: Epoch 13 
2025-03-05 23:10:15.546987: Current learning rate: 0.00882 
2025-03-05 23:10:22.164592: train_loss -0.8505 
2025-03-05 23:10:22.171205: val_loss -0.8471 
2025-03-05 23:10:22.174797: Pseudo dice [np.float32(0.8935), np.float32(0.8766)] 
2025-03-05 23:10:22.177922: Epoch time: 6.63 s 
2025-03-05 23:10:22.181474: Yayy! New best EMA pseudo Dice: 0.765999972820282 
2025-03-05 23:10:22.736453:  
2025-03-05 23:10:22.742047: Epoch 14 
2025-03-05 23:10:22.745620: Current learning rate: 0.00873 
2025-03-05 23:10:29.350715: train_loss -0.8524 
2025-03-05 23:10:29.356831: val_loss -0.8425 
2025-03-05 23:10:29.360874: Pseudo dice [np.float32(0.8923), np.float32(0.8691)] 
2025-03-05 23:10:29.364430: Epoch time: 6.61 s 
2025-03-05 23:10:29.367994: Yayy! New best EMA pseudo Dice: 0.777400016784668 
2025-03-05 23:10:29.901712:  
2025-03-05 23:10:29.907250: Epoch 15 
2025-03-05 23:10:29.910794: Current learning rate: 0.00864 
2025-03-05 23:10:36.502137: train_loss -0.8524 
2025-03-05 23:10:36.507599: val_loss -0.8505 
2025-03-05 23:10:36.510608: Pseudo dice [np.float32(0.8968), np.float32(0.878)] 
2025-03-05 23:10:36.513633: Epoch time: 6.6 s 
2025-03-05 23:10:36.518208: Yayy! New best EMA pseudo Dice: 0.7883999943733215 
2025-03-05 23:10:37.054546:  
2025-03-05 23:10:37.061136: Epoch 16 
2025-03-05 23:10:37.063794: Current learning rate: 0.00855 
2025-03-05 23:10:43.685486: train_loss -0.856 
2025-03-05 23:10:43.691608: val_loss -0.8463 
2025-03-05 23:10:43.695204: Pseudo dice [np.float32(0.8933), np.float32(0.8744)] 
2025-03-05 23:10:43.698249: Epoch time: 6.63 s 
2025-03-05 23:10:43.702857: Yayy! New best EMA pseudo Dice: 0.7979999780654907 
2025-03-05 23:10:44.243403:  
2025-03-05 23:10:44.249213: Epoch 17 
2025-03-05 23:10:44.252800: Current learning rate: 0.00846 
2025-03-05 23:10:50.894332: train_loss -0.858 
2025-03-05 23:10:50.899977: val_loss -0.8494 
2025-03-05 23:10:50.904513: Pseudo dice [np.float32(0.8966), np.float32(0.8769)] 
2025-03-05 23:10:50.907856: Epoch time: 6.65 s 
2025-03-05 23:10:50.911868: Yayy! New best EMA pseudo Dice: 0.8068000078201294 
2025-03-05 23:10:51.455519:  
2025-03-05 23:10:51.461086: Epoch 18 
2025-03-05 23:10:51.465669: Current learning rate: 0.00836 
2025-03-05 23:10:58.075897: train_loss -0.8579 
2025-03-05 23:10:58.081563: val_loss -0.8471 
2025-03-05 23:10:58.085160: Pseudo dice [np.float32(0.8929), np.float32(0.8783)] 
2025-03-05 23:10:58.088750: Epoch time: 6.62 s 
2025-03-05 23:10:58.091834: Yayy! New best EMA pseudo Dice: 0.8147000074386597 
2025-03-05 23:10:58.640717:  
2025-03-05 23:10:58.646230: Epoch 19 
2025-03-05 23:10:58.650743: Current learning rate: 0.00827 
2025-03-05 23:11:05.256645: train_loss -0.858 
2025-03-05 23:11:05.263709: val_loss -0.852 
2025-03-05 23:11:05.266751: Pseudo dice [np.float32(0.8981), np.float32(0.88)] 
2025-03-05 23:11:05.270278: Epoch time: 6.62 s 
2025-03-05 23:11:05.274368: Yayy! New best EMA pseudo Dice: 0.8222000002861023 
2025-03-05 23:11:05.821964:  
2025-03-05 23:11:05.827993: Epoch 20 
2025-03-05 23:11:05.832049: Current learning rate: 0.00818 
2025-03-05 23:11:12.435333: train_loss -0.8611 
2025-03-05 23:11:12.440924: val_loss -0.8495 
2025-03-05 23:11:12.445084: Pseudo dice [np.float32(0.8963), np.float32(0.8783)] 
2025-03-05 23:11:12.448145: Epoch time: 6.61 s 
2025-03-05 23:11:12.452184: Yayy! New best EMA pseudo Dice: 0.8287000060081482 
2025-03-05 23:11:13.144633:  
2025-03-05 23:11:13.150156: Epoch 21 
2025-03-05 23:11:13.153669: Current learning rate: 0.00809 
2025-03-05 23:11:19.736754: train_loss -0.8616 
2025-03-05 23:11:19.743360: val_loss -0.8483 
2025-03-05 23:11:19.746954: Pseudo dice [np.float32(0.8952), np.float32(0.8763)] 
2025-03-05 23:11:19.750638: Epoch time: 6.59 s 
2025-03-05 23:11:19.755241: Yayy! New best EMA pseudo Dice: 0.8343999981880188 
2025-03-05 23:11:20.276803:  
2025-03-05 23:11:20.282830: Epoch 22 
2025-03-05 23:11:20.287856: Current learning rate: 0.008 
2025-03-05 23:11:26.891760: train_loss -0.8623 
2025-03-05 23:11:26.898939: val_loss -0.847 
2025-03-05 23:11:26.903473: Pseudo dice [np.float32(0.8931), np.float32(0.8778)] 
2025-03-05 23:11:26.907513: Epoch time: 6.62 s 
2025-03-05 23:11:26.911027: Yayy! New best EMA pseudo Dice: 0.8395000100135803 
2025-03-05 23:11:27.434448:  
2025-03-05 23:11:27.439976: Epoch 23 
2025-03-05 23:11:27.443494: Current learning rate: 0.0079 
2025-03-05 23:11:34.074041: train_loss -0.8639 
2025-03-05 23:11:34.080058: val_loss -0.8428 
2025-03-05 23:11:34.084068: Pseudo dice [np.float32(0.8904), np.float32(0.8734)] 
2025-03-05 23:11:34.087582: Epoch time: 6.64 s 
2025-03-05 23:11:34.091095: Yayy! New best EMA pseudo Dice: 0.8436999917030334 
2025-03-05 23:11:34.607316:  
2025-03-05 23:11:34.613836: Epoch 24 
2025-03-05 23:11:34.617343: Current learning rate: 0.00781 
2025-03-05 23:11:41.237873: train_loss -0.8661 
2025-03-05 23:11:41.244047: val_loss -0.8488 
2025-03-05 23:11:41.248159: Pseudo dice [np.float32(0.8961), np.float32(0.8789)] 
2025-03-05 23:11:41.251204: Epoch time: 6.63 s 
2025-03-05 23:11:41.255793: Yayy! New best EMA pseudo Dice: 0.8481000065803528 
2025-03-05 23:11:41.776717:  
2025-03-05 23:11:41.782815: Epoch 25 
2025-03-05 23:11:41.786349: Current learning rate: 0.00772 
2025-03-05 23:11:48.386647: train_loss -0.8655 
2025-03-05 23:11:48.393196: val_loss -0.8516 
2025-03-05 23:11:48.397389: Pseudo dice [np.float32(0.8972), np.float32(0.8787)] 
2025-03-05 23:11:48.401410: Epoch time: 6.61 s 
2025-03-05 23:11:48.405922: Yayy! New best EMA pseudo Dice: 0.8521000146865845 
2025-03-05 23:11:48.927410:  
2025-03-05 23:11:48.932962: Epoch 26 
2025-03-05 23:11:48.937038: Current learning rate: 0.00763 
2025-03-05 23:11:55.542711: train_loss -0.8687 
2025-03-05 23:11:55.548268: val_loss -0.8457 
2025-03-05 23:11:55.552111: Pseudo dice [np.float32(0.8936), np.float32(0.8743)] 
2025-03-05 23:11:55.555684: Epoch time: 6.62 s 
2025-03-05 23:11:55.559290: Yayy! New best EMA pseudo Dice: 0.8553000092506409 
2025-03-05 23:11:56.085287:  
2025-03-05 23:11:56.091338: Epoch 27 
2025-03-05 23:11:56.095497: Current learning rate: 0.00753 
2025-03-05 23:12:02.707943: train_loss -0.8661 
2025-03-05 23:12:02.714087: val_loss -0.8468 
2025-03-05 23:12:02.718149: Pseudo dice [np.float32(0.8943), np.float32(0.8756)] 
2025-03-05 23:12:02.721191: Epoch time: 6.62 s 
2025-03-05 23:12:02.725037: Yayy! New best EMA pseudo Dice: 0.8582000136375427 
2025-03-05 23:12:03.254030:  
2025-03-05 23:12:03.260064: Epoch 28 
2025-03-05 23:12:03.264876: Current learning rate: 0.00744 
2025-03-05 23:12:09.866365: train_loss -0.8688 
2025-03-05 23:12:09.872416: val_loss -0.8464 
2025-03-05 23:12:09.876425: Pseudo dice [np.float32(0.8932), np.float32(0.8761)] 
2025-03-05 23:12:09.880949: Epoch time: 6.61 s 
2025-03-05 23:12:09.884963: Yayy! New best EMA pseudo Dice: 0.8608999848365784 
2025-03-05 23:12:10.417464:  
2025-03-05 23:12:10.423017: Epoch 29 
2025-03-05 23:12:10.427532: Current learning rate: 0.00735 
2025-03-05 23:12:17.020104: train_loss -0.8694 
2025-03-05 23:12:17.028262: val_loss -0.8518 
2025-03-05 23:12:17.032778: Pseudo dice [np.float32(0.8962), np.float32(0.8806)] 
2025-03-05 23:12:17.037801: Epoch time: 6.6 s 
2025-03-05 23:12:17.041891: Yayy! New best EMA pseudo Dice: 0.8636000156402588 
2025-03-05 23:12:17.727963:  
2025-03-05 23:12:17.733551: Epoch 30 
2025-03-05 23:12:17.737662: Current learning rate: 0.00725 
2025-03-05 23:12:24.335390: train_loss -0.8678 
2025-03-05 23:12:24.341547: val_loss -0.8532 
2025-03-05 23:12:24.346424: Pseudo dice [np.float32(0.8989), np.float32(0.8808)] 
2025-03-05 23:12:24.350667: Epoch time: 6.61 s 
2025-03-05 23:12:24.353677: Yayy! New best EMA pseudo Dice: 0.8662999868392944 
2025-03-05 23:12:24.903283:  
2025-03-05 23:12:24.908303: Epoch 31 
2025-03-05 23:12:24.912813: Current learning rate: 0.00716 
2025-03-05 23:12:31.523802: train_loss -0.8693 
2025-03-05 23:12:31.529371: val_loss -0.8483 
2025-03-05 23:12:31.533417: Pseudo dice [np.float32(0.8946), np.float32(0.8777)] 
2025-03-05 23:12:31.537461: Epoch time: 6.62 s 
2025-03-05 23:12:31.541016: Yayy! New best EMA pseudo Dice: 0.8682000041007996 
2025-03-05 23:12:32.067015:  
2025-03-05 23:12:32.072602: Epoch 32 
2025-03-05 23:12:32.076681: Current learning rate: 0.00707 
2025-03-05 23:12:38.696715: train_loss -0.871 
2025-03-05 23:12:38.702939: val_loss -0.8522 
2025-03-05 23:12:38.707025: Pseudo dice [np.float32(0.8999), np.float32(0.8792)] 
2025-03-05 23:12:38.710623: Epoch time: 6.63 s 
2025-03-05 23:12:38.714183: Yayy! New best EMA pseudo Dice: 0.8704000115394592 
2025-03-05 23:12:39.248273:  
2025-03-05 23:12:39.253815: Epoch 33 
2025-03-05 23:12:39.256847: Current learning rate: 0.00697 
2025-03-05 23:12:45.848293: train_loss -0.8726 
2025-03-05 23:12:45.854426: val_loss -0.8525 
2025-03-05 23:12:45.858525: Pseudo dice [np.float32(0.8989), np.float32(0.8799)] 
2025-03-05 23:12:45.862104: Epoch time: 6.6 s 
2025-03-05 23:12:45.866217: Yayy! New best EMA pseudo Dice: 0.8723000288009644 
2025-03-05 23:12:46.402120:  
2025-03-05 23:12:46.407190: Epoch 34 
2025-03-05 23:12:46.411752: Current learning rate: 0.00688 
2025-03-05 23:12:53.007201: train_loss -0.8716 
2025-03-05 23:12:53.013790: val_loss -0.8476 
2025-03-05 23:12:53.018468: Pseudo dice [np.float32(0.8957), np.float32(0.8749)] 
2025-03-05 23:12:53.022596: Epoch time: 6.61 s 
2025-03-05 23:12:53.026165: Yayy! New best EMA pseudo Dice: 0.8736000061035156 
2025-03-05 23:12:53.564606:  
2025-03-05 23:12:53.570661: Epoch 35 
2025-03-05 23:12:53.574693: Current learning rate: 0.00679 
2025-03-05 23:13:00.173910: train_loss -0.8748 
2025-03-05 23:13:00.180022: val_loss -0.8517 
2025-03-05 23:13:00.183574: Pseudo dice [np.float32(0.8976), np.float32(0.879)] 
2025-03-05 23:13:00.187184: Epoch time: 6.61 s 
2025-03-05 23:13:00.191364: Yayy! New best EMA pseudo Dice: 0.8751000165939331 
2025-03-05 23:13:00.732506:  
2025-03-05 23:13:00.739103: Epoch 36 
2025-03-05 23:13:00.743154: Current learning rate: 0.00669 
2025-03-05 23:13:07.356091: train_loss -0.8751 
2025-03-05 23:13:07.361753: val_loss -0.8449 
2025-03-05 23:13:07.366792: Pseudo dice [np.float32(0.8907), np.float32(0.8765)] 
2025-03-05 23:13:07.369855: Epoch time: 6.62 s 
2025-03-05 23:13:07.373955: Yayy! New best EMA pseudo Dice: 0.8758999705314636 
2025-03-05 23:13:08.053674:  
2025-03-05 23:13:08.060412: Epoch 37 
2025-03-05 23:13:08.064470: Current learning rate: 0.0066 
2025-03-05 23:13:14.655031: train_loss -0.8754 
2025-03-05 23:13:14.660654: val_loss -0.8441 
2025-03-05 23:13:14.665353: Pseudo dice [np.float32(0.8926), np.float32(0.8738)] 
2025-03-05 23:13:14.668940: Epoch time: 6.6 s 
2025-03-05 23:13:14.672528: Yayy! New best EMA pseudo Dice: 0.8766000270843506 
2025-03-05 23:13:15.213438:  
2025-03-05 23:13:15.218952: Epoch 38 
2025-03-05 23:13:15.222464: Current learning rate: 0.0065 
2025-03-05 23:13:21.844067: train_loss -0.8767 
2025-03-05 23:13:21.850121: val_loss -0.8456 
2025-03-05 23:13:21.853686: Pseudo dice [np.float32(0.8923), np.float32(0.8767)] 
2025-03-05 23:13:21.857745: Epoch time: 6.63 s 
2025-03-05 23:13:21.861817: Yayy! New best EMA pseudo Dice: 0.8773999810218811 
2025-03-05 23:13:22.420782:  
2025-03-05 23:13:22.426803: Epoch 39 
2025-03-05 23:13:22.430807: Current learning rate: 0.00641 
2025-03-05 23:13:29.044672: train_loss -0.8769 
2025-03-05 23:13:29.050787: val_loss -0.8493 
2025-03-05 23:13:29.054831: Pseudo dice [np.float32(0.8963), np.float32(0.8786)] 
2025-03-05 23:13:29.057866: Epoch time: 6.62 s 
2025-03-05 23:13:29.062467: Yayy! New best EMA pseudo Dice: 0.8784000277519226 
2025-03-05 23:13:29.614721:  
2025-03-05 23:13:29.621246: Epoch 40 
2025-03-05 23:13:29.625255: Current learning rate: 0.00631 
2025-03-05 23:13:36.212420: train_loss -0.877 
2025-03-05 23:13:36.219109: val_loss -0.8488 
2025-03-05 23:13:36.223757: Pseudo dice [np.float32(0.8971), np.float32(0.875)] 
2025-03-05 23:13:36.229887: Epoch time: 6.6 s 
2025-03-05 23:13:36.235450: Yayy! New best EMA pseudo Dice: 0.8791999816894531 
2025-03-05 23:13:36.793153:  
2025-03-05 23:13:36.799899: Epoch 41 
2025-03-05 23:13:36.806016: Current learning rate: 0.00622 
2025-03-05 23:13:43.418524: train_loss -0.8761 
2025-03-05 23:13:43.424258: val_loss -0.8513 
2025-03-05 23:13:43.427277: Pseudo dice [np.float32(0.8987), np.float32(0.8791)] 
2025-03-05 23:13:43.431830: Epoch time: 6.63 s 
2025-03-05 23:13:43.435345: Yayy! New best EMA pseudo Dice: 0.8802000284194946 
2025-03-05 23:13:43.953373:  
2025-03-05 23:13:43.958394: Epoch 42 
2025-03-05 23:13:43.961912: Current learning rate: 0.00612 
2025-03-05 23:13:50.588238: train_loss -0.8764 
2025-03-05 23:13:50.593273: val_loss -0.8531 
2025-03-05 23:13:50.597862: Pseudo dice [np.float32(0.8989), np.float32(0.8819)] 
2025-03-05 23:13:50.601430: Epoch time: 6.64 s 
2025-03-05 23:13:50.604970: Yayy! New best EMA pseudo Dice: 0.8812000155448914 
2025-03-05 23:13:51.118407:  
2025-03-05 23:13:51.124425: Epoch 43 
2025-03-05 23:13:51.128435: Current learning rate: 0.00603 
2025-03-05 23:13:57.744952: train_loss -0.8795 
2025-03-05 23:13:57.753573: val_loss -0.8491 
2025-03-05 23:13:57.759197: Pseudo dice [np.float32(0.8946), np.float32(0.88)] 
2025-03-05 23:13:57.763283: Epoch time: 6.63 s 
2025-03-05 23:13:57.767404: Yayy! New best EMA pseudo Dice: 0.8817999958992004 
2025-03-05 23:13:58.291428:  
2025-03-05 23:13:58.297945: Epoch 44 
2025-03-05 23:13:58.301462: Current learning rate: 0.00593 
2025-03-05 23:14:05.120253: train_loss -0.8811 
2025-03-05 23:14:05.125901: val_loss -0.8431 
2025-03-05 23:14:05.130459: Pseudo dice [np.float32(0.8915), np.float32(0.8739)] 
2025-03-05 23:14:05.133555: Epoch time: 6.83 s 
2025-03-05 23:14:05.138709: Yayy! New best EMA pseudo Dice: 0.8819000124931335 
2025-03-05 23:14:05.819355:  
2025-03-05 23:14:05.824881: Epoch 45 
2025-03-05 23:14:05.828392: Current learning rate: 0.00584 
2025-03-05 23:14:12.423534: train_loss -0.881 
2025-03-05 23:14:12.430108: val_loss -0.8478 
2025-03-05 23:14:12.433646: Pseudo dice [np.float32(0.8945), np.float32(0.8767)] 
2025-03-05 23:14:12.437693: Epoch time: 6.61 s 
2025-03-05 23:14:12.441818: Yayy! New best EMA pseudo Dice: 0.8823000192642212 
2025-03-05 23:14:12.954660:  
2025-03-05 23:14:12.961308: Epoch 46 
2025-03-05 23:14:12.964885: Current learning rate: 0.00574 
2025-03-05 23:14:19.534130: train_loss -0.8816 
2025-03-05 23:14:19.540244: val_loss -0.8534 
2025-03-05 23:14:19.544290: Pseudo dice [np.float32(0.9007), np.float32(0.8803)] 
2025-03-05 23:14:19.547817: Epoch time: 6.58 s 
2025-03-05 23:14:19.552022: Yayy! New best EMA pseudo Dice: 0.8830999732017517 
2025-03-05 23:14:20.065159:  
2025-03-05 23:14:20.070683: Epoch 47 
2025-03-05 23:14:20.074199: Current learning rate: 0.00565 
2025-03-05 23:14:26.642771: train_loss -0.8813 
2025-03-05 23:14:26.648964: val_loss -0.8494 
2025-03-05 23:14:26.652508: Pseudo dice [np.float32(0.8972), np.float32(0.8764)] 
2025-03-05 23:14:26.656586: Epoch time: 6.58 s 
2025-03-05 23:14:26.660705: Yayy! New best EMA pseudo Dice: 0.8834999799728394 
2025-03-05 23:14:27.177936:  
2025-03-05 23:14:27.184601: Epoch 48 
2025-03-05 23:14:27.189660: Current learning rate: 0.00555 
2025-03-05 23:14:33.773181: train_loss -0.882 
2025-03-05 23:14:33.779735: val_loss -0.8497 
2025-03-05 23:14:33.783764: Pseudo dice [np.float32(0.8978), np.float32(0.8789)] 
2025-03-05 23:14:33.787289: Epoch time: 6.6 s 
2025-03-05 23:14:33.790880: Yayy! New best EMA pseudo Dice: 0.883899986743927 
2025-03-05 23:14:34.313549:  
2025-03-05 23:14:34.320594: Epoch 49 
2025-03-05 23:14:34.323638: Current learning rate: 0.00546 
2025-03-05 23:14:40.896430: train_loss -0.8832 
2025-03-05 23:14:40.901998: val_loss -0.8539 
2025-03-05 23:14:40.906592: Pseudo dice [np.float32(0.9), np.float32(0.8807)] 
2025-03-05 23:14:40.910268: Epoch time: 6.58 s 
2025-03-05 23:14:40.946081: Yayy! New best EMA pseudo Dice: 0.8845999836921692 
2025-03-05 23:14:41.476626:  
2025-03-05 23:14:41.482608: Epoch 50 
2025-03-05 23:14:41.486620: Current learning rate: 0.00536 
2025-03-05 23:14:48.045505: train_loss -0.884 
2025-03-05 23:14:48.051689: val_loss -0.8529 
2025-03-05 23:14:48.056237: Pseudo dice [np.float32(0.8994), np.float32(0.8804)] 
2025-03-05 23:14:48.059361: Epoch time: 6.57 s 
2025-03-05 23:14:48.063390: Yayy! New best EMA pseudo Dice: 0.8851000070571899 
2025-03-05 23:14:48.588867:  
2025-03-05 23:14:48.594420: Epoch 51 
2025-03-05 23:14:48.598474: Current learning rate: 0.00526 
2025-03-05 23:14:55.157875: train_loss -0.8835 
2025-03-05 23:14:55.162643: val_loss -0.8501 
2025-03-05 23:14:55.167193: Pseudo dice [np.float32(0.898), np.float32(0.8795)] 
2025-03-05 23:14:55.171324: Epoch time: 6.57 s 
2025-03-05 23:14:55.175344: Yayy! New best EMA pseudo Dice: 0.8855000138282776 
2025-03-05 23:14:55.699731:  
2025-03-05 23:14:55.705795: Epoch 52 
2025-03-05 23:14:55.711449: Current learning rate: 0.00517 
2025-03-05 23:15:02.284578: train_loss -0.8855 
2025-03-05 23:15:02.291261: val_loss -0.8461 
2025-03-05 23:15:02.296304: Pseudo dice [np.float32(0.8958), np.float32(0.8754)] 
2025-03-05 23:15:02.300901: Epoch time: 6.58 s 
2025-03-05 23:15:02.305548: Yayy! New best EMA pseudo Dice: 0.8855000138282776 
2025-03-05 23:15:02.833565:  
2025-03-05 23:15:02.839603: Epoch 53 
2025-03-05 23:15:02.842613: Current learning rate: 0.00507 
2025-03-05 23:15:09.432793: train_loss -0.8859 
2025-03-05 23:15:09.438457: val_loss -0.848 
2025-03-05 23:15:09.442549: Pseudo dice [np.float32(0.8962), np.float32(0.8757)] 
2025-03-05 23:15:09.447199: Epoch time: 6.6 s 
2025-03-05 23:15:09.452010: Yayy! New best EMA pseudo Dice: 0.8855000138282776 
2025-03-05 23:15:10.127866:  
2025-03-05 23:15:10.134389: Epoch 54 
2025-03-05 23:15:10.137897: Current learning rate: 0.00497 
2025-03-05 23:15:16.704817: train_loss -0.8859 
2025-03-05 23:15:16.710440: val_loss -0.8474 
2025-03-05 23:15:16.714478: Pseudo dice [np.float32(0.8952), np.float32(0.8774)] 
2025-03-05 23:15:16.718643: Epoch time: 6.58 s 
2025-03-05 23:15:16.721711: Yayy! New best EMA pseudo Dice: 0.8855999708175659 
2025-03-05 23:15:17.251248:  
2025-03-05 23:15:17.257267: Epoch 55 
2025-03-05 23:15:17.261279: Current learning rate: 0.00487 
2025-03-05 23:15:23.828166: train_loss -0.8865 
2025-03-05 23:15:23.833747: val_loss -0.8459 
2025-03-05 23:15:23.836782: Pseudo dice [np.float32(0.8928), np.float32(0.8775)] 
2025-03-05 23:15:23.840818: Epoch time: 6.58 s 
2025-03-05 23:15:24.333051:  
2025-03-05 23:15:24.338066: Epoch 56 
2025-03-05 23:15:24.341576: Current learning rate: 0.00478 
2025-03-05 23:15:31.069145: train_loss -0.8867 
2025-03-05 23:15:31.076757: val_loss -0.8508 
2025-03-05 23:15:31.081422: Pseudo dice [np.float32(0.8986), np.float32(0.8799)] 
2025-03-05 23:15:31.085537: Epoch time: 6.74 s 
2025-03-05 23:15:31.090600: Yayy! New best EMA pseudo Dice: 0.8859000205993652 
2025-03-05 23:15:31.630811:  
2025-03-05 23:15:31.636830: Epoch 57 
2025-03-05 23:15:31.640842: Current learning rate: 0.00468 
2025-03-05 23:15:38.479141: train_loss -0.8882 
2025-03-05 23:15:38.485258: val_loss -0.8496 
2025-03-05 23:15:38.488331: Pseudo dice [np.float32(0.8978), np.float32(0.8787)] 
2025-03-05 23:15:38.491881: Epoch time: 6.85 s 
2025-03-05 23:15:38.494925: Yayy! New best EMA pseudo Dice: 0.8862000107765198 
2025-03-05 23:15:39.093724:  
2025-03-05 23:15:39.099769: Epoch 58 
2025-03-05 23:15:39.102712: Current learning rate: 0.00458 
2025-03-05 23:15:45.718865: train_loss -0.8887 
2025-03-05 23:15:45.725220: val_loss -0.8513 
2025-03-05 23:15:45.729387: Pseudo dice [np.float32(0.8975), np.float32(0.8805)] 
2025-03-05 23:15:45.732455: Epoch time: 6.63 s 
2025-03-05 23:15:45.736097: Yayy! New best EMA pseudo Dice: 0.8865000009536743 
2025-03-05 23:15:46.268305:  
2025-03-05 23:15:46.273335: Epoch 59 
2025-03-05 23:15:46.277041: Current learning rate: 0.00448 
2025-03-05 23:15:52.888339: train_loss -0.8886 
2025-03-05 23:15:52.894548: val_loss -0.8437 
2025-03-05 23:15:52.898115: Pseudo dice [np.float32(0.8931), np.float32(0.8768)] 
2025-03-05 23:15:52.901697: Epoch time: 6.62 s 
2025-03-05 23:15:53.397756:  
2025-03-05 23:15:53.403354: Epoch 60 
2025-03-05 23:15:53.406916: Current learning rate: 0.00438 
2025-03-05 23:16:00.028684: train_loss -0.8903 
2025-03-05 23:16:00.036918: val_loss -0.8455 
2025-03-05 23:16:00.040983: Pseudo dice [np.float32(0.8945), np.float32(0.8761)] 
2025-03-05 23:16:00.045022: Epoch time: 6.63 s 
2025-03-05 23:16:00.548204:  
2025-03-05 23:16:00.553726: Epoch 61 
2025-03-05 23:16:00.557237: Current learning rate: 0.00429 
2025-03-05 23:16:07.297388: train_loss -0.8898 
2025-03-05 23:16:07.303532: val_loss -0.8516 
2025-03-05 23:16:07.307162: Pseudo dice [np.float32(0.8976), np.float32(0.8814)] 
2025-03-05 23:16:07.309695: Epoch time: 6.75 s 
2025-03-05 23:16:07.314461: Yayy! New best EMA pseudo Dice: 0.8865000009536743 
2025-03-05 23:16:07.852268:  
2025-03-05 23:16:07.857783: Epoch 62 
2025-03-05 23:16:07.861297: Current learning rate: 0.00419 
2025-03-05 23:16:14.463848: train_loss -0.8905 
2025-03-05 23:16:14.470034: val_loss -0.8469 
2025-03-05 23:16:14.473093: Pseudo dice [np.float32(0.8942), np.float32(0.8775)] 
2025-03-05 23:16:14.476645: Epoch time: 6.61 s 
2025-03-05 23:16:14.977689:  
2025-03-05 23:16:14.982700: Epoch 63 
2025-03-05 23:16:14.985710: Current learning rate: 0.00409 
2025-03-05 23:16:21.596968: train_loss -0.8918 
2025-03-05 23:16:21.602009: val_loss -0.8479 
2025-03-05 23:16:21.606034: Pseudo dice [np.float32(0.8957), np.float32(0.8779)] 
2025-03-05 23:16:21.609629: Epoch time: 6.62 s 
2025-03-05 23:16:22.109538:  
2025-03-05 23:16:22.113554: Epoch 64 
2025-03-05 23:16:22.117563: Current learning rate: 0.00399 
2025-03-05 23:16:28.736310: train_loss -0.8927 
2025-03-05 23:16:28.741892: val_loss -0.8454 
2025-03-05 23:16:28.745425: Pseudo dice [np.float32(0.8951), np.float32(0.8776)] 
2025-03-05 23:16:28.748547: Epoch time: 6.63 s 
2025-03-05 23:16:29.248878:  
2025-03-05 23:16:29.253892: Epoch 65 
2025-03-05 23:16:29.256901: Current learning rate: 0.00389 
2025-03-05 23:16:35.856145: train_loss -0.892 
2025-03-05 23:16:35.861744: val_loss -0.8482 
2025-03-05 23:16:35.866256: Pseudo dice [np.float32(0.8959), np.float32(0.8787)] 
2025-03-05 23:16:35.869307: Epoch time: 6.61 s 
2025-03-05 23:16:35.872627: Yayy! New best EMA pseudo Dice: 0.8866000175476074 
2025-03-05 23:16:36.412370:  
2025-03-05 23:16:36.417412: Epoch 66 
2025-03-05 23:16:36.421033: Current learning rate: 0.00379 
2025-03-05 23:16:43.032464: train_loss -0.8925 
2025-03-05 23:16:43.038541: val_loss -0.8432 
2025-03-05 23:16:43.042154: Pseudo dice [np.float32(0.8938), np.float32(0.8756)] 
2025-03-05 23:16:43.045181: Epoch time: 6.62 s 
2025-03-05 23:16:43.541888:  
2025-03-05 23:16:43.547421: Epoch 67 
2025-03-05 23:16:43.550884: Current learning rate: 0.00369 
2025-03-05 23:16:50.170511: train_loss -0.8916 
2025-03-05 23:16:50.175559: val_loss -0.8548 
2025-03-05 23:16:50.179589: Pseudo dice [np.float32(0.9011), np.float32(0.8837)] 
2025-03-05 23:16:50.182120: Epoch time: 6.63 s 
2025-03-05 23:16:50.185309: Yayy! New best EMA pseudo Dice: 0.8870000243186951 
2025-03-05 23:16:50.725384:  
2025-03-05 23:16:50.731902: Epoch 68 
2025-03-05 23:16:50.735414: Current learning rate: 0.00359 
2025-03-05 23:16:57.353458: train_loss -0.8928 
2025-03-05 23:16:57.358622: val_loss -0.8496 
2025-03-05 23:16:57.361152: Pseudo dice [np.float32(0.8978), np.float32(0.8802)] 
2025-03-05 23:16:57.366222: Epoch time: 6.63 s 
2025-03-05 23:16:57.370316: Yayy! New best EMA pseudo Dice: 0.8871999979019165 
2025-03-05 23:16:58.053960:  
2025-03-05 23:16:58.058975: Epoch 69 
2025-03-05 23:16:58.062488: Current learning rate: 0.00349 
2025-03-05 23:17:04.649314: train_loss -0.8939 
2025-03-05 23:17:04.654865: val_loss -0.8458 
2025-03-05 23:17:04.658377: Pseudo dice [np.float32(0.8958), np.float32(0.8762)] 
2025-03-05 23:17:04.662392: Epoch time: 6.6 s 
2025-03-05 23:17:05.174773:  
2025-03-05 23:17:05.180292: Epoch 70 
2025-03-05 23:17:05.183807: Current learning rate: 0.00338 
2025-03-05 23:17:11.788175: train_loss -0.8932 
2025-03-05 23:17:11.793877: val_loss -0.848 
2025-03-05 23:17:11.797411: Pseudo dice [np.float32(0.8958), np.float32(0.8782)] 
2025-03-05 23:17:11.800458: Epoch time: 6.61 s 
2025-03-05 23:17:12.307899:  
2025-03-05 23:17:12.314417: Epoch 71 
2025-03-05 23:17:12.317929: Current learning rate: 0.00328 
2025-03-05 23:17:18.929124: train_loss -0.8939 
2025-03-05 23:17:18.934840: val_loss -0.8474 
2025-03-05 23:17:18.938420: Pseudo dice [np.float32(0.8971), np.float32(0.8773)] 
2025-03-05 23:17:18.941997: Epoch time: 6.62 s 
2025-03-05 23:17:19.448277:  
2025-03-05 23:17:19.453295: Epoch 72 
2025-03-05 23:17:19.456807: Current learning rate: 0.00318 
2025-03-05 23:17:26.069822: train_loss -0.8948 
2025-03-05 23:17:26.075953: val_loss -0.8435 
2025-03-05 23:17:26.078464: Pseudo dice [np.float32(0.8936), np.float32(0.8752)] 
2025-03-05 23:17:26.082391: Epoch time: 6.62 s 
2025-03-05 23:17:26.591819:  
2025-03-05 23:17:26.595834: Epoch 73 
2025-03-05 23:17:26.598345: Current learning rate: 0.00308 
2025-03-05 23:17:33.205025: train_loss -0.8959 
2025-03-05 23:17:33.211088: val_loss -0.8481 
2025-03-05 23:17:33.214677: Pseudo dice [np.float32(0.8973), np.float32(0.8777)] 
2025-03-05 23:17:33.217740: Epoch time: 6.61 s 
2025-03-05 23:17:33.723246:  
2025-03-05 23:17:33.728796: Epoch 74 
2025-03-05 23:17:33.731884: Current learning rate: 0.00297 
2025-03-05 23:17:40.354405: train_loss -0.8956 
2025-03-05 23:17:40.359486: val_loss -0.848 
2025-03-05 23:17:40.361725: Pseudo dice [np.float32(0.8976), np.float32(0.8776)] 
2025-03-05 23:17:40.366474: Epoch time: 6.63 s 
2025-03-05 23:17:40.875391:  
2025-03-05 23:17:40.882440: Epoch 75 
2025-03-05 23:17:40.885998: Current learning rate: 0.00287 
2025-03-05 23:17:47.477382: train_loss -0.8975 
2025-03-05 23:17:47.483439: val_loss -0.8476 
2025-03-05 23:17:47.486830: Pseudo dice [np.float32(0.8964), np.float32(0.8767)] 
2025-03-05 23:17:47.489871: Epoch time: 6.6 s 
2025-03-05 23:17:48.006653:  
2025-03-05 23:17:48.012224: Epoch 76 
2025-03-05 23:17:48.015777: Current learning rate: 0.00277 
2025-03-05 23:17:54.598134: train_loss -0.8973 
2025-03-05 23:17:54.604198: val_loss -0.8498 
2025-03-05 23:17:54.607720: Pseudo dice [np.float32(0.8979), np.float32(0.8803)] 
2025-03-05 23:17:54.610760: Epoch time: 6.59 s 
2025-03-05 23:17:55.277642:  
2025-03-05 23:17:55.283161: Epoch 77 
2025-03-05 23:17:55.286676: Current learning rate: 0.00266 
2025-03-05 23:18:01.874843: train_loss -0.8972 
2025-03-05 23:18:01.882467: val_loss -0.8467 
2025-03-05 23:18:01.886028: Pseudo dice [np.float32(0.8956), np.float32(0.8766)] 
2025-03-05 23:18:01.888553: Epoch time: 6.6 s 
2025-03-05 23:18:02.408429:  
2025-03-05 23:18:02.413944: Epoch 78 
2025-03-05 23:18:02.418459: Current learning rate: 0.00256 
2025-03-05 23:18:09.040612: train_loss -0.8963 
2025-03-05 23:18:09.045689: val_loss -0.8453 
2025-03-05 23:18:09.049548: Pseudo dice [np.float32(0.895), np.float32(0.8756)] 
2025-03-05 23:18:09.051554: Epoch time: 6.63 s 
2025-03-05 23:18:09.564039:  
2025-03-05 23:18:09.569050: Epoch 79 
2025-03-05 23:18:09.572561: Current learning rate: 0.00245 
2025-03-05 23:18:16.177215: train_loss -0.8972 
2025-03-05 23:18:16.182803: val_loss -0.8478 
2025-03-05 23:18:16.186333: Pseudo dice [np.float32(0.8961), np.float32(0.8802)] 
2025-03-05 23:18:16.189416: Epoch time: 6.61 s 
2025-03-05 23:18:16.709847:  
2025-03-05 23:18:16.715409: Epoch 80 
2025-03-05 23:18:16.717993: Current learning rate: 0.00235 
2025-03-05 23:18:23.317687: train_loss -0.8987 
2025-03-05 23:18:23.323264: val_loss -0.8471 
2025-03-05 23:18:23.325815: Pseudo dice [np.float32(0.8965), np.float32(0.8789)] 
2025-03-05 23:18:23.329849: Epoch time: 6.61 s 
2025-03-05 23:18:23.841349:  
2025-03-05 23:18:23.846963: Epoch 81 
2025-03-05 23:18:23.850547: Current learning rate: 0.00224 
2025-03-05 23:18:30.462884: train_loss -0.8989 
2025-03-05 23:18:30.468037: val_loss -0.845 
2025-03-05 23:18:30.472051: Pseudo dice [np.float32(0.8944), np.float32(0.8767)] 
2025-03-05 23:18:30.475568: Epoch time: 6.62 s 
2025-03-05 23:18:30.986465:  
2025-03-05 23:18:30.992547: Epoch 82 
2025-03-05 23:18:30.995615: Current learning rate: 0.00214 
2025-03-05 23:18:37.615317: train_loss -0.898 
2025-03-05 23:18:37.620997: val_loss -0.8462 
2025-03-05 23:18:37.624561: Pseudo dice [np.float32(0.8948), np.float32(0.8774)] 
2025-03-05 23:18:37.627590: Epoch time: 6.63 s 
2025-03-05 23:18:38.113784:  
2025-03-05 23:18:38.119337: Epoch 83 
2025-03-05 23:18:38.121874: Current learning rate: 0.00203 
2025-03-05 23:18:44.719057: train_loss -0.8992 
2025-03-05 23:18:44.724634: val_loss -0.8437 
2025-03-05 23:18:44.728214: Pseudo dice [np.float32(0.8926), np.float32(0.8767)] 
2025-03-05 23:18:44.730898: Epoch time: 6.61 s 
2025-03-05 23:18:45.358627:  
2025-03-05 23:18:45.364742: Epoch 84 
2025-03-05 23:18:45.368299: Current learning rate: 0.00192 
2025-03-05 23:18:52.048141: train_loss -0.9002 
2025-03-05 23:18:52.054276: val_loss -0.847 
2025-03-05 23:18:52.058446: Pseudo dice [np.float32(0.8975), np.float32(0.878)] 
2025-03-05 23:18:52.062029: Epoch time: 6.69 s 
2025-03-05 23:18:52.550155:  
2025-03-05 23:18:52.554785: Epoch 85 
2025-03-05 23:18:52.559454: Current learning rate: 0.00181 
2025-03-05 23:18:59.267178: train_loss -0.9013 
2025-03-05 23:18:59.273360: val_loss -0.8453 
2025-03-05 23:18:59.277540: Pseudo dice [np.float32(0.8954), np.float32(0.8768)] 
2025-03-05 23:18:59.280607: Epoch time: 6.72 s 
2025-03-05 23:18:59.770901:  
2025-03-05 23:18:59.776923: Epoch 86 
2025-03-05 23:18:59.780426: Current learning rate: 0.0017 
2025-03-05 23:19:06.396465: train_loss -0.902 
2025-03-05 23:19:06.402123: val_loss -0.8432 
2025-03-05 23:19:06.406177: Pseudo dice [np.float32(0.8943), np.float32(0.875)] 
2025-03-05 23:19:06.409228: Epoch time: 6.63 s 
2025-03-05 23:19:06.890739:  
2025-03-05 23:19:06.896291: Epoch 87 
2025-03-05 23:19:06.899393: Current learning rate: 0.00159 
2025-03-05 23:19:13.517817: train_loss -0.9007 
2025-03-05 23:19:13.523437: val_loss -0.8455 
2025-03-05 23:19:13.527575: Pseudo dice [np.float32(0.8955), np.float32(0.8771)] 
2025-03-05 23:19:13.530602: Epoch time: 6.63 s 
2025-03-05 23:19:14.024767:  
2025-03-05 23:19:14.030434: Epoch 88 
2025-03-05 23:19:14.033479: Current learning rate: 0.00148 
2025-03-05 23:19:20.646922: train_loss -0.9017 
2025-03-05 23:19:20.652488: val_loss -0.8477 
2025-03-05 23:19:20.656384: Pseudo dice [np.float32(0.8967), np.float32(0.8787)] 
2025-03-05 23:19:20.659926: Epoch time: 6.62 s 
2025-03-05 23:19:21.138854:  
2025-03-05 23:19:21.144963: Epoch 89 
2025-03-05 23:19:21.148003: Current learning rate: 0.00137 
2025-03-05 23:19:27.783468: train_loss -0.9014 
2025-03-05 23:19:27.789495: val_loss -0.8458 
2025-03-05 23:19:27.793521: Pseudo dice [np.float32(0.8951), np.float32(0.8767)] 
2025-03-05 23:19:27.796040: Epoch time: 6.64 s 
2025-03-05 23:19:28.280864:  
2025-03-05 23:19:28.286941: Epoch 90 
2025-03-05 23:19:28.290048: Current learning rate: 0.00126 
2025-03-05 23:19:35.058254: train_loss -0.8999 
2025-03-05 23:19:35.064275: val_loss -0.8423 
2025-03-05 23:19:35.068294: Pseudo dice [np.float32(0.8931), np.float32(0.8759)] 
2025-03-05 23:19:35.071798: Epoch time: 6.78 s 
2025-03-05 23:19:35.566526:  
2025-03-05 23:19:35.572091: Epoch 91 
2025-03-05 23:19:35.575641: Current learning rate: 0.00115 
2025-03-05 23:19:42.205539: train_loss -0.9028 
2025-03-05 23:19:42.210704: val_loss -0.8505 
2025-03-05 23:19:42.215325: Pseudo dice [np.float32(0.8981), np.float32(0.881)] 
2025-03-05 23:19:42.218879: Epoch time: 6.64 s 
2025-03-05 23:19:42.706768:  
2025-03-05 23:19:42.712287: Epoch 92 
2025-03-05 23:19:42.715799: Current learning rate: 0.00103 
2025-03-05 23:19:49.490088: train_loss -0.9015 
2025-03-05 23:19:49.495177: val_loss -0.8479 
2025-03-05 23:19:49.500229: Pseudo dice [np.float32(0.8965), np.float32(0.8784)] 
2025-03-05 23:19:49.503268: Epoch time: 6.78 s 
2025-03-05 23:19:50.146802:  
2025-03-05 23:19:50.151821: Epoch 93 
2025-03-05 23:19:50.155330: Current learning rate: 0.00091 
2025-03-05 23:19:56.762713: train_loss -0.902 
2025-03-05 23:19:56.767816: val_loss -0.8453 
2025-03-05 23:19:56.771334: Pseudo dice [np.float32(0.8949), np.float32(0.8765)] 
2025-03-05 23:19:56.775342: Epoch time: 6.62 s 
2025-03-05 23:19:57.261579:  
2025-03-05 23:19:57.267698: Epoch 94 
2025-03-05 23:19:57.270767: Current learning rate: 0.00079 
2025-03-05 23:20:03.861890: train_loss -0.903 
2025-03-05 23:20:03.868574: val_loss -0.8463 
2025-03-05 23:20:03.872112: Pseudo dice [np.float32(0.8959), np.float32(0.8784)] 
2025-03-05 23:20:03.875172: Epoch time: 6.6 s 
2025-03-05 23:20:04.358975:  
2025-03-05 23:20:04.363996: Epoch 95 
2025-03-05 23:20:04.367514: Current learning rate: 0.00067 
2025-03-05 23:20:10.972697: train_loss -0.9043 
2025-03-05 23:20:10.977223: val_loss -0.8473 
2025-03-05 23:20:10.981829: Pseudo dice [np.float32(0.8968), np.float32(0.8781)] 
2025-03-05 23:20:10.985403: Epoch time: 6.61 s 
2025-03-05 23:20:11.470876:  
2025-03-05 23:20:11.476389: Epoch 96 
2025-03-05 23:20:11.479906: Current learning rate: 0.00055 
2025-03-05 23:20:18.097857: train_loss -0.9035 
2025-03-05 23:20:18.102994: val_loss -0.8408 
2025-03-05 23:20:18.106523: Pseudo dice [np.float32(0.8926), np.float32(0.8739)] 
2025-03-05 23:20:18.110205: Epoch time: 6.63 s 
2025-03-05 23:20:18.608058:  
2025-03-05 23:20:18.613208: Epoch 97 
2025-03-05 23:20:18.616800: Current learning rate: 0.00043 
2025-03-05 23:20:25.228749: train_loss -0.9035 
2025-03-05 23:20:25.235121: val_loss -0.8459 
2025-03-05 23:20:25.238680: Pseudo dice [np.float32(0.8957), np.float32(0.8785)] 
2025-03-05 23:20:25.241732: Epoch time: 6.62 s 
2025-03-05 23:20:25.733478:  
2025-03-05 23:20:25.739024: Epoch 98 
2025-03-05 23:20:25.742567: Current learning rate: 0.0003 
2025-03-05 23:20:32.344455: train_loss -0.9041 
2025-03-05 23:20:32.350494: val_loss -0.8468 
2025-03-05 23:20:32.353984: Pseudo dice [np.float32(0.8953), np.float32(0.8777)] 
2025-03-05 23:20:32.357583: Epoch time: 6.61 s 
2025-03-05 23:20:32.849007:  
2025-03-05 23:20:32.854026: Epoch 99 
2025-03-05 23:20:32.857545: Current learning rate: 0.00016 
2025-03-05 23:20:39.467927: train_loss -0.904 
2025-03-05 23:20:39.474076: val_loss -0.8447 
2025-03-05 23:20:39.477607: Pseudo dice [np.float32(0.8952), np.float32(0.8762)] 
2025-03-05 23:20:39.481178: Epoch time: 6.62 s 
2025-03-05 23:20:40.024379: Training done. 
2025-03-05 23:20:40.061382: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2025-03-05 23:20:40.069387: The split file contains 5 splits. 
2025-03-05 23:20:40.076385: Desired fold for training: 0 
2025-03-05 23:20:40.080890: This split has 208 training and 52 validation cases. 
2025-03-05 23:20:40.086896: predicting hippocampus_017 
2025-03-05 23:20:40.091897: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2025-03-05 23:20:40.182160: predicting hippocampus_019 
2025-03-05 23:20:40.188165: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2025-03-05 23:20:40.220160: predicting hippocampus_033 
2025-03-05 23:20:40.226160: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2025-03-05 23:20:40.248161: predicting hippocampus_035 
2025-03-05 23:20:40.255161: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2025-03-05 23:20:40.276166: predicting hippocampus_037 
2025-03-05 23:20:40.282377: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2025-03-05 23:20:40.305376: predicting hippocampus_049 
2025-03-05 23:20:40.312374: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2025-03-05 23:20:40.335377: predicting hippocampus_052 
2025-03-05 23:20:40.341374: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2025-03-05 23:20:40.364375: predicting hippocampus_065 
2025-03-05 23:20:40.370379: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2025-03-05 23:20:40.392574: predicting hippocampus_083 
2025-03-05 23:20:40.399574: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2025-03-05 23:20:40.422573: predicting hippocampus_088 
2025-03-05 23:20:40.429574: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2025-03-05 23:20:44.271528: predicting hippocampus_090 
2025-03-05 23:20:44.278532: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2025-03-05 23:20:44.334045: predicting hippocampus_092 
2025-03-05 23:20:44.349044: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2025-03-05 23:20:44.409552: predicting hippocampus_095 
2025-03-05 23:20:44.416553: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2025-03-05 23:20:44.464553: predicting hippocampus_107 
2025-03-05 23:20:44.470557: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2025-03-05 23:20:44.518061: predicting hippocampus_108 
2025-03-05 23:20:44.524061: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2025-03-05 23:20:44.571063: predicting hippocampus_123 
2025-03-05 23:20:44.578065: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2025-03-05 23:20:44.611571: predicting hippocampus_125 
2025-03-05 23:20:44.619571: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2025-03-05 23:20:44.672573: predicting hippocampus_157 
2025-03-05 23:20:44.680573: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2025-03-05 23:20:44.715079: predicting hippocampus_164 
2025-03-05 23:20:44.722079: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2025-03-05 23:20:44.803591: predicting hippocampus_169 
2025-03-05 23:20:44.810591: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2025-03-05 23:20:44.837592: predicting hippocampus_175 
2025-03-05 23:20:44.842592: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2025-03-05 23:20:44.870593: predicting hippocampus_185 
2025-03-05 23:20:44.877593: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2025-03-05 23:20:44.903101: predicting hippocampus_190 
2025-03-05 23:20:44.910103: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2025-03-05 23:20:44.937101: predicting hippocampus_194 
2025-03-05 23:20:44.945104: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2025-03-05 23:20:44.975103: predicting hippocampus_204 
2025-03-05 23:20:44.980105: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2025-03-05 23:20:45.008613: predicting hippocampus_205 
2025-03-05 23:20:45.015612: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2025-03-05 23:20:45.044613: predicting hippocampus_210 
2025-03-05 23:20:45.050612: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2025-03-05 23:20:45.081614: predicting hippocampus_217 
2025-03-05 23:20:45.087120: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2025-03-05 23:20:45.115120: predicting hippocampus_219 
2025-03-05 23:20:45.122120: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2025-03-05 23:20:45.151120: predicting hippocampus_229 
2025-03-05 23:20:45.157120: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2025-03-05 23:20:45.183625: predicting hippocampus_244 
2025-03-05 23:20:45.189628: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2025-03-05 23:20:45.217628: predicting hippocampus_261 
2025-03-05 23:20:45.222628: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2025-03-05 23:20:45.269631: predicting hippocampus_264 
2025-03-05 23:20:45.275632: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2025-03-05 23:20:45.312143: predicting hippocampus_277 
2025-03-05 23:20:45.320142: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2025-03-05 23:20:45.365140: predicting hippocampus_280 
2025-03-05 23:20:45.373145: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2025-03-05 23:20:45.402648: predicting hippocampus_286 
2025-03-05 23:20:45.409648: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2025-03-05 23:20:45.454648: predicting hippocampus_288 
2025-03-05 23:20:45.461648: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2025-03-05 23:20:45.506156: predicting hippocampus_289 
2025-03-05 23:20:45.514158: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2025-03-05 23:20:45.540156: predicting hippocampus_296 
2025-03-05 23:20:45.547158: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2025-03-05 23:20:45.575158: predicting hippocampus_305 
2025-03-05 23:20:45.581160: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2025-03-05 23:20:45.609664: predicting hippocampus_308 
2025-03-05 23:20:45.616666: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2025-03-05 23:20:45.643664: predicting hippocampus_317 
2025-03-05 23:20:45.649666: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2025-03-05 23:20:45.679667: predicting hippocampus_327 
2025-03-05 23:20:45.685173: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2025-03-05 23:20:45.713173: predicting hippocampus_330 
2025-03-05 23:20:45.719173: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2025-03-05 23:20:45.750174: predicting hippocampus_332 
2025-03-05 23:20:45.756173: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2025-03-05 23:20:45.784680: predicting hippocampus_338 
2025-03-05 23:20:45.790680: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2025-03-05 23:20:45.835680: predicting hippocampus_349 
2025-03-05 23:20:45.841681: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2025-03-05 23:20:45.868682: predicting hippocampus_350 
2025-03-05 23:20:45.874684: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2025-03-05 23:20:45.903187: predicting hippocampus_356 
2025-03-05 23:20:45.909187: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2025-03-05 23:20:45.938187: predicting hippocampus_358 
2025-03-05 23:20:45.944187: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2025-03-05 23:20:45.972189: predicting hippocampus_374 
2025-03-05 23:20:45.977190: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2025-03-05 23:20:46.005696: predicting hippocampus_394 
2025-03-05 23:20:46.010699: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2025-03-05 23:20:49.716144: Validation complete 
2025-03-05 23:20:49.722145: Mean Validation Dice:  0.891025966433158 
