
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-08 05:57:21.830298: do_dummy_2d_data_aug: False 
2024-12-08 05:57:21.846416: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-08 05:57:21.854475: The split file contains 5 splits. 
2024-12-08 05:57:21.854475: Desired fold for training: 0 
2024-12-08 05:57:21.854475: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-08 05:57:28.081682: unpacking dataset... 
2024-12-08 05:57:28.392412: unpacking done... 
2024-12-08 05:57:29.467486:  
2024-12-08 05:57:29.472600: Epoch 0 
2024-12-08 05:57:29.475139: Current learning rate: 0.01 
2024-12-08 05:57:36.718467: train_loss -0.3264 
2024-12-08 05:57:36.724125: val_loss -0.7676 
2024-12-08 05:57:36.726669: Pseudo dice [np.float32(0.8299), np.float32(0.8264)] 
2024-12-08 05:57:36.729204: Epoch time: 7.25 s 
2024-12-08 05:57:36.732762: Yayy! New best EMA pseudo Dice: 0.8281999826431274 
2024-12-08 05:57:37.251449:  
2024-12-08 05:57:37.256582: Epoch 1 
2024-12-08 05:57:37.259619: Current learning rate: 0.00991 
2024-12-08 05:57:43.615414: train_loss -0.7691 
2024-12-08 05:57:43.620561: val_loss -0.8051 
2024-12-08 05:57:43.624614: Pseudo dice [np.float32(0.8618), np.float32(0.846)] 
2024-12-08 05:57:43.628167: Epoch time: 6.36 s 
2024-12-08 05:57:43.630700: Yayy! New best EMA pseudo Dice: 0.8307999968528748 
2024-12-08 05:57:44.198904:  
2024-12-08 05:57:44.205487: Epoch 2 
2024-12-08 05:57:44.208020: Current learning rate: 0.00982 
2024-12-08 05:57:50.574963: train_loss -0.8039 
2024-12-08 05:57:50.581036: val_loss -0.8135 
2024-12-08 05:57:50.583655: Pseudo dice [np.float32(0.8661), np.float32(0.8527)] 
2024-12-08 05:57:50.586689: Epoch time: 6.38 s 
2024-12-08 05:57:50.590221: Yayy! New best EMA pseudo Dice: 0.8335999846458435 
2024-12-08 05:57:51.198518:  
2024-12-08 05:57:51.204091: Epoch 3 
2024-12-08 05:57:51.206624: Current learning rate: 0.00973 
2024-12-08 05:57:57.562240: train_loss -0.8125 
2024-12-08 05:57:57.567323: val_loss -0.8243 
2024-12-08 05:57:57.569854: Pseudo dice [np.float32(0.8735), np.float32(0.8606)] 
2024-12-08 05:57:57.574397: Epoch time: 6.36 s 
2024-12-08 05:57:57.577505: Yayy! New best EMA pseudo Dice: 0.8370000123977661 
2024-12-08 05:57:58.165851:  
2024-12-08 05:57:58.170957: Epoch 4 
2024-12-08 05:57:58.173999: Current learning rate: 0.00964 
2024-12-08 05:58:04.518405: train_loss -0.8235 
2024-12-08 05:58:04.522460: val_loss -0.8271 
2024-12-08 05:58:04.527624: Pseudo dice [np.float32(0.8768), np.float32(0.8636)] 
2024-12-08 05:58:04.530662: Epoch time: 6.35 s 
2024-12-08 05:58:04.533193: Yayy! New best EMA pseudo Dice: 0.8403000235557556 
2024-12-08 05:58:05.132381:  
2024-12-08 05:58:05.137983: Epoch 5 
2024-12-08 05:58:05.140522: Current learning rate: 0.00955 
2024-12-08 05:58:11.485554: train_loss -0.8295 
2024-12-08 05:58:11.491153: val_loss -0.8301 
2024-12-08 05:58:11.495231: Pseudo dice [np.float32(0.8777), np.float32(0.8663)] 
2024-12-08 05:58:11.497774: Epoch time: 6.36 s 
2024-12-08 05:58:11.500306: Yayy! New best EMA pseudo Dice: 0.843500018119812 
2024-12-08 05:58:12.195405:  
2024-12-08 05:58:12.201487: Epoch 6 
2024-12-08 05:58:12.204084: Current learning rate: 0.00946 
2024-12-08 05:58:18.544724: train_loss -0.8355 
2024-12-08 05:58:18.550836: val_loss -0.8326 
2024-12-08 05:58:18.553373: Pseudo dice [np.float32(0.8823), np.float32(0.8692)] 
2024-12-08 05:58:18.556947: Epoch time: 6.35 s 
2024-12-08 05:58:18.560002: Yayy! New best EMA pseudo Dice: 0.8467000126838684 
2024-12-08 05:58:19.148220:  
2024-12-08 05:58:19.153817: Epoch 7 
2024-12-08 05:58:19.156862: Current learning rate: 0.00937 
2024-12-08 05:58:25.504073: train_loss -0.8384 
2024-12-08 05:58:25.509758: val_loss -0.8373 
2024-12-08 05:58:25.514320: Pseudo dice [np.float32(0.8869), np.float32(0.8685)] 
2024-12-08 05:58:25.517383: Epoch time: 6.36 s 
2024-12-08 05:58:25.519914: Yayy! New best EMA pseudo Dice: 0.8497999906539917 
2024-12-08 05:58:26.107820:  
2024-12-08 05:58:26.112880: Epoch 8 
2024-12-08 05:58:26.115406: Current learning rate: 0.00928 
2024-12-08 05:58:32.480142: train_loss -0.8396 
2024-12-08 05:58:32.485234: val_loss -0.8356 
2024-12-08 05:58:32.488774: Pseudo dice [np.float32(0.887), np.float32(0.8675)] 
2024-12-08 05:58:32.492337: Epoch time: 6.37 s 
2024-12-08 05:58:32.495385: Yayy! New best EMA pseudo Dice: 0.8525000214576721 
2024-12-08 05:58:33.099563:  
2024-12-08 05:58:33.104665: Epoch 9 
2024-12-08 05:58:33.107720: Current learning rate: 0.00919 
2024-12-08 05:58:39.454110: train_loss -0.8426 
2024-12-08 05:58:39.459204: val_loss -0.8437 
2024-12-08 05:58:39.462749: Pseudo dice [np.float32(0.8903), np.float32(0.8769)] 
2024-12-08 05:58:39.465285: Epoch time: 6.36 s 
2024-12-08 05:58:39.468360: Yayy! New best EMA pseudo Dice: 0.8555999994277954 
2024-12-08 05:58:40.051664:  
2024-12-08 05:58:40.057226: Epoch 10 
2024-12-08 05:58:40.060795: Current learning rate: 0.0091 
2024-12-08 05:58:46.404373: train_loss -0.8473 
2024-12-08 05:58:46.410042: val_loss -0.8405 
2024-12-08 05:58:46.413593: Pseudo dice [np.float32(0.8889), np.float32(0.8716)] 
2024-12-08 05:58:46.416650: Epoch time: 6.35 s 
2024-12-08 05:58:46.419176: Yayy! New best EMA pseudo Dice: 0.8580999970436096 
2024-12-08 05:58:46.995007:  
2024-12-08 05:58:47.000583: Epoch 11 
2024-12-08 05:58:47.003184: Current learning rate: 0.009 
2024-12-08 05:58:53.348709: train_loss -0.8494 
2024-12-08 05:58:53.354318: val_loss -0.8401 
2024-12-08 05:58:53.356914: Pseudo dice [np.float32(0.8876), np.float32(0.8725)] 
2024-12-08 05:58:53.360968: Epoch time: 6.35 s 
2024-12-08 05:58:53.363535: Yayy! New best EMA pseudo Dice: 0.8603000044822693 
2024-12-08 05:58:53.941126:  
2024-12-08 05:58:53.946689: Epoch 12 
2024-12-08 05:58:53.949791: Current learning rate: 0.00891 
2024-12-08 05:59:00.299387: train_loss -0.8517 
2024-12-08 05:59:00.305068: val_loss -0.8437 
2024-12-08 05:59:00.308196: Pseudo dice [np.float32(0.8913), np.float32(0.8731)] 
2024-12-08 05:59:00.311274: Epoch time: 6.36 s 
2024-12-08 05:59:00.314314: Yayy! New best EMA pseudo Dice: 0.862500011920929 
2024-12-08 05:59:00.900316:  
2024-12-08 05:59:00.905883: Epoch 13 
2024-12-08 05:59:00.908413: Current learning rate: 0.00882 
2024-12-08 05:59:07.257752: train_loss -0.8528 
2024-12-08 05:59:07.263390: val_loss -0.8502 
2024-12-08 05:59:07.268051: Pseudo dice [np.float32(0.8961), np.float32(0.8808)] 
2024-12-08 05:59:07.271595: Epoch time: 6.36 s 
2024-12-08 05:59:07.275142: Yayy! New best EMA pseudo Dice: 0.8651000261306763 
2024-12-08 05:59:08.008502:  
2024-12-08 05:59:08.014070: Epoch 14 
2024-12-08 05:59:08.017118: Current learning rate: 0.00873 
2024-12-08 05:59:14.357609: train_loss -0.8538 
2024-12-08 05:59:14.363218: val_loss -0.8443 
2024-12-08 05:59:14.366281: Pseudo dice [np.float32(0.8905), np.float32(0.8752)] 
2024-12-08 05:59:14.369470: Epoch time: 6.35 s 
2024-12-08 05:59:14.372006: Yayy! New best EMA pseudo Dice: 0.8669000267982483 
2024-12-08 05:59:14.961989:  
2024-12-08 05:59:14.968079: Epoch 15 
2024-12-08 05:59:14.970620: Current learning rate: 0.00864 
2024-12-08 05:59:21.315195: train_loss -0.8542 
2024-12-08 05:59:21.323410: val_loss -0.8465 
2024-12-08 05:59:21.326471: Pseudo dice [np.float32(0.8938), np.float32(0.8754)] 
2024-12-08 05:59:21.329001: Epoch time: 6.35 s 
2024-12-08 05:59:21.333104: Yayy! New best EMA pseudo Dice: 0.8686000108718872 
2024-12-08 05:59:21.932683:  
2024-12-08 05:59:21.937737: Epoch 16 
2024-12-08 05:59:21.940262: Current learning rate: 0.00855 
2024-12-08 05:59:28.300960: train_loss -0.855 
2024-12-08 05:59:28.306070: val_loss -0.8441 
2024-12-08 05:59:28.310113: Pseudo dice [np.float32(0.892), np.float32(0.8754)] 
2024-12-08 05:59:28.313168: Epoch time: 6.37 s 
2024-12-08 05:59:28.315697: Yayy! New best EMA pseudo Dice: 0.8701000213623047 
2024-12-08 05:59:28.928784:  
2024-12-08 05:59:28.934878: Epoch 17 
2024-12-08 05:59:28.938926: Current learning rate: 0.00846 
2024-12-08 05:59:35.292248: train_loss -0.8581 
2024-12-08 05:59:35.297370: val_loss -0.8541 
2024-12-08 05:59:35.300930: Pseudo dice [np.float32(0.8994), np.float32(0.8814)] 
2024-12-08 05:59:35.303976: Epoch time: 6.36 s 
2024-12-08 05:59:35.307528: Yayy! New best EMA pseudo Dice: 0.8722000122070312 
2024-12-08 05:59:35.903299:  
2024-12-08 05:59:35.908412: Epoch 18 
2024-12-08 05:59:35.910941: Current learning rate: 0.00836 
2024-12-08 05:59:42.263313: train_loss -0.8582 
2024-12-08 05:59:42.269432: val_loss -0.8422 
2024-12-08 05:59:42.271977: Pseudo dice [np.float32(0.8906), np.float32(0.8718)] 
2024-12-08 05:59:42.275620: Epoch time: 6.36 s 
2024-12-08 05:59:42.279682: Yayy! New best EMA pseudo Dice: 0.8730999827384949 
2024-12-08 05:59:42.874079:  
2024-12-08 05:59:42.879694: Epoch 19 
2024-12-08 05:59:42.884763: Current learning rate: 0.00827 
2024-12-08 05:59:49.231053: train_loss -0.8621 
2024-12-08 05:59:49.237621: val_loss -0.8525 
2024-12-08 05:59:49.241184: Pseudo dice [np.float32(0.8965), np.float32(0.8809)] 
2024-12-08 05:59:49.243754: Epoch time: 6.36 s 
2024-12-08 05:59:49.247789: Yayy! New best EMA pseudo Dice: 0.8745999932289124 
2024-12-08 05:59:49.848246:  
2024-12-08 05:59:49.854842: Epoch 20 
2024-12-08 05:59:49.858398: Current learning rate: 0.00818 
2024-12-08 05:59:56.201784: train_loss -0.8607 
2024-12-08 05:59:56.206856: val_loss -0.8459 
2024-12-08 05:59:56.210395: Pseudo dice [np.float32(0.8917), np.float32(0.8764)] 
2024-12-08 05:59:56.213491: Epoch time: 6.35 s 
2024-12-08 05:59:56.216022: Yayy! New best EMA pseudo Dice: 0.8755999803543091 
2024-12-08 05:59:56.967332:  
2024-12-08 05:59:56.972912: Epoch 21 
2024-12-08 05:59:56.975442: Current learning rate: 0.00809 
2024-12-08 06:00:03.325351: train_loss -0.8629 
2024-12-08 06:00:03.330484: val_loss -0.8479 
2024-12-08 06:00:03.334548: Pseudo dice [np.float32(0.8957), np.float32(0.8766)] 
2024-12-08 06:00:03.338614: Epoch time: 6.36 s 
2024-12-08 06:00:03.340631: Yayy! New best EMA pseudo Dice: 0.8766000270843506 
2024-12-08 06:00:03.915220:  
2024-12-08 06:00:03.920282: Epoch 22 
2024-12-08 06:00:03.923835: Current learning rate: 0.008 
2024-12-08 06:00:10.275267: train_loss -0.8622 
2024-12-08 06:00:10.279839: val_loss -0.8506 
2024-12-08 06:00:10.284410: Pseudo dice [np.float32(0.8956), np.float32(0.8799)] 
2024-12-08 06:00:10.286938: Epoch time: 6.36 s 
2024-12-08 06:00:10.289507: Yayy! New best EMA pseudo Dice: 0.8776999711990356 
2024-12-08 06:00:10.871744:  
2024-12-08 06:00:10.877374: Epoch 23 
2024-12-08 06:00:10.880422: Current learning rate: 0.0079 
2024-12-08 06:00:17.228075: train_loss -0.8624 
2024-12-08 06:00:17.233697: val_loss -0.8462 
2024-12-08 06:00:17.236752: Pseudo dice [np.float32(0.8923), np.float32(0.8761)] 
2024-12-08 06:00:17.239824: Epoch time: 6.36 s 
2024-12-08 06:00:17.242367: Yayy! New best EMA pseudo Dice: 0.8784000277519226 
2024-12-08 06:00:17.819029:  
2024-12-08 06:00:17.824081: Epoch 24 
2024-12-08 06:00:17.826605: Current learning rate: 0.00781 
2024-12-08 06:00:24.179199: train_loss -0.8647 
2024-12-08 06:00:24.186873: val_loss -0.8502 
2024-12-08 06:00:24.189448: Pseudo dice [np.float32(0.8979), np.float32(0.8787)] 
2024-12-08 06:00:24.191471: Epoch time: 6.36 s 
2024-12-08 06:00:24.196005: Yayy! New best EMA pseudo Dice: 0.8794000148773193 
2024-12-08 06:00:24.773340:  
2024-12-08 06:00:24.780494: Epoch 25 
2024-12-08 06:00:24.785566: Current learning rate: 0.00772 
2024-12-08 06:00:31.137072: train_loss -0.867 
2024-12-08 06:00:31.142204: val_loss -0.8478 
2024-12-08 06:00:31.144742: Pseudo dice [np.float32(0.8942), np.float32(0.8773)] 
2024-12-08 06:00:31.148279: Epoch time: 6.36 s 
2024-12-08 06:00:31.151817: Yayy! New best EMA pseudo Dice: 0.8799999952316284 
2024-12-08 06:00:31.737557:  
2024-12-08 06:00:31.742612: Epoch 26 
2024-12-08 06:00:31.745655: Current learning rate: 0.00763 
2024-12-08 06:00:38.095142: train_loss -0.8654 
2024-12-08 06:00:38.102265: val_loss -0.8477 
2024-12-08 06:00:38.105330: Pseudo dice [np.float32(0.8941), np.float32(0.8791)] 
2024-12-08 06:00:38.107872: Epoch time: 6.36 s 
2024-12-08 06:00:38.111462: Yayy! New best EMA pseudo Dice: 0.8806999921798706 
2024-12-08 06:00:38.698944:  
2024-12-08 06:00:38.704121: Epoch 27 
2024-12-08 06:00:38.709185: Current learning rate: 0.00753 
2024-12-08 06:00:45.055900: train_loss -0.8675 
2024-12-08 06:00:45.061475: val_loss -0.8466 
2024-12-08 06:00:45.065559: Pseudo dice [np.float32(0.8922), np.float32(0.878)] 
2024-12-08 06:00:45.068607: Epoch time: 6.36 s 
2024-12-08 06:00:45.071137: Yayy! New best EMA pseudo Dice: 0.8810999989509583 
2024-12-08 06:00:45.644202:  
2024-12-08 06:00:45.649782: Epoch 28 
2024-12-08 06:00:45.652317: Current learning rate: 0.00744 
2024-12-08 06:00:52.011091: train_loss -0.8691 
2024-12-08 06:00:52.017197: val_loss -0.8502 
2024-12-08 06:00:52.019746: Pseudo dice [np.float32(0.896), np.float32(0.8785)] 
2024-12-08 06:00:52.023313: Epoch time: 6.37 s 
2024-12-08 06:00:52.025842: Yayy! New best EMA pseudo Dice: 0.8816999793052673 
2024-12-08 06:00:52.757366:  
2024-12-08 06:00:52.762445: Epoch 29 
2024-12-08 06:00:52.764969: Current learning rate: 0.00735 
2024-12-08 06:00:59.120002: train_loss -0.8693 
2024-12-08 06:00:59.126106: val_loss -0.852 
2024-12-08 06:00:59.128643: Pseudo dice [np.float32(0.8971), np.float32(0.8804)] 
2024-12-08 06:00:59.131175: Epoch time: 6.36 s 
2024-12-08 06:00:59.135267: Yayy! New best EMA pseudo Dice: 0.8823999762535095 
2024-12-08 06:00:59.722437:  
2024-12-08 06:00:59.729043: Epoch 30 
2024-12-08 06:00:59.732086: Current learning rate: 0.00725 
2024-12-08 06:01:06.084563: train_loss -0.8706 
2024-12-08 06:01:06.090713: val_loss -0.8486 
2024-12-08 06:01:06.093244: Pseudo dice [np.float32(0.8953), np.float32(0.8765)] 
2024-12-08 06:01:06.095770: Epoch time: 6.36 s 
2024-12-08 06:01:06.099803: Yayy! New best EMA pseudo Dice: 0.8827999830245972 
2024-12-08 06:01:06.692071:  
2024-12-08 06:01:06.697179: Epoch 31 
2024-12-08 06:01:06.700228: Current learning rate: 0.00716 
2024-12-08 06:01:13.044631: train_loss -0.8705 
2024-12-08 06:01:13.049790: val_loss -0.8485 
2024-12-08 06:01:13.053348: Pseudo dice [np.float32(0.896), np.float32(0.879)] 
2024-12-08 06:01:13.056408: Epoch time: 6.35 s 
2024-12-08 06:01:13.059451: Yayy! New best EMA pseudo Dice: 0.8831999897956848 
2024-12-08 06:01:13.641868:  
2024-12-08 06:01:13.646924: Epoch 32 
2024-12-08 06:01:13.649449: Current learning rate: 0.00707 
2024-12-08 06:01:19.995200: train_loss -0.8724 
2024-12-08 06:01:20.001827: val_loss -0.8455 
2024-12-08 06:01:20.005378: Pseudo dice [np.float32(0.8948), np.float32(0.8742)] 
2024-12-08 06:01:20.007912: Epoch time: 6.35 s 
2024-12-08 06:01:20.011497: Yayy! New best EMA pseudo Dice: 0.883400022983551 
2024-12-08 06:01:20.612814:  
2024-12-08 06:01:20.618905: Epoch 33 
2024-12-08 06:01:20.622442: Current learning rate: 0.00697 
2024-12-08 06:01:26.976495: train_loss -0.8737 
2024-12-08 06:01:26.981588: val_loss -0.8483 
2024-12-08 06:01:26.984683: Pseudo dice [np.float32(0.8957), np.float32(0.8768)] 
2024-12-08 06:01:26.987719: Epoch time: 6.36 s 
2024-12-08 06:01:26.990248: Yayy! New best EMA pseudo Dice: 0.8837000131607056 
2024-12-08 06:01:27.581734:  
2024-12-08 06:01:27.587315: Epoch 34 
2024-12-08 06:01:27.589859: Current learning rate: 0.00688 
2024-12-08 06:01:33.929350: train_loss -0.8721 
2024-12-08 06:01:33.934449: val_loss -0.8435 
2024-12-08 06:01:33.938057: Pseudo dice [np.float32(0.8931), np.float32(0.8742)] 
2024-12-08 06:01:33.941102: Epoch time: 6.35 s 
2024-12-08 06:01:34.498980:  
2024-12-08 06:01:34.504052: Epoch 35 
2024-12-08 06:01:34.507100: Current learning rate: 0.00679 
2024-12-08 06:01:40.857611: train_loss -0.8731 
2024-12-08 06:01:40.863192: val_loss -0.85 
2024-12-08 06:01:40.865721: Pseudo dice [np.float32(0.8972), np.float32(0.88)] 
2024-12-08 06:01:40.870335: Epoch time: 6.36 s 
2024-12-08 06:01:40.872886: Yayy! New best EMA pseudo Dice: 0.8841999769210815 
2024-12-08 06:01:41.477844:  
2024-12-08 06:01:41.483980: Epoch 36 
2024-12-08 06:01:41.486515: Current learning rate: 0.00669 
2024-12-08 06:01:47.829093: train_loss -0.8746 
2024-12-08 06:01:47.834159: val_loss -0.8516 
2024-12-08 06:01:47.836725: Pseudo dice [np.float32(0.8979), np.float32(0.8795)] 
2024-12-08 06:01:47.841784: Epoch time: 6.35 s 
2024-12-08 06:01:47.844831: Yayy! New best EMA pseudo Dice: 0.8845999836921692 
2024-12-08 06:01:48.592750:  
2024-12-08 06:01:48.598325: Epoch 37 
2024-12-08 06:01:48.601396: Current learning rate: 0.0066 
2024-12-08 06:01:54.942088: train_loss -0.876 
2024-12-08 06:01:54.947151: val_loss -0.8479 
2024-12-08 06:01:54.950185: Pseudo dice [np.float32(0.895), np.float32(0.8787)] 
2024-12-08 06:01:54.953265: Epoch time: 6.35 s 
2024-12-08 06:01:54.955805: Yayy! New best EMA pseudo Dice: 0.8848000168800354 
2024-12-08 06:01:55.553665:  
2024-12-08 06:01:55.558737: Epoch 38 
2024-12-08 06:01:55.561791: Current learning rate: 0.0065 
2024-12-08 06:02:01.899207: train_loss -0.8757 
2024-12-08 06:02:01.904261: val_loss -0.8496 
2024-12-08 06:02:01.908305: Pseudo dice [np.float32(0.8965), np.float32(0.878)] 
2024-12-08 06:02:01.910836: Epoch time: 6.35 s 
2024-12-08 06:02:01.913929: Yayy! New best EMA pseudo Dice: 0.8851000070571899 
2024-12-08 06:02:02.515045:  
2024-12-08 06:02:02.520647: Epoch 39 
2024-12-08 06:02:02.523244: Current learning rate: 0.00641 
2024-12-08 06:02:08.882852: train_loss -0.8756 
2024-12-08 06:02:08.887951: val_loss -0.8495 
2024-12-08 06:02:08.890484: Pseudo dice [np.float32(0.8968), np.float32(0.877)] 
2024-12-08 06:02:08.893014: Epoch time: 6.37 s 
2024-12-08 06:02:08.897151: Yayy! New best EMA pseudo Dice: 0.8852999806404114 
2024-12-08 06:02:09.512893:  
2024-12-08 06:02:09.517970: Epoch 40 
2024-12-08 06:02:09.520500: Current learning rate: 0.00631 
2024-12-08 06:02:15.864841: train_loss -0.8768 
2024-12-08 06:02:15.870991: val_loss -0.8502 
2024-12-08 06:02:15.874043: Pseudo dice [np.float32(0.8973), np.float32(0.8782)] 
2024-12-08 06:02:15.877589: Epoch time: 6.35 s 
2024-12-08 06:02:15.880656: Yayy! New best EMA pseudo Dice: 0.8855000138282776 
2024-12-08 06:02:16.488955:  
2024-12-08 06:02:16.494034: Epoch 41 
2024-12-08 06:02:16.499095: Current learning rate: 0.00622 
2024-12-08 06:02:22.846022: train_loss -0.8784 
2024-12-08 06:02:22.852643: val_loss -0.8499 
2024-12-08 06:02:22.855182: Pseudo dice [np.float32(0.8977), np.float32(0.8782)] 
2024-12-08 06:02:22.858730: Epoch time: 6.36 s 
2024-12-08 06:02:22.861260: Yayy! New best EMA pseudo Dice: 0.8858000040054321 
2024-12-08 06:02:23.431384:  
2024-12-08 06:02:23.436964: Epoch 42 
2024-12-08 06:02:23.439508: Current learning rate: 0.00612 
2024-12-08 06:02:29.796271: train_loss -0.8784 
2024-12-08 06:02:29.801407: val_loss -0.8447 
2024-12-08 06:02:29.803947: Pseudo dice [np.float32(0.8937), np.float32(0.8764)] 
2024-12-08 06:02:29.807498: Epoch time: 6.37 s 
2024-12-08 06:02:30.357001:  
2024-12-08 06:02:30.362619: Epoch 43 
2024-12-08 06:02:30.365667: Current learning rate: 0.00603 
2024-12-08 06:02:36.706376: train_loss -0.8772 
2024-12-08 06:02:36.711505: val_loss -0.8476 
2024-12-08 06:02:36.714561: Pseudo dice [np.float32(0.8956), np.float32(0.8785)] 
2024-12-08 06:02:36.716587: Epoch time: 6.35 s 
2024-12-08 06:02:36.720630: Yayy! New best EMA pseudo Dice: 0.8858000040054321 
2024-12-08 06:02:37.298494:  
2024-12-08 06:02:37.304100: Epoch 44 
2024-12-08 06:02:37.307137: Current learning rate: 0.00593 
2024-12-08 06:02:43.651732: train_loss -0.8796 
2024-12-08 06:02:43.656794: val_loss -0.8496 
2024-12-08 06:02:43.659920: Pseudo dice [np.float32(0.8974), np.float32(0.8793)] 
2024-12-08 06:02:43.663465: Epoch time: 6.35 s 
2024-12-08 06:02:43.666504: Yayy! New best EMA pseudo Dice: 0.8860999941825867 
2024-12-08 06:02:44.383302:  
2024-12-08 06:02:44.390436: Epoch 45 
2024-12-08 06:02:44.393491: Current learning rate: 0.00584 
2024-12-08 06:02:50.753712: train_loss -0.8795 
2024-12-08 06:02:50.758793: val_loss -0.8441 
2024-12-08 06:02:50.761323: Pseudo dice [np.float32(0.892), np.float32(0.8748)] 
2024-12-08 06:02:50.764951: Epoch time: 6.37 s 
2024-12-08 06:02:51.308471:  
2024-12-08 06:02:51.313526: Epoch 46 
2024-12-08 06:02:51.316055: Current learning rate: 0.00574 
2024-12-08 06:02:57.647309: train_loss -0.883 
2024-12-08 06:02:57.651903: val_loss -0.8488 
2024-12-08 06:02:57.655989: Pseudo dice [np.float32(0.8972), np.float32(0.879)] 
2024-12-08 06:02:57.659033: Epoch time: 6.34 s 
2024-12-08 06:02:58.203862:  
2024-12-08 06:02:58.206903: Epoch 47 
2024-12-08 06:02:58.211513: Current learning rate: 0.00565 
2024-12-08 06:03:04.549125: train_loss -0.8832 
2024-12-08 06:03:04.554251: val_loss -0.8486 
2024-12-08 06:03:04.556781: Pseudo dice [np.float32(0.8965), np.float32(0.8796)] 
2024-12-08 06:03:04.561329: Epoch time: 6.35 s 
2024-12-08 06:03:04.564382: Yayy! New best EMA pseudo Dice: 0.8862000107765198 
2024-12-08 06:03:05.131496:  
2024-12-08 06:03:05.138067: Epoch 48 
2024-12-08 06:03:05.141108: Current learning rate: 0.00555 
2024-12-08 06:03:11.486575: train_loss -0.8825 
2024-12-08 06:03:11.491662: val_loss -0.8454 
2024-12-08 06:03:11.494200: Pseudo dice [np.float32(0.8935), np.float32(0.8772)] 
2024-12-08 06:03:11.498295: Epoch time: 6.36 s 
2024-12-08 06:03:12.047082:  
2024-12-08 06:03:12.052709: Epoch 49 
2024-12-08 06:03:12.055243: Current learning rate: 0.00546 
2024-12-08 06:03:18.390984: train_loss -0.884 
2024-12-08 06:03:18.396150: val_loss -0.8477 
2024-12-08 06:03:18.400221: Pseudo dice [np.float32(0.8961), np.float32(0.8772)] 
2024-12-08 06:03:18.402749: Epoch time: 6.34 s 
2024-12-08 06:03:18.989171:  
2024-12-08 06:03:18.994233: Epoch 50 
2024-12-08 06:03:18.996796: Current learning rate: 0.00536 
2024-12-08 06:03:25.352695: train_loss -0.8832 
2024-12-08 06:03:25.358895: val_loss -0.8454 
2024-12-08 06:03:25.361427: Pseudo dice [np.float32(0.895), np.float32(0.8763)] 
2024-12-08 06:03:25.365969: Epoch time: 6.36 s 
2024-12-08 06:03:25.909878:  
2024-12-08 06:03:25.915452: Epoch 51 
2024-12-08 06:03:25.918020: Current learning rate: 0.00526 
2024-12-08 06:03:32.255572: train_loss -0.8838 
2024-12-08 06:03:32.260681: val_loss -0.8528 
2024-12-08 06:03:32.263221: Pseudo dice [np.float32(0.9), np.float32(0.881)] 
2024-12-08 06:03:32.267757: Epoch time: 6.35 s 
2024-12-08 06:03:32.270815: Yayy! New best EMA pseudo Dice: 0.8866000175476074 
2024-12-08 06:03:32.852919:  
2024-12-08 06:03:32.858529: Epoch 52 
2024-12-08 06:03:32.861062: Current learning rate: 0.00517 
2024-12-08 06:03:39.201417: train_loss -0.8839 
2024-12-08 06:03:39.206528: val_loss -0.8482 
2024-12-08 06:03:39.210122: Pseudo dice [np.float32(0.8961), np.float32(0.8789)] 
2024-12-08 06:03:39.212658: Epoch time: 6.35 s 
2024-12-08 06:03:39.216693: Yayy! New best EMA pseudo Dice: 0.8866999745368958 
2024-12-08 06:03:39.955175:  
2024-12-08 06:03:39.961272: Epoch 53 
2024-12-08 06:03:39.965358: Current learning rate: 0.00507 
2024-12-08 06:03:46.308666: train_loss -0.885 
2024-12-08 06:03:46.313814: val_loss -0.8524 
2024-12-08 06:03:46.317392: Pseudo dice [np.float32(0.8991), np.float32(0.8803)] 
2024-12-08 06:03:46.320448: Epoch time: 6.35 s 
2024-12-08 06:03:46.323985: Yayy! New best EMA pseudo Dice: 0.8870000243186951 
2024-12-08 06:03:46.906341:  
2024-12-08 06:03:46.911402: Epoch 54 
2024-12-08 06:03:46.913936: Current learning rate: 0.00497 
2024-12-08 06:03:53.266948: train_loss -0.8857 
2024-12-08 06:03:53.272581: val_loss -0.8447 
2024-12-08 06:03:53.275700: Pseudo dice [np.float32(0.8943), np.float32(0.8755)] 
2024-12-08 06:03:53.278232: Epoch time: 6.36 s 
2024-12-08 06:03:53.826400:  
2024-12-08 06:03:53.831453: Epoch 55 
2024-12-08 06:03:53.834496: Current learning rate: 0.00487 
2024-12-08 06:04:00.169362: train_loss -0.8874 
2024-12-08 06:04:00.174564: val_loss -0.8447 
2024-12-08 06:04:00.177123: Pseudo dice [np.float32(0.8949), np.float32(0.876)] 
2024-12-08 06:04:00.182350: Epoch time: 6.34 s 
2024-12-08 06:04:00.738209:  
2024-12-08 06:04:00.743842: Epoch 56 
2024-12-08 06:04:00.746893: Current learning rate: 0.00478 
2024-12-08 06:04:07.099838: train_loss -0.8869 
2024-12-08 06:04:07.104936: val_loss -0.8491 
2024-12-08 06:04:07.108489: Pseudo dice [np.float32(0.8968), np.float32(0.8787)] 
2024-12-08 06:04:07.111585: Epoch time: 6.36 s 
2024-12-08 06:04:07.660210:  
2024-12-08 06:04:07.666280: Epoch 57 
2024-12-08 06:04:07.669320: Current learning rate: 0.00468 
2024-12-08 06:04:14.013435: train_loss -0.8885 
2024-12-08 06:04:14.019001: val_loss -0.8455 
2024-12-08 06:04:14.022542: Pseudo dice [np.float32(0.8956), np.float32(0.8748)] 
2024-12-08 06:04:14.025654: Epoch time: 6.35 s 
2024-12-08 06:04:14.565819:  
2024-12-08 06:04:14.571923: Epoch 58 
2024-12-08 06:04:14.575473: Current learning rate: 0.00458 
2024-12-08 06:04:20.919956: train_loss -0.8862 
2024-12-08 06:04:20.926576: val_loss -0.8491 
2024-12-08 06:04:20.930137: Pseudo dice [np.float32(0.8986), np.float32(0.8792)] 
2024-12-08 06:04:20.932670: Epoch time: 6.35 s 
2024-12-08 06:04:21.495612:  
2024-12-08 06:04:21.501266: Epoch 59 
2024-12-08 06:04:21.504324: Current learning rate: 0.00448 
2024-12-08 06:04:27.850492: train_loss -0.8876 
2024-12-08 06:04:27.855577: val_loss -0.8522 
2024-12-08 06:04:27.858121: Pseudo dice [np.float32(0.8993), np.float32(0.881)] 
2024-12-08 06:04:27.861159: Epoch time: 6.35 s 
2024-12-08 06:04:27.865190: Yayy! New best EMA pseudo Dice: 0.8871999979019165 
2024-12-08 06:04:28.460749:  
2024-12-08 06:04:28.465823: Epoch 60 
2024-12-08 06:04:28.469444: Current learning rate: 0.00438 
2024-12-08 06:04:34.818689: train_loss -0.8883 
2024-12-08 06:04:34.824359: val_loss -0.8445 
2024-12-08 06:04:34.827408: Pseudo dice [np.float32(0.8941), np.float32(0.8752)] 
2024-12-08 06:04:34.829956: Epoch time: 6.36 s 
2024-12-08 06:04:35.530370:  
2024-12-08 06:04:35.535964: Epoch 61 
2024-12-08 06:04:35.538494: Current learning rate: 0.00429 
2024-12-08 06:04:41.882959: train_loss -0.89 
2024-12-08 06:04:41.888099: val_loss -0.8434 
2024-12-08 06:04:41.891156: Pseudo dice [np.float32(0.8926), np.float32(0.8744)] 
2024-12-08 06:04:41.893186: Epoch time: 6.35 s 
2024-12-08 06:04:42.454417:  
2024-12-08 06:04:42.460071: Epoch 62 
2024-12-08 06:04:42.462610: Current learning rate: 0.00419 
2024-12-08 06:04:48.809625: train_loss -0.8899 
2024-12-08 06:04:48.815232: val_loss -0.847 
2024-12-08 06:04:48.818319: Pseudo dice [np.float32(0.8965), np.float32(0.8775)] 
2024-12-08 06:04:48.822376: Epoch time: 6.36 s 
2024-12-08 06:04:49.386335:  
2024-12-08 06:04:49.392910: Epoch 63 
2024-12-08 06:04:49.395947: Current learning rate: 0.00409 
2024-12-08 06:04:55.728821: train_loss -0.8912 
2024-12-08 06:04:55.734473: val_loss -0.8455 
2024-12-08 06:04:55.737010: Pseudo dice [np.float32(0.8952), np.float32(0.8766)] 
2024-12-08 06:04:55.739543: Epoch time: 6.34 s 
2024-12-08 06:04:56.293590:  
2024-12-08 06:04:56.298653: Epoch 64 
2024-12-08 06:04:56.301709: Current learning rate: 0.00399 
2024-12-08 06:05:02.654824: train_loss -0.8914 
2024-12-08 06:05:02.659977: val_loss -0.8459 
2024-12-08 06:05:02.663546: Pseudo dice [np.float32(0.8948), np.float32(0.8768)] 
2024-12-08 06:05:02.666654: Epoch time: 6.36 s 
2024-12-08 06:05:03.222235:  
2024-12-08 06:05:03.227298: Epoch 65 
2024-12-08 06:05:03.230344: Current learning rate: 0.00389 
2024-12-08 06:05:09.594796: train_loss -0.8919 
2024-12-08 06:05:09.599874: val_loss -0.8513 
2024-12-08 06:05:09.602407: Pseudo dice [np.float32(0.8979), np.float32(0.8814)] 
2024-12-08 06:05:09.605939: Epoch time: 6.37 s 
2024-12-08 06:05:10.171608:  
2024-12-08 06:05:10.176692: Epoch 66 
2024-12-08 06:05:10.179737: Current learning rate: 0.00379 
2024-12-08 06:05:16.527194: train_loss -0.8937 
2024-12-08 06:05:16.532295: val_loss -0.8454 
2024-12-08 06:05:16.535339: Pseudo dice [np.float32(0.8945), np.float32(0.8776)] 
2024-12-08 06:05:16.537868: Epoch time: 6.36 s 
2024-12-08 06:05:17.093174:  
2024-12-08 06:05:17.098232: Epoch 67 
2024-12-08 06:05:17.101771: Current learning rate: 0.00369 
2024-12-08 06:05:23.438802: train_loss -0.8917 
2024-12-08 06:05:23.445455: val_loss -0.8403 
2024-12-08 06:05:23.449568: Pseudo dice [np.float32(0.8895), np.float32(0.8745)] 
2024-12-08 06:05:23.452101: Epoch time: 6.35 s 
2024-12-08 06:05:24.161736:  
2024-12-08 06:05:24.167343: Epoch 68 
2024-12-08 06:05:24.170390: Current learning rate: 0.00359 
2024-12-08 06:05:30.517408: train_loss -0.8945 
2024-12-08 06:05:30.522548: val_loss -0.8403 
2024-12-08 06:05:30.526112: Pseudo dice [np.float32(0.892), np.float32(0.872)] 
2024-12-08 06:05:30.528196: Epoch time: 6.36 s 
2024-12-08 06:05:31.112108:  
2024-12-08 06:05:31.117176: Epoch 69 
2024-12-08 06:05:31.120242: Current learning rate: 0.00349 
2024-12-08 06:05:37.489238: train_loss -0.8945 
2024-12-08 06:05:37.494865: val_loss -0.8473 
2024-12-08 06:05:37.497396: Pseudo dice [np.float32(0.8959), np.float32(0.8788)] 
2024-12-08 06:05:37.499929: Epoch time: 6.38 s 
2024-12-08 06:05:38.061886:  
2024-12-08 06:05:38.067500: Epoch 70 
2024-12-08 06:05:38.070543: Current learning rate: 0.00338 
2024-12-08 06:05:44.414738: train_loss -0.8936 
2024-12-08 06:05:44.420392: val_loss -0.8461 
2024-12-08 06:05:44.423476: Pseudo dice [np.float32(0.895), np.float32(0.8784)] 
2024-12-08 06:05:44.425536: Epoch time: 6.35 s 
2024-12-08 06:05:44.987070:  
2024-12-08 06:05:44.992148: Epoch 71 
2024-12-08 06:05:44.995196: Current learning rate: 0.00328 
2024-12-08 06:05:51.347944: train_loss -0.8932 
2024-12-08 06:05:51.353131: val_loss -0.8437 
2024-12-08 06:05:51.356686: Pseudo dice [np.float32(0.8942), np.float32(0.8761)] 
2024-12-08 06:05:51.359776: Epoch time: 6.36 s 
2024-12-08 06:05:51.930129:  
2024-12-08 06:05:51.935190: Epoch 72 
2024-12-08 06:05:51.938231: Current learning rate: 0.00318 
2024-12-08 06:05:58.285515: train_loss -0.8953 
2024-12-08 06:05:58.290113: val_loss -0.8487 
2024-12-08 06:05:58.293194: Pseudo dice [np.float32(0.8955), np.float32(0.8803)] 
2024-12-08 06:05:58.297233: Epoch time: 6.36 s 
2024-12-08 06:05:58.867666:  
2024-12-08 06:05:58.872723: Epoch 73 
2024-12-08 06:05:58.875764: Current learning rate: 0.00308 
2024-12-08 06:06:05.237466: train_loss -0.8956 
2024-12-08 06:06:05.243546: val_loss -0.8453 
2024-12-08 06:06:05.246660: Pseudo dice [np.float32(0.8951), np.float32(0.8771)] 
2024-12-08 06:06:05.249705: Epoch time: 6.37 s 
2024-12-08 06:06:05.810754:  
2024-12-08 06:06:05.816315: Epoch 74 
2024-12-08 06:06:05.819850: Current learning rate: 0.00297 
2024-12-08 06:06:12.173093: train_loss -0.8955 
2024-12-08 06:06:12.178192: val_loss -0.842 
2024-12-08 06:06:12.181757: Pseudo dice [np.float32(0.8936), np.float32(0.8748)] 
2024-12-08 06:06:12.184798: Epoch time: 6.36 s 
2024-12-08 06:06:12.763174:  
2024-12-08 06:06:12.768317: Epoch 75 
2024-12-08 06:06:12.771370: Current learning rate: 0.00287 
2024-12-08 06:06:19.110024: train_loss -0.8969 
2024-12-08 06:06:19.115616: val_loss -0.8516 
2024-12-08 06:06:19.120214: Pseudo dice [np.float32(0.8997), np.float32(0.8826)] 
2024-12-08 06:06:19.122744: Epoch time: 6.35 s 
2024-12-08 06:06:19.847658:  
2024-12-08 06:06:19.853307: Epoch 76 
2024-12-08 06:06:19.855836: Current learning rate: 0.00277 
2024-12-08 06:06:26.199879: train_loss -0.8969 
2024-12-08 06:06:26.205462: val_loss -0.8439 
2024-12-08 06:06:26.208614: Pseudo dice [np.float32(0.894), np.float32(0.8776)] 
2024-12-08 06:06:26.211661: Epoch time: 6.35 s 
2024-12-08 06:06:26.778741:  
2024-12-08 06:06:26.783815: Epoch 77 
2024-12-08 06:06:26.787379: Current learning rate: 0.00266 
2024-12-08 06:06:33.134749: train_loss -0.8968 
2024-12-08 06:06:33.140350: val_loss -0.8432 
2024-12-08 06:06:33.143396: Pseudo dice [np.float32(0.8941), np.float32(0.8765)] 
2024-12-08 06:06:33.146469: Epoch time: 6.36 s 
2024-12-08 06:06:33.714653:  
2024-12-08 06:06:33.720295: Epoch 78 
2024-12-08 06:06:33.722831: Current learning rate: 0.00256 
2024-12-08 06:06:40.060206: train_loss -0.8964 
2024-12-08 06:06:40.065800: val_loss -0.8439 
2024-12-08 06:06:40.069361: Pseudo dice [np.float32(0.8933), np.float32(0.8786)] 
2024-12-08 06:06:40.072453: Epoch time: 6.35 s 
2024-12-08 06:06:40.651186:  
2024-12-08 06:06:40.656273: Epoch 79 
2024-12-08 06:06:40.658801: Current learning rate: 0.00245 
2024-12-08 06:06:46.985812: train_loss -0.8967 
2024-12-08 06:06:46.991420: val_loss -0.8443 
2024-12-08 06:06:46.993963: Pseudo dice [np.float32(0.8954), np.float32(0.8767)] 
2024-12-08 06:06:46.996567: Epoch time: 6.34 s 
2024-12-08 06:06:47.567517:  
2024-12-08 06:06:47.572566: Epoch 80 
2024-12-08 06:06:47.575131: Current learning rate: 0.00235 
2024-12-08 06:06:53.908971: train_loss -0.8975 
2024-12-08 06:06:53.914650: val_loss -0.8468 
2024-12-08 06:06:53.918205: Pseudo dice [np.float32(0.8961), np.float32(0.8787)] 
2024-12-08 06:06:53.921254: Epoch time: 6.34 s 
2024-12-08 06:06:54.495858:  
2024-12-08 06:06:54.500911: Epoch 81 
2024-12-08 06:06:54.503438: Current learning rate: 0.00224 
2024-12-08 06:07:00.851079: train_loss -0.8983 
2024-12-08 06:07:00.856184: val_loss -0.8457 
2024-12-08 06:07:00.858724: Pseudo dice [np.float32(0.8949), np.float32(0.8783)] 
2024-12-08 06:07:00.862263: Epoch time: 6.36 s 
2024-12-08 06:07:01.446947:  
2024-12-08 06:07:01.452046: Epoch 82 
2024-12-08 06:07:01.454571: Current learning rate: 0.00214 
2024-12-08 06:07:07.817200: train_loss -0.8996 
2024-12-08 06:07:07.822904: val_loss -0.8496 
2024-12-08 06:07:07.826020: Pseudo dice [np.float32(0.8978), np.float32(0.8822)] 
2024-12-08 06:07:07.829111: Epoch time: 6.37 s 
2024-12-08 06:07:08.369885:  
2024-12-08 06:07:08.376478: Epoch 83 
2024-12-08 06:07:08.379536: Current learning rate: 0.00203 
2024-12-08 06:07:14.909189: train_loss -0.8979 
2024-12-08 06:07:14.915331: val_loss -0.8469 
2024-12-08 06:07:14.918875: Pseudo dice [np.float32(0.8967), np.float32(0.879)] 
2024-12-08 06:07:14.921405: Epoch time: 6.54 s 
2024-12-08 06:07:15.458279:  
2024-12-08 06:07:15.463395: Epoch 84 
2024-12-08 06:07:15.466443: Current learning rate: 0.00192 
2024-12-08 06:07:21.817109: train_loss -0.9008 
2024-12-08 06:07:21.823834: val_loss -0.8503 
2024-12-08 06:07:21.828952: Pseudo dice [np.float32(0.8988), np.float32(0.8797)] 
2024-12-08 06:07:21.831496: Epoch time: 6.36 s 
2024-12-08 06:07:22.385318:  
2024-12-08 06:07:22.391401: Epoch 85 
2024-12-08 06:07:22.393931: Current learning rate: 0.00181 
2024-12-08 06:07:28.735999: train_loss -0.8992 
2024-12-08 06:07:28.742597: val_loss -0.8487 
2024-12-08 06:07:28.745653: Pseudo dice [np.float32(0.8973), np.float32(0.88)] 
2024-12-08 06:07:28.748243: Epoch time: 6.35 s 
2024-12-08 06:07:28.750772: Yayy! New best EMA pseudo Dice: 0.8873000144958496 
2024-12-08 06:07:29.334372:  
2024-12-08 06:07:29.340465: Epoch 86 
2024-12-08 06:07:29.344561: Current learning rate: 0.0017 
2024-12-08 06:07:35.680660: train_loss -0.9003 
2024-12-08 06:07:35.686249: val_loss -0.8478 
2024-12-08 06:07:35.689353: Pseudo dice [np.float32(0.897), np.float32(0.8792)] 
2024-12-08 06:07:35.692389: Epoch time: 6.35 s 
2024-12-08 06:07:35.694412: Yayy! New best EMA pseudo Dice: 0.8873000144958496 
2024-12-08 06:07:36.269905:  
2024-12-08 06:07:36.277001: Epoch 87 
2024-12-08 06:07:36.280054: Current learning rate: 0.00159 
2024-12-08 06:07:42.633327: train_loss -0.9014 
2024-12-08 06:07:42.638937: val_loss -0.8445 
2024-12-08 06:07:42.641982: Pseudo dice [np.float32(0.8952), np.float32(0.8771)] 
2024-12-08 06:07:42.644512: Epoch time: 6.36 s 
2024-12-08 06:07:43.191800:  
2024-12-08 06:07:43.197429: Epoch 88 
2024-12-08 06:07:43.200964: Current learning rate: 0.00148 
2024-12-08 06:07:49.546255: train_loss -0.9013 
2024-12-08 06:07:49.552878: val_loss -0.8445 
2024-12-08 06:07:49.556436: Pseudo dice [np.float32(0.895), np.float32(0.8768)] 
2024-12-08 06:07:49.559474: Epoch time: 6.35 s 
2024-12-08 06:07:50.110005:  
2024-12-08 06:07:50.116087: Epoch 89 
2024-12-08 06:07:50.118619: Current learning rate: 0.00137 
2024-12-08 06:07:56.457884: train_loss -0.9016 
2024-12-08 06:07:56.464011: val_loss -0.8446 
2024-12-08 06:07:56.466552: Pseudo dice [np.float32(0.8951), np.float32(0.8777)] 
2024-12-08 06:07:56.470150: Epoch time: 6.35 s 
2024-12-08 06:07:57.007359:  
2024-12-08 06:07:57.012520: Epoch 90 
2024-12-08 06:07:57.016073: Current learning rate: 0.00126 
2024-12-08 06:08:03.359902: train_loss -0.9003 
2024-12-08 06:08:03.364998: val_loss -0.8447 
2024-12-08 06:08:03.369119: Pseudo dice [np.float32(0.8945), np.float32(0.8786)] 
2024-12-08 06:08:03.372164: Epoch time: 6.35 s 
2024-12-08 06:08:03.908042:  
2024-12-08 06:08:03.913613: Epoch 91 
2024-12-08 06:08:03.916178: Current learning rate: 0.00115 
2024-12-08 06:08:10.251606: train_loss -0.9014 
2024-12-08 06:08:10.256699: val_loss -0.8476 
2024-12-08 06:08:10.260246: Pseudo dice [np.float32(0.8979), np.float32(0.8789)] 
2024-12-08 06:08:10.263829: Epoch time: 6.35 s 
2024-12-08 06:08:10.958323:  
2024-12-08 06:08:10.963935: Epoch 92 
2024-12-08 06:08:10.965958: Current learning rate: 0.00103 
2024-12-08 06:08:17.290092: train_loss -0.9024 
2024-12-08 06:08:17.295146: val_loss -0.8498 
2024-12-08 06:08:17.299690: Pseudo dice [np.float32(0.899), np.float32(0.8812)] 
2024-12-08 06:08:17.302805: Epoch time: 6.33 s 
2024-12-08 06:08:17.305345: Yayy! New best EMA pseudo Dice: 0.8873999714851379 
2024-12-08 06:08:17.877351:  
2024-12-08 06:08:17.882405: Epoch 93 
2024-12-08 06:08:17.886030: Current learning rate: 0.00091 
2024-12-08 06:08:24.221952: train_loss -0.9023 
2024-12-08 06:08:24.229106: val_loss -0.8478 
2024-12-08 06:08:24.233148: Pseudo dice [np.float32(0.8967), np.float32(0.8801)] 
2024-12-08 06:08:24.236231: Epoch time: 6.35 s 
2024-12-08 06:08:24.238761: Yayy! New best EMA pseudo Dice: 0.887499988079071 
2024-12-08 06:08:24.810904:  
2024-12-08 06:08:24.815988: Epoch 94 
2024-12-08 06:08:24.819535: Current learning rate: 0.00079 
2024-12-08 06:08:31.153740: train_loss -0.9022 
2024-12-08 06:08:31.159422: val_loss -0.8472 
2024-12-08 06:08:31.161951: Pseudo dice [np.float32(0.8967), np.float32(0.8796)] 
2024-12-08 06:08:31.164994: Epoch time: 6.34 s 
2024-12-08 06:08:31.169025: Yayy! New best EMA pseudo Dice: 0.8876000046730042 
2024-12-08 06:08:31.747092:  
2024-12-08 06:08:31.753226: Epoch 95 
2024-12-08 06:08:31.756776: Current learning rate: 0.00067 
2024-12-08 06:08:38.099319: train_loss -0.9027 
2024-12-08 06:08:38.104897: val_loss -0.8447 
2024-12-08 06:08:38.107453: Pseudo dice [np.float32(0.8951), np.float32(0.8775)] 
2024-12-08 06:08:38.110492: Epoch time: 6.35 s 
2024-12-08 06:08:38.647147:  
2024-12-08 06:08:38.652270: Epoch 96 
2024-12-08 06:08:38.655829: Current learning rate: 0.00055 
2024-12-08 06:08:44.984054: train_loss -0.9024 
2024-12-08 06:08:44.989126: val_loss -0.848 
2024-12-08 06:08:44.991679: Pseudo dice [np.float32(0.8972), np.float32(0.8793)] 
2024-12-08 06:08:44.995730: Epoch time: 6.34 s 
2024-12-08 06:08:45.537466:  
2024-12-08 06:08:45.544040: Epoch 97 
2024-12-08 06:08:45.546576: Current learning rate: 0.00043 
2024-12-08 06:08:51.879461: train_loss -0.9049 
2024-12-08 06:08:51.885038: val_loss -0.8474 
2024-12-08 06:08:51.887668: Pseudo dice [np.float32(0.8962), np.float32(0.8792)] 
2024-12-08 06:08:51.891721: Epoch time: 6.34 s 
2024-12-08 06:08:52.444367:  
2024-12-08 06:08:52.449466: Epoch 98 
2024-12-08 06:08:52.453016: Current learning rate: 0.0003 
2024-12-08 06:08:58.803697: train_loss -0.9027 
2024-12-08 06:08:58.808839: val_loss -0.8481 
2024-12-08 06:08:58.811924: Pseudo dice [np.float32(0.8969), np.float32(0.8797)] 
2024-12-08 06:08:58.814963: Epoch time: 6.36 s 
2024-12-08 06:08:58.818006: Yayy! New best EMA pseudo Dice: 0.8876000046730042 
2024-12-08 06:08:59.415536:  
2024-12-08 06:08:59.421113: Epoch 99 
2024-12-08 06:08:59.423657: Current learning rate: 0.00016 
2024-12-08 06:09:05.770332: train_loss -0.9039 
2024-12-08 06:09:05.775508: val_loss -0.8459 
2024-12-08 06:09:05.779563: Pseudo dice [np.float32(0.8965), np.float32(0.8779)] 
2024-12-08 06:09:05.782638: Epoch time: 6.36 s 
2024-12-08 06:09:06.541188: Training done. 
2024-12-08 06:09:06.577346: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-08 06:09:06.583359: The split file contains 5 splits. 
2024-12-08 06:09:06.589538: Desired fold for training: 0 
2024-12-08 06:09:06.589538: This split has 208 training and 52 validation cases. 
2024-12-08 06:09:06.597753: predicting hippocampus_017 
2024-12-08 06:09:06.597753: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-08 06:09:06.703814: predicting hippocampus_019 
2024-12-08 06:09:06.711957: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-08 06:09:06.752686: predicting hippocampus_033 
2024-12-08 06:09:06.761101: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-08 06:09:06.786086: predicting hippocampus_035 
2024-12-08 06:09:06.786086: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-08 06:09:06.810753: predicting hippocampus_037 
2024-12-08 06:09:06.818913: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-08 06:09:06.843838: predicting hippocampus_049 
2024-12-08 06:09:06.851893: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-08 06:09:06.876572: predicting hippocampus_052 
2024-12-08 06:09:06.884633: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-08 06:09:06.909136: predicting hippocampus_065 
2024-12-08 06:09:06.917202: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-08 06:09:06.942167: predicting hippocampus_083 
2024-12-08 06:09:06.950456: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-08 06:09:06.975220: predicting hippocampus_088 
2024-12-08 06:09:06.983231: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-08 06:09:10.327728: predicting hippocampus_090 
2024-12-08 06:09:10.329474: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-08 06:09:10.370175: predicting hippocampus_092 
2024-12-08 06:09:10.378432: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-08 06:09:10.419095: predicting hippocampus_095 
2024-12-08 06:09:10.427120: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-08 06:09:10.471770: predicting hippocampus_107 
2024-12-08 06:09:10.477545: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-08 06:09:10.532234: predicting hippocampus_108 
2024-12-08 06:09:10.544441: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-08 06:09:10.606685: predicting hippocampus_123 
2024-12-08 06:09:10.630734: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-08 06:09:10.666816: predicting hippocampus_125 
2024-12-08 06:09:10.674829: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-08 06:09:10.746958: predicting hippocampus_157 
2024-12-08 06:09:10.750964: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-08 06:09:10.787035: predicting hippocampus_164 
2024-12-08 06:09:10.793047: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-08 06:09:10.877554: predicting hippocampus_169 
2024-12-08 06:09:10.887642: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-08 06:09:10.910171: predicting hippocampus_175 
2024-12-08 06:09:10.918199: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-08 06:09:10.946251: predicting hippocampus_185 
2024-12-08 06:09:10.951925: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-08 06:09:10.977983: predicting hippocampus_190 
2024-12-08 06:09:10.986174: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-08 06:09:11.006348: predicting hippocampus_194 
2024-12-08 06:09:11.018758: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-08 06:09:11.044806: predicting hippocampus_204 
2024-12-08 06:09:11.048813: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-08 06:09:11.078867: predicting hippocampus_205 
2024-12-08 06:09:11.082873: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-08 06:09:11.108657: predicting hippocampus_210 
2024-12-08 06:09:11.112664: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-08 06:09:11.138725: predicting hippocampus_217 
2024-12-08 06:09:11.144736: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-08 06:09:11.170781: predicting hippocampus_219 
2024-12-08 06:09:11.176791: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-08 06:09:11.202835: predicting hippocampus_229 
2024-12-08 06:09:11.206840: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-08 06:09:11.234901: predicting hippocampus_244 
2024-12-08 06:09:11.240912: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-08 06:09:11.266953: predicting hippocampus_261 
2024-12-08 06:09:11.272964: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-08 06:09:11.317071: predicting hippocampus_264 
2024-12-08 06:09:11.323084: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-08 06:09:11.349140: predicting hippocampus_277 
2024-12-08 06:09:11.355149: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-08 06:09:11.399231: predicting hippocampus_280 
2024-12-08 06:09:11.405242: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-08 06:09:11.429288: predicting hippocampus_286 
2024-12-08 06:09:11.433295: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-08 06:09:11.475389: predicting hippocampus_288 
2024-12-08 06:09:11.483497: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-08 06:09:11.527568: predicting hippocampus_289 
2024-12-08 06:09:11.533553: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-08 06:09:11.559594: predicting hippocampus_296 
2024-12-08 06:09:11.565606: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-08 06:09:11.593669: predicting hippocampus_305 
2024-12-08 06:09:11.597677: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-08 06:09:11.623726: predicting hippocampus_308 
2024-12-08 06:09:11.627732: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-08 06:09:11.655795: predicting hippocampus_317 
2024-12-08 06:09:11.659803: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-08 06:09:11.687859: predicting hippocampus_327 
2024-12-08 06:09:11.691865: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-08 06:09:11.719920: predicting hippocampus_330 
2024-12-08 06:09:11.723927: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-08 06:09:11.751710: predicting hippocampus_332 
2024-12-08 06:09:11.757723: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-08 06:09:11.785773: predicting hippocampus_338 
2024-12-08 06:09:11.789778: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-08 06:09:11.833881: predicting hippocampus_349 
2024-12-08 06:09:11.837888: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-08 06:09:11.863945: predicting hippocampus_350 
2024-12-08 06:09:11.869957: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-08 06:09:11.898015: predicting hippocampus_356 
2024-12-08 06:09:11.902021: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-08 06:09:11.928067: predicting hippocampus_358 
2024-12-08 06:09:11.934079: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-08 06:09:11.958132: predicting hippocampus_374 
2024-12-08 06:09:11.964143: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-08 06:09:11.992197: predicting hippocampus_394 
2024-12-08 06:09:11.996204: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-08 06:09:15.433877: Validation complete 
2024-12-08 06:09:15.437224: Mean Validation Dice:  0.8913239938098475 
