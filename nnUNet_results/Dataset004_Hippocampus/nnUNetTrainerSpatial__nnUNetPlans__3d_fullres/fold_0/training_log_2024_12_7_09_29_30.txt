
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-07 09:29:30.051295: do_dummy_2d_data_aug: False 
2024-12-07 09:29:30.056294: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-07 09:29:30.061729: The split file contains 5 splits. 
2024-12-07 09:29:30.064728: Desired fold for training: 0 
2024-12-07 09:29:30.066729: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-07 09:29:36.229159: unpacking dataset... 
2024-12-07 09:29:36.544263: unpacking done... 
2024-12-07 09:29:38.353479:  
2024-12-07 09:29:38.357487: Epoch 0 
2024-12-07 09:29:38.359992: Current learning rate: 0.01 
2024-12-07 09:29:45.611136: train_loss -0.451 
2024-12-07 09:29:45.615709: val_loss -0.7706 
2024-12-07 09:29:45.619750: Pseudo dice [np.float32(0.8387), np.float32(0.8174)] 
2024-12-07 09:29:45.622805: Epoch time: 7.26 s 
2024-12-07 09:29:45.625327: Yayy! New best EMA pseudo Dice: 0.828000009059906 
2024-12-07 09:29:46.138383:  
2024-12-07 09:29:46.142395: Epoch 1 
2024-12-07 09:29:46.144900: Current learning rate: 0.00991 
2024-12-07 09:29:52.526215: train_loss -0.7832 
2024-12-07 09:29:52.531231: val_loss -0.8124 
2024-12-07 09:29:52.534758: Pseudo dice [np.float32(0.8674), np.float32(0.8544)] 
2024-12-07 09:29:52.537850: Epoch time: 6.39 s 
2024-12-07 09:29:52.540411: Yayy! New best EMA pseudo Dice: 0.8313000202178955 
2024-12-07 09:29:53.133326:  
2024-12-07 09:29:53.136334: Epoch 2 
2024-12-07 09:29:53.139843: Current learning rate: 0.00982 
2024-12-07 09:29:59.505355: train_loss -0.8095 
2024-12-07 09:29:59.509365: val_loss -0.8245 
2024-12-07 09:29:59.513416: Pseudo dice [np.float32(0.8758), np.float32(0.8617)] 
2024-12-07 09:29:59.516486: Epoch time: 6.37 s 
2024-12-07 09:29:59.519544: Yayy! New best EMA pseudo Dice: 0.835099995136261 
2024-12-07 09:30:00.148718:  
2024-12-07 09:30:00.152765: Epoch 3 
2024-12-07 09:30:00.155308: Current learning rate: 0.00973 
2024-12-07 09:30:06.521084: train_loss -0.8221 
2024-12-07 09:30:06.526154: val_loss -0.8331 
2024-12-07 09:30:06.528693: Pseudo dice [np.float32(0.8845), np.float32(0.8653)] 
2024-12-07 09:30:06.532209: Epoch time: 6.37 s 
2024-12-07 09:30:06.535229: Yayy! New best EMA pseudo Dice: 0.8389999866485596 
2024-12-07 09:30:07.130651:  
2024-12-07 09:30:07.136215: Epoch 4 
2024-12-07 09:30:07.139280: Current learning rate: 0.00964 
2024-12-07 09:30:13.483024: train_loss -0.8264 
2024-12-07 09:30:13.488548: val_loss -0.8257 
2024-12-07 09:30:13.491083: Pseudo dice [np.float32(0.8754), np.float32(0.8645)] 
2024-12-07 09:30:13.494642: Epoch time: 6.35 s 
2024-12-07 09:30:13.497682: Yayy! New best EMA pseudo Dice: 0.8421000242233276 
2024-12-07 09:30:14.113720:  
2024-12-07 09:30:14.119286: Epoch 5 
2024-12-07 09:30:14.121839: Current learning rate: 0.00955 
2024-12-07 09:30:20.481414: train_loss -0.8345 
2024-12-07 09:30:20.486476: val_loss -0.8289 
2024-12-07 09:30:20.489539: Pseudo dice [np.float32(0.8823), np.float32(0.8612)] 
2024-12-07 09:30:20.492072: Epoch time: 6.37 s 
2024-12-07 09:30:20.494603: Yayy! New best EMA pseudo Dice: 0.8450999855995178 
2024-12-07 09:30:21.196628:  
2024-12-07 09:30:21.201911: Epoch 6 
2024-12-07 09:30:21.204418: Current learning rate: 0.00946 
2024-12-07 09:30:27.560861: train_loss -0.8401 
2024-12-07 09:30:27.566487: val_loss -0.8401 
2024-12-07 09:30:27.569518: Pseudo dice [np.float32(0.8904), np.float32(0.8737)] 
2024-12-07 09:30:27.572538: Epoch time: 6.36 s 
2024-12-07 09:30:27.574589: Yayy! New best EMA pseudo Dice: 0.848800003528595 
2024-12-07 09:30:28.174652:  
2024-12-07 09:30:28.180228: Epoch 7 
2024-12-07 09:30:28.183265: Current learning rate: 0.00937 
2024-12-07 09:30:34.545635: train_loss -0.8429 
2024-12-07 09:30:34.551216: val_loss -0.8364 
2024-12-07 09:30:34.553743: Pseudo dice [np.float32(0.8869), np.float32(0.8695)] 
2024-12-07 09:30:34.557288: Epoch time: 6.37 s 
2024-12-07 09:30:34.560321: Yayy! New best EMA pseudo Dice: 0.8517000079154968 
2024-12-07 09:30:35.172270:  
2024-12-07 09:30:35.177783: Epoch 8 
2024-12-07 09:30:35.181294: Current learning rate: 0.00928 
2024-12-07 09:30:41.549128: train_loss -0.8457 
2024-12-07 09:30:41.555697: val_loss -0.8368 
2024-12-07 09:30:41.559206: Pseudo dice [np.float32(0.8866), np.float32(0.8686)] 
2024-12-07 09:30:41.562217: Epoch time: 6.38 s 
2024-12-07 09:30:41.565255: Yayy! New best EMA pseudo Dice: 0.8543000221252441 
2024-12-07 09:30:42.182947:  
2024-12-07 09:30:42.188691: Epoch 9 
2024-12-07 09:30:42.191071: Current learning rate: 0.00919 
2024-12-07 09:30:48.548621: train_loss -0.8474 
2024-12-07 09:30:48.553746: val_loss -0.845 
2024-12-07 09:30:48.556801: Pseudo dice [np.float32(0.894), np.float32(0.8753)] 
2024-12-07 09:30:48.559865: Epoch time: 6.37 s 
2024-12-07 09:30:48.562389: Yayy! New best EMA pseudo Dice: 0.8572999835014343 
2024-12-07 09:30:49.145028:  
2024-12-07 09:30:49.149039: Epoch 10 
2024-12-07 09:30:49.152546: Current learning rate: 0.0091 
2024-12-07 09:30:55.499015: train_loss -0.8487 
2024-12-07 09:30:55.505566: val_loss -0.8409 
2024-12-07 09:30:55.508591: Pseudo dice [np.float32(0.8887), np.float32(0.8726)] 
2024-12-07 09:30:55.511621: Epoch time: 6.35 s 
2024-12-07 09:30:55.514654: Yayy! New best EMA pseudo Dice: 0.8597000241279602 
2024-12-07 09:30:56.113096:  
2024-12-07 09:30:56.117629: Epoch 11 
2024-12-07 09:30:56.120708: Current learning rate: 0.009 
2024-12-07 09:31:02.468998: train_loss -0.8519 
2024-12-07 09:31:02.474599: val_loss -0.8462 
2024-12-07 09:31:02.477647: Pseudo dice [np.float32(0.8946), np.float32(0.8748)] 
2024-12-07 09:31:02.480711: Epoch time: 6.36 s 
2024-12-07 09:31:02.483242: Yayy! New best EMA pseudo Dice: 0.8622000217437744 
2024-12-07 09:31:03.060071:  
2024-12-07 09:31:03.065126: Epoch 12 
2024-12-07 09:31:03.068639: Current learning rate: 0.00891 
2024-12-07 09:31:09.399737: train_loss -0.8527 
2024-12-07 09:31:09.405334: val_loss -0.8431 
2024-12-07 09:31:09.408402: Pseudo dice [np.float32(0.8917), np.float32(0.8746)] 
2024-12-07 09:31:09.411937: Epoch time: 6.34 s 
2024-12-07 09:31:09.414679: Yayy! New best EMA pseudo Dice: 0.864300012588501 
2024-12-07 09:31:10.156630:  
2024-12-07 09:31:10.162196: Epoch 13 
2024-12-07 09:31:10.165236: Current learning rate: 0.00882 
2024-12-07 09:31:16.483992: train_loss -0.8547 
2024-12-07 09:31:16.489551: val_loss -0.848 
2024-12-07 09:31:16.492089: Pseudo dice [np.float32(0.8968), np.float32(0.8749)] 
2024-12-07 09:31:16.495135: Epoch time: 6.33 s 
2024-12-07 09:31:16.498156: Yayy! New best EMA pseudo Dice: 0.8664000034332275 
2024-12-07 09:31:17.093326:  
2024-12-07 09:31:17.098342: Epoch 14 
2024-12-07 09:31:17.100849: Current learning rate: 0.00873 
2024-12-07 09:31:23.428877: train_loss -0.8564 
2024-12-07 09:31:23.434467: val_loss -0.8491 
2024-12-07 09:31:23.437526: Pseudo dice [np.float32(0.8973), np.float32(0.8777)] 
2024-12-07 09:31:23.440074: Epoch time: 6.34 s 
2024-12-07 09:31:23.443644: Yayy! New best EMA pseudo Dice: 0.8684999942779541 
2024-12-07 09:31:24.052417:  
2024-12-07 09:31:24.057487: Epoch 15 
2024-12-07 09:31:24.060554: Current learning rate: 0.00864 
2024-12-07 09:31:30.384293: train_loss -0.8587 
2024-12-07 09:31:30.389866: val_loss -0.8448 
2024-12-07 09:31:30.393885: Pseudo dice [np.float32(0.8942), np.float32(0.8727)] 
2024-12-07 09:31:30.396939: Epoch time: 6.33 s 
2024-12-07 09:31:30.399472: Yayy! New best EMA pseudo Dice: 0.8700000047683716 
2024-12-07 09:31:31.013940:  
2024-12-07 09:31:31.018007: Epoch 16 
2024-12-07 09:31:31.020589: Current learning rate: 0.00855 
2024-12-07 09:31:37.384949: train_loss -0.8569 
2024-12-07 09:31:37.390604: val_loss -0.851 
2024-12-07 09:31:37.393478: Pseudo dice [np.float32(0.8975), np.float32(0.8796)] 
2024-12-07 09:31:37.396007: Epoch time: 6.37 s 
2024-12-07 09:31:37.399533: Yayy! New best EMA pseudo Dice: 0.8719000220298767 
2024-12-07 09:31:38.018532:  
2024-12-07 09:31:38.023544: Epoch 17 
2024-12-07 09:31:38.027059: Current learning rate: 0.00846 
2024-12-07 09:31:44.381146: train_loss -0.8596 
2024-12-07 09:31:44.386725: val_loss -0.8476 
2024-12-07 09:31:44.389791: Pseudo dice [np.float32(0.893), np.float32(0.8793)] 
2024-12-07 09:31:44.392835: Epoch time: 6.36 s 
2024-12-07 09:31:44.395386: Yayy! New best EMA pseudo Dice: 0.8733000159263611 
2024-12-07 09:31:45.006875:  
2024-12-07 09:31:45.010388: Epoch 18 
2024-12-07 09:31:45.013445: Current learning rate: 0.00836 
2024-12-07 09:31:51.357283: train_loss -0.8624 
2024-12-07 09:31:51.363365: val_loss -0.8505 
2024-12-07 09:31:51.366380: Pseudo dice [np.float32(0.8969), np.float32(0.8799)] 
2024-12-07 09:31:51.369416: Epoch time: 6.35 s 
2024-12-07 09:31:51.372470: Yayy! New best EMA pseudo Dice: 0.8748000264167786 
2024-12-07 09:31:51.967762:  
2024-12-07 09:31:51.971801: Epoch 19 
2024-12-07 09:31:51.974489: Current learning rate: 0.00827 
2024-12-07 09:31:58.314168: train_loss -0.8634 
2024-12-07 09:31:58.319766: val_loss -0.8487 
2024-12-07 09:31:58.322277: Pseudo dice [np.float32(0.8946), np.float32(0.8774)] 
2024-12-07 09:31:58.325795: Epoch time: 6.35 s 
2024-12-07 09:31:58.328306: Yayy! New best EMA pseudo Dice: 0.8758999705314636 
2024-12-07 09:31:58.922917:  
2024-12-07 09:31:58.927000: Epoch 20 
2024-12-07 09:31:58.929557: Current learning rate: 0.00818 
2024-12-07 09:32:05.278275: train_loss -0.8633 
2024-12-07 09:32:05.283811: val_loss -0.85 
2024-12-07 09:32:05.285910: Pseudo dice [np.float32(0.8968), np.float32(0.8792)] 
2024-12-07 09:32:05.288955: Epoch time: 6.36 s 
2024-12-07 09:32:05.292465: Yayy! New best EMA pseudo Dice: 0.8770999908447266 
2024-12-07 09:32:06.072178:  
2024-12-07 09:32:06.077761: Epoch 21 
2024-12-07 09:32:06.080851: Current learning rate: 0.00809 
2024-12-07 09:32:12.431956: train_loss -0.8647 
2024-12-07 09:32:12.436733: val_loss -0.8527 
2024-12-07 09:32:12.440253: Pseudo dice [np.float32(0.8981), np.float32(0.8812)] 
2024-12-07 09:32:12.442273: Epoch time: 6.36 s 
2024-12-07 09:32:12.446364: Yayy! New best EMA pseudo Dice: 0.8784000277519226 
2024-12-07 09:32:13.024485:  
2024-12-07 09:32:13.028536: Epoch 22 
2024-12-07 09:32:13.031081: Current learning rate: 0.008 
2024-12-07 09:32:19.379462: train_loss -0.8659 
2024-12-07 09:32:19.385064: val_loss -0.8462 
2024-12-07 09:32:19.388127: Pseudo dice [np.float32(0.8933), np.float32(0.8747)] 
2024-12-07 09:32:19.391186: Epoch time: 6.36 s 
2024-12-07 09:32:19.393729: Yayy! New best EMA pseudo Dice: 0.8788999915122986 
2024-12-07 09:32:19.969693:  
2024-12-07 09:32:19.973710: Epoch 23 
2024-12-07 09:32:19.977220: Current learning rate: 0.0079 
2024-12-07 09:32:26.311281: train_loss -0.867 
2024-12-07 09:32:26.317315: val_loss -0.8488 
2024-12-07 09:32:26.320371: Pseudo dice [np.float32(0.8968), np.float32(0.8782)] 
2024-12-07 09:32:26.322921: Epoch time: 6.34 s 
2024-12-07 09:32:26.326435: Yayy! New best EMA pseudo Dice: 0.879800021648407 
2024-12-07 09:32:26.900445:  
2024-12-07 09:32:26.906486: Epoch 24 
2024-12-07 09:32:26.909294: Current learning rate: 0.00781 
2024-12-07 09:32:33.242925: train_loss -0.8698 
2024-12-07 09:32:33.248008: val_loss -0.85 
2024-12-07 09:32:33.251055: Pseudo dice [np.float32(0.8952), np.float32(0.8802)] 
2024-12-07 09:32:33.254093: Epoch time: 6.34 s 
2024-12-07 09:32:33.257608: Yayy! New best EMA pseudo Dice: 0.8805999755859375 
2024-12-07 09:32:33.848645:  
2024-12-07 09:32:33.853177: Epoch 25 
2024-12-07 09:32:33.856250: Current learning rate: 0.00772 
2024-12-07 09:32:40.198536: train_loss -0.8685 
2024-12-07 09:32:40.205574: val_loss -0.8489 
2024-12-07 09:32:40.208129: Pseudo dice [np.float32(0.8955), np.float32(0.8792)] 
2024-12-07 09:32:40.211152: Epoch time: 6.35 s 
2024-12-07 09:32:40.214189: Yayy! New best EMA pseudo Dice: 0.8812999725341797 
2024-12-07 09:32:40.795882:  
2024-12-07 09:32:40.800394: Epoch 26 
2024-12-07 09:32:40.803407: Current learning rate: 0.00763 
2024-12-07 09:32:47.146840: train_loss -0.8694 
2024-12-07 09:32:47.152977: val_loss -0.8512 
2024-12-07 09:32:47.155524: Pseudo dice [np.float32(0.896), np.float32(0.8802)] 
2024-12-07 09:32:47.158575: Epoch time: 6.35 s 
2024-12-07 09:32:47.162111: Yayy! New best EMA pseudo Dice: 0.8819000124931335 
2024-12-07 09:32:47.738708:  
2024-12-07 09:32:47.742739: Epoch 27 
2024-12-07 09:32:47.745268: Current learning rate: 0.00753 
2024-12-07 09:32:54.095632: train_loss -0.8715 
2024-12-07 09:32:54.100724: val_loss -0.8447 
2024-12-07 09:32:54.104311: Pseudo dice [np.float32(0.8921), np.float32(0.8749)] 
2024-12-07 09:32:54.107393: Epoch time: 6.36 s 
2024-12-07 09:32:54.109954: Yayy! New best EMA pseudo Dice: 0.882099986076355 
2024-12-07 09:32:54.684520:  
2024-12-07 09:32:54.688532: Epoch 28 
2024-12-07 09:32:54.691040: Current learning rate: 0.00744 
2024-12-07 09:33:01.023554: train_loss -0.8707 
2024-12-07 09:33:01.029126: val_loss -0.8507 
2024-12-07 09:33:01.032163: Pseudo dice [np.float32(0.8977), np.float32(0.88)] 
2024-12-07 09:33:01.034183: Epoch time: 6.34 s 
2024-12-07 09:33:01.038244: Yayy! New best EMA pseudo Dice: 0.8827999830245972 
2024-12-07 09:33:01.772187:  
2024-12-07 09:33:01.775198: Epoch 29 
2024-12-07 09:33:01.778756: Current learning rate: 0.00735 
2024-12-07 09:33:08.117631: train_loss -0.8729 
2024-12-07 09:33:08.122675: val_loss -0.8581 
2024-12-07 09:33:08.126708: Pseudo dice [np.float32(0.9033), np.float32(0.8853)] 
2024-12-07 09:33:08.129736: Epoch time: 6.35 s 
2024-12-07 09:33:08.132272: Yayy! New best EMA pseudo Dice: 0.883899986743927 
2024-12-07 09:33:08.737750:  
2024-12-07 09:33:08.741780: Epoch 30 
2024-12-07 09:33:08.744307: Current learning rate: 0.00725 
2024-12-07 09:33:15.081794: train_loss -0.8725 
2024-12-07 09:33:15.086329: val_loss -0.8487 
2024-12-07 09:33:15.090352: Pseudo dice [np.float32(0.8956), np.float32(0.8781)] 
2024-12-07 09:33:15.093390: Epoch time: 6.35 s 
2024-12-07 09:33:15.096012: Yayy! New best EMA pseudo Dice: 0.8841999769210815 
2024-12-07 09:33:15.691123:  
2024-12-07 09:33:15.696698: Epoch 31 
2024-12-07 09:33:15.699294: Current learning rate: 0.00716 
2024-12-07 09:33:22.036227: train_loss -0.8743 
2024-12-07 09:33:22.041633: val_loss -0.8494 
2024-12-07 09:33:22.044153: Pseudo dice [np.float32(0.8955), np.float32(0.8803)] 
2024-12-07 09:33:22.047679: Epoch time: 6.35 s 
2024-12-07 09:33:22.051213: Yayy! New best EMA pseudo Dice: 0.8845999836921692 
2024-12-07 09:33:22.650124:  
2024-12-07 09:33:22.655643: Epoch 32 
2024-12-07 09:33:22.658150: Current learning rate: 0.00707 
2024-12-07 09:33:28.991660: train_loss -0.875 
2024-12-07 09:33:28.997272: val_loss -0.8547 
2024-12-07 09:33:29.000818: Pseudo dice [np.float32(0.9), np.float32(0.8837)] 
2024-12-07 09:33:29.003859: Epoch time: 6.34 s 
2024-12-07 09:33:29.006407: Yayy! New best EMA pseudo Dice: 0.8852999806404114 
2024-12-07 09:33:29.604169:  
2024-12-07 09:33:29.609730: Epoch 33 
2024-12-07 09:33:29.612237: Current learning rate: 0.00697 
2024-12-07 09:33:35.950916: train_loss -0.8741 
2024-12-07 09:33:35.955969: val_loss -0.8517 
2024-12-07 09:33:35.959008: Pseudo dice [np.float32(0.8973), np.float32(0.8807)] 
2024-12-07 09:33:35.962020: Epoch time: 6.35 s 
2024-12-07 09:33:35.963560: Yayy! New best EMA pseudo Dice: 0.885699987411499 
2024-12-07 09:33:36.579295:  
2024-12-07 09:33:36.584309: Epoch 34 
2024-12-07 09:33:36.587318: Current learning rate: 0.00688 
2024-12-07 09:33:42.923517: train_loss -0.8761 
2024-12-07 09:33:42.930687: val_loss -0.8535 
2024-12-07 09:33:42.934251: Pseudo dice [np.float32(0.8993), np.float32(0.8813)] 
2024-12-07 09:33:42.936763: Epoch time: 6.35 s 
2024-12-07 09:33:42.939771: Yayy! New best EMA pseudo Dice: 0.8860999941825867 
2024-12-07 09:33:43.534498:  
2024-12-07 09:33:43.538550: Epoch 35 
2024-12-07 09:33:43.541100: Current learning rate: 0.00679 
2024-12-07 09:33:49.894076: train_loss -0.8772 
2024-12-07 09:33:49.899639: val_loss -0.8571 
2024-12-07 09:33:49.902688: Pseudo dice [np.float32(0.9024), np.float32(0.884)] 
2024-12-07 09:33:49.905720: Epoch time: 6.36 s 
2024-12-07 09:33:49.908759: Yayy! New best EMA pseudo Dice: 0.886900007724762 
2024-12-07 09:33:50.510151:  
2024-12-07 09:33:50.514187: Epoch 36 
2024-12-07 09:33:50.516719: Current learning rate: 0.00669 
2024-12-07 09:33:56.863860: train_loss -0.8776 
2024-12-07 09:33:56.869879: val_loss -0.853 
2024-12-07 09:33:56.872656: Pseudo dice [np.float32(0.8992), np.float32(0.8823)] 
2024-12-07 09:33:56.875193: Epoch time: 6.35 s 
2024-12-07 09:33:56.878701: Yayy! New best EMA pseudo Dice: 0.8871999979019165 
2024-12-07 09:33:57.634723:  
2024-12-07 09:33:57.639738: Epoch 37 
2024-12-07 09:33:57.642244: Current learning rate: 0.0066 
2024-12-07 09:34:03.980992: train_loss -0.8777 
2024-12-07 09:34:03.986529: val_loss -0.8517 
2024-12-07 09:34:03.990043: Pseudo dice [np.float32(0.8994), np.float32(0.88)] 
2024-12-07 09:34:03.993064: Epoch time: 6.35 s 
2024-12-07 09:34:03.995621: Yayy! New best EMA pseudo Dice: 0.887499988079071 
2024-12-07 09:34:04.599929:  
2024-12-07 09:34:04.605515: Epoch 38 
2024-12-07 09:34:04.608071: Current learning rate: 0.0065 
2024-12-07 09:34:10.935631: train_loss -0.8787 
2024-12-07 09:34:10.940224: val_loss -0.8495 
2024-12-07 09:34:10.944266: Pseudo dice [np.float32(0.8982), np.float32(0.8784)] 
2024-12-07 09:34:10.946801: Epoch time: 6.34 s 
2024-12-07 09:34:10.949334: Yayy! New best EMA pseudo Dice: 0.8876000046730042 
2024-12-07 09:34:11.544112:  
2024-12-07 09:34:11.548774: Epoch 39 
2024-12-07 09:34:11.552311: Current learning rate: 0.00641 
2024-12-07 09:34:17.880019: train_loss -0.8815 
2024-12-07 09:34:17.884577: val_loss -0.8555 
2024-12-07 09:34:17.888109: Pseudo dice [np.float32(0.9007), np.float32(0.884)] 
2024-12-07 09:34:17.891139: Epoch time: 6.34 s 
2024-12-07 09:34:17.894176: Yayy! New best EMA pseudo Dice: 0.8881000280380249 
2024-12-07 09:34:18.518208:  
2024-12-07 09:34:18.522740: Epoch 40 
2024-12-07 09:34:18.525835: Current learning rate: 0.00631 
2024-12-07 09:34:24.862287: train_loss -0.8811 
2024-12-07 09:34:24.867888: val_loss -0.8556 
2024-12-07 09:34:24.870972: Pseudo dice [np.float32(0.901), np.float32(0.8835)] 
2024-12-07 09:34:24.874047: Epoch time: 6.34 s 
2024-12-07 09:34:24.876069: Yayy! New best EMA pseudo Dice: 0.8884999752044678 
2024-12-07 09:34:25.492348:  
2024-12-07 09:34:25.496903: Epoch 41 
2024-12-07 09:34:25.499928: Current learning rate: 0.00622 
2024-12-07 09:34:31.853575: train_loss -0.8809 
2024-12-07 09:34:31.859153: val_loss -0.8551 
2024-12-07 09:34:31.862195: Pseudo dice [np.float32(0.8998), np.float32(0.8843)] 
2024-12-07 09:34:31.864216: Epoch time: 6.36 s 
2024-12-07 09:34:31.866764: Yayy! New best EMA pseudo Dice: 0.8888000249862671 
2024-12-07 09:34:32.448614:  
2024-12-07 09:34:32.453666: Epoch 42 
2024-12-07 09:34:32.456738: Current learning rate: 0.00612 
2024-12-07 09:34:38.808429: train_loss -0.8825 
2024-12-07 09:34:38.813503: val_loss -0.8493 
2024-12-07 09:34:38.816578: Pseudo dice [np.float32(0.8966), np.float32(0.8791)] 
2024-12-07 09:34:38.819144: Epoch time: 6.36 s 
2024-12-07 09:34:39.359045:  
2024-12-07 09:34:39.363094: Epoch 43 
2024-12-07 09:34:39.365655: Current learning rate: 0.00603 
2024-12-07 09:34:45.722626: train_loss -0.8819 
2024-12-07 09:34:45.730316: val_loss -0.8537 
2024-12-07 09:34:45.732823: Pseudo dice [np.float32(0.9), np.float32(0.8818)] 
2024-12-07 09:34:45.735841: Epoch time: 6.36 s 
2024-12-07 09:34:45.738880: Yayy! New best EMA pseudo Dice: 0.8888999819755554 
2024-12-07 09:34:46.516341:  
2024-12-07 09:34:46.519852: Epoch 44 
2024-12-07 09:34:46.522613: Current learning rate: 0.00593 
2024-12-07 09:34:52.860844: train_loss -0.8817 
2024-12-07 09:34:52.865950: val_loss -0.8497 
2024-12-07 09:34:52.869022: Pseudo dice [np.float32(0.8958), np.float32(0.8787)] 
2024-12-07 09:34:52.871093: Epoch time: 6.35 s 
2024-12-07 09:34:53.418720:  
2024-12-07 09:34:53.422219: Epoch 45 
2024-12-07 09:34:53.425727: Current learning rate: 0.00584 
2024-12-07 09:34:59.777259: train_loss -0.8834 
2024-12-07 09:34:59.782811: val_loss -0.8498 
2024-12-07 09:34:59.785845: Pseudo dice [np.float32(0.8961), np.float32(0.88)] 
2024-12-07 09:34:59.788392: Epoch time: 6.36 s 
2024-12-07 09:35:00.335090:  
2024-12-07 09:35:00.340654: Epoch 46 
2024-12-07 09:35:00.343666: Current learning rate: 0.00574 
2024-12-07 09:35:06.688400: train_loss -0.8847 
2024-12-07 09:35:06.693990: val_loss -0.8518 
2024-12-07 09:35:06.697030: Pseudo dice [np.float32(0.8985), np.float32(0.882)] 
2024-12-07 09:35:06.699540: Epoch time: 6.35 s 
2024-12-07 09:35:07.245151:  
2024-12-07 09:35:07.250151: Epoch 47 
2024-12-07 09:35:07.252742: Current learning rate: 0.00565 
2024-12-07 09:35:13.598085: train_loss -0.8842 
2024-12-07 09:35:13.602659: val_loss -0.8551 
2024-12-07 09:35:13.606195: Pseudo dice [np.float32(0.9013), np.float32(0.8837)] 
2024-12-07 09:35:13.609318: Epoch time: 6.35 s 
2024-12-07 09:35:13.611878: Yayy! New best EMA pseudo Dice: 0.88919997215271 
2024-12-07 09:35:14.189202:  
2024-12-07 09:35:14.192251: Epoch 48 
2024-12-07 09:35:14.195299: Current learning rate: 0.00555 
2024-12-07 09:35:20.521333: train_loss -0.8866 
2024-12-07 09:35:20.526421: val_loss -0.8479 
2024-12-07 09:35:20.528968: Pseudo dice [np.float32(0.8946), np.float32(0.8784)] 
2024-12-07 09:35:20.532559: Epoch time: 6.33 s 
2024-12-07 09:35:21.081159:  
2024-12-07 09:35:21.086259: Epoch 49 
2024-12-07 09:35:21.089343: Current learning rate: 0.00546 
2024-12-07 09:35:27.403827: train_loss -0.8857 
2024-12-07 09:35:27.408911: val_loss -0.8482 
2024-12-07 09:35:27.411980: Pseudo dice [np.float32(0.8967), np.float32(0.8781)] 
2024-12-07 09:35:27.415020: Epoch time: 6.32 s 
2024-12-07 09:35:27.989894:  
2024-12-07 09:35:27.993407: Epoch 50 
2024-12-07 09:35:27.995913: Current learning rate: 0.00536 
2024-12-07 09:35:34.339735: train_loss -0.8856 
2024-12-07 09:35:34.344799: val_loss -0.8511 
2024-12-07 09:35:34.347844: Pseudo dice [np.float32(0.8968), np.float32(0.8832)] 
2024-12-07 09:35:34.349879: Epoch time: 6.35 s 
2024-12-07 09:35:34.920920:  
2024-12-07 09:35:34.924458: Epoch 51 
2024-12-07 09:35:34.926985: Current learning rate: 0.00526 
2024-12-07 09:35:41.270697: train_loss -0.8867 
2024-12-07 09:35:41.275711: val_loss -0.8515 
2024-12-07 09:35:41.279268: Pseudo dice [np.float32(0.8995), np.float32(0.8803)] 
2024-12-07 09:35:41.281780: Epoch time: 6.35 s 
2024-12-07 09:35:41.974685:  
2024-12-07 09:35:41.978219: Epoch 52 
2024-12-07 09:35:41.981294: Current learning rate: 0.00517 
2024-12-07 09:35:48.314801: train_loss -0.8883 
2024-12-07 09:35:48.321428: val_loss -0.8506 
2024-12-07 09:35:48.324512: Pseudo dice [np.float32(0.8969), np.float32(0.8801)] 
2024-12-07 09:35:48.329077: Epoch time: 6.34 s 
2024-12-07 09:35:48.876742:  
2024-12-07 09:35:48.880210: Epoch 53 
2024-12-07 09:35:48.882718: Current learning rate: 0.00507 
2024-12-07 09:35:55.202049: train_loss -0.8892 
2024-12-07 09:35:55.207263: val_loss -0.8492 
2024-12-07 09:35:55.211299: Pseudo dice [np.float32(0.897), np.float32(0.8795)] 
2024-12-07 09:35:55.214311: Epoch time: 6.33 s 
2024-12-07 09:35:55.759782:  
2024-12-07 09:35:55.763301: Epoch 54 
2024-12-07 09:35:55.766812: Current learning rate: 0.00497 
2024-12-07 09:36:02.110545: train_loss -0.8874 
2024-12-07 09:36:02.116151: val_loss -0.8481 
2024-12-07 09:36:02.118683: Pseudo dice [np.float32(0.8972), np.float32(0.8785)] 
2024-12-07 09:36:02.120716: Epoch time: 6.35 s 
2024-12-07 09:36:02.664416:  
2024-12-07 09:36:02.668999: Epoch 55 
2024-12-07 09:36:02.671045: Current learning rate: 0.00487 
2024-12-07 09:36:08.993608: train_loss -0.8891 
2024-12-07 09:36:08.998680: val_loss -0.8514 
2024-12-07 09:36:09.001644: Pseudo dice [np.float32(0.8979), np.float32(0.8811)] 
2024-12-07 09:36:09.004156: Epoch time: 6.33 s 
2024-12-07 09:36:09.551272:  
2024-12-07 09:36:09.555824: Epoch 56 
2024-12-07 09:36:09.558893: Current learning rate: 0.00478 
2024-12-07 09:36:15.891619: train_loss -0.8909 
2024-12-07 09:36:15.897239: val_loss -0.8487 
2024-12-07 09:36:15.900261: Pseudo dice [np.float32(0.8957), np.float32(0.8806)] 
2024-12-07 09:36:15.903300: Epoch time: 6.34 s 
2024-12-07 09:36:16.450717:  
2024-12-07 09:36:16.454239: Epoch 57 
2024-12-07 09:36:16.457273: Current learning rate: 0.00468 
2024-12-07 09:36:22.800015: train_loss -0.8899 
2024-12-07 09:36:22.805798: val_loss -0.8519 
2024-12-07 09:36:22.808860: Pseudo dice [np.float32(0.899), np.float32(0.8821)] 
2024-12-07 09:36:22.811917: Epoch time: 6.35 s 
2024-12-07 09:36:23.362311:  
2024-12-07 09:36:23.366331: Epoch 58 
2024-12-07 09:36:23.369530: Current learning rate: 0.00458 
2024-12-07 09:36:29.704834: train_loss -0.8925 
2024-12-07 09:36:29.709941: val_loss -0.8518 
2024-12-07 09:36:29.711971: Pseudo dice [np.float32(0.9001), np.float32(0.8809)] 
2024-12-07 09:36:29.716047: Epoch time: 6.34 s 
2024-12-07 09:36:30.279056:  
2024-12-07 09:36:30.283074: Epoch 59 
2024-12-07 09:36:30.287088: Current learning rate: 0.00448 
2024-12-07 09:36:36.635736: train_loss -0.8928 
2024-12-07 09:36:36.641330: val_loss -0.8522 
2024-12-07 09:36:36.643884: Pseudo dice [np.float32(0.9), np.float32(0.8821)] 
2024-12-07 09:36:36.646936: Epoch time: 6.36 s 
2024-12-07 09:36:36.649454: Yayy! New best EMA pseudo Dice: 0.8892999887466431 
2024-12-07 09:36:37.388855:  
2024-12-07 09:36:37.391866: Epoch 60 
2024-12-07 09:36:37.395383: Current learning rate: 0.00438 
2024-12-07 09:36:43.730964: train_loss -0.8916 
2024-12-07 09:36:43.737602: val_loss -0.8543 
2024-12-07 09:36:43.740871: Pseudo dice [np.float32(0.9012), np.float32(0.8835)] 
2024-12-07 09:36:43.742893: Epoch time: 6.34 s 
2024-12-07 09:36:43.746600: Yayy! New best EMA pseudo Dice: 0.8895999789237976 
2024-12-07 09:36:44.331411:  
2024-12-07 09:36:44.335452: Epoch 61 
2024-12-07 09:36:44.337964: Current learning rate: 0.00429 
2024-12-07 09:36:50.692208: train_loss -0.8923 
2024-12-07 09:36:50.696285: val_loss -0.8517 
2024-12-07 09:36:50.699396: Pseudo dice [np.float32(0.8986), np.float32(0.8827)] 
2024-12-07 09:36:50.702491: Epoch time: 6.36 s 
2024-12-07 09:36:50.705020: Yayy! New best EMA pseudo Dice: 0.8896999955177307 
2024-12-07 09:36:51.291490:  
2024-12-07 09:36:51.295557: Epoch 62 
2024-12-07 09:36:51.298120: Current learning rate: 0.00419 
2024-12-07 09:36:57.637020: train_loss -0.8956 
2024-12-07 09:36:57.642179: val_loss -0.8534 
2024-12-07 09:36:57.645274: Pseudo dice [np.float32(0.8997), np.float32(0.8824)] 
2024-12-07 09:36:57.647856: Epoch time: 6.35 s 
2024-12-07 09:36:57.650949: Yayy! New best EMA pseudo Dice: 0.8898000121116638 
2024-12-07 09:36:58.241036:  
2024-12-07 09:36:58.245549: Epoch 63 
2024-12-07 09:36:58.248565: Current learning rate: 0.00409 
2024-12-07 09:37:04.589914: train_loss -0.8931 
2024-12-07 09:37:04.595034: val_loss -0.8506 
2024-12-07 09:37:04.598128: Pseudo dice [np.float32(0.8983), np.float32(0.8809)] 
2024-12-07 09:37:04.600702: Epoch time: 6.35 s 
2024-12-07 09:37:05.174520:  
2024-12-07 09:37:05.179538: Epoch 64 
2024-12-07 09:37:05.183555: Current learning rate: 0.00399 
2024-12-07 09:37:11.517992: train_loss -0.896 
2024-12-07 09:37:11.523023: val_loss -0.8514 
2024-12-07 09:37:11.525655: Pseudo dice [np.float32(0.8997), np.float32(0.8822)] 
2024-12-07 09:37:11.528219: Epoch time: 6.34 s 
2024-12-07 09:37:11.530751: Yayy! New best EMA pseudo Dice: 0.8899000287055969 
2024-12-07 09:37:12.129261:  
2024-12-07 09:37:12.132302: Epoch 65 
2024-12-07 09:37:12.134864: Current learning rate: 0.00389 
2024-12-07 09:37:18.475108: train_loss -0.8952 
2024-12-07 09:37:18.480215: val_loss -0.8521 
2024-12-07 09:37:18.484760: Pseudo dice [np.float32(0.8993), np.float32(0.8823)] 
2024-12-07 09:37:18.487271: Epoch time: 6.35 s 
2024-12-07 09:37:18.489832: Yayy! New best EMA pseudo Dice: 0.8899999856948853 
2024-12-07 09:37:19.086717:  
2024-12-07 09:37:19.090230: Epoch 66 
2024-12-07 09:37:19.093741: Current learning rate: 0.00379 
2024-12-07 09:37:25.434035: train_loss -0.8946 
2024-12-07 09:37:25.439669: val_loss -0.8498 
2024-12-07 09:37:25.442726: Pseudo dice [np.float32(0.8984), np.float32(0.8799)] 
2024-12-07 09:37:25.445273: Epoch time: 6.35 s 
2024-12-07 09:37:26.007760:  
2024-12-07 09:37:26.012499: Epoch 67 
2024-12-07 09:37:26.015010: Current learning rate: 0.00369 
2024-12-07 09:37:32.358426: train_loss -0.895 
2024-12-07 09:37:32.363523: val_loss -0.8513 
2024-12-07 09:37:32.366548: Pseudo dice [np.float32(0.8983), np.float32(0.8813)] 
2024-12-07 09:37:32.369644: Epoch time: 6.35 s 
2024-12-07 09:37:32.940150:  
2024-12-07 09:37:32.945727: Epoch 68 
2024-12-07 09:37:32.948282: Current learning rate: 0.00359 
2024-12-07 09:37:39.283540: train_loss -0.8958 
2024-12-07 09:37:39.287638: val_loss -0.8472 
2024-12-07 09:37:39.291184: Pseudo dice [np.float32(0.897), np.float32(0.8767)] 
2024-12-07 09:37:39.294307: Epoch time: 6.34 s 
2024-12-07 09:37:40.004853:  
2024-12-07 09:37:40.007885: Epoch 69 
2024-12-07 09:37:40.011453: Current learning rate: 0.00349 
2024-12-07 09:37:46.349323: train_loss -0.8958 
2024-12-07 09:37:46.356183: val_loss -0.8496 
2024-12-07 09:37:46.358737: Pseudo dice [np.float32(0.8974), np.float32(0.8807)] 
2024-12-07 09:37:46.360772: Epoch time: 6.34 s 
2024-12-07 09:37:46.918221:  
2024-12-07 09:37:46.922241: Epoch 70 
2024-12-07 09:37:46.924754: Current learning rate: 0.00338 
2024-12-07 09:37:53.263787: train_loss -0.8977 
2024-12-07 09:37:53.268904: val_loss -0.8483 
2024-12-07 09:37:53.272994: Pseudo dice [np.float32(0.8962), np.float32(0.8805)] 
2024-12-07 09:37:53.276066: Epoch time: 6.35 s 
2024-12-07 09:37:53.836164:  
2024-12-07 09:37:53.839179: Epoch 71 
2024-12-07 09:37:53.842697: Current learning rate: 0.00328 
2024-12-07 09:38:00.193567: train_loss -0.8977 
2024-12-07 09:38:00.199161: val_loss -0.8454 
2024-12-07 09:38:00.202239: Pseudo dice [np.float32(0.8956), np.float32(0.8766)] 
2024-12-07 09:38:00.204788: Epoch time: 6.36 s 
2024-12-07 09:38:00.761593:  
2024-12-07 09:38:00.766663: Epoch 72 
2024-12-07 09:38:00.769738: Current learning rate: 0.00318 
2024-12-07 09:38:07.125361: train_loss -0.8975 
2024-12-07 09:38:07.130393: val_loss -0.847 
2024-12-07 09:38:07.132911: Pseudo dice [np.float32(0.8971), np.float32(0.8777)] 
2024-12-07 09:38:07.136436: Epoch time: 6.36 s 
2024-12-07 09:38:07.706703:  
2024-12-07 09:38:07.711234: Epoch 73 
2024-12-07 09:38:07.714287: Current learning rate: 0.00308 
2024-12-07 09:38:14.058594: train_loss -0.8998 
2024-12-07 09:38:14.064199: val_loss -0.8487 
2024-12-07 09:38:14.067302: Pseudo dice [np.float32(0.8965), np.float32(0.8806)] 
2024-12-07 09:38:14.070364: Epoch time: 6.35 s 
2024-12-07 09:38:14.642534:  
2024-12-07 09:38:14.647553: Epoch 74 
2024-12-07 09:38:14.650566: Current learning rate: 0.00297 
2024-12-07 09:38:21.005195: train_loss -0.8974 
2024-12-07 09:38:21.010772: val_loss -0.8483 
2024-12-07 09:38:21.014833: Pseudo dice [np.float32(0.8968), np.float32(0.8807)] 
2024-12-07 09:38:21.017848: Epoch time: 6.36 s 
2024-12-07 09:38:21.586989:  
2024-12-07 09:38:21.591007: Epoch 75 
2024-12-07 09:38:21.593520: Current learning rate: 0.00287 
2024-12-07 09:38:27.929819: train_loss -0.8997 
2024-12-07 09:38:27.934592: val_loss -0.8511 
2024-12-07 09:38:27.938154: Pseudo dice [np.float32(0.8989), np.float32(0.8828)] 
2024-12-07 09:38:27.940839: Epoch time: 6.34 s 
2024-12-07 09:38:28.657902:  
2024-12-07 09:38:28.661988: Epoch 76 
2024-12-07 09:38:28.664518: Current learning rate: 0.00277 
2024-12-07 09:38:35.012461: train_loss -0.8998 
2024-12-07 09:38:35.017556: val_loss -0.8528 
2024-12-07 09:38:35.020647: Pseudo dice [np.float32(0.9006), np.float32(0.8819)] 
2024-12-07 09:38:35.023721: Epoch time: 6.35 s 
2024-12-07 09:38:35.627955:  
2024-12-07 09:38:35.633027: Epoch 77 
2024-12-07 09:38:35.636122: Current learning rate: 0.00266 
2024-12-07 09:38:41.977868: train_loss -0.9005 
2024-12-07 09:38:41.982968: val_loss -0.847 
2024-12-07 09:38:41.986506: Pseudo dice [np.float32(0.8965), np.float32(0.8783)] 
2024-12-07 09:38:41.988630: Epoch time: 6.35 s 
2024-12-07 09:38:42.566704:  
2024-12-07 09:38:42.571766: Epoch 78 
2024-12-07 09:38:42.574869: Current learning rate: 0.00256 
2024-12-07 09:38:48.914087: train_loss -0.9001 
2024-12-07 09:38:48.919714: val_loss -0.8448 
2024-12-07 09:38:48.922790: Pseudo dice [np.float32(0.8952), np.float32(0.8769)] 
2024-12-07 09:38:48.925886: Epoch time: 6.35 s 
2024-12-07 09:38:49.489840:  
2024-12-07 09:38:49.494475: Epoch 79 
2024-12-07 09:38:49.497524: Current learning rate: 0.00245 
2024-12-07 09:38:55.826670: train_loss -0.901 
2024-12-07 09:38:55.831792: val_loss -0.8544 
2024-12-07 09:38:55.834860: Pseudo dice [np.float32(0.902), np.float32(0.8851)] 
2024-12-07 09:38:55.837405: Epoch time: 6.34 s 
2024-12-07 09:38:56.405807:  
2024-12-07 09:38:56.408846: Epoch 80 
2024-12-07 09:38:56.412921: Current learning rate: 0.00235 
2024-12-07 09:39:02.746889: train_loss -0.9003 
2024-12-07 09:39:02.752465: val_loss -0.8519 
2024-12-07 09:39:02.755518: Pseudo dice [np.float32(0.8981), np.float32(0.8831)] 
2024-12-07 09:39:02.758074: Epoch time: 6.34 s 
2024-12-07 09:39:03.335436:  
2024-12-07 09:39:03.340962: Epoch 81 
2024-12-07 09:39:03.343113: Current learning rate: 0.00224 
2024-12-07 09:39:09.703022: train_loss -0.9012 
2024-12-07 09:39:09.708035: val_loss -0.8465 
2024-12-07 09:39:09.711592: Pseudo dice [np.float32(0.8961), np.float32(0.8785)] 
2024-12-07 09:39:09.714622: Epoch time: 6.37 s 
2024-12-07 09:39:10.281898:  
2024-12-07 09:39:10.285908: Epoch 82 
2024-12-07 09:39:10.288415: Current learning rate: 0.00214 
2024-12-07 09:39:16.613282: train_loss -0.9018 
2024-12-07 09:39:16.618878: val_loss -0.8485 
2024-12-07 09:39:16.621943: Pseudo dice [np.float32(0.8987), np.float32(0.8793)] 
2024-12-07 09:39:16.624978: Epoch time: 6.33 s 
2024-12-07 09:39:17.169328:  
2024-12-07 09:39:17.173342: Epoch 83 
2024-12-07 09:39:17.175848: Current learning rate: 0.00203 
2024-12-07 09:39:23.521079: train_loss -0.9007 
2024-12-07 09:39:23.526658: val_loss -0.8475 
2024-12-07 09:39:23.529689: Pseudo dice [np.float32(0.897), np.float32(0.8784)] 
2024-12-07 09:39:23.532220: Epoch time: 6.35 s 
2024-12-07 09:39:24.235128:  
2024-12-07 09:39:24.239139: Epoch 84 
2024-12-07 09:39:24.242644: Current learning rate: 0.00192 
2024-12-07 09:39:30.586934: train_loss -0.902 
2024-12-07 09:39:30.592021: val_loss -0.8522 
2024-12-07 09:39:30.595044: Pseudo dice [np.float32(0.8998), np.float32(0.8826)] 
2024-12-07 09:39:30.598104: Epoch time: 6.35 s 
2024-12-07 09:39:31.140833:  
2024-12-07 09:39:31.145382: Epoch 85 
2024-12-07 09:39:31.149005: Current learning rate: 0.00181 
2024-12-07 09:39:37.503493: train_loss -0.9035 
2024-12-07 09:39:37.509094: val_loss -0.8483 
2024-12-07 09:39:37.512175: Pseudo dice [np.float32(0.8974), np.float32(0.8804)] 
2024-12-07 09:39:37.514741: Epoch time: 6.36 s 
2024-12-07 09:39:38.052572:  
2024-12-07 09:39:38.057643: Epoch 86 
2024-12-07 09:39:38.060702: Current learning rate: 0.0017 
2024-12-07 09:39:44.392864: train_loss -0.9031 
2024-12-07 09:39:44.399903: val_loss -0.8476 
2024-12-07 09:39:44.402412: Pseudo dice [np.float32(0.8969), np.float32(0.879)] 
2024-12-07 09:39:44.405930: Epoch time: 6.34 s 
2024-12-07 09:39:44.940239:  
2024-12-07 09:39:44.945310: Epoch 87 
2024-12-07 09:39:44.947867: Current learning rate: 0.00159 
2024-12-07 09:39:51.309479: train_loss -0.9022 
2024-12-07 09:39:51.314562: val_loss -0.85 
2024-12-07 09:39:51.317100: Pseudo dice [np.float32(0.8988), np.float32(0.8824)] 
2024-12-07 09:39:51.320163: Epoch time: 6.37 s 
2024-12-07 09:39:51.849825:  
2024-12-07 09:39:51.853343: Epoch 88 
2024-12-07 09:39:51.855468: Current learning rate: 0.00148 
2024-12-07 09:39:58.211051: train_loss -0.9025 
2024-12-07 09:39:58.216129: val_loss -0.8465 
2024-12-07 09:39:58.220181: Pseudo dice [np.float32(0.897), np.float32(0.878)] 
2024-12-07 09:39:58.222714: Epoch time: 6.36 s 
2024-12-07 09:39:58.758360:  
2024-12-07 09:39:58.763374: Epoch 89 
2024-12-07 09:39:58.767380: Current learning rate: 0.00137 
2024-12-07 09:40:05.112941: train_loss -0.9046 
2024-12-07 09:40:05.117450: val_loss -0.8451 
2024-12-07 09:40:05.120460: Pseudo dice [np.float32(0.8957), np.float32(0.878)] 
2024-12-07 09:40:05.122969: Epoch time: 6.35 s 
2024-12-07 09:40:05.675658:  
2024-12-07 09:40:05.681668: Epoch 90 
2024-12-07 09:40:05.684678: Current learning rate: 0.00126 
2024-12-07 09:40:12.025992: train_loss -0.9055 
2024-12-07 09:40:12.031662: val_loss -0.8493 
2024-12-07 09:40:12.034723: Pseudo dice [np.float32(0.8983), np.float32(0.8811)] 
2024-12-07 09:40:12.037757: Epoch time: 6.35 s 
2024-12-07 09:40:12.605647:  
2024-12-07 09:40:12.610746: Epoch 91 
2024-12-07 09:40:12.613786: Current learning rate: 0.00115 
2024-12-07 09:40:18.965481: train_loss -0.9046 
2024-12-07 09:40:18.971122: val_loss -0.8465 
2024-12-07 09:40:18.973663: Pseudo dice [np.float32(0.8963), np.float32(0.8805)] 
2024-12-07 09:40:18.976717: Epoch time: 6.36 s 
2024-12-07 09:40:19.672445:  
2024-12-07 09:40:19.678052: Epoch 92 
2024-12-07 09:40:19.680615: Current learning rate: 0.00103 
2024-12-07 09:40:26.032161: train_loss -0.9041 
2024-12-07 09:40:26.037821: val_loss -0.8503 
2024-12-07 09:40:26.040881: Pseudo dice [np.float32(0.8992), np.float32(0.8812)] 
2024-12-07 09:40:26.043954: Epoch time: 6.36 s 
2024-12-07 09:40:26.593705:  
2024-12-07 09:40:26.598751: Epoch 93 
2024-12-07 09:40:26.601797: Current learning rate: 0.00091 
2024-12-07 09:40:32.952667: train_loss -0.9052 
2024-12-07 09:40:32.958279: val_loss -0.8496 
2024-12-07 09:40:32.961384: Pseudo dice [np.float32(0.8985), np.float32(0.8817)] 
2024-12-07 09:40:32.964489: Epoch time: 6.36 s 
2024-12-07 09:40:33.515111:  
2024-12-07 09:40:33.520217: Epoch 94 
2024-12-07 09:40:33.522801: Current learning rate: 0.00079 
2024-12-07 09:40:39.879134: train_loss -0.9049 
2024-12-07 09:40:39.884260: val_loss -0.8496 
2024-12-07 09:40:39.887290: Pseudo dice [np.float32(0.8983), np.float32(0.8812)] 
2024-12-07 09:40:39.890173: Epoch time: 6.36 s 
2024-12-07 09:40:40.434980:  
2024-12-07 09:40:40.438748: Epoch 95 
2024-12-07 09:40:40.442313: Current learning rate: 0.00067 
2024-12-07 09:40:46.778582: train_loss -0.9054 
2024-12-07 09:40:46.784163: val_loss -0.854 
2024-12-07 09:40:46.786702: Pseudo dice [np.float32(0.9012), np.float32(0.8828)] 
2024-12-07 09:40:46.790267: Epoch time: 6.34 s 
2024-12-07 09:40:47.318573:  
2024-12-07 09:40:47.322659: Epoch 96 
2024-12-07 09:40:47.325224: Current learning rate: 0.00055 
2024-12-07 09:40:53.668349: train_loss -0.9062 
2024-12-07 09:40:53.673948: val_loss -0.8508 
2024-12-07 09:40:53.676477: Pseudo dice [np.float32(0.8994), np.float32(0.8823)] 
2024-12-07 09:40:53.680004: Epoch time: 6.35 s 
2024-12-07 09:40:54.235604:  
2024-12-07 09:40:54.238118: Epoch 97 
2024-12-07 09:40:54.241751: Current learning rate: 0.00043 
2024-12-07 09:41:00.598783: train_loss -0.9043 
2024-12-07 09:41:00.604432: val_loss -0.8463 
2024-12-07 09:41:00.607525: Pseudo dice [np.float32(0.8973), np.float32(0.8777)] 
2024-12-07 09:41:00.610624: Epoch time: 6.36 s 
2024-12-07 09:41:01.164462:  
2024-12-07 09:41:01.168527: Epoch 98 
2024-12-07 09:41:01.172607: Current learning rate: 0.0003 
2024-12-07 09:41:07.504641: train_loss -0.908 
2024-12-07 09:41:07.510681: val_loss -0.85 
2024-12-07 09:41:07.513315: Pseudo dice [np.float32(0.8994), np.float32(0.8804)] 
2024-12-07 09:41:07.516895: Epoch time: 6.34 s 
2024-12-07 09:41:08.068467:  
2024-12-07 09:41:08.071985: Epoch 99 
2024-12-07 09:41:08.074500: Current learning rate: 0.00016 
2024-12-07 09:41:14.428957: train_loss -0.9068 
2024-12-07 09:41:14.434998: val_loss -0.8485 
2024-12-07 09:41:14.438027: Pseudo dice [np.float32(0.8986), np.float32(0.8795)] 
2024-12-07 09:41:14.440599: Epoch time: 6.36 s 
2024-12-07 09:41:15.044734: Training done. 
2024-12-07 09:41:15.080735: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-07 09:41:15.088733: The split file contains 5 splits. 
2024-12-07 09:41:15.094733: Desired fold for training: 0 
2024-12-07 09:41:15.098734: This split has 208 training and 52 validation cases. 
2024-12-07 09:41:15.104734: predicting hippocampus_017 
2024-12-07 09:41:15.110735: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-07 09:41:15.196733: predicting hippocampus_019 
2024-12-07 09:41:15.202734: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-07 09:41:15.237733: predicting hippocampus_033 
2024-12-07 09:41:15.243734: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-07 09:41:15.265733: predicting hippocampus_035 
2024-12-07 09:41:15.271734: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-07 09:41:15.296734: predicting hippocampus_037 
2024-12-07 09:41:15.302733: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-07 09:41:15.326733: predicting hippocampus_049 
2024-12-07 09:41:15.333733: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-07 09:41:15.355734: predicting hippocampus_052 
2024-12-07 09:41:15.361734: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-07 09:41:15.385733: predicting hippocampus_065 
2024-12-07 09:41:15.392734: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-07 09:41:15.415733: predicting hippocampus_083 
2024-12-07 09:41:15.421734: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-07 09:41:15.455736: predicting hippocampus_088 
2024-12-07 09:41:15.461733: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-07 09:41:18.903660: predicting hippocampus_090 
2024-12-07 09:41:18.910763: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-07 09:41:18.968761: predicting hippocampus_092 
2024-12-07 09:41:18.978764: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-07 09:41:19.042762: predicting hippocampus_095 
2024-12-07 09:41:19.049762: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-07 09:41:19.108761: predicting hippocampus_107 
2024-12-07 09:41:19.115762: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-07 09:41:19.163761: predicting hippocampus_108 
2024-12-07 09:41:19.170764: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-07 09:41:19.214761: predicting hippocampus_123 
2024-12-07 09:41:19.221762: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-07 09:41:19.265761: predicting hippocampus_125 
2024-12-07 09:41:19.272764: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-07 09:41:19.327761: predicting hippocampus_157 
2024-12-07 09:41:19.333762: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-07 09:41:19.365761: predicting hippocampus_164 
2024-12-07 09:41:19.371763: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-07 09:41:19.467762: predicting hippocampus_169 
2024-12-07 09:41:19.474762: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-07 09:41:19.501761: predicting hippocampus_175 
2024-12-07 09:41:19.506763: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-07 09:41:19.534761: predicting hippocampus_185 
2024-12-07 09:41:19.540763: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-07 09:41:19.567761: predicting hippocampus_190 
2024-12-07 09:41:19.572762: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-07 09:41:19.598761: predicting hippocampus_194 
2024-12-07 09:41:19.603761: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-07 09:41:19.632761: predicting hippocampus_204 
2024-12-07 09:41:19.637762: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-07 09:41:19.664761: predicting hippocampus_205 
2024-12-07 09:41:19.670762: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-07 09:41:19.697761: predicting hippocampus_210 
2024-12-07 09:41:19.703762: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-07 09:41:19.730761: predicting hippocampus_217 
2024-12-07 09:41:19.736761: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-07 09:41:19.762761: predicting hippocampus_219 
2024-12-07 09:41:19.768762: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-07 09:41:19.795762: predicting hippocampus_229 
2024-12-07 09:41:19.802762: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-07 09:41:19.830761: predicting hippocampus_244 
2024-12-07 09:41:19.835762: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-07 09:41:19.868762: predicting hippocampus_261 
2024-12-07 09:41:19.874762: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-07 09:41:19.923762: predicting hippocampus_264 
2024-12-07 09:41:19.929762: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-07 09:41:19.959761: predicting hippocampus_277 
2024-12-07 09:41:19.966763: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-07 09:41:20.015762: predicting hippocampus_280 
2024-12-07 09:41:20.022762: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-07 09:41:20.049762: predicting hippocampus_286 
2024-12-07 09:41:20.055762: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-07 09:41:20.103761: predicting hippocampus_288 
2024-12-07 09:41:20.108762: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-07 09:41:20.157761: predicting hippocampus_289 
2024-12-07 09:41:20.162761: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-07 09:41:20.190761: predicting hippocampus_296 
2024-12-07 09:41:20.196761: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-07 09:41:20.223761: predicting hippocampus_305 
2024-12-07 09:41:20.229762: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-07 09:41:20.256761: predicting hippocampus_308 
2024-12-07 09:41:20.261762: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-07 09:41:20.288761: predicting hippocampus_317 
2024-12-07 09:41:20.293761: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-07 09:41:20.322761: predicting hippocampus_327 
2024-12-07 09:41:20.328762: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-07 09:41:20.355761: predicting hippocampus_330 
2024-12-07 09:41:20.360761: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-07 09:41:20.387761: predicting hippocampus_332 
2024-12-07 09:41:20.392763: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-07 09:41:20.420762: predicting hippocampus_338 
2024-12-07 09:41:20.426763: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-07 09:41:20.473761: predicting hippocampus_349 
2024-12-07 09:41:20.480762: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-07 09:41:20.506761: predicting hippocampus_350 
2024-12-07 09:41:20.512762: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-07 09:41:20.538761: predicting hippocampus_356 
2024-12-07 09:41:20.543761: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-07 09:41:20.570761: predicting hippocampus_358 
2024-12-07 09:41:20.576763: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-07 09:41:20.603761: predicting hippocampus_374 
2024-12-07 09:41:20.608762: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-07 09:41:20.637761: predicting hippocampus_394 
2024-12-07 09:41:20.643763: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-07 09:41:24.159309: Validation complete 
2024-12-07 09:41:24.164310: Mean Validation Dice:  0.8927233621706824 
