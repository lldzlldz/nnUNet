
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-07 00:09:38.485811: do_dummy_2d_data_aug: False 
2024-12-07 00:09:38.487812: Creating new 5-fold cross-validation split... 
2024-12-07 00:09:38.493811: Desired fold for training: 0 
2024-12-07 00:09:38.497067: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 366, 'patch_size': [56, 40], 'median_image_size_in_voxels': [50.0, 35.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-07 00:10:08.815576: unpacking dataset... 
2024-12-07 00:10:09.033543: unpacking done... 
2024-12-07 00:10:09.966676:  
2024-12-07 00:10:09.971690: Epoch 0 
2024-12-07 00:10:09.975208: Current learning rate: 0.01 
2024-12-07 00:10:19.768858: train_loss -0.2076 
2024-12-07 00:10:19.774896: val_loss -0.6937 
2024-12-07 00:10:19.778920: Pseudo dice [np.float32(0.8305), np.float32(0.82)] 
2024-12-07 00:10:19.783949: Epoch time: 9.8 s 
2024-12-07 00:10:19.787975: Yayy! New best EMA pseudo Dice: 0.8252000212669373 
2024-12-07 00:10:20.420093:  
2024-12-07 00:10:20.425133: Epoch 1 
2024-12-07 00:10:20.428173: Current learning rate: 0.00991 
2024-12-07 00:10:29.398766: train_loss -0.8007 
2024-12-07 00:10:29.405803: val_loss -0.797 
2024-12-07 00:10:29.409827: Pseudo dice [np.float32(0.8691), np.float32(0.8573)] 
2024-12-07 00:10:29.413343: Epoch time: 8.98 s 
2024-12-07 00:10:29.416876: Yayy! New best EMA pseudo Dice: 0.8289999961853027 
2024-12-07 00:10:30.117405:  
2024-12-07 00:10:30.123472: Epoch 2 
2024-12-07 00:10:30.126553: Current learning rate: 0.00982 
2024-12-07 00:10:39.172933: train_loss -0.8502 
2024-12-07 00:10:39.179463: val_loss -0.8016 
2024-12-07 00:10:39.182985: Pseudo dice [np.float32(0.8748), np.float32(0.8594)] 
2024-12-07 00:10:39.186998: Epoch time: 9.06 s 
2024-12-07 00:10:39.190513: Yayy! New best EMA pseudo Dice: 0.8327999711036682 
2024-12-07 00:10:39.896571:  
2024-12-07 00:10:39.902106: Epoch 3 
2024-12-07 00:10:39.905205: Current learning rate: 0.00973 
2024-12-07 00:10:48.929681: train_loss -0.8727 
2024-12-07 00:10:48.937529: val_loss -0.7961 
2024-12-07 00:10:48.942046: Pseudo dice [np.float32(0.8738), np.float32(0.8585)] 
2024-12-07 00:10:48.947577: Epoch time: 9.03 s 
2024-12-07 00:10:48.952411: Yayy! New best EMA pseudo Dice: 0.8361999988555908 
2024-12-07 00:10:49.643535:  
2024-12-07 00:10:49.648549: Epoch 4 
2024-12-07 00:10:49.651054: Current learning rate: 0.00964 
2024-12-07 00:10:58.654211: train_loss -0.8881 
2024-12-07 00:10:58.660733: val_loss -0.7935 
2024-12-07 00:10:58.665288: Pseudo dice [np.float32(0.8748), np.float32(0.857)] 
2024-12-07 00:10:58.670310: Epoch time: 9.01 s 
2024-12-07 00:10:58.676336: Yayy! New best EMA pseudo Dice: 0.8392000198364258 
2024-12-07 00:10:59.382822:  
2024-12-07 00:10:59.388380: Epoch 5 
2024-12-07 00:10:59.391429: Current learning rate: 0.00955 
2024-12-07 00:11:08.382080: train_loss -0.8995 
2024-12-07 00:11:08.388110: val_loss -0.7906 
2024-12-07 00:11:08.391635: Pseudo dice [np.float32(0.8749), np.float32(0.8569)] 
2024-12-07 00:11:08.396423: Epoch time: 9.0 s 
2024-12-07 00:11:08.400448: Yayy! New best EMA pseudo Dice: 0.8417999744415283 
2024-12-07 00:11:09.184053:  
2024-12-07 00:11:09.189608: Epoch 6 
2024-12-07 00:11:09.192137: Current learning rate: 0.00946 
2024-12-07 00:11:18.243059: train_loss -0.9083 
2024-12-07 00:11:18.248083: val_loss -0.7863 
2024-12-07 00:11:18.252601: Pseudo dice [np.float32(0.8747), np.float32(0.8561)] 
2024-12-07 00:11:18.255618: Epoch time: 9.06 s 
2024-12-07 00:11:18.259136: Yayy! New best EMA pseudo Dice: 0.8442000150680542 
2024-12-07 00:11:18.949979:  
2024-12-07 00:11:18.955523: Epoch 7 
2024-12-07 00:11:18.958069: Current learning rate: 0.00937 
2024-12-07 00:11:27.931485: train_loss -0.9154 
2024-12-07 00:11:27.937714: val_loss -0.7843 
2024-12-07 00:11:27.942809: Pseudo dice [np.float32(0.8747), np.float32(0.8558)] 
2024-12-07 00:11:27.947404: Epoch time: 8.98 s 
2024-12-07 00:11:27.951545: Yayy! New best EMA pseudo Dice: 0.8463000059127808 
2024-12-07 00:11:28.656023:  
2024-12-07 00:11:28.661573: Epoch 8 
2024-12-07 00:11:28.664124: Current learning rate: 0.00928 
2024-12-07 00:11:37.511591: train_loss -0.9214 
2024-12-07 00:11:37.516699: val_loss -0.7781 
2024-12-07 00:11:37.520741: Pseudo dice [np.float32(0.8735), np.float32(0.8545)] 
2024-12-07 00:11:37.524769: Epoch time: 8.86 s 
2024-12-07 00:11:37.528289: Yayy! New best EMA pseudo Dice: 0.8481000065803528 
2024-12-07 00:11:38.218714:  
2024-12-07 00:11:38.222728: Epoch 9 
2024-12-07 00:11:38.226735: Current learning rate: 0.00919 
2024-12-07 00:11:47.114193: train_loss -0.926 
2024-12-07 00:11:47.120206: val_loss -0.7758 
2024-12-07 00:11:47.125354: Pseudo dice [np.float32(0.8734), np.float32(0.8544)] 
2024-12-07 00:11:47.130406: Epoch time: 8.9 s 
2024-12-07 00:11:47.134433: Yayy! New best EMA pseudo Dice: 0.8496000170707703 
2024-12-07 00:11:47.818236:  
2024-12-07 00:11:47.823314: Epoch 10 
2024-12-07 00:11:47.826341: Current learning rate: 0.0091 
2024-12-07 00:11:56.677506: train_loss -0.9303 
2024-12-07 00:11:56.684587: val_loss -0.7737 
2024-12-07 00:11:56.689611: Pseudo dice [np.float32(0.8732), np.float32(0.8548)] 
2024-12-07 00:11:56.695145: Epoch time: 8.86 s 
2024-12-07 00:11:56.700170: Yayy! New best EMA pseudo Dice: 0.8511000275611877 
2024-12-07 00:11:57.376514:  
2024-12-07 00:11:57.382061: Epoch 11 
2024-12-07 00:11:57.384593: Current learning rate: 0.009 
2024-12-07 00:12:06.256722: train_loss -0.9339 
2024-12-07 00:12:06.262249: val_loss -0.7725 
2024-12-07 00:12:06.266275: Pseudo dice [np.float32(0.8735), np.float32(0.8558)] 
2024-12-07 00:12:06.269848: Epoch time: 8.88 s 
2024-12-07 00:12:06.274967: Yayy! New best EMA pseudo Dice: 0.852400004863739 
2024-12-07 00:12:06.971569:  
2024-12-07 00:12:06.977127: Epoch 12 
2024-12-07 00:12:06.979687: Current learning rate: 0.00891 
2024-12-07 00:12:15.851452: train_loss -0.9367 
2024-12-07 00:12:15.858167: val_loss -0.7693 
2024-12-07 00:12:15.861706: Pseudo dice [np.float32(0.8739), np.float32(0.8546)] 
2024-12-07 00:12:15.866286: Epoch time: 8.88 s 
2024-12-07 00:12:15.869907: Yayy! New best EMA pseudo Dice: 0.853600025177002 
2024-12-07 00:12:16.690419:  
2024-12-07 00:12:16.694926: Epoch 13 
2024-12-07 00:12:16.697935: Current learning rate: 0.00882 
2024-12-07 00:12:25.535867: train_loss -0.9398 
2024-12-07 00:12:25.543026: val_loss -0.7643 
2024-12-07 00:12:25.546199: Pseudo dice [np.float32(0.8713), np.float32(0.8532)] 
2024-12-07 00:12:25.549514: Epoch time: 8.85 s 
2024-12-07 00:12:25.553531: Yayy! New best EMA pseudo Dice: 0.8544999957084656 
2024-12-07 00:12:26.242183:  
2024-12-07 00:12:26.247752: Epoch 14 
2024-12-07 00:12:26.250296: Current learning rate: 0.00873 
2024-12-07 00:12:35.073276: train_loss -0.9422 
2024-12-07 00:12:35.078911: val_loss -0.7626 
2024-12-07 00:12:35.083997: Pseudo dice [np.float32(0.8719), np.float32(0.8546)] 
2024-12-07 00:12:35.088554: Epoch time: 8.83 s 
2024-12-07 00:12:35.092079: Yayy! New best EMA pseudo Dice: 0.855400025844574 
2024-12-07 00:12:35.797788:  
2024-12-07 00:12:35.802870: Epoch 15 
2024-12-07 00:12:35.805953: Current learning rate: 0.00864 
2024-12-07 00:12:44.664878: train_loss -0.9443 
2024-12-07 00:12:44.670527: val_loss -0.7636 
2024-12-07 00:12:44.675642: Pseudo dice [np.float32(0.8725), np.float32(0.8555)] 
2024-12-07 00:12:44.679165: Epoch time: 8.87 s 
2024-12-07 00:12:44.684191: Yayy! New best EMA pseudo Dice: 0.8561999797821045 
2024-12-07 00:12:45.401936:  
2024-12-07 00:12:45.407496: Epoch 16 
2024-12-07 00:12:45.410066: Current learning rate: 0.00855 
2024-12-07 00:12:54.244093: train_loss -0.9465 
2024-12-07 00:12:54.250125: val_loss -0.7605 
2024-12-07 00:12:54.254143: Pseudo dice [np.float32(0.8713), np.float32(0.8542)] 
2024-12-07 00:12:54.257660: Epoch time: 8.84 s 
2024-12-07 00:12:54.261675: Yayy! New best EMA pseudo Dice: 0.8568999767303467 
2024-12-07 00:12:54.982666:  
2024-12-07 00:12:54.988736: Epoch 17 
2024-12-07 00:12:54.991800: Current learning rate: 0.00846 
2024-12-07 00:13:03.811596: train_loss -0.9487 
2024-12-07 00:13:03.817621: val_loss -0.7557 
2024-12-07 00:13:03.821634: Pseudo dice [np.float32(0.8703), np.float32(0.8528)] 
2024-12-07 00:13:03.825144: Epoch time: 8.83 s 
2024-12-07 00:13:03.829157: Yayy! New best EMA pseudo Dice: 0.8572999835014343 
2024-12-07 00:13:04.542178:  
2024-12-07 00:13:04.547698: Epoch 18 
2024-12-07 00:13:04.550205: Current learning rate: 0.00836 
2024-12-07 00:13:13.512569: train_loss -0.9502 
2024-12-07 00:13:13.519100: val_loss -0.7571 
2024-12-07 00:13:13.522612: Pseudo dice [np.float32(0.8715), np.float32(0.854)] 
2024-12-07 00:13:13.526121: Epoch time: 8.97 s 
2024-12-07 00:13:13.530136: Yayy! New best EMA pseudo Dice: 0.8579000234603882 
2024-12-07 00:13:14.242003:  
2024-12-07 00:13:14.247016: Epoch 19 
2024-12-07 00:13:14.250527: Current learning rate: 0.00827 
2024-12-07 00:13:23.091118: train_loss -0.9519 
2024-12-07 00:13:23.097237: val_loss -0.7549 
2024-12-07 00:13:23.101415: Pseudo dice [np.float32(0.8717), np.float32(0.8536)] 
2024-12-07 00:13:23.105997: Epoch time: 8.85 s 
2024-12-07 00:13:23.109635: Yayy! New best EMA pseudo Dice: 0.8583999872207642 
2024-12-07 00:13:23.811338:  
2024-12-07 00:13:23.816347: Epoch 20 
2024-12-07 00:13:23.819856: Current learning rate: 0.00818 
2024-12-07 00:13:32.661995: train_loss -0.9533 
2024-12-07 00:13:32.668013: val_loss -0.7526 
2024-12-07 00:13:32.672584: Pseudo dice [np.float32(0.8703), np.float32(0.8538)] 
2024-12-07 00:13:32.677116: Epoch time: 8.85 s 
2024-12-07 00:13:32.680635: Yayy! New best EMA pseudo Dice: 0.8586999773979187 
2024-12-07 00:13:33.529922:  
2024-12-07 00:13:33.534942: Epoch 21 
2024-12-07 00:13:33.537731: Current learning rate: 0.00809 
2024-12-07 00:13:42.374728: train_loss -0.9548 
2024-12-07 00:13:42.380768: val_loss -0.7523 
2024-12-07 00:13:42.384793: Pseudo dice [np.float32(0.8716), np.float32(0.8538)] 
2024-12-07 00:13:42.388309: Epoch time: 8.85 s 
2024-12-07 00:13:42.391325: Yayy! New best EMA pseudo Dice: 0.8590999841690063 
2024-12-07 00:13:43.074412:  
2024-12-07 00:13:43.080423: Epoch 22 
2024-12-07 00:13:43.083430: Current learning rate: 0.008 
2024-12-07 00:13:51.945826: train_loss -0.9562 
2024-12-07 00:13:51.953373: val_loss -0.7504 
2024-12-07 00:13:51.958404: Pseudo dice [np.float32(0.8703), np.float32(0.8538)] 
2024-12-07 00:13:51.961924: Epoch time: 8.87 s 
2024-12-07 00:13:51.966949: Yayy! New best EMA pseudo Dice: 0.8593999743461609 
2024-12-07 00:13:52.638911:  
2024-12-07 00:13:52.643923: Epoch 23 
2024-12-07 00:13:52.647432: Current learning rate: 0.0079 
2024-12-07 00:14:01.466069: train_loss -0.9571 
2024-12-07 00:14:01.470637: val_loss -0.7487 
2024-12-07 00:14:01.475390: Pseudo dice [np.float32(0.871), np.float32(0.853)] 
2024-12-07 00:14:01.478903: Epoch time: 8.83 s 
2024-12-07 00:14:01.482917: Yayy! New best EMA pseudo Dice: 0.8597000241279602 
2024-12-07 00:14:02.162082:  
2024-12-07 00:14:02.167108: Epoch 24 
2024-12-07 00:14:02.169836: Current learning rate: 0.00781 
2024-12-07 00:14:11.046435: train_loss -0.9581 
2024-12-07 00:14:11.051460: val_loss -0.746 
2024-12-07 00:14:11.056489: Pseudo dice [np.float32(0.8703), np.float32(0.8529)] 
2024-12-07 00:14:11.061011: Epoch time: 8.89 s 
2024-12-07 00:14:11.065066: Yayy! New best EMA pseudo Dice: 0.8598999977111816 
2024-12-07 00:14:11.744638:  
2024-12-07 00:14:11.750666: Epoch 25 
2024-12-07 00:14:11.753174: Current learning rate: 0.00772 
2024-12-07 00:14:20.589926: train_loss -0.9593 
2024-12-07 00:14:20.596476: val_loss -0.7461 
2024-12-07 00:14:20.599994: Pseudo dice [np.float32(0.8707), np.float32(0.8533)] 
2024-12-07 00:14:20.604012: Epoch time: 8.85 s 
2024-12-07 00:14:20.609036: Yayy! New best EMA pseudo Dice: 0.8600999712944031 
2024-12-07 00:14:21.288468:  
2024-12-07 00:14:21.293535: Epoch 26 
2024-12-07 00:14:21.296532: Current learning rate: 0.00763 
2024-12-07 00:14:30.114846: train_loss -0.9601 
2024-12-07 00:14:30.120384: val_loss -0.7463 
2024-12-07 00:14:30.123898: Pseudo dice [np.float32(0.871), np.float32(0.8528)] 
2024-12-07 00:14:30.127916: Epoch time: 8.83 s 
2024-12-07 00:14:30.131435: Yayy! New best EMA pseudo Dice: 0.8603000044822693 
2024-12-07 00:14:30.809282:  
2024-12-07 00:14:30.814296: Epoch 27 
2024-12-07 00:14:30.817804: Current learning rate: 0.00753 
2024-12-07 00:14:39.671586: train_loss -0.9614 
2024-12-07 00:14:39.677130: val_loss -0.7439 
2024-12-07 00:14:39.681670: Pseudo dice [np.float32(0.8695), np.float32(0.8538)] 
2024-12-07 00:14:39.686246: Epoch time: 8.86 s 
2024-12-07 00:14:39.690846: Yayy! New best EMA pseudo Dice: 0.8604000210762024 
2024-12-07 00:14:40.387513:  
2024-12-07 00:14:40.393059: Epoch 28 
2024-12-07 00:14:40.396117: Current learning rate: 0.00744 
2024-12-07 00:14:49.229556: train_loss -0.9622 
2024-12-07 00:14:49.238097: val_loss -0.7424 
2024-12-07 00:14:49.241251: Pseudo dice [np.float32(0.8696), np.float32(0.8523)] 
2024-12-07 00:14:49.245863: Epoch time: 8.84 s 
2024-12-07 00:14:49.249900: Yayy! New best EMA pseudo Dice: 0.8604999780654907 
2024-12-07 00:14:50.053232:  
2024-12-07 00:14:50.058772: Epoch 29 
2024-12-07 00:14:50.061329: Current learning rate: 0.00735 
2024-12-07 00:14:58.890149: train_loss -0.9631 
2024-12-07 00:14:58.895724: val_loss -0.7406 
2024-12-07 00:14:58.899425: Pseudo dice [np.float32(0.8696), np.float32(0.8524)] 
2024-12-07 00:14:58.904503: Epoch time: 8.84 s 
2024-12-07 00:14:58.909068: Yayy! New best EMA pseudo Dice: 0.8604999780654907 
2024-12-07 00:14:59.588734:  
2024-12-07 00:14:59.594297: Epoch 30 
2024-12-07 00:14:59.597745: Current learning rate: 0.00725 
2024-12-07 00:15:08.427733: train_loss -0.9638 
2024-12-07 00:15:08.434856: val_loss -0.7406 
2024-12-07 00:15:08.439428: Pseudo dice [np.float32(0.8701), np.float32(0.8534)] 
2024-12-07 00:15:08.442234: Epoch time: 8.84 s 
2024-12-07 00:15:08.446790: Yayy! New best EMA pseudo Dice: 0.8605999946594238 
2024-12-07 00:15:09.108491:  
2024-12-07 00:15:09.114542: Epoch 31 
2024-12-07 00:15:09.117575: Current learning rate: 0.00716 
2024-12-07 00:15:17.935508: train_loss -0.9646 
2024-12-07 00:15:17.941233: val_loss -0.741 
2024-12-07 00:15:17.946041: Pseudo dice [np.float32(0.8693), np.float32(0.8526)] 
2024-12-07 00:15:17.949604: Epoch time: 8.83 s 
2024-12-07 00:15:17.953673: Yayy! New best EMA pseudo Dice: 0.8607000112533569 
2024-12-07 00:15:18.648962:  
2024-12-07 00:15:18.654502: Epoch 32 
2024-12-07 00:15:18.657032: Current learning rate: 0.00707 
2024-12-07 00:15:27.527032: train_loss -0.9655 
2024-12-07 00:15:27.533558: val_loss -0.7417 
2024-12-07 00:15:27.538605: Pseudo dice [np.float32(0.8708), np.float32(0.8531)] 
2024-12-07 00:15:27.542635: Epoch time: 8.88 s 
2024-12-07 00:15:27.547163: Yayy! New best EMA pseudo Dice: 0.86080002784729 
2024-12-07 00:15:28.243045:  
2024-12-07 00:15:28.248057: Epoch 33 
2024-12-07 00:15:28.250564: Current learning rate: 0.00697 
2024-12-07 00:15:37.133617: train_loss -0.9659 
2024-12-07 00:15:37.139141: val_loss -0.7408 
2024-12-07 00:15:37.143659: Pseudo dice [np.float32(0.8711), np.float32(0.8532)] 
2024-12-07 00:15:37.147727: Epoch time: 8.89 s 
2024-12-07 00:15:37.151253: Yayy! New best EMA pseudo Dice: 0.8608999848365784 
2024-12-07 00:15:37.852764:  
2024-12-07 00:15:37.858826: Epoch 34 
2024-12-07 00:15:37.861882: Current learning rate: 0.00688 
2024-12-07 00:15:46.695798: train_loss -0.9666 
2024-12-07 00:15:46.701338: val_loss -0.7394 
2024-12-07 00:15:46.706370: Pseudo dice [np.float32(0.8696), np.float32(0.8532)] 
2024-12-07 00:15:46.711130: Epoch time: 8.84 s 
2024-12-07 00:15:46.716155: Yayy! New best EMA pseudo Dice: 0.8610000014305115 
2024-12-07 00:15:47.418982:  
2024-12-07 00:15:47.424004: Epoch 35 
2024-12-07 00:15:47.426562: Current learning rate: 0.00679 
2024-12-07 00:15:56.257917: train_loss -0.9674 
2024-12-07 00:15:56.263944: val_loss -0.7394 
2024-12-07 00:15:56.267960: Pseudo dice [np.float32(0.8709), np.float32(0.8524)] 
2024-12-07 00:15:56.272478: Epoch time: 8.84 s 
2024-12-07 00:15:56.275495: Yayy! New best EMA pseudo Dice: 0.8611000180244446 
2024-12-07 00:15:56.978025:  
2024-12-07 00:15:56.983054: Epoch 36 
2024-12-07 00:15:56.985821: Current learning rate: 0.00669 
2024-12-07 00:16:05.837691: train_loss -0.9679 
2024-12-07 00:16:05.843697: val_loss -0.7392 
2024-12-07 00:16:05.847726: Pseudo dice [np.float32(0.8704), np.float32(0.8532)] 
2024-12-07 00:16:05.852256: Epoch time: 8.86 s 
2024-12-07 00:16:05.856285: Yayy! New best EMA pseudo Dice: 0.8611000180244446 
2024-12-07 00:16:06.707542:  
2024-12-07 00:16:06.713069: Epoch 37 
2024-12-07 00:16:06.715089: Current learning rate: 0.0066 
2024-12-07 00:16:15.488611: train_loss -0.9683 
2024-12-07 00:16:15.495447: val_loss -0.7384 
2024-12-07 00:16:15.499040: Pseudo dice [np.float32(0.8702), np.float32(0.8524)] 
2024-12-07 00:16:15.503642: Epoch time: 8.78 s 
2024-12-07 00:16:15.507727: Yayy! New best EMA pseudo Dice: 0.8611000180244446 
2024-12-07 00:16:16.228977:  
2024-12-07 00:16:16.233987: Epoch 38 
2024-12-07 00:16:16.237498: Current learning rate: 0.0065 
2024-12-07 00:16:25.067612: train_loss -0.9687 
2024-12-07 00:16:25.073636: val_loss -0.7369 
2024-12-07 00:16:25.077657: Pseudo dice [np.float32(0.8693), np.float32(0.8522)] 
2024-12-07 00:16:25.082187: Epoch time: 8.84 s 
2024-12-07 00:16:25.779041:  
2024-12-07 00:16:25.784553: Epoch 39 
2024-12-07 00:16:25.788061: Current learning rate: 0.00641 
2024-12-07 00:16:34.597836: train_loss -0.9692 
2024-12-07 00:16:34.602869: val_loss -0.7403 
2024-12-07 00:16:34.607461: Pseudo dice [np.float32(0.8706), np.float32(0.8546)] 
2024-12-07 00:16:34.612589: Epoch time: 8.82 s 
2024-12-07 00:16:34.616614: Yayy! New best EMA pseudo Dice: 0.861299991607666 
2024-12-07 00:16:35.314269:  
2024-12-07 00:16:35.319295: Epoch 40 
2024-12-07 00:16:35.321488: Current learning rate: 0.00631 
2024-12-07 00:16:44.092373: train_loss -0.9699 
2024-12-07 00:16:44.099038: val_loss -0.7385 
2024-12-07 00:16:44.102619: Pseudo dice [np.float32(0.8705), np.float32(0.8547)] 
2024-12-07 00:16:44.106683: Epoch time: 8.78 s 
2024-12-07 00:16:44.112302: Yayy! New best EMA pseudo Dice: 0.8614000082015991 
2024-12-07 00:16:44.815784:  
2024-12-07 00:16:44.821318: Epoch 41 
2024-12-07 00:16:44.823840: Current learning rate: 0.00622 
2024-12-07 00:16:53.609907: train_loss -0.9706 
2024-12-07 00:16:53.616439: val_loss -0.7361 
2024-12-07 00:16:53.620957: Pseudo dice [np.float32(0.8697), np.float32(0.854)] 
2024-12-07 00:16:53.624983: Epoch time: 8.79 s 
2024-12-07 00:16:53.628490: Yayy! New best EMA pseudo Dice: 0.8614000082015991 
2024-12-07 00:16:54.292090:  
2024-12-07 00:16:54.297603: Epoch 42 
2024-12-07 00:16:54.300109: Current learning rate: 0.00612 
2024-12-07 00:17:03.095862: train_loss -0.971 
2024-12-07 00:17:03.102393: val_loss -0.7371 
2024-12-07 00:17:03.105911: Pseudo dice [np.float32(0.8707), np.float32(0.8528)] 
2024-12-07 00:17:03.110939: Epoch time: 8.8 s 
2024-12-07 00:17:03.114960: Yayy! New best EMA pseudo Dice: 0.8615000247955322 
2024-12-07 00:17:03.796131:  
2024-12-07 00:17:03.801142: Epoch 43 
2024-12-07 00:17:03.804152: Current learning rate: 0.00603 
2024-12-07 00:17:12.622008: train_loss -0.9713 
2024-12-07 00:17:12.628034: val_loss -0.7361 
2024-12-07 00:17:12.632059: Pseudo dice [np.float32(0.8691), np.float32(0.8528)] 
2024-12-07 00:17:12.636078: Epoch time: 8.83 s 
2024-12-07 00:17:13.437699:  
2024-12-07 00:17:13.442785: Epoch 44 
2024-12-07 00:17:13.445818: Current learning rate: 0.00593 
2024-12-07 00:17:22.206722: train_loss -0.972 
2024-12-07 00:17:22.213414: val_loss -0.7345 
2024-12-07 00:17:22.216923: Pseudo dice [np.float32(0.8704), np.float32(0.8518)] 
2024-12-07 00:17:22.220932: Epoch time: 8.77 s 
2024-12-07 00:17:22.894575:  
2024-12-07 00:17:22.899584: Epoch 45 
2024-12-07 00:17:22.902089: Current learning rate: 0.00584 
2024-12-07 00:17:31.711058: train_loss -0.9724 
2024-12-07 00:17:31.716088: val_loss -0.7367 
2024-12-07 00:17:31.720115: Pseudo dice [np.float32(0.8703), np.float32(0.8527)] 
2024-12-07 00:17:31.723634: Epoch time: 8.82 s 
2024-12-07 00:17:32.374801:  
2024-12-07 00:17:32.379879: Epoch 46 
2024-12-07 00:17:32.382391: Current learning rate: 0.00574 
2024-12-07 00:17:41.203487: train_loss -0.9726 
2024-12-07 00:17:41.209616: val_loss -0.7363 
2024-12-07 00:17:41.214693: Pseudo dice [np.float32(0.8709), np.float32(0.853)] 
2024-12-07 00:17:41.220284: Epoch time: 8.83 s 
2024-12-07 00:17:41.864168:  
2024-12-07 00:17:41.869679: Epoch 47 
2024-12-07 00:17:41.872186: Current learning rate: 0.00565 
2024-12-07 00:17:50.681314: train_loss -0.9731 
2024-12-07 00:17:50.688845: val_loss -0.7357 
2024-12-07 00:17:50.692912: Pseudo dice [np.float32(0.8694), np.float32(0.8527)] 
2024-12-07 00:17:50.698000: Epoch time: 8.82 s 
2024-12-07 00:17:51.355979:  
2024-12-07 00:17:51.360989: Epoch 48 
2024-12-07 00:17:51.364497: Current learning rate: 0.00555 
2024-12-07 00:18:00.175231: train_loss -0.9733 
2024-12-07 00:18:00.180841: val_loss -0.7341 
2024-12-07 00:18:00.185444: Pseudo dice [np.float32(0.8699), np.float32(0.8529)] 
2024-12-07 00:18:00.188996: Epoch time: 8.82 s 
2024-12-07 00:18:00.825862:  
2024-12-07 00:18:00.830870: Epoch 49 
2024-12-07 00:18:00.834382: Current learning rate: 0.00546 
2024-12-07 00:18:09.657775: train_loss -0.9739 
2024-12-07 00:18:09.663394: val_loss -0.7385 
2024-12-07 00:18:09.669104: Pseudo dice [np.float32(0.8715), np.float32(0.8548)] 
2024-12-07 00:18:09.673172: Epoch time: 8.83 s 
2024-12-07 00:18:09.698093: Yayy! New best EMA pseudo Dice: 0.8615999817848206 
2024-12-07 00:18:10.370061:  
2024-12-07 00:18:10.375072: Epoch 50 
2024-12-07 00:18:10.378583: Current learning rate: 0.00536 
2024-12-07 00:18:19.163927: train_loss -0.974 
2024-12-07 00:18:19.169544: val_loss -0.736 
2024-12-07 00:18:19.173094: Pseudo dice [np.float32(0.8709), np.float32(0.8536)] 
2024-12-07 00:18:19.177516: Epoch time: 8.79 s 
2024-12-07 00:18:19.182537: Yayy! New best EMA pseudo Dice: 0.8615999817848206 
2024-12-07 00:18:19.863653:  
2024-12-07 00:18:19.868683: Epoch 51 
2024-12-07 00:18:19.871763: Current learning rate: 0.00526 
2024-12-07 00:18:28.694906: train_loss -0.9747 
2024-12-07 00:18:28.699929: val_loss -0.7346 
2024-12-07 00:18:28.704956: Pseudo dice [np.float32(0.8699), np.float32(0.854)] 
2024-12-07 00:18:28.707469: Epoch time: 8.83 s 
2024-12-07 00:18:28.712498: Yayy! New best EMA pseudo Dice: 0.8616999983787537 
2024-12-07 00:18:29.531206:  
2024-12-07 00:18:29.536229: Epoch 52 
2024-12-07 00:18:29.539757: Current learning rate: 0.00517 
2024-12-07 00:18:38.368098: train_loss -0.9749 
2024-12-07 00:18:38.374627: val_loss -0.7305 
2024-12-07 00:18:38.380660: Pseudo dice [np.float32(0.869), np.float32(0.8527)] 
2024-12-07 00:18:38.386222: Epoch time: 8.84 s 
2024-12-07 00:18:39.053406:  
2024-12-07 00:18:39.058918: Epoch 53 
2024-12-07 00:18:39.062427: Current learning rate: 0.00507 
2024-12-07 00:18:47.837716: train_loss -0.9752 
2024-12-07 00:18:47.843952: val_loss -0.733 
2024-12-07 00:18:47.847580: Pseudo dice [np.float32(0.87), np.float32(0.8528)] 
2024-12-07 00:18:47.851205: Epoch time: 8.79 s 
2024-12-07 00:18:48.532323:  
2024-12-07 00:18:48.538383: Epoch 54 
2024-12-07 00:18:48.541422: Current learning rate: 0.00497 
2024-12-07 00:18:57.371762: train_loss -0.9757 
2024-12-07 00:18:57.378846: val_loss -0.7321 
2024-12-07 00:18:57.382439: Pseudo dice [np.float32(0.8704), np.float32(0.8523)] 
2024-12-07 00:18:57.384993: Epoch time: 8.84 s 
2024-12-07 00:18:58.048698:  
2024-12-07 00:18:58.054234: Epoch 55 
2024-12-07 00:18:58.056765: Current learning rate: 0.00487 
2024-12-07 00:19:06.839459: train_loss -0.9757 
2024-12-07 00:19:06.845559: val_loss -0.7328 
2024-12-07 00:19:06.850593: Pseudo dice [np.float32(0.8702), np.float32(0.8523)] 
2024-12-07 00:19:06.856642: Epoch time: 8.79 s 
2024-12-07 00:19:07.537321:  
2024-12-07 00:19:07.542353: Epoch 56 
2024-12-07 00:19:07.546425: Current learning rate: 0.00478 
2024-12-07 00:19:16.335615: train_loss -0.976 
2024-12-07 00:19:16.341141: val_loss -0.7331 
2024-12-07 00:19:16.346164: Pseudo dice [np.float32(0.8696), np.float32(0.8537)] 
2024-12-07 00:19:16.350683: Epoch time: 8.8 s 
2024-12-07 00:19:16.992442:  
2024-12-07 00:19:16.997465: Epoch 57 
2024-12-07 00:19:17.001493: Current learning rate: 0.00468 
2024-12-07 00:19:25.852667: train_loss -0.9765 
2024-12-07 00:19:25.858710: val_loss -0.7293 
2024-12-07 00:19:25.863748: Pseudo dice [np.float32(0.8691), np.float32(0.8533)] 
2024-12-07 00:19:25.867765: Epoch time: 8.86 s 
2024-12-07 00:19:26.533713:  
2024-12-07 00:19:26.539259: Epoch 58 
2024-12-07 00:19:26.541787: Current learning rate: 0.00458 
2024-12-07 00:19:35.336384: train_loss -0.9766 
2024-12-07 00:19:35.341415: val_loss -0.7304 
2024-12-07 00:19:35.345932: Pseudo dice [np.float32(0.8697), np.float32(0.8521)] 
2024-12-07 00:19:35.349957: Epoch time: 8.8 s 
2024-12-07 00:19:36.019820:  
2024-12-07 00:19:36.024829: Epoch 59 
2024-12-07 00:19:36.028339: Current learning rate: 0.00448 
2024-12-07 00:19:44.808623: train_loss -0.977 
2024-12-07 00:19:44.814639: val_loss -0.7295 
2024-12-07 00:19:44.818659: Pseudo dice [np.float32(0.8689), np.float32(0.8534)] 
2024-12-07 00:19:44.822170: Epoch time: 8.79 s 
2024-12-07 00:19:45.490856:  
2024-12-07 00:19:45.495866: Epoch 60 
2024-12-07 00:19:45.498874: Current learning rate: 0.00438 
2024-12-07 00:19:54.305539: train_loss -0.9775 
2024-12-07 00:19:54.312073: val_loss -0.7272 
2024-12-07 00:19:54.316089: Pseudo dice [np.float32(0.868), np.float32(0.8516)] 
2024-12-07 00:19:54.321106: Epoch time: 8.82 s 
2024-12-07 00:19:55.124326:  
2024-12-07 00:19:55.129335: Epoch 61 
2024-12-07 00:19:55.131840: Current learning rate: 0.00429 
2024-12-07 00:20:03.953911: train_loss -0.9775 
2024-12-07 00:20:03.959464: val_loss -0.7277 
2024-12-07 00:20:03.963494: Pseudo dice [np.float32(0.8684), np.float32(0.8514)] 
2024-12-07 00:20:03.967012: Epoch time: 8.83 s 
2024-12-07 00:20:04.630410:  
2024-12-07 00:20:04.636461: Epoch 62 
2024-12-07 00:20:04.639517: Current learning rate: 0.00419 
2024-12-07 00:20:13.472709: train_loss -0.9779 
2024-12-07 00:20:13.478242: val_loss -0.7298 
2024-12-07 00:20:13.481766: Pseudo dice [np.float32(0.8695), np.float32(0.852)] 
2024-12-07 00:20:13.485278: Epoch time: 8.84 s 
2024-12-07 00:20:14.170505:  
2024-12-07 00:20:14.175571: Epoch 63 
2024-12-07 00:20:14.177856: Current learning rate: 0.00409 
2024-12-07 00:20:22.993747: train_loss -0.978 
2024-12-07 00:20:23.000346: val_loss -0.7333 
2024-12-07 00:20:23.004974: Pseudo dice [np.float32(0.8709), np.float32(0.8539)] 
2024-12-07 00:20:23.009017: Epoch time: 8.82 s 
2024-12-07 00:20:23.682156:  
2024-12-07 00:20:23.687701: Epoch 64 
2024-12-07 00:20:23.690767: Current learning rate: 0.00399 
2024-12-07 00:20:32.464274: train_loss -0.9781 
2024-12-07 00:20:32.469859: val_loss -0.7292 
2024-12-07 00:20:32.474943: Pseudo dice [np.float32(0.8708), np.float32(0.8521)] 
2024-12-07 00:20:32.479520: Epoch time: 8.78 s 
2024-12-07 00:20:33.163842:  
2024-12-07 00:20:33.169385: Epoch 65 
2024-12-07 00:20:33.172947: Current learning rate: 0.00389 
2024-12-07 00:20:41.947155: train_loss -0.9785 
2024-12-07 00:20:41.952687: val_loss -0.7287 
2024-12-07 00:20:41.957708: Pseudo dice [np.float32(0.8687), np.float32(0.8524)] 
2024-12-07 00:20:41.961220: Epoch time: 8.78 s 
2024-12-07 00:20:42.638760:  
2024-12-07 00:20:42.644309: Epoch 66 
2024-12-07 00:20:42.647363: Current learning rate: 0.00379 
2024-12-07 00:20:51.471327: train_loss -0.9787 
2024-12-07 00:20:51.478927: val_loss -0.7272 
2024-12-07 00:20:51.482956: Pseudo dice [np.float32(0.8685), np.float32(0.8529)] 
2024-12-07 00:20:51.486531: Epoch time: 8.83 s 
2024-12-07 00:20:52.148175:  
2024-12-07 00:20:52.153235: Epoch 67 
2024-12-07 00:20:52.156307: Current learning rate: 0.00369 
2024-12-07 00:21:00.943475: train_loss -0.9789 
2024-12-07 00:21:00.948504: val_loss -0.7294 
2024-12-07 00:21:00.953027: Pseudo dice [np.float32(0.8695), np.float32(0.854)] 
2024-12-07 00:21:00.957042: Epoch time: 8.8 s 
2024-12-07 00:21:01.634114:  
2024-12-07 00:21:01.639124: Epoch 68 
2024-12-07 00:21:01.642135: Current learning rate: 0.00359 
2024-12-07 00:21:10.451579: train_loss -0.9791 
2024-12-07 00:21:10.457104: val_loss -0.7282 
2024-12-07 00:21:10.460613: Pseudo dice [np.float32(0.869), np.float32(0.8525)] 
2024-12-07 00:21:10.464627: Epoch time: 8.82 s 
2024-12-07 00:21:11.274986:  
2024-12-07 00:21:11.280110: Epoch 69 
2024-12-07 00:21:11.282627: Current learning rate: 0.00349 
2024-12-07 00:21:20.086616: train_loss -0.9793 
2024-12-07 00:21:20.092152: val_loss -0.7307 
2024-12-07 00:21:20.096507: Pseudo dice [np.float32(0.871), np.float32(0.8535)] 
2024-12-07 00:21:20.100026: Epoch time: 8.81 s 
2024-12-07 00:21:20.789592:  
2024-12-07 00:21:20.793609: Epoch 70 
2024-12-07 00:21:20.796766: Current learning rate: 0.00338 
2024-12-07 00:21:29.614960: train_loss -0.9794 
2024-12-07 00:21:29.620034: val_loss -0.7296 
2024-12-07 00:21:29.625156: Pseudo dice [np.float32(0.8698), np.float32(0.8529)] 
2024-12-07 00:21:29.629120: Epoch time: 8.83 s 
2024-12-07 00:21:30.308924:  
2024-12-07 00:21:30.314463: Epoch 71 
2024-12-07 00:21:30.317000: Current learning rate: 0.00328 
2024-12-07 00:21:39.124952: train_loss -0.9797 
2024-12-07 00:21:39.130547: val_loss -0.7286 
2024-12-07 00:21:39.134706: Pseudo dice [np.float32(0.8694), np.float32(0.853)] 
2024-12-07 00:21:39.138296: Epoch time: 8.82 s 
2024-12-07 00:21:39.833119:  
2024-12-07 00:21:39.837155: Epoch 72 
2024-12-07 00:21:39.841703: Current learning rate: 0.00318 
2024-12-07 00:21:48.606717: train_loss -0.98 
2024-12-07 00:21:48.613457: val_loss -0.7264 
2024-12-07 00:21:48.616984: Pseudo dice [np.float32(0.8694), np.float32(0.8531)] 
2024-12-07 00:21:48.620172: Epoch time: 8.77 s 
2024-12-07 00:21:49.329652:  
2024-12-07 00:21:49.335206: Epoch 73 
2024-12-07 00:21:49.338776: Current learning rate: 0.00308 
2024-12-07 00:21:58.117836: train_loss -0.9801 
2024-12-07 00:21:58.124892: val_loss -0.7272 
2024-12-07 00:21:58.129431: Pseudo dice [np.float32(0.8698), np.float32(0.8526)] 
2024-12-07 00:21:58.134451: Epoch time: 8.79 s 
2024-12-07 00:21:58.823831:  
2024-12-07 00:21:58.828840: Epoch 74 
2024-12-07 00:21:58.831346: Current learning rate: 0.00297 
2024-12-07 00:22:07.640752: train_loss -0.9802 
2024-12-07 00:22:07.646861: val_loss -0.7251 
2024-12-07 00:22:07.651424: Pseudo dice [np.float32(0.8684), np.float32(0.8514)] 
2024-12-07 00:22:07.654461: Epoch time: 8.82 s 
2024-12-07 00:22:08.335255:  
2024-12-07 00:22:08.340767: Epoch 75 
2024-12-07 00:22:08.344275: Current learning rate: 0.00287 
2024-12-07 00:22:17.144558: train_loss -0.9805 
2024-12-07 00:22:17.150088: val_loss -0.7274 
2024-12-07 00:22:17.153606: Pseudo dice [np.float32(0.8697), np.float32(0.8527)] 
2024-12-07 00:22:17.157622: Epoch time: 8.81 s 
2024-12-07 00:22:17.850269:  
2024-12-07 00:22:17.855308: Epoch 76 
2024-12-07 00:22:17.858375: Current learning rate: 0.00277 
2024-12-07 00:22:26.704233: train_loss -0.9806 
2024-12-07 00:22:26.709765: val_loss -0.7227 
2024-12-07 00:22:26.714283: Pseudo dice [np.float32(0.8676), np.float32(0.8521)] 
2024-12-07 00:22:26.717296: Epoch time: 8.85 s 
2024-12-07 00:22:27.542683:  
2024-12-07 00:22:27.548249: Epoch 77 
2024-12-07 00:22:27.551266: Current learning rate: 0.00266 
2024-12-07 00:22:36.354668: train_loss -0.9808 
2024-12-07 00:22:36.360697: val_loss -0.726 
2024-12-07 00:22:36.364725: Pseudo dice [np.float32(0.8677), np.float32(0.8529)] 
2024-12-07 00:22:36.369745: Epoch time: 8.81 s 
2024-12-07 00:22:37.078022:  
2024-12-07 00:22:37.083535: Epoch 78 
2024-12-07 00:22:37.087043: Current learning rate: 0.00256 
2024-12-07 00:22:45.860630: train_loss -0.9812 
2024-12-07 00:22:45.866710: val_loss -0.7263 
2024-12-07 00:22:45.870209: Pseudo dice [np.float32(0.8696), np.float32(0.8509)] 
2024-12-07 00:22:45.874983: Epoch time: 8.78 s 
2024-12-07 00:22:46.578232:  
2024-12-07 00:22:46.583241: Epoch 79 
2024-12-07 00:22:46.585746: Current learning rate: 0.00245 
2024-12-07 00:22:55.385419: train_loss -0.9812 
2024-12-07 00:22:55.391955: val_loss -0.7255 
2024-12-07 00:22:55.396499: Pseudo dice [np.float32(0.8692), np.float32(0.8525)] 
2024-12-07 00:22:55.400605: Epoch time: 8.81 s 
2024-12-07 00:22:56.118056:  
2024-12-07 00:22:56.123126: Epoch 80 
2024-12-07 00:22:56.126205: Current learning rate: 0.00235 
2024-12-07 00:23:04.920194: train_loss -0.9812 
2024-12-07 00:23:04.925220: val_loss -0.7239 
2024-12-07 00:23:04.929236: Pseudo dice [np.float32(0.8678), np.float32(0.8524)] 
2024-12-07 00:23:04.932755: Epoch time: 8.8 s 
2024-12-07 00:23:05.619841:  
2024-12-07 00:23:05.625351: Epoch 81 
2024-12-07 00:23:05.628862: Current learning rate: 0.00224 
2024-12-07 00:23:14.408069: train_loss -0.9814 
2024-12-07 00:23:14.413599: val_loss -0.7286 
2024-12-07 00:23:14.418623: Pseudo dice [np.float32(0.8708), np.float32(0.853)] 
2024-12-07 00:23:14.422144: Epoch time: 8.79 s 
2024-12-07 00:23:15.117567:  
2024-12-07 00:23:15.122579: Epoch 82 
2024-12-07 00:23:15.125084: Current learning rate: 0.00214 
2024-12-07 00:23:23.898929: train_loss -0.9812 
2024-12-07 00:23:23.904589: val_loss -0.7246 
2024-12-07 00:23:23.909171: Pseudo dice [np.float32(0.8677), np.float32(0.8524)] 
2024-12-07 00:23:23.913209: Epoch time: 8.78 s 
2024-12-07 00:23:24.572181:  
2024-12-07 00:23:24.577270: Epoch 83 
2024-12-07 00:23:24.580801: Current learning rate: 0.00203 
2024-12-07 00:23:33.329473: train_loss -0.9816 
2024-12-07 00:23:33.334503: val_loss -0.7235 
2024-12-07 00:23:33.339527: Pseudo dice [np.float32(0.8681), np.float32(0.8513)] 
2024-12-07 00:23:33.343045: Epoch time: 8.76 s 
2024-12-07 00:23:34.163249:  
2024-12-07 00:23:34.168760: Epoch 84 
2024-12-07 00:23:34.171270: Current learning rate: 0.00192 
2024-12-07 00:23:42.945271: train_loss -0.982 
2024-12-07 00:23:42.950501: val_loss -0.7243 
2024-12-07 00:23:42.954020: Pseudo dice [np.float32(0.8686), np.float32(0.852)] 
2024-12-07 00:23:42.959048: Epoch time: 8.78 s 
2024-12-07 00:23:43.619139:  
2024-12-07 00:23:43.624174: Epoch 85 
2024-12-07 00:23:43.626694: Current learning rate: 0.00181 
2024-12-07 00:23:52.408919: train_loss -0.982 
2024-12-07 00:23:52.415054: val_loss -0.7232 
2024-12-07 00:23:52.419118: Pseudo dice [np.float32(0.8689), np.float32(0.8525)] 
2024-12-07 00:23:52.423716: Epoch time: 8.79 s 
2024-12-07 00:23:53.084213:  
2024-12-07 00:23:53.089235: Epoch 86 
2024-12-07 00:23:53.091933: Current learning rate: 0.0017 
2024-12-07 00:24:01.887921: train_loss -0.9819 
2024-12-07 00:24:01.894453: val_loss -0.7235 
2024-12-07 00:24:01.899528: Pseudo dice [np.float32(0.8688), np.float32(0.8509)] 
2024-12-07 00:24:01.903045: Epoch time: 8.8 s 
2024-12-07 00:24:02.549901:  
2024-12-07 00:24:02.554913: Epoch 87 
2024-12-07 00:24:02.557920: Current learning rate: 0.00159 
2024-12-07 00:24:11.321434: train_loss -0.9821 
2024-12-07 00:24:11.326723: val_loss -0.7208 
2024-12-07 00:24:11.331318: Pseudo dice [np.float32(0.8681), np.float32(0.85)] 
2024-12-07 00:24:11.334888: Epoch time: 8.77 s 
2024-12-07 00:24:11.996592:  
2024-12-07 00:24:12.002120: Epoch 88 
2024-12-07 00:24:12.005151: Current learning rate: 0.00148 
2024-12-07 00:24:20.800295: train_loss -0.9823 
2024-12-07 00:24:20.805889: val_loss -0.7255 
2024-12-07 00:24:20.810684: Pseudo dice [np.float32(0.8702), np.float32(0.8516)] 
2024-12-07 00:24:20.814766: Epoch time: 8.8 s 
2024-12-07 00:24:21.487192:  
2024-12-07 00:24:21.492220: Epoch 89 
2024-12-07 00:24:21.494971: Current learning rate: 0.00137 
2024-12-07 00:24:30.257996: train_loss -0.9823 
2024-12-07 00:24:30.263183: val_loss -0.7213 
2024-12-07 00:24:30.267196: Pseudo dice [np.float32(0.8676), np.float32(0.8505)] 
2024-12-07 00:24:30.270711: Epoch time: 8.77 s 
2024-12-07 00:24:30.912611:  
2024-12-07 00:24:30.917453: Epoch 90 
2024-12-07 00:24:30.920477: Current learning rate: 0.00126 
2024-12-07 00:24:39.679855: train_loss -0.9825 
2024-12-07 00:24:39.684885: val_loss -0.7236 
2024-12-07 00:24:39.689412: Pseudo dice [np.float32(0.8684), np.float32(0.8534)] 
2024-12-07 00:24:39.693436: Epoch time: 8.77 s 
2024-12-07 00:24:40.350644:  
2024-12-07 00:24:40.355667: Epoch 91 
2024-12-07 00:24:40.357910: Current learning rate: 0.00115 
2024-12-07 00:24:49.146482: train_loss -0.9825 
2024-12-07 00:24:49.152531: val_loss -0.7239 
2024-12-07 00:24:49.157324: Pseudo dice [np.float32(0.8699), np.float32(0.8514)] 
2024-12-07 00:24:49.161912: Epoch time: 8.8 s 
2024-12-07 00:24:49.825839:  
2024-12-07 00:24:49.830347: Epoch 92 
2024-12-07 00:24:49.833355: Current learning rate: 0.00103 
2024-12-07 00:24:58.571574: train_loss -0.9825 
2024-12-07 00:24:58.578202: val_loss -0.7229 
2024-12-07 00:24:58.581815: Pseudo dice [np.float32(0.8694), np.float32(0.8515)] 
2024-12-07 00:24:58.587422: Epoch time: 8.75 s 
2024-12-07 00:24:59.424551:  
2024-12-07 00:24:59.430094: Epoch 93 
2024-12-07 00:24:59.432635: Current learning rate: 0.00091 
2024-12-07 00:25:08.191341: train_loss -0.9827 
2024-12-07 00:25:08.197465: val_loss -0.7234 
2024-12-07 00:25:08.201576: Pseudo dice [np.float32(0.8689), np.float32(0.8529)] 
2024-12-07 00:25:08.206599: Epoch time: 8.77 s 
2024-12-07 00:25:08.871492:  
2024-12-07 00:25:08.877029: Epoch 94 
2024-12-07 00:25:08.880053: Current learning rate: 0.00079 
2024-12-07 00:25:17.689933: train_loss -0.9827 
2024-12-07 00:25:17.694960: val_loss -0.719 
2024-12-07 00:25:17.699997: Pseudo dice [np.float32(0.8673), np.float32(0.8506)] 
2024-12-07 00:25:17.704527: Epoch time: 8.82 s 
2024-12-07 00:25:18.362855:  
2024-12-07 00:25:18.366910: Epoch 95 
2024-12-07 00:25:18.371464: Current learning rate: 0.00067 
2024-12-07 00:25:27.131301: train_loss -0.9828 
2024-12-07 00:25:27.136485: val_loss -0.7236 
2024-12-07 00:25:27.141575: Pseudo dice [np.float32(0.8692), np.float32(0.8512)] 
2024-12-07 00:25:27.145117: Epoch time: 8.77 s 
2024-12-07 00:25:27.815977:  
2024-12-07 00:25:27.821489: Epoch 96 
2024-12-07 00:25:27.823996: Current learning rate: 0.00055 
2024-12-07 00:25:36.614368: train_loss -0.9826 
2024-12-07 00:25:36.620400: val_loss -0.7211 
2024-12-07 00:25:36.624463: Pseudo dice [np.float32(0.8682), np.float32(0.8511)] 
2024-12-07 00:25:36.628007: Epoch time: 8.8 s 
2024-12-07 00:25:37.290950:  
2024-12-07 00:25:37.296492: Epoch 97 
2024-12-07 00:25:37.299029: Current learning rate: 0.00043 
2024-12-07 00:25:46.080486: train_loss -0.9829 
2024-12-07 00:25:46.085505: val_loss -0.7217 
2024-12-07 00:25:46.090037: Pseudo dice [np.float32(0.8688), np.float32(0.8509)] 
2024-12-07 00:25:46.093084: Epoch time: 8.79 s 
2024-12-07 00:25:46.771821:  
2024-12-07 00:25:46.776852: Epoch 98 
2024-12-07 00:25:46.779896: Current learning rate: 0.0003 
2024-12-07 00:25:55.587561: train_loss -0.983 
2024-12-07 00:25:55.595096: val_loss -0.7218 
2024-12-07 00:25:55.599613: Pseudo dice [np.float32(0.8687), np.float32(0.8508)] 
2024-12-07 00:25:55.603628: Epoch time: 8.82 s 
2024-12-07 00:25:56.282727:  
2024-12-07 00:25:56.288265: Epoch 99 
2024-12-07 00:25:56.290795: Current learning rate: 0.00016 
2024-12-07 00:26:05.046158: train_loss -0.983 
2024-12-07 00:26:05.052246: val_loss -0.724 
2024-12-07 00:26:05.056317: Pseudo dice [np.float32(0.8686), np.float32(0.8517)] 
2024-12-07 00:26:05.059886: Epoch time: 8.76 s 
2024-12-07 00:26:05.766439: Training done. 
2024-12-07 00:26:05.804441: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-07 00:26:05.814440: The split file contains 5 splits. 
2024-12-07 00:26:05.818440: Desired fold for training: 0 
2024-12-07 00:26:05.822442: This split has 208 training and 52 validation cases. 
2024-12-07 00:26:05.826441: predicting hippocampus_017 
2024-12-07 00:26:05.831441: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-07 00:26:05.988438: predicting hippocampus_019 
2024-12-07 00:26:05.995439: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-07 00:26:06.063438: predicting hippocampus_033 
2024-12-07 00:26:06.070439: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-07 00:26:06.162438: predicting hippocampus_035 
2024-12-07 00:26:06.168439: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-07 00:26:06.256438: predicting hippocampus_037 
2024-12-07 00:26:06.262440: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-07 00:26:06.345439: predicting hippocampus_049 
2024-12-07 00:26:06.351439: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-07 00:26:06.418438: predicting hippocampus_052 
2024-12-07 00:26:06.424442: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-07 00:26:06.492438: predicting hippocampus_065 
2024-12-07 00:26:06.498439: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-07 00:26:06.568438: predicting hippocampus_083 
2024-12-07 00:26:06.574440: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-07 00:26:06.642439: predicting hippocampus_088 
2024-12-07 00:26:06.649439: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-07 00:26:09.629958: predicting hippocampus_090 
2024-12-07 00:26:09.636964: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-07 00:26:09.714963: predicting hippocampus_092 
2024-12-07 00:26:09.722965: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-07 00:26:09.797962: predicting hippocampus_095 
2024-12-07 00:26:09.806964: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-07 00:26:09.918965: predicting hippocampus_107 
2024-12-07 00:26:09.925964: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-07 00:26:10.025964: predicting hippocampus_108 
2024-12-07 00:26:10.032963: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-07 00:26:10.130964: predicting hippocampus_123 
2024-12-07 00:26:10.139964: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-07 00:26:10.248963: predicting hippocampus_125 
2024-12-07 00:26:10.255965: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-07 00:26:10.409962: predicting hippocampus_157 
2024-12-07 00:26:10.415964: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-07 00:26:10.494962: predicting hippocampus_164 
2024-12-07 00:26:10.501962: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-07 00:26:10.669962: predicting hippocampus_169 
2024-12-07 00:26:10.674963: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-07 00:26:10.747962: predicting hippocampus_175 
2024-12-07 00:26:10.752963: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-07 00:26:10.817962: predicting hippocampus_185 
2024-12-07 00:26:10.823963: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-07 00:26:10.889962: predicting hippocampus_190 
2024-12-07 00:26:10.894964: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-07 00:26:10.957963: predicting hippocampus_194 
2024-12-07 00:26:10.963963: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-07 00:26:11.025963: predicting hippocampus_204 
2024-12-07 00:26:11.031963: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-07 00:26:11.104962: predicting hippocampus_205 
2024-12-07 00:26:11.109962: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-07 00:26:11.170962: predicting hippocampus_210 
2024-12-07 00:26:11.175963: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-07 00:26:11.255962: predicting hippocampus_217 
2024-12-07 00:26:11.261962: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-07 00:26:11.333962: predicting hippocampus_219 
2024-12-07 00:26:11.339963: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-07 00:26:11.416964: predicting hippocampus_229 
2024-12-07 00:26:11.423964: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-07 00:26:11.489963: predicting hippocampus_244 
2024-12-07 00:26:11.495963: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-07 00:26:11.559963: predicting hippocampus_261 
2024-12-07 00:26:11.564963: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-07 00:26:11.686962: predicting hippocampus_264 
2024-12-07 00:26:11.691963: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-07 00:26:11.763963: predicting hippocampus_277 
2024-12-07 00:26:11.768963: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-07 00:26:11.872963: predicting hippocampus_280 
2024-12-07 00:26:11.878963: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-07 00:26:11.939963: predicting hippocampus_286 
2024-12-07 00:26:11.945963: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-07 00:26:12.029963: predicting hippocampus_288 
2024-12-07 00:26:12.035963: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-07 00:26:12.119962: predicting hippocampus_289 
2024-12-07 00:26:12.124963: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-07 00:26:12.211963: predicting hippocampus_296 
2024-12-07 00:26:12.216963: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-07 00:26:12.293962: predicting hippocampus_305 
2024-12-07 00:26:12.298962: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-07 00:26:12.358963: predicting hippocampus_308 
2024-12-07 00:26:12.362962: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-07 00:26:12.444969: predicting hippocampus_317 
2024-12-07 00:26:12.449970: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-07 00:26:12.528969: predicting hippocampus_327 
2024-12-07 00:26:12.534969: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-07 00:26:12.598969: predicting hippocampus_330 
2024-12-07 00:26:12.603971: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-07 00:26:12.673969: predicting hippocampus_332 
2024-12-07 00:26:12.678969: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-07 00:26:12.748971: predicting hippocampus_338 
2024-12-07 00:26:12.754969: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-07 00:26:12.843969: predicting hippocampus_349 
2024-12-07 00:26:12.848969: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-07 00:26:12.924969: predicting hippocampus_350 
2024-12-07 00:26:12.929969: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-07 00:26:13.001969: predicting hippocampus_356 
2024-12-07 00:26:13.007969: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-07 00:26:13.086969: predicting hippocampus_358 
2024-12-07 00:26:13.091969: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-07 00:26:13.170969: predicting hippocampus_374 
2024-12-07 00:26:13.175969: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-07 00:26:13.254969: predicting hippocampus_394 
2024-12-07 00:26:13.260969: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-07 00:26:16.793029: Validation complete 
2024-12-07 00:26:16.798029: Mean Validation Dice:  0.8543077779172743 
