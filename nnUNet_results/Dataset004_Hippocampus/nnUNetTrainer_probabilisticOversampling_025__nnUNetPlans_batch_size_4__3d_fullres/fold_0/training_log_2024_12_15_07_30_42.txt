2024-12-15 07:30:42.049032: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.25 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-15 07:30:42.053031: self.oversample_foreground_percent 0.2222222222222222 
2024-12-15 07:30:42.057033: do_dummy_2d_data_aug: False 
2024-12-15 07:30:42.098032: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-15 07:30:42.106031: The split file contains 5 splits. 
2024-12-15 07:30:42.109032: Desired fold for training: 0 
2024-12-15 07:30:42.111032: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-15 07:30:48.465523: unpacking dataset... 
2024-12-15 07:30:48.793612: unpacking done... 
2024-12-15 07:30:49.774444:  
2024-12-15 07:30:49.778449: Epoch 0 
2024-12-15 07:30:49.780954: Current learning rate: 0.01 
2024-12-15 07:30:57.127545: train_loss -0.3628 
2024-12-15 07:30:57.133673: val_loss -0.7633 
2024-12-15 07:30:57.136265: Pseudo dice [np.float32(0.8312), np.float32(0.8218)] 
2024-12-15 07:30:57.139405: Epoch time: 7.35 s 
2024-12-15 07:30:57.141990: Yayy! New best EMA pseudo Dice: 0.8264999985694885 
2024-12-15 07:30:57.647839:  
2024-12-15 07:30:57.652920: Epoch 1 
2024-12-15 07:30:57.656044: Current learning rate: 0.00991 
2024-12-15 07:31:04.022860: train_loss -0.7715 
2024-12-15 07:31:04.027926: val_loss -0.805 
2024-12-15 07:31:04.030970: Pseudo dice [np.float32(0.8655), np.float32(0.8443)] 
2024-12-15 07:31:04.033513: Epoch time: 6.38 s 
2024-12-15 07:31:04.035594: Yayy! New best EMA pseudo Dice: 0.8292999863624573 
2024-12-15 07:31:04.601339:  
2024-12-15 07:31:04.606355: Epoch 2 
2024-12-15 07:31:04.608861: Current learning rate: 0.00982 
2024-12-15 07:31:10.999557: train_loss -0.8021 
2024-12-15 07:31:11.004140: val_loss -0.8226 
2024-12-15 07:31:11.007180: Pseudo dice [np.float32(0.8756), np.float32(0.8622)] 
2024-12-15 07:31:11.010688: Epoch time: 6.4 s 
2024-12-15 07:31:11.013700: Yayy! New best EMA pseudo Dice: 0.833299994468689 
2024-12-15 07:31:11.631926:  
2024-12-15 07:31:11.636947: Epoch 3 
2024-12-15 07:31:11.640465: Current learning rate: 0.00973 
2024-12-15 07:31:18.019547: train_loss -0.8164 
2024-12-15 07:31:18.024559: val_loss -0.8257 
2024-12-15 07:31:18.028071: Pseudo dice [np.float32(0.8791), np.float32(0.859)] 
2024-12-15 07:31:18.031143: Epoch time: 6.39 s 
2024-12-15 07:31:18.033689: Yayy! New best EMA pseudo Dice: 0.8367999792098999 
2024-12-15 07:31:18.611507:  
2024-12-15 07:31:18.616520: Epoch 4 
2024-12-15 07:31:18.619528: Current learning rate: 0.00964 
2024-12-15 07:31:25.011682: train_loss -0.8223 
2024-12-15 07:31:25.016312: val_loss -0.8323 
2024-12-15 07:31:25.020383: Pseudo dice [np.float32(0.8857), np.float32(0.8652)] 
2024-12-15 07:31:25.023064: Epoch time: 6.4 s 
2024-12-15 07:31:25.025610: Yayy! New best EMA pseudo Dice: 0.8406999707221985 
2024-12-15 07:31:25.738776:  
2024-12-15 07:31:25.743788: Epoch 5 
2024-12-15 07:31:25.747298: Current learning rate: 0.00955 
2024-12-15 07:31:32.120009: train_loss -0.8287 
2024-12-15 07:31:32.127074: val_loss -0.8385 
2024-12-15 07:31:32.130174: Pseudo dice [np.float32(0.8888), np.float32(0.8709)] 
2024-12-15 07:31:32.133209: Epoch time: 6.38 s 
2024-12-15 07:31:32.135722: Yayy! New best EMA pseudo Dice: 0.8446000218391418 
2024-12-15 07:31:32.698379:  
2024-12-15 07:31:32.703502: Epoch 6 
2024-12-15 07:31:32.706010: Current learning rate: 0.00946 
2024-12-15 07:31:39.095387: train_loss -0.8367 
2024-12-15 07:31:39.100581: val_loss -0.8366 
2024-12-15 07:31:39.104219: Pseudo dice [np.float32(0.8846), np.float32(0.8719)] 
2024-12-15 07:31:39.106757: Epoch time: 6.4 s 
2024-12-15 07:31:39.109297: Yayy! New best EMA pseudo Dice: 0.8479999899864197 
2024-12-15 07:31:39.681215:  
2024-12-15 07:31:39.686260: Epoch 7 
2024-12-15 07:31:39.689378: Current learning rate: 0.00937 
2024-12-15 07:31:46.042901: train_loss -0.8386 
2024-12-15 07:31:46.048119: val_loss -0.8361 
2024-12-15 07:31:46.051191: Pseudo dice [np.float32(0.8864), np.float32(0.8689)] 
2024-12-15 07:31:46.054245: Epoch time: 6.36 s 
2024-12-15 07:31:46.056844: Yayy! New best EMA pseudo Dice: 0.8510000109672546 
2024-12-15 07:31:46.642826:  
2024-12-15 07:31:46.646344: Epoch 8 
2024-12-15 07:31:46.650466: Current learning rate: 0.00928 
2024-12-15 07:31:53.016761: train_loss -0.8385 
2024-12-15 07:31:53.023380: val_loss -0.838 
2024-12-15 07:31:53.025828: Pseudo dice [np.float32(0.8884), np.float32(0.8705)] 
2024-12-15 07:31:53.029338: Epoch time: 6.37 s 
2024-12-15 07:31:53.032373: Yayy! New best EMA pseudo Dice: 0.8537999987602234 
2024-12-15 07:31:53.619706:  
2024-12-15 07:31:53.624223: Epoch 9 
2024-12-15 07:31:53.627460: Current learning rate: 0.00919 
2024-12-15 07:31:59.989676: train_loss -0.8448 
2024-12-15 07:31:59.994776: val_loss -0.844 
2024-12-15 07:31:59.998334: Pseudo dice [np.float32(0.8922), np.float32(0.8742)] 
2024-12-15 07:32:00.000471: Epoch time: 6.37 s 
2024-12-15 07:32:00.003525: Yayy! New best EMA pseudo Dice: 0.8567000031471252 
2024-12-15 07:32:00.567624:  
2024-12-15 07:32:00.571633: Epoch 10 
2024-12-15 07:32:00.573996: Current learning rate: 0.0091 
2024-12-15 07:32:06.932458: train_loss -0.8463 
2024-12-15 07:32:06.937532: val_loss -0.8412 
2024-12-15 07:32:06.940542: Pseudo dice [np.float32(0.8927), np.float32(0.8691)] 
2024-12-15 07:32:06.943047: Epoch time: 6.37 s 
2024-12-15 07:32:06.946079: Yayy! New best EMA pseudo Dice: 0.8592000007629395 
2024-12-15 07:32:07.509969:  
2024-12-15 07:32:07.513550: Epoch 11 
2024-12-15 07:32:07.516626: Current learning rate: 0.009 
2024-12-15 07:32:13.883331: train_loss -0.8497 
2024-12-15 07:32:13.888420: val_loss -0.8422 
2024-12-15 07:32:13.892951: Pseudo dice [np.float32(0.8925), np.float32(0.8731)] 
2024-12-15 07:32:13.895456: Epoch time: 6.37 s 
2024-12-15 07:32:13.897999: Yayy! New best EMA pseudo Dice: 0.8615000247955322 
2024-12-15 07:32:14.466408:  
2024-12-15 07:32:14.471422: Epoch 12 
2024-12-15 07:32:14.473929: Current learning rate: 0.00891 
2024-12-15 07:32:20.834148: train_loss -0.85 
2024-12-15 07:32:20.839230: val_loss -0.8469 
2024-12-15 07:32:20.841796: Pseudo dice [np.float32(0.8933), np.float32(0.8756)] 
2024-12-15 07:32:20.844931: Epoch time: 6.37 s 
2024-12-15 07:32:20.847979: Yayy! New best EMA pseudo Dice: 0.8637999892234802 
2024-12-15 07:32:21.557595:  
2024-12-15 07:32:21.561650: Epoch 13 
2024-12-15 07:32:21.565720: Current learning rate: 0.00882 
2024-12-15 07:32:27.916735: train_loss -0.852 
2024-12-15 07:32:27.921883: val_loss -0.8416 
2024-12-15 07:32:27.924394: Pseudo dice [np.float32(0.8901), np.float32(0.8723)] 
2024-12-15 07:32:27.926899: Epoch time: 6.36 s 
2024-12-15 07:32:27.930415: Yayy! New best EMA pseudo Dice: 0.8655999898910522 
2024-12-15 07:32:28.503475:  
2024-12-15 07:32:28.508498: Epoch 14 
2024-12-15 07:32:28.511871: Current learning rate: 0.00873 
2024-12-15 07:32:34.854198: train_loss -0.8553 
2024-12-15 07:32:34.858497: val_loss -0.8463 
2024-12-15 07:32:34.862019: Pseudo dice [np.float32(0.8942), np.float32(0.8749)] 
2024-12-15 07:32:34.864575: Epoch time: 6.35 s 
2024-12-15 07:32:34.866630: Yayy! New best EMA pseudo Dice: 0.8673999905586243 
2024-12-15 07:32:35.447427:  
2024-12-15 07:32:35.453016: Epoch 15 
2024-12-15 07:32:35.455557: Current learning rate: 0.00864 
2024-12-15 07:32:41.812599: train_loss -0.8559 
2024-12-15 07:32:41.817119: val_loss -0.8478 
2024-12-15 07:32:41.820166: Pseudo dice [np.float32(0.8962), np.float32(0.8765)] 
2024-12-15 07:32:41.823685: Epoch time: 6.37 s 
2024-12-15 07:32:41.826290: Yayy! New best EMA pseudo Dice: 0.8693000078201294 
2024-12-15 07:32:42.416191:  
2024-12-15 07:32:42.421761: Epoch 16 
2024-12-15 07:32:42.424364: Current learning rate: 0.00855 
2024-12-15 07:32:48.798254: train_loss -0.8547 
2024-12-15 07:32:48.803319: val_loss -0.8409 
2024-12-15 07:32:48.805896: Pseudo dice [np.float32(0.8918), np.float32(0.8706)] 
2024-12-15 07:32:48.809481: Epoch time: 6.38 s 
2024-12-15 07:32:48.812133: Yayy! New best EMA pseudo Dice: 0.8705000281333923 
2024-12-15 07:32:49.403798:  
2024-12-15 07:32:49.408848: Epoch 17 
2024-12-15 07:32:49.411948: Current learning rate: 0.00846 
2024-12-15 07:32:55.775529: train_loss -0.858 
2024-12-15 07:32:55.781141: val_loss -0.851 
2024-12-15 07:32:55.783676: Pseudo dice [np.float32(0.8996), np.float32(0.88)] 
2024-12-15 07:32:55.786739: Epoch time: 6.37 s 
2024-12-15 07:32:55.789759: Yayy! New best EMA pseudo Dice: 0.8725000023841858 
2024-12-15 07:32:56.379447:  
2024-12-15 07:32:56.384504: Epoch 18 
2024-12-15 07:32:56.387636: Current learning rate: 0.00836 
2024-12-15 07:33:02.748195: train_loss -0.8602 
2024-12-15 07:33:02.753264: val_loss -0.8451 
2024-12-15 07:33:02.755966: Pseudo dice [np.float32(0.8938), np.float32(0.8744)] 
2024-12-15 07:33:02.758472: Epoch time: 6.37 s 
2024-12-15 07:33:02.761982: Yayy! New best EMA pseudo Dice: 0.8736000061035156 
2024-12-15 07:33:03.351852:  
2024-12-15 07:33:03.356512: Epoch 19 
2024-12-15 07:33:03.359569: Current learning rate: 0.00827 
2024-12-15 07:33:09.724589: train_loss -0.8617 
2024-12-15 07:33:09.731115: val_loss -0.8424 
2024-12-15 07:33:09.733634: Pseudo dice [np.float32(0.8929), np.float32(0.8721)] 
2024-12-15 07:33:09.737144: Epoch time: 6.37 s 
2024-12-15 07:33:09.739650: Yayy! New best EMA pseudo Dice: 0.8744999766349792 
2024-12-15 07:33:10.462988:  
2024-12-15 07:33:10.468003: Epoch 20 
2024-12-15 07:33:10.470508: Current learning rate: 0.00818 
2024-12-15 07:33:16.816782: train_loss -0.8613 
2024-12-15 07:33:16.822307: val_loss -0.8542 
2024-12-15 07:33:16.825347: Pseudo dice [np.float32(0.9003), np.float32(0.8821)] 
2024-12-15 07:33:16.828358: Epoch time: 6.35 s 
2024-12-15 07:33:16.831409: Yayy! New best EMA pseudo Dice: 0.8762000203132629 
2024-12-15 07:33:17.425228:  
2024-12-15 07:33:17.429277: Epoch 21 
2024-12-15 07:33:17.433873: Current learning rate: 0.00809 
2024-12-15 07:33:23.797051: train_loss -0.8629 
2024-12-15 07:33:23.801702: val_loss -0.8504 
2024-12-15 07:33:23.804778: Pseudo dice [np.float32(0.8984), np.float32(0.8781)] 
2024-12-15 07:33:23.807839: Epoch time: 6.37 s 
2024-12-15 07:33:23.810863: Yayy! New best EMA pseudo Dice: 0.8773999810218811 
2024-12-15 07:33:24.379016:  
2024-12-15 07:33:24.384027: Epoch 22 
2024-12-15 07:33:24.386537: Current learning rate: 0.008 
2024-12-15 07:33:30.739752: train_loss -0.8644 
2024-12-15 07:33:30.744767: val_loss -0.8528 
2024-12-15 07:33:30.747819: Pseudo dice [np.float32(0.8973), np.float32(0.8824)] 
2024-12-15 07:33:30.750912: Epoch time: 6.36 s 
2024-12-15 07:33:30.754008: Yayy! New best EMA pseudo Dice: 0.878600001335144 
2024-12-15 07:33:31.316041:  
2024-12-15 07:33:31.321074: Epoch 23 
2024-12-15 07:33:31.324086: Current learning rate: 0.0079 
2024-12-15 07:33:37.674276: train_loss -0.8667 
2024-12-15 07:33:37.679820: val_loss -0.8529 
2024-12-15 07:33:37.682353: Pseudo dice [np.float32(0.8983), np.float32(0.8812)] 
2024-12-15 07:33:37.686483: Epoch time: 6.36 s 
2024-12-15 07:33:37.689528: Yayy! New best EMA pseudo Dice: 0.8797000050544739 
2024-12-15 07:33:38.256102:  
2024-12-15 07:33:38.260142: Epoch 24 
2024-12-15 07:33:38.262701: Current learning rate: 0.00781 
2024-12-15 07:33:44.612947: train_loss -0.8667 
2024-12-15 07:33:44.618515: val_loss -0.8533 
2024-12-15 07:33:44.621052: Pseudo dice [np.float32(0.8976), np.float32(0.8822)] 
2024-12-15 07:33:44.624597: Epoch time: 6.36 s 
2024-12-15 07:33:44.627118: Yayy! New best EMA pseudo Dice: 0.8808000087738037 
2024-12-15 07:33:45.195526:  
2024-12-15 07:33:45.199571: Epoch 25 
2024-12-15 07:33:45.203639: Current learning rate: 0.00772 
2024-12-15 07:33:51.548402: train_loss -0.8676 
2024-12-15 07:33:51.553547: val_loss -0.8475 
2024-12-15 07:33:51.556592: Pseudo dice [np.float32(0.8974), np.float32(0.8754)] 
2024-12-15 07:33:51.559772: Epoch time: 6.35 s 
2024-12-15 07:33:51.562363: Yayy! New best EMA pseudo Dice: 0.8812999725341797 
2024-12-15 07:33:52.128731:  
2024-12-15 07:33:52.132775: Epoch 26 
2024-12-15 07:33:52.136838: Current learning rate: 0.00763 
2024-12-15 07:33:58.492481: train_loss -0.868 
2024-12-15 07:33:58.498302: val_loss -0.8477 
2024-12-15 07:33:58.500813: Pseudo dice [np.float32(0.8955), np.float32(0.8765)] 
2024-12-15 07:33:58.504328: Epoch time: 6.36 s 
2024-12-15 07:33:58.506862: Yayy! New best EMA pseudo Dice: 0.8817999958992004 
2024-12-15 07:33:59.072304:  
2024-12-15 07:33:59.077912: Epoch 27 
2024-12-15 07:33:59.080978: Current learning rate: 0.00753 
2024-12-15 07:34:05.433367: train_loss -0.8686 
2024-12-15 07:34:05.438403: val_loss -0.8477 
2024-12-15 07:34:05.441411: Pseudo dice [np.float32(0.8966), np.float32(0.8781)] 
2024-12-15 07:34:05.444424: Epoch time: 6.36 s 
2024-12-15 07:34:05.447461: Yayy! New best EMA pseudo Dice: 0.8823000192642212 
2024-12-15 07:34:06.162581:  
2024-12-15 07:34:06.167593: Epoch 28 
2024-12-15 07:34:06.170099: Current learning rate: 0.00744 
2024-12-15 07:34:12.520451: train_loss -0.8698 
2024-12-15 07:34:12.525487: val_loss -0.8487 
2024-12-15 07:34:12.528206: Pseudo dice [np.float32(0.895), np.float32(0.8772)] 
2024-12-15 07:34:12.530748: Epoch time: 6.36 s 
2024-12-15 07:34:12.533289: Yayy! New best EMA pseudo Dice: 0.8827000260353088 
2024-12-15 07:34:13.104831:  
2024-12-15 07:34:13.109854: Epoch 29 
2024-12-15 07:34:13.113365: Current learning rate: 0.00735 
2024-12-15 07:34:19.469961: train_loss -0.8709 
2024-12-15 07:34:19.475603: val_loss -0.8493 
2024-12-15 07:34:19.478676: Pseudo dice [np.float32(0.8987), np.float32(0.8776)] 
2024-12-15 07:34:19.481828: Epoch time: 6.37 s 
2024-12-15 07:34:19.484416: Yayy! New best EMA pseudo Dice: 0.8833000063896179 
2024-12-15 07:34:20.060662:  
2024-12-15 07:34:20.064674: Epoch 30 
2024-12-15 07:34:20.067181: Current learning rate: 0.00725 
2024-12-15 07:34:26.428893: train_loss -0.8708 
2024-12-15 07:34:26.434452: val_loss -0.8492 
2024-12-15 07:34:26.437956: Pseudo dice [np.float32(0.8963), np.float32(0.8802)] 
2024-12-15 07:34:26.441031: Epoch time: 6.37 s 
2024-12-15 07:34:26.443578: Yayy! New best EMA pseudo Dice: 0.8838000297546387 
2024-12-15 07:34:27.012903:  
2024-12-15 07:34:27.018486: Epoch 31 
2024-12-15 07:34:27.021545: Current learning rate: 0.00716 
2024-12-15 07:34:33.377016: train_loss -0.8723 
2024-12-15 07:34:33.382554: val_loss -0.8484 
2024-12-15 07:34:33.385060: Pseudo dice [np.float32(0.8941), np.float32(0.8778)] 
2024-12-15 07:34:33.387600: Epoch time: 6.36 s 
2024-12-15 07:34:33.391655: Yayy! New best EMA pseudo Dice: 0.8840000033378601 
2024-12-15 07:34:33.970994:  
2024-12-15 07:34:33.976057: Epoch 32 
2024-12-15 07:34:33.978639: Current learning rate: 0.00707 
2024-12-15 07:34:40.336690: train_loss -0.8727 
2024-12-15 07:34:40.341274: val_loss -0.8475 
2024-12-15 07:34:40.345877: Pseudo dice [np.float32(0.8942), np.float32(0.8786)] 
2024-12-15 07:34:40.348478: Epoch time: 6.37 s 
2024-12-15 07:34:40.351547: Yayy! New best EMA pseudo Dice: 0.8841999769210815 
2024-12-15 07:34:40.930462:  
2024-12-15 07:34:40.935490: Epoch 33 
2024-12-15 07:34:40.938057: Current learning rate: 0.00697 
2024-12-15 07:34:47.290218: train_loss -0.8745 
2024-12-15 07:34:47.295229: val_loss -0.8527 
2024-12-15 07:34:47.298745: Pseudo dice [np.float32(0.9011), np.float32(0.8803)] 
2024-12-15 07:34:47.300770: Epoch time: 6.36 s 
2024-12-15 07:34:47.303800: Yayy! New best EMA pseudo Dice: 0.8848999738693237 
2024-12-15 07:34:47.884372:  
2024-12-15 07:34:47.888897: Epoch 34 
2024-12-15 07:34:47.892181: Current learning rate: 0.00688 
2024-12-15 07:34:54.257504: train_loss -0.8746 
2024-12-15 07:34:54.264102: val_loss -0.8552 
2024-12-15 07:34:54.267192: Pseudo dice [np.float32(0.8997), np.float32(0.8844)] 
2024-12-15 07:34:54.270240: Epoch time: 6.37 s 
2024-12-15 07:34:54.272757: Yayy! New best EMA pseudo Dice: 0.8855999708175659 
2024-12-15 07:34:54.861867:  
2024-12-15 07:34:54.866880: Epoch 35 
2024-12-15 07:34:54.869388: Current learning rate: 0.00679 
2024-12-15 07:35:01.224957: train_loss -0.8768 
2024-12-15 07:35:01.230019: val_loss -0.848 
2024-12-15 07:35:01.233042: Pseudo dice [np.float32(0.8969), np.float32(0.8774)] 
2024-12-15 07:35:01.236157: Epoch time: 6.36 s 
2024-12-15 07:35:01.238675: Yayy! New best EMA pseudo Dice: 0.885699987411499 
2024-12-15 07:35:01.972005:  
2024-12-15 07:35:01.977557: Epoch 36 
2024-12-15 07:35:01.980595: Current learning rate: 0.00669 
2024-12-15 07:35:08.356991: train_loss -0.8769 
2024-12-15 07:35:08.362128: val_loss -0.8537 
2024-12-15 07:35:08.365185: Pseudo dice [np.float32(0.9003), np.float32(0.8816)] 
2024-12-15 07:35:08.367690: Epoch time: 6.38 s 
2024-12-15 07:35:08.370731: Yayy! New best EMA pseudo Dice: 0.8863000273704529 
2024-12-15 07:35:08.969456:  
2024-12-15 07:35:08.974484: Epoch 37 
2024-12-15 07:35:08.978534: Current learning rate: 0.0066 
2024-12-15 07:35:15.359312: train_loss -0.8781 
2024-12-15 07:35:15.364480: val_loss -0.8492 
2024-12-15 07:35:15.368038: Pseudo dice [np.float32(0.898), np.float32(0.8764)] 
2024-12-15 07:35:15.370588: Epoch time: 6.39 s 
2024-12-15 07:35:15.373114: Yayy! New best EMA pseudo Dice: 0.8863999843597412 
2024-12-15 07:35:15.964523:  
2024-12-15 07:35:15.968597: Epoch 38 
2024-12-15 07:35:15.972735: Current learning rate: 0.0065 
2024-12-15 07:35:22.346150: train_loss -0.8767 
2024-12-15 07:35:22.351773: val_loss -0.8487 
2024-12-15 07:35:22.354334: Pseudo dice [np.float32(0.8945), np.float32(0.8787)] 
2024-12-15 07:35:22.357409: Epoch time: 6.38 s 
2024-12-15 07:35:22.360469: Yayy! New best EMA pseudo Dice: 0.8863999843597412 
2024-12-15 07:35:22.947682:  
2024-12-15 07:35:22.952742: Epoch 39 
2024-12-15 07:35:22.956254: Current learning rate: 0.00641 
2024-12-15 07:35:29.326185: train_loss -0.8801 
2024-12-15 07:35:29.331286: val_loss -0.8556 
2024-12-15 07:35:29.333793: Pseudo dice [np.float32(0.9013), np.float32(0.8825)] 
2024-12-15 07:35:29.337301: Epoch time: 6.38 s 
2024-12-15 07:35:29.340399: Yayy! New best EMA pseudo Dice: 0.886900007724762 
2024-12-15 07:35:29.934615:  
2024-12-15 07:35:29.937646: Epoch 40 
2024-12-15 07:35:29.940195: Current learning rate: 0.00631 
2024-12-15 07:35:36.297892: train_loss -0.8786 
2024-12-15 07:35:36.303459: val_loss -0.8529 
2024-12-15 07:35:36.305973: Pseudo dice [np.float32(0.9003), np.float32(0.8805)] 
2024-12-15 07:35:36.309497: Epoch time: 6.36 s 
2024-12-15 07:35:36.312550: Yayy! New best EMA pseudo Dice: 0.8873000144958496 
2024-12-15 07:35:36.923771:  
2024-12-15 07:35:36.928834: Epoch 41 
2024-12-15 07:35:36.931910: Current learning rate: 0.00622 
2024-12-15 07:35:43.296257: train_loss -0.8832 
2024-12-15 07:35:43.301819: val_loss -0.8526 
2024-12-15 07:35:43.304850: Pseudo dice [np.float32(0.9016), np.float32(0.8801)] 
2024-12-15 07:35:43.308375: Epoch time: 6.37 s 
2024-12-15 07:35:43.311399: Yayy! New best EMA pseudo Dice: 0.8876000046730042 
2024-12-15 07:35:43.877059:  
2024-12-15 07:35:43.881579: Epoch 42 
2024-12-15 07:35:43.885087: Current learning rate: 0.00612 
2024-12-15 07:35:50.261719: train_loss -0.8803 
2024-12-15 07:35:50.266739: val_loss -0.8497 
2024-12-15 07:35:50.269997: Pseudo dice [np.float32(0.8967), np.float32(0.8789)] 
2024-12-15 07:35:50.272537: Epoch time: 6.38 s 
2024-12-15 07:35:50.275609: Yayy! New best EMA pseudo Dice: 0.8877000212669373 
2024-12-15 07:35:50.845120:  
2024-12-15 07:35:50.850195: Epoch 43 
2024-12-15 07:35:50.853338: Current learning rate: 0.00603 
2024-12-15 07:35:57.238514: train_loss -0.8807 
2024-12-15 07:35:57.244707: val_loss -0.85 
2024-12-15 07:35:57.247746: Pseudo dice [np.float32(0.8982), np.float32(0.8791)] 
2024-12-15 07:35:57.250756: Epoch time: 6.39 s 
2024-12-15 07:35:57.253808: Yayy! New best EMA pseudo Dice: 0.8877999782562256 
2024-12-15 07:35:57.966955:  
2024-12-15 07:35:57.971035: Epoch 44 
2024-12-15 07:35:57.973572: Current learning rate: 0.00593 
2024-12-15 07:36:04.355865: train_loss -0.8816 
2024-12-15 07:36:04.360967: val_loss -0.8548 
2024-12-15 07:36:04.364541: Pseudo dice [np.float32(0.9014), np.float32(0.8832)] 
2024-12-15 07:36:04.367606: Epoch time: 6.39 s 
2024-12-15 07:36:04.369644: Yayy! New best EMA pseudo Dice: 0.8881999850273132 
2024-12-15 07:36:04.939862:  
2024-12-15 07:36:04.944399: Epoch 45 
2024-12-15 07:36:04.947922: Current learning rate: 0.00584 
2024-12-15 07:36:11.329703: train_loss -0.8828 
2024-12-15 07:36:11.335219: val_loss -0.8527 
2024-12-15 07:36:11.337724: Pseudo dice [np.float32(0.8993), np.float32(0.8807)] 
2024-12-15 07:36:11.341241: Epoch time: 6.39 s 
2024-12-15 07:36:11.343752: Yayy! New best EMA pseudo Dice: 0.8884000182151794 
2024-12-15 07:36:11.910702:  
2024-12-15 07:36:11.916293: Epoch 46 
2024-12-15 07:36:11.918841: Current learning rate: 0.00574 
2024-12-15 07:36:18.270257: train_loss -0.8832 
2024-12-15 07:36:18.276079: val_loss -0.8524 
2024-12-15 07:36:18.278625: Pseudo dice [np.float32(0.8992), np.float32(0.8828)] 
2024-12-15 07:36:18.281132: Epoch time: 6.36 s 
2024-12-15 07:36:18.284676: Yayy! New best EMA pseudo Dice: 0.8885999917984009 
2024-12-15 07:36:18.844605:  
2024-12-15 07:36:18.848617: Epoch 47 
2024-12-15 07:36:18.852634: Current learning rate: 0.00565 
2024-12-15 07:36:25.210013: train_loss -0.8824 
2024-12-15 07:36:25.215055: val_loss -0.8527 
2024-12-15 07:36:25.217616: Pseudo dice [np.float32(0.8999), np.float32(0.8799)] 
2024-12-15 07:36:25.220667: Epoch time: 6.37 s 
2024-12-15 07:36:25.224185: Yayy! New best EMA pseudo Dice: 0.8888000249862671 
2024-12-15 07:36:25.786793:  
2024-12-15 07:36:25.790171: Epoch 48 
2024-12-15 07:36:25.794184: Current learning rate: 0.00555 
2024-12-15 07:36:32.145818: train_loss -0.8851 
2024-12-15 07:36:32.150889: val_loss -0.8477 
2024-12-15 07:36:32.153983: Pseudo dice [np.float32(0.8968), np.float32(0.8776)] 
2024-12-15 07:36:32.157530: Epoch time: 6.36 s 
2024-12-15 07:36:32.692000:  
2024-12-15 07:36:32.697580: Epoch 49 
2024-12-15 07:36:32.700590: Current learning rate: 0.00546 
2024-12-15 07:36:39.058027: train_loss -0.8856 
2024-12-15 07:36:39.063658: val_loss -0.8448 
2024-12-15 07:36:39.066210: Pseudo dice [np.float32(0.8955), np.float32(0.8752)] 
2024-12-15 07:36:39.068758: Epoch time: 6.37 s 
2024-12-15 07:36:39.639038:  
2024-12-15 07:36:39.644604: Epoch 50 
2024-12-15 07:36:39.647156: Current learning rate: 0.00536 
2024-12-15 07:36:46.006282: train_loss -0.8855 
2024-12-15 07:36:46.011399: val_loss -0.8491 
2024-12-15 07:36:46.014455: Pseudo dice [np.float32(0.897), np.float32(0.8791)] 
2024-12-15 07:36:46.017497: Epoch time: 6.37 s 
2024-12-15 07:36:46.549678:  
2024-12-15 07:36:46.554214: Epoch 51 
2024-12-15 07:36:46.557295: Current learning rate: 0.00526 
2024-12-15 07:36:52.905226: train_loss -0.8869 
2024-12-15 07:36:52.910273: val_loss -0.8529 
2024-12-15 07:36:52.912801: Pseudo dice [np.float32(0.9006), np.float32(0.8802)] 
2024-12-15 07:36:52.916336: Epoch time: 6.36 s 
2024-12-15 07:36:53.588088:  
2024-12-15 07:36:53.592597: Epoch 52 
2024-12-15 07:36:53.595610: Current learning rate: 0.00517 
2024-12-15 07:36:59.949733: train_loss -0.8864 
2024-12-15 07:36:59.954788: val_loss -0.85 
2024-12-15 07:36:59.958305: Pseudo dice [np.float32(0.8984), np.float32(0.8784)] 
2024-12-15 07:36:59.960927: Epoch time: 6.36 s 
2024-12-15 07:37:00.494880:  
2024-12-15 07:37:00.498932: Epoch 53 
2024-12-15 07:37:00.503045: Current learning rate: 0.00507 
2024-12-15 07:37:06.854467: train_loss -0.8884 
2024-12-15 07:37:06.860059: val_loss -0.846 
2024-12-15 07:37:06.862580: Pseudo dice [np.float32(0.8953), np.float32(0.8768)] 
2024-12-15 07:37:06.866105: Epoch time: 6.36 s 
2024-12-15 07:37:07.394657:  
2024-12-15 07:37:07.399672: Epoch 54 
2024-12-15 07:37:07.404685: Current learning rate: 0.00497 
2024-12-15 07:37:13.746271: train_loss -0.8894 
2024-12-15 07:37:13.751331: val_loss -0.8472 
2024-12-15 07:37:13.754373: Pseudo dice [np.float32(0.8963), np.float32(0.8772)] 
2024-12-15 07:37:13.756914: Epoch time: 6.35 s 
2024-12-15 07:37:14.297875:  
2024-12-15 07:37:14.301906: Epoch 55 
2024-12-15 07:37:14.305439: Current learning rate: 0.00487 
2024-12-15 07:37:20.656584: train_loss -0.888 
2024-12-15 07:37:20.662724: val_loss -0.8517 
2024-12-15 07:37:20.665775: Pseudo dice [np.float32(0.9002), np.float32(0.8801)] 
2024-12-15 07:37:20.668312: Epoch time: 6.36 s 
2024-12-15 07:37:21.207363:  
2024-12-15 07:37:21.212377: Epoch 56 
2024-12-15 07:37:21.214884: Current learning rate: 0.00478 
2024-12-15 07:37:27.575546: train_loss -0.8888 
2024-12-15 07:37:27.580653: val_loss -0.8505 
2024-12-15 07:37:27.584224: Pseudo dice [np.float32(0.8999), np.float32(0.8797)] 
2024-12-15 07:37:27.587260: Epoch time: 6.37 s 
2024-12-15 07:37:28.118146:  
2024-12-15 07:37:28.122699: Epoch 57 
2024-12-15 07:37:28.125778: Current learning rate: 0.00468 
2024-12-15 07:37:34.490405: train_loss -0.8896 
2024-12-15 07:37:34.495002: val_loss -0.8484 
2024-12-15 07:37:34.499081: Pseudo dice [np.float32(0.8975), np.float32(0.8775)] 
2024-12-15 07:37:34.502153: Epoch time: 6.37 s 
2024-12-15 07:37:35.039595:  
2024-12-15 07:37:35.045180: Epoch 58 
2024-12-15 07:37:35.047746: Current learning rate: 0.00458 
2024-12-15 07:37:41.391054: train_loss -0.8903 
2024-12-15 07:37:41.396091: val_loss -0.8519 
2024-12-15 07:37:41.399603: Pseudo dice [np.float32(0.8993), np.float32(0.881)] 
2024-12-15 07:37:41.402122: Epoch time: 6.35 s 
2024-12-15 07:37:41.944788:  
2024-12-15 07:37:41.948836: Epoch 59 
2024-12-15 07:37:41.951368: Current learning rate: 0.00448 
2024-12-15 07:37:48.308424: train_loss -0.8899 
2024-12-15 07:37:48.313531: val_loss -0.8521 
2024-12-15 07:37:48.316164: Pseudo dice [np.float32(0.8987), np.float32(0.8823)] 
2024-12-15 07:37:48.319216: Epoch time: 6.36 s 
2024-12-15 07:37:49.007751:  
2024-12-15 07:37:49.012774: Epoch 60 
2024-12-15 07:37:49.016275: Current learning rate: 0.00438 
2024-12-15 07:37:55.360498: train_loss -0.8924 
2024-12-15 07:37:55.365456: val_loss -0.8491 
2024-12-15 07:37:55.369511: Pseudo dice [np.float32(0.8989), np.float32(0.8774)] 
2024-12-15 07:37:55.372543: Epoch time: 6.35 s 
2024-12-15 07:37:55.915388:  
2024-12-15 07:37:55.920407: Epoch 61 
2024-12-15 07:37:55.922917: Current learning rate: 0.00429 
2024-12-15 07:38:02.279717: train_loss -0.8911 
2024-12-15 07:38:02.283735: val_loss -0.8467 
2024-12-15 07:38:02.287245: Pseudo dice [np.float32(0.8956), np.float32(0.8786)] 
2024-12-15 07:38:02.290262: Epoch time: 6.36 s 
2024-12-15 07:38:02.835346:  
2024-12-15 07:38:02.839860: Epoch 62 
2024-12-15 07:38:02.842873: Current learning rate: 0.00419 
2024-12-15 07:38:09.182336: train_loss -0.8922 
2024-12-15 07:38:09.186872: val_loss -0.8474 
2024-12-15 07:38:09.190408: Pseudo dice [np.float32(0.8982), np.float32(0.8768)] 
2024-12-15 07:38:09.193432: Epoch time: 6.35 s 
2024-12-15 07:38:09.752733:  
2024-12-15 07:38:09.757294: Epoch 63 
2024-12-15 07:38:09.760854: Current learning rate: 0.00409 
2024-12-15 07:38:16.146291: train_loss -0.8934 
2024-12-15 07:38:16.151361: val_loss -0.8483 
2024-12-15 07:38:16.154419: Pseudo dice [np.float32(0.8978), np.float32(0.8787)] 
2024-12-15 07:38:16.157189: Epoch time: 6.39 s 
2024-12-15 07:38:16.703838:  
2024-12-15 07:38:16.709375: Epoch 64 
2024-12-15 07:38:16.711883: Current learning rate: 0.00399 
2024-12-15 07:38:23.086080: train_loss -0.893 
2024-12-15 07:38:23.091140: val_loss -0.8455 
2024-12-15 07:38:23.094744: Pseudo dice [np.float32(0.8961), np.float32(0.8762)] 
2024-12-15 07:38:23.098324: Epoch time: 6.38 s 
2024-12-15 07:38:23.651577:  
2024-12-15 07:38:23.656589: Epoch 65 
2024-12-15 07:38:23.659095: Current learning rate: 0.00389 
2024-12-15 07:38:30.041752: train_loss -0.8926 
2024-12-15 07:38:30.047420: val_loss -0.8448 
2024-12-15 07:38:30.050547: Pseudo dice [np.float32(0.8944), np.float32(0.876)] 
2024-12-15 07:38:30.054562: Epoch time: 6.39 s 
2024-12-15 07:38:30.599410:  
2024-12-15 07:38:30.604480: Epoch 66 
2024-12-15 07:38:30.606985: Current learning rate: 0.00379 
2024-12-15 07:38:36.979036: train_loss -0.8945 
2024-12-15 07:38:36.985396: val_loss -0.851 
2024-12-15 07:38:36.988480: Pseudo dice [np.float32(0.8981), np.float32(0.8806)] 
2024-12-15 07:38:36.992103: Epoch time: 6.38 s 
2024-12-15 07:38:37.539146:  
2024-12-15 07:38:37.544664: Epoch 67 
2024-12-15 07:38:37.547172: Current learning rate: 0.00369 
2024-12-15 07:38:43.921292: train_loss -0.8948 
2024-12-15 07:38:43.926314: val_loss -0.8503 
2024-12-15 07:38:43.929818: Pseudo dice [np.float32(0.899), np.float32(0.8796)] 
2024-12-15 07:38:43.932824: Epoch time: 6.38 s 
2024-12-15 07:38:44.637499:  
2024-12-15 07:38:44.641575: Epoch 68 
2024-12-15 07:38:44.646149: Current learning rate: 0.00359 
2024-12-15 07:38:51.015953: train_loss -0.8937 
2024-12-15 07:38:51.021478: val_loss -0.8464 
2024-12-15 07:38:51.023991: Pseudo dice [np.float32(0.8973), np.float32(0.8757)] 
2024-12-15 07:38:51.026497: Epoch time: 6.38 s 
2024-12-15 07:38:51.581084:  
2024-12-15 07:38:51.585608: Epoch 69 
2024-12-15 07:38:51.589613: Current learning rate: 0.00349 
2024-12-15 07:38:57.969133: train_loss -0.8954 
2024-12-15 07:38:57.974183: val_loss -0.8507 
2024-12-15 07:38:57.977244: Pseudo dice [np.float32(0.9004), np.float32(0.8784)] 
2024-12-15 07:38:57.979796: Epoch time: 6.39 s 
2024-12-15 07:38:58.531768:  
2024-12-15 07:38:58.536295: Epoch 70 
2024-12-15 07:38:58.538802: Current learning rate: 0.00338 
2024-12-15 07:39:04.899718: train_loss -0.897 
2024-12-15 07:39:04.905245: val_loss -0.8516 
2024-12-15 07:39:04.907290: Pseudo dice [np.float32(0.8999), np.float32(0.8803)] 
2024-12-15 07:39:04.910952: Epoch time: 6.37 s 
2024-12-15 07:39:05.466468:  
2024-12-15 07:39:05.471522: Epoch 71 
2024-12-15 07:39:05.474591: Current learning rate: 0.00328 
2024-12-15 07:39:11.863517: train_loss -0.897 
2024-12-15 07:39:11.868663: val_loss -0.8459 
2024-12-15 07:39:11.871722: Pseudo dice [np.float32(0.8977), np.float32(0.8763)] 
2024-12-15 07:39:11.875255: Epoch time: 6.4 s 
2024-12-15 07:39:12.429140:  
2024-12-15 07:39:12.433153: Epoch 72 
2024-12-15 07:39:12.436666: Current learning rate: 0.00318 
2024-12-15 07:39:18.797195: train_loss -0.8979 
2024-12-15 07:39:18.802493: val_loss -0.848 
2024-12-15 07:39:18.804999: Pseudo dice [np.float32(0.897), np.float32(0.8784)] 
2024-12-15 07:39:18.808573: Epoch time: 6.37 s 
2024-12-15 07:39:19.364125:  
2024-12-15 07:39:19.369179: Epoch 73 
2024-12-15 07:39:19.372239: Current learning rate: 0.00308 
2024-12-15 07:39:25.737720: train_loss -0.8968 
2024-12-15 07:39:25.744280: val_loss -0.8525 
2024-12-15 07:39:25.747300: Pseudo dice [np.float32(0.9015), np.float32(0.88)] 
2024-12-15 07:39:25.749807: Epoch time: 6.37 s 
2024-12-15 07:39:26.299945:  
2024-12-15 07:39:26.305510: Epoch 74 
2024-12-15 07:39:26.308573: Current learning rate: 0.00297 
2024-12-15 07:39:32.664615: train_loss -0.899 
2024-12-15 07:39:32.669631: val_loss -0.8493 
2024-12-15 07:39:32.672665: Pseudo dice [np.float32(0.9008), np.float32(0.8774)] 
2024-12-15 07:39:32.675173: Epoch time: 6.36 s 
2024-12-15 07:39:33.376277:  
2024-12-15 07:39:33.381841: Epoch 75 
2024-12-15 07:39:33.384931: Current learning rate: 0.00287 
2024-12-15 07:39:39.727752: train_loss -0.8971 
2024-12-15 07:39:39.733391: val_loss -0.8457 
2024-12-15 07:39:39.735916: Pseudo dice [np.float32(0.8964), np.float32(0.8758)] 
2024-12-15 07:39:39.738452: Epoch time: 6.35 s 
2024-12-15 07:39:40.296933:  
2024-12-15 07:39:40.300982: Epoch 76 
2024-12-15 07:39:40.303533: Current learning rate: 0.00277 
2024-12-15 07:39:46.639218: train_loss -0.9004 
2024-12-15 07:39:46.644875: val_loss -0.8474 
2024-12-15 07:39:46.648492: Pseudo dice [np.float32(0.8984), np.float32(0.8769)] 
2024-12-15 07:39:46.651021: Epoch time: 6.34 s 
2024-12-15 07:39:47.200698:  
2024-12-15 07:39:47.205210: Epoch 77 
2024-12-15 07:39:47.208219: Current learning rate: 0.00266 
2024-12-15 07:39:53.548817: train_loss -0.8984 
2024-12-15 07:39:53.553695: val_loss -0.8444 
2024-12-15 07:39:53.556159: Pseudo dice [np.float32(0.8968), np.float32(0.875)] 
2024-12-15 07:39:53.559672: Epoch time: 6.35 s 
2024-12-15 07:39:54.127050:  
2024-12-15 07:39:54.131083: Epoch 78 
2024-12-15 07:39:54.134634: Current learning rate: 0.00256 
2024-12-15 07:40:00.480475: train_loss -0.8988 
2024-12-15 07:40:00.487982: val_loss -0.8452 
2024-12-15 07:40:00.491021: Pseudo dice [np.float32(0.8959), np.float32(0.8752)] 
2024-12-15 07:40:00.493556: Epoch time: 6.35 s 
2024-12-15 07:40:01.055313:  
2024-12-15 07:40:01.060328: Epoch 79 
2024-12-15 07:40:01.062836: Current learning rate: 0.00245 
2024-12-15 07:40:07.421629: train_loss -0.9003 
2024-12-15 07:40:07.426198: val_loss -0.8459 
2024-12-15 07:40:07.429273: Pseudo dice [np.float32(0.8971), np.float32(0.8755)] 
2024-12-15 07:40:07.432303: Epoch time: 6.37 s 
2024-12-15 07:40:07.985806:  
2024-12-15 07:40:07.990860: Epoch 80 
2024-12-15 07:40:07.993934: Current learning rate: 0.00235 
2024-12-15 07:40:14.343822: train_loss -0.8989 
2024-12-15 07:40:14.348925: val_loss -0.849 
2024-12-15 07:40:14.352000: Pseudo dice [np.float32(0.8985), np.float32(0.8785)] 
2024-12-15 07:40:14.354535: Epoch time: 6.36 s 
2024-12-15 07:40:14.916272:  
2024-12-15 07:40:14.920791: Epoch 81 
2024-12-15 07:40:14.924307: Current learning rate: 0.00224 
2024-12-15 07:40:21.293130: train_loss -0.9005 
2024-12-15 07:40:21.298246: val_loss -0.8463 
2024-12-15 07:40:21.301301: Pseudo dice [np.float32(0.8974), np.float32(0.8766)] 
2024-12-15 07:40:21.304348: Epoch time: 6.38 s 
2024-12-15 07:40:21.866636:  
2024-12-15 07:40:21.870678: Epoch 82 
2024-12-15 07:40:21.874288: Current learning rate: 0.00214 
2024-12-15 07:40:28.254253: train_loss -0.8995 
2024-12-15 07:40:28.260402: val_loss -0.8437 
2024-12-15 07:40:28.263443: Pseudo dice [np.float32(0.8958), np.float32(0.8739)] 
2024-12-15 07:40:28.266516: Epoch time: 6.39 s 
2024-12-15 07:40:28.945139:  
2024-12-15 07:40:28.951153: Epoch 83 
2024-12-15 07:40:28.954165: Current learning rate: 0.00203 
2024-12-15 07:40:35.313692: train_loss -0.9011 
2024-12-15 07:40:35.319261: val_loss -0.8474 
2024-12-15 07:40:35.322314: Pseudo dice [np.float32(0.8981), np.float32(0.8779)] 
2024-12-15 07:40:35.324356: Epoch time: 6.37 s 
2024-12-15 07:40:35.851728:  
2024-12-15 07:40:35.856743: Epoch 84 
2024-12-15 07:40:35.859752: Current learning rate: 0.00192 
2024-12-15 07:40:42.210196: train_loss -0.9025 
2024-12-15 07:40:42.215977: val_loss -0.8442 
2024-12-15 07:40:42.219497: Pseudo dice [np.float32(0.8966), np.float32(0.8745)] 
2024-12-15 07:40:42.222590: Epoch time: 6.36 s 
2024-12-15 07:40:42.750616:  
2024-12-15 07:40:42.756143: Epoch 85 
2024-12-15 07:40:42.758652: Current learning rate: 0.00181 
2024-12-15 07:40:49.120935: train_loss -0.9017 
2024-12-15 07:40:49.125993: val_loss -0.8475 
2024-12-15 07:40:49.129527: Pseudo dice [np.float32(0.8992), np.float32(0.8772)] 
2024-12-15 07:40:49.132564: Epoch time: 6.37 s 
2024-12-15 07:40:49.657579:  
2024-12-15 07:40:49.662094: Epoch 86 
2024-12-15 07:40:49.665107: Current learning rate: 0.0017 
2024-12-15 07:40:56.031990: train_loss -0.9029 
2024-12-15 07:40:56.039073: val_loss -0.8456 
2024-12-15 07:40:56.043603: Pseudo dice [np.float32(0.8973), np.float32(0.8765)] 
2024-12-15 07:40:56.045178: Epoch time: 6.37 s 
2024-12-15 07:40:56.576139:  
2024-12-15 07:40:56.581147: Epoch 87 
2024-12-15 07:40:56.584154: Current learning rate: 0.00159 
2024-12-15 07:41:02.956640: train_loss -0.9025 
2024-12-15 07:41:02.963920: val_loss -0.8472 
2024-12-15 07:41:02.969015: Pseudo dice [np.float32(0.8976), np.float32(0.8777)] 
2024-12-15 07:41:02.971523: Epoch time: 6.38 s 
2024-12-15 07:41:03.493577:  
2024-12-15 07:41:03.498630: Epoch 88 
2024-12-15 07:41:03.501709: Current learning rate: 0.00148 
2024-12-15 07:41:09.871699: train_loss -0.9039 
2024-12-15 07:41:09.877325: val_loss -0.8475 
2024-12-15 07:41:09.880367: Pseudo dice [np.float32(0.8979), np.float32(0.8781)] 
2024-12-15 07:41:09.882900: Epoch time: 6.38 s 
2024-12-15 07:41:10.408347:  
2024-12-15 07:41:10.412856: Epoch 89 
2024-12-15 07:41:10.415864: Current learning rate: 0.00137 
2024-12-15 07:41:16.788691: train_loss -0.904 
2024-12-15 07:41:16.793773: val_loss -0.8472 
2024-12-15 07:41:16.796310: Pseudo dice [np.float32(0.8972), np.float32(0.8778)] 
2024-12-15 07:41:16.799849: Epoch time: 6.38 s 
2024-12-15 07:41:17.326324:  
2024-12-15 07:41:17.331340: Epoch 90 
2024-12-15 07:41:17.333847: Current learning rate: 0.00126 
2024-12-15 07:41:23.691001: train_loss -0.9041 
2024-12-15 07:41:23.696578: val_loss -0.8491 
2024-12-15 07:41:23.699672: Pseudo dice [np.float32(0.8988), np.float32(0.8781)] 
2024-12-15 07:41:23.702764: Epoch time: 6.37 s 
2024-12-15 07:41:24.377379:  
2024-12-15 07:41:24.381902: Epoch 91 
2024-12-15 07:41:24.385915: Current learning rate: 0.00115 
2024-12-15 07:41:30.748099: train_loss -0.9044 
2024-12-15 07:41:30.753716: val_loss -0.8497 
2024-12-15 07:41:30.756226: Pseudo dice [np.float32(0.8999), np.float32(0.8789)] 
2024-12-15 07:41:30.759736: Epoch time: 6.37 s 
2024-12-15 07:41:31.283723:  
2024-12-15 07:41:31.288762: Epoch 92 
2024-12-15 07:41:31.291810: Current learning rate: 0.00103 
2024-12-15 07:41:37.633807: train_loss -0.9046 
2024-12-15 07:41:37.638127: val_loss -0.8425 
2024-12-15 07:41:37.641673: Pseudo dice [np.float32(0.8956), np.float32(0.8731)] 
2024-12-15 07:41:37.644219: Epoch time: 6.35 s 
2024-12-15 07:41:38.171244:  
2024-12-15 07:41:38.176258: Epoch 93 
2024-12-15 07:41:38.178766: Current learning rate: 0.00091 
2024-12-15 07:41:44.519443: train_loss -0.9058 
2024-12-15 07:41:44.524540: val_loss -0.8491 
2024-12-15 07:41:44.527586: Pseudo dice [np.float32(0.9005), np.float32(0.879)] 
2024-12-15 07:41:44.530648: Epoch time: 6.35 s 
2024-12-15 07:41:45.051540:  
2024-12-15 07:41:45.055574: Epoch 94 
2024-12-15 07:41:45.058668: Current learning rate: 0.00079 
2024-12-15 07:41:51.405781: train_loss -0.9045 
2024-12-15 07:41:51.411417: val_loss -0.8461 
2024-12-15 07:41:51.414468: Pseudo dice [np.float32(0.8979), np.float32(0.8752)] 
2024-12-15 07:41:51.416992: Epoch time: 6.36 s 
2024-12-15 07:41:51.982571:  
2024-12-15 07:41:51.987624: Epoch 95 
2024-12-15 07:41:51.990131: Current learning rate: 0.00067 
2024-12-15 07:41:58.326588: train_loss -0.906 
2024-12-15 07:41:58.332171: val_loss -0.8462 
2024-12-15 07:41:58.335286: Pseudo dice [np.float32(0.8968), np.float32(0.8772)] 
2024-12-15 07:41:58.337807: Epoch time: 6.34 s 
2024-12-15 07:41:58.866228:  
2024-12-15 07:41:58.870738: Epoch 96 
2024-12-15 07:41:58.873749: Current learning rate: 0.00055 
2024-12-15 07:42:05.208749: train_loss -0.9072 
2024-12-15 07:42:05.215343: val_loss -0.8463 
2024-12-15 07:42:05.217941: Pseudo dice [np.float32(0.8966), np.float32(0.877)] 
2024-12-15 07:42:05.221502: Epoch time: 6.34 s 
2024-12-15 07:42:05.764524:  
2024-12-15 07:42:05.768538: Epoch 97 
2024-12-15 07:42:05.772552: Current learning rate: 0.00043 
2024-12-15 07:42:12.120714: train_loss -0.9064 
2024-12-15 07:42:12.126287: val_loss -0.8432 
2024-12-15 07:42:12.129311: Pseudo dice [np.float32(0.8958), np.float32(0.8752)] 
2024-12-15 07:42:12.131916: Epoch time: 6.36 s 
2024-12-15 07:42:12.665010:  
2024-12-15 07:42:12.669058: Epoch 98 
2024-12-15 07:42:12.673129: Current learning rate: 0.0003 
2024-12-15 07:42:19.033806: train_loss -0.9062 
2024-12-15 07:42:19.038842: val_loss -0.8431 
2024-12-15 07:42:19.042362: Pseudo dice [np.float32(0.8962), np.float32(0.8753)] 
2024-12-15 07:42:19.044895: Epoch time: 6.37 s 
2024-12-15 07:42:19.581459:  
2024-12-15 07:42:19.584487: Epoch 99 
2024-12-15 07:42:19.587034: Current learning rate: 0.00016 
2024-12-15 07:42:25.961979: train_loss -0.9057 
2024-12-15 07:42:25.967025: val_loss -0.8493 
2024-12-15 07:42:25.970118: Pseudo dice [np.float32(0.8995), np.float32(0.8786)] 
2024-12-15 07:42:25.973159: Epoch time: 6.38 s 
2024-12-15 07:42:26.731986: Training done. 
2024-12-15 07:42:26.767987: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-15 07:42:26.774987: The split file contains 5 splits. 
2024-12-15 07:42:26.780987: Desired fold for training: 0 
2024-12-15 07:42:26.785988: This split has 208 training and 52 validation cases. 
2024-12-15 07:42:26.791987: predicting hippocampus_017 
2024-12-15 07:42:26.796988: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-15 07:42:26.895985: predicting hippocampus_019 
2024-12-15 07:42:26.901986: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-15 07:42:26.943986: predicting hippocampus_033 
2024-12-15 07:42:26.949986: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-15 07:42:26.975988: predicting hippocampus_035 
2024-12-15 07:42:26.980987: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-15 07:42:27.006987: predicting hippocampus_037 
2024-12-15 07:42:27.011988: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-15 07:42:27.038986: predicting hippocampus_049 
2024-12-15 07:42:27.044987: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-15 07:42:27.071987: predicting hippocampus_052 
2024-12-15 07:42:27.077987: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-15 07:42:27.103987: predicting hippocampus_065 
2024-12-15 07:42:27.109987: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-15 07:42:27.138987: predicting hippocampus_083 
2024-12-15 07:42:27.144987: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-15 07:42:27.172986: predicting hippocampus_088 
2024-12-15 07:42:27.178986: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-15 07:42:30.523875: predicting hippocampus_090 
2024-12-15 07:42:30.529088: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-15 07:42:30.572088: predicting hippocampus_092 
2024-12-15 07:42:30.579088: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-15 07:42:30.627089: predicting hippocampus_095 
2024-12-15 07:42:30.634087: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-15 07:42:30.682087: predicting hippocampus_107 
2024-12-15 07:42:30.688086: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-15 07:42:30.729087: predicting hippocampus_108 
2024-12-15 07:42:30.736088: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-15 07:42:30.778086: predicting hippocampus_123 
2024-12-15 07:42:30.785086: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-15 07:42:30.823087: predicting hippocampus_125 
2024-12-15 07:42:30.841087: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-15 07:42:30.904086: predicting hippocampus_157 
2024-12-15 07:42:30.912086: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-15 07:42:30.948087: predicting hippocampus_164 
2024-12-15 07:42:30.956086: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-15 07:42:31.053086: predicting hippocampus_169 
2024-12-15 07:42:31.060086: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-15 07:42:31.090086: predicting hippocampus_175 
2024-12-15 07:42:31.096086: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-15 07:42:31.122086: predicting hippocampus_185 
2024-12-15 07:42:31.129086: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-15 07:42:31.155086: predicting hippocampus_190 
2024-12-15 07:42:31.162086: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-15 07:42:31.189086: predicting hippocampus_194 
2024-12-15 07:42:31.194087: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-15 07:42:31.221086: predicting hippocampus_204 
2024-12-15 07:42:31.227086: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-15 07:42:31.258088: predicting hippocampus_205 
2024-12-15 07:42:31.263086: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-15 07:42:31.291086: predicting hippocampus_210 
2024-12-15 07:42:31.297086: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-15 07:42:31.323086: predicting hippocampus_217 
2024-12-15 07:42:31.328086: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-15 07:42:31.361087: predicting hippocampus_219 
2024-12-15 07:42:31.368086: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-15 07:42:31.395086: predicting hippocampus_229 
2024-12-15 07:42:31.401088: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-15 07:42:31.432086: predicting hippocampus_244 
2024-12-15 07:42:31.439086: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-15 07:42:31.469088: predicting hippocampus_261 
2024-12-15 07:42:31.476088: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-15 07:42:31.524088: predicting hippocampus_264 
2024-12-15 07:42:31.530086: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-15 07:42:31.557086: predicting hippocampus_277 
2024-12-15 07:42:31.563086: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-15 07:42:31.606086: predicting hippocampus_280 
2024-12-15 07:42:31.613087: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-15 07:42:31.639086: predicting hippocampus_286 
2024-12-15 07:42:31.646086: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-15 07:42:31.689086: predicting hippocampus_288 
2024-12-15 07:42:31.695088: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-15 07:42:31.739086: predicting hippocampus_289 
2024-12-15 07:42:31.745086: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-15 07:42:31.772086: predicting hippocampus_296 
2024-12-15 07:42:31.778086: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-15 07:42:31.806086: predicting hippocampus_305 
2024-12-15 07:42:31.812086: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-15 07:42:31.839086: predicting hippocampus_308 
2024-12-15 07:42:31.845086: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-15 07:42:31.872086: predicting hippocampus_317 
2024-12-15 07:42:31.878086: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-15 07:42:31.905086: predicting hippocampus_327 
2024-12-15 07:42:31.911086: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-15 07:42:31.937086: predicting hippocampus_330 
2024-12-15 07:42:31.943086: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-15 07:42:31.974086: predicting hippocampus_332 
2024-12-15 07:42:31.980086: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-15 07:42:32.009086: predicting hippocampus_338 
2024-12-15 07:42:32.015086: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-15 07:42:32.056086: predicting hippocampus_349 
2024-12-15 07:42:32.062086: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-15 07:42:32.088086: predicting hippocampus_350 
2024-12-15 07:42:32.094086: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-15 07:42:32.120086: predicting hippocampus_356 
2024-12-15 07:42:32.125087: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-15 07:42:32.153086: predicting hippocampus_358 
2024-12-15 07:42:32.160086: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-15 07:42:32.189086: predicting hippocampus_374 
2024-12-15 07:42:32.195086: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-15 07:42:32.222086: predicting hippocampus_394 
2024-12-15 07:42:32.228086: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-15 07:42:36.017128: Validation complete 
2024-12-15 07:42:36.022128: Mean Validation Dice:  0.8923029917615876 
