2024-12-13 07:27:46.313673: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 1 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-13 07:27:46.317673: self.oversample_foreground_percent 1.0 
2024-12-13 07:27:46.320673: do_dummy_2d_data_aug: False 
2024-12-13 07:27:46.324674: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-13 07:27:46.330674: The split file contains 5 splits. 
2024-12-13 07:27:46.333674: Desired fold for training: 0 
2024-12-13 07:27:46.335674: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-13 07:27:52.494169: unpacking dataset... 
2024-12-13 07:27:52.838453: unpacking done... 
2024-12-13 07:27:53.823663:  
2024-12-13 07:27:53.828177: Epoch 0 
2024-12-13 07:27:53.831193: Current learning rate: 0.01 
2024-12-13 07:28:01.103807: train_loss -0.3436 
2024-12-13 07:28:01.110404: val_loss -0.7637 
2024-12-13 07:28:01.113433: Pseudo dice [np.float32(0.8307), np.float32(0.8226)] 
2024-12-13 07:28:01.115978: Epoch time: 7.28 s 
2024-12-13 07:28:01.119036: Yayy! New best EMA pseudo Dice: 0.82669997215271 
2024-12-13 07:28:01.636936:  
2024-12-13 07:28:01.640466: Epoch 1 
2024-12-13 07:28:01.643523: Current learning rate: 0.00991 
2024-12-13 07:28:08.013571: train_loss -0.7699 
2024-12-13 07:28:08.018623: val_loss -0.8093 
2024-12-13 07:28:08.022659: Pseudo dice [np.float32(0.8633), np.float32(0.8541)] 
2024-12-13 07:28:08.025688: Epoch time: 6.38 s 
2024-12-13 07:28:08.028230: Yayy! New best EMA pseudo Dice: 0.8299000263214111 
2024-12-13 07:28:08.611594:  
2024-12-13 07:28:08.616703: Epoch 2 
2024-12-13 07:28:08.620251: Current learning rate: 0.00982 
2024-12-13 07:28:14.990618: train_loss -0.8029 
2024-12-13 07:28:14.995650: val_loss -0.8142 
2024-12-13 07:28:14.999190: Pseudo dice [np.float32(0.8654), np.float32(0.8551)] 
2024-12-13 07:28:15.002257: Epoch time: 6.38 s 
2024-12-13 07:28:15.004803: Yayy! New best EMA pseudo Dice: 0.8328999876976013 
2024-12-13 07:28:15.617691:  
2024-12-13 07:28:15.623307: Epoch 3 
2024-12-13 07:28:15.625846: Current learning rate: 0.00973 
2024-12-13 07:28:22.011241: train_loss -0.8144 
2024-12-13 07:28:22.016284: val_loss -0.8285 
2024-12-13 07:28:22.019313: Pseudo dice [np.float32(0.8791), np.float32(0.8632)] 
2024-12-13 07:28:22.022834: Epoch time: 6.39 s 
2024-12-13 07:28:22.025858: Yayy! New best EMA pseudo Dice: 0.8367000222206116 
2024-12-13 07:28:22.611170:  
2024-12-13 07:28:22.616201: Epoch 4 
2024-12-13 07:28:22.619807: Current learning rate: 0.00964 
2024-12-13 07:28:28.981518: train_loss -0.8224 
2024-12-13 07:28:28.986683: val_loss -0.8246 
2024-12-13 07:28:28.989714: Pseudo dice [np.float32(0.8778), np.float32(0.8635)] 
2024-12-13 07:28:28.992761: Epoch time: 6.37 s 
2024-12-13 07:28:28.995287: Yayy! New best EMA pseudo Dice: 0.8400999903678894 
2024-12-13 07:28:29.715279:  
2024-12-13 07:28:29.720288: Epoch 5 
2024-12-13 07:28:29.723800: Current learning rate: 0.00955 
2024-12-13 07:28:36.071701: train_loss -0.8283 
2024-12-13 07:28:36.079828: val_loss -0.8329 
2024-12-13 07:28:36.082893: Pseudo dice [np.float32(0.8834), np.float32(0.865)] 
2024-12-13 07:28:36.085403: Epoch time: 6.36 s 
2024-12-13 07:28:36.088913: Yayy! New best EMA pseudo Dice: 0.843500018119812 
2024-12-13 07:28:36.668618:  
2024-12-13 07:28:36.672158: Epoch 6 
2024-12-13 07:28:36.675267: Current learning rate: 0.00946 
2024-12-13 07:28:43.040065: train_loss -0.8327 
2024-12-13 07:28:43.045654: val_loss -0.8366 
2024-12-13 07:28:43.048189: Pseudo dice [np.float32(0.8859), np.float32(0.8686)] 
2024-12-13 07:28:43.052232: Epoch time: 6.37 s 
2024-12-13 07:28:43.054741: Yayy! New best EMA pseudo Dice: 0.8468999862670898 
2024-12-13 07:28:43.641673:  
2024-12-13 07:28:43.646702: Epoch 7 
2024-12-13 07:28:43.648816: Current learning rate: 0.00937 
2024-12-13 07:28:50.013194: train_loss -0.8358 
2024-12-13 07:28:50.018798: val_loss -0.8397 
2024-12-13 07:28:50.021848: Pseudo dice [np.float32(0.8874), np.float32(0.8702)] 
2024-12-13 07:28:50.024380: Epoch time: 6.37 s 
2024-12-13 07:28:50.027926: Yayy! New best EMA pseudo Dice: 0.8500999808311462 
2024-12-13 07:28:50.632027:  
2024-12-13 07:28:50.637062: Epoch 8 
2024-12-13 07:28:50.640092: Current learning rate: 0.00928 
2024-12-13 07:28:57.007331: train_loss -0.8393 
2024-12-13 07:28:57.012938: val_loss -0.8422 
2024-12-13 07:28:57.015977: Pseudo dice [np.float32(0.8898), np.float32(0.8736)] 
2024-12-13 07:28:57.018500: Epoch time: 6.38 s 
2024-12-13 07:28:57.022027: Yayy! New best EMA pseudo Dice: 0.8532999753952026 
2024-12-13 07:28:57.623945:  
2024-12-13 07:28:57.629516: Epoch 9 
2024-12-13 07:28:57.632584: Current learning rate: 0.00919 
2024-12-13 07:29:03.991924: train_loss -0.841 
2024-12-13 07:29:03.996989: val_loss -0.8411 
2024-12-13 07:29:04.000013: Pseudo dice [np.float32(0.8889), np.float32(0.8715)] 
2024-12-13 07:29:04.003049: Epoch time: 6.37 s 
2024-12-13 07:29:04.006078: Yayy! New best EMA pseudo Dice: 0.8560000061988831 
2024-12-13 07:29:04.582202:  
2024-12-13 07:29:04.587761: Epoch 10 
2024-12-13 07:29:04.590304: Current learning rate: 0.0091 
2024-12-13 07:29:10.970792: train_loss -0.8441 
2024-12-13 07:29:10.976402: val_loss -0.8439 
2024-12-13 07:29:10.979431: Pseudo dice [np.float32(0.8917), np.float32(0.8717)] 
2024-12-13 07:29:10.982468: Epoch time: 6.39 s 
2024-12-13 07:29:10.985521: Yayy! New best EMA pseudo Dice: 0.8585000038146973 
2024-12-13 07:29:11.576784:  
2024-12-13 07:29:11.580814: Epoch 11 
2024-12-13 07:29:11.584343: Current learning rate: 0.009 
2024-12-13 07:29:17.947638: train_loss -0.8485 
2024-12-13 07:29:17.953193: val_loss -0.8484 
2024-12-13 07:29:17.956774: Pseudo dice [np.float32(0.8937), np.float32(0.8774)] 
2024-12-13 07:29:17.958816: Epoch time: 6.37 s 
2024-12-13 07:29:17.962338: Yayy! New best EMA pseudo Dice: 0.8611999750137329 
2024-12-13 07:29:18.545848:  
2024-12-13 07:29:18.549906: Epoch 12 
2024-12-13 07:29:18.552434: Current learning rate: 0.00891 
2024-12-13 07:29:24.918225: train_loss -0.8477 
2024-12-13 07:29:24.923778: val_loss -0.8484 
2024-12-13 07:29:24.927366: Pseudo dice [np.float32(0.8934), np.float32(0.8797)] 
2024-12-13 07:29:24.930406: Epoch time: 6.37 s 
2024-12-13 07:29:24.932955: Yayy! New best EMA pseudo Dice: 0.8637999892234802 
2024-12-13 07:29:25.662585:  
2024-12-13 07:29:25.668632: Epoch 13 
2024-12-13 07:29:25.671685: Current learning rate: 0.00882 
2024-12-13 07:29:32.012519: train_loss -0.8499 
2024-12-13 07:29:32.018065: val_loss -0.8467 
2024-12-13 07:29:32.020643: Pseudo dice [np.float32(0.8925), np.float32(0.8761)] 
2024-12-13 07:29:32.023150: Epoch time: 6.35 s 
2024-12-13 07:29:32.025687: Yayy! New best EMA pseudo Dice: 0.8658000230789185 
2024-12-13 07:29:32.626444:  
2024-12-13 07:29:32.632009: Epoch 14 
2024-12-13 07:29:32.635047: Current learning rate: 0.00873 
2024-12-13 07:29:39.001236: train_loss -0.852 
2024-12-13 07:29:39.008296: val_loss -0.8506 
2024-12-13 07:29:39.011318: Pseudo dice [np.float32(0.8968), np.float32(0.8799)] 
2024-12-13 07:29:39.014425: Epoch time: 6.37 s 
2024-12-13 07:29:39.017987: Yayy! New best EMA pseudo Dice: 0.8680999875068665 
2024-12-13 07:29:39.619437:  
2024-12-13 07:29:39.623485: Epoch 15 
2024-12-13 07:29:39.626023: Current learning rate: 0.00864 
2024-12-13 07:29:46.006925: train_loss -0.8537 
2024-12-13 07:29:46.011966: val_loss -0.8484 
2024-12-13 07:29:46.015995: Pseudo dice [np.float32(0.893), np.float32(0.8778)] 
2024-12-13 07:29:46.018523: Epoch time: 6.39 s 
2024-12-13 07:29:46.022051: Yayy! New best EMA pseudo Dice: 0.8697999715805054 
2024-12-13 07:29:46.626670:  
2024-12-13 07:29:46.632245: Epoch 16 
2024-12-13 07:29:46.634780: Current learning rate: 0.00855 
2024-12-13 07:29:52.999078: train_loss -0.8527 
2024-12-13 07:29:53.004646: val_loss -0.8438 
2024-12-13 07:29:53.007677: Pseudo dice [np.float32(0.8911), np.float32(0.8741)] 
2024-12-13 07:29:53.010779: Epoch time: 6.37 s 
2024-12-13 07:29:53.013285: Yayy! New best EMA pseudo Dice: 0.8711000084877014 
2024-12-13 07:29:53.617484:  
2024-12-13 07:29:53.623034: Epoch 17 
2024-12-13 07:29:53.626080: Current learning rate: 0.00846 
2024-12-13 07:30:00.015350: train_loss -0.8524 
2024-12-13 07:30:00.020927: val_loss -0.8508 
2024-12-13 07:30:00.024026: Pseudo dice [np.float32(0.8955), np.float32(0.8784)] 
2024-12-13 07:30:00.027092: Epoch time: 6.4 s 
2024-12-13 07:30:00.030129: Yayy! New best EMA pseudo Dice: 0.8726999759674072 
2024-12-13 07:30:00.637586:  
2024-12-13 07:30:00.642629: Epoch 18 
2024-12-13 07:30:00.646181: Current learning rate: 0.00836 
2024-12-13 07:30:07.000308: train_loss -0.8563 
2024-12-13 07:30:07.005898: val_loss -0.8493 
2024-12-13 07:30:07.009978: Pseudo dice [np.float32(0.8934), np.float32(0.8788)] 
2024-12-13 07:30:07.013020: Epoch time: 6.36 s 
2024-12-13 07:30:07.016052: Yayy! New best EMA pseudo Dice: 0.8740000128746033 
2024-12-13 07:30:07.617987:  
2024-12-13 07:30:07.623022: Epoch 19 
2024-12-13 07:30:07.626558: Current learning rate: 0.00827 
2024-12-13 07:30:13.994261: train_loss -0.8579 
2024-12-13 07:30:13.998319: val_loss -0.8512 
2024-12-13 07:30:14.001887: Pseudo dice [np.float32(0.8944), np.float32(0.8814)] 
2024-12-13 07:30:14.004435: Epoch time: 6.38 s 
2024-12-13 07:30:14.007967: Yayy! New best EMA pseudo Dice: 0.8754000067710876 
2024-12-13 07:30:14.753887:  
2024-12-13 07:30:14.759434: Epoch 20 
2024-12-13 07:30:14.762458: Current learning rate: 0.00818 
2024-12-13 07:30:21.111646: train_loss -0.8568 
2024-12-13 07:30:21.116801: val_loss -0.8497 
2024-12-13 07:30:21.120852: Pseudo dice [np.float32(0.8958), np.float32(0.878)] 
2024-12-13 07:30:21.123890: Epoch time: 6.36 s 
2024-12-13 07:30:21.126415: Yayy! New best EMA pseudo Dice: 0.8765000104904175 
2024-12-13 07:30:21.737473:  
2024-12-13 07:30:21.743031: Epoch 21 
2024-12-13 07:30:21.745576: Current learning rate: 0.00809 
2024-12-13 07:30:28.104796: train_loss -0.8571 
2024-12-13 07:30:28.108327: val_loss -0.8493 
2024-12-13 07:30:28.111351: Pseudo dice [np.float32(0.8959), np.float32(0.8758)] 
2024-12-13 07:30:28.113870: Epoch time: 6.37 s 
2024-12-13 07:30:28.117392: Yayy! New best EMA pseudo Dice: 0.8774999976158142 
2024-12-13 07:30:28.694368:  
2024-12-13 07:30:28.699528: Epoch 22 
2024-12-13 07:30:28.702587: Current learning rate: 0.008 
2024-12-13 07:30:35.064851: train_loss -0.8598 
2024-12-13 07:30:35.069870: val_loss -0.848 
2024-12-13 07:30:35.073382: Pseudo dice [np.float32(0.8952), np.float32(0.878)] 
2024-12-13 07:30:35.076957: Epoch time: 6.37 s 
2024-12-13 07:30:35.079977: Yayy! New best EMA pseudo Dice: 0.8784000277519226 
2024-12-13 07:30:35.663984:  
2024-12-13 07:30:35.669029: Epoch 23 
2024-12-13 07:30:35.672594: Current learning rate: 0.0079 
2024-12-13 07:30:42.044863: train_loss -0.8614 
2024-12-13 07:30:42.051443: val_loss -0.8541 
2024-12-13 07:30:42.057498: Pseudo dice [np.float32(0.8977), np.float32(0.8833)] 
2024-12-13 07:30:42.060523: Epoch time: 6.38 s 
2024-12-13 07:30:42.063554: Yayy! New best EMA pseudo Dice: 0.8795999884605408 
2024-12-13 07:30:42.640131:  
2024-12-13 07:30:42.645209: Epoch 24 
2024-12-13 07:30:42.648762: Current learning rate: 0.00781 
2024-12-13 07:30:49.021268: train_loss -0.8634 
2024-12-13 07:30:49.026889: val_loss -0.8489 
2024-12-13 07:30:49.029951: Pseudo dice [np.float32(0.8934), np.float32(0.8787)] 
2024-12-13 07:30:49.032504: Epoch time: 6.38 s 
2024-12-13 07:30:49.036032: Yayy! New best EMA pseudo Dice: 0.880299985408783 
2024-12-13 07:30:49.613124:  
2024-12-13 07:30:49.618363: Epoch 25 
2024-12-13 07:30:49.620872: Current learning rate: 0.00772 
2024-12-13 07:30:55.981885: train_loss -0.8612 
2024-12-13 07:30:55.987900: val_loss -0.8495 
2024-12-13 07:30:55.990405: Pseudo dice [np.float32(0.8937), np.float32(0.8788)] 
2024-12-13 07:30:55.994422: Epoch time: 6.37 s 
2024-12-13 07:30:55.996938: Yayy! New best EMA pseudo Dice: 0.8809000253677368 
2024-12-13 07:30:56.584327:  
2024-12-13 07:30:56.589152: Epoch 26 
2024-12-13 07:30:56.592664: Current learning rate: 0.00763 
2024-12-13 07:31:02.976347: train_loss -0.8635 
2024-12-13 07:31:02.981937: val_loss -0.8524 
2024-12-13 07:31:02.985495: Pseudo dice [np.float32(0.8975), np.float32(0.8784)] 
2024-12-13 07:31:02.988571: Epoch time: 6.39 s 
2024-12-13 07:31:02.991643: Yayy! New best EMA pseudo Dice: 0.881600022315979 
2024-12-13 07:31:03.573361:  
2024-12-13 07:31:03.579494: Epoch 27 
2024-12-13 07:31:03.582562: Current learning rate: 0.00753 
2024-12-13 07:31:09.961183: train_loss -0.8623 
2024-12-13 07:31:09.966716: val_loss -0.8522 
2024-12-13 07:31:09.970232: Pseudo dice [np.float32(0.8972), np.float32(0.88)] 
2024-12-13 07:31:09.973749: Epoch time: 6.39 s 
2024-12-13 07:31:09.977063: Yayy! New best EMA pseudo Dice: 0.8823000192642212 
2024-12-13 07:31:10.707000:  
2024-12-13 07:31:10.710011: Epoch 28 
2024-12-13 07:31:10.713523: Current learning rate: 0.00744 
2024-12-13 07:31:17.080261: train_loss -0.865 
2024-12-13 07:31:17.085849: val_loss -0.8516 
2024-12-13 07:31:17.089429: Pseudo dice [np.float32(0.8974), np.float32(0.8778)] 
2024-12-13 07:31:17.092474: Epoch time: 6.37 s 
2024-12-13 07:31:17.095496: Yayy! New best EMA pseudo Dice: 0.8827999830245972 
2024-12-13 07:31:17.678712:  
2024-12-13 07:31:17.682769: Epoch 29 
2024-12-13 07:31:17.685320: Current learning rate: 0.00735 
2024-12-13 07:31:24.052149: train_loss -0.8659 
2024-12-13 07:31:24.058315: val_loss -0.8509 
2024-12-13 07:31:24.061399: Pseudo dice [np.float32(0.8955), np.float32(0.8805)] 
2024-12-13 07:31:24.064988: Epoch time: 6.37 s 
2024-12-13 07:31:24.068053: Yayy! New best EMA pseudo Dice: 0.8833000063896179 
2024-12-13 07:31:24.663071:  
2024-12-13 07:31:24.666081: Epoch 30 
2024-12-13 07:31:24.669593: Current learning rate: 0.00725 
2024-12-13 07:31:31.044439: train_loss -0.867 
2024-12-13 07:31:31.049575: val_loss -0.8583 
2024-12-13 07:31:31.052624: Pseudo dice [np.float32(0.9018), np.float32(0.8841)] 
2024-12-13 07:31:31.055193: Epoch time: 6.38 s 
2024-12-13 07:31:31.058748: Yayy! New best EMA pseudo Dice: 0.8842999935150146 
2024-12-13 07:31:31.649823:  
2024-12-13 07:31:31.655881: Epoch 31 
2024-12-13 07:31:31.658412: Current learning rate: 0.00716 
2024-12-13 07:31:38.038628: train_loss -0.8654 
2024-12-13 07:31:38.045765: val_loss -0.8571 
2024-12-13 07:31:38.049357: Pseudo dice [np.float32(0.9012), np.float32(0.883)] 
2024-12-13 07:31:38.051401: Epoch time: 6.39 s 
2024-12-13 07:31:38.054914: Yayy! New best EMA pseudo Dice: 0.8851000070571899 
2024-12-13 07:31:38.645769:  
2024-12-13 07:31:38.651392: Epoch 32 
2024-12-13 07:31:38.654448: Current learning rate: 0.00707 
2024-12-13 07:31:45.042343: train_loss -0.8679 
2024-12-13 07:31:45.048440: val_loss -0.8523 
2024-12-13 07:31:45.051492: Pseudo dice [np.float32(0.8975), np.float32(0.8804)] 
2024-12-13 07:31:45.054028: Epoch time: 6.4 s 
2024-12-13 07:31:45.057544: Yayy! New best EMA pseudo Dice: 0.8855000138282776 
2024-12-13 07:31:45.649103:  
2024-12-13 07:31:45.654673: Epoch 33 
2024-12-13 07:31:45.657289: Current learning rate: 0.00697 
2024-12-13 07:31:52.046210: train_loss -0.8682 
2024-12-13 07:31:52.051265: val_loss -0.8493 
2024-12-13 07:31:52.054875: Pseudo dice [np.float32(0.8945), np.float32(0.8793)] 
2024-12-13 07:31:52.057967: Epoch time: 6.4 s 
2024-12-13 07:31:52.060506: Yayy! New best EMA pseudo Dice: 0.8855999708175659 
2024-12-13 07:31:52.665787:  
2024-12-13 07:31:52.670844: Epoch 34 
2024-12-13 07:31:52.673937: Current learning rate: 0.00688 
2024-12-13 07:31:59.061756: train_loss -0.8673 
2024-12-13 07:31:59.067340: val_loss -0.8473 
2024-12-13 07:31:59.070389: Pseudo dice [np.float32(0.8944), np.float32(0.8748)] 
2024-12-13 07:31:59.072959: Epoch time: 6.4 s 
2024-12-13 07:31:59.638781:  
2024-12-13 07:31:59.643938: Epoch 35 
2024-12-13 07:31:59.646444: Current learning rate: 0.00679 
2024-12-13 07:32:06.014306: train_loss -0.8687 
2024-12-13 07:32:06.019899: val_loss -0.852 
2024-12-13 07:32:06.022943: Pseudo dice [np.float32(0.8964), np.float32(0.881)] 
2024-12-13 07:32:06.025475: Epoch time: 6.38 s 
2024-12-13 07:32:06.029021: Yayy! New best EMA pseudo Dice: 0.8858000040054321 
2024-12-13 07:32:06.778695:  
2024-12-13 07:32:06.783548: Epoch 36 
2024-12-13 07:32:06.787060: Current learning rate: 0.00669 
2024-12-13 07:32:13.165572: train_loss -0.8694 
2024-12-13 07:32:13.172920: val_loss -0.8475 
2024-12-13 07:32:13.175470: Pseudo dice [np.float32(0.896), np.float32(0.8753)] 
2024-12-13 07:32:13.179054: Epoch time: 6.39 s 
2024-12-13 07:32:13.741357:  
2024-12-13 07:32:13.747389: Epoch 37 
2024-12-13 07:32:13.749578: Current learning rate: 0.0066 
2024-12-13 07:32:20.125144: train_loss -0.8708 
2024-12-13 07:32:20.130750: val_loss -0.8509 
2024-12-13 07:32:20.133835: Pseudo dice [np.float32(0.8974), np.float32(0.8799)] 
2024-12-13 07:32:20.137481: Epoch time: 6.38 s 
2024-12-13 07:32:20.140047: Yayy! New best EMA pseudo Dice: 0.8860999941825867 
2024-12-13 07:32:20.753599:  
2024-12-13 07:32:20.759116: Epoch 38 
2024-12-13 07:32:20.761622: Current learning rate: 0.0065 
2024-12-13 07:32:27.135066: train_loss -0.8691 
2024-12-13 07:32:27.141168: val_loss -0.856 
2024-12-13 07:32:27.144271: Pseudo dice [np.float32(0.8987), np.float32(0.8829)] 
2024-12-13 07:32:27.147357: Epoch time: 6.38 s 
2024-12-13 07:32:27.149924: Yayy! New best EMA pseudo Dice: 0.8866000175476074 
2024-12-13 07:32:27.757608:  
2024-12-13 07:32:27.762642: Epoch 39 
2024-12-13 07:32:27.764787: Current learning rate: 0.00641 
2024-12-13 07:32:34.130798: train_loss -0.8723 
2024-12-13 07:32:34.136383: val_loss -0.8562 
2024-12-13 07:32:34.139961: Pseudo dice [np.float32(0.9006), np.float32(0.8834)] 
2024-12-13 07:32:34.142483: Epoch time: 6.37 s 
2024-12-13 07:32:34.146005: Yayy! New best EMA pseudo Dice: 0.8870999813079834 
2024-12-13 07:32:34.758512:  
2024-12-13 07:32:34.764125: Epoch 40 
2024-12-13 07:32:34.767163: Current learning rate: 0.00631 
2024-12-13 07:32:41.136943: train_loss -0.8723 
2024-12-13 07:32:41.141956: val_loss -0.8543 
2024-12-13 07:32:41.145529: Pseudo dice [np.float32(0.8979), np.float32(0.8824)] 
2024-12-13 07:32:41.149076: Epoch time: 6.38 s 
2024-12-13 07:32:41.152133: Yayy! New best EMA pseudo Dice: 0.8873999714851379 
2024-12-13 07:32:41.767059:  
2024-12-13 07:32:41.772623: Epoch 41 
2024-12-13 07:32:41.776238: Current learning rate: 0.00622 
2024-12-13 07:32:48.152332: train_loss -0.8723 
2024-12-13 07:32:48.157386: val_loss -0.8509 
2024-12-13 07:32:48.160230: Pseudo dice [np.float32(0.8972), np.float32(0.8792)] 
2024-12-13 07:32:48.163739: Epoch time: 6.39 s 
2024-12-13 07:32:48.166245: Yayy! New best EMA pseudo Dice: 0.887499988079071 
2024-12-13 07:32:48.741978:  
2024-12-13 07:32:48.746006: Epoch 42 
2024-12-13 07:32:48.748528: Current learning rate: 0.00612 
2024-12-13 07:32:55.137926: train_loss -0.8732 
2024-12-13 07:32:55.143490: val_loss -0.8508 
2024-12-13 07:32:55.146531: Pseudo dice [np.float32(0.8973), np.float32(0.8789)] 
2024-12-13 07:32:55.149562: Epoch time: 6.4 s 
2024-12-13 07:32:55.152083: Yayy! New best EMA pseudo Dice: 0.8876000046730042 
2024-12-13 07:32:55.728527:  
2024-12-13 07:32:55.733538: Epoch 43 
2024-12-13 07:32:55.736547: Current learning rate: 0.00603 
2024-12-13 07:33:02.093838: train_loss -0.8735 
2024-12-13 07:33:02.099400: val_loss -0.8521 
2024-12-13 07:33:02.102174: Pseudo dice [np.float32(0.8972), np.float32(0.8806)] 
2024-12-13 07:33:02.105690: Epoch time: 6.37 s 
2024-12-13 07:33:02.108514: Yayy! New best EMA pseudo Dice: 0.8877000212669373 
2024-12-13 07:33:02.843718:  
2024-12-13 07:33:02.848743: Epoch 44 
2024-12-13 07:33:02.851834: Current learning rate: 0.00593 
2024-12-13 07:33:09.228003: train_loss -0.875 
2024-12-13 07:33:09.234014: val_loss -0.8518 
2024-12-13 07:33:09.237022: Pseudo dice [np.float32(0.8977), np.float32(0.8785)] 
2024-12-13 07:33:09.239527: Epoch time: 6.39 s 
2024-12-13 07:33:09.243060: Yayy! New best EMA pseudo Dice: 0.8877000212669373 
2024-12-13 07:33:09.826786:  
2024-12-13 07:33:09.831797: Epoch 45 
2024-12-13 07:33:09.834302: Current learning rate: 0.00584 
2024-12-13 07:33:16.205587: train_loss -0.8755 
2024-12-13 07:33:16.212128: val_loss -0.8544 
2024-12-13 07:33:16.215712: Pseudo dice [np.float32(0.8996), np.float32(0.8809)] 
2024-12-13 07:33:16.218241: Epoch time: 6.38 s 
2024-12-13 07:33:16.221772: Yayy! New best EMA pseudo Dice: 0.8880000114440918 
2024-12-13 07:33:16.804127:  
2024-12-13 07:33:16.808168: Epoch 46 
2024-12-13 07:33:16.810710: Current learning rate: 0.00574 
2024-12-13 07:33:23.185046: train_loss -0.8753 
2024-12-13 07:33:23.190603: val_loss -0.8529 
2024-12-13 07:33:23.193656: Pseudo dice [np.float32(0.8988), np.float32(0.8789)] 
2024-12-13 07:33:23.197194: Epoch time: 6.38 s 
2024-12-13 07:33:23.200239: Yayy! New best EMA pseudo Dice: 0.8881000280380249 
2024-12-13 07:33:23.786491:  
2024-12-13 07:33:23.790531: Epoch 47 
2024-12-13 07:33:23.793079: Current learning rate: 0.00565 
2024-12-13 07:33:30.176135: train_loss -0.8754 
2024-12-13 07:33:30.181749: val_loss -0.8578 
2024-12-13 07:33:30.184800: Pseudo dice [np.float32(0.9021), np.float32(0.8841)] 
2024-12-13 07:33:30.187874: Epoch time: 6.39 s 
2024-12-13 07:33:30.190917: Yayy! New best EMA pseudo Dice: 0.8885999917984009 
2024-12-13 07:33:30.763502:  
2024-12-13 07:33:30.769018: Epoch 48 
2024-12-13 07:33:30.771526: Current learning rate: 0.00555 
2024-12-13 07:33:37.157763: train_loss -0.8746 
2024-12-13 07:33:37.164827: val_loss -0.8612 
2024-12-13 07:33:37.169388: Pseudo dice [np.float32(0.9032), np.float32(0.8868)] 
2024-12-13 07:33:37.172946: Epoch time: 6.4 s 
2024-12-13 07:33:37.176030: Yayy! New best EMA pseudo Dice: 0.88919997215271 
2024-12-13 07:33:37.765635:  
2024-12-13 07:33:37.770651: Epoch 49 
2024-12-13 07:33:37.775161: Current learning rate: 0.00546 
2024-12-13 07:33:44.163458: train_loss -0.8769 
2024-12-13 07:33:44.168558: val_loss -0.8521 
2024-12-13 07:33:44.171658: Pseudo dice [np.float32(0.8983), np.float32(0.8798)] 
2024-12-13 07:33:44.174716: Epoch time: 6.4 s 
2024-12-13 07:33:44.755468:  
2024-12-13 07:33:44.761521: Epoch 50 
2024-12-13 07:33:44.764585: Current learning rate: 0.00536 
2024-12-13 07:33:51.130630: train_loss -0.8769 
2024-12-13 07:33:51.136236: val_loss -0.8526 
2024-12-13 07:33:51.139803: Pseudo dice [np.float32(0.8977), np.float32(0.8794)] 
2024-12-13 07:33:51.141829: Epoch time: 6.38 s 
2024-12-13 07:33:51.692079:  
2024-12-13 07:33:51.697591: Epoch 51 
2024-12-13 07:33:51.700095: Current learning rate: 0.00526 
2024-12-13 07:33:58.072756: train_loss -0.8782 
2024-12-13 07:33:58.077846: val_loss -0.8518 
2024-12-13 07:33:58.081867: Pseudo dice [np.float32(0.8972), np.float32(0.8813)] 
2024-12-13 07:33:58.084875: Epoch time: 6.38 s 
2024-12-13 07:33:58.770628:  
2024-12-13 07:33:58.775659: Epoch 52 
2024-12-13 07:33:58.779186: Current learning rate: 0.00517 
2024-12-13 07:34:05.149546: train_loss -0.8787 
2024-12-13 07:34:05.155152: val_loss -0.8577 
2024-12-13 07:34:05.158678: Pseudo dice [np.float32(0.9013), np.float32(0.8858)] 
2024-12-13 07:34:05.161724: Epoch time: 6.38 s 
2024-12-13 07:34:05.164247: Yayy! New best EMA pseudo Dice: 0.8895999789237976 
2024-12-13 07:34:05.752196:  
2024-12-13 07:34:05.757240: Epoch 53 
2024-12-13 07:34:05.759588: Current learning rate: 0.00507 
2024-12-13 07:34:12.118150: train_loss -0.879 
2024-12-13 07:34:12.122737: val_loss -0.8529 
2024-12-13 07:34:12.125775: Pseudo dice [np.float32(0.8974), np.float32(0.8793)] 
2024-12-13 07:34:12.129303: Epoch time: 6.37 s 
2024-12-13 07:34:12.681623:  
2024-12-13 07:34:12.686634: Epoch 54 
2024-12-13 07:34:12.689141: Current learning rate: 0.00497 
2024-12-13 07:34:19.058848: train_loss -0.8788 
2024-12-13 07:34:19.064121: val_loss -0.8576 
2024-12-13 07:34:19.067638: Pseudo dice [np.float32(0.9025), np.float32(0.8844)] 
2024-12-13 07:34:19.070151: Epoch time: 6.38 s 
2024-12-13 07:34:19.073666: Yayy! New best EMA pseudo Dice: 0.8899000287055969 
2024-12-13 07:34:19.666291:  
2024-12-13 07:34:19.671301: Epoch 55 
2024-12-13 07:34:19.673806: Current learning rate: 0.00487 
2024-12-13 07:34:26.045526: train_loss -0.8795 
2024-12-13 07:34:26.051083: val_loss -0.8508 
2024-12-13 07:34:26.054116: Pseudo dice [np.float32(0.8959), np.float32(0.8801)] 
2024-12-13 07:34:26.057146: Epoch time: 6.38 s 
2024-12-13 07:34:26.603656:  
2024-12-13 07:34:26.607668: Epoch 56 
2024-12-13 07:34:26.610175: Current learning rate: 0.00478 
2024-12-13 07:34:32.975240: train_loss -0.8806 
2024-12-13 07:34:32.981123: val_loss -0.8578 
2024-12-13 07:34:32.984153: Pseudo dice [np.float32(0.9026), np.float32(0.8848)] 
2024-12-13 07:34:32.986679: Epoch time: 6.37 s 
2024-12-13 07:34:32.990206: Yayy! New best EMA pseudo Dice: 0.8901000022888184 
2024-12-13 07:34:33.577529:  
2024-12-13 07:34:33.580550: Epoch 57 
2024-12-13 07:34:33.584611: Current learning rate: 0.00468 
2024-12-13 07:34:39.965760: train_loss -0.8805 
2024-12-13 07:34:39.971814: val_loss -0.8538 
2024-12-13 07:34:39.975365: Pseudo dice [np.float32(0.898), np.float32(0.8819)] 
2024-12-13 07:34:39.978438: Epoch time: 6.39 s 
2024-12-13 07:34:40.523725:  
2024-12-13 07:34:40.527763: Epoch 58 
2024-12-13 07:34:40.532341: Current learning rate: 0.00458 
2024-12-13 07:34:46.904539: train_loss -0.8802 
2024-12-13 07:34:46.910573: val_loss -0.8506 
2024-12-13 07:34:46.914148: Pseudo dice [np.float32(0.8976), np.float32(0.8793)] 
2024-12-13 07:34:46.917256: Epoch time: 6.38 s 
2024-12-13 07:34:47.478846:  
2024-12-13 07:34:47.482875: Epoch 59 
2024-12-13 07:34:47.485970: Current learning rate: 0.00448 
2024-12-13 07:34:53.870343: train_loss -0.8823 
2024-12-13 07:34:53.876543: val_loss -0.8526 
2024-12-13 07:34:53.879595: Pseudo dice [np.float32(0.8975), np.float32(0.8811)] 
2024-12-13 07:34:53.882645: Epoch time: 6.39 s 
2024-12-13 07:34:54.584570:  
2024-12-13 07:34:54.590084: Epoch 60 
2024-12-13 07:34:54.592591: Current learning rate: 0.00438 
2024-12-13 07:35:00.967632: train_loss -0.8819 
2024-12-13 07:35:00.972807: val_loss -0.8534 
2024-12-13 07:35:00.976327: Pseudo dice [np.float32(0.8979), np.float32(0.8816)] 
2024-12-13 07:35:00.979412: Epoch time: 6.38 s 
2024-12-13 07:35:01.541970:  
2024-12-13 07:35:01.544995: Epoch 61 
2024-12-13 07:35:01.549576: Current learning rate: 0.00429 
2024-12-13 07:35:07.924278: train_loss -0.881 
2024-12-13 07:35:07.930913: val_loss -0.857 
2024-12-13 07:35:07.933988: Pseudo dice [np.float32(0.9022), np.float32(0.8839)] 
2024-12-13 07:35:07.937029: Epoch time: 6.38 s 
2024-12-13 07:35:07.940053: Yayy! New best EMA pseudo Dice: 0.8902000188827515 
2024-12-13 07:35:08.532693:  
2024-12-13 07:35:08.538308: Epoch 62 
2024-12-13 07:35:08.541368: Current learning rate: 0.00419 
2024-12-13 07:35:14.901407: train_loss -0.8833 
2024-12-13 07:35:14.906980: val_loss -0.8519 
2024-12-13 07:35:14.910041: Pseudo dice [np.float32(0.8978), np.float32(0.881)] 
2024-12-13 07:35:14.913111: Epoch time: 6.37 s 
2024-12-13 07:35:15.475804:  
2024-12-13 07:35:15.481318: Epoch 63 
2024-12-13 07:35:15.483829: Current learning rate: 0.00409 
2024-12-13 07:35:21.847846: train_loss -0.8842 
2024-12-13 07:35:21.852925: val_loss -0.8512 
2024-12-13 07:35:21.855955: Pseudo dice [np.float32(0.8956), np.float32(0.8809)] 
2024-12-13 07:35:21.859016: Epoch time: 6.37 s 
2024-12-13 07:35:22.420251:  
2024-12-13 07:35:22.426292: Epoch 64 
2024-12-13 07:35:22.429816: Current learning rate: 0.00399 
2024-12-13 07:35:28.805033: train_loss -0.8843 
2024-12-13 07:35:28.809090: val_loss -0.8542 
2024-12-13 07:35:28.812632: Pseudo dice [np.float32(0.9001), np.float32(0.8808)] 
2024-12-13 07:35:28.815698: Epoch time: 6.38 s 
2024-12-13 07:35:29.380224:  
2024-12-13 07:35:29.386277: Epoch 65 
2024-12-13 07:35:29.389324: Current learning rate: 0.00389 
2024-12-13 07:35:35.768917: train_loss -0.8844 
2024-12-13 07:35:35.774788: val_loss -0.844 
2024-12-13 07:35:35.776994: Pseudo dice [np.float32(0.8924), np.float32(0.8747)] 
2024-12-13 07:35:35.780506: Epoch time: 6.39 s 
2024-12-13 07:35:36.342592:  
2024-12-13 07:35:36.347603: Epoch 66 
2024-12-13 07:35:36.350109: Current learning rate: 0.00379 
2024-12-13 07:35:42.733453: train_loss -0.8839 
2024-12-13 07:35:42.739122: val_loss -0.8505 
2024-12-13 07:35:42.742199: Pseudo dice [np.float32(0.8982), np.float32(0.8795)] 
2024-12-13 07:35:42.745251: Epoch time: 6.39 s 
2024-12-13 07:35:43.304844:  
2024-12-13 07:35:43.309855: Epoch 67 
2024-12-13 07:35:43.312865: Current learning rate: 0.00369 
2024-12-13 07:35:49.684512: train_loss -0.8846 
2024-12-13 07:35:49.689611: val_loss -0.8513 
2024-12-13 07:35:49.692653: Pseudo dice [np.float32(0.8983), np.float32(0.8781)] 
2024-12-13 07:35:49.695181: Epoch time: 6.38 s 
2024-12-13 07:35:50.412344:  
2024-12-13 07:35:50.417385: Epoch 68 
2024-12-13 07:35:50.420296: Current learning rate: 0.00359 
2024-12-13 07:35:56.781791: train_loss -0.8861 
2024-12-13 07:35:56.785864: val_loss -0.8541 
2024-12-13 07:35:56.790422: Pseudo dice [np.float32(0.8995), np.float32(0.8838)] 
2024-12-13 07:35:56.792928: Epoch time: 6.37 s 
2024-12-13 07:35:57.364045:  
2024-12-13 07:35:57.369075: Epoch 69 
2024-12-13 07:35:57.371847: Current learning rate: 0.00349 
2024-12-13 07:36:03.745526: train_loss -0.886 
2024-12-13 07:36:03.751155: val_loss -0.8582 
2024-12-13 07:36:03.754209: Pseudo dice [np.float32(0.9021), np.float32(0.8855)] 
2024-12-13 07:36:03.756767: Epoch time: 6.38 s 
2024-12-13 07:36:04.324386:  
2024-12-13 07:36:04.329396: Epoch 70 
2024-12-13 07:36:04.332411: Current learning rate: 0.00338 
2024-12-13 07:36:10.699878: train_loss -0.8863 
2024-12-13 07:36:10.704890: val_loss -0.8534 
2024-12-13 07:36:10.708203: Pseudo dice [np.float32(0.8989), np.float32(0.8802)] 
2024-12-13 07:36:10.711239: Epoch time: 6.38 s 
2024-12-13 07:36:11.279308:  
2024-12-13 07:36:11.285355: Epoch 71 
2024-12-13 07:36:11.289367: Current learning rate: 0.00328 
2024-12-13 07:36:17.654498: train_loss -0.8879 
2024-12-13 07:36:17.660570: val_loss -0.8534 
2024-12-13 07:36:17.665182: Pseudo dice [np.float32(0.8984), np.float32(0.882)] 
2024-12-13 07:36:17.669285: Epoch time: 6.38 s 
2024-12-13 07:36:18.240375:  
2024-12-13 07:36:18.245941: Epoch 72 
2024-12-13 07:36:18.250558: Current learning rate: 0.00318 
2024-12-13 07:36:24.619428: train_loss -0.8885 
2024-12-13 07:36:24.625906: val_loss -0.8528 
2024-12-13 07:36:24.629680: Pseudo dice [np.float32(0.8982), np.float32(0.8811)] 
2024-12-13 07:36:24.633745: Epoch time: 6.38 s 
2024-12-13 07:36:25.198820:  
2024-12-13 07:36:25.203942: Epoch 73 
2024-12-13 07:36:25.207773: Current learning rate: 0.00308 
2024-12-13 07:36:31.593573: train_loss -0.8873 
2024-12-13 07:36:31.599659: val_loss -0.8531 
2024-12-13 07:36:31.603219: Pseudo dice [np.float32(0.9004), np.float32(0.8805)] 
2024-12-13 07:36:31.605733: Epoch time: 6.4 s 
2024-12-13 07:36:32.178046:  
2024-12-13 07:36:32.183082: Epoch 74 
2024-12-13 07:36:32.186610: Current learning rate: 0.00297 
2024-12-13 07:36:38.558228: train_loss -0.8892 
2024-12-13 07:36:38.565352: val_loss -0.8551 
2024-12-13 07:36:38.568951: Pseudo dice [np.float32(0.8999), np.float32(0.8827)] 
2024-12-13 07:36:38.572037: Epoch time: 6.38 s 
2024-12-13 07:36:39.284013:  
2024-12-13 07:36:39.290107: Epoch 75 
2024-12-13 07:36:39.294118: Current learning rate: 0.00287 
2024-12-13 07:36:45.676741: train_loss -0.888 
2024-12-13 07:36:45.682871: val_loss -0.855 
2024-12-13 07:36:45.686500: Pseudo dice [np.float32(0.8995), np.float32(0.8834)] 
2024-12-13 07:36:45.690068: Epoch time: 6.39 s 
2024-12-13 07:36:45.692720: Yayy! New best EMA pseudo Dice: 0.8902000188827515 
2024-12-13 07:36:46.297217:  
2024-12-13 07:36:46.303292: Epoch 76 
2024-12-13 07:36:46.307370: Current learning rate: 0.00277 
2024-12-13 07:36:52.669496: train_loss -0.8884 
2024-12-13 07:36:52.676034: val_loss -0.8518 
2024-12-13 07:36:52.679758: Pseudo dice [np.float32(0.8984), np.float32(0.8806)] 
2024-12-13 07:36:52.683655: Epoch time: 6.37 s 
2024-12-13 07:36:53.250510:  
2024-12-13 07:36:53.257866: Epoch 77 
2024-12-13 07:36:53.261173: Current learning rate: 0.00266 
2024-12-13 07:36:59.631443: train_loss -0.8884 
2024-12-13 07:36:59.636558: val_loss -0.8518 
2024-12-13 07:36:59.641672: Pseudo dice [np.float32(0.8988), np.float32(0.8787)] 
2024-12-13 07:36:59.645720: Epoch time: 6.38 s 
2024-12-13 07:37:00.224669:  
2024-12-13 07:37:00.230711: Epoch 78 
2024-12-13 07:37:00.235136: Current learning rate: 0.00256 
2024-12-13 07:37:06.617521: train_loss -0.8884 
2024-12-13 07:37:06.622617: val_loss -0.8563 
2024-12-13 07:37:06.626220: Pseudo dice [np.float32(0.8999), np.float32(0.8837)] 
2024-12-13 07:37:06.630304: Epoch time: 6.39 s 
2024-12-13 07:37:07.207181:  
2024-12-13 07:37:07.212698: Epoch 79 
2024-12-13 07:37:07.217210: Current learning rate: 0.00245 
2024-12-13 07:37:13.594869: train_loss -0.8891 
2024-12-13 07:37:13.601483: val_loss -0.8567 
2024-12-13 07:37:13.605127: Pseudo dice [np.float32(0.9007), np.float32(0.8841)] 
2024-12-13 07:37:13.609231: Epoch time: 6.39 s 
2024-12-13 07:37:13.612825: Yayy! New best EMA pseudo Dice: 0.8903999924659729 
2024-12-13 07:37:14.226864:  
2024-12-13 07:37:14.232377: Epoch 80 
2024-12-13 07:37:14.237392: Current learning rate: 0.00235 
2024-12-13 07:37:20.620197: train_loss -0.8911 
2024-12-13 07:37:20.624758: val_loss -0.8526 
2024-12-13 07:37:20.629862: Pseudo dice [np.float32(0.8991), np.float32(0.8819)] 
2024-12-13 07:37:20.633430: Epoch time: 6.39 s 
2024-12-13 07:37:20.637382: Yayy! New best EMA pseudo Dice: 0.8903999924659729 
2024-12-13 07:37:21.253034:  
2024-12-13 07:37:21.258549: Epoch 81 
2024-12-13 07:37:21.263062: Current learning rate: 0.00224 
2024-12-13 07:37:27.640427: train_loss -0.8895 
2024-12-13 07:37:27.647581: val_loss -0.8558 
2024-12-13 07:37:27.651135: Pseudo dice [np.float32(0.9011), np.float32(0.8839)] 
2024-12-13 07:37:27.655187: Epoch time: 6.39 s 
2024-12-13 07:37:27.658234: Yayy! New best EMA pseudo Dice: 0.8906000256538391 
2024-12-13 07:37:28.273399:  
2024-12-13 07:37:28.279632: Epoch 82 
2024-12-13 07:37:28.283675: Current learning rate: 0.00214 
2024-12-13 07:37:34.639675: train_loss -0.8903 
2024-12-13 07:37:34.646317: val_loss -0.8548 
2024-12-13 07:37:34.650387: Pseudo dice [np.float32(0.8995), np.float32(0.882)] 
2024-12-13 07:37:34.653921: Epoch time: 6.37 s 
2024-12-13 07:37:34.657959: Yayy! New best EMA pseudo Dice: 0.8906000256538391 
2024-12-13 07:37:35.397383:  
2024-12-13 07:37:35.403900: Epoch 83 
2024-12-13 07:37:35.407907: Current learning rate: 0.00203 
2024-12-13 07:37:41.776486: train_loss -0.8913 
2024-12-13 07:37:41.782594: val_loss -0.8543 
2024-12-13 07:37:41.786638: Pseudo dice [np.float32(0.8987), np.float32(0.8843)] 
2024-12-13 07:37:41.790664: Epoch time: 6.38 s 
2024-12-13 07:37:41.793742: Yayy! New best EMA pseudo Dice: 0.8906999826431274 
2024-12-13 07:37:42.380362:  
2024-12-13 07:37:42.385879: Epoch 84 
2024-12-13 07:37:42.390388: Current learning rate: 0.00192 
2024-12-13 07:37:48.756302: train_loss -0.8913 
2024-12-13 07:37:48.761378: val_loss -0.8495 
2024-12-13 07:37:48.765909: Pseudo dice [np.float32(0.8962), np.float32(0.8791)] 
2024-12-13 07:37:48.769949: Epoch time: 6.38 s 
2024-12-13 07:37:49.314669:  
2024-12-13 07:37:49.320752: Epoch 85 
2024-12-13 07:37:49.324858: Current learning rate: 0.00181 
2024-12-13 07:37:55.686714: train_loss -0.8911 
2024-12-13 07:37:55.692810: val_loss -0.8531 
2024-12-13 07:37:55.696374: Pseudo dice [np.float32(0.898), np.float32(0.8811)] 
2024-12-13 07:37:55.700967: Epoch time: 6.37 s 
2024-12-13 07:37:56.236317:  
2024-12-13 07:37:56.242376: Epoch 86 
2024-12-13 07:37:56.245438: Current learning rate: 0.0017 
2024-12-13 07:38:02.606306: train_loss -0.8925 
2024-12-13 07:38:02.612427: val_loss -0.8578 
2024-12-13 07:38:02.616487: Pseudo dice [np.float32(0.9018), np.float32(0.8845)] 
2024-12-13 07:38:02.620523: Epoch time: 6.37 s 
2024-12-13 07:38:03.166837:  
2024-12-13 07:38:03.173429: Epoch 87 
2024-12-13 07:38:03.177518: Current learning rate: 0.00159 
2024-12-13 07:38:09.536648: train_loss -0.8935 
2024-12-13 07:38:09.543222: val_loss -0.8513 
2024-12-13 07:38:09.546809: Pseudo dice [np.float32(0.8984), np.float32(0.8794)] 
2024-12-13 07:38:09.550351: Epoch time: 6.37 s 
2024-12-13 07:38:10.103662:  
2024-12-13 07:38:10.109218: Epoch 88 
2024-12-13 07:38:10.113815: Current learning rate: 0.00148 
2024-12-13 07:38:16.482650: train_loss -0.8929 
2024-12-13 07:38:16.488704: val_loss -0.8537 
2024-12-13 07:38:16.492800: Pseudo dice [np.float32(0.9), np.float32(0.8816)] 
2024-12-13 07:38:16.496353: Epoch time: 6.38 s 
2024-12-13 07:38:17.042040:  
2024-12-13 07:38:17.048012: Epoch 89 
2024-12-13 07:38:17.052027: Current learning rate: 0.00137 
2024-12-13 07:38:23.439056: train_loss -0.8928 
2024-12-13 07:38:23.445115: val_loss -0.8539 
2024-12-13 07:38:23.448661: Pseudo dice [np.float32(0.8995), np.float32(0.881)] 
2024-12-13 07:38:23.452772: Epoch time: 6.4 s 
2024-12-13 07:38:24.008713:  
2024-12-13 07:38:24.015314: Epoch 90 
2024-12-13 07:38:24.017862: Current learning rate: 0.00126 
2024-12-13 07:38:30.399019: train_loss -0.8927 
2024-12-13 07:38:30.403587: val_loss -0.847 
2024-12-13 07:38:30.407656: Pseudo dice [np.float32(0.8944), np.float32(0.877)] 
2024-12-13 07:38:30.410717: Epoch time: 6.39 s 
2024-12-13 07:38:30.950287:  
2024-12-13 07:38:30.955301: Epoch 91 
2024-12-13 07:38:30.958312: Current learning rate: 0.00115 
2024-12-13 07:38:37.328261: train_loss -0.8945 
2024-12-13 07:38:37.333846: val_loss -0.8521 
2024-12-13 07:38:37.336916: Pseudo dice [np.float32(0.898), np.float32(0.8819)] 
2024-12-13 07:38:37.339991: Epoch time: 6.38 s 
2024-12-13 07:38:38.029483:  
2024-12-13 07:38:38.035012: Epoch 92 
2024-12-13 07:38:38.038554: Current learning rate: 0.00103 
2024-12-13 07:38:44.393496: train_loss -0.8937 
2024-12-13 07:38:44.399549: val_loss -0.8536 
2024-12-13 07:38:44.402611: Pseudo dice [np.float32(0.8993), np.float32(0.8825)] 
2024-12-13 07:38:44.405214: Epoch time: 6.37 s 
2024-12-13 07:38:44.951093:  
2024-12-13 07:38:44.956105: Epoch 93 
2024-12-13 07:38:44.960114: Current learning rate: 0.00091 
2024-12-13 07:38:51.352833: train_loss -0.8947 
2024-12-13 07:38:51.358462: val_loss -0.8523 
2024-12-13 07:38:51.362033: Pseudo dice [np.float32(0.8978), np.float32(0.8813)] 
2024-12-13 07:38:51.364107: Epoch time: 6.4 s 
2024-12-13 07:38:51.905542:  
2024-12-13 07:38:51.910576: Epoch 94 
2024-12-13 07:38:51.913285: Current learning rate: 0.00079 
2024-12-13 07:38:58.270821: train_loss -0.8964 
2024-12-13 07:38:58.276337: val_loss -0.8554 
2024-12-13 07:38:58.279847: Pseudo dice [np.float32(0.9008), np.float32(0.8832)] 
2024-12-13 07:38:58.282354: Epoch time: 6.37 s 
2024-12-13 07:38:58.827080:  
2024-12-13 07:38:58.830590: Epoch 95 
2024-12-13 07:38:58.833101: Current learning rate: 0.00067 
2024-12-13 07:39:05.203498: train_loss -0.8943 
2024-12-13 07:39:05.209085: val_loss -0.8571 
2024-12-13 07:39:05.212158: Pseudo dice [np.float32(0.9006), np.float32(0.8859)] 
2024-12-13 07:39:05.215225: Epoch time: 6.38 s 
2024-12-13 07:39:05.752704:  
2024-12-13 07:39:05.758251: Epoch 96 
2024-12-13 07:39:05.761295: Current learning rate: 0.00055 
2024-12-13 07:39:12.148703: train_loss -0.8952 
2024-12-13 07:39:12.154270: val_loss -0.8491 
2024-12-13 07:39:12.156776: Pseudo dice [np.float32(0.8952), np.float32(0.8806)] 
2024-12-13 07:39:12.160288: Epoch time: 6.4 s 
2024-12-13 07:39:12.718536:  
2024-12-13 07:39:12.721556: Epoch 97 
2024-12-13 07:39:12.725609: Current learning rate: 0.00043 
2024-12-13 07:39:19.100459: train_loss -0.8974 
2024-12-13 07:39:19.106471: val_loss -0.8552 
2024-12-13 07:39:19.109485: Pseudo dice [np.float32(0.9003), np.float32(0.8822)] 
2024-12-13 07:39:19.113000: Epoch time: 6.38 s 
2024-12-13 07:39:19.664720:  
2024-12-13 07:39:19.669731: Epoch 98 
2024-12-13 07:39:19.673242: Current learning rate: 0.0003 
2024-12-13 07:39:26.054841: train_loss -0.8972 
2024-12-13 07:39:26.059901: val_loss -0.8551 
2024-12-13 07:39:26.062983: Pseudo dice [np.float32(0.8999), np.float32(0.8842)] 
2024-12-13 07:39:26.066537: Epoch time: 6.39 s 
2024-12-13 07:39:26.612059:  
2024-12-13 07:39:26.617684: Epoch 99 
2024-12-13 07:39:26.620240: Current learning rate: 0.00016 
2024-12-13 07:39:32.975798: train_loss -0.8963 
2024-12-13 07:39:32.981385: val_loss -0.8486 
2024-12-13 07:39:32.984426: Pseudo dice [np.float32(0.8959), np.float32(0.8792)] 
2024-12-13 07:39:32.987004: Epoch time: 6.36 s 
2024-12-13 07:39:33.746679: Training done. 
2024-12-13 07:39:33.782682: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-13 07:39:33.788682: The split file contains 5 splits. 
2024-12-13 07:39:33.793681: Desired fold for training: 0 
2024-12-13 07:39:33.797684: This split has 208 training and 52 validation cases. 
2024-12-13 07:39:33.802682: predicting hippocampus_017 
2024-12-13 07:39:33.808691: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-13 07:39:33.910808: predicting hippocampus_019 
2024-12-13 07:39:33.916813: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-13 07:39:33.954319: predicting hippocampus_033 
2024-12-13 07:39:33.960318: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-13 07:39:33.984319: predicting hippocampus_035 
2024-12-13 07:39:33.990321: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-13 07:39:34.016325: predicting hippocampus_037 
2024-12-13 07:39:34.022840: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-13 07:39:34.049836: predicting hippocampus_049 
2024-12-13 07:39:34.055837: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-13 07:39:34.080839: predicting hippocampus_052 
2024-12-13 07:39:34.087837: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-13 07:39:34.113846: predicting hippocampus_065 
2024-12-13 07:39:34.120361: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-13 07:39:34.145358: predicting hippocampus_083 
2024-12-13 07:39:34.151359: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-13 07:39:34.178359: predicting hippocampus_088 
2024-12-13 07:39:34.184358: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-13 07:39:37.627199: predicting hippocampus_090 
2024-12-13 07:39:37.633709: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-13 07:39:37.674707: predicting hippocampus_092 
2024-12-13 07:39:37.692707: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-13 07:39:37.744220: predicting hippocampus_095 
2024-12-13 07:39:37.754220: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-13 07:39:37.819221: predicting hippocampus_107 
2024-12-13 07:39:37.825726: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-13 07:39:37.880727: predicting hippocampus_108 
2024-12-13 07:39:37.891726: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-13 07:39:37.943233: predicting hippocampus_123 
2024-12-13 07:39:37.948233: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-13 07:39:37.986233: predicting hippocampus_125 
2024-12-13 07:39:37.993234: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-13 07:39:38.057740: predicting hippocampus_157 
2024-12-13 07:39:38.062741: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-13 07:39:38.091740: predicting hippocampus_164 
2024-12-13 07:39:38.096741: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-13 07:39:38.177247: predicting hippocampus_169 
2024-12-13 07:39:38.186247: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-13 07:39:38.215249: predicting hippocampus_175 
2024-12-13 07:39:38.222754: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-13 07:39:38.252754: predicting hippocampus_185 
2024-12-13 07:39:38.258754: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-13 07:39:38.284754: predicting hippocampus_190 
2024-12-13 07:39:38.291754: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-13 07:39:38.318756: predicting hippocampus_194 
2024-12-13 07:39:38.323262: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-13 07:39:38.347262: predicting hippocampus_204 
2024-12-13 07:39:38.352262: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-13 07:39:38.379262: predicting hippocampus_205 
2024-12-13 07:39:38.384262: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-13 07:39:38.410264: predicting hippocampus_210 
2024-12-13 07:39:38.416265: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-13 07:39:38.443774: predicting hippocampus_217 
2024-12-13 07:39:38.449774: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-13 07:39:38.478772: predicting hippocampus_219 
2024-12-13 07:39:38.484772: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-13 07:39:38.510775: predicting hippocampus_229 
2024-12-13 07:39:38.514775: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-13 07:39:38.540280: predicting hippocampus_244 
2024-12-13 07:39:38.546280: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-13 07:39:38.571280: predicting hippocampus_261 
2024-12-13 07:39:38.576280: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-13 07:39:38.625795: predicting hippocampus_264 
2024-12-13 07:39:38.633795: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-13 07:39:38.663795: predicting hippocampus_277 
2024-12-13 07:39:38.669793: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-13 07:39:38.712796: predicting hippocampus_280 
2024-12-13 07:39:38.719797: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-13 07:39:38.744302: predicting hippocampus_286 
2024-12-13 07:39:38.749302: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-13 07:39:38.790301: predicting hippocampus_288 
2024-12-13 07:39:38.796302: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-13 07:39:38.836809: predicting hippocampus_289 
2024-12-13 07:39:38.843809: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-13 07:39:38.869808: predicting hippocampus_296 
2024-12-13 07:39:38.876809: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-13 07:39:38.901809: predicting hippocampus_305 
2024-12-13 07:39:38.906813: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-13 07:39:38.934318: predicting hippocampus_308 
2024-12-13 07:39:38.941318: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-13 07:39:38.966318: predicting hippocampus_317 
2024-12-13 07:39:38.970318: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-13 07:39:38.997318: predicting hippocampus_327 
2024-12-13 07:39:39.002318: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-13 07:39:39.027825: predicting hippocampus_330 
2024-12-13 07:39:39.032825: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-13 07:39:39.061825: predicting hippocampus_332 
2024-12-13 07:39:39.066825: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-13 07:39:39.094825: predicting hippocampus_338 
2024-12-13 07:39:39.098825: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-13 07:39:39.141332: predicting hippocampus_349 
2024-12-13 07:39:39.146332: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-13 07:39:39.171332: predicting hippocampus_350 
2024-12-13 07:39:39.175332: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-13 07:39:39.201332: predicting hippocampus_356 
2024-12-13 07:39:39.208335: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-13 07:39:39.232839: predicting hippocampus_358 
2024-12-13 07:39:39.237840: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-13 07:39:39.262839: predicting hippocampus_374 
2024-12-13 07:39:39.268839: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-13 07:39:39.294840: predicting hippocampus_394 
2024-12-13 07:39:39.300840: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-13 07:39:42.762410: Validation complete 
2024-12-13 07:39:42.767410: Mean Validation Dice:  0.8920892070677229 
