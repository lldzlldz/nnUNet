2024-12-15 01:00:57.509190: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.5 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-15 01:00:57.513181: self.oversample_foreground_percent 0.5555555555555556 
2024-12-15 01:00:57.516178: do_dummy_2d_data_aug: False 
2024-12-15 01:00:57.523305: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-15 01:00:57.530310: The split file contains 5 splits. 
2024-12-15 01:00:57.532308: Desired fold for training: 0 
2024-12-15 01:00:57.534306: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-15 01:01:03.749087: unpacking dataset... 
2024-12-15 01:01:04.588963: unpacking done... 
2024-12-15 01:01:05.683702:  
2024-12-15 01:01:05.689722: Epoch 0 
2024-12-15 01:01:05.693736: Current learning rate: 0.01 
2024-12-15 01:01:13.173107: train_loss -0.2245 
2024-12-15 01:01:13.178653: val_loss -0.7146 
2024-12-15 01:01:13.182164: Pseudo dice [np.float32(0.8109), np.float32(0.7932)] 
2024-12-15 01:01:13.185723: Epoch time: 7.49 s 
2024-12-15 01:01:13.188794: Yayy! New best EMA pseudo Dice: 0.8019999861717224 
2024-12-15 01:01:13.714859:  
2024-12-15 01:01:13.720964: Epoch 1 
2024-12-15 01:01:13.724051: Current learning rate: 0.00991 
2024-12-15 01:01:20.359628: train_loss -0.7552 
2024-12-15 01:01:20.365873: val_loss -0.7984 
2024-12-15 01:01:20.368928: Pseudo dice [np.float32(0.856), np.float32(0.8396)] 
2024-12-15 01:01:20.371967: Epoch time: 6.64 s 
2024-12-15 01:01:20.375475: Yayy! New best EMA pseudo Dice: 0.8065999746322632 
2024-12-15 01:01:20.966293:  
2024-12-15 01:01:20.972310: Epoch 2 
2024-12-15 01:01:20.974817: Current learning rate: 0.00982 
2024-12-15 01:01:27.592907: train_loss -0.7927 
2024-12-15 01:01:27.598582: val_loss -0.8161 
2024-12-15 01:01:27.601617: Pseudo dice [np.float32(0.873), np.float32(0.855)] 
2024-12-15 01:01:27.605693: Epoch time: 6.63 s 
2024-12-15 01:01:27.608203: Yayy! New best EMA pseudo Dice: 0.8123000264167786 
2024-12-15 01:01:28.224166:  
2024-12-15 01:01:28.230268: Epoch 3 
2024-12-15 01:01:28.233354: Current learning rate: 0.00973 
2024-12-15 01:01:34.707214: train_loss -0.8094 
2024-12-15 01:01:34.713353: val_loss -0.8242 
2024-12-15 01:01:34.716410: Pseudo dice [np.float32(0.8759), np.float32(0.8628)] 
2024-12-15 01:01:34.719464: Epoch time: 6.48 s 
2024-12-15 01:01:34.722508: Yayy! New best EMA pseudo Dice: 0.8180000185966492 
2024-12-15 01:01:35.326299:  
2024-12-15 01:01:35.332406: Epoch 4 
2024-12-15 01:01:35.335999: Current learning rate: 0.00964 
2024-12-15 01:01:41.827663: train_loss -0.8188 
2024-12-15 01:01:41.833257: val_loss -0.8337 
2024-12-15 01:01:41.836942: Pseudo dice [np.float32(0.8862), np.float32(0.8665)] 
2024-12-15 01:01:41.839984: Epoch time: 6.5 s 
2024-12-15 01:01:41.843060: Yayy! New best EMA pseudo Dice: 0.8238999843597412 
2024-12-15 01:01:42.581139:  
2024-12-15 01:01:42.586717: Epoch 5 
2024-12-15 01:01:42.589779: Current learning rate: 0.00955 
2024-12-15 01:01:49.144684: train_loss -0.8234 
2024-12-15 01:01:49.150236: val_loss -0.8247 
2024-12-15 01:01:49.153265: Pseudo dice [np.float32(0.8793), np.float32(0.8587)] 
2024-12-15 01:01:49.156785: Epoch time: 6.56 s 
2024-12-15 01:01:49.159832: Yayy! New best EMA pseudo Dice: 0.8284000158309937 
2024-12-15 01:01:49.756944:  
2024-12-15 01:01:49.762478: Epoch 6 
2024-12-15 01:01:49.766024: Current learning rate: 0.00946 
2024-12-15 01:01:56.262875: train_loss -0.83 
2024-12-15 01:01:56.267561: val_loss -0.8315 
2024-12-15 01:01:56.271636: Pseudo dice [np.float32(0.883), np.float32(0.8662)] 
2024-12-15 01:01:56.274704: Epoch time: 6.51 s 
2024-12-15 01:01:56.277738: Yayy! New best EMA pseudo Dice: 0.8330000042915344 
2024-12-15 01:01:56.876371:  
2024-12-15 01:01:56.881429: Epoch 7 
2024-12-15 01:01:56.884050: Current learning rate: 0.00937 
2024-12-15 01:02:03.489225: train_loss -0.834 
2024-12-15 01:02:03.494377: val_loss -0.838 
2024-12-15 01:02:03.498999: Pseudo dice [np.float32(0.8872), np.float32(0.8691)] 
2024-12-15 01:02:03.501572: Epoch time: 6.61 s 
2024-12-15 01:02:03.503597: Yayy! New best EMA pseudo Dice: 0.8374999761581421 
2024-12-15 01:02:04.127859:  
2024-12-15 01:02:04.133904: Epoch 8 
2024-12-15 01:02:04.136412: Current learning rate: 0.00928 
2024-12-15 01:02:10.867330: train_loss -0.8396 
2024-12-15 01:02:10.872919: val_loss -0.8389 
2024-12-15 01:02:10.877584: Pseudo dice [np.float32(0.8883), np.float32(0.8725)] 
2024-12-15 01:02:10.881849: Epoch time: 6.74 s 
2024-12-15 01:02:10.886224: Yayy! New best EMA pseudo Dice: 0.8417999744415283 
2024-12-15 01:02:11.543130:  
2024-12-15 01:02:11.548150: Epoch 9 
2024-12-15 01:02:11.551668: Current learning rate: 0.00919 
2024-12-15 01:02:18.084087: train_loss -0.8407 
2024-12-15 01:02:18.089927: val_loss -0.8407 
2024-12-15 01:02:18.093977: Pseudo dice [np.float32(0.8908), np.float32(0.8728)] 
2024-12-15 01:02:18.097507: Epoch time: 6.54 s 
2024-12-15 01:02:18.100027: Yayy! New best EMA pseudo Dice: 0.84579998254776 
2024-12-15 01:02:18.707778:  
2024-12-15 01:02:18.713920: Epoch 10 
2024-12-15 01:02:18.717443: Current learning rate: 0.0091 
2024-12-15 01:02:25.224189: train_loss -0.8441 
2024-12-15 01:02:25.229778: val_loss -0.8451 
2024-12-15 01:02:25.233307: Pseudo dice [np.float32(0.8936), np.float32(0.8754)] 
2024-12-15 01:02:25.236353: Epoch time: 6.52 s 
2024-12-15 01:02:25.239417: Yayy! New best EMA pseudo Dice: 0.8496999740600586 
2024-12-15 01:02:25.825146:  
2024-12-15 01:02:25.830187: Epoch 11 
2024-12-15 01:02:25.832955: Current learning rate: 0.009 
2024-12-15 01:02:32.312682: train_loss -0.8447 
2024-12-15 01:02:32.318737: val_loss -0.8453 
2024-12-15 01:02:32.322288: Pseudo dice [np.float32(0.8945), np.float32(0.8732)] 
2024-12-15 01:02:32.325331: Epoch time: 6.49 s 
2024-12-15 01:02:32.327939: Yayy! New best EMA pseudo Dice: 0.8531000018119812 
2024-12-15 01:02:32.923109:  
2024-12-15 01:02:32.929155: Epoch 12 
2024-12-15 01:02:32.932204: Current learning rate: 0.00891 
2024-12-15 01:02:39.415645: train_loss -0.846 
2024-12-15 01:02:39.421173: val_loss -0.8386 
2024-12-15 01:02:39.424685: Pseudo dice [np.float32(0.8881), np.float32(0.8696)] 
2024-12-15 01:02:39.428195: Epoch time: 6.49 s 
2024-12-15 01:02:39.431206: Yayy! New best EMA pseudo Dice: 0.8557000160217285 
2024-12-15 01:02:40.187031:  
2024-12-15 01:02:40.192561: Epoch 13 
2024-12-15 01:02:40.195596: Current learning rate: 0.00882 
2024-12-15 01:02:46.680817: train_loss -0.8491 
2024-12-15 01:02:46.686370: val_loss -0.8459 
2024-12-15 01:02:46.689894: Pseudo dice [np.float32(0.894), np.float32(0.8752)] 
2024-12-15 01:02:46.693138: Epoch time: 6.49 s 
2024-12-15 01:02:46.695696: Yayy! New best EMA pseudo Dice: 0.8586000204086304 
2024-12-15 01:02:47.291200:  
2024-12-15 01:02:47.296215: Epoch 14 
2024-12-15 01:02:47.299224: Current learning rate: 0.00873 
2024-12-15 01:02:53.703784: train_loss -0.8513 
2024-12-15 01:02:53.709421: val_loss -0.8463 
2024-12-15 01:02:53.712958: Pseudo dice [np.float32(0.8955), np.float32(0.8742)] 
2024-12-15 01:02:53.716028: Epoch time: 6.41 s 
2024-12-15 01:02:53.719078: Yayy! New best EMA pseudo Dice: 0.8611999750137329 
2024-12-15 01:02:54.330518:  
2024-12-15 01:02:54.336035: Epoch 15 
2024-12-15 01:02:54.339545: Current learning rate: 0.00864 
2024-12-15 01:03:00.911509: train_loss -0.8529 
2024-12-15 01:03:00.917141: val_loss -0.8464 
2024-12-15 01:03:00.920654: Pseudo dice [np.float32(0.8935), np.float32(0.8768)] 
2024-12-15 01:03:00.924162: Epoch time: 6.58 s 
2024-12-15 01:03:00.927179: Yayy! New best EMA pseudo Dice: 0.8636000156402588 
2024-12-15 01:03:01.541343:  
2024-12-15 01:03:01.546391: Epoch 16 
2024-12-15 01:03:01.549907: Current learning rate: 0.00855 
2024-12-15 01:03:08.082115: train_loss -0.8534 
2024-12-15 01:03:08.088232: val_loss -0.8465 
2024-12-15 01:03:08.092260: Pseudo dice [np.float32(0.8942), np.float32(0.8763)] 
2024-12-15 01:03:08.095274: Epoch time: 6.54 s 
2024-12-15 01:03:08.098786: Yayy! New best EMA pseudo Dice: 0.8658000230789185 
2024-12-15 01:03:08.732228:  
2024-12-15 01:03:08.737259: Epoch 17 
2024-12-15 01:03:08.740072: Current learning rate: 0.00846 
2024-12-15 01:03:15.293430: train_loss -0.8537 
2024-12-15 01:03:15.298537: val_loss -0.8485 
2024-12-15 01:03:15.305217: Pseudo dice [np.float32(0.8952), np.float32(0.8767)] 
2024-12-15 01:03:15.310302: Epoch time: 6.56 s 
2024-12-15 01:03:15.314343: Yayy! New best EMA pseudo Dice: 0.8677999973297119 
2024-12-15 01:03:15.935041:  
2024-12-15 01:03:15.940055: Epoch 18 
2024-12-15 01:03:15.943568: Current learning rate: 0.00836 
2024-12-15 01:03:22.822410: train_loss -0.8551 
2024-12-15 01:03:22.828591: val_loss -0.8486 
2024-12-15 01:03:22.831737: Pseudo dice [np.float32(0.8942), np.float32(0.8768)] 
2024-12-15 01:03:22.835301: Epoch time: 6.89 s 
2024-12-15 01:03:22.838873: Yayy! New best EMA pseudo Dice: 0.8694999814033508 
2024-12-15 01:03:23.457581:  
2024-12-15 01:03:23.462660: Epoch 19 
2024-12-15 01:03:23.466217: Current learning rate: 0.00827 
2024-12-15 01:03:30.157973: train_loss -0.8575 
2024-12-15 01:03:30.163022: val_loss -0.8452 
2024-12-15 01:03:30.166532: Pseudo dice [np.float32(0.8921), np.float32(0.8751)] 
2024-12-15 01:03:30.169556: Epoch time: 6.7 s 
2024-12-15 01:03:30.172642: Yayy! New best EMA pseudo Dice: 0.8708999752998352 
2024-12-15 01:03:30.797423:  
2024-12-15 01:03:30.803953: Epoch 20 
2024-12-15 01:03:30.807472: Current learning rate: 0.00818 
2024-12-15 01:03:37.303994: train_loss -0.8607 
2024-12-15 01:03:37.309562: val_loss -0.8494 
2024-12-15 01:03:37.312704: Pseudo dice [np.float32(0.8949), np.float32(0.8782)] 
2024-12-15 01:03:37.315775: Epoch time: 6.51 s 
2024-12-15 01:03:37.318825: Yayy! New best EMA pseudo Dice: 0.8725000023841858 
2024-12-15 01:03:38.088117:  
2024-12-15 01:03:38.093171: Epoch 21 
2024-12-15 01:03:38.096238: Current learning rate: 0.00809 
2024-12-15 01:03:44.793527: train_loss -0.8568 
2024-12-15 01:03:44.799114: val_loss -0.8534 
2024-12-15 01:03:44.802123: Pseudo dice [np.float32(0.8979), np.float32(0.8827)] 
2024-12-15 01:03:44.805664: Epoch time: 6.71 s 
2024-12-15 01:03:44.808728: Yayy! New best EMA pseudo Dice: 0.8743000030517578 
2024-12-15 01:03:45.553190:  
2024-12-15 01:03:45.558208: Epoch 22 
2024-12-15 01:03:45.561719: Current learning rate: 0.008 
2024-12-15 01:03:51.950331: train_loss -0.8611 
2024-12-15 01:03:51.955398: val_loss -0.8487 
2024-12-15 01:03:51.958686: Pseudo dice [np.float32(0.8955), np.float32(0.8777)] 
2024-12-15 01:03:51.961810: Epoch time: 6.4 s 
2024-12-15 01:03:51.965320: Yayy! New best EMA pseudo Dice: 0.8755000233650208 
2024-12-15 01:03:52.545410:  
2024-12-15 01:03:52.550357: Epoch 23 
2024-12-15 01:03:52.553869: Current learning rate: 0.0079 
2024-12-15 01:03:58.926501: train_loss -0.8596 
2024-12-15 01:03:58.932106: val_loss -0.8493 
2024-12-15 01:03:58.935143: Pseudo dice [np.float32(0.8953), np.float32(0.8774)] 
2024-12-15 01:03:58.938673: Epoch time: 6.38 s 
2024-12-15 01:03:58.941737: Yayy! New best EMA pseudo Dice: 0.8766000270843506 
2024-12-15 01:03:59.521104:  
2024-12-15 01:03:59.526670: Epoch 24 
2024-12-15 01:03:59.530223: Current learning rate: 0.00781 
2024-12-15 01:04:05.884826: train_loss -0.8635 
2024-12-15 01:04:05.889880: val_loss -0.847 
2024-12-15 01:04:05.893920: Pseudo dice [np.float32(0.8935), np.float32(0.8766)] 
2024-12-15 01:04:05.897035: Epoch time: 6.36 s 
2024-12-15 01:04:05.899542: Yayy! New best EMA pseudo Dice: 0.8774999976158142 
2024-12-15 01:04:06.491969:  
2024-12-15 01:04:06.497512: Epoch 25 
2024-12-15 01:04:06.500548: Current learning rate: 0.00772 
2024-12-15 01:04:12.886472: train_loss -0.8625 
2024-12-15 01:04:12.893036: val_loss -0.8519 
2024-12-15 01:04:12.896065: Pseudo dice [np.float32(0.8976), np.float32(0.8789)] 
2024-12-15 01:04:12.899165: Epoch time: 6.4 s 
2024-12-15 01:04:12.902227: Yayy! New best EMA pseudo Dice: 0.8784999847412109 
2024-12-15 01:04:13.481508:  
2024-12-15 01:04:13.487024: Epoch 26 
2024-12-15 01:04:13.490534: Current learning rate: 0.00763 
2024-12-15 01:04:19.868130: train_loss -0.8624 
2024-12-15 01:04:19.873696: val_loss -0.8452 
2024-12-15 01:04:19.877207: Pseudo dice [np.float32(0.8944), np.float32(0.8751)] 
2024-12-15 01:04:19.880237: Epoch time: 6.39 s 
2024-12-15 01:04:19.883289: Yayy! New best EMA pseudo Dice: 0.8791999816894531 
2024-12-15 01:04:20.461649:  
2024-12-15 01:04:20.467164: Epoch 27 
2024-12-15 01:04:20.470678: Current learning rate: 0.00753 
2024-12-15 01:04:26.850188: train_loss -0.8635 
2024-12-15 01:04:26.855200: val_loss -0.8509 
2024-12-15 01:04:26.859211: Pseudo dice [np.float32(0.8983), np.float32(0.876)] 
2024-12-15 01:04:26.862259: Epoch time: 6.39 s 
2024-12-15 01:04:26.864298: Yayy! New best EMA pseudo Dice: 0.8799999952316284 
2024-12-15 01:04:27.447473:  
2024-12-15 01:04:27.452533: Epoch 28 
2024-12-15 01:04:27.455585: Current learning rate: 0.00744 
2024-12-15 01:04:33.829642: train_loss -0.8657 
2024-12-15 01:04:33.835299: val_loss -0.8486 
2024-12-15 01:04:33.838853: Pseudo dice [np.float32(0.8951), np.float32(0.8764)] 
2024-12-15 01:04:33.841898: Epoch time: 6.38 s 
2024-12-15 01:04:33.844950: Yayy! New best EMA pseudo Dice: 0.8805000185966492 
2024-12-15 01:04:34.570655:  
2024-12-15 01:04:34.574681: Epoch 29 
2024-12-15 01:04:34.577210: Current learning rate: 0.00735 
2024-12-15 01:04:40.943457: train_loss -0.8649 
2024-12-15 01:04:40.948520: val_loss -0.8548 
2024-12-15 01:04:40.952118: Pseudo dice [np.float32(0.8987), np.float32(0.8831)] 
2024-12-15 01:04:40.955158: Epoch time: 6.37 s 
2024-12-15 01:04:40.958199: Yayy! New best EMA pseudo Dice: 0.881600022315979 
2024-12-15 01:04:41.547512:  
2024-12-15 01:04:41.551566: Epoch 30 
2024-12-15 01:04:41.554122: Current learning rate: 0.00725 
2024-12-15 01:04:47.917338: train_loss -0.8672 
2024-12-15 01:04:47.923458: val_loss -0.8529 
2024-12-15 01:04:47.927519: Pseudo dice [np.float32(0.8967), np.float32(0.8809)] 
2024-12-15 01:04:47.930637: Epoch time: 6.37 s 
2024-12-15 01:04:47.933683: Yayy! New best EMA pseudo Dice: 0.8823000192642212 
2024-12-15 01:04:48.524822:  
2024-12-15 01:04:48.529834: Epoch 31 
2024-12-15 01:04:48.533346: Current learning rate: 0.00716 
2024-12-15 01:04:55.083932: train_loss -0.8685 
2024-12-15 01:04:55.089079: val_loss -0.8486 
2024-12-15 01:04:55.092136: Pseudo dice [np.float32(0.8961), np.float32(0.8774)] 
2024-12-15 01:04:55.094671: Epoch time: 6.56 s 
2024-12-15 01:04:55.097718: Yayy! New best EMA pseudo Dice: 0.8827000260353088 
2024-12-15 01:04:55.710552:  
2024-12-15 01:04:55.716069: Epoch 32 
2024-12-15 01:04:55.718575: Current learning rate: 0.00707 
2024-12-15 01:05:02.293111: train_loss -0.8669 
2024-12-15 01:05:02.299363: val_loss -0.8499 
2024-12-15 01:05:02.302456: Pseudo dice [np.float32(0.8975), np.float32(0.8789)] 
2024-12-15 01:05:02.305557: Epoch time: 6.58 s 
2024-12-15 01:05:02.308596: Yayy! New best EMA pseudo Dice: 0.8833000063896179 
2024-12-15 01:05:02.916641:  
2024-12-15 01:05:02.922203: Epoch 33 
2024-12-15 01:05:02.925306: Current learning rate: 0.00697 
2024-12-15 01:05:09.522890: train_loss -0.8683 
2024-12-15 01:05:09.529975: val_loss -0.8532 
2024-12-15 01:05:09.533529: Pseudo dice [np.float32(0.8977), np.float32(0.883)] 
2024-12-15 01:05:09.537173: Epoch time: 6.61 s 
2024-12-15 01:05:09.540255: Yayy! New best EMA pseudo Dice: 0.8840000033378601 
2024-12-15 01:05:10.163360:  
2024-12-15 01:05:10.168373: Epoch 34 
2024-12-15 01:05:10.171886: Current learning rate: 0.00688 
2024-12-15 01:05:16.949085: train_loss -0.8697 
2024-12-15 01:05:16.955193: val_loss -0.8486 
2024-12-15 01:05:16.958804: Pseudo dice [np.float32(0.8968), np.float32(0.8772)] 
2024-12-15 01:05:16.961851: Epoch time: 6.79 s 
2024-12-15 01:05:16.964930: Yayy! New best EMA pseudo Dice: 0.8842999935150146 
2024-12-15 01:05:17.591304:  
2024-12-15 01:05:17.597818: Epoch 35 
2024-12-15 01:05:17.601328: Current learning rate: 0.00679 
2024-12-15 01:05:24.203676: train_loss -0.8699 
2024-12-15 01:05:24.209280: val_loss -0.85 
2024-12-15 01:05:24.212391: Pseudo dice [np.float32(0.895), np.float32(0.8798)] 
2024-12-15 01:05:24.215949: Epoch time: 6.61 s 
2024-12-15 01:05:24.218506: Yayy! New best EMA pseudo Dice: 0.8845999836921692 
2024-12-15 01:05:24.976429:  
2024-12-15 01:05:24.981948: Epoch 36 
2024-12-15 01:05:24.985460: Current learning rate: 0.00669 
2024-12-15 01:05:31.533052: train_loss -0.8698 
2024-12-15 01:05:31.539226: val_loss -0.8472 
2024-12-15 01:05:31.542796: Pseudo dice [np.float32(0.8935), np.float32(0.8782)] 
2024-12-15 01:05:31.545864: Epoch time: 6.56 s 
2024-12-15 01:05:31.549405: Yayy! New best EMA pseudo Dice: 0.8847000002861023 
2024-12-15 01:05:32.193854:  
2024-12-15 01:05:32.199432: Epoch 37 
2024-12-15 01:05:32.202046: Current learning rate: 0.0066 
2024-12-15 01:05:38.714327: train_loss -0.8708 
2024-12-15 01:05:38.719433: val_loss -0.8514 
2024-12-15 01:05:38.723001: Pseudo dice [np.float32(0.898), np.float32(0.8821)] 
2024-12-15 01:05:38.726103: Epoch time: 6.52 s 
2024-12-15 01:05:38.729198: Yayy! New best EMA pseudo Dice: 0.8852999806404114 
2024-12-15 01:05:39.338243:  
2024-12-15 01:05:39.343762: Epoch 38 
2024-12-15 01:05:39.347279: Current learning rate: 0.0065 
2024-12-15 01:05:45.879555: train_loss -0.874 
2024-12-15 01:05:45.886411: val_loss -0.8482 
2024-12-15 01:05:45.890004: Pseudo dice [np.float32(0.8959), np.float32(0.8769)] 
2024-12-15 01:05:45.892546: Epoch time: 6.54 s 
2024-12-15 01:05:45.896091: Yayy! New best EMA pseudo Dice: 0.8853999972343445 
2024-12-15 01:05:46.529894:  
2024-12-15 01:05:46.536416: Epoch 39 
2024-12-15 01:05:46.539932: Current learning rate: 0.00641 
2024-12-15 01:05:53.450511: train_loss -0.8743 
2024-12-15 01:05:53.456581: val_loss -0.8494 
2024-12-15 01:05:53.460136: Pseudo dice [np.float32(0.897), np.float32(0.8776)] 
2024-12-15 01:05:53.463164: Epoch time: 6.92 s 
2024-12-15 01:05:53.465684: Yayy! New best EMA pseudo Dice: 0.8855999708175659 
2024-12-15 01:05:54.095835:  
2024-12-15 01:05:54.098851: Epoch 40 
2024-12-15 01:05:54.102874: Current learning rate: 0.00631 
2024-12-15 01:06:00.606275: train_loss -0.8756 
2024-12-15 01:06:00.612319: val_loss -0.857 
2024-12-15 01:06:00.616333: Pseudo dice [np.float32(0.9007), np.float32(0.886)] 
2024-12-15 01:06:00.618842: Epoch time: 6.51 s 
2024-12-15 01:06:00.622391: Yayy! New best EMA pseudo Dice: 0.8863000273704529 
2024-12-15 01:06:01.254636:  
2024-12-15 01:06:01.259663: Epoch 41 
2024-12-15 01:06:01.263253: Current learning rate: 0.00622 
2024-12-15 01:06:07.728319: train_loss -0.8703 
2024-12-15 01:06:07.733492: val_loss -0.8443 
2024-12-15 01:06:07.737038: Pseudo dice [np.float32(0.8942), np.float32(0.873)] 
2024-12-15 01:06:07.741050: Epoch time: 6.47 s 
2024-12-15 01:06:08.290771:  
2024-12-15 01:06:08.297204: Epoch 42 
2024-12-15 01:06:08.300715: Current learning rate: 0.00612 
2024-12-15 01:06:14.740191: train_loss -0.8746 
2024-12-15 01:06:14.745713: val_loss -0.8512 
2024-12-15 01:06:14.749228: Pseudo dice [np.float32(0.8969), np.float32(0.8803)] 
2024-12-15 01:06:14.752346: Epoch time: 6.45 s 
2024-12-15 01:06:15.311336:  
2024-12-15 01:06:15.316346: Epoch 43 
2024-12-15 01:06:15.318851: Current learning rate: 0.00603 
2024-12-15 01:06:21.708669: train_loss -0.8741 
2024-12-15 01:06:21.714749: val_loss -0.854 
2024-12-15 01:06:21.717800: Pseudo dice [np.float32(0.8995), np.float32(0.8813)] 
2024-12-15 01:06:21.720925: Epoch time: 6.4 s 
2024-12-15 01:06:21.724014: Yayy! New best EMA pseudo Dice: 0.8866999745368958 
2024-12-15 01:06:22.461289:  
2024-12-15 01:06:22.466833: Epoch 44 
2024-12-15 01:06:22.470348: Current learning rate: 0.00593 
2024-12-15 01:06:28.963008: train_loss -0.8758 
2024-12-15 01:06:28.968593: val_loss -0.8531 
2024-12-15 01:06:28.972133: Pseudo dice [np.float32(0.8991), np.float32(0.8812)] 
2024-12-15 01:06:28.975069: Epoch time: 6.5 s 
2024-12-15 01:06:28.977587: Yayy! New best EMA pseudo Dice: 0.8870999813079834 
2024-12-15 01:06:29.570959:  
2024-12-15 01:06:29.576477: Epoch 45 
2024-12-15 01:06:29.578984: Current learning rate: 0.00584 
2024-12-15 01:06:36.055879: train_loss -0.8781 
2024-12-15 01:06:36.060483: val_loss -0.856 
2024-12-15 01:06:36.064604: Pseudo dice [np.float32(0.9022), np.float32(0.8836)] 
2024-12-15 01:06:36.068161: Epoch time: 6.49 s 
2024-12-15 01:06:36.071300: Yayy! New best EMA pseudo Dice: 0.8877000212669373 
2024-12-15 01:06:36.650481:  
2024-12-15 01:06:36.655501: Epoch 46 
2024-12-15 01:06:36.659011: Current learning rate: 0.00574 
2024-12-15 01:06:43.098386: train_loss -0.8783 
2024-12-15 01:06:43.104407: val_loss -0.8485 
2024-12-15 01:06:43.108153: Pseudo dice [np.float32(0.8962), np.float32(0.8787)] 
2024-12-15 01:06:43.111195: Epoch time: 6.45 s 
2024-12-15 01:06:43.655854:  
2024-12-15 01:06:43.661463: Epoch 47 
2024-12-15 01:06:43.665049: Current learning rate: 0.00565 
2024-12-15 01:06:50.094532: train_loss -0.8795 
2024-12-15 01:06:50.100609: val_loss -0.8544 
2024-12-15 01:06:50.103127: Pseudo dice [np.float32(0.9002), np.float32(0.8835)] 
2024-12-15 01:06:50.106652: Epoch time: 6.44 s 
2024-12-15 01:06:50.109760: Yayy! New best EMA pseudo Dice: 0.8880000114440918 
2024-12-15 01:06:50.691023:  
2024-12-15 01:06:50.696616: Epoch 48 
2024-12-15 01:06:50.699185: Current learning rate: 0.00555 
2024-12-15 01:06:57.133898: train_loss -0.877 
2024-12-15 01:06:57.138968: val_loss -0.8549 
2024-12-15 01:06:57.143030: Pseudo dice [np.float32(0.8979), np.float32(0.8835)] 
2024-12-15 01:06:57.146043: Epoch time: 6.44 s 
2024-12-15 01:06:57.149559: Yayy! New best EMA pseudo Dice: 0.8883000016212463 
2024-12-15 01:06:57.744976:  
2024-12-15 01:06:57.750610: Epoch 49 
2024-12-15 01:06:57.754161: Current learning rate: 0.00546 
2024-12-15 01:07:04.180876: train_loss -0.8796 
2024-12-15 01:07:04.185947: val_loss -0.8484 
2024-12-15 01:07:04.189640: Pseudo dice [np.float32(0.8962), np.float32(0.8778)] 
2024-12-15 01:07:04.193175: Epoch time: 6.44 s 
2024-12-15 01:07:04.778892:  
2024-12-15 01:07:04.783914: Epoch 50 
2024-12-15 01:07:04.786428: Current learning rate: 0.00536 
2024-12-15 01:07:11.313965: train_loss -0.8803 
2024-12-15 01:07:11.319991: val_loss -0.851 
2024-12-15 01:07:11.323110: Pseudo dice [np.float32(0.898), np.float32(0.8803)] 
2024-12-15 01:07:11.325823: Epoch time: 6.54 s 
2024-12-15 01:07:11.889742:  
2024-12-15 01:07:11.894756: Epoch 51 
2024-12-15 01:07:11.898268: Current learning rate: 0.00526 
2024-12-15 01:07:18.392037: train_loss -0.88 
2024-12-15 01:07:18.398096: val_loss -0.8501 
2024-12-15 01:07:18.401138: Pseudo dice [np.float32(0.8958), np.float32(0.8812)] 
2024-12-15 01:07:18.404180: Epoch time: 6.5 s 
2024-12-15 01:07:18.953055:  
2024-12-15 01:07:18.958609: Epoch 52 
2024-12-15 01:07:18.961740: Current learning rate: 0.00517 
2024-12-15 01:07:25.388261: train_loss -0.8796 
2024-12-15 01:07:25.393883: val_loss -0.8556 
2024-12-15 01:07:25.397448: Pseudo dice [np.float32(0.9017), np.float32(0.8834)] 
2024-12-15 01:07:25.400063: Epoch time: 6.44 s 
2024-12-15 01:07:25.404102: Yayy! New best EMA pseudo Dice: 0.888700008392334 
2024-12-15 01:07:26.155802:  
2024-12-15 01:07:26.161932: Epoch 53 
2024-12-15 01:07:26.164965: Current learning rate: 0.00507 
2024-12-15 01:07:32.580102: train_loss -0.8806 
2024-12-15 01:07:32.585747: val_loss -0.8551 
2024-12-15 01:07:32.589369: Pseudo dice [np.float32(0.9022), np.float32(0.8816)] 
2024-12-15 01:07:32.592460: Epoch time: 6.42 s 
2024-12-15 01:07:32.594993: Yayy! New best EMA pseudo Dice: 0.8889999985694885 
2024-12-15 01:07:33.186344:  
2024-12-15 01:07:33.192392: Epoch 54 
2024-12-15 01:07:33.197633: Current learning rate: 0.00497 
2024-12-15 01:07:39.627251: train_loss -0.8814 
2024-12-15 01:07:39.632808: val_loss -0.8463 
2024-12-15 01:07:39.635840: Pseudo dice [np.float32(0.8925), np.float32(0.8756)] 
2024-12-15 01:07:39.639368: Epoch time: 6.44 s 
2024-12-15 01:07:40.199572:  
2024-12-15 01:07:40.205151: Epoch 55 
2024-12-15 01:07:40.207700: Current learning rate: 0.00487 
2024-12-15 01:07:46.609339: train_loss -0.8821 
2024-12-15 01:07:46.614926: val_loss -0.848 
2024-12-15 01:07:46.617980: Pseudo dice [np.float32(0.8944), np.float32(0.8777)] 
2024-12-15 01:07:46.620999: Epoch time: 6.41 s 
2024-12-15 01:07:47.181299:  
2024-12-15 01:07:47.186815: Epoch 56 
2024-12-15 01:07:47.189322: Current learning rate: 0.00478 
2024-12-15 01:07:53.559229: train_loss -0.8809 
2024-12-15 01:07:53.565286: val_loss -0.8535 
2024-12-15 01:07:53.568823: Pseudo dice [np.float32(0.9008), np.float32(0.8804)] 
2024-12-15 01:07:53.571844: Epoch time: 6.38 s 
2024-12-15 01:07:54.127544:  
2024-12-15 01:07:54.132557: Epoch 57 
2024-12-15 01:07:54.136069: Current learning rate: 0.00468 
2024-12-15 01:08:00.572166: train_loss -0.8826 
2024-12-15 01:08:00.578256: val_loss -0.8504 
2024-12-15 01:08:00.581811: Pseudo dice [np.float32(0.8962), np.float32(0.88)] 
2024-12-15 01:08:00.585850: Epoch time: 6.45 s 
2024-12-15 01:08:01.139091:  
2024-12-15 01:08:01.144114: Epoch 58 
2024-12-15 01:08:01.147149: Current learning rate: 0.00458 
2024-12-15 01:08:07.627753: train_loss -0.8834 
2024-12-15 01:08:07.633351: val_loss -0.8548 
2024-12-15 01:08:07.636972: Pseudo dice [np.float32(0.9), np.float32(0.8834)] 
2024-12-15 01:08:07.639535: Epoch time: 6.49 s 
2024-12-15 01:08:08.205557:  
2024-12-15 01:08:08.210570: Epoch 59 
2024-12-15 01:08:08.215588: Current learning rate: 0.00448 
2024-12-15 01:08:14.759168: train_loss -0.8838 
2024-12-15 01:08:14.765764: val_loss -0.8526 
2024-12-15 01:08:14.768814: Pseudo dice [np.float32(0.8981), np.float32(0.881)] 
2024-12-15 01:08:14.771908: Epoch time: 6.55 s 
2024-12-15 01:08:15.350636:  
2024-12-15 01:08:15.356674: Epoch 60 
2024-12-15 01:08:15.362691: Current learning rate: 0.00438 
2024-12-15 01:08:21.790051: train_loss -0.8852 
2024-12-15 01:08:21.796621: val_loss -0.8598 
2024-12-15 01:08:21.800201: Pseudo dice [np.float32(0.9043), np.float32(0.8864)] 
2024-12-15 01:08:21.803246: Epoch time: 6.44 s 
2024-12-15 01:08:21.806839: Yayy! New best EMA pseudo Dice: 0.8895000219345093 
2024-12-15 01:08:22.582692:  
2024-12-15 01:08:22.589334: Epoch 61 
2024-12-15 01:08:22.593421: Current learning rate: 0.00429 
2024-12-15 01:08:29.022588: train_loss -0.8843 
2024-12-15 01:08:29.028158: val_loss -0.8519 
2024-12-15 01:08:29.031689: Pseudo dice [np.float32(0.8981), np.float32(0.88)] 
2024-12-15 01:08:29.034726: Epoch time: 6.44 s 
2024-12-15 01:08:29.598024:  
2024-12-15 01:08:29.604048: Epoch 62 
2024-12-15 01:08:29.607557: Current learning rate: 0.00419 
2024-12-15 01:08:36.101234: train_loss -0.8867 
2024-12-15 01:08:36.106365: val_loss -0.8544 
2024-12-15 01:08:36.109922: Pseudo dice [np.float32(0.9008), np.float32(0.8829)] 
2024-12-15 01:08:36.112962: Epoch time: 6.5 s 
2024-12-15 01:08:36.116035: Yayy! New best EMA pseudo Dice: 0.8896999955177307 
2024-12-15 01:08:36.732984:  
2024-12-15 01:08:36.738551: Epoch 63 
2024-12-15 01:08:36.742031: Current learning rate: 0.00409 
2024-12-15 01:08:43.148886: train_loss -0.887 
2024-12-15 01:08:43.155047: val_loss -0.8551 
2024-12-15 01:08:43.158087: Pseudo dice [np.float32(0.9), np.float32(0.8837)] 
2024-12-15 01:08:43.160595: Epoch time: 6.42 s 
2024-12-15 01:08:43.164112: Yayy! New best EMA pseudo Dice: 0.8899000287055969 
2024-12-15 01:08:43.767047:  
2024-12-15 01:08:43.772561: Epoch 64 
2024-12-15 01:08:43.776069: Current learning rate: 0.00399 
2024-12-15 01:08:50.195318: train_loss -0.8845 
2024-12-15 01:08:50.201362: val_loss -0.8515 
2024-12-15 01:08:50.205070: Pseudo dice [np.float32(0.8997), np.float32(0.8816)] 
2024-12-15 01:08:50.207632: Epoch time: 6.43 s 
2024-12-15 01:08:50.211743: Yayy! New best EMA pseudo Dice: 0.8899999856948853 
2024-12-15 01:08:50.819113:  
2024-12-15 01:08:50.824130: Epoch 65 
2024-12-15 01:08:50.827411: Current learning rate: 0.00389 
2024-12-15 01:08:57.374311: train_loss -0.8852 
2024-12-15 01:08:57.379902: val_loss -0.8463 
2024-12-15 01:08:57.383006: Pseudo dice [np.float32(0.8953), np.float32(0.8763)] 
2024-12-15 01:08:57.386055: Epoch time: 6.56 s 
2024-12-15 01:08:57.965792:  
2024-12-15 01:08:57.972435: Epoch 66 
2024-12-15 01:08:57.975880: Current learning rate: 0.00379 
2024-12-15 01:09:04.447265: train_loss -0.8871 
2024-12-15 01:09:04.452484: val_loss -0.8537 
2024-12-15 01:09:04.456606: Pseudo dice [np.float32(0.9009), np.float32(0.8813)] 
2024-12-15 01:09:04.459658: Epoch time: 6.48 s 
2024-12-15 01:09:05.038646:  
2024-12-15 01:09:05.042698: Epoch 67 
2024-12-15 01:09:05.047327: Current learning rate: 0.00369 
2024-12-15 01:09:11.529496: train_loss -0.887 
2024-12-15 01:09:11.536118: val_loss -0.8524 
2024-12-15 01:09:11.540179: Pseudo dice [np.float32(0.8987), np.float32(0.8809)] 
2024-12-15 01:09:11.542724: Epoch time: 6.49 s 
2024-12-15 01:09:12.269670:  
2024-12-15 01:09:12.275190: Epoch 68 
2024-12-15 01:09:12.278203: Current learning rate: 0.00359 
2024-12-15 01:09:18.656847: train_loss -0.8888 
2024-12-15 01:09:18.662993: val_loss -0.8468 
2024-12-15 01:09:18.666512: Pseudo dice [np.float32(0.8944), np.float32(0.879)] 
2024-12-15 01:09:18.668722: Epoch time: 6.39 s 
2024-12-15 01:09:19.242823:  
2024-12-15 01:09:19.247835: Epoch 69 
2024-12-15 01:09:19.251346: Current learning rate: 0.00349 
2024-12-15 01:09:25.640118: train_loss -0.8882 
2024-12-15 01:09:25.645699: val_loss -0.8531 
2024-12-15 01:09:25.649254: Pseudo dice [np.float32(0.8985), np.float32(0.8832)] 
2024-12-15 01:09:25.652812: Epoch time: 6.4 s 
2024-12-15 01:09:26.255517:  
2024-12-15 01:09:26.262252: Epoch 70 
2024-12-15 01:09:26.266346: Current learning rate: 0.00338 
2024-12-15 01:09:32.758125: train_loss -0.8906 
2024-12-15 01:09:32.763765: val_loss -0.8489 
2024-12-15 01:09:32.767351: Pseudo dice [np.float32(0.8954), np.float32(0.8787)] 
2024-12-15 01:09:32.770368: Epoch time: 6.5 s 
2024-12-15 01:09:33.344632:  
2024-12-15 01:09:33.349666: Epoch 71 
2024-12-15 01:09:33.352422: Current learning rate: 0.00328 
2024-12-15 01:09:39.739379: train_loss -0.8888 
2024-12-15 01:09:39.744461: val_loss -0.8536 
2024-12-15 01:09:39.747519: Pseudo dice [np.float32(0.901), np.float32(0.8816)] 
2024-12-15 01:09:39.750046: Epoch time: 6.4 s 
2024-12-15 01:09:40.327255:  
2024-12-15 01:09:40.332818: Epoch 72 
2024-12-15 01:09:40.336441: Current learning rate: 0.00318 
2024-12-15 01:09:46.781742: train_loss -0.8875 
2024-12-15 01:09:46.787189: val_loss -0.8517 
2024-12-15 01:09:46.790755: Pseudo dice [np.float32(0.8986), np.float32(0.8824)] 
2024-12-15 01:09:46.794872: Epoch time: 6.45 s 
2024-12-15 01:09:47.363629:  
2024-12-15 01:09:47.369153: Epoch 73 
2024-12-15 01:09:47.371664: Current learning rate: 0.00308 
2024-12-15 01:09:53.759608: train_loss -0.8903 
2024-12-15 01:09:53.765290: val_loss -0.8492 
2024-12-15 01:09:53.768396: Pseudo dice [np.float32(0.8969), np.float32(0.8791)] 
2024-12-15 01:09:53.771035: Epoch time: 6.4 s 
2024-12-15 01:09:54.339271:  
2024-12-15 01:09:54.344844: Epoch 74 
2024-12-15 01:09:54.348432: Current learning rate: 0.00297 
2024-12-15 01:10:00.783545: train_loss -0.8907 
2024-12-15 01:10:00.789130: val_loss -0.8512 
2024-12-15 01:10:00.792723: Pseudo dice [np.float32(0.8996), np.float32(0.8798)] 
2024-12-15 01:10:00.795236: Epoch time: 6.44 s 
2024-12-15 01:10:01.364497:  
2024-12-15 01:10:01.370086: Epoch 75 
2024-12-15 01:10:01.372654: Current learning rate: 0.00287 
2024-12-15 01:10:07.791446: train_loss -0.8915 
2024-12-15 01:10:07.797040: val_loss -0.8454 
2024-12-15 01:10:07.799714: Pseudo dice [np.float32(0.8955), np.float32(0.877)] 
2024-12-15 01:10:07.803229: Epoch time: 6.43 s 
2024-12-15 01:10:08.531019:  
2024-12-15 01:10:08.537116: Epoch 76 
2024-12-15 01:10:08.540642: Current learning rate: 0.00277 
2024-12-15 01:10:14.985590: train_loss -0.8916 
2024-12-15 01:10:14.992283: val_loss -0.8562 
2024-12-15 01:10:14.995404: Pseudo dice [np.float32(0.9016), np.float32(0.8853)] 
2024-12-15 01:10:14.998959: Epoch time: 6.46 s 
2024-12-15 01:10:15.577891:  
2024-12-15 01:10:15.582910: Epoch 77 
2024-12-15 01:10:15.586425: Current learning rate: 0.00266 
2024-12-15 01:10:22.041984: train_loss -0.8935 
2024-12-15 01:10:22.048583: val_loss -0.8505 
2024-12-15 01:10:22.051639: Pseudo dice [np.float32(0.8984), np.float32(0.8805)] 
2024-12-15 01:10:22.055151: Epoch time: 6.46 s 
2024-12-15 01:10:22.638672:  
2024-12-15 01:10:22.644202: Epoch 78 
2024-12-15 01:10:22.647212: Current learning rate: 0.00256 
2024-12-15 01:10:29.044145: train_loss -0.8921 
2024-12-15 01:10:29.050278: val_loss -0.8501 
2024-12-15 01:10:29.054354: Pseudo dice [np.float32(0.8975), np.float32(0.8807)] 
2024-12-15 01:10:29.057955: Epoch time: 6.41 s 
2024-12-15 01:10:29.639745:  
2024-12-15 01:10:29.645295: Epoch 79 
2024-12-15 01:10:29.648860: Current learning rate: 0.00245 
2024-12-15 01:10:36.048405: train_loss -0.8928 
2024-12-15 01:10:36.054478: val_loss -0.8471 
2024-12-15 01:10:36.058536: Pseudo dice [np.float32(0.8971), np.float32(0.8788)] 
2024-12-15 01:10:36.060593: Epoch time: 6.41 s 
2024-12-15 01:10:36.641134:  
2024-12-15 01:10:36.646191: Epoch 80 
2024-12-15 01:10:36.649732: Current learning rate: 0.00235 
2024-12-15 01:10:43.038821: train_loss -0.8934 
2024-12-15 01:10:43.043868: val_loss -0.8514 
2024-12-15 01:10:43.048399: Pseudo dice [np.float32(0.8974), np.float32(0.8808)] 
2024-12-15 01:10:43.051437: Epoch time: 6.4 s 
2024-12-15 01:10:43.636829:  
2024-12-15 01:10:43.641877: Epoch 81 
2024-12-15 01:10:43.644068: Current learning rate: 0.00224 
2024-12-15 01:10:50.113561: train_loss -0.8926 
2024-12-15 01:10:50.119149: val_loss -0.8518 
2024-12-15 01:10:50.122707: Pseudo dice [np.float32(0.8991), np.float32(0.8805)] 
2024-12-15 01:10:50.125730: Epoch time: 6.48 s 
2024-12-15 01:10:50.715879:  
2024-12-15 01:10:50.721542: Epoch 82 
2024-12-15 01:10:50.725085: Current learning rate: 0.00214 
2024-12-15 01:10:57.155424: train_loss -0.894 
2024-12-15 01:10:57.161009: val_loss -0.8483 
2024-12-15 01:10:57.164560: Pseudo dice [np.float32(0.8965), np.float32(0.8799)] 
2024-12-15 01:10:57.168089: Epoch time: 6.44 s 
2024-12-15 01:10:57.718730:  
2024-12-15 01:10:57.724274: Epoch 83 
2024-12-15 01:10:57.727834: Current learning rate: 0.00203 
2024-12-15 01:11:04.115685: train_loss -0.8933 
2024-12-15 01:11:04.122743: val_loss -0.8462 
2024-12-15 01:11:04.126304: Pseudo dice [np.float32(0.8959), np.float32(0.8753)] 
2024-12-15 01:11:04.128808: Epoch time: 6.4 s 
2024-12-15 01:11:04.838721:  
2024-12-15 01:11:04.845000: Epoch 84 
2024-12-15 01:11:04.848587: Current learning rate: 0.00192 
2024-12-15 01:11:11.242751: train_loss -0.8938 
2024-12-15 01:11:11.249391: val_loss -0.846 
2024-12-15 01:11:11.253048: Pseudo dice [np.float32(0.8959), np.float32(0.8763)] 
2024-12-15 01:11:11.255817: Epoch time: 6.4 s 
2024-12-15 01:11:11.823002:  
2024-12-15 01:11:11.827040: Epoch 85 
2024-12-15 01:11:11.832046: Current learning rate: 0.00181 
2024-12-15 01:11:18.276328: train_loss -0.8957 
2024-12-15 01:11:18.281389: val_loss -0.8522 
2024-12-15 01:11:18.285420: Pseudo dice [np.float32(0.8983), np.float32(0.8826)] 
2024-12-15 01:11:18.289442: Epoch time: 6.45 s 
2024-12-15 01:11:18.842553:  
2024-12-15 01:11:18.848071: Epoch 86 
2024-12-15 01:11:18.851100: Current learning rate: 0.0017 
2024-12-15 01:11:25.329668: train_loss -0.8948 
2024-12-15 01:11:25.334818: val_loss -0.8503 
2024-12-15 01:11:25.338911: Pseudo dice [np.float32(0.8985), np.float32(0.8795)] 
2024-12-15 01:11:25.341949: Epoch time: 6.49 s 
2024-12-15 01:11:25.892892:  
2024-12-15 01:11:25.898475: Epoch 87 
2024-12-15 01:11:25.901556: Current learning rate: 0.00159 
2024-12-15 01:11:32.344926: train_loss -0.896 
2024-12-15 01:11:32.351059: val_loss -0.8538 
2024-12-15 01:11:32.354175: Pseudo dice [np.float32(0.9005), np.float32(0.8815)] 
2024-12-15 01:11:32.357711: Epoch time: 6.45 s 
2024-12-15 01:11:32.918001:  
2024-12-15 01:11:32.923013: Epoch 88 
2024-12-15 01:11:32.926530: Current learning rate: 0.00148 
2024-12-15 01:11:39.403735: train_loss -0.8978 
2024-12-15 01:11:39.409816: val_loss -0.8526 
2024-12-15 01:11:39.412066: Pseudo dice [np.float32(0.9009), np.float32(0.8808)] 
2024-12-15 01:11:39.416119: Epoch time: 6.49 s 
2024-12-15 01:11:39.960789:  
2024-12-15 01:11:39.966844: Epoch 89 
2024-12-15 01:11:39.969881: Current learning rate: 0.00137 
2024-12-15 01:11:46.461801: train_loss -0.8953 
2024-12-15 01:11:46.467402: val_loss -0.8475 
2024-12-15 01:11:46.470915: Pseudo dice [np.float32(0.8977), np.float32(0.8753)] 
2024-12-15 01:11:46.473936: Epoch time: 6.5 s 
2024-12-15 01:11:47.030312:  
2024-12-15 01:11:47.035830: Epoch 90 
2024-12-15 01:11:47.038336: Current learning rate: 0.00126 
2024-12-15 01:11:53.601197: train_loss -0.8973 
2024-12-15 01:11:53.606731: val_loss -0.8495 
2024-12-15 01:11:53.609774: Pseudo dice [np.float32(0.8985), np.float32(0.8791)] 
2024-12-15 01:11:53.613288: Epoch time: 6.57 s 
2024-12-15 01:11:54.150746:  
2024-12-15 01:11:54.156363: Epoch 91 
2024-12-15 01:11:54.158912: Current learning rate: 0.00115 
2024-12-15 01:12:00.636270: train_loss -0.8965 
2024-12-15 01:12:00.643448: val_loss -0.8503 
2024-12-15 01:12:00.646497: Pseudo dice [np.float32(0.8982), np.float32(0.881)] 
2024-12-15 01:12:00.649538: Epoch time: 6.49 s 
2024-12-15 01:12:01.353156:  
2024-12-15 01:12:01.359182: Epoch 92 
2024-12-15 01:12:01.362692: Current learning rate: 0.00103 
2024-12-15 01:12:07.733576: train_loss -0.8973 
2024-12-15 01:12:07.739164: val_loss -0.8517 
2024-12-15 01:12:07.742195: Pseudo dice [np.float32(0.8984), np.float32(0.8814)] 
2024-12-15 01:12:07.745217: Epoch time: 6.38 s 
2024-12-15 01:12:08.291617:  
2024-12-15 01:12:08.296648: Epoch 93 
2024-12-15 01:12:08.301366: Current learning rate: 0.00091 
2024-12-15 01:12:14.686296: train_loss -0.8966 
2024-12-15 01:12:14.692410: val_loss -0.8479 
2024-12-15 01:12:14.695495: Pseudo dice [np.float32(0.8966), np.float32(0.8765)] 
2024-12-15 01:12:14.699057: Epoch time: 6.4 s 
2024-12-15 01:12:15.248334:  
2024-12-15 01:12:15.253943: Epoch 94 
2024-12-15 01:12:15.256475: Current learning rate: 0.00079 
2024-12-15 01:12:21.648685: train_loss -0.8986 
2024-12-15 01:12:21.654816: val_loss -0.8561 
2024-12-15 01:12:21.657851: Pseudo dice [np.float32(0.9017), np.float32(0.8843)] 
2024-12-15 01:12:21.660380: Epoch time: 6.4 s 
2024-12-15 01:12:22.206082:  
2024-12-15 01:12:22.211094: Epoch 95 
2024-12-15 01:12:22.214604: Current learning rate: 0.00067 
2024-12-15 01:12:28.701385: train_loss -0.8972 
2024-12-15 01:12:28.706518: val_loss -0.8479 
2024-12-15 01:12:28.710055: Pseudo dice [np.float32(0.8984), np.float32(0.8783)] 
2024-12-15 01:12:28.712831: Epoch time: 6.5 s 
2024-12-15 01:12:29.260267:  
2024-12-15 01:12:29.266297: Epoch 96 
2024-12-15 01:12:29.268808: Current learning rate: 0.00055 
2024-12-15 01:12:35.688130: train_loss -0.8979 
2024-12-15 01:12:35.693717: val_loss -0.851 
2024-12-15 01:12:35.696763: Pseudo dice [np.float32(0.9002), np.float32(0.8825)] 
2024-12-15 01:12:35.700300: Epoch time: 6.43 s 
2024-12-15 01:12:36.255088:  
2024-12-15 01:12:36.261207: Epoch 97 
2024-12-15 01:12:36.264264: Current learning rate: 0.00043 
2024-12-15 01:12:42.652599: train_loss -0.8994 
2024-12-15 01:12:42.658771: val_loss -0.8494 
2024-12-15 01:12:42.662359: Pseudo dice [np.float32(0.8985), np.float32(0.8807)] 
2024-12-15 01:12:42.665416: Epoch time: 6.4 s 
2024-12-15 01:12:43.221458:  
2024-12-15 01:12:43.226506: Epoch 98 
2024-12-15 01:12:43.229483: Current learning rate: 0.0003 
2024-12-15 01:12:49.685058: train_loss -0.8979 
2024-12-15 01:12:49.690077: val_loss -0.8486 
2024-12-15 01:12:49.694086: Pseudo dice [np.float32(0.8969), np.float32(0.8786)] 
2024-12-15 01:12:49.696594: Epoch time: 6.46 s 
2024-12-15 01:12:50.273175:  
2024-12-15 01:12:50.278228: Epoch 99 
2024-12-15 01:12:50.281743: Current learning rate: 0.00016 
2024-12-15 01:12:56.760929: train_loss -0.899 
2024-12-15 01:12:56.766487: val_loss -0.8444 
2024-12-15 01:12:56.770500: Pseudo dice [np.float32(0.8954), np.float32(0.8758)] 
2024-12-15 01:12:56.773575: Epoch time: 6.49 s 
2024-12-15 01:12:57.387513: Training done. 
2024-12-15 01:12:57.423514: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-15 01:12:57.431517: The split file contains 5 splits. 
2024-12-15 01:12:57.437518: Desired fold for training: 0 
2024-12-15 01:12:57.444029: This split has 208 training and 52 validation cases. 
2024-12-15 01:12:57.448028: predicting hippocampus_017 
2024-12-15 01:12:57.453030: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-15 01:12:57.572536: predicting hippocampus_019 
2024-12-15 01:12:57.579544: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-15 01:12:57.623539: predicting hippocampus_033 
2024-12-15 01:12:57.630546: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-15 01:12:57.655608: predicting hippocampus_035 
2024-12-15 01:12:57.661609: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-15 01:12:57.687608: predicting hippocampus_037 
2024-12-15 01:12:57.694611: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-15 01:12:57.720612: predicting hippocampus_049 
2024-12-15 01:12:57.727615: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-15 01:12:57.752829: predicting hippocampus_052 
2024-12-15 01:12:57.758830: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-15 01:12:57.784829: predicting hippocampus_065 
2024-12-15 01:12:57.791829: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-15 01:12:57.817829: predicting hippocampus_083 
2024-12-15 01:12:57.824828: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-15 01:12:57.853342: predicting hippocampus_088 
2024-12-15 01:12:57.859341: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-15 01:13:01.514751: predicting hippocampus_090 
2024-12-15 01:13:01.550261: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-15 01:13:01.607263: predicting hippocampus_092 
2024-12-15 01:13:01.626260: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-15 01:13:01.679771: predicting hippocampus_095 
2024-12-15 01:13:01.694771: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-15 01:13:01.752278: predicting hippocampus_107 
2024-12-15 01:13:01.759280: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-15 01:13:01.806278: predicting hippocampus_108 
2024-12-15 01:13:01.812280: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-15 01:13:01.847787: predicting hippocampus_123 
2024-12-15 01:13:01.854790: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-15 01:13:01.891788: predicting hippocampus_125 
2024-12-15 01:13:01.898789: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-15 01:13:01.961298: predicting hippocampus_157 
2024-12-15 01:13:01.967300: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-15 01:13:02.003298: predicting hippocampus_164 
2024-12-15 01:13:02.010298: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-15 01:13:02.088804: predicting hippocampus_169 
2024-12-15 01:13:02.095804: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-15 01:13:02.123804: predicting hippocampus_175 
2024-12-15 01:13:02.130810: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-15 01:13:02.161315: predicting hippocampus_185 
2024-12-15 01:13:02.167316: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-15 01:13:02.196315: predicting hippocampus_190 
2024-12-15 01:13:02.203315: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-15 01:13:02.230318: predicting hippocampus_194 
2024-12-15 01:13:02.237318: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-15 01:13:02.263823: predicting hippocampus_204 
2024-12-15 01:13:02.270823: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-15 01:13:02.299823: predicting hippocampus_205 
2024-12-15 01:13:02.306823: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-15 01:13:02.336826: predicting hippocampus_210 
2024-12-15 01:13:02.344335: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-15 01:13:02.374335: predicting hippocampus_217 
2024-12-15 01:13:02.381335: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-15 01:13:02.409335: predicting hippocampus_219 
2024-12-15 01:13:02.416335: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-15 01:13:02.442840: predicting hippocampus_229 
2024-12-15 01:13:02.448843: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-15 01:13:02.475842: predicting hippocampus_244 
2024-12-15 01:13:02.481843: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-15 01:13:02.512843: predicting hippocampus_261 
2024-12-15 01:13:02.518843: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-15 01:13:02.563351: predicting hippocampus_264 
2024-12-15 01:13:02.570351: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-15 01:13:02.598350: predicting hippocampus_277 
2024-12-15 01:13:02.605351: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-15 01:13:02.648857: predicting hippocampus_280 
2024-12-15 01:13:02.653857: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-15 01:13:02.681857: predicting hippocampus_286 
2024-12-15 01:13:02.687857: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-15 01:13:02.731859: predicting hippocampus_288 
2024-12-15 01:13:02.738859: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-15 01:13:02.780366: predicting hippocampus_289 
2024-12-15 01:13:02.788366: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-15 01:13:02.818367: predicting hippocampus_296 
2024-12-15 01:13:02.825366: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-15 01:13:02.856877: predicting hippocampus_305 
2024-12-15 01:13:02.864877: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-15 01:13:02.890877: predicting hippocampus_308 
2024-12-15 01:13:02.896877: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-15 01:13:02.923877: predicting hippocampus_317 
2024-12-15 01:13:02.929880: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-15 01:13:03.135895: predicting hippocampus_327 
2024-12-15 01:13:03.142400: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-15 01:13:03.165404: predicting hippocampus_330 
2024-12-15 01:13:03.170404: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-15 01:13:03.194404: predicting hippocampus_332 
2024-12-15 01:13:03.201404: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-15 01:13:03.227403: predicting hippocampus_338 
2024-12-15 01:13:03.233406: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-15 01:13:03.276911: predicting hippocampus_349 
2024-12-15 01:13:03.284911: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-15 01:13:03.312912: predicting hippocampus_350 
2024-12-15 01:13:03.318911: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-15 01:13:03.345419: predicting hippocampus_356 
2024-12-15 01:13:03.352419: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-15 01:13:03.383419: predicting hippocampus_358 
2024-12-15 01:13:03.390419: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-15 01:13:03.417419: predicting hippocampus_374 
2024-12-15 01:13:03.424419: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-15 01:13:03.451927: predicting hippocampus_394 
2024-12-15 01:13:03.457927: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-15 01:13:07.253055: Validation complete 
2024-12-15 01:13:07.259054: Mean Validation Dice:  0.8926940678002457 
