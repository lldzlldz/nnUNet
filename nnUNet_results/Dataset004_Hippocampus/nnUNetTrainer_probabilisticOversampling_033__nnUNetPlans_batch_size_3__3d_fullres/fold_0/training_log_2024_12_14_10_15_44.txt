2024-12-14 10:15:44.182564: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.33 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-14 10:15:44.186569: self.oversample_foreground_percent 0.3333333333333333 
2024-12-14 10:15:44.189078: do_dummy_2d_data_aug: False 
2024-12-14 10:15:44.200637: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-14 10:15:44.206640: The split file contains 5 splits. 
2024-12-14 10:15:44.209148: Desired fold for training: 0 
2024-12-14 10:15:44.212148: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_3_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 9, 'patch_size': [40, 56, 40], 'median_image_size_in_voxels': [36.0, 50.0, 35.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans_batch_size_3', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-14 10:15:50.389614: unpacking dataset... 
2024-12-14 10:15:51.177838: unpacking done... 
2024-12-14 10:15:52.250777:  
2024-12-14 10:15:52.255610: Epoch 0 
2024-12-14 10:15:52.259125: Current learning rate: 0.01 
2024-12-14 10:15:59.582527: train_loss -0.271 
2024-12-14 10:15:59.587627: val_loss -0.7453 
2024-12-14 10:15:59.591214: Pseudo dice [np.float32(0.8267), np.float32(0.8249)] 
2024-12-14 10:15:59.593757: Epoch time: 7.33 s 
2024-12-14 10:15:59.596266: Yayy! New best EMA pseudo Dice: 0.8258000016212463 
2024-12-14 10:16:00.111782:  
2024-12-14 10:16:00.116793: Epoch 1 
2024-12-14 10:16:00.120324: Current learning rate: 0.00991 
2024-12-14 10:16:06.521319: train_loss -0.7632 
2024-12-14 10:16:06.526425: val_loss -0.7999 
2024-12-14 10:16:06.528963: Pseudo dice [np.float32(0.8594), np.float32(0.8436)] 
2024-12-14 10:16:06.532500: Epoch time: 6.41 s 
2024-12-14 10:16:06.535551: Yayy! New best EMA pseudo Dice: 0.8284000158309937 
2024-12-14 10:16:07.107777:  
2024-12-14 10:16:07.111827: Epoch 2 
2024-12-14 10:16:07.116005: Current learning rate: 0.00982 
2024-12-14 10:16:13.516719: train_loss -0.799 
2024-12-14 10:16:13.522366: val_loss -0.8159 
2024-12-14 10:16:13.525441: Pseudo dice [np.float32(0.8697), np.float32(0.855)] 
2024-12-14 10:16:13.528144: Epoch time: 6.41 s 
2024-12-14 10:16:13.531702: Yayy! New best EMA pseudo Dice: 0.8317999839782715 
2024-12-14 10:16:14.136033:  
2024-12-14 10:16:14.141574: Epoch 3 
2024-12-14 10:16:14.144083: Current learning rate: 0.00973 
2024-12-14 10:16:20.539878: train_loss -0.8113 
2024-12-14 10:16:20.544939: val_loss -0.8294 
2024-12-14 10:16:20.548553: Pseudo dice [np.float32(0.8808), np.float32(0.8639)] 
2024-12-14 10:16:20.551640: Epoch time: 6.4 s 
2024-12-14 10:16:20.554724: Yayy! New best EMA pseudo Dice: 0.8357999920845032 
2024-12-14 10:16:21.131794:  
2024-12-14 10:16:21.137336: Epoch 4 
2024-12-14 10:16:21.140346: Current learning rate: 0.00964 
2024-12-14 10:16:27.529487: train_loss -0.8207 
2024-12-14 10:16:27.535100: val_loss -0.8262 
2024-12-14 10:16:27.538636: Pseudo dice [np.float32(0.879), np.float32(0.8613)] 
2024-12-14 10:16:27.541773: Epoch time: 6.4 s 
2024-12-14 10:16:27.544812: Yayy! New best EMA pseudo Dice: 0.8392000198364258 
2024-12-14 10:16:28.258233:  
2024-12-14 10:16:28.262741: Epoch 5 
2024-12-14 10:16:28.265751: Current learning rate: 0.00955 
2024-12-14 10:16:34.655887: train_loss -0.8277 
2024-12-14 10:16:34.662035: val_loss -0.8353 
2024-12-14 10:16:34.664557: Pseudo dice [np.float32(0.8853), np.float32(0.8694)] 
2024-12-14 10:16:34.668121: Epoch time: 6.4 s 
2024-12-14 10:16:34.671165: Yayy! New best EMA pseudo Dice: 0.8431000113487244 
2024-12-14 10:16:35.245332:  
2024-12-14 10:16:35.250846: Epoch 6 
2024-12-14 10:16:35.253353: Current learning rate: 0.00946 
2024-12-14 10:16:41.644804: train_loss -0.8317 
2024-12-14 10:16:41.649915: val_loss -0.8398 
2024-12-14 10:16:41.653966: Pseudo dice [np.float32(0.8906), np.float32(0.8704)] 
2024-12-14 10:16:41.657515: Epoch time: 6.4 s 
2024-12-14 10:16:41.660086: Yayy! New best EMA pseudo Dice: 0.8468000292778015 
2024-12-14 10:16:42.238950:  
2024-12-14 10:16:42.244992: Epoch 7 
2024-12-14 10:16:42.248034: Current learning rate: 0.00937 
2024-12-14 10:16:48.652337: train_loss -0.8354 
2024-12-14 10:16:48.657921: val_loss -0.8325 
2024-12-14 10:16:48.661458: Pseudo dice [np.float32(0.8836), np.float32(0.8634)] 
2024-12-14 10:16:48.664489: Epoch time: 6.41 s 
2024-12-14 10:16:48.667105: Yayy! New best EMA pseudo Dice: 0.8495000004768372 
2024-12-14 10:16:49.263017:  
2024-12-14 10:16:49.266595: Epoch 8 
2024-12-14 10:16:49.271180: Current learning rate: 0.00928 
2024-12-14 10:16:55.636997: train_loss -0.8395 
2024-12-14 10:16:55.642045: val_loss -0.8423 
2024-12-14 10:16:55.646070: Pseudo dice [np.float32(0.8932), np.float32(0.8722)] 
2024-12-14 10:16:55.648608: Epoch time: 6.37 s 
2024-12-14 10:16:55.652169: Yayy! New best EMA pseudo Dice: 0.8528000116348267 
2024-12-14 10:16:56.248827:  
2024-12-14 10:16:56.254382: Epoch 9 
2024-12-14 10:16:56.257433: Current learning rate: 0.00919 
2024-12-14 10:17:02.624750: train_loss -0.8422 
2024-12-14 10:17:02.631846: val_loss -0.846 
2024-12-14 10:17:02.634873: Pseudo dice [np.float32(0.8942), np.float32(0.8718)] 
2024-12-14 10:17:02.637902: Epoch time: 6.38 s 
2024-12-14 10:17:02.640930: Yayy! New best EMA pseudo Dice: 0.8557999730110168 
2024-12-14 10:17:03.205891:  
2024-12-14 10:17:03.211907: Epoch 10 
2024-12-14 10:17:03.214418: Current learning rate: 0.0091 
2024-12-14 10:17:09.590291: train_loss -0.8459 
2024-12-14 10:17:09.596356: val_loss -0.8391 
2024-12-14 10:17:09.598595: Pseudo dice [np.float32(0.8882), np.float32(0.8669)] 
2024-12-14 10:17:09.603196: Epoch time: 6.38 s 
2024-12-14 10:17:09.605703: Yayy! New best EMA pseudo Dice: 0.8579999804496765 
2024-12-14 10:17:10.181067:  
2024-12-14 10:17:10.186224: Epoch 11 
2024-12-14 10:17:10.189736: Current learning rate: 0.009 
2024-12-14 10:17:16.546778: train_loss -0.8455 
2024-12-14 10:17:16.552345: val_loss -0.8427 
2024-12-14 10:17:16.555228: Pseudo dice [np.float32(0.8903), np.float32(0.8737)] 
2024-12-14 10:17:16.558294: Epoch time: 6.37 s 
2024-12-14 10:17:16.561341: Yayy! New best EMA pseudo Dice: 0.8604000210762024 
2024-12-14 10:17:17.134425:  
2024-12-14 10:17:17.139454: Epoch 12 
2024-12-14 10:17:17.141978: Current learning rate: 0.00891 
2024-12-14 10:17:23.663696: train_loss -0.8481 
2024-12-14 10:17:23.668742: val_loss -0.8404 
2024-12-14 10:17:23.671772: Pseudo dice [np.float32(0.8897), np.float32(0.8711)] 
2024-12-14 10:17:23.674845: Epoch time: 6.53 s 
2024-12-14 10:17:23.677983: Yayy! New best EMA pseudo Dice: 0.8623999953269958 
2024-12-14 10:17:24.275515:  
2024-12-14 10:17:24.281080: Epoch 13 
2024-12-14 10:17:24.284125: Current learning rate: 0.00882 
2024-12-14 10:17:30.652429: train_loss -0.8498 
2024-12-14 10:17:30.657016: val_loss -0.8443 
2024-12-14 10:17:30.659562: Pseudo dice [np.float32(0.8923), np.float32(0.8747)] 
2024-12-14 10:17:30.663596: Epoch time: 6.38 s 
2024-12-14 10:17:30.666371: Yayy! New best EMA pseudo Dice: 0.8644999861717224 
2024-12-14 10:17:31.247503:  
2024-12-14 10:17:31.253015: Epoch 14 
2024-12-14 10:17:31.255520: Current learning rate: 0.00873 
2024-12-14 10:17:37.638481: train_loss -0.8532 
2024-12-14 10:17:37.644086: val_loss -0.8502 
2024-12-14 10:17:37.647157: Pseudo dice [np.float32(0.8977), np.float32(0.8777)] 
2024-12-14 10:17:37.649685: Epoch time: 6.39 s 
2024-12-14 10:17:37.653212: Yayy! New best EMA pseudo Dice: 0.8668000102043152 
2024-12-14 10:17:38.252304:  
2024-12-14 10:17:38.257342: Epoch 15 
2024-12-14 10:17:38.260109: Current learning rate: 0.00864 
2024-12-14 10:17:44.639034: train_loss -0.8552 
2024-12-14 10:17:44.645177: val_loss -0.8487 
2024-12-14 10:17:44.648106: Pseudo dice [np.float32(0.8971), np.float32(0.8781)] 
2024-12-14 10:17:44.651129: Epoch time: 6.39 s 
2024-12-14 10:17:44.654084: Yayy! New best EMA pseudo Dice: 0.8689000010490417 
2024-12-14 10:17:45.252148:  
2024-12-14 10:17:45.257170: Epoch 16 
2024-12-14 10:17:45.259685: Current learning rate: 0.00855 
2024-12-14 10:17:51.627223: train_loss -0.8551 
2024-12-14 10:17:51.632384: val_loss -0.8453 
2024-12-14 10:17:51.636038: Pseudo dice [np.float32(0.8938), np.float32(0.8729)] 
2024-12-14 10:17:51.639095: Epoch time: 6.38 s 
2024-12-14 10:17:51.641814: Yayy! New best EMA pseudo Dice: 0.8704000115394592 
2024-12-14 10:17:52.255083:  
2024-12-14 10:17:52.259645: Epoch 17 
2024-12-14 10:17:52.263191: Current learning rate: 0.00846 
2024-12-14 10:17:58.589631: train_loss -0.8577 
2024-12-14 10:17:58.596832: val_loss -0.8441 
2024-12-14 10:17:58.599867: Pseudo dice [np.float32(0.892), np.float32(0.8737)] 
2024-12-14 10:17:58.603421: Epoch time: 6.33 s 
2024-12-14 10:17:58.605954: Yayy! New best EMA pseudo Dice: 0.8715999722480774 
2024-12-14 10:17:59.205533:  
2024-12-14 10:17:59.211087: Epoch 18 
2024-12-14 10:17:59.214112: Current learning rate: 0.00836 
2024-12-14 10:18:05.541365: train_loss -0.8571 
2024-12-14 10:18:05.546950: val_loss -0.8483 
2024-12-14 10:18:05.550484: Pseudo dice [np.float32(0.8945), np.float32(0.8777)] 
2024-12-14 10:18:05.553545: Epoch time: 6.34 s 
2024-12-14 10:18:05.556578: Yayy! New best EMA pseudo Dice: 0.8730999827384949 
2024-12-14 10:18:06.155328:  
2024-12-14 10:18:06.161378: Epoch 19 
2024-12-14 10:18:06.164386: Current learning rate: 0.00827 
2024-12-14 10:18:12.498681: train_loss -0.8583 
2024-12-14 10:18:12.504254: val_loss -0.8533 
2024-12-14 10:18:12.508284: Pseudo dice [np.float32(0.9001), np.float32(0.8814)] 
2024-12-14 10:18:12.511323: Epoch time: 6.34 s 
2024-12-14 10:18:12.513860: Yayy! New best EMA pseudo Dice: 0.8748000264167786 
2024-12-14 10:18:13.248667:  
2024-12-14 10:18:13.254771: Epoch 20 
2024-12-14 10:18:13.257801: Current learning rate: 0.00818 
2024-12-14 10:18:19.583498: train_loss -0.8589 
2024-12-14 10:18:19.589051: val_loss -0.8477 
2024-12-14 10:18:19.592081: Pseudo dice [np.float32(0.8955), np.float32(0.8761)] 
2024-12-14 10:18:19.595570: Epoch time: 6.33 s 
2024-12-14 10:18:19.598600: Yayy! New best EMA pseudo Dice: 0.8758999705314636 
2024-12-14 10:18:20.211765:  
2024-12-14 10:18:20.216794: Epoch 21 
2024-12-14 10:18:20.220433: Current learning rate: 0.00809 
2024-12-14 10:18:26.561409: train_loss -0.8614 
2024-12-14 10:18:26.566987: val_loss -0.8434 
2024-12-14 10:18:26.569536: Pseudo dice [np.float32(0.8937), np.float32(0.875)] 
2024-12-14 10:18:26.573063: Epoch time: 6.35 s 
2024-12-14 10:18:26.575597: Yayy! New best EMA pseudo Dice: 0.876800000667572 
2024-12-14 10:18:27.152388:  
2024-12-14 10:18:27.158398: Epoch 22 
2024-12-14 10:18:27.161406: Current learning rate: 0.008 
2024-12-14 10:18:33.495245: train_loss -0.8623 
2024-12-14 10:18:33.500790: val_loss -0.8498 
2024-12-14 10:18:33.503336: Pseudo dice [np.float32(0.8973), np.float32(0.8786)] 
2024-12-14 10:18:33.506862: Epoch time: 6.34 s 
2024-12-14 10:18:33.509880: Yayy! New best EMA pseudo Dice: 0.8779000043869019 
2024-12-14 10:18:34.083012:  
2024-12-14 10:18:34.087535: Epoch 23 
2024-12-14 10:18:34.090601: Current learning rate: 0.0079 
2024-12-14 10:18:40.449077: train_loss -0.8624 
2024-12-14 10:18:40.454651: val_loss -0.8532 
2024-12-14 10:18:40.457661: Pseudo dice [np.float32(0.8985), np.float32(0.884)] 
2024-12-14 10:18:40.461233: Epoch time: 6.37 s 
2024-12-14 10:18:40.463739: Yayy! New best EMA pseudo Dice: 0.8791999816894531 
2024-12-14 10:18:41.030057:  
2024-12-14 10:18:41.034153: Epoch 24 
2024-12-14 10:18:41.036745: Current learning rate: 0.00781 
2024-12-14 10:18:47.389464: train_loss -0.8655 
2024-12-14 10:18:47.394572: val_loss -0.8481 
2024-12-14 10:18:47.397626: Pseudo dice [np.float32(0.8974), np.float32(0.8767)] 
2024-12-14 10:18:47.400164: Epoch time: 6.36 s 
2024-12-14 10:18:47.403190: Yayy! New best EMA pseudo Dice: 0.8799999952316284 
2024-12-14 10:18:47.974217:  
2024-12-14 10:18:47.979813: Epoch 25 
2024-12-14 10:18:47.982356: Current learning rate: 0.00772 
2024-12-14 10:18:54.339076: train_loss -0.8653 
2024-12-14 10:18:54.344664: val_loss -0.8487 
2024-12-14 10:18:54.348206: Pseudo dice [np.float32(0.8966), np.float32(0.8779)] 
2024-12-14 10:18:54.351252: Epoch time: 6.37 s 
2024-12-14 10:18:54.354289: Yayy! New best EMA pseudo Dice: 0.8806999921798706 
2024-12-14 10:18:54.934848:  
2024-12-14 10:18:54.939914: Epoch 26 
2024-12-14 10:18:54.942450: Current learning rate: 0.00763 
2024-12-14 10:19:01.299160: train_loss -0.8655 
2024-12-14 10:19:01.306231: val_loss -0.8455 
2024-12-14 10:19:01.309259: Pseudo dice [np.float32(0.8937), np.float32(0.8764)] 
2024-12-14 10:19:01.312288: Epoch time: 6.36 s 
2024-12-14 10:19:01.314382: Yayy! New best EMA pseudo Dice: 0.8812000155448914 
2024-12-14 10:19:01.889701:  
2024-12-14 10:19:01.894742: Epoch 27 
2024-12-14 10:19:01.897250: Current learning rate: 0.00753 
2024-12-14 10:19:08.206308: train_loss -0.8667 
2024-12-14 10:19:08.211952: val_loss -0.8475 
2024-12-14 10:19:08.214998: Pseudo dice [np.float32(0.8957), np.float32(0.8756)] 
2024-12-14 10:19:08.218551: Epoch time: 6.32 s 
2024-12-14 10:19:08.221599: Yayy! New best EMA pseudo Dice: 0.881600022315979 
2024-12-14 10:19:08.948723:  
2024-12-14 10:19:08.954240: Epoch 28 
2024-12-14 10:19:08.957752: Current learning rate: 0.00744 
2024-12-14 10:19:15.286411: train_loss -0.8682 
2024-12-14 10:19:15.291987: val_loss -0.8506 
2024-12-14 10:19:15.295517: Pseudo dice [np.float32(0.8987), np.float32(0.8788)] 
2024-12-14 10:19:15.298869: Epoch time: 6.34 s 
2024-12-14 10:19:15.301890: Yayy! New best EMA pseudo Dice: 0.8823000192642212 
2024-12-14 10:19:15.878814:  
2024-12-14 10:19:15.883826: Epoch 29 
2024-12-14 10:19:15.886333: Current learning rate: 0.00735 
2024-12-14 10:19:22.217089: train_loss -0.8664 
2024-12-14 10:19:22.222786: val_loss -0.8535 
2024-12-14 10:19:22.225844: Pseudo dice [np.float32(0.8996), np.float32(0.8813)] 
2024-12-14 10:19:22.228613: Epoch time: 6.34 s 
2024-12-14 10:19:22.230623: Yayy! New best EMA pseudo Dice: 0.8830999732017517 
2024-12-14 10:19:22.824951:  
2024-12-14 10:19:22.829990: Epoch 30 
2024-12-14 10:19:22.833032: Current learning rate: 0.00725 
2024-12-14 10:19:29.159840: train_loss -0.8689 
2024-12-14 10:19:29.165449: val_loss -0.8509 
2024-12-14 10:19:29.168525: Pseudo dice [np.float32(0.8984), np.float32(0.8792)] 
2024-12-14 10:19:29.171579: Epoch time: 6.34 s 
2024-12-14 10:19:29.174635: Yayy! New best EMA pseudo Dice: 0.8837000131607056 
2024-12-14 10:19:29.759454:  
2024-12-14 10:19:29.764510: Epoch 31 
2024-12-14 10:19:29.767613: Current learning rate: 0.00716 
2024-12-14 10:19:36.114540: train_loss -0.871 
2024-12-14 10:19:36.120715: val_loss -0.8438 
2024-12-14 10:19:36.123758: Pseudo dice [np.float32(0.8938), np.float32(0.8742)] 
2024-12-14 10:19:36.127287: Epoch time: 6.36 s 
2024-12-14 10:19:36.130352: Yayy! New best EMA pseudo Dice: 0.8837000131607056 
2024-12-14 10:19:36.729016:  
2024-12-14 10:19:36.734033: Epoch 32 
2024-12-14 10:19:36.737552: Current learning rate: 0.00707 
2024-12-14 10:19:43.071609: train_loss -0.8703 
2024-12-14 10:19:43.076629: val_loss -0.8507 
2024-12-14 10:19:43.080145: Pseudo dice [np.float32(0.8972), np.float32(0.8789)] 
2024-12-14 10:19:43.083444: Epoch time: 6.34 s 
2024-12-14 10:19:43.085952: Yayy! New best EMA pseudo Dice: 0.8841999769210815 
2024-12-14 10:19:43.680300:  
2024-12-14 10:19:43.685312: Epoch 33 
2024-12-14 10:19:43.688823: Current learning rate: 0.00697 
2024-12-14 10:19:50.023481: train_loss -0.8717 
2024-12-14 10:19:50.029072: val_loss -0.847 
2024-12-14 10:19:50.032623: Pseudo dice [np.float32(0.8962), np.float32(0.8758)] 
2024-12-14 10:19:50.034156: Epoch time: 6.34 s 
2024-12-14 10:19:50.038211: Yayy! New best EMA pseudo Dice: 0.8842999935150146 
2024-12-14 10:19:50.667801:  
2024-12-14 10:19:50.671877: Epoch 34 
2024-12-14 10:19:50.676443: Current learning rate: 0.00688 
2024-12-14 10:19:56.992531: train_loss -0.8709 
2024-12-14 10:19:56.998096: val_loss -0.8511 
2024-12-14 10:19:57.001207: Pseudo dice [np.float32(0.8974), np.float32(0.8812)] 
2024-12-14 10:19:57.004312: Epoch time: 6.32 s 
2024-12-14 10:19:57.006876: Yayy! New best EMA pseudo Dice: 0.8848000168800354 
2024-12-14 10:19:57.605318:  
2024-12-14 10:19:57.609406: Epoch 35 
2024-12-14 10:19:57.613454: Current learning rate: 0.00679 
2024-12-14 10:20:03.928279: train_loss -0.8758 
2024-12-14 10:20:03.935365: val_loss -0.8495 
2024-12-14 10:20:03.939934: Pseudo dice [np.float32(0.8969), np.float32(0.8779)] 
2024-12-14 10:20:03.943030: Epoch time: 6.32 s 
2024-12-14 10:20:03.945564: Yayy! New best EMA pseudo Dice: 0.8851000070571899 
2024-12-14 10:20:04.690459:  
2024-12-14 10:20:04.695472: Epoch 36 
2024-12-14 10:20:04.698983: Current learning rate: 0.00669 
2024-12-14 10:20:11.033794: train_loss -0.8735 
2024-12-14 10:20:11.038824: val_loss -0.8497 
2024-12-14 10:20:11.042346: Pseudo dice [np.float32(0.8969), np.float32(0.8803)] 
2024-12-14 10:20:11.045372: Epoch time: 6.34 s 
2024-12-14 10:20:11.047931: Yayy! New best EMA pseudo Dice: 0.8853999972343445 
2024-12-14 10:20:11.641790:  
2024-12-14 10:20:11.646888: Epoch 37 
2024-12-14 10:20:11.650397: Current learning rate: 0.0066 
2024-12-14 10:20:17.974473: train_loss -0.8759 
2024-12-14 10:20:17.981022: val_loss -0.8431 
2024-12-14 10:20:17.984072: Pseudo dice [np.float32(0.8929), np.float32(0.8736)] 
2024-12-14 10:20:17.986581: Epoch time: 6.33 s 
2024-12-14 10:20:18.554917:  
2024-12-14 10:20:18.559543: Epoch 38 
2024-12-14 10:20:18.563564: Current learning rate: 0.0065 
2024-12-14 10:20:24.917058: train_loss -0.877 
2024-12-14 10:20:24.922675: val_loss -0.8501 
2024-12-14 10:20:24.925705: Pseudo dice [np.float32(0.8964), np.float32(0.8812)] 
2024-12-14 10:20:24.928869: Epoch time: 6.36 s 
2024-12-14 10:20:24.931427: Yayy! New best EMA pseudo Dice: 0.8855999708175659 
2024-12-14 10:20:25.532108:  
2024-12-14 10:20:25.537221: Epoch 39 
2024-12-14 10:20:25.539774: Current learning rate: 0.00641 
2024-12-14 10:20:31.878249: train_loss -0.8743 
2024-12-14 10:20:31.883807: val_loss -0.8533 
2024-12-14 10:20:31.886832: Pseudo dice [np.float32(0.8991), np.float32(0.882)] 
2024-12-14 10:20:31.890044: Epoch time: 6.35 s 
2024-12-14 10:20:31.892589: Yayy! New best EMA pseudo Dice: 0.8860999941825867 
2024-12-14 10:20:32.500133:  
2024-12-14 10:20:32.505101: Epoch 40 
2024-12-14 10:20:32.507609: Current learning rate: 0.00631 
2024-12-14 10:20:38.845025: train_loss -0.8758 
2024-12-14 10:20:38.851161: val_loss -0.8562 
2024-12-14 10:20:38.853711: Pseudo dice [np.float32(0.9026), np.float32(0.8821)] 
2024-12-14 10:20:38.857772: Epoch time: 6.35 s 
2024-12-14 10:20:38.860852: Yayy! New best EMA pseudo Dice: 0.8866999745368958 
2024-12-14 10:20:39.472780:  
2024-12-14 10:20:39.477299: Epoch 41 
2024-12-14 10:20:39.480354: Current learning rate: 0.00622 
2024-12-14 10:20:45.812316: train_loss -0.878 
2024-12-14 10:20:45.817365: val_loss -0.8548 
2024-12-14 10:20:45.820427: Pseudo dice [np.float32(0.9018), np.float32(0.8804)] 
2024-12-14 10:20:45.823467: Epoch time: 6.34 s 
2024-12-14 10:20:45.826497: Yayy! New best EMA pseudo Dice: 0.8870999813079834 
2024-12-14 10:20:46.400273:  
2024-12-14 10:20:46.405291: Epoch 42 
2024-12-14 10:20:46.407716: Current learning rate: 0.00612 
2024-12-14 10:20:52.743507: train_loss -0.878 
2024-12-14 10:20:52.749067: val_loss -0.8462 
2024-12-14 10:20:52.752089: Pseudo dice [np.float32(0.8961), np.float32(0.8771)] 
2024-12-14 10:20:52.755188: Epoch time: 6.34 s 
2024-12-14 10:20:53.296274:  
2024-12-14 10:20:53.300471: Epoch 43 
2024-12-14 10:20:53.304485: Current learning rate: 0.00603 
2024-12-14 10:20:59.652402: train_loss -0.8799 
2024-12-14 10:20:59.658464: val_loss -0.8524 
2024-12-14 10:20:59.660970: Pseudo dice [np.float32(0.8981), np.float32(0.879)] 
2024-12-14 10:20:59.664479: Epoch time: 6.36 s 
2024-12-14 10:20:59.667487: Yayy! New best EMA pseudo Dice: 0.8871999979019165 
2024-12-14 10:21:00.400334:  
2024-12-14 10:21:00.405357: Epoch 44 
2024-12-14 10:21:00.408379: Current learning rate: 0.00593 
2024-12-14 10:21:06.750602: train_loss -0.8791 
2024-12-14 10:21:06.755674: val_loss -0.8489 
2024-12-14 10:21:06.759203: Pseudo dice [np.float32(0.8978), np.float32(0.8772)] 
2024-12-14 10:21:06.762281: Epoch time: 6.35 s 
2024-12-14 10:21:06.765338: Yayy! New best EMA pseudo Dice: 0.8873000144958496 
2024-12-14 10:21:07.348057:  
2024-12-14 10:21:07.353087: Epoch 45 
2024-12-14 10:21:07.356035: Current learning rate: 0.00584 
2024-12-14 10:21:13.705267: train_loss -0.8808 
2024-12-14 10:21:13.710845: val_loss -0.8467 
2024-12-14 10:21:13.713621: Pseudo dice [np.float32(0.896), np.float32(0.8749)] 
2024-12-14 10:21:13.717133: Epoch time: 6.36 s 
2024-12-14 10:21:14.251380:  
2024-12-14 10:21:14.256445: Epoch 46 
2024-12-14 10:21:14.260020: Current learning rate: 0.00574 
2024-12-14 10:21:20.612319: train_loss -0.8811 
2024-12-14 10:21:20.617923: val_loss -0.8557 
2024-12-14 10:21:20.620973: Pseudo dice [np.float32(0.9016), np.float32(0.8844)] 
2024-12-14 10:21:20.624061: Epoch time: 6.36 s 
2024-12-14 10:21:20.626109: Yayy! New best EMA pseudo Dice: 0.8877000212669373 
2024-12-14 10:21:21.201378:  
2024-12-14 10:21:21.206950: Epoch 47 
2024-12-14 10:21:21.210026: Current learning rate: 0.00565 
2024-12-14 10:21:27.570511: train_loss -0.8809 
2024-12-14 10:21:27.576561: val_loss -0.8487 
2024-12-14 10:21:27.579618: Pseudo dice [np.float32(0.8974), np.float32(0.8761)] 
2024-12-14 10:21:27.582659: Epoch time: 6.37 s 
2024-12-14 10:21:28.119336:  
2024-12-14 10:21:28.124854: Epoch 48 
2024-12-14 10:21:28.127360: Current learning rate: 0.00555 
2024-12-14 10:21:34.457170: train_loss -0.882 
2024-12-14 10:21:34.463230: val_loss -0.8476 
2024-12-14 10:21:34.466239: Pseudo dice [np.float32(0.8968), np.float32(0.8759)] 
2024-12-14 10:21:34.469263: Epoch time: 6.34 s 
2024-12-14 10:21:35.023893:  
2024-12-14 10:21:35.029436: Epoch 49 
2024-12-14 10:21:35.033011: Current learning rate: 0.00546 
2024-12-14 10:21:41.388596: train_loss -0.8817 
2024-12-14 10:21:41.395227: val_loss -0.8452 
2024-12-14 10:21:41.397777: Pseudo dice [np.float32(0.8953), np.float32(0.8749)] 
2024-12-14 10:21:41.401335: Epoch time: 6.37 s 
2024-12-14 10:21:41.982235:  
2024-12-14 10:21:41.987782: Epoch 50 
2024-12-14 10:21:41.990328: Current learning rate: 0.00536 
2024-12-14 10:21:48.338715: train_loss -0.8829 
2024-12-14 10:21:48.344307: val_loss -0.848 
2024-12-14 10:21:48.347839: Pseudo dice [np.float32(0.8966), np.float32(0.8761)] 
2024-12-14 10:21:48.350899: Epoch time: 6.36 s 
2024-12-14 10:21:48.897654:  
2024-12-14 10:21:48.902668: Epoch 51 
2024-12-14 10:21:48.906180: Current learning rate: 0.00526 
2024-12-14 10:21:55.259634: train_loss -0.8845 
2024-12-14 10:21:55.264281: val_loss -0.8499 
2024-12-14 10:21:55.267813: Pseudo dice [np.float32(0.8969), np.float32(0.8799)] 
2024-12-14 10:21:55.270184: Epoch time: 6.36 s 
2024-12-14 10:21:55.962709:  
2024-12-14 10:21:55.968238: Epoch 52 
2024-12-14 10:21:55.971664: Current learning rate: 0.00517 
2024-12-14 10:22:02.288857: train_loss -0.8851 
2024-12-14 10:22:02.295981: val_loss -0.8572 
2024-12-14 10:22:02.298488: Pseudo dice [np.float32(0.9029), np.float32(0.8843)] 
2024-12-14 10:22:02.301692: Epoch time: 6.33 s 
2024-12-14 10:22:02.304734: Yayy! New best EMA pseudo Dice: 0.8878999948501587 
2024-12-14 10:22:02.884911:  
2024-12-14 10:22:02.889438: Epoch 53 
2024-12-14 10:22:02.892955: Current learning rate: 0.00507 
2024-12-14 10:22:09.210365: train_loss -0.884 
2024-12-14 10:22:09.217119: val_loss -0.8467 
2024-12-14 10:22:09.219625: Pseudo dice [np.float32(0.8947), np.float32(0.8785)] 
2024-12-14 10:22:09.223139: Epoch time: 6.33 s 
2024-12-14 10:22:09.769713:  
2024-12-14 10:22:09.775297: Epoch 54 
2024-12-14 10:22:09.778370: Current learning rate: 0.00497 
2024-12-14 10:22:16.102545: train_loss -0.8875 
2024-12-14 10:22:16.107591: val_loss -0.8468 
2024-12-14 10:22:16.110632: Pseudo dice [np.float32(0.8974), np.float32(0.8746)] 
2024-12-14 10:22:16.113160: Epoch time: 6.33 s 
2024-12-14 10:22:16.667040:  
2024-12-14 10:22:16.672052: Epoch 55 
2024-12-14 10:22:16.675564: Current learning rate: 0.00487 
2024-12-14 10:22:23.015410: train_loss -0.8851 
2024-12-14 10:22:23.020973: val_loss -0.8508 
2024-12-14 10:22:23.024027: Pseudo dice [np.float32(0.898), np.float32(0.8787)] 
2024-12-14 10:22:23.027075: Epoch time: 6.35 s 
2024-12-14 10:22:23.569011:  
2024-12-14 10:22:23.574530: Epoch 56 
2024-12-14 10:22:23.577036: Current learning rate: 0.00478 
2024-12-14 10:22:29.910744: train_loss -0.8883 
2024-12-14 10:22:29.915816: val_loss -0.8464 
2024-12-14 10:22:29.918877: Pseudo dice [np.float32(0.8946), np.float32(0.8763)] 
2024-12-14 10:22:29.921402: Epoch time: 6.34 s 
2024-12-14 10:22:30.467501:  
2024-12-14 10:22:30.472046: Epoch 57 
2024-12-14 10:22:30.475622: Current learning rate: 0.00468 
2024-12-14 10:22:36.819903: train_loss -0.8874 
2024-12-14 10:22:36.825005: val_loss -0.8476 
2024-12-14 10:22:36.828536: Pseudo dice [np.float32(0.8978), np.float32(0.8771)] 
2024-12-14 10:22:36.831565: Epoch time: 6.35 s 
2024-12-14 10:22:37.375867:  
2024-12-14 10:22:37.380932: Epoch 58 
2024-12-14 10:22:37.384507: Current learning rate: 0.00458 
2024-12-14 10:22:43.703446: train_loss -0.8882 
2024-12-14 10:22:43.709016: val_loss -0.8529 
2024-12-14 10:22:43.711540: Pseudo dice [np.float32(0.9006), np.float32(0.8813)] 
2024-12-14 10:22:43.715129: Epoch time: 6.33 s 
2024-12-14 10:22:44.269852:  
2024-12-14 10:22:44.275578: Epoch 59 
2024-12-14 10:22:44.278942: Current learning rate: 0.00448 
2024-12-14 10:22:50.604222: train_loss -0.8895 
2024-12-14 10:22:50.609339: val_loss -0.8471 
2024-12-14 10:22:50.611380: Pseudo dice [np.float32(0.8969), np.float32(0.8765)] 
2024-12-14 10:22:50.615926: Epoch time: 6.33 s 
2024-12-14 10:22:51.317338:  
2024-12-14 10:22:51.322397: Epoch 60 
2024-12-14 10:22:51.325912: Current learning rate: 0.00438 
2024-12-14 10:22:57.657411: train_loss -0.8902 
2024-12-14 10:22:57.662455: val_loss -0.8468 
2024-12-14 10:22:57.665959: Pseudo dice [np.float32(0.8972), np.float32(0.8747)] 
2024-12-14 10:22:57.668989: Epoch time: 6.34 s 
2024-12-14 10:22:58.221242:  
2024-12-14 10:22:58.226808: Epoch 61 
2024-12-14 10:22:58.229849: Current learning rate: 0.00429 
2024-12-14 10:23:04.553746: train_loss -0.8917 
2024-12-14 10:23:04.560872: val_loss -0.8495 
2024-12-14 10:23:04.563946: Pseudo dice [np.float32(0.8983), np.float32(0.8789)] 
2024-12-14 10:23:04.566505: Epoch time: 6.33 s 
2024-12-14 10:23:05.122370:  
2024-12-14 10:23:05.127883: Epoch 62 
2024-12-14 10:23:05.130389: Current learning rate: 0.00419 
2024-12-14 10:23:11.461400: train_loss -0.8895 
2024-12-14 10:23:11.465969: val_loss -0.8462 
2024-12-14 10:23:11.470016: Pseudo dice [np.float32(0.8956), np.float32(0.8744)] 
2024-12-14 10:23:11.473100: Epoch time: 6.34 s 
2024-12-14 10:23:12.040042:  
2024-12-14 10:23:12.044760: Epoch 63 
2024-12-14 10:23:12.048270: Current learning rate: 0.00409 
2024-12-14 10:23:18.382548: train_loss -0.8909 
2024-12-14 10:23:18.387631: val_loss -0.8463 
2024-12-14 10:23:18.391228: Pseudo dice [np.float32(0.8962), np.float32(0.8758)] 
2024-12-14 10:23:18.394266: Epoch time: 6.34 s 
2024-12-14 10:23:18.948618:  
2024-12-14 10:23:18.953632: Epoch 64 
2024-12-14 10:23:18.956330: Current learning rate: 0.00399 
2024-12-14 10:23:25.281636: train_loss -0.8919 
2024-12-14 10:23:25.287388: val_loss -0.8519 
2024-12-14 10:23:25.290436: Pseudo dice [np.float32(0.9002), np.float32(0.8792)] 
2024-12-14 10:23:25.293488: Epoch time: 6.33 s 
2024-12-14 10:23:25.854038:  
2024-12-14 10:23:25.859576: Epoch 65 
2024-12-14 10:23:25.862623: Current learning rate: 0.00389 
2024-12-14 10:23:32.182238: train_loss -0.8915 
2024-12-14 10:23:32.188320: val_loss -0.8493 
2024-12-14 10:23:32.191369: Pseudo dice [np.float32(0.8987), np.float32(0.8785)] 
2024-12-14 10:23:32.194950: Epoch time: 6.33 s 
2024-12-14 10:23:32.748346:  
2024-12-14 10:23:32.753964: Epoch 66 
2024-12-14 10:23:32.756509: Current learning rate: 0.00379 
2024-12-14 10:23:39.081262: train_loss -0.8912 
2024-12-14 10:23:39.086833: val_loss -0.8525 
2024-12-14 10:23:39.089361: Pseudo dice [np.float32(0.8998), np.float32(0.881)] 
2024-12-14 10:23:39.092400: Epoch time: 6.33 s 
2024-12-14 10:23:39.645097:  
2024-12-14 10:23:39.648607: Epoch 67 
2024-12-14 10:23:39.652117: Current learning rate: 0.00369 
2024-12-14 10:23:45.977123: train_loss -0.8933 
2024-12-14 10:23:45.982575: val_loss -0.8485 
2024-12-14 10:23:45.985088: Pseudo dice [np.float32(0.898), np.float32(0.8776)] 
2024-12-14 10:23:45.988606: Epoch time: 6.33 s 
2024-12-14 10:23:46.700887:  
2024-12-14 10:23:46.703913: Epoch 68 
2024-12-14 10:23:46.707423: Current learning rate: 0.00359 
2024-12-14 10:23:53.069212: train_loss -0.8933 
2024-12-14 10:23:53.074224: val_loss -0.8571 
2024-12-14 10:23:53.077735: Pseudo dice [np.float32(0.903), np.float32(0.8829)] 
2024-12-14 10:23:53.080745: Epoch time: 6.37 s 
2024-12-14 10:23:53.084259: Yayy! New best EMA pseudo Dice: 0.8884000182151794 
2024-12-14 10:23:53.690766:  
2024-12-14 10:23:53.695780: Epoch 69 
2024-12-14 10:23:53.699292: Current learning rate: 0.00349 
2024-12-14 10:24:00.052379: train_loss -0.8923 
2024-12-14 10:24:00.057968: val_loss -0.8454 
2024-12-14 10:24:00.061065: Pseudo dice [np.float32(0.8972), np.float32(0.875)] 
2024-12-14 10:24:00.064606: Epoch time: 6.36 s 
2024-12-14 10:24:00.636379:  
2024-12-14 10:24:00.641908: Epoch 70 
2024-12-14 10:24:00.644919: Current learning rate: 0.00338 
2024-12-14 10:24:06.998261: train_loss -0.8942 
2024-12-14 10:24:07.003884: val_loss -0.8451 
2024-12-14 10:24:07.006934: Pseudo dice [np.float32(0.8934), np.float32(0.876)] 
2024-12-14 10:24:07.010984: Epoch time: 6.36 s 
2024-12-14 10:24:07.576203:  
2024-12-14 10:24:07.581282: Epoch 71 
2024-12-14 10:24:07.584363: Current learning rate: 0.00328 
2024-12-14 10:24:13.937129: train_loss -0.8952 
2024-12-14 10:24:13.942704: val_loss -0.8409 
2024-12-14 10:24:13.946260: Pseudo dice [np.float32(0.8939), np.float32(0.8716)] 
2024-12-14 10:24:13.949821: Epoch time: 6.36 s 
2024-12-14 10:24:14.516829:  
2024-12-14 10:24:14.521870: Epoch 72 
2024-12-14 10:24:14.525510: Current learning rate: 0.00318 
2024-12-14 10:24:20.882463: train_loss -0.8966 
2024-12-14 10:24:20.887533: val_loss -0.8445 
2024-12-14 10:24:20.892079: Pseudo dice [np.float32(0.8954), np.float32(0.8754)] 
2024-12-14 10:24:20.895113: Epoch time: 6.37 s 
2024-12-14 10:24:21.465856:  
2024-12-14 10:24:21.471879: Epoch 73 
2024-12-14 10:24:21.474390: Current learning rate: 0.00308 
2024-12-14 10:24:27.813715: train_loss -0.8952 
2024-12-14 10:24:27.820239: val_loss -0.8516 
2024-12-14 10:24:27.823285: Pseudo dice [np.float32(0.8996), np.float32(0.8816)] 
2024-12-14 10:24:27.826299: Epoch time: 6.35 s 
2024-12-14 10:24:28.391190:  
2024-12-14 10:24:28.396655: Epoch 74 
2024-12-14 10:24:28.399167: Current learning rate: 0.00297 
2024-12-14 10:24:34.739570: train_loss -0.8961 
2024-12-14 10:24:34.744624: val_loss -0.8466 
2024-12-14 10:24:34.748195: Pseudo dice [np.float32(0.8976), np.float32(0.8776)] 
2024-12-14 10:24:34.750721: Epoch time: 6.35 s 
2024-12-14 10:24:35.471088:  
2024-12-14 10:24:35.476657: Epoch 75 
2024-12-14 10:24:35.479208: Current learning rate: 0.00287 
2024-12-14 10:24:41.810569: train_loss -0.8965 
2024-12-14 10:24:41.815666: val_loss -0.8504 
2024-12-14 10:24:41.819214: Pseudo dice [np.float32(0.8995), np.float32(0.8789)] 
2024-12-14 10:24:41.822283: Epoch time: 6.34 s 
2024-12-14 10:24:42.392042:  
2024-12-14 10:24:42.397075: Epoch 76 
2024-12-14 10:24:42.400046: Current learning rate: 0.00277 
2024-12-14 10:24:48.734620: train_loss -0.8969 
2024-12-14 10:24:48.740180: val_loss -0.8506 
2024-12-14 10:24:48.743218: Pseudo dice [np.float32(0.9002), np.float32(0.8795)] 
2024-12-14 10:24:48.746256: Epoch time: 6.34 s 
2024-12-14 10:24:49.310035:  
2024-12-14 10:24:49.314051: Epoch 77 
2024-12-14 10:24:49.316558: Current learning rate: 0.00266 
2024-12-14 10:24:55.631186: train_loss -0.8965 
2024-12-14 10:24:55.637261: val_loss -0.8435 
2024-12-14 10:24:55.640296: Pseudo dice [np.float32(0.8951), np.float32(0.8745)] 
2024-12-14 10:24:55.642850: Epoch time: 6.32 s 
2024-12-14 10:24:56.214770:  
2024-12-14 10:24:56.219807: Epoch 78 
2024-12-14 10:24:56.222849: Current learning rate: 0.00256 
2024-12-14 10:25:02.550362: train_loss -0.8988 
2024-12-14 10:25:02.556931: val_loss -0.8483 
2024-12-14 10:25:02.560443: Pseudo dice [np.float32(0.8989), np.float32(0.8777)] 
2024-12-14 10:25:02.563496: Epoch time: 6.34 s 
2024-12-14 10:25:03.132392:  
2024-12-14 10:25:03.137971: Epoch 79 
2024-12-14 10:25:03.140569: Current learning rate: 0.00245 
2024-12-14 10:25:09.465958: train_loss -0.8977 
2024-12-14 10:25:09.471985: val_loss -0.8492 
2024-12-14 10:25:09.474499: Pseudo dice [np.float32(0.8989), np.float32(0.8786)] 
2024-12-14 10:25:09.478032: Epoch time: 6.33 s 
2024-12-14 10:25:10.046599:  
2024-12-14 10:25:10.051664: Epoch 80 
2024-12-14 10:25:10.055181: Current learning rate: 0.00235 
2024-12-14 10:25:16.398508: train_loss -0.8985 
2024-12-14 10:25:16.404127: val_loss -0.8486 
2024-12-14 10:25:16.407224: Pseudo dice [np.float32(0.8977), np.float32(0.8786)] 
2024-12-14 10:25:16.410334: Epoch time: 6.35 s 
2024-12-14 10:25:16.989561:  
2024-12-14 10:25:16.994703: Epoch 81 
2024-12-14 10:25:16.997785: Current learning rate: 0.00224 
2024-12-14 10:25:23.327746: train_loss -0.8992 
2024-12-14 10:25:23.333355: val_loss -0.8495 
2024-12-14 10:25:23.336381: Pseudo dice [np.float32(0.8997), np.float32(0.8784)] 
2024-12-14 10:25:23.338899: Epoch time: 6.34 s 
2024-12-14 10:25:23.911756:  
2024-12-14 10:25:23.917367: Epoch 82 
2024-12-14 10:25:23.920434: Current learning rate: 0.00214 
2024-12-14 10:25:30.246109: train_loss -0.9002 
2024-12-14 10:25:30.251623: val_loss -0.8481 
2024-12-14 10:25:30.255161: Pseudo dice [np.float32(0.8976), np.float32(0.8778)] 
2024-12-14 10:25:30.257752: Epoch time: 6.33 s 
2024-12-14 10:25:30.954201:  
2024-12-14 10:25:30.959230: Epoch 83 
2024-12-14 10:25:30.961960: Current learning rate: 0.00203 
2024-12-14 10:25:37.306082: train_loss -0.8989 
2024-12-14 10:25:37.311649: val_loss -0.849 
2024-12-14 10:25:37.315179: Pseudo dice [np.float32(0.8976), np.float32(0.8787)] 
2024-12-14 10:25:37.318205: Epoch time: 6.35 s 
2024-12-14 10:25:37.866970:  
2024-12-14 10:25:37.872009: Epoch 84 
2024-12-14 10:25:37.875542: Current learning rate: 0.00192 
2024-12-14 10:25:44.214379: train_loss -0.901 
2024-12-14 10:25:44.220015: val_loss -0.8487 
2024-12-14 10:25:44.224094: Pseudo dice [np.float32(0.8974), np.float32(0.8785)] 
2024-12-14 10:25:44.227146: Epoch time: 6.35 s 
2024-12-14 10:25:44.771758:  
2024-12-14 10:25:44.776780: Epoch 85 
2024-12-14 10:25:44.779295: Current learning rate: 0.00181 
2024-12-14 10:25:51.131343: train_loss -0.9007 
2024-12-14 10:25:51.136901: val_loss -0.8509 
2024-12-14 10:25:51.140915: Pseudo dice [np.float32(0.8996), np.float32(0.8807)] 
2024-12-14 10:25:51.143426: Epoch time: 6.36 s 
2024-12-14 10:25:51.679839:  
2024-12-14 10:25:51.684874: Epoch 86 
2024-12-14 10:25:51.688410: Current learning rate: 0.0017 
2024-12-14 10:25:58.033836: train_loss -0.9003 
2024-12-14 10:25:58.038905: val_loss -0.8476 
2024-12-14 10:25:58.043446: Pseudo dice [np.float32(0.8958), np.float32(0.8788)] 
2024-12-14 10:25:58.047483: Epoch time: 6.35 s 
2024-12-14 10:25:58.581169:  
2024-12-14 10:25:58.586757: Epoch 87 
2024-12-14 10:25:58.590816: Current learning rate: 0.00159 
2024-12-14 10:26:04.951005: train_loss -0.9004 
2024-12-14 10:26:04.957161: val_loss -0.8467 
2024-12-14 10:26:04.960670: Pseudo dice [np.float32(0.8967), np.float32(0.8766)] 
2024-12-14 10:26:04.963681: Epoch time: 6.37 s 
2024-12-14 10:26:05.505821:  
2024-12-14 10:26:05.510835: Epoch 88 
2024-12-14 10:26:05.514349: Current learning rate: 0.00148 
2024-12-14 10:26:11.864538: train_loss -0.9031 
2024-12-14 10:26:11.870091: val_loss -0.8422 
2024-12-14 10:26:11.873659: Pseudo dice [np.float32(0.8941), np.float32(0.8729)] 
2024-12-14 10:26:11.876695: Epoch time: 6.36 s 
2024-12-14 10:26:12.414371:  
2024-12-14 10:26:12.419912: Epoch 89 
2024-12-14 10:26:12.422951: Current learning rate: 0.00137 
2024-12-14 10:26:18.771644: train_loss -0.9016 
2024-12-14 10:26:18.777218: val_loss -0.8392 
2024-12-14 10:26:18.780766: Pseudo dice [np.float32(0.8929), np.float32(0.8707)] 
2024-12-14 10:26:18.783807: Epoch time: 6.36 s 
2024-12-14 10:26:19.324445:  
2024-12-14 10:26:19.329971: Epoch 90 
2024-12-14 10:26:19.333027: Current learning rate: 0.00126 
2024-12-14 10:26:25.672282: train_loss -0.9029 
2024-12-14 10:26:25.677841: val_loss -0.8484 
2024-12-14 10:26:25.680886: Pseudo dice [np.float32(0.8984), np.float32(0.8788)] 
2024-12-14 10:26:25.683923: Epoch time: 6.35 s 
2024-12-14 10:26:26.367850:  
2024-12-14 10:26:26.373401: Epoch 91 
2024-12-14 10:26:26.376914: Current learning rate: 0.00115 
2024-12-14 10:26:32.718963: train_loss -0.9021 
2024-12-14 10:26:32.724534: val_loss -0.85 
2024-12-14 10:26:32.729083: Pseudo dice [np.float32(0.9006), np.float32(0.88)] 
2024-12-14 10:26:32.732117: Epoch time: 6.35 s 
2024-12-14 10:26:33.276891:  
2024-12-14 10:26:33.282460: Epoch 92 
2024-12-14 10:26:33.285007: Current learning rate: 0.00103 
2024-12-14 10:26:39.619706: train_loss -0.9024 
2024-12-14 10:26:39.624895: val_loss -0.8466 
2024-12-14 10:26:39.628454: Pseudo dice [np.float32(0.8971), np.float32(0.8764)] 
2024-12-14 10:26:39.631493: Epoch time: 6.34 s 
2024-12-14 10:26:40.174523:  
2024-12-14 10:26:40.180176: Epoch 93 
2024-12-14 10:26:40.183280: Current learning rate: 0.00091 
2024-12-14 10:26:46.494428: train_loss -0.9027 
2024-12-14 10:26:46.500078: val_loss -0.8451 
2024-12-14 10:26:46.503139: Pseudo dice [np.float32(0.896), np.float32(0.8767)] 
2024-12-14 10:26:46.506200: Epoch time: 6.32 s 
2024-12-14 10:26:47.039555:  
2024-12-14 10:26:47.045566: Epoch 94 
2024-12-14 10:26:47.048577: Current learning rate: 0.00079 
2024-12-14 10:26:53.365493: train_loss -0.9023 
2024-12-14 10:26:53.371587: val_loss -0.8478 
2024-12-14 10:26:53.374670: Pseudo dice [np.float32(0.8979), np.float32(0.8785)] 
2024-12-14 10:26:53.377826: Epoch time: 6.33 s 
2024-12-14 10:26:53.912215:  
2024-12-14 10:26:53.917793: Epoch 95 
2024-12-14 10:26:53.921423: Current learning rate: 0.00067 
2024-12-14 10:27:00.245295: train_loss -0.9046 
2024-12-14 10:27:00.250826: val_loss -0.8484 
2024-12-14 10:27:00.254869: Pseudo dice [np.float32(0.8986), np.float32(0.8781)] 
2024-12-14 10:27:00.257906: Epoch time: 6.33 s 
2024-12-14 10:27:00.791581:  
2024-12-14 10:27:00.797114: Epoch 96 
2024-12-14 10:27:00.800194: Current learning rate: 0.00055 
2024-12-14 10:27:07.140996: train_loss -0.9024 
2024-12-14 10:27:07.146911: val_loss -0.8459 
2024-12-14 10:27:07.150419: Pseudo dice [np.float32(0.8969), np.float32(0.8759)] 
2024-12-14 10:27:07.153458: Epoch time: 6.35 s 
2024-12-14 10:27:07.704149:  
2024-12-14 10:27:07.709712: Epoch 97 
2024-12-14 10:27:07.712753: Current learning rate: 0.00043 
2024-12-14 10:27:14.076488: train_loss -0.9042 
2024-12-14 10:27:14.082057: val_loss -0.8376 
2024-12-14 10:27:14.085626: Pseudo dice [np.float32(0.8915), np.float32(0.8717)] 
2024-12-14 10:27:14.088654: Epoch time: 6.37 s 
2024-12-14 10:27:14.634151:  
2024-12-14 10:27:14.639201: Epoch 98 
2024-12-14 10:27:14.642727: Current learning rate: 0.0003 
2024-12-14 10:27:20.994229: train_loss -0.9041 
2024-12-14 10:27:20.999885: val_loss -0.8448 
2024-12-14 10:27:21.003451: Pseudo dice [np.float32(0.8957), np.float32(0.8772)] 
2024-12-14 10:27:21.005474: Epoch time: 6.36 s 
2024-12-14 10:27:21.561495:  
2024-12-14 10:27:21.566570: Epoch 99 
2024-12-14 10:27:21.569644: Current learning rate: 0.00016 
2024-12-14 10:27:27.923438: train_loss -0.9038 
2024-12-14 10:27:27.929162: val_loss -0.8439 
2024-12-14 10:27:27.932261: Pseudo dice [np.float32(0.8955), np.float32(0.8753)] 
2024-12-14 10:27:27.935326: Epoch time: 6.36 s 
2024-12-14 10:27:28.687371: Training done. 
2024-12-14 10:27:28.721406: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-14 10:27:28.728416: The split file contains 5 splits. 
2024-12-14 10:27:28.734932: Desired fold for training: 0 
2024-12-14 10:27:28.740932: This split has 208 training and 52 validation cases. 
2024-12-14 10:27:28.746948: predicting hippocampus_017 
2024-12-14 10:27:28.752460: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-14 10:27:28.847671: predicting hippocampus_019 
2024-12-14 10:27:28.855179: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-14 10:27:28.890199: predicting hippocampus_033 
2024-12-14 10:27:28.897279: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-14 10:27:28.918290: predicting hippocampus_035 
2024-12-14 10:27:28.923800: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-14 10:27:28.944813: predicting hippocampus_037 
2024-12-14 10:27:28.951255: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-14 10:27:28.972609: predicting hippocampus_049 
2024-12-14 10:27:28.979609: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-14 10:27:29.001352: predicting hippocampus_052 
2024-12-14 10:27:29.008554: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-14 10:27:29.030159: predicting hippocampus_065 
2024-12-14 10:27:29.036668: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-14 10:27:29.060196: predicting hippocampus_083 
2024-12-14 10:27:29.066706: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-14 10:27:29.088725: predicting hippocampus_088 
2024-12-14 10:27:29.095234: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-14 10:27:32.533483: predicting hippocampus_090 
2024-12-14 10:27:32.540994: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-14 10:27:32.583447: predicting hippocampus_092 
2024-12-14 10:27:32.590446: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-14 10:27:32.636364: predicting hippocampus_095 
2024-12-14 10:27:32.642869: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-14 10:27:32.689427: predicting hippocampus_107 
2024-12-14 10:27:32.696937: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-14 10:27:32.741492: predicting hippocampus_108 
2024-12-14 10:27:32.749009: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-14 10:27:32.797323: predicting hippocampus_123 
2024-12-14 10:27:32.804840: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-14 10:27:32.851213: predicting hippocampus_125 
2024-12-14 10:27:32.858530: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-14 10:27:32.937634: predicting hippocampus_157 
2024-12-14 10:27:32.945148: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-14 10:27:32.978188: predicting hippocampus_164 
2024-12-14 10:27:32.985699: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-14 10:27:33.072796: predicting hippocampus_169 
2024-12-14 10:27:33.079800: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-14 10:27:33.108333: predicting hippocampus_175 
2024-12-14 10:27:33.115843: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-14 10:27:33.143368: predicting hippocampus_185 
2024-12-14 10:27:33.149873: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-14 10:27:33.178398: predicting hippocampus_190 
2024-12-14 10:27:33.183906: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-14 10:27:33.208923: predicting hippocampus_194 
2024-12-14 10:27:33.215432: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-14 10:27:33.241957: predicting hippocampus_204 
2024-12-14 10:27:33.248466: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-14 10:27:33.275996: predicting hippocampus_205 
2024-12-14 10:27:33.283502: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-14 10:27:33.311026: predicting hippocampus_210 
2024-12-14 10:27:33.316035: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-14 10:27:33.344564: predicting hippocampus_217 
2024-12-14 10:27:33.351579: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-14 10:27:33.376601: predicting hippocampus_219 
2024-12-14 10:27:33.383111: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-14 10:27:33.411133: predicting hippocampus_229 
2024-12-14 10:27:33.416646: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-14 10:27:33.443171: predicting hippocampus_244 
2024-12-14 10:27:33.448678: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-14 10:27:33.476211: predicting hippocampus_261 
2024-12-14 10:27:33.481713: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-14 10:27:33.526760: predicting hippocampus_264 
2024-12-14 10:27:33.532270: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-14 10:27:33.559798: predicting hippocampus_277 
2024-12-14 10:27:33.565308: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-14 10:27:33.610348: predicting hippocampus_280 
2024-12-14 10:27:33.617864: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-14 10:27:33.647393: predicting hippocampus_286 
2024-12-14 10:27:33.652409: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-14 10:27:33.695451: predicting hippocampus_288 
2024-12-14 10:27:33.702958: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-14 10:27:33.745003: predicting hippocampus_289 
2024-12-14 10:27:33.752015: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-14 10:27:33.779041: predicting hippocampus_296 
2024-12-14 10:27:33.785554: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-14 10:27:33.821083: predicting hippocampus_305 
2024-12-14 10:27:33.837098: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-14 10:27:33.866131: predicting hippocampus_308 
2024-12-14 10:27:33.871132: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-14 10:27:33.898660: predicting hippocampus_317 
2024-12-14 10:27:33.904171: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-14 10:27:33.931194: predicting hippocampus_327 
2024-12-14 10:27:33.936704: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-14 10:27:33.964735: predicting hippocampus_330 
2024-12-14 10:27:33.969735: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-14 10:27:33.996260: predicting hippocampus_332 
2024-12-14 10:27:34.001764: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-14 10:27:34.028791: predicting hippocampus_338 
2024-12-14 10:27:34.033300: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-14 10:27:34.075847: predicting hippocampus_349 
2024-12-14 10:27:34.082354: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-14 10:27:34.107377: predicting hippocampus_350 
2024-12-14 10:27:34.113887: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-14 10:27:34.139910: predicting hippocampus_356 
2024-12-14 10:27:34.145420: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-14 10:27:34.174451: predicting hippocampus_358 
2024-12-14 10:27:34.180451: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-14 10:27:34.206982: predicting hippocampus_374 
2024-12-14 10:27:34.211485: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-14 10:27:34.238514: predicting hippocampus_394 
2024-12-14 10:27:34.243021: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-14 10:27:37.944246: Validation complete 
2024-12-14 10:27:37.949248: Mean Validation Dice:  0.890786140484092 
