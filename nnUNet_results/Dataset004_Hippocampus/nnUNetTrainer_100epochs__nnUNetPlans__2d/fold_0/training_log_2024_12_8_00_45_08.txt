
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-08 00:45:08.324813: do_dummy_2d_data_aug: False 
2024-12-08 00:45:08.328323: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-08 00:45:08.335324: The split file contains 5 splits. 
2024-12-08 00:45:08.338832: Desired fold for training: 0 
2024-12-08 00:45:08.341836: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 366, 'patch_size': [56, 40], 'median_image_size_in_voxels': [50.0, 35.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-08 00:45:16.703411: unpacking dataset... 
2024-12-08 00:45:16.989388: unpacking done... 
2024-12-08 00:45:18.162904:  
2024-12-08 00:45:18.168427: Epoch 0 
2024-12-08 00:45:18.171452: Current learning rate: 0.01 
2024-12-08 00:45:34.400680: train_loss -0.0764 
2024-12-08 00:45:34.405863: val_loss -0.4847 
2024-12-08 00:45:34.410944: Pseudo dice [np.float32(0.6198), np.float32(0.6739)] 
2024-12-08 00:45:34.417048: Epoch time: 16.24 s 
2024-12-08 00:45:34.422646: Yayy! New best EMA pseudo Dice: 0.6467999815940857 
2024-12-08 00:45:35.080501:  
2024-12-08 00:45:35.088098: Epoch 1 
2024-12-08 00:45:35.093736: Current learning rate: 0.00991 
2024-12-08 00:45:50.619213: train_loss -0.6379 
2024-12-08 00:45:50.625803: val_loss -0.7548 
2024-12-08 00:45:50.633979: Pseudo dice [np.float32(0.8433), np.float32(0.8229)] 
2024-12-08 00:45:50.638543: Epoch time: 15.54 s 
2024-12-08 00:45:50.644145: Yayy! New best EMA pseudo Dice: 0.6654999852180481 
2024-12-08 00:45:51.340363:  
2024-12-08 00:45:51.345582: Epoch 2 
2024-12-08 00:45:51.352185: Current learning rate: 0.00982 
2024-12-08 00:46:06.867776: train_loss -0.7541 
2024-12-08 00:46:06.876977: val_loss -0.7871 
2024-12-08 00:46:06.882526: Pseudo dice [np.float32(0.8636), np.float32(0.8475)] 
2024-12-08 00:46:06.889667: Epoch time: 15.53 s 
2024-12-08 00:46:06.894766: Yayy! New best EMA pseudo Dice: 0.684499979019165 
2024-12-08 00:46:07.619802:  
2024-12-08 00:46:07.626323: Epoch 3 
2024-12-08 00:46:07.629837: Current learning rate: 0.00973 
2024-12-08 00:46:23.107297: train_loss -0.7853 
2024-12-08 00:46:23.114298: val_loss -0.8004 
2024-12-08 00:46:23.120325: Pseudo dice [np.float32(0.8714), np.float32(0.8558)] 
2024-12-08 00:46:23.124336: Epoch time: 15.49 s 
2024-12-08 00:46:23.130895: Yayy! New best EMA pseudo Dice: 0.7024000287055969 
2024-12-08 00:46:23.845403:  
2024-12-08 00:46:23.851985: Epoch 4 
2024-12-08 00:46:23.857059: Current learning rate: 0.00964 
2024-12-08 00:46:39.453132: train_loss -0.8006 
2024-12-08 00:46:39.459708: val_loss -0.8053 
2024-12-08 00:46:39.466316: Pseudo dice [np.float32(0.8737), np.float32(0.8595)] 
2024-12-08 00:46:39.470332: Epoch time: 15.61 s 
2024-12-08 00:46:39.475981: Yayy! New best EMA pseudo Dice: 0.7188000082969666 
2024-12-08 00:46:40.349528:  
2024-12-08 00:46:40.357099: Epoch 5 
2024-12-08 00:46:40.363786: Current learning rate: 0.00955 
2024-12-08 00:46:55.873987: train_loss -0.812 
2024-12-08 00:46:55.880524: val_loss -0.8091 
2024-12-08 00:46:55.886549: Pseudo dice [np.float32(0.8766), np.float32(0.8621)] 
2024-12-08 00:46:55.893235: Epoch time: 15.52 s 
2024-12-08 00:46:55.899313: Yayy! New best EMA pseudo Dice: 0.7339000105857849 
2024-12-08 00:46:56.570444:  
2024-12-08 00:46:56.575672: Epoch 6 
2024-12-08 00:46:56.578184: Current learning rate: 0.00946 
2024-12-08 00:47:11.875281: train_loss -0.8188 
2024-12-08 00:47:11.882409: val_loss -0.8128 
2024-12-08 00:47:11.887994: Pseudo dice [np.float32(0.8784), np.float32(0.8661)] 
2024-12-08 00:47:11.894223: Epoch time: 15.31 s 
2024-12-08 00:47:11.898352: Yayy! New best EMA pseudo Dice: 0.7476999759674072 
2024-12-08 00:47:12.590268:  
2024-12-08 00:47:12.595806: Epoch 7 
2024-12-08 00:47:12.598326: Current learning rate: 0.00937 
2024-12-08 00:47:28.043263: train_loss -0.8244 
2024-12-08 00:47:28.051875: val_loss -0.8122 
2024-12-08 00:47:28.057446: Pseudo dice [np.float32(0.8792), np.float32(0.8637)] 
2024-12-08 00:47:28.063179: Epoch time: 15.45 s 
2024-12-08 00:47:28.067716: Yayy! New best EMA pseudo Dice: 0.7601000070571899 
2024-12-08 00:47:28.786561:  
2024-12-08 00:47:28.792080: Epoch 8 
2024-12-08 00:47:28.797097: Current learning rate: 0.00928 
2024-12-08 00:47:44.210646: train_loss -0.8292 
2024-12-08 00:47:44.219264: val_loss -0.8097 
2024-12-08 00:47:44.225874: Pseudo dice [np.float32(0.8776), np.float32(0.8623)] 
2024-12-08 00:47:44.231505: Epoch time: 15.43 s 
2024-12-08 00:47:44.236073: Yayy! New best EMA pseudo Dice: 0.7710999846458435 
2024-12-08 00:47:44.964175:  
2024-12-08 00:47:44.969188: Epoch 9 
2024-12-08 00:47:44.972717: Current learning rate: 0.00919 
2024-12-08 00:48:00.337224: train_loss -0.8329 
2024-12-08 00:48:00.343781: val_loss -0.8135 
2024-12-08 00:48:00.348798: Pseudo dice [np.float32(0.8796), np.float32(0.865)] 
2024-12-08 00:48:00.354895: Epoch time: 15.37 s 
2024-12-08 00:48:00.361417: Yayy! New best EMA pseudo Dice: 0.7811999917030334 
2024-12-08 00:48:01.067891:  
2024-12-08 00:48:01.073457: Epoch 10 
2024-12-08 00:48:01.079479: Current learning rate: 0.0091 
2024-12-08 00:48:16.477633: train_loss -0.8366 
2024-12-08 00:48:16.485152: val_loss -0.8153 
2024-12-08 00:48:16.490175: Pseudo dice [np.float32(0.8803), np.float32(0.8667)] 
2024-12-08 00:48:16.496878: Epoch time: 15.41 s 
2024-12-08 00:48:16.501894: Yayy! New best EMA pseudo Dice: 0.7904000282287598 
2024-12-08 00:48:17.209314:  
2024-12-08 00:48:17.214884: Epoch 11 
2024-12-08 00:48:17.219627: Current learning rate: 0.009 
2024-12-08 00:48:32.704235: train_loss -0.8402 
2024-12-08 00:48:32.710897: val_loss -0.8134 
2024-12-08 00:48:32.716036: Pseudo dice [np.float32(0.8814), np.float32(0.8642)] 
2024-12-08 00:48:32.721191: Epoch time: 15.49 s 
2024-12-08 00:48:32.728795: Yayy! New best EMA pseudo Dice: 0.7986999750137329 
2024-12-08 00:48:33.442129:  
2024-12-08 00:48:33.447667: Epoch 12 
2024-12-08 00:48:33.450797: Current learning rate: 0.00891 
2024-12-08 00:48:48.841403: train_loss -0.8429 
2024-12-08 00:48:48.849073: val_loss -0.8146 
2024-12-08 00:48:48.854202: Pseudo dice [np.float32(0.881), np.float32(0.8651)] 
2024-12-08 00:48:48.861841: Epoch time: 15.4 s 
2024-12-08 00:48:48.869012: Yayy! New best EMA pseudo Dice: 0.8061000108718872 
2024-12-08 00:48:49.723382:  
2024-12-08 00:48:49.729406: Epoch 13 
2024-12-08 00:48:49.733421: Current learning rate: 0.00882 
2024-12-08 00:49:05.318381: train_loss -0.8448 
2024-12-08 00:49:05.324575: val_loss -0.8143 
2024-12-08 00:49:05.332281: Pseudo dice [np.float32(0.8809), np.float32(0.8663)] 
2024-12-08 00:49:05.337339: Epoch time: 15.6 s 
2024-12-08 00:49:05.343942: Yayy! New best EMA pseudo Dice: 0.8127999901771545 
2024-12-08 00:49:06.062560:  
2024-12-08 00:49:06.068121: Epoch 14 
2024-12-08 00:49:06.071141: Current learning rate: 0.00873 
2024-12-08 00:49:21.458032: train_loss -0.8472 
2024-12-08 00:49:21.466640: val_loss -0.815 
2024-12-08 00:49:21.473659: Pseudo dice [np.float32(0.8817), np.float32(0.8667)] 
2024-12-08 00:49:21.478329: Epoch time: 15.4 s 
2024-12-08 00:49:21.484988: Yayy! New best EMA pseudo Dice: 0.8190000057220459 
2024-12-08 00:49:22.204527:  
2024-12-08 00:49:22.210874: Epoch 15 
2024-12-08 00:49:22.215398: Current learning rate: 0.00864 
2024-12-08 00:49:37.718621: train_loss -0.8493 
2024-12-08 00:49:37.725740: val_loss -0.8151 
2024-12-08 00:49:37.732904: Pseudo dice [np.float32(0.8819), np.float32(0.8662)] 
2024-12-08 00:49:37.737597: Epoch time: 15.51 s 
2024-12-08 00:49:37.742739: Yayy! New best EMA pseudo Dice: 0.8245000243186951 
2024-12-08 00:49:38.480212:  
2024-12-08 00:49:38.485960: Epoch 16 
2024-12-08 00:49:38.491560: Current learning rate: 0.00855 
2024-12-08 00:49:53.852395: train_loss -0.8516 
2024-12-08 00:49:53.861949: val_loss -0.8146 
2024-12-08 00:49:53.868277: Pseudo dice [np.float32(0.8826), np.float32(0.8649)] 
2024-12-08 00:49:53.872799: Epoch time: 15.37 s 
2024-12-08 00:49:53.879721: Yayy! New best EMA pseudo Dice: 0.8294000029563904 
2024-12-08 00:49:54.609957:  
2024-12-08 00:49:54.616481: Epoch 17 
2024-12-08 00:49:54.620490: Current learning rate: 0.00846 
2024-12-08 00:50:09.920435: train_loss -0.8529 
2024-12-08 00:50:09.926563: val_loss -0.8142 
2024-12-08 00:50:09.933669: Pseudo dice [np.float32(0.8811), np.float32(0.8647)] 
2024-12-08 00:50:09.938758: Epoch time: 15.31 s 
2024-12-08 00:50:09.945900: Yayy! New best EMA pseudo Dice: 0.8338000178337097 
2024-12-08 00:50:10.678009:  
2024-12-08 00:50:10.683563: Epoch 18 
2024-12-08 00:50:10.687079: Current learning rate: 0.00836 
2024-12-08 00:50:26.026376: train_loss -0.8554 
2024-12-08 00:50:26.034567: val_loss -0.8155 
2024-12-08 00:50:26.041176: Pseudo dice [np.float32(0.8834), np.float32(0.8659)] 
2024-12-08 00:50:26.046249: Epoch time: 15.35 s 
2024-12-08 00:50:26.049843: Yayy! New best EMA pseudo Dice: 0.8378999829292297 
2024-12-08 00:50:26.782874:  
2024-12-08 00:50:26.788392: Epoch 19 
2024-12-08 00:50:26.794486: Current learning rate: 0.00827 
2024-12-08 00:50:42.189694: train_loss -0.857 
2024-12-08 00:50:42.197262: val_loss -0.8158 
2024-12-08 00:50:42.203814: Pseudo dice [np.float32(0.8843), np.float32(0.865)] 
2024-12-08 00:50:42.207829: Epoch time: 15.41 s 
2024-12-08 00:50:42.214446: Yayy! New best EMA pseudo Dice: 0.8414999842643738 
2024-12-08 00:50:43.068007:  
2024-12-08 00:50:43.076656: Epoch 20 
2024-12-08 00:50:43.081729: Current learning rate: 0.00818 
2024-12-08 00:50:58.409742: train_loss -0.8582 
2024-12-08 00:50:58.417946: val_loss -0.8138 
2024-12-08 00:50:58.423030: Pseudo dice [np.float32(0.8824), np.float32(0.8648)] 
2024-12-08 00:50:58.427081: Epoch time: 15.34 s 
2024-12-08 00:50:58.434200: Yayy! New best EMA pseudo Dice: 0.8446999788284302 
2024-12-08 00:50:59.195175:  
2024-12-08 00:50:59.200696: Epoch 21 
2024-12-08 00:50:59.205711: Current learning rate: 0.00809 
2024-12-08 00:51:14.400494: train_loss -0.8595 
2024-12-08 00:51:14.406564: val_loss -0.8166 
2024-12-08 00:51:14.412749: Pseudo dice [np.float32(0.8833), np.float32(0.8669)] 
2024-12-08 00:51:14.417835: Epoch time: 15.21 s 
2024-12-08 00:51:14.424432: Yayy! New best EMA pseudo Dice: 0.8478000164031982 
2024-12-08 00:51:15.106375:  
2024-12-08 00:51:15.112131: Epoch 22 
2024-12-08 00:51:15.116693: Current learning rate: 0.008 
2024-12-08 00:51:30.282222: train_loss -0.8614 
2024-12-08 00:51:30.289829: val_loss -0.8132 
2024-12-08 00:51:30.295469: Pseudo dice [np.float32(0.8826), np.float32(0.8643)] 
2024-12-08 00:51:30.300572: Epoch time: 15.18 s 
2024-12-08 00:51:30.318461: Yayy! New best EMA pseudo Dice: 0.8503000140190125 
2024-12-08 00:51:31.005694:  
2024-12-08 00:51:31.012241: Epoch 23 
2024-12-08 00:51:31.016248: Current learning rate: 0.0079 
2024-12-08 00:51:46.326468: train_loss -0.8629 
2024-12-08 00:51:46.335703: val_loss -0.8158 
2024-12-08 00:51:46.340776: Pseudo dice [np.float32(0.8836), np.float32(0.8667)] 
2024-12-08 00:51:46.345793: Epoch time: 15.32 s 
2024-12-08 00:51:46.352277: Yayy! New best EMA pseudo Dice: 0.8528000116348267 
2024-12-08 00:51:47.056451:  
2024-12-08 00:51:47.062505: Epoch 24 
2024-12-08 00:51:47.068705: Current learning rate: 0.00781 
2024-12-08 00:52:02.413875: train_loss -0.8636 
2024-12-08 00:52:02.420015: val_loss -0.8128 
2024-12-08 00:52:02.425106: Pseudo dice [np.float32(0.8816), np.float32(0.8644)] 
2024-12-08 00:52:02.432756: Epoch time: 15.36 s 
2024-12-08 00:52:02.437844: Yayy! New best EMA pseudo Dice: 0.8547999858856201 
2024-12-08 00:52:03.150356:  
2024-12-08 00:52:03.155480: Epoch 25 
2024-12-08 00:52:03.158520: Current learning rate: 0.00772 
2024-12-08 00:52:18.467981: train_loss -0.8649 
2024-12-08 00:52:18.474070: val_loss -0.8146 
2024-12-08 00:52:18.480189: Pseudo dice [np.float32(0.8833), np.float32(0.8659)] 
2024-12-08 00:52:18.485772: Epoch time: 15.32 s 
2024-12-08 00:52:18.491374: Yayy! New best EMA pseudo Dice: 0.8568000197410583 
2024-12-08 00:52:19.189495:  
2024-12-08 00:52:19.195068: Epoch 26 
2024-12-08 00:52:19.198089: Current learning rate: 0.00763 
2024-12-08 00:52:34.804909: train_loss -0.8659 
2024-12-08 00:52:34.812058: val_loss -0.8103 
2024-12-08 00:52:34.818813: Pseudo dice [np.float32(0.8813), np.float32(0.8615)] 
2024-12-08 00:52:34.823887: Epoch time: 15.62 s 
2024-12-08 00:52:34.829473: Yayy! New best EMA pseudo Dice: 0.858299970626831 
2024-12-08 00:52:35.560171:  
2024-12-08 00:52:35.565728: Epoch 27 
2024-12-08 00:52:35.570819: Current learning rate: 0.00753 
2024-12-08 00:52:51.283789: train_loss -0.867 
2024-12-08 00:52:51.290903: val_loss -0.8159 
2024-12-08 00:52:51.298003: Pseudo dice [np.float32(0.8839), np.float32(0.867)] 
2024-12-08 00:52:51.302540: Epoch time: 15.72 s 
2024-12-08 00:52:51.307613: Yayy! New best EMA pseudo Dice: 0.8600000143051147 
2024-12-08 00:52:52.211252:  
2024-12-08 00:52:52.217773: Epoch 28 
2024-12-08 00:52:52.221784: Current learning rate: 0.00744 
2024-12-08 00:53:07.876121: train_loss -0.8686 
2024-12-08 00:53:07.881819: val_loss -0.814 
2024-12-08 00:53:07.886877: Pseudo dice [np.float32(0.8833), np.float32(0.8662)] 
2024-12-08 00:53:07.892600: Epoch time: 15.67 s 
2024-12-08 00:53:07.897616: Yayy! New best EMA pseudo Dice: 0.8615000247955322 
2024-12-08 00:53:08.616038:  
2024-12-08 00:53:08.621049: Epoch 29 
2024-12-08 00:53:08.626074: Current learning rate: 0.00735 
2024-12-08 00:53:23.969828: train_loss -0.8693 
2024-12-08 00:53:23.976453: val_loss -0.8125 
2024-12-08 00:53:23.983078: Pseudo dice [np.float32(0.8836), np.float32(0.8643)] 
2024-12-08 00:53:23.988203: Epoch time: 15.35 s 
2024-12-08 00:53:23.994296: Yayy! New best EMA pseudo Dice: 0.8626999855041504 
2024-12-08 00:53:24.716068:  
2024-12-08 00:53:24.721217: Epoch 30 
2024-12-08 00:53:24.724784: Current learning rate: 0.00725 
2024-12-08 00:53:40.198010: train_loss -0.87 
2024-12-08 00:53:40.205547: val_loss -0.8126 
2024-12-08 00:53:40.213715: Pseudo dice [np.float32(0.8831), np.float32(0.8643)] 
2024-12-08 00:53:40.218277: Epoch time: 15.48 s 
2024-12-08 00:53:40.225165: Yayy! New best EMA pseudo Dice: 0.8637999892234802 
2024-12-08 00:53:40.948182:  
2024-12-08 00:53:40.954704: Epoch 31 
2024-12-08 00:53:40.958220: Current learning rate: 0.00716 
2024-12-08 00:53:56.512143: train_loss -0.8709 
2024-12-08 00:53:56.521792: val_loss -0.8152 
2024-12-08 00:53:56.526810: Pseudo dice [np.float32(0.8846), np.float32(0.8668)] 
2024-12-08 00:53:56.532911: Epoch time: 15.56 s 
2024-12-08 00:53:56.541008: Yayy! New best EMA pseudo Dice: 0.8650000095367432 
2024-12-08 00:53:57.290806:  
2024-12-08 00:53:57.296370: Epoch 32 
2024-12-08 00:53:57.299906: Current learning rate: 0.00707 
2024-12-08 00:54:13.031515: train_loss -0.8716 
2024-12-08 00:54:13.039191: val_loss -0.8153 
2024-12-08 00:54:13.048433: Pseudo dice [np.float32(0.885), np.float32(0.8676)] 
2024-12-08 00:54:13.055490: Epoch time: 15.74 s 
2024-12-08 00:54:13.062476: Yayy! New best EMA pseudo Dice: 0.866100013256073 
2024-12-08 00:54:13.791937:  
2024-12-08 00:54:13.796998: Epoch 33 
2024-12-08 00:54:13.799547: Current learning rate: 0.00697 
2024-12-08 00:54:29.402721: train_loss -0.8729 
2024-12-08 00:54:29.409298: val_loss -0.8144 
2024-12-08 00:54:29.415426: Pseudo dice [np.float32(0.884), np.float32(0.866)] 
2024-12-08 00:54:29.419478: Epoch time: 15.61 s 
2024-12-08 00:54:29.426097: Yayy! New best EMA pseudo Dice: 0.8669999837875366 
2024-12-08 00:54:30.137501:  
2024-12-08 00:54:30.142516: Epoch 34 
2024-12-08 00:54:30.146531: Current learning rate: 0.00688 
2024-12-08 00:54:45.476223: train_loss -0.8736 
2024-12-08 00:54:45.485722: val_loss -0.814 
2024-12-08 00:54:45.493060: Pseudo dice [np.float32(0.8838), np.float32(0.8645)] 
2024-12-08 00:54:45.499617: Epoch time: 15.34 s 
2024-12-08 00:54:45.504686: Yayy! New best EMA pseudo Dice: 0.8676999807357788 
2024-12-08 00:54:46.244445:  
2024-12-08 00:54:46.249457: Epoch 35 
2024-12-08 00:54:46.252969: Current learning rate: 0.00679 
2024-12-08 00:55:01.539691: train_loss -0.8747 
2024-12-08 00:55:01.547471: val_loss -0.8128 
2024-12-08 00:55:01.551063: Pseudo dice [np.float32(0.8833), np.float32(0.8644)] 
2024-12-08 00:55:01.558718: Epoch time: 15.3 s 
2024-12-08 00:55:01.563302: Yayy! New best EMA pseudo Dice: 0.8683000206947327 
2024-12-08 00:55:02.430572:  
2024-12-08 00:55:02.436146: Epoch 36 
2024-12-08 00:55:02.438700: Current learning rate: 0.00669 
2024-12-08 00:55:17.636864: train_loss -0.8756 
2024-12-08 00:55:17.646433: val_loss -0.8114 
2024-12-08 00:55:17.651694: Pseudo dice [np.float32(0.8818), np.float32(0.8648)] 
2024-12-08 00:55:17.656765: Epoch time: 15.21 s 
2024-12-08 00:55:17.662412: Yayy! New best EMA pseudo Dice: 0.8687999844551086 
2024-12-08 00:55:18.378586:  
2024-12-08 00:55:18.384102: Epoch 37 
2024-12-08 00:55:18.388615: Current learning rate: 0.0066 
2024-12-08 00:55:33.474095: train_loss -0.8761 
2024-12-08 00:55:33.481249: val_loss -0.8103 
2024-12-08 00:55:33.487378: Pseudo dice [np.float32(0.881), np.float32(0.8654)] 
2024-12-08 00:55:33.490928: Epoch time: 15.1 s 
2024-12-08 00:55:33.498216: Yayy! New best EMA pseudo Dice: 0.8693000078201294 
2024-12-08 00:55:34.227493:  
2024-12-08 00:55:34.233009: Epoch 38 
2024-12-08 00:55:34.236525: Current learning rate: 0.0065 
2024-12-08 00:55:49.492347: train_loss -0.8771 
2024-12-08 00:55:49.500019: val_loss -0.8141 
2024-12-08 00:55:49.505152: Pseudo dice [np.float32(0.8832), np.float32(0.8672)] 
2024-12-08 00:55:49.511296: Epoch time: 15.27 s 
2024-12-08 00:55:49.517371: Yayy! New best EMA pseudo Dice: 0.8698999881744385 
2024-12-08 00:55:50.250600:  
2024-12-08 00:55:50.257210: Epoch 39 
2024-12-08 00:55:50.259753: Current learning rate: 0.00641 
2024-12-08 00:56:05.674630: train_loss -0.8774 
2024-12-08 00:56:05.682258: val_loss -0.8109 
2024-12-08 00:56:05.688284: Pseudo dice [np.float32(0.8829), np.float32(0.8641)] 
2024-12-08 00:56:05.693817: Epoch time: 15.42 s 
2024-12-08 00:56:05.697388: Yayy! New best EMA pseudo Dice: 0.870199978351593 
2024-12-08 00:56:06.456072:  
2024-12-08 00:56:06.462637: Epoch 40 
2024-12-08 00:56:06.467197: Current learning rate: 0.00631 
2024-12-08 00:56:21.985642: train_loss -0.8784 
2024-12-08 00:56:21.992737: val_loss -0.8128 
2024-12-08 00:56:21.996354: Pseudo dice [np.float32(0.8834), np.float32(0.8666)] 
2024-12-08 00:56:22.003495: Epoch time: 15.53 s 
2024-12-08 00:56:22.008650: Yayy! New best EMA pseudo Dice: 0.8707000017166138 
2024-12-08 00:56:22.772313:  
2024-12-08 00:56:22.778462: Epoch 41 
2024-12-08 00:56:22.781491: Current learning rate: 0.00622 
2024-12-08 00:56:37.955772: train_loss -0.8788 
2024-12-08 00:56:37.962422: val_loss -0.8137 
2024-12-08 00:56:37.969462: Pseudo dice [np.float32(0.8842), np.float32(0.8671)] 
2024-12-08 00:56:37.974040: Epoch time: 15.18 s 
2024-12-08 00:56:37.979680: Yayy! New best EMA pseudo Dice: 0.8712000250816345 
2024-12-08 00:56:38.679388:  
2024-12-08 00:56:38.685407: Epoch 42 
2024-12-08 00:56:38.688917: Current learning rate: 0.00612 
2024-12-08 00:56:54.020534: train_loss -0.8801 
2024-12-08 00:56:54.027145: val_loss -0.8138 
2024-12-08 00:56:54.030738: Pseudo dice [np.float32(0.8842), np.float32(0.8668)] 
2024-12-08 00:56:54.037931: Epoch time: 15.34 s 
2024-12-08 00:56:54.045607: Yayy! New best EMA pseudo Dice: 0.8715999722480774 
2024-12-08 00:56:54.908285:  
2024-12-08 00:56:54.913801: Epoch 43 
2024-12-08 00:56:54.917309: Current learning rate: 0.00603 
2024-12-08 00:57:10.294066: train_loss -0.8806 
2024-12-08 00:57:10.300121: val_loss -0.8106 
2024-12-08 00:57:10.305718: Pseudo dice [np.float32(0.8813), np.float32(0.8673)] 
2024-12-08 00:57:10.312929: Epoch time: 15.39 s 
2024-12-08 00:57:10.318532: Yayy! New best EMA pseudo Dice: 0.8719000220298767 
2024-12-08 00:57:11.036513:  
2024-12-08 00:57:11.041529: Epoch 44 
2024-12-08 00:57:11.046043: Current learning rate: 0.00593 
2024-12-08 00:57:26.622847: train_loss -0.8805 
2024-12-08 00:57:26.630579: val_loss -0.8126 
2024-12-08 00:57:26.634629: Pseudo dice [np.float32(0.8836), np.float32(0.8656)] 
2024-12-08 00:57:26.642671: Epoch time: 15.59 s 
2024-12-08 00:57:26.649725: Yayy! New best EMA pseudo Dice: 0.8722000122070312 
2024-12-08 00:57:27.362839:  
2024-12-08 00:57:27.368402: Epoch 45 
2024-12-08 00:57:27.372228: Current learning rate: 0.00584 
2024-12-08 00:57:42.742423: train_loss -0.8811 
2024-12-08 00:57:42.748684: val_loss -0.8139 
2024-12-08 00:57:42.756331: Pseudo dice [np.float32(0.884), np.float32(0.8674)] 
2024-12-08 00:57:42.760347: Epoch time: 15.38 s 
2024-12-08 00:57:42.767940: Yayy! New best EMA pseudo Dice: 0.8725000023841858 
2024-12-08 00:57:43.480434:  
2024-12-08 00:57:43.485994: Epoch 46 
2024-12-08 00:57:43.491633: Current learning rate: 0.00574 
2024-12-08 00:57:59.120877: train_loss -0.8815 
2024-12-08 00:57:59.127989: val_loss -0.812 
2024-12-08 00:57:59.135143: Pseudo dice [np.float32(0.8824), np.float32(0.867)] 
2024-12-08 00:57:59.139718: Epoch time: 15.64 s 
2024-12-08 00:57:59.144034: Yayy! New best EMA pseudo Dice: 0.8726999759674072 
2024-12-08 00:57:59.837991:  
2024-12-08 00:57:59.843532: Epoch 47 
2024-12-08 00:57:59.849617: Current learning rate: 0.00565 
2024-12-08 00:58:15.210147: train_loss -0.8821 
2024-12-08 00:58:15.217724: val_loss -0.8107 
2024-12-08 00:58:15.222751: Pseudo dice [np.float32(0.8834), np.float32(0.8654)] 
2024-12-08 00:58:15.228808: Epoch time: 15.37 s 
2024-12-08 00:58:15.233824: Yayy! New best EMA pseudo Dice: 0.8729000091552734 
2024-12-08 00:58:15.918765:  
2024-12-08 00:58:15.923779: Epoch 48 
2024-12-08 00:58:15.928797: Current learning rate: 0.00555 
2024-12-08 00:58:31.481628: train_loss -0.8827 
2024-12-08 00:58:31.488191: val_loss -0.813 
2024-12-08 00:58:31.493731: Pseudo dice [np.float32(0.8846), np.float32(0.8664)] 
2024-12-08 00:58:31.501396: Epoch time: 15.56 s 
2024-12-08 00:58:31.506490: Yayy! New best EMA pseudo Dice: 0.873199999332428 
2024-12-08 00:58:32.280469:  
2024-12-08 00:58:32.287071: Epoch 49 
2024-12-08 00:58:32.292646: Current learning rate: 0.00546 
2024-12-08 00:58:48.029685: train_loss -0.883 
2024-12-08 00:58:48.038950: val_loss -0.8103 
2024-12-08 00:58:48.045573: Pseudo dice [np.float32(0.8832), np.float32(0.8642)] 
2024-12-08 00:58:48.051714: Epoch time: 15.75 s 
2024-12-08 00:58:48.083783: Yayy! New best EMA pseudo Dice: 0.873199999332428 
2024-12-08 00:58:48.783440:  
2024-12-08 00:58:48.790065: Epoch 50 
2024-12-08 00:58:48.793650: Current learning rate: 0.00536 
2024-12-08 00:59:04.390124: train_loss -0.8839 
2024-12-08 00:59:04.397753: val_loss -0.8111 
2024-12-08 00:59:04.403386: Pseudo dice [np.float32(0.883), np.float32(0.8664)] 
2024-12-08 00:59:04.409504: Epoch time: 15.61 s 
2024-12-08 00:59:04.416592: Yayy! New best EMA pseudo Dice: 0.8733999729156494 
2024-12-08 00:59:05.323664:  
2024-12-08 00:59:05.329254: Epoch 51 
2024-12-08 00:59:05.333290: Current learning rate: 0.00526 
2024-12-08 00:59:20.885105: train_loss -0.885 
2024-12-08 00:59:20.892243: val_loss -0.8087 
2024-12-08 00:59:20.899292: Pseudo dice [np.float32(0.8805), np.float32(0.8655)] 
2024-12-08 00:59:20.905462: Epoch time: 15.56 s 
2024-12-08 00:59:21.600799:  
2024-12-08 00:59:21.607877: Epoch 52 
2024-12-08 00:59:21.612449: Current learning rate: 0.00517 
2024-12-08 00:59:37.236695: train_loss -0.8849 
2024-12-08 00:59:37.244857: val_loss -0.8106 
2024-12-08 00:59:37.250467: Pseudo dice [np.float32(0.884), np.float32(0.8646)] 
2024-12-08 00:59:37.259118: Epoch time: 15.64 s 
2024-12-08 00:59:37.266253: Yayy! New best EMA pseudo Dice: 0.8733999729156494 
2024-12-08 00:59:37.985697:  
2024-12-08 00:59:37.992251: Epoch 53 
2024-12-08 00:59:37.995778: Current learning rate: 0.00507 
2024-12-08 00:59:53.409435: train_loss -0.8856 
2024-12-08 00:59:53.418424: val_loss -0.8139 
2024-12-08 00:59:53.423342: Pseudo dice [np.float32(0.8846), np.float32(0.8675)] 
2024-12-08 00:59:53.429946: Epoch time: 15.42 s 
2024-12-08 00:59:53.435529: Yayy! New best EMA pseudo Dice: 0.8737000226974487 
2024-12-08 00:59:54.140463:  
2024-12-08 00:59:54.145477: Epoch 54 
2024-12-08 00:59:54.148987: Current learning rate: 0.00497 
2024-12-08 01:00:09.534636: train_loss -0.8859 
2024-12-08 01:00:09.540509: val_loss -0.8092 
2024-12-08 01:00:09.545589: Pseudo dice [np.float32(0.8814), np.float32(0.8661)] 
2024-12-08 01:00:09.551739: Epoch time: 15.39 s 
2024-12-08 01:00:09.555796: Yayy! New best EMA pseudo Dice: 0.8737000226974487 
2024-12-08 01:00:10.264622:  
2024-12-08 01:00:10.270683: Epoch 55 
2024-12-08 01:00:10.275226: Current learning rate: 0.00487 
2024-12-08 01:00:25.607890: train_loss -0.8867 
2024-12-08 01:00:25.614028: val_loss -0.8115 
2024-12-08 01:00:25.620167: Pseudo dice [np.float32(0.883), np.float32(0.8666)] 
2024-12-08 01:00:25.626333: Epoch time: 15.34 s 
2024-12-08 01:00:25.633543: Yayy! New best EMA pseudo Dice: 0.8737999796867371 
2024-12-08 01:00:26.336874:  
2024-12-08 01:00:26.341919: Epoch 56 
2024-12-08 01:00:26.346817: Current learning rate: 0.00478 
2024-12-08 01:00:41.612329: train_loss -0.8869 
2024-12-08 01:00:41.620882: val_loss -0.8101 
2024-12-08 01:00:41.625895: Pseudo dice [np.float32(0.8832), np.float32(0.8646)] 
2024-12-08 01:00:41.631918: Epoch time: 15.28 s 
2024-12-08 01:00:41.638440: Yayy! New best EMA pseudo Dice: 0.8737999796867371 
2024-12-08 01:00:42.350883:  
2024-12-08 01:00:42.356905: Epoch 57 
2024-12-08 01:00:42.360412: Current learning rate: 0.00468 
2024-12-08 01:00:57.878179: train_loss -0.887 
2024-12-08 01:00:57.886858: val_loss -0.8122 
2024-12-08 01:00:57.894462: Pseudo dice [np.float32(0.8846), np.float32(0.8664)] 
2024-12-08 01:00:57.901198: Epoch time: 15.53 s 
2024-12-08 01:00:57.907806: Yayy! New best EMA pseudo Dice: 0.8740000128746033 
2024-12-08 01:00:58.608996:  
2024-12-08 01:00:58.614519: Epoch 58 
2024-12-08 01:00:58.619537: Current learning rate: 0.00458 
2024-12-08 01:01:14.302047: train_loss -0.888 
2024-12-08 01:01:14.310108: val_loss -0.8091 
2024-12-08 01:01:14.314670: Pseudo dice [np.float32(0.882), np.float32(0.8658)] 
2024-12-08 01:01:14.321318: Epoch time: 15.69 s 
2024-12-08 01:01:15.203926:  
2024-12-08 01:01:15.209988: Epoch 59 
2024-12-08 01:01:15.213021: Current learning rate: 0.00448 
2024-12-08 01:01:30.831613: train_loss -0.8887 
2024-12-08 01:01:30.839342: val_loss -0.8116 
2024-12-08 01:01:30.845981: Pseudo dice [np.float32(0.884), np.float32(0.8661)] 
2024-12-08 01:01:30.851091: Epoch time: 15.63 s 
2024-12-08 01:01:30.858239: Yayy! New best EMA pseudo Dice: 0.8741000294685364 
2024-12-08 01:01:31.604417:  
2024-12-08 01:01:31.609704: Epoch 60 
2024-12-08 01:01:31.613212: Current learning rate: 0.00438 
2024-12-08 01:01:47.278834: train_loss -0.8883 
2024-12-08 01:01:47.285973: val_loss -0.8108 
2024-12-08 01:01:47.290988: Pseudo dice [np.float32(0.8834), np.float32(0.8669)] 
2024-12-08 01:01:47.298048: Epoch time: 15.67 s 
2024-12-08 01:01:47.303088: Yayy! New best EMA pseudo Dice: 0.8741999864578247 
2024-12-08 01:01:48.020713:  
2024-12-08 01:01:48.027344: Epoch 61 
2024-12-08 01:01:48.031361: Current learning rate: 0.00429 
2024-12-08 01:02:03.383584: train_loss -0.8891 
2024-12-08 01:02:03.391670: val_loss -0.8074 
2024-12-08 01:02:03.398217: Pseudo dice [np.float32(0.8823), np.float32(0.8645)] 
2024-12-08 01:02:03.404781: Epoch time: 15.36 s 
2024-12-08 01:02:04.079349:  
2024-12-08 01:02:04.084372: Epoch 62 
2024-12-08 01:02:04.089386: Current learning rate: 0.00419 
2024-12-08 01:02:19.223122: train_loss -0.8895 
2024-12-08 01:02:19.230248: val_loss -0.8088 
2024-12-08 01:02:19.235822: Pseudo dice [np.float32(0.8828), np.float32(0.8649)] 
2024-12-08 01:02:19.239865: Epoch time: 15.14 s 
2024-12-08 01:02:19.930865:  
2024-12-08 01:02:19.936421: Epoch 63 
2024-12-08 01:02:19.938952: Current learning rate: 0.00409 
2024-12-08 01:02:35.149400: train_loss -0.8901 
2024-12-08 01:02:35.157080: val_loss -0.8091 
2024-12-08 01:02:35.162149: Pseudo dice [np.float32(0.8834), np.float32(0.8644)] 
2024-12-08 01:02:35.169791: Epoch time: 15.22 s 
2024-12-08 01:02:35.890604:  
2024-12-08 01:02:35.897204: Epoch 64 
2024-12-08 01:02:35.900618: Current learning rate: 0.00399 
2024-12-08 01:02:51.443292: train_loss -0.8899 
2024-12-08 01:02:51.453370: val_loss -0.809 
2024-12-08 01:02:51.459431: Pseudo dice [np.float32(0.8829), np.float32(0.8663)] 
2024-12-08 01:02:51.466039: Epoch time: 15.55 s 
2024-12-08 01:02:52.158952:  
2024-12-08 01:02:52.165132: Epoch 65 
2024-12-08 01:02:52.169151: Current learning rate: 0.00389 
2024-12-08 01:03:07.427721: train_loss -0.8903 
2024-12-08 01:03:07.434314: val_loss -0.8109 
2024-12-08 01:03:07.439933: Pseudo dice [np.float32(0.8843), np.float32(0.8668)] 
2024-12-08 01:03:07.447614: Epoch time: 15.27 s 
2024-12-08 01:03:07.452185: Yayy! New best EMA pseudo Dice: 0.8743000030517578 
2024-12-08 01:03:08.174739:  
2024-12-08 01:03:08.181785: Epoch 66 
2024-12-08 01:03:08.185815: Current learning rate: 0.00379 
2024-12-08 01:03:23.657193: train_loss -0.8906 
2024-12-08 01:03:23.665229: val_loss -0.8087 
2024-12-08 01:03:23.671258: Pseudo dice [np.float32(0.8819), np.float32(0.8659)] 
2024-12-08 01:03:23.675270: Epoch time: 15.48 s 
2024-12-08 01:03:24.552551:  
2024-12-08 01:03:24.558088: Epoch 67 
2024-12-08 01:03:24.563760: Current learning rate: 0.00369 
2024-12-08 01:03:39.762559: train_loss -0.8904 
2024-12-08 01:03:39.768703: val_loss -0.8068 
2024-12-08 01:03:39.775846: Pseudo dice [np.float32(0.8819), np.float32(0.8636)] 
2024-12-08 01:03:39.781446: Epoch time: 15.21 s 
2024-12-08 01:03:40.491106:  
2024-12-08 01:03:40.497125: Epoch 68 
2024-12-08 01:03:40.501139: Current learning rate: 0.00359 
2024-12-08 01:03:55.801756: train_loss -0.8912 
2024-12-08 01:03:55.811046: val_loss -0.8094 
2024-12-08 01:03:55.817684: Pseudo dice [np.float32(0.8833), np.float32(0.8657)] 
2024-12-08 01:03:55.823769: Epoch time: 15.31 s 
2024-12-08 01:03:56.563106:  
2024-12-08 01:03:56.569764: Epoch 69 
2024-12-08 01:03:56.574429: Current learning rate: 0.00349 
2024-12-08 01:04:11.747787: train_loss -0.892 
2024-12-08 01:04:11.753891: val_loss -0.8072 
2024-12-08 01:04:11.759483: Pseudo dice [np.float32(0.8826), np.float32(0.8652)] 
2024-12-08 01:04:11.766613: Epoch time: 15.18 s 
2024-12-08 01:04:12.486732:  
2024-12-08 01:04:12.491289: Epoch 70 
2024-12-08 01:04:12.494837: Current learning rate: 0.00338 
2024-12-08 01:04:27.548600: train_loss -0.8923 
2024-12-08 01:04:27.555761: val_loss -0.8091 
2024-12-08 01:04:27.561370: Pseudo dice [np.float32(0.8835), np.float32(0.8648)] 
2024-12-08 01:04:27.567997: Epoch time: 15.06 s 
2024-12-08 01:04:28.277019:  
2024-12-08 01:04:28.282561: Epoch 71 
2024-12-08 01:04:28.286074: Current learning rate: 0.00328 
2024-12-08 01:04:43.589798: train_loss -0.8924 
2024-12-08 01:04:43.598463: val_loss -0.8079 
2024-12-08 01:04:43.605048: Pseudo dice [np.float32(0.8825), np.float32(0.8646)] 
2024-12-08 01:04:43.610151: Epoch time: 15.31 s 
2024-12-08 01:04:44.324572:  
2024-12-08 01:04:44.329584: Epoch 72 
2024-12-08 01:04:44.332594: Current learning rate: 0.00318 
2024-12-08 01:04:59.830406: train_loss -0.8928 
2024-12-08 01:04:59.837524: val_loss -0.8073 
2024-12-08 01:04:59.845201: Pseudo dice [np.float32(0.8829), np.float32(0.8639)] 
2024-12-08 01:04:59.848772: Epoch time: 15.51 s 
2024-12-08 01:05:00.569692:  
2024-12-08 01:05:00.575256: Epoch 73 
2024-12-08 01:05:00.580357: Current learning rate: 0.00308 
2024-12-08 01:05:15.948013: train_loss -0.8932 
2024-12-08 01:05:15.955650: val_loss -0.8076 
2024-12-08 01:05:15.960714: Pseudo dice [np.float32(0.8823), np.float32(0.8649)] 
2024-12-08 01:05:15.965764: Epoch time: 15.38 s 
2024-12-08 01:05:16.842481:  
2024-12-08 01:05:16.848523: Epoch 74 
2024-12-08 01:05:16.853187: Current learning rate: 0.00297 
2024-12-08 01:05:32.086366: train_loss -0.8936 
2024-12-08 01:05:32.093496: val_loss -0.808 
2024-12-08 01:05:32.097051: Pseudo dice [np.float32(0.882), np.float32(0.8658)] 
2024-12-08 01:05:32.104217: Epoch time: 15.24 s 
2024-12-08 01:05:32.810645:  
2024-12-08 01:05:32.817183: Epoch 75 
2024-12-08 01:05:32.820690: Current learning rate: 0.00287 
2024-12-08 01:05:48.404921: train_loss -0.8934 
2024-12-08 01:05:48.411508: val_loss -0.807 
2024-12-08 01:05:48.418060: Pseudo dice [np.float32(0.8825), np.float32(0.864)] 
2024-12-08 01:05:48.424082: Epoch time: 15.59 s 
2024-12-08 01:05:49.147943:  
2024-12-08 01:05:49.153477: Epoch 76 
2024-12-08 01:05:49.155987: Current learning rate: 0.00277 
2024-12-08 01:06:04.465171: train_loss -0.8939 
2024-12-08 01:06:04.472833: val_loss -0.808 
2024-12-08 01:06:04.478913: Pseudo dice [np.float32(0.8829), np.float32(0.8647)] 
2024-12-08 01:06:04.485357: Epoch time: 15.32 s 
2024-12-08 01:06:05.203663:  
2024-12-08 01:06:05.209195: Epoch 77 
2024-12-08 01:06:05.212749: Current learning rate: 0.00266 
2024-12-08 01:06:20.742761: train_loss -0.8944 
2024-12-08 01:06:20.748911: val_loss -0.8063 
2024-12-08 01:06:20.755530: Pseudo dice [np.float32(0.8815), np.float32(0.8646)] 
2024-12-08 01:06:20.760078: Epoch time: 15.54 s 
2024-12-08 01:06:21.489951:  
2024-12-08 01:06:21.495480: Epoch 78 
2024-12-08 01:06:21.498502: Current learning rate: 0.00256 
2024-12-08 01:06:36.893105: train_loss -0.8948 
2024-12-08 01:06:36.900158: val_loss -0.8055 
2024-12-08 01:06:36.907788: Pseudo dice [np.float32(0.8828), np.float32(0.8624)] 
2024-12-08 01:06:36.912807: Epoch time: 15.4 s 
2024-12-08 01:06:37.632465:  
2024-12-08 01:06:37.638004: Epoch 79 
2024-12-08 01:06:37.642519: Current learning rate: 0.00245 
2024-12-08 01:06:53.032272: train_loss -0.895 
2024-12-08 01:06:53.041917: val_loss -0.8072 
2024-12-08 01:06:53.049020: Pseudo dice [np.float32(0.8836), np.float32(0.8649)] 
2024-12-08 01:06:53.053583: Epoch time: 15.4 s 
2024-12-08 01:06:53.774220:  
2024-12-08 01:06:53.779233: Epoch 80 
2024-12-08 01:06:53.784252: Current learning rate: 0.00235 
2024-12-08 01:07:08.965165: train_loss -0.8953 
2024-12-08 01:07:08.974256: val_loss -0.8062 
2024-12-08 01:07:08.979903: Pseudo dice [np.float32(0.8818), np.float32(0.8644)] 
2024-12-08 01:07:08.985521: Epoch time: 15.19 s 
2024-12-08 01:07:09.707271:  
2024-12-08 01:07:09.712840: Epoch 81 
2024-12-08 01:07:09.716383: Current learning rate: 0.00224 
2024-12-08 01:07:25.024003: train_loss -0.8952 
2024-12-08 01:07:25.031184: val_loss -0.8054 
2024-12-08 01:07:25.036823: Pseudo dice [np.float32(0.8806), np.float32(0.8636)] 
2024-12-08 01:07:25.043965: Epoch time: 15.32 s 
2024-12-08 01:07:25.944891:  
2024-12-08 01:07:25.951044: Epoch 82 
2024-12-08 01:07:25.954569: Current learning rate: 0.00214 
2024-12-08 01:07:41.188062: train_loss -0.896 
2024-12-08 01:07:41.194864: val_loss -0.8042 
2024-12-08 01:07:41.200894: Pseudo dice [np.float32(0.8806), np.float32(0.8638)] 
2024-12-08 01:07:41.207563: Epoch time: 15.24 s 
2024-12-08 01:07:41.893311:  
2024-12-08 01:07:41.898887: Epoch 83 
2024-12-08 01:07:41.903899: Current learning rate: 0.00203 
2024-12-08 01:07:57.321897: train_loss -0.8965 
2024-12-08 01:07:57.331110: val_loss -0.8048 
2024-12-08 01:07:57.335699: Pseudo dice [np.float32(0.8819), np.float32(0.8637)] 
2024-12-08 01:07:57.340256: Epoch time: 15.43 s 
2024-12-08 01:07:58.019357:  
2024-12-08 01:07:58.024393: Epoch 84 
2024-12-08 01:07:58.030539: Current learning rate: 0.00192 
2024-12-08 01:08:13.408015: train_loss -0.8967 
2024-12-08 01:08:13.415669: val_loss -0.808 
2024-12-08 01:08:13.420810: Pseudo dice [np.float32(0.8834), np.float32(0.8657)] 
2024-12-08 01:08:13.427954: Epoch time: 15.39 s 
2024-12-08 01:08:14.107727:  
2024-12-08 01:08:14.113259: Epoch 85 
2024-12-08 01:08:14.116769: Current learning rate: 0.00181 
2024-12-08 01:08:29.420770: train_loss -0.8975 
2024-12-08 01:08:29.426857: val_loss -0.8067 
2024-12-08 01:08:29.434015: Pseudo dice [np.float32(0.8822), np.float32(0.8649)] 
2024-12-08 01:08:29.438565: Epoch time: 15.31 s 
2024-12-08 01:08:30.105216:  
2024-12-08 01:08:30.110747: Epoch 86 
2024-12-08 01:08:30.114268: Current learning rate: 0.0017 
2024-12-08 01:08:45.330253: train_loss -0.8973 
2024-12-08 01:08:45.337341: val_loss -0.8059 
2024-12-08 01:08:45.345014: Pseudo dice [np.float32(0.8819), np.float32(0.8649)] 
2024-12-08 01:08:45.350628: Epoch time: 15.23 s 
2024-12-08 01:08:46.007469:  
2024-12-08 01:08:46.012518: Epoch 87 
2024-12-08 01:08:46.017538: Current learning rate: 0.00159 
2024-12-08 01:09:01.312317: train_loss -0.897 
2024-12-08 01:09:01.319965: val_loss -0.8054 
2024-12-08 01:09:01.325077: Pseudo dice [np.float32(0.8817), np.float32(0.8641)] 
2024-12-08 01:09:01.330215: Epoch time: 15.31 s 
2024-12-08 01:09:02.028930:  
2024-12-08 01:09:02.034862: Epoch 88 
2024-12-08 01:09:02.037888: Current learning rate: 0.00148 
2024-12-08 01:09:17.273022: train_loss -0.8977 
2024-12-08 01:09:17.281737: val_loss -0.8061 
2024-12-08 01:09:17.289331: Pseudo dice [np.float32(0.8835), np.float32(0.8639)] 
2024-12-08 01:09:17.294874: Epoch time: 15.24 s 
2024-12-08 01:09:17.968156:  
2024-12-08 01:09:17.974712: Epoch 89 
2024-12-08 01:09:17.978739: Current learning rate: 0.00137 
2024-12-08 01:09:33.202846: train_loss -0.8977 
2024-12-08 01:09:33.209868: val_loss -0.805 
2024-12-08 01:09:33.215469: Pseudo dice [np.float32(0.8813), np.float32(0.8638)] 
2024-12-08 01:09:33.220492: Epoch time: 15.23 s 
2024-12-08 01:09:34.059630:  
2024-12-08 01:09:34.065653: Epoch 90 
2024-12-08 01:09:34.069155: Current learning rate: 0.00126 
2024-12-08 01:09:49.305204: train_loss -0.8982 
2024-12-08 01:09:49.313904: val_loss -0.8074 
2024-12-08 01:09:49.319542: Pseudo dice [np.float32(0.8831), np.float32(0.8656)] 
2024-12-08 01:09:49.324646: Epoch time: 15.25 s 
2024-12-08 01:09:49.984874:  
2024-12-08 01:09:49.990903: Epoch 91 
2024-12-08 01:09:49.995960: Current learning rate: 0.00115 
2024-12-08 01:10:05.181892: train_loss -0.8989 
2024-12-08 01:10:05.190038: val_loss -0.806 
2024-12-08 01:10:05.196182: Pseudo dice [np.float32(0.8833), np.float32(0.8639)] 
2024-12-08 01:10:05.200285: Epoch time: 15.2 s 
2024-12-08 01:10:05.865702:  
2024-12-08 01:10:05.871727: Epoch 92 
2024-12-08 01:10:05.876916: Current learning rate: 0.00103 
2024-12-08 01:10:21.075719: train_loss -0.8983 
2024-12-08 01:10:21.083323: val_loss -0.804 
2024-12-08 01:10:21.088980: Pseudo dice [np.float32(0.8806), np.float32(0.8632)] 
2024-12-08 01:10:21.093569: Epoch time: 15.21 s 
2024-12-08 01:10:21.760088:  
2024-12-08 01:10:21.765653: Epoch 93 
2024-12-08 01:10:21.769245: Current learning rate: 0.00091 
2024-12-08 01:10:36.923664: train_loss -0.899 
2024-12-08 01:10:36.929692: val_loss -0.8039 
2024-12-08 01:10:36.935743: Pseudo dice [np.float32(0.882), np.float32(0.8628)] 
2024-12-08 01:10:36.941016: Epoch time: 15.16 s 
2024-12-08 01:10:37.604679:  
2024-12-08 01:10:37.614417: Epoch 94 
2024-12-08 01:10:37.620018: Current learning rate: 0.00079 
2024-12-08 01:10:52.882339: train_loss -0.8995 
2024-12-08 01:10:52.888471: val_loss -0.8065 
2024-12-08 01:10:52.893566: Pseudo dice [np.float32(0.8826), np.float32(0.8646)] 
2024-12-08 01:10:52.900192: Epoch time: 15.28 s 
2024-12-08 01:10:53.563497:  
2024-12-08 01:10:53.569067: Epoch 95 
2024-12-08 01:10:53.573653: Current learning rate: 0.00067 
2024-12-08 01:11:08.846958: train_loss -0.899 
2024-12-08 01:11:08.857047: val_loss -0.8038 
2024-12-08 01:11:08.862170: Pseudo dice [np.float32(0.8814), np.float32(0.8639)] 
2024-12-08 01:11:08.869318: Epoch time: 15.28 s 
2024-12-08 01:11:09.537507:  
2024-12-08 01:11:09.543562: Epoch 96 
2024-12-08 01:11:09.548536: Current learning rate: 0.00055 
2024-12-08 01:11:24.779265: train_loss -0.8994 
2024-12-08 01:11:24.786349: val_loss -0.8063 
2024-12-08 01:11:24.793961: Pseudo dice [np.float32(0.882), np.float32(0.8657)] 
2024-12-08 01:11:24.798983: Epoch time: 15.24 s 
2024-12-08 01:11:25.488431:  
2024-12-08 01:11:25.494971: Epoch 97 
2024-12-08 01:11:25.498977: Current learning rate: 0.00043 
2024-12-08 01:11:40.980822: train_loss -0.8996 
2024-12-08 01:11:40.989362: val_loss -0.8034 
2024-12-08 01:11:40.996412: Pseudo dice [np.float32(0.8815), np.float32(0.8632)] 
2024-12-08 01:11:41.001552: Epoch time: 15.49 s 
2024-12-08 01:11:41.694181:  
2024-12-08 01:11:41.701596: Epoch 98 
2024-12-08 01:11:41.707163: Current learning rate: 0.0003 
2024-12-08 01:11:57.281479: train_loss -0.8993 
2024-12-08 01:11:57.292734: val_loss -0.8054 
2024-12-08 01:11:57.299308: Pseudo dice [np.float32(0.881), np.float32(0.8646)] 
2024-12-08 01:11:57.305402: Epoch time: 15.59 s 
2024-12-08 01:11:58.183784:  
2024-12-08 01:11:58.189872: Epoch 99 
2024-12-08 01:11:58.196029: Current learning rate: 0.00016 
2024-12-08 01:12:13.579677: train_loss -0.8999 
2024-12-08 01:12:13.586314: val_loss -0.8042 
2024-12-08 01:12:13.592962: Pseudo dice [np.float32(0.8815), np.float32(0.8639)] 
2024-12-08 01:12:13.597584: Epoch time: 15.4 s 
2024-12-08 01:12:14.330911: Training done. 
2024-12-08 01:12:14.464853: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-08 01:12:14.474363: The split file contains 5 splits. 
2024-12-08 01:12:14.479366: Desired fold for training: 0 
2024-12-08 01:12:14.487875: This split has 208 training and 52 validation cases. 
2024-12-08 01:12:14.499390: predicting hippocampus_017 
2024-12-08 01:12:14.515926: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-08 01:12:14.939441: predicting hippocampus_019 
2024-12-08 01:12:14.946955: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-08 01:12:15.337731: predicting hippocampus_033 
2024-12-08 01:12:15.344244: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-08 01:12:15.666636: predicting hippocampus_035 
2024-12-08 01:12:15.674146: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-08 01:12:16.003006: predicting hippocampus_037 
2024-12-08 01:12:16.010000: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-08 01:12:16.297939: predicting hippocampus_049 
2024-12-08 01:12:16.304447: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-08 01:12:16.659928: predicting hippocampus_052 
2024-12-08 01:12:16.667408: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-08 01:12:17.085811: predicting hippocampus_065 
2024-12-08 01:12:17.094322: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-08 01:12:17.480686: predicting hippocampus_083 
2024-12-08 01:12:17.488194: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-08 01:12:17.939352: predicting hippocampus_088 
2024-12-08 01:12:17.945871: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-08 01:12:19.252280: predicting hippocampus_090 
2024-12-08 01:12:19.264302: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-08 01:12:19.721509: predicting hippocampus_092 
2024-12-08 01:12:19.731538: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-08 01:12:20.096528: predicting hippocampus_095 
2024-12-08 01:12:20.111551: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-08 01:12:20.533157: predicting hippocampus_107 
2024-12-08 01:12:20.544671: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-08 01:12:20.913451: predicting hippocampus_108 
2024-12-08 01:12:20.923497: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-08 01:12:21.319529: predicting hippocampus_123 
2024-12-08 01:12:21.334545: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-08 01:12:21.705061: predicting hippocampus_125 
2024-12-08 01:12:21.714073: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-08 01:12:22.390472: predicting hippocampus_157 
2024-12-08 01:12:22.399986: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-08 01:12:22.700507: predicting hippocampus_164 
2024-12-08 01:12:22.711015: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-08 01:12:23.500986: predicting hippocampus_169 
2024-12-08 01:12:23.511499: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-08 01:12:23.849921: predicting hippocampus_175 
2024-12-08 01:12:23.867942: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-08 01:12:24.169190: predicting hippocampus_185 
2024-12-08 01:12:24.175698: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-08 01:12:24.472373: predicting hippocampus_190 
2024-12-08 01:12:24.479884: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-08 01:12:24.746512: predicting hippocampus_194 
2024-12-08 01:12:24.755020: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-08 01:12:25.023594: predicting hippocampus_204 
2024-12-08 01:12:25.030603: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-08 01:12:25.360396: predicting hippocampus_205 
2024-12-08 01:12:25.368911: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-08 01:12:25.652503: predicting hippocampus_210 
2024-12-08 01:12:25.660532: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-08 01:12:26.091543: predicting hippocampus_217 
2024-12-08 01:12:26.099551: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-08 01:12:26.358744: predicting hippocampus_219 
2024-12-08 01:12:26.368256: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-08 01:12:26.715937: predicting hippocampus_229 
2024-12-08 01:12:26.725448: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-08 01:12:27.065985: predicting hippocampus_244 
2024-12-08 01:12:27.075487: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-08 01:12:27.360288: predicting hippocampus_261 
2024-12-08 01:12:27.368799: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-08 01:12:27.925113: predicting hippocampus_264 
2024-12-08 01:12:27.933616: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-08 01:12:28.254911: predicting hippocampus_277 
2024-12-08 01:12:28.262907: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-08 01:12:28.726717: predicting hippocampus_280 
2024-12-08 01:12:28.742226: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-08 01:12:29.008955: predicting hippocampus_286 
2024-12-08 01:12:29.023966: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-08 01:12:29.392311: predicting hippocampus_288 
2024-12-08 01:12:29.400322: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-08 01:12:29.741566: predicting hippocampus_289 
2024-12-08 01:12:29.749076: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-08 01:12:30.047918: predicting hippocampus_296 
2024-12-08 01:12:30.056424: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-08 01:12:30.351119: predicting hippocampus_305 
2024-12-08 01:12:30.358303: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-08 01:12:30.613003: predicting hippocampus_308 
2024-12-08 01:12:30.621511: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-08 01:12:30.956057: predicting hippocampus_317 
2024-12-08 01:12:30.966562: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-08 01:12:31.257059: predicting hippocampus_327 
2024-12-08 01:12:31.266567: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-08 01:12:31.512292: predicting hippocampus_330 
2024-12-08 01:12:31.520802: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-08 01:12:31.803975: predicting hippocampus_332 
2024-12-08 01:12:31.811983: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-08 01:12:32.127725: predicting hippocampus_338 
2024-12-08 01:12:32.138231: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-08 01:12:32.539051: predicting hippocampus_349 
2024-12-08 01:12:32.545557: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-08 01:12:32.831300: predicting hippocampus_350 
2024-12-08 01:12:32.839812: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-08 01:12:33.132247: predicting hippocampus_356 
2024-12-08 01:12:33.140561: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-08 01:12:33.466480: predicting hippocampus_358 
2024-12-08 01:12:33.476987: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-08 01:12:33.766626: predicting hippocampus_374 
2024-12-08 01:12:33.787644: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-08 01:12:34.117185: predicting hippocampus_394 
2024-12-08 01:12:34.125688: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-08 01:12:38.437898: Validation complete 
2024-12-08 01:12:38.442899: Mean Validation Dice:  0.8783194347152328 
