
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-07 06:47:42.077973: do_dummy_2d_data_aug: False 
2024-12-07 06:47:42.083971: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-07 06:47:42.087970: The split file contains 5 splits. 
2024-12-07 06:47:42.089975: Desired fold for training: 0 
2024-12-07 06:47:42.092972: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 366, 'patch_size': [56, 40], 'median_image_size_in_voxels': [50.0, 35.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-07 06:47:49.194896: unpacking dataset... 
2024-12-07 06:47:49.412196: unpacking done... 
2024-12-07 06:47:50.377105:  
2024-12-07 06:47:50.382117: Epoch 0 
2024-12-07 06:47:50.384621: Current learning rate: 0.01 
2024-12-07 06:48:03.394291: train_loss -0.163 
2024-12-07 06:48:03.400311: val_loss -0.6507 
2024-12-07 06:48:03.402822: Pseudo dice [np.float32(0.7928), np.float32(0.747)] 
2024-12-07 06:48:03.406845: Epoch time: 13.02 s 
2024-12-07 06:48:03.409873: Yayy! New best EMA pseudo Dice: 0.7699000239372253 
2024-12-07 06:48:04.057014:  
2024-12-07 06:48:04.063123: Epoch 1 
2024-12-07 06:48:04.066185: Current learning rate: 0.00991 
2024-12-07 06:48:16.255849: train_loss -0.6937 
2024-12-07 06:48:16.260916: val_loss -0.7576 
2024-12-07 06:48:16.263963: Pseudo dice [np.float32(0.848), np.float32(0.8262)] 
2024-12-07 06:48:16.267472: Epoch time: 12.2 s 
2024-12-07 06:48:16.269980: Yayy! New best EMA pseudo Dice: 0.7766000032424927 
2024-12-07 06:48:16.982187:  
2024-12-07 06:48:16.987125: Epoch 2 
2024-12-07 06:48:16.990137: Current learning rate: 0.00982 
2024-12-07 06:48:29.148644: train_loss -0.7635 
2024-12-07 06:48:29.154160: val_loss -0.7906 
2024-12-07 06:48:29.156670: Pseudo dice [np.float32(0.8682), np.float32(0.8485)] 
2024-12-07 06:48:29.160182: Epoch time: 12.17 s 
2024-12-07 06:48:29.162692: Yayy! New best EMA pseudo Dice: 0.7847999930381775 
2024-12-07 06:48:29.918430:  
2024-12-07 06:48:29.921443: Epoch 3 
2024-12-07 06:48:29.925461: Current learning rate: 0.00973 
2024-12-07 06:48:42.153747: train_loss -0.7907 
2024-12-07 06:48:42.158757: val_loss -0.7986 
2024-12-07 06:48:42.162766: Pseudo dice [np.float32(0.8703), np.float32(0.8542)] 
2024-12-07 06:48:42.166274: Epoch time: 12.24 s 
2024-12-07 06:48:42.169304: Yayy! New best EMA pseudo Dice: 0.7925000190734863 
2024-12-07 06:48:42.893973:  
2024-12-07 06:48:42.897998: Epoch 4 
2024-12-07 06:48:42.901066: Current learning rate: 0.00964 
2024-12-07 06:48:55.109381: train_loss -0.8046 
2024-12-07 06:48:55.114401: val_loss -0.8025 
2024-12-07 06:48:55.117913: Pseudo dice [np.float32(0.8736), np.float32(0.8562)] 
2024-12-07 06:48:55.121426: Epoch time: 12.22 s 
2024-12-07 06:48:55.123938: Yayy! New best EMA pseudo Dice: 0.7997999787330627 
2024-12-07 06:48:55.839611:  
2024-12-07 06:48:55.843140: Epoch 5 
2024-12-07 06:48:55.845659: Current learning rate: 0.00955 
2024-12-07 06:49:08.061024: train_loss -0.8141 
2024-12-07 06:49:08.066035: val_loss -0.8077 
2024-12-07 06:49:08.068543: Pseudo dice [np.float32(0.8756), np.float32(0.8613)] 
2024-12-07 06:49:08.072551: Epoch time: 12.22 s 
2024-12-07 06:49:08.075058: Yayy! New best EMA pseudo Dice: 0.8065999746322632 
2024-12-07 06:49:08.911818:  
2024-12-07 06:49:08.916831: Epoch 6 
2024-12-07 06:49:08.919337: Current learning rate: 0.00946 
2024-12-07 06:49:21.128715: train_loss -0.8217 
2024-12-07 06:49:21.133806: val_loss -0.8094 
2024-12-07 06:49:21.136346: Pseudo dice [np.float32(0.8775), np.float32(0.8618)] 
2024-12-07 06:49:21.140389: Epoch time: 12.22 s 
2024-12-07 06:49:21.143411: Yayy! New best EMA pseudo Dice: 0.8129000067710876 
2024-12-07 06:49:21.832975:  
2024-12-07 06:49:21.838005: Epoch 7 
2024-12-07 06:49:21.841536: Current learning rate: 0.00937 
2024-12-07 06:49:33.947905: train_loss -0.8274 
2024-12-07 06:49:33.952982: val_loss -0.8134 
2024-12-07 06:49:33.957048: Pseudo dice [np.float32(0.8798), np.float32(0.8648)] 
2024-12-07 06:49:33.960102: Epoch time: 12.12 s 
2024-12-07 06:49:33.963150: Yayy! New best EMA pseudo Dice: 0.8188999891281128 
2024-12-07 06:49:34.672067:  
2024-12-07 06:49:34.677581: Epoch 8 
2024-12-07 06:49:34.681090: Current learning rate: 0.00928 
2024-12-07 06:49:46.762635: train_loss -0.8313 
2024-12-07 06:49:46.768652: val_loss -0.8108 
2024-12-07 06:49:46.771474: Pseudo dice [np.float32(0.8775), np.float32(0.8635)] 
2024-12-07 06:49:46.774988: Epoch time: 12.09 s 
2024-12-07 06:49:46.777502: Yayy! New best EMA pseudo Dice: 0.8240000009536743 
2024-12-07 06:49:47.516973:  
2024-12-07 06:49:47.521999: Epoch 9 
2024-12-07 06:49:47.525017: Current learning rate: 0.00919 
2024-12-07 06:49:59.794102: train_loss -0.8363 
2024-12-07 06:49:59.799149: val_loss -0.8096 
2024-12-07 06:49:59.802203: Pseudo dice [np.float32(0.8787), np.float32(0.8621)] 
2024-12-07 06:49:59.805730: Epoch time: 12.28 s 
2024-12-07 06:49:59.808248: Yayy! New best EMA pseudo Dice: 0.8287000060081482 
2024-12-07 06:50:00.532269:  
2024-12-07 06:50:00.538305: Epoch 10 
2024-12-07 06:50:00.541837: Current learning rate: 0.0091 
2024-12-07 06:50:12.797649: train_loss -0.8395 
2024-12-07 06:50:12.804222: val_loss -0.8141 
2024-12-07 06:50:12.806733: Pseudo dice [np.float32(0.881), np.float32(0.8654)] 
2024-12-07 06:50:12.809747: Epoch time: 12.27 s 
2024-12-07 06:50:12.812279: Yayy! New best EMA pseudo Dice: 0.8331000208854675 
2024-12-07 06:50:13.523357:  
2024-12-07 06:50:13.527390: Epoch 11 
2024-12-07 06:50:13.529908: Current learning rate: 0.009 
2024-12-07 06:50:25.833462: train_loss -0.8423 
2024-12-07 06:50:25.836972: val_loss -0.8148 
2024-12-07 06:50:25.840985: Pseudo dice [np.float32(0.8821), np.float32(0.8654)] 
2024-12-07 06:50:25.844020: Epoch time: 12.31 s 
2024-12-07 06:50:25.847532: Yayy! New best EMA pseudo Dice: 0.8371999859809875 
2024-12-07 06:50:26.552074:  
2024-12-07 06:50:26.556112: Epoch 12 
2024-12-07 06:50:26.558659: Current learning rate: 0.00891 
2024-12-07 06:50:38.789678: train_loss -0.8459 
2024-12-07 06:50:38.793239: val_loss -0.8153 
2024-12-07 06:50:38.797320: Pseudo dice [np.float32(0.882), np.float32(0.8663)] 
2024-12-07 06:50:38.800373: Epoch time: 12.24 s 
2024-12-07 06:50:38.803409: Yayy! New best EMA pseudo Dice: 0.8409000039100647 
2024-12-07 06:50:39.535291:  
2024-12-07 06:50:39.540343: Epoch 13 
2024-12-07 06:50:39.543419: Current learning rate: 0.00882 
2024-12-07 06:50:51.744024: train_loss -0.8486 
2024-12-07 06:50:51.749119: val_loss -0.8139 
2024-12-07 06:50:51.751657: Pseudo dice [np.float32(0.8824), np.float32(0.866)] 
2024-12-07 06:50:51.754189: Epoch time: 12.21 s 
2024-12-07 06:50:51.758218: Yayy! New best EMA pseudo Dice: 0.8442000150680542 
2024-12-07 06:50:52.594954:  
2024-12-07 06:50:52.600480: Epoch 14 
2024-12-07 06:50:52.603502: Current learning rate: 0.00873 
2024-12-07 06:51:04.903032: train_loss -0.8498 
2024-12-07 06:51:04.907542: val_loss -0.8135 
2024-12-07 06:51:04.910569: Pseudo dice [np.float32(0.8809), np.float32(0.8653)] 
2024-12-07 06:51:04.913100: Epoch time: 12.31 s 
2024-12-07 06:51:04.916631: Yayy! New best EMA pseudo Dice: 0.847100019454956 
2024-12-07 06:51:05.644088:  
2024-12-07 06:51:05.649096: Epoch 15 
2024-12-07 06:51:05.652610: Current learning rate: 0.00864 
2024-12-07 06:51:17.812672: train_loss -0.8526 
2024-12-07 06:51:17.818238: val_loss -0.8154 
2024-12-07 06:51:17.821297: Pseudo dice [np.float32(0.8822), np.float32(0.8668)] 
2024-12-07 06:51:17.823839: Epoch time: 12.17 s 
2024-12-07 06:51:17.827895: Yayy! New best EMA pseudo Dice: 0.8499000072479248 
2024-12-07 06:51:18.553551:  
2024-12-07 06:51:18.559141: Epoch 16 
2024-12-07 06:51:18.561709: Current learning rate: 0.00855 
2024-12-07 06:51:30.866264: train_loss -0.8551 
2024-12-07 06:51:30.871778: val_loss -0.8124 
2024-12-07 06:51:30.874288: Pseudo dice [np.float32(0.882), np.float32(0.8642)] 
2024-12-07 06:51:30.877807: Epoch time: 12.31 s 
2024-12-07 06:51:30.880320: Yayy! New best EMA pseudo Dice: 0.8521999716758728 
2024-12-07 06:51:31.614979:  
2024-12-07 06:51:31.619999: Epoch 17 
2024-12-07 06:51:31.622509: Current learning rate: 0.00846 
2024-12-07 06:51:43.788392: train_loss -0.8564 
2024-12-07 06:51:43.794929: val_loss -0.8136 
2024-12-07 06:51:43.798442: Pseudo dice [np.float32(0.8814), np.float32(0.8666)] 
2024-12-07 06:51:43.801498: Epoch time: 12.17 s 
2024-12-07 06:51:43.804012: Yayy! New best EMA pseudo Dice: 0.8543999791145325 
2024-12-07 06:51:44.532901:  
2024-12-07 06:51:44.538481: Epoch 18 
2024-12-07 06:51:44.541571: Current learning rate: 0.00836 
2024-12-07 06:51:56.831621: train_loss -0.8583 
2024-12-07 06:51:56.836717: val_loss -0.8169 
2024-12-07 06:51:56.840309: Pseudo dice [np.float32(0.8853), np.float32(0.8662)] 
2024-12-07 06:51:56.843848: Epoch time: 12.3 s 
2024-12-07 06:51:56.846749: Yayy! New best EMA pseudo Dice: 0.8565000295639038 
2024-12-07 06:51:57.598891:  
2024-12-07 06:51:57.603908: Epoch 19 
2024-12-07 06:51:57.606921: Current learning rate: 0.00827 
2024-12-07 06:52:09.882180: train_loss -0.8599 
2024-12-07 06:52:09.888730: val_loss -0.8157 
2024-12-07 06:52:09.891473: Pseudo dice [np.float32(0.8821), np.float32(0.8672)] 
2024-12-07 06:52:09.894992: Epoch time: 12.28 s 
2024-12-07 06:52:09.898504: Yayy! New best EMA pseudo Dice: 0.858299970626831 
2024-12-07 06:52:10.631810:  
2024-12-07 06:52:10.636830: Epoch 20 
2024-12-07 06:52:10.640345: Current learning rate: 0.00818 
2024-12-07 06:52:22.977420: train_loss -0.8617 
2024-12-07 06:52:22.983467: val_loss -0.8141 
2024-12-07 06:52:22.987129: Pseudo dice [np.float32(0.8823), np.float32(0.8673)] 
2024-12-07 06:52:22.991181: Epoch time: 12.35 s 
2024-12-07 06:52:22.994782: Yayy! New best EMA pseudo Dice: 0.8600000143051147 
2024-12-07 06:52:23.863228:  
2024-12-07 06:52:23.868789: Epoch 21 
2024-12-07 06:52:23.872340: Current learning rate: 0.00809 
2024-12-07 06:52:36.047022: train_loss -0.8631 
2024-12-07 06:52:36.053190: val_loss -0.814 
2024-12-07 06:52:36.056199: Pseudo dice [np.float32(0.8835), np.float32(0.8665)] 
2024-12-07 06:52:36.059712: Epoch time: 12.18 s 
2024-12-07 06:52:36.062756: Yayy! New best EMA pseudo Dice: 0.8615000247955322 
2024-12-07 06:52:36.770904:  
2024-12-07 06:52:36.776465: Epoch 22 
2024-12-07 06:52:36.779021: Current learning rate: 0.008 
2024-12-07 06:52:48.901714: train_loss -0.8636 
2024-12-07 06:52:48.906723: val_loss -0.812 
2024-12-07 06:52:48.910236: Pseudo dice [np.float32(0.8819), np.float32(0.8644)] 
2024-12-07 06:52:48.913245: Epoch time: 12.13 s 
2024-12-07 06:52:48.915755: Yayy! New best EMA pseudo Dice: 0.8626000285148621 
2024-12-07 06:52:49.636140:  
2024-12-07 06:52:49.641190: Epoch 23 
2024-12-07 06:52:49.643713: Current learning rate: 0.0079 
2024-12-07 06:53:01.833119: train_loss -0.8652 
2024-12-07 06:53:01.838137: val_loss -0.8138 
2024-12-07 06:53:01.840651: Pseudo dice [np.float32(0.8829), np.float32(0.8663)] 
2024-12-07 06:53:01.843166: Epoch time: 12.2 s 
2024-12-07 06:53:01.847179: Yayy! New best EMA pseudo Dice: 0.8637999892234802 
2024-12-07 06:53:02.576353:  
2024-12-07 06:53:02.581374: Epoch 24 
2024-12-07 06:53:02.584892: Current learning rate: 0.00781 
2024-12-07 06:53:14.712194: train_loss -0.8667 
2024-12-07 06:53:14.717319: val_loss -0.8168 
2024-12-07 06:53:14.720388: Pseudo dice [np.float32(0.8845), np.float32(0.8685)] 
2024-12-07 06:53:14.724454: Epoch time: 12.14 s 
2024-12-07 06:53:14.727505: Yayy! New best EMA pseudo Dice: 0.8651000261306763 
2024-12-07 06:53:15.433545:  
2024-12-07 06:53:15.438625: Epoch 25 
2024-12-07 06:53:15.441177: Current learning rate: 0.00772 
2024-12-07 06:53:27.699338: train_loss -0.8677 
2024-12-07 06:53:27.705867: val_loss -0.814 
2024-12-07 06:53:27.709380: Pseudo dice [np.float32(0.8825), np.float32(0.8675)] 
2024-12-07 06:53:27.711918: Epoch time: 12.27 s 
2024-12-07 06:53:27.715820: Yayy! New best EMA pseudo Dice: 0.866100013256073 
2024-12-07 06:53:28.421092:  
2024-12-07 06:53:28.426188: Epoch 26 
2024-12-07 06:53:28.429293: Current learning rate: 0.00763 
2024-12-07 06:53:40.665635: train_loss -0.8684 
2024-12-07 06:53:40.671697: val_loss -0.8129 
2024-12-07 06:53:40.675220: Pseudo dice [np.float32(0.8836), np.float32(0.8643)] 
2024-12-07 06:53:40.677898: Epoch time: 12.24 s 
2024-12-07 06:53:40.680936: Yayy! New best EMA pseudo Dice: 0.8669000267982483 
2024-12-07 06:53:41.376430:  
2024-12-07 06:53:41.379987: Epoch 27 
2024-12-07 06:53:41.383506: Current learning rate: 0.00753 
2024-12-07 06:53:53.617267: train_loss -0.8702 
2024-12-07 06:53:53.622898: val_loss -0.8111 
2024-12-07 06:53:53.626561: Pseudo dice [np.float32(0.8821), np.float32(0.8637)] 
2024-12-07 06:53:53.629596: Epoch time: 12.24 s 
2024-12-07 06:53:53.633109: Yayy! New best EMA pseudo Dice: 0.8675000071525574 
2024-12-07 06:53:54.353487:  
2024-12-07 06:53:54.357537: Epoch 28 
2024-12-07 06:53:54.360080: Current learning rate: 0.00744 
2024-12-07 06:54:06.585114: train_loss -0.8709 
2024-12-07 06:54:06.590210: val_loss -0.8134 
2024-12-07 06:54:06.594803: Pseudo dice [np.float32(0.884), np.float32(0.8655)] 
2024-12-07 06:54:06.597831: Epoch time: 12.23 s 
2024-12-07 06:54:06.602347: Yayy! New best EMA pseudo Dice: 0.8682000041007996 
2024-12-07 06:54:07.457861:  
2024-12-07 06:54:07.461376: Epoch 29 
2024-12-07 06:54:07.465392: Current learning rate: 0.00735 
2024-12-07 06:54:19.690955: train_loss -0.872 
2024-12-07 06:54:19.697485: val_loss -0.8142 
2024-12-07 06:54:19.701007: Pseudo dice [np.float32(0.8844), np.float32(0.8652)] 
2024-12-07 06:54:19.703515: Epoch time: 12.23 s 
2024-12-07 06:54:19.707533: Yayy! New best EMA pseudo Dice: 0.8689000010490417 
2024-12-07 06:54:20.434632:  
2024-12-07 06:54:20.439182: Epoch 30 
2024-12-07 06:54:20.442704: Current learning rate: 0.00725 
2024-12-07 06:54:32.602835: train_loss -0.8729 
2024-12-07 06:54:32.607425: val_loss -0.8119 
2024-12-07 06:54:32.611023: Pseudo dice [np.float32(0.8827), np.float32(0.8649)] 
2024-12-07 06:54:32.614530: Epoch time: 12.17 s 
2024-12-07 06:54:32.617547: Yayy! New best EMA pseudo Dice: 0.8694000244140625 
2024-12-07 06:54:33.350761:  
2024-12-07 06:54:33.356304: Epoch 31 
2024-12-07 06:54:33.359739: Current learning rate: 0.00716 
2024-12-07 06:54:45.553825: train_loss -0.8743 
2024-12-07 06:54:45.559849: val_loss -0.8141 
2024-12-07 06:54:45.562867: Pseudo dice [np.float32(0.8845), np.float32(0.8672)] 
2024-12-07 06:54:45.566377: Epoch time: 12.2 s 
2024-12-07 06:54:45.569559: Yayy! New best EMA pseudo Dice: 0.8700000047683716 
2024-12-07 06:54:46.293607:  
2024-12-07 06:54:46.298664: Epoch 32 
2024-12-07 06:54:46.301059: Current learning rate: 0.00707 
2024-12-07 06:54:58.615983: train_loss -0.8747 
2024-12-07 06:54:58.621556: val_loss -0.812 
2024-12-07 06:54:58.624651: Pseudo dice [np.float32(0.8813), np.float32(0.8652)] 
2024-12-07 06:54:58.628704: Epoch time: 12.32 s 
2024-12-07 06:54:58.631779: Yayy! New best EMA pseudo Dice: 0.8702999949455261 
2024-12-07 06:54:59.366233:  
2024-12-07 06:54:59.371863: Epoch 33 
2024-12-07 06:54:59.374931: Current learning rate: 0.00697 
2024-12-07 06:55:11.615670: train_loss -0.8752 
2024-12-07 06:55:11.622340: val_loss -0.8116 
2024-12-07 06:55:11.626371: Pseudo dice [np.float32(0.883), np.float32(0.8645)] 
2024-12-07 06:55:11.628893: Epoch time: 12.25 s 
2024-12-07 06:55:11.632416: Yayy! New best EMA pseudo Dice: 0.8707000017166138 
2024-12-07 06:55:12.378302:  
2024-12-07 06:55:12.383355: Epoch 34 
2024-12-07 06:55:12.386046: Current learning rate: 0.00688 
2024-12-07 06:55:24.510374: train_loss -0.8765 
2024-12-07 06:55:24.515136: val_loss -0.8109 
2024-12-07 06:55:24.518656: Pseudo dice [np.float32(0.8831), np.float32(0.8637)] 
2024-12-07 06:55:24.522168: Epoch time: 12.13 s 
2024-12-07 06:55:24.525182: Yayy! New best EMA pseudo Dice: 0.8709999918937683 
2024-12-07 06:55:25.254118:  
2024-12-07 06:55:25.259166: Epoch 35 
2024-12-07 06:55:25.262715: Current learning rate: 0.00679 
2024-12-07 06:55:37.442674: train_loss -0.8772 
2024-12-07 06:55:37.447248: val_loss -0.8114 
2024-12-07 06:55:37.450839: Pseudo dice [np.float32(0.883), np.float32(0.8659)] 
2024-12-07 06:55:37.453397: Epoch time: 12.19 s 
2024-12-07 06:55:37.455983: Yayy! New best EMA pseudo Dice: 0.8712999820709229 
2024-12-07 06:55:38.182136:  
2024-12-07 06:55:38.186190: Epoch 36 
2024-12-07 06:55:38.188735: Current learning rate: 0.00669 
2024-12-07 06:55:50.440645: train_loss -0.8777 
2024-12-07 06:55:50.445246: val_loss -0.814 
2024-12-07 06:55:50.448292: Pseudo dice [np.float32(0.8852), np.float32(0.8664)] 
2024-12-07 06:55:50.451861: Epoch time: 12.26 s 
2024-12-07 06:55:50.455403: Yayy! New best EMA pseudo Dice: 0.8718000054359436 
2024-12-07 06:55:51.331510:  
2024-12-07 06:55:51.335565: Epoch 37 
2024-12-07 06:55:51.339138: Current learning rate: 0.0066 
2024-12-07 06:56:03.565908: train_loss -0.8784 
2024-12-07 06:56:03.570444: val_loss -0.8094 
2024-12-07 06:56:03.574462: Pseudo dice [np.float32(0.8841), np.float32(0.8615)] 
2024-12-07 06:56:03.577982: Epoch time: 12.23 s 
2024-12-07 06:56:03.581014: Yayy! New best EMA pseudo Dice: 0.8719000220298767 
2024-12-07 06:56:04.314045:  
2024-12-07 06:56:04.319645: Epoch 38 
2024-12-07 06:56:04.322208: Current learning rate: 0.0065 
2024-12-07 06:56:16.323146: train_loss -0.8794 
2024-12-07 06:56:16.328738: val_loss -0.8084 
2024-12-07 06:56:16.332562: Pseudo dice [np.float32(0.8811), np.float32(0.8637)] 
2024-12-07 06:56:16.336089: Epoch time: 12.01 s 
2024-12-07 06:56:16.339365: Yayy! New best EMA pseudo Dice: 0.8719000220298767 
2024-12-07 06:56:17.081601:  
2024-12-07 06:56:17.087701: Epoch 39 
2024-12-07 06:56:17.090784: Current learning rate: 0.00641 
2024-12-07 06:56:29.340448: train_loss -0.8793 
2024-12-07 06:56:29.346972: val_loss -0.8127 
2024-12-07 06:56:29.350488: Pseudo dice [np.float32(0.8836), np.float32(0.867)] 
2024-12-07 06:56:29.352996: Epoch time: 12.26 s 
2024-12-07 06:56:29.357327: Yayy! New best EMA pseudo Dice: 0.8722000122070312 
2024-12-07 06:56:30.091766:  
2024-12-07 06:56:30.096303: Epoch 40 
2024-12-07 06:56:30.099827: Current learning rate: 0.00631 
2024-12-07 06:56:42.357171: train_loss -0.8797 
2024-12-07 06:56:42.363275: val_loss -0.8113 
2024-12-07 06:56:42.368291: Pseudo dice [np.float32(0.8833), np.float32(0.8647)] 
2024-12-07 06:56:42.372303: Epoch time: 12.27 s 
2024-12-07 06:56:42.375818: Yayy! New best EMA pseudo Dice: 0.8723999857902527 
2024-12-07 06:56:43.123912:  
2024-12-07 06:56:43.127931: Epoch 41 
2024-12-07 06:56:43.131948: Current learning rate: 0.00622 
2024-12-07 06:56:55.329164: train_loss -0.8817 
2024-12-07 06:56:55.334787: val_loss -0.8088 
2024-12-07 06:56:55.337846: Pseudo dice [np.float32(0.8836), np.float32(0.8635)] 
2024-12-07 06:56:55.340406: Epoch time: 12.21 s 
2024-12-07 06:56:55.344473: Yayy! New best EMA pseudo Dice: 0.8725000023841858 
2024-12-07 06:56:56.050015:  
2024-12-07 06:56:56.054674: Epoch 42 
2024-12-07 06:56:56.057193: Current learning rate: 0.00612 
2024-12-07 06:57:08.277988: train_loss -0.8822 
2024-12-07 06:57:08.281569: val_loss -0.8113 
2024-12-07 06:57:08.285647: Pseudo dice [np.float32(0.8841), np.float32(0.8656)] 
2024-12-07 06:57:08.289267: Epoch time: 12.23 s 
2024-12-07 06:57:08.291827: Yayy! New best EMA pseudo Dice: 0.8727999925613403 
2024-12-07 06:57:09.016426:  
2024-12-07 06:57:09.020496: Epoch 43 
2024-12-07 06:57:09.023088: Current learning rate: 0.00603 
2024-12-07 06:57:21.269670: train_loss -0.8826 
2024-12-07 06:57:21.274731: val_loss -0.8131 
2024-12-07 06:57:21.278324: Pseudo dice [np.float32(0.8831), np.float32(0.8674)] 
2024-12-07 06:57:21.281398: Epoch time: 12.25 s 
2024-12-07 06:57:21.283942: Yayy! New best EMA pseudo Dice: 0.8730000257492065 
2024-12-07 06:57:21.966603:  
2024-12-07 06:57:21.972203: Epoch 44 
2024-12-07 06:57:21.974758: Current learning rate: 0.00593 
2024-12-07 06:57:34.164632: train_loss -0.8832 
2024-12-07 06:57:34.168651: val_loss -0.8085 
2024-12-07 06:57:34.172164: Pseudo dice [np.float32(0.8814), np.float32(0.8654)] 
2024-12-07 06:57:34.176174: Epoch time: 12.2 s 
2024-12-07 06:57:34.179685: Yayy! New best EMA pseudo Dice: 0.8730000257492065 
2024-12-07 06:57:35.048353:  
2024-12-07 06:57:35.053511: Epoch 45 
2024-12-07 06:57:35.056638: Current learning rate: 0.00584 
2024-12-07 06:57:47.298425: train_loss -0.8839 
2024-12-07 06:57:47.303962: val_loss -0.812 
2024-12-07 06:57:47.307473: Pseudo dice [np.float32(0.8839), np.float32(0.8661)] 
2024-12-07 06:57:47.310488: Epoch time: 12.25 s 
2024-12-07 06:57:47.314008: Yayy! New best EMA pseudo Dice: 0.873199999332428 
2024-12-07 06:57:48.037058:  
2024-12-07 06:57:48.042078: Epoch 46 
2024-12-07 06:57:48.045591: Current learning rate: 0.00574 
2024-12-07 06:58:00.254178: train_loss -0.8845 
2024-12-07 06:58:00.260857: val_loss -0.811 
2024-12-07 06:58:00.263368: Pseudo dice [np.float32(0.8839), np.float32(0.8654)] 
2024-12-07 06:58:00.266888: Epoch time: 12.22 s 
2024-12-07 06:58:00.270903: Yayy! New best EMA pseudo Dice: 0.8733999729156494 
2024-12-07 06:58:00.967776:  
2024-12-07 06:58:00.972834: Epoch 47 
2024-12-07 06:58:00.976490: Current learning rate: 0.00565 
2024-12-07 06:58:13.155465: train_loss -0.8849 
2024-12-07 06:58:13.161493: val_loss -0.8103 
2024-12-07 06:58:13.165006: Pseudo dice [np.float32(0.8835), np.float32(0.8661)] 
2024-12-07 06:58:13.168020: Epoch time: 12.19 s 
2024-12-07 06:58:13.170531: Yayy! New best EMA pseudo Dice: 0.8734999895095825 
2024-12-07 06:58:13.902119:  
2024-12-07 06:58:13.907140: Epoch 48 
2024-12-07 06:58:13.910655: Current learning rate: 0.00555 
2024-12-07 06:58:26.059038: train_loss -0.8852 
2024-12-07 06:58:26.064141: val_loss -0.8104 
2024-12-07 06:58:26.068722: Pseudo dice [np.float32(0.8834), np.float32(0.8655)] 
2024-12-07 06:58:26.071766: Epoch time: 12.16 s 
2024-12-07 06:58:26.075321: Yayy! New best EMA pseudo Dice: 0.8736000061035156 
2024-12-07 06:58:26.777370:  
2024-12-07 06:58:26.780886: Epoch 49 
2024-12-07 06:58:26.784902: Current learning rate: 0.00546 
2024-12-07 06:58:38.918326: train_loss -0.8861 
2024-12-07 06:58:38.924343: val_loss -0.8103 
2024-12-07 06:58:38.928437: Pseudo dice [np.float32(0.8837), np.float32(0.8653)] 
2024-12-07 06:58:38.931948: Epoch time: 12.14 s 
2024-12-07 06:58:38.959598: Yayy! New best EMA pseudo Dice: 0.8737000226974487 
2024-12-07 06:58:39.672252:  
2024-12-07 06:58:39.676271: Epoch 50 
2024-12-07 06:58:39.680283: Current learning rate: 0.00536 
2024-12-07 06:58:51.940632: train_loss -0.886 
2024-12-07 06:58:51.944665: val_loss -0.807 
2024-12-07 06:58:51.948674: Pseudo dice [np.float32(0.8822), np.float32(0.8646)] 
2024-12-07 06:58:51.951227: Epoch time: 12.27 s 
2024-12-07 06:58:52.666974:  
2024-12-07 06:58:52.671024: Epoch 51 
2024-12-07 06:58:52.675092: Current learning rate: 0.00526 
2024-12-07 06:59:04.869268: train_loss -0.8873 
2024-12-07 06:59:04.872777: val_loss -0.8091 
2024-12-07 06:59:04.877340: Pseudo dice [np.float32(0.8834), np.float32(0.8636)] 
2024-12-07 06:59:04.880361: Epoch time: 12.2 s 
2024-12-07 06:59:05.570748:  
2024-12-07 06:59:05.575768: Epoch 52 
2024-12-07 06:59:05.578278: Current learning rate: 0.00517 
2024-12-07 06:59:17.662505: train_loss -0.8876 
2024-12-07 06:59:17.667529: val_loss -0.8093 
2024-12-07 06:59:17.670043: Pseudo dice [np.float32(0.883), np.float32(0.8651)] 
2024-12-07 06:59:17.674056: Epoch time: 12.09 s 
2024-12-07 06:59:18.515221:  
2024-12-07 06:59:18.520254: Epoch 53 
2024-12-07 06:59:18.523946: Current learning rate: 0.00507 
2024-12-07 06:59:30.708920: train_loss -0.8885 
2024-12-07 06:59:30.714940: val_loss -0.8095 
2024-12-07 06:59:30.717951: Pseudo dice [np.float32(0.8833), np.float32(0.8655)] 
2024-12-07 06:59:30.721468: Epoch time: 12.19 s 
2024-12-07 06:59:30.723973: Yayy! New best EMA pseudo Dice: 0.8737999796867371 
2024-12-07 06:59:31.460185:  
2024-12-07 06:59:31.464205: Epoch 54 
2024-12-07 06:59:31.466717: Current learning rate: 0.00497 
2024-12-07 06:59:43.660320: train_loss -0.8883 
2024-12-07 06:59:43.665913: val_loss -0.8093 
2024-12-07 06:59:43.669028: Pseudo dice [np.float32(0.8825), np.float32(0.8653)] 
2024-12-07 06:59:43.672060: Epoch time: 12.2 s 
2024-12-07 06:59:43.675635: Yayy! New best EMA pseudo Dice: 0.8737999796867371 
2024-12-07 06:59:44.414483:  
2024-12-07 06:59:44.417511: Epoch 55 
2024-12-07 06:59:44.422100: Current learning rate: 0.00487 
2024-12-07 06:59:56.639570: train_loss -0.8883 
2024-12-07 06:59:56.644670: val_loss -0.8067 
2024-12-07 06:59:56.648731: Pseudo dice [np.float32(0.8819), np.float32(0.8643)] 
2024-12-07 06:59:56.652318: Epoch time: 12.23 s 
2024-12-07 06:59:57.336601:  
2024-12-07 06:59:57.340671: Epoch 56 
2024-12-07 06:59:57.343234: Current learning rate: 0.00478 
2024-12-07 07:00:09.528543: train_loss -0.89 
2024-12-07 07:00:09.533567: val_loss -0.8093 
2024-12-07 07:00:09.536147: Pseudo dice [np.float32(0.883), np.float32(0.8655)] 
2024-12-07 07:00:09.539672: Epoch time: 12.19 s 
2024-12-07 07:00:10.238939:  
2024-12-07 07:00:10.242959: Epoch 57 
2024-12-07 07:00:10.246972: Current learning rate: 0.00468 
2024-12-07 07:00:22.365724: train_loss -0.8901 
2024-12-07 07:00:22.370803: val_loss -0.807 
2024-12-07 07:00:22.374388: Pseudo dice [np.float32(0.8829), np.float32(0.8632)] 
2024-12-07 07:00:22.377429: Epoch time: 12.13 s 
2024-12-07 07:00:23.084209:  
2024-12-07 07:00:23.089798: Epoch 58 
2024-12-07 07:00:23.092869: Current learning rate: 0.00458 
2024-12-07 07:00:35.285230: train_loss -0.8904 
2024-12-07 07:00:35.290829: val_loss -0.8082 
2024-12-07 07:00:35.293855: Pseudo dice [np.float32(0.8834), np.float32(0.8647)] 
2024-12-07 07:00:35.296707: Epoch time: 12.2 s 
2024-12-07 07:00:35.971961:  
2024-12-07 07:00:35.977498: Epoch 59 
2024-12-07 07:00:35.980511: Current learning rate: 0.00448 
2024-12-07 07:00:48.068253: train_loss -0.8908 
2024-12-07 07:00:48.073313: val_loss -0.8061 
2024-12-07 07:00:48.075843: Pseudo dice [np.float32(0.8828), np.float32(0.8629)] 
2024-12-07 07:00:48.079374: Epoch time: 12.1 s 
2024-12-07 07:00:48.789099:  
2024-12-07 07:00:48.793613: Epoch 60 
2024-12-07 07:00:48.796143: Current learning rate: 0.00438 
2024-12-07 07:01:01.021782: train_loss -0.8907 
2024-12-07 07:01:01.027303: val_loss -0.8088 
2024-12-07 07:01:01.029813: Pseudo dice [np.float32(0.8832), np.float32(0.8654)] 
2024-12-07 07:01:01.033323: Epoch time: 12.23 s 
2024-12-07 07:01:01.880541:  
2024-12-07 07:01:01.884086: Epoch 61 
2024-12-07 07:01:01.887169: Current learning rate: 0.00429 
2024-12-07 07:01:14.051991: train_loss -0.8918 
2024-12-07 07:01:14.056001: val_loss -0.8073 
2024-12-07 07:01:14.059520: Pseudo dice [np.float32(0.8834), np.float32(0.864)] 
2024-12-07 07:01:14.063029: Epoch time: 12.17 s 
2024-12-07 07:01:14.760493:  
2024-12-07 07:01:14.765504: Epoch 62 
2024-12-07 07:01:14.769513: Current learning rate: 0.00419 
2024-12-07 07:01:26.904947: train_loss -0.8921 
2024-12-07 07:01:26.909995: val_loss -0.8047 
2024-12-07 07:01:26.914029: Pseudo dice [np.float32(0.8815), np.float32(0.8632)] 
2024-12-07 07:01:26.916554: Epoch time: 12.14 s 
2024-12-07 07:01:27.632551:  
2024-12-07 07:01:27.637596: Epoch 63 
2024-12-07 07:01:27.640767: Current learning rate: 0.00409 
2024-12-07 07:01:39.840305: train_loss -0.8923 
2024-12-07 07:01:39.845320: val_loss -0.8044 
2024-12-07 07:01:39.849330: Pseudo dice [np.float32(0.8809), np.float32(0.8635)] 
2024-12-07 07:01:39.851837: Epoch time: 12.21 s 
2024-12-07 07:01:40.576698:  
2024-12-07 07:01:40.582262: Epoch 64 
2024-12-07 07:01:40.584808: Current learning rate: 0.00399 
2024-12-07 07:01:52.775143: train_loss -0.8929 
2024-12-07 07:01:52.780698: val_loss -0.8075 
2024-12-07 07:01:52.784254: Pseudo dice [np.float32(0.8829), np.float32(0.8645)] 
2024-12-07 07:01:52.787807: Epoch time: 12.2 s 
2024-12-07 07:01:53.495185:  
2024-12-07 07:01:53.499201: Epoch 65 
2024-12-07 07:01:53.501947: Current learning rate: 0.00389 
2024-12-07 07:02:05.631882: train_loss -0.8932 
2024-12-07 07:02:05.638141: val_loss -0.8064 
2024-12-07 07:02:05.641710: Pseudo dice [np.float32(0.8827), np.float32(0.8643)] 
2024-12-07 07:02:05.644250: Epoch time: 12.14 s 
2024-12-07 07:02:06.342089:  
2024-12-07 07:02:06.345113: Epoch 66 
2024-12-07 07:02:06.349163: Current learning rate: 0.00379 
2024-12-07 07:02:18.512068: train_loss -0.8935 
2024-12-07 07:02:18.516792: val_loss -0.8052 
2024-12-07 07:02:18.519827: Pseudo dice [np.float32(0.8806), np.float32(0.8644)] 
2024-12-07 07:02:18.523359: Epoch time: 12.17 s 
2024-12-07 07:02:19.235705:  
2024-12-07 07:02:19.240716: Epoch 67 
2024-12-07 07:02:19.243728: Current learning rate: 0.00369 
2024-12-07 07:02:31.417121: train_loss -0.8934 
2024-12-07 07:02:31.422689: val_loss -0.807 
2024-12-07 07:02:31.426201: Pseudo dice [np.float32(0.8828), np.float32(0.865)] 
2024-12-07 07:02:31.429240: Epoch time: 12.18 s 
2024-12-07 07:02:32.293329:  
2024-12-07 07:02:32.297848: Epoch 68 
2024-12-07 07:02:32.301061: Current learning rate: 0.00359 
2024-12-07 07:02:44.407359: train_loss -0.8945 
2024-12-07 07:02:44.413871: val_loss -0.8048 
2024-12-07 07:02:44.417384: Pseudo dice [np.float32(0.881), np.float32(0.8635)] 
2024-12-07 07:02:44.419893: Epoch time: 12.11 s 
2024-12-07 07:02:45.147334:  
2024-12-07 07:02:45.151370: Epoch 69 
2024-12-07 07:02:45.153920: Current learning rate: 0.00349 
2024-12-07 07:02:57.315954: train_loss -0.8946 
2024-12-07 07:02:57.321021: val_loss -0.807 
2024-12-07 07:02:57.324062: Pseudo dice [np.float32(0.8848), np.float32(0.8635)] 
2024-12-07 07:02:57.327105: Epoch time: 12.17 s 
2024-12-07 07:02:58.073332:  
2024-12-07 07:02:58.076882: Epoch 70 
2024-12-07 07:02:58.080896: Current learning rate: 0.00338 
2024-12-07 07:03:10.171028: train_loss -0.8947 
2024-12-07 07:03:10.177594: val_loss -0.8058 
2024-12-07 07:03:10.180667: Pseudo dice [np.float32(0.8832), np.float32(0.8636)] 
2024-12-07 07:03:10.184179: Epoch time: 12.1 s 
2024-12-07 07:03:10.915166:  
2024-12-07 07:03:10.918862: Epoch 71 
2024-12-07 07:03:10.922371: Current learning rate: 0.00328 
2024-12-07 07:03:23.137515: train_loss -0.8954 
2024-12-07 07:03:23.142033: val_loss -0.8045 
2024-12-07 07:03:23.145549: Pseudo dice [np.float32(0.8819), np.float32(0.8632)] 
2024-12-07 07:03:23.148659: Epoch time: 12.22 s 
2024-12-07 07:03:23.860993:  
2024-12-07 07:03:23.866014: Epoch 72 
2024-12-07 07:03:23.868520: Current learning rate: 0.00318 
2024-12-07 07:03:35.989775: train_loss -0.8958 
2024-12-07 07:03:35.995320: val_loss -0.8041 
2024-12-07 07:03:35.998846: Pseudo dice [np.float32(0.8825), np.float32(0.8626)] 
2024-12-07 07:03:36.001862: Epoch time: 12.13 s 
2024-12-07 07:03:36.698630:  
2024-12-07 07:03:36.704213: Epoch 73 
2024-12-07 07:03:36.707264: Current learning rate: 0.00308 
2024-12-07 07:03:48.880041: train_loss -0.8962 
2024-12-07 07:03:48.885599: val_loss -0.804 
2024-12-07 07:03:48.889616: Pseudo dice [np.float32(0.8816), np.float32(0.8631)] 
2024-12-07 07:03:48.892127: Epoch time: 12.18 s 
2024-12-07 07:03:49.644119:  
2024-12-07 07:03:49.649153: Epoch 74 
2024-12-07 07:03:49.652205: Current learning rate: 0.00297 
2024-12-07 07:04:01.767771: train_loss -0.8961 
2024-12-07 07:04:01.773553: val_loss -0.8058 
2024-12-07 07:04:01.776639: Pseudo dice [np.float32(0.8831), np.float32(0.8641)] 
2024-12-07 07:04:01.780158: Epoch time: 12.12 s 
2024-12-07 07:04:02.509501:  
2024-12-07 07:04:02.513514: Epoch 75 
2024-12-07 07:04:02.516020: Current learning rate: 0.00287 
2024-12-07 07:04:14.747381: train_loss -0.8969 
2024-12-07 07:04:14.752913: val_loss -0.8039 
2024-12-07 07:04:14.756430: Pseudo dice [np.float32(0.8821), np.float32(0.8629)] 
2024-12-07 07:04:14.759948: Epoch time: 12.24 s 
2024-12-07 07:04:15.645144:  
2024-12-07 07:04:15.649173: Epoch 76 
2024-12-07 07:04:15.652719: Current learning rate: 0.00277 
2024-12-07 07:04:27.824020: train_loss -0.897 
2024-12-07 07:04:27.828547: val_loss -0.8067 
2024-12-07 07:04:27.832068: Pseudo dice [np.float32(0.8848), np.float32(0.8635)] 
2024-12-07 07:04:27.834584: Epoch time: 12.18 s 
2024-12-07 07:04:28.583347:  
2024-12-07 07:04:28.588879: Epoch 77 
2024-12-07 07:04:28.592468: Current learning rate: 0.00266 
2024-12-07 07:04:40.710717: train_loss -0.8978 
2024-12-07 07:04:40.714734: val_loss -0.8037 
2024-12-07 07:04:40.718253: Pseudo dice [np.float32(0.8816), np.float32(0.8627)] 
2024-12-07 07:04:40.721763: Epoch time: 12.13 s 
2024-12-07 07:04:41.450643:  
2024-12-07 07:04:41.456169: Epoch 78 
2024-12-07 07:04:41.459741: Current learning rate: 0.00256 
2024-12-07 07:04:53.746119: train_loss -0.8982 
2024-12-07 07:04:53.751699: val_loss -0.8024 
2024-12-07 07:04:53.754239: Pseudo dice [np.float32(0.8814), np.float32(0.8624)] 
2024-12-07 07:04:53.758373: Epoch time: 12.3 s 
2024-12-07 07:04:54.502666:  
2024-12-07 07:04:54.507715: Epoch 79 
2024-12-07 07:04:54.510754: Current learning rate: 0.00245 
2024-12-07 07:05:06.723192: train_loss -0.8978 
2024-12-07 07:05:06.728798: val_loss -0.8049 
2024-12-07 07:05:06.732337: Pseudo dice [np.float32(0.8833), np.float32(0.8631)] 
2024-12-07 07:05:06.735397: Epoch time: 12.22 s 
2024-12-07 07:05:07.460764:  
2024-12-07 07:05:07.464794: Epoch 80 
2024-12-07 07:05:07.468364: Current learning rate: 0.00235 
2024-12-07 07:05:19.541584: train_loss -0.8982 
2024-12-07 07:05:19.546136: val_loss -0.8032 
2024-12-07 07:05:19.550151: Pseudo dice [np.float32(0.882), np.float32(0.8623)] 
2024-12-07 07:05:19.552663: Epoch time: 12.08 s 
2024-12-07 07:05:20.285111:  
2024-12-07 07:05:20.289145: Epoch 81 
2024-12-07 07:05:20.292164: Current learning rate: 0.00224 
2024-12-07 07:05:32.424687: train_loss -0.8986 
2024-12-07 07:05:32.429718: val_loss -0.8057 
2024-12-07 07:05:32.433239: Pseudo dice [np.float32(0.8835), np.float32(0.8634)] 
2024-12-07 07:05:32.436763: Epoch time: 12.14 s 
2024-12-07 07:05:33.153201:  
2024-12-07 07:05:33.159755: Epoch 82 
2024-12-07 07:05:33.163283: Current learning rate: 0.00214 
2024-12-07 07:05:45.417154: train_loss -0.8992 
2024-12-07 07:05:45.420673: val_loss -0.8023 
2024-12-07 07:05:45.424193: Pseudo dice [np.float32(0.8823), np.float32(0.8619)] 
2024-12-07 07:05:45.427212: Epoch time: 12.26 s 
2024-12-07 07:05:46.146625:  
2024-12-07 07:05:46.151654: Epoch 83 
2024-12-07 07:05:46.154710: Current learning rate: 0.00203 
2024-12-07 07:05:58.300420: train_loss -0.8993 
2024-12-07 07:05:58.307956: val_loss -0.8018 
2024-12-07 07:05:58.310469: Pseudo dice [np.float32(0.8815), np.float32(0.8615)] 
2024-12-07 07:05:58.313981: Epoch time: 12.15 s 
2024-12-07 07:05:58.997361:  
2024-12-07 07:05:59.002414: Epoch 84 
2024-12-07 07:05:59.005472: Current learning rate: 0.00192 
2024-12-07 07:06:11.209878: train_loss -0.8997 
2024-12-07 07:06:11.215901: val_loss -0.8011 
2024-12-07 07:06:11.218919: Pseudo dice [np.float32(0.8819), np.float32(0.8605)] 
2024-12-07 07:06:11.222466: Epoch time: 12.21 s 
2024-12-07 07:06:11.887187:  
2024-12-07 07:06:11.892255: Epoch 85 
2024-12-07 07:06:11.894779: Current learning rate: 0.00181 
2024-12-07 07:06:24.115466: train_loss -0.8996 
2024-12-07 07:06:24.121490: val_loss -0.8022 
2024-12-07 07:06:24.124507: Pseudo dice [np.float32(0.8812), np.float32(0.8636)] 
2024-12-07 07:06:24.128026: Epoch time: 12.23 s 
2024-12-07 07:06:24.840312:  
2024-12-07 07:06:24.844884: Epoch 86 
2024-12-07 07:06:24.848899: Current learning rate: 0.0017 
2024-12-07 07:06:37.015264: train_loss -0.9 
2024-12-07 07:06:37.021286: val_loss -0.8047 
2024-12-07 07:06:37.024707: Pseudo dice [np.float32(0.8828), np.float32(0.8643)] 
2024-12-07 07:06:37.028716: Epoch time: 12.18 s 
2024-12-07 07:06:37.732692:  
2024-12-07 07:06:37.736722: Epoch 87 
2024-12-07 07:06:37.739838: Current learning rate: 0.00159 
2024-12-07 07:06:50.020867: train_loss -0.9006 
2024-12-07 07:06:50.026466: val_loss -0.8021 
2024-12-07 07:06:50.029506: Pseudo dice [np.float32(0.8826), np.float32(0.8616)] 
2024-12-07 07:06:50.033535: Epoch time: 12.29 s 
2024-12-07 07:06:50.694903:  
2024-12-07 07:06:50.699915: Epoch 88 
2024-12-07 07:06:50.703924: Current learning rate: 0.00148 
2024-12-07 07:07:02.821557: train_loss -0.9003 
2024-12-07 07:07:02.827646: val_loss -0.8032 
2024-12-07 07:07:02.831712: Pseudo dice [np.float32(0.8823), np.float32(0.8633)] 
2024-12-07 07:07:02.835264: Epoch time: 12.13 s 
2024-12-07 07:07:03.524767:  
2024-12-07 07:07:03.529813: Epoch 89 
2024-12-07 07:07:03.533356: Current learning rate: 0.00137 
2024-12-07 07:07:15.693548: train_loss -0.9011 
2024-12-07 07:07:15.699083: val_loss -0.8016 
2024-12-07 07:07:15.703098: Pseudo dice [np.float32(0.881), np.float32(0.8626)] 
2024-12-07 07:07:15.706138: Epoch time: 12.17 s 
2024-12-07 07:07:16.495294:  
2024-12-07 07:07:16.499308: Epoch 90 
2024-12-07 07:07:16.502816: Current learning rate: 0.00126 
2024-12-07 07:07:28.664999: train_loss -0.9011 
2024-12-07 07:07:28.671203: val_loss -0.801 
2024-12-07 07:07:28.674718: Pseudo dice [np.float32(0.8804), np.float32(0.8625)] 
2024-12-07 07:07:28.677731: Epoch time: 12.17 s 
2024-12-07 07:07:29.355733:  
2024-12-07 07:07:29.359249: Epoch 91 
2024-12-07 07:07:29.362302: Current learning rate: 0.00115 
2024-12-07 07:07:41.528765: train_loss -0.9008 
2024-12-07 07:07:41.535282: val_loss -0.8014 
2024-12-07 07:07:41.538819: Pseudo dice [np.float32(0.8821), np.float32(0.8613)] 
2024-12-07 07:07:41.541395: Epoch time: 12.17 s 
2024-12-07 07:07:42.363431:  
2024-12-07 07:07:42.367483: Epoch 92 
2024-12-07 07:07:42.370029: Current learning rate: 0.00103 
2024-12-07 07:07:54.422484: train_loss -0.9014 
2024-12-07 07:07:54.427018: val_loss -0.8007 
2024-12-07 07:07:54.430530: Pseudo dice [np.float32(0.8818), np.float32(0.8619)] 
2024-12-07 07:07:54.434543: Epoch time: 12.06 s 
2024-12-07 07:07:55.131196:  
2024-12-07 07:07:55.136757: Epoch 93 
2024-12-07 07:07:55.140392: Current learning rate: 0.00091 
2024-12-07 07:08:07.260292: train_loss -0.9015 
2024-12-07 07:08:07.267416: val_loss -0.8006 
2024-12-07 07:08:07.270487: Pseudo dice [np.float32(0.8817), np.float32(0.861)] 
2024-12-07 07:08:07.274532: Epoch time: 12.13 s 
2024-12-07 07:08:07.969252:  
2024-12-07 07:08:07.974303: Epoch 94 
2024-12-07 07:08:07.977366: Current learning rate: 0.00079 
2024-12-07 07:08:20.037102: train_loss -0.9017 
2024-12-07 07:08:20.042689: val_loss -0.8011 
2024-12-07 07:08:20.045706: Pseudo dice [np.float32(0.8818), np.float32(0.8618)] 
2024-12-07 07:08:20.049276: Epoch time: 12.07 s 
2024-12-07 07:08:20.720394:  
2024-12-07 07:08:20.725451: Epoch 95 
2024-12-07 07:08:20.728534: Current learning rate: 0.00067 
2024-12-07 07:08:32.693863: train_loss -0.9016 
2024-12-07 07:08:32.697874: val_loss -0.7998 
2024-12-07 07:08:32.701923: Pseudo dice [np.float32(0.8813), np.float32(0.8616)] 
2024-12-07 07:08:32.705433: Epoch time: 11.97 s 
2024-12-07 07:08:33.403291:  
2024-12-07 07:08:33.408872: Epoch 96 
2024-12-07 07:08:33.411421: Current learning rate: 0.00055 
2024-12-07 07:08:45.520344: train_loss -0.9025 
2024-12-07 07:08:45.525859: val_loss -0.8014 
2024-12-07 07:08:45.529372: Pseudo dice [np.float32(0.8823), np.float32(0.8625)] 
2024-12-07 07:08:45.532880: Epoch time: 12.12 s 
2024-12-07 07:08:46.224202:  
2024-12-07 07:08:46.229718: Epoch 97 
2024-12-07 07:08:46.233227: Current learning rate: 0.00043 
2024-12-07 07:08:58.373831: train_loss -0.9019 
2024-12-07 07:08:58.379441: val_loss -0.8026 
2024-12-07 07:08:58.381982: Pseudo dice [np.float32(0.8828), np.float32(0.8631)] 
2024-12-07 07:08:58.386026: Epoch time: 12.15 s 
2024-12-07 07:08:59.069650:  
2024-12-07 07:08:59.073698: Epoch 98 
2024-12-07 07:08:59.078817: Current learning rate: 0.0003 
2024-12-07 07:09:11.293393: train_loss -0.9024 
2024-12-07 07:09:11.300016: val_loss -0.8033 
2024-12-07 07:09:11.303589: Pseudo dice [np.float32(0.8827), np.float32(0.863)] 
2024-12-07 07:09:11.307132: Epoch time: 12.22 s 
2024-12-07 07:09:12.011047:  
2024-12-07 07:09:12.015101: Epoch 99 
2024-12-07 07:09:12.017670: Current learning rate: 0.00016 
2024-12-07 07:09:24.277796: train_loss -0.9027 
2024-12-07 07:09:24.283329: val_loss -0.802 
2024-12-07 07:09:24.286400: Pseudo dice [np.float32(0.8821), np.float32(0.8631)] 
2024-12-07 07:09:24.289515: Epoch time: 12.27 s 
2024-12-07 07:09:25.168343: Training done. 
2024-12-07 07:09:25.204344: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-07 07:09:25.212344: The split file contains 5 splits. 
2024-12-07 07:09:25.218343: Desired fold for training: 0 
2024-12-07 07:09:25.223343: This split has 208 training and 52 validation cases. 
2024-12-07 07:09:25.229344: predicting hippocampus_017 
2024-12-07 07:09:25.235344: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-07 07:09:25.620342: predicting hippocampus_019 
2024-12-07 07:09:25.628343: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-07 07:09:25.963344: predicting hippocampus_033 
2024-12-07 07:09:25.970343: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-07 07:09:26.223343: predicting hippocampus_035 
2024-12-07 07:09:26.229342: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-07 07:09:26.494343: predicting hippocampus_037 
2024-12-07 07:09:26.502344: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-07 07:09:26.726344: predicting hippocampus_049 
2024-12-07 07:09:26.733344: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-07 07:09:26.986342: predicting hippocampus_052 
2024-12-07 07:09:26.993342: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-07 07:09:27.280346: predicting hippocampus_065 
2024-12-07 07:09:27.287344: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-07 07:09:27.573343: predicting hippocampus_083 
2024-12-07 07:09:27.580343: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-07 07:09:27.853342: predicting hippocampus_088 
2024-12-07 07:09:27.860342: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-07 07:09:29.333496: predicting hippocampus_090 
2024-12-07 07:09:29.340499: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-07 07:09:29.637541: predicting hippocampus_092 
2024-12-07 07:09:29.644541: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-07 07:09:29.863052: predicting hippocampus_095 
2024-12-07 07:09:29.870052: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-07 07:09:30.177557: predicting hippocampus_107 
2024-12-07 07:09:30.184557: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-07 07:09:30.470558: predicting hippocampus_108 
2024-12-07 07:09:30.477559: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-07 07:09:30.759558: predicting hippocampus_123 
2024-12-07 07:09:30.766557: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-07 07:09:31.040557: predicting hippocampus_125 
2024-12-07 07:09:31.046557: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-07 07:09:31.593557: predicting hippocampus_157 
2024-12-07 07:09:31.600559: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-07 07:09:31.857557: predicting hippocampus_164 
2024-12-07 07:09:31.863559: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-07 07:09:32.523557: predicting hippocampus_169 
2024-12-07 07:09:32.530558: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-07 07:09:32.821557: predicting hippocampus_175 
2024-12-07 07:09:32.826559: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-07 07:09:33.104557: predicting hippocampus_185 
2024-12-07 07:09:33.110558: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-07 07:09:33.355557: predicting hippocampus_190 
2024-12-07 07:09:33.360558: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-07 07:09:33.593557: predicting hippocampus_194 
2024-12-07 07:09:33.600559: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-07 07:09:33.817557: predicting hippocampus_204 
2024-12-07 07:09:33.822559: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-07 07:09:34.122557: predicting hippocampus_205 
2024-12-07 07:09:34.129559: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-07 07:09:34.345557: predicting hippocampus_210 
2024-12-07 07:09:34.351559: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-07 07:09:34.625557: predicting hippocampus_217 
2024-12-07 07:09:34.630559: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-07 07:09:34.848557: predicting hippocampus_219 
2024-12-07 07:09:34.855561: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-07 07:09:35.123557: predicting hippocampus_229 
2024-12-07 07:09:35.130559: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-07 07:09:35.400557: predicting hippocampus_244 
2024-12-07 07:09:35.406557: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-07 07:09:35.640557: predicting hippocampus_261 
2024-12-07 07:09:35.646561: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-07 07:09:36.112557: predicting hippocampus_264 
2024-12-07 07:09:36.118559: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-07 07:09:36.400557: predicting hippocampus_277 
2024-12-07 07:09:36.407559: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-07 07:09:36.826557: predicting hippocampus_280 
2024-12-07 07:09:36.832559: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-07 07:09:37.065557: predicting hippocampus_286 
2024-12-07 07:09:37.070559: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-07 07:09:37.415557: predicting hippocampus_288 
2024-12-07 07:09:37.422559: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-07 07:09:37.733557: predicting hippocampus_289 
2024-12-07 07:09:37.738559: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-07 07:09:38.016557: predicting hippocampus_296 
2024-12-07 07:09:38.022559: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-07 07:09:38.293557: predicting hippocampus_305 
2024-12-07 07:09:38.298561: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-07 07:09:38.537558: predicting hippocampus_308 
2024-12-07 07:09:38.542559: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-07 07:09:38.829557: predicting hippocampus_317 
2024-12-07 07:09:38.834558: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-07 07:09:39.086558: predicting hippocampus_327 
2024-12-07 07:09:39.092558: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-07 07:09:39.312557: predicting hippocampus_330 
2024-12-07 07:09:39.317559: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-07 07:09:39.565557: predicting hippocampus_332 
2024-12-07 07:09:39.570559: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-07 07:09:39.828557: predicting hippocampus_338 
2024-12-07 07:09:39.834559: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-07 07:09:40.161557: predicting hippocampus_349 
2024-12-07 07:09:40.168558: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-07 07:09:40.434557: predicting hippocampus_350 
2024-12-07 07:09:40.439561: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-07 07:09:40.673557: predicting hippocampus_356 
2024-12-07 07:09:40.678559: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-07 07:09:40.965558: predicting hippocampus_358 
2024-12-07 07:09:40.971558: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-07 07:09:41.235557: predicting hippocampus_374 
2024-12-07 07:09:41.241560: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-07 07:09:41.525557: predicting hippocampus_394 
2024-12-07 07:09:41.532559: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-07 07:09:45.227599: Validation complete 
2024-12-07 07:09:45.233598: Mean Validation Dice:  0.8771062863388417 
