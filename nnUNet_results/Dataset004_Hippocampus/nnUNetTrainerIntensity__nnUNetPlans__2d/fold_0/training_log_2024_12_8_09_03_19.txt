
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-08 09:03:19.369539: do_dummy_2d_data_aug: False 
2024-12-08 09:03:19.375087: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-08 09:03:19.377948: The split file contains 5 splits. 
2024-12-08 09:03:19.377948: Desired fold for training: 0 
2024-12-08 09:03:19.386332: This split has 208 training and 52 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 366, 'patch_size': [56, 40], 'median_image_size_in_voxels': [50.0, 35.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 4, 'features_per_stage': [32, 64, 128, 256], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset004_Hippocampus', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [36, 50, 35], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 486420.21875, 'mean': 22360.326171875, 'median': 362.88250732421875, 'min': 0.0, 'percentile_00_5': 28.0, 'percentile_99_5': 277682.03125, 'std': 60656.1328125}}} 
 
2024-12-08 09:03:25.899913: unpacking dataset... 
2024-12-08 09:03:26.117533: unpacking done... 
2024-12-08 09:03:27.023386:  
2024-12-08 09:03:27.028478: Epoch 0 
2024-12-08 09:03:27.031016: Current learning rate: 0.01 
2024-12-08 09:03:37.424736: train_loss -0.1664 
2024-12-08 09:03:37.432309: val_loss -0.639 
2024-12-08 09:03:37.437410: Pseudo dice [np.float32(0.7501), np.float32(0.7941)] 
2024-12-08 09:03:37.439957: Epoch time: 10.4 s 
2024-12-08 09:03:37.443502: Yayy! New best EMA pseudo Dice: 0.7720999717712402 
2024-12-08 09:03:38.097985:  
2024-12-08 09:03:38.103067: Epoch 1 
2024-12-08 09:03:38.106116: Current learning rate: 0.00991 
2024-12-08 09:03:47.798232: train_loss -0.7755 
2024-12-08 09:03:47.803329: val_loss -0.7913 
2024-12-08 09:03:47.806877: Pseudo dice [np.float32(0.8667), np.float32(0.8556)] 
2024-12-08 09:03:47.809916: Epoch time: 9.7 s 
2024-12-08 09:03:47.812458: Yayy! New best EMA pseudo Dice: 0.781000018119812 
2024-12-08 09:03:48.507835:  
2024-12-08 09:03:48.512901: Epoch 2 
2024-12-08 09:03:48.515956: Current learning rate: 0.00982 
2024-12-08 09:03:58.162256: train_loss -0.8401 
2024-12-08 09:03:58.168117: val_loss -0.7991 
2024-12-08 09:03:58.172162: Pseudo dice [np.float32(0.872), np.float32(0.8587)] 
2024-12-08 09:03:58.175715: Epoch time: 9.66 s 
2024-12-08 09:03:58.178262: Yayy! New best EMA pseudo Dice: 0.7893999814987183 
2024-12-08 09:03:58.934473:  
2024-12-08 09:03:58.941643: Epoch 3 
2024-12-08 09:03:58.944690: Current learning rate: 0.00973 
2024-12-08 09:04:08.658824: train_loss -0.8649 
2024-12-08 09:04:08.663882: val_loss -0.7987 
2024-12-08 09:04:08.667918: Pseudo dice [np.float32(0.875), np.float32(0.8588)] 
2024-12-08 09:04:08.670470: Epoch time: 9.72 s 
2024-12-08 09:04:08.674019: Yayy! New best EMA pseudo Dice: 0.7972000241279602 
2024-12-08 09:04:09.369972:  
2024-12-08 09:04:09.375046: Epoch 4 
2024-12-08 09:04:09.378598: Current learning rate: 0.00964 
2024-12-08 09:04:19.051834: train_loss -0.8819 
2024-12-08 09:04:19.056945: val_loss -0.7965 
2024-12-08 09:04:19.060992: Pseudo dice [np.float32(0.8758), np.float32(0.8596)] 
2024-12-08 09:04:19.063525: Epoch time: 9.68 s 
2024-12-08 09:04:19.066059: Yayy! New best EMA pseudo Dice: 0.8041999936103821 
2024-12-08 09:04:19.810692:  
2024-12-08 09:04:19.816322: Epoch 5 
2024-12-08 09:04:19.818859: Current learning rate: 0.00955 
2024-12-08 09:04:29.492492: train_loss -0.8941 
2024-12-08 09:04:29.497635: val_loss -0.7916 
2024-12-08 09:04:29.502698: Pseudo dice [np.float32(0.875), np.float32(0.8581)] 
2024-12-08 09:04:29.505232: Epoch time: 9.68 s 
2024-12-08 09:04:29.507763: Yayy! New best EMA pseudo Dice: 0.8105000257492065 
2024-12-08 09:04:30.322547:  
2024-12-08 09:04:30.328130: Epoch 6 
2024-12-08 09:04:30.331186: Current learning rate: 0.00946 
2024-12-08 09:04:40.078622: train_loss -0.9039 
2024-12-08 09:04:40.084240: val_loss -0.7873 
2024-12-08 09:04:40.088312: Pseudo dice [np.float32(0.8759), np.float32(0.8576)] 
2024-12-08 09:04:40.090864: Epoch time: 9.76 s 
2024-12-08 09:04:40.094446: Yayy! New best EMA pseudo Dice: 0.816100001335144 
2024-12-08 09:04:40.827128:  
2024-12-08 09:04:40.832803: Epoch 7 
2024-12-08 09:04:40.835909: Current learning rate: 0.00937 
2024-12-08 09:04:50.678576: train_loss -0.9108 
2024-12-08 09:04:50.684704: val_loss -0.7832 
2024-12-08 09:04:50.687234: Pseudo dice [np.float32(0.8743), np.float32(0.8556)] 
2024-12-08 09:04:50.691312: Epoch time: 9.85 s 
2024-12-08 09:04:50.693883: Yayy! New best EMA pseudo Dice: 0.8209999799728394 
2024-12-08 09:04:51.435829:  
2024-12-08 09:04:51.441939: Epoch 8 
2024-12-08 09:04:51.446028: Current learning rate: 0.00928 
2024-12-08 09:05:01.488859: train_loss -0.9172 
2024-12-08 09:05:01.495078: val_loss -0.7799 
2024-12-08 09:05:01.499147: Pseudo dice [np.float32(0.875), np.float32(0.8555)] 
2024-12-08 09:05:01.502708: Epoch time: 10.05 s 
2024-12-08 09:05:01.505252: Yayy! New best EMA pseudo Dice: 0.8253999948501587 
2024-12-08 09:05:02.232785:  
2024-12-08 09:05:02.238372: Epoch 9 
2024-12-08 09:05:02.240913: Current learning rate: 0.00919 
2024-12-08 09:05:12.205030: train_loss -0.9221 
2024-12-08 09:05:12.210604: val_loss -0.7787 
2024-12-08 09:05:12.213153: Pseudo dice [np.float32(0.8756), np.float32(0.8563)] 
2024-12-08 09:05:12.216711: Epoch time: 9.97 s 
2024-12-08 09:05:12.219271: Yayy! New best EMA pseudo Dice: 0.8295000195503235 
2024-12-08 09:05:12.918006:  
2024-12-08 09:05:12.923075: Epoch 10 
2024-12-08 09:05:12.925612: Current learning rate: 0.0091 
2024-12-08 09:05:22.984731: train_loss -0.9261 
2024-12-08 09:05:22.990814: val_loss -0.7767 
2024-12-08 09:05:22.993928: Pseudo dice [np.float32(0.8754), np.float32(0.8564)] 
2024-12-08 09:05:22.997483: Epoch time: 10.07 s 
2024-12-08 09:05:23.000043: Yayy! New best EMA pseudo Dice: 0.8331000208854675 
2024-12-08 09:05:23.704412:  
2024-12-08 09:05:23.709999: Epoch 11 
2024-12-08 09:05:23.712536: Current learning rate: 0.009 
2024-12-08 09:05:33.627641: train_loss -0.9298 
2024-12-08 09:05:33.633767: val_loss -0.7735 
2024-12-08 09:05:33.636300: Pseudo dice [np.float32(0.8743), np.float32(0.8553)] 
2024-12-08 09:05:33.638844: Epoch time: 9.92 s 
2024-12-08 09:05:33.642889: Yayy! New best EMA pseudo Dice: 0.8363000154495239 
2024-12-08 09:05:34.351468:  
2024-12-08 09:05:34.357563: Epoch 12 
2024-12-08 09:05:34.360112: Current learning rate: 0.00891 
2024-12-08 09:05:44.285588: train_loss -0.9329 
2024-12-08 09:05:44.295228: val_loss -0.7711 
2024-12-08 09:05:44.300337: Pseudo dice [np.float32(0.8756), np.float32(0.8541)] 
2024-12-08 09:05:44.304390: Epoch time: 9.93 s 
2024-12-08 09:05:44.307942: Yayy! New best EMA pseudo Dice: 0.8391000032424927 
2024-12-08 09:05:45.032642:  
2024-12-08 09:05:45.037718: Epoch 13 
2024-12-08 09:05:45.040815: Current learning rate: 0.00882 
2024-12-08 09:05:55.039052: train_loss -0.9357 
2024-12-08 09:05:55.046972: val_loss -0.7671 
2024-12-08 09:05:55.049542: Pseudo dice [np.float32(0.8735), np.float32(0.855)] 
2024-12-08 09:05:55.052659: Epoch time: 10.01 s 
2024-12-08 09:05:55.054668: Yayy! New best EMA pseudo Dice: 0.8416000008583069 
2024-12-08 09:05:55.910268:  
2024-12-08 09:05:55.916459: Epoch 14 
2024-12-08 09:05:55.920521: Current learning rate: 0.00873 
2024-12-08 09:06:05.966170: train_loss -0.9383 
2024-12-08 09:06:05.971360: val_loss -0.7665 
2024-12-08 09:06:05.975967: Pseudo dice [np.float32(0.8737), np.float32(0.8546)] 
2024-12-08 09:06:05.979020: Epoch time: 10.06 s 
2024-12-08 09:06:05.981559: Yayy! New best EMA pseudo Dice: 0.8439000248908997 
2024-12-08 09:06:06.712282:  
2024-12-08 09:06:06.717355: Epoch 15 
2024-12-08 09:06:06.720410: Current learning rate: 0.00864 
2024-12-08 09:06:16.777476: train_loss -0.9408 
2024-12-08 09:06:16.782540: val_loss -0.764 
2024-12-08 09:06:16.784597: Pseudo dice [np.float32(0.8747), np.float32(0.8544)] 
2024-12-08 09:06:16.789146: Epoch time: 10.07 s 
2024-12-08 09:06:16.792212: Yayy! New best EMA pseudo Dice: 0.8460000157356262 
2024-12-08 09:06:17.511301:  
2024-12-08 09:06:17.516900: Epoch 16 
2024-12-08 09:06:17.519483: Current learning rate: 0.00855 
2024-12-08 09:06:27.472735: train_loss -0.9428 
2024-12-08 09:06:27.478352: val_loss -0.7621 
2024-12-08 09:06:27.480899: Pseudo dice [np.float32(0.8738), np.float32(0.8549)] 
2024-12-08 09:06:27.483953: Epoch time: 9.96 s 
2024-12-08 09:06:27.488017: Yayy! New best EMA pseudo Dice: 0.8478000164031982 
2024-12-08 09:06:28.237122:  
2024-12-08 09:06:28.243724: Epoch 17 
2024-12-08 09:06:28.246801: Current learning rate: 0.00846 
2024-12-08 09:06:38.258550: train_loss -0.9446 
2024-12-08 09:06:38.264169: val_loss -0.7573 
2024-12-08 09:06:38.266704: Pseudo dice [np.float32(0.872), np.float32(0.8545)] 
2024-12-08 09:06:38.269244: Epoch time: 10.02 s 
2024-12-08 09:06:38.273290: Yayy! New best EMA pseudo Dice: 0.8493000268936157 
2024-12-08 09:06:38.997518:  
2024-12-08 09:06:39.003611: Epoch 18 
2024-12-08 09:06:39.007677: Current learning rate: 0.00836 
2024-12-08 09:06:49.057621: train_loss -0.9464 
2024-12-08 09:06:49.065233: val_loss -0.7563 
2024-12-08 09:06:49.070316: Pseudo dice [np.float32(0.8716), np.float32(0.8534)] 
2024-12-08 09:06:49.072845: Epoch time: 10.06 s 
2024-12-08 09:06:49.075377: Yayy! New best EMA pseudo Dice: 0.8507000207901001 
2024-12-08 09:06:49.798326:  
2024-12-08 09:06:49.803399: Epoch 19 
2024-12-08 09:06:49.805994: Current learning rate: 0.00827 
2024-12-08 09:06:59.865823: train_loss -0.9481 
2024-12-08 09:06:59.872593: val_loss -0.7547 
2024-12-08 09:06:59.875125: Pseudo dice [np.float32(0.872), np.float32(0.8542)] 
2024-12-08 09:06:59.879681: Epoch time: 10.07 s 
2024-12-08 09:06:59.882765: Yayy! New best EMA pseudo Dice: 0.8518999814987183 
2024-12-08 09:07:00.584900:  
2024-12-08 09:07:00.590534: Epoch 20 
2024-12-08 09:07:00.594589: Current learning rate: 0.00818 
2024-12-08 09:07:10.524604: train_loss -0.9495 
2024-12-08 09:07:10.530688: val_loss -0.7527 
2024-12-08 09:07:10.534743: Pseudo dice [np.float32(0.872), np.float32(0.8537)] 
2024-12-08 09:07:10.538296: Epoch time: 9.94 s 
2024-12-08 09:07:10.541382: Yayy! New best EMA pseudo Dice: 0.8529999852180481 
2024-12-08 09:07:11.409542:  
2024-12-08 09:07:11.414627: Epoch 21 
2024-12-08 09:07:11.417167: Current learning rate: 0.00809 
2024-12-08 09:07:21.247154: train_loss -0.951 
2024-12-08 09:07:21.252241: val_loss -0.7509 
2024-12-08 09:07:21.255812: Pseudo dice [np.float32(0.8714), np.float32(0.853)] 
2024-12-08 09:07:21.258879: Epoch time: 9.84 s 
2024-12-08 09:07:21.261419: Yayy! New best EMA pseudo Dice: 0.8539000153541565 
2024-12-08 09:07:21.952541:  
2024-12-08 09:07:21.958639: Epoch 22 
2024-12-08 09:07:21.961173: Current learning rate: 0.008 
2024-12-08 09:07:31.914038: train_loss -0.9525 
2024-12-08 09:07:31.919139: val_loss -0.7514 
2024-12-08 09:07:31.922698: Pseudo dice [np.float32(0.8723), np.float32(0.8552)] 
2024-12-08 09:07:31.925236: Epoch time: 9.96 s 
2024-12-08 09:07:31.929286: Yayy! New best EMA pseudo Dice: 0.8549000024795532 
2024-12-08 09:07:32.641354:  
2024-12-08 09:07:32.646981: Epoch 23 
2024-12-08 09:07:32.649519: Current learning rate: 0.0079 
2024-12-08 09:07:42.480701: train_loss -0.9538 
2024-12-08 09:07:42.485379: val_loss -0.7488 
2024-12-08 09:07:42.488965: Pseudo dice [np.float32(0.8717), np.float32(0.8541)] 
2024-12-08 09:07:42.492066: Epoch time: 9.84 s 
2024-12-08 09:07:42.495122: Yayy! New best EMA pseudo Dice: 0.8557000160217285 
2024-12-08 09:07:43.152656:  
2024-12-08 09:07:43.159312: Epoch 24 
2024-12-08 09:07:43.161848: Current learning rate: 0.00781 
2024-12-08 09:07:52.992199: train_loss -0.9548 
2024-12-08 09:07:52.999333: val_loss -0.7469 
2024-12-08 09:07:53.002411: Pseudo dice [np.float32(0.8715), np.float32(0.8539)] 
2024-12-08 09:07:53.004949: Epoch time: 9.84 s 
2024-12-08 09:07:53.008590: Yayy! New best EMA pseudo Dice: 0.8564000129699707 
2024-12-08 09:07:53.711073:  
2024-12-08 09:07:53.717225: Epoch 25 
2024-12-08 09:07:53.720777: Current learning rate: 0.00772 
2024-12-08 09:08:03.566925: train_loss -0.9562 
2024-12-08 09:08:03.572618: val_loss -0.7453 
2024-12-08 09:08:03.577158: Pseudo dice [np.float32(0.8712), np.float32(0.8527)] 
2024-12-08 09:08:03.580278: Epoch time: 9.86 s 
2024-12-08 09:08:03.582811: Yayy! New best EMA pseudo Dice: 0.8569999933242798 
2024-12-08 09:08:04.305698:  
2024-12-08 09:08:04.310770: Epoch 26 
2024-12-08 09:08:04.314332: Current learning rate: 0.00763 
2024-12-08 09:08:14.226472: train_loss -0.9572 
2024-12-08 09:08:14.232094: val_loss -0.7447 
2024-12-08 09:08:14.234654: Pseudo dice [np.float32(0.8737), np.float32(0.8528)] 
2024-12-08 09:08:14.239228: Epoch time: 9.92 s 
2024-12-08 09:08:14.242374: Yayy! New best EMA pseudo Dice: 0.8575999736785889 
2024-12-08 09:08:14.913575:  
2024-12-08 09:08:14.919177: Epoch 27 
2024-12-08 09:08:14.921711: Current learning rate: 0.00753 
2024-12-08 09:08:24.834508: train_loss -0.9581 
2024-12-08 09:08:24.840163: val_loss -0.745 
2024-12-08 09:08:24.843237: Pseudo dice [np.float32(0.8717), np.float32(0.8539)] 
2024-12-08 09:08:24.845791: Epoch time: 9.92 s 
2024-12-08 09:08:24.849350: Yayy! New best EMA pseudo Dice: 0.8580999970436096 
2024-12-08 09:08:25.557573:  
2024-12-08 09:08:25.562712: Epoch 28 
2024-12-08 09:08:25.565246: Current learning rate: 0.00744 
2024-12-08 09:08:35.363347: train_loss -0.9591 
2024-12-08 09:08:35.368453: val_loss -0.7463 
2024-12-08 09:08:35.371502: Pseudo dice [np.float32(0.8736), np.float32(0.8551)] 
2024-12-08 09:08:35.374038: Epoch time: 9.81 s 
2024-12-08 09:08:35.377604: Yayy! New best EMA pseudo Dice: 0.8586999773979187 
2024-12-08 09:08:36.075400:  
2024-12-08 09:08:36.081995: Epoch 29 
2024-12-08 09:08:36.084531: Current learning rate: 0.00735 
2024-12-08 09:08:45.997255: train_loss -0.9602 
2024-12-08 09:08:46.002500: val_loss -0.7402 
2024-12-08 09:08:46.005035: Pseudo dice [np.float32(0.8713), np.float32(0.8521)] 
2024-12-08 09:08:46.007568: Epoch time: 9.92 s 
2024-12-08 09:08:46.012119: Yayy! New best EMA pseudo Dice: 0.859000027179718 
2024-12-08 09:08:46.869575:  
2024-12-08 09:08:46.876187: Epoch 30 
2024-12-08 09:08:46.879237: Current learning rate: 0.00725 
2024-12-08 09:08:56.830974: train_loss -0.9608 
2024-12-08 09:08:56.839146: val_loss -0.7422 
2024-12-08 09:08:56.841687: Pseudo dice [np.float32(0.8734), np.float32(0.853)] 
2024-12-08 09:08:56.845731: Epoch time: 9.96 s 
2024-12-08 09:08:56.848797: Yayy! New best EMA pseudo Dice: 0.8593999743461609 
2024-12-08 09:08:57.560840:  
2024-12-08 09:08:57.566933: Epoch 31 
2024-12-08 09:08:57.569987: Current learning rate: 0.00716 
2024-12-08 09:09:07.367285: train_loss -0.9619 
2024-12-08 09:09:07.372896: val_loss -0.7396 
2024-12-08 09:09:07.375965: Pseudo dice [np.float32(0.8729), np.float32(0.8545)] 
2024-12-08 09:09:07.379031: Epoch time: 9.81 s 
2024-12-08 09:09:07.381573: Yayy! New best EMA pseudo Dice: 0.8598999977111816 
2024-12-08 09:09:08.080889:  
2024-12-08 09:09:08.086980: Epoch 32 
2024-12-08 09:09:08.090065: Current learning rate: 0.00707 
2024-12-08 09:09:17.970658: train_loss -0.9625 
2024-12-08 09:09:17.976758: val_loss -0.7358 
2024-12-08 09:09:17.979289: Pseudo dice [np.float32(0.8707), np.float32(0.8533)] 
2024-12-08 09:09:17.983349: Epoch time: 9.89 s 
2024-12-08 09:09:17.985881: Yayy! New best EMA pseudo Dice: 0.8600999712944031 
2024-12-08 09:09:18.706693:  
2024-12-08 09:09:18.711756: Epoch 33 
2024-12-08 09:09:18.714317: Current learning rate: 0.00697 
2024-12-08 09:09:28.617885: train_loss -0.9632 
2024-12-08 09:09:28.623004: val_loss -0.7378 
2024-12-08 09:09:28.625531: Pseudo dice [np.float32(0.8723), np.float32(0.8539)] 
2024-12-08 09:09:28.630072: Epoch time: 9.91 s 
2024-12-08 09:09:28.633118: Yayy! New best EMA pseudo Dice: 0.8604000210762024 
2024-12-08 09:09:29.377376:  
2024-12-08 09:09:29.382953: Epoch 34 
2024-12-08 09:09:29.385514: Current learning rate: 0.00688 
2024-12-08 09:09:39.303726: train_loss -0.964 
2024-12-08 09:09:39.308816: val_loss -0.738 
2024-12-08 09:09:39.312927: Pseudo dice [np.float32(0.8718), np.float32(0.8548)] 
2024-12-08 09:09:39.315983: Epoch time: 9.93 s 
2024-12-08 09:09:39.318528: Yayy! New best EMA pseudo Dice: 0.8607000112533569 
2024-12-08 09:09:40.037181:  
2024-12-08 09:09:40.043287: Epoch 35 
2024-12-08 09:09:40.045823: Current learning rate: 0.00679 
2024-12-08 09:09:49.923631: train_loss -0.9643 
2024-12-08 09:09:49.930817: val_loss -0.7364 
2024-12-08 09:09:49.933871: Pseudo dice [np.float32(0.8722), np.float32(0.8544)] 
2024-12-08 09:09:49.936399: Epoch time: 9.89 s 
2024-12-08 09:09:49.938928: Yayy! New best EMA pseudo Dice: 0.8608999848365784 
2024-12-08 09:09:50.650822:  
2024-12-08 09:09:50.656408: Epoch 36 
2024-12-08 09:09:50.658948: Current learning rate: 0.00669 
2024-12-08 09:10:00.534927: train_loss -0.965 
2024-12-08 09:10:00.542496: val_loss -0.7369 
2024-12-08 09:10:00.547578: Pseudo dice [np.float32(0.872), np.float32(0.8537)] 
2024-12-08 09:10:00.552648: Epoch time: 9.88 s 
2024-12-08 09:10:00.555203: Yayy! New best EMA pseudo Dice: 0.8611000180244446 
2024-12-08 09:10:01.416179:  
2024-12-08 09:10:01.420768: Epoch 37 
2024-12-08 09:10:01.423835: Current learning rate: 0.0066 
2024-12-08 09:10:11.318319: train_loss -0.9658 
2024-12-08 09:10:11.323897: val_loss -0.7331 
2024-12-08 09:10:11.326428: Pseudo dice [np.float32(0.8711), np.float32(0.8538)] 
2024-12-08 09:10:11.328986: Epoch time: 9.9 s 
2024-12-08 09:10:11.331514: Yayy! New best EMA pseudo Dice: 0.861299991607666 
2024-12-08 09:10:12.075724:  
2024-12-08 09:10:12.080849: Epoch 38 
2024-12-08 09:10:12.083909: Current learning rate: 0.0065 
2024-12-08 09:10:21.860554: train_loss -0.9664 
2024-12-08 09:10:21.866634: val_loss -0.7333 
2024-12-08 09:10:21.869171: Pseudo dice [np.float32(0.8716), np.float32(0.8539)] 
2024-12-08 09:10:21.873246: Epoch time: 9.79 s 
2024-12-08 09:10:21.875816: Yayy! New best EMA pseudo Dice: 0.8614000082015991 
2024-12-08 09:10:22.595432:  
2024-12-08 09:10:22.601080: Epoch 39 
2024-12-08 09:10:22.603620: Current learning rate: 0.00641 
2024-12-08 09:10:32.367321: train_loss -0.9669 
2024-12-08 09:10:32.371957: val_loss -0.7325 
2024-12-08 09:10:32.376571: Pseudo dice [np.float32(0.8715), np.float32(0.8543)] 
2024-12-08 09:10:32.379617: Epoch time: 9.77 s 
2024-12-08 09:10:32.382150: Yayy! New best EMA pseudo Dice: 0.8615999817848206 
2024-12-08 09:10:33.125090:  
2024-12-08 09:10:33.130161: Epoch 40 
2024-12-08 09:10:33.133731: Current learning rate: 0.00631 
2024-12-08 09:10:42.936263: train_loss -0.9675 
2024-12-08 09:10:42.941344: val_loss -0.7288 
2024-12-08 09:10:42.946419: Pseudo dice [np.float32(0.8707), np.float32(0.8515)] 
2024-12-08 09:10:42.948962: Epoch time: 9.81 s 
2024-12-08 09:10:43.659415:  
2024-12-08 09:10:43.664480: Epoch 41 
2024-12-08 09:10:43.667524: Current learning rate: 0.00622 
2024-12-08 09:10:53.498437: train_loss -0.9682 
2024-12-08 09:10:53.504519: val_loss -0.73 
2024-12-08 09:10:53.507614: Pseudo dice [np.float32(0.8714), np.float32(0.8524)] 
2024-12-08 09:10:53.510154: Epoch time: 9.84 s 
2024-12-08 09:10:54.216193:  
2024-12-08 09:10:54.222289: Epoch 42 
2024-12-08 09:10:54.225332: Current learning rate: 0.00612 
2024-12-08 09:11:04.086723: train_loss -0.9688 
2024-12-08 09:11:04.092830: val_loss -0.7288 
2024-12-08 09:11:04.096894: Pseudo dice [np.float32(0.8713), np.float32(0.8535)] 
2024-12-08 09:11:04.099954: Epoch time: 9.87 s 
2024-12-08 09:11:04.102519: Yayy! New best EMA pseudo Dice: 0.8615999817848206 
2024-12-08 09:11:04.792897:  
2024-12-08 09:11:04.799498: Epoch 43 
2024-12-08 09:11:04.802539: Current learning rate: 0.00603 
2024-12-08 09:11:14.610683: train_loss -0.9693 
2024-12-08 09:11:14.615909: val_loss -0.7291 
2024-12-08 09:11:14.618526: Pseudo dice [np.float32(0.8709), np.float32(0.8532)] 
2024-12-08 09:11:14.621102: Epoch time: 9.82 s 
2024-12-08 09:11:14.626439: Yayy! New best EMA pseudo Dice: 0.8616999983787537 
2024-12-08 09:11:15.306644:  
2024-12-08 09:11:15.311756: Epoch 44 
2024-12-08 09:11:15.315822: Current learning rate: 0.00593 
2024-12-08 09:11:25.183094: train_loss -0.9698 
2024-12-08 09:11:25.188405: val_loss -0.729 
2024-12-08 09:11:25.191035: Pseudo dice [np.float32(0.8727), np.float32(0.8529)] 
2024-12-08 09:11:25.193669: Epoch time: 9.88 s 
2024-12-08 09:11:25.196386: Yayy! New best EMA pseudo Dice: 0.8618000149726868 
2024-12-08 09:11:26.044629:  
2024-12-08 09:11:26.049695: Epoch 45 
2024-12-08 09:11:26.053784: Current learning rate: 0.00584 
2024-12-08 09:11:35.918460: train_loss -0.9703 
2024-12-08 09:11:35.923516: val_loss -0.7268 
2024-12-08 09:11:35.926058: Pseudo dice [np.float32(0.8712), np.float32(0.8522)] 
2024-12-08 09:11:35.928599: Epoch time: 9.87 s 
2024-12-08 09:11:36.592094:  
2024-12-08 09:11:36.597166: Epoch 46 
2024-12-08 09:11:36.600234: Current learning rate: 0.00574 
2024-12-08 09:11:46.520944: train_loss -0.9707 
2024-12-08 09:11:46.526217: val_loss -0.7267 
2024-12-08 09:11:46.528752: Pseudo dice [np.float32(0.8704), np.float32(0.8529)] 
2024-12-08 09:11:46.531405: Epoch time: 9.93 s 
2024-12-08 09:11:47.194746:  
2024-12-08 09:11:47.199833: Epoch 47 
2024-12-08 09:11:47.202891: Current learning rate: 0.00565 
2024-12-08 09:11:57.048365: train_loss -0.9712 
2024-12-08 09:11:57.053456: val_loss -0.7274 
2024-12-08 09:11:57.056994: Pseudo dice [np.float32(0.872), np.float32(0.8521)] 
2024-12-08 09:11:57.060555: Epoch time: 9.85 s 
2024-12-08 09:11:57.063601: Yayy! New best EMA pseudo Dice: 0.8618000149726868 
2024-12-08 09:11:57.750550:  
2024-12-08 09:11:57.756161: Epoch 48 
2024-12-08 09:11:57.758702: Current learning rate: 0.00555 
2024-12-08 09:12:07.621709: train_loss -0.9714 
2024-12-08 09:12:07.627841: val_loss -0.726 
2024-12-08 09:12:07.631423: Pseudo dice [np.float32(0.8713), np.float32(0.8528)] 
2024-12-08 09:12:07.634981: Epoch time: 9.87 s 
2024-12-08 09:12:07.638034: Yayy! New best EMA pseudo Dice: 0.8618000149726868 
2024-12-08 09:12:08.346668:  
2024-12-08 09:12:08.351726: Epoch 49 
2024-12-08 09:12:08.354256: Current learning rate: 0.00546 
2024-12-08 09:12:18.242043: train_loss -0.9719 
2024-12-08 09:12:18.247699: val_loss -0.7261 
2024-12-08 09:12:18.250763: Pseudo dice [np.float32(0.8715), np.float32(0.854)] 
2024-12-08 09:12:18.252805: Epoch time: 9.9 s 
2024-12-08 09:12:18.283472: Yayy! New best EMA pseudo Dice: 0.8618999719619751 
2024-12-08 09:12:19.004200:  
2024-12-08 09:12:19.009773: Epoch 50 
2024-12-08 09:12:19.013334: Current learning rate: 0.00536 
2024-12-08 09:12:28.840230: train_loss -0.9722 
2024-12-08 09:12:28.845857: val_loss -0.7227 
2024-12-08 09:12:28.849428: Pseudo dice [np.float32(0.8706), np.float32(0.8521)] 
2024-12-08 09:12:28.851976: Epoch time: 9.84 s 
2024-12-08 09:12:29.518951:  
2024-12-08 09:12:29.524033: Epoch 51 
2024-12-08 09:12:29.527084: Current learning rate: 0.00526 
2024-12-08 09:12:39.400474: train_loss -0.9725 
2024-12-08 09:12:39.405548: val_loss -0.7242 
2024-12-08 09:12:39.409091: Pseudo dice [np.float32(0.8721), np.float32(0.8528)] 
2024-12-08 09:12:39.412681: Epoch time: 9.88 s 
2024-12-08 09:12:39.415731: Yayy! New best EMA pseudo Dice: 0.8618999719619751 
2024-12-08 09:12:40.112909:  
2024-12-08 09:12:40.119494: Epoch 52 
2024-12-08 09:12:40.122577: Current learning rate: 0.00517 
2024-12-08 09:12:49.921137: train_loss -0.973 
2024-12-08 09:12:49.926205: val_loss -0.7228 
2024-12-08 09:12:49.929283: Pseudo dice [np.float32(0.8708), np.float32(0.852)] 
2024-12-08 09:12:49.931830: Epoch time: 9.81 s 
2024-12-08 09:12:50.760910:  
2024-12-08 09:12:50.767064: Epoch 53 
2024-12-08 09:12:50.769596: Current learning rate: 0.00507 
2024-12-08 09:13:00.659483: train_loss -0.9736 
2024-12-08 09:13:00.664560: val_loss -0.7231 
2024-12-08 09:13:00.667118: Pseudo dice [np.float32(0.8714), np.float32(0.853)] 
2024-12-08 09:13:00.670662: Epoch time: 9.9 s 
2024-12-08 09:13:01.350985:  
2024-12-08 09:13:01.356607: Epoch 54 
2024-12-08 09:13:01.359663: Current learning rate: 0.00497 
2024-12-08 09:13:11.094725: train_loss -0.974 
2024-12-08 09:13:11.102348: val_loss -0.7249 
2024-12-08 09:13:11.104915: Pseudo dice [np.float32(0.8723), np.float32(0.8533)] 
2024-12-08 09:13:11.107509: Epoch time: 9.74 s 
2024-12-08 09:13:11.112788: Yayy! New best EMA pseudo Dice: 0.8619999885559082 
2024-12-08 09:13:11.795733:  
2024-12-08 09:13:11.802855: Epoch 55 
2024-12-08 09:13:11.805915: Current learning rate: 0.00487 
2024-12-08 09:13:21.665690: train_loss -0.9744 
2024-12-08 09:13:21.672383: val_loss -0.7249 
2024-12-08 09:13:21.676019: Pseudo dice [np.float32(0.872), np.float32(0.8526)] 
2024-12-08 09:13:21.678557: Epoch time: 9.87 s 
2024-12-08 09:13:21.681212: Yayy! New best EMA pseudo Dice: 0.8619999885559082 
2024-12-08 09:13:22.383906:  
2024-12-08 09:13:22.388982: Epoch 56 
2024-12-08 09:13:22.392084: Current learning rate: 0.00478 
2024-12-08 09:13:32.242479: train_loss -0.9747 
2024-12-08 09:13:32.247550: val_loss -0.7222 
2024-12-08 09:13:32.250082: Pseudo dice [np.float32(0.8705), np.float32(0.8521)] 
2024-12-08 09:13:32.254127: Epoch time: 9.86 s 
2024-12-08 09:13:32.943546:  
2024-12-08 09:13:32.949620: Epoch 57 
2024-12-08 09:13:32.952700: Current learning rate: 0.00468 
2024-12-08 09:13:42.818763: train_loss -0.9748 
2024-12-08 09:13:42.822366: val_loss -0.724 
2024-12-08 09:13:42.826913: Pseudo dice [np.float32(0.8715), np.float32(0.8528)] 
2024-12-08 09:13:42.829965: Epoch time: 9.88 s 
2024-12-08 09:13:43.523241:  
2024-12-08 09:13:43.529329: Epoch 58 
2024-12-08 09:13:43.531920: Current learning rate: 0.00458 
2024-12-08 09:13:53.251915: train_loss -0.9751 
2024-12-08 09:13:53.258035: val_loss -0.723 
2024-12-08 09:13:53.261595: Pseudo dice [np.float32(0.8723), np.float32(0.8524)] 
2024-12-08 09:13:53.265133: Epoch time: 9.73 s 
2024-12-08 09:13:53.956718:  
2024-12-08 09:13:53.963303: Epoch 59 
2024-12-08 09:13:53.966346: Current learning rate: 0.00448 
2024-12-08 09:14:03.835695: train_loss -0.9756 
2024-12-08 09:14:03.841836: val_loss -0.7173 
2024-12-08 09:14:03.844365: Pseudo dice [np.float32(0.8704), np.float32(0.851)] 
2024-12-08 09:14:03.846894: Epoch time: 9.88 s 
2024-12-08 09:14:04.542531:  
2024-12-08 09:14:04.548126: Epoch 60 
2024-12-08 09:14:04.550661: Current learning rate: 0.00438 
2024-12-08 09:14:14.432599: train_loss -0.9759 
2024-12-08 09:14:14.439704: val_loss -0.721 
2024-12-08 09:14:14.442763: Pseudo dice [np.float32(0.8704), np.float32(0.8532)] 
2024-12-08 09:14:14.445295: Epoch time: 9.89 s 
2024-12-08 09:14:15.276791:  
2024-12-08 09:14:15.282385: Epoch 61 
2024-12-08 09:14:15.284921: Current learning rate: 0.00429 
2024-12-08 09:14:25.150778: train_loss -0.9759 
2024-12-08 09:14:25.157379: val_loss -0.7189 
2024-12-08 09:14:25.161046: Pseudo dice [np.float32(0.8695), np.float32(0.8523)] 
2024-12-08 09:14:25.163578: Epoch time: 9.88 s 
2024-12-08 09:14:25.840025:  
2024-12-08 09:14:25.846642: Epoch 62 
2024-12-08 09:14:25.849183: Current learning rate: 0.00419 
2024-12-08 09:14:35.659409: train_loss -0.9762 
2024-12-08 09:14:35.666071: val_loss -0.72 
2024-12-08 09:14:35.668610: Pseudo dice [np.float32(0.8703), np.float32(0.8529)] 
2024-12-08 09:14:35.672164: Epoch time: 9.82 s 
2024-12-08 09:14:36.372643:  
2024-12-08 09:14:36.379255: Epoch 63 
2024-12-08 09:14:36.381845: Current learning rate: 0.00409 
2024-12-08 09:14:46.156631: train_loss -0.9765 
2024-12-08 09:14:46.161760: val_loss -0.7193 
2024-12-08 09:14:46.164935: Pseudo dice [np.float32(0.8716), np.float32(0.8518)] 
2024-12-08 09:14:46.169500: Epoch time: 9.78 s 
2024-12-08 09:14:46.881713:  
2024-12-08 09:14:46.887309: Epoch 64 
2024-12-08 09:14:46.890358: Current learning rate: 0.00399 
2024-12-08 09:14:56.766855: train_loss -0.9772 
2024-12-08 09:14:56.773053: val_loss -0.7189 
2024-12-08 09:14:56.775103: Pseudo dice [np.float32(0.8698), np.float32(0.8528)] 
2024-12-08 09:14:56.779149: Epoch time: 9.89 s 
2024-12-08 09:14:57.478504:  
2024-12-08 09:14:57.483579: Epoch 65 
2024-12-08 09:14:57.486146: Current learning rate: 0.00389 
2024-12-08 09:15:07.254060: train_loss -0.9771 
2024-12-08 09:15:07.259126: val_loss -0.7142 
2024-12-08 09:15:07.262731: Pseudo dice [np.float32(0.8692), np.float32(0.8508)] 
2024-12-08 09:15:07.266271: Epoch time: 9.78 s 
2024-12-08 09:15:07.964286:  
2024-12-08 09:15:07.969888: Epoch 66 
2024-12-08 09:15:07.972928: Current learning rate: 0.00379 
2024-12-08 09:15:17.833237: train_loss -0.9773 
2024-12-08 09:15:17.840404: val_loss -0.7175 
2024-12-08 09:15:17.844986: Pseudo dice [np.float32(0.8708), np.float32(0.851)] 
2024-12-08 09:15:17.848050: Epoch time: 9.87 s 
2024-12-08 09:15:18.541845:  
2024-12-08 09:15:18.547960: Epoch 67 
2024-12-08 09:15:18.550500: Current learning rate: 0.00369 
2024-12-08 09:15:28.438380: train_loss -0.9778 
2024-12-08 09:15:28.443440: val_loss -0.7173 
2024-12-08 09:15:28.445972: Pseudo dice [np.float32(0.8694), np.float32(0.8521)] 
2024-12-08 09:15:28.450543: Epoch time: 9.9 s 
2024-12-08 09:15:29.161795:  
2024-12-08 09:15:29.166857: Epoch 68 
2024-12-08 09:15:29.169392: Current learning rate: 0.00359 
2024-12-08 09:15:39.024883: train_loss -0.9777 
2024-12-08 09:15:39.030480: val_loss -0.7163 
2024-12-08 09:15:39.033053: Pseudo dice [np.float32(0.8709), np.float32(0.8513)] 
2024-12-08 09:15:39.035583: Epoch time: 9.86 s 
2024-12-08 09:15:39.883651:  
2024-12-08 09:15:39.888728: Epoch 69 
2024-12-08 09:15:39.891329: Current learning rate: 0.00349 
2024-12-08 09:15:49.806767: train_loss -0.9782 
2024-12-08 09:15:49.811834: val_loss -0.7174 
2024-12-08 09:15:49.814388: Pseudo dice [np.float32(0.8711), np.float32(0.8534)] 
2024-12-08 09:15:49.818436: Epoch time: 9.92 s 
2024-12-08 09:15:50.532377:  
2024-12-08 09:15:50.537482: Epoch 70 
2024-12-08 09:15:50.541041: Current learning rate: 0.00338 
2024-12-08 09:16:00.410929: train_loss -0.9784 
2024-12-08 09:16:00.416563: val_loss -0.7142 
2024-12-08 09:16:00.419105: Pseudo dice [np.float32(0.8698), np.float32(0.8517)] 
2024-12-08 09:16:00.423164: Epoch time: 9.88 s 
2024-12-08 09:16:01.125748:  
2024-12-08 09:16:01.130812: Epoch 71 
2024-12-08 09:16:01.133352: Current learning rate: 0.00328 
2024-12-08 09:16:11.015087: train_loss -0.979 
2024-12-08 09:16:11.020287: val_loss -0.714 
2024-12-08 09:16:11.024359: Pseudo dice [np.float32(0.8701), np.float32(0.8514)] 
2024-12-08 09:16:11.027410: Epoch time: 9.89 s 
2024-12-08 09:16:11.746790:  
2024-12-08 09:16:11.752366: Epoch 72 
2024-12-08 09:16:11.755410: Current learning rate: 0.00318 
2024-12-08 09:16:21.629458: train_loss -0.9788 
2024-12-08 09:16:21.637237: val_loss -0.7149 
2024-12-08 09:16:21.638249: Pseudo dice [np.float32(0.87), np.float32(0.8512)] 
2024-12-08 09:16:21.643476: Epoch time: 9.88 s 
2024-12-08 09:16:22.355509:  
2024-12-08 09:16:22.360630: Epoch 73 
2024-12-08 09:16:22.364183: Current learning rate: 0.00308 
2024-12-08 09:16:32.243535: train_loss -0.979 
2024-12-08 09:16:32.249664: val_loss -0.7145 
2024-12-08 09:16:32.252216: Pseudo dice [np.float32(0.8694), np.float32(0.8508)] 
2024-12-08 09:16:32.255319: Epoch time: 9.89 s 
2024-12-08 09:16:32.969123:  
2024-12-08 09:16:32.974206: Epoch 74 
2024-12-08 09:16:32.977263: Current learning rate: 0.00297 
2024-12-08 09:16:42.828679: train_loss -0.9792 
2024-12-08 09:16:42.833759: val_loss -0.7099 
2024-12-08 09:16:42.837309: Pseudo dice [np.float32(0.8684), np.float32(0.8513)] 
2024-12-08 09:16:42.839842: Epoch time: 9.86 s 
2024-12-08 09:16:43.547243:  
2024-12-08 09:16:43.553843: Epoch 75 
2024-12-08 09:16:43.556899: Current learning rate: 0.00287 
2024-12-08 09:16:53.350871: train_loss -0.9793 
2024-12-08 09:16:53.356457: val_loss -0.7132 
2024-12-08 09:16:53.359515: Pseudo dice [np.float32(0.8708), np.float32(0.8513)] 
2024-12-08 09:16:53.362573: Epoch time: 9.8 s 
2024-12-08 09:16:54.055438:  
2024-12-08 09:16:54.062025: Epoch 76 
2024-12-08 09:16:54.065648: Current learning rate: 0.00277 
2024-12-08 09:17:03.951419: train_loss -0.9797 
2024-12-08 09:17:03.956729: val_loss -0.7135 
2024-12-08 09:17:03.961289: Pseudo dice [np.float32(0.8705), np.float32(0.8516)] 
2024-12-08 09:17:03.963829: Epoch time: 9.9 s 
2024-12-08 09:17:04.815868:  
2024-12-08 09:17:04.821492: Epoch 77 
2024-12-08 09:17:04.825036: Current learning rate: 0.00266 
2024-12-08 09:17:14.664088: train_loss -0.9797 
2024-12-08 09:17:14.669159: val_loss -0.7149 
2024-12-08 09:17:14.671736: Pseudo dice [np.float32(0.8708), np.float32(0.8514)] 
2024-12-08 09:17:14.675782: Epoch time: 9.85 s 
2024-12-08 09:17:15.384529:  
2024-12-08 09:17:15.389603: Epoch 78 
2024-12-08 09:17:15.393210: Current learning rate: 0.00256 
2024-12-08 09:17:25.210712: train_loss -0.98 
2024-12-08 09:17:25.216295: val_loss -0.7132 
2024-12-08 09:17:25.220861: Pseudo dice [np.float32(0.8701), np.float32(0.8516)] 
2024-12-08 09:17:25.223955: Epoch time: 9.83 s 
2024-12-08 09:17:25.931187:  
2024-12-08 09:17:25.936259: Epoch 79 
2024-12-08 09:17:25.938797: Current learning rate: 0.00245 
2024-12-08 09:17:35.809537: train_loss -0.9801 
2024-12-08 09:17:35.815749: val_loss -0.7126 
2024-12-08 09:17:35.818273: Pseudo dice [np.float32(0.8701), np.float32(0.8509)] 
2024-12-08 09:17:35.821407: Epoch time: 9.88 s 
2024-12-08 09:17:36.510141:  
2024-12-08 09:17:36.516772: Epoch 80 
2024-12-08 09:17:36.519278: Current learning rate: 0.00235 
2024-12-08 09:17:46.379767: train_loss -0.9803 
2024-12-08 09:17:46.385363: val_loss -0.7128 
2024-12-08 09:17:46.387902: Pseudo dice [np.float32(0.8697), np.float32(0.8516)] 
2024-12-08 09:17:46.390956: Epoch time: 9.87 s 
2024-12-08 09:17:47.099278:  
2024-12-08 09:17:47.104336: Epoch 81 
2024-12-08 09:17:47.106868: Current learning rate: 0.00224 
2024-12-08 09:17:56.950301: train_loss -0.9806 
2024-12-08 09:17:56.955403: val_loss -0.7072 
2024-12-08 09:17:56.958953: Pseudo dice [np.float32(0.868), np.float32(0.8509)] 
2024-12-08 09:17:56.962551: Epoch time: 9.85 s 
2024-12-08 09:17:57.678791:  
2024-12-08 09:17:57.683899: Epoch 82 
2024-12-08 09:17:57.686442: Current learning rate: 0.00214 
2024-12-08 09:18:07.452079: train_loss -0.9806 
2024-12-08 09:18:07.458191: val_loss -0.7111 
2024-12-08 09:18:07.460740: Pseudo dice [np.float32(0.869), np.float32(0.852)] 
2024-12-08 09:18:07.464808: Epoch time: 9.78 s 
2024-12-08 09:18:08.156717:  
2024-12-08 09:18:08.163837: Epoch 83 
2024-12-08 09:18:08.166890: Current learning rate: 0.00203 
2024-12-08 09:18:18.022506: train_loss -0.9808 
2024-12-08 09:18:18.028688: val_loss -0.708 
2024-12-08 09:18:18.031219: Pseudo dice [np.float32(0.8682), np.float32(0.8511)] 
2024-12-08 09:18:18.033775: Epoch time: 9.87 s 
2024-12-08 09:18:18.722776:  
2024-12-08 09:18:18.729463: Epoch 84 
2024-12-08 09:18:18.732506: Current learning rate: 0.00192 
2024-12-08 09:18:28.630871: train_loss -0.981 
2024-12-08 09:18:28.637619: val_loss -0.7091 
2024-12-08 09:18:28.642206: Pseudo dice [np.float32(0.8694), np.float32(0.8509)] 
2024-12-08 09:18:28.645269: Epoch time: 9.91 s 
2024-12-08 09:18:29.489644:  
2024-12-08 09:18:29.495798: Epoch 85 
2024-12-08 09:18:29.498340: Current learning rate: 0.00181 
2024-12-08 09:18:39.357779: train_loss -0.9812 
2024-12-08 09:18:39.362840: val_loss -0.7093 
2024-12-08 09:18:39.366377: Pseudo dice [np.float32(0.8696), np.float32(0.8507)] 
2024-12-08 09:18:39.368948: Epoch time: 9.87 s 
2024-12-08 09:18:40.047565:  
2024-12-08 09:18:40.052164: Epoch 86 
2024-12-08 09:18:40.055226: Current learning rate: 0.0017 
2024-12-08 09:18:49.902199: train_loss -0.9811 
2024-12-08 09:18:49.907279: val_loss -0.7107 
2024-12-08 09:18:49.911354: Pseudo dice [np.float32(0.8706), np.float32(0.8513)] 
2024-12-08 09:18:49.914892: Epoch time: 9.86 s 
2024-12-08 09:18:50.577891:  
2024-12-08 09:18:50.583512: Epoch 87 
2024-12-08 09:18:50.587080: Current learning rate: 0.00159 
2024-12-08 09:19:00.384874: train_loss -0.9813 
2024-12-08 09:19:00.390455: val_loss -0.7079 
2024-12-08 09:19:00.392993: Pseudo dice [np.float32(0.869), np.float32(0.8511)] 
2024-12-08 09:19:00.397052: Epoch time: 9.81 s 
2024-12-08 09:19:01.090759:  
2024-12-08 09:19:01.095816: Epoch 88 
2024-12-08 09:19:01.098375: Current learning rate: 0.00148 
2024-12-08 09:19:10.818203: train_loss -0.9813 
2024-12-08 09:19:10.823790: val_loss -0.7092 
2024-12-08 09:19:10.826845: Pseudo dice [np.float32(0.8701), np.float32(0.8503)] 
2024-12-08 09:19:10.829380: Epoch time: 9.73 s 
2024-12-08 09:19:11.516548:  
2024-12-08 09:19:11.521665: Epoch 89 
2024-12-08 09:19:11.525227: Current learning rate: 0.00137 
2024-12-08 09:19:21.413969: train_loss -0.9816 
2024-12-08 09:19:21.421088: val_loss -0.7098 
2024-12-08 09:19:21.423624: Pseudo dice [np.float32(0.8692), np.float32(0.8519)] 
2024-12-08 09:19:21.427669: Epoch time: 9.9 s 
2024-12-08 09:19:22.072634:  
2024-12-08 09:19:22.078732: Epoch 90 
2024-12-08 09:19:22.081812: Current learning rate: 0.00126 
2024-12-08 09:19:31.957258: train_loss -0.9818 
2024-12-08 09:19:31.962839: val_loss -0.7123 
2024-12-08 09:19:31.965954: Pseudo dice [np.float32(0.8713), np.float32(0.8502)] 
2024-12-08 09:19:31.967974: Epoch time: 9.88 s 
2024-12-08 09:19:32.652620:  
2024-12-08 09:19:32.658264: Epoch 91 
2024-12-08 09:19:32.661310: Current learning rate: 0.00115 
2024-12-08 09:19:42.525450: train_loss -0.9819 
2024-12-08 09:19:42.531041: val_loss -0.7088 
2024-12-08 09:19:42.534088: Pseudo dice [np.float32(0.8698), np.float32(0.8503)] 
2024-12-08 09:19:42.536151: Epoch time: 9.87 s 
2024-12-08 09:19:43.207845:  
2024-12-08 09:19:43.212907: Epoch 92 
2024-12-08 09:19:43.216474: Current learning rate: 0.00103 
2024-12-08 09:19:53.097475: train_loss -0.982 
2024-12-08 09:19:53.103598: val_loss -0.7075 
2024-12-08 09:19:53.107144: Pseudo dice [np.float32(0.8686), np.float32(0.8505)] 
2024-12-08 09:19:53.110244: Epoch time: 9.89 s 
2024-12-08 09:19:53.922187:  
2024-12-08 09:19:53.927273: Epoch 93 
2024-12-08 09:19:53.930863: Current learning rate: 0.00091 
2024-12-08 09:20:03.800049: train_loss -0.982 
2024-12-08 09:20:03.806221: val_loss -0.7071 
2024-12-08 09:20:03.809780: Pseudo dice [np.float32(0.8698), np.float32(0.8506)] 
2024-12-08 09:20:03.813843: Epoch time: 9.88 s 
2024-12-08 09:20:04.490564:  
2024-12-08 09:20:04.496167: Epoch 94 
2024-12-08 09:20:04.499716: Current learning rate: 0.00079 
2024-12-08 09:20:14.346324: train_loss -0.982 
2024-12-08 09:20:14.353486: val_loss -0.7081 
2024-12-08 09:20:14.356543: Pseudo dice [np.float32(0.8699), np.float32(0.8517)] 
2024-12-08 09:20:14.360585: Epoch time: 9.86 s 
2024-12-08 09:20:15.028731:  
2024-12-08 09:20:15.034319: Epoch 95 
2024-12-08 09:20:15.036859: Current learning rate: 0.00067 
2024-12-08 09:20:24.939466: train_loss -0.9822 
2024-12-08 09:20:24.947100: val_loss -0.7066 
2024-12-08 09:20:24.950646: Pseudo dice [np.float32(0.8681), np.float32(0.8494)] 
2024-12-08 09:20:24.954184: Epoch time: 9.91 s 
2024-12-08 09:20:25.603163:  
2024-12-08 09:20:25.610283: Epoch 96 
2024-12-08 09:20:25.613341: Current learning rate: 0.00055 
2024-12-08 09:20:35.352133: train_loss -0.9823 
2024-12-08 09:20:35.357195: val_loss -0.7066 
2024-12-08 09:20:35.359737: Pseudo dice [np.float32(0.8694), np.float32(0.8502)] 
2024-12-08 09:20:35.364934: Epoch time: 9.75 s 
2024-12-08 09:20:36.046477:  
2024-12-08 09:20:36.051561: Epoch 97 
2024-12-08 09:20:36.055106: Current learning rate: 0.00043 
2024-12-08 09:20:45.946576: train_loss -0.9824 
2024-12-08 09:20:45.951685: val_loss -0.7108 
2024-12-08 09:20:45.956263: Pseudo dice [np.float32(0.8696), np.float32(0.8511)] 
2024-12-08 09:20:45.959320: Epoch time: 9.9 s 
2024-12-08 09:20:46.658400:  
2024-12-08 09:20:46.664004: Epoch 98 
2024-12-08 09:20:46.667092: Current learning rate: 0.0003 
2024-12-08 09:20:56.537438: train_loss -0.9823 
2024-12-08 09:20:56.543063: val_loss -0.7059 
2024-12-08 09:20:56.546699: Pseudo dice [np.float32(0.8694), np.float32(0.8492)] 
2024-12-08 09:20:56.550261: Epoch time: 9.88 s 
2024-12-08 09:20:57.246200:  
2024-12-08 09:20:57.251831: Epoch 99 
2024-12-08 09:20:57.256982: Current learning rate: 0.00016 
2024-12-08 09:21:08.448531: train_loss -0.9826 
2024-12-08 09:21:08.454120: val_loss -0.7081 
2024-12-08 09:21:08.456710: Pseudo dice [np.float32(0.8699), np.float32(0.8502)] 
2024-12-08 09:21:08.460761: Epoch time: 11.2 s 
2024-12-08 09:21:09.177369: Training done. 
2024-12-08 09:21:09.234685: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset004_Hippocampus\splits_final.json 
2024-12-08 09:21:09.242602: The split file contains 5 splits. 
2024-12-08 09:21:09.250999: Desired fold for training: 0 
2024-12-08 09:21:09.257054: This split has 208 training and 52 validation cases. 
2024-12-08 09:21:09.259062: predicting hippocampus_017 
2024-12-08 09:21:09.259062: hippocampus_017, shape torch.Size([1, 32, 48, 35]), rank 0 
2024-12-08 09:21:09.406596: predicting hippocampus_019 
2024-12-08 09:21:09.412606: hippocampus_019, shape torch.Size([1, 41, 47, 36]), rank 0 
2024-12-08 09:21:09.485093: predicting hippocampus_033 
2024-12-08 09:21:09.493160: hippocampus_033, shape torch.Size([1, 38, 48, 33]), rank 0 
2024-12-08 09:21:09.565631: predicting hippocampus_035 
2024-12-08 09:21:09.573719: hippocampus_035, shape torch.Size([1, 37, 47, 35]), rank 0 
2024-12-08 09:21:09.637962: predicting hippocampus_037 
2024-12-08 09:21:09.645988: hippocampus_037, shape torch.Size([1, 32, 51, 34]), rank 0 
2024-12-08 09:21:09.710581: predicting hippocampus_049 
2024-12-08 09:21:09.710581: hippocampus_049, shape torch.Size([1, 36, 51, 35]), rank 0 
2024-12-08 09:21:09.798907: predicting hippocampus_052 
2024-12-08 09:21:09.806921: hippocampus_052, shape torch.Size([1, 40, 52, 34]), rank 0 
2024-12-08 09:21:09.887333: predicting hippocampus_065 
2024-12-08 09:21:09.895517: hippocampus_065, shape torch.Size([1, 37, 52, 39]), rank 0 
2024-12-08 09:21:09.969200: predicting hippocampus_083 
2024-12-08 09:21:09.969200: hippocampus_083, shape torch.Size([1, 37, 52, 33]), rank 0 
2024-12-08 09:21:10.052290: predicting hippocampus_088 
2024-12-08 09:21:10.058500: hippocampus_088, shape torch.Size([1, 35, 52, 40]), rank 0 
2024-12-08 09:21:13.040782: predicting hippocampus_090 
2024-12-08 09:21:13.040782: hippocampus_090, shape torch.Size([1, 40, 50, 37]), rank 0 
2024-12-08 09:21:13.142229: predicting hippocampus_092 
2024-12-08 09:21:13.148238: hippocampus_092, shape torch.Size([1, 28, 49, 38]), rank 0 
2024-12-08 09:21:13.250466: predicting hippocampus_095 
2024-12-08 09:21:13.264492: hippocampus_095, shape torch.Size([1, 39, 49, 34]), rank 0 
2024-12-08 09:21:13.388487: predicting hippocampus_107 
2024-12-08 09:21:13.394498: hippocampus_107, shape torch.Size([1, 34, 55, 35]), rank 0 
2024-12-08 09:21:13.488726: predicting hippocampus_108 
2024-12-08 09:21:13.496743: hippocampus_108, shape torch.Size([1, 37, 53, 36]), rank 0 
2024-12-08 09:21:13.600860: predicting hippocampus_123 
2024-12-08 09:21:13.608873: hippocampus_123, shape torch.Size([1, 38, 53, 32]), rank 0 
2024-12-08 09:21:13.691012: predicting hippocampus_125 
2024-12-08 09:21:13.697020: hippocampus_125, shape torch.Size([1, 39, 42, 43]), rank 0 
2024-12-08 09:21:13.848925: predicting hippocampus_157 
2024-12-08 09:21:13.854932: hippocampus_157, shape torch.Size([1, 35, 51, 36]), rank 0 
2024-12-08 09:21:13.922493: predicting hippocampus_164 
2024-12-08 09:21:13.922493: hippocampus_164, shape torch.Size([1, 47, 48, 41]), rank 0 
2024-12-08 09:21:14.100195: predicting hippocampus_169 
2024-12-08 09:21:14.104201: hippocampus_169, shape torch.Size([1, 39, 45, 36]), rank 0 
2024-12-08 09:21:14.184040: predicting hippocampus_175 
2024-12-08 09:21:14.190048: hippocampus_175, shape torch.Size([1, 35, 47, 33]), rank 0 
2024-12-08 09:21:14.259607: predicting hippocampus_185 
2024-12-08 09:21:14.265891: hippocampus_185, shape torch.Size([1, 33, 49, 35]), rank 0 
2024-12-08 09:21:14.331775: predicting hippocampus_190 
2024-12-08 09:21:14.337786: hippocampus_190, shape torch.Size([1, 30, 52, 37]), rank 0 
2024-12-08 09:21:14.401601: predicting hippocampus_194 
2024-12-08 09:21:14.409616: hippocampus_194, shape torch.Size([1, 30, 50, 35]), rank 0 
2024-12-08 09:21:14.471474: predicting hippocampus_204 
2024-12-08 09:21:14.475478: hippocampus_204, shape torch.Size([1, 39, 48, 36]), rank 0 
2024-12-08 09:21:14.555316: predicting hippocampus_205 
2024-12-08 09:21:14.559321: hippocampus_205, shape torch.Size([1, 32, 47, 32]), rank 0 
2024-12-08 09:21:14.627397: predicting hippocampus_210 
2024-12-08 09:21:14.633406: hippocampus_210, shape torch.Size([1, 40, 48, 34]), rank 0 
2024-12-08 09:21:14.713518: predicting hippocampus_217 
2024-12-08 09:21:14.721805: hippocampus_217, shape torch.Size([1, 27, 53, 38]), rank 0 
2024-12-08 09:21:14.777860: predicting hippocampus_219 
2024-12-08 09:21:14.782263: hippocampus_219, shape torch.Size([1, 39, 45, 37]), rank 0 
2024-12-08 09:21:14.860384: predicting hippocampus_229 
2024-12-08 09:21:14.866391: hippocampus_229, shape torch.Size([1, 35, 50, 33]), rank 0 
2024-12-08 09:21:14.940476: predicting hippocampus_244 
2024-12-08 09:21:14.946483: hippocampus_244, shape torch.Size([1, 30, 53, 38]), rank 0 
2024-12-08 09:21:15.010640: predicting hippocampus_261 
2024-12-08 09:21:15.014800: hippocampus_261, shape torch.Size([1, 33, 58, 36]), rank 0 
2024-12-08 09:21:15.146699: predicting hippocampus_264 
2024-12-08 09:21:15.156707: hippocampus_264, shape torch.Size([1, 37, 51, 38]), rank 0 
2024-12-08 09:21:15.230699: predicting hippocampus_277 
2024-12-08 09:21:15.234703: hippocampus_277, shape torch.Size([1, 29, 59, 33]), rank 0 
2024-12-08 09:21:15.345054: predicting hippocampus_280 
2024-12-08 09:21:15.351064: hippocampus_280, shape torch.Size([1, 32, 47, 37]), rank 0 
2024-12-08 09:21:15.411202: predicting hippocampus_286 
2024-12-08 09:21:15.422355: hippocampus_286, shape torch.Size([1, 46, 45, 37]), rank 0 
2024-12-08 09:21:15.513286: predicting hippocampus_288 
2024-12-08 09:21:15.517293: hippocampus_288, shape torch.Size([1, 42, 50, 38]), rank 0 
2024-12-08 09:21:15.603141: predicting hippocampus_289 
2024-12-08 09:21:15.607149: hippocampus_289, shape torch.Size([1, 36, 49, 35]), rank 0 
2024-12-08 09:21:15.683609: predicting hippocampus_296 
2024-12-08 09:21:15.689048: hippocampus_296, shape torch.Size([1, 35, 54, 35]), rank 0 
2024-12-08 09:21:15.764295: predicting hippocampus_305 
2024-12-08 09:21:15.770622: hippocampus_305, shape torch.Size([1, 30, 49, 34]), rank 0 
2024-12-08 09:21:15.840455: predicting hippocampus_308 
2024-12-08 09:21:15.846465: hippocampus_308, shape torch.Size([1, 40, 48, 38]), rank 0 
2024-12-08 09:21:15.939826: predicting hippocampus_317 
2024-12-08 09:21:15.946221: hippocampus_317, shape torch.Size([1, 34, 51, 33]), rank 0 
2024-12-08 09:21:16.026345: predicting hippocampus_327 
2024-12-08 09:21:16.030350: hippocampus_327, shape torch.Size([1, 27, 54, 36]), rank 0 
2024-12-08 09:21:16.094659: predicting hippocampus_330 
2024-12-08 09:21:16.100405: hippocampus_330, shape torch.Size([1, 33, 55, 35]), rank 0 
2024-12-08 09:21:16.180060: predicting hippocampus_332 
2024-12-08 09:21:16.184064: hippocampus_332, shape torch.Size([1, 33, 52, 35]), rank 0 
2024-12-08 09:21:16.261888: predicting hippocampus_338 
2024-12-08 09:21:16.265892: hippocampus_338, shape torch.Size([1, 43, 43, 37]), rank 0 
2024-12-08 09:21:16.366001: predicting hippocampus_349 
2024-12-08 09:21:16.369905: hippocampus_349, shape torch.Size([1, 34, 50, 34]), rank 0 
2024-12-08 09:21:16.451745: predicting hippocampus_350 
2024-12-08 09:21:16.455749: hippocampus_350, shape torch.Size([1, 34, 49, 35]), rank 0 
2024-12-08 09:21:16.535555: predicting hippocampus_356 
2024-12-08 09:21:16.541562: hippocampus_356, shape torch.Size([1, 37, 51, 36]), rank 0 
2024-12-08 09:21:16.627411: predicting hippocampus_358 
2024-12-08 09:21:16.631415: hippocampus_358, shape torch.Size([1, 34, 50, 35]), rank 0 
2024-12-08 09:21:16.713459: predicting hippocampus_374 
2024-12-08 09:21:16.717464: hippocampus_374, shape torch.Size([1, 39, 48, 38]), rank 0 
2024-12-08 09:21:16.809560: predicting hippocampus_394 
2024-12-08 09:21:16.813567: hippocampus_394, shape torch.Size([1, 32, 52, 36]), rank 0 
2024-12-08 09:21:20.350132: Validation complete 
2024-12-08 09:21:20.358457: Mean Validation Dice:  0.8551005571581123 
