
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-11 03:45:47.147201: do_dummy_2d_data_aug: False 
2024-12-11 03:45:47.161388: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset008_HepaticVessel\splits_final.json 
2024-12-11 03:45:47.167455: The split file contains 5 splits. 
2024-12-11 03:45:47.170451: Desired fold for training: 0 
2024-12-11 03:45:47.173454: This split has 242 training and 61 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_avg_spacing_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [96, 160, 160], 'median_image_size_in_voxels': [115.0, 210.0, 210.0], 'spacing': [1.9500125156770838, 1.9500125156770838, 1.9500125156770838], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset008_HepaticVessel', 'plans_name': 'nnUNetPlans_avg_spacing', 'original_median_spacing_after_transp': [5.0, 0.7988280057907104, 0.7988280057907104], 'original_median_shape_after_transp': [49, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3072.0, 'mean': 128.6698455810547, 'median': 129.0, 'min': -726.0, 'percentile_00_5': 8.0, 'percentile_99_5': 268.0, 'std': 54.57704544067383}}} 
 
2024-12-11 03:46:18.616350: unpacking dataset... 
2024-12-11 03:46:22.972311: unpacking done... 
2024-12-11 03:46:27.020330:  
2024-12-11 03:46:27.024838: Epoch 0 
2024-12-11 03:46:27.027483: Current learning rate: 0.01 
2024-12-11 03:47:15.764157: train_loss 0.082 
2024-12-11 03:47:15.769716: val_loss 0.0149 
2024-12-11 03:47:15.772240: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-11 03:47:15.775760: Epoch time: 48.74 s 
2024-12-11 03:47:15.778127: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-11 03:47:16.418459:  
2024-12-11 03:47:16.423576: Epoch 1 
2024-12-11 03:47:16.426124: Current learning rate: 0.00991 
2024-12-11 03:48:00.702008: train_loss 0.0026 
2024-12-11 03:48:00.707117: val_loss -0.0313 
2024-12-11 03:48:00.710182: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-11 03:48:00.713686: Epoch time: 44.28 s 
2024-12-11 03:48:01.262586:  
2024-12-11 03:48:01.267706: Epoch 2 
2024-12-11 03:48:01.271269: Current learning rate: 0.00982 
2024-12-11 03:48:45.492328: train_loss -0.104 
2024-12-11 03:48:45.497537: val_loss -0.2192 
2024-12-11 03:48:45.501149: Pseudo dice [np.float32(0.4885), np.float32(0.2491)] 
2024-12-11 03:48:45.504190: Epoch time: 44.23 s 
2024-12-11 03:48:45.507273: Yayy! New best EMA pseudo Dice: 0.03689999878406525 
2024-12-11 03:48:46.260813:  
2024-12-11 03:48:46.267019: Epoch 3 
2024-12-11 03:48:46.270073: Current learning rate: 0.00973 
2024-12-11 03:49:30.451377: train_loss -0.2404 
2024-12-11 03:49:30.457477: val_loss -0.3349 
2024-12-11 03:49:30.460485: Pseudo dice [np.float32(0.5559), np.float32(0.4153)] 
2024-12-11 03:49:30.463632: Epoch time: 44.19 s 
2024-12-11 03:49:30.466137: Yayy! New best EMA pseudo Dice: 0.08179999887943268 
2024-12-11 03:49:31.191638:  
2024-12-11 03:49:31.197192: Epoch 4 
2024-12-11 03:49:31.201293: Current learning rate: 0.00964 
2024-12-11 03:50:15.379586: train_loss -0.2832 
2024-12-11 03:50:15.384742: val_loss -0.343 
2024-12-11 03:50:15.387778: Pseudo dice [np.float32(0.5572), np.float32(0.4047)] 
2024-12-11 03:50:15.390392: Epoch time: 44.19 s 
2024-12-11 03:50:15.393986: Yayy! New best EMA pseudo Dice: 0.1216999962925911 
2024-12-11 03:50:16.260464:  
2024-12-11 03:50:16.266036: Epoch 5 
2024-12-11 03:50:16.270051: Current learning rate: 0.00955 
2024-12-11 03:51:00.457649: train_loss -0.3189 
2024-12-11 03:51:00.462264: val_loss -0.374 
2024-12-11 03:51:00.466291: Pseudo dice [np.float32(0.5656), np.float32(0.4982)] 
2024-12-11 03:51:00.469315: Epoch time: 44.2 s 
2024-12-11 03:51:00.472403: Yayy! New best EMA pseudo Dice: 0.16269999742507935 
2024-12-11 03:51:01.175698:  
2024-12-11 03:51:01.181798: Epoch 6 
2024-12-11 03:51:01.184901: Current learning rate: 0.00946 
2024-12-11 03:51:45.373189: train_loss -0.3384 
2024-12-11 03:51:45.378335: val_loss -0.4162 
2024-12-11 03:51:45.381868: Pseudo dice [np.float32(0.5884), np.float32(0.6025)] 
2024-12-11 03:51:45.384910: Epoch time: 44.2 s 
2024-12-11 03:51:45.387996: Yayy! New best EMA pseudo Dice: 0.20600000023841858 
2024-12-11 03:51:46.113330:  
2024-12-11 03:51:46.118922: Epoch 7 
2024-12-11 03:51:46.122436: Current learning rate: 0.00937 
2024-12-11 03:52:30.319835: train_loss -0.3802 
2024-12-11 03:52:30.324846: val_loss -0.4818 
2024-12-11 03:52:30.328858: Pseudo dice [np.float32(0.5837), np.float32(0.665)] 
2024-12-11 03:52:30.331363: Epoch time: 44.21 s 
2024-12-11 03:52:30.334872: Yayy! New best EMA pseudo Dice: 0.24779999256134033 
2024-12-11 03:52:31.067234:  
2024-12-11 03:52:31.072868: Epoch 8 
2024-12-11 03:52:31.076374: Current learning rate: 0.00928 
2024-12-11 03:53:15.288770: train_loss -0.378 
2024-12-11 03:53:15.293782: val_loss -0.4492 
2024-12-11 03:53:15.296791: Pseudo dice [np.float32(0.5802), np.float32(0.6282)] 
2024-12-11 03:53:15.299434: Epoch time: 44.22 s 
2024-12-11 03:53:15.303475: Yayy! New best EMA pseudo Dice: 0.28349998593330383 
2024-12-11 03:53:16.041843:  
2024-12-11 03:53:16.047507: Epoch 9 
2024-12-11 03:53:16.050572: Current learning rate: 0.00919 
2024-12-11 03:54:00.306584: train_loss -0.4063 
2024-12-11 03:54:00.311713: val_loss -0.4478 
2024-12-11 03:54:00.314268: Pseudo dice [np.float32(0.5764), np.float32(0.641)] 
2024-12-11 03:54:00.317444: Epoch time: 44.27 s 
2024-12-11 03:54:00.320562: Yayy! New best EMA pseudo Dice: 0.3160000145435333 
2024-12-11 03:54:01.042993:  
2024-12-11 03:54:01.048535: Epoch 10 
2024-12-11 03:54:01.052132: Current learning rate: 0.0091 
2024-12-11 03:54:45.241035: train_loss -0.4216 
2024-12-11 03:54:45.246614: val_loss -0.4971 
2024-12-11 03:54:45.250200: Pseudo dice [np.float32(0.6004), np.float32(0.7332)] 
2024-12-11 03:54:45.253778: Epoch time: 44.2 s 
2024-12-11 03:54:45.256857: Yayy! New best EMA pseudo Dice: 0.35109999775886536 
2024-12-11 03:54:45.968596:  
2024-12-11 03:54:45.973783: Epoch 11 
2024-12-11 03:54:45.977295: Current learning rate: 0.009 
2024-12-11 03:55:30.145725: train_loss -0.4321 
2024-12-11 03:55:30.151369: val_loss -0.508 
2024-12-11 03:55:30.154981: Pseudo dice [np.float32(0.614), np.float32(0.7033)] 
2024-12-11 03:55:30.157506: Epoch time: 44.18 s 
2024-12-11 03:55:30.161290: Yayy! New best EMA pseudo Dice: 0.38179999589920044 
2024-12-11 03:55:30.881578:  
2024-12-11 03:55:30.886704: Epoch 12 
2024-12-11 03:55:30.890309: Current learning rate: 0.00891 
2024-12-11 03:56:15.064232: train_loss -0.4461 
2024-12-11 03:56:15.070252: val_loss -0.4767 
2024-12-11 03:56:15.073761: Pseudo dice [np.float32(0.616), np.float32(0.6721)] 
2024-12-11 03:56:15.076841: Epoch time: 44.18 s 
2024-12-11 03:56:15.079348: Yayy! New best EMA pseudo Dice: 0.40799999237060547 
2024-12-11 03:56:15.961242:  
2024-12-11 03:56:15.966325: Epoch 13 
2024-12-11 03:56:15.969907: Current learning rate: 0.00882 
2024-12-11 03:57:00.191444: train_loss -0.4625 
2024-12-11 03:57:00.198691: val_loss -0.4835 
2024-12-11 03:57:00.203369: Pseudo dice [np.float32(0.5715), np.float32(0.6831)] 
2024-12-11 03:57:00.206429: Epoch time: 44.23 s 
2024-12-11 03:57:00.209562: Yayy! New best EMA pseudo Dice: 0.4300000071525574 
2024-12-11 03:57:00.953997:  
2024-12-11 03:57:00.959530: Epoch 14 
2024-12-11 03:57:00.963109: Current learning rate: 0.00873 
2024-12-11 03:57:45.136987: train_loss -0.4491 
2024-12-11 03:57:45.142113: val_loss -0.5311 
2024-12-11 03:57:45.145199: Pseudo dice [np.float32(0.6096), np.float32(0.731)] 
2024-12-11 03:57:45.147709: Epoch time: 44.18 s 
2024-12-11 03:57:45.151836: Yayy! New best EMA pseudo Dice: 0.45399999618530273 
2024-12-11 03:57:45.882563:  
2024-12-11 03:57:45.888177: Epoch 15 
2024-12-11 03:57:45.891745: Current learning rate: 0.00864 
2024-12-11 03:58:30.045170: train_loss -0.4642 
2024-12-11 03:58:30.050292: val_loss -0.5089 
2024-12-11 03:58:30.053941: Pseudo dice [np.float32(0.5937), np.float32(0.7547)] 
2024-12-11 03:58:30.057724: Epoch time: 44.16 s 
2024-12-11 03:58:30.060790: Yayy! New best EMA pseudo Dice: 0.47600001096725464 
2024-12-11 03:58:30.798492:  
2024-12-11 03:58:30.805013: Epoch 16 
2024-12-11 03:58:30.807522: Current learning rate: 0.00855 
2024-12-11 03:59:14.995660: train_loss -0.4717 
2024-12-11 03:59:15.001804: val_loss -0.5309 
2024-12-11 03:59:15.004849: Pseudo dice [np.float32(0.6183), np.float32(0.6544)] 
2024-12-11 03:59:15.008488: Epoch time: 44.2 s 
2024-12-11 03:59:15.011037: Yayy! New best EMA pseudo Dice: 0.4921000003814697 
2024-12-11 03:59:15.757928:  
2024-12-11 03:59:15.763582: Epoch 17 
2024-12-11 03:59:15.767163: Current learning rate: 0.00846 
2024-12-11 03:59:59.958807: train_loss -0.4811 
2024-12-11 03:59:59.964428: val_loss -0.5329 
2024-12-11 03:59:59.967539: Pseudo dice [np.float32(0.6154), np.float32(0.7535)] 
2024-12-11 03:59:59.970649: Epoch time: 44.2 s 
2024-12-11 03:59:59.974277: Yayy! New best EMA pseudo Dice: 0.5113000273704529 
2024-12-11 04:00:00.733452:  
2024-12-11 04:00:00.739662: Epoch 18 
2024-12-11 04:00:00.742241: Current learning rate: 0.00836 
2024-12-11 04:00:44.865721: train_loss -0.467 
2024-12-11 04:00:44.871405: val_loss -0.5309 
2024-12-11 04:00:44.874424: Pseudo dice [np.float32(0.6271), np.float32(0.7071)] 
2024-12-11 04:00:44.877640: Epoch time: 44.13 s 
2024-12-11 04:00:44.880900: Yayy! New best EMA pseudo Dice: 0.5268999934196472 
2024-12-11 04:00:45.631160:  
2024-12-11 04:00:45.636721: Epoch 19 
2024-12-11 04:00:45.640318: Current learning rate: 0.00827 
2024-12-11 04:01:29.807598: train_loss -0.4817 
2024-12-11 04:01:29.814232: val_loss -0.5276 
2024-12-11 04:01:29.817331: Pseudo dice [np.float32(0.6002), np.float32(0.7509)] 
2024-12-11 04:01:29.819847: Epoch time: 44.18 s 
2024-12-11 04:01:29.822935: Yayy! New best EMA pseudo Dice: 0.541700005531311 
2024-12-11 04:01:30.559981:  
2024-12-11 04:01:30.566071: Epoch 20 
2024-12-11 04:01:30.571163: Current learning rate: 0.00818 
2024-12-11 04:02:15.160466: train_loss -0.4858 
2024-12-11 04:02:15.166110: val_loss -0.551 
2024-12-11 04:02:15.169804: Pseudo dice [np.float32(0.6209), np.float32(0.767)] 
2024-12-11 04:02:15.172863: Epoch time: 44.6 s 
2024-12-11 04:02:15.176435: Yayy! New best EMA pseudo Dice: 0.5569999814033508 
2024-12-11 04:02:16.081253:  
2024-12-11 04:02:16.087362: Epoch 21 
2024-12-11 04:02:16.090872: Current learning rate: 0.00809 
2024-12-11 04:03:00.269505: train_loss -0.4867 
2024-12-11 04:03:00.275174: val_loss -0.4782 
2024-12-11 04:03:00.278213: Pseudo dice [np.float32(0.591), np.float32(0.7007)] 
2024-12-11 04:03:00.281328: Epoch time: 44.19 s 
2024-12-11 04:03:00.284947: Yayy! New best EMA pseudo Dice: 0.5658000111579895 
2024-12-11 04:03:00.993693:  
2024-12-11 04:03:01.000281: Epoch 22 
2024-12-11 04:03:01.003792: Current learning rate: 0.008 
2024-12-11 04:03:45.142880: train_loss -0.4886 
2024-12-11 04:03:45.148468: val_loss -0.516 
2024-12-11 04:03:45.154108: Pseudo dice [np.float32(0.6194), np.float32(0.6844)] 
2024-12-11 04:03:45.157274: Epoch time: 44.15 s 
2024-12-11 04:03:45.161313: Yayy! New best EMA pseudo Dice: 0.574400007724762 
2024-12-11 04:03:45.875489:  
2024-12-11 04:03:45.880501: Epoch 23 
2024-12-11 04:03:45.883759: Current learning rate: 0.0079 
2024-12-11 04:04:30.003232: train_loss -0.4913 
2024-12-11 04:04:30.009842: val_loss -0.5475 
2024-12-11 04:04:30.012348: Pseudo dice [np.float32(0.6235), np.float32(0.7621)] 
2024-12-11 04:04:30.016445: Epoch time: 44.13 s 
2024-12-11 04:04:30.019852: Yayy! New best EMA pseudo Dice: 0.5863000154495239 
2024-12-11 04:04:30.731894:  
2024-12-11 04:04:30.737432: Epoch 24 
2024-12-11 04:04:30.742003: Current learning rate: 0.00781 
2024-12-11 04:05:14.970106: train_loss -0.5128 
2024-12-11 04:05:14.976481: val_loss -0.5443 
2024-12-11 04:05:14.979990: Pseudo dice [np.float32(0.616), np.float32(0.7955)] 
2024-12-11 04:05:14.983998: Epoch time: 44.24 s 
2024-12-11 04:05:14.986503: Yayy! New best EMA pseudo Dice: 0.5982000231742859 
2024-12-11 04:05:15.720458:  
2024-12-11 04:05:15.726083: Epoch 25 
2024-12-11 04:05:15.730295: Current learning rate: 0.00772 
2024-12-11 04:05:59.878527: train_loss -0.5027 
2024-12-11 04:05:59.884179: val_loss -0.5228 
2024-12-11 04:05:59.887847: Pseudo dice [np.float32(0.5899), np.float32(0.7631)] 
2024-12-11 04:05:59.891412: Epoch time: 44.16 s 
2024-12-11 04:05:59.896606: Yayy! New best EMA pseudo Dice: 0.6061000227928162 
2024-12-11 04:06:00.629595:  
2024-12-11 04:06:00.633722: Epoch 26 
2024-12-11 04:06:00.638387: Current learning rate: 0.00763 
2024-12-11 04:06:44.845480: train_loss -0.5011 
2024-12-11 04:06:44.852091: val_loss -0.5264 
2024-12-11 04:06:44.855099: Pseudo dice [np.float32(0.6279), np.float32(0.709)] 
2024-12-11 04:06:44.858607: Epoch time: 44.22 s 
2024-12-11 04:06:44.862616: Yayy! New best EMA pseudo Dice: 0.6122999787330627 
2024-12-11 04:06:45.589176:  
2024-12-11 04:06:45.594226: Epoch 27 
2024-12-11 04:06:45.597889: Current learning rate: 0.00753 
2024-12-11 04:07:29.862877: train_loss -0.5252 
2024-12-11 04:07:29.868949: val_loss -0.5063 
2024-12-11 04:07:29.871983: Pseudo dice [np.float32(0.6247), np.float32(0.7515)] 
2024-12-11 04:07:29.875110: Epoch time: 44.27 s 
2024-12-11 04:07:29.878670: Yayy! New best EMA pseudo Dice: 0.6198999881744385 
2024-12-11 04:07:30.616243:  
2024-12-11 04:07:30.622301: Epoch 28 
2024-12-11 04:07:30.625849: Current learning rate: 0.00744 
2024-12-11 04:08:14.933531: train_loss -0.5075 
2024-12-11 04:08:14.938543: val_loss -0.5248 
2024-12-11 04:08:14.943054: Pseudo dice [np.float32(0.6315), np.float32(0.7425)] 
2024-12-11 04:08:14.946065: Epoch time: 44.32 s 
2024-12-11 04:08:14.949575: Yayy! New best EMA pseudo Dice: 0.6266000270843506 
2024-12-11 04:08:15.666114:  
2024-12-11 04:08:15.671672: Epoch 29 
2024-12-11 04:08:15.675793: Current learning rate: 0.00735 
2024-12-11 04:08:59.871157: train_loss -0.5221 
2024-12-11 04:08:59.876711: val_loss -0.5249 
2024-12-11 04:08:59.879741: Pseudo dice [np.float32(0.6323), np.float32(0.7561)] 
2024-12-11 04:08:59.883772: Epoch time: 44.21 s 
2024-12-11 04:08:59.886802: Yayy! New best EMA pseudo Dice: 0.633400022983551 
2024-12-11 04:09:00.623312:  
2024-12-11 04:09:00.629415: Epoch 30 
2024-12-11 04:09:00.634517: Current learning rate: 0.00725 
2024-12-11 04:09:44.866313: train_loss -0.5237 
2024-12-11 04:09:44.872468: val_loss -0.5195 
2024-12-11 04:09:44.875501: Pseudo dice [np.float32(0.5891), np.float32(0.6964)] 
2024-12-11 04:09:44.879039: Epoch time: 44.24 s 
2024-12-11 04:09:44.882590: Yayy! New best EMA pseudo Dice: 0.6342999935150146 
2024-12-11 04:09:45.612131:  
2024-12-11 04:09:45.617193: Epoch 31 
2024-12-11 04:09:45.621246: Current learning rate: 0.00716 
2024-12-11 04:10:29.833704: train_loss -0.5163 
2024-12-11 04:10:29.839321: val_loss -0.5369 
2024-12-11 04:10:29.842871: Pseudo dice [np.float32(0.6145), np.float32(0.7693)] 
2024-12-11 04:10:29.846583: Epoch time: 44.22 s 
2024-12-11 04:10:29.849658: Yayy! New best EMA pseudo Dice: 0.6401000022888184 
2024-12-11 04:10:30.576679:  
2024-12-11 04:10:30.582247: Epoch 32 
2024-12-11 04:10:30.586299: Current learning rate: 0.00707 
2024-12-11 04:11:14.811796: train_loss -0.5289 
2024-12-11 04:11:14.817865: val_loss -0.5206 
2024-12-11 04:11:14.821374: Pseudo dice [np.float32(0.6148), np.float32(0.733)] 
2024-12-11 04:11:14.824881: Epoch time: 44.24 s 
2024-12-11 04:11:14.828111: Yayy! New best EMA pseudo Dice: 0.6434000134468079 
2024-12-11 04:11:15.563780:  
2024-12-11 04:11:15.569847: Epoch 33 
2024-12-11 04:11:15.572890: Current learning rate: 0.00697 
2024-12-11 04:11:59.801478: train_loss -0.5464 
2024-12-11 04:11:59.807603: val_loss -0.5648 
2024-12-11 04:11:59.811153: Pseudo dice [np.float32(0.6352), np.float32(0.7436)] 
2024-12-11 04:11:59.814760: Epoch time: 44.24 s 
2024-12-11 04:11:59.817828: Yayy! New best EMA pseudo Dice: 0.6480000019073486 
2024-12-11 04:12:00.551641:  
2024-12-11 04:12:00.557655: Epoch 34 
2024-12-11 04:12:00.561164: Current learning rate: 0.00688 
2024-12-11 04:12:44.781668: train_loss -0.5365 
2024-12-11 04:12:44.787230: val_loss -0.5317 
2024-12-11 04:12:44.791740: Pseudo dice [np.float32(0.6166), np.float32(0.753)] 
2024-12-11 04:12:44.794752: Epoch time: 44.23 s 
2024-12-11 04:12:44.798261: Yayy! New best EMA pseudo Dice: 0.6517000198364258 
2024-12-11 04:12:45.526243:  
2024-12-11 04:12:45.531772: Epoch 35 
2024-12-11 04:12:45.535307: Current learning rate: 0.00679 
2024-12-11 04:13:29.772868: train_loss -0.5466 
2024-12-11 04:13:29.778427: val_loss -0.56 
2024-12-11 04:13:29.782003: Pseudo dice [np.float32(0.6052), np.float32(0.7783)] 
2024-12-11 04:13:29.785679: Epoch time: 44.25 s 
2024-12-11 04:13:29.788755: Yayy! New best EMA pseudo Dice: 0.6557000279426575 
2024-12-11 04:13:30.662642:  
2024-12-11 04:13:30.666683: Epoch 36 
2024-12-11 04:13:30.670745: Current learning rate: 0.00669 
2024-12-11 04:14:14.860972: train_loss -0.56 
2024-12-11 04:14:14.866017: val_loss -0.5643 
2024-12-11 04:14:14.870059: Pseudo dice [np.float32(0.6411), np.float32(0.7826)] 
2024-12-11 04:14:14.873701: Epoch time: 44.2 s 
2024-12-11 04:14:14.877207: Yayy! New best EMA pseudo Dice: 0.661300003528595 
2024-12-11 04:14:15.634821:  
2024-12-11 04:14:15.642365: Epoch 37 
2024-12-11 04:14:15.647377: Current learning rate: 0.0066 
2024-12-11 04:14:59.857167: train_loss -0.5517 
2024-12-11 04:14:59.862265: val_loss -0.5496 
2024-12-11 04:14:59.866287: Pseudo dice [np.float32(0.6449), np.float32(0.7361)] 
2024-12-11 04:14:59.869819: Epoch time: 44.22 s 
2024-12-11 04:14:59.873328: Yayy! New best EMA pseudo Dice: 0.6642000079154968 
2024-12-11 04:15:00.650568:  
2024-12-11 04:15:00.657158: Epoch 38 
2024-12-11 04:15:00.660208: Current learning rate: 0.0065 
2024-12-11 04:15:44.896752: train_loss -0.5547 
2024-12-11 04:15:44.904217: val_loss -0.5847 
2024-12-11 04:15:44.906723: Pseudo dice [np.float32(0.6404), np.float32(0.7816)] 
2024-12-11 04:15:44.909768: Epoch time: 44.25 s 
2024-12-11 04:15:44.914300: Yayy! New best EMA pseudo Dice: 0.6689000129699707 
2024-12-11 04:15:45.658783:  
2024-12-11 04:15:45.664859: Epoch 39 
2024-12-11 04:15:45.668905: Current learning rate: 0.00641 
2024-12-11 04:16:29.867192: train_loss -0.5582 
2024-12-11 04:16:29.873351: val_loss -0.5552 
2024-12-11 04:16:29.876914: Pseudo dice [np.float32(0.6271), np.float32(0.7654)] 
2024-12-11 04:16:29.880460: Epoch time: 44.21 s 
2024-12-11 04:16:29.883573: Yayy! New best EMA pseudo Dice: 0.6717000007629395 
2024-12-11 04:16:30.630005:  
2024-12-11 04:16:30.636563: Epoch 40 
2024-12-11 04:16:30.640093: Current learning rate: 0.00631 
2024-12-11 04:17:14.831166: train_loss -0.5642 
2024-12-11 04:17:14.837215: val_loss -0.5678 
2024-12-11 04:17:14.841202: Pseudo dice [np.float32(0.609), np.float32(0.7979)] 
2024-12-11 04:17:14.844717: Epoch time: 44.2 s 
2024-12-11 04:17:14.847728: Yayy! New best EMA pseudo Dice: 0.6747999787330627 
2024-12-11 04:17:15.615904:  
2024-12-11 04:17:15.621462: Epoch 41 
2024-12-11 04:17:15.624477: Current learning rate: 0.00622 
2024-12-11 04:17:59.856491: train_loss -0.5373 
2024-12-11 04:17:59.862506: val_loss -0.5553 
2024-12-11 04:17:59.866516: Pseudo dice [np.float32(0.6471), np.float32(0.7245)] 
2024-12-11 04:17:59.870027: Epoch time: 44.24 s 
2024-12-11 04:17:59.873534: Yayy! New best EMA pseudo Dice: 0.6758999824523926 
2024-12-11 04:18:00.599328:  
2024-12-11 04:18:00.604912: Epoch 42 
2024-12-11 04:18:00.609059: Current learning rate: 0.00612 
2024-12-11 04:18:44.812382: train_loss -0.5695 
2024-12-11 04:18:44.818470: val_loss -0.5482 
2024-12-11 04:18:44.821985: Pseudo dice [np.float32(0.6323), np.float32(0.7211)] 
2024-12-11 04:18:44.825027: Epoch time: 44.21 s 
2024-12-11 04:18:44.829174: Yayy! New best EMA pseudo Dice: 0.6759999990463257 
2024-12-11 04:18:45.548570:  
2024-12-11 04:18:45.552613: Epoch 43 
2024-12-11 04:18:45.556678: Current learning rate: 0.00603 
2024-12-11 04:19:29.787850: train_loss -0.5487 
2024-12-11 04:19:29.793510: val_loss -0.5655 
2024-12-11 04:19:29.797539: Pseudo dice [np.float32(0.6183), np.float32(0.7682)] 
2024-12-11 04:19:29.801089: Epoch time: 44.24 s 
2024-12-11 04:19:29.805099: Yayy! New best EMA pseudo Dice: 0.6776999831199646 
2024-12-11 04:19:30.699720:  
2024-12-11 04:19:30.705787: Epoch 44 
2024-12-11 04:19:30.709321: Current learning rate: 0.00593 
2024-12-11 04:20:14.955863: train_loss -0.5556 
2024-12-11 04:20:14.961927: val_loss -0.5323 
2024-12-11 04:20:14.966947: Pseudo dice [np.float32(0.603), np.float32(0.7359)] 
2024-12-11 04:20:14.970456: Epoch time: 44.26 s 
2024-12-11 04:20:15.512554:  
2024-12-11 04:20:15.518125: Epoch 45 
2024-12-11 04:20:15.522166: Current learning rate: 0.00584 
2024-12-11 04:20:59.752128: train_loss -0.568 
2024-12-11 04:20:59.758707: val_loss -0.5768 
2024-12-11 04:20:59.762764: Pseudo dice [np.float32(0.6485), np.float32(0.7993)] 
2024-12-11 04:20:59.766280: Epoch time: 44.24 s 
2024-12-11 04:20:59.769305: Yayy! New best EMA pseudo Dice: 0.6815999746322632 
2024-12-11 04:21:00.489766:  
2024-12-11 04:21:00.495333: Epoch 46 
2024-12-11 04:21:00.497955: Current learning rate: 0.00574 
2024-12-11 04:21:44.699235: train_loss -0.5638 
2024-12-11 04:21:44.704247: val_loss -0.5584 
2024-12-11 04:21:44.707758: Pseudo dice [np.float32(0.6441), np.float32(0.7686)] 
2024-12-11 04:21:44.710264: Epoch time: 44.21 s 
2024-12-11 04:21:44.713769: Yayy! New best EMA pseudo Dice: 0.6840999722480774 
2024-12-11 04:21:45.428707:  
2024-12-11 04:21:45.434244: Epoch 47 
2024-12-11 04:21:45.437754: Current learning rate: 0.00565 
2024-12-11 04:22:29.634345: train_loss -0.5562 
2024-12-11 04:22:29.639356: val_loss -0.5708 
2024-12-11 04:22:29.642882: Pseudo dice [np.float32(0.6373), np.float32(0.7444)] 
2024-12-11 04:22:29.645914: Epoch time: 44.21 s 
2024-12-11 04:22:29.648421: Yayy! New best EMA pseudo Dice: 0.6848000288009644 
2024-12-11 04:22:30.364107:  
2024-12-11 04:22:30.369263: Epoch 48 
2024-12-11 04:22:30.372304: Current learning rate: 0.00555 
2024-12-11 04:23:14.596269: train_loss -0.5442 
2024-12-11 04:23:14.601274: val_loss -0.558 
2024-12-11 04:23:14.604790: Pseudo dice [np.float32(0.631), np.float32(0.7226)] 
2024-12-11 04:23:14.607820: Epoch time: 44.23 s 
2024-12-11 04:23:15.160672:  
2024-12-11 04:23:15.165724: Epoch 49 
2024-12-11 04:23:15.168749: Current learning rate: 0.00546 
2024-12-11 04:23:59.430166: train_loss -0.5535 
2024-12-11 04:23:59.435699: val_loss -0.5235 
2024-12-11 04:23:59.438714: Pseudo dice [np.float32(0.6285), np.float32(0.6969)] 
2024-12-11 04:23:59.442240: Epoch time: 44.27 s 
2024-12-11 04:24:00.143534:  
2024-12-11 04:24:00.149654: Epoch 50 
2024-12-11 04:24:00.152694: Current learning rate: 0.00536 
2024-12-11 04:24:44.367607: train_loss -0.5655 
2024-12-11 04:24:44.372654: val_loss -0.5404 
2024-12-11 04:24:44.376197: Pseudo dice [np.float32(0.6393), np.float32(0.7123)] 
2024-12-11 04:24:44.378704: Epoch time: 44.22 s 
2024-12-11 04:24:44.923234:  
2024-12-11 04:24:44.927919: Epoch 51 
2024-12-11 04:24:44.931939: Current learning rate: 0.00526 
2024-12-11 04:25:29.148673: train_loss -0.5649 
2024-12-11 04:25:29.154693: val_loss -0.587 
2024-12-11 04:25:29.158283: Pseudo dice [np.float32(0.6203), np.float32(0.8016)] 
2024-12-11 04:25:29.161303: Epoch time: 44.23 s 
2024-12-11 04:25:29.874371:  
2024-12-11 04:25:29.879884: Epoch 52 
2024-12-11 04:25:29.882391: Current learning rate: 0.00517 
2024-12-11 04:26:14.119703: train_loss -0.569 
2024-12-11 04:26:14.125713: val_loss -0.5794 
2024-12-11 04:26:14.128724: Pseudo dice [np.float32(0.6313), np.float32(0.7749)] 
2024-12-11 04:26:14.131233: Epoch time: 44.25 s 
2024-12-11 04:26:14.134744: Yayy! New best EMA pseudo Dice: 0.6861000061035156 
2024-12-11 04:26:14.854802:  
2024-12-11 04:26:14.859840: Epoch 53 
2024-12-11 04:26:14.862873: Current learning rate: 0.00507 
2024-12-11 04:26:59.097976: train_loss -0.5865 
2024-12-11 04:26:59.103504: val_loss -0.6119 
2024-12-11 04:26:59.107013: Pseudo dice [np.float32(0.6405), np.float32(0.827)] 
2024-12-11 04:26:59.110021: Epoch time: 44.24 s 
2024-12-11 04:26:59.112526: Yayy! New best EMA pseudo Dice: 0.6909000277519226 
2024-12-11 04:26:59.833192:  
2024-12-11 04:26:59.838748: Epoch 54 
2024-12-11 04:26:59.841257: Current learning rate: 0.00497 
2024-12-11 04:27:44.062837: train_loss -0.5648 
2024-12-11 04:27:44.068359: val_loss -0.548 
2024-12-11 04:27:44.071892: Pseudo dice [np.float32(0.6324), np.float32(0.7304)] 
2024-12-11 04:27:44.074399: Epoch time: 44.23 s 
2024-12-11 04:27:44.631327:  
2024-12-11 04:27:44.636415: Epoch 55 
2024-12-11 04:27:44.639735: Current learning rate: 0.00487 
2024-12-11 04:28:28.853792: train_loss -0.5851 
2024-12-11 04:28:28.859349: val_loss -0.5576 
2024-12-11 04:28:28.862860: Pseudo dice [np.float32(0.6209), np.float32(0.78)] 
2024-12-11 04:28:28.865369: Epoch time: 44.22 s 
2024-12-11 04:28:28.868874: Yayy! New best EMA pseudo Dice: 0.6909999847412109 
2024-12-11 04:28:29.584678:  
2024-12-11 04:28:29.590191: Epoch 56 
2024-12-11 04:28:29.593287: Current learning rate: 0.00478 
2024-12-11 04:29:13.824633: train_loss -0.5708 
2024-12-11 04:29:13.829662: val_loss -0.573 
2024-12-11 04:29:13.833176: Pseudo dice [np.float32(0.6464), np.float32(0.799)] 
2024-12-11 04:29:13.836185: Epoch time: 44.24 s 
2024-12-11 04:29:13.839208: Yayy! New best EMA pseudo Dice: 0.694100022315979 
2024-12-11 04:29:14.583470:  
2024-12-11 04:29:14.589028: Epoch 57 
2024-12-11 04:29:14.592605: Current learning rate: 0.00468 
2024-12-11 04:29:58.783543: train_loss -0.5839 
2024-12-11 04:29:58.789639: val_loss -0.5638 
2024-12-11 04:29:58.792697: Pseudo dice [np.float32(0.6171), np.float32(0.7307)] 
2024-12-11 04:29:58.796270: Epoch time: 44.2 s 
2024-12-11 04:29:59.367264:  
2024-12-11 04:29:59.372868: Epoch 58 
2024-12-11 04:29:59.375889: Current learning rate: 0.00458 
2024-12-11 04:30:43.579698: train_loss -0.5919 
2024-12-11 04:30:43.586275: val_loss -0.5937 
2024-12-11 04:30:43.589347: Pseudo dice [np.float32(0.6411), np.float32(0.7843)] 
2024-12-11 04:30:43.592903: Epoch time: 44.21 s 
2024-12-11 04:30:43.595954: Yayy! New best EMA pseudo Dice: 0.6941999793052673 
2024-12-11 04:30:44.486414:  
2024-12-11 04:30:44.491458: Epoch 59 
2024-12-11 04:30:44.494501: Current learning rate: 0.00448 
2024-12-11 04:31:28.670541: train_loss -0.5947 
2024-12-11 04:31:28.676609: val_loss -0.5678 
2024-12-11 04:31:28.680141: Pseudo dice [np.float32(0.6353), np.float32(0.7937)] 
2024-12-11 04:31:28.683183: Epoch time: 44.18 s 
2024-12-11 04:31:28.686220: Yayy! New best EMA pseudo Dice: 0.6962000131607056 
2024-12-11 04:31:29.424511:  
2024-12-11 04:31:29.429565: Epoch 60 
2024-12-11 04:31:29.432574: Current learning rate: 0.00438 
2024-12-11 04:32:13.656475: train_loss -0.5951 
2024-12-11 04:32:13.662031: val_loss -0.5847 
2024-12-11 04:32:13.665541: Pseudo dice [np.float32(0.6367), np.float32(0.8252)] 
2024-12-11 04:32:13.669047: Epoch time: 44.23 s 
2024-12-11 04:32:13.672094: Yayy! New best EMA pseudo Dice: 0.6996999979019165 
2024-12-11 04:32:14.395366:  
2024-12-11 04:32:14.399874: Epoch 61 
2024-12-11 04:32:14.402889: Current learning rate: 0.00429 
2024-12-11 04:32:58.617321: train_loss -0.5933 
2024-12-11 04:32:58.622856: val_loss -0.6121 
2024-12-11 04:32:58.626452: Pseudo dice [np.float32(0.6488), np.float32(0.8363)] 
2024-12-11 04:32:58.629957: Epoch time: 44.22 s 
2024-12-11 04:32:58.632970: Yayy! New best EMA pseudo Dice: 0.7039999961853027 
2024-12-11 04:32:59.379728:  
2024-12-11 04:32:59.385304: Epoch 62 
2024-12-11 04:32:59.388905: Current learning rate: 0.00419 
2024-12-11 04:33:43.581551: train_loss -0.5975 
2024-12-11 04:33:43.587200: val_loss -0.5707 
2024-12-11 04:33:43.589720: Pseudo dice [np.float32(0.643), np.float32(0.7896)] 
2024-12-11 04:33:43.593282: Epoch time: 44.2 s 
2024-12-11 04:33:43.596310: Yayy! New best EMA pseudo Dice: 0.7052000164985657 
2024-12-11 04:33:44.322436:  
2024-12-11 04:33:44.327456: Epoch 63 
2024-12-11 04:33:44.330484: Current learning rate: 0.00409 
2024-12-11 04:34:28.528469: train_loss -0.6125 
2024-12-11 04:34:28.533496: val_loss -0.5983 
2024-12-11 04:34:28.537054: Pseudo dice [np.float32(0.6463), np.float32(0.862)] 
2024-12-11 04:34:28.540256: Epoch time: 44.21 s 
2024-12-11 04:34:28.544825: Yayy! New best EMA pseudo Dice: 0.710099995136261 
2024-12-11 04:34:29.299525:  
2024-12-11 04:34:29.304056: Epoch 64 
2024-12-11 04:34:29.307095: Current learning rate: 0.00399 
2024-12-11 04:35:13.507865: train_loss -0.6009 
2024-12-11 04:35:13.514469: val_loss -0.5616 
2024-12-11 04:35:13.517503: Pseudo dice [np.float32(0.6143), np.float32(0.8059)] 
2024-12-11 04:35:13.520542: Epoch time: 44.21 s 
2024-12-11 04:35:13.523628: Yayy! New best EMA pseudo Dice: 0.710099995136261 
2024-12-11 04:35:14.264049:  
2024-12-11 04:35:14.270119: Epoch 65 
2024-12-11 04:35:14.272126: Current learning rate: 0.00389 
2024-12-11 04:35:58.474004: train_loss -0.6001 
2024-12-11 04:35:58.479830: val_loss -0.5909 
2024-12-11 04:35:58.482865: Pseudo dice [np.float32(0.6199), np.float32(0.8347)] 
2024-12-11 04:35:58.485399: Epoch time: 44.21 s 
2024-12-11 04:35:58.488926: Yayy! New best EMA pseudo Dice: 0.7117999792098999 
2024-12-11 04:35:59.216375:  
2024-12-11 04:35:59.221390: Epoch 66 
2024-12-11 04:35:59.224904: Current learning rate: 0.00379 
2024-12-11 04:36:43.452466: train_loss -0.6114 
2024-12-11 04:36:43.459503: val_loss -0.5913 
2024-12-11 04:36:43.462566: Pseudo dice [np.float32(0.6423), np.float32(0.823)] 
2024-12-11 04:36:43.466095: Epoch time: 44.24 s 
2024-12-11 04:36:43.469135: Yayy! New best EMA pseudo Dice: 0.7139000296592712 
2024-12-11 04:36:44.351056:  
2024-12-11 04:36:44.356100: Epoch 67 
2024-12-11 04:36:44.359614: Current learning rate: 0.00369 
2024-12-11 04:37:28.595891: train_loss -0.6041 
2024-12-11 04:37:28.599977: val_loss -0.5992 
2024-12-11 04:37:28.604523: Pseudo dice [np.float32(0.6292), np.float32(0.7221)] 
2024-12-11 04:37:28.607085: Epoch time: 44.25 s 
2024-12-11 04:37:29.191024:  
2024-12-11 04:37:29.197548: Epoch 68 
2024-12-11 04:37:29.201051: Current learning rate: 0.00359 
2024-12-11 04:38:13.410091: train_loss -0.6123 
2024-12-11 04:38:13.415690: val_loss -0.5748 
2024-12-11 04:38:13.419261: Pseudo dice [np.float32(0.6258), np.float32(0.8267)] 
2024-12-11 04:38:13.421348: Epoch time: 44.22 s 
2024-12-11 04:38:14.000571:  
2024-12-11 04:38:14.006164: Epoch 69 
2024-12-11 04:38:14.009217: Current learning rate: 0.00349 
2024-12-11 04:38:58.207872: train_loss -0.6129 
2024-12-11 04:38:58.213406: val_loss -0.5994 
2024-12-11 04:38:58.215422: Pseudo dice [np.float32(0.6184), np.float32(0.8422)] 
2024-12-11 04:38:58.218974: Epoch time: 44.21 s 
2024-12-11 04:38:58.786835:  
2024-12-11 04:38:58.792092: Epoch 70 
2024-12-11 04:38:58.795643: Current learning rate: 0.00338 
2024-12-11 04:39:42.951167: train_loss -0.6152 
2024-12-11 04:39:42.956177: val_loss -0.5624 
2024-12-11 04:39:42.960187: Pseudo dice [np.float32(0.6196), np.float32(0.8093)] 
2024-12-11 04:39:42.963694: Epoch time: 44.16 s 
2024-12-11 04:39:43.541979:  
2024-12-11 04:39:43.547128: Epoch 71 
2024-12-11 04:39:43.550690: Current learning rate: 0.00328 
2024-12-11 04:40:27.808875: train_loss -0.6059 
2024-12-11 04:40:27.813980: val_loss -0.5754 
2024-12-11 04:40:27.817555: Pseudo dice [np.float32(0.6386), np.float32(0.8323)] 
2024-12-11 04:40:27.820617: Epoch time: 44.27 s 
2024-12-11 04:40:27.823670: Yayy! New best EMA pseudo Dice: 0.7157999873161316 
2024-12-11 04:40:28.557060:  
2024-12-11 04:40:28.562629: Epoch 72 
2024-12-11 04:40:28.565684: Current learning rate: 0.00318 
2024-12-11 04:41:12.759552: train_loss -0.6222 
2024-12-11 04:41:12.765566: val_loss -0.5808 
2024-12-11 04:41:12.769073: Pseudo dice [np.float32(0.6574), np.float32(0.8038)] 
2024-12-11 04:41:12.772087: Epoch time: 44.2 s 
2024-12-11 04:41:12.774592: Yayy! New best EMA pseudo Dice: 0.7172999978065491 
2024-12-11 04:41:13.515401:  
2024-12-11 04:41:13.520436: Epoch 73 
2024-12-11 04:41:13.524237: Current learning rate: 0.00308 
2024-12-11 04:41:57.718939: train_loss -0.6057 
2024-12-11 04:41:57.724004: val_loss -0.5764 
2024-12-11 04:41:57.728067: Pseudo dice [np.float32(0.6353), np.float32(0.7903)] 
2024-12-11 04:41:57.730574: Epoch time: 44.2 s 
2024-12-11 04:41:58.312038:  
2024-12-11 04:41:58.317067: Epoch 74 
2024-12-11 04:41:58.320956: Current learning rate: 0.00297 
2024-12-11 04:42:42.540193: train_loss -0.6186 
2024-12-11 04:42:42.545237: val_loss -0.6154 
2024-12-11 04:42:42.548760: Pseudo dice [np.float32(0.6297), np.float32(0.8527)] 
2024-12-11 04:42:42.551782: Epoch time: 44.23 s 
2024-12-11 04:42:42.554867: Yayy! New best EMA pseudo Dice: 0.7192999720573425 
2024-12-11 04:42:43.464627:  
2024-12-11 04:42:43.470145: Epoch 75 
2024-12-11 04:42:43.473686: Current learning rate: 0.00287 
2024-12-11 04:43:27.722678: train_loss -0.6044 
2024-12-11 04:43:27.727792: val_loss -0.5932 
2024-12-11 04:43:27.730864: Pseudo dice [np.float32(0.6541), np.float32(0.7657)] 
2024-12-11 04:43:27.733413: Epoch time: 44.26 s 
2024-12-11 04:43:28.314254:  
2024-12-11 04:43:28.319267: Epoch 76 
2024-12-11 04:43:28.323276: Current learning rate: 0.00277 
2024-12-11 04:44:12.552846: train_loss -0.6048 
2024-12-11 04:44:12.557893: val_loss -0.5816 
2024-12-11 04:44:12.561435: Pseudo dice [np.float32(0.6102), np.float32(0.7925)] 
2024-12-11 04:44:12.563943: Epoch time: 44.24 s 
2024-12-11 04:44:13.146424:  
2024-12-11 04:44:13.151465: Epoch 77 
2024-12-11 04:44:13.155010: Current learning rate: 0.00266 
2024-12-11 04:44:57.354457: train_loss -0.6278 
2024-12-11 04:44:57.360523: val_loss -0.5528 
2024-12-11 04:44:57.364110: Pseudo dice [np.float32(0.6207), np.float32(0.7821)] 
2024-12-11 04:44:57.366213: Epoch time: 44.21 s 
2024-12-11 04:44:57.942814:  
2024-12-11 04:44:57.947863: Epoch 78 
2024-12-11 04:44:57.950743: Current learning rate: 0.00256 
2024-12-11 04:45:42.147294: train_loss -0.6175 
2024-12-11 04:45:42.152829: val_loss -0.5743 
2024-12-11 04:45:42.155840: Pseudo dice [np.float32(0.6302), np.float32(0.8108)] 
2024-12-11 04:45:42.159387: Epoch time: 44.2 s 
2024-12-11 04:45:42.737900:  
2024-12-11 04:45:42.742912: Epoch 79 
2024-12-11 04:45:42.746919: Current learning rate: 0.00245 
2024-12-11 04:46:26.967319: train_loss -0.6277 
2024-12-11 04:46:26.972388: val_loss -0.5923 
2024-12-11 04:46:26.976432: Pseudo dice [np.float32(0.6376), np.float32(0.8022)] 
2024-12-11 04:46:26.979475: Epoch time: 44.23 s 
2024-12-11 04:46:27.570367:  
2024-12-11 04:46:27.576939: Epoch 80 
2024-12-11 04:46:27.580012: Current learning rate: 0.00235 
2024-12-11 04:47:11.808596: train_loss -0.6175 
2024-12-11 04:47:11.814633: val_loss -0.5874 
2024-12-11 04:47:11.817708: Pseudo dice [np.float32(0.6506), np.float32(0.8359)] 
2024-12-11 04:47:11.821231: Epoch time: 44.24 s 
2024-12-11 04:47:12.419127:  
2024-12-11 04:47:12.424702: Epoch 81 
2024-12-11 04:47:12.428756: Current learning rate: 0.00224 
2024-12-11 04:47:56.638701: train_loss -0.6279 
2024-12-11 04:47:56.643766: val_loss -0.6091 
2024-12-11 04:47:56.647839: Pseudo dice [np.float32(0.6551), np.float32(0.8304)] 
2024-12-11 04:47:56.650850: Epoch time: 44.22 s 
2024-12-11 04:47:56.653356: Yayy! New best EMA pseudo Dice: 0.7211999893188477 
2024-12-11 04:47:57.418555:  
2024-12-11 04:47:57.426133: Epoch 82 
2024-12-11 04:47:57.430684: Current learning rate: 0.00214 
2024-12-11 04:48:41.663427: train_loss -0.625 
2024-12-11 04:48:41.668547: val_loss -0.6191 
2024-12-11 04:48:41.671645: Pseudo dice [np.float32(0.6418), np.float32(0.842)] 
2024-12-11 04:48:41.674684: Epoch time: 44.24 s 
2024-12-11 04:48:41.677695: Yayy! New best EMA pseudo Dice: 0.7232999801635742 
2024-12-11 04:48:42.564323:  
2024-12-11 04:48:42.569902: Epoch 83 
2024-12-11 04:48:42.572938: Current learning rate: 0.00203 
2024-12-11 04:49:26.821179: train_loss -0.6065 
2024-12-11 04:49:26.826822: val_loss -0.5576 
2024-12-11 04:49:26.829862: Pseudo dice [np.float32(0.6276), np.float32(0.78)] 
2024-12-11 04:49:26.832410: Epoch time: 44.26 s 
2024-12-11 04:49:27.384889:  
2024-12-11 04:49:27.389960: Epoch 84 
2024-12-11 04:49:27.393008: Current learning rate: 0.00192 
2024-12-11 04:50:11.629933: train_loss -0.6211 
2024-12-11 04:50:11.635481: val_loss -0.5928 
2024-12-11 04:50:11.638990: Pseudo dice [np.float32(0.6502), np.float32(0.8003)] 
2024-12-11 04:50:11.641171: Epoch time: 44.25 s 
2024-12-11 04:50:12.196859:  
2024-12-11 04:50:12.202404: Epoch 85 
2024-12-11 04:50:12.204939: Current learning rate: 0.00181 
2024-12-11 04:50:56.354476: train_loss -0.6304 
2024-12-11 04:50:56.359539: val_loss -0.597 
2024-12-11 04:50:56.362578: Pseudo dice [np.float32(0.6366), np.float32(0.8326)] 
2024-12-11 04:50:56.365622: Epoch time: 44.16 s 
2024-12-11 04:50:56.929811:  
2024-12-11 04:50:56.934977: Epoch 86 
2024-12-11 04:50:56.938530: Current learning rate: 0.0017 
2024-12-11 04:51:41.119748: train_loss -0.6367 
2024-12-11 04:51:41.125883: val_loss -0.6126 
2024-12-11 04:51:41.128970: Pseudo dice [np.float32(0.6358), np.float32(0.8164)] 
2024-12-11 04:51:41.132024: Epoch time: 44.19 s 
2024-12-11 04:51:41.134608: Yayy! New best EMA pseudo Dice: 0.7232999801635742 
2024-12-11 04:51:41.855395:  
2024-12-11 04:51:41.860471: Epoch 87 
2024-12-11 04:51:41.863036: Current learning rate: 0.00159 
2024-12-11 04:52:26.056248: train_loss -0.6321 
2024-12-11 04:52:26.061802: val_loss -0.5981 
2024-12-11 04:52:26.064324: Pseudo dice [np.float32(0.6294), np.float32(0.8247)] 
2024-12-11 04:52:26.068346: Epoch time: 44.2 s 
2024-12-11 04:52:26.071396: Yayy! New best EMA pseudo Dice: 0.7236999869346619 
2024-12-11 04:52:26.791873:  
2024-12-11 04:52:26.797907: Epoch 88 
2024-12-11 04:52:26.800516: Current learning rate: 0.00148 
2024-12-11 04:53:11.014790: train_loss -0.6324 
2024-12-11 04:53:11.019838: val_loss -0.6302 
2024-12-11 04:53:11.023346: Pseudo dice [np.float32(0.664), np.float32(0.8377)] 
2024-12-11 04:53:11.025503: Epoch time: 44.22 s 
2024-12-11 04:53:11.029513: Yayy! New best EMA pseudo Dice: 0.7264000177383423 
2024-12-11 04:53:11.742889:  
2024-12-11 04:53:11.748503: Epoch 89 
2024-12-11 04:53:11.752601: Current learning rate: 0.00137 
2024-12-11 04:53:56.001629: train_loss -0.6358 
2024-12-11 04:53:56.006730: val_loss -0.6052 
2024-12-11 04:53:56.009790: Pseudo dice [np.float32(0.6612), np.float32(0.8153)] 
2024-12-11 04:53:56.011808: Epoch time: 44.26 s 
2024-12-11 04:53:56.015866: Yayy! New best EMA pseudo Dice: 0.7275999784469604 
2024-12-11 04:53:56.724447:  
2024-12-11 04:53:56.730036: Epoch 90 
2024-12-11 04:53:56.732577: Current learning rate: 0.00126 
2024-12-11 04:54:40.941463: train_loss -0.6424 
2024-12-11 04:54:40.946495: val_loss -0.6033 
2024-12-11 04:54:40.950478: Pseudo dice [np.float32(0.6538), np.float32(0.8186)] 
2024-12-11 04:54:40.953992: Epoch time: 44.22 s 
2024-12-11 04:54:40.957096: Yayy! New best EMA pseudo Dice: 0.7285000085830688 
2024-12-11 04:54:41.828912:  
2024-12-11 04:54:41.834036: Epoch 91 
2024-12-11 04:54:41.836569: Current learning rate: 0.00115 
2024-12-11 04:55:26.075063: train_loss -0.6345 
2024-12-11 04:55:26.080670: val_loss -0.5862 
2024-12-11 04:55:26.083720: Pseudo dice [np.float32(0.6305), np.float32(0.8118)] 
2024-12-11 04:55:26.086794: Epoch time: 44.25 s 
2024-12-11 04:55:26.642892:  
2024-12-11 04:55:26.647910: Epoch 92 
2024-12-11 04:55:26.651423: Current learning rate: 0.00103 
2024-12-11 04:56:10.872090: train_loss -0.6428 
2024-12-11 04:56:10.878123: val_loss -0.6181 
2024-12-11 04:56:10.881234: Pseudo dice [np.float32(0.6155), np.float32(0.8473)] 
2024-12-11 04:56:10.883745: Epoch time: 44.23 s 
2024-12-11 04:56:11.434849:  
2024-12-11 04:56:11.439926: Epoch 93 
2024-12-11 04:56:11.442486: Current learning rate: 0.00091 
2024-12-11 04:56:55.661795: train_loss -0.6514 
2024-12-11 04:56:55.667428: val_loss -0.6432 
2024-12-11 04:56:55.671023: Pseudo dice [np.float32(0.66), np.float32(0.8405)] 
2024-12-11 04:56:55.674210: Epoch time: 44.23 s 
2024-12-11 04:56:55.677317: Yayy! New best EMA pseudo Dice: 0.7303000092506409 
2024-12-11 04:56:56.387061:  
2024-12-11 04:56:56.392603: Epoch 94 
2024-12-11 04:56:56.395175: Current learning rate: 0.00079 
2024-12-11 04:57:40.599235: train_loss -0.6533 
2024-12-11 04:57:40.605328: val_loss -0.6114 
2024-12-11 04:57:40.608473: Pseudo dice [np.float32(0.6641), np.float32(0.8605)] 
2024-12-11 04:57:40.612014: Epoch time: 44.21 s 
2024-12-11 04:57:40.615110: Yayy! New best EMA pseudo Dice: 0.7335000038146973 
2024-12-11 04:57:41.331454:  
2024-12-11 04:57:41.337041: Epoch 95 
2024-12-11 04:57:41.340090: Current learning rate: 0.00067 
2024-12-11 04:58:25.536175: train_loss -0.6378 
2024-12-11 04:58:25.541762: val_loss -0.622 
2024-12-11 04:58:25.544814: Pseudo dice [np.float32(0.6632), np.float32(0.8323)] 
2024-12-11 04:58:25.548331: Epoch time: 44.2 s 
2024-12-11 04:58:25.550844: Yayy! New best EMA pseudo Dice: 0.7348999977111816 
2024-12-11 04:58:26.269452:  
2024-12-11 04:58:26.274466: Epoch 96 
2024-12-11 04:58:26.277986: Current learning rate: 0.00055 
2024-12-11 04:59:10.489372: train_loss -0.654 
2024-12-11 04:59:10.495432: val_loss -0.6183 
2024-12-11 04:59:10.499445: Pseudo dice [np.float32(0.651), np.float32(0.8244)] 
2024-12-11 04:59:10.503462: Epoch time: 44.22 s 
2024-12-11 04:59:10.507012: Yayy! New best EMA pseudo Dice: 0.7351999878883362 
2024-12-11 04:59:11.241555:  
2024-12-11 04:59:11.247517: Epoch 97 
2024-12-11 04:59:11.250612: Current learning rate: 0.00043 
2024-12-11 04:59:55.472630: train_loss -0.6489 
2024-12-11 04:59:55.478667: val_loss -0.6303 
2024-12-11 04:59:55.481678: Pseudo dice [np.float32(0.6625), np.float32(0.8458)] 
2024-12-11 04:59:55.484184: Epoch time: 44.23 s 
2024-12-11 04:59:55.489196: Yayy! New best EMA pseudo Dice: 0.7371000051498413 
2024-12-11 04:59:56.206391:  
2024-12-11 04:59:56.211928: Epoch 98 
2024-12-11 04:59:56.214434: Current learning rate: 0.0003 
2024-12-11 05:00:40.417135: train_loss -0.6441 
2024-12-11 05:00:40.422177: val_loss -0.5814 
2024-12-11 05:00:40.425766: Pseudo dice [np.float32(0.6427), np.float32(0.8387)] 
2024-12-11 05:00:40.428371: Epoch time: 44.21 s 
2024-12-11 05:00:40.431880: Yayy! New best EMA pseudo Dice: 0.737500011920929 
2024-12-11 05:00:41.317959:  
2024-12-11 05:00:41.323475: Epoch 99 
2024-12-11 05:00:41.326985: Current learning rate: 0.00016 
2024-12-11 05:01:25.530850: train_loss -0.6488 
2024-12-11 05:01:25.535927: val_loss -0.5758 
2024-12-11 05:01:25.539936: Pseudo dice [np.float32(0.6473), np.float32(0.7964)] 
2024-12-11 05:01:25.542960: Epoch time: 44.21 s 
2024-12-11 05:01:26.343741: Training done. 
2024-12-11 05:01:26.375518: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset008_HepaticVessel\splits_final.json 
2024-12-11 05:01:26.381517: The split file contains 5 splits. 
2024-12-11 05:01:26.387029: Desired fold for training: 0 
2024-12-11 05:01:26.392030: This split has 242 training and 61 validation cases. 
2024-12-11 05:01:26.397120: predicting hepaticvessel_018 
2024-12-11 05:01:26.402630: hepaticvessel_018, shape torch.Size([1, 92, 187, 187]), rank 0 
2024-12-11 05:01:27.922771: predicting hepaticvessel_019 
2024-12-11 05:01:27.931281: hepaticvessel_019, shape torch.Size([1, 115, 203, 203]), rank 0 
2024-12-11 05:01:29.494491: predicting hepaticvessel_026 
2024-12-11 05:01:29.504000: hepaticvessel_026, shape torch.Size([1, 133, 213, 213]), rank 0 
2024-12-11 05:01:31.070378: predicting hepaticvessel_028 
2024-12-11 05:01:31.080886: hepaticvessel_028, shape torch.Size([1, 103, 206, 206]), rank 0 
2024-12-11 05:01:32.647275: predicting hepaticvessel_030 
2024-12-11 05:01:32.656447: hepaticvessel_030, shape torch.Size([1, 100, 249, 249]), rank 0 
2024-12-11 05:01:36.176913: predicting hepaticvessel_050 
2024-12-11 05:01:36.185921: hepaticvessel_050, shape torch.Size([1, 105, 229, 229]), rank 0 
2024-12-11 05:01:37.759754: predicting hepaticvessel_053 
2024-12-11 05:01:37.768266: hepaticvessel_053, shape torch.Size([1, 108, 223, 223]), rank 0 
2024-12-11 05:01:39.339400: predicting hepaticvessel_058 
2024-12-11 05:01:39.347914: hepaticvessel_058, shape torch.Size([1, 85, 174, 174]), rank 0 
2024-12-11 05:01:40.144795: predicting hepaticvessel_066 
2024-12-11 05:01:40.154800: hepaticvessel_066, shape torch.Size([1, 126, 205, 205]), rank 0 
2024-12-11 05:01:41.731210: predicting hepaticvessel_077 
2024-12-11 05:01:41.747228: hepaticvessel_077, shape torch.Size([1, 100, 181, 181]), rank 0 
2024-12-11 05:01:43.337723: predicting hepaticvessel_080 
2024-12-11 05:01:43.351468: hepaticvessel_080, shape torch.Size([1, 115, 256, 256]), rank 0 
2024-12-11 05:01:47.002078: predicting hepaticvessel_082 
2024-12-11 05:01:47.011593: hepaticvessel_082, shape torch.Size([1, 128, 247, 247]), rank 0 
2024-12-11 05:01:50.645632: predicting hepaticvessel_084 
2024-12-11 05:01:50.656714: hepaticvessel_084, shape torch.Size([1, 115, 215, 215]), rank 0 
2024-12-11 05:01:52.273085: predicting hepaticvessel_085 
2024-12-11 05:01:52.283591: hepaticvessel_085, shape torch.Size([1, 92, 195, 195]), rank 0 
2024-12-11 05:01:53.104825: predicting hepaticvessel_087 
2024-12-11 05:01:53.113328: hepaticvessel_087, shape torch.Size([1, 100, 221, 221]), rank 0 
2024-12-11 05:01:54.738015: predicting hepaticvessel_098 
2024-12-11 05:01:54.747525: hepaticvessel_098, shape torch.Size([1, 95, 201, 201]), rank 0 
2024-12-11 05:01:55.549595: predicting hepaticvessel_100 
2024-12-11 05:01:55.559108: hepaticvessel_100, shape torch.Size([1, 118, 195, 195]), rank 0 
2024-12-11 05:01:57.130307: predicting hepaticvessel_110 
2024-12-11 05:01:57.142814: hepaticvessel_110, shape torch.Size([1, 126, 253, 253]), rank 0 
2024-12-11 05:02:00.647574: predicting hepaticvessel_112 
2024-12-11 05:02:00.659086: hepaticvessel_112, shape torch.Size([1, 113, 245, 245]), rank 0 
2024-12-11 05:02:04.160742: predicting hepaticvessel_127 
2024-12-11 05:02:04.171082: hepaticvessel_127, shape torch.Size([1, 208, 160, 160]), rank 0 
2024-12-11 05:02:04.972206: predicting hepaticvessel_129 
2024-12-11 05:02:04.983246: hepaticvessel_129, shape torch.Size([1, 151, 222, 222]), rank 0 
2024-12-11 05:02:07.328032: predicting hepaticvessel_146 
2024-12-11 05:02:07.339040: hepaticvessel_146, shape torch.Size([1, 149, 215, 215]), rank 0 
2024-12-11 05:02:09.686138: predicting hepaticvessel_147 
2024-12-11 05:02:09.703660: hepaticvessel_147, shape torch.Size([1, 149, 251, 251]), rank 0 
2024-12-11 05:02:14.956708: predicting hepaticvessel_150 
2024-12-11 05:02:14.967714: hepaticvessel_150, shape torch.Size([1, 227, 215, 215]), rank 0 
2024-12-11 05:02:18.094257: predicting hepaticvessel_157 
2024-12-11 05:02:18.105271: hepaticvessel_157, shape torch.Size([1, 138, 256, 256]), rank 0 
2024-12-11 05:02:21.613627: predicting hepaticvessel_161 
2024-12-11 05:02:21.625190: hepaticvessel_161, shape torch.Size([1, 92, 185, 185]), rank 0 
2024-12-11 05:02:22.431463: predicting hepaticvessel_164 
2024-12-11 05:02:22.441979: hepaticvessel_164, shape torch.Size([1, 104, 189, 189]), rank 0 
2024-12-11 05:02:24.014403: predicting hepaticvessel_167 
2024-12-11 05:02:24.023967: hepaticvessel_167, shape torch.Size([1, 138, 205, 205]), rank 0 
2024-12-11 05:02:25.597423: predicting hepaticvessel_175 
2024-12-11 05:02:25.607435: hepaticvessel_175, shape torch.Size([1, 105, 185, 185]), rank 0 
2024-12-11 05:02:27.177819: predicting hepaticvessel_194 
2024-12-11 05:02:27.187453: hepaticvessel_194, shape torch.Size([1, 87, 225, 225]), rank 0 
2024-12-11 05:02:27.995630: predicting hepaticvessel_206 
2024-12-11 05:02:28.009802: hepaticvessel_206, shape torch.Size([1, 122, 177, 177]), rank 0 
2024-12-11 05:02:29.589034: predicting hepaticvessel_213 
2024-12-11 05:02:29.601057: hepaticvessel_213, shape torch.Size([1, 134, 242, 242]), rank 0 
2024-12-11 05:02:33.118192: predicting hepaticvessel_217 
2024-12-11 05:02:33.129208: hepaticvessel_217, shape torch.Size([1, 121, 256, 256]), rank 0 
2024-12-11 05:02:36.632039: predicting hepaticvessel_218 
2024-12-11 05:02:36.643550: hepaticvessel_218, shape torch.Size([1, 128, 192, 192]), rank 0 
2024-12-11 05:02:38.215995: predicting hepaticvessel_224 
2024-12-11 05:02:38.227510: hepaticvessel_224, shape torch.Size([1, 115, 199, 199]), rank 0 
2024-12-11 05:02:39.798573: predicting hepaticvessel_234 
2024-12-11 05:02:39.808584: hepaticvessel_234, shape torch.Size([1, 133, 232, 232]), rank 0 
2024-12-11 05:02:41.390847: predicting hepaticvessel_244 
2024-12-11 05:02:41.401855: hepaticvessel_244, shape torch.Size([1, 87, 164, 164]), rank 0 
2024-12-11 05:02:42.204070: predicting hepaticvessel_248 
2024-12-11 05:02:42.212092: hepaticvessel_248, shape torch.Size([1, 92, 178, 178]), rank 0 
2024-12-11 05:02:43.007759: predicting hepaticvessel_266 
2024-12-11 05:02:43.016270: hepaticvessel_266, shape torch.Size([1, 105, 209, 209]), rank 0 
2024-12-11 05:02:44.587416: predicting hepaticvessel_269 
2024-12-11 05:02:44.597425: hepaticvessel_269, shape torch.Size([1, 131, 244, 244]), rank 0 
2024-12-11 05:02:48.104413: predicting hepaticvessel_270 
2024-12-11 05:02:48.114470: hepaticvessel_270, shape torch.Size([1, 114, 169, 169]), rank 0 
2024-12-11 05:02:49.683553: predicting hepaticvessel_272 
2024-12-11 05:02:49.691693: hepaticvessel_272, shape torch.Size([1, 121, 215, 215]), rank 0 
2024-12-11 05:02:51.263908: predicting hepaticvessel_274 
2024-12-11 05:02:51.274424: hepaticvessel_274, shape torch.Size([1, 122, 231, 231]), rank 0 
2024-12-11 05:02:52.848709: predicting hepaticvessel_275 
2024-12-11 05:02:52.859718: hepaticvessel_275, shape torch.Size([1, 101, 207, 207]), rank 0 
2024-12-11 05:02:54.432966: predicting hepaticvessel_282 
2024-12-11 05:02:54.443025: hepaticvessel_282, shape torch.Size([1, 104, 226, 226]), rank 0 
2024-12-11 05:02:56.012927: predicting hepaticvessel_309 
2024-12-11 05:02:56.024142: hepaticvessel_309, shape torch.Size([1, 115, 237, 237]), rank 0 
2024-12-11 05:02:57.596477: predicting hepaticvessel_329 
2024-12-11 05:02:57.606581: hepaticvessel_329, shape torch.Size([1, 126, 216, 216]), rank 0 
2024-12-11 05:02:59.178700: predicting hepaticvessel_333 
2024-12-11 05:02:59.189211: hepaticvessel_333, shape torch.Size([1, 140, 206, 206]), rank 0 
2024-12-11 05:03:00.768387: predicting hepaticvessel_358 
2024-12-11 05:03:00.782413: hepaticvessel_358, shape torch.Size([1, 108, 169, 169]), rank 0 
2024-12-11 05:03:02.351881: predicting hepaticvessel_359 
2024-12-11 05:03:02.358885: hepaticvessel_359, shape torch.Size([1, 121, 196, 196]), rank 0 
2024-12-11 05:03:03.926886: predicting hepaticvessel_361 
2024-12-11 05:03:03.939343: hepaticvessel_361, shape torch.Size([1, 128, 236, 236]), rank 0 
2024-12-11 05:03:05.526735: predicting hepaticvessel_363 
2024-12-11 05:03:05.543753: hepaticvessel_363, shape torch.Size([1, 103, 185, 185]), rank 0 
2024-12-11 05:03:07.117951: predicting hepaticvessel_368 
2024-12-11 05:03:07.127995: hepaticvessel_368, shape torch.Size([1, 114, 192, 192]), rank 0 
2024-12-11 05:03:08.707415: predicting hepaticvessel_375 
2024-12-11 05:03:08.718427: hepaticvessel_375, shape torch.Size([1, 137, 207, 207]), rank 0 
2024-12-11 05:03:10.294171: predicting hepaticvessel_422 
2024-12-11 05:03:10.309184: hepaticvessel_422, shape torch.Size([1, 121, 186, 186]), rank 0 
2024-12-11 05:03:11.879238: predicting hepaticvessel_424 
2024-12-11 05:03:11.888386: hepaticvessel_424, shape torch.Size([1, 103, 192, 192]), rank 0 
2024-12-11 05:03:13.457665: predicting hepaticvessel_437 
2024-12-11 05:03:13.467173: hepaticvessel_437, shape torch.Size([1, 106, 255, 255]), rank 0 
2024-12-11 05:03:16.966924: predicting hepaticvessel_441 
2024-12-11 05:03:16.976142: hepaticvessel_441, shape torch.Size([1, 126, 218, 218]), rank 0 
2024-12-11 05:03:18.548523: predicting hepaticvessel_444 
2024-12-11 05:03:18.559035: hepaticvessel_444, shape torch.Size([1, 112, 186, 186]), rank 0 
2024-12-11 05:03:20.124288: predicting hepaticvessel_445 
2024-12-11 05:03:20.134309: hepaticvessel_445, shape torch.Size([1, 129, 210, 210]), rank 0 
2024-12-11 05:03:21.707552: predicting hepaticvessel_458 
2024-12-11 05:03:21.717072: hepaticvessel_458, shape torch.Size([1, 108, 224, 224]), rank 0 
2024-12-11 05:03:35.824595: Validation complete 
2024-12-11 05:03:35.830598: Mean Validation Dice:  0.649672327093948 
