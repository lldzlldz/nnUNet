
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-11 18:10:08.388569: do_dummy_2d_data_aug: True 
2024-12-11 18:10:08.394570: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset008_HepaticVessel\splits_final.json 
2024-12-11 18:10:08.401076: The split file contains 5 splits. 
2024-12-11 18:10:08.404194: Desired fold for training: 0 
2024-12-11 18:10:08.406194: This split has 242 training and 61 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_median_spacing_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [28, 256, 256], 'median_image_size_in_voxels': [45.0, 512.0, 512.0], 'spacing': [5.0, 0.7988280057907104, 0.7988280057907104], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset008_HepaticVessel', 'plans_name': 'nnUNetPlans_median_spacing', 'original_median_spacing_after_transp': [5.0, 0.7988280057907104, 0.7988280057907104], 'original_median_shape_after_transp': [49, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3072.0, 'mean': 128.6698455810547, 'median': 129.0, 'min': -726.0, 'percentile_00_5': 8.0, 'percentile_99_5': 268.0, 'std': 54.57704544067383}}} 
 
2024-12-11 18:10:40.591989: unpacking dataset... 
2024-12-11 18:10:49.455910: unpacking done... 
2024-12-11 18:10:52.574341:  
2024-12-11 18:10:52.579355: Epoch 0 
2024-12-11 18:10:52.581864: Current learning rate: 0.01 
2024-12-11 18:11:40.082869: train_loss 0.1298 
2024-12-11 18:11:40.086879: val_loss 0.0669 
2024-12-11 18:11:40.089385: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-11 18:11:40.092895: Epoch time: 47.51 s 
2024-12-11 18:11:40.095399: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-11 18:11:40.832922:  
2024-12-11 18:11:40.838023: Epoch 1 
2024-12-11 18:11:40.841074: Current learning rate: 0.00991 
2024-12-11 18:12:23.642566: train_loss 0.0443 
2024-12-11 18:12:23.649109: val_loss 0.0029 
2024-12-11 18:12:23.651819: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-11 18:12:23.654325: Epoch time: 42.81 s 
2024-12-11 18:12:24.226362:  
2024-12-11 18:12:24.231951: Epoch 2 
2024-12-11 18:12:24.235317: Current learning rate: 0.00982 
2024-12-11 18:13:06.932272: train_loss -0.0536 
2024-12-11 18:13:06.937809: val_loss -0.1802 
2024-12-11 18:13:06.940818: Pseudo dice [np.float32(0.5425), np.float32(0.2953)] 
2024-12-11 18:13:06.943345: Epoch time: 42.71 s 
2024-12-11 18:13:06.945851: Yayy! New best EMA pseudo Dice: 0.04190000146627426 
2024-12-11 18:13:07.802384:  
2024-12-11 18:13:07.809479: Epoch 3 
2024-12-11 18:13:07.812531: Current learning rate: 0.00973 
2024-12-11 18:13:50.516573: train_loss -0.1746 
2024-12-11 18:13:50.520601: val_loss -0.1671 
2024-12-11 18:13:50.524614: Pseudo dice [np.float32(0.5569), np.float32(0.2763)] 
2024-12-11 18:13:50.527194: Epoch time: 42.71 s 
2024-12-11 18:13:50.530705: Yayy! New best EMA pseudo Dice: 0.07940000295639038 
2024-12-11 18:13:51.359872:  
2024-12-11 18:13:51.364920: Epoch 4 
2024-12-11 18:13:51.367959: Current learning rate: 0.00964 
2024-12-11 18:14:34.127344: train_loss -0.1888 
2024-12-11 18:14:34.132405: val_loss -0.2372 
2024-12-11 18:14:34.135934: Pseudo dice [np.float32(0.534), np.float32(0.3163)] 
2024-12-11 18:14:34.137998: Epoch time: 42.77 s 
2024-12-11 18:14:34.140538: Yayy! New best EMA pseudo Dice: 0.11389999836683273 
2024-12-11 18:14:35.116447:  
2024-12-11 18:14:35.122585: Epoch 5 
2024-12-11 18:14:35.125090: Current learning rate: 0.00955 
2024-12-11 18:15:17.855371: train_loss -0.2058 
2024-12-11 18:15:17.862416: val_loss -0.2741 
2024-12-11 18:15:17.867427: Pseudo dice [np.float32(0.5705), np.float32(0.3996)] 
2024-12-11 18:15:17.869933: Epoch time: 42.74 s 
2024-12-11 18:15:17.873442: Yayy! New best EMA pseudo Dice: 0.1509999930858612 
2024-12-11 18:15:18.697701:  
2024-12-11 18:15:18.702739: Epoch 6 
2024-12-11 18:15:18.707758: Current learning rate: 0.00946 
2024-12-11 18:16:01.455877: train_loss -0.2512 
2024-12-11 18:16:01.461458: val_loss -0.2931 
2024-12-11 18:16:01.464483: Pseudo dice [np.float32(0.5764), np.float32(0.4261)] 
2024-12-11 18:16:01.466988: Epoch time: 42.76 s 
2024-12-11 18:16:01.470500: Yayy! New best EMA pseudo Dice: 0.18610000610351562 
2024-12-11 18:16:02.322640:  
2024-12-11 18:16:02.328192: Epoch 7 
2024-12-11 18:16:02.331722: Current learning rate: 0.00937 
2024-12-11 18:16:45.060600: train_loss -0.2801 
2024-12-11 18:16:45.068405: val_loss -0.274 
2024-12-11 18:16:45.070914: Pseudo dice [np.float32(0.5569), np.float32(0.4481)] 
2024-12-11 18:16:45.073931: Epoch time: 42.74 s 
2024-12-11 18:16:45.076976: Yayy! New best EMA pseudo Dice: 0.21770000457763672 
2024-12-11 18:16:45.940165:  
2024-12-11 18:16:45.947211: Epoch 8 
2024-12-11 18:16:45.951816: Current learning rate: 0.00928 
2024-12-11 18:17:28.753268: train_loss -0.2784 
2024-12-11 18:17:28.759350: val_loss -0.297 
2024-12-11 18:17:28.762470: Pseudo dice [np.float32(0.603), np.float32(0.4707)] 
2024-12-11 18:17:28.766025: Epoch time: 42.81 s 
2024-12-11 18:17:28.770104: Yayy! New best EMA pseudo Dice: 0.24959999322891235 
2024-12-11 18:17:29.611938:  
2024-12-11 18:17:29.617546: Epoch 9 
2024-12-11 18:17:29.621059: Current learning rate: 0.00919 
2024-12-11 18:18:12.526858: train_loss -0.2913 
2024-12-11 18:18:12.531404: val_loss -0.3085 
2024-12-11 18:18:12.535465: Pseudo dice [np.float32(0.5853), np.float32(0.6014)] 
2024-12-11 18:18:12.538576: Epoch time: 42.92 s 
2024-12-11 18:18:12.542224: Yayy! New best EMA pseudo Dice: 0.2840000092983246 
2024-12-11 18:18:13.468765:  
2024-12-11 18:18:13.474352: Epoch 10 
2024-12-11 18:18:13.478378: Current learning rate: 0.0091 
2024-12-11 18:18:56.249690: train_loss -0.3098 
2024-12-11 18:18:56.255309: val_loss -0.3364 
2024-12-11 18:18:56.258834: Pseudo dice [np.float32(0.5767), np.float32(0.5792)] 
2024-12-11 18:18:56.262427: Epoch time: 42.78 s 
2024-12-11 18:18:56.265440: Yayy! New best EMA pseudo Dice: 0.313400000333786 
2024-12-11 18:18:57.099012:  
2024-12-11 18:18:57.105042: Epoch 11 
2024-12-11 18:18:57.109082: Current learning rate: 0.009 
2024-12-11 18:19:39.099491: train_loss -0.2968 
2024-12-11 18:19:39.104452: val_loss -0.3437 
2024-12-11 18:19:39.107971: Pseudo dice [np.float32(0.6166), np.float32(0.4523)] 
2024-12-11 18:19:39.110483: Epoch time: 42.0 s 
2024-12-11 18:19:39.114005: Yayy! New best EMA pseudo Dice: 0.33550000190734863 
2024-12-11 18:19:39.921141:  
2024-12-11 18:19:39.927217: Epoch 12 
2024-12-11 18:19:39.930203: Current learning rate: 0.00891 
2024-12-11 18:20:21.517615: train_loss -0.2998 
2024-12-11 18:20:21.522628: val_loss -0.3703 
2024-12-11 18:20:21.526137: Pseudo dice [np.float32(0.5918), np.float32(0.6503)] 
2024-12-11 18:20:21.528645: Epoch time: 41.6 s 
2024-12-11 18:20:21.532155: Yayy! New best EMA pseudo Dice: 0.36410000920295715 
2024-12-11 18:20:22.530126:  
2024-12-11 18:20:22.536641: Epoch 13 
2024-12-11 18:20:22.540218: Current learning rate: 0.00882 
2024-12-11 18:21:04.122435: train_loss -0.3186 
2024-12-11 18:21:04.126500: val_loss -0.3483 
2024-12-11 18:21:04.131042: Pseudo dice [np.float32(0.6103), np.float32(0.5384)] 
2024-12-11 18:21:04.133608: Epoch time: 41.59 s 
2024-12-11 18:21:04.137118: Yayy! New best EMA pseudo Dice: 0.38510000705718994 
2024-12-11 18:21:04.947863:  
2024-12-11 18:21:04.952891: Epoch 14 
2024-12-11 18:21:04.956512: Current learning rate: 0.00873 
2024-12-11 18:21:46.543941: train_loss -0.326 
2024-12-11 18:21:46.550481: val_loss -0.3491 
2024-12-11 18:21:46.552988: Pseudo dice [np.float32(0.5976), np.float32(0.634)] 
2024-12-11 18:21:46.556501: Epoch time: 41.6 s 
2024-12-11 18:21:46.558591: Yayy! New best EMA pseudo Dice: 0.4081000089645386 
2024-12-11 18:21:47.396654:  
2024-12-11 18:21:47.400935: Epoch 15 
2024-12-11 18:21:47.403946: Current learning rate: 0.00864 
2024-12-11 18:22:28.965862: train_loss -0.3207 
2024-12-11 18:22:28.971454: val_loss -0.344 
2024-12-11 18:22:28.973558: Pseudo dice [np.float32(0.5726), np.float32(0.6262)] 
2024-12-11 18:22:28.977624: Epoch time: 41.57 s 
2024-12-11 18:22:28.979166: Yayy! New best EMA pseudo Dice: 0.42730000615119934 
2024-12-11 18:22:29.804142:  
2024-12-11 18:22:29.809752: Epoch 16 
2024-12-11 18:22:29.812302: Current learning rate: 0.00855 
2024-12-11 18:23:11.393477: train_loss -0.3496 
2024-12-11 18:23:11.399511: val_loss -0.4312 
2024-12-11 18:23:11.402520: Pseudo dice [np.float32(0.6353), np.float32(0.6981)] 
2024-12-11 18:23:11.407556: Epoch time: 41.59 s 
2024-12-11 18:23:11.410062: Yayy! New best EMA pseudo Dice: 0.451200008392334 
2024-12-11 18:23:12.256124:  
2024-12-11 18:23:12.261142: Epoch 17 
2024-12-11 18:23:12.264153: Current learning rate: 0.00846 
2024-12-11 18:23:53.845649: train_loss -0.3549 
2024-12-11 18:23:53.850856: val_loss -0.427 
2024-12-11 18:23:53.854907: Pseudo dice [np.float32(0.6353), np.float32(0.7125)] 
2024-12-11 18:23:53.857967: Epoch time: 41.59 s 
2024-12-11 18:23:53.861010: Yayy! New best EMA pseudo Dice: 0.47350001335144043 
2024-12-11 18:23:54.684614:  
2024-12-11 18:23:54.690683: Epoch 18 
2024-12-11 18:23:54.693742: Current learning rate: 0.00836 
2024-12-11 18:24:36.272974: train_loss -0.3765 
2024-12-11 18:24:36.277992: val_loss -0.4476 
2024-12-11 18:24:36.281502: Pseudo dice [np.float32(0.6276), np.float32(0.7536)] 
2024-12-11 18:24:36.285009: Epoch time: 41.59 s 
2024-12-11 18:24:36.288020: Yayy! New best EMA pseudo Dice: 0.4952000081539154 
2024-12-11 18:24:37.159706:  
2024-12-11 18:24:37.165776: Epoch 19 
2024-12-11 18:24:37.168830: Current learning rate: 0.00827 
2024-12-11 18:25:18.724721: train_loss -0.3817 
2024-12-11 18:25:18.730247: val_loss -0.4314 
2024-12-11 18:25:18.733756: Pseudo dice [np.float32(0.6075), np.float32(0.7155)] 
2024-12-11 18:25:18.736267: Epoch time: 41.57 s 
2024-12-11 18:25:18.740277: Yayy! New best EMA pseudo Dice: 0.5117999911308289 
2024-12-11 18:25:19.582795:  
2024-12-11 18:25:19.588310: Epoch 20 
2024-12-11 18:25:19.591820: Current learning rate: 0.00818 
2024-12-11 18:26:01.147487: train_loss -0.3933 
2024-12-11 18:26:01.153536: val_loss -0.4227 
2024-12-11 18:26:01.156366: Pseudo dice [np.float32(0.635), np.float32(0.7228)] 
2024-12-11 18:26:01.159878: Epoch time: 41.57 s 
2024-12-11 18:26:01.162388: Yayy! New best EMA pseudo Dice: 0.5285000205039978 
2024-12-11 18:26:02.179463:  
2024-12-11 18:26:02.187015: Epoch 21 
2024-12-11 18:26:02.190562: Current learning rate: 0.00809 
2024-12-11 18:26:43.736816: train_loss -0.3909 
2024-12-11 18:26:43.742938: val_loss -0.3852 
2024-12-11 18:26:43.745995: Pseudo dice [np.float32(0.6579), np.float32(0.5774)] 
2024-12-11 18:26:43.748548: Epoch time: 41.56 s 
2024-12-11 18:26:43.751081: Yayy! New best EMA pseudo Dice: 0.5374000072479248 
2024-12-11 18:26:44.564605:  
2024-12-11 18:26:44.570136: Epoch 22 
2024-12-11 18:26:44.573160: Current learning rate: 0.008 
2024-12-11 18:27:26.130515: train_loss -0.3698 
2024-12-11 18:27:26.136554: val_loss -0.413 
2024-12-11 18:27:26.139060: Pseudo dice [np.float32(0.6114), np.float32(0.694)] 
2024-12-11 18:27:26.142567: Epoch time: 41.57 s 
2024-12-11 18:27:26.145594: Yayy! New best EMA pseudo Dice: 0.5490000247955322 
2024-12-11 18:27:26.935131:  
2024-12-11 18:27:26.940207: Epoch 23 
2024-12-11 18:27:26.944254: Current learning rate: 0.0079 
2024-12-11 18:28:08.546737: train_loss -0.4059 
2024-12-11 18:28:08.554257: val_loss -0.4631 
2024-12-11 18:28:08.558790: Pseudo dice [np.float32(0.6304), np.float32(0.7773)] 
2024-12-11 18:28:08.561817: Epoch time: 41.61 s 
2024-12-11 18:28:08.565327: Yayy! New best EMA pseudo Dice: 0.5644999742507935 
2024-12-11 18:28:09.352436:  
2024-12-11 18:28:09.358470: Epoch 24 
2024-12-11 18:28:09.362025: Current learning rate: 0.00781 
2024-12-11 18:28:50.904967: train_loss -0.4082 
2024-12-11 18:28:50.910547: val_loss -0.4458 
2024-12-11 18:28:50.914070: Pseudo dice [np.float32(0.657), np.float32(0.6751)] 
2024-12-11 18:28:50.917100: Epoch time: 41.55 s 
2024-12-11 18:28:50.920609: Yayy! New best EMA pseudo Dice: 0.5745999813079834 
2024-12-11 18:28:51.740938:  
2024-12-11 18:28:51.746506: Epoch 25 
2024-12-11 18:28:51.749565: Current learning rate: 0.00772 
2024-12-11 18:29:33.300541: train_loss -0.4192 
2024-12-11 18:29:33.306128: val_loss -0.4854 
2024-12-11 18:29:33.309236: Pseudo dice [np.float32(0.6608), np.float32(0.7992)] 
2024-12-11 18:29:33.312777: Epoch time: 41.56 s 
2024-12-11 18:29:33.315813: Yayy! New best EMA pseudo Dice: 0.5902000069618225 
2024-12-11 18:29:34.139138:  
2024-12-11 18:29:34.144150: Epoch 26 
2024-12-11 18:29:34.148176: Current learning rate: 0.00763 
2024-12-11 18:30:15.705980: train_loss -0.4273 
2024-12-11 18:30:15.712589: val_loss -0.4651 
2024-12-11 18:30:15.715617: Pseudo dice [np.float32(0.6076), np.float32(0.8166)] 
2024-12-11 18:30:15.719126: Epoch time: 41.57 s 
2024-12-11 18:30:15.721636: Yayy! New best EMA pseudo Dice: 0.602400004863739 
2024-12-11 18:30:16.529365:  
2024-12-11 18:30:16.534921: Epoch 27 
2024-12-11 18:30:16.537945: Current learning rate: 0.00753 
2024-12-11 18:30:58.108664: train_loss -0.4031 
2024-12-11 18:30:58.114191: val_loss -0.4603 
2024-12-11 18:30:58.117700: Pseudo dice [np.float32(0.6592), np.float32(0.7985)] 
2024-12-11 18:30:58.120223: Epoch time: 41.58 s 
2024-12-11 18:30:58.123728: Yayy! New best EMA pseudo Dice: 0.6150000095367432 
2024-12-11 18:30:58.920850:  
2024-12-11 18:30:58.925861: Epoch 28 
2024-12-11 18:30:58.929369: Current learning rate: 0.00744 
2024-12-11 18:31:40.495778: train_loss -0.4106 
2024-12-11 18:31:40.501825: val_loss -0.4295 
2024-12-11 18:31:40.504833: Pseudo dice [np.float32(0.6323), np.float32(0.702)] 
2024-12-11 18:31:40.507338: Epoch time: 41.58 s 
2024-12-11 18:31:40.510848: Yayy! New best EMA pseudo Dice: 0.620199978351593 
2024-12-11 18:31:41.452354:  
2024-12-11 18:31:41.457364: Epoch 29 
2024-12-11 18:31:41.460873: Current learning rate: 0.00735 
2024-12-11 18:32:22.997078: train_loss -0.4199 
2024-12-11 18:32:23.000685: val_loss -0.4568 
2024-12-11 18:32:23.004208: Pseudo dice [np.float32(0.6434), np.float32(0.7743)] 
2024-12-11 18:32:23.007433: Epoch time: 41.55 s 
2024-12-11 18:32:23.010452: Yayy! New best EMA pseudo Dice: 0.6291000247001648 
2024-12-11 18:32:23.829216:  
2024-12-11 18:32:23.834792: Epoch 30 
2024-12-11 18:32:23.837834: Current learning rate: 0.00725 
2024-12-11 18:33:05.382573: train_loss -0.4492 
2024-12-11 18:33:05.388153: val_loss -0.4813 
2024-12-11 18:33:05.391709: Pseudo dice [np.float32(0.6368), np.float32(0.8263)] 
2024-12-11 18:33:05.395236: Epoch time: 41.55 s 
2024-12-11 18:33:05.398297: Yayy! New best EMA pseudo Dice: 0.6392999887466431 
2024-12-11 18:33:06.225111:  
2024-12-11 18:33:06.231628: Epoch 31 
2024-12-11 18:33:06.235218: Current learning rate: 0.00716 
2024-12-11 18:33:47.787106: train_loss -0.4291 
2024-12-11 18:33:47.792809: val_loss -0.4539 
2024-12-11 18:33:47.795340: Pseudo dice [np.float32(0.6439), np.float32(0.6795)] 
2024-12-11 18:33:47.798866: Epoch time: 41.56 s 
2024-12-11 18:33:47.802009: Yayy! New best EMA pseudo Dice: 0.6416000127792358 
2024-12-11 18:33:48.608250:  
2024-12-11 18:33:48.613862: Epoch 32 
2024-12-11 18:33:48.617412: Current learning rate: 0.00707 
2024-12-11 18:34:30.181170: train_loss -0.4388 
2024-12-11 18:34:30.188221: val_loss -0.452 
2024-12-11 18:34:30.191230: Pseudo dice [np.float32(0.6413), np.float32(0.787)] 
2024-12-11 18:34:30.194743: Epoch time: 41.57 s 
2024-12-11 18:34:30.197250: Yayy! New best EMA pseudo Dice: 0.6488000154495239 
2024-12-11 18:34:31.006083:  
2024-12-11 18:34:31.011157: Epoch 33 
2024-12-11 18:34:31.014218: Current learning rate: 0.00697 
2024-12-11 18:35:12.597274: train_loss -0.4421 
2024-12-11 18:35:12.602826: val_loss -0.4619 
2024-12-11 18:35:12.605849: Pseudo dice [np.float32(0.6591), np.float32(0.7604)] 
2024-12-11 18:35:12.609382: Epoch time: 41.59 s 
2024-12-11 18:35:12.611893: Yayy! New best EMA pseudo Dice: 0.6549000144004822 
2024-12-11 18:35:13.427953:  
2024-12-11 18:35:13.434064: Epoch 34 
2024-12-11 18:35:13.438121: Current learning rate: 0.00688 
2024-12-11 18:35:55.001951: train_loss -0.4646 
2024-12-11 18:35:55.007097: val_loss -0.4586 
2024-12-11 18:35:55.010621: Pseudo dice [np.float32(0.6463), np.float32(0.7384)] 
2024-12-11 18:35:55.013647: Epoch time: 41.57 s 
2024-12-11 18:35:55.016163: Yayy! New best EMA pseudo Dice: 0.6586999893188477 
2024-12-11 18:35:55.863903:  
2024-12-11 18:35:55.869418: Epoch 35 
2024-12-11 18:35:55.872026: Current learning rate: 0.00679 
2024-12-11 18:36:37.453802: train_loss -0.459 
2024-12-11 18:36:37.460851: val_loss -0.4676 
2024-12-11 18:36:37.465873: Pseudo dice [np.float32(0.6513), np.float32(0.7658)] 
2024-12-11 18:36:37.469385: Epoch time: 41.59 s 
2024-12-11 18:36:37.471893: Yayy! New best EMA pseudo Dice: 0.6636000275611877 
2024-12-11 18:36:38.463847:  
2024-12-11 18:36:38.468871: Epoch 36 
2024-12-11 18:36:38.472496: Current learning rate: 0.00669 
2024-12-11 18:37:20.054932: train_loss -0.4353 
2024-12-11 18:37:20.060007: val_loss -0.4692 
2024-12-11 18:37:20.064095: Pseudo dice [np.float32(0.6537), np.float32(0.7161)] 
2024-12-11 18:37:20.066641: Epoch time: 41.59 s 
2024-12-11 18:37:20.070211: Yayy! New best EMA pseudo Dice: 0.6657999753952026 
2024-12-11 18:37:20.913117:  
2024-12-11 18:37:20.919131: Epoch 37 
2024-12-11 18:37:20.922636: Current learning rate: 0.0066 
2024-12-11 18:38:02.494554: train_loss -0.4229 
2024-12-11 18:38:02.498594: val_loss -0.4902 
2024-12-11 18:38:02.501603: Pseudo dice [np.float32(0.6105), np.float32(0.7622)] 
2024-12-11 18:38:02.504717: Epoch time: 41.58 s 
2024-12-11 18:38:02.507751: Yayy! New best EMA pseudo Dice: 0.6678000092506409 
2024-12-11 18:38:03.330854:  
2024-12-11 18:38:03.337372: Epoch 38 
2024-12-11 18:38:03.340883: Current learning rate: 0.0065 
2024-12-11 18:38:44.918925: train_loss -0.4586 
2024-12-11 18:38:44.924552: val_loss -0.4846 
2024-12-11 18:38:44.927611: Pseudo dice [np.float32(0.6492), np.float32(0.7528)] 
2024-12-11 18:38:44.931150: Epoch time: 41.59 s 
2024-12-11 18:38:44.934301: Yayy! New best EMA pseudo Dice: 0.6711000204086304 
2024-12-11 18:38:45.770582:  
2024-12-11 18:38:45.775594: Epoch 39 
2024-12-11 18:38:45.778099: Current learning rate: 0.00641 
2024-12-11 18:39:27.374249: train_loss -0.4608 
2024-12-11 18:39:27.379303: val_loss -0.4863 
2024-12-11 18:39:27.381946: Pseudo dice [np.float32(0.6545), np.float32(0.7986)] 
2024-12-11 18:39:27.385975: Epoch time: 41.6 s 
2024-12-11 18:39:27.388491: Yayy! New best EMA pseudo Dice: 0.6766999959945679 
2024-12-11 18:39:28.239597:  
2024-12-11 18:39:28.244217: Epoch 40 
2024-12-11 18:39:28.247743: Current learning rate: 0.00631 
2024-12-11 18:40:09.811918: train_loss -0.4785 
2024-12-11 18:40:09.817431: val_loss -0.4462 
2024-12-11 18:40:09.820971: Pseudo dice [np.float32(0.6578), np.float32(0.787)] 
2024-12-11 18:40:09.824478: Epoch time: 41.57 s 
2024-12-11 18:40:09.827487: Yayy! New best EMA pseudo Dice: 0.6812999844551086 
2024-12-11 18:40:10.686141:  
2024-12-11 18:40:10.690691: Epoch 41 
2024-12-11 18:40:10.693744: Current learning rate: 0.00622 
2024-12-11 18:40:52.275266: train_loss -0.4538 
2024-12-11 18:40:52.281362: val_loss -0.5052 
2024-12-11 18:40:52.283886: Pseudo dice [np.float32(0.6534), np.float32(0.8606)] 
2024-12-11 18:40:52.288944: Epoch time: 41.59 s 
2024-12-11 18:40:52.292489: Yayy! New best EMA pseudo Dice: 0.6887999773025513 
2024-12-11 18:40:53.090890:  
2024-12-11 18:40:53.096930: Epoch 42 
2024-12-11 18:40:53.100447: Current learning rate: 0.00612 
2024-12-11 18:41:34.678669: train_loss -0.4616 
2024-12-11 18:41:34.685863: val_loss -0.4652 
2024-12-11 18:41:34.691990: Pseudo dice [np.float32(0.6692), np.float32(0.7518)] 
2024-12-11 18:41:34.695035: Epoch time: 41.59 s 
2024-12-11 18:41:34.698094: Yayy! New best EMA pseudo Dice: 0.6909999847412109 
2024-12-11 18:41:35.507238:  
2024-12-11 18:41:35.512787: Epoch 43 
2024-12-11 18:41:35.516298: Current learning rate: 0.00603 
2024-12-11 18:42:17.105411: train_loss -0.464 
2024-12-11 18:42:17.111005: val_loss -0.5061 
2024-12-11 18:42:17.114569: Pseudo dice [np.float32(0.6726), np.float32(0.7745)] 
2024-12-11 18:42:17.118110: Epoch time: 41.6 s 
2024-12-11 18:42:17.121145: Yayy! New best EMA pseudo Dice: 0.6941999793052673 
2024-12-11 18:42:18.088392:  
2024-12-11 18:42:18.095064: Epoch 44 
2024-12-11 18:42:18.097610: Current learning rate: 0.00593 
2024-12-11 18:42:59.697992: train_loss -0.4616 
2024-12-11 18:42:59.704076: val_loss -0.4613 
2024-12-11 18:42:59.707689: Pseudo dice [np.float32(0.6446), np.float32(0.8038)] 
2024-12-11 18:42:59.711245: Epoch time: 41.61 s 
2024-12-11 18:42:59.713867: Yayy! New best EMA pseudo Dice: 0.6972000002861023 
2024-12-11 18:43:00.535638:  
2024-12-11 18:43:00.540683: Epoch 45 
2024-12-11 18:43:00.543837: Current learning rate: 0.00584 
2024-12-11 18:43:42.146086: train_loss -0.4748 
2024-12-11 18:43:42.152710: val_loss -0.5223 
2024-12-11 18:43:42.155747: Pseudo dice [np.float32(0.6755), np.float32(0.8218)] 
2024-12-11 18:43:42.158807: Epoch time: 41.61 s 
2024-12-11 18:43:42.161332: Yayy! New best EMA pseudo Dice: 0.7024000287055969 
2024-12-11 18:43:43.101163:  
2024-12-11 18:43:43.106185: Epoch 46 
2024-12-11 18:43:43.108690: Current learning rate: 0.00574 
2024-12-11 18:44:24.709601: train_loss -0.4713 
2024-12-11 18:44:24.714612: val_loss -0.4885 
2024-12-11 18:44:24.718120: Pseudo dice [np.float32(0.6466), np.float32(0.7847)] 
2024-12-11 18:44:24.720626: Epoch time: 41.61 s 
2024-12-11 18:44:24.724634: Yayy! New best EMA pseudo Dice: 0.7037000060081482 
2024-12-11 18:44:25.519760:  
2024-12-11 18:44:25.525809: Epoch 47 
2024-12-11 18:44:25.529358: Current learning rate: 0.00565 
2024-12-11 18:45:07.085842: train_loss -0.4582 
2024-12-11 18:45:07.091945: val_loss -0.4483 
2024-12-11 18:45:07.094979: Pseudo dice [np.float32(0.6446), np.float32(0.7319)] 
2024-12-11 18:45:07.097507: Epoch time: 41.57 s 
2024-12-11 18:45:07.654950:  
2024-12-11 18:45:07.659964: Epoch 48 
2024-12-11 18:45:07.662989: Current learning rate: 0.00555 
2024-12-11 18:45:49.232216: train_loss -0.4634 
2024-12-11 18:45:49.237301: val_loss -0.5056 
2024-12-11 18:45:49.241361: Pseudo dice [np.float32(0.6644), np.float32(0.8115)] 
2024-12-11 18:45:49.244374: Epoch time: 41.58 s 
2024-12-11 18:45:49.247921: Yayy! New best EMA pseudo Dice: 0.7057999968528748 
2024-12-11 18:45:50.070610:  
2024-12-11 18:45:50.076193: Epoch 49 
2024-12-11 18:45:50.078742: Current learning rate: 0.00546 
2024-12-11 18:46:31.670602: train_loss -0.4635 
2024-12-11 18:46:31.676211: val_loss -0.4671 
2024-12-11 18:46:31.678722: Pseudo dice [np.float32(0.6369), np.float32(0.7995)] 
2024-12-11 18:46:31.681159: Epoch time: 41.6 s 
2024-12-11 18:46:31.903723: Yayy! New best EMA pseudo Dice: 0.7070000171661377 
2024-12-11 18:46:32.738230:  
2024-12-11 18:46:32.744267: Epoch 50 
2024-12-11 18:46:32.747794: Current learning rate: 0.00536 
2024-12-11 18:47:14.335527: train_loss -0.4767 
2024-12-11 18:47:14.341679: val_loss -0.4856 
2024-12-11 18:47:14.344799: Pseudo dice [np.float32(0.6364), np.float32(0.82)] 
2024-12-11 18:47:14.347836: Epoch time: 41.6 s 
2024-12-11 18:47:14.352885: Yayy! New best EMA pseudo Dice: 0.7091000080108643 
2024-12-11 18:47:15.174051:  
2024-12-11 18:47:15.180190: Epoch 51 
2024-12-11 18:47:15.185207: Current learning rate: 0.00526 
2024-12-11 18:47:56.772318: train_loss -0.4756 
2024-12-11 18:47:56.778334: val_loss -0.5236 
2024-12-11 18:47:56.781844: Pseudo dice [np.float32(0.6604), np.float32(0.8013)] 
2024-12-11 18:47:56.784853: Epoch time: 41.6 s 
2024-12-11 18:47:56.787360: Yayy! New best EMA pseudo Dice: 0.7113000154495239 
2024-12-11 18:47:57.750961:  
2024-12-11 18:47:57.756599: Epoch 52 
2024-12-11 18:47:57.760156: Current learning rate: 0.00517 
2024-12-11 18:48:39.355257: train_loss -0.4823 
2024-12-11 18:48:39.359295: val_loss -0.4549 
2024-12-11 18:48:39.363881: Pseudo dice [np.float32(0.655), np.float32(0.7918)] 
2024-12-11 18:48:39.366429: Epoch time: 41.6 s 
2024-12-11 18:48:39.369941: Yayy! New best EMA pseudo Dice: 0.7124999761581421 
2024-12-11 18:48:40.198918:  
2024-12-11 18:48:40.204465: Epoch 53 
2024-12-11 18:48:40.208023: Current learning rate: 0.00507 
2024-12-11 18:49:21.795455: train_loss -0.485 
2024-12-11 18:49:21.800485: val_loss -0.4438 
2024-12-11 18:49:21.803995: Pseudo dice [np.float32(0.6415), np.float32(0.8136)] 
2024-12-11 18:49:21.806506: Epoch time: 41.6 s 
2024-12-11 18:49:21.810021: Yayy! New best EMA pseudo Dice: 0.7139999866485596 
2024-12-11 18:49:22.622660:  
2024-12-11 18:49:22.629238: Epoch 54 
2024-12-11 18:49:22.632274: Current learning rate: 0.00497 
2024-12-11 18:50:04.214233: train_loss -0.494 
2024-12-11 18:50:04.219295: val_loss -0.498 
2024-12-11 18:50:04.222305: Pseudo dice [np.float32(0.6636), np.float32(0.8208)] 
2024-12-11 18:50:04.225855: Epoch time: 41.59 s 
2024-12-11 18:50:04.228364: Yayy! New best EMA pseudo Dice: 0.7167999744415283 
2024-12-11 18:50:05.032885:  
2024-12-11 18:50:05.037913: Epoch 55 
2024-12-11 18:50:05.042003: Current learning rate: 0.00487 
2024-12-11 18:50:46.592206: train_loss -0.4679 
2024-12-11 18:50:46.598722: val_loss -0.4585 
2024-12-11 18:50:46.602310: Pseudo dice [np.float32(0.6524), np.float32(0.7439)] 
2024-12-11 18:50:46.605820: Epoch time: 41.56 s 
2024-12-11 18:50:47.174599:  
2024-12-11 18:50:47.180613: Epoch 56 
2024-12-11 18:50:47.183621: Current learning rate: 0.00478 
2024-12-11 18:51:28.757275: train_loss -0.4743 
2024-12-11 18:51:28.762801: val_loss -0.5184 
2024-12-11 18:51:28.766840: Pseudo dice [np.float32(0.6921), np.float32(0.8118)] 
2024-12-11 18:51:28.769848: Epoch time: 41.58 s 
2024-12-11 18:51:28.772865: Yayy! New best EMA pseudo Dice: 0.7186999917030334 
2024-12-11 18:51:29.587089:  
2024-12-11 18:51:29.592694: Epoch 57 
2024-12-11 18:51:29.596246: Current learning rate: 0.00468 
2024-12-11 18:52:11.219829: train_loss -0.4931 
2024-12-11 18:52:11.226080: val_loss -0.5019 
2024-12-11 18:52:11.229142: Pseudo dice [np.float32(0.6354), np.float32(0.7962)] 
2024-12-11 18:52:11.232170: Epoch time: 41.63 s 
2024-12-11 18:52:11.800743:  
2024-12-11 18:52:11.805923: Epoch 58 
2024-12-11 18:52:11.808452: Current learning rate: 0.00458 
2024-12-11 18:52:53.378866: train_loss -0.4885 
2024-12-11 18:52:53.386391: val_loss -0.5512 
2024-12-11 18:52:53.390401: Pseudo dice [np.float32(0.6682), np.float32(0.8366)] 
2024-12-11 18:52:53.393472: Epoch time: 41.58 s 
2024-12-11 18:52:53.395980: Yayy! New best EMA pseudo Dice: 0.7218000292778015 
2024-12-11 18:52:54.231838:  
2024-12-11 18:52:54.236976: Epoch 59 
2024-12-11 18:52:54.241021: Current learning rate: 0.00448 
2024-12-11 18:53:35.796770: train_loss -0.4906 
2024-12-11 18:53:35.802787: val_loss -0.527 
2024-12-11 18:53:35.805296: Pseudo dice [np.float32(0.6677), np.float32(0.8472)] 
2024-12-11 18:53:35.808803: Epoch time: 41.57 s 
2024-12-11 18:53:35.813821: Yayy! New best EMA pseudo Dice: 0.7253999710083008 
2024-12-11 18:53:36.806092:  
2024-12-11 18:53:36.811720: Epoch 60 
2024-12-11 18:53:36.815346: Current learning rate: 0.00438 
2024-12-11 18:54:18.621781: train_loss -0.5 
2024-12-11 18:54:18.626817: val_loss -0.501 
2024-12-11 18:54:18.630826: Pseudo dice [np.float32(0.674), np.float32(0.8467)] 
2024-12-11 18:54:18.634356: Epoch time: 41.82 s 
2024-12-11 18:54:18.638370: Yayy! New best EMA pseudo Dice: 0.7289000153541565 
2024-12-11 18:54:19.474956:  
2024-12-11 18:54:19.481062: Epoch 61 
2024-12-11 18:54:19.486150: Current learning rate: 0.00429 
2024-12-11 18:55:01.168380: train_loss -0.5033 
2024-12-11 18:55:01.173512: val_loss -0.5017 
2024-12-11 18:55:01.176579: Pseudo dice [np.float32(0.6395), np.float32(0.8315)] 
2024-12-11 18:55:01.179619: Epoch time: 41.69 s 
2024-12-11 18:55:01.182980: Yayy! New best EMA pseudo Dice: 0.7294999957084656 
2024-12-11 18:55:02.019629:  
2024-12-11 18:55:02.025241: Epoch 62 
2024-12-11 18:55:02.028312: Current learning rate: 0.00419 
2024-12-11 18:55:43.595951: train_loss -0.5009 
2024-12-11 18:55:43.600991: val_loss -0.4669 
2024-12-11 18:55:43.605014: Pseudo dice [np.float32(0.6753), np.float32(0.803)] 
2024-12-11 18:55:43.608033: Epoch time: 41.58 s 
2024-12-11 18:55:43.611054: Yayy! New best EMA pseudo Dice: 0.7304999828338623 
2024-12-11 18:55:44.452002:  
2024-12-11 18:55:44.457040: Epoch 63 
2024-12-11 18:55:44.460620: Current learning rate: 0.00409 
2024-12-11 18:56:26.063038: train_loss -0.5169 
2024-12-11 18:56:26.069060: val_loss -0.4981 
2024-12-11 18:56:26.071568: Pseudo dice [np.float32(0.6652), np.float32(0.8377)] 
2024-12-11 18:56:26.075667: Epoch time: 41.61 s 
2024-12-11 18:56:26.079179: Yayy! New best EMA pseudo Dice: 0.7325999736785889 
2024-12-11 18:56:26.921269:  
2024-12-11 18:56:26.927500: Epoch 64 
2024-12-11 18:56:26.930029: Current learning rate: 0.00399 
2024-12-11 18:57:08.517520: train_loss -0.519 
2024-12-11 18:57:08.523947: val_loss -0.4831 
2024-12-11 18:57:08.527514: Pseudo dice [np.float32(0.6429), np.float32(0.8218)] 
2024-12-11 18:57:08.530053: Epoch time: 41.6 s 
2024-12-11 18:57:09.130106:  
2024-12-11 18:57:09.135421: Epoch 65 
2024-12-11 18:57:09.137928: Current learning rate: 0.00389 
2024-12-11 18:57:50.731613: train_loss -0.5073 
2024-12-11 18:57:50.737129: val_loss -0.5595 
2024-12-11 18:57:50.740642: Pseudo dice [np.float32(0.6738), np.float32(0.8543)] 
2024-12-11 18:57:50.744148: Epoch time: 41.6 s 
2024-12-11 18:57:50.747158: Yayy! New best EMA pseudo Dice: 0.7357000112533569 
2024-12-11 18:57:51.572262:  
2024-12-11 18:57:51.578843: Epoch 66 
2024-12-11 18:57:51.581371: Current learning rate: 0.00379 
2024-12-11 18:58:33.148104: train_loss -0.5012 
2024-12-11 18:58:33.153371: val_loss -0.4852 
2024-12-11 18:58:33.156884: Pseudo dice [np.float32(0.6891), np.float32(0.8)] 
2024-12-11 18:58:33.160420: Epoch time: 41.58 s 
2024-12-11 18:58:33.162950: Yayy! New best EMA pseudo Dice: 0.7365999817848206 
2024-12-11 18:58:33.990805:  
2024-12-11 18:58:33.995868: Epoch 67 
2024-12-11 18:58:33.999522: Current learning rate: 0.00369 
2024-12-11 18:59:15.570674: train_loss -0.518 
2024-12-11 18:59:15.577189: val_loss -0.4646 
2024-12-11 18:59:15.579700: Pseudo dice [np.float32(0.6586), np.float32(0.7836)] 
2024-12-11 18:59:15.583210: Epoch time: 41.58 s 
2024-12-11 18:59:16.359105:  
2024-12-11 18:59:16.365179: Epoch 68 
2024-12-11 18:59:16.368232: Current learning rate: 0.00359 
2024-12-11 18:59:57.932054: train_loss -0.5194 
2024-12-11 18:59:57.937124: val_loss -0.5135 
2024-12-11 18:59:57.941222: Pseudo dice [np.float32(0.6487), np.float32(0.7947)] 
2024-12-11 18:59:57.944292: Epoch time: 41.57 s 
2024-12-11 18:59:58.526593:  
2024-12-11 18:59:58.531611: Epoch 69 
2024-12-11 18:59:58.535122: Current learning rate: 0.00349 
2024-12-11 19:00:40.113430: train_loss -0.5132 
2024-12-11 19:00:40.119536: val_loss -0.5371 
2024-12-11 19:00:40.122592: Pseudo dice [np.float32(0.6633), np.float32(0.853)] 
2024-12-11 19:00:40.125642: Epoch time: 41.59 s 
2024-12-11 19:00:40.712225:  
2024-12-11 19:00:40.718300: Epoch 70 
2024-12-11 19:00:40.722412: Current learning rate: 0.00338 
2024-12-11 19:01:22.293385: train_loss -0.509 
2024-12-11 19:01:22.299403: val_loss -0.489 
2024-12-11 19:01:22.301908: Pseudo dice [np.float32(0.6863), np.float32(0.8386)] 
2024-12-11 19:01:22.305919: Epoch time: 41.58 s 
2024-12-11 19:01:22.308426: Yayy! New best EMA pseudo Dice: 0.7387999892234802 
2024-12-11 19:01:23.136616:  
2024-12-11 19:01:23.142181: Epoch 71 
2024-12-11 19:01:23.145791: Current learning rate: 0.00328 
2024-12-11 19:02:04.731173: train_loss -0.5055 
2024-12-11 19:02:04.735274: val_loss -0.4726 
2024-12-11 19:02:04.738312: Pseudo dice [np.float32(0.6692), np.float32(0.814)] 
2024-12-11 19:02:04.741372: Epoch time: 41.6 s 
2024-12-11 19:02:04.744416: Yayy! New best EMA pseudo Dice: 0.7390999794006348 
2024-12-11 19:02:05.575316:  
2024-12-11 19:02:05.580881: Epoch 72 
2024-12-11 19:02:05.584427: Current learning rate: 0.00318 
2024-12-11 19:02:47.175888: train_loss -0.4985 
2024-12-11 19:02:47.181024: val_loss -0.5174 
2024-12-11 19:02:47.185585: Pseudo dice [np.float32(0.6318), np.float32(0.7825)] 
2024-12-11 19:02:47.189145: Epoch time: 41.6 s 
2024-12-11 19:02:47.786356:  
2024-12-11 19:02:47.791920: Epoch 73 
2024-12-11 19:02:47.795527: Current learning rate: 0.00308 
2024-12-11 19:03:29.413047: train_loss -0.4967 
2024-12-11 19:03:29.418025: val_loss -0.4955 
2024-12-11 19:03:29.421603: Pseudo dice [np.float32(0.6561), np.float32(0.7072)] 
2024-12-11 19:03:29.425163: Epoch time: 41.63 s 
2024-12-11 19:03:30.016372:  
2024-12-11 19:03:30.021404: Epoch 74 
2024-12-11 19:03:30.024440: Current learning rate: 0.00297 
2024-12-11 19:04:11.601343: train_loss -0.5158 
2024-12-11 19:04:11.607985: val_loss -0.4635 
2024-12-11 19:04:11.611553: Pseudo dice [np.float32(0.6544), np.float32(0.8108)] 
2024-12-11 19:04:11.614061: Epoch time: 41.59 s 
2024-12-11 19:04:12.347372:  
2024-12-11 19:04:12.352435: Epoch 75 
2024-12-11 19:04:12.354941: Current learning rate: 0.00287 
2024-12-11 19:04:53.947016: train_loss -0.5263 
2024-12-11 19:04:53.953124: val_loss -0.5423 
2024-12-11 19:04:53.956100: Pseudo dice [np.float32(0.6924), np.float32(0.825)] 
2024-12-11 19:04:53.959611: Epoch time: 41.6 s 
2024-12-11 19:04:54.547673:  
2024-12-11 19:04:54.552701: Epoch 76 
2024-12-11 19:04:54.556228: Current learning rate: 0.00277 
2024-12-11 19:05:36.122192: train_loss -0.5176 
2024-12-11 19:05:36.128757: val_loss -0.4758 
2024-12-11 19:05:36.131819: Pseudo dice [np.float32(0.6467), np.float32(0.8489)] 
2024-12-11 19:05:36.134947: Epoch time: 41.58 s 
2024-12-11 19:05:36.733175:  
2024-12-11 19:05:36.738737: Epoch 77 
2024-12-11 19:05:36.742782: Current learning rate: 0.00266 
2024-12-11 19:06:18.308889: train_loss -0.5209 
2024-12-11 19:06:18.313544: val_loss -0.5063 
2024-12-11 19:06:18.317579: Pseudo dice [np.float32(0.6823), np.float32(0.7954)] 
2024-12-11 19:06:18.320085: Epoch time: 41.58 s 
2024-12-11 19:06:18.914166:  
2024-12-11 19:06:18.920227: Epoch 78 
2024-12-11 19:06:18.923427: Current learning rate: 0.00256 
2024-12-11 19:07:00.501779: train_loss -0.5119 
2024-12-11 19:07:00.507849: val_loss -0.4936 
2024-12-11 19:07:00.511360: Pseudo dice [np.float32(0.678), np.float32(0.8169)] 
2024-12-11 19:07:00.514380: Epoch time: 41.59 s 
2024-12-11 19:07:01.117495:  
2024-12-11 19:07:01.121522: Epoch 79 
2024-12-11 19:07:01.124887: Current learning rate: 0.00245 
2024-12-11 19:07:42.696142: train_loss -0.5417 
2024-12-11 19:07:42.701266: val_loss -0.5532 
2024-12-11 19:07:42.704787: Pseudo dice [np.float32(0.6892), np.float32(0.8574)] 
2024-12-11 19:07:42.707815: Epoch time: 41.58 s 
2024-12-11 19:07:42.711340: Yayy! New best EMA pseudo Dice: 0.7401999831199646 
2024-12-11 19:07:43.547308:  
2024-12-11 19:07:43.552857: Epoch 80 
2024-12-11 19:07:43.556365: Current learning rate: 0.00235 
2024-12-11 19:08:25.153069: train_loss -0.5191 
2024-12-11 19:08:25.158661: val_loss -0.5167 
2024-12-11 19:08:25.162217: Pseudo dice [np.float32(0.6448), np.float32(0.8135)] 
2024-12-11 19:08:25.165267: Epoch time: 41.61 s 
2024-12-11 19:08:25.848328:  
2024-12-11 19:08:25.853456: Epoch 81 
2024-12-11 19:08:25.856987: Current learning rate: 0.00224 
2024-12-11 19:09:07.452549: train_loss -0.5302 
2024-12-11 19:09:07.458089: val_loss -0.5212 
2024-12-11 19:09:07.462133: Pseudo dice [np.float32(0.6521), np.float32(0.8284)] 
2024-12-11 19:09:07.464640: Epoch time: 41.61 s 
2024-12-11 19:09:08.065488:  
2024-12-11 19:09:08.071004: Epoch 82 
2024-12-11 19:09:08.074512: Current learning rate: 0.00214 
2024-12-11 19:09:49.646535: train_loss -0.5058 
2024-12-11 19:09:49.651995: val_loss -0.5388 
2024-12-11 19:09:49.655514: Pseudo dice [np.float32(0.6599), np.float32(0.8236)] 
2024-12-11 19:09:49.659026: Epoch time: 41.58 s 
2024-12-11 19:09:50.385694:  
2024-12-11 19:09:50.391237: Epoch 83 
2024-12-11 19:09:50.394314: Current learning rate: 0.00203 
2024-12-11 19:10:31.978946: train_loss -0.5356 
2024-12-11 19:10:31.985515: val_loss -0.5759 
2024-12-11 19:10:31.989084: Pseudo dice [np.float32(0.6626), np.float32(0.8115)] 
2024-12-11 19:10:31.991612: Epoch time: 41.59 s 
2024-12-11 19:10:32.570017:  
2024-12-11 19:10:32.575531: Epoch 84 
2024-12-11 19:10:32.579041: Current learning rate: 0.00192 
2024-12-11 19:11:14.148220: train_loss -0.5391 
2024-12-11 19:11:14.153798: val_loss -0.5422 
2024-12-11 19:11:14.157308: Pseudo dice [np.float32(0.6878), np.float32(0.842)] 
2024-12-11 19:11:14.159814: Epoch time: 41.58 s 
2024-12-11 19:11:14.163359: Yayy! New best EMA pseudo Dice: 0.7418000102043152 
2024-12-11 19:11:15.255094:  
2024-12-11 19:11:15.259629: Epoch 85 
2024-12-11 19:11:15.263234: Current learning rate: 0.00181 
2024-12-11 19:11:56.867512: train_loss -0.5432 
2024-12-11 19:11:56.873074: val_loss -0.5233 
2024-12-11 19:11:56.875606: Pseudo dice [np.float32(0.6276), np.float32(0.8431)] 
2024-12-11 19:11:56.879152: Epoch time: 41.61 s 
2024-12-11 19:11:57.441826:  
2024-12-11 19:11:57.446803: Epoch 86 
2024-12-11 19:11:57.450310: Current learning rate: 0.0017 
2024-12-11 19:12:39.008845: train_loss -0.5421 
2024-12-11 19:12:39.014409: val_loss -0.5226 
2024-12-11 19:12:39.017919: Pseudo dice [np.float32(0.6508), np.float32(0.8557)] 
2024-12-11 19:12:39.021441: Epoch time: 41.57 s 
2024-12-11 19:12:39.024470: Yayy! New best EMA pseudo Dice: 0.7423999905586243 
2024-12-11 19:12:39.829098:  
2024-12-11 19:12:39.834677: Epoch 87 
2024-12-11 19:12:39.837723: Current learning rate: 0.00159 
2024-12-11 19:13:21.415662: train_loss -0.5359 
2024-12-11 19:13:21.419703: val_loss -0.5191 
2024-12-11 19:13:21.423303: Pseudo dice [np.float32(0.6701), np.float32(0.8459)] 
2024-12-11 19:13:21.425839: Epoch time: 41.59 s 
2024-12-11 19:13:21.429861: Yayy! New best EMA pseudo Dice: 0.7439000010490417 
2024-12-11 19:13:22.260243:  
2024-12-11 19:13:22.265766: Epoch 88 
2024-12-11 19:13:22.268794: Current learning rate: 0.00148 
2024-12-11 19:14:03.845705: train_loss -0.5187 
2024-12-11 19:14:03.850237: val_loss -0.5447 
2024-12-11 19:14:03.854752: Pseudo dice [np.float32(0.647), np.float32(0.8399)] 
2024-12-11 19:14:03.857766: Epoch time: 41.59 s 
2024-12-11 19:14:04.426547:  
2024-12-11 19:14:04.432083: Epoch 89 
2024-12-11 19:14:04.435630: Current learning rate: 0.00137 
2024-12-11 19:14:46.003038: train_loss -0.5366 
2024-12-11 19:14:46.010288: val_loss -0.5536 
2024-12-11 19:14:46.013339: Pseudo dice [np.float32(0.6698), np.float32(0.8469)] 
2024-12-11 19:14:46.015891: Epoch time: 41.58 s 
2024-12-11 19:14:46.019950: Yayy! New best EMA pseudo Dice: 0.7452999949455261 
2024-12-11 19:14:46.835949:  
2024-12-11 19:14:46.841497: Epoch 90 
2024-12-11 19:14:46.845100: Current learning rate: 0.00126 
2024-12-11 19:15:28.393718: train_loss -0.5404 
2024-12-11 19:15:28.398795: val_loss -0.5451 
2024-12-11 19:15:28.401828: Pseudo dice [np.float32(0.6711), np.float32(0.8483)] 
2024-12-11 19:15:28.404855: Epoch time: 41.56 s 
2024-12-11 19:15:28.408378: Yayy! New best EMA pseudo Dice: 0.7468000054359436 
2024-12-11 19:15:29.383400:  
2024-12-11 19:15:29.389054: Epoch 91 
2024-12-11 19:15:29.392627: Current learning rate: 0.00115 
2024-12-11 19:16:10.973132: train_loss -0.5563 
2024-12-11 19:16:10.979648: val_loss -0.5215 
2024-12-11 19:16:10.982159: Pseudo dice [np.float32(0.6826), np.float32(0.8326)] 
2024-12-11 19:16:10.985669: Epoch time: 41.59 s 
2024-12-11 19:16:10.989176: Yayy! New best EMA pseudo Dice: 0.7477999925613403 
2024-12-11 19:16:11.826077:  
2024-12-11 19:16:11.831597: Epoch 92 
2024-12-11 19:16:11.835109: Current learning rate: 0.00103 
2024-12-11 19:16:53.464350: train_loss -0.5471 
2024-12-11 19:16:53.470913: val_loss -0.5342 
2024-12-11 19:16:53.473521: Pseudo dice [np.float32(0.6657), np.float32(0.8161)] 
2024-12-11 19:16:53.477618: Epoch time: 41.64 s 
2024-12-11 19:16:54.062915:  
2024-12-11 19:16:54.068492: Epoch 93 
2024-12-11 19:16:54.072636: Current learning rate: 0.00091 
2024-12-11 19:17:35.635769: train_loss -0.5479 
2024-12-11 19:17:35.641422: val_loss -0.5228 
2024-12-11 19:17:35.644595: Pseudo dice [np.float32(0.6804), np.float32(0.8554)] 
2024-12-11 19:17:35.648165: Epoch time: 41.57 s 
2024-12-11 19:17:35.651225: Yayy! New best EMA pseudo Dice: 0.7491999864578247 
2024-12-11 19:17:36.462338:  
2024-12-11 19:17:36.467912: Epoch 94 
2024-12-11 19:17:36.471425: Current learning rate: 0.00079 
2024-12-11 19:18:18.025120: train_loss -0.5648 
2024-12-11 19:18:18.030681: val_loss -0.5066 
2024-12-11 19:18:18.034338: Pseudo dice [np.float32(0.6555), np.float32(0.8354)] 
2024-12-11 19:18:18.036843: Epoch time: 41.56 s 
2024-12-11 19:18:18.606953:  
2024-12-11 19:18:18.613503: Epoch 95 
2024-12-11 19:18:18.616009: Current learning rate: 0.00067 
2024-12-11 19:19:00.185143: train_loss -0.5472 
2024-12-11 19:19:00.190691: val_loss -0.5394 
2024-12-11 19:19:00.193830: Pseudo dice [np.float32(0.7), np.float32(0.8403)] 
2024-12-11 19:19:00.196871: Epoch time: 41.58 s 
2024-12-11 19:19:00.200901: Yayy! New best EMA pseudo Dice: 0.7509999871253967 
2024-12-11 19:19:01.010960:  
2024-12-11 19:19:01.016574: Epoch 96 
2024-12-11 19:19:01.020120: Current learning rate: 0.00055 
2024-12-11 19:19:42.588824: train_loss -0.5602 
2024-12-11 19:19:42.594495: val_loss -0.5029 
2024-12-11 19:19:42.598052: Pseudo dice [np.float32(0.6841), np.float32(0.8487)] 
2024-12-11 19:19:42.601103: Epoch time: 41.58 s 
2024-12-11 19:19:42.603632: Yayy! New best EMA pseudo Dice: 0.7524999976158142 
2024-12-11 19:19:43.437056:  
2024-12-11 19:19:43.443637: Epoch 97 
2024-12-11 19:19:43.446750: Current learning rate: 0.00043 
2024-12-11 19:20:25.034564: train_loss -0.5547 
2024-12-11 19:20:25.040163: val_loss -0.5264 
2024-12-11 19:20:25.043244: Pseudo dice [np.float32(0.6544), np.float32(0.8762)] 
2024-12-11 19:20:25.046338: Epoch time: 41.6 s 
2024-12-11 19:20:25.049403: Yayy! New best EMA pseudo Dice: 0.7537999749183655 
2024-12-11 19:20:25.869812:  
2024-12-11 19:20:25.875423: Epoch 98 
2024-12-11 19:20:25.878514: Current learning rate: 0.0003 
2024-12-11 19:21:07.478481: train_loss -0.5807 
2024-12-11 19:21:07.484024: val_loss -0.5388 
2024-12-11 19:21:07.487533: Pseudo dice [np.float32(0.6886), np.float32(0.832)] 
2024-12-11 19:21:07.490039: Epoch time: 41.61 s 
2024-12-11 19:21:07.494049: Yayy! New best EMA pseudo Dice: 0.7544999718666077 
2024-12-11 19:21:08.497908:  
2024-12-11 19:21:08.503179: Epoch 99 
2024-12-11 19:21:08.506749: Current learning rate: 0.00016 
2024-12-11 19:21:50.090449: train_loss -0.5399 
2024-12-11 19:21:50.096470: val_loss -0.5127 
2024-12-11 19:21:50.099977: Pseudo dice [np.float32(0.6722), np.float32(0.8387)] 
2024-12-11 19:21:50.103127: Epoch time: 41.59 s 
2024-12-11 19:21:50.105634: Yayy! New best EMA pseudo Dice: 0.7545999884605408 
2024-12-11 19:21:51.206799: Training done. 
2024-12-11 19:21:51.244257: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset008_HepaticVessel\splits_final.json 
2024-12-11 19:21:51.249255: The split file contains 5 splits. 
2024-12-11 19:21:51.254908: Desired fold for training: 0 
2024-12-11 19:21:51.259906: This split has 242 training and 61 validation cases. 
2024-12-11 19:21:51.264958: predicting hepaticvessel_018 
2024-12-11 19:21:51.270958: hepaticvessel_018, shape torch.Size([1, 36, 456, 456]), rank 0 
2024-12-11 19:21:55.153493: predicting hepaticvessel_019 
2024-12-11 19:21:55.163154: hepaticvessel_019, shape torch.Size([1, 45, 496, 496]), rank 0 
2024-12-11 19:21:59.981468: predicting hepaticvessel_026 
2024-12-11 19:21:59.993977: hepaticvessel_026, shape torch.Size([1, 52, 521, 521]), rank 0 
2024-12-11 19:22:08.549757: predicting hepaticvessel_028 
2024-12-11 19:22:08.562373: hepaticvessel_028, shape torch.Size([1, 40, 502, 502]), rank 0 
2024-12-11 19:22:11.790843: predicting hepaticvessel_030 
2024-12-11 19:22:11.802074: hepaticvessel_030, shape torch.Size([1, 39, 608, 608]), rank 0 
2024-12-11 19:22:17.523587: predicting hepaticvessel_050 
2024-12-11 19:22:17.536250: hepaticvessel_050, shape torch.Size([1, 41, 560, 560]), rank 0 
2024-12-11 19:22:23.255126: predicting hepaticvessel_053 
2024-12-11 19:22:23.266315: hepaticvessel_053, shape torch.Size([1, 42, 545, 545]), rank 0 
2024-12-11 19:22:28.983376: predicting hepaticvessel_058 
2024-12-11 19:22:28.995035: hepaticvessel_058, shape torch.Size([1, 33, 426, 426]), rank 0 
2024-12-11 19:22:32.210652: predicting hepaticvessel_066 
2024-12-11 19:22:32.220303: hepaticvessel_066, shape torch.Size([1, 49, 501, 501]), rank 0 
2024-12-11 19:22:37.054199: predicting hepaticvessel_077 
2024-12-11 19:22:37.065885: hepaticvessel_077, shape torch.Size([1, 39, 442, 442]), rank 0 
2024-12-11 19:22:40.290791: predicting hepaticvessel_080 
2024-12-11 19:22:40.300401: hepaticvessel_080, shape torch.Size([1, 45, 626, 626]), rank 0 
2024-12-11 19:22:48.857768: predicting hepaticvessel_082 
2024-12-11 19:22:48.873985: hepaticvessel_082, shape torch.Size([1, 50, 603, 603]), rank 0 
2024-12-11 19:22:57.434919: predicting hepaticvessel_084 
2024-12-11 19:22:57.447926: hepaticvessel_084, shape torch.Size([1, 45, 526, 526]), rank 0 
2024-12-11 19:23:06.008804: predicting hepaticvessel_085 
2024-12-11 19:23:06.020403: hepaticvessel_085, shape torch.Size([1, 36, 476, 476]), rank 0 
2024-12-11 19:23:09.244071: predicting hepaticvessel_087 
2024-12-11 19:23:09.253720: hepaticvessel_087, shape torch.Size([1, 39, 540, 540]), rank 0 
2024-12-11 19:23:14.964859: predicting hepaticvessel_098 
2024-12-11 19:23:14.976367: hepaticvessel_098, shape torch.Size([1, 37, 491, 491]), rank 0 
2024-12-11 19:23:18.206069: predicting hepaticvessel_100 
2024-12-11 19:23:18.216302: hepaticvessel_100, shape torch.Size([1, 46, 476, 476]), rank 0 
2024-12-11 19:23:23.038983: predicting hepaticvessel_110 
2024-12-11 19:23:23.049488: hepaticvessel_110, shape torch.Size([1, 49, 617, 617]), rank 0 
2024-12-11 19:23:31.606221: predicting hepaticvessel_112 
2024-12-11 19:23:31.618858: hepaticvessel_112, shape torch.Size([1, 44, 597, 597]), rank 0 
2024-12-11 19:23:40.173408: predicting hepaticvessel_127 
2024-12-11 19:23:40.185915: hepaticvessel_127, shape torch.Size([1, 81, 391, 391]), rank 0 
2024-12-11 19:23:48.210565: predicting hepaticvessel_129 
2024-12-11 19:23:48.222072: hepaticvessel_129, shape torch.Size([1, 59, 542, 542]), rank 0 
2024-12-11 19:23:59.621005: predicting hepaticvessel_146 
2024-12-11 19:23:59.636020: hepaticvessel_146, shape torch.Size([1, 58, 526, 526]), rank 0 
2024-12-11 19:24:11.028613: predicting hepaticvessel_147 
2024-12-11 19:24:11.043291: hepaticvessel_147, shape torch.Size([1, 58, 612, 612]), rank 0 
2024-12-11 19:24:22.456392: predicting hepaticvessel_150 
2024-12-11 19:24:22.471507: hepaticvessel_150, shape torch.Size([1, 88, 526, 526]), rank 0 
2024-12-11 19:24:39.571852: predicting hepaticvessel_157 
2024-12-11 19:24:39.587358: hepaticvessel_157, shape torch.Size([1, 54, 626, 626]), rank 0 
2024-12-11 19:24:48.179862: predicting hepaticvessel_161 
2024-12-11 19:24:48.197471: hepaticvessel_161, shape torch.Size([1, 36, 451, 451]), rank 0 
2024-12-11 19:24:51.424352: predicting hepaticvessel_164 
2024-12-11 19:24:51.434545: hepaticvessel_164, shape torch.Size([1, 40, 461, 461]), rank 0 
2024-12-11 19:24:54.657745: predicting hepaticvessel_167 
2024-12-11 19:24:54.668146: hepaticvessel_167, shape torch.Size([1, 54, 501, 501]), rank 0 
2024-12-11 19:24:59.498461: predicting hepaticvessel_175 
2024-12-11 19:24:59.512062: hepaticvessel_175, shape torch.Size([1, 41, 451, 451]), rank 0 
2024-12-11 19:25:02.743479: predicting hepaticvessel_194 
2024-12-11 19:25:02.753654: hepaticvessel_194, shape torch.Size([1, 34, 550, 550]), rank 0 
2024-12-11 19:25:08.469369: predicting hepaticvessel_206 
2024-12-11 19:25:08.479459: hepaticvessel_206, shape torch.Size([1, 48, 432, 432]), rank 0 
2024-12-11 19:25:13.297943: predicting hepaticvessel_213 
2024-12-11 19:25:13.308450: hepaticvessel_213, shape torch.Size([1, 52, 591, 591]), rank 0 
2024-12-11 19:25:21.868829: predicting hepaticvessel_217 
2024-12-11 19:25:21.883446: hepaticvessel_217, shape torch.Size([1, 47, 626, 626]), rank 0 
2024-12-11 19:25:30.450247: predicting hepaticvessel_218 
2024-12-11 19:25:30.464410: hepaticvessel_218, shape torch.Size([1, 50, 469, 469]), rank 0 
2024-12-11 19:25:35.294926: predicting hepaticvessel_224 
2024-12-11 19:25:35.305940: hepaticvessel_224, shape torch.Size([1, 45, 487, 487]), rank 0 
2024-12-11 19:25:40.136760: predicting hepaticvessel_234 
2024-12-11 19:25:40.147403: hepaticvessel_234, shape torch.Size([1, 52, 567, 567]), rank 0 
2024-12-11 19:25:48.703852: predicting hepaticvessel_244 
2024-12-11 19:25:48.717374: hepaticvessel_244, shape torch.Size([1, 34, 401, 401]), rank 0 
2024-12-11 19:25:51.942314: predicting hepaticvessel_248 
2024-12-11 19:25:51.950820: hepaticvessel_248, shape torch.Size([1, 36, 436, 436]), rank 0 
2024-12-11 19:25:55.166113: predicting hepaticvessel_266 
2024-12-11 19:25:55.177270: hepaticvessel_266, shape torch.Size([1, 41, 511, 511]), rank 0 
2024-12-11 19:25:58.404584: predicting hepaticvessel_269 
2024-12-11 19:25:58.416201: hepaticvessel_269, shape torch.Size([1, 51, 595, 595]), rank 0 
2024-12-11 19:26:06.973863: predicting hepaticvessel_270 
2024-12-11 19:26:06.991876: hepaticvessel_270, shape torch.Size([1, 44, 413, 413]), rank 0 
2024-12-11 19:26:11.818979: predicting hepaticvessel_272 
2024-12-11 19:26:11.829555: hepaticvessel_272, shape torch.Size([1, 47, 526, 526]), rank 0 
2024-12-11 19:26:20.384264: predicting hepaticvessel_274 
2024-12-11 19:26:20.395917: hepaticvessel_274, shape torch.Size([1, 47, 563, 563]), rank 0 
2024-12-11 19:26:28.950868: predicting hepaticvessel_275 
2024-12-11 19:26:28.965379: hepaticvessel_275, shape torch.Size([1, 39, 504, 504]), rank 0 
2024-12-11 19:26:32.201362: predicting hepaticvessel_282 
2024-12-11 19:26:32.213116: hepaticvessel_282, shape torch.Size([1, 40, 551, 551]), rank 0 
2024-12-11 19:26:37.948522: predicting hepaticvessel_309 
2024-12-11 19:26:37.961029: hepaticvessel_309, shape torch.Size([1, 45, 580, 580]), rank 0 
2024-12-11 19:26:46.522684: predicting hepaticvessel_329 
2024-12-11 19:26:46.535752: hepaticvessel_329, shape torch.Size([1, 49, 528, 528]), rank 0 
2024-12-11 19:26:55.096700: predicting hepaticvessel_333 
2024-12-11 19:26:55.108945: hepaticvessel_333, shape torch.Size([1, 54, 503, 503]), rank 0 
2024-12-11 19:26:59.941599: predicting hepaticvessel_358 
2024-12-11 19:26:59.954304: hepaticvessel_358, shape torch.Size([1, 42, 413, 413]), rank 0 
2024-12-11 19:27:03.184786: predicting hepaticvessel_359 
2024-12-11 19:27:03.195486: hepaticvessel_359, shape torch.Size([1, 47, 479, 479]), rank 0 
2024-12-11 19:27:08.036143: predicting hepaticvessel_361 
2024-12-11 19:27:08.049237: hepaticvessel_361, shape torch.Size([1, 50, 576, 576]), rank 0 
2024-12-11 19:27:16.626030: predicting hepaticvessel_363 
2024-12-11 19:27:16.639195: hepaticvessel_363, shape torch.Size([1, 40, 451, 451]), rank 0 
2024-12-11 19:27:19.867479: predicting hepaticvessel_368 
2024-12-11 19:27:19.877988: hepaticvessel_368, shape torch.Size([1, 44, 469, 469]), rank 0 
2024-12-11 19:27:24.700990: predicting hepaticvessel_375 
2024-12-11 19:27:24.711011: hepaticvessel_375, shape torch.Size([1, 53, 504, 504]), rank 0 
2024-12-11 19:27:29.549618: predicting hepaticvessel_422 
2024-12-11 19:27:29.561711: hepaticvessel_422, shape torch.Size([1, 47, 454, 454]), rank 0 
2024-12-11 19:27:34.392975: predicting hepaticvessel_424 
2024-12-11 19:27:34.406482: hepaticvessel_424, shape torch.Size([1, 40, 469, 469]), rank 0 
2024-12-11 19:27:37.638501: predicting hepaticvessel_437 
2024-12-11 19:27:37.649011: hepaticvessel_437, shape torch.Size([1, 41, 622, 622]), rank 0 
2024-12-11 19:27:43.378912: predicting hepaticvessel_441 
2024-12-11 19:27:43.395008: hepaticvessel_441, shape torch.Size([1, 49, 532, 532]), rank 0 
2024-12-11 19:27:51.990716: predicting hepaticvessel_444 
2024-12-11 19:27:52.002824: hepaticvessel_444, shape torch.Size([1, 44, 454, 454]), rank 0 
2024-12-11 19:27:56.826545: predicting hepaticvessel_445 
2024-12-11 19:27:56.837203: hepaticvessel_445, shape torch.Size([1, 50, 513, 513]), rank 0 
2024-12-11 19:28:05.399284: predicting hepaticvessel_458 
2024-12-11 19:28:05.411397: hepaticvessel_458, shape torch.Size([1, 42, 546, 546]), rank 0 
2024-12-11 19:28:26.579854: Validation complete 
2024-12-11 19:28:26.585378: Mean Validation Dice:  0.6672423165121564 
