
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-22 04:02:44.551244: do_dummy_2d_data_aug: False 
2025-03-22 04:02:44.762839: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset137_BraTS2021\splits_final.json 
2025-03-22 04:02:44.774840: The split file contains 5 splits. 
2025-03-22 04:02:44.777841: Desired fold for training: 1 
2025-03-22 04:02:44.780844: This split has 1001 training and 250 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_1_spacing_batchsize_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [96, 128, 96], 'median_image_size_in_voxels': [140.0, 171.0, 137.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset137_BraTS2021', 'plans_name': 'nnUNetPlans_1_spacing_batchsize_4', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [140, 171, 137], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 95242.25, 'mean': 871.816650390625, 'median': 407.0, 'min': 0.10992202162742615, 'percentile_00_5': 55.0, 'percentile_99_5': 5825.0, 'std': 2023.5313720703125}, '1': {'max': 1905559.25, 'mean': 1698.2144775390625, 'median': 552.0, 'min': 0.0, 'percentile_00_5': 47.0, 'percentile_99_5': 8322.0, 'std': 18787.4140625}, '2': {'max': 4438107.0, 'mean': 2141.349365234375, 'median': 738.0, 'min': 0.0, 'percentile_00_5': 110.0, 'percentile_99_5': 10396.0, 'std': 45159.37890625}, '3': {'max': 580014.3125, 'mean': 995.436279296875, 'median': 512.3143920898438, 'min': 0.0, 'percentile_00_5': 108.0, 'percentile_99_5': 11925.0, 'std': 4629.87939453125}}} 
 
2025-03-22 04:03:28.965297: unpacking dataset... 
2025-03-22 04:03:30.595972: unpacking done... 
2025-03-22 04:03:33.708230:  
2025-03-22 04:03:33.714245: Epoch 0 
2025-03-22 04:03:33.718256: Current learning rate: 0.01 
2025-03-22 04:04:21.322481: train_loss -0.409 
2025-03-22 04:04:21.330000: val_loss -0.5833 
2025-03-22 04:04:21.336017: Pseudo dice [np.float64(0.8143), np.float64(0.7041), np.float64(0.7832)] 
2025-03-22 04:04:21.342536: Epoch time: 47.61 s 
2025-03-22 04:04:21.350067: Yayy! New best EMA pseudo Dice: 0.7672 
2025-03-22 04:04:22.127469:  
2025-03-22 04:04:22.132989: Epoch 1 
2025-03-22 04:04:22.139009: Current learning rate: 0.00999 
2025-03-22 04:05:05.465328: train_loss -0.6422 
2025-03-22 04:05:05.472852: val_loss -0.6453 
2025-03-22 04:05:05.480377: Pseudo dice [np.float64(0.8512), np.float64(0.7521), np.float64(0.7783)] 
2025-03-22 04:05:05.486895: Epoch time: 43.34 s 
2025-03-22 04:05:05.492915: Yayy! New best EMA pseudo Dice: 0.7699 
2025-03-22 04:05:06.355170:  
2025-03-22 04:05:06.360687: Epoch 2 
2025-03-22 04:05:06.365200: Current learning rate: 0.00998 
2025-03-22 04:05:49.717771: train_loss -0.6966 
2025-03-22 04:05:49.725292: val_loss -0.74 
2025-03-22 04:05:49.730305: Pseudo dice [np.float64(0.8952), np.float64(0.8512), np.float64(0.8531)] 
2025-03-22 04:05:49.737832: Epoch time: 43.36 s 
2025-03-22 04:05:49.743855: Yayy! New best EMA pseudo Dice: 0.7795 
2025-03-22 04:05:50.636284:  
2025-03-22 04:05:50.641804: Epoch 3 
2025-03-22 04:05:50.649337: Current learning rate: 0.00997 
2025-03-22 04:06:33.863698: train_loss -0.7235 
2025-03-22 04:06:33.870720: val_loss -0.7317 
2025-03-22 04:06:33.877250: Pseudo dice [np.float64(0.8956), np.float64(0.8379), np.float64(0.8626)] 
2025-03-22 04:06:33.883766: Epoch time: 43.23 s 
2025-03-22 04:06:33.888784: Yayy! New best EMA pseudo Dice: 0.7881 
2025-03-22 04:06:34.946970:  
2025-03-22 04:06:34.953490: Epoch 4 
2025-03-22 04:06:34.958508: Current learning rate: 0.00996 
2025-03-22 04:07:18.284058: train_loss -0.7278 
2025-03-22 04:07:18.291581: val_loss -0.764 
2025-03-22 04:07:18.297097: Pseudo dice [np.float64(0.9026), np.float64(0.8468), np.float64(0.8558)] 
2025-03-22 04:07:18.303114: Epoch time: 43.34 s 
2025-03-22 04:07:18.310642: Yayy! New best EMA pseudo Dice: 0.7961 
2025-03-22 04:07:19.200228:  
2025-03-22 04:07:19.206324: Epoch 5 
2025-03-22 04:07:19.209956: Current learning rate: 0.00995 
2025-03-22 04:08:02.510370: train_loss -0.7675 
2025-03-22 04:08:02.517987: val_loss -0.7523 
2025-03-22 04:08:02.523588: Pseudo dice [np.float64(0.9139), np.float64(0.8769), np.float64(0.8659)] 
2025-03-22 04:08:02.528145: Epoch time: 43.31 s 
2025-03-22 04:08:02.532228: Yayy! New best EMA pseudo Dice: 0.8051 
2025-03-22 04:08:03.351203:  
2025-03-22 04:08:03.359345: Epoch 6 
2025-03-22 04:08:03.365444: Current learning rate: 0.00995 
2025-03-22 04:08:46.852576: train_loss -0.7534 
2025-03-22 04:08:46.861102: val_loss -0.7624 
2025-03-22 04:08:46.867623: Pseudo dice [np.float64(0.9135), np.float64(0.8758), np.float64(0.8693)] 
2025-03-22 04:08:46.873640: Epoch time: 43.5 s 
2025-03-22 04:08:46.879161: Yayy! New best EMA pseudo Dice: 0.8132 
2025-03-22 04:08:47.749638:  
2025-03-22 04:08:47.755665: Epoch 7 
2025-03-22 04:08:47.760209: Current learning rate: 0.00994 
2025-03-22 04:09:30.840980: train_loss -0.7777 
2025-03-22 04:09:30.848499: val_loss -0.7526 
2025-03-22 04:09:30.852005: Pseudo dice [np.float64(0.9064), np.float64(0.875), np.float64(0.8894)] 
2025-03-22 04:09:30.856023: Epoch time: 43.09 s 
2025-03-22 04:09:30.862036: Yayy! New best EMA pseudo Dice: 0.8209 
2025-03-22 04:09:31.740431:  
2025-03-22 04:09:31.747995: Epoch 8 
2025-03-22 04:09:31.754065: Current learning rate: 0.00993 
2025-03-22 04:10:16.306195: train_loss -0.7904 
2025-03-22 04:10:16.312718: val_loss -0.797 
2025-03-22 04:10:16.317731: Pseudo dice [np.float64(0.9296), np.float64(0.8969), np.float64(0.8836)] 
2025-03-22 04:10:16.324255: Epoch time: 44.57 s 
2025-03-22 04:10:16.332792: Yayy! New best EMA pseudo Dice: 0.8291 
2025-03-22 04:10:17.263967:  
2025-03-22 04:10:17.269984: Epoch 9 
2025-03-22 04:10:17.274997: Current learning rate: 0.00992 
2025-03-22 04:11:00.483574: train_loss -0.7951 
2025-03-22 04:11:00.490586: val_loss -0.7815 
2025-03-22 04:11:00.494598: Pseudo dice [np.float64(0.9183), np.float64(0.8813), np.float64(0.8756)] 
2025-03-22 04:11:00.499615: Epoch time: 43.22 s 
2025-03-22 04:11:00.503626: Yayy! New best EMA pseudo Dice: 0.8354 
2025-03-22 04:11:01.360003:  
2025-03-22 04:11:01.366071: Epoch 10 
2025-03-22 04:11:01.373186: Current learning rate: 0.00991 
2025-03-22 04:11:44.960908: train_loss -0.7805 
2025-03-22 04:11:44.968441: val_loss -0.8038 
2025-03-22 04:11:44.972961: Pseudo dice [np.float64(0.9254), np.float64(0.9034), np.float64(0.8838)] 
2025-03-22 04:11:44.978663: Epoch time: 43.6 s 
2025-03-22 04:11:44.985181: Yayy! New best EMA pseudo Dice: 0.8423 
2025-03-22 04:11:45.874132:  
2025-03-22 04:11:45.881699: Epoch 11 
2025-03-22 04:11:45.886268: Current learning rate: 0.0099 
2025-03-22 04:12:29.266316: train_loss -0.7985 
2025-03-22 04:12:29.272832: val_loss -0.7765 
2025-03-22 04:12:29.278855: Pseudo dice [np.float64(0.9238), np.float64(0.9085), np.float64(0.8855)] 
2025-03-22 04:12:29.287379: Epoch time: 43.39 s 
2025-03-22 04:12:29.295409: Yayy! New best EMA pseudo Dice: 0.8487 
2025-03-22 04:12:30.375188:  
2025-03-22 04:12:30.381775: Epoch 12 
2025-03-22 04:12:30.386858: Current learning rate: 0.00989 
2025-03-22 04:13:13.811387: train_loss -0.7971 
2025-03-22 04:13:13.817907: val_loss -0.8051 
2025-03-22 04:13:13.823926: Pseudo dice [np.float64(0.9308), np.float64(0.9286), np.float64(0.9054)] 
2025-03-22 04:13:13.830445: Epoch time: 43.44 s 
2025-03-22 04:13:13.835456: Yayy! New best EMA pseudo Dice: 0.8559 
2025-03-22 04:13:14.626268:  
2025-03-22 04:13:14.631785: Epoch 13 
2025-03-22 04:13:14.636800: Current learning rate: 0.00988 
2025-03-22 04:13:57.763775: train_loss -0.8095 
2025-03-22 04:13:57.771346: val_loss -0.8216 
2025-03-22 04:13:57.775383: Pseudo dice [np.float64(0.9288), np.float64(0.9312), np.float64(0.907)] 
2025-03-22 04:13:57.780452: Epoch time: 43.14 s 
2025-03-22 04:13:57.785017: Yayy! New best EMA pseudo Dice: 0.8626 
2025-03-22 04:13:58.624835:  
2025-03-22 04:13:58.630349: Epoch 14 
2025-03-22 04:13:58.635364: Current learning rate: 0.00987 
2025-03-22 04:14:41.723768: train_loss -0.8006 
2025-03-22 04:14:41.731283: val_loss -0.7655 
2025-03-22 04:14:41.737803: Pseudo dice [np.float64(0.917), np.float64(0.8882), np.float64(0.8909)] 
2025-03-22 04:14:41.745325: Epoch time: 43.1 s 
2025-03-22 04:14:41.752847: Yayy! New best EMA pseudo Dice: 0.8662 
2025-03-22 04:14:42.644649:  
2025-03-22 04:14:42.650667: Epoch 15 
2025-03-22 04:14:42.654681: Current learning rate: 0.00986 
2025-03-22 04:15:25.557670: train_loss -0.804 
2025-03-22 04:15:25.564957: val_loss -0.7942 
2025-03-22 04:15:25.570973: Pseudo dice [np.float64(0.9265), np.float64(0.9146), np.float64(0.8988)] 
2025-03-22 04:15:25.576992: Epoch time: 42.91 s 
2025-03-22 04:15:25.582515: Yayy! New best EMA pseudo Dice: 0.8709 
2025-03-22 04:15:26.441582:  
2025-03-22 04:15:26.448110: Epoch 16 
2025-03-22 04:15:26.453131: Current learning rate: 0.00986 
2025-03-22 04:16:09.497841: train_loss -0.8083 
2025-03-22 04:16:09.506861: val_loss -0.8312 
2025-03-22 04:16:09.512876: Pseudo dice [np.float64(0.9223), np.float64(0.9205), np.float64(0.8982)] 
2025-03-22 04:16:09.519393: Epoch time: 43.06 s 
2025-03-22 04:16:09.525412: Yayy! New best EMA pseudo Dice: 0.8752 
2025-03-22 04:16:10.437380:  
2025-03-22 04:16:10.443466: Epoch 17 
2025-03-22 04:16:10.447532: Current learning rate: 0.00985 
2025-03-22 04:16:54.351730: train_loss -0.8104 
2025-03-22 04:16:54.360264: val_loss -0.8219 
2025-03-22 04:16:54.366793: Pseudo dice [np.float64(0.9385), np.float64(0.9085), np.float64(0.8944)] 
2025-03-22 04:16:54.373328: Epoch time: 43.92 s 
2025-03-22 04:16:54.380510: Yayy! New best EMA pseudo Dice: 0.879 
2025-03-22 04:16:55.270421:  
2025-03-22 04:16:55.275945: Epoch 18 
2025-03-22 04:16:55.281585: Current learning rate: 0.00984 
2025-03-22 04:17:38.414578: train_loss -0.8117 
2025-03-22 04:17:38.421117: val_loss -0.8031 
2025-03-22 04:17:38.426131: Pseudo dice [np.float64(0.9344), np.float64(0.9035), np.float64(0.8913)] 
2025-03-22 04:17:38.431141: Epoch time: 43.15 s 
2025-03-22 04:17:38.436152: Yayy! New best EMA pseudo Dice: 0.8821 
2025-03-22 04:17:39.326789:  
2025-03-22 04:17:39.332383: Epoch 19 
2025-03-22 04:17:39.337448: Current learning rate: 0.00983 
2025-03-22 04:18:28.245828: train_loss -0.8137 
2025-03-22 04:18:28.254860: val_loss -0.8392 
2025-03-22 04:18:28.262384: Pseudo dice [np.float64(0.9419), np.float64(0.9283), np.float64(0.9029)] 
2025-03-22 04:18:28.269966: Epoch time: 48.92 s 
2025-03-22 04:18:28.277142: Yayy! New best EMA pseudo Dice: 0.8863 
2025-03-22 04:18:29.394738:  
2025-03-22 04:18:29.403363: Epoch 20 
2025-03-22 04:18:29.407564: Current learning rate: 0.00982 
2025-03-22 04:19:12.581211: train_loss -0.8137 
2025-03-22 04:19:12.588741: val_loss -0.8031 
2025-03-22 04:19:12.595264: Pseudo dice [np.float64(0.9293), np.float64(0.916), np.float64(0.89)] 
2025-03-22 04:19:12.600280: Epoch time: 43.19 s 
2025-03-22 04:19:12.605825: Yayy! New best EMA pseudo Dice: 0.8889 
2025-03-22 04:19:13.489866:  
2025-03-22 04:19:13.496967: Epoch 21 
2025-03-22 04:19:13.503492: Current learning rate: 0.00981 
2025-03-22 04:19:56.770134: train_loss -0.8154 
2025-03-22 04:19:56.779158: val_loss -0.8022 
2025-03-22 04:19:56.786176: Pseudo dice [np.float64(0.9328), np.float64(0.9117), np.float64(0.8902)] 
2025-03-22 04:19:56.791698: Epoch time: 43.28 s 
2025-03-22 04:19:56.797716: Yayy! New best EMA pseudo Dice: 0.8912 
2025-03-22 04:19:57.619760:  
2025-03-22 04:19:57.627811: Epoch 22 
2025-03-22 04:19:57.631361: Current learning rate: 0.0098 
2025-03-22 04:20:41.076916: train_loss -0.8168 
2025-03-22 04:20:41.084436: val_loss -0.8134 
2025-03-22 04:20:41.090956: Pseudo dice [np.float64(0.9365), np.float64(0.9104), np.float64(0.9028)] 
2025-03-22 04:20:41.097979: Epoch time: 43.46 s 
2025-03-22 04:20:41.104504: Yayy! New best EMA pseudo Dice: 0.8937 
2025-03-22 04:20:41.972523:  
2025-03-22 04:20:41.980042: Epoch 23 
2025-03-22 04:20:41.985561: Current learning rate: 0.00979 
2025-03-22 04:21:25.365580: train_loss -0.8238 
2025-03-22 04:21:25.374793: val_loss -0.8195 
2025-03-22 04:21:25.381905: Pseudo dice [np.float64(0.9358), np.float64(0.8907), np.float64(0.9015)] 
2025-03-22 04:21:25.389051: Epoch time: 43.39 s 
2025-03-22 04:21:25.397173: Yayy! New best EMA pseudo Dice: 0.8953 
2025-03-22 04:21:26.204938:  
2025-03-22 04:21:26.210463: Epoch 24 
2025-03-22 04:21:26.215481: Current learning rate: 0.00978 
2025-03-22 04:22:09.469907: train_loss -0.8037 
2025-03-22 04:22:09.476553: val_loss -0.7702 
2025-03-22 04:22:09.481131: Pseudo dice [np.float64(0.9204), np.float64(0.8957), np.float64(0.8734)] 
2025-03-22 04:22:09.487205: Epoch time: 43.27 s 
2025-03-22 04:22:09.492220: Yayy! New best EMA pseudo Dice: 0.8954 
2025-03-22 04:22:10.342247:  
2025-03-22 04:22:10.350453: Epoch 25 
2025-03-22 04:22:10.357105: Current learning rate: 0.00977 
2025-03-22 04:22:53.412382: train_loss -0.8149 
2025-03-22 04:22:53.421932: val_loss -0.7912 
2025-03-22 04:22:53.427955: Pseudo dice [np.float64(0.9248), np.float64(0.9139), np.float64(0.8941)] 
2025-03-22 04:22:53.434476: Epoch time: 43.07 s 
2025-03-22 04:22:53.441502: Yayy! New best EMA pseudo Dice: 0.8969 
2025-03-22 04:22:54.258562:  
2025-03-22 04:22:54.266085: Epoch 26 
2025-03-22 04:22:54.270598: Current learning rate: 0.00977 
2025-03-22 04:23:37.417165: train_loss -0.8103 
2025-03-22 04:23:37.425699: val_loss -0.8146 
2025-03-22 04:23:37.433226: Pseudo dice [np.float64(0.9289), np.float64(0.9243), np.float64(0.8972)] 
2025-03-22 04:23:37.439750: Epoch time: 43.16 s 
2025-03-22 04:23:37.446277: Yayy! New best EMA pseudo Dice: 0.8989 
2025-03-22 04:23:38.300257:  
2025-03-22 04:23:38.307869: Epoch 27 
2025-03-22 04:23:38.313560: Current learning rate: 0.00976 
2025-03-22 04:24:21.619186: train_loss -0.806 
2025-03-22 04:24:21.629229: val_loss -0.8331 
2025-03-22 04:24:21.635750: Pseudo dice [np.float64(0.9287), np.float64(0.9306), np.float64(0.9077)] 
2025-03-22 04:24:21.643273: Epoch time: 43.32 s 
2025-03-22 04:24:21.648286: Yayy! New best EMA pseudo Dice: 0.9013 
2025-03-22 04:24:22.688790:  
2025-03-22 04:24:22.694311: Epoch 28 
2025-03-22 04:24:22.698917: Current learning rate: 0.00975 
2025-03-22 04:25:05.927088: train_loss -0.8304 
2025-03-22 04:25:05.933645: val_loss -0.8324 
2025-03-22 04:25:05.938661: Pseudo dice [np.float64(0.9441), np.float64(0.9224), np.float64(0.9083)] 
2025-03-22 04:25:05.945184: Epoch time: 43.24 s 
2025-03-22 04:25:05.952209: Yayy! New best EMA pseudo Dice: 0.9036 
2025-03-22 04:25:06.778409:  
2025-03-22 04:25:06.786215: Epoch 29 
2025-03-22 04:25:06.791232: Current learning rate: 0.00974 
2025-03-22 04:25:49.921803: train_loss -0.8279 
2025-03-22 04:25:49.929831: val_loss -0.847 
2025-03-22 04:25:49.934844: Pseudo dice [np.float64(0.9383), np.float64(0.9352), np.float64(0.9065)] 
2025-03-22 04:25:49.939856: Epoch time: 43.14 s 
2025-03-22 04:25:49.944366: Yayy! New best EMA pseudo Dice: 0.9059 
2025-03-22 04:25:50.787845:  
2025-03-22 04:25:50.795549: Epoch 30 
2025-03-22 04:25:50.801154: Current learning rate: 0.00973 
2025-03-22 04:26:33.898814: train_loss -0.8244 
2025-03-22 04:26:33.905333: val_loss -0.8262 
2025-03-22 04:26:33.910356: Pseudo dice [np.float64(0.9405), np.float64(0.9253), np.float64(0.912)] 
2025-03-22 04:26:33.914866: Epoch time: 43.11 s 
2025-03-22 04:26:33.919882: Yayy! New best EMA pseudo Dice: 0.9079 
2025-03-22 04:26:34.786010:  
2025-03-22 04:26:34.794671: Epoch 31 
2025-03-22 04:26:34.798809: Current learning rate: 0.00972 
2025-03-22 04:27:17.929212: train_loss -0.828 
2025-03-22 04:27:17.936731: val_loss -0.8162 
2025-03-22 04:27:17.943256: Pseudo dice [np.float64(0.932), np.float64(0.9184), np.float64(0.9031)] 
2025-03-22 04:27:17.950783: Epoch time: 43.14 s 
2025-03-22 04:27:17.955904: Yayy! New best EMA pseudo Dice: 0.9089 
2025-03-22 04:27:18.807485:  
2025-03-22 04:27:18.815007: Epoch 32 
2025-03-22 04:27:18.820027: Current learning rate: 0.00971 
2025-03-22 04:28:02.122032: train_loss -0.8294 
2025-03-22 04:28:02.130555: val_loss -0.8295 
2025-03-22 04:28:02.137092: Pseudo dice [np.float64(0.9295), np.float64(0.9207), np.float64(0.8975)] 
2025-03-22 04:28:02.142108: Epoch time: 43.32 s 
2025-03-22 04:28:02.147127: Yayy! New best EMA pseudo Dice: 0.9096 
2025-03-22 04:28:03.025796:  
2025-03-22 04:28:03.033439: Epoch 33 
2025-03-22 04:28:03.037513: Current learning rate: 0.0097 
2025-03-22 04:28:47.458932: train_loss -0.8268 
2025-03-22 04:28:47.467458: val_loss -0.8354 
2025-03-22 04:28:47.472478: Pseudo dice [np.float64(0.9493), np.float64(0.9209), np.float64(0.8976)] 
2025-03-22 04:28:47.478499: Epoch time: 44.43 s 
2025-03-22 04:28:47.485026: Yayy! New best EMA pseudo Dice: 0.9109 
2025-03-22 04:28:48.335333:  
2025-03-22 04:28:48.342864: Epoch 34 
2025-03-22 04:28:48.348383: Current learning rate: 0.00969 
2025-03-22 04:29:31.920792: train_loss -0.8183 
2025-03-22 04:29:31.927308: val_loss -0.8269 
2025-03-22 04:29:31.934330: Pseudo dice [np.float64(0.9359), np.float64(0.9275), np.float64(0.9108)] 
2025-03-22 04:29:31.940856: Epoch time: 43.59 s 
2025-03-22 04:29:31.947374: Yayy! New best EMA pseudo Dice: 0.9123 
2025-03-22 04:29:32.824549:  
2025-03-22 04:29:32.831635: Epoch 35 
2025-03-22 04:29:32.835713: Current learning rate: 0.00968 
2025-03-22 04:30:15.975668: train_loss -0.8273 
2025-03-22 04:30:15.984231: val_loss -0.8046 
2025-03-22 04:30:15.991879: Pseudo dice [np.float64(0.9287), np.float64(0.9184), np.float64(0.895)] 
2025-03-22 04:30:15.998187: Epoch time: 43.15 s 
2025-03-22 04:30:16.004888: Yayy! New best EMA pseudo Dice: 0.9125 
2025-03-22 04:30:17.019056:  
2025-03-22 04:30:17.027106: Epoch 36 
2025-03-22 04:30:17.032124: Current learning rate: 0.00968 
2025-03-22 04:31:00.289434: train_loss -0.8216 
2025-03-22 04:31:00.297513: val_loss -0.8183 
2025-03-22 04:31:00.305692: Pseudo dice [np.float64(0.9327), np.float64(0.9145), np.float64(0.9001)] 
2025-03-22 04:31:00.312268: Epoch time: 43.27 s 
2025-03-22 04:31:00.319356: Yayy! New best EMA pseudo Dice: 0.9128 
2025-03-22 04:31:01.160386:  
2025-03-22 04:31:01.166943: Epoch 37 
2025-03-22 04:31:01.173460: Current learning rate: 0.00967 
2025-03-22 04:31:44.101378: train_loss -0.8335 
2025-03-22 04:31:44.108953: val_loss -0.7903 
2025-03-22 04:31:44.113974: Pseudo dice [np.float64(0.9341), np.float64(0.9281), np.float64(0.8943)] 
2025-03-22 04:31:44.119494: Epoch time: 42.94 s 
2025-03-22 04:31:44.125513: Yayy! New best EMA pseudo Dice: 0.9134 
2025-03-22 04:31:45.014324:  
2025-03-22 04:31:45.021899: Epoch 38 
2025-03-22 04:31:45.027012: Current learning rate: 0.00966 
2025-03-22 04:32:28.107189: train_loss -0.8301 
2025-03-22 04:32:28.115847: val_loss -0.8344 
2025-03-22 04:32:28.123561: Pseudo dice [np.float64(0.9416), np.float64(0.9184), np.float64(0.9004)] 
2025-03-22 04:32:28.132800: Epoch time: 43.09 s 
2025-03-22 04:32:28.138383: Yayy! New best EMA pseudo Dice: 0.9141 
2025-03-22 04:32:28.993251:  
2025-03-22 04:32:29.000773: Epoch 39 
2025-03-22 04:32:29.004783: Current learning rate: 0.00965 
2025-03-22 04:33:11.866484: train_loss -0.8373 
2025-03-22 04:33:11.876121: val_loss -0.81 
2025-03-22 04:33:11.883748: Pseudo dice [np.float64(0.9352), np.float64(0.9261), np.float64(0.9063)] 
2025-03-22 04:33:11.891867: Epoch time: 42.87 s 
2025-03-22 04:33:11.896929: Yayy! New best EMA pseudo Dice: 0.9149 
2025-03-22 04:33:12.777233:  
2025-03-22 04:33:12.784337: Epoch 40 
2025-03-22 04:33:12.788398: Current learning rate: 0.00964 
2025-03-22 04:33:55.650057: train_loss -0.8387 
2025-03-22 04:33:55.658586: val_loss -0.8083 
2025-03-22 04:33:55.665105: Pseudo dice [np.float64(0.9428), np.float64(0.9133), np.float64(0.887)] 
2025-03-22 04:33:55.672127: Epoch time: 42.87 s 
2025-03-22 04:33:56.452688:  
2025-03-22 04:33:56.460716: Epoch 41 
2025-03-22 04:33:56.466237: Current learning rate: 0.00963 
2025-03-22 04:34:39.550630: train_loss -0.8219 
2025-03-22 04:34:39.558155: val_loss -0.8025 
2025-03-22 04:34:39.564176: Pseudo dice [np.float64(0.926), np.float64(0.9181), np.float64(0.9043)] 
2025-03-22 04:34:39.568737: Epoch time: 43.1 s 
2025-03-22 04:34:39.572310: Yayy! New best EMA pseudo Dice: 0.915 
2025-03-22 04:34:40.383877:  
2025-03-22 04:34:40.389958: Epoch 42 
2025-03-22 04:34:40.395501: Current learning rate: 0.00962 
2025-03-22 04:35:24.569759: train_loss -0.8281 
2025-03-22 04:35:24.576968: val_loss -0.832 
2025-03-22 04:35:24.582037: Pseudo dice [np.float64(0.9437), np.float64(0.9263), np.float64(0.8995)] 
2025-03-22 04:35:24.588245: Epoch time: 44.19 s 
2025-03-22 04:35:24.593316: Yayy! New best EMA pseudo Dice: 0.9158 
2025-03-22 04:35:25.450581:  
2025-03-22 04:35:25.458099: Epoch 43 
2025-03-22 04:35:25.462109: Current learning rate: 0.00961 
2025-03-22 04:36:08.687637: train_loss -0.8328 
2025-03-22 04:36:08.697162: val_loss -0.8195 
2025-03-22 04:36:08.703690: Pseudo dice [np.float64(0.9395), np.float64(0.9197), np.float64(0.9049)] 
2025-03-22 04:36:08.709703: Epoch time: 43.24 s 
2025-03-22 04:36:08.714719: Yayy! New best EMA pseudo Dice: 0.9164 
2025-03-22 04:36:09.718554:  
2025-03-22 04:36:09.725122: Epoch 44 
2025-03-22 04:36:09.728631: Current learning rate: 0.0096 
2025-03-22 04:36:52.590522: train_loss -0.8361 
2025-03-22 04:36:52.597618: val_loss -0.8183 
2025-03-22 04:36:52.604145: Pseudo dice [np.float64(0.9426), np.float64(0.9047), np.float64(0.888)] 
2025-03-22 04:36:52.609160: Epoch time: 42.87 s 
2025-03-22 04:36:53.334526:  
2025-03-22 04:36:53.341124: Epoch 45 
2025-03-22 04:36:53.346866: Current learning rate: 0.00959 
2025-03-22 04:37:36.074720: train_loss -0.8285 
2025-03-22 04:37:36.082253: val_loss -0.8083 
2025-03-22 04:37:36.088779: Pseudo dice [np.float64(0.9318), np.float64(0.9223), np.float64(0.9031)] 
2025-03-22 04:37:36.092299: Epoch time: 42.74 s 
2025-03-22 04:37:36.842820:  
2025-03-22 04:37:36.849902: Epoch 46 
2025-03-22 04:37:36.853468: Current learning rate: 0.00959 
2025-03-22 04:38:19.626413: train_loss -0.8348 
2025-03-22 04:38:19.633934: val_loss -0.8481 
2025-03-22 04:38:19.641464: Pseudo dice [np.float64(0.9372), np.float64(0.9396), np.float64(0.9173)] 
2025-03-22 04:38:19.647985: Epoch time: 42.78 s 
2025-03-22 04:38:19.655008: Yayy! New best EMA pseudo Dice: 0.9177 
2025-03-22 04:38:20.453132:  
2025-03-22 04:38:20.459705: Epoch 47 
2025-03-22 04:38:20.463721: Current learning rate: 0.00958 
2025-03-22 04:39:03.443359: train_loss -0.8452 
2025-03-22 04:39:03.449379: val_loss -0.8306 
2025-03-22 04:39:03.455905: Pseudo dice [np.float64(0.9404), np.float64(0.9273), np.float64(0.9092)] 
2025-03-22 04:39:03.461920: Epoch time: 42.99 s 
2025-03-22 04:39:03.468434: Yayy! New best EMA pseudo Dice: 0.9185 
2025-03-22 04:39:04.371263:  
2025-03-22 04:39:04.379916: Epoch 48 
2025-03-22 04:39:04.383952: Current learning rate: 0.00957 
2025-03-22 04:39:47.350992: train_loss -0.8429 
2025-03-22 04:39:47.360113: val_loss -0.8274 
2025-03-22 04:39:47.365126: Pseudo dice [np.float64(0.9372), np.float64(0.9384), np.float64(0.9092)] 
2025-03-22 04:39:47.371145: Epoch time: 42.98 s 
2025-03-22 04:39:47.376159: Yayy! New best EMA pseudo Dice: 0.9195 
2025-03-22 04:39:48.236810:  
2025-03-22 04:39:48.244336: Epoch 49 
2025-03-22 04:39:48.250358: Current learning rate: 0.00956 
2025-03-22 04:40:31.049807: train_loss -0.8294 
2025-03-22 04:40:31.056326: val_loss -0.8258 
2025-03-22 04:40:31.061339: Pseudo dice [np.float64(0.9345), np.float64(0.894), np.float64(0.8953)] 
2025-03-22 04:40:31.066352: Epoch time: 42.81 s 
2025-03-22 04:40:31.891769:  
2025-03-22 04:40:31.898293: Epoch 50 
2025-03-22 04:40:31.902308: Current learning rate: 0.00955 
2025-03-22 04:41:14.643729: train_loss -0.8313 
2025-03-22 04:41:14.651316: val_loss -0.8416 
2025-03-22 04:41:14.656333: Pseudo dice [np.float64(0.9344), np.float64(0.9173), np.float64(0.9079)] 
2025-03-22 04:41:14.662859: Epoch time: 42.75 s 
2025-03-22 04:41:15.398985:  
2025-03-22 04:41:15.406619: Epoch 51 
2025-03-22 04:41:15.412637: Current learning rate: 0.00954 
2025-03-22 04:41:59.557547: train_loss -0.8391 
2025-03-22 04:41:59.566579: val_loss -0.8038 
2025-03-22 04:41:59.571596: Pseudo dice [np.float64(0.9369), np.float64(0.8973), np.float64(0.9092)] 
2025-03-22 04:41:59.576616: Epoch time: 44.16 s 
2025-03-22 04:42:00.294530:  
2025-03-22 04:42:00.300549: Epoch 52 
2025-03-22 04:42:00.307071: Current learning rate: 0.00953 
2025-03-22 04:42:43.410988: train_loss -0.8301 
2025-03-22 04:42:43.418509: val_loss -0.7963 
2025-03-22 04:42:43.423523: Pseudo dice [np.float64(0.9409), np.float64(0.9175), np.float64(0.9172)] 
2025-03-22 04:42:43.428035: Epoch time: 43.12 s 
2025-03-22 04:42:44.380057:  
2025-03-22 04:42:44.387686: Epoch 53 
2025-03-22 04:42:44.391405: Current learning rate: 0.00952 
2025-03-22 04:43:27.278044: train_loss -0.8403 
2025-03-22 04:43:27.285566: val_loss -0.8421 
2025-03-22 04:43:27.292655: Pseudo dice [np.float64(0.9367), np.float64(0.9193), np.float64(0.9003)] 
2025-03-22 04:43:27.298672: Epoch time: 42.9 s 
2025-03-22 04:43:28.023875:  
2025-03-22 04:43:28.030393: Epoch 54 
2025-03-22 04:43:28.034404: Current learning rate: 0.00951 
2025-03-22 04:44:10.991480: train_loss -0.8435 
2025-03-22 04:44:10.999631: val_loss -0.8322 
2025-03-22 04:44:11.005655: Pseudo dice [np.float64(0.9402), np.float64(0.9109), np.float64(0.9123)] 
2025-03-22 04:44:11.010705: Epoch time: 42.97 s 
2025-03-22 04:44:11.749998:  
2025-03-22 04:44:11.757146: Epoch 55 
2025-03-22 04:44:11.762733: Current learning rate: 0.0095 
2025-03-22 04:44:54.687017: train_loss -0.8255 
2025-03-22 04:44:54.694607: val_loss -0.836 
2025-03-22 04:44:54.702186: Pseudo dice [np.float64(0.9378), np.float64(0.9175), np.float64(0.9096)] 
2025-03-22 04:44:54.710717: Epoch time: 42.94 s 
2025-03-22 04:44:55.421175:  
2025-03-22 04:44:55.428764: Epoch 56 
2025-03-22 04:44:55.433429: Current learning rate: 0.00949 
2025-03-22 04:45:38.259999: train_loss -0.8301 
2025-03-22 04:45:38.266512: val_loss -0.8267 
2025-03-22 04:45:38.272527: Pseudo dice [np.float64(0.944), np.float64(0.9264), np.float64(0.9065)] 
2025-03-22 04:45:38.277541: Epoch time: 42.84 s 
2025-03-22 04:45:38.284057: Yayy! New best EMA pseudo Dice: 0.9199 
2025-03-22 04:45:39.115418:  
2025-03-22 04:45:39.123589: Epoch 57 
2025-03-22 04:45:39.127156: Current learning rate: 0.00949 
2025-03-22 04:46:22.078096: train_loss -0.8398 
2025-03-22 04:46:22.087618: val_loss -0.8247 
2025-03-22 04:46:22.093646: Pseudo dice [np.float64(0.9429), np.float64(0.9061), np.float64(0.9121)] 
2025-03-22 04:46:22.099301: Epoch time: 42.96 s 
2025-03-22 04:46:22.103334: Yayy! New best EMA pseudo Dice: 0.92 
2025-03-22 04:46:22.942649:  
2025-03-22 04:46:22.950262: Epoch 58 
2025-03-22 04:46:22.956346: Current learning rate: 0.00948 
2025-03-22 04:47:05.809258: train_loss -0.8427 
2025-03-22 04:47:05.816371: val_loss -0.842 
2025-03-22 04:47:05.822463: Pseudo dice [np.float64(0.9366), np.float64(0.9449), np.float64(0.9135)] 
2025-03-22 04:47:05.828617: Epoch time: 42.87 s 
2025-03-22 04:47:05.835252: Yayy! New best EMA pseudo Dice: 0.9211 
2025-03-22 04:47:06.696054:  
2025-03-22 04:47:06.703661: Epoch 59 
2025-03-22 04:47:06.708821: Current learning rate: 0.00947 
2025-03-22 04:47:49.682894: train_loss -0.8469 
2025-03-22 04:47:49.690417: val_loss -0.8445 
2025-03-22 04:47:49.696941: Pseudo dice [np.float64(0.9467), np.float64(0.9355), np.float64(0.9076)] 
2025-03-22 04:47:49.703460: Epoch time: 42.99 s 
2025-03-22 04:47:49.710486: Yayy! New best EMA pseudo Dice: 0.922 
2025-03-22 04:47:50.562781:  
2025-03-22 04:47:50.568320: Epoch 60 
2025-03-22 04:47:50.573409: Current learning rate: 0.00946 
2025-03-22 04:48:34.909094: train_loss -0.844 
2025-03-22 04:48:34.917257: val_loss -0.836 
2025-03-22 04:48:34.921819: Pseudo dice [np.float64(0.9422), np.float64(0.928), np.float64(0.92)] 
2025-03-22 04:48:34.925390: Epoch time: 44.35 s 
2025-03-22 04:48:34.930537: Yayy! New best EMA pseudo Dice: 0.9228 
2025-03-22 04:48:35.794694:  
2025-03-22 04:48:35.801749: Epoch 61 
2025-03-22 04:48:35.807331: Current learning rate: 0.00945 
2025-03-22 04:49:18.692454: train_loss -0.8429 
2025-03-22 04:49:18.698970: val_loss -0.8292 
2025-03-22 04:49:18.704795: Pseudo dice [np.float64(0.9357), np.float64(0.928), np.float64(0.8942)] 
2025-03-22 04:49:18.710812: Epoch time: 42.9 s 
2025-03-22 04:49:19.686391:  
2025-03-22 04:49:19.695053: Epoch 62 
2025-03-22 04:49:19.699062: Current learning rate: 0.00944 
2025-03-22 04:50:02.447306: train_loss -0.834 
2025-03-22 04:50:02.454827: val_loss -0.8331 
2025-03-22 04:50:02.459358: Pseudo dice [np.float64(0.9357), np.float64(0.9347), np.float64(0.8933)] 
2025-03-22 04:50:02.463405: Epoch time: 42.76 s 
2025-03-22 04:50:03.211403:  
2025-03-22 04:50:03.219548: Epoch 63 
2025-03-22 04:50:03.226109: Current learning rate: 0.00943 
2025-03-22 04:50:46.313900: train_loss -0.8378 
2025-03-22 04:50:46.321926: val_loss -0.8286 
2025-03-22 04:50:46.327945: Pseudo dice [np.float64(0.9402), np.float64(0.9316), np.float64(0.9014)] 
2025-03-22 04:50:46.336468: Epoch time: 43.1 s 
2025-03-22 04:50:47.062911:  
2025-03-22 04:50:47.069472: Epoch 64 
2025-03-22 04:50:47.074205: Current learning rate: 0.00942 
2025-03-22 04:51:29.791770: train_loss -0.8416 
2025-03-22 04:51:29.798786: val_loss -0.815 
2025-03-22 04:51:29.804306: Pseudo dice [np.float64(0.9354), np.float64(0.9222), np.float64(0.9019)] 
2025-03-22 04:51:29.810327: Epoch time: 42.73 s 
2025-03-22 04:51:30.530818:  
2025-03-22 04:51:30.537968: Epoch 65 
2025-03-22 04:51:30.544021: Current learning rate: 0.00941 
2025-03-22 04:52:13.184289: train_loss -0.8527 
2025-03-22 04:52:13.191386: val_loss -0.8458 
2025-03-22 04:52:13.197005: Pseudo dice [np.float64(0.9463), np.float64(0.9456), np.float64(0.9231)] 
2025-03-22 04:52:13.202679: Epoch time: 42.65 s 
2025-03-22 04:52:13.206788: Yayy! New best EMA pseudo Dice: 0.9239 
2025-03-22 04:52:14.029455:  
2025-03-22 04:52:14.036019: Epoch 66 
2025-03-22 04:52:14.041677: Current learning rate: 0.0094 
2025-03-22 04:52:57.025067: train_loss -0.8433 
2025-03-22 04:52:57.032590: val_loss -0.8605 
2025-03-22 04:52:57.039117: Pseudo dice [np.float64(0.9476), np.float64(0.9216), np.float64(0.9136)] 
2025-03-22 04:52:57.044137: Epoch time: 43.0 s 
2025-03-22 04:52:57.049675: Yayy! New best EMA pseudo Dice: 0.9243 
2025-03-22 04:52:57.884302:  
2025-03-22 04:52:57.891833: Epoch 67 
2025-03-22 04:52:57.897357: Current learning rate: 0.00939 
2025-03-22 04:53:40.768928: train_loss -0.8354 
2025-03-22 04:53:40.775945: val_loss -0.839 
2025-03-22 04:53:40.781471: Pseudo dice [np.float64(0.942), np.float64(0.9374), np.float64(0.913)] 
2025-03-22 04:53:40.788998: Epoch time: 42.89 s 
2025-03-22 04:53:40.795021: Yayy! New best EMA pseudo Dice: 0.9249 
2025-03-22 04:53:41.670614:  
2025-03-22 04:53:41.675689: Epoch 68 
2025-03-22 04:53:41.679371: Current learning rate: 0.00939 
2025-03-22 04:54:24.510908: train_loss -0.8366 
2025-03-22 04:54:24.517687: val_loss -0.8253 
2025-03-22 04:54:24.521697: Pseudo dice [np.float64(0.9398), np.float64(0.918), np.float64(0.9052)] 
2025-03-22 04:54:24.525206: Epoch time: 42.84 s 
2025-03-22 04:54:25.282411:  
2025-03-22 04:54:25.288808: Epoch 69 
2025-03-22 04:54:25.292823: Current learning rate: 0.00938 
2025-03-22 04:55:09.259020: train_loss -0.8384 
2025-03-22 04:55:09.266036: val_loss -0.8333 
2025-03-22 04:55:09.271554: Pseudo dice [np.float64(0.9403), np.float64(0.9221), np.float64(0.9107)] 
2025-03-22 04:55:09.275064: Epoch time: 43.98 s 
2025-03-22 04:55:10.251362:  
2025-03-22 04:55:10.259389: Epoch 70 
2025-03-22 04:55:10.262902: Current learning rate: 0.00937 
2025-03-22 04:55:53.284339: train_loss -0.8475 
2025-03-22 04:55:53.291912: val_loss -0.8254 
2025-03-22 04:55:53.297956: Pseudo dice [np.float64(0.9418), np.float64(0.9122), np.float64(0.9059)] 
2025-03-22 04:55:53.304529: Epoch time: 43.03 s 
2025-03-22 04:55:54.055321:  
2025-03-22 04:55:54.061849: Epoch 71 
2025-03-22 04:55:54.066860: Current learning rate: 0.00936 
2025-03-22 04:56:37.062782: train_loss -0.8447 
2025-03-22 04:56:37.070308: val_loss -0.8275 
2025-03-22 04:56:37.075320: Pseudo dice [np.float64(0.9295), np.float64(0.9303), np.float64(0.9078)] 
2025-03-22 04:56:37.080336: Epoch time: 43.01 s 
2025-03-22 04:56:37.846424:  
2025-03-22 04:56:37.853494: Epoch 72 
2025-03-22 04:56:37.859092: Current learning rate: 0.00935 
2025-03-22 04:57:20.543642: train_loss -0.8465 
2025-03-22 04:57:20.550715: val_loss -0.7991 
2025-03-22 04:57:20.554850: Pseudo dice [np.float64(0.9368), np.float64(0.8815), np.float64(0.8988)] 
2025-03-22 04:57:20.559899: Epoch time: 42.7 s 
2025-03-22 04:57:21.331335:  
2025-03-22 04:57:21.338853: Epoch 73 
2025-03-22 04:57:21.343362: Current learning rate: 0.00934 
2025-03-22 04:58:04.331686: train_loss -0.8532 
2025-03-22 04:58:04.341718: val_loss -0.8148 
2025-03-22 04:58:04.349743: Pseudo dice [np.float64(0.9421), np.float64(0.9211), np.float64(0.8975)] 
2025-03-22 04:58:04.356764: Epoch time: 43.0 s 
2025-03-22 04:58:05.090667:  
2025-03-22 04:58:05.096221: Epoch 74 
2025-03-22 04:58:05.101292: Current learning rate: 0.00933 
2025-03-22 04:58:47.843609: train_loss -0.8456 
2025-03-22 04:58:47.852123: val_loss -0.8553 
2025-03-22 04:58:47.857637: Pseudo dice [np.float64(0.9465), np.float64(0.936), np.float64(0.9204)] 
2025-03-22 04:58:47.863654: Epoch time: 42.75 s 
2025-03-22 04:58:48.652986:  
2025-03-22 04:58:48.660579: Epoch 75 
2025-03-22 04:58:48.666683: Current learning rate: 0.00932 
2025-03-22 04:59:31.618380: train_loss -0.8317 
2025-03-22 04:59:31.625467: val_loss -0.8384 
2025-03-22 04:59:31.631076: Pseudo dice [np.float64(0.9446), np.float64(0.9256), np.float64(0.9131)] 
2025-03-22 04:59:31.638247: Epoch time: 42.97 s 
2025-03-22 04:59:32.376426:  
2025-03-22 04:59:32.383014: Epoch 76 
2025-03-22 04:59:32.388058: Current learning rate: 0.00931 
2025-03-22 05:00:15.186924: train_loss -0.8522 
2025-03-22 05:00:15.194506: val_loss -0.8407 
2025-03-22 05:00:15.200564: Pseudo dice [np.float64(0.9472), np.float64(0.9111), np.float64(0.9016)] 
2025-03-22 05:00:15.204601: Epoch time: 42.81 s 
2025-03-22 05:00:15.960201:  
2025-03-22 05:00:15.967379: Epoch 77 
2025-03-22 05:00:15.971422: Current learning rate: 0.0093 
2025-03-22 05:00:58.679795: train_loss -0.8487 
2025-03-22 05:00:58.688326: val_loss -0.8394 
2025-03-22 05:00:58.694845: Pseudo dice [np.float64(0.9374), np.float64(0.9284), np.float64(0.9133)] 
2025-03-22 05:00:58.702365: Epoch time: 42.72 s 
2025-03-22 05:00:59.470500:  
2025-03-22 05:00:59.476050: Epoch 78 
2025-03-22 05:00:59.481204: Current learning rate: 0.0093 
2025-03-22 05:01:43.959855: train_loss -0.848 
2025-03-22 05:01:43.966815: val_loss -0.8426 
2025-03-22 05:01:43.975106: Pseudo dice [np.float64(0.9368), np.float64(0.9289), np.float64(0.9164)] 
2025-03-22 05:01:43.981621: Epoch time: 44.49 s 
2025-03-22 05:01:44.988096:  
2025-03-22 05:01:44.996117: Epoch 79 
2025-03-22 05:01:45.002131: Current learning rate: 0.00929 
2025-03-22 05:02:27.937052: train_loss -0.8391 
2025-03-22 05:02:27.944570: val_loss -0.8265 
2025-03-22 05:02:27.951594: Pseudo dice [np.float64(0.9372), np.float64(0.9267), np.float64(0.9124)] 
2025-03-22 05:02:27.958115: Epoch time: 42.95 s 
2025-03-22 05:02:28.717071:  
2025-03-22 05:02:28.723080: Epoch 80 
2025-03-22 05:02:28.730599: Current learning rate: 0.00928 
2025-03-22 05:03:11.740360: train_loss -0.8492 
2025-03-22 05:03:11.748881: val_loss -0.8303 
2025-03-22 05:03:11.754396: Pseudo dice [np.float64(0.9423), np.float64(0.9186), np.float64(0.9107)] 
2025-03-22 05:03:11.760415: Epoch time: 43.02 s 
2025-03-22 05:03:12.499206:  
2025-03-22 05:03:12.504822: Epoch 81 
2025-03-22 05:03:12.509377: Current learning rate: 0.00927 
2025-03-22 05:03:55.254070: train_loss -0.853 
2025-03-22 05:03:55.261060: val_loss -0.8492 
2025-03-22 05:03:55.266573: Pseudo dice [np.float64(0.9496), np.float64(0.9404), np.float64(0.9217)] 
2025-03-22 05:03:55.272613: Epoch time: 42.76 s 
2025-03-22 05:03:55.278625: Yayy! New best EMA pseudo Dice: 0.9254 
2025-03-22 05:03:56.131112:  
2025-03-22 05:03:56.138733: Epoch 82 
2025-03-22 05:03:56.143293: Current learning rate: 0.00926 
2025-03-22 05:04:38.877034: train_loss -0.853 
2025-03-22 05:04:38.883555: val_loss -0.8226 
2025-03-22 05:04:38.889570: Pseudo dice [np.float64(0.9434), np.float64(0.9326), np.float64(0.9025)] 
2025-03-22 05:04:38.896081: Epoch time: 42.75 s 
2025-03-22 05:04:38.901089: Yayy! New best EMA pseudo Dice: 0.9255 
2025-03-22 05:04:39.736977:  
2025-03-22 05:04:39.744543: Epoch 83 
2025-03-22 05:04:39.751627: Current learning rate: 0.00925 
2025-03-22 05:05:22.488204: train_loss -0.8354 
2025-03-22 05:05:22.494724: val_loss -0.8545 
2025-03-22 05:05:22.501238: Pseudo dice [np.float64(0.94), np.float64(0.9269), np.float64(0.9106)] 
2025-03-22 05:05:22.506248: Epoch time: 42.75 s 
2025-03-22 05:05:22.510756: Yayy! New best EMA pseudo Dice: 0.9255 
2025-03-22 05:05:23.335484:  
2025-03-22 05:05:23.342032: Epoch 84 
2025-03-22 05:05:23.347064: Current learning rate: 0.00924 
2025-03-22 05:06:06.416517: train_loss -0.8477 
2025-03-22 05:06:06.425039: val_loss -0.8509 
2025-03-22 05:06:06.431557: Pseudo dice [np.float64(0.9438), np.float64(0.9365), np.float64(0.9162)] 
2025-03-22 05:06:06.437572: Epoch time: 43.08 s 
2025-03-22 05:06:06.443584: Yayy! New best EMA pseudo Dice: 0.9262 
2025-03-22 05:06:07.285515:  
2025-03-22 05:06:07.292094: Epoch 85 
2025-03-22 05:06:07.295653: Current learning rate: 0.00923 
2025-03-22 05:06:50.241638: train_loss -0.85 
2025-03-22 05:06:50.250241: val_loss -0.8504 
2025-03-22 05:06:50.257859: Pseudo dice [np.float64(0.9442), np.float64(0.938), np.float64(0.9119)] 
2025-03-22 05:06:50.266394: Epoch time: 42.96 s 
2025-03-22 05:06:50.274426: Yayy! New best EMA pseudo Dice: 0.9267 
2025-03-22 05:06:51.076381:  
2025-03-22 05:06:51.082019: Epoch 86 
2025-03-22 05:06:51.086556: Current learning rate: 0.00922 
2025-03-22 05:07:33.782882: train_loss -0.8411 
2025-03-22 05:07:33.791459: val_loss -0.8373 
2025-03-22 05:07:33.799543: Pseudo dice [np.float64(0.941), np.float64(0.9331), np.float64(0.92)] 
2025-03-22 05:07:33.805121: Epoch time: 42.71 s 
2025-03-22 05:07:33.809676: Yayy! New best EMA pseudo Dice: 0.9272 
2025-03-22 05:07:34.903072:  
2025-03-22 05:07:34.911203: Epoch 87 
2025-03-22 05:07:34.914786: Current learning rate: 0.00921 
2025-03-22 05:08:19.058640: train_loss -0.8479 
2025-03-22 05:08:19.065159: val_loss -0.8096 
2025-03-22 05:08:19.071180: Pseudo dice [np.float64(0.9297), np.float64(0.9136), np.float64(0.8987)] 
2025-03-22 05:08:19.075193: Epoch time: 44.16 s 
2025-03-22 05:08:19.790038:  
2025-03-22 05:08:19.797558: Epoch 88 
2025-03-22 05:08:19.803100: Current learning rate: 0.0092 
2025-03-22 05:09:02.658168: train_loss -0.8385 
2025-03-22 05:09:02.667753: val_loss -0.8172 
2025-03-22 05:09:02.675323: Pseudo dice [np.float64(0.9379), np.float64(0.9345), np.float64(0.9048)] 
2025-03-22 05:09:02.679961: Epoch time: 42.87 s 
2025-03-22 05:09:03.400353:  
2025-03-22 05:09:03.406879: Epoch 89 
2025-03-22 05:09:03.412899: Current learning rate: 0.0092 
2025-03-22 05:09:46.682970: train_loss -0.8493 
2025-03-22 05:09:46.692078: val_loss -0.829 
2025-03-22 05:09:46.699657: Pseudo dice [np.float64(0.9493), np.float64(0.9248), np.float64(0.8977)] 
2025-03-22 05:09:46.707252: Epoch time: 43.28 s 
2025-03-22 05:09:47.447448:  
2025-03-22 05:09:47.454000: Epoch 90 
2025-03-22 05:09:47.459051: Current learning rate: 0.00919 
2025-03-22 05:10:30.254941: train_loss -0.8472 
2025-03-22 05:10:30.262011: val_loss -0.8432 
2025-03-22 05:10:30.268527: Pseudo dice [np.float64(0.9446), np.float64(0.9281), np.float64(0.9072)] 
2025-03-22 05:10:30.273538: Epoch time: 42.81 s 
2025-03-22 05:10:31.025477:  
2025-03-22 05:10:31.032997: Epoch 91 
2025-03-22 05:10:31.038513: Current learning rate: 0.00918 
2025-03-22 05:11:14.051805: train_loss -0.8562 
2025-03-22 05:11:14.060833: val_loss -0.8584 
2025-03-22 05:11:14.066851: Pseudo dice [np.float64(0.9415), np.float64(0.9231), np.float64(0.912)] 
2025-03-22 05:11:14.072868: Epoch time: 43.03 s 
2025-03-22 05:11:14.788920:  
2025-03-22 05:11:14.796480: Epoch 92 
2025-03-22 05:11:14.801145: Current learning rate: 0.00917 
2025-03-22 05:11:57.704740: train_loss -0.8345 
2025-03-22 05:11:57.710630: val_loss -0.8286 
2025-03-22 05:11:57.717695: Pseudo dice [np.float64(0.9368), np.float64(0.9174), np.float64(0.8796)] 
2025-03-22 05:11:57.723818: Epoch time: 42.92 s 
2025-03-22 05:11:58.439917:  
2025-03-22 05:11:58.448035: Epoch 93 
2025-03-22 05:11:58.453547: Current learning rate: 0.00916 
2025-03-22 05:12:41.456411: train_loss -0.8506 
2025-03-22 05:12:41.465153: val_loss -0.8634 
2025-03-22 05:12:41.470757: Pseudo dice [np.float64(0.9452), np.float64(0.9285), np.float64(0.9166)] 
2025-03-22 05:12:41.475844: Epoch time: 43.02 s 
2025-03-22 05:12:42.197001:  
2025-03-22 05:12:42.203076: Epoch 94 
2025-03-22 05:12:42.208131: Current learning rate: 0.00915 
2025-03-22 05:13:25.139616: train_loss -0.8362 
2025-03-22 05:13:25.146672: val_loss -0.8462 
2025-03-22 05:13:25.150204: Pseudo dice [np.float64(0.9325), np.float64(0.9296), np.float64(0.9155)] 
2025-03-22 05:13:25.156236: Epoch time: 42.94 s 
2025-03-22 05:13:26.142275:  
2025-03-22 05:13:26.150846: Epoch 95 
2025-03-22 05:13:26.154368: Current learning rate: 0.00914 
2025-03-22 05:14:08.707102: train_loss -0.8352 
2025-03-22 05:14:08.714726: val_loss -0.8364 
2025-03-22 05:14:08.720784: Pseudo dice [np.float64(0.943), np.float64(0.8926), np.float64(0.8946)] 
2025-03-22 05:14:08.726420: Epoch time: 42.57 s 
2025-03-22 05:14:09.442309:  
2025-03-22 05:14:09.450875: Epoch 96 
2025-03-22 05:14:09.458957: Current learning rate: 0.00913 
2025-03-22 05:14:53.488362: train_loss -0.8517 
2025-03-22 05:14:53.495960: val_loss -0.8422 
2025-03-22 05:14:53.503080: Pseudo dice [np.float64(0.9396), np.float64(0.9256), np.float64(0.9166)] 
2025-03-22 05:14:53.509693: Epoch time: 44.05 s 
2025-03-22 05:14:54.247269:  
2025-03-22 05:14:54.253388: Epoch 97 
2025-03-22 05:14:54.259519: Current learning rate: 0.00912 
2025-03-22 05:15:37.293668: train_loss -0.848 
2025-03-22 05:15:37.301188: val_loss -0.8293 
2025-03-22 05:15:37.308712: Pseudo dice [np.float64(0.9451), np.float64(0.9247), np.float64(0.9074)] 
2025-03-22 05:15:37.317740: Epoch time: 43.05 s 
2025-03-22 05:15:38.063287:  
2025-03-22 05:15:38.069932: Epoch 98 
2025-03-22 05:15:38.074028: Current learning rate: 0.00911 
2025-03-22 05:16:21.116554: train_loss -0.8495 
2025-03-22 05:16:21.124078: val_loss -0.8485 
2025-03-22 05:16:21.131645: Pseudo dice [np.float64(0.946), np.float64(0.9364), np.float64(0.9131)] 
2025-03-22 05:16:21.138754: Epoch time: 43.05 s 
2025-03-22 05:16:21.903991:  
2025-03-22 05:16:21.910572: Epoch 99 
2025-03-22 05:16:21.914078: Current learning rate: 0.0091 
2025-03-22 05:17:05.013638: train_loss -0.85 
2025-03-22 05:17:05.023668: val_loss -0.8348 
2025-03-22 05:17:05.029685: Pseudo dice [np.float64(0.9395), np.float64(0.937), np.float64(0.9189)] 
2025-03-22 05:17:05.036201: Epoch time: 43.11 s 
2025-03-22 05:17:05.847717:  
2025-03-22 05:17:05.853264: Epoch 100 
2025-03-22 05:17:05.860358: Current learning rate: 0.0091 
2025-03-22 05:17:48.733104: train_loss -0.8529 
2025-03-22 05:17:48.741580: val_loss -0.8448 
2025-03-22 05:17:48.748965: Pseudo dice [np.float64(0.9421), np.float64(0.9206), np.float64(0.9152)] 
2025-03-22 05:17:48.756625: Epoch time: 42.89 s 
2025-03-22 05:17:49.482924:  
2025-03-22 05:17:49.490120: Epoch 101 
2025-03-22 05:17:49.494175: Current learning rate: 0.00909 
2025-03-22 05:18:32.511167: train_loss -0.8475 
2025-03-22 05:18:32.518688: val_loss -0.8607 
2025-03-22 05:18:32.526210: Pseudo dice [np.float64(0.9421), np.float64(0.9317), np.float64(0.915)] 
2025-03-22 05:18:32.532227: Epoch time: 43.03 s 
2025-03-22 05:18:33.253573:  
2025-03-22 05:18:33.260089: Epoch 102 
2025-03-22 05:18:33.264096: Current learning rate: 0.00908 
2025-03-22 05:19:16.256269: train_loss -0.8648 
2025-03-22 05:19:16.263788: val_loss -0.8252 
2025-03-22 05:19:16.270303: Pseudo dice [np.float64(0.9403), np.float64(0.9022), np.float64(0.9187)] 
2025-03-22 05:19:16.276320: Epoch time: 43.0 s 
2025-03-22 05:19:16.997976:  
2025-03-22 05:19:17.005551: Epoch 103 
2025-03-22 05:19:17.013253: Current learning rate: 0.00907 
2025-03-22 05:20:00.051044: train_loss -0.8481 
2025-03-22 05:20:00.056621: val_loss -0.8418 
2025-03-22 05:20:00.062818: Pseudo dice [np.float64(0.9454), np.float64(0.9076), np.float64(0.9071)] 
2025-03-22 05:20:00.067080: Epoch time: 43.05 s 
2025-03-22 05:20:01.057281:  
2025-03-22 05:20:01.064377: Epoch 104 
2025-03-22 05:20:01.067970: Current learning rate: 0.00906 
2025-03-22 05:20:43.960727: train_loss -0.8414 
2025-03-22 05:20:43.970756: val_loss -0.8337 
2025-03-22 05:20:43.978278: Pseudo dice [np.float64(0.944), np.float64(0.9324), np.float64(0.9076)] 
2025-03-22 05:20:43.986800: Epoch time: 42.9 s 
2025-03-22 05:20:44.700783:  
2025-03-22 05:20:44.706335: Epoch 105 
2025-03-22 05:20:44.710845: Current learning rate: 0.00905 
2025-03-22 05:21:27.385107: train_loss -0.8506 
2025-03-22 05:21:27.395135: val_loss -0.8329 
2025-03-22 05:21:27.400147: Pseudo dice [np.float64(0.9448), np.float64(0.9405), np.float64(0.9155)] 
2025-03-22 05:21:27.405163: Epoch time: 42.69 s 
2025-03-22 05:21:28.109740:  
2025-03-22 05:21:28.116764: Epoch 106 
2025-03-22 05:21:28.120780: Current learning rate: 0.00904 
2025-03-22 05:22:11.083619: train_loss -0.8514 
2025-03-22 05:22:11.091139: val_loss -0.8471 
2025-03-22 05:22:11.098660: Pseudo dice [np.float64(0.9277), np.float64(0.9162), np.float64(0.9104)] 
2025-03-22 05:22:11.104679: Epoch time: 42.97 s 
2025-03-22 05:22:11.839459:  
2025-03-22 05:22:11.845004: Epoch 107 
2025-03-22 05:22:11.849564: Current learning rate: 0.00903 
2025-03-22 05:22:54.648998: train_loss -0.852 
2025-03-22 05:22:54.657526: val_loss -0.852 
2025-03-22 05:22:54.666047: Pseudo dice [np.float64(0.95), np.float64(0.9414), np.float64(0.9208)] 
2025-03-22 05:22:54.672567: Epoch time: 42.81 s 
2025-03-22 05:22:55.409847:  
2025-03-22 05:22:55.417367: Epoch 108 
2025-03-22 05:22:55.422377: Current learning rate: 0.00902 
2025-03-22 05:23:38.325419: train_loss -0.8499 
2025-03-22 05:23:38.332938: val_loss -0.8307 
2025-03-22 05:23:38.340458: Pseudo dice [np.float64(0.9407), np.float64(0.9106), np.float64(0.9179)] 
2025-03-22 05:23:38.345474: Epoch time: 42.92 s 
2025-03-22 05:23:39.098860:  
2025-03-22 05:23:39.106952: Epoch 109 
2025-03-22 05:23:39.113530: Current learning rate: 0.00901 
2025-03-22 05:24:22.000823: train_loss -0.8509 
2025-03-22 05:24:22.008343: val_loss -0.8537 
2025-03-22 05:24:22.013356: Pseudo dice [np.float64(0.9447), np.float64(0.9452), np.float64(0.9162)] 
2025-03-22 05:24:22.020922: Epoch time: 42.9 s 
2025-03-22 05:24:22.781844:  
2025-03-22 05:24:22.788867: Epoch 110 
2025-03-22 05:24:22.793018: Current learning rate: 0.009 
2025-03-22 05:25:05.705941: train_loss -0.8426 
2025-03-22 05:25:05.713456: val_loss -0.8459 
2025-03-22 05:25:05.718473: Pseudo dice [np.float64(0.9449), np.float64(0.9323), np.float64(0.9081)] 
2025-03-22 05:25:05.723993: Epoch time: 42.93 s 
2025-03-22 05:25:05.730007: Yayy! New best EMA pseudo Dice: 0.9272 
2025-03-22 05:25:06.541219:  
2025-03-22 05:25:06.547240: Epoch 111 
2025-03-22 05:25:06.553757: Current learning rate: 0.009 
2025-03-22 05:25:49.535440: train_loss -0.8319 
2025-03-22 05:25:49.542999: val_loss -0.8123 
2025-03-22 05:25:49.549599: Pseudo dice [np.float64(0.9441), np.float64(0.9297), np.float64(0.9002)] 
2025-03-22 05:25:49.555671: Epoch time: 43.0 s 
2025-03-22 05:25:50.557944:  
2025-03-22 05:25:50.563963: Epoch 112 
2025-03-22 05:25:50.567970: Current learning rate: 0.00899 
2025-03-22 05:26:33.491794: train_loss -0.8474 
2025-03-22 05:26:33.498888: val_loss -0.832 
2025-03-22 05:26:33.505039: Pseudo dice [np.float64(0.941), np.float64(0.9215), np.float64(0.9211)] 
2025-03-22 05:26:33.511136: Epoch time: 42.94 s 
2025-03-22 05:26:34.243592:  
2025-03-22 05:26:34.251692: Epoch 113 
2025-03-22 05:26:34.257257: Current learning rate: 0.00898 
2025-03-22 05:27:17.198346: train_loss -0.8477 
2025-03-22 05:27:17.206021: val_loss -0.8305 
2025-03-22 05:27:17.214146: Pseudo dice [np.float64(0.9476), np.float64(0.9052), np.float64(0.9012)] 
2025-03-22 05:27:17.220258: Epoch time: 42.96 s 
2025-03-22 05:27:17.957026:  
2025-03-22 05:27:17.963117: Epoch 114 
2025-03-22 05:27:17.968654: Current learning rate: 0.00897 
2025-03-22 05:28:00.891888: train_loss -0.8407 
2025-03-22 05:28:00.900441: val_loss -0.8338 
2025-03-22 05:28:00.907464: Pseudo dice [np.float64(0.9446), np.float64(0.9273), np.float64(0.9108)] 
2025-03-22 05:28:00.913985: Epoch time: 42.94 s 
2025-03-22 05:28:01.657713:  
2025-03-22 05:28:01.664785: Epoch 115 
2025-03-22 05:28:01.669990: Current learning rate: 0.00896 
2025-03-22 05:28:44.646219: train_loss -0.8538 
2025-03-22 05:28:44.653737: val_loss -0.8334 
2025-03-22 05:28:44.660258: Pseudo dice [np.float64(0.9366), np.float64(0.928), np.float64(0.9053)] 
2025-03-22 05:28:44.667777: Epoch time: 42.99 s 
2025-03-22 05:28:45.406159:  
2025-03-22 05:28:45.412341: Epoch 116 
2025-03-22 05:28:45.417423: Current learning rate: 0.00895 
2025-03-22 05:29:28.196794: train_loss -0.8625 
2025-03-22 05:29:28.205816: val_loss -0.822 
2025-03-22 05:29:28.214353: Pseudo dice [np.float64(0.9415), np.float64(0.9051), np.float64(0.9012)] 
2025-03-22 05:29:28.222875: Epoch time: 42.79 s 
2025-03-22 05:29:28.977156:  
2025-03-22 05:29:28.983680: Epoch 117 
2025-03-22 05:29:28.990199: Current learning rate: 0.00894 
2025-03-22 05:30:11.951706: train_loss -0.8505 
2025-03-22 05:30:11.960729: val_loss -0.825 
2025-03-22 05:30:11.965750: Pseudo dice [np.float64(0.9356), np.float64(0.9192), np.float64(0.9097)] 
2025-03-22 05:30:11.970763: Epoch time: 42.98 s 
2025-03-22 05:30:12.721882:  
2025-03-22 05:30:12.729991: Epoch 118 
2025-03-22 05:30:12.737147: Current learning rate: 0.00893 
2025-03-22 05:30:55.712670: train_loss -0.847 
2025-03-22 05:30:55.720185: val_loss -0.8426 
2025-03-22 05:30:55.726198: Pseudo dice [np.float64(0.9445), np.float64(0.9296), np.float64(0.898)] 
2025-03-22 05:30:55.734225: Epoch time: 42.99 s 
2025-03-22 05:30:56.496315:  
2025-03-22 05:30:56.502911: Epoch 119 
2025-03-22 05:30:56.508471: Current learning rate: 0.00892 
2025-03-22 05:31:39.718437: train_loss -0.8524 
2025-03-22 05:31:39.726964: val_loss -0.8393 
2025-03-22 05:31:39.734486: Pseudo dice [np.float64(0.9418), np.float64(0.9106), np.float64(0.9072)] 
2025-03-22 05:31:39.743518: Epoch time: 43.22 s 
2025-03-22 05:31:40.495797:  
2025-03-22 05:31:40.502321: Epoch 120 
2025-03-22 05:31:40.508338: Current learning rate: 0.00891 
2025-03-22 05:32:24.446564: train_loss -0.8499 
2025-03-22 05:32:24.455086: val_loss -0.8399 
2025-03-22 05:32:24.463118: Pseudo dice [np.float64(0.9467), np.float64(0.9141), np.float64(0.9078)] 
2025-03-22 05:32:24.470644: Epoch time: 43.95 s 
2025-03-22 05:32:25.476918:  
2025-03-22 05:32:25.483441: Epoch 121 
2025-03-22 05:32:25.488454: Current learning rate: 0.0089 
2025-03-22 05:33:08.461148: train_loss -0.8524 
2025-03-22 05:33:08.468666: val_loss -0.8148 
2025-03-22 05:33:08.473715: Pseudo dice [np.float64(0.9434), np.float64(0.9129), np.float64(0.9032)] 
2025-03-22 05:33:08.479732: Epoch time: 42.99 s 
2025-03-22 05:33:09.231000:  
2025-03-22 05:33:09.237453: Epoch 122 
2025-03-22 05:33:09.241469: Current learning rate: 0.00889 
2025-03-22 05:33:52.133228: train_loss -0.8593 
2025-03-22 05:33:52.141371: val_loss -0.822 
2025-03-22 05:33:52.147433: Pseudo dice [np.float64(0.9408), np.float64(0.9375), np.float64(0.915)] 
2025-03-22 05:33:52.152199: Epoch time: 42.9 s 
2025-03-22 05:33:52.911921:  
2025-03-22 05:33:52.918993: Epoch 123 
2025-03-22 05:33:52.924686: Current learning rate: 0.00889 
2025-03-22 05:34:35.675453: train_loss -0.8483 
2025-03-22 05:34:35.681973: val_loss -0.8202 
2025-03-22 05:34:35.686982: Pseudo dice [np.float64(0.9454), np.float64(0.9293), np.float64(0.9061)] 
2025-03-22 05:34:35.693001: Epoch time: 42.76 s 
2025-03-22 05:34:36.424500:  
2025-03-22 05:34:36.431686: Epoch 124 
2025-03-22 05:34:36.439057: Current learning rate: 0.00888 
2025-03-22 05:35:19.226143: train_loss -0.8414 
2025-03-22 05:35:19.234179: val_loss -0.8457 
2025-03-22 05:35:19.241196: Pseudo dice [np.float64(0.9397), np.float64(0.9227), np.float64(0.9164)] 
2025-03-22 05:35:19.245706: Epoch time: 42.8 s 
2025-03-22 05:35:19.982660:  
2025-03-22 05:35:19.988514: Epoch 125 
2025-03-22 05:35:19.993031: Current learning rate: 0.00887 
2025-03-22 05:36:02.970603: train_loss -0.8602 
2025-03-22 05:36:02.979624: val_loss -0.8416 
2025-03-22 05:36:02.985638: Pseudo dice [np.float64(0.936), np.float64(0.9324), np.float64(0.9194)] 
2025-03-22 05:36:02.992254: Epoch time: 42.99 s 
2025-03-22 05:36:03.728037:  
2025-03-22 05:36:03.735170: Epoch 126 
2025-03-22 05:36:03.739905: Current learning rate: 0.00886 
2025-03-22 05:36:46.700999: train_loss -0.8546 
2025-03-22 05:36:46.708527: val_loss -0.8179 
2025-03-22 05:36:46.713549: Pseudo dice [np.float64(0.9434), np.float64(0.9127), np.float64(0.9056)] 
2025-03-22 05:36:46.718564: Epoch time: 42.97 s 
2025-03-22 05:36:47.463972:  
2025-03-22 05:36:47.470986: Epoch 127 
2025-03-22 05:36:47.474995: Current learning rate: 0.00885 
2025-03-22 05:37:30.340537: train_loss -0.8564 
2025-03-22 05:37:30.348566: val_loss -0.8447 
2025-03-22 05:37:30.355583: Pseudo dice [np.float64(0.9459), np.float64(0.9254), np.float64(0.9154)] 
2025-03-22 05:37:30.362107: Epoch time: 42.88 s 
2025-03-22 05:37:31.100363:  
2025-03-22 05:37:31.106882: Epoch 128 
2025-03-22 05:37:31.113395: Current learning rate: 0.00884 
2025-03-22 05:38:14.106309: train_loss -0.8546 
2025-03-22 05:38:14.114326: val_loss -0.8271 
2025-03-22 05:38:14.120339: Pseudo dice [np.float64(0.9452), np.float64(0.9157), np.float64(0.9049)] 
2025-03-22 05:38:14.126859: Epoch time: 43.01 s 
2025-03-22 05:38:15.118099:  
2025-03-22 05:38:15.124748: Epoch 129 
2025-03-22 05:38:15.128303: Current learning rate: 0.00883 
2025-03-22 05:38:58.351714: train_loss -0.8475 
2025-03-22 05:38:58.359235: val_loss -0.8493 
2025-03-22 05:38:58.365765: Pseudo dice [np.float64(0.9398), np.float64(0.9384), np.float64(0.9209)] 
2025-03-22 05:38:58.371815: Epoch time: 43.23 s 
2025-03-22 05:38:59.140339:  
2025-03-22 05:38:59.147460: Epoch 130 
2025-03-22 05:38:59.151052: Current learning rate: 0.00882 
2025-03-22 05:39:42.238760: train_loss -0.8553 
2025-03-22 05:39:42.246274: val_loss -0.8458 
2025-03-22 05:39:42.251284: Pseudo dice [np.float64(0.9472), np.float64(0.9161), np.float64(0.9089)] 
2025-03-22 05:39:42.256295: Epoch time: 43.1 s 
2025-03-22 05:39:42.997244:  
2025-03-22 05:39:43.003321: Epoch 131 
2025-03-22 05:39:43.006406: Current learning rate: 0.00881 
2025-03-22 05:40:25.680491: train_loss -0.8538 
2025-03-22 05:40:25.688200: val_loss -0.8441 
2025-03-22 05:40:25.694215: Pseudo dice [np.float64(0.9499), np.float64(0.9222), np.float64(0.9172)] 
2025-03-22 05:40:25.699228: Epoch time: 42.68 s 
2025-03-22 05:40:26.482702:  
2025-03-22 05:40:26.489748: Epoch 132 
2025-03-22 05:40:26.495763: Current learning rate: 0.0088 
2025-03-22 05:41:09.302214: train_loss -0.8487 
2025-03-22 05:41:09.310242: val_loss -0.8449 
2025-03-22 05:41:09.315257: Pseudo dice [np.float64(0.947), np.float64(0.9119), np.float64(0.9068)] 
2025-03-22 05:41:09.320271: Epoch time: 42.82 s 
2025-03-22 05:41:10.096492:  
2025-03-22 05:41:10.104576: Epoch 133 
2025-03-22 05:41:10.110623: Current learning rate: 0.00879 
2025-03-22 05:41:52.961247: train_loss -0.853 
2025-03-22 05:41:52.968415: val_loss -0.8499 
2025-03-22 05:41:52.974544: Pseudo dice [np.float64(0.9435), np.float64(0.9283), np.float64(0.9151)] 
2025-03-22 05:41:52.980791: Epoch time: 42.87 s 
2025-03-22 05:41:53.711611:  
2025-03-22 05:41:53.718167: Epoch 134 
2025-03-22 05:41:53.723203: Current learning rate: 0.00879 
2025-03-22 05:42:36.478426: train_loss -0.8372 
2025-03-22 05:42:36.485942: val_loss -0.8395 
2025-03-22 05:42:36.490952: Pseudo dice [np.float64(0.9473), np.float64(0.924), np.float64(0.9084)] 
2025-03-22 05:42:36.495960: Epoch time: 42.77 s 
2025-03-22 05:42:37.253065:  
2025-03-22 05:42:37.259615: Epoch 135 
2025-03-22 05:42:37.264656: Current learning rate: 0.00878 
2025-03-22 05:43:20.092543: train_loss -0.8502 
2025-03-22 05:43:20.101255: val_loss -0.8278 
2025-03-22 05:43:20.108428: Pseudo dice [np.float64(0.9404), np.float64(0.9226), np.float64(0.9115)] 
2025-03-22 05:43:20.115160: Epoch time: 42.84 s 
2025-03-22 05:43:20.854635:  
2025-03-22 05:43:20.861864: Epoch 136 
2025-03-22 05:43:20.866989: Current learning rate: 0.00877 
2025-03-22 05:44:03.754326: train_loss -0.8581 
2025-03-22 05:44:03.763003: val_loss -0.8495 
2025-03-22 05:44:03.770065: Pseudo dice [np.float64(0.9466), np.float64(0.9422), np.float64(0.9159)] 
2025-03-22 05:44:03.775626: Epoch time: 42.9 s 
2025-03-22 05:44:04.557167:  
2025-03-22 05:44:04.563758: Epoch 137 
2025-03-22 05:44:04.568935: Current learning rate: 0.00876 
2025-03-22 05:44:47.306884: train_loss -0.8593 
2025-03-22 05:44:47.314404: val_loss -0.8527 
2025-03-22 05:44:47.320417: Pseudo dice [np.float64(0.9411), np.float64(0.9362), np.float64(0.9167)] 
2025-03-22 05:44:47.325433: Epoch time: 42.75 s 
2025-03-22 05:44:47.330446: Yayy! New best EMA pseudo Dice: 0.9272 
2025-03-22 05:44:48.449368:  
2025-03-22 05:44:48.454924: Epoch 138 
2025-03-22 05:44:48.459507: Current learning rate: 0.00875 
2025-03-22 05:45:32.265226: train_loss -0.8503 
2025-03-22 05:45:32.272334: val_loss -0.8503 
2025-03-22 05:45:32.276389: Pseudo dice [np.float64(0.9435), np.float64(0.9332), np.float64(0.9188)] 
2025-03-22 05:45:32.280294: Epoch time: 43.82 s 
2025-03-22 05:45:32.285410: Yayy! New best EMA pseudo Dice: 0.9277 
2025-03-22 05:45:33.128116:  
2025-03-22 05:45:33.135691: Epoch 139 
2025-03-22 05:45:33.140808: Current learning rate: 0.00874 
2025-03-22 05:46:16.243816: train_loss -0.8407 
2025-03-22 05:46:16.252346: val_loss -0.855 
2025-03-22 05:46:16.258862: Pseudo dice [np.float64(0.9497), np.float64(0.9392), np.float64(0.9195)] 
2025-03-22 05:46:16.264882: Epoch time: 43.12 s 
2025-03-22 05:46:16.271394: Yayy! New best EMA pseudo Dice: 0.9285 
2025-03-22 05:46:17.069793:  
2025-03-22 05:46:17.076459: Epoch 140 
2025-03-22 05:46:17.081010: Current learning rate: 0.00873 
2025-03-22 05:46:59.657362: train_loss -0.8425 
2025-03-22 05:46:59.664880: val_loss -0.8178 
2025-03-22 05:46:59.669893: Pseudo dice [np.float64(0.9455), np.float64(0.9263), np.float64(0.9126)] 
2025-03-22 05:46:59.673402: Epoch time: 42.59 s 
2025-03-22 05:47:00.415266:  
2025-03-22 05:47:00.421782: Epoch 141 
2025-03-22 05:47:00.428299: Current learning rate: 0.00872 
2025-03-22 05:47:43.348092: train_loss -0.8405 
2025-03-22 05:47:43.356193: val_loss -0.8431 
2025-03-22 05:47:43.363339: Pseudo dice [np.float64(0.9305), np.float64(0.9249), np.float64(0.9088)] 
2025-03-22 05:47:43.369355: Epoch time: 42.93 s 
2025-03-22 05:47:44.115012:  
2025-03-22 05:47:44.118557: Epoch 142 
2025-03-22 05:47:44.122568: Current learning rate: 0.00871 
2025-03-22 05:48:26.901916: train_loss -0.8428 
2025-03-22 05:48:26.908975: val_loss -0.8389 
2025-03-22 05:48:26.914016: Pseudo dice [np.float64(0.9412), np.float64(0.9287), np.float64(0.921)] 
2025-03-22 05:48:26.919057: Epoch time: 42.79 s 
2025-03-22 05:48:27.660218:  
2025-03-22 05:48:27.666786: Epoch 143 
2025-03-22 05:48:27.670836: Current learning rate: 0.0087 
2025-03-22 05:49:10.708420: train_loss -0.8449 
2025-03-22 05:49:10.716442: val_loss -0.8455 
2025-03-22 05:49:10.722532: Pseudo dice [np.float64(0.9517), np.float64(0.9312), np.float64(0.9159)] 
2025-03-22 05:49:10.728393: Epoch time: 43.05 s 
2025-03-22 05:49:11.497226:  
2025-03-22 05:49:11.505349: Epoch 144 
2025-03-22 05:49:11.510456: Current learning rate: 0.00869 
2025-03-22 05:49:54.337895: train_loss -0.8577 
2025-03-22 05:49:54.344420: val_loss -0.8389 
2025-03-22 05:49:54.350441: Pseudo dice [np.float64(0.9493), np.float64(0.9281), np.float64(0.9117)] 
2025-03-22 05:49:54.356569: Epoch time: 42.84 s 
2025-03-22 05:49:54.364200: Yayy! New best EMA pseudo Dice: 0.9286 
2025-03-22 05:49:55.194365:  
2025-03-22 05:49:55.200884: Epoch 145 
2025-03-22 05:49:55.206896: Current learning rate: 0.00868 
2025-03-22 05:50:37.967165: train_loss -0.8537 
2025-03-22 05:50:37.975192: val_loss -0.8651 
2025-03-22 05:50:37.981206: Pseudo dice [np.float64(0.9506), np.float64(0.9225), np.float64(0.9266)] 
2025-03-22 05:50:37.988729: Epoch time: 42.77 s 
2025-03-22 05:50:37.997759: Yayy! New best EMA pseudo Dice: 0.9291 
2025-03-22 05:50:39.095589:  
2025-03-22 05:50:39.102159: Epoch 146 
2025-03-22 05:50:39.106255: Current learning rate: 0.00868 
2025-03-22 05:51:21.943065: train_loss -0.8632 
2025-03-22 05:51:21.949579: val_loss -0.8616 
2025-03-22 05:51:21.955596: Pseudo dice [np.float64(0.943), np.float64(0.9287), np.float64(0.9168)] 
2025-03-22 05:51:21.960611: Epoch time: 42.85 s 
2025-03-22 05:51:21.967128: Yayy! New best EMA pseudo Dice: 0.9291 
2025-03-22 05:51:22.838393:  
2025-03-22 05:51:22.844501: Epoch 147 
2025-03-22 05:51:22.848559: Current learning rate: 0.00867 
2025-03-22 05:52:06.614623: train_loss -0.849 
2025-03-22 05:52:06.624840: val_loss -0.8385 
2025-03-22 05:52:06.631979: Pseudo dice [np.float64(0.9455), np.float64(0.9308), np.float64(0.9126)] 
2025-03-22 05:52:06.638288: Epoch time: 43.78 s 
2025-03-22 05:52:06.642316: Yayy! New best EMA pseudo Dice: 0.9292 
2025-03-22 05:52:07.510787:  
2025-03-22 05:52:07.518450: Epoch 148 
2025-03-22 05:52:07.524110: Current learning rate: 0.00866 
2025-03-22 05:52:50.594520: train_loss -0.8498 
2025-03-22 05:52:50.602044: val_loss -0.8613 
2025-03-22 05:52:50.608060: Pseudo dice [np.float64(0.9426), np.float64(0.9332), np.float64(0.9192)] 
2025-03-22 05:52:50.613075: Epoch time: 43.08 s 
2025-03-22 05:52:50.618085: Yayy! New best EMA pseudo Dice: 0.9294 
2025-03-22 05:52:51.471151:  
2025-03-22 05:52:51.478940: Epoch 149 
2025-03-22 05:52:51.484068: Current learning rate: 0.00865 
2025-03-22 05:53:34.362473: train_loss -0.8608 
2025-03-22 05:53:34.369527: val_loss -0.8621 
2025-03-22 05:53:34.376078: Pseudo dice [np.float64(0.9475), np.float64(0.9375), np.float64(0.9136)] 
2025-03-22 05:53:34.382115: Epoch time: 42.89 s 
2025-03-22 05:53:34.493186: Yayy! New best EMA pseudo Dice: 0.9298 
2025-03-22 05:53:35.332883:  
2025-03-22 05:53:35.338939: Epoch 150 
2025-03-22 05:53:35.344140: Current learning rate: 0.00864 
2025-03-22 05:54:18.308818: train_loss -0.8554 
2025-03-22 05:54:18.316334: val_loss -0.8265 
2025-03-22 05:54:18.322855: Pseudo dice [np.float64(0.933), np.float64(0.9179), np.float64(0.9055)] 
2025-03-22 05:54:18.328873: Epoch time: 42.98 s 
2025-03-22 05:54:19.084417:  
2025-03-22 05:54:19.090432: Epoch 151 
2025-03-22 05:54:19.095445: Current learning rate: 0.00863 
2025-03-22 05:55:01.895113: train_loss -0.8593 
2025-03-22 05:55:01.903140: val_loss -0.8316 
2025-03-22 05:55:01.908155: Pseudo dice [np.float64(0.9456), np.float64(0.9227), np.float64(0.9155)] 
2025-03-22 05:55:01.913167: Epoch time: 42.81 s 
2025-03-22 05:55:02.659506:  
2025-03-22 05:55:02.667572: Epoch 152 
2025-03-22 05:55:02.674319: Current learning rate: 0.00862 
2025-03-22 05:55:45.694753: train_loss -0.8634 
2025-03-22 05:55:45.704782: val_loss -0.8467 
2025-03-22 05:55:45.713808: Pseudo dice [np.float64(0.9387), np.float64(0.9295), np.float64(0.9077)] 
2025-03-22 05:55:45.718856: Epoch time: 43.04 s 
2025-03-22 05:55:46.515233:  
2025-03-22 05:55:46.522836: Epoch 153 
2025-03-22 05:55:46.528873: Current learning rate: 0.00861 
2025-03-22 05:56:29.457051: train_loss -0.8564 
2025-03-22 05:56:29.464105: val_loss -0.8363 
2025-03-22 05:56:29.468139: Pseudo dice [np.float64(0.945), np.float64(0.944), np.float64(0.9104)] 
2025-03-22 05:56:29.472672: Epoch time: 42.94 s 
2025-03-22 05:56:30.486912:  
2025-03-22 05:56:30.493499: Epoch 154 
2025-03-22 05:56:30.497545: Current learning rate: 0.0086 
2025-03-22 05:57:13.545556: train_loss -0.8605 
2025-03-22 05:57:13.553080: val_loss -0.8466 
2025-03-22 05:57:13.559101: Pseudo dice [np.float64(0.95), np.float64(0.9305), np.float64(0.9194)] 
2025-03-22 05:57:13.563116: Epoch time: 43.06 s 
2025-03-22 05:57:14.358402:  
2025-03-22 05:57:14.364958: Epoch 155 
2025-03-22 05:57:14.370319: Current learning rate: 0.00859 
2025-03-22 05:57:57.131156: train_loss -0.8525 
2025-03-22 05:57:57.138684: val_loss -0.8541 
2025-03-22 05:57:57.143696: Pseudo dice [np.float64(0.9441), np.float64(0.9379), np.float64(0.9181)] 
2025-03-22 05:57:57.146704: Epoch time: 42.77 s 
2025-03-22 05:57:57.905898:  
2025-03-22 05:57:57.913922: Epoch 156 
2025-03-22 05:57:57.918934: Current learning rate: 0.00858 
2025-03-22 05:58:41.368246: train_loss -0.8468 
2025-03-22 05:58:41.378279: val_loss -0.8476 
2025-03-22 05:58:41.385302: Pseudo dice [np.float64(0.9431), np.float64(0.9299), np.float64(0.9062)] 
2025-03-22 05:58:41.390826: Epoch time: 43.46 s 
2025-03-22 05:58:42.141280:  
2025-03-22 05:58:42.147804: Epoch 157 
2025-03-22 05:58:42.152818: Current learning rate: 0.00858 
2025-03-22 05:59:25.144293: train_loss -0.8522 
2025-03-22 05:59:25.153325: val_loss -0.8259 
2025-03-22 05:59:25.159853: Pseudo dice [np.float64(0.9414), np.float64(0.9098), np.float64(0.9066)] 
2025-03-22 05:59:25.164381: Epoch time: 43.0 s 
2025-03-22 05:59:25.936239:  
2025-03-22 05:59:25.942448: Epoch 158 
2025-03-22 05:59:25.948059: Current learning rate: 0.00857 
2025-03-22 06:00:08.921400: train_loss -0.851 
2025-03-22 06:00:08.928995: val_loss -0.8309 
2025-03-22 06:00:08.935061: Pseudo dice [np.float64(0.9401), np.float64(0.9231), np.float64(0.9071)] 
2025-03-22 06:00:08.941723: Epoch time: 42.99 s 
2025-03-22 06:00:09.734716:  
2025-03-22 06:00:09.741258: Epoch 159 
2025-03-22 06:00:09.744800: Current learning rate: 0.00856 
2025-03-22 06:00:52.709935: train_loss -0.8564 
2025-03-22 06:00:52.720615: val_loss -0.8685 
2025-03-22 06:00:52.728142: Pseudo dice [np.float64(0.9485), np.float64(0.9211), np.float64(0.9146)] 
2025-03-22 06:00:52.735191: Epoch time: 42.98 s 
2025-03-22 06:00:53.513945:  
2025-03-22 06:00:53.520461: Epoch 160 
2025-03-22 06:00:53.524971: Current learning rate: 0.00855 
2025-03-22 06:01:36.323172: train_loss -0.8598 
2025-03-22 06:01:36.331700: val_loss -0.8232 
2025-03-22 06:01:36.338223: Pseudo dice [np.float64(0.9403), np.float64(0.9247), np.float64(0.9107)] 
2025-03-22 06:01:36.345743: Epoch time: 42.81 s 
2025-03-22 06:01:37.101333:  
2025-03-22 06:01:37.108848: Epoch 161 
2025-03-22 06:01:37.112855: Current learning rate: 0.00854 
2025-03-22 06:02:20.021110: train_loss -0.8527 
2025-03-22 06:02:20.029131: val_loss -0.8446 
2025-03-22 06:02:20.037658: Pseudo dice [np.float64(0.9425), np.float64(0.943), np.float64(0.9258)] 
2025-03-22 06:02:20.044176: Epoch time: 42.92 s 
2025-03-22 06:02:21.010082:  
2025-03-22 06:02:21.015804: Epoch 162 
2025-03-22 06:02:21.018344: Current learning rate: 0.00853 
2025-03-22 06:03:04.133205: train_loss -0.8387 
2025-03-22 06:03:04.139850: val_loss -0.8258 
2025-03-22 06:03:04.148591: Pseudo dice [np.float64(0.9271), np.float64(0.927), np.float64(0.8943)] 
2025-03-22 06:03:04.156240: Epoch time: 43.12 s 
2025-03-22 06:03:04.926385:  
2025-03-22 06:03:04.933419: Epoch 163 
2025-03-22 06:03:04.939430: Current learning rate: 0.00852 
2025-03-22 06:03:47.756279: train_loss -0.8428 
2025-03-22 06:03:47.763795: val_loss -0.8445 
2025-03-22 06:03:47.768303: Pseudo dice [np.float64(0.9438), np.float64(0.9352), np.float64(0.9095)] 
2025-03-22 06:03:47.772312: Epoch time: 42.83 s 
2025-03-22 06:03:48.518579:  
2025-03-22 06:03:48.526159: Epoch 164 
2025-03-22 06:03:48.532338: Current learning rate: 0.00851 
2025-03-22 06:04:31.428607: train_loss -0.852 
2025-03-22 06:04:31.438133: val_loss -0.8589 
2025-03-22 06:04:31.444653: Pseudo dice [np.float64(0.9427), np.float64(0.9317), np.float64(0.913)] 
2025-03-22 06:04:31.450670: Epoch time: 42.91 s 
2025-03-22 06:04:32.200702:  
2025-03-22 06:04:32.207218: Epoch 165 
2025-03-22 06:04:32.212238: Current learning rate: 0.0085 
2025-03-22 06:05:16.150597: train_loss -0.8562 
2025-03-22 06:05:16.159713: val_loss -0.8562 
2025-03-22 06:05:16.166778: Pseudo dice [np.float64(0.9472), np.float64(0.9357), np.float64(0.9029)] 
2025-03-22 06:05:16.171317: Epoch time: 43.95 s 
2025-03-22 06:05:16.875865:  
2025-03-22 06:05:16.882439: Epoch 166 
2025-03-22 06:05:16.887496: Current learning rate: 0.00849 
2025-03-22 06:05:59.853565: train_loss -0.8627 
2025-03-22 06:05:59.861092: val_loss -0.8263 
2025-03-22 06:05:59.867615: Pseudo dice [np.float64(0.9447), np.float64(0.9263), np.float64(0.9195)] 
2025-03-22 06:05:59.874654: Epoch time: 42.98 s 
2025-03-22 06:06:00.607141:  
2025-03-22 06:06:00.613655: Epoch 167 
2025-03-22 06:06:00.618667: Current learning rate: 0.00848 
2025-03-22 06:06:43.369658: train_loss -0.8561 
2025-03-22 06:06:43.377722: val_loss -0.8615 
2025-03-22 06:06:43.384284: Pseudo dice [np.float64(0.945), np.float64(0.9283), np.float64(0.9191)] 
2025-03-22 06:06:43.390864: Epoch time: 42.76 s 
2025-03-22 06:06:44.147780:  
2025-03-22 06:06:44.154376: Epoch 168 
2025-03-22 06:06:44.158409: Current learning rate: 0.00847 
2025-03-22 06:07:27.127786: train_loss -0.8623 
2025-03-22 06:07:27.135303: val_loss -0.8265 
2025-03-22 06:07:27.141818: Pseudo dice [np.float64(0.9426), np.float64(0.9162), np.float64(0.8989)] 
2025-03-22 06:07:27.146828: Epoch time: 42.98 s 
2025-03-22 06:07:27.881660:  
2025-03-22 06:07:27.888286: Epoch 169 
2025-03-22 06:07:27.891826: Current learning rate: 0.00847 
2025-03-22 06:08:10.892554: train_loss -0.8548 
2025-03-22 06:08:10.899771: val_loss -0.8242 
2025-03-22 06:08:10.906998: Pseudo dice [np.float64(0.9248), np.float64(0.9176), np.float64(0.8958)] 
2025-03-22 06:08:10.913145: Epoch time: 43.01 s 
2025-03-22 06:08:11.852886:  
2025-03-22 06:08:11.860469: Epoch 170 
2025-03-22 06:08:11.863530: Current learning rate: 0.00846 
2025-03-22 06:08:54.643127: train_loss -0.8409 
2025-03-22 06:08:54.650654: val_loss -0.8276 
2025-03-22 06:08:54.655668: Pseudo dice [np.float64(0.942), np.float64(0.9162), np.float64(0.9075)] 
2025-03-22 06:08:54.660681: Epoch time: 42.79 s 
2025-03-22 06:08:55.422078:  
2025-03-22 06:08:55.428611: Epoch 171 
2025-03-22 06:08:55.433136: Current learning rate: 0.00845 
2025-03-22 06:09:38.452788: train_loss -0.8503 
2025-03-22 06:09:38.460307: val_loss -0.8668 
2025-03-22 06:09:38.467827: Pseudo dice [np.float64(0.9428), np.float64(0.9438), np.float64(0.9133)] 
2025-03-22 06:09:38.474845: Epoch time: 43.03 s 
2025-03-22 06:09:39.226259:  
2025-03-22 06:09:39.235069: Epoch 172 
2025-03-22 06:09:39.240082: Current learning rate: 0.00844 
2025-03-22 06:10:21.984576: train_loss -0.8513 
2025-03-22 06:10:21.993098: val_loss -0.837 
2025-03-22 06:10:22.001127: Pseudo dice [np.float64(0.9386), np.float64(0.9215), np.float64(0.904)] 
2025-03-22 06:10:22.009651: Epoch time: 42.76 s 
2025-03-22 06:10:22.773667:  
2025-03-22 06:10:22.780272: Epoch 173 
2025-03-22 06:10:22.784809: Current learning rate: 0.00843 
2025-03-22 06:11:05.610651: train_loss -0.8447 
2025-03-22 06:11:05.618757: val_loss -0.8336 
2025-03-22 06:11:05.625948: Pseudo dice [np.float64(0.9426), np.float64(0.9318), np.float64(0.9031)] 
2025-03-22 06:11:05.632045: Epoch time: 42.84 s 
2025-03-22 06:11:06.410695:  
2025-03-22 06:11:06.416720: Epoch 174 
2025-03-22 06:11:06.420738: Current learning rate: 0.00842 
2025-03-22 06:11:50.730805: train_loss -0.8553 
2025-03-22 06:11:50.738320: val_loss -0.8452 
2025-03-22 06:11:50.744837: Pseudo dice [np.float64(0.9495), np.float64(0.936), np.float64(0.9152)] 
2025-03-22 06:11:50.749848: Epoch time: 44.32 s 
2025-03-22 06:11:51.520112:  
2025-03-22 06:11:51.527174: Epoch 175 
2025-03-22 06:11:51.530711: Current learning rate: 0.00841 
2025-03-22 06:12:34.543210: train_loss -0.8594 
2025-03-22 06:12:34.553427: val_loss -0.8493 
2025-03-22 06:12:34.561139: Pseudo dice [np.float64(0.9455), np.float64(0.9488), np.float64(0.9199)] 
2025-03-22 06:12:34.567944: Epoch time: 43.02 s 
2025-03-22 06:12:35.325284:  
2025-03-22 06:12:35.332477: Epoch 176 
2025-03-22 06:12:35.338114: Current learning rate: 0.0084 
2025-03-22 06:13:18.464230: train_loss -0.8652 
2025-03-22 06:13:18.471751: val_loss -0.8546 
2025-03-22 06:13:18.479271: Pseudo dice [np.float64(0.9431), np.float64(0.9406), np.float64(0.9113)] 
2025-03-22 06:13:18.486793: Epoch time: 43.14 s 
2025-03-22 06:13:19.234768:  
2025-03-22 06:13:19.242378: Epoch 177 
2025-03-22 06:13:19.248498: Current learning rate: 0.00839 
2025-03-22 06:14:02.379563: train_loss -0.8573 
2025-03-22 06:14:02.385576: val_loss -0.8182 
2025-03-22 06:14:02.389594: Pseudo dice [np.float64(0.9431), np.float64(0.9147), np.float64(0.911)] 
2025-03-22 06:14:02.393108: Epoch time: 43.15 s 
2025-03-22 06:14:03.424099:  
2025-03-22 06:14:03.429662: Epoch 178 
2025-03-22 06:14:03.432210: Current learning rate: 0.00838 
2025-03-22 06:14:46.420025: train_loss -0.8516 
2025-03-22 06:14:46.428547: val_loss -0.8197 
2025-03-22 06:14:46.436070: Pseudo dice [np.float64(0.9353), np.float64(0.9214), np.float64(0.9083)] 
2025-03-22 06:14:46.441081: Epoch time: 43.0 s 
2025-03-22 06:14:47.216707:  
2025-03-22 06:14:47.223222: Epoch 179 
2025-03-22 06:14:47.228234: Current learning rate: 0.00837 
2025-03-22 06:15:30.207309: train_loss -0.8526 
2025-03-22 06:15:30.214325: val_loss -0.8479 
2025-03-22 06:15:30.218338: Pseudo dice [np.float64(0.9462), np.float64(0.9103), np.float64(0.9178)] 
2025-03-22 06:15:30.222379: Epoch time: 42.99 s 
2025-03-22 06:15:30.957687:  
2025-03-22 06:15:30.963706: Epoch 180 
2025-03-22 06:15:30.967715: Current learning rate: 0.00836 
2025-03-22 06:16:14.063906: train_loss -0.8435 
2025-03-22 06:16:14.069999: val_loss -0.8238 
2025-03-22 06:16:14.075599: Pseudo dice [np.float64(0.9482), np.float64(0.947), np.float64(0.9157)] 
2025-03-22 06:16:14.079636: Epoch time: 43.11 s 
2025-03-22 06:16:14.833399:  
2025-03-22 06:16:14.840024: Epoch 181 
2025-03-22 06:16:14.844594: Current learning rate: 0.00836 
2025-03-22 06:16:57.965915: train_loss -0.8618 
2025-03-22 06:16:57.973434: val_loss -0.8455 
2025-03-22 06:16:57.979953: Pseudo dice [np.float64(0.9375), np.float64(0.921), np.float64(0.9117)] 
2025-03-22 06:16:57.987478: Epoch time: 43.13 s 
2025-03-22 06:16:58.743664:  
2025-03-22 06:16:58.749709: Epoch 182 
2025-03-22 06:16:58.754861: Current learning rate: 0.00835 
2025-03-22 06:17:41.709082: train_loss -0.8551 
2025-03-22 06:17:41.716666: val_loss -0.8342 
2025-03-22 06:17:41.722266: Pseudo dice [np.float64(0.9492), np.float64(0.927), np.float64(0.9197)] 
2025-03-22 06:17:41.729427: Epoch time: 42.97 s 
2025-03-22 06:17:42.474843:  
2025-03-22 06:17:42.482399: Epoch 183 
2025-03-22 06:17:42.488148: Current learning rate: 0.00834 
2025-03-22 06:18:25.382189: train_loss -0.8564 
2025-03-22 06:18:25.389717: val_loss -0.8396 
2025-03-22 06:18:25.393728: Pseudo dice [np.float64(0.9399), np.float64(0.9296), np.float64(0.9228)] 
2025-03-22 06:18:25.399747: Epoch time: 42.91 s 
2025-03-22 06:18:26.148757:  
2025-03-22 06:18:26.155775: Epoch 184 
2025-03-22 06:18:26.159785: Current learning rate: 0.00833 
2025-03-22 06:19:09.226025: train_loss -0.8526 
2025-03-22 06:19:09.234560: val_loss -0.8519 
2025-03-22 06:19:09.241083: Pseudo dice [np.float64(0.9415), np.float64(0.9382), np.float64(0.9124)] 
2025-03-22 06:19:09.246099: Epoch time: 43.08 s 
2025-03-22 06:19:10.006691:  
2025-03-22 06:19:10.012270: Epoch 185 
2025-03-22 06:19:10.016394: Current learning rate: 0.00832 
2025-03-22 06:19:53.008249: train_loss -0.8634 
2025-03-22 06:19:53.014264: val_loss -0.85 
2025-03-22 06:19:53.018273: Pseudo dice [np.float64(0.9417), np.float64(0.9344), np.float64(0.9143)] 
2025-03-22 06:19:53.025294: Epoch time: 43.0 s 
2025-03-22 06:19:53.787833:  
2025-03-22 06:19:53.794929: Epoch 186 
2025-03-22 06:19:53.798476: Current learning rate: 0.00831 
2025-03-22 06:20:36.725878: train_loss -0.8602 
2025-03-22 06:20:36.733395: val_loss -0.8368 
2025-03-22 06:20:36.737407: Pseudo dice [np.float64(0.9353), np.float64(0.9306), np.float64(0.898)] 
2025-03-22 06:20:36.741413: Epoch time: 42.94 s 
2025-03-22 06:20:37.746396:  
2025-03-22 06:20:37.752410: Epoch 187 
2025-03-22 06:20:37.755917: Current learning rate: 0.0083 
2025-03-22 06:21:20.745555: train_loss -0.8648 
2025-03-22 06:21:20.753079: val_loss -0.8477 
2025-03-22 06:21:20.759091: Pseudo dice [np.float64(0.9509), np.float64(0.9362), np.float64(0.9217)] 
2025-03-22 06:21:20.764612: Epoch time: 43.0 s 
2025-03-22 06:21:21.503522:  
2025-03-22 06:21:21.509575: Epoch 188 
2025-03-22 06:21:21.513618: Current learning rate: 0.00829 
2025-03-22 06:22:04.389333: train_loss -0.8616 
2025-03-22 06:22:04.396852: val_loss -0.828 
2025-03-22 06:22:04.403367: Pseudo dice [np.float64(0.951), np.float64(0.935), np.float64(0.902)] 
2025-03-22 06:22:04.409388: Epoch time: 42.89 s 
2025-03-22 06:22:05.175557:  
2025-03-22 06:22:05.182189: Epoch 189 
2025-03-22 06:22:05.187737: Current learning rate: 0.00828 
2025-03-22 06:22:48.200650: train_loss -0.8576 
2025-03-22 06:22:48.207174: val_loss -0.8295 
2025-03-22 06:22:48.213696: Pseudo dice [np.float64(0.9481), np.float64(0.9386), np.float64(0.9161)] 
2025-03-22 06:22:48.219716: Epoch time: 43.03 s 
2025-03-22 06:22:49.204534:  
2025-03-22 06:22:49.212564: Epoch 190 
2025-03-22 06:22:49.216078: Current learning rate: 0.00827 
2025-03-22 06:23:31.983160: train_loss -0.851 
2025-03-22 06:23:31.989686: val_loss -0.8446 
2025-03-22 06:23:31.993700: Pseudo dice [np.float64(0.944), np.float64(0.94), np.float64(0.9183)] 
2025-03-22 06:23:31.997216: Epoch time: 42.78 s 
2025-03-22 06:23:32.002232: Yayy! New best EMA pseudo Dice: 0.9298 
2025-03-22 06:23:32.850778:  
2025-03-22 06:23:32.856846: Epoch 191 
2025-03-22 06:23:32.861474: Current learning rate: 0.00826 
2025-03-22 06:24:15.757017: train_loss -0.8576 
2025-03-22 06:24:15.763066: val_loss -0.8488 
2025-03-22 06:24:15.767076: Pseudo dice [np.float64(0.9473), np.float64(0.9347), np.float64(0.9213)] 
2025-03-22 06:24:15.772092: Epoch time: 42.91 s 
2025-03-22 06:24:15.778108: Yayy! New best EMA pseudo Dice: 0.9302 
2025-03-22 06:24:16.680322:  
2025-03-22 06:24:16.685981: Epoch 192 
2025-03-22 06:24:16.690573: Current learning rate: 0.00825 
2025-03-22 06:24:59.609674: train_loss -0.864 
2025-03-22 06:24:59.616190: val_loss -0.8375 
2025-03-22 06:24:59.622212: Pseudo dice [np.float64(0.9394), np.float64(0.929), np.float64(0.9133)] 
2025-03-22 06:24:59.628229: Epoch time: 42.93 s 
2025-03-22 06:25:00.409311:  
2025-03-22 06:25:00.414861: Epoch 193 
2025-03-22 06:25:00.419428: Current learning rate: 0.00824 
2025-03-22 06:25:43.253361: train_loss -0.8586 
2025-03-22 06:25:43.259877: val_loss -0.8671 
2025-03-22 06:25:43.265894: Pseudo dice [np.float64(0.9468), np.float64(0.935), np.float64(0.9174)] 
2025-03-22 06:25:43.269903: Epoch time: 42.84 s 
2025-03-22 06:25:43.273411: Yayy! New best EMA pseudo Dice: 0.9303 
2025-03-22 06:25:44.144182:  
2025-03-22 06:25:44.150738: Epoch 194 
2025-03-22 06:25:44.154273: Current learning rate: 0.00824 
2025-03-22 06:26:29.474613: train_loss -0.8549 
2025-03-22 06:26:29.482258: val_loss -0.8451 
2025-03-22 06:26:29.486876: Pseudo dice [np.float64(0.9433), np.float64(0.9295), np.float64(0.9082)] 
2025-03-22 06:26:29.490933: Epoch time: 45.33 s 
2025-03-22 06:26:30.502722:  
2025-03-22 06:26:30.507829: Epoch 195 
2025-03-22 06:26:30.511485: Current learning rate: 0.00823 
2025-03-22 06:27:13.650885: train_loss -0.8445 
2025-03-22 06:27:13.657397: val_loss -0.8155 
2025-03-22 06:27:13.662408: Pseudo dice [np.float64(0.9322), np.float64(0.8877), np.float64(0.908)] 
2025-03-22 06:27:13.668426: Epoch time: 43.15 s 
2025-03-22 06:27:14.449129:  
2025-03-22 06:27:14.454688: Epoch 196 
2025-03-22 06:27:14.459272: Current learning rate: 0.00822 
2025-03-22 06:27:57.191675: train_loss -0.8558 
2025-03-22 06:27:57.198203: val_loss -0.8373 
2025-03-22 06:27:57.203220: Pseudo dice [np.float64(0.942), np.float64(0.9169), np.float64(0.9171)] 
2025-03-22 06:27:57.208236: Epoch time: 42.74 s 
2025-03-22 06:27:57.979239:  
2025-03-22 06:27:57.985985: Epoch 197 
2025-03-22 06:27:57.991585: Current learning rate: 0.00821 
2025-03-22 06:28:40.843772: train_loss -0.8546 
2025-03-22 06:28:40.850316: val_loss -0.8429 
2025-03-22 06:28:40.854328: Pseudo dice [np.float64(0.9452), np.float64(0.9295), np.float64(0.9228)] 
2025-03-22 06:28:40.859349: Epoch time: 42.86 s 
2025-03-22 06:28:41.627085:  
2025-03-22 06:28:41.633658: Epoch 198 
2025-03-22 06:28:41.638725: Current learning rate: 0.0082 
2025-03-22 06:29:24.246063: train_loss -0.8529 
2025-03-22 06:29:24.252589: val_loss -0.8279 
2025-03-22 06:29:24.256601: Pseudo dice [np.float64(0.9386), np.float64(0.9183), np.float64(0.9129)] 
2025-03-22 06:29:24.261771: Epoch time: 42.62 s 
2025-03-22 06:29:25.056674:  
2025-03-22 06:29:25.063235: Epoch 199 
2025-03-22 06:29:25.067892: Current learning rate: 0.00819 
2025-03-22 06:30:08.132121: train_loss -0.8485 
2025-03-22 06:30:08.140643: val_loss -0.8513 
2025-03-22 06:30:08.146654: Pseudo dice [np.float64(0.947), np.float64(0.9348), np.float64(0.9083)] 
2025-03-22 06:30:08.151665: Epoch time: 43.08 s 
2025-03-22 06:30:09.019600:  
2025-03-22 06:30:09.026688: Epoch 200 
2025-03-22 06:30:09.032777: Current learning rate: 0.00818 
2025-03-22 06:30:51.946768: train_loss -0.8451 
2025-03-22 06:30:51.952784: val_loss -0.8532 
2025-03-22 06:30:51.957798: Pseudo dice [np.float64(0.9442), np.float64(0.9235), np.float64(0.9091)] 
2025-03-22 06:30:51.963816: Epoch time: 42.93 s 
2025-03-22 06:30:52.717598:  
2025-03-22 06:30:52.723123: Epoch 201 
2025-03-22 06:30:52.728670: Current learning rate: 0.00817 
2025-03-22 06:31:35.632114: train_loss -0.8573 
2025-03-22 06:31:35.638704: val_loss -0.8431 
2025-03-22 06:31:35.643549: Pseudo dice [np.float64(0.9481), np.float64(0.9273), np.float64(0.9073)] 
2025-03-22 06:31:35.647735: Epoch time: 42.92 s 
2025-03-22 06:31:36.376265:  
2025-03-22 06:31:36.381815: Epoch 202 
2025-03-22 06:31:36.386434: Current learning rate: 0.00816 
2025-03-22 06:32:19.098530: train_loss -0.8593 
2025-03-22 06:32:19.105602: val_loss -0.827 
2025-03-22 06:32:19.109642: Pseudo dice [np.float64(0.9411), np.float64(0.907), np.float64(0.9134)] 
2025-03-22 06:32:19.115690: Epoch time: 42.72 s 
2025-03-22 06:32:20.143923:  
2025-03-22 06:32:20.149965: Epoch 203 
2025-03-22 06:32:20.153008: Current learning rate: 0.00815 
2025-03-22 06:33:04.654526: train_loss -0.853 
2025-03-22 06:33:04.662553: val_loss -0.8383 
2025-03-22 06:33:04.668571: Pseudo dice [np.float64(0.9408), np.float64(0.9307), np.float64(0.9012)] 
2025-03-22 06:33:04.672587: Epoch time: 44.51 s 
2025-03-22 06:33:05.411230:  
2025-03-22 06:33:05.417246: Epoch 204 
2025-03-22 06:33:05.421254: Current learning rate: 0.00814 
2025-03-22 06:33:48.308206: train_loss -0.8524 
2025-03-22 06:33:48.315727: val_loss -0.8374 
2025-03-22 06:33:48.321744: Pseudo dice [np.float64(0.9447), np.float64(0.937), np.float64(0.9136)] 
2025-03-22 06:33:48.328262: Epoch time: 42.9 s 
2025-03-22 06:33:49.103119:  
2025-03-22 06:33:49.109697: Epoch 205 
2025-03-22 06:33:49.113731: Current learning rate: 0.00813 
2025-03-22 06:34:31.840430: train_loss -0.8521 
2025-03-22 06:34:31.847946: val_loss -0.834 
2025-03-22 06:34:31.852959: Pseudo dice [np.float64(0.9438), np.float64(0.9276), np.float64(0.9143)] 
2025-03-22 06:34:31.859005: Epoch time: 42.74 s 
2025-03-22 06:34:32.577292:  
2025-03-22 06:34:32.583852: Epoch 206 
2025-03-22 06:34:32.587863: Current learning rate: 0.00813 
2025-03-22 06:35:15.512734: train_loss -0.8592 
2025-03-22 06:35:15.518854: val_loss -0.8607 
2025-03-22 06:35:15.524895: Pseudo dice [np.float64(0.9445), np.float64(0.9327), np.float64(0.924)] 
2025-03-22 06:35:15.531074: Epoch time: 42.94 s 
2025-03-22 06:35:16.275726:  
2025-03-22 06:35:16.281299: Epoch 207 
2025-03-22 06:35:16.285865: Current learning rate: 0.00812 
2025-03-22 06:35:58.983473: train_loss -0.8588 
2025-03-22 06:35:58.989491: val_loss -0.8603 
2025-03-22 06:35:58.993507: Pseudo dice [np.float64(0.9469), np.float64(0.9354), np.float64(0.9247)] 
2025-03-22 06:35:58.997017: Epoch time: 42.71 s 
2025-03-22 06:35:59.697005:  
2025-03-22 06:35:59.702559: Epoch 208 
2025-03-22 06:35:59.707131: Current learning rate: 0.00811 
2025-03-22 06:36:42.684079: train_loss -0.8617 
2025-03-22 06:36:42.690092: val_loss -0.8705 
2025-03-22 06:36:42.694233: Pseudo dice [np.float64(0.9538), np.float64(0.9493), np.float64(0.9235)] 
2025-03-22 06:36:42.698242: Epoch time: 42.99 s 
2025-03-22 06:36:43.418439:  
2025-03-22 06:36:43.424467: Epoch 209 
2025-03-22 06:36:43.430489: Current learning rate: 0.0081 
2025-03-22 06:37:26.322165: train_loss -0.8504 
2025-03-22 06:37:26.328198: val_loss -0.8649 
2025-03-22 06:37:26.332239: Pseudo dice [np.float64(0.9442), np.float64(0.9334), np.float64(0.9073)] 
2025-03-22 06:37:26.335291: Epoch time: 42.9 s 
2025-03-22 06:37:27.089033:  
2025-03-22 06:37:27.095652: Epoch 210 
2025-03-22 06:37:27.098191: Current learning rate: 0.00809 
2025-03-22 06:38:09.941541: train_loss -0.8555 
2025-03-22 06:38:09.949065: val_loss -0.8555 
2025-03-22 06:38:09.953577: Pseudo dice [np.float64(0.9474), np.float64(0.9329), np.float64(0.9162)] 
2025-03-22 06:38:09.957595: Epoch time: 42.85 s 
2025-03-22 06:38:10.956680:  
2025-03-22 06:38:10.963232: Epoch 211 
2025-03-22 06:38:10.969304: Current learning rate: 0.00808 
2025-03-22 06:38:53.883570: train_loss -0.8577 
2025-03-22 06:38:53.890419: val_loss -0.8481 
2025-03-22 06:38:53.897465: Pseudo dice [np.float64(0.944), np.float64(0.9259), np.float64(0.9229)] 
2025-03-22 06:38:53.905671: Epoch time: 42.93 s 
2025-03-22 06:38:54.645235:  
2025-03-22 06:38:54.650760: Epoch 212 
2025-03-22 06:38:54.654273: Current learning rate: 0.00807 
2025-03-22 06:39:39.113234: train_loss -0.86 
2025-03-22 06:39:39.120750: val_loss -0.8576 
2025-03-22 06:39:39.125259: Pseudo dice [np.float64(0.9492), np.float64(0.9338), np.float64(0.9178)] 
2025-03-22 06:39:39.130770: Epoch time: 44.47 s 
2025-03-22 06:39:39.136786: Yayy! New best EMA pseudo Dice: 0.9305 
2025-03-22 06:39:39.957227:  
2025-03-22 06:39:39.962750: Epoch 213 
2025-03-22 06:39:39.967802: Current learning rate: 0.00806 
2025-03-22 06:40:22.823991: train_loss -0.8628 
2025-03-22 06:40:22.830508: val_loss -0.8411 
2025-03-22 06:40:22.835525: Pseudo dice [np.float64(0.9262), np.float64(0.934), np.float64(0.9181)] 
2025-03-22 06:40:22.842107: Epoch time: 42.87 s 
2025-03-22 06:40:23.560312:  
2025-03-22 06:40:23.565866: Epoch 214 
2025-03-22 06:40:23.569906: Current learning rate: 0.00805 
2025-03-22 06:41:06.543062: train_loss -0.8514 
2025-03-22 06:41:06.550117: val_loss -0.8511 
2025-03-22 06:41:06.556265: Pseudo dice [np.float64(0.9524), np.float64(0.9297), np.float64(0.9233)] 
2025-03-22 06:41:06.561340: Epoch time: 42.98 s 
2025-03-22 06:41:06.565885: Yayy! New best EMA pseudo Dice: 0.9306 
2025-03-22 06:41:07.380520:  
2025-03-22 06:41:07.388039: Epoch 215 
2025-03-22 06:41:07.392048: Current learning rate: 0.00804 
2025-03-22 06:41:50.141305: train_loss -0.8545 
2025-03-22 06:41:50.148388: val_loss -0.8524 
2025-03-22 06:41:50.152422: Pseudo dice [np.float64(0.9521), np.float64(0.9339), np.float64(0.9229)] 
2025-03-22 06:41:50.158435: Epoch time: 42.76 s 
2025-03-22 06:41:50.164452: Yayy! New best EMA pseudo Dice: 0.9312 
2025-03-22 06:41:51.018681:  
2025-03-22 06:41:51.025298: Epoch 216 
2025-03-22 06:41:51.029367: Current learning rate: 0.00803 
2025-03-22 06:42:33.786178: train_loss -0.8571 
2025-03-22 06:42:33.793700: val_loss -0.8283 
2025-03-22 06:42:33.800756: Pseudo dice [np.float64(0.9479), np.float64(0.9214), np.float64(0.9093)] 
2025-03-22 06:42:33.808601: Epoch time: 42.77 s 
2025-03-22 06:42:34.544288:  
2025-03-22 06:42:34.551917: Epoch 217 
2025-03-22 06:42:34.559576: Current learning rate: 0.00802 
2025-03-22 06:43:17.500090: train_loss -0.8703 
2025-03-22 06:43:17.507609: val_loss -0.8335 
2025-03-22 06:43:17.513633: Pseudo dice [np.float64(0.9405), np.float64(0.9361), np.float64(0.9281)] 
2025-03-22 06:43:17.520151: Epoch time: 42.96 s 
2025-03-22 06:43:18.256261:  
2025-03-22 06:43:18.261949: Epoch 218 
2025-03-22 06:43:18.267036: Current learning rate: 0.00801 
2025-03-22 06:44:01.083370: train_loss -0.8628 
2025-03-22 06:44:01.089939: val_loss -0.8552 
2025-03-22 06:44:01.094474: Pseudo dice [np.float64(0.9424), np.float64(0.933), np.float64(0.9195)] 
2025-03-22 06:44:01.100495: Epoch time: 42.83 s 
2025-03-22 06:44:01.797204:  
2025-03-22 06:44:01.806319: Epoch 219 
2025-03-22 06:44:01.813432: Current learning rate: 0.00801 
2025-03-22 06:44:44.951585: train_loss -0.8643 
2025-03-22 06:44:44.958103: val_loss -0.8627 
2025-03-22 06:44:44.962111: Pseudo dice [np.float64(0.9499), np.float64(0.9427), np.float64(0.9184)] 
2025-03-22 06:44:44.965621: Epoch time: 43.15 s 
2025-03-22 06:44:44.969128: Yayy! New best EMA pseudo Dice: 0.9317 
2025-03-22 06:44:46.019079:  
2025-03-22 06:44:46.025605: Epoch 220 
2025-03-22 06:44:46.029623: Current learning rate: 0.008 
2025-03-22 06:45:28.889413: train_loss -0.8543 
2025-03-22 06:45:28.896999: val_loss -0.8312 
2025-03-22 06:45:28.901117: Pseudo dice [np.float64(0.9474), np.float64(0.9292), np.float64(0.9137)] 
2025-03-22 06:45:28.904625: Epoch time: 42.87 s 
2025-03-22 06:45:29.625304:  
2025-03-22 06:45:29.631866: Epoch 221 
2025-03-22 06:45:29.635465: Current learning rate: 0.00799 
2025-03-22 06:46:13.778319: train_loss -0.8622 
2025-03-22 06:46:13.783329: val_loss -0.8623 
2025-03-22 06:46:13.787336: Pseudo dice [np.float64(0.9486), np.float64(0.9141), np.float64(0.916)] 
2025-03-22 06:46:13.790844: Epoch time: 44.15 s 
2025-03-22 06:46:14.525566:  
2025-03-22 06:46:14.530577: Epoch 222 
2025-03-22 06:46:14.535589: Current learning rate: 0.00798 
2025-03-22 06:46:57.654211: train_loss -0.845 
2025-03-22 06:46:57.661317: val_loss -0.8616 
2025-03-22 06:46:57.665874: Pseudo dice [np.float64(0.9389), np.float64(0.9347), np.float64(0.9144)] 
2025-03-22 06:46:57.669982: Epoch time: 43.13 s 
2025-03-22 06:46:58.384973:  
2025-03-22 06:46:58.391558: Epoch 223 
2025-03-22 06:46:58.396134: Current learning rate: 0.00797 
2025-03-22 06:47:41.308965: train_loss -0.854 
2025-03-22 06:47:41.315989: val_loss -0.8558 
2025-03-22 06:47:41.322506: Pseudo dice [np.float64(0.9483), np.float64(0.9331), np.float64(0.9229)] 
2025-03-22 06:47:41.329028: Epoch time: 42.92 s 
2025-03-22 06:47:42.065774:  
2025-03-22 06:47:42.072295: Epoch 224 
2025-03-22 06:47:42.078314: Current learning rate: 0.00796 
2025-03-22 06:48:25.019735: train_loss -0.8592 
2025-03-22 06:48:25.027255: val_loss -0.8353 
2025-03-22 06:48:25.030766: Pseudo dice [np.float64(0.9504), np.float64(0.9087), np.float64(0.9193)] 
2025-03-22 06:48:25.034273: Epoch time: 42.95 s 
2025-03-22 06:48:25.742426:  
2025-03-22 06:48:25.750527: Epoch 225 
2025-03-22 06:48:25.756168: Current learning rate: 0.00795 
2025-03-22 06:49:08.696280: train_loss -0.8597 
2025-03-22 06:49:08.703882: val_loss -0.8269 
2025-03-22 06:49:08.708429: Pseudo dice [np.float64(0.9433), np.float64(0.9285), np.float64(0.9077)] 
2025-03-22 06:49:08.713561: Epoch time: 42.95 s 
2025-03-22 06:49:09.432983:  
2025-03-22 06:49:09.439037: Epoch 226 
2025-03-22 06:49:09.443069: Current learning rate: 0.00794 
2025-03-22 06:49:52.252132: train_loss -0.8587 
2025-03-22 06:49:52.258650: val_loss -0.8215 
2025-03-22 06:49:52.264667: Pseudo dice [np.float64(0.9505), np.float64(0.9219), np.float64(0.9065)] 
2025-03-22 06:49:52.271185: Epoch time: 42.82 s 
2025-03-22 06:49:52.982785:  
2025-03-22 06:49:52.988810: Epoch 227 
2025-03-22 06:49:52.992825: Current learning rate: 0.00793 
2025-03-22 06:50:35.822301: train_loss -0.8605 
2025-03-22 06:50:35.829326: val_loss -0.8468 
2025-03-22 06:50:35.833340: Pseudo dice [np.float64(0.9434), np.float64(0.926), np.float64(0.9158)] 
2025-03-22 06:50:35.837358: Epoch time: 42.84 s 
2025-03-22 06:50:36.808891:  
2025-03-22 06:50:36.815020: Epoch 228 
2025-03-22 06:50:36.817537: Current learning rate: 0.00792 
2025-03-22 06:51:19.770512: train_loss -0.8532 
2025-03-22 06:51:19.778184: val_loss -0.8425 
2025-03-22 06:51:19.784774: Pseudo dice [np.float64(0.9377), np.float64(0.9264), np.float64(0.9086)] 
2025-03-22 06:51:19.792421: Epoch time: 42.96 s 
2025-03-22 06:51:20.500358:  
2025-03-22 06:51:20.507414: Epoch 229 
2025-03-22 06:51:20.510498: Current learning rate: 0.00791 
2025-03-22 06:52:03.484962: train_loss -0.8524 
2025-03-22 06:52:03.492482: val_loss -0.8398 
2025-03-22 06:52:03.497497: Pseudo dice [np.float64(0.9466), np.float64(0.9448), np.float64(0.9232)] 
2025-03-22 06:52:03.502511: Epoch time: 42.98 s 
2025-03-22 06:52:04.234107:  
2025-03-22 06:52:04.239448: Epoch 230 
2025-03-22 06:52:04.243981: Current learning rate: 0.0079 
2025-03-22 06:52:48.517005: train_loss -0.8574 
2025-03-22 06:52:48.524523: val_loss -0.8461 
2025-03-22 06:52:48.530547: Pseudo dice [np.float64(0.9469), np.float64(0.9298), np.float64(0.9154)] 
2025-03-22 06:52:48.534557: Epoch time: 44.28 s 
2025-03-22 06:52:49.248743:  
2025-03-22 06:52:49.255460: Epoch 231 
2025-03-22 06:52:49.260546: Current learning rate: 0.00789 
2025-03-22 06:53:32.376624: train_loss -0.8536 
2025-03-22 06:53:32.382138: val_loss -0.8622 
2025-03-22 06:53:32.388158: Pseudo dice [np.float64(0.946), np.float64(0.9243), np.float64(0.9096)] 
2025-03-22 06:53:32.394674: Epoch time: 43.13 s 
2025-03-22 06:53:33.124918:  
2025-03-22 06:53:33.131440: Epoch 232 
2025-03-22 06:53:33.136454: Current learning rate: 0.00789 
2025-03-22 06:54:16.196676: train_loss -0.8506 
2025-03-22 06:54:16.203196: val_loss -0.8403 
2025-03-22 06:54:16.208207: Pseudo dice [np.float64(0.9448), np.float64(0.934), np.float64(0.9099)] 
2025-03-22 06:54:16.212214: Epoch time: 43.07 s 
2025-03-22 06:54:16.961182:  
2025-03-22 06:54:16.966736: Epoch 233 
2025-03-22 06:54:16.971294: Current learning rate: 0.00788 
2025-03-22 06:54:59.897582: train_loss -0.8481 
2025-03-22 06:54:59.905202: val_loss -0.8643 
2025-03-22 06:54:59.913845: Pseudo dice [np.float64(0.9509), np.float64(0.9231), np.float64(0.9176)] 
2025-03-22 06:54:59.921959: Epoch time: 42.94 s 
2025-03-22 06:55:00.675221:  
2025-03-22 06:55:00.681742: Epoch 234 
2025-03-22 06:55:00.685252: Current learning rate: 0.00787 
2025-03-22 06:55:43.720974: train_loss -0.8588 
2025-03-22 06:55:43.730500: val_loss -0.8396 
2025-03-22 06:55:43.738028: Pseudo dice [np.float64(0.9452), np.float64(0.9302), np.float64(0.9203)] 
2025-03-22 06:55:43.743542: Epoch time: 43.05 s 
2025-03-22 06:55:44.467978:  
2025-03-22 06:55:44.473502: Epoch 235 
2025-03-22 06:55:44.478019: Current learning rate: 0.00786 
2025-03-22 06:56:27.291109: train_loss -0.8537 
2025-03-22 06:56:27.298629: val_loss -0.8597 
2025-03-22 06:56:27.304652: Pseudo dice [np.float64(0.9478), np.float64(0.9449), np.float64(0.9201)] 
2025-03-22 06:56:27.311172: Epoch time: 42.82 s 
2025-03-22 06:56:28.049953:  
2025-03-22 06:56:28.056027: Epoch 236 
2025-03-22 06:56:28.061100: Current learning rate: 0.00785 
2025-03-22 06:57:11.219581: train_loss -0.8556 
2025-03-22 06:57:11.227100: val_loss -0.8523 
2025-03-22 06:57:11.233617: Pseudo dice [np.float64(0.9468), np.float64(0.9359), np.float64(0.9179)] 
2025-03-22 06:57:11.239638: Epoch time: 43.17 s 
2025-03-22 06:57:12.225255:  
2025-03-22 06:57:12.232780: Epoch 237 
2025-03-22 06:57:12.236292: Current learning rate: 0.00784 
2025-03-22 06:57:55.232845: train_loss -0.855 
2025-03-22 06:57:55.240883: val_loss -0.8332 
2025-03-22 06:57:55.247401: Pseudo dice [np.float64(0.9421), np.float64(0.9245), np.float64(0.9054)] 
2025-03-22 06:57:55.254926: Epoch time: 43.01 s 
2025-03-22 06:57:55.961000:  
2025-03-22 06:57:55.967517: Epoch 238 
2025-03-22 06:57:55.971025: Current learning rate: 0.00783 
2025-03-22 06:58:38.846259: train_loss -0.8601 
2025-03-22 06:58:38.853782: val_loss -0.834 
2025-03-22 06:58:38.859796: Pseudo dice [np.float64(0.9461), np.float64(0.9343), np.float64(0.925)] 
2025-03-22 06:58:38.864806: Epoch time: 42.89 s 
2025-03-22 06:58:39.605659:  
2025-03-22 06:58:39.613178: Epoch 239 
2025-03-22 06:58:39.617200: Current learning rate: 0.00782 
2025-03-22 06:59:23.275680: train_loss -0.8595 
2025-03-22 06:59:23.281729: val_loss -0.8556 
2025-03-22 06:59:23.284756: Pseudo dice [np.float64(0.9485), np.float64(0.9419), np.float64(0.9197)] 
2025-03-22 06:59:23.288275: Epoch time: 43.67 s 
2025-03-22 06:59:24.010827:  
2025-03-22 06:59:24.017107: Epoch 240 
2025-03-22 06:59:24.021318: Current learning rate: 0.00781 
2025-03-22 07:00:07.133657: train_loss -0.8651 
2025-03-22 07:00:07.140188: val_loss -0.8425 
2025-03-22 07:00:07.144726: Pseudo dice [np.float64(0.9377), np.float64(0.9197), np.float64(0.9144)] 
2025-03-22 07:00:07.150264: Epoch time: 43.12 s 
2025-03-22 07:00:07.890267:  
2025-03-22 07:00:07.898423: Epoch 241 
2025-03-22 07:00:07.902997: Current learning rate: 0.0078 
2025-03-22 07:00:50.874937: train_loss -0.8485 
2025-03-22 07:00:50.882592: val_loss -0.8552 
2025-03-22 07:00:50.886148: Pseudo dice [np.float64(0.9508), np.float64(0.9297), np.float64(0.9074)] 
2025-03-22 07:00:50.889655: Epoch time: 42.98 s 
2025-03-22 07:00:51.625166:  
2025-03-22 07:00:51.631891: Epoch 242 
2025-03-22 07:00:51.635461: Current learning rate: 0.00779 
2025-03-22 07:01:34.419479: train_loss -0.8667 
2025-03-22 07:01:34.426492: val_loss -0.8786 
2025-03-22 07:01:34.430508: Pseudo dice [np.float64(0.9479), np.float64(0.9384), np.float64(0.916)] 
2025-03-22 07:01:34.434521: Epoch time: 42.8 s 
2025-03-22 07:01:35.198055:  
2025-03-22 07:01:35.205249: Epoch 243 
2025-03-22 07:01:35.210416: Current learning rate: 0.00778 
2025-03-22 07:02:18.011678: train_loss -0.8622 
2025-03-22 07:02:18.019202: val_loss -0.8271 
2025-03-22 07:02:18.025723: Pseudo dice [np.float64(0.9432), np.float64(0.9343), np.float64(0.9202)] 
2025-03-22 07:02:18.030235: Epoch time: 42.81 s 
2025-03-22 07:02:18.754026:  
2025-03-22 07:02:18.760132: Epoch 244 
2025-03-22 07:02:18.764702: Current learning rate: 0.00777 
2025-03-22 07:03:01.591877: train_loss -0.8607 
2025-03-22 07:03:01.599395: val_loss -0.8399 
2025-03-22 07:03:01.605408: Pseudo dice [np.float64(0.946), np.float64(0.9226), np.float64(0.9202)] 
2025-03-22 07:03:01.610421: Epoch time: 42.84 s 
2025-03-22 07:03:02.602700:  
2025-03-22 07:03:02.609321: Epoch 245 
2025-03-22 07:03:02.613375: Current learning rate: 0.00777 
2025-03-22 07:03:45.568481: train_loss -0.859 
2025-03-22 07:03:45.577235: val_loss -0.8579 
2025-03-22 07:03:45.584362: Pseudo dice [np.float64(0.9418), np.float64(0.926), np.float64(0.907)] 
2025-03-22 07:03:45.592055: Epoch time: 42.97 s 
2025-03-22 07:03:46.337945:  
2025-03-22 07:03:46.344052: Epoch 246 
2025-03-22 07:03:46.347722: Current learning rate: 0.00776 
2025-03-22 07:04:29.246274: train_loss -0.8595 
2025-03-22 07:04:29.252796: val_loss -0.8467 
2025-03-22 07:04:29.259311: Pseudo dice [np.float64(0.9408), np.float64(0.9353), np.float64(0.9208)] 
2025-03-22 07:04:29.266411: Epoch time: 42.91 s 
2025-03-22 07:04:29.969550:  
2025-03-22 07:04:29.975066: Epoch 247 
2025-03-22 07:04:29.978578: Current learning rate: 0.00775 
2025-03-22 07:05:12.769369: train_loss -0.8584 
2025-03-22 07:05:12.775429: val_loss -0.8279 
2025-03-22 07:05:12.780464: Pseudo dice [np.float64(0.9437), np.float64(0.9257), np.float64(0.9179)] 
2025-03-22 07:05:12.787001: Epoch time: 42.8 s 
2025-03-22 07:05:13.493149:  
2025-03-22 07:05:13.500745: Epoch 248 
2025-03-22 07:05:13.505305: Current learning rate: 0.00774 
2025-03-22 07:05:56.908542: train_loss -0.8584 
2025-03-22 07:05:56.916566: val_loss -0.8724 
2025-03-22 07:05:56.921582: Pseudo dice [np.float64(0.9485), np.float64(0.944), np.float64(0.9223)] 
2025-03-22 07:05:56.926603: Epoch time: 43.42 s 
2025-03-22 07:05:57.660970:  
2025-03-22 07:05:57.667500: Epoch 249 
2025-03-22 07:05:57.671021: Current learning rate: 0.00773 
2025-03-22 07:06:40.743577: train_loss -0.8662 
2025-03-22 07:06:40.751147: val_loss -0.8443 
2025-03-22 07:06:40.755686: Pseudo dice [np.float64(0.9493), np.float64(0.9255), np.float64(0.916)] 
2025-03-22 07:06:40.759225: Epoch time: 43.08 s 
2025-03-22 07:06:41.577514:  
2025-03-22 07:06:41.583587: Epoch 250 
2025-03-22 07:06:41.588658: Current learning rate: 0.00772 
2025-03-22 07:07:24.594284: train_loss -0.8615 
2025-03-22 07:07:24.601802: val_loss -0.8609 
2025-03-22 07:07:24.606821: Pseudo dice [np.float64(0.9435), np.float64(0.948), np.float64(0.9096)] 
2025-03-22 07:07:24.611361: Epoch time: 43.02 s 
2025-03-22 07:07:25.350459:  
2025-03-22 07:07:25.356552: Epoch 251 
2025-03-22 07:07:25.360561: Current learning rate: 0.00771 
2025-03-22 07:08:08.106222: train_loss -0.8476 
2025-03-22 07:08:08.112322: val_loss -0.8417 
2025-03-22 07:08:08.119391: Pseudo dice [np.float64(0.9401), np.float64(0.9365), np.float64(0.9072)] 
2025-03-22 07:08:08.123927: Epoch time: 42.76 s 
2025-03-22 07:08:08.844301:  
2025-03-22 07:08:08.849864: Epoch 252 
2025-03-22 07:08:08.857045: Current learning rate: 0.0077 
2025-03-22 07:08:51.976876: train_loss -0.866 
2025-03-22 07:08:51.984050: val_loss -0.8161 
2025-03-22 07:08:51.989173: Pseudo dice [np.float64(0.9389), np.float64(0.9153), np.float64(0.9095)] 
2025-03-22 07:08:51.993199: Epoch time: 43.13 s 
2025-03-22 07:08:52.744582:  
2025-03-22 07:08:52.751143: Epoch 253 
2025-03-22 07:08:52.755187: Current learning rate: 0.00769 
2025-03-22 07:09:35.387740: train_loss -0.8634 
2025-03-22 07:09:35.393908: val_loss -0.8602 
2025-03-22 07:09:35.401549: Pseudo dice [np.float64(0.9504), np.float64(0.9265), np.float64(0.9162)] 
2025-03-22 07:09:35.407698: Epoch time: 42.64 s 
2025-03-22 07:09:36.380909:  
2025-03-22 07:09:36.386979: Epoch 254 
2025-03-22 07:09:36.391141: Current learning rate: 0.00768 
2025-03-22 07:10:19.312092: train_loss -0.8573 
2025-03-22 07:10:19.319689: val_loss -0.8444 
2025-03-22 07:10:19.326787: Pseudo dice [np.float64(0.9499), np.float64(0.8936), np.float64(0.9168)] 
2025-03-22 07:10:19.331843: Epoch time: 42.93 s 
2025-03-22 07:10:20.073635:  
2025-03-22 07:10:20.079706: Epoch 255 
2025-03-22 07:10:20.082808: Current learning rate: 0.00767 
2025-03-22 07:11:03.032861: train_loss -0.8692 
2025-03-22 07:11:03.040377: val_loss -0.8447 
2025-03-22 07:11:03.047903: Pseudo dice [np.float64(0.9487), np.float64(0.939), np.float64(0.9142)] 
2025-03-22 07:11:03.052917: Epoch time: 42.96 s 
2025-03-22 07:11:03.799264:  
2025-03-22 07:11:03.804950: Epoch 256 
2025-03-22 07:11:03.809004: Current learning rate: 0.00766 
2025-03-22 07:11:46.706873: train_loss -0.8596 
2025-03-22 07:11:46.713382: val_loss -0.8353 
2025-03-22 07:11:46.716891: Pseudo dice [np.float64(0.9475), np.float64(0.9193), np.float64(0.9002)] 
2025-03-22 07:11:46.720898: Epoch time: 42.91 s 
2025-03-22 07:11:47.447578:  
2025-03-22 07:11:47.454096: Epoch 257 
2025-03-22 07:11:47.457603: Current learning rate: 0.00765 
2025-03-22 07:12:31.042928: train_loss -0.8569 
2025-03-22 07:12:31.049979: val_loss -0.8576 
2025-03-22 07:12:31.055102: Pseudo dice [np.float64(0.947), np.float64(0.9396), np.float64(0.9194)] 
2025-03-22 07:12:31.059652: Epoch time: 43.6 s 
2025-03-22 07:12:31.798521:  
2025-03-22 07:12:31.804614: Epoch 258 
2025-03-22 07:12:31.811229: Current learning rate: 0.00764 
2025-03-22 07:13:14.608385: train_loss -0.8528 
2025-03-22 07:13:14.615436: val_loss -0.84 
2025-03-22 07:13:14.618958: Pseudo dice [np.float64(0.949), np.float64(0.915), np.float64(0.9037)] 
2025-03-22 07:13:14.622484: Epoch time: 42.81 s 
2025-03-22 07:13:15.319321:  
2025-03-22 07:13:15.326369: Epoch 259 
2025-03-22 07:13:15.330488: Current learning rate: 0.00764 
2025-03-22 07:13:58.279870: train_loss -0.8626 
2025-03-22 07:13:58.286388: val_loss -0.8281 
2025-03-22 07:13:58.291401: Pseudo dice [np.float64(0.945), np.float64(0.9298), np.float64(0.8993)] 
2025-03-22 07:13:58.297418: Epoch time: 42.96 s 
2025-03-22 07:13:59.042312:  
2025-03-22 07:13:59.047485: Epoch 260 
2025-03-22 07:13:59.050036: Current learning rate: 0.00763 
2025-03-22 07:14:42.208837: train_loss -0.8582 
2025-03-22 07:14:42.217664: val_loss -0.8401 
2025-03-22 07:14:42.223762: Pseudo dice [np.float64(0.9424), np.float64(0.937), np.float64(0.914)] 
2025-03-22 07:14:42.231015: Epoch time: 43.17 s 
2025-03-22 07:14:42.955169:  
2025-03-22 07:14:42.960181: Epoch 261 
2025-03-22 07:14:42.963692: Current learning rate: 0.00762 
2025-03-22 07:15:25.907767: train_loss -0.8583 
2025-03-22 07:15:25.914820: val_loss -0.8367 
2025-03-22 07:15:25.918871: Pseudo dice [np.float64(0.9418), np.float64(0.9331), np.float64(0.9178)] 
2025-03-22 07:15:25.922985: Epoch time: 42.95 s 
2025-03-22 07:15:26.895986:  
2025-03-22 07:15:26.902592: Epoch 262 
2025-03-22 07:15:26.906128: Current learning rate: 0.00761 
2025-03-22 07:16:09.876801: train_loss -0.865 
2025-03-22 07:16:09.883317: val_loss -0.8582 
2025-03-22 07:16:09.889333: Pseudo dice [np.float64(0.9501), np.float64(0.9483), np.float64(0.9306)] 
2025-03-22 07:16:09.895853: Epoch time: 42.98 s 
2025-03-22 07:16:10.614822:  
2025-03-22 07:16:10.621393: Epoch 263 
2025-03-22 07:16:10.626573: Current learning rate: 0.0076 
2025-03-22 07:16:53.405867: train_loss -0.8552 
2025-03-22 07:16:53.412414: val_loss -0.8527 
2025-03-22 07:16:53.416012: Pseudo dice [np.float64(0.9472), np.float64(0.9289), np.float64(0.9132)] 
2025-03-22 07:16:53.421049: Epoch time: 42.79 s 
2025-03-22 07:16:54.172797:  
2025-03-22 07:16:54.178942: Epoch 264 
2025-03-22 07:16:54.182487: Current learning rate: 0.00759 
2025-03-22 07:17:37.115349: train_loss -0.8618 
2025-03-22 07:17:37.122427: val_loss -0.8561 
2025-03-22 07:17:37.126953: Pseudo dice [np.float64(0.9464), np.float64(0.9501), np.float64(0.9223)] 
2025-03-22 07:17:37.130483: Epoch time: 42.94 s 
2025-03-22 07:17:37.867319:  
2025-03-22 07:17:37.873835: Epoch 265 
2025-03-22 07:17:37.878846: Current learning rate: 0.00758 
2025-03-22 07:18:20.946970: train_loss -0.8572 
2025-03-22 07:18:20.954513: val_loss -0.8439 
2025-03-22 07:18:20.959523: Pseudo dice [np.float64(0.9472), np.float64(0.9334), np.float64(0.9129)] 
2025-03-22 07:18:20.966036: Epoch time: 43.08 s 
2025-03-22 07:18:21.711473:  
2025-03-22 07:18:21.717538: Epoch 266 
2025-03-22 07:18:21.723660: Current learning rate: 0.00757 
2025-03-22 07:19:05.612549: train_loss -0.8617 
2025-03-22 07:19:05.621259: val_loss -0.8738 
2025-03-22 07:19:05.628362: Pseudo dice [np.float64(0.9507), np.float64(0.9398), np.float64(0.9297)] 
2025-03-22 07:19:05.636625: Epoch time: 43.9 s 
2025-03-22 07:19:05.642231: Yayy! New best EMA pseudo Dice: 0.9321 
2025-03-22 07:19:06.521044:  
2025-03-22 07:19:06.527598: Epoch 267 
2025-03-22 07:19:06.530665: Current learning rate: 0.00756 
2025-03-22 07:19:49.743018: train_loss -0.8578 
2025-03-22 07:19:49.749586: val_loss -0.8409 
2025-03-22 07:19:49.754646: Pseudo dice [np.float64(0.9436), np.float64(0.939), np.float64(0.9219)] 
2025-03-22 07:19:49.760703: Epoch time: 43.22 s 
2025-03-22 07:19:49.764755: Yayy! New best EMA pseudo Dice: 0.9324 
2025-03-22 07:19:50.661315:  
2025-03-22 07:19:50.667387: Epoch 268 
2025-03-22 07:19:50.672493: Current learning rate: 0.00755 
2025-03-22 07:20:33.348881: train_loss -0.8503 
2025-03-22 07:20:33.355403: val_loss -0.8373 
2025-03-22 07:20:33.360415: Pseudo dice [np.float64(0.9393), np.float64(0.9301), np.float64(0.9174)] 
2025-03-22 07:20:33.363925: Epoch time: 42.69 s 
2025-03-22 07:20:34.126808:  
2025-03-22 07:20:34.133924: Epoch 269 
2025-03-22 07:20:34.137454: Current learning rate: 0.00754 
2025-03-22 07:21:17.001975: train_loss -0.8571 
2025-03-22 07:21:17.009000: val_loss -0.8474 
2025-03-22 07:21:17.015522: Pseudo dice [np.float64(0.9513), np.float64(0.9437), np.float64(0.9096)] 
2025-03-22 07:21:17.019533: Epoch time: 42.88 s 
2025-03-22 07:21:17.748184:  
2025-03-22 07:21:17.753703: Epoch 270 
2025-03-22 07:21:17.758715: Current learning rate: 0.00753 
2025-03-22 07:22:00.923347: train_loss -0.8592 
2025-03-22 07:22:00.932931: val_loss -0.8308 
2025-03-22 07:22:00.938500: Pseudo dice [np.float64(0.9539), np.float64(0.9374), np.float64(0.9021)] 
2025-03-22 07:22:00.944555: Epoch time: 43.18 s 
2025-03-22 07:22:01.851909:  
2025-03-22 07:22:01.857470: Epoch 271 
2025-03-22 07:22:01.861532: Current learning rate: 0.00752 
2025-03-22 07:22:44.647622: train_loss -0.8628 
2025-03-22 07:22:44.655801: val_loss -0.8325 
2025-03-22 07:22:44.660915: Pseudo dice [np.float64(0.9407), np.float64(0.9209), np.float64(0.9088)] 
2025-03-22 07:22:44.670781: Epoch time: 42.8 s 
2025-03-22 07:22:45.409128:  
2025-03-22 07:22:45.415727: Epoch 272 
2025-03-22 07:22:45.420943: Current learning rate: 0.00751 
2025-03-22 07:23:28.162898: train_loss -0.8654 
2025-03-22 07:23:28.169413: val_loss -0.8413 
2025-03-22 07:23:28.174426: Pseudo dice [np.float64(0.9454), np.float64(0.9338), np.float64(0.912)] 
2025-03-22 07:23:28.177936: Epoch time: 42.75 s 
2025-03-22 07:23:28.917020:  
2025-03-22 07:23:28.923142: Epoch 273 
2025-03-22 07:23:28.927678: Current learning rate: 0.00751 
2025-03-22 07:24:11.625539: train_loss -0.8588 
2025-03-22 07:24:11.634101: val_loss -0.8685 
2025-03-22 07:24:11.639134: Pseudo dice [np.float64(0.9451), np.float64(0.941), np.float64(0.9207)] 
2025-03-22 07:24:11.644177: Epoch time: 42.71 s 
2025-03-22 07:24:12.376921:  
2025-03-22 07:24:12.383497: Epoch 274 
2025-03-22 07:24:12.388579: Current learning rate: 0.0075 
2025-03-22 07:24:55.431355: train_loss -0.8555 
2025-03-22 07:24:55.438369: val_loss -0.8686 
2025-03-22 07:24:55.443884: Pseudo dice [np.float64(0.9471), np.float64(0.945), np.float64(0.9192)] 
2025-03-22 07:24:55.448898: Epoch time: 43.06 s 
2025-03-22 07:24:56.162229:  
2025-03-22 07:24:56.167743: Epoch 275 
2025-03-22 07:24:56.171253: Current learning rate: 0.00749 
2025-03-22 07:25:40.211305: train_loss -0.8677 
2025-03-22 07:25:40.220892: val_loss -0.817 
2025-03-22 07:25:40.226471: Pseudo dice [np.float64(0.9388), np.float64(0.9135), np.float64(0.9063)] 
2025-03-22 07:25:40.231529: Epoch time: 44.05 s 
2025-03-22 07:25:40.971495:  
2025-03-22 07:25:40.978543: Epoch 276 
2025-03-22 07:25:40.983561: Current learning rate: 0.00748 
2025-03-22 07:26:23.863175: train_loss -0.8555 
2025-03-22 07:26:23.870694: val_loss -0.8343 
2025-03-22 07:26:23.875208: Pseudo dice [np.float64(0.9447), np.float64(0.9357), np.float64(0.9065)] 
2025-03-22 07:26:23.880221: Epoch time: 42.89 s 
2025-03-22 07:26:24.619445:  
2025-03-22 07:26:24.625513: Epoch 277 
2025-03-22 07:26:24.628564: Current learning rate: 0.00747 
2025-03-22 07:27:07.620801: train_loss -0.8566 
2025-03-22 07:27:07.630838: val_loss -0.8544 
2025-03-22 07:27:07.637359: Pseudo dice [np.float64(0.9467), np.float64(0.932), np.float64(0.9141)] 
2025-03-22 07:27:07.643377: Epoch time: 43.0 s 
2025-03-22 07:27:08.384911:  
2025-03-22 07:27:08.389624: Epoch 278 
2025-03-22 07:27:08.393693: Current learning rate: 0.00746 
2025-03-22 07:27:51.189499: train_loss -0.8632 
2025-03-22 07:27:51.198024: val_loss -0.8807 
2025-03-22 07:27:51.204037: Pseudo dice [np.float64(0.9528), np.float64(0.9587), np.float64(0.9322)] 
2025-03-22 07:27:51.209049: Epoch time: 42.81 s 
2025-03-22 07:27:51.212057: Yayy! New best EMA pseudo Dice: 0.9325 
2025-03-22 07:27:52.058623:  
2025-03-22 07:27:52.064145: Epoch 279 
2025-03-22 07:27:52.067656: Current learning rate: 0.00745 
2025-03-22 07:28:35.038379: train_loss -0.844 
2025-03-22 07:28:35.044902: val_loss -0.8217 
2025-03-22 07:28:35.051417: Pseudo dice [np.float64(0.9324), np.float64(0.9397), np.float64(0.9019)] 
2025-03-22 07:28:35.056430: Epoch time: 42.98 s 
2025-03-22 07:28:36.030796:  
2025-03-22 07:28:36.036909: Epoch 280 
2025-03-22 07:28:36.040226: Current learning rate: 0.00744 
2025-03-22 07:29:18.809761: train_loss -0.8608 
2025-03-22 07:29:18.817283: val_loss -0.8481 
2025-03-22 07:29:18.820794: Pseudo dice [np.float64(0.9439), np.float64(0.9262), np.float64(0.912)] 
2025-03-22 07:29:18.824804: Epoch time: 42.78 s 
2025-03-22 07:29:19.555356:  
2025-03-22 07:29:19.561897: Epoch 281 
2025-03-22 07:29:19.565931: Current learning rate: 0.00743 
2025-03-22 07:30:02.437589: train_loss -0.8606 
2025-03-22 07:30:02.444606: val_loss -0.8531 
2025-03-22 07:30:02.448621: Pseudo dice [np.float64(0.9519), np.float64(0.9398), np.float64(0.9281)] 
2025-03-22 07:30:02.455143: Epoch time: 42.88 s 
2025-03-22 07:30:03.194116:  
2025-03-22 07:30:03.200742: Epoch 282 
2025-03-22 07:30:03.204770: Current learning rate: 0.00742 
2025-03-22 07:30:46.040780: train_loss -0.8647 
2025-03-22 07:30:46.047294: val_loss -0.8416 
2025-03-22 07:30:46.052310: Pseudo dice [np.float64(0.9472), np.float64(0.9339), np.float64(0.9154)] 
2025-03-22 07:30:46.057323: Epoch time: 42.85 s 
2025-03-22 07:30:46.832948:  
2025-03-22 07:30:46.838517: Epoch 283 
2025-03-22 07:30:46.842034: Current learning rate: 0.00741 
2025-03-22 07:31:29.665488: train_loss -0.8612 
2025-03-22 07:31:29.675521: val_loss -0.8684 
2025-03-22 07:31:29.681540: Pseudo dice [np.float64(0.9533), np.float64(0.9437), np.float64(0.9165)] 
2025-03-22 07:31:29.688056: Epoch time: 42.83 s 
2025-03-22 07:31:29.693071: Yayy! New best EMA pseudo Dice: 0.9327 
2025-03-22 07:31:30.528054:  
2025-03-22 07:31:30.535607: Epoch 284 
2025-03-22 07:31:30.540655: Current learning rate: 0.0074 
2025-03-22 07:32:15.012618: train_loss -0.858 
2025-03-22 07:32:15.021139: val_loss -0.8581 
2025-03-22 07:32:15.026152: Pseudo dice [np.float64(0.9495), np.float64(0.9282), np.float64(0.9171)] 
2025-03-22 07:32:15.029161: Epoch time: 44.48 s 
2025-03-22 07:32:15.760728:  
2025-03-22 07:32:15.768116: Epoch 285 
2025-03-22 07:32:15.773877: Current learning rate: 0.00739 
2025-03-22 07:32:58.608791: train_loss -0.8688 
2025-03-22 07:32:58.616311: val_loss -0.8507 
2025-03-22 07:32:58.622326: Pseudo dice [np.float64(0.9487), np.float64(0.916), np.float64(0.9064)] 
2025-03-22 07:32:58.627345: Epoch time: 42.85 s 
2025-03-22 07:32:59.386179:  
2025-03-22 07:32:59.392754: Epoch 286 
2025-03-22 07:32:59.397666: Current learning rate: 0.00738 
2025-03-22 07:33:42.373757: train_loss -0.8679 
2025-03-22 07:33:42.381457: val_loss -0.8632 
2025-03-22 07:33:42.387999: Pseudo dice [np.float64(0.9478), np.float64(0.9355), np.float64(0.9167)] 
2025-03-22 07:33:42.394098: Epoch time: 42.99 s 
2025-03-22 07:33:43.166377:  
2025-03-22 07:33:43.171895: Epoch 287 
2025-03-22 07:33:43.175404: Current learning rate: 0.00738 
2025-03-22 07:34:26.247091: train_loss -0.8596 
2025-03-22 07:34:26.255718: val_loss -0.8644 
2025-03-22 07:34:26.262966: Pseudo dice [np.float64(0.948), np.float64(0.9248), np.float64(0.9248)] 
2025-03-22 07:34:26.269441: Epoch time: 43.08 s 
2025-03-22 07:34:27.264115:  
2025-03-22 07:34:27.270637: Epoch 288 
2025-03-22 07:34:27.274143: Current learning rate: 0.00737 
2025-03-22 07:35:09.855524: train_loss -0.8646 
2025-03-22 07:35:09.863045: val_loss -0.8354 
2025-03-22 07:35:09.867052: Pseudo dice [np.float64(0.9492), np.float64(0.9017), np.float64(0.8986)] 
2025-03-22 07:35:09.870559: Epoch time: 42.59 s 
2025-03-22 07:35:10.615221:  
2025-03-22 07:35:10.620762: Epoch 289 
2025-03-22 07:35:10.628523: Current learning rate: 0.00736 
2025-03-22 07:35:53.454847: train_loss -0.8555 
2025-03-22 07:35:53.460861: val_loss -0.8489 
2025-03-22 07:35:53.465872: Pseudo dice [np.float64(0.9446), np.float64(0.9409), np.float64(0.9186)] 
2025-03-22 07:35:53.469880: Epoch time: 42.84 s 
2025-03-22 07:35:54.185405:  
2025-03-22 07:35:54.194644: Epoch 290 
2025-03-22 07:35:54.200217: Current learning rate: 0.00735 
2025-03-22 07:36:37.080509: train_loss -0.8648 
2025-03-22 07:36:37.087025: val_loss -0.8431 
2025-03-22 07:36:37.093043: Pseudo dice [np.float64(0.944), np.float64(0.9501), np.float64(0.9208)] 
2025-03-22 07:36:37.099060: Epoch time: 42.9 s 
2025-03-22 07:36:37.851408:  
2025-03-22 07:36:37.858928: Epoch 291 
2025-03-22 07:36:37.864944: Current learning rate: 0.00734 
2025-03-22 07:37:20.853545: train_loss -0.8623 
2025-03-22 07:37:20.860608: val_loss -0.8254 
2025-03-22 07:37:20.866701: Pseudo dice [np.float64(0.9388), np.float64(0.9263), np.float64(0.9077)] 
2025-03-22 07:37:20.873788: Epoch time: 43.0 s 
2025-03-22 07:37:21.636780:  
2025-03-22 07:37:21.643359: Epoch 292 
2025-03-22 07:37:21.647419: Current learning rate: 0.00733 
2025-03-22 07:38:04.659614: train_loss -0.862 
2025-03-22 07:38:04.668141: val_loss -0.8322 
2025-03-22 07:38:04.674658: Pseudo dice [np.float64(0.9488), np.float64(0.9227), np.float64(0.9213)] 
2025-03-22 07:38:04.678169: Epoch time: 43.02 s 
2025-03-22 07:38:05.451510:  
2025-03-22 07:38:05.458145: Epoch 293 
2025-03-22 07:38:05.463225: Current learning rate: 0.00732 
2025-03-22 07:38:49.383217: train_loss -0.8647 
2025-03-22 07:38:49.390736: val_loss -0.8541 
2025-03-22 07:38:49.398261: Pseudo dice [np.float64(0.9472), np.float64(0.9446), np.float64(0.9202)] 
2025-03-22 07:38:49.403275: Epoch time: 43.93 s 
2025-03-22 07:38:50.182089:  
2025-03-22 07:38:50.189749: Epoch 294 
2025-03-22 07:38:50.194764: Current learning rate: 0.00731 
2025-03-22 07:39:33.216325: train_loss -0.8566 
2025-03-22 07:39:33.222341: val_loss -0.8412 
2025-03-22 07:39:33.228857: Pseudo dice [np.float64(0.9374), np.float64(0.9289), np.float64(0.9132)] 
2025-03-22 07:39:33.234873: Epoch time: 43.03 s 
2025-03-22 07:39:34.014616:  
2025-03-22 07:39:34.021268: Epoch 295 
2025-03-22 07:39:34.026335: Current learning rate: 0.0073 
2025-03-22 07:40:16.930431: train_loss -0.8495 
2025-03-22 07:40:16.937951: val_loss -0.84 
2025-03-22 07:40:16.942963: Pseudo dice [np.float64(0.9437), np.float64(0.9345), np.float64(0.9139)] 
2025-03-22 07:40:16.946769: Epoch time: 42.92 s 
2025-03-22 07:40:17.930040:  
2025-03-22 07:40:17.936596: Epoch 296 
2025-03-22 07:40:17.941252: Current learning rate: 0.00729 
2025-03-22 07:41:00.784875: train_loss -0.8767 
2025-03-22 07:41:00.791406: val_loss -0.8567 
2025-03-22 07:41:00.797423: Pseudo dice [np.float64(0.951), np.float64(0.9287), np.float64(0.917)] 
2025-03-22 07:41:00.803940: Epoch time: 42.86 s 
2025-03-22 07:41:01.572180:  
2025-03-22 07:41:01.579291: Epoch 297 
2025-03-22 07:41:01.582872: Current learning rate: 0.00728 
2025-03-22 07:41:44.550462: train_loss -0.8709 
2025-03-22 07:41:44.561121: val_loss -0.8832 
2025-03-22 07:41:44.569234: Pseudo dice [np.float64(0.9484), np.float64(0.9524), np.float64(0.9142)] 
2025-03-22 07:41:44.575818: Epoch time: 42.98 s 
2025-03-22 07:41:45.318212:  
2025-03-22 07:41:45.324274: Epoch 298 
2025-03-22 07:41:45.329355: Current learning rate: 0.00727 
2025-03-22 07:42:28.098949: train_loss -0.866 
2025-03-22 07:42:28.105495: val_loss -0.8598 
2025-03-22 07:42:28.112040: Pseudo dice [np.float64(0.9455), np.float64(0.9293), np.float64(0.9132)] 
2025-03-22 07:42:28.118134: Epoch time: 42.78 s 
2025-03-22 07:42:28.886443:  
2025-03-22 07:42:28.893961: Epoch 299 
2025-03-22 07:42:28.897967: Current learning rate: 0.00726 
2025-03-22 07:43:11.812459: train_loss -0.8585 
2025-03-22 07:43:11.820482: val_loss -0.8698 
2025-03-22 07:43:11.828009: Pseudo dice [np.float64(0.9492), np.float64(0.9177), np.float64(0.9201)] 
2025-03-22 07:43:11.833029: Epoch time: 42.93 s 
2025-03-22 07:43:12.704618:  
2025-03-22 07:43:12.711142: Epoch 300 
2025-03-22 07:43:12.714658: Current learning rate: 0.00725 
2025-03-22 07:43:55.681138: train_loss -0.8641 
2025-03-22 07:43:55.688153: val_loss -0.8255 
2025-03-22 07:43:55.694668: Pseudo dice [np.float64(0.935), np.float64(0.9329), np.float64(0.9026)] 
2025-03-22 07:43:55.701180: Epoch time: 42.98 s 
2025-03-22 07:43:56.448946:  
2025-03-22 07:43:56.455545: Epoch 301 
2025-03-22 07:43:56.460098: Current learning rate: 0.00724 
2025-03-22 07:44:39.288169: train_loss -0.8634 
2025-03-22 07:44:39.294682: val_loss -0.8504 
2025-03-22 07:44:39.300697: Pseudo dice [np.float64(0.9487), np.float64(0.9422), np.float64(0.9185)] 
2025-03-22 07:44:39.307217: Epoch time: 42.84 s 
2025-03-22 07:44:40.019809:  
2025-03-22 07:44:40.025835: Epoch 302 
2025-03-22 07:44:40.031854: Current learning rate: 0.00724 
2025-03-22 07:45:23.971378: train_loss -0.863 
2025-03-22 07:45:23.982410: val_loss -0.8626 
2025-03-22 07:45:23.988931: Pseudo dice [np.float64(0.9401), np.float64(0.9371), np.float64(0.9057)] 
2025-03-22 07:45:23.994951: Epoch time: 43.95 s 
2025-03-22 07:45:24.742174:  
2025-03-22 07:45:24.748728: Epoch 303 
2025-03-22 07:45:24.753897: Current learning rate: 0.00723 
2025-03-22 07:46:07.817621: train_loss -0.8597 
2025-03-22 07:46:07.825773: val_loss -0.8142 
2025-03-22 07:46:07.830288: Pseudo dice [np.float64(0.9406), np.float64(0.9273), np.float64(0.9098)] 
2025-03-22 07:46:07.836814: Epoch time: 43.08 s 
2025-03-22 07:46:08.809508:  
2025-03-22 07:46:08.815525: Epoch 304 
2025-03-22 07:46:08.819536: Current learning rate: 0.00722 
2025-03-22 07:46:51.654188: train_loss -0.861 
2025-03-22 07:46:51.660243: val_loss -0.8261 
2025-03-22 07:46:51.665379: Pseudo dice [np.float64(0.9442), np.float64(0.9297), np.float64(0.9158)] 
2025-03-22 07:46:51.669423: Epoch time: 42.85 s 
2025-03-22 07:46:52.402079:  
2025-03-22 07:46:52.409570: Epoch 305 
2025-03-22 07:46:52.412867: Current learning rate: 0.00721 
2025-03-22 07:47:35.299107: train_loss -0.8672 
2025-03-22 07:47:35.306622: val_loss -0.8531 
2025-03-22 07:47:35.314144: Pseudo dice [np.float64(0.9505), np.float64(0.942), np.float64(0.925)] 
2025-03-22 07:47:35.320711: Epoch time: 42.9 s 
2025-03-22 07:47:36.079865:  
2025-03-22 07:47:36.083878: Epoch 306 
2025-03-22 07:47:36.087888: Current learning rate: 0.0072 
2025-03-22 07:48:18.658098: train_loss -0.8674 
2025-03-22 07:48:18.664115: val_loss -0.8473 
2025-03-22 07:48:18.669136: Pseudo dice [np.float64(0.9408), np.float64(0.9267), np.float64(0.9141)] 
2025-03-22 07:48:18.673151: Epoch time: 42.58 s 
2025-03-22 07:48:19.501271:  
2025-03-22 07:48:19.507826: Epoch 307 
2025-03-22 07:48:19.512862: Current learning rate: 0.00719 
2025-03-22 07:49:02.316772: train_loss -0.8717 
2025-03-22 07:49:02.324291: val_loss -0.8309 
2025-03-22 07:49:02.330319: Pseudo dice [np.float64(0.9431), np.float64(0.9318), np.float64(0.9159)] 
2025-03-22 07:49:02.336841: Epoch time: 42.82 s 
2025-03-22 07:49:03.102178:  
2025-03-22 07:49:03.108248: Epoch 308 
2025-03-22 07:49:03.113314: Current learning rate: 0.00718 
2025-03-22 07:49:45.874816: train_loss -0.8566 
2025-03-22 07:49:45.882838: val_loss -0.8563 
2025-03-22 07:49:45.887848: Pseudo dice [np.float64(0.9451), np.float64(0.941), np.float64(0.9165)] 
2025-03-22 07:49:45.892882: Epoch time: 42.77 s 
2025-03-22 07:49:46.653797:  
2025-03-22 07:49:46.660323: Epoch 309 
2025-03-22 07:49:46.663828: Current learning rate: 0.00717 
2025-03-22 07:50:29.408228: train_loss -0.857 
2025-03-22 07:50:29.414744: val_loss -0.8557 
2025-03-22 07:50:29.420759: Pseudo dice [np.float64(0.9469), np.float64(0.9281), np.float64(0.9092)] 
2025-03-22 07:50:29.425773: Epoch time: 42.76 s 
2025-03-22 07:50:30.201796:  
2025-03-22 07:50:30.208944: Epoch 310 
2025-03-22 07:50:30.213964: Current learning rate: 0.00716 
2025-03-22 07:51:13.005056: train_loss -0.8637 
2025-03-22 07:51:13.013577: val_loss -0.862 
2025-03-22 07:51:13.017594: Pseudo dice [np.float64(0.9354), np.float64(0.943), np.float64(0.913)] 
2025-03-22 07:51:13.021604: Epoch time: 42.8 s 
2025-03-22 07:51:13.767981:  
2025-03-22 07:51:13.774545: Epoch 311 
2025-03-22 07:51:13.780642: Current learning rate: 0.00715 
2025-03-22 07:51:57.783408: train_loss -0.8577 
2025-03-22 07:51:57.791934: val_loss -0.8343 
2025-03-22 07:51:57.800979: Pseudo dice [np.float64(0.9301), np.float64(0.9136), np.float64(0.9104)] 
2025-03-22 07:51:57.806498: Epoch time: 44.02 s 
2025-03-22 07:51:58.787555:  
2025-03-22 07:51:58.793074: Epoch 312 
2025-03-22 07:51:58.796581: Current learning rate: 0.00714 
2025-03-22 07:52:41.879239: train_loss -0.871 
2025-03-22 07:52:41.887264: val_loss -0.8393 
2025-03-22 07:52:41.894793: Pseudo dice [np.float64(0.9383), np.float64(0.9122), np.float64(0.9032)] 
2025-03-22 07:52:41.899806: Epoch time: 43.09 s 
2025-03-22 07:52:42.682681:  
2025-03-22 07:52:42.688767: Epoch 313 
2025-03-22 07:52:42.692774: Current learning rate: 0.00713 
2025-03-22 07:53:25.572582: train_loss -0.8638 
2025-03-22 07:53:25.580159: val_loss -0.8491 
2025-03-22 07:53:25.586233: Pseudo dice [np.float64(0.9391), np.float64(0.9201), np.float64(0.9166)] 
2025-03-22 07:53:25.591792: Epoch time: 42.89 s 
2025-03-22 07:53:26.353046:  
2025-03-22 07:53:26.359678: Epoch 314 
2025-03-22 07:53:26.364213: Current learning rate: 0.00712 
2025-03-22 07:54:09.331641: train_loss -0.8591 
2025-03-22 07:54:09.338156: val_loss -0.8445 
2025-03-22 07:54:09.344176: Pseudo dice [np.float64(0.9459), np.float64(0.9311), np.float64(0.9065)] 
2025-03-22 07:54:09.349210: Epoch time: 42.98 s 
2025-03-22 07:54:10.116754:  
2025-03-22 07:54:10.122788: Epoch 315 
2025-03-22 07:54:10.127817: Current learning rate: 0.00711 
2025-03-22 07:54:53.030004: train_loss -0.8743 
2025-03-22 07:54:53.037018: val_loss -0.852 
2025-03-22 07:54:53.041028: Pseudo dice [np.float64(0.9517), np.float64(0.9292), np.float64(0.9166)] 
2025-03-22 07:54:53.045036: Epoch time: 42.91 s 
2025-03-22 07:54:53.806536:  
2025-03-22 07:54:53.812125: Epoch 316 
2025-03-22 07:54:53.817274: Current learning rate: 0.0071 
2025-03-22 07:55:36.567148: train_loss -0.8647 
2025-03-22 07:55:36.574667: val_loss -0.8533 
2025-03-22 07:55:36.579678: Pseudo dice [np.float64(0.9455), np.float64(0.9376), np.float64(0.9267)] 
2025-03-22 07:55:36.584689: Epoch time: 42.76 s 
2025-03-22 07:55:37.333620:  
2025-03-22 07:55:37.340638: Epoch 317 
2025-03-22 07:55:37.344650: Current learning rate: 0.0071 
2025-03-22 07:56:20.201038: train_loss -0.8566 
2025-03-22 07:56:20.208560: val_loss -0.8563 
2025-03-22 07:56:20.213573: Pseudo dice [np.float64(0.9478), np.float64(0.9264), np.float64(0.9172)] 
2025-03-22 07:56:20.217582: Epoch time: 42.87 s 
2025-03-22 07:56:20.993196:  
2025-03-22 07:56:20.999748: Epoch 318 
2025-03-22 07:56:21.004896: Current learning rate: 0.00709 
2025-03-22 07:57:03.966379: train_loss -0.8624 
2025-03-22 07:57:03.973895: val_loss -0.8497 
2025-03-22 07:57:03.978907: Pseudo dice [np.float64(0.9493), np.float64(0.9336), np.float64(0.9109)] 
2025-03-22 07:57:03.982914: Epoch time: 42.97 s 
2025-03-22 07:57:04.742669:  
2025-03-22 07:57:04.750238: Epoch 319 
2025-03-22 07:57:04.757949: Current learning rate: 0.00708 
2025-03-22 07:57:47.578306: train_loss -0.8629 
2025-03-22 07:57:47.585833: val_loss -0.8221 
2025-03-22 07:57:47.594918: Pseudo dice [np.float64(0.9376), np.float64(0.918), np.float64(0.901)] 
2025-03-22 07:57:47.600527: Epoch time: 42.84 s 
2025-03-22 07:57:48.578620:  
2025-03-22 07:57:48.584701: Epoch 320 
2025-03-22 07:57:48.588714: Current learning rate: 0.00707 
2025-03-22 07:58:32.889907: train_loss -0.8569 
2025-03-22 07:58:32.897431: val_loss -0.8384 
2025-03-22 07:58:32.904955: Pseudo dice [np.float64(0.9443), np.float64(0.9179), np.float64(0.9138)] 
2025-03-22 07:58:32.911477: Epoch time: 44.31 s 
2025-03-22 07:58:33.625764:  
2025-03-22 07:58:33.632396: Epoch 321 
2025-03-22 07:58:33.637450: Current learning rate: 0.00706 
2025-03-22 07:59:16.820919: train_loss -0.8574 
2025-03-22 07:59:16.831349: val_loss -0.841 
2025-03-22 07:59:16.839881: Pseudo dice [np.float64(0.9472), np.float64(0.9036), np.float64(0.9141)] 
2025-03-22 07:59:16.846398: Epoch time: 43.2 s 
2025-03-22 07:59:17.584308:  
2025-03-22 07:59:17.590326: Epoch 322 
2025-03-22 07:59:17.593835: Current learning rate: 0.00705 
2025-03-22 08:00:00.225972: train_loss -0.8515 
2025-03-22 08:00:00.233492: val_loss -0.8624 
2025-03-22 08:00:00.238003: Pseudo dice [np.float64(0.9451), np.float64(0.9363), np.float64(0.9078)] 
2025-03-22 08:00:00.243160: Epoch time: 42.64 s 
2025-03-22 08:00:00.989570:  
2025-03-22 08:00:00.996087: Epoch 323 
2025-03-22 08:00:01.002603: Current learning rate: 0.00704 
2025-03-22 08:00:44.070881: train_loss -0.8697 
2025-03-22 08:00:44.078407: val_loss -0.8583 
2025-03-22 08:00:44.083923: Pseudo dice [np.float64(0.9519), np.float64(0.9343), np.float64(0.9216)] 
2025-03-22 08:00:44.091449: Epoch time: 43.08 s 
2025-03-22 08:00:44.840862:  
2025-03-22 08:00:44.846880: Epoch 324 
2025-03-22 08:00:44.851899: Current learning rate: 0.00703 
2025-03-22 08:01:27.716314: train_loss -0.8683 
2025-03-22 08:01:27.724040: val_loss -0.8321 
2025-03-22 08:01:27.729217: Pseudo dice [np.float64(0.9468), np.float64(0.932), np.float64(0.9187)] 
2025-03-22 08:01:27.734299: Epoch time: 42.88 s 
2025-03-22 08:01:28.475700:  
2025-03-22 08:01:28.482266: Epoch 325 
2025-03-22 08:01:28.486370: Current learning rate: 0.00702 
2025-03-22 08:02:11.412810: train_loss -0.8707 
2025-03-22 08:02:11.420041: val_loss -0.855 
2025-03-22 08:02:11.426167: Pseudo dice [np.float64(0.9497), np.float64(0.9312), np.float64(0.9195)] 
2025-03-22 08:02:11.431249: Epoch time: 42.94 s 
2025-03-22 08:02:12.197469:  
2025-03-22 08:02:12.203535: Epoch 326 
2025-03-22 08:02:12.209108: Current learning rate: 0.00701 
2025-03-22 08:02:54.952373: train_loss -0.8639 
2025-03-22 08:02:54.959893: val_loss -0.8487 
2025-03-22 08:02:54.963909: Pseudo dice [np.float64(0.9524), np.float64(0.9376), np.float64(0.9169)] 
2025-03-22 08:02:54.968927: Epoch time: 42.76 s 
2025-03-22 08:02:55.729947:  
2025-03-22 08:02:55.735964: Epoch 327 
2025-03-22 08:02:55.739469: Current learning rate: 0.007 
2025-03-22 08:03:38.507338: train_loss -0.8642 
2025-03-22 08:03:38.514854: val_loss -0.8641 
2025-03-22 08:03:38.520901: Pseudo dice [np.float64(0.9544), np.float64(0.9395), np.float64(0.9188)] 
2025-03-22 08:03:38.529925: Epoch time: 42.78 s 
2025-03-22 08:03:39.519886:  
2025-03-22 08:03:39.529554: Epoch 328 
2025-03-22 08:03:39.533607: Current learning rate: 0.00699 
2025-03-22 08:04:22.485539: train_loss -0.8526 
2025-03-22 08:04:22.494063: val_loss -0.8559 
2025-03-22 08:04:22.499580: Pseudo dice [np.float64(0.9434), np.float64(0.9382), np.float64(0.9191)] 
2025-03-22 08:04:22.504592: Epoch time: 42.97 s 
2025-03-22 08:04:23.240007:  
2025-03-22 08:04:23.246023: Epoch 329 
2025-03-22 08:04:23.249530: Current learning rate: 0.00698 
2025-03-22 08:05:06.936575: train_loss -0.8726 
2025-03-22 08:05:06.945100: val_loss -0.8626 
2025-03-22 08:05:06.952627: Pseudo dice [np.float64(0.9476), np.float64(0.9454), np.float64(0.9249)] 
2025-03-22 08:05:06.959146: Epoch time: 43.7 s 
2025-03-22 08:05:07.736644:  
2025-03-22 08:05:07.742194: Epoch 330 
2025-03-22 08:05:07.747255: Current learning rate: 0.00697 
2025-03-22 08:05:50.767643: train_loss -0.871 
2025-03-22 08:05:50.773667: val_loss -0.8365 
2025-03-22 08:05:50.778215: Pseudo dice [np.float64(0.9432), np.float64(0.9337), np.float64(0.9212)] 
2025-03-22 08:05:50.781263: Epoch time: 43.03 s 
2025-03-22 08:05:51.548569:  
2025-03-22 08:05:51.555635: Epoch 331 
2025-03-22 08:05:51.561296: Current learning rate: 0.00696 
2025-03-22 08:06:34.251096: train_loss -0.8596 
2025-03-22 08:06:34.258621: val_loss -0.8374 
2025-03-22 08:06:34.267144: Pseudo dice [np.float64(0.9503), np.float64(0.9246), np.float64(0.9244)] 
2025-03-22 08:06:34.273685: Epoch time: 42.7 s 
2025-03-22 08:06:35.026369:  
2025-03-22 08:06:35.033911: Epoch 332 
2025-03-22 08:06:35.040463: Current learning rate: 0.00696 
2025-03-22 08:07:17.894974: train_loss -0.8672 
2025-03-22 08:07:17.902508: val_loss -0.8256 
2025-03-22 08:07:17.906527: Pseudo dice [np.float64(0.9457), np.float64(0.9262), np.float64(0.9196)] 
2025-03-22 08:07:17.911540: Epoch time: 42.87 s 
2025-03-22 08:07:18.685738:  
2025-03-22 08:07:18.692319: Epoch 333 
2025-03-22 08:07:18.697394: Current learning rate: 0.00695 
2025-03-22 08:08:01.612719: train_loss -0.8662 
2025-03-22 08:08:01.620237: val_loss -0.8563 
2025-03-22 08:08:01.625252: Pseudo dice [np.float64(0.9494), np.float64(0.9412), np.float64(0.9146)] 
2025-03-22 08:08:01.629263: Epoch time: 42.93 s 
2025-03-22 08:08:02.394027:  
2025-03-22 08:08:02.401040: Epoch 334 
2025-03-22 08:08:02.405053: Current learning rate: 0.00694 
2025-03-22 08:08:45.081824: train_loss -0.869 
2025-03-22 08:08:45.088950: val_loss -0.859 
2025-03-22 08:08:45.095057: Pseudo dice [np.float64(0.948), np.float64(0.937), np.float64(0.9247)] 
2025-03-22 08:08:45.101200: Epoch time: 42.69 s 
2025-03-22 08:08:45.903942:  
2025-03-22 08:08:45.912199: Epoch 335 
2025-03-22 08:08:45.918343: Current learning rate: 0.00693 
2025-03-22 08:09:28.886626: train_loss -0.8619 
2025-03-22 08:09:28.894675: val_loss -0.8437 
2025-03-22 08:09:28.902192: Pseudo dice [np.float64(0.9408), np.float64(0.9305), np.float64(0.9106)] 
2025-03-22 08:09:28.908209: Epoch time: 42.98 s 
2025-03-22 08:09:29.923080:  
2025-03-22 08:09:29.929656: Epoch 336 
2025-03-22 08:09:29.932199: Current learning rate: 0.00692 
2025-03-22 08:10:12.659619: train_loss -0.87 
2025-03-22 08:10:12.665690: val_loss -0.8572 
2025-03-22 08:10:12.670297: Pseudo dice [np.float64(0.9494), np.float64(0.9381), np.float64(0.9223)] 
2025-03-22 08:10:12.675362: Epoch time: 42.74 s 
2025-03-22 08:10:13.449746:  
2025-03-22 08:10:13.456779: Epoch 337 
2025-03-22 08:10:13.462392: Current learning rate: 0.00691 
2025-03-22 08:10:56.495947: train_loss -0.8578 
2025-03-22 08:10:56.504473: val_loss -0.8501 
2025-03-22 08:10:56.511998: Pseudo dice [np.float64(0.948), np.float64(0.9416), np.float64(0.9247)] 
2025-03-22 08:10:56.518012: Epoch time: 43.05 s 
2025-03-22 08:10:56.524534: Yayy! New best EMA pseudo Dice: 0.9331 
2025-03-22 08:10:57.353562:  
2025-03-22 08:10:57.359077: Epoch 338 
2025-03-22 08:10:57.363588: Current learning rate: 0.0069 
2025-03-22 08:11:40.893810: train_loss -0.861 
2025-03-22 08:11:40.900331: val_loss -0.8602 
2025-03-22 08:11:40.903841: Pseudo dice [np.float64(0.9547), np.float64(0.9452), np.float64(0.9133)] 
2025-03-22 08:11:40.907986: Epoch time: 43.54 s 
2025-03-22 08:11:40.913100: Yayy! New best EMA pseudo Dice: 0.9336 
2025-03-22 08:11:41.827962:  
2025-03-22 08:11:41.834522: Epoch 339 
2025-03-22 08:11:41.838081: Current learning rate: 0.00689 
2025-03-22 08:12:24.805542: train_loss -0.8605 
2025-03-22 08:12:24.811608: val_loss -0.8669 
2025-03-22 08:12:24.818185: Pseudo dice [np.float64(0.9512), np.float64(0.9258), np.float64(0.9181)] 
2025-03-22 08:12:24.824336: Epoch time: 42.98 s 
2025-03-22 08:12:25.576371:  
2025-03-22 08:12:25.583981: Epoch 340 
2025-03-22 08:12:25.589564: Current learning rate: 0.00688 
2025-03-22 08:13:08.357794: train_loss -0.8721 
2025-03-22 08:13:08.365314: val_loss -0.8451 
2025-03-22 08:13:08.368824: Pseudo dice [np.float64(0.9447), np.float64(0.9205), np.float64(0.92)] 
2025-03-22 08:13:08.372835: Epoch time: 42.78 s 
2025-03-22 08:13:09.136287:  
2025-03-22 08:13:09.141821: Epoch 341 
2025-03-22 08:13:09.146331: Current learning rate: 0.00687 
2025-03-22 08:13:52.044317: train_loss -0.8519 
2025-03-22 08:13:52.051932: val_loss -0.8537 
2025-03-22 08:13:52.059596: Pseudo dice [np.float64(0.9466), np.float64(0.943), np.float64(0.9195)] 
2025-03-22 08:13:52.066321: Epoch time: 42.91 s 
2025-03-22 08:13:52.861130:  
2025-03-22 08:13:52.867684: Epoch 342 
2025-03-22 08:13:52.871214: Current learning rate: 0.00686 
2025-03-22 08:14:35.941100: train_loss -0.8724 
2025-03-22 08:14:35.947112: val_loss -0.8582 
2025-03-22 08:14:35.951121: Pseudo dice [np.float64(0.9518), np.float64(0.9376), np.float64(0.9127)] 
2025-03-22 08:14:35.955629: Epoch time: 43.08 s 
2025-03-22 08:14:36.727415:  
2025-03-22 08:14:36.733500: Epoch 343 
2025-03-22 08:14:36.737041: Current learning rate: 0.00685 
2025-03-22 08:15:19.749289: train_loss -0.8505 
2025-03-22 08:15:19.759324: val_loss -0.8429 
2025-03-22 08:15:19.766851: Pseudo dice [np.float64(0.9417), np.float64(0.9165), np.float64(0.9236)] 
2025-03-22 08:15:19.774372: Epoch time: 43.02 s 
2025-03-22 08:15:20.750921:  
2025-03-22 08:15:20.757111: Epoch 344 
2025-03-22 08:15:20.762170: Current learning rate: 0.00684 
2025-03-22 08:16:03.815842: train_loss -0.855 
2025-03-22 08:16:03.823071: val_loss -0.8449 
2025-03-22 08:16:03.829185: Pseudo dice [np.float64(0.941), np.float64(0.9101), np.float64(0.9049)] 
2025-03-22 08:16:03.833745: Epoch time: 43.07 s 
2025-03-22 08:16:04.582932:  
2025-03-22 08:16:04.588946: Epoch 345 
2025-03-22 08:16:04.593968: Current learning rate: 0.00683 
2025-03-22 08:16:47.450879: train_loss -0.8506 
2025-03-22 08:16:47.459406: val_loss -0.8492 
2025-03-22 08:16:47.466932: Pseudo dice [np.float64(0.9473), np.float64(0.9318), np.float64(0.8966)] 
2025-03-22 08:16:47.470941: Epoch time: 42.87 s 
2025-03-22 08:16:48.237406:  
2025-03-22 08:16:48.242923: Epoch 346 
2025-03-22 08:16:48.247932: Current learning rate: 0.00682 
2025-03-22 08:17:31.161279: train_loss -0.86 
2025-03-22 08:17:31.170350: val_loss -0.8479 
2025-03-22 08:17:31.177403: Pseudo dice [np.float64(0.9563), np.float64(0.9299), np.float64(0.9103)] 
2025-03-22 08:17:31.182963: Epoch time: 42.92 s 
2025-03-22 08:17:31.973275:  
2025-03-22 08:17:31.978785: Epoch 347 
2025-03-22 08:17:31.984801: Current learning rate: 0.00681 
2025-03-22 08:18:16.402210: train_loss -0.8569 
2025-03-22 08:18:16.409729: val_loss -0.8425 
2025-03-22 08:18:16.415745: Pseudo dice [np.float64(0.9465), np.float64(0.9313), np.float64(0.9224)] 
2025-03-22 08:18:16.420759: Epoch time: 44.43 s 
2025-03-22 08:18:17.176669:  
2025-03-22 08:18:17.182706: Epoch 348 
2025-03-22 08:18:17.187233: Current learning rate: 0.0068 
2025-03-22 08:19:00.062124: train_loss -0.8672 
2025-03-22 08:19:00.068967: val_loss -0.8358 
2025-03-22 08:19:00.074345: Pseudo dice [np.float64(0.9403), np.float64(0.9282), np.float64(0.916)] 
2025-03-22 08:19:00.081022: Epoch time: 42.89 s 
2025-03-22 08:19:00.855482:  
2025-03-22 08:19:00.862125: Epoch 349 
2025-03-22 08:19:00.867213: Current learning rate: 0.0068 
2025-03-22 08:19:43.798562: train_loss -0.8566 
2025-03-22 08:19:43.808635: val_loss -0.8332 
2025-03-22 08:19:43.814835: Pseudo dice [np.float64(0.9489), np.float64(0.9412), np.float64(0.922)] 
2025-03-22 08:19:43.820942: Epoch time: 42.94 s 
2025-03-22 08:19:44.689795:  
2025-03-22 08:19:44.696408: Epoch 350 
2025-03-22 08:19:44.700459: Current learning rate: 0.00679 
2025-03-22 08:20:27.546387: train_loss -0.8573 
2025-03-22 08:20:27.555090: val_loss -0.8541 
2025-03-22 08:20:27.560108: Pseudo dice [np.float64(0.9512), np.float64(0.9385), np.float64(0.9239)] 
2025-03-22 08:20:27.563622: Epoch time: 42.86 s 
2025-03-22 08:20:28.321400:  
2025-03-22 08:20:28.328925: Epoch 351 
2025-03-22 08:20:28.335440: Current learning rate: 0.00678 
2025-03-22 08:21:11.352439: train_loss -0.8595 
2025-03-22 08:21:11.359530: val_loss -0.8524 
2025-03-22 08:21:11.366082: Pseudo dice [np.float64(0.952), np.float64(0.9349), np.float64(0.9187)] 
2025-03-22 08:21:11.372165: Epoch time: 43.03 s 
2025-03-22 08:21:12.388397:  
2025-03-22 08:21:12.394500: Epoch 352 
2025-03-22 08:21:12.397560: Current learning rate: 0.00677 
2025-03-22 08:21:55.320413: train_loss -0.8782 
2025-03-22 08:21:55.329612: val_loss -0.8332 
2025-03-22 08:21:55.336816: Pseudo dice [np.float64(0.9514), np.float64(0.8953), np.float64(0.9144)] 
2025-03-22 08:21:55.342391: Epoch time: 42.93 s 
2025-03-22 08:21:56.106151:  
2025-03-22 08:21:56.111195: Epoch 353 
2025-03-22 08:21:56.116210: Current learning rate: 0.00676 
2025-03-22 08:22:38.888986: train_loss -0.8694 
2025-03-22 08:22:38.896506: val_loss -0.8594 
2025-03-22 08:22:38.903665: Pseudo dice [np.float64(0.9549), np.float64(0.9402), np.float64(0.9286)] 
2025-03-22 08:22:38.910705: Epoch time: 42.78 s 
2025-03-22 08:22:39.666102:  
2025-03-22 08:22:39.673748: Epoch 354 
2025-03-22 08:22:39.679352: Current learning rate: 0.00675 
2025-03-22 08:23:22.443044: train_loss -0.8586 
2025-03-22 08:23:22.449563: val_loss -0.8506 
2025-03-22 08:23:22.454574: Pseudo dice [np.float64(0.9487), np.float64(0.9382), np.float64(0.9196)] 
2025-03-22 08:23:22.458583: Epoch time: 42.78 s 
2025-03-22 08:23:23.237903:  
2025-03-22 08:23:23.243468: Epoch 355 
2025-03-22 08:23:23.248009: Current learning rate: 0.00674 
2025-03-22 08:24:06.132485: train_loss -0.8635 
2025-03-22 08:24:06.142540: val_loss -0.8546 
2025-03-22 08:24:06.147553: Pseudo dice [np.float64(0.943), np.float64(0.9236), np.float64(0.914)] 
2025-03-22 08:24:06.152066: Epoch time: 42.9 s 
2025-03-22 08:24:06.901448:  
2025-03-22 08:24:06.907531: Epoch 356 
2025-03-22 08:24:06.911568: Current learning rate: 0.00673 
2025-03-22 08:24:49.517365: train_loss -0.8672 
2025-03-22 08:24:49.524952: val_loss -0.8638 
2025-03-22 08:24:49.530063: Pseudo dice [np.float64(0.9524), np.float64(0.9331), np.float64(0.9205)] 
2025-03-22 08:24:49.536644: Epoch time: 42.62 s 
2025-03-22 08:24:50.302911:  
2025-03-22 08:24:50.312046: Epoch 357 
2025-03-22 08:24:50.317329: Current learning rate: 0.00672 
2025-03-22 08:25:33.128074: train_loss -0.8538 
2025-03-22 08:25:33.135590: val_loss -0.8258 
2025-03-22 08:25:33.140601: Pseudo dice [np.float64(0.941), np.float64(0.9195), np.float64(0.9105)] 
2025-03-22 08:25:33.146612: Epoch time: 42.83 s 
2025-03-22 08:25:33.914279:  
2025-03-22 08:25:33.919824: Epoch 358 
2025-03-22 08:25:33.924376: Current learning rate: 0.00671 
2025-03-22 08:26:16.976480: train_loss -0.8625 
2025-03-22 08:26:16.983481: val_loss -0.8522 
2025-03-22 08:26:16.991013: Pseudo dice [np.float64(0.9426), np.float64(0.947), np.float64(0.9159)] 
2025-03-22 08:26:16.996036: Epoch time: 43.06 s 
2025-03-22 08:26:17.772973:  
2025-03-22 08:26:17.779031: Epoch 359 
2025-03-22 08:26:17.783058: Current learning rate: 0.0067 
2025-03-22 08:27:00.793049: train_loss -0.8601 
2025-03-22 08:27:00.800065: val_loss -0.852 
2025-03-22 08:27:00.805582: Pseudo dice [np.float64(0.9479), np.float64(0.945), np.float64(0.9275)] 
2025-03-22 08:27:00.810598: Epoch time: 43.02 s 
2025-03-22 08:27:01.829970:  
2025-03-22 08:27:01.837489: Epoch 360 
2025-03-22 08:27:01.841501: Current learning rate: 0.00669 
2025-03-22 08:27:44.550141: train_loss -0.86 
2025-03-22 08:27:44.559728: val_loss -0.8483 
2025-03-22 08:27:44.565742: Pseudo dice [np.float64(0.9492), np.float64(0.9242), np.float64(0.9207)] 
2025-03-22 08:27:44.570764: Epoch time: 42.72 s 
2025-03-22 08:27:45.322091:  
2025-03-22 08:27:45.329697: Epoch 361 
2025-03-22 08:27:45.334305: Current learning rate: 0.00668 
2025-03-22 08:28:28.102928: train_loss -0.8626 
2025-03-22 08:28:28.110003: val_loss -0.8317 
2025-03-22 08:28:28.114058: Pseudo dice [np.float64(0.9466), np.float64(0.9209), np.float64(0.9183)] 
2025-03-22 08:28:28.121753: Epoch time: 42.78 s 
2025-03-22 08:28:28.896276:  
2025-03-22 08:28:28.903340: Epoch 362 
2025-03-22 08:28:28.906899: Current learning rate: 0.00667 
2025-03-22 08:29:11.971188: train_loss -0.8592 
2025-03-22 08:29:11.976261: val_loss -0.8434 
2025-03-22 08:29:11.979841: Pseudo dice [np.float64(0.9499), np.float64(0.9187), np.float64(0.9135)] 
2025-03-22 08:29:11.983922: Epoch time: 43.08 s 
2025-03-22 08:29:12.763129:  
2025-03-22 08:29:12.770674: Epoch 363 
2025-03-22 08:29:12.776883: Current learning rate: 0.00666 
2025-03-22 08:29:56.198224: train_loss -0.8606 
2025-03-22 08:29:56.205749: val_loss -0.8531 
2025-03-22 08:29:56.211267: Pseudo dice [np.float64(0.9477), np.float64(0.9307), np.float64(0.9075)] 
2025-03-22 08:29:56.216282: Epoch time: 43.43 s 
2025-03-22 08:29:56.969360:  
2025-03-22 08:29:56.975510: Epoch 364 
2025-03-22 08:29:56.979086: Current learning rate: 0.00665 
2025-03-22 08:30:40.057136: train_loss -0.8618 
2025-03-22 08:30:40.064707: val_loss -0.8521 
2025-03-22 08:30:40.071832: Pseudo dice [np.float64(0.9413), np.float64(0.9307), np.float64(0.9189)] 
2025-03-22 08:30:40.076932: Epoch time: 43.09 s 
2025-03-22 08:30:40.855816:  
2025-03-22 08:30:40.862339: Epoch 365 
2025-03-22 08:30:40.866851: Current learning rate: 0.00665 
2025-03-22 08:31:23.866012: train_loss -0.8649 
2025-03-22 08:31:23.873533: val_loss -0.8638 
2025-03-22 08:31:23.878556: Pseudo dice [np.float64(0.9482), np.float64(0.9304), np.float64(0.9221)] 
2025-03-22 08:31:23.883570: Epoch time: 43.01 s 
2025-03-22 08:31:24.666639:  
2025-03-22 08:31:24.673264: Epoch 366 
2025-03-22 08:31:24.676844: Current learning rate: 0.00664 
2025-03-22 08:32:07.695029: train_loss -0.8667 
2025-03-22 08:32:07.703553: val_loss -0.8053 
2025-03-22 08:32:07.707567: Pseudo dice [np.float64(0.9443), np.float64(0.917), np.float64(0.9133)] 
2025-03-22 08:32:07.714089: Epoch time: 43.03 s 
2025-03-22 08:32:08.503906:  
2025-03-22 08:32:08.509448: Epoch 367 
2025-03-22 08:32:08.514536: Current learning rate: 0.00663 
2025-03-22 08:32:52.649577: train_loss -0.8628 
2025-03-22 08:32:52.657603: val_loss -0.8695 
2025-03-22 08:32:52.663623: Pseudo dice [np.float64(0.9421), np.float64(0.9487), np.float64(0.9234)] 
2025-03-22 08:32:52.671154: Epoch time: 44.15 s 
2025-03-22 08:32:53.429232:  
2025-03-22 08:32:53.436810: Epoch 368 
2025-03-22 08:32:53.441892: Current learning rate: 0.00662 
2025-03-22 08:33:36.538448: train_loss -0.8677 
2025-03-22 08:33:36.547976: val_loss -0.859 
2025-03-22 08:33:36.554504: Pseudo dice [np.float64(0.9495), np.float64(0.9451), np.float64(0.9172)] 
2025-03-22 08:33:36.559519: Epoch time: 43.11 s 
2025-03-22 08:33:37.557363:  
2025-03-22 08:33:37.563428: Epoch 369 
2025-03-22 08:33:37.566962: Current learning rate: 0.00661 
2025-03-22 08:34:20.609778: train_loss -0.8678 
2025-03-22 08:34:20.617350: val_loss -0.8693 
2025-03-22 08:34:20.622442: Pseudo dice [np.float64(0.9497), np.float64(0.9499), np.float64(0.9286)] 
2025-03-22 08:34:20.628199: Epoch time: 43.05 s 
2025-03-22 08:34:21.420498:  
2025-03-22 08:34:21.426022: Epoch 370 
2025-03-22 08:34:21.431036: Current learning rate: 0.0066 
2025-03-22 08:35:04.238086: train_loss -0.8701 
2025-03-22 08:35:04.244598: val_loss -0.8384 
2025-03-22 08:35:04.248110: Pseudo dice [np.float64(0.9478), np.float64(0.94), np.float64(0.9235)] 
2025-03-22 08:35:04.252128: Epoch time: 42.82 s 
2025-03-22 08:35:05.050193:  
2025-03-22 08:35:05.056219: Epoch 371 
2025-03-22 08:35:05.062377: Current learning rate: 0.00659 
2025-03-22 08:35:48.068918: train_loss -0.8493 
2025-03-22 08:35:48.075961: val_loss -0.8432 
2025-03-22 08:35:48.079538: Pseudo dice [np.float64(0.9442), np.float64(0.9374), np.float64(0.9262)] 
2025-03-22 08:35:48.084622: Epoch time: 43.02 s 
2025-03-22 08:35:48.087674: Yayy! New best EMA pseudo Dice: 0.9338 
2025-03-22 08:35:48.971650:  
2025-03-22 08:35:48.979175: Epoch 372 
2025-03-22 08:35:48.984467: Current learning rate: 0.00658 
2025-03-22 08:36:31.727563: train_loss -0.8749 
2025-03-22 08:36:31.735085: val_loss -0.8324 
2025-03-22 08:36:31.740108: Pseudo dice [np.float64(0.9465), np.float64(0.924), np.float64(0.9098)] 
2025-03-22 08:36:31.746123: Epoch time: 42.76 s 
2025-03-22 08:36:32.536284:  
2025-03-22 08:36:32.542395: Epoch 373 
2025-03-22 08:36:32.547458: Current learning rate: 0.00657 
2025-03-22 08:37:15.470064: train_loss -0.8733 
2025-03-22 08:37:15.476592: val_loss -0.8624 
2025-03-22 08:37:15.483112: Pseudo dice [np.float64(0.9461), np.float64(0.9323), np.float64(0.9047)] 
2025-03-22 08:37:15.489125: Epoch time: 42.94 s 
2025-03-22 08:37:16.283982:  
2025-03-22 08:37:16.289556: Epoch 374 
2025-03-22 08:37:16.293626: Current learning rate: 0.00656 
2025-03-22 08:37:59.118834: train_loss -0.8767 
2025-03-22 08:37:59.126368: val_loss -0.8543 
2025-03-22 08:37:59.132886: Pseudo dice [np.float64(0.9429), np.float64(0.9166), np.float64(0.9113)] 
2025-03-22 08:37:59.139907: Epoch time: 42.84 s 
2025-03-22 08:37:59.923364:  
2025-03-22 08:37:59.930012: Epoch 375 
2025-03-22 08:37:59.932551: Current learning rate: 0.00655 
2025-03-22 08:38:42.821835: train_loss -0.8577 
2025-03-22 08:38:42.830360: val_loss -0.8412 
2025-03-22 08:38:42.836876: Pseudo dice [np.float64(0.9435), np.float64(0.9332), np.float64(0.9042)] 
2025-03-22 08:38:42.844401: Epoch time: 42.9 s 
2025-03-22 08:38:43.617476:  
2025-03-22 08:38:43.624535: Epoch 376 
2025-03-22 08:38:43.628153: Current learning rate: 0.00654 
2025-03-22 08:39:28.380000: train_loss -0.8536 
2025-03-22 08:39:28.387771: val_loss -0.8388 
2025-03-22 08:39:28.393289: Pseudo dice [np.float64(0.9519), np.float64(0.9329), np.float64(0.9026)] 
2025-03-22 08:39:28.400308: Epoch time: 44.76 s 
2025-03-22 08:39:29.438550:  
2025-03-22 08:39:29.441596: Epoch 377 
2025-03-22 08:39:29.446163: Current learning rate: 0.00653 
2025-03-22 08:40:12.246662: train_loss -0.863 
2025-03-22 08:40:12.255744: val_loss -0.8567 
2025-03-22 08:40:12.263269: Pseudo dice [np.float64(0.9381), np.float64(0.9522), np.float64(0.9271)] 
2025-03-22 08:40:12.269799: Epoch time: 42.81 s 
2025-03-22 08:40:13.059097:  
2025-03-22 08:40:13.066720: Epoch 378 
2025-03-22 08:40:13.071732: Current learning rate: 0.00652 
2025-03-22 08:40:56.265916: train_loss -0.8575 
2025-03-22 08:40:56.273940: val_loss -0.8351 
2025-03-22 08:40:56.278953: Pseudo dice [np.float64(0.9436), np.float64(0.9274), np.float64(0.9072)] 
2025-03-22 08:40:56.283968: Epoch time: 43.21 s 
2025-03-22 08:40:57.028914:  
2025-03-22 08:40:57.035999: Epoch 379 
2025-03-22 08:40:57.040083: Current learning rate: 0.00651 
2025-03-22 08:41:39.943031: train_loss -0.8634 
2025-03-22 08:41:39.950561: val_loss -0.8474 
2025-03-22 08:41:39.957585: Pseudo dice [np.float64(0.9428), np.float64(0.9349), np.float64(0.9173)] 
2025-03-22 08:41:39.963105: Epoch time: 42.91 s 
2025-03-22 08:41:40.746978:  
2025-03-22 08:41:40.753004: Epoch 380 
2025-03-22 08:41:40.759022: Current learning rate: 0.0065 
2025-03-22 08:42:23.434561: train_loss -0.8691 
2025-03-22 08:42:23.441086: val_loss -0.8757 
2025-03-22 08:42:23.447107: Pseudo dice [np.float64(0.9538), np.float64(0.9361), np.float64(0.9212)] 
2025-03-22 08:42:23.451118: Epoch time: 42.69 s 
2025-03-22 08:42:24.217463:  
2025-03-22 08:42:24.223514: Epoch 381 
2025-03-22 08:42:24.229087: Current learning rate: 0.00649 
2025-03-22 08:43:07.324703: train_loss -0.8659 
2025-03-22 08:43:07.333739: val_loss -0.8567 
2025-03-22 08:43:07.341261: Pseudo dice [np.float64(0.9501), np.float64(0.9377), np.float64(0.912)] 
2025-03-22 08:43:07.348785: Epoch time: 43.11 s 
2025-03-22 08:43:08.132761:  
2025-03-22 08:43:08.138784: Epoch 382 
2025-03-22 08:43:08.143804: Current learning rate: 0.00648 
2025-03-22 08:43:50.965533: train_loss -0.8628 
2025-03-22 08:43:50.973062: val_loss -0.8598 
2025-03-22 08:43:50.978079: Pseudo dice [np.float64(0.9428), np.float64(0.943), np.float64(0.9096)] 
2025-03-22 08:43:50.982596: Epoch time: 42.83 s 
2025-03-22 08:43:51.781039:  
2025-03-22 08:43:51.786575: Epoch 383 
2025-03-22 08:43:51.790090: Current learning rate: 0.00648 
2025-03-22 08:44:34.813884: train_loss -0.8674 
2025-03-22 08:44:34.821414: val_loss -0.8696 
2025-03-22 08:44:34.827931: Pseudo dice [np.float64(0.9514), np.float64(0.94), np.float64(0.9161)] 
2025-03-22 08:44:34.832944: Epoch time: 43.03 s 
2025-03-22 08:44:35.866817:  
2025-03-22 08:44:35.874926: Epoch 384 
2025-03-22 08:44:35.877964: Current learning rate: 0.00647 
2025-03-22 08:45:18.878719: train_loss -0.8657 
2025-03-22 08:45:18.885234: val_loss -0.8218 
2025-03-22 08:45:18.890251: Pseudo dice [np.float64(0.9436), np.float64(0.9265), np.float64(0.9088)] 
2025-03-22 08:45:18.895264: Epoch time: 43.01 s 
2025-03-22 08:45:19.670153:  
2025-03-22 08:45:19.675722: Epoch 385 
2025-03-22 08:45:19.680300: Current learning rate: 0.00646 
2025-03-22 08:46:04.048199: train_loss -0.8685 
2025-03-22 08:46:04.056223: val_loss -0.8447 
2025-03-22 08:46:04.061754: Pseudo dice [np.float64(0.9428), np.float64(0.9446), np.float64(0.9228)] 
2025-03-22 08:46:04.066297: Epoch time: 44.38 s 
2025-03-22 08:46:04.851990:  
2025-03-22 08:46:04.858946: Epoch 386 
2025-03-22 08:46:04.863469: Current learning rate: 0.00645 
2025-03-22 08:46:48.176751: train_loss -0.8656 
2025-03-22 08:46:48.185188: val_loss -0.8485 
2025-03-22 08:46:48.192723: Pseudo dice [np.float64(0.9463), np.float64(0.9318), np.float64(0.9175)] 
2025-03-22 08:46:48.198750: Epoch time: 43.33 s 
2025-03-22 08:46:49.004646:  
2025-03-22 08:46:49.010161: Epoch 387 
2025-03-22 08:46:49.014672: Current learning rate: 0.00644 
2025-03-22 08:47:31.907795: train_loss -0.8674 
2025-03-22 08:47:31.915322: val_loss -0.8514 
2025-03-22 08:47:31.921344: Pseudo dice [np.float64(0.9413), np.float64(0.9373), np.float64(0.9064)] 
2025-03-22 08:47:31.927867: Epoch time: 42.9 s 
2025-03-22 08:47:32.717551:  
2025-03-22 08:47:32.724740: Epoch 388 
2025-03-22 08:47:32.729767: Current learning rate: 0.00643 
2025-03-22 08:48:15.891361: train_loss -0.8629 
2025-03-22 08:48:15.898892: val_loss -0.8143 
2025-03-22 08:48:15.907413: Pseudo dice [np.float64(0.9507), np.float64(0.9368), np.float64(0.908)] 
2025-03-22 08:48:15.914939: Epoch time: 43.17 s 
2025-03-22 08:48:16.667317:  
2025-03-22 08:48:16.673351: Epoch 389 
2025-03-22 08:48:16.676912: Current learning rate: 0.00642 
2025-03-22 08:48:59.545521: train_loss -0.8602 
2025-03-22 08:48:59.553077: val_loss -0.8444 
2025-03-22 08:48:59.558086: Pseudo dice [np.float64(0.9414), np.float64(0.9374), np.float64(0.9089)] 
2025-03-22 08:48:59.564105: Epoch time: 42.88 s 
2025-03-22 08:49:00.342200:  
2025-03-22 08:49:00.348743: Epoch 390 
2025-03-22 08:49:00.353872: Current learning rate: 0.00641 
2025-03-22 08:49:43.620800: train_loss -0.8628 
2025-03-22 08:49:43.629325: val_loss -0.8437 
2025-03-22 08:49:43.635837: Pseudo dice [np.float64(0.9364), np.float64(0.939), np.float64(0.9144)] 
2025-03-22 08:49:43.643359: Epoch time: 43.28 s 
2025-03-22 08:49:44.436938:  
2025-03-22 08:49:44.443488: Epoch 391 
2025-03-22 08:49:44.447025: Current learning rate: 0.0064 
2025-03-22 08:50:27.325846: train_loss -0.8598 
2025-03-22 08:50:27.333011: val_loss -0.8313 
2025-03-22 08:50:27.336519: Pseudo dice [np.float64(0.9448), np.float64(0.9158), np.float64(0.9134)] 
2025-03-22 08:50:27.340533: Epoch time: 42.89 s 
2025-03-22 08:50:28.377821:  
2025-03-22 08:50:28.384459: Epoch 392 
2025-03-22 08:50:28.387507: Current learning rate: 0.00639 
2025-03-22 08:51:11.448450: train_loss -0.8692 
2025-03-22 08:51:11.456483: val_loss -0.8236 
2025-03-22 08:51:11.462498: Pseudo dice [np.float64(0.9489), np.float64(0.9395), np.float64(0.9172)] 
2025-03-22 08:51:11.469026: Epoch time: 43.07 s 
2025-03-22 08:51:12.216654:  
2025-03-22 08:51:12.222701: Epoch 393 
2025-03-22 08:51:12.225750: Current learning rate: 0.00638 
2025-03-22 08:51:55.089778: train_loss -0.8531 
2025-03-22 08:51:55.097312: val_loss -0.8623 
2025-03-22 08:51:55.102324: Pseudo dice [np.float64(0.9493), np.float64(0.937), np.float64(0.904)] 
2025-03-22 08:51:55.107343: Epoch time: 42.87 s 
2025-03-22 08:51:55.884328:  
2025-03-22 08:51:55.891427: Epoch 394 
2025-03-22 08:51:55.895434: Current learning rate: 0.00637 
2025-03-22 08:52:40.380455: train_loss -0.8516 
2025-03-22 08:52:40.386975: val_loss -0.8628 
2025-03-22 08:52:40.392988: Pseudo dice [np.float64(0.9432), np.float64(0.9195), np.float64(0.9161)] 
2025-03-22 08:52:40.398007: Epoch time: 44.5 s 
2025-03-22 08:52:41.201231:  
2025-03-22 08:52:41.208291: Epoch 395 
2025-03-22 08:52:41.215475: Current learning rate: 0.00636 
2025-03-22 08:53:24.130977: train_loss -0.8551 
2025-03-22 08:53:24.138511: val_loss -0.8432 
2025-03-22 08:53:24.143526: Pseudo dice [np.float64(0.943), np.float64(0.9223), np.float64(0.908)] 
2025-03-22 08:53:24.148540: Epoch time: 42.93 s 
2025-03-22 08:53:24.946796:  
2025-03-22 08:53:24.954325: Epoch 396 
2025-03-22 08:53:24.959334: Current learning rate: 0.00635 
2025-03-22 08:54:07.984571: train_loss -0.8602 
2025-03-22 08:54:07.992092: val_loss -0.8485 
2025-03-22 08:54:07.998610: Pseudo dice [np.float64(0.9511), np.float64(0.9305), np.float64(0.9161)] 
2025-03-22 08:54:08.003626: Epoch time: 43.04 s 
2025-03-22 08:54:08.806802:  
2025-03-22 08:54:08.813817: Epoch 397 
2025-03-22 08:54:08.817833: Current learning rate: 0.00634 
2025-03-22 08:54:51.521363: train_loss -0.8694 
2025-03-22 08:54:51.528383: val_loss -0.8312 
2025-03-22 08:54:51.533400: Pseudo dice [np.float64(0.943), np.float64(0.9346), np.float64(0.9189)] 
2025-03-22 08:54:51.537420: Epoch time: 42.72 s 
2025-03-22 08:54:52.324610:  
2025-03-22 08:54:52.330158: Epoch 398 
2025-03-22 08:54:52.335274: Current learning rate: 0.00633 
2025-03-22 08:55:35.282005: train_loss -0.8737 
2025-03-22 08:55:35.289527: val_loss -0.8628 
2025-03-22 08:55:35.295543: Pseudo dice [np.float64(0.9474), np.float64(0.9429), np.float64(0.9131)] 
2025-03-22 08:55:35.300555: Epoch time: 42.96 s 
2025-03-22 08:55:36.091023:  
2025-03-22 08:55:36.097623: Epoch 399 
2025-03-22 08:55:36.101683: Current learning rate: 0.00632 
2025-03-22 08:56:19.258044: train_loss -0.8577 
2025-03-22 08:56:19.268081: val_loss -0.8451 
2025-03-22 08:56:19.276981: Pseudo dice [np.float64(0.9464), np.float64(0.9465), np.float64(0.9228)] 
2025-03-22 08:56:19.283510: Epoch time: 43.17 s 
2025-03-22 08:56:20.377354:  
2025-03-22 08:56:20.383869: Epoch 400 
2025-03-22 08:56:20.387882: Current learning rate: 0.00631 
2025-03-22 08:57:03.580745: train_loss -0.8714 
2025-03-22 08:57:03.588263: val_loss -0.822 
2025-03-22 08:57:03.593278: Pseudo dice [np.float64(0.9458), np.float64(0.9256), np.float64(0.9071)] 
2025-03-22 08:57:03.600804: Epoch time: 43.2 s 
2025-03-22 08:57:04.360460:  
2025-03-22 08:57:04.367070: Epoch 401 
2025-03-22 08:57:04.370717: Current learning rate: 0.0063 
2025-03-22 08:57:47.249077: train_loss -0.8775 
2025-03-22 08:57:47.255599: val_loss -0.8509 
2025-03-22 08:57:47.261666: Pseudo dice [np.float64(0.9475), np.float64(0.9319), np.float64(0.9247)] 
2025-03-22 08:57:47.266679: Epoch time: 42.89 s 
2025-03-22 08:57:48.069969:  
2025-03-22 08:57:48.075664: Epoch 402 
2025-03-22 08:57:48.080751: Current learning rate: 0.0063 
2025-03-22 08:58:31.195630: train_loss -0.8565 
2025-03-22 08:58:31.203173: val_loss -0.8451 
2025-03-22 08:58:31.209697: Pseudo dice [np.float64(0.9519), np.float64(0.9272), np.float64(0.9183)] 
2025-03-22 08:58:31.214710: Epoch time: 43.13 s 
2025-03-22 08:58:32.012221:  
2025-03-22 08:58:32.017273: Epoch 403 
2025-03-22 08:58:32.022370: Current learning rate: 0.00629 
2025-03-22 08:59:16.153114: train_loss -0.8636 
2025-03-22 08:59:16.161159: val_loss -0.8343 
2025-03-22 08:59:16.166176: Pseudo dice [np.float64(0.9519), np.float64(0.9242), np.float64(0.921)] 
2025-03-22 08:59:16.172193: Epoch time: 44.14 s 
2025-03-22 08:59:16.979345:  
2025-03-22 08:59:16.986866: Epoch 404 
2025-03-22 08:59:16.992883: Current learning rate: 0.00628 
2025-03-22 09:00:00.136321: train_loss -0.8622 
2025-03-22 09:00:00.143847: val_loss -0.8544 
2025-03-22 09:00:00.151383: Pseudo dice [np.float64(0.9487), np.float64(0.9302), np.float64(0.9122)] 
2025-03-22 09:00:00.158916: Epoch time: 43.16 s 
2025-03-22 09:00:00.952762:  
2025-03-22 09:00:00.959342: Epoch 405 
2025-03-22 09:00:00.964417: Current learning rate: 0.00627 
2025-03-22 09:00:43.975668: train_loss -0.8716 
2025-03-22 09:00:43.983191: val_loss -0.8165 
2025-03-22 09:00:43.988205: Pseudo dice [np.float64(0.9397), np.float64(0.9213), np.float64(0.8975)] 
2025-03-22 09:00:43.992216: Epoch time: 43.02 s 
2025-03-22 09:00:44.778848:  
2025-03-22 09:00:44.785672: Epoch 406 
2025-03-22 09:00:44.790279: Current learning rate: 0.00626 
2025-03-22 09:01:27.943774: train_loss -0.861 
2025-03-22 09:01:27.952302: val_loss -0.8574 
2025-03-22 09:01:27.957819: Pseudo dice [np.float64(0.949), np.float64(0.9518), np.float64(0.9203)] 
2025-03-22 09:01:27.963861: Epoch time: 43.17 s 
2025-03-22 09:01:28.741513:  
2025-03-22 09:01:28.748080: Epoch 407 
2025-03-22 09:01:28.754785: Current learning rate: 0.00625 
2025-03-22 09:02:11.892231: train_loss -0.8684 
2025-03-22 09:02:11.899902: val_loss -0.8575 
2025-03-22 09:02:11.906419: Pseudo dice [np.float64(0.9449), np.float64(0.9337), np.float64(0.9218)] 
2025-03-22 09:02:11.914944: Epoch time: 43.15 s 
2025-03-22 09:02:12.930920:  
2025-03-22 09:02:12.937470: Epoch 408 
2025-03-22 09:02:12.942613: Current learning rate: 0.00624 
2025-03-22 09:02:56.001307: train_loss -0.868 
2025-03-22 09:02:56.008828: val_loss -0.8294 
2025-03-22 09:02:56.016349: Pseudo dice [np.float64(0.9468), np.float64(0.9282), np.float64(0.9144)] 
2025-03-22 09:02:56.021362: Epoch time: 43.07 s 
2025-03-22 09:02:56.823576:  
2025-03-22 09:02:56.830150: Epoch 409 
2025-03-22 09:02:56.836746: Current learning rate: 0.00623 
2025-03-22 09:03:39.732028: train_loss -0.8701 
2025-03-22 09:03:39.740555: val_loss -0.8316 
2025-03-22 09:03:39.747091: Pseudo dice [np.float64(0.9468), np.float64(0.9322), np.float64(0.9109)] 
2025-03-22 09:03:39.752106: Epoch time: 42.91 s 
2025-03-22 09:03:40.545006:  
2025-03-22 09:03:40.551030: Epoch 410 
2025-03-22 09:03:40.556045: Current learning rate: 0.00622 
2025-03-22 09:04:23.651916: train_loss -0.8678 
2025-03-22 09:04:23.659440: val_loss -0.8359 
2025-03-22 09:04:23.665456: Pseudo dice [np.float64(0.9452), np.float64(0.9283), np.float64(0.9157)] 
2025-03-22 09:04:23.670973: Epoch time: 43.11 s 
2025-03-22 09:04:24.408058:  
2025-03-22 09:04:24.414576: Epoch 411 
2025-03-22 09:04:24.419592: Current learning rate: 0.00621 
2025-03-22 09:05:07.326338: train_loss -0.8684 
2025-03-22 09:05:07.333858: val_loss -0.8644 
2025-03-22 09:05:07.340379: Pseudo dice [np.float64(0.948), np.float64(0.9354), np.float64(0.9128)] 
2025-03-22 09:05:07.346398: Epoch time: 42.92 s 
2025-03-22 09:05:08.070212:  
2025-03-22 09:05:08.075757: Epoch 412 
2025-03-22 09:05:08.080824: Current learning rate: 0.0062 
2025-03-22 09:05:52.207776: train_loss -0.8738 
2025-03-22 09:05:52.215363: val_loss -0.8713 
2025-03-22 09:05:52.221882: Pseudo dice [np.float64(0.9496), np.float64(0.9455), np.float64(0.9209)] 
2025-03-22 09:05:52.228925: Epoch time: 44.14 s 
2025-03-22 09:05:52.984389:  
2025-03-22 09:05:52.991940: Epoch 413 
2025-03-22 09:05:52.996973: Current learning rate: 0.00619 
2025-03-22 09:06:36.161702: train_loss -0.8715 
2025-03-22 09:06:36.169840: val_loss -0.8604 
2025-03-22 09:06:36.176009: Pseudo dice [np.float64(0.9499), np.float64(0.9366), np.float64(0.9204)] 
2025-03-22 09:06:36.182578: Epoch time: 43.18 s 
2025-03-22 09:06:36.900837:  
2025-03-22 09:06:36.907408: Epoch 414 
2025-03-22 09:06:36.909944: Current learning rate: 0.00618 
2025-03-22 09:07:19.833231: train_loss -0.8679 
2025-03-22 09:07:19.839743: val_loss -0.8456 
2025-03-22 09:07:19.843251: Pseudo dice [np.float64(0.9512), np.float64(0.9326), np.float64(0.9121)] 
2025-03-22 09:07:19.847261: Epoch time: 42.93 s 
2025-03-22 09:07:20.614017:  
2025-03-22 09:07:20.620030: Epoch 415 
2025-03-22 09:07:20.625043: Current learning rate: 0.00617 
2025-03-22 09:08:03.687863: train_loss -0.8612 
2025-03-22 09:08:03.696388: val_loss -0.8557 
2025-03-22 09:08:03.701907: Pseudo dice [np.float64(0.9467), np.float64(0.9362), np.float64(0.905)] 
2025-03-22 09:08:03.707924: Epoch time: 43.08 s 
2025-03-22 09:08:04.464607:  
2025-03-22 09:08:04.470148: Epoch 416 
2025-03-22 09:08:04.475190: Current learning rate: 0.00616 
2025-03-22 09:08:47.574960: train_loss -0.8668 
2025-03-22 09:08:47.583664: val_loss -0.8399 
2025-03-22 09:08:47.589670: Pseudo dice [np.float64(0.9483), np.float64(0.9124), np.float64(0.9149)] 
2025-03-22 09:08:47.594686: Epoch time: 43.11 s 
2025-03-22 09:08:48.569378:  
2025-03-22 09:08:48.574891: Epoch 417 
2025-03-22 09:08:48.578407: Current learning rate: 0.00615 
2025-03-22 09:09:31.567777: train_loss -0.8678 
2025-03-22 09:09:31.575302: val_loss -0.8412 
2025-03-22 09:09:31.580317: Pseudo dice [np.float64(0.946), np.float64(0.9328), np.float64(0.9172)] 
2025-03-22 09:09:31.584325: Epoch time: 43.0 s 
2025-03-22 09:09:32.349829:  
2025-03-22 09:09:32.356352: Epoch 418 
2025-03-22 09:09:32.361362: Current learning rate: 0.00614 
2025-03-22 09:10:15.151865: train_loss -0.874 
2025-03-22 09:10:15.159520: val_loss -0.8611 
2025-03-22 09:10:15.165199: Pseudo dice [np.float64(0.9499), np.float64(0.951), np.float64(0.923)] 
2025-03-22 09:10:15.171509: Epoch time: 42.8 s 
2025-03-22 09:10:15.931013:  
2025-03-22 09:10:15.937581: Epoch 419 
2025-03-22 09:10:15.942712: Current learning rate: 0.00613 
2025-03-22 09:10:58.921508: train_loss -0.8652 
2025-03-22 09:10:58.929031: val_loss -0.8187 
2025-03-22 09:10:58.935051: Pseudo dice [np.float64(0.9395), np.float64(0.9335), np.float64(0.907)] 
2025-03-22 09:10:58.939059: Epoch time: 42.99 s 
2025-03-22 09:10:59.697873:  
2025-03-22 09:10:59.703974: Epoch 420 
2025-03-22 09:10:59.710637: Current learning rate: 0.00612 
2025-03-22 09:11:42.529140: train_loss -0.8635 
2025-03-22 09:11:42.536665: val_loss -0.8277 
2025-03-22 09:11:42.543180: Pseudo dice [np.float64(0.9433), np.float64(0.9314), np.float64(0.9133)] 
2025-03-22 09:11:42.548193: Epoch time: 42.83 s 
2025-03-22 09:11:43.314521:  
2025-03-22 09:11:43.321034: Epoch 421 
2025-03-22 09:11:43.327050: Current learning rate: 0.00612 
2025-03-22 09:12:27.617775: train_loss -0.861 
2025-03-22 09:12:27.625297: val_loss -0.8613 
2025-03-22 09:12:27.629314: Pseudo dice [np.float64(0.9386), np.float64(0.9362), np.float64(0.9137)] 
2025-03-22 09:12:27.632823: Epoch time: 44.3 s 
2025-03-22 09:12:28.344964:  
2025-03-22 09:12:28.351482: Epoch 422 
2025-03-22 09:12:28.355492: Current learning rate: 0.00611 
2025-03-22 09:13:11.521590: train_loss -0.8673 
2025-03-22 09:13:11.529783: val_loss -0.8464 
2025-03-22 09:13:11.534848: Pseudo dice [np.float64(0.944), np.float64(0.9417), np.float64(0.9149)] 
2025-03-22 09:13:11.539912: Epoch time: 43.18 s 
2025-03-22 09:13:12.296227:  
2025-03-22 09:13:12.302802: Epoch 423 
2025-03-22 09:13:12.307873: Current learning rate: 0.0061 
2025-03-22 09:13:55.480801: train_loss -0.8754 
2025-03-22 09:13:55.487843: val_loss -0.8552 
2025-03-22 09:13:55.493859: Pseudo dice [np.float64(0.9506), np.float64(0.9434), np.float64(0.9216)] 
2025-03-22 09:13:55.497869: Epoch time: 43.19 s 
2025-03-22 09:13:56.235868:  
2025-03-22 09:13:56.241987: Epoch 424 
2025-03-22 09:13:56.247057: Current learning rate: 0.00609 
2025-03-22 09:14:39.443320: train_loss -0.8751 
2025-03-22 09:14:39.450835: val_loss -0.8304 
2025-03-22 09:14:39.458361: Pseudo dice [np.float64(0.9472), np.float64(0.9337), np.float64(0.92)] 
2025-03-22 09:14:39.464880: Epoch time: 43.21 s 
2025-03-22 09:14:40.463004:  
2025-03-22 09:14:40.469022: Epoch 425 
2025-03-22 09:14:40.472525: Current learning rate: 0.00608 
2025-03-22 09:15:23.458206: train_loss -0.8642 
2025-03-22 09:15:23.465731: val_loss -0.8405 
2025-03-22 09:15:23.472248: Pseudo dice [np.float64(0.9463), np.float64(0.9218), np.float64(0.9154)] 
2025-03-22 09:15:23.476756: Epoch time: 43.0 s 
2025-03-22 09:15:24.236229:  
2025-03-22 09:15:24.243791: Epoch 426 
2025-03-22 09:15:24.249848: Current learning rate: 0.00607 
2025-03-22 09:16:07.208656: train_loss -0.8641 
2025-03-22 09:16:07.215741: val_loss -0.8625 
2025-03-22 09:16:07.222327: Pseudo dice [np.float64(0.9518), np.float64(0.9308), np.float64(0.9119)] 
2025-03-22 09:16:07.229900: Epoch time: 42.97 s 
2025-03-22 09:16:07.972493:  
2025-03-22 09:16:07.977552: Epoch 427 
2025-03-22 09:16:07.982285: Current learning rate: 0.00606 
2025-03-22 09:16:51.015258: train_loss -0.8771 
2025-03-22 09:16:51.021327: val_loss -0.8459 
2025-03-22 09:16:51.026988: Pseudo dice [np.float64(0.9512), np.float64(0.9497), np.float64(0.916)] 
2025-03-22 09:16:51.032013: Epoch time: 43.04 s 
2025-03-22 09:16:51.807426:  
2025-03-22 09:16:51.815016: Epoch 428 
2025-03-22 09:16:51.821114: Current learning rate: 0.00605 
2025-03-22 09:17:34.768659: train_loss -0.8757 
2025-03-22 09:17:34.775677: val_loss -0.8535 
2025-03-22 09:17:34.781224: Pseudo dice [np.float64(0.9507), np.float64(0.9328), np.float64(0.9185)] 
2025-03-22 09:17:34.787245: Epoch time: 42.96 s 
2025-03-22 09:17:35.532093:  
2025-03-22 09:17:35.538625: Epoch 429 
2025-03-22 09:17:35.543149: Current learning rate: 0.00604 
2025-03-22 09:18:18.523877: train_loss -0.8708 
2025-03-22 09:18:18.530962: val_loss -0.8392 
2025-03-22 09:18:18.536980: Pseudo dice [np.float64(0.9483), np.float64(0.9392), np.float64(0.9173)] 
2025-03-22 09:18:18.543501: Epoch time: 42.99 s 
2025-03-22 09:18:19.301751:  
2025-03-22 09:18:19.309277: Epoch 430 
2025-03-22 09:18:19.315298: Current learning rate: 0.00603 
2025-03-22 09:19:03.632306: train_loss -0.8716 
2025-03-22 09:19:03.638826: val_loss -0.8502 
2025-03-22 09:19:03.644842: Pseudo dice [np.float64(0.9418), np.float64(0.9347), np.float64(0.917)] 
2025-03-22 09:19:03.651362: Epoch time: 44.33 s 
2025-03-22 09:19:04.423827:  
2025-03-22 09:19:04.430410: Epoch 431 
2025-03-22 09:19:04.435429: Current learning rate: 0.00602 
2025-03-22 09:19:47.600774: train_loss -0.8625 
2025-03-22 09:19:47.610317: val_loss -0.8668 
2025-03-22 09:19:47.616850: Pseudo dice [np.float64(0.9519), np.float64(0.9495), np.float64(0.9248)] 
2025-03-22 09:19:47.621866: Epoch time: 43.18 s 
2025-03-22 09:19:48.382804:  
2025-03-22 09:19:48.388341: Epoch 432 
2025-03-22 09:19:48.392948: Current learning rate: 0.00601 
2025-03-22 09:20:31.513963: train_loss -0.8642 
2025-03-22 09:20:31.520483: val_loss -0.8613 
2025-03-22 09:20:31.526506: Pseudo dice [np.float64(0.9466), np.float64(0.9458), np.float64(0.9173)] 
2025-03-22 09:20:31.531523: Epoch time: 43.13 s 
2025-03-22 09:20:31.536541: Yayy! New best EMA pseudo Dice: 0.934 
2025-03-22 09:20:32.337436:  
2025-03-22 09:20:32.343450: Epoch 433 
2025-03-22 09:20:32.347465: Current learning rate: 0.006 
2025-03-22 09:21:15.389782: train_loss -0.8691 
2025-03-22 09:21:15.397810: val_loss -0.8453 
2025-03-22 09:21:15.402318: Pseudo dice [np.float64(0.9501), np.float64(0.9471), np.float64(0.9194)] 
2025-03-22 09:21:15.406331: Epoch time: 43.05 s 
2025-03-22 09:21:15.411342: Yayy! New best EMA pseudo Dice: 0.9345 
2025-03-22 09:21:16.538365:  
2025-03-22 09:21:16.544380: Epoch 434 
2025-03-22 09:21:16.548396: Current learning rate: 0.00599 
2025-03-22 09:21:59.507920: train_loss -0.874 
2025-03-22 09:21:59.515442: val_loss -0.8685 
2025-03-22 09:21:59.522964: Pseudo dice [np.float64(0.9489), np.float64(0.9321), np.float64(0.9245)] 
2025-03-22 09:21:59.528996: Epoch time: 42.97 s 
2025-03-22 09:21:59.536528: Yayy! New best EMA pseudo Dice: 0.9346 
2025-03-22 09:22:00.429217:  
2025-03-22 09:22:00.438297: Epoch 435 
2025-03-22 09:22:00.443902: Current learning rate: 0.00598 
2025-03-22 09:22:43.584628: train_loss -0.867 
2025-03-22 09:22:43.590646: val_loss -0.838 
2025-03-22 09:22:43.597690: Pseudo dice [np.float64(0.9378), np.float64(0.9345), np.float64(0.9091)] 
2025-03-22 09:22:43.604712: Epoch time: 43.16 s 
2025-03-22 09:22:44.346813:  
2025-03-22 09:22:44.355045: Epoch 436 
2025-03-22 09:22:44.360141: Current learning rate: 0.00597 
2025-03-22 09:23:27.293530: train_loss -0.8713 
2025-03-22 09:23:27.300047: val_loss -0.8522 
2025-03-22 09:23:27.308086: Pseudo dice [np.float64(0.9455), np.float64(0.9408), np.float64(0.9168)] 
2025-03-22 09:23:27.314130: Epoch time: 42.95 s 
2025-03-22 09:23:28.022631:  
2025-03-22 09:23:28.029151: Epoch 437 
2025-03-22 09:23:28.034171: Current learning rate: 0.00596 
2025-03-22 09:24:10.903284: train_loss -0.8664 
2025-03-22 09:24:10.909802: val_loss -0.8495 
2025-03-22 09:24:10.914819: Pseudo dice [np.float64(0.9474), np.float64(0.9264), np.float64(0.9075)] 
2025-03-22 09:24:10.920838: Epoch time: 42.88 s 
2025-03-22 09:24:11.651750:  
2025-03-22 09:24:11.659269: Epoch 438 
2025-03-22 09:24:11.664279: Current learning rate: 0.00595 
2025-03-22 09:24:54.530509: train_loss -0.8663 
2025-03-22 09:24:54.538536: val_loss -0.8474 
2025-03-22 09:24:54.543552: Pseudo dice [np.float64(0.9469), np.float64(0.8979), np.float64(0.9234)] 
2025-03-22 09:24:54.548570: Epoch time: 42.88 s 
2025-03-22 09:24:55.297828:  
2025-03-22 09:24:55.303845: Epoch 439 
2025-03-22 09:24:55.308856: Current learning rate: 0.00594 
2025-03-22 09:25:38.233605: train_loss -0.868 
2025-03-22 09:25:38.242119: val_loss -0.8608 
2025-03-22 09:25:38.247634: Pseudo dice [np.float64(0.9454), np.float64(0.9417), np.float64(0.9149)] 
2025-03-22 09:25:38.252645: Epoch time: 42.94 s 
2025-03-22 09:25:39.007870:  
2025-03-22 09:25:39.013885: Epoch 440 
2025-03-22 09:25:39.018898: Current learning rate: 0.00593 
2025-03-22 09:26:21.798105: train_loss -0.857 
2025-03-22 09:26:21.806131: val_loss -0.8582 
2025-03-22 09:26:21.813652: Pseudo dice [np.float64(0.9466), np.float64(0.9449), np.float64(0.9169)] 
2025-03-22 09:26:21.818162: Epoch time: 42.79 s 
2025-03-22 09:26:22.583644:  
2025-03-22 09:26:22.591172: Epoch 441 
2025-03-22 09:26:22.596688: Current learning rate: 0.00592 
2025-03-22 09:27:07.597230: train_loss -0.8591 
2025-03-22 09:27:07.604805: val_loss -0.8162 
2025-03-22 09:27:07.609891: Pseudo dice [np.float64(0.9424), np.float64(0.9111), np.float64(0.9102)] 
2025-03-22 09:27:07.615020: Epoch time: 45.01 s 
2025-03-22 09:27:08.621615:  
2025-03-22 09:27:08.628161: Epoch 442 
2025-03-22 09:27:08.632189: Current learning rate: 0.00592 
2025-03-22 09:27:51.686923: train_loss -0.8762 
2025-03-22 09:27:51.693994: val_loss -0.8475 
2025-03-22 09:27:51.700513: Pseudo dice [np.float64(0.948), np.float64(0.9336), np.float64(0.9207)] 
2025-03-22 09:27:51.705530: Epoch time: 43.07 s 
2025-03-22 09:27:52.446713:  
2025-03-22 09:27:52.453924: Epoch 443 
2025-03-22 09:27:52.457966: Current learning rate: 0.00591 
2025-03-22 09:28:35.417379: train_loss -0.8682 
2025-03-22 09:28:35.424901: val_loss -0.8332 
2025-03-22 09:28:35.429917: Pseudo dice [np.float64(0.9402), np.float64(0.9413), np.float64(0.913)] 
2025-03-22 09:28:35.434933: Epoch time: 42.97 s 
2025-03-22 09:28:36.190253:  
2025-03-22 09:28:36.195783: Epoch 444 
2025-03-22 09:28:36.201797: Current learning rate: 0.0059 
2025-03-22 09:29:19.166538: train_loss -0.8705 
2025-03-22 09:29:19.174062: val_loss -0.8523 
2025-03-22 09:29:19.180578: Pseudo dice [np.float64(0.9483), np.float64(0.938), np.float64(0.9186)] 
2025-03-22 09:29:19.186594: Epoch time: 42.98 s 
2025-03-22 09:29:19.950976:  
2025-03-22 09:29:19.958122: Epoch 445 
2025-03-22 09:29:19.961672: Current learning rate: 0.00589 
2025-03-22 09:30:03.145546: train_loss -0.8656 
2025-03-22 09:30:03.154685: val_loss -0.8503 
2025-03-22 09:30:03.160378: Pseudo dice [np.float64(0.9541), np.float64(0.937), np.float64(0.924)] 
2025-03-22 09:30:03.164401: Epoch time: 43.2 s 
2025-03-22 09:30:03.932008:  
2025-03-22 09:30:03.939102: Epoch 446 
2025-03-22 09:30:03.943192: Current learning rate: 0.00588 
2025-03-22 09:30:46.927792: train_loss -0.8674 
2025-03-22 09:30:46.936345: val_loss -0.8517 
2025-03-22 09:30:46.942010: Pseudo dice [np.float64(0.9475), np.float64(0.9238), np.float64(0.9098)] 
2025-03-22 09:30:46.949806: Epoch time: 43.0 s 
2025-03-22 09:30:47.696670:  
2025-03-22 09:30:47.703187: Epoch 447 
2025-03-22 09:30:47.708203: Current learning rate: 0.00587 
2025-03-22 09:31:30.749993: train_loss -0.8656 
2025-03-22 09:31:30.757516: val_loss -0.8427 
2025-03-22 09:31:30.763530: Pseudo dice [np.float64(0.9465), np.float64(0.942), np.float64(0.9141)] 
2025-03-22 09:31:30.769046: Epoch time: 43.05 s 
2025-03-22 09:31:31.506641:  
2025-03-22 09:31:31.514354: Epoch 448 
2025-03-22 09:31:31.518911: Current learning rate: 0.00586 
2025-03-22 09:32:14.478454: train_loss -0.8657 
2025-03-22 09:32:14.486580: val_loss -0.8301 
2025-03-22 09:32:14.491751: Pseudo dice [np.float64(0.9452), np.float64(0.9322), np.float64(0.9045)] 
2025-03-22 09:32:14.497411: Epoch time: 42.97 s 
2025-03-22 09:32:15.289825:  
2025-03-22 09:32:15.297976: Epoch 449 
2025-03-22 09:32:15.304628: Current learning rate: 0.00585 
2025-03-22 09:32:58.403972: train_loss -0.8653 
2025-03-22 09:32:58.413615: val_loss -0.873 
2025-03-22 09:32:58.421346: Pseudo dice [np.float64(0.9521), np.float64(0.9538), np.float64(0.9256)] 
2025-03-22 09:32:58.428470: Epoch time: 43.11 s 
2025-03-22 09:32:59.279440:  
2025-03-22 09:32:59.285957: Epoch 450 
2025-03-22 09:32:59.289963: Current learning rate: 0.00584 
2025-03-22 09:33:42.533407: train_loss -0.867 
2025-03-22 09:33:42.540927: val_loss -0.8583 
2025-03-22 09:33:42.545940: Pseudo dice [np.float64(0.9554), np.float64(0.9254), np.float64(0.9077)] 
2025-03-22 09:33:42.549948: Epoch time: 43.25 s 
2025-03-22 09:33:43.548307:  
2025-03-22 09:33:43.555512: Epoch 451 
2025-03-22 09:33:43.558660: Current learning rate: 0.00583 
2025-03-22 09:34:26.671257: train_loss -0.856 
2025-03-22 09:34:26.679783: val_loss -0.8387 
2025-03-22 09:34:26.685798: Pseudo dice [np.float64(0.9398), np.float64(0.9461), np.float64(0.9147)] 
2025-03-22 09:34:26.693827: Epoch time: 43.12 s 
2025-03-22 09:34:27.446482:  
2025-03-22 09:34:27.453004: Epoch 452 
2025-03-22 09:34:27.457016: Current learning rate: 0.00582 
2025-03-22 09:35:10.410580: train_loss -0.8667 
2025-03-22 09:35:10.418105: val_loss -0.8552 
2025-03-22 09:35:10.424621: Pseudo dice [np.float64(0.952), np.float64(0.9392), np.float64(0.9281)] 
2025-03-22 09:35:10.430639: Epoch time: 42.97 s 
2025-03-22 09:35:11.191930:  
2025-03-22 09:35:11.199021: Epoch 453 
2025-03-22 09:35:11.203114: Current learning rate: 0.00581 
2025-03-22 09:35:54.537601: train_loss -0.8688 
2025-03-22 09:35:54.545733: val_loss -0.8468 
2025-03-22 09:35:54.551750: Pseudo dice [np.float64(0.9449), np.float64(0.9326), np.float64(0.9167)] 
2025-03-22 09:35:54.557762: Epoch time: 43.35 s 
2025-03-22 09:35:55.311223:  
2025-03-22 09:35:55.317323: Epoch 454 
2025-03-22 09:35:55.320366: Current learning rate: 0.0058 
2025-03-22 09:36:38.297775: train_loss -0.8659 
2025-03-22 09:36:38.306298: val_loss -0.8266 
2025-03-22 09:36:38.312813: Pseudo dice [np.float64(0.945), np.float64(0.9375), np.float64(0.9121)] 
2025-03-22 09:36:38.320337: Epoch time: 42.99 s 
2025-03-22 09:36:39.084724:  
2025-03-22 09:36:39.091317: Epoch 455 
2025-03-22 09:36:39.096440: Current learning rate: 0.00579 
2025-03-22 09:37:21.941540: train_loss -0.8669 
2025-03-22 09:37:21.950568: val_loss -0.8465 
2025-03-22 09:37:21.957589: Pseudo dice [np.float64(0.9458), np.float64(0.9373), np.float64(0.9177)] 
2025-03-22 09:37:21.963108: Epoch time: 42.86 s 
2025-03-22 09:37:22.700411:  
2025-03-22 09:37:22.706501: Epoch 456 
2025-03-22 09:37:22.711515: Current learning rate: 0.00578 
2025-03-22 09:38:05.656887: train_loss -0.8688 
2025-03-22 09:38:05.662963: val_loss -0.866 
2025-03-22 09:38:05.668033: Pseudo dice [np.float64(0.9486), np.float64(0.9502), np.float64(0.9228)] 
2025-03-22 09:38:05.672593: Epoch time: 42.96 s 
2025-03-22 09:38:06.417915:  
2025-03-22 09:38:06.424526: Epoch 457 
2025-03-22 09:38:06.429576: Current learning rate: 0.00577 
2025-03-22 09:38:49.481285: train_loss -0.8728 
2025-03-22 09:38:49.489858: val_loss -0.8476 
2025-03-22 09:38:49.495418: Pseudo dice [np.float64(0.9454), np.float64(0.9481), np.float64(0.9287)] 
2025-03-22 09:38:49.499952: Epoch time: 43.06 s 
2025-03-22 09:38:49.505002: Yayy! New best EMA pseudo Dice: 0.9346 
2025-03-22 09:38:50.384990:  
2025-03-22 09:38:50.392038: Epoch 458 
2025-03-22 09:38:50.396587: Current learning rate: 0.00576 
2025-03-22 09:39:34.292737: train_loss -0.8713 
2025-03-22 09:39:34.300258: val_loss -0.846 
2025-03-22 09:39:34.304273: Pseudo dice [np.float64(0.9425), np.float64(0.9319), np.float64(0.9205)] 
2025-03-22 09:39:34.308783: Epoch time: 43.91 s 
2025-03-22 09:39:35.058063:  
2025-03-22 09:39:35.064620: Epoch 459 
2025-03-22 09:39:35.069678: Current learning rate: 0.00575 
2025-03-22 09:40:18.006655: train_loss -0.8748 
2025-03-22 09:40:18.016232: val_loss -0.8594 
2025-03-22 09:40:18.021786: Pseudo dice [np.float64(0.9512), np.float64(0.9472), np.float64(0.9302)] 
2025-03-22 09:40:18.025815: Epoch time: 42.95 s 
2025-03-22 09:40:18.030856: Yayy! New best EMA pseudo Dice: 0.9351 
2025-03-22 09:40:19.112719:  
2025-03-22 09:40:19.119275: Epoch 460 
2025-03-22 09:40:19.121845: Current learning rate: 0.00574 
2025-03-22 09:41:02.156038: train_loss -0.8669 
2025-03-22 09:41:02.163563: val_loss -0.8644 
2025-03-22 09:41:02.170088: Pseudo dice [np.float64(0.9527), np.float64(0.9376), np.float64(0.9141)] 
2025-03-22 09:41:02.177116: Epoch time: 43.04 s 
2025-03-22 09:41:02.875424:  
2025-03-22 09:41:02.881436: Epoch 461 
2025-03-22 09:41:02.885446: Current learning rate: 0.00573 
2025-03-22 09:41:45.793571: train_loss -0.8703 
2025-03-22 09:41:45.801103: val_loss -0.85 
2025-03-22 09:41:45.805113: Pseudo dice [np.float64(0.9505), np.float64(0.9367), np.float64(0.9184)] 
2025-03-22 09:41:45.808620: Epoch time: 42.92 s 
2025-03-22 09:41:46.558884:  
2025-03-22 09:41:46.566569: Epoch 462 
2025-03-22 09:41:46.572161: Current learning rate: 0.00572 
2025-03-22 09:42:29.542781: train_loss -0.8667 
2025-03-22 09:42:29.553534: val_loss -0.8466 
2025-03-22 09:42:29.560556: Pseudo dice [np.float64(0.9477), np.float64(0.9464), np.float64(0.917)] 
2025-03-22 09:42:29.567079: Epoch time: 42.98 s 
2025-03-22 09:42:29.573094: Yayy! New best EMA pseudo Dice: 0.9353 
2025-03-22 09:42:30.441642:  
2025-03-22 09:42:30.447678: Epoch 463 
2025-03-22 09:42:30.454222: Current learning rate: 0.00571 
2025-03-22 09:43:13.506826: train_loss -0.8756 
2025-03-22 09:43:13.514410: val_loss -0.8484 
2025-03-22 09:43:13.521477: Pseudo dice [np.float64(0.9477), np.float64(0.9448), np.float64(0.9253)] 
2025-03-22 09:43:13.526656: Epoch time: 43.07 s 
2025-03-22 09:43:13.531223: Yayy! New best EMA pseudo Dice: 0.9357 
2025-03-22 09:43:14.375326:  
2025-03-22 09:43:14.381898: Epoch 464 
2025-03-22 09:43:14.386985: Current learning rate: 0.0057 
2025-03-22 09:43:57.360851: train_loss -0.8729 
2025-03-22 09:43:57.367368: val_loss -0.8529 
2025-03-22 09:43:57.372379: Pseudo dice [np.float64(0.942), np.float64(0.9443), np.float64(0.9209)] 
2025-03-22 09:43:57.377395: Epoch time: 42.99 s 
2025-03-22 09:43:57.383415: Yayy! New best EMA pseudo Dice: 0.9357 
2025-03-22 09:43:58.238531:  
2025-03-22 09:43:58.245083: Epoch 465 
2025-03-22 09:43:58.251126: Current learning rate: 0.0057 
2025-03-22 09:44:41.394468: train_loss -0.8692 
2025-03-22 09:44:41.400550: val_loss -0.8681 
2025-03-22 09:44:41.405604: Pseudo dice [np.float64(0.9467), np.float64(0.9294), np.float64(0.9184)] 
2025-03-22 09:44:41.410657: Epoch time: 43.16 s 
2025-03-22 09:44:42.151392:  
2025-03-22 09:44:42.156415: Epoch 466 
2025-03-22 09:44:42.162462: Current learning rate: 0.00569 
2025-03-22 09:45:25.265625: train_loss -0.8752 
2025-03-22 09:45:25.273666: val_loss -0.8306 
2025-03-22 09:45:25.281200: Pseudo dice [np.float64(0.9439), np.float64(0.9285), np.float64(0.9169)] 
2025-03-22 09:45:25.288726: Epoch time: 43.12 s 
2025-03-22 09:45:26.043051:  
2025-03-22 09:45:26.050569: Epoch 467 
2025-03-22 09:45:26.055583: Current learning rate: 0.00568 
2025-03-22 09:46:10.372299: train_loss -0.8668 
2025-03-22 09:46:10.379319: val_loss -0.8271 
2025-03-22 09:46:10.384333: Pseudo dice [np.float64(0.9455), np.float64(0.9278), np.float64(0.9127)] 
2025-03-22 09:46:10.388344: Epoch time: 44.33 s 
2025-03-22 09:46:11.388098:  
2025-03-22 09:46:11.393666: Epoch 468 
2025-03-22 09:46:11.398756: Current learning rate: 0.00567 
2025-03-22 09:46:54.797987: train_loss -0.868 
2025-03-22 09:46:54.805566: val_loss -0.8231 
2025-03-22 09:46:54.810695: Pseudo dice [np.float64(0.9471), np.float64(0.9383), np.float64(0.9061)] 
2025-03-22 09:46:54.814846: Epoch time: 43.41 s 
2025-03-22 09:46:55.571167:  
2025-03-22 09:46:55.577739: Epoch 469 
2025-03-22 09:46:55.582867: Current learning rate: 0.00566 
2025-03-22 09:47:38.588542: train_loss -0.8747 
2025-03-22 09:47:38.596068: val_loss -0.8504 
2025-03-22 09:47:38.602594: Pseudo dice [np.float64(0.9417), np.float64(0.9217), np.float64(0.9142)] 
2025-03-22 09:47:38.608614: Epoch time: 43.02 s 
2025-03-22 09:47:39.355539:  
2025-03-22 09:47:39.362086: Epoch 470 
2025-03-22 09:47:39.367135: Current learning rate: 0.00565 
2025-03-22 09:48:22.544422: train_loss -0.8762 
2025-03-22 09:48:22.552949: val_loss -0.8412 
2025-03-22 09:48:22.559469: Pseudo dice [np.float64(0.9493), np.float64(0.9269), np.float64(0.9156)] 
2025-03-22 09:48:22.565493: Epoch time: 43.19 s 
2025-03-22 09:48:23.292881:  
2025-03-22 09:48:23.298983: Epoch 471 
2025-03-22 09:48:23.303020: Current learning rate: 0.00564 
2025-03-22 09:49:06.394984: train_loss -0.8695 
2025-03-22 09:49:06.401510: val_loss -0.8383 
2025-03-22 09:49:06.408026: Pseudo dice [np.float64(0.9488), np.float64(0.9322), np.float64(0.9156)] 
2025-03-22 09:49:06.415041: Epoch time: 43.1 s 
2025-03-22 09:49:07.161276:  
2025-03-22 09:49:07.167847: Epoch 472 
2025-03-22 09:49:07.171896: Current learning rate: 0.00563 
2025-03-22 09:49:50.334147: train_loss -0.8705 
2025-03-22 09:49:50.342176: val_loss -0.8661 
2025-03-22 09:49:50.349198: Pseudo dice [np.float64(0.9462), np.float64(0.9406), np.float64(0.9129)] 
2025-03-22 09:49:50.355720: Epoch time: 43.17 s 
2025-03-22 09:49:51.095421:  
2025-03-22 09:49:51.102507: Epoch 473 
2025-03-22 09:49:51.107648: Current learning rate: 0.00562 
2025-03-22 09:50:33.974834: train_loss -0.87 
2025-03-22 09:50:33.983145: val_loss -0.8506 
2025-03-22 09:50:33.987729: Pseudo dice [np.float64(0.9525), np.float64(0.9336), np.float64(0.9225)] 
2025-03-22 09:50:33.992874: Epoch time: 42.88 s 
2025-03-22 09:50:34.708121:  
2025-03-22 09:50:34.715135: Epoch 474 
2025-03-22 09:50:34.721660: Current learning rate: 0.00561 
2025-03-22 09:51:17.856998: train_loss -0.8728 
2025-03-22 09:51:17.866024: val_loss -0.8688 
2025-03-22 09:51:17.872044: Pseudo dice [np.float64(0.9472), np.float64(0.9364), np.float64(0.9227)] 
2025-03-22 09:51:17.878092: Epoch time: 43.15 s 
2025-03-22 09:51:18.604854:  
2025-03-22 09:51:18.611701: Epoch 475 
2025-03-22 09:51:18.615720: Current learning rate: 0.0056 
2025-03-22 09:52:01.603731: train_loss -0.8674 
2025-03-22 09:52:01.612451: val_loss -0.8511 
2025-03-22 09:52:01.619534: Pseudo dice [np.float64(0.9434), np.float64(0.9432), np.float64(0.907)] 
2025-03-22 09:52:01.624049: Epoch time: 43.0 s 
2025-03-22 09:52:02.384882:  
2025-03-22 09:52:02.391524: Epoch 476 
2025-03-22 09:52:02.396588: Current learning rate: 0.00559 
2025-03-22 09:52:46.728258: train_loss -0.8506 
2025-03-22 09:52:46.736675: val_loss -0.8292 
2025-03-22 09:52:46.743422: Pseudo dice [np.float64(0.9394), np.float64(0.9341), np.float64(0.907)] 
2025-03-22 09:52:46.748943: Epoch time: 44.34 s 
2025-03-22 09:52:47.696320:  
2025-03-22 09:52:47.703489: Epoch 477 
2025-03-22 09:52:47.706572: Current learning rate: 0.00558 
2025-03-22 09:53:30.849530: train_loss -0.8586 
2025-03-22 09:53:30.858600: val_loss -0.8401 
2025-03-22 09:53:30.864660: Pseudo dice [np.float64(0.9444), np.float64(0.9241), np.float64(0.9138)] 
2025-03-22 09:53:30.871700: Epoch time: 43.15 s 
2025-03-22 09:53:31.646036:  
2025-03-22 09:53:31.652609: Epoch 478 
2025-03-22 09:53:31.656646: Current learning rate: 0.00557 
2025-03-22 09:54:14.635013: train_loss -0.8554 
2025-03-22 09:54:14.643617: val_loss -0.8131 
2025-03-22 09:54:14.650196: Pseudo dice [np.float64(0.941), np.float64(0.9223), np.float64(0.9099)] 
2025-03-22 09:54:14.654203: Epoch time: 42.99 s 
2025-03-22 09:54:15.431570:  
2025-03-22 09:54:15.437131: Epoch 479 
2025-03-22 09:54:15.442241: Current learning rate: 0.00556 
2025-03-22 09:54:58.346642: train_loss -0.8525 
2025-03-22 09:54:58.353678: val_loss -0.8483 
2025-03-22 09:54:58.359697: Pseudo dice [np.float64(0.9517), np.float64(0.9312), np.float64(0.9077)] 
2025-03-22 09:54:58.366217: Epoch time: 42.92 s 
2025-03-22 09:54:59.137160:  
2025-03-22 09:54:59.142743: Epoch 480 
2025-03-22 09:54:59.148761: Current learning rate: 0.00555 
2025-03-22 09:55:41.832952: train_loss -0.8519 
2025-03-22 09:55:41.839467: val_loss -0.8568 
2025-03-22 09:55:41.843476: Pseudo dice [np.float64(0.9508), np.float64(0.9133), np.float64(0.9086)] 
2025-03-22 09:55:41.848486: Epoch time: 42.7 s 
2025-03-22 09:55:42.612808:  
2025-03-22 09:55:42.618491: Epoch 481 
2025-03-22 09:55:42.623503: Current learning rate: 0.00554 
2025-03-22 09:56:25.391869: train_loss -0.8615 
2025-03-22 09:56:25.399387: val_loss -0.8489 
2025-03-22 09:56:25.405403: Pseudo dice [np.float64(0.9429), np.float64(0.9354), np.float64(0.9129)] 
2025-03-22 09:56:25.411917: Epoch time: 42.78 s 
2025-03-22 09:56:26.188418:  
2025-03-22 09:56:26.194432: Epoch 482 
2025-03-22 09:56:26.199442: Current learning rate: 0.00553 
2025-03-22 09:57:09.268020: train_loss -0.8657 
2025-03-22 09:57:09.275547: val_loss -0.8263 
2025-03-22 09:57:09.280562: Pseudo dice [np.float64(0.9348), np.float64(0.9203), np.float64(0.9057)] 
2025-03-22 09:57:09.285073: Epoch time: 43.08 s 
2025-03-22 09:57:10.022332:  
2025-03-22 09:57:10.028763: Epoch 483 
2025-03-22 09:57:10.034290: Current learning rate: 0.00552 
2025-03-22 09:57:52.935301: train_loss -0.8769 
2025-03-22 09:57:52.942821: val_loss -0.8736 
2025-03-22 09:57:52.946330: Pseudo dice [np.float64(0.948), np.float64(0.9532), np.float64(0.927)] 
2025-03-22 09:57:52.950343: Epoch time: 42.91 s 
2025-03-22 09:57:53.703395:  
2025-03-22 09:57:53.710467: Epoch 484 
2025-03-22 09:57:53.715526: Current learning rate: 0.00551 
2025-03-22 09:58:36.903149: train_loss -0.865 
2025-03-22 09:58:36.910673: val_loss -0.8677 
2025-03-22 09:58:36.915691: Pseudo dice [np.float64(0.9499), np.float64(0.938), np.float64(0.9183)] 
2025-03-22 09:58:36.920709: Epoch time: 43.2 s 
2025-03-22 09:58:37.851560:  
2025-03-22 09:58:37.859180: Epoch 485 
2025-03-22 09:58:37.863772: Current learning rate: 0.0055 
2025-03-22 09:59:21.807449: train_loss -0.8663 
2025-03-22 09:59:21.816975: val_loss -0.8228 
2025-03-22 09:59:21.823502: Pseudo dice [np.float64(0.9478), np.float64(0.9164), np.float64(0.9158)] 
2025-03-22 09:59:21.830030: Epoch time: 43.96 s 
2025-03-22 09:59:22.601929:  
2025-03-22 09:59:22.608457: Epoch 486 
2025-03-22 09:59:22.612976: Current learning rate: 0.00549 
2025-03-22 10:00:05.739786: train_loss -0.8604 
2025-03-22 10:00:05.748311: val_loss -0.8673 
2025-03-22 10:00:05.753826: Pseudo dice [np.float64(0.95), np.float64(0.9362), np.float64(0.9213)] 
2025-03-22 10:00:05.759847: Epoch time: 43.14 s 
2025-03-22 10:00:06.522328:  
2025-03-22 10:00:06.529896: Epoch 487 
2025-03-22 10:00:06.534968: Current learning rate: 0.00548 
2025-03-22 10:00:49.864611: train_loss -0.8659 
2025-03-22 10:00:49.873144: val_loss -0.8578 
2025-03-22 10:00:49.879669: Pseudo dice [np.float64(0.944), np.float64(0.9327), np.float64(0.914)] 
2025-03-22 10:00:49.884687: Epoch time: 43.34 s 
2025-03-22 10:00:50.646762:  
2025-03-22 10:00:50.653275: Epoch 488 
2025-03-22 10:00:50.656797: Current learning rate: 0.00547 
2025-03-22 10:01:33.715107: train_loss -0.8746 
2025-03-22 10:01:33.723129: val_loss -0.8352 
2025-03-22 10:01:33.728142: Pseudo dice [np.float64(0.9537), np.float64(0.9273), np.float64(0.919)] 
2025-03-22 10:01:33.733157: Epoch time: 43.07 s 
2025-03-22 10:01:34.506813:  
2025-03-22 10:01:34.513439: Epoch 489 
2025-03-22 10:01:34.518513: Current learning rate: 0.00546 
2025-03-22 10:02:17.678030: train_loss -0.8655 
2025-03-22 10:02:17.685164: val_loss -0.8482 
2025-03-22 10:02:17.689773: Pseudo dice [np.float64(0.9528), np.float64(0.9328), np.float64(0.917)] 
2025-03-22 10:02:17.695823: Epoch time: 43.17 s 
2025-03-22 10:02:18.462080:  
2025-03-22 10:02:18.469255: Epoch 490 
2025-03-22 10:02:18.474286: Current learning rate: 0.00546 
2025-03-22 10:03:01.746035: train_loss -0.8708 
2025-03-22 10:03:01.755101: val_loss -0.8534 
2025-03-22 10:03:01.762211: Pseudo dice [np.float64(0.9449), np.float64(0.9406), np.float64(0.9201)] 
2025-03-22 10:03:01.767792: Epoch time: 43.28 s 
2025-03-22 10:03:02.547900:  
2025-03-22 10:03:02.554971: Epoch 491 
2025-03-22 10:03:02.558979: Current learning rate: 0.00545 
2025-03-22 10:03:45.428888: train_loss -0.8615 
2025-03-22 10:03:45.436405: val_loss -0.8456 
2025-03-22 10:03:45.442427: Pseudo dice [np.float64(0.9491), np.float64(0.9284), np.float64(0.9136)] 
2025-03-22 10:03:45.447437: Epoch time: 42.88 s 
2025-03-22 10:03:46.292587:  
2025-03-22 10:03:46.299109: Epoch 492 
2025-03-22 10:03:46.303113: Current learning rate: 0.00544 
2025-03-22 10:04:29.513473: train_loss -0.8694 
2025-03-22 10:04:29.519991: val_loss -0.8674 
2025-03-22 10:04:29.527008: Pseudo dice [np.float64(0.9523), np.float64(0.9289), np.float64(0.9132)] 
2025-03-22 10:04:29.532521: Epoch time: 43.22 s 
2025-03-22 10:04:30.295295:  
2025-03-22 10:04:30.304397: Epoch 493 
2025-03-22 10:04:30.309441: Current learning rate: 0.00543 
2025-03-22 10:05:13.355088: train_loss -0.8758 
2025-03-22 10:05:13.361688: val_loss -0.8547 
2025-03-22 10:05:13.366699: Pseudo dice [np.float64(0.9426), np.float64(0.9329), np.float64(0.9043)] 
2025-03-22 10:05:13.371212: Epoch time: 43.06 s 
2025-03-22 10:05:14.412986:  
2025-03-22 10:05:14.420427: Epoch 494 
2025-03-22 10:05:14.423939: Current learning rate: 0.00542 
2025-03-22 10:05:58.478662: train_loss -0.8685 
2025-03-22 10:05:58.486761: val_loss -0.8523 
2025-03-22 10:05:58.491826: Pseudo dice [np.float64(0.9528), np.float64(0.9359), np.float64(0.9125)] 
2025-03-22 10:05:58.494901: Epoch time: 44.07 s 
2025-03-22 10:05:59.254380:  
2025-03-22 10:05:59.260393: Epoch 495 
2025-03-22 10:05:59.264403: Current learning rate: 0.00541 
2025-03-22 10:06:42.121678: train_loss -0.8758 
2025-03-22 10:06:42.129197: val_loss -0.8446 
2025-03-22 10:06:42.134211: Pseudo dice [np.float64(0.9477), np.float64(0.9317), np.float64(0.9042)] 
2025-03-22 10:06:42.138752: Epoch time: 42.87 s 
2025-03-22 10:06:42.879128:  
2025-03-22 10:06:42.886649: Epoch 496 
2025-03-22 10:06:42.891664: Current learning rate: 0.0054 
2025-03-22 10:07:26.008753: train_loss -0.867 
2025-03-22 10:07:26.018783: val_loss -0.8657 
2025-03-22 10:07:26.024315: Pseudo dice [np.float64(0.9482), np.float64(0.9396), np.float64(0.9172)] 
2025-03-22 10:07:26.028888: Epoch time: 43.13 s 
2025-03-22 10:07:26.798460:  
2025-03-22 10:07:26.804621: Epoch 497 
2025-03-22 10:07:26.809164: Current learning rate: 0.00539 
2025-03-22 10:08:10.037382: train_loss -0.8783 
2025-03-22 10:08:10.046570: val_loss -0.8691 
2025-03-22 10:08:10.052793: Pseudo dice [np.float64(0.9525), np.float64(0.9545), np.float64(0.9225)] 
2025-03-22 10:08:10.058809: Epoch time: 43.24 s 
2025-03-22 10:08:10.833500:  
2025-03-22 10:08:10.840105: Epoch 498 
2025-03-22 10:08:10.845181: Current learning rate: 0.00538 
2025-03-22 10:08:53.707250: train_loss -0.8764 
2025-03-22 10:08:53.714772: val_loss -0.8515 
2025-03-22 10:08:53.719785: Pseudo dice [np.float64(0.9537), np.float64(0.9263), np.float64(0.9223)] 
2025-03-22 10:08:53.724800: Epoch time: 42.87 s 
2025-03-22 10:08:54.466055:  
2025-03-22 10:08:54.472782: Epoch 499 
2025-03-22 10:08:54.476838: Current learning rate: 0.00537 
2025-03-22 10:09:37.650438: train_loss -0.8656 
2025-03-22 10:09:37.656502: val_loss -0.8546 
2025-03-22 10:09:37.664132: Pseudo dice [np.float64(0.9488), np.float64(0.9517), np.float64(0.9202)] 
2025-03-22 10:09:37.670828: Epoch time: 43.18 s 
2025-03-22 10:09:38.542672:  
2025-03-22 10:09:38.550816: Epoch 500 
2025-03-22 10:09:38.557471: Current learning rate: 0.00536 
2025-03-22 10:10:21.397489: train_loss -0.8654 
2025-03-22 10:10:21.406008: val_loss -0.8291 
2025-03-22 10:10:21.411524: Pseudo dice [np.float64(0.9435), np.float64(0.9262), np.float64(0.9003)] 
2025-03-22 10:10:21.416033: Epoch time: 42.85 s 
2025-03-22 10:10:22.195874:  
2025-03-22 10:10:22.201894: Epoch 501 
2025-03-22 10:10:22.206909: Current learning rate: 0.00535 
2025-03-22 10:11:05.383382: train_loss -0.8688 
2025-03-22 10:11:05.390896: val_loss -0.8415 
2025-03-22 10:11:05.395910: Pseudo dice [np.float64(0.9373), np.float64(0.9368), np.float64(0.9061)] 
2025-03-22 10:11:05.401927: Epoch time: 43.19 s 
2025-03-22 10:11:06.167526:  
2025-03-22 10:11:06.173643: Epoch 502 
2025-03-22 10:11:06.180415: Current learning rate: 0.00534 
2025-03-22 10:11:49.275148: train_loss -0.8661 
2025-03-22 10:11:49.283685: val_loss -0.8769 
2025-03-22 10:11:49.293239: Pseudo dice [np.float64(0.9493), np.float64(0.9435), np.float64(0.931)] 
2025-03-22 10:11:49.301775: Epoch time: 43.11 s 
2025-03-22 10:11:50.329713:  
2025-03-22 10:11:50.339240: Epoch 503 
2025-03-22 10:11:50.344754: Current learning rate: 0.00533 
2025-03-22 10:12:34.701307: train_loss -0.8803 
2025-03-22 10:12:34.708819: val_loss -0.8304 
2025-03-22 10:12:34.713831: Pseudo dice [np.float64(0.945), np.float64(0.9117), np.float64(0.9068)] 
2025-03-22 10:12:34.717840: Epoch time: 44.37 s 
2025-03-22 10:12:35.488062:  
2025-03-22 10:12:35.495659: Epoch 504 
2025-03-22 10:12:35.500782: Current learning rate: 0.00532 
2025-03-22 10:13:18.536569: train_loss -0.8619 
2025-03-22 10:13:18.542585: val_loss -0.8602 
2025-03-22 10:13:18.549100: Pseudo dice [np.float64(0.9443), np.float64(0.9408), np.float64(0.9189)] 
2025-03-22 10:13:18.555115: Epoch time: 43.05 s 
2025-03-22 10:13:19.323387:  
2025-03-22 10:13:19.330071: Epoch 505 
2025-03-22 10:13:19.335212: Current learning rate: 0.00531 
2025-03-22 10:14:02.422288: train_loss -0.8635 
2025-03-22 10:14:02.428806: val_loss -0.8521 
2025-03-22 10:14:02.436328: Pseudo dice [np.float64(0.9514), np.float64(0.9353), np.float64(0.919)] 
2025-03-22 10:14:02.445633: Epoch time: 43.1 s 
2025-03-22 10:14:03.222062:  
2025-03-22 10:14:03.229148: Epoch 506 
2025-03-22 10:14:03.233745: Current learning rate: 0.0053 
2025-03-22 10:14:46.306803: train_loss -0.8767 
2025-03-22 10:14:46.316065: val_loss -0.8546 
2025-03-22 10:14:46.322218: Pseudo dice [np.float64(0.9511), np.float64(0.9385), np.float64(0.9151)] 
2025-03-22 10:14:46.327390: Epoch time: 43.09 s 
2025-03-22 10:14:47.100572:  
2025-03-22 10:14:47.108342: Epoch 507 
2025-03-22 10:14:47.114432: Current learning rate: 0.00529 
2025-03-22 10:15:32.944776: train_loss -0.8782 
2025-03-22 10:15:32.951560: val_loss -0.8769 
2025-03-22 10:15:32.955652: Pseudo dice [np.float64(0.9511), np.float64(0.9414), np.float64(0.927)] 
2025-03-22 10:15:32.961332: Epoch time: 45.84 s 
2025-03-22 10:15:33.733439:  
2025-03-22 10:15:33.740000: Epoch 508 
2025-03-22 10:15:33.746582: Current learning rate: 0.00528 
2025-03-22 10:16:17.184033: train_loss -0.869 
2025-03-22 10:16:17.191551: val_loss -0.8527 
2025-03-22 10:16:17.196562: Pseudo dice [np.float64(0.9449), np.float64(0.9389), np.float64(0.9252)] 
2025-03-22 10:16:17.200569: Epoch time: 43.45 s 
2025-03-22 10:16:17.965641:  
2025-03-22 10:16:17.972229: Epoch 509 
2025-03-22 10:16:17.977311: Current learning rate: 0.00527 
2025-03-22 10:17:03.644854: train_loss -0.8621 
2025-03-22 10:17:03.651371: val_loss -0.84 
2025-03-22 10:17:03.656382: Pseudo dice [np.float64(0.9448), np.float64(0.926), np.float64(0.9208)] 
2025-03-22 10:17:03.661394: Epoch time: 45.68 s 
2025-03-22 10:17:04.446850:  
2025-03-22 10:17:04.455003: Epoch 510 
2025-03-22 10:17:04.460065: Current learning rate: 0.00526 
2025-03-22 10:17:49.238181: train_loss -0.8568 
2025-03-22 10:17:49.245706: val_loss -0.8348 
2025-03-22 10:17:49.250720: Pseudo dice [np.float64(0.9458), np.float64(0.944), np.float64(0.9188)] 
2025-03-22 10:17:49.254230: Epoch time: 44.79 s 
2025-03-22 10:17:50.275946:  
2025-03-22 10:17:50.283465: Epoch 511 
2025-03-22 10:17:50.287483: Current learning rate: 0.00525 
2025-03-22 10:18:33.449669: train_loss -0.8709 
2025-03-22 10:18:33.456764: val_loss -0.8528 
2025-03-22 10:18:33.460789: Pseudo dice [np.float64(0.9537), np.float64(0.9433), np.float64(0.9241)] 
2025-03-22 10:18:33.464797: Epoch time: 43.17 s 
2025-03-22 10:18:34.240435:  
2025-03-22 10:18:34.246542: Epoch 512 
2025-03-22 10:18:34.252639: Current learning rate: 0.00524 
2025-03-22 10:19:17.556717: train_loss -0.8706 
2025-03-22 10:19:17.564239: val_loss -0.8285 
2025-03-22 10:19:17.571761: Pseudo dice [np.float64(0.9487), np.float64(0.9033), np.float64(0.9144)] 
2025-03-22 10:19:17.580456: Epoch time: 43.32 s 
2025-03-22 10:19:18.355888:  
2025-03-22 10:19:18.362414: Epoch 513 
2025-03-22 10:19:18.366422: Current learning rate: 0.00523 
2025-03-22 10:20:01.187307: train_loss -0.8678 
2025-03-22 10:20:01.194841: val_loss -0.8629 
2025-03-22 10:20:01.200864: Pseudo dice [np.float64(0.9431), np.float64(0.9321), np.float64(0.9152)] 
2025-03-22 10:20:01.206886: Epoch time: 42.83 s 
2025-03-22 10:20:01.959306:  
2025-03-22 10:20:01.967570: Epoch 514 
2025-03-22 10:20:01.973582: Current learning rate: 0.00522 
2025-03-22 10:20:45.011035: train_loss -0.8743 
2025-03-22 10:20:45.020558: val_loss -0.8542 
2025-03-22 10:20:45.028585: Pseudo dice [np.float64(0.947), np.float64(0.9303), np.float64(0.9197)] 
2025-03-22 10:20:45.036101: Epoch time: 43.05 s 
2025-03-22 10:20:45.817496:  
2025-03-22 10:20:45.824508: Epoch 515 
2025-03-22 10:20:45.830026: Current learning rate: 0.00521 
2025-03-22 10:21:28.807482: train_loss -0.873 
2025-03-22 10:21:28.816540: val_loss -0.8419 
2025-03-22 10:21:28.823558: Pseudo dice [np.float64(0.937), np.float64(0.9351), np.float64(0.9033)] 
2025-03-22 10:21:28.829074: Epoch time: 42.99 s 
2025-03-22 10:21:29.568596:  
2025-03-22 10:21:29.574609: Epoch 516 
2025-03-22 10:21:29.579620: Current learning rate: 0.0052 
2025-03-22 10:22:12.585924: train_loss -0.8651 
2025-03-22 10:22:12.593447: val_loss -0.8374 
2025-03-22 10:22:12.599466: Pseudo dice [np.float64(0.9435), np.float64(0.9265), np.float64(0.9229)] 
2025-03-22 10:22:12.604483: Epoch time: 43.02 s 
2025-03-22 10:22:13.365929:  
2025-03-22 10:22:13.373610: Epoch 517 
2025-03-22 10:22:13.378691: Current learning rate: 0.00519 
2025-03-22 10:22:56.610975: train_loss -0.8708 
2025-03-22 10:22:56.619497: val_loss -0.8173 
2025-03-22 10:22:56.625014: Pseudo dice [np.float64(0.9491), np.float64(0.9317), np.float64(0.9141)] 
2025-03-22 10:22:56.632035: Epoch time: 43.25 s 
2025-03-22 10:22:57.375493:  
2025-03-22 10:22:57.383566: Epoch 518 
2025-03-22 10:22:57.387607: Current learning rate: 0.00518 
2025-03-22 10:23:40.136163: train_loss -0.871 
2025-03-22 10:23:40.144758: val_loss -0.8761 
2025-03-22 10:23:40.151423: Pseudo dice [np.float64(0.9494), np.float64(0.95), np.float64(0.9281)] 
2025-03-22 10:23:40.157473: Epoch time: 42.76 s 
2025-03-22 10:23:41.198631:  
2025-03-22 10:23:41.205675: Epoch 519 
2025-03-22 10:23:41.209235: Current learning rate: 0.00518 
2025-03-22 10:24:24.224481: train_loss -0.8785 
2025-03-22 10:24:24.232004: val_loss -0.8508 
2025-03-22 10:24:24.238019: Pseudo dice [np.float64(0.9505), np.float64(0.9294), np.float64(0.914)] 
2025-03-22 10:24:24.243037: Epoch time: 43.03 s 
2025-03-22 10:24:25.003919:  
2025-03-22 10:24:25.010995: Epoch 520 
2025-03-22 10:24:25.014616: Current learning rate: 0.00517 
2025-03-22 10:25:07.770136: train_loss -0.8801 
2025-03-22 10:25:07.777772: val_loss -0.8525 
2025-03-22 10:25:07.783886: Pseudo dice [np.float64(0.944), np.float64(0.9199), np.float64(0.9077)] 
2025-03-22 10:25:07.791559: Epoch time: 42.77 s 
2025-03-22 10:25:08.544160:  
2025-03-22 10:25:08.550789: Epoch 521 
2025-03-22 10:25:08.555336: Current learning rate: 0.00516 
2025-03-22 10:25:51.509266: train_loss -0.8735 
2025-03-22 10:25:51.517369: val_loss -0.8536 
2025-03-22 10:25:51.523507: Pseudo dice [np.float64(0.9536), np.float64(0.9416), np.float64(0.9092)] 
2025-03-22 10:25:51.530579: Epoch time: 42.97 s 
2025-03-22 10:25:52.309286:  
2025-03-22 10:25:52.316978: Epoch 522 
2025-03-22 10:25:52.322018: Current learning rate: 0.00515 
2025-03-22 10:26:35.335310: train_loss -0.8765 
2025-03-22 10:26:35.343862: val_loss -0.8092 
2025-03-22 10:26:35.349451: Pseudo dice [np.float64(0.9491), np.float64(0.9082), np.float64(0.9008)] 
2025-03-22 10:26:35.356503: Epoch time: 43.03 s 
2025-03-22 10:26:36.135255:  
2025-03-22 10:26:36.141373: Epoch 523 
2025-03-22 10:26:36.145380: Current learning rate: 0.00514 
2025-03-22 10:27:19.115486: train_loss -0.8642 
2025-03-22 10:27:19.123001: val_loss -0.8755 
2025-03-22 10:27:19.128012: Pseudo dice [np.float64(0.9467), np.float64(0.9418), np.float64(0.9171)] 
2025-03-22 10:27:19.133023: Epoch time: 42.98 s 
2025-03-22 10:27:19.896304:  
2025-03-22 10:27:19.902842: Epoch 524 
2025-03-22 10:27:19.907899: Current learning rate: 0.00513 
2025-03-22 10:28:03.162458: train_loss -0.8838 
2025-03-22 10:28:03.170192: val_loss -0.8502 
2025-03-22 10:28:03.177837: Pseudo dice [np.float64(0.9439), np.float64(0.9443), np.float64(0.9106)] 
2025-03-22 10:28:03.185005: Epoch time: 43.27 s 
2025-03-22 10:28:03.942754:  
2025-03-22 10:28:03.949332: Epoch 525 
2025-03-22 10:28:03.951871: Current learning rate: 0.00512 
2025-03-22 10:28:46.837974: train_loss -0.8723 
2025-03-22 10:28:46.846066: val_loss -0.8826 
2025-03-22 10:28:46.851643: Pseudo dice [np.float64(0.9475), np.float64(0.9525), np.float64(0.9258)] 
2025-03-22 10:28:46.857704: Epoch time: 42.9 s 
2025-03-22 10:28:47.619426:  
2025-03-22 10:28:47.625054: Epoch 526 
2025-03-22 10:28:47.630654: Current learning rate: 0.00511 
2025-03-22 10:29:30.451039: train_loss -0.8725 
2025-03-22 10:29:30.458560: val_loss -0.8426 
2025-03-22 10:29:30.466125: Pseudo dice [np.float64(0.9466), np.float64(0.9207), np.float64(0.9057)] 
2025-03-22 10:29:30.472141: Epoch time: 42.83 s 
2025-03-22 10:29:31.235088:  
2025-03-22 10:29:31.241640: Epoch 527 
2025-03-22 10:29:31.246168: Current learning rate: 0.0051 
2025-03-22 10:30:14.195176: train_loss -0.846 
2025-03-22 10:30:14.202722: val_loss -0.872 
2025-03-22 10:30:14.209239: Pseudo dice [np.float64(0.9466), np.float64(0.9318), np.float64(0.912)] 
2025-03-22 10:30:14.215252: Epoch time: 42.96 s 
2025-03-22 10:30:15.213625:  
2025-03-22 10:30:15.221164: Epoch 528 
2025-03-22 10:30:15.225690: Current learning rate: 0.00509 
2025-03-22 10:30:57.980515: train_loss -0.8647 
2025-03-22 10:30:57.988037: val_loss -0.8334 
2025-03-22 10:30:57.994550: Pseudo dice [np.float64(0.9497), np.float64(0.9054), np.float64(0.9027)] 
2025-03-22 10:30:58.000562: Epoch time: 42.77 s 
2025-03-22 10:30:58.754566:  
2025-03-22 10:30:58.762858: Epoch 529 
2025-03-22 10:30:58.769091: Current learning rate: 0.00508 
2025-03-22 10:31:41.729517: train_loss -0.8633 
2025-03-22 10:31:41.737041: val_loss -0.8419 
2025-03-22 10:31:41.744561: Pseudo dice [np.float64(0.9413), np.float64(0.9161), np.float64(0.9108)] 
2025-03-22 10:31:41.749573: Epoch time: 42.98 s 
2025-03-22 10:31:42.522364:  
2025-03-22 10:31:42.528991: Epoch 530 
2025-03-22 10:31:42.532583: Current learning rate: 0.00507 
2025-03-22 10:32:25.612504: train_loss -0.8542 
2025-03-22 10:32:25.620616: val_loss -0.8457 
2025-03-22 10:32:25.627768: Pseudo dice [np.float64(0.9391), np.float64(0.9387), np.float64(0.9205)] 
2025-03-22 10:32:25.634481: Epoch time: 43.09 s 
2025-03-22 10:32:26.394898:  
2025-03-22 10:32:26.401915: Epoch 531 
2025-03-22 10:32:26.405928: Current learning rate: 0.00506 
2025-03-22 10:33:10.644193: train_loss -0.865 
2025-03-22 10:33:10.653216: val_loss -0.8107 
2025-03-22 10:33:10.658231: Pseudo dice [np.float64(0.9418), np.float64(0.9305), np.float64(0.9117)] 
2025-03-22 10:33:10.663246: Epoch time: 44.25 s 
2025-03-22 10:33:11.416934:  
2025-03-22 10:33:11.423514: Epoch 532 
2025-03-22 10:33:11.428571: Current learning rate: 0.00505 
2025-03-22 10:33:54.526667: train_loss -0.8537 
2025-03-22 10:33:54.535691: val_loss -0.8538 
2025-03-22 10:33:54.540704: Pseudo dice [np.float64(0.9458), np.float64(0.9169), np.float64(0.9109)] 
2025-03-22 10:33:54.545720: Epoch time: 43.11 s 
2025-03-22 10:33:55.321824:  
2025-03-22 10:33:55.329949: Epoch 533 
2025-03-22 10:33:55.334152: Current learning rate: 0.00504 
2025-03-22 10:34:38.311422: train_loss -0.8635 
2025-03-22 10:34:38.318937: val_loss -0.8791 
2025-03-22 10:34:38.322958: Pseudo dice [np.float64(0.9456), np.float64(0.9431), np.float64(0.9148)] 
2025-03-22 10:34:38.328974: Epoch time: 42.99 s 
2025-03-22 10:34:39.100370:  
2025-03-22 10:34:39.107410: Epoch 534 
2025-03-22 10:34:39.111416: Current learning rate: 0.00503 
2025-03-22 10:35:22.182137: train_loss -0.8631 
2025-03-22 10:35:22.190208: val_loss -0.863 
2025-03-22 10:35:22.195282: Pseudo dice [np.float64(0.946), np.float64(0.9421), np.float64(0.9208)] 
2025-03-22 10:35:22.200338: Epoch time: 43.08 s 
2025-03-22 10:35:22.960867:  
2025-03-22 10:35:22.967890: Epoch 535 
2025-03-22 10:35:22.972901: Current learning rate: 0.00502 
2025-03-22 10:36:05.829893: train_loss -0.8726 
2025-03-22 10:36:05.837413: val_loss -0.866 
2025-03-22 10:36:05.841428: Pseudo dice [np.float64(0.9482), np.float64(0.944), np.float64(0.9262)] 
2025-03-22 10:36:05.845436: Epoch time: 42.87 s 
2025-03-22 10:36:06.907327:  
2025-03-22 10:36:06.913915: Epoch 536 
2025-03-22 10:36:06.918602: Current learning rate: 0.00501 
2025-03-22 10:36:49.883057: train_loss -0.8698 
2025-03-22 10:36:49.889111: val_loss -0.8263 
2025-03-22 10:36:49.894148: Pseudo dice [np.float64(0.9541), np.float64(0.9292), np.float64(0.9039)] 
2025-03-22 10:36:49.900244: Epoch time: 42.98 s 
2025-03-22 10:36:50.684368:  
2025-03-22 10:36:50.690479: Epoch 537 
2025-03-22 10:36:50.695523: Current learning rate: 0.005 
2025-03-22 10:37:33.559016: train_loss -0.8779 
2025-03-22 10:37:33.566533: val_loss -0.8625 
2025-03-22 10:37:33.574059: Pseudo dice [np.float64(0.9473), np.float64(0.9349), np.float64(0.9251)] 
2025-03-22 10:37:33.580071: Epoch time: 42.88 s 
2025-03-22 10:37:34.345897:  
2025-03-22 10:37:34.354018: Epoch 538 
2025-03-22 10:37:34.360217: Current learning rate: 0.00499 
2025-03-22 10:38:17.286180: train_loss -0.8658 
2025-03-22 10:38:17.292745: val_loss -0.8482 
2025-03-22 10:38:17.297823: Pseudo dice [np.float64(0.9426), np.float64(0.9362), np.float64(0.9157)] 
2025-03-22 10:38:17.302033: Epoch time: 42.94 s 
2025-03-22 10:38:18.043172:  
2025-03-22 10:38:18.049786: Epoch 539 
2025-03-22 10:38:18.054297: Current learning rate: 0.00498 
2025-03-22 10:39:01.134999: train_loss -0.8755 
2025-03-22 10:39:01.144528: val_loss -0.8639 
2025-03-22 10:39:01.152554: Pseudo dice [np.float64(0.9555), np.float64(0.9543), np.float64(0.9259)] 
2025-03-22 10:39:01.157565: Epoch time: 43.09 s 
2025-03-22 10:39:01.920105:  
2025-03-22 10:39:01.926682: Epoch 540 
2025-03-22 10:39:01.931217: Current learning rate: 0.00497 
2025-03-22 10:39:46.483001: train_loss -0.87 
2025-03-22 10:39:46.492027: val_loss -0.8571 
2025-03-22 10:39:46.499080: Pseudo dice [np.float64(0.9491), np.float64(0.9188), np.float64(0.918)] 
2025-03-22 10:39:46.505601: Epoch time: 44.56 s 
2025-03-22 10:39:47.271161:  
2025-03-22 10:39:47.278726: Epoch 541 
2025-03-22 10:39:47.285293: Current learning rate: 0.00496 
2025-03-22 10:40:30.249054: train_loss -0.8739 
2025-03-22 10:40:30.256572: val_loss -0.8707 
2025-03-22 10:40:30.262109: Pseudo dice [np.float64(0.9536), np.float64(0.9414), np.float64(0.9147)] 
2025-03-22 10:40:30.268124: Epoch time: 42.98 s 
2025-03-22 10:40:31.013353:  
2025-03-22 10:40:31.020370: Epoch 542 
2025-03-22 10:40:31.025884: Current learning rate: 0.00495 
2025-03-22 10:41:13.857013: train_loss -0.8656 
2025-03-22 10:41:13.864534: val_loss -0.8515 
2025-03-22 10:41:13.870551: Pseudo dice [np.float64(0.946), np.float64(0.9465), np.float64(0.9225)] 
2025-03-22 10:41:13.875587: Epoch time: 42.85 s 
2025-03-22 10:41:14.630174:  
2025-03-22 10:41:14.636695: Epoch 543 
2025-03-22 10:41:14.641712: Current learning rate: 0.00494 
2025-03-22 10:41:57.486506: train_loss -0.8593 
2025-03-22 10:41:57.493539: val_loss -0.8504 
2025-03-22 10:41:57.499552: Pseudo dice [np.float64(0.9482), np.float64(0.9455), np.float64(0.9291)] 
2025-03-22 10:41:57.504564: Epoch time: 42.86 s 
2025-03-22 10:41:58.550655:  
2025-03-22 10:41:58.556686: Epoch 544 
2025-03-22 10:41:58.560735: Current learning rate: 0.00493 
2025-03-22 10:42:41.476612: train_loss -0.8651 
2025-03-22 10:42:41.482793: val_loss -0.8522 
2025-03-22 10:42:41.490930: Pseudo dice [np.float64(0.9466), np.float64(0.9455), np.float64(0.922)] 
2025-03-22 10:42:41.497448: Epoch time: 42.93 s 
2025-03-22 10:42:42.252854:  
2025-03-22 10:42:42.258992: Epoch 545 
2025-03-22 10:42:42.264005: Current learning rate: 0.00492 
2025-03-22 10:43:25.380700: train_loss -0.8542 
2025-03-22 10:43:25.388223: val_loss -0.8328 
2025-03-22 10:43:25.396814: Pseudo dice [np.float64(0.95), np.float64(0.9498), np.float64(0.925)] 
2025-03-22 10:43:25.403328: Epoch time: 43.13 s 
2025-03-22 10:43:26.187523:  
2025-03-22 10:43:26.193087: Epoch 546 
2025-03-22 10:43:26.197635: Current learning rate: 0.00491 
2025-03-22 10:44:08.961428: train_loss -0.866 
2025-03-22 10:44:08.970073: val_loss -0.8707 
2025-03-22 10:44:08.977677: Pseudo dice [np.float64(0.9444), np.float64(0.9381), np.float64(0.9118)] 
2025-03-22 10:44:08.985347: Epoch time: 42.77 s 
2025-03-22 10:44:09.733666:  
2025-03-22 10:44:09.740279: Epoch 547 
2025-03-22 10:44:09.745330: Current learning rate: 0.0049 
2025-03-22 10:44:52.712191: train_loss -0.8689 
2025-03-22 10:44:52.721212: val_loss -0.8487 
2025-03-22 10:44:52.726761: Pseudo dice [np.float64(0.9474), np.float64(0.9351), np.float64(0.9158)] 
2025-03-22 10:44:52.730802: Epoch time: 42.98 s 
2025-03-22 10:44:53.489266:  
2025-03-22 10:44:53.495812: Epoch 548 
2025-03-22 10:44:53.499382: Current learning rate: 0.00489 
2025-03-22 10:45:36.468897: train_loss -0.8814 
2025-03-22 10:45:36.477417: val_loss -0.8705 
2025-03-22 10:45:36.481426: Pseudo dice [np.float64(0.9482), np.float64(0.9492), np.float64(0.9216)] 
2025-03-22 10:45:36.486441: Epoch time: 42.98 s 
2025-03-22 10:45:37.267747:  
2025-03-22 10:45:37.276866: Epoch 549 
2025-03-22 10:45:37.282443: Current learning rate: 0.00488 
2025-03-22 10:46:21.743061: train_loss -0.8761 
2025-03-22 10:46:21.750671: val_loss -0.8592 
2025-03-22 10:46:21.759762: Pseudo dice [np.float64(0.9538), np.float64(0.9197), np.float64(0.9158)] 
2025-03-22 10:46:21.765822: Epoch time: 44.48 s 
2025-03-22 10:46:22.637768:  
2025-03-22 10:46:22.644292: Epoch 550 
2025-03-22 10:46:22.650813: Current learning rate: 0.00487 
2025-03-22 10:47:05.708717: train_loss -0.8709 
2025-03-22 10:47:05.717252: val_loss -0.8627 
2025-03-22 10:47:05.723775: Pseudo dice [np.float64(0.9569), np.float64(0.9414), np.float64(0.9194)] 
2025-03-22 10:47:05.729795: Epoch time: 43.07 s 
2025-03-22 10:47:06.493088:  
2025-03-22 10:47:06.499691: Epoch 551 
2025-03-22 10:47:06.504763: Current learning rate: 0.00486 
2025-03-22 10:47:49.431966: train_loss -0.8599 
2025-03-22 10:47:49.440485: val_loss -0.8668 
2025-03-22 10:47:49.445999: Pseudo dice [np.float64(0.9555), np.float64(0.9398), np.float64(0.9175)] 
2025-03-22 10:47:49.453517: Epoch time: 42.94 s 
2025-03-22 10:47:50.211714:  
2025-03-22 10:47:50.218416: Epoch 552 
2025-03-22 10:47:50.222648: Current learning rate: 0.00485 
2025-03-22 10:48:33.219425: train_loss -0.8678 
2025-03-22 10:48:33.226939: val_loss -0.8688 
2025-03-22 10:48:33.233959: Pseudo dice [np.float64(0.9541), np.float64(0.947), np.float64(0.9228)] 
2025-03-22 10:48:33.241479: Epoch time: 43.01 s 
2025-03-22 10:48:33.249507: Yayy! New best EMA pseudo Dice: 0.9359 
2025-03-22 10:48:34.314298:  
2025-03-22 10:48:34.321900: Epoch 553 
2025-03-22 10:48:34.325820: Current learning rate: 0.00484 
2025-03-22 10:49:17.366566: train_loss -0.8758 
2025-03-22 10:49:17.374592: val_loss -0.8513 
2025-03-22 10:49:17.381610: Pseudo dice [np.float64(0.9456), np.float64(0.9254), np.float64(0.911)] 
2025-03-22 10:49:17.387128: Epoch time: 43.05 s 
2025-03-22 10:49:18.147800:  
2025-03-22 10:49:18.154323: Epoch 554 
2025-03-22 10:49:18.159335: Current learning rate: 0.00484 
2025-03-22 10:50:01.296868: train_loss -0.8626 
2025-03-22 10:50:01.304389: val_loss -0.8671 
2025-03-22 10:50:01.309907: Pseudo dice [np.float64(0.947), np.float64(0.9499), np.float64(0.9182)] 
2025-03-22 10:50:01.314461: Epoch time: 43.15 s 
2025-03-22 10:50:02.073003:  
2025-03-22 10:50:02.079624: Epoch 555 
2025-03-22 10:50:02.084176: Current learning rate: 0.00483 
2025-03-22 10:50:45.212583: train_loss -0.8779 
2025-03-22 10:50:45.221226: val_loss -0.8472 
2025-03-22 10:50:45.228404: Pseudo dice [np.float64(0.9485), np.float64(0.9322), np.float64(0.9219)] 
2025-03-22 10:50:45.237119: Epoch time: 43.14 s 
2025-03-22 10:50:45.961280:  
2025-03-22 10:50:45.967800: Epoch 556 
2025-03-22 10:50:45.971808: Current learning rate: 0.00482 
2025-03-22 10:51:28.899731: train_loss -0.8742 
2025-03-22 10:51:28.907247: val_loss -0.8539 
2025-03-22 10:51:28.913260: Pseudo dice [np.float64(0.9469), np.float64(0.9426), np.float64(0.9249)] 
2025-03-22 10:51:28.919273: Epoch time: 42.94 s 
2025-03-22 10:51:29.682073:  
2025-03-22 10:51:29.689687: Epoch 557 
2025-03-22 10:51:29.692740: Current learning rate: 0.00481 
2025-03-22 10:52:12.725748: train_loss -0.8733 
2025-03-22 10:52:12.734275: val_loss -0.8551 
2025-03-22 10:52:12.740789: Pseudo dice [np.float64(0.9452), np.float64(0.9323), np.float64(0.9009)] 
2025-03-22 10:52:12.746804: Epoch time: 43.04 s 
2025-03-22 10:52:13.495116:  
2025-03-22 10:52:13.501719: Epoch 558 
2025-03-22 10:52:13.506861: Current learning rate: 0.0048 
2025-03-22 10:52:57.921009: train_loss -0.8766 
2025-03-22 10:52:57.930034: val_loss -0.8475 
2025-03-22 10:52:57.937554: Pseudo dice [np.float64(0.9513), np.float64(0.9436), np.float64(0.9168)] 
2025-03-22 10:52:57.942566: Epoch time: 44.43 s 
2025-03-22 10:52:58.703702:  
2025-03-22 10:52:58.711290: Epoch 559 
2025-03-22 10:52:58.716433: Current learning rate: 0.00479 
2025-03-22 10:53:41.907826: train_loss -0.8698 
2025-03-22 10:53:41.918867: val_loss -0.8584 
2025-03-22 10:53:41.925925: Pseudo dice [np.float64(0.9485), np.float64(0.9335), np.float64(0.9161)] 
2025-03-22 10:53:41.933044: Epoch time: 43.2 s 
2025-03-22 10:53:42.700761:  
2025-03-22 10:53:42.707344: Epoch 560 
2025-03-22 10:53:42.711376: Current learning rate: 0.00478 
2025-03-22 10:54:25.553261: train_loss -0.8681 
2025-03-22 10:54:25.559362: val_loss -0.844 
2025-03-22 10:54:25.564470: Pseudo dice [np.float64(0.9474), np.float64(0.9385), np.float64(0.9242)] 
2025-03-22 10:54:25.567001: Epoch time: 42.85 s 
2025-03-22 10:54:26.576129:  
2025-03-22 10:54:26.583674: Epoch 561 
2025-03-22 10:54:26.586695: Current learning rate: 0.00477 
2025-03-22 10:55:09.495368: train_loss -0.8577 
2025-03-22 10:55:09.503889: val_loss -0.8645 
2025-03-22 10:55:09.509407: Pseudo dice [np.float64(0.9434), np.float64(0.9375), np.float64(0.92)] 
2025-03-22 10:55:09.514419: Epoch time: 42.92 s 
2025-03-22 10:55:10.306767:  
2025-03-22 10:55:10.315418: Epoch 562 
2025-03-22 10:55:10.319935: Current learning rate: 0.00476 
2025-03-22 10:55:53.406419: train_loss -0.8689 
2025-03-22 10:55:53.414018: val_loss -0.8437 
2025-03-22 10:55:53.419658: Pseudo dice [np.float64(0.9452), np.float64(0.9352), np.float64(0.9081)] 
2025-03-22 10:55:53.425326: Epoch time: 43.1 s 
2025-03-22 10:55:54.166434:  
2025-03-22 10:55:54.171995: Epoch 563 
2025-03-22 10:55:54.177598: Current learning rate: 0.00475 
2025-03-22 10:56:37.103955: train_loss -0.874 
2025-03-22 10:56:37.112498: val_loss -0.8328 
2025-03-22 10:56:37.118022: Pseudo dice [np.float64(0.9454), np.float64(0.911), np.float64(0.9231)] 
2025-03-22 10:56:37.124040: Epoch time: 42.94 s 
2025-03-22 10:56:37.910865:  
2025-03-22 10:56:37.917513: Epoch 564 
2025-03-22 10:56:37.922604: Current learning rate: 0.00474 
2025-03-22 10:57:20.704464: train_loss -0.8686 
2025-03-22 10:57:20.711984: val_loss -0.8454 
2025-03-22 10:57:20.717996: Pseudo dice [np.float64(0.9409), np.float64(0.9331), np.float64(0.922)] 
2025-03-22 10:57:20.723514: Epoch time: 42.79 s 
2025-03-22 10:57:21.492385:  
2025-03-22 10:57:21.499956: Epoch 565 
2025-03-22 10:57:21.505522: Current learning rate: 0.00473 
2025-03-22 10:58:04.589679: train_loss -0.8671 
2025-03-22 10:58:04.597195: val_loss -0.8654 
2025-03-22 10:58:04.604717: Pseudo dice [np.float64(0.9462), np.float64(0.9336), np.float64(0.9128)] 
2025-03-22 10:58:04.613247: Epoch time: 43.1 s 
2025-03-22 10:58:05.393683:  
2025-03-22 10:58:05.399201: Epoch 566 
2025-03-22 10:58:05.403713: Current learning rate: 0.00472 
2025-03-22 10:58:48.329429: train_loss -0.8699 
2025-03-22 10:58:48.338454: val_loss -0.8427 
2025-03-22 10:58:48.346978: Pseudo dice [np.float64(0.9549), np.float64(0.9281), np.float64(0.9238)] 
2025-03-22 10:58:48.354501: Epoch time: 42.94 s 
2025-03-22 10:58:49.103345:  
2025-03-22 10:58:49.109866: Epoch 567 
2025-03-22 10:58:49.113373: Current learning rate: 0.00471 
2025-03-22 10:59:33.867550: train_loss -0.8725 
2025-03-22 10:59:33.875070: val_loss -0.8345 
2025-03-22 10:59:33.881086: Pseudo dice [np.float64(0.941), np.float64(0.9445), np.float64(0.9155)] 
2025-03-22 10:59:33.887604: Epoch time: 44.77 s 
2025-03-22 10:59:34.658075:  
2025-03-22 10:59:34.664707: Epoch 568 
2025-03-22 10:59:34.668719: Current learning rate: 0.0047 
2025-03-22 11:00:17.791212: train_loss -0.8674 
2025-03-22 11:00:17.799737: val_loss -0.8428 
2025-03-22 11:00:17.805749: Pseudo dice [np.float64(0.9393), np.float64(0.943), np.float64(0.92)] 
2025-03-22 11:00:17.810764: Epoch time: 43.13 s 
2025-03-22 11:00:18.835008:  
2025-03-22 11:00:18.842027: Epoch 569 
2025-03-22 11:00:18.845038: Current learning rate: 0.00469 
2025-03-22 11:01:01.841825: train_loss -0.8733 
2025-03-22 11:01:01.848344: val_loss -0.8548 
2025-03-22 11:01:01.854358: Pseudo dice [np.float64(0.9464), np.float64(0.9336), np.float64(0.92)] 
2025-03-22 11:01:01.859877: Epoch time: 43.01 s 
2025-03-22 11:01:02.630842:  
2025-03-22 11:01:02.638997: Epoch 570 
2025-03-22 11:01:02.643052: Current learning rate: 0.00468 
2025-03-22 11:01:45.700426: train_loss -0.8796 
2025-03-22 11:01:45.708545: val_loss -0.8519 
2025-03-22 11:01:45.715645: Pseudo dice [np.float64(0.9463), np.float64(0.9395), np.float64(0.9268)] 
2025-03-22 11:01:45.721601: Epoch time: 43.07 s 
2025-03-22 11:01:46.468082:  
2025-03-22 11:01:46.473604: Epoch 571 
2025-03-22 11:01:46.477122: Current learning rate: 0.00467 
2025-03-22 11:02:29.611876: train_loss -0.8755 
2025-03-22 11:02:29.620396: val_loss -0.8458 
2025-03-22 11:02:29.625913: Pseudo dice [np.float64(0.9519), np.float64(0.9381), np.float64(0.9299)] 
2025-03-22 11:02:29.630927: Epoch time: 43.14 s 
2025-03-22 11:02:30.401425:  
2025-03-22 11:02:30.408998: Epoch 572 
2025-03-22 11:02:30.413775: Current learning rate: 0.00466 
2025-03-22 11:03:13.276788: train_loss -0.8665 
2025-03-22 11:03:13.284308: val_loss -0.8796 
2025-03-22 11:03:13.290828: Pseudo dice [np.float64(0.9506), np.float64(0.945), np.float64(0.9265)] 
2025-03-22 11:03:13.297340: Epoch time: 42.88 s 
2025-03-22 11:03:14.067660:  
2025-03-22 11:03:14.075239: Epoch 573 
2025-03-22 11:03:14.080864: Current learning rate: 0.00465 
2025-03-22 11:03:56.932582: train_loss -0.8856 
2025-03-22 11:03:56.940106: val_loss -0.8417 
2025-03-22 11:03:56.946623: Pseudo dice [np.float64(0.9488), np.float64(0.9282), np.float64(0.9122)] 
2025-03-22 11:03:56.954146: Epoch time: 42.86 s 
2025-03-22 11:03:57.724162:  
2025-03-22 11:03:57.730684: Epoch 574 
2025-03-22 11:03:57.734694: Current learning rate: 0.00464 
2025-03-22 11:04:40.358640: train_loss -0.8827 
2025-03-22 11:04:40.365162: val_loss -0.8579 
2025-03-22 11:04:40.370184: Pseudo dice [np.float64(0.9488), np.float64(0.947), np.float64(0.9197)] 
2025-03-22 11:04:40.374194: Epoch time: 42.64 s 
2025-03-22 11:04:41.124626:  
2025-03-22 11:04:41.129671: Epoch 575 
2025-03-22 11:04:41.133524: Current learning rate: 0.00463 
2025-03-22 11:05:24.180623: train_loss -0.8772 
2025-03-22 11:05:24.189650: val_loss -0.8762 
2025-03-22 11:05:24.196164: Pseudo dice [np.float64(0.9512), np.float64(0.939), np.float64(0.9292)] 
2025-03-22 11:05:24.202192: Epoch time: 43.06 s 
2025-03-22 11:05:24.989693:  
2025-03-22 11:05:24.995868: Epoch 576 
2025-03-22 11:05:24.999442: Current learning rate: 0.00462 
2025-03-22 11:06:10.066058: train_loss -0.8677 
2025-03-22 11:06:10.076686: val_loss -0.8363 
2025-03-22 11:06:10.083198: Pseudo dice [np.float64(0.9438), np.float64(0.9283), np.float64(0.9173)] 
2025-03-22 11:06:10.089211: Epoch time: 45.08 s 
2025-03-22 11:06:10.883258:  
2025-03-22 11:06:10.889287: Epoch 577 
2025-03-22 11:06:10.893293: Current learning rate: 0.00461 
2025-03-22 11:06:54.200996: train_loss -0.8793 
2025-03-22 11:06:54.208516: val_loss -0.8511 
2025-03-22 11:06:54.212024: Pseudo dice [np.float64(0.9489), np.float64(0.9373), np.float64(0.9151)] 
2025-03-22 11:06:54.216037: Epoch time: 43.32 s 
2025-03-22 11:06:55.000956:  
2025-03-22 11:06:55.006973: Epoch 578 
2025-03-22 11:06:55.011986: Current learning rate: 0.0046 
2025-03-22 11:07:37.985989: train_loss -0.87 
2025-03-22 11:07:37.993510: val_loss -0.8676 
2025-03-22 11:07:38.001029: Pseudo dice [np.float64(0.9478), np.float64(0.9511), np.float64(0.9227)] 
2025-03-22 11:07:38.007044: Epoch time: 42.99 s 
2025-03-22 11:07:38.773643:  
2025-03-22 11:07:38.780714: Epoch 579 
2025-03-22 11:07:38.786841: Current learning rate: 0.00459 
2025-03-22 11:08:21.780327: train_loss -0.8775 
2025-03-22 11:08:21.789393: val_loss -0.8559 
2025-03-22 11:08:21.794406: Pseudo dice [np.float64(0.9525), np.float64(0.9324), np.float64(0.9097)] 
2025-03-22 11:08:21.802931: Epoch time: 43.01 s 
2025-03-22 11:08:22.572461:  
2025-03-22 11:08:22.578979: Epoch 580 
2025-03-22 11:08:22.585016: Current learning rate: 0.00458 
2025-03-22 11:09:05.631003: train_loss -0.8701 
2025-03-22 11:09:05.639162: val_loss -0.8509 
2025-03-22 11:09:05.646305: Pseudo dice [np.float64(0.9502), np.float64(0.9365), np.float64(0.9261)] 
2025-03-22 11:09:05.652499: Epoch time: 43.06 s 
2025-03-22 11:09:06.423401:  
2025-03-22 11:09:06.430547: Epoch 581 
2025-03-22 11:09:06.434557: Current learning rate: 0.00457 
2025-03-22 11:09:49.578320: train_loss -0.8733 
2025-03-22 11:09:49.586481: val_loss -0.8728 
2025-03-22 11:09:49.595506: Pseudo dice [np.float64(0.9527), np.float64(0.9453), np.float64(0.9204)] 
2025-03-22 11:09:49.602525: Epoch time: 43.15 s 
2025-03-22 11:09:50.384574:  
2025-03-22 11:09:50.390601: Epoch 582 
2025-03-22 11:09:50.394611: Current learning rate: 0.00456 
2025-03-22 11:10:33.202853: train_loss -0.8791 
2025-03-22 11:10:33.211394: val_loss -0.8683 
2025-03-22 11:10:33.217921: Pseudo dice [np.float64(0.9436), np.float64(0.9375), np.float64(0.9162)] 
2025-03-22 11:10:33.225440: Epoch time: 42.82 s 
2025-03-22 11:10:33.992559:  
2025-03-22 11:10:33.998800: Epoch 583 
2025-03-22 11:10:34.002323: Current learning rate: 0.00455 
2025-03-22 11:11:16.799674: train_loss -0.8775 
2025-03-22 11:11:16.809216: val_loss -0.8516 
2025-03-22 11:11:16.816742: Pseudo dice [np.float64(0.951), np.float64(0.9312), np.float64(0.9144)] 
2025-03-22 11:11:16.823266: Epoch time: 42.81 s 
2025-03-22 11:11:17.585911:  
2025-03-22 11:11:17.592208: Epoch 584 
2025-03-22 11:11:17.596313: Current learning rate: 0.00454 
2025-03-22 11:12:00.249564: train_loss -0.8746 
2025-03-22 11:12:00.258591: val_loss -0.8698 
2025-03-22 11:12:00.263101: Pseudo dice [np.float64(0.951), np.float64(0.931), np.float64(0.9249)] 
2025-03-22 11:12:00.266226: Epoch time: 42.66 s 
2025-03-22 11:12:01.045973:  
2025-03-22 11:12:01.052085: Epoch 585 
2025-03-22 11:12:01.057244: Current learning rate: 0.00453 
2025-03-22 11:12:45.496991: train_loss -0.8774 
2025-03-22 11:12:45.504515: val_loss -0.8634 
2025-03-22 11:12:45.509523: Pseudo dice [np.float64(0.9483), np.float64(0.9279), np.float64(0.9243)] 
2025-03-22 11:12:45.514539: Epoch time: 44.45 s 
2025-03-22 11:12:46.570266:  
2025-03-22 11:12:46.577328: Epoch 586 
2025-03-22 11:12:46.581075: Current learning rate: 0.00452 
2025-03-22 11:13:29.738088: train_loss -0.872 
2025-03-22 11:13:29.745619: val_loss -0.8545 
2025-03-22 11:13:29.753139: Pseudo dice [np.float64(0.9527), np.float64(0.9423), np.float64(0.9286)] 
2025-03-22 11:13:29.759654: Epoch time: 43.17 s 
2025-03-22 11:13:30.528848:  
2025-03-22 11:13:30.535431: Epoch 587 
2025-03-22 11:13:30.538503: Current learning rate: 0.00451 
2025-03-22 11:14:13.422899: train_loss -0.8688 
2025-03-22 11:14:13.430433: val_loss -0.8337 
2025-03-22 11:14:13.435445: Pseudo dice [np.float64(0.9367), np.float64(0.9169), np.float64(0.9069)] 
2025-03-22 11:14:13.439464: Epoch time: 42.9 s 
2025-03-22 11:14:14.194209:  
2025-03-22 11:14:14.200871: Epoch 588 
2025-03-22 11:14:14.205930: Current learning rate: 0.0045 
2025-03-22 11:14:57.271664: train_loss -0.8676 
2025-03-22 11:14:57.279197: val_loss -0.8482 
2025-03-22 11:14:57.285712: Pseudo dice [np.float64(0.9528), np.float64(0.9407), np.float64(0.9192)] 
2025-03-22 11:14:57.291727: Epoch time: 43.08 s 
2025-03-22 11:14:58.059428:  
2025-03-22 11:14:58.067514: Epoch 589 
2025-03-22 11:14:58.072688: Current learning rate: 0.00449 
2025-03-22 11:15:41.019490: train_loss -0.8659 
2025-03-22 11:15:41.027101: val_loss -0.8447 
2025-03-22 11:15:41.031737: Pseudo dice [np.float64(0.953), np.float64(0.9385), np.float64(0.9304)] 
2025-03-22 11:15:41.035802: Epoch time: 42.96 s 
2025-03-22 11:15:41.833688:  
2025-03-22 11:15:41.840852: Epoch 590 
2025-03-22 11:15:41.844982: Current learning rate: 0.00448 
2025-03-22 11:16:24.746544: train_loss -0.8787 
2025-03-22 11:16:24.753434: val_loss -0.8613 
2025-03-22 11:16:24.759458: Pseudo dice [np.float64(0.9528), np.float64(0.9434), np.float64(0.9182)] 
2025-03-22 11:16:24.765546: Epoch time: 42.91 s 
2025-03-22 11:16:25.564664:  
2025-03-22 11:16:25.572344: Epoch 591 
2025-03-22 11:16:25.577425: Current learning rate: 0.00447 
2025-03-22 11:17:08.542662: train_loss -0.8741 
2025-03-22 11:17:08.550696: val_loss -0.8599 
2025-03-22 11:17:08.559225: Pseudo dice [np.float64(0.9503), np.float64(0.9484), np.float64(0.9244)] 
2025-03-22 11:17:08.565748: Epoch time: 42.98 s 
2025-03-22 11:17:09.333984:  
2025-03-22 11:17:09.341516: Epoch 592 
2025-03-22 11:17:09.347533: Current learning rate: 0.00446 
2025-03-22 11:17:52.290697: train_loss -0.8695 
2025-03-22 11:17:52.296724: val_loss -0.8594 
2025-03-22 11:17:52.302737: Pseudo dice [np.float64(0.9568), np.float64(0.9225), np.float64(0.9143)] 
2025-03-22 11:17:52.308261: Epoch time: 42.96 s 
2025-03-22 11:17:53.086232:  
2025-03-22 11:17:53.093289: Epoch 593 
2025-03-22 11:17:53.097305: Current learning rate: 0.00445 
2025-03-22 11:18:36.083461: train_loss -0.8776 
2025-03-22 11:18:36.089999: val_loss -0.8588 
2025-03-22 11:18:36.095519: Pseudo dice [np.float64(0.9583), np.float64(0.9518), np.float64(0.9262)] 
2025-03-22 11:18:36.099070: Epoch time: 43.0 s 
2025-03-22 11:18:36.105112: Yayy! New best EMA pseudo Dice: 0.9364 
2025-03-22 11:18:37.187050:  
2025-03-22 11:18:37.193596: Epoch 594 
2025-03-22 11:18:37.197144: Current learning rate: 0.00444 
2025-03-22 11:19:21.934199: train_loss -0.8647 
2025-03-22 11:19:21.941268: val_loss -0.8502 
2025-03-22 11:19:21.947334: Pseudo dice [np.float64(0.9466), np.float64(0.9278), np.float64(0.9165)] 
2025-03-22 11:19:21.953899: Epoch time: 44.75 s 
2025-03-22 11:19:22.729876:  
2025-03-22 11:19:22.735411: Epoch 595 
2025-03-22 11:19:22.741479: Current learning rate: 0.00443 
2025-03-22 11:20:05.782149: train_loss -0.8628 
2025-03-22 11:20:05.789167: val_loss -0.8626 
2025-03-22 11:20:05.795690: Pseudo dice [np.float64(0.9554), np.float64(0.9456), np.float64(0.9306)] 
2025-03-22 11:20:05.802208: Epoch time: 43.05 s 
2025-03-22 11:20:05.807224: Yayy! New best EMA pseudo Dice: 0.9366 
2025-03-22 11:20:06.699650:  
2025-03-22 11:20:06.707227: Epoch 596 
2025-03-22 11:20:06.713390: Current learning rate: 0.00442 
2025-03-22 11:20:49.725518: train_loss -0.8611 
2025-03-22 11:20:49.733608: val_loss -0.852 
2025-03-22 11:20:49.740677: Pseudo dice [np.float64(0.9453), np.float64(0.9371), np.float64(0.9145)] 
2025-03-22 11:20:49.748044: Epoch time: 43.03 s 
2025-03-22 11:20:50.509687:  
2025-03-22 11:20:50.516712: Epoch 597 
2025-03-22 11:20:50.521727: Current learning rate: 0.00441 
2025-03-22 11:21:33.294871: train_loss -0.8767 
2025-03-22 11:21:33.302415: val_loss -0.8372 
2025-03-22 11:21:33.307439: Pseudo dice [np.float64(0.944), np.float64(0.9401), np.float64(0.9165)] 
2025-03-22 11:21:33.312888: Epoch time: 42.79 s 
2025-03-22 11:21:34.099321:  
2025-03-22 11:21:34.105431: Epoch 598 
2025-03-22 11:21:34.110451: Current learning rate: 0.0044 
2025-03-22 11:22:17.117482: train_loss -0.8745 
2025-03-22 11:22:17.127015: val_loss -0.8468 
2025-03-22 11:22:17.135055: Pseudo dice [np.float64(0.957), np.float64(0.9371), np.float64(0.9172)] 
2025-03-22 11:22:17.141081: Epoch time: 43.02 s 
2025-03-22 11:22:17.921259:  
2025-03-22 11:22:17.926833: Epoch 599 
2025-03-22 11:22:17.931915: Current learning rate: 0.00439 
2025-03-22 11:23:00.895119: train_loss -0.8645 
2025-03-22 11:23:00.903660: val_loss -0.8706 
2025-03-22 11:23:00.911180: Pseudo dice [np.float64(0.9542), np.float64(0.9471), np.float64(0.9166)] 
2025-03-22 11:23:00.917699: Epoch time: 42.97 s 
2025-03-22 11:23:01.770952:  
2025-03-22 11:23:01.776977: Epoch 600 
2025-03-22 11:23:01.781990: Current learning rate: 0.00438 
2025-03-22 11:23:44.730096: train_loss -0.8758 
2025-03-22 11:23:44.737292: val_loss -0.8608 
2025-03-22 11:23:44.742315: Pseudo dice [np.float64(0.9479), np.float64(0.9298), np.float64(0.9237)] 
2025-03-22 11:23:44.746333: Epoch time: 42.96 s 
2025-03-22 11:23:45.502651:  
2025-03-22 11:23:45.509728: Epoch 601 
2025-03-22 11:23:45.515892: Current learning rate: 0.00437 
2025-03-22 11:24:28.606182: train_loss -0.8756 
2025-03-22 11:24:28.615223: val_loss -0.8643 
2025-03-22 11:24:28.621742: Pseudo dice [np.float64(0.9481), np.float64(0.9306), np.float64(0.9189)] 
2025-03-22 11:24:28.627758: Epoch time: 43.1 s 
2025-03-22 11:24:29.632080:  
2025-03-22 11:24:29.638682: Epoch 602 
2025-03-22 11:24:29.641737: Current learning rate: 0.00436 
2025-03-22 11:25:12.765303: train_loss -0.858 
2025-03-22 11:25:12.773839: val_loss -0.8298 
2025-03-22 11:25:12.780368: Pseudo dice [np.float64(0.9384), np.float64(0.9304), np.float64(0.9022)] 
2025-03-22 11:25:12.787388: Epoch time: 43.13 s 
2025-03-22 11:25:13.545922:  
2025-03-22 11:25:13.552525: Epoch 603 
2025-03-22 11:25:13.556810: Current learning rate: 0.00435 
2025-03-22 11:25:56.464628: train_loss -0.8737 
2025-03-22 11:25:56.473192: val_loss -0.8581 
2025-03-22 11:25:56.478765: Pseudo dice [np.float64(0.9498), np.float64(0.9276), np.float64(0.9183)] 
2025-03-22 11:25:56.483842: Epoch time: 42.92 s 
2025-03-22 11:25:57.263050:  
2025-03-22 11:25:57.270184: Epoch 604 
2025-03-22 11:25:57.276283: Current learning rate: 0.00434 
2025-03-22 11:26:40.361926: train_loss -0.8653 
2025-03-22 11:26:40.368452: val_loss -0.8655 
2025-03-22 11:26:40.374501: Pseudo dice [np.float64(0.9472), np.float64(0.9419), np.float64(0.9259)] 
2025-03-22 11:26:40.379716: Epoch time: 43.1 s 
2025-03-22 11:26:41.143778:  
2025-03-22 11:26:41.151164: Epoch 605 
2025-03-22 11:26:41.155184: Current learning rate: 0.00433 
2025-03-22 11:27:24.017523: train_loss -0.8737 
2025-03-22 11:27:24.023130: val_loss -0.843 
2025-03-22 11:27:24.030282: Pseudo dice [np.float64(0.9501), np.float64(0.9184), np.float64(0.913)] 
2025-03-22 11:27:24.035349: Epoch time: 42.87 s 
2025-03-22 11:27:24.815343:  
2025-03-22 11:27:24.821914: Epoch 606 
2025-03-22 11:27:24.825470: Current learning rate: 0.00432 
2025-03-22 11:28:08.409303: train_loss -0.87 
2025-03-22 11:28:08.418322: val_loss -0.8741 
2025-03-22 11:28:08.423335: Pseudo dice [np.float64(0.9528), np.float64(0.9307), np.float64(0.915)] 
2025-03-22 11:28:08.430859: Epoch time: 43.59 s 
2025-03-22 11:28:09.220567:  
2025-03-22 11:28:09.227114: Epoch 607 
2025-03-22 11:28:09.233170: Current learning rate: 0.00431 
2025-03-22 11:28:52.403465: train_loss -0.8758 
2025-03-22 11:28:52.411661: val_loss -0.8323 
2025-03-22 11:28:52.419370: Pseudo dice [np.float64(0.9471), np.float64(0.9123), np.float64(0.9122)] 
2025-03-22 11:28:52.425578: Epoch time: 43.18 s 
2025-03-22 11:28:53.207197:  
2025-03-22 11:28:53.212207: Epoch 608 
2025-03-22 11:28:53.216719: Current learning rate: 0.0043 
2025-03-22 11:29:36.397225: train_loss -0.8754 
2025-03-22 11:29:36.407780: val_loss -0.8587 
2025-03-22 11:29:36.413800: Pseudo dice [np.float64(0.9511), np.float64(0.9285), np.float64(0.9215)] 
2025-03-22 11:29:36.419830: Epoch time: 43.19 s 
2025-03-22 11:29:37.155880:  
2025-03-22 11:29:37.162430: Epoch 609 
2025-03-22 11:29:37.166439: Current learning rate: 0.00429 
2025-03-22 11:30:20.059738: train_loss -0.8754 
2025-03-22 11:30:20.067254: val_loss -0.8176 
2025-03-22 11:30:20.071264: Pseudo dice [np.float64(0.9453), np.float64(0.9155), np.float64(0.9045)] 
2025-03-22 11:30:20.076280: Epoch time: 42.9 s 
2025-03-22 11:30:20.847380:  
2025-03-22 11:30:20.854907: Epoch 610 
2025-03-22 11:30:20.861927: Current learning rate: 0.00429 
2025-03-22 11:31:04.085470: train_loss -0.873 
2025-03-22 11:31:04.092990: val_loss -0.853 
2025-03-22 11:31:04.100008: Pseudo dice [np.float64(0.9536), np.float64(0.9359), np.float64(0.9171)] 
2025-03-22 11:31:04.107535: Epoch time: 43.24 s 
2025-03-22 11:31:05.123303:  
2025-03-22 11:31:05.132431: Epoch 611 
2025-03-22 11:31:05.135470: Current learning rate: 0.00428 
2025-03-22 11:31:48.164734: train_loss -0.8737 
2025-03-22 11:31:48.172856: val_loss -0.853 
2025-03-22 11:31:48.179010: Pseudo dice [np.float64(0.9519), np.float64(0.9429), np.float64(0.9234)] 
2025-03-22 11:31:48.186629: Epoch time: 43.04 s 
2025-03-22 11:31:48.987449:  
2025-03-22 11:31:48.995035: Epoch 612 
2025-03-22 11:31:49.000706: Current learning rate: 0.00427 
2025-03-22 11:32:31.830385: train_loss -0.8816 
2025-03-22 11:32:31.837908: val_loss -0.8568 
2025-03-22 11:32:31.843929: Pseudo dice [np.float64(0.9511), np.float64(0.9272), np.float64(0.9167)] 
2025-03-22 11:32:31.850450: Epoch time: 42.84 s 
2025-03-22 11:32:32.628861:  
2025-03-22 11:32:32.635423: Epoch 613 
2025-03-22 11:32:32.640564: Current learning rate: 0.00426 
2025-03-22 11:33:15.491237: train_loss -0.8795 
2025-03-22 11:33:15.499766: val_loss -0.8492 
2025-03-22 11:33:15.506292: Pseudo dice [np.float64(0.9498), np.float64(0.9348), np.float64(0.9091)] 
2025-03-22 11:33:15.512812: Epoch time: 42.86 s 
2025-03-22 11:33:16.278705:  
2025-03-22 11:33:16.284791: Epoch 614 
2025-03-22 11:33:16.289346: Current learning rate: 0.00425 
2025-03-22 11:33:59.183904: train_loss -0.8747 
2025-03-22 11:33:59.191427: val_loss -0.8634 
2025-03-22 11:33:59.197441: Pseudo dice [np.float64(0.9523), np.float64(0.9386), np.float64(0.9173)] 
2025-03-22 11:33:59.201455: Epoch time: 42.91 s 
2025-03-22 11:33:59.995821:  
2025-03-22 11:34:00.002346: Epoch 615 
2025-03-22 11:34:00.006356: Current learning rate: 0.00424 
2025-03-22 11:34:44.946199: train_loss -0.876 
2025-03-22 11:34:44.953718: val_loss -0.8455 
2025-03-22 11:34:44.957227: Pseudo dice [np.float64(0.9432), np.float64(0.9224), np.float64(0.9104)] 
2025-03-22 11:34:44.962238: Epoch time: 44.95 s 
2025-03-22 11:34:45.748454:  
2025-03-22 11:34:45.754975: Epoch 616 
2025-03-22 11:34:45.760348: Current learning rate: 0.00423 
2025-03-22 11:35:28.895859: train_loss -0.8817 
2025-03-22 11:35:28.904897: val_loss -0.8527 
2025-03-22 11:35:28.910915: Pseudo dice [np.float64(0.9498), np.float64(0.9539), np.float64(0.9191)] 
2025-03-22 11:35:28.917436: Epoch time: 43.15 s 
2025-03-22 11:35:29.763739:  
2025-03-22 11:35:29.771264: Epoch 617 
2025-03-22 11:35:29.776275: Current learning rate: 0.00422 
2025-03-22 11:36:12.626482: train_loss -0.8718 
2025-03-22 11:36:12.635014: val_loss -0.8483 
2025-03-22 11:36:12.642535: Pseudo dice [np.float64(0.9533), np.float64(0.9385), np.float64(0.9125)] 
2025-03-22 11:36:12.649047: Epoch time: 42.86 s 
2025-03-22 11:36:13.441495:  
2025-03-22 11:36:13.449652: Epoch 618 
2025-03-22 11:36:13.456770: Current learning rate: 0.00421 
2025-03-22 11:36:56.648764: train_loss -0.8735 
2025-03-22 11:36:56.657402: val_loss -0.8524 
2025-03-22 11:36:56.665029: Pseudo dice [np.float64(0.9476), np.float64(0.9337), np.float64(0.9201)] 
2025-03-22 11:36:56.671639: Epoch time: 43.21 s 
2025-03-22 11:36:57.698235:  
2025-03-22 11:36:57.706351: Epoch 619 
2025-03-22 11:36:57.710399: Current learning rate: 0.0042 
2025-03-22 11:37:40.681908: train_loss -0.8797 
2025-03-22 11:37:40.689026: val_loss -0.8777 
2025-03-22 11:37:40.694038: Pseudo dice [np.float64(0.9476), np.float64(0.9389), np.float64(0.9211)] 
2025-03-22 11:37:40.700052: Epoch time: 42.98 s 
2025-03-22 11:37:41.486644:  
2025-03-22 11:37:41.494171: Epoch 620 
2025-03-22 11:37:41.500127: Current learning rate: 0.00419 
2025-03-22 11:38:24.510411: train_loss -0.8693 
2025-03-22 11:38:24.519933: val_loss -0.8609 
2025-03-22 11:38:24.525451: Pseudo dice [np.float64(0.9555), np.float64(0.9408), np.float64(0.9265)] 
2025-03-22 11:38:24.531471: Epoch time: 43.03 s 
2025-03-22 11:38:25.325409:  
2025-03-22 11:38:25.331996: Epoch 621 
2025-03-22 11:38:25.336103: Current learning rate: 0.00418 
2025-03-22 11:39:08.154167: train_loss -0.8627 
2025-03-22 11:39:08.161686: val_loss -0.8335 
2025-03-22 11:39:08.166698: Pseudo dice [np.float64(0.9448), np.float64(0.9237), np.float64(0.9113)] 
2025-03-22 11:39:08.171710: Epoch time: 42.83 s 
2025-03-22 11:39:08.971161:  
2025-03-22 11:39:08.978179: Epoch 622 
2025-03-22 11:39:08.982192: Current learning rate: 0.00417 
2025-03-22 11:39:52.095269: train_loss -0.8683 
2025-03-22 11:39:52.103294: val_loss -0.8631 
2025-03-22 11:39:52.112825: Pseudo dice [np.float64(0.946), np.float64(0.9485), np.float64(0.9227)] 
2025-03-22 11:39:52.120853: Epoch time: 43.13 s 
2025-03-22 11:39:52.923116:  
2025-03-22 11:39:52.929628: Epoch 623 
2025-03-22 11:39:52.933136: Current learning rate: 0.00416 
2025-03-22 11:40:35.795501: train_loss -0.8679 
2025-03-22 11:40:35.802017: val_loss -0.8322 
2025-03-22 11:40:35.809035: Pseudo dice [np.float64(0.9499), np.float64(0.9294), np.float64(0.9204)] 
2025-03-22 11:40:35.817063: Epoch time: 42.87 s 
2025-03-22 11:40:36.609302:  
2025-03-22 11:40:36.616853: Epoch 624 
2025-03-22 11:40:36.622459: Current learning rate: 0.00415 
2025-03-22 11:41:20.787602: train_loss -0.869 
2025-03-22 11:41:20.795125: val_loss -0.8896 
2025-03-22 11:41:20.799635: Pseudo dice [np.float64(0.9507), np.float64(0.9538), np.float64(0.9227)] 
2025-03-22 11:41:20.802645: Epoch time: 44.18 s 
2025-03-22 11:41:21.597570:  
2025-03-22 11:41:21.606097: Epoch 625 
2025-03-22 11:41:21.611613: Current learning rate: 0.00414 
2025-03-22 11:42:04.788072: train_loss -0.8665 
2025-03-22 11:42:04.794593: val_loss -0.8777 
2025-03-22 11:42:04.799639: Pseudo dice [np.float64(0.9503), np.float64(0.9512), np.float64(0.931)] 
2025-03-22 11:42:04.803151: Epoch time: 43.19 s 
2025-03-22 11:42:05.590530:  
2025-03-22 11:42:05.597094: Epoch 626 
2025-03-22 11:42:05.601196: Current learning rate: 0.00413 
2025-03-22 11:42:48.610635: train_loss -0.8712 
2025-03-22 11:42:48.618157: val_loss -0.8643 
2025-03-22 11:42:48.623169: Pseudo dice [np.float64(0.952), np.float64(0.9423), np.float64(0.9232)] 
2025-03-22 11:42:48.628187: Epoch time: 43.02 s 
2025-03-22 11:42:49.638796:  
2025-03-22 11:42:49.647376: Epoch 627 
2025-03-22 11:42:49.650426: Current learning rate: 0.00412 
2025-03-22 11:43:32.581753: train_loss -0.8838 
2025-03-22 11:43:32.590278: val_loss -0.8631 
2025-03-22 11:43:32.595798: Pseudo dice [np.float64(0.9482), np.float64(0.9255), np.float64(0.9213)] 
2025-03-22 11:43:32.604326: Epoch time: 42.94 s 
2025-03-22 11:43:33.379729:  
2025-03-22 11:43:33.386243: Epoch 628 
2025-03-22 11:43:33.390252: Current learning rate: 0.00411 
2025-03-22 11:44:16.327668: train_loss -0.8763 
2025-03-22 11:44:16.334183: val_loss -0.834 
2025-03-22 11:44:16.341703: Pseudo dice [np.float64(0.949), np.float64(0.925), np.float64(0.9085)] 
2025-03-22 11:44:16.346716: Epoch time: 42.95 s 
2025-03-22 11:44:17.181915:  
2025-03-22 11:44:17.188003: Epoch 629 
2025-03-22 11:44:17.192634: Current learning rate: 0.0041 
2025-03-22 11:45:04.508715: train_loss -0.8784 
2025-03-22 11:45:04.516231: val_loss -0.8679 
2025-03-22 11:45:04.530109: Pseudo dice [np.float64(0.9487), np.float64(0.9421), np.float64(0.9272)] 
2025-03-22 11:45:04.539532: Epoch time: 47.33 s 
2025-03-22 11:45:05.345002:  
2025-03-22 11:45:05.351563: Epoch 630 
2025-03-22 11:45:05.356187: Current learning rate: 0.00409 
2025-03-22 11:45:48.331698: train_loss -0.8826 
2025-03-22 11:45:48.338783: val_loss -0.8613 
2025-03-22 11:45:48.343954: Pseudo dice [np.float64(0.9488), np.float64(0.9411), np.float64(0.922)] 
2025-03-22 11:45:48.348531: Epoch time: 42.99 s 
2025-03-22 11:45:49.142012:  
2025-03-22 11:45:49.148564: Epoch 631 
2025-03-22 11:45:49.153629: Current learning rate: 0.00408 
2025-03-22 11:46:31.984549: train_loss -0.8766 
2025-03-22 11:46:31.991622: val_loss -0.8423 
2025-03-22 11:46:31.997273: Pseudo dice [np.float64(0.9528), np.float64(0.9381), np.float64(0.9196)] 
2025-03-22 11:46:32.004888: Epoch time: 42.84 s 
2025-03-22 11:46:32.795740:  
2025-03-22 11:46:32.802482: Epoch 632 
2025-03-22 11:46:32.806593: Current learning rate: 0.00407 
2025-03-22 11:47:15.912492: train_loss -0.88 
2025-03-22 11:47:15.920012: val_loss -0.8566 
2025-03-22 11:47:15.926026: Pseudo dice [np.float64(0.9452), np.float64(0.9347), np.float64(0.9177)] 
2025-03-22 11:47:15.931042: Epoch time: 43.12 s 
2025-03-22 11:47:16.671826:  
2025-03-22 11:47:16.678360: Epoch 633 
2025-03-22 11:47:16.682389: Current learning rate: 0.00406 
2025-03-22 11:48:01.945446: train_loss -0.8688 
2025-03-22 11:48:01.955502: val_loss -0.8388 
2025-03-22 11:48:01.962024: Pseudo dice [np.float64(0.9528), np.float64(0.9147), np.float64(0.9137)] 
2025-03-22 11:48:01.967035: Epoch time: 45.27 s 
2025-03-22 11:48:02.742682:  
2025-03-22 11:48:02.749717: Epoch 634 
2025-03-22 11:48:02.754733: Current learning rate: 0.00405 
2025-03-22 11:48:46.004763: train_loss -0.8687 
2025-03-22 11:48:46.013789: val_loss -0.8521 
2025-03-22 11:48:46.018806: Pseudo dice [np.float64(0.9504), np.float64(0.9407), np.float64(0.9207)] 
2025-03-22 11:48:46.022316: Epoch time: 43.26 s 
2025-03-22 11:48:47.043695:  
2025-03-22 11:48:47.051280: Epoch 635 
2025-03-22 11:48:47.054343: Current learning rate: 0.00404 
2025-03-22 11:49:29.872210: train_loss -0.8699 
2025-03-22 11:49:29.880725: val_loss -0.8497 
2025-03-22 11:49:29.888747: Pseudo dice [np.float64(0.9462), np.float64(0.942), np.float64(0.9223)] 
2025-03-22 11:49:29.894770: Epoch time: 42.83 s 
2025-03-22 11:49:30.669037:  
2025-03-22 11:49:30.675553: Epoch 636 
2025-03-22 11:49:30.679564: Current learning rate: 0.00403 
2025-03-22 11:50:13.418643: train_loss -0.8587 
2025-03-22 11:50:13.426159: val_loss -0.8203 
2025-03-22 11:50:13.430171: Pseudo dice [np.float64(0.9444), np.float64(0.8934), np.float64(0.9025)] 
2025-03-22 11:50:13.435234: Epoch time: 42.75 s 
2025-03-22 11:50:14.221981:  
2025-03-22 11:50:14.228525: Epoch 637 
2025-03-22 11:50:14.233568: Current learning rate: 0.00402 
2025-03-22 11:50:57.252843: train_loss -0.8568 
2025-03-22 11:50:57.260414: val_loss -0.8508 
2025-03-22 11:50:57.265567: Pseudo dice [np.float64(0.9476), np.float64(0.9359), np.float64(0.9149)] 
2025-03-22 11:50:57.268577: Epoch time: 43.03 s 
2025-03-22 11:50:58.015060:  
2025-03-22 11:50:58.021074: Epoch 638 
2025-03-22 11:50:58.025083: Current learning rate: 0.00401 
2025-03-22 11:51:40.957804: train_loss -0.8605 
2025-03-22 11:51:40.966321: val_loss -0.8537 
2025-03-22 11:51:40.974347: Pseudo dice [np.float64(0.947), np.float64(0.9437), np.float64(0.9251)] 
2025-03-22 11:51:40.979361: Epoch time: 42.94 s 
2025-03-22 11:51:41.773622:  
2025-03-22 11:51:41.782171: Epoch 639 
2025-03-22 11:51:41.787408: Current learning rate: 0.004 
2025-03-22 11:52:24.589274: train_loss -0.8659 
2025-03-22 11:52:24.597405: val_loss -0.8542 
2025-03-22 11:52:24.604470: Pseudo dice [np.float64(0.9536), np.float64(0.9315), np.float64(0.9261)] 
2025-03-22 11:52:24.609027: Epoch time: 42.82 s 
2025-03-22 11:52:25.360487:  
2025-03-22 11:52:25.366500: Epoch 640 
2025-03-22 11:52:25.370515: Current learning rate: 0.00399 
2025-03-22 11:53:08.171873: train_loss -0.8628 
2025-03-22 11:53:08.179893: val_loss -0.8533 
2025-03-22 11:53:08.187415: Pseudo dice [np.float64(0.949), np.float64(0.9418), np.float64(0.9162)] 
2025-03-22 11:53:08.193434: Epoch time: 42.81 s 
2025-03-22 11:53:08.980793:  
2025-03-22 11:53:08.988365: Epoch 641 
2025-03-22 11:53:08.995019: Current learning rate: 0.00398 
2025-03-22 11:53:51.881995: train_loss -0.8798 
2025-03-22 11:53:51.889507: val_loss -0.8623 
2025-03-22 11:53:51.897027: Pseudo dice [np.float64(0.9527), np.float64(0.945), np.float64(0.926)] 
2025-03-22 11:53:51.903545: Epoch time: 42.9 s 
2025-03-22 11:53:52.679529:  
2025-03-22 11:53:52.686609: Epoch 642 
2025-03-22 11:53:52.691626: Current learning rate: 0.00397 
2025-03-22 11:54:37.238671: train_loss -0.8766 
2025-03-22 11:54:37.246006: val_loss -0.8513 
2025-03-22 11:54:37.252025: Pseudo dice [np.float64(0.951), np.float64(0.946), np.float64(0.9174)] 
2025-03-22 11:54:37.258036: Epoch time: 44.56 s 
2025-03-22 11:54:38.275701:  
2025-03-22 11:54:38.283779: Epoch 643 
2025-03-22 11:54:38.286828: Current learning rate: 0.00396 
2025-03-22 11:55:21.412087: train_loss -0.8808 
2025-03-22 11:55:21.418606: val_loss -0.8642 
2025-03-22 11:55:21.426130: Pseudo dice [np.float64(0.9508), np.float64(0.9423), np.float64(0.9223)] 
2025-03-22 11:55:21.432146: Epoch time: 43.14 s 
2025-03-22 11:55:22.190048:  
2025-03-22 11:55:22.197232: Epoch 644 
2025-03-22 11:55:22.201266: Current learning rate: 0.00395 
2025-03-22 11:56:05.014438: train_loss -0.8741 
2025-03-22 11:56:05.022962: val_loss -0.8431 
2025-03-22 11:56:05.029494: Pseudo dice [np.float64(0.9462), np.float64(0.9259), np.float64(0.9067)] 
2025-03-22 11:56:05.036012: Epoch time: 42.83 s 
2025-03-22 11:56:05.817118:  
2025-03-22 11:56:05.824187: Epoch 645 
2025-03-22 11:56:05.828239: Current learning rate: 0.00394 
2025-03-22 11:56:48.784925: train_loss -0.8708 
2025-03-22 11:56:48.792962: val_loss -0.8348 
2025-03-22 11:56:48.799983: Pseudo dice [np.float64(0.943), np.float64(0.9379), np.float64(0.9156)] 
2025-03-22 11:56:48.805501: Epoch time: 42.97 s 
2025-03-22 11:56:49.616887:  
2025-03-22 11:56:49.624474: Epoch 646 
2025-03-22 11:56:49.629026: Current learning rate: 0.00393 
2025-03-22 11:57:32.539865: train_loss -0.8737 
2025-03-22 11:57:32.547898: val_loss -0.8607 
2025-03-22 11:57:32.555420: Pseudo dice [np.float64(0.9506), np.float64(0.9291), np.float64(0.9128)] 
2025-03-22 11:57:32.563945: Epoch time: 42.92 s 
2025-03-22 11:57:33.353065:  
2025-03-22 11:57:33.359648: Epoch 647 
2025-03-22 11:57:33.366268: Current learning rate: 0.00392 
2025-03-22 11:58:16.368134: train_loss -0.87 
2025-03-22 11:58:16.374648: val_loss -0.8414 
2025-03-22 11:58:16.378158: Pseudo dice [np.float64(0.9524), np.float64(0.9332), np.float64(0.9162)] 
2025-03-22 11:58:16.382166: Epoch time: 43.02 s 
2025-03-22 11:58:17.152712:  
2025-03-22 11:58:17.159266: Epoch 648 
2025-03-22 11:58:17.164309: Current learning rate: 0.00391 
2025-03-22 11:59:00.330616: train_loss -0.8747 
2025-03-22 11:59:00.340211: val_loss -0.854 
2025-03-22 11:59:00.346750: Pseudo dice [np.float64(0.9445), np.float64(0.9335), np.float64(0.9163)] 
2025-03-22 11:59:00.352761: Epoch time: 43.18 s 
2025-03-22 11:59:01.102185:  
2025-03-22 11:59:01.108763: Epoch 649 
2025-03-22 11:59:01.112323: Current learning rate: 0.0039 
2025-03-22 11:59:44.061345: train_loss -0.8711 
2025-03-22 11:59:44.068872: val_loss -0.8463 
2025-03-22 11:59:44.073886: Pseudo dice [np.float64(0.9429), np.float64(0.9261), np.float64(0.9157)] 
2025-03-22 11:59:44.079901: Epoch time: 42.96 s 
2025-03-22 11:59:44.977530:  
2025-03-22 11:59:44.985198: Epoch 650 
2025-03-22 11:59:44.989749: Current learning rate: 0.00389 
2025-03-22 12:00:27.943371: train_loss -0.8733 
2025-03-22 12:00:27.949965: val_loss -0.835 
2025-03-22 12:00:27.955031: Pseudo dice [np.float64(0.9515), np.float64(0.9386), np.float64(0.9142)] 
2025-03-22 12:00:27.961686: Epoch time: 42.97 s 
2025-03-22 12:00:28.975099:  
2025-03-22 12:00:28.983121: Epoch 651 
2025-03-22 12:00:28.987132: Current learning rate: 0.00388 
2025-03-22 12:01:12.867969: train_loss -0.8727 
2025-03-22 12:01:12.876998: val_loss -0.8628 
2025-03-22 12:01:12.883519: Pseudo dice [np.float64(0.9507), np.float64(0.9524), np.float64(0.9283)] 
2025-03-22 12:01:12.889537: Epoch time: 43.89 s 
2025-03-22 12:01:13.685014:  
2025-03-22 12:01:13.691582: Epoch 652 
2025-03-22 12:01:13.695112: Current learning rate: 0.00387 
2025-03-22 12:01:56.652933: train_loss -0.8686 
2025-03-22 12:01:56.658449: val_loss -0.8651 
2025-03-22 12:01:56.663465: Pseudo dice [np.float64(0.9484), np.float64(0.9437), np.float64(0.9328)] 
2025-03-22 12:01:56.668542: Epoch time: 42.97 s 
2025-03-22 12:01:57.439300:  
2025-03-22 12:01:57.447399: Epoch 653 
2025-03-22 12:01:57.452489: Current learning rate: 0.00386 
2025-03-22 12:02:40.483398: train_loss -0.8835 
2025-03-22 12:02:40.490922: val_loss -0.8358 
2025-03-22 12:02:40.496943: Pseudo dice [np.float64(0.9476), np.float64(0.9262), np.float64(0.9112)] 
2025-03-22 12:02:40.501958: Epoch time: 43.04 s 
2025-03-22 12:02:41.266323:  
2025-03-22 12:02:41.273413: Epoch 654 
2025-03-22 12:02:41.277550: Current learning rate: 0.00385 
2025-03-22 12:03:24.127820: train_loss -0.8775 
2025-03-22 12:03:24.135864: val_loss -0.8554 
2025-03-22 12:03:24.143386: Pseudo dice [np.float64(0.9472), np.float64(0.9521), np.float64(0.9322)] 
2025-03-22 12:03:24.151909: Epoch time: 42.86 s 
2025-03-22 12:03:24.949247:  
2025-03-22 12:03:24.955820: Epoch 655 
2025-03-22 12:03:24.962968: Current learning rate: 0.00384 
2025-03-22 12:04:07.774550: train_loss -0.8817 
2025-03-22 12:04:07.781619: val_loss -0.8365 
2025-03-22 12:04:07.786791: Pseudo dice [np.float64(0.9452), np.float64(0.9264), np.float64(0.9134)] 
2025-03-22 12:04:07.793307: Epoch time: 42.83 s 
2025-03-22 12:04:08.524099:  
2025-03-22 12:04:08.531630: Epoch 656 
2025-03-22 12:04:08.538149: Current learning rate: 0.00383 
2025-03-22 12:04:51.354649: train_loss -0.8795 
2025-03-22 12:04:51.362171: val_loss -0.8583 
2025-03-22 12:04:51.367182: Pseudo dice [np.float64(0.9489), np.float64(0.9425), np.float64(0.9277)] 
2025-03-22 12:04:51.372193: Epoch time: 42.83 s 
2025-03-22 12:04:52.167664:  
2025-03-22 12:04:52.174219: Epoch 657 
2025-03-22 12:04:52.177767: Current learning rate: 0.00382 
2025-03-22 12:05:35.328616: train_loss -0.8808 
2025-03-22 12:05:35.338146: val_loss -0.8659 
2025-03-22 12:05:35.344667: Pseudo dice [np.float64(0.9541), np.float64(0.9264), np.float64(0.9145)] 
2025-03-22 12:05:35.348680: Epoch time: 43.16 s 
2025-03-22 12:05:36.182656:  
2025-03-22 12:05:36.189232: Epoch 658 
2025-03-22 12:05:36.196897: Current learning rate: 0.00381 
2025-03-22 12:06:19.253193: train_loss -0.8822 
2025-03-22 12:06:19.261715: val_loss -0.8672 
2025-03-22 12:06:19.268239: Pseudo dice [np.float64(0.9569), np.float64(0.9409), np.float64(0.9271)] 
2025-03-22 12:06:19.274757: Epoch time: 43.07 s 
2025-03-22 12:06:20.269220:  
2025-03-22 12:06:20.275784: Epoch 659 
2025-03-22 12:06:20.278324: Current learning rate: 0.0038 
2025-03-22 12:07:03.296416: train_loss -0.8675 
2025-03-22 12:07:03.305943: val_loss -0.8669 
2025-03-22 12:07:03.313969: Pseudo dice [np.float64(0.9451), np.float64(0.9373), np.float64(0.9222)] 
2025-03-22 12:07:03.318482: Epoch time: 43.03 s 
2025-03-22 12:07:04.086946:  
2025-03-22 12:07:04.093467: Epoch 660 
2025-03-22 12:07:04.095973: Current learning rate: 0.00379 
2025-03-22 12:07:47.556067: train_loss -0.8693 
2025-03-22 12:07:47.563082: val_loss -0.8546 
2025-03-22 12:07:47.568181: Pseudo dice [np.float64(0.956), np.float64(0.9479), np.float64(0.9306)] 
2025-03-22 12:07:47.573192: Epoch time: 43.47 s 
2025-03-22 12:07:48.344245:  
2025-03-22 12:07:48.350764: Epoch 661 
2025-03-22 12:07:48.354774: Current learning rate: 0.00378 
2025-03-22 12:08:31.377529: train_loss -0.8763 
2025-03-22 12:08:31.385056: val_loss -0.8121 
2025-03-22 12:08:31.391074: Pseudo dice [np.float64(0.9478), np.float64(0.9321), np.float64(0.9183)] 
2025-03-22 12:08:31.397593: Epoch time: 43.03 s 
2025-03-22 12:08:32.183939:  
2025-03-22 12:08:32.190457: Epoch 662 
2025-03-22 12:08:32.195470: Current learning rate: 0.00377 
2025-03-22 12:09:15.016177: train_loss -0.8732 
2025-03-22 12:09:15.025220: val_loss -0.8598 
2025-03-22 12:09:15.031746: Pseudo dice [np.float64(0.952), np.float64(0.9472), np.float64(0.9207)] 
2025-03-22 12:09:15.039278: Epoch time: 42.83 s 
2025-03-22 12:09:15.812587:  
2025-03-22 12:09:15.820108: Epoch 663 
2025-03-22 12:09:15.825119: Current learning rate: 0.00376 
2025-03-22 12:09:58.890269: train_loss -0.8767 
2025-03-22 12:09:58.899476: val_loss -0.8451 
2025-03-22 12:09:58.905996: Pseudo dice [np.float64(0.9539), np.float64(0.9514), np.float64(0.9175)] 
2025-03-22 12:09:58.914530: Epoch time: 43.08 s 
2025-03-22 12:09:58.922559: Yayy! New best EMA pseudo Dice: 0.9368 
2025-03-22 12:09:59.792519:  
2025-03-22 12:09:59.799573: Epoch 664 
2025-03-22 12:09:59.804589: Current learning rate: 0.00375 
2025-03-22 12:10:42.795383: train_loss -0.8636 
2025-03-22 12:10:42.804404: val_loss -0.8301 
2025-03-22 12:10:42.811928: Pseudo dice [np.float64(0.9501), np.float64(0.9383), np.float64(0.9222)] 
2025-03-22 12:10:42.817125: Epoch time: 43.0 s 
2025-03-22 12:10:42.823146: Yayy! New best EMA pseudo Dice: 0.9368 
2025-03-22 12:10:43.690503:  
2025-03-22 12:10:43.698083: Epoch 665 
2025-03-22 12:10:43.703725: Current learning rate: 0.00374 
2025-03-22 12:11:26.675924: train_loss -0.8675 
2025-03-22 12:11:26.683453: val_loss -0.8659 
2025-03-22 12:11:26.688980: Pseudo dice [np.float64(0.9441), np.float64(0.9426), np.float64(0.9266)] 
2025-03-22 12:11:26.696008: Epoch time: 42.98 s 
2025-03-22 12:11:26.702041: Yayy! New best EMA pseudo Dice: 0.9369 
2025-03-22 12:11:27.615952:  
2025-03-22 12:11:27.625976: Epoch 666 
2025-03-22 12:11:27.632497: Current learning rate: 0.00373 
2025-03-22 12:12:10.589636: train_loss -0.8702 
2025-03-22 12:12:10.598662: val_loss -0.8822 
2025-03-22 12:12:10.603674: Pseudo dice [np.float64(0.9482), np.float64(0.9452), np.float64(0.9207)] 
2025-03-22 12:12:10.608685: Epoch time: 42.97 s 
2025-03-22 12:12:10.612193: Yayy! New best EMA pseudo Dice: 0.937 
2025-03-22 12:12:11.709377:  
2025-03-22 12:12:11.717478: Epoch 667 
2025-03-22 12:12:11.722021: Current learning rate: 0.00372 
2025-03-22 12:12:54.594145: train_loss -0.874 
2025-03-22 12:12:54.602317: val_loss -0.8628 
2025-03-22 12:12:54.608836: Pseudo dice [np.float64(0.9549), np.float64(0.9461), np.float64(0.9204)] 
2025-03-22 12:12:54.616361: Epoch time: 42.88 s 
2025-03-22 12:12:54.621376: Yayy! New best EMA pseudo Dice: 0.9374 
2025-03-22 12:12:55.532679:  
2025-03-22 12:12:55.540201: Epoch 668 
2025-03-22 12:12:55.546224: Current learning rate: 0.00371 
2025-03-22 12:13:38.304072: train_loss -0.8793 
2025-03-22 12:13:38.311732: val_loss -0.8439 
2025-03-22 12:13:38.317756: Pseudo dice [np.float64(0.9499), np.float64(0.9249), np.float64(0.9225)] 
2025-03-22 12:13:38.326790: Epoch time: 42.77 s 
2025-03-22 12:13:39.116144:  
2025-03-22 12:13:39.122760: Epoch 669 
2025-03-22 12:13:39.127808: Current learning rate: 0.0037 
2025-03-22 12:14:23.395904: train_loss -0.8776 
2025-03-22 12:14:23.405427: val_loss -0.8483 
2025-03-22 12:14:23.411948: Pseudo dice [np.float64(0.9526), np.float64(0.9248), np.float64(0.9239)] 
2025-03-22 12:14:23.418464: Epoch time: 44.28 s 
2025-03-22 12:14:24.211731:  
2025-03-22 12:14:24.217346: Epoch 670 
2025-03-22 12:14:24.222420: Current learning rate: 0.00369 
2025-03-22 12:15:07.423274: train_loss -0.8732 
2025-03-22 12:15:07.430795: val_loss -0.8571 
2025-03-22 12:15:07.435806: Pseudo dice [np.float64(0.9483), np.float64(0.934), np.float64(0.9125)] 
2025-03-22 12:15:07.440820: Epoch time: 43.21 s 
2025-03-22 12:15:08.246810:  
2025-03-22 12:15:08.253978: Epoch 671 
2025-03-22 12:15:08.258488: Current learning rate: 0.00368 
2025-03-22 12:15:51.175719: train_loss -0.865 
2025-03-22 12:15:51.183528: val_loss -0.8387 
2025-03-22 12:15:51.190613: Pseudo dice [np.float64(0.944), np.float64(0.9399), np.float64(0.9109)] 
2025-03-22 12:15:51.197693: Epoch time: 42.93 s 
2025-03-22 12:15:51.984805:  
2025-03-22 12:15:51.991381: Epoch 672 
2025-03-22 12:15:51.995924: Current learning rate: 0.00367 
2025-03-22 12:16:35.134352: train_loss -0.8763 
2025-03-22 12:16:35.141874: val_loss -0.8602 
2025-03-22 12:16:35.149394: Pseudo dice [np.float64(0.9531), np.float64(0.9376), np.float64(0.9228)] 
2025-03-22 12:16:35.156914: Epoch time: 43.15 s 
2025-03-22 12:16:35.933349:  
2025-03-22 12:16:35.939877: Epoch 673 
2025-03-22 12:16:35.945888: Current learning rate: 0.00366 
2025-03-22 12:17:19.117357: train_loss -0.8659 
2025-03-22 12:17:19.127388: val_loss -0.8576 
2025-03-22 12:17:19.134908: Pseudo dice [np.float64(0.9455), np.float64(0.9456), np.float64(0.9246)] 
2025-03-22 12:17:19.142434: Epoch time: 43.19 s 
2025-03-22 12:17:19.929444:  
2025-03-22 12:17:19.936457: Epoch 674 
2025-03-22 12:17:19.940472: Current learning rate: 0.00365 
2025-03-22 12:18:02.788185: train_loss -0.8643 
2025-03-22 12:18:02.795897: val_loss -0.8717 
2025-03-22 12:18:02.800710: Pseudo dice [np.float64(0.9528), np.float64(0.9307), np.float64(0.9182)] 
2025-03-22 12:18:02.805392: Epoch time: 42.86 s 
2025-03-22 12:18:03.836349:  
2025-03-22 12:18:03.844368: Epoch 675 
2025-03-22 12:18:03.849379: Current learning rate: 0.00364 
2025-03-22 12:18:46.559731: train_loss -0.8674 
2025-03-22 12:18:46.567272: val_loss -0.8571 
2025-03-22 12:18:46.572790: Pseudo dice [np.float64(0.9416), np.float64(0.9404), np.float64(0.9196)] 
2025-03-22 12:18:46.580313: Epoch time: 42.72 s 
2025-03-22 12:18:47.377757:  
2025-03-22 12:18:47.383431: Epoch 676 
2025-03-22 12:18:47.388972: Current learning rate: 0.00363 
2025-03-22 12:19:30.278912: train_loss -0.8797 
2025-03-22 12:19:30.288177: val_loss -0.852 
2025-03-22 12:19:30.293830: Pseudo dice [np.float64(0.952), np.float64(0.9376), np.float64(0.912)] 
2025-03-22 12:19:30.301444: Epoch time: 42.9 s 
2025-03-22 12:19:31.104324:  
2025-03-22 12:19:31.111900: Epoch 677 
2025-03-22 12:19:31.115956: Current learning rate: 0.00362 
2025-03-22 12:20:14.027428: train_loss -0.8705 
2025-03-22 12:20:14.035182: val_loss -0.8393 
2025-03-22 12:20:14.040201: Pseudo dice [np.float64(0.9534), np.float64(0.9413), np.float64(0.9038)] 
2025-03-22 12:20:14.046218: Epoch time: 42.92 s 
2025-03-22 12:20:14.846269:  
2025-03-22 12:20:14.853456: Epoch 678 
2025-03-22 12:20:14.858024: Current learning rate: 0.00361 
2025-03-22 12:20:57.870416: train_loss -0.8778 
2025-03-22 12:20:57.879444: val_loss -0.8657 
2025-03-22 12:20:57.887026: Pseudo dice [np.float64(0.9552), np.float64(0.944), np.float64(0.9246)] 
2025-03-22 12:20:57.892612: Epoch time: 43.02 s 
2025-03-22 12:20:58.712326:  
2025-03-22 12:20:58.718893: Epoch 679 
2025-03-22 12:20:58.723543: Current learning rate: 0.0036 
2025-03-22 12:21:41.721426: train_loss -0.8702 
2025-03-22 12:21:41.730454: val_loss -0.8464 
2025-03-22 12:21:41.738983: Pseudo dice [np.float64(0.945), np.float64(0.9284), np.float64(0.9113)] 
2025-03-22 12:21:41.743998: Epoch time: 43.01 s 
2025-03-22 12:21:42.531293:  
2025-03-22 12:21:42.537813: Epoch 680 
2025-03-22 12:21:42.542828: Current learning rate: 0.00359 
2025-03-22 12:22:25.462810: train_loss -0.8761 
2025-03-22 12:22:25.470329: val_loss -0.8695 
2025-03-22 12:22:25.477854: Pseudo dice [np.float64(0.9518), np.float64(0.9499), np.float64(0.916)] 
2025-03-22 12:22:25.485373: Epoch time: 42.93 s 
2025-03-22 12:22:26.265690:  
2025-03-22 12:22:26.272306: Epoch 681 
2025-03-22 12:22:26.276347: Current learning rate: 0.00358 
2025-03-22 12:23:09.172904: train_loss -0.8807 
2025-03-22 12:23:09.179918: val_loss -0.8693 
2025-03-22 12:23:09.183931: Pseudo dice [np.float64(0.9545), np.float64(0.9427), np.float64(0.9281)] 
2025-03-22 12:23:09.188946: Epoch time: 42.91 s 
2025-03-22 12:23:09.989105:  
2025-03-22 12:23:09.997198: Epoch 682 
2025-03-22 12:23:10.004910: Current learning rate: 0.00357 
2025-03-22 12:23:52.924074: train_loss -0.8818 
2025-03-22 12:23:52.931593: val_loss -0.8577 
2025-03-22 12:23:52.938608: Pseudo dice [np.float64(0.9478), np.float64(0.9495), np.float64(0.9201)] 
2025-03-22 12:23:52.945135: Epoch time: 42.93 s 
2025-03-22 12:23:53.991716:  
2025-03-22 12:23:53.998255: Epoch 683 
2025-03-22 12:23:54.004342: Current learning rate: 0.00356 
2025-03-22 12:24:36.805104: train_loss -0.8813 
2025-03-22 12:24:36.812688: val_loss -0.8612 
2025-03-22 12:24:36.817702: Pseudo dice [np.float64(0.9541), np.float64(0.9604), np.float64(0.9257)] 
2025-03-22 12:24:36.822715: Epoch time: 42.81 s 
2025-03-22 12:24:36.828736: Yayy! New best EMA pseudo Dice: 0.9375 
2025-03-22 12:24:37.744586:  
2025-03-22 12:24:37.753684: Epoch 684 
2025-03-22 12:24:37.758843: Current learning rate: 0.00355 
2025-03-22 12:25:20.677936: train_loss -0.8691 
2025-03-22 12:25:20.685520: val_loss -0.838 
2025-03-22 12:25:20.693106: Pseudo dice [np.float64(0.9416), np.float64(0.9278), np.float64(0.9174)] 
2025-03-22 12:25:20.700187: Epoch time: 42.93 s 
2025-03-22 12:25:21.488799:  
2025-03-22 12:25:21.497816: Epoch 685 
2025-03-22 12:25:21.501323: Current learning rate: 0.00354 
2025-03-22 12:26:04.452050: train_loss -0.8733 
2025-03-22 12:26:04.459572: val_loss -0.8275 
2025-03-22 12:26:04.465592: Pseudo dice [np.float64(0.9418), np.float64(0.9377), np.float64(0.9163)] 
2025-03-22 12:26:04.473113: Epoch time: 42.96 s 
2025-03-22 12:26:05.268649:  
2025-03-22 12:26:05.274288: Epoch 686 
2025-03-22 12:26:05.278316: Current learning rate: 0.00353 
2025-03-22 12:26:48.454891: train_loss -0.8686 
2025-03-22 12:26:48.463102: val_loss -0.8446 
2025-03-22 12:26:48.470710: Pseudo dice [np.float64(0.952), np.float64(0.9366), np.float64(0.9118)] 
2025-03-22 12:26:48.476833: Epoch time: 43.19 s 
2025-03-22 12:26:49.247669:  
2025-03-22 12:26:49.255198: Epoch 687 
2025-03-22 12:26:49.260211: Current learning rate: 0.00352 
2025-03-22 12:27:32.379094: train_loss -0.8754 
2025-03-22 12:27:32.388279: val_loss -0.8572 
2025-03-22 12:27:32.394799: Pseudo dice [np.float64(0.9536), np.float64(0.9416), np.float64(0.9208)] 
2025-03-22 12:27:32.401317: Epoch time: 43.13 s 
2025-03-22 12:27:33.193355:  
2025-03-22 12:27:33.199442: Epoch 688 
2025-03-22 12:27:33.204987: Current learning rate: 0.00351 
2025-03-22 12:28:16.135032: train_loss -0.8812 
2025-03-22 12:28:16.144057: val_loss -0.8565 
2025-03-22 12:28:16.152592: Pseudo dice [np.float64(0.9483), np.float64(0.9408), np.float64(0.9254)] 
2025-03-22 12:28:16.161120: Epoch time: 42.94 s 
2025-03-22 12:28:16.956513:  
2025-03-22 12:28:16.963561: Epoch 689 
2025-03-22 12:28:16.968101: Current learning rate: 0.0035 
2025-03-22 12:28:59.678383: train_loss -0.8736 
2025-03-22 12:28:59.686913: val_loss -0.8481 
2025-03-22 12:28:59.691932: Pseudo dice [np.float64(0.9448), np.float64(0.9413), np.float64(0.9202)] 
2025-03-22 12:28:59.695946: Epoch time: 42.72 s 
2025-03-22 12:29:00.494337:  
2025-03-22 12:29:00.502857: Epoch 690 
2025-03-22 12:29:00.509374: Current learning rate: 0.00349 
2025-03-22 12:29:43.450523: train_loss -0.8864 
2025-03-22 12:29:43.458044: val_loss -0.8568 
2025-03-22 12:29:43.463059: Pseudo dice [np.float64(0.9413), np.float64(0.9395), np.float64(0.9115)] 
2025-03-22 12:29:43.468072: Epoch time: 42.96 s 
2025-03-22 12:29:44.472883:  
2025-03-22 12:29:44.478397: Epoch 691 
2025-03-22 12:29:44.482905: Current learning rate: 0.00348 
2025-03-22 12:30:27.333833: train_loss -0.8756 
2025-03-22 12:30:27.341899: val_loss -0.8631 
2025-03-22 12:30:27.347491: Pseudo dice [np.float64(0.9476), np.float64(0.9384), np.float64(0.9229)] 
2025-03-22 12:30:27.355601: Epoch time: 42.86 s 
2025-03-22 12:30:28.133986:  
2025-03-22 12:30:28.142047: Epoch 692 
2025-03-22 12:30:28.148120: Current learning rate: 0.00346 
2025-03-22 12:31:11.216893: train_loss -0.8765 
2025-03-22 12:31:11.226045: val_loss -0.8675 
2025-03-22 12:31:11.231110: Pseudo dice [np.float64(0.9557), np.float64(0.9411), np.float64(0.9176)] 
2025-03-22 12:31:11.238140: Epoch time: 43.08 s 
2025-03-22 12:31:12.019894:  
2025-03-22 12:31:12.027456: Epoch 693 
2025-03-22 12:31:12.031512: Current learning rate: 0.00345 
2025-03-22 12:31:54.879481: train_loss -0.8809 
2025-03-22 12:31:54.888052: val_loss -0.8605 
2025-03-22 12:31:54.895120: Pseudo dice [np.float64(0.9505), np.float64(0.9459), np.float64(0.9188)] 
2025-03-22 12:31:54.901700: Epoch time: 42.86 s 
2025-03-22 12:31:55.684758:  
2025-03-22 12:31:55.692424: Epoch 694 
2025-03-22 12:31:55.697482: Current learning rate: 0.00344 
2025-03-22 12:32:38.506367: train_loss -0.8758 
2025-03-22 12:32:38.513960: val_loss -0.8606 
2025-03-22 12:32:38.520537: Pseudo dice [np.float64(0.9511), np.float64(0.9504), np.float64(0.926)] 
2025-03-22 12:32:38.526187: Epoch time: 42.82 s 
2025-03-22 12:32:39.315213:  
2025-03-22 12:32:39.322330: Epoch 695 
2025-03-22 12:32:39.327439: Current learning rate: 0.00343 
2025-03-22 12:33:24.026520: train_loss -0.867 
2025-03-22 12:33:24.036738: val_loss -0.8538 
2025-03-22 12:33:24.044766: Pseudo dice [np.float64(0.9534), np.float64(0.9268), np.float64(0.9103)] 
2025-03-22 12:33:24.052438: Epoch time: 44.71 s 
2025-03-22 12:33:24.841101:  
2025-03-22 12:33:24.847168: Epoch 696 
2025-03-22 12:33:24.852298: Current learning rate: 0.00342 
2025-03-22 12:34:07.769900: train_loss -0.882 
2025-03-22 12:34:07.778435: val_loss -0.8603 
2025-03-22 12:34:07.785971: Pseudo dice [np.float64(0.9478), np.float64(0.9293), np.float64(0.9217)] 
2025-03-22 12:34:07.792503: Epoch time: 42.93 s 
2025-03-22 12:34:08.590091:  
2025-03-22 12:34:08.596667: Epoch 697 
2025-03-22 12:34:08.603821: Current learning rate: 0.00341 
2025-03-22 12:34:51.587880: train_loss -0.8803 
2025-03-22 12:34:51.595400: val_loss -0.8686 
2025-03-22 12:34:51.601926: Pseudo dice [np.float64(0.9513), np.float64(0.9325), np.float64(0.9273)] 
2025-03-22 12:34:51.606438: Epoch time: 43.0 s 
2025-03-22 12:34:52.375160:  
2025-03-22 12:34:52.381755: Epoch 698 
2025-03-22 12:34:52.386846: Current learning rate: 0.0034 
2025-03-22 12:35:35.321013: train_loss -0.8756 
2025-03-22 12:35:35.330539: val_loss -0.8669 
2025-03-22 12:35:35.334552: Pseudo dice [np.float64(0.9463), np.float64(0.9378), np.float64(0.9218)] 
2025-03-22 12:35:35.338563: Epoch time: 42.95 s 
2025-03-22 12:35:36.397007:  
2025-03-22 12:35:36.404561: Epoch 699 
2025-03-22 12:35:36.408616: Current learning rate: 0.00339 
2025-03-22 12:36:19.183374: train_loss -0.8807 
2025-03-22 12:36:19.191896: val_loss -0.8684 
2025-03-22 12:36:19.199418: Pseudo dice [np.float64(0.9493), np.float64(0.9463), np.float64(0.9249)] 
2025-03-22 12:36:19.205430: Epoch time: 42.79 s 
2025-03-22 12:36:20.136107:  
2025-03-22 12:36:20.142672: Epoch 700 
2025-03-22 12:36:20.147421: Current learning rate: 0.00338 
2025-03-22 12:37:03.070502: train_loss -0.8845 
2025-03-22 12:37:03.079029: val_loss -0.8585 
2025-03-22 12:37:03.085551: Pseudo dice [np.float64(0.9544), np.float64(0.9499), np.float64(0.9333)] 
2025-03-22 12:37:03.089560: Epoch time: 42.93 s 
2025-03-22 12:37:03.889717:  
2025-03-22 12:37:03.896280: Epoch 701 
2025-03-22 12:37:03.901321: Current learning rate: 0.00337 
2025-03-22 12:37:47.242031: train_loss -0.8773 
2025-03-22 12:37:47.250741: val_loss -0.8601 
2025-03-22 12:37:47.257390: Pseudo dice [np.float64(0.9517), np.float64(0.9384), np.float64(0.9185)] 
2025-03-22 12:37:47.263907: Epoch time: 43.35 s 
2025-03-22 12:37:48.080656:  
2025-03-22 12:37:48.088180: Epoch 702 
2025-03-22 12:37:48.093194: Current learning rate: 0.00336 
2025-03-22 12:38:30.868933: train_loss -0.8845 
2025-03-22 12:38:30.877455: val_loss -0.8455 
2025-03-22 12:38:30.882969: Pseudo dice [np.float64(0.9459), np.float64(0.9305), np.float64(0.9198)] 
2025-03-22 12:38:30.887480: Epoch time: 42.79 s 
2025-03-22 12:38:31.681636:  
2025-03-22 12:38:31.689155: Epoch 703 
2025-03-22 12:38:31.695678: Current learning rate: 0.00335 
2025-03-22 12:39:14.879889: train_loss -0.8734 
2025-03-22 12:39:14.887970: val_loss -0.836 
2025-03-22 12:39:14.894046: Pseudo dice [np.float64(0.9488), np.float64(0.9419), np.float64(0.9156)] 
2025-03-22 12:39:14.901108: Epoch time: 43.2 s 
2025-03-22 12:39:15.661819:  
2025-03-22 12:39:15.668919: Epoch 704 
2025-03-22 12:39:15.671993: Current learning rate: 0.00334 
2025-03-22 12:40:00.226962: train_loss -0.8823 
2025-03-22 12:40:00.237992: val_loss -0.8313 
2025-03-22 12:40:00.244514: Pseudo dice [np.float64(0.9505), np.float64(0.9308), np.float64(0.9161)] 
2025-03-22 12:40:00.249524: Epoch time: 44.57 s 
2025-03-22 12:40:01.059685:  
2025-03-22 12:40:01.065698: Epoch 705 
2025-03-22 12:40:01.070725: Current learning rate: 0.00333 
2025-03-22 12:40:44.220892: train_loss -0.8763 
2025-03-22 12:40:44.228917: val_loss -0.8601 
2025-03-22 12:40:44.235466: Pseudo dice [np.float64(0.9543), np.float64(0.9406), np.float64(0.9259)] 
2025-03-22 12:40:44.242536: Epoch time: 43.16 s 
2025-03-22 12:40:45.033319:  
2025-03-22 12:40:45.039989: Epoch 706 
2025-03-22 12:40:45.044034: Current learning rate: 0.00332 
2025-03-22 12:41:27.895110: train_loss -0.8797 
2025-03-22 12:41:27.904134: val_loss -0.8384 
2025-03-22 12:41:27.910151: Pseudo dice [np.float64(0.9574), np.float64(0.9306), np.float64(0.9162)] 
2025-03-22 12:41:27.915161: Epoch time: 42.86 s 
2025-03-22 12:41:28.983426:  
2025-03-22 12:41:28.990948: Epoch 707 
2025-03-22 12:41:28.994962: Current learning rate: 0.00331 
2025-03-22 12:42:11.829434: train_loss -0.883 
2025-03-22 12:42:11.837462: val_loss -0.8773 
2025-03-22 12:42:11.842477: Pseudo dice [np.float64(0.9559), np.float64(0.9307), np.float64(0.9272)] 
2025-03-22 12:42:11.846987: Epoch time: 42.85 s 
2025-03-22 12:42:12.647058:  
2025-03-22 12:42:12.655083: Epoch 708 
2025-03-22 12:42:12.662102: Current learning rate: 0.0033 
2025-03-22 12:42:55.707269: train_loss -0.8841 
2025-03-22 12:42:55.714788: val_loss -0.8744 
2025-03-22 12:42:55.719802: Pseudo dice [np.float64(0.9499), np.float64(0.9481), np.float64(0.9243)] 
2025-03-22 12:42:55.723313: Epoch time: 43.06 s 
2025-03-22 12:42:56.522857:  
2025-03-22 12:42:56.530457: Epoch 709 
2025-03-22 12:42:56.535472: Current learning rate: 0.00329 
2025-03-22 12:43:39.558666: train_loss -0.8746 
2025-03-22 12:43:39.566786: val_loss -0.8557 
2025-03-22 12:43:39.574450: Pseudo dice [np.float64(0.943), np.float64(0.9285), np.float64(0.9241)] 
2025-03-22 12:43:39.581784: Epoch time: 43.04 s 
2025-03-22 12:43:40.382946:  
2025-03-22 12:43:40.389461: Epoch 710 
2025-03-22 12:43:40.393975: Current learning rate: 0.00328 
2025-03-22 12:44:23.448875: train_loss -0.8859 
2025-03-22 12:44:23.456397: val_loss -0.8739 
2025-03-22 12:44:23.464421: Pseudo dice [np.float64(0.9491), np.float64(0.941), np.float64(0.9216)] 
2025-03-22 12:44:23.470439: Epoch time: 43.07 s 
2025-03-22 12:44:24.247499:  
2025-03-22 12:44:24.253087: Epoch 711 
2025-03-22 12:44:24.257767: Current learning rate: 0.00327 
2025-03-22 12:45:07.320252: train_loss -0.877 
2025-03-22 12:45:07.328300: val_loss -0.8486 
2025-03-22 12:45:07.334327: Pseudo dice [np.float64(0.9502), np.float64(0.95), np.float64(0.9159)] 
2025-03-22 12:45:07.338353: Epoch time: 43.07 s 
2025-03-22 12:45:08.159411:  
2025-03-22 12:45:08.166931: Epoch 712 
2025-03-22 12:45:08.170944: Current learning rate: 0.00326 
2025-03-22 12:45:51.021247: train_loss -0.883 
2025-03-22 12:45:51.028790: val_loss -0.8382 
2025-03-22 12:45:51.036330: Pseudo dice [np.float64(0.9452), np.float64(0.9436), np.float64(0.9216)] 
2025-03-22 12:45:51.043363: Epoch time: 42.86 s 
2025-03-22 12:45:51.831079:  
2025-03-22 12:45:51.837104: Epoch 713 
2025-03-22 12:45:51.840135: Current learning rate: 0.00325 
2025-03-22 12:46:36.444235: train_loss -0.879 
2025-03-22 12:46:36.453255: val_loss -0.8534 
2025-03-22 12:46:36.459780: Pseudo dice [np.float64(0.9469), np.float64(0.94), np.float64(0.9254)] 
2025-03-22 12:46:36.465810: Epoch time: 44.61 s 
2025-03-22 12:46:37.269282:  
2025-03-22 12:46:37.275870: Epoch 714 
2025-03-22 12:46:37.283037: Current learning rate: 0.00324 
2025-03-22 12:47:20.266262: train_loss -0.8892 
2025-03-22 12:47:20.274916: val_loss -0.8804 
2025-03-22 12:47:20.282054: Pseudo dice [np.float64(0.9513), np.float64(0.9535), np.float64(0.9243)] 
2025-03-22 12:47:20.289145: Epoch time: 43.0 s 
2025-03-22 12:47:21.290273:  
2025-03-22 12:47:21.298465: Epoch 715 
2025-03-22 12:47:21.301022: Current learning rate: 0.00323 
2025-03-22 12:48:04.063059: train_loss -0.8749 
2025-03-22 12:48:04.070583: val_loss -0.8613 
2025-03-22 12:48:04.078109: Pseudo dice [np.float64(0.9528), np.float64(0.9504), np.float64(0.9293)] 
2025-03-22 12:48:04.085136: Epoch time: 42.77 s 
2025-03-22 12:48:04.093169: Yayy! New best EMA pseudo Dice: 0.9381 
2025-03-22 12:48:05.010869:  
2025-03-22 12:48:05.017396: Epoch 716 
2025-03-22 12:48:05.020908: Current learning rate: 0.00322 
2025-03-22 12:48:47.956648: train_loss -0.8841 
2025-03-22 12:48:47.965265: val_loss -0.884 
2025-03-22 12:48:47.972850: Pseudo dice [np.float64(0.9492), np.float64(0.9424), np.float64(0.9172)] 
2025-03-22 12:48:47.980437: Epoch time: 42.95 s 
2025-03-22 12:48:48.810222:  
2025-03-22 12:48:48.817867: Epoch 717 
2025-03-22 12:48:48.823984: Current learning rate: 0.00321 
2025-03-22 12:49:31.700287: train_loss -0.8824 
2025-03-22 12:49:31.710364: val_loss -0.8767 
2025-03-22 12:49:31.715383: Pseudo dice [np.float64(0.9562), np.float64(0.9513), np.float64(0.9315)] 
2025-03-22 12:49:31.721401: Epoch time: 42.89 s 
2025-03-22 12:49:31.726417: Yayy! New best EMA pseudo Dice: 0.9388 
2025-03-22 12:49:32.640040:  
2025-03-22 12:49:32.647653: Epoch 718 
2025-03-22 12:49:32.652755: Current learning rate: 0.0032 
2025-03-22 12:50:15.632527: train_loss -0.8882 
2025-03-22 12:50:15.641054: val_loss -0.8595 
2025-03-22 12:50:15.647573: Pseudo dice [np.float64(0.9461), np.float64(0.9366), np.float64(0.9207)] 
2025-03-22 12:50:15.653589: Epoch time: 42.99 s 
2025-03-22 12:50:16.466406:  
2025-03-22 12:50:16.474573: Epoch 719 
2025-03-22 12:50:16.478611: Current learning rate: 0.00319 
2025-03-22 12:50:59.358538: train_loss -0.8794 
2025-03-22 12:50:59.366639: val_loss -0.8344 
2025-03-22 12:50:59.371690: Pseudo dice [np.float64(0.9486), np.float64(0.945), np.float64(0.9203)] 
2025-03-22 12:50:59.375728: Epoch time: 42.89 s 
2025-03-22 12:51:00.176206:  
2025-03-22 12:51:00.181719: Epoch 720 
2025-03-22 12:51:00.186730: Current learning rate: 0.00318 
2025-03-22 12:51:43.278291: train_loss -0.8779 
2025-03-22 12:51:43.285813: val_loss -0.8453 
2025-03-22 12:51:43.293337: Pseudo dice [np.float64(0.9455), np.float64(0.9289), np.float64(0.9113)] 
2025-03-22 12:51:43.300857: Epoch time: 43.1 s 
2025-03-22 12:51:44.052191:  
2025-03-22 12:51:44.059308: Epoch 721 
2025-03-22 12:51:44.063317: Current learning rate: 0.00317 
2025-03-22 12:52:27.331956: train_loss -0.8759 
2025-03-22 12:52:27.340988: val_loss -0.8621 
2025-03-22 12:52:27.349509: Pseudo dice [np.float64(0.944), np.float64(0.9434), np.float64(0.925)] 
2025-03-22 12:52:27.357532: Epoch time: 43.28 s 
2025-03-22 12:52:28.141888:  
2025-03-22 12:52:28.147903: Epoch 722 
2025-03-22 12:52:28.152924: Current learning rate: 0.00316 
2025-03-22 12:53:13.061909: train_loss -0.893 
2025-03-22 12:53:13.070434: val_loss -0.8573 
2025-03-22 12:53:13.076950: Pseudo dice [np.float64(0.9433), np.float64(0.9206), np.float64(0.9115)] 
2025-03-22 12:53:13.081962: Epoch time: 44.92 s 
2025-03-22 12:53:14.151217:  
2025-03-22 12:53:14.158301: Epoch 723 
2025-03-22 12:53:14.163492: Current learning rate: 0.00315 
2025-03-22 12:53:57.274222: train_loss -0.876 
2025-03-22 12:53:57.281736: val_loss -0.8691 
2025-03-22 12:53:57.286745: Pseudo dice [np.float64(0.9518), np.float64(0.9326), np.float64(0.9173)] 
2025-03-22 12:53:57.291756: Epoch time: 43.12 s 
2025-03-22 12:53:58.092801:  
2025-03-22 12:53:58.099679: Epoch 724 
2025-03-22 12:53:58.103231: Current learning rate: 0.00314 
2025-03-22 12:54:40.830919: train_loss -0.8766 
2025-03-22 12:54:40.838437: val_loss -0.8544 
2025-03-22 12:54:40.845452: Pseudo dice [np.float64(0.9426), np.float64(0.9494), np.float64(0.9222)] 
2025-03-22 12:54:40.850461: Epoch time: 42.74 s 
2025-03-22 12:54:41.665159:  
2025-03-22 12:54:41.671811: Epoch 725 
2025-03-22 12:54:41.675386: Current learning rate: 0.00313 
2025-03-22 12:55:24.591549: train_loss -0.8843 
2025-03-22 12:55:24.600650: val_loss -0.8588 
2025-03-22 12:55:24.608326: Pseudo dice [np.float64(0.9589), np.float64(0.9496), np.float64(0.9158)] 
2025-03-22 12:55:24.615931: Epoch time: 42.93 s 
2025-03-22 12:55:25.415242:  
2025-03-22 12:55:25.421883: Epoch 726 
2025-03-22 12:55:25.424420: Current learning rate: 0.00312 
2025-03-22 12:56:08.332528: train_loss -0.8781 
2025-03-22 12:56:08.340090: val_loss -0.8512 
2025-03-22 12:56:08.344617: Pseudo dice [np.float64(0.9518), np.float64(0.9403), np.float64(0.9238)] 
2025-03-22 12:56:08.348645: Epoch time: 42.92 s 
2025-03-22 12:56:09.139293:  
2025-03-22 12:56:09.144812: Epoch 727 
2025-03-22 12:56:09.149826: Current learning rate: 0.00311 
2025-03-22 12:56:52.061601: train_loss -0.8733 
2025-03-22 12:56:52.069143: val_loss -0.8567 
2025-03-22 12:56:52.074212: Pseudo dice [np.float64(0.9514), np.float64(0.9292), np.float64(0.9134)] 
2025-03-22 12:56:52.078757: Epoch time: 42.92 s 
2025-03-22 12:56:52.886340:  
2025-03-22 12:56:52.893942: Epoch 728 
2025-03-22 12:56:52.896993: Current learning rate: 0.0031 
2025-03-22 12:57:35.821517: train_loss -0.8759 
2025-03-22 12:57:35.828595: val_loss -0.8391 
2025-03-22 12:57:35.833718: Pseudo dice [np.float64(0.9447), np.float64(0.9258), np.float64(0.9143)] 
2025-03-22 12:57:35.838244: Epoch time: 42.94 s 
2025-03-22 12:57:36.647717:  
2025-03-22 12:57:36.653765: Epoch 729 
2025-03-22 12:57:36.658778: Current learning rate: 0.00309 
2025-03-22 12:58:19.599468: train_loss -0.8834 
2025-03-22 12:58:19.610001: val_loss -0.8623 
2025-03-22 12:58:19.617520: Pseudo dice [np.float64(0.9496), np.float64(0.9445), np.float64(0.9172)] 
2025-03-22 12:58:19.622030: Epoch time: 42.95 s 
2025-03-22 12:58:20.428347:  
2025-03-22 12:58:20.436936: Epoch 730 
2025-03-22 12:58:20.443097: Current learning rate: 0.00308 
2025-03-22 12:59:03.511690: train_loss -0.8719 
2025-03-22 12:59:03.519820: val_loss -0.8562 
2025-03-22 12:59:03.525407: Pseudo dice [np.float64(0.9556), np.float64(0.9359), np.float64(0.9157)] 
2025-03-22 12:59:03.531487: Epoch time: 43.08 s 
2025-03-22 12:59:04.565112:  
2025-03-22 12:59:04.571740: Epoch 731 
2025-03-22 12:59:04.576331: Current learning rate: 0.00307 
2025-03-22 12:59:48.805208: train_loss -0.8868 
2025-03-22 12:59:48.812727: val_loss -0.8407 
2025-03-22 12:59:48.817739: Pseudo dice [np.float64(0.9494), np.float64(0.9422), np.float64(0.9292)] 
2025-03-22 12:59:48.822749: Epoch time: 44.24 s 
2025-03-22 12:59:49.853583:  
2025-03-22 12:59:49.861123: Epoch 732 
2025-03-22 12:59:49.865654: Current learning rate: 0.00306 
2025-03-22 13:00:32.722012: train_loss -0.8746 
2025-03-22 13:00:32.729167: val_loss -0.8515 
2025-03-22 13:00:32.733826: Pseudo dice [np.float64(0.9488), np.float64(0.9233), np.float64(0.9142)] 
2025-03-22 13:00:32.740038: Epoch time: 42.87 s 
2025-03-22 13:00:33.556779:  
2025-03-22 13:00:33.565308: Epoch 733 
2025-03-22 13:00:33.569318: Current learning rate: 0.00305 
2025-03-22 13:01:16.488029: train_loss -0.876 
2025-03-22 13:01:16.496551: val_loss -0.8418 
2025-03-22 13:01:16.504069: Pseudo dice [np.float64(0.9451), np.float64(0.9264), np.float64(0.9128)] 
2025-03-22 13:01:16.509595: Epoch time: 42.93 s 
2025-03-22 13:01:17.262111:  
2025-03-22 13:01:17.268662: Epoch 734 
2025-03-22 13:01:17.272197: Current learning rate: 0.00304 
2025-03-22 13:02:00.161217: train_loss -0.8783 
2025-03-22 13:02:00.170739: val_loss -0.8673 
2025-03-22 13:02:00.176255: Pseudo dice [np.float64(0.9527), np.float64(0.9322), np.float64(0.913)] 
2025-03-22 13:02:00.183774: Epoch time: 42.9 s 
2025-03-22 13:02:00.959965:  
2025-03-22 13:02:00.965983: Epoch 735 
2025-03-22 13:02:00.972500: Current learning rate: 0.00303 
2025-03-22 13:02:43.838366: train_loss -0.8805 
2025-03-22 13:02:43.845886: val_loss -0.8582 
2025-03-22 13:02:43.850897: Pseudo dice [np.float64(0.9524), np.float64(0.9279), np.float64(0.9159)] 
2025-03-22 13:02:43.854906: Epoch time: 42.88 s 
2025-03-22 13:02:44.662772:  
2025-03-22 13:02:44.669344: Epoch 736 
2025-03-22 13:02:44.674433: Current learning rate: 0.00302 
2025-03-22 13:03:27.601973: train_loss -0.8836 
2025-03-22 13:03:27.609494: val_loss -0.866 
2025-03-22 13:03:27.613003: Pseudo dice [np.float64(0.9501), np.float64(0.9314), np.float64(0.8995)] 
2025-03-22 13:03:27.617015: Epoch time: 42.94 s 
2025-03-22 13:03:28.421302:  
2025-03-22 13:03:28.428342: Epoch 737 
2025-03-22 13:03:28.433359: Current learning rate: 0.00301 
2025-03-22 13:04:11.338835: train_loss -0.8742 
2025-03-22 13:04:11.347356: val_loss -0.8419 
2025-03-22 13:04:11.354874: Pseudo dice [np.float64(0.9464), np.float64(0.9382), np.float64(0.9154)] 
2025-03-22 13:04:11.363908: Epoch time: 42.92 s 
2025-03-22 13:04:12.178818:  
2025-03-22 13:04:12.185833: Epoch 738 
2025-03-22 13:04:12.192357: Current learning rate: 0.003 
2025-03-22 13:04:55.056802: train_loss -0.8789 
2025-03-22 13:04:55.063593: val_loss -0.8434 
2025-03-22 13:04:55.069611: Pseudo dice [np.float64(0.952), np.float64(0.9404), np.float64(0.924)] 
2025-03-22 13:04:55.075620: Epoch time: 42.88 s 
2025-03-22 13:04:55.862689:  
2025-03-22 13:04:55.871246: Epoch 739 
2025-03-22 13:04:55.875286: Current learning rate: 0.00299 
2025-03-22 13:05:38.667012: train_loss -0.884 
2025-03-22 13:05:38.675550: val_loss -0.873 
2025-03-22 13:05:38.680567: Pseudo dice [np.float64(0.9476), np.float64(0.9305), np.float64(0.9191)] 
2025-03-22 13:05:38.685581: Epoch time: 42.81 s 
2025-03-22 13:05:39.723529:  
2025-03-22 13:05:39.731604: Epoch 740 
2025-03-22 13:05:39.735667: Current learning rate: 0.00297 
2025-03-22 13:06:24.275277: train_loss -0.874 
2025-03-22 13:06:24.284301: val_loss -0.8425 
2025-03-22 13:06:24.289316: Pseudo dice [np.float64(0.9515), np.float64(0.9437), np.float64(0.9247)] 
2025-03-22 13:06:24.293825: Epoch time: 44.55 s 
2025-03-22 13:06:25.095955:  
2025-03-22 13:06:25.104166: Epoch 741 
2025-03-22 13:06:25.109801: Current learning rate: 0.00296 
2025-03-22 13:07:08.223424: train_loss -0.8784 
2025-03-22 13:07:08.233452: val_loss -0.8451 
2025-03-22 13:07:08.240469: Pseudo dice [np.float64(0.9535), np.float64(0.9475), np.float64(0.9217)] 
2025-03-22 13:07:08.246543: Epoch time: 43.13 s 
2025-03-22 13:07:09.004869:  
2025-03-22 13:07:09.010967: Epoch 742 
2025-03-22 13:07:09.015542: Current learning rate: 0.00295 
2025-03-22 13:07:52.000939: train_loss -0.8796 
2025-03-22 13:07:52.008971: val_loss -0.8464 
2025-03-22 13:07:52.014994: Pseudo dice [np.float64(0.9448), np.float64(0.9382), np.float64(0.9208)] 
2025-03-22 13:07:52.020012: Epoch time: 43.0 s 
2025-03-22 13:07:52.780398:  
2025-03-22 13:07:52.787073: Epoch 743 
2025-03-22 13:07:52.791234: Current learning rate: 0.00294 
2025-03-22 13:08:35.634259: train_loss -0.8803 
2025-03-22 13:08:35.642840: val_loss -0.8693 
2025-03-22 13:08:35.649897: Pseudo dice [np.float64(0.9443), np.float64(0.9575), np.float64(0.9324)] 
2025-03-22 13:08:35.655448: Epoch time: 42.85 s 
2025-03-22 13:08:36.448955:  
2025-03-22 13:08:36.456001: Epoch 744 
2025-03-22 13:08:36.460611: Current learning rate: 0.00293 
2025-03-22 13:09:19.550818: train_loss -0.8896 
2025-03-22 13:09:19.558336: val_loss -0.8479 
2025-03-22 13:09:19.564389: Pseudo dice [np.float64(0.9525), np.float64(0.9346), np.float64(0.9213)] 
2025-03-22 13:09:19.570907: Epoch time: 43.1 s 
2025-03-22 13:09:20.383363:  
2025-03-22 13:09:20.390951: Epoch 745 
2025-03-22 13:09:20.396595: Current learning rate: 0.00292 
2025-03-22 13:10:03.271138: train_loss -0.8928 
2025-03-22 13:10:03.279662: val_loss -0.8982 
2025-03-22 13:10:03.284675: Pseudo dice [np.float64(0.9553), np.float64(0.9548), np.float64(0.9263)] 
2025-03-22 13:10:03.288685: Epoch time: 42.89 s 
2025-03-22 13:10:04.094798:  
2025-03-22 13:10:04.100420: Epoch 746 
2025-03-22 13:10:04.107011: Current learning rate: 0.00291 
2025-03-22 13:10:47.000194: train_loss -0.8751 
2025-03-22 13:10:47.008259: val_loss -0.8596 
2025-03-22 13:10:47.015339: Pseudo dice [np.float64(0.9555), np.float64(0.9341), np.float64(0.9176)] 
2025-03-22 13:10:47.022917: Epoch time: 42.91 s 
2025-03-22 13:10:48.041570:  
2025-03-22 13:10:48.048753: Epoch 747 
2025-03-22 13:10:48.053311: Current learning rate: 0.0029 
2025-03-22 13:11:30.927732: train_loss -0.8782 
2025-03-22 13:11:30.936257: val_loss -0.8643 
2025-03-22 13:11:30.942777: Pseudo dice [np.float64(0.951), np.float64(0.9487), np.float64(0.9327)] 
2025-03-22 13:11:30.948795: Epoch time: 42.89 s 
2025-03-22 13:11:31.743256:  
2025-03-22 13:11:31.749770: Epoch 748 
2025-03-22 13:11:31.754789: Current learning rate: 0.00289 
2025-03-22 13:12:14.507409: train_loss -0.8863 
2025-03-22 13:12:14.514442: val_loss -0.8736 
2025-03-22 13:12:14.519474: Pseudo dice [np.float64(0.956), np.float64(0.9432), np.float64(0.9244)] 
2025-03-22 13:12:14.525019: Epoch time: 42.76 s 
2025-03-22 13:12:15.329150:  
2025-03-22 13:12:15.336228: Epoch 749 
2025-03-22 13:12:15.342960: Current learning rate: 0.00288 
2025-03-22 13:12:59.676383: train_loss -0.8747 
2025-03-22 13:12:59.684906: val_loss -0.8583 
2025-03-22 13:12:59.692438: Pseudo dice [np.float64(0.9522), np.float64(0.9295), np.float64(0.9192)] 
2025-03-22 13:12:59.699966: Epoch time: 44.35 s 
2025-03-22 13:13:00.628711:  
2025-03-22 13:13:00.635252: Epoch 750 
2025-03-22 13:13:00.641455: Current learning rate: 0.00287 
2025-03-22 13:13:43.793253: train_loss -0.8866 
2025-03-22 13:13:43.801776: val_loss -0.8701 
2025-03-22 13:13:43.806787: Pseudo dice [np.float64(0.9472), np.float64(0.9427), np.float64(0.9265)] 
2025-03-22 13:13:43.811798: Epoch time: 43.17 s 
2025-03-22 13:13:44.620677:  
2025-03-22 13:13:44.626241: Epoch 751 
2025-03-22 13:13:44.631331: Current learning rate: 0.00286 
2025-03-22 13:14:27.400939: train_loss -0.885 
2025-03-22 13:14:27.409456: val_loss -0.8638 
2025-03-22 13:14:27.415977: Pseudo dice [np.float64(0.9503), np.float64(0.9355), np.float64(0.913)] 
2025-03-22 13:14:27.422495: Epoch time: 42.78 s 
2025-03-22 13:14:28.219967:  
2025-03-22 13:14:28.226040: Epoch 752 
2025-03-22 13:14:28.230146: Current learning rate: 0.00285 
2025-03-22 13:15:11.109353: train_loss -0.8811 
2025-03-22 13:15:11.118381: val_loss -0.862 
2025-03-22 13:15:11.125399: Pseudo dice [np.float64(0.9529), np.float64(0.9403), np.float64(0.9259)] 
2025-03-22 13:15:11.131919: Epoch time: 42.89 s 
2025-03-22 13:15:11.934345:  
2025-03-22 13:15:11.941477: Epoch 753 
2025-03-22 13:15:11.947589: Current learning rate: 0.00284 
2025-03-22 13:15:54.995571: train_loss -0.8759 
2025-03-22 13:15:55.004092: val_loss -0.8556 
2025-03-22 13:15:55.010612: Pseudo dice [np.float64(0.9489), np.float64(0.937), np.float64(0.9179)] 
2025-03-22 13:15:55.018135: Epoch time: 43.06 s 
2025-03-22 13:15:55.822200:  
2025-03-22 13:15:55.828729: Epoch 754 
2025-03-22 13:15:55.833748: Current learning rate: 0.00283 
2025-03-22 13:16:38.861675: train_loss -0.8749 
2025-03-22 13:16:38.871707: val_loss -0.8781 
2025-03-22 13:16:38.878221: Pseudo dice [np.float64(0.9576), np.float64(0.9399), np.float64(0.9272)] 
2025-03-22 13:16:38.884233: Epoch time: 43.04 s 
2025-03-22 13:16:39.679181:  
2025-03-22 13:16:39.686196: Epoch 755 
2025-03-22 13:16:39.691206: Current learning rate: 0.00282 
2025-03-22 13:17:22.661688: train_loss -0.8775 
2025-03-22 13:17:22.671166: val_loss -0.8754 
2025-03-22 13:17:22.678688: Pseudo dice [np.float64(0.9519), np.float64(0.9449), np.float64(0.9181)] 
2025-03-22 13:17:22.686215: Epoch time: 42.98 s 
2025-03-22 13:17:23.756546:  
2025-03-22 13:17:23.762058: Epoch 756 
2025-03-22 13:17:23.765566: Current learning rate: 0.00281 
2025-03-22 13:18:06.755376: train_loss -0.8843 
2025-03-22 13:18:06.763404: val_loss -0.8477 
2025-03-22 13:18:06.768425: Pseudo dice [np.float64(0.9491), np.float64(0.9473), np.float64(0.927)] 
2025-03-22 13:18:06.773437: Epoch time: 43.0 s 
2025-03-22 13:18:07.576606:  
2025-03-22 13:18:07.583570: Epoch 757 
2025-03-22 13:18:07.588666: Current learning rate: 0.0028 
2025-03-22 13:18:50.566886: train_loss -0.8775 
2025-03-22 13:18:50.575399: val_loss -0.8421 
2025-03-22 13:18:50.580410: Pseudo dice [np.float64(0.9463), np.float64(0.9493), np.float64(0.9148)] 
2025-03-22 13:18:50.586930: Epoch time: 42.99 s 
2025-03-22 13:18:51.391670:  
2025-03-22 13:18:51.398216: Epoch 758 
2025-03-22 13:18:51.405275: Current learning rate: 0.00279 
2025-03-22 13:19:34.491180: train_loss -0.8777 
2025-03-22 13:19:34.499356: val_loss -0.8483 
2025-03-22 13:19:34.505875: Pseudo dice [np.float64(0.9552), np.float64(0.9431), np.float64(0.9144)] 
2025-03-22 13:19:34.511904: Epoch time: 43.1 s 
2025-03-22 13:19:35.298077:  
2025-03-22 13:19:35.305183: Epoch 759 
2025-03-22 13:19:35.308744: Current learning rate: 0.00278 
2025-03-22 13:20:18.503304: train_loss -0.8846 
2025-03-22 13:20:18.513336: val_loss -0.8615 
2025-03-22 13:20:18.519353: Pseudo dice [np.float64(0.9493), np.float64(0.9346), np.float64(0.9259)] 
2025-03-22 13:20:18.526874: Epoch time: 43.21 s 
2025-03-22 13:20:19.331182:  
2025-03-22 13:20:19.338752: Epoch 760 
2025-03-22 13:20:19.345331: Current learning rate: 0.00277 
2025-03-22 13:21:02.470456: train_loss -0.8856 
2025-03-22 13:21:02.479487: val_loss -0.8683 
2025-03-22 13:21:02.486002: Pseudo dice [np.float64(0.9534), np.float64(0.9343), np.float64(0.9223)] 
2025-03-22 13:21:02.492022: Epoch time: 43.14 s 
2025-03-22 13:21:03.286489:  
2025-03-22 13:21:03.293104: Epoch 761 
2025-03-22 13:21:03.298183: Current learning rate: 0.00276 
2025-03-22 13:21:46.252722: train_loss -0.8829 
2025-03-22 13:21:46.260747: val_loss -0.8713 
2025-03-22 13:21:46.268270: Pseudo dice [np.float64(0.9505), np.float64(0.9411), np.float64(0.9223)] 
2025-03-22 13:21:46.274287: Epoch time: 42.97 s 
2025-03-22 13:21:47.076910:  
2025-03-22 13:21:47.084425: Epoch 762 
2025-03-22 13:21:47.089439: Current learning rate: 0.00275 
2025-03-22 13:22:30.192287: train_loss -0.8754 
2025-03-22 13:22:30.201309: val_loss -0.8737 
2025-03-22 13:22:30.208829: Pseudo dice [np.float64(0.955), np.float64(0.9416), np.float64(0.9237)] 
2025-03-22 13:22:30.214843: Epoch time: 43.12 s 
2025-03-22 13:22:31.210817:  
2025-03-22 13:22:31.218906: Epoch 763 
2025-03-22 13:22:31.223447: Current learning rate: 0.00274 
2025-03-22 13:23:14.144155: train_loss -0.8853 
2025-03-22 13:23:14.152673: val_loss -0.8481 
2025-03-22 13:23:14.159192: Pseudo dice [np.float64(0.95), np.float64(0.9345), np.float64(0.933)] 
2025-03-22 13:23:14.165711: Epoch time: 42.93 s 
2025-03-22 13:23:14.995497:  
2025-03-22 13:23:15.004019: Epoch 764 
2025-03-22 13:23:15.008032: Current learning rate: 0.00273 
2025-03-22 13:23:57.976522: train_loss -0.8824 
2025-03-22 13:23:57.986547: val_loss -0.8433 
2025-03-22 13:23:57.997581: Pseudo dice [np.float64(0.9482), np.float64(0.9241), np.float64(0.9216)] 
2025-03-22 13:23:58.006619: Epoch time: 42.98 s 
2025-03-22 13:23:58.809896:  
2025-03-22 13:23:58.816410: Epoch 765 
2025-03-22 13:23:58.821424: Current learning rate: 0.00272 
2025-03-22 13:24:41.693267: train_loss -0.8853 
2025-03-22 13:24:41.700682: val_loss -0.8361 
2025-03-22 13:24:41.706909: Pseudo dice [np.float64(0.9488), np.float64(0.915), np.float64(0.916)] 
2025-03-22 13:24:41.713488: Epoch time: 42.88 s 
2025-03-22 13:24:42.527968:  
2025-03-22 13:24:42.535058: Epoch 766 
2025-03-22 13:24:42.539627: Current learning rate: 0.00271 
2025-03-22 13:25:25.437549: train_loss -0.8854 
2025-03-22 13:25:25.445569: val_loss -0.8426 
2025-03-22 13:25:25.450579: Pseudo dice [np.float64(0.9504), np.float64(0.9429), np.float64(0.9217)] 
2025-03-22 13:25:25.455590: Epoch time: 42.91 s 
2025-03-22 13:25:26.265651:  
2025-03-22 13:25:26.272164: Epoch 767 
2025-03-22 13:25:26.278177: Current learning rate: 0.0027 
2025-03-22 13:26:09.237086: train_loss -0.8761 
2025-03-22 13:26:09.245600: val_loss -0.8213 
2025-03-22 13:26:09.251630: Pseudo dice [np.float64(0.9452), np.float64(0.9396), np.float64(0.9253)] 
2025-03-22 13:26:09.259246: Epoch time: 42.97 s 
2025-03-22 13:26:10.055362:  
2025-03-22 13:26:10.062427: Epoch 768 
2025-03-22 13:26:10.066491: Current learning rate: 0.00268 
2025-03-22 13:26:53.049667: train_loss -0.8781 
2025-03-22 13:26:53.059691: val_loss -0.8328 
2025-03-22 13:26:53.067212: Pseudo dice [np.float64(0.9464), np.float64(0.9353), np.float64(0.9151)] 
2025-03-22 13:26:53.073724: Epoch time: 42.99 s 
2025-03-22 13:26:53.873991:  
2025-03-22 13:26:53.881562: Epoch 769 
2025-03-22 13:26:53.887631: Current learning rate: 0.00267 
2025-03-22 13:27:37.146098: train_loss -0.8843 
2025-03-22 13:27:37.153622: val_loss -0.8493 
2025-03-22 13:27:37.159633: Pseudo dice [np.float64(0.9528), np.float64(0.9271), np.float64(0.9234)] 
2025-03-22 13:27:37.163643: Epoch time: 43.27 s 
2025-03-22 13:27:37.970124:  
2025-03-22 13:27:37.977650: Epoch 770 
2025-03-22 13:27:37.981658: Current learning rate: 0.00266 
2025-03-22 13:28:20.926079: train_loss -0.8833 
2025-03-22 13:28:20.934603: val_loss -0.8631 
2025-03-22 13:28:20.941118: Pseudo dice [np.float64(0.9539), np.float64(0.954), np.float64(0.9229)] 
2025-03-22 13:28:20.948639: Epoch time: 42.96 s 
2025-03-22 13:28:21.994115:  
2025-03-22 13:28:22.001131: Epoch 771 
2025-03-22 13:28:22.006658: Current learning rate: 0.00265 
2025-03-22 13:29:04.970508: train_loss -0.8827 
2025-03-22 13:29:04.980417: val_loss -0.8513 
2025-03-22 13:29:04.987111: Pseudo dice [np.float64(0.9466), np.float64(0.9354), np.float64(0.9202)] 
2025-03-22 13:29:04.992141: Epoch time: 42.98 s 
2025-03-22 13:29:05.778682:  
2025-03-22 13:29:05.785201: Epoch 772 
2025-03-22 13:29:05.790215: Current learning rate: 0.00264 
2025-03-22 13:29:49.019124: train_loss -0.8844 
2025-03-22 13:29:49.028837: val_loss -0.8536 
2025-03-22 13:29:49.035959: Pseudo dice [np.float64(0.9496), np.float64(0.9352), np.float64(0.9225)] 
2025-03-22 13:29:49.040578: Epoch time: 43.24 s 
2025-03-22 13:29:49.838526:  
2025-03-22 13:29:49.845160: Epoch 773 
2025-03-22 13:29:49.850224: Current learning rate: 0.00263 
2025-03-22 13:30:32.698083: train_loss -0.8797 
2025-03-22 13:30:32.706658: val_loss -0.8598 
2025-03-22 13:30:32.713218: Pseudo dice [np.float64(0.9502), np.float64(0.9063), np.float64(0.9193)] 
2025-03-22 13:30:32.720304: Epoch time: 42.86 s 
2025-03-22 13:30:33.537946:  
2025-03-22 13:30:33.545520: Epoch 774 
2025-03-22 13:30:33.550122: Current learning rate: 0.00262 
2025-03-22 13:31:16.240531: train_loss -0.8849 
2025-03-22 13:31:16.248048: val_loss -0.857 
2025-03-22 13:31:16.253075: Pseudo dice [np.float64(0.9472), np.float64(0.9526), np.float64(0.9321)] 
2025-03-22 13:31:16.257582: Epoch time: 42.7 s 
2025-03-22 13:31:17.063588:  
2025-03-22 13:31:17.071142: Epoch 775 
2025-03-22 13:31:17.076190: Current learning rate: 0.00261 
2025-03-22 13:32:00.006366: train_loss -0.8807 
2025-03-22 13:32:00.016898: val_loss -0.8623 
2025-03-22 13:32:00.024421: Pseudo dice [np.float64(0.9531), np.float64(0.9381), np.float64(0.9237)] 
2025-03-22 13:32:00.029433: Epoch time: 42.94 s 
2025-03-22 13:32:00.856770:  
2025-03-22 13:32:00.863287: Epoch 776 
2025-03-22 13:32:00.866797: Current learning rate: 0.0026 
2025-03-22 13:32:43.937094: train_loss -0.8851 
2025-03-22 13:32:43.944611: val_loss -0.8703 
2025-03-22 13:32:43.949626: Pseudo dice [np.float64(0.9552), np.float64(0.9561), np.float64(0.9284)] 
2025-03-22 13:32:43.955647: Epoch time: 43.08 s 
2025-03-22 13:32:44.740699:  
2025-03-22 13:32:44.747267: Epoch 777 
2025-03-22 13:32:44.750049: Current learning rate: 0.00259 
2025-03-22 13:33:29.711838: train_loss -0.8873 
2025-03-22 13:33:29.719856: val_loss -0.8225 
2025-03-22 13:33:29.724363: Pseudo dice [np.float64(0.9427), np.float64(0.9089), np.float64(0.9061)] 
2025-03-22 13:33:29.729875: Epoch time: 44.97 s 
2025-03-22 13:33:30.578021:  
2025-03-22 13:33:30.585117: Epoch 778 
2025-03-22 13:33:30.590731: Current learning rate: 0.00258 
2025-03-22 13:34:13.582240: train_loss -0.8767 
2025-03-22 13:34:13.589812: val_loss -0.8324 
2025-03-22 13:34:13.594867: Pseudo dice [np.float64(0.9522), np.float64(0.9198), np.float64(0.906)] 
2025-03-22 13:34:13.598522: Epoch time: 43.0 s 
2025-03-22 13:34:14.425673:  
2025-03-22 13:34:14.433206: Epoch 779 
2025-03-22 13:34:14.438240: Current learning rate: 0.00257 
2025-03-22 13:34:57.221177: train_loss -0.8695 
2025-03-22 13:34:57.229697: val_loss -0.8547 
2025-03-22 13:34:57.237247: Pseudo dice [np.float64(0.9447), np.float64(0.9346), np.float64(0.9159)] 
2025-03-22 13:34:57.242277: Epoch time: 42.8 s 
2025-03-22 13:34:58.299774:  
2025-03-22 13:34:58.306829: Epoch 780 
2025-03-22 13:34:58.310494: Current learning rate: 0.00256 
2025-03-22 13:35:41.352934: train_loss -0.8694 
2025-03-22 13:35:41.360457: val_loss -0.8611 
2025-03-22 13:35:41.368090: Pseudo dice [np.float64(0.9526), np.float64(0.9409), np.float64(0.9253)] 
2025-03-22 13:35:41.373319: Epoch time: 43.05 s 
2025-03-22 13:35:42.196249:  
2025-03-22 13:35:42.202769: Epoch 781 
2025-03-22 13:35:42.207783: Current learning rate: 0.00255 
2025-03-22 13:36:25.223977: train_loss -0.8785 
2025-03-22 13:36:25.234011: val_loss -0.8526 
2025-03-22 13:36:25.239529: Pseudo dice [np.float64(0.9497), np.float64(0.9284), np.float64(0.9212)] 
2025-03-22 13:36:25.247054: Epoch time: 43.03 s 
2025-03-22 13:36:26.037779:  
2025-03-22 13:36:26.044868: Epoch 782 
2025-03-22 13:36:26.049994: Current learning rate: 0.00254 
2025-03-22 13:37:08.938081: train_loss -0.8817 
2025-03-22 13:37:08.946684: val_loss -0.8343 
2025-03-22 13:37:08.953219: Pseudo dice [np.float64(0.9381), np.float64(0.9193), np.float64(0.915)] 
2025-03-22 13:37:08.957233: Epoch time: 42.9 s 
2025-03-22 13:37:09.764956:  
2025-03-22 13:37:09.772034: Epoch 783 
2025-03-22 13:37:09.777381: Current learning rate: 0.00253 
2025-03-22 13:37:52.829014: train_loss -0.8885 
2025-03-22 13:37:52.837035: val_loss -0.8498 
2025-03-22 13:37:52.844053: Pseudo dice [np.float64(0.9424), np.float64(0.9396), np.float64(0.9223)] 
2025-03-22 13:37:52.848063: Epoch time: 43.06 s 
2025-03-22 13:37:53.657565:  
2025-03-22 13:37:53.663607: Epoch 784 
2025-03-22 13:37:53.669143: Current learning rate: 0.00252 
2025-03-22 13:38:36.589931: train_loss -0.8895 
2025-03-22 13:38:36.598457: val_loss -0.851 
2025-03-22 13:38:36.603024: Pseudo dice [np.float64(0.9493), np.float64(0.9305), np.float64(0.9251)] 
2025-03-22 13:38:36.607574: Epoch time: 42.93 s 
2025-03-22 13:38:37.422424:  
2025-03-22 13:38:37.428945: Epoch 785 
2025-03-22 13:38:37.433958: Current learning rate: 0.00251 
2025-03-22 13:39:20.359741: train_loss -0.8835 
2025-03-22 13:39:20.368407: val_loss -0.8785 
2025-03-22 13:39:20.373420: Pseudo dice [np.float64(0.9479), np.float64(0.9402), np.float64(0.9161)] 
2025-03-22 13:39:20.376426: Epoch time: 42.94 s 
2025-03-22 13:39:21.198842:  
2025-03-22 13:39:21.206993: Epoch 786 
2025-03-22 13:39:21.213992: Current learning rate: 0.0025 
2025-03-22 13:40:06.329329: train_loss -0.8839 
2025-03-22 13:40:06.338854: val_loss -0.8542 
2025-03-22 13:40:06.344376: Pseudo dice [np.float64(0.9438), np.float64(0.9341), np.float64(0.9257)] 
2025-03-22 13:40:06.351908: Epoch time: 45.13 s 
2025-03-22 13:40:07.401922:  
2025-03-22 13:40:07.408451: Epoch 787 
2025-03-22 13:40:07.411965: Current learning rate: 0.00249 
2025-03-22 13:40:50.625973: train_loss -0.8844 
2025-03-22 13:40:50.633542: val_loss -0.8388 
2025-03-22 13:40:50.641106: Pseudo dice [np.float64(0.9492), np.float64(0.9356), np.float64(0.9215)] 
2025-03-22 13:40:50.647665: Epoch time: 43.23 s 
2025-03-22 13:40:51.449617:  
2025-03-22 13:40:51.455173: Epoch 788 
2025-03-22 13:40:51.460256: Current learning rate: 0.00248 
2025-03-22 13:41:34.374009: train_loss -0.8819 
2025-03-22 13:41:34.381078: val_loss -0.8527 
2025-03-22 13:41:34.384615: Pseudo dice [np.float64(0.9536), np.float64(0.9389), np.float64(0.9153)] 
2025-03-22 13:41:34.388641: Epoch time: 42.92 s 
2025-03-22 13:41:35.229690:  
2025-03-22 13:41:35.237209: Epoch 789 
2025-03-22 13:41:35.242224: Current learning rate: 0.00247 
2025-03-22 13:42:18.409297: train_loss -0.8765 
2025-03-22 13:42:18.418324: val_loss -0.8653 
2025-03-22 13:42:18.424346: Pseudo dice [np.float64(0.9561), np.float64(0.9418), np.float64(0.9196)] 
2025-03-22 13:42:18.430904: Epoch time: 43.18 s 
2025-03-22 13:42:19.225467:  
2025-03-22 13:42:19.234061: Epoch 790 
2025-03-22 13:42:19.239072: Current learning rate: 0.00245 
2025-03-22 13:43:02.270823: train_loss -0.8885 
2025-03-22 13:43:02.277763: val_loss -0.864 
2025-03-22 13:43:02.281832: Pseudo dice [np.float64(0.9515), np.float64(0.9379), np.float64(0.9257)] 
2025-03-22 13:43:02.287001: Epoch time: 43.05 s 
2025-03-22 13:43:03.082961:  
2025-03-22 13:43:03.091519: Epoch 791 
2025-03-22 13:43:03.097583: Current learning rate: 0.00244 
2025-03-22 13:43:46.255241: train_loss -0.8711 
2025-03-22 13:43:46.263777: val_loss -0.8633 
2025-03-22 13:43:46.270298: Pseudo dice [np.float64(0.9506), np.float64(0.9369), np.float64(0.929)] 
2025-03-22 13:43:46.277315: Epoch time: 43.17 s 
2025-03-22 13:43:47.063250:  
2025-03-22 13:43:47.071379: Epoch 792 
2025-03-22 13:43:47.075417: Current learning rate: 0.00243 
2025-03-22 13:44:30.103601: train_loss -0.8844 
2025-03-22 13:44:30.113712: val_loss -0.862 
2025-03-22 13:44:30.120266: Pseudo dice [np.float64(0.9506), np.float64(0.93), np.float64(0.9147)] 
2025-03-22 13:44:30.126337: Epoch time: 43.04 s 
2025-03-22 13:44:30.979005:  
2025-03-22 13:44:30.985566: Epoch 793 
2025-03-22 13:44:30.989103: Current learning rate: 0.00242 
2025-03-22 13:45:13.966881: train_loss -0.8833 
2025-03-22 13:45:13.976907: val_loss -0.8553 
2025-03-22 13:45:13.981919: Pseudo dice [np.float64(0.9512), np.float64(0.9348), np.float64(0.9213)] 
2025-03-22 13:45:13.986455: Epoch time: 42.99 s 
2025-03-22 13:45:14.799525:  
2025-03-22 13:45:14.807161: Epoch 794 
2025-03-22 13:45:14.810299: Current learning rate: 0.00241 
2025-03-22 13:45:57.793805: train_loss -0.8775 
2025-03-22 13:45:57.801470: val_loss -0.8617 
2025-03-22 13:45:57.807042: Pseudo dice [np.float64(0.9484), np.float64(0.9326), np.float64(0.9107)] 
2025-03-22 13:45:57.811587: Epoch time: 42.99 s 
2025-03-22 13:45:58.853884:  
2025-03-22 13:45:58.860054: Epoch 795 
2025-03-22 13:45:58.863613: Current learning rate: 0.0024 
2025-03-22 13:46:43.330349: train_loss -0.8712 
2025-03-22 13:46:43.339407: val_loss -0.8562 
2025-03-22 13:46:43.348542: Pseudo dice [np.float64(0.9524), np.float64(0.9421), np.float64(0.9147)] 
2025-03-22 13:46:43.355710: Epoch time: 44.48 s 
2025-03-22 13:46:44.170535:  
2025-03-22 13:46:44.177575: Epoch 796 
2025-03-22 13:46:44.181600: Current learning rate: 0.00239 
2025-03-22 13:47:27.313332: train_loss -0.8759 
2025-03-22 13:47:27.321668: val_loss -0.8683 
2025-03-22 13:47:27.329257: Pseudo dice [np.float64(0.9479), np.float64(0.9471), np.float64(0.9283)] 
2025-03-22 13:47:27.335828: Epoch time: 43.14 s 
2025-03-22 13:47:28.084649:  
2025-03-22 13:47:28.089531: Epoch 797 
2025-03-22 13:47:28.093044: Current learning rate: 0.00238 
2025-03-22 13:48:11.046179: train_loss -0.8809 
2025-03-22 13:48:11.053843: val_loss -0.8595 
2025-03-22 13:48:11.060932: Pseudo dice [np.float64(0.9484), np.float64(0.947), np.float64(0.9279)] 
2025-03-22 13:48:11.068546: Epoch time: 42.96 s 
2025-03-22 13:48:11.874569:  
2025-03-22 13:48:11.883261: Epoch 798 
2025-03-22 13:48:11.888276: Current learning rate: 0.00237 
2025-03-22 13:48:54.622583: train_loss -0.8571 
2025-03-22 13:48:54.631608: val_loss -0.853 
2025-03-22 13:48:54.637624: Pseudo dice [np.float64(0.9429), np.float64(0.9358), np.float64(0.914)] 
2025-03-22 13:48:54.645149: Epoch time: 42.75 s 
2025-03-22 13:48:55.452818:  
2025-03-22 13:48:55.460916: Epoch 799 
2025-03-22 13:48:55.464956: Current learning rate: 0.00236 
2025-03-22 13:49:38.597992: train_loss -0.8777 
2025-03-22 13:49:38.608219: val_loss -0.8545 
2025-03-22 13:49:38.615402: Pseudo dice [np.float64(0.9441), np.float64(0.9444), np.float64(0.9194)] 
2025-03-22 13:49:38.622328: Epoch time: 43.15 s 
2025-03-22 13:49:39.559979:  
2025-03-22 13:49:39.567540: Epoch 800 
2025-03-22 13:49:39.571569: Current learning rate: 0.00235 
2025-03-22 13:50:22.532934: train_loss -0.877 
2025-03-22 13:50:22.541632: val_loss -0.8542 
2025-03-22 13:50:22.547716: Pseudo dice [np.float64(0.948), np.float64(0.9493), np.float64(0.9216)] 
2025-03-22 13:50:22.551789: Epoch time: 42.97 s 
2025-03-22 13:50:23.354073:  
2025-03-22 13:50:23.361599: Epoch 801 
2025-03-22 13:50:23.366610: Current learning rate: 0.00234 
2025-03-22 13:51:06.209066: train_loss -0.8801 
2025-03-22 13:51:06.216087: val_loss -0.8633 
2025-03-22 13:51:06.221602: Pseudo dice [np.float64(0.9498), np.float64(0.9202), np.float64(0.9201)] 
2025-03-22 13:51:06.226623: Epoch time: 42.86 s 
2025-03-22 13:51:07.025689:  
2025-03-22 13:51:07.035728: Epoch 802 
2025-03-22 13:51:07.042246: Current learning rate: 0.00233 
2025-03-22 13:51:50.035985: train_loss -0.8693 
2025-03-22 13:51:50.043534: val_loss -0.8593 
2025-03-22 13:51:50.050537: Pseudo dice [np.float64(0.953), np.float64(0.9334), np.float64(0.9097)] 
2025-03-22 13:51:50.057561: Epoch time: 43.01 s 
2025-03-22 13:51:51.075463:  
2025-03-22 13:51:51.083583: Epoch 803 
2025-03-22 13:51:51.087138: Current learning rate: 0.00232 
2025-03-22 13:52:34.046978: train_loss -0.8783 
2025-03-22 13:52:34.054507: val_loss -0.8568 
2025-03-22 13:52:34.061527: Pseudo dice [np.float64(0.9486), np.float64(0.9339), np.float64(0.9155)] 
2025-03-22 13:52:34.065546: Epoch time: 42.97 s 
2025-03-22 13:52:34.877012:  
2025-03-22 13:52:34.884038: Epoch 804 
2025-03-22 13:52:34.888091: Current learning rate: 0.00231 
2025-03-22 13:53:19.129792: train_loss -0.8877 
2025-03-22 13:53:19.138827: val_loss -0.8755 
2025-03-22 13:53:19.143852: Pseudo dice [np.float64(0.9549), np.float64(0.9406), np.float64(0.9247)] 
2025-03-22 13:53:19.150364: Epoch time: 44.25 s 
2025-03-22 13:53:19.933506:  
2025-03-22 13:53:19.941112: Epoch 805 
2025-03-22 13:53:19.944167: Current learning rate: 0.0023 
2025-03-22 13:54:03.028660: train_loss -0.8788 
2025-03-22 13:54:03.039198: val_loss -0.8448 
2025-03-22 13:54:03.044209: Pseudo dice [np.float64(0.9494), np.float64(0.9293), np.float64(0.9219)] 
2025-03-22 13:54:03.050224: Epoch time: 43.1 s 
2025-03-22 13:54:03.868882:  
2025-03-22 13:54:03.874909: Epoch 806 
2025-03-22 13:54:03.878917: Current learning rate: 0.00229 
2025-03-22 13:54:47.062778: train_loss -0.8768 
2025-03-22 13:54:47.071298: val_loss -0.8719 
2025-03-22 13:54:47.077815: Pseudo dice [np.float64(0.9539), np.float64(0.9456), np.float64(0.9245)] 
2025-03-22 13:54:47.083825: Epoch time: 43.2 s 
2025-03-22 13:54:47.894334:  
2025-03-22 13:54:47.899848: Epoch 807 
2025-03-22 13:54:47.904860: Current learning rate: 0.00228 
2025-03-22 13:55:30.997991: train_loss -0.8846 
2025-03-22 13:55:31.008023: val_loss -0.8625 
2025-03-22 13:55:31.016548: Pseudo dice [np.float64(0.9564), np.float64(0.9296), np.float64(0.9237)] 
2025-03-22 13:55:31.022560: Epoch time: 43.1 s 
2025-03-22 13:55:31.842278:  
2025-03-22 13:55:31.849380: Epoch 808 
2025-03-22 13:55:31.854446: Current learning rate: 0.00226 
2025-03-22 13:56:14.757257: train_loss -0.8882 
2025-03-22 13:56:14.767319: val_loss -0.8536 
2025-03-22 13:56:14.774839: Pseudo dice [np.float64(0.9435), np.float64(0.9322), np.float64(0.9264)] 
2025-03-22 13:56:14.779853: Epoch time: 42.92 s 
2025-03-22 13:56:15.563120:  
2025-03-22 13:56:15.570136: Epoch 809 
2025-03-22 13:56:15.575146: Current learning rate: 0.00225 
2025-03-22 13:56:58.532277: train_loss -0.883 
2025-03-22 13:56:58.539794: val_loss -0.8601 
2025-03-22 13:56:58.545812: Pseudo dice [np.float64(0.9534), np.float64(0.94), np.float64(0.9191)] 
2025-03-22 13:56:58.551825: Epoch time: 42.97 s 
2025-03-22 13:56:59.365638:  
2025-03-22 13:56:59.373162: Epoch 810 
2025-03-22 13:56:59.376171: Current learning rate: 0.00224 
2025-03-22 13:57:42.293291: train_loss -0.8859 
2025-03-22 13:57:42.299817: val_loss -0.8404 
2025-03-22 13:57:42.304840: Pseudo dice [np.float64(0.9506), np.float64(0.9386), np.float64(0.9052)] 
2025-03-22 13:57:42.310857: Epoch time: 42.93 s 
2025-03-22 13:57:43.337849:  
2025-03-22 13:57:43.343874: Epoch 811 
2025-03-22 13:57:43.347385: Current learning rate: 0.00223 
2025-03-22 13:58:26.085541: train_loss -0.8835 
2025-03-22 13:58:26.093063: val_loss -0.8552 
2025-03-22 13:58:26.102114: Pseudo dice [np.float64(0.9549), np.float64(0.9119), np.float64(0.9199)] 
2025-03-22 13:58:26.109632: Epoch time: 42.75 s 
2025-03-22 13:58:26.926701:  
2025-03-22 13:58:26.932216: Epoch 812 
2025-03-22 13:58:26.937230: Current learning rate: 0.00222 
2025-03-22 13:59:09.903175: train_loss -0.877 
2025-03-22 13:59:09.912201: val_loss -0.8617 
2025-03-22 13:59:09.919257: Pseudo dice [np.float64(0.9524), np.float64(0.9392), np.float64(0.9186)] 
2025-03-22 13:59:09.925779: Epoch time: 42.98 s 
2025-03-22 13:59:10.752209:  
2025-03-22 13:59:10.757730: Epoch 813 
2025-03-22 13:59:10.762742: Current learning rate: 0.00221 
2025-03-22 13:59:54.907550: train_loss -0.8809 
2025-03-22 13:59:54.916080: val_loss -0.8594 
2025-03-22 13:59:54.923604: Pseudo dice [np.float64(0.9494), np.float64(0.9395), np.float64(0.9224)] 
2025-03-22 13:59:54.932632: Epoch time: 44.16 s 
2025-03-22 13:59:55.781432:  
2025-03-22 13:59:55.788450: Epoch 814 
2025-03-22 13:59:55.792466: Current learning rate: 0.0022 
2025-03-22 14:00:38.932434: train_loss -0.8739 
2025-03-22 14:00:38.940958: val_loss -0.8581 
2025-03-22 14:00:38.947477: Pseudo dice [np.float64(0.9451), np.float64(0.9381), np.float64(0.9251)] 
2025-03-22 14:00:38.952492: Epoch time: 43.15 s 
2025-03-22 14:00:39.772062:  
2025-03-22 14:00:39.779646: Epoch 815 
2025-03-22 14:00:39.785230: Current learning rate: 0.00219 
2025-03-22 14:01:22.619722: train_loss -0.877 
2025-03-22 14:01:22.628245: val_loss -0.8332 
2025-03-22 14:01:22.636318: Pseudo dice [np.float64(0.946), np.float64(0.9233), np.float64(0.9065)] 
2025-03-22 14:01:22.643337: Epoch time: 42.85 s 
2025-03-22 14:01:23.451889:  
2025-03-22 14:01:23.460014: Epoch 816 
2025-03-22 14:01:23.464029: Current learning rate: 0.00218 
2025-03-22 14:02:06.556365: train_loss -0.8823 
2025-03-22 14:02:06.566396: val_loss -0.8601 
2025-03-22 14:02:06.572913: Pseudo dice [np.float64(0.9557), np.float64(0.9244), np.float64(0.9265)] 
2025-03-22 14:02:06.579930: Epoch time: 43.1 s 
2025-03-22 14:02:07.356520:  
2025-03-22 14:02:07.362036: Epoch 817 
2025-03-22 14:02:07.367047: Current learning rate: 0.00217 
2025-03-22 14:02:50.285673: train_loss -0.8931 
2025-03-22 14:02:50.293194: val_loss -0.8621 
2025-03-22 14:02:50.298206: Pseudo dice [np.float64(0.9536), np.float64(0.9354), np.float64(0.9204)] 
2025-03-22 14:02:50.304218: Epoch time: 42.93 s 
2025-03-22 14:02:51.131247:  
2025-03-22 14:02:51.138876: Epoch 818 
2025-03-22 14:02:51.142911: Current learning rate: 0.00216 
2025-03-22 14:03:34.185186: train_loss -0.8773 
2025-03-22 14:03:34.194085: val_loss -0.8607 
2025-03-22 14:03:34.200606: Pseudo dice [np.float64(0.9501), np.float64(0.9396), np.float64(0.9216)] 
2025-03-22 14:03:34.208130: Epoch time: 43.05 s 
2025-03-22 14:03:35.256767:  
2025-03-22 14:03:35.264360: Epoch 819 
2025-03-22 14:03:35.267460: Current learning rate: 0.00215 
2025-03-22 14:04:18.131620: train_loss -0.8826 
2025-03-22 14:04:18.138651: val_loss -0.8646 
2025-03-22 14:04:18.143717: Pseudo dice [np.float64(0.941), np.float64(0.9429), np.float64(0.9205)] 
2025-03-22 14:04:18.147752: Epoch time: 42.87 s 
2025-03-22 14:04:18.902098:  
2025-03-22 14:04:18.908667: Epoch 820 
2025-03-22 14:04:18.913238: Current learning rate: 0.00214 
2025-03-22 14:05:01.774022: train_loss -0.8808 
2025-03-22 14:05:01.782090: val_loss -0.8503 
2025-03-22 14:05:01.789665: Pseudo dice [np.float64(0.9441), np.float64(0.9432), np.float64(0.9201)] 
2025-03-22 14:05:01.795210: Epoch time: 42.87 s 
2025-03-22 14:05:02.572759:  
2025-03-22 14:05:02.579403: Epoch 821 
2025-03-22 14:05:02.583966: Current learning rate: 0.00213 
2025-03-22 14:05:45.708658: train_loss -0.8855 
2025-03-22 14:05:45.716788: val_loss -0.8715 
2025-03-22 14:05:45.724908: Pseudo dice [np.float64(0.9526), np.float64(0.937), np.float64(0.925)] 
2025-03-22 14:05:45.730922: Epoch time: 43.14 s 
2025-03-22 14:05:46.495727:  
2025-03-22 14:05:46.502875: Epoch 822 
2025-03-22 14:05:46.506890: Current learning rate: 0.00212 
2025-03-22 14:06:31.039049: train_loss -0.877 
2025-03-22 14:06:31.047155: val_loss -0.8688 
2025-03-22 14:06:31.051699: Pseudo dice [np.float64(0.9507), np.float64(0.9206), np.float64(0.9275)] 
2025-03-22 14:06:31.055788: Epoch time: 44.54 s 
2025-03-22 14:06:31.836437:  
2025-03-22 14:06:31.842961: Epoch 823 
2025-03-22 14:06:31.848976: Current learning rate: 0.0021 
2025-03-22 14:07:14.784262: train_loss -0.8791 
2025-03-22 14:07:14.791781: val_loss -0.8651 
2025-03-22 14:07:14.796795: Pseudo dice [np.float64(0.9575), np.float64(0.9453), np.float64(0.9272)] 
2025-03-22 14:07:14.803311: Epoch time: 42.95 s 
2025-03-22 14:07:15.587708:  
2025-03-22 14:07:15.594357: Epoch 824 
2025-03-22 14:07:15.598386: Current learning rate: 0.00209 
2025-03-22 14:07:58.531439: train_loss -0.8827 
2025-03-22 14:07:58.538967: val_loss -0.8623 
2025-03-22 14:07:58.543982: Pseudo dice [np.float64(0.9528), np.float64(0.9361), np.float64(0.9234)] 
2025-03-22 14:07:58.548539: Epoch time: 42.94 s 
2025-03-22 14:07:59.337552:  
2025-03-22 14:07:59.344073: Epoch 825 
2025-03-22 14:07:59.349085: Current learning rate: 0.00208 
2025-03-22 14:08:42.328562: train_loss -0.884 
2025-03-22 14:08:42.336082: val_loss -0.8642 
2025-03-22 14:08:42.342102: Pseudo dice [np.float64(0.9522), np.float64(0.9436), np.float64(0.9211)] 
2025-03-22 14:08:42.348639: Epoch time: 42.99 s 
2025-03-22 14:08:43.139829:  
2025-03-22 14:08:43.147389: Epoch 826 
2025-03-22 14:08:43.151946: Current learning rate: 0.00207 
2025-03-22 14:09:25.855720: train_loss -0.8915 
2025-03-22 14:09:25.863841: val_loss -0.8692 
2025-03-22 14:09:25.870895: Pseudo dice [np.float64(0.9485), np.float64(0.9339), np.float64(0.9124)] 
2025-03-22 14:09:25.876914: Epoch time: 42.72 s 
2025-03-22 14:09:26.653489:  
2025-03-22 14:09:26.662099: Epoch 827 
2025-03-22 14:09:26.667772: Current learning rate: 0.00206 
2025-03-22 14:10:09.718222: train_loss -0.8789 
2025-03-22 14:10:09.725745: val_loss -0.8586 
2025-03-22 14:10:09.733262: Pseudo dice [np.float64(0.95), np.float64(0.9358), np.float64(0.9199)] 
2025-03-22 14:10:09.737269: Epoch time: 43.06 s 
2025-03-22 14:10:10.743564:  
2025-03-22 14:10:10.751588: Epoch 828 
2025-03-22 14:10:10.755098: Current learning rate: 0.00205 
2025-03-22 14:10:53.615793: train_loss -0.8776 
2025-03-22 14:10:53.623311: val_loss -0.8488 
2025-03-22 14:10:53.629832: Pseudo dice [np.float64(0.9479), np.float64(0.9354), np.float64(0.926)] 
2025-03-22 14:10:53.635851: Epoch time: 42.87 s 
2025-03-22 14:10:54.419122:  
2025-03-22 14:10:54.427799: Epoch 829 
2025-03-22 14:10:54.435321: Current learning rate: 0.00204 
2025-03-22 14:11:37.509603: train_loss -0.8813 
2025-03-22 14:11:37.517134: val_loss -0.8522 
2025-03-22 14:11:37.523656: Pseudo dice [np.float64(0.9461), np.float64(0.9246), np.float64(0.9143)] 
2025-03-22 14:11:37.530176: Epoch time: 43.09 s 
2025-03-22 14:11:38.319245:  
2025-03-22 14:11:38.325869: Epoch 830 
2025-03-22 14:11:38.329929: Current learning rate: 0.00203 
2025-03-22 14:12:21.182368: train_loss -0.8847 
2025-03-22 14:12:21.189953: val_loss -0.8483 
2025-03-22 14:12:21.195970: Pseudo dice [np.float64(0.9521), np.float64(0.9201), np.float64(0.9164)] 
2025-03-22 14:12:21.199981: Epoch time: 42.86 s 
2025-03-22 14:12:21.978129:  
2025-03-22 14:12:21.985254: Epoch 831 
2025-03-22 14:12:21.991894: Current learning rate: 0.00202 
2025-03-22 14:13:06.487345: train_loss -0.8854 
2025-03-22 14:13:06.496410: val_loss -0.8539 
2025-03-22 14:13:06.502511: Pseudo dice [np.float64(0.9544), np.float64(0.9518), np.float64(0.9173)] 
2025-03-22 14:13:06.508104: Epoch time: 44.51 s 
2025-03-22 14:13:07.264142:  
2025-03-22 14:13:07.269666: Epoch 832 
2025-03-22 14:13:07.277719: Current learning rate: 0.00201 
2025-03-22 14:13:50.259224: train_loss -0.8879 
2025-03-22 14:13:50.266249: val_loss -0.8348 
2025-03-22 14:13:50.271267: Pseudo dice [np.float64(0.9447), np.float64(0.9186), np.float64(0.9097)] 
2025-03-22 14:13:50.277795: Epoch time: 43.0 s 
2025-03-22 14:13:51.052744:  
2025-03-22 14:13:51.059884: Epoch 833 
2025-03-22 14:13:51.063929: Current learning rate: 0.002 
2025-03-22 14:14:34.183437: train_loss -0.8765 
2025-03-22 14:14:34.191960: val_loss -0.8499 
2025-03-22 14:14:34.197971: Pseudo dice [np.float64(0.9509), np.float64(0.9349), np.float64(0.9078)] 
2025-03-22 14:14:34.203485: Epoch time: 43.13 s 
2025-03-22 14:14:34.973488:  
2025-03-22 14:14:34.980057: Epoch 834 
2025-03-22 14:14:34.985168: Current learning rate: 0.00199 
2025-03-22 14:15:17.866931: train_loss -0.893 
2025-03-22 14:15:17.875056: val_loss -0.8446 
2025-03-22 14:15:17.884079: Pseudo dice [np.float64(0.9489), np.float64(0.9385), np.float64(0.9229)] 
2025-03-22 14:15:17.890094: Epoch time: 42.89 s 
2025-03-22 14:15:18.668809:  
2025-03-22 14:15:18.676832: Epoch 835 
2025-03-22 14:15:18.681847: Current learning rate: 0.00198 
2025-03-22 14:16:01.666912: train_loss -0.8855 
2025-03-22 14:16:01.674985: val_loss -0.8321 
2025-03-22 14:16:01.680441: Pseudo dice [np.float64(0.9454), np.float64(0.9381), np.float64(0.9232)] 
2025-03-22 14:16:01.684914: Epoch time: 43.0 s 
2025-03-22 14:16:02.666426:  
2025-03-22 14:16:02.672981: Epoch 836 
2025-03-22 14:16:02.678033: Current learning rate: 0.00196 
2025-03-22 14:16:45.682196: train_loss -0.8842 
2025-03-22 14:16:45.689718: val_loss -0.852 
2025-03-22 14:16:45.696234: Pseudo dice [np.float64(0.9474), np.float64(0.9402), np.float64(0.9185)] 
2025-03-22 14:16:45.701247: Epoch time: 43.02 s 
2025-03-22 14:16:46.489805:  
2025-03-22 14:16:46.496326: Epoch 837 
2025-03-22 14:16:46.502337: Current learning rate: 0.00195 
2025-03-22 14:17:29.535273: train_loss -0.8826 
2025-03-22 14:17:29.543383: val_loss -0.8615 
2025-03-22 14:17:29.549476: Pseudo dice [np.float64(0.9548), np.float64(0.9422), np.float64(0.9166)] 
2025-03-22 14:17:29.554994: Epoch time: 43.05 s 
2025-03-22 14:17:30.327737:  
2025-03-22 14:17:30.334803: Epoch 838 
2025-03-22 14:17:30.340333: Current learning rate: 0.00194 
2025-03-22 14:18:13.182710: train_loss -0.8845 
2025-03-22 14:18:13.192157: val_loss -0.859 
2025-03-22 14:18:13.199287: Pseudo dice [np.float64(0.9512), np.float64(0.9359), np.float64(0.9216)] 
2025-03-22 14:18:13.206912: Epoch time: 42.85 s 
2025-03-22 14:18:13.987861:  
2025-03-22 14:18:13.995431: Epoch 839 
2025-03-22 14:18:14.000654: Current learning rate: 0.00193 
2025-03-22 14:18:56.945666: train_loss -0.8856 
2025-03-22 14:18:56.953234: val_loss -0.8538 
2025-03-22 14:18:56.959790: Pseudo dice [np.float64(0.9504), np.float64(0.9457), np.float64(0.9227)] 
2025-03-22 14:18:56.965338: Epoch time: 42.96 s 
2025-03-22 14:18:57.707758:  
2025-03-22 14:18:57.714282: Epoch 840 
2025-03-22 14:18:57.720804: Current learning rate: 0.00192 
2025-03-22 14:19:41.900800: train_loss -0.8813 
2025-03-22 14:19:41.910482: val_loss -0.8614 
2025-03-22 14:19:41.916592: Pseudo dice [np.float64(0.9465), np.float64(0.9371), np.float64(0.915)] 
2025-03-22 14:19:41.923173: Epoch time: 44.19 s 
2025-03-22 14:19:42.674025:  
2025-03-22 14:19:42.679663: Epoch 841 
2025-03-22 14:19:42.687304: Current learning rate: 0.00191 
2025-03-22 14:20:25.625536: train_loss -0.8776 
2025-03-22 14:20:25.634051: val_loss -0.8507 
2025-03-22 14:20:25.640568: Pseudo dice [np.float64(0.95), np.float64(0.9391), np.float64(0.9199)] 
2025-03-22 14:20:25.644574: Epoch time: 42.95 s 
2025-03-22 14:20:26.416815:  
2025-03-22 14:20:26.424891: Epoch 842 
2025-03-22 14:20:26.429963: Current learning rate: 0.0019 
2025-03-22 14:21:09.419614: train_loss -0.8829 
2025-03-22 14:21:09.427640: val_loss -0.8424 
2025-03-22 14:21:09.432656: Pseudo dice [np.float64(0.9502), np.float64(0.934), np.float64(0.9194)] 
2025-03-22 14:21:09.437168: Epoch time: 43.0 s 
2025-03-22 14:21:10.194540:  
2025-03-22 14:21:10.201090: Epoch 843 
2025-03-22 14:21:10.206137: Current learning rate: 0.00189 
2025-03-22 14:21:52.985079: train_loss -0.8814 
2025-03-22 14:21:52.993186: val_loss -0.8759 
2025-03-22 14:21:53.000734: Pseudo dice [np.float64(0.9505), np.float64(0.9397), np.float64(0.9237)] 
2025-03-22 14:21:53.005758: Epoch time: 42.79 s 
2025-03-22 14:21:53.785134:  
2025-03-22 14:21:53.792893: Epoch 844 
2025-03-22 14:21:53.799580: Current learning rate: 0.00188 
2025-03-22 14:22:36.947622: train_loss -0.8849 
2025-03-22 14:22:36.955144: val_loss -0.8369 
2025-03-22 14:22:36.961158: Pseudo dice [np.float64(0.9573), np.float64(0.911), np.float64(0.9284)] 
2025-03-22 14:22:36.966674: Epoch time: 43.16 s 
2025-03-22 14:22:37.990087:  
2025-03-22 14:22:37.996687: Epoch 845 
2025-03-22 14:22:38.002824: Current learning rate: 0.00187 
2025-03-22 14:23:20.932786: train_loss -0.8826 
2025-03-22 14:23:20.940909: val_loss -0.8513 
2025-03-22 14:23:20.947937: Pseudo dice [np.float64(0.9551), np.float64(0.9496), np.float64(0.9228)] 
2025-03-22 14:23:20.955980: Epoch time: 42.94 s 
2025-03-22 14:23:21.746880:  
2025-03-22 14:23:21.752894: Epoch 846 
2025-03-22 14:23:21.757907: Current learning rate: 0.00186 
2025-03-22 14:24:04.753755: train_loss -0.8978 
2025-03-22 14:24:04.762600: val_loss -0.8799 
2025-03-22 14:24:04.767951: Pseudo dice [np.float64(0.9574), np.float64(0.9359), np.float64(0.921)] 
2025-03-22 14:24:04.771713: Epoch time: 43.01 s 
2025-03-22 14:24:05.528531:  
2025-03-22 14:24:05.535094: Epoch 847 
2025-03-22 14:24:05.538649: Current learning rate: 0.00185 
2025-03-22 14:24:48.634502: train_loss -0.8854 
2025-03-22 14:24:48.641349: val_loss -0.8627 
2025-03-22 14:24:48.646628: Pseudo dice [np.float64(0.9575), np.float64(0.9324), np.float64(0.9154)] 
2025-03-22 14:24:48.650700: Epoch time: 43.11 s 
2025-03-22 14:24:49.418387:  
2025-03-22 14:24:49.425456: Epoch 848 
2025-03-22 14:24:49.431061: Current learning rate: 0.00184 
2025-03-22 14:25:32.524019: train_loss -0.879 
2025-03-22 14:25:32.533035: val_loss -0.8697 
2025-03-22 14:25:32.540550: Pseudo dice [np.float64(0.9512), np.float64(0.9473), np.float64(0.9268)] 
2025-03-22 14:25:32.546142: Epoch time: 43.11 s 
2025-03-22 14:25:33.320353:  
2025-03-22 14:25:33.325918: Epoch 849 
2025-03-22 14:25:33.330003: Current learning rate: 0.00182 
2025-03-22 14:26:16.187905: train_loss -0.8831 
2025-03-22 14:26:16.195428: val_loss -0.8492 
2025-03-22 14:26:16.201951: Pseudo dice [np.float64(0.9539), np.float64(0.9449), np.float64(0.9234)] 
2025-03-22 14:26:16.206965: Epoch time: 42.87 s 
2025-03-22 14:26:17.097764:  
2025-03-22 14:26:17.104331: Epoch 850 
2025-03-22 14:26:17.109453: Current learning rate: 0.00181 
2025-03-22 14:27:00.496088: train_loss -0.8932 
2025-03-22 14:27:00.503604: val_loss -0.8305 
2025-03-22 14:27:00.507611: Pseudo dice [np.float64(0.9476), np.float64(0.9414), np.float64(0.9231)] 
2025-03-22 14:27:00.511119: Epoch time: 43.4 s 
2025-03-22 14:27:01.291353:  
2025-03-22 14:27:01.298409: Epoch 851 
2025-03-22 14:27:01.302453: Current learning rate: 0.0018 
2025-03-22 14:27:44.533731: train_loss -0.8857 
2025-03-22 14:27:44.542285: val_loss -0.8524 
2025-03-22 14:27:44.548883: Pseudo dice [np.float64(0.9537), np.float64(0.9311), np.float64(0.9219)] 
2025-03-22 14:27:44.555934: Epoch time: 43.24 s 
2025-03-22 14:27:45.349267:  
2025-03-22 14:27:45.355708: Epoch 852 
2025-03-22 14:27:45.360903: Current learning rate: 0.00179 
2025-03-22 14:28:28.465847: train_loss -0.897 
2025-03-22 14:28:28.472866: val_loss -0.8501 
2025-03-22 14:28:28.478381: Pseudo dice [np.float64(0.9492), np.float64(0.9428), np.float64(0.9234)] 
2025-03-22 14:28:28.484399: Epoch time: 43.12 s 
2025-03-22 14:28:29.477831:  
2025-03-22 14:28:29.484352: Epoch 853 
2025-03-22 14:28:29.489363: Current learning rate: 0.00178 
2025-03-22 14:29:12.547014: train_loss -0.886 
2025-03-22 14:29:12.555573: val_loss -0.8757 
2025-03-22 14:29:12.563637: Pseudo dice [np.float64(0.9568), np.float64(0.9488), np.float64(0.931)] 
2025-03-22 14:29:12.570199: Epoch time: 43.07 s 
2025-03-22 14:29:13.333129:  
2025-03-22 14:29:13.340808: Epoch 854 
2025-03-22 14:29:13.344343: Current learning rate: 0.00177 
2025-03-22 14:29:56.339304: train_loss -0.8855 
2025-03-22 14:29:56.346824: val_loss -0.8566 
2025-03-22 14:29:56.352341: Pseudo dice [np.float64(0.9534), np.float64(0.9482), np.float64(0.92)] 
2025-03-22 14:29:56.358361: Epoch time: 43.01 s 
2025-03-22 14:29:57.091713:  
2025-03-22 14:29:57.098768: Epoch 855 
2025-03-22 14:29:57.102813: Current learning rate: 0.00176 
2025-03-22 14:30:40.004649: train_loss -0.8919 
2025-03-22 14:30:40.012177: val_loss -0.8676 
2025-03-22 14:30:40.021707: Pseudo dice [np.float64(0.9506), np.float64(0.9406), np.float64(0.9222)] 
2025-03-22 14:30:40.028748: Epoch time: 42.91 s 
2025-03-22 14:30:40.771976:  
2025-03-22 14:30:40.778497: Epoch 856 
2025-03-22 14:30:40.782003: Current learning rate: 0.00175 
2025-03-22 14:31:23.887290: train_loss -0.887 
2025-03-22 14:31:23.895814: val_loss -0.8749 
2025-03-22 14:31:23.901330: Pseudo dice [np.float64(0.9546), np.float64(0.9302), np.float64(0.9215)] 
2025-03-22 14:31:23.908350: Epoch time: 43.12 s 
2025-03-22 14:31:24.666825:  
2025-03-22 14:31:24.673370: Epoch 857 
2025-03-22 14:31:24.678421: Current learning rate: 0.00174 
2025-03-22 14:32:07.852123: train_loss -0.8978 
2025-03-22 14:32:07.859646: val_loss -0.8497 
2025-03-22 14:32:07.865664: Pseudo dice [np.float64(0.9522), np.float64(0.9434), np.float64(0.9235)] 
2025-03-22 14:32:07.873191: Epoch time: 43.19 s 
2025-03-22 14:32:08.641332:  
2025-03-22 14:32:08.647964: Epoch 858 
2025-03-22 14:32:08.652531: Current learning rate: 0.00173 
2025-03-22 14:32:51.497992: train_loss -0.8923 
2025-03-22 14:32:51.505051: val_loss -0.8587 
2025-03-22 14:32:51.509090: Pseudo dice [np.float64(0.9408), np.float64(0.937), np.float64(0.9223)] 
2025-03-22 14:32:51.513119: Epoch time: 42.86 s 
2025-03-22 14:32:52.263403:  
2025-03-22 14:32:52.270493: Epoch 859 
2025-03-22 14:32:52.275648: Current learning rate: 0.00172 
2025-03-22 14:33:37.210867: train_loss -0.887 
2025-03-22 14:33:37.219389: val_loss -0.8647 
2025-03-22 14:33:37.225402: Pseudo dice [np.float64(0.9505), np.float64(0.9447), np.float64(0.918)] 
2025-03-22 14:33:37.229420: Epoch time: 44.95 s 
2025-03-22 14:33:38.001480:  
2025-03-22 14:33:38.009028: Epoch 860 
2025-03-22 14:33:38.012572: Current learning rate: 0.0017 
2025-03-22 14:34:21.035530: train_loss -0.8936 
2025-03-22 14:34:21.043229: val_loss -0.8577 
2025-03-22 14:34:21.048821: Pseudo dice [np.float64(0.9512), np.float64(0.9454), np.float64(0.9259)] 
2025-03-22 14:34:21.053943: Epoch time: 43.03 s 
2025-03-22 14:34:21.813946:  
2025-03-22 14:34:21.819541: Epoch 861 
2025-03-22 14:34:21.824091: Current learning rate: 0.00169 
2025-03-22 14:35:04.790014: train_loss -0.8899 
2025-03-22 14:35:04.797533: val_loss -0.8719 
2025-03-22 14:35:04.802543: Pseudo dice [np.float64(0.9551), np.float64(0.9445), np.float64(0.9222)] 
2025-03-22 14:35:04.806051: Epoch time: 42.98 s 
2025-03-22 14:35:05.827147:  
2025-03-22 14:35:05.836289: Epoch 862 
2025-03-22 14:35:05.840822: Current learning rate: 0.00168 
2025-03-22 14:35:48.705464: train_loss -0.8891 
2025-03-22 14:35:48.713109: val_loss -0.874 
2025-03-22 14:35:48.719198: Pseudo dice [np.float64(0.9489), np.float64(0.9421), np.float64(0.9192)] 
2025-03-22 14:35:48.723762: Epoch time: 42.88 s 
2025-03-22 14:35:49.496650:  
2025-03-22 14:35:49.503167: Epoch 863 
2025-03-22 14:35:49.507176: Current learning rate: 0.00167 
2025-03-22 14:36:32.339412: train_loss -0.8905 
2025-03-22 14:36:32.348941: val_loss -0.8399 
2025-03-22 14:36:32.354036: Pseudo dice [np.float64(0.9508), np.float64(0.9201), np.float64(0.9013)] 
2025-03-22 14:36:32.360058: Epoch time: 42.84 s 
2025-03-22 14:36:33.097020:  
2025-03-22 14:36:33.103616: Epoch 864 
2025-03-22 14:36:33.108695: Current learning rate: 0.00166 
2025-03-22 14:37:16.150731: train_loss -0.8836 
2025-03-22 14:37:16.160762: val_loss -0.8577 
2025-03-22 14:37:16.168791: Pseudo dice [np.float64(0.9543), np.float64(0.9464), np.float64(0.9216)] 
2025-03-22 14:37:16.176310: Epoch time: 43.05 s 
2025-03-22 14:37:16.952385:  
2025-03-22 14:37:16.960989: Epoch 865 
2025-03-22 14:37:16.967173: Current learning rate: 0.00165 
2025-03-22 14:38:00.040511: train_loss -0.8794 
2025-03-22 14:38:00.050783: val_loss -0.8786 
2025-03-22 14:38:00.060138: Pseudo dice [np.float64(0.9528), np.float64(0.9244), np.float64(0.9148)] 
2025-03-22 14:38:00.067693: Epoch time: 43.09 s 
2025-03-22 14:38:00.833166:  
2025-03-22 14:38:00.840768: Epoch 866 
2025-03-22 14:38:00.844372: Current learning rate: 0.00164 
2025-03-22 14:38:43.566399: train_loss -0.8789 
2025-03-22 14:38:43.574670: val_loss -0.8751 
2025-03-22 14:38:43.579688: Pseudo dice [np.float64(0.9544), np.float64(0.956), np.float64(0.9266)] 
2025-03-22 14:38:43.584703: Epoch time: 42.73 s 
2025-03-22 14:38:44.350185:  
2025-03-22 14:38:44.356830: Epoch 867 
2025-03-22 14:38:44.363035: Current learning rate: 0.00163 
2025-03-22 14:39:27.196716: train_loss -0.886 
2025-03-22 14:39:27.204793: val_loss -0.8516 
2025-03-22 14:39:27.209837: Pseudo dice [np.float64(0.9515), np.float64(0.9492), np.float64(0.9308)] 
2025-03-22 14:39:27.213863: Epoch time: 42.85 s 
2025-03-22 14:39:27.984622:  
2025-03-22 14:39:27.990634: Epoch 868 
2025-03-22 14:39:27.995647: Current learning rate: 0.00162 
2025-03-22 14:40:12.083762: train_loss -0.8889 
2025-03-22 14:40:12.093781: val_loss -0.8599 
2025-03-22 14:40:12.100798: Pseudo dice [np.float64(0.9522), np.float64(0.9336), np.float64(0.915)] 
2025-03-22 14:40:12.105811: Epoch time: 44.1 s 
2025-03-22 14:40:12.879238:  
2025-03-22 14:40:12.887264: Epoch 869 
2025-03-22 14:40:12.893287: Current learning rate: 0.00161 
2025-03-22 14:40:55.958319: train_loss -0.8851 
2025-03-22 14:40:55.966365: val_loss -0.8562 
2025-03-22 14:40:55.971416: Pseudo dice [np.float64(0.9517), np.float64(0.9259), np.float64(0.9194)] 
2025-03-22 14:40:55.976465: Epoch time: 43.08 s 
2025-03-22 14:40:56.716512:  
2025-03-22 14:40:56.722070: Epoch 870 
2025-03-22 14:40:56.727160: Current learning rate: 0.00159 
2025-03-22 14:41:39.698436: train_loss -0.885 
2025-03-22 14:41:39.707516: val_loss -0.8519 
2025-03-22 14:41:39.714599: Pseudo dice [np.float64(0.9522), np.float64(0.9327), np.float64(0.9197)] 
2025-03-22 14:41:39.718644: Epoch time: 42.98 s 
2025-03-22 14:41:40.703647:  
2025-03-22 14:41:40.709748: Epoch 871 
2025-03-22 14:41:40.713829: Current learning rate: 0.00158 
2025-03-22 14:42:23.597626: train_loss -0.8848 
2025-03-22 14:42:23.605187: val_loss -0.8459 
2025-03-22 14:42:23.609220: Pseudo dice [np.float64(0.954), np.float64(0.9315), np.float64(0.9145)] 
2025-03-22 14:42:23.613245: Epoch time: 42.89 s 
2025-03-22 14:42:24.350237:  
2025-03-22 14:42:24.356785: Epoch 872 
2025-03-22 14:42:24.360815: Current learning rate: 0.00157 
2025-03-22 14:43:07.068298: train_loss -0.8896 
2025-03-22 14:43:07.074814: val_loss -0.8663 
2025-03-22 14:43:07.079828: Pseudo dice [np.float64(0.9496), np.float64(0.9521), np.float64(0.926)] 
2025-03-22 14:43:07.083337: Epoch time: 42.72 s 
2025-03-22 14:43:07.843547:  
2025-03-22 14:43:07.850087: Epoch 873 
2025-03-22 14:43:07.855131: Current learning rate: 0.00156 
2025-03-22 14:43:50.585580: train_loss -0.8848 
2025-03-22 14:43:50.594106: val_loss -0.8662 
2025-03-22 14:43:50.603132: Pseudo dice [np.float64(0.9558), np.float64(0.936), np.float64(0.9265)] 
2025-03-22 14:43:50.608666: Epoch time: 42.74 s 
2025-03-22 14:43:51.349475:  
2025-03-22 14:43:51.356055: Epoch 874 
2025-03-22 14:43:51.361190: Current learning rate: 0.00155 
2025-03-22 14:44:34.338486: train_loss -0.8942 
2025-03-22 14:44:34.348017: val_loss -0.8349 
2025-03-22 14:44:34.355109: Pseudo dice [np.float64(0.9476), np.float64(0.9117), np.float64(0.9047)] 
2025-03-22 14:44:34.360671: Epoch time: 42.99 s 
2025-03-22 14:44:35.131476:  
2025-03-22 14:44:35.137515: Epoch 875 
2025-03-22 14:44:35.141093: Current learning rate: 0.00154 
2025-03-22 14:45:18.262644: train_loss -0.8829 
2025-03-22 14:45:18.270809: val_loss -0.8536 
2025-03-22 14:45:18.276377: Pseudo dice [np.float64(0.957), np.float64(0.934), np.float64(0.9202)] 
2025-03-22 14:45:18.282392: Epoch time: 43.13 s 
2025-03-22 14:45:19.053372:  
2025-03-22 14:45:19.059889: Epoch 876 
2025-03-22 14:45:19.063899: Current learning rate: 0.00153 
2025-03-22 14:46:02.222601: train_loss -0.8903 
2025-03-22 14:46:02.232635: val_loss -0.8336 
2025-03-22 14:46:02.240158: Pseudo dice [np.float64(0.9522), np.float64(0.9363), np.float64(0.9268)] 
2025-03-22 14:46:02.247682: Epoch time: 43.17 s 
2025-03-22 14:46:02.996801:  
2025-03-22 14:46:03.003443: Epoch 877 
2025-03-22 14:46:03.008004: Current learning rate: 0.00152 
2025-03-22 14:46:47.401316: train_loss -0.8876 
2025-03-22 14:46:47.409414: val_loss -0.8623 
2025-03-22 14:46:47.414476: Pseudo dice [np.float64(0.9515), np.float64(0.9459), np.float64(0.929)] 
2025-03-22 14:46:47.419006: Epoch time: 44.41 s 
2025-03-22 14:46:48.180594:  
2025-03-22 14:46:48.187161: Epoch 878 
2025-03-22 14:46:48.192277: Current learning rate: 0.00151 
2025-03-22 14:47:31.024232: train_loss -0.8864 
2025-03-22 14:47:31.032754: val_loss -0.8701 
2025-03-22 14:47:31.038928: Pseudo dice [np.float64(0.945), np.float64(0.9485), np.float64(0.924)] 
2025-03-22 14:47:31.043942: Epoch time: 42.84 s 
2025-03-22 14:47:31.813213:  
2025-03-22 14:47:31.820781: Epoch 879 
2025-03-22 14:47:31.825338: Current learning rate: 0.00149 
2025-03-22 14:48:14.853035: train_loss -0.8887 
2025-03-22 14:48:14.862063: val_loss -0.8522 
2025-03-22 14:48:14.868581: Pseudo dice [np.float64(0.9545), np.float64(0.9372), np.float64(0.9169)] 
2025-03-22 14:48:14.875604: Epoch time: 43.04 s 
2025-03-22 14:48:15.864171:  
2025-03-22 14:48:15.872236: Epoch 880 
2025-03-22 14:48:15.875767: Current learning rate: 0.00148 
2025-03-22 14:48:58.824240: train_loss -0.885 
2025-03-22 14:48:58.832284: val_loss -0.8722 
2025-03-22 14:48:58.838377: Pseudo dice [np.float64(0.9537), np.float64(0.945), np.float64(0.9279)] 
2025-03-22 14:48:58.844540: Epoch time: 42.96 s 
2025-03-22 14:48:59.580691:  
2025-03-22 14:48:59.586708: Epoch 881 
2025-03-22 14:48:59.591725: Current learning rate: 0.00147 
2025-03-22 14:49:42.543404: train_loss -0.8908 
2025-03-22 14:49:42.550925: val_loss -0.8637 
2025-03-22 14:49:42.556943: Pseudo dice [np.float64(0.9562), np.float64(0.9314), np.float64(0.9183)] 
2025-03-22 14:49:42.563461: Epoch time: 42.96 s 
2025-03-22 14:49:43.305471:  
2025-03-22 14:49:43.312111: Epoch 882 
2025-03-22 14:49:43.314658: Current learning rate: 0.00146 
2025-03-22 14:50:26.204661: train_loss -0.8847 
2025-03-22 14:50:26.214685: val_loss -0.8567 
2025-03-22 14:50:26.221699: Pseudo dice [np.float64(0.9456), np.float64(0.9468), np.float64(0.9217)] 
2025-03-22 14:50:26.227212: Epoch time: 42.9 s 
2025-03-22 14:50:27.002481:  
2025-03-22 14:50:27.008628: Epoch 883 
2025-03-22 14:50:27.013186: Current learning rate: 0.00145 
2025-03-22 14:51:09.965860: train_loss -0.8921 
2025-03-22 14:51:09.972911: val_loss -0.8671 
2025-03-22 14:51:09.977984: Pseudo dice [np.float64(0.9588), np.float64(0.9407), np.float64(0.9212)] 
2025-03-22 14:51:09.984152: Epoch time: 42.96 s 
2025-03-22 14:51:10.752643:  
2025-03-22 14:51:10.759168: Epoch 884 
2025-03-22 14:51:10.766195: Current learning rate: 0.00144 
2025-03-22 14:51:53.545261: train_loss -0.8906 
2025-03-22 14:51:53.552782: val_loss -0.8563 
2025-03-22 14:51:53.558800: Pseudo dice [np.float64(0.9524), np.float64(0.9475), np.float64(0.9256)] 
2025-03-22 14:51:53.565837: Epoch time: 42.79 s 
2025-03-22 14:51:54.340963:  
2025-03-22 14:51:54.348028: Epoch 885 
2025-03-22 14:51:54.352181: Current learning rate: 0.00143 
2025-03-22 14:52:37.313299: train_loss -0.8824 
2025-03-22 14:52:37.321818: val_loss -0.8656 
2025-03-22 14:52:37.327830: Pseudo dice [np.float64(0.9485), np.float64(0.9284), np.float64(0.9211)] 
2025-03-22 14:52:37.335365: Epoch time: 42.97 s 
2025-03-22 14:52:38.084072:  
2025-03-22 14:52:38.090594: Epoch 886 
2025-03-22 14:52:38.094601: Current learning rate: 0.00142 
2025-03-22 14:53:22.923505: train_loss -0.8947 
2025-03-22 14:53:22.931525: val_loss -0.8599 
2025-03-22 14:53:22.937541: Pseudo dice [np.float64(0.9486), np.float64(0.9235), np.float64(0.9261)] 
2025-03-22 14:53:22.942552: Epoch time: 44.84 s 
2025-03-22 14:53:23.717733:  
2025-03-22 14:53:23.724313: Epoch 887 
2025-03-22 14:53:23.727844: Current learning rate: 0.00141 
2025-03-22 14:54:06.997809: train_loss -0.8984 
2025-03-22 14:54:07.005953: val_loss -0.8469 
2025-03-22 14:54:07.011772: Pseudo dice [np.float64(0.9508), np.float64(0.9305), np.float64(0.924)] 
2025-03-22 14:54:07.016658: Epoch time: 43.28 s 
2025-03-22 14:54:07.988097:  
2025-03-22 14:54:07.995238: Epoch 888 
2025-03-22 14:54:07.998286: Current learning rate: 0.00139 
2025-03-22 14:54:50.872199: train_loss -0.8911 
2025-03-22 14:54:50.879719: val_loss -0.8789 
2025-03-22 14:54:50.886231: Pseudo dice [np.float64(0.9573), np.float64(0.9595), np.float64(0.9239)] 
2025-03-22 14:54:50.891241: Epoch time: 42.88 s 
2025-03-22 14:54:51.668827:  
2025-03-22 14:54:51.676478: Epoch 889 
2025-03-22 14:54:51.680565: Current learning rate: 0.00138 
2025-03-22 14:55:34.538970: train_loss -0.8963 
2025-03-22 14:55:34.546486: val_loss -0.863 
2025-03-22 14:55:34.552998: Pseudo dice [np.float64(0.9497), np.float64(0.9193), np.float64(0.9217)] 
2025-03-22 14:55:34.560011: Epoch time: 42.87 s 
2025-03-22 14:55:35.328014:  
2025-03-22 14:55:35.334590: Epoch 890 
2025-03-22 14:55:35.339697: Current learning rate: 0.00137 
2025-03-22 14:56:18.139993: train_loss -0.8922 
2025-03-22 14:56:18.149019: val_loss -0.8742 
2025-03-22 14:56:18.155539: Pseudo dice [np.float64(0.9506), np.float64(0.9448), np.float64(0.9219)] 
2025-03-22 14:56:18.161557: Epoch time: 42.81 s 
2025-03-22 14:56:18.901154:  
2025-03-22 14:56:18.907390: Epoch 891 
2025-03-22 14:56:18.912481: Current learning rate: 0.00136 
2025-03-22 14:57:01.864695: train_loss -0.8778 
2025-03-22 14:57:01.874728: val_loss -0.8552 
2025-03-22 14:57:01.883255: Pseudo dice [np.float64(0.9518), np.float64(0.937), np.float64(0.9201)] 
2025-03-22 14:57:01.891286: Epoch time: 42.96 s 
2025-03-22 14:57:02.665790:  
2025-03-22 14:57:02.673574: Epoch 892 
2025-03-22 14:57:02.677145: Current learning rate: 0.00135 
2025-03-22 14:57:45.550835: train_loss -0.8862 
2025-03-22 14:57:45.560858: val_loss -0.8251 
2025-03-22 14:57:45.566880: Pseudo dice [np.float64(0.9454), np.float64(0.9247), np.float64(0.9163)] 
2025-03-22 14:57:45.573395: Epoch time: 42.89 s 
2025-03-22 14:57:46.347118:  
2025-03-22 14:57:46.354879: Epoch 893 
2025-03-22 14:57:46.360957: Current learning rate: 0.00134 
2025-03-22 14:58:29.430800: train_loss -0.8833 
2025-03-22 14:58:29.438958: val_loss -0.8606 
2025-03-22 14:58:29.446249: Pseudo dice [np.float64(0.9514), np.float64(0.9294), np.float64(0.9284)] 
2025-03-22 14:58:29.451339: Epoch time: 43.08 s 
2025-03-22 14:58:30.175850:  
2025-03-22 14:58:30.181863: Epoch 894 
2025-03-22 14:58:30.185371: Current learning rate: 0.00133 
2025-03-22 14:59:13.326963: train_loss -0.88 
2025-03-22 14:59:13.335001: val_loss -0.853 
2025-03-22 14:59:13.339560: Pseudo dice [np.float64(0.9553), np.float64(0.9409), np.float64(0.9199)] 
2025-03-22 14:59:13.343164: Epoch time: 43.15 s 
2025-03-22 14:59:14.101661:  
2025-03-22 14:59:14.108185: Epoch 895 
2025-03-22 14:59:14.111694: Current learning rate: 0.00132 
2025-03-22 14:59:58.884158: train_loss -0.8798 
2025-03-22 14:59:58.891675: val_loss -0.8542 
2025-03-22 14:59:58.895686: Pseudo dice [np.float64(0.9451), np.float64(0.9365), np.float64(0.932)] 
2025-03-22 14:59:58.899693: Epoch time: 44.78 s 
2025-03-22 14:59:59.681193:  
2025-03-22 14:59:59.687844: Epoch 896 
2025-03-22 14:59:59.694495: Current learning rate: 0.0013 
2025-03-22 15:00:42.959546: train_loss -0.8942 
2025-03-22 15:00:42.967614: val_loss -0.8647 
2025-03-22 15:00:42.975178: Pseudo dice [np.float64(0.9529), np.float64(0.929), np.float64(0.9112)] 
2025-03-22 15:00:42.982235: Epoch time: 43.28 s 
2025-03-22 15:00:43.996267:  
2025-03-22 15:00:44.002382: Epoch 897 
2025-03-22 15:00:44.006977: Current learning rate: 0.00129 
2025-03-22 15:01:27.120972: train_loss -0.8961 
2025-03-22 15:01:27.132006: val_loss -0.8606 
2025-03-22 15:01:27.138594: Pseudo dice [np.float64(0.9504), np.float64(0.9304), np.float64(0.9208)] 
2025-03-22 15:01:27.145900: Epoch time: 43.13 s 
2025-03-22 15:01:27.918606:  
2025-03-22 15:01:27.925139: Epoch 898 
2025-03-22 15:01:27.930152: Current learning rate: 0.00128 
2025-03-22 15:02:10.848519: train_loss -0.889 
2025-03-22 15:02:10.858541: val_loss -0.8681 
2025-03-22 15:02:10.867568: Pseudo dice [np.float64(0.9499), np.float64(0.9523), np.float64(0.9286)] 
2025-03-22 15:02:10.874587: Epoch time: 42.93 s 
2025-03-22 15:02:11.631084:  
2025-03-22 15:02:11.638147: Epoch 899 
2025-03-22 15:02:11.641717: Current learning rate: 0.00127 
2025-03-22 15:02:54.286122: train_loss -0.8821 
2025-03-22 15:02:54.294645: val_loss -0.868 
2025-03-22 15:02:54.302163: Pseudo dice [np.float64(0.9568), np.float64(0.9304), np.float64(0.9061)] 
2025-03-22 15:02:54.307182: Epoch time: 42.66 s 
2025-03-22 15:02:55.194436:  
2025-03-22 15:02:55.200470: Epoch 900 
2025-03-22 15:02:55.204504: Current learning rate: 0.00126 
2025-03-22 15:03:38.199126: train_loss -0.8858 
2025-03-22 15:03:38.207422: val_loss -0.8875 
2025-03-22 15:03:38.213435: Pseudo dice [np.float64(0.9561), np.float64(0.9386), np.float64(0.9181)] 
2025-03-22 15:03:38.219446: Epoch time: 43.01 s 
2025-03-22 15:03:38.987457:  
2025-03-22 15:03:38.995034: Epoch 901 
2025-03-22 15:03:38.998583: Current learning rate: 0.00125 
2025-03-22 15:04:22.120744: train_loss -0.8868 
2025-03-22 15:04:22.130771: val_loss -0.8556 
2025-03-22 15:04:22.136790: Pseudo dice [np.float64(0.9474), np.float64(0.9309), np.float64(0.9136)] 
2025-03-22 15:04:22.144314: Epoch time: 43.13 s 
2025-03-22 15:04:22.881181:  
2025-03-22 15:04:22.887299: Epoch 902 
2025-03-22 15:04:22.891898: Current learning rate: 0.00124 
2025-03-22 15:05:05.714611: train_loss -0.8916 
2025-03-22 15:05:05.722126: val_loss -0.8722 
2025-03-22 15:05:05.728638: Pseudo dice [np.float64(0.9532), np.float64(0.9478), np.float64(0.9333)] 
2025-03-22 15:05:05.734651: Epoch time: 42.83 s 
2025-03-22 15:05:06.496510:  
2025-03-22 15:05:06.503064: Epoch 903 
2025-03-22 15:05:06.510648: Current learning rate: 0.00122 
2025-03-22 15:05:49.687334: train_loss -0.8881 
2025-03-22 15:05:49.695862: val_loss -0.8511 
2025-03-22 15:05:49.701877: Pseudo dice [np.float64(0.9496), np.float64(0.9476), np.float64(0.9292)] 
2025-03-22 15:05:49.707485: Epoch time: 43.19 s 
2025-03-22 15:05:50.437993:  
2025-03-22 15:05:50.445096: Epoch 904 
2025-03-22 15:05:50.450110: Current learning rate: 0.00121 
2025-03-22 15:06:34.629624: train_loss -0.8838 
2025-03-22 15:06:34.638142: val_loss -0.8437 
2025-03-22 15:06:34.644156: Pseudo dice [np.float64(0.9528), np.float64(0.9308), np.float64(0.9202)] 
2025-03-22 15:06:34.650682: Epoch time: 44.19 s 
2025-03-22 15:06:35.679914:  
2025-03-22 15:06:35.686430: Epoch 905 
2025-03-22 15:06:35.689937: Current learning rate: 0.0012 
2025-03-22 15:07:18.659933: train_loss -0.8889 
2025-03-22 15:07:18.668450: val_loss -0.8598 
2025-03-22 15:07:18.673961: Pseudo dice [np.float64(0.9525), np.float64(0.9341), np.float64(0.9207)] 
2025-03-22 15:07:18.678971: Epoch time: 42.98 s 
2025-03-22 15:07:19.450511:  
2025-03-22 15:07:19.457075: Epoch 906 
2025-03-22 15:07:19.461197: Current learning rate: 0.00119 
2025-03-22 15:08:02.289703: train_loss -0.8974 
2025-03-22 15:08:02.297222: val_loss -0.8699 
2025-03-22 15:08:02.302236: Pseudo dice [np.float64(0.9531), np.float64(0.9416), np.float64(0.9191)] 
2025-03-22 15:08:02.307253: Epoch time: 42.84 s 
2025-03-22 15:08:03.086116:  
2025-03-22 15:08:03.092665: Epoch 907 
2025-03-22 15:08:03.096918: Current learning rate: 0.00118 
2025-03-22 15:08:45.911471: train_loss -0.8924 
2025-03-22 15:08:45.920497: val_loss -0.8548 
2025-03-22 15:08:45.926511: Pseudo dice [np.float64(0.9524), np.float64(0.9471), np.float64(0.92)] 
2025-03-22 15:08:45.931521: Epoch time: 42.83 s 
2025-03-22 15:08:46.684666:  
2025-03-22 15:08:46.693919: Epoch 908 
2025-03-22 15:08:46.700011: Current learning rate: 0.00117 
2025-03-22 15:09:29.606336: train_loss -0.8837 
2025-03-22 15:09:29.614858: val_loss -0.865 
2025-03-22 15:09:29.618865: Pseudo dice [np.float64(0.9521), np.float64(0.9255), np.float64(0.9107)] 
2025-03-22 15:09:29.623375: Epoch time: 42.92 s 
2025-03-22 15:09:30.388507:  
2025-03-22 15:09:30.395059: Epoch 909 
2025-03-22 15:09:30.401617: Current learning rate: 0.00116 
2025-03-22 15:10:13.442027: train_loss -0.8901 
2025-03-22 15:10:13.450732: val_loss -0.8484 
2025-03-22 15:10:13.457841: Pseudo dice [np.float64(0.9517), np.float64(0.9376), np.float64(0.9285)] 
2025-03-22 15:10:13.464444: Epoch time: 43.05 s 
2025-03-22 15:10:14.226711:  
2025-03-22 15:10:14.233806: Epoch 910 
2025-03-22 15:10:14.238350: Current learning rate: 0.00115 
2025-03-22 15:10:57.089835: train_loss -0.8843 
2025-03-22 15:10:57.097381: val_loss -0.8277 
2025-03-22 15:10:57.103478: Pseudo dice [np.float64(0.9489), np.float64(0.9214), np.float64(0.918)] 
2025-03-22 15:10:57.107512: Epoch time: 42.86 s 
2025-03-22 15:10:57.852659:  
2025-03-22 15:10:57.860177: Epoch 911 
2025-03-22 15:10:57.864187: Current learning rate: 0.00113 
2025-03-22 15:11:40.839815: train_loss -0.8876 
2025-03-22 15:11:40.849847: val_loss -0.8382 
2025-03-22 15:11:40.856363: Pseudo dice [np.float64(0.9491), np.float64(0.9379), np.float64(0.9244)] 
2025-03-22 15:11:40.862877: Epoch time: 42.99 s 
2025-03-22 15:11:41.626112:  
2025-03-22 15:11:41.631665: Epoch 912 
2025-03-22 15:11:41.636291: Current learning rate: 0.00112 
2025-03-22 15:12:24.455876: train_loss -0.8785 
2025-03-22 15:12:24.464904: val_loss -0.8485 
2025-03-22 15:12:24.471926: Pseudo dice [np.float64(0.9507), np.float64(0.9364), np.float64(0.9209)] 
2025-03-22 15:12:24.477442: Epoch time: 42.83 s 
2025-03-22 15:12:25.256313:  
2025-03-22 15:12:25.262899: Epoch 913 
2025-03-22 15:12:25.269512: Current learning rate: 0.00111 
2025-03-22 15:13:09.599879: train_loss -0.8822 
2025-03-22 15:13:09.608396: val_loss -0.8473 
2025-03-22 15:13:09.614919: Pseudo dice [np.float64(0.9486), np.float64(0.9394), np.float64(0.9146)] 
2025-03-22 15:13:09.621438: Epoch time: 44.34 s 
2025-03-22 15:13:10.644694:  
2025-03-22 15:13:10.651226: Epoch 914 
2025-03-22 15:13:10.655245: Current learning rate: 0.0011 
2025-03-22 15:13:53.623624: train_loss -0.8929 
2025-03-22 15:13:53.631818: val_loss -0.8802 
2025-03-22 15:13:53.637997: Pseudo dice [np.float64(0.9551), np.float64(0.9485), np.float64(0.9286)] 
2025-03-22 15:13:53.644621: Epoch time: 42.98 s 
2025-03-22 15:13:54.427191:  
2025-03-22 15:13:54.434263: Epoch 915 
2025-03-22 15:13:54.440860: Current learning rate: 0.00109 
2025-03-22 15:14:37.363592: train_loss -0.8852 
2025-03-22 15:14:37.372746: val_loss -0.8683 
2025-03-22 15:14:37.379937: Pseudo dice [np.float64(0.9585), np.float64(0.9445), np.float64(0.9292)] 
2025-03-22 15:14:37.386501: Epoch time: 42.94 s 
2025-03-22 15:14:38.162704:  
2025-03-22 15:14:38.169242: Epoch 916 
2025-03-22 15:14:38.173267: Current learning rate: 0.00108 
2025-03-22 15:15:21.070119: train_loss -0.8874 
2025-03-22 15:15:21.078635: val_loss -0.8785 
2025-03-22 15:15:21.085150: Pseudo dice [np.float64(0.9534), np.float64(0.9264), np.float64(0.9188)] 
2025-03-22 15:15:21.091662: Epoch time: 42.91 s 
2025-03-22 15:15:21.869035:  
2025-03-22 15:15:21.876739: Epoch 917 
2025-03-22 15:15:21.879830: Current learning rate: 0.00106 
2025-03-22 15:16:04.959023: train_loss -0.8904 
2025-03-22 15:16:04.966584: val_loss -0.8689 
2025-03-22 15:16:04.972627: Pseudo dice [np.float64(0.9578), np.float64(0.937), np.float64(0.9241)] 
2025-03-22 15:16:04.976678: Epoch time: 43.09 s 
2025-03-22 15:16:05.747786:  
2025-03-22 15:16:05.754360: Epoch 918 
2025-03-22 15:16:05.758393: Current learning rate: 0.00105 
2025-03-22 15:16:48.657254: train_loss -0.8903 
2025-03-22 15:16:48.664821: val_loss -0.8674 
2025-03-22 15:16:48.669360: Pseudo dice [np.float64(0.9502), np.float64(0.9388), np.float64(0.9283)] 
2025-03-22 15:16:48.673899: Epoch time: 42.91 s 
2025-03-22 15:16:49.457717:  
2025-03-22 15:16:49.464334: Epoch 919 
2025-03-22 15:16:49.469415: Current learning rate: 0.00104 
2025-03-22 15:17:32.305428: train_loss -0.8898 
2025-03-22 15:17:32.313954: val_loss -0.8511 
2025-03-22 15:17:32.321480: Pseudo dice [np.float64(0.9486), np.float64(0.9342), np.float64(0.9143)] 
2025-03-22 15:17:32.330564: Epoch time: 42.85 s 
2025-03-22 15:17:33.096157:  
2025-03-22 15:17:33.102720: Epoch 920 
2025-03-22 15:17:33.107287: Current learning rate: 0.00103 
2025-03-22 15:18:16.047779: train_loss -0.8788 
2025-03-22 15:18:16.055294: val_loss -0.8679 
2025-03-22 15:18:16.058803: Pseudo dice [np.float64(0.9526), np.float64(0.9463), np.float64(0.9209)] 
2025-03-22 15:18:16.062814: Epoch time: 42.95 s 
2025-03-22 15:18:16.814221:  
2025-03-22 15:18:16.823312: Epoch 921 
2025-03-22 15:18:16.829884: Current learning rate: 0.00102 
2025-03-22 15:18:59.758990: train_loss -0.8834 
2025-03-22 15:18:59.767516: val_loss -0.8428 
2025-03-22 15:18:59.774032: Pseudo dice [np.float64(0.9495), np.float64(0.9306), np.float64(0.9267)] 
2025-03-22 15:18:59.779044: Epoch time: 42.95 s 
2025-03-22 15:19:00.545932:  
2025-03-22 15:19:00.553979: Epoch 922 
2025-03-22 15:19:00.559529: Current learning rate: 0.00101 
2025-03-22 15:19:45.203529: train_loss -0.8787 
2025-03-22 15:19:45.213104: val_loss -0.8642 
2025-03-22 15:19:45.219159: Pseudo dice [np.float64(0.9463), np.float64(0.9425), np.float64(0.9242)] 
2025-03-22 15:19:45.226214: Epoch time: 44.66 s 
2025-03-22 15:19:46.264882:  
2025-03-22 15:19:46.273411: Epoch 923 
2025-03-22 15:19:46.276923: Current learning rate: 0.001 
2025-03-22 15:20:29.160906: train_loss -0.8929 
2025-03-22 15:20:29.170037: val_loss -0.8811 
2025-03-22 15:20:29.175606: Pseudo dice [np.float64(0.9582), np.float64(0.9457), np.float64(0.9323)] 
2025-03-22 15:20:29.182172: Epoch time: 42.9 s 
2025-03-22 15:20:29.950839:  
2025-03-22 15:20:29.958019: Epoch 924 
2025-03-22 15:20:29.962596: Current learning rate: 0.00098 
2025-03-22 15:21:13.185541: train_loss -0.8862 
2025-03-22 15:21:13.196619: val_loss -0.8428 
2025-03-22 15:21:13.206858: Pseudo dice [np.float64(0.9456), np.float64(0.9351), np.float64(0.9204)] 
2025-03-22 15:21:13.213010: Epoch time: 43.24 s 
2025-03-22 15:21:13.953037:  
2025-03-22 15:21:13.960374: Epoch 925 
2025-03-22 15:21:13.965971: Current learning rate: 0.00097 
2025-03-22 15:21:57.112244: train_loss -0.8925 
2025-03-22 15:21:57.119334: val_loss -0.836 
2025-03-22 15:21:57.124462: Pseudo dice [np.float64(0.9458), np.float64(0.9417), np.float64(0.9232)] 
2025-03-22 15:21:57.130029: Epoch time: 43.16 s 
2025-03-22 15:21:57.891161:  
2025-03-22 15:21:57.897188: Epoch 926 
2025-03-22 15:21:57.901220: Current learning rate: 0.00096 
2025-03-22 15:22:40.831231: train_loss -0.8952 
2025-03-22 15:22:40.838755: val_loss -0.8607 
2025-03-22 15:22:40.843769: Pseudo dice [np.float64(0.9527), np.float64(0.9416), np.float64(0.918)] 
2025-03-22 15:22:40.848786: Epoch time: 42.94 s 
2025-03-22 15:22:41.581849:  
2025-03-22 15:22:41.588467: Epoch 927 
2025-03-22 15:22:41.595104: Current learning rate: 0.00095 
2025-03-22 15:23:24.522385: train_loss -0.8836 
2025-03-22 15:23:24.529907: val_loss -0.8743 
2025-03-22 15:23:24.534920: Pseudo dice [np.float64(0.953), np.float64(0.9509), np.float64(0.9224)] 
2025-03-22 15:23:24.539932: Epoch time: 42.94 s 
2025-03-22 15:23:25.303614:  
2025-03-22 15:23:25.310206: Epoch 928 
2025-03-22 15:23:25.315733: Current learning rate: 0.00094 
2025-03-22 15:24:08.408349: train_loss -0.888 
2025-03-22 15:24:08.415870: val_loss -0.8577 
2025-03-22 15:24:08.420891: Pseudo dice [np.float64(0.9509), np.float64(0.9195), np.float64(0.9131)] 
2025-03-22 15:24:08.425905: Epoch time: 43.11 s 
2025-03-22 15:24:09.193082:  
2025-03-22 15:24:09.200172: Epoch 929 
2025-03-22 15:24:09.204750: Current learning rate: 0.00092 
2025-03-22 15:24:52.158651: train_loss -0.8959 
2025-03-22 15:24:52.165992: val_loss -0.8851 
2025-03-22 15:24:52.172010: Pseudo dice [np.float64(0.9549), np.float64(0.954), np.float64(0.9357)] 
2025-03-22 15:24:52.178529: Epoch time: 42.97 s 
2025-03-22 15:24:52.961462:  
2025-03-22 15:24:52.968526: Epoch 930 
2025-03-22 15:24:52.974687: Current learning rate: 0.00091 
2025-03-22 15:25:35.831262: train_loss -0.8909 
2025-03-22 15:25:35.838777: val_loss -0.8448 
2025-03-22 15:25:35.843288: Pseudo dice [np.float64(0.9503), np.float64(0.9448), np.float64(0.9211)] 
2025-03-22 15:25:35.848803: Epoch time: 42.87 s 
2025-03-22 15:25:36.855847:  
2025-03-22 15:25:36.861988: Epoch 931 
2025-03-22 15:25:36.866157: Current learning rate: 0.0009 
2025-03-22 15:26:19.954137: train_loss -0.8794 
2025-03-22 15:26:19.962289: val_loss -0.8728 
2025-03-22 15:26:19.970541: Pseudo dice [np.float64(0.9513), np.float64(0.9265), np.float64(0.9264)] 
2025-03-22 15:26:19.978163: Epoch time: 43.1 s 
2025-03-22 15:26:20.729352:  
2025-03-22 15:26:20.735903: Epoch 932 
2025-03-22 15:26:20.739413: Current learning rate: 0.00089 
2025-03-22 15:27:03.928857: train_loss -0.8889 
2025-03-22 15:27:03.937884: val_loss -0.8414 
2025-03-22 15:27:03.943945: Pseudo dice [np.float64(0.9538), np.float64(0.9427), np.float64(0.9235)] 
2025-03-22 15:27:03.949522: Epoch time: 43.2 s 
2025-03-22 15:27:04.706542:  
2025-03-22 15:27:04.714644: Epoch 933 
2025-03-22 15:27:04.719714: Current learning rate: 0.00088 
2025-03-22 15:27:47.663404: train_loss -0.8888 
2025-03-22 15:27:47.670924: val_loss -0.8628 
2025-03-22 15:27:47.676448: Pseudo dice [np.float64(0.9555), np.float64(0.9269), np.float64(0.929)] 
2025-03-22 15:27:47.682483: Epoch time: 42.96 s 
2025-03-22 15:27:48.436098:  
2025-03-22 15:27:48.443740: Epoch 934 
2025-03-22 15:27:48.450269: Current learning rate: 0.00087 
2025-03-22 15:28:31.279330: train_loss -0.884 
2025-03-22 15:28:31.286859: val_loss -0.8356 
2025-03-22 15:28:31.291872: Pseudo dice [np.float64(0.9526), np.float64(0.9249), np.float64(0.9258)] 
2025-03-22 15:28:31.295887: Epoch time: 42.84 s 
2025-03-22 15:28:32.028788:  
2025-03-22 15:28:32.035310: Epoch 935 
2025-03-22 15:28:32.039317: Current learning rate: 0.00085 
2025-03-22 15:29:19.154158: train_loss -0.8851 
2025-03-22 15:29:19.161480: val_loss -0.8468 
2025-03-22 15:29:19.169045: Pseudo dice [np.float64(0.9464), np.float64(0.9411), np.float64(0.9162)] 
2025-03-22 15:29:19.176571: Epoch time: 47.13 s 
2025-03-22 15:29:19.946546:  
2025-03-22 15:29:19.954107: Epoch 936 
2025-03-22 15:29:19.959182: Current learning rate: 0.00084 
2025-03-22 15:30:03.433027: train_loss -0.8971 
2025-03-22 15:30:03.441549: val_loss -0.8409 
2025-03-22 15:30:03.448066: Pseudo dice [np.float64(0.9519), np.float64(0.9228), np.float64(0.9147)] 
2025-03-22 15:30:03.453083: Epoch time: 43.49 s 
2025-03-22 15:30:04.213965:  
2025-03-22 15:30:04.221516: Epoch 937 
2025-03-22 15:30:04.225557: Current learning rate: 0.00083 
2025-03-22 15:30:47.630045: train_loss -0.8904 
2025-03-22 15:30:47.637624: val_loss -0.8699 
2025-03-22 15:30:47.644697: Pseudo dice [np.float64(0.9456), np.float64(0.9279), np.float64(0.917)] 
2025-03-22 15:30:47.651786: Epoch time: 43.42 s 
2025-03-22 15:30:48.425893:  
2025-03-22 15:30:48.433418: Epoch 938 
2025-03-22 15:30:48.439434: Current learning rate: 0.00082 
2025-03-22 15:31:31.690151: train_loss -0.8962 
2025-03-22 15:31:31.698677: val_loss -0.8735 
2025-03-22 15:31:31.706707: Pseudo dice [np.float64(0.9477), np.float64(0.9395), np.float64(0.922)] 
2025-03-22 15:31:31.715241: Epoch time: 43.26 s 
2025-03-22 15:31:32.493821:  
2025-03-22 15:31:32.500901: Epoch 939 
2025-03-22 15:31:32.505043: Current learning rate: 0.00081 
2025-03-22 15:32:16.110079: train_loss -0.8901 
2025-03-22 15:32:16.120113: val_loss -0.8393 
2025-03-22 15:32:16.126131: Pseudo dice [np.float64(0.9521), np.float64(0.9284), np.float64(0.9149)] 
2025-03-22 15:32:16.133655: Epoch time: 43.62 s 
2025-03-22 15:32:17.118544:  
2025-03-22 15:32:17.126124: Epoch 940 
2025-03-22 15:32:17.130634: Current learning rate: 0.00079 
2025-03-22 15:33:00.500240: train_loss -0.8937 
2025-03-22 15:33:00.508266: val_loss -0.8605 
2025-03-22 15:33:00.515787: Pseudo dice [np.float64(0.9536), np.float64(0.9385), np.float64(0.9242)] 
2025-03-22 15:33:00.523306: Epoch time: 43.38 s 
2025-03-22 15:33:01.307986:  
2025-03-22 15:33:01.315621: Epoch 941 
2025-03-22 15:33:01.322303: Current learning rate: 0.00078 
2025-03-22 15:33:44.592416: train_loss -0.886 
2025-03-22 15:33:44.600950: val_loss -0.852 
2025-03-22 15:33:44.607480: Pseudo dice [np.float64(0.9538), np.float64(0.924), np.float64(0.917)] 
2025-03-22 15:33:44.614012: Epoch time: 43.29 s 
2025-03-22 15:33:45.383882:  
2025-03-22 15:33:45.391531: Epoch 942 
2025-03-22 15:33:45.395118: Current learning rate: 0.00077 
2025-03-22 15:34:28.556448: train_loss -0.8915 
2025-03-22 15:34:28.565627: val_loss -0.8749 
2025-03-22 15:34:28.572147: Pseudo dice [np.float64(0.9565), np.float64(0.9493), np.float64(0.9237)] 
2025-03-22 15:34:28.578676: Epoch time: 43.17 s 
2025-03-22 15:34:29.349827:  
2025-03-22 15:34:29.357355: Epoch 943 
2025-03-22 15:34:29.363878: Current learning rate: 0.00076 
2025-03-22 15:35:12.799384: train_loss -0.8914 
2025-03-22 15:35:12.807408: val_loss -0.8461 
2025-03-22 15:35:12.812426: Pseudo dice [np.float64(0.9531), np.float64(0.9426), np.float64(0.918)] 
2025-03-22 15:35:12.817441: Epoch time: 43.45 s 
2025-03-22 15:35:13.594332:  
2025-03-22 15:35:13.602280: Epoch 944 
2025-03-22 15:35:13.607800: Current learning rate: 0.00075 
2025-03-22 15:35:57.176611: train_loss -0.8923 
2025-03-22 15:35:57.185649: val_loss -0.8798 
2025-03-22 15:35:57.193179: Pseudo dice [np.float64(0.9528), np.float64(0.9501), np.float64(0.9314)] 
2025-03-22 15:35:57.200206: Epoch time: 43.58 s 
2025-03-22 15:35:57.959088:  
2025-03-22 15:35:57.966614: Epoch 945 
2025-03-22 15:35:57.970131: Current learning rate: 0.00074 
2025-03-22 15:36:41.819975: train_loss -0.8879 
2025-03-22 15:36:41.829172: val_loss -0.8278 
2025-03-22 15:36:41.835245: Pseudo dice [np.float64(0.9511), np.float64(0.9233), np.float64(0.8999)] 
2025-03-22 15:36:41.839315: Epoch time: 43.86 s 
2025-03-22 15:36:42.607378:  
2025-03-22 15:36:42.613907: Epoch 946 
2025-03-22 15:36:42.617925: Current learning rate: 0.00072 
2025-03-22 15:37:25.853556: train_loss -0.8862 
2025-03-22 15:37:25.862581: val_loss -0.8431 
2025-03-22 15:37:25.870095: Pseudo dice [np.float64(0.953), np.float64(0.9399), np.float64(0.9254)] 
2025-03-22 15:37:25.876111: Epoch time: 43.25 s 
2025-03-22 15:37:26.686205:  
2025-03-22 15:37:26.693332: Epoch 947 
2025-03-22 15:37:26.696940: Current learning rate: 0.00071 
2025-03-22 15:38:09.838668: train_loss -0.8897 
2025-03-22 15:38:09.847190: val_loss -0.8509 
2025-03-22 15:38:09.852211: Pseudo dice [np.float64(0.9539), np.float64(0.9147), np.float64(0.9223)] 
2025-03-22 15:38:09.857226: Epoch time: 43.15 s 
2025-03-22 15:38:10.621365:  
2025-03-22 15:38:10.627410: Epoch 948 
2025-03-22 15:38:10.631926: Current learning rate: 0.0007 
2025-03-22 15:38:53.764589: train_loss -0.8915 
2025-03-22 15:38:53.772147: val_loss -0.8455 
2025-03-22 15:38:53.778693: Pseudo dice [np.float64(0.9546), np.float64(0.9405), np.float64(0.9256)] 
2025-03-22 15:38:53.784831: Epoch time: 43.14 s 
2025-03-22 15:38:54.753577:  
2025-03-22 15:38:54.759591: Epoch 949 
2025-03-22 15:38:54.763603: Current learning rate: 0.00069 
2025-03-22 15:39:37.750735: train_loss -0.8881 
2025-03-22 15:39:37.758905: val_loss -0.8421 
2025-03-22 15:39:37.765507: Pseudo dice [np.float64(0.954), np.float64(0.9316), np.float64(0.9279)] 
2025-03-22 15:39:37.772100: Epoch time: 43.0 s 
2025-03-22 15:39:38.677197:  
2025-03-22 15:39:38.683751: Epoch 950 
2025-03-22 15:39:38.687800: Current learning rate: 0.00067 
2025-03-22 15:40:21.513112: train_loss -0.8961 
2025-03-22 15:40:21.521276: val_loss -0.8605 
2025-03-22 15:40:21.529446: Pseudo dice [np.float64(0.9536), np.float64(0.9489), np.float64(0.9232)] 
2025-03-22 15:40:21.537087: Epoch time: 42.84 s 
2025-03-22 15:40:22.300246:  
2025-03-22 15:40:22.306271: Epoch 951 
2025-03-22 15:40:22.310285: Current learning rate: 0.00066 
2025-03-22 15:41:04.756431: train_loss -0.9018 
2025-03-22 15:41:04.763597: val_loss -0.8772 
2025-03-22 15:41:04.767651: Pseudo dice [np.float64(0.9517), np.float64(0.95), np.float64(0.9232)] 
2025-03-22 15:41:04.771735: Epoch time: 42.46 s 
2025-03-22 15:41:05.553570:  
2025-03-22 15:41:05.559599: Epoch 952 
2025-03-22 15:41:05.563616: Current learning rate: 0.00065 
2025-03-22 15:41:48.358425: train_loss -0.8958 
2025-03-22 15:41:48.366991: val_loss -0.8728 
2025-03-22 15:41:48.374318: Pseudo dice [np.float64(0.9561), np.float64(0.9509), np.float64(0.9341)] 
2025-03-22 15:41:48.380899: Epoch time: 42.81 s 
2025-03-22 15:41:49.146908:  
2025-03-22 15:41:49.154060: Epoch 953 
2025-03-22 15:41:49.158165: Current learning rate: 0.00064 
2025-03-22 15:42:31.954769: train_loss -0.8967 
2025-03-22 15:42:31.963299: val_loss -0.8555 
2025-03-22 15:42:31.972867: Pseudo dice [np.float64(0.9547), np.float64(0.9413), np.float64(0.9251)] 
2025-03-22 15:42:31.980385: Epoch time: 42.81 s 
2025-03-22 15:42:32.757324:  
2025-03-22 15:42:32.763355: Epoch 954 
2025-03-22 15:42:32.767452: Current learning rate: 0.00063 
2025-03-22 15:43:15.547378: train_loss -0.8885 
2025-03-22 15:43:15.554896: val_loss -0.8723 
2025-03-22 15:43:15.559917: Pseudo dice [np.float64(0.9529), np.float64(0.9324), np.float64(0.9127)] 
2025-03-22 15:43:15.563926: Epoch time: 42.79 s 
2025-03-22 15:43:16.355601:  
2025-03-22 15:43:16.363675: Epoch 955 
2025-03-22 15:43:16.368306: Current learning rate: 0.00061 
2025-03-22 15:43:59.924050: train_loss -0.8822 
2025-03-22 15:43:59.931064: val_loss -0.859 
2025-03-22 15:43:59.936082: Pseudo dice [np.float64(0.951), np.float64(0.927), np.float64(0.9187)] 
2025-03-22 15:43:59.941606: Epoch time: 43.57 s 
2025-03-22 15:44:00.702502:  
2025-03-22 15:44:00.708527: Epoch 956 
2025-03-22 15:44:00.713554: Current learning rate: 0.0006 
2025-03-22 15:44:43.736993: train_loss -0.8829 
2025-03-22 15:44:43.746013: val_loss -0.8658 
2025-03-22 15:44:43.752043: Pseudo dice [np.float64(0.9489), np.float64(0.9362), np.float64(0.9246)] 
2025-03-22 15:44:43.759573: Epoch time: 43.04 s 
2025-03-22 15:44:44.546523:  
2025-03-22 15:44:44.554045: Epoch 957 
2025-03-22 15:44:44.558064: Current learning rate: 0.00059 
2025-03-22 15:45:27.441611: train_loss -0.8871 
2025-03-22 15:45:27.450166: val_loss -0.845 
2025-03-22 15:45:27.455190: Pseudo dice [np.float64(0.9485), np.float64(0.9446), np.float64(0.93)] 
2025-03-22 15:45:27.459198: Epoch time: 42.9 s 
2025-03-22 15:45:28.455244:  
2025-03-22 15:45:28.460256: Epoch 958 
2025-03-22 15:45:28.464773: Current learning rate: 0.00058 
2025-03-22 15:46:10.952266: train_loss -0.8925 
2025-03-22 15:46:10.958315: val_loss -0.8558 
2025-03-22 15:46:10.963396: Pseudo dice [np.float64(0.9459), np.float64(0.9228), np.float64(0.9143)] 
2025-03-22 15:46:10.967915: Epoch time: 42.5 s 
2025-03-22 15:46:11.745757:  
2025-03-22 15:46:11.752844: Epoch 959 
2025-03-22 15:46:11.758407: Current learning rate: 0.00056 
2025-03-22 15:46:54.184952: train_loss -0.8886 
2025-03-22 15:46:54.192470: val_loss -0.8399 
2025-03-22 15:46:54.197484: Pseudo dice [np.float64(0.95), np.float64(0.9285), np.float64(0.9191)] 
2025-03-22 15:46:54.202498: Epoch time: 42.44 s 
2025-03-22 15:46:54.992522:  
2025-03-22 15:46:55.000598: Epoch 960 
2025-03-22 15:46:55.004236: Current learning rate: 0.00055 
2025-03-22 15:47:37.713005: train_loss -0.8946 
2025-03-22 15:47:37.720526: val_loss -0.8592 
2025-03-22 15:47:37.726540: Pseudo dice [np.float64(0.9547), np.float64(0.9474), np.float64(0.9253)] 
2025-03-22 15:47:37.733059: Epoch time: 42.72 s 
2025-03-22 15:47:38.518967:  
2025-03-22 15:47:38.526486: Epoch 961 
2025-03-22 15:47:38.530502: Current learning rate: 0.00054 
2025-03-22 15:48:21.121159: train_loss -0.8895 
2025-03-22 15:48:21.129858: val_loss -0.8469 
2025-03-22 15:48:21.134924: Pseudo dice [np.float64(0.9476), np.float64(0.933), np.float64(0.9126)] 
2025-03-22 15:48:21.142465: Epoch time: 42.6 s 
2025-03-22 15:48:21.914505:  
2025-03-22 15:48:21.921623: Epoch 962 
2025-03-22 15:48:21.925687: Current learning rate: 0.00053 
2025-03-22 15:49:04.598285: train_loss -0.883 
2025-03-22 15:49:04.608527: val_loss -0.8536 
2025-03-22 15:49:04.616130: Pseudo dice [np.float64(0.9476), np.float64(0.938), np.float64(0.9215)] 
2025-03-22 15:49:04.623208: Epoch time: 42.68 s 
2025-03-22 15:49:05.421142:  
2025-03-22 15:49:05.428809: Epoch 963 
2025-03-22 15:49:05.431874: Current learning rate: 0.00051 
2025-03-22 15:49:47.838726: train_loss -0.8961 
2025-03-22 15:49:47.847248: val_loss -0.8626 
2025-03-22 15:49:47.852765: Pseudo dice [np.float64(0.9491), np.float64(0.9438), np.float64(0.9263)] 
2025-03-22 15:49:47.859791: Epoch time: 42.42 s 
2025-03-22 15:49:48.637735:  
2025-03-22 15:49:48.644855: Epoch 964 
2025-03-22 15:49:48.649983: Current learning rate: 0.0005 
2025-03-22 15:50:31.115693: train_loss -0.8934 
2025-03-22 15:50:31.123212: val_loss -0.8537 
2025-03-22 15:50:31.127728: Pseudo dice [np.float64(0.9499), np.float64(0.9398), np.float64(0.9269)] 
2025-03-22 15:50:31.131739: Epoch time: 42.48 s 
2025-03-22 15:50:31.888749:  
2025-03-22 15:50:31.897266: Epoch 965 
2025-03-22 15:50:31.902783: Current learning rate: 0.00049 
2025-03-22 15:51:16.373976: train_loss -0.8989 
2025-03-22 15:51:16.382639: val_loss -0.8552 
2025-03-22 15:51:16.386698: Pseudo dice [np.float64(0.9519), np.float64(0.9337), np.float64(0.9259)] 
2025-03-22 15:51:16.391239: Epoch time: 44.49 s 
2025-03-22 15:51:17.372258:  
2025-03-22 15:51:17.380299: Epoch 966 
2025-03-22 15:51:17.383807: Current learning rate: 0.00048 
2025-03-22 15:51:59.911939: train_loss -0.8846 
2025-03-22 15:51:59.918499: val_loss -0.8734 
2025-03-22 15:51:59.926022: Pseudo dice [np.float64(0.9503), np.float64(0.9568), np.float64(0.9314)] 
2025-03-22 15:51:59.932041: Epoch time: 42.54 s 
2025-03-22 15:52:00.725476:  
2025-03-22 15:52:00.733531: Epoch 967 
2025-03-22 15:52:00.739111: Current learning rate: 0.00046 
2025-03-22 15:52:43.200444: train_loss -0.8974 
2025-03-22 15:52:43.207960: val_loss -0.8685 
2025-03-22 15:52:43.213479: Pseudo dice [np.float64(0.9522), np.float64(0.9495), np.float64(0.9199)] 
2025-03-22 15:52:43.219497: Epoch time: 42.48 s 
2025-03-22 15:52:44.003646:  
2025-03-22 15:52:44.010873: Epoch 968 
2025-03-22 15:52:44.014020: Current learning rate: 0.00045 
2025-03-22 15:53:26.466726: train_loss -0.8881 
2025-03-22 15:53:26.475620: val_loss -0.855 
2025-03-22 15:53:26.483158: Pseudo dice [np.float64(0.9559), np.float64(0.943), np.float64(0.9214)] 
2025-03-22 15:53:26.490705: Epoch time: 42.46 s 
2025-03-22 15:53:27.268745:  
2025-03-22 15:53:27.276828: Epoch 969 
2025-03-22 15:53:27.282415: Current learning rate: 0.00044 
2025-03-22 15:54:10.200527: train_loss -0.8957 
2025-03-22 15:54:10.207550: val_loss -0.854 
2025-03-22 15:54:10.215072: Pseudo dice [np.float64(0.9506), np.float64(0.9413), np.float64(0.9222)] 
2025-03-22 15:54:10.223099: Epoch time: 42.93 s 
2025-03-22 15:54:11.008499:  
2025-03-22 15:54:11.015036: Epoch 970 
2025-03-22 15:54:11.019628: Current learning rate: 0.00043 
2025-03-22 15:54:54.026038: train_loss -0.887 
2025-03-22 15:54:54.035561: val_loss -0.8525 
2025-03-22 15:54:54.042083: Pseudo dice [np.float64(0.9519), np.float64(0.9468), np.float64(0.9179)] 
2025-03-22 15:54:54.048099: Epoch time: 43.02 s 
2025-03-22 15:54:54.837656:  
2025-03-22 15:54:54.845221: Epoch 971 
2025-03-22 15:54:54.850286: Current learning rate: 0.00041 
2025-03-22 15:55:37.556470: train_loss -0.8927 
2025-03-22 15:55:37.563982: val_loss -0.8608 
2025-03-22 15:55:37.570494: Pseudo dice [np.float64(0.9593), np.float64(0.9388), np.float64(0.9328)] 
2025-03-22 15:55:37.575502: Epoch time: 42.72 s 
2025-03-22 15:55:37.582512: Yayy! New best EMA pseudo Dice: 0.9388 
2025-03-22 15:55:38.516326:  
2025-03-22 15:55:38.524928: Epoch 972 
2025-03-22 15:55:38.530618: Current learning rate: 0.0004 
2025-03-22 15:56:21.230450: train_loss -0.898 
2025-03-22 15:56:21.236463: val_loss -0.866 
2025-03-22 15:56:21.242993: Pseudo dice [np.float64(0.9524), np.float64(0.9416), np.float64(0.9174)] 
2025-03-22 15:56:21.249012: Epoch time: 42.71 s 
2025-03-22 15:56:22.049937:  
2025-03-22 15:56:22.056476: Epoch 973 
2025-03-22 15:56:22.061500: Current learning rate: 0.00039 
2025-03-22 15:57:04.519410: train_loss -0.8881 
2025-03-22 15:57:04.526988: val_loss -0.8762 
2025-03-22 15:57:04.533617: Pseudo dice [np.float64(0.9565), np.float64(0.9375), np.float64(0.9174)] 
2025-03-22 15:57:04.540146: Epoch time: 42.47 s 
2025-03-22 15:57:05.315777:  
2025-03-22 15:57:05.322351: Epoch 974 
2025-03-22 15:57:05.327954: Current learning rate: 0.00037 
2025-03-22 15:57:48.855431: train_loss -0.8959 
2025-03-22 15:57:48.865454: val_loss -0.8707 
2025-03-22 15:57:48.872976: Pseudo dice [np.float64(0.955), np.float64(0.9531), np.float64(0.9276)] 
2025-03-22 15:57:48.879498: Epoch time: 43.54 s 
2025-03-22 15:57:48.886016: Yayy! New best EMA pseudo Dice: 0.9392 
2025-03-22 15:57:50.038379:  
2025-03-22 15:57:50.045434: Epoch 975 
2025-03-22 15:57:50.049024: Current learning rate: 0.00036 
2025-03-22 15:58:32.580329: train_loss -0.9003 
2025-03-22 15:58:32.588451: val_loss -0.8856 
2025-03-22 15:58:32.595563: Pseudo dice [np.float64(0.9558), np.float64(0.9514), np.float64(0.9207)] 
2025-03-22 15:58:32.601137: Epoch time: 42.54 s 
2025-03-22 15:58:32.607247: Yayy! New best EMA pseudo Dice: 0.9395 
2025-03-22 15:58:33.505439:  
2025-03-22 15:58:33.512489: Epoch 976 
2025-03-22 15:58:33.516138: Current learning rate: 0.00035 
2025-03-22 15:59:16.131061: train_loss -0.8961 
2025-03-22 15:59:16.139582: val_loss -0.8658 
2025-03-22 15:59:16.147101: Pseudo dice [np.float64(0.954), np.float64(0.9254), np.float64(0.9177)] 
2025-03-22 15:59:16.152116: Epoch time: 42.63 s 
2025-03-22 15:59:16.900794:  
2025-03-22 15:59:16.908874: Epoch 977 
2025-03-22 15:59:16.915059: Current learning rate: 0.00034 
2025-03-22 15:59:59.491634: train_loss -0.8937 
2025-03-22 15:59:59.499654: val_loss -0.8598 
2025-03-22 15:59:59.505672: Pseudo dice [np.float64(0.9509), np.float64(0.9246), np.float64(0.9175)] 
2025-03-22 15:59:59.512185: Epoch time: 42.59 s 
2025-03-22 16:00:00.286650:  
2025-03-22 16:00:00.292678: Epoch 978 
2025-03-22 16:00:00.297761: Current learning rate: 0.00032 
2025-03-22 16:00:42.884140: train_loss -0.8973 
2025-03-22 16:00:42.891154: val_loss -0.8533 
2025-03-22 16:00:42.896172: Pseudo dice [np.float64(0.9546), np.float64(0.9149), np.float64(0.9171)] 
2025-03-22 16:00:42.900185: Epoch time: 42.6 s 
2025-03-22 16:00:43.678513:  
2025-03-22 16:00:43.685067: Epoch 979 
2025-03-22 16:00:43.690090: Current learning rate: 0.00031 
2025-03-22 16:01:26.318262: train_loss -0.89 
2025-03-22 16:01:26.325781: val_loss -0.8599 
2025-03-22 16:01:26.333303: Pseudo dice [np.float64(0.9535), np.float64(0.9452), np.float64(0.9209)] 
2025-03-22 16:01:26.340832: Epoch time: 42.64 s 
2025-03-22 16:01:27.122977:  
2025-03-22 16:01:27.130494: Epoch 980 
2025-03-22 16:01:27.135519: Current learning rate: 0.0003 
2025-03-22 16:02:09.662411: train_loss -0.8959 
2025-03-22 16:02:09.669927: val_loss -0.8607 
2025-03-22 16:02:09.678957: Pseudo dice [np.float64(0.9537), np.float64(0.9139), np.float64(0.916)] 
2025-03-22 16:02:09.687478: Epoch time: 42.54 s 
2025-03-22 16:02:10.519009:  
2025-03-22 16:02:10.526244: Epoch 981 
2025-03-22 16:02:10.531789: Current learning rate: 0.00028 
2025-03-22 16:02:53.315860: train_loss -0.8941 
2025-03-22 16:02:53.325495: val_loss -0.8667 
2025-03-22 16:02:53.333718: Pseudo dice [np.float64(0.9553), np.float64(0.9413), np.float64(0.9151)] 
2025-03-22 16:02:53.341363: Epoch time: 42.8 s 
2025-03-22 16:02:54.163061:  
2025-03-22 16:02:54.169632: Epoch 982 
2025-03-22 16:02:54.174746: Current learning rate: 0.00027 
2025-03-22 16:03:37.114165: train_loss -0.8913 
2025-03-22 16:03:37.121805: val_loss -0.8526 
2025-03-22 16:03:37.129451: Pseudo dice [np.float64(0.9554), np.float64(0.9409), np.float64(0.9197)] 
2025-03-22 16:03:37.136085: Epoch time: 42.95 s 
2025-03-22 16:03:38.151028:  
2025-03-22 16:03:38.157753: Epoch 983 
2025-03-22 16:03:38.161265: Current learning rate: 0.00026 
2025-03-22 16:04:20.903669: train_loss -0.8927 
2025-03-22 16:04:20.912689: val_loss -0.8605 
2025-03-22 16:04:20.917706: Pseudo dice [np.float64(0.9483), np.float64(0.9347), np.float64(0.9213)] 
2025-03-22 16:04:20.922722: Epoch time: 42.75 s 
2025-03-22 16:04:21.707936:  
2025-03-22 16:04:21.714497: Epoch 984 
2025-03-22 16:04:21.719027: Current learning rate: 0.00024 
2025-03-22 16:05:07.915390: train_loss -0.8886 
2025-03-22 16:05:07.922970: val_loss -0.8599 
2025-03-22 16:05:07.929037: Pseudo dice [np.float64(0.9522), np.float64(0.9514), np.float64(0.9275)] 
2025-03-22 16:05:07.936114: Epoch time: 46.21 s 
2025-03-22 16:05:08.724213:  
2025-03-22 16:05:08.733291: Epoch 985 
2025-03-22 16:05:08.738843: Current learning rate: 0.00023 
2025-03-22 16:05:51.111692: train_loss -0.8996 
2025-03-22 16:05:51.120219: val_loss -0.8509 
2025-03-22 16:05:51.127739: Pseudo dice [np.float64(0.9494), np.float64(0.9134), np.float64(0.9119)] 
2025-03-22 16:05:51.133749: Epoch time: 42.39 s 
2025-03-22 16:05:51.919877:  
2025-03-22 16:05:51.926438: Epoch 986 
2025-03-22 16:05:51.931306: Current learning rate: 0.00021 
2025-03-22 16:06:34.645983: train_loss -0.9001 
2025-03-22 16:06:34.653544: val_loss -0.8466 
2025-03-22 16:06:34.661069: Pseudo dice [np.float64(0.949), np.float64(0.9397), np.float64(0.9241)] 
2025-03-22 16:06:34.666083: Epoch time: 42.73 s 
2025-03-22 16:06:35.438371:  
2025-03-22 16:06:35.445994: Epoch 987 
2025-03-22 16:06:35.451603: Current learning rate: 0.0002 
2025-03-22 16:07:18.349257: train_loss -0.8917 
2025-03-22 16:07:18.357785: val_loss -0.8274 
2025-03-22 16:07:18.364313: Pseudo dice [np.float64(0.9539), np.float64(0.937), np.float64(0.9256)] 
2025-03-22 16:07:18.371840: Epoch time: 42.91 s 
2025-03-22 16:07:19.170925:  
2025-03-22 16:07:19.176970: Epoch 988 
2025-03-22 16:07:19.181011: Current learning rate: 0.00019 
2025-03-22 16:08:01.831515: train_loss -0.8863 
2025-03-22 16:08:01.839041: val_loss -0.8419 
2025-03-22 16:08:01.844058: Pseudo dice [np.float64(0.9488), np.float64(0.9419), np.float64(0.9136)] 
2025-03-22 16:08:01.849080: Epoch time: 42.66 s 
2025-03-22 16:08:02.631542:  
2025-03-22 16:08:02.639423: Epoch 989 
2025-03-22 16:08:02.644527: Current learning rate: 0.00017 
2025-03-22 16:08:45.412366: train_loss -0.8969 
2025-03-22 16:08:45.422402: val_loss -0.8626 
2025-03-22 16:08:45.431931: Pseudo dice [np.float64(0.9548), np.float64(0.943), np.float64(0.9239)] 
2025-03-22 16:08:45.438455: Epoch time: 42.78 s 
2025-03-22 16:08:46.195331:  
2025-03-22 16:08:46.201970: Epoch 990 
2025-03-22 16:08:46.207047: Current learning rate: 0.00016 
2025-03-22 16:09:28.911919: train_loss -0.8996 
2025-03-22 16:09:28.919973: val_loss -0.875 
2025-03-22 16:09:28.924986: Pseudo dice [np.float64(0.9534), np.float64(0.9466), np.float64(0.926)] 
2025-03-22 16:09:28.929996: Epoch time: 42.72 s 
2025-03-22 16:09:29.955034:  
2025-03-22 16:09:29.964054: Epoch 991 
2025-03-22 16:09:29.968062: Current learning rate: 0.00014 
2025-03-22 16:10:12.782886: train_loss -0.8949 
2025-03-22 16:10:12.792980: val_loss -0.8488 
2025-03-22 16:10:12.803060: Pseudo dice [np.float64(0.9502), np.float64(0.9392), np.float64(0.9309)] 
2025-03-22 16:10:12.812740: Epoch time: 42.83 s 
2025-03-22 16:10:13.596655:  
2025-03-22 16:10:13.604754: Epoch 992 
2025-03-22 16:10:13.611425: Current learning rate: 0.00013 
2025-03-22 16:10:56.325935: train_loss -0.8916 
2025-03-22 16:10:56.332536: val_loss -0.8581 
2025-03-22 16:10:56.338572: Pseudo dice [np.float64(0.9542), np.float64(0.9384), np.float64(0.9307)] 
2025-03-22 16:10:56.343657: Epoch time: 42.73 s 
2025-03-22 16:10:57.142238:  
2025-03-22 16:10:57.148846: Epoch 993 
2025-03-22 16:10:57.153865: Current learning rate: 0.00011 
2025-03-22 16:11:40.912386: train_loss -0.8955 
2025-03-22 16:11:40.922052: val_loss -0.8682 
2025-03-22 16:11:40.929641: Pseudo dice [np.float64(0.9507), np.float64(0.9309), np.float64(0.9269)] 
2025-03-22 16:11:40.935720: Epoch time: 43.77 s 
2025-03-22 16:11:41.736248:  
2025-03-22 16:11:41.743392: Epoch 994 
2025-03-22 16:11:41.748937: Current learning rate: 0.0001 
2025-03-22 16:12:24.498768: train_loss -0.8953 
2025-03-22 16:12:24.506540: val_loss -0.8683 
2025-03-22 16:12:24.512518: Pseudo dice [np.float64(0.9577), np.float64(0.9548), np.float64(0.9206)] 
2025-03-22 16:12:24.520744: Epoch time: 42.76 s 
2025-03-22 16:12:25.306941:  
2025-03-22 16:12:25.313463: Epoch 995 
2025-03-22 16:12:25.318476: Current learning rate: 8e-05 
2025-03-22 16:13:08.147977: train_loss -0.8964 
2025-03-22 16:13:08.155501: val_loss -0.8577 
2025-03-22 16:13:08.160515: Pseudo dice [np.float64(0.9498), np.float64(0.9523), np.float64(0.9282)] 
2025-03-22 16:13:08.165032: Epoch time: 42.84 s 
2025-03-22 16:13:08.940507:  
2025-03-22 16:13:08.948127: Epoch 996 
2025-03-22 16:13:08.952692: Current learning rate: 7e-05 
2025-03-22 16:13:51.395980: train_loss -0.8989 
2025-03-22 16:13:51.403073: val_loss -0.8618 
2025-03-22 16:13:51.408151: Pseudo dice [np.float64(0.9545), np.float64(0.9485), np.float64(0.9301)] 
2025-03-22 16:13:51.413271: Epoch time: 42.46 s 
2025-03-22 16:13:52.205355:  
2025-03-22 16:13:52.211870: Epoch 997 
2025-03-22 16:13:52.216884: Current learning rate: 5e-05 
2025-03-22 16:14:35.022328: train_loss -0.8967 
2025-03-22 16:14:35.030356: val_loss -0.8483 
2025-03-22 16:14:35.036376: Pseudo dice [np.float64(0.9524), np.float64(0.9048), np.float64(0.9149)] 
2025-03-22 16:14:35.042900: Epoch time: 42.82 s 
2025-03-22 16:14:35.817575:  
2025-03-22 16:14:35.824701: Epoch 998 
2025-03-22 16:14:35.829785: Current learning rate: 4e-05 
2025-03-22 16:15:18.755178: train_loss -0.8825 
2025-03-22 16:15:18.763420: val_loss -0.8495 
2025-03-22 16:15:18.772545: Pseudo dice [np.float64(0.9499), np.float64(0.9184), np.float64(0.917)] 
2025-03-22 16:15:18.778634: Epoch time: 42.94 s 
2025-03-22 16:15:19.540598:  
2025-03-22 16:15:19.548119: Epoch 999 
2025-03-22 16:15:19.553133: Current learning rate: 2e-05 
2025-03-22 16:16:02.114551: train_loss -0.8894 
2025-03-22 16:16:02.123079: val_loss -0.867 
2025-03-22 16:16:02.129596: Pseudo dice [np.float64(0.9514), np.float64(0.9431), np.float64(0.9219)] 
2025-03-22 16:16:02.135614: Epoch time: 42.58 s 
2025-03-22 16:16:03.345698: Training done. 
2025-03-22 16:16:03.401699: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset137_BraTS2021\splits_final.json 
2025-03-22 16:16:03.417705: The split file contains 5 splits. 
2025-03-22 16:16:03.424703: Desired fold for training: 1 
2025-03-22 16:16:03.429747: This split has 1001 training and 250 validation cases. 
2025-03-22 16:16:03.440747: predicting BraTS2021_00005 
2025-03-22 16:16:03.451748: BraTS2021_00005, shape torch.Size([4, 136, 161, 134]), rank 0 
2025-03-22 16:16:04.617148: predicting BraTS2021_00006 
2025-03-22 16:16:04.627655: BraTS2021_00006, shape torch.Size([4, 136, 177, 134]), rank 0 
2025-03-22 16:16:05.377435: predicting BraTS2021_00011 
2025-03-22 16:16:05.388434: BraTS2021_00011, shape torch.Size([4, 142, 166, 141]), rank 0 
2025-03-22 16:16:06.127834: predicting BraTS2021_00012 
2025-03-22 16:16:06.139872: BraTS2021_00012, shape torch.Size([4, 141, 178, 143]), rank 0 
2025-03-22 16:16:06.884443: predicting BraTS2021_00020 
2025-03-22 16:16:06.901443: BraTS2021_00020, shape torch.Size([4, 137, 182, 137]), rank 0 
2025-03-22 16:16:07.642873: predicting BraTS2021_00021 
2025-03-22 16:16:07.658380: BraTS2021_00021, shape torch.Size([4, 134, 177, 128]), rank 0 
2025-03-22 16:16:08.396348: predicting BraTS2021_00036 
2025-03-22 16:16:08.406348: BraTS2021_00036, shape torch.Size([4, 134, 201, 142]), rank 0 
2025-03-22 16:16:09.520478: predicting BraTS2021_00053 
2025-03-22 16:16:09.531986: BraTS2021_00053, shape torch.Size([4, 145, 208, 141]), rank 0 
2025-03-22 16:16:11.128636: predicting BraTS2021_00061 
2025-03-22 16:16:11.142640: BraTS2021_00061, shape torch.Size([4, 141, 188, 136]), rank 0 
2025-03-22 16:16:11.920189: predicting BraTS2021_00081 
2025-03-22 16:16:11.939248: BraTS2021_00081, shape torch.Size([4, 145, 150, 139]), rank 0 
2025-03-22 16:16:13.027442: predicting BraTS2021_00084 
2025-03-22 16:16:13.041946: BraTS2021_00084, shape torch.Size([4, 128, 171, 128]), rank 0 
2025-03-22 16:16:13.782675: predicting BraTS2021_00090 
2025-03-22 16:16:13.793675: BraTS2021_00090, shape torch.Size([4, 140, 177, 135]), rank 0 
2025-03-22 16:16:14.547473: predicting BraTS2021_00095 
2025-03-22 16:16:14.563473: BraTS2021_00095, shape torch.Size([4, 136, 193, 149]), rank 0 
2025-03-22 16:16:16.183237: predicting BraTS2021_00097 
2025-03-22 16:16:16.197236: BraTS2021_00097, shape torch.Size([4, 133, 175, 133]), rank 0 
2025-03-22 16:16:16.958618: predicting BraTS2021_00101 
2025-03-22 16:16:16.973618: BraTS2021_00101, shape torch.Size([4, 137, 178, 137]), rank 0 
2025-03-22 16:16:17.716379: predicting BraTS2021_00109 
2025-03-22 16:16:17.730377: BraTS2021_00109, shape torch.Size([4, 144, 157, 135]), rank 0 
2025-03-22 16:16:18.468520: predicting BraTS2021_00133 
2025-03-22 16:16:18.480520: BraTS2021_00133, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-03-22 16:16:19.583772: predicting BraTS2021_00147 
2025-03-22 16:16:19.603774: BraTS2021_00147, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-03-22 16:16:20.695769: predicting BraTS2021_00157 
2025-03-22 16:16:20.710768: BraTS2021_00157, shape torch.Size([4, 131, 163, 177]), rank 0 
2025-03-22 16:16:21.815217: predicting BraTS2021_00159 
2025-03-22 16:16:21.828219: BraTS2021_00159, shape torch.Size([4, 143, 180, 138]), rank 0 
2025-03-22 16:16:22.594369: predicting BraTS2021_00162 
2025-03-22 16:16:22.608369: BraTS2021_00162, shape torch.Size([4, 139, 172, 135]), rank 0 
2025-03-22 16:16:23.380579: predicting BraTS2021_00170 
2025-03-22 16:16:23.398578: BraTS2021_00170, shape torch.Size([4, 137, 170, 125]), rank 0 
2025-03-22 16:16:24.137130: predicting BraTS2021_00171 
2025-03-22 16:16:24.150129: BraTS2021_00171, shape torch.Size([4, 136, 177, 141]), rank 0 
2025-03-22 16:16:24.920179: predicting BraTS2021_00177 
2025-03-22 16:16:24.935183: BraTS2021_00177, shape torch.Size([4, 139, 172, 147]), rank 0 
2025-03-22 16:16:26.027216: predicting BraTS2021_00178 
2025-03-22 16:16:26.039725: BraTS2021_00178, shape torch.Size([4, 141, 175, 135]), rank 0 
2025-03-22 16:16:26.799264: predicting BraTS2021_00184 
2025-03-22 16:16:26.815265: BraTS2021_00184, shape torch.Size([4, 137, 177, 139]), rank 0 
2025-03-22 16:16:27.582615: predicting BraTS2021_00188 
2025-03-22 16:16:27.596616: BraTS2021_00188, shape torch.Size([4, 138, 180, 143]), rank 0 
2025-03-22 16:16:28.355967: predicting BraTS2021_00191 
2025-03-22 16:16:28.368967: BraTS2021_00191, shape torch.Size([4, 140, 179, 136]), rank 0 
2025-03-22 16:16:29.135825: predicting BraTS2021_00204 
2025-03-22 16:16:29.149336: BraTS2021_00204, shape torch.Size([4, 138, 174, 140]), rank 0 
2025-03-22 16:16:29.929635: predicting BraTS2021_00207 
2025-03-22 16:16:29.944141: BraTS2021_00207, shape torch.Size([4, 143, 170, 132]), rank 0 
2025-03-22 16:16:30.703107: predicting BraTS2021_00210 
2025-03-22 16:16:30.716107: BraTS2021_00210, shape torch.Size([4, 142, 170, 135]), rank 0 
2025-03-22 16:16:31.476899: predicting BraTS2021_00220 
2025-03-22 16:16:31.490899: BraTS2021_00220, shape torch.Size([4, 137, 172, 127]), rank 0 
2025-03-22 16:16:32.235587: predicting BraTS2021_00222 
2025-03-22 16:16:32.251096: BraTS2021_00222, shape torch.Size([4, 140, 175, 141]), rank 0 
2025-03-22 16:16:32.995758: predicting BraTS2021_00233 
2025-03-22 16:16:33.007758: BraTS2021_00233, shape torch.Size([4, 135, 162, 142]), rank 0 
2025-03-22 16:16:33.762973: predicting BraTS2021_00234 
2025-03-22 16:16:33.774973: BraTS2021_00234, shape torch.Size([4, 144, 178, 146]), rank 0 
2025-03-22 16:16:34.879580: predicting BraTS2021_00237 
2025-03-22 16:16:34.893580: BraTS2021_00237, shape torch.Size([4, 138, 173, 133]), rank 0 
2025-03-22 16:16:35.648024: predicting BraTS2021_00247 
2025-03-22 16:16:35.661024: BraTS2021_00247, shape torch.Size([4, 136, 160, 129]), rank 0 
2025-03-22 16:16:36.424444: predicting BraTS2021_00258 
2025-03-22 16:16:36.442630: BraTS2021_00258, shape torch.Size([4, 138, 177, 129]), rank 0 
2025-03-22 16:16:37.185501: predicting BraTS2021_00260 
2025-03-22 16:16:37.201501: BraTS2021_00260, shape torch.Size([4, 143, 162, 147]), rank 0 
2025-03-22 16:16:38.293406: predicting BraTS2021_00263 
2025-03-22 16:16:38.305405: BraTS2021_00263, shape torch.Size([4, 140, 190, 138]), rank 0 
2025-03-22 16:16:39.063873: predicting BraTS2021_00267 
2025-03-22 16:16:39.077873: BraTS2021_00267, shape torch.Size([4, 142, 171, 146]), rank 0 
2025-03-22 16:16:40.196093: predicting BraTS2021_00281 
2025-03-22 16:16:40.210094: BraTS2021_00281, shape torch.Size([4, 140, 162, 136]), rank 0 
2025-03-22 16:16:40.950374: predicting BraTS2021_00282 
2025-03-22 16:16:40.961374: BraTS2021_00282, shape torch.Size([4, 139, 173, 146]), rank 0 
2025-03-22 16:16:42.067215: predicting BraTS2021_00289 
2025-03-22 16:16:42.080216: BraTS2021_00289, shape torch.Size([4, 139, 175, 130]), rank 0 
2025-03-22 16:16:42.835160: predicting BraTS2021_00290 
2025-03-22 16:16:42.849667: BraTS2021_00290, shape torch.Size([4, 149, 176, 143]), rank 0 
2025-03-22 16:16:43.958982: predicting BraTS2021_00293 
2025-03-22 16:16:43.974983: BraTS2021_00293, shape torch.Size([4, 141, 176, 138]), rank 0 
2025-03-22 16:16:44.718302: predicting BraTS2021_00303 
2025-03-22 16:16:44.730304: BraTS2021_00303, shape torch.Size([4, 140, 176, 142]), rank 0 
2025-03-22 16:16:45.496272: predicting BraTS2021_00310 
2025-03-22 16:16:45.515272: BraTS2021_00310, shape torch.Size([4, 136, 162, 135]), rank 0 
2025-03-22 16:16:46.258116: predicting BraTS2021_00312 
2025-03-22 16:16:46.268116: BraTS2021_00312, shape torch.Size([4, 140, 168, 135]), rank 0 
2025-03-22 16:16:47.034969: predicting BraTS2021_00331 
2025-03-22 16:16:47.048482: BraTS2021_00331, shape torch.Size([4, 147, 173, 137]), rank 0 
2025-03-22 16:16:48.145755: predicting BraTS2021_00339 
2025-03-22 16:16:48.157871: BraTS2021_00339, shape torch.Size([4, 142, 174, 138]), rank 0 
2025-03-22 16:16:48.923086: predicting BraTS2021_00341 
2025-03-22 16:16:48.939091: BraTS2021_00341, shape torch.Size([4, 135, 160, 132]), rank 0 
2025-03-22 16:16:49.694737: predicting BraTS2021_00343 
2025-03-22 16:16:49.710739: BraTS2021_00343, shape torch.Size([4, 143, 179, 127]), rank 0 
2025-03-22 16:16:50.507117: predicting BraTS2021_00344 
2025-03-22 16:16:50.519116: BraTS2021_00344, shape torch.Size([4, 138, 167, 132]), rank 0 
2025-03-22 16:16:51.323368: predicting BraTS2021_00360 
2025-03-22 16:16:51.335371: BraTS2021_00360, shape torch.Size([4, 137, 165, 138]), rank 0 
2025-03-22 16:16:52.086802: predicting BraTS2021_00377 
2025-03-22 16:16:52.099803: BraTS2021_00377, shape torch.Size([4, 131, 162, 132]), rank 0 
2025-03-22 16:16:52.850894: predicting BraTS2021_00397 
2025-03-22 16:16:52.863894: BraTS2021_00397, shape torch.Size([4, 145, 168, 126]), rank 0 
2025-03-22 16:16:53.963840: predicting BraTS2021_00417 
2025-03-22 16:16:53.976840: BraTS2021_00417, shape torch.Size([4, 135, 162, 142]), rank 0 
2025-03-22 16:16:54.730122: predicting BraTS2021_00440 
2025-03-22 16:16:54.744122: BraTS2021_00440, shape torch.Size([4, 139, 179, 138]), rank 0 
2025-03-22 16:16:55.531743: predicting BraTS2021_00445 
2025-03-22 16:16:55.545747: BraTS2021_00445, shape torch.Size([4, 133, 179, 146]), rank 0 
2025-03-22 16:16:56.647331: predicting BraTS2021_00453 
2025-03-22 16:16:56.659838: BraTS2021_00453, shape torch.Size([4, 136, 170, 128]), rank 0 
2025-03-22 16:16:57.415026: predicting BraTS2021_00455 
2025-03-22 16:16:57.428026: BraTS2021_00455, shape torch.Size([4, 133, 157, 134]), rank 0 
2025-03-22 16:16:58.178419: predicting BraTS2021_00466 
2025-03-22 16:16:58.191419: BraTS2021_00466, shape torch.Size([4, 149, 163, 145]), rank 0 
2025-03-22 16:16:59.813129: predicting BraTS2021_00468 
2025-03-22 16:16:59.828129: BraTS2021_00468, shape torch.Size([4, 144, 169, 133]), rank 0 
2025-03-22 16:17:00.588289: predicting BraTS2021_00477 
2025-03-22 16:17:00.606289: BraTS2021_00477, shape torch.Size([4, 144, 178, 142]), rank 0 
2025-03-22 16:17:01.358665: predicting BraTS2021_00488 
2025-03-22 16:17:01.373664: BraTS2021_00488, shape torch.Size([4, 138, 181, 136]), rank 0 
2025-03-22 16:17:02.144982: predicting BraTS2021_00506 
2025-03-22 16:17:02.163006: BraTS2021_00506, shape torch.Size([4, 145, 182, 142]), rank 0 
2025-03-22 16:17:03.257815: predicting BraTS2021_00518 
2025-03-22 16:17:03.275816: BraTS2021_00518, shape torch.Size([4, 136, 181, 133]), rank 0 
2025-03-22 16:17:04.043446: predicting BraTS2021_00520 
2025-03-22 16:17:04.061953: BraTS2021_00520, shape torch.Size([4, 138, 171, 137]), rank 0 
2025-03-22 16:17:04.808483: predicting BraTS2021_00525 
2025-03-22 16:17:04.823483: BraTS2021_00525, shape torch.Size([4, 148, 175, 143]), rank 0 
2025-03-22 16:17:05.948936: predicting BraTS2021_00529 
2025-03-22 16:17:05.968446: BraTS2021_00529, shape torch.Size([4, 143, 178, 138]), rank 0 
2025-03-22 16:17:06.730452: predicting BraTS2021_00545 
2025-03-22 16:17:06.748456: BraTS2021_00545, shape torch.Size([4, 132, 168, 138]), rank 0 
2025-03-22 16:17:07.490822: predicting BraTS2021_00547 
2025-03-22 16:17:07.508823: BraTS2021_00547, shape torch.Size([4, 146, 172, 141]), rank 0 
2025-03-22 16:17:08.607459: predicting BraTS2021_00552 
2025-03-22 16:17:08.625459: BraTS2021_00552, shape torch.Size([4, 148, 173, 138]), rank 0 
2025-03-22 16:17:09.723179: predicting BraTS2021_00555 
2025-03-22 16:17:09.741181: BraTS2021_00555, shape torch.Size([4, 141, 156, 139]), rank 0 
2025-03-22 16:17:10.485329: predicting BraTS2021_00557 
2025-03-22 16:17:10.500335: BraTS2021_00557, shape torch.Size([4, 137, 173, 137]), rank 0 
2025-03-22 16:17:11.249425: predicting BraTS2021_00559 
2025-03-22 16:17:11.263930: BraTS2021_00559, shape torch.Size([4, 143, 169, 138]), rank 0 
2025-03-22 16:17:12.021133: predicting BraTS2021_00570 
2025-03-22 16:17:12.035133: BraTS2021_00570, shape torch.Size([4, 102, 166, 128]), rank 0 
2025-03-22 16:17:12.779105: predicting BraTS2021_00571 
2025-03-22 16:17:12.792105: BraTS2021_00571, shape torch.Size([4, 98, 175, 138]), rank 0 
2025-03-22 16:17:13.528775: predicting BraTS2021_00576 
2025-03-22 16:17:13.541774: BraTS2021_00576, shape torch.Size([4, 130, 167, 128]), rank 0 
2025-03-22 16:17:14.280584: predicting BraTS2021_00579 
2025-03-22 16:17:14.295584: BraTS2021_00579, shape torch.Size([4, 143, 177, 135]), rank 0 
2025-03-22 16:17:15.044323: predicting BraTS2021_00580 
2025-03-22 16:17:15.063325: BraTS2021_00580, shape torch.Size([4, 141, 184, 139]), rank 0 
2025-03-22 16:17:15.810594: predicting BraTS2021_00593 
2025-03-22 16:17:15.830595: BraTS2021_00593, shape torch.Size([4, 147, 171, 142]), rank 0 
2025-03-22 16:17:16.929636: predicting BraTS2021_00594 
2025-03-22 16:17:16.945632: BraTS2021_00594, shape torch.Size([4, 133, 193, 146]), rank 0 
2025-03-22 16:17:18.575414: predicting BraTS2021_00598 
2025-03-22 16:17:18.590414: BraTS2021_00598, shape torch.Size([4, 140, 188, 142]), rank 0 
2025-03-22 16:17:19.352535: predicting BraTS2021_00599 
2025-03-22 16:17:19.370612: BraTS2021_00599, shape torch.Size([4, 135, 155, 134]), rank 0 
2025-03-22 16:17:20.109534: predicting BraTS2021_00610 
2025-03-22 16:17:20.122533: BraTS2021_00610, shape torch.Size([4, 143, 179, 141]), rank 0 
2025-03-22 16:17:20.883950: predicting BraTS2021_00612 
2025-03-22 16:17:20.904950: BraTS2021_00612, shape torch.Size([4, 140, 180, 120]), rank 0 
2025-03-22 16:17:21.642199: predicting BraTS2021_00615 
2025-03-22 16:17:21.656201: BraTS2021_00615, shape torch.Size([4, 141, 176, 132]), rank 0 
2025-03-22 16:17:22.413866: predicting BraTS2021_00616 
2025-03-22 16:17:22.427865: BraTS2021_00616, shape torch.Size([4, 149, 174, 136]), rank 0 
2025-03-22 16:17:23.527383: predicting BraTS2021_00628 
2025-03-22 16:17:23.548383: BraTS2021_00628, shape torch.Size([4, 151, 177, 134]), rank 0 
2025-03-22 16:17:24.642757: predicting BraTS2021_00631 
2025-03-22 16:17:24.659760: BraTS2021_00631, shape torch.Size([4, 140, 176, 143]), rank 0 
2025-03-22 16:17:25.426332: predicting BraTS2021_00640 
2025-03-22 16:17:25.441330: BraTS2021_00640, shape torch.Size([4, 142, 170, 143]), rank 0 
2025-03-22 16:17:26.212186: predicting BraTS2021_00642 
2025-03-22 16:17:26.231185: BraTS2021_00642, shape torch.Size([4, 138, 170, 137]), rank 0 
2025-03-22 16:17:26.973306: predicting BraTS2021_00645 
2025-03-22 16:17:26.988307: BraTS2021_00645, shape torch.Size([4, 137, 177, 140]), rank 0 
2025-03-22 16:17:27.765066: predicting BraTS2021_00657 
2025-03-22 16:17:27.778573: BraTS2021_00657, shape torch.Size([4, 146, 172, 139]), rank 0 
2025-03-22 16:17:28.882094: predicting BraTS2021_00658 
2025-03-22 16:17:28.903095: BraTS2021_00658, shape torch.Size([4, 142, 181, 147]), rank 0 
2025-03-22 16:17:29.998166: predicting BraTS2021_00661 
2025-03-22 16:17:30.015722: BraTS2021_00661, shape torch.Size([4, 145, 173, 131]), rank 0 
2025-03-22 16:17:31.113058: predicting BraTS2021_00663 
2025-03-22 16:17:31.128057: BraTS2021_00663, shape torch.Size([4, 147, 167, 150]), rank 0 
2025-03-22 16:17:32.767865: predicting BraTS2021_00675 
2025-03-22 16:17:32.784371: BraTS2021_00675, shape torch.Size([4, 148, 180, 140]), rank 0 
2025-03-22 16:17:33.889392: predicting BraTS2021_00688 
2025-03-22 16:17:33.905392: BraTS2021_00688, shape torch.Size([4, 138, 190, 138]), rank 0 
2025-03-22 16:17:34.656223: predicting BraTS2021_00692 
2025-03-22 16:17:34.675228: BraTS2021_00692, shape torch.Size([4, 146, 192, 145]), rank 0 
2025-03-22 16:17:36.279801: predicting BraTS2021_00703 
2025-03-22 16:17:36.296801: BraTS2021_00703, shape torch.Size([4, 143, 183, 139]), rank 0 
2025-03-22 16:17:37.059419: predicting BraTS2021_00718 
2025-03-22 16:17:37.074420: BraTS2021_00718, shape torch.Size([4, 147, 180, 146]), rank 0 
2025-03-22 16:17:38.701412: predicting BraTS2021_00730 
2025-03-22 16:17:38.718420: BraTS2021_00730, shape torch.Size([4, 140, 162, 140]), rank 0 
2025-03-22 16:17:39.472553: predicting BraTS2021_00731 
2025-03-22 16:17:39.487061: BraTS2021_00731, shape torch.Size([4, 143, 155, 136]), rank 0 
2025-03-22 16:17:40.249699: predicting BraTS2021_00736 
2025-03-22 16:17:40.263698: BraTS2021_00736, shape torch.Size([4, 140, 169, 134]), rank 0 
2025-03-22 16:17:41.009869: predicting BraTS2021_00744 
2025-03-22 16:17:41.023868: BraTS2021_00744, shape torch.Size([4, 140, 188, 141]), rank 0 
2025-03-22 16:17:41.781733: predicting BraTS2021_00746 
2025-03-22 16:17:41.801901: BraTS2021_00746, shape torch.Size([4, 142, 170, 134]), rank 0 
2025-03-22 16:17:42.558565: predicting BraTS2021_00778 
2025-03-22 16:17:42.576569: BraTS2021_00778, shape torch.Size([4, 133, 175, 132]), rank 0 
2025-03-22 16:17:43.316944: predicting BraTS2021_00784 
2025-03-22 16:17:43.333945: BraTS2021_00784, shape torch.Size([4, 141, 158, 128]), rank 0 
2025-03-22 16:17:44.075096: predicting BraTS2021_00788 
2025-03-22 16:17:44.093136: BraTS2021_00788, shape torch.Size([4, 134, 166, 133]), rank 0 
2025-03-22 16:17:44.832495: predicting BraTS2021_00795 
2025-03-22 16:17:44.846494: BraTS2021_00795, shape torch.Size([4, 152, 176, 143]), rank 0 
2025-03-22 16:17:45.961175: predicting BraTS2021_00809 
2025-03-22 16:17:45.979181: BraTS2021_00809, shape torch.Size([4, 141, 170, 148]), rank 0 
2025-03-22 16:17:47.075768: predicting BraTS2021_00811 
2025-03-22 16:17:47.095275: BraTS2021_00811, shape torch.Size([4, 152, 159, 140]), rank 0 
2025-03-22 16:17:48.194112: predicting BraTS2021_00814 
2025-03-22 16:17:48.209112: BraTS2021_00814, shape torch.Size([4, 150, 164, 135]), rank 0 
2025-03-22 16:17:49.316159: predicting BraTS2021_00819 
2025-03-22 16:17:49.335164: BraTS2021_00819, shape torch.Size([4, 151, 182, 137]), rank 0 
2025-03-22 16:17:50.434408: predicting BraTS2021_00837 
2025-03-22 16:17:50.450412: BraTS2021_00837, shape torch.Size([4, 140, 166, 132]), rank 0 
2025-03-22 16:17:51.212658: predicting BraTS2021_01002 
2025-03-22 16:17:51.226657: BraTS2021_01002, shape torch.Size([4, 136, 165, 140]), rank 0 
2025-03-22 16:17:51.984607: predicting BraTS2021_01003 
2025-03-22 16:17:52.002115: BraTS2021_01003, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-03-22 16:17:52.743633: predicting BraTS2021_01009 
2025-03-22 16:17:52.759631: BraTS2021_01009, shape torch.Size([4, 139, 169, 135]), rank 0 
2025-03-22 16:17:53.505984: predicting BraTS2021_01019 
2025-03-22 16:17:53.521984: BraTS2021_01019, shape torch.Size([4, 145, 177, 148]), rank 0 
2025-03-22 16:17:55.126467: predicting BraTS2021_01020 
2025-03-22 16:17:55.143467: BraTS2021_01020, shape torch.Size([4, 137, 170, 140]), rank 0 
2025-03-22 16:17:55.884875: predicting BraTS2021_01027 
2025-03-22 16:17:55.899133: BraTS2021_01027, shape torch.Size([4, 141, 178, 137]), rank 0 
2025-03-22 16:17:56.672262: predicting BraTS2021_01028 
2025-03-22 16:17:56.687273: BraTS2021_01028, shape torch.Size([4, 140, 162, 138]), rank 0 
2025-03-22 16:17:57.444250: predicting BraTS2021_01034 
2025-03-22 16:17:57.458251: BraTS2021_01034, shape torch.Size([4, 140, 173, 127]), rank 0 
2025-03-22 16:17:58.214685: predicting BraTS2021_01040 
2025-03-22 16:17:58.230686: BraTS2021_01040, shape torch.Size([4, 140, 184, 137]), rank 0 
2025-03-22 16:17:58.979980: predicting BraTS2021_01041 
2025-03-22 16:17:58.996487: BraTS2021_01041, shape torch.Size([4, 144, 176, 138]), rank 0 
2025-03-22 16:17:59.762651: predicting BraTS2021_01045 
2025-03-22 16:17:59.777652: BraTS2021_01045, shape torch.Size([4, 142, 183, 133]), rank 0 
2025-03-22 16:18:00.558860: predicting BraTS2021_01053 
2025-03-22 16:18:00.577860: BraTS2021_01053, shape torch.Size([4, 139, 168, 135]), rank 0 
2025-03-22 16:18:01.323580: predicting BraTS2021_01054 
2025-03-22 16:18:01.337580: BraTS2021_01054, shape torch.Size([4, 134, 172, 133]), rank 0 
2025-03-22 16:18:02.098915: predicting BraTS2021_01061 
2025-03-22 16:18:02.112914: BraTS2021_01061, shape torch.Size([4, 141, 172, 130]), rank 0 
2025-03-22 16:18:02.871834: predicting BraTS2021_01067 
2025-03-22 16:18:02.885839: BraTS2021_01067, shape torch.Size([4, 143, 165, 137]), rank 0 
2025-03-22 16:18:03.649801: predicting BraTS2021_01068 
2025-03-22 16:18:03.664799: BraTS2021_01068, shape torch.Size([4, 143, 178, 148]), rank 0 
2025-03-22 16:18:04.778118: predicting BraTS2021_01084 
2025-03-22 16:18:04.796125: BraTS2021_01084, shape torch.Size([4, 137, 182, 134]), rank 0 
2025-03-22 16:18:05.538901: predicting BraTS2021_01086 
2025-03-22 16:18:05.557903: BraTS2021_01086, shape torch.Size([4, 144, 183, 143]), rank 0 
2025-03-22 16:18:06.305779: predicting BraTS2021_01092 
2025-03-22 16:18:06.323780: BraTS2021_01092, shape torch.Size([4, 139, 161, 129]), rank 0 
2025-03-22 16:18:07.065803: predicting BraTS2021_01098 
2025-03-22 16:18:07.080804: BraTS2021_01098, shape torch.Size([4, 142, 180, 138]), rank 0 
2025-03-22 16:18:07.826756: predicting BraTS2021_01102 
2025-03-22 16:18:07.843757: BraTS2021_01102, shape torch.Size([4, 137, 165, 147]), rank 0 
2025-03-22 16:18:08.954856: predicting BraTS2021_01112 
2025-03-22 16:18:08.971856: BraTS2021_01112, shape torch.Size([4, 152, 173, 133]), rank 0 
2025-03-22 16:18:10.066108: predicting BraTS2021_01114 
2025-03-22 16:18:10.086114: BraTS2021_01114, shape torch.Size([4, 140, 171, 126]), rank 0 
2025-03-22 16:18:10.832216: predicting BraTS2021_01119 
2025-03-22 16:18:10.850218: BraTS2021_01119, shape torch.Size([4, 131, 169, 134]), rank 0 
2025-03-22 16:18:11.593291: predicting BraTS2021_01125 
2025-03-22 16:18:11.607800: BraTS2021_01125, shape torch.Size([4, 140, 179, 141]), rank 0 
2025-03-22 16:18:12.350738: predicting BraTS2021_01140 
2025-03-22 16:18:12.367738: BraTS2021_01140, shape torch.Size([4, 139, 167, 134]), rank 0 
2025-03-22 16:18:13.111434: predicting BraTS2021_01144 
2025-03-22 16:18:13.126436: BraTS2021_01144, shape torch.Size([4, 135, 176, 140]), rank 0 
2025-03-22 16:18:13.895273: predicting BraTS2021_01148 
2025-03-22 16:18:13.914780: BraTS2021_01148, shape torch.Size([4, 140, 178, 130]), rank 0 
2025-03-22 16:18:14.657281: predicting BraTS2021_01155 
2025-03-22 16:18:14.674281: BraTS2021_01155, shape torch.Size([4, 138, 183, 135]), rank 0 
2025-03-22 16:18:15.419994: predicting BraTS2021_01165 
2025-03-22 16:18:15.433995: BraTS2021_01165, shape torch.Size([4, 132, 185, 140]), rank 0 
2025-03-22 16:18:16.194898: predicting BraTS2021_01166 
2025-03-22 16:18:16.213406: BraTS2021_01166, shape torch.Size([4, 132, 162, 140]), rank 0 
2025-03-22 16:18:16.959738: predicting BraTS2021_01172 
2025-03-22 16:18:16.974737: BraTS2021_01172, shape torch.Size([4, 133, 183, 131]), rank 0 
2025-03-22 16:18:17.718727: predicting BraTS2021_01184 
2025-03-22 16:18:17.737725: BraTS2021_01184, shape torch.Size([4, 126, 153, 123]), rank 0 
2025-03-22 16:18:18.475965: predicting BraTS2021_01186 
2025-03-22 16:18:18.488962: BraTS2021_01186, shape torch.Size([4, 125, 151, 118]), rank 0 
2025-03-22 16:18:19.237674: predicting BraTS2021_01188 
2025-03-22 16:18:19.250674: BraTS2021_01188, shape torch.Size([4, 127, 156, 130]), rank 0 
2025-03-22 16:18:20.004249: predicting BraTS2021_01193 
2025-03-22 16:18:20.016759: BraTS2021_01193, shape torch.Size([4, 134, 162, 134]), rank 0 
2025-03-22 16:18:20.764533: predicting BraTS2021_01194 
2025-03-22 16:18:20.778533: BraTS2021_01194, shape torch.Size([4, 137, 179, 130]), rank 0 
2025-03-22 16:18:21.528714: predicting BraTS2021_01199 
2025-03-22 16:18:21.542714: BraTS2021_01199, shape torch.Size([4, 137, 172, 132]), rank 0 
2025-03-22 16:18:22.285934: predicting BraTS2021_01200 
2025-03-22 16:18:22.302940: BraTS2021_01200, shape torch.Size([4, 130, 159, 123]), rank 0 
2025-03-22 16:18:23.046219: predicting BraTS2021_01215 
2025-03-22 16:18:23.060221: BraTS2021_01215, shape torch.Size([4, 141, 176, 144]), rank 0 
2025-03-22 16:18:23.818092: predicting BraTS2021_01219 
2025-03-22 16:18:23.834093: BraTS2021_01219, shape torch.Size([4, 143, 181, 134]), rank 0 
2025-03-22 16:18:24.600409: predicting BraTS2021_01220 
2025-03-22 16:18:24.616922: BraTS2021_01220, shape torch.Size([4, 140, 171, 129]), rank 0 
2025-03-22 16:18:25.358504: predicting BraTS2021_01224 
2025-03-22 16:18:25.373507: BraTS2021_01224, shape torch.Size([4, 147, 168, 127]), rank 0 
2025-03-22 16:18:26.463010: predicting BraTS2021_01228 
2025-03-22 16:18:26.478010: BraTS2021_01228, shape torch.Size([4, 142, 184, 141]), rank 0 
2025-03-22 16:18:27.240610: predicting BraTS2021_01229 
2025-03-22 16:18:27.254608: BraTS2021_01229, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-03-22 16:18:28.022895: predicting BraTS2021_01232 
2025-03-22 16:18:28.038896: BraTS2021_01232, shape torch.Size([4, 140, 182, 132]), rank 0 
2025-03-22 16:18:28.787149: predicting BraTS2021_01233 
2025-03-22 16:18:28.805151: BraTS2021_01233, shape torch.Size([4, 145, 177, 140]), rank 0 
2025-03-22 16:18:29.904017: predicting BraTS2021_01234 
2025-03-22 16:18:29.919529: BraTS2021_01234, shape torch.Size([4, 143, 172, 129]), rank 0 
2025-03-22 16:18:30.678246: predicting BraTS2021_01245 
2025-03-22 16:18:30.692246: BraTS2021_01245, shape torch.Size([4, 143, 174, 137]), rank 0 
2025-03-22 16:18:31.444301: predicting BraTS2021_01246 
2025-03-22 16:18:31.464303: BraTS2021_01246, shape torch.Size([4, 143, 176, 153]), rank 0 
2025-03-22 16:18:32.556523: predicting BraTS2021_01249 
2025-03-22 16:18:32.572524: BraTS2021_01249, shape torch.Size([4, 137, 176, 133]), rank 0 
2025-03-22 16:18:33.333712: predicting BraTS2021_01252 
2025-03-22 16:18:33.350713: BraTS2021_01252, shape torch.Size([4, 141, 174, 138]), rank 0 
2025-03-22 16:18:34.097934: predicting BraTS2021_01254 
2025-03-22 16:18:34.114938: BraTS2021_01254, shape torch.Size([4, 136, 161, 130]), rank 0 
2025-03-22 16:18:34.853465: predicting BraTS2021_01257 
2025-03-22 16:18:34.870466: BraTS2021_01257, shape torch.Size([4, 137, 166, 140]), rank 0 
2025-03-22 16:18:35.610992: predicting BraTS2021_01258 
2025-03-22 16:18:35.626498: BraTS2021_01258, shape torch.Size([4, 137, 174, 139]), rank 0 
2025-03-22 16:18:36.397620: predicting BraTS2021_01259 
2025-03-22 16:18:36.412625: BraTS2021_01259, shape torch.Size([4, 139, 167, 145]), rank 0 
2025-03-22 16:18:37.521097: predicting BraTS2021_01264 
2025-03-22 16:18:37.535098: BraTS2021_01264, shape torch.Size([4, 140, 169, 142]), rank 0 
2025-03-22 16:18:38.293148: predicting BraTS2021_01269 
2025-03-22 16:18:38.309150: BraTS2021_01269, shape torch.Size([4, 138, 166, 147]), rank 0 
2025-03-22 16:18:39.401452: predicting BraTS2021_01272 
2025-03-22 16:18:39.421966: BraTS2021_01272, shape torch.Size([4, 137, 169, 138]), rank 0 
2025-03-22 16:18:40.166055: predicting BraTS2021_01279 
2025-03-22 16:18:40.181055: BraTS2021_01279, shape torch.Size([4, 138, 155, 139]), rank 0 
2025-03-22 16:18:40.936287: predicting BraTS2021_01281 
2025-03-22 16:18:40.952287: BraTS2021_01281, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-03-22 16:18:41.725465: predicting BraTS2021_01287 
2025-03-22 16:18:41.741467: BraTS2021_01287, shape torch.Size([4, 138, 177, 142]), rank 0 
2025-03-22 16:18:42.504974: predicting BraTS2021_01288 
2025-03-22 16:18:42.520978: BraTS2021_01288, shape torch.Size([4, 141, 175, 139]), rank 0 
2025-03-22 16:18:43.295325: predicting BraTS2021_01295 
2025-03-22 16:18:43.311332: BraTS2021_01295, shape torch.Size([4, 131, 167, 129]), rank 0 
2025-03-22 16:18:44.048800: predicting BraTS2021_01297 
2025-03-22 16:18:44.064794: BraTS2021_01297, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-03-22 16:18:44.808561: predicting BraTS2021_01303 
2025-03-22 16:18:44.825069: BraTS2021_01303, shape torch.Size([4, 139, 153, 138]), rank 0 
2025-03-22 16:18:45.564518: predicting BraTS2021_01311 
2025-03-22 16:18:45.582518: BraTS2021_01311, shape torch.Size([4, 138, 163, 136]), rank 0 
2025-03-22 16:18:46.324645: predicting BraTS2021_01323 
2025-03-22 16:18:46.338774: BraTS2021_01323, shape torch.Size([4, 139, 145, 140]), rank 0 
2025-03-22 16:18:47.092091: predicting BraTS2021_01327 
2025-03-22 16:18:47.105089: BraTS2021_01327, shape torch.Size([4, 143, 170, 143]), rank 0 
2025-03-22 16:18:47.872679: predicting BraTS2021_01337 
2025-03-22 16:18:47.893679: BraTS2021_01337, shape torch.Size([4, 137, 166, 147]), rank 0 
2025-03-22 16:18:48.983369: predicting BraTS2021_01338 
2025-03-22 16:18:48.998371: BraTS2021_01338, shape torch.Size([4, 144, 169, 134]), rank 0 
2025-03-22 16:18:49.755474: predicting BraTS2021_01341 
2025-03-22 16:18:49.770476: BraTS2021_01341, shape torch.Size([4, 141, 178, 137]), rank 0 
2025-03-22 16:18:50.522464: predicting BraTS2021_01343 
2025-03-22 16:18:50.537973: BraTS2021_01343, shape torch.Size([4, 139, 162, 129]), rank 0 
2025-03-22 16:18:51.282147: predicting BraTS2021_01344 
2025-03-22 16:18:51.297145: BraTS2021_01344, shape torch.Size([4, 143, 151, 131]), rank 0 
2025-03-22 16:18:52.040127: predicting BraTS2021_01346 
2025-03-22 16:18:52.056128: BraTS2021_01346, shape torch.Size([4, 141, 186, 143]), rank 0 
2025-03-22 16:18:52.802339: predicting BraTS2021_01352 
2025-03-22 16:18:52.817341: BraTS2021_01352, shape torch.Size([4, 140, 171, 136]), rank 0 
2025-03-22 16:18:53.556269: predicting BraTS2021_01355 
2025-03-22 16:18:53.573270: BraTS2021_01355, shape torch.Size([4, 138, 166, 136]), rank 0 
2025-03-22 16:18:54.314356: predicting BraTS2021_01362 
2025-03-22 16:18:54.327356: BraTS2021_01362, shape torch.Size([4, 142, 149, 138]), rank 0 
2025-03-22 16:18:55.096026: predicting BraTS2021_01364 
2025-03-22 16:18:55.110025: BraTS2021_01364, shape torch.Size([4, 139, 170, 127]), rank 0 
2025-03-22 16:18:55.859530: predicting BraTS2021_01377 
2025-03-22 16:18:55.875530: BraTS2021_01377, shape torch.Size([4, 142, 166, 134]), rank 0 
2025-03-22 16:18:56.619137: predicting BraTS2021_01381 
2025-03-22 16:18:56.636649: BraTS2021_01381, shape torch.Size([4, 139, 176, 167]), rank 0 
2025-03-22 16:18:57.739884: predicting BraTS2021_01382 
2025-03-22 16:18:57.755884: BraTS2021_01382, shape torch.Size([4, 141, 172, 134]), rank 0 
2025-03-22 16:18:58.512080: predicting BraTS2021_01386 
2025-03-22 16:18:58.530083: BraTS2021_01386, shape torch.Size([4, 145, 181, 140]), rank 0 
2025-03-22 16:18:59.628056: predicting BraTS2021_01400 
2025-03-22 16:18:59.643564: BraTS2021_01400, shape torch.Size([4, 142, 171, 126]), rank 0 
2025-03-22 16:19:00.396391: predicting BraTS2021_01408 
2025-03-22 16:19:00.414392: BraTS2021_01408, shape torch.Size([4, 141, 163, 142]), rank 0 
2025-03-22 16:19:01.158357: predicting BraTS2021_01411 
2025-03-22 16:19:01.175357: BraTS2021_01411, shape torch.Size([4, 132, 176, 136]), rank 0 
2025-03-22 16:19:01.920106: predicting BraTS2021_01422 
2025-03-22 16:19:01.934130: BraTS2021_01422, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-22 16:19:02.704350: predicting BraTS2021_01427 
2025-03-22 16:19:02.721355: BraTS2021_01427, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-03-22 16:19:03.493915: predicting BraTS2021_01432 
2025-03-22 16:19:03.508915: BraTS2021_01432, shape torch.Size([4, 133, 167, 144]), rank 0 
2025-03-22 16:19:04.249141: predicting BraTS2021_01433 
2025-03-22 16:19:04.266141: BraTS2021_01433, shape torch.Size([4, 135, 176, 145]), rank 0 
2025-03-22 16:19:05.359472: predicting BraTS2021_01434 
2025-03-22 16:19:05.375473: BraTS2021_01434, shape torch.Size([4, 131, 167, 131]), rank 0 
2025-03-22 16:19:06.138290: predicting BraTS2021_01438 
2025-03-22 16:19:06.153291: BraTS2021_01438, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-03-22 16:19:07.261309: predicting BraTS2021_01439 
2025-03-22 16:19:07.275309: BraTS2021_01439, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-03-22 16:19:08.386141: predicting BraTS2021_01446 
2025-03-22 16:19:08.401139: BraTS2021_01446, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-03-22 16:19:09.142365: predicting BraTS2021_01451 
2025-03-22 16:19:09.158363: BraTS2021_01451, shape torch.Size([4, 137, 180, 141]), rank 0 
2025-03-22 16:19:09.902630: predicting BraTS2021_01460 
2025-03-22 16:19:09.918631: BraTS2021_01460, shape torch.Size([4, 138, 171, 139]), rank 0 
2025-03-22 16:19:10.681477: predicting BraTS2021_01462 
2025-03-22 16:19:10.696477: BraTS2021_01462, shape torch.Size([4, 138, 175, 145]), rank 0 
2025-03-22 16:19:11.792137: predicting BraTS2021_01471 
2025-03-22 16:19:11.808136: BraTS2021_01471, shape torch.Size([4, 130, 169, 152]), rank 0 
2025-03-22 16:19:12.911513: predicting BraTS2021_01474 
2025-03-22 16:19:12.927513: BraTS2021_01474, shape torch.Size([4, 137, 156, 132]), rank 0 
2025-03-22 16:19:13.666655: predicting BraTS2021_01485 
2025-03-22 16:19:13.680655: BraTS2021_01485, shape torch.Size([4, 135, 176, 134]), rank 0 
2025-03-22 16:19:14.431158: predicting BraTS2021_01486 
2025-03-22 16:19:14.448669: BraTS2021_01486, shape torch.Size([4, 140, 166, 134]), rank 0 
2025-03-22 16:19:15.191370: predicting BraTS2021_01487 
2025-03-22 16:19:15.206373: BraTS2021_01487, shape torch.Size([4, 138, 160, 133]), rank 0 
2025-03-22 16:19:15.974912: predicting BraTS2021_01497 
2025-03-22 16:19:15.987913: BraTS2021_01497, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-03-22 16:19:16.738521: predicting BraTS2021_01505 
2025-03-22 16:19:16.754030: BraTS2021_01505, shape torch.Size([4, 131, 164, 139]), rank 0 
2025-03-22 16:19:17.517150: predicting BraTS2021_01506 
2025-03-22 16:19:17.534157: BraTS2021_01506, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-03-22 16:19:18.275760: predicting BraTS2021_01510 
2025-03-22 16:19:18.291762: BraTS2021_01510, shape torch.Size([4, 138, 174, 136]), rank 0 
2025-03-22 16:19:19.038269: predicting BraTS2021_01520 
2025-03-22 16:19:19.054781: BraTS2021_01520, shape torch.Size([4, 143, 173, 131]), rank 0 
2025-03-22 16:19:19.812229: predicting BraTS2021_01525 
2025-03-22 16:19:19.829229: BraTS2021_01525, shape torch.Size([4, 141, 171, 144]), rank 0 
2025-03-22 16:19:20.572330: predicting BraTS2021_01528 
2025-03-22 16:19:20.588331: BraTS2021_01528, shape torch.Size([4, 140, 163, 139]), rank 0 
2025-03-22 16:19:21.343359: predicting BraTS2021_01539 
2025-03-22 16:19:21.360869: BraTS2021_01539, shape torch.Size([4, 136, 165, 131]), rank 0 
2025-03-22 16:19:22.113342: predicting BraTS2021_01550 
2025-03-22 16:19:22.126343: BraTS2021_01550, shape torch.Size([4, 137, 158, 136]), rank 0 
2025-03-22 16:19:22.880409: predicting BraTS2021_01551 
2025-03-22 16:19:22.894408: BraTS2021_01551, shape torch.Size([4, 141, 182, 138]), rank 0 
2025-03-22 16:19:23.661061: predicting BraTS2021_01555 
2025-03-22 16:19:23.675059: BraTS2021_01555, shape torch.Size([4, 140, 166, 122]), rank 0 
2025-03-22 16:19:24.428925: predicting BraTS2021_01557 
2025-03-22 16:19:24.443931: BraTS2021_01557, shape torch.Size([4, 149, 179, 143]), rank 0 
2025-03-22 16:19:25.541561: predicting BraTS2021_01563 
2025-03-22 16:19:25.559075: BraTS2021_01563, shape torch.Size([4, 139, 174, 135]), rank 0 
2025-03-22 16:19:26.314193: predicting BraTS2021_01569 
2025-03-22 16:19:26.328195: BraTS2021_01569, shape torch.Size([4, 152, 175, 129]), rank 0 
2025-03-22 16:19:27.444848: predicting BraTS2021_01572 
2025-03-22 16:19:27.459353: BraTS2021_01572, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-03-22 16:19:28.225211: predicting BraTS2021_01576 
2025-03-22 16:19:28.243214: BraTS2021_01576, shape torch.Size([4, 143, 175, 131]), rank 0 
2025-03-22 16:19:28.988091: predicting BraTS2021_01579 
2025-03-22 16:19:29.003091: BraTS2021_01579, shape torch.Size([4, 148, 160, 140]), rank 0 
2025-03-22 16:19:30.108199: predicting BraTS2021_01581 
2025-03-22 16:19:30.123199: BraTS2021_01581, shape torch.Size([4, 138, 184, 141]), rank 0 
2025-03-22 16:19:30.887137: predicting BraTS2021_01595 
2025-03-22 16:19:30.904138: BraTS2021_01595, shape torch.Size([4, 137, 168, 131]), rank 0 
2025-03-22 16:19:31.661633: predicting BraTS2021_01604 
2025-03-22 16:19:31.676630: BraTS2021_01604, shape torch.Size([4, 138, 178, 128]), rank 0 
2025-03-22 16:19:32.416504: predicting BraTS2021_01605 
2025-03-22 16:19:32.434504: BraTS2021_01605, shape torch.Size([4, 136, 180, 131]), rank 0 
2025-03-22 16:19:33.184611: predicting BraTS2021_01610 
2025-03-22 16:19:33.198610: BraTS2021_01610, shape torch.Size([4, 137, 159, 125]), rank 0 
2025-03-22 16:19:33.956923: predicting BraTS2021_01624 
2025-03-22 16:19:33.972432: BraTS2021_01624, shape torch.Size([4, 132, 179, 132]), rank 0 
2025-03-22 16:19:34.712603: predicting BraTS2021_01627 
2025-03-22 16:19:34.726603: BraTS2021_01627, shape torch.Size([4, 149, 166, 128]), rank 0 
2025-03-22 16:19:35.835575: predicting BraTS2021_01632 
2025-03-22 16:19:35.851576: BraTS2021_01632, shape torch.Size([4, 147, 161, 135]), rank 0 
2025-03-22 16:19:36.958480: predicting BraTS2021_01633 
2025-03-22 16:19:36.972988: BraTS2021_01633, shape torch.Size([4, 132, 176, 137]), rank 0 
2025-03-22 16:19:37.736192: predicting BraTS2021_01637 
2025-03-22 16:19:37.754196: BraTS2021_01637, shape torch.Size([4, 122, 179, 138]), rank 0 
2025-03-22 16:19:38.498170: predicting BraTS2021_01642 
2025-03-22 16:19:38.515171: BraTS2021_01642, shape torch.Size([4, 146, 181, 136]), rank 0 
2025-03-22 16:19:39.611317: predicting BraTS2021_01647 
2025-03-22 16:19:39.627317: BraTS2021_01647, shape torch.Size([4, 143, 169, 133]), rank 0 
2025-03-22 16:19:40.394876: predicting BraTS2021_01658 
2025-03-22 16:19:40.410878: BraTS2021_01658, shape torch.Size([4, 131, 173, 128]), rank 0 
2025-03-22 16:19:56.379129: Validation complete 
2025-03-22 16:19:56.387129: Mean Validation Dice:  0.9107202286892773 
