
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-27 14:28:53.947457: do_dummy_2d_data_aug: True 
2025-02-27 14:28:53.954457: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-02-27 14:28:53.962752: The split file contains 5 splits. 
2025-02-27 14:28:53.964929: Desired fold for training: 0 
2025-02-27 14:28:53.967932: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-02-27 14:29:04.767189: unpacking dataset... 
2025-02-27 14:29:16.918948: unpacking done... 
2025-02-27 14:29:21.326572:  
2025-02-27 14:29:21.332193: Epoch 0 
2025-02-27 14:29:21.335243: Current learning rate: 0.01 
2025-02-27 14:30:55.318685: train_loss 0.0512 
2025-02-27 14:30:55.325523: val_loss 0.0067 
2025-02-27 14:30:55.328552: Pseudo dice [np.float32(0.0)] 
2025-02-27 14:30:55.331059: Epoch time: 93.99 s 
2025-02-27 14:30:55.334569: Yayy! New best EMA pseudo Dice: 0.0 
2025-02-27 14:30:56.006778:  
2025-02-27 14:30:56.012936: Epoch 1 
2025-02-27 14:30:56.016487: Current learning rate: 0.00991 
2025-02-27 14:32:20.648459: train_loss -0.0176 
2025-02-27 14:32:20.655978: val_loss -0.0637 
2025-02-27 14:32:20.659990: Pseudo dice [np.float32(0.0)] 
2025-02-27 14:32:20.662534: Epoch time: 84.64 s 
2025-02-27 14:32:21.225902:  
2025-02-27 14:32:21.231417: Epoch 2 
2025-02-27 14:32:21.234930: Current learning rate: 0.00982 
2025-02-27 14:33:45.872684: train_loss -0.1312 
2025-02-27 14:33:45.879260: val_loss -0.2665 
2025-02-27 14:33:45.882819: Pseudo dice [np.float32(0.3513)] 
2025-02-27 14:33:45.885058: Epoch time: 84.65 s 
2025-02-27 14:33:45.889608: Yayy! New best EMA pseudo Dice: 0.035100001841783524 
2025-02-27 14:33:46.662394:  
2025-02-27 14:33:46.668951: Epoch 3 
2025-02-27 14:33:46.671991: Current learning rate: 0.00973 
2025-02-27 14:35:11.308405: train_loss -0.243 
2025-02-27 14:35:11.318431: val_loss -0.2407 
2025-02-27 14:35:11.321940: Pseudo dice [np.float32(0.2994)] 
2025-02-27 14:35:11.325447: Epoch time: 84.65 s 
2025-02-27 14:35:11.329463: Yayy! New best EMA pseudo Dice: 0.06159999966621399 
2025-02-27 14:35:12.071479:  
2025-02-27 14:35:12.076993: Epoch 4 
2025-02-27 14:35:12.080502: Current learning rate: 0.00964 
2025-02-27 14:36:36.690416: train_loss -0.3194 
2025-02-27 14:36:36.697433: val_loss -0.2955 
2025-02-27 14:36:36.700443: Pseudo dice [np.float32(0.3373)] 
2025-02-27 14:36:36.703954: Epoch time: 84.62 s 
2025-02-27 14:36:36.706461: Yayy! New best EMA pseudo Dice: 0.08910000324249268 
2025-02-27 14:36:37.648445:  
2025-02-27 14:36:37.654458: Epoch 5 
2025-02-27 14:36:37.657465: Current learning rate: 0.00955 
2025-02-27 14:38:02.294696: train_loss -0.343 
2025-02-27 14:38:02.300269: val_loss -0.3425 
2025-02-27 14:38:02.304304: Pseudo dice [np.float32(0.4201)] 
2025-02-27 14:38:02.307346: Epoch time: 84.65 s 
2025-02-27 14:38:02.310375: Yayy! New best EMA pseudo Dice: 0.12219999730587006 
2025-02-27 14:38:03.034870:  
2025-02-27 14:38:03.040445: Epoch 6 
2025-02-27 14:38:03.042985: Current learning rate: 0.00946 
2025-02-27 14:39:27.669327: train_loss -0.3573 
2025-02-27 14:39:27.675839: val_loss -0.2986 
2025-02-27 14:39:27.679348: Pseudo dice [np.float32(0.386)] 
2025-02-27 14:39:27.683377: Epoch time: 84.63 s 
2025-02-27 14:39:27.686416: Yayy! New best EMA pseudo Dice: 0.1485999971628189 
2025-02-27 14:39:28.447021:  
2025-02-27 14:39:28.452592: Epoch 7 
2025-02-27 14:39:28.456201: Current learning rate: 0.00937 
2025-02-27 14:40:53.024149: train_loss -0.395 
2025-02-27 14:40:53.031168: val_loss -0.3109 
2025-02-27 14:40:53.035182: Pseudo dice [np.float32(0.3804)] 
2025-02-27 14:40:53.037686: Epoch time: 84.58 s 
2025-02-27 14:40:53.041694: Yayy! New best EMA pseudo Dice: 0.17180000245571136 
2025-02-27 14:40:53.781188:  
2025-02-27 14:40:53.788720: Epoch 8 
2025-02-27 14:40:53.792233: Current learning rate: 0.00928 
2025-02-27 14:42:18.437415: train_loss -0.407 
2025-02-27 14:42:18.443432: val_loss -0.3849 
2025-02-27 14:42:18.447438: Pseudo dice [np.float32(0.4798)] 
2025-02-27 14:42:18.449944: Epoch time: 84.66 s 
2025-02-27 14:42:18.453458: Yayy! New best EMA pseudo Dice: 0.20260000228881836 
2025-02-27 14:42:19.220003:  
2025-02-27 14:42:19.225014: Epoch 9 
2025-02-27 14:42:19.228524: Current learning rate: 0.00919 
2025-02-27 14:43:43.869880: train_loss -0.3826 
2025-02-27 14:43:43.875711: val_loss -0.3861 
2025-02-27 14:43:43.879721: Pseudo dice [np.float32(0.4337)] 
2025-02-27 14:43:43.883231: Epoch time: 84.65 s 
2025-02-27 14:43:43.886739: Yayy! New best EMA pseudo Dice: 0.2257000058889389 
2025-02-27 14:43:44.649724:  
2025-02-27 14:43:44.655278: Epoch 10 
2025-02-27 14:43:44.659333: Current learning rate: 0.0091 
2025-02-27 14:45:09.246380: train_loss -0.4191 
2025-02-27 14:45:09.251394: val_loss -0.3953 
2025-02-27 14:45:09.255405: Pseudo dice [np.float32(0.5111)] 
2025-02-27 14:45:09.257911: Epoch time: 84.6 s 
2025-02-27 14:45:09.261424: Yayy! New best EMA pseudo Dice: 0.2542000114917755 
2025-02-27 14:45:10.010049:  
2025-02-27 14:45:10.016162: Epoch 11 
2025-02-27 14:45:10.019243: Current learning rate: 0.009 
2025-02-27 14:46:34.591848: train_loss -0.4188 
2025-02-27 14:46:34.598367: val_loss -0.3824 
2025-02-27 14:46:34.602376: Pseudo dice [np.float32(0.462)] 
2025-02-27 14:46:34.605887: Epoch time: 84.58 s 
2025-02-27 14:46:34.609393: Yayy! New best EMA pseudo Dice: 0.2750000059604645 
2025-02-27 14:46:35.344768:  
2025-02-27 14:46:35.350333: Epoch 12 
2025-02-27 14:46:35.353916: Current learning rate: 0.00891 
2025-02-27 14:47:59.979005: train_loss -0.4733 
2025-02-27 14:47:59.985529: val_loss -0.3604 
2025-02-27 14:47:59.988037: Pseudo dice [np.float32(0.4474)] 
2025-02-27 14:47:59.992055: Epoch time: 84.64 s 
2025-02-27 14:47:59.995566: Yayy! New best EMA pseudo Dice: 0.2922999858856201 
2025-02-27 14:48:00.916448:  
2025-02-27 14:48:00.921962: Epoch 13 
2025-02-27 14:48:00.925476: Current learning rate: 0.00882 
2025-02-27 14:49:25.521386: train_loss -0.4376 
2025-02-27 14:49:25.528483: val_loss -0.3381 
2025-02-27 14:49:25.532058: Pseudo dice [np.float32(0.4074)] 
2025-02-27 14:49:25.535094: Epoch time: 84.61 s 
2025-02-27 14:49:25.538603: Yayy! New best EMA pseudo Dice: 0.30379998683929443 
2025-02-27 14:49:26.266289:  
2025-02-27 14:49:26.272837: Epoch 14 
2025-02-27 14:49:26.276850: Current learning rate: 0.00873 
2025-02-27 14:50:50.904205: train_loss -0.4484 
2025-02-27 14:50:50.910722: val_loss -0.3962 
2025-02-27 14:50:50.914733: Pseudo dice [np.float32(0.4614)] 
2025-02-27 14:50:50.917238: Epoch time: 84.64 s 
2025-02-27 14:50:50.920750: Yayy! New best EMA pseudo Dice: 0.31949999928474426 
2025-02-27 14:50:51.678743:  
2025-02-27 14:50:51.684297: Epoch 15 
2025-02-27 14:50:51.687333: Current learning rate: 0.00864 
2025-02-27 14:52:16.279215: train_loss -0.5167 
2025-02-27 14:52:16.285774: val_loss -0.3415 
2025-02-27 14:52:16.289345: Pseudo dice [np.float32(0.4815)] 
2025-02-27 14:52:16.291464: Epoch time: 84.6 s 
2025-02-27 14:52:16.296055: Yayy! New best EMA pseudo Dice: 0.33570000529289246 
2025-02-27 14:52:17.055060:  
2025-02-27 14:52:17.061636: Epoch 16 
2025-02-27 14:52:17.065750: Current learning rate: 0.00855 
2025-02-27 14:53:41.683849: train_loss -0.4869 
2025-02-27 14:53:41.689864: val_loss -0.4657 
2025-02-27 14:53:41.693873: Pseudo dice [np.float32(0.5571)] 
2025-02-27 14:53:41.697384: Epoch time: 84.63 s 
2025-02-27 14:53:41.699891: Yayy! New best EMA pseudo Dice: 0.3578999936580658 
2025-02-27 14:53:42.478377:  
2025-02-27 14:53:42.483371: Epoch 17 
2025-02-27 14:53:42.486882: Current learning rate: 0.00846 
2025-02-27 14:55:07.121217: train_loss -0.4792 
2025-02-27 14:55:07.128234: val_loss -0.4063 
2025-02-27 14:55:07.131757: Pseudo dice [np.float32(0.5198)] 
2025-02-27 14:55:07.134801: Epoch time: 84.64 s 
2025-02-27 14:55:07.138812: Yayy! New best EMA pseudo Dice: 0.374099999666214 
2025-02-27 14:55:07.877012:  
2025-02-27 14:55:07.883075: Epoch 18 
2025-02-27 14:55:07.886590: Current learning rate: 0.00836 
2025-02-27 14:56:32.512389: train_loss -0.4549 
2025-02-27 14:56:32.518912: val_loss -0.4058 
2025-02-27 14:56:32.522429: Pseudo dice [np.float32(0.5204)] 
2025-02-27 14:56:32.525939: Epoch time: 84.64 s 
2025-02-27 14:56:32.529962: Yayy! New best EMA pseudo Dice: 0.388700008392334 
2025-02-27 14:56:33.331591:  
2025-02-27 14:56:33.338181: Epoch 19 
2025-02-27 14:56:33.341781: Current learning rate: 0.00827 
2025-02-27 14:57:57.973381: train_loss -0.5141 
2025-02-27 14:57:57.979401: val_loss -0.4058 
2025-02-27 14:57:57.983409: Pseudo dice [np.float32(0.5457)] 
2025-02-27 14:57:57.986918: Epoch time: 84.64 s 
2025-02-27 14:57:57.989424: Yayy! New best EMA pseudo Dice: 0.4043999910354614 
2025-02-27 14:57:58.721979:  
2025-02-27 14:57:58.727525: Epoch 20 
2025-02-27 14:57:58.731080: Current learning rate: 0.00818 
2025-02-27 14:59:23.321079: train_loss -0.513 
2025-02-27 14:59:23.327098: val_loss -0.2717 
2025-02-27 14:59:23.331113: Pseudo dice [np.float32(0.4144)] 
2025-02-27 14:59:23.333619: Epoch time: 84.6 s 
2025-02-27 14:59:23.337129: Yayy! New best EMA pseudo Dice: 0.40540000796318054 
2025-02-27 14:59:24.287966:  
2025-02-27 14:59:24.293527: Epoch 21 
2025-02-27 14:59:24.297153: Current learning rate: 0.00809 
2025-02-27 15:00:48.887569: train_loss -0.4538 
2025-02-27 15:00:48.894098: val_loss -0.3609 
2025-02-27 15:00:48.897612: Pseudo dice [np.float32(0.5089)] 
2025-02-27 15:00:48.901172: Epoch time: 84.6 s 
2025-02-27 15:00:48.904191: Yayy! New best EMA pseudo Dice: 0.4156999886035919 
2025-02-27 15:00:49.637268:  
2025-02-27 15:00:49.643353: Epoch 22 
2025-02-27 15:00:49.646538: Current learning rate: 0.008 
2025-02-27 15:02:14.262698: train_loss -0.518 
2025-02-27 15:02:14.269217: val_loss -0.4282 
2025-02-27 15:02:14.272730: Pseudo dice [np.float32(0.5981)] 
2025-02-27 15:02:14.275237: Epoch time: 84.63 s 
2025-02-27 15:02:14.281767: Yayy! New best EMA pseudo Dice: 0.4339999854564667 
2025-02-27 15:02:15.008735:  
2025-02-27 15:02:15.014257: Epoch 23 
2025-02-27 15:02:15.017767: Current learning rate: 0.0079 
2025-02-27 15:03:39.605809: train_loss -0.5106 
2025-02-27 15:03:39.611830: val_loss -0.3939 
2025-02-27 15:03:39.615843: Pseudo dice [np.float32(0.487)] 
2025-02-27 15:03:39.619358: Epoch time: 84.6 s 
2025-02-27 15:03:39.622869: Yayy! New best EMA pseudo Dice: 0.439300000667572 
2025-02-27 15:03:40.354895:  
2025-02-27 15:03:40.360451: Epoch 24 
2025-02-27 15:03:40.362987: Current learning rate: 0.00781 
2025-02-27 15:05:04.986392: train_loss -0.5739 
2025-02-27 15:05:04.992413: val_loss -0.2536 
2025-02-27 15:05:04.996423: Pseudo dice [np.float32(0.3642)] 
2025-02-27 15:05:04.998933: Epoch time: 84.63 s 
2025-02-27 15:05:05.575346:  
2025-02-27 15:05:05.580431: Epoch 25 
2025-02-27 15:05:05.583992: Current learning rate: 0.00772 
2025-02-27 15:06:30.193184: train_loss -0.5129 
2025-02-27 15:06:30.199702: val_loss -0.38 
2025-02-27 15:06:30.204716: Pseudo dice [np.float32(0.4989)] 
2025-02-27 15:06:30.207222: Epoch time: 84.62 s 
2025-02-27 15:06:30.778445:  
2025-02-27 15:06:30.784029: Epoch 26 
2025-02-27 15:06:30.786568: Current learning rate: 0.00763 
2025-02-27 15:07:55.428200: train_loss -0.5279 
2025-02-27 15:07:55.434719: val_loss -0.4037 
2025-02-27 15:07:55.438236: Pseudo dice [np.float32(0.5039)] 
2025-02-27 15:07:55.442166: Epoch time: 84.65 s 
2025-02-27 15:07:55.445679: Yayy! New best EMA pseudo Dice: 0.4449999928474426 
2025-02-27 15:07:56.171138:  
2025-02-27 15:07:56.176699: Epoch 27 
2025-02-27 15:07:56.180253: Current learning rate: 0.00753 
2025-02-27 15:09:20.787879: train_loss -0.5401 
2025-02-27 15:09:20.794463: val_loss -0.2891 
2025-02-27 15:09:20.797995: Pseudo dice [np.float32(0.4795)] 
2025-02-27 15:09:20.800057: Epoch time: 84.62 s 
2025-02-27 15:09:20.804152: Yayy! New best EMA pseudo Dice: 0.44850000739097595 
2025-02-27 15:09:21.552860:  
2025-02-27 15:09:21.558414: Epoch 28 
2025-02-27 15:09:21.560957: Current learning rate: 0.00744 
2025-02-27 15:10:46.180817: train_loss -0.5691 
2025-02-27 15:10:46.187840: val_loss -0.4044 
2025-02-27 15:10:46.190849: Pseudo dice [np.float32(0.5346)] 
2025-02-27 15:10:46.194359: Epoch time: 84.63 s 
2025-02-27 15:10:46.197869: Yayy! New best EMA pseudo Dice: 0.4571000039577484 
2025-02-27 15:10:47.104895:  
2025-02-27 15:10:47.111047: Epoch 29 
2025-02-27 15:10:47.114118: Current learning rate: 0.00735 
2025-02-27 15:12:11.704219: train_loss -0.5479 
2025-02-27 15:12:11.710738: val_loss -0.3958 
2025-02-27 15:12:11.714248: Pseudo dice [np.float32(0.5521)] 
2025-02-27 15:12:11.718258: Epoch time: 84.6 s 
2025-02-27 15:12:11.720763: Yayy! New best EMA pseudo Dice: 0.4666000008583069 
2025-02-27 15:12:12.478161:  
2025-02-27 15:12:12.483687: Epoch 30 
2025-02-27 15:12:12.486709: Current learning rate: 0.00725 
2025-02-27 15:13:37.106933: train_loss -0.5613 
2025-02-27 15:13:37.114453: val_loss -0.4285 
2025-02-27 15:13:37.117964: Pseudo dice [np.float32(0.5597)] 
2025-02-27 15:13:37.120470: Epoch time: 84.63 s 
2025-02-27 15:13:37.124477: Yayy! New best EMA pseudo Dice: 0.47589999437332153 
2025-02-27 15:13:37.857783:  
2025-02-27 15:13:37.862683: Epoch 31 
2025-02-27 15:13:37.866195: Current learning rate: 0.00716 
2025-02-27 15:15:02.469677: train_loss -0.5508 
2025-02-27 15:15:02.476189: val_loss -0.3485 
2025-02-27 15:15:02.478696: Pseudo dice [np.float32(0.4915)] 
2025-02-27 15:15:02.482205: Epoch time: 84.61 s 
2025-02-27 15:15:02.485713: Yayy! New best EMA pseudo Dice: 0.47749999165534973 
2025-02-27 15:15:03.224628:  
2025-02-27 15:15:03.230789: Epoch 32 
2025-02-27 15:15:03.234359: Current learning rate: 0.00707 
2025-02-27 15:16:27.814830: train_loss -0.5714 
2025-02-27 15:16:27.821903: val_loss -0.4921 
2025-02-27 15:16:27.825413: Pseudo dice [np.float32(0.6254)] 
2025-02-27 15:16:27.828921: Epoch time: 84.59 s 
2025-02-27 15:16:27.831931: Yayy! New best EMA pseudo Dice: 0.49230000376701355 
2025-02-27 15:16:28.568343:  
2025-02-27 15:16:28.574370: Epoch 33 
2025-02-27 15:16:28.577415: Current learning rate: 0.00697 
2025-02-27 15:17:53.184171: train_loss -0.5694 
2025-02-27 15:17:53.190746: val_loss -0.3744 
2025-02-27 15:17:53.194768: Pseudo dice [np.float32(0.4474)] 
2025-02-27 15:17:53.198282: Epoch time: 84.62 s 
2025-02-27 15:17:53.783297:  
2025-02-27 15:17:53.789962: Epoch 34 
2025-02-27 15:17:53.793023: Current learning rate: 0.00688 
2025-02-27 15:19:18.451811: train_loss -0.564 
2025-02-27 15:19:18.457830: val_loss -0.36 
2025-02-27 15:19:18.461337: Pseudo dice [np.float32(0.5287)] 
2025-02-27 15:19:18.464344: Epoch time: 84.67 s 
2025-02-27 15:19:19.060704:  
2025-02-27 15:19:19.066279: Epoch 35 
2025-02-27 15:19:19.068826: Current learning rate: 0.00679 
2025-02-27 15:20:43.679446: train_loss -0.5861 
2025-02-27 15:20:43.685962: val_loss -0.4248 
2025-02-27 15:20:43.689475: Pseudo dice [np.float32(0.5463)] 
2025-02-27 15:20:43.692981: Epoch time: 84.62 s 
2025-02-27 15:20:43.695997: Yayy! New best EMA pseudo Dice: 0.49729999899864197 
2025-02-27 15:20:44.443589:  
2025-02-27 15:20:44.450169: Epoch 36 
2025-02-27 15:20:44.453706: Current learning rate: 0.00669 
2025-02-27 15:22:09.068243: train_loss -0.5606 
2025-02-27 15:22:09.074261: val_loss -0.5183 
2025-02-27 15:22:09.077276: Pseudo dice [np.float32(0.6418)] 
2025-02-27 15:22:09.081795: Epoch time: 84.62 s 
2025-02-27 15:22:09.085815: Yayy! New best EMA pseudo Dice: 0.5117999911308289 
2025-02-27 15:22:10.079276:  
2025-02-27 15:22:10.084838: Epoch 37 
2025-02-27 15:22:10.087866: Current learning rate: 0.0066 
2025-02-27 15:23:34.668437: train_loss -0.6027 
2025-02-27 15:23:34.675030: val_loss -0.3458 
2025-02-27 15:23:34.678580: Pseudo dice [np.float32(0.4199)] 
2025-02-27 15:23:34.681616: Epoch time: 84.59 s 
2025-02-27 15:23:35.275630:  
2025-02-27 15:23:35.281238: Epoch 38 
2025-02-27 15:23:35.285298: Current learning rate: 0.0065 
2025-02-27 15:24:59.928895: train_loss -0.5929 
2025-02-27 15:24:59.936411: val_loss -0.4696 
2025-02-27 15:24:59.938918: Pseudo dice [np.float32(0.604)] 
2025-02-27 15:24:59.942432: Epoch time: 84.65 s 
2025-02-27 15:24:59.945938: Yayy! New best EMA pseudo Dice: 0.5127000212669373 
2025-02-27 15:25:00.701048:  
2025-02-27 15:25:00.707128: Epoch 39 
2025-02-27 15:25:00.710180: Current learning rate: 0.00641 
2025-02-27 15:26:25.324924: train_loss -0.563 
2025-02-27 15:26:25.331445: val_loss -0.4042 
2025-02-27 15:26:25.334960: Pseudo dice [np.float32(0.5436)] 
2025-02-27 15:26:25.338491: Epoch time: 84.62 s 
2025-02-27 15:26:25.341544: Yayy! New best EMA pseudo Dice: 0.5157999992370605 
2025-02-27 15:26:26.112398:  
2025-02-27 15:26:26.118554: Epoch 40 
2025-02-27 15:26:26.121620: Current learning rate: 0.00631 
2025-02-27 15:27:50.706938: train_loss -0.5916 
2025-02-27 15:27:50.713961: val_loss -0.4902 
2025-02-27 15:27:50.716974: Pseudo dice [np.float32(0.6144)] 
2025-02-27 15:27:50.720487: Epoch time: 84.59 s 
2025-02-27 15:27:50.722998: Yayy! New best EMA pseudo Dice: 0.5256999731063843 
2025-02-27 15:27:51.495371:  
2025-02-27 15:27:51.500886: Epoch 41 
2025-02-27 15:27:51.504396: Current learning rate: 0.00622 
2025-02-27 15:29:16.123940: train_loss -0.6472 
2025-02-27 15:29:16.130546: val_loss -0.3772 
2025-02-27 15:29:16.133051: Pseudo dice [np.float32(0.5143)] 
2025-02-27 15:29:16.136561: Epoch time: 84.63 s 
2025-02-27 15:29:16.707042:  
2025-02-27 15:29:16.713156: Epoch 42 
2025-02-27 15:29:16.715662: Current learning rate: 0.00612 
2025-02-27 15:30:41.951711: train_loss -0.5976 
2025-02-27 15:30:41.958313: val_loss -0.3926 
2025-02-27 15:30:41.961964: Pseudo dice [np.float32(0.4894)] 
2025-02-27 15:30:41.965513: Epoch time: 85.25 s 
2025-02-27 15:30:42.541822:  
2025-02-27 15:30:42.548394: Epoch 43 
2025-02-27 15:30:42.551026: Current learning rate: 0.00603 
2025-02-27 15:32:07.195456: train_loss -0.5799 
2025-02-27 15:32:07.201977: val_loss -0.3843 
2025-02-27 15:32:07.204484: Pseudo dice [np.float32(0.5458)] 
2025-02-27 15:32:07.210999: Epoch time: 84.65 s 
2025-02-27 15:32:07.775743:  
2025-02-27 15:32:07.781258: Epoch 44 
2025-02-27 15:32:07.783763: Current learning rate: 0.00593 
2025-02-27 15:33:32.409646: train_loss -0.5819 
2025-02-27 15:33:32.416162: val_loss -0.4638 
2025-02-27 15:33:32.419672: Pseudo dice [np.float32(0.5866)] 
2025-02-27 15:33:32.422180: Epoch time: 84.63 s 
2025-02-27 15:33:32.425687: Yayy! New best EMA pseudo Dice: 0.5297999978065491 
2025-02-27 15:33:33.308670:  
2025-02-27 15:33:33.314210: Epoch 45 
2025-02-27 15:33:33.317766: Current learning rate: 0.00584 
2025-02-27 15:34:57.897630: train_loss -0.6078 
2025-02-27 15:34:57.905154: val_loss -0.521 
2025-02-27 15:34:57.907660: Pseudo dice [np.float32(0.6751)] 
2025-02-27 15:34:57.911670: Epoch time: 84.59 s 
2025-02-27 15:34:57.914175: Yayy! New best EMA pseudo Dice: 0.5443000197410583 
2025-02-27 15:34:58.647878:  
2025-02-27 15:34:58.654534: Epoch 46 
2025-02-27 15:34:58.657604: Current learning rate: 0.00574 
2025-02-27 15:36:23.242585: train_loss -0.59 
2025-02-27 15:36:23.249102: val_loss -0.3817 
2025-02-27 15:36:23.252616: Pseudo dice [np.float32(0.5007)] 
2025-02-27 15:36:23.255123: Epoch time: 84.59 s 
2025-02-27 15:36:23.822392:  
2025-02-27 15:36:23.826950: Epoch 47 
2025-02-27 15:36:23.829489: Current learning rate: 0.00565 
2025-02-27 15:37:48.454778: train_loss -0.6336 
2025-02-27 15:37:48.461294: val_loss -0.3751 
2025-02-27 15:37:48.464804: Pseudo dice [np.float32(0.5817)] 
2025-02-27 15:37:48.468316: Epoch time: 84.63 s 
2025-02-27 15:37:49.033064:  
2025-02-27 15:37:49.039201: Epoch 48 
2025-02-27 15:37:49.041707: Current learning rate: 0.00555 
2025-02-27 15:39:13.661060: train_loss -0.6316 
2025-02-27 15:39:13.666581: val_loss -0.4446 
2025-02-27 15:39:13.669090: Pseudo dice [np.float32(0.5678)] 
2025-02-27 15:39:13.672605: Epoch time: 84.63 s 
2025-02-27 15:39:13.676112: Yayy! New best EMA pseudo Dice: 0.546500027179718 
2025-02-27 15:39:14.399224:  
2025-02-27 15:39:14.405322: Epoch 49 
2025-02-27 15:39:14.408461: Current learning rate: 0.00546 
2025-02-27 15:40:39.044935: train_loss -0.613 
2025-02-27 15:40:39.051453: val_loss -0.4492 
2025-02-27 15:40:39.054964: Pseudo dice [np.float32(0.5637)] 
2025-02-27 15:40:39.057468: Epoch time: 84.65 s 
2025-02-27 15:40:39.222434: Yayy! New best EMA pseudo Dice: 0.5482000112533569 
2025-02-27 15:40:39.962288:  
2025-02-27 15:40:39.967904: Epoch 50 
2025-02-27 15:40:39.971462: Current learning rate: 0.00536 
2025-02-27 15:42:04.619998: train_loss -0.5819 
2025-02-27 15:42:04.627521: val_loss -0.5013 
2025-02-27 15:42:04.631030: Pseudo dice [np.float32(0.6216)] 
2025-02-27 15:42:04.633540: Epoch time: 84.66 s 
2025-02-27 15:42:04.637553: Yayy! New best EMA pseudo Dice: 0.5555999875068665 
2025-02-27 15:42:05.387729:  
2025-02-27 15:42:05.393359: Epoch 51 
2025-02-27 15:42:05.396895: Current learning rate: 0.00526 
2025-02-27 15:43:30.033365: train_loss -0.6081 
2025-02-27 15:43:30.039383: val_loss -0.3967 
2025-02-27 15:43:30.043393: Pseudo dice [np.float32(0.5176)] 
2025-02-27 15:43:30.046506: Epoch time: 84.65 s 
2025-02-27 15:43:30.643745:  
2025-02-27 15:43:30.648860: Epoch 52 
2025-02-27 15:43:30.652462: Current learning rate: 0.00517 
2025-02-27 15:44:55.332860: train_loss -0.6027 
2025-02-27 15:44:55.339876: val_loss -0.3849 
2025-02-27 15:44:55.343891: Pseudo dice [np.float32(0.5179)] 
2025-02-27 15:44:55.346398: Epoch time: 84.69 s 
2025-02-27 15:44:55.919223:  
2025-02-27 15:44:55.924267: Epoch 53 
2025-02-27 15:44:55.927327: Current learning rate: 0.00507 
2025-02-27 15:46:20.589490: train_loss -0.6383 
2025-02-27 15:46:20.597013: val_loss -0.339 
2025-02-27 15:46:20.601026: Pseudo dice [np.float32(0.571)] 
2025-02-27 15:46:20.604536: Epoch time: 84.67 s 
2025-02-27 15:46:21.187251:  
2025-02-27 15:46:21.192767: Epoch 54 
2025-02-27 15:46:21.196278: Current learning rate: 0.00497 
2025-02-27 15:47:45.824169: train_loss -0.6248 
2025-02-27 15:47:45.831696: val_loss -0.3912 
2025-02-27 15:47:45.835210: Pseudo dice [np.float32(0.6059)] 
2025-02-27 15:47:45.839222: Epoch time: 84.64 s 
2025-02-27 15:47:45.842736: Yayy! New best EMA pseudo Dice: 0.5562000274658203 
2025-02-27 15:47:46.577922:  
2025-02-27 15:47:46.583986: Epoch 55 
2025-02-27 15:47:46.587109: Current learning rate: 0.00487 
2025-02-27 15:49:11.221009: train_loss -0.6232 
2025-02-27 15:49:11.227533: val_loss -0.4618 
2025-02-27 15:49:11.231544: Pseudo dice [np.float32(0.572)] 
2025-02-27 15:49:11.235567: Epoch time: 84.64 s 
2025-02-27 15:49:11.239111: Yayy! New best EMA pseudo Dice: 0.5577999949455261 
2025-02-27 15:49:11.986142:  
2025-02-27 15:49:11.992197: Epoch 56 
2025-02-27 15:49:11.995246: Current learning rate: 0.00478 
2025-02-27 15:50:36.599959: train_loss -0.5827 
2025-02-27 15:50:36.607481: val_loss -0.4167 
2025-02-27 15:50:36.611493: Pseudo dice [np.float32(0.5738)] 
2025-02-27 15:50:36.615007: Epoch time: 84.61 s 
2025-02-27 15:50:36.618512: Yayy! New best EMA pseudo Dice: 0.5594000220298767 
2025-02-27 15:50:37.368292:  
2025-02-27 15:50:37.374886: Epoch 57 
2025-02-27 15:50:37.379518: Current learning rate: 0.00468 
2025-02-27 15:52:01.982294: train_loss -0.6135 
2025-02-27 15:52:01.989311: val_loss -0.4559 
2025-02-27 15:52:01.993322: Pseudo dice [np.float32(0.5943)] 
2025-02-27 15:52:01.996831: Epoch time: 84.61 s 
2025-02-27 15:52:01.999840: Yayy! New best EMA pseudo Dice: 0.5627999901771545 
2025-02-27 15:52:02.747658:  
2025-02-27 15:52:02.753206: Epoch 58 
2025-02-27 15:52:02.756749: Current learning rate: 0.00458 
2025-02-27 15:53:27.338477: train_loss -0.6297 
2025-02-27 15:53:27.347496: val_loss -0.4124 
2025-02-27 15:53:27.351007: Pseudo dice [np.float32(0.5883)] 
2025-02-27 15:53:27.355187: Epoch time: 84.59 s 
2025-02-27 15:53:27.357728: Yayy! New best EMA pseudo Dice: 0.5654000043869019 
2025-02-27 15:53:28.103295:  
2025-02-27 15:53:28.108340: Epoch 59 
2025-02-27 15:53:28.112483: Current learning rate: 0.00448 
2025-02-27 15:54:52.752907: train_loss -0.6621 
2025-02-27 15:54:52.759925: val_loss -0.4559 
2025-02-27 15:54:52.763455: Pseudo dice [np.float32(0.6096)] 
2025-02-27 15:54:52.766484: Epoch time: 84.65 s 
2025-02-27 15:54:52.770497: Yayy! New best EMA pseudo Dice: 0.5698000192642212 
2025-02-27 15:54:53.526534:  
2025-02-27 15:54:53.531545: Epoch 60 
2025-02-27 15:54:53.535057: Current learning rate: 0.00438 
2025-02-27 15:56:18.149863: train_loss -0.6496 
2025-02-27 15:56:18.157393: val_loss -0.4692 
2025-02-27 15:56:18.160905: Pseudo dice [np.float32(0.6338)] 
2025-02-27 15:56:18.164927: Epoch time: 84.62 s 
2025-02-27 15:56:18.168441: Yayy! New best EMA pseudo Dice: 0.576200008392334 
2025-02-27 15:56:18.921161:  
2025-02-27 15:56:18.927299: Epoch 61 
2025-02-27 15:56:18.931308: Current learning rate: 0.00429 
2025-02-27 15:57:43.545032: train_loss -0.6385 
2025-02-27 15:57:43.552552: val_loss -0.4774 
2025-02-27 15:57:43.556062: Pseudo dice [np.float32(0.6276)] 
2025-02-27 15:57:43.560073: Epoch time: 84.62 s 
2025-02-27 15:57:43.563583: Yayy! New best EMA pseudo Dice: 0.5813000202178955 
2025-02-27 15:57:44.486441:  
2025-02-27 15:57:44.492958: Epoch 62 
2025-02-27 15:57:44.496464: Current learning rate: 0.00419 
2025-02-27 15:59:09.091155: train_loss -0.6732 
2025-02-27 15:59:09.098680: val_loss -0.3737 
2025-02-27 15:59:09.102189: Pseudo dice [np.float32(0.5845)] 
2025-02-27 15:59:09.104696: Epoch time: 84.61 s 
2025-02-27 15:59:09.109710: Yayy! New best EMA pseudo Dice: 0.5817000269889832 
2025-02-27 15:59:09.896705:  
2025-02-27 15:59:09.903243: Epoch 63 
2025-02-27 15:59:09.906790: Current learning rate: 0.00409 
2025-02-27 16:00:34.473187: train_loss -0.6512 
2025-02-27 16:00:34.479700: val_loss -0.4687 
2025-02-27 16:00:34.483209: Pseudo dice [np.float32(0.599)] 
2025-02-27 16:00:34.487222: Epoch time: 84.58 s 
2025-02-27 16:00:34.490731: Yayy! New best EMA pseudo Dice: 0.5834000110626221 
2025-02-27 16:00:35.252787:  
2025-02-27 16:00:35.258305: Epoch 64 
2025-02-27 16:00:35.261813: Current learning rate: 0.00399 
2025-02-27 16:01:59.857335: train_loss -0.6596 
2025-02-27 16:01:59.864852: val_loss -0.4403 
2025-02-27 16:01:59.868365: Pseudo dice [np.float32(0.5815)] 
2025-02-27 16:01:59.872373: Epoch time: 84.61 s 
2025-02-27 16:02:00.500089:  
2025-02-27 16:02:00.506135: Epoch 65 
2025-02-27 16:02:00.510195: Current learning rate: 0.00389 
2025-02-27 16:03:25.166374: train_loss -0.6623 
2025-02-27 16:03:25.172887: val_loss -0.4742 
2025-02-27 16:03:25.177902: Pseudo dice [np.float32(0.6736)] 
2025-02-27 16:03:25.181413: Epoch time: 84.67 s 
2025-02-27 16:03:25.185425: Yayy! New best EMA pseudo Dice: 0.592199981212616 
2025-02-27 16:03:25.937432:  
2025-02-27 16:03:25.942989: Epoch 66 
2025-02-27 16:03:25.948064: Current learning rate: 0.00379 
2025-02-27 16:04:50.592939: train_loss -0.7015 
2025-02-27 16:04:50.600370: val_loss -0.4616 
2025-02-27 16:04:50.604883: Pseudo dice [np.float32(0.6111)] 
2025-02-27 16:04:50.608901: Epoch time: 84.66 s 
2025-02-27 16:04:50.612920: Yayy! New best EMA pseudo Dice: 0.5940999984741211 
2025-02-27 16:04:51.365617:  
2025-02-27 16:04:51.371715: Epoch 67 
2025-02-27 16:04:51.375273: Current learning rate: 0.00369 
2025-02-27 16:06:16.037739: train_loss -0.6728 
2025-02-27 16:06:16.045254: val_loss -0.4506 
2025-02-27 16:06:16.049268: Pseudo dice [np.float32(0.6415)] 
2025-02-27 16:06:16.053779: Epoch time: 84.67 s 
2025-02-27 16:06:16.056789: Yayy! New best EMA pseudo Dice: 0.5989000201225281 
2025-02-27 16:06:16.813559:  
2025-02-27 16:06:16.819514: Epoch 68 
2025-02-27 16:06:16.823527: Current learning rate: 0.00359 
2025-02-27 16:07:41.441449: train_loss -0.6698 
2025-02-27 16:07:41.448967: val_loss -0.4895 
2025-02-27 16:07:41.453984: Pseudo dice [np.float32(0.6779)] 
2025-02-27 16:07:41.457499: Epoch time: 84.63 s 
2025-02-27 16:07:41.461511: Yayy! New best EMA pseudo Dice: 0.6068000197410583 
2025-02-27 16:07:42.412389:  
2025-02-27 16:07:42.419029: Epoch 69 
2025-02-27 16:07:42.423096: Current learning rate: 0.00349 
2025-02-27 16:09:07.034975: train_loss -0.6849 
2025-02-27 16:09:07.040999: val_loss -0.4736 
2025-02-27 16:09:07.045011: Pseudo dice [np.float32(0.6193)] 
2025-02-27 16:09:07.049525: Epoch time: 84.62 s 
2025-02-27 16:09:07.053544: Yayy! New best EMA pseudo Dice: 0.6079999804496765 
2025-02-27 16:09:07.862749:  
2025-02-27 16:09:07.869265: Epoch 70 
2025-02-27 16:09:07.872770: Current learning rate: 0.00338 
2025-02-27 16:10:32.501729: train_loss -0.6691 
2025-02-27 16:10:32.509248: val_loss -0.3655 
2025-02-27 16:10:32.512259: Pseudo dice [np.float32(0.5829)] 
2025-02-27 16:10:32.516769: Epoch time: 84.64 s 
2025-02-27 16:10:33.120273:  
2025-02-27 16:10:33.126288: Epoch 71 
2025-02-27 16:10:33.130297: Current learning rate: 0.00328 
2025-02-27 16:11:57.784344: train_loss -0.6785 
2025-02-27 16:11:57.791869: val_loss -0.4417 
2025-02-27 16:11:57.795380: Pseudo dice [np.float32(0.6296)] 
2025-02-27 16:11:57.799390: Epoch time: 84.66 s 
2025-02-27 16:11:58.404375:  
2025-02-27 16:11:58.410499: Epoch 72 
2025-02-27 16:11:58.413565: Current learning rate: 0.00318 
2025-02-27 16:13:23.069298: train_loss -0.6652 
2025-02-27 16:13:23.076816: val_loss -0.416 
2025-02-27 16:13:23.080328: Pseudo dice [np.float32(0.5516)] 
2025-02-27 16:13:23.084337: Epoch time: 84.66 s 
2025-02-27 16:13:23.713274:  
2025-02-27 16:13:23.719836: Epoch 73 
2025-02-27 16:13:23.723361: Current learning rate: 0.00308 
2025-02-27 16:14:48.343500: train_loss -0.6727 
2025-02-27 16:14:48.351036: val_loss -0.4319 
2025-02-27 16:14:48.355554: Pseudo dice [np.float32(0.5983)] 
2025-02-27 16:14:48.359571: Epoch time: 84.63 s 
2025-02-27 16:14:48.957887:  
2025-02-27 16:14:48.963450: Epoch 74 
2025-02-27 16:14:48.967495: Current learning rate: 0.00297 
2025-02-27 16:16:13.618155: train_loss -0.6707 
2025-02-27 16:16:13.625674: val_loss -0.3821 
2025-02-27 16:16:13.629184: Pseudo dice [np.float32(0.5817)] 
2025-02-27 16:16:13.633191: Epoch time: 84.66 s 
2025-02-27 16:16:14.227036:  
2025-02-27 16:16:14.233068: Epoch 75 
2025-02-27 16:16:14.237620: Current learning rate: 0.00287 
2025-02-27 16:17:38.874228: train_loss -0.6891 
2025-02-27 16:17:38.882753: val_loss -0.5335 
2025-02-27 16:17:38.886762: Pseudo dice [np.float32(0.6603)] 
2025-02-27 16:17:38.890271: Epoch time: 84.65 s 
2025-02-27 16:17:39.497129:  
2025-02-27 16:17:39.502143: Epoch 76 
2025-02-27 16:17:39.506156: Current learning rate: 0.00277 
2025-02-27 16:19:04.130503: train_loss -0.7142 
2025-02-27 16:19:04.138021: val_loss -0.5282 
2025-02-27 16:19:04.141029: Pseudo dice [np.float32(0.6966)] 
2025-02-27 16:19:04.145539: Epoch time: 84.63 s 
2025-02-27 16:19:04.148548: Yayy! New best EMA pseudo Dice: 0.6150000095367432 
2025-02-27 16:19:05.076151:  
2025-02-27 16:19:05.082709: Epoch 77 
2025-02-27 16:19:05.086235: Current learning rate: 0.00266 
2025-02-27 16:20:29.644769: train_loss -0.7064 
2025-02-27 16:20:29.650816: val_loss -0.2916 
2025-02-27 16:20:29.657339: Pseudo dice [np.float32(0.481)] 
2025-02-27 16:20:29.662352: Epoch time: 84.57 s 
2025-02-27 16:20:30.269721:  
2025-02-27 16:20:30.276294: Epoch 78 
2025-02-27 16:20:30.280364: Current learning rate: 0.00256 
2025-02-27 16:21:54.923918: train_loss -0.6725 
2025-02-27 16:21:54.932441: val_loss -0.4212 
2025-02-27 16:21:54.936453: Pseudo dice [np.float32(0.6106)] 
2025-02-27 16:21:54.940466: Epoch time: 84.65 s 
2025-02-27 16:21:55.545806:  
2025-02-27 16:21:55.552415: Epoch 79 
2025-02-27 16:21:55.554960: Current learning rate: 0.00245 
2025-02-27 16:23:20.167464: train_loss -0.6695 
2025-02-27 16:23:20.174994: val_loss -0.4666 
2025-02-27 16:23:20.178503: Pseudo dice [np.float32(0.5985)] 
2025-02-27 16:23:20.182518: Epoch time: 84.62 s 
2025-02-27 16:23:20.787530:  
2025-02-27 16:23:20.793545: Epoch 80 
2025-02-27 16:23:20.797555: Current learning rate: 0.00235 
2025-02-27 16:24:45.447839: train_loss -0.7197 
2025-02-27 16:24:45.455405: val_loss -0.4062 
2025-02-27 16:24:45.459449: Pseudo dice [np.float32(0.6005)] 
2025-02-27 16:24:45.463497: Epoch time: 84.66 s 
2025-02-27 16:24:46.077545:  
2025-02-27 16:24:46.083654: Epoch 81 
2025-02-27 16:24:46.087664: Current learning rate: 0.00224 
2025-02-27 16:26:10.700009: train_loss -0.7244 
2025-02-27 16:26:10.706554: val_loss -0.45 
2025-02-27 16:26:10.710571: Pseudo dice [np.float32(0.6415)] 
2025-02-27 16:26:10.715088: Epoch time: 84.62 s 
2025-02-27 16:26:11.344972:  
2025-02-27 16:26:11.351562: Epoch 82 
2025-02-27 16:26:11.355626: Current learning rate: 0.00214 
2025-02-27 16:27:36.007633: train_loss -0.7107 
2025-02-27 16:27:36.015153: val_loss -0.301 
2025-02-27 16:27:36.019687: Pseudo dice [np.float32(0.5757)] 
2025-02-27 16:27:36.022229: Epoch time: 84.66 s 
2025-02-27 16:27:36.593209:  
2025-02-27 16:27:36.599228: Epoch 83 
2025-02-27 16:27:36.603240: Current learning rate: 0.00203 
2025-02-27 16:29:01.283890: train_loss -0.7206 
2025-02-27 16:29:01.291411: val_loss -0.5367 
2025-02-27 16:29:01.295418: Pseudo dice [np.float32(0.66)] 
2025-02-27 16:29:01.297924: Epoch time: 84.69 s 
2025-02-27 16:29:01.878581:  
2025-02-27 16:29:01.885230: Epoch 84 
2025-02-27 16:29:01.888775: Current learning rate: 0.00192 
2025-02-27 16:30:27.029952: train_loss -0.7298 
2025-02-27 16:30:27.037475: val_loss -0.4601 
2025-02-27 16:30:27.040986: Pseudo dice [np.float32(0.6957)] 
2025-02-27 16:30:27.046000: Epoch time: 85.15 s 
2025-02-27 16:30:27.050012: Yayy! New best EMA pseudo Dice: 0.6172999739646912 
2025-02-27 16:30:27.941005:  
2025-02-27 16:30:27.946585: Epoch 85 
2025-02-27 16:30:27.951151: Current learning rate: 0.00181 
2025-02-27 16:31:52.514427: train_loss -0.7053 
2025-02-27 16:31:52.521312: val_loss -0.4382 
2025-02-27 16:31:52.524370: Pseudo dice [np.float32(0.6562)] 
2025-02-27 16:31:52.527881: Epoch time: 84.57 s 
2025-02-27 16:31:52.531393: Yayy! New best EMA pseudo Dice: 0.6212000250816345 
2025-02-27 16:31:53.284595:  
2025-02-27 16:31:53.291111: Epoch 86 
2025-02-27 16:31:53.294642: Current learning rate: 0.0017 
2025-02-27 16:33:17.932812: train_loss -0.7124 
2025-02-27 16:33:17.939335: val_loss -0.4498 
2025-02-27 16:33:17.941843: Pseudo dice [np.float32(0.6239)] 
2025-02-27 16:33:17.945856: Epoch time: 84.65 s 
2025-02-27 16:33:17.948362: Yayy! New best EMA pseudo Dice: 0.6215000152587891 
2025-02-27 16:33:18.678350:  
2025-02-27 16:33:18.684388: Epoch 87 
2025-02-27 16:33:18.687925: Current learning rate: 0.00159 
2025-02-27 16:34:43.354964: train_loss -0.716 
2025-02-27 16:34:43.361481: val_loss -0.451 
2025-02-27 16:34:43.364998: Pseudo dice [np.float32(0.613)] 
2025-02-27 16:34:43.369015: Epoch time: 84.68 s 
2025-02-27 16:34:43.934960:  
2025-02-27 16:34:43.940478: Epoch 88 
2025-02-27 16:34:43.943986: Current learning rate: 0.00148 
2025-02-27 16:36:08.576108: train_loss -0.7182 
2025-02-27 16:36:08.584630: val_loss -0.3957 
2025-02-27 16:36:08.588201: Pseudo dice [np.float32(0.6256)] 
2025-02-27 16:36:08.590739: Epoch time: 84.64 s 
2025-02-27 16:36:09.158496:  
2025-02-27 16:36:09.163514: Epoch 89 
2025-02-27 16:36:09.166523: Current learning rate: 0.00137 
2025-02-27 16:37:33.797869: train_loss -0.716 
2025-02-27 16:37:33.803885: val_loss -0.4512 
2025-02-27 16:37:33.807897: Pseudo dice [np.float32(0.6795)] 
2025-02-27 16:37:33.810915: Epoch time: 84.64 s 
2025-02-27 16:37:33.813944: Yayy! New best EMA pseudo Dice: 0.6269999742507935 
2025-02-27 16:37:34.530546:  
2025-02-27 16:37:34.536066: Epoch 90 
2025-02-27 16:37:34.539575: Current learning rate: 0.00126 
2025-02-27 16:38:59.187789: train_loss -0.7389 
2025-02-27 16:38:59.194311: val_loss -0.435 
2025-02-27 16:38:59.197825: Pseudo dice [np.float32(0.5812)] 
2025-02-27 16:38:59.201838: Epoch time: 84.66 s 
2025-02-27 16:38:59.772366:  
2025-02-27 16:38:59.777377: Epoch 91 
2025-02-27 16:38:59.780887: Current learning rate: 0.00115 
2025-02-27 16:40:24.398161: train_loss -0.7461 
2025-02-27 16:40:24.404722: val_loss -0.5114 
2025-02-27 16:40:24.407483: Pseudo dice [np.float32(0.6798)] 
2025-02-27 16:40:24.410996: Epoch time: 84.63 s 
2025-02-27 16:40:24.413509: Yayy! New best EMA pseudo Dice: 0.6280999779701233 
2025-02-27 16:40:25.142580:  
2025-02-27 16:40:25.147327: Epoch 92 
2025-02-27 16:40:25.150839: Current learning rate: 0.00103 
2025-02-27 16:41:49.774975: train_loss -0.7296 
2025-02-27 16:41:49.782496: val_loss -0.3899 
2025-02-27 16:41:49.785507: Pseudo dice [np.float32(0.5366)] 
2025-02-27 16:41:49.790019: Epoch time: 84.63 s 
2025-02-27 16:41:50.540096:  
2025-02-27 16:41:50.545613: Epoch 93 
2025-02-27 16:41:50.549123: Current learning rate: 0.00091 
2025-02-27 16:43:15.152814: train_loss -0.724 
2025-02-27 16:43:15.159334: val_loss -0.4598 
2025-02-27 16:43:15.163347: Pseudo dice [np.float32(0.6507)] 
2025-02-27 16:43:15.166860: Epoch time: 84.61 s 
2025-02-27 16:43:15.730963:  
2025-02-27 16:43:15.736480: Epoch 94 
2025-02-27 16:43:15.739990: Current learning rate: 0.00079 
2025-02-27 16:44:40.341507: train_loss -0.7583 
2025-02-27 16:44:40.349763: val_loss -0.4366 
2025-02-27 16:44:40.352841: Pseudo dice [np.float32(0.6561)] 
2025-02-27 16:44:40.355925: Epoch time: 84.61 s 
2025-02-27 16:44:40.918734:  
2025-02-27 16:44:40.924264: Epoch 95 
2025-02-27 16:44:40.927811: Current learning rate: 0.00067 
2025-02-27 16:46:05.553613: train_loss -0.767 
2025-02-27 16:46:05.560702: val_loss -0.4455 
2025-02-27 16:46:05.564251: Pseudo dice [np.float32(0.6481)] 
2025-02-27 16:46:05.567930: Epoch time: 84.64 s 
2025-02-27 16:46:06.139702:  
2025-02-27 16:46:06.145825: Epoch 96 
2025-02-27 16:46:06.149404: Current learning rate: 0.00055 
2025-02-27 16:47:30.788526: train_loss -0.7588 
2025-02-27 16:47:30.795041: val_loss -0.4204 
2025-02-27 16:47:30.798552: Pseudo dice [np.float32(0.5983)] 
2025-02-27 16:47:30.802563: Epoch time: 84.65 s 
2025-02-27 16:47:31.383025:  
2025-02-27 16:47:31.388042: Epoch 97 
2025-02-27 16:47:31.391553: Current learning rate: 0.00043 
2025-02-27 16:48:56.055796: train_loss -0.7604 
2025-02-27 16:48:56.062314: val_loss -0.5093 
2025-02-27 16:48:56.065827: Pseudo dice [np.float32(0.7215)] 
2025-02-27 16:48:56.069332: Epoch time: 84.67 s 
2025-02-27 16:48:56.072342: Yayy! New best EMA pseudo Dice: 0.6345000267028809 
2025-02-27 16:48:56.798681:  
2025-02-27 16:48:56.804235: Epoch 98 
2025-02-27 16:48:56.806789: Current learning rate: 0.0003 
2025-02-27 16:50:21.442535: train_loss -0.7521 
2025-02-27 16:50:21.449113: val_loss -0.388 
2025-02-27 16:50:21.453142: Pseudo dice [np.float32(0.5694)] 
2025-02-27 16:50:21.456169: Epoch time: 84.64 s 
2025-02-27 16:50:22.051138:  
2025-02-27 16:50:22.056702: Epoch 99 
2025-02-27 16:50:22.059248: Current learning rate: 0.00016 
2025-02-27 16:51:46.704841: train_loss -0.7543 
2025-02-27 16:51:46.712362: val_loss -0.4435 
2025-02-27 16:51:46.715870: Pseudo dice [np.float32(0.6285)] 
2025-02-27 16:51:46.719379: Epoch time: 84.66 s 
2025-02-27 16:51:47.532075: Training done. 
2025-02-27 16:51:47.560590: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-02-27 16:51:47.566592: The split file contains 5 splits. 
2025-02-27 16:51:47.571593: Desired fold for training: 0 
2025-02-27 16:51:47.575594: This split has 100 training and 26 validation cases. 
2025-02-27 16:51:47.581593: predicting colon_008 
2025-02-27 16:51:47.587592: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-02-27 16:52:04.101419: predicting colon_027 
2025-02-27 16:52:04.124417: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-02-27 16:52:10.435689: predicting colon_030 
2025-02-27 16:52:10.450690: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-02-27 16:52:19.368959: predicting colon_033 
2025-02-27 16:52:19.388053: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-02-27 16:52:35.184553: predicting colon_041 
2025-02-27 16:52:35.211061: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-02-27 16:53:17.678743: predicting colon_042 
2025-02-27 16:53:17.718253: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-02-27 16:53:39.012544: predicting colon_061 
2025-02-27 16:53:39.039753: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-02-27 16:54:03.666129: predicting colon_074 
2025-02-27 16:54:03.689134: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-02-27 16:54:32.082130: predicting colon_075 
2025-02-27 16:54:32.112130: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-02-27 16:54:47.935764: predicting colon_088 
2025-02-27 16:54:47.961764: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-02-27 16:55:12.627351: predicting colon_091 
2025-02-27 16:55:12.658352: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-02-27 16:55:42.188030: predicting colon_092 
2025-02-27 16:55:42.223544: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-02-27 16:56:06.857031: predicting colon_095 
2025-02-27 16:56:06.884031: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-02-27 16:56:22.723718: predicting colon_102 
2025-02-27 16:56:22.747931: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-02-27 16:56:58.149791: predicting colon_111 
2025-02-27 16:56:58.187305: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-02-27 16:57:08.112791: predicting colon_115 
2025-02-27 16:57:08.132792: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-02-27 16:57:23.973509: predicting colon_118 
2025-02-27 16:57:23.998683: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-02-27 16:57:48.600473: predicting colon_124 
2025-02-27 16:57:48.628979: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-02-27 16:58:13.237833: predicting colon_127 
2025-02-27 16:58:13.270833: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-02-27 16:59:02.843922: predicting colon_154 
2025-02-27 16:59:02.886430: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-02-27 16:59:18.705493: predicting colon_161 
2025-02-27 16:59:18.729493: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-02-27 16:59:34.561427: predicting colon_162 
2025-02-27 16:59:34.587937: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-02-27 17:00:17.111315: predicting colon_165 
2025-02-27 17:00:17.145358: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-02-27 17:00:52.547985: predicting colon_166 
2025-02-27 17:00:52.579984: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-02-27 17:01:08.371916: predicting colon_169 
2025-02-27 17:01:08.391916: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-02-27 17:01:58.078028: predicting colon_187 
2025-02-27 17:01:58.126535: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-02-27 17:02:32.574836: Validation complete 
2025-02-27 17:02:32.579836: Mean Validation Dice:  0.24928981066887035 
