
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-13 11:05:42.554791: do_dummy_2d_data_aug: True 
2025-03-13 11:05:42.562794: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-13 11:05:42.570795: The split file contains 5 splits. 
2025-03-13 11:05:42.572795: Desired fold for training: 0 
2025-03-13 11:05:42.575794: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-03-13 11:05:51.225173: unpacking dataset... 
2025-03-13 11:06:02.586293: unpacking done... 
2025-03-13 11:06:05.822655:  
2025-03-13 11:06:05.827666: Epoch 0 
2025-03-13 11:06:05.830676: Current learning rate: 0.01 
2025-03-13 11:06:51.663459: train_loss 0.025 
2025-03-13 11:06:51.669476: val_loss -0.0232 
2025-03-13 11:06:51.672984: Pseudo dice [np.float32(0.0)] 
2025-03-13 11:06:51.675995: Epoch time: 45.84 s 
2025-03-13 11:06:51.679504: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-13 11:06:52.267607:  
2025-03-13 11:06:52.273168: Epoch 1 
2025-03-13 11:06:52.276691: Current learning rate: 0.00991 
2025-03-13 11:07:33.611987: train_loss -0.1595 
2025-03-13 11:07:33.617058: val_loss -0.2575 
2025-03-13 11:07:33.621629: Pseudo dice [np.float32(0.3841)] 
2025-03-13 11:07:33.626183: Epoch time: 41.34 s 
2025-03-13 11:07:33.629235: Yayy! New best EMA pseudo Dice: 0.03840000182390213 
2025-03-13 11:07:34.300662:  
2025-03-13 11:07:34.306730: Epoch 2 
2025-03-13 11:07:34.310280: Current learning rate: 0.00982 
2025-03-13 11:08:15.641179: train_loss -0.2713 
2025-03-13 11:08:15.647780: val_loss -0.2351 
2025-03-13 11:08:15.651828: Pseudo dice [np.float32(0.2863)] 
2025-03-13 11:08:15.655395: Epoch time: 41.34 s 
2025-03-13 11:08:15.657919: Yayy! New best EMA pseudo Dice: 0.06319999694824219 
2025-03-13 11:08:16.351300:  
2025-03-13 11:08:16.357372: Epoch 3 
2025-03-13 11:08:16.360432: Current learning rate: 0.00973 
2025-03-13 11:08:57.695907: train_loss -0.3539 
2025-03-13 11:08:57.701453: val_loss -0.2992 
2025-03-13 11:08:57.705044: Pseudo dice [np.float32(0.3555)] 
2025-03-13 11:08:57.708555: Epoch time: 41.35 s 
2025-03-13 11:08:57.712061: Yayy! New best EMA pseudo Dice: 0.09239999949932098 
2025-03-13 11:08:58.404227:  
2025-03-13 11:08:58.409739: Epoch 4 
2025-03-13 11:08:58.413256: Current learning rate: 0.00964 
2025-03-13 11:09:39.729114: train_loss -0.3147 
2025-03-13 11:09:39.734650: val_loss -0.3217 
2025-03-13 11:09:39.737788: Pseudo dice [np.float32(0.402)] 
2025-03-13 11:09:39.741870: Epoch time: 41.33 s 
2025-03-13 11:09:39.744880: Yayy! New best EMA pseudo Dice: 0.1234000027179718 
2025-03-13 11:09:40.547726:  
2025-03-13 11:09:40.553770: Epoch 5 
2025-03-13 11:09:40.556818: Current learning rate: 0.00955 
2025-03-13 11:10:21.883399: train_loss -0.3553 
2025-03-13 11:10:21.889522: val_loss -0.346 
2025-03-13 11:10:21.892555: Pseudo dice [np.float32(0.4147)] 
2025-03-13 11:10:21.895598: Epoch time: 41.34 s 
2025-03-13 11:10:21.898634: Yayy! New best EMA pseudo Dice: 0.1525000035762787 
2025-03-13 11:10:22.562449:  
2025-03-13 11:10:22.568469: Epoch 6 
2025-03-13 11:10:22.570975: Current learning rate: 0.00946 
2025-03-13 11:11:03.900227: train_loss -0.3509 
2025-03-13 11:11:03.907288: val_loss -0.2849 
2025-03-13 11:11:03.911329: Pseudo dice [np.float32(0.377)] 
2025-03-13 11:11:03.914363: Epoch time: 41.34 s 
2025-03-13 11:11:03.917459: Yayy! New best EMA pseudo Dice: 0.17499999701976776 
2025-03-13 11:11:04.603060:  
2025-03-13 11:11:04.609098: Epoch 7 
2025-03-13 11:11:04.612609: Current learning rate: 0.00937 
2025-03-13 11:11:45.941222: train_loss -0.33 
2025-03-13 11:11:45.946787: val_loss -0.316 
2025-03-13 11:11:45.950526: Pseudo dice [np.float32(0.3954)] 
2025-03-13 11:11:45.954054: Epoch time: 41.34 s 
2025-03-13 11:11:45.957067: Yayy! New best EMA pseudo Dice: 0.19699999690055847 
2025-03-13 11:11:46.648253:  
2025-03-13 11:11:46.653776: Epoch 8 
2025-03-13 11:11:46.657285: Current learning rate: 0.00928 
2025-03-13 11:12:27.982991: train_loss -0.3772 
2025-03-13 11:12:27.989003: val_loss -0.4109 
2025-03-13 11:12:27.993012: Pseudo dice [np.float32(0.4689)] 
2025-03-13 11:12:27.996521: Epoch time: 41.34 s 
2025-03-13 11:12:27.999026: Yayy! New best EMA pseudo Dice: 0.22419999539852142 
2025-03-13 11:12:28.713008:  
2025-03-13 11:12:28.719042: Epoch 9 
2025-03-13 11:12:28.722088: Current learning rate: 0.00919 
2025-03-13 11:13:10.061104: train_loss -0.3713 
2025-03-13 11:13:10.067117: val_loss -0.4269 
2025-03-13 11:13:10.071126: Pseudo dice [np.float32(0.4979)] 
2025-03-13 11:13:10.074634: Epoch time: 41.35 s 
2025-03-13 11:13:10.078140: Yayy! New best EMA pseudo Dice: 0.2515999972820282 
2025-03-13 11:13:10.785794:  
2025-03-13 11:13:10.791316: Epoch 10 
2025-03-13 11:13:10.794824: Current learning rate: 0.0091 
2025-03-13 11:13:52.135302: train_loss -0.4033 
2025-03-13 11:13:52.141370: val_loss -0.4262 
2025-03-13 11:13:52.144913: Pseudo dice [np.float32(0.4291)] 
2025-03-13 11:13:52.148468: Epoch time: 41.35 s 
2025-03-13 11:13:52.151523: Yayy! New best EMA pseudo Dice: 0.26930001378059387 
2025-03-13 11:13:52.860477:  
2025-03-13 11:13:52.865988: Epoch 11 
2025-03-13 11:13:52.869498: Current learning rate: 0.009 
2025-03-13 11:14:34.200248: train_loss -0.4265 
2025-03-13 11:14:34.205847: val_loss -0.3446 
2025-03-13 11:14:34.209410: Pseudo dice [np.float32(0.3965)] 
2025-03-13 11:14:34.213478: Epoch time: 41.34 s 
2025-03-13 11:14:34.215987: Yayy! New best EMA pseudo Dice: 0.28200000524520874 
2025-03-13 11:14:34.879551:  
2025-03-13 11:14:34.885663: Epoch 12 
2025-03-13 11:14:34.889207: Current learning rate: 0.00891 
2025-03-13 11:15:16.213224: train_loss -0.4323 
2025-03-13 11:15:16.219764: val_loss -0.3989 
2025-03-13 11:15:16.223273: Pseudo dice [np.float32(0.4485)] 
2025-03-13 11:15:16.227280: Epoch time: 41.33 s 
2025-03-13 11:15:16.230787: Yayy! New best EMA pseudo Dice: 0.2987000048160553 
2025-03-13 11:15:17.054210:  
2025-03-13 11:15:17.060784: Epoch 13 
2025-03-13 11:15:17.063857: Current learning rate: 0.00882 
2025-03-13 11:15:58.378813: train_loss -0.4272 
2025-03-13 11:15:58.383888: val_loss -0.4179 
2025-03-13 11:15:58.389024: Pseudo dice [np.float32(0.4585)] 
2025-03-13 11:15:58.391581: Epoch time: 41.32 s 
2025-03-13 11:15:58.395621: Yayy! New best EMA pseudo Dice: 0.31470000743865967 
2025-03-13 11:15:59.063584:  
2025-03-13 11:15:59.070122: Epoch 14 
2025-03-13 11:15:59.073643: Current learning rate: 0.00873 
2025-03-13 11:16:40.399327: train_loss -0.4245 
2025-03-13 11:16:40.405881: val_loss -0.347 
2025-03-13 11:16:40.409425: Pseudo dice [np.float32(0.3576)] 
2025-03-13 11:16:40.412942: Epoch time: 41.34 s 
2025-03-13 11:16:40.416086: Yayy! New best EMA pseudo Dice: 0.3190000057220459 
2025-03-13 11:16:41.103123:  
2025-03-13 11:16:41.109221: Epoch 15 
2025-03-13 11:16:41.112725: Current learning rate: 0.00864 
2025-03-13 11:17:22.455516: train_loss -0.4499 
2025-03-13 11:17:22.463566: val_loss -0.394 
2025-03-13 11:17:22.467576: Pseudo dice [np.float32(0.4726)] 
2025-03-13 11:17:22.470081: Epoch time: 41.35 s 
2025-03-13 11:17:22.473590: Yayy! New best EMA pseudo Dice: 0.3343000113964081 
2025-03-13 11:17:23.159655:  
2025-03-13 11:17:23.165184: Epoch 16 
2025-03-13 11:17:23.168733: Current learning rate: 0.00855 
2025-03-13 11:18:04.516686: train_loss -0.4402 
2025-03-13 11:18:04.524206: val_loss -0.364 
2025-03-13 11:18:04.528218: Pseudo dice [np.float32(0.4571)] 
2025-03-13 11:18:04.531727: Epoch time: 41.36 s 
2025-03-13 11:18:04.535233: Yayy! New best EMA pseudo Dice: 0.3465999960899353 
2025-03-13 11:18:05.225069:  
2025-03-13 11:18:05.231707: Epoch 17 
2025-03-13 11:18:05.234756: Current learning rate: 0.00846 
2025-03-13 11:18:46.599365: train_loss -0.392 
2025-03-13 11:18:46.605440: val_loss -0.4961 
2025-03-13 11:18:46.607990: Pseudo dice [np.float32(0.5221)] 
2025-03-13 11:18:46.612033: Epoch time: 41.37 s 
2025-03-13 11:18:46.615622: Yayy! New best EMA pseudo Dice: 0.36410000920295715 
2025-03-13 11:18:47.309376:  
2025-03-13 11:18:47.314891: Epoch 18 
2025-03-13 11:18:47.318402: Current learning rate: 0.00836 
2025-03-13 11:19:28.661778: train_loss -0.4624 
2025-03-13 11:19:28.668847: val_loss -0.4878 
2025-03-13 11:19:28.672356: Pseudo dice [np.float32(0.5484)] 
2025-03-13 11:19:28.676375: Epoch time: 41.35 s 
2025-03-13 11:19:28.678884: Yayy! New best EMA pseudo Dice: 0.38260000944137573 
2025-03-13 11:19:29.359994:  
2025-03-13 11:19:29.365538: Epoch 19 
2025-03-13 11:19:29.370093: Current learning rate: 0.00827 
2025-03-13 11:20:10.702903: train_loss -0.5037 
2025-03-13 11:20:10.710989: val_loss -0.4197 
2025-03-13 11:20:10.714011: Pseudo dice [np.float32(0.4601)] 
2025-03-13 11:20:10.717973: Epoch time: 41.34 s 
2025-03-13 11:20:10.721485: Yayy! New best EMA pseudo Dice: 0.3903000056743622 
2025-03-13 11:20:11.404813:  
2025-03-13 11:20:11.412394: Epoch 20 
2025-03-13 11:20:11.416044: Current learning rate: 0.00818 
2025-03-13 11:20:52.749983: train_loss -0.4536 
2025-03-13 11:20:52.757013: val_loss -0.434 
2025-03-13 11:20:52.760860: Pseudo dice [np.float32(0.4375)] 
2025-03-13 11:20:52.764372: Epoch time: 41.35 s 
2025-03-13 11:20:52.767755: Yayy! New best EMA pseudo Dice: 0.39500001072883606 
2025-03-13 11:20:53.602206:  
2025-03-13 11:20:53.608251: Epoch 21 
2025-03-13 11:20:53.612804: Current learning rate: 0.00809 
2025-03-13 11:21:34.934777: train_loss -0.4618 
2025-03-13 11:21:34.941346: val_loss -0.4297 
2025-03-13 11:21:34.944905: Pseudo dice [np.float32(0.5248)] 
2025-03-13 11:21:34.947987: Epoch time: 41.33 s 
2025-03-13 11:21:34.951020: Yayy! New best EMA pseudo Dice: 0.40799999237060547 
2025-03-13 11:21:35.617405:  
2025-03-13 11:21:35.622530: Epoch 22 
2025-03-13 11:21:35.626594: Current learning rate: 0.008 
2025-03-13 11:22:16.965301: train_loss -0.4946 
2025-03-13 11:22:16.972816: val_loss -0.5003 
2025-03-13 11:22:16.976332: Pseudo dice [np.float32(0.5758)] 
2025-03-13 11:22:16.980341: Epoch time: 41.35 s 
2025-03-13 11:22:16.982847: Yayy! New best EMA pseudo Dice: 0.42480000853538513 
2025-03-13 11:22:17.650840:  
2025-03-13 11:22:17.656877: Epoch 23 
2025-03-13 11:22:17.659919: Current learning rate: 0.0079 
2025-03-13 11:22:58.999654: train_loss -0.4897 
2025-03-13 11:22:59.006163: val_loss -0.4345 
2025-03-13 11:22:59.010675: Pseudo dice [np.float32(0.5653)] 
2025-03-13 11:22:59.013686: Epoch time: 41.35 s 
2025-03-13 11:22:59.017198: Yayy! New best EMA pseudo Dice: 0.43880000710487366 
2025-03-13 11:22:59.707171:  
2025-03-13 11:22:59.712695: Epoch 24 
2025-03-13 11:22:59.716212: Current learning rate: 0.00781 
2025-03-13 11:23:41.016095: train_loss -0.458 
2025-03-13 11:23:41.022641: val_loss -0.4149 
2025-03-13 11:23:41.026655: Pseudo dice [np.float32(0.4922)] 
2025-03-13 11:23:41.030162: Epoch time: 41.31 s 
2025-03-13 11:23:41.033178: Yayy! New best EMA pseudo Dice: 0.4442000091075897 
2025-03-13 11:23:41.709242:  
2025-03-13 11:23:41.715267: Epoch 25 
2025-03-13 11:23:41.718779: Current learning rate: 0.00772 
2025-03-13 11:24:23.025137: train_loss -0.4565 
2025-03-13 11:24:23.031651: val_loss -0.4776 
2025-03-13 11:24:23.035167: Pseudo dice [np.float32(0.5472)] 
2025-03-13 11:24:23.038679: Epoch time: 41.32 s 
2025-03-13 11:24:23.042691: Yayy! New best EMA pseudo Dice: 0.4544999897480011 
2025-03-13 11:24:23.721954:  
2025-03-13 11:24:23.727997: Epoch 26 
2025-03-13 11:24:23.731522: Current learning rate: 0.00763 
2025-03-13 11:25:05.048932: train_loss -0.5187 
2025-03-13 11:25:05.056503: val_loss -0.4463 
2025-03-13 11:25:05.060012: Pseudo dice [np.float32(0.5109)] 
2025-03-13 11:25:05.064022: Epoch time: 41.33 s 
2025-03-13 11:25:05.067540: Yayy! New best EMA pseudo Dice: 0.460099995136261 
2025-03-13 11:25:05.743426:  
2025-03-13 11:25:05.750019: Epoch 27 
2025-03-13 11:25:05.754059: Current learning rate: 0.00753 
2025-03-13 11:25:47.080352: train_loss -0.5012 
2025-03-13 11:25:47.086377: val_loss -0.4662 
2025-03-13 11:25:47.089385: Pseudo dice [np.float32(0.5051)] 
2025-03-13 11:25:47.092902: Epoch time: 41.34 s 
2025-03-13 11:25:47.096406: Yayy! New best EMA pseudo Dice: 0.46459999680519104 
2025-03-13 11:25:47.769789:  
2025-03-13 11:25:47.775301: Epoch 28 
2025-03-13 11:25:47.778808: Current learning rate: 0.00744 
2025-03-13 11:26:29.110459: train_loss -0.4403 
2025-03-13 11:26:29.117028: val_loss -0.4183 
2025-03-13 11:26:29.122044: Pseudo dice [np.float32(0.526)] 
2025-03-13 11:26:29.125562: Epoch time: 41.34 s 
2025-03-13 11:26:29.129071: Yayy! New best EMA pseudo Dice: 0.4708000123500824 
2025-03-13 11:26:29.952130:  
2025-03-13 11:26:29.957653: Epoch 29 
2025-03-13 11:26:29.961215: Current learning rate: 0.00735 
2025-03-13 11:27:11.264325: train_loss -0.4889 
2025-03-13 11:27:11.271841: val_loss -0.4694 
2025-03-13 11:27:11.275851: Pseudo dice [np.float32(0.5358)] 
2025-03-13 11:27:11.279365: Epoch time: 41.31 s 
2025-03-13 11:27:11.281876: Yayy! New best EMA pseudo Dice: 0.4772999882698059 
2025-03-13 11:27:11.972528:  
2025-03-13 11:27:11.978602: Epoch 30 
2025-03-13 11:27:11.982116: Current learning rate: 0.00725 
2025-03-13 11:27:53.291812: train_loss -0.5261 
2025-03-13 11:27:53.297357: val_loss -0.3779 
2025-03-13 11:27:53.300865: Pseudo dice [np.float32(0.4725)] 
2025-03-13 11:27:53.304380: Epoch time: 41.32 s 
2025-03-13 11:27:53.828686:  
2025-03-13 11:27:53.833697: Epoch 31 
2025-03-13 11:27:53.837205: Current learning rate: 0.00716 
2025-03-13 11:28:35.149183: train_loss -0.5222 
2025-03-13 11:28:35.155210: val_loss -0.4733 
2025-03-13 11:28:35.159217: Pseudo dice [np.float32(0.5217)] 
2025-03-13 11:28:35.162726: Epoch time: 41.32 s 
2025-03-13 11:28:35.165240: Yayy! New best EMA pseudo Dice: 0.4812999963760376 
2025-03-13 11:28:35.841641:  
2025-03-13 11:28:35.847156: Epoch 32 
2025-03-13 11:28:35.850667: Current learning rate: 0.00707 
2025-03-13 11:29:17.158678: train_loss -0.5532 
2025-03-13 11:29:17.166304: val_loss -0.4524 
2025-03-13 11:29:17.169353: Pseudo dice [np.float32(0.5059)] 
2025-03-13 11:29:17.172888: Epoch time: 41.32 s 
2025-03-13 11:29:17.175917: Yayy! New best EMA pseudo Dice: 0.4837000072002411 
2025-03-13 11:29:17.851831:  
2025-03-13 11:29:17.857382: Epoch 33 
2025-03-13 11:29:17.860835: Current learning rate: 0.00697 
2025-03-13 11:29:59.182508: train_loss -0.5366 
2025-03-13 11:29:59.189111: val_loss -0.46 
2025-03-13 11:29:59.193132: Pseudo dice [np.float32(0.5571)] 
2025-03-13 11:29:59.195642: Epoch time: 41.33 s 
2025-03-13 11:29:59.199151: Yayy! New best EMA pseudo Dice: 0.491100013256073 
2025-03-13 11:29:59.879843:  
2025-03-13 11:29:59.885363: Epoch 34 
2025-03-13 11:29:59.888872: Current learning rate: 0.00688 
2025-03-13 11:30:41.197688: train_loss -0.5283 
2025-03-13 11:30:41.203225: val_loss -0.4735 
2025-03-13 11:30:41.206732: Pseudo dice [np.float32(0.557)] 
2025-03-13 11:30:41.210243: Epoch time: 41.32 s 
2025-03-13 11:30:41.214256: Yayy! New best EMA pseudo Dice: 0.4977000057697296 
2025-03-13 11:30:41.935438:  
2025-03-13 11:30:41.940452: Epoch 35 
2025-03-13 11:30:41.943963: Current learning rate: 0.00679 
2025-03-13 11:31:23.269776: train_loss -0.5046 
2025-03-13 11:31:23.275790: val_loss -0.4294 
2025-03-13 11:31:23.279799: Pseudo dice [np.float32(0.5069)] 
2025-03-13 11:31:23.283307: Epoch time: 41.34 s 
2025-03-13 11:31:23.287316: Yayy! New best EMA pseudo Dice: 0.4986000061035156 
2025-03-13 11:31:23.992590:  
2025-03-13 11:31:23.998613: Epoch 36 
2025-03-13 11:31:24.002124: Current learning rate: 0.00669 
2025-03-13 11:32:05.345767: train_loss -0.5194 
2025-03-13 11:32:05.352890: val_loss -0.4074 
2025-03-13 11:32:05.356483: Pseudo dice [np.float32(0.4342)] 
2025-03-13 11:32:05.360032: Epoch time: 41.35 s 
2025-03-13 11:32:06.036848:  
2025-03-13 11:32:06.041665: Epoch 37 
2025-03-13 11:32:06.045177: Current learning rate: 0.0066 
2025-03-13 11:32:47.362560: train_loss -0.5465 
2025-03-13 11:32:47.368092: val_loss -0.556 
2025-03-13 11:32:47.371404: Pseudo dice [np.float32(0.6141)] 
2025-03-13 11:32:47.374426: Epoch time: 41.33 s 
2025-03-13 11:32:47.378434: Yayy! New best EMA pseudo Dice: 0.5042999982833862 
2025-03-13 11:32:48.067568:  
2025-03-13 11:32:48.072596: Epoch 38 
2025-03-13 11:32:48.075449: Current learning rate: 0.0065 
2025-03-13 11:33:29.393955: train_loss -0.5711 
2025-03-13 11:33:29.399967: val_loss -0.4527 
2025-03-13 11:33:29.402978: Pseudo dice [np.float32(0.5327)] 
2025-03-13 11:33:29.406491: Epoch time: 41.33 s 
2025-03-13 11:33:29.410501: Yayy! New best EMA pseudo Dice: 0.5072000026702881 
2025-03-13 11:33:30.107987:  
2025-03-13 11:33:30.113502: Epoch 39 
2025-03-13 11:33:30.117014: Current learning rate: 0.00641 
2025-03-13 11:34:11.448889: train_loss -0.544 
2025-03-13 11:34:11.454675: val_loss -0.454 
2025-03-13 11:34:11.458184: Pseudo dice [np.float32(0.5219)] 
2025-03-13 11:34:11.460689: Epoch time: 41.34 s 
2025-03-13 11:34:11.464712: Yayy! New best EMA pseudo Dice: 0.5087000131607056 
2025-03-13 11:34:12.164506:  
2025-03-13 11:34:12.171067: Epoch 40 
2025-03-13 11:34:12.173608: Current learning rate: 0.00631 
2025-03-13 11:34:53.501118: train_loss -0.5495 
2025-03-13 11:34:53.507146: val_loss -0.411 
2025-03-13 11:34:53.509680: Pseudo dice [np.float32(0.5203)] 
2025-03-13 11:34:53.513710: Epoch time: 41.34 s 
2025-03-13 11:34:53.516217: Yayy! New best EMA pseudo Dice: 0.5098000168800354 
2025-03-13 11:34:54.217225:  
2025-03-13 11:34:54.222238: Epoch 41 
2025-03-13 11:34:54.225746: Current learning rate: 0.00622 
2025-03-13 11:35:35.553906: train_loss -0.5637 
2025-03-13 11:35:35.559945: val_loss -0.517 
2025-03-13 11:35:35.563062: Pseudo dice [np.float32(0.6299)] 
2025-03-13 11:35:35.567102: Epoch time: 41.34 s 
2025-03-13 11:35:35.570146: Yayy! New best EMA pseudo Dice: 0.5217999815940857 
2025-03-13 11:35:36.234481:  
2025-03-13 11:35:36.240535: Epoch 42 
2025-03-13 11:35:36.244051: Current learning rate: 0.00612 
2025-03-13 11:36:17.559226: train_loss -0.5681 
2025-03-13 11:36:17.566311: val_loss -0.5005 
2025-03-13 11:36:17.569842: Pseudo dice [np.float32(0.5974)] 
2025-03-13 11:36:17.573388: Epoch time: 41.32 s 
2025-03-13 11:36:17.576420: Yayy! New best EMA pseudo Dice: 0.5293999910354614 
2025-03-13 11:36:18.247211:  
2025-03-13 11:36:18.253282: Epoch 43 
2025-03-13 11:36:18.256328: Current learning rate: 0.00603 
2025-03-13 11:36:59.594014: train_loss -0.5967 
2025-03-13 11:36:59.600641: val_loss -0.4616 
2025-03-13 11:36:59.604328: Pseudo dice [np.float32(0.5285)] 
2025-03-13 11:36:59.607396: Epoch time: 41.35 s 
2025-03-13 11:37:00.179990:  
2025-03-13 11:37:00.186044: Epoch 44 
2025-03-13 11:37:00.188592: Current learning rate: 0.00593 
2025-03-13 11:37:41.509084: train_loss -0.5064 
2025-03-13 11:37:41.514666: val_loss -0.4946 
2025-03-13 11:37:41.518205: Pseudo dice [np.float32(0.5101)] 
2025-03-13 11:37:41.521268: Epoch time: 41.33 s 
2025-03-13 11:37:42.182508:  
2025-03-13 11:37:42.187521: Epoch 45 
2025-03-13 11:37:42.191030: Current learning rate: 0.00584 
2025-03-13 11:38:23.497900: train_loss -0.5502 
2025-03-13 11:38:23.504431: val_loss -0.5451 
2025-03-13 11:38:23.508442: Pseudo dice [np.float32(0.5717)] 
2025-03-13 11:38:23.510947: Epoch time: 41.32 s 
2025-03-13 11:38:23.514454: Yayy! New best EMA pseudo Dice: 0.5317999720573425 
2025-03-13 11:38:24.183120:  
2025-03-13 11:38:24.189085: Epoch 46 
2025-03-13 11:38:24.191592: Current learning rate: 0.00574 
2025-03-13 11:39:05.491526: train_loss -0.5759 
2025-03-13 11:39:05.498105: val_loss -0.5263 
2025-03-13 11:39:05.502216: Pseudo dice [np.float32(0.5769)] 
2025-03-13 11:39:05.505272: Epoch time: 41.31 s 
2025-03-13 11:39:05.509314: Yayy! New best EMA pseudo Dice: 0.536300003528595 
2025-03-13 11:39:06.186735:  
2025-03-13 11:39:06.192777: Epoch 47 
2025-03-13 11:39:06.195307: Current learning rate: 0.00565 
2025-03-13 11:39:47.501889: train_loss -0.5926 
2025-03-13 11:39:47.506959: val_loss -0.4724 
2025-03-13 11:39:47.510468: Pseudo dice [np.float32(0.5203)] 
2025-03-13 11:39:47.514481: Epoch time: 41.32 s 
2025-03-13 11:39:48.021533:  
2025-03-13 11:39:48.028134: Epoch 48 
2025-03-13 11:39:48.031173: Current learning rate: 0.00555 
2025-03-13 11:40:29.358163: train_loss -0.5678 
2025-03-13 11:40:29.364211: val_loss -0.5605 
2025-03-13 11:40:29.366717: Pseudo dice [np.float32(0.6026)] 
2025-03-13 11:40:29.370730: Epoch time: 41.34 s 
2025-03-13 11:40:29.374239: Yayy! New best EMA pseudo Dice: 0.5414999723434448 
2025-03-13 11:40:30.042207:  
2025-03-13 11:40:30.047754: Epoch 49 
2025-03-13 11:40:30.051286: Current learning rate: 0.00546 
2025-03-13 11:41:11.369767: train_loss -0.6009 
2025-03-13 11:41:11.376551: val_loss -0.4071 
2025-03-13 11:41:11.381129: Pseudo dice [np.float32(0.4343)] 
2025-03-13 11:41:11.383670: Epoch time: 41.33 s 
2025-03-13 11:41:12.037688:  
2025-03-13 11:41:12.043213: Epoch 50 
2025-03-13 11:41:12.046723: Current learning rate: 0.00536 
2025-03-13 11:41:53.378634: train_loss -0.5371 
2025-03-13 11:41:53.383720: val_loss -0.4783 
2025-03-13 11:41:53.387826: Pseudo dice [np.float32(0.5456)] 
2025-03-13 11:41:53.390924: Epoch time: 41.34 s 
2025-03-13 11:41:53.907584:  
2025-03-13 11:41:53.913638: Epoch 51 
2025-03-13 11:41:53.916777: Current learning rate: 0.00526 
2025-03-13 11:42:35.248822: train_loss -0.5861 
2025-03-13 11:42:35.254336: val_loss -0.4568 
2025-03-13 11:42:35.257844: Pseudo dice [np.float32(0.5145)] 
2025-03-13 11:42:35.261356: Epoch time: 41.34 s 
2025-03-13 11:42:35.786119:  
2025-03-13 11:42:35.791631: Epoch 52 
2025-03-13 11:42:35.795139: Current learning rate: 0.00517 
2025-03-13 11:43:17.121667: train_loss -0.5953 
2025-03-13 11:43:17.129317: val_loss -0.5522 
2025-03-13 11:43:17.131855: Pseudo dice [np.float32(0.6108)] 
2025-03-13 11:43:17.136922: Epoch time: 41.34 s 
2025-03-13 11:43:17.670424:  
2025-03-13 11:43:17.675945: Epoch 53 
2025-03-13 11:43:17.679462: Current learning rate: 0.00507 
2025-03-13 11:43:59.033870: train_loss -0.5925 
2025-03-13 11:43:59.038939: val_loss -0.5699 
2025-03-13 11:43:59.042701: Pseudo dice [np.float32(0.6192)] 
2025-03-13 11:43:59.047252: Epoch time: 41.36 s 
2025-03-13 11:43:59.050495: Yayy! New best EMA pseudo Dice: 0.5465999841690063 
2025-03-13 11:43:59.889578:  
2025-03-13 11:43:59.895616: Epoch 54 
2025-03-13 11:43:59.899623: Current learning rate: 0.00497 
2025-03-13 11:44:41.215444: train_loss -0.5686 
2025-03-13 11:44:41.221461: val_loss -0.4712 
2025-03-13 11:44:41.226472: Pseudo dice [np.float32(0.5613)] 
2025-03-13 11:44:41.230481: Epoch time: 41.33 s 
2025-03-13 11:44:41.233992: Yayy! New best EMA pseudo Dice: 0.5480999946594238 
2025-03-13 11:44:41.921219:  
2025-03-13 11:44:41.927810: Epoch 55 
2025-03-13 11:44:41.931397: Current learning rate: 0.00487 
2025-03-13 11:45:23.276962: train_loss -0.6056 
2025-03-13 11:45:23.284052: val_loss -0.4417 
2025-03-13 11:45:23.288563: Pseudo dice [np.float32(0.5512)] 
2025-03-13 11:45:23.291576: Epoch time: 41.36 s 
2025-03-13 11:45:23.295085: Yayy! New best EMA pseudo Dice: 0.5483999848365784 
2025-03-13 11:45:23.970128:  
2025-03-13 11:45:23.975690: Epoch 56 
2025-03-13 11:45:23.980764: Current learning rate: 0.00478 
2025-03-13 11:46:05.322230: train_loss -0.6082 
2025-03-13 11:46:05.330302: val_loss -0.4368 
2025-03-13 11:46:05.333811: Pseudo dice [np.float32(0.5394)] 
2025-03-13 11:46:05.337818: Epoch time: 41.35 s 
2025-03-13 11:46:05.867537:  
2025-03-13 11:46:05.873076: Epoch 57 
2025-03-13 11:46:05.876652: Current learning rate: 0.00468 
2025-03-13 11:46:47.197691: train_loss -0.5958 
2025-03-13 11:46:47.204271: val_loss -0.4642 
2025-03-13 11:46:47.207857: Pseudo dice [np.float32(0.5593)] 
2025-03-13 11:46:47.211480: Epoch time: 41.33 s 
2025-03-13 11:46:47.215108: Yayy! New best EMA pseudo Dice: 0.5486999750137329 
2025-03-13 11:46:47.897789:  
2025-03-13 11:46:47.903302: Epoch 58 
2025-03-13 11:46:47.906810: Current learning rate: 0.00458 
2025-03-13 11:47:29.235628: train_loss -0.6132 
2025-03-13 11:47:29.241714: val_loss -0.5086 
2025-03-13 11:47:29.245724: Pseudo dice [np.float32(0.5867)] 
2025-03-13 11:47:29.249235: Epoch time: 41.34 s 
2025-03-13 11:47:29.253242: Yayy! New best EMA pseudo Dice: 0.5525000095367432 
2025-03-13 11:47:29.950613:  
2025-03-13 11:47:29.957164: Epoch 59 
2025-03-13 11:47:29.959198: Current learning rate: 0.00448 
2025-03-13 11:48:11.269217: train_loss -0.5984 
2025-03-13 11:48:11.276767: val_loss -0.4232 
2025-03-13 11:48:11.285284: Pseudo dice [np.float32(0.5138)] 
2025-03-13 11:48:11.292800: Epoch time: 41.32 s 
2025-03-13 11:48:11.831474:  
2025-03-13 11:48:11.838015: Epoch 60 
2025-03-13 11:48:11.842025: Current learning rate: 0.00438 
2025-03-13 11:48:53.180988: train_loss -0.6035 
2025-03-13 11:48:53.187557: val_loss -0.5429 
2025-03-13 11:48:53.191127: Pseudo dice [np.float32(0.5751)] 
2025-03-13 11:48:53.195741: Epoch time: 41.35 s 
2025-03-13 11:48:53.715952:  
2025-03-13 11:48:53.721989: Epoch 61 
2025-03-13 11:48:53.726028: Current learning rate: 0.00429 
2025-03-13 11:49:35.059448: train_loss -0.6213 
2025-03-13 11:49:35.065994: val_loss -0.5258 
2025-03-13 11:49:35.070559: Pseudo dice [np.float32(0.582)] 
2025-03-13 11:49:35.074569: Epoch time: 41.34 s 
2025-03-13 11:49:35.078077: Yayy! New best EMA pseudo Dice: 0.5543000102043152 
2025-03-13 11:49:35.914300:  
2025-03-13 11:49:35.920890: Epoch 62 
2025-03-13 11:49:35.924979: Current learning rate: 0.00419 
2025-03-13 11:50:17.249052: train_loss -0.6005 
2025-03-13 11:50:17.255162: val_loss -0.5765 
2025-03-13 11:50:17.260375: Pseudo dice [np.float32(0.6273)] 
2025-03-13 11:50:17.262910: Epoch time: 41.33 s 
2025-03-13 11:50:17.267962: Yayy! New best EMA pseudo Dice: 0.5616000294685364 
2025-03-13 11:50:17.959550:  
2025-03-13 11:50:17.965106: Epoch 63 
2025-03-13 11:50:17.969712: Current learning rate: 0.00409 
2025-03-13 11:50:59.296994: train_loss -0.6425 
2025-03-13 11:50:59.305052: val_loss -0.4617 
2025-03-13 11:50:59.309060: Pseudo dice [np.float32(0.5035)] 
2025-03-13 11:50:59.312576: Epoch time: 41.34 s 
2025-03-13 11:50:59.842283:  
2025-03-13 11:50:59.848332: Epoch 64 
2025-03-13 11:50:59.851418: Current learning rate: 0.00399 
2025-03-13 11:51:41.166551: train_loss -0.582 
2025-03-13 11:51:41.172614: val_loss -0.5472 
2025-03-13 11:51:41.176649: Pseudo dice [np.float32(0.5757)] 
2025-03-13 11:51:41.180685: Epoch time: 41.33 s 
2025-03-13 11:51:41.767184:  
2025-03-13 11:51:41.774284: Epoch 65 
2025-03-13 11:51:41.777869: Current learning rate: 0.00389 
2025-03-13 11:52:23.086079: train_loss -0.6167 
2025-03-13 11:52:23.092677: val_loss -0.547 
2025-03-13 11:52:23.097289: Pseudo dice [np.float32(0.6407)] 
2025-03-13 11:52:23.101900: Epoch time: 41.32 s 
2025-03-13 11:52:23.105952: Yayy! New best EMA pseudo Dice: 0.566100001335144 
2025-03-13 11:52:23.830070:  
2025-03-13 11:52:23.837137: Epoch 66 
2025-03-13 11:52:23.842219: Current learning rate: 0.00379 
2025-03-13 11:53:05.292232: train_loss -0.5754 
2025-03-13 11:53:05.298750: val_loss -0.5805 
2025-03-13 11:53:05.303348: Pseudo dice [np.float32(0.6295)] 
2025-03-13 11:53:05.306428: Epoch time: 41.46 s 
2025-03-13 11:53:05.310941: Yayy! New best EMA pseudo Dice: 0.5723999738693237 
2025-03-13 11:53:06.031237:  
2025-03-13 11:53:06.037827: Epoch 67 
2025-03-13 11:53:06.041873: Current learning rate: 0.00369 
2025-03-13 11:53:47.446429: train_loss -0.6049 
2025-03-13 11:53:47.453010: val_loss -0.4835 
2025-03-13 11:53:47.457083: Pseudo dice [np.float32(0.5519)] 
2025-03-13 11:53:47.461123: Epoch time: 41.42 s 
2025-03-13 11:53:48.013591:  
2025-03-13 11:53:48.019605: Epoch 68 
2025-03-13 11:53:48.023620: Current learning rate: 0.00359 
2025-03-13 11:54:29.372393: train_loss -0.6081 
2025-03-13 11:54:29.378940: val_loss -0.4737 
2025-03-13 11:54:29.382454: Pseudo dice [np.float32(0.6361)] 
2025-03-13 11:54:29.386462: Epoch time: 41.36 s 
2025-03-13 11:54:29.390973: Yayy! New best EMA pseudo Dice: 0.5769000053405762 
2025-03-13 11:54:30.103845:  
2025-03-13 11:54:30.110367: Epoch 69 
2025-03-13 11:54:30.115381: Current learning rate: 0.00349 
2025-03-13 11:55:11.429320: train_loss -0.6305 
2025-03-13 11:55:11.436401: val_loss -0.5182 
2025-03-13 11:55:11.440928: Pseudo dice [np.float32(0.6141)] 
2025-03-13 11:55:11.444440: Epoch time: 41.33 s 
2025-03-13 11:55:11.447945: Yayy! New best EMA pseudo Dice: 0.5806999802589417 
2025-03-13 11:55:12.140996:  
2025-03-13 11:55:12.147508: Epoch 70 
2025-03-13 11:55:12.151016: Current learning rate: 0.00338 
2025-03-13 11:55:53.451576: train_loss -0.6191 
2025-03-13 11:55:53.457592: val_loss -0.5457 
2025-03-13 11:55:53.462604: Pseudo dice [np.float32(0.6417)] 
2025-03-13 11:55:53.466617: Epoch time: 41.31 s 
2025-03-13 11:55:53.470127: Yayy! New best EMA pseudo Dice: 0.5867999792098999 
2025-03-13 11:55:54.326047:  
2025-03-13 11:55:54.333092: Epoch 71 
2025-03-13 11:55:54.337094: Current learning rate: 0.00328 
2025-03-13 11:56:35.670135: train_loss -0.6298 
2025-03-13 11:56:35.676172: val_loss -0.5068 
2025-03-13 11:56:35.680280: Pseudo dice [np.float32(0.6549)] 
2025-03-13 11:56:35.683856: Epoch time: 41.34 s 
2025-03-13 11:56:35.687918: Yayy! New best EMA pseudo Dice: 0.5935999751091003 
2025-03-13 11:56:36.380521:  
2025-03-13 11:56:36.384601: Epoch 72 
2025-03-13 11:56:36.389173: Current learning rate: 0.00318 
2025-03-13 11:57:17.744822: train_loss -0.6525 
2025-03-13 11:57:17.752375: val_loss -0.4586 
2025-03-13 11:57:17.762396: Pseudo dice [np.float32(0.5359)] 
2025-03-13 11:57:17.765906: Epoch time: 41.36 s 
2025-03-13 11:57:18.310241:  
2025-03-13 11:57:18.316756: Epoch 73 
2025-03-13 11:57:18.320764: Current learning rate: 0.00308 
2025-03-13 11:57:59.675286: train_loss -0.6204 
2025-03-13 11:57:59.683809: val_loss -0.4648 
2025-03-13 11:57:59.687816: Pseudo dice [np.float32(0.5762)] 
2025-03-13 11:57:59.691327: Epoch time: 41.37 s 
2025-03-13 11:58:00.237283:  
2025-03-13 11:58:00.243343: Epoch 74 
2025-03-13 11:58:00.246864: Current learning rate: 0.00297 
2025-03-13 11:58:41.580777: train_loss -0.6283 
2025-03-13 11:58:41.587831: val_loss -0.5196 
2025-03-13 11:58:41.590843: Pseudo dice [np.float32(0.5569)] 
2025-03-13 11:58:41.594355: Epoch time: 41.34 s 
2025-03-13 11:58:42.137269:  
2025-03-13 11:58:42.142644: Epoch 75 
2025-03-13 11:58:42.146168: Current learning rate: 0.00287 
2025-03-13 11:59:23.459443: train_loss -0.6277 
2025-03-13 11:59:23.466537: val_loss -0.5402 
2025-03-13 11:59:23.470549: Pseudo dice [np.float32(0.6153)] 
2025-03-13 11:59:23.475062: Epoch time: 41.32 s 
2025-03-13 11:59:24.009204:  
2025-03-13 11:59:24.016323: Epoch 76 
2025-03-13 11:59:24.020351: Current learning rate: 0.00277 
2025-03-13 12:00:05.355180: train_loss -0.6306 
2025-03-13 12:00:05.361866: val_loss -0.5036 
2025-03-13 12:00:05.365380: Pseudo dice [np.float32(0.6288)] 
2025-03-13 12:00:05.368903: Epoch time: 41.35 s 
2025-03-13 12:00:05.910495:  
2025-03-13 12:00:05.917011: Epoch 77 
2025-03-13 12:00:05.921026: Current learning rate: 0.00266 
2025-03-13 12:00:47.249596: train_loss -0.6337 
2025-03-13 12:00:47.256638: val_loss -0.4677 
2025-03-13 12:00:47.260714: Pseudo dice [np.float32(0.571)] 
2025-03-13 12:00:47.264737: Epoch time: 41.34 s 
2025-03-13 12:00:47.956373:  
2025-03-13 12:00:47.961980: Epoch 78 
2025-03-13 12:00:47.966795: Current learning rate: 0.00256 
2025-03-13 12:01:29.304799: train_loss -0.6399 
2025-03-13 12:01:29.310814: val_loss -0.4994 
2025-03-13 12:01:29.314822: Pseudo dice [np.float32(0.6029)] 
2025-03-13 12:01:29.318330: Epoch time: 41.35 s 
2025-03-13 12:01:29.862465:  
2025-03-13 12:01:29.868478: Epoch 79 
2025-03-13 12:01:29.872499: Current learning rate: 0.00245 
2025-03-13 12:02:11.199195: train_loss -0.6698 
2025-03-13 12:02:11.207279: val_loss -0.5454 
2025-03-13 12:02:11.211807: Pseudo dice [np.float32(0.6425)] 
2025-03-13 12:02:11.215324: Epoch time: 41.34 s 
2025-03-13 12:02:11.219328: Yayy! New best EMA pseudo Dice: 0.5956000089645386 
2025-03-13 12:02:11.935951:  
2025-03-13 12:02:11.941467: Epoch 80 
2025-03-13 12:02:11.945994: Current learning rate: 0.00235 
2025-03-13 12:02:53.267359: train_loss -0.6431 
2025-03-13 12:02:53.274995: val_loss -0.475 
2025-03-13 12:02:53.279108: Pseudo dice [np.float32(0.5925)] 
2025-03-13 12:02:53.282676: Epoch time: 41.33 s 
2025-03-13 12:02:53.833115:  
2025-03-13 12:02:53.839700: Epoch 81 
2025-03-13 12:02:53.843236: Current learning rate: 0.00224 
2025-03-13 12:03:35.185357: train_loss -0.6414 
2025-03-13 12:03:35.191480: val_loss -0.6151 
2025-03-13 12:03:35.208120: Pseudo dice [np.float32(0.7202)] 
2025-03-13 12:03:35.212711: Epoch time: 41.35 s 
2025-03-13 12:03:35.228958: Yayy! New best EMA pseudo Dice: 0.6078000068664551 
2025-03-13 12:03:35.947241:  
2025-03-13 12:03:35.953882: Epoch 82 
2025-03-13 12:03:35.958420: Current learning rate: 0.00214 
2025-03-13 12:04:17.289298: train_loss -0.6385 
2025-03-13 12:04:17.295313: val_loss -0.4678 
2025-03-13 12:04:17.312851: Pseudo dice [np.float32(0.5437)] 
2025-03-13 12:04:17.316859: Epoch time: 41.34 s 
2025-03-13 12:04:17.836860:  
2025-03-13 12:04:17.843437: Epoch 83 
2025-03-13 12:04:17.860553: Current learning rate: 0.00203 
2025-03-13 12:04:59.190636: train_loss -0.649 
2025-03-13 12:04:59.196648: val_loss -0.5856 
2025-03-13 12:04:59.200656: Pseudo dice [np.float32(0.6305)] 
2025-03-13 12:04:59.205164: Epoch time: 41.35 s 
2025-03-13 12:04:59.734207:  
2025-03-13 12:04:59.740721: Epoch 84 
2025-03-13 12:04:59.744227: Current learning rate: 0.00192 
2025-03-13 12:05:41.053674: train_loss -0.6248 
2025-03-13 12:05:41.059762: val_loss -0.5307 
2025-03-13 12:05:41.062356: Pseudo dice [np.float32(0.6752)] 
2025-03-13 12:05:41.065881: Epoch time: 41.32 s 
2025-03-13 12:05:41.070437: Yayy! New best EMA pseudo Dice: 0.6114000082015991 
2025-03-13 12:05:41.749577:  
2025-03-13 12:05:41.756228: Epoch 85 
2025-03-13 12:05:41.759786: Current learning rate: 0.00181 
2025-03-13 12:06:23.088113: train_loss -0.6511 
2025-03-13 12:06:23.096142: val_loss -0.5165 
2025-03-13 12:06:23.099650: Pseudo dice [np.float32(0.6581)] 
2025-03-13 12:06:23.103657: Epoch time: 41.34 s 
2025-03-13 12:06:23.108165: Yayy! New best EMA pseudo Dice: 0.616100013256073 
2025-03-13 12:06:23.920639:  
2025-03-13 12:06:23.927201: Epoch 86 
2025-03-13 12:06:23.931207: Current learning rate: 0.0017 
2025-03-13 12:07:05.255917: train_loss -0.6489 
2025-03-13 12:07:05.263433: val_loss -0.5777 
2025-03-13 12:07:05.266941: Pseudo dice [np.float32(0.6858)] 
2025-03-13 12:07:05.270948: Epoch time: 41.34 s 
2025-03-13 12:07:05.275458: Yayy! New best EMA pseudo Dice: 0.6230000257492065 
2025-03-13 12:07:05.946590:  
2025-03-13 12:07:05.953105: Epoch 87 
2025-03-13 12:07:05.958116: Current learning rate: 0.00159 
2025-03-13 12:07:47.283106: train_loss -0.6586 
2025-03-13 12:07:47.289143: val_loss -0.5961 
2025-03-13 12:07:47.293180: Pseudo dice [np.float32(0.655)] 
2025-03-13 12:07:47.296702: Epoch time: 41.34 s 
2025-03-13 12:07:47.300736: Yayy! New best EMA pseudo Dice: 0.6262000203132629 
2025-03-13 12:07:47.982691:  
2025-03-13 12:07:47.989229: Epoch 88 
2025-03-13 12:07:47.993758: Current learning rate: 0.00148 
2025-03-13 12:08:29.319069: train_loss -0.6657 
2025-03-13 12:08:29.325585: val_loss -0.5035 
2025-03-13 12:08:29.330095: Pseudo dice [np.float32(0.6107)] 
2025-03-13 12:08:29.334107: Epoch time: 41.34 s 
2025-03-13 12:08:29.849770:  
2025-03-13 12:08:29.855797: Epoch 89 
2025-03-13 12:08:29.860811: Current learning rate: 0.00137 
2025-03-13 12:09:11.175074: train_loss -0.6619 
2025-03-13 12:09:11.183206: val_loss -0.5418 
2025-03-13 12:09:11.187237: Pseudo dice [np.float32(0.6692)] 
2025-03-13 12:09:11.191269: Epoch time: 41.33 s 
2025-03-13 12:09:11.195802: Yayy! New best EMA pseudo Dice: 0.6291000247001648 
2025-03-13 12:09:11.862778:  
2025-03-13 12:09:11.869355: Epoch 90 
2025-03-13 12:09:11.872957: Current learning rate: 0.00126 
2025-03-13 12:09:53.178763: train_loss -0.6657 
2025-03-13 12:09:53.186303: val_loss -0.5101 
2025-03-13 12:09:53.190963: Pseudo dice [np.float32(0.6194)] 
2025-03-13 12:09:53.195211: Epoch time: 41.32 s 
2025-03-13 12:09:53.707273:  
2025-03-13 12:09:53.712852: Epoch 91 
2025-03-13 12:09:53.717971: Current learning rate: 0.00115 
2025-03-13 12:10:35.062879: train_loss -0.6746 
2025-03-13 12:10:35.069508: val_loss -0.5417 
2025-03-13 12:10:35.073055: Pseudo dice [np.float32(0.6983)] 
2025-03-13 12:10:35.077648: Epoch time: 41.36 s 
2025-03-13 12:10:35.081187: Yayy! New best EMA pseudo Dice: 0.635200023651123 
2025-03-13 12:10:35.748767:  
2025-03-13 12:10:35.755308: Epoch 92 
2025-03-13 12:10:35.759321: Current learning rate: 0.00103 
2025-03-13 12:11:17.075517: train_loss -0.6594 
2025-03-13 12:11:17.084034: val_loss -0.5594 
2025-03-13 12:11:17.088048: Pseudo dice [np.float32(0.6686)] 
2025-03-13 12:11:17.093065: Epoch time: 41.33 s 
2025-03-13 12:11:17.096570: Yayy! New best EMA pseudo Dice: 0.6384999752044678 
2025-03-13 12:11:17.782705:  
2025-03-13 12:11:17.790226: Epoch 93 
2025-03-13 12:11:17.794232: Current learning rate: 0.00091 
2025-03-13 12:11:59.131866: train_loss -0.6535 
2025-03-13 12:11:59.137879: val_loss -0.5525 
2025-03-13 12:11:59.142892: Pseudo dice [np.float32(0.6295)] 
2025-03-13 12:11:59.146906: Epoch time: 41.35 s 
2025-03-13 12:11:59.798712:  
2025-03-13 12:11:59.805355: Epoch 94 
2025-03-13 12:11:59.809469: Current learning rate: 0.00079 
2025-03-13 12:12:41.134058: train_loss -0.6756 
2025-03-13 12:12:41.141120: val_loss -0.51 
2025-03-13 12:12:41.145137: Pseudo dice [np.float32(0.6165)] 
2025-03-13 12:12:41.148648: Epoch time: 41.34 s 
2025-03-13 12:12:41.663362:  
2025-03-13 12:12:41.670410: Epoch 95 
2025-03-13 12:12:41.674427: Current learning rate: 0.00067 
2025-03-13 12:13:22.984237: train_loss -0.6873 
2025-03-13 12:13:22.992769: val_loss -0.5864 
2025-03-13 12:13:22.996283: Pseudo dice [np.float32(0.6781)] 
2025-03-13 12:13:22.999476: Epoch time: 41.32 s 
2025-03-13 12:13:23.004486: Yayy! New best EMA pseudo Dice: 0.6398000121116638 
2025-03-13 12:13:23.675691:  
2025-03-13 12:13:23.682739: Epoch 96 
2025-03-13 12:13:23.686750: Current learning rate: 0.00055 
2025-03-13 12:14:04.996355: train_loss -0.695 
2025-03-13 12:14:05.005391: val_loss -0.5496 
2025-03-13 12:14:05.012168: Pseudo dice [np.float32(0.6926)] 
2025-03-13 12:14:05.015678: Epoch time: 41.32 s 
2025-03-13 12:14:05.019690: Yayy! New best EMA pseudo Dice: 0.6450999975204468 
2025-03-13 12:14:05.697823:  
2025-03-13 12:14:05.704376: Epoch 97 
2025-03-13 12:14:05.709474: Current learning rate: 0.00043 
2025-03-13 12:14:47.021809: train_loss -0.6664 
2025-03-13 12:14:47.027936: val_loss -0.5257 
2025-03-13 12:14:47.032473: Pseudo dice [np.float32(0.6279)] 
2025-03-13 12:14:47.037025: Epoch time: 41.32 s 
2025-03-13 12:14:47.560693:  
2025-03-13 12:14:47.567238: Epoch 98 
2025-03-13 12:14:47.571750: Current learning rate: 0.0003 
2025-03-13 12:15:28.898565: train_loss -0.678 
2025-03-13 12:15:28.905088: val_loss -0.5475 
2025-03-13 12:15:28.910101: Pseudo dice [np.float32(0.6512)] 
2025-03-13 12:15:28.913620: Epoch time: 41.34 s 
2025-03-13 12:15:29.436357:  
2025-03-13 12:15:29.443415: Epoch 99 
2025-03-13 12:15:29.449953: Current learning rate: 0.00016 
2025-03-13 12:16:10.784162: train_loss -0.6811 
2025-03-13 12:16:10.792846: val_loss -0.5957 
2025-03-13 12:16:10.796899: Pseudo dice [np.float32(0.6975)] 
2025-03-13 12:16:10.801552: Epoch time: 41.35 s 
2025-03-13 12:16:10.805596: Yayy! New best EMA pseudo Dice: 0.6495000123977661 
2025-03-13 12:16:11.700368: Training done. 
2025-03-13 12:16:11.727371: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-13 12:16:11.733369: The split file contains 5 splits. 
2025-03-13 12:16:11.738369: Desired fold for training: 0 
2025-03-13 12:16:11.743372: This split has 100 training and 26 validation cases. 
2025-03-13 12:16:11.748369: predicting colon_008 
2025-03-13 12:16:11.754369: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-03-13 12:16:27.491493: predicting colon_027 
2025-03-13 12:16:27.515493: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-03-13 12:16:33.561656: predicting colon_030 
2025-03-13 12:16:33.574656: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-03-13 12:16:42.058895: predicting colon_033 
2025-03-13 12:16:42.077895: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-03-13 12:16:57.122247: predicting colon_041 
2025-03-13 12:16:57.141247: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-03-13 12:17:37.651781: predicting colon_042 
2025-03-13 12:17:37.686781: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-03-13 12:17:57.978888: predicting colon_061 
2025-03-13 12:17:57.999888: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-03-13 12:18:21.469189: predicting colon_074 
2025-03-13 12:18:21.492189: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-03-13 12:18:48.537984: predicting colon_075 
2025-03-13 12:18:48.562984: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-03-13 12:19:03.613607: predicting colon_088 
2025-03-13 12:19:03.634606: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-03-13 12:19:27.121114: predicting colon_091 
2025-03-13 12:19:27.148113: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-03-13 12:19:55.310354: predicting colon_092 
2025-03-13 12:19:55.344353: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-03-13 12:20:18.824264: predicting colon_095 
2025-03-13 12:20:18.845264: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-03-13 12:20:33.891706: predicting colon_102 
2025-03-13 12:20:33.912705: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-03-13 12:21:07.699827: predicting colon_111 
2025-03-13 12:21:07.727828: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-03-13 12:21:17.184466: predicting colon_115 
2025-03-13 12:21:17.204466: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-03-13 12:21:32.257906: predicting colon_118 
2025-03-13 12:21:32.281905: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-03-13 12:21:55.768562: predicting colon_124 
2025-03-13 12:21:55.796563: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-03-13 12:22:19.292602: predicting colon_127 
2025-03-13 12:22:19.316602: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-03-13 12:23:06.634534: predicting colon_154 
2025-03-13 12:23:06.679534: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-03-13 12:23:21.751050: predicting colon_161 
2025-03-13 12:23:21.770050: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-03-13 12:23:36.829114: predicting colon_162 
2025-03-13 12:23:36.858115: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-03-13 12:24:17.326568: predicting colon_165 
2025-03-13 12:24:17.356569: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-03-13 12:24:51.136498: predicting colon_166 
2025-03-13 12:24:51.171499: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-03-13 12:25:06.229418: predicting colon_169 
2025-03-13 12:25:06.252417: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-03-13 12:25:53.576774: predicting colon_187 
2025-03-13 12:25:53.611775: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-03-13 12:26:26.101894: Validation complete 
2025-03-13 12:26:26.108714: Mean Validation Dice:  0.27587809261387347 
