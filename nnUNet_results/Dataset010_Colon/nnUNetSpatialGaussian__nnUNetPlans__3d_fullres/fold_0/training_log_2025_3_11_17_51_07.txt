
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-11 17:51:07.228860: do_dummy_2d_data_aug: True 
2025-03-11 17:51:07.235125: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-11 17:51:07.243554: The split file contains 5 splits. 
2025-03-11 17:51:07.246587: Desired fold for training: 0 
2025-03-11 17:51:07.248312: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-03-11 17:51:16.757732: unpacking dataset... 
2025-03-11 17:51:29.428403: unpacking done... 
2025-03-11 17:51:33.890850:  
2025-03-11 17:51:33.896134: Epoch 0 
2025-03-11 17:51:33.899756: Current learning rate: 0.01 
2025-03-11 17:52:21.974540: train_loss 0.0343 
2025-03-11 17:52:21.981179: val_loss -0.0323 
2025-03-11 17:52:21.984729: Pseudo dice [np.float32(0.0)] 
2025-03-11 17:52:21.987765: Epoch time: 48.08 s 
2025-03-11 17:52:21.991359: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-11 17:52:22.670753:  
2025-03-11 17:52:22.676407: Epoch 1 
2025-03-11 17:52:22.679537: Current learning rate: 0.00991 
2025-03-11 17:53:05.780271: train_loss -0.1226 
2025-03-11 17:53:05.786876: val_loss -0.1477 
2025-03-11 17:53:05.789919: Pseudo dice [np.float32(0.1778)] 
2025-03-11 17:53:05.793971: Epoch time: 43.11 s 
2025-03-11 17:53:05.797027: Yayy! New best EMA pseudo Dice: 0.017799999564886093 
2025-03-11 17:53:06.536978:  
2025-03-11 17:53:06.543186: Epoch 2 
2025-03-11 17:53:06.545783: Current learning rate: 0.00982 
2025-03-11 17:53:49.614815: train_loss -0.3069 
2025-03-11 17:53:49.621198: val_loss -0.3479 
2025-03-11 17:53:49.624812: Pseudo dice [np.float32(0.4712)] 
2025-03-11 17:53:49.628440: Epoch time: 43.08 s 
2025-03-11 17:53:49.631545: Yayy! New best EMA pseudo Dice: 0.06310000270605087 
2025-03-11 17:53:50.412890:  
2025-03-11 17:53:50.418476: Epoch 3 
2025-03-11 17:53:50.422697: Current learning rate: 0.00973 
2025-03-11 17:54:33.503707: train_loss -0.3356 
2025-03-11 17:54:33.510008: val_loss -0.4062 
2025-03-11 17:54:33.513128: Pseudo dice [np.float32(0.5244)] 
2025-03-11 17:54:33.516755: Epoch time: 43.09 s 
2025-03-11 17:54:33.519868: Yayy! New best EMA pseudo Dice: 0.10930000245571136 
2025-03-11 17:54:34.279193:  
2025-03-11 17:54:34.285487: Epoch 4 
2025-03-11 17:54:34.289100: Current learning rate: 0.00964 
2025-03-11 17:55:17.388938: train_loss -0.4118 
2025-03-11 17:55:17.394869: val_loss -0.3454 
2025-03-11 17:55:17.398913: Pseudo dice [np.float32(0.4482)] 
2025-03-11 17:55:17.401973: Epoch time: 43.11 s 
2025-03-11 17:55:17.405666: Yayy! New best EMA pseudo Dice: 0.14319999516010284 
2025-03-11 17:55:18.308931:  
2025-03-11 17:55:18.315514: Epoch 5 
2025-03-11 17:55:18.318569: Current learning rate: 0.00955 
2025-03-11 17:56:01.388529: train_loss -0.4121 
2025-03-11 17:56:01.394095: val_loss -0.4197 
2025-03-11 17:56:01.398123: Pseudo dice [np.float32(0.4718)] 
2025-03-11 17:56:01.401655: Epoch time: 43.08 s 
2025-03-11 17:56:01.405178: Yayy! New best EMA pseudo Dice: 0.17599999904632568 
2025-03-11 17:56:02.140611:  
2025-03-11 17:56:02.145769: Epoch 6 
2025-03-11 17:56:02.149003: Current learning rate: 0.00946 
2025-03-11 17:56:45.221725: train_loss -0.4861 
2025-03-11 17:56:45.228181: val_loss -0.4768 
2025-03-11 17:56:45.231938: Pseudo dice [np.float32(0.5358)] 
2025-03-11 17:56:45.235035: Epoch time: 43.08 s 
2025-03-11 17:56:45.238137: Yayy! New best EMA pseudo Dice: 0.21199999749660492 
2025-03-11 17:56:46.009954:  
2025-03-11 17:56:46.015643: Epoch 7 
2025-03-11 17:56:46.019398: Current learning rate: 0.00937 
2025-03-11 17:57:29.118046: train_loss -0.4377 
2025-03-11 17:57:29.123207: val_loss -0.4033 
2025-03-11 17:57:29.127013: Pseudo dice [np.float32(0.5005)] 
2025-03-11 17:57:29.130080: Epoch time: 43.11 s 
2025-03-11 17:57:29.135369: Yayy! New best EMA pseudo Dice: 0.24079999327659607 
2025-03-11 17:57:29.924709:  
2025-03-11 17:57:29.930976: Epoch 8 
2025-03-11 17:57:29.934028: Current learning rate: 0.00928 
2025-03-11 17:58:13.025784: train_loss -0.4015 
2025-03-11 17:58:13.032323: val_loss -0.3425 
2025-03-11 17:58:13.035854: Pseudo dice [np.float32(0.4132)] 
2025-03-11 17:58:13.039879: Epoch time: 43.1 s 
2025-03-11 17:58:13.043408: Yayy! New best EMA pseudo Dice: 0.2581000030040741 
2025-03-11 17:58:13.874858:  
2025-03-11 17:58:13.881488: Epoch 9 
2025-03-11 17:58:13.884517: Current learning rate: 0.00919 
2025-03-11 17:58:56.966738: train_loss -0.4386 
2025-03-11 17:58:56.973902: val_loss -0.4124 
2025-03-11 17:58:56.977552: Pseudo dice [np.float32(0.5023)] 
2025-03-11 17:58:56.981183: Epoch time: 43.09 s 
2025-03-11 17:58:56.984309: Yayy! New best EMA pseudo Dice: 0.2824999988079071 
2025-03-11 17:58:57.747328:  
2025-03-11 17:58:57.753483: Epoch 10 
2025-03-11 17:58:57.757116: Current learning rate: 0.0091 
2025-03-11 17:59:40.859811: train_loss -0.5003 
2025-03-11 17:59:40.866509: val_loss -0.4564 
2025-03-11 17:59:40.869622: Pseudo dice [np.float32(0.5217)] 
2025-03-11 17:59:40.873297: Epoch time: 43.11 s 
2025-03-11 17:59:40.877215: Yayy! New best EMA pseudo Dice: 0.30640000104904175 
2025-03-11 17:59:41.659589:  
2025-03-11 17:59:41.665350: Epoch 11 
2025-03-11 17:59:41.668980: Current learning rate: 0.009 
2025-03-11 18:00:24.766683: train_loss -0.4454 
2025-03-11 18:00:24.773741: val_loss -0.4897 
2025-03-11 18:00:24.776813: Pseudo dice [np.float32(0.5624)] 
2025-03-11 18:00:24.780344: Epoch time: 43.11 s 
2025-03-11 18:00:24.784386: Yayy! New best EMA pseudo Dice: 0.3319999873638153 
2025-03-11 18:00:25.502981:  
2025-03-11 18:00:25.508610: Epoch 12 
2025-03-11 18:00:25.512162: Current learning rate: 0.00891 
2025-03-11 18:01:08.595217: train_loss -0.4888 
2025-03-11 18:01:08.601962: val_loss -0.4514 
2025-03-11 18:01:08.605636: Pseudo dice [np.float32(0.5495)] 
2025-03-11 18:01:08.609155: Epoch time: 43.09 s 
2025-03-11 18:01:08.612405: Yayy! New best EMA pseudo Dice: 0.3537999987602234 
2025-03-11 18:01:09.556322:  
2025-03-11 18:01:09.561850: Epoch 13 
2025-03-11 18:01:09.566145: Current learning rate: 0.00882 
2025-03-11 18:01:52.623296: train_loss -0.5066 
2025-03-11 18:01:52.629409: val_loss -0.4731 
2025-03-11 18:01:52.633457: Pseudo dice [np.float32(0.5256)] 
2025-03-11 18:01:52.636508: Epoch time: 43.07 s 
2025-03-11 18:01:52.640130: Yayy! New best EMA pseudo Dice: 0.3709000051021576 
2025-03-11 18:01:53.386992:  
2025-03-11 18:01:53.393037: Epoch 14 
2025-03-11 18:01:53.396578: Current learning rate: 0.00873 
2025-03-11 18:02:36.452629: train_loss -0.5268 
2025-03-11 18:02:36.458990: val_loss -0.4725 
2025-03-11 18:02:36.462099: Pseudo dice [np.float32(0.5302)] 
2025-03-11 18:02:36.465734: Epoch time: 43.07 s 
2025-03-11 18:02:36.468835: Yayy! New best EMA pseudo Dice: 0.38690000772476196 
2025-03-11 18:02:37.221915:  
2025-03-11 18:02:37.227597: Epoch 15 
2025-03-11 18:02:37.231710: Current learning rate: 0.00864 
2025-03-11 18:03:20.302227: train_loss -0.5196 
2025-03-11 18:03:20.309028: val_loss -0.5344 
2025-03-11 18:03:20.312663: Pseudo dice [np.float32(0.5876)] 
2025-03-11 18:03:20.316298: Epoch time: 43.08 s 
2025-03-11 18:03:20.319941: Yayy! New best EMA pseudo Dice: 0.40689998865127563 
2025-03-11 18:03:21.123247:  
2025-03-11 18:03:21.129477: Epoch 16 
2025-03-11 18:03:21.133100: Current learning rate: 0.00855 
2025-03-11 18:04:04.206162: train_loss -0.5544 
2025-03-11 18:04:04.212921: val_loss -0.4479 
2025-03-11 18:04:04.216664: Pseudo dice [np.float32(0.5759)] 
2025-03-11 18:04:04.219785: Epoch time: 43.08 s 
2025-03-11 18:04:04.223639: Yayy! New best EMA pseudo Dice: 0.423799991607666 
2025-03-11 18:04:04.978414:  
2025-03-11 18:04:04.984683: Epoch 17 
2025-03-11 18:04:04.988308: Current learning rate: 0.00846 
2025-03-11 18:04:48.059858: train_loss -0.5705 
2025-03-11 18:04:48.068113: val_loss -0.4792 
2025-03-11 18:04:48.074219: Pseudo dice [np.float32(0.5733)] 
2025-03-11 18:04:48.077813: Epoch time: 43.08 s 
2025-03-11 18:04:48.080926: Yayy! New best EMA pseudo Dice: 0.43880000710487366 
2025-03-11 18:04:48.851572:  
2025-03-11 18:04:48.857770: Epoch 18 
2025-03-11 18:04:48.861414: Current learning rate: 0.00836 
2025-03-11 18:05:31.907820: train_loss -0.5089 
2025-03-11 18:05:31.914553: val_loss -0.462 
2025-03-11 18:05:31.918148: Pseudo dice [np.float32(0.5253)] 
2025-03-11 18:05:31.921712: Epoch time: 43.06 s 
2025-03-11 18:05:31.925272: Yayy! New best EMA pseudo Dice: 0.4474000036716461 
2025-03-11 18:05:32.700167:  
2025-03-11 18:05:32.706346: Epoch 19 
2025-03-11 18:05:32.710031: Current learning rate: 0.00827 
2025-03-11 18:06:15.773870: train_loss -0.582 
2025-03-11 18:06:15.780454: val_loss -0.4535 
2025-03-11 18:06:15.784488: Pseudo dice [np.float32(0.5404)] 
2025-03-11 18:06:15.788041: Epoch time: 43.07 s 
2025-03-11 18:06:15.791572: Yayy! New best EMA pseudo Dice: 0.45669999718666077 
2025-03-11 18:06:16.620557:  
2025-03-11 18:06:16.626341: Epoch 20 
2025-03-11 18:06:16.630412: Current learning rate: 0.00818 
2025-03-11 18:06:59.709304: train_loss -0.554 
2025-03-11 18:06:59.715757: val_loss -0.5083 
2025-03-11 18:06:59.719910: Pseudo dice [np.float32(0.582)] 
2025-03-11 18:06:59.723031: Epoch time: 43.09 s 
2025-03-11 18:06:59.726705: Yayy! New best EMA pseudo Dice: 0.4693000018596649 
2025-03-11 18:07:00.686958:  
2025-03-11 18:07:00.693246: Epoch 21 
2025-03-11 18:07:00.696969: Current learning rate: 0.00809 
2025-03-11 18:07:43.743939: train_loss -0.5662 
2025-03-11 18:07:43.750242: val_loss -0.4293 
2025-03-11 18:07:43.753984: Pseudo dice [np.float32(0.5373)] 
2025-03-11 18:07:43.757915: Epoch time: 43.06 s 
2025-03-11 18:07:43.761030: Yayy! New best EMA pseudo Dice: 0.47609999775886536 
2025-03-11 18:07:44.498358:  
2025-03-11 18:07:44.504541: Epoch 22 
2025-03-11 18:07:44.508713: Current learning rate: 0.008 
2025-03-11 18:08:27.564165: train_loss -0.5571 
2025-03-11 18:08:27.570749: val_loss -0.5221 
2025-03-11 18:08:27.574322: Pseudo dice [np.float32(0.6209)] 
2025-03-11 18:08:27.578461: Epoch time: 43.07 s 
2025-03-11 18:08:27.581527: Yayy! New best EMA pseudo Dice: 0.49050000309944153 
2025-03-11 18:08:28.304036:  
2025-03-11 18:08:28.310130: Epoch 23 
2025-03-11 18:08:28.314157: Current learning rate: 0.0079 
2025-03-11 18:09:11.362101: train_loss -0.5959 
2025-03-11 18:09:11.368829: val_loss -0.4237 
2025-03-11 18:09:11.372962: Pseudo dice [np.float32(0.551)] 
2025-03-11 18:09:11.376673: Epoch time: 43.06 s 
2025-03-11 18:09:11.380311: Yayy! New best EMA pseudo Dice: 0.4966000020503998 
2025-03-11 18:09:12.095060:  
2025-03-11 18:09:12.101280: Epoch 24 
2025-03-11 18:09:12.104907: Current learning rate: 0.00781 
2025-03-11 18:09:55.165653: train_loss -0.589 
2025-03-11 18:09:55.173997: val_loss -0.505 
2025-03-11 18:09:55.177570: Pseudo dice [np.float32(0.5736)] 
2025-03-11 18:09:55.181218: Epoch time: 43.07 s 
2025-03-11 18:09:55.184271: Yayy! New best EMA pseudo Dice: 0.5042999982833862 
2025-03-11 18:09:55.907835:  
2025-03-11 18:09:55.913900: Epoch 25 
2025-03-11 18:09:55.917814: Current learning rate: 0.00772 
2025-03-11 18:10:38.948972: train_loss -0.577 
2025-03-11 18:10:38.955170: val_loss -0.4961 
2025-03-11 18:10:38.959431: Pseudo dice [np.float32(0.5378)] 
2025-03-11 18:10:38.962986: Epoch time: 43.04 s 
2025-03-11 18:10:38.966259: Yayy! New best EMA pseudo Dice: 0.5076000094413757 
2025-03-11 18:10:39.700053:  
2025-03-11 18:10:39.707262: Epoch 26 
2025-03-11 18:10:39.710823: Current learning rate: 0.00763 
2025-03-11 18:11:22.773215: train_loss -0.5829 
2025-03-11 18:11:22.779453: val_loss -0.4728 
2025-03-11 18:11:22.782999: Pseudo dice [np.float32(0.5508)] 
2025-03-11 18:11:22.786032: Epoch time: 43.07 s 
2025-03-11 18:11:22.790058: Yayy! New best EMA pseudo Dice: 0.5120000243186951 
2025-03-11 18:11:23.561743:  
2025-03-11 18:11:23.568245: Epoch 27 
2025-03-11 18:11:23.570862: Current learning rate: 0.00753 
2025-03-11 18:12:06.608328: train_loss -0.5491 
2025-03-11 18:12:06.613967: val_loss -0.4591 
2025-03-11 18:12:06.618620: Pseudo dice [np.float32(0.5777)] 
2025-03-11 18:12:06.622300: Epoch time: 43.05 s 
2025-03-11 18:12:06.625938: Yayy! New best EMA pseudo Dice: 0.5184999704360962 
2025-03-11 18:12:07.346589:  
2025-03-11 18:12:07.352837: Epoch 28 
2025-03-11 18:12:07.356979: Current learning rate: 0.00744 
2025-03-11 18:12:50.403451: train_loss -0.6095 
2025-03-11 18:12:50.409666: val_loss -0.441 
2025-03-11 18:12:50.413772: Pseudo dice [np.float32(0.5732)] 
2025-03-11 18:12:50.417532: Epoch time: 43.06 s 
2025-03-11 18:12:50.421203: Yayy! New best EMA pseudo Dice: 0.5239999890327454 
2025-03-11 18:12:51.371611:  
2025-03-11 18:12:51.380770: Epoch 29 
2025-03-11 18:12:51.385938: Current learning rate: 0.00735 
2025-03-11 18:13:34.399936: train_loss -0.6171 
2025-03-11 18:13:34.406509: val_loss -0.4636 
2025-03-11 18:13:34.410040: Pseudo dice [np.float32(0.545)] 
2025-03-11 18:13:34.414083: Epoch time: 43.03 s 
2025-03-11 18:13:34.418127: Yayy! New best EMA pseudo Dice: 0.5260999798774719 
2025-03-11 18:13:35.149334:  
2025-03-11 18:13:35.155555: Epoch 30 
2025-03-11 18:13:35.159750: Current learning rate: 0.00725 
2025-03-11 18:14:18.165925: train_loss -0.6305 
2025-03-11 18:14:18.171646: val_loss -0.5395 
2025-03-11 18:14:18.175280: Pseudo dice [np.float32(0.5989)] 
2025-03-11 18:14:18.179539: Epoch time: 43.02 s 
2025-03-11 18:14:18.183686: Yayy! New best EMA pseudo Dice: 0.5333999991416931 
2025-03-11 18:14:18.986630:  
2025-03-11 18:14:18.992741: Epoch 31 
2025-03-11 18:14:18.996845: Current learning rate: 0.00716 
2025-03-11 18:15:02.015196: train_loss -0.5907 
2025-03-11 18:15:02.022002: val_loss -0.3906 
2025-03-11 18:15:02.025647: Pseudo dice [np.float32(0.4228)] 
2025-03-11 18:15:02.029344: Epoch time: 43.03 s 
2025-03-11 18:15:02.600703:  
2025-03-11 18:15:02.606343: Epoch 32 
2025-03-11 18:15:02.610532: Current learning rate: 0.00707 
2025-03-11 18:15:45.630174: train_loss -0.5421 
2025-03-11 18:15:45.636264: val_loss -0.5359 
2025-03-11 18:15:45.640795: Pseudo dice [np.float32(0.6282)] 
2025-03-11 18:15:45.644341: Epoch time: 43.03 s 
2025-03-11 18:15:46.207038:  
2025-03-11 18:15:46.212700: Epoch 33 
2025-03-11 18:15:46.216825: Current learning rate: 0.00697 
2025-03-11 18:16:29.239292: train_loss -0.6156 
2025-03-11 18:16:29.246073: val_loss -0.4133 
2025-03-11 18:16:29.250485: Pseudo dice [np.float32(0.5614)] 
2025-03-11 18:16:29.254125: Epoch time: 43.03 s 
2025-03-11 18:16:29.257771: Yayy! New best EMA pseudo Dice: 0.5357999801635742 
2025-03-11 18:16:29.996662:  
2025-03-11 18:16:30.002679: Epoch 34 
2025-03-11 18:16:30.007025: Current learning rate: 0.00688 
2025-03-11 18:17:13.030256: train_loss -0.6141 
2025-03-11 18:17:13.036357: val_loss -0.511 
2025-03-11 18:17:13.040503: Pseudo dice [np.float32(0.6232)] 
2025-03-11 18:17:13.044046: Epoch time: 43.03 s 
2025-03-11 18:17:13.048080: Yayy! New best EMA pseudo Dice: 0.5444999933242798 
2025-03-11 18:17:13.783953:  
2025-03-11 18:17:13.790746: Epoch 35 
2025-03-11 18:17:13.793811: Current learning rate: 0.00679 
2025-03-11 18:17:56.816804: train_loss -0.6056 
2025-03-11 18:17:56.823358: val_loss -0.4652 
2025-03-11 18:17:56.826900: Pseudo dice [np.float32(0.5482)] 
2025-03-11 18:17:56.830417: Epoch time: 43.03 s 
2025-03-11 18:17:56.834448: Yayy! New best EMA pseudo Dice: 0.5449000000953674 
2025-03-11 18:17:57.586242:  
2025-03-11 18:17:57.592491: Epoch 36 
2025-03-11 18:17:57.596583: Current learning rate: 0.00669 
2025-03-11 18:18:40.605778: train_loss -0.6082 
2025-03-11 18:18:40.612540: val_loss -0.4364 
2025-03-11 18:18:40.616319: Pseudo dice [np.float32(0.5703)] 
2025-03-11 18:18:40.619942: Epoch time: 43.02 s 
2025-03-11 18:18:40.623710: Yayy! New best EMA pseudo Dice: 0.5473999977111816 
2025-03-11 18:18:41.518912:  
2025-03-11 18:18:41.523634: Epoch 37 
2025-03-11 18:18:41.527765: Current learning rate: 0.0066 
2025-03-11 18:19:24.530126: train_loss -0.5987 
2025-03-11 18:19:24.536829: val_loss -0.4658 
2025-03-11 18:19:24.541072: Pseudo dice [np.float32(0.546)] 
2025-03-11 18:19:24.544139: Epoch time: 43.01 s 
2025-03-11 18:19:25.134994:  
2025-03-11 18:19:25.141197: Epoch 38 
2025-03-11 18:19:25.145517: Current learning rate: 0.0065 
2025-03-11 18:20:08.147679: train_loss -0.6441 
2025-03-11 18:20:08.154464: val_loss -0.5242 
2025-03-11 18:20:08.158088: Pseudo dice [np.float32(0.641)] 
2025-03-11 18:20:08.162158: Epoch time: 43.01 s 
2025-03-11 18:20:08.165314: Yayy! New best EMA pseudo Dice: 0.5566999912261963 
2025-03-11 18:20:08.900276:  
2025-03-11 18:20:08.906850: Epoch 39 
2025-03-11 18:20:08.910522: Current learning rate: 0.00641 
2025-03-11 18:20:51.923519: train_loss -0.6325 
2025-03-11 18:20:51.930062: val_loss -0.5054 
2025-03-11 18:20:51.933597: Pseudo dice [np.float32(0.6232)] 
2025-03-11 18:20:51.937621: Epoch time: 43.02 s 
2025-03-11 18:20:51.941153: Yayy! New best EMA pseudo Dice: 0.5633000135421753 
2025-03-11 18:20:52.696190:  
2025-03-11 18:20:52.701763: Epoch 40 
2025-03-11 18:20:52.705784: Current learning rate: 0.00631 
2025-03-11 18:21:35.720364: train_loss -0.6334 
2025-03-11 18:21:35.725974: val_loss -0.4005 
2025-03-11 18:21:35.730363: Pseudo dice [np.float32(0.5238)] 
2025-03-11 18:21:35.734476: Epoch time: 43.02 s 
2025-03-11 18:21:36.315172:  
2025-03-11 18:21:36.321854: Epoch 41 
2025-03-11 18:21:36.325968: Current learning rate: 0.00622 
2025-03-11 18:22:19.339679: train_loss -0.6213 
2025-03-11 18:22:19.346434: val_loss -0.4436 
2025-03-11 18:22:19.350561: Pseudo dice [np.float32(0.5629)] 
2025-03-11 18:22:19.354529: Epoch time: 43.02 s 
2025-03-11 18:22:19.906229:  
2025-03-11 18:22:19.912293: Epoch 42 
2025-03-11 18:22:19.916821: Current learning rate: 0.00612 
2025-03-11 18:23:02.971866: train_loss -0.6486 
2025-03-11 18:23:02.978271: val_loss -0.4737 
2025-03-11 18:23:02.981849: Pseudo dice [np.float32(0.5967)] 
2025-03-11 18:23:02.986012: Epoch time: 43.07 s 
2025-03-11 18:23:02.989529: Yayy! New best EMA pseudo Dice: 0.5633999705314636 
2025-03-11 18:23:03.759431:  
2025-03-11 18:23:03.765614: Epoch 43 
2025-03-11 18:23:03.769272: Current learning rate: 0.00603 
2025-03-11 18:23:46.799824: train_loss -0.6368 
2025-03-11 18:23:46.806031: val_loss -0.3788 
2025-03-11 18:23:46.809757: Pseudo dice [np.float32(0.5015)] 
2025-03-11 18:23:46.813438: Epoch time: 43.04 s 
2025-03-11 18:23:47.365974:  
2025-03-11 18:23:47.373267: Epoch 44 
2025-03-11 18:23:47.376824: Current learning rate: 0.00593 
2025-03-11 18:24:30.403046: train_loss -0.6332 
2025-03-11 18:24:30.408805: val_loss -0.4607 
2025-03-11 18:24:30.412956: Pseudo dice [np.float32(0.5203)] 
2025-03-11 18:24:30.416582: Epoch time: 43.04 s 
2025-03-11 18:24:31.123891:  
2025-03-11 18:24:31.130677: Epoch 45 
2025-03-11 18:24:31.134431: Current learning rate: 0.00584 
2025-03-11 18:25:14.160254: train_loss -0.6597 
2025-03-11 18:25:14.166504: val_loss -0.4228 
2025-03-11 18:25:14.170134: Pseudo dice [np.float32(0.549)] 
2025-03-11 18:25:14.174207: Epoch time: 43.04 s 
2025-03-11 18:25:14.719337:  
2025-03-11 18:25:14.726031: Epoch 46 
2025-03-11 18:25:14.729555: Current learning rate: 0.00574 
2025-03-11 18:25:57.751289: train_loss -0.6395 
2025-03-11 18:25:57.757288: val_loss -0.4553 
2025-03-11 18:25:57.761658: Pseudo dice [np.float32(0.6078)] 
2025-03-11 18:25:57.765273: Epoch time: 43.03 s 
2025-03-11 18:25:58.310212:  
2025-03-11 18:25:58.318084: Epoch 47 
2025-03-11 18:25:58.323312: Current learning rate: 0.00565 
2025-03-11 18:26:41.352732: train_loss -0.6678 
2025-03-11 18:26:41.359475: val_loss -0.5002 
2025-03-11 18:26:41.363600: Pseudo dice [np.float32(0.6076)] 
2025-03-11 18:26:41.367765: Epoch time: 43.04 s 
2025-03-11 18:26:41.371493: Yayy! New best EMA pseudo Dice: 0.5634999871253967 
2025-03-11 18:26:42.088354:  
2025-03-11 18:26:42.094540: Epoch 48 
2025-03-11 18:26:42.098697: Current learning rate: 0.00555 
2025-03-11 18:27:25.146645: train_loss -0.6375 
2025-03-11 18:27:25.154019: val_loss -0.4579 
2025-03-11 18:27:25.157650: Pseudo dice [np.float32(0.5393)] 
2025-03-11 18:27:25.161940: Epoch time: 43.06 s 
2025-03-11 18:27:25.717620:  
2025-03-11 18:27:25.724349: Epoch 49 
2025-03-11 18:27:25.727981: Current learning rate: 0.00546 
2025-03-11 18:28:08.972073: train_loss -0.6476 
2025-03-11 18:28:08.978263: val_loss -0.5182 
2025-03-11 18:28:08.982584: Pseudo dice [np.float32(0.5985)] 
2025-03-11 18:28:08.986847: Epoch time: 43.25 s 
2025-03-11 18:28:09.138464: Yayy! New best EMA pseudo Dice: 0.5648000240325928 
2025-03-11 18:28:09.855754:  
2025-03-11 18:28:09.861520: Epoch 50 
2025-03-11 18:28:09.865752: Current learning rate: 0.00536 
2025-03-11 18:28:52.929650: train_loss -0.6432 
2025-03-11 18:28:52.936675: val_loss -0.5164 
2025-03-11 18:28:52.940759: Pseudo dice [np.float32(0.6578)] 
2025-03-11 18:28:52.944553: Epoch time: 43.07 s 
2025-03-11 18:28:52.948112: Yayy! New best EMA pseudo Dice: 0.5741000175476074 
2025-03-11 18:28:53.740742:  
2025-03-11 18:28:53.746943: Epoch 51 
2025-03-11 18:28:53.750786: Current learning rate: 0.00526 
2025-03-11 18:29:36.818596: train_loss -0.6327 
2025-03-11 18:29:36.825648: val_loss -0.4891 
2025-03-11 18:29:36.829188: Pseudo dice [np.float32(0.6186)] 
2025-03-11 18:29:36.833212: Epoch time: 43.08 s 
2025-03-11 18:29:36.836746: Yayy! New best EMA pseudo Dice: 0.578499972820282 
2025-03-11 18:29:37.570262:  
2025-03-11 18:29:37.576462: Epoch 52 
2025-03-11 18:29:37.580592: Current learning rate: 0.00517 
2025-03-11 18:30:20.620121: train_loss -0.6414 
2025-03-11 18:30:20.627267: val_loss -0.5168 
2025-03-11 18:30:20.631388: Pseudo dice [np.float32(0.6364)] 
2025-03-11 18:30:20.634963: Epoch time: 43.05 s 
2025-03-11 18:30:20.638005: Yayy! New best EMA pseudo Dice: 0.5842999815940857 
2025-03-11 18:30:21.383586:  
2025-03-11 18:30:21.389691: Epoch 53 
2025-03-11 18:30:21.394227: Current learning rate: 0.00507 
2025-03-11 18:31:04.435497: train_loss -0.6733 
2025-03-11 18:31:04.442237: val_loss -0.4444 
2025-03-11 18:31:04.446004: Pseudo dice [np.float32(0.6473)] 
2025-03-11 18:31:04.449783: Epoch time: 43.05 s 
2025-03-11 18:31:04.454023: Yayy! New best EMA pseudo Dice: 0.5906000137329102 
2025-03-11 18:31:05.382432:  
2025-03-11 18:31:05.389110: Epoch 54 
2025-03-11 18:31:05.392707: Current learning rate: 0.00497 
2025-03-11 18:31:48.424563: train_loss -0.6868 
2025-03-11 18:31:48.431183: val_loss -0.4847 
2025-03-11 18:31:48.435279: Pseudo dice [np.float32(0.6626)] 
2025-03-11 18:31:48.438861: Epoch time: 43.04 s 
2025-03-11 18:31:48.442045: Yayy! New best EMA pseudo Dice: 0.5978000164031982 
2025-03-11 18:31:49.169450:  
2025-03-11 18:31:49.174522: Epoch 55 
2025-03-11 18:31:49.179078: Current learning rate: 0.00487 
2025-03-11 18:32:32.241784: train_loss -0.6756 
2025-03-11 18:32:32.247850: val_loss -0.4575 
2025-03-11 18:32:32.252386: Pseudo dice [np.float32(0.6227)] 
2025-03-11 18:32:32.255447: Epoch time: 43.07 s 
2025-03-11 18:32:32.259471: Yayy! New best EMA pseudo Dice: 0.6003000140190125 
2025-03-11 18:32:33.063306:  
2025-03-11 18:32:33.068911: Epoch 56 
2025-03-11 18:32:33.072992: Current learning rate: 0.00478 
2025-03-11 18:33:16.107350: train_loss -0.6839 
2025-03-11 18:33:16.114004: val_loss -0.5256 
2025-03-11 18:33:16.119255: Pseudo dice [np.float32(0.6524)] 
2025-03-11 18:33:16.122878: Epoch time: 43.05 s 
2025-03-11 18:33:16.126979: Yayy! New best EMA pseudo Dice: 0.6054999828338623 
2025-03-11 18:33:16.878193:  
2025-03-11 18:33:16.885434: Epoch 57 
2025-03-11 18:33:16.889040: Current learning rate: 0.00468 
2025-03-11 18:33:59.927481: train_loss -0.7013 
2025-03-11 18:33:59.934315: val_loss -0.4526 
2025-03-11 18:33:59.937385: Pseudo dice [np.float32(0.5823)] 
2025-03-11 18:33:59.941585: Epoch time: 43.05 s 
2025-03-11 18:34:00.507479:  
2025-03-11 18:34:00.513698: Epoch 58 
2025-03-11 18:34:00.517819: Current learning rate: 0.00458 
2025-03-11 18:34:43.587282: train_loss -0.6625 
2025-03-11 18:34:43.594013: val_loss -0.468 
2025-03-11 18:34:43.597789: Pseudo dice [np.float32(0.6322)] 
2025-03-11 18:34:43.601352: Epoch time: 43.08 s 
2025-03-11 18:34:43.605037: Yayy! New best EMA pseudo Dice: 0.6061000227928162 
2025-03-11 18:34:44.332281:  
2025-03-11 18:34:44.336406: Epoch 59 
2025-03-11 18:34:44.340561: Current learning rate: 0.00448 
2025-03-11 18:35:27.380371: train_loss -0.6905 
2025-03-11 18:35:27.388121: val_loss -0.5052 
2025-03-11 18:35:27.392233: Pseudo dice [np.float32(0.6499)] 
2025-03-11 18:35:27.395886: Epoch time: 43.05 s 
2025-03-11 18:35:27.399562: Yayy! New best EMA pseudo Dice: 0.6104999780654907 
2025-03-11 18:35:28.144987:  
2025-03-11 18:35:28.151565: Epoch 60 
2025-03-11 18:35:28.155132: Current learning rate: 0.00438 
2025-03-11 18:36:11.201128: train_loss -0.6935 
2025-03-11 18:36:11.207875: val_loss -0.5339 
2025-03-11 18:36:11.211551: Pseudo dice [np.float32(0.6653)] 
2025-03-11 18:36:11.215125: Epoch time: 43.06 s 
2025-03-11 18:36:11.219226: Yayy! New best EMA pseudo Dice: 0.6158999800682068 
2025-03-11 18:36:11.958855:  
2025-03-11 18:36:11.965245: Epoch 61 
2025-03-11 18:36:11.968861: Current learning rate: 0.00429 
2025-03-11 18:36:54.992066: train_loss -0.6617 
2025-03-11 18:36:54.998710: val_loss -0.4927 
2025-03-11 18:36:55.002294: Pseudo dice [np.float32(0.6429)] 
2025-03-11 18:36:55.006167: Epoch time: 43.03 s 
2025-03-11 18:36:55.010195: Yayy! New best EMA pseudo Dice: 0.6186000108718872 
2025-03-11 18:36:55.971694:  
2025-03-11 18:36:55.977355: Epoch 62 
2025-03-11 18:36:55.981512: Current learning rate: 0.00419 
2025-03-11 18:37:39.018269: train_loss -0.6668 
2025-03-11 18:37:39.025602: val_loss -0.4992 
2025-03-11 18:37:39.030187: Pseudo dice [np.float32(0.6091)] 
2025-03-11 18:37:39.033705: Epoch time: 43.05 s 
2025-03-11 18:37:39.626140:  
2025-03-11 18:37:39.632238: Epoch 63 
2025-03-11 18:37:39.636270: Current learning rate: 0.00409 
2025-03-11 18:38:22.669080: train_loss -0.6957 
2025-03-11 18:38:22.675893: val_loss -0.5038 
2025-03-11 18:38:22.679500: Pseudo dice [np.float32(0.6256)] 
2025-03-11 18:38:22.682618: Epoch time: 43.04 s 
2025-03-11 18:38:23.262531:  
2025-03-11 18:38:23.269239: Epoch 64 
2025-03-11 18:38:23.273324: Current learning rate: 0.00399 
2025-03-11 18:39:06.320279: train_loss -0.6808 
2025-03-11 18:39:06.328989: val_loss -0.5421 
2025-03-11 18:39:06.333104: Pseudo dice [np.float32(0.6364)] 
2025-03-11 18:39:06.336153: Epoch time: 43.06 s 
2025-03-11 18:39:06.340315: Yayy! New best EMA pseudo Dice: 0.6202999949455261 
2025-03-11 18:39:07.189600:  
2025-03-11 18:39:07.195299: Epoch 65 
2025-03-11 18:39:07.198885: Current learning rate: 0.00389 
2025-03-11 18:39:50.225734: train_loss -0.6777 
2025-03-11 18:39:50.232280: val_loss -0.5097 
2025-03-11 18:39:50.235823: Pseudo dice [np.float32(0.6548)] 
2025-03-11 18:39:50.239975: Epoch time: 43.04 s 
2025-03-11 18:39:50.243528: Yayy! New best EMA pseudo Dice: 0.6237000226974487 
2025-03-11 18:39:51.008129:  
2025-03-11 18:39:51.013714: Epoch 66 
2025-03-11 18:39:51.017349: Current learning rate: 0.00379 
2025-03-11 18:40:34.025304: train_loss -0.7025 
2025-03-11 18:40:34.032133: val_loss -0.4922 
2025-03-11 18:40:34.035252: Pseudo dice [np.float32(0.6406)] 
2025-03-11 18:40:34.038885: Epoch time: 43.02 s 
2025-03-11 18:40:34.042489: Yayy! New best EMA pseudo Dice: 0.6254000067710876 
2025-03-11 18:40:34.777060:  
2025-03-11 18:40:34.783305: Epoch 67 
2025-03-11 18:40:34.786913: Current learning rate: 0.00369 
2025-03-11 18:41:17.811093: train_loss -0.6896 
2025-03-11 18:41:17.817270: val_loss -0.5156 
2025-03-11 18:41:17.820815: Pseudo dice [np.float32(0.6481)] 
2025-03-11 18:41:17.824386: Epoch time: 43.03 s 
2025-03-11 18:41:17.828023: Yayy! New best EMA pseudo Dice: 0.6276999711990356 
2025-03-11 18:41:18.577369:  
2025-03-11 18:41:18.584102: Epoch 68 
2025-03-11 18:41:18.587172: Current learning rate: 0.00359 
2025-03-11 18:42:01.631687: train_loss -0.7147 
2025-03-11 18:42:01.638320: val_loss -0.5267 
2025-03-11 18:42:01.641957: Pseudo dice [np.float32(0.6119)] 
2025-03-11 18:42:01.645761: Epoch time: 43.05 s 
2025-03-11 18:42:02.235231:  
2025-03-11 18:42:02.240806: Epoch 69 
2025-03-11 18:42:02.244325: Current learning rate: 0.00349 
2025-03-11 18:42:45.260089: train_loss -0.7082 
2025-03-11 18:42:45.266315: val_loss -0.5263 
2025-03-11 18:42:45.270459: Pseudo dice [np.float32(0.6136)] 
2025-03-11 18:42:45.273513: Epoch time: 43.03 s 
2025-03-11 18:42:46.045915:  
2025-03-11 18:42:46.052133: Epoch 70 
2025-03-11 18:42:46.055760: Current learning rate: 0.00338 
2025-03-11 18:43:29.085560: train_loss -0.7147 
2025-03-11 18:43:29.091757: val_loss -0.4674 
2025-03-11 18:43:29.095410: Pseudo dice [np.float32(0.6382)] 
2025-03-11 18:43:29.099199: Epoch time: 43.04 s 
2025-03-11 18:43:29.676692:  
2025-03-11 18:43:29.682917: Epoch 71 
2025-03-11 18:43:29.686541: Current learning rate: 0.00328 
2025-03-11 18:44:12.727375: train_loss -0.6919 
2025-03-11 18:44:12.733059: val_loss -0.4875 
2025-03-11 18:44:12.737678: Pseudo dice [np.float32(0.6366)] 
2025-03-11 18:44:12.741287: Epoch time: 43.05 s 
2025-03-11 18:44:13.362436:  
2025-03-11 18:44:13.369074: Epoch 72 
2025-03-11 18:44:13.372732: Current learning rate: 0.00318 
2025-03-11 18:44:56.387462: train_loss -0.6866 
2025-03-11 18:44:56.394167: val_loss -0.539 
2025-03-11 18:44:56.397714: Pseudo dice [np.float32(0.6409)] 
2025-03-11 18:44:56.401311: Epoch time: 43.03 s 
2025-03-11 18:44:56.404834: Yayy! New best EMA pseudo Dice: 0.628600001335144 
2025-03-11 18:44:57.223560:  
2025-03-11 18:44:57.229112: Epoch 73 
2025-03-11 18:44:57.232143: Current learning rate: 0.00308 
2025-03-11 18:45:40.256218: train_loss -0.709 
2025-03-11 18:45:40.263938: val_loss -0.5317 
2025-03-11 18:45:40.267123: Pseudo dice [np.float32(0.6568)] 
2025-03-11 18:45:40.270761: Epoch time: 43.03 s 
2025-03-11 18:45:40.273859: Yayy! New best EMA pseudo Dice: 0.6313999891281128 
2025-03-11 18:45:41.025995:  
2025-03-11 18:45:41.031630: Epoch 74 
2025-03-11 18:45:41.035226: Current learning rate: 0.00297 
2025-03-11 18:46:24.069356: train_loss -0.7239 
2025-03-11 18:46:24.075409: val_loss -0.4776 
2025-03-11 18:46:24.078926: Pseudo dice [np.float32(0.7013)] 
2025-03-11 18:46:24.081960: Epoch time: 43.04 s 
2025-03-11 18:46:24.085488: Yayy! New best EMA pseudo Dice: 0.6384000182151794 
2025-03-11 18:46:24.845091:  
2025-03-11 18:46:24.851182: Epoch 75 
2025-03-11 18:46:24.854222: Current learning rate: 0.00287 
2025-03-11 18:47:07.858868: train_loss -0.6939 
2025-03-11 18:47:07.867019: val_loss -0.4533 
2025-03-11 18:47:07.871582: Pseudo dice [np.float32(0.616)] 
2025-03-11 18:47:07.875109: Epoch time: 43.01 s 
2025-03-11 18:47:08.459142:  
2025-03-11 18:47:08.464694: Epoch 76 
2025-03-11 18:47:08.468297: Current learning rate: 0.00277 
2025-03-11 18:47:51.476766: train_loss -0.7055 
2025-03-11 18:47:51.482956: val_loss -0.4762 
2025-03-11 18:47:51.486529: Pseudo dice [np.float32(0.6576)] 
2025-03-11 18:47:51.490085: Epoch time: 43.02 s 
2025-03-11 18:47:52.067700:  
2025-03-11 18:47:52.073781: Epoch 77 
2025-03-11 18:47:52.076829: Current learning rate: 0.00266 
2025-03-11 18:48:35.090344: train_loss -0.7037 
2025-03-11 18:48:35.095894: val_loss -0.4571 
2025-03-11 18:48:35.098932: Pseudo dice [np.float32(0.5721)] 
2025-03-11 18:48:35.102961: Epoch time: 43.02 s 
2025-03-11 18:48:35.850217:  
2025-03-11 18:48:35.855916: Epoch 78 
2025-03-11 18:48:35.860541: Current learning rate: 0.00256 
2025-03-11 18:49:18.892350: train_loss -0.7101 
2025-03-11 18:49:18.898953: val_loss -0.4903 
2025-03-11 18:49:18.901483: Pseudo dice [np.float32(0.6021)] 
2025-03-11 18:49:18.905515: Epoch time: 43.04 s 
2025-03-11 18:49:19.523571:  
2025-03-11 18:49:19.529129: Epoch 79 
2025-03-11 18:49:19.532161: Current learning rate: 0.00245 
2025-03-11 18:50:02.527253: train_loss -0.7178 
2025-03-11 18:50:02.533467: val_loss -0.4474 
2025-03-11 18:50:02.536040: Pseudo dice [np.float32(0.6354)] 
2025-03-11 18:50:02.540151: Epoch time: 43.0 s 
2025-03-11 18:50:03.128568:  
2025-03-11 18:50:03.133765: Epoch 80 
2025-03-11 18:50:03.137465: Current learning rate: 0.00235 
2025-03-11 18:50:46.137711: train_loss -0.7456 
2025-03-11 18:50:46.143411: val_loss -0.491 
2025-03-11 18:50:46.147017: Pseudo dice [np.float32(0.6705)] 
2025-03-11 18:50:46.150542: Epoch time: 43.01 s 
2025-03-11 18:50:46.741983:  
2025-03-11 18:50:46.748113: Epoch 81 
2025-03-11 18:50:46.751328: Current learning rate: 0.00224 
2025-03-11 18:51:29.742166: train_loss -0.7235 
2025-03-11 18:51:29.748429: val_loss -0.5583 
2025-03-11 18:51:29.752602: Pseudo dice [np.float32(0.6728)] 
2025-03-11 18:51:29.756339: Epoch time: 43.0 s 
2025-03-11 18:51:30.352441:  
2025-03-11 18:51:30.357627: Epoch 82 
2025-03-11 18:51:30.361277: Current learning rate: 0.00214 
2025-03-11 18:52:13.335768: train_loss -0.7473 
2025-03-11 18:52:13.342453: val_loss -0.5364 
2025-03-11 18:52:13.346113: Pseudo dice [np.float32(0.7089)] 
2025-03-11 18:52:13.349277: Epoch time: 42.98 s 
2025-03-11 18:52:13.352891: Yayy! New best EMA pseudo Dice: 0.644599974155426 
2025-03-11 18:52:14.120093:  
2025-03-11 18:52:14.125842: Epoch 83 
2025-03-11 18:52:14.129416: Current learning rate: 0.00203 
2025-03-11 18:52:57.124034: train_loss -0.7445 
2025-03-11 18:52:57.130719: val_loss -0.4745 
2025-03-11 18:52:57.134480: Pseudo dice [np.float32(0.5848)] 
2025-03-11 18:52:57.138083: Epoch time: 43.0 s 
2025-03-11 18:52:57.723446:  
2025-03-11 18:52:57.729708: Epoch 84 
2025-03-11 18:52:57.733575: Current learning rate: 0.00192 
2025-03-11 18:53:40.751842: train_loss -0.7352 
2025-03-11 18:53:40.757990: val_loss -0.499 
2025-03-11 18:53:40.762008: Pseudo dice [np.float32(0.6375)] 
2025-03-11 18:53:40.765056: Epoch time: 43.03 s 
2025-03-11 18:53:41.329417:  
2025-03-11 18:53:41.335507: Epoch 85 
2025-03-11 18:53:41.339062: Current learning rate: 0.00181 
2025-03-11 18:54:24.378910: train_loss -0.7162 
2025-03-11 18:54:24.385010: val_loss -0.5336 
2025-03-11 18:54:24.388558: Pseudo dice [np.float32(0.6908)] 
2025-03-11 18:54:24.391604: Epoch time: 43.05 s 
2025-03-11 18:54:25.110606:  
2025-03-11 18:54:25.116363: Epoch 86 
2025-03-11 18:54:25.119440: Current learning rate: 0.0017 
2025-03-11 18:55:08.143274: train_loss -0.7441 
2025-03-11 18:55:08.148952: val_loss -0.5016 
2025-03-11 18:55:08.152565: Pseudo dice [np.float32(0.5947)] 
2025-03-11 18:55:08.155655: Epoch time: 43.03 s 
2025-03-11 18:55:08.720112:  
2025-03-11 18:55:08.725733: Epoch 87 
2025-03-11 18:55:08.729324: Current learning rate: 0.00159 
2025-03-11 18:55:51.759645: train_loss -0.7363 
2025-03-11 18:55:51.766215: val_loss -0.5054 
2025-03-11 18:55:51.769886: Pseudo dice [np.float32(0.685)] 
2025-03-11 18:55:51.773647: Epoch time: 43.04 s 
2025-03-11 18:55:52.330892:  
2025-03-11 18:55:52.336634: Epoch 88 
2025-03-11 18:55:52.340234: Current learning rate: 0.00148 
2025-03-11 18:56:35.347369: train_loss -0.7455 
2025-03-11 18:56:35.353540: val_loss -0.4789 
2025-03-11 18:56:35.357601: Pseudo dice [np.float32(0.6556)] 
2025-03-11 18:56:35.361148: Epoch time: 43.02 s 
2025-03-11 18:56:35.364680: Yayy! New best EMA pseudo Dice: 0.6446999907493591 
2025-03-11 18:56:36.125981:  
2025-03-11 18:56:36.132574: Epoch 89 
2025-03-11 18:56:36.136115: Current learning rate: 0.00137 
2025-03-11 18:57:19.152308: train_loss -0.7442 
2025-03-11 18:57:19.159022: val_loss -0.4497 
2025-03-11 18:57:19.162086: Pseudo dice [np.float32(0.6899)] 
2025-03-11 18:57:19.165478: Epoch time: 43.03 s 
2025-03-11 18:57:19.168687: Yayy! New best EMA pseudo Dice: 0.6492000222206116 
2025-03-11 18:57:19.960673:  
2025-03-11 18:57:19.966434: Epoch 90 
2025-03-11 18:57:19.970050: Current learning rate: 0.00126 
2025-03-11 18:58:03.183052: train_loss -0.759 
2025-03-11 18:58:03.188701: val_loss -0.5558 
2025-03-11 18:58:03.192499: Pseudo dice [np.float32(0.7139)] 
2025-03-11 18:58:03.196159: Epoch time: 43.22 s 
2025-03-11 18:58:03.199737: Yayy! New best EMA pseudo Dice: 0.6557000279426575 
2025-03-11 18:58:03.928382:  
2025-03-11 18:58:03.934621: Epoch 91 
2025-03-11 18:58:03.938227: Current learning rate: 0.00115 
2025-03-11 18:58:46.963310: train_loss -0.7519 
2025-03-11 18:58:46.969363: val_loss -0.515 
2025-03-11 18:58:46.972892: Pseudo dice [np.float32(0.6529)] 
2025-03-11 18:58:46.975941: Epoch time: 43.04 s 
2025-03-11 18:58:47.568871:  
2025-03-11 18:58:47.573005: Epoch 92 
2025-03-11 18:58:47.577118: Current learning rate: 0.00103 
2025-03-11 18:59:30.603410: train_loss -0.7511 
2025-03-11 18:59:30.609404: val_loss -0.5489 
2025-03-11 18:59:30.613001: Pseudo dice [np.float32(0.6714)] 
2025-03-11 18:59:30.616706: Epoch time: 43.03 s 
2025-03-11 18:59:30.619850: Yayy! New best EMA pseudo Dice: 0.6570000052452087 
2025-03-11 18:59:31.350352:  
2025-03-11 18:59:31.356007: Epoch 93 
2025-03-11 18:59:31.359612: Current learning rate: 0.00091 
2025-03-11 19:00:14.412138: train_loss -0.7573 
2025-03-11 19:00:14.418802: val_loss -0.4613 
2025-03-11 19:00:14.422479: Pseudo dice [np.float32(0.6931)] 
2025-03-11 19:00:14.425549: Epoch time: 43.06 s 
2025-03-11 19:00:14.429110: Yayy! New best EMA pseudo Dice: 0.6606000065803528 
2025-03-11 19:00:15.313310:  
2025-03-11 19:00:15.321034: Epoch 94 
2025-03-11 19:00:15.324597: Current learning rate: 0.00079 
2025-03-11 19:00:58.337175: train_loss -0.762 
2025-03-11 19:00:58.344132: val_loss -0.4346 
2025-03-11 19:00:58.348314: Pseudo dice [np.float32(0.6278)] 
2025-03-11 19:00:58.352458: Epoch time: 43.02 s 
2025-03-11 19:00:58.911036:  
2025-03-11 19:00:58.917325: Epoch 95 
2025-03-11 19:00:58.920882: Current learning rate: 0.00067 
2025-03-11 19:01:41.954523: train_loss -0.7659 
2025-03-11 19:01:41.960606: val_loss -0.4985 
2025-03-11 19:01:41.964137: Pseudo dice [np.float32(0.6604)] 
2025-03-11 19:01:41.967679: Epoch time: 43.04 s 
2025-03-11 19:01:42.535128:  
2025-03-11 19:01:42.541684: Epoch 96 
2025-03-11 19:01:42.545228: Current learning rate: 0.00055 
2025-03-11 19:02:25.590471: train_loss -0.7584 
2025-03-11 19:02:25.597068: val_loss -0.4172 
2025-03-11 19:02:25.600622: Pseudo dice [np.float32(0.6255)] 
2025-03-11 19:02:25.604146: Epoch time: 43.06 s 
2025-03-11 19:02:26.168506:  
2025-03-11 19:02:26.174186: Epoch 97 
2025-03-11 19:02:26.178116: Current learning rate: 0.00043 
2025-03-11 19:03:09.209306: train_loss -0.7629 
2025-03-11 19:03:09.214573: val_loss -0.4835 
2025-03-11 19:03:09.219111: Pseudo dice [np.float32(0.571)] 
2025-03-11 19:03:09.222539: Epoch time: 43.04 s 
2025-03-11 19:03:09.793157:  
2025-03-11 19:03:09.797773: Epoch 98 
2025-03-11 19:03:09.801372: Current learning rate: 0.0003 
2025-03-11 19:03:52.829194: train_loss -0.7669 
2025-03-11 19:03:52.836404: val_loss -0.4383 
2025-03-11 19:03:52.840475: Pseudo dice [np.float32(0.5978)] 
2025-03-11 19:03:52.845021: Epoch time: 43.04 s 
2025-03-11 19:03:53.432696:  
2025-03-11 19:03:53.438818: Epoch 99 
2025-03-11 19:03:53.443406: Current learning rate: 0.00016 
2025-03-11 19:04:36.502825: train_loss -0.7622 
2025-03-11 19:04:36.510009: val_loss -0.5212 
2025-03-11 19:04:36.514461: Pseudo dice [np.float32(0.6794)] 
2025-03-11 19:04:36.519102: Epoch time: 43.07 s 
2025-03-11 19:04:37.300695: Training done. 
2025-03-11 19:04:37.335856: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-11 19:04:37.344272: The split file contains 5 splits. 
2025-03-11 19:04:37.351690: Desired fold for training: 0 
2025-03-11 19:04:37.357707: This split has 100 training and 26 validation cases. 
2025-03-11 19:04:37.364504: predicting colon_008 
2025-03-11 19:04:37.373042: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-03-11 19:04:53.713410: predicting colon_027 
2025-03-11 19:04:53.734659: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-03-11 19:04:59.996309: predicting colon_030 
2025-03-11 19:05:00.010282: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-03-11 19:05:08.823711: predicting colon_033 
2025-03-11 19:05:08.841040: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-03-11 19:05:24.466114: predicting colon_041 
2025-03-11 19:05:24.490443: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-03-11 19:06:06.549282: predicting colon_042 
2025-03-11 19:06:06.591872: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-03-11 19:06:27.654456: predicting colon_061 
2025-03-11 19:06:27.677309: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-03-11 19:06:52.019164: predicting colon_074 
2025-03-11 19:06:52.044980: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-03-11 19:07:20.124390: predicting colon_075 
2025-03-11 19:07:20.151882: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-03-11 19:07:35.795545: predicting colon_088 
2025-03-11 19:07:35.817477: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-03-11 19:08:00.292709: predicting colon_091 
2025-03-11 19:08:00.318870: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-03-11 19:08:29.562724: predicting colon_092 
2025-03-11 19:08:29.596581: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-03-11 19:08:53.959194: predicting colon_095 
2025-03-11 19:08:53.981467: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-03-11 19:09:09.623583: predicting colon_102 
2025-03-11 19:09:09.644346: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-03-11 19:09:44.732415: predicting colon_111 
2025-03-11 19:09:44.765008: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-03-11 19:09:54.573011: predicting colon_115 
2025-03-11 19:09:54.591905: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-03-11 19:10:10.241253: predicting colon_118 
2025-03-11 19:10:10.262642: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-03-11 19:10:34.629802: predicting colon_124 
2025-03-11 19:10:34.653954: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-03-11 19:10:59.044507: predicting colon_127 
2025-03-11 19:10:59.068513: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-03-11 19:11:48.150774: predicting colon_154 
2025-03-11 19:11:48.191710: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-03-11 19:12:03.872979: predicting colon_161 
2025-03-11 19:12:03.893456: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-03-11 19:12:19.595707: predicting colon_162 
2025-03-11 19:12:19.620284: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-03-11 19:13:01.681848: predicting colon_165 
2025-03-11 19:13:01.711921: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-03-11 19:13:36.863361: predicting colon_166 
2025-03-11 19:13:36.902097: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-03-11 19:13:52.556185: predicting colon_169 
2025-03-11 19:13:52.575386: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-03-11 19:14:41.729252: predicting colon_187 
2025-03-11 19:14:41.770820: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-03-11 19:15:16.198063: Validation complete 
2025-03-11 19:15:16.203797: Mean Validation Dice:  0.20943060220480492 
