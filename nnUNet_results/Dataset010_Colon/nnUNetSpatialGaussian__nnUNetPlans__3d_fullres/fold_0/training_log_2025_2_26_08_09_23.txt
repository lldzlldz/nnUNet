
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-26 08:09:23.783121: do_dummy_2d_data_aug: True 
2025-02-26 08:09:23.789497: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-02-26 08:09:23.797497: The split file contains 5 splits. 
2025-02-26 08:09:23.800496: Desired fold for training: 0 
2025-02-26 08:09:23.804496: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-02-26 08:09:30.826150: unpacking dataset... 
2025-02-26 08:09:31.086639: unpacking done... 
2025-02-26 08:09:34.037132:  
2025-02-26 08:09:34.043148: Epoch 0 
2025-02-26 08:09:34.046157: Current learning rate: 0.01 
2025-02-26 08:10:21.922332: train_loss 0.0203 
2025-02-26 08:10:21.928849: val_loss -0.065 
2025-02-26 08:10:21.932362: Pseudo dice [np.float32(0.0)] 
2025-02-26 08:10:21.936375: Epoch time: 47.89 s 
2025-02-26 08:10:21.938917: Yayy! New best EMA pseudo Dice: 0.0 
2025-02-26 08:10:22.514680:  
2025-02-26 08:10:22.520712: Epoch 1 
2025-02-26 08:10:22.523220: Current learning rate: 0.00991 
2025-02-26 08:11:05.783885: train_loss -0.1578 
2025-02-26 08:11:05.789910: val_loss -0.232 
2025-02-26 08:11:05.793416: Pseudo dice [np.float32(0.3143)] 
2025-02-26 08:11:05.796426: Epoch time: 43.27 s 
2025-02-26 08:11:05.799937: Yayy! New best EMA pseudo Dice: 0.03139999881386757 
2025-02-26 08:11:06.441148:  
2025-02-26 08:11:06.446202: Epoch 2 
2025-02-26 08:11:06.449026: Current learning rate: 0.00982 
2025-02-26 08:11:49.653256: train_loss -0.2813 
2025-02-26 08:11:49.660780: val_loss -0.3605 
2025-02-26 08:11:49.664286: Pseudo dice [np.float32(0.4111)] 
2025-02-26 08:11:49.668347: Epoch time: 43.21 s 
2025-02-26 08:11:49.671856: Yayy! New best EMA pseudo Dice: 0.06939999759197235 
2025-02-26 08:11:50.340573:  
2025-02-26 08:11:50.346348: Epoch 3 
2025-02-26 08:11:50.348861: Current learning rate: 0.00973 
2025-02-26 08:12:33.574521: train_loss -0.3261 
2025-02-26 08:12:33.582126: val_loss -0.3743 
2025-02-26 08:12:33.586658: Pseudo dice [np.float32(0.4034)] 
2025-02-26 08:12:33.589164: Epoch time: 43.23 s 
2025-02-26 08:12:33.593675: Yayy! New best EMA pseudo Dice: 0.10279999673366547 
2025-02-26 08:12:34.252315:  
2025-02-26 08:12:34.257850: Epoch 4 
2025-02-26 08:12:34.261391: Current learning rate: 0.00964 
2025-02-26 08:13:17.473558: train_loss -0.3759 
2025-02-26 08:13:17.479741: val_loss -0.383 
2025-02-26 08:13:17.482247: Pseudo dice [np.float32(0.4728)] 
2025-02-26 08:13:17.485760: Epoch time: 43.22 s 
2025-02-26 08:13:17.489772: Yayy! New best EMA pseudo Dice: 0.13979999721050262 
2025-02-26 08:13:18.269492:  
2025-02-26 08:13:18.274056: Epoch 5 
2025-02-26 08:13:18.277657: Current learning rate: 0.00955 
2025-02-26 08:14:01.486036: train_loss -0.3866 
2025-02-26 08:14:01.492077: val_loss -0.3933 
2025-02-26 08:14:01.495584: Pseudo dice [np.float32(0.4547)] 
2025-02-26 08:14:01.498592: Epoch time: 43.22 s 
2025-02-26 08:14:01.502100: Yayy! New best EMA pseudo Dice: 0.1712999939918518 
2025-02-26 08:14:02.149333:  
2025-02-26 08:14:02.155904: Epoch 6 
2025-02-26 08:14:02.158962: Current learning rate: 0.00946 
2025-02-26 08:14:45.363712: train_loss -0.4216 
2025-02-26 08:14:45.370228: val_loss -0.3288 
2025-02-26 08:14:45.374736: Pseudo dice [np.float32(0.4014)] 
2025-02-26 08:14:45.378383: Epoch time: 43.21 s 
2025-02-26 08:14:45.382438: Yayy! New best EMA pseudo Dice: 0.19429999589920044 
2025-02-26 08:14:46.026671:  
2025-02-26 08:14:46.033216: Epoch 7 
2025-02-26 08:14:46.035720: Current learning rate: 0.00937 
2025-02-26 08:15:29.252134: train_loss -0.4453 
2025-02-26 08:15:29.258648: val_loss -0.3842 
2025-02-26 08:15:29.262161: Pseudo dice [np.float32(0.4432)] 
2025-02-26 08:15:29.265675: Epoch time: 43.23 s 
2025-02-26 08:15:29.268684: Yayy! New best EMA pseudo Dice: 0.219200000166893 
2025-02-26 08:15:29.927239:  
2025-02-26 08:15:29.933808: Epoch 8 
2025-02-26 08:15:29.936338: Current learning rate: 0.00928 
2025-02-26 08:16:13.160127: train_loss -0.4313 
2025-02-26 08:16:13.165704: val_loss -0.4386 
2025-02-26 08:16:13.170212: Pseudo dice [np.float32(0.5072)] 
2025-02-26 08:16:13.175222: Epoch time: 43.23 s 
2025-02-26 08:16:13.178231: Yayy! New best EMA pseudo Dice: 0.24799999594688416 
2025-02-26 08:16:13.850274:  
2025-02-26 08:16:13.855289: Epoch 9 
2025-02-26 08:16:13.858798: Current learning rate: 0.00919 
2025-02-26 08:16:57.072129: train_loss -0.4738 
2025-02-26 08:16:57.076642: val_loss -0.4211 
2025-02-26 08:16:57.079651: Pseudo dice [np.float32(0.5244)] 
2025-02-26 08:16:57.083164: Epoch time: 43.22 s 
2025-02-26 08:16:57.086678: Yayy! New best EMA pseudo Dice: 0.27559998631477356 
2025-02-26 08:16:57.719379:  
2025-02-26 08:16:57.724896: Epoch 10 
2025-02-26 08:16:57.728412: Current learning rate: 0.0091 
2025-02-26 08:17:40.956898: train_loss -0.4762 
2025-02-26 08:17:40.963421: val_loss -0.4427 
2025-02-26 08:17:40.968435: Pseudo dice [np.float32(0.5096)] 
2025-02-26 08:17:40.971946: Epoch time: 43.24 s 
2025-02-26 08:17:40.975513: Yayy! New best EMA pseudo Dice: 0.29899999499320984 
2025-02-26 08:17:41.622686:  
2025-02-26 08:17:41.627735: Epoch 11 
2025-02-26 08:17:41.631823: Current learning rate: 0.009 
2025-02-26 08:18:24.865246: train_loss -0.4832 
2025-02-26 08:18:24.870325: val_loss -0.4295 
2025-02-26 08:18:24.874877: Pseudo dice [np.float32(0.4881)] 
2025-02-26 08:18:24.878016: Epoch time: 43.24 s 
2025-02-26 08:18:24.881560: Yayy! New best EMA pseudo Dice: 0.31790000200271606 
2025-02-26 08:18:25.539918:  
2025-02-26 08:18:25.545437: Epoch 12 
2025-02-26 08:18:25.547943: Current learning rate: 0.00891 
2025-02-26 08:19:08.786947: train_loss -0.4793 
2025-02-26 08:19:08.793466: val_loss -0.4728 
2025-02-26 08:19:08.797979: Pseudo dice [np.float32(0.5217)] 
2025-02-26 08:19:08.802995: Epoch time: 43.25 s 
2025-02-26 08:19:08.806006: Yayy! New best EMA pseudo Dice: 0.3382999897003174 
2025-02-26 08:19:09.607394:  
2025-02-26 08:19:09.612954: Epoch 13 
2025-02-26 08:19:09.617004: Current learning rate: 0.00882 
2025-02-26 08:19:52.838709: train_loss -0.4999 
2025-02-26 08:19:52.845222: val_loss -0.4426 
2025-02-26 08:19:52.849238: Pseudo dice [np.float32(0.5277)] 
2025-02-26 08:19:52.852256: Epoch time: 43.23 s 
2025-02-26 08:19:52.855768: Yayy! New best EMA pseudo Dice: 0.3571999967098236 
2025-02-26 08:19:53.516790:  
2025-02-26 08:19:53.522324: Epoch 14 
2025-02-26 08:19:53.525896: Current learning rate: 0.00873 
2025-02-26 08:20:36.749902: train_loss -0.5282 
2025-02-26 08:20:36.757428: val_loss -0.3732 
2025-02-26 08:20:36.761437: Pseudo dice [np.float32(0.3763)] 
2025-02-26 08:20:36.763944: Epoch time: 43.23 s 
2025-02-26 08:20:36.767454: Yayy! New best EMA pseudo Dice: 0.35910001397132874 
2025-02-26 08:20:37.433781:  
2025-02-26 08:20:37.438794: Epoch 15 
2025-02-26 08:20:37.442307: Current learning rate: 0.00864 
2025-02-26 08:21:20.653614: train_loss -0.466 
2025-02-26 08:21:20.659226: val_loss -0.4496 
2025-02-26 08:21:20.662279: Pseudo dice [np.float32(0.5447)] 
2025-02-26 08:21:20.665810: Epoch time: 43.22 s 
2025-02-26 08:21:20.668863: Yayy! New best EMA pseudo Dice: 0.37770000100135803 
2025-02-26 08:21:21.328575:  
2025-02-26 08:21:21.334175: Epoch 16 
2025-02-26 08:21:21.337718: Current learning rate: 0.00855 
2025-02-26 08:22:04.555475: train_loss -0.5125 
2025-02-26 08:22:04.561018: val_loss -0.5029 
2025-02-26 08:22:04.566044: Pseudo dice [np.float32(0.5888)] 
2025-02-26 08:22:04.569559: Epoch time: 43.23 s 
2025-02-26 08:22:04.574579: Yayy! New best EMA pseudo Dice: 0.39879998564720154 
2025-02-26 08:22:05.264007:  
2025-02-26 08:22:05.269037: Epoch 17 
2025-02-26 08:22:05.272581: Current learning rate: 0.00846 
2025-02-26 08:22:48.497885: train_loss -0.4829 
2025-02-26 08:22:48.503901: val_loss -0.4249 
2025-02-26 08:22:48.507908: Pseudo dice [np.float32(0.4824)] 
2025-02-26 08:22:48.511418: Epoch time: 43.23 s 
2025-02-26 08:22:48.514931: Yayy! New best EMA pseudo Dice: 0.40720000863075256 
2025-02-26 08:22:49.185149:  
2025-02-26 08:22:49.190663: Epoch 18 
2025-02-26 08:22:49.194176: Current learning rate: 0.00836 
2025-02-26 08:23:32.422258: train_loss -0.5344 
2025-02-26 08:23:32.428317: val_loss -0.3946 
2025-02-26 08:23:32.431341: Pseudo dice [np.float32(0.5069)] 
2025-02-26 08:23:32.433671: Epoch time: 43.24 s 
2025-02-26 08:23:32.438236: Yayy! New best EMA pseudo Dice: 0.4171000123023987 
2025-02-26 08:23:33.108520:  
2025-02-26 08:23:33.114067: Epoch 19 
2025-02-26 08:23:33.117624: Current learning rate: 0.00827 
2025-02-26 08:24:16.308660: train_loss -0.5264 
2025-02-26 08:24:16.315181: val_loss -0.433 
2025-02-26 08:24:16.318763: Pseudo dice [np.float32(0.482)] 
2025-02-26 08:24:16.321296: Epoch time: 43.2 s 
2025-02-26 08:24:16.325942: Yayy! New best EMA pseudo Dice: 0.4235999882221222 
2025-02-26 08:24:16.987674:  
2025-02-26 08:24:16.993805: Epoch 20 
2025-02-26 08:24:16.997378: Current learning rate: 0.00818 
2025-02-26 08:25:00.200978: train_loss -0.5279 
2025-02-26 08:25:00.208098: val_loss -0.4255 
2025-02-26 08:25:00.211132: Pseudo dice [np.float32(0.5042)] 
2025-02-26 08:25:00.213674: Epoch time: 43.21 s 
2025-02-26 08:25:00.217744: Yayy! New best EMA pseudo Dice: 0.4316999912261963 
2025-02-26 08:25:01.060944:  
2025-02-26 08:25:01.066458: Epoch 21 
2025-02-26 08:25:01.069970: Current learning rate: 0.00809 
2025-02-26 08:25:44.285255: train_loss -0.5164 
2025-02-26 08:25:44.291850: val_loss -0.4954 
2025-02-26 08:25:44.295358: Pseudo dice [np.float32(0.5688)] 
2025-02-26 08:25:44.299377: Epoch time: 43.23 s 
2025-02-26 08:25:44.302887: Yayy! New best EMA pseudo Dice: 0.4453999996185303 
2025-02-26 08:25:44.935645:  
2025-02-26 08:25:44.941686: Epoch 22 
2025-02-26 08:25:44.945246: Current learning rate: 0.008 
2025-02-26 08:26:28.174536: train_loss -0.5454 
2025-02-26 08:26:28.180546: val_loss -0.5129 
2025-02-26 08:26:28.183555: Pseudo dice [np.float32(0.594)] 
2025-02-26 08:26:28.187066: Epoch time: 43.24 s 
2025-02-26 08:26:28.191081: Yayy! New best EMA pseudo Dice: 0.4602999985218048 
2025-02-26 08:26:28.828795:  
2025-02-26 08:26:28.834813: Epoch 23 
2025-02-26 08:26:28.837318: Current learning rate: 0.0079 
2025-02-26 08:27:12.059325: train_loss -0.5839 
2025-02-26 08:27:12.064897: val_loss -0.431 
2025-02-26 08:27:12.068427: Pseudo dice [np.float32(0.5581)] 
2025-02-26 08:27:12.071569: Epoch time: 43.23 s 
2025-02-26 08:27:12.076124: Yayy! New best EMA pseudo Dice: 0.4699999988079071 
2025-02-26 08:27:12.734987:  
2025-02-26 08:27:12.740547: Epoch 24 
2025-02-26 08:27:12.743111: Current learning rate: 0.00781 
2025-02-26 08:27:55.964743: train_loss -0.6088 
2025-02-26 08:27:55.971844: val_loss -0.5317 
2025-02-26 08:27:55.975356: Pseudo dice [np.float32(0.6137)] 
2025-02-26 08:27:55.978865: Epoch time: 43.23 s 
2025-02-26 08:27:55.982884: Yayy! New best EMA pseudo Dice: 0.4844000041484833 
2025-02-26 08:27:56.654891:  
2025-02-26 08:27:56.661022: Epoch 25 
2025-02-26 08:27:56.665049: Current learning rate: 0.00772 
2025-02-26 08:28:39.887191: train_loss -0.576 
2025-02-26 08:28:39.893705: val_loss -0.501 
2025-02-26 08:28:39.897214: Pseudo dice [np.float32(0.5899)] 
2025-02-26 08:28:39.901224: Epoch time: 43.23 s 
2025-02-26 08:28:39.904737: Yayy! New best EMA pseudo Dice: 0.4950000047683716 
2025-02-26 08:28:40.561145:  
2025-02-26 08:28:40.567169: Epoch 26 
2025-02-26 08:28:40.570671: Current learning rate: 0.00763 
2025-02-26 08:29:23.798550: train_loss -0.5925 
2025-02-26 08:29:23.804570: val_loss -0.4455 
2025-02-26 08:29:23.808078: Pseudo dice [np.float32(0.5201)] 
2025-02-26 08:29:23.811089: Epoch time: 43.24 s 
2025-02-26 08:29:23.815601: Yayy! New best EMA pseudo Dice: 0.4975000023841858 
2025-02-26 08:29:24.458425:  
2025-02-26 08:29:24.463955: Epoch 27 
2025-02-26 08:29:24.467494: Current learning rate: 0.00753 
2025-02-26 08:30:07.695816: train_loss -0.5889 
2025-02-26 08:30:07.701430: val_loss -0.4611 
2025-02-26 08:30:07.705493: Pseudo dice [np.float32(0.5142)] 
2025-02-26 08:30:07.708622: Epoch time: 43.24 s 
2025-02-26 08:30:07.712711: Yayy! New best EMA pseudo Dice: 0.499099999666214 
2025-02-26 08:30:08.375417:  
2025-02-26 08:30:08.381998: Epoch 28 
2025-02-26 08:30:08.385040: Current learning rate: 0.00744 
2025-02-26 08:30:51.607677: train_loss -0.5858 
2025-02-26 08:30:51.613694: val_loss -0.5271 
2025-02-26 08:30:51.617704: Pseudo dice [np.float32(0.592)] 
2025-02-26 08:30:51.620213: Epoch time: 43.23 s 
2025-02-26 08:30:51.623724: Yayy! New best EMA pseudo Dice: 0.508400022983551 
2025-02-26 08:30:52.435205:  
2025-02-26 08:30:52.440763: Epoch 29 
2025-02-26 08:30:52.444798: Current learning rate: 0.00735 
2025-02-26 08:31:35.656176: train_loss -0.5922 
2025-02-26 08:31:35.662308: val_loss -0.4489 
2025-02-26 08:31:35.665850: Pseudo dice [np.float32(0.5316)] 
2025-02-26 08:31:35.669391: Epoch time: 43.22 s 
2025-02-26 08:31:35.672622: Yayy! New best EMA pseudo Dice: 0.510699987411499 
2025-02-26 08:31:36.318094:  
2025-02-26 08:31:36.323612: Epoch 30 
2025-02-26 08:31:36.327122: Current learning rate: 0.00725 
2025-02-26 08:32:19.553531: train_loss -0.6016 
2025-02-26 08:32:19.558600: val_loss -0.4823 
2025-02-26 08:32:19.564723: Pseudo dice [np.float32(0.5791)] 
2025-02-26 08:32:19.569567: Epoch time: 43.24 s 
2025-02-26 08:32:19.573172: Yayy! New best EMA pseudo Dice: 0.5175999999046326 
2025-02-26 08:32:20.239668:  
2025-02-26 08:32:20.245686: Epoch 31 
2025-02-26 08:32:20.249194: Current learning rate: 0.00716 
2025-02-26 08:33:03.459435: train_loss -0.5879 
2025-02-26 08:33:03.465032: val_loss -0.4547 
2025-02-26 08:33:03.469161: Pseudo dice [np.float32(0.5579)] 
2025-02-26 08:33:03.472200: Epoch time: 43.22 s 
2025-02-26 08:33:03.475771: Yayy! New best EMA pseudo Dice: 0.5216000080108643 
2025-02-26 08:33:04.126173:  
2025-02-26 08:33:04.132241: Epoch 32 
2025-02-26 08:33:04.136296: Current learning rate: 0.00707 
2025-02-26 08:33:47.349241: train_loss -0.6023 
2025-02-26 08:33:47.354757: val_loss -0.4168 
2025-02-26 08:33:47.358268: Pseudo dice [np.float32(0.5133)] 
2025-02-26 08:33:47.362281: Epoch time: 43.22 s 
2025-02-26 08:33:47.861154:  
2025-02-26 08:33:47.867268: Epoch 33 
2025-02-26 08:33:47.870838: Current learning rate: 0.00697 
2025-02-26 08:34:31.075697: train_loss -0.591 
2025-02-26 08:34:31.082824: val_loss -0.5103 
2025-02-26 08:34:31.085871: Pseudo dice [np.float32(0.577)] 
2025-02-26 08:34:31.089172: Epoch time: 43.21 s 
2025-02-26 08:34:31.093678: Yayy! New best EMA pseudo Dice: 0.5264000296592712 
2025-02-26 08:34:31.756982:  
2025-02-26 08:34:31.761999: Epoch 34 
2025-02-26 08:34:31.765508: Current learning rate: 0.00688 
2025-02-26 08:35:14.978631: train_loss -0.5779 
2025-02-26 08:35:14.984220: val_loss -0.4532 
2025-02-26 08:35:14.988235: Pseudo dice [np.float32(0.572)] 
2025-02-26 08:35:14.991592: Epoch time: 43.22 s 
2025-02-26 08:35:14.995101: Yayy! New best EMA pseudo Dice: 0.531000018119812 
2025-02-26 08:35:15.675323:  
2025-02-26 08:35:15.680839: Epoch 35 
2025-02-26 08:35:15.684347: Current learning rate: 0.00679 
2025-02-26 08:35:58.889741: train_loss -0.5707 
2025-02-26 08:35:58.895754: val_loss -0.491 
2025-02-26 08:35:58.899771: Pseudo dice [np.float32(0.6389)] 
2025-02-26 08:35:58.903782: Epoch time: 43.22 s 
2025-02-26 08:35:58.908798: Yayy! New best EMA pseudo Dice: 0.541700005531311 
2025-02-26 08:35:59.582761:  
2025-02-26 08:35:59.587774: Epoch 36 
2025-02-26 08:35:59.591288: Current learning rate: 0.00669 
2025-02-26 08:36:42.801068: train_loss -0.5723 
2025-02-26 08:36:42.807583: val_loss -0.4945 
2025-02-26 08:36:42.811094: Pseudo dice [np.float32(0.6383)] 
2025-02-26 08:36:42.813602: Epoch time: 43.22 s 
2025-02-26 08:36:42.817619: Yayy! New best EMA pseudo Dice: 0.5514000058174133 
2025-02-26 08:36:43.645134:  
2025-02-26 08:36:43.650209: Epoch 37 
2025-02-26 08:36:43.654834: Current learning rate: 0.0066 
2025-02-26 08:37:26.850833: train_loss -0.6107 
2025-02-26 08:37:26.855890: val_loss -0.4129 
2025-02-26 08:37:26.862411: Pseudo dice [np.float32(0.5315)] 
2025-02-26 08:37:26.865921: Epoch time: 43.21 s 
2025-02-26 08:37:27.371810:  
2025-02-26 08:37:27.377849: Epoch 38 
2025-02-26 08:37:27.380903: Current learning rate: 0.0065 
2025-02-26 08:38:10.599589: train_loss -0.6387 
2025-02-26 08:38:10.605881: val_loss -0.5016 
2025-02-26 08:38:10.609398: Pseudo dice [np.float32(0.559)] 
2025-02-26 08:38:10.611956: Epoch time: 43.23 s 
2025-02-26 08:38:11.126927:  
2025-02-26 08:38:11.132995: Epoch 39 
2025-02-26 08:38:11.135626: Current learning rate: 0.00641 
2025-02-26 08:38:54.327065: train_loss -0.6304 
2025-02-26 08:38:54.333608: val_loss -0.4973 
2025-02-26 08:38:54.336620: Pseudo dice [np.float32(0.627)] 
2025-02-26 08:38:54.340130: Epoch time: 43.2 s 
2025-02-26 08:38:54.344142: Yayy! New best EMA pseudo Dice: 0.5580000281333923 
2025-02-26 08:38:55.027196:  
2025-02-26 08:38:55.032758: Epoch 40 
2025-02-26 08:38:55.036305: Current learning rate: 0.00631 
2025-02-26 08:39:38.305141: train_loss -0.6366 
2025-02-26 08:39:38.310664: val_loss -0.5708 
2025-02-26 08:39:38.315182: Pseudo dice [np.float32(0.6691)] 
2025-02-26 08:39:38.318401: Epoch time: 43.28 s 
2025-02-26 08:39:38.321911: Yayy! New best EMA pseudo Dice: 0.569100022315979 
2025-02-26 08:39:38.990583:  
2025-02-26 08:39:38.996206: Epoch 41 
2025-02-26 08:39:39.000250: Current learning rate: 0.00622 
2025-02-26 08:40:22.226600: train_loss -0.64 
2025-02-26 08:40:22.233118: val_loss -0.4625 
2025-02-26 08:40:22.238133: Pseudo dice [np.float32(0.5546)] 
2025-02-26 08:40:22.243152: Epoch time: 43.24 s 
2025-02-26 08:40:22.749268:  
2025-02-26 08:40:22.755352: Epoch 42 
2025-02-26 08:40:22.758890: Current learning rate: 0.00612 
2025-02-26 08:41:05.990647: train_loss -0.5993 
2025-02-26 08:41:05.996164: val_loss -0.5387 
2025-02-26 08:41:05.999672: Pseudo dice [np.float32(0.6418)] 
2025-02-26 08:41:06.002182: Epoch time: 43.24 s 
2025-02-26 08:41:06.006192: Yayy! New best EMA pseudo Dice: 0.5751000046730042 
2025-02-26 08:41:06.661448:  
2025-02-26 08:41:06.667005: Epoch 43 
2025-02-26 08:41:06.669542: Current learning rate: 0.00603 
2025-02-26 08:41:49.899917: train_loss -0.6248 
2025-02-26 08:41:49.905435: val_loss -0.4828 
2025-02-26 08:41:49.908946: Pseudo dice [np.float32(0.5799)] 
2025-02-26 08:41:49.912456: Epoch time: 43.24 s 
2025-02-26 08:41:49.916476: Yayy! New best EMA pseudo Dice: 0.5756000280380249 
2025-02-26 08:41:50.585076:  
2025-02-26 08:41:50.590607: Epoch 44 
2025-02-26 08:41:50.594148: Current learning rate: 0.00593 
2025-02-26 08:42:33.840950: train_loss -0.6344 
2025-02-26 08:42:33.845951: val_loss -0.5448 
2025-02-26 08:42:33.849469: Pseudo dice [np.float32(0.6264)] 
2025-02-26 08:42:33.853477: Epoch time: 43.26 s 
2025-02-26 08:42:33.856992: Yayy! New best EMA pseudo Dice: 0.5806000232696533 
2025-02-26 08:42:34.641613:  
2025-02-26 08:42:34.648266: Epoch 45 
2025-02-26 08:42:34.653827: Current learning rate: 0.00584 
2025-02-26 08:43:17.892159: train_loss -0.6033 
2025-02-26 08:43:17.897173: val_loss -0.5136 
2025-02-26 08:43:17.901183: Pseudo dice [np.float32(0.6386)] 
2025-02-26 08:43:17.903690: Epoch time: 43.25 s 
2025-02-26 08:43:17.908201: Yayy! New best EMA pseudo Dice: 0.5863999724388123 
2025-02-26 08:43:18.549669:  
2025-02-26 08:43:18.554422: Epoch 46 
2025-02-26 08:43:18.557933: Current learning rate: 0.00574 
2025-02-26 08:44:01.787763: train_loss -0.6453 
2025-02-26 08:44:01.793420: val_loss -0.5216 
2025-02-26 08:44:01.796975: Pseudo dice [np.float32(0.5846)] 
2025-02-26 08:44:01.800536: Epoch time: 43.24 s 
2025-02-26 08:44:02.287608:  
2025-02-26 08:44:02.293199: Epoch 47 
2025-02-26 08:44:02.296710: Current learning rate: 0.00565 
2025-02-26 08:44:45.528488: train_loss -0.6403 
2025-02-26 08:44:45.535598: val_loss -0.3285 
2025-02-26 08:44:45.539209: Pseudo dice [np.float32(0.5216)] 
2025-02-26 08:44:45.541723: Epoch time: 43.24 s 
2025-02-26 08:44:46.032837:  
2025-02-26 08:44:46.037898: Epoch 48 
2025-02-26 08:44:46.041430: Current learning rate: 0.00555 
2025-02-26 08:45:29.271943: train_loss -0.635 
2025-02-26 08:45:29.277956: val_loss -0.5862 
2025-02-26 08:45:29.281467: Pseudo dice [np.float32(0.6658)] 
2025-02-26 08:45:29.284480: Epoch time: 43.24 s 
2025-02-26 08:45:29.288994: Yayy! New best EMA pseudo Dice: 0.5884000062942505 
2025-02-26 08:45:29.945935:  
2025-02-26 08:45:29.950946: Epoch 49 
2025-02-26 08:45:29.954463: Current learning rate: 0.00546 
2025-02-26 08:46:13.206097: train_loss -0.6507 
2025-02-26 08:46:13.212172: val_loss -0.529 
2025-02-26 08:46:13.214685: Pseudo dice [np.float32(0.5911)] 
2025-02-26 08:46:13.218852: Epoch time: 43.26 s 
2025-02-26 08:46:13.359475: Yayy! New best EMA pseudo Dice: 0.588699996471405 
2025-02-26 08:46:14.014184:  
2025-02-26 08:46:14.019701: Epoch 50 
2025-02-26 08:46:14.023220: Current learning rate: 0.00536 
2025-02-26 08:46:57.271988: train_loss -0.6685 
2025-02-26 08:46:57.278618: val_loss -0.499 
2025-02-26 08:46:57.282202: Pseudo dice [np.float32(0.6389)] 
2025-02-26 08:46:57.285337: Epoch time: 43.26 s 
2025-02-26 08:46:57.288399: Yayy! New best EMA pseudo Dice: 0.5936999917030334 
2025-02-26 08:46:57.957038:  
2025-02-26 08:46:57.962570: Epoch 51 
2025-02-26 08:46:57.966149: Current learning rate: 0.00526 
2025-02-26 08:47:41.224266: train_loss -0.668 
2025-02-26 08:47:41.230779: val_loss -0.4399 
2025-02-26 08:47:41.234289: Pseudo dice [np.float32(0.5487)] 
2025-02-26 08:47:41.238308: Epoch time: 43.27 s 
2025-02-26 08:47:41.739197:  
2025-02-26 08:47:41.744758: Epoch 52 
2025-02-26 08:47:41.748824: Current learning rate: 0.00517 
2025-02-26 08:48:24.988615: train_loss -0.6458 
2025-02-26 08:48:24.994130: val_loss -0.5016 
2025-02-26 08:48:24.997640: Pseudo dice [np.float32(0.6474)] 
2025-02-26 08:48:25.000149: Epoch time: 43.25 s 
2025-02-26 08:48:25.004163: Yayy! New best EMA pseudo Dice: 0.5950000286102295 
2025-02-26 08:48:25.810401:  
2025-02-26 08:48:25.816570: Epoch 53 
2025-02-26 08:48:25.820144: Current learning rate: 0.00507 
2025-02-26 08:49:09.042102: train_loss -0.66 
2025-02-26 08:49:09.048216: val_loss -0.4747 
2025-02-26 08:49:09.052847: Pseudo dice [np.float32(0.5918)] 
2025-02-26 08:49:09.056389: Epoch time: 43.23 s 
2025-02-26 08:49:09.551150:  
2025-02-26 08:49:09.556755: Epoch 54 
2025-02-26 08:49:09.560319: Current learning rate: 0.00497 
2025-02-26 08:49:52.781028: train_loss -0.6475 
2025-02-26 08:49:52.786655: val_loss -0.4101 
2025-02-26 08:49:52.790251: Pseudo dice [np.float32(0.5191)] 
2025-02-26 08:49:52.792788: Epoch time: 43.23 s 
2025-02-26 08:49:53.297625:  
2025-02-26 08:49:53.303683: Epoch 55 
2025-02-26 08:49:53.306781: Current learning rate: 0.00487 
2025-02-26 08:50:36.549664: train_loss -0.6599 
2025-02-26 08:50:36.555741: val_loss -0.4591 
2025-02-26 08:50:36.559351: Pseudo dice [np.float32(0.5611)] 
2025-02-26 08:50:36.561859: Epoch time: 43.25 s 
2025-02-26 08:50:37.066450:  
2025-02-26 08:50:37.071965: Epoch 56 
2025-02-26 08:50:37.075475: Current learning rate: 0.00478 
2025-02-26 08:51:20.300130: train_loss -0.6562 
2025-02-26 08:51:20.306215: val_loss -0.4593 
2025-02-26 08:51:20.309752: Pseudo dice [np.float32(0.5688)] 
2025-02-26 08:51:20.312783: Epoch time: 43.23 s 
2025-02-26 08:51:20.815838:  
2025-02-26 08:51:20.821355: Epoch 57 
2025-02-26 08:51:20.824872: Current learning rate: 0.00468 
2025-02-26 08:52:04.060474: train_loss -0.6507 
2025-02-26 08:52:04.065498: val_loss -0.4884 
2025-02-26 08:52:04.069511: Pseudo dice [np.float32(0.5963)] 
2025-02-26 08:52:04.073021: Epoch time: 43.25 s 
2025-02-26 08:52:04.573751:  
2025-02-26 08:52:04.578783: Epoch 58 
2025-02-26 08:52:04.582814: Current learning rate: 0.00458 
2025-02-26 08:52:47.796656: train_loss -0.6332 
2025-02-26 08:52:47.804172: val_loss -0.5113 
2025-02-26 08:52:47.807682: Pseudo dice [np.float32(0.627)] 
2025-02-26 08:52:47.810191: Epoch time: 43.22 s 
2025-02-26 08:52:48.311782:  
2025-02-26 08:52:48.318337: Epoch 59 
2025-02-26 08:52:48.321916: Current learning rate: 0.00448 
2025-02-26 08:53:31.620202: train_loss -0.6613 
2025-02-26 08:53:31.626219: val_loss -0.5481 
2025-02-26 08:53:31.630240: Pseudo dice [np.float32(0.6514)] 
2025-02-26 08:53:31.633753: Epoch time: 43.31 s 
2025-02-26 08:53:32.147088:  
2025-02-26 08:53:32.152127: Epoch 60 
2025-02-26 08:53:32.156644: Current learning rate: 0.00438 
2025-02-26 08:54:15.368578: train_loss -0.6582 
2025-02-26 08:54:15.375157: val_loss -0.4992 
2025-02-26 08:54:15.379231: Pseudo dice [np.float32(0.591)] 
2025-02-26 08:54:15.383248: Epoch time: 43.22 s 
2025-02-26 08:54:16.049021:  
2025-02-26 08:54:16.054739: Epoch 61 
2025-02-26 08:54:16.058342: Current learning rate: 0.00429 
2025-02-26 08:54:59.287712: train_loss -0.6273 
2025-02-26 08:54:59.293226: val_loss -0.4179 
2025-02-26 08:54:59.297743: Pseudo dice [np.float32(0.581)] 
2025-02-26 08:54:59.301761: Epoch time: 43.24 s 
2025-02-26 08:54:59.809479:  
2025-02-26 08:54:59.816100: Epoch 62 
2025-02-26 08:54:59.820216: Current learning rate: 0.00419 
2025-02-26 08:55:43.044293: train_loss -0.6717 
2025-02-26 08:55:43.050380: val_loss -0.5858 
2025-02-26 08:55:43.054918: Pseudo dice [np.float32(0.6712)] 
2025-02-26 08:55:43.058547: Epoch time: 43.24 s 
2025-02-26 08:55:43.063143: Yayy! New best EMA pseudo Dice: 0.6008999943733215 
2025-02-26 08:55:43.732771:  
2025-02-26 08:55:43.739417: Epoch 63 
2025-02-26 08:55:43.741978: Current learning rate: 0.00409 
2025-02-26 08:56:26.962359: train_loss -0.6821 
2025-02-26 08:56:26.969110: val_loss -0.4562 
2025-02-26 08:56:26.972965: Pseudo dice [np.float32(0.6267)] 
2025-02-26 08:56:26.976482: Epoch time: 43.23 s 
2025-02-26 08:56:26.980698: Yayy! New best EMA pseudo Dice: 0.6035000085830688 
2025-02-26 08:56:27.639343:  
2025-02-26 08:56:27.645416: Epoch 64 
2025-02-26 08:56:27.649526: Current learning rate: 0.00399 
2025-02-26 08:57:10.887914: train_loss -0.6745 
2025-02-26 08:57:10.894440: val_loss -0.4327 
2025-02-26 08:57:10.898959: Pseudo dice [np.float32(0.5766)] 
2025-02-26 08:57:10.903219: Epoch time: 43.25 s 
2025-02-26 08:57:11.414484:  
2025-02-26 08:57:11.420503: Epoch 65 
2025-02-26 08:57:11.424515: Current learning rate: 0.00389 
2025-02-26 08:57:54.658835: train_loss -0.6854 
2025-02-26 08:57:54.664901: val_loss -0.4441 
2025-02-26 08:57:54.668530: Pseudo dice [np.float32(0.6168)] 
2025-02-26 08:57:54.672103: Epoch time: 43.24 s 
2025-02-26 08:57:55.173539:  
2025-02-26 08:57:55.180064: Epoch 66 
2025-02-26 08:57:55.183576: Current learning rate: 0.00379 
2025-02-26 08:58:38.405282: train_loss -0.6793 
2025-02-26 08:58:38.411347: val_loss -0.413 
2025-02-26 08:58:38.415411: Pseudo dice [np.float32(0.5492)] 
2025-02-26 08:58:38.419446: Epoch time: 43.23 s 
2025-02-26 08:58:38.928509:  
2025-02-26 08:58:38.935603: Epoch 67 
2025-02-26 08:58:38.939184: Current learning rate: 0.00369 
2025-02-26 08:59:22.172590: train_loss -0.7003 
2025-02-26 08:59:22.178799: val_loss -0.5249 
2025-02-26 08:59:22.182842: Pseudo dice [np.float32(0.6442)] 
2025-02-26 08:59:22.186384: Epoch time: 43.24 s 
2025-02-26 08:59:22.707458:  
2025-02-26 08:59:22.712971: Epoch 68 
2025-02-26 08:59:22.717480: Current learning rate: 0.00359 
2025-02-26 09:00:05.938714: train_loss -0.6894 
2025-02-26 09:00:05.945041: val_loss -0.3365 
2025-02-26 09:00:05.948084: Pseudo dice [np.float32(0.5744)] 
2025-02-26 09:00:05.952645: Epoch time: 43.23 s 
2025-02-26 09:00:06.616350:  
2025-02-26 09:00:06.622363: Epoch 69 
2025-02-26 09:00:06.626374: Current learning rate: 0.00349 
2025-02-26 09:00:50.230175: train_loss -0.6997 
2025-02-26 09:00:50.236691: val_loss -0.4502 
2025-02-26 09:00:50.240199: Pseudo dice [np.float32(0.6027)] 
2025-02-26 09:00:50.244212: Epoch time: 43.61 s 
2025-02-26 09:00:50.757617:  
2025-02-26 09:00:50.763739: Epoch 70 
2025-02-26 09:00:50.767253: Current learning rate: 0.00338 
2025-02-26 09:01:33.989532: train_loss -0.6783 
2025-02-26 09:01:33.995129: val_loss -0.4707 
2025-02-26 09:01:34.000673: Pseudo dice [np.float32(0.6078)] 
2025-02-26 09:01:34.004211: Epoch time: 43.23 s 
2025-02-26 09:01:34.528815:  
2025-02-26 09:01:34.534332: Epoch 71 
2025-02-26 09:01:34.537848: Current learning rate: 0.00328 
2025-02-26 09:02:17.768001: train_loss -0.6838 
2025-02-26 09:02:17.774518: val_loss -0.3548 
2025-02-26 09:02:17.778032: Pseudo dice [np.float32(0.5456)] 
2025-02-26 09:02:17.782045: Epoch time: 43.24 s 
2025-02-26 09:02:18.300985:  
2025-02-26 09:02:18.306498: Epoch 72 
2025-02-26 09:02:18.311011: Current learning rate: 0.00318 
2025-02-26 09:03:01.557564: train_loss -0.7027 
2025-02-26 09:03:01.563154: val_loss -0.5303 
2025-02-26 09:03:01.567696: Pseudo dice [np.float32(0.658)] 
2025-02-26 09:03:01.570239: Epoch time: 43.26 s 
2025-02-26 09:03:02.091400:  
2025-02-26 09:03:02.097933: Epoch 73 
2025-02-26 09:03:02.102486: Current learning rate: 0.00308 
2025-02-26 09:03:45.337064: train_loss -0.6822 
2025-02-26 09:03:45.343127: val_loss -0.4984 
2025-02-26 09:03:45.347217: Pseudo dice [np.float32(0.6252)] 
2025-02-26 09:03:45.350766: Epoch time: 43.25 s 
2025-02-26 09:03:45.356115: Yayy! New best EMA pseudo Dice: 0.6035000085830688 
2025-02-26 09:03:46.016735:  
2025-02-26 09:03:46.022283: Epoch 74 
2025-02-26 09:03:46.026866: Current learning rate: 0.00297 
2025-02-26 09:04:29.266763: train_loss -0.6988 
2025-02-26 09:04:29.273875: val_loss -0.4379 
2025-02-26 09:04:29.280056: Pseudo dice [np.float32(0.6011)] 
2025-02-26 09:04:29.283140: Epoch time: 43.25 s 
2025-02-26 09:04:29.809886:  
2025-02-26 09:04:29.814921: Epoch 75 
2025-02-26 09:04:29.819085: Current learning rate: 0.00287 
2025-02-26 09:05:13.022541: train_loss -0.7109 
2025-02-26 09:05:13.029066: val_loss -0.5076 
2025-02-26 09:05:13.032575: Pseudo dice [np.float32(0.67)] 
2025-02-26 09:05:13.035585: Epoch time: 43.21 s 
2025-02-26 09:05:13.039099: Yayy! New best EMA pseudo Dice: 0.6098999977111816 
2025-02-26 09:05:13.734556:  
2025-02-26 09:05:13.740577: Epoch 76 
2025-02-26 09:05:13.744080: Current learning rate: 0.00277 
2025-02-26 09:05:56.957573: train_loss -0.7053 
2025-02-26 09:05:56.963741: val_loss -0.4991 
2025-02-26 09:05:56.967315: Pseudo dice [np.float32(0.5555)] 
2025-02-26 09:05:56.970890: Epoch time: 43.22 s 
2025-02-26 09:05:57.630257:  
2025-02-26 09:05:57.635795: Epoch 77 
2025-02-26 09:05:57.638829: Current learning rate: 0.00266 
2025-02-26 09:06:40.863329: train_loss -0.7327 
2025-02-26 09:06:40.870846: val_loss -0.5542 
2025-02-26 09:06:40.874359: Pseudo dice [np.float32(0.6698)] 
2025-02-26 09:06:40.877367: Epoch time: 43.23 s 
2025-02-26 09:06:40.880386: Yayy! New best EMA pseudo Dice: 0.6110000014305115 
2025-02-26 09:06:41.547569:  
2025-02-26 09:06:41.554116: Epoch 78 
2025-02-26 09:06:41.557677: Current learning rate: 0.00256 
2025-02-26 09:07:24.769614: train_loss -0.7211 
2025-02-26 09:07:24.776309: val_loss -0.5214 
2025-02-26 09:07:24.779909: Pseudo dice [np.float32(0.715)] 
2025-02-26 09:07:24.783557: Epoch time: 43.22 s 
2025-02-26 09:07:24.787629: Yayy! New best EMA pseudo Dice: 0.621399998664856 
2025-02-26 09:07:25.476304:  
2025-02-26 09:07:25.482367: Epoch 79 
2025-02-26 09:07:25.485922: Current learning rate: 0.00245 
2025-02-26 09:08:08.716936: train_loss -0.7193 
2025-02-26 09:08:08.722452: val_loss -0.5047 
2025-02-26 09:08:08.725964: Pseudo dice [np.float32(0.6738)] 
2025-02-26 09:08:08.729974: Epoch time: 43.24 s 
2025-02-26 09:08:08.733486: Yayy! New best EMA pseudo Dice: 0.6266999840736389 
2025-02-26 09:08:09.413986:  
2025-02-26 09:08:09.419100: Epoch 80 
2025-02-26 09:08:09.422610: Current learning rate: 0.00235 
2025-02-26 09:08:52.640145: train_loss -0.7184 
2025-02-26 09:08:52.646736: val_loss -0.4777 
2025-02-26 09:08:52.650305: Pseudo dice [np.float32(0.6466)] 
2025-02-26 09:08:52.654877: Epoch time: 43.23 s 
2025-02-26 09:08:52.658463: Yayy! New best EMA pseudo Dice: 0.6287000179290771 
2025-02-26 09:08:53.353069:  
2025-02-26 09:08:53.359084: Epoch 81 
2025-02-26 09:08:53.362101: Current learning rate: 0.00224 
2025-02-26 09:09:36.581420: train_loss -0.7287 
2025-02-26 09:09:36.587494: val_loss -0.509 
2025-02-26 09:09:36.590559: Pseudo dice [np.float32(0.6185)] 
2025-02-26 09:09:36.595116: Epoch time: 43.23 s 
2025-02-26 09:09:37.115438:  
2025-02-26 09:09:37.121457: Epoch 82 
2025-02-26 09:09:37.124968: Current learning rate: 0.00214 
2025-02-26 09:10:20.183722: train_loss -0.731 
2025-02-26 09:10:20.190802: val_loss -0.4688 
2025-02-26 09:10:20.195314: Pseudo dice [np.float32(0.6505)] 
2025-02-26 09:10:20.198322: Epoch time: 43.07 s 
2025-02-26 09:10:20.202834: Yayy! New best EMA pseudo Dice: 0.6298999786376953 
2025-02-26 09:10:20.867657:  
2025-02-26 09:10:20.873676: Epoch 83 
2025-02-26 09:10:20.877687: Current learning rate: 0.00203 
2025-02-26 09:11:03.912270: train_loss -0.7417 
2025-02-26 09:11:03.918288: val_loss -0.4874 
2025-02-26 09:11:03.922298: Pseudo dice [np.float32(0.6859)] 
2025-02-26 09:11:03.925810: Epoch time: 43.05 s 
2025-02-26 09:11:03.929824: Yayy! New best EMA pseudo Dice: 0.6355000138282776 
2025-02-26 09:11:04.597117:  
2025-02-26 09:11:04.603156: Epoch 84 
2025-02-26 09:11:04.606718: Current learning rate: 0.00192 
2025-02-26 09:11:47.656367: train_loss -0.7325 
2025-02-26 09:11:47.663389: val_loss -0.4893 
2025-02-26 09:11:47.666402: Pseudo dice [np.float32(0.6258)] 
2025-02-26 09:11:47.669920: Epoch time: 43.06 s 
2025-02-26 09:11:48.307759:  
2025-02-26 09:11:48.313282: Epoch 85 
2025-02-26 09:11:48.316799: Current learning rate: 0.00181 
2025-02-26 09:12:31.432500: train_loss -0.724 
2025-02-26 09:12:31.438074: val_loss -0.5711 
2025-02-26 09:12:31.442158: Pseudo dice [np.float32(0.6555)] 
2025-02-26 09:12:31.445707: Epoch time: 43.13 s 
2025-02-26 09:12:31.449769: Yayy! New best EMA pseudo Dice: 0.6366999745368958 
2025-02-26 09:12:32.100881:  
2025-02-26 09:12:32.107399: Epoch 86 
2025-02-26 09:12:32.110907: Current learning rate: 0.0017 
2025-02-26 09:13:15.330503: train_loss -0.7293 
2025-02-26 09:13:15.336520: val_loss -0.5027 
2025-02-26 09:13:15.340533: Pseudo dice [np.float32(0.6691)] 
2025-02-26 09:13:15.344039: Epoch time: 43.23 s 
2025-02-26 09:13:15.348057: Yayy! New best EMA pseudo Dice: 0.6399000287055969 
2025-02-26 09:13:15.999930:  
2025-02-26 09:13:16.004943: Epoch 87 
2025-02-26 09:13:16.009569: Current learning rate: 0.00159 
2025-02-26 09:13:59.221115: train_loss -0.7451 
2025-02-26 09:13:59.227213: val_loss -0.4307 
2025-02-26 09:13:59.231258: Pseudo dice [np.float32(0.6513)] 
2025-02-26 09:13:59.234281: Epoch time: 43.22 s 
2025-02-26 09:13:59.238964: Yayy! New best EMA pseudo Dice: 0.640999972820282 
2025-02-26 09:13:59.900349:  
2025-02-26 09:13:59.906387: Epoch 88 
2025-02-26 09:13:59.909467: Current learning rate: 0.00148 
2025-02-26 09:14:43.125385: train_loss -0.7385 
2025-02-26 09:14:43.132932: val_loss -0.4676 
2025-02-26 09:14:43.138621: Pseudo dice [np.float32(0.6329)] 
2025-02-26 09:14:43.143635: Epoch time: 43.23 s 
2025-02-26 09:14:43.640946:  
2025-02-26 09:14:43.647514: Epoch 89 
2025-02-26 09:14:43.651181: Current learning rate: 0.00137 
2025-02-26 09:15:26.873817: train_loss -0.7605 
2025-02-26 09:15:26.880345: val_loss -0.4769 
2025-02-26 09:15:26.883358: Pseudo dice [np.float32(0.6691)] 
2025-02-26 09:15:26.886873: Epoch time: 43.23 s 
2025-02-26 09:15:26.890883: Yayy! New best EMA pseudo Dice: 0.6431000232696533 
2025-02-26 09:15:27.553999:  
2025-02-26 09:15:27.560014: Epoch 90 
2025-02-26 09:15:27.563521: Current learning rate: 0.00126 
2025-02-26 09:16:10.798119: train_loss -0.7525 
2025-02-26 09:16:10.804641: val_loss -0.4318 
2025-02-26 09:16:10.808148: Pseudo dice [np.float32(0.6499)] 
2025-02-26 09:16:10.811158: Epoch time: 43.24 s 
2025-02-26 09:16:10.815670: Yayy! New best EMA pseudo Dice: 0.6438000202178955 
2025-02-26 09:16:11.478369:  
2025-02-26 09:16:11.484010: Epoch 91 
2025-02-26 09:16:11.488077: Current learning rate: 0.00115 
2025-02-26 09:16:54.695159: train_loss -0.7367 
2025-02-26 09:16:54.702693: val_loss -0.407 
2025-02-26 09:16:54.706709: Pseudo dice [np.float32(0.636)] 
2025-02-26 09:16:54.710225: Epoch time: 43.22 s 
2025-02-26 09:16:55.212186:  
2025-02-26 09:16:55.216995: Epoch 92 
2025-02-26 09:16:55.221513: Current learning rate: 0.00103 
2025-02-26 09:17:38.440877: train_loss -0.7332 
2025-02-26 09:17:38.446892: val_loss -0.4728 
2025-02-26 09:17:38.450402: Pseudo dice [np.float32(0.6038)] 
2025-02-26 09:17:38.453413: Epoch time: 43.23 s 
2025-02-26 09:17:39.098456:  
2025-02-26 09:17:39.104547: Epoch 93 
2025-02-26 09:17:39.107625: Current learning rate: 0.00091 
2025-02-26 09:18:22.328991: train_loss -0.7407 
2025-02-26 09:18:22.335015: val_loss -0.4852 
2025-02-26 09:18:22.338027: Pseudo dice [np.float32(0.6638)] 
2025-02-26 09:18:22.341535: Epoch time: 43.23 s 
2025-02-26 09:18:22.830365:  
2025-02-26 09:18:22.836897: Epoch 94 
2025-02-26 09:18:22.840906: Current learning rate: 0.00079 
2025-02-26 09:19:06.057566: train_loss -0.7542 
2025-02-26 09:19:06.064258: val_loss -0.5686 
2025-02-26 09:19:06.069337: Pseudo dice [np.float32(0.7078)] 
2025-02-26 09:19:06.074980: Epoch time: 43.23 s 
2025-02-26 09:19:06.078998: Yayy! New best EMA pseudo Dice: 0.6481999754905701 
2025-02-26 09:19:06.719230:  
2025-02-26 09:19:06.725375: Epoch 95 
2025-02-26 09:19:06.729465: Current learning rate: 0.00067 
2025-02-26 09:19:49.922508: train_loss -0.7356 
2025-02-26 09:19:49.928599: val_loss -0.4604 
2025-02-26 09:19:49.932672: Pseudo dice [np.float32(0.6726)] 
2025-02-26 09:19:49.935182: Epoch time: 43.2 s 
2025-02-26 09:19:49.939800: Yayy! New best EMA pseudo Dice: 0.650600016117096 
2025-02-26 09:19:50.582640:  
2025-02-26 09:19:50.589164: Epoch 96 
2025-02-26 09:19:50.592671: Current learning rate: 0.00055 
2025-02-26 09:20:33.837836: train_loss -0.7517 
2025-02-26 09:20:33.843365: val_loss -0.4882 
2025-02-26 09:20:33.847995: Pseudo dice [np.float32(0.6889)] 
2025-02-26 09:20:33.850531: Epoch time: 43.26 s 
2025-02-26 09:20:33.856123: Yayy! New best EMA pseudo Dice: 0.6545000076293945 
2025-02-26 09:20:34.532022:  
2025-02-26 09:20:34.537644: Epoch 97 
2025-02-26 09:20:34.541733: Current learning rate: 0.00043 
2025-02-26 09:21:17.767930: train_loss -0.7521 
2025-02-26 09:21:17.775557: val_loss -0.4127 
2025-02-26 09:21:17.779086: Pseudo dice [np.float32(0.6278)] 
2025-02-26 09:21:17.783154: Epoch time: 43.24 s 
2025-02-26 09:21:18.288708:  
2025-02-26 09:21:18.294285: Epoch 98 
2025-02-26 09:21:18.298457: Current learning rate: 0.0003 
2025-02-26 09:22:01.528076: train_loss -0.7653 
2025-02-26 09:22:01.535092: val_loss -0.4773 
2025-02-26 09:22:01.539103: Pseudo dice [np.float32(0.6959)] 
2025-02-26 09:22:01.542614: Epoch time: 43.24 s 
2025-02-26 09:22:01.546633: Yayy! New best EMA pseudo Dice: 0.6561999917030334 
2025-02-26 09:22:02.206188:  
2025-02-26 09:22:02.212749: Epoch 99 
2025-02-26 09:22:02.216328: Current learning rate: 0.00016 
2025-02-26 09:22:45.463877: train_loss -0.7432 
2025-02-26 09:22:45.470443: val_loss -0.4447 
2025-02-26 09:22:45.474463: Pseudo dice [np.float32(0.6724)] 
2025-02-26 09:22:45.477980: Epoch time: 43.26 s 
2025-02-26 09:22:45.481988: Yayy! New best EMA pseudo Dice: 0.657800018787384 
2025-02-26 09:22:46.310448: Training done. 
2025-02-26 09:22:46.343967: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-02-26 09:22:46.350965: The split file contains 5 splits. 
2025-02-26 09:22:46.356965: Desired fold for training: 0 
2025-02-26 09:22:46.362964: This split has 100 training and 26 validation cases. 
2025-02-26 09:22:46.367965: predicting colon_008 
2025-02-26 09:22:46.374966: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-02-26 09:23:02.880136: predicting colon_027 
2025-02-26 09:23:02.900136: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-02-26 09:23:09.247561: predicting colon_030 
2025-02-26 09:23:09.260065: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-02-26 09:23:18.212359: predicting colon_033 
2025-02-26 09:23:18.230360: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-02-26 09:23:34.042340: predicting colon_041 
2025-02-26 09:23:34.064348: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-02-26 09:24:16.644567: predicting colon_042 
2025-02-26 09:24:16.681570: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-02-26 09:24:37.984096: predicting colon_061 
2025-02-26 09:24:38.005602: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-02-26 09:25:02.676534: predicting colon_074 
2025-02-26 09:25:02.702538: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-02-26 09:25:31.288997: predicting colon_075 
2025-02-26 09:25:31.313996: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-02-26 09:25:47.244370: predicting colon_088 
2025-02-26 09:25:47.266371: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-02-26 09:26:12.165311: predicting colon_091 
2025-02-26 09:26:12.190311: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-02-26 09:26:42.008899: predicting colon_092 
2025-02-26 09:26:42.035901: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-02-26 09:27:06.849626: predicting colon_095 
2025-02-26 09:27:06.869626: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-02-26 09:27:22.805951: predicting colon_102 
2025-02-26 09:27:22.826004: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-02-26 09:27:58.581346: predicting colon_111 
2025-02-26 09:27:58.611346: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-02-26 09:28:08.620647: predicting colon_115 
2025-02-26 09:28:08.638157: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-02-26 09:28:24.553663: predicting colon_118 
2025-02-26 09:28:24.575663: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-02-26 09:28:49.427253: predicting colon_124 
2025-02-26 09:28:49.452257: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-02-26 09:29:14.302957: predicting colon_127 
2025-02-26 09:29:14.325960: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-02-26 09:30:04.604974: predicting colon_154 
2025-02-26 09:30:04.640482: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-02-26 09:30:20.641230: predicting colon_161 
2025-02-26 09:30:20.664230: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-02-26 09:30:36.613882: predicting colon_162 
2025-02-26 09:30:36.636395: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-02-26 09:31:19.595224: predicting colon_165 
2025-02-26 09:31:19.626227: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-02-26 09:31:55.424378: predicting colon_166 
2025-02-26 09:31:55.449377: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-02-26 09:32:11.389732: predicting colon_169 
2025-02-26 09:32:11.410241: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-02-26 09:33:01.472343: predicting colon_187 
2025-02-26 09:33:01.511343: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-02-26 09:33:35.970320: Validation complete 
2025-02-26 09:33:35.977320: Mean Validation Dice:  0.2684891204024311 
