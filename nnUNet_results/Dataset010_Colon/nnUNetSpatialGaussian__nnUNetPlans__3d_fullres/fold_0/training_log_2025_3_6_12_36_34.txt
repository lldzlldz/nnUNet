
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-06 12:36:34.628048: do_dummy_2d_data_aug: True 
2025-03-06 12:36:34.652191: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-06 12:36:34.658838: The split file contains 5 splits. 
2025-03-06 12:36:34.661838: Desired fold for training: 0 
2025-03-06 12:36:34.664838: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-03-06 12:36:43.057939: unpacking dataset... 
2025-03-06 12:36:43.300054: unpacking done... 
2025-03-06 12:36:47.231539:  
2025-03-06 12:36:47.236557: Epoch 0 
2025-03-06 12:36:47.239062: Current learning rate: 0.01 
2025-03-06 12:38:19.356409: train_loss 0.0373 
2025-03-06 12:38:19.362431: val_loss 0.004 
2025-03-06 12:38:19.365591: Pseudo dice [np.float32(0.0)] 
2025-03-06 12:38:19.369099: Epoch time: 92.13 s 
2025-03-06 12:38:19.371605: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-06 12:38:20.033750:  
2025-03-06 12:38:20.039790: Epoch 1 
2025-03-06 12:38:20.042300: Current learning rate: 0.00991 
2025-03-06 12:39:43.476860: train_loss -0.0178 
2025-03-06 12:39:43.482376: val_loss -0.0799 
2025-03-06 12:39:43.485888: Pseudo dice [np.float32(0.0)] 
2025-03-06 12:39:43.489393: Epoch time: 83.44 s 
2025-03-06 12:39:44.032941:  
2025-03-06 12:39:44.038970: Epoch 2 
2025-03-06 12:39:44.043015: Current learning rate: 0.00982 
2025-03-06 12:41:07.442453: train_loss -0.142 
2025-03-06 12:41:07.448464: val_loss -0.2265 
2025-03-06 12:41:07.451475: Pseudo dice [np.float32(0.2958)] 
2025-03-06 12:41:07.454985: Epoch time: 83.41 s 
2025-03-06 12:41:07.457492: Yayy! New best EMA pseudo Dice: 0.029600000008940697 
2025-03-06 12:41:08.194679:  
2025-03-06 12:41:08.200735: Epoch 3 
2025-03-06 12:41:08.203806: Current learning rate: 0.00973 
2025-03-06 12:42:31.558660: train_loss -0.2759 
2025-03-06 12:42:31.566179: val_loss -0.3354 
2025-03-06 12:42:31.569684: Pseudo dice [np.float32(0.4237)] 
2025-03-06 12:42:31.572692: Epoch time: 83.36 s 
2025-03-06 12:42:31.575197: Yayy! New best EMA pseudo Dice: 0.0689999982714653 
2025-03-06 12:42:32.320695:  
2025-03-06 12:42:32.326210: Epoch 4 
2025-03-06 12:42:32.329723: Current learning rate: 0.00964 
2025-03-06 12:43:55.763891: train_loss -0.3044 
2025-03-06 12:43:55.769904: val_loss -0.3681 
2025-03-06 12:43:55.772917: Pseudo dice [np.float32(0.4369)] 
2025-03-06 12:43:55.776430: Epoch time: 83.44 s 
2025-03-06 12:43:55.780446: Yayy! New best EMA pseudo Dice: 0.10580000281333923 
2025-03-06 12:43:56.675956:  
2025-03-06 12:43:56.682479: Epoch 5 
2025-03-06 12:43:56.686020: Current learning rate: 0.00955 
2025-03-06 12:45:20.047423: train_loss -0.3621 
2025-03-06 12:45:20.053984: val_loss -0.2506 
2025-03-06 12:45:20.057020: Pseudo dice [np.float32(0.3365)] 
2025-03-06 12:45:20.061054: Epoch time: 83.37 s 
2025-03-06 12:45:20.064062: Yayy! New best EMA pseudo Dice: 0.12890000641345978 
2025-03-06 12:45:20.796126:  
2025-03-06 12:45:20.801139: Epoch 6 
2025-03-06 12:45:20.804647: Current learning rate: 0.00946 
2025-03-06 12:46:44.155858: train_loss -0.3229 
2025-03-06 12:46:44.161375: val_loss -0.4548 
2025-03-06 12:46:44.164886: Pseudo dice [np.float32(0.5285)] 
2025-03-06 12:46:44.168895: Epoch time: 83.36 s 
2025-03-06 12:46:44.171402: Yayy! New best EMA pseudo Dice: 0.1687999963760376 
2025-03-06 12:46:44.908624:  
2025-03-06 12:46:44.914141: Epoch 7 
2025-03-06 12:46:44.917653: Current learning rate: 0.00937 
2025-03-06 12:48:08.266834: train_loss -0.3834 
2025-03-06 12:48:08.273348: val_loss -0.3658 
2025-03-06 12:48:08.276858: Pseudo dice [np.float32(0.4185)] 
2025-03-06 12:48:08.279877: Epoch time: 83.36 s 
2025-03-06 12:48:08.282946: Yayy! New best EMA pseudo Dice: 0.19380000233650208 
2025-03-06 12:48:09.046011:  
2025-03-06 12:48:09.050973: Epoch 8 
2025-03-06 12:48:09.054486: Current learning rate: 0.00928 
2025-03-06 12:49:32.403445: train_loss -0.3957 
2025-03-06 12:49:32.408997: val_loss -0.4239 
2025-03-06 12:49:32.413057: Pseudo dice [np.float32(0.5031)] 
2025-03-06 12:49:32.416146: Epoch time: 83.36 s 
2025-03-06 12:49:32.419184: Yayy! New best EMA pseudo Dice: 0.22470000386238098 
2025-03-06 12:49:33.177744:  
2025-03-06 12:49:33.182953: Epoch 9 
2025-03-06 12:49:33.186466: Current learning rate: 0.00919 
2025-03-06 12:50:56.545485: train_loss -0.3692 
2025-03-06 12:50:56.552012: val_loss -0.4005 
2025-03-06 12:50:56.555525: Pseudo dice [np.float32(0.4667)] 
2025-03-06 12:50:56.558724: Epoch time: 83.37 s 
2025-03-06 12:50:56.561227: Yayy! New best EMA pseudo Dice: 0.24889999628067017 
2025-03-06 12:50:57.312510:  
2025-03-06 12:50:57.318116: Epoch 10 
2025-03-06 12:50:57.321666: Current learning rate: 0.0091 
2025-03-06 12:52:20.651053: train_loss -0.4271 
2025-03-06 12:52:20.656604: val_loss -0.3618 
2025-03-06 12:52:20.660113: Pseudo dice [np.float32(0.4763)] 
2025-03-06 12:52:20.662619: Epoch time: 83.34 s 
2025-03-06 12:52:20.666125: Yayy! New best EMA pseudo Dice: 0.271699994802475 
2025-03-06 12:52:21.390999:  
2025-03-06 12:52:21.396014: Epoch 11 
2025-03-06 12:52:21.399523: Current learning rate: 0.009 
2025-03-06 12:53:44.734688: train_loss -0.4157 
2025-03-06 12:53:44.740230: val_loss -0.3636 
2025-03-06 12:53:44.743742: Pseudo dice [np.float32(0.4606)] 
2025-03-06 12:53:44.747758: Epoch time: 83.34 s 
2025-03-06 12:53:44.750266: Yayy! New best EMA pseudo Dice: 0.2904999852180481 
2025-03-06 12:53:45.465596:  
2025-03-06 12:53:45.472152: Epoch 12 
2025-03-06 12:53:45.475214: Current learning rate: 0.00891 
2025-03-06 12:55:08.825969: train_loss -0.4162 
2025-03-06 12:55:08.831397: val_loss -0.4079 
2025-03-06 12:55:08.834920: Pseudo dice [np.float32(0.543)] 
2025-03-06 12:55:08.838327: Epoch time: 83.36 s 
2025-03-06 12:55:08.840835: Yayy! New best EMA pseudo Dice: 0.3158000111579895 
2025-03-06 12:55:09.710158:  
2025-03-06 12:55:09.715204: Epoch 13 
2025-03-06 12:55:09.718847: Current learning rate: 0.00882 
2025-03-06 12:56:33.049357: train_loss -0.4112 
2025-03-06 12:56:33.055380: val_loss -0.4267 
2025-03-06 12:56:33.059481: Pseudo dice [np.float32(0.5306)] 
2025-03-06 12:56:33.062540: Epoch time: 83.34 s 
2025-03-06 12:56:33.065575: Yayy! New best EMA pseudo Dice: 0.33730000257492065 
2025-03-06 12:56:33.795112:  
2025-03-06 12:56:33.800123: Epoch 14 
2025-03-06 12:56:33.803632: Current learning rate: 0.00873 
2025-03-06 12:57:57.094976: train_loss -0.4288 
2025-03-06 12:57:57.101548: val_loss -0.4429 
2025-03-06 12:57:57.104558: Pseudo dice [np.float32(0.5327)] 
2025-03-06 12:57:57.108067: Epoch time: 83.3 s 
2025-03-06 12:57:57.110576: Yayy! New best EMA pseudo Dice: 0.35679998993873596 
2025-03-06 12:57:57.822487:  
2025-03-06 12:57:57.828084: Epoch 15 
2025-03-06 12:57:57.830625: Current learning rate: 0.00864 
2025-03-06 12:59:21.149090: train_loss -0.466 
2025-03-06 12:59:21.155138: val_loss -0.4295 
2025-03-06 12:59:21.158650: Pseudo dice [np.float32(0.5262)] 
2025-03-06 12:59:21.162168: Epoch time: 83.33 s 
2025-03-06 12:59:21.165186: Yayy! New best EMA pseudo Dice: 0.37380000948905945 
2025-03-06 12:59:21.892148:  
2025-03-06 12:59:21.897170: Epoch 16 
2025-03-06 12:59:21.900840: Current learning rate: 0.00855 
2025-03-06 13:00:45.226129: train_loss -0.4443 
2025-03-06 13:00:45.231696: val_loss -0.3707 
2025-03-06 13:00:45.235756: Pseudo dice [np.float32(0.4817)] 
2025-03-06 13:00:45.239331: Epoch time: 83.34 s 
2025-03-06 13:00:45.242383: Yayy! New best EMA pseudo Dice: 0.38449999690055847 
2025-03-06 13:00:46.021413:  
2025-03-06 13:00:46.026988: Epoch 17 
2025-03-06 13:00:46.031042: Current learning rate: 0.00846 
2025-03-06 13:02:09.361670: train_loss -0.496 
2025-03-06 13:02:09.367248: val_loss -0.4127 
2025-03-06 13:02:09.371279: Pseudo dice [np.float32(0.5749)] 
2025-03-06 13:02:09.374288: Epoch time: 83.34 s 
2025-03-06 13:02:09.377798: Yayy! New best EMA pseudo Dice: 0.4036000072956085 
2025-03-06 13:02:10.106047:  
2025-03-06 13:02:10.111586: Epoch 18 
2025-03-06 13:02:10.115095: Current learning rate: 0.00836 
2025-03-06 13:03:33.446810: train_loss -0.5243 
2025-03-06 13:03:33.452824: val_loss -0.39 
2025-03-06 13:03:33.456330: Pseudo dice [np.float32(0.49)] 
2025-03-06 13:03:33.459340: Epoch time: 83.34 s 
2025-03-06 13:03:33.463853: Yayy! New best EMA pseudo Dice: 0.412200003862381 
2025-03-06 13:03:34.194452:  
2025-03-06 13:03:34.199965: Epoch 19 
2025-03-06 13:03:34.203476: Current learning rate: 0.00827 
2025-03-06 13:04:57.536757: train_loss -0.4764 
2025-03-06 13:04:57.543276: val_loss -0.3946 
2025-03-06 13:04:57.546781: Pseudo dice [np.float32(0.4681)] 
2025-03-06 13:04:57.550827: Epoch time: 83.34 s 
2025-03-06 13:04:57.553332: Yayy! New best EMA pseudo Dice: 0.41780000925064087 
2025-03-06 13:04:58.279993:  
2025-03-06 13:04:58.285507: Epoch 20 
2025-03-06 13:04:58.289017: Current learning rate: 0.00818 
2025-03-06 13:06:21.581061: train_loss -0.4776 
2025-03-06 13:06:21.587633: val_loss -0.3919 
2025-03-06 13:06:21.591142: Pseudo dice [np.float32(0.5155)] 
2025-03-06 13:06:21.593649: Epoch time: 83.3 s 
2025-03-06 13:06:21.597660: Yayy! New best EMA pseudo Dice: 0.4275999963283539 
2025-03-06 13:06:22.486257:  
2025-03-06 13:06:22.491772: Epoch 21 
2025-03-06 13:06:22.495282: Current learning rate: 0.00809 
2025-03-06 13:07:45.815161: train_loss -0.4924 
2025-03-06 13:07:45.821220: val_loss -0.4621 
2025-03-06 13:07:45.824727: Pseudo dice [np.float32(0.5759)] 
2025-03-06 13:07:45.827736: Epoch time: 83.33 s 
2025-03-06 13:07:45.831245: Yayy! New best EMA pseudo Dice: 0.4424000084400177 
2025-03-06 13:07:46.535668:  
2025-03-06 13:07:46.541183: Epoch 22 
2025-03-06 13:07:46.544693: Current learning rate: 0.008 
2025-03-06 13:09:09.843199: train_loss -0.5298 
2025-03-06 13:09:09.849715: val_loss -0.4589 
2025-03-06 13:09:09.853224: Pseudo dice [np.float32(0.5577)] 
2025-03-06 13:09:09.856729: Epoch time: 83.31 s 
2025-03-06 13:09:09.859739: Yayy! New best EMA pseudo Dice: 0.453900009393692 
2025-03-06 13:09:10.585702:  
2025-03-06 13:09:10.591737: Epoch 23 
2025-03-06 13:09:10.595749: Current learning rate: 0.0079 
2025-03-06 13:10:33.889597: train_loss -0.5116 
2025-03-06 13:10:33.896152: val_loss -0.4114 
2025-03-06 13:10:33.899660: Pseudo dice [np.float32(0.5334)] 
2025-03-06 13:10:33.903674: Epoch time: 83.3 s 
2025-03-06 13:10:33.907184: Yayy! New best EMA pseudo Dice: 0.461899995803833 
2025-03-06 13:10:34.611434:  
2025-03-06 13:10:34.618032: Epoch 24 
2025-03-06 13:10:34.621579: Current learning rate: 0.00781 
2025-03-06 13:11:57.981020: train_loss -0.5339 
2025-03-06 13:11:57.988038: val_loss -0.3633 
2025-03-06 13:11:57.991051: Pseudo dice [np.float32(0.4831)] 
2025-03-06 13:11:57.994611: Epoch time: 83.37 s 
2025-03-06 13:11:57.998359: Yayy! New best EMA pseudo Dice: 0.46399998664855957 
2025-03-06 13:11:58.732518:  
2025-03-06 13:11:58.738090: Epoch 25 
2025-03-06 13:11:58.740640: Current learning rate: 0.00772 
2025-03-06 13:13:22.045374: train_loss -0.5583 
2025-03-06 13:13:22.051396: val_loss -0.4267 
2025-03-06 13:13:22.055410: Pseudo dice [np.float32(0.6068)] 
2025-03-06 13:13:22.057916: Epoch time: 83.31 s 
2025-03-06 13:13:22.061426: Yayy! New best EMA pseudo Dice: 0.478300005197525 
2025-03-06 13:13:22.769861:  
2025-03-06 13:13:22.775891: Epoch 26 
2025-03-06 13:13:22.781182: Current learning rate: 0.00763 
2025-03-06 13:14:46.096526: train_loss -0.5762 
2025-03-06 13:14:46.104096: val_loss -0.4329 
2025-03-06 13:14:46.107154: Pseudo dice [np.float32(0.5468)] 
2025-03-06 13:14:46.110666: Epoch time: 83.33 s 
2025-03-06 13:14:46.114172: Yayy! New best EMA pseudo Dice: 0.48510000109672546 
2025-03-06 13:14:46.850760:  
2025-03-06 13:14:46.856830: Epoch 27 
2025-03-06 13:14:46.859871: Current learning rate: 0.00753 
2025-03-06 13:16:10.162546: train_loss -0.5335 
2025-03-06 13:16:10.168123: val_loss -0.4165 
2025-03-06 13:16:10.171639: Pseudo dice [np.float32(0.4882)] 
2025-03-06 13:16:10.174143: Epoch time: 83.31 s 
2025-03-06 13:16:10.178152: Yayy! New best EMA pseudo Dice: 0.48539999127388 
2025-03-06 13:16:10.888645:  
2025-03-06 13:16:10.894722: Epoch 28 
2025-03-06 13:16:10.898232: Current learning rate: 0.00744 
2025-03-06 13:17:34.174076: train_loss -0.5422 
2025-03-06 13:17:34.180091: val_loss -0.3465 
2025-03-06 13:17:34.182599: Pseudo dice [np.float32(0.4487)] 
2025-03-06 13:17:34.186104: Epoch time: 83.29 s 
2025-03-06 13:17:34.884500:  
2025-03-06 13:17:34.890067: Epoch 29 
2025-03-06 13:17:34.893614: Current learning rate: 0.00735 
2025-03-06 13:18:58.147358: train_loss -0.5151 
2025-03-06 13:18:58.152874: val_loss -0.4262 
2025-03-06 13:18:58.156383: Pseudo dice [np.float32(0.5922)] 
2025-03-06 13:18:58.159892: Epoch time: 83.26 s 
2025-03-06 13:18:58.162903: Yayy! New best EMA pseudo Dice: 0.4927999973297119 
2025-03-06 13:18:58.878649:  
2025-03-06 13:18:58.884686: Epoch 30 
2025-03-06 13:18:58.886695: Current learning rate: 0.00725 
2025-03-06 13:20:22.211022: train_loss -0.5559 
2025-03-06 13:20:22.216629: val_loss -0.416 
2025-03-06 13:20:22.219174: Pseudo dice [np.float32(0.5616)] 
2025-03-06 13:20:22.222769: Epoch time: 83.33 s 
2025-03-06 13:20:22.225797: Yayy! New best EMA pseudo Dice: 0.49970000982284546 
2025-03-06 13:20:22.945410:  
2025-03-06 13:20:22.950966: Epoch 31 
2025-03-06 13:20:22.954475: Current learning rate: 0.00716 
2025-03-06 13:21:46.229732: train_loss -0.5334 
2025-03-06 13:21:46.237763: val_loss -0.4055 
2025-03-06 13:21:46.241273: Pseudo dice [np.float32(0.5289)] 
2025-03-06 13:21:46.243779: Epoch time: 83.28 s 
2025-03-06 13:21:46.247495: Yayy! New best EMA pseudo Dice: 0.5026000142097473 
2025-03-06 13:21:46.965911:  
2025-03-06 13:21:46.970965: Epoch 32 
2025-03-06 13:21:46.974546: Current learning rate: 0.00707 
2025-03-06 13:23:10.283755: train_loss -0.5417 
2025-03-06 13:23:10.289207: val_loss -0.4841 
2025-03-06 13:23:10.292721: Pseudo dice [np.float32(0.5941)] 
2025-03-06 13:23:10.296236: Epoch time: 83.32 s 
2025-03-06 13:23:10.299252: Yayy! New best EMA pseudo Dice: 0.5117999911308289 
2025-03-06 13:23:11.023587:  
2025-03-06 13:23:11.029113: Epoch 33 
2025-03-06 13:23:11.032609: Current learning rate: 0.00697 
2025-03-06 13:24:34.680380: train_loss -0.5361 
2025-03-06 13:24:34.686404: val_loss -0.4421 
2025-03-06 13:24:34.690418: Pseudo dice [np.float32(0.5559)] 
2025-03-06 13:24:34.693927: Epoch time: 83.66 s 
2025-03-06 13:24:34.696433: Yayy! New best EMA pseudo Dice: 0.5162000060081482 
2025-03-06 13:24:35.413447:  
2025-03-06 13:24:35.419495: Epoch 34 
2025-03-06 13:24:35.423512: Current learning rate: 0.00688 
2025-03-06 13:25:58.725764: train_loss -0.584 
2025-03-06 13:25:58.731326: val_loss -0.3781 
2025-03-06 13:25:58.734857: Pseudo dice [np.float32(0.5751)] 
2025-03-06 13:25:58.738415: Epoch time: 83.31 s 
2025-03-06 13:25:58.741441: Yayy! New best EMA pseudo Dice: 0.5220999717712402 
2025-03-06 13:25:59.486524:  
2025-03-06 13:25:59.493044: Epoch 35 
2025-03-06 13:25:59.496557: Current learning rate: 0.00679 
2025-03-06 13:27:22.906309: train_loss -0.5868 
2025-03-06 13:27:22.912325: val_loss -0.4245 
2025-03-06 13:27:22.916086: Pseudo dice [np.float32(0.5143)] 
2025-03-06 13:27:22.919596: Epoch time: 83.42 s 
2025-03-06 13:27:23.503891:  
2025-03-06 13:27:23.508905: Epoch 36 
2025-03-06 13:27:23.512416: Current learning rate: 0.00669 
2025-03-06 13:28:46.810471: train_loss -0.5694 
2025-03-06 13:28:46.816083: val_loss -0.411 
2025-03-06 13:28:46.819134: Pseudo dice [np.float32(0.5432)] 
2025-03-06 13:28:46.822177: Epoch time: 83.31 s 
2025-03-06 13:28:46.825216: Yayy! New best EMA pseudo Dice: 0.5235000252723694 
2025-03-06 13:28:47.695591:  
2025-03-06 13:28:47.701156: Epoch 37 
2025-03-06 13:28:47.703710: Current learning rate: 0.0066 
2025-03-06 13:30:11.001818: train_loss -0.5672 
2025-03-06 13:30:11.007831: val_loss -0.4797 
2025-03-06 13:30:11.011846: Pseudo dice [np.float32(0.5762)] 
2025-03-06 13:30:11.014354: Epoch time: 83.31 s 
2025-03-06 13:30:11.018363: Yayy! New best EMA pseudo Dice: 0.5286999940872192 
2025-03-06 13:30:11.750647:  
2025-03-06 13:30:11.756201: Epoch 38 
2025-03-06 13:30:11.759741: Current learning rate: 0.0065 
2025-03-06 13:31:35.045306: train_loss -0.5572 
2025-03-06 13:31:35.050918: val_loss -0.4103 
2025-03-06 13:31:35.054427: Pseudo dice [np.float32(0.5133)] 
2025-03-06 13:31:35.056933: Epoch time: 83.3 s 
2025-03-06 13:31:35.625385:  
2025-03-06 13:31:35.630944: Epoch 39 
2025-03-06 13:31:35.633490: Current learning rate: 0.00641 
2025-03-06 13:32:58.925865: train_loss -0.5841 
2025-03-06 13:32:58.933384: val_loss -0.4491 
2025-03-06 13:32:58.937397: Pseudo dice [np.float32(0.6094)] 
2025-03-06 13:32:58.940682: Epoch time: 83.3 s 
2025-03-06 13:32:58.943191: Yayy! New best EMA pseudo Dice: 0.5353999733924866 
2025-03-06 13:32:59.688933:  
2025-03-06 13:32:59.695504: Epoch 40 
2025-03-06 13:32:59.698095: Current learning rate: 0.00631 
2025-03-06 13:34:23.074084: train_loss -0.5462 
2025-03-06 13:34:23.079096: val_loss -0.2785 
2025-03-06 13:34:23.082605: Pseudo dice [np.float32(0.4599)] 
2025-03-06 13:34:23.086111: Epoch time: 83.39 s 
2025-03-06 13:34:23.676269:  
2025-03-06 13:34:23.681281: Epoch 41 
2025-03-06 13:34:23.684790: Current learning rate: 0.00622 
2025-03-06 13:35:46.997734: train_loss -0.5644 
2025-03-06 13:35:47.005256: val_loss -0.4781 
2025-03-06 13:35:47.008269: Pseudo dice [np.float32(0.6076)] 
2025-03-06 13:35:47.011782: Epoch time: 83.32 s 
2025-03-06 13:35:47.015287: Yayy! New best EMA pseudo Dice: 0.5357999801635742 
2025-03-06 13:35:47.718333:  
2025-03-06 13:35:47.723347: Epoch 42 
2025-03-06 13:35:47.726857: Current learning rate: 0.00612 
2025-03-06 13:37:11.023654: train_loss -0.6078 
2025-03-06 13:37:11.029256: val_loss -0.4935 
2025-03-06 13:37:11.032385: Pseudo dice [np.float32(0.582)] 
2025-03-06 13:37:11.035432: Epoch time: 83.31 s 
2025-03-06 13:37:11.038448: Yayy! New best EMA pseudo Dice: 0.5404999852180481 
2025-03-06 13:37:11.749742:  
2025-03-06 13:37:11.754757: Epoch 43 
2025-03-06 13:37:11.758270: Current learning rate: 0.00603 
2025-03-06 13:38:35.060286: train_loss -0.5967 
2025-03-06 13:38:35.066803: val_loss -0.4575 
2025-03-06 13:38:35.070313: Pseudo dice [np.float32(0.5846)] 
2025-03-06 13:38:35.072823: Epoch time: 83.31 s 
2025-03-06 13:38:35.076836: Yayy! New best EMA pseudo Dice: 0.5449000000953674 
2025-03-06 13:38:35.784144:  
2025-03-06 13:38:35.789713: Epoch 44 
2025-03-06 13:38:35.792260: Current learning rate: 0.00593 
2025-03-06 13:39:59.100831: train_loss -0.5829 
2025-03-06 13:39:59.104355: val_loss -0.4127 
2025-03-06 13:39:59.107383: Pseudo dice [np.float32(0.5787)] 
2025-03-06 13:39:59.110406: Epoch time: 83.32 s 
2025-03-06 13:39:59.113446: Yayy! New best EMA pseudo Dice: 0.5482000112533569 
2025-03-06 13:39:59.819603:  
2025-03-06 13:39:59.825161: Epoch 45 
2025-03-06 13:39:59.828760: Current learning rate: 0.00584 
2025-03-06 13:41:23.190616: train_loss -0.6291 
2025-03-06 13:41:23.196633: val_loss -0.2341 
2025-03-06 13:41:23.199140: Pseudo dice [np.float32(0.5012)] 
2025-03-06 13:41:23.202645: Epoch time: 83.37 s 
2025-03-06 13:41:23.739862:  
2025-03-06 13:41:23.745417: Epoch 46 
2025-03-06 13:41:23.747956: Current learning rate: 0.00574 
2025-03-06 13:42:47.087530: train_loss -0.6046 
2025-03-06 13:42:47.093091: val_loss -0.1894 
2025-03-06 13:42:47.096650: Pseudo dice [np.float32(0.3986)] 
2025-03-06 13:42:47.098743: Epoch time: 83.35 s 
2025-03-06 13:42:47.636411:  
2025-03-06 13:42:47.641979: Epoch 47 
2025-03-06 13:42:47.645581: Current learning rate: 0.00565 
2025-03-06 13:44:10.941041: train_loss -0.5196 
2025-03-06 13:44:10.947105: val_loss -0.4289 
2025-03-06 13:44:10.950115: Pseudo dice [np.float32(0.5388)] 
2025-03-06 13:44:10.953624: Epoch time: 83.3 s 
2025-03-06 13:44:11.489820:  
2025-03-06 13:44:11.495368: Epoch 48 
2025-03-06 13:44:11.498938: Current learning rate: 0.00555 
2025-03-06 13:45:34.771042: train_loss -0.6127 
2025-03-06 13:45:34.776603: val_loss -0.4461 
2025-03-06 13:45:34.779635: Pseudo dice [np.float32(0.5617)] 
2025-03-06 13:45:34.783643: Epoch time: 83.28 s 
2025-03-06 13:45:35.381401:  
2025-03-06 13:45:35.387470: Epoch 49 
2025-03-06 13:45:35.390511: Current learning rate: 0.00546 
2025-03-06 13:46:58.680815: train_loss -0.6096 
2025-03-06 13:46:58.686877: val_loss -0.4352 
2025-03-06 13:46:58.689986: Pseudo dice [np.float32(0.5863)] 
2025-03-06 13:46:58.692492: Epoch time: 83.3 s 
2025-03-06 13:46:59.387982:  
2025-03-06 13:46:59.393533: Epoch 50 
2025-03-06 13:46:59.396075: Current learning rate: 0.00536 
2025-03-06 13:48:22.759902: train_loss -0.6291 
2025-03-06 13:48:22.765918: val_loss -0.4197 
2025-03-06 13:48:22.769425: Pseudo dice [np.float32(0.5729)] 
2025-03-06 13:48:22.772434: Epoch time: 83.37 s 
2025-03-06 13:48:23.320362:  
2025-03-06 13:48:23.325962: Epoch 51 
2025-03-06 13:48:23.328500: Current learning rate: 0.00526 
2025-03-06 13:49:46.661933: train_loss -0.6176 
2025-03-06 13:49:46.666944: val_loss -0.4652 
2025-03-06 13:49:46.670956: Pseudo dice [np.float32(0.6125)] 
2025-03-06 13:49:46.674467: Epoch time: 83.34 s 
2025-03-06 13:49:46.677974: Yayy! New best EMA pseudo Dice: 0.5490000247955322 
2025-03-06 13:49:47.390261:  
2025-03-06 13:49:47.395815: Epoch 52 
2025-03-06 13:49:47.398849: Current learning rate: 0.00517 
2025-03-06 13:51:10.691440: train_loss -0.6319 
2025-03-06 13:51:10.698975: val_loss -0.4167 
2025-03-06 13:51:10.702020: Pseudo dice [np.float32(0.5547)] 
2025-03-06 13:51:10.705106: Epoch time: 83.3 s 
2025-03-06 13:51:10.708621: Yayy! New best EMA pseudo Dice: 0.5496000051498413 
2025-03-06 13:51:11.417748:  
2025-03-06 13:51:11.423264: Epoch 53 
2025-03-06 13:51:11.426775: Current learning rate: 0.00507 
2025-03-06 13:52:34.788383: train_loss -0.65 
2025-03-06 13:52:34.793962: val_loss -0.426 
2025-03-06 13:52:34.798093: Pseudo dice [np.float32(0.61)] 
2025-03-06 13:52:34.801142: Epoch time: 83.37 s 
2025-03-06 13:52:34.803690: Yayy! New best EMA pseudo Dice: 0.5555999875068665 
2025-03-06 13:52:35.691120:  
2025-03-06 13:52:35.697636: Epoch 54 
2025-03-06 13:52:35.700143: Current learning rate: 0.00497 
2025-03-06 13:53:58.991758: train_loss -0.6004 
2025-03-06 13:53:58.998846: val_loss -0.4856 
2025-03-06 13:53:59.001886: Pseudo dice [np.float32(0.5825)] 
2025-03-06 13:53:59.005390: Epoch time: 83.3 s 
2025-03-06 13:53:59.008398: Yayy! New best EMA pseudo Dice: 0.5583000183105469 
2025-03-06 13:53:59.732374:  
2025-03-06 13:53:59.738890: Epoch 55 
2025-03-06 13:53:59.741395: Current learning rate: 0.00487 
2025-03-06 13:55:23.101688: train_loss -0.6183 
2025-03-06 13:55:23.107276: val_loss -0.3599 
2025-03-06 13:55:23.110077: Pseudo dice [np.float32(0.4983)] 
2025-03-06 13:55:23.113591: Epoch time: 83.37 s 
2025-03-06 13:55:23.671705:  
2025-03-06 13:55:23.676741: Epoch 56 
2025-03-06 13:55:23.680280: Current learning rate: 0.00478 
2025-03-06 13:56:46.983986: train_loss -0.639 
2025-03-06 13:56:46.990062: val_loss -0.4166 
2025-03-06 13:56:46.994071: Pseudo dice [np.float32(0.5701)] 
2025-03-06 13:56:46.997580: Epoch time: 83.31 s 
2025-03-06 13:56:47.548446:  
2025-03-06 13:56:47.553963: Epoch 57 
2025-03-06 13:56:47.558480: Current learning rate: 0.00468 
2025-03-06 13:58:10.828382: train_loss -0.6384 
2025-03-06 13:58:10.834670: val_loss -0.3871 
2025-03-06 13:58:10.838683: Pseudo dice [np.float32(0.5505)] 
2025-03-06 13:58:10.842193: Epoch time: 83.28 s 
2025-03-06 13:58:11.395141:  
2025-03-06 13:58:11.401163: Epoch 58 
2025-03-06 13:58:11.404665: Current learning rate: 0.00458 
2025-03-06 13:59:34.704605: train_loss -0.6255 
2025-03-06 13:59:34.711248: val_loss -0.4569 
2025-03-06 13:59:34.715261: Pseudo dice [np.float32(0.6312)] 
2025-03-06 13:59:34.718773: Epoch time: 83.31 s 
2025-03-06 13:59:34.722785: Yayy! New best EMA pseudo Dice: 0.5615000128746033 
2025-03-06 13:59:35.441653:  
2025-03-06 13:59:35.448281: Epoch 59 
2025-03-06 13:59:35.451853: Current learning rate: 0.00448 
2025-03-06 14:00:58.754833: train_loss -0.6551 
2025-03-06 14:00:58.761943: val_loss -0.3558 
2025-03-06 14:00:58.765992: Pseudo dice [np.float32(0.5614)] 
2025-03-06 14:00:58.769033: Epoch time: 83.31 s 
2025-03-06 14:00:59.326905:  
2025-03-06 14:00:59.333420: Epoch 60 
2025-03-06 14:00:59.336929: Current learning rate: 0.00438 
2025-03-06 14:02:22.671461: train_loss -0.6501 
2025-03-06 14:02:22.678522: val_loss -0.4693 
2025-03-06 14:02:22.682537: Pseudo dice [np.float32(0.6423)] 
2025-03-06 14:02:22.686551: Epoch time: 83.34 s 
2025-03-06 14:02:22.690065: Yayy! New best EMA pseudo Dice: 0.5695000290870667 
2025-03-06 14:02:23.454402:  
2025-03-06 14:02:23.459974: Epoch 61 
2025-03-06 14:02:23.464038: Current learning rate: 0.00429 
2025-03-06 14:03:46.806830: train_loss -0.6469 
2025-03-06 14:03:46.812934: val_loss -0.3603 
2025-03-06 14:03:46.816944: Pseudo dice [np.float32(0.5328)] 
2025-03-06 14:03:46.820452: Epoch time: 83.35 s 
2025-03-06 14:03:47.524756:  
2025-03-06 14:03:47.530824: Epoch 62 
2025-03-06 14:03:47.535457: Current learning rate: 0.00419 
2025-03-06 14:05:10.797827: train_loss -0.6443 
2025-03-06 14:05:10.804402: val_loss -0.4721 
2025-03-06 14:05:10.807914: Pseudo dice [np.float32(0.6247)] 
2025-03-06 14:05:10.811925: Epoch time: 83.27 s 
2025-03-06 14:05:10.815436: Yayy! New best EMA pseudo Dice: 0.5717999935150146 
2025-03-06 14:05:11.543683:  
2025-03-06 14:05:11.549198: Epoch 63 
2025-03-06 14:05:11.552706: Current learning rate: 0.00409 
2025-03-06 14:06:34.865499: train_loss -0.6472 
2025-03-06 14:06:34.871514: val_loss -0.4436 
2025-03-06 14:06:34.874020: Pseudo dice [np.float32(0.5738)] 
2025-03-06 14:06:34.878031: Epoch time: 83.32 s 
2025-03-06 14:06:34.880537: Yayy! New best EMA pseudo Dice: 0.5720000267028809 
2025-03-06 14:06:35.613444:  
2025-03-06 14:06:35.618460: Epoch 64 
2025-03-06 14:06:35.621969: Current learning rate: 0.00399 
2025-03-06 14:07:58.928091: train_loss -0.6647 
2025-03-06 14:07:58.936128: val_loss -0.3497 
2025-03-06 14:07:58.938634: Pseudo dice [np.float32(0.5612)] 
2025-03-06 14:07:58.942646: Epoch time: 83.32 s 
2025-03-06 14:07:59.511549:  
2025-03-06 14:07:59.517666: Epoch 65 
2025-03-06 14:07:59.520222: Current learning rate: 0.00389 
2025-03-06 14:09:22.825339: train_loss -0.6449 
2025-03-06 14:09:22.830350: val_loss -0.5121 
2025-03-06 14:09:22.834382: Pseudo dice [np.float32(0.6671)] 
2025-03-06 14:09:22.837011: Epoch time: 83.31 s 
2025-03-06 14:09:22.841072: Yayy! New best EMA pseudo Dice: 0.5805000066757202 
2025-03-06 14:09:23.576176:  
2025-03-06 14:09:23.581696: Epoch 66 
2025-03-06 14:09:23.584202: Current learning rate: 0.00379 
2025-03-06 14:10:46.859558: train_loss -0.6708 
2025-03-06 14:10:46.865577: val_loss -0.3815 
2025-03-06 14:10:46.868082: Pseudo dice [np.float32(0.5638)] 
2025-03-06 14:10:46.872094: Epoch time: 83.28 s 
2025-03-06 14:10:47.433098:  
2025-03-06 14:10:47.438653: Epoch 67 
2025-03-06 14:10:47.441234: Current learning rate: 0.00369 
2025-03-06 14:12:10.721709: train_loss -0.6596 
2025-03-06 14:12:10.728222: val_loss -0.4086 
2025-03-06 14:12:10.730728: Pseudo dice [np.float32(0.5695)] 
2025-03-06 14:12:10.734239: Epoch time: 83.29 s 
2025-03-06 14:12:11.301861:  
2025-03-06 14:12:11.308413: Epoch 68 
2025-03-06 14:12:11.311921: Current learning rate: 0.00359 
2025-03-06 14:13:34.625970: train_loss -0.6509 
2025-03-06 14:13:34.631053: val_loss -0.3446 
2025-03-06 14:13:34.633593: Pseudo dice [np.float32(0.5314)] 
2025-03-06 14:13:34.638165: Epoch time: 83.32 s 
2025-03-06 14:13:35.355457:  
2025-03-06 14:13:35.361083: Epoch 69 
2025-03-06 14:13:35.364648: Current learning rate: 0.00349 
2025-03-06 14:14:58.652385: train_loss -0.6416 
2025-03-06 14:14:58.660470: val_loss -0.4953 
2025-03-06 14:14:58.662976: Pseudo dice [np.float32(0.608)] 
2025-03-06 14:14:58.666486: Epoch time: 83.3 s 
2025-03-06 14:14:59.237637:  
2025-03-06 14:14:59.243199: Epoch 70 
2025-03-06 14:14:59.245798: Current learning rate: 0.00338 
2025-03-06 14:16:22.550970: train_loss -0.6794 
2025-03-06 14:16:22.556657: val_loss -0.3667 
2025-03-06 14:16:22.559682: Pseudo dice [np.float32(0.5333)] 
2025-03-06 14:16:22.563690: Epoch time: 83.31 s 
2025-03-06 14:16:23.136079:  
2025-03-06 14:16:23.141098: Epoch 71 
2025-03-06 14:16:23.144621: Current learning rate: 0.00328 
2025-03-06 14:17:46.430328: train_loss -0.6798 
2025-03-06 14:17:46.437362: val_loss -0.3599 
2025-03-06 14:17:46.439886: Pseudo dice [np.float32(0.5118)] 
2025-03-06 14:17:46.443395: Epoch time: 83.3 s 
2025-03-06 14:17:47.012836:  
2025-03-06 14:17:47.018404: Epoch 72 
2025-03-06 14:17:47.022012: Current learning rate: 0.00318 
2025-03-06 14:19:10.333708: train_loss -0.6626 
2025-03-06 14:19:10.338718: val_loss -0.43 
2025-03-06 14:19:10.342726: Pseudo dice [np.float32(0.633)] 
2025-03-06 14:19:10.345233: Epoch time: 83.32 s 
2025-03-06 14:19:10.917540:  
2025-03-06 14:19:10.923056: Epoch 73 
2025-03-06 14:19:10.925563: Current learning rate: 0.00308 
2025-03-06 14:20:34.207819: train_loss -0.6541 
2025-03-06 14:20:34.212835: val_loss -0.4498 
2025-03-06 14:20:34.216846: Pseudo dice [np.float32(0.6451)] 
2025-03-06 14:20:34.219354: Epoch time: 83.29 s 
2025-03-06 14:20:34.788660:  
2025-03-06 14:20:34.794737: Epoch 74 
2025-03-06 14:20:34.797761: Current learning rate: 0.00297 
2025-03-06 14:21:58.077914: train_loss -0.6866 
2025-03-06 14:21:58.084990: val_loss -0.5326 
2025-03-06 14:21:58.088002: Pseudo dice [np.float32(0.6529)] 
2025-03-06 14:21:58.091511: Epoch time: 83.29 s 
2025-03-06 14:21:58.094020: Yayy! New best EMA pseudo Dice: 0.5874999761581421 
2025-03-06 14:21:58.830834:  
2025-03-06 14:21:58.836395: Epoch 75 
2025-03-06 14:21:58.838982: Current learning rate: 0.00287 
2025-03-06 14:23:22.111154: train_loss -0.6956 
2025-03-06 14:23:22.116724: val_loss -0.4148 
2025-03-06 14:23:22.120270: Pseudo dice [np.float32(0.6131)] 
2025-03-06 14:23:22.123822: Epoch time: 83.28 s 
2025-03-06 14:23:22.126409: Yayy! New best EMA pseudo Dice: 0.5899999737739563 
2025-03-06 14:23:22.870796:  
2025-03-06 14:23:22.875807: Epoch 76 
2025-03-06 14:23:22.878815: Current learning rate: 0.00277 
2025-03-06 14:24:46.631681: train_loss -0.7049 
2025-03-06 14:24:46.637199: val_loss -0.4649 
2025-03-06 14:24:46.640711: Pseudo dice [np.float32(0.6289)] 
2025-03-06 14:24:46.644217: Epoch time: 83.76 s 
2025-03-06 14:24:46.647225: Yayy! New best EMA pseudo Dice: 0.5939000248908997 
2025-03-06 14:24:47.543885:  
2025-03-06 14:24:47.549456: Epoch 77 
2025-03-06 14:24:47.551995: Current learning rate: 0.00266 
2025-03-06 14:26:10.846441: train_loss -0.6861 
2025-03-06 14:26:10.852458: val_loss -0.3559 
2025-03-06 14:26:10.855964: Pseudo dice [np.float32(0.5814)] 
2025-03-06 14:26:10.858972: Epoch time: 83.3 s 
2025-03-06 14:26:11.435455:  
2025-03-06 14:26:11.441512: Epoch 78 
2025-03-06 14:26:11.444584: Current learning rate: 0.00256 
2025-03-06 14:27:34.725004: train_loss -0.6937 
2025-03-06 14:27:34.732043: val_loss -0.4556 
2025-03-06 14:27:34.734550: Pseudo dice [np.float32(0.5937)] 
2025-03-06 14:27:34.738062: Epoch time: 83.29 s 
2025-03-06 14:27:35.319673:  
2025-03-06 14:27:35.325210: Epoch 79 
2025-03-06 14:27:35.327715: Current learning rate: 0.00245 
2025-03-06 14:28:58.621601: train_loss -0.7058 
2025-03-06 14:28:58.625143: val_loss -0.3501 
2025-03-06 14:28:58.628695: Pseudo dice [np.float32(0.5787)] 
2025-03-06 14:28:58.631223: Epoch time: 83.3 s 
2025-03-06 14:28:59.214123:  
2025-03-06 14:28:59.220207: Epoch 80 
2025-03-06 14:28:59.223325: Current learning rate: 0.00235 
2025-03-06 14:30:22.555836: train_loss -0.689 
2025-03-06 14:30:22.560848: val_loss -0.3576 
2025-03-06 14:30:22.564360: Pseudo dice [np.float32(0.5947)] 
2025-03-06 14:30:22.568368: Epoch time: 83.34 s 
2025-03-06 14:30:23.153343:  
2025-03-06 14:30:23.158945: Epoch 81 
2025-03-06 14:30:23.162963: Current learning rate: 0.00224 
2025-03-06 14:31:46.494519: train_loss -0.6895 
2025-03-06 14:31:46.500533: val_loss -0.3628 
2025-03-06 14:31:46.504038: Pseudo dice [np.float32(0.6128)] 
2025-03-06 14:31:46.507048: Epoch time: 83.34 s 
2025-03-06 14:31:47.093173:  
2025-03-06 14:31:47.098186: Epoch 82 
2025-03-06 14:31:47.101696: Current learning rate: 0.00214 
2025-03-06 14:33:10.407133: train_loss -0.7013 
2025-03-06 14:33:10.412422: val_loss -0.4634 
2025-03-06 14:33:10.415935: Pseudo dice [np.float32(0.641)] 
2025-03-06 14:33:10.419449: Epoch time: 83.31 s 
2025-03-06 14:33:10.422463: Yayy! New best EMA pseudo Dice: 0.5985000133514404 
2025-03-06 14:33:11.146187:  
2025-03-06 14:33:11.151239: Epoch 83 
2025-03-06 14:33:11.154886: Current learning rate: 0.00203 
2025-03-06 14:34:34.517605: train_loss -0.6902 
2025-03-06 14:34:34.524123: val_loss -0.4646 
2025-03-06 14:34:34.526630: Pseudo dice [np.float32(0.6226)] 
2025-03-06 14:34:34.530140: Epoch time: 83.37 s 
2025-03-06 14:34:34.533647: Yayy! New best EMA pseudo Dice: 0.6008999943733215 
2025-03-06 14:34:35.255938:  
2025-03-06 14:34:35.260948: Epoch 84 
2025-03-06 14:34:35.264458: Current learning rate: 0.00192 
2025-03-06 14:36:00.392870: train_loss -0.7141 
2025-03-06 14:36:00.400011: val_loss -0.3927 
2025-03-06 14:36:00.404249: Pseudo dice [np.float32(0.5708)] 
2025-03-06 14:36:00.409802: Epoch time: 85.14 s 
2025-03-06 14:36:01.231441:  
2025-03-06 14:36:01.238025: Epoch 85 
2025-03-06 14:36:01.240562: Current learning rate: 0.00181 
2025-03-06 14:37:29.580460: train_loss -0.7058 
2025-03-06 14:37:29.586988: val_loss -0.4845 
2025-03-06 14:37:29.589998: Pseudo dice [np.float32(0.6732)] 
2025-03-06 14:37:29.593508: Epoch time: 88.35 s 
2025-03-06 14:37:29.597517: Yayy! New best EMA pseudo Dice: 0.605400025844574 
2025-03-06 14:37:30.309691:  
2025-03-06 14:37:30.314704: Epoch 86 
2025-03-06 14:37:30.319221: Current learning rate: 0.0017 
2025-03-06 14:38:54.569078: train_loss -0.7241 
2025-03-06 14:38:54.575621: val_loss -0.4624 
2025-03-06 14:38:54.580738: Pseudo dice [np.float32(0.6808)] 
2025-03-06 14:38:54.585752: Epoch time: 84.26 s 
2025-03-06 14:38:54.588257: Yayy! New best EMA pseudo Dice: 0.6129999756813049 
2025-03-06 14:38:55.300269:  
2025-03-06 14:38:55.306301: Epoch 87 
2025-03-06 14:38:55.309359: Current learning rate: 0.00159 
2025-03-06 14:40:19.556954: train_loss -0.714 
2025-03-06 14:40:19.562999: val_loss -0.3691 
2025-03-06 14:40:19.567010: Pseudo dice [np.float32(0.519)] 
2025-03-06 14:40:19.570519: Epoch time: 84.26 s 
2025-03-06 14:40:20.118979:  
2025-03-06 14:40:20.125570: Epoch 88 
2025-03-06 14:40:20.128113: Current learning rate: 0.00148 
2025-03-06 14:41:44.499419: train_loss -0.7197 
2025-03-06 14:41:44.505444: val_loss -0.4607 
2025-03-06 14:41:44.509454: Pseudo dice [np.float32(0.6354)] 
2025-03-06 14:41:44.512971: Epoch time: 84.38 s 
2025-03-06 14:41:45.128812:  
2025-03-06 14:41:45.134392: Epoch 89 
2025-03-06 14:41:45.137941: Current learning rate: 0.00137 
2025-03-06 14:43:09.327513: train_loss -0.7234 
2025-03-06 14:43:09.333558: val_loss -0.4884 
2025-03-06 14:43:09.337575: Pseudo dice [np.float32(0.6789)] 
2025-03-06 14:43:09.341596: Epoch time: 84.2 s 
2025-03-06 14:43:09.345107: Yayy! New best EMA pseudo Dice: 0.6140000224113464 
2025-03-06 14:43:10.050154:  
2025-03-06 14:43:10.055760: Epoch 90 
2025-03-06 14:43:10.059009: Current learning rate: 0.00126 
2025-03-06 14:44:34.324651: train_loss -0.7299 
2025-03-06 14:44:34.330674: val_loss -0.3475 
2025-03-06 14:44:34.333710: Pseudo dice [np.float32(0.5731)] 
2025-03-06 14:44:34.337219: Epoch time: 84.28 s 
2025-03-06 14:44:34.875447:  
2025-03-06 14:44:34.880467: Epoch 91 
2025-03-06 14:44:34.885483: Current learning rate: 0.00115 
2025-03-06 14:45:59.094466: train_loss -0.7441 
2025-03-06 14:45:59.101586: val_loss -0.3925 
2025-03-06 14:45:59.105094: Pseudo dice [np.float32(0.5864)] 
2025-03-06 14:45:59.109106: Epoch time: 84.22 s 
2025-03-06 14:45:59.696015:  
2025-03-06 14:45:59.701616: Epoch 92 
2025-03-06 14:45:59.706218: Current learning rate: 0.00103 
2025-03-06 14:47:23.939801: train_loss -0.7316 
2025-03-06 14:47:23.946491: val_loss -0.3909 
2025-03-06 14:47:23.950550: Pseudo dice [np.float32(0.5901)] 
2025-03-06 14:47:23.953101: Epoch time: 84.24 s 
2025-03-06 14:47:24.497524:  
2025-03-06 14:47:24.503042: Epoch 93 
2025-03-06 14:47:24.506555: Current learning rate: 0.00091 
2025-03-06 14:48:48.234969: train_loss -0.7319 
2025-03-06 14:48:48.241314: val_loss -0.448 
2025-03-06 14:48:48.244826: Pseudo dice [np.float32(0.5908)] 
2025-03-06 14:48:48.247838: Epoch time: 83.74 s 
2025-03-06 14:48:48.945361:  
2025-03-06 14:48:48.950878: Epoch 94 
2025-03-06 14:48:48.956907: Current learning rate: 0.00079 
2025-03-06 14:50:12.209996: train_loss -0.7246 
2025-03-06 14:50:12.216511: val_loss -0.4074 
2025-03-06 14:50:12.221023: Pseudo dice [np.float32(0.6057)] 
2025-03-06 14:50:12.225038: Epoch time: 83.27 s 
2025-03-06 14:50:12.761404:  
2025-03-06 14:50:12.766919: Epoch 95 
2025-03-06 14:50:12.771943: Current learning rate: 0.00067 
2025-03-06 14:51:36.026462: train_loss -0.7132 
2025-03-06 14:51:36.032001: val_loss -0.4723 
2025-03-06 14:51:36.037020: Pseudo dice [np.float32(0.6454)] 
2025-03-06 14:51:36.040540: Epoch time: 83.27 s 
2025-03-06 14:51:36.584048:  
2025-03-06 14:51:36.589644: Epoch 96 
2025-03-06 14:51:36.594731: Current learning rate: 0.00055 
2025-03-06 14:52:59.843763: train_loss -0.7281 
2025-03-06 14:52:59.851912: val_loss -0.322 
2025-03-06 14:52:59.855446: Pseudo dice [np.float32(0.5324)] 
2025-03-06 14:52:59.862070: Epoch time: 83.26 s 
2025-03-06 14:53:00.406129:  
2025-03-06 14:53:00.411645: Epoch 97 
2025-03-06 14:53:00.416664: Current learning rate: 0.00043 
2025-03-06 14:54:23.771623: train_loss -0.7408 
2025-03-06 14:54:23.778265: val_loss -0.4547 
2025-03-06 14:54:23.783276: Pseudo dice [np.float32(0.6595)] 
2025-03-06 14:54:23.787282: Epoch time: 83.37 s 
2025-03-06 14:54:24.329401:  
2025-03-06 14:54:24.335428: Epoch 98 
2025-03-06 14:54:24.340436: Current learning rate: 0.0003 
2025-03-06 14:55:47.610112: train_loss -0.7533 
2025-03-06 14:55:47.616651: val_loss -0.403 
2025-03-06 14:55:47.620667: Pseudo dice [np.float32(0.5481)] 
2025-03-06 14:55:47.625682: Epoch time: 83.28 s 
2025-03-06 14:55:48.172339:  
2025-03-06 14:55:48.177882: Epoch 99 
2025-03-06 14:55:48.181394: Current learning rate: 0.00016 
2025-03-06 14:57:11.434657: train_loss -0.7312 
2025-03-06 14:57:11.440681: val_loss -0.348 
2025-03-06 14:57:11.443944: Pseudo dice [np.float32(0.5436)] 
2025-03-06 14:57:11.447957: Epoch time: 83.26 s 
2025-03-06 14:57:12.211140: Training done. 
2025-03-06 14:57:12.238140: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-06 14:57:12.244140: The split file contains 5 splits. 
2025-03-06 14:57:12.250145: Desired fold for training: 0 
2025-03-06 14:57:12.255146: This split has 100 training and 26 validation cases. 
2025-03-06 14:57:12.261146: predicting colon_008 
2025-03-06 14:57:12.267593: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-03-06 14:57:28.401103: predicting colon_027 
2025-03-06 14:57:28.424102: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-03-06 14:57:34.650812: predicting colon_030 
2025-03-06 14:57:34.661812: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-03-06 14:57:43.406938: predicting colon_033 
2025-03-06 14:57:43.425938: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-03-06 14:57:58.917260: predicting colon_041 
2025-03-06 14:57:58.939259: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-03-06 14:58:40.683556: predicting colon_042 
2025-03-06 14:58:40.721070: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-03-06 14:59:01.641696: predicting colon_061 
2025-03-06 14:59:01.666696: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-03-06 14:59:25.847780: predicting colon_074 
2025-03-06 14:59:25.875780: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-03-06 14:59:53.757501: predicting colon_075 
2025-03-06 14:59:53.783006: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-03-06 15:00:09.300620: predicting colon_088 
2025-03-06 15:00:09.325620: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-03-06 15:00:33.524315: predicting colon_091 
2025-03-06 15:00:33.556314: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-03-06 15:01:02.574444: predicting colon_092 
2025-03-06 15:01:02.608954: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-03-06 15:01:26.801625: predicting colon_095 
2025-03-06 15:01:26.823629: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-03-06 15:01:42.381233: predicting colon_102 
2025-03-06 15:01:42.400233: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-03-06 15:02:17.182872: predicting colon_111 
2025-03-06 15:02:17.211874: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-03-06 15:02:26.942537: predicting colon_115 
2025-03-06 15:02:26.957539: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-03-06 15:02:42.464913: predicting colon_118 
2025-03-06 15:02:42.489934: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-03-06 15:03:06.671757: predicting colon_124 
2025-03-06 15:03:06.701266: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-03-06 15:03:30.915483: predicting colon_127 
2025-03-06 15:03:30.939483: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-03-06 15:04:19.637109: predicting colon_154 
2025-03-06 15:04:19.684618: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-03-06 15:04:35.219900: predicting colon_161 
2025-03-06 15:04:35.240904: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-03-06 15:04:50.796135: predicting colon_162 
2025-03-06 15:04:50.816138: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-03-06 15:05:32.648114: predicting colon_165 
2025-03-06 15:05:32.685115: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-03-06 15:06:07.544054: predicting colon_166 
2025-03-06 15:06:07.572053: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-03-06 15:06:23.093806: predicting colon_169 
2025-03-06 15:06:23.117806: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-03-06 15:07:11.875340: predicting colon_187 
2025-03-06 15:07:11.914847: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-03-06 15:07:45.795244: Validation complete 
2025-03-06 15:07:45.800245: Mean Validation Dice:  0.2091668510726035 
