
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-10 13:09:37.577477: do_dummy_2d_data_aug: True 
2025-03-10 13:09:37.586477: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-10 13:09:37.594476: The split file contains 5 splits. 
2025-03-10 13:09:37.597476: Desired fold for training: 0 
2025-03-10 13:09:37.600476: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-03-10 13:09:46.298951: unpacking dataset... 
2025-03-10 13:09:46.536971: unpacking done... 
2025-03-10 13:09:49.596288:  
2025-03-10 13:09:49.602302: Epoch 0 
2025-03-10 13:09:49.606316: Current learning rate: 0.01 
2025-03-10 13:11:22.079741: train_loss 0.0457 
2025-03-10 13:11:22.086798: val_loss 0.0008 
2025-03-10 13:11:22.089408: Pseudo dice [np.float32(0.0)] 
2025-03-10 13:11:22.093996: Epoch time: 92.48 s 
2025-03-10 13:11:22.096546: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-10 13:11:22.755233:  
2025-03-10 13:11:22.761305: Epoch 1 
2025-03-10 13:11:22.764365: Current learning rate: 0.00991 
2025-03-10 13:12:46.457871: train_loss -0.0153 
2025-03-10 13:12:46.463888: val_loss -0.0516 
2025-03-10 13:12:46.467898: Pseudo dice [np.float32(0.0)] 
2025-03-10 13:12:46.471408: Epoch time: 83.7 s 
2025-03-10 13:12:47.025712:  
2025-03-10 13:12:47.031789: Epoch 2 
2025-03-10 13:12:47.034854: Current learning rate: 0.00982 
2025-03-10 13:14:10.725727: train_loss -0.1459 
2025-03-10 13:14:10.732267: val_loss -0.2061 
2025-03-10 13:14:10.736276: Pseudo dice [np.float32(0.26)] 
2025-03-10 13:14:10.739305: Epoch time: 83.7 s 
2025-03-10 13:14:10.742353: Yayy! New best EMA pseudo Dice: 0.026000000536441803 
2025-03-10 13:14:11.484358:  
2025-03-10 13:14:11.490394: Epoch 3 
2025-03-10 13:14:11.493486: Current learning rate: 0.00973 
2025-03-10 13:15:35.154271: train_loss -0.1909 
2025-03-10 13:15:35.160788: val_loss -0.2533 
2025-03-10 13:15:35.164799: Pseudo dice [np.float32(0.2821)] 
2025-03-10 13:15:35.168308: Epoch time: 83.67 s 
2025-03-10 13:15:35.171814: Yayy! New best EMA pseudo Dice: 0.051600001752376556 
2025-03-10 13:15:35.919325:  
2025-03-10 13:15:35.924841: Epoch 4 
2025-03-10 13:15:35.928355: Current learning rate: 0.00964 
2025-03-10 13:16:59.715092: train_loss -0.3454 
2025-03-10 13:16:59.721611: val_loss -0.3221 
2025-03-10 13:16:59.725623: Pseudo dice [np.float32(0.4194)] 
2025-03-10 13:16:59.729133: Epoch time: 83.8 s 
2025-03-10 13:16:59.733146: Yayy! New best EMA pseudo Dice: 0.08839999884366989 
2025-03-10 13:17:00.631619:  
2025-03-10 13:17:00.638145: Epoch 5 
2025-03-10 13:17:00.641659: Current learning rate: 0.00955 
2025-03-10 13:18:24.335603: train_loss -0.3482 
2025-03-10 13:18:24.341719: val_loss -0.3587 
2025-03-10 13:18:24.345335: Pseudo dice [np.float32(0.4431)] 
2025-03-10 13:18:24.348901: Epoch time: 83.7 s 
2025-03-10 13:18:24.351966: Yayy! New best EMA pseudo Dice: 0.12389999628067017 
2025-03-10 13:18:25.106725:  
2025-03-10 13:18:25.112741: Epoch 6 
2025-03-10 13:18:25.116246: Current learning rate: 0.00946 
2025-03-10 13:19:48.757088: train_loss -0.3359 
2025-03-10 13:19:48.763607: val_loss -0.3196 
2025-03-10 13:19:48.769624: Pseudo dice [np.float32(0.3776)] 
2025-03-10 13:19:48.773637: Epoch time: 83.65 s 
2025-03-10 13:19:48.777644: Yayy! New best EMA pseudo Dice: 0.14920000731945038 
2025-03-10 13:19:49.506039:  
2025-03-10 13:19:49.513635: Epoch 7 
2025-03-10 13:19:49.516716: Current learning rate: 0.00937 
2025-03-10 13:21:13.135491: train_loss -0.3522 
2025-03-10 13:21:13.141680: val_loss -0.3349 
2025-03-10 13:21:13.145690: Pseudo dice [np.float32(0.4168)] 
2025-03-10 13:21:13.149202: Epoch time: 83.63 s 
2025-03-10 13:21:13.152712: Yayy! New best EMA pseudo Dice: 0.17599999904632568 
2025-03-10 13:21:13.960007:  
2025-03-10 13:21:13.967599: Epoch 8 
2025-03-10 13:21:13.971179: Current learning rate: 0.00928 
2025-03-10 13:22:37.624121: train_loss -0.395 
2025-03-10 13:22:37.630235: val_loss -0.2761 
2025-03-10 13:22:37.634821: Pseudo dice [np.float32(0.3239)] 
2025-03-10 13:22:37.638334: Epoch time: 83.66 s 
2025-03-10 13:22:37.642344: Yayy! New best EMA pseudo Dice: 0.1907999962568283 
2025-03-10 13:22:38.398149:  
2025-03-10 13:22:38.403192: Epoch 9 
2025-03-10 13:22:38.406298: Current learning rate: 0.00919 
2025-03-10 13:24:02.120767: train_loss -0.3908 
2025-03-10 13:24:02.127876: val_loss -0.3781 
2025-03-10 13:24:02.130654: Pseudo dice [np.float32(0.4418)] 
2025-03-10 13:24:02.134799: Epoch time: 83.72 s 
2025-03-10 13:24:02.138357: Yayy! New best EMA pseudo Dice: 0.2159000039100647 
2025-03-10 13:24:02.846832:  
2025-03-10 13:24:02.852861: Epoch 10 
2025-03-10 13:24:02.855897: Current learning rate: 0.0091 
2025-03-10 13:25:26.490996: train_loss -0.4341 
2025-03-10 13:25:26.497513: val_loss -0.4243 
2025-03-10 13:25:26.502025: Pseudo dice [np.float32(0.5516)] 
2025-03-10 13:25:26.505036: Epoch time: 83.65 s 
2025-03-10 13:25:26.508587: Yayy! New best EMA pseudo Dice: 0.24950000643730164 
2025-03-10 13:25:27.296268:  
2025-03-10 13:25:27.301874: Epoch 11 
2025-03-10 13:25:27.305413: Current learning rate: 0.009 
2025-03-10 13:26:50.925692: train_loss -0.4205 
2025-03-10 13:26:50.932237: val_loss -0.3646 
2025-03-10 13:26:50.935753: Pseudo dice [np.float32(0.4612)] 
2025-03-10 13:26:50.939394: Epoch time: 83.63 s 
2025-03-10 13:26:50.942428: Yayy! New best EMA pseudo Dice: 0.27059999108314514 
2025-03-10 13:26:51.647009:  
2025-03-10 13:26:51.653024: Epoch 12 
2025-03-10 13:26:51.656532: Current learning rate: 0.00891 
2025-03-10 13:28:15.286119: train_loss -0.4463 
2025-03-10 13:28:15.292638: val_loss -0.4109 
2025-03-10 13:28:15.296675: Pseudo dice [np.float32(0.5007)] 
2025-03-10 13:28:15.300186: Epoch time: 83.64 s 
2025-03-10 13:28:15.303691: Yayy! New best EMA pseudo Dice: 0.2935999929904938 
2025-03-10 13:28:16.170354:  
2025-03-10 13:28:16.175385: Epoch 13 
2025-03-10 13:28:16.178915: Current learning rate: 0.00882 
2025-03-10 13:29:40.141376: train_loss -0.4239 
2025-03-10 13:29:40.149420: val_loss -0.4303 
2025-03-10 13:29:40.153434: Pseudo dice [np.float32(0.4941)] 
2025-03-10 13:29:40.156945: Epoch time: 83.97 s 
2025-03-10 13:29:40.160450: Yayy! New best EMA pseudo Dice: 0.31369999051094055 
2025-03-10 13:29:40.884046:  
2025-03-10 13:29:40.890126: Epoch 14 
2025-03-10 13:29:40.893201: Current learning rate: 0.00873 
2025-03-10 13:31:04.621114: train_loss -0.4612 
2025-03-10 13:31:04.628093: val_loss -0.4574 
2025-03-10 13:31:04.631600: Pseudo dice [np.float32(0.5147)] 
2025-03-10 13:31:04.634610: Epoch time: 83.74 s 
2025-03-10 13:31:04.638119: Yayy! New best EMA pseudo Dice: 0.33379998803138733 
2025-03-10 13:31:05.522910:  
2025-03-10 13:31:05.527924: Epoch 15 
2025-03-10 13:31:05.532433: Current learning rate: 0.00864 
2025-03-10 13:32:29.319685: train_loss -0.4878 
2025-03-10 13:32:29.325726: val_loss -0.4511 
2025-03-10 13:32:29.329234: Pseudo dice [np.float32(0.5635)] 
2025-03-10 13:32:29.333248: Epoch time: 83.8 s 
2025-03-10 13:32:29.336756: Yayy! New best EMA pseudo Dice: 0.35679998993873596 
2025-03-10 13:32:30.065207:  
2025-03-10 13:32:30.070766: Epoch 16 
2025-03-10 13:32:30.075399: Current learning rate: 0.00855 
2025-03-10 13:33:53.807651: train_loss -0.4823 
2025-03-10 13:33:53.814018: val_loss -0.374 
2025-03-10 13:33:53.818041: Pseudo dice [np.float32(0.4937)] 
2025-03-10 13:33:53.821555: Epoch time: 83.74 s 
2025-03-10 13:33:53.824065: Yayy! New best EMA pseudo Dice: 0.37040001153945923 
2025-03-10 13:33:54.720436:  
2025-03-10 13:33:54.726472: Epoch 17 
2025-03-10 13:33:54.729500: Current learning rate: 0.00846 
2025-03-10 13:35:18.319467: train_loss -0.4394 
2025-03-10 13:35:18.325593: val_loss -0.3539 
2025-03-10 13:35:18.329208: Pseudo dice [np.float32(0.4413)] 
2025-03-10 13:35:18.332758: Epoch time: 83.6 s 
2025-03-10 13:35:18.336318: Yayy! New best EMA pseudo Dice: 0.3774999976158142 
2025-03-10 13:35:19.081371:  
2025-03-10 13:35:19.087430: Epoch 18 
2025-03-10 13:35:19.090493: Current learning rate: 0.00836 
2025-03-10 13:36:42.650860: train_loss -0.4876 
2025-03-10 13:36:42.656377: val_loss -0.325 
2025-03-10 13:36:42.660410: Pseudo dice [np.float32(0.4132)] 
2025-03-10 13:36:42.663965: Epoch time: 83.57 s 
2025-03-10 13:36:42.667480: Yayy! New best EMA pseudo Dice: 0.38109999895095825 
2025-03-10 13:36:43.397462:  
2025-03-10 13:36:43.403503: Epoch 19 
2025-03-10 13:36:43.407012: Current learning rate: 0.00827 
2025-03-10 13:38:07.117473: train_loss -0.4639 
2025-03-10 13:38:07.124993: val_loss -0.433 
2025-03-10 13:38:07.128519: Pseudo dice [np.float32(0.5121)] 
2025-03-10 13:38:07.131545: Epoch time: 83.72 s 
2025-03-10 13:38:07.135055: Yayy! New best EMA pseudo Dice: 0.39419999718666077 
2025-03-10 13:38:07.955492:  
2025-03-10 13:38:07.961538: Epoch 20 
2025-03-10 13:38:07.966050: Current learning rate: 0.00818 
2025-03-10 13:39:31.514962: train_loss -0.4589 
2025-03-10 13:39:31.522255: val_loss -0.4157 
2025-03-10 13:39:31.526271: Pseudo dice [np.float32(0.5369)] 
2025-03-10 13:39:31.528783: Epoch time: 83.56 s 
2025-03-10 13:39:31.532294: Yayy! New best EMA pseudo Dice: 0.40849998593330383 
2025-03-10 13:39:32.425318:  
2025-03-10 13:39:32.431904: Epoch 21 
2025-03-10 13:39:32.435964: Current learning rate: 0.00809 
2025-03-10 13:40:56.065903: train_loss -0.5234 
2025-03-10 13:40:56.072470: val_loss -0.4939 
2025-03-10 13:40:56.076489: Pseudo dice [np.float32(0.5822)] 
2025-03-10 13:40:56.080000: Epoch time: 83.64 s 
2025-03-10 13:40:56.083506: Yayy! New best EMA pseudo Dice: 0.42579999566078186 
2025-03-10 13:40:56.787182:  
2025-03-10 13:40:56.792736: Epoch 22 
2025-03-10 13:40:56.797305: Current learning rate: 0.008 
2025-03-10 13:42:20.379528: train_loss -0.4945 
2025-03-10 13:42:20.386582: val_loss -0.4404 
2025-03-10 13:42:20.389645: Pseudo dice [np.float32(0.5019)] 
2025-03-10 13:42:20.393154: Epoch time: 83.59 s 
2025-03-10 13:42:20.397165: Yayy! New best EMA pseudo Dice: 0.4334999918937683 
2025-03-10 13:42:21.108309:  
2025-03-10 13:42:21.113868: Epoch 23 
2025-03-10 13:42:21.117905: Current learning rate: 0.0079 
2025-03-10 13:43:44.723346: train_loss -0.5098 
2025-03-10 13:43:44.730961: val_loss -0.3472 
2025-03-10 13:43:44.734026: Pseudo dice [np.float32(0.4869)] 
2025-03-10 13:43:44.738559: Epoch time: 83.62 s 
2025-03-10 13:43:44.741067: Yayy! New best EMA pseudo Dice: 0.43880000710487366 
2025-03-10 13:43:45.447076:  
2025-03-10 13:43:45.453089: Epoch 24 
2025-03-10 13:43:45.457098: Current learning rate: 0.00781 
2025-03-10 13:45:09.130458: train_loss -0.4868 
2025-03-10 13:45:09.136971: val_loss -0.3842 
2025-03-10 13:45:09.141485: Pseudo dice [np.float32(0.4824)] 
2025-03-10 13:45:09.144495: Epoch time: 83.68 s 
2025-03-10 13:45:09.148004: Yayy! New best EMA pseudo Dice: 0.4431999921798706 
2025-03-10 13:45:09.857663:  
2025-03-10 13:45:09.864184: Epoch 25 
2025-03-10 13:45:09.867689: Current learning rate: 0.00772 
2025-03-10 13:46:33.466997: train_loss -0.4817 
2025-03-10 13:46:33.473068: val_loss -0.3972 
2025-03-10 13:46:33.477582: Pseudo dice [np.float32(0.4647)] 
2025-03-10 13:46:33.480592: Epoch time: 83.61 s 
2025-03-10 13:46:33.484105: Yayy! New best EMA pseudo Dice: 0.44530001282691956 
2025-03-10 13:46:34.202563:  
2025-03-10 13:46:34.209675: Epoch 26 
2025-03-10 13:46:34.213190: Current learning rate: 0.00763 
2025-03-10 13:47:57.789400: train_loss -0.536 
2025-03-10 13:47:57.795914: val_loss -0.3916 
2025-03-10 13:47:57.799424: Pseudo dice [np.float32(0.5714)] 
2025-03-10 13:47:57.803436: Epoch time: 83.59 s 
2025-03-10 13:47:57.806945: Yayy! New best EMA pseudo Dice: 0.4578999876976013 
2025-03-10 13:47:58.517340:  
2025-03-10 13:47:58.523370: Epoch 27 
2025-03-10 13:47:58.526880: Current learning rate: 0.00753 
2025-03-10 13:49:22.156358: train_loss -0.5282 
2025-03-10 13:49:22.162872: val_loss -0.4243 
2025-03-10 13:49:22.166380: Pseudo dice [np.float32(0.5137)] 
2025-03-10 13:49:22.170392: Epoch time: 83.64 s 
2025-03-10 13:49:22.173904: Yayy! New best EMA pseudo Dice: 0.4634999930858612 
2025-03-10 13:49:23.024257:  
2025-03-10 13:49:23.030276: Epoch 28 
2025-03-10 13:49:23.034286: Current learning rate: 0.00744 
2025-03-10 13:50:46.677100: train_loss -0.5204 
2025-03-10 13:50:46.684704: val_loss -0.4692 
2025-03-10 13:50:46.688277: Pseudo dice [np.float32(0.5537)] 
2025-03-10 13:50:46.692320: Epoch time: 83.65 s 
2025-03-10 13:50:46.695382: Yayy! New best EMA pseudo Dice: 0.4724999964237213 
2025-03-10 13:50:47.578601:  
2025-03-10 13:50:47.583652: Epoch 29 
2025-03-10 13:50:47.587814: Current learning rate: 0.00735 
2025-03-10 13:52:11.232129: train_loss -0.5575 
2025-03-10 13:52:11.238141: val_loss -0.4233 
2025-03-10 13:52:11.241150: Pseudo dice [np.float32(0.5693)] 
2025-03-10 13:52:11.245663: Epoch time: 83.65 s 
2025-03-10 13:52:11.248674: Yayy! New best EMA pseudo Dice: 0.4821999967098236 
2025-03-10 13:52:11.980244:  
2025-03-10 13:52:11.985260: Epoch 30 
2025-03-10 13:52:11.988772: Current learning rate: 0.00725 
2025-03-10 13:53:35.605529: train_loss -0.5377 
2025-03-10 13:53:35.611544: val_loss -0.4582 
2025-03-10 13:53:35.615554: Pseudo dice [np.float32(0.5899)] 
2025-03-10 13:53:35.619065: Epoch time: 83.63 s 
2025-03-10 13:53:35.623076: Yayy! New best EMA pseudo Dice: 0.49300000071525574 
2025-03-10 13:53:36.374356:  
2025-03-10 13:53:36.380380: Epoch 31 
2025-03-10 13:53:36.383888: Current learning rate: 0.00716 
2025-03-10 13:54:59.968398: train_loss -0.5536 
2025-03-10 13:54:59.975515: val_loss -0.4338 
2025-03-10 13:54:59.979582: Pseudo dice [np.float32(0.5266)] 
2025-03-10 13:54:59.983157: Epoch time: 83.6 s 
2025-03-10 13:54:59.986707: Yayy! New best EMA pseudo Dice: 0.49630001187324524 
2025-03-10 13:55:00.797922:  
2025-03-10 13:55:00.804061: Epoch 32 
2025-03-10 13:55:00.808637: Current learning rate: 0.00707 
2025-03-10 13:56:24.403257: train_loss -0.5354 
2025-03-10 13:56:24.409271: val_loss -0.3682 
2025-03-10 13:56:24.413281: Pseudo dice [np.float32(0.5085)] 
2025-03-10 13:56:24.416790: Epoch time: 83.61 s 
2025-03-10 13:56:24.420799: Yayy! New best EMA pseudo Dice: 0.4975000023841858 
2025-03-10 13:56:25.149683:  
2025-03-10 13:56:25.155756: Epoch 33 
2025-03-10 13:56:25.159838: Current learning rate: 0.00697 
2025-03-10 13:57:48.773945: train_loss -0.5492 
2025-03-10 13:57:48.781488: val_loss -0.3042 
2025-03-10 13:57:48.785509: Pseudo dice [np.float32(0.4216)] 
2025-03-10 13:57:48.789033: Epoch time: 83.63 s 
2025-03-10 13:57:49.389600:  
2025-03-10 13:57:49.395623: Epoch 34 
2025-03-10 13:57:49.400132: Current learning rate: 0.00688 
2025-03-10 13:59:13.043974: train_loss -0.5455 
2025-03-10 13:59:13.051059: val_loss -0.4616 
2025-03-10 13:59:13.055119: Pseudo dice [np.float32(0.5691)] 
2025-03-10 13:59:13.057662: Epoch time: 83.66 s 
2025-03-10 13:59:13.061764: Yayy! New best EMA pseudo Dice: 0.49790000915527344 
2025-03-10 13:59:13.802641:  
2025-03-10 13:59:13.809300: Epoch 35 
2025-03-10 13:59:13.811843: Current learning rate: 0.00679 
2025-03-10 14:00:37.481027: train_loss -0.5423 
2025-03-10 14:00:37.487545: val_loss -0.4842 
2025-03-10 14:00:37.492055: Pseudo dice [np.float32(0.5386)] 
2025-03-10 14:00:37.495066: Epoch time: 83.68 s 
2025-03-10 14:00:37.498577: Yayy! New best EMA pseudo Dice: 0.5019000172615051 
2025-03-10 14:00:38.222312:  
2025-03-10 14:00:38.228327: Epoch 36 
2025-03-10 14:00:38.232340: Current learning rate: 0.00669 
2025-03-10 14:02:01.806413: train_loss -0.5158 
2025-03-10 14:02:01.812930: val_loss -0.4701 
2025-03-10 14:02:01.816938: Pseudo dice [np.float32(0.571)] 
2025-03-10 14:02:01.820449: Epoch time: 83.58 s 
2025-03-10 14:02:01.823954: Yayy! New best EMA pseudo Dice: 0.5088000297546387 
2025-03-10 14:02:02.722522:  
2025-03-10 14:02:02.728554: Epoch 37 
2025-03-10 14:02:02.731592: Current learning rate: 0.0066 
2025-03-10 14:03:26.326720: train_loss -0.5677 
2025-03-10 14:03:26.333235: val_loss -0.4343 
2025-03-10 14:03:26.339254: Pseudo dice [np.float32(0.6141)] 
2025-03-10 14:03:26.345269: Epoch time: 83.61 s 
2025-03-10 14:03:26.349289: Yayy! New best EMA pseudo Dice: 0.5194000005722046 
2025-03-10 14:03:27.085622:  
2025-03-10 14:03:27.091203: Epoch 38 
2025-03-10 14:03:27.096306: Current learning rate: 0.0065 
2025-03-10 14:04:50.748891: train_loss -0.56 
2025-03-10 14:04:50.755450: val_loss -0.4099 
2025-03-10 14:04:50.759001: Pseudo dice [np.float32(0.5195)] 
2025-03-10 14:04:50.762835: Epoch time: 83.66 s 
2025-03-10 14:04:50.766349: Yayy! New best EMA pseudo Dice: 0.5194000005722046 
2025-03-10 14:04:51.503601:  
2025-03-10 14:04:51.509087: Epoch 39 
2025-03-10 14:04:51.512603: Current learning rate: 0.00641 
2025-03-10 14:06:15.141274: train_loss -0.5944 
2025-03-10 14:06:15.147811: val_loss -0.4574 
2025-03-10 14:06:15.152822: Pseudo dice [np.float32(0.5826)] 
2025-03-10 14:06:15.156831: Epoch time: 83.64 s 
2025-03-10 14:06:15.160339: Yayy! New best EMA pseudo Dice: 0.5256999731063843 
2025-03-10 14:06:15.900216:  
2025-03-10 14:06:15.908253: Epoch 40 
2025-03-10 14:06:15.912304: Current learning rate: 0.00631 
2025-03-10 14:07:39.592879: train_loss -0.5948 
2025-03-10 14:07:39.600477: val_loss -0.4562 
2025-03-10 14:07:39.603989: Pseudo dice [np.float32(0.5657)] 
2025-03-10 14:07:39.607495: Epoch time: 83.69 s 
2025-03-10 14:07:39.611510: Yayy! New best EMA pseudo Dice: 0.529699981212616 
2025-03-10 14:07:40.346293:  
2025-03-10 14:07:40.352812: Epoch 41 
2025-03-10 14:07:40.356823: Current learning rate: 0.00622 
2025-03-10 14:09:03.992178: train_loss -0.5923 
2025-03-10 14:09:03.999266: val_loss -0.3919 
2025-03-10 14:09:04.002336: Pseudo dice [np.float32(0.5087)] 
2025-03-10 14:09:04.006912: Epoch time: 83.65 s 
2025-03-10 14:09:04.559219:  
2025-03-10 14:09:04.565814: Epoch 42 
2025-03-10 14:09:04.569907: Current learning rate: 0.00612 
2025-03-10 14:10:28.202749: train_loss -0.5431 
2025-03-10 14:10:28.209791: val_loss -0.4573 
2025-03-10 14:10:28.213335: Pseudo dice [np.float32(0.5779)] 
2025-03-10 14:10:28.217363: Epoch time: 83.64 s 
2025-03-10 14:10:28.220902: Yayy! New best EMA pseudo Dice: 0.5325999855995178 
2025-03-10 14:10:28.941605:  
2025-03-10 14:10:28.948206: Epoch 43 
2025-03-10 14:10:28.950742: Current learning rate: 0.00603 
2025-03-10 14:11:52.594516: train_loss -0.5544 
2025-03-10 14:11:52.602036: val_loss -0.4208 
2025-03-10 14:11:52.605545: Pseudo dice [np.float32(0.5164)] 
2025-03-10 14:11:52.609594: Epoch time: 83.65 s 
2025-03-10 14:11:53.156603:  
2025-03-10 14:11:53.163743: Epoch 44 
2025-03-10 14:11:53.167331: Current learning rate: 0.00593 
2025-03-10 14:13:16.786943: train_loss -0.541 
2025-03-10 14:13:16.793631: val_loss -0.439 
2025-03-10 14:13:16.798168: Pseudo dice [np.float32(0.5596)] 
2025-03-10 14:13:16.802211: Epoch time: 83.63 s 
2025-03-10 14:13:16.805835: Yayy! New best EMA pseudo Dice: 0.5339000225067139 
2025-03-10 14:13:17.677654:  
2025-03-10 14:13:17.684243: Epoch 45 
2025-03-10 14:13:17.688815: Current learning rate: 0.00584 
2025-03-10 14:14:41.283349: train_loss -0.5634 
2025-03-10 14:14:41.289637: val_loss -0.4431 
2025-03-10 14:14:41.294655: Pseudo dice [np.float32(0.5771)] 
2025-03-10 14:14:41.298663: Epoch time: 83.61 s 
2025-03-10 14:14:41.302174: Yayy! New best EMA pseudo Dice: 0.5382000207901001 
2025-03-10 14:14:42.013969:  
2025-03-10 14:14:42.021031: Epoch 46 
2025-03-10 14:14:42.024700: Current learning rate: 0.00574 
2025-03-10 14:16:05.562001: train_loss -0.6213 
2025-03-10 14:16:05.568514: val_loss -0.4111 
2025-03-10 14:16:05.573022: Pseudo dice [np.float32(0.5646)] 
2025-03-10 14:16:05.577037: Epoch time: 83.55 s 
2025-03-10 14:16:05.580544: Yayy! New best EMA pseudo Dice: 0.5407999753952026 
2025-03-10 14:16:06.285439:  
2025-03-10 14:16:06.291276: Epoch 47 
2025-03-10 14:16:06.295288: Current learning rate: 0.00565 
2025-03-10 14:17:29.857137: train_loss -0.5805 
2025-03-10 14:17:29.863152: val_loss -0.4403 
2025-03-10 14:17:29.867160: Pseudo dice [np.float32(0.6135)] 
2025-03-10 14:17:29.870674: Epoch time: 83.57 s 
2025-03-10 14:17:29.874682: Yayy! New best EMA pseudo Dice: 0.5480999946594238 
2025-03-10 14:17:30.581137:  
2025-03-10 14:17:30.587157: Epoch 48 
2025-03-10 14:17:30.591667: Current learning rate: 0.00555 
2025-03-10 14:18:54.141431: train_loss -0.5704 
2025-03-10 14:18:54.149406: val_loss -0.4471 
2025-03-10 14:18:54.152917: Pseudo dice [np.float32(0.5632)] 
2025-03-10 14:18:54.156430: Epoch time: 83.56 s 
2025-03-10 14:18:54.160530: Yayy! New best EMA pseudo Dice: 0.5496000051498413 
2025-03-10 14:18:55.004001:  
2025-03-10 14:18:55.010018: Epoch 49 
2025-03-10 14:18:55.015036: Current learning rate: 0.00546 
2025-03-10 14:20:18.612292: train_loss -0.6032 
2025-03-10 14:20:18.619370: val_loss -0.4878 
2025-03-10 14:20:18.622933: Pseudo dice [np.float32(0.5987)] 
2025-03-10 14:20:18.626481: Epoch time: 83.61 s 
2025-03-10 14:20:18.776144: Yayy! New best EMA pseudo Dice: 0.5544999837875366 
2025-03-10 14:20:19.506746:  
2025-03-10 14:20:19.512262: Epoch 50 
2025-03-10 14:20:19.515772: Current learning rate: 0.00536 
2025-03-10 14:21:43.135838: train_loss -0.5848 
2025-03-10 14:21:43.142351: val_loss -0.5128 
2025-03-10 14:21:43.146859: Pseudo dice [np.float32(0.6391)] 
2025-03-10 14:21:43.150874: Epoch time: 83.63 s 
2025-03-10 14:21:43.154406: Yayy! New best EMA pseudo Dice: 0.5630000233650208 
2025-03-10 14:21:43.870188:  
2025-03-10 14:21:43.876227: Epoch 51 
2025-03-10 14:21:43.879292: Current learning rate: 0.00526 
2025-03-10 14:23:07.465879: train_loss -0.5664 
2025-03-10 14:23:07.472416: val_loss -0.3545 
2025-03-10 14:23:07.475928: Pseudo dice [np.float32(0.5569)] 
2025-03-10 14:23:07.479938: Epoch time: 83.6 s 
2025-03-10 14:23:08.038817:  
2025-03-10 14:23:08.044332: Epoch 52 
2025-03-10 14:23:08.048845: Current learning rate: 0.00517 
2025-03-10 14:24:31.655422: train_loss -0.596 
2025-03-10 14:24:31.661937: val_loss -0.384 
2025-03-10 14:24:31.665449: Pseudo dice [np.float32(0.4873)] 
2025-03-10 14:24:31.669472: Epoch time: 83.62 s 
2025-03-10 14:24:32.234103:  
2025-03-10 14:24:32.240169: Epoch 53 
2025-03-10 14:24:32.244262: Current learning rate: 0.00507 
2025-03-10 14:25:55.864516: train_loss -0.6137 
2025-03-10 14:25:55.871552: val_loss -0.5382 
2025-03-10 14:25:55.875062: Pseudo dice [np.float32(0.65)] 
2025-03-10 14:25:55.880075: Epoch time: 83.63 s 
2025-03-10 14:25:55.884084: Yayy! New best EMA pseudo Dice: 0.5644000172615051 
2025-03-10 14:25:56.767667:  
2025-03-10 14:25:56.773206: Epoch 54 
2025-03-10 14:25:56.776761: Current learning rate: 0.00497 
2025-03-10 14:27:20.369624: train_loss -0.6228 
2025-03-10 14:27:20.375641: val_loss -0.508 
2025-03-10 14:27:20.379650: Pseudo dice [np.float32(0.6354)] 
2025-03-10 14:27:20.384160: Epoch time: 83.6 s 
2025-03-10 14:27:20.387172: Yayy! New best EMA pseudo Dice: 0.5715000033378601 
2025-03-10 14:27:21.113053:  
2025-03-10 14:27:21.119690: Epoch 55 
2025-03-10 14:27:21.123756: Current learning rate: 0.00487 
2025-03-10 14:28:44.986929: train_loss -0.6039 
2025-03-10 14:28:44.993946: val_loss -0.3009 
2025-03-10 14:28:44.997960: Pseudo dice [np.float32(0.4654)] 
2025-03-10 14:28:45.001974: Epoch time: 83.87 s 
2025-03-10 14:28:45.560718:  
2025-03-10 14:28:45.567235: Epoch 56 
2025-03-10 14:28:45.571247: Current learning rate: 0.00478 
2025-03-10 14:30:09.386544: train_loss -0.6299 
2025-03-10 14:30:09.394062: val_loss -0.5326 
2025-03-10 14:30:09.398573: Pseudo dice [np.float32(0.6336)] 
2025-03-10 14:30:09.402588: Epoch time: 83.83 s 
2025-03-10 14:30:09.962264:  
2025-03-10 14:30:09.968783: Epoch 57 
2025-03-10 14:30:09.972794: Current learning rate: 0.00468 
2025-03-10 14:31:33.602422: train_loss -0.6434 
2025-03-10 14:31:33.609940: val_loss -0.425 
2025-03-10 14:31:33.613951: Pseudo dice [np.float32(0.5818)] 
2025-03-10 14:31:33.617461: Epoch time: 83.64 s 
2025-03-10 14:31:34.172733:  
2025-03-10 14:31:34.178798: Epoch 58 
2025-03-10 14:31:34.181340: Current learning rate: 0.00458 
2025-03-10 14:32:57.744790: train_loss -0.6173 
2025-03-10 14:32:57.750913: val_loss -0.4654 
2025-03-10 14:32:57.754462: Pseudo dice [np.float32(0.5942)] 
2025-03-10 14:32:57.757501: Epoch time: 83.57 s 
2025-03-10 14:32:57.761030: Yayy! New best EMA pseudo Dice: 0.5720000267028809 
2025-03-10 14:32:58.494670:  
2025-03-10 14:32:58.502200: Epoch 59 
2025-03-10 14:32:58.505708: Current learning rate: 0.00448 
2025-03-10 14:34:22.069991: train_loss -0.6463 
2025-03-10 14:34:22.077071: val_loss -0.4053 
2025-03-10 14:34:22.080663: Pseudo dice [np.float32(0.5606)] 
2025-03-10 14:34:22.083702: Epoch time: 83.58 s 
2025-03-10 14:34:22.640228:  
2025-03-10 14:34:22.646244: Epoch 60 
2025-03-10 14:34:22.649755: Current learning rate: 0.00438 
2025-03-10 14:35:46.171835: train_loss -0.6656 
2025-03-10 14:35:46.178855: val_loss -0.4053 
2025-03-10 14:35:46.181868: Pseudo dice [np.float32(0.5963)] 
2025-03-10 14:35:46.185380: Epoch time: 83.53 s 
2025-03-10 14:35:46.189391: Yayy! New best EMA pseudo Dice: 0.5734000205993652 
2025-03-10 14:35:46.919396:  
2025-03-10 14:35:46.925945: Epoch 61 
2025-03-10 14:35:46.929983: Current learning rate: 0.00429 
2025-03-10 14:37:10.494443: train_loss -0.6547 
2025-03-10 14:37:10.500959: val_loss -0.421 
2025-03-10 14:37:10.505972: Pseudo dice [np.float32(0.5541)] 
2025-03-10 14:37:10.509485: Epoch time: 83.58 s 
2025-03-10 14:37:11.227320:  
2025-03-10 14:37:11.234370: Epoch 62 
2025-03-10 14:37:11.237414: Current learning rate: 0.00419 
2025-03-10 14:38:34.826245: train_loss -0.6161 
2025-03-10 14:38:34.833259: val_loss -0.3757 
2025-03-10 14:38:34.837276: Pseudo dice [np.float32(0.5175)] 
2025-03-10 14:38:34.841290: Epoch time: 83.6 s 
2025-03-10 14:38:35.408375:  
2025-03-10 14:38:35.414451: Epoch 63 
2025-03-10 14:38:35.418025: Current learning rate: 0.00409 
2025-03-10 14:39:58.971360: train_loss -0.6123 
2025-03-10 14:39:58.977874: val_loss -0.4577 
2025-03-10 14:39:58.982387: Pseudo dice [np.float32(0.6373)] 
2025-03-10 14:39:58.985398: Epoch time: 83.56 s 
2025-03-10 14:39:59.549378:  
2025-03-10 14:39:59.556964: Epoch 64 
2025-03-10 14:39:59.559680: Current learning rate: 0.00399 
2025-03-10 14:41:23.097485: train_loss -0.6143 
2025-03-10 14:41:23.105002: val_loss -0.4033 
2025-03-10 14:41:23.108513: Pseudo dice [np.float32(0.5717)] 
2025-03-10 14:41:23.112525: Epoch time: 83.55 s 
2025-03-10 14:41:23.682484:  
2025-03-10 14:41:23.688049: Epoch 65 
2025-03-10 14:41:23.692707: Current learning rate: 0.00389 
2025-03-10 14:42:47.247928: train_loss -0.6183 
2025-03-10 14:42:47.254443: val_loss -0.3924 
2025-03-10 14:42:47.258953: Pseudo dice [np.float32(0.5546)] 
2025-03-10 14:42:47.265476: Epoch time: 83.57 s 
2025-03-10 14:42:47.830982:  
2025-03-10 14:42:47.837077: Epoch 66 
2025-03-10 14:42:47.841143: Current learning rate: 0.00379 
2025-03-10 14:44:11.407114: train_loss -0.6329 
2025-03-10 14:44:11.413857: val_loss -0.4377 
2025-03-10 14:44:11.417961: Pseudo dice [np.float32(0.5591)] 
2025-03-10 14:44:11.421473: Epoch time: 83.58 s 
2025-03-10 14:44:11.991406:  
2025-03-10 14:44:11.997968: Epoch 67 
2025-03-10 14:44:12.002010: Current learning rate: 0.00369 
2025-03-10 14:45:35.602546: train_loss -0.641 
2025-03-10 14:45:35.609064: val_loss -0.5137 
2025-03-10 14:45:35.613075: Pseudo dice [np.float32(0.6546)] 
2025-03-10 14:45:35.616584: Epoch time: 83.61 s 
2025-03-10 14:45:35.620592: Yayy! New best EMA pseudo Dice: 0.578499972820282 
2025-03-10 14:45:36.362235:  
2025-03-10 14:45:36.368800: Epoch 68 
2025-03-10 14:45:36.372372: Current learning rate: 0.00359 
2025-03-10 14:47:00.026900: train_loss -0.6746 
2025-03-10 14:47:00.034418: val_loss -0.4628 
2025-03-10 14:47:00.038929: Pseudo dice [np.float32(0.6237)] 
2025-03-10 14:47:00.042943: Epoch time: 83.67 s 
2025-03-10 14:47:00.046451: Yayy! New best EMA pseudo Dice: 0.5830000042915344 
2025-03-10 14:47:00.943430:  
2025-03-10 14:47:00.949482: Epoch 69 
2025-03-10 14:47:00.954036: Current learning rate: 0.00349 
2025-03-10 14:48:24.549050: train_loss -0.6737 
2025-03-10 14:48:24.555067: val_loss -0.514 
2025-03-10 14:48:24.560079: Pseudo dice [np.float32(0.6442)] 
2025-03-10 14:48:24.564089: Epoch time: 83.61 s 
2025-03-10 14:48:24.566595: Yayy! New best EMA pseudo Dice: 0.5891000032424927 
2025-03-10 14:48:25.298672:  
2025-03-10 14:48:25.304721: Epoch 70 
2025-03-10 14:48:25.308732: Current learning rate: 0.00338 
2025-03-10 14:49:48.906570: train_loss -0.648 
2025-03-10 14:49:48.912638: val_loss -0.4152 
2025-03-10 14:49:48.916650: Pseudo dice [np.float32(0.5589)] 
2025-03-10 14:49:48.920162: Epoch time: 83.61 s 
2025-03-10 14:49:49.509581:  
2025-03-10 14:49:49.516708: Epoch 71 
2025-03-10 14:49:49.520283: Current learning rate: 0.00328 
2025-03-10 14:51:13.131001: train_loss -0.6599 
2025-03-10 14:51:13.138551: val_loss -0.4762 
2025-03-10 14:51:13.142566: Pseudo dice [np.float32(0.5915)] 
2025-03-10 14:51:13.146574: Epoch time: 83.62 s 
2025-03-10 14:51:13.721501:  
2025-03-10 14:51:13.727617: Epoch 72 
2025-03-10 14:51:13.735144: Current learning rate: 0.00318 
2025-03-10 14:52:37.351658: train_loss -0.6482 
2025-03-10 14:52:37.357717: val_loss -0.4464 
2025-03-10 14:52:37.362750: Pseudo dice [np.float32(0.6035)] 
2025-03-10 14:52:37.366345: Epoch time: 83.63 s 
2025-03-10 14:52:37.944082:  
2025-03-10 14:52:37.949642: Epoch 73 
2025-03-10 14:52:37.954810: Current learning rate: 0.00308 
2025-03-10 14:54:01.595747: train_loss -0.678 
2025-03-10 14:54:01.601762: val_loss -0.3977 
2025-03-10 14:54:01.605775: Pseudo dice [np.float32(0.6014)] 
2025-03-10 14:54:01.610286: Epoch time: 83.65 s 
2025-03-10 14:54:01.614300: Yayy! New best EMA pseudo Dice: 0.5896000266075134 
2025-03-10 14:54:02.363836:  
2025-03-10 14:54:02.370898: Epoch 74 
2025-03-10 14:54:02.374915: Current learning rate: 0.00297 
2025-03-10 14:55:25.975543: train_loss -0.6931 
2025-03-10 14:55:25.981561: val_loss -0.4374 
2025-03-10 14:55:25.985569: Pseudo dice [np.float32(0.5931)] 
2025-03-10 14:55:25.990079: Epoch time: 83.61 s 
2025-03-10 14:55:25.994096: Yayy! New best EMA pseudo Dice: 0.5899999737739563 
2025-03-10 14:55:26.803833:  
2025-03-10 14:55:26.809386: Epoch 75 
2025-03-10 14:55:26.815014: Current learning rate: 0.00287 
2025-03-10 14:56:50.482932: train_loss -0.6839 
2025-03-10 14:56:50.489448: val_loss -0.4113 
2025-03-10 14:56:50.494463: Pseudo dice [np.float32(0.5801)] 
2025-03-10 14:56:50.497973: Epoch time: 83.68 s 
2025-03-10 14:56:51.076916:  
2025-03-10 14:56:51.082932: Epoch 76 
2025-03-10 14:56:51.086943: Current learning rate: 0.00277 
2025-03-10 14:58:14.733214: train_loss -0.6737 
2025-03-10 14:58:14.740732: val_loss -0.4387 
2025-03-10 14:58:14.745243: Pseudo dice [np.float32(0.5905)] 
2025-03-10 14:58:14.749258: Epoch time: 83.66 s 
2025-03-10 14:58:15.483428:  
2025-03-10 14:58:15.488945: Epoch 77 
2025-03-10 14:58:15.492455: Current learning rate: 0.00266 
2025-03-10 14:59:39.113127: train_loss -0.6824 
2025-03-10 14:59:39.119138: val_loss -0.487 
2025-03-10 14:59:39.123171: Pseudo dice [np.float32(0.6202)] 
2025-03-10 14:59:39.127179: Epoch time: 83.63 s 
2025-03-10 14:59:39.130688: Yayy! New best EMA pseudo Dice: 0.592199981212616 
2025-03-10 14:59:39.880360:  
2025-03-10 14:59:39.886882: Epoch 78 
2025-03-10 14:59:39.890891: Current learning rate: 0.00256 
2025-03-10 15:01:03.465811: train_loss -0.7016 
2025-03-10 15:01:03.472882: val_loss -0.4967 
2025-03-10 15:01:03.476892: Pseudo dice [np.float32(0.6548)] 
2025-03-10 15:01:03.481906: Epoch time: 83.59 s 
2025-03-10 15:01:03.485416: Yayy! New best EMA pseudo Dice: 0.5985000133514404 
2025-03-10 15:01:04.236466:  
2025-03-10 15:01:04.242577: Epoch 79 
2025-03-10 15:01:04.247128: Current learning rate: 0.00245 
2025-03-10 15:02:27.849515: train_loss -0.6985 
2025-03-10 15:02:27.856731: val_loss -0.3846 
2025-03-10 15:02:27.861294: Pseudo dice [np.float32(0.6309)] 
2025-03-10 15:02:27.865343: Epoch time: 83.61 s 
2025-03-10 15:02:27.868854: Yayy! New best EMA pseudo Dice: 0.6017000079154968 
2025-03-10 15:02:28.618099:  
2025-03-10 15:02:28.625225: Epoch 80 
2025-03-10 15:02:28.628801: Current learning rate: 0.00235 
2025-03-10 15:03:52.214736: train_loss -0.6704 
2025-03-10 15:03:52.221249: val_loss -0.3384 
2025-03-10 15:03:52.225760: Pseudo dice [np.float32(0.5826)] 
2025-03-10 15:03:52.229773: Epoch time: 83.6 s 
2025-03-10 15:03:52.813251:  
2025-03-10 15:03:52.819295: Epoch 81 
2025-03-10 15:03:52.823337: Current learning rate: 0.00224 
2025-03-10 15:05:16.437701: train_loss -0.7013 
2025-03-10 15:05:16.443715: val_loss -0.4931 
2025-03-10 15:05:16.447725: Pseudo dice [np.float32(0.6341)] 
2025-03-10 15:05:16.451235: Epoch time: 83.62 s 
2025-03-10 15:05:16.455244: Yayy! New best EMA pseudo Dice: 0.6032000184059143 
2025-03-10 15:05:17.202072:  
2025-03-10 15:05:17.208085: Epoch 82 
2025-03-10 15:05:17.212094: Current learning rate: 0.00214 
2025-03-10 15:06:40.781572: train_loss -0.6977 
2025-03-10 15:06:40.787583: val_loss -0.5281 
2025-03-10 15:06:40.790591: Pseudo dice [np.float32(0.6814)] 
2025-03-10 15:06:40.794104: Epoch time: 83.58 s 
2025-03-10 15:06:40.798111: Yayy! New best EMA pseudo Dice: 0.6111000180244446 
2025-03-10 15:06:41.606493:  
2025-03-10 15:06:41.612658: Epoch 83 
2025-03-10 15:06:41.617759: Current learning rate: 0.00203 
2025-03-10 15:08:05.201194: train_loss -0.6898 
2025-03-10 15:08:05.207265: val_loss -0.4389 
2025-03-10 15:08:05.213782: Pseudo dice [np.float32(0.608)] 
2025-03-10 15:08:05.218295: Epoch time: 83.59 s 
2025-03-10 15:08:05.773766:  
2025-03-10 15:08:05.779363: Epoch 84 
2025-03-10 15:08:05.783945: Current learning rate: 0.00192 
2025-03-10 15:09:29.377206: train_loss -0.6896 
2025-03-10 15:09:29.383217: val_loss -0.4236 
2025-03-10 15:09:29.386226: Pseudo dice [np.float32(0.6019)] 
2025-03-10 15:09:29.389737: Epoch time: 83.6 s 
2025-03-10 15:09:30.104865:  
2025-03-10 15:09:30.109877: Epoch 85 
2025-03-10 15:09:30.113385: Current learning rate: 0.00181 
2025-03-10 15:10:53.697453: train_loss -0.7105 
2025-03-10 15:10:53.703019: val_loss -0.3311 
2025-03-10 15:10:53.706530: Pseudo dice [np.float32(0.5327)] 
2025-03-10 15:10:53.710035: Epoch time: 83.59 s 
2025-03-10 15:10:54.258811:  
2025-03-10 15:10:54.264845: Epoch 86 
2025-03-10 15:10:54.267351: Current learning rate: 0.0017 
2025-03-10 15:12:17.886152: train_loss -0.6997 
2025-03-10 15:12:17.892667: val_loss -0.396 
2025-03-10 15:12:17.896175: Pseudo dice [np.float32(0.5874)] 
2025-03-10 15:12:17.900180: Epoch time: 83.63 s 
2025-03-10 15:12:18.444971:  
2025-03-10 15:12:18.451602: Epoch 87 
2025-03-10 15:12:18.454672: Current learning rate: 0.00159 
2025-03-10 15:13:42.028369: train_loss -0.6952 
2025-03-10 15:13:42.034382: val_loss -0.4977 
2025-03-10 15:13:42.037396: Pseudo dice [np.float32(0.6696)] 
2025-03-10 15:13:42.040907: Epoch time: 83.58 s 
2025-03-10 15:13:42.587844:  
2025-03-10 15:13:42.593379: Epoch 88 
2025-03-10 15:13:42.597243: Current learning rate: 0.00148 
2025-03-10 15:15:06.261509: train_loss -0.7024 
2025-03-10 15:15:06.267113: val_loss -0.4542 
2025-03-10 15:15:06.271671: Pseudo dice [np.float32(0.6286)] 
2025-03-10 15:15:06.274181: Epoch time: 83.67 s 
2025-03-10 15:15:06.824190:  
2025-03-10 15:15:06.829770: Epoch 89 
2025-03-10 15:15:06.833324: Current learning rate: 0.00137 
2025-03-10 15:16:30.431529: train_loss -0.7093 
2025-03-10 15:16:30.438043: val_loss -0.4803 
2025-03-10 15:16:30.440551: Pseudo dice [np.float32(0.624)] 
2025-03-10 15:16:30.444063: Epoch time: 83.61 s 
2025-03-10 15:16:30.448072: Yayy! New best EMA pseudo Dice: 0.6111000180244446 
2025-03-10 15:16:31.154902:  
2025-03-10 15:16:31.161153: Epoch 90 
2025-03-10 15:16:31.163677: Current learning rate: 0.00126 
2025-03-10 15:17:54.766114: train_loss -0.7081 
2025-03-10 15:17:54.772132: val_loss -0.5265 
2025-03-10 15:17:54.775640: Pseudo dice [np.float32(0.6736)] 
2025-03-10 15:17:54.778650: Epoch time: 83.61 s 
2025-03-10 15:17:54.782159: Yayy! New best EMA pseudo Dice: 0.6173999905586243 
2025-03-10 15:17:55.486863:  
2025-03-10 15:17:55.492403: Epoch 91 
2025-03-10 15:17:55.495913: Current learning rate: 0.00115 
2025-03-10 15:19:19.083058: train_loss -0.7314 
2025-03-10 15:19:19.088574: val_loss -0.4272 
2025-03-10 15:19:19.092084: Pseudo dice [np.float32(0.6339)] 
2025-03-10 15:19:19.096095: Epoch time: 83.6 s 
2025-03-10 15:19:19.099604: Yayy! New best EMA pseudo Dice: 0.6190000176429749 
2025-03-10 15:19:19.815161:  
2025-03-10 15:19:19.820189: Epoch 92 
2025-03-10 15:19:19.823158: Current learning rate: 0.00103 
2025-03-10 15:20:43.412882: train_loss -0.7212 
2025-03-10 15:20:43.419899: val_loss -0.4617 
2025-03-10 15:20:43.423916: Pseudo dice [np.float32(0.6005)] 
2025-03-10 15:20:43.427420: Epoch time: 83.6 s 
2025-03-10 15:20:43.977322:  
2025-03-10 15:20:43.982913: Epoch 93 
2025-03-10 15:20:43.986967: Current learning rate: 0.00091 
2025-03-10 15:22:07.595267: train_loss -0.7061 
2025-03-10 15:22:07.601829: val_loss -0.5229 
2025-03-10 15:22:07.605384: Pseudo dice [np.float32(0.6699)] 
2025-03-10 15:22:07.608446: Epoch time: 83.62 s 
2025-03-10 15:22:07.611975: Yayy! New best EMA pseudo Dice: 0.6223999857902527 
2025-03-10 15:22:08.493585:  
2025-03-10 15:22:08.499100: Epoch 94 
2025-03-10 15:22:08.502609: Current learning rate: 0.00079 
2025-03-10 15:23:32.092492: train_loss -0.7056 
2025-03-10 15:23:32.099005: val_loss -0.4727 
2025-03-10 15:23:32.102513: Pseudo dice [np.float32(0.6423)] 
2025-03-10 15:23:32.105019: Epoch time: 83.6 s 
2025-03-10 15:23:32.109032: Yayy! New best EMA pseudo Dice: 0.6244000196456909 
2025-03-10 15:23:32.820276:  
2025-03-10 15:23:32.827331: Epoch 95 
2025-03-10 15:23:32.830391: Current learning rate: 0.00067 
2025-03-10 15:24:56.374580: train_loss -0.7422 
2025-03-10 15:24:56.380596: val_loss -0.3728 
2025-03-10 15:24:56.384604: Pseudo dice [np.float32(0.6448)] 
2025-03-10 15:24:56.388117: Epoch time: 83.55 s 
2025-03-10 15:24:56.390619: Yayy! New best EMA pseudo Dice: 0.6265000104904175 
2025-03-10 15:24:57.104957:  
2025-03-10 15:24:57.111000: Epoch 96 
2025-03-10 15:24:57.114511: Current learning rate: 0.00055 
2025-03-10 15:26:20.705857: train_loss -0.7095 
2025-03-10 15:26:20.712332: val_loss -0.4685 
2025-03-10 15:26:20.715506: Pseudo dice [np.float32(0.6717)] 
2025-03-10 15:26:20.719017: Epoch time: 83.6 s 
2025-03-10 15:26:20.721522: Yayy! New best EMA pseudo Dice: 0.6309999823570251 
2025-03-10 15:26:21.450964:  
2025-03-10 15:26:21.457028: Epoch 97 
2025-03-10 15:26:21.461165: Current learning rate: 0.00043 
2025-03-10 15:27:45.124740: train_loss -0.7368 
2025-03-10 15:27:45.131295: val_loss -0.4455 
2025-03-10 15:27:45.134804: Pseudo dice [np.float32(0.5896)] 
2025-03-10 15:27:45.137815: Epoch time: 83.67 s 
2025-03-10 15:27:45.706170:  
2025-03-10 15:27:45.711694: Epoch 98 
2025-03-10 15:27:45.715276: Current learning rate: 0.0003 
2025-03-10 15:29:09.379117: train_loss -0.7298 
2025-03-10 15:29:09.385197: val_loss -0.4444 
2025-03-10 15:29:09.388266: Pseudo dice [np.float32(0.5721)] 
2025-03-10 15:29:09.391795: Epoch time: 83.67 s 
2025-03-10 15:29:09.952568:  
2025-03-10 15:29:09.958704: Epoch 99 
2025-03-10 15:29:09.961733: Current learning rate: 0.00016 
2025-03-10 15:30:33.588589: train_loss -0.7283 
2025-03-10 15:30:33.594607: val_loss -0.384 
2025-03-10 15:30:33.598115: Pseudo dice [np.float32(0.5521)] 
2025-03-10 15:30:33.601125: Epoch time: 83.64 s 
2025-03-10 15:30:34.392394: Training done. 
2025-03-10 15:30:34.444396: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-10 15:30:34.453400: The split file contains 5 splits. 
2025-03-10 15:30:34.459400: Desired fold for training: 0 
2025-03-10 15:30:34.463401: This split has 100 training and 26 validation cases. 
2025-03-10 15:30:34.468662: predicting colon_008 
2025-03-10 15:30:34.473660: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-03-10 15:30:50.739384: predicting colon_027 
2025-03-10 15:30:50.759383: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-03-10 15:30:57.021186: predicting colon_030 
2025-03-10 15:30:57.036186: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-03-10 15:31:05.845629: predicting colon_033 
2025-03-10 15:31:05.861629: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-03-10 15:31:21.475895: predicting colon_041 
2025-03-10 15:31:21.499406: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-03-10 15:32:03.476318: predicting colon_042 
2025-03-10 15:32:03.507321: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-03-10 15:32:24.573098: predicting colon_061 
2025-03-10 15:32:24.596098: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-03-10 15:32:49.003693: predicting colon_074 
2025-03-10 15:32:49.033694: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-03-10 15:33:17.060837: predicting colon_075 
2025-03-10 15:33:17.090343: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-03-10 15:33:32.711564: predicting colon_088 
2025-03-10 15:33:32.734564: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-03-10 15:33:57.116054: predicting colon_091 
2025-03-10 15:33:57.142054: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-03-10 15:34:26.383370: predicting colon_092 
2025-03-10 15:34:26.414373: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-03-10 15:34:50.764281: predicting colon_095 
2025-03-10 15:34:50.786284: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-03-10 15:35:06.410429: predicting colon_102 
2025-03-10 15:35:06.431430: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-03-10 15:35:41.484274: predicting colon_111 
2025-03-10 15:35:41.516276: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-03-10 15:35:51.318709: predicting colon_115 
2025-03-10 15:35:51.336710: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-03-10 15:36:06.965572: predicting colon_118 
2025-03-10 15:36:06.986578: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-03-10 15:36:31.378001: predicting colon_124 
2025-03-10 15:36:31.410511: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-03-10 15:36:55.736959: predicting colon_127 
2025-03-10 15:36:55.761959: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-03-10 15:37:44.716905: predicting colon_154 
2025-03-10 15:37:44.757411: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-03-10 15:38:00.379252: predicting colon_161 
2025-03-10 15:38:00.400253: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-03-10 15:38:16.077994: predicting colon_162 
2025-03-10 15:38:16.104506: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-03-10 15:38:58.165876: predicting colon_165 
2025-03-10 15:38:58.199875: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-03-10 15:39:33.252047: predicting colon_166 
2025-03-10 15:39:33.284048: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-03-10 15:39:48.947184: predicting colon_169 
2025-03-10 15:39:48.967184: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-03-10 15:40:38.123232: predicting colon_187 
2025-03-10 15:40:38.165232: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-03-10 15:41:12.385164: Validation complete 
2025-03-10 15:41:12.391164: Mean Validation Dice:  0.2227834167289277 
