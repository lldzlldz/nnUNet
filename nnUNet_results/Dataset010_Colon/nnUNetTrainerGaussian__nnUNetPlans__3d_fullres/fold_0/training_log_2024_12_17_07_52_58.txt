
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-17 07:52:58.381818: do_dummy_2d_data_aug: True 
2024-12-17 07:52:58.386823: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-17 07:52:58.389821: The split file contains 5 splits. 
2024-12-17 07:52:58.391821: Desired fold for training: 0 
2024-12-17 07:52:58.394821: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2024-12-17 07:53:04.576055: unpacking dataset... 
2024-12-17 07:53:04.763269: unpacking done... 
2024-12-17 07:53:07.383280:  
2024-12-17 07:53:07.387292: Epoch 0 
2024-12-17 07:53:07.390803: Current learning rate: 0.01 
2024-12-17 07:53:53.116205: train_loss 0.0493 
2024-12-17 07:53:53.122805: val_loss -0.0023 
2024-12-17 07:53:53.125931: Pseudo dice [np.float32(0.0)] 
2024-12-17 07:53:53.128478: Epoch time: 45.73 s 
2024-12-17 07:53:53.132062: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-17 07:53:53.761376:  
2024-12-17 07:53:53.766345: Epoch 1 
2024-12-17 07:53:53.769359: Current learning rate: 0.00991 
2024-12-17 07:54:35.006619: train_loss -0.096 
2024-12-17 07:54:35.011664: val_loss -0.2479 
2024-12-17 07:54:35.014188: Pseudo dice [np.float32(0.3282)] 
2024-12-17 07:54:35.017720: Epoch time: 41.25 s 
2024-12-17 07:54:35.020277: Yayy! New best EMA pseudo Dice: 0.03280000016093254 
2024-12-17 07:54:35.719338:  
2024-12-17 07:54:35.724276: Epoch 2 
2024-12-17 07:54:35.727791: Current learning rate: 0.00982 
2024-12-17 07:55:16.959295: train_loss -0.1983 
2024-12-17 07:55:16.964810: val_loss -0.2348 
2024-12-17 07:55:16.967857: Pseudo dice [np.float32(0.3086)] 
2024-12-17 07:55:16.970881: Epoch time: 41.24 s 
2024-12-17 07:55:16.973386: Yayy! New best EMA pseudo Dice: 0.06040000170469284 
2024-12-17 07:55:17.687521:  
2024-12-17 07:55:17.692043: Epoch 3 
2024-12-17 07:55:17.695065: Current learning rate: 0.00973 
2024-12-17 07:55:58.925583: train_loss -0.2938 
2024-12-17 07:55:58.931097: val_loss -0.3092 
2024-12-17 07:55:58.934605: Pseudo dice [np.float32(0.4214)] 
2024-12-17 07:55:58.937110: Epoch time: 41.24 s 
2024-12-17 07:55:58.939615: Yayy! New best EMA pseudo Dice: 0.09650000184774399 
2024-12-17 07:55:59.640127:  
2024-12-17 07:55:59.645143: Epoch 4 
2024-12-17 07:55:59.648652: Current learning rate: 0.00964 
2024-12-17 07:56:40.874867: train_loss -0.3842 
2024-12-17 07:56:40.880915: val_loss -0.4745 
2024-12-17 07:56:40.883177: Pseudo dice [np.float32(0.5345)] 
2024-12-17 07:56:40.887285: Epoch time: 41.24 s 
2024-12-17 07:56:40.890294: Yayy! New best EMA pseudo Dice: 0.14030000567436218 
2024-12-17 07:56:41.727866:  
2024-12-17 07:56:41.732224: Epoch 5 
2024-12-17 07:56:41.735232: Current learning rate: 0.00955 
2024-12-17 07:57:22.955981: train_loss -0.4174 
2024-12-17 07:57:22.961994: val_loss -0.3711 
2024-12-17 07:57:22.964500: Pseudo dice [np.float32(0.4528)] 
2024-12-17 07:57:22.967006: Epoch time: 41.23 s 
2024-12-17 07:57:22.970510: Yayy! New best EMA pseudo Dice: 0.17149999737739563 
2024-12-17 07:57:23.663430:  
2024-12-17 07:57:23.668478: Epoch 6 
2024-12-17 07:57:23.671504: Current learning rate: 0.00946 
2024-12-17 07:58:04.887033: train_loss -0.463 
2024-12-17 07:58:04.893585: val_loss -0.4044 
2024-12-17 07:58:04.897112: Pseudo dice [np.float32(0.5236)] 
2024-12-17 07:58:04.899179: Epoch time: 41.22 s 
2024-12-17 07:58:04.902206: Yayy! New best EMA pseudo Dice: 0.20669999718666077 
2024-12-17 07:58:05.612826:  
2024-12-17 07:58:05.617837: Epoch 7 
2024-12-17 07:58:05.620845: Current learning rate: 0.00937 
2024-12-17 07:58:46.843737: train_loss -0.4485 
2024-12-17 07:58:46.848751: val_loss -0.3477 
2024-12-17 07:58:46.852760: Pseudo dice [np.float32(0.4791)] 
2024-12-17 07:58:46.856270: Epoch time: 41.23 s 
2024-12-17 07:58:46.859776: Yayy! New best EMA pseudo Dice: 0.23399999737739563 
2024-12-17 07:58:47.585190:  
2024-12-17 07:58:47.590293: Epoch 8 
2024-12-17 07:58:47.592838: Current learning rate: 0.00928 
2024-12-17 07:59:28.821838: train_loss -0.5383 
2024-12-17 07:59:28.828964: val_loss -0.4169 
2024-12-17 07:59:28.831988: Pseudo dice [np.float32(0.5003)] 
2024-12-17 07:59:28.834494: Epoch time: 41.24 s 
2024-12-17 07:59:28.838006: Yayy! New best EMA pseudo Dice: 0.2606000006198883 
2024-12-17 07:59:29.567513:  
2024-12-17 07:59:29.572557: Epoch 9 
2024-12-17 07:59:29.575595: Current learning rate: 0.00919 
2024-12-17 08:00:10.792166: train_loss -0.5187 
2024-12-17 08:00:10.799233: val_loss -0.4215 
2024-12-17 08:00:10.803265: Pseudo dice [np.float32(0.5469)] 
2024-12-17 08:00:10.806290: Epoch time: 41.23 s 
2024-12-17 08:00:10.809328: Yayy! New best EMA pseudo Dice: 0.2892000079154968 
2024-12-17 08:00:11.511744:  
2024-12-17 08:00:11.517309: Epoch 10 
2024-12-17 08:00:11.520362: Current learning rate: 0.0091 
2024-12-17 08:00:52.741333: train_loss -0.5518 
2024-12-17 08:00:52.747884: val_loss -0.4981 
2024-12-17 08:00:52.750407: Pseudo dice [np.float32(0.5896)] 
2024-12-17 08:00:52.753932: Epoch time: 41.23 s 
2024-12-17 08:00:52.755966: Yayy! New best EMA pseudo Dice: 0.31929999589920044 
2024-12-17 08:00:53.451576:  
2024-12-17 08:00:53.456644: Epoch 11 
2024-12-17 08:00:53.459694: Current learning rate: 0.009 
2024-12-17 08:01:34.688934: train_loss -0.5659 
2024-12-17 08:01:34.695980: val_loss -0.4483 
2024-12-17 08:01:34.699005: Pseudo dice [np.float32(0.519)] 
2024-12-17 08:01:34.702523: Epoch time: 41.24 s 
2024-12-17 08:01:34.705037: Yayy! New best EMA pseudo Dice: 0.3393000066280365 
2024-12-17 08:01:35.412084:  
2024-12-17 08:01:35.417624: Epoch 12 
2024-12-17 08:01:35.420674: Current learning rate: 0.00891 
2024-12-17 08:02:16.670400: train_loss -0.6006 
2024-12-17 08:02:16.675432: val_loss -0.3848 
2024-12-17 08:02:16.678945: Pseudo dice [np.float32(0.5173)] 
2024-12-17 08:02:16.682452: Epoch time: 41.26 s 
2024-12-17 08:02:16.685463: Yayy! New best EMA pseudo Dice: 0.3571000099182129 
2024-12-17 08:02:17.544168:  
2024-12-17 08:02:17.550685: Epoch 13 
2024-12-17 08:02:17.555699: Current learning rate: 0.00882 
2024-12-17 08:02:58.786256: train_loss -0.5837 
2024-12-17 08:02:58.791497: val_loss -0.4379 
2024-12-17 08:02:58.794004: Pseudo dice [np.float32(0.5233)] 
2024-12-17 08:02:58.798014: Epoch time: 41.24 s 
2024-12-17 08:02:58.800519: Yayy! New best EMA pseudo Dice: 0.37369999289512634 
2024-12-17 08:02:59.515223:  
2024-12-17 08:02:59.520233: Epoch 14 
2024-12-17 08:02:59.523743: Current learning rate: 0.00873 
2024-12-17 08:03:40.760707: train_loss -0.5877 
2024-12-17 08:03:40.765755: val_loss -0.4249 
2024-12-17 08:03:40.768788: Pseudo dice [np.float32(0.5345)] 
2024-12-17 08:03:40.772319: Epoch time: 41.25 s 
2024-12-17 08:03:40.775354: Yayy! New best EMA pseudo Dice: 0.3898000121116638 
2024-12-17 08:03:41.495858:  
2024-12-17 08:03:41.501409: Epoch 15 
2024-12-17 08:03:41.504964: Current learning rate: 0.00864 
2024-12-17 08:04:22.723098: train_loss -0.5924 
2024-12-17 08:04:22.731169: val_loss -0.4409 
2024-12-17 08:04:22.735717: Pseudo dice [np.float32(0.5534)] 
2024-12-17 08:04:22.738775: Epoch time: 41.23 s 
2024-12-17 08:04:22.741280: Yayy! New best EMA pseudo Dice: 0.40610000491142273 
2024-12-17 08:04:23.456775:  
2024-12-17 08:04:23.462267: Epoch 16 
2024-12-17 08:04:23.465779: Current learning rate: 0.00855 
2024-12-17 08:05:04.728799: train_loss -0.6192 
2024-12-17 08:05:04.734824: val_loss -0.4763 
2024-12-17 08:05:04.738345: Pseudo dice [np.float32(0.5708)] 
2024-12-17 08:05:04.741721: Epoch time: 41.27 s 
2024-12-17 08:05:04.744229: Yayy! New best EMA pseudo Dice: 0.42260000109672546 
2024-12-17 08:05:05.484768:  
2024-12-17 08:05:05.489782: Epoch 17 
2024-12-17 08:05:05.492796: Current learning rate: 0.00846 
2024-12-17 08:05:46.738481: train_loss -0.6306 
2024-12-17 08:05:46.745530: val_loss -0.388 
2024-12-17 08:05:46.747796: Pseudo dice [np.float32(0.5074)] 
2024-12-17 08:05:46.750910: Epoch time: 41.25 s 
2024-12-17 08:05:46.754920: Yayy! New best EMA pseudo Dice: 0.4311000108718872 
2024-12-17 08:05:47.469868:  
2024-12-17 08:05:47.474882: Epoch 18 
2024-12-17 08:05:47.477896: Current learning rate: 0.00836 
2024-12-17 08:06:28.698059: train_loss -0.5526 
2024-12-17 08:06:28.704186: val_loss -0.4232 
2024-12-17 08:06:28.707727: Pseudo dice [np.float32(0.5303)] 
2024-12-17 08:06:28.710753: Epoch time: 41.23 s 
2024-12-17 08:06:28.713258: Yayy! New best EMA pseudo Dice: 0.4410000145435333 
2024-12-17 08:06:29.431721:  
2024-12-17 08:06:29.437773: Epoch 19 
2024-12-17 08:06:29.441299: Current learning rate: 0.00827 
2024-12-17 08:07:10.666574: train_loss -0.5946 
2024-12-17 08:07:10.672549: val_loss -0.4444 
2024-12-17 08:07:10.676054: Pseudo dice [np.float32(0.5739)] 
2024-12-17 08:07:10.679062: Epoch time: 41.23 s 
2024-12-17 08:07:10.681567: Yayy! New best EMA pseudo Dice: 0.4542999863624573 
2024-12-17 08:07:11.400956:  
2024-12-17 08:07:11.406067: Epoch 20 
2024-12-17 08:07:11.409131: Current learning rate: 0.00818 
2024-12-17 08:07:52.627554: train_loss -0.6465 
2024-12-17 08:07:52.633136: val_loss -0.4149 
2024-12-17 08:07:52.636162: Pseudo dice [np.float32(0.5135)] 
2024-12-17 08:07:52.639667: Epoch time: 41.23 s 
2024-12-17 08:07:52.642675: Yayy! New best EMA pseudo Dice: 0.4602000117301941 
2024-12-17 08:07:53.516602:  
2024-12-17 08:07:53.522115: Epoch 21 
2024-12-17 08:07:53.525623: Current learning rate: 0.00809 
2024-12-17 08:08:34.744462: train_loss -0.6484 
2024-12-17 08:08:34.750506: val_loss -0.2581 
2024-12-17 08:08:34.753566: Pseudo dice [np.float32(0.3719)] 
2024-12-17 08:08:34.756117: Epoch time: 41.23 s 
2024-12-17 08:08:35.289282:  
2024-12-17 08:08:35.294386: Epoch 22 
2024-12-17 08:08:35.298417: Current learning rate: 0.008 
2024-12-17 08:09:16.520762: train_loss -0.6186 
2024-12-17 08:09:16.526908: val_loss -0.4087 
2024-12-17 08:09:16.530437: Pseudo dice [np.float32(0.5608)] 
2024-12-17 08:09:16.533464: Epoch time: 41.23 s 
2024-12-17 08:09:16.536495: Yayy! New best EMA pseudo Dice: 0.46230000257492065 
2024-12-17 08:09:17.229851:  
2024-12-17 08:09:17.234653: Epoch 23 
2024-12-17 08:09:17.238165: Current learning rate: 0.0079 
2024-12-17 08:09:58.447793: train_loss -0.681 
2024-12-17 08:09:58.453846: val_loss -0.3677 
2024-12-17 08:09:58.457858: Pseudo dice [np.float32(0.4798)] 
2024-12-17 08:09:58.460365: Epoch time: 41.22 s 
2024-12-17 08:09:58.463877: Yayy! New best EMA pseudo Dice: 0.4641000032424927 
2024-12-17 08:09:59.155210:  
2024-12-17 08:09:59.160243: Epoch 24 
2024-12-17 08:09:59.163168: Current learning rate: 0.00781 
2024-12-17 08:10:40.376501: train_loss -0.6635 
2024-12-17 08:10:40.381544: val_loss -0.4094 
2024-12-17 08:10:40.385102: Pseudo dice [np.float32(0.5167)] 
2024-12-17 08:10:40.387609: Epoch time: 41.22 s 
2024-12-17 08:10:40.391624: Yayy! New best EMA pseudo Dice: 0.4693000018596649 
2024-12-17 08:10:41.089672:  
2024-12-17 08:10:41.094728: Epoch 25 
2024-12-17 08:10:41.097260: Current learning rate: 0.00772 
2024-12-17 08:11:22.324024: train_loss -0.6693 
2024-12-17 08:11:22.330542: val_loss -0.4924 
2024-12-17 08:11:22.334051: Pseudo dice [np.float32(0.5701)] 
2024-12-17 08:11:22.339064: Epoch time: 41.23 s 
2024-12-17 08:11:22.341570: Yayy! New best EMA pseudo Dice: 0.47940000891685486 
2024-12-17 08:11:23.036534:  
2024-12-17 08:11:23.041542: Epoch 26 
2024-12-17 08:11:23.045051: Current learning rate: 0.00763 
2024-12-17 08:12:04.274645: train_loss -0.627 
2024-12-17 08:12:04.281697: val_loss -0.4787 
2024-12-17 08:12:04.285297: Pseudo dice [np.float32(0.6004)] 
2024-12-17 08:12:04.288359: Epoch time: 41.24 s 
2024-12-17 08:12:04.291393: Yayy! New best EMA pseudo Dice: 0.49149999022483826 
2024-12-17 08:12:04.992139:  
2024-12-17 08:12:04.996956: Epoch 27 
2024-12-17 08:12:05.000469: Current learning rate: 0.00753 
2024-12-17 08:12:46.195873: train_loss -0.6402 
2024-12-17 08:12:46.201427: val_loss -0.4763 
2024-12-17 08:12:46.204956: Pseudo dice [np.float32(0.5936)] 
2024-12-17 08:12:46.207461: Epoch time: 41.21 s 
2024-12-17 08:12:46.209970: Yayy! New best EMA pseudo Dice: 0.5016999840736389 
2024-12-17 08:12:46.907659:  
2024-12-17 08:12:46.912670: Epoch 28 
2024-12-17 08:12:46.916180: Current learning rate: 0.00744 
2024-12-17 08:13:28.125751: train_loss -0.6408 
2024-12-17 08:13:28.130811: val_loss -0.4747 
2024-12-17 08:13:28.134858: Pseudo dice [np.float32(0.6124)] 
2024-12-17 08:13:28.137894: Epoch time: 41.22 s 
2024-12-17 08:13:28.140419: Yayy! New best EMA pseudo Dice: 0.5127999782562256 
2024-12-17 08:13:28.977559:  
2024-12-17 08:13:28.983072: Epoch 29 
2024-12-17 08:13:28.985578: Current learning rate: 0.00735 
2024-12-17 08:14:10.207406: train_loss -0.6756 
2024-12-17 08:14:10.213012: val_loss -0.3314 
2024-12-17 08:14:10.216637: Pseudo dice [np.float32(0.4386)] 
2024-12-17 08:14:10.220150: Epoch time: 41.23 s 
2024-12-17 08:14:10.766741:  
2024-12-17 08:14:10.771771: Epoch 30 
2024-12-17 08:14:10.774782: Current learning rate: 0.00725 
2024-12-17 08:14:51.985069: train_loss -0.6782 
2024-12-17 08:14:51.992185: val_loss -0.3508 
2024-12-17 08:14:51.995731: Pseudo dice [np.float32(0.5109)] 
2024-12-17 08:14:51.998770: Epoch time: 41.22 s 
2024-12-17 08:14:52.548734:  
2024-12-17 08:14:52.553745: Epoch 31 
2024-12-17 08:14:52.556754: Current learning rate: 0.00716 
2024-12-17 08:15:33.766746: train_loss -0.6903 
2024-12-17 08:15:33.772277: val_loss -0.4103 
2024-12-17 08:15:33.774785: Pseudo dice [np.float32(0.5502)] 
2024-12-17 08:15:33.778291: Epoch time: 41.22 s 
2024-12-17 08:15:34.322152:  
2024-12-17 08:15:34.326674: Epoch 32 
2024-12-17 08:15:34.329761: Current learning rate: 0.00707 
2024-12-17 08:16:15.534223: train_loss -0.6676 
2024-12-17 08:16:15.539846: val_loss -0.4637 
2024-12-17 08:16:15.542887: Pseudo dice [np.float32(0.6198)] 
2024-12-17 08:16:15.546913: Epoch time: 41.21 s 
2024-12-17 08:16:15.549922: Yayy! New best EMA pseudo Dice: 0.5213000178337097 
2024-12-17 08:16:16.271999:  
2024-12-17 08:16:16.277025: Epoch 33 
2024-12-17 08:16:16.280066: Current learning rate: 0.00697 
2024-12-17 08:16:57.485178: train_loss -0.6837 
2024-12-17 08:16:57.491296: val_loss -0.4563 
2024-12-17 08:16:57.494830: Pseudo dice [np.float32(0.5784)] 
2024-12-17 08:16:57.498375: Epoch time: 41.21 s 
2024-12-17 08:16:57.501040: Yayy! New best EMA pseudo Dice: 0.5270000100135803 
2024-12-17 08:16:58.226951:  
2024-12-17 08:16:58.231964: Epoch 34 
2024-12-17 08:16:58.235476: Current learning rate: 0.00688 
2024-12-17 08:17:39.467737: train_loss -0.6886 
2024-12-17 08:17:39.472796: val_loss -0.4459 
2024-12-17 08:17:39.476841: Pseudo dice [np.float32(0.6193)] 
2024-12-17 08:17:39.479875: Epoch time: 41.24 s 
2024-12-17 08:17:39.482381: Yayy! New best EMA pseudo Dice: 0.5361999869346619 
2024-12-17 08:17:40.202760:  
2024-12-17 08:17:40.207794: Epoch 35 
2024-12-17 08:17:40.211339: Current learning rate: 0.00679 
2024-12-17 08:18:21.418567: train_loss -0.7082 
2024-12-17 08:18:21.424664: val_loss -0.4323 
2024-12-17 08:18:21.427198: Pseudo dice [np.float32(0.6178)] 
2024-12-17 08:18:21.430224: Epoch time: 41.22 s 
2024-12-17 08:18:21.433729: Yayy! New best EMA pseudo Dice: 0.5443999767303467 
2024-12-17 08:18:22.146963:  
2024-12-17 08:18:22.153038: Epoch 36 
2024-12-17 08:18:22.156148: Current learning rate: 0.00669 
2024-12-17 08:19:03.380578: train_loss -0.7198 
2024-12-17 08:19:03.387181: val_loss -0.3578 
2024-12-17 08:19:03.389708: Pseudo dice [np.float32(0.5785)] 
2024-12-17 08:19:03.393738: Epoch time: 41.23 s 
2024-12-17 08:19:03.396770: Yayy! New best EMA pseudo Dice: 0.5478000044822693 
2024-12-17 08:19:04.256060:  
2024-12-17 08:19:04.262070: Epoch 37 
2024-12-17 08:19:04.265079: Current learning rate: 0.0066 
2024-12-17 08:19:45.477430: train_loss -0.7188 
2024-12-17 08:19:45.483003: val_loss -0.4213 
2024-12-17 08:19:45.486047: Pseudo dice [np.float32(0.599)] 
2024-12-17 08:19:45.488586: Epoch time: 41.22 s 
2024-12-17 08:19:45.492172: Yayy! New best EMA pseudo Dice: 0.5529000163078308 
2024-12-17 08:19:46.208252:  
2024-12-17 08:19:46.213832: Epoch 38 
2024-12-17 08:19:46.216881: Current learning rate: 0.0065 
2024-12-17 08:20:27.436456: train_loss -0.7017 
2024-12-17 08:20:27.443973: val_loss -0.4928 
2024-12-17 08:20:27.446478: Pseudo dice [np.float32(0.6412)] 
2024-12-17 08:20:27.449984: Epoch time: 41.23 s 
2024-12-17 08:20:27.452994: Yayy! New best EMA pseudo Dice: 0.5618000030517578 
2024-12-17 08:20:28.176064:  
2024-12-17 08:20:28.181581: Epoch 39 
2024-12-17 08:20:28.184588: Current learning rate: 0.00641 
2024-12-17 08:21:09.400741: train_loss -0.6637 
2024-12-17 08:21:09.407254: val_loss -0.3618 
2024-12-17 08:21:09.410764: Pseudo dice [np.float32(0.4569)] 
2024-12-17 08:21:09.413305: Epoch time: 41.22 s 
2024-12-17 08:21:09.980706:  
2024-12-17 08:21:09.985222: Epoch 40 
2024-12-17 08:21:09.988735: Current learning rate: 0.00631 
2024-12-17 08:21:51.227191: train_loss -0.6768 
2024-12-17 08:21:51.234449: val_loss -0.3898 
2024-12-17 08:21:51.237461: Pseudo dice [np.float32(0.4917)] 
2024-12-17 08:21:51.240972: Epoch time: 41.25 s 
2024-12-17 08:21:51.804962:  
2024-12-17 08:21:51.809976: Epoch 41 
2024-12-17 08:21:51.813488: Current learning rate: 0.00622 
2024-12-17 08:22:33.031884: train_loss -0.7047 
2024-12-17 08:22:33.036904: val_loss -0.4762 
2024-12-17 08:22:33.040066: Pseudo dice [np.float32(0.6175)] 
2024-12-17 08:22:33.043579: Epoch time: 41.23 s 
2024-12-17 08:22:33.578666:  
2024-12-17 08:22:33.582681: Epoch 42 
2024-12-17 08:22:33.584909: Current learning rate: 0.00612 
2024-12-17 08:23:14.819335: train_loss -0.7031 
2024-12-17 08:23:14.826560: val_loss -0.3343 
2024-12-17 08:23:14.830099: Pseudo dice [np.float32(0.4848)] 
2024-12-17 08:23:14.833166: Epoch time: 41.24 s 
2024-12-17 08:23:15.373649:  
2024-12-17 08:23:15.378190: Epoch 43 
2024-12-17 08:23:15.381738: Current learning rate: 0.00603 
2024-12-17 08:23:56.602448: train_loss -0.7221 
2024-12-17 08:23:56.608471: val_loss -0.419 
2024-12-17 08:23:56.611903: Pseudo dice [np.float32(0.5829)] 
2024-12-17 08:23:56.614411: Epoch time: 41.23 s 
2024-12-17 08:23:57.155171:  
2024-12-17 08:23:57.160740: Epoch 44 
2024-12-17 08:23:57.163288: Current learning rate: 0.00593 
2024-12-17 08:24:38.376323: train_loss -0.7243 
2024-12-17 08:24:38.381398: val_loss -0.3596 
2024-12-17 08:24:38.385951: Pseudo dice [np.float32(0.4912)] 
2024-12-17 08:24:38.388458: Epoch time: 41.22 s 
2024-12-17 08:24:39.067335:  
2024-12-17 08:24:39.072926: Epoch 45 
2024-12-17 08:24:39.075476: Current learning rate: 0.00584 
2024-12-17 08:25:20.296012: train_loss -0.7166 
2024-12-17 08:25:20.302109: val_loss -0.3096 
2024-12-17 08:25:20.305157: Pseudo dice [np.float32(0.4077)] 
2024-12-17 08:25:20.308664: Epoch time: 41.23 s 
2024-12-17 08:25:20.836593:  
2024-12-17 08:25:20.841632: Epoch 46 
2024-12-17 08:25:20.845436: Current learning rate: 0.00574 
2024-12-17 08:26:02.069372: train_loss -0.7034 
2024-12-17 08:26:02.075965: val_loss -0.3621 
2024-12-17 08:26:02.078472: Pseudo dice [np.float32(0.5251)] 
2024-12-17 08:26:02.081985: Epoch time: 41.23 s 
2024-12-17 08:26:02.623540:  
2024-12-17 08:26:02.629100: Epoch 47 
2024-12-17 08:26:02.632198: Current learning rate: 0.00565 
2024-12-17 08:26:43.866674: train_loss -0.7183 
2024-12-17 08:26:43.872739: val_loss -0.421 
2024-12-17 08:26:43.874763: Pseudo dice [np.float32(0.5338)] 
2024-12-17 08:26:43.879304: Epoch time: 41.24 s 
2024-12-17 08:26:44.412693:  
2024-12-17 08:26:44.417720: Epoch 48 
2024-12-17 08:26:44.421556: Current learning rate: 0.00555 
2024-12-17 08:27:25.644968: train_loss -0.7261 
2024-12-17 08:27:25.651069: val_loss -0.315 
2024-12-17 08:27:25.654579: Pseudo dice [np.float32(0.441)] 
2024-12-17 08:27:25.657086: Epoch time: 41.23 s 
2024-12-17 08:27:26.202868:  
2024-12-17 08:27:26.206905: Epoch 49 
2024-12-17 08:27:26.211470: Current learning rate: 0.00546 
2024-12-17 08:28:07.490230: train_loss -0.731 
2024-12-17 08:28:07.496338: val_loss -0.388 
2024-12-17 08:28:07.499951: Pseudo dice [np.float32(0.5236)] 
2024-12-17 08:28:07.503466: Epoch time: 41.29 s 
2024-12-17 08:28:08.193526:  
2024-12-17 08:28:08.198590: Epoch 50 
2024-12-17 08:28:08.201369: Current learning rate: 0.00536 
2024-12-17 08:28:49.448435: train_loss -0.7329 
2024-12-17 08:28:49.453453: val_loss -0.4678 
2024-12-17 08:28:49.457001: Pseudo dice [np.float32(0.6128)] 
2024-12-17 08:28:49.460107: Epoch time: 41.26 s 
2024-12-17 08:28:49.995287:  
2024-12-17 08:28:50.000327: Epoch 51 
2024-12-17 08:28:50.003837: Current learning rate: 0.00526 
2024-12-17 08:29:31.233687: train_loss -0.7393 
2024-12-17 08:29:31.239792: val_loss -0.3946 
2024-12-17 08:29:31.242831: Pseudo dice [np.float32(0.5889)] 
2024-12-17 08:29:31.246354: Epoch time: 41.24 s 
2024-12-17 08:29:31.783995:  
2024-12-17 08:29:31.788021: Epoch 52 
2024-12-17 08:29:31.791560: Current learning rate: 0.00517 
2024-12-17 08:30:13.019239: train_loss -0.7426 
2024-12-17 08:30:13.025366: val_loss -0.5302 
2024-12-17 08:30:13.027914: Pseudo dice [np.float32(0.663)] 
2024-12-17 08:30:13.031986: Epoch time: 41.24 s 
2024-12-17 08:30:13.714607:  
2024-12-17 08:30:13.718647: Epoch 53 
2024-12-17 08:30:13.723243: Current learning rate: 0.00507 
2024-12-17 08:30:54.948015: train_loss -0.7605 
2024-12-17 08:30:54.955082: val_loss -0.4206 
2024-12-17 08:30:54.959123: Pseudo dice [np.float32(0.5783)] 
2024-12-17 08:30:54.962149: Epoch time: 41.23 s 
2024-12-17 08:30:55.502295:  
2024-12-17 08:30:55.507321: Epoch 54 
2024-12-17 08:30:55.510143: Current learning rate: 0.00497 
2024-12-17 08:31:36.726995: train_loss -0.7585 
2024-12-17 08:31:36.733574: val_loss -0.3608 
2024-12-17 08:31:36.737141: Pseudo dice [np.float32(0.5463)] 
2024-12-17 08:31:36.739647: Epoch time: 41.23 s 
2024-12-17 08:31:37.282428:  
2024-12-17 08:31:37.287459: Epoch 55 
2024-12-17 08:31:37.290332: Current learning rate: 0.00487 
2024-12-17 08:32:18.521894: train_loss -0.7427 
2024-12-17 08:32:18.527506: val_loss -0.4536 
2024-12-17 08:32:18.530056: Pseudo dice [np.float32(0.6122)] 
2024-12-17 08:32:18.533573: Epoch time: 41.24 s 
2024-12-17 08:32:19.077253:  
2024-12-17 08:32:19.082300: Epoch 56 
2024-12-17 08:32:19.085135: Current learning rate: 0.00478 
2024-12-17 08:33:00.306727: train_loss -0.7551 
2024-12-17 08:33:00.313305: val_loss -0.4078 
2024-12-17 08:33:00.315820: Pseudo dice [np.float32(0.6351)] 
2024-12-17 08:33:00.319333: Epoch time: 41.23 s 
2024-12-17 08:33:00.322349: Yayy! New best EMA pseudo Dice: 0.5651999711990356 
2024-12-17 08:33:01.023720:  
2024-12-17 08:33:01.028760: Epoch 57 
2024-12-17 08:33:01.032292: Current learning rate: 0.00468 
2024-12-17 08:33:42.241920: train_loss -0.7694 
2024-12-17 08:33:42.248433: val_loss -0.2703 
2024-12-17 08:33:42.251487: Pseudo dice [np.float32(0.5157)] 
2024-12-17 08:33:42.255057: Epoch time: 41.22 s 
2024-12-17 08:33:42.791030:  
2024-12-17 08:33:42.796072: Epoch 58 
2024-12-17 08:33:42.799672: Current learning rate: 0.00458 
2024-12-17 08:34:24.022988: train_loss -0.7582 
2024-12-17 08:34:24.028998: val_loss -0.3833 
2024-12-17 08:34:24.032008: Pseudo dice [np.float32(0.5743)] 
2024-12-17 08:34:24.035517: Epoch time: 41.23 s 
2024-12-17 08:34:24.578235:  
2024-12-17 08:34:24.583789: Epoch 59 
2024-12-17 08:34:24.587346: Current learning rate: 0.00448 
2024-12-17 08:35:05.797332: train_loss -0.771 
2024-12-17 08:35:05.804929: val_loss -0.3452 
2024-12-17 08:35:05.808438: Pseudo dice [np.float32(0.4718)] 
2024-12-17 08:35:05.811944: Epoch time: 41.22 s 
2024-12-17 08:35:06.366483:  
2024-12-17 08:35:06.372028: Epoch 60 
2024-12-17 08:35:06.375536: Current learning rate: 0.00438 
2024-12-17 08:35:47.599502: train_loss -0.7684 
2024-12-17 08:35:47.605549: val_loss -0.3783 
2024-12-17 08:35:47.609068: Pseudo dice [np.float32(0.5433)] 
2024-12-17 08:35:47.612087: Epoch time: 41.23 s 
2024-12-17 08:35:48.305189:  
2024-12-17 08:35:48.310232: Epoch 61 
2024-12-17 08:35:48.313318: Current learning rate: 0.00429 
2024-12-17 08:36:29.539588: train_loss -0.7554 
2024-12-17 08:36:29.545602: val_loss -0.377 
2024-12-17 08:36:29.549107: Pseudo dice [np.float32(0.5682)] 
2024-12-17 08:36:29.552114: Epoch time: 41.23 s 
2024-12-17 08:36:30.100960:  
2024-12-17 08:36:30.105985: Epoch 62 
2024-12-17 08:36:30.109509: Current learning rate: 0.00419 
2024-12-17 08:37:11.333098: train_loss -0.7673 
2024-12-17 08:37:11.339634: val_loss -0.3741 
2024-12-17 08:37:11.343157: Pseudo dice [np.float32(0.5992)] 
2024-12-17 08:37:11.345671: Epoch time: 41.23 s 
2024-12-17 08:37:11.894235:  
2024-12-17 08:37:11.898809: Epoch 63 
2024-12-17 08:37:11.908843: Current learning rate: 0.00409 
2024-12-17 08:37:53.129080: train_loss -0.7711 
2024-12-17 08:37:53.136201: val_loss -0.237 
2024-12-17 08:37:53.139248: Pseudo dice [np.float32(0.3707)] 
2024-12-17 08:37:53.141785: Epoch time: 41.23 s 
2024-12-17 08:37:53.691394:  
2024-12-17 08:37:53.695408: Epoch 64 
2024-12-17 08:37:53.698950: Current learning rate: 0.00399 
2024-12-17 08:38:34.912363: train_loss -0.7725 
2024-12-17 08:38:34.918429: val_loss -0.2679 
2024-12-17 08:38:34.921506: Pseudo dice [np.float32(0.4776)] 
2024-12-17 08:38:34.924550: Epoch time: 41.22 s 
2024-12-17 08:38:35.471397:  
2024-12-17 08:38:35.476418: Epoch 65 
2024-12-17 08:38:35.481436: Current learning rate: 0.00389 
2024-12-17 08:39:16.699232: train_loss -0.7824 
2024-12-17 08:39:16.705745: val_loss -0.3259 
2024-12-17 08:39:16.709254: Pseudo dice [np.float32(0.5597)] 
2024-12-17 08:39:16.711760: Epoch time: 41.23 s 
2024-12-17 08:39:17.261514:  
2024-12-17 08:39:17.266403: Epoch 66 
2024-12-17 08:39:17.268911: Current learning rate: 0.00379 
2024-12-17 08:39:58.496040: train_loss -0.787 
2024-12-17 08:39:58.502565: val_loss -0.4036 
2024-12-17 08:39:58.506081: Pseudo dice [np.float32(0.6008)] 
2024-12-17 08:39:58.509511: Epoch time: 41.24 s 
2024-12-17 08:39:59.058040:  
2024-12-17 08:39:59.063063: Epoch 67 
2024-12-17 08:39:59.066581: Current learning rate: 0.00369 
2024-12-17 08:40:40.272724: train_loss -0.7754 
2024-12-17 08:40:40.278788: val_loss -0.4279 
2024-12-17 08:40:40.282341: Pseudo dice [np.float32(0.5986)] 
2024-12-17 08:40:40.285381: Epoch time: 41.22 s 
2024-12-17 08:40:40.842021:  
2024-12-17 08:40:40.847035: Epoch 68 
2024-12-17 08:40:40.850047: Current learning rate: 0.00359 
2024-12-17 08:41:22.080899: train_loss -0.7897 
2024-12-17 08:41:22.088439: val_loss -0.365 
2024-12-17 08:41:22.091455: Pseudo dice [np.float32(0.587)] 
2024-12-17 08:41:22.094490: Epoch time: 41.24 s 
2024-12-17 08:41:22.798712:  
2024-12-17 08:41:22.803702: Epoch 69 
2024-12-17 08:41:22.807212: Current learning rate: 0.00349 
2024-12-17 08:42:04.024849: train_loss -0.7812 
2024-12-17 08:42:04.030872: val_loss -0.3416 
2024-12-17 08:42:04.034388: Pseudo dice [np.float32(0.5216)] 
2024-12-17 08:42:04.037619: Epoch time: 41.23 s 
2024-12-17 08:42:04.597555:  
2024-12-17 08:42:04.602089: Epoch 70 
2024-12-17 08:42:04.605162: Current learning rate: 0.00338 
2024-12-17 08:42:45.855167: train_loss -0.7611 
2024-12-17 08:42:45.862688: val_loss -0.3219 
2024-12-17 08:42:45.867203: Pseudo dice [np.float32(0.4988)] 
2024-12-17 08:42:45.870215: Epoch time: 41.26 s 
2024-12-17 08:42:46.434727:  
2024-12-17 08:42:46.440277: Epoch 71 
2024-12-17 08:42:46.443791: Current learning rate: 0.00328 
2024-12-17 08:43:27.691469: train_loss -0.7683 
2024-12-17 08:43:27.697506: val_loss -0.4001 
2024-12-17 08:43:27.701095: Pseudo dice [np.float32(0.5872)] 
2024-12-17 08:43:27.704138: Epoch time: 41.26 s 
2024-12-17 08:43:28.267499:  
2024-12-17 08:43:28.272511: Epoch 72 
2024-12-17 08:43:28.275524: Current learning rate: 0.00318 
2024-12-17 08:44:09.494126: train_loss -0.7933 
2024-12-17 08:44:09.500212: val_loss -0.4349 
2024-12-17 08:44:09.503748: Pseudo dice [np.float32(0.5994)] 
2024-12-17 08:44:09.506430: Epoch time: 41.23 s 
2024-12-17 08:44:10.066864:  
2024-12-17 08:44:10.071938: Epoch 73 
2024-12-17 08:44:10.075035: Current learning rate: 0.00308 
2024-12-17 08:44:51.307608: train_loss -0.7885 
2024-12-17 08:44:51.314258: val_loss -0.4373 
2024-12-17 08:44:51.317372: Pseudo dice [np.float32(0.665)] 
2024-12-17 08:44:51.320436: Epoch time: 41.24 s 
2024-12-17 08:44:51.880847:  
2024-12-17 08:44:51.885861: Epoch 74 
2024-12-17 08:44:51.888368: Current learning rate: 0.00297 
2024-12-17 08:45:33.130044: train_loss -0.7975 
2024-12-17 08:45:33.136130: val_loss -0.4805 
2024-12-17 08:45:33.139189: Pseudo dice [np.float32(0.6554)] 
2024-12-17 08:45:33.141754: Epoch time: 41.25 s 
2024-12-17 08:45:33.144830: Yayy! New best EMA pseudo Dice: 0.5734999775886536 
2024-12-17 08:45:33.858505:  
2024-12-17 08:45:33.862532: Epoch 75 
2024-12-17 08:45:33.866552: Current learning rate: 0.00287 
2024-12-17 08:46:15.075648: train_loss -0.8183 
2024-12-17 08:46:15.081696: val_loss -0.3518 
2024-12-17 08:46:15.085200: Pseudo dice [np.float32(0.6426)] 
2024-12-17 08:46:15.088208: Epoch time: 41.22 s 
2024-12-17 08:46:15.090713: Yayy! New best EMA pseudo Dice: 0.5803999900817871 
2024-12-17 08:46:15.811359:  
2024-12-17 08:46:15.816900: Epoch 76 
2024-12-17 08:46:15.820001: Current learning rate: 0.00277 
2024-12-17 08:46:57.032557: train_loss -0.8157 
2024-12-17 08:46:57.039076: val_loss -0.3549 
2024-12-17 08:46:57.042583: Pseudo dice [np.float32(0.5592)] 
2024-12-17 08:46:57.045593: Epoch time: 41.22 s 
2024-12-17 08:46:57.755225:  
2024-12-17 08:46:57.760258: Epoch 77 
2024-12-17 08:46:57.763316: Current learning rate: 0.00266 
2024-12-17 08:47:38.976251: train_loss -0.8103 
2024-12-17 08:47:38.981263: val_loss -0.2728 
2024-12-17 08:47:38.984772: Pseudo dice [np.float32(0.5085)] 
2024-12-17 08:47:38.987278: Epoch time: 41.22 s 
2024-12-17 08:47:39.564807:  
2024-12-17 08:47:39.568831: Epoch 78 
2024-12-17 08:47:39.572355: Current learning rate: 0.00256 
2024-12-17 08:48:20.791733: train_loss -0.8066 
2024-12-17 08:48:20.797749: val_loss -0.3374 
2024-12-17 08:48:20.800255: Pseudo dice [np.float32(0.5331)] 
2024-12-17 08:48:20.803762: Epoch time: 41.23 s 
2024-12-17 08:48:21.367515:  
2024-12-17 08:48:21.372526: Epoch 79 
2024-12-17 08:48:21.375034: Current learning rate: 0.00245 
2024-12-17 08:49:02.592183: train_loss -0.8113 
2024-12-17 08:49:02.598225: val_loss -0.4364 
2024-12-17 08:49:02.601242: Pseudo dice [np.float32(0.6119)] 
2024-12-17 08:49:02.603752: Epoch time: 41.23 s 
2024-12-17 08:49:03.170790:  
2024-12-17 08:49:03.174846: Epoch 80 
2024-12-17 08:49:03.178897: Current learning rate: 0.00235 
2024-12-17 08:49:44.395864: train_loss -0.8136 
2024-12-17 08:49:44.401378: val_loss -0.3574 
2024-12-17 08:49:44.403885: Pseudo dice [np.float32(0.564)] 
2024-12-17 08:49:44.406392: Epoch time: 41.23 s 
2024-12-17 08:49:44.976034:  
2024-12-17 08:49:44.980057: Epoch 81 
2024-12-17 08:49:44.983584: Current learning rate: 0.00224 
2024-12-17 08:50:26.204197: train_loss -0.8026 
2024-12-17 08:50:26.209742: val_loss -0.4107 
2024-12-17 08:50:26.212813: Pseudo dice [np.float32(0.639)] 
2024-12-17 08:50:26.214838: Epoch time: 41.23 s 
2024-12-17 08:50:26.783051:  
2024-12-17 08:50:26.788605: Epoch 82 
2024-12-17 08:50:26.791614: Current learning rate: 0.00214 
2024-12-17 08:51:07.992666: train_loss -0.8156 
2024-12-17 08:51:07.999187: val_loss -0.2757 
2024-12-17 08:51:08.002197: Pseudo dice [np.float32(0.4601)] 
2024-12-17 08:51:08.005708: Epoch time: 41.21 s 
2024-12-17 08:51:08.544923:  
2024-12-17 08:51:08.548934: Epoch 83 
2024-12-17 08:51:08.552442: Current learning rate: 0.00203 
2024-12-17 08:51:49.777384: train_loss -0.8025 
2024-12-17 08:51:49.782452: val_loss -0.3864 
2024-12-17 08:51:49.786482: Pseudo dice [np.float32(0.5409)] 
2024-12-17 08:51:49.789030: Epoch time: 41.23 s 
2024-12-17 08:51:50.337373:  
2024-12-17 08:51:50.340401: Epoch 84 
2024-12-17 08:51:50.342935: Current learning rate: 0.00192 
2024-12-17 08:52:31.556830: train_loss -0.8198 
2024-12-17 08:52:31.562429: val_loss -0.4134 
2024-12-17 08:52:31.565941: Pseudo dice [np.float32(0.6399)] 
2024-12-17 08:52:31.568447: Epoch time: 41.22 s 
2024-12-17 08:52:32.257506:  
2024-12-17 08:52:32.262295: Epoch 85 
2024-12-17 08:52:32.265807: Current learning rate: 0.00181 
2024-12-17 08:53:13.478989: train_loss -0.817 
2024-12-17 08:53:13.486006: val_loss -0.3253 
2024-12-17 08:53:13.490019: Pseudo dice [np.float32(0.5385)] 
2024-12-17 08:53:13.493527: Epoch time: 41.22 s 
2024-12-17 08:53:14.029583:  
2024-12-17 08:53:14.033613: Epoch 86 
2024-12-17 08:53:14.037141: Current learning rate: 0.0017 
2024-12-17 08:53:55.248889: train_loss -0.811 
2024-12-17 08:53:55.253946: val_loss -0.3445 
2024-12-17 08:53:55.256997: Pseudo dice [np.float32(0.5466)] 
2024-12-17 08:53:55.260036: Epoch time: 41.22 s 
2024-12-17 08:53:55.788796:  
2024-12-17 08:53:55.793850: Epoch 87 
2024-12-17 08:53:55.796927: Current learning rate: 0.00159 
2024-12-17 08:54:37.039697: train_loss -0.8244 
2024-12-17 08:54:37.045225: val_loss -0.3855 
2024-12-17 08:54:37.048745: Pseudo dice [np.float32(0.5944)] 
2024-12-17 08:54:37.052260: Epoch time: 41.25 s 
2024-12-17 08:54:37.583498:  
2024-12-17 08:54:37.588511: Epoch 88 
2024-12-17 08:54:37.591524: Current learning rate: 0.00148 
2024-12-17 08:55:18.846678: train_loss -0.8151 
2024-12-17 08:55:18.858834: val_loss -0.4032 
2024-12-17 08:55:18.863904: Pseudo dice [np.float32(0.6508)] 
2024-12-17 08:55:18.866952: Epoch time: 41.26 s 
2024-12-17 08:55:19.398015:  
2024-12-17 08:55:19.402538: Epoch 89 
2024-12-17 08:55:19.406049: Current learning rate: 0.00137 
2024-12-17 08:56:00.630384: train_loss -0.8015 
2024-12-17 08:56:00.635971: val_loss -0.3277 
2024-12-17 08:56:00.638510: Pseudo dice [np.float32(0.5889)] 
2024-12-17 08:56:00.642053: Epoch time: 41.23 s 
2024-12-17 08:56:01.170644:  
2024-12-17 08:56:01.175665: Epoch 90 
2024-12-17 08:56:01.179181: Current learning rate: 0.00126 
2024-12-17 08:56:42.423401: train_loss -0.8392 
2024-12-17 08:56:42.429427: val_loss -0.356 
2024-12-17 08:56:42.432933: Pseudo dice [np.float32(0.5887)] 
2024-12-17 08:56:42.436457: Epoch time: 41.25 s 
2024-12-17 08:56:42.968439:  
2024-12-17 08:56:42.972510: Epoch 91 
2024-12-17 08:56:42.976593: Current learning rate: 0.00115 
2024-12-17 08:57:24.216150: train_loss -0.8236 
2024-12-17 08:57:24.222176: val_loss -0.3417 
2024-12-17 08:57:24.224688: Pseudo dice [np.float32(0.5953)] 
2024-12-17 08:57:24.228200: Epoch time: 41.25 s 
2024-12-17 08:57:24.231210: Yayy! New best EMA pseudo Dice: 0.5807999968528748 
2024-12-17 08:57:24.914610:  
2024-12-17 08:57:24.919124: Epoch 92 
2024-12-17 08:57:24.922138: Current learning rate: 0.00103 
2024-12-17 08:58:06.169759: train_loss -0.8292 
2024-12-17 08:58:06.174828: val_loss -0.3602 
2024-12-17 08:58:06.177450: Pseudo dice [np.float32(0.5991)] 
2024-12-17 08:58:06.179962: Epoch time: 41.26 s 
2024-12-17 08:58:06.183476: Yayy! New best EMA pseudo Dice: 0.5825999975204468 
2024-12-17 08:58:06.871850:  
2024-12-17 08:58:06.876912: Epoch 93 
2024-12-17 08:58:06.879925: Current learning rate: 0.00091 
2024-12-17 08:58:48.123301: train_loss -0.8221 
2024-12-17 08:58:48.127833: val_loss -0.3245 
2024-12-17 08:58:48.131881: Pseudo dice [np.float32(0.6155)] 
2024-12-17 08:58:48.134896: Epoch time: 41.25 s 
2024-12-17 08:58:48.137406: Yayy! New best EMA pseudo Dice: 0.5859000086784363 
2024-12-17 08:58:48.975490:  
2024-12-17 08:58:48.983461: Epoch 94 
2024-12-17 08:58:48.987989: Current learning rate: 0.00079 
2024-12-17 08:59:30.223339: train_loss -0.8176 
2024-12-17 08:59:30.228859: val_loss -0.3794 
2024-12-17 08:59:30.232369: Pseudo dice [np.float32(0.6304)] 
2024-12-17 08:59:30.234873: Epoch time: 41.25 s 
2024-12-17 08:59:30.237377: Yayy! New best EMA pseudo Dice: 0.5903000235557556 
2024-12-17 08:59:30.932352:  
2024-12-17 08:59:30.937952: Epoch 95 
2024-12-17 08:59:30.941018: Current learning rate: 0.00067 
2024-12-17 09:00:12.168358: train_loss -0.8177 
2024-12-17 09:00:12.173932: val_loss -0.3944 
2024-12-17 09:00:12.176985: Pseudo dice [np.float32(0.5785)] 
2024-12-17 09:00:12.180034: Epoch time: 41.24 s 
2024-12-17 09:00:12.707702:  
2024-12-17 09:00:12.713263: Epoch 96 
2024-12-17 09:00:12.716316: Current learning rate: 0.00055 
2024-12-17 09:00:53.952533: train_loss -0.8387 
2024-12-17 09:00:53.959050: val_loss -0.3773 
2024-12-17 09:00:53.961906: Pseudo dice [np.float32(0.5885)] 
2024-12-17 09:00:53.964423: Epoch time: 41.25 s 
2024-12-17 09:00:54.504978:  
2024-12-17 09:00:54.508993: Epoch 97 
2024-12-17 09:00:54.512507: Current learning rate: 0.00043 
2024-12-17 09:01:35.746325: train_loss -0.8337 
2024-12-17 09:01:35.752341: val_loss -0.3311 
2024-12-17 09:01:35.755352: Pseudo dice [np.float32(0.5556)] 
2024-12-17 09:01:35.757859: Epoch time: 41.24 s 
2024-12-17 09:01:36.302277:  
2024-12-17 09:01:36.305293: Epoch 98 
2024-12-17 09:01:36.309335: Current learning rate: 0.0003 
2024-12-17 09:02:17.540496: train_loss -0.8322 
2024-12-17 09:02:17.546512: val_loss -0.3407 
2024-12-17 09:02:17.550525: Pseudo dice [np.float32(0.6028)] 
2024-12-17 09:02:17.553031: Epoch time: 41.24 s 
2024-12-17 09:02:18.093983:  
2024-12-17 09:02:18.099551: Epoch 99 
2024-12-17 09:02:18.102099: Current learning rate: 0.00016 
2024-12-17 09:02:59.323697: train_loss -0.8261 
2024-12-17 09:02:59.330225: val_loss -0.3643 
2024-12-17 09:02:59.332736: Pseudo dice [np.float32(0.618)] 
2024-12-17 09:02:59.336251: Epoch time: 41.23 s 
2024-12-17 09:02:59.338762: Yayy! New best EMA pseudo Dice: 0.590499997138977 
2024-12-17 09:03:00.285153: Training done. 
2024-12-17 09:03:00.319193: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-17 09:03:00.324192: The split file contains 5 splits. 
2024-12-17 09:03:00.327192: Desired fold for training: 0 
2024-12-17 09:03:00.332191: This split has 100 training and 26 validation cases. 
2024-12-17 09:03:00.337194: predicting colon_008 
2024-12-17 09:03:00.341191: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2024-12-17 09:03:02.926533: predicting colon_027 
2024-12-17 09:03:02.950534: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2024-12-17 09:03:03.732936: predicting colon_030 
2024-12-17 09:03:03.744936: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2024-12-17 09:03:04.846530: predicting colon_033 
2024-12-17 09:03:04.863530: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2024-12-17 09:03:06.807886: predicting colon_041 
2024-12-17 09:03:06.830107: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2024-12-17 09:03:11.997313: predicting colon_042 
2024-12-17 09:03:12.032826: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2024-12-17 09:03:14.665093: predicting colon_061 
2024-12-17 09:03:14.686093: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2024-12-17 09:03:17.717969: predicting colon_074 
2024-12-17 09:03:17.752970: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2024-12-17 09:03:21.230518: predicting colon_075 
2024-12-17 09:03:21.263514: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2024-12-17 09:03:23.221709: predicting colon_088 
2024-12-17 09:03:23.243709: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2024-12-17 09:03:26.298372: predicting colon_091 
2024-12-17 09:03:26.325879: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2024-12-17 09:03:29.948880: predicting colon_092 
2024-12-17 09:03:29.976881: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2024-12-17 09:03:32.977525: predicting colon_095 
2024-12-17 09:03:32.998525: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2024-12-17 09:03:34.945404: predicting colon_102 
2024-12-17 09:03:34.965404: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2024-12-17 09:03:39.293260: predicting colon_111 
2024-12-17 09:03:39.322778: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2024-12-17 09:03:40.564659: predicting colon_115 
2024-12-17 09:03:40.581658: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2024-12-17 09:03:42.527460: predicting colon_118 
2024-12-17 09:03:42.550460: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2024-12-17 09:03:45.581400: predicting colon_124 
2024-12-17 09:03:45.613403: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2024-12-17 09:03:48.632355: predicting colon_127 
2024-12-17 09:03:48.656355: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2024-12-17 09:03:54.693405: predicting colon_154 
2024-12-17 09:03:54.731913: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2024-12-17 09:03:56.682048: predicting colon_161 
2024-12-17 09:03:56.703048: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2024-12-17 09:03:58.667188: predicting colon_162 
2024-12-17 09:03:58.694188: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2024-12-17 09:04:03.877167: predicting colon_165 
2024-12-17 09:04:03.925169: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2024-12-17 09:04:08.243506: predicting colon_166 
2024-12-17 09:04:08.268507: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2024-12-17 09:04:10.215094: predicting colon_169 
2024-12-17 09:04:10.234230: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2024-12-17 09:04:16.286837: predicting colon_187 
2024-12-17 09:04:16.336343: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2024-12-17 09:04:33.026542: Validation complete 
2024-12-17 09:04:33.031544: Mean Validation Dice:  0.29527878825286147 
