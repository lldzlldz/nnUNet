2025-01-11 23:15:40.407478: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.25 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-11 23:15:40.411477: self.oversample_foreground_percent 0.25 
2025-01-11 23:15:40.414985: do_dummy_2d_data_aug: True 
2025-01-11 23:15:40.432298: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-11 23:15:40.438298: The split file contains 5 splits. 
2025-01-11 23:15:40.441297: Desired fold for training: 0 
2025-01-11 23:15:40.443297: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [40, 160, 160], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-01-11 23:15:47.482841: unpacking dataset... 
2025-01-11 23:15:47.719348: unpacking done... 
2025-01-11 23:15:50.866409:  
2025-01-11 23:15:50.866409: Epoch 0 
2025-01-11 23:15:50.871423: Current learning rate: 0.01 
2025-01-11 23:16:35.625706: train_loss 0.0409 
2025-01-11 23:16:35.626706: val_loss -0.0043 
2025-01-11 23:16:35.632222: Pseudo dice [np.float32(0.0)] 
2025-01-11 23:16:35.635734: Epoch time: 44.76 s 
2025-01-11 23:16:35.638242: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-11 23:16:36.301296:  
2025-01-11 23:16:36.301296: Epoch 1 
2025-01-11 23:16:36.307631: Current learning rate: 0.00996 
2025-01-11 23:17:16.655057: train_loss -0.0616 
2025-01-11 23:17:16.655562: val_loss -0.1588 
2025-01-11 23:17:16.661690: Pseudo dice [np.float32(0.2939)] 
2025-01-11 23:17:16.665754: Epoch time: 40.35 s 
2025-01-11 23:17:16.668809: Yayy! New best EMA pseudo Dice: 0.029400000348687172 
2025-01-11 23:17:17.431522:  
2025-01-11 23:17:17.433025: Epoch 2 
2025-01-11 23:17:17.438039: Current learning rate: 0.00993 
2025-01-11 23:17:57.753700: train_loss -0.1829 
2025-01-11 23:17:57.754203: val_loss -0.2472 
2025-01-11 23:17:57.759749: Pseudo dice [np.float32(0.3102)] 
2025-01-11 23:17:57.762781: Epoch time: 40.32 s 
2025-01-11 23:17:57.766804: Yayy! New best EMA pseudo Dice: 0.057500001043081284 
2025-01-11 23:17:58.575159:  
2025-01-11 23:17:58.575159: Epoch 3 
2025-01-11 23:17:58.580683: Current learning rate: 0.00989 
2025-01-11 23:18:38.873081: train_loss -0.237 
2025-01-11 23:18:38.873081: val_loss -0.2422 
2025-01-11 23:18:38.880601: Pseudo dice [np.float32(0.3152)] 
2025-01-11 23:18:38.883923: Epoch time: 40.3 s 
2025-01-11 23:18:38.886433: Yayy! New best EMA pseudo Dice: 0.08320000022649765 
2025-01-11 23:18:39.625221:  
2025-01-11 23:18:39.625221: Epoch 4 
2025-01-11 23:18:39.631250: Current learning rate: 0.00986 
2025-01-11 23:19:19.890170: train_loss -0.2592 
2025-01-11 23:19:19.891172: val_loss -0.2485 
2025-01-11 23:19:19.896689: Pseudo dice [np.float32(0.3203)] 
2025-01-11 23:19:19.901197: Epoch time: 40.26 s 
2025-01-11 23:19:19.904211: Yayy! New best EMA pseudo Dice: 0.10689999908208847 
2025-01-11 23:19:20.826733:  
2025-01-11 23:19:20.827733: Epoch 5 
2025-01-11 23:19:20.832813: Current learning rate: 0.00982 
2025-01-11 23:20:01.525677: train_loss -0.3002 
2025-01-11 23:20:01.527188: val_loss -0.3737 
2025-01-11 23:20:01.533350: Pseudo dice [np.float32(0.435)] 
2025-01-11 23:20:01.536387: Epoch time: 40.7 s 
2025-01-11 23:20:01.539928: Yayy! New best EMA pseudo Dice: 0.13979999721050262 
2025-01-11 23:20:02.300619:  
2025-01-11 23:20:02.301121: Epoch 6 
2025-01-11 23:20:02.306131: Current learning rate: 0.00978 
2025-01-11 23:20:43.160627: train_loss -0.2933 
2025-01-11 23:20:43.161628: val_loss -0.2795 
2025-01-11 23:20:43.167147: Pseudo dice [np.float32(0.2949)] 
2025-01-11 23:20:43.171660: Epoch time: 40.86 s 
2025-01-11 23:20:43.174672: Yayy! New best EMA pseudo Dice: 0.15530000627040863 
2025-01-11 23:20:43.979199:  
2025-01-11 23:20:43.979199: Epoch 7 
2025-01-11 23:20:43.984719: Current learning rate: 0.00975 
2025-01-11 23:21:26.382399: train_loss -0.3405 
2025-01-11 23:21:26.382903: val_loss -0.2984 
2025-01-11 23:21:26.388970: Pseudo dice [np.float32(0.3635)] 
2025-01-11 23:21:26.393016: Epoch time: 42.4 s 
2025-01-11 23:21:26.397063: Yayy! New best EMA pseudo Dice: 0.1761000007390976 
2025-01-11 23:21:27.208334:  
2025-01-11 23:21:27.208334: Epoch 8 
2025-01-11 23:21:27.214461: Current learning rate: 0.00971 
2025-01-11 23:22:09.774523: train_loss -0.336 
2025-01-11 23:22:09.775526: val_loss -0.2687 
2025-01-11 23:22:09.782040: Pseudo dice [np.float32(0.3126)] 
2025-01-11 23:22:09.785549: Epoch time: 42.57 s 
2025-01-11 23:22:09.788058: Yayy! New best EMA pseudo Dice: 0.18970000743865967 
2025-01-11 23:22:10.624016:  
2025-01-11 23:22:10.624016: Epoch 9 
2025-01-11 23:22:10.630092: Current learning rate: 0.00968 
2025-01-11 23:22:52.251502: train_loss -0.3104 
2025-01-11 23:22:52.252036: val_loss -0.3152 
2025-01-11 23:22:52.255552: Pseudo dice [np.float32(0.3683)] 
2025-01-11 23:22:52.259564: Epoch time: 41.63 s 
2025-01-11 23:22:52.262073: Yayy! New best EMA pseudo Dice: 0.20759999752044678 
2025-01-11 23:22:53.102247:  
2025-01-11 23:22:53.102751: Epoch 10 
2025-01-11 23:22:53.108768: Current learning rate: 0.00964 
2025-01-11 23:23:34.044807: train_loss -0.3965 
2025-01-11 23:23:34.045839: val_loss -0.3548 
2025-01-11 23:23:34.051481: Pseudo dice [np.float32(0.4)] 
2025-01-11 23:23:34.054529: Epoch time: 40.94 s 
2025-01-11 23:23:34.057597: Yayy! New best EMA pseudo Dice: 0.22679999470710754 
2025-01-11 23:23:34.880776:  
2025-01-11 23:23:34.880776: Epoch 11 
2025-01-11 23:23:34.885787: Current learning rate: 0.0096 
2025-01-11 23:24:16.227008: train_loss -0.398 
2025-01-11 23:24:16.227517: val_loss -0.383 
2025-01-11 23:24:16.232686: Pseudo dice [np.float32(0.4457)] 
2025-01-11 23:24:16.236260: Epoch time: 41.35 s 
2025-01-11 23:24:16.239312: Yayy! New best EMA pseudo Dice: 0.24869999289512634 
2025-01-11 23:24:17.055556:  
2025-01-11 23:24:17.056562: Epoch 12 
2025-01-11 23:24:17.061159: Current learning rate: 0.00957 
2025-01-11 23:24:57.472876: train_loss -0.3746 
2025-01-11 23:24:57.472876: val_loss -0.425 
2025-01-11 23:24:57.478442: Pseudo dice [np.float32(0.4907)] 
2025-01-11 23:24:57.481947: Epoch time: 40.42 s 
2025-01-11 23:24:57.484955: Yayy! New best EMA pseudo Dice: 0.2728999853134155 
2025-01-11 23:24:58.480429:  
2025-01-11 23:24:58.480429: Epoch 13 
2025-01-11 23:24:58.485968: Current learning rate: 0.00953 
2025-01-11 23:25:39.343812: train_loss -0.3868 
2025-01-11 23:25:39.344315: val_loss -0.333 
2025-01-11 23:25:39.349872: Pseudo dice [np.float32(0.3985)] 
2025-01-11 23:25:39.352901: Epoch time: 40.86 s 
2025-01-11 23:25:39.355421: Yayy! New best EMA pseudo Dice: 0.2854999899864197 
2025-01-11 23:25:40.170841:  
2025-01-11 23:25:40.171358: Epoch 14 
2025-01-11 23:25:40.176369: Current learning rate: 0.00949 
2025-01-11 23:26:21.037459: train_loss -0.3836 
2025-01-11 23:26:21.037459: val_loss -0.265 
2025-01-11 23:26:21.044663: Pseudo dice [np.float32(0.336)] 
2025-01-11 23:26:21.047706: Epoch time: 40.87 s 
2025-01-11 23:26:21.050740: Yayy! New best EMA pseudo Dice: 0.2904999852180481 
2025-01-11 23:26:21.878643:  
2025-01-11 23:26:21.878643: Epoch 15 
2025-01-11 23:26:21.884698: Current learning rate: 0.00946 
2025-01-11 23:27:02.210008: train_loss -0.4003 
2025-01-11 23:27:02.210008: val_loss -0.4566 
2025-01-11 23:27:02.217643: Pseudo dice [np.float32(0.5134)] 
2025-01-11 23:27:02.220684: Epoch time: 40.33 s 
2025-01-11 23:27:02.223216: Yayy! New best EMA pseudo Dice: 0.31279999017715454 
2025-01-11 23:27:03.044863:  
2025-01-11 23:27:03.045365: Epoch 16 
2025-01-11 23:27:03.050376: Current learning rate: 0.00942 
2025-01-11 23:27:44.158565: train_loss -0.4402 
2025-01-11 23:27:44.159569: val_loss -0.3712 
2025-01-11 23:27:44.165580: Pseudo dice [np.float32(0.4916)] 
2025-01-11 23:27:44.169592: Epoch time: 41.11 s 
2025-01-11 23:27:44.173099: Yayy! New best EMA pseudo Dice: 0.33070001006126404 
2025-01-11 23:27:44.999795:  
2025-01-11 23:27:44.999795: Epoch 17 
2025-01-11 23:27:45.004829: Current learning rate: 0.00939 
2025-01-11 23:28:27.120879: train_loss -0.4133 
2025-01-11 23:28:27.122393: val_loss -0.3919 
2025-01-11 23:28:27.128493: Pseudo dice [np.float32(0.4722)] 
2025-01-11 23:28:27.131535: Epoch time: 42.12 s 
2025-01-11 23:28:27.134569: Yayy! New best EMA pseudo Dice: 0.3447999954223633 
2025-01-11 23:28:27.960036:  
2025-01-11 23:28:27.960036: Epoch 18 
2025-01-11 23:28:27.965080: Current learning rate: 0.00935 
2025-01-11 23:29:08.825373: train_loss -0.4082 
2025-01-11 23:29:08.825373: val_loss -0.4056 
2025-01-11 23:29:08.831887: Pseudo dice [np.float32(0.4587)] 
2025-01-11 23:29:08.834393: Epoch time: 40.87 s 
2025-01-11 23:29:08.837903: Yayy! New best EMA pseudo Dice: 0.3562000095844269 
2025-01-11 23:29:09.616083:  
2025-01-11 23:29:09.617086: Epoch 19 
2025-01-11 23:29:09.622718: Current learning rate: 0.00931 
2025-01-11 23:29:50.302314: train_loss -0.4404 
2025-01-11 23:29:50.302819: val_loss -0.2868 
2025-01-11 23:29:50.308857: Pseudo dice [np.float32(0.3011)] 
2025-01-11 23:29:50.312385: Epoch time: 40.69 s 
2025-01-11 23:29:50.889512:  
2025-01-11 23:29:50.890020: Epoch 20 
2025-01-11 23:29:50.895061: Current learning rate: 0.00928 
2025-01-11 23:30:32.025759: train_loss -0.4042 
2025-01-11 23:30:32.025759: val_loss -0.4162 
2025-01-11 23:30:32.032275: Pseudo dice [np.float32(0.5041)] 
2025-01-11 23:30:32.037286: Epoch time: 41.14 s 
2025-01-11 23:30:32.040796: Yayy! New best EMA pseudo Dice: 0.366100013256073 
2025-01-11 23:30:33.020998:  
2025-01-11 23:30:33.020998: Epoch 21 
2025-01-11 23:30:33.025970: Current learning rate: 0.00924 
2025-01-11 23:31:13.256474: train_loss -0.3331 
2025-01-11 23:31:13.257976: val_loss -0.2821 
2025-01-11 23:31:13.264144: Pseudo dice [np.float32(0.4084)] 
2025-01-11 23:31:13.266649: Epoch time: 40.24 s 
2025-01-11 23:31:13.270155: Yayy! New best EMA pseudo Dice: 0.3702999949455261 
2025-01-11 23:31:14.065703:  
2025-01-11 23:31:14.065703: Epoch 22 
2025-01-11 23:31:14.069728: Current learning rate: 0.0092 
2025-01-11 23:31:54.779183: train_loss -0.3569 
2025-01-11 23:31:54.780197: val_loss -0.4248 
2025-01-11 23:31:54.785239: Pseudo dice [np.float32(0.4879)] 
2025-01-11 23:31:54.789266: Epoch time: 40.71 s 
2025-01-11 23:31:54.792290: Yayy! New best EMA pseudo Dice: 0.382099986076355 
2025-01-11 23:31:55.549155:  
2025-01-11 23:31:55.550161: Epoch 23 
2025-01-11 23:31:55.554719: Current learning rate: 0.00917 
2025-01-11 23:32:36.257458: train_loss -0.4247 
2025-01-11 23:32:36.257971: val_loss -0.3763 
2025-01-11 23:32:36.264537: Pseudo dice [np.float32(0.3983)] 
2025-01-11 23:32:36.267579: Epoch time: 40.71 s 
2025-01-11 23:32:36.270621: Yayy! New best EMA pseudo Dice: 0.38370001316070557 
2025-01-11 23:32:37.067258:  
2025-01-11 23:32:37.068261: Epoch 24 
2025-01-11 23:32:37.073792: Current learning rate: 0.00913 
2025-01-11 23:33:17.480556: train_loss -0.4444 
2025-01-11 23:33:17.481064: val_loss -0.4072 
2025-01-11 23:33:17.487598: Pseudo dice [np.float32(0.4754)] 
2025-01-11 23:33:17.490615: Epoch time: 40.41 s 
2025-01-11 23:33:17.493636: Yayy! New best EMA pseudo Dice: 0.3928999900817871 
2025-01-11 23:33:18.318271:  
2025-01-11 23:33:18.319274: Epoch 25 
2025-01-11 23:33:18.324808: Current learning rate: 0.0091 
2025-01-11 23:33:59.696120: train_loss -0.4314 
2025-01-11 23:33:59.697123: val_loss -0.2801 
2025-01-11 23:33:59.703133: Pseudo dice [np.float32(0.364)] 
2025-01-11 23:33:59.706652: Epoch time: 41.38 s 
2025-01-11 23:34:00.266474:  
2025-01-11 23:34:00.266474: Epoch 26 
2025-01-11 23:34:00.271490: Current learning rate: 0.00906 
2025-01-11 23:34:41.449190: train_loss -0.399 
2025-01-11 23:34:41.450191: val_loss -0.329 
2025-01-11 23:34:41.455708: Pseudo dice [np.float32(0.4031)] 
2025-01-11 23:34:41.459218: Epoch time: 41.18 s 
2025-01-11 23:34:42.026186:  
2025-01-11 23:34:42.026186: Epoch 27 
2025-01-11 23:34:42.032199: Current learning rate: 0.00902 
2025-01-11 23:35:23.077999: train_loss -0.4471 
2025-01-11 23:35:23.078505: val_loss -0.3683 
2025-01-11 23:35:23.083555: Pseudo dice [np.float32(0.4089)] 
2025-01-11 23:35:23.086582: Epoch time: 41.05 s 
2025-01-11 23:35:23.090100: Yayy! New best EMA pseudo Dice: 0.3930000066757202 
2025-01-11 23:35:23.902367:  
2025-01-11 23:35:23.902367: Epoch 28 
2025-01-11 23:35:23.908479: Current learning rate: 0.00899 
2025-01-11 23:36:04.511886: train_loss -0.4845 
2025-01-11 23:36:04.512907: val_loss -0.431 
2025-01-11 23:36:04.518496: Pseudo dice [np.float32(0.4643)] 
2025-01-11 23:36:04.521528: Epoch time: 40.61 s 
2025-01-11 23:36:04.524047: Yayy! New best EMA pseudo Dice: 0.4002000093460083 
2025-01-11 23:36:05.306686:  
2025-01-11 23:36:05.306686: Epoch 29 
2025-01-11 23:36:05.311732: Current learning rate: 0.00895 
2025-01-11 23:36:45.759969: train_loss -0.4599 
2025-01-11 23:36:45.760472: val_loss -0.362 
2025-01-11 23:36:45.765030: Pseudo dice [np.float32(0.4198)] 
2025-01-11 23:36:45.768535: Epoch time: 40.45 s 
2025-01-11 23:36:45.771543: Yayy! New best EMA pseudo Dice: 0.40209999680519104 
2025-01-11 23:36:46.549888:  
2025-01-11 23:36:46.549888: Epoch 30 
2025-01-11 23:36:46.556022: Current learning rate: 0.00891 
2025-01-11 23:37:26.841287: train_loss -0.4423 
2025-01-11 23:37:26.842793: val_loss -0.3143 
2025-01-11 23:37:26.848326: Pseudo dice [np.float32(0.298)] 
2025-01-11 23:37:26.851837: Epoch time: 40.29 s 
2025-01-11 23:37:27.423475:  
2025-01-11 23:37:27.423475: Epoch 31 
2025-01-11 23:37:27.428486: Current learning rate: 0.00888 
2025-01-11 23:38:08.027133: train_loss -0.502 
2025-01-11 23:38:08.027640: val_loss -0.3702 
2025-01-11 23:38:08.032736: Pseudo dice [np.float32(0.4143)] 
2025-01-11 23:38:08.036796: Epoch time: 40.6 s 
2025-01-11 23:38:08.622168:  
2025-01-11 23:38:08.622168: Epoch 32 
2025-01-11 23:38:08.628268: Current learning rate: 0.00884 
2025-01-11 23:38:48.851631: train_loss -0.4385 
2025-01-11 23:38:48.851631: val_loss -0.3911 
2025-01-11 23:38:48.858769: Pseudo dice [np.float32(0.4116)] 
2025-01-11 23:38:48.861275: Epoch time: 40.23 s 
2025-01-11 23:38:49.512570:  
2025-01-11 23:38:49.512570: Epoch 33 
2025-01-11 23:38:49.518125: Current learning rate: 0.0088 
2025-01-11 23:39:29.741999: train_loss -0.4858 
2025-01-11 23:39:29.743502: val_loss -0.4538 
2025-01-11 23:39:29.748515: Pseudo dice [np.float32(0.5229)] 
2025-01-11 23:39:29.752027: Epoch time: 40.23 s 
2025-01-11 23:39:29.754531: Yayy! New best EMA pseudo Dice: 0.40849998593330383 
2025-01-11 23:39:30.575951:  
2025-01-11 23:39:30.575951: Epoch 34 
2025-01-11 23:39:30.581502: Current learning rate: 0.00877 
2025-01-11 23:40:10.811833: train_loss -0.4744 
2025-01-11 23:40:10.812836: val_loss -0.4564 
2025-01-11 23:40:10.818482: Pseudo dice [np.float32(0.4921)] 
2025-01-11 23:40:10.821515: Epoch time: 40.24 s 
2025-01-11 23:40:10.824543: Yayy! New best EMA pseudo Dice: 0.41679999232292175 
2025-01-11 23:40:11.600480:  
2025-01-11 23:40:11.600480: Epoch 35 
2025-01-11 23:40:11.606017: Current learning rate: 0.00873 
2025-01-11 23:40:51.844565: train_loss -0.4959 
2025-01-11 23:40:51.845570: val_loss -0.5156 
2025-01-11 23:40:51.850581: Pseudo dice [np.float32(0.5591)] 
2025-01-11 23:40:51.854589: Epoch time: 40.25 s 
2025-01-11 23:40:51.857094: Yayy! New best EMA pseudo Dice: 0.4309999942779541 
2025-01-11 23:40:52.780209:  
2025-01-11 23:40:52.781209: Epoch 36 
2025-01-11 23:40:52.786725: Current learning rate: 0.00869 
2025-01-11 23:41:33.000685: train_loss -0.4967 
2025-01-11 23:41:33.001689: val_loss -0.4323 
2025-01-11 23:41:33.006699: Pseudo dice [np.float32(0.5487)] 
2025-01-11 23:41:33.010710: Epoch time: 40.22 s 
2025-01-11 23:41:33.013216: Yayy! New best EMA pseudo Dice: 0.44279998540878296 
2025-01-11 23:41:33.787726:  
2025-01-11 23:41:33.788228: Epoch 37 
2025-01-11 23:41:33.793240: Current learning rate: 0.00866 
2025-01-11 23:42:14.020988: train_loss -0.4732 
2025-01-11 23:42:14.020988: val_loss -0.4096 
2025-01-11 23:42:14.027501: Pseudo dice [np.float32(0.4901)] 
2025-01-11 23:42:14.030007: Epoch time: 40.23 s 
2025-01-11 23:42:14.032513: Yayy! New best EMA pseudo Dice: 0.44749999046325684 
2025-01-11 23:42:14.813113:  
2025-01-11 23:42:14.813113: Epoch 38 
2025-01-11 23:42:14.818645: Current learning rate: 0.00862 
2025-01-11 23:42:55.059202: train_loss -0.4941 
2025-01-11 23:42:55.059202: val_loss -0.3013 
2025-01-11 23:42:55.065227: Pseudo dice [np.float32(0.2718)] 
2025-01-11 23:42:55.068734: Epoch time: 40.25 s 
2025-01-11 23:42:55.654195:  
2025-01-11 23:42:55.655700: Epoch 39 
2025-01-11 23:42:55.659249: Current learning rate: 0.00858 
2025-01-11 23:43:35.920771: train_loss -0.465 
2025-01-11 23:43:35.920771: val_loss -0.4138 
2025-01-11 23:43:35.926276: Pseudo dice [np.float32(0.4424)] 
2025-01-11 23:43:35.929792: Epoch time: 40.27 s 
2025-01-11 23:43:36.539247:  
2025-01-11 23:43:36.539247: Epoch 40 
2025-01-11 23:43:36.544258: Current learning rate: 0.00855 
2025-01-11 23:44:16.892171: train_loss -0.4552 
2025-01-11 23:44:16.893168: val_loss -0.4237 
2025-01-11 23:44:16.899690: Pseudo dice [np.float32(0.4804)] 
2025-01-11 23:44:16.903198: Epoch time: 40.35 s 
2025-01-11 23:44:17.596427:  
2025-01-11 23:44:17.596427: Epoch 41 
2025-01-11 23:44:17.601439: Current learning rate: 0.00851 
2025-01-11 23:44:57.828733: train_loss -0.4959 
2025-01-11 23:44:57.829247: val_loss -0.467 
2025-01-11 23:44:57.836322: Pseudo dice [np.float32(0.5259)] 
2025-01-11 23:44:57.838827: Epoch time: 40.23 s 
2025-01-11 23:44:58.425676:  
2025-01-11 23:44:58.425676: Epoch 42 
2025-01-11 23:44:58.431776: Current learning rate: 0.00847 
2025-01-11 23:45:38.684193: train_loss -0.4994 
2025-01-11 23:45:38.684193: val_loss -0.4206 
2025-01-11 23:45:38.690207: Pseudo dice [np.float32(0.5439)] 
2025-01-11 23:45:38.692715: Epoch time: 40.26 s 
2025-01-11 23:45:38.696223: Yayy! New best EMA pseudo Dice: 0.45500001311302185 
2025-01-11 23:45:39.496632:  
2025-01-11 23:45:39.496632: Epoch 43 
2025-01-11 23:45:39.502304: Current learning rate: 0.00844 
2025-01-11 23:46:19.678391: train_loss -0.4534 
2025-01-11 23:46:19.678391: val_loss -0.4541 
2025-01-11 23:46:19.684414: Pseudo dice [np.float32(0.5093)] 
2025-01-11 23:46:19.688430: Epoch time: 40.18 s 
2025-01-11 23:46:19.691442: Yayy! New best EMA pseudo Dice: 0.4603999853134155 
2025-01-11 23:46:20.656228:  
2025-01-11 23:46:20.656228: Epoch 44 
2025-01-11 23:46:20.661835: Current learning rate: 0.0084 
2025-01-11 23:47:00.856583: train_loss -0.4907 
2025-01-11 23:47:00.856583: val_loss -0.4647 
2025-01-11 23:47:00.864351: Pseudo dice [np.float32(0.5105)] 
2025-01-11 23:47:00.869894: Epoch time: 40.2 s 
2025-01-11 23:47:00.872400: Yayy! New best EMA pseudo Dice: 0.46540001034736633 
2025-01-11 23:47:01.676268:  
2025-01-11 23:47:01.677271: Epoch 45 
2025-01-11 23:47:01.682305: Current learning rate: 0.00836 
2025-01-11 23:47:41.890771: train_loss -0.5122 
2025-01-11 23:47:41.891775: val_loss -0.4054 
2025-01-11 23:47:41.896880: Pseudo dice [np.float32(0.4511)] 
2025-01-11 23:47:41.900415: Epoch time: 40.21 s 
2025-01-11 23:47:42.452207:  
2025-01-11 23:47:42.452207: Epoch 46 
2025-01-11 23:47:42.455719: Current learning rate: 0.00833 
2025-01-11 23:48:22.664666: train_loss -0.4991 
2025-01-11 23:48:22.665693: val_loss -0.4885 
2025-01-11 23:48:22.670282: Pseudo dice [np.float32(0.5677)] 
2025-01-11 23:48:22.673815: Epoch time: 40.21 s 
2025-01-11 23:48:22.676850: Yayy! New best EMA pseudo Dice: 0.47440001368522644 
2025-01-11 23:48:23.432787:  
2025-01-11 23:48:23.434291: Epoch 47 
2025-01-11 23:48:23.439303: Current learning rate: 0.00829 
2025-01-11 23:49:03.659536: train_loss -0.5234 
2025-01-11 23:49:03.660550: val_loss -0.4022 
2025-01-11 23:49:03.667660: Pseudo dice [np.float32(0.4591)] 
2025-01-11 23:49:03.672197: Epoch time: 40.23 s 
2025-01-11 23:49:04.232610:  
2025-01-11 23:49:04.232610: Epoch 48 
2025-01-11 23:49:04.237623: Current learning rate: 0.00825 
2025-01-11 23:49:44.271856: train_loss -0.52 
2025-01-11 23:49:44.272861: val_loss -0.4148 
2025-01-11 23:49:44.279033: Pseudo dice [np.float32(0.5229)] 
2025-01-11 23:49:44.283077: Epoch time: 40.04 s 
2025-01-11 23:49:44.286130: Yayy! New best EMA pseudo Dice: 0.47780001163482666 
2025-01-11 23:49:45.104330:  
2025-01-11 23:49:45.104832: Epoch 49 
2025-01-11 23:49:45.109843: Current learning rate: 0.00822 
2025-01-11 23:50:25.133017: train_loss -0.5265 
2025-01-11 23:50:25.135037: val_loss -0.3788 
2025-01-11 23:50:25.140050: Pseudo dice [np.float32(0.451)] 
2025-01-11 23:50:25.143559: Epoch time: 40.03 s 
2025-01-11 23:50:25.894023:  
2025-01-11 23:50:25.895027: Epoch 50 
2025-01-11 23:50:25.899605: Current learning rate: 0.00818 
2025-01-11 23:51:05.938440: train_loss -0.4942 
2025-01-11 23:51:05.939444: val_loss -0.4768 
2025-01-11 23:51:05.945160: Pseudo dice [np.float32(0.526)] 
2025-01-11 23:51:05.948217: Epoch time: 40.04 s 
2025-01-11 23:51:05.950236: Yayy! New best EMA pseudo Dice: 0.48019999265670776 
2025-01-11 23:51:06.711048:  
2025-01-11 23:51:06.711048: Epoch 51 
2025-01-11 23:51:06.716584: Current learning rate: 0.00814 
2025-01-11 23:51:46.746155: train_loss -0.5434 
2025-01-11 23:51:46.746661: val_loss -0.4419 
2025-01-11 23:51:46.752702: Pseudo dice [np.float32(0.4733)] 
2025-01-11 23:51:46.755730: Epoch time: 40.04 s 
2025-01-11 23:51:47.490622:  
2025-01-11 23:51:47.490622: Epoch 52 
2025-01-11 23:51:47.496218: Current learning rate: 0.00811 
2025-01-11 23:52:31.958826: train_loss -0.5427 
2025-01-11 23:52:31.958826: val_loss -0.4231 
2025-01-11 23:52:31.964842: Pseudo dice [np.float32(0.5188)] 
2025-01-11 23:52:31.968389: Epoch time: 44.47 s 
2025-01-11 23:52:31.971574: Yayy! New best EMA pseudo Dice: 0.48350000381469727 
2025-01-11 23:52:32.790722:  
2025-01-11 23:52:32.791722: Epoch 53 
2025-01-11 23:52:32.796849: Current learning rate: 0.00807 
2025-01-11 23:53:13.016526: train_loss -0.5468 
2025-01-11 23:53:13.017525: val_loss -0.4633 
2025-01-11 23:53:13.025053: Pseudo dice [np.float32(0.5146)] 
2025-01-11 23:53:13.029072: Epoch time: 40.23 s 
2025-01-11 23:53:13.032593: Yayy! New best EMA pseudo Dice: 0.48660001158714294 
2025-01-11 23:53:13.850701:  
2025-01-11 23:53:13.850701: Epoch 54 
2025-01-11 23:53:13.854217: Current learning rate: 0.00803 
2025-01-11 23:53:54.080750: train_loss -0.514 
2025-01-11 23:53:54.080750: val_loss -0.4636 
2025-01-11 23:53:54.087291: Pseudo dice [np.float32(0.5042)] 
2025-01-11 23:53:54.089810: Epoch time: 40.23 s 
2025-01-11 23:53:54.093347: Yayy! New best EMA pseudo Dice: 0.48829999566078186 
2025-01-11 23:53:54.904454:  
2025-01-11 23:53:54.904454: Epoch 55 
2025-01-11 23:53:54.910002: Current learning rate: 0.008 
2025-01-11 23:54:35.137859: train_loss -0.5496 
2025-01-11 23:54:35.138858: val_loss -0.3955 
2025-01-11 23:54:35.144383: Pseudo dice [np.float32(0.4783)] 
2025-01-11 23:54:35.147902: Epoch time: 40.23 s 
2025-01-11 23:54:35.721666:  
2025-01-11 23:54:35.722170: Epoch 56 
2025-01-11 23:54:35.727195: Current learning rate: 0.00796 
2025-01-11 23:55:15.961943: train_loss -0.4855 
2025-01-11 23:55:15.961943: val_loss -0.4636 
2025-01-11 23:55:15.969473: Pseudo dice [np.float32(0.545)] 
2025-01-11 23:55:15.973488: Epoch time: 40.24 s 
2025-01-11 23:55:15.977005: Yayy! New best EMA pseudo Dice: 0.49309998750686646 
2025-01-11 23:55:16.794659:  
2025-01-11 23:55:16.794659: Epoch 57 
2025-01-11 23:55:16.801065: Current learning rate: 0.00792 
2025-01-11 23:55:57.009463: train_loss -0.5012 
2025-01-11 23:55:57.010463: val_loss -0.3996 
2025-01-11 23:55:57.015980: Pseudo dice [np.float32(0.4483)] 
2025-01-11 23:55:57.019489: Epoch time: 40.22 s 
2025-01-11 23:55:57.578145:  
2025-01-11 23:55:57.578145: Epoch 58 
2025-01-11 23:55:57.583710: Current learning rate: 0.00789 
2025-01-11 23:56:37.787419: train_loss -0.5101 
2025-01-11 23:56:37.788423: val_loss -0.3583 
2025-01-11 23:56:37.793938: Pseudo dice [np.float32(0.4263)] 
2025-01-11 23:56:37.796964: Epoch time: 40.21 s 
2025-01-11 23:56:38.364695:  
2025-01-11 23:56:38.364695: Epoch 59 
2025-01-11 23:56:38.370798: Current learning rate: 0.00785 
2025-01-11 23:57:18.582630: train_loss -0.5127 
2025-01-11 23:57:18.582630: val_loss -0.384 
2025-01-11 23:57:18.590200: Pseudo dice [np.float32(0.4056)] 
2025-01-11 23:57:18.594735: Epoch time: 40.22 s 
2025-01-11 23:57:19.167255:  
2025-01-11 23:57:19.168260: Epoch 60 
2025-01-11 23:57:19.172820: Current learning rate: 0.00781 
2025-01-11 23:57:59.436893: train_loss -0.504 
2025-01-11 23:57:59.437897: val_loss -0.4227 
2025-01-11 23:57:59.443468: Pseudo dice [np.float32(0.4554)] 
2025-01-11 23:57:59.446512: Epoch time: 40.27 s 
2025-01-11 23:58:00.021482:  
2025-01-11 23:58:00.021482: Epoch 61 
2025-01-11 23:58:00.027052: Current learning rate: 0.00777 
2025-01-11 23:58:40.222515: train_loss -0.4999 
2025-01-11 23:58:40.223017: val_loss -0.4991 
2025-01-11 23:58:40.228555: Pseudo dice [np.float32(0.5578)] 
2025-01-11 23:58:40.232074: Epoch time: 40.2 s 
2025-01-11 23:58:40.795466:  
2025-01-11 23:58:40.795466: Epoch 62 
2025-01-11 23:58:40.801029: Current learning rate: 0.00774 
2025-01-11 23:59:20.983828: train_loss -0.5464 
2025-01-11 23:59:20.984831: val_loss -0.4393 
2025-01-11 23:59:20.992383: Pseudo dice [np.float32(0.5166)] 
2025-01-11 23:59:20.996391: Epoch time: 40.19 s 
2025-01-11 23:59:21.566546:  
2025-01-11 23:59:21.566546: Epoch 63 
2025-01-11 23:59:21.571556: Current learning rate: 0.0077 
2025-01-12 00:00:01.901251: train_loss -0.5113 
2025-01-12 00:00:01.902251: val_loss -0.4912 
2025-01-12 00:00:01.905259: Pseudo dice [np.float32(0.5395)] 
2025-01-12 00:00:01.908769: Epoch time: 40.34 s 
2025-01-12 00:00:02.479932:  
2025-01-12 00:00:02.479932: Epoch 64 
2025-01-12 00:00:02.484944: Current learning rate: 0.00766 
2025-01-12 00:00:42.695561: train_loss -0.552 
2025-01-12 00:00:42.696074: val_loss -0.4194 
2025-01-12 00:00:42.701130: Pseudo dice [np.float32(0.4952)] 
2025-01-12 00:00:42.703706: Epoch time: 40.22 s 
2025-01-12 00:00:43.274899:  
2025-01-12 00:00:43.274899: Epoch 65 
2025-01-12 00:00:43.280432: Current learning rate: 0.00763 
2025-01-12 00:01:23.477801: train_loss -0.5166 
2025-01-12 00:01:23.477801: val_loss -0.3776 
2025-01-12 00:01:23.481817: Pseudo dice [np.float32(0.4452)] 
2025-01-12 00:01:23.485329: Epoch time: 40.2 s 
2025-01-12 00:01:24.060328:  
2025-01-12 00:01:24.060328: Epoch 66 
2025-01-12 00:01:24.065339: Current learning rate: 0.00759 
2025-01-12 00:02:04.257445: train_loss -0.5132 
2025-01-12 00:02:04.257986: val_loss -0.431 
2025-01-12 00:02:04.263586: Pseudo dice [np.float32(0.5072)] 
2025-01-12 00:02:04.266117: Epoch time: 40.2 s 
2025-01-12 00:02:04.840808:  
2025-01-12 00:02:04.840808: Epoch 67 
2025-01-12 00:02:04.845816: Current learning rate: 0.00755 
2025-01-12 00:02:45.063467: train_loss -0.5322 
2025-01-12 00:02:45.064471: val_loss -0.4188 
2025-01-12 00:02:45.070481: Pseudo dice [np.float32(0.4821)] 
2025-01-12 00:02:45.073524: Epoch time: 40.22 s 
2025-01-12 00:02:45.802911:  
2025-01-12 00:02:45.802911: Epoch 68 
2025-01-12 00:02:45.808978: Current learning rate: 0.00751 
2025-01-12 00:03:26.084147: train_loss -0.5272 
2025-01-12 00:03:26.084651: val_loss -0.3868 
2025-01-12 00:03:26.089664: Pseudo dice [np.float32(0.4844)] 
2025-01-12 00:03:26.093173: Epoch time: 40.28 s 
2025-01-12 00:03:26.682695:  
2025-01-12 00:03:26.683696: Epoch 69 
2025-01-12 00:03:26.688758: Current learning rate: 0.00748 
2025-01-12 00:04:06.917653: train_loss -0.4947 
2025-01-12 00:04:06.917653: val_loss -0.5088 
2025-01-12 00:04:06.923667: Pseudo dice [np.float32(0.5977)] 
2025-01-12 00:04:06.926676: Epoch time: 40.24 s 
2025-01-12 00:04:06.929183: Yayy! New best EMA pseudo Dice: 0.4984000027179718 
2025-01-12 00:04:07.766425:  
2025-01-12 00:04:07.766425: Epoch 70 
2025-01-12 00:04:07.771970: Current learning rate: 0.00744 
2025-01-12 00:04:47.962711: train_loss -0.5226 
2025-01-12 00:04:47.963225: val_loss -0.4905 
2025-01-12 00:04:47.968370: Pseudo dice [np.float32(0.561)] 
2025-01-12 00:04:47.971926: Epoch time: 40.2 s 
2025-01-12 00:04:47.974650: Yayy! New best EMA pseudo Dice: 0.5047000050544739 
2025-01-12 00:04:48.812890:  
2025-01-12 00:04:48.813393: Epoch 71 
2025-01-12 00:04:48.818408: Current learning rate: 0.0074 
2025-01-12 00:05:28.846091: train_loss -0.5375 
2025-01-12 00:05:28.846091: val_loss -0.4677 
2025-01-12 00:05:28.852608: Pseudo dice [np.float32(0.5329)] 
2025-01-12 00:05:28.856117: Epoch time: 40.03 s 
2025-01-12 00:05:28.858626: Yayy! New best EMA pseudo Dice: 0.5074999928474426 
2025-01-12 00:05:29.688916:  
2025-01-12 00:05:29.688916: Epoch 72 
2025-01-12 00:05:29.694953: Current learning rate: 0.00737 
2025-01-12 00:06:09.714819: train_loss -0.5302 
2025-01-12 00:06:09.715325: val_loss -0.4502 
2025-01-12 00:06:09.720898: Pseudo dice [np.float32(0.5198)] 
2025-01-12 00:06:09.723938: Epoch time: 40.03 s 
2025-01-12 00:06:09.726472: Yayy! New best EMA pseudo Dice: 0.5087000131607056 
2025-01-12 00:06:10.553859:  
2025-01-12 00:06:10.553859: Epoch 73 
2025-01-12 00:06:10.558891: Current learning rate: 0.00733 
2025-01-12 00:06:50.596575: train_loss -0.5324 
2025-01-12 00:06:50.598079: val_loss -0.4693 
2025-01-12 00:06:50.603096: Pseudo dice [np.float32(0.5403)] 
2025-01-12 00:06:50.606611: Epoch time: 40.04 s 
2025-01-12 00:06:50.609619: Yayy! New best EMA pseudo Dice: 0.511900007724762 
2025-01-12 00:06:51.443510:  
2025-01-12 00:06:51.443510: Epoch 74 
2025-01-12 00:06:51.449550: Current learning rate: 0.00729 
2025-01-12 00:07:31.480954: train_loss -0.5441 
2025-01-12 00:07:31.482456: val_loss -0.4577 
2025-01-12 00:07:31.488472: Pseudo dice [np.float32(0.5381)] 
2025-01-12 00:07:31.491978: Epoch time: 40.04 s 
2025-01-12 00:07:31.494989: Yayy! New best EMA pseudo Dice: 0.5145000219345093 
2025-01-12 00:07:32.265945:  
2025-01-12 00:07:32.265945: Epoch 75 
2025-01-12 00:07:32.271511: Current learning rate: 0.00725 
2025-01-12 00:08:12.295921: train_loss -0.4988 
2025-01-12 00:08:12.297423: val_loss -0.4762 
2025-01-12 00:08:12.302435: Pseudo dice [np.float32(0.5513)] 
2025-01-12 00:08:12.305946: Epoch time: 40.03 s 
2025-01-12 00:08:12.309455: Yayy! New best EMA pseudo Dice: 0.5181999802589417 
2025-01-12 00:08:13.311595:  
2025-01-12 00:08:13.312598: Epoch 76 
2025-01-12 00:08:13.317202: Current learning rate: 0.00722 
2025-01-12 00:08:53.334761: train_loss -0.5288 
2025-01-12 00:08:53.335764: val_loss -0.4695 
2025-01-12 00:08:53.342287: Pseudo dice [np.float32(0.545)] 
2025-01-12 00:08:53.344796: Epoch time: 40.02 s 
2025-01-12 00:08:53.348307: Yayy! New best EMA pseudo Dice: 0.5209000110626221 
2025-01-12 00:08:54.175859:  
2025-01-12 00:08:54.175859: Epoch 77 
2025-01-12 00:08:54.180871: Current learning rate: 0.00718 
2025-01-12 00:09:34.190345: train_loss -0.5434 
2025-01-12 00:09:34.190863: val_loss -0.5022 
2025-01-12 00:09:34.196932: Pseudo dice [np.float32(0.5699)] 
2025-01-12 00:09:34.199972: Epoch time: 40.02 s 
2025-01-12 00:09:34.203011: Yayy! New best EMA pseudo Dice: 0.5257999897003174 
2025-01-12 00:09:35.031557:  
2025-01-12 00:09:35.031557: Epoch 78 
2025-01-12 00:09:35.037149: Current learning rate: 0.00714 
2025-01-12 00:10:15.073323: train_loss -0.5356 
2025-01-12 00:10:15.073834: val_loss -0.4819 
2025-01-12 00:10:15.079430: Pseudo dice [np.float32(0.5379)] 
2025-01-12 00:10:15.082462: Epoch time: 40.04 s 
2025-01-12 00:10:15.084984: Yayy! New best EMA pseudo Dice: 0.5270000100135803 
2025-01-12 00:10:15.920128:  
2025-01-12 00:10:15.920128: Epoch 79 
2025-01-12 00:10:15.926195: Current learning rate: 0.0071 
2025-01-12 00:10:55.941929: train_loss -0.5745 
2025-01-12 00:10:55.942432: val_loss -0.501 
2025-01-12 00:10:55.947451: Pseudo dice [np.float32(0.5796)] 
2025-01-12 00:10:55.950968: Epoch time: 40.02 s 
2025-01-12 00:10:55.953482: Yayy! New best EMA pseudo Dice: 0.5321999788284302 
2025-01-12 00:10:56.793036:  
2025-01-12 00:10:56.793539: Epoch 80 
2025-01-12 00:10:56.798549: Current learning rate: 0.00707 
2025-01-12 00:11:36.795909: train_loss -0.5275 
2025-01-12 00:11:36.796917: val_loss -0.4245 
2025-01-12 00:11:36.801947: Pseudo dice [np.float32(0.4748)] 
2025-01-12 00:11:36.806509: Epoch time: 40.0 s 
2025-01-12 00:11:37.400387:  
2025-01-12 00:11:37.400387: Epoch 81 
2025-01-12 00:11:37.405399: Current learning rate: 0.00703 
2025-01-12 00:12:17.420171: train_loss -0.5389 
2025-01-12 00:12:17.420685: val_loss -0.4739 
2025-01-12 00:12:17.426250: Pseudo dice [np.float32(0.5772)] 
2025-01-12 00:12:17.428775: Epoch time: 40.02 s 
2025-01-12 00:12:18.020045:  
2025-01-12 00:12:18.021048: Epoch 82 
2025-01-12 00:12:18.026111: Current learning rate: 0.00699 
2025-01-12 00:12:58.032701: train_loss -0.5614 
2025-01-12 00:12:58.033213: val_loss -0.498 
2025-01-12 00:12:58.040886: Pseudo dice [np.float32(0.575)] 
2025-01-12 00:12:58.043929: Epoch time: 40.01 s 
2025-01-12 00:12:58.046467: Yayy! New best EMA pseudo Dice: 0.5358999967575073 
2025-01-12 00:12:59.005779:  
2025-01-12 00:12:59.006281: Epoch 83 
2025-01-12 00:12:59.011338: Current learning rate: 0.00696 
2025-01-12 00:13:39.040023: train_loss -0.5664 
2025-01-12 00:13:39.040023: val_loss -0.5644 
2025-01-12 00:13:39.046073: Pseudo dice [np.float32(0.6456)] 
2025-01-12 00:13:39.049082: Epoch time: 40.03 s 
2025-01-12 00:13:39.051620: Yayy! New best EMA pseudo Dice: 0.5468999743461609 
2025-01-12 00:13:39.845123:  
2025-01-12 00:13:39.845123: Epoch 84 
2025-01-12 00:13:39.850655: Current learning rate: 0.00692 
2025-01-12 00:14:19.877429: train_loss -0.5472 
2025-01-12 00:14:19.877932: val_loss -0.4576 
2025-01-12 00:14:19.882975: Pseudo dice [np.float32(0.5031)] 
2025-01-12 00:14:19.886485: Epoch time: 40.03 s 
2025-01-12 00:14:20.438357:  
2025-01-12 00:14:20.439357: Epoch 85 
2025-01-12 00:14:20.446383: Current learning rate: 0.00688 
2025-01-12 00:15:00.468332: train_loss -0.572 
2025-01-12 00:15:00.468835: val_loss -0.4445 
2025-01-12 00:15:00.473846: Pseudo dice [np.float32(0.4767)] 
2025-01-12 00:15:00.477355: Epoch time: 40.03 s 
2025-01-12 00:15:01.035359:  
2025-01-12 00:15:01.036362: Epoch 86 
2025-01-12 00:15:01.041897: Current learning rate: 0.00684 
2025-01-12 00:15:41.059697: train_loss -0.5575 
2025-01-12 00:15:41.059697: val_loss -0.3939 
2025-01-12 00:15:41.065711: Pseudo dice [np.float32(0.5408)] 
2025-01-12 00:15:41.069217: Epoch time: 40.02 s 
2025-01-12 00:15:41.622944:  
2025-01-12 00:15:41.623948: Epoch 87 
2025-01-12 00:15:41.628513: Current learning rate: 0.0068 
2025-01-12 00:16:21.610516: train_loss -0.5698 
2025-01-12 00:16:21.611028: val_loss -0.4946 
2025-01-12 00:16:21.616588: Pseudo dice [np.float32(0.5748)] 
2025-01-12 00:16:21.620617: Epoch time: 39.99 s 
2025-01-12 00:16:22.180165:  
2025-01-12 00:16:22.180165: Epoch 88 
2025-01-12 00:16:22.185704: Current learning rate: 0.00677 
2025-01-12 00:17:02.214491: train_loss -0.5416 
2025-01-12 00:17:02.215002: val_loss -0.4826 
2025-01-12 00:17:02.220619: Pseudo dice [np.float32(0.5436)] 
2025-01-12 00:17:02.224148: Epoch time: 40.04 s 
2025-01-12 00:17:02.780766:  
2025-01-12 00:17:02.780766: Epoch 89 
2025-01-12 00:17:02.786280: Current learning rate: 0.00673 
2025-01-12 00:17:42.797444: train_loss -0.5616 
2025-01-12 00:17:42.797947: val_loss -0.4233 
2025-01-12 00:17:42.803481: Pseudo dice [np.float32(0.5013)] 
2025-01-12 00:17:42.806991: Epoch time: 40.02 s 
2025-01-12 00:17:43.373769:  
2025-01-12 00:17:43.374772: Epoch 90 
2025-01-12 00:17:43.379852: Current learning rate: 0.00669 
2025-01-12 00:18:23.397585: train_loss -0.5493 
2025-01-12 00:18:23.397585: val_loss -0.4521 
2025-01-12 00:18:23.404121: Pseudo dice [np.float32(0.4991)] 
2025-01-12 00:18:23.407186: Epoch time: 40.02 s 
2025-01-12 00:18:24.124410:  
2025-01-12 00:18:24.124410: Epoch 91 
2025-01-12 00:18:24.129441: Current learning rate: 0.00665 
2025-01-12 00:19:04.126907: train_loss -0.5699 
2025-01-12 00:19:04.127907: val_loss -0.4886 
2025-01-12 00:19:04.133420: Pseudo dice [np.float32(0.577)] 
2025-01-12 00:19:04.135926: Epoch time: 40.0 s 
2025-01-12 00:19:04.699298:  
2025-01-12 00:19:04.699298: Epoch 92 
2025-01-12 00:19:04.704326: Current learning rate: 0.00662 
2025-01-12 00:19:44.703060: train_loss -0.5569 
2025-01-12 00:19:44.704059: val_loss -0.4464 
2025-01-12 00:19:44.709572: Pseudo dice [np.float32(0.575)] 
2025-01-12 00:19:44.713080: Epoch time: 40.0 s 
2025-01-12 00:19:45.275911:  
2025-01-12 00:19:45.275911: Epoch 93 
2025-01-12 00:19:45.281431: Current learning rate: 0.00658 
2025-01-12 00:20:25.281314: train_loss -0.5279 
2025-01-12 00:20:25.281816: val_loss -0.4583 
2025-01-12 00:20:25.287350: Pseudo dice [np.float32(0.5631)] 
2025-01-12 00:20:25.290869: Epoch time: 40.01 s 
2025-01-12 00:20:25.852340:  
2025-01-12 00:20:25.852340: Epoch 94 
2025-01-12 00:20:25.856849: Current learning rate: 0.00654 
2025-01-12 00:21:05.873121: train_loss -0.5834 
2025-01-12 00:21:05.873635: val_loss -0.4757 
2025-01-12 00:21:05.879726: Pseudo dice [np.float32(0.5632)] 
2025-01-12 00:21:05.883284: Epoch time: 40.02 s 
2025-01-12 00:21:06.440452:  
2025-01-12 00:21:06.441454: Epoch 95 
2025-01-12 00:21:06.445982: Current learning rate: 0.0065 
2025-01-12 00:21:46.444160: train_loss -0.5821 
2025-01-12 00:21:46.445164: val_loss -0.4592 
2025-01-12 00:21:46.450750: Pseudo dice [np.float32(0.5152)] 
2025-01-12 00:21:46.453788: Epoch time: 40.0 s 
2025-01-12 00:21:47.015529:  
2025-01-12 00:21:47.015529: Epoch 96 
2025-01-12 00:21:47.021094: Current learning rate: 0.00647 
2025-01-12 00:22:27.030750: train_loss -0.5615 
2025-01-12 00:22:27.030750: val_loss -0.5074 
2025-01-12 00:22:27.037263: Pseudo dice [np.float32(0.5914)] 
2025-01-12 00:22:27.040772: Epoch time: 40.02 s 
2025-01-12 00:22:27.044280: Yayy! New best EMA pseudo Dice: 0.5472000241279602 
2025-01-12 00:22:27.870330:  
2025-01-12 00:22:27.870330: Epoch 97 
2025-01-12 00:22:27.875341: Current learning rate: 0.00643 
2025-01-12 00:23:07.898626: train_loss -0.5926 
2025-01-12 00:23:07.899635: val_loss -0.4924 
2025-01-12 00:23:07.905200: Pseudo dice [np.float32(0.5803)] 
2025-01-12 00:23:07.909237: Epoch time: 40.03 s 
2025-01-12 00:23:07.911777: Yayy! New best EMA pseudo Dice: 0.5504999756813049 
2025-01-12 00:23:08.736640:  
2025-01-12 00:23:08.737643: Epoch 98 
2025-01-12 00:23:08.742683: Current learning rate: 0.00639 
2025-01-12 00:23:48.780819: train_loss -0.5714 
2025-01-12 00:23:48.781322: val_loss -0.4916 
2025-01-12 00:23:48.787336: Pseudo dice [np.float32(0.5204)] 
2025-01-12 00:23:48.791344: Epoch time: 40.04 s 
2025-01-12 00:23:49.521777:  
2025-01-12 00:23:49.522780: Epoch 99 
2025-01-12 00:23:49.527811: Current learning rate: 0.00635 
2025-01-12 00:24:29.541198: train_loss -0.547 
2025-01-12 00:24:29.542198: val_loss -0.4896 
2025-01-12 00:24:29.547782: Pseudo dice [np.float32(0.5616)] 
2025-01-12 00:24:29.551291: Epoch time: 40.02 s 
2025-01-12 00:24:30.335852:  
2025-01-12 00:24:30.335852: Epoch 100 
2025-01-12 00:24:30.340892: Current learning rate: 0.00631 
2025-01-12 00:25:10.337031: train_loss -0.5751 
2025-01-12 00:25:10.337534: val_loss -0.5122 
2025-01-12 00:25:10.343559: Pseudo dice [np.float32(0.6073)] 
2025-01-12 00:25:10.347071: Epoch time: 40.0 s 
2025-01-12 00:25:10.350083: Yayy! New best EMA pseudo Dice: 0.5547000169754028 
2025-01-12 00:25:11.174105:  
2025-01-12 00:25:11.175107: Epoch 101 
2025-01-12 00:25:11.180139: Current learning rate: 0.00628 
2025-01-12 00:25:51.180774: train_loss -0.6052 
2025-01-12 00:25:51.181778: val_loss -0.5398 
2025-01-12 00:25:51.187298: Pseudo dice [np.float32(0.6093)] 
2025-01-12 00:25:51.191316: Epoch time: 40.01 s 
2025-01-12 00:25:51.194346: Yayy! New best EMA pseudo Dice: 0.5601999759674072 
2025-01-12 00:25:51.985999:  
2025-01-12 00:25:51.985999: Epoch 102 
2025-01-12 00:25:51.991010: Current learning rate: 0.00624 
2025-01-12 00:26:31.975810: train_loss -0.5779 
2025-01-12 00:26:31.975810: val_loss -0.5189 
2025-01-12 00:26:31.982357: Pseudo dice [np.float32(0.5989)] 
2025-01-12 00:26:31.985895: Epoch time: 39.99 s 
2025-01-12 00:26:31.988415: Yayy! New best EMA pseudo Dice: 0.5641000270843506 
2025-01-12 00:26:32.756719:  
2025-01-12 00:26:32.757222: Epoch 103 
2025-01-12 00:26:32.762232: Current learning rate: 0.0062 
2025-01-12 00:27:12.776989: train_loss -0.5231 
2025-01-12 00:27:12.777492: val_loss -0.4772 
2025-01-12 00:27:12.783506: Pseudo dice [np.float32(0.5507)] 
2025-01-12 00:27:12.787029: Epoch time: 40.02 s 
2025-01-12 00:27:13.362104:  
2025-01-12 00:27:13.362607: Epoch 104 
2025-01-12 00:27:13.367617: Current learning rate: 0.00616 
2025-01-12 00:27:53.387343: train_loss -0.5848 
2025-01-12 00:27:53.388365: val_loss -0.4323 
2025-01-12 00:27:53.394431: Pseudo dice [np.float32(0.5485)] 
2025-01-12 00:27:53.397988: Epoch time: 40.03 s 
2025-01-12 00:27:53.974462:  
2025-01-12 00:27:53.974462: Epoch 105 
2025-01-12 00:27:53.980479: Current learning rate: 0.00612 
2025-01-12 00:28:34.004174: train_loss -0.5315 
2025-01-12 00:28:34.005177: val_loss -0.5026 
2025-01-12 00:28:34.011232: Pseudo dice [np.float32(0.5544)] 
2025-01-12 00:28:34.014259: Epoch time: 40.03 s 
2025-01-12 00:28:34.586143:  
2025-01-12 00:28:34.586646: Epoch 106 
2025-01-12 00:28:34.591684: Current learning rate: 0.00609 
2025-01-12 00:29:14.594428: train_loss -0.5791 
2025-01-12 00:29:14.595432: val_loss -0.428 
2025-01-12 00:29:14.601442: Pseudo dice [np.float32(0.5329)] 
2025-01-12 00:29:14.604449: Epoch time: 40.01 s 
2025-01-12 00:29:15.336187:  
2025-01-12 00:29:15.336691: Epoch 107 
2025-01-12 00:29:15.341735: Current learning rate: 0.00605 
2025-01-12 00:29:55.357135: train_loss -0.5871 
2025-01-12 00:29:55.357638: val_loss -0.543 
2025-01-12 00:29:55.363654: Pseudo dice [np.float32(0.6167)] 
2025-01-12 00:29:55.367160: Epoch time: 40.02 s 
2025-01-12 00:29:55.943401:  
2025-01-12 00:29:55.944402: Epoch 108 
2025-01-12 00:29:55.948954: Current learning rate: 0.00601 
2025-01-12 00:30:35.969332: train_loss -0.5802 
2025-01-12 00:30:35.969332: val_loss -0.3515 
2025-01-12 00:30:35.975845: Pseudo dice [np.float32(0.4258)] 
2025-01-12 00:30:35.979354: Epoch time: 40.03 s 
2025-01-12 00:30:36.560159:  
2025-01-12 00:30:36.561162: Epoch 109 
2025-01-12 00:30:36.566246: Current learning rate: 0.00597 
2025-01-12 00:31:16.561209: train_loss -0.5812 
2025-01-12 00:31:16.561711: val_loss -0.4518 
2025-01-12 00:31:16.567259: Pseudo dice [np.float32(0.5413)] 
2025-01-12 00:31:16.571282: Epoch time: 40.0 s 
2025-01-12 00:31:17.140639:  
2025-01-12 00:31:17.141142: Epoch 110 
2025-01-12 00:31:17.146180: Current learning rate: 0.00593 
2025-01-12 00:31:57.138250: train_loss -0.5861 
2025-01-12 00:31:57.139250: val_loss -0.4908 
2025-01-12 00:31:57.144806: Pseudo dice [np.float32(0.5205)] 
2025-01-12 00:31:57.147311: Epoch time: 40.0 s 
2025-01-12 00:31:57.735755:  
2025-01-12 00:31:57.735755: Epoch 111 
2025-01-12 00:31:57.741796: Current learning rate: 0.0059 
2025-01-12 00:32:37.765722: train_loss -0.5968 
2025-01-12 00:32:37.766725: val_loss -0.5248 
2025-01-12 00:32:37.772780: Pseudo dice [np.float32(0.635)] 
2025-01-12 00:32:37.775816: Epoch time: 40.03 s 
2025-01-12 00:32:38.346888:  
2025-01-12 00:32:38.346888: Epoch 112 
2025-01-12 00:32:38.352432: Current learning rate: 0.00586 
2025-01-12 00:33:18.366795: train_loss -0.5873 
2025-01-12 00:33:18.367309: val_loss -0.546 
2025-01-12 00:33:18.373371: Pseudo dice [np.float32(0.6425)] 
2025-01-12 00:33:18.376982: Epoch time: 40.02 s 
2025-01-12 00:33:18.935722:  
2025-01-12 00:33:18.936727: Epoch 113 
2025-01-12 00:33:18.942251: Current learning rate: 0.00582 
2025-01-12 00:33:58.951748: train_loss -0.5637 
2025-01-12 00:33:58.952751: val_loss -0.4533 
2025-01-12 00:33:58.958762: Pseudo dice [np.float32(0.443)] 
2025-01-12 00:33:58.962303: Epoch time: 40.02 s 
2025-01-12 00:33:59.535748:  
2025-01-12 00:33:59.535748: Epoch 114 
2025-01-12 00:33:59.540756: Current learning rate: 0.00578 
2025-01-12 00:34:39.553303: train_loss -0.5702 
2025-01-12 00:34:39.553806: val_loss -0.5323 
2025-01-12 00:34:39.559821: Pseudo dice [np.float32(0.6636)] 
2025-01-12 00:34:39.563326: Epoch time: 40.02 s 
2025-01-12 00:34:40.283849:  
2025-01-12 00:34:40.284853: Epoch 115 
2025-01-12 00:34:40.289405: Current learning rate: 0.00574 
2025-01-12 00:35:20.309405: train_loss -0.6121 
2025-01-12 00:35:20.310409: val_loss -0.5127 
2025-01-12 00:35:20.316955: Pseudo dice [np.float32(0.55)] 
2025-01-12 00:35:20.321463: Epoch time: 40.03 s 
2025-01-12 00:35:20.889840:  
2025-01-12 00:35:20.889840: Epoch 116 
2025-01-12 00:35:20.894864: Current learning rate: 0.0057 
2025-01-12 00:36:00.908645: train_loss -0.5964 
2025-01-12 00:36:00.909649: val_loss -0.4165 
2025-01-12 00:36:00.915171: Pseudo dice [np.float32(0.5333)] 
2025-01-12 00:36:00.917680: Epoch time: 40.02 s 
2025-01-12 00:36:01.493252:  
2025-01-12 00:36:01.494250: Epoch 117 
2025-01-12 00:36:01.498261: Current learning rate: 0.00567 
2025-01-12 00:36:41.481540: train_loss -0.5722 
2025-01-12 00:36:41.482540: val_loss -0.3211 
2025-01-12 00:36:41.488054: Pseudo dice [np.float32(0.4102)] 
2025-01-12 00:36:41.491562: Epoch time: 39.99 s 
2025-01-12 00:36:42.070792:  
2025-01-12 00:36:42.070792: Epoch 118 
2025-01-12 00:36:42.076347: Current learning rate: 0.00563 
2025-01-12 00:37:22.050622: train_loss -0.6096 
2025-01-12 00:37:22.051137: val_loss -0.4783 
2025-01-12 00:37:22.054682: Pseudo dice [np.float32(0.5977)] 
2025-01-12 00:37:22.058716: Epoch time: 39.98 s 
2025-01-12 00:37:22.629498:  
2025-01-12 00:37:22.629498: Epoch 119 
2025-01-12 00:37:22.634537: Current learning rate: 0.00559 
2025-01-12 00:38:02.634026: train_loss -0.6189 
2025-01-12 00:38:02.634026: val_loss -0.5574 
2025-01-12 00:38:02.640565: Pseudo dice [np.float32(0.6318)] 
2025-01-12 00:38:02.643582: Epoch time: 40.01 s 
2025-01-12 00:38:03.216712:  
2025-01-12 00:38:03.217713: Epoch 120 
2025-01-12 00:38:03.223303: Current learning rate: 0.00555 
2025-01-12 00:38:43.245479: train_loss -0.5666 
2025-01-12 00:38:43.246479: val_loss -0.5396 
2025-01-12 00:38:43.251992: Pseudo dice [np.float32(0.647)] 
2025-01-12 00:38:43.254497: Epoch time: 40.03 s 
2025-01-12 00:38:43.258047: Yayy! New best EMA pseudo Dice: 0.5665000081062317 
2025-01-12 00:38:44.100336:  
2025-01-12 00:38:44.101336: Epoch 121 
2025-01-12 00:38:44.106922: Current learning rate: 0.00551 
2025-01-12 00:39:24.125192: train_loss -0.5703 
2025-01-12 00:39:24.126192: val_loss -0.4987 
2025-01-12 00:39:24.132278: Pseudo dice [np.float32(0.5994)] 
2025-01-12 00:39:24.136805: Epoch time: 40.02 s 
2025-01-12 00:39:24.140314: Yayy! New best EMA pseudo Dice: 0.5698000192642212 
2025-01-12 00:39:24.967257:  
2025-01-12 00:39:24.967257: Epoch 122 
2025-01-12 00:39:24.972842: Current learning rate: 0.00547 
2025-01-12 00:40:04.994856: train_loss -0.5605 
2025-01-12 00:40:04.995856: val_loss -0.5003 
2025-01-12 00:40:05.001370: Pseudo dice [np.float32(0.5716)] 
2025-01-12 00:40:05.004879: Epoch time: 40.03 s 
2025-01-12 00:40:05.008389: Yayy! New best EMA pseudo Dice: 0.5699999928474426 
2025-01-12 00:40:05.992899:  
2025-01-12 00:40:05.993402: Epoch 123 
2025-01-12 00:40:05.998425: Current learning rate: 0.00544 
2025-01-12 00:40:46.008586: train_loss -0.5907 
2025-01-12 00:40:46.009088: val_loss -0.4836 
2025-01-12 00:40:46.015103: Pseudo dice [np.float32(0.5607)] 
2025-01-12 00:40:46.018612: Epoch time: 40.02 s 
2025-01-12 00:40:46.589962:  
2025-01-12 00:40:46.589962: Epoch 124 
2025-01-12 00:40:46.595587: Current learning rate: 0.0054 
2025-01-12 00:41:26.605728: train_loss -0.558 
2025-01-12 00:41:26.606250: val_loss -0.5064 
2025-01-12 00:41:26.613849: Pseudo dice [np.float32(0.5883)] 
2025-01-12 00:41:26.616436: Epoch time: 40.02 s 
2025-01-12 00:41:26.620495: Yayy! New best EMA pseudo Dice: 0.5709999799728394 
2025-01-12 00:41:27.445608:  
2025-01-12 00:41:27.445608: Epoch 125 
2025-01-12 00:41:27.451667: Current learning rate: 0.00536 
2025-01-12 00:42:07.483243: train_loss -0.5947 
2025-01-12 00:42:07.484247: val_loss -0.5284 
2025-01-12 00:42:07.491770: Pseudo dice [np.float32(0.6074)] 
2025-01-12 00:42:07.494276: Epoch time: 40.04 s 
2025-01-12 00:42:07.498286: Yayy! New best EMA pseudo Dice: 0.5745999813079834 
2025-01-12 00:42:08.299590:  
2025-01-12 00:42:08.300590: Epoch 126 
2025-01-12 00:42:08.305647: Current learning rate: 0.00532 
2025-01-12 00:42:48.337971: train_loss -0.6124 
2025-01-12 00:42:48.338482: val_loss -0.5439 
2025-01-12 00:42:48.344046: Pseudo dice [np.float32(0.6462)] 
2025-01-12 00:42:48.347615: Epoch time: 40.04 s 
2025-01-12 00:42:48.351190: Yayy! New best EMA pseudo Dice: 0.5817999839782715 
2025-01-12 00:42:49.172772:  
2025-01-12 00:42:49.172772: Epoch 127 
2025-01-12 00:42:49.178821: Current learning rate: 0.00528 
2025-01-12 00:43:29.240064: train_loss -0.5851 
2025-01-12 00:43:29.242545: val_loss -0.5578 
2025-01-12 00:43:29.248623: Pseudo dice [np.float32(0.6313)] 
2025-01-12 00:43:29.251879: Epoch time: 40.07 s 
2025-01-12 00:43:29.254918: Yayy! New best EMA pseudo Dice: 0.5867000222206116 
2025-01-12 00:43:30.054170:  
2025-01-12 00:43:30.054673: Epoch 128 
2025-01-12 00:43:30.059686: Current learning rate: 0.00524 
2025-01-12 00:44:10.082348: train_loss -0.6034 
2025-01-12 00:44:10.083349: val_loss -0.5796 
2025-01-12 00:44:10.088867: Pseudo dice [np.float32(0.654)] 
2025-01-12 00:44:10.092382: Epoch time: 40.03 s 
2025-01-12 00:44:10.096396: Yayy! New best EMA pseudo Dice: 0.5934000015258789 
2025-01-12 00:44:10.968628:  
2025-01-12 00:44:10.969628: Epoch 129 
2025-01-12 00:44:10.974683: Current learning rate: 0.0052 
2025-01-12 00:44:51.035481: train_loss -0.6231 
2025-01-12 00:44:51.036000: val_loss -0.4546 
2025-01-12 00:44:51.041643: Pseudo dice [np.float32(0.5838)] 
2025-01-12 00:44:51.045253: Epoch time: 40.07 s 
2025-01-12 00:44:51.622083:  
2025-01-12 00:44:51.622083: Epoch 130 
2025-01-12 00:44:51.627616: Current learning rate: 0.00517 
2025-01-12 00:45:31.659055: train_loss -0.5887 
2025-01-12 00:45:31.659055: val_loss -0.4616 
2025-01-12 00:45:31.666631: Pseudo dice [np.float32(0.5243)] 
2025-01-12 00:45:31.669170: Epoch time: 40.04 s 
2025-01-12 00:45:32.413031:  
2025-01-12 00:45:32.414031: Epoch 131 
2025-01-12 00:45:32.419216: Current learning rate: 0.00513 
2025-01-12 00:46:12.469126: train_loss -0.6264 
2025-01-12 00:46:12.470127: val_loss -0.4801 
2025-01-12 00:46:12.475656: Pseudo dice [np.float32(0.5715)] 
2025-01-12 00:46:12.479165: Epoch time: 40.06 s 
2025-01-12 00:46:13.048149:  
2025-01-12 00:46:13.048149: Epoch 132 
2025-01-12 00:46:13.053218: Current learning rate: 0.00509 
2025-01-12 00:46:53.090563: train_loss -0.5761 
2025-01-12 00:46:53.091067: val_loss -0.5435 
2025-01-12 00:46:53.097085: Pseudo dice [np.float32(0.6361)] 
2025-01-12 00:46:53.100107: Epoch time: 40.04 s 
2025-01-12 00:46:53.678838:  
2025-01-12 00:46:53.678838: Epoch 133 
2025-01-12 00:46:53.683932: Current learning rate: 0.00505 
2025-01-12 00:47:33.705326: train_loss -0.5901 
2025-01-12 00:47:33.706330: val_loss -0.4774 
2025-01-12 00:47:33.711914: Pseudo dice [np.float32(0.6069)] 
2025-01-12 00:47:33.714974: Epoch time: 40.03 s 
2025-01-12 00:47:34.298028:  
2025-01-12 00:47:34.298028: Epoch 134 
2025-01-12 00:47:34.303197: Current learning rate: 0.00501 
2025-01-12 00:48:14.331594: train_loss -0.6005 
2025-01-12 00:48:14.331594: val_loss -0.4928 
2025-01-12 00:48:14.337617: Pseudo dice [np.float32(0.622)] 
2025-01-12 00:48:14.341633: Epoch time: 40.03 s 
2025-01-12 00:48:14.343640: Yayy! New best EMA pseudo Dice: 0.5942999720573425 
2025-01-12 00:48:15.121541:  
2025-01-12 00:48:15.122547: Epoch 135 
2025-01-12 00:48:15.127105: Current learning rate: 0.00497 
2025-01-12 00:48:55.139402: train_loss -0.6209 
2025-01-12 00:48:55.139905: val_loss -0.5336 
2025-01-12 00:48:55.144918: Pseudo dice [np.float32(0.6232)] 
2025-01-12 00:48:55.148427: Epoch time: 40.02 s 
2025-01-12 00:48:55.151946: Yayy! New best EMA pseudo Dice: 0.5971999764442444 
2025-01-12 00:48:55.989406:  
2025-01-12 00:48:55.990409: Epoch 136 
2025-01-12 00:48:55.995459: Current learning rate: 0.00493 
2025-01-12 00:49:36.003389: train_loss -0.5872 
2025-01-12 00:49:36.003389: val_loss -0.501 
2025-01-12 00:49:36.010415: Pseudo dice [np.float32(0.5968)] 
2025-01-12 00:49:36.013425: Epoch time: 40.01 s 
2025-01-12 00:49:36.596215:  
2025-01-12 00:49:36.597718: Epoch 137 
2025-01-12 00:49:36.603803: Current learning rate: 0.00489 
2025-01-12 00:50:16.639456: train_loss -0.606 
2025-01-12 00:50:16.639456: val_loss -0.5471 
2025-01-12 00:50:16.645334: Pseudo dice [np.float32(0.6262)] 
2025-01-12 00:50:16.649355: Epoch time: 40.04 s 
2025-01-12 00:50:16.652395: Yayy! New best EMA pseudo Dice: 0.6000000238418579 
2025-01-12 00:50:17.476648:  
2025-01-12 00:50:17.477652: Epoch 138 
2025-01-12 00:50:17.481694: Current learning rate: 0.00485 
2025-01-12 00:50:57.483969: train_loss -0.5875 
2025-01-12 00:50:57.484970: val_loss -0.5535 
2025-01-12 00:50:57.490483: Pseudo dice [np.float32(0.6584)] 
2025-01-12 00:50:57.493992: Epoch time: 40.01 s 
2025-01-12 00:50:57.496497: Yayy! New best EMA pseudo Dice: 0.60589998960495 
2025-01-12 00:50:58.503241:  
2025-01-12 00:50:58.503241: Epoch 139 
2025-01-12 00:50:58.508255: Current learning rate: 0.00482 
2025-01-12 00:51:38.500351: train_loss -0.6461 
2025-01-12 00:51:38.501353: val_loss -0.4883 
2025-01-12 00:51:38.506874: Pseudo dice [np.float32(0.5881)] 
2025-01-12 00:51:38.510383: Epoch time: 40.0 s 
2025-01-12 00:51:39.089762:  
2025-01-12 00:51:39.089762: Epoch 140 
2025-01-12 00:51:39.094478: Current learning rate: 0.00478 
2025-01-12 00:52:19.113282: train_loss -0.6124 
2025-01-12 00:52:19.113793: val_loss -0.4785 
2025-01-12 00:52:19.119385: Pseudo dice [np.float32(0.5535)] 
2025-01-12 00:52:19.122973: Epoch time: 40.02 s 
2025-01-12 00:52:19.713344:  
2025-01-12 00:52:19.714345: Epoch 141 
2025-01-12 00:52:19.719418: Current learning rate: 0.00474 
2025-01-12 00:52:59.731195: train_loss -0.6301 
2025-01-12 00:52:59.731699: val_loss -0.5246 
2025-01-12 00:52:59.736713: Pseudo dice [np.float32(0.6114)] 
2025-01-12 00:52:59.740256: Epoch time: 40.02 s 
2025-01-12 00:53:00.331182:  
2025-01-12 00:53:00.331182: Epoch 142 
2025-01-12 00:53:00.336193: Current learning rate: 0.0047 
2025-01-12 00:53:44.292726: train_loss -0.6492 
2025-01-12 00:53:44.292726: val_loss -0.5333 
2025-01-12 00:53:44.299239: Pseudo dice [np.float32(0.6116)] 
2025-01-12 00:53:44.301780: Epoch time: 43.96 s 
2025-01-12 00:53:44.855110:  
2025-01-12 00:53:44.855110: Epoch 143 
2025-01-12 00:53:44.860648: Current learning rate: 0.00466 
2025-01-12 00:54:25.388976: train_loss -0.6003 
2025-01-12 00:54:25.389981: val_loss -0.4722 
2025-01-12 00:54:25.397501: Pseudo dice [np.float32(0.5672)] 
2025-01-12 00:54:25.401007: Epoch time: 40.53 s 
2025-01-12 00:54:25.985424:  
2025-01-12 00:54:25.985926: Epoch 144 
2025-01-12 00:54:25.990940: Current learning rate: 0.00462 
2025-01-12 00:55:06.200557: train_loss -0.5852 
2025-01-12 00:55:06.200557: val_loss -0.3665 
2025-01-12 00:55:06.206638: Pseudo dice [np.float32(0.5059)] 
2025-01-12 00:55:06.210205: Epoch time: 40.22 s 
2025-01-12 00:55:06.799018:  
2025-01-12 00:55:06.799018: Epoch 145 
2025-01-12 00:55:06.805143: Current learning rate: 0.00458 
2025-01-12 00:55:47.038860: train_loss -0.6108 
2025-01-12 00:55:47.039367: val_loss -0.4154 
2025-01-12 00:55:47.045557: Pseudo dice [np.float32(0.5154)] 
2025-01-12 00:55:47.048115: Epoch time: 40.24 s 
2025-01-12 00:55:47.635021:  
2025-01-12 00:55:47.635537: Epoch 146 
2025-01-12 00:55:47.641097: Current learning rate: 0.00454 
2025-01-12 00:56:27.858953: train_loss -0.6024 
2025-01-12 00:56:27.858953: val_loss -0.5045 
2025-01-12 00:56:27.865474: Pseudo dice [np.float32(0.6108)] 
2025-01-12 00:56:27.868986: Epoch time: 40.23 s 
2025-01-12 00:56:28.607868:  
2025-01-12 00:56:28.608866: Epoch 147 
2025-01-12 00:56:28.611910: Current learning rate: 0.0045 
2025-01-12 00:57:08.823310: train_loss -0.6013 
2025-01-12 00:57:08.823310: val_loss -0.5046 
2025-01-12 00:57:08.828963: Pseudo dice [np.float32(0.5915)] 
2025-01-12 00:57:08.831987: Epoch time: 40.22 s 
2025-01-12 00:57:09.428610:  
2025-01-12 00:57:09.429613: Epoch 148 
2025-01-12 00:57:09.434647: Current learning rate: 0.00446 
2025-01-12 00:57:49.657782: train_loss -0.6203 
2025-01-12 00:57:49.659286: val_loss -0.5348 
2025-01-12 00:57:49.665308: Pseudo dice [np.float32(0.6164)] 
2025-01-12 00:57:49.667817: Epoch time: 40.23 s 
2025-01-12 00:57:50.253211:  
2025-01-12 00:57:50.254211: Epoch 149 
2025-01-12 00:57:50.259821: Current learning rate: 0.00442 
2025-01-12 00:58:30.550649: train_loss -0.6187 
2025-01-12 00:58:30.551653: val_loss -0.5544 
2025-01-12 00:58:30.556666: Pseudo dice [np.float32(0.6315)] 
2025-01-12 00:58:30.560675: Epoch time: 40.3 s 
2025-01-12 00:58:31.373118:  
2025-01-12 00:58:31.374123: Epoch 150 
2025-01-12 00:58:31.378675: Current learning rate: 0.00438 
2025-01-12 00:59:11.617916: train_loss -0.6251 
2025-01-12 00:59:11.618920: val_loss -0.5518 
2025-01-12 00:59:11.624934: Pseudo dice [np.float32(0.5876)] 
2025-01-12 00:59:11.627942: Epoch time: 40.25 s 
2025-01-12 00:59:12.214212:  
2025-01-12 00:59:12.214714: Epoch 151 
2025-01-12 00:59:12.220729: Current learning rate: 0.00434 
2025-01-12 00:59:52.593572: train_loss -0.6279 
2025-01-12 00:59:52.594074: val_loss -0.4345 
2025-01-12 00:59:52.600094: Pseudo dice [np.float32(0.5156)] 
2025-01-12 00:59:52.603602: Epoch time: 40.38 s 
2025-01-12 00:59:53.194370:  
2025-01-12 00:59:53.194370: Epoch 152 
2025-01-12 00:59:53.200979: Current learning rate: 0.0043 
2025-01-12 01:00:33.418175: train_loss -0.6259 
2025-01-12 01:00:33.418679: val_loss -0.4375 
2025-01-12 01:00:33.425743: Pseudo dice [np.float32(0.5737)] 
2025-01-12 01:00:33.428272: Epoch time: 40.22 s 
2025-01-12 01:00:34.018249:  
2025-01-12 01:00:34.019252: Epoch 153 
2025-01-12 01:00:34.024335: Current learning rate: 0.00427 
2025-01-12 01:01:14.251740: train_loss -0.6075 
2025-01-12 01:01:14.251740: val_loss -0.5208 
2025-01-12 01:01:14.257834: Pseudo dice [np.float32(0.652)] 
2025-01-12 01:01:14.261349: Epoch time: 40.23 s 
2025-01-12 01:01:14.860533:  
2025-01-12 01:01:14.861035: Epoch 154 
2025-01-12 01:01:14.866066: Current learning rate: 0.00423 
2025-01-12 01:01:55.097580: train_loss -0.6101 
2025-01-12 01:01:55.098586: val_loss -0.4758 
2025-01-12 01:01:55.104127: Pseudo dice [np.float32(0.5998)] 
2025-01-12 01:01:55.107151: Epoch time: 40.24 s 
2025-01-12 01:01:55.865488:  
2025-01-12 01:01:55.865488: Epoch 155 
2025-01-12 01:01:55.871523: Current learning rate: 0.00419 
2025-01-12 01:02:36.081314: train_loss -0.6071 
2025-01-12 01:02:36.081314: val_loss -0.3896 
2025-01-12 01:02:36.087356: Pseudo dice [np.float32(0.565)] 
2025-01-12 01:02:36.090954: Epoch time: 40.22 s 
2025-01-12 01:02:36.686389:  
2025-01-12 01:02:36.687389: Epoch 156 
2025-01-12 01:02:36.692449: Current learning rate: 0.00415 
2025-01-12 01:03:16.904018: train_loss -0.6365 
2025-01-12 01:03:16.904526: val_loss -0.4966 
2025-01-12 01:03:16.909097: Pseudo dice [np.float32(0.608)] 
2025-01-12 01:03:16.912126: Epoch time: 40.22 s 
2025-01-12 01:03:17.511177:  
2025-01-12 01:03:17.511177: Epoch 157 
2025-01-12 01:03:17.516705: Current learning rate: 0.00411 
2025-01-12 01:03:57.707072: train_loss -0.6308 
2025-01-12 01:03:57.707575: val_loss -0.5153 
2025-01-12 01:03:57.712612: Pseudo dice [np.float32(0.6172)] 
2025-01-12 01:03:57.716646: Epoch time: 40.2 s 
2025-01-12 01:03:58.340936:  
2025-01-12 01:03:58.340936: Epoch 158 
2025-01-12 01:03:58.346958: Current learning rate: 0.00407 
2025-01-12 01:04:38.551324: train_loss -0.6353 
2025-01-12 01:04:38.551835: val_loss -0.4347 
2025-01-12 01:04:38.557399: Pseudo dice [np.float32(0.5819)] 
2025-01-12 01:04:38.560956: Epoch time: 40.21 s 
2025-01-12 01:04:39.159600:  
2025-01-12 01:04:39.159600: Epoch 159 
2025-01-12 01:04:39.164611: Current learning rate: 0.00403 
2025-01-12 01:05:19.157891: train_loss -0.6419 
2025-01-12 01:05:19.157891: val_loss -0.5277 
2025-01-12 01:05:19.164003: Pseudo dice [np.float32(0.5914)] 
2025-01-12 01:05:19.167585: Epoch time: 40.0 s 
2025-01-12 01:05:19.765342:  
2025-01-12 01:05:19.766345: Epoch 160 
2025-01-12 01:05:19.771872: Current learning rate: 0.00399 
2025-01-12 01:05:59.781446: train_loss -0.6448 
2025-01-12 01:05:59.781961: val_loss -0.5467 
2025-01-12 01:05:59.787044: Pseudo dice [np.float32(0.6789)] 
2025-01-12 01:05:59.791641: Epoch time: 40.02 s 
2025-01-12 01:06:00.390972:  
2025-01-12 01:06:00.390972: Epoch 161 
2025-01-12 01:06:00.396513: Current learning rate: 0.00395 
2025-01-12 01:06:40.406276: train_loss -0.6219 
2025-01-12 01:06:40.407279: val_loss -0.5373 
2025-01-12 01:06:40.413292: Pseudo dice [np.float32(0.6669)] 
2025-01-12 01:06:40.416302: Epoch time: 40.02 s 
2025-01-12 01:06:40.419826: Yayy! New best EMA pseudo Dice: 0.6072999835014343 
2025-01-12 01:06:41.280443:  
2025-01-12 01:06:41.280945: Epoch 162 
2025-01-12 01:06:41.286963: Current learning rate: 0.00391 
2025-01-12 01:07:21.312714: train_loss -0.6499 
2025-01-12 01:07:21.313221: val_loss -0.5362 
2025-01-12 01:07:21.320285: Pseudo dice [np.float32(0.5986)] 
2025-01-12 01:07:21.323346: Epoch time: 40.03 s 
2025-01-12 01:07:22.081113:  
2025-01-12 01:07:22.082116: Epoch 163 
2025-01-12 01:07:22.087140: Current learning rate: 0.00387 
2025-01-12 01:08:02.094480: train_loss -0.6556 
2025-01-12 01:08:02.094480: val_loss -0.5378 
2025-01-12 01:08:02.101036: Pseudo dice [np.float32(0.6445)] 
2025-01-12 01:08:02.104574: Epoch time: 40.01 s 
2025-01-12 01:08:02.107098: Yayy! New best EMA pseudo Dice: 0.6101999878883362 
2025-01-12 01:08:02.962235:  
2025-01-12 01:08:02.962235: Epoch 164 
2025-01-12 01:08:02.967805: Current learning rate: 0.00383 
2025-01-12 01:08:42.948195: train_loss -0.5987 
2025-01-12 01:08:42.949194: val_loss -0.5464 
2025-01-12 01:08:42.954711: Pseudo dice [np.float32(0.6276)] 
2025-01-12 01:08:42.958220: Epoch time: 39.99 s 
2025-01-12 01:08:42.962244: Yayy! New best EMA pseudo Dice: 0.6119999885559082 
2025-01-12 01:08:43.770668:  
2025-01-12 01:08:43.770668: Epoch 165 
2025-01-12 01:08:43.776237: Current learning rate: 0.00379 
2025-01-12 01:09:23.762676: train_loss -0.6439 
2025-01-12 01:09:23.762676: val_loss -0.5652 
2025-01-12 01:09:23.769193: Pseudo dice [np.float32(0.7029)] 
2025-01-12 01:09:23.772702: Epoch time: 39.99 s 
2025-01-12 01:09:23.776208: Yayy! New best EMA pseudo Dice: 0.6211000084877014 
2025-01-12 01:09:24.622636:  
2025-01-12 01:09:24.622636: Epoch 166 
2025-01-12 01:09:24.628167: Current learning rate: 0.00375 
2025-01-12 01:10:04.646775: train_loss -0.6294 
2025-01-12 01:10:04.647278: val_loss -0.4897 
2025-01-12 01:10:04.652860: Pseudo dice [np.float32(0.6103)] 
2025-01-12 01:10:04.655889: Epoch time: 40.03 s 
2025-01-12 01:10:05.237111:  
2025-01-12 01:10:05.237619: Epoch 167 
2025-01-12 01:10:05.242170: Current learning rate: 0.00371 
2025-01-12 01:10:45.248026: train_loss -0.6654 
2025-01-12 01:10:45.248026: val_loss -0.5181 
2025-01-12 01:10:45.255547: Pseudo dice [np.float32(0.6675)] 
2025-01-12 01:10:45.259056: Epoch time: 40.01 s 
2025-01-12 01:10:45.261563: Yayy! New best EMA pseudo Dice: 0.6247000098228455 
2025-01-12 01:10:46.104576:  
2025-01-12 01:10:46.104576: Epoch 168 
2025-01-12 01:10:46.110110: Current learning rate: 0.00367 
2025-01-12 01:11:26.106092: train_loss -0.6214 
2025-01-12 01:11:26.106595: val_loss -0.5533 
2025-01-12 01:11:26.113672: Pseudo dice [np.float32(0.6511)] 
2025-01-12 01:11:26.116680: Epoch time: 40.0 s 
2025-01-12 01:11:26.120189: Yayy! New best EMA pseudo Dice: 0.6273999810218811 
2025-01-12 01:11:26.961659:  
2025-01-12 01:11:26.961659: Epoch 169 
2025-01-12 01:11:26.967196: Current learning rate: 0.00363 
2025-01-12 01:12:06.964646: train_loss -0.6419 
2025-01-12 01:12:06.965650: val_loss -0.566 
2025-01-12 01:12:06.971661: Pseudo dice [np.float32(0.6531)] 
2025-01-12 01:12:06.974713: Epoch time: 40.0 s 
2025-01-12 01:12:06.977238: Yayy! New best EMA pseudo Dice: 0.6298999786376953 
2025-01-12 01:12:07.975294:  
2025-01-12 01:12:07.976298: Epoch 170 
2025-01-12 01:12:07.980912: Current learning rate: 0.00359 
2025-01-12 01:12:47.987608: train_loss -0.6124 
2025-01-12 01:12:47.988611: val_loss -0.5206 
2025-01-12 01:12:47.994622: Pseudo dice [np.float32(0.6516)] 
2025-01-12 01:12:47.997629: Epoch time: 40.01 s 
2025-01-12 01:12:48.000660: Yayy! New best EMA pseudo Dice: 0.632099986076355 
2025-01-12 01:12:48.799129:  
2025-01-12 01:12:48.799129: Epoch 171 
2025-01-12 01:12:48.804140: Current learning rate: 0.00355 
2025-01-12 01:13:28.798930: train_loss -0.6773 
2025-01-12 01:13:28.799929: val_loss -0.4773 
2025-01-12 01:13:28.806446: Pseudo dice [np.float32(0.6328)] 
2025-01-12 01:13:28.810487: Epoch time: 40.0 s 
2025-01-12 01:13:28.812993: Yayy! New best EMA pseudo Dice: 0.6322000026702881 
2025-01-12 01:13:29.675394:  
2025-01-12 01:13:29.675394: Epoch 172 
2025-01-12 01:13:29.680500: Current learning rate: 0.00351 
2025-01-12 01:14:09.670286: train_loss -0.6288 
2025-01-12 01:14:09.671286: val_loss -0.5434 
2025-01-12 01:14:09.676800: Pseudo dice [np.float32(0.6888)] 
2025-01-12 01:14:09.680341: Epoch time: 40.0 s 
2025-01-12 01:14:09.682847: Yayy! New best EMA pseudo Dice: 0.6377999782562256 
2025-01-12 01:14:10.529426:  
2025-01-12 01:14:10.530429: Epoch 173 
2025-01-12 01:14:10.535489: Current learning rate: 0.00346 
2025-01-12 01:14:50.530649: train_loss -0.6497 
2025-01-12 01:14:50.531661: val_loss -0.4985 
2025-01-12 01:14:50.536747: Pseudo dice [np.float32(0.5824)] 
2025-01-12 01:14:50.539272: Epoch time: 40.0 s 
2025-01-12 01:14:51.132762:  
2025-01-12 01:14:51.132762: Epoch 174 
2025-01-12 01:14:51.137790: Current learning rate: 0.00342 
2025-01-12 01:15:31.140505: train_loss -0.6548 
2025-01-12 01:15:31.140505: val_loss -0.5347 
2025-01-12 01:15:31.148022: Pseudo dice [np.float32(0.6556)] 
2025-01-12 01:15:31.150527: Epoch time: 40.01 s 
2025-01-12 01:15:31.746371:  
2025-01-12 01:15:31.747375: Epoch 175 
2025-01-12 01:15:31.751906: Current learning rate: 0.00338 
2025-01-12 01:16:11.723774: train_loss -0.6328 
2025-01-12 01:16:11.724778: val_loss -0.5205 
2025-01-12 01:16:11.729788: Pseudo dice [np.float32(0.6597)] 
2025-01-12 01:16:11.733294: Epoch time: 39.98 s 
2025-01-12 01:16:12.325071:  
2025-01-12 01:16:12.325071: Epoch 176 
2025-01-12 01:16:12.331167: Current learning rate: 0.00334 
2025-01-12 01:16:52.333729: train_loss -0.6844 
2025-01-12 01:16:52.333729: val_loss -0.5698 
2025-01-12 01:16:52.340242: Pseudo dice [np.float32(0.6912)] 
2025-01-12 01:16:52.343752: Epoch time: 40.01 s 
2025-01-12 01:16:52.345773: Yayy! New best EMA pseudo Dice: 0.6424999833106995 
2025-01-12 01:16:53.190701:  
2025-01-12 01:16:53.191705: Epoch 177 
2025-01-12 01:16:53.196286: Current learning rate: 0.0033 
2025-01-12 01:17:33.168604: train_loss -0.6434 
2025-01-12 01:17:33.168604: val_loss -0.5421 
2025-01-12 01:17:33.175756: Pseudo dice [np.float32(0.6821)] 
2025-01-12 01:17:33.179310: Epoch time: 39.98 s 
2025-01-12 01:17:33.181835: Yayy! New best EMA pseudo Dice: 0.6464999914169312 
2025-01-12 01:17:34.199957:  
2025-01-12 01:17:34.200960: Epoch 178 
2025-01-12 01:17:34.205971: Current learning rate: 0.00326 
2025-01-12 01:18:14.179823: train_loss -0.6348 
2025-01-12 01:18:14.179823: val_loss -0.4996 
2025-01-12 01:18:14.185419: Pseudo dice [np.float32(0.6211)] 
2025-01-12 01:18:14.188460: Epoch time: 39.98 s 
2025-01-12 01:18:14.780098:  
2025-01-12 01:18:14.780098: Epoch 179 
2025-01-12 01:18:14.786212: Current learning rate: 0.00322 
2025-01-12 01:18:54.757181: train_loss -0.674 
2025-01-12 01:18:54.757181: val_loss -0.5645 
2025-01-12 01:18:54.763195: Pseudo dice [np.float32(0.7129)] 
2025-01-12 01:18:54.766709: Epoch time: 39.98 s 
2025-01-12 01:18:54.769758: Yayy! New best EMA pseudo Dice: 0.6507999897003174 
2025-01-12 01:18:55.610245:  
2025-01-12 01:18:55.610755: Epoch 180 
2025-01-12 01:18:55.615791: Current learning rate: 0.00318 
2025-01-12 01:19:35.608753: train_loss -0.6617 
2025-01-12 01:19:35.608753: val_loss -0.5954 
2025-01-12 01:19:35.614808: Pseudo dice [np.float32(0.6512)] 
2025-01-12 01:19:35.617316: Epoch time: 40.0 s 
2025-01-12 01:19:35.620820: Yayy! New best EMA pseudo Dice: 0.6509000062942505 
2025-01-12 01:19:38.088820:  
2025-01-12 01:19:38.088820: Epoch 181 
2025-01-12 01:19:38.094984: Current learning rate: 0.00314 
2025-01-12 01:20:21.353568: train_loss -0.6458 
2025-01-12 01:20:21.354071: val_loss -0.5443 
2025-01-12 01:20:21.361313: Pseudo dice [np.float32(0.6304)] 
2025-01-12 01:20:21.365385: Epoch time: 43.27 s 
2025-01-12 01:20:21.930160:  
2025-01-12 01:20:21.930160: Epoch 182 
2025-01-12 01:20:21.935675: Current learning rate: 0.0031 
2025-01-12 01:21:02.303833: train_loss -0.6348 
2025-01-12 01:21:02.304837: val_loss -0.5406 
2025-01-12 01:21:02.309850: Pseudo dice [np.float32(0.6172)] 
2025-01-12 01:21:02.313374: Epoch time: 40.37 s 
2025-01-12 01:21:02.875348:  
2025-01-12 01:21:02.876348: Epoch 183 
2025-01-12 01:21:02.881124: Current learning rate: 0.00306 
2025-01-12 01:21:43.265791: train_loss -0.6276 
2025-01-12 01:21:43.265791: val_loss -0.5242 
2025-01-12 01:21:43.271315: Pseudo dice [np.float32(0.6362)] 
2025-01-12 01:21:43.275341: Epoch time: 40.39 s 
2025-01-12 01:21:43.835094:  
2025-01-12 01:21:43.836100: Epoch 184 
2025-01-12 01:21:43.840636: Current learning rate: 0.00302 
2025-01-12 01:22:24.228374: train_loss -0.6395 
2025-01-12 01:22:24.229877: val_loss -0.5583 
2025-01-12 01:22:24.237396: Pseudo dice [np.float32(0.662)] 
2025-01-12 01:22:24.240905: Epoch time: 40.39 s 
2025-01-12 01:22:24.803553:  
2025-01-12 01:22:24.804056: Epoch 185 
2025-01-12 01:22:24.808566: Current learning rate: 0.00297 
2025-01-12 01:23:05.167591: train_loss -0.6828 
2025-01-12 01:23:05.168093: val_loss -0.5088 
2025-01-12 01:23:05.174107: Pseudo dice [np.float32(0.5952)] 
2025-01-12 01:23:05.178119: Epoch time: 40.37 s 
2025-01-12 01:23:05.894985:  
2025-01-12 01:23:05.895988: Epoch 186 
2025-01-12 01:23:05.902171: Current learning rate: 0.00293 
2025-01-12 01:23:46.246836: train_loss -0.6642 
2025-01-12 01:23:46.247340: val_loss -0.5107 
2025-01-12 01:23:46.253360: Pseudo dice [np.float32(0.6454)] 
2025-01-12 01:23:46.256882: Epoch time: 40.35 s 
2025-01-12 01:23:46.814289:  
2025-01-12 01:23:46.815294: Epoch 187 
2025-01-12 01:23:46.820379: Current learning rate: 0.00289 
2025-01-12 01:24:27.197255: train_loss -0.6455 
2025-01-12 01:24:27.197791: val_loss -0.4855 
2025-01-12 01:24:27.204944: Pseudo dice [np.float32(0.6523)] 
2025-01-12 01:24:27.208514: Epoch time: 40.38 s 
2025-01-12 01:24:27.763755:  
2025-01-12 01:24:27.764754: Epoch 188 
2025-01-12 01:24:27.769821: Current learning rate: 0.00285 
2025-01-12 01:25:08.130884: train_loss -0.6394 
2025-01-12 01:25:08.130884: val_loss -0.442 
2025-01-12 01:25:08.137900: Pseudo dice [np.float32(0.5758)] 
2025-01-12 01:25:08.141914: Epoch time: 40.37 s 
2025-01-12 01:25:08.699663:  
2025-01-12 01:25:08.699663: Epoch 189 
2025-01-12 01:25:08.705756: Current learning rate: 0.00281 
2025-01-12 01:25:49.339738: train_loss -0.6486 
2025-01-12 01:25:49.340742: val_loss -0.4824 
2025-01-12 01:25:49.346386: Pseudo dice [np.float32(0.6603)] 
2025-01-12 01:25:49.350394: Epoch time: 40.64 s 
2025-01-12 01:25:49.903717:  
2025-01-12 01:25:49.903717: Epoch 190 
2025-01-12 01:25:49.909736: Current learning rate: 0.00277 
2025-01-12 01:26:30.259878: train_loss -0.6415 
2025-01-12 01:26:30.260391: val_loss -0.5045 
2025-01-12 01:26:30.267560: Pseudo dice [np.float32(0.5878)] 
2025-01-12 01:26:30.271683: Epoch time: 40.36 s 
2025-01-12 01:26:30.830399:  
2025-01-12 01:26:30.830399: Epoch 191 
2025-01-12 01:26:30.835940: Current learning rate: 0.00273 
2025-01-12 01:27:11.208684: train_loss -0.682 
2025-01-12 01:27:11.209188: val_loss -0.5001 
2025-01-12 01:27:11.214271: Pseudo dice [np.float32(0.6368)] 
2025-01-12 01:27:11.218283: Epoch time: 40.38 s 
2025-01-12 01:27:11.780774:  
2025-01-12 01:27:11.781779: Epoch 192 
2025-01-12 01:27:11.786894: Current learning rate: 0.00268 
2025-01-12 01:27:52.160391: train_loss -0.6521 
2025-01-12 01:27:52.161394: val_loss -0.4936 
2025-01-12 01:27:52.166648: Pseudo dice [np.float32(0.6613)] 
2025-01-12 01:27:52.170167: Epoch time: 40.38 s 
2025-01-12 01:27:52.894248:  
2025-01-12 01:27:52.894248: Epoch 193 
2025-01-12 01:27:52.898971: Current learning rate: 0.00264 
2025-01-12 01:28:33.236504: train_loss -0.6687 
2025-01-12 01:28:33.237018: val_loss -0.5535 
2025-01-12 01:28:33.242587: Pseudo dice [np.float32(0.6987)] 
2025-01-12 01:28:33.246114: Epoch time: 40.34 s 
2025-01-12 01:28:33.806803:  
2025-01-12 01:28:33.807306: Epoch 194 
2025-01-12 01:28:33.812319: Current learning rate: 0.0026 
2025-01-12 01:29:14.166236: train_loss -0.6701 
2025-01-12 01:29:14.166236: val_loss -0.4783 
2025-01-12 01:29:14.172760: Pseudo dice [np.float32(0.557)] 
2025-01-12 01:29:14.176280: Epoch time: 40.36 s 
2025-01-12 01:29:14.746120:  
2025-01-12 01:29:14.747121: Epoch 195 
2025-01-12 01:29:14.752637: Current learning rate: 0.00256 
2025-01-12 01:29:55.104002: train_loss -0.6836 
2025-01-12 01:29:55.105006: val_loss -0.5634 
2025-01-12 01:29:55.109678: Pseudo dice [np.float32(0.7118)] 
2025-01-12 01:29:55.114691: Epoch time: 40.36 s 
2025-01-12 01:29:55.679729:  
2025-01-12 01:29:55.679729: Epoch 196 
2025-01-12 01:29:55.684748: Current learning rate: 0.00252 
2025-01-12 01:30:36.002029: train_loss -0.6936 
2025-01-12 01:30:36.003035: val_loss -0.4693 
2025-01-12 01:30:36.009874: Pseudo dice [np.float32(0.5806)] 
2025-01-12 01:30:36.012886: Epoch time: 40.32 s 
2025-01-12 01:30:36.582603:  
2025-01-12 01:30:36.582603: Epoch 197 
2025-01-12 01:30:36.588520: Current learning rate: 0.00248 
2025-01-12 01:31:16.727299: train_loss -0.6667 
2025-01-12 01:31:16.728304: val_loss -0.5356 
2025-01-12 01:31:16.733315: Pseudo dice [np.float32(0.6183)] 
2025-01-12 01:31:16.737349: Epoch time: 40.15 s 
2025-01-12 01:31:17.309641:  
2025-01-12 01:31:17.309641: Epoch 198 
2025-01-12 01:31:17.315733: Current learning rate: 0.00243 
2025-01-12 01:31:57.452482: train_loss -0.6602 
2025-01-12 01:31:57.453992: val_loss -0.5464 
2025-01-12 01:31:57.460539: Pseudo dice [np.float32(0.6594)] 
2025-01-12 01:31:57.464059: Epoch time: 40.14 s 
2025-01-12 01:31:58.027269:  
2025-01-12 01:31:58.028273: Epoch 199 
2025-01-12 01:31:58.032803: Current learning rate: 0.00239 
2025-01-12 01:32:38.157821: train_loss -0.668 
2025-01-12 01:32:38.157821: val_loss -0.4677 
2025-01-12 01:32:38.165036: Pseudo dice [np.float32(0.6138)] 
2025-01-12 01:32:38.168549: Epoch time: 40.13 s 
2025-01-12 01:32:38.966304:  
2025-01-12 01:32:38.966808: Epoch 200 
2025-01-12 01:32:38.972023: Current learning rate: 0.00235 
2025-01-12 01:33:19.100220: train_loss -0.6846 
2025-01-12 01:33:19.100722: val_loss -0.4996 
2025-01-12 01:33:19.106736: Pseudo dice [np.float32(0.6263)] 
2025-01-12 01:33:19.110245: Epoch time: 40.13 s 
2025-01-12 01:33:19.836042:  
2025-01-12 01:33:19.837045: Epoch 201 
2025-01-12 01:33:19.842156: Current learning rate: 0.00231 
2025-01-12 01:33:59.993536: train_loss -0.6775 
2025-01-12 01:33:59.994541: val_loss -0.5235 
2025-01-12 01:34:00.000414: Pseudo dice [np.float32(0.652)] 
2025-01-12 01:34:00.005431: Epoch time: 40.16 s 
2025-01-12 01:34:00.578411:  
2025-01-12 01:34:00.578411: Epoch 202 
2025-01-12 01:34:00.584497: Current learning rate: 0.00226 
2025-01-12 01:34:40.734693: train_loss -0.6932 
2025-01-12 01:34:40.735199: val_loss -0.5222 
2025-01-12 01:34:40.740809: Pseudo dice [np.float32(0.6226)] 
2025-01-12 01:34:40.743393: Epoch time: 40.16 s 
2025-01-12 01:34:41.311062:  
2025-01-12 01:34:41.311062: Epoch 203 
2025-01-12 01:34:41.316662: Current learning rate: 0.00222 
2025-01-12 01:35:21.459553: train_loss -0.6844 
2025-01-12 01:35:21.459553: val_loss -0.5422 
2025-01-12 01:35:21.467129: Pseudo dice [np.float32(0.6481)] 
2025-01-12 01:35:21.470252: Epoch time: 40.15 s 
2025-01-12 01:35:22.037930:  
2025-01-12 01:35:22.037930: Epoch 204 
2025-01-12 01:35:22.042948: Current learning rate: 0.00218 
2025-01-12 01:36:02.179346: train_loss -0.6776 
2025-01-12 01:36:02.180350: val_loss -0.3758 
2025-01-12 01:36:02.185366: Pseudo dice [np.float32(0.4831)] 
2025-01-12 01:36:02.189377: Epoch time: 40.14 s 
2025-01-12 01:36:02.754059:  
2025-01-12 01:36:02.754059: Epoch 205 
2025-01-12 01:36:02.759630: Current learning rate: 0.00214 
2025-01-12 01:36:42.901902: train_loss -0.6752 
2025-01-12 01:36:42.902405: val_loss -0.5173 
2025-01-12 01:36:42.908503: Pseudo dice [np.float32(0.6213)] 
2025-01-12 01:36:42.912039: Epoch time: 40.15 s 
2025-01-12 01:36:43.445622:  
2025-01-12 01:36:43.445622: Epoch 206 
2025-01-12 01:36:43.451695: Current learning rate: 0.00209 
2025-01-12 01:37:23.575809: train_loss -0.6791 
2025-01-12 01:37:23.576326: val_loss -0.398 
2025-01-12 01:37:23.583955: Pseudo dice [np.float32(0.4938)] 
2025-01-12 01:37:23.587609: Epoch time: 40.13 s 
2025-01-12 01:37:24.122589:  
2025-01-12 01:37:24.123092: Epoch 207 
2025-01-12 01:37:24.128130: Current learning rate: 0.00205 
2025-01-12 01:38:04.260136: train_loss -0.6789 
2025-01-12 01:38:04.261652: val_loss -0.5262 
2025-01-12 01:38:04.267196: Pseudo dice [np.float32(0.6576)] 
2025-01-12 01:38:04.270205: Epoch time: 40.14 s 
2025-01-12 01:38:04.950703:  
2025-01-12 01:38:04.951707: Epoch 208 
2025-01-12 01:38:04.956256: Current learning rate: 0.00201 
2025-01-12 01:38:47.000931: train_loss -0.6611 
2025-01-12 01:38:47.001931: val_loss -0.4495 
2025-01-12 01:38:47.007449: Pseudo dice [np.float32(0.5656)] 
2025-01-12 01:38:47.010964: Epoch time: 42.05 s 
2025-01-12 01:38:47.548816:  
2025-01-12 01:38:47.548816: Epoch 209 
2025-01-12 01:38:47.554889: Current learning rate: 0.00196 
2025-01-12 01:39:27.705991: train_loss -0.6615 
2025-01-12 01:39:27.706996: val_loss -0.5965 
2025-01-12 01:39:27.713089: Pseudo dice [np.float32(0.6853)] 
2025-01-12 01:39:27.717132: Epoch time: 40.16 s 
2025-01-12 01:39:28.247580:  
2025-01-12 01:39:28.247580: Epoch 210 
2025-01-12 01:39:28.252590: Current learning rate: 0.00192 
2025-01-12 01:40:08.401092: train_loss -0.6839 
2025-01-12 01:40:08.401092: val_loss -0.5533 
2025-01-12 01:40:08.407114: Pseudo dice [np.float32(0.6686)] 
2025-01-12 01:40:08.411127: Epoch time: 40.16 s 
2025-01-12 01:40:08.948291:  
2025-01-12 01:40:08.948799: Epoch 211 
2025-01-12 01:40:08.953399: Current learning rate: 0.00188 
2025-01-12 01:40:49.100700: train_loss -0.68 
2025-01-12 01:40:49.101204: val_loss -0.6054 
2025-01-12 01:40:49.106752: Pseudo dice [np.float32(0.7307)] 
2025-01-12 01:40:49.110293: Epoch time: 40.15 s 
2025-01-12 01:40:49.644848:  
2025-01-12 01:40:49.644848: Epoch 212 
2025-01-12 01:40:49.650391: Current learning rate: 0.00184 
2025-01-12 01:41:29.825232: train_loss -0.6905 
2025-01-12 01:41:29.826234: val_loss -0.5411 
2025-01-12 01:41:29.832281: Pseudo dice [np.float32(0.6561)] 
2025-01-12 01:41:29.836310: Epoch time: 40.18 s 
2025-01-12 01:41:30.372898:  
2025-01-12 01:41:30.373401: Epoch 213 
2025-01-12 01:41:30.378410: Current learning rate: 0.00179 
2025-01-12 01:42:10.513981: train_loss -0.6984 
2025-01-12 01:42:10.514984: val_loss -0.4756 
2025-01-12 01:42:10.520507: Pseudo dice [np.float32(0.6342)] 
2025-01-12 01:42:10.524547: Epoch time: 40.14 s 
2025-01-12 01:42:11.060006:  
2025-01-12 01:42:11.060006: Epoch 214 
2025-01-12 01:42:11.065543: Current learning rate: 0.00175 
2025-01-12 01:42:51.203538: train_loss -0.7156 
2025-01-12 01:42:51.204541: val_loss -0.4402 
2025-01-12 01:42:51.211093: Pseudo dice [np.float32(0.5956)] 
2025-01-12 01:42:51.213619: Epoch time: 40.14 s 
2025-01-12 01:42:51.743361:  
2025-01-12 01:42:51.744361: Epoch 215 
2025-01-12 01:42:51.749419: Current learning rate: 0.0017 
2025-01-12 01:43:31.881989: train_loss -0.7152 
2025-01-12 01:43:31.882491: val_loss -0.5255 
2025-01-12 01:43:31.887501: Pseudo dice [np.float32(0.6556)] 
2025-01-12 01:43:31.891014: Epoch time: 40.14 s 
2025-01-12 01:43:32.564457:  
2025-01-12 01:43:32.565461: Epoch 216 
2025-01-12 01:43:32.570009: Current learning rate: 0.00166 
2025-01-12 01:44:12.683454: train_loss -0.6978 
2025-01-12 01:44:12.683454: val_loss -0.5273 
2025-01-12 01:44:12.689970: Pseudo dice [np.float32(0.6519)] 
2025-01-12 01:44:12.692477: Epoch time: 40.12 s 
2025-01-12 01:44:13.222211:  
2025-01-12 01:44:13.222211: Epoch 217 
2025-01-12 01:44:13.228228: Current learning rate: 0.00162 
2025-01-12 01:44:53.373591: train_loss -0.7105 
2025-01-12 01:44:53.374594: val_loss -0.5129 
2025-01-12 01:44:53.380605: Pseudo dice [np.float32(0.6863)] 
2025-01-12 01:44:53.384617: Epoch time: 40.15 s 
2025-01-12 01:44:53.912888:  
2025-01-12 01:44:53.912888: Epoch 218 
2025-01-12 01:44:53.917899: Current learning rate: 0.00157 
2025-01-12 01:45:34.048543: train_loss -0.6957 
2025-01-12 01:45:34.049545: val_loss -0.5276 
2025-01-12 01:45:34.054609: Pseudo dice [np.float32(0.6749)] 
2025-01-12 01:45:34.057639: Epoch time: 40.14 s 
2025-01-12 01:45:34.593227:  
2025-01-12 01:45:34.593227: Epoch 219 
2025-01-12 01:45:34.598741: Current learning rate: 0.00153 
2025-01-12 01:46:14.726869: train_loss -0.6973 
2025-01-12 01:46:14.726869: val_loss -0.4877 
2025-01-12 01:46:14.732885: Pseudo dice [np.float32(0.6311)] 
2025-01-12 01:46:14.736404: Epoch time: 40.13 s 
2025-01-12 01:46:15.263314:  
2025-01-12 01:46:15.264314: Epoch 220 
2025-01-12 01:46:15.269382: Current learning rate: 0.00148 
2025-01-12 01:46:55.381140: train_loss -0.7158 
2025-01-12 01:46:55.382142: val_loss -0.4724 
2025-01-12 01:46:55.388154: Pseudo dice [np.float32(0.6557)] 
2025-01-12 01:46:55.391164: Epoch time: 40.12 s 
2025-01-12 01:46:55.922586:  
2025-01-12 01:46:55.923590: Epoch 221 
2025-01-12 01:46:55.928122: Current learning rate: 0.00144 
2025-01-12 01:47:36.064637: train_loss -0.6756 
2025-01-12 01:47:36.064637: val_loss -0.5538 
2025-01-12 01:47:36.071157: Pseudo dice [np.float32(0.6273)] 
2025-01-12 01:47:36.074669: Epoch time: 40.14 s 
2025-01-12 01:47:36.605895:  
2025-01-12 01:47:36.605895: Epoch 222 
2025-01-12 01:47:36.611432: Current learning rate: 0.00139 
2025-01-12 01:48:16.737707: train_loss -0.6961 
2025-01-12 01:48:16.738212: val_loss -0.5208 
2025-01-12 01:48:16.743864: Pseudo dice [np.float32(0.7097)] 
2025-01-12 01:48:16.747937: Epoch time: 40.13 s 
2025-01-12 01:48:17.280010:  
2025-01-12 01:48:17.280010: Epoch 223 
2025-01-12 01:48:17.285022: Current learning rate: 0.00135 
2025-01-12 01:48:57.407003: train_loss -0.7129 
2025-01-12 01:48:57.408006: val_loss -0.4966 
2025-01-12 01:48:57.413527: Pseudo dice [np.float32(0.6638)] 
2025-01-12 01:48:57.417041: Epoch time: 40.13 s 
2025-01-12 01:48:58.094061:  
2025-01-12 01:48:58.094061: Epoch 224 
2025-01-12 01:48:58.100179: Current learning rate: 0.0013 
2025-01-12 01:49:38.227533: train_loss -0.7005 
2025-01-12 01:49:38.227533: val_loss -0.5899 
2025-01-12 01:49:38.232638: Pseudo dice [np.float32(0.729)] 
2025-01-12 01:49:38.237200: Epoch time: 40.13 s 
2025-01-12 01:49:38.239731: Yayy! New best EMA pseudo Dice: 0.6581000089645386 
2025-01-12 01:49:39.036412:  
2025-01-12 01:49:39.036915: Epoch 225 
2025-01-12 01:49:39.041929: Current learning rate: 0.00126 
2025-01-12 01:50:19.184022: train_loss -0.7148 
2025-01-12 01:50:19.185027: val_loss -0.4596 
2025-01-12 01:50:19.190037: Pseudo dice [np.float32(0.5964)] 
2025-01-12 01:50:19.194050: Epoch time: 40.15 s 
2025-01-12 01:50:19.723142:  
2025-01-12 01:50:19.724144: Epoch 226 
2025-01-12 01:50:19.728692: Current learning rate: 0.00121 
2025-01-12 01:50:59.857300: train_loss -0.714 
2025-01-12 01:50:59.857300: val_loss -0.4446 
2025-01-12 01:50:59.863311: Pseudo dice [np.float32(0.5845)] 
2025-01-12 01:50:59.867323: Epoch time: 40.14 s 
2025-01-12 01:51:00.412440:  
2025-01-12 01:51:00.413440: Epoch 227 
2025-01-12 01:51:00.418511: Current learning rate: 0.00117 
2025-01-12 01:51:40.570761: train_loss -0.7256 
2025-01-12 01:51:40.570761: val_loss -0.5399 
2025-01-12 01:51:40.576848: Pseudo dice [np.float32(0.717)] 
2025-01-12 01:51:40.580387: Epoch time: 40.16 s 
2025-01-12 01:51:41.112947:  
2025-01-12 01:51:41.112947: Epoch 228 
2025-01-12 01:51:41.117978: Current learning rate: 0.00112 
2025-01-12 01:52:21.231340: train_loss -0.6871 
2025-01-12 01:52:21.232847: val_loss -0.5695 
2025-01-12 01:52:21.239370: Pseudo dice [np.float32(0.6913)] 
2025-01-12 01:52:21.242322: Epoch time: 40.12 s 
2025-01-12 01:52:21.782240:  
2025-01-12 01:52:21.782756: Epoch 229 
2025-01-12 01:52:21.787771: Current learning rate: 0.00108 
2025-01-12 01:53:01.941170: train_loss -0.7189 
2025-01-12 01:53:01.941170: val_loss -0.5424 
2025-01-12 01:53:01.947690: Pseudo dice [np.float32(0.6894)] 
2025-01-12 01:53:01.951202: Epoch time: 40.16 s 
2025-01-12 01:53:01.954707: Yayy! New best EMA pseudo Dice: 0.659600019454956 
2025-01-12 01:53:02.769235:  
2025-01-12 01:53:02.769235: Epoch 230 
2025-01-12 01:53:02.775347: Current learning rate: 0.00103 
2025-01-12 01:53:42.922437: train_loss -0.707 
2025-01-12 01:53:42.922437: val_loss -0.5033 
2025-01-12 01:53:42.929451: Pseudo dice [np.float32(0.672)] 
2025-01-12 01:53:42.932971: Epoch time: 40.15 s 
2025-01-12 01:53:42.935997: Yayy! New best EMA pseudo Dice: 0.6607999801635742 
2025-01-12 01:53:43.725034:  
2025-01-12 01:53:43.725537: Epoch 231 
2025-01-12 01:53:43.730070: Current learning rate: 0.00098 
2025-01-12 01:54:23.869595: train_loss -0.7121 
2025-01-12 01:54:23.869595: val_loss -0.5506 
2025-01-12 01:54:23.877120: Pseudo dice [np.float32(0.7221)] 
2025-01-12 01:54:23.880631: Epoch time: 40.15 s 
2025-01-12 01:54:23.883151: Yayy! New best EMA pseudo Dice: 0.6669999957084656 
2025-01-12 01:54:24.655675:  
2025-01-12 01:54:24.656675: Epoch 232 
2025-01-12 01:54:24.661741: Current learning rate: 0.00094 
2025-01-12 01:55:04.852326: train_loss -0.7089 
2025-01-12 01:55:04.852829: val_loss -0.5571 
2025-01-12 01:55:04.858842: Pseudo dice [np.float32(0.7037)] 
2025-01-12 01:55:04.862354: Epoch time: 40.2 s 
2025-01-12 01:55:04.865408: Yayy! New best EMA pseudo Dice: 0.6705999970436096 
2025-01-12 01:55:05.604391:  
2025-01-12 01:55:05.604391: Epoch 233 
2025-01-12 01:55:05.608997: Current learning rate: 0.00089 
2025-01-12 01:55:45.773225: train_loss -0.7034 
2025-01-12 01:55:45.773225: val_loss -0.4929 
2025-01-12 01:55:45.779239: Pseudo dice [np.float32(0.6475)] 
2025-01-12 01:55:45.782746: Epoch time: 40.17 s 
2025-01-12 01:55:46.307837:  
2025-01-12 01:55:46.307837: Epoch 234 
2025-01-12 01:55:46.311394: Current learning rate: 0.00084 
2025-01-12 01:56:26.453010: train_loss -0.7202 
2025-01-12 01:56:26.453010: val_loss -0.481 
2025-01-12 01:56:26.460532: Pseudo dice [np.float32(0.6359)] 
2025-01-12 01:56:26.464043: Epoch time: 40.14 s 
2025-01-12 01:56:26.995296:  
2025-01-12 01:56:26.995296: Epoch 235 
2025-01-12 01:56:27.001411: Current learning rate: 0.00079 
2025-01-12 01:57:07.125126: train_loss -0.7173 
2025-01-12 01:57:07.125640: val_loss -0.5411 
2025-01-12 01:57:07.130685: Pseudo dice [np.float32(0.6401)] 
2025-01-12 01:57:07.135246: Epoch time: 40.13 s 
2025-01-12 01:57:07.670794:  
2025-01-12 01:57:07.670794: Epoch 236 
2025-01-12 01:57:07.676373: Current learning rate: 0.00075 
2025-01-12 01:57:47.799300: train_loss -0.7201 
2025-01-12 01:57:47.800300: val_loss -0.5318 
2025-01-12 01:57:47.805817: Pseudo dice [np.float32(0.6587)] 
2025-01-12 01:57:47.809325: Epoch time: 40.13 s 
2025-01-12 01:57:48.341977:  
2025-01-12 01:57:48.341977: Epoch 237 
2025-01-12 01:57:48.347019: Current learning rate: 0.0007 
2025-01-12 01:58:28.521434: train_loss -0.7169 
2025-01-12 01:58:28.521434: val_loss -0.4926 
2025-01-12 01:58:28.527456: Pseudo dice [np.float32(0.7174)] 
2025-01-12 01:58:28.530960: Epoch time: 40.18 s 
2025-01-12 01:58:29.073848:  
2025-01-12 01:58:29.073848: Epoch 238 
2025-01-12 01:58:29.078925: Current learning rate: 0.00065 
2025-01-12 01:59:09.238999: train_loss -0.7198 
2025-01-12 01:59:09.239503: val_loss -0.5325 
2025-01-12 01:59:09.245525: Pseudo dice [np.float32(0.6807)] 
2025-01-12 01:59:09.249033: Epoch time: 40.17 s 
2025-01-12 01:59:09.774699:  
2025-01-12 01:59:09.775703: Epoch 239 
2025-01-12 01:59:09.780251: Current learning rate: 0.0006 
2025-01-12 01:59:49.926719: train_loss -0.7274 
2025-01-12 01:59:49.927237: val_loss -0.4418 
2025-01-12 01:59:49.932811: Pseudo dice [np.float32(0.6092)] 
2025-01-12 01:59:49.935905: Epoch time: 40.15 s 
2025-01-12 01:59:50.480471:  
2025-01-12 01:59:50.481475: Epoch 240 
2025-01-12 01:59:50.486530: Current learning rate: 0.00055 
2025-01-12 02:00:30.713172: train_loss -0.7146 
2025-01-12 02:00:30.713172: val_loss -0.5331 
2025-01-12 02:00:30.721256: Pseudo dice [np.float32(0.6925)] 
2025-01-12 02:00:30.725294: Epoch time: 40.23 s 
2025-01-12 02:00:31.261010:  
2025-01-12 02:00:31.262015: Epoch 241 
2025-01-12 02:00:31.266547: Current learning rate: 0.0005 
2025-01-12 02:01:11.407005: train_loss -0.7249 
2025-01-12 02:01:11.408007: val_loss -0.5269 
2025-01-12 02:01:11.414021: Pseudo dice [np.float32(0.6574)] 
2025-01-12 02:01:11.418032: Epoch time: 40.15 s 
2025-01-12 02:01:11.963100:  
2025-01-12 02:01:11.963602: Epoch 242 
2025-01-12 02:01:11.968612: Current learning rate: 0.00045 
2025-01-12 02:01:52.118112: train_loss -0.7196 
2025-01-12 02:01:52.118614: val_loss -0.5442 
2025-01-12 02:01:52.123625: Pseudo dice [np.float32(0.6909)] 
2025-01-12 02:01:52.128171: Epoch time: 40.16 s 
2025-01-12 02:01:52.664901:  
2025-01-12 02:01:52.665403: Epoch 243 
2025-01-12 02:01:52.670928: Current learning rate: 0.0004 
2025-01-12 02:02:32.785915: train_loss -0.7239 
2025-01-12 02:02:32.785915: val_loss -0.5264 
2025-01-12 02:02:32.793433: Pseudo dice [np.float32(0.6625)] 
2025-01-12 02:02:32.798444: Epoch time: 40.12 s 
2025-01-12 02:02:33.343491:  
2025-01-12 02:02:33.343491: Epoch 244 
2025-01-12 02:02:33.348515: Current learning rate: 0.00035 
2025-01-12 02:03:13.474147: train_loss -0.7288 
2025-01-12 02:03:13.474648: val_loss -0.3711 
2025-01-12 02:03:13.480197: Pseudo dice [np.float32(0.603)] 
2025-01-12 02:03:13.483780: Epoch time: 40.13 s 
2025-01-12 02:03:14.031532:  
2025-01-12 02:03:14.031532: Epoch 245 
2025-01-12 02:03:14.036596: Current learning rate: 0.0003 
2025-01-12 02:03:54.188128: train_loss -0.736 
2025-01-12 02:03:54.188128: val_loss -0.5695 
2025-01-12 02:03:54.194650: Pseudo dice [np.float32(0.679)] 
2025-01-12 02:03:54.198158: Epoch time: 40.16 s 
2025-01-12 02:03:54.735022:  
2025-01-12 02:03:54.735022: Epoch 246 
2025-01-12 02:03:54.740562: Current learning rate: 0.00024 
2025-01-12 02:04:34.914316: train_loss -0.7198 
2025-01-12 02:04:34.915316: val_loss -0.5373 
2025-01-12 02:04:34.920832: Pseudo dice [np.float32(0.691)] 
2025-01-12 02:04:34.925346: Epoch time: 40.18 s 
2025-01-12 02:04:35.468384:  
2025-01-12 02:04:35.469388: Epoch 247 
2025-01-12 02:04:35.474420: Current learning rate: 0.00019 
2025-01-12 02:05:15.609627: train_loss -0.7183 
2025-01-12 02:05:15.610627: val_loss -0.6001 
2025-01-12 02:05:15.616145: Pseudo dice [np.float32(0.7231)] 
2025-01-12 02:05:15.618685: Epoch time: 40.14 s 
2025-01-12 02:05:15.621722: Yayy! New best EMA pseudo Dice: 0.6711999773979187 
2025-01-12 02:05:16.563050:  
2025-01-12 02:05:16.564056: Epoch 248 
2025-01-12 02:05:16.568620: Current learning rate: 0.00013 
2025-01-12 02:05:56.688860: train_loss -0.7265 
2025-01-12 02:05:56.688860: val_loss -0.5715 
2025-01-12 02:05:56.696382: Pseudo dice [np.float32(0.6437)] 
2025-01-12 02:05:56.698887: Epoch time: 40.13 s 
2025-01-12 02:05:57.238421:  
2025-01-12 02:05:57.239426: Epoch 249 
2025-01-12 02:05:57.243972: Current learning rate: 7e-05 
2025-01-12 02:06:37.386858: train_loss -0.7372 
2025-01-12 02:06:37.386858: val_loss -0.5623 
2025-01-12 02:06:37.393377: Pseudo dice [np.float32(0.6573)] 
2025-01-12 02:06:37.396885: Epoch time: 40.15 s 
2025-01-12 02:06:38.144163: Training done. 
2025-01-12 02:06:38.171671: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-12 02:06:38.177671: The split file contains 5 splits. 
2025-01-12 02:06:38.182672: Desired fold for training: 0 
2025-01-12 02:06:38.186670: This split has 100 training and 26 validation cases. 
2025-01-12 02:06:38.190671: predicting colon_008 
2025-01-12 02:06:38.196671: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-01-12 02:06:52.632757: predicting colon_027 
2025-01-12 02:06:52.650758: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-01-12 02:06:58.710215: predicting colon_030 
2025-01-12 02:06:58.718215: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-01-12 02:07:07.722076: predicting colon_033 
2025-01-12 02:07:07.734076: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-01-12 02:07:23.825974: predicting colon_041 
2025-01-12 02:07:23.845973: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-01-12 02:07:55.333950: predicting colon_042 
2025-01-12 02:07:55.364949: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-01-12 02:08:11.113339: predicting colon_061 
2025-01-12 02:08:11.133339: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-01-12 02:08:31.397499: predicting colon_074 
2025-01-12 02:08:31.418500: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-01-12 02:08:55.035085: predicting colon_075 
2025-01-12 02:08:55.060589: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-01-12 02:09:09.124594: predicting colon_088 
2025-01-12 02:09:09.141597: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-01-12 02:09:36.686961: predicting colon_091 
2025-01-12 02:09:36.712961: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-01-12 02:09:59.850289: predicting colon_092 
2025-01-12 02:09:59.876293: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-01-12 02:10:20.109419: predicting colon_095 
2025-01-12 02:10:20.129420: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-01-12 02:10:34.228949: predicting colon_102 
2025-01-12 02:10:34.245947: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-01-12 02:11:01.833444: predicting colon_111 
2025-01-12 02:11:01.861442: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-01-12 02:11:10.588923: predicting colon_115 
2025-01-12 02:11:10.601923: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-01-12 02:11:26.666809: predicting colon_118 
2025-01-12 02:11:26.685808: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-01-12 02:11:49.863636: predicting colon_124 
2025-01-12 02:11:49.884637: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-01-12 02:12:10.124772: predicting colon_127 
2025-01-12 02:12:10.147773: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-01-12 02:12:49.536339: predicting colon_154 
2025-01-12 02:12:49.576340: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-01-12 02:13:03.741817: predicting colon_161 
2025-01-12 02:13:03.761817: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-01-12 02:13:17.884056: predicting colon_162 
2025-01-12 02:13:17.903059: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-01-12 02:13:49.363667: predicting colon_165 
2025-01-12 02:13:49.394665: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-01-12 02:14:16.941249: predicting colon_166 
2025-01-12 02:14:16.965756: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-01-12 02:14:31.080836: predicting colon_169 
2025-01-12 02:14:31.099836: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-01-12 02:15:10.424638: predicting colon_187 
2025-01-12 02:15:10.466638: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-01-12 02:15:39.924566: Validation complete 
2025-01-12 02:15:39.925566: Mean Validation Dice:  0.40746159660244236 
