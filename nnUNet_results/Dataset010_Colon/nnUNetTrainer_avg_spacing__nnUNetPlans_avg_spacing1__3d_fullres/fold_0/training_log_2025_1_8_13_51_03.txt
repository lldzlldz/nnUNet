
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-08 13:51:03.258401: do_dummy_2d_data_aug: False 
2025-01-08 13:51:03.283425: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-08 13:51:03.289730: The split file contains 5 splits. 
2025-01-08 13:51:03.292731: Desired fold for training: 0 
2025-01-08 13:51:03.294730: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_avg_spacing1_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [450.0, 400.0, 400.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans_avg_spacing1', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-01-08 13:51:10.859317: unpacking dataset... 
2025-01-08 13:51:11.133608: unpacking done... 
2025-01-08 13:51:14.037180:  
2025-01-08 13:51:14.037180: Epoch 0 
2025-01-08 13:51:14.042191: Current learning rate: 0.01 
2025-01-08 13:51:54.275911: train_loss 0.022 
2025-01-08 13:51:54.276414: val_loss -0.0462 
2025-01-08 13:51:54.282074: Pseudo dice [np.float32(0.0)] 
2025-01-08 13:51:54.285102: Epoch time: 40.24 s 
2025-01-08 13:51:54.287608: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-08 13:51:55.014698:  
2025-01-08 13:51:55.014698: Epoch 1 
2025-01-08 13:51:55.019750: Current learning rate: 0.00991 
2025-01-08 13:52:31.413862: train_loss -0.1604 
2025-01-08 13:52:31.414381: val_loss -0.2207 
2025-01-08 13:52:31.419908: Pseudo dice [np.float32(0.2852)] 
2025-01-08 13:52:31.422412: Epoch time: 36.4 s 
2025-01-08 13:52:31.426419: Yayy! New best EMA pseudo Dice: 0.02850000001490116 
2025-01-08 13:52:32.187380:  
2025-01-08 13:52:32.187882: Epoch 2 
2025-01-08 13:52:32.191392: Current learning rate: 0.00982 
2025-01-08 13:53:08.594566: train_loss -0.2566 
2025-01-08 13:53:08.595569: val_loss -0.2994 
2025-01-08 13:53:08.600581: Pseudo dice [np.float32(0.4066)] 
2025-01-08 13:53:08.603086: Epoch time: 36.41 s 
2025-01-08 13:53:08.606592: Yayy! New best EMA pseudo Dice: 0.06629999727010727 
2025-01-08 13:53:09.415435:  
2025-01-08 13:53:09.415937: Epoch 3 
2025-01-08 13:53:09.419446: Current learning rate: 0.00973 
2025-01-08 13:53:45.816761: train_loss -0.3084 
2025-01-08 13:53:45.817271: val_loss -0.3894 
2025-01-08 13:53:45.823368: Pseudo dice [np.float32(0.4778)] 
2025-01-08 13:53:45.825909: Epoch time: 36.4 s 
2025-01-08 13:53:45.828962: Yayy! New best EMA pseudo Dice: 0.10750000178813934 
2025-01-08 13:53:46.652050:  
2025-01-08 13:53:46.652552: Epoch 4 
2025-01-08 13:53:46.657595: Current learning rate: 0.00964 
2025-01-08 13:54:23.011261: train_loss -0.355 
2025-01-08 13:54:23.011769: val_loss -0.3383 
2025-01-08 13:54:23.016811: Pseudo dice [np.float32(0.4271)] 
2025-01-08 13:54:23.019332: Epoch time: 36.36 s 
2025-01-08 13:54:23.022856: Yayy! New best EMA pseudo Dice: 0.13940000534057617 
2025-01-08 13:54:23.939795:  
2025-01-08 13:54:23.940797: Epoch 5 
2025-01-08 13:54:23.945807: Current learning rate: 0.00955 
2025-01-08 13:55:00.322931: train_loss -0.364 
2025-01-08 13:55:00.323434: val_loss -0.3787 
2025-01-08 13:55:00.328541: Pseudo dice [np.float32(0.4429)] 
2025-01-08 13:55:00.331579: Epoch time: 36.38 s 
2025-01-08 13:55:00.334635: Yayy! New best EMA pseudo Dice: 0.16979999840259552 
2025-01-08 13:55:01.135175:  
2025-01-08 13:55:01.136175: Epoch 6 
2025-01-08 13:55:01.139214: Current learning rate: 0.00946 
2025-01-08 13:55:37.486342: train_loss -0.3769 
2025-01-08 13:55:37.486342: val_loss -0.322 
2025-01-08 13:55:37.492399: Pseudo dice [np.float32(0.3611)] 
2025-01-08 13:55:37.495929: Epoch time: 36.35 s 
2025-01-08 13:55:37.498977: Yayy! New best EMA pseudo Dice: 0.18889999389648438 
2025-01-08 13:55:38.287690:  
2025-01-08 13:55:38.288697: Epoch 7 
2025-01-08 13:55:38.292218: Current learning rate: 0.00937 
2025-01-08 13:56:14.640727: train_loss -0.3951 
2025-01-08 13:56:14.641230: val_loss -0.3287 
2025-01-08 13:56:14.646241: Pseudo dice [np.float32(0.4551)] 
2025-01-08 13:56:14.649751: Epoch time: 36.35 s 
2025-01-08 13:56:14.652259: Yayy! New best EMA pseudo Dice: 0.21549999713897705 
2025-01-08 13:56:15.465405:  
2025-01-08 13:56:15.465909: Epoch 8 
2025-01-08 13:56:15.470951: Current learning rate: 0.00928 
2025-01-08 13:56:51.851204: train_loss -0.4008 
2025-01-08 13:56:51.851204: val_loss -0.3993 
2025-01-08 13:56:51.857216: Pseudo dice [np.float32(0.4728)] 
2025-01-08 13:56:51.860224: Epoch time: 36.39 s 
2025-01-08 13:56:51.863732: Yayy! New best EMA pseudo Dice: 0.24130000174045563 
2025-01-08 13:56:52.697138:  
2025-01-08 13:56:52.698645: Epoch 9 
2025-01-08 13:56:52.703663: Current learning rate: 0.00919 
2025-01-08 13:57:29.052979: train_loss -0.4048 
2025-01-08 13:57:29.053495: val_loss -0.3748 
2025-01-08 13:57:29.058568: Pseudo dice [np.float32(0.4671)] 
2025-01-08 13:57:29.061106: Epoch time: 36.36 s 
2025-01-08 13:57:29.065202: Yayy! New best EMA pseudo Dice: 0.2637999951839447 
2025-01-08 13:57:29.869795:  
2025-01-08 13:57:29.870795: Epoch 10 
2025-01-08 13:57:29.876308: Current learning rate: 0.0091 
2025-01-08 13:58:06.227318: train_loss -0.419 
2025-01-08 13:58:06.228322: val_loss -0.3599 
2025-01-08 13:58:06.234331: Pseudo dice [np.float32(0.4606)] 
2025-01-08 13:58:06.237338: Epoch time: 36.36 s 
2025-01-08 13:58:06.239843: Yayy! New best EMA pseudo Dice: 0.28349998593330383 
2025-01-08 13:58:07.043171:  
2025-01-08 13:58:07.043171: Epoch 11 
2025-01-08 13:58:07.049205: Current learning rate: 0.009 
2025-01-08 13:58:43.478488: train_loss -0.4098 
2025-01-08 13:58:43.479491: val_loss -0.3371 
2025-01-08 13:58:43.485132: Pseudo dice [np.float32(0.4346)] 
2025-01-08 13:58:43.487717: Epoch time: 36.44 s 
2025-01-08 13:58:43.492267: Yayy! New best EMA pseudo Dice: 0.2985999882221222 
2025-01-08 13:58:44.288263:  
2025-01-08 13:58:44.288263: Epoch 12 
2025-01-08 13:58:44.293307: Current learning rate: 0.00891 
2025-01-08 13:59:20.735788: train_loss -0.3967 
2025-01-08 13:59:20.736290: val_loss -0.4497 
2025-01-08 13:59:20.741300: Pseudo dice [np.float32(0.5215)] 
2025-01-08 13:59:20.744808: Epoch time: 36.45 s 
2025-01-08 13:59:20.747313: Yayy! New best EMA pseudo Dice: 0.32089999318122864 
2025-01-08 13:59:21.686740:  
2025-01-08 13:59:21.687744: Epoch 13 
2025-01-08 13:59:21.693259: Current learning rate: 0.00882 
2025-01-08 13:59:58.032726: train_loss -0.453 
2025-01-08 13:59:58.033725: val_loss -0.3845 
2025-01-08 13:59:58.039239: Pseudo dice [np.float32(0.4307)] 
2025-01-08 13:59:58.041744: Epoch time: 36.35 s 
2025-01-08 13:59:58.045252: Yayy! New best EMA pseudo Dice: 0.3319000005722046 
2025-01-08 13:59:58.867228:  
2025-01-08 13:59:58.868228: Epoch 14 
2025-01-08 13:59:58.873349: Current learning rate: 0.00873 
2025-01-08 14:00:35.207504: train_loss -0.4403 
2025-01-08 14:00:35.208024: val_loss -0.4447 
2025-01-08 14:00:35.213101: Pseudo dice [np.float32(0.5001)] 
2025-01-08 14:00:35.217147: Epoch time: 36.34 s 
2025-01-08 14:00:35.220185: Yayy! New best EMA pseudo Dice: 0.34869998693466187 
2025-01-08 14:00:36.029139:  
2025-01-08 14:00:36.029139: Epoch 15 
2025-01-08 14:00:36.034151: Current learning rate: 0.00864 
2025-01-08 14:01:12.408763: train_loss -0.469 
2025-01-08 14:01:12.409266: val_loss -0.4341 
2025-01-08 14:01:12.414801: Pseudo dice [np.float32(0.5149)] 
2025-01-08 14:01:12.418319: Epoch time: 36.38 s 
2025-01-08 14:01:12.420834: Yayy! New best EMA pseudo Dice: 0.3652999997138977 
2025-01-08 14:01:13.225403:  
2025-01-08 14:01:13.226406: Epoch 16 
2025-01-08 14:01:13.231472: Current learning rate: 0.00855 
2025-01-08 14:01:49.600193: train_loss -0.4591 
2025-01-08 14:01:49.601196: val_loss -0.4426 
2025-01-08 14:01:49.607719: Pseudo dice [np.float32(0.5342)] 
2025-01-08 14:01:49.610228: Epoch time: 36.37 s 
2025-01-08 14:01:49.614246: Yayy! New best EMA pseudo Dice: 0.3822000026702881 
2025-01-08 14:01:50.404900:  
2025-01-08 14:01:50.404900: Epoch 17 
2025-01-08 14:01:50.410936: Current learning rate: 0.00846 
2025-01-08 14:02:26.752359: train_loss -0.4684 
2025-01-08 14:02:26.752359: val_loss -0.4054 
2025-01-08 14:02:26.758371: Pseudo dice [np.float32(0.4876)] 
2025-01-08 14:02:26.762382: Epoch time: 36.35 s 
2025-01-08 14:02:26.764887: Yayy! New best EMA pseudo Dice: 0.3928000032901764 
2025-01-08 14:02:27.571556:  
2025-01-08 14:02:27.571556: Epoch 18 
2025-01-08 14:02:27.577112: Current learning rate: 0.00836 
2025-01-08 14:03:03.958063: train_loss -0.4471 
2025-01-08 14:03:03.958063: val_loss -0.3755 
2025-01-08 14:03:03.964610: Pseudo dice [np.float32(0.4661)] 
2025-01-08 14:03:03.967640: Epoch time: 36.39 s 
2025-01-08 14:03:03.970667: Yayy! New best EMA pseudo Dice: 0.4000999927520752 
2025-01-08 14:03:04.809954:  
2025-01-08 14:03:04.809954: Epoch 19 
2025-01-08 14:03:04.815507: Current learning rate: 0.00827 
2025-01-08 14:03:41.152468: train_loss -0.4515 
2025-01-08 14:03:41.152974: val_loss -0.4015 
2025-01-08 14:03:41.158600: Pseudo dice [np.float32(0.5212)] 
2025-01-08 14:03:41.161106: Epoch time: 36.34 s 
2025-01-08 14:03:41.164614: Yayy! New best EMA pseudo Dice: 0.412200003862381 
2025-01-08 14:03:41.979466:  
2025-01-08 14:03:41.979466: Epoch 20 
2025-01-08 14:03:41.985489: Current learning rate: 0.00818 
2025-01-08 14:04:18.469431: train_loss -0.4267 
2025-01-08 14:04:18.469431: val_loss -0.3597 
2025-01-08 14:04:18.474451: Pseudo dice [np.float32(0.4742)] 
2025-01-08 14:04:18.478470: Epoch time: 36.49 s 
2025-01-08 14:04:18.480978: Yayy! New best EMA pseudo Dice: 0.41839998960494995 
2025-01-08 14:04:19.359190:  
2025-01-08 14:04:19.359190: Epoch 21 
2025-01-08 14:04:19.365288: Current learning rate: 0.00809 
2025-01-08 14:04:55.754869: train_loss -0.5065 
2025-01-08 14:04:55.754869: val_loss -0.4623 
2025-01-08 14:04:55.761000: Pseudo dice [np.float32(0.5119)] 
2025-01-08 14:04:55.764530: Epoch time: 36.4 s 
2025-01-08 14:04:55.767575: Yayy! New best EMA pseudo Dice: 0.427700012922287 
2025-01-08 14:04:56.637881:  
2025-01-08 14:04:56.638384: Epoch 22 
2025-01-08 14:04:56.643416: Current learning rate: 0.008 
2025-01-08 14:05:33.126671: train_loss -0.5136 
2025-01-08 14:05:33.128182: val_loss -0.411 
2025-01-08 14:05:33.134098: Pseudo dice [np.float32(0.4808)] 
2025-01-08 14:05:33.137127: Epoch time: 36.49 s 
2025-01-08 14:05:33.140635: Yayy! New best EMA pseudo Dice: 0.43309998512268066 
2025-01-08 14:05:33.951190:  
2025-01-08 14:05:33.951190: Epoch 23 
2025-01-08 14:05:33.957227: Current learning rate: 0.0079 
2025-01-08 14:06:10.350373: train_loss -0.4975 
2025-01-08 14:06:10.351376: val_loss -0.3919 
2025-01-08 14:06:10.356986: Pseudo dice [np.float32(0.4472)] 
2025-01-08 14:06:10.360516: Epoch time: 36.4 s 
2025-01-08 14:06:10.362547: Yayy! New best EMA pseudo Dice: 0.4345000088214874 
2025-01-08 14:06:11.173435:  
2025-01-08 14:06:11.174438: Epoch 24 
2025-01-08 14:06:11.180527: Current learning rate: 0.00781 
2025-01-08 14:06:47.539079: train_loss -0.5066 
2025-01-08 14:06:47.540164: val_loss -0.3841 
2025-01-08 14:06:47.545784: Pseudo dice [np.float32(0.4677)] 
2025-01-08 14:06:47.548829: Epoch time: 36.37 s 
2025-01-08 14:06:47.551869: Yayy! New best EMA pseudo Dice: 0.43779999017715454 
2025-01-08 14:06:48.369127:  
2025-01-08 14:06:48.369635: Epoch 25 
2025-01-08 14:06:48.374672: Current learning rate: 0.00772 
2025-01-08 14:07:24.774405: train_loss -0.5094 
2025-01-08 14:07:24.775407: val_loss -0.3509 
2025-01-08 14:07:24.780445: Pseudo dice [np.float32(0.4493)] 
2025-01-08 14:07:24.784589: Epoch time: 36.41 s 
2025-01-08 14:07:24.787094: Yayy! New best EMA pseudo Dice: 0.4388999938964844 
2025-01-08 14:07:25.606450:  
2025-01-08 14:07:25.606450: Epoch 26 
2025-01-08 14:07:25.611986: Current learning rate: 0.00763 
2025-01-08 14:08:01.978213: train_loss -0.5361 
2025-01-08 14:08:01.978213: val_loss -0.4013 
2025-01-08 14:08:01.984736: Pseudo dice [np.float32(0.495)] 
2025-01-08 14:08:01.986742: Epoch time: 36.37 s 
2025-01-08 14:08:01.990956: Yayy! New best EMA pseudo Dice: 0.444599986076355 
2025-01-08 14:08:02.762090:  
2025-01-08 14:08:02.762593: Epoch 27 
2025-01-08 14:08:02.767606: Current learning rate: 0.00753 
2025-01-08 14:08:39.165164: train_loss -0.5402 
2025-01-08 14:08:39.165671: val_loss -0.4566 
2025-01-08 14:08:39.171220: Pseudo dice [np.float32(0.559)] 
2025-01-08 14:08:39.174749: Epoch time: 36.4 s 
2025-01-08 14:08:39.177264: Yayy! New best EMA pseudo Dice: 0.4560000002384186 
2025-01-08 14:08:40.147619:  
2025-01-08 14:08:40.148622: Epoch 28 
2025-01-08 14:08:40.153206: Current learning rate: 0.00744 
2025-01-08 14:09:16.514659: train_loss -0.5444 
2025-01-08 14:09:16.515161: val_loss -0.4944 
2025-01-08 14:09:16.520172: Pseudo dice [np.float32(0.5688)] 
2025-01-08 14:09:16.523680: Epoch time: 36.37 s 
2025-01-08 14:09:16.527215: Yayy! New best EMA pseudo Dice: 0.4672999978065491 
2025-01-08 14:09:17.330145:  
2025-01-08 14:09:17.330145: Epoch 29 
2025-01-08 14:09:17.335156: Current learning rate: 0.00735 
2025-01-08 14:09:53.666122: train_loss -0.5157 
2025-01-08 14:09:53.666625: val_loss -0.4771 
2025-01-08 14:09:53.672638: Pseudo dice [np.float32(0.5344)] 
2025-01-08 14:09:53.676143: Epoch time: 36.34 s 
2025-01-08 14:09:53.679189: Yayy! New best EMA pseudo Dice: 0.4740000069141388 
2025-01-08 14:09:54.502733:  
2025-01-08 14:09:54.503736: Epoch 30 
2025-01-08 14:09:54.508286: Current learning rate: 0.00725 
2025-01-08 14:10:30.877430: train_loss -0.4904 
2025-01-08 14:10:30.877936: val_loss -0.4389 
2025-01-08 14:10:30.884017: Pseudo dice [np.float32(0.528)] 
2025-01-08 14:10:30.887040: Epoch time: 36.37 s 
2025-01-08 14:10:30.890548: Yayy! New best EMA pseudo Dice: 0.47940000891685486 
2025-01-08 14:10:31.667330:  
2025-01-08 14:10:31.668329: Epoch 31 
2025-01-08 14:10:31.671370: Current learning rate: 0.00716 
2025-01-08 14:11:08.026420: train_loss -0.5098 
2025-01-08 14:11:08.026923: val_loss -0.4558 
2025-01-08 14:11:08.032520: Pseudo dice [np.float32(0.5146)] 
2025-01-08 14:11:08.035614: Epoch time: 36.36 s 
2025-01-08 14:11:08.039123: Yayy! New best EMA pseudo Dice: 0.4828999936580658 
2025-01-08 14:11:08.824212:  
2025-01-08 14:11:08.824714: Epoch 32 
2025-01-08 14:11:08.829725: Current learning rate: 0.00707 
2025-01-08 14:11:45.224878: train_loss -0.5206 
2025-01-08 14:11:45.224878: val_loss -0.4422 
2025-01-08 14:11:45.230891: Pseudo dice [np.float32(0.5165)] 
2025-01-08 14:11:45.233396: Epoch time: 36.4 s 
2025-01-08 14:11:45.236900: Yayy! New best EMA pseudo Dice: 0.486299991607666 
2025-01-08 14:11:46.058806:  
2025-01-08 14:11:46.058806: Epoch 33 
2025-01-08 14:11:46.064848: Current learning rate: 0.00697 
2025-01-08 14:12:22.432565: train_loss -0.5425 
2025-01-08 14:12:22.432565: val_loss -0.4742 
2025-01-08 14:12:22.438579: Pseudo dice [np.float32(0.5663)] 
2025-01-08 14:12:22.442586: Epoch time: 36.37 s 
2025-01-08 14:12:22.445091: Yayy! New best EMA pseudo Dice: 0.4943000078201294 
2025-01-08 14:12:23.268336:  
2025-01-08 14:12:23.268336: Epoch 34 
2025-01-08 14:12:23.273874: Current learning rate: 0.00688 
2025-01-08 14:12:59.695972: train_loss -0.5455 
2025-01-08 14:12:59.695972: val_loss -0.4506 
2025-01-08 14:12:59.700544: Pseudo dice [np.float32(0.525)] 
2025-01-08 14:12:59.704590: Epoch time: 36.43 s 
2025-01-08 14:12:59.707604: Yayy! New best EMA pseudo Dice: 0.49729999899864197 
2025-01-08 14:13:00.529742:  
2025-01-08 14:13:00.529742: Epoch 35 
2025-01-08 14:13:00.535277: Current learning rate: 0.00679 
2025-01-08 14:13:36.940102: train_loss -0.5594 
2025-01-08 14:13:36.940102: val_loss -0.4343 
2025-01-08 14:13:36.946275: Pseudo dice [np.float32(0.5302)] 
2025-01-08 14:13:36.949784: Epoch time: 36.41 s 
2025-01-08 14:13:36.952290: Yayy! New best EMA pseudo Dice: 0.5005999803543091 
2025-01-08 14:13:37.949104:  
2025-01-08 14:13:37.949104: Epoch 36 
2025-01-08 14:13:37.955146: Current learning rate: 0.00669 
2025-01-08 14:14:14.335562: train_loss -0.518 
2025-01-08 14:14:14.336565: val_loss -0.3994 
2025-01-08 14:14:14.342576: Pseudo dice [np.float32(0.485)] 
2025-01-08 14:14:14.345583: Epoch time: 36.39 s 
2025-01-08 14:14:14.947443:  
2025-01-08 14:14:14.948443: Epoch 37 
2025-01-08 14:14:14.954068: Current learning rate: 0.0066 
2025-01-08 14:14:51.329942: train_loss -0.5404 
2025-01-08 14:14:51.329942: val_loss -0.4885 
2025-01-08 14:14:51.336350: Pseudo dice [np.float32(0.5557)] 
2025-01-08 14:14:51.340360: Epoch time: 36.38 s 
2025-01-08 14:14:51.342865: Yayy! New best EMA pseudo Dice: 0.5047000050544739 
2025-01-08 14:14:52.136335:  
2025-01-08 14:14:52.137338: Epoch 38 
2025-01-08 14:14:52.141868: Current learning rate: 0.0065 
2025-01-08 14:15:28.516929: train_loss -0.5384 
2025-01-08 14:15:28.517932: val_loss -0.5007 
2025-01-08 14:15:28.523445: Pseudo dice [np.float32(0.6103)] 
2025-01-08 14:15:28.526458: Epoch time: 36.38 s 
2025-01-08 14:15:28.529489: Yayy! New best EMA pseudo Dice: 0.5152999758720398 
2025-01-08 14:15:29.344034:  
2025-01-08 14:15:29.344034: Epoch 39 
2025-01-08 14:15:29.350107: Current learning rate: 0.00641 
2025-01-08 14:16:05.714824: train_loss -0.5392 
2025-01-08 14:16:05.716325: val_loss -0.434 
2025-01-08 14:16:05.721337: Pseudo dice [np.float32(0.4979)] 
2025-01-08 14:16:05.724848: Epoch time: 36.37 s 
2025-01-08 14:16:06.333326:  
2025-01-08 14:16:06.333326: Epoch 40 
2025-01-08 14:16:06.337358: Current learning rate: 0.00631 
2025-01-08 14:16:42.727147: train_loss -0.5974 
2025-01-08 14:16:42.727655: val_loss -0.4873 
2025-01-08 14:16:42.732665: Pseudo dice [np.float32(0.5364)] 
2025-01-08 14:16:42.736173: Epoch time: 36.39 s 
2025-01-08 14:16:42.738679: Yayy! New best EMA pseudo Dice: 0.5157999992370605 
2025-01-08 14:16:43.590583:  
2025-01-08 14:16:43.591085: Epoch 41 
2025-01-08 14:16:43.596099: Current learning rate: 0.00622 
2025-01-08 14:17:20.028337: train_loss -0.5211 
2025-01-08 14:17:20.028337: val_loss -0.4469 
2025-01-08 14:17:20.034352: Pseudo dice [np.float32(0.5245)] 
2025-01-08 14:17:20.037857: Epoch time: 36.44 s 
2025-01-08 14:17:20.040864: Yayy! New best EMA pseudo Dice: 0.516700029373169 
2025-01-08 14:17:20.814798:  
2025-01-08 14:17:20.815301: Epoch 42 
2025-01-08 14:17:20.820324: Current learning rate: 0.00612 
2025-01-08 14:17:57.274417: train_loss -0.5107 
2025-01-08 14:17:57.274920: val_loss -0.4796 
2025-01-08 14:17:57.280935: Pseudo dice [np.float32(0.5721)] 
2025-01-08 14:17:57.283440: Epoch time: 36.46 s 
2025-01-08 14:17:57.286944: Yayy! New best EMA pseudo Dice: 0.5221999883651733 
2025-01-08 14:17:58.094236:  
2025-01-08 14:17:58.095240: Epoch 43 
2025-01-08 14:17:58.099799: Current learning rate: 0.00603 
2025-01-08 14:18:34.511185: train_loss -0.557 
2025-01-08 14:18:34.512188: val_loss -0.4647 
2025-01-08 14:18:34.518202: Pseudo dice [np.float32(0.5062)] 
2025-01-08 14:18:34.521211: Epoch time: 36.42 s 
2025-01-08 14:18:35.256764:  
2025-01-08 14:18:35.256764: Epoch 44 
2025-01-08 14:18:35.262778: Current learning rate: 0.00593 
2025-01-08 14:19:11.631984: train_loss -0.5601 
2025-01-08 14:19:11.631984: val_loss -0.4378 
2025-01-08 14:19:11.637998: Pseudo dice [np.float32(0.537)] 
2025-01-08 14:19:11.640503: Epoch time: 36.38 s 
2025-01-08 14:19:11.644008: Yayy! New best EMA pseudo Dice: 0.5223000049591064 
2025-01-08 14:19:12.512525:  
2025-01-08 14:19:12.513028: Epoch 45 
2025-01-08 14:19:12.518038: Current learning rate: 0.00584 
2025-01-08 14:19:48.877499: train_loss -0.5492 
2025-01-08 14:19:48.878005: val_loss -0.4137 
2025-01-08 14:19:48.882744: Pseudo dice [np.float32(0.5219)] 
2025-01-08 14:19:48.886129: Epoch time: 36.37 s 
2025-01-08 14:19:49.465233:  
2025-01-08 14:19:49.466236: Epoch 46 
2025-01-08 14:19:49.470789: Current learning rate: 0.00574 
2025-01-08 14:20:25.845040: train_loss -0.5415 
2025-01-08 14:20:25.845040: val_loss -0.4375 
2025-01-08 14:20:25.851050: Pseudo dice [np.float32(0.5434)] 
2025-01-08 14:20:25.854061: Epoch time: 36.38 s 
2025-01-08 14:20:25.857570: Yayy! New best EMA pseudo Dice: 0.524399995803833 
2025-01-08 14:20:26.668932:  
2025-01-08 14:20:26.669434: Epoch 47 
2025-01-08 14:20:26.674446: Current learning rate: 0.00565 
2025-01-08 14:21:03.061253: train_loss -0.5562 
2025-01-08 14:21:03.061765: val_loss -0.4637 
2025-01-08 14:21:03.067430: Pseudo dice [np.float32(0.5253)] 
2025-01-08 14:21:03.069965: Epoch time: 36.39 s 
2025-01-08 14:21:03.074063: Yayy! New best EMA pseudo Dice: 0.5245000123977661 
2025-01-08 14:21:03.836154:  
2025-01-08 14:21:03.837657: Epoch 48 
2025-01-08 14:21:03.842668: Current learning rate: 0.00555 
2025-01-08 14:21:40.224614: train_loss -0.5825 
2025-01-08 14:21:40.225116: val_loss -0.4435 
2025-01-08 14:21:40.230127: Pseudo dice [np.float32(0.527)] 
2025-01-08 14:21:40.233639: Epoch time: 36.39 s 
2025-01-08 14:21:40.236145: Yayy! New best EMA pseudo Dice: 0.5246999859809875 
2025-01-08 14:21:41.028858:  
2025-01-08 14:21:41.029360: Epoch 49 
2025-01-08 14:21:41.034371: Current learning rate: 0.00546 
2025-01-08 14:22:17.404073: train_loss -0.5892 
2025-01-08 14:22:17.404589: val_loss -0.5213 
2025-01-08 14:22:17.409681: Pseudo dice [np.float32(0.5787)] 
2025-01-08 14:22:17.412737: Epoch time: 36.38 s 
2025-01-08 14:22:17.584772: Yayy! New best EMA pseudo Dice: 0.5300999879837036 
2025-01-08 14:22:18.517367:  
2025-01-08 14:22:18.518371: Epoch 50 
2025-01-08 14:22:18.522941: Current learning rate: 0.00536 
2025-01-08 14:22:54.926665: train_loss -0.5943 
2025-01-08 14:22:54.927172: val_loss -0.4078 
2025-01-08 14:22:54.933120: Pseudo dice [np.float32(0.5155)] 
2025-01-08 14:22:54.935625: Epoch time: 36.41 s 
2025-01-08 14:22:55.677001:  
2025-01-08 14:22:55.678005: Epoch 51 
2025-01-08 14:22:55.683070: Current learning rate: 0.00526 
2025-01-08 14:23:32.040776: train_loss -0.5884 
2025-01-08 14:23:32.041291: val_loss -0.5594 
2025-01-08 14:23:32.048414: Pseudo dice [np.float32(0.6345)] 
2025-01-08 14:23:32.051445: Epoch time: 36.36 s 
2025-01-08 14:23:32.054974: Yayy! New best EMA pseudo Dice: 0.5392000079154968 
2025-01-08 14:23:32.859889:  
2025-01-08 14:23:32.860893: Epoch 52 
2025-01-08 14:23:32.865943: Current learning rate: 0.00517 
2025-01-08 14:24:09.216151: train_loss -0.5573 
2025-01-08 14:24:09.217154: val_loss -0.4246 
2025-01-08 14:24:09.222704: Pseudo dice [np.float32(0.4811)] 
2025-01-08 14:24:09.225738: Epoch time: 36.36 s 
2025-01-08 14:24:09.800807:  
2025-01-08 14:24:09.801310: Epoch 53 
2025-01-08 14:24:09.804822: Current learning rate: 0.00507 
2025-01-08 14:24:46.203060: train_loss -0.5962 
2025-01-08 14:24:46.204647: val_loss -0.5328 
2025-01-08 14:24:46.210784: Pseudo dice [np.float32(0.6222)] 
2025-01-08 14:24:46.213834: Epoch time: 36.4 s 
2025-01-08 14:24:46.216362: Yayy! New best EMA pseudo Dice: 0.5422999858856201 
2025-01-08 14:24:47.049059:  
2025-01-08 14:24:47.049562: Epoch 54 
2025-01-08 14:24:47.053612: Current learning rate: 0.00497 
2025-01-08 14:25:23.454259: train_loss -0.5691 
2025-01-08 14:25:23.454772: val_loss -0.5203 
2025-01-08 14:25:23.460340: Pseudo dice [np.float32(0.6338)] 
2025-01-08 14:25:23.463374: Epoch time: 36.41 s 
2025-01-08 14:25:23.466418: Yayy! New best EMA pseudo Dice: 0.5514000058174133 
2025-01-08 14:25:24.287490:  
2025-01-08 14:25:24.287490: Epoch 55 
2025-01-08 14:25:24.293562: Current learning rate: 0.00487 
2025-01-08 14:26:00.657043: train_loss -0.5938 
2025-01-08 14:26:00.658043: val_loss -0.4745 
2025-01-08 14:26:00.663557: Pseudo dice [np.float32(0.5583)] 
2025-01-08 14:26:00.667068: Epoch time: 36.37 s 
2025-01-08 14:26:00.669089: Yayy! New best EMA pseudo Dice: 0.5521000027656555 
2025-01-08 14:26:01.444656:  
2025-01-08 14:26:01.444656: Epoch 56 
2025-01-08 14:26:01.450680: Current learning rate: 0.00478 
2025-01-08 14:26:37.820273: train_loss -0.5621 
2025-01-08 14:26:37.821777: val_loss -0.5422 
2025-01-08 14:26:37.826787: Pseudo dice [np.float32(0.5865)] 
2025-01-08 14:26:37.830156: Epoch time: 36.38 s 
2025-01-08 14:26:37.832481: Yayy! New best EMA pseudo Dice: 0.5555999875068665 
2025-01-08 14:26:38.648729:  
2025-01-08 14:26:38.649732: Epoch 57 
2025-01-08 14:26:38.654280: Current learning rate: 0.00468 
2025-01-08 14:27:15.070109: train_loss -0.614 
2025-01-08 14:27:15.070611: val_loss -0.5106 
2025-01-08 14:27:15.075621: Pseudo dice [np.float32(0.6297)] 
2025-01-08 14:27:15.079129: Epoch time: 36.42 s 
2025-01-08 14:27:15.081635: Yayy! New best EMA pseudo Dice: 0.5630000233650208 
2025-01-08 14:27:15.870243:  
2025-01-08 14:27:15.870243: Epoch 58 
2025-01-08 14:27:15.876319: Current learning rate: 0.00458 
2025-01-08 14:27:52.248127: train_loss -0.5987 
2025-01-08 14:27:52.249130: val_loss -0.4695 
2025-01-08 14:27:52.255185: Pseudo dice [np.float32(0.5859)] 
2025-01-08 14:27:52.258211: Epoch time: 36.38 s 
2025-01-08 14:27:52.261733: Yayy! New best EMA pseudo Dice: 0.5652999877929688 
2025-01-08 14:27:53.266032:  
2025-01-08 14:27:53.266032: Epoch 59 
2025-01-08 14:27:53.271077: Current learning rate: 0.00448 
2025-01-08 14:28:29.638570: train_loss -0.5757 
2025-01-08 14:28:29.639073: val_loss -0.5221 
2025-01-08 14:28:29.644325: Pseudo dice [np.float32(0.6187)] 
2025-01-08 14:28:29.647830: Epoch time: 36.37 s 
2025-01-08 14:28:29.650841: Yayy! New best EMA pseudo Dice: 0.5705999732017517 
2025-01-08 14:28:30.482836:  
2025-01-08 14:28:30.482836: Epoch 60 
2025-01-08 14:28:30.488395: Current learning rate: 0.00438 
2025-01-08 14:29:06.826335: train_loss -0.6283 
2025-01-08 14:29:06.826846: val_loss -0.5062 
2025-01-08 14:29:06.832435: Pseudo dice [np.float32(0.6248)] 
2025-01-08 14:29:06.835970: Epoch time: 36.34 s 
2025-01-08 14:29:06.839034: Yayy! New best EMA pseudo Dice: 0.5759999752044678 
2025-01-08 14:29:07.637378:  
2025-01-08 14:29:07.638880: Epoch 61 
2025-01-08 14:29:07.643890: Current learning rate: 0.00429 
2025-01-08 14:29:44.029213: train_loss -0.5745 
2025-01-08 14:29:44.030213: val_loss -0.5457 
2025-01-08 14:29:44.036734: Pseudo dice [np.float32(0.6207)] 
2025-01-08 14:29:44.039239: Epoch time: 36.39 s 
2025-01-08 14:29:44.043247: Yayy! New best EMA pseudo Dice: 0.5805000066757202 
2025-01-08 14:29:44.873572:  
2025-01-08 14:29:44.874082: Epoch 62 
2025-01-08 14:29:44.879120: Current learning rate: 0.00419 
2025-01-08 14:30:21.309623: train_loss -0.6159 
2025-01-08 14:30:21.309623: val_loss -0.5394 
2025-01-08 14:30:21.315157: Pseudo dice [np.float32(0.639)] 
2025-01-08 14:30:21.318662: Epoch time: 36.44 s 
2025-01-08 14:30:21.321669: Yayy! New best EMA pseudo Dice: 0.5863000154495239 
2025-01-08 14:30:22.114682:  
2025-01-08 14:30:22.114682: Epoch 63 
2025-01-08 14:30:22.119693: Current learning rate: 0.00409 
2025-01-08 14:30:58.478841: train_loss -0.5647 
2025-01-08 14:30:58.479844: val_loss -0.5866 
2025-01-08 14:30:58.485868: Pseudo dice [np.float32(0.6568)] 
2025-01-08 14:30:58.488880: Epoch time: 36.36 s 
2025-01-08 14:30:58.492517: Yayy! New best EMA pseudo Dice: 0.5934000015258789 
2025-01-08 14:30:59.307092:  
2025-01-08 14:30:59.307092: Epoch 64 
2025-01-08 14:30:59.312110: Current learning rate: 0.00399 
2025-01-08 14:31:35.673722: train_loss -0.6249 
2025-01-08 14:31:35.674728: val_loss -0.5759 
2025-01-08 14:31:35.680736: Pseudo dice [np.float32(0.6702)] 
2025-01-08 14:31:35.683743: Epoch time: 36.37 s 
2025-01-08 14:31:35.686318: Yayy! New best EMA pseudo Dice: 0.6011000275611877 
2025-01-08 14:31:36.493162:  
2025-01-08 14:31:36.494165: Epoch 65 
2025-01-08 14:31:36.498714: Current learning rate: 0.00389 
2025-01-08 14:32:12.876260: train_loss -0.6113 
2025-01-08 14:32:12.877263: val_loss -0.5382 
2025-01-08 14:32:12.883366: Pseudo dice [np.float32(0.6107)] 
2025-01-08 14:32:12.886406: Epoch time: 36.38 s 
2025-01-08 14:32:12.888930: Yayy! New best EMA pseudo Dice: 0.6019999980926514 
2025-01-08 14:32:13.728641:  
2025-01-08 14:32:13.729644: Epoch 66 
2025-01-08 14:32:13.734679: Current learning rate: 0.00379 
2025-01-08 14:32:50.108433: train_loss -0.6063 
2025-01-08 14:32:50.109437: val_loss -0.5893 
2025-01-08 14:32:50.115446: Pseudo dice [np.float32(0.6789)] 
2025-01-08 14:32:50.118453: Epoch time: 36.38 s 
2025-01-08 14:32:50.120957: Yayy! New best EMA pseudo Dice: 0.6097000241279602 
2025-01-08 14:32:51.095525:  
2025-01-08 14:32:51.095525: Epoch 67 
2025-01-08 14:32:51.101057: Current learning rate: 0.00369 
2025-01-08 14:33:27.437229: train_loss -0.6238 
2025-01-08 14:33:27.437738: val_loss -0.5884 
2025-01-08 14:33:27.441878: Pseudo dice [np.float32(0.6632)] 
2025-01-08 14:33:27.445036: Epoch time: 36.34 s 
2025-01-08 14:33:27.447557: Yayy! New best EMA pseudo Dice: 0.6151000261306763 
2025-01-08 14:33:28.300603:  
2025-01-08 14:33:28.300603: Epoch 68 
2025-01-08 14:33:28.306160: Current learning rate: 0.00359 
2025-01-08 14:34:04.679890: train_loss -0.623 
2025-01-08 14:34:04.679890: val_loss -0.5396 
2025-01-08 14:34:04.685905: Pseudo dice [np.float32(0.6432)] 
2025-01-08 14:34:04.688410: Epoch time: 36.38 s 
2025-01-08 14:34:04.692417: Yayy! New best EMA pseudo Dice: 0.617900013923645 
2025-01-08 14:34:05.523881:  
2025-01-08 14:34:05.524884: Epoch 69 
2025-01-08 14:34:05.529902: Current learning rate: 0.00349 
2025-01-08 14:34:41.884031: train_loss -0.6231 
2025-01-08 14:34:41.884031: val_loss -0.5149 
2025-01-08 14:34:41.891633: Pseudo dice [np.float32(0.6229)] 
2025-01-08 14:34:41.895164: Epoch time: 36.36 s 
2025-01-08 14:34:41.898193: Yayy! New best EMA pseudo Dice: 0.618399977684021 
2025-01-08 14:34:42.732852:  
2025-01-08 14:34:42.732852: Epoch 70 
2025-01-08 14:34:42.738448: Current learning rate: 0.00338 
2025-01-08 14:35:19.085092: train_loss -0.5878 
2025-01-08 14:35:19.087677: val_loss -0.459 
2025-01-08 14:35:19.093247: Pseudo dice [np.float32(0.5508)] 
2025-01-08 14:35:19.097291: Epoch time: 36.35 s 
2025-01-08 14:35:19.751049:  
2025-01-08 14:35:19.751049: Epoch 71 
2025-01-08 14:35:19.757112: Current learning rate: 0.00328 
2025-01-08 14:35:56.060512: train_loss -0.586 
2025-01-08 14:35:56.061511: val_loss -0.4239 
2025-01-08 14:35:56.067024: Pseudo dice [np.float32(0.5224)] 
2025-01-08 14:35:56.069529: Epoch time: 36.31 s 
2025-01-08 14:35:56.674192:  
2025-01-08 14:35:56.674695: Epoch 72 
2025-01-08 14:35:56.679706: Current learning rate: 0.00318 
2025-01-08 14:36:33.082337: train_loss -0.6086 
2025-01-08 14:36:33.082337: val_loss -0.5694 
2025-01-08 14:36:33.088942: Pseudo dice [np.float32(0.6112)] 
2025-01-08 14:36:33.092447: Epoch time: 36.41 s 
2025-01-08 14:36:33.701559:  
2025-01-08 14:36:33.702560: Epoch 73 
2025-01-08 14:36:33.707133: Current learning rate: 0.00308 
2025-01-08 14:37:10.114145: train_loss -0.6406 
2025-01-08 14:37:10.114647: val_loss -0.5362 
2025-01-08 14:37:10.120195: Pseudo dice [np.float32(0.6036)] 
2025-01-08 14:37:10.123257: Epoch time: 36.41 s 
2025-01-08 14:37:10.730305:  
2025-01-08 14:37:10.731308: Epoch 74 
2025-01-08 14:37:10.735862: Current learning rate: 0.00297 
2025-01-08 14:37:47.163447: train_loss -0.59 
2025-01-08 14:37:47.164450: val_loss -0.5828 
2025-01-08 14:37:47.170110: Pseudo dice [np.float32(0.6592)] 
2025-01-08 14:37:47.173150: Epoch time: 36.43 s 
2025-01-08 14:37:47.935756:  
2025-01-08 14:37:47.935756: Epoch 75 
2025-01-08 14:37:47.941316: Current learning rate: 0.00287 
2025-01-08 14:38:24.290328: train_loss -0.6367 
2025-01-08 14:38:24.290328: val_loss -0.5131 
2025-01-08 14:38:24.295859: Pseudo dice [np.float32(0.6179)] 
2025-01-08 14:38:24.298887: Epoch time: 36.35 s 
2025-01-08 14:38:24.898370:  
2025-01-08 14:38:24.899374: Epoch 76 
2025-01-08 14:38:24.903948: Current learning rate: 0.00277 
2025-01-08 14:39:01.263159: train_loss -0.6308 
2025-01-08 14:39:01.263662: val_loss -0.5452 
2025-01-08 14:39:01.269701: Pseudo dice [np.float32(0.6059)] 
2025-01-08 14:39:01.273220: Epoch time: 36.36 s 
2025-01-08 14:39:01.879452:  
2025-01-08 14:39:01.880452: Epoch 77 
2025-01-08 14:39:01.886101: Current learning rate: 0.00266 
2025-01-08 14:39:38.264386: train_loss -0.6548 
2025-01-08 14:39:38.264386: val_loss -0.5817 
2025-01-08 14:39:38.271399: Pseudo dice [np.float32(0.6368)] 
2025-01-08 14:39:38.274407: Epoch time: 36.38 s 
2025-01-08 14:39:38.888740:  
2025-01-08 14:39:38.888740: Epoch 78 
2025-01-08 14:39:38.894786: Current learning rate: 0.00256 
2025-01-08 14:40:15.265906: train_loss -0.6499 
2025-01-08 14:40:15.265906: val_loss -0.5204 
2025-01-08 14:40:15.271920: Pseudo dice [np.float32(0.5707)] 
2025-01-08 14:40:15.274426: Epoch time: 36.38 s 
2025-01-08 14:40:15.880393:  
2025-01-08 14:40:15.881392: Epoch 79 
2025-01-08 14:40:15.885438: Current learning rate: 0.00245 
2025-01-08 14:40:52.254946: train_loss -0.6228 
2025-01-08 14:40:52.255462: val_loss -0.5901 
2025-01-08 14:40:52.260546: Pseudo dice [np.float32(0.6736)] 
2025-01-08 14:40:52.263651: Epoch time: 36.37 s 
2025-01-08 14:40:52.873954:  
2025-01-08 14:40:52.873954: Epoch 80 
2025-01-08 14:40:52.879475: Current learning rate: 0.00235 
2025-01-08 14:41:29.266137: train_loss -0.6536 
2025-01-08 14:41:29.266137: val_loss -0.598 
2025-01-08 14:41:29.272146: Pseudo dice [np.float32(0.6784)] 
2025-01-08 14:41:29.275155: Epoch time: 36.39 s 
2025-01-08 14:41:29.277660: Yayy! New best EMA pseudo Dice: 0.6211000084877014 
2025-01-08 14:41:30.079992:  
2025-01-08 14:41:30.079992: Epoch 81 
2025-01-08 14:41:30.085072: Current learning rate: 0.00224 
2025-01-08 14:42:06.455747: train_loss -0.6454 
2025-01-08 14:42:06.455747: val_loss -0.5503 
2025-01-08 14:42:06.462269: Pseudo dice [np.float32(0.66)] 
2025-01-08 14:42:06.464777: Epoch time: 36.38 s 
2025-01-08 14:42:06.468290: Yayy! New best EMA pseudo Dice: 0.625 
2025-01-08 14:42:07.293053:  
2025-01-08 14:42:07.293053: Epoch 82 
2025-01-08 14:42:07.299124: Current learning rate: 0.00214 
2025-01-08 14:42:43.844540: train_loss -0.6678 
2025-01-08 14:42:43.845100: val_loss -0.5516 
2025-01-08 14:42:43.850719: Pseudo dice [np.float32(0.6868)] 
2025-01-08 14:42:43.853281: Epoch time: 36.55 s 
2025-01-08 14:42:43.856821: Yayy! New best EMA pseudo Dice: 0.6310999989509583 
2025-01-08 14:42:44.826228:  
2025-01-08 14:42:44.826228: Epoch 83 
2025-01-08 14:42:44.832290: Current learning rate: 0.00203 
2025-01-08 14:43:21.244125: train_loss -0.6297 
2025-01-08 14:43:21.245125: val_loss -0.5413 
2025-01-08 14:43:21.250643: Pseudo dice [np.float32(0.6382)] 
2025-01-08 14:43:21.254154: Epoch time: 36.42 s 
2025-01-08 14:43:21.257663: Yayy! New best EMA pseudo Dice: 0.6317999958992004 
2025-01-08 14:43:22.082336:  
2025-01-08 14:43:22.082336: Epoch 84 
2025-01-08 14:43:22.088420: Current learning rate: 0.00192 
2025-01-08 14:43:58.470738: train_loss -0.6555 
2025-01-08 14:43:58.470738: val_loss -0.5645 
2025-01-08 14:43:58.477252: Pseudo dice [np.float32(0.6591)] 
2025-01-08 14:43:58.479760: Epoch time: 36.39 s 
2025-01-08 14:43:58.483270: Yayy! New best EMA pseudo Dice: 0.6345999836921692 
2025-01-08 14:43:59.264971:  
2025-01-08 14:43:59.265975: Epoch 85 
2025-01-08 14:43:59.271041: Current learning rate: 0.00181 
2025-01-08 14:44:35.691666: train_loss -0.6647 
2025-01-08 14:44:35.691666: val_loss -0.5805 
2025-01-08 14:44:35.698789: Pseudo dice [np.float32(0.6818)] 
2025-01-08 14:44:35.701343: Epoch time: 36.43 s 
2025-01-08 14:44:35.704447: Yayy! New best EMA pseudo Dice: 0.6392999887466431 
2025-01-08 14:44:36.498060:  
2025-01-08 14:44:36.498060: Epoch 86 
2025-01-08 14:44:36.503702: Current learning rate: 0.0017 
2025-01-08 14:45:12.915527: train_loss -0.6574 
2025-01-08 14:45:12.915527: val_loss -0.4932 
2025-01-08 14:45:12.920097: Pseudo dice [np.float32(0.6011)] 
2025-01-08 14:45:12.922710: Epoch time: 36.42 s 
2025-01-08 14:45:13.509290:  
2025-01-08 14:45:13.509290: Epoch 87 
2025-01-08 14:45:13.514886: Current learning rate: 0.00159 
2025-01-08 14:45:49.925642: train_loss -0.6232 
2025-01-08 14:45:49.926146: val_loss -0.5475 
2025-01-08 14:45:49.932168: Pseudo dice [np.float32(0.6356)] 
2025-01-08 14:45:49.935674: Epoch time: 36.42 s 
2025-01-08 14:45:50.525100:  
2025-01-08 14:45:50.526104: Epoch 88 
2025-01-08 14:45:50.530655: Current learning rate: 0.00148 
2025-01-08 14:46:26.925509: train_loss -0.6599 
2025-01-08 14:46:26.926013: val_loss -0.572 
2025-01-08 14:46:26.931028: Pseudo dice [np.float32(0.6598)] 
2025-01-08 14:46:26.934542: Epoch time: 36.4 s 
2025-01-08 14:46:27.514475:  
2025-01-08 14:46:27.514978: Epoch 89 
2025-01-08 14:46:27.519996: Current learning rate: 0.00137 
2025-01-08 14:47:03.931160: train_loss -0.6603 
2025-01-08 14:47:03.931674: val_loss -0.5981 
2025-01-08 14:47:03.937285: Pseudo dice [np.float32(0.6394)] 
2025-01-08 14:47:03.940331: Epoch time: 36.42 s 
2025-01-08 14:47:04.517685:  
2025-01-08 14:47:04.517685: Epoch 90 
2025-01-08 14:47:04.522502: Current learning rate: 0.00126 
2025-01-08 14:47:40.941288: train_loss -0.6375 
2025-01-08 14:47:40.941288: val_loss -0.5758 
2025-01-08 14:47:40.947987: Pseudo dice [np.float32(0.6576)] 
2025-01-08 14:47:40.950494: Epoch time: 36.42 s 
2025-01-08 14:47:40.954005: Yayy! New best EMA pseudo Dice: 0.6399999856948853 
2025-01-08 14:47:41.955727:  
2025-01-08 14:47:41.956728: Epoch 91 
2025-01-08 14:47:41.960303: Current learning rate: 0.00115 
2025-01-08 14:48:18.368109: train_loss -0.6693 
2025-01-08 14:48:18.368612: val_loss -0.5269 
2025-01-08 14:48:18.374631: Pseudo dice [np.float32(0.6156)] 
2025-01-08 14:48:18.378646: Epoch time: 36.41 s 
2025-01-08 14:48:18.955877:  
2025-01-08 14:48:18.956922: Epoch 92 
2025-01-08 14:48:18.961454: Current learning rate: 0.00103 
2025-01-08 14:48:55.343793: train_loss -0.6745 
2025-01-08 14:48:55.344797: val_loss -0.5811 
2025-01-08 14:48:55.349903: Pseudo dice [np.float32(0.6787)] 
2025-01-08 14:48:55.353474: Epoch time: 36.39 s 
2025-01-08 14:48:55.356025: Yayy! New best EMA pseudo Dice: 0.641700029373169 
2025-01-08 14:48:56.152902:  
2025-01-08 14:48:56.153901: Epoch 93 
2025-01-08 14:48:56.159008: Current learning rate: 0.00091 
2025-01-08 14:49:32.540221: train_loss -0.6564 
2025-01-08 14:49:32.540733: val_loss -0.4567 
2025-01-08 14:49:32.545779: Pseudo dice [np.float32(0.5898)] 
2025-01-08 14:49:32.549305: Epoch time: 36.39 s 
2025-01-08 14:49:33.139616:  
2025-01-08 14:49:33.139616: Epoch 94 
2025-01-08 14:49:33.145633: Current learning rate: 0.00079 
2025-01-08 14:50:09.547095: train_loss -0.6864 
2025-01-08 14:50:09.547095: val_loss -0.5524 
2025-01-08 14:50:09.553113: Pseudo dice [np.float32(0.6676)] 
2025-01-08 14:50:09.557123: Epoch time: 36.41 s 
2025-01-08 14:50:10.148942:  
2025-01-08 14:50:10.149940: Epoch 95 
2025-01-08 14:50:10.152990: Current learning rate: 0.00067 
2025-01-08 14:50:46.586809: train_loss -0.6703 
2025-01-08 14:50:46.586809: val_loss -0.5511 
2025-01-08 14:50:46.592822: Pseudo dice [np.float32(0.6397)] 
2025-01-08 14:50:46.595835: Epoch time: 36.44 s 
2025-01-08 14:50:47.172932:  
2025-01-08 14:50:47.172932: Epoch 96 
2025-01-08 14:50:47.178952: Current learning rate: 0.00055 
2025-01-08 14:51:23.582861: train_loss -0.6611 
2025-01-08 14:51:23.583365: val_loss -0.559 
2025-01-08 14:51:23.589060: Pseudo dice [np.float32(0.6246)] 
2025-01-08 14:51:23.592628: Epoch time: 36.41 s 
2025-01-08 14:51:24.180548:  
2025-01-08 14:51:24.180548: Epoch 97 
2025-01-08 14:51:24.186601: Current learning rate: 0.00043 
2025-01-08 14:52:00.609035: train_loss -0.6939 
2025-01-08 14:52:00.610040: val_loss -0.5117 
2025-01-08 14:52:00.616055: Pseudo dice [np.float32(0.6413)] 
2025-01-08 14:52:00.619066: Epoch time: 36.43 s 
2025-01-08 14:52:01.217104:  
2025-01-08 14:52:01.217104: Epoch 98 
2025-01-08 14:52:01.223157: Current learning rate: 0.0003 
2025-01-08 14:52:37.622928: train_loss -0.6629 
2025-01-08 14:52:37.623933: val_loss -0.5297 
2025-01-08 14:52:37.629951: Pseudo dice [np.float32(0.5848)] 
2025-01-08 14:52:37.632962: Epoch time: 36.41 s 
2025-01-08 14:52:38.472481:  
2025-01-08 14:52:38.473485: Epoch 99 
2025-01-08 14:52:38.478027: Current learning rate: 0.00016 
2025-01-08 14:53:14.897103: train_loss -0.6868 
2025-01-08 14:53:14.897616: val_loss -0.5706 
2025-01-08 14:53:14.903234: Pseudo dice [np.float32(0.6776)] 
2025-01-08 14:53:14.906283: Epoch time: 36.42 s 
2025-01-08 14:53:15.694061: Training done. 
2025-01-08 14:53:15.726575: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-08 14:53:15.733576: The split file contains 5 splits. 
2025-01-08 14:53:15.739575: Desired fold for training: 0 
2025-01-08 14:53:15.743577: This split has 100 training and 26 validation cases. 
2025-01-08 14:53:15.750575: predicting colon_008 
2025-01-08 14:53:15.757575: colon_008, shape torch.Size([1, 447, 363, 363]), rank 0 
2025-01-08 14:53:40.078815: predicting colon_027 
2025-01-08 14:53:40.099815: colon_027, shape torch.Size([1, 190, 344, 344]), rank 0 
2025-01-08 14:53:47.999754: predicting colon_030 
2025-01-08 14:53:48.010754: colon_030, shape torch.Size([1, 448, 300, 300]), rank 0 
2025-01-08 14:54:03.181250: predicting colon_033 
2025-01-08 14:54:03.197250: colon_033, shape torch.Size([1, 488, 375, 375]), rank 0 
2025-01-08 14:54:30.770911: predicting colon_041 
2025-01-08 14:54:30.796911: colon_041, shape torch.Size([1, 520, 462, 462]), rank 0 
2025-01-08 14:55:32.298160: predicting colon_042 
2025-01-08 14:55:32.346159: colon_042, shape torch.Size([1, 275, 500, 500]), rank 0 
2025-01-08 14:56:03.268549: predicting colon_061 
2025-01-08 14:56:03.294549: colon_061, shape torch.Size([1, 425, 413, 413]), rank 0 
2025-01-08 14:56:37.316907: predicting colon_074 
2025-01-08 14:56:37.342415: colon_074, shape torch.Size([1, 400, 474, 474]), rank 0 
2025-01-08 14:57:23.525251: predicting colon_075 
2025-01-08 14:57:23.557253: colon_075, shape torch.Size([1, 430, 370, 370]), rank 0 
2025-01-08 14:57:47.203742: predicting colon_088 
2025-01-08 14:57:47.229742: colon_088, shape torch.Size([1, 475, 440, 440]), rank 0 
2025-01-08 14:58:31.962838: predicting colon_091 
2025-01-08 14:58:31.993839: colon_091, shape torch.Size([1, 513, 424, 424]), rank 0 
2025-01-08 14:59:18.562949: predicting colon_092 
2025-01-08 14:59:18.597460: colon_092, shape torch.Size([1, 450, 384, 384]), rank 0 
2025-01-08 14:59:46.909984: predicting colon_095 
2025-01-08 14:59:46.937066: colon_095, shape torch.Size([1, 480, 353, 353]), rank 0 
2025-01-08 15:00:15.211562: predicting colon_102 
2025-01-08 15:00:15.237067: colon_102, shape torch.Size([1, 480, 461, 461]), rank 0 
2025-01-08 15:01:10.628818: predicting colon_111 
2025-01-08 15:01:10.675326: colon_111, shape torch.Size([1, 240, 407, 407]), rank 0 
2025-01-08 15:01:28.211835: predicting colon_115 
2025-01-08 15:01:28.231833: colon_115, shape torch.Size([1, 485, 367, 367]), rank 0 
2025-01-08 15:01:56.459733: predicting colon_118 
2025-01-08 15:01:56.481737: colon_118, shape torch.Size([1, 498, 380, 380]), rank 0 
2025-01-08 15:02:24.872112: predicting colon_124 
2025-01-08 15:02:24.896113: colon_124, shape torch.Size([1, 459, 418, 418]), rank 0 
2025-01-08 15:03:05.540804: predicting colon_127 
2025-01-08 15:03:05.571805: colon_127, shape torch.Size([1, 649, 467, 467]), rank 0 
2025-01-08 15:04:22.466643: predicting colon_154 
2025-01-08 15:04:22.517154: colon_154, shape torch.Size([1, 472, 360, 360]), rank 0 
2025-01-08 15:04:50.072863: predicting colon_161 
2025-01-08 15:04:50.096866: colon_161, shape torch.Size([1, 475, 370, 370]), rank 0 
2025-01-08 15:05:17.641383: predicting colon_162 
2025-01-08 15:05:17.668383: colon_162, shape torch.Size([1, 520, 467, 467]), rank 0 
2025-01-08 15:06:19.222094: predicting colon_165 
2025-01-08 15:06:19.263602: colon_165, shape torch.Size([1, 426, 451, 451]), rank 0 
2025-01-08 15:07:05.502480: predicting colon_166 
2025-01-08 15:07:05.546481: colon_166, shape torch.Size([1, 435, 370, 370]), rank 0 
2025-01-08 15:07:29.152625: predicting colon_169 
2025-01-08 15:07:29.175626: colon_169, shape torch.Size([1, 645, 485, 485]), rank 0 
2025-01-08 15:08:46.109733: predicting colon_187 
2025-01-08 15:08:46.180242: colon_187, shape torch.Size([1, 470, 401, 401]), rank 0 
2025-01-08 15:09:37.361933: Validation complete 
2025-01-08 15:09:37.361933: Mean Validation Dice:  0.2450479758737993 
