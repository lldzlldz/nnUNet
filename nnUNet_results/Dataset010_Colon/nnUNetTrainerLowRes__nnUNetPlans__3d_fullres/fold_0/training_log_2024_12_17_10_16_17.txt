
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-17 10:16:17.562895: do_dummy_2d_data_aug: True 
2024-12-17 10:16:17.567895: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-17 10:16:17.569894: The split file contains 5 splits. 
2024-12-17 10:16:17.572895: Desired fold for training: 0 
2024-12-17 10:16:17.574895: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2024-12-17 10:16:23.526712: unpacking dataset... 
2024-12-17 10:16:23.719184: unpacking done... 
2024-12-17 10:16:26.481233:  
2024-12-17 10:16:26.485247: Epoch 0 
2024-12-17 10:16:26.488755: Current learning rate: 0.01 
2024-12-17 10:17:12.212855: train_loss 0.0524 
2024-12-17 10:17:12.219872: val_loss -0.0014 
2024-12-17 10:17:12.222882: Pseudo dice [np.float32(0.0)] 
2024-12-17 10:17:12.226393: Epoch time: 45.73 s 
2024-12-17 10:17:12.228898: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-17 10:17:12.854318:  
2024-12-17 10:17:12.860901: Epoch 1 
2024-12-17 10:17:12.864432: Current learning rate: 0.00991 
2024-12-17 10:17:54.123180: train_loss -0.0668 
2024-12-17 10:17:54.128190: val_loss -0.2146 
2024-12-17 10:17:54.132200: Pseudo dice [np.float32(0.2709)] 
2024-12-17 10:17:54.134705: Epoch time: 41.27 s 
2024-12-17 10:17:54.138214: Yayy! New best EMA pseudo Dice: 0.02710000053048134 
2024-12-17 10:17:54.822762:  
2024-12-17 10:17:54.828349: Epoch 2 
2024-12-17 10:17:54.831902: Current learning rate: 0.00982 
2024-12-17 10:18:36.067646: train_loss -0.2404 
2024-12-17 10:18:36.074162: val_loss -0.2776 
2024-12-17 10:18:36.076667: Pseudo dice [np.float32(0.4026)] 
2024-12-17 10:18:36.079172: Epoch time: 41.24 s 
2024-12-17 10:18:36.081678: Yayy! New best EMA pseudo Dice: 0.06459999829530716 
2024-12-17 10:18:36.804464:  
2024-12-17 10:18:36.810052: Epoch 3 
2024-12-17 10:18:36.813104: Current learning rate: 0.00973 
2024-12-17 10:19:18.038952: train_loss -0.3658 
2024-12-17 10:19:18.045081: val_loss -0.4121 
2024-12-17 10:19:18.047626: Pseudo dice [np.float32(0.4715)] 
2024-12-17 10:19:18.050167: Epoch time: 41.23 s 
2024-12-17 10:19:18.052710: Yayy! New best EMA pseudo Dice: 0.10530000180006027 
2024-12-17 10:19:18.746560:  
2024-12-17 10:19:18.751593: Epoch 4 
2024-12-17 10:19:18.754623: Current learning rate: 0.00964 
2024-12-17 10:19:59.987708: train_loss -0.4168 
2024-12-17 10:19:59.993232: val_loss -0.4448 
2024-12-17 10:19:59.995251: Pseudo dice [np.float32(0.5301)] 
2024-12-17 10:19:59.998276: Epoch time: 41.24 s 
2024-12-17 10:20:00.000785: Yayy! New best EMA pseudo Dice: 0.1477999985218048 
2024-12-17 10:20:00.835391:  
2024-12-17 10:20:00.839976: Epoch 5 
2024-12-17 10:20:00.843002: Current learning rate: 0.00955 
2024-12-17 10:20:42.058282: train_loss -0.4846 
2024-12-17 10:20:42.064296: val_loss -0.434 
2024-12-17 10:20:42.068308: Pseudo dice [np.float32(0.4708)] 
2024-12-17 10:20:42.070813: Epoch time: 41.22 s 
2024-12-17 10:20:42.073318: Yayy! New best EMA pseudo Dice: 0.1800999939441681 
2024-12-17 10:20:42.753237:  
2024-12-17 10:20:42.758248: Epoch 6 
2024-12-17 10:20:42.761756: Current learning rate: 0.00946 
2024-12-17 10:21:23.983167: train_loss -0.5018 
2024-12-17 10:21:23.989728: val_loss -0.5069 
2024-12-17 10:21:23.992234: Pseudo dice [np.float32(0.5958)] 
2024-12-17 10:21:23.995744: Epoch time: 41.23 s 
2024-12-17 10:21:23.998250: Yayy! New best EMA pseudo Dice: 0.22169999778270721 
2024-12-17 10:21:24.692883:  
2024-12-17 10:21:24.698408: Epoch 7 
2024-12-17 10:21:24.701420: Current learning rate: 0.00937 
2024-12-17 10:22:05.938708: train_loss -0.5059 
2024-12-17 10:22:05.943719: val_loss -0.4568 
2024-12-17 10:22:05.946224: Pseudo dice [np.float32(0.5471)] 
2024-12-17 10:22:05.948730: Epoch time: 41.25 s 
2024-12-17 10:22:05.952238: Yayy! New best EMA pseudo Dice: 0.2542000114917755 
2024-12-17 10:22:06.667979:  
2024-12-17 10:22:06.673004: Epoch 8 
2024-12-17 10:22:06.676030: Current learning rate: 0.00928 
2024-12-17 10:22:47.912850: train_loss -0.5179 
2024-12-17 10:22:47.919370: val_loss -0.3501 
2024-12-17 10:22:47.922426: Pseudo dice [np.float32(0.4787)] 
2024-12-17 10:22:47.925934: Epoch time: 41.24 s 
2024-12-17 10:22:47.928442: Yayy! New best EMA pseudo Dice: 0.2766999900341034 
2024-12-17 10:22:48.653151:  
2024-12-17 10:22:48.659182: Epoch 9 
2024-12-17 10:22:48.662208: Current learning rate: 0.00919 
2024-12-17 10:23:29.886972: train_loss -0.5452 
2024-12-17 10:23:29.893080: val_loss -0.5034 
2024-12-17 10:23:29.895599: Pseudo dice [np.float32(0.5867)] 
2024-12-17 10:23:29.899122: Epoch time: 41.23 s 
2024-12-17 10:23:29.902141: Yayy! New best EMA pseudo Dice: 0.3077000081539154 
2024-12-17 10:23:30.597489:  
2024-12-17 10:23:30.602504: Epoch 10 
2024-12-17 10:23:30.605540: Current learning rate: 0.0091 
2024-12-17 10:24:11.840353: train_loss -0.5453 
2024-12-17 10:24:11.846372: val_loss -0.5047 
2024-12-17 10:24:11.849879: Pseudo dice [np.float32(0.6289)] 
2024-12-17 10:24:11.852888: Epoch time: 41.24 s 
2024-12-17 10:24:11.856399: Yayy! New best EMA pseudo Dice: 0.33980000019073486 
2024-12-17 10:24:12.566316:  
2024-12-17 10:24:12.572337: Epoch 11 
2024-12-17 10:24:12.575381: Current learning rate: 0.009 
2024-12-17 10:24:53.794887: train_loss -0.609 
2024-12-17 10:24:53.799938: val_loss -0.4781 
2024-12-17 10:24:53.802961: Pseudo dice [np.float32(0.5241)] 
2024-12-17 10:24:53.806466: Epoch time: 41.23 s 
2024-12-17 10:24:53.809478: Yayy! New best EMA pseudo Dice: 0.3582000136375427 
2024-12-17 10:24:54.508252:  
2024-12-17 10:24:54.513808: Epoch 12 
2024-12-17 10:24:54.517361: Current learning rate: 0.00891 
2024-12-17 10:25:35.737064: train_loss -0.5881 
2024-12-17 10:25:35.744188: val_loss -0.533 
2024-12-17 10:25:35.746713: Pseudo dice [np.float32(0.6146)] 
2024-12-17 10:25:35.749754: Epoch time: 41.23 s 
2024-12-17 10:25:35.752827: Yayy! New best EMA pseudo Dice: 0.383899986743927 
2024-12-17 10:25:36.592570:  
2024-12-17 10:25:36.598083: Epoch 13 
2024-12-17 10:25:36.600589: Current learning rate: 0.00882 
2024-12-17 10:26:17.818462: train_loss -0.5618 
2024-12-17 10:26:17.824009: val_loss -0.461 
2024-12-17 10:26:17.827530: Pseudo dice [np.float32(0.5393)] 
2024-12-17 10:26:17.830550: Epoch time: 41.23 s 
2024-12-17 10:26:17.833572: Yayy! New best EMA pseudo Dice: 0.399399995803833 
2024-12-17 10:26:18.541877:  
2024-12-17 10:26:18.547451: Epoch 14 
2024-12-17 10:26:18.550493: Current learning rate: 0.00873 
2024-12-17 10:26:59.773287: train_loss -0.5376 
2024-12-17 10:26:59.778874: val_loss -0.3758 
2024-12-17 10:26:59.781911: Pseudo dice [np.float32(0.4873)] 
2024-12-17 10:26:59.784439: Epoch time: 41.23 s 
2024-12-17 10:26:59.787975: Yayy! New best EMA pseudo Dice: 0.4081999957561493 
2024-12-17 10:27:00.509449:  
2024-12-17 10:27:00.515061: Epoch 15 
2024-12-17 10:27:00.518119: Current learning rate: 0.00864 
2024-12-17 10:27:41.750734: train_loss -0.5626 
2024-12-17 10:27:41.757779: val_loss -0.4887 
2024-12-17 10:27:41.760349: Pseudo dice [np.float32(0.5687)] 
2024-12-17 10:27:41.763374: Epoch time: 41.24 s 
2024-12-17 10:27:41.765880: Yayy! New best EMA pseudo Dice: 0.42419999837875366 
2024-12-17 10:27:42.485136:  
2024-12-17 10:27:42.490169: Epoch 16 
2024-12-17 10:27:42.493709: Current learning rate: 0.00855 
2024-12-17 10:28:23.725851: train_loss -0.6132 
2024-12-17 10:28:23.732412: val_loss -0.4529 
2024-12-17 10:28:23.734919: Pseudo dice [np.float32(0.558)] 
2024-12-17 10:28:23.738425: Epoch time: 41.24 s 
2024-12-17 10:28:23.741433: Yayy! New best EMA pseudo Dice: 0.4375999867916107 
2024-12-17 10:28:24.473665:  
2024-12-17 10:28:24.479222: Epoch 17 
2024-12-17 10:28:24.483274: Current learning rate: 0.00846 
2024-12-17 10:29:05.705087: train_loss -0.6485 
2024-12-17 10:29:05.710665: val_loss -0.4664 
2024-12-17 10:29:05.713751: Pseudo dice [np.float32(0.5346)] 
2024-12-17 10:29:05.716794: Epoch time: 41.23 s 
2024-12-17 10:29:05.718810: Yayy! New best EMA pseudo Dice: 0.447299987077713 
2024-12-17 10:29:06.435567:  
2024-12-17 10:29:06.441158: Epoch 18 
2024-12-17 10:29:06.445191: Current learning rate: 0.00836 
2024-12-17 10:29:47.650034: train_loss -0.6895 
2024-12-17 10:29:47.656583: val_loss -0.49 
2024-12-17 10:29:47.659088: Pseudo dice [np.float32(0.56)] 
2024-12-17 10:29:47.663096: Epoch time: 41.21 s 
2024-12-17 10:29:47.665601: Yayy! New best EMA pseudo Dice: 0.4586000144481659 
2024-12-17 10:29:48.378469:  
2024-12-17 10:29:48.384020: Epoch 19 
2024-12-17 10:29:48.387090: Current learning rate: 0.00827 
2024-12-17 10:30:29.616401: train_loss -0.631 
2024-12-17 10:30:29.621944: val_loss -0.4269 
2024-12-17 10:30:29.625959: Pseudo dice [np.float32(0.5354)] 
2024-12-17 10:30:29.628465: Epoch time: 41.24 s 
2024-12-17 10:30:29.631974: Yayy! New best EMA pseudo Dice: 0.46630001068115234 
2024-12-17 10:30:30.352532:  
2024-12-17 10:30:30.358094: Epoch 20 
2024-12-17 10:30:30.360636: Current learning rate: 0.00818 
2024-12-17 10:31:11.575910: train_loss -0.6284 
2024-12-17 10:31:11.582949: val_loss -0.4746 
2024-12-17 10:31:11.585457: Pseudo dice [np.float32(0.5661)] 
2024-12-17 10:31:11.587962: Epoch time: 41.22 s 
2024-12-17 10:31:11.591469: Yayy! New best EMA pseudo Dice: 0.4763000011444092 
2024-12-17 10:31:12.468682:  
2024-12-17 10:31:12.473692: Epoch 21 
2024-12-17 10:31:12.477201: Current learning rate: 0.00809 
2024-12-17 10:31:53.696444: train_loss -0.6809 
2024-12-17 10:31:53.702173: val_loss -0.3401 
2024-12-17 10:31:53.704710: Pseudo dice [np.float32(0.477)] 
2024-12-17 10:31:53.707247: Epoch time: 41.23 s 
2024-12-17 10:31:53.709784: Yayy! New best EMA pseudo Dice: 0.4763000011444092 
2024-12-17 10:31:54.409870:  
2024-12-17 10:31:54.414880: Epoch 22 
2024-12-17 10:31:54.418889: Current learning rate: 0.008 
2024-12-17 10:32:35.643442: train_loss -0.6702 
2024-12-17 10:32:35.650016: val_loss -0.4162 
2024-12-17 10:32:35.653141: Pseudo dice [np.float32(0.5423)] 
2024-12-17 10:32:35.656187: Epoch time: 41.23 s 
2024-12-17 10:32:35.658723: Yayy! New best EMA pseudo Dice: 0.4828999936580658 
2024-12-17 10:32:36.349571:  
2024-12-17 10:32:36.355132: Epoch 23 
2024-12-17 10:32:36.358188: Current learning rate: 0.0079 
2024-12-17 10:33:17.578310: train_loss -0.6557 
2024-12-17 10:33:17.583835: val_loss -0.3294 
2024-12-17 10:33:17.586936: Pseudo dice [np.float32(0.4664)] 
2024-12-17 10:33:17.590441: Epoch time: 41.23 s 
2024-12-17 10:33:18.119811:  
2024-12-17 10:33:18.123821: Epoch 24 
2024-12-17 10:33:18.127337: Current learning rate: 0.00781 
2024-12-17 10:33:59.354291: train_loss -0.671 
2024-12-17 10:33:59.360302: val_loss -0.4322 
2024-12-17 10:33:59.363351: Pseudo dice [np.float32(0.5716)] 
2024-12-17 10:33:59.365858: Epoch time: 41.24 s 
2024-12-17 10:33:59.369366: Yayy! New best EMA pseudo Dice: 0.4902999997138977 
2024-12-17 10:34:00.064397:  
2024-12-17 10:34:00.069408: Epoch 25 
2024-12-17 10:34:00.071918: Current learning rate: 0.00772 
2024-12-17 10:34:41.299954: train_loss -0.6898 
2024-12-17 10:34:41.305468: val_loss -0.4228 
2024-12-17 10:34:41.308976: Pseudo dice [np.float32(0.5362)] 
2024-12-17 10:34:41.311482: Epoch time: 41.24 s 
2024-12-17 10:34:41.313988: Yayy! New best EMA pseudo Dice: 0.4948999881744385 
2024-12-17 10:34:42.012855:  
2024-12-17 10:34:42.017865: Epoch 26 
2024-12-17 10:34:42.020873: Current learning rate: 0.00763 
2024-12-17 10:35:23.250818: train_loss -0.6945 
2024-12-17 10:35:23.256851: val_loss -0.4461 
2024-12-17 10:35:23.259366: Pseudo dice [np.float32(0.5402)] 
2024-12-17 10:35:23.263382: Epoch time: 41.24 s 
2024-12-17 10:35:23.265895: Yayy! New best EMA pseudo Dice: 0.49939998984336853 
2024-12-17 10:35:23.958845:  
2024-12-17 10:35:23.964404: Epoch 27 
2024-12-17 10:35:23.967458: Current learning rate: 0.00753 
2024-12-17 10:36:05.203758: train_loss -0.6953 
2024-12-17 10:36:05.209334: val_loss -0.4218 
2024-12-17 10:36:05.211840: Pseudo dice [np.float32(0.4874)] 
2024-12-17 10:36:05.215348: Epoch time: 41.24 s 
2024-12-17 10:36:05.762528:  
2024-12-17 10:36:05.767061: Epoch 28 
2024-12-17 10:36:05.770082: Current learning rate: 0.00744 
2024-12-17 10:36:46.991229: train_loss -0.6798 
2024-12-17 10:36:46.996784: val_loss -0.3726 
2024-12-17 10:36:47.000311: Pseudo dice [np.float32(0.5459)] 
2024-12-17 10:36:47.003336: Epoch time: 41.23 s 
2024-12-17 10:36:47.006360: Yayy! New best EMA pseudo Dice: 0.503000020980835 
2024-12-17 10:36:47.842427:  
2024-12-17 10:36:47.847983: Epoch 29 
2024-12-17 10:36:47.851017: Current learning rate: 0.00735 
2024-12-17 10:37:29.077621: train_loss -0.6354 
2024-12-17 10:37:29.084635: val_loss -0.4299 
2024-12-17 10:37:29.087642: Pseudo dice [np.float32(0.571)] 
2024-12-17 10:37:29.090149: Epoch time: 41.24 s 
2024-12-17 10:37:29.093657: Yayy! New best EMA pseudo Dice: 0.5098000168800354 
2024-12-17 10:37:29.803303:  
2024-12-17 10:37:29.807815: Epoch 30 
2024-12-17 10:37:29.810822: Current learning rate: 0.00725 
2024-12-17 10:38:11.029509: train_loss -0.6833 
2024-12-17 10:38:11.035527: val_loss -0.3947 
2024-12-17 10:38:11.038033: Pseudo dice [np.float32(0.497)] 
2024-12-17 10:38:11.041539: Epoch time: 41.23 s 
2024-12-17 10:38:11.592117:  
2024-12-17 10:38:11.596141: Epoch 31 
2024-12-17 10:38:11.599664: Current learning rate: 0.00716 
2024-12-17 10:38:52.810498: train_loss -0.6979 
2024-12-17 10:38:52.815546: val_loss -0.5253 
2024-12-17 10:38:52.819085: Pseudo dice [np.float32(0.6404)] 
2024-12-17 10:38:52.821612: Epoch time: 41.22 s 
2024-12-17 10:38:52.824635: Yayy! New best EMA pseudo Dice: 0.5217000246047974 
2024-12-17 10:38:53.554916:  
2024-12-17 10:38:53.558426: Epoch 32 
2024-12-17 10:38:53.562434: Current learning rate: 0.00707 
2024-12-17 10:39:34.781301: train_loss -0.7151 
2024-12-17 10:39:34.787869: val_loss -0.4041 
2024-12-17 10:39:34.790385: Pseudo dice [np.float32(0.5192)] 
2024-12-17 10:39:34.793904: Epoch time: 41.23 s 
2024-12-17 10:39:35.344475:  
2024-12-17 10:39:35.348512: Epoch 33 
2024-12-17 10:39:35.353069: Current learning rate: 0.00697 
2024-12-17 10:40:16.569776: train_loss -0.7253 
2024-12-17 10:40:16.575841: val_loss -0.3215 
2024-12-17 10:40:16.579862: Pseudo dice [np.float32(0.4993)] 
2024-12-17 10:40:16.583385: Epoch time: 41.23 s 
2024-12-17 10:40:17.140839:  
2024-12-17 10:40:17.145849: Epoch 34 
2024-12-17 10:40:17.148858: Current learning rate: 0.00688 
2024-12-17 10:40:58.380771: train_loss -0.6959 
2024-12-17 10:40:58.385856: val_loss -0.3087 
2024-12-17 10:40:58.390468: Pseudo dice [np.float32(0.3812)] 
2024-12-17 10:40:58.392974: Epoch time: 41.24 s 
2024-12-17 10:40:58.952141:  
2024-12-17 10:40:58.956658: Epoch 35 
2024-12-17 10:40:58.959688: Current learning rate: 0.00679 
2024-12-17 10:41:40.182849: train_loss -0.7049 
2024-12-17 10:41:40.188179: val_loss -0.4352 
2024-12-17 10:41:40.191736: Pseudo dice [np.float32(0.5172)] 
2024-12-17 10:41:40.194281: Epoch time: 41.23 s 
2024-12-17 10:41:40.890273:  
2024-12-17 10:41:40.895916: Epoch 36 
2024-12-17 10:41:40.898454: Current learning rate: 0.00669 
2024-12-17 10:42:22.121554: train_loss -0.6986 
2024-12-17 10:42:22.127148: val_loss -0.4358 
2024-12-17 10:42:22.130190: Pseudo dice [np.float32(0.5821)] 
2024-12-17 10:42:22.133723: Epoch time: 41.23 s 
2024-12-17 10:42:22.706066:  
2024-12-17 10:42:22.711589: Epoch 37 
2024-12-17 10:42:22.714597: Current learning rate: 0.0066 
2024-12-17 10:43:03.934580: train_loss -0.722 
2024-12-17 10:43:03.940122: val_loss -0.418 
2024-12-17 10:43:03.943657: Pseudo dice [np.float32(0.5799)] 
2024-12-17 10:43:03.946681: Epoch time: 41.23 s 
2024-12-17 10:43:04.507576:  
2024-12-17 10:43:04.512609: Epoch 38 
2024-12-17 10:43:04.516146: Current learning rate: 0.0065 
2024-12-17 10:43:45.726731: train_loss -0.7076 
2024-12-17 10:43:45.732783: val_loss -0.4369 
2024-12-17 10:43:45.736323: Pseudo dice [np.float32(0.5401)] 
2024-12-17 10:43:45.739356: Epoch time: 41.22 s 
2024-12-17 10:43:45.741881: Yayy! New best EMA pseudo Dice: 0.5227000117301941 
2024-12-17 10:43:46.456970:  
2024-12-17 10:43:46.461989: Epoch 39 
2024-12-17 10:43:46.466003: Current learning rate: 0.00641 
2024-12-17 10:44:27.678148: train_loss -0.739 
2024-12-17 10:44:27.684664: val_loss -0.3191 
2024-12-17 10:44:27.688672: Pseudo dice [np.float32(0.4528)] 
2024-12-17 10:44:27.692180: Epoch time: 41.22 s 
2024-12-17 10:44:28.260105:  
2024-12-17 10:44:28.265157: Epoch 40 
2024-12-17 10:44:28.268709: Current learning rate: 0.00631 
2024-12-17 10:45:09.478870: train_loss -0.7443 
2024-12-17 10:45:09.484403: val_loss -0.4148 
2024-12-17 10:45:09.487961: Pseudo dice [np.float32(0.5407)] 
2024-12-17 10:45:09.491995: Epoch time: 41.22 s 
2024-12-17 10:45:10.055974:  
2024-12-17 10:45:10.060991: Epoch 41 
2024-12-17 10:45:10.064503: Current learning rate: 0.00622 
2024-12-17 10:45:51.293021: train_loss -0.7442 
2024-12-17 10:45:51.299097: val_loss -0.2638 
2024-12-17 10:45:51.303141: Pseudo dice [np.float32(0.4352)] 
2024-12-17 10:45:51.306210: Epoch time: 41.24 s 
2024-12-17 10:45:51.845185:  
2024-12-17 10:45:51.848730: Epoch 42 
2024-12-17 10:45:51.853804: Current learning rate: 0.00612 
2024-12-17 10:46:33.099089: train_loss -0.7392 
2024-12-17 10:46:33.104656: val_loss -0.4419 
2024-12-17 10:46:33.107201: Pseudo dice [np.float32(0.5813)] 
2024-12-17 10:46:33.110710: Epoch time: 41.25 s 
2024-12-17 10:46:33.641451:  
2024-12-17 10:46:33.645492: Epoch 43 
2024-12-17 10:46:33.648025: Current learning rate: 0.00603 
2024-12-17 10:47:14.879213: train_loss -0.7537 
2024-12-17 10:47:14.886896: val_loss -0.3273 
2024-12-17 10:47:14.889944: Pseudo dice [np.float32(0.5426)] 
2024-12-17 10:47:14.892993: Epoch time: 41.24 s 
2024-12-17 10:47:15.581489:  
2024-12-17 10:47:15.586519: Epoch 44 
2024-12-17 10:47:15.589569: Current learning rate: 0.00593 
2024-12-17 10:47:56.893620: train_loss -0.7187 
2024-12-17 10:47:56.899755: val_loss -0.4282 
2024-12-17 10:47:56.903300: Pseudo dice [np.float32(0.5841)] 
2024-12-17 10:47:56.906894: Epoch time: 41.31 s 
2024-12-17 10:47:56.909906: Yayy! New best EMA pseudo Dice: 0.5260000228881836 
2024-12-17 10:47:57.622653:  
2024-12-17 10:47:57.627546: Epoch 45 
2024-12-17 10:47:57.630582: Current learning rate: 0.00584 
2024-12-17 10:48:38.940243: train_loss -0.7496 
2024-12-17 10:48:38.946764: val_loss -0.2128 
2024-12-17 10:48:38.950773: Pseudo dice [np.float32(0.4691)] 
2024-12-17 10:48:38.953280: Epoch time: 41.32 s 
2024-12-17 10:48:39.496531:  
2024-12-17 10:48:39.501571: Epoch 46 
2024-12-17 10:48:39.505119: Current learning rate: 0.00574 
2024-12-17 10:49:20.851605: train_loss -0.7289 
2024-12-17 10:49:20.860633: val_loss -0.335 
2024-12-17 10:49:20.864680: Pseudo dice [np.float32(0.4716)] 
2024-12-17 10:49:20.868695: Epoch time: 41.36 s 
2024-12-17 10:49:21.427229:  
2024-12-17 10:49:21.432790: Epoch 47 
2024-12-17 10:49:21.436383: Current learning rate: 0.00565 
2024-12-17 10:50:02.789473: train_loss -0.7109 
2024-12-17 10:50:02.795993: val_loss -0.3352 
2024-12-17 10:50:02.799505: Pseudo dice [np.float32(0.477)] 
2024-12-17 10:50:02.802011: Epoch time: 41.36 s 
2024-12-17 10:50:03.339451:  
2024-12-17 10:50:03.344485: Epoch 48 
2024-12-17 10:50:03.348017: Current learning rate: 0.00555 
2024-12-17 10:50:44.660494: train_loss -0.7085 
2024-12-17 10:50:44.666507: val_loss -0.3859 
2024-12-17 10:50:44.669519: Pseudo dice [np.float32(0.541)] 
2024-12-17 10:50:44.673032: Epoch time: 41.32 s 
2024-12-17 10:50:45.226597:  
2024-12-17 10:50:45.230626: Epoch 49 
2024-12-17 10:50:45.234640: Current learning rate: 0.00546 
2024-12-17 10:51:26.571591: train_loss -0.732 
2024-12-17 10:51:26.577732: val_loss -0.42 
2024-12-17 10:51:26.581276: Pseudo dice [np.float32(0.5671)] 
2024-12-17 10:51:26.583788: Epoch time: 41.35 s 
2024-12-17 10:51:27.279988:  
2024-12-17 10:51:27.285501: Epoch 50 
2024-12-17 10:51:27.289010: Current learning rate: 0.00536 
2024-12-17 10:52:08.599498: train_loss -0.7395 
2024-12-17 10:52:08.606023: val_loss -0.4803 
2024-12-17 10:52:08.609577: Pseudo dice [np.float32(0.6348)] 
2024-12-17 10:52:08.613138: Epoch time: 41.32 s 
2024-12-17 10:52:08.615645: Yayy! New best EMA pseudo Dice: 0.5313000082969666 
2024-12-17 10:52:09.328991:  
2024-12-17 10:52:09.335091: Epoch 51 
2024-12-17 10:52:09.337633: Current learning rate: 0.00526 
2024-12-17 10:52:50.635128: train_loss -0.7735 
2024-12-17 10:52:50.641734: val_loss -0.3599 
2024-12-17 10:52:50.644778: Pseudo dice [np.float32(0.505)] 
2024-12-17 10:52:50.649872: Epoch time: 41.31 s 
2024-12-17 10:52:51.345552:  
2024-12-17 10:52:51.351112: Epoch 52 
2024-12-17 10:52:51.353652: Current learning rate: 0.00517 
2024-12-17 10:53:32.646103: train_loss -0.7598 
2024-12-17 10:53:32.651673: val_loss -0.317 
2024-12-17 10:53:32.655197: Pseudo dice [np.float32(0.5173)] 
2024-12-17 10:53:32.658215: Epoch time: 41.3 s 
2024-12-17 10:53:33.207209:  
2024-12-17 10:53:33.212227: Epoch 53 
2024-12-17 10:53:33.215739: Current learning rate: 0.00507 
2024-12-17 10:54:14.526319: train_loss -0.7755 
2024-12-17 10:54:14.532834: val_loss -0.2704 
2024-12-17 10:54:14.536343: Pseudo dice [np.float32(0.4583)] 
2024-12-17 10:54:14.539849: Epoch time: 41.32 s 
2024-12-17 10:54:15.087992:  
2024-12-17 10:54:15.093003: Epoch 54 
2024-12-17 10:54:15.096540: Current learning rate: 0.00497 
2024-12-17 10:54:56.381208: train_loss -0.7879 
2024-12-17 10:54:56.387011: val_loss -0.3875 
2024-12-17 10:54:56.390556: Pseudo dice [np.float32(0.5802)] 
2024-12-17 10:54:56.393595: Epoch time: 41.29 s 
2024-12-17 10:54:56.944232:  
2024-12-17 10:54:56.948777: Epoch 55 
2024-12-17 10:54:56.951729: Current learning rate: 0.00487 
2024-12-17 10:55:38.261257: train_loss -0.7839 
2024-12-17 10:55:38.268289: val_loss -0.4554 
2024-12-17 10:55:38.271330: Pseudo dice [np.float32(0.6002)] 
2024-12-17 10:55:38.274359: Epoch time: 41.32 s 
2024-12-17 10:55:38.277923: Yayy! New best EMA pseudo Dice: 0.5339000225067139 
2024-12-17 10:55:38.993539:  
2024-12-17 10:55:38.998549: Epoch 56 
2024-12-17 10:55:39.003059: Current learning rate: 0.00478 
2024-12-17 10:56:20.311341: train_loss -0.7716 
2024-12-17 10:56:20.317444: val_loss -0.352 
2024-12-17 10:56:20.322017: Pseudo dice [np.float32(0.4876)] 
2024-12-17 10:56:20.325068: Epoch time: 41.32 s 
2024-12-17 10:56:20.870939:  
2024-12-17 10:56:20.875957: Epoch 57 
2024-12-17 10:56:20.879974: Current learning rate: 0.00468 
2024-12-17 10:57:02.178407: train_loss -0.7695 
2024-12-17 10:57:02.184425: val_loss -0.3043 
2024-12-17 10:57:02.188026: Pseudo dice [np.float32(0.4375)] 
2024-12-17 10:57:02.191051: Epoch time: 41.31 s 
2024-12-17 10:57:02.771312:  
2024-12-17 10:57:02.776825: Epoch 58 
2024-12-17 10:57:02.780333: Current learning rate: 0.00458 
2024-12-17 10:57:44.087675: train_loss -0.7752 
2024-12-17 10:57:44.094255: val_loss -0.3522 
2024-12-17 10:57:44.098290: Pseudo dice [np.float32(0.4951)] 
2024-12-17 10:57:44.101848: Epoch time: 41.32 s 
2024-12-17 10:57:44.668691:  
2024-12-17 10:57:44.674745: Epoch 59 
2024-12-17 10:57:44.678773: Current learning rate: 0.00448 
2024-12-17 10:58:26.002497: train_loss -0.7696 
2024-12-17 10:58:26.008620: val_loss -0.3341 
2024-12-17 10:58:26.012168: Pseudo dice [np.float32(0.4412)] 
2024-12-17 10:58:26.015678: Epoch time: 41.33 s 
2024-12-17 10:58:26.569789:  
2024-12-17 10:58:26.574801: Epoch 60 
2024-12-17 10:58:26.578813: Current learning rate: 0.00438 
2024-12-17 10:59:07.923396: train_loss -0.7549 
2024-12-17 10:59:07.929911: val_loss -0.3991 
2024-12-17 10:59:07.932957: Pseudo dice [np.float32(0.5622)] 
2024-12-17 10:59:07.936462: Epoch time: 41.35 s 
2024-12-17 10:59:08.498042:  
2024-12-17 10:59:08.503592: Epoch 61 
2024-12-17 10:59:08.506619: Current learning rate: 0.00429 
2024-12-17 10:59:49.835951: train_loss -0.7913 
2024-12-17 10:59:49.842574: val_loss -0.4941 
2024-12-17 10:59:49.845649: Pseudo dice [np.float32(0.6338)] 
2024-12-17 10:59:49.848680: Epoch time: 41.34 s 
2024-12-17 10:59:50.419991:  
2024-12-17 10:59:50.424449: Epoch 62 
2024-12-17 10:59:50.427459: Current learning rate: 0.00419 
2024-12-17 11:00:31.751989: train_loss -0.7984 
2024-12-17 11:00:31.758011: val_loss -0.3877 
2024-12-17 11:00:31.761082: Pseudo dice [np.float32(0.5432)] 
2024-12-17 11:00:31.764591: Epoch time: 41.33 s 
2024-12-17 11:00:32.326238:  
2024-12-17 11:00:32.331277: Epoch 63 
2024-12-17 11:00:32.334064: Current learning rate: 0.00409 
2024-12-17 11:01:13.638143: train_loss -0.7833 
2024-12-17 11:01:13.643444: val_loss -0.3789 
2024-12-17 11:01:13.646955: Pseudo dice [np.float32(0.5676)] 
2024-12-17 11:01:13.649464: Epoch time: 41.31 s 
2024-12-17 11:01:14.211135:  
2024-12-17 11:01:14.216167: Epoch 64 
2024-12-17 11:01:14.219196: Current learning rate: 0.00399 
2024-12-17 11:01:55.523036: train_loss -0.7905 
2024-12-17 11:01:55.529592: val_loss -0.3608 
2024-12-17 11:01:55.532106: Pseudo dice [np.float32(0.5486)] 
2024-12-17 11:01:55.535624: Epoch time: 41.31 s 
2024-12-17 11:01:55.538641: Yayy! New best EMA pseudo Dice: 0.5342000126838684 
2024-12-17 11:01:56.272199:  
2024-12-17 11:01:56.277211: Epoch 65 
2024-12-17 11:01:56.279718: Current learning rate: 0.00389 
2024-12-17 11:02:37.588257: train_loss -0.783 
2024-12-17 11:02:37.593269: val_loss -0.4158 
2024-12-17 11:02:37.596778: Pseudo dice [np.float32(0.622)] 
2024-12-17 11:02:37.599284: Epoch time: 41.32 s 
2024-12-17 11:02:37.602790: Yayy! New best EMA pseudo Dice: 0.542900025844574 
2024-12-17 11:02:38.332652:  
2024-12-17 11:02:38.337760: Epoch 66 
2024-12-17 11:02:38.342269: Current learning rate: 0.00379 
2024-12-17 11:03:19.668024: train_loss -0.7786 
2024-12-17 11:03:19.674080: val_loss -0.2121 
2024-12-17 11:03:19.676842: Pseudo dice [np.float32(0.4514)] 
2024-12-17 11:03:19.679354: Epoch time: 41.34 s 
2024-12-17 11:03:20.245687:  
2024-12-17 11:03:20.250726: Epoch 67 
2024-12-17 11:03:20.253290: Current learning rate: 0.00369 
2024-12-17 11:04:01.569848: train_loss -0.7773 
2024-12-17 11:04:01.575911: val_loss -0.3596 
2024-12-17 11:04:01.578971: Pseudo dice [np.float32(0.5747)] 
2024-12-17 11:04:01.581524: Epoch time: 41.33 s 
2024-12-17 11:04:02.302248:  
2024-12-17 11:04:02.307303: Epoch 68 
2024-12-17 11:04:02.310373: Current learning rate: 0.00359 
2024-12-17 11:04:43.621725: train_loss -0.8051 
2024-12-17 11:04:43.627760: val_loss -0.3918 
2024-12-17 11:04:43.630784: Pseudo dice [np.float32(0.6049)] 
2024-12-17 11:04:43.633801: Epoch time: 41.32 s 
2024-12-17 11:04:43.636315: Yayy! New best EMA pseudo Dice: 0.5446000099182129 
2024-12-17 11:04:44.371698:  
2024-12-17 11:04:44.377233: Epoch 69 
2024-12-17 11:04:44.380810: Current learning rate: 0.00349 
2024-12-17 11:05:25.682933: train_loss -0.785 
2024-12-17 11:05:25.689516: val_loss -0.3621 
2024-12-17 11:05:25.692568: Pseudo dice [np.float32(0.5106)] 
2024-12-17 11:05:25.695675: Epoch time: 41.31 s 
2024-12-17 11:05:26.264257:  
2024-12-17 11:05:26.268837: Epoch 70 
2024-12-17 11:05:26.272344: Current learning rate: 0.00338 
2024-12-17 11:06:07.594956: train_loss -0.818 
2024-12-17 11:06:07.600000: val_loss -0.3552 
2024-12-17 11:06:07.604032: Pseudo dice [np.float32(0.4925)] 
2024-12-17 11:06:07.606561: Epoch time: 41.33 s 
2024-12-17 11:06:08.181008:  
2024-12-17 11:06:08.186559: Epoch 71 
2024-12-17 11:06:08.189596: Current learning rate: 0.00328 
2024-12-17 11:06:49.503367: train_loss -0.8097 
2024-12-17 11:06:49.508431: val_loss -0.3931 
2024-12-17 11:06:49.511943: Pseudo dice [np.float32(0.6266)] 
2024-12-17 11:06:49.514451: Epoch time: 41.32 s 
2024-12-17 11:06:49.517959: Yayy! New best EMA pseudo Dice: 0.5453000068664551 
2024-12-17 11:06:50.259121:  
2024-12-17 11:06:50.264151: Epoch 72 
2024-12-17 11:06:50.267671: Current learning rate: 0.00318 
2024-12-17 11:07:31.634401: train_loss -0.8007 
2024-12-17 11:07:31.641417: val_loss -0.3131 
2024-12-17 11:07:31.644428: Pseudo dice [np.float32(0.5485)] 
2024-12-17 11:07:31.647939: Epoch time: 41.38 s 
2024-12-17 11:07:31.650445: Yayy! New best EMA pseudo Dice: 0.5457000136375427 
2024-12-17 11:07:32.382019:  
2024-12-17 11:07:32.388052: Epoch 73 
2024-12-17 11:07:32.390618: Current learning rate: 0.00308 
2024-12-17 11:08:13.732712: train_loss -0.7905 
2024-12-17 11:08:13.737724: val_loss -0.3897 
2024-12-17 11:08:13.740262: Pseudo dice [np.float32(0.5672)] 
2024-12-17 11:08:13.744305: Epoch time: 41.35 s 
2024-12-17 11:08:13.745839: Yayy! New best EMA pseudo Dice: 0.5478000044822693 
2024-12-17 11:08:14.485348:  
2024-12-17 11:08:14.490363: Epoch 74 
2024-12-17 11:08:14.493872: Current learning rate: 0.00297 
2024-12-17 11:08:55.803040: train_loss -0.8026 
2024-12-17 11:08:55.809070: val_loss -0.4467 
2024-12-17 11:08:55.812093: Pseudo dice [np.float32(0.6063)] 
2024-12-17 11:08:55.815600: Epoch time: 41.32 s 
2024-12-17 11:08:55.818608: Yayy! New best EMA pseudo Dice: 0.5536999702453613 
2024-12-17 11:08:56.555857:  
2024-12-17 11:08:56.561423: Epoch 75 
2024-12-17 11:08:56.563970: Current learning rate: 0.00287 
2024-12-17 11:09:37.877451: train_loss -0.8106 
2024-12-17 11:09:37.884964: val_loss -0.3553 
2024-12-17 11:09:37.887468: Pseudo dice [np.float32(0.518)] 
2024-12-17 11:09:37.891588: Epoch time: 41.32 s 
2024-12-17 11:09:38.469846:  
2024-12-17 11:09:38.474866: Epoch 76 
2024-12-17 11:09:38.477375: Current learning rate: 0.00277 
2024-12-17 11:10:19.820436: train_loss -0.8188 
2024-12-17 11:10:19.826451: val_loss -0.4275 
2024-12-17 11:10:19.828486: Pseudo dice [np.float32(0.5346)] 
2024-12-17 11:10:19.832517: Epoch time: 41.35 s 
2024-12-17 11:10:20.410080:  
2024-12-17 11:10:20.415606: Epoch 77 
2024-12-17 11:10:20.418613: Current learning rate: 0.00266 
2024-12-17 11:11:01.732239: train_loss -0.8214 
2024-12-17 11:11:01.737297: val_loss -0.311 
2024-12-17 11:11:01.739825: Pseudo dice [np.float32(0.5083)] 
2024-12-17 11:11:01.743337: Epoch time: 41.32 s 
2024-12-17 11:11:02.334804:  
2024-12-17 11:11:02.339878: Epoch 78 
2024-12-17 11:11:02.343412: Current learning rate: 0.00256 
2024-12-17 11:11:43.659662: train_loss -0.8183 
2024-12-17 11:11:43.666178: val_loss -0.4547 
2024-12-17 11:11:43.668687: Pseudo dice [np.float32(0.6113)] 
2024-12-17 11:11:43.672194: Epoch time: 41.32 s 
2024-12-17 11:11:44.263192:  
2024-12-17 11:11:44.267222: Epoch 79 
2024-12-17 11:11:44.270759: Current learning rate: 0.00245 
2024-12-17 11:12:25.580788: train_loss -0.8253 
2024-12-17 11:12:25.586353: val_loss -0.3674 
2024-12-17 11:12:25.588899: Pseudo dice [np.float32(0.5694)] 
2024-12-17 11:12:25.592943: Epoch time: 41.32 s 
2024-12-17 11:12:26.179373:  
2024-12-17 11:12:26.184410: Epoch 80 
2024-12-17 11:12:26.187931: Current learning rate: 0.00235 
2024-12-17 11:13:07.489409: train_loss -0.8361 
2024-12-17 11:13:07.494995: val_loss -0.3358 
2024-12-17 11:13:07.498022: Pseudo dice [np.float32(0.5077)] 
2024-12-17 11:13:07.501060: Epoch time: 41.31 s 
2024-12-17 11:13:08.080485:  
2024-12-17 11:13:08.085497: Epoch 81 
2024-12-17 11:13:08.089504: Current learning rate: 0.00224 
2024-12-17 11:13:49.386146: train_loss -0.8245 
2024-12-17 11:13:49.391686: val_loss -0.3546 
2024-12-17 11:13:49.394225: Pseudo dice [np.float32(0.6231)] 
2024-12-17 11:13:49.396745: Epoch time: 41.31 s 
2024-12-17 11:13:49.400767: Yayy! New best EMA pseudo Dice: 0.555899977684021 
2024-12-17 11:13:50.149110:  
2024-12-17 11:13:50.154704: Epoch 82 
2024-12-17 11:13:50.157743: Current learning rate: 0.00214 
2024-12-17 11:14:31.470654: train_loss -0.8123 
2024-12-17 11:14:31.476205: val_loss -0.396 
2024-12-17 11:14:31.479785: Pseudo dice [np.float32(0.5771)] 
2024-12-17 11:14:31.482315: Epoch time: 41.32 s 
2024-12-17 11:14:31.484846: Yayy! New best EMA pseudo Dice: 0.5580999851226807 
2024-12-17 11:14:32.206075:  
2024-12-17 11:14:32.213124: Epoch 83 
2024-12-17 11:14:32.217132: Current learning rate: 0.00203 
2024-12-17 11:15:13.523340: train_loss -0.8248 
2024-12-17 11:15:13.529633: val_loss -0.2827 
2024-12-17 11:15:13.532667: Pseudo dice [np.float32(0.515)] 
2024-12-17 11:15:13.535195: Epoch time: 41.32 s 
2024-12-17 11:15:14.227959:  
2024-12-17 11:15:14.233530: Epoch 84 
2024-12-17 11:15:14.236110: Current learning rate: 0.00192 
2024-12-17 11:15:55.538179: train_loss -0.8107 
2024-12-17 11:15:55.543231: val_loss -0.2949 
2024-12-17 11:15:55.546273: Pseudo dice [np.float32(0.4813)] 
2024-12-17 11:15:55.548797: Epoch time: 41.31 s 
2024-12-17 11:15:56.114397:  
2024-12-17 11:15:56.119454: Epoch 85 
2024-12-17 11:15:56.122528: Current learning rate: 0.00181 
2024-12-17 11:16:37.428732: train_loss -0.8427 
2024-12-17 11:16:37.435869: val_loss -0.3496 
2024-12-17 11:16:37.438978: Pseudo dice [np.float32(0.5518)] 
2024-12-17 11:16:37.441542: Epoch time: 41.31 s 
2024-12-17 11:16:37.985878:  
2024-12-17 11:16:37.990915: Epoch 86 
2024-12-17 11:16:37.993676: Current learning rate: 0.0017 
2024-12-17 11:17:19.286870: train_loss -0.8188 
2024-12-17 11:17:19.292888: val_loss -0.1761 
2024-12-17 11:17:19.296397: Pseudo dice [np.float32(0.3848)] 
2024-12-17 11:17:19.299408: Epoch time: 41.3 s 
2024-12-17 11:17:19.839195:  
2024-12-17 11:17:19.844213: Epoch 87 
2024-12-17 11:17:19.846724: Current learning rate: 0.00159 
2024-12-17 11:18:01.158772: train_loss -0.8098 
2024-12-17 11:18:01.164313: val_loss -0.3827 
2024-12-17 11:18:01.166835: Pseudo dice [np.float32(0.5878)] 
2024-12-17 11:18:01.169867: Epoch time: 41.32 s 
2024-12-17 11:18:01.713213:  
2024-12-17 11:18:01.718273: Epoch 88 
2024-12-17 11:18:01.721340: Current learning rate: 0.00148 
2024-12-17 11:18:43.048876: train_loss -0.8426 
2024-12-17 11:18:43.054889: val_loss -0.3172 
2024-12-17 11:18:43.057901: Pseudo dice [np.float32(0.5547)] 
2024-12-17 11:18:43.061413: Epoch time: 41.34 s 
2024-12-17 11:18:43.604532:  
2024-12-17 11:18:43.611046: Epoch 89 
2024-12-17 11:18:43.614558: Current learning rate: 0.00137 
2024-12-17 11:19:24.935526: train_loss -0.8373 
2024-12-17 11:19:24.943045: val_loss -0.3561 
2024-12-17 11:19:24.946558: Pseudo dice [np.float32(0.5626)] 
2024-12-17 11:19:24.950570: Epoch time: 41.33 s 
2024-12-17 11:19:25.492304:  
2024-12-17 11:19:25.498379: Epoch 90 
2024-12-17 11:19:25.501891: Current learning rate: 0.00126 
2024-12-17 11:20:06.801487: train_loss -0.8403 
2024-12-17 11:20:06.808007: val_loss -0.3677 
2024-12-17 11:20:06.811517: Pseudo dice [np.float32(0.5812)] 
2024-12-17 11:20:06.815025: Epoch time: 41.31 s 
2024-12-17 11:20:07.360814:  
2024-12-17 11:20:07.364851: Epoch 91 
2024-12-17 11:20:07.369907: Current learning rate: 0.00115 
2024-12-17 11:20:48.710609: train_loss -0.8348 
2024-12-17 11:20:48.717623: val_loss -0.3662 
2024-12-17 11:20:48.721639: Pseudo dice [np.float32(0.6017)] 
2024-12-17 11:20:48.725650: Epoch time: 41.35 s 
2024-12-17 11:20:49.273196:  
2024-12-17 11:20:49.278240: Epoch 92 
2024-12-17 11:20:49.282172: Current learning rate: 0.00103 
2024-12-17 11:21:30.641898: train_loss -0.8492 
2024-12-17 11:21:30.649492: val_loss -0.3256 
2024-12-17 11:21:30.652537: Pseudo dice [np.float32(0.6169)] 
2024-12-17 11:21:30.656608: Epoch time: 41.37 s 
2024-12-17 11:21:31.363575:  
2024-12-17 11:21:31.368614: Epoch 93 
2024-12-17 11:21:31.372529: Current learning rate: 0.00091 
2024-12-17 11:22:12.697006: train_loss -0.8505 
2024-12-17 11:22:12.702576: val_loss -0.3267 
2024-12-17 11:22:12.706671: Pseudo dice [np.float32(0.6339)] 
2024-12-17 11:22:12.709730: Epoch time: 41.33 s 
2024-12-17 11:22:12.713772: Yayy! New best EMA pseudo Dice: 0.5648000240325928 
2024-12-17 11:22:13.420066:  
2024-12-17 11:22:13.426081: Epoch 94 
2024-12-17 11:22:13.430095: Current learning rate: 0.00079 
2024-12-17 11:22:54.752276: train_loss -0.8474 
2024-12-17 11:22:54.758086: val_loss -0.3131 
2024-12-17 11:22:54.761593: Pseudo dice [np.float32(0.5441)] 
2024-12-17 11:22:54.764606: Epoch time: 41.33 s 
2024-12-17 11:22:55.305006:  
2024-12-17 11:22:55.309061: Epoch 95 
2024-12-17 11:22:55.313652: Current learning rate: 0.00067 
2024-12-17 11:23:36.620302: train_loss -0.8381 
2024-12-17 11:23:36.625323: val_loss -0.2825 
2024-12-17 11:23:36.628837: Pseudo dice [np.float32(0.537)] 
2024-12-17 11:23:36.632432: Epoch time: 41.32 s 
2024-12-17 11:23:37.183593:  
2024-12-17 11:23:37.188646: Epoch 96 
2024-12-17 11:23:37.191710: Current learning rate: 0.00055 
2024-12-17 11:24:18.507792: train_loss -0.8506 
2024-12-17 11:24:18.514851: val_loss -0.4096 
2024-12-17 11:24:18.518454: Pseudo dice [np.float32(0.6462)] 
2024-12-17 11:24:18.521977: Epoch time: 41.32 s 
2024-12-17 11:24:18.525007: Yayy! New best EMA pseudo Dice: 0.5687999725341797 
2024-12-17 11:24:19.237744:  
2024-12-17 11:24:19.243265: Epoch 97 
2024-12-17 11:24:19.245772: Current learning rate: 0.00043 
2024-12-17 11:25:00.546544: train_loss -0.8452 
2024-12-17 11:25:00.552135: val_loss -0.3276 
2024-12-17 11:25:00.555159: Pseudo dice [np.float32(0.6066)] 
2024-12-17 11:25:00.558674: Epoch time: 41.31 s 
2024-12-17 11:25:00.562192: Yayy! New best EMA pseudo Dice: 0.5724999904632568 
2024-12-17 11:25:01.277007:  
2024-12-17 11:25:01.283159: Epoch 98 
2024-12-17 11:25:01.286200: Current learning rate: 0.0003 
2024-12-17 11:25:42.627602: train_loss -0.8464 
2024-12-17 11:25:42.633725: val_loss -0.283 
2024-12-17 11:25:42.638273: Pseudo dice [np.float32(0.6019)] 
2024-12-17 11:25:42.640780: Epoch time: 41.35 s 
2024-12-17 11:25:42.644292: Yayy! New best EMA pseudo Dice: 0.5755000114440918 
2024-12-17 11:25:43.363026:  
2024-12-17 11:25:43.368060: Epoch 99 
2024-12-17 11:25:43.371600: Current learning rate: 0.00016 
2024-12-17 11:26:24.700864: train_loss -0.8483 
2024-12-17 11:26:24.706430: val_loss -0.3789 
2024-12-17 11:26:24.709969: Pseudo dice [np.float32(0.6206)] 
2024-12-17 11:26:24.713485: Epoch time: 41.34 s 
2024-12-17 11:26:24.716529: Yayy! New best EMA pseudo Dice: 0.5799999833106995 
2024-12-17 11:26:25.637459: Training done. 
2024-12-17 11:26:25.670460: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-17 11:26:25.676460: The split file contains 5 splits. 
2024-12-17 11:26:25.680459: Desired fold for training: 0 
2024-12-17 11:26:25.684458: This split has 100 training and 26 validation cases. 
2024-12-17 11:26:25.688458: predicting colon_008 
2024-12-17 11:26:25.693458: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2024-12-17 11:26:28.342912: predicting colon_027 
2024-12-17 11:26:28.361912: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2024-12-17 11:26:29.146474: predicting colon_030 
2024-12-17 11:26:29.157474: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2024-12-17 11:26:30.261687: predicting colon_033 
2024-12-17 11:26:30.276687: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2024-12-17 11:26:32.219977: predicting colon_041 
2024-12-17 11:26:32.246977: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2024-12-17 11:26:37.421606: predicting colon_042 
2024-12-17 11:26:37.459606: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2024-12-17 11:26:40.099688: predicting colon_061 
2024-12-17 11:26:40.121765: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2024-12-17 11:26:43.143801: predicting colon_074 
2024-12-17 11:26:43.175799: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2024-12-17 11:26:46.663160: predicting colon_075 
2024-12-17 11:26:46.694161: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2024-12-17 11:26:48.657885: predicting colon_088 
2024-12-17 11:26:48.680885: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2024-12-17 11:26:51.727518: predicting colon_091 
2024-12-17 11:26:51.757517: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2024-12-17 11:26:55.376433: predicting colon_092 
2024-12-17 11:26:55.413436: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2024-12-17 11:26:58.429792: predicting colon_095 
2024-12-17 11:26:58.458792: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2024-12-17 11:27:00.415213: predicting colon_102 
2024-12-17 11:27:00.437722: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2024-12-17 11:27:04.768493: predicting colon_111 
2024-12-17 11:27:04.808491: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2024-12-17 11:27:06.059101: predicting colon_115 
2024-12-17 11:27:06.076102: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2024-12-17 11:27:08.034269: predicting colon_118 
2024-12-17 11:27:08.059269: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2024-12-17 11:27:11.091080: predicting colon_124 
2024-12-17 11:27:11.135592: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2024-12-17 11:27:14.155030: predicting colon_127 
2024-12-17 11:27:14.187030: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2024-12-17 11:27:20.238011: predicting colon_154 
2024-12-17 11:27:20.290011: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2024-12-17 11:27:22.251676: predicting colon_161 
2024-12-17 11:27:22.271677: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2024-12-17 11:27:24.242496: predicting colon_162 
2024-12-17 11:27:24.263496: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2024-12-17 11:27:29.445540: predicting colon_165 
2024-12-17 11:27:29.481540: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2024-12-17 11:27:33.836008: predicting colon_166 
2024-12-17 11:27:33.881008: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2024-12-17 11:27:35.867723: predicting colon_169 
2024-12-17 11:27:35.897723: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2024-12-17 11:27:42.000648: predicting colon_187 
2024-12-17 11:27:42.039155: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2024-12-17 11:28:00.250251: Validation complete 
2024-12-17 11:28:00.256252: Mean Validation Dice:  0.27681374814613857 
