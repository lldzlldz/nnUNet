
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-16 06:18:35.717928: do_dummy_2d_data_aug: True 
2025-03-16 06:18:35.730927: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-16 06:18:35.738932: The split file contains 5 splits. 
2025-03-16 06:18:35.741931: Desired fold for training: 0 
2025-03-16 06:18:35.744932: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-03-16 06:18:42.369373: unpacking dataset... 
2025-03-16 06:18:42.622771: unpacking done... 
2025-03-16 06:18:45.579386:  
2025-03-16 06:18:45.584415: Epoch 0 
2025-03-16 06:18:45.587931: Current learning rate: 0.01 
2025-03-16 06:19:31.622602: train_loss 0.0403 
2025-03-16 06:19:31.628623: val_loss -0.0167 
2025-03-16 06:19:31.632157: Pseudo dice [np.float32(0.0)] 
2025-03-16 06:19:31.635182: Epoch time: 46.04 s 
2025-03-16 06:19:31.638707: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-16 06:19:32.252034:  
2025-03-16 06:19:32.257598: Epoch 1 
2025-03-16 06:19:32.261723: Current learning rate: 0.00991 
2025-03-16 06:20:13.786494: train_loss -0.1178 
2025-03-16 06:20:13.793102: val_loss -0.3011 
2025-03-16 06:20:13.797633: Pseudo dice [np.float32(0.3996)] 
2025-03-16 06:20:13.800958: Epoch time: 41.53 s 
2025-03-16 06:20:13.804974: Yayy! New best EMA pseudo Dice: 0.03999999910593033 
2025-03-16 06:20:14.519015:  
2025-03-16 06:20:14.525214: Epoch 2 
2025-03-16 06:20:14.528258: Current learning rate: 0.00982 
2025-03-16 06:20:56.066168: train_loss -0.2956 
2025-03-16 06:20:56.072268: val_loss -0.3629 
2025-03-16 06:20:56.078784: Pseudo dice [np.float32(0.4449)] 
2025-03-16 06:20:56.081290: Epoch time: 41.55 s 
2025-03-16 06:20:56.084797: Yayy! New best EMA pseudo Dice: 0.08049999922513962 
2025-03-16 06:20:56.801002:  
2025-03-16 06:20:56.806055: Epoch 3 
2025-03-16 06:20:56.810178: Current learning rate: 0.00973 
2025-03-16 06:21:38.316042: train_loss -0.3226 
2025-03-16 06:21:38.322515: val_loss -0.3241 
2025-03-16 06:21:38.326029: Pseudo dice [np.float32(0.381)] 
2025-03-16 06:21:38.329046: Epoch time: 41.52 s 
2025-03-16 06:21:38.332563: Yayy! New best EMA pseudo Dice: 0.11050000041723251 
2025-03-16 06:21:39.027550:  
2025-03-16 06:21:39.033126: Epoch 4 
2025-03-16 06:21:39.036635: Current learning rate: 0.00964 
2025-03-16 06:22:20.546987: train_loss -0.3631 
2025-03-16 06:22:20.553504: val_loss -0.3842 
2025-03-16 06:22:20.558518: Pseudo dice [np.float32(0.4177)] 
2025-03-16 06:22:20.562025: Epoch time: 41.52 s 
2025-03-16 06:22:20.565065: Yayy! New best EMA pseudo Dice: 0.1412000060081482 
2025-03-16 06:22:21.424351:  
2025-03-16 06:22:21.430372: Epoch 5 
2025-03-16 06:22:21.432994: Current learning rate: 0.00955 
2025-03-16 06:23:02.960130: train_loss -0.3888 
2025-03-16 06:23:02.966708: val_loss -0.3217 
2025-03-16 06:23:02.970219: Pseudo dice [np.float32(0.3911)] 
2025-03-16 06:23:02.973728: Epoch time: 41.54 s 
2025-03-16 06:23:02.976766: Yayy! New best EMA pseudo Dice: 0.16619999706745148 
2025-03-16 06:23:03.698404:  
2025-03-16 06:23:03.703953: Epoch 6 
2025-03-16 06:23:03.707994: Current learning rate: 0.00946 
2025-03-16 06:23:45.196135: train_loss -0.4369 
2025-03-16 06:23:45.202147: val_loss -0.3937 
2025-03-16 06:23:45.206155: Pseudo dice [np.float32(0.4765)] 
2025-03-16 06:23:45.208660: Epoch time: 41.5 s 
2025-03-16 06:23:45.212248: Yayy! New best EMA pseudo Dice: 0.1972000002861023 
2025-03-16 06:23:45.892736:  
2025-03-16 06:23:45.898878: Epoch 7 
2025-03-16 06:23:45.901935: Current learning rate: 0.00937 
2025-03-16 06:24:27.387597: train_loss -0.433 
2025-03-16 06:24:27.394113: val_loss -0.4038 
2025-03-16 06:24:27.397657: Pseudo dice [np.float32(0.4623)] 
2025-03-16 06:24:27.400321: Epoch time: 41.49 s 
2025-03-16 06:24:27.403834: Yayy! New best EMA pseudo Dice: 0.22370000183582306 
2025-03-16 06:24:28.136644:  
2025-03-16 06:24:28.142224: Epoch 8 
2025-03-16 06:24:28.146310: Current learning rate: 0.00928 
2025-03-16 06:25:09.631592: train_loss -0.4062 
2025-03-16 06:25:09.637609: val_loss -0.417 
2025-03-16 06:25:09.641649: Pseudo dice [np.float32(0.5147)] 
2025-03-16 06:25:09.644155: Epoch time: 41.5 s 
2025-03-16 06:25:09.647664: Yayy! New best EMA pseudo Dice: 0.25279998779296875 
2025-03-16 06:25:10.344101:  
2025-03-16 06:25:10.350174: Epoch 9 
2025-03-16 06:25:10.353753: Current learning rate: 0.00919 
2025-03-16 06:25:51.860227: train_loss -0.4372 
2025-03-16 06:25:51.866247: val_loss -0.4871 
2025-03-16 06:25:51.870257: Pseudo dice [np.float32(0.5694)] 
2025-03-16 06:25:51.873770: Epoch time: 41.52 s 
2025-03-16 06:25:51.877783: Yayy! New best EMA pseudo Dice: 0.28450000286102295 
2025-03-16 06:25:52.625105:  
2025-03-16 06:25:52.631713: Epoch 10 
2025-03-16 06:25:52.635760: Current learning rate: 0.0091 
2025-03-16 06:26:34.113773: train_loss -0.4735 
2025-03-16 06:26:34.120895: val_loss -0.4829 
2025-03-16 06:26:34.126001: Pseudo dice [np.float32(0.5373)] 
2025-03-16 06:26:34.129563: Epoch time: 41.49 s 
2025-03-16 06:26:34.132604: Yayy! New best EMA pseudo Dice: 0.30979999899864197 
2025-03-16 06:26:34.809567:  
2025-03-16 06:26:34.815118: Epoch 11 
2025-03-16 06:26:34.818684: Current learning rate: 0.009 
2025-03-16 06:27:16.330288: train_loss -0.4657 
2025-03-16 06:27:16.336311: val_loss -0.4476 
2025-03-16 06:27:16.340318: Pseudo dice [np.float32(0.5571)] 
2025-03-16 06:27:16.343352: Epoch time: 41.52 s 
2025-03-16 06:27:16.346379: Yayy! New best EMA pseudo Dice: 0.3345000147819519 
2025-03-16 06:27:17.022138:  
2025-03-16 06:27:17.027689: Epoch 12 
2025-03-16 06:27:17.032762: Current learning rate: 0.00891 
2025-03-16 06:27:58.530105: train_loss -0.4628 
2025-03-16 06:27:58.537122: val_loss -0.4035 
2025-03-16 06:27:58.541136: Pseudo dice [np.float32(0.4602)] 
2025-03-16 06:27:58.543641: Epoch time: 41.51 s 
2025-03-16 06:27:58.547651: Yayy! New best EMA pseudo Dice: 0.34709998965263367 
2025-03-16 06:27:59.427480:  
2025-03-16 06:27:59.433028: Epoch 13 
2025-03-16 06:27:59.439127: Current learning rate: 0.00882 
2025-03-16 06:28:40.935658: train_loss -0.4651 
2025-03-16 06:28:40.942175: val_loss -0.4166 
2025-03-16 06:28:40.945684: Pseudo dice [np.float32(0.4852)] 
2025-03-16 06:28:40.949693: Epoch time: 41.51 s 
2025-03-16 06:28:40.953202: Yayy! New best EMA pseudo Dice: 0.36090001463890076 
2025-03-16 06:28:41.632682:  
2025-03-16 06:28:41.638672: Epoch 14 
2025-03-16 06:28:41.642689: Current learning rate: 0.00873 
2025-03-16 06:29:23.145252: train_loss -0.4695 
2025-03-16 06:29:23.153392: val_loss -0.4554 
2025-03-16 06:29:23.158435: Pseudo dice [np.float32(0.5151)] 
2025-03-16 06:29:23.162981: Epoch time: 41.51 s 
2025-03-16 06:29:23.166584: Yayy! New best EMA pseudo Dice: 0.37630000710487366 
2025-03-16 06:29:23.904531:  
2025-03-16 06:29:23.910620: Epoch 15 
2025-03-16 06:29:23.914706: Current learning rate: 0.00864 
2025-03-16 06:30:05.392677: train_loss -0.5354 
2025-03-16 06:30:05.399689: val_loss -0.5265 
2025-03-16 06:30:05.403702: Pseudo dice [np.float32(0.5747)] 
2025-03-16 06:30:05.407207: Epoch time: 41.49 s 
2025-03-16 06:30:05.411224: Yayy! New best EMA pseudo Dice: 0.3962000012397766 
2025-03-16 06:30:06.109092:  
2025-03-16 06:30:06.114653: Epoch 16 
2025-03-16 06:30:06.118716: Current learning rate: 0.00855 
2025-03-16 06:30:47.610441: train_loss -0.5006 
2025-03-16 06:30:47.617966: val_loss -0.4931 
2025-03-16 06:30:47.622476: Pseudo dice [np.float32(0.5184)] 
2025-03-16 06:30:47.625500: Epoch time: 41.5 s 
2025-03-16 06:30:47.628034: Yayy! New best EMA pseudo Dice: 0.4083999991416931 
2025-03-16 06:30:48.384606:  
2025-03-16 06:30:48.389663: Epoch 17 
2025-03-16 06:30:48.392703: Current learning rate: 0.00846 
2025-03-16 06:31:29.879318: train_loss -0.533 
2025-03-16 06:31:29.885377: val_loss -0.4981 
2025-03-16 06:31:29.891012: Pseudo dice [np.float32(0.5538)] 
2025-03-16 06:31:29.895564: Epoch time: 41.5 s 
2025-03-16 06:31:29.898101: Yayy! New best EMA pseudo Dice: 0.42289999127388 
2025-03-16 06:31:30.640036:  
2025-03-16 06:31:30.646048: Epoch 18 
2025-03-16 06:31:30.650058: Current learning rate: 0.00836 
2025-03-16 06:32:12.146283: train_loss -0.4984 
2025-03-16 06:32:12.153306: val_loss -0.4617 
2025-03-16 06:32:12.156620: Pseudo dice [np.float32(0.4862)] 
2025-03-16 06:32:12.160628: Epoch time: 41.51 s 
2025-03-16 06:32:12.164139: Yayy! New best EMA pseudo Dice: 0.4291999936103821 
2025-03-16 06:32:12.902485:  
2025-03-16 06:32:12.908029: Epoch 19 
2025-03-16 06:32:12.913160: Current learning rate: 0.00827 
2025-03-16 06:32:54.416708: train_loss -0.5471 
2025-03-16 06:32:54.421567: val_loss -0.4532 
2025-03-16 06:32:54.426356: Pseudo dice [np.float32(0.5247)] 
2025-03-16 06:32:54.429868: Epoch time: 41.51 s 
2025-03-16 06:32:54.433378: Yayy! New best EMA pseudo Dice: 0.43880000710487366 
2025-03-16 06:32:55.133983:  
2025-03-16 06:32:55.140555: Epoch 20 
2025-03-16 06:32:55.144564: Current learning rate: 0.00818 
2025-03-16 06:33:36.628940: train_loss -0.5194 
2025-03-16 06:33:36.634953: val_loss -0.5307 
2025-03-16 06:33:36.638672: Pseudo dice [np.float32(0.5698)] 
2025-03-16 06:33:36.642185: Epoch time: 41.49 s 
2025-03-16 06:33:36.645451: Yayy! New best EMA pseudo Dice: 0.45190000534057617 
2025-03-16 06:33:37.544539:  
2025-03-16 06:33:37.550056: Epoch 21 
2025-03-16 06:33:37.553565: Current learning rate: 0.00809 
2025-03-16 06:34:19.044209: train_loss -0.5664 
2025-03-16 06:34:19.050240: val_loss -0.4238 
2025-03-16 06:34:19.053798: Pseudo dice [np.float32(0.5012)] 
2025-03-16 06:34:19.056310: Epoch time: 41.5 s 
2025-03-16 06:34:19.060610: Yayy! New best EMA pseudo Dice: 0.45680001378059387 
2025-03-16 06:34:19.734575:  
2025-03-16 06:34:19.740088: Epoch 22 
2025-03-16 06:34:19.745097: Current learning rate: 0.008 
2025-03-16 06:35:01.244634: train_loss -0.5606 
2025-03-16 06:35:01.251147: val_loss -0.5467 
2025-03-16 06:35:01.254657: Pseudo dice [np.float32(0.6227)] 
2025-03-16 06:35:01.258667: Epoch time: 41.51 s 
2025-03-16 06:35:01.262176: Yayy! New best EMA pseudo Dice: 0.4733999967575073 
2025-03-16 06:35:01.963428:  
2025-03-16 06:35:01.968979: Epoch 23 
2025-03-16 06:35:01.974124: Current learning rate: 0.0079 
2025-03-16 06:35:43.463195: train_loss -0.5234 
2025-03-16 06:35:43.469240: val_loss -0.475 
2025-03-16 06:35:43.473305: Pseudo dice [np.float32(0.5755)] 
2025-03-16 06:35:43.476981: Epoch time: 41.5 s 
2025-03-16 06:35:43.480530: Yayy! New best EMA pseudo Dice: 0.483599990606308 
2025-03-16 06:35:44.166629:  
2025-03-16 06:35:44.172655: Epoch 24 
2025-03-16 06:35:44.176164: Current learning rate: 0.00781 
2025-03-16 06:36:25.677194: train_loss -0.4992 
2025-03-16 06:36:25.684740: val_loss -0.4333 
2025-03-16 06:36:25.688774: Pseudo dice [np.float32(0.5848)] 
2025-03-16 06:36:25.692283: Epoch time: 41.51 s 
2025-03-16 06:36:25.695291: Yayy! New best EMA pseudo Dice: 0.4936999976634979 
2025-03-16 06:36:26.399235:  
2025-03-16 06:36:26.404749: Epoch 25 
2025-03-16 06:36:26.408261: Current learning rate: 0.00772 
2025-03-16 06:37:07.920309: train_loss -0.5633 
2025-03-16 06:37:07.925321: val_loss -0.4487 
2025-03-16 06:37:07.930442: Pseudo dice [np.float32(0.5078)] 
2025-03-16 06:37:07.933667: Epoch time: 41.52 s 
2025-03-16 06:37:07.937170: Yayy! New best EMA pseudo Dice: 0.4950999915599823 
2025-03-16 06:37:08.615723:  
2025-03-16 06:37:08.621256: Epoch 26 
2025-03-16 06:37:08.625764: Current learning rate: 0.00763 
2025-03-16 06:37:50.113525: train_loss -0.5445 
2025-03-16 06:37:50.120038: val_loss -0.4572 
2025-03-16 06:37:50.124551: Pseudo dice [np.float32(0.5448)] 
2025-03-16 06:37:50.127650: Epoch time: 41.5 s 
2025-03-16 06:37:50.131158: Yayy! New best EMA pseudo Dice: 0.5001000165939331 
2025-03-16 06:37:50.847026:  
2025-03-16 06:37:50.852117: Epoch 27 
2025-03-16 06:37:50.856217: Current learning rate: 0.00753 
2025-03-16 06:38:32.346896: train_loss -0.5704 
2025-03-16 06:38:32.352921: val_loss -0.4137 
2025-03-16 06:38:32.356948: Pseudo dice [np.float32(0.5736)] 
2025-03-16 06:38:32.359956: Epoch time: 41.5 s 
2025-03-16 06:38:32.363465: Yayy! New best EMA pseudo Dice: 0.5073999762535095 
2025-03-16 06:38:33.099646:  
2025-03-16 06:38:33.105191: Epoch 28 
2025-03-16 06:38:33.110350: Current learning rate: 0.00744 
2025-03-16 06:39:14.600612: train_loss -0.5405 
2025-03-16 06:39:14.606640: val_loss -0.4533 
2025-03-16 06:39:14.609727: Pseudo dice [np.float32(0.5159)] 
2025-03-16 06:39:14.613238: Epoch time: 41.5 s 
2025-03-16 06:39:14.616773: Yayy! New best EMA pseudo Dice: 0.5083000063896179 
2025-03-16 06:39:15.475964:  
2025-03-16 06:39:15.481500: Epoch 29 
2025-03-16 06:39:15.485011: Current learning rate: 0.00735 
2025-03-16 06:39:56.969727: train_loss -0.545 
2025-03-16 06:39:56.976810: val_loss -0.4417 
2025-03-16 06:39:56.980384: Pseudo dice [np.float32(0.5573)] 
2025-03-16 06:39:56.983436: Epoch time: 41.49 s 
2025-03-16 06:39:56.986989: Yayy! New best EMA pseudo Dice: 0.5131999850273132 
2025-03-16 06:39:57.679563:  
2025-03-16 06:39:57.684627: Epoch 30 
2025-03-16 06:39:57.689228: Current learning rate: 0.00725 
2025-03-16 06:40:39.153144: train_loss -0.5657 
2025-03-16 06:40:39.159752: val_loss -0.4377 
2025-03-16 06:40:39.162786: Pseudo dice [np.float32(0.5099)] 
2025-03-16 06:40:39.166816: Epoch time: 41.47 s 
2025-03-16 06:40:39.691279:  
2025-03-16 06:40:39.697310: Epoch 31 
2025-03-16 06:40:39.701367: Current learning rate: 0.00716 
2025-03-16 06:41:21.203288: train_loss -0.5645 
2025-03-16 06:41:21.209806: val_loss -0.5101 
2025-03-16 06:41:21.214819: Pseudo dice [np.float32(0.5595)] 
2025-03-16 06:41:21.218326: Epoch time: 41.51 s 
2025-03-16 06:41:21.221333: Yayy! New best EMA pseudo Dice: 0.5174999833106995 
2025-03-16 06:41:21.901931:  
2025-03-16 06:41:21.910022: Epoch 32 
2025-03-16 06:41:21.913615: Current learning rate: 0.00707 
2025-03-16 06:42:03.403443: train_loss -0.5773 
2025-03-16 06:42:03.411140: val_loss -0.5486 
2025-03-16 06:42:03.413739: Pseudo dice [np.float32(0.5805)] 
2025-03-16 06:42:03.417783: Epoch time: 41.5 s 
2025-03-16 06:42:03.421348: Yayy! New best EMA pseudo Dice: 0.5238000154495239 
2025-03-16 06:42:04.151303:  
2025-03-16 06:42:04.157311: Epoch 33 
2025-03-16 06:42:04.161323: Current learning rate: 0.00697 
2025-03-16 06:42:45.660597: train_loss -0.5715 
2025-03-16 06:42:45.667125: val_loss -0.5005 
2025-03-16 06:42:45.670637: Pseudo dice [np.float32(0.5678)] 
2025-03-16 06:42:45.674645: Epoch time: 41.51 s 
2025-03-16 06:42:45.679157: Yayy! New best EMA pseudo Dice: 0.5281999707221985 
2025-03-16 06:42:46.366075:  
2025-03-16 06:42:46.371092: Epoch 34 
2025-03-16 06:42:46.374611: Current learning rate: 0.00688 
2025-03-16 06:43:27.858412: train_loss -0.5773 
2025-03-16 06:43:27.863925: val_loss -0.5434 
2025-03-16 06:43:27.869974: Pseudo dice [np.float32(0.6333)] 
2025-03-16 06:43:27.874987: Epoch time: 41.49 s 
2025-03-16 06:43:27.878996: Yayy! New best EMA pseudo Dice: 0.5386999845504761 
2025-03-16 06:43:28.636739:  
2025-03-16 06:43:28.643297: Epoch 35 
2025-03-16 06:43:28.645870: Current learning rate: 0.00679 
2025-03-16 06:44:10.138397: train_loss -0.5931 
2025-03-16 06:44:10.143909: val_loss -0.4691 
2025-03-16 06:44:10.147006: Pseudo dice [np.float32(0.5337)] 
2025-03-16 06:44:10.151584: Epoch time: 41.5 s 
2025-03-16 06:44:10.700691:  
2025-03-16 06:44:10.705767: Epoch 36 
2025-03-16 06:44:10.709440: Current learning rate: 0.00669 
2025-03-16 06:44:52.237145: train_loss -0.5593 
2025-03-16 06:44:52.243664: val_loss -0.498 
2025-03-16 06:44:52.246169: Pseudo dice [np.float32(0.5745)] 
2025-03-16 06:44:52.250180: Epoch time: 41.54 s 
2025-03-16 06:44:52.253687: Yayy! New best EMA pseudo Dice: 0.5418999791145325 
2025-03-16 06:44:53.173993:  
2025-03-16 06:44:53.179543: Epoch 37 
2025-03-16 06:44:53.184095: Current learning rate: 0.0066 
2025-03-16 06:45:34.678971: train_loss -0.5751 
2025-03-16 06:45:34.685571: val_loss -0.5468 
2025-03-16 06:45:34.689111: Pseudo dice [np.float32(0.6138)] 
2025-03-16 06:45:34.692168: Epoch time: 41.5 s 
2025-03-16 06:45:34.695193: Yayy! New best EMA pseudo Dice: 0.5490999817848206 
2025-03-16 06:45:35.384620:  
2025-03-16 06:45:35.390236: Epoch 38 
2025-03-16 06:45:35.393744: Current learning rate: 0.0065 
2025-03-16 06:46:16.897449: train_loss -0.5979 
2025-03-16 06:46:16.904487: val_loss -0.4699 
2025-03-16 06:46:16.907998: Pseudo dice [np.float32(0.5942)] 
2025-03-16 06:46:16.911503: Epoch time: 41.51 s 
2025-03-16 06:46:16.914511: Yayy! New best EMA pseudo Dice: 0.553600013256073 
2025-03-16 06:46:17.610172:  
2025-03-16 06:46:17.616194: Epoch 39 
2025-03-16 06:46:17.620248: Current learning rate: 0.00641 
2025-03-16 06:46:59.114725: train_loss -0.5922 
2025-03-16 06:46:59.122250: val_loss -0.4851 
2025-03-16 06:46:59.125758: Pseudo dice [np.float32(0.5742)] 
2025-03-16 06:46:59.129264: Epoch time: 41.51 s 
2025-03-16 06:46:59.132270: Yayy! New best EMA pseudo Dice: 0.5555999875068665 
2025-03-16 06:46:59.839687:  
2025-03-16 06:46:59.845272: Epoch 40 
2025-03-16 06:46:59.847810: Current learning rate: 0.00631 
2025-03-16 06:47:41.350105: train_loss -0.5774 
2025-03-16 06:47:41.355617: val_loss -0.6051 
2025-03-16 06:47:41.359645: Pseudo dice [np.float32(0.6395)] 
2025-03-16 06:47:41.363173: Epoch time: 41.51 s 
2025-03-16 06:47:41.366695: Yayy! New best EMA pseudo Dice: 0.5640000104904175 
2025-03-16 06:47:42.219168:  
2025-03-16 06:47:42.224679: Epoch 41 
2025-03-16 06:47:42.228189: Current learning rate: 0.00622 
2025-03-16 06:48:23.729247: train_loss -0.5675 
2025-03-16 06:48:23.736790: val_loss -0.4994 
2025-03-16 06:48:23.739850: Pseudo dice [np.float32(0.5275)] 
2025-03-16 06:48:23.743357: Epoch time: 41.51 s 
2025-03-16 06:48:24.271390:  
2025-03-16 06:48:24.278973: Epoch 42 
2025-03-16 06:48:24.283069: Current learning rate: 0.00612 
2025-03-16 06:49:05.783273: train_loss -0.6016 
2025-03-16 06:49:05.788802: val_loss -0.5274 
2025-03-16 06:49:05.793338: Pseudo dice [np.float32(0.5984)] 
2025-03-16 06:49:05.795869: Epoch time: 41.51 s 
2025-03-16 06:49:05.799922: Yayy! New best EMA pseudo Dice: 0.5641999840736389 
2025-03-16 06:49:06.536972:  
2025-03-16 06:49:06.543544: Epoch 43 
2025-03-16 06:49:06.548092: Current learning rate: 0.00603 
2025-03-16 06:49:48.026787: train_loss -0.5975 
2025-03-16 06:49:48.033973: val_loss -0.463 
2025-03-16 06:49:48.038648: Pseudo dice [np.float32(0.5846)] 
2025-03-16 06:49:48.042165: Epoch time: 41.49 s 
2025-03-16 06:49:48.045450: Yayy! New best EMA pseudo Dice: 0.5662000179290771 
2025-03-16 06:49:48.767945:  
2025-03-16 06:49:48.773992: Epoch 44 
2025-03-16 06:49:48.777608: Current learning rate: 0.00593 
2025-03-16 06:50:30.259645: train_loss -0.61 
2025-03-16 06:50:30.265669: val_loss -0.4871 
2025-03-16 06:50:30.269479: Pseudo dice [np.float32(0.5954)] 
2025-03-16 06:50:30.271990: Epoch time: 41.49 s 
2025-03-16 06:50:30.276132: Yayy! New best EMA pseudo Dice: 0.569100022315979 
2025-03-16 06:50:31.153980:  
2025-03-16 06:50:31.160535: Epoch 45 
2025-03-16 06:50:31.164041: Current learning rate: 0.00584 
2025-03-16 06:51:12.659061: train_loss -0.6323 
2025-03-16 06:51:12.665098: val_loss -0.4685 
2025-03-16 06:51:12.668256: Pseudo dice [np.float32(0.5748)] 
2025-03-16 06:51:12.671803: Epoch time: 41.51 s 
2025-03-16 06:51:12.675342: Yayy! New best EMA pseudo Dice: 0.5697000026702881 
2025-03-16 06:51:13.362610:  
2025-03-16 06:51:13.367621: Epoch 46 
2025-03-16 06:51:13.371129: Current learning rate: 0.00574 
2025-03-16 06:51:54.870971: train_loss -0.6326 
2025-03-16 06:51:54.877050: val_loss -0.5425 
2025-03-16 06:51:54.880081: Pseudo dice [np.float32(0.6102)] 
2025-03-16 06:51:54.884091: Epoch time: 41.51 s 
2025-03-16 06:51:54.887599: Yayy! New best EMA pseudo Dice: 0.5737000107765198 
2025-03-16 06:51:55.567177:  
2025-03-16 06:51:55.573792: Epoch 47 
2025-03-16 06:51:55.577337: Current learning rate: 0.00565 
2025-03-16 06:52:37.051878: train_loss -0.6349 
2025-03-16 06:52:37.058421: val_loss -0.4988 
2025-03-16 06:52:37.061980: Pseudo dice [np.float32(0.6012)] 
2025-03-16 06:52:37.065491: Epoch time: 41.48 s 
2025-03-16 06:52:37.069505: Yayy! New best EMA pseudo Dice: 0.5764999985694885 
2025-03-16 06:52:37.778313:  
2025-03-16 06:52:37.784388: Epoch 48 
2025-03-16 06:52:37.789004: Current learning rate: 0.00555 
2025-03-16 06:53:19.299839: train_loss -0.6064 
2025-03-16 06:53:19.309863: val_loss -0.5321 
2025-03-16 06:53:19.314374: Pseudo dice [np.float32(0.6001)] 
2025-03-16 06:53:19.317383: Epoch time: 41.52 s 
2025-03-16 06:53:19.320895: Yayy! New best EMA pseudo Dice: 0.5788999795913696 
2025-03-16 06:53:20.044162:  
2025-03-16 06:53:20.049695: Epoch 49 
2025-03-16 06:53:20.053795: Current learning rate: 0.00546 
2025-03-16 06:54:01.548766: train_loss -0.6404 
2025-03-16 06:54:01.555290: val_loss -0.4844 
2025-03-16 06:54:01.557794: Pseudo dice [np.float32(0.5572)] 
2025-03-16 06:54:01.561804: Epoch time: 41.51 s 
2025-03-16 06:54:02.234532:  
2025-03-16 06:54:02.240088: Epoch 50 
2025-03-16 06:54:02.243699: Current learning rate: 0.00536 
2025-03-16 06:54:43.711737: train_loss -0.6138 
2025-03-16 06:54:43.719359: val_loss -0.5731 
2025-03-16 06:54:43.723413: Pseudo dice [np.float32(0.6094)] 
2025-03-16 06:54:43.726961: Epoch time: 41.48 s 
2025-03-16 06:54:43.729998: Yayy! New best EMA pseudo Dice: 0.5799999833106995 
2025-03-16 06:54:44.460745:  
2025-03-16 06:54:44.466808: Epoch 51 
2025-03-16 06:54:44.470366: Current learning rate: 0.00526 
2025-03-16 06:55:25.966236: train_loss -0.5947 
2025-03-16 06:55:25.972760: val_loss -0.5403 
2025-03-16 06:55:25.976880: Pseudo dice [np.float32(0.6113)] 
2025-03-16 06:55:25.979918: Epoch time: 41.51 s 
2025-03-16 06:55:25.983427: Yayy! New best EMA pseudo Dice: 0.5831000208854675 
2025-03-16 06:55:26.671232:  
2025-03-16 06:55:26.677295: Epoch 52 
2025-03-16 06:55:26.680354: Current learning rate: 0.00517 
2025-03-16 06:56:08.174060: train_loss -0.6314 
2025-03-16 06:56:08.180770: val_loss -0.486 
2025-03-16 06:56:08.184465: Pseudo dice [np.float32(0.6041)] 
2025-03-16 06:56:08.188528: Epoch time: 41.5 s 
2025-03-16 06:56:08.192109: Yayy! New best EMA pseudo Dice: 0.5852000117301941 
2025-03-16 06:56:09.081614:  
2025-03-16 06:56:09.088667: Epoch 53 
2025-03-16 06:56:09.092675: Current learning rate: 0.00507 
2025-03-16 06:56:50.582446: train_loss -0.6376 
2025-03-16 06:56:50.589688: val_loss -0.4567 
2025-03-16 06:56:50.593261: Pseudo dice [np.float32(0.5717)] 
2025-03-16 06:56:50.596813: Epoch time: 41.5 s 
2025-03-16 06:56:51.118970:  
2025-03-16 06:56:51.124528: Epoch 54 
2025-03-16 06:56:51.129612: Current learning rate: 0.00497 
2025-03-16 06:57:32.636597: train_loss -0.6184 
2025-03-16 06:57:32.644116: val_loss -0.5185 
2025-03-16 06:57:32.649128: Pseudo dice [np.float32(0.5806)] 
2025-03-16 06:57:32.652637: Epoch time: 41.52 s 
2025-03-16 06:57:33.169209:  
2025-03-16 06:57:33.175739: Epoch 55 
2025-03-16 06:57:33.180290: Current learning rate: 0.00487 
2025-03-16 06:58:14.665952: train_loss -0.5962 
2025-03-16 06:58:14.670523: val_loss -0.4472 
2025-03-16 06:58:14.675735: Pseudo dice [np.float32(0.5443)] 
2025-03-16 06:58:14.678782: Epoch time: 41.5 s 
2025-03-16 06:58:15.200520:  
2025-03-16 06:58:15.205531: Epoch 56 
2025-03-16 06:58:15.210041: Current learning rate: 0.00478 
2025-03-16 06:58:56.676443: train_loss -0.6359 
2025-03-16 06:58:56.683963: val_loss -0.5295 
2025-03-16 06:58:56.687973: Pseudo dice [np.float32(0.6227)] 
2025-03-16 06:58:56.693020: Epoch time: 41.48 s 
2025-03-16 06:58:57.211723:  
2025-03-16 06:58:57.219240: Epoch 57 
2025-03-16 06:58:57.223250: Current learning rate: 0.00468 
2025-03-16 06:59:38.703679: train_loss -0.6241 
2025-03-16 06:59:38.711207: val_loss -0.4689 
2025-03-16 06:59:38.716227: Pseudo dice [np.float32(0.549)] 
2025-03-16 06:59:38.720245: Epoch time: 41.49 s 
2025-03-16 06:59:39.288685:  
2025-03-16 06:59:39.295206: Epoch 58 
2025-03-16 06:59:39.299216: Current learning rate: 0.00458 
2025-03-16 07:00:20.775392: train_loss -0.6533 
2025-03-16 07:00:20.781912: val_loss -0.4994 
2025-03-16 07:00:20.785921: Pseudo dice [np.float32(0.6337)] 
2025-03-16 07:00:20.789430: Epoch time: 41.49 s 
2025-03-16 07:00:20.793439: Yayy! New best EMA pseudo Dice: 0.5856999754905701 
2025-03-16 07:00:21.535994:  
2025-03-16 07:00:21.542617: Epoch 59 
2025-03-16 07:00:21.546696: Current learning rate: 0.00448 
2025-03-16 07:01:03.042508: train_loss -0.6464 
2025-03-16 07:01:03.049586: val_loss -0.5175 
2025-03-16 07:01:03.054155: Pseudo dice [np.float32(0.6252)] 
2025-03-16 07:01:03.058187: Epoch time: 41.51 s 
2025-03-16 07:01:03.061741: Yayy! New best EMA pseudo Dice: 0.5896999835968018 
2025-03-16 07:01:03.794206:  
2025-03-16 07:01:03.800748: Epoch 60 
2025-03-16 07:01:03.805278: Current learning rate: 0.00438 
2025-03-16 07:01:45.289550: train_loss -0.6762 
2025-03-16 07:01:45.298072: val_loss -0.5334 
2025-03-16 07:01:45.303116: Pseudo dice [np.float32(0.6051)] 
2025-03-16 07:01:45.307125: Epoch time: 41.5 s 
2025-03-16 07:01:45.310634: Yayy! New best EMA pseudo Dice: 0.5911999940872192 
2025-03-16 07:01:46.190347:  
2025-03-16 07:01:46.196971: Epoch 61 
2025-03-16 07:01:46.202033: Current learning rate: 0.00429 
2025-03-16 07:02:27.684806: train_loss -0.5702 
2025-03-16 07:02:27.690924: val_loss -0.5039 
2025-03-16 07:02:27.695483: Pseudo dice [np.float32(0.5381)] 
2025-03-16 07:02:27.699546: Epoch time: 41.5 s 
2025-03-16 07:02:28.234647:  
2025-03-16 07:02:28.240161: Epoch 62 
2025-03-16 07:02:28.245173: Current learning rate: 0.00419 
2025-03-16 07:03:09.729804: train_loss -0.6241 
2025-03-16 07:03:09.735363: val_loss -0.5696 
2025-03-16 07:03:09.740478: Pseudo dice [np.float32(0.6716)] 
2025-03-16 07:03:09.745038: Epoch time: 41.5 s 
2025-03-16 07:03:09.748103: Yayy! New best EMA pseudo Dice: 0.5945000052452087 
2025-03-16 07:03:10.450572:  
2025-03-16 07:03:10.455657: Epoch 63 
2025-03-16 07:03:10.459192: Current learning rate: 0.00409 
2025-03-16 07:03:51.945006: train_loss -0.6215 
2025-03-16 07:03:51.950057: val_loss -0.5148 
2025-03-16 07:03:51.955172: Pseudo dice [np.float32(0.6361)] 
2025-03-16 07:03:51.957711: Epoch time: 41.49 s 
2025-03-16 07:03:51.962288: Yayy! New best EMA pseudo Dice: 0.5985999703407288 
2025-03-16 07:03:52.667853:  
2025-03-16 07:03:52.673913: Epoch 64 
2025-03-16 07:03:52.676971: Current learning rate: 0.00399 
2025-03-16 07:04:34.170921: train_loss -0.6239 
2025-03-16 07:04:34.177513: val_loss -0.5117 
2025-03-16 07:04:34.181625: Pseudo dice [np.float32(0.6252)] 
2025-03-16 07:04:34.184721: Epoch time: 41.5 s 
2025-03-16 07:04:34.189775: Yayy! New best EMA pseudo Dice: 0.6013000011444092 
2025-03-16 07:04:34.898025:  
2025-03-16 07:04:34.903542: Epoch 65 
2025-03-16 07:04:34.908555: Current learning rate: 0.00389 
2025-03-16 07:05:16.382509: train_loss -0.6594 
2025-03-16 07:05:16.389102: val_loss -0.5054 
2025-03-16 07:05:16.392656: Pseudo dice [np.float32(0.5777)] 
2025-03-16 07:05:16.396194: Epoch time: 41.49 s 
2025-03-16 07:05:16.945907:  
2025-03-16 07:05:16.951453: Epoch 66 
2025-03-16 07:05:16.956529: Current learning rate: 0.00379 
2025-03-16 07:05:58.451743: train_loss -0.6657 
2025-03-16 07:05:58.458846: val_loss -0.5117 
2025-03-16 07:05:58.461878: Pseudo dice [np.float32(0.6609)] 
2025-03-16 07:05:58.466423: Epoch time: 41.51 s 
2025-03-16 07:05:58.469459: Yayy! New best EMA pseudo Dice: 0.6050999760627747 
2025-03-16 07:05:59.221808:  
2025-03-16 07:05:59.228887: Epoch 67 
2025-03-16 07:05:59.232463: Current learning rate: 0.00369 
2025-03-16 07:06:40.703592: train_loss -0.6477 
2025-03-16 07:06:40.709382: val_loss -0.5116 
2025-03-16 07:06:40.713390: Pseudo dice [np.float32(0.6012)] 
2025-03-16 07:06:40.716896: Epoch time: 41.48 s 
2025-03-16 07:06:41.258427:  
2025-03-16 07:06:41.264442: Epoch 68 
2025-03-16 07:06:41.268454: Current learning rate: 0.00359 
2025-03-16 07:07:22.773163: train_loss -0.6502 
2025-03-16 07:07:22.779793: val_loss -0.4754 
2025-03-16 07:07:22.783831: Pseudo dice [np.float32(0.5879)] 
2025-03-16 07:07:22.787843: Epoch time: 41.52 s 
2025-03-16 07:07:23.476174:  
2025-03-16 07:07:23.483274: Epoch 69 
2025-03-16 07:07:23.487827: Current learning rate: 0.00349 
2025-03-16 07:08:04.954313: train_loss -0.6741 
2025-03-16 07:08:04.960931: val_loss -0.5232 
2025-03-16 07:08:04.964493: Pseudo dice [np.float32(0.6383)] 
2025-03-16 07:08:04.969031: Epoch time: 41.48 s 
2025-03-16 07:08:04.972543: Yayy! New best EMA pseudo Dice: 0.6065999865531921 
2025-03-16 07:08:05.677681:  
2025-03-16 07:08:05.682727: Epoch 70 
2025-03-16 07:08:05.687339: Current learning rate: 0.00338 
2025-03-16 07:08:47.182455: train_loss -0.6715 
2025-03-16 07:08:47.188551: val_loss -0.5385 
2025-03-16 07:08:47.192665: Pseudo dice [np.float32(0.6232)] 
2025-03-16 07:08:47.196266: Epoch time: 41.51 s 
2025-03-16 07:08:47.199807: Yayy! New best EMA pseudo Dice: 0.608299970626831 
2025-03-16 07:08:47.903561:  
2025-03-16 07:08:47.909632: Epoch 71 
2025-03-16 07:08:47.913826: Current learning rate: 0.00328 
2025-03-16 07:09:29.394885: train_loss -0.6251 
2025-03-16 07:09:29.400902: val_loss -0.5863 
2025-03-16 07:09:29.404911: Pseudo dice [np.float32(0.6037)] 
2025-03-16 07:09:29.408419: Epoch time: 41.49 s 
2025-03-16 07:09:29.959719:  
2025-03-16 07:09:29.965232: Epoch 72 
2025-03-16 07:09:29.970288: Current learning rate: 0.00318 
2025-03-16 07:10:11.448725: train_loss -0.6662 
2025-03-16 07:10:11.455804: val_loss -0.5416 
2025-03-16 07:10:11.460840: Pseudo dice [np.float32(0.6615)] 
2025-03-16 07:10:11.466362: Epoch time: 41.49 s 
2025-03-16 07:10:11.469869: Yayy! New best EMA pseudo Dice: 0.6132000088691711 
2025-03-16 07:10:12.270328:  
2025-03-16 07:10:12.277176: Epoch 73 
2025-03-16 07:10:12.281188: Current learning rate: 0.00308 
2025-03-16 07:10:53.788091: train_loss -0.6529 
2025-03-16 07:10:53.794664: val_loss -0.5124 
2025-03-16 07:10:53.799174: Pseudo dice [np.float32(0.5979)] 
2025-03-16 07:10:53.803185: Epoch time: 41.52 s 
2025-03-16 07:10:54.343194:  
2025-03-16 07:10:54.349250: Epoch 74 
2025-03-16 07:10:54.354261: Current learning rate: 0.00297 
2025-03-16 07:11:35.837292: train_loss -0.6513 
2025-03-16 07:11:35.845868: val_loss -0.529 
2025-03-16 07:11:35.850883: Pseudo dice [np.float32(0.5817)] 
2025-03-16 07:11:35.855896: Epoch time: 41.49 s 
2025-03-16 07:11:36.397581:  
2025-03-16 07:11:36.403092: Epoch 75 
2025-03-16 07:11:36.406604: Current learning rate: 0.00287 
2025-03-16 07:12:17.920044: train_loss -0.6666 
2025-03-16 07:12:17.927088: val_loss -0.4559 
2025-03-16 07:12:17.931142: Pseudo dice [np.float32(0.6208)] 
2025-03-16 07:12:17.934679: Epoch time: 41.52 s 
2025-03-16 07:12:18.485049:  
2025-03-16 07:12:18.491063: Epoch 76 
2025-03-16 07:12:18.495070: Current learning rate: 0.00277 
2025-03-16 07:12:59.999281: train_loss -0.6357 
2025-03-16 07:13:00.006428: val_loss -0.4528 
2025-03-16 07:13:00.011888: Pseudo dice [np.float32(0.5915)] 
2025-03-16 07:13:00.017905: Epoch time: 41.51 s 
2025-03-16 07:13:00.702252:  
2025-03-16 07:13:00.710391: Epoch 77 
2025-03-16 07:13:00.715178: Current learning rate: 0.00266 
2025-03-16 07:13:42.210295: train_loss -0.6909 
2025-03-16 07:13:42.216811: val_loss -0.4847 
2025-03-16 07:13:42.220823: Pseudo dice [np.float32(0.6754)] 
2025-03-16 07:13:42.224335: Epoch time: 41.51 s 
2025-03-16 07:13:42.228344: Yayy! New best EMA pseudo Dice: 0.614799976348877 
2025-03-16 07:13:42.928403:  
2025-03-16 07:13:42.934454: Epoch 78 
2025-03-16 07:13:42.939085: Current learning rate: 0.00256 
2025-03-16 07:14:24.447474: train_loss -0.6761 
2025-03-16 07:14:24.456015: val_loss -0.5173 
2025-03-16 07:14:24.460039: Pseudo dice [np.float32(0.6585)] 
2025-03-16 07:14:24.464046: Epoch time: 41.52 s 
2025-03-16 07:14:24.468555: Yayy! New best EMA pseudo Dice: 0.6190999746322632 
2025-03-16 07:14:25.175865:  
2025-03-16 07:14:25.183419: Epoch 79 
2025-03-16 07:14:25.187433: Current learning rate: 0.00245 
2025-03-16 07:15:06.687745: train_loss -0.6958 
2025-03-16 07:15:06.694307: val_loss -0.5326 
2025-03-16 07:15:06.697814: Pseudo dice [np.float32(0.6697)] 
2025-03-16 07:15:06.701826: Epoch time: 41.51 s 
2025-03-16 07:15:06.705836: Yayy! New best EMA pseudo Dice: 0.6241999864578247 
2025-03-16 07:15:07.422335:  
2025-03-16 07:15:07.428347: Epoch 80 
2025-03-16 07:15:07.432353: Current learning rate: 0.00235 
2025-03-16 07:15:48.946125: train_loss -0.6927 
2025-03-16 07:15:48.953664: val_loss -0.4175 
2025-03-16 07:15:48.960245: Pseudo dice [np.float32(0.5794)] 
2025-03-16 07:15:48.964740: Epoch time: 41.52 s 
2025-03-16 07:15:49.526664:  
2025-03-16 07:15:49.532177: Epoch 81 
2025-03-16 07:15:49.536799: Current learning rate: 0.00224 
2025-03-16 07:16:31.046753: train_loss -0.698 
2025-03-16 07:16:31.053267: val_loss -0.552 
2025-03-16 07:16:31.058280: Pseudo dice [np.float32(0.6392)] 
2025-03-16 07:16:31.061791: Epoch time: 41.52 s 
2025-03-16 07:16:31.611632:  
2025-03-16 07:16:31.618751: Epoch 82 
2025-03-16 07:16:31.623300: Current learning rate: 0.00214 
2025-03-16 07:17:13.135437: train_loss -0.6762 
2025-03-16 07:17:13.143068: val_loss -0.5736 
2025-03-16 07:17:13.145625: Pseudo dice [np.float32(0.6661)] 
2025-03-16 07:17:13.150686: Epoch time: 41.52 s 
2025-03-16 07:17:13.154791: Yayy! New best EMA pseudo Dice: 0.6261000037193298 
2025-03-16 07:17:13.836940:  
2025-03-16 07:17:13.842968: Epoch 83 
2025-03-16 07:17:13.847535: Current learning rate: 0.00203 
2025-03-16 07:17:55.346991: train_loss -0.686 
2025-03-16 07:17:55.353506: val_loss -0.5854 
2025-03-16 07:17:55.357519: Pseudo dice [np.float32(0.6725)] 
2025-03-16 07:17:55.362032: Epoch time: 41.51 s 
2025-03-16 07:17:55.366042: Yayy! New best EMA pseudo Dice: 0.6306999921798706 
2025-03-16 07:17:56.194622:  
2025-03-16 07:17:56.202137: Epoch 84 
2025-03-16 07:17:56.206146: Current learning rate: 0.00192 
2025-03-16 07:18:37.702816: train_loss -0.7181 
2025-03-16 07:18:37.710437: val_loss -0.5618 
2025-03-16 07:18:37.715448: Pseudo dice [np.float32(0.6726)] 
2025-03-16 07:18:37.720458: Epoch time: 41.51 s 
2025-03-16 07:18:37.725474: Yayy! New best EMA pseudo Dice: 0.6348999738693237 
2025-03-16 07:18:38.398875:  
2025-03-16 07:18:38.406000: Epoch 85 
2025-03-16 07:18:38.411058: Current learning rate: 0.00181 
2025-03-16 07:19:19.898038: train_loss -0.7123 
2025-03-16 07:19:19.905597: val_loss -0.5312 
2025-03-16 07:19:19.910615: Pseudo dice [np.float32(0.6672)] 
2025-03-16 07:19:19.915628: Epoch time: 41.5 s 
2025-03-16 07:19:19.919644: Yayy! New best EMA pseudo Dice: 0.6381000280380249 
2025-03-16 07:19:20.591062:  
2025-03-16 07:19:20.597630: Epoch 86 
2025-03-16 07:19:20.602687: Current learning rate: 0.0017 
2025-03-16 07:20:02.097617: train_loss -0.675 
2025-03-16 07:20:02.104734: val_loss -0.4817 
2025-03-16 07:20:02.109761: Pseudo dice [np.float32(0.6234)] 
2025-03-16 07:20:02.114888: Epoch time: 41.51 s 
2025-03-16 07:20:02.627767:  
2025-03-16 07:20:02.633858: Epoch 87 
2025-03-16 07:20:02.640439: Current learning rate: 0.00159 
2025-03-16 07:20:44.126597: train_loss -0.7129 
2025-03-16 07:20:44.134155: val_loss -0.5046 
2025-03-16 07:20:44.139672: Pseudo dice [np.float32(0.6561)] 
2025-03-16 07:20:44.143182: Epoch time: 41.5 s 
2025-03-16 07:20:44.148192: Yayy! New best EMA pseudo Dice: 0.6385999917984009 
2025-03-16 07:20:44.880427:  
2025-03-16 07:20:44.887486: Epoch 88 
2025-03-16 07:20:44.892538: Current learning rate: 0.00148 
2025-03-16 07:21:26.362579: train_loss -0.7177 
2025-03-16 07:21:26.371597: val_loss -0.4567 
2025-03-16 07:21:26.376105: Pseudo dice [np.float32(0.615)] 
2025-03-16 07:21:26.379114: Epoch time: 41.48 s 
2025-03-16 07:21:26.890635:  
2025-03-16 07:21:26.896149: Epoch 89 
2025-03-16 07:21:26.901162: Current learning rate: 0.00137 
2025-03-16 07:22:08.391373: train_loss -0.6911 
2025-03-16 07:22:08.398387: val_loss -0.4168 
2025-03-16 07:22:08.402398: Pseudo dice [np.float32(0.5953)] 
2025-03-16 07:22:08.405905: Epoch time: 41.5 s 
2025-03-16 07:22:08.924706:  
2025-03-16 07:22:08.930722: Epoch 90 
2025-03-16 07:22:08.934733: Current learning rate: 0.00126 
2025-03-16 07:22:50.409378: train_loss -0.7081 
2025-03-16 07:22:50.415393: val_loss -0.4158 
2025-03-16 07:22:50.419403: Pseudo dice [np.float32(0.6084)] 
2025-03-16 07:22:50.422913: Epoch time: 41.49 s 
2025-03-16 07:22:50.940201:  
2025-03-16 07:22:50.946280: Epoch 91 
2025-03-16 07:22:50.949842: Current learning rate: 0.00115 
2025-03-16 07:23:32.408342: train_loss -0.7127 
2025-03-16 07:23:32.414410: val_loss -0.4563 
2025-03-16 07:23:32.417433: Pseudo dice [np.float32(0.6509)] 
2025-03-16 07:23:32.420941: Epoch time: 41.47 s 
2025-03-16 07:23:33.085178:  
2025-03-16 07:23:33.090691: Epoch 92 
2025-03-16 07:23:33.094199: Current learning rate: 0.00103 
2025-03-16 07:24:14.569395: train_loss -0.7054 
2025-03-16 07:24:14.575485: val_loss -0.4726 
2025-03-16 07:24:14.579061: Pseudo dice [np.float32(0.5827)] 
2025-03-16 07:24:14.581082: Epoch time: 41.49 s 
2025-03-16 07:24:15.108320:  
2025-03-16 07:24:15.112345: Epoch 93 
2025-03-16 07:24:15.115887: Current learning rate: 0.00091 
2025-03-16 07:24:56.567940: train_loss -0.7034 
2025-03-16 07:24:56.573482: val_loss -0.5479 
2025-03-16 07:24:56.577055: Pseudo dice [np.float32(0.6968)] 
2025-03-16 07:24:56.580093: Epoch time: 41.46 s 
2025-03-16 07:24:57.112885:  
2025-03-16 07:24:57.118432: Epoch 94 
2025-03-16 07:24:57.121955: Current learning rate: 0.00079 
2025-03-16 07:25:38.596689: train_loss -0.7251 
2025-03-16 07:25:38.603203: val_loss -0.5067 
2025-03-16 07:25:38.606715: Pseudo dice [np.float32(0.6414)] 
2025-03-16 07:25:38.610723: Epoch time: 41.48 s 
2025-03-16 07:25:39.121184:  
2025-03-16 07:25:39.126205: Epoch 95 
2025-03-16 07:25:39.129740: Current learning rate: 0.00067 
2025-03-16 07:26:20.600620: train_loss -0.7135 
2025-03-16 07:26:20.606512: val_loss -0.498 
2025-03-16 07:26:20.609019: Pseudo dice [np.float32(0.6535)] 
2025-03-16 07:26:20.613030: Epoch time: 41.48 s 
2025-03-16 07:26:21.128330:  
2025-03-16 07:26:21.134383: Epoch 96 
2025-03-16 07:26:21.137819: Current learning rate: 0.00055 
2025-03-16 07:27:02.618431: train_loss -0.7275 
2025-03-16 07:27:02.624950: val_loss -0.4806 
2025-03-16 07:27:02.628461: Pseudo dice [np.float32(0.6562)] 
2025-03-16 07:27:02.631971: Epoch time: 41.49 s 
2025-03-16 07:27:03.158812:  
2025-03-16 07:27:03.164899: Epoch 97 
2025-03-16 07:27:03.168946: Current learning rate: 0.00043 
2025-03-16 07:27:44.676758: train_loss -0.718 
2025-03-16 07:27:44.683299: val_loss -0.5125 
2025-03-16 07:27:44.686918: Pseudo dice [np.float32(0.6335)] 
2025-03-16 07:27:44.690000: Epoch time: 41.52 s 
2025-03-16 07:27:45.217441:  
2025-03-16 07:27:45.224513: Epoch 98 
2025-03-16 07:27:45.228089: Current learning rate: 0.0003 
2025-03-16 07:28:26.691722: train_loss -0.7415 
2025-03-16 07:28:26.699246: val_loss -0.5319 
2025-03-16 07:28:26.703258: Pseudo dice [np.float32(0.7255)] 
2025-03-16 07:28:26.706770: Epoch time: 41.47 s 
2025-03-16 07:28:26.710780: Yayy! New best EMA pseudo Dice: 0.6467999815940857 
2025-03-16 07:28:27.403791:  
2025-03-16 07:28:27.409835: Epoch 99 
2025-03-16 07:28:27.413891: Current learning rate: 0.00016 
2025-03-16 07:29:08.891821: train_loss -0.7438 
2025-03-16 07:29:08.898481: val_loss -0.5297 
2025-03-16 07:29:08.902090: Pseudo dice [np.float32(0.6986)] 
2025-03-16 07:29:08.905137: Epoch time: 41.49 s 
2025-03-16 07:29:08.909197: Yayy! New best EMA pseudo Dice: 0.6520000100135803 
2025-03-16 07:29:09.937381: Training done. 
2025-03-16 07:29:09.965385: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-16 07:29:09.971462: The split file contains 5 splits. 
2025-03-16 07:29:09.976462: Desired fold for training: 0 
2025-03-16 07:29:09.980462: This split has 100 training and 26 validation cases. 
2025-03-16 07:29:09.987462: predicting colon_008 
2025-03-16 07:29:09.993462: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-03-16 07:29:25.701906: predicting colon_027 
2025-03-16 07:29:25.725905: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-03-16 07:29:31.767751: predicting colon_030 
2025-03-16 07:29:31.778750: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-03-16 07:29:40.268973: predicting colon_033 
2025-03-16 07:29:40.285481: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-03-16 07:29:55.335568: predicting colon_041 
2025-03-16 07:29:55.362568: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-03-16 07:30:35.809985: predicting colon_042 
2025-03-16 07:30:35.847497: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-03-16 07:30:56.170956: predicting colon_061 
2025-03-16 07:30:56.197955: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-03-16 07:31:19.730790: predicting colon_074 
2025-03-16 07:31:19.757301: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-03-16 07:31:46.783777: predicting colon_075 
2025-03-16 07:31:46.813777: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-03-16 07:32:01.920396: predicting colon_088 
2025-03-16 07:32:01.943396: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-03-16 07:32:25.451339: predicting colon_091 
2025-03-16 07:32:25.484344: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-03-16 07:32:53.675996: predicting colon_092 
2025-03-16 07:32:53.707505: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-03-16 07:33:17.189203: predicting colon_095 
2025-03-16 07:33:17.214205: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-03-16 07:33:32.306314: predicting colon_102 
2025-03-16 07:33:32.327317: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-03-16 07:34:06.104328: predicting colon_111 
2025-03-16 07:34:06.139330: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-03-16 07:34:15.588489: predicting colon_115 
2025-03-16 07:34:15.609488: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-03-16 07:34:30.682319: predicting colon_118 
2025-03-16 07:34:30.708320: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-03-16 07:34:54.207806: predicting colon_124 
2025-03-16 07:34:54.236806: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-03-16 07:35:17.713484: predicting colon_127 
2025-03-16 07:35:17.741484: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-03-16 07:36:05.003244: predicting colon_154 
2025-03-16 07:36:05.044748: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-03-16 07:36:20.126468: predicting colon_161 
2025-03-16 07:36:20.151977: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-03-16 07:36:35.238233: predicting colon_162 
2025-03-16 07:36:35.264740: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-03-16 07:37:15.758528: predicting colon_165 
2025-03-16 07:37:15.796035: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-03-16 07:37:49.554528: predicting colon_166 
2025-03-16 07:37:49.587528: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-03-16 07:38:04.692010: predicting colon_169 
2025-03-16 07:38:04.717012: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-03-16 07:38:52.024025: predicting colon_187 
2025-03-16 07:38:52.071532: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-03-16 07:39:25.072098: Validation complete 
2025-03-16 07:39:25.079098: Mean Validation Dice:  0.22528071990178647 
