
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-17 04:06:50.058257: do_dummy_2d_data_aug: True 
2025-03-17 04:06:50.064256: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-17 04:06:50.072257: The split file contains 5 splits. 
2025-03-17 04:06:50.074255: Desired fold for training: 0 
2025-03-17 04:06:50.077256: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-03-17 04:06:57.142049: unpacking dataset... 
2025-03-17 04:06:57.395479: unpacking done... 
2025-03-17 04:07:00.490786:  
2025-03-17 04:07:00.495806: Epoch 0 
2025-03-17 04:07:00.499315: Current learning rate: 0.01 
2025-03-17 04:07:46.648321: train_loss 0.0699 
2025-03-17 04:07:46.653331: val_loss 0.0035 
2025-03-17 04:07:46.656838: Pseudo dice [np.float32(0.0)] 
2025-03-17 04:07:46.660343: Epoch time: 46.16 s 
2025-03-17 04:07:46.663373: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-17 04:07:47.338515:  
2025-03-17 04:07:47.344028: Epoch 1 
2025-03-17 04:07:47.347536: Current learning rate: 0.00991 
2025-03-17 04:08:28.821371: train_loss -0.0569 
2025-03-17 04:08:28.827432: val_loss -0.0997 
2025-03-17 04:08:28.831467: Pseudo dice [np.float32(0.0)] 
2025-03-17 04:08:28.834491: Epoch time: 41.48 s 
2025-03-17 04:08:29.403113:  
2025-03-17 04:08:29.409146: Epoch 2 
2025-03-17 04:08:29.412175: Current learning rate: 0.00982 
2025-03-17 04:09:10.853891: train_loss -0.1739 
2025-03-17 04:09:10.860411: val_loss -0.2436 
2025-03-17 04:09:10.863925: Pseudo dice [np.float32(0.3446)] 
2025-03-17 04:09:10.866965: Epoch time: 41.45 s 
2025-03-17 04:09:10.870478: Yayy! New best EMA pseudo Dice: 0.03449999913573265 
2025-03-17 04:09:11.645991:  
2025-03-17 04:09:11.652642: Epoch 3 
2025-03-17 04:09:11.655192: Current learning rate: 0.00973 
2025-03-17 04:09:53.092214: train_loss -0.2854 
2025-03-17 04:09:53.098266: val_loss -0.2168 
2025-03-17 04:09:53.100773: Pseudo dice [np.float32(0.3191)] 
2025-03-17 04:09:53.104784: Epoch time: 41.45 s 
2025-03-17 04:09:53.107290: Yayy! New best EMA pseudo Dice: 0.06289999932050705 
2025-03-17 04:09:53.870176:  
2025-03-17 04:09:53.875728: Epoch 4 
2025-03-17 04:09:53.879774: Current learning rate: 0.00964 
2025-03-17 04:10:35.294285: train_loss -0.3138 
2025-03-17 04:10:35.299311: val_loss -0.3089 
2025-03-17 04:10:35.302828: Pseudo dice [np.float32(0.3759)] 
2025-03-17 04:10:35.305987: Epoch time: 41.42 s 
2025-03-17 04:10:35.309493: Yayy! New best EMA pseudo Dice: 0.094200000166893 
2025-03-17 04:10:36.213796:  
2025-03-17 04:10:36.218912: Epoch 5 
2025-03-17 04:10:36.222510: Current learning rate: 0.00955 
2025-03-17 04:11:17.664948: train_loss -0.3568 
2025-03-17 04:11:17.671116: val_loss -0.3151 
2025-03-17 04:11:17.674418: Pseudo dice [np.float32(0.4021)] 
2025-03-17 04:11:17.677979: Epoch time: 41.45 s 
2025-03-17 04:11:17.680515: Yayy! New best EMA pseudo Dice: 0.125 
2025-03-17 04:11:18.436124:  
2025-03-17 04:11:18.441686: Epoch 6 
2025-03-17 04:11:18.444731: Current learning rate: 0.00946 
2025-03-17 04:11:59.864659: train_loss -0.3765 
2025-03-17 04:11:59.868174: val_loss -0.3531 
2025-03-17 04:11:59.872190: Pseudo dice [np.float32(0.4432)] 
2025-03-17 04:11:59.874701: Epoch time: 41.43 s 
2025-03-17 04:11:59.878211: Yayy! New best EMA pseudo Dice: 0.15680000185966492 
2025-03-17 04:12:00.652332:  
2025-03-17 04:12:00.657851: Epoch 7 
2025-03-17 04:12:00.660400: Current learning rate: 0.00937 
2025-03-17 04:12:42.071672: train_loss -0.3952 
2025-03-17 04:12:42.077695: val_loss -0.3594 
2025-03-17 04:12:42.081709: Pseudo dice [np.float32(0.42)] 
2025-03-17 04:12:42.084216: Epoch time: 41.42 s 
2025-03-17 04:12:42.088249: Yayy! New best EMA pseudo Dice: 0.18310000002384186 
2025-03-17 04:12:42.879670:  
2025-03-17 04:12:42.885185: Epoch 8 
2025-03-17 04:12:42.889696: Current learning rate: 0.00928 
2025-03-17 04:13:24.321829: train_loss -0.3384 
2025-03-17 04:13:24.327856: val_loss -0.3755 
2025-03-17 04:13:24.331486: Pseudo dice [np.float32(0.4318)] 
2025-03-17 04:13:24.334513: Epoch time: 41.44 s 
2025-03-17 04:13:24.337021: Yayy! New best EMA pseudo Dice: 0.20800000429153442 
2025-03-17 04:13:25.104848:  
2025-03-17 04:13:25.110963: Epoch 9 
2025-03-17 04:13:25.114017: Current learning rate: 0.00919 
2025-03-17 04:14:06.520082: train_loss -0.3558 
2025-03-17 04:14:06.527598: val_loss -0.3577 
2025-03-17 04:14:06.531107: Pseudo dice [np.float32(0.3954)] 
2025-03-17 04:14:06.533615: Epoch time: 41.42 s 
2025-03-17 04:14:06.537621: Yayy! New best EMA pseudo Dice: 0.22679999470710754 
2025-03-17 04:14:07.306545:  
2025-03-17 04:14:07.313190: Epoch 10 
2025-03-17 04:14:07.315729: Current learning rate: 0.0091 
2025-03-17 04:14:48.736503: train_loss -0.4121 
2025-03-17 04:14:48.742517: val_loss -0.4319 
2025-03-17 04:14:48.746021: Pseudo dice [np.float32(0.4783)] 
2025-03-17 04:14:48.749031: Epoch time: 41.43 s 
2025-03-17 04:14:48.752540: Yayy! New best EMA pseudo Dice: 0.25189998745918274 
2025-03-17 04:14:49.509029:  
2025-03-17 04:14:49.514063: Epoch 11 
2025-03-17 04:14:49.518116: Current learning rate: 0.009 
2025-03-17 04:15:30.931446: train_loss -0.4324 
2025-03-17 04:15:30.938071: val_loss -0.3535 
2025-03-17 04:15:30.941225: Pseudo dice [np.float32(0.4011)] 
2025-03-17 04:15:30.944794: Epoch time: 41.42 s 
2025-03-17 04:15:30.947851: Yayy! New best EMA pseudo Dice: 0.2667999863624573 
2025-03-17 04:15:31.680507:  
2025-03-17 04:15:31.687523: Epoch 12 
2025-03-17 04:15:31.690030: Current learning rate: 0.00891 
2025-03-17 04:16:13.102147: train_loss -0.4588 
2025-03-17 04:16:13.108660: val_loss -0.4755 
2025-03-17 04:16:13.112172: Pseudo dice [np.float32(0.5529)] 
2025-03-17 04:16:13.116186: Epoch time: 41.42 s 
2025-03-17 04:16:13.119697: Yayy! New best EMA pseudo Dice: 0.2953999936580658 
2025-03-17 04:16:14.078647:  
2025-03-17 04:16:14.083672: Epoch 13 
2025-03-17 04:16:14.087216: Current learning rate: 0.00882 
2025-03-17 04:16:55.477602: train_loss -0.443 
2025-03-17 04:16:55.484708: val_loss -0.3974 
2025-03-17 04:16:55.488724: Pseudo dice [np.float32(0.4489)] 
2025-03-17 04:16:55.491765: Epoch time: 41.4 s 
2025-03-17 04:16:55.494775: Yayy! New best EMA pseudo Dice: 0.3107999861240387 
2025-03-17 04:16:56.267042:  
2025-03-17 04:16:56.271698: Epoch 14 
2025-03-17 04:16:56.276259: Current learning rate: 0.00873 
2025-03-17 04:17:37.669078: train_loss -0.4121 
2025-03-17 04:17:37.675186: val_loss -0.4107 
2025-03-17 04:17:37.677719: Pseudo dice [np.float32(0.423)] 
2025-03-17 04:17:37.681758: Epoch time: 41.4 s 
2025-03-17 04:17:37.684811: Yayy! New best EMA pseudo Dice: 0.32199999690055847 
2025-03-17 04:17:38.474257:  
2025-03-17 04:17:38.479269: Epoch 15 
2025-03-17 04:17:38.482778: Current learning rate: 0.00864 
2025-03-17 04:18:19.879498: train_loss -0.3961 
2025-03-17 04:18:19.886170: val_loss -0.4375 
2025-03-17 04:18:19.889733: Pseudo dice [np.float32(0.5292)] 
2025-03-17 04:18:19.893349: Epoch time: 41.41 s 
2025-03-17 04:18:19.896408: Yayy! New best EMA pseudo Dice: 0.3427000045776367 
2025-03-17 04:18:20.700454:  
2025-03-17 04:18:20.706528: Epoch 16 
2025-03-17 04:18:20.710665: Current learning rate: 0.00855 
2025-03-17 04:19:02.100744: train_loss -0.4365 
2025-03-17 04:19:02.106371: val_loss -0.3669 
2025-03-17 04:19:02.109429: Pseudo dice [np.float32(0.4459)] 
2025-03-17 04:19:02.113459: Epoch time: 41.4 s 
2025-03-17 04:19:02.116493: Yayy! New best EMA pseudo Dice: 0.3529999852180481 
2025-03-17 04:19:02.912516:  
2025-03-17 04:19:02.916551: Epoch 17 
2025-03-17 04:19:02.920599: Current learning rate: 0.00846 
2025-03-17 04:19:44.309935: train_loss -0.4281 
2025-03-17 04:19:44.316531: val_loss -0.4435 
2025-03-17 04:19:44.320204: Pseudo dice [np.float32(0.4914)] 
2025-03-17 04:19:44.323773: Epoch time: 41.4 s 
2025-03-17 04:19:44.327300: Yayy! New best EMA pseudo Dice: 0.3668999969959259 
2025-03-17 04:19:45.106832:  
2025-03-17 04:19:45.112365: Epoch 18 
2025-03-17 04:19:45.115936: Current learning rate: 0.00836 
2025-03-17 04:20:26.566443: train_loss -0.4875 
2025-03-17 04:20:26.572527: val_loss -0.4866 
2025-03-17 04:20:26.576075: Pseudo dice [np.float32(0.5411)] 
2025-03-17 04:20:26.579716: Epoch time: 41.46 s 
2025-03-17 04:20:26.582791: Yayy! New best EMA pseudo Dice: 0.38429999351501465 
2025-03-17 04:20:27.353464:  
2025-03-17 04:20:27.358512: Epoch 19 
2025-03-17 04:20:27.360949: Current learning rate: 0.00827 
2025-03-17 04:21:08.779132: train_loss -0.4504 
2025-03-17 04:21:08.785795: val_loss -0.4437 
2025-03-17 04:21:08.790359: Pseudo dice [np.float32(0.5067)] 
2025-03-17 04:21:08.793403: Epoch time: 41.43 s 
2025-03-17 04:21:08.795951: Yayy! New best EMA pseudo Dice: 0.39649999141693115 
2025-03-17 04:21:09.567535:  
2025-03-17 04:21:09.574051: Epoch 20 
2025-03-17 04:21:09.577559: Current learning rate: 0.00818 
2025-03-17 04:21:50.994285: train_loss -0.509 
2025-03-17 04:21:51.000396: val_loss -0.4266 
2025-03-17 04:21:51.004725: Pseudo dice [np.float32(0.4799)] 
2025-03-17 04:21:51.007737: Epoch time: 41.43 s 
2025-03-17 04:21:51.011249: Yayy! New best EMA pseudo Dice: 0.4049000144004822 
2025-03-17 04:21:51.961692:  
2025-03-17 04:21:51.968233: Epoch 21 
2025-03-17 04:21:51.972379: Current learning rate: 0.00809 
2025-03-17 04:22:33.380471: train_loss -0.4504 
2025-03-17 04:22:33.386279: val_loss -0.4349 
2025-03-17 04:22:33.390825: Pseudo dice [np.float32(0.4912)] 
2025-03-17 04:22:33.393874: Epoch time: 41.42 s 
2025-03-17 04:22:33.397911: Yayy! New best EMA pseudo Dice: 0.41350001096725464 
2025-03-17 04:22:34.130316:  
2025-03-17 04:22:34.136343: Epoch 22 
2025-03-17 04:22:34.140403: Current learning rate: 0.008 
2025-03-17 04:23:15.569396: train_loss -0.4146 
2025-03-17 04:23:15.575444: val_loss -0.336 
2025-03-17 04:23:15.577833: Pseudo dice [np.float32(0.3952)] 
2025-03-17 04:23:15.582773: Epoch time: 41.44 s 
2025-03-17 04:23:16.145379:  
2025-03-17 04:23:16.150925: Epoch 23 
2025-03-17 04:23:16.154506: Current learning rate: 0.0079 
2025-03-17 04:23:57.570892: train_loss -0.4275 
2025-03-17 04:23:57.577511: val_loss -0.527 
2025-03-17 04:23:57.581085: Pseudo dice [np.float32(0.5878)] 
2025-03-17 04:23:57.584229: Epoch time: 41.43 s 
2025-03-17 04:23:57.587761: Yayy! New best EMA pseudo Dice: 0.4293000102043152 
2025-03-17 04:23:58.347788:  
2025-03-17 04:23:58.353802: Epoch 24 
2025-03-17 04:23:58.357814: Current learning rate: 0.00781 
2025-03-17 04:24:39.778129: train_loss -0.4591 
2025-03-17 04:24:39.784243: val_loss -0.5129 
2025-03-17 04:24:39.788360: Pseudo dice [np.float32(0.5832)] 
2025-03-17 04:24:39.791920: Epoch time: 41.43 s 
2025-03-17 04:24:39.794449: Yayy! New best EMA pseudo Dice: 0.4447000026702881 
2025-03-17 04:24:40.538998:  
2025-03-17 04:24:40.544544: Epoch 25 
2025-03-17 04:24:40.549107: Current learning rate: 0.00772 
2025-03-17 04:25:21.972720: train_loss -0.516 
2025-03-17 04:25:21.978736: val_loss -0.4826 
2025-03-17 04:25:21.983753: Pseudo dice [np.float32(0.5531)] 
2025-03-17 04:25:21.987267: Epoch time: 41.43 s 
2025-03-17 04:25:21.990424: Yayy! New best EMA pseudo Dice: 0.4555000066757202 
2025-03-17 04:25:22.756227:  
2025-03-17 04:25:22.761744: Epoch 26 
2025-03-17 04:25:22.766760: Current learning rate: 0.00763 
2025-03-17 04:26:04.191281: train_loss -0.5471 
2025-03-17 04:26:04.196882: val_loss -0.4042 
2025-03-17 04:26:04.201440: Pseudo dice [np.float32(0.4575)] 
2025-03-17 04:26:04.204509: Epoch time: 41.44 s 
2025-03-17 04:26:04.208541: Yayy! New best EMA pseudo Dice: 0.45570001006126404 
2025-03-17 04:26:04.987069:  
2025-03-17 04:26:04.993190: Epoch 27 
2025-03-17 04:26:04.997198: Current learning rate: 0.00753 
2025-03-17 04:26:46.419439: train_loss -0.4812 
2025-03-17 04:26:46.426021: val_loss -0.5084 
2025-03-17 04:26:46.430159: Pseudo dice [np.float32(0.5538)] 
2025-03-17 04:26:46.432681: Epoch time: 41.43 s 
2025-03-17 04:26:46.436707: Yayy! New best EMA pseudo Dice: 0.46549999713897705 
2025-03-17 04:26:47.205379:  
2025-03-17 04:26:47.210941: Epoch 28 
2025-03-17 04:26:47.215494: Current learning rate: 0.00744 
2025-03-17 04:27:28.637156: train_loss -0.52 
2025-03-17 04:27:28.643851: val_loss -0.3928 
2025-03-17 04:27:28.647437: Pseudo dice [np.float32(0.4484)] 
2025-03-17 04:27:28.650973: Epoch time: 41.43 s 
2025-03-17 04:27:29.378599:  
2025-03-17 04:27:29.382625: Epoch 29 
2025-03-17 04:27:29.385767: Current learning rate: 0.00735 
2025-03-17 04:28:10.802992: train_loss -0.5134 
2025-03-17 04:28:10.811196: val_loss -0.4006 
2025-03-17 04:28:10.815219: Pseudo dice [np.float32(0.4544)] 
2025-03-17 04:28:10.818231: Epoch time: 41.42 s 
2025-03-17 04:28:11.397654:  
2025-03-17 04:28:11.404746: Epoch 30 
2025-03-17 04:28:11.407808: Current learning rate: 0.00725 
2025-03-17 04:28:52.836244: train_loss -0.5016 
2025-03-17 04:28:52.842311: val_loss -0.4284 
2025-03-17 04:28:52.846344: Pseudo dice [np.float32(0.5078)] 
2025-03-17 04:28:52.849888: Epoch time: 41.44 s 
2025-03-17 04:28:52.852921: Yayy! New best EMA pseudo Dice: 0.4674000144004822 
2025-03-17 04:28:53.590242:  
2025-03-17 04:28:53.596760: Epoch 31 
2025-03-17 04:28:53.600769: Current learning rate: 0.00716 
2025-03-17 04:29:35.024528: train_loss -0.5027 
2025-03-17 04:29:35.030553: val_loss -0.5365 
2025-03-17 04:29:35.034566: Pseudo dice [np.float32(0.5989)] 
2025-03-17 04:29:35.038082: Epoch time: 41.43 s 
2025-03-17 04:29:35.042100: Yayy! New best EMA pseudo Dice: 0.4805000126361847 
2025-03-17 04:29:35.786460:  
2025-03-17 04:29:35.793526: Epoch 32 
2025-03-17 04:29:35.797100: Current learning rate: 0.00707 
2025-03-17 04:30:17.205904: train_loss -0.5408 
2025-03-17 04:30:17.212508: val_loss -0.517 
2025-03-17 04:30:17.217053: Pseudo dice [np.float32(0.5756)] 
2025-03-17 04:30:17.220642: Epoch time: 41.42 s 
2025-03-17 04:30:17.224198: Yayy! New best EMA pseudo Dice: 0.49000000953674316 
2025-03-17 04:30:18.016025:  
2025-03-17 04:30:18.022545: Epoch 33 
2025-03-17 04:30:18.027055: Current learning rate: 0.00697 
2025-03-17 04:30:59.440000: train_loss -0.5287 
2025-03-17 04:30:59.446548: val_loss -0.5191 
2025-03-17 04:30:59.450110: Pseudo dice [np.float32(0.5686)] 
2025-03-17 04:30:59.453624: Epoch time: 41.42 s 
2025-03-17 04:30:59.456635: Yayy! New best EMA pseudo Dice: 0.49790000915527344 
2025-03-17 04:31:00.198258:  
2025-03-17 04:31:00.204339: Epoch 34 
2025-03-17 04:31:00.207400: Current learning rate: 0.00688 
2025-03-17 04:31:41.645835: train_loss -0.5294 
2025-03-17 04:31:41.650929: val_loss -0.5501 
2025-03-17 04:31:41.655485: Pseudo dice [np.float32(0.6194)] 
2025-03-17 04:31:41.658564: Epoch time: 41.45 s 
2025-03-17 04:31:41.662075: Yayy! New best EMA pseudo Dice: 0.5099999904632568 
2025-03-17 04:31:42.450635:  
2025-03-17 04:31:42.456148: Epoch 35 
2025-03-17 04:31:42.460660: Current learning rate: 0.00679 
2025-03-17 04:32:23.890826: train_loss -0.5466 
2025-03-17 04:32:23.897406: val_loss -0.4477 
2025-03-17 04:32:23.901565: Pseudo dice [np.float32(0.511)] 
2025-03-17 04:32:23.905130: Epoch time: 41.44 s 
2025-03-17 04:32:23.908700: Yayy! New best EMA pseudo Dice: 0.5101000070571899 
2025-03-17 04:32:24.713511:  
2025-03-17 04:32:24.720031: Epoch 36 
2025-03-17 04:32:24.724035: Current learning rate: 0.00669 
2025-03-17 04:33:06.136304: train_loss -0.5259 
2025-03-17 04:33:06.142873: val_loss -0.5372 
2025-03-17 04:33:06.145928: Pseudo dice [np.float32(0.5875)] 
2025-03-17 04:33:06.150503: Epoch time: 41.42 s 
2025-03-17 04:33:06.153124: Yayy! New best EMA pseudo Dice: 0.5178999900817871 
2025-03-17 04:33:07.058384:  
2025-03-17 04:33:07.064970: Epoch 37 
2025-03-17 04:33:07.069021: Current learning rate: 0.0066 
2025-03-17 04:33:48.491493: train_loss -0.5948 
2025-03-17 04:33:48.499019: val_loss -0.4202 
2025-03-17 04:33:48.502530: Pseudo dice [np.float32(0.4547)] 
2025-03-17 04:33:48.506037: Epoch time: 41.43 s 
2025-03-17 04:33:49.095676:  
2025-03-17 04:33:49.101807: Epoch 38 
2025-03-17 04:33:49.104848: Current learning rate: 0.0065 
2025-03-17 04:34:30.522477: train_loss -0.5514 
2025-03-17 04:34:30.529022: val_loss -0.5069 
2025-03-17 04:34:30.533533: Pseudo dice [np.float32(0.5318)] 
2025-03-17 04:34:30.536541: Epoch time: 41.43 s 
2025-03-17 04:34:31.126356:  
2025-03-17 04:34:31.131919: Epoch 39 
2025-03-17 04:34:31.136482: Current learning rate: 0.00641 
2025-03-17 04:35:12.553378: train_loss -0.5752 
2025-03-17 04:35:12.562027: val_loss -0.5185 
2025-03-17 04:35:12.565606: Pseudo dice [np.float32(0.5401)] 
2025-03-17 04:35:12.569662: Epoch time: 41.43 s 
2025-03-17 04:35:13.190761:  
2025-03-17 04:35:13.197282: Epoch 40 
2025-03-17 04:35:13.200788: Current learning rate: 0.00631 
2025-03-17 04:35:54.638786: train_loss -0.5679 
2025-03-17 04:35:54.644801: val_loss -0.5282 
2025-03-17 04:35:54.648814: Pseudo dice [np.float32(0.5955)] 
2025-03-17 04:35:54.652323: Epoch time: 41.45 s 
2025-03-17 04:35:54.656332: Yayy! New best EMA pseudo Dice: 0.5242000222206116 
2025-03-17 04:35:55.422302:  
2025-03-17 04:35:55.427814: Epoch 41 
2025-03-17 04:35:55.431324: Current learning rate: 0.00622 
2025-03-17 04:36:36.836608: train_loss -0.5829 
2025-03-17 04:36:36.843184: val_loss -0.4656 
2025-03-17 04:36:36.846235: Pseudo dice [np.float32(0.5141)] 
2025-03-17 04:36:36.849744: Epoch time: 41.42 s 
2025-03-17 04:36:37.428754:  
2025-03-17 04:36:37.433779: Epoch 42 
2025-03-17 04:36:37.438315: Current learning rate: 0.00612 
2025-03-17 04:37:18.846770: train_loss -0.5574 
2025-03-17 04:37:18.854326: val_loss -0.5254 
2025-03-17 04:37:18.858352: Pseudo dice [np.float32(0.5715)] 
2025-03-17 04:37:18.861887: Epoch time: 41.42 s 
2025-03-17 04:37:18.865909: Yayy! New best EMA pseudo Dice: 0.527999997138977 
2025-03-17 04:37:19.635308:  
2025-03-17 04:37:19.641824: Epoch 43 
2025-03-17 04:37:19.645329: Current learning rate: 0.00603 
2025-03-17 04:38:01.054976: train_loss -0.5375 
2025-03-17 04:38:01.061076: val_loss -0.5836 
2025-03-17 04:38:01.065124: Pseudo dice [np.float32(0.6602)] 
2025-03-17 04:38:01.068180: Epoch time: 41.42 s 
2025-03-17 04:38:01.072244: Yayy! New best EMA pseudo Dice: 0.5411999821662903 
2025-03-17 04:38:01.828637:  
2025-03-17 04:38:01.834701: Epoch 44 
2025-03-17 04:38:01.838749: Current learning rate: 0.00593 
2025-03-17 04:38:43.275256: train_loss -0.5867 
2025-03-17 04:38:43.281322: val_loss -0.4739 
2025-03-17 04:38:43.285332: Pseudo dice [np.float32(0.5189)] 
2025-03-17 04:38:43.287838: Epoch time: 41.45 s 
2025-03-17 04:38:43.997636:  
2025-03-17 04:38:44.004198: Epoch 45 
2025-03-17 04:38:44.007738: Current learning rate: 0.00584 
2025-03-17 04:39:25.401245: train_loss -0.5842 
2025-03-17 04:39:25.407771: val_loss -0.4977 
2025-03-17 04:39:25.411281: Pseudo dice [np.float32(0.5205)] 
2025-03-17 04:39:25.414793: Epoch time: 41.4 s 
2025-03-17 04:39:25.980173:  
2025-03-17 04:39:25.985691: Epoch 46 
2025-03-17 04:39:25.989201: Current learning rate: 0.00574 
2025-03-17 04:40:07.384757: train_loss -0.5651 
2025-03-17 04:40:07.390276: val_loss -0.4351 
2025-03-17 04:40:07.393791: Pseudo dice [np.float32(0.4834)] 
2025-03-17 04:40:07.397297: Epoch time: 41.4 s 
2025-03-17 04:40:07.958714:  
2025-03-17 04:40:07.963813: Epoch 47 
2025-03-17 04:40:07.967355: Current learning rate: 0.00565 
2025-03-17 04:40:49.377486: train_loss -0.4906 
2025-03-17 04:40:49.383078: val_loss -0.4638 
2025-03-17 04:40:49.387688: Pseudo dice [np.float32(0.5086)] 
2025-03-17 04:40:49.390740: Epoch time: 41.42 s 
2025-03-17 04:40:49.946459:  
2025-03-17 04:40:49.952038: Epoch 48 
2025-03-17 04:40:49.956088: Current learning rate: 0.00555 
2025-03-17 04:41:31.354097: train_loss -0.5699 
2025-03-17 04:41:31.360186: val_loss -0.5324 
2025-03-17 04:41:31.363279: Pseudo dice [np.float32(0.5758)] 
2025-03-17 04:41:31.365300: Epoch time: 41.41 s 
2025-03-17 04:41:31.952358:  
2025-03-17 04:41:31.959016: Epoch 49 
2025-03-17 04:41:31.962589: Current learning rate: 0.00546 
2025-03-17 04:42:13.365264: train_loss -0.5808 
2025-03-17 04:42:13.372832: val_loss -0.394 
2025-03-17 04:42:13.376340: Pseudo dice [np.float32(0.4619)] 
2025-03-17 04:42:13.379353: Epoch time: 41.41 s 
2025-03-17 04:42:14.124165:  
2025-03-17 04:42:14.129204: Epoch 50 
2025-03-17 04:42:14.132315: Current learning rate: 0.00536 
2025-03-17 04:42:55.558957: train_loss -0.5867 
2025-03-17 04:42:55.563970: val_loss -0.5305 
2025-03-17 04:42:55.567480: Pseudo dice [np.float32(0.5202)] 
2025-03-17 04:42:55.569988: Epoch time: 41.43 s 
2025-03-17 04:42:56.134623:  
2025-03-17 04:42:56.140191: Epoch 51 
2025-03-17 04:42:56.144752: Current learning rate: 0.00526 
2025-03-17 04:43:37.559087: train_loss -0.5904 
2025-03-17 04:43:37.564640: val_loss -0.5654 
2025-03-17 04:43:37.568165: Pseudo dice [np.float32(0.5872)] 
2025-03-17 04:43:37.571722: Epoch time: 41.42 s 
2025-03-17 04:43:38.148048:  
2025-03-17 04:43:38.154297: Epoch 52 
2025-03-17 04:43:38.156880: Current learning rate: 0.00517 
2025-03-17 04:44:19.546160: train_loss -0.5952 
2025-03-17 04:44:19.552703: val_loss -0.4376 
2025-03-17 04:44:19.555727: Pseudo dice [np.float32(0.5295)] 
2025-03-17 04:44:19.558757: Epoch time: 41.4 s 
2025-03-17 04:44:20.291240:  
2025-03-17 04:44:20.296787: Epoch 53 
2025-03-17 04:44:20.300297: Current learning rate: 0.00507 
2025-03-17 04:45:01.686899: train_loss -0.6093 
2025-03-17 04:45:01.692960: val_loss -0.4379 
2025-03-17 04:45:01.696975: Pseudo dice [np.float32(0.4883)] 
2025-03-17 04:45:01.699481: Epoch time: 41.4 s 
2025-03-17 04:45:02.275399:  
2025-03-17 04:45:02.280957: Epoch 54 
2025-03-17 04:45:02.285579: Current learning rate: 0.00497 
2025-03-17 04:45:43.675628: train_loss -0.5544 
2025-03-17 04:45:43.682147: val_loss -0.5644 
2025-03-17 04:45:43.685656: Pseudo dice [np.float32(0.6381)] 
2025-03-17 04:45:43.688161: Epoch time: 41.4 s 
2025-03-17 04:45:44.257832:  
2025-03-17 04:45:44.263862: Epoch 55 
2025-03-17 04:45:44.266892: Current learning rate: 0.00487 
2025-03-17 04:46:25.673847: train_loss -0.6 
2025-03-17 04:46:25.681021: val_loss -0.4311 
2025-03-17 04:46:25.684100: Pseudo dice [np.float32(0.4951)] 
2025-03-17 04:46:25.687608: Epoch time: 41.42 s 
2025-03-17 04:46:26.254533:  
2025-03-17 04:46:26.261117: Epoch 56 
2025-03-17 04:46:26.263660: Current learning rate: 0.00478 
2025-03-17 04:47:07.649613: train_loss -0.5668 
2025-03-17 04:47:07.656184: val_loss -0.4454 
2025-03-17 04:47:07.659249: Pseudo dice [np.float32(0.5437)] 
2025-03-17 04:47:07.662382: Epoch time: 41.4 s 
2025-03-17 04:47:08.237524:  
2025-03-17 04:47:08.243171: Epoch 57 
2025-03-17 04:47:08.246219: Current learning rate: 0.00468 
2025-03-17 04:47:49.628856: train_loss -0.5736 
2025-03-17 04:47:49.633913: val_loss -0.4629 
2025-03-17 04:47:49.638495: Pseudo dice [np.float32(0.4943)] 
2025-03-17 04:47:49.641547: Epoch time: 41.39 s 
2025-03-17 04:47:50.210152:  
2025-03-17 04:47:50.216288: Epoch 58 
2025-03-17 04:47:50.219844: Current learning rate: 0.00458 
2025-03-17 04:48:31.648557: train_loss -0.6057 
2025-03-17 04:48:31.654218: val_loss -0.5071 
2025-03-17 04:48:31.658294: Pseudo dice [np.float32(0.5835)] 
2025-03-17 04:48:31.661821: Epoch time: 41.44 s 
2025-03-17 04:48:32.240359:  
2025-03-17 04:48:32.245890: Epoch 59 
2025-03-17 04:48:32.249430: Current learning rate: 0.00448 
2025-03-17 04:49:13.649415: train_loss -0.5959 
2025-03-17 04:49:13.656561: val_loss -0.5757 
2025-03-17 04:49:13.660592: Pseudo dice [np.float32(0.6236)] 
2025-03-17 04:49:13.664130: Epoch time: 41.41 s 
2025-03-17 04:49:13.667658: Yayy! New best EMA pseudo Dice: 0.5450999736785889 
2025-03-17 04:49:14.414282:  
2025-03-17 04:49:14.421324: Epoch 60 
2025-03-17 04:49:14.424366: Current learning rate: 0.00438 
2025-03-17 04:49:55.847063: train_loss -0.5967 
2025-03-17 04:49:55.852103: val_loss -0.4099 
2025-03-17 04:49:55.856125: Pseudo dice [np.float32(0.4918)] 
2025-03-17 04:49:55.859665: Epoch time: 41.43 s 
2025-03-17 04:49:56.601183:  
2025-03-17 04:49:56.607708: Epoch 61 
2025-03-17 04:49:56.611221: Current learning rate: 0.00429 
2025-03-17 04:50:38.017221: train_loss -0.5737 
2025-03-17 04:50:38.023782: val_loss -0.5127 
2025-03-17 04:50:38.027310: Pseudo dice [np.float32(0.5803)] 
2025-03-17 04:50:38.030839: Epoch time: 41.42 s 
2025-03-17 04:50:38.616187:  
2025-03-17 04:50:38.622224: Epoch 62 
2025-03-17 04:50:38.625263: Current learning rate: 0.00419 
2025-03-17 04:51:20.038929: train_loss -0.6211 
2025-03-17 04:51:20.045481: val_loss -0.5354 
2025-03-17 04:51:20.049515: Pseudo dice [np.float32(0.5904)] 
2025-03-17 04:51:20.053035: Epoch time: 41.42 s 
2025-03-17 04:51:20.056055: Yayy! New best EMA pseudo Dice: 0.5485000014305115 
2025-03-17 04:51:20.808088:  
2025-03-17 04:51:20.814145: Epoch 63 
2025-03-17 04:51:20.818179: Current learning rate: 0.00409 
2025-03-17 04:52:02.194063: train_loss -0.5989 
2025-03-17 04:52:02.200140: val_loss -0.4967 
2025-03-17 04:52:02.204170: Pseudo dice [np.float32(0.5195)] 
2025-03-17 04:52:02.207204: Epoch time: 41.39 s 
2025-03-17 04:52:02.787364:  
2025-03-17 04:52:02.793429: Epoch 64 
2025-03-17 04:52:02.797991: Current learning rate: 0.00399 
2025-03-17 04:52:44.209769: train_loss -0.5884 
2025-03-17 04:52:44.215801: val_loss -0.4701 
2025-03-17 04:52:44.220327: Pseudo dice [np.float32(0.5265)] 
2025-03-17 04:52:44.223836: Epoch time: 41.42 s 
2025-03-17 04:52:44.820589:  
2025-03-17 04:52:44.825449: Epoch 65 
2025-03-17 04:52:44.828960: Current learning rate: 0.00389 
2025-03-17 04:53:26.244946: train_loss -0.618 
2025-03-17 04:53:26.251470: val_loss -0.4979 
2025-03-17 04:53:26.255507: Pseudo dice [np.float32(0.585)] 
2025-03-17 04:53:26.259544: Epoch time: 41.43 s 
2025-03-17 04:53:26.865882:  
2025-03-17 04:53:26.871914: Epoch 66 
2025-03-17 04:53:26.875963: Current learning rate: 0.00379 
2025-03-17 04:54:08.287045: train_loss -0.6104 
2025-03-17 04:54:08.292629: val_loss -0.4033 
2025-03-17 04:54:08.297207: Pseudo dice [np.float32(0.4594)] 
2025-03-17 04:54:08.300715: Epoch time: 41.42 s 
2025-03-17 04:54:08.886694:  
2025-03-17 04:54:08.892783: Epoch 67 
2025-03-17 04:54:08.897413: Current learning rate: 0.00369 
2025-03-17 04:54:50.313057: train_loss -0.6135 
2025-03-17 04:54:50.320210: val_loss -0.4527 
2025-03-17 04:54:50.323753: Pseudo dice [np.float32(0.5173)] 
2025-03-17 04:54:50.326787: Epoch time: 41.43 s 
2025-03-17 04:54:50.919293:  
2025-03-17 04:54:50.925930: Epoch 68 
2025-03-17 04:54:50.929965: Current learning rate: 0.00359 
2025-03-17 04:55:32.343116: train_loss -0.6179 
2025-03-17 04:55:32.350177: val_loss -0.4763 
2025-03-17 04:55:32.354225: Pseudo dice [np.float32(0.5107)] 
2025-03-17 04:55:32.358233: Epoch time: 41.42 s 
2025-03-17 04:55:33.107639:  
2025-03-17 04:55:33.114242: Epoch 69 
2025-03-17 04:55:33.118384: Current learning rate: 0.00349 
2025-03-17 04:56:14.517726: train_loss -0.6022 
2025-03-17 04:56:14.526301: val_loss -0.5633 
2025-03-17 04:56:14.530362: Pseudo dice [np.float32(0.637)] 
2025-03-17 04:56:14.533890: Epoch time: 41.41 s 
2025-03-17 04:56:15.119540:  
2025-03-17 04:56:15.125103: Epoch 70 
2025-03-17 04:56:15.129666: Current learning rate: 0.00338 
2025-03-17 04:56:56.523728: train_loss -0.6284 
2025-03-17 04:56:56.529788: val_loss -0.4728 
2025-03-17 04:56:56.534319: Pseudo dice [np.float32(0.5366)] 
2025-03-17 04:56:56.537350: Epoch time: 41.4 s 
2025-03-17 04:56:57.146538:  
2025-03-17 04:56:57.153061: Epoch 71 
2025-03-17 04:56:57.157069: Current learning rate: 0.00328 
2025-03-17 04:57:38.896984: train_loss -0.6147 
2025-03-17 04:57:38.902998: val_loss -0.4954 
2025-03-17 04:57:38.907007: Pseudo dice [np.float32(0.6043)] 
2025-03-17 04:57:38.910518: Epoch time: 41.75 s 
2025-03-17 04:57:38.914023: Yayy! New best EMA pseudo Dice: 0.5497000217437744 
2025-03-17 04:57:39.679098:  
2025-03-17 04:57:39.685663: Epoch 72 
2025-03-17 04:57:39.689741: Current learning rate: 0.00318 
2025-03-17 04:58:21.123183: train_loss -0.596 
2025-03-17 04:58:21.130200: val_loss -0.537 
2025-03-17 04:58:21.134215: Pseudo dice [np.float32(0.6159)] 
2025-03-17 04:58:21.136720: Epoch time: 41.44 s 
2025-03-17 04:58:21.140731: Yayy! New best EMA pseudo Dice: 0.5564000010490417 
2025-03-17 04:58:21.888995:  
2025-03-17 04:58:21.895514: Epoch 73 
2025-03-17 04:58:21.899025: Current learning rate: 0.00308 
2025-03-17 04:59:03.303360: train_loss -0.6184 
2025-03-17 04:59:03.310547: val_loss -0.5633 
2025-03-17 04:59:03.314090: Pseudo dice [np.float32(0.5839)] 
2025-03-17 04:59:03.316645: Epoch time: 41.41 s 
2025-03-17 04:59:03.320159: Yayy! New best EMA pseudo Dice: 0.5590999722480774 
2025-03-17 04:59:04.089837:  
2025-03-17 04:59:04.096406: Epoch 74 
2025-03-17 04:59:04.100451: Current learning rate: 0.00297 
2025-03-17 04:59:45.504554: train_loss -0.6027 
2025-03-17 04:59:45.511570: val_loss -0.5487 
2025-03-17 04:59:45.515587: Pseudo dice [np.float32(0.5975)] 
2025-03-17 04:59:45.519601: Epoch time: 41.42 s 
2025-03-17 04:59:45.523112: Yayy! New best EMA pseudo Dice: 0.5629000067710876 
2025-03-17 04:59:46.278864:  
2025-03-17 04:59:46.284380: Epoch 75 
2025-03-17 04:59:46.288890: Current learning rate: 0.00287 
2025-03-17 05:00:27.708857: train_loss -0.6085 
2025-03-17 05:00:27.715911: val_loss -0.5168 
2025-03-17 05:00:27.720531: Pseudo dice [np.float32(0.645)] 
2025-03-17 05:00:27.724084: Epoch time: 41.43 s 
2025-03-17 05:00:27.727117: Yayy! New best EMA pseudo Dice: 0.5712000131607056 
2025-03-17 05:00:28.514836:  
2025-03-17 05:00:28.521472: Epoch 76 
2025-03-17 05:00:28.526030: Current learning rate: 0.00277 
2025-03-17 05:01:09.928640: train_loss -0.6316 
2025-03-17 05:01:09.935179: val_loss -0.5499 
2025-03-17 05:01:09.939712: Pseudo dice [np.float32(0.6118)] 
2025-03-17 05:01:09.943257: Epoch time: 41.41 s 
2025-03-17 05:01:09.947280: Yayy! New best EMA pseudo Dice: 0.5752000212669373 
2025-03-17 05:01:10.849273:  
2025-03-17 05:01:10.855794: Epoch 77 
2025-03-17 05:01:10.859802: Current learning rate: 0.00266 
2025-03-17 05:01:52.266283: train_loss -0.6361 
2025-03-17 05:01:52.272366: val_loss -0.5606 
2025-03-17 05:01:52.277525: Pseudo dice [np.float32(0.6389)] 
2025-03-17 05:01:52.280566: Epoch time: 41.42 s 
2025-03-17 05:01:52.285156: Yayy! New best EMA pseudo Dice: 0.58160001039505 
2025-03-17 05:01:53.059269:  
2025-03-17 05:01:53.065285: Epoch 78 
2025-03-17 05:01:53.070302: Current learning rate: 0.00256 
2025-03-17 05:02:34.465558: train_loss -0.6199 
2025-03-17 05:02:34.471630: val_loss -0.5266 
2025-03-17 05:02:34.475695: Pseudo dice [np.float32(0.663)] 
2025-03-17 05:02:34.479764: Epoch time: 41.41 s 
2025-03-17 05:02:34.483303: Yayy! New best EMA pseudo Dice: 0.5896999835968018 
2025-03-17 05:02:35.253993:  
2025-03-17 05:02:35.260592: Epoch 79 
2025-03-17 05:02:35.265166: Current learning rate: 0.00245 
2025-03-17 05:03:16.684516: train_loss -0.6339 
2025-03-17 05:03:16.692037: val_loss -0.5224 
2025-03-17 05:03:16.695547: Pseudo dice [np.float32(0.6594)] 
2025-03-17 05:03:16.699557: Epoch time: 41.43 s 
2025-03-17 05:03:16.703066: Yayy! New best EMA pseudo Dice: 0.5967000126838684 
2025-03-17 05:03:17.471763:  
2025-03-17 05:03:17.478321: Epoch 80 
2025-03-17 05:03:17.482854: Current learning rate: 0.00235 
2025-03-17 05:03:58.869589: train_loss -0.6172 
2025-03-17 05:03:58.876155: val_loss -0.4791 
2025-03-17 05:03:58.879663: Pseudo dice [np.float32(0.5297)] 
2025-03-17 05:03:58.883673: Epoch time: 41.4 s 
2025-03-17 05:03:59.490981:  
2025-03-17 05:03:59.497610: Epoch 81 
2025-03-17 05:03:59.501644: Current learning rate: 0.00224 
2025-03-17 05:04:40.894924: train_loss -0.63 
2025-03-17 05:04:40.901568: val_loss -0.4781 
2025-03-17 05:04:40.905620: Pseudo dice [np.float32(0.5915)] 
2025-03-17 05:04:40.909170: Epoch time: 41.4 s 
2025-03-17 05:04:41.520853:  
2025-03-17 05:04:41.527395: Epoch 82 
2025-03-17 05:04:41.531423: Current learning rate: 0.00214 
2025-03-17 05:05:22.950968: train_loss -0.6532 
2025-03-17 05:05:22.958028: val_loss -0.5588 
2025-03-17 05:05:22.962054: Pseudo dice [np.float32(0.648)] 
2025-03-17 05:05:22.966074: Epoch time: 41.43 s 
2025-03-17 05:05:23.531011:  
2025-03-17 05:05:23.537058: Epoch 83 
2025-03-17 05:05:23.541065: Current learning rate: 0.00203 
2025-03-17 05:06:04.944701: train_loss -0.6394 
2025-03-17 05:06:04.951279: val_loss -0.559 
2025-03-17 05:06:04.955287: Pseudo dice [np.float32(0.6554)] 
2025-03-17 05:06:04.958799: Epoch time: 41.41 s 
2025-03-17 05:06:04.962807: Yayy! New best EMA pseudo Dice: 0.6018999814987183 
2025-03-17 05:06:05.705518:  
2025-03-17 05:06:05.712688: Epoch 84 
2025-03-17 05:06:05.717248: Current learning rate: 0.00192 
2025-03-17 05:06:47.131649: train_loss -0.6711 
2025-03-17 05:06:47.138205: val_loss -0.6173 
2025-03-17 05:06:47.142745: Pseudo dice [np.float32(0.7106)] 
2025-03-17 05:06:47.145769: Epoch time: 41.43 s 
2025-03-17 05:06:47.150301: Yayy! New best EMA pseudo Dice: 0.6126999855041504 
2025-03-17 05:06:48.033637:  
2025-03-17 05:06:48.040156: Epoch 85 
2025-03-17 05:06:48.044161: Current learning rate: 0.00181 
2025-03-17 05:07:29.440775: train_loss -0.6302 
2025-03-17 05:07:29.448454: val_loss -0.5075 
2025-03-17 05:07:29.452481: Pseudo dice [np.float32(0.6018)] 
2025-03-17 05:07:29.456504: Epoch time: 41.41 s 
2025-03-17 05:07:30.078535:  
2025-03-17 05:07:30.085123: Epoch 86 
2025-03-17 05:07:30.089672: Current learning rate: 0.0017 
2025-03-17 05:08:11.490756: train_loss -0.6596 
2025-03-17 05:08:11.496907: val_loss -0.4492 
2025-03-17 05:08:11.500952: Pseudo dice [np.float32(0.6074)] 
2025-03-17 05:08:11.504490: Epoch time: 41.41 s 
2025-03-17 05:08:12.069053:  
2025-03-17 05:08:12.075628: Epoch 87 
2025-03-17 05:08:12.079742: Current learning rate: 0.00159 
2025-03-17 05:08:53.479037: train_loss -0.6752 
2025-03-17 05:08:53.486058: val_loss -0.5912 
2025-03-17 05:08:53.490070: Pseudo dice [np.float32(0.7343)] 
2025-03-17 05:08:53.493575: Epoch time: 41.41 s 
2025-03-17 05:08:53.497591: Yayy! New best EMA pseudo Dice: 0.6234999895095825 
2025-03-17 05:08:54.227894:  
2025-03-17 05:08:54.235027: Epoch 88 
2025-03-17 05:08:54.238607: Current learning rate: 0.00148 
2025-03-17 05:09:35.642856: train_loss -0.6501 
2025-03-17 05:09:35.648958: val_loss -0.5238 
2025-03-17 05:09:35.653551: Pseudo dice [np.float32(0.6158)] 
2025-03-17 05:09:35.657618: Epoch time: 41.41 s 
2025-03-17 05:09:36.258056:  
2025-03-17 05:09:36.264654: Epoch 89 
2025-03-17 05:09:36.269731: Current learning rate: 0.00137 
2025-03-17 05:10:17.667930: train_loss -0.6636 
2025-03-17 05:10:17.675502: val_loss -0.6024 
2025-03-17 05:10:17.679512: Pseudo dice [np.float32(0.7126)] 
2025-03-17 05:10:17.683022: Epoch time: 41.41 s 
2025-03-17 05:10:17.686527: Yayy! New best EMA pseudo Dice: 0.6316999793052673 
2025-03-17 05:10:18.416929:  
2025-03-17 05:10:18.422442: Epoch 90 
2025-03-17 05:10:18.425951: Current learning rate: 0.00126 
2025-03-17 05:10:59.822450: train_loss -0.6862 
2025-03-17 05:10:59.830061: val_loss -0.6032 
2025-03-17 05:10:59.833570: Pseudo dice [np.float32(0.6701)] 
2025-03-17 05:10:59.837077: Epoch time: 41.41 s 
2025-03-17 05:10:59.840088: Yayy! New best EMA pseudo Dice: 0.6355999708175659 
2025-03-17 05:11:00.609764:  
2025-03-17 05:11:00.615597: Epoch 91 
2025-03-17 05:11:00.619605: Current learning rate: 0.00115 
2025-03-17 05:11:42.022988: train_loss -0.6614 
2025-03-17 05:11:42.028553: val_loss -0.5714 
2025-03-17 05:11:42.033067: Pseudo dice [np.float32(0.6605)] 
2025-03-17 05:11:42.036075: Epoch time: 41.41 s 
2025-03-17 05:11:42.039584: Yayy! New best EMA pseudo Dice: 0.6381000280380249 
2025-03-17 05:11:42.773440:  
2025-03-17 05:11:42.779030: Epoch 92 
2025-03-17 05:11:42.783085: Current learning rate: 0.00103 
2025-03-17 05:12:24.234307: train_loss -0.6907 
2025-03-17 05:12:24.241339: val_loss -0.5434 
2025-03-17 05:12:24.243874: Pseudo dice [np.float32(0.6396)] 
2025-03-17 05:12:24.248439: Epoch time: 41.46 s 
2025-03-17 05:12:24.251495: Yayy! New best EMA pseudo Dice: 0.6381999850273132 
2025-03-17 05:12:24.986736:  
2025-03-17 05:12:24.993251: Epoch 93 
2025-03-17 05:12:24.998269: Current learning rate: 0.00091 
2025-03-17 05:13:06.406889: train_loss -0.6848 
2025-03-17 05:13:06.413593: val_loss -0.4698 
2025-03-17 05:13:06.417158: Pseudo dice [np.float32(0.6109)] 
2025-03-17 05:13:06.419681: Epoch time: 41.42 s 
2025-03-17 05:13:06.979633:  
2025-03-17 05:13:06.986259: Epoch 94 
2025-03-17 05:13:06.990317: Current learning rate: 0.00079 
2025-03-17 05:13:48.408707: train_loss -0.6636 
2025-03-17 05:13:48.415224: val_loss -0.4563 
2025-03-17 05:13:48.418734: Pseudo dice [np.float32(0.5663)] 
2025-03-17 05:13:48.422244: Epoch time: 41.43 s 
2025-03-17 05:13:49.006252:  
2025-03-17 05:13:49.012292: Epoch 95 
2025-03-17 05:13:49.015381: Current learning rate: 0.00067 
2025-03-17 05:14:30.423323: train_loss -0.6705 
2025-03-17 05:14:30.430880: val_loss -0.5421 
2025-03-17 05:14:30.434391: Pseudo dice [np.float32(0.6547)] 
2025-03-17 05:14:30.438399: Epoch time: 41.42 s 
2025-03-17 05:14:31.012510:  
2025-03-17 05:14:31.018109: Epoch 96 
2025-03-17 05:14:31.022697: Current learning rate: 0.00055 
2025-03-17 05:15:12.441777: train_loss -0.6744 
2025-03-17 05:15:12.450514: val_loss -0.552 
2025-03-17 05:15:12.454048: Pseudo dice [np.float32(0.6769)] 
2025-03-17 05:15:12.457547: Epoch time: 41.43 s 
2025-03-17 05:15:13.030297:  
2025-03-17 05:15:13.036861: Epoch 97 
2025-03-17 05:15:13.040922: Current learning rate: 0.00043 
2025-03-17 05:15:54.472167: train_loss -0.6757 
2025-03-17 05:15:54.479266: val_loss -0.4993 
2025-03-17 05:15:54.483311: Pseudo dice [np.float32(0.634)] 
2025-03-17 05:15:54.486932: Epoch time: 41.44 s 
2025-03-17 05:15:55.066924:  
2025-03-17 05:15:55.072484: Epoch 98 
2025-03-17 05:15:55.077551: Current learning rate: 0.0003 
2025-03-17 05:16:36.491694: train_loss -0.6802 
2025-03-17 05:16:36.498878: val_loss -0.5547 
2025-03-17 05:16:36.502955: Pseudo dice [np.float32(0.6963)] 
2025-03-17 05:16:36.506523: Epoch time: 41.43 s 
2025-03-17 05:16:36.510586: Yayy! New best EMA pseudo Dice: 0.641700029373169 
2025-03-17 05:16:37.268697:  
2025-03-17 05:16:37.274752: Epoch 99 
2025-03-17 05:16:37.278871: Current learning rate: 0.00016 
2025-03-17 05:17:18.708442: train_loss -0.6941 
2025-03-17 05:17:18.714959: val_loss -0.4211 
2025-03-17 05:17:18.719514: Pseudo dice [np.float32(0.5502)] 
2025-03-17 05:17:18.723550: Epoch time: 41.44 s 
2025-03-17 05:17:19.647475: Training done. 
2025-03-17 05:17:19.677475: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-03-17 05:17:19.684476: The split file contains 5 splits. 
2025-03-17 05:17:19.689475: Desired fold for training: 0 
2025-03-17 05:17:19.696476: This split has 100 training and 26 validation cases. 
2025-03-17 05:17:19.701475: predicting colon_008 
2025-03-17 05:17:19.707480: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-03-17 05:17:35.406887: predicting colon_027 
2025-03-17 05:17:35.426891: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-03-17 05:17:41.445704: predicting colon_030 
2025-03-17 05:17:41.457705: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-03-17 05:17:49.941991: predicting colon_033 
2025-03-17 05:17:49.957989: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-03-17 05:18:05.008157: predicting colon_041 
2025-03-17 05:18:05.029161: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-03-17 05:18:45.526670: predicting colon_042 
2025-03-17 05:18:45.559673: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-03-17 05:19:05.849789: predicting colon_061 
2025-03-17 05:19:05.871790: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-03-17 05:19:29.360811: predicting colon_074 
2025-03-17 05:19:29.388813: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-03-17 05:19:56.415957: predicting colon_075 
2025-03-17 05:19:56.441463: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-03-17 05:20:11.487059: predicting colon_088 
2025-03-17 05:20:11.506060: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-03-17 05:20:35.011858: predicting colon_091 
2025-03-17 05:20:35.037860: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-03-17 05:21:03.205518: predicting colon_092 
2025-03-17 05:21:03.231519: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-03-17 05:21:26.701632: predicting colon_095 
2025-03-17 05:21:26.722632: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-03-17 05:21:41.781311: predicting colon_102 
2025-03-17 05:21:41.800815: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-03-17 05:22:15.527400: predicting colon_111 
2025-03-17 05:22:15.557400: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-03-17 05:22:24.998292: predicting colon_115 
2025-03-17 05:22:25.016297: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-03-17 05:22:40.070613: predicting colon_118 
2025-03-17 05:22:40.091613: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-03-17 05:23:03.607302: predicting colon_124 
2025-03-17 05:23:03.631310: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-03-17 05:23:27.131310: predicting colon_127 
2025-03-17 05:23:27.157687: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-03-17 05:24:14.370312: predicting colon_154 
2025-03-17 05:24:14.418820: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-03-17 05:24:29.504728: predicting colon_161 
2025-03-17 05:24:29.527727: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-03-17 05:24:44.588186: predicting colon_162 
2025-03-17 05:24:44.608697: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-03-17 05:25:25.149162: predicting colon_165 
2025-03-17 05:25:25.181162: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-03-17 05:25:58.944184: predicting colon_166 
2025-03-17 05:25:58.969693: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-03-17 05:26:14.059159: predicting colon_169 
2025-03-17 05:26:14.081665: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-03-17 05:27:01.331553: predicting colon_187 
2025-03-17 05:27:01.370553: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-03-17 05:27:34.619245: Validation complete 
2025-03-17 05:27:34.625649: Mean Validation Dice:  0.2637886845170845 
