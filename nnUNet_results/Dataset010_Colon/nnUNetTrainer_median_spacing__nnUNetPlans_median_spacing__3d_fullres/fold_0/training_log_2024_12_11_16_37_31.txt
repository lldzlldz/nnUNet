
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-11 16:37:31.707462: do_dummy_2d_data_aug: True 
2024-12-11 16:37:31.714460: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-11 16:37:31.718462: The split file contains 5 splits. 
2024-12-11 16:37:31.720460: Desired fold for training: 0 
2024-12-11 16:37:31.723460: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_median_spacing_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [32, 224, 224], 'median_image_size_in_voxels': [90.0, 512.0, 512.0], 'spacing': [5.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans_median_spacing', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2024-12-11 16:37:39.768376: unpacking dataset... 
2024-12-11 16:37:46.324581: unpacking done... 
2024-12-11 16:37:49.223238:  
2024-12-11 16:37:49.227251: Epoch 0 
2024-12-11 16:37:49.231263: Current learning rate: 0.01 
2024-12-11 16:38:28.738907: train_loss 0.0349 
2024-12-11 16:38:28.744520: val_loss -0.0136 
2024-12-11 16:38:28.747574: Pseudo dice [np.float32(0.0)] 
2024-12-11 16:38:28.750098: Epoch time: 39.52 s 
2024-12-11 16:38:28.753133: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-11 16:38:29.402786:  
2024-12-11 16:38:29.408299: Epoch 1 
2024-12-11 16:38:29.410805: Current learning rate: 0.00991 
2024-12-11 16:39:05.075827: train_loss -0.0661 
2024-12-11 16:39:05.080863: val_loss -0.1908 
2024-12-11 16:39:05.084385: Pseudo dice [np.float32(0.3271)] 
2024-12-11 16:39:05.087910: Epoch time: 35.67 s 
2024-12-11 16:39:05.090942: Yayy! New best EMA pseudo Dice: 0.03269999846816063 
2024-12-11 16:39:05.826367:  
2024-12-11 16:39:05.831945: Epoch 2 
2024-12-11 16:39:05.834492: Current learning rate: 0.00982 
2024-12-11 16:39:41.856765: train_loss -0.2267 
2024-12-11 16:39:41.861800: val_loss -0.292 
2024-12-11 16:39:41.865901: Pseudo dice [np.float32(0.3502)] 
2024-12-11 16:39:41.868441: Epoch time: 36.03 s 
2024-12-11 16:39:41.871505: Yayy! New best EMA pseudo Dice: 0.06449999660253525 
2024-12-11 16:39:42.648855:  
2024-12-11 16:39:42.654432: Epoch 3 
2024-12-11 16:39:42.656965: Current learning rate: 0.00973 
2024-12-11 16:40:18.309023: train_loss -0.3175 
2024-12-11 16:40:18.316123: val_loss -0.3383 
2024-12-11 16:40:18.319160: Pseudo dice [np.float32(0.3876)] 
2024-12-11 16:40:18.322191: Epoch time: 35.66 s 
2024-12-11 16:40:18.326198: Yayy! New best EMA pseudo Dice: 0.09679999947547913 
2024-12-11 16:40:19.102533:  
2024-12-11 16:40:19.108081: Epoch 4 
2024-12-11 16:40:19.111116: Current learning rate: 0.00964 
2024-12-11 16:40:54.789585: train_loss -0.3071 
2024-12-11 16:40:54.796105: val_loss -0.3377 
2024-12-11 16:40:54.798614: Pseudo dice [np.float32(0.4065)] 
2024-12-11 16:40:54.802129: Epoch time: 35.69 s 
2024-12-11 16:40:54.804636: Yayy! New best EMA pseudo Dice: 0.12770000100135803 
2024-12-11 16:40:55.744047:  
2024-12-11 16:40:55.749661: Epoch 5 
2024-12-11 16:40:55.753250: Current learning rate: 0.00955 
2024-12-11 16:41:31.405549: train_loss -0.3165 
2024-12-11 16:41:31.409058: val_loss -0.3868 
2024-12-11 16:41:31.412568: Pseudo dice [np.float32(0.4284)] 
2024-12-11 16:41:31.415582: Epoch time: 35.66 s 
2024-12-11 16:41:31.418088: Yayy! New best EMA pseudo Dice: 0.15780000388622284 
2024-12-11 16:41:32.138786:  
2024-12-11 16:41:32.143803: Epoch 6 
2024-12-11 16:41:32.147314: Current learning rate: 0.00946 
2024-12-11 16:42:07.802450: train_loss -0.342 
2024-12-11 16:42:07.808061: val_loss -0.3545 
2024-12-11 16:42:07.811117: Pseudo dice [np.float32(0.4246)] 
2024-12-11 16:42:07.813623: Epoch time: 35.66 s 
2024-12-11 16:42:07.817133: Yayy! New best EMA pseudo Dice: 0.18449999392032623 
2024-12-11 16:42:08.568325:  
2024-12-11 16:42:08.573894: Epoch 7 
2024-12-11 16:42:08.576437: Current learning rate: 0.00937 
2024-12-11 16:42:44.220550: train_loss -0.3499 
2024-12-11 16:42:44.225566: val_loss -0.398 
2024-12-11 16:42:44.229076: Pseudo dice [np.float32(0.462)] 
2024-12-11 16:42:44.231584: Epoch time: 35.65 s 
2024-12-11 16:42:44.235096: Yayy! New best EMA pseudo Dice: 0.21220000088214874 
2024-12-11 16:42:44.992042:  
2024-12-11 16:42:44.996086: Epoch 8 
2024-12-11 16:42:45.000167: Current learning rate: 0.00928 
2024-12-11 16:43:20.670714: train_loss -0.359 
2024-12-11 16:43:20.676729: val_loss -0.3368 
2024-12-11 16:43:20.679237: Pseudo dice [np.float32(0.3908)] 
2024-12-11 16:43:20.682745: Epoch time: 35.68 s 
2024-12-11 16:43:20.685755: Yayy! New best EMA pseudo Dice: 0.23010000586509705 
2024-12-11 16:43:21.473858:  
2024-12-11 16:43:21.478931: Epoch 9 
2024-12-11 16:43:21.481981: Current learning rate: 0.00919 
2024-12-11 16:43:57.133007: train_loss -0.3929 
2024-12-11 16:43:57.138605: val_loss -0.3655 
2024-12-11 16:43:57.141634: Pseudo dice [np.float32(0.4871)] 
2024-12-11 16:43:57.145643: Epoch time: 35.66 s 
2024-12-11 16:43:57.148149: Yayy! New best EMA pseudo Dice: 0.2558000087738037 
2024-12-11 16:43:57.880109:  
2024-12-11 16:43:57.885119: Epoch 10 
2024-12-11 16:43:57.889131: Current learning rate: 0.0091 
2024-12-11 16:44:33.541283: train_loss -0.4378 
2024-12-11 16:44:33.546841: val_loss -0.4358 
2024-12-11 16:44:33.549888: Pseudo dice [np.float32(0.4659)] 
2024-12-11 16:44:33.552929: Epoch time: 35.66 s 
2024-12-11 16:44:33.555457: Yayy! New best EMA pseudo Dice: 0.2768000066280365 
2024-12-11 16:44:34.307174:  
2024-12-11 16:44:34.312276: Epoch 11 
2024-12-11 16:44:34.315782: Current learning rate: 0.009 
2024-12-11 16:45:09.979484: train_loss -0.4404 
2024-12-11 16:45:09.985506: val_loss -0.415 
2024-12-11 16:45:09.988012: Pseudo dice [np.float32(0.479)] 
2024-12-11 16:45:09.991524: Epoch time: 35.67 s 
2024-12-11 16:45:09.994535: Yayy! New best EMA pseudo Dice: 0.296999990940094 
2024-12-11 16:45:10.745122:  
2024-12-11 16:45:10.750679: Epoch 12 
2024-12-11 16:45:10.753221: Current learning rate: 0.00891 
2024-12-11 16:45:46.410402: train_loss -0.4321 
2024-12-11 16:45:46.416560: val_loss -0.3372 
2024-12-11 16:45:46.420103: Pseudo dice [np.float32(0.462)] 
2024-12-11 16:45:46.423617: Epoch time: 35.67 s 
2024-12-11 16:45:46.427019: Yayy! New best EMA pseudo Dice: 0.31349998712539673 
2024-12-11 16:45:47.309360:  
2024-12-11 16:45:47.314372: Epoch 13 
2024-12-11 16:45:47.317880: Current learning rate: 0.00882 
2024-12-11 16:46:22.953284: train_loss -0.4192 
2024-12-11 16:46:22.958830: val_loss -0.3997 
2024-12-11 16:46:22.962339: Pseudo dice [np.float32(0.5483)] 
2024-12-11 16:46:22.968350: Epoch time: 35.65 s 
2024-12-11 16:46:22.971357: Yayy! New best EMA pseudo Dice: 0.3370000123977661 
2024-12-11 16:46:23.721824:  
2024-12-11 16:46:23.727337: Epoch 14 
2024-12-11 16:46:23.730845: Current learning rate: 0.00873 
2024-12-11 16:46:59.378182: train_loss -0.4116 
2024-12-11 16:46:59.384717: val_loss -0.3746 
2024-12-11 16:46:59.387725: Pseudo dice [np.float32(0.4611)] 
2024-12-11 16:46:59.391233: Epoch time: 35.66 s 
2024-12-11 16:46:59.393739: Yayy! New best EMA pseudo Dice: 0.34940001368522644 
2024-12-11 16:47:00.169211:  
2024-12-11 16:47:00.174784: Epoch 15 
2024-12-11 16:47:00.178833: Current learning rate: 0.00864 
2024-12-11 16:47:35.840423: train_loss -0.4273 
2024-12-11 16:47:35.845515: val_loss -0.457 
2024-12-11 16:47:35.850065: Pseudo dice [np.float32(0.4892)] 
2024-12-11 16:47:35.853100: Epoch time: 35.67 s 
2024-12-11 16:47:35.855662: Yayy! New best EMA pseudo Dice: 0.36340001225471497 
2024-12-11 16:47:36.605544:  
2024-12-11 16:47:36.611104: Epoch 16 
2024-12-11 16:47:36.613652: Current learning rate: 0.00855 
2024-12-11 16:48:12.248807: train_loss -0.427 
2024-12-11 16:48:12.255342: val_loss -0.4305 
2024-12-11 16:48:12.258350: Pseudo dice [np.float32(0.4849)] 
2024-12-11 16:48:12.261859: Epoch time: 35.64 s 
2024-12-11 16:48:12.265364: Yayy! New best EMA pseudo Dice: 0.37549999356269836 
2024-12-11 16:48:13.032182:  
2024-12-11 16:48:13.038199: Epoch 17 
2024-12-11 16:48:13.041719: Current learning rate: 0.00846 
2024-12-11 16:48:48.689270: train_loss -0.4238 
2024-12-11 16:48:48.695794: val_loss -0.4329 
2024-12-11 16:48:48.698301: Pseudo dice [np.float32(0.4995)] 
2024-12-11 16:48:48.701814: Epoch time: 35.66 s 
2024-12-11 16:48:48.704324: Yayy! New best EMA pseudo Dice: 0.3878999948501587 
2024-12-11 16:48:49.457700:  
2024-12-11 16:48:49.463744: Epoch 18 
2024-12-11 16:48:49.467335: Current learning rate: 0.00836 
2024-12-11 16:49:25.108681: train_loss -0.4738 
2024-12-11 16:49:25.114268: val_loss -0.4402 
2024-12-11 16:49:25.117812: Pseudo dice [np.float32(0.4888)] 
2024-12-11 16:49:25.120828: Epoch time: 35.65 s 
2024-12-11 16:49:25.124381: Yayy! New best EMA pseudo Dice: 0.39800000190734863 
2024-12-11 16:49:25.912806:  
2024-12-11 16:49:25.917986: Epoch 19 
2024-12-11 16:49:25.921560: Current learning rate: 0.00827 
2024-12-11 16:50:01.567313: train_loss -0.4307 
2024-12-11 16:50:01.572330: val_loss -0.4552 
2024-12-11 16:50:01.575846: Pseudo dice [np.float32(0.5242)] 
2024-12-11 16:50:01.578351: Epoch time: 35.66 s 
2024-12-11 16:50:01.581860: Yayy! New best EMA pseudo Dice: 0.4106000065803528 
2024-12-11 16:50:02.367190:  
2024-12-11 16:50:02.372240: Epoch 20 
2024-12-11 16:50:02.375753: Current learning rate: 0.00818 
2024-12-11 16:50:38.007163: train_loss -0.4857 
2024-12-11 16:50:38.012658: val_loss -0.4643 
2024-12-11 16:50:38.016693: Pseudo dice [np.float32(0.5306)] 
2024-12-11 16:50:38.019197: Epoch time: 35.64 s 
2024-12-11 16:50:38.022705: Yayy! New best EMA pseudo Dice: 0.42260000109672546 
2024-12-11 16:50:38.952178:  
2024-12-11 16:50:38.957719: Epoch 21 
2024-12-11 16:50:38.960974: Current learning rate: 0.00809 
2024-12-11 16:51:14.583294: train_loss -0.4381 
2024-12-11 16:51:14.588317: val_loss -0.4504 
2024-12-11 16:51:14.592327: Pseudo dice [np.float32(0.5206)] 
2024-12-11 16:51:14.594837: Epoch time: 35.63 s 
2024-12-11 16:51:14.598352: Yayy! New best EMA pseudo Dice: 0.4323999881744385 
2024-12-11 16:51:15.345034:  
2024-12-11 16:51:15.352615: Epoch 22 
2024-12-11 16:51:15.357315: Current learning rate: 0.008 
2024-12-11 16:51:50.989300: train_loss -0.4455 
2024-12-11 16:51:50.995457: val_loss -0.4308 
2024-12-11 16:51:50.998506: Pseudo dice [np.float32(0.4985)] 
2024-12-11 16:51:51.001566: Epoch time: 35.65 s 
2024-12-11 16:51:51.004644: Yayy! New best EMA pseudo Dice: 0.4390000104904175 
2024-12-11 16:51:51.736413:  
2024-12-11 16:51:51.741456: Epoch 23 
2024-12-11 16:51:51.746032: Current learning rate: 0.0079 
2024-12-11 16:52:27.369848: train_loss -0.4666 
2024-12-11 16:52:27.373932: val_loss -0.4558 
2024-12-11 16:52:27.377440: Pseudo dice [np.float32(0.5316)] 
2024-12-11 16:52:27.379946: Epoch time: 35.63 s 
2024-12-11 16:52:27.383953: Yayy! New best EMA pseudo Dice: 0.44830000400543213 
2024-12-11 16:52:28.126689:  
2024-12-11 16:52:28.132245: Epoch 24 
2024-12-11 16:52:28.136323: Current learning rate: 0.00781 
2024-12-11 16:53:03.789403: train_loss -0.472 
2024-12-11 16:53:03.794415: val_loss -0.4531 
2024-12-11 16:53:03.798426: Pseudo dice [np.float32(0.5569)] 
2024-12-11 16:53:03.800931: Epoch time: 35.66 s 
2024-12-11 16:53:03.804440: Yayy! New best EMA pseudo Dice: 0.459199994802475 
2024-12-11 16:53:04.535105:  
2024-12-11 16:53:04.538118: Epoch 25 
2024-12-11 16:53:04.542169: Current learning rate: 0.00772 
2024-12-11 16:53:46.185102: train_loss -0.4853 
2024-12-11 16:53:46.191147: val_loss -0.3904 
2024-12-11 16:53:46.193753: Pseudo dice [np.float32(0.472)] 
2024-12-11 16:53:46.196814: Epoch time: 41.65 s 
2024-12-11 16:53:46.199347: Yayy! New best EMA pseudo Dice: 0.4603999853134155 
2024-12-11 16:53:46.917211:  
2024-12-11 16:53:46.922357: Epoch 26 
2024-12-11 16:53:46.925399: Current learning rate: 0.00763 
2024-12-11 16:54:23.706031: train_loss -0.5126 
2024-12-11 16:54:23.711088: val_loss -0.4123 
2024-12-11 16:54:23.714713: Pseudo dice [np.float32(0.4746)] 
2024-12-11 16:54:23.717759: Epoch time: 36.79 s 
2024-12-11 16:54:23.720280: Yayy! New best EMA pseudo Dice: 0.461899995803833 
2024-12-11 16:54:24.435910:  
2024-12-11 16:54:24.441472: Epoch 27 
2024-12-11 16:54:24.444510: Current learning rate: 0.00753 
2024-12-11 16:55:01.349841: train_loss -0.5089 
2024-12-11 16:55:01.355477: val_loss -0.3906 
2024-12-11 16:55:01.358511: Pseudo dice [np.float32(0.4248)] 
2024-12-11 16:55:01.361561: Epoch time: 36.91 s 
2024-12-11 16:55:01.938640:  
2024-12-11 16:55:01.944650: Epoch 28 
2024-12-11 16:55:01.947156: Current learning rate: 0.00744 
2024-12-11 16:55:38.734615: train_loss -0.4361 
2024-12-11 16:55:38.740301: val_loss -0.4779 
2024-12-11 16:55:38.743954: Pseudo dice [np.float32(0.4999)] 
2024-12-11 16:55:38.747020: Epoch time: 36.8 s 
2024-12-11 16:55:38.750620: Yayy! New best EMA pseudo Dice: 0.46230000257492065 
2024-12-11 16:55:39.651790:  
2024-12-11 16:55:39.656834: Epoch 29 
2024-12-11 16:55:39.660379: Current learning rate: 0.00735 
2024-12-11 16:56:16.861598: train_loss -0.4975 
2024-12-11 16:56:16.866685: val_loss -0.491 
2024-12-11 16:56:16.870379: Pseudo dice [np.float32(0.5371)] 
2024-12-11 16:56:16.873610: Epoch time: 37.21 s 
2024-12-11 16:56:16.876175: Yayy! New best EMA pseudo Dice: 0.4697999954223633 
2024-12-11 16:56:17.608660:  
2024-12-11 16:56:17.613770: Epoch 30 
2024-12-11 16:56:17.616829: Current learning rate: 0.00725 
2024-12-11 16:56:54.710455: train_loss -0.5214 
2024-12-11 16:56:54.716104: val_loss -0.5025 
2024-12-11 16:56:54.719630: Pseudo dice [np.float32(0.548)] 
2024-12-11 16:56:54.722408: Epoch time: 37.1 s 
2024-12-11 16:56:54.725931: Yayy! New best EMA pseudo Dice: 0.47760000824928284 
2024-12-11 16:56:55.442755:  
2024-12-11 16:56:55.448127: Epoch 31 
2024-12-11 16:56:55.451192: Current learning rate: 0.00716 
2024-12-11 16:57:32.243971: train_loss -0.5245 
2024-12-11 16:57:32.249683: val_loss -0.4071 
2024-12-11 16:57:32.252849: Pseudo dice [np.float32(0.4948)] 
2024-12-11 16:57:32.255960: Epoch time: 36.8 s 
2024-12-11 16:57:32.258542: Yayy! New best EMA pseudo Dice: 0.47929999232292175 
2024-12-11 16:57:32.999238:  
2024-12-11 16:57:33.003974: Epoch 32 
2024-12-11 16:57:33.007082: Current learning rate: 0.00707 
2024-12-11 16:58:09.573272: train_loss -0.4677 
2024-12-11 16:58:09.578500: val_loss -0.4507 
2024-12-11 16:58:09.582030: Pseudo dice [np.float32(0.5532)] 
2024-12-11 16:58:09.585164: Epoch time: 36.57 s 
2024-12-11 16:58:09.588221: Yayy! New best EMA pseudo Dice: 0.48669999837875366 
2024-12-11 16:58:10.338837:  
2024-12-11 16:58:10.344499: Epoch 33 
2024-12-11 16:58:10.348094: Current learning rate: 0.00697 
2024-12-11 16:58:46.932713: train_loss -0.4822 
2024-12-11 16:58:46.938236: val_loss -0.405 
2024-12-11 16:58:46.941746: Pseudo dice [np.float32(0.4446)] 
2024-12-11 16:58:46.944309: Epoch time: 36.59 s 
2024-12-11 16:58:47.506935:  
2024-12-11 16:58:47.511456: Epoch 34 
2024-12-11 16:58:47.514607: Current learning rate: 0.00688 
2024-12-11 16:59:24.329209: train_loss -0.4861 
2024-12-11 16:59:24.335762: val_loss -0.4745 
2024-12-11 16:59:24.340831: Pseudo dice [np.float32(0.5828)] 
2024-12-11 16:59:24.344998: Epoch time: 36.82 s 
2024-12-11 16:59:24.348561: Yayy! New best EMA pseudo Dice: 0.4925000071525574 
2024-12-11 16:59:25.141268:  
2024-12-11 16:59:25.146858: Epoch 35 
2024-12-11 16:59:25.150456: Current learning rate: 0.00679 
2024-12-11 17:00:01.809750: train_loss -0.5384 
2024-12-11 17:00:01.814899: val_loss -0.4814 
2024-12-11 17:00:01.818950: Pseudo dice [np.float32(0.582)] 
2024-12-11 17:00:01.822038: Epoch time: 36.67 s 
2024-12-11 17:00:01.825193: Yayy! New best EMA pseudo Dice: 0.5015000104904175 
2024-12-11 17:00:02.620022:  
2024-12-11 17:00:02.625677: Epoch 36 
2024-12-11 17:00:02.629726: Current learning rate: 0.00669 
2024-12-11 17:00:39.464178: train_loss -0.5308 
2024-12-11 17:00:39.469263: val_loss -0.4452 
2024-12-11 17:00:39.471813: Pseudo dice [np.float32(0.4909)] 
2024-12-11 17:00:39.475345: Epoch time: 36.84 s 
2024-12-11 17:00:40.229003:  
2024-12-11 17:00:40.234092: Epoch 37 
2024-12-11 17:00:40.237172: Current learning rate: 0.0066 
2024-12-11 17:01:17.208807: train_loss -0.5441 
2024-12-11 17:01:17.214940: val_loss -0.4548 
2024-12-11 17:01:17.217463: Pseudo dice [np.float32(0.5336)] 
2024-12-11 17:01:17.220995: Epoch time: 36.98 s 
2024-12-11 17:01:17.224025: Yayy! New best EMA pseudo Dice: 0.5037000179290771 
2024-12-11 17:01:18.004634:  
2024-12-11 17:01:18.010192: Epoch 38 
2024-12-11 17:01:18.013765: Current learning rate: 0.0065 
2024-12-11 17:01:54.835858: train_loss -0.532 
2024-12-11 17:01:54.842143: val_loss -0.5119 
2024-12-11 17:01:54.844315: Pseudo dice [np.float32(0.5678)] 
2024-12-11 17:01:54.848969: Epoch time: 36.83 s 
2024-12-11 17:01:54.852549: Yayy! New best EMA pseudo Dice: 0.510200023651123 
2024-12-11 17:01:55.638974:  
2024-12-11 17:01:55.642482: Epoch 39 
2024-12-11 17:01:55.645988: Current learning rate: 0.00641 
2024-12-11 17:02:32.416289: train_loss -0.5532 
2024-12-11 17:02:32.421880: val_loss -0.4759 
2024-12-11 17:02:32.424901: Pseudo dice [np.float32(0.5158)] 
2024-12-11 17:02:32.428108: Epoch time: 36.78 s 
2024-12-11 17:02:32.431121: Yayy! New best EMA pseudo Dice: 0.510699987411499 
2024-12-11 17:02:33.211812:  
2024-12-11 17:02:33.217349: Epoch 40 
2024-12-11 17:02:33.220900: Current learning rate: 0.00631 
2024-12-11 17:03:10.106691: train_loss -0.5544 
2024-12-11 17:03:10.112282: val_loss -0.5141 
2024-12-11 17:03:10.115794: Pseudo dice [np.float32(0.5547)] 
2024-12-11 17:03:10.119297: Epoch time: 36.9 s 
2024-12-11 17:03:10.122887: Yayy! New best EMA pseudo Dice: 0.5151000022888184 
2024-12-11 17:03:10.900511:  
2024-12-11 17:03:10.905521: Epoch 41 
2024-12-11 17:03:10.909030: Current learning rate: 0.00622 
2024-12-11 17:03:47.701039: train_loss -0.5009 
2024-12-11 17:03:47.707160: val_loss -0.4678 
2024-12-11 17:03:47.709680: Pseudo dice [np.float32(0.5574)] 
2024-12-11 17:03:47.712801: Epoch time: 36.8 s 
2024-12-11 17:03:47.715841: Yayy! New best EMA pseudo Dice: 0.5192999839782715 
2024-12-11 17:03:48.478367:  
2024-12-11 17:03:48.482989: Epoch 42 
2024-12-11 17:03:48.487022: Current learning rate: 0.00612 
2024-12-11 17:04:25.336745: train_loss -0.5439 
2024-12-11 17:04:25.342808: val_loss -0.4131 
2024-12-11 17:04:25.346367: Pseudo dice [np.float32(0.4645)] 
2024-12-11 17:04:25.348908: Epoch time: 36.86 s 
2024-12-11 17:04:25.939993:  
2024-12-11 17:04:25.945580: Epoch 43 
2024-12-11 17:04:25.949141: Current learning rate: 0.00603 
2024-12-11 17:05:02.801020: train_loss -0.4835 
2024-12-11 17:05:02.807042: val_loss -0.4723 
2024-12-11 17:05:02.810561: Pseudo dice [np.float32(0.4657)] 
2024-12-11 17:05:02.813147: Epoch time: 36.86 s 
2024-12-11 17:05:03.545254:  
2024-12-11 17:05:03.551308: Epoch 44 
2024-12-11 17:05:03.554833: Current learning rate: 0.00593 
2024-12-11 17:05:40.360793: train_loss -0.5352 
2024-12-11 17:05:40.366464: val_loss -0.4737 
2024-12-11 17:05:40.369514: Pseudo dice [np.float32(0.5153)] 
2024-12-11 17:05:40.373155: Epoch time: 36.82 s 
2024-12-11 17:05:40.963145:  
2024-12-11 17:05:40.968204: Epoch 45 
2024-12-11 17:05:40.971862: Current learning rate: 0.00584 
2024-12-11 17:06:17.937845: train_loss -0.5384 
2024-12-11 17:06:17.943106: val_loss -0.4427 
2024-12-11 17:06:17.946646: Pseudo dice [np.float32(0.5071)] 
2024-12-11 17:06:17.950188: Epoch time: 36.98 s 
2024-12-11 17:06:18.518167:  
2024-12-11 17:06:18.523727: Epoch 46 
2024-12-11 17:06:18.527259: Current learning rate: 0.00574 
2024-12-11 17:06:55.604623: train_loss -0.536 
2024-12-11 17:06:55.609697: val_loss -0.4271 
2024-12-11 17:06:55.613230: Pseudo dice [np.float32(0.5131)] 
2024-12-11 17:06:55.616766: Epoch time: 37.09 s 
2024-12-11 17:06:56.193779:  
2024-12-11 17:06:56.199337: Epoch 47 
2024-12-11 17:06:56.204486: Current learning rate: 0.00565 
2024-12-11 17:07:33.072837: train_loss -0.5355 
2024-12-11 17:07:33.078396: val_loss -0.4993 
2024-12-11 17:07:33.081451: Pseudo dice [np.float32(0.5572)] 
2024-12-11 17:07:33.085084: Epoch time: 36.88 s 
2024-12-11 17:07:33.672428:  
2024-12-11 17:07:33.678028: Epoch 48 
2024-12-11 17:07:33.682043: Current learning rate: 0.00555 
2024-12-11 17:08:10.680586: train_loss -0.5645 
2024-12-11 17:08:10.686188: val_loss -0.4934 
2024-12-11 17:08:10.688728: Pseudo dice [np.float32(0.5591)] 
2024-12-11 17:08:10.692842: Epoch time: 37.01 s 
2024-12-11 17:08:11.294951:  
2024-12-11 17:08:11.300505: Epoch 49 
2024-12-11 17:08:11.303568: Current learning rate: 0.00546 
2024-12-11 17:08:48.469497: train_loss -0.5721 
2024-12-11 17:08:48.475043: val_loss -0.4254 
2024-12-11 17:08:48.478561: Pseudo dice [np.float32(0.5245)] 
2024-12-11 17:08:48.481579: Epoch time: 37.18 s 
2024-12-11 17:08:48.635148: Yayy! New best EMA pseudo Dice: 0.5195000171661377 
2024-12-11 17:08:49.396184:  
2024-12-11 17:08:49.402221: Epoch 50 
2024-12-11 17:08:49.406345: Current learning rate: 0.00536 
2024-12-11 17:09:26.324395: train_loss -0.5415 
2024-12-11 17:09:26.329467: val_loss -0.5378 
2024-12-11 17:09:26.332993: Pseudo dice [np.float32(0.5837)] 
2024-12-11 17:09:26.336621: Epoch time: 36.93 s 
2024-12-11 17:09:26.339678: Yayy! New best EMA pseudo Dice: 0.5259000062942505 
2024-12-11 17:09:27.093284:  
2024-12-11 17:09:27.098824: Epoch 51 
2024-12-11 17:09:27.101330: Current learning rate: 0.00526 
2024-12-11 17:10:04.253729: train_loss -0.5445 
2024-12-11 17:10:04.259881: val_loss -0.5071 
2024-12-11 17:10:04.263544: Pseudo dice [np.float32(0.5522)] 
2024-12-11 17:10:04.266572: Epoch time: 37.16 s 
2024-12-11 17:10:04.270083: Yayy! New best EMA pseudo Dice: 0.5285999774932861 
2024-12-11 17:10:05.204132:  
2024-12-11 17:10:05.209193: Epoch 52 
2024-12-11 17:10:05.212799: Current learning rate: 0.00517 
2024-12-11 17:10:42.284044: train_loss -0.5377 
2024-12-11 17:10:42.290201: val_loss -0.4909 
2024-12-11 17:10:42.292726: Pseudo dice [np.float32(0.5301)] 
2024-12-11 17:10:42.296273: Epoch time: 37.08 s 
2024-12-11 17:10:42.300325: Yayy! New best EMA pseudo Dice: 0.5286999940872192 
2024-12-11 17:10:43.048621:  
2024-12-11 17:10:43.054179: Epoch 53 
2024-12-11 17:10:43.057200: Current learning rate: 0.00507 
2024-12-11 17:11:20.135348: train_loss -0.577 
2024-12-11 17:11:20.141007: val_loss -0.5139 
2024-12-11 17:11:20.144127: Pseudo dice [np.float32(0.5523)] 
2024-12-11 17:11:20.146652: Epoch time: 37.09 s 
2024-12-11 17:11:20.150680: Yayy! New best EMA pseudo Dice: 0.5310999751091003 
2024-12-11 17:11:20.920618:  
2024-12-11 17:11:20.926842: Epoch 54 
2024-12-11 17:11:20.929910: Current learning rate: 0.00497 
2024-12-11 17:11:57.797477: train_loss -0.5467 
2024-12-11 17:11:57.803583: val_loss -0.5137 
2024-12-11 17:11:57.806621: Pseudo dice [np.float32(0.6121)] 
2024-12-11 17:11:57.810130: Epoch time: 36.88 s 
2024-12-11 17:11:57.813639: Yayy! New best EMA pseudo Dice: 0.5392000079154968 
2024-12-11 17:11:58.574595:  
2024-12-11 17:11:58.581110: Epoch 55 
2024-12-11 17:11:58.584709: Current learning rate: 0.00487 
2024-12-11 17:12:35.686981: train_loss -0.5334 
2024-12-11 17:12:35.692564: val_loss -0.5746 
2024-12-11 17:12:35.696195: Pseudo dice [np.float32(0.669)] 
2024-12-11 17:12:35.699709: Epoch time: 37.11 s 
2024-12-11 17:12:35.702184: Yayy! New best EMA pseudo Dice: 0.5522000193595886 
2024-12-11 17:12:36.476148:  
2024-12-11 17:12:36.483162: Epoch 56 
2024-12-11 17:12:36.486170: Current learning rate: 0.00478 
2024-12-11 17:13:13.297933: train_loss -0.5207 
2024-12-11 17:13:13.301469: val_loss -0.4885 
2024-12-11 17:13:13.304616: Pseudo dice [np.float32(0.5868)] 
2024-12-11 17:13:13.307656: Epoch time: 36.82 s 
2024-12-11 17:13:13.311203: Yayy! New best EMA pseudo Dice: 0.5555999875068665 
2024-12-11 17:13:14.090654:  
2024-12-11 17:13:14.095781: Epoch 57 
2024-12-11 17:13:14.098826: Current learning rate: 0.00468 
2024-12-11 17:13:51.161145: train_loss -0.5683 
2024-12-11 17:13:51.168389: val_loss -0.5355 
2024-12-11 17:13:51.173015: Pseudo dice [np.float32(0.5471)] 
2024-12-11 17:13:51.177047: Epoch time: 37.07 s 
2024-12-11 17:13:51.770460:  
2024-12-11 17:13:51.775974: Epoch 58 
2024-12-11 17:13:51.779486: Current learning rate: 0.00458 
2024-12-11 17:14:29.001819: train_loss -0.5813 
2024-12-11 17:14:29.007967: val_loss -0.4972 
2024-12-11 17:14:29.011036: Pseudo dice [np.float32(0.5689)] 
2024-12-11 17:14:29.014114: Epoch time: 37.23 s 
2024-12-11 17:14:29.017169: Yayy! New best EMA pseudo Dice: 0.5562000274658203 
2024-12-11 17:14:29.805607:  
2024-12-11 17:14:29.811123: Epoch 59 
2024-12-11 17:14:29.814634: Current learning rate: 0.00448 
2024-12-11 17:15:06.815509: train_loss -0.5649 
2024-12-11 17:15:06.821138: val_loss -0.5139 
2024-12-11 17:15:06.824802: Pseudo dice [np.float32(0.581)] 
2024-12-11 17:15:06.828373: Epoch time: 37.01 s 
2024-12-11 17:15:06.831431: Yayy! New best EMA pseudo Dice: 0.5587000250816345 
2024-12-11 17:15:07.770622:  
2024-12-11 17:15:07.776315: Epoch 60 
2024-12-11 17:15:07.780403: Current learning rate: 0.00438 
2024-12-11 17:15:44.653248: train_loss -0.6147 
2024-12-11 17:15:44.659268: val_loss -0.5638 
2024-12-11 17:15:44.662773: Pseudo dice [np.float32(0.6275)] 
2024-12-11 17:15:44.665833: Epoch time: 36.88 s 
2024-12-11 17:15:44.669342: Yayy! New best EMA pseudo Dice: 0.5655999779701233 
2024-12-11 17:15:45.429145:  
2024-12-11 17:15:45.434840: Epoch 61 
2024-12-11 17:15:45.438896: Current learning rate: 0.00429 
2024-12-11 17:16:22.523168: train_loss -0.556 
2024-12-11 17:16:22.529183: val_loss -0.5457 
2024-12-11 17:16:22.532771: Pseudo dice [np.float32(0.6039)] 
2024-12-11 17:16:22.535796: Epoch time: 37.09 s 
2024-12-11 17:16:22.539305: Yayy! New best EMA pseudo Dice: 0.5694000124931335 
2024-12-11 17:16:23.295596:  
2024-12-11 17:16:23.300641: Epoch 62 
2024-12-11 17:16:23.304533: Current learning rate: 0.00419 
2024-12-11 17:17:00.329003: train_loss -0.6319 
2024-12-11 17:17:00.335543: val_loss -0.5694 
2024-12-11 17:17:00.338051: Pseudo dice [np.float32(0.6495)] 
2024-12-11 17:17:00.341564: Epoch time: 37.03 s 
2024-12-11 17:17:00.345571: Yayy! New best EMA pseudo Dice: 0.5774000287055969 
2024-12-11 17:17:01.108623:  
2024-12-11 17:17:01.115782: Epoch 63 
2024-12-11 17:17:01.119863: Current learning rate: 0.00409 
2024-12-11 17:17:38.141734: train_loss -0.5619 
2024-12-11 17:17:38.146745: val_loss -0.5135 
2024-12-11 17:17:38.150254: Pseudo dice [np.float32(0.6335)] 
2024-12-11 17:17:38.153262: Epoch time: 37.03 s 
2024-12-11 17:17:38.156771: Yayy! New best EMA pseudo Dice: 0.5830000042915344 
2024-12-11 17:17:38.930590:  
2024-12-11 17:17:38.936159: Epoch 64 
2024-12-11 17:17:38.938698: Current learning rate: 0.00399 
2024-12-11 17:18:16.334035: train_loss -0.5922 
2024-12-11 17:18:16.340552: val_loss -0.5292 
2024-12-11 17:18:16.344176: Pseudo dice [np.float32(0.5888)] 
2024-12-11 17:18:16.347681: Epoch time: 37.4 s 
2024-12-11 17:18:16.350690: Yayy! New best EMA pseudo Dice: 0.5835999846458435 
2024-12-11 17:18:17.128685:  
2024-12-11 17:18:17.133877: Epoch 65 
2024-12-11 17:18:17.136919: Current learning rate: 0.00389 
2024-12-11 17:18:53.964173: train_loss -0.5719 
2024-12-11 17:18:53.969795: val_loss -0.5342 
2024-12-11 17:18:53.973329: Pseudo dice [np.float32(0.597)] 
2024-12-11 17:18:53.975849: Epoch time: 36.84 s 
2024-12-11 17:18:53.979872: Yayy! New best EMA pseudo Dice: 0.5849000215530396 
2024-12-11 17:18:54.743970:  
2024-12-11 17:18:54.749666: Epoch 66 
2024-12-11 17:18:54.752693: Current learning rate: 0.00379 
2024-12-11 17:19:31.766325: train_loss -0.5862 
2024-12-11 17:19:31.772058: val_loss -0.5282 
2024-12-11 17:19:31.775584: Pseudo dice [np.float32(0.6007)] 
2024-12-11 17:19:31.779180: Epoch time: 37.02 s 
2024-12-11 17:19:31.781723: Yayy! New best EMA pseudo Dice: 0.5864999890327454 
2024-12-11 17:19:32.577061:  
2024-12-11 17:19:32.582727: Epoch 67 
2024-12-11 17:19:32.586278: Current learning rate: 0.00369 
2024-12-11 17:20:09.842042: train_loss -0.5799 
2024-12-11 17:20:09.847468: val_loss -0.5853 
2024-12-11 17:20:09.850982: Pseudo dice [np.float32(0.616)] 
2024-12-11 17:20:09.854497: Epoch time: 37.27 s 
2024-12-11 17:20:09.857509: Yayy! New best EMA pseudo Dice: 0.5895000100135803 
2024-12-11 17:20:10.783706:  
2024-12-11 17:20:10.788721: Epoch 68 
2024-12-11 17:20:10.792847: Current learning rate: 0.00359 
2024-12-11 17:20:47.700869: train_loss -0.5991 
2024-12-11 17:20:47.705972: val_loss -0.5165 
2024-12-11 17:20:47.709533: Pseudo dice [np.float32(0.5775)] 
2024-12-11 17:20:47.712565: Epoch time: 36.92 s 
2024-12-11 17:20:48.327956:  
2024-12-11 17:20:48.332969: Epoch 69 
2024-12-11 17:20:48.336480: Current learning rate: 0.00349 
2024-12-11 17:21:25.171365: train_loss -0.6012 
2024-12-11 17:21:25.175443: val_loss -0.5532 
2024-12-11 17:21:25.177994: Pseudo dice [np.float32(0.6403)] 
2024-12-11 17:21:25.182166: Epoch time: 36.84 s 
2024-12-11 17:21:25.184745: Yayy! New best EMA pseudo Dice: 0.593500018119812 
2024-12-11 17:21:25.986131:  
2024-12-11 17:21:25.992808: Epoch 70 
2024-12-11 17:21:25.995340: Current learning rate: 0.00338 
2024-12-11 17:22:02.873157: train_loss -0.5892 
2024-12-11 17:22:02.878756: val_loss -0.5216 
2024-12-11 17:22:02.882931: Pseudo dice [np.float32(0.5445)] 
2024-12-11 17:22:02.885474: Epoch time: 36.89 s 
2024-12-11 17:22:03.488824:  
2024-12-11 17:22:03.494516: Epoch 71 
2024-12-11 17:22:03.497045: Current learning rate: 0.00328 
2024-12-11 17:22:40.337906: train_loss -0.5855 
2024-12-11 17:22:40.343564: val_loss -0.4594 
2024-12-11 17:22:40.347094: Pseudo dice [np.float32(0.4942)] 
2024-12-11 17:22:40.350643: Epoch time: 36.85 s 
2024-12-11 17:22:40.963542:  
2024-12-11 17:22:40.969092: Epoch 72 
2024-12-11 17:22:40.972626: Current learning rate: 0.00318 
2024-12-11 17:23:17.979501: train_loss -0.5955 
2024-12-11 17:23:17.985096: val_loss -0.4944 
2024-12-11 17:23:17.988156: Pseudo dice [np.float32(0.551)] 
2024-12-11 17:23:17.991691: Epoch time: 37.02 s 
2024-12-11 17:23:18.603608:  
2024-12-11 17:23:18.609132: Epoch 73 
2024-12-11 17:23:18.611708: Current learning rate: 0.00308 
2024-12-11 17:23:55.993765: train_loss -0.6099 
2024-12-11 17:23:55.999311: val_loss -0.5292 
2024-12-11 17:23:56.001816: Pseudo dice [np.float32(0.5768)] 
2024-12-11 17:23:56.005828: Epoch time: 37.39 s 
2024-12-11 17:23:56.612930:  
2024-12-11 17:23:56.617951: Epoch 74 
2024-12-11 17:23:56.620960: Current learning rate: 0.00297 
2024-12-11 17:24:33.786227: train_loss -0.6156 
2024-12-11 17:24:33.792280: val_loss -0.4932 
2024-12-11 17:24:33.795824: Pseudo dice [np.float32(0.6034)] 
2024-12-11 17:24:33.798856: Epoch time: 37.17 s 
2024-12-11 17:24:34.573728:  
2024-12-11 17:24:34.578742: Epoch 75 
2024-12-11 17:24:34.582258: Current learning rate: 0.00287 
2024-12-11 17:25:11.453795: train_loss -0.5702 
2024-12-11 17:25:11.461404: val_loss -0.549 
2024-12-11 17:25:11.466478: Pseudo dice [np.float32(0.6226)] 
2024-12-11 17:25:11.469069: Epoch time: 36.88 s 
2024-12-11 17:25:12.086291:  
2024-12-11 17:25:12.091377: Epoch 76 
2024-12-11 17:25:12.095023: Current learning rate: 0.00277 
2024-12-11 17:25:48.970219: train_loss -0.6021 
2024-12-11 17:25:48.975582: val_loss -0.5241 
2024-12-11 17:25:48.979127: Pseudo dice [np.float32(0.642)] 
2024-12-11 17:25:48.982358: Epoch time: 36.88 s 
2024-12-11 17:25:49.590590:  
2024-12-11 17:25:49.596244: Epoch 77 
2024-12-11 17:25:49.598777: Current learning rate: 0.00266 
2024-12-11 17:26:26.808640: train_loss -0.6183 
2024-12-11 17:26:26.814828: val_loss -0.6044 
2024-12-11 17:26:26.818379: Pseudo dice [np.float32(0.7037)] 
2024-12-11 17:26:26.820905: Epoch time: 37.22 s 
2024-12-11 17:26:26.824485: Yayy! New best EMA pseudo Dice: 0.6007000207901001 
2024-12-11 17:26:27.615401:  
2024-12-11 17:26:27.621029: Epoch 78 
2024-12-11 17:26:27.624131: Current learning rate: 0.00256 
2024-12-11 17:27:04.554313: train_loss -0.6242 
2024-12-11 17:27:04.560325: val_loss -0.6158 
2024-12-11 17:27:04.563336: Pseudo dice [np.float32(0.6643)] 
2024-12-11 17:27:04.565843: Epoch time: 36.94 s 
2024-12-11 17:27:04.569351: Yayy! New best EMA pseudo Dice: 0.6071000099182129 
2024-12-11 17:27:05.350891:  
2024-12-11 17:27:05.356966: Epoch 79 
2024-12-11 17:27:05.360030: Current learning rate: 0.00245 
2024-12-11 17:27:42.776201: train_loss -0.6272 
2024-12-11 17:27:42.781863: val_loss -0.6014 
2024-12-11 17:27:42.784983: Pseudo dice [np.float32(0.6372)] 
2024-12-11 17:27:42.788055: Epoch time: 37.43 s 
2024-12-11 17:27:42.791120: Yayy! New best EMA pseudo Dice: 0.6100999712944031 
2024-12-11 17:27:43.586563:  
2024-12-11 17:27:43.591653: Epoch 80 
2024-12-11 17:27:43.594164: Current learning rate: 0.00235 
2024-12-11 17:28:20.752182: train_loss -0.599 
2024-12-11 17:28:20.757800: val_loss -0.4136 
2024-12-11 17:28:20.760328: Pseudo dice [np.float32(0.4579)] 
2024-12-11 17:28:20.763932: Epoch time: 37.17 s 
2024-12-11 17:28:21.385487:  
2024-12-11 17:28:21.391033: Epoch 81 
2024-12-11 17:28:21.394170: Current learning rate: 0.00224 
2024-12-11 17:28:58.803621: train_loss -0.6377 
2024-12-11 17:28:58.808682: val_loss -0.5513 
2024-12-11 17:28:58.812732: Pseudo dice [np.float32(0.5972)] 
2024-12-11 17:28:58.816345: Epoch time: 37.42 s 
2024-12-11 17:28:59.441754:  
2024-12-11 17:28:59.446782: Epoch 82 
2024-12-11 17:28:59.450349: Current learning rate: 0.00214 
2024-12-11 17:29:36.547455: train_loss -0.6379 
2024-12-11 17:29:36.553771: val_loss -0.6302 
2024-12-11 17:29:36.558337: Pseudo dice [np.float32(0.7134)] 
2024-12-11 17:29:36.563998: Epoch time: 37.11 s 
2024-12-11 17:29:37.331453:  
2024-12-11 17:29:37.336483: Epoch 83 
2024-12-11 17:29:37.339145: Current learning rate: 0.00203 
2024-12-11 17:30:14.443320: train_loss -0.5882 
2024-12-11 17:30:14.449330: val_loss -0.5529 
2024-12-11 17:30:14.452339: Pseudo dice [np.float32(0.6295)] 
2024-12-11 17:30:14.455848: Epoch time: 37.11 s 
2024-12-11 17:30:15.048808:  
2024-12-11 17:30:15.054449: Epoch 84 
2024-12-11 17:30:15.057976: Current learning rate: 0.00192 
2024-12-11 17:30:52.066689: train_loss -0.6189 
2024-12-11 17:30:52.072221: val_loss -0.5919 
2024-12-11 17:30:52.075727: Pseudo dice [np.float32(0.633)] 
2024-12-11 17:30:52.078740: Epoch time: 37.02 s 
2024-12-11 17:30:52.082249: Yayy! New best EMA pseudo Dice: 0.6115999817848206 
2024-12-11 17:30:52.830611:  
2024-12-11 17:30:52.836187: Epoch 85 
2024-12-11 17:30:52.838725: Current learning rate: 0.00181 
2024-12-11 17:31:29.905957: train_loss -0.6547 
2024-12-11 17:31:29.911970: val_loss -0.6078 
2024-12-11 17:31:29.915983: Pseudo dice [np.float32(0.6345)] 
2024-12-11 17:31:29.919991: Epoch time: 37.08 s 
2024-12-11 17:31:29.922496: Yayy! New best EMA pseudo Dice: 0.6139000058174133 
2024-12-11 17:31:30.680323:  
2024-12-11 17:31:30.687434: Epoch 86 
2024-12-11 17:31:30.691034: Current learning rate: 0.0017 
2024-12-11 17:32:07.520956: train_loss -0.6472 
2024-12-11 17:32:07.526557: val_loss -0.5524 
2024-12-11 17:32:07.529069: Pseudo dice [np.float32(0.6121)] 
2024-12-11 17:32:07.533086: Epoch time: 36.84 s 
2024-12-11 17:32:08.111536:  
2024-12-11 17:32:08.117130: Epoch 87 
2024-12-11 17:32:08.120273: Current learning rate: 0.00159 
2024-12-11 17:32:45.185782: train_loss -0.6567 
2024-12-11 17:32:45.191378: val_loss -0.6422 
2024-12-11 17:32:45.194080: Pseudo dice [np.float32(0.7215)] 
2024-12-11 17:32:45.198133: Epoch time: 37.07 s 
2024-12-11 17:32:45.200681: Yayy! New best EMA pseudo Dice: 0.6244999766349792 
2024-12-11 17:32:45.960100:  
2024-12-11 17:32:45.966347: Epoch 88 
2024-12-11 17:32:45.969453: Current learning rate: 0.00148 
2024-12-11 17:33:22.855809: train_loss -0.6189 
2024-12-11 17:33:22.861957: val_loss -0.549 
2024-12-11 17:33:22.865110: Pseudo dice [np.float32(0.6819)] 
2024-12-11 17:33:22.869124: Epoch time: 36.9 s 
2024-12-11 17:33:22.871630: Yayy! New best EMA pseudo Dice: 0.6302000284194946 
2024-12-11 17:33:23.636859:  
2024-12-11 17:33:23.643091: Epoch 89 
2024-12-11 17:33:23.645610: Current learning rate: 0.00137 
2024-12-11 17:34:00.549267: train_loss -0.6313 
2024-12-11 17:34:00.554906: val_loss -0.5654 
2024-12-11 17:34:00.558505: Pseudo dice [np.float32(0.6757)] 
2024-12-11 17:34:00.564154: Epoch time: 36.91 s 
2024-12-11 17:34:00.567183: Yayy! New best EMA pseudo Dice: 0.6348000168800354 
2024-12-11 17:34:01.325735:  
2024-12-11 17:34:01.331250: Epoch 90 
2024-12-11 17:34:01.334380: Current learning rate: 0.00126 
2024-12-11 17:34:38.233912: train_loss -0.649 
2024-12-11 17:34:38.239978: val_loss -0.5851 
2024-12-11 17:34:38.243602: Pseudo dice [np.float32(0.6862)] 
2024-12-11 17:34:38.246123: Epoch time: 36.91 s 
2024-12-11 17:34:38.249647: Yayy! New best EMA pseudo Dice: 0.6399000287055969 
2024-12-11 17:34:39.162141:  
2024-12-11 17:34:39.167666: Epoch 91 
2024-12-11 17:34:39.171191: Current learning rate: 0.00115 
2024-12-11 17:35:16.534583: train_loss -0.6297 
2024-12-11 17:35:16.540112: val_loss -0.5914 
2024-12-11 17:35:16.543136: Pseudo dice [np.float32(0.6468)] 
2024-12-11 17:35:16.546164: Epoch time: 37.37 s 
2024-12-11 17:35:16.549669: Yayy! New best EMA pseudo Dice: 0.6406000256538391 
2024-12-11 17:35:17.311601:  
2024-12-11 17:35:17.317115: Epoch 92 
2024-12-11 17:35:17.320626: Current learning rate: 0.00103 
2024-12-11 17:35:54.318128: train_loss -0.6354 
2024-12-11 17:35:54.324285: val_loss -0.6135 
2024-12-11 17:35:54.326807: Pseudo dice [np.float32(0.7131)] 
2024-12-11 17:35:54.330332: Epoch time: 37.01 s 
2024-12-11 17:35:54.332930: Yayy! New best EMA pseudo Dice: 0.6478000283241272 
2024-12-11 17:35:55.095924:  
2024-12-11 17:35:55.100988: Epoch 93 
2024-12-11 17:35:55.106187: Current learning rate: 0.00091 
2024-12-11 17:36:32.178972: train_loss -0.6611 
2024-12-11 17:36:32.184547: val_loss -0.4866 
2024-12-11 17:36:32.188076: Pseudo dice [np.float32(0.5884)] 
2024-12-11 17:36:32.191132: Epoch time: 37.08 s 
2024-12-11 17:36:32.773630:  
2024-12-11 17:36:32.779165: Epoch 94 
2024-12-11 17:36:32.781754: Current learning rate: 0.00079 
2024-12-11 17:37:09.614683: train_loss -0.6312 
2024-12-11 17:37:09.619695: val_loss -0.5631 
2024-12-11 17:37:09.623703: Pseudo dice [np.float32(0.6585)] 
2024-12-11 17:37:09.627211: Epoch time: 36.84 s 
2024-12-11 17:37:10.206654:  
2024-12-11 17:37:10.212274: Epoch 95 
2024-12-11 17:37:10.215896: Current learning rate: 0.00067 
2024-12-11 17:37:47.294022: train_loss -0.6383 
2024-12-11 17:37:47.300079: val_loss -0.601 
2024-12-11 17:37:47.303621: Pseudo dice [np.float32(0.6626)] 
2024-12-11 17:37:47.306660: Epoch time: 37.09 s 
2024-12-11 17:37:47.883073:  
2024-12-11 17:37:47.888616: Epoch 96 
2024-12-11 17:37:47.891745: Current learning rate: 0.00055 
2024-12-11 17:38:24.789208: train_loss -0.6482 
2024-12-11 17:38:24.795424: val_loss -0.6156 
2024-12-11 17:38:24.799436: Pseudo dice [np.float32(0.683)] 
2024-12-11 17:38:24.802054: Epoch time: 36.91 s 
2024-12-11 17:38:24.804595: Yayy! New best EMA pseudo Dice: 0.6492000222206116 
2024-12-11 17:38:25.562156:  
2024-12-11 17:38:25.569357: Epoch 97 
2024-12-11 17:38:25.572977: Current learning rate: 0.00043 
2024-12-11 17:39:02.700239: train_loss -0.662 
2024-12-11 17:39:02.706825: val_loss -0.5841 
2024-12-11 17:39:02.710859: Pseudo dice [np.float32(0.6183)] 
2024-12-11 17:39:02.714868: Epoch time: 37.14 s 
2024-12-11 17:39:03.310730:  
2024-12-11 17:39:03.316474: Epoch 98 
2024-12-11 17:39:03.322168: Current learning rate: 0.0003 
2024-12-11 17:39:40.698968: train_loss -0.6784 
2024-12-11 17:39:40.705146: val_loss -0.5914 
2024-12-11 17:39:40.709717: Pseudo dice [np.float32(0.6596)] 
2024-12-11 17:39:40.713269: Epoch time: 37.39 s 
2024-12-11 17:39:41.481257:  
2024-12-11 17:39:41.487925: Epoch 99 
2024-12-11 17:39:41.491959: Current learning rate: 0.00016 
2024-12-11 17:40:18.349905: train_loss -0.6379 
2024-12-11 17:40:18.356163: val_loss -0.5678 
2024-12-11 17:40:18.361186: Pseudo dice [np.float32(0.6552)] 
2024-12-11 17:40:18.365314: Epoch time: 36.87 s 
2024-12-11 17:40:19.174097: Training done. 
2024-12-11 17:40:19.203082: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-11 17:40:19.210081: The split file contains 5 splits. 
2024-12-11 17:40:19.217082: Desired fold for training: 0 
2024-12-11 17:40:19.221084: This split has 100 training and 26 validation cases. 
2024-12-11 17:40:19.228225: predicting colon_008 
2024-12-11 17:40:19.234224: colon_008, shape torch.Size([1, 89, 465, 465]), rank 0 
2024-12-11 17:40:32.565940: predicting colon_027 
2024-12-11 17:40:32.581941: colon_027, shape torch.Size([1, 38, 440, 440]), rank 0 
2024-12-11 17:40:35.436910: predicting colon_030 
2024-12-11 17:40:35.448911: colon_030, shape torch.Size([1, 90, 384, 384]), rank 0 
2024-12-11 17:40:42.710877: predicting colon_033 
2024-12-11 17:40:42.723051: colon_033, shape torch.Size([1, 98, 480, 480]), rank 0 
2024-12-11 17:40:58.056481: predicting colon_041 
2024-12-11 17:40:58.072548: colon_041, shape torch.Size([1, 104, 591, 591]), rank 0 
2024-12-11 17:41:21.968451: predicting colon_042 
2024-12-11 17:41:21.989877: colon_042, shape torch.Size([1, 55, 640, 640]), rank 0 
2024-12-11 17:41:33.925714: predicting colon_061 
2024-12-11 17:41:33.943017: colon_061, shape torch.Size([1, 85, 529, 529]), rank 0 
2024-12-11 17:41:46.653483: predicting colon_074 
2024-12-11 17:41:46.670210: colon_074, shape torch.Size([1, 80, 607, 607]), rank 0 
2024-12-11 17:42:02.539239: predicting colon_075 
2024-12-11 17:42:02.559238: colon_075, shape torch.Size([1, 86, 474, 474]), rank 0 
2024-12-11 17:42:15.248185: predicting colon_088 
2024-12-11 17:42:15.265185: colon_088, shape torch.Size([1, 95, 563, 563]), rank 0 
2024-12-11 17:42:35.188962: predicting colon_091 
2024-12-11 17:42:35.212687: colon_091, shape torch.Size([1, 103, 543, 543]), rank 0 
2024-12-11 17:42:50.698338: predicting colon_092 
2024-12-11 17:42:50.718998: colon_092, shape torch.Size([1, 90, 492, 492]), rank 0 
2024-12-11 17:43:03.697829: predicting colon_095 
2024-12-11 17:43:03.713832: colon_095, shape torch.Size([1, 96, 452, 452]), rank 0 
2024-12-11 17:43:16.459241: predicting colon_102 
2024-12-11 17:43:16.475242: colon_102, shape torch.Size([1, 96, 590, 590]), rank 0 
2024-12-11 17:43:36.472122: predicting colon_111 
2024-12-11 17:43:36.494277: colon_111, shape torch.Size([1, 48, 521, 521]), rank 0 
2024-12-11 17:43:41.713975: predicting colon_115 
2024-12-11 17:43:41.726224: colon_115, shape torch.Size([1, 97, 470, 470]), rank 0 
2024-12-11 17:43:57.005558: predicting colon_118 
2024-12-11 17:43:57.021558: colon_118, shape torch.Size([1, 100, 486, 486]), rank 0 
2024-12-11 17:44:12.183915: predicting colon_124 
2024-12-11 17:44:12.205097: colon_124, shape torch.Size([1, 92, 535, 535]), rank 0 
2024-12-11 17:44:25.438250: predicting colon_127 
2024-12-11 17:44:25.455485: colon_127, shape torch.Size([1, 130, 598, 598]), rank 0 
2024-12-11 17:44:57.360132: predicting colon_154 
2024-12-11 17:44:57.385077: colon_154, shape torch.Size([1, 94, 461, 461]), rank 0 
2024-12-11 17:45:10.111781: predicting colon_161 
2024-12-11 17:45:10.129654: colon_161, shape torch.Size([1, 95, 474, 474]), rank 0 
2024-12-11 17:45:22.888403: predicting colon_162 
2024-12-11 17:45:22.904406: colon_162, shape torch.Size([1, 104, 598, 598]), rank 0 
2024-12-11 17:45:47.030802: predicting colon_165 
2024-12-11 17:45:47.054954: colon_165, shape torch.Size([1, 85, 577, 577]), rank 0 
2024-12-11 17:46:06.911702: predicting colon_166 
2024-12-11 17:46:06.933053: colon_166, shape torch.Size([1, 87, 474, 474]), rank 0 
2024-12-11 17:46:19.665409: predicting colon_169 
2024-12-11 17:46:19.680562: colon_169, shape torch.Size([1, 129, 621, 621]), rank 0 
2024-12-11 17:46:51.404154: predicting colon_187 
2024-12-11 17:46:51.432657: colon_187, shape torch.Size([1, 94, 513, 513]), rank 0 
2024-12-11 17:47:12.168805: Validation complete 
2024-12-11 17:47:12.174804: Mean Validation Dice:  0.30463340783310344 
