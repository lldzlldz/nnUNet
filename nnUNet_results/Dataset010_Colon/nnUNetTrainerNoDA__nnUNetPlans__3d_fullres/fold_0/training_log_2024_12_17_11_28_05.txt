
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-17 11:28:05.347261: do_dummy_2d_data_aug: True 
2024-12-17 11:28:05.348261: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-17 11:28:05.352261: The split file contains 5 splits. 
2024-12-17 11:28:05.355261: Desired fold for training: 0 
2024-12-17 11:28:05.357261: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2024-12-17 11:28:11.285877: unpacking dataset... 
2024-12-17 11:28:11.482626: unpacking done... 
2024-12-17 11:28:14.227566:  
2024-12-17 11:28:14.232139: Epoch 0 
2024-12-17 11:28:14.235152: Current learning rate: 0.01 
2024-12-17 11:29:00.033638: train_loss 0.0367 
2024-12-17 11:29:00.038661: val_loss -0.005 
2024-12-17 11:29:00.042169: Pseudo dice [np.float32(0.0)] 
2024-12-17 11:29:00.044707: Epoch time: 45.81 s 
2024-12-17 11:29:00.048223: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-17 11:29:00.686358:  
2024-12-17 11:29:00.691905: Epoch 1 
2024-12-17 11:29:00.695418: Current learning rate: 0.00991 
2024-12-17 11:29:42.018322: train_loss -0.1267 
2024-12-17 11:29:42.023974: val_loss -0.2088 
2024-12-17 11:29:42.026521: Pseudo dice [np.float32(0.273)] 
2024-12-17 11:29:42.031084: Epoch time: 41.33 s 
2024-12-17 11:29:42.034139: Yayy! New best EMA pseudo Dice: 0.027300000190734863 
2024-12-17 11:29:42.737399:  
2024-12-17 11:29:42.742528: Epoch 2 
2024-12-17 11:29:42.745041: Current learning rate: 0.00982 
2024-12-17 11:30:24.077739: train_loss -0.3182 
2024-12-17 11:30:24.084265: val_loss -0.3598 
2024-12-17 11:30:24.086773: Pseudo dice [np.float32(0.4114)] 
2024-12-17 11:30:24.090320: Epoch time: 41.34 s 
2024-12-17 11:30:24.092842: Yayy! New best EMA pseudo Dice: 0.065700002014637 
2024-12-17 11:30:24.822617:  
2024-12-17 11:30:24.827631: Epoch 3 
2024-12-17 11:30:24.831138: Current learning rate: 0.00973 
2024-12-17 11:31:06.169825: train_loss -0.3535 
2024-12-17 11:31:06.174837: val_loss -0.3433 
2024-12-17 11:31:06.177342: Pseudo dice [np.float32(0.4565)] 
2024-12-17 11:31:06.180851: Epoch time: 41.35 s 
2024-12-17 11:31:06.183357: Yayy! New best EMA pseudo Dice: 0.10480000078678131 
2024-12-17 11:31:06.894646:  
2024-12-17 11:31:06.898226: Epoch 4 
2024-12-17 11:31:06.902296: Current learning rate: 0.00964 
2024-12-17 11:31:48.222481: train_loss -0.3912 
2024-12-17 11:31:48.229028: val_loss -0.4021 
2024-12-17 11:31:48.232049: Pseudo dice [np.float32(0.4622)] 
2024-12-17 11:31:48.234565: Epoch time: 41.33 s 
2024-12-17 11:31:48.237592: Yayy! New best EMA pseudo Dice: 0.1404999941587448 
2024-12-17 11:31:49.067830:  
2024-12-17 11:31:49.073407: Epoch 5 
2024-12-17 11:31:49.075937: Current learning rate: 0.00955 
2024-12-17 11:32:30.390975: train_loss -0.4349 
2024-12-17 11:32:30.397042: val_loss -0.3458 
2024-12-17 11:32:30.400092: Pseudo dice [np.float32(0.4615)] 
2024-12-17 11:32:30.402641: Epoch time: 41.32 s 
2024-12-17 11:32:30.405178: Yayy! New best EMA pseudo Dice: 0.17260000109672546 
2024-12-17 11:32:31.098707:  
2024-12-17 11:32:31.103723: Epoch 6 
2024-12-17 11:32:31.107233: Current learning rate: 0.00946 
2024-12-17 11:33:12.421695: train_loss -0.4528 
2024-12-17 11:33:12.426706: val_loss -0.4113 
2024-12-17 11:33:12.430215: Pseudo dice [np.float32(0.4881)] 
2024-12-17 11:33:12.432720: Epoch time: 41.32 s 
2024-12-17 11:33:12.435226: Yayy! New best EMA pseudo Dice: 0.20419999957084656 
2024-12-17 11:33:13.140443:  
2024-12-17 11:33:13.145490: Epoch 7 
2024-12-17 11:33:13.147997: Current learning rate: 0.00937 
2024-12-17 11:33:54.475913: train_loss -0.4717 
2024-12-17 11:33:54.481576: val_loss -0.4032 
2024-12-17 11:33:54.484140: Pseudo dice [np.float32(0.511)] 
2024-12-17 11:33:54.487201: Epoch time: 41.34 s 
2024-12-17 11:33:54.489740: Yayy! New best EMA pseudo Dice: 0.23489999771118164 
2024-12-17 11:33:55.209417:  
2024-12-17 11:33:55.213979: Epoch 8 
2024-12-17 11:33:55.217012: Current learning rate: 0.00928 
2024-12-17 11:34:36.554093: train_loss -0.4817 
2024-12-17 11:34:36.559225: val_loss -0.4277 
2024-12-17 11:34:36.562769: Pseudo dice [np.float32(0.5009)] 
2024-12-17 11:34:36.565289: Epoch time: 41.35 s 
2024-12-17 11:34:36.567811: Yayy! New best EMA pseudo Dice: 0.2615000009536743 
2024-12-17 11:34:37.296789:  
2024-12-17 11:34:37.301894: Epoch 9 
2024-12-17 11:34:37.304430: Current learning rate: 0.00919 
2024-12-17 11:35:18.628947: train_loss -0.4888 
2024-12-17 11:35:18.634520: val_loss -0.4107 
2024-12-17 11:35:18.638030: Pseudo dice [np.float32(0.5005)] 
2024-12-17 11:35:18.640539: Epoch time: 41.33 s 
2024-12-17 11:35:18.643043: Yayy! New best EMA pseudo Dice: 0.28540000319480896 
2024-12-17 11:35:19.335214:  
2024-12-17 11:35:19.339280: Epoch 10 
2024-12-17 11:35:19.343849: Current learning rate: 0.0091 
2024-12-17 11:36:00.677271: train_loss -0.5693 
2024-12-17 11:36:00.682881: val_loss -0.4683 
2024-12-17 11:36:00.686433: Pseudo dice [np.float32(0.5976)] 
2024-12-17 11:36:00.690467: Epoch time: 41.34 s 
2024-12-17 11:36:00.693505: Yayy! New best EMA pseudo Dice: 0.3165999948978424 
2024-12-17 11:36:01.400219:  
2024-12-17 11:36:01.405229: Epoch 11 
2024-12-17 11:36:01.408237: Current learning rate: 0.009 
2024-12-17 11:36:42.723254: train_loss -0.5598 
2024-12-17 11:36:42.730309: val_loss -0.4936 
2024-12-17 11:36:42.733337: Pseudo dice [np.float32(0.579)] 
2024-12-17 11:36:42.736859: Epoch time: 41.32 s 
2024-12-17 11:36:42.739379: Yayy! New best EMA pseudo Dice: 0.34279999136924744 
2024-12-17 11:36:43.443879:  
2024-12-17 11:36:43.449438: Epoch 12 
2024-12-17 11:36:43.451978: Current learning rate: 0.00891 
2024-12-17 11:37:24.797710: train_loss -0.5449 
2024-12-17 11:37:24.804281: val_loss -0.3998 
2024-12-17 11:37:24.807344: Pseudo dice [np.float32(0.4819)] 
2024-12-17 11:37:24.810400: Epoch time: 41.35 s 
2024-12-17 11:37:24.812947: Yayy! New best EMA pseudo Dice: 0.35670000314712524 
2024-12-17 11:37:25.667225:  
2024-12-17 11:37:25.672804: Epoch 13 
2024-12-17 11:37:25.676352: Current learning rate: 0.00882 
2024-12-17 11:38:06.998252: train_loss -0.573 
2024-12-17 11:38:07.003303: val_loss -0.4882 
2024-12-17 11:38:07.006812: Pseudo dice [np.float32(0.5869)] 
2024-12-17 11:38:07.009317: Epoch time: 41.33 s 
2024-12-17 11:38:07.011827: Yayy! New best EMA pseudo Dice: 0.3797999918460846 
2024-12-17 11:38:07.728642:  
2024-12-17 11:38:07.733562: Epoch 14 
2024-12-17 11:38:07.736067: Current learning rate: 0.00873 
2024-12-17 11:38:49.053678: train_loss -0.5479 
2024-12-17 11:38:49.059192: val_loss -0.4971 
2024-12-17 11:38:49.061697: Pseudo dice [np.float32(0.5798)] 
2024-12-17 11:38:49.065206: Epoch time: 41.33 s 
2024-12-17 11:38:49.067712: Yayy! New best EMA pseudo Dice: 0.39980000257492065 
2024-12-17 11:38:49.786076:  
2024-12-17 11:38:49.790593: Epoch 15 
2024-12-17 11:38:49.794106: Current learning rate: 0.00864 
2024-12-17 11:39:31.100640: train_loss -0.5901 
2024-12-17 11:39:31.107179: val_loss -0.4321 
2024-12-17 11:39:31.110198: Pseudo dice [np.float32(0.5204)] 
2024-12-17 11:39:31.113222: Epoch time: 41.32 s 
2024-12-17 11:39:31.116261: Yayy! New best EMA pseudo Dice: 0.41179999709129333 
2024-12-17 11:39:31.837355:  
2024-12-17 11:39:31.842366: Epoch 16 
2024-12-17 11:39:31.845874: Current learning rate: 0.00855 
2024-12-17 11:40:13.181230: train_loss -0.5599 
2024-12-17 11:40:13.186780: val_loss -0.4905 
2024-12-17 11:40:13.190304: Pseudo dice [np.float32(0.6172)] 
2024-12-17 11:40:13.193332: Epoch time: 41.35 s 
2024-12-17 11:40:13.196355: Yayy! New best EMA pseudo Dice: 0.4323999881744385 
2024-12-17 11:40:13.929418:  
2024-12-17 11:40:13.934931: Epoch 17 
2024-12-17 11:40:13.937441: Current learning rate: 0.00846 
2024-12-17 11:40:55.271102: train_loss -0.5897 
2024-12-17 11:40:55.275714: val_loss -0.3547 
2024-12-17 11:40:55.280264: Pseudo dice [np.float32(0.573)] 
2024-12-17 11:40:55.283370: Epoch time: 41.34 s 
2024-12-17 11:40:55.285906: Yayy! New best EMA pseudo Dice: 0.446399986743927 
2024-12-17 11:40:56.014628:  
2024-12-17 11:40:56.019657: Epoch 18 
2024-12-17 11:40:56.022685: Current learning rate: 0.00836 
2024-12-17 11:41:37.335708: train_loss -0.6628 
2024-12-17 11:41:37.342242: val_loss -0.4437 
2024-12-17 11:41:37.344779: Pseudo dice [np.float32(0.5478)] 
2024-12-17 11:41:37.348288: Epoch time: 41.32 s 
2024-12-17 11:41:37.351794: Yayy! New best EMA pseudo Dice: 0.45660001039505005 
2024-12-17 11:41:38.077138:  
2024-12-17 11:41:38.082703: Epoch 19 
2024-12-17 11:41:38.086277: Current learning rate: 0.00827 
2024-12-17 11:42:19.409318: train_loss -0.6047 
2024-12-17 11:42:19.415387: val_loss -0.4465 
2024-12-17 11:42:19.418916: Pseudo dice [np.float32(0.5457)] 
2024-12-17 11:42:19.421941: Epoch time: 41.33 s 
2024-12-17 11:42:19.424976: Yayy! New best EMA pseudo Dice: 0.46549999713897705 
2024-12-17 11:42:20.153544:  
2024-12-17 11:42:20.157570: Epoch 20 
2024-12-17 11:42:20.161095: Current learning rate: 0.00818 
2024-12-17 11:43:01.474554: train_loss -0.6479 
2024-12-17 11:43:01.481647: val_loss -0.3896 
2024-12-17 11:43:01.484167: Pseudo dice [np.float32(0.5154)] 
2024-12-17 11:43:01.487202: Epoch time: 41.32 s 
2024-12-17 11:43:01.490231: Yayy! New best EMA pseudo Dice: 0.47049999237060547 
2024-12-17 11:43:02.384403:  
2024-12-17 11:43:02.389462: Epoch 21 
2024-12-17 11:43:02.393003: Current learning rate: 0.00809 
2024-12-17 11:43:43.719425: train_loss -0.647 
2024-12-17 11:43:43.723507: val_loss -0.3666 
2024-12-17 11:43:43.727016: Pseudo dice [np.float32(0.5675)] 
2024-12-17 11:43:43.730029: Epoch time: 41.34 s 
2024-12-17 11:43:43.732540: Yayy! New best EMA pseudo Dice: 0.48019999265670776 
2024-12-17 11:43:44.441748:  
2024-12-17 11:43:44.446795: Epoch 22 
2024-12-17 11:43:44.450281: Current learning rate: 0.008 
2024-12-17 11:44:25.779076: train_loss -0.6307 
2024-12-17 11:44:25.786310: val_loss -0.4227 
2024-12-17 11:44:25.788821: Pseudo dice [np.float32(0.5228)] 
2024-12-17 11:44:25.792335: Epoch time: 41.34 s 
2024-12-17 11:44:25.794596: Yayy! New best EMA pseudo Dice: 0.4844000041484833 
2024-12-17 11:44:26.498741:  
2024-12-17 11:44:26.504291: Epoch 23 
2024-12-17 11:44:26.507857: Current learning rate: 0.0079 
2024-12-17 11:45:07.834428: train_loss -0.6587 
2024-12-17 11:45:07.838952: val_loss -0.4933 
2024-12-17 11:45:07.842460: Pseudo dice [np.float32(0.6203)] 
2024-12-17 11:45:07.844967: Epoch time: 41.34 s 
2024-12-17 11:45:07.848473: Yayy! New best EMA pseudo Dice: 0.49799999594688416 
2024-12-17 11:45:08.566633:  
2024-12-17 11:45:08.572188: Epoch 24 
2024-12-17 11:45:08.577273: Current learning rate: 0.00781 
2024-12-17 11:45:49.905288: train_loss -0.6534 
2024-12-17 11:45:49.912368: val_loss -0.397 
2024-12-17 11:45:49.915956: Pseudo dice [np.float32(0.4788)] 
2024-12-17 11:45:49.918505: Epoch time: 41.34 s 
2024-12-17 11:45:50.465796:  
2024-12-17 11:45:50.470808: Epoch 25 
2024-12-17 11:45:50.473817: Current learning rate: 0.00772 
2024-12-17 11:46:31.797844: train_loss -0.6785 
2024-12-17 11:46:31.803858: val_loss -0.4906 
2024-12-17 11:46:31.807365: Pseudo dice [np.float32(0.5822)] 
2024-12-17 11:46:31.810373: Epoch time: 41.33 s 
2024-12-17 11:46:31.813886: Yayy! New best EMA pseudo Dice: 0.5047000050544739 
2024-12-17 11:46:32.539976:  
2024-12-17 11:46:32.545523: Epoch 26 
2024-12-17 11:46:32.549074: Current learning rate: 0.00763 
2024-12-17 11:47:13.882634: train_loss -0.653 
2024-12-17 11:47:13.888655: val_loss -0.4954 
2024-12-17 11:47:13.892163: Pseudo dice [np.float32(0.5912)] 
2024-12-17 11:47:13.895199: Epoch time: 41.34 s 
2024-12-17 11:47:13.898244: Yayy! New best EMA pseudo Dice: 0.5134000182151794 
2024-12-17 11:47:14.609860:  
2024-12-17 11:47:14.615383: Epoch 27 
2024-12-17 11:47:14.617963: Current learning rate: 0.00753 
2024-12-17 11:47:55.945830: train_loss -0.6713 
2024-12-17 11:47:55.951422: val_loss -0.4677 
2024-12-17 11:47:55.953944: Pseudo dice [np.float32(0.6011)] 
2024-12-17 11:47:55.957473: Epoch time: 41.34 s 
2024-12-17 11:47:55.960501: Yayy! New best EMA pseudo Dice: 0.5220999717712402 
2024-12-17 11:47:56.671353:  
2024-12-17 11:47:56.676380: Epoch 28 
2024-12-17 11:47:56.678903: Current learning rate: 0.00744 
2024-12-17 11:48:38.048156: train_loss -0.6845 
2024-12-17 11:48:38.055364: val_loss -0.4586 
2024-12-17 11:48:38.058875: Pseudo dice [np.float32(0.6238)] 
2024-12-17 11:48:38.061381: Epoch time: 41.38 s 
2024-12-17 11:48:38.063887: Yayy! New best EMA pseudo Dice: 0.5322999954223633 
2024-12-17 11:48:38.915856:  
2024-12-17 11:48:38.920869: Epoch 29 
2024-12-17 11:48:38.923878: Current learning rate: 0.00735 
2024-12-17 11:49:20.282995: train_loss -0.703 
2024-12-17 11:49:20.290344: val_loss -0.4204 
2024-12-17 11:49:20.293852: Pseudo dice [np.float32(0.5293)] 
2024-12-17 11:49:20.296358: Epoch time: 41.37 s 
2024-12-17 11:49:20.857635:  
2024-12-17 11:49:20.862682: Epoch 30 
2024-12-17 11:49:20.866241: Current learning rate: 0.00725 
2024-12-17 11:50:02.177862: train_loss -0.6552 
2024-12-17 11:50:02.183909: val_loss -0.3743 
2024-12-17 11:50:02.186419: Pseudo dice [np.float32(0.4931)] 
2024-12-17 11:50:02.189924: Epoch time: 41.32 s 
2024-12-17 11:50:02.748607:  
2024-12-17 11:50:02.753620: Epoch 31 
2024-12-17 11:50:02.757126: Current learning rate: 0.00716 
2024-12-17 11:50:44.071312: train_loss -0.6766 
2024-12-17 11:50:44.076427: val_loss -0.4442 
2024-12-17 11:50:44.078966: Pseudo dice [np.float32(0.6236)] 
2024-12-17 11:50:44.081508: Epoch time: 41.32 s 
2024-12-17 11:50:44.085553: Yayy! New best EMA pseudo Dice: 0.5376999974250793 
2024-12-17 11:50:44.799626:  
2024-12-17 11:50:44.804663: Epoch 32 
2024-12-17 11:50:44.808189: Current learning rate: 0.00707 
2024-12-17 11:51:26.118979: train_loss -0.6678 
2024-12-17 11:51:26.125537: val_loss -0.4425 
2024-12-17 11:51:26.129060: Pseudo dice [np.float32(0.5723)] 
2024-12-17 11:51:26.132082: Epoch time: 41.32 s 
2024-12-17 11:51:26.134603: Yayy! New best EMA pseudo Dice: 0.541100025177002 
2024-12-17 11:51:26.862085:  
2024-12-17 11:51:26.867689: Epoch 33 
2024-12-17 11:51:26.871226: Current learning rate: 0.00697 
2024-12-17 11:52:08.223049: train_loss -0.6868 
2024-12-17 11:52:08.227592: val_loss -0.3189 
2024-12-17 11:52:08.231632: Pseudo dice [np.float32(0.4665)] 
2024-12-17 11:52:08.234676: Epoch time: 41.36 s 
2024-12-17 11:52:08.805814:  
2024-12-17 11:52:08.811374: Epoch 34 
2024-12-17 11:52:08.814425: Current learning rate: 0.00688 
2024-12-17 11:52:50.162532: train_loss -0.6561 
2024-12-17 11:52:50.168599: val_loss -0.4431 
2024-12-17 11:52:50.172149: Pseudo dice [np.float32(0.578)] 
2024-12-17 11:52:50.174732: Epoch time: 41.36 s 
2024-12-17 11:52:50.736652:  
2024-12-17 11:52:50.741665: Epoch 35 
2024-12-17 11:52:50.745677: Current learning rate: 0.00679 
2024-12-17 11:53:32.070229: train_loss -0.6719 
2024-12-17 11:53:32.075791: val_loss -0.4735 
2024-12-17 11:53:32.078831: Pseudo dice [np.float32(0.5794)] 
2024-12-17 11:53:32.081360: Epoch time: 41.33 s 
2024-12-17 11:53:32.085418: Yayy! New best EMA pseudo Dice: 0.5422000288963318 
2024-12-17 11:53:32.807026:  
2024-12-17 11:53:32.812586: Epoch 36 
2024-12-17 11:53:32.815123: Current learning rate: 0.00669 
2024-12-17 11:54:14.155418: train_loss -0.6898 
2024-12-17 11:54:14.161443: val_loss -0.4072 
2024-12-17 11:54:14.164496: Pseudo dice [np.float32(0.5344)] 
2024-12-17 11:54:14.167048: Epoch time: 41.35 s 
2024-12-17 11:54:14.870695:  
2024-12-17 11:54:14.875743: Epoch 37 
2024-12-17 11:54:14.879267: Current learning rate: 0.0066 
2024-12-17 11:54:56.203618: train_loss -0.7093 
2024-12-17 11:54:56.208648: val_loss -0.4033 
2024-12-17 11:54:56.212678: Pseudo dice [np.float32(0.5065)] 
2024-12-17 11:54:56.215194: Epoch time: 41.33 s 
2024-12-17 11:54:56.779289:  
2024-12-17 11:54:56.783816: Epoch 38 
2024-12-17 11:54:56.786844: Current learning rate: 0.0065 
2024-12-17 11:55:38.105217: train_loss -0.6971 
2024-12-17 11:55:38.110792: val_loss -0.4536 
2024-12-17 11:55:38.114817: Pseudo dice [np.float32(0.6321)] 
2024-12-17 11:55:38.117826: Epoch time: 41.33 s 
2024-12-17 11:55:38.120332: Yayy! New best EMA pseudo Dice: 0.5473999977111816 
2024-12-17 11:55:38.841419:  
2024-12-17 11:55:38.845943: Epoch 39 
2024-12-17 11:55:38.849003: Current learning rate: 0.00641 
2024-12-17 11:56:20.193714: train_loss -0.6815 
2024-12-17 11:56:20.199740: val_loss -0.4449 
2024-12-17 11:56:20.203253: Pseudo dice [np.float32(0.5842)] 
2024-12-17 11:56:20.206266: Epoch time: 41.35 s 
2024-12-17 11:56:20.208775: Yayy! New best EMA pseudo Dice: 0.5509999990463257 
2024-12-17 11:56:20.939572:  
2024-12-17 11:56:20.945591: Epoch 40 
2024-12-17 11:56:20.949100: Current learning rate: 0.00631 
2024-12-17 11:57:02.288804: train_loss -0.668 
2024-12-17 11:57:02.293328: val_loss -0.4654 
2024-12-17 11:57:02.297355: Pseudo dice [np.float32(0.6058)] 
2024-12-17 11:57:02.300363: Epoch time: 41.35 s 
2024-12-17 11:57:02.302868: Yayy! New best EMA pseudo Dice: 0.5565000176429749 
2024-12-17 11:57:03.031491:  
2024-12-17 11:57:03.035999: Epoch 41 
2024-12-17 11:57:03.039006: Current learning rate: 0.00622 
2024-12-17 11:57:44.379202: train_loss -0.6882 
2024-12-17 11:57:44.385216: val_loss -0.4691 
2024-12-17 11:57:44.387723: Pseudo dice [np.float32(0.6123)] 
2024-12-17 11:57:44.391732: Epoch time: 41.35 s 
2024-12-17 11:57:44.394238: Yayy! New best EMA pseudo Dice: 0.5620999932289124 
2024-12-17 11:57:45.091452:  
2024-12-17 11:57:45.096462: Epoch 42 
2024-12-17 11:57:45.099506: Current learning rate: 0.00612 
2024-12-17 11:58:26.430197: train_loss -0.6957 
2024-12-17 11:58:26.437238: val_loss -0.5474 
2024-12-17 11:58:26.440746: Pseudo dice [np.float32(0.6527)] 
2024-12-17 11:58:26.443252: Epoch time: 41.34 s 
2024-12-17 11:58:26.445760: Yayy! New best EMA pseudo Dice: 0.5712000131607056 
2024-12-17 11:58:27.141622:  
2024-12-17 11:58:27.145662: Epoch 43 
2024-12-17 11:58:27.149682: Current learning rate: 0.00603 
2024-12-17 11:59:08.477628: train_loss -0.7232 
2024-12-17 11:59:08.483202: val_loss -0.3656 
2024-12-17 11:59:08.486239: Pseudo dice [np.float32(0.5341)] 
2024-12-17 11:59:08.489297: Epoch time: 41.34 s 
2024-12-17 11:59:09.030188:  
2024-12-17 11:59:09.034220: Epoch 44 
2024-12-17 11:59:09.037750: Current learning rate: 0.00593 
2024-12-17 11:59:50.360089: train_loss -0.7121 
2024-12-17 11:59:50.365700: val_loss -0.4621 
2024-12-17 11:59:50.368791: Pseudo dice [np.float32(0.6411)] 
2024-12-17 11:59:50.371314: Epoch time: 41.33 s 
2024-12-17 11:59:50.373838: Yayy! New best EMA pseudo Dice: 0.5748000144958496 
2024-12-17 11:59:51.228005:  
2024-12-17 11:59:51.232544: Epoch 45 
2024-12-17 11:59:51.235620: Current learning rate: 0.00584 
2024-12-17 12:00:32.550288: train_loss -0.7213 
2024-12-17 12:00:32.556834: val_loss -0.3478 
2024-12-17 12:00:32.560343: Pseudo dice [np.float32(0.4958)] 
2024-12-17 12:00:32.564352: Epoch time: 41.32 s 
2024-12-17 12:00:33.102561:  
2024-12-17 12:00:33.107630: Epoch 46 
2024-12-17 12:00:33.110667: Current learning rate: 0.00574 
2024-12-17 12:01:14.432085: train_loss -0.7322 
2024-12-17 12:01:14.437654: val_loss -0.3788 
2024-12-17 12:01:14.440791: Pseudo dice [np.float32(0.5041)] 
2024-12-17 12:01:14.443813: Epoch time: 41.33 s 
2024-12-17 12:01:14.982809:  
2024-12-17 12:01:14.986317: Epoch 47 
2024-12-17 12:01:14.989823: Current learning rate: 0.00565 
2024-12-17 12:01:56.325145: train_loss -0.7358 
2024-12-17 12:01:56.332260: val_loss -0.3545 
2024-12-17 12:01:56.335294: Pseudo dice [np.float32(0.5126)] 
2024-12-17 12:01:56.337982: Epoch time: 41.34 s 
2024-12-17 12:01:56.873534:  
2024-12-17 12:01:56.878653: Epoch 48 
2024-12-17 12:01:56.882164: Current learning rate: 0.00555 
2024-12-17 12:02:38.223544: train_loss -0.7372 
2024-12-17 12:02:38.230595: val_loss -0.3819 
2024-12-17 12:02:38.233627: Pseudo dice [np.float32(0.5954)] 
2024-12-17 12:02:38.237136: Epoch time: 41.35 s 
2024-12-17 12:02:38.776140:  
2024-12-17 12:02:38.781157: Epoch 49 
2024-12-17 12:02:38.785172: Current learning rate: 0.00546 
2024-12-17 12:03:20.139502: train_loss -0.7517 
2024-12-17 12:03:20.145066: val_loss -0.2934 
2024-12-17 12:03:20.148197: Pseudo dice [np.float32(0.4982)] 
2024-12-17 12:03:20.150732: Epoch time: 41.36 s 
2024-12-17 12:03:20.842331:  
2024-12-17 12:03:20.847227: Epoch 50 
2024-12-17 12:03:20.849740: Current learning rate: 0.00536 
2024-12-17 12:04:02.200532: train_loss -0.7517 
2024-12-17 12:04:02.206100: val_loss -0.301 
2024-12-17 12:04:02.209124: Pseudo dice [np.float32(0.5309)] 
2024-12-17 12:04:02.212171: Epoch time: 41.36 s 
2024-12-17 12:04:02.753265:  
2024-12-17 12:04:02.757306: Epoch 51 
2024-12-17 12:04:02.761367: Current learning rate: 0.00526 
2024-12-17 12:04:44.104903: train_loss -0.7546 
2024-12-17 12:04:44.111420: val_loss -0.3388 
2024-12-17 12:04:44.114983: Pseudo dice [np.float32(0.5335)] 
2024-12-17 12:04:44.118003: Epoch time: 41.35 s 
2024-12-17 12:04:44.659125:  
2024-12-17 12:04:44.664136: Epoch 52 
2024-12-17 12:04:44.667642: Current learning rate: 0.00517 
2024-12-17 12:05:25.991466: train_loss -0.7456 
2024-12-17 12:05:25.998043: val_loss -0.4559 
2024-12-17 12:05:26.001563: Pseudo dice [np.float32(0.5712)] 
2024-12-17 12:05:26.004583: Epoch time: 41.33 s 
2024-12-17 12:05:26.688784:  
2024-12-17 12:05:26.693803: Epoch 53 
2024-12-17 12:05:26.697818: Current learning rate: 0.00507 
2024-12-17 12:06:08.043481: train_loss -0.7324 
2024-12-17 12:06:08.049009: val_loss -0.4274 
2024-12-17 12:06:08.052060: Pseudo dice [np.float32(0.5564)] 
2024-12-17 12:06:08.054621: Epoch time: 41.35 s 
2024-12-17 12:06:08.596200:  
2024-12-17 12:06:08.601315: Epoch 54 
2024-12-17 12:06:08.603846: Current learning rate: 0.00497 
2024-12-17 12:06:49.961957: train_loss -0.7366 
2024-12-17 12:06:49.968476: val_loss -0.3901 
2024-12-17 12:06:49.971984: Pseudo dice [np.float32(0.5697)] 
2024-12-17 12:06:49.974491: Epoch time: 41.37 s 
2024-12-17 12:06:50.518112:  
2024-12-17 12:06:50.523181: Epoch 55 
2024-12-17 12:06:50.526728: Current learning rate: 0.00487 
2024-12-17 12:07:31.868819: train_loss -0.7468 
2024-12-17 12:07:31.875936: val_loss -0.485 
2024-12-17 12:07:31.879512: Pseudo dice [np.float32(0.6126)] 
2024-12-17 12:07:31.882567: Epoch time: 41.35 s 
2024-12-17 12:07:32.431541:  
2024-12-17 12:07:32.436376: Epoch 56 
2024-12-17 12:07:32.438883: Current learning rate: 0.00478 
2024-12-17 12:08:13.803060: train_loss -0.7498 
2024-12-17 12:08:13.808608: val_loss -0.4824 
2024-12-17 12:08:13.811138: Pseudo dice [np.float32(0.6085)] 
2024-12-17 12:08:13.814302: Epoch time: 41.37 s 
2024-12-17 12:08:14.361437:  
2024-12-17 12:08:14.366446: Epoch 57 
2024-12-17 12:08:14.368949: Current learning rate: 0.00468 
2024-12-17 12:08:55.731242: train_loss -0.7706 
2024-12-17 12:08:55.736816: val_loss -0.3416 
2024-12-17 12:08:55.740390: Pseudo dice [np.float32(0.5066)] 
2024-12-17 12:08:55.743450: Epoch time: 41.37 s 
2024-12-17 12:08:56.289758:  
2024-12-17 12:08:56.294800: Epoch 58 
2024-12-17 12:08:56.297875: Current learning rate: 0.00458 
2024-12-17 12:09:37.674797: train_loss -0.7812 
2024-12-17 12:09:37.680326: val_loss -0.4254 
2024-12-17 12:09:37.683900: Pseudo dice [np.float32(0.6098)] 
2024-12-17 12:09:37.686944: Epoch time: 41.39 s 
2024-12-17 12:09:38.244512:  
2024-12-17 12:09:38.249567: Epoch 59 
2024-12-17 12:09:38.252668: Current learning rate: 0.00448 
2024-12-17 12:10:19.581039: train_loss -0.7635 
2024-12-17 12:10:19.587053: val_loss -0.3833 
2024-12-17 12:10:19.590062: Pseudo dice [np.float32(0.5455)] 
2024-12-17 12:10:19.593573: Epoch time: 41.34 s 
2024-12-17 12:10:20.148109:  
2024-12-17 12:10:20.152146: Epoch 60 
2024-12-17 12:10:20.155685: Current learning rate: 0.00438 
2024-12-17 12:11:01.484405: train_loss -0.7903 
2024-12-17 12:11:01.490548: val_loss -0.3658 
2024-12-17 12:11:01.493860: Pseudo dice [np.float32(0.4454)] 
2024-12-17 12:11:01.496244: Epoch time: 41.34 s 
2024-12-17 12:11:02.194764:  
2024-12-17 12:11:02.199779: Epoch 61 
2024-12-17 12:11:02.202792: Current learning rate: 0.00429 
2024-12-17 12:11:43.532635: train_loss -0.7633 
2024-12-17 12:11:43.539268: val_loss -0.374 
2024-12-17 12:11:43.542309: Pseudo dice [np.float32(0.5297)] 
2024-12-17 12:11:43.545349: Epoch time: 41.34 s 
2024-12-17 12:11:44.105995:  
2024-12-17 12:11:44.110542: Epoch 62 
2024-12-17 12:11:44.113065: Current learning rate: 0.00419 
2024-12-17 12:12:25.465580: train_loss -0.7517 
2024-12-17 12:12:25.472099: val_loss -0.3706 
2024-12-17 12:12:25.474606: Pseudo dice [np.float32(0.5504)] 
2024-12-17 12:12:25.478112: Epoch time: 41.36 s 
2024-12-17 12:12:26.033021:  
2024-12-17 12:12:26.036566: Epoch 63 
2024-12-17 12:12:26.040626: Current learning rate: 0.00409 
2024-12-17 12:13:07.382067: train_loss -0.7728 
2024-12-17 12:13:07.387110: val_loss -0.4235 
2024-12-17 12:13:07.390184: Pseudo dice [np.float32(0.583)] 
2024-12-17 12:13:07.394193: Epoch time: 41.35 s 
2024-12-17 12:13:07.945901:  
2024-12-17 12:13:07.950976: Epoch 64 
2024-12-17 12:13:07.953506: Current learning rate: 0.00399 
2024-12-17 12:13:49.290464: train_loss -0.7565 
2024-12-17 12:13:49.296580: val_loss -0.4001 
2024-12-17 12:13:49.300168: Pseudo dice [np.float32(0.5248)] 
2024-12-17 12:13:49.303202: Epoch time: 41.35 s 
2024-12-17 12:13:49.862548:  
2024-12-17 12:13:49.868091: Epoch 65 
2024-12-17 12:13:49.871131: Current learning rate: 0.00389 
2024-12-17 12:14:31.188225: train_loss -0.7839 
2024-12-17 12:14:31.194245: val_loss -0.5311 
2024-12-17 12:14:31.197776: Pseudo dice [np.float32(0.6954)] 
2024-12-17 12:14:31.200819: Epoch time: 41.33 s 
2024-12-17 12:14:31.748856:  
2024-12-17 12:14:31.752893: Epoch 66 
2024-12-17 12:14:31.756962: Current learning rate: 0.00379 
2024-12-17 12:15:13.088522: train_loss -0.768 
2024-12-17 12:15:13.093535: val_loss -0.3424 
2024-12-17 12:15:13.097044: Pseudo dice [np.float32(0.5717)] 
2024-12-17 12:15:13.099550: Epoch time: 41.34 s 
2024-12-17 12:15:13.647087:  
2024-12-17 12:15:13.652639: Epoch 67 
2024-12-17 12:15:13.655200: Current learning rate: 0.00369 
2024-12-17 12:15:55.007378: train_loss -0.7788 
2024-12-17 12:15:55.012583: val_loss -0.4518 
2024-12-17 12:15:55.015765: Pseudo dice [np.float32(0.6341)] 
2024-12-17 12:15:55.018295: Epoch time: 41.36 s 
2024-12-17 12:15:55.599512:  
2024-12-17 12:15:55.603553: Epoch 68 
2024-12-17 12:15:55.607602: Current learning rate: 0.00359 
2024-12-17 12:16:36.975845: train_loss -0.7653 
2024-12-17 12:16:36.980860: val_loss -0.2572 
2024-12-17 12:16:36.983897: Pseudo dice [np.float32(0.4735)] 
2024-12-17 12:16:36.986927: Epoch time: 41.38 s 
2024-12-17 12:16:37.853275:  
2024-12-17 12:16:37.861877: Epoch 69 
2024-12-17 12:16:37.865023: Current learning rate: 0.00349 
2024-12-17 12:17:19.206358: train_loss -0.7728 
2024-12-17 12:17:19.211370: val_loss -0.2337 
2024-12-17 12:17:19.214880: Pseudo dice [np.float32(0.4351)] 
2024-12-17 12:17:19.217385: Epoch time: 41.35 s 
2024-12-17 12:17:19.778192:  
2024-12-17 12:17:19.783249: Epoch 70 
2024-12-17 12:17:19.786297: Current learning rate: 0.00338 
2024-12-17 12:18:01.126903: train_loss -0.7748 
2024-12-17 12:18:01.131918: val_loss -0.4099 
2024-12-17 12:18:01.135927: Pseudo dice [np.float32(0.6409)] 
2024-12-17 12:18:01.138433: Epoch time: 41.35 s 
2024-12-17 12:18:01.707834:  
2024-12-17 12:18:01.712902: Epoch 71 
2024-12-17 12:18:01.715950: Current learning rate: 0.00328 
2024-12-17 12:18:43.074469: train_loss -0.8068 
2024-12-17 12:18:43.081065: val_loss -0.313 
2024-12-17 12:18:43.085078: Pseudo dice [np.float32(0.5415)] 
2024-12-17 12:18:43.087583: Epoch time: 41.37 s 
2024-12-17 12:18:43.651186:  
2024-12-17 12:18:43.656199: Epoch 72 
2024-12-17 12:18:43.659208: Current learning rate: 0.00318 
2024-12-17 12:19:25.022485: train_loss -0.7978 
2024-12-17 12:19:25.029072: val_loss -0.3574 
2024-12-17 12:19:25.032579: Pseudo dice [np.float32(0.6145)] 
2024-12-17 12:19:25.035591: Epoch time: 41.37 s 
2024-12-17 12:19:25.597701:  
2024-12-17 12:19:25.601713: Epoch 73 
2024-12-17 12:19:25.605220: Current learning rate: 0.00308 
2024-12-17 12:20:06.939325: train_loss -0.7971 
2024-12-17 12:20:06.945386: val_loss -0.4305 
2024-12-17 12:20:06.948418: Pseudo dice [np.float32(0.6278)] 
2024-12-17 12:20:06.951459: Epoch time: 41.34 s 
2024-12-17 12:20:07.514750:  
2024-12-17 12:20:07.518779: Epoch 74 
2024-12-17 12:20:07.522804: Current learning rate: 0.00297 
2024-12-17 12:20:48.861374: train_loss -0.8044 
2024-12-17 12:20:48.871027: val_loss -0.3917 
2024-12-17 12:20:48.874054: Pseudo dice [np.float32(0.6338)] 
2024-12-17 12:20:48.876068: Epoch time: 41.35 s 
2024-12-17 12:20:48.879103: Yayy! New best EMA pseudo Dice: 0.5755000114440918 
2024-12-17 12:20:49.603338:  
2024-12-17 12:20:49.608351: Epoch 75 
2024-12-17 12:20:49.610857: Current learning rate: 0.00287 
2024-12-17 12:21:30.957486: train_loss -0.8103 
2024-12-17 12:21:30.964004: val_loss -0.3683 
2024-12-17 12:21:30.967512: Pseudo dice [np.float32(0.6112)] 
2024-12-17 12:21:30.970520: Epoch time: 41.35 s 
2024-12-17 12:21:30.974028: Yayy! New best EMA pseudo Dice: 0.5789999961853027 
2024-12-17 12:21:31.707282:  
2024-12-17 12:21:31.712492: Epoch 76 
2024-12-17 12:21:31.716021: Current learning rate: 0.00277 
2024-12-17 12:22:13.063582: train_loss -0.8089 
2024-12-17 12:22:13.069664: val_loss -0.3853 
2024-12-17 12:22:13.072639: Pseudo dice [np.float32(0.6032)] 
2024-12-17 12:22:13.076156: Epoch time: 41.36 s 
2024-12-17 12:22:13.078674: Yayy! New best EMA pseudo Dice: 0.5813999772071838 
2024-12-17 12:22:13.958061:  
2024-12-17 12:22:13.963097: Epoch 77 
2024-12-17 12:22:13.966148: Current learning rate: 0.00266 
2024-12-17 12:22:55.344254: train_loss -0.8162 
2024-12-17 12:22:55.351382: val_loss -0.3104 
2024-12-17 12:22:55.355455: Pseudo dice [np.float32(0.5483)] 
2024-12-17 12:22:55.358547: Epoch time: 41.39 s 
2024-12-17 12:22:55.939666:  
2024-12-17 12:22:55.944814: Epoch 78 
2024-12-17 12:22:55.948353: Current learning rate: 0.00256 
2024-12-17 12:23:37.343863: train_loss -0.8205 
2024-12-17 12:23:37.348921: val_loss -0.2677 
2024-12-17 12:23:37.352480: Pseudo dice [np.float32(0.5303)] 
2024-12-17 12:23:37.354986: Epoch time: 41.41 s 
2024-12-17 12:23:37.940439:  
2024-12-17 12:23:37.944977: Epoch 79 
2024-12-17 12:23:37.948007: Current learning rate: 0.00245 
2024-12-17 12:24:19.286928: train_loss -0.8144 
2024-12-17 12:24:19.292528: val_loss -0.4064 
2024-12-17 12:24:19.296537: Pseudo dice [np.float32(0.6416)] 
2024-12-17 12:24:19.299044: Epoch time: 41.35 s 
2024-12-17 12:24:19.879192:  
2024-12-17 12:24:19.885324: Epoch 80 
2024-12-17 12:24:19.888346: Current learning rate: 0.00235 
2024-12-17 12:25:01.226443: train_loss -0.8193 
2024-12-17 12:25:01.232092: val_loss -0.3479 
2024-12-17 12:25:01.235133: Pseudo dice [np.float32(0.5764)] 
2024-12-17 12:25:01.238168: Epoch time: 41.35 s 
2024-12-17 12:25:01.821056:  
2024-12-17 12:25:01.826198: Epoch 81 
2024-12-17 12:25:01.828705: Current learning rate: 0.00224 
2024-12-17 12:25:43.175486: train_loss -0.8169 
2024-12-17 12:25:43.180500: val_loss -0.3772 
2024-12-17 12:25:43.184013: Pseudo dice [np.float32(0.5593)] 
2024-12-17 12:25:43.186521: Epoch time: 41.35 s 
2024-12-17 12:25:43.767496:  
2024-12-17 12:25:43.772512: Epoch 82 
2024-12-17 12:25:43.775020: Current learning rate: 0.00214 
2024-12-17 12:26:25.128322: train_loss -0.8216 
2024-12-17 12:26:25.135340: val_loss -0.3138 
2024-12-17 12:26:25.138356: Pseudo dice [np.float32(0.5161)] 
2024-12-17 12:26:25.140863: Epoch time: 41.36 s 
2024-12-17 12:26:25.683916:  
2024-12-17 12:26:25.688957: Epoch 83 
2024-12-17 12:26:25.691716: Current learning rate: 0.00203 
2024-12-17 12:27:07.015189: train_loss -0.8257 
2024-12-17 12:27:07.020229: val_loss -0.3021 
2024-12-17 12:27:07.023756: Pseudo dice [np.float32(0.509)] 
2024-12-17 12:27:07.026291: Epoch time: 41.33 s 
2024-12-17 12:27:07.569765:  
2024-12-17 12:27:07.574814: Epoch 84 
2024-12-17 12:27:07.577905: Current learning rate: 0.00192 
2024-12-17 12:27:48.914146: train_loss -0.82 
2024-12-17 12:27:48.921220: val_loss -0.312 
2024-12-17 12:27:48.924236: Pseudo dice [np.float32(0.5625)] 
2024-12-17 12:27:48.927745: Epoch time: 41.34 s 
2024-12-17 12:27:49.614094:  
2024-12-17 12:27:49.619159: Epoch 85 
2024-12-17 12:27:49.622204: Current learning rate: 0.00181 
2024-12-17 12:28:30.976497: train_loss -0.8152 
2024-12-17 12:28:30.983041: val_loss -0.351 
2024-12-17 12:28:30.986639: Pseudo dice [np.float32(0.5357)] 
2024-12-17 12:28:30.989144: Epoch time: 41.36 s 
2024-12-17 12:28:31.532531:  
2024-12-17 12:28:31.536558: Epoch 86 
2024-12-17 12:28:31.540091: Current learning rate: 0.0017 
2024-12-17 12:29:12.884296: train_loss -0.8245 
2024-12-17 12:29:12.890814: val_loss -0.1868 
2024-12-17 12:29:12.893321: Pseudo dice [np.float32(0.3844)] 
2024-12-17 12:29:12.896618: Epoch time: 41.35 s 
2024-12-17 12:29:13.438563:  
2024-12-17 12:29:13.442600: Epoch 87 
2024-12-17 12:29:13.445581: Current learning rate: 0.00159 
2024-12-17 12:29:54.771199: train_loss -0.8236 
2024-12-17 12:29:54.777836: val_loss -0.2711 
2024-12-17 12:29:54.780869: Pseudo dice [np.float32(0.549)] 
2024-12-17 12:29:54.782890: Epoch time: 41.33 s 
2024-12-17 12:29:55.331427:  
2024-12-17 12:29:55.336438: Epoch 88 
2024-12-17 12:29:55.339450: Current learning rate: 0.00148 
2024-12-17 12:30:36.681162: train_loss -0.8403 
2024-12-17 12:30:36.687678: val_loss -0.3826 
2024-12-17 12:30:36.690183: Pseudo dice [np.float32(0.6184)] 
2024-12-17 12:30:36.692688: Epoch time: 41.35 s 
2024-12-17 12:30:37.237372:  
2024-12-17 12:30:37.242938: Epoch 89 
2024-12-17 12:30:37.246505: Current learning rate: 0.00137 
2024-12-17 12:31:18.594349: train_loss -0.8284 
2024-12-17 12:31:18.599360: val_loss -0.2189 
2024-12-17 12:31:18.602871: Pseudo dice [np.float32(0.4799)] 
2024-12-17 12:31:18.605375: Epoch time: 41.36 s 
2024-12-17 12:31:19.145015:  
2024-12-17 12:31:19.149526: Epoch 90 
2024-12-17 12:31:19.153537: Current learning rate: 0.00126 
2024-12-17 12:32:00.492661: train_loss -0.823 
2024-12-17 12:32:00.499203: val_loss -0.3909 
2024-12-17 12:32:00.502218: Pseudo dice [np.float32(0.6342)] 
2024-12-17 12:32:00.505728: Epoch time: 41.35 s 
2024-12-17 12:32:01.057139:  
2024-12-17 12:32:01.061150: Epoch 91 
2024-12-17 12:32:01.064658: Current learning rate: 0.00115 
2024-12-17 12:32:42.404930: train_loss -0.8336 
2024-12-17 12:32:42.411487: val_loss -0.3436 
2024-12-17 12:32:42.414581: Pseudo dice [np.float32(0.5634)] 
2024-12-17 12:32:42.417609: Epoch time: 41.35 s 
2024-12-17 12:32:42.962008:  
2024-12-17 12:32:42.966021: Epoch 92 
2024-12-17 12:32:42.969629: Current learning rate: 0.00103 
2024-12-17 12:33:24.313390: train_loss -0.8341 
2024-12-17 12:33:24.318402: val_loss -0.2739 
2024-12-17 12:33:24.321911: Pseudo dice [np.float32(0.4796)] 
2024-12-17 12:33:24.325928: Epoch time: 41.35 s 
2024-12-17 12:33:24.870020:  
2024-12-17 12:33:24.876539: Epoch 93 
2024-12-17 12:33:24.881551: Current learning rate: 0.00091 
2024-12-17 12:34:06.225524: train_loss -0.8204 
2024-12-17 12:34:06.231594: val_loss -0.4037 
2024-12-17 12:34:06.233659: Pseudo dice [np.float32(0.651)] 
2024-12-17 12:34:06.238264: Epoch time: 41.36 s 
2024-12-17 12:34:06.922012:  
2024-12-17 12:34:06.927121: Epoch 94 
2024-12-17 12:34:06.931166: Current learning rate: 0.00079 
2024-12-17 12:34:48.323337: train_loss -0.8236 
2024-12-17 12:34:48.329370: val_loss -0.4099 
2024-12-17 12:34:48.332406: Pseudo dice [np.float32(0.6542)] 
2024-12-17 12:34:48.335465: Epoch time: 41.4 s 
2024-12-17 12:34:48.882535:  
2024-12-17 12:34:48.888093: Epoch 95 
2024-12-17 12:34:48.891133: Current learning rate: 0.00067 
2024-12-17 12:35:30.262521: train_loss -0.8427 
2024-12-17 12:35:30.269039: val_loss -0.2439 
2024-12-17 12:35:30.272547: Pseudo dice [np.float32(0.4498)] 
2024-12-17 12:35:30.275557: Epoch time: 41.38 s 
2024-12-17 12:35:30.821725:  
2024-12-17 12:35:30.826397: Epoch 96 
2024-12-17 12:35:30.830022: Current learning rate: 0.00055 
2024-12-17 12:36:12.182956: train_loss -0.84 
2024-12-17 12:36:12.187969: val_loss -0.3078 
2024-12-17 12:36:12.191476: Pseudo dice [np.float32(0.5524)] 
2024-12-17 12:36:12.194484: Epoch time: 41.36 s 
2024-12-17 12:36:12.738503:  
2024-12-17 12:36:12.743545: Epoch 97 
2024-12-17 12:36:12.746066: Current learning rate: 0.00043 
2024-12-17 12:36:54.088878: train_loss -0.8348 
2024-12-17 12:36:54.094926: val_loss -0.2344 
2024-12-17 12:36:54.097783: Pseudo dice [np.float32(0.5204)] 
2024-12-17 12:36:54.100293: Epoch time: 41.35 s 
2024-12-17 12:36:54.664239:  
2024-12-17 12:36:54.669785: Epoch 98 
2024-12-17 12:36:54.672811: Current learning rate: 0.0003 
2024-12-17 12:37:36.018996: train_loss -0.8332 
2024-12-17 12:37:36.025127: val_loss -0.2775 
2024-12-17 12:37:36.028192: Pseudo dice [np.float32(0.5505)] 
2024-12-17 12:37:36.030716: Epoch time: 41.35 s 
2024-12-17 12:37:36.583725:  
2024-12-17 12:37:36.588735: Epoch 99 
2024-12-17 12:37:36.591241: Current learning rate: 0.00016 
2024-12-17 12:38:17.917258: train_loss -0.8396 
2024-12-17 12:38:17.922813: val_loss -0.277 
2024-12-17 12:38:17.926343: Pseudo dice [np.float32(0.5087)] 
2024-12-17 12:38:17.928932: Epoch time: 41.33 s 
2024-12-17 12:38:18.669813: Training done. 
2024-12-17 12:38:18.701818: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-17 12:38:18.706814: The split file contains 5 splits. 
2024-12-17 12:38:18.710814: Desired fold for training: 0 
2024-12-17 12:38:18.715813: This split has 100 training and 26 validation cases. 
2024-12-17 12:38:18.719814: predicting colon_008 
2024-12-17 12:38:18.724815: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2024-12-17 12:38:21.323060: predicting colon_027 
2024-12-17 12:38:21.342060: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2024-12-17 12:38:22.126833: predicting colon_030 
2024-12-17 12:38:22.138835: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2024-12-17 12:38:23.241531: predicting colon_033 
2024-12-17 12:38:23.256531: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2024-12-17 12:38:25.201553: predicting colon_041 
2024-12-17 12:38:25.222551: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2024-12-17 12:38:30.402947: predicting colon_042 
2024-12-17 12:38:30.454953: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2024-12-17 12:38:33.102431: predicting colon_061 
2024-12-17 12:38:33.125430: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2024-12-17 12:38:36.164551: predicting colon_074 
2024-12-17 12:38:36.190551: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2024-12-17 12:38:39.669444: predicting colon_075 
2024-12-17 12:38:39.699444: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2024-12-17 12:38:41.661463: predicting colon_088 
2024-12-17 12:38:41.683970: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2024-12-17 12:38:44.745364: predicting colon_091 
2024-12-17 12:38:44.785875: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2024-12-17 12:38:48.429742: predicting colon_092 
2024-12-17 12:38:48.460745: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2024-12-17 12:38:51.471028: predicting colon_095 
2024-12-17 12:38:51.498028: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2024-12-17 12:38:53.450683: predicting colon_102 
2024-12-17 12:38:53.473193: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2024-12-17 12:38:57.791470: predicting colon_111 
2024-12-17 12:38:57.826471: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2024-12-17 12:38:59.075017: predicting colon_115 
2024-12-17 12:38:59.098012: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2024-12-17 12:39:01.047973: predicting colon_118 
2024-12-17 12:39:01.070978: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2024-12-17 12:39:04.113549: predicting colon_124 
2024-12-17 12:39:04.137550: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2024-12-17 12:39:07.171865: predicting colon_127 
2024-12-17 12:39:07.199370: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2024-12-17 12:39:13.240005: predicting colon_154 
2024-12-17 12:39:13.277511: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2024-12-17 12:39:15.241764: predicting colon_161 
2024-12-17 12:39:15.262768: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2024-12-17 12:39:17.220547: predicting colon_162 
2024-12-17 12:39:17.242547: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2024-12-17 12:39:22.425944: predicting colon_165 
2024-12-17 12:39:22.464947: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2024-12-17 12:39:26.813263: predicting colon_166 
2024-12-17 12:39:26.847263: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2024-12-17 12:39:28.843397: predicting colon_169 
2024-12-17 12:39:28.878399: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2024-12-17 12:39:34.991884: predicting colon_187 
2024-12-17 12:39:35.030884: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2024-12-17 12:39:53.612736: Validation complete 
2024-12-17 12:39:53.618735: Mean Validation Dice:  0.26811331329715815 
