2025-01-09 01:19:42.250712: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.25 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-09 01:19:42.254711: self.oversample_foreground_percent 0.0 
2025-01-09 01:19:42.258711: do_dummy_2d_data_aug: True 
2025-01-09 01:19:42.279995: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-09 01:19:42.285843: The split file contains 5 splits. 
2025-01-09 01:19:42.288843: Desired fold for training: 0 
2025-01-09 01:19:42.290843: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-01-09 01:19:49.523180: unpacking dataset... 
2025-01-09 01:19:49.782346: unpacking done... 
2025-01-09 01:19:52.732833:  
2025-01-09 01:19:52.733337: Epoch 0 
2025-01-09 01:19:52.737844: Current learning rate: 0.01 
2025-01-09 01:20:38.734317: train_loss 0.0468 
2025-01-09 01:20:38.734317: val_loss 0.0112 
2025-01-09 01:20:38.740444: Pseudo dice [np.float32(0.0)] 
2025-01-09 01:20:38.744549: Epoch time: 46.0 s 
2025-01-09 01:20:38.748072: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-09 01:20:39.428102:  
2025-01-09 01:20:39.428102: Epoch 1 
2025-01-09 01:20:39.433115: Current learning rate: 0.00996 
2025-01-09 01:21:20.822710: train_loss 0.011 
2025-01-09 01:21:20.822710: val_loss 0.0075 
2025-01-09 01:21:20.829073: Pseudo dice [np.float32(0.0)] 
2025-01-09 01:21:20.833088: Epoch time: 41.4 s 
2025-01-09 01:21:21.359888:  
2025-01-09 01:21:21.359888: Epoch 2 
2025-01-09 01:21:21.365489: Current learning rate: 0.00993 
2025-01-09 01:22:02.732508: train_loss 0.0077 
2025-01-09 01:22:02.733508: val_loss 0.0042 
2025-01-09 01:22:02.739032: Pseudo dice [np.float32(0.0)] 
2025-01-09 01:22:02.744055: Epoch time: 41.37 s 
2025-01-09 01:22:03.281556:  
2025-01-09 01:22:03.281556: Epoch 3 
2025-01-09 01:22:03.286566: Current learning rate: 0.00989 
2025-01-09 01:22:44.648191: train_loss 0.0041 
2025-01-09 01:22:44.648694: val_loss 0.0044 
2025-01-09 01:22:44.654707: Pseudo dice [np.float32(0.0)] 
2025-01-09 01:22:44.658720: Epoch time: 41.37 s 
2025-01-09 01:22:45.178847:  
2025-01-09 01:22:45.179349: Epoch 4 
2025-01-09 01:22:45.184359: Current learning rate: 0.00986 
2025-01-09 01:23:26.556010: train_loss 0.0047 
2025-01-09 01:23:26.556533: val_loss 0.0043 
2025-01-09 01:23:26.562168: Pseudo dice [np.float32(0.0)] 
2025-01-09 01:23:26.565254: Epoch time: 41.38 s 
2025-01-09 01:23:27.219534:  
2025-01-09 01:23:27.220038: Epoch 5 
2025-01-09 01:23:27.225050: Current learning rate: 0.00982 
2025-01-09 01:24:08.609010: train_loss 0.0015 
2025-01-09 01:24:08.610015: val_loss 0.0034 
2025-01-09 01:24:08.616628: Pseudo dice [np.float32(0.0)] 
2025-01-09 01:24:08.619678: Epoch time: 41.39 s 
2025-01-09 01:24:09.133634:  
2025-01-09 01:24:09.133634: Epoch 6 
2025-01-09 01:24:09.139184: Current learning rate: 0.00978 
2025-01-09 01:24:50.472546: train_loss -0.0007 
2025-01-09 01:24:50.473049: val_loss -0.0032 
2025-01-09 01:24:50.479068: Pseudo dice [np.float32(0.0)] 
2025-01-09 01:24:50.481086: Epoch time: 41.34 s 
2025-01-09 01:24:51.009567:  
2025-01-09 01:24:51.010570: Epoch 7 
2025-01-09 01:24:51.015126: Current learning rate: 0.00975 
2025-01-09 01:25:32.386970: train_loss 0.0012 
2025-01-09 01:25:32.386970: val_loss 0.0026 
2025-01-09 01:25:32.392984: Pseudo dice [np.float32(0.0)] 
2025-01-09 01:25:32.396490: Epoch time: 41.38 s 
2025-01-09 01:25:32.931557:  
2025-01-09 01:25:32.932060: Epoch 8 
2025-01-09 01:25:32.937072: Current learning rate: 0.00971 
2025-01-09 01:26:14.285151: train_loss -0.0041 
2025-01-09 01:26:14.286150: val_loss -0.0106 
2025-01-09 01:26:14.291664: Pseudo dice [np.float32(0.0)] 
2025-01-09 01:26:14.294689: Epoch time: 41.35 s 
2025-01-09 01:26:14.831361:  
2025-01-09 01:26:14.832364: Epoch 9 
2025-01-09 01:26:14.836906: Current learning rate: 0.00968 
2025-01-09 01:26:56.212893: train_loss -0.009 
2025-01-09 01:26:56.212893: val_loss -0.0209 
2025-01-09 01:26:56.218907: Pseudo dice [np.float32(0.0238)] 
2025-01-09 01:26:56.221414: Epoch time: 41.38 s 
2025-01-09 01:26:56.225424: Yayy! New best EMA pseudo Dice: 0.002400000113993883 
2025-01-09 01:26:57.000227:  
2025-01-09 01:26:57.001230: Epoch 10 
2025-01-09 01:26:57.005772: Current learning rate: 0.00964 
2025-01-09 01:27:38.378608: train_loss -0.0007 
2025-01-09 01:27:38.378608: val_loss -0.0075 
2025-01-09 01:27:38.384140: Pseudo dice [np.float32(0.0381)] 
2025-01-09 01:27:38.387650: Epoch time: 41.38 s 
2025-01-09 01:27:38.390660: Yayy! New best EMA pseudo Dice: 0.006000000052154064 
2025-01-09 01:27:39.110003:  
2025-01-09 01:27:39.110507: Epoch 11 
2025-01-09 01:27:39.115379: Current learning rate: 0.0096 
2025-01-09 01:28:20.480748: train_loss -0.0055 
2025-01-09 01:28:20.481754: val_loss -0.0226 
2025-01-09 01:28:20.487293: Pseudo dice [np.float32(0.0815)] 
2025-01-09 01:28:20.489534: Epoch time: 41.37 s 
2025-01-09 01:28:20.493551: Yayy! New best EMA pseudo Dice: 0.013500000350177288 
2025-01-09 01:28:21.223390:  
2025-01-09 01:28:21.223390: Epoch 12 
2025-01-09 01:28:21.228972: Current learning rate: 0.00957 
2025-01-09 01:29:02.615341: train_loss -0.0095 
2025-01-09 01:29:02.616345: val_loss -0.0059 
2025-01-09 01:29:02.622365: Pseudo dice [np.float32(0.0611)] 
2025-01-09 01:29:02.625919: Epoch time: 41.39 s 
2025-01-09 01:29:02.627941: Yayy! New best EMA pseudo Dice: 0.018300000578165054 
2025-01-09 01:29:03.493740:  
2025-01-09 01:29:03.493740: Epoch 13 
2025-01-09 01:29:03.498754: Current learning rate: 0.00953 
2025-01-09 01:29:47.078546: train_loss 0.0009 
2025-01-09 01:29:47.079652: val_loss -0.013 
2025-01-09 01:29:47.086741: Pseudo dice [np.float32(0.0)] 
2025-01-09 01:29:47.089815: Epoch time: 43.59 s 
2025-01-09 01:29:47.613133:  
2025-01-09 01:29:47.614133: Epoch 14 
2025-01-09 01:29:47.619190: Current learning rate: 0.00949 
2025-01-09 01:30:28.951257: train_loss -0.0191 
2025-01-09 01:30:28.952260: val_loss -0.0071 
2025-01-09 01:30:28.956836: Pseudo dice [np.float32(0.0678)] 
2025-01-09 01:30:28.960887: Epoch time: 41.34 s 
2025-01-09 01:30:28.963918: Yayy! New best EMA pseudo Dice: 0.02160000056028366 
2025-01-09 01:30:29.710006:  
2025-01-09 01:30:29.711006: Epoch 15 
2025-01-09 01:30:29.717530: Current learning rate: 0.00946 
2025-01-09 01:31:11.036891: train_loss -0.0007 
2025-01-09 01:31:11.037895: val_loss 0.0021 
2025-01-09 01:31:11.042772: Pseudo dice [np.float32(0.0264)] 
2025-01-09 01:31:11.046282: Epoch time: 41.33 s 
2025-01-09 01:31:11.049787: Yayy! New best EMA pseudo Dice: 0.022099999710917473 
2025-01-09 01:31:11.774705:  
2025-01-09 01:31:11.774705: Epoch 16 
2025-01-09 01:31:11.780257: Current learning rate: 0.00942 
2025-01-09 01:31:53.150838: train_loss -0.0078 
2025-01-09 01:31:53.151839: val_loss -0.0111 
2025-01-09 01:31:53.158367: Pseudo dice [np.float32(0.0644)] 
2025-01-09 01:31:53.161872: Epoch time: 41.38 s 
2025-01-09 01:31:53.164884: Yayy! New best EMA pseudo Dice: 0.02630000002682209 
2025-01-09 01:31:53.917738:  
2025-01-09 01:31:53.917738: Epoch 17 
2025-01-09 01:31:53.924255: Current learning rate: 0.00939 
2025-01-09 01:32:35.263260: train_loss -0.0178 
2025-01-09 01:32:35.264264: val_loss -0.0303 
2025-01-09 01:32:35.270277: Pseudo dice [np.float32(0.0805)] 
2025-01-09 01:32:35.274190: Epoch time: 41.35 s 
2025-01-09 01:32:35.277534: Yayy! New best EMA pseudo Dice: 0.031700000166893005 
2025-01-09 01:32:36.040418:  
2025-01-09 01:32:36.040920: Epoch 18 
2025-01-09 01:32:36.046934: Current learning rate: 0.00935 
2025-01-09 01:33:17.407548: train_loss -0.0226 
2025-01-09 01:33:17.407548: val_loss -0.0129 
2025-01-09 01:33:17.413561: Pseudo dice [np.float32(0.1128)] 
2025-01-09 01:33:17.417601: Epoch time: 41.37 s 
2025-01-09 01:33:17.420691: Yayy! New best EMA pseudo Dice: 0.039799999445676804 
2025-01-09 01:33:18.231368:  
2025-01-09 01:33:18.231368: Epoch 19 
2025-01-09 01:33:18.237414: Current learning rate: 0.00931 
2025-01-09 01:33:59.619095: train_loss -0.0064 
2025-01-09 01:33:59.620099: val_loss -0.0064 
2025-01-09 01:33:59.625286: Pseudo dice [np.float32(0.0541)] 
2025-01-09 01:33:59.629441: Epoch time: 41.39 s 
2025-01-09 01:33:59.634004: Yayy! New best EMA pseudo Dice: 0.04129999876022339 
2025-01-09 01:34:00.540297:  
2025-01-09 01:34:00.540297: Epoch 20 
2025-01-09 01:34:00.546312: Current learning rate: 0.00928 
2025-01-09 01:34:41.878602: train_loss -0.0118 
2025-01-09 01:34:41.879105: val_loss -0.0249 
2025-01-09 01:34:41.885121: Pseudo dice [np.float32(0.1048)] 
2025-01-09 01:34:41.889132: Epoch time: 41.34 s 
2025-01-09 01:34:41.892641: Yayy! New best EMA pseudo Dice: 0.047600001096725464 
2025-01-09 01:34:42.652694:  
2025-01-09 01:34:42.652694: Epoch 21 
2025-01-09 01:34:42.658721: Current learning rate: 0.00924 
2025-01-09 01:35:24.008683: train_loss -0.0082 
2025-01-09 01:35:24.008683: val_loss -0.0243 
2025-01-09 01:35:24.015199: Pseudo dice [np.float32(0.0787)] 
2025-01-09 01:35:24.018741: Epoch time: 41.36 s 
2025-01-09 01:35:24.022249: Yayy! New best EMA pseudo Dice: 0.050700001418590546 
2025-01-09 01:35:24.755216:  
2025-01-09 01:35:24.755216: Epoch 22 
2025-01-09 01:35:24.760812: Current learning rate: 0.0092 
2025-01-09 01:36:06.102402: train_loss -0.026 
2025-01-09 01:36:06.102910: val_loss -0.0515 
2025-01-09 01:36:06.108447: Pseudo dice [np.float32(0.1349)] 
2025-01-09 01:36:06.111953: Epoch time: 41.35 s 
2025-01-09 01:36:06.114961: Yayy! New best EMA pseudo Dice: 0.05909999832510948 
2025-01-09 01:36:06.820821:  
2025-01-09 01:36:06.821825: Epoch 23 
2025-01-09 01:36:06.826858: Current learning rate: 0.00917 
2025-01-09 01:36:48.165354: train_loss -0.0178 
2025-01-09 01:36:48.165863: val_loss -0.0365 
2025-01-09 01:36:48.170901: Pseudo dice [np.float32(0.1407)] 
2025-01-09 01:36:48.174411: Epoch time: 41.34 s 
2025-01-09 01:36:48.178417: Yayy! New best EMA pseudo Dice: 0.06729999929666519 
2025-01-09 01:36:48.886839:  
2025-01-09 01:36:48.886839: Epoch 24 
2025-01-09 01:36:48.894151: Current learning rate: 0.00913 
2025-01-09 01:37:30.244757: train_loss -0.0128 
2025-01-09 01:37:30.244757: val_loss -0.0345 
2025-01-09 01:37:30.251273: Pseudo dice [np.float32(0.0958)] 
2025-01-09 01:37:30.254782: Epoch time: 41.36 s 
2025-01-09 01:37:30.257289: Yayy! New best EMA pseudo Dice: 0.07010000199079514 
2025-01-09 01:37:30.975477:  
2025-01-09 01:37:30.975477: Epoch 25 
2025-01-09 01:37:30.981560: Current learning rate: 0.0091 
2025-01-09 01:38:12.311351: train_loss -0.0345 
2025-01-09 01:38:12.312350: val_loss -0.0216 
2025-01-09 01:38:12.317541: Pseudo dice [np.float32(0.0689)] 
2025-01-09 01:38:12.321066: Epoch time: 41.34 s 
2025-01-09 01:38:12.836239:  
2025-01-09 01:38:12.837238: Epoch 26 
2025-01-09 01:38:12.841784: Current learning rate: 0.00906 
2025-01-09 01:38:54.184653: train_loss -0.0074 
2025-01-09 01:38:54.184653: val_loss -0.0387 
2025-01-09 01:38:54.191667: Pseudo dice [np.float32(0.1199)] 
2025-01-09 01:38:54.194675: Epoch time: 41.35 s 
2025-01-09 01:38:54.197180: Yayy! New best EMA pseudo Dice: 0.07500000298023224 
2025-01-09 01:38:54.908555:  
2025-01-09 01:38:54.908555: Epoch 27 
2025-01-09 01:38:54.913124: Current learning rate: 0.00902 
2025-01-09 01:39:36.255547: train_loss -0.0288 
2025-01-09 01:39:36.256552: val_loss -0.0402 
2025-01-09 01:39:36.262563: Pseudo dice [np.float32(0.1184)] 
2025-01-09 01:39:36.265575: Epoch time: 41.35 s 
2025-01-09 01:39:36.268083: Yayy! New best EMA pseudo Dice: 0.07940000295639038 
2025-01-09 01:39:36.983144:  
2025-01-09 01:39:36.983144: Epoch 28 
2025-01-09 01:39:36.988161: Current learning rate: 0.00899 
2025-01-09 01:40:18.326483: train_loss -0.0377 
2025-01-09 01:40:18.327487: val_loss -0.0394 
2025-01-09 01:40:18.333172: Pseudo dice [np.float32(0.1159)] 
2025-01-09 01:40:18.335677: Epoch time: 41.34 s 
2025-01-09 01:40:18.338183: Yayy! New best EMA pseudo Dice: 0.08299999684095383 
2025-01-09 01:40:19.181111:  
2025-01-09 01:40:19.181111: Epoch 29 
2025-01-09 01:40:19.186126: Current learning rate: 0.00895 
2025-01-09 01:41:00.526978: train_loss -0.0187 
2025-01-09 01:41:00.527481: val_loss 0.0185 
2025-01-09 01:41:00.533500: Pseudo dice [np.float32(0.0194)] 
2025-01-09 01:41:00.537011: Epoch time: 41.35 s 
2025-01-09 01:41:01.064093:  
2025-01-09 01:41:01.064093: Epoch 30 
2025-01-09 01:41:01.069139: Current learning rate: 0.00891 
2025-01-09 01:41:42.389972: train_loss -0.0164 
2025-01-09 01:41:42.390491: val_loss -0.0302 
2025-01-09 01:41:42.395016: Pseudo dice [np.float32(0.1031)] 
2025-01-09 01:41:42.398525: Epoch time: 41.33 s 
2025-01-09 01:41:42.924874:  
2025-01-09 01:41:42.924874: Epoch 31 
2025-01-09 01:41:42.930940: Current learning rate: 0.00888 
2025-01-09 01:42:24.271017: train_loss -0.0347 
2025-01-09 01:42:24.271017: val_loss 0.0005 
2025-01-09 01:42:24.277035: Pseudo dice [np.float32(0.032)] 
2025-01-09 01:42:24.279046: Epoch time: 41.35 s 
2025-01-09 01:42:24.809502:  
2025-01-09 01:42:24.810502: Epoch 32 
2025-01-09 01:42:24.815556: Current learning rate: 0.00884 
2025-01-09 01:43:06.158545: train_loss -0.0333 
2025-01-09 01:43:06.160060: val_loss -0.0373 
2025-01-09 01:43:06.165607: Pseudo dice [np.float32(0.0844)] 
2025-01-09 01:43:06.168113: Epoch time: 41.35 s 
2025-01-09 01:43:06.693971:  
2025-01-09 01:43:06.693971: Epoch 33 
2025-01-09 01:43:06.699519: Current learning rate: 0.0088 
2025-01-09 01:43:48.027302: train_loss -0.0344 
2025-01-09 01:43:48.027831: val_loss -0.0395 
2025-01-09 01:43:48.032948: Pseudo dice [np.float32(0.1106)] 
2025-01-09 01:43:48.036478: Epoch time: 41.33 s 
2025-01-09 01:43:48.565024:  
2025-01-09 01:43:48.565526: Epoch 34 
2025-01-09 01:43:48.570539: Current learning rate: 0.00877 
2025-01-09 01:44:29.910713: train_loss -0.026 
2025-01-09 01:44:29.912278: val_loss -0.0247 
2025-01-09 01:44:29.918411: Pseudo dice [np.float32(0.0866)] 
2025-01-09 01:44:29.920958: Epoch time: 41.35 s 
2025-01-09 01:44:30.463088:  
2025-01-09 01:44:30.464091: Epoch 35 
2025-01-09 01:44:30.468685: Current learning rate: 0.00873 
2025-01-09 01:45:11.843540: train_loss -0.03 
2025-01-09 01:45:11.843540: val_loss -0.0129 
2025-01-09 01:45:11.849556: Pseudo dice [np.float32(0.0568)] 
2025-01-09 01:45:11.853062: Epoch time: 41.38 s 
2025-01-09 01:45:12.522832:  
2025-01-09 01:45:12.523835: Epoch 36 
2025-01-09 01:45:12.528376: Current learning rate: 0.00869 
2025-01-09 01:45:53.875923: train_loss -0.039 
2025-01-09 01:45:53.876929: val_loss -0.0175 
2025-01-09 01:45:53.882938: Pseudo dice [np.float32(0.1022)] 
2025-01-09 01:45:53.886951: Epoch time: 41.35 s 
2025-01-09 01:45:54.432918:  
2025-01-09 01:45:54.433922: Epoch 37 
2025-01-09 01:45:54.438474: Current learning rate: 0.00866 
2025-01-09 01:46:35.759479: train_loss -0.0204 
2025-01-09 01:46:35.759479: val_loss -0.0251 
2025-01-09 01:46:35.765570: Pseudo dice [np.float32(0.0893)] 
2025-01-09 01:46:35.768113: Epoch time: 41.33 s 
2025-01-09 01:46:36.305856:  
2025-01-09 01:46:36.305856: Epoch 38 
2025-01-09 01:46:36.310869: Current learning rate: 0.00862 
2025-01-09 01:47:17.621060: train_loss -0.0364 
2025-01-09 01:47:17.622060: val_loss -0.0513 
2025-01-09 01:47:17.627608: Pseudo dice [np.float32(0.1134)] 
2025-01-09 01:47:17.630147: Epoch time: 41.32 s 
2025-01-09 01:47:17.633676: Yayy! New best EMA pseudo Dice: 0.08420000225305557 
2025-01-09 01:47:18.393838:  
2025-01-09 01:47:18.393838: Epoch 39 
2025-01-09 01:47:18.398865: Current learning rate: 0.00858 
2025-01-09 01:47:59.736276: train_loss -0.0269 
2025-01-09 01:47:59.736276: val_loss -0.0241 
2025-01-09 01:47:59.742790: Pseudo dice [np.float32(0.0801)] 
2025-01-09 01:47:59.747334: Epoch time: 41.34 s 
2025-01-09 01:48:00.301795:  
2025-01-09 01:48:00.301795: Epoch 40 
2025-01-09 01:48:00.306853: Current learning rate: 0.00855 
2025-01-09 01:48:41.640053: train_loss -0.0269 
2025-01-09 01:48:41.640556: val_loss -0.0184 
2025-01-09 01:48:41.646101: Pseudo dice [np.float32(0.0635)] 
2025-01-09 01:48:41.648635: Epoch time: 41.34 s 
2025-01-09 01:48:42.206586:  
2025-01-09 01:48:42.207090: Epoch 41 
2025-01-09 01:48:42.212100: Current learning rate: 0.00851 
2025-01-09 01:49:23.551911: train_loss -0.0384 
2025-01-09 01:49:23.552916: val_loss -0.0645 
2025-01-09 01:49:23.558486: Pseudo dice [np.float32(0.1725)] 
2025-01-09 01:49:23.561524: Epoch time: 41.35 s 
2025-01-09 01:49:23.564049: Yayy! New best EMA pseudo Dice: 0.09080000221729279 
2025-01-09 01:49:24.302870:  
2025-01-09 01:49:24.302870: Epoch 42 
2025-01-09 01:49:24.308451: Current learning rate: 0.00847 
2025-01-09 01:50:05.654552: train_loss -0.0337 
2025-01-09 01:50:05.655552: val_loss -0.0409 
2025-01-09 01:50:05.661112: Pseudo dice [np.float32(0.1257)] 
2025-01-09 01:50:05.664146: Epoch time: 41.35 s 
2025-01-09 01:50:05.667177: Yayy! New best EMA pseudo Dice: 0.09430000185966492 
2025-01-09 01:50:06.386822:  
2025-01-09 01:50:06.387825: Epoch 43 
2025-01-09 01:50:06.392370: Current learning rate: 0.00844 
2025-01-09 01:50:47.703567: train_loss -0.0414 
2025-01-09 01:50:47.704574: val_loss -0.0505 
2025-01-09 01:50:47.709683: Pseudo dice [np.float32(0.1519)] 
2025-01-09 01:50:47.712194: Epoch time: 41.32 s 
2025-01-09 01:50:47.716200: Yayy! New best EMA pseudo Dice: 0.10000000149011612 
2025-01-09 01:50:48.595014:  
2025-01-09 01:50:48.595014: Epoch 44 
2025-01-09 01:50:48.600540: Current learning rate: 0.0084 
2025-01-09 01:51:29.914056: train_loss -0.0268 
2025-01-09 01:51:29.914565: val_loss -0.0367 
2025-01-09 01:51:29.919625: Pseudo dice [np.float32(0.1097)] 
2025-01-09 01:51:29.922167: Epoch time: 41.32 s 
2025-01-09 01:51:29.924700: Yayy! New best EMA pseudo Dice: 0.10100000351667404 
2025-01-09 01:51:30.645375:  
2025-01-09 01:51:30.645375: Epoch 45 
2025-01-09 01:51:30.650389: Current learning rate: 0.00836 
2025-01-09 01:52:11.999067: train_loss -0.0436 
2025-01-09 01:52:12.000065: val_loss -0.0517 
2025-01-09 01:52:12.005076: Pseudo dice [np.float32(0.1576)] 
2025-01-09 01:52:12.008088: Epoch time: 41.35 s 
2025-01-09 01:52:12.010595: Yayy! New best EMA pseudo Dice: 0.10670000314712524 
2025-01-09 01:52:12.746122:  
2025-01-09 01:52:12.747125: Epoch 46 
2025-01-09 01:52:12.752151: Current learning rate: 0.00833 
2025-01-09 01:52:54.060334: train_loss -0.0541 
2025-01-09 01:52:54.061334: val_loss -0.0474 
2025-01-09 01:52:54.066849: Pseudo dice [np.float32(0.1537)] 
2025-01-09 01:52:54.070356: Epoch time: 41.31 s 
2025-01-09 01:52:54.072862: Yayy! New best EMA pseudo Dice: 0.11140000075101852 
2025-01-09 01:52:54.801391:  
2025-01-09 01:52:54.802395: Epoch 47 
2025-01-09 01:52:54.806936: Current learning rate: 0.00829 
2025-01-09 01:53:36.105672: train_loss -0.0222 
2025-01-09 01:53:36.106178: val_loss -0.0493 
2025-01-09 01:53:36.111251: Pseudo dice [np.float32(0.1503)] 
2025-01-09 01:53:36.114292: Epoch time: 41.3 s 
2025-01-09 01:53:36.117378: Yayy! New best EMA pseudo Dice: 0.1152999997138977 
2025-01-09 01:53:36.836044:  
2025-01-09 01:53:36.836044: Epoch 48 
2025-01-09 01:53:36.841064: Current learning rate: 0.00825 
2025-01-09 01:54:18.154354: train_loss -0.0213 
2025-01-09 01:54:18.155358: val_loss -0.08 
2025-01-09 01:54:18.160881: Pseudo dice [np.float32(0.2218)] 
2025-01-09 01:54:18.163914: Epoch time: 41.32 s 
2025-01-09 01:54:18.166977: Yayy! New best EMA pseudo Dice: 0.125900000333786 
2025-01-09 01:54:18.892151:  
2025-01-09 01:54:18.892151: Epoch 49 
2025-01-09 01:54:18.897685: Current learning rate: 0.00822 
2025-01-09 01:55:00.197363: train_loss -0.0372 
2025-01-09 01:55:00.197363: val_loss -0.0199 
2025-01-09 01:55:00.203389: Pseudo dice [np.float32(0.0642)] 
2025-01-09 01:55:00.205941: Epoch time: 41.31 s 
2025-01-09 01:55:00.911151:  
2025-01-09 01:55:00.911151: Epoch 50 
2025-01-09 01:55:00.917203: Current learning rate: 0.00818 
2025-01-09 01:55:42.271387: train_loss -0.0458 
2025-01-09 01:55:42.272387: val_loss -0.0353 
2025-01-09 01:55:42.277929: Pseudo dice [np.float32(0.1265)] 
2025-01-09 01:55:42.280435: Epoch time: 41.36 s 
2025-01-09 01:55:42.795994:  
2025-01-09 01:55:42.796507: Epoch 51 
2025-01-09 01:55:42.801042: Current learning rate: 0.00814 
2025-01-09 01:56:24.143135: train_loss -0.0432 
2025-01-09 01:56:24.143638: val_loss -0.0552 
2025-01-09 01:56:24.148721: Pseudo dice [np.float32(0.1085)] 
2025-01-09 01:56:24.151226: Epoch time: 41.35 s 
2025-01-09 01:56:24.818422:  
2025-01-09 01:56:24.818927: Epoch 52 
2025-01-09 01:56:24.823563: Current learning rate: 0.00811 
2025-01-09 01:57:06.160355: train_loss -0.0509 
2025-01-09 01:57:06.161361: val_loss -0.0566 
2025-01-09 01:57:06.166369: Pseudo dice [np.float32(0.1553)] 
2025-01-09 01:57:06.168875: Epoch time: 41.34 s 
2025-01-09 01:57:06.702706:  
2025-01-09 01:57:06.702706: Epoch 53 
2025-01-09 01:57:06.707743: Current learning rate: 0.00807 
2025-01-09 01:57:48.041652: train_loss -0.0576 
2025-01-09 01:57:48.041652: val_loss -0.0639 
2025-01-09 01:57:48.047671: Pseudo dice [np.float32(0.2035)] 
2025-01-09 01:57:48.050737: Epoch time: 41.34 s 
2025-01-09 01:57:48.053274: Yayy! New best EMA pseudo Dice: 0.13089999556541443 
2025-01-09 01:57:48.823194:  
2025-01-09 01:57:48.823194: Epoch 54 
2025-01-09 01:57:48.830208: Current learning rate: 0.00803 
2025-01-09 01:58:30.159888: train_loss -0.0557 
2025-01-09 01:58:30.160892: val_loss -0.1022 
2025-01-09 01:58:30.166496: Pseudo dice [np.float32(0.2104)] 
2025-01-09 01:58:30.169034: Epoch time: 41.34 s 
2025-01-09 01:58:30.171567: Yayy! New best EMA pseudo Dice: 0.1387999951839447 
2025-01-09 01:58:30.913023:  
2025-01-09 01:58:30.913023: Epoch 55 
2025-01-09 01:58:30.917588: Current learning rate: 0.008 
2025-01-09 01:59:12.256711: train_loss -0.0282 
2025-01-09 01:59:12.256711: val_loss -0.0841 
2025-01-09 01:59:12.262905: Pseudo dice [np.float32(0.2375)] 
2025-01-09 01:59:12.265960: Epoch time: 41.34 s 
2025-01-09 01:59:12.269013: Yayy! New best EMA pseudo Dice: 0.14869999885559082 
2025-01-09 01:59:13.001029:  
2025-01-09 01:59:13.001029: Epoch 56 
2025-01-09 01:59:13.006575: Current learning rate: 0.00796 
2025-01-09 01:59:54.329088: train_loss -0.0369 
2025-01-09 01:59:54.330092: val_loss -0.0521 
2025-01-09 01:59:54.335104: Pseudo dice [np.float32(0.1385)] 
2025-01-09 01:59:54.337610: Epoch time: 41.33 s 
2025-01-09 01:59:54.867853:  
2025-01-09 01:59:54.867853: Epoch 57 
2025-01-09 01:59:54.871885: Current learning rate: 0.00792 
2025-01-09 02:00:36.215174: train_loss -0.0413 
2025-01-09 02:00:36.216681: val_loss -0.0426 
2025-01-09 02:00:36.221707: Pseudo dice [np.float32(0.1312)] 
2025-01-09 02:00:36.225222: Epoch time: 41.35 s 
2025-01-09 02:00:36.740783:  
2025-01-09 02:00:36.740783: Epoch 58 
2025-01-09 02:00:36.745867: Current learning rate: 0.00789 
2025-01-09 02:01:18.069691: train_loss -0.0425 
2025-01-09 02:01:18.069691: val_loss -0.0591 
2025-01-09 02:01:18.075704: Pseudo dice [np.float32(0.143)] 
2025-01-09 02:01:18.078736: Epoch time: 41.33 s 
2025-01-09 02:01:18.602996:  
2025-01-09 02:01:18.602996: Epoch 59 
2025-01-09 02:01:18.607035: Current learning rate: 0.00785 
2025-01-09 02:01:59.940069: train_loss -0.0341 
2025-01-09 02:01:59.940574: val_loss -0.0906 
2025-01-09 02:01:59.945159: Pseudo dice [np.float32(0.2168)] 
2025-01-09 02:01:59.948302: Epoch time: 41.34 s 
2025-01-09 02:01:59.951358: Yayy! New best EMA pseudo Dice: 0.15279999375343323 
2025-01-09 02:02:00.864051:  
2025-01-09 02:02:00.864556: Epoch 60 
2025-01-09 02:02:00.869123: Current learning rate: 0.00781 
2025-01-09 02:02:42.206712: train_loss -0.0477 
2025-01-09 02:02:42.207260: val_loss -0.074 
2025-01-09 02:02:42.212347: Pseudo dice [np.float32(0.2206)] 
2025-01-09 02:02:42.214871: Epoch time: 41.34 s 
2025-01-09 02:02:42.217397: Yayy! New best EMA pseudo Dice: 0.15960000455379486 
2025-01-09 02:02:42.999545:  
2025-01-09 02:02:42.999545: Epoch 61 
2025-01-09 02:02:43.004653: Current learning rate: 0.00777 
2025-01-09 02:03:24.327144: train_loss -0.0325 
2025-01-09 02:03:24.328149: val_loss -0.0469 
2025-01-09 02:03:24.333678: Pseudo dice [np.float32(0.1151)] 
2025-01-09 02:03:24.336699: Epoch time: 41.33 s 
2025-01-09 02:03:24.862732:  
2025-01-09 02:03:24.863235: Epoch 62 
2025-01-09 02:03:24.867814: Current learning rate: 0.00774 
2025-01-09 02:04:06.191502: train_loss -0.0666 
2025-01-09 02:04:06.192013: val_loss -0.0629 
2025-01-09 02:04:06.197095: Pseudo dice [np.float32(0.1854)] 
2025-01-09 02:04:06.199615: Epoch time: 41.33 s 
2025-01-09 02:04:06.725751:  
2025-01-09 02:04:06.725751: Epoch 63 
2025-01-09 02:04:06.729260: Current learning rate: 0.0077 
2025-01-09 02:04:48.047994: train_loss -0.0621 
2025-01-09 02:04:48.047994: val_loss -0.0212 
2025-01-09 02:04:48.054008: Pseudo dice [np.float32(0.0688)] 
2025-01-09 02:04:48.056514: Epoch time: 41.32 s 
2025-01-09 02:04:48.582866:  
2025-01-09 02:04:48.583866: Epoch 64 
2025-01-09 02:04:48.588922: Current learning rate: 0.00766 
2025-01-09 02:05:29.935523: train_loss -0.0482 
2025-01-09 02:05:29.935523: val_loss -0.0906 
2025-01-09 02:05:29.941535: Pseudo dice [np.float32(0.194)] 
2025-01-09 02:05:29.944546: Epoch time: 41.35 s 
2025-01-09 02:05:30.487708:  
2025-01-09 02:05:30.488709: Epoch 65 
2025-01-09 02:05:30.493755: Current learning rate: 0.00763 
2025-01-09 02:06:11.819420: train_loss -0.0182 
2025-01-09 02:06:11.820421: val_loss -0.0424 
2025-01-09 02:06:11.825435: Pseudo dice [np.float32(0.1719)] 
2025-01-09 02:06:11.828515: Epoch time: 41.33 s 
2025-01-09 02:06:12.365844:  
2025-01-09 02:06:12.366411: Epoch 66 
2025-01-09 02:06:12.372991: Current learning rate: 0.00759 
2025-01-09 02:06:53.728499: train_loss -0.0575 
2025-01-09 02:06:53.729504: val_loss -0.0376 
2025-01-09 02:06:53.736018: Pseudo dice [np.float32(0.1015)] 
2025-01-09 02:06:53.739526: Epoch time: 41.36 s 
2025-01-09 02:06:54.286289:  
2025-01-09 02:06:54.287293: Epoch 67 
2025-01-09 02:06:54.291840: Current learning rate: 0.00755 
2025-01-09 02:07:35.632969: train_loss -0.0556 
2025-01-09 02:07:35.633969: val_loss -0.0524 
2025-01-09 02:07:35.640049: Pseudo dice [np.float32(0.1253)] 
2025-01-09 02:07:35.642557: Epoch time: 41.35 s 
2025-01-09 02:07:36.333338:  
2025-01-09 02:07:36.333338: Epoch 68 
2025-01-09 02:07:36.338378: Current learning rate: 0.00751 
2025-01-09 02:08:17.666478: train_loss -0.0403 
2025-01-09 02:08:17.666993: val_loss -0.05 
2025-01-09 02:08:17.672059: Pseudo dice [np.float32(0.1172)] 
2025-01-09 02:08:17.675568: Epoch time: 41.33 s 
2025-01-09 02:08:18.212568:  
2025-01-09 02:08:18.213079: Epoch 69 
2025-01-09 02:08:18.217664: Current learning rate: 0.00748 
2025-01-09 02:08:59.529660: train_loss -0.0464 
2025-01-09 02:08:59.530165: val_loss -0.033 
2025-01-09 02:08:59.535740: Pseudo dice [np.float32(0.0915)] 
2025-01-09 02:08:59.539248: Epoch time: 41.32 s 
2025-01-09 02:09:00.076592:  
2025-01-09 02:09:00.077094: Epoch 70 
2025-01-09 02:09:00.082105: Current learning rate: 0.00744 
2025-01-09 02:09:41.404546: train_loss -0.06 
2025-01-09 02:09:41.404546: val_loss -0.0529 
2025-01-09 02:09:41.410653: Pseudo dice [np.float32(0.1371)] 
2025-01-09 02:09:41.413164: Epoch time: 41.33 s 
2025-01-09 02:09:41.956403:  
2025-01-09 02:09:41.957407: Epoch 71 
2025-01-09 02:09:41.962147: Current learning rate: 0.0074 
2025-01-09 02:10:23.272309: train_loss -0.0423 
2025-01-09 02:10:23.273309: val_loss -0.0416 
2025-01-09 02:10:23.278321: Pseudo dice [np.float32(0.1421)] 
2025-01-09 02:10:23.281330: Epoch time: 41.32 s 
2025-01-09 02:10:23.820940:  
2025-01-09 02:10:23.820940: Epoch 72 
2025-01-09 02:10:23.826480: Current learning rate: 0.00737 
2025-01-09 02:11:05.165876: train_loss -0.0422 
2025-01-09 02:11:05.166876: val_loss -0.0687 
2025-01-09 02:11:05.172389: Pseudo dice [np.float32(0.1835)] 
2025-01-09 02:11:05.174899: Epoch time: 41.35 s 
2025-01-09 02:11:05.720326:  
2025-01-09 02:11:05.720829: Epoch 73 
2025-01-09 02:11:05.725841: Current learning rate: 0.00733 
2025-01-09 02:11:47.082431: train_loss -0.0637 
2025-01-09 02:11:47.082431: val_loss -0.0816 
2025-01-09 02:11:47.088445: Pseudo dice [np.float32(0.2027)] 
2025-01-09 02:11:47.090955: Epoch time: 41.36 s 
2025-01-09 02:11:47.636401:  
2025-01-09 02:11:47.636401: Epoch 74 
2025-01-09 02:11:47.641412: Current learning rate: 0.00729 
2025-01-09 02:12:28.994697: train_loss -0.0436 
2025-01-09 02:12:28.995697: val_loss -0.0866 
2025-01-09 02:12:29.001239: Pseudo dice [np.float32(0.1921)] 
2025-01-09 02:12:29.004277: Epoch time: 41.36 s 
2025-01-09 02:12:29.552727:  
2025-01-09 02:12:29.552727: Epoch 75 
2025-01-09 02:12:29.557333: Current learning rate: 0.00725 
2025-01-09 02:13:10.902771: train_loss -0.0624 
2025-01-09 02:13:10.903773: val_loss -0.0724 
2025-01-09 02:13:10.909290: Pseudo dice [np.float32(0.2365)] 
2025-01-09 02:13:10.911795: Epoch time: 41.35 s 
2025-01-09 02:13:10.915303: Yayy! New best EMA pseudo Dice: 0.16220000386238098 
2025-01-09 02:13:11.859395:  
2025-01-09 02:13:11.859395: Epoch 76 
2025-01-09 02:13:11.864980: Current learning rate: 0.00722 
2025-01-09 02:13:53.176478: train_loss -0.0555 
2025-01-09 02:13:53.176478: val_loss -0.0194 
2025-01-09 02:13:53.183073: Pseudo dice [np.float32(0.0523)] 
2025-01-09 02:13:53.186084: Epoch time: 41.32 s 
2025-01-09 02:13:53.734975:  
2025-01-09 02:13:53.735978: Epoch 77 
2025-01-09 02:13:53.742558: Current learning rate: 0.00718 
2025-01-09 02:14:35.057920: train_loss -0.037 
2025-01-09 02:14:35.057920: val_loss -0.0507 
2025-01-09 02:14:35.063931: Pseudo dice [np.float32(0.1373)] 
2025-01-09 02:14:35.066977: Epoch time: 41.32 s 
2025-01-09 02:14:35.617007:  
2025-01-09 02:14:35.618010: Epoch 78 
2025-01-09 02:14:35.623064: Current learning rate: 0.00714 
2025-01-09 02:15:16.954939: train_loss -0.0432 
2025-01-09 02:15:16.954939: val_loss -0.0843 
2025-01-09 02:15:16.959949: Pseudo dice [np.float32(0.1899)] 
2025-01-09 02:15:16.963457: Epoch time: 41.34 s 
2025-01-09 02:15:17.507858:  
2025-01-09 02:15:17.508361: Epoch 79 
2025-01-09 02:15:17.513372: Current learning rate: 0.0071 
2025-01-09 02:15:58.830429: train_loss -0.0556 
2025-01-09 02:15:58.830429: val_loss -0.0545 
2025-01-09 02:15:58.836018: Pseudo dice [np.float32(0.1403)] 
2025-01-09 02:15:58.839164: Epoch time: 41.32 s 
2025-01-09 02:15:59.390770:  
2025-01-09 02:15:59.391773: Epoch 80 
2025-01-09 02:15:59.396357: Current learning rate: 0.00707 
2025-01-09 02:16:40.720632: train_loss -0.0622 
2025-01-09 02:16:40.720632: val_loss -0.0639 
2025-01-09 02:16:40.725751: Pseudo dice [np.float32(0.1414)] 
2025-01-09 02:16:40.728227: Epoch time: 41.33 s 
2025-01-09 02:16:41.276599:  
2025-01-09 02:16:41.277599: Epoch 81 
2025-01-09 02:16:41.280670: Current learning rate: 0.00703 
2025-01-09 02:17:22.598043: train_loss -0.0613 
2025-01-09 02:17:22.598043: val_loss -0.0221 
2025-01-09 02:17:22.603108: Pseudo dice [np.float32(0.1061)] 
2025-01-09 02:17:22.606641: Epoch time: 41.32 s 
2025-01-09 02:17:23.158372:  
2025-01-09 02:17:23.158372: Epoch 82 
2025-01-09 02:17:23.164434: Current learning rate: 0.00699 
2025-01-09 02:18:04.511761: train_loss -0.0631 
2025-01-09 02:18:04.511761: val_loss -0.0605 
2025-01-09 02:18:04.517776: Pseudo dice [np.float32(0.153)] 
2025-01-09 02:18:04.520281: Epoch time: 41.35 s 
2025-01-09 02:18:05.039965:  
2025-01-09 02:18:05.039965: Epoch 83 
2025-01-09 02:18:05.045526: Current learning rate: 0.00696 
2025-01-09 02:18:46.427884: train_loss -0.0657 
2025-01-09 02:18:46.427884: val_loss -0.0573 
2025-01-09 02:18:46.433959: Pseudo dice [np.float32(0.1736)] 
2025-01-09 02:18:46.437068: Epoch time: 41.39 s 
2025-01-09 02:18:47.105040:  
2025-01-09 02:18:47.106044: Epoch 84 
2025-01-09 02:18:47.110584: Current learning rate: 0.00692 
2025-01-09 02:19:28.454463: train_loss -0.0949 
2025-01-09 02:19:28.454965: val_loss -0.0214 
2025-01-09 02:19:28.460549: Pseudo dice [np.float32(0.0899)] 
2025-01-09 02:19:28.463587: Epoch time: 41.35 s 
2025-01-09 02:19:28.989926:  
2025-01-09 02:19:28.990430: Epoch 85 
2025-01-09 02:19:28.995445: Current learning rate: 0.00688 
2025-01-09 02:20:10.330861: train_loss -0.0794 
2025-01-09 02:20:10.331365: val_loss -0.0705 
2025-01-09 02:20:10.336957: Pseudo dice [np.float32(0.2071)] 
2025-01-09 02:20:10.338993: Epoch time: 41.34 s 
2025-01-09 02:20:10.857802:  
2025-01-09 02:20:10.858803: Epoch 86 
2025-01-09 02:20:10.865417: Current learning rate: 0.00684 
2025-01-09 02:20:52.176460: train_loss -0.0646 
2025-01-09 02:20:52.177459: val_loss -0.0831 
2025-01-09 02:20:52.183086: Pseudo dice [np.float32(0.2333)] 
2025-01-09 02:20:52.186634: Epoch time: 41.32 s 
2025-01-09 02:20:52.705405:  
2025-01-09 02:20:52.705909: Epoch 87 
2025-01-09 02:20:52.710922: Current learning rate: 0.0068 
2025-01-09 02:21:34.045265: train_loss -0.0667 
2025-01-09 02:21:34.046266: val_loss -0.0639 
2025-01-09 02:21:34.051781: Pseudo dice [np.float32(0.135)] 
2025-01-09 02:21:34.054292: Epoch time: 41.34 s 
2025-01-09 02:21:34.576844:  
2025-01-09 02:21:34.576844: Epoch 88 
2025-01-09 02:21:34.581857: Current learning rate: 0.00677 
2025-01-09 02:22:15.911887: train_loss -0.0388 
2025-01-09 02:22:15.912891: val_loss -0.0693 
2025-01-09 02:22:15.917409: Pseudo dice [np.float32(0.1542)] 
2025-01-09 02:22:15.921479: Epoch time: 41.34 s 
2025-01-09 02:22:16.441403:  
2025-01-09 02:22:16.441403: Epoch 89 
2025-01-09 02:22:16.446503: Current learning rate: 0.00673 
2025-01-09 02:22:57.776349: train_loss -0.078 
2025-01-09 02:22:57.776349: val_loss -0.0394 
2025-01-09 02:22:57.781411: Pseudo dice [np.float32(0.1207)] 
2025-01-09 02:22:57.783919: Epoch time: 41.34 s 
2025-01-09 02:22:58.309828:  
2025-01-09 02:22:58.310828: Epoch 90 
2025-01-09 02:22:58.314841: Current learning rate: 0.00669 
2025-01-09 02:23:39.658317: train_loss -0.0656 
2025-01-09 02:23:39.659827: val_loss -0.0425 
2025-01-09 02:23:39.665407: Pseudo dice [np.float32(0.1035)] 
2025-01-09 02:23:39.668440: Epoch time: 41.35 s 
2025-01-09 02:23:40.188540:  
2025-01-09 02:23:40.188540: Epoch 91 
2025-01-09 02:23:40.194065: Current learning rate: 0.00665 
2025-01-09 02:24:21.538915: train_loss -0.0431 
2025-01-09 02:24:21.539920: val_loss -0.0426 
2025-01-09 02:24:21.544929: Pseudo dice [np.float32(0.0914)] 
2025-01-09 02:24:21.547436: Epoch time: 41.35 s 
2025-01-09 02:24:22.230067:  
2025-01-09 02:24:22.230067: Epoch 92 
2025-01-09 02:24:22.235077: Current learning rate: 0.00662 
2025-01-09 02:25:03.527708: train_loss -0.0479 
2025-01-09 02:25:03.528708: val_loss -0.013 
2025-01-09 02:25:03.534221: Pseudo dice [np.float32(0.036)] 
2025-01-09 02:25:03.536740: Epoch time: 41.3 s 
2025-01-09 02:25:04.051831:  
2025-01-09 02:25:04.051831: Epoch 93 
2025-01-09 02:25:04.055867: Current learning rate: 0.00658 
2025-01-09 02:25:45.368589: train_loss -0.0436 
2025-01-09 02:25:45.369591: val_loss -0.0875 
2025-01-09 02:25:45.375105: Pseudo dice [np.float32(0.1709)] 
2025-01-09 02:25:45.377611: Epoch time: 41.32 s 
2025-01-09 02:25:45.897297:  
2025-01-09 02:25:45.897297: Epoch 94 
2025-01-09 02:25:45.902855: Current learning rate: 0.00654 
2025-01-09 02:26:27.232855: train_loss -0.0637 
2025-01-09 02:26:27.233358: val_loss -0.0662 
2025-01-09 02:26:27.238369: Pseudo dice [np.float32(0.1993)] 
2025-01-09 02:26:27.241876: Epoch time: 41.34 s 
2025-01-09 02:26:27.762309:  
2025-01-09 02:26:27.762309: Epoch 95 
2025-01-09 02:26:27.767847: Current learning rate: 0.0065 
2025-01-09 02:27:09.091970: train_loss -0.0675 
2025-01-09 02:27:09.092977: val_loss -0.093 
2025-01-09 02:27:09.099492: Pseudo dice [np.float32(0.1839)] 
2025-01-09 02:27:09.101999: Epoch time: 41.33 s 
2025-01-09 02:27:09.629221:  
2025-01-09 02:27:09.629221: Epoch 96 
2025-01-09 02:27:09.634782: Current learning rate: 0.00647 
2025-01-09 02:27:50.969484: train_loss -0.0754 
2025-01-09 02:27:50.969484: val_loss -0.0935 
2025-01-09 02:27:50.974921: Pseudo dice [np.float32(0.1989)] 
2025-01-09 02:27:50.978437: Epoch time: 41.34 s 
2025-01-09 02:27:51.511799:  
2025-01-09 02:27:51.511799: Epoch 97 
2025-01-09 02:27:51.515831: Current learning rate: 0.00643 
2025-01-09 02:28:32.848885: train_loss -0.0979 
2025-01-09 02:28:32.848885: val_loss -0.0769 
2025-01-09 02:28:32.853936: Pseudo dice [np.float32(0.1683)] 
2025-01-09 02:28:32.856441: Epoch time: 41.34 s 
2025-01-09 02:28:33.392841:  
2025-01-09 02:28:33.393839: Epoch 98 
2025-01-09 02:28:33.398401: Current learning rate: 0.00639 
2025-01-09 02:29:14.715769: train_loss -0.0821 
2025-01-09 02:29:14.715769: val_loss -0.0493 
2025-01-09 02:29:14.721843: Pseudo dice [np.float32(0.1182)] 
2025-01-09 02:29:14.723927: Epoch time: 41.32 s 
2025-01-09 02:29:15.256392:  
2025-01-09 02:29:15.256392: Epoch 99 
2025-01-09 02:29:15.261429: Current learning rate: 0.00635 
2025-01-09 02:29:56.603024: train_loss -0.064 
2025-01-09 02:29:56.603527: val_loss -0.0979 
2025-01-09 02:29:56.610546: Pseudo dice [np.float32(0.2584)] 
2025-01-09 02:29:56.613608: Epoch time: 41.35 s 
2025-01-09 02:29:57.403111:  
2025-01-09 02:29:57.404114: Epoch 100 
2025-01-09 02:29:57.408657: Current learning rate: 0.00631 
2025-01-09 02:30:38.740895: train_loss -0.0935 
2025-01-09 02:30:38.741410: val_loss -0.1034 
2025-01-09 02:30:38.746463: Pseudo dice [np.float32(0.2088)] 
2025-01-09 02:30:38.748968: Epoch time: 41.34 s 
2025-01-09 02:30:38.752511: Yayy! New best EMA pseudo Dice: 0.16519999504089355 
2025-01-09 02:30:39.625480:  
2025-01-09 02:30:39.625480: Epoch 101 
2025-01-09 02:30:39.631550: Current learning rate: 0.00628 
2025-01-09 02:31:20.947331: train_loss -0.0924 
2025-01-09 02:31:20.948331: val_loss -0.0128 
2025-01-09 02:31:20.953851: Pseudo dice [np.float32(0.1134)] 
2025-01-09 02:31:20.956355: Epoch time: 41.32 s 
2025-01-09 02:31:21.483784:  
2025-01-09 02:31:21.483784: Epoch 102 
2025-01-09 02:31:21.488796: Current learning rate: 0.00624 
2025-01-09 02:32:02.835918: train_loss -0.0244 
2025-01-09 02:32:02.836429: val_loss -0.0743 
2025-01-09 02:32:02.843491: Pseudo dice [np.float32(0.1693)] 
2025-01-09 02:32:02.846563: Epoch time: 41.35 s 
2025-01-09 02:32:03.390773:  
2025-01-09 02:32:03.391777: Epoch 103 
2025-01-09 02:32:03.396319: Current learning rate: 0.0062 
2025-01-09 02:32:44.705252: train_loss -0.0494 
2025-01-09 02:32:44.705755: val_loss -0.0379 
2025-01-09 02:32:44.710767: Pseudo dice [np.float32(0.1051)] 
2025-01-09 02:32:44.714284: Epoch time: 41.31 s 
2025-01-09 02:32:45.249583:  
2025-01-09 02:32:45.249583: Epoch 104 
2025-01-09 02:32:45.254636: Current learning rate: 0.00616 
2025-01-09 02:33:26.600312: train_loss -0.0799 
2025-01-09 02:33:26.600817: val_loss -0.0708 
2025-01-09 02:33:26.605855: Pseudo dice [np.float32(0.1243)] 
2025-01-09 02:33:26.609392: Epoch time: 41.35 s 
2025-01-09 02:33:27.148507:  
2025-01-09 02:33:27.148507: Epoch 105 
2025-01-09 02:33:27.153544: Current learning rate: 0.00612 
2025-01-09 02:34:08.456402: train_loss -0.0728 
2025-01-09 02:34:08.456904: val_loss -0.0348 
2025-01-09 02:34:08.463926: Pseudo dice [np.float32(0.1142)] 
2025-01-09 02:34:08.466941: Epoch time: 41.31 s 
2025-01-09 02:34:09.013064:  
2025-01-09 02:34:09.013566: Epoch 106 
2025-01-09 02:34:09.018584: Current learning rate: 0.00609 
2025-01-09 02:34:50.374410: train_loss -0.0876 
2025-01-09 02:34:50.375416: val_loss -0.0735 
2025-01-09 02:34:50.380430: Pseudo dice [np.float32(0.2195)] 
2025-01-09 02:34:50.383934: Epoch time: 41.36 s 
2025-01-09 02:34:50.924560:  
2025-01-09 02:34:50.925063: Epoch 107 
2025-01-09 02:34:50.930073: Current learning rate: 0.00605 
2025-01-09 02:35:32.268026: train_loss -0.0911 
2025-01-09 02:35:32.269026: val_loss -0.076 
2025-01-09 02:35:32.274598: Pseudo dice [np.float32(0.2179)] 
2025-01-09 02:35:32.277105: Epoch time: 41.34 s 
2025-01-09 02:35:32.842861:  
2025-01-09 02:35:32.843860: Epoch 108 
2025-01-09 02:35:32.849372: Current learning rate: 0.00601 
2025-01-09 02:36:14.162354: train_loss -0.0824 
2025-01-09 02:36:14.162354: val_loss -0.0758 
2025-01-09 02:36:14.168412: Pseudo dice [np.float32(0.1684)] 
2025-01-09 02:36:14.171166: Epoch time: 41.32 s 
2025-01-09 02:36:14.873215:  
2025-01-09 02:36:14.873215: Epoch 109 
2025-01-09 02:36:14.878796: Current learning rate: 0.00597 
2025-01-09 02:36:56.190235: train_loss -0.0798 
2025-01-09 02:36:56.190235: val_loss -0.0716 
2025-01-09 02:36:56.195870: Pseudo dice [np.float32(0.1683)] 
2025-01-09 02:36:56.199382: Epoch time: 41.32 s 
2025-01-09 02:36:56.740737:  
2025-01-09 02:36:56.740737: Epoch 110 
2025-01-09 02:36:56.747351: Current learning rate: 0.00593 
2025-01-09 02:37:38.077877: train_loss -0.0476 
2025-01-09 02:37:38.078381: val_loss -0.0929 
2025-01-09 02:37:38.083393: Pseudo dice [np.float32(0.2454)] 
2025-01-09 02:37:38.085898: Epoch time: 41.34 s 
2025-01-09 02:37:38.089406: Yayy! New best EMA pseudo Dice: 0.1712999939918518 
2025-01-09 02:37:38.852443:  
2025-01-09 02:37:38.852443: Epoch 111 
2025-01-09 02:37:38.857472: Current learning rate: 0.0059 
2025-01-09 02:38:20.197287: train_loss -0.092 
2025-01-09 02:38:20.197287: val_loss -0.0724 
2025-01-09 02:38:20.203306: Pseudo dice [np.float32(0.1824)] 
2025-01-09 02:38:20.206819: Epoch time: 41.35 s 
2025-01-09 02:38:20.209919: Yayy! New best EMA pseudo Dice: 0.17239999771118164 
2025-01-09 02:38:21.014934:  
2025-01-09 02:38:21.014934: Epoch 112 
2025-01-09 02:38:21.020487: Current learning rate: 0.00586 
2025-01-09 02:39:02.380008: train_loss -0.0838 
2025-01-09 02:39:02.381013: val_loss -0.1164 
2025-01-09 02:39:02.387026: Pseudo dice [np.float32(0.3271)] 
2025-01-09 02:39:02.390078: Epoch time: 41.37 s 
2025-01-09 02:39:02.393590: Yayy! New best EMA pseudo Dice: 0.18790000677108765 
2025-01-09 02:39:03.154651:  
2025-01-09 02:39:03.154651: Epoch 113 
2025-01-09 02:39:03.160182: Current learning rate: 0.00582 
2025-01-09 02:39:44.482743: train_loss -0.0907 
2025-01-09 02:39:44.482743: val_loss -0.0408 
2025-01-09 02:39:44.488779: Pseudo dice [np.float32(0.1491)] 
2025-01-09 02:39:44.491359: Epoch time: 41.33 s 
2025-01-09 02:39:45.023460:  
2025-01-09 02:39:45.023963: Epoch 114 
2025-01-09 02:39:45.028982: Current learning rate: 0.00578 
2025-01-09 02:40:26.342419: train_loss -0.0719 
2025-01-09 02:40:26.342923: val_loss -0.0434 
2025-01-09 02:40:26.348479: Pseudo dice [np.float32(0.1105)] 
2025-01-09 02:40:26.351508: Epoch time: 41.32 s 
2025-01-09 02:40:26.891643:  
2025-01-09 02:40:26.892644: Epoch 115 
2025-01-09 02:40:26.897693: Current learning rate: 0.00574 
2025-01-09 02:41:08.246295: train_loss -0.0737 
2025-01-09 02:41:08.247298: val_loss -0.0475 
2025-01-09 02:41:08.253818: Pseudo dice [np.float32(0.1118)] 
2025-01-09 02:41:08.257324: Epoch time: 41.35 s 
2025-01-09 02:41:08.808271:  
2025-01-09 02:41:08.808773: Epoch 116 
2025-01-09 02:41:08.813307: Current learning rate: 0.0057 
2025-01-09 02:41:50.166668: train_loss -0.1083 
2025-01-09 02:41:50.166668: val_loss -0.0712 
2025-01-09 02:41:50.172685: Pseudo dice [np.float32(0.1564)] 
2025-01-09 02:41:50.175777: Epoch time: 41.36 s 
2025-01-09 02:41:50.877369:  
2025-01-09 02:41:50.877872: Epoch 117 
2025-01-09 02:41:50.882882: Current learning rate: 0.00567 
2025-01-09 02:42:32.205183: train_loss -0.1073 
2025-01-09 02:42:32.206186: val_loss -0.0747 
2025-01-09 02:42:32.211395: Pseudo dice [np.float32(0.208)] 
2025-01-09 02:42:32.213445: Epoch time: 41.33 s 
2025-01-09 02:42:32.749596:  
2025-01-09 02:42:32.750595: Epoch 118 
2025-01-09 02:42:32.756110: Current learning rate: 0.00563 
2025-01-09 02:43:14.077836: train_loss -0.0779 
2025-01-09 02:43:14.078835: val_loss -0.0649 
2025-01-09 02:43:14.084385: Pseudo dice [np.float32(0.2108)] 
2025-01-09 02:43:14.086890: Epoch time: 41.33 s 
2025-01-09 02:43:14.628913:  
2025-01-09 02:43:14.629914: Epoch 119 
2025-01-09 02:43:14.634977: Current learning rate: 0.00559 
2025-01-09 02:43:55.969610: train_loss -0.1 
2025-01-09 02:43:55.970610: val_loss -0.1245 
2025-01-09 02:43:55.976127: Pseudo dice [np.float32(0.212)] 
2025-01-09 02:43:55.978632: Epoch time: 41.34 s 
2025-01-09 02:43:56.515419:  
2025-01-09 02:43:56.516419: Epoch 120 
2025-01-09 02:43:56.521447: Current learning rate: 0.00555 
2025-01-09 02:44:37.834431: train_loss -0.0888 
2025-01-09 02:44:37.834431: val_loss -0.1113 
2025-01-09 02:44:37.840950: Pseudo dice [np.float32(0.2129)] 
2025-01-09 02:44:37.844463: Epoch time: 41.32 s 
2025-01-09 02:44:38.381880:  
2025-01-09 02:44:38.381880: Epoch 121 
2025-01-09 02:44:38.387411: Current learning rate: 0.00551 
2025-01-09 02:45:19.703878: train_loss -0.0898 
2025-01-09 02:45:19.704389: val_loss -0.0738 
2025-01-09 02:45:19.708944: Pseudo dice [np.float32(0.1943)] 
2025-01-09 02:45:19.711481: Epoch time: 41.32 s 
2025-01-09 02:45:20.254464:  
2025-01-09 02:45:20.254464: Epoch 122 
2025-01-09 02:45:20.259558: Current learning rate: 0.00547 
2025-01-09 02:46:01.603683: train_loss -0.1023 
2025-01-09 02:46:01.603683: val_loss -0.1248 
2025-01-09 02:46:01.611206: Pseudo dice [np.float32(0.2802)] 
2025-01-09 02:46:01.613734: Epoch time: 41.35 s 
2025-01-09 02:46:01.617782: Yayy! New best EMA pseudo Dice: 0.1940000057220459 
2025-01-09 02:46:02.397673:  
2025-01-09 02:46:02.398676: Epoch 123 
2025-01-09 02:46:02.403234: Current learning rate: 0.00544 
2025-01-09 02:46:43.739040: train_loss -0.1029 
2025-01-09 02:46:43.740043: val_loss -0.0997 
2025-01-09 02:46:43.745052: Pseudo dice [np.float32(0.218)] 
2025-01-09 02:46:43.747558: Epoch time: 41.34 s 
2025-01-09 02:46:43.751063: Yayy! New best EMA pseudo Dice: 0.1964000016450882 
2025-01-09 02:46:44.546347:  
2025-01-09 02:46:44.546347: Epoch 124 
2025-01-09 02:46:44.550371: Current learning rate: 0.0054 
2025-01-09 02:47:25.883710: train_loss -0.0835 
2025-01-09 02:47:25.884213: val_loss -0.1108 
2025-01-09 02:47:25.889827: Pseudo dice [np.float32(0.2464)] 
2025-01-09 02:47:25.892952: Epoch time: 41.34 s 
2025-01-09 02:47:25.895470: Yayy! New best EMA pseudo Dice: 0.2013999968767166 
2025-01-09 02:47:26.860419:  
2025-01-09 02:47:26.861422: Epoch 125 
2025-01-09 02:47:26.865450: Current learning rate: 0.00536 
2025-01-09 02:48:08.188207: train_loss -0.0985 
2025-01-09 02:48:08.188717: val_loss -0.1066 
2025-01-09 02:48:08.193776: Pseudo dice [np.float32(0.2435)] 
2025-01-09 02:48:08.197047: Epoch time: 41.33 s 
2025-01-09 02:48:08.199553: Yayy! New best EMA pseudo Dice: 0.20559999346733093 
2025-01-09 02:48:08.973813:  
2025-01-09 02:48:08.974814: Epoch 126 
2025-01-09 02:48:08.980331: Current learning rate: 0.00532 
2025-01-09 02:48:50.318484: train_loss -0.0695 
2025-01-09 02:48:50.319489: val_loss -0.0583 
2025-01-09 02:48:50.324010: Pseudo dice [np.float32(0.141)] 
2025-01-09 02:48:50.328044: Epoch time: 41.34 s 
2025-01-09 02:48:50.862804:  
2025-01-09 02:48:50.862804: Epoch 127 
2025-01-09 02:48:50.868939: Current learning rate: 0.00528 
2025-01-09 02:49:32.221066: train_loss -0.0525 
2025-01-09 02:49:32.221570: val_loss -0.0763 
2025-01-09 02:49:32.227588: Pseudo dice [np.float32(0.1932)] 
2025-01-09 02:49:32.230095: Epoch time: 41.36 s 
2025-01-09 02:49:32.782712:  
2025-01-09 02:49:32.782712: Epoch 128 
2025-01-09 02:49:32.787729: Current learning rate: 0.00524 
2025-01-09 02:50:14.157376: train_loss -0.1053 
2025-01-09 02:50:14.157376: val_loss -0.068 
2025-01-09 02:50:14.163918: Pseudo dice [np.float32(0.1709)] 
2025-01-09 02:50:14.166960: Epoch time: 41.38 s 
2025-01-09 02:50:14.710103:  
2025-01-09 02:50:14.710103: Epoch 129 
2025-01-09 02:50:14.715629: Current learning rate: 0.0052 
2025-01-09 02:50:56.057936: train_loss -0.0789 
2025-01-09 02:50:56.058940: val_loss -0.0949 
2025-01-09 02:50:56.063951: Pseudo dice [np.float32(0.2439)] 
2025-01-09 02:50:56.067456: Epoch time: 41.35 s 
2025-01-09 02:50:56.607453:  
2025-01-09 02:50:56.607453: Epoch 130 
2025-01-09 02:50:56.612982: Current learning rate: 0.00517 
2025-01-09 02:51:37.940549: train_loss -0.0905 
2025-01-09 02:51:37.942076: val_loss -0.05 
2025-01-09 02:51:37.948272: Pseudo dice [np.float32(0.1648)] 
2025-01-09 02:51:37.951309: Epoch time: 41.33 s 
2025-01-09 02:51:38.507171:  
2025-01-09 02:51:38.508176: Epoch 131 
2025-01-09 02:51:38.512712: Current learning rate: 0.00513 
2025-01-09 02:52:19.849857: train_loss -0.0746 
2025-01-09 02:52:19.850861: val_loss -0.0842 
2025-01-09 02:52:19.856404: Pseudo dice [np.float32(0.2387)] 
2025-01-09 02:52:19.859919: Epoch time: 41.34 s 
2025-01-09 02:52:20.559824:  
2025-01-09 02:52:20.560827: Epoch 132 
2025-01-09 02:52:20.565367: Current learning rate: 0.00509 
2025-01-09 02:53:01.905767: train_loss -0.0873 
2025-01-09 02:53:01.905767: val_loss -0.0568 
2025-01-09 02:53:01.913401: Pseudo dice [np.float32(0.1749)] 
2025-01-09 02:53:01.915946: Epoch time: 41.35 s 
2025-01-09 02:53:02.455915:  
2025-01-09 02:53:02.455915: Epoch 133 
2025-01-09 02:53:02.461046: Current learning rate: 0.00505 
2025-01-09 02:53:43.795447: train_loss -0.0801 
2025-01-09 02:53:43.795960: val_loss -0.0912 
2025-01-09 02:53:43.801039: Pseudo dice [np.float32(0.2649)] 
2025-01-09 02:53:43.804082: Epoch time: 41.34 s 
2025-01-09 02:53:44.347211:  
2025-01-09 02:53:44.348219: Epoch 134 
2025-01-09 02:53:44.353244: Current learning rate: 0.00501 
2025-01-09 02:54:25.678069: train_loss -0.1266 
2025-01-09 02:54:25.678572: val_loss -0.117 
2025-01-09 02:54:25.684116: Pseudo dice [np.float32(0.268)] 
2025-01-09 02:54:25.687137: Epoch time: 41.33 s 
2025-01-09 02:54:25.689653: Yayy! New best EMA pseudo Dice: 0.21150000393390656 
2025-01-09 02:54:26.495858:  
2025-01-09 02:54:26.495858: Epoch 135 
2025-01-09 02:54:26.500870: Current learning rate: 0.00497 
2025-01-09 02:55:07.805579: train_loss -0.061 
2025-01-09 02:55:07.805579: val_loss -0.048 
2025-01-09 02:55:07.812125: Pseudo dice [np.float32(0.1184)] 
2025-01-09 02:55:07.814666: Epoch time: 41.31 s 
2025-01-09 02:55:08.426013:  
2025-01-09 02:55:08.426013: Epoch 136 
2025-01-09 02:55:08.432037: Current learning rate: 0.00493 
2025-01-09 02:55:49.770036: train_loss -0.0992 
2025-01-09 02:55:49.770546: val_loss -0.0982 
2025-01-09 02:55:49.775596: Pseudo dice [np.float32(0.259)] 
2025-01-09 02:55:49.778677: Epoch time: 41.34 s 
2025-01-09 02:55:50.328616:  
2025-01-09 02:55:50.329617: Epoch 137 
2025-01-09 02:55:50.334747: Current learning rate: 0.00489 
2025-01-09 02:56:31.648951: train_loss -0.0701 
2025-01-09 02:56:31.648951: val_loss -0.1104 
2025-01-09 02:56:31.653962: Pseudo dice [np.float32(0.2189)] 
2025-01-09 02:56:31.657979: Epoch time: 41.32 s 
2025-01-09 02:56:32.218428:  
2025-01-09 02:56:32.218428: Epoch 138 
2025-01-09 02:56:32.223558: Current learning rate: 0.00485 
2025-01-09 02:57:13.547776: train_loss -0.0895 
2025-01-09 02:57:13.547776: val_loss -0.1364 
2025-01-09 02:57:13.553790: Pseudo dice [np.float32(0.353)] 
2025-01-09 02:57:13.555801: Epoch time: 41.33 s 
2025-01-09 02:57:13.559834: Yayy! New best EMA pseudo Dice: 0.22339999675750732 
2025-01-09 02:57:14.400071:  
2025-01-09 02:57:14.400071: Epoch 139 
2025-01-09 02:57:14.405081: Current learning rate: 0.00482 
2025-01-09 02:57:55.761487: train_loss -0.0722 
2025-01-09 02:57:55.762488: val_loss -0.122 
2025-01-09 02:57:55.768025: Pseudo dice [np.float32(0.3197)] 
2025-01-09 02:57:55.771059: Epoch time: 41.36 s 
2025-01-09 02:57:55.773090: Yayy! New best EMA pseudo Dice: 0.2329999953508377 
2025-01-09 02:57:56.563893:  
2025-01-09 02:57:56.563893: Epoch 140 
2025-01-09 02:57:56.569932: Current learning rate: 0.00478 
2025-01-09 02:58:37.884888: train_loss -0.0984 
2025-01-09 02:58:37.885888: val_loss -0.0944 
2025-01-09 02:58:37.891441: Pseudo dice [np.float32(0.2378)] 
2025-01-09 02:58:37.894950: Epoch time: 41.32 s 
2025-01-09 02:58:37.897456: Yayy! New best EMA pseudo Dice: 0.23350000381469727 
2025-01-09 02:58:38.806326:  
2025-01-09 02:58:38.806326: Epoch 141 
2025-01-09 02:58:38.811875: Current learning rate: 0.00474 
2025-01-09 02:59:20.138086: train_loss -0.1047 
2025-01-09 02:59:20.138086: val_loss -0.1389 
2025-01-09 02:59:20.144605: Pseudo dice [np.float32(0.2746)] 
2025-01-09 02:59:20.147622: Epoch time: 41.33 s 
2025-01-09 02:59:20.150648: Yayy! New best EMA pseudo Dice: 0.23759999871253967 
2025-01-09 02:59:20.902238:  
2025-01-09 02:59:20.902238: Epoch 142 
2025-01-09 02:59:20.907927: Current learning rate: 0.0047 
2025-01-09 03:00:02.224085: train_loss -0.087 
2025-01-09 03:00:02.224085: val_loss -0.0658 
2025-01-09 03:00:02.229642: Pseudo dice [np.float32(0.1606)] 
2025-01-09 03:00:02.232681: Epoch time: 41.32 s 
2025-01-09 03:00:02.784464:  
2025-01-09 03:00:02.784969: Epoch 143 
2025-01-09 03:00:02.789840: Current learning rate: 0.00466 
2025-01-09 03:00:44.109974: train_loss -0.0741 
2025-01-09 03:00:44.110976: val_loss -0.127 
2025-01-09 03:00:44.116489: Pseudo dice [np.float32(0.2796)] 
2025-01-09 03:00:44.119997: Epoch time: 41.33 s 
2025-01-09 03:00:44.664812:  
2025-01-09 03:00:44.664812: Epoch 144 
2025-01-09 03:00:44.670872: Current learning rate: 0.00462 
2025-01-09 03:01:26.012360: train_loss -0.0988 
2025-01-09 03:01:26.012863: val_loss -0.0456 
2025-01-09 03:01:26.017945: Pseudo dice [np.float32(0.2433)] 
2025-01-09 03:01:26.021453: Epoch time: 41.35 s 
2025-01-09 03:01:26.627504:  
2025-01-09 03:01:26.628505: Epoch 145 
2025-01-09 03:01:26.634121: Current learning rate: 0.00458 
2025-01-09 03:02:07.948308: train_loss -0.0975 
2025-01-09 03:02:07.948811: val_loss -0.0873 
2025-01-09 03:02:07.954353: Pseudo dice [np.float32(0.235)] 
2025-01-09 03:02:07.957398: Epoch time: 41.32 s 
2025-01-09 03:02:08.512486:  
2025-01-09 03:02:08.512486: Epoch 146 
2025-01-09 03:02:08.518582: Current learning rate: 0.00454 
2025-01-09 03:02:49.836800: train_loss -0.1194 
2025-01-09 03:02:49.837803: val_loss -0.0592 
2025-01-09 03:02:49.843818: Pseudo dice [np.float32(0.1211)] 
2025-01-09 03:02:49.846900: Epoch time: 41.33 s 
2025-01-09 03:02:50.398807:  
2025-01-09 03:02:50.399813: Epoch 147 
2025-01-09 03:02:50.404368: Current learning rate: 0.0045 
2025-01-09 03:03:31.732702: train_loss -0.1129 
2025-01-09 03:03:31.733205: val_loss -0.087 
2025-01-09 03:03:31.738215: Pseudo dice [np.float32(0.2013)] 
2025-01-09 03:03:31.741724: Epoch time: 41.33 s 
2025-01-09 03:03:32.437185:  
2025-01-09 03:03:32.438188: Epoch 148 
2025-01-09 03:03:32.443209: Current learning rate: 0.00446 
2025-01-09 03:04:13.752567: train_loss -0.1182 
2025-01-09 03:04:13.752567: val_loss -0.0543 
2025-01-09 03:04:13.760082: Pseudo dice [np.float32(0.1821)] 
2025-01-09 03:04:13.762589: Epoch time: 41.32 s 
2025-01-09 03:04:14.314674:  
2025-01-09 03:04:14.314674: Epoch 149 
2025-01-09 03:04:14.319685: Current learning rate: 0.00442 
2025-01-09 03:04:55.620293: train_loss -0.0996 
2025-01-09 03:04:55.620293: val_loss -0.1228 
2025-01-09 03:04:55.626811: Pseudo dice [np.float32(0.324)] 
2025-01-09 03:04:55.629321: Epoch time: 41.31 s 
2025-01-09 03:04:56.377400:  
2025-01-09 03:04:56.377400: Epoch 150 
2025-01-09 03:04:56.382535: Current learning rate: 0.00438 
2025-01-09 03:05:37.720164: train_loss -0.0999 
2025-01-09 03:05:37.720164: val_loss -0.1711 
2025-01-09 03:05:37.726322: Pseudo dice [np.float32(0.4063)] 
2025-01-09 03:05:37.728827: Epoch time: 41.34 s 
2025-01-09 03:05:37.732343: Yayy! New best EMA pseudo Dice: 0.24629999697208405 
2025-01-09 03:05:38.532080:  
2025-01-09 03:05:38.532080: Epoch 151 
2025-01-09 03:05:38.537171: Current learning rate: 0.00434 
2025-01-09 03:06:19.872059: train_loss -0.0853 
2025-01-09 03:06:19.873063: val_loss -0.0714 
2025-01-09 03:06:19.879082: Pseudo dice [np.float32(0.2307)] 
2025-01-09 03:06:19.882092: Epoch time: 41.34 s 
2025-01-09 03:06:20.438542:  
2025-01-09 03:06:20.438542: Epoch 152 
2025-01-09 03:06:20.444102: Current learning rate: 0.0043 
2025-01-09 03:07:01.790140: train_loss -0.136 
2025-01-09 03:07:01.790140: val_loss -0.0889 
2025-01-09 03:07:01.797662: Pseudo dice [np.float32(0.2576)] 
2025-01-09 03:07:01.800169: Epoch time: 41.35 s 
2025-01-09 03:07:02.365843:  
2025-01-09 03:07:02.365843: Epoch 153 
2025-01-09 03:07:02.370854: Current learning rate: 0.00427 
2025-01-09 03:07:43.733174: train_loss -0.1008 
2025-01-09 03:07:43.733174: val_loss -0.096 
2025-01-09 03:07:43.739191: Pseudo dice [np.float32(0.193)] 
2025-01-09 03:07:43.743198: Epoch time: 41.37 s 
2025-01-09 03:07:44.312574:  
2025-01-09 03:07:44.313576: Epoch 154 
2025-01-09 03:07:44.318630: Current learning rate: 0.00423 
2025-01-09 03:08:25.652812: train_loss -0.1014 
2025-01-09 03:08:25.653316: val_loss -0.0924 
2025-01-09 03:08:25.659330: Pseudo dice [np.float32(0.315)] 
2025-01-09 03:08:25.662837: Epoch time: 41.34 s 
2025-01-09 03:08:25.665899: Yayy! New best EMA pseudo Dice: 0.24819999933242798 
2025-01-09 03:08:26.531064:  
2025-01-09 03:08:26.532069: Epoch 155 
2025-01-09 03:08:26.536665: Current learning rate: 0.00419 
2025-01-09 03:09:07.889374: train_loss -0.0918 
2025-01-09 03:09:07.889876: val_loss -0.1666 
2025-01-09 03:09:07.895400: Pseudo dice [np.float32(0.3501)] 
2025-01-09 03:09:07.899441: Epoch time: 41.36 s 
2025-01-09 03:09:07.903453: Yayy! New best EMA pseudo Dice: 0.2583000063896179 
2025-01-09 03:09:08.903357:  
2025-01-09 03:09:08.903357: Epoch 156 
2025-01-09 03:09:08.908377: Current learning rate: 0.00415 
2025-01-09 03:09:50.239901: train_loss -0.1376 
2025-01-09 03:09:50.239901: val_loss -0.1127 
2025-01-09 03:09:50.245920: Pseudo dice [np.float32(0.2896)] 
2025-01-09 03:09:50.249267: Epoch time: 41.34 s 
2025-01-09 03:09:50.251771: Yayy! New best EMA pseudo Dice: 0.2615000009536743 
2025-01-09 03:09:51.011914:  
2025-01-09 03:09:51.011914: Epoch 157 
2025-01-09 03:09:51.016936: Current learning rate: 0.00411 
2025-01-09 03:10:32.340495: train_loss -0.1283 
2025-01-09 03:10:32.340495: val_loss -0.0756 
2025-01-09 03:10:32.346522: Pseudo dice [np.float32(0.2684)] 
2025-01-09 03:10:32.349705: Epoch time: 41.33 s 
2025-01-09 03:10:32.353230: Yayy! New best EMA pseudo Dice: 0.2621999979019165 
2025-01-09 03:10:33.135680:  
2025-01-09 03:10:33.136184: Epoch 158 
2025-01-09 03:10:33.141204: Current learning rate: 0.00407 
2025-01-09 03:11:14.431883: train_loss -0.0914 
2025-01-09 03:11:14.431883: val_loss -0.0578 
2025-01-09 03:11:14.438401: Pseudo dice [np.float32(0.1579)] 
2025-01-09 03:11:14.442910: Epoch time: 41.3 s 
2025-01-09 03:11:15.000646:  
2025-01-09 03:11:15.000646: Epoch 159 
2025-01-09 03:11:15.006164: Current learning rate: 0.00403 
2025-01-09 03:11:56.343772: train_loss -0.109 
2025-01-09 03:11:56.343772: val_loss -0.0765 
2025-01-09 03:11:56.349838: Pseudo dice [np.float32(0.1867)] 
2025-01-09 03:11:56.352941: Epoch time: 41.34 s 
2025-01-09 03:11:56.938770:  
2025-01-09 03:11:56.938770: Epoch 160 
2025-01-09 03:11:56.943780: Current learning rate: 0.00399 
2025-01-09 03:12:38.312320: train_loss -0.0828 
2025-01-09 03:12:38.312823: val_loss -0.133 
2025-01-09 03:12:38.318835: Pseudo dice [np.float32(0.3131)] 
2025-01-09 03:12:38.322340: Epoch time: 41.37 s 
2025-01-09 03:12:38.887583:  
2025-01-09 03:12:38.887583: Epoch 161 
2025-01-09 03:12:38.892617: Current learning rate: 0.00395 
2025-01-09 03:13:20.223857: train_loss -0.1002 
2025-01-09 03:13:20.224857: val_loss -0.0781 
2025-01-09 03:13:20.230416: Pseudo dice [np.float32(0.1764)] 
2025-01-09 03:13:20.232923: Epoch time: 41.34 s 
2025-01-09 03:13:20.803561:  
2025-01-09 03:13:20.804567: Epoch 162 
2025-01-09 03:13:20.809112: Current learning rate: 0.00391 
2025-01-09 03:14:02.147960: train_loss -0.1493 
2025-01-09 03:14:02.147960: val_loss -0.1549 
2025-01-09 03:14:02.155480: Pseudo dice [np.float32(0.3142)] 
2025-01-09 03:14:02.159488: Epoch time: 41.34 s 
2025-01-09 03:14:02.729711:  
2025-01-09 03:14:02.729711: Epoch 163 
2025-01-09 03:14:02.733726: Current learning rate: 0.00387 
2025-01-09 03:14:44.081461: train_loss -0.1049 
2025-01-09 03:14:44.082464: val_loss -0.0831 
2025-01-09 03:14:44.088036: Pseudo dice [np.float32(0.147)] 
2025-01-09 03:14:44.091588: Epoch time: 41.35 s 
2025-01-09 03:14:44.803762:  
2025-01-09 03:14:44.803762: Epoch 164 
2025-01-09 03:14:44.809775: Current learning rate: 0.00383 
2025-01-09 03:15:26.149092: train_loss -0.0958 
2025-01-09 03:15:26.149594: val_loss -0.0916 
2025-01-09 03:15:26.154608: Pseudo dice [np.float32(0.2013)] 
2025-01-09 03:15:26.158669: Epoch time: 41.35 s 
2025-01-09 03:15:26.703725:  
2025-01-09 03:15:26.703725: Epoch 165 
2025-01-09 03:15:26.709773: Current learning rate: 0.00379 
2025-01-09 03:16:08.040933: train_loss -0.1121 
2025-01-09 03:16:08.041939: val_loss -0.1145 
2025-01-09 03:16:08.047948: Pseudo dice [np.float32(0.3142)] 
2025-01-09 03:16:08.050956: Epoch time: 41.34 s 
2025-01-09 03:16:08.595371:  
2025-01-09 03:16:08.595371: Epoch 166 
2025-01-09 03:16:08.601413: Current learning rate: 0.00375 
2025-01-09 03:16:49.946863: train_loss -0.1163 
2025-01-09 03:16:49.948384: val_loss -0.0763 
2025-01-09 03:16:49.954001: Pseudo dice [np.float32(0.2409)] 
2025-01-09 03:16:49.957044: Epoch time: 41.35 s 
2025-01-09 03:16:50.506737:  
2025-01-09 03:16:50.506737: Epoch 167 
2025-01-09 03:16:50.512254: Current learning rate: 0.00371 
2025-01-09 03:17:31.869550: train_loss -0.1437 
2025-01-09 03:17:31.870053: val_loss -0.1503 
2025-01-09 03:17:31.876071: Pseudo dice [np.float32(0.2933)] 
2025-01-09 03:17:31.879584: Epoch time: 41.36 s 
2025-01-09 03:17:32.444378:  
2025-01-09 03:17:32.444378: Epoch 168 
2025-01-09 03:17:32.448960: Current learning rate: 0.00367 
2025-01-09 03:18:13.749102: train_loss -0.1113 
2025-01-09 03:18:13.749102: val_loss -0.0912 
2025-01-09 03:18:13.755118: Pseudo dice [np.float32(0.2149)] 
2025-01-09 03:18:13.757625: Epoch time: 41.31 s 
2025-01-09 03:18:14.319173:  
2025-01-09 03:18:14.320171: Epoch 169 
2025-01-09 03:18:14.325182: Current learning rate: 0.00363 
2025-01-09 03:18:55.689660: train_loss -0.1153 
2025-01-09 03:18:55.689660: val_loss -0.0817 
2025-01-09 03:18:55.694730: Pseudo dice [np.float32(0.157)] 
2025-01-09 03:18:55.698773: Epoch time: 41.37 s 
2025-01-09 03:18:56.269018:  
2025-01-09 03:18:56.269018: Epoch 170 
2025-01-09 03:18:56.274031: Current learning rate: 0.00359 
2025-01-09 03:19:37.621113: train_loss -0.0861 
2025-01-09 03:19:37.622113: val_loss -0.0691 
2025-01-09 03:19:37.627630: Pseudo dice [np.float32(0.1977)] 
2025-01-09 03:19:37.630136: Epoch time: 41.35 s 
2025-01-09 03:19:38.196887:  
2025-01-09 03:19:38.197888: Epoch 171 
2025-01-09 03:19:38.202955: Current learning rate: 0.00355 
2025-01-09 03:20:19.529599: train_loss -0.1023 
2025-01-09 03:20:19.530114: val_loss -0.1612 
2025-01-09 03:20:19.534730: Pseudo dice [np.float32(0.3882)] 
2025-01-09 03:20:19.538261: Epoch time: 41.33 s 
2025-01-09 03:20:20.250488:  
2025-01-09 03:20:20.251487: Epoch 172 
2025-01-09 03:20:20.256546: Current learning rate: 0.00351 
2025-01-09 03:21:01.602791: train_loss -0.1267 
2025-01-09 03:21:01.602791: val_loss -0.0754 
2025-01-09 03:21:01.610309: Pseudo dice [np.float32(0.2277)] 
2025-01-09 03:21:01.615326: Epoch time: 41.35 s 
2025-01-09 03:21:02.185520:  
2025-01-09 03:21:02.185520: Epoch 173 
2025-01-09 03:21:02.191538: Current learning rate: 0.00346 
2025-01-09 03:21:43.519679: train_loss -0.1479 
2025-01-09 03:21:43.520182: val_loss -0.0899 
2025-01-09 03:21:43.525718: Pseudo dice [np.float32(0.296)] 
2025-01-09 03:21:43.528797: Epoch time: 41.33 s 
2025-01-09 03:21:44.093524:  
2025-01-09 03:21:44.093524: Epoch 174 
2025-01-09 03:21:44.099100: Current learning rate: 0.00342 
2025-01-09 03:22:25.458026: train_loss -0.1127 
2025-01-09 03:22:25.459027: val_loss -0.0976 
2025-01-09 03:22:25.465060: Pseudo dice [np.float32(0.3213)] 
2025-01-09 03:22:25.467638: Epoch time: 41.37 s 
2025-01-09 03:22:26.049233:  
2025-01-09 03:22:26.049233: Epoch 175 
2025-01-09 03:22:26.054283: Current learning rate: 0.00338 
2025-01-09 03:23:07.437306: train_loss -0.1251 
2025-01-09 03:23:07.437306: val_loss -0.054 
2025-01-09 03:23:07.443844: Pseudo dice [np.float32(0.1669)] 
2025-01-09 03:23:07.446879: Epoch time: 41.39 s 
2025-01-09 03:23:08.010702:  
2025-01-09 03:23:08.011205: Epoch 176 
2025-01-09 03:23:08.015716: Current learning rate: 0.00334 
2025-01-09 03:23:49.342547: train_loss -0.114 
2025-01-09 03:23:49.343051: val_loss -0.1404 
2025-01-09 03:23:49.349070: Pseudo dice [np.float32(0.3073)] 
2025-01-09 03:23:49.351574: Epoch time: 41.33 s 
2025-01-09 03:23:49.920695:  
2025-01-09 03:23:49.921197: Epoch 177 
2025-01-09 03:23:49.926230: Current learning rate: 0.0033 
2025-01-09 03:24:31.280049: train_loss -0.1156 
2025-01-09 03:24:31.281048: val_loss -0.1115 
2025-01-09 03:24:31.286585: Pseudo dice [np.float32(0.405)] 
2025-01-09 03:24:31.290132: Epoch time: 41.36 s 
2025-01-09 03:24:31.292652: Yayy! New best EMA pseudo Dice: 0.2700999975204468 
2025-01-09 03:24:32.049678:  
2025-01-09 03:24:32.049678: Epoch 178 
2025-01-09 03:24:32.056232: Current learning rate: 0.00326 
2025-01-09 03:25:13.386394: train_loss -0.1177 
2025-01-09 03:25:13.387397: val_loss -0.0734 
2025-01-09 03:25:13.391917: Pseudo dice [np.float32(0.2785)] 
2025-01-09 03:25:13.396451: Epoch time: 41.34 s 
2025-01-09 03:25:13.398957: Yayy! New best EMA pseudo Dice: 0.27090001106262207 
2025-01-09 03:25:14.189141:  
2025-01-09 03:25:14.189141: Epoch 179 
2025-01-09 03:25:14.195169: Current learning rate: 0.00322 
2025-01-09 03:25:55.538924: train_loss -0.1497 
2025-01-09 03:25:55.539436: val_loss -0.1399 
2025-01-09 03:25:55.544977: Pseudo dice [np.float32(0.3463)] 
2025-01-09 03:25:55.547485: Epoch time: 41.35 s 
2025-01-09 03:25:55.550017: Yayy! New best EMA pseudo Dice: 0.2784000039100647 
2025-01-09 03:25:56.548623:  
2025-01-09 03:25:56.548623: Epoch 180 
2025-01-09 03:25:56.554161: Current learning rate: 0.00318 
2025-01-09 03:26:37.880164: train_loss -0.1196 
2025-01-09 03:26:37.881169: val_loss -0.1999 
2025-01-09 03:26:37.886178: Pseudo dice [np.float32(0.3934)] 
2025-01-09 03:26:37.890187: Epoch time: 41.33 s 
2025-01-09 03:26:37.892718: Yayy! New best EMA pseudo Dice: 0.289900004863739 
2025-01-09 03:26:38.714418:  
2025-01-09 03:26:38.714418: Epoch 181 
2025-01-09 03:26:38.721022: Current learning rate: 0.00314 
2025-01-09 03:27:20.021109: train_loss -0.1396 
2025-01-09 03:27:20.021622: val_loss -0.1268 
2025-01-09 03:27:20.026694: Pseudo dice [np.float32(0.3447)] 
2025-01-09 03:27:20.030297: Epoch time: 41.31 s 
2025-01-09 03:27:20.032826: Yayy! New best EMA pseudo Dice: 0.2953999936580658 
2025-01-09 03:27:20.822069:  
2025-01-09 03:27:20.823069: Epoch 182 
2025-01-09 03:27:20.828112: Current learning rate: 0.0031 
2025-01-09 03:28:02.153756: train_loss -0.1333 
2025-01-09 03:28:02.154757: val_loss -0.1019 
2025-01-09 03:28:02.160275: Pseudo dice [np.float32(0.2551)] 
2025-01-09 03:28:02.163782: Epoch time: 41.33 s 
2025-01-09 03:28:02.734839:  
2025-01-09 03:28:02.734839: Epoch 183 
2025-01-09 03:28:02.741358: Current learning rate: 0.00306 
2025-01-09 03:28:44.088579: train_loss -0.112 
2025-01-09 03:28:44.089578: val_loss -0.1424 
2025-01-09 03:28:44.095091: Pseudo dice [np.float32(0.3416)] 
2025-01-09 03:28:44.097597: Epoch time: 41.35 s 
2025-01-09 03:28:44.101108: Yayy! New best EMA pseudo Dice: 0.2964000105857849 
2025-01-09 03:28:44.880333:  
2025-01-09 03:28:44.880333: Epoch 184 
2025-01-09 03:28:44.887456: Current learning rate: 0.00302 
2025-01-09 03:29:26.213354: train_loss -0.1361 
2025-01-09 03:29:26.214358: val_loss -0.1217 
2025-01-09 03:29:26.219375: Pseudo dice [np.float32(0.3872)] 
2025-01-09 03:29:26.222933: Epoch time: 41.33 s 
2025-01-09 03:29:26.225515: Yayy! New best EMA pseudo Dice: 0.30550000071525574 
2025-01-09 03:29:27.056872:  
2025-01-09 03:29:27.056872: Epoch 185 
2025-01-09 03:29:27.061885: Current learning rate: 0.00297 
2025-01-09 03:30:08.391695: train_loss -0.1195 
2025-01-09 03:30:08.392217: val_loss -0.1115 
2025-01-09 03:30:08.397228: Pseudo dice [np.float32(0.3433)] 
2025-01-09 03:30:08.400736: Epoch time: 41.34 s 
2025-01-09 03:30:08.403244: Yayy! New best EMA pseudo Dice: 0.3093000054359436 
2025-01-09 03:30:09.163108:  
2025-01-09 03:30:09.163108: Epoch 186 
2025-01-09 03:30:09.169144: Current learning rate: 0.00293 
2025-01-09 03:30:50.498933: train_loss -0.1174 
2025-01-09 03:30:50.499456: val_loss -0.0914 
2025-01-09 03:30:50.505148: Pseudo dice [np.float32(0.3174)] 
2025-01-09 03:30:50.508367: Epoch time: 41.34 s 
2025-01-09 03:30:50.510914: Yayy! New best EMA pseudo Dice: 0.3100999891757965 
2025-01-09 03:30:51.291523:  
2025-01-09 03:30:51.292525: Epoch 187 
2025-01-09 03:30:51.298162: Current learning rate: 0.00289 
2025-01-09 03:31:32.658820: train_loss -0.1226 
2025-01-09 03:31:32.659820: val_loss -0.1738 
2025-01-09 03:31:32.665336: Pseudo dice [np.float32(0.3729)] 
2025-01-09 03:31:32.667842: Epoch time: 41.37 s 
2025-01-09 03:31:32.671351: Yayy! New best EMA pseudo Dice: 0.3163999915122986 
2025-01-09 03:31:33.627699:  
2025-01-09 03:31:33.628203: Epoch 188 
2025-01-09 03:31:33.633214: Current learning rate: 0.00285 
2025-01-09 03:32:14.957326: train_loss -0.1387 
2025-01-09 03:32:14.957326: val_loss -0.1904 
2025-01-09 03:32:14.963340: Pseudo dice [np.float32(0.375)] 
2025-01-09 03:32:14.965845: Epoch time: 41.33 s 
2025-01-09 03:32:14.969350: Yayy! New best EMA pseudo Dice: 0.3222000002861023 
2025-01-09 03:32:15.750059:  
2025-01-09 03:32:15.750565: Epoch 189 
2025-01-09 03:32:15.755577: Current learning rate: 0.00281 
2025-01-09 03:32:57.072855: train_loss -0.1208 
2025-01-09 03:32:57.073858: val_loss -0.1764 
2025-01-09 03:32:57.078872: Pseudo dice [np.float32(0.4756)] 
2025-01-09 03:32:57.082380: Epoch time: 41.32 s 
2025-01-09 03:32:57.085388: Yayy! New best EMA pseudo Dice: 0.3375999927520752 
2025-01-09 03:32:57.893348:  
2025-01-09 03:32:57.893348: Epoch 190 
2025-01-09 03:32:57.898360: Current learning rate: 0.00277 
2025-01-09 03:33:39.252775: train_loss -0.1156 
2025-01-09 03:33:39.252775: val_loss -0.1077 
2025-01-09 03:33:39.258794: Pseudo dice [np.float32(0.248)] 
2025-01-09 03:33:39.261303: Epoch time: 41.36 s 
2025-01-09 03:33:39.832122:  
2025-01-09 03:33:39.832122: Epoch 191 
2025-01-09 03:33:39.837178: Current learning rate: 0.00273 
2025-01-09 03:34:21.162586: train_loss -0.1394 
2025-01-09 03:34:21.163586: val_loss -0.1496 
2025-01-09 03:34:21.169099: Pseudo dice [np.float32(0.35)] 
2025-01-09 03:34:21.172607: Epoch time: 41.33 s 
2025-01-09 03:34:21.747208:  
2025-01-09 03:34:21.747208: Epoch 192 
2025-01-09 03:34:21.753225: Current learning rate: 0.00268 
2025-01-09 03:35:03.098720: train_loss -0.1383 
2025-01-09 03:35:03.099730: val_loss -0.1026 
2025-01-09 03:35:03.104832: Pseudo dice [np.float32(0.2473)] 
2025-01-09 03:35:03.107404: Epoch time: 41.35 s 
2025-01-09 03:35:03.681751:  
2025-01-09 03:35:03.681751: Epoch 193 
2025-01-09 03:35:03.688370: Current learning rate: 0.00264 
2025-01-09 03:35:45.018479: train_loss -0.1347 
2025-01-09 03:35:45.019981: val_loss -0.1334 
2025-01-09 03:35:45.024997: Pseudo dice [np.float32(0.2889)] 
2025-01-09 03:35:45.028507: Epoch time: 41.34 s 
2025-01-09 03:35:45.590066:  
2025-01-09 03:35:45.591069: Epoch 194 
2025-01-09 03:35:45.595615: Current learning rate: 0.0026 
2025-01-09 03:36:26.933506: train_loss -0.1608 
2025-01-09 03:36:26.934008: val_loss -0.1832 
2025-01-09 03:36:26.940021: Pseudo dice [np.float32(0.4101)] 
2025-01-09 03:36:26.942528: Epoch time: 41.34 s 
2025-01-09 03:36:27.512410:  
2025-01-09 03:36:27.512925: Epoch 195 
2025-01-09 03:36:27.517939: Current learning rate: 0.00256 
2025-01-09 03:37:08.878749: train_loss -0.1658 
2025-01-09 03:37:08.878749: val_loss -0.1496 
2025-01-09 03:37:08.886264: Pseudo dice [np.float32(0.4215)] 
2025-01-09 03:37:08.889777: Epoch time: 41.37 s 
2025-01-09 03:37:09.602711:  
2025-01-09 03:37:09.602711: Epoch 196 
2025-01-09 03:37:09.608370: Current learning rate: 0.00252 
2025-01-09 03:37:50.933085: train_loss -0.1473 
2025-01-09 03:37:50.933085: val_loss -0.1107 
2025-01-09 03:37:50.938674: Pseudo dice [np.float32(0.2679)] 
2025-01-09 03:37:50.941716: Epoch time: 41.33 s 
2025-01-09 03:37:51.495524:  
2025-01-09 03:37:51.495524: Epoch 197 
2025-01-09 03:37:51.501061: Current learning rate: 0.00248 
2025-01-09 03:38:32.829283: train_loss -0.1493 
2025-01-09 03:38:32.829787: val_loss -0.1253 
2025-01-09 03:38:32.834798: Pseudo dice [np.float32(0.4024)] 
2025-01-09 03:38:32.838305: Epoch time: 41.33 s 
2025-01-09 03:38:32.840811: Yayy! New best EMA pseudo Dice: 0.3377000093460083 
2025-01-09 03:38:33.683903:  
2025-01-09 03:38:33.684407: Epoch 198 
2025-01-09 03:38:33.689418: Current learning rate: 0.00243 
2025-01-09 03:39:15.003337: train_loss -0.1456 
2025-01-09 03:39:15.003855: val_loss -0.1255 
2025-01-09 03:39:15.009488: Pseudo dice [np.float32(0.5294)] 
2025-01-09 03:39:15.012503: Epoch time: 41.32 s 
2025-01-09 03:39:15.015608: Yayy! New best EMA pseudo Dice: 0.35690000653266907 
2025-01-09 03:39:15.836310:  
2025-01-09 03:39:15.837313: Epoch 199 
2025-01-09 03:39:15.842426: Current learning rate: 0.00239 
2025-01-09 03:39:57.173277: train_loss -0.1381 
2025-01-09 03:39:57.173277: val_loss -0.0791 
2025-01-09 03:39:57.178346: Pseudo dice [np.float32(0.2081)] 
2025-01-09 03:39:57.181467: Epoch time: 41.34 s 
2025-01-09 03:39:57.934107:  
2025-01-09 03:39:57.935112: Epoch 200 
2025-01-09 03:39:57.939707: Current learning rate: 0.00235 
2025-01-09 03:40:39.273372: train_loss -0.1249 
2025-01-09 03:40:39.274378: val_loss -0.1742 
2025-01-09 03:40:39.280388: Pseudo dice [np.float32(0.4479)] 
2025-01-09 03:40:39.283399: Epoch time: 41.34 s 
2025-01-09 03:40:39.846366:  
2025-01-09 03:40:39.846366: Epoch 201 
2025-01-09 03:40:39.851919: Current learning rate: 0.00231 
2025-01-09 03:41:21.187077: train_loss -0.1498 
2025-01-09 03:41:21.188618: val_loss -0.1149 
2025-01-09 03:41:21.193709: Pseudo dice [np.float32(0.2902)] 
2025-01-09 03:41:21.196718: Epoch time: 41.34 s 
2025-01-09 03:41:21.769199:  
2025-01-09 03:41:21.769199: Epoch 202 
2025-01-09 03:41:21.774209: Current learning rate: 0.00226 
2025-01-09 03:42:03.123434: train_loss -0.1822 
2025-01-09 03:42:03.123990: val_loss -0.1841 
2025-01-09 03:42:03.129749: Pseudo dice [np.float32(0.4083)] 
2025-01-09 03:42:03.132288: Epoch time: 41.35 s 
2025-01-09 03:42:03.706642:  
2025-01-09 03:42:03.706642: Epoch 203 
2025-01-09 03:42:03.712203: Current learning rate: 0.00222 
2025-01-09 03:42:45.047846: train_loss -0.1252 
2025-01-09 03:42:45.048848: val_loss -0.1679 
2025-01-09 03:42:45.054367: Pseudo dice [np.float32(0.3271)] 
2025-01-09 03:42:45.057408: Epoch time: 41.34 s 
2025-01-09 03:42:45.773230:  
2025-01-09 03:42:45.773230: Epoch 204 
2025-01-09 03:42:45.778296: Current learning rate: 0.00218 
2025-01-09 03:43:27.107723: train_loss -0.1737 
2025-01-09 03:43:27.107723: val_loss -0.226 
2025-01-09 03:43:27.112747: Pseudo dice [np.float32(0.463)] 
2025-01-09 03:43:27.118402: Epoch time: 41.33 s 
2025-01-09 03:43:27.120912: Yayy! New best EMA pseudo Dice: 0.361299991607666 
2025-01-09 03:43:28.010083:  
2025-01-09 03:43:28.010083: Epoch 205 
2025-01-09 03:43:28.015113: Current learning rate: 0.00214 
2025-01-09 03:44:09.341940: train_loss -0.1496 
2025-01-09 03:44:09.342946: val_loss -0.1176 
2025-01-09 03:44:09.348531: Pseudo dice [np.float32(0.2525)] 
2025-01-09 03:44:09.352151: Epoch time: 41.33 s 
2025-01-09 03:44:09.887329:  
2025-01-09 03:44:09.887329: Epoch 206 
2025-01-09 03:44:09.893427: Current learning rate: 0.00209 
2025-01-09 03:44:51.202788: train_loss -0.1367 
2025-01-09 03:44:51.202788: val_loss -0.176 
2025-01-09 03:44:51.207845: Pseudo dice [np.float32(0.3694)] 
2025-01-09 03:44:51.211353: Epoch time: 41.32 s 
2025-01-09 03:44:51.738859:  
2025-01-09 03:44:51.739856: Epoch 207 
2025-01-09 03:44:51.744894: Current learning rate: 0.00205 
2025-01-09 03:45:33.071769: train_loss -0.1489 
2025-01-09 03:45:33.071769: val_loss -0.1006 
2025-01-09 03:45:33.078284: Pseudo dice [np.float32(0.3594)] 
2025-01-09 03:45:33.080790: Epoch time: 41.33 s 
2025-01-09 03:45:33.611991:  
2025-01-09 03:45:33.612494: Epoch 208 
2025-01-09 03:45:33.617506: Current learning rate: 0.00201 
2025-01-09 03:46:14.950783: train_loss -0.1677 
2025-01-09 03:46:14.951799: val_loss -0.1087 
2025-01-09 03:46:14.956842: Pseudo dice [np.float32(0.3358)] 
2025-01-09 03:46:14.959884: Epoch time: 41.34 s 
2025-01-09 03:46:15.503287:  
2025-01-09 03:46:15.503287: Epoch 209 
2025-01-09 03:46:15.508297: Current learning rate: 0.00196 
2025-01-09 03:46:56.859334: train_loss -0.1717 
2025-01-09 03:46:56.860334: val_loss -0.2005 
2025-01-09 03:46:56.865404: Pseudo dice [np.float32(0.4054)] 
2025-01-09 03:46:56.868913: Epoch time: 41.36 s 
2025-01-09 03:46:57.418783:  
2025-01-09 03:46:57.418783: Epoch 210 
2025-01-09 03:46:57.423794: Current learning rate: 0.00192 
2025-01-09 03:47:38.820685: train_loss -0.149 
2025-01-09 03:47:38.820685: val_loss -0.112 
2025-01-09 03:47:38.825694: Pseudo dice [np.float32(0.2412)] 
2025-01-09 03:47:38.829703: Epoch time: 41.4 s 
2025-01-09 03:47:39.389371:  
2025-01-09 03:47:39.394457: Epoch 211 
2025-01-09 03:47:39.397492: Current learning rate: 0.00188 
2025-01-09 03:48:20.800753: train_loss -0.1517 
2025-01-09 03:48:20.805783: val_loss -0.2072 
2025-01-09 03:48:20.808295: Pseudo dice [np.float32(0.4504)] 
2025-01-09 03:48:20.812344: Epoch time: 41.41 s 
2025-01-09 03:48:21.523654:  
2025-01-09 03:48:21.524651: Epoch 212 
2025-01-09 03:48:21.527714: Current learning rate: 0.00184 
2025-01-09 03:49:02.855308: train_loss -0.1559 
2025-01-09 03:49:02.855308: val_loss -0.1018 
2025-01-09 03:49:02.861324: Pseudo dice [np.float32(0.4843)] 
2025-01-09 03:49:02.864831: Epoch time: 41.33 s 
2025-01-09 03:49:02.867840: Yayy! New best EMA pseudo Dice: 0.3686000108718872 
2025-01-09 03:49:03.603614:  
2025-01-09 03:49:03.603614: Epoch 213 
2025-01-09 03:49:03.609184: Current learning rate: 0.00179 
2025-01-09 03:49:44.944319: train_loss -0.1671 
2025-01-09 03:49:44.944822: val_loss -0.1636 
2025-01-09 03:49:44.949504: Pseudo dice [np.float32(0.3255)] 
2025-01-09 03:49:44.952621: Epoch time: 41.34 s 
2025-01-09 03:49:45.482546:  
2025-01-09 03:49:45.484049: Epoch 214 
2025-01-09 03:49:45.489059: Current learning rate: 0.00175 
2025-01-09 03:50:26.817330: train_loss -0.1686 
2025-01-09 03:50:26.818842: val_loss -0.151 
2025-01-09 03:50:26.824407: Pseudo dice [np.float32(0.4348)] 
2025-01-09 03:50:26.828467: Epoch time: 41.33 s 
2025-01-09 03:50:26.831501: Yayy! New best EMA pseudo Dice: 0.37130001187324524 
2025-01-09 03:50:27.706584:  
2025-01-09 03:50:27.707588: Epoch 215 
2025-01-09 03:50:27.713732: Current learning rate: 0.0017 
2025-01-09 03:51:09.044610: train_loss -0.1647 
2025-01-09 03:51:09.045182: val_loss -0.1163 
2025-01-09 03:51:09.052698: Pseudo dice [np.float32(0.2577)] 
2025-01-09 03:51:09.056208: Epoch time: 41.34 s 
2025-01-09 03:51:09.587558:  
2025-01-09 03:51:09.588557: Epoch 216 
2025-01-09 03:51:09.594074: Current learning rate: 0.00166 
2025-01-09 03:51:50.940623: train_loss -0.1466 
2025-01-09 03:51:50.940623: val_loss -0.1593 
2025-01-09 03:51:50.946642: Pseudo dice [np.float32(0.4887)] 
2025-01-09 03:51:50.949652: Epoch time: 41.35 s 
2025-01-09 03:51:50.952156: Yayy! New best EMA pseudo Dice: 0.37279999256134033 
2025-01-09 03:51:51.703198:  
2025-01-09 03:51:51.703198: Epoch 217 
2025-01-09 03:51:51.708741: Current learning rate: 0.00162 
2025-01-09 03:52:33.046640: train_loss -0.1789 
2025-01-09 03:52:33.047640: val_loss -0.1466 
2025-01-09 03:52:33.053164: Pseudo dice [np.float32(0.392)] 
2025-01-09 03:52:33.058176: Epoch time: 41.34 s 
2025-01-09 03:52:33.061192: Yayy! New best EMA pseudo Dice: 0.37470000982284546 
2025-01-09 03:52:33.795995:  
2025-01-09 03:52:33.795995: Epoch 218 
2025-01-09 03:52:33.801008: Current learning rate: 0.00157 
2025-01-09 03:53:15.154943: train_loss -0.1473 
2025-01-09 03:53:15.155942: val_loss -0.1222 
2025-01-09 03:53:15.163466: Pseudo dice [np.float32(0.3312)] 
2025-01-09 03:53:15.166479: Epoch time: 41.36 s 
2025-01-09 03:53:15.700803:  
2025-01-09 03:53:15.701806: Epoch 219 
2025-01-09 03:53:15.706449: Current learning rate: 0.00153 
2025-01-09 03:53:57.030320: train_loss -0.1887 
2025-01-09 03:53:57.030320: val_loss -0.1247 
2025-01-09 03:53:57.036840: Pseudo dice [np.float32(0.3194)] 
2025-01-09 03:53:57.039350: Epoch time: 41.33 s 
2025-01-09 03:53:57.576321:  
2025-01-09 03:53:57.577321: Epoch 220 
2025-01-09 03:53:57.581919: Current learning rate: 0.00148 
2025-01-09 03:54:38.979878: train_loss -0.1567 
2025-01-09 03:54:38.979878: val_loss -0.2383 
2025-01-09 03:54:38.984889: Pseudo dice [np.float32(0.4848)] 
2025-01-09 03:54:38.988396: Epoch time: 41.4 s 
2025-01-09 03:54:38.990901: Yayy! New best EMA pseudo Dice: 0.37720000743865967 
2025-01-09 03:54:39.908347:  
2025-01-09 03:54:39.908849: Epoch 221 
2025-01-09 03:54:39.913861: Current learning rate: 0.00144 
2025-01-09 03:55:21.238539: train_loss -0.1782 
2025-01-09 03:55:21.239041: val_loss -0.159 
2025-01-09 03:55:21.245092: Pseudo dice [np.float32(0.4757)] 
2025-01-09 03:55:21.247616: Epoch time: 41.33 s 
2025-01-09 03:55:21.251137: Yayy! New best EMA pseudo Dice: 0.3871000111103058 
2025-01-09 03:55:21.981670:  
2025-01-09 03:55:21.981670: Epoch 222 
2025-01-09 03:55:21.987214: Current learning rate: 0.00139 
2025-01-09 03:56:03.319973: train_loss -0.1637 
2025-01-09 03:56:03.320978: val_loss -0.0772 
2025-01-09 03:56:03.325988: Pseudo dice [np.float32(0.2475)] 
2025-01-09 03:56:03.329496: Epoch time: 41.34 s 
2025-01-09 03:56:03.863882:  
2025-01-09 03:56:03.864385: Epoch 223 
2025-01-09 03:56:03.869395: Current learning rate: 0.00135 
2025-01-09 03:56:45.207410: train_loss -0.1991 
2025-01-09 03:56:45.207410: val_loss -0.2006 
2025-01-09 03:56:45.212428: Pseudo dice [np.float32(0.5098)] 
2025-01-09 03:56:45.215944: Epoch time: 41.34 s 
2025-01-09 03:56:45.744664:  
2025-01-09 03:56:45.744664: Epoch 224 
2025-01-09 03:56:45.749690: Current learning rate: 0.0013 
2025-01-09 03:57:27.056416: train_loss -0.2174 
2025-01-09 03:57:27.056937: val_loss -0.1669 
2025-01-09 03:57:27.064029: Pseudo dice [np.float32(0.4183)] 
2025-01-09 03:57:27.067706: Epoch time: 41.31 s 
2025-01-09 03:57:27.070214: Yayy! New best EMA pseudo Dice: 0.38989999890327454 
2025-01-09 03:57:27.891261:  
2025-01-09 03:57:27.891261: Epoch 225 
2025-01-09 03:57:27.896286: Current learning rate: 0.00126 
2025-01-09 03:58:09.232151: train_loss -0.1903 
2025-01-09 03:58:09.233150: val_loss -0.1241 
2025-01-09 03:58:09.238708: Pseudo dice [np.float32(0.3734)] 
2025-01-09 03:58:09.241749: Epoch time: 41.34 s 
2025-01-09 03:58:09.782719:  
2025-01-09 03:58:09.784222: Epoch 226 
2025-01-09 03:58:09.789236: Current learning rate: 0.00121 
2025-01-09 03:58:51.125680: train_loss -0.186 
2025-01-09 03:58:51.126680: val_loss -0.1129 
2025-01-09 03:58:51.132219: Pseudo dice [np.float32(0.3432)] 
2025-01-09 03:58:51.134724: Epoch time: 41.34 s 
2025-01-09 03:58:51.672460:  
2025-01-09 03:58:51.673460: Epoch 227 
2025-01-09 03:58:51.679037: Current learning rate: 0.00117 
2025-01-09 03:59:33.034909: train_loss -0.1578 
2025-01-09 03:59:33.035410: val_loss -0.0905 
2025-01-09 03:59:33.041491: Pseudo dice [np.float32(0.2307)] 
2025-01-09 03:59:33.046541: Epoch time: 41.36 s 
2025-01-09 03:59:33.585523:  
2025-01-09 03:59:33.585523: Epoch 228 
2025-01-09 03:59:33.590551: Current learning rate: 0.00112 
2025-01-09 04:00:14.931053: train_loss -0.16 
2025-01-09 04:00:14.931556: val_loss -0.1581 
2025-01-09 04:00:14.936565: Pseudo dice [np.float32(0.4141)] 
2025-01-09 04:00:14.939644: Epoch time: 41.35 s 
2025-01-09 04:00:15.478351:  
2025-01-09 04:00:15.479351: Epoch 229 
2025-01-09 04:00:15.484430: Current learning rate: 0.00108 
2025-01-09 04:00:56.839742: train_loss -0.1788 
2025-01-09 04:00:56.840244: val_loss -0.073 
2025-01-09 04:00:56.846264: Pseudo dice [np.float32(0.3106)] 
2025-01-09 04:00:56.849787: Epoch time: 41.36 s 
2025-01-09 04:00:57.542622:  
2025-01-09 04:00:57.543125: Epoch 230 
2025-01-09 04:00:57.548064: Current learning rate: 0.00103 
2025-01-09 04:01:38.884546: train_loss -0.199 
2025-01-09 04:01:38.885049: val_loss -0.1014 
2025-01-09 04:01:38.892715: Pseudo dice [np.float32(0.3314)] 
2025-01-09 04:01:38.897222: Epoch time: 41.34 s 
2025-01-09 04:01:39.443458:  
2025-01-09 04:01:39.443458: Epoch 231 
2025-01-09 04:01:39.449000: Current learning rate: 0.00098 
2025-01-09 04:02:20.766747: train_loss -0.1725 
2025-01-09 04:02:20.766747: val_loss -0.1804 
2025-01-09 04:02:20.772332: Pseudo dice [np.float32(0.4303)] 
2025-01-09 04:02:20.774350: Epoch time: 41.32 s 
2025-01-09 04:02:21.308482:  
2025-01-09 04:02:21.309482: Epoch 232 
2025-01-09 04:02:21.314493: Current learning rate: 0.00094 
2025-01-09 04:03:02.647167: train_loss -0.1679 
2025-01-09 04:03:02.647674: val_loss -0.1017 
2025-01-09 04:03:02.652750: Pseudo dice [np.float32(0.256)] 
2025-01-09 04:03:02.656800: Epoch time: 41.34 s 
2025-01-09 04:03:03.204112:  
2025-01-09 04:03:03.204624: Epoch 233 
2025-01-09 04:03:03.209182: Current learning rate: 0.00089 
2025-01-09 04:03:44.579606: train_loss -0.1469 
2025-01-09 04:03:44.580607: val_loss -0.1251 
2025-01-09 04:03:44.587125: Pseudo dice [np.float32(0.3265)] 
2025-01-09 04:03:44.590642: Epoch time: 41.38 s 
2025-01-09 04:03:45.135972:  
2025-01-09 04:03:45.136477: Epoch 234 
2025-01-09 04:03:45.141490: Current learning rate: 0.00084 
2025-01-09 04:04:26.487071: train_loss -0.1662 
2025-01-09 04:04:26.487573: val_loss -0.1568 
2025-01-09 04:04:26.492584: Pseudo dice [np.float32(0.3876)] 
2025-01-09 04:04:26.495088: Epoch time: 41.35 s 
2025-01-09 04:04:27.037449:  
2025-01-09 04:04:27.037449: Epoch 235 
2025-01-09 04:04:27.042462: Current learning rate: 0.00079 
2025-01-09 04:05:08.395222: train_loss -0.1662 
2025-01-09 04:05:08.395724: val_loss -0.1194 
2025-01-09 04:05:08.401738: Pseudo dice [np.float32(0.3614)] 
2025-01-09 04:05:08.405244: Epoch time: 41.36 s 
2025-01-09 04:05:08.942164:  
2025-01-09 04:05:08.942164: Epoch 236 
2025-01-09 04:05:08.947202: Current learning rate: 0.00075 
2025-01-09 04:05:50.296679: train_loss -0.1961 
2025-01-09 04:05:50.297683: val_loss -0.1451 
2025-01-09 04:05:50.302694: Pseudo dice [np.float32(0.3717)] 
2025-01-09 04:05:50.306200: Epoch time: 41.36 s 
2025-01-09 04:05:50.850372:  
2025-01-09 04:05:50.851374: Epoch 237 
2025-01-09 04:05:50.856475: Current learning rate: 0.0007 
2025-01-09 04:06:32.201659: train_loss -0.2073 
2025-01-09 04:06:32.202659: val_loss -0.1016 
2025-01-09 04:06:32.208172: Pseudo dice [np.float32(0.3054)] 
2025-01-09 04:06:32.211680: Epoch time: 41.35 s 
2025-01-09 04:06:32.913481:  
2025-01-09 04:06:32.913481: Epoch 238 
2025-01-09 04:06:32.918996: Current learning rate: 0.00065 
2025-01-09 04:07:14.231651: train_loss -0.1767 
2025-01-09 04:07:14.232651: val_loss -0.1839 
2025-01-09 04:07:14.238178: Pseudo dice [np.float32(0.4817)] 
2025-01-09 04:07:14.241701: Epoch time: 41.32 s 
2025-01-09 04:07:14.769841:  
2025-01-09 04:07:14.769841: Epoch 239 
2025-01-09 04:07:14.775400: Current learning rate: 0.0006 
2025-01-09 04:07:56.107928: train_loss -0.2 
2025-01-09 04:07:56.108927: val_loss -0.1346 
2025-01-09 04:07:56.115443: Pseudo dice [np.float32(0.4653)] 
2025-01-09 04:07:56.118949: Epoch time: 41.34 s 
2025-01-09 04:07:56.670577:  
2025-01-09 04:07:56.670577: Epoch 240 
2025-01-09 04:07:56.676652: Current learning rate: 0.00055 
2025-01-09 04:08:38.016527: train_loss -0.1881 
2025-01-09 04:08:38.017052: val_loss -0.2029 
2025-01-09 04:08:38.022170: Pseudo dice [np.float32(0.5416)] 
2025-01-09 04:08:38.027186: Epoch time: 41.35 s 
2025-01-09 04:08:38.030695: Yayy! New best EMA pseudo Dice: 0.3935999870300293 
2025-01-09 04:08:38.790998:  
2025-01-09 04:08:38.790998: Epoch 241 
2025-01-09 04:08:38.796048: Current learning rate: 0.0005 
2025-01-09 04:09:20.135906: train_loss -0.2034 
2025-01-09 04:09:20.135906: val_loss -0.1701 
2025-01-09 04:09:20.141927: Pseudo dice [np.float32(0.4345)] 
2025-01-09 04:09:20.144436: Epoch time: 41.35 s 
2025-01-09 04:09:20.146994: Yayy! New best EMA pseudo Dice: 0.3977000117301941 
2025-01-09 04:09:20.945100:  
2025-01-09 04:09:20.945100: Epoch 242 
2025-01-09 04:09:20.950125: Current learning rate: 0.00045 
2025-01-09 04:10:02.318260: train_loss -0.1739 
2025-01-09 04:10:02.318260: val_loss -0.1305 
2025-01-09 04:10:02.323802: Pseudo dice [np.float32(0.3837)] 
2025-01-09 04:10:02.327811: Epoch time: 41.37 s 
2025-01-09 04:10:02.881622:  
2025-01-09 04:10:02.882124: Epoch 243 
2025-01-09 04:10:02.887135: Current learning rate: 0.0004 
2025-01-09 04:10:44.246055: train_loss -0.2086 
2025-01-09 04:10:44.247058: val_loss -0.1965 
2025-01-09 04:10:44.252078: Pseudo dice [np.float32(0.5404)] 
2025-01-09 04:10:44.255622: Epoch time: 41.37 s 
2025-01-09 04:10:44.258182: Yayy! New best EMA pseudo Dice: 0.4106999933719635 
2025-01-09 04:10:45.074968:  
2025-01-09 04:10:45.075969: Epoch 244 
2025-01-09 04:10:45.081080: Current learning rate: 0.00035 
2025-01-09 04:11:26.425624: train_loss -0.17 
2025-01-09 04:11:26.426623: val_loss -0.1283 
2025-01-09 04:11:26.432144: Pseudo dice [np.float32(0.35)] 
2025-01-09 04:11:26.435156: Epoch time: 41.35 s 
2025-01-09 04:11:26.983814:  
2025-01-09 04:11:26.984818: Epoch 245 
2025-01-09 04:11:26.989371: Current learning rate: 0.0003 
2025-01-09 04:12:08.325972: train_loss -0.2211 
2025-01-09 04:12:08.326484: val_loss -0.1704 
2025-01-09 04:12:08.331587: Pseudo dice [np.float32(0.5296)] 
2025-01-09 04:12:08.334783: Epoch time: 41.34 s 
2025-01-09 04:12:08.337833: Yayy! New best EMA pseudo Dice: 0.4171000123023987 
2025-01-09 04:12:09.144726:  
2025-01-09 04:12:09.144726: Epoch 246 
2025-01-09 04:12:09.149736: Current learning rate: 0.00024 
2025-01-09 04:12:50.484583: train_loss -0.1867 
2025-01-09 04:12:50.484583: val_loss -0.1303 
2025-01-09 04:12:50.491199: Pseudo dice [np.float32(0.4178)] 
2025-01-09 04:12:50.494216: Epoch time: 41.34 s 
2025-01-09 04:12:50.497248: Yayy! New best EMA pseudo Dice: 0.4171999990940094 
2025-01-09 04:12:51.479222:  
2025-01-09 04:12:51.479222: Epoch 247 
2025-01-09 04:12:51.484296: Current learning rate: 0.00019 
2025-01-09 04:13:32.828000: train_loss -0.1954 
2025-01-09 04:13:32.829005: val_loss -0.1647 
2025-01-09 04:13:32.834015: Pseudo dice [np.float32(0.573)] 
2025-01-09 04:13:32.838026: Epoch time: 41.35 s 
2025-01-09 04:13:32.840544: Yayy! New best EMA pseudo Dice: 0.4327999949455261 
2025-01-09 04:13:33.611542:  
2025-01-09 04:13:33.611542: Epoch 248 
2025-01-09 04:13:33.617605: Current learning rate: 0.00013 
2025-01-09 04:14:14.951032: train_loss -0.1842 
2025-01-09 04:14:14.951536: val_loss -0.1936 
2025-01-09 04:14:14.957233: Pseudo dice [np.float32(0.4711)] 
2025-01-09 04:14:14.959741: Epoch time: 41.34 s 
2025-01-09 04:14:14.963233: Yayy! New best EMA pseudo Dice: 0.436599999666214 
2025-01-09 04:14:15.770537:  
2025-01-09 04:14:15.770537: Epoch 249 
2025-01-09 04:14:15.775608: Current learning rate: 7e-05 
2025-01-09 04:14:57.117258: train_loss -0.1998 
2025-01-09 04:14:57.117767: val_loss -0.1233 
2025-01-09 04:14:57.124309: Pseudo dice [np.float32(0.3806)] 
2025-01-09 04:14:57.127317: Epoch time: 41.35 s 
2025-01-09 04:14:57.860537: Training done. 
2025-01-09 04:14:57.897045: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-09 04:14:57.909045: The split file contains 5 splits. 
2025-01-09 04:14:57.916046: Desired fold for training: 0 
2025-01-09 04:14:57.920045: This split has 100 training and 26 validation cases. 
2025-01-09 04:14:57.926047: predicting colon_008 
2025-01-09 04:14:57.931045: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-01-09 04:15:13.617257: predicting colon_027 
2025-01-09 04:15:13.633256: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-01-09 04:15:19.640416: predicting colon_030 
2025-01-09 04:15:19.646417: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-01-09 04:15:28.090655: predicting colon_033 
2025-01-09 04:15:28.104749: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-01-09 04:15:43.123983: predicting colon_041 
2025-01-09 04:15:43.142982: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-01-09 04:16:23.545382: predicting colon_042 
2025-01-09 04:16:23.576382: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-01-09 04:16:43.827441: predicting colon_061 
2025-01-09 04:16:43.846947: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-01-09 04:17:07.289265: predicting colon_074 
2025-01-09 04:17:07.310265: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-01-09 04:17:34.294879: predicting colon_075 
2025-01-09 04:17:34.318880: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-01-09 04:17:49.343456: predicting colon_088 
2025-01-09 04:17:49.361964: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-01-09 04:18:12.857466: predicting colon_091 
2025-01-09 04:18:12.882981: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-01-09 04:18:41.050871: predicting colon_092 
2025-01-09 04:18:41.077871: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-01-09 04:19:04.511875: predicting colon_095 
2025-01-09 04:19:04.530875: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-01-09 04:19:19.567833: predicting colon_102 
2025-01-09 04:19:19.584833: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-01-09 04:19:53.319009: predicting colon_111 
2025-01-09 04:19:53.346517: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-01-09 04:20:02.757539: predicting colon_115 
2025-01-09 04:20:02.769539: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-01-09 04:20:17.842467: predicting colon_118 
2025-01-09 04:20:17.860977: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-01-09 04:20:41.344999: predicting colon_124 
2025-01-09 04:20:41.365001: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-01-09 04:21:04.827857: predicting colon_127 
2025-01-09 04:21:04.849857: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-01-09 04:21:52.096705: predicting colon_154 
2025-01-09 04:21:52.133214: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-01-09 04:22:07.205917: predicting colon_161 
2025-01-09 04:22:07.223922: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-01-09 04:22:22.271953: predicting colon_162 
2025-01-09 04:22:22.289953: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-01-09 04:23:02.736687: predicting colon_165 
2025-01-09 04:23:02.764689: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-01-09 04:23:36.565382: predicting colon_166 
2025-01-09 04:23:36.588385: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-01-09 04:23:51.638009: predicting colon_169 
2025-01-09 04:23:51.653009: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-01-09 04:24:38.889639: predicting colon_187 
2025-01-09 04:24:38.926639: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-01-09 04:25:11.883170: Validation complete 
2025-01-09 04:25:11.883170: Mean Validation Dice:  0.3001284442508029 
