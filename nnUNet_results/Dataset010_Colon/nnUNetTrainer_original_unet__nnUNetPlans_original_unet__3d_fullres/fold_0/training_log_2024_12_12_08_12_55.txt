
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-12 08:12:55.096215: do_dummy_2d_data_aug: True 
2024-12-12 08:12:55.101214: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-12 08:12:55.108217: The split file contains 5 splits. 
2024-12-12 08:12:55.111214: Desired fold for training: 0 
2024-12-12 08:12:55.113218: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_original_unet_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 256, 224], 'median_image_size_in_voxels': [90.0, 512.0, 512.0], 'spacing': [5.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans_original_unet', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2024-12-12 08:13:03.317085: unpacking dataset... 
2024-12-12 08:13:09.990880: unpacking done... 
2024-12-12 08:13:13.202638:  
2024-12-12 08:13:13.207168: Epoch 0 
2024-12-12 08:13:13.210737: Current learning rate: 0.01 
2024-12-12 08:13:57.731754: train_loss 0.0203 
2024-12-12 08:13:57.737290: val_loss -0.0363 
2024-12-12 08:13:57.739798: Pseudo dice [np.float32(0.0)] 
2024-12-12 08:13:57.743313: Epoch time: 44.53 s 
2024-12-12 08:13:57.745821: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-12 08:13:58.378022:  
2024-12-12 08:13:58.382075: Epoch 1 
2024-12-12 08:13:58.386154: Current learning rate: 0.00991 
2024-12-12 08:14:38.698843: train_loss -0.1011 
2024-12-12 08:14:38.703856: val_loss -0.1753 
2024-12-12 08:14:38.707362: Pseudo dice [np.float32(0.2448)] 
2024-12-12 08:14:38.710653: Epoch time: 40.32 s 
2024-12-12 08:14:38.713159: Yayy! New best EMA pseudo Dice: 0.02449999935925007 
2024-12-12 08:14:39.425632:  
2024-12-12 08:14:39.431191: Epoch 2 
2024-12-12 08:14:39.433749: Current learning rate: 0.00982 
2024-12-12 08:15:19.753737: train_loss -0.2158 
2024-12-12 08:15:19.759276: val_loss -0.2632 
2024-12-12 08:15:19.762789: Pseudo dice [np.float32(0.2936)] 
2024-12-12 08:15:19.765300: Epoch time: 40.33 s 
2024-12-12 08:15:19.768807: Yayy! New best EMA pseudo Dice: 0.05139999836683273 
2024-12-12 08:15:20.510627:  
2024-12-12 08:15:20.515823: Epoch 3 
2024-12-12 08:15:20.519334: Current learning rate: 0.00973 
2024-12-12 08:16:00.821535: train_loss -0.2618 
2024-12-12 08:16:00.828052: val_loss -0.2002 
2024-12-12 08:16:00.830558: Pseudo dice [np.float32(0.273)] 
2024-12-12 08:16:00.834067: Epoch time: 40.31 s 
2024-12-12 08:16:00.836576: Yayy! New best EMA pseudo Dice: 0.07360000163316727 
2024-12-12 08:16:01.563816:  
2024-12-12 08:16:01.568676: Epoch 4 
2024-12-12 08:16:01.572188: Current learning rate: 0.00964 
2024-12-12 08:16:41.898352: train_loss -0.286 
2024-12-12 08:16:41.903428: val_loss -0.335 
2024-12-12 08:16:41.906464: Pseudo dice [np.float32(0.3839)] 
2024-12-12 08:16:41.909559: Epoch time: 40.34 s 
2024-12-12 08:16:41.912109: Yayy! New best EMA pseudo Dice: 0.10459999740123749 
2024-12-12 08:16:42.783677:  
2024-12-12 08:16:42.788710: Epoch 5 
2024-12-12 08:16:42.791736: Current learning rate: 0.00955 
2024-12-12 08:17:23.085590: train_loss -0.2884 
2024-12-12 08:17:23.092234: val_loss -0.2782 
2024-12-12 08:17:23.095312: Pseudo dice [np.float32(0.3574)] 
2024-12-12 08:17:23.098375: Epoch time: 40.3 s 
2024-12-12 08:17:23.100922: Yayy! New best EMA pseudo Dice: 0.1298999935388565 
2024-12-12 08:17:23.827758:  
2024-12-12 08:17:23.832770: Epoch 6 
2024-12-12 08:17:23.835782: Current learning rate: 0.00946 
2024-12-12 08:18:04.138384: train_loss -0.3151 
2024-12-12 08:18:04.144030: val_loss -0.3351 
2024-12-12 08:18:04.147076: Pseudo dice [np.float32(0.3714)] 
2024-12-12 08:18:04.149613: Epoch time: 40.31 s 
2024-12-12 08:18:04.152148: Yayy! New best EMA pseudo Dice: 0.15399999916553497 
2024-12-12 08:18:04.891274:  
2024-12-12 08:18:04.897288: Epoch 7 
2024-12-12 08:18:04.900299: Current learning rate: 0.00937 
2024-12-12 08:18:45.195482: train_loss -0.3286 
2024-12-12 08:18:45.201009: val_loss -0.2931 
2024-12-12 08:18:45.204051: Pseudo dice [np.float32(0.3717)] 
2024-12-12 08:18:45.207559: Epoch time: 40.3 s 
2024-12-12 08:18:45.210569: Yayy! New best EMA pseudo Dice: 0.17579999566078186 
2024-12-12 08:18:45.964780:  
2024-12-12 08:18:45.969793: Epoch 8 
2024-12-12 08:18:45.973305: Current learning rate: 0.00928 
2024-12-12 08:19:26.269077: train_loss -0.3551 
2024-12-12 08:19:26.274091: val_loss -0.2862 
2024-12-12 08:19:26.277599: Pseudo dice [np.float32(0.3131)] 
2024-12-12 08:19:26.280610: Epoch time: 40.31 s 
2024-12-12 08:19:26.284122: Yayy! New best EMA pseudo Dice: 0.18950000405311584 
2024-12-12 08:19:27.044049:  
2024-12-12 08:19:27.048094: Epoch 9 
2024-12-12 08:19:27.052164: Current learning rate: 0.00919 
2024-12-12 08:20:07.354261: train_loss -0.363 
2024-12-12 08:20:07.359777: val_loss -0.3735 
2024-12-12 08:20:07.363314: Pseudo dice [np.float32(0.4552)] 
2024-12-12 08:20:07.365579: Epoch time: 40.31 s 
2024-12-12 08:20:07.369600: Yayy! New best EMA pseudo Dice: 0.21610000729560852 
2024-12-12 08:20:08.090091:  
2024-12-12 08:20:08.095621: Epoch 10 
2024-12-12 08:20:08.098706: Current learning rate: 0.0091 
2024-12-12 08:20:48.401742: train_loss -0.3489 
2024-12-12 08:20:48.408316: val_loss -0.4176 
2024-12-12 08:20:48.411355: Pseudo dice [np.float32(0.4754)] 
2024-12-12 08:20:48.414458: Epoch time: 40.31 s 
2024-12-12 08:20:48.418003: Yayy! New best EMA pseudo Dice: 0.24199999868869781 
2024-12-12 08:20:49.133966:  
2024-12-12 08:20:49.140479: Epoch 11 
2024-12-12 08:20:49.143988: Current learning rate: 0.009 
2024-12-12 08:21:29.431399: train_loss -0.4114 
2024-12-12 08:21:29.436994: val_loss -0.365 
2024-12-12 08:21:29.440036: Pseudo dice [np.float32(0.3969)] 
2024-12-12 08:21:29.443562: Epoch time: 40.3 s 
2024-12-12 08:21:29.446586: Yayy! New best EMA pseudo Dice: 0.2574999928474426 
2024-12-12 08:21:30.216285:  
2024-12-12 08:21:30.221818: Epoch 12 
2024-12-12 08:21:30.225348: Current learning rate: 0.00891 
2024-12-12 08:22:10.527923: train_loss -0.3762 
2024-12-12 08:22:10.535381: val_loss -0.3411 
2024-12-12 08:22:10.539394: Pseudo dice [np.float32(0.3754)] 
2024-12-12 08:22:10.542904: Epoch time: 40.31 s 
2024-12-12 08:22:10.545412: Yayy! New best EMA pseudo Dice: 0.26930001378059387 
2024-12-12 08:22:11.417462:  
2024-12-12 08:22:11.423003: Epoch 13 
2024-12-12 08:22:11.426536: Current learning rate: 0.00882 
2024-12-12 08:22:51.736425: train_loss -0.3721 
2024-12-12 08:22:51.742437: val_loss -0.4176 
2024-12-12 08:22:51.745447: Pseudo dice [np.float32(0.4507)] 
2024-12-12 08:22:51.748959: Epoch time: 40.32 s 
2024-12-12 08:22:51.751465: Yayy! New best EMA pseudo Dice: 0.2874000072479248 
2024-12-12 08:22:52.469354:  
2024-12-12 08:22:52.474886: Epoch 14 
2024-12-12 08:22:52.478444: Current learning rate: 0.00873 
2024-12-12 08:23:32.753504: train_loss -0.4048 
2024-12-12 08:23:32.759599: val_loss -0.416 
2024-12-12 08:23:32.762159: Pseudo dice [np.float32(0.4805)] 
2024-12-12 08:23:32.764692: Epoch time: 40.29 s 
2024-12-12 08:23:32.769244: Yayy! New best EMA pseudo Dice: 0.3066999912261963 
2024-12-12 08:23:33.509474:  
2024-12-12 08:23:33.515488: Epoch 15 
2024-12-12 08:23:33.518998: Current learning rate: 0.00864 
2024-12-12 08:24:13.795391: train_loss -0.4152 
2024-12-12 08:24:13.803437: val_loss -0.3858 
2024-12-12 08:24:13.807986: Pseudo dice [np.float32(0.4669)] 
2024-12-12 08:24:13.811115: Epoch time: 40.29 s 
2024-12-12 08:24:13.814144: Yayy! New best EMA pseudo Dice: 0.32269999384880066 
2024-12-12 08:24:14.561458:  
2024-12-12 08:24:14.567011: Epoch 16 
2024-12-12 08:24:14.571055: Current learning rate: 0.00855 
2024-12-12 08:24:54.877203: train_loss -0.3734 
2024-12-12 08:24:54.884788: val_loss -0.3457 
2024-12-12 08:24:54.887310: Pseudo dice [np.float32(0.3629)] 
2024-12-12 08:24:54.891427: Epoch time: 40.32 s 
2024-12-12 08:24:54.894041: Yayy! New best EMA pseudo Dice: 0.32679998874664307 
2024-12-12 08:24:55.674912:  
2024-12-12 08:24:55.679923: Epoch 17 
2024-12-12 08:24:55.683439: Current learning rate: 0.00846 
2024-12-12 08:25:35.983335: train_loss -0.3821 
2024-12-12 08:25:35.989884: val_loss -0.4172 
2024-12-12 08:25:35.992431: Pseudo dice [np.float32(0.4643)] 
2024-12-12 08:25:35.995941: Epoch time: 40.31 s 
2024-12-12 08:25:35.999447: Yayy! New best EMA pseudo Dice: 0.34049999713897705 
2024-12-12 08:25:36.742518:  
2024-12-12 08:25:36.748033: Epoch 18 
2024-12-12 08:25:36.751546: Current learning rate: 0.00836 
2024-12-12 08:26:17.065722: train_loss -0.347 
2024-12-12 08:26:17.071737: val_loss -0.429 
2024-12-12 08:26:17.075748: Pseudo dice [np.float32(0.4883)] 
2024-12-12 08:26:17.078255: Epoch time: 40.32 s 
2024-12-12 08:26:17.081765: Yayy! New best EMA pseudo Dice: 0.35530000925064087 
2024-12-12 08:26:17.838938:  
2024-12-12 08:26:17.844031: Epoch 19 
2024-12-12 08:26:17.847603: Current learning rate: 0.00827 
2024-12-12 08:26:58.153755: train_loss -0.3889 
2024-12-12 08:26:58.158808: val_loss -0.3478 
2024-12-12 08:26:58.161866: Pseudo dice [np.float32(0.4086)] 
2024-12-12 08:26:58.164924: Epoch time: 40.32 s 
2024-12-12 08:26:58.167963: Yayy! New best EMA pseudo Dice: 0.36059999465942383 
2024-12-12 08:26:59.053584:  
2024-12-12 08:26:59.059150: Epoch 20 
2024-12-12 08:26:59.062745: Current learning rate: 0.00818 
2024-12-12 08:27:39.352122: train_loss -0.3772 
2024-12-12 08:27:39.358165: val_loss -0.3909 
2024-12-12 08:27:39.361185: Pseudo dice [np.float32(0.4331)] 
2024-12-12 08:27:39.364692: Epoch time: 40.3 s 
2024-12-12 08:27:39.367198: Yayy! New best EMA pseudo Dice: 0.367900013923645 
2024-12-12 08:27:40.126287:  
2024-12-12 08:27:40.130312: Epoch 21 
2024-12-12 08:27:40.134343: Current learning rate: 0.00809 
2024-12-12 08:28:20.435052: train_loss -0.3972 
2024-12-12 08:28:20.443571: val_loss -0.4805 
2024-12-12 08:28:20.447580: Pseudo dice [np.float32(0.5003)] 
2024-12-12 08:28:20.451089: Epoch time: 40.31 s 
2024-12-12 08:28:20.453594: Yayy! New best EMA pseudo Dice: 0.38109999895095825 
2024-12-12 08:28:21.167844:  
2024-12-12 08:28:21.173919: Epoch 22 
2024-12-12 08:28:21.177000: Current learning rate: 0.008 
2024-12-12 08:29:01.487254: train_loss -0.4197 
2024-12-12 08:29:01.492812: val_loss -0.3891 
2024-12-12 08:29:01.495833: Pseudo dice [np.float32(0.438)] 
2024-12-12 08:29:01.498861: Epoch time: 40.32 s 
2024-12-12 08:29:01.502888: Yayy! New best EMA pseudo Dice: 0.38679999113082886 
2024-12-12 08:29:02.252130:  
2024-12-12 08:29:02.258642: Epoch 23 
2024-12-12 08:29:02.262152: Current learning rate: 0.0079 
2024-12-12 08:29:42.541685: train_loss -0.4422 
2024-12-12 08:29:42.548201: val_loss -0.4035 
2024-12-12 08:29:42.552210: Pseudo dice [np.float32(0.4717)] 
2024-12-12 08:29:42.555719: Epoch time: 40.29 s 
2024-12-12 08:29:42.558224: Yayy! New best EMA pseudo Dice: 0.3953000009059906 
2024-12-12 08:29:43.270350:  
2024-12-12 08:29:43.275387: Epoch 24 
2024-12-12 08:29:43.279918: Current learning rate: 0.00781 
2024-12-12 08:30:23.586633: train_loss -0.3913 
2024-12-12 08:30:23.593160: val_loss -0.3711 
2024-12-12 08:30:23.595679: Pseudo dice [np.float32(0.433)] 
2024-12-12 08:30:23.599200: Epoch time: 40.32 s 
2024-12-12 08:30:23.601235: Yayy! New best EMA pseudo Dice: 0.39910000562667847 
2024-12-12 08:30:24.322457:  
2024-12-12 08:30:24.328016: Epoch 25 
2024-12-12 08:30:24.330564: Current learning rate: 0.00772 
2024-12-12 08:31:04.616652: train_loss -0.428 
2024-12-12 08:31:04.622661: val_loss -0.3544 
2024-12-12 08:31:04.625668: Pseudo dice [np.float32(0.428)] 
2024-12-12 08:31:04.628173: Epoch time: 40.29 s 
2024-12-12 08:31:04.631681: Yayy! New best EMA pseudo Dice: 0.4020000100135803 
2024-12-12 08:31:05.350611:  
2024-12-12 08:31:05.356125: Epoch 26 
2024-12-12 08:31:05.359633: Current learning rate: 0.00763 
2024-12-12 08:31:45.669895: train_loss -0.4317 
2024-12-12 08:31:45.674972: val_loss -0.4342 
2024-12-12 08:31:45.678495: Pseudo dice [np.float32(0.482)] 
2024-12-12 08:31:45.681520: Epoch time: 40.32 s 
2024-12-12 08:31:45.684558: Yayy! New best EMA pseudo Dice: 0.4099999964237213 
2024-12-12 08:31:46.417528:  
2024-12-12 08:31:46.423083: Epoch 27 
2024-12-12 08:31:46.425638: Current learning rate: 0.00753 
2024-12-12 08:32:26.713573: train_loss -0.4129 
2024-12-12 08:32:26.719636: val_loss -0.3682 
2024-12-12 08:32:26.722146: Pseudo dice [np.float32(0.3879)] 
2024-12-12 08:32:26.725653: Epoch time: 40.3 s 
2024-12-12 08:32:27.425632:  
2024-12-12 08:32:27.431642: Epoch 28 
2024-12-12 08:32:27.434653: Current learning rate: 0.00744 
2024-12-12 08:33:07.747401: train_loss -0.456 
2024-12-12 08:33:07.753459: val_loss -0.4032 
2024-12-12 08:33:07.756468: Pseudo dice [np.float32(0.4328)] 
2024-12-12 08:33:07.759977: Epoch time: 40.32 s 
2024-12-12 08:33:07.762484: Yayy! New best EMA pseudo Dice: 0.41029998660087585 
2024-12-12 08:33:08.491133:  
2024-12-12 08:33:08.495178: Epoch 29 
2024-12-12 08:33:08.499239: Current learning rate: 0.00735 
2024-12-12 08:33:48.804452: train_loss -0.4648 
2024-12-12 08:33:48.810466: val_loss -0.3694 
2024-12-12 08:33:48.813983: Pseudo dice [np.float32(0.4368)] 
2024-12-12 08:33:48.817053: Epoch time: 40.31 s 
2024-12-12 08:33:48.819561: Yayy! New best EMA pseudo Dice: 0.41290000081062317 
2024-12-12 08:33:49.547916:  
2024-12-12 08:33:49.553989: Epoch 30 
2024-12-12 08:33:49.557054: Current learning rate: 0.00725 
2024-12-12 08:34:29.860664: train_loss -0.421 
2024-12-12 08:34:29.866683: val_loss -0.4827 
2024-12-12 08:34:29.870210: Pseudo dice [np.float32(0.5639)] 
2024-12-12 08:34:29.873269: Epoch time: 40.31 s 
2024-12-12 08:34:29.875798: Yayy! New best EMA pseudo Dice: 0.42800000309944153 
2024-12-12 08:34:30.602740:  
2024-12-12 08:34:30.607928: Epoch 31 
2024-12-12 08:34:30.611440: Current learning rate: 0.00716 
2024-12-12 08:35:10.891359: train_loss -0.418 
2024-12-12 08:35:10.896908: val_loss -0.3209 
2024-12-12 08:35:10.899936: Pseudo dice [np.float32(0.3783)] 
2024-12-12 08:35:10.902951: Epoch time: 40.29 s 
2024-12-12 08:35:11.475358:  
2024-12-12 08:35:11.481420: Epoch 32 
2024-12-12 08:35:11.484482: Current learning rate: 0.00707 
2024-12-12 08:35:51.782934: train_loss -0.4365 
2024-12-12 08:35:51.788547: val_loss -0.4252 
2024-12-12 08:35:51.791562: Pseudo dice [np.float32(0.4837)] 
2024-12-12 08:35:51.794073: Epoch time: 40.31 s 
2024-12-12 08:35:51.797586: Yayy! New best EMA pseudo Dice: 0.42910000681877136 
2024-12-12 08:35:52.542708:  
2024-12-12 08:35:52.548295: Epoch 33 
2024-12-12 08:35:52.551348: Current learning rate: 0.00697 
2024-12-12 08:36:32.850627: train_loss -0.4678 
2024-12-12 08:36:32.856148: val_loss -0.3763 
2024-12-12 08:36:32.858658: Pseudo dice [np.float32(0.4542)] 
2024-12-12 08:36:32.862174: Epoch time: 40.31 s 
2024-12-12 08:36:32.864686: Yayy! New best EMA pseudo Dice: 0.43160000443458557 
2024-12-12 08:36:33.601672:  
2024-12-12 08:36:33.607268: Epoch 34 
2024-12-12 08:36:33.610406: Current learning rate: 0.00688 
2024-12-12 08:37:13.910719: train_loss -0.4608 
2024-12-12 08:37:13.916738: val_loss -0.3802 
2024-12-12 08:37:13.919753: Pseudo dice [np.float32(0.4549)] 
2024-12-12 08:37:13.922802: Epoch time: 40.31 s 
2024-12-12 08:37:13.925864: Yayy! New best EMA pseudo Dice: 0.4339999854564667 
2024-12-12 08:37:14.667253:  
2024-12-12 08:37:14.672817: Epoch 35 
2024-12-12 08:37:14.676445: Current learning rate: 0.00679 
2024-12-12 08:37:54.979417: train_loss -0.4558 
2024-12-12 08:37:54.985436: val_loss -0.4747 
2024-12-12 08:37:54.988949: Pseudo dice [np.float32(0.5516)] 
2024-12-12 08:37:54.991983: Epoch time: 40.31 s 
2024-12-12 08:37:54.994487: Yayy! New best EMA pseudo Dice: 0.4456999897956848 
2024-12-12 08:37:55.886480:  
2024-12-12 08:37:55.891494: Epoch 36 
2024-12-12 08:37:55.894505: Current learning rate: 0.00669 
2024-12-12 08:38:36.190717: train_loss -0.4729 
2024-12-12 08:38:36.196234: val_loss -0.3686 
2024-12-12 08:38:36.199747: Pseudo dice [np.float32(0.4411)] 
2024-12-12 08:38:36.202254: Epoch time: 40.31 s 
2024-12-12 08:38:36.782088:  
2024-12-12 08:38:36.787174: Epoch 37 
2024-12-12 08:38:36.790126: Current learning rate: 0.0066 
2024-12-12 08:39:17.070932: train_loss -0.4542 
2024-12-12 08:39:17.077013: val_loss -0.4846 
2024-12-12 08:39:17.079572: Pseudo dice [np.float32(0.556)] 
2024-12-12 08:39:17.083106: Epoch time: 40.29 s 
2024-12-12 08:39:17.085662: Yayy! New best EMA pseudo Dice: 0.4562999904155731 
2024-12-12 08:39:17.828182:  
2024-12-12 08:39:17.833212: Epoch 38 
2024-12-12 08:39:17.836738: Current learning rate: 0.0065 
2024-12-12 08:39:58.108230: train_loss -0.4918 
2024-12-12 08:39:58.115752: val_loss -0.3817 
2024-12-12 08:39:58.119262: Pseudo dice [np.float32(0.4369)] 
2024-12-12 08:39:58.122312: Epoch time: 40.28 s 
2024-12-12 08:39:58.700699:  
2024-12-12 08:39:58.705710: Epoch 39 
2024-12-12 08:39:58.709218: Current learning rate: 0.00641 
2024-12-12 08:40:38.995597: train_loss -0.4366 
2024-12-12 08:40:39.001168: val_loss -0.3774 
2024-12-12 08:40:39.005144: Pseudo dice [np.float32(0.4394)] 
2024-12-12 08:40:39.008657: Epoch time: 40.3 s 
2024-12-12 08:40:39.593826:  
2024-12-12 08:40:39.599381: Epoch 40 
2024-12-12 08:40:39.601932: Current learning rate: 0.00631 
2024-12-12 08:41:19.896029: train_loss -0.4585 
2024-12-12 08:41:19.902104: val_loss -0.4491 
2024-12-12 08:41:19.906111: Pseudo dice [np.float32(0.5172)] 
2024-12-12 08:41:19.908616: Epoch time: 40.3 s 
2024-12-12 08:41:19.912125: Yayy! New best EMA pseudo Dice: 0.4593000113964081 
2024-12-12 08:41:20.659965:  
2024-12-12 08:41:20.663973: Epoch 41 
2024-12-12 08:41:20.666478: Current learning rate: 0.00622 
2024-12-12 08:42:00.974911: train_loss -0.4812 
2024-12-12 08:42:00.980926: val_loss -0.3696 
2024-12-12 08:42:00.984434: Pseudo dice [np.float32(0.4605)] 
2024-12-12 08:42:00.987448: Epoch time: 40.31 s 
2024-12-12 08:42:00.989955: Yayy! New best EMA pseudo Dice: 0.4593999981880188 
2024-12-12 08:42:01.706721:  
2024-12-12 08:42:01.711786: Epoch 42 
2024-12-12 08:42:01.715317: Current learning rate: 0.00612 
2024-12-12 08:42:42.015847: train_loss -0.4339 
2024-12-12 08:42:42.022361: val_loss -0.4368 
2024-12-12 08:42:42.025874: Pseudo dice [np.float32(0.4916)] 
2024-12-12 08:42:42.028383: Epoch time: 40.31 s 
2024-12-12 08:42:42.031890: Yayy! New best EMA pseudo Dice: 0.4627000093460083 
2024-12-12 08:42:42.760830:  
2024-12-12 08:42:42.766344: Epoch 43 
2024-12-12 08:42:42.769852: Current learning rate: 0.00603 
2024-12-12 08:43:23.058941: train_loss -0.4725 
2024-12-12 08:43:23.064964: val_loss -0.4449 
2024-12-12 08:43:23.068025: Pseudo dice [np.float32(0.5434)] 
2024-12-12 08:43:23.070531: Epoch time: 40.3 s 
2024-12-12 08:43:23.074045: Yayy! New best EMA pseudo Dice: 0.4706999957561493 
2024-12-12 08:43:23.947865:  
2024-12-12 08:43:23.953404: Epoch 44 
2024-12-12 08:43:23.956476: Current learning rate: 0.00593 
2024-12-12 08:44:04.277320: train_loss -0.4655 
2024-12-12 08:44:04.282332: val_loss -0.4578 
2024-12-12 08:44:04.286341: Pseudo dice [np.float32(0.5337)] 
2024-12-12 08:44:04.288848: Epoch time: 40.33 s 
2024-12-12 08:44:04.292360: Yayy! New best EMA pseudo Dice: 0.47699999809265137 
2024-12-12 08:44:05.060030:  
2024-12-12 08:44:05.064058: Epoch 45 
2024-12-12 08:44:05.067391: Current learning rate: 0.00584 
2024-12-12 08:44:45.383567: train_loss -0.5051 
2024-12-12 08:44:45.389211: val_loss -0.4565 
2024-12-12 08:44:45.392265: Pseudo dice [np.float32(0.5291)] 
2024-12-12 08:44:45.395281: Epoch time: 40.32 s 
2024-12-12 08:44:45.396821: Yayy! New best EMA pseudo Dice: 0.4821999967098236 
2024-12-12 08:44:46.118723:  
2024-12-12 08:44:46.122765: Epoch 46 
2024-12-12 08:44:46.127338: Current learning rate: 0.00574 
2024-12-12 08:45:26.449219: train_loss -0.5073 
2024-12-12 08:45:26.455315: val_loss -0.4066 
2024-12-12 08:45:26.458889: Pseudo dice [np.float32(0.474)] 
2024-12-12 08:45:26.461945: Epoch time: 40.33 s 
2024-12-12 08:45:27.011103:  
2024-12-12 08:45:27.016184: Epoch 47 
2024-12-12 08:45:27.018772: Current learning rate: 0.00565 
2024-12-12 08:46:07.326538: train_loss -0.5297 
2024-12-12 08:46:07.332586: val_loss -0.4631 
2024-12-12 08:46:07.335644: Pseudo dice [np.float32(0.5483)] 
2024-12-12 08:46:07.338150: Epoch time: 40.32 s 
2024-12-12 08:46:07.341658: Yayy! New best EMA pseudo Dice: 0.48809999227523804 
2024-12-12 08:46:08.056070:  
2024-12-12 08:46:08.059609: Epoch 48 
2024-12-12 08:46:08.063133: Current learning rate: 0.00555 
2024-12-12 08:46:48.399946: train_loss -0.4989 
2024-12-12 08:46:48.404958: val_loss -0.4217 
2024-12-12 08:46:48.408965: Pseudo dice [np.float32(0.5243)] 
2024-12-12 08:46:48.411470: Epoch time: 40.34 s 
2024-12-12 08:46:48.414981: Yayy! New best EMA pseudo Dice: 0.4916999936103821 
2024-12-12 08:46:49.134032:  
2024-12-12 08:46:49.139688: Epoch 49 
2024-12-12 08:46:49.142750: Current learning rate: 0.00546 
2024-12-12 08:47:29.445337: train_loss -0.5052 
2024-12-12 08:47:29.451352: val_loss -0.4761 
2024-12-12 08:47:29.455359: Pseudo dice [np.float32(0.5491)] 
2024-12-12 08:47:29.458868: Epoch time: 40.31 s 
2024-12-12 08:47:29.611283: Yayy! New best EMA pseudo Dice: 0.4975000023841858 
2024-12-12 08:47:30.344369:  
2024-12-12 08:47:30.349429: Epoch 50 
2024-12-12 08:47:30.352452: Current learning rate: 0.00536 
2024-12-12 08:48:10.650942: train_loss -0.5029 
2024-12-12 08:48:10.657070: val_loss -0.3917 
2024-12-12 08:48:10.659090: Pseudo dice [np.float32(0.4922)] 
2024-12-12 08:48:10.663122: Epoch time: 40.31 s 
2024-12-12 08:48:11.221372:  
2024-12-12 08:48:11.226413: Epoch 51 
2024-12-12 08:48:11.229461: Current learning rate: 0.00526 
2024-12-12 08:48:51.513510: train_loss -0.5067 
2024-12-12 08:48:51.519593: val_loss -0.4315 
2024-12-12 08:48:51.522693: Pseudo dice [np.float32(0.519)] 
2024-12-12 08:48:51.525755: Epoch time: 40.29 s 
2024-12-12 08:48:51.528794: Yayy! New best EMA pseudo Dice: 0.499099999666214 
2024-12-12 08:48:52.404046:  
2024-12-12 08:48:52.409559: Epoch 52 
2024-12-12 08:48:52.412064: Current learning rate: 0.00517 
2024-12-12 08:49:32.709562: train_loss -0.4746 
2024-12-12 08:49:32.714576: val_loss -0.4741 
2024-12-12 08:49:32.718081: Pseudo dice [np.float32(0.5405)] 
2024-12-12 08:49:32.721088: Epoch time: 40.31 s 
2024-12-12 08:49:32.724596: Yayy! New best EMA pseudo Dice: 0.5033000111579895 
2024-12-12 08:49:33.450871:  
2024-12-12 08:49:33.456981: Epoch 53 
2024-12-12 08:49:33.460011: Current learning rate: 0.00507 
2024-12-12 08:50:13.759394: train_loss -0.4979 
2024-12-12 08:50:13.765924: val_loss -0.4721 
2024-12-12 08:50:13.768931: Pseudo dice [np.float32(0.5128)] 
2024-12-12 08:50:13.771436: Epoch time: 40.31 s 
2024-12-12 08:50:13.774945: Yayy! New best EMA pseudo Dice: 0.5041999816894531 
2024-12-12 08:50:14.517154:  
2024-12-12 08:50:14.522190: Epoch 54 
2024-12-12 08:50:14.524714: Current learning rate: 0.00497 
2024-12-12 08:50:54.842003: train_loss -0.5331 
2024-12-12 08:50:54.848076: val_loss -0.4154 
2024-12-12 08:50:54.851109: Pseudo dice [np.float32(0.518)] 
2024-12-12 08:50:54.853614: Epoch time: 40.33 s 
2024-12-12 08:50:54.857120: Yayy! New best EMA pseudo Dice: 0.5055999755859375 
2024-12-12 08:50:55.583510:  
2024-12-12 08:50:55.589064: Epoch 55 
2024-12-12 08:50:55.591584: Current learning rate: 0.00487 
2024-12-12 08:51:35.894262: train_loss -0.4963 
2024-12-12 08:51:35.900282: val_loss -0.464 
2024-12-12 08:51:35.902790: Pseudo dice [np.float32(0.5811)] 
2024-12-12 08:51:35.906302: Epoch time: 40.31 s 
2024-12-12 08:51:35.908810: Yayy! New best EMA pseudo Dice: 0.5131999850273132 
2024-12-12 08:51:36.641821:  
2024-12-12 08:51:36.647385: Epoch 56 
2024-12-12 08:51:36.650955: Current learning rate: 0.00478 
2024-12-12 08:52:16.970534: train_loss -0.5271 
2024-12-12 08:52:16.978560: val_loss -0.425 
2024-12-12 08:52:16.982109: Pseudo dice [np.float32(0.4797)] 
2024-12-12 08:52:16.985655: Epoch time: 40.33 s 
2024-12-12 08:52:17.549209:  
2024-12-12 08:52:17.554745: Epoch 57 
2024-12-12 08:52:17.558254: Current learning rate: 0.00468 
2024-12-12 08:52:57.855430: train_loss -0.5331 
2024-12-12 08:52:57.860441: val_loss -0.3808 
2024-12-12 08:52:57.864949: Pseudo dice [np.float32(0.4597)] 
2024-12-12 08:52:57.867956: Epoch time: 40.31 s 
2024-12-12 08:52:58.430509:  
2024-12-12 08:52:58.436076: Epoch 58 
2024-12-12 08:52:58.439138: Current learning rate: 0.00458 
2024-12-12 08:53:38.771935: train_loss -0.5424 
2024-12-12 08:53:38.777974: val_loss -0.3824 
2024-12-12 08:53:38.781006: Pseudo dice [np.float32(0.4481)] 
2024-12-12 08:53:38.783523: Epoch time: 40.34 s 
2024-12-12 08:53:39.358471:  
2024-12-12 08:53:39.364000: Epoch 59 
2024-12-12 08:53:39.367012: Current learning rate: 0.00448 
2024-12-12 08:54:19.660737: train_loss -0.5152 
2024-12-12 08:54:19.668755: val_loss -0.4936 
2024-12-12 08:54:19.673264: Pseudo dice [np.float32(0.5867)] 
2024-12-12 08:54:19.676271: Epoch time: 40.3 s 
2024-12-12 08:54:20.404832:  
2024-12-12 08:54:20.409864: Epoch 60 
2024-12-12 08:54:20.412889: Current learning rate: 0.00438 
2024-12-12 08:55:00.729733: train_loss -0.5541 
2024-12-12 08:55:00.735329: val_loss -0.4395 
2024-12-12 08:55:00.737837: Pseudo dice [np.float32(0.536)] 
2024-12-12 08:55:00.741345: Epoch time: 40.33 s 
2024-12-12 08:55:01.317925:  
2024-12-12 08:55:01.323489: Epoch 61 
2024-12-12 08:55:01.326530: Current learning rate: 0.00429 
2024-12-12 08:55:41.607902: train_loss -0.5181 
2024-12-12 08:55:41.613965: val_loss -0.3981 
2024-12-12 08:55:41.617489: Pseudo dice [np.float32(0.4795)] 
2024-12-12 08:55:41.620512: Epoch time: 40.29 s 
2024-12-12 08:55:42.189336:  
2024-12-12 08:55:42.194864: Epoch 62 
2024-12-12 08:55:42.197887: Current learning rate: 0.00419 
2024-12-12 08:56:22.501472: train_loss -0.5699 
2024-12-12 08:56:22.505995: val_loss -0.5202 
2024-12-12 08:56:22.510525: Pseudo dice [np.float32(0.6136)] 
2024-12-12 08:56:22.513030: Epoch time: 40.31 s 
2024-12-12 08:56:22.516538: Yayy! New best EMA pseudo Dice: 0.5181999802589417 
2024-12-12 08:56:23.249341:  
2024-12-12 08:56:23.255861: Epoch 63 
2024-12-12 08:56:23.259870: Current learning rate: 0.00409 
2024-12-12 08:57:03.589523: train_loss -0.5007 
2024-12-12 08:57:03.595141: val_loss -0.4171 
2024-12-12 08:57:03.598652: Pseudo dice [np.float32(0.5031)] 
2024-12-12 08:57:03.602160: Epoch time: 40.34 s 
2024-12-12 08:57:04.178846:  
2024-12-12 08:57:04.184912: Epoch 64 
2024-12-12 08:57:04.188011: Current learning rate: 0.00399 
2024-12-12 08:57:44.501724: train_loss -0.5497 
2024-12-12 08:57:44.506309: val_loss -0.3751 
2024-12-12 08:57:44.510353: Pseudo dice [np.float32(0.4648)] 
2024-12-12 08:57:44.512862: Epoch time: 40.32 s 
2024-12-12 08:57:45.080642:  
2024-12-12 08:57:45.085678: Epoch 65 
2024-12-12 08:57:45.088725: Current learning rate: 0.00389 
2024-12-12 08:58:25.407585: train_loss -0.5508 
2024-12-12 08:58:25.415609: val_loss -0.5108 
2024-12-12 08:58:25.420623: Pseudo dice [np.float32(0.6115)] 
2024-12-12 08:58:25.423129: Epoch time: 40.33 s 
2024-12-12 08:58:25.426637: Yayy! New best EMA pseudo Dice: 0.5214999914169312 
2024-12-12 08:58:26.170207:  
2024-12-12 08:58:26.175266: Epoch 66 
2024-12-12 08:58:26.178833: Current learning rate: 0.00379 
2024-12-12 08:59:06.492374: train_loss -0.5001 
2024-12-12 08:59:06.497392: val_loss -0.4644 
2024-12-12 08:59:06.501402: Pseudo dice [np.float32(0.5288)] 
2024-12-12 08:59:06.503908: Epoch time: 40.32 s 
2024-12-12 08:59:06.507417: Yayy! New best EMA pseudo Dice: 0.5221999883651733 
2024-12-12 08:59:07.257877:  
2024-12-12 08:59:07.262912: Epoch 67 
2024-12-12 08:59:07.265463: Current learning rate: 0.00369 
2024-12-12 08:59:47.584129: train_loss -0.5521 
2024-12-12 08:59:47.590721: val_loss -0.4128 
2024-12-12 08:59:47.594272: Pseudo dice [np.float32(0.522)] 
2024-12-12 08:59:47.596816: Epoch time: 40.33 s 
2024-12-12 08:59:48.339682:  
2024-12-12 08:59:48.345232: Epoch 68 
2024-12-12 08:59:48.348784: Current learning rate: 0.00359 
2024-12-12 09:00:28.660871: train_loss -0.5583 
2024-12-12 09:00:28.669299: val_loss -0.4122 
2024-12-12 09:00:28.673380: Pseudo dice [np.float32(0.5286)] 
2024-12-12 09:00:28.676912: Epoch time: 40.32 s 
2024-12-12 09:00:28.680033: Yayy! New best EMA pseudo Dice: 0.5228000283241272 
2024-12-12 09:00:29.424425:  
2024-12-12 09:00:29.429437: Epoch 69 
2024-12-12 09:00:29.432951: Current learning rate: 0.00349 
2024-12-12 09:01:09.737787: train_loss -0.5414 
2024-12-12 09:01:09.743839: val_loss -0.4469 
2024-12-12 09:01:09.746850: Pseudo dice [np.float32(0.5564)] 
2024-12-12 09:01:09.750362: Epoch time: 40.31 s 
2024-12-12 09:01:09.752869: Yayy! New best EMA pseudo Dice: 0.526199996471405 
2024-12-12 09:01:10.500598:  
2024-12-12 09:01:10.506659: Epoch 70 
2024-12-12 09:01:10.510227: Current learning rate: 0.00338 
2024-12-12 09:01:50.815353: train_loss -0.587 
2024-12-12 09:01:50.819415: val_loss -0.4484 
2024-12-12 09:01:50.823947: Pseudo dice [np.float32(0.5306)] 
2024-12-12 09:01:50.826452: Epoch time: 40.31 s 
2024-12-12 09:01:50.829961: Yayy! New best EMA pseudo Dice: 0.5266000032424927 
2024-12-12 09:01:51.574573:  
2024-12-12 09:01:51.580682: Epoch 71 
2024-12-12 09:01:51.583771: Current learning rate: 0.00328 
2024-12-12 09:02:31.877112: train_loss -0.5979 
2024-12-12 09:02:31.882133: val_loss -0.4088 
2024-12-12 09:02:31.885644: Pseudo dice [np.float32(0.5239)] 
2024-12-12 09:02:31.888152: Epoch time: 40.3 s 
2024-12-12 09:02:32.467272:  
2024-12-12 09:02:32.472785: Epoch 72 
2024-12-12 09:02:32.476293: Current learning rate: 0.00318 
2024-12-12 09:03:12.769138: train_loss -0.5396 
2024-12-12 09:03:12.774760: val_loss -0.4586 
2024-12-12 09:03:12.777313: Pseudo dice [np.float32(0.574)] 
2024-12-12 09:03:12.781357: Epoch time: 40.3 s 
2024-12-12 09:03:12.784423: Yayy! New best EMA pseudo Dice: 0.5310999751091003 
2024-12-12 09:03:13.532015:  
2024-12-12 09:03:13.537579: Epoch 73 
2024-12-12 09:03:13.540118: Current learning rate: 0.00308 
2024-12-12 09:03:53.837275: train_loss -0.5627 
2024-12-12 09:03:53.842286: val_loss -0.3661 
2024-12-12 09:03:53.846795: Pseudo dice [np.float32(0.4721)] 
2024-12-12 09:03:53.849803: Epoch time: 40.31 s 
2024-12-12 09:03:54.433022:  
2024-12-12 09:03:54.438592: Epoch 74 
2024-12-12 09:03:54.442129: Current learning rate: 0.00297 
2024-12-12 09:04:35.138615: train_loss -0.5413 
2024-12-12 09:04:35.143187: val_loss -0.4392 
2024-12-12 09:04:35.147215: Pseudo dice [np.float32(0.5408)] 
2024-12-12 09:04:35.150245: Epoch time: 40.71 s 
2024-12-12 09:04:35.727698:  
2024-12-12 09:04:35.733259: Epoch 75 
2024-12-12 09:04:35.736830: Current learning rate: 0.00287 
2024-12-12 09:05:16.097476: train_loss -0.5469 
2024-12-12 09:05:16.104082: val_loss -0.4308 
2024-12-12 09:05:16.107126: Pseudo dice [np.float32(0.5989)] 
2024-12-12 09:05:16.110222: Epoch time: 40.37 s 
2024-12-12 09:05:16.113765: Yayy! New best EMA pseudo Dice: 0.5339999794960022 
2024-12-12 09:05:17.014089:  
2024-12-12 09:05:17.020602: Epoch 76 
2024-12-12 09:05:17.024110: Current learning rate: 0.00277 
2024-12-12 09:05:57.389454: train_loss -0.5693 
2024-12-12 09:05:57.395521: val_loss -0.4606 
2024-12-12 09:05:57.399056: Pseudo dice [np.float32(0.5344)] 
2024-12-12 09:05:57.402098: Epoch time: 40.38 s 
2024-12-12 09:05:57.405130: Yayy! New best EMA pseudo Dice: 0.5339999794960022 
2024-12-12 09:05:58.151159:  
2024-12-12 09:05:58.156683: Epoch 77 
2024-12-12 09:05:58.159697: Current learning rate: 0.00266 
2024-12-12 09:06:38.505678: train_loss -0.5437 
2024-12-12 09:06:38.511223: val_loss -0.4697 
2024-12-12 09:06:38.514758: Pseudo dice [np.float32(0.4871)] 
2024-12-12 09:06:38.518322: Epoch time: 40.36 s 
2024-12-12 09:06:39.101425:  
2024-12-12 09:06:39.106440: Epoch 78 
2024-12-12 09:06:39.110447: Current learning rate: 0.00256 
2024-12-12 09:07:19.451515: train_loss -0.5885 
2024-12-12 09:07:19.457061: val_loss -0.4053 
2024-12-12 09:07:19.461092: Pseudo dice [np.float32(0.4743)] 
2024-12-12 09:07:19.464131: Epoch time: 40.35 s 
2024-12-12 09:07:20.099747:  
2024-12-12 09:07:20.104276: Epoch 79 
2024-12-12 09:07:20.107861: Current learning rate: 0.00245 
2024-12-12 09:08:00.452089: train_loss -0.5751 
2024-12-12 09:08:00.458104: val_loss -0.4583 
2024-12-12 09:08:00.462135: Pseudo dice [np.float32(0.5312)] 
2024-12-12 09:08:00.465204: Epoch time: 40.35 s 
2024-12-12 09:08:01.050340:  
2024-12-12 09:08:01.055352: Epoch 80 
2024-12-12 09:08:01.059368: Current learning rate: 0.00235 
2024-12-12 09:08:41.404685: train_loss -0.5723 
2024-12-12 09:08:41.410754: val_loss -0.4394 
2024-12-12 09:08:41.414298: Pseudo dice [np.float32(0.5571)] 
2024-12-12 09:08:41.417868: Epoch time: 40.35 s 
2024-12-12 09:08:42.010605:  
2024-12-12 09:08:42.015615: Epoch 81 
2024-12-12 09:08:42.019124: Current learning rate: 0.00224 
2024-12-12 09:09:22.377445: train_loss -0.5967 
2024-12-12 09:09:22.383039: val_loss -0.4069 
2024-12-12 09:09:22.387101: Pseudo dice [np.float32(0.4985)] 
2024-12-12 09:09:22.390154: Epoch time: 40.37 s 
2024-12-12 09:09:22.981566:  
2024-12-12 09:09:22.986599: Epoch 82 
2024-12-12 09:09:22.990131: Current learning rate: 0.00214 
2024-12-12 09:10:03.358212: train_loss -0.5771 
2024-12-12 09:10:03.364272: val_loss -0.4618 
2024-12-12 09:10:03.367827: Pseudo dice [np.float32(0.5601)] 
2024-12-12 09:10:03.370368: Epoch time: 40.38 s 
2024-12-12 09:10:04.075751:  
2024-12-12 09:10:04.081806: Epoch 83 
2024-12-12 09:10:04.084322: Current learning rate: 0.00203 
2024-12-12 09:10:44.439001: train_loss -0.5911 
2024-12-12 09:10:44.445034: val_loss -0.4178 
2024-12-12 09:10:44.447569: Pseudo dice [np.float32(0.5188)] 
2024-12-12 09:10:44.452134: Epoch time: 40.36 s 
2024-12-12 09:10:45.007317:  
2024-12-12 09:10:45.012364: Epoch 84 
2024-12-12 09:10:45.015966: Current learning rate: 0.00192 
2024-12-12 09:11:25.360859: train_loss -0.5878 
2024-12-12 09:11:25.367544: val_loss -0.5388 
2024-12-12 09:11:25.371082: Pseudo dice [np.float32(0.5899)] 
2024-12-12 09:11:25.373118: Epoch time: 40.35 s 
2024-12-12 09:11:25.929610:  
2024-12-12 09:11:25.935681: Epoch 85 
2024-12-12 09:11:25.939209: Current learning rate: 0.00181 
2024-12-12 09:12:06.271104: train_loss -0.6043 
2024-12-12 09:12:06.276636: val_loss -0.4688 
2024-12-12 09:12:06.280659: Pseudo dice [np.float32(0.5948)] 
2024-12-12 09:12:06.283666: Epoch time: 40.34 s 
2024-12-12 09:12:06.287174: Yayy! New best EMA pseudo Dice: 0.5397999882698059 
2024-12-12 09:12:07.063247:  
2024-12-12 09:12:07.068227: Epoch 86 
2024-12-12 09:12:07.071738: Current learning rate: 0.0017 
2024-12-12 09:12:47.435581: train_loss -0.6107 
2024-12-12 09:12:47.441146: val_loss -0.4647 
2024-12-12 09:12:47.444675: Pseudo dice [np.float32(0.5479)] 
2024-12-12 09:12:47.447732: Epoch time: 40.37 s 
2024-12-12 09:12:47.450239: Yayy! New best EMA pseudo Dice: 0.5406000018119812 
2024-12-12 09:12:48.167818:  
2024-12-12 09:12:48.171905: Epoch 87 
2024-12-12 09:12:48.175968: Current learning rate: 0.00159 
2024-12-12 09:13:28.504288: train_loss -0.5985 
2024-12-12 09:13:28.510807: val_loss -0.4866 
2024-12-12 09:13:28.514322: Pseudo dice [np.float32(0.5682)] 
2024-12-12 09:13:28.517829: Epoch time: 40.34 s 
2024-12-12 09:13:28.520835: Yayy! New best EMA pseudo Dice: 0.54339998960495 
2024-12-12 09:13:29.239154:  
2024-12-12 09:13:29.245165: Epoch 88 
2024-12-12 09:13:29.249179: Current learning rate: 0.00148 
2024-12-12 09:14:09.593605: train_loss -0.6103 
2024-12-12 09:14:09.599118: val_loss -0.4689 
2024-12-12 09:14:09.602628: Pseudo dice [np.float32(0.538)] 
2024-12-12 09:14:09.606133: Epoch time: 40.35 s 
2024-12-12 09:14:10.159966:  
2024-12-12 09:14:10.164976: Epoch 89 
2024-12-12 09:14:10.168484: Current learning rate: 0.00137 
2024-12-12 09:14:50.532820: train_loss -0.5892 
2024-12-12 09:14:50.538386: val_loss -0.5755 
2024-12-12 09:14:50.541918: Pseudo dice [np.float32(0.6354)] 
2024-12-12 09:14:50.545444: Epoch time: 40.37 s 
2024-12-12 09:14:50.548477: Yayy! New best EMA pseudo Dice: 0.5521000027656555 
2024-12-12 09:14:51.257069:  
2024-12-12 09:14:51.262630: Epoch 90 
2024-12-12 09:14:51.265172: Current learning rate: 0.00126 
2024-12-12 09:15:31.602363: train_loss -0.6035 
2024-12-12 09:15:31.607898: val_loss -0.5035 
2024-12-12 09:15:31.611919: Pseudo dice [np.float32(0.6351)] 
2024-12-12 09:15:31.614983: Epoch time: 40.35 s 
2024-12-12 09:15:31.618041: Yayy! New best EMA pseudo Dice: 0.5604000091552734 
2024-12-12 09:15:32.488795:  
2024-12-12 09:15:32.494334: Epoch 91 
2024-12-12 09:15:32.497896: Current learning rate: 0.00115 
2024-12-12 09:16:12.815683: train_loss -0.6366 
2024-12-12 09:16:12.821731: val_loss -0.4586 
2024-12-12 09:16:12.824783: Pseudo dice [np.float32(0.5794)] 
2024-12-12 09:16:12.828292: Epoch time: 40.33 s 
2024-12-12 09:16:12.830799: Yayy! New best EMA pseudo Dice: 0.5623000264167786 
2024-12-12 09:16:13.548454:  
2024-12-12 09:16:13.554070: Epoch 92 
2024-12-12 09:16:13.556615: Current learning rate: 0.00103 
2024-12-12 09:16:53.888613: train_loss -0.6228 
2024-12-12 09:16:53.895221: val_loss -0.4518 
2024-12-12 09:16:53.898263: Pseudo dice [np.float32(0.5783)] 
2024-12-12 09:16:53.901360: Epoch time: 40.34 s 
2024-12-12 09:16:53.904429: Yayy! New best EMA pseudo Dice: 0.5638999938964844 
2024-12-12 09:16:54.624411:  
2024-12-12 09:16:54.629951: Epoch 93 
2024-12-12 09:16:54.633463: Current learning rate: 0.00091 
2024-12-12 09:17:34.976153: train_loss -0.6264 
2024-12-12 09:17:34.982666: val_loss -0.4319 
2024-12-12 09:17:34.986200: Pseudo dice [np.float32(0.567)] 
2024-12-12 09:17:34.989738: Epoch time: 40.35 s 
2024-12-12 09:17:34.992773: Yayy! New best EMA pseudo Dice: 0.5641999840736389 
2024-12-12 09:17:35.711161:  
2024-12-12 09:17:35.715217: Epoch 94 
2024-12-12 09:17:35.719835: Current learning rate: 0.00079 
2024-12-12 09:18:16.056980: train_loss -0.6239 
2024-12-12 09:18:16.062994: val_loss -0.4062 
2024-12-12 09:18:16.067045: Pseudo dice [np.float32(0.511)] 
2024-12-12 09:18:16.070095: Epoch time: 40.35 s 
2024-12-12 09:18:16.622456:  
2024-12-12 09:18:16.627969: Epoch 95 
2024-12-12 09:18:16.630476: Current learning rate: 0.00067 
2024-12-12 09:18:56.969193: train_loss -0.641 
2024-12-12 09:18:56.975797: val_loss -0.4705 
2024-12-12 09:18:56.978870: Pseudo dice [np.float32(0.5634)] 
2024-12-12 09:18:56.981920: Epoch time: 40.35 s 
2024-12-12 09:18:57.531700:  
2024-12-12 09:18:57.537087: Epoch 96 
2024-12-12 09:18:57.540599: Current learning rate: 0.00055 
2024-12-12 09:19:37.913302: train_loss -0.6114 
2024-12-12 09:19:37.920384: val_loss -0.4813 
2024-12-12 09:19:37.923950: Pseudo dice [np.float32(0.5823)] 
2024-12-12 09:19:37.926996: Epoch time: 40.38 s 
2024-12-12 09:19:38.488721:  
2024-12-12 09:19:38.494298: Epoch 97 
2024-12-12 09:19:38.497417: Current learning rate: 0.00043 
2024-12-12 09:20:18.845071: train_loss -0.6169 
2024-12-12 09:20:18.851120: val_loss -0.4707 
2024-12-12 09:20:18.854638: Pseudo dice [np.float32(0.531)] 
2024-12-12 09:20:18.858257: Epoch time: 40.36 s 
2024-12-12 09:20:19.420745:  
2024-12-12 09:20:19.426284: Epoch 98 
2024-12-12 09:20:19.429314: Current learning rate: 0.0003 
2024-12-12 09:20:59.763674: train_loss -0.6409 
2024-12-12 09:20:59.769223: val_loss -0.4723 
2024-12-12 09:20:59.773247: Pseudo dice [np.float32(0.58)] 
2024-12-12 09:20:59.776784: Epoch time: 40.34 s 
2024-12-12 09:21:00.346787:  
2024-12-12 09:21:00.352886: Epoch 99 
2024-12-12 09:21:00.356414: Current learning rate: 0.00016 
2024-12-12 09:21:43.011767: train_loss -0.6286 
2024-12-12 09:21:43.018321: val_loss -0.467 
2024-12-12 09:21:43.021539: Pseudo dice [np.float32(0.5846)] 
2024-12-12 09:21:43.024891: Epoch time: 42.67 s 
2024-12-12 09:21:43.944885: Training done. 
2024-12-12 09:21:43.990888: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-12 09:21:44.000893: The split file contains 5 splits. 
2024-12-12 09:21:44.004892: Desired fold for training: 0 
2024-12-12 09:21:44.008397: This split has 100 training and 26 validation cases. 
2024-12-12 09:21:44.013402: predicting colon_008 
2024-12-12 09:21:44.018403: colon_008, shape torch.Size([1, 89, 465, 465]), rank 0 
2024-12-12 09:21:53.259600: predicting colon_027 
2024-12-12 09:21:53.275600: colon_027, shape torch.Size([1, 38, 440, 440]), rank 0 
2024-12-12 09:21:54.905011: predicting colon_030 
2024-12-12 09:21:54.915515: colon_030, shape torch.Size([1, 90, 384, 384]), rank 0 
2024-12-12 09:21:59.212935: predicting colon_033 
2024-12-12 09:21:59.224441: colon_033, shape torch.Size([1, 98, 480, 480]), rank 0 
2024-12-12 09:22:07.792921: predicting colon_041 
2024-12-12 09:22:07.810925: colon_041, shape torch.Size([1, 104, 591, 591]), rank 0 
2024-12-12 09:22:25.638607: predicting colon_042 
2024-12-12 09:22:25.663607: colon_042, shape torch.Size([1, 55, 640, 640]), rank 0 
2024-12-12 09:22:32.830281: predicting colon_061 
2024-12-12 09:22:32.850399: colon_061, shape torch.Size([1, 85, 529, 529]), rank 0 
2024-12-12 09:22:44.240288: predicting colon_074 
2024-12-12 09:22:44.258333: colon_074, shape torch.Size([1, 80, 607, 607]), rank 0 
2024-12-12 09:22:54.982267: predicting colon_075 
2024-12-12 09:22:55.005266: colon_075, shape torch.Size([1, 86, 474, 474]), rank 0 
2024-12-12 09:23:03.554528: predicting colon_088 
2024-12-12 09:23:03.572036: colon_088, shape torch.Size([1, 95, 563, 563]), rank 0 
2024-12-12 09:23:17.834911: predicting colon_091 
2024-12-12 09:23:17.859914: colon_091, shape torch.Size([1, 103, 543, 543]), rank 0 
2024-12-12 09:23:32.115495: predicting colon_092 
2024-12-12 09:23:32.137496: colon_092, shape torch.Size([1, 90, 492, 492]), rank 0 
2024-12-12 09:23:40.709374: predicting colon_095 
2024-12-12 09:23:40.728375: colon_095, shape torch.Size([1, 96, 452, 452]), rank 0 
2024-12-12 09:23:49.278499: predicting colon_102 
2024-12-12 09:23:49.295526: colon_102, shape torch.Size([1, 96, 590, 590]), rank 0 
2024-12-12 09:24:03.574783: predicting colon_111 
2024-12-12 09:24:03.599293: colon_111, shape torch.Size([1, 48, 521, 521]), rank 0 
2024-12-12 09:24:09.310822: predicting colon_115 
2024-12-12 09:24:09.323822: colon_115, shape torch.Size([1, 97, 470, 470]), rank 0 
2024-12-12 09:24:17.888472: predicting colon_118 
2024-12-12 09:24:17.907978: colon_118, shape torch.Size([1, 100, 486, 486]), rank 0 
2024-12-12 09:24:26.475681: predicting colon_124 
2024-12-12 09:24:26.494681: colon_124, shape torch.Size([1, 92, 535, 535]), rank 0 
2024-12-12 09:24:37.910476: predicting colon_127 
2024-12-12 09:24:37.930983: colon_127, shape torch.Size([1, 130, 598, 598]), rank 0 
2024-12-12 09:24:59.285231: predicting colon_154 
2024-12-12 09:24:59.315419: colon_154, shape torch.Size([1, 94, 461, 461]), rank 0 
2024-12-12 09:25:07.886488: predicting colon_161 
2024-12-12 09:25:07.903488: colon_161, shape torch.Size([1, 95, 474, 474]), rank 0 
2024-12-12 09:25:16.467283: predicting colon_162 
2024-12-12 09:25:16.486283: colon_162, shape torch.Size([1, 104, 598, 598]), rank 0 
2024-12-12 09:25:34.295115: predicting colon_165 
2024-12-12 09:25:34.323307: colon_165, shape torch.Size([1, 85, 577, 577]), rank 0 
2024-12-12 09:25:48.558878: predicting colon_166 
2024-12-12 09:25:48.579388: colon_166, shape torch.Size([1, 87, 474, 474]), rank 0 
2024-12-12 09:25:57.134497: predicting colon_169 
2024-12-12 09:25:57.152498: colon_169, shape torch.Size([1, 129, 621, 621]), rank 0 
2024-12-12 09:26:18.545598: predicting colon_187 
2024-12-12 09:26:18.577599: colon_187, shape torch.Size([1, 94, 513, 513]), rank 0 
2024-12-12 09:26:37.521323: Validation complete 
2024-12-12 09:26:37.526323: Mean Validation Dice:  0.24359659420397267 
