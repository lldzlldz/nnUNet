
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-11 10:48:15.909200: do_dummy_2d_data_aug: True 
2024-12-11 10:48:15.909200: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-11 10:48:15.925711: The split file contains 5 splits. 
2024-12-11 10:48:15.925711: Desired fold for training: 0 
2024-12-11 10:48:15.925711: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2024-12-11 10:48:24.851716: unpacking dataset... 
2024-12-11 10:48:36.052144: unpacking done... 
2024-12-11 10:48:40.181069:  
2024-12-11 10:48:40.186177: Epoch 0 
2024-12-11 10:48:40.188725: Current learning rate: 0.01 
2024-12-11 10:49:29.256064: train_loss 0.0433 
2024-12-11 10:49:29.261749: val_loss -0.0065 
2024-12-11 10:49:29.265319: Pseudo dice [np.float32(0.0)] 
2024-12-11 10:49:29.268906: Epoch time: 49.08 s 
2024-12-11 10:49:29.271457: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-11 10:49:29.930810:  
2024-12-11 10:49:29.935993: Epoch 1 
2024-12-11 10:49:29.939046: Current learning rate: 0.00991 
2024-12-11 10:50:14.054874: train_loss -0.0812 
2024-12-11 10:50:14.061012: val_loss -0.21 
2024-12-11 10:50:14.064064: Pseudo dice [np.float32(0.2751)] 
2024-12-11 10:50:14.066613: Epoch time: 44.13 s 
2024-12-11 10:50:14.069660: Yayy! New best EMA pseudo Dice: 0.027499999850988388 
2024-12-11 10:50:14.780849:  
2024-12-11 10:50:14.787484: Epoch 2 
2024-12-11 10:50:14.790525: Current learning rate: 0.00982 
2024-12-11 10:50:58.906604: train_loss -0.2857 
2024-12-11 10:50:58.912199: val_loss -0.2742 
2024-12-11 10:50:58.915249: Pseudo dice [np.float32(0.3324)] 
2024-12-11 10:50:58.918300: Epoch time: 44.13 s 
2024-12-11 10:50:58.921961: Yayy! New best EMA pseudo Dice: 0.057999998331069946 
2024-12-11 10:50:59.681418:  
2024-12-11 10:50:59.688037: Epoch 3 
2024-12-11 10:50:59.691094: Current learning rate: 0.00973 
2024-12-11 10:51:43.801965: train_loss -0.3073 
2024-12-11 10:51:43.809619: val_loss -0.3307 
2024-12-11 10:51:43.813661: Pseudo dice [np.float32(0.3901)] 
2024-12-11 10:51:43.817258: Epoch time: 44.12 s 
2024-12-11 10:51:43.819794: Yayy! New best EMA pseudo Dice: 0.09120000153779984 
2024-12-11 10:51:44.544033:  
2024-12-11 10:51:44.550175: Epoch 4 
2024-12-11 10:51:44.554752: Current learning rate: 0.00964 
2024-12-11 10:52:28.699198: train_loss -0.3135 
2024-12-11 10:52:28.704805: val_loss -0.3439 
2024-12-11 10:52:28.707862: Pseudo dice [np.float32(0.4139)] 
2024-12-11 10:52:28.710396: Epoch time: 44.16 s 
2024-12-11 10:52:28.713981: Yayy! New best EMA pseudo Dice: 0.12349999696016312 
2024-12-11 10:52:29.658945:  
2024-12-11 10:52:29.664607: Epoch 5 
2024-12-11 10:52:29.667149: Current learning rate: 0.00955 
2024-12-11 10:53:13.347688: train_loss -0.3522 
2024-12-11 10:53:13.354288: val_loss -0.3346 
2024-12-11 10:53:13.357356: Pseudo dice [np.float32(0.3717)] 
2024-12-11 10:53:13.360870: Epoch time: 43.69 s 
2024-12-11 10:53:13.363377: Yayy! New best EMA pseudo Dice: 0.14830000698566437 
2024-12-11 10:53:14.100211:  
2024-12-11 10:53:14.105812: Epoch 6 
2024-12-11 10:53:14.108910: Current learning rate: 0.00946 
2024-12-11 10:53:57.152543: train_loss -0.4019 
2024-12-11 10:53:57.159078: val_loss -0.408 
2024-12-11 10:53:57.162593: Pseudo dice [np.float32(0.4292)] 
2024-12-11 10:53:57.165604: Epoch time: 43.05 s 
2024-12-11 10:53:57.168682: Yayy! New best EMA pseudo Dice: 0.17640000581741333 
2024-12-11 10:53:57.901894:  
2024-12-11 10:53:57.906913: Epoch 7 
2024-12-11 10:53:57.910930: Current learning rate: 0.00937 
2024-12-11 10:54:40.952127: train_loss -0.4125 
2024-12-11 10:54:40.957654: val_loss -0.4317 
2024-12-11 10:54:40.961720: Pseudo dice [np.float32(0.4865)] 
2024-12-11 10:54:40.964728: Epoch time: 43.05 s 
2024-12-11 10:54:40.967288: Yayy! New best EMA pseudo Dice: 0.20739999413490295 
2024-12-11 10:54:41.709138:  
2024-12-11 10:54:41.714794: Epoch 8 
2024-12-11 10:54:41.718814: Current learning rate: 0.00928 
2024-12-11 10:55:24.748980: train_loss -0.3845 
2024-12-11 10:55:24.754575: val_loss -0.3661 
2024-12-11 10:55:24.758101: Pseudo dice [np.float32(0.4118)] 
2024-12-11 10:55:24.760134: Epoch time: 43.04 s 
2024-12-11 10:55:24.764322: Yayy! New best EMA pseudo Dice: 0.22779999673366547 
2024-12-11 10:55:25.511760:  
2024-12-11 10:55:25.517297: Epoch 9 
2024-12-11 10:55:25.520843: Current learning rate: 0.00919 
2024-12-11 10:56:08.581991: train_loss -0.3987 
2024-12-11 10:56:08.587179: val_loss -0.4699 
2024-12-11 10:56:08.590748: Pseudo dice [np.float32(0.5313)] 
2024-12-11 10:56:08.593812: Epoch time: 43.07 s 
2024-12-11 10:56:08.596333: Yayy! New best EMA pseudo Dice: 0.2581999897956848 
2024-12-11 10:56:09.299598:  
2024-12-11 10:56:09.305201: Epoch 10 
2024-12-11 10:56:09.308901: Current learning rate: 0.0091 
2024-12-11 10:56:52.384227: train_loss -0.3896 
2024-12-11 10:56:52.390836: val_loss -0.3642 
2024-12-11 10:56:52.393387: Pseudo dice [np.float32(0.4253)] 
2024-12-11 10:56:52.397537: Epoch time: 43.08 s 
2024-12-11 10:56:52.400094: Yayy! New best EMA pseudo Dice: 0.27489998936653137 
2024-12-11 10:56:53.142388:  
2024-12-11 10:56:53.147484: Epoch 11 
2024-12-11 10:56:53.152106: Current learning rate: 0.009 
2024-12-11 10:57:36.184660: train_loss -0.4197 
2024-12-11 10:57:36.190759: val_loss -0.4601 
2024-12-11 10:57:36.193783: Pseudo dice [np.float32(0.5288)] 
2024-12-11 10:57:36.196894: Epoch time: 43.04 s 
2024-12-11 10:57:36.200414: Yayy! New best EMA pseudo Dice: 0.3003000020980835 
2024-12-11 10:57:36.942381:  
2024-12-11 10:57:36.947430: Epoch 12 
2024-12-11 10:57:36.951036: Current learning rate: 0.00891 
2024-12-11 10:58:20.001988: train_loss -0.4627 
2024-12-11 10:58:20.007661: val_loss -0.309 
2024-12-11 10:58:20.011169: Pseudo dice [np.float32(0.3367)] 
2024-12-11 10:58:20.013675: Epoch time: 43.06 s 
2024-12-11 10:58:20.017186: Yayy! New best EMA pseudo Dice: 0.30390000343322754 
2024-12-11 10:58:20.885474:  
2024-12-11 10:58:20.891541: Epoch 13 
2024-12-11 10:58:20.894619: Current learning rate: 0.00882 
2024-12-11 10:59:03.944882: train_loss -0.4482 
2024-12-11 10:59:03.950516: val_loss -0.3642 
2024-12-11 10:59:03.953053: Pseudo dice [np.float32(0.4166)] 
2024-12-11 10:59:03.956128: Epoch time: 43.06 s 
2024-12-11 10:59:03.959633: Yayy! New best EMA pseudo Dice: 0.31520000100135803 
2024-12-11 10:59:04.702648:  
2024-12-11 10:59:04.707709: Epoch 14 
2024-12-11 10:59:04.711368: Current learning rate: 0.00873 
2024-12-11 10:59:47.728872: train_loss -0.4606 
2024-12-11 10:59:47.734009: val_loss -0.4375 
2024-12-11 10:59:47.737548: Pseudo dice [np.float32(0.4932)] 
2024-12-11 10:59:47.740756: Epoch time: 43.03 s 
2024-12-11 10:59:47.743360: Yayy! New best EMA pseudo Dice: 0.3330000042915344 
2024-12-11 10:59:48.487505:  
2024-12-11 10:59:48.492595: Epoch 15 
2024-12-11 10:59:48.496632: Current learning rate: 0.00864 
2024-12-11 11:00:31.556447: train_loss -0.4677 
2024-12-11 11:00:31.562655: val_loss -0.4717 
2024-12-11 11:00:31.565163: Pseudo dice [np.float32(0.5789)] 
2024-12-11 11:00:31.568755: Epoch time: 43.07 s 
2024-12-11 11:00:31.572764: Yayy! New best EMA pseudo Dice: 0.35760000348091125 
2024-12-11 11:00:32.316938:  
2024-12-11 11:00:32.322014: Epoch 16 
2024-12-11 11:00:32.325526: Current learning rate: 0.00855 
2024-12-11 11:01:15.382813: train_loss -0.4604 
2024-12-11 11:01:15.388728: val_loss -0.3908 
2024-12-11 11:01:15.391275: Pseudo dice [np.float32(0.4504)] 
2024-12-11 11:01:15.395308: Epoch time: 43.07 s 
2024-12-11 11:01:15.398443: Yayy! New best EMA pseudo Dice: 0.3668999969959259 
2024-12-11 11:01:16.156460:  
2024-12-11 11:01:16.161058: Epoch 17 
2024-12-11 11:01:16.165620: Current learning rate: 0.00846 
2024-12-11 11:01:59.204051: train_loss -0.4867 
2024-12-11 11:01:59.212136: val_loss -0.4675 
2024-12-11 11:01:59.216144: Pseudo dice [np.float32(0.5467)] 
2024-12-11 11:01:59.219709: Epoch time: 43.05 s 
2024-12-11 11:01:59.222215: Yayy! New best EMA pseudo Dice: 0.3849000036716461 
2024-12-11 11:01:59.971460:  
2024-12-11 11:01:59.977976: Epoch 18 
2024-12-11 11:01:59.980482: Current learning rate: 0.00836 
2024-12-11 11:02:42.999972: train_loss -0.4698 
2024-12-11 11:02:43.005122: val_loss -0.4045 
2024-12-11 11:02:43.008210: Pseudo dice [np.float32(0.4797)] 
2024-12-11 11:02:43.012221: Epoch time: 43.03 s 
2024-12-11 11:02:43.015010: Yayy! New best EMA pseudo Dice: 0.39430001378059387 
2024-12-11 11:02:43.786600:  
2024-12-11 11:02:43.792238: Epoch 19 
2024-12-11 11:02:43.796293: Current learning rate: 0.00827 
2024-12-11 11:03:26.830732: train_loss -0.4844 
2024-12-11 11:03:26.837399: val_loss -0.4355 
2024-12-11 11:03:26.840475: Pseudo dice [np.float32(0.4864)] 
2024-12-11 11:03:26.842984: Epoch time: 43.04 s 
2024-12-11 11:03:26.847055: Yayy! New best EMA pseudo Dice: 0.4034999907016754 
2024-12-11 11:03:27.749243:  
2024-12-11 11:03:27.754368: Epoch 20 
2024-12-11 11:03:27.758453: Current learning rate: 0.00818 
2024-12-11 11:04:10.788536: train_loss -0.4498 
2024-12-11 11:04:10.794660: val_loss -0.4217 
2024-12-11 11:04:10.798278: Pseudo dice [np.float32(0.4781)] 
2024-12-11 11:04:10.801328: Epoch time: 43.04 s 
2024-12-11 11:04:10.803540: Yayy! New best EMA pseudo Dice: 0.41100001335144043 
2024-12-11 11:04:11.559109:  
2024-12-11 11:04:11.564725: Epoch 21 
2024-12-11 11:04:11.568321: Current learning rate: 0.00809 
2024-12-11 11:04:54.618139: train_loss -0.4987 
2024-12-11 11:04:54.623731: val_loss -0.4665 
2024-12-11 11:04:54.627242: Pseudo dice [np.float32(0.5487)] 
2024-12-11 11:04:54.630872: Epoch time: 43.06 s 
2024-12-11 11:04:54.633380: Yayy! New best EMA pseudo Dice: 0.42480000853538513 
2024-12-11 11:04:55.365119:  
2024-12-11 11:04:55.370715: Epoch 22 
2024-12-11 11:04:55.374333: Current learning rate: 0.008 
2024-12-11 11:05:38.443009: train_loss -0.49 
2024-12-11 11:05:38.449600: val_loss -0.4417 
2024-12-11 11:05:38.453179: Pseudo dice [np.float32(0.5035)] 
2024-12-11 11:05:38.455854: Epoch time: 43.08 s 
2024-12-11 11:05:38.459418: Yayy! New best EMA pseudo Dice: 0.4325999915599823 
2024-12-11 11:05:39.179071:  
2024-12-11 11:05:39.185138: Epoch 23 
2024-12-11 11:05:39.188738: Current learning rate: 0.0079 
2024-12-11 11:06:22.229624: train_loss -0.4917 
2024-12-11 11:06:22.234670: val_loss -0.4664 
2024-12-11 11:06:22.238266: Pseudo dice [np.float32(0.527)] 
2024-12-11 11:06:22.241782: Epoch time: 43.05 s 
2024-12-11 11:06:22.244802: Yayy! New best EMA pseudo Dice: 0.44209998846054077 
2024-12-11 11:06:22.945544:  
2024-12-11 11:06:22.951194: Epoch 24 
2024-12-11 11:06:22.955308: Current learning rate: 0.00781 
2024-12-11 11:07:06.002121: train_loss -0.5036 
2024-12-11 11:07:06.007374: val_loss -0.4044 
2024-12-11 11:07:06.010960: Pseudo dice [np.float32(0.4519)] 
2024-12-11 11:07:06.014478: Epoch time: 43.06 s 
2024-12-11 11:07:06.017033: Yayy! New best EMA pseudo Dice: 0.4431000053882599 
2024-12-11 11:07:06.743286:  
2024-12-11 11:07:06.748861: Epoch 25 
2024-12-11 11:07:06.752528: Current learning rate: 0.00772 
2024-12-11 11:07:49.807364: train_loss -0.5096 
2024-12-11 11:07:49.812883: val_loss -0.2786 
2024-12-11 11:07:49.816402: Pseudo dice [np.float32(0.356)] 
2024-12-11 11:07:49.820413: Epoch time: 43.06 s 
2024-12-11 11:07:50.384182:  
2024-12-11 11:07:50.388695: Epoch 26 
2024-12-11 11:07:50.391710: Current learning rate: 0.00763 
2024-12-11 11:08:33.450856: train_loss -0.4771 
2024-12-11 11:08:33.457703: val_loss -0.4388 
2024-12-11 11:08:33.461220: Pseudo dice [np.float32(0.4721)] 
2024-12-11 11:08:33.464335: Epoch time: 43.07 s 
2024-12-11 11:08:34.026250:  
2024-12-11 11:08:34.032377: Epoch 27 
2024-12-11 11:08:34.036116: Current learning rate: 0.00753 
2024-12-11 11:09:17.085483: train_loss -0.5278 
2024-12-11 11:09:17.091155: val_loss -0.4801 
2024-12-11 11:09:17.094684: Pseudo dice [np.float32(0.5821)] 
2024-12-11 11:09:17.099519: Epoch time: 43.06 s 
2024-12-11 11:09:17.102182: Yayy! New best EMA pseudo Dice: 0.45249998569488525 
2024-12-11 11:09:17.981400:  
2024-12-11 11:09:17.986462: Epoch 28 
2024-12-11 11:09:17.990475: Current learning rate: 0.00744 
2024-12-11 11:10:01.030982: train_loss -0.4796 
2024-12-11 11:10:01.037009: val_loss -0.4241 
2024-12-11 11:10:01.041066: Pseudo dice [np.float32(0.5194)] 
2024-12-11 11:10:01.043578: Epoch time: 43.05 s 
2024-12-11 11:10:01.047154: Yayy! New best EMA pseudo Dice: 0.459199994802475 
2024-12-11 11:10:01.763010:  
2024-12-11 11:10:01.769082: Epoch 29 
2024-12-11 11:10:01.772726: Current learning rate: 0.00735 
2024-12-11 11:10:44.796818: train_loss -0.5164 
2024-12-11 11:10:44.802397: val_loss -0.4891 
2024-12-11 11:10:44.805921: Pseudo dice [np.float32(0.5303)] 
2024-12-11 11:10:44.809456: Epoch time: 43.03 s 
2024-12-11 11:10:44.813003: Yayy! New best EMA pseudo Dice: 0.46630001068115234 
2024-12-11 11:10:45.569766:  
2024-12-11 11:10:45.575509: Epoch 30 
2024-12-11 11:10:45.578663: Current learning rate: 0.00725 
2024-12-11 11:11:28.611573: train_loss -0.5067 
2024-12-11 11:11:28.617684: val_loss -0.4818 
2024-12-11 11:11:28.621270: Pseudo dice [np.float32(0.5518)] 
2024-12-11 11:11:28.623775: Epoch time: 43.04 s 
2024-12-11 11:11:28.627280: Yayy! New best EMA pseudo Dice: 0.4749000072479248 
2024-12-11 11:11:29.411080:  
2024-12-11 11:11:29.416110: Epoch 31 
2024-12-11 11:11:29.419627: Current learning rate: 0.00716 
2024-12-11 11:12:12.479482: train_loss -0.5385 
2024-12-11 11:12:12.485081: val_loss -0.3973 
2024-12-11 11:12:12.489214: Pseudo dice [np.float32(0.4439)] 
2024-12-11 11:12:12.492721: Epoch time: 43.07 s 
2024-12-11 11:12:13.063193:  
2024-12-11 11:12:13.068825: Epoch 32 
2024-12-11 11:12:13.072891: Current learning rate: 0.00707 
2024-12-11 11:12:56.108889: train_loss -0.5233 
2024-12-11 11:12:56.114936: val_loss -0.4569 
2024-12-11 11:12:56.118532: Pseudo dice [np.float32(0.5577)] 
2024-12-11 11:12:56.121558: Epoch time: 43.05 s 
2024-12-11 11:12:56.125218: Yayy! New best EMA pseudo Dice: 0.4803999960422516 
2024-12-11 11:12:56.873996:  
2024-12-11 11:12:56.879079: Epoch 33 
2024-12-11 11:12:56.882681: Current learning rate: 0.00697 
2024-12-11 11:13:39.893852: train_loss -0.5512 
2024-12-11 11:13:39.898961: val_loss -0.4739 
2024-12-11 11:13:39.902621: Pseudo dice [np.float32(0.5517)] 
2024-12-11 11:13:39.906233: Epoch time: 43.02 s 
2024-12-11 11:13:39.909833: Yayy! New best EMA pseudo Dice: 0.48750001192092896 
2024-12-11 11:13:40.645596:  
2024-12-11 11:13:40.651158: Epoch 34 
2024-12-11 11:13:40.655720: Current learning rate: 0.00688 
2024-12-11 11:14:23.715879: train_loss -0.5278 
2024-12-11 11:14:23.723083: val_loss -0.5019 
2024-12-11 11:14:23.728231: Pseudo dice [np.float32(0.5777)] 
2024-12-11 11:14:23.730759: Epoch time: 43.07 s 
2024-12-11 11:14:23.734793: Yayy! New best EMA pseudo Dice: 0.4964999854564667 
2024-12-11 11:14:24.486382:  
2024-12-11 11:14:24.491958: Epoch 35 
2024-12-11 11:14:24.496132: Current learning rate: 0.00679 
2024-12-11 11:15:07.542525: train_loss -0.5411 
2024-12-11 11:15:07.549063: val_loss -0.4882 
2024-12-11 11:15:07.552172: Pseudo dice [np.float32(0.5453)] 
2024-12-11 11:15:07.555765: Epoch time: 43.06 s 
2024-12-11 11:15:07.559283: Yayy! New best EMA pseudo Dice: 0.5013999938964844 
2024-12-11 11:15:08.513913:  
2024-12-11 11:15:08.519441: Epoch 36 
2024-12-11 11:15:08.523031: Current learning rate: 0.00669 
2024-12-11 11:15:51.563142: train_loss -0.5263 
2024-12-11 11:15:51.568262: val_loss -0.3757 
2024-12-11 11:15:51.572838: Pseudo dice [np.float32(0.4493)] 
2024-12-11 11:15:51.575930: Epoch time: 43.05 s 
2024-12-11 11:15:52.161323:  
2024-12-11 11:15:52.166981: Epoch 37 
2024-12-11 11:15:52.171024: Current learning rate: 0.0066 
2024-12-11 11:16:41.345500: train_loss -0.5358 
2024-12-11 11:16:41.351206: val_loss -0.4556 
2024-12-11 11:16:41.354761: Pseudo dice [np.float32(0.5696)] 
2024-12-11 11:16:41.358367: Epoch time: 49.18 s 
2024-12-11 11:16:41.361425: Yayy! New best EMA pseudo Dice: 0.5034999847412109 
2024-12-11 11:16:42.102015:  
2024-12-11 11:16:42.109128: Epoch 38 
2024-12-11 11:16:42.112182: Current learning rate: 0.0065 
2024-12-11 11:17:26.411093: train_loss -0.5475 
2024-12-11 11:17:26.416164: val_loss -0.4772 
2024-12-11 11:17:26.421000: Pseudo dice [np.float32(0.5752)] 
2024-12-11 11:17:26.423535: Epoch time: 44.31 s 
2024-12-11 11:17:26.428109: Yayy! New best EMA pseudo Dice: 0.510699987411499 
2024-12-11 11:17:27.175996:  
2024-12-11 11:17:27.181581: Epoch 39 
2024-12-11 11:17:27.185137: Current learning rate: 0.00641 
2024-12-11 11:18:11.496102: train_loss -0.5336 
2024-12-11 11:18:11.501200: val_loss -0.4837 
2024-12-11 11:18:11.506342: Pseudo dice [np.float32(0.5363)] 
2024-12-11 11:18:11.508890: Epoch time: 44.32 s 
2024-12-11 11:18:11.511937: Yayy! New best EMA pseudo Dice: 0.5133000016212463 
2024-12-11 11:18:12.261932:  
2024-12-11 11:18:12.268024: Epoch 40 
2024-12-11 11:18:12.271567: Current learning rate: 0.00631 
2024-12-11 11:18:56.575323: train_loss -0.5587 
2024-12-11 11:18:56.581424: val_loss -0.5014 
2024-12-11 11:18:56.585502: Pseudo dice [np.float32(0.5838)] 
2024-12-11 11:18:56.588928: Epoch time: 44.31 s 
2024-12-11 11:18:56.592505: Yayy! New best EMA pseudo Dice: 0.5202999711036682 
2024-12-11 11:18:57.338100:  
2024-12-11 11:18:57.344421: Epoch 41 
2024-12-11 11:18:57.348490: Current learning rate: 0.00622 
2024-12-11 11:19:41.642698: train_loss -0.5477 
2024-12-11 11:19:41.647771: val_loss -0.5183 
2024-12-11 11:19:41.651821: Pseudo dice [np.float32(0.5818)] 
2024-12-11 11:19:41.655454: Epoch time: 44.31 s 
2024-12-11 11:19:41.657984: Yayy! New best EMA pseudo Dice: 0.5264999866485596 
2024-12-11 11:19:42.381870:  
2024-12-11 11:19:42.388971: Epoch 42 
2024-12-11 11:19:42.392069: Current learning rate: 0.00612 
2024-12-11 11:20:26.718430: train_loss -0.5397 
2024-12-11 11:20:26.723008: val_loss -0.4813 
2024-12-11 11:20:26.728083: Pseudo dice [np.float32(0.5291)] 
2024-12-11 11:20:26.730694: Epoch time: 44.34 s 
2024-12-11 11:20:26.735271: Yayy! New best EMA pseudo Dice: 0.5267000198364258 
2024-12-11 11:20:27.478308:  
2024-12-11 11:20:27.484481: Epoch 43 
2024-12-11 11:20:27.488527: Current learning rate: 0.00603 
2024-12-11 11:21:11.521562: train_loss -0.5665 
2024-12-11 11:21:11.527180: val_loss -0.545 
2024-12-11 11:21:11.530798: Pseudo dice [np.float32(0.6289)] 
2024-12-11 11:21:11.533845: Epoch time: 44.04 s 
2024-12-11 11:21:11.537463: Yayy! New best EMA pseudo Dice: 0.536899983882904 
2024-12-11 11:21:12.454594:  
2024-12-11 11:21:12.460201: Epoch 44 
2024-12-11 11:21:12.462207: Current learning rate: 0.00593 
2024-12-11 11:21:55.496379: train_loss -0.5367 
2024-12-11 11:21:55.501925: val_loss -0.5544 
2024-12-11 11:21:55.505527: Pseudo dice [np.float32(0.6028)] 
2024-12-11 11:21:55.508585: Epoch time: 43.04 s 
2024-12-11 11:21:55.512094: Yayy! New best EMA pseudo Dice: 0.5435000061988831 
2024-12-11 11:21:56.237749:  
2024-12-11 11:21:56.243431: Epoch 45 
2024-12-11 11:21:56.247275: Current learning rate: 0.00584 
2024-12-11 11:22:39.245556: train_loss -0.5945 
2024-12-11 11:22:39.253221: val_loss -0.4444 
2024-12-11 11:22:39.257755: Pseudo dice [np.float32(0.4913)] 
2024-12-11 11:22:39.261350: Epoch time: 43.01 s 
2024-12-11 11:22:39.826413:  
2024-12-11 11:22:39.832034: Epoch 46 
2024-12-11 11:22:39.835664: Current learning rate: 0.00574 
2024-12-11 11:23:22.864729: train_loss -0.5616 
2024-12-11 11:23:22.870354: val_loss -0.5013 
2024-12-11 11:23:22.874450: Pseudo dice [np.float32(0.5688)] 
2024-12-11 11:23:22.878051: Epoch time: 43.04 s 
2024-12-11 11:23:23.434428:  
2024-12-11 11:23:23.440078: Epoch 47 
2024-12-11 11:23:23.443358: Current learning rate: 0.00565 
2024-12-11 11:24:06.471627: train_loss -0.5742 
2024-12-11 11:24:06.476705: val_loss -0.5088 
2024-12-11 11:24:06.480715: Pseudo dice [np.float32(0.6235)] 
2024-12-11 11:24:06.483298: Epoch time: 43.04 s 
2024-12-11 11:24:06.486809: Yayy! New best EMA pseudo Dice: 0.5496000051498413 
2024-12-11 11:24:07.207291:  
2024-12-11 11:24:07.213721: Epoch 48 
2024-12-11 11:24:07.216230: Current learning rate: 0.00555 
2024-12-11 11:24:50.254658: train_loss -0.581 
2024-12-11 11:24:50.261921: val_loss -0.5275 
2024-12-11 11:24:50.265463: Pseudo dice [np.float32(0.5609)] 
2024-12-11 11:24:50.269010: Epoch time: 43.05 s 
2024-12-11 11:24:50.272033: Yayy! New best EMA pseudo Dice: 0.5507000088691711 
2024-12-11 11:24:50.998253:  
2024-12-11 11:24:51.004830: Epoch 49 
2024-12-11 11:24:51.008392: Current learning rate: 0.00546 
2024-12-11 11:25:34.060786: train_loss -0.5755 
2024-12-11 11:25:34.066968: val_loss -0.5047 
2024-12-11 11:25:34.070020: Pseudo dice [np.float32(0.5675)] 
2024-12-11 11:25:34.073074: Epoch time: 43.06 s 
2024-12-11 11:25:34.222472: Yayy! New best EMA pseudo Dice: 0.5523999929428101 
2024-12-11 11:25:34.947361:  
2024-12-11 11:25:34.953019: Epoch 50 
2024-12-11 11:25:34.956546: Current learning rate: 0.00536 
2024-12-11 11:26:18.011122: train_loss -0.5794 
2024-12-11 11:26:18.017229: val_loss -0.4929 
2024-12-11 11:26:18.020597: Pseudo dice [np.float32(0.5927)] 
2024-12-11 11:26:18.023613: Epoch time: 43.06 s 
2024-12-11 11:26:18.027319: Yayy! New best EMA pseudo Dice: 0.5564000010490417 
2024-12-11 11:26:18.756416:  
2024-12-11 11:26:18.763014: Epoch 51 
2024-12-11 11:26:18.766592: Current learning rate: 0.00526 
2024-12-11 11:27:01.804082: train_loss -0.5732 
2024-12-11 11:27:01.811689: val_loss -0.52 
2024-12-11 11:27:01.816712: Pseudo dice [np.float32(0.5884)] 
2024-12-11 11:27:01.819817: Epoch time: 43.05 s 
2024-12-11 11:27:01.822850: Yayy! New best EMA pseudo Dice: 0.5595999956130981 
2024-12-11 11:27:02.559067:  
2024-12-11 11:27:02.564690: Epoch 52 
2024-12-11 11:27:02.568269: Current learning rate: 0.00517 
2024-12-11 11:27:45.598282: train_loss -0.5755 
2024-12-11 11:27:45.603819: val_loss -0.5442 
2024-12-11 11:27:45.607407: Pseudo dice [np.float32(0.6212)] 
2024-12-11 11:27:45.611440: Epoch time: 43.04 s 
2024-12-11 11:27:45.613497: Yayy! New best EMA pseudo Dice: 0.5658000111579895 
2024-12-11 11:27:46.499422:  
2024-12-11 11:27:46.505437: Epoch 53 
2024-12-11 11:27:46.509448: Current learning rate: 0.00507 
2024-12-11 11:28:29.552824: train_loss -0.5945 
2024-12-11 11:28:29.558964: val_loss -0.4802 
2024-12-11 11:28:29.562472: Pseudo dice [np.float32(0.5155)] 
2024-12-11 11:28:29.565547: Epoch time: 43.05 s 
2024-12-11 11:28:30.135314:  
2024-12-11 11:28:30.140961: Epoch 54 
2024-12-11 11:28:30.144502: Current learning rate: 0.00497 
2024-12-11 11:29:13.186287: train_loss -0.5776 
2024-12-11 11:29:13.193389: val_loss -0.4969 
2024-12-11 11:29:13.198404: Pseudo dice [np.float32(0.5791)] 
2024-12-11 11:29:13.202503: Epoch time: 43.05 s 
2024-12-11 11:29:13.761950:  
2024-12-11 11:29:13.767588: Epoch 55 
2024-12-11 11:29:13.771167: Current learning rate: 0.00487 
2024-12-11 11:29:56.807013: train_loss -0.5762 
2024-12-11 11:29:56.813149: val_loss -0.3775 
2024-12-11 11:29:56.816746: Pseudo dice [np.float32(0.3586)] 
2024-12-11 11:29:56.819780: Epoch time: 43.05 s 
2024-12-11 11:29:57.378812:  
2024-12-11 11:29:57.385127: Epoch 56 
2024-12-11 11:29:57.389193: Current learning rate: 0.00478 
2024-12-11 11:30:40.444425: train_loss -0.5899 
2024-12-11 11:30:40.450531: val_loss -0.5351 
2024-12-11 11:30:40.454147: Pseudo dice [np.float32(0.6332)] 
2024-12-11 11:30:40.457702: Epoch time: 43.07 s 
2024-12-11 11:30:41.006282:  
2024-12-11 11:30:41.012841: Epoch 57 
2024-12-11 11:30:41.016476: Current learning rate: 0.00468 
2024-12-11 11:31:24.061266: train_loss -0.5878 
2024-12-11 11:31:24.066662: val_loss -0.441 
2024-12-11 11:31:24.070259: Pseudo dice [np.float32(0.5707)] 
2024-12-11 11:31:24.073773: Epoch time: 43.05 s 
2024-12-11 11:31:24.645659:  
2024-12-11 11:31:24.651293: Epoch 58 
2024-12-11 11:31:24.655358: Current learning rate: 0.00458 
2024-12-11 11:32:07.709979: train_loss -0.6249 
2024-12-11 11:32:07.715582: val_loss -0.5327 
2024-12-11 11:32:07.719707: Pseudo dice [np.float32(0.5602)] 
2024-12-11 11:32:07.722755: Epoch time: 43.07 s 
2024-12-11 11:32:08.298489:  
2024-12-11 11:32:08.305110: Epoch 59 
2024-12-11 11:32:08.309258: Current learning rate: 0.00448 
2024-12-11 11:32:51.353569: train_loss -0.6093 
2024-12-11 11:32:51.360191: val_loss -0.4518 
2024-12-11 11:32:51.363302: Pseudo dice [np.float32(0.4994)] 
2024-12-11 11:32:51.366861: Epoch time: 43.06 s 
2024-12-11 11:32:51.944247:  
2024-12-11 11:32:51.950355: Epoch 60 
2024-12-11 11:32:51.953860: Current learning rate: 0.00438 
2024-12-11 11:33:34.991137: train_loss -0.6137 
2024-12-11 11:33:34.996740: val_loss -0.5277 
2024-12-11 11:33:35.000245: Pseudo dice [np.float32(0.6097)] 
2024-12-11 11:33:35.004312: Epoch time: 43.05 s 
2024-12-11 11:33:35.718858:  
2024-12-11 11:33:35.723973: Epoch 61 
2024-12-11 11:33:35.728485: Current learning rate: 0.00429 
2024-12-11 11:34:18.757363: train_loss -0.6113 
2024-12-11 11:34:18.763999: val_loss -0.564 
2024-12-11 11:34:18.767543: Pseudo dice [np.float32(0.6418)] 
2024-12-11 11:34:18.771099: Epoch time: 43.04 s 
2024-12-11 11:34:19.405435:  
2024-12-11 11:34:19.411983: Epoch 62 
2024-12-11 11:34:19.415580: Current learning rate: 0.00419 
2024-12-11 11:35:02.450959: train_loss -0.5989 
2024-12-11 11:35:02.456605: val_loss -0.4977 
2024-12-11 11:35:02.460660: Pseudo dice [np.float32(0.5726)] 
2024-12-11 11:35:02.464211: Epoch time: 43.05 s 
2024-12-11 11:35:03.037413:  
2024-12-11 11:35:03.042984: Epoch 63 
2024-12-11 11:35:03.047493: Current learning rate: 0.00409 
2024-12-11 11:35:46.089888: train_loss -0.6013 
2024-12-11 11:35:46.096908: val_loss -0.5128 
2024-12-11 11:35:46.100920: Pseudo dice [np.float32(0.6022)] 
2024-12-11 11:35:46.104425: Epoch time: 43.05 s 
2024-12-11 11:35:46.107435: Yayy! New best EMA pseudo Dice: 0.5680000185966492 
2024-12-11 11:35:46.851120:  
2024-12-11 11:35:46.856708: Epoch 64 
2024-12-11 11:35:46.860718: Current learning rate: 0.00399 
2024-12-11 11:36:29.912637: train_loss -0.5918 
2024-12-11 11:36:29.920273: val_loss -0.479 
2024-12-11 11:36:29.925437: Pseudo dice [np.float32(0.4824)] 
2024-12-11 11:36:29.928501: Epoch time: 43.06 s 
2024-12-11 11:36:30.493814:  
2024-12-11 11:36:30.500437: Epoch 65 
2024-12-11 11:36:30.502982: Current learning rate: 0.00389 
2024-12-11 11:37:19.992381: train_loss -0.5859 
2024-12-11 11:37:19.999079: val_loss -0.4837 
2024-12-11 11:37:20.001626: Pseudo dice [np.float32(0.4644)] 
2024-12-11 11:37:20.006709: Epoch time: 49.5 s 
2024-12-11 11:37:20.592571:  
2024-12-11 11:37:20.599161: Epoch 66 
2024-12-11 11:37:20.603265: Current learning rate: 0.00379 
2024-12-11 11:38:05.005858: train_loss -0.617 
2024-12-11 11:38:05.012521: val_loss -0.5526 
2024-12-11 11:38:05.016577: Pseudo dice [np.float32(0.6265)] 
2024-12-11 11:38:05.020137: Epoch time: 44.41 s 
2024-12-11 11:38:05.599476:  
2024-12-11 11:38:05.605576: Epoch 67 
2024-12-11 11:38:05.609648: Current learning rate: 0.00369 
2024-12-11 11:38:50.060349: train_loss -0.623 
2024-12-11 11:38:50.065415: val_loss -0.5479 
2024-12-11 11:38:50.070772: Pseudo dice [np.float32(0.5834)] 
2024-12-11 11:38:50.074833: Epoch time: 44.46 s 
2024-12-11 11:38:50.658771:  
2024-12-11 11:38:50.664925: Epoch 68 
2024-12-11 11:38:50.668971: Current learning rate: 0.00359 
2024-12-11 11:39:35.122039: train_loss -0.6137 
2024-12-11 11:39:35.129857: val_loss -0.5607 
2024-12-11 11:39:35.135146: Pseudo dice [np.float32(0.5888)] 
2024-12-11 11:39:35.137681: Epoch time: 44.46 s 
2024-12-11 11:39:35.869690:  
2024-12-11 11:39:35.875291: Epoch 69 
2024-12-11 11:39:35.878874: Current learning rate: 0.00349 
2024-12-11 11:40:20.244584: train_loss -0.6003 
2024-12-11 11:40:20.250182: val_loss -0.5654 
2024-12-11 11:40:20.252726: Pseudo dice [np.float32(0.6449)] 
2024-12-11 11:40:20.255256: Epoch time: 44.38 s 
2024-12-11 11:40:20.259873: Yayy! New best EMA pseudo Dice: 0.5712000131607056 
2024-12-11 11:40:21.001565:  
2024-12-11 11:40:21.007212: Epoch 70 
2024-12-11 11:40:21.009759: Current learning rate: 0.00338 
2024-12-11 11:41:05.406404: train_loss -0.5931 
2024-12-11 11:41:05.413001: val_loss -0.5331 
2024-12-11 11:41:05.416593: Pseudo dice [np.float32(0.594)] 
2024-12-11 11:41:05.419130: Epoch time: 44.41 s 
2024-12-11 11:41:05.421658: Yayy! New best EMA pseudo Dice: 0.5734999775886536 
2024-12-11 11:41:06.168738:  
2024-12-11 11:41:06.174969: Epoch 71 
2024-12-11 11:41:06.179050: Current learning rate: 0.00328 
2024-12-11 11:41:50.332455: train_loss -0.6394 
2024-12-11 11:41:50.338118: val_loss -0.4784 
2024-12-11 11:41:50.342679: Pseudo dice [np.float32(0.601)] 
2024-12-11 11:41:50.347815: Epoch time: 44.17 s 
2024-12-11 11:41:50.351899: Yayy! New best EMA pseudo Dice: 0.5763000249862671 
2024-12-11 11:41:51.114474:  
2024-12-11 11:41:51.120641: Epoch 72 
2024-12-11 11:41:51.124787: Current learning rate: 0.00318 
2024-12-11 11:42:34.261899: train_loss -0.6182 
2024-12-11 11:42:34.269010: val_loss -0.5378 
2024-12-11 11:42:34.272519: Pseudo dice [np.float32(0.6627)] 
2024-12-11 11:42:34.276068: Epoch time: 43.15 s 
2024-12-11 11:42:34.279688: Yayy! New best EMA pseudo Dice: 0.5849000215530396 
2024-12-11 11:42:35.027333:  
2024-12-11 11:42:35.032902: Epoch 73 
2024-12-11 11:42:35.035921: Current learning rate: 0.00308 
2024-12-11 11:43:18.195003: train_loss -0.6173 
2024-12-11 11:43:18.202144: val_loss -0.5122 
2024-12-11 11:43:18.204685: Pseudo dice [np.float32(0.5851)] 
2024-12-11 11:43:18.207863: Epoch time: 43.17 s 
2024-12-11 11:43:18.210371: Yayy! New best EMA pseudo Dice: 0.5849000215530396 
2024-12-11 11:43:18.967448:  
2024-12-11 11:43:18.974047: Epoch 74 
2024-12-11 11:43:18.977566: Current learning rate: 0.00297 
2024-12-11 11:44:02.160059: train_loss -0.5987 
2024-12-11 11:44:02.166772: val_loss -0.572 
2024-12-11 11:44:02.169857: Pseudo dice [np.float32(0.6492)] 
2024-12-11 11:44:02.172406: Epoch time: 43.19 s 
2024-12-11 11:44:02.176244: Yayy! New best EMA pseudo Dice: 0.5914000272750854 
2024-12-11 11:44:02.929844:  
2024-12-11 11:44:02.935612: Epoch 75 
2024-12-11 11:44:02.940206: Current learning rate: 0.00287 
2024-12-11 11:44:49.719694: train_loss -0.6003 
2024-12-11 11:44:49.726790: val_loss -0.497 
2024-12-11 11:44:49.729848: Pseudo dice [np.float32(0.5634)] 
2024-12-11 11:44:49.732433: Epoch time: 46.79 s 
2024-12-11 11:44:50.325994:  
2024-12-11 11:44:50.332644: Epoch 76 
2024-12-11 11:44:50.336734: Current learning rate: 0.00277 
2024-12-11 11:45:34.631016: train_loss -0.6365 
2024-12-11 11:45:34.636135: val_loss -0.6259 
2024-12-11 11:45:34.640191: Pseudo dice [np.float32(0.6831)] 
2024-12-11 11:45:34.643774: Epoch time: 44.31 s 
2024-12-11 11:45:34.646305: Yayy! New best EMA pseudo Dice: 0.5979999899864197 
2024-12-11 11:45:35.563589:  
2024-12-11 11:45:35.569744: Epoch 77 
2024-12-11 11:45:35.573814: Current learning rate: 0.00266 
2024-12-11 11:46:19.915128: train_loss -0.6125 
2024-12-11 11:46:19.922796: val_loss -0.5106 
2024-12-11 11:46:19.925464: Pseudo dice [np.float32(0.5712)] 
2024-12-11 11:46:19.929033: Epoch time: 44.35 s 
2024-12-11 11:46:20.521139:  
2024-12-11 11:46:20.526565: Epoch 78 
2024-12-11 11:46:20.529667: Current learning rate: 0.00256 
2024-12-11 11:47:04.841127: train_loss -0.6328 
2024-12-11 11:47:04.848224: val_loss -0.4701 
2024-12-11 11:47:04.851928: Pseudo dice [np.float32(0.5672)] 
2024-12-11 11:47:04.856040: Epoch time: 44.32 s 
2024-12-11 11:47:05.465355:  
2024-12-11 11:47:05.470679: Epoch 79 
2024-12-11 11:47:05.474252: Current learning rate: 0.00245 
2024-12-11 11:47:49.831139: train_loss -0.6352 
2024-12-11 11:47:49.837388: val_loss -0.5686 
2024-12-11 11:47:49.840441: Pseudo dice [np.float32(0.6215)] 
2024-12-11 11:47:49.843665: Epoch time: 44.37 s 
2024-12-11 11:47:50.438825:  
2024-12-11 11:47:50.446269: Epoch 80 
2024-12-11 11:47:50.448551: Current learning rate: 0.00235 
2024-12-11 11:48:34.803329: train_loss -0.5845 
2024-12-11 11:48:34.809174: val_loss -0.5531 
2024-12-11 11:48:34.813222: Pseudo dice [np.float32(0.5879)] 
2024-12-11 11:48:34.816280: Epoch time: 44.36 s 
2024-12-11 11:48:35.419955:  
2024-12-11 11:48:35.425355: Epoch 81 
2024-12-11 11:48:35.428135: Current learning rate: 0.00224 
2024-12-11 11:49:19.744134: train_loss -0.6193 
2024-12-11 11:49:19.750269: val_loss -0.5839 
2024-12-11 11:49:19.754164: Pseudo dice [np.float32(0.6284)] 
2024-12-11 11:49:19.757223: Epoch time: 44.33 s 
2024-12-11 11:49:19.760299: Yayy! New best EMA pseudo Dice: 0.5979999899864197 
2024-12-11 11:49:20.532044:  
2024-12-11 11:49:20.537873: Epoch 82 
2024-12-11 11:49:20.540973: Current learning rate: 0.00214 
2024-12-11 11:50:04.825057: train_loss -0.6244 
2024-12-11 11:50:04.832702: val_loss -0.5429 
2024-12-11 11:50:04.836062: Pseudo dice [np.float32(0.6454)] 
2024-12-11 11:50:04.839598: Epoch time: 44.29 s 
2024-12-11 11:50:04.842461: Yayy! New best EMA pseudo Dice: 0.6028000116348267 
2024-12-11 11:50:05.572289:  
2024-12-11 11:50:05.577351: Epoch 83 
2024-12-11 11:50:05.581129: Current learning rate: 0.00203 
2024-12-11 11:50:49.904719: train_loss -0.6349 
2024-12-11 11:50:49.911042: val_loss -0.5288 
2024-12-11 11:50:49.914078: Pseudo dice [np.float32(0.5553)] 
2024-12-11 11:50:49.917402: Epoch time: 44.33 s 
2024-12-11 11:50:50.502607:  
2024-12-11 11:50:50.509075: Epoch 84 
2024-12-11 11:50:50.512329: Current learning rate: 0.00192 
2024-12-11 11:51:34.074780: train_loss -0.66 
2024-12-11 11:51:34.080855: val_loss -0.5296 
2024-12-11 11:51:34.084960: Pseudo dice [np.float32(0.6123)] 
2024-12-11 11:51:34.088470: Epoch time: 43.57 s 
2024-12-11 11:51:34.824446:  
2024-12-11 11:51:34.830021: Epoch 85 
2024-12-11 11:51:34.833541: Current learning rate: 0.00181 
2024-12-11 11:52:17.854219: train_loss -0.6572 
2024-12-11 11:52:17.861350: val_loss -0.4876 
2024-12-11 11:52:17.864942: Pseudo dice [np.float32(0.5802)] 
2024-12-11 11:52:17.868081: Epoch time: 43.03 s 
2024-12-11 11:52:18.432211:  
2024-12-11 11:52:18.437234: Epoch 86 
2024-12-11 11:52:18.441340: Current learning rate: 0.0017 
2024-12-11 11:53:01.474293: train_loss -0.6507 
2024-12-11 11:53:01.480874: val_loss -0.5095 
2024-12-11 11:53:01.484387: Pseudo dice [np.float32(0.5759)] 
2024-12-11 11:53:01.486896: Epoch time: 43.04 s 
2024-12-11 11:53:02.040307:  
2024-12-11 11:53:02.045897: Epoch 87 
2024-12-11 11:53:02.049976: Current learning rate: 0.00159 
2024-12-11 11:53:45.087259: train_loss -0.6381 
2024-12-11 11:53:45.091931: val_loss -0.5585 
2024-12-11 11:53:45.095493: Pseudo dice [np.float32(0.6267)] 
2024-12-11 11:53:45.098037: Epoch time: 43.05 s 
2024-12-11 11:53:45.659422:  
2024-12-11 11:53:45.664530: Epoch 88 
2024-12-11 11:53:45.668109: Current learning rate: 0.00148 
2024-12-11 11:54:28.704651: train_loss -0.6479 
2024-12-11 11:54:28.710667: val_loss -0.6037 
2024-12-11 11:54:28.714254: Pseudo dice [np.float32(0.708)] 
2024-12-11 11:54:28.717263: Epoch time: 43.05 s 
2024-12-11 11:54:28.720854: Yayy! New best EMA pseudo Dice: 0.609499990940094 
2024-12-11 11:54:29.446163:  
2024-12-11 11:54:29.451177: Epoch 89 
2024-12-11 11:54:29.454682: Current learning rate: 0.00137 
2024-12-11 11:55:12.535174: train_loss -0.6782 
2024-12-11 11:55:12.541721: val_loss -0.5383 
2024-12-11 11:55:12.545790: Pseudo dice [np.float32(0.6422)] 
2024-12-11 11:55:12.549301: Epoch time: 43.09 s 
2024-12-11 11:55:12.552490: Yayy! New best EMA pseudo Dice: 0.6126999855041504 
2024-12-11 11:55:13.291668:  
2024-12-11 11:55:13.296726: Epoch 90 
2024-12-11 11:55:13.300236: Current learning rate: 0.00126 
2024-12-11 11:55:56.376590: train_loss -0.6506 
2024-12-11 11:55:56.384172: val_loss -0.5095 
2024-12-11 11:55:56.389239: Pseudo dice [np.float32(0.6123)] 
2024-12-11 11:55:56.391745: Epoch time: 43.09 s 
2024-12-11 11:55:56.953062:  
2024-12-11 11:55:56.958658: Epoch 91 
2024-12-11 11:55:56.962203: Current learning rate: 0.00115 
2024-12-11 11:56:40.045550: train_loss -0.6587 
2024-12-11 11:56:40.051718: val_loss -0.5392 
2024-12-11 11:56:40.054240: Pseudo dice [np.float32(0.6724)] 
2024-12-11 11:56:40.057835: Epoch time: 43.09 s 
2024-12-11 11:56:40.061890: Yayy! New best EMA pseudo Dice: 0.6187000274658203 
2024-12-11 11:56:40.784659:  
2024-12-11 11:56:40.790767: Epoch 92 
2024-12-11 11:56:40.794391: Current learning rate: 0.00103 
2024-12-11 11:57:23.870378: train_loss -0.6488 
2024-12-11 11:57:23.876427: val_loss -0.5369 
2024-12-11 11:57:23.879489: Pseudo dice [np.float32(0.6546)] 
2024-12-11 11:57:23.882995: Epoch time: 43.09 s 
2024-12-11 11:57:23.886088: Yayy! New best EMA pseudo Dice: 0.6222000122070312 
2024-12-11 11:57:24.773676:  
2024-12-11 11:57:24.779211: Epoch 93 
2024-12-11 11:57:24.782752: Current learning rate: 0.00091 
2024-12-11 11:58:07.826098: train_loss -0.6605 
2024-12-11 11:58:07.831739: val_loss -0.5793 
2024-12-11 11:58:07.835308: Pseudo dice [np.float32(0.6759)] 
2024-12-11 11:58:07.838840: Epoch time: 43.05 s 
2024-12-11 11:58:07.841971: Yayy! New best EMA pseudo Dice: 0.6276000142097473 
2024-12-11 11:58:08.585421:  
2024-12-11 11:58:08.590993: Epoch 94 
2024-12-11 11:58:08.594637: Current learning rate: 0.00079 
2024-12-11 11:58:51.657724: train_loss -0.6829 
2024-12-11 11:58:51.663793: val_loss -0.5577 
2024-12-11 11:58:51.666875: Pseudo dice [np.float32(0.6534)] 
2024-12-11 11:58:51.670412: Epoch time: 43.07 s 
2024-12-11 11:58:51.673002: Yayy! New best EMA pseudo Dice: 0.6302000284194946 
2024-12-11 11:58:52.417471:  
2024-12-11 11:58:52.423165: Epoch 95 
2024-12-11 11:58:52.427205: Current learning rate: 0.00067 
2024-12-11 11:59:35.488096: train_loss -0.6877 
2024-12-11 11:59:35.493695: val_loss -0.5918 
2024-12-11 11:59:35.497205: Pseudo dice [np.float32(0.685)] 
2024-12-11 11:59:35.501369: Epoch time: 43.07 s 
2024-12-11 11:59:35.503874: Yayy! New best EMA pseudo Dice: 0.635699987411499 
2024-12-11 11:59:36.260402:  
2024-12-11 11:59:36.266024: Epoch 96 
2024-12-11 11:59:36.270067: Current learning rate: 0.00055 
2024-12-11 12:00:19.311340: train_loss -0.658 
2024-12-11 12:00:19.318926: val_loss -0.5592 
2024-12-11 12:00:19.321434: Pseudo dice [np.float32(0.6107)] 
2024-12-11 12:00:19.325603: Epoch time: 43.05 s 
2024-12-11 12:00:19.909615:  
2024-12-11 12:00:19.915459: Epoch 97 
2024-12-11 12:00:19.918513: Current learning rate: 0.00043 
2024-12-11 12:01:02.966406: train_loss -0.6724 
2024-12-11 12:01:02.973056: val_loss -0.588 
2024-12-11 12:01:02.976104: Pseudo dice [np.float32(0.7054)] 
2024-12-11 12:01:02.979137: Epoch time: 43.06 s 
2024-12-11 12:01:02.982707: Yayy! New best EMA pseudo Dice: 0.6403999924659729 
2024-12-11 12:01:03.721967:  
2024-12-11 12:01:03.725997: Epoch 98 
2024-12-11 12:01:03.731144: Current learning rate: 0.0003 
2024-12-11 12:01:46.764957: train_loss -0.6896 
2024-12-11 12:01:46.771587: val_loss -0.5171 
2024-12-11 12:01:46.775161: Pseudo dice [np.float32(0.6325)] 
2024-12-11 12:01:46.778746: Epoch time: 43.04 s 
2024-12-11 12:01:47.347655:  
2024-12-11 12:01:47.353760: Epoch 99 
2024-12-11 12:01:47.358318: Current learning rate: 0.00016 
2024-12-11 12:02:30.439984: train_loss -0.6891 
2024-12-11 12:02:30.446609: val_loss -0.5375 
2024-12-11 12:02:30.453210: Pseudo dice [np.float32(0.6661)] 
2024-12-11 12:02:30.456982: Epoch time: 43.09 s 
2024-12-11 12:02:30.461612: Yayy! New best EMA pseudo Dice: 0.642300009727478 
2024-12-11 12:02:31.394207: Training done. 
2024-12-11 12:02:31.434100: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-11 12:02:31.441255: The split file contains 5 splits. 
2024-12-11 12:02:31.448365: Desired fold for training: 0 
2024-12-11 12:02:31.452470: This split has 100 training and 26 validation cases. 
2024-12-11 12:02:31.458471: predicting colon_008 
2024-12-11 12:02:31.465620: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2024-12-11 12:02:47.660919: predicting colon_027 
2024-12-11 12:02:47.678154: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2024-12-11 12:02:53.869554: predicting colon_030 
2024-12-11 12:02:53.881688: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2024-12-11 12:03:02.600242: predicting colon_033 
2024-12-11 12:03:02.614355: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2024-12-11 12:03:18.080275: predicting colon_041 
2024-12-11 12:03:18.101461: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2024-12-11 12:03:59.775292: predicting colon_042 
2024-12-11 12:03:59.816745: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2024-12-11 12:04:20.679136: predicting colon_061 
2024-12-11 12:04:20.703335: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2024-12-11 12:04:44.845545: predicting colon_074 
2024-12-11 12:04:44.867898: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2024-12-11 12:05:12.679056: predicting colon_075 
2024-12-11 12:05:12.703240: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2024-12-11 12:05:28.159362: predicting colon_088 
2024-12-11 12:05:28.184676: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2024-12-11 12:05:52.356556: predicting colon_091 
2024-12-11 12:05:52.391836: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2024-12-11 12:06:21.352187: predicting colon_092 
2024-12-11 12:06:21.380955: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2024-12-11 12:06:45.502899: predicting colon_095 
2024-12-11 12:06:45.524063: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2024-12-11 12:07:00.983002: predicting colon_102 
2024-12-11 12:07:01.003259: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2024-12-11 12:07:35.715375: predicting colon_111 
2024-12-11 12:07:35.745723: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2024-12-11 12:07:45.454410: predicting colon_115 
2024-12-11 12:07:45.472568: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2024-12-11 12:08:00.942573: predicting colon_118 
2024-12-11 12:08:00.964743: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2024-12-11 12:08:25.085869: predicting colon_124 
2024-12-11 12:08:25.108078: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2024-12-11 12:08:49.257194: predicting colon_127 
2024-12-11 12:08:49.281892: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2024-12-11 12:09:37.963416: predicting colon_154 
2024-12-11 12:09:38.000697: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2024-12-11 12:09:53.503106: predicting colon_161 
2024-12-11 12:09:53.523775: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2024-12-11 12:10:08.995523: predicting colon_162 
2024-12-11 12:10:09.016749: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2024-12-11 12:10:50.731245: predicting colon_165 
2024-12-11 12:10:50.762977: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2024-12-11 12:11:25.540030: predicting colon_166 
2024-12-11 12:11:25.570275: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2024-12-11 12:11:41.039394: predicting colon_169 
2024-12-11 12:11:41.058646: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2024-12-11 12:12:29.770706: predicting colon_187 
2024-12-11 12:12:29.811995: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2024-12-11 12:13:03.870545: Validation complete 
2024-12-11 12:13:03.876604: Mean Validation Dice:  0.27865428384618574 
