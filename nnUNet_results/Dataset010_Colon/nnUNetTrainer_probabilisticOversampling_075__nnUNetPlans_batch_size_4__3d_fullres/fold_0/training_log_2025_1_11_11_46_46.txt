2025-01-11 11:46:46.729748: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.75 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-11 11:46:46.733746: self.oversample_foreground_percent 0.75 
2025-01-11 11:46:46.736746: do_dummy_2d_data_aug: True 
2025-01-11 11:46:46.757990: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-11 11:46:46.764517: The split file contains 5 splits. 
2025-01-11 11:46:46.766516: Desired fold for training: 0 
2025-01-11 11:46:46.769014: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [40, 160, 160], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-01-11 11:46:54.247297: unpacking dataset... 
2025-01-11 11:46:54.469584: unpacking done... 
2025-01-11 11:46:57.654882:  
2025-01-11 11:46:57.654882: Epoch 0 
2025-01-11 11:46:57.660530: Current learning rate: 0.01 
2025-01-11 11:47:42.315655: train_loss -0.0637 
2025-01-11 11:47:42.315655: val_loss -0.2556 
2025-01-11 11:47:42.320671: Pseudo dice [np.float32(0.3838)] 
2025-01-11 11:47:42.324683: Epoch time: 44.66 s 
2025-01-11 11:47:42.327192: Yayy! New best EMA pseudo Dice: 0.3837999999523163 
2025-01-11 11:47:43.014715:  
2025-01-11 11:47:43.014715: Epoch 1 
2025-01-11 11:47:43.023305: Current learning rate: 0.00996 
2025-01-11 11:48:23.263536: train_loss -0.3701 
2025-01-11 11:48:23.264537: val_loss -0.3886 
2025-01-11 11:48:23.270060: Pseudo dice [np.float32(0.5083)] 
2025-01-11 11:48:23.273575: Epoch time: 40.25 s 
2025-01-11 11:48:23.276086: Yayy! New best EMA pseudo Dice: 0.3962000012397766 
2025-01-11 11:48:24.022082:  
2025-01-11 11:48:24.022082: Epoch 2 
2025-01-11 11:48:24.027093: Current learning rate: 0.00993 
2025-01-11 11:49:04.251701: train_loss -0.4365 
2025-01-11 11:49:04.252203: val_loss -0.3983 
2025-01-11 11:49:04.257790: Pseudo dice [np.float32(0.5064)] 
2025-01-11 11:49:04.260884: Epoch time: 40.23 s 
2025-01-11 11:49:04.264894: Yayy! New best EMA pseudo Dice: 0.4072999954223633 
2025-01-11 11:49:05.036281:  
2025-01-11 11:49:05.037282: Epoch 3 
2025-01-11 11:49:05.042859: Current learning rate: 0.00989 
2025-01-11 11:49:45.231238: train_loss -0.4667 
2025-01-11 11:49:45.231238: val_loss -0.425 
2025-01-11 11:49:45.238701: Pseudo dice [np.float32(0.5245)] 
2025-01-11 11:49:45.241709: Epoch time: 40.19 s 
2025-01-11 11:49:45.245218: Yayy! New best EMA pseudo Dice: 0.4189999997615814 
2025-01-11 11:49:45.993346:  
2025-01-11 11:49:45.994350: Epoch 4 
2025-01-11 11:49:45.999415: Current learning rate: 0.00986 
2025-01-11 11:50:26.236813: train_loss -0.5017 
2025-01-11 11:50:26.237322: val_loss -0.4322 
2025-01-11 11:50:26.242879: Pseudo dice [np.float32(0.5245)] 
2025-01-11 11:50:26.246406: Epoch time: 40.24 s 
2025-01-11 11:50:26.249430: Yayy! New best EMA pseudo Dice: 0.429500013589859 
2025-01-11 11:50:27.157617:  
2025-01-11 11:50:27.158122: Epoch 5 
2025-01-11 11:50:27.163133: Current learning rate: 0.00982 
2025-01-11 11:51:07.316617: train_loss -0.5287 
2025-01-11 11:51:07.317119: val_loss -0.4767 
2025-01-11 11:51:07.322713: Pseudo dice [np.float32(0.5653)] 
2025-01-11 11:51:07.325753: Epoch time: 40.16 s 
2025-01-11 11:51:07.328779: Yayy! New best EMA pseudo Dice: 0.4431000053882599 
2025-01-11 11:51:08.082224:  
2025-01-11 11:51:08.083229: Epoch 6 
2025-01-11 11:51:08.087773: Current learning rate: 0.00978 
2025-01-11 11:51:48.248596: train_loss -0.548 
2025-01-11 11:51:48.249110: val_loss -0.4849 
2025-01-11 11:51:48.254200: Pseudo dice [np.float32(0.5735)] 
2025-01-11 11:51:48.257731: Epoch time: 40.17 s 
2025-01-11 11:51:48.261784: Yayy! New best EMA pseudo Dice: 0.4560999870300293 
2025-01-11 11:51:49.034496:  
2025-01-11 11:51:49.034496: Epoch 7 
2025-01-11 11:51:49.039511: Current learning rate: 0.00975 
2025-01-11 11:52:29.212329: train_loss -0.5502 
2025-01-11 11:52:29.213328: val_loss -0.4453 
2025-01-11 11:52:29.218844: Pseudo dice [np.float32(0.5399)] 
2025-01-11 11:52:29.222353: Epoch time: 40.18 s 
2025-01-11 11:52:29.224859: Yayy! New best EMA pseudo Dice: 0.4645000100135803 
2025-01-11 11:52:29.985314:  
2025-01-11 11:52:29.986318: Epoch 8 
2025-01-11 11:52:29.990869: Current learning rate: 0.00971 
2025-01-11 11:53:10.147507: train_loss -0.5539 
2025-01-11 11:53:10.148512: val_loss -0.5002 
2025-01-11 11:53:10.153525: Pseudo dice [np.float32(0.5958)] 
2025-01-11 11:53:10.157536: Epoch time: 40.16 s 
2025-01-11 11:53:10.160042: Yayy! New best EMA pseudo Dice: 0.47769999504089355 
2025-01-11 11:53:10.969316:  
2025-01-11 11:53:10.970316: Epoch 9 
2025-01-11 11:53:10.975385: Current learning rate: 0.00968 
2025-01-11 11:53:51.112838: train_loss -0.5714 
2025-01-11 11:53:51.112838: val_loss -0.4923 
2025-01-11 11:53:51.118853: Pseudo dice [np.float32(0.5888)] 
2025-01-11 11:53:51.122358: Epoch time: 40.14 s 
2025-01-11 11:53:51.125367: Yayy! New best EMA pseudo Dice: 0.4887999892234802 
2025-01-11 11:53:51.850185:  
2025-01-11 11:53:51.850693: Epoch 10 
2025-01-11 11:53:51.854728: Current learning rate: 0.00964 
2025-01-11 11:54:32.016214: train_loss -0.5791 
2025-01-11 11:54:32.016733: val_loss -0.4558 
2025-01-11 11:54:32.022424: Pseudo dice [np.float32(0.5398)] 
2025-01-11 11:54:32.025455: Epoch time: 40.17 s 
2025-01-11 11:54:32.029496: Yayy! New best EMA pseudo Dice: 0.49390000104904175 
2025-01-11 11:54:32.762292:  
2025-01-11 11:54:32.762292: Epoch 11 
2025-01-11 11:54:32.768308: Current learning rate: 0.0096 
2025-01-11 11:55:12.939591: train_loss -0.5881 
2025-01-11 11:55:12.939591: val_loss -0.5288 
2025-01-11 11:55:12.945605: Pseudo dice [np.float32(0.6226)] 
2025-01-11 11:55:12.948614: Epoch time: 40.18 s 
2025-01-11 11:55:12.951121: Yayy! New best EMA pseudo Dice: 0.5066999793052673 
2025-01-11 11:55:13.686178:  
2025-01-11 11:55:13.686178: Epoch 12 
2025-01-11 11:55:13.691195: Current learning rate: 0.00957 
2025-01-11 11:55:53.868665: train_loss -0.6041 
2025-01-11 11:55:53.870172: val_loss -0.564 
2025-01-11 11:55:53.875707: Pseudo dice [np.float32(0.6513)] 
2025-01-11 11:55:53.879216: Epoch time: 40.18 s 
2025-01-11 11:55:53.882722: Yayy! New best EMA pseudo Dice: 0.5212000012397766 
2025-01-11 11:55:54.801255:  
2025-01-11 11:55:54.801763: Epoch 13 
2025-01-11 11:55:54.805887: Current learning rate: 0.00953 
2025-01-11 11:56:34.959691: train_loss -0.6005 
2025-01-11 11:56:34.959691: val_loss -0.5383 
2025-01-11 11:56:34.964705: Pseudo dice [np.float32(0.6275)] 
2025-01-11 11:56:34.968214: Epoch time: 40.16 s 
2025-01-11 11:56:34.970720: Yayy! New best EMA pseudo Dice: 0.5317999720573425 
2025-01-11 11:56:35.710156:  
2025-01-11 11:56:35.711159: Epoch 14 
2025-01-11 11:56:35.716197: Current learning rate: 0.00949 
2025-01-11 11:57:15.852705: train_loss -0.6101 
2025-01-11 11:57:15.852705: val_loss -0.5732 
2025-01-11 11:57:15.858722: Pseudo dice [np.float32(0.6549)] 
2025-01-11 11:57:15.862230: Epoch time: 40.14 s 
2025-01-11 11:57:15.865239: Yayy! New best EMA pseudo Dice: 0.5440999865531921 
2025-01-11 11:57:16.626863:  
2025-01-11 11:57:16.626863: Epoch 15 
2025-01-11 11:57:16.632408: Current learning rate: 0.00946 
2025-01-11 11:57:56.815361: train_loss -0.6184 
2025-01-11 11:57:56.815871: val_loss -0.5265 
2025-01-11 11:57:56.821450: Pseudo dice [np.float32(0.6313)] 
2025-01-11 11:57:56.825016: Epoch time: 40.19 s 
2025-01-11 11:57:56.828133: Yayy! New best EMA pseudo Dice: 0.5527999997138977 
2025-01-11 11:57:57.578460:  
2025-01-11 11:57:57.579458: Epoch 16 
2025-01-11 11:57:57.584471: Current learning rate: 0.00942 
2025-01-11 11:58:37.708973: train_loss -0.6131 
2025-01-11 11:58:37.709482: val_loss -0.5731 
2025-01-11 11:58:37.714586: Pseudo dice [np.float32(0.6498)] 
2025-01-11 11:58:37.718116: Epoch time: 40.13 s 
2025-01-11 11:58:37.721277: Yayy! New best EMA pseudo Dice: 0.5625 
2025-01-11 11:58:38.482638:  
2025-01-11 11:58:38.483642: Epoch 17 
2025-01-11 11:58:38.488740: Current learning rate: 0.00939 
2025-01-11 11:59:18.620591: train_loss -0.6369 
2025-01-11 11:59:18.621096: val_loss -0.5174 
2025-01-11 11:59:18.626168: Pseudo dice [np.float32(0.6312)] 
2025-01-11 11:59:18.630206: Epoch time: 40.14 s 
2025-01-11 11:59:18.633248: Yayy! New best EMA pseudo Dice: 0.5694000124931335 
2025-01-11 11:59:19.394080:  
2025-01-11 11:59:19.394080: Epoch 18 
2025-01-11 11:59:19.399091: Current learning rate: 0.00935 
2025-01-11 11:59:59.542838: train_loss -0.6106 
2025-01-11 11:59:59.543340: val_loss -0.563 
2025-01-11 11:59:59.550386: Pseudo dice [np.float32(0.6613)] 
2025-01-11 11:59:59.553407: Epoch time: 40.15 s 
2025-01-11 11:59:59.556430: Yayy! New best EMA pseudo Dice: 0.5785999894142151 
2025-01-11 12:00:00.302849:  
2025-01-11 12:00:00.302849: Epoch 19 
2025-01-11 12:00:00.308865: Current learning rate: 0.00931 
2025-01-11 12:00:40.436260: train_loss -0.6318 
2025-01-11 12:00:40.436767: val_loss -0.5774 
2025-01-11 12:00:40.442857: Pseudo dice [np.float32(0.6721)] 
2025-01-11 12:00:40.445904: Epoch time: 40.13 s 
2025-01-11 12:00:40.447925: Yayy! New best EMA pseudo Dice: 0.5878999829292297 
2025-01-11 12:00:41.375988:  
2025-01-11 12:00:41.375988: Epoch 20 
2025-01-11 12:00:41.382003: Current learning rate: 0.00928 
2025-01-11 12:01:21.486706: train_loss -0.6465 
2025-01-11 12:01:21.486706: val_loss -0.5889 
2025-01-11 12:01:21.493725: Pseudo dice [np.float32(0.6874)] 
2025-01-11 12:01:21.496739: Epoch time: 40.11 s 
2025-01-11 12:01:21.500252: Yayy! New best EMA pseudo Dice: 0.5978999733924866 
2025-01-11 12:01:22.266178:  
2025-01-11 12:01:22.266681: Epoch 21 
2025-01-11 12:01:22.271693: Current learning rate: 0.00924 
2025-01-11 12:02:02.384543: train_loss -0.6263 
2025-01-11 12:02:02.385046: val_loss -0.583 
2025-01-11 12:02:02.390058: Pseudo dice [np.float32(0.6698)] 
2025-01-11 12:02:02.393568: Epoch time: 40.12 s 
2025-01-11 12:02:02.397074: Yayy! New best EMA pseudo Dice: 0.6050999760627747 
2025-01-11 12:02:03.129394:  
2025-01-11 12:02:03.129394: Epoch 22 
2025-01-11 12:02:03.134405: Current learning rate: 0.0092 
2025-01-11 12:02:43.265279: train_loss -0.6361 
2025-01-11 12:02:43.265279: val_loss -0.5407 
2025-01-11 12:02:43.271296: Pseudo dice [np.float32(0.6405)] 
2025-01-11 12:02:43.275305: Epoch time: 40.14 s 
2025-01-11 12:02:43.278815: Yayy! New best EMA pseudo Dice: 0.6086000204086304 
2025-01-11 12:02:44.017587:  
2025-01-11 12:02:44.018591: Epoch 23 
2025-01-11 12:02:44.023132: Current learning rate: 0.00917 
2025-01-11 12:03:24.174645: train_loss -0.6284 
2025-01-11 12:03:24.175149: val_loss -0.5401 
2025-01-11 12:03:24.180700: Pseudo dice [np.float32(0.6461)] 
2025-01-11 12:03:24.184728: Epoch time: 40.16 s 
2025-01-11 12:03:24.187746: Yayy! New best EMA pseudo Dice: 0.6123999953269958 
2025-01-11 12:03:24.921512:  
2025-01-11 12:03:24.921512: Epoch 24 
2025-01-11 12:03:24.927056: Current learning rate: 0.00913 
2025-01-11 12:04:05.086594: train_loss -0.6447 
2025-01-11 12:04:05.087599: val_loss -0.5474 
2025-01-11 12:04:05.093221: Pseudo dice [np.float32(0.6474)] 
2025-01-11 12:04:05.096778: Epoch time: 40.17 s 
2025-01-11 12:04:05.099922: Yayy! New best EMA pseudo Dice: 0.6158999800682068 
2025-01-11 12:04:05.849506:  
2025-01-11 12:04:05.849506: Epoch 25 
2025-01-11 12:04:05.856188: Current learning rate: 0.0091 
2025-01-11 12:04:45.971586: train_loss -0.6593 
2025-01-11 12:04:45.971586: val_loss -0.5858 
2025-01-11 12:04:45.979134: Pseudo dice [np.float32(0.67)] 
2025-01-11 12:04:45.982180: Epoch time: 40.12 s 
2025-01-11 12:04:45.985224: Yayy! New best EMA pseudo Dice: 0.6212999820709229 
2025-01-11 12:04:46.759436:  
2025-01-11 12:04:46.760951: Epoch 26 
2025-01-11 12:04:46.766022: Current learning rate: 0.00906 
2025-01-11 12:05:26.892490: train_loss -0.6845 
2025-01-11 12:05:26.893013: val_loss -0.5435 
2025-01-11 12:05:26.898089: Pseudo dice [np.float32(0.645)] 
2025-01-11 12:05:26.901601: Epoch time: 40.13 s 
2025-01-11 12:05:26.904109: Yayy! New best EMA pseudo Dice: 0.6236000061035156 
2025-01-11 12:05:27.646115:  
2025-01-11 12:05:27.646115: Epoch 27 
2025-01-11 12:05:27.651126: Current learning rate: 0.00902 
2025-01-11 12:06:07.871440: train_loss -0.6774 
2025-01-11 12:06:07.872439: val_loss -0.5901 
2025-01-11 12:06:07.877953: Pseudo dice [np.float32(0.6732)] 
2025-01-11 12:06:07.881466: Epoch time: 40.23 s 
2025-01-11 12:06:07.883973: Yayy! New best EMA pseudo Dice: 0.628600001335144 
2025-01-11 12:06:08.809388:  
2025-01-11 12:06:08.809892: Epoch 28 
2025-01-11 12:06:08.814975: Current learning rate: 0.00899 
2025-01-11 12:06:48.940944: train_loss -0.6773 
2025-01-11 12:06:48.940944: val_loss -0.5378 
2025-01-11 12:06:48.947120: Pseudo dice [np.float32(0.6158)] 
2025-01-11 12:06:48.950190: Epoch time: 40.13 s 
2025-01-11 12:06:49.521375:  
2025-01-11 12:06:49.522375: Epoch 29 
2025-01-11 12:06:49.527889: Current learning rate: 0.00895 
2025-01-11 12:07:29.639426: train_loss -0.6999 
2025-01-11 12:07:29.639935: val_loss -0.5873 
2025-01-11 12:07:29.645524: Pseudo dice [np.float32(0.6838)] 
2025-01-11 12:07:29.648601: Epoch time: 40.12 s 
2025-01-11 12:07:29.651145: Yayy! New best EMA pseudo Dice: 0.6330000162124634 
2025-01-11 12:07:30.436796:  
2025-01-11 12:07:30.436796: Epoch 30 
2025-01-11 12:07:30.444356: Current learning rate: 0.00891 
2025-01-11 12:08:10.601494: train_loss -0.6809 
2025-01-11 12:08:10.602494: val_loss -0.5165 
2025-01-11 12:08:10.608041: Pseudo dice [np.float32(0.5959)] 
2025-01-11 12:08:10.611551: Epoch time: 40.17 s 
2025-01-11 12:08:11.202969:  
2025-01-11 12:08:11.203972: Epoch 31 
2025-01-11 12:08:11.208525: Current learning rate: 0.00888 
2025-01-11 12:08:51.353683: train_loss -0.6752 
2025-01-11 12:08:51.354193: val_loss -0.618 
2025-01-11 12:08:51.359525: Pseudo dice [np.float32(0.7062)] 
2025-01-11 12:08:51.362584: Epoch time: 40.15 s 
2025-01-11 12:08:51.366126: Yayy! New best EMA pseudo Dice: 0.6370000243186951 
2025-01-11 12:08:52.121514:  
2025-01-11 12:08:52.121514: Epoch 32 
2025-01-11 12:08:52.126569: Current learning rate: 0.00884 
2025-01-11 12:09:32.287266: train_loss -0.6929 
2025-01-11 12:09:32.287266: val_loss -0.5693 
2025-01-11 12:09:32.292368: Pseudo dice [np.float32(0.6713)] 
2025-01-11 12:09:32.294909: Epoch time: 40.17 s 
2025-01-11 12:09:32.298951: Yayy! New best EMA pseudo Dice: 0.6403999924659729 
2025-01-11 12:09:33.064637:  
2025-01-11 12:09:33.065640: Epoch 33 
2025-01-11 12:09:33.070672: Current learning rate: 0.0088 
2025-01-11 12:10:13.231091: train_loss -0.6823 
2025-01-11 12:10:13.232094: val_loss -0.5582 
2025-01-11 12:10:13.238111: Pseudo dice [np.float32(0.6419)] 
2025-01-11 12:10:13.241121: Epoch time: 40.17 s 
2025-01-11 12:10:13.244638: Yayy! New best EMA pseudo Dice: 0.640500009059906 
2025-01-11 12:10:14.000217:  
2025-01-11 12:10:14.000726: Epoch 34 
2025-01-11 12:10:14.006310: Current learning rate: 0.00877 
2025-01-11 12:10:54.171814: train_loss -0.6558 
2025-01-11 12:10:54.171814: val_loss -0.5725 
2025-01-11 12:10:54.178334: Pseudo dice [np.float32(0.6969)] 
2025-01-11 12:10:54.180842: Epoch time: 40.17 s 
2025-01-11 12:10:54.184355: Yayy! New best EMA pseudo Dice: 0.6462000012397766 
2025-01-11 12:10:54.934217:  
2025-01-11 12:10:54.934217: Epoch 35 
2025-01-11 12:10:54.939229: Current learning rate: 0.00873 
2025-01-11 12:11:35.116245: train_loss -0.6647 
2025-01-11 12:11:35.117250: val_loss -0.5792 
2025-01-11 12:11:35.122272: Pseudo dice [np.float32(0.685)] 
2025-01-11 12:11:35.125780: Epoch time: 40.18 s 
2025-01-11 12:11:35.128792: Yayy! New best EMA pseudo Dice: 0.6500999927520752 
2025-01-11 12:11:36.102747:  
2025-01-11 12:11:36.103754: Epoch 36 
2025-01-11 12:11:36.108288: Current learning rate: 0.00869 
2025-01-11 12:12:16.267040: train_loss -0.6869 
2025-01-11 12:12:16.267040: val_loss -0.6371 
2025-01-11 12:12:16.273055: Pseudo dice [np.float32(0.7284)] 
2025-01-11 12:12:16.275563: Epoch time: 40.16 s 
2025-01-11 12:12:16.279068: Yayy! New best EMA pseudo Dice: 0.6578999757766724 
2025-01-11 12:12:17.049046:  
2025-01-11 12:12:17.050050: Epoch 37 
2025-01-11 12:12:17.054609: Current learning rate: 0.00866 
2025-01-11 12:12:57.189839: train_loss -0.708 
2025-01-11 12:12:57.190347: val_loss -0.628 
2025-01-11 12:12:57.196106: Pseudo dice [np.float32(0.7077)] 
2025-01-11 12:12:57.199671: Epoch time: 40.14 s 
2025-01-11 12:12:57.202214: Yayy! New best EMA pseudo Dice: 0.6628999710083008 
2025-01-11 12:12:57.996807:  
2025-01-11 12:12:57.997310: Epoch 38 
2025-01-11 12:12:58.002332: Current learning rate: 0.00862 
2025-01-11 12:13:38.207169: train_loss -0.6871 
2025-01-11 12:13:38.207169: val_loss -0.6065 
2025-01-11 12:13:38.213688: Pseudo dice [np.float32(0.7034)] 
2025-01-11 12:13:38.216724: Epoch time: 40.21 s 
2025-01-11 12:13:38.219230: Yayy! New best EMA pseudo Dice: 0.6668999791145325 
2025-01-11 12:13:38.971534:  
2025-01-11 12:13:38.971534: Epoch 39 
2025-01-11 12:13:38.976545: Current learning rate: 0.00858 
2025-01-11 12:14:19.130462: train_loss -0.7144 
2025-01-11 12:14:19.131485: val_loss -0.6373 
2025-01-11 12:14:19.136497: Pseudo dice [np.float32(0.7174)] 
2025-01-11 12:14:19.140006: Epoch time: 40.16 s 
2025-01-11 12:14:19.142513: Yayy! New best EMA pseudo Dice: 0.671999990940094 
2025-01-11 12:14:19.910331:  
2025-01-11 12:14:19.910331: Epoch 40 
2025-01-11 12:14:19.915343: Current learning rate: 0.00855 
2025-01-11 12:15:00.075423: train_loss -0.709 
2025-01-11 12:15:00.075423: val_loss -0.558 
2025-01-11 12:15:00.081461: Pseudo dice [np.float32(0.653)] 
2025-01-11 12:15:00.084986: Epoch time: 40.17 s 
2025-01-11 12:15:00.683764:  
2025-01-11 12:15:00.684764: Epoch 41 
2025-01-11 12:15:00.689823: Current learning rate: 0.00851 
2025-01-11 12:15:40.853680: train_loss -0.7222 
2025-01-11 12:15:40.854192: val_loss -0.5425 
2025-01-11 12:15:40.859797: Pseudo dice [np.float32(0.6406)] 
2025-01-11 12:15:40.862345: Epoch time: 40.17 s 
2025-01-11 12:15:41.423565:  
2025-01-11 12:15:41.423565: Epoch 42 
2025-01-11 12:15:41.427633: Current learning rate: 0.00847 
2025-01-11 12:16:21.562805: train_loss -0.7147 
2025-01-11 12:16:21.563311: val_loss -0.6129 
2025-01-11 12:16:21.568359: Pseudo dice [np.float32(0.7125)] 
2025-01-11 12:16:21.571885: Epoch time: 40.14 s 
2025-01-11 12:16:22.289710:  
2025-01-11 12:16:22.289710: Epoch 43 
2025-01-11 12:16:22.295836: Current learning rate: 0.00844 
2025-01-11 12:17:02.433748: train_loss -0.701 
2025-01-11 12:17:02.433748: val_loss -0.5594 
2025-01-11 12:17:02.440156: Pseudo dice [np.float32(0.6753)] 
2025-01-11 12:17:02.444263: Epoch time: 40.15 s 
2025-01-11 12:17:02.446769: Yayy! New best EMA pseudo Dice: 0.671999990940094 
2025-01-11 12:17:03.183043:  
2025-01-11 12:17:03.183043: Epoch 44 
2025-01-11 12:17:03.189145: Current learning rate: 0.0084 
2025-01-11 12:17:43.307950: train_loss -0.7073 
2025-01-11 12:17:43.307950: val_loss -0.5804 
2025-01-11 12:17:43.314001: Pseudo dice [np.float32(0.6878)] 
2025-01-11 12:17:43.317562: Epoch time: 40.12 s 
2025-01-11 12:17:43.320109: Yayy! New best EMA pseudo Dice: 0.6736000180244446 
2025-01-11 12:17:44.074582:  
2025-01-11 12:17:44.075585: Epoch 45 
2025-01-11 12:17:44.080276: Current learning rate: 0.00836 
2025-01-11 12:18:24.220263: train_loss -0.7353 
2025-01-11 12:18:24.221263: val_loss -0.5915 
2025-01-11 12:18:24.226778: Pseudo dice [np.float32(0.6671)] 
2025-01-11 12:18:24.230286: Epoch time: 40.15 s 
2025-01-11 12:18:24.801916:  
2025-01-11 12:18:24.801916: Epoch 46 
2025-01-11 12:18:24.806928: Current learning rate: 0.00833 
2025-01-11 12:19:04.956504: train_loss -0.7376 
2025-01-11 12:19:04.957009: val_loss -0.6102 
2025-01-11 12:19:04.964027: Pseudo dice [np.float32(0.7278)] 
2025-01-11 12:19:04.968040: Epoch time: 40.16 s 
2025-01-11 12:19:04.970550: Yayy! New best EMA pseudo Dice: 0.6783999800682068 
2025-01-11 12:19:05.743224:  
2025-01-11 12:19:05.743224: Epoch 47 
2025-01-11 12:19:05.748235: Current learning rate: 0.00829 
2025-01-11 12:19:45.869028: train_loss -0.7179 
2025-01-11 12:19:45.869028: val_loss -0.6405 
2025-01-11 12:19:45.875061: Pseudo dice [np.float32(0.7105)] 
2025-01-11 12:19:45.879091: Epoch time: 40.13 s 
2025-01-11 12:19:45.882155: Yayy! New best EMA pseudo Dice: 0.6815999746322632 
2025-01-11 12:19:46.615426:  
2025-01-11 12:19:46.615426: Epoch 48 
2025-01-11 12:19:46.621528: Current learning rate: 0.00825 
2025-01-11 12:20:26.747401: train_loss -0.7324 
2025-01-11 12:20:26.748404: val_loss -0.6307 
2025-01-11 12:20:26.753416: Pseudo dice [np.float32(0.7192)] 
2025-01-11 12:20:26.757424: Epoch time: 40.13 s 
2025-01-11 12:20:26.759931: Yayy! New best EMA pseudo Dice: 0.6854000091552734 
2025-01-11 12:20:27.514237:  
2025-01-11 12:20:27.515240: Epoch 49 
2025-01-11 12:20:27.519801: Current learning rate: 0.00822 
2025-01-11 12:21:07.748384: train_loss -0.7473 
2025-01-11 12:21:07.748384: val_loss -0.6019 
2025-01-11 12:21:07.754403: Pseudo dice [np.float32(0.6791)] 
2025-01-11 12:21:07.757417: Epoch time: 40.23 s 
2025-01-11 12:21:08.504584:  
2025-01-11 12:21:08.505585: Epoch 50 
2025-01-11 12:21:08.510660: Current learning rate: 0.00818 
2025-01-11 12:21:48.634627: train_loss -0.743 
2025-01-11 12:21:48.635656: val_loss -0.5396 
2025-01-11 12:21:48.642300: Pseudo dice [np.float32(0.6537)] 
2025-01-11 12:21:48.645935: Epoch time: 40.13 s 
2025-01-11 12:21:49.383557:  
2025-01-11 12:21:49.383557: Epoch 51 
2025-01-11 12:21:49.389116: Current learning rate: 0.00814 
2025-01-11 12:22:29.498528: train_loss -0.7496 
2025-01-11 12:22:29.499030: val_loss -0.6457 
2025-01-11 12:22:29.504048: Pseudo dice [np.float32(0.7287)] 
2025-01-11 12:22:29.507561: Epoch time: 40.12 s 
2025-01-11 12:22:29.510066: Yayy! New best EMA pseudo Dice: 0.6863999962806702 
2025-01-11 12:22:30.268174:  
2025-01-11 12:22:30.268174: Epoch 52 
2025-01-11 12:22:30.273184: Current learning rate: 0.00811 
2025-01-11 12:23:10.392909: train_loss -0.7522 
2025-01-11 12:23:10.393411: val_loss -0.5206 
2025-01-11 12:23:10.399434: Pseudo dice [np.float32(0.642)] 
2025-01-11 12:23:10.402948: Epoch time: 40.13 s 
2025-01-11 12:23:10.983833:  
2025-01-11 12:23:10.984837: Epoch 53 
2025-01-11 12:23:10.989369: Current learning rate: 0.00807 
2025-01-11 12:23:51.108897: train_loss -0.7492 
2025-01-11 12:23:51.109400: val_loss -0.67 
2025-01-11 12:23:51.116413: Pseudo dice [np.float32(0.7488)] 
2025-01-11 12:23:51.119422: Epoch time: 40.13 s 
2025-01-11 12:23:51.121927: Yayy! New best EMA pseudo Dice: 0.6886000037193298 
2025-01-11 12:23:51.875088:  
2025-01-11 12:23:51.875088: Epoch 54 
2025-01-11 12:23:51.880099: Current learning rate: 0.00803 
2025-01-11 12:24:31.994581: train_loss -0.7333 
2025-01-11 12:24:31.994581: val_loss -0.6025 
2025-01-11 12:24:32.001102: Pseudo dice [np.float32(0.6917)] 
2025-01-11 12:24:32.003608: Epoch time: 40.12 s 
2025-01-11 12:24:32.007118: Yayy! New best EMA pseudo Dice: 0.6888999938964844 
2025-01-11 12:24:32.774112:  
2025-01-11 12:24:32.774112: Epoch 55 
2025-01-11 12:24:32.779638: Current learning rate: 0.008 
2025-01-11 12:25:12.917045: train_loss -0.7339 
2025-01-11 12:25:12.917547: val_loss -0.6358 
2025-01-11 12:25:12.923566: Pseudo dice [np.float32(0.7248)] 
2025-01-11 12:25:12.926078: Epoch time: 40.14 s 
2025-01-11 12:25:12.929584: Yayy! New best EMA pseudo Dice: 0.6924999952316284 
2025-01-11 12:25:13.676954:  
2025-01-11 12:25:13.677958: Epoch 56 
2025-01-11 12:25:13.682023: Current learning rate: 0.00796 
2025-01-11 12:25:53.828698: train_loss -0.7425 
2025-01-11 12:25:53.829200: val_loss -0.5546 
2025-01-11 12:25:53.835327: Pseudo dice [np.float32(0.6283)] 
2025-01-11 12:25:53.838368: Epoch time: 40.15 s 
2025-01-11 12:25:54.431843:  
2025-01-11 12:25:54.432346: Epoch 57 
2025-01-11 12:25:54.437357: Current learning rate: 0.00792 
2025-01-11 12:26:34.584261: train_loss -0.7436 
2025-01-11 12:26:34.584771: val_loss -0.6644 
2025-01-11 12:26:34.590318: Pseudo dice [np.float32(0.7589)] 
2025-01-11 12:26:34.592827: Epoch time: 40.15 s 
2025-01-11 12:26:34.596339: Yayy! New best EMA pseudo Dice: 0.6934000253677368 
2025-01-11 12:26:35.347584:  
2025-01-11 12:26:35.348584: Epoch 58 
2025-01-11 12:26:35.353596: Current learning rate: 0.00789 
2025-01-11 12:27:20.521177: train_loss -0.7576 
2025-01-11 12:27:20.522181: val_loss -0.6421 
2025-01-11 12:27:20.527701: Pseudo dice [np.float32(0.7283)] 
2025-01-11 12:27:20.531213: Epoch time: 45.17 s 
2025-01-11 12:27:20.533921: Yayy! New best EMA pseudo Dice: 0.6969000101089478 
2025-01-11 12:27:21.490680:  
2025-01-11 12:27:21.491182: Epoch 59 
2025-01-11 12:27:21.496193: Current learning rate: 0.00785 
2025-01-11 12:28:01.799303: train_loss -0.7733 
2025-01-11 12:28:01.800306: val_loss -0.6655 
2025-01-11 12:28:01.805319: Pseudo dice [np.float32(0.7606)] 
2025-01-11 12:28:01.808830: Epoch time: 40.31 s 
2025-01-11 12:28:01.811846: Yayy! New best EMA pseudo Dice: 0.7031999826431274 
2025-01-11 12:28:02.582277:  
2025-01-11 12:28:02.583277: Epoch 60 
2025-01-11 12:28:02.588406: Current learning rate: 0.00781 
2025-01-11 12:28:42.986760: train_loss -0.7548 
2025-01-11 12:28:42.988267: val_loss -0.5959 
2025-01-11 12:28:42.994386: Pseudo dice [np.float32(0.7066)] 
2025-01-11 12:28:42.997443: Epoch time: 40.4 s 
2025-01-11 12:28:43.000496: Yayy! New best EMA pseudo Dice: 0.7035999894142151 
2025-01-11 12:28:43.738105:  
2025-01-11 12:28:43.738609: Epoch 61 
2025-01-11 12:28:43.743622: Current learning rate: 0.00777 
2025-01-11 12:29:24.177393: train_loss -0.7556 
2025-01-11 12:29:24.177896: val_loss -0.5847 
2025-01-11 12:29:24.183528: Pseudo dice [np.float32(0.6904)] 
2025-01-11 12:29:24.187098: Epoch time: 40.44 s 
2025-01-11 12:29:24.763053:  
2025-01-11 12:29:24.763451: Epoch 62 
2025-01-11 12:29:24.768584: Current learning rate: 0.00774 
2025-01-11 12:30:05.133301: train_loss -0.7538 
2025-01-11 12:30:05.134305: val_loss -0.614 
2025-01-11 12:30:05.140321: Pseudo dice [np.float32(0.695)] 
2025-01-11 12:30:05.143332: Epoch time: 40.37 s 
2025-01-11 12:30:05.717236:  
2025-01-11 12:30:05.718236: Epoch 63 
2025-01-11 12:30:05.723842: Current learning rate: 0.0077 
2025-01-11 12:30:46.062316: train_loss -0.7348 
2025-01-11 12:30:46.062831: val_loss -0.6341 
2025-01-11 12:30:46.068931: Pseudo dice [np.float32(0.7105)] 
2025-01-11 12:30:46.071961: Epoch time: 40.35 s 
2025-01-11 12:30:46.647774:  
2025-01-11 12:30:46.648276: Epoch 64 
2025-01-11 12:30:46.653288: Current learning rate: 0.00766 
2025-01-11 12:31:27.034095: train_loss -0.7631 
2025-01-11 12:31:27.034597: val_loss -0.5651 
2025-01-11 12:31:27.039611: Pseudo dice [np.float32(0.6935)] 
2025-01-11 12:31:27.043121: Epoch time: 40.39 s 
2025-01-11 12:31:27.625671:  
2025-01-11 12:31:27.625671: Epoch 65 
2025-01-11 12:31:27.630683: Current learning rate: 0.00763 
2025-01-11 12:32:08.057888: train_loss -0.7591 
2025-01-11 12:32:08.058392: val_loss -0.5791 
2025-01-11 12:32:08.064407: Pseudo dice [np.float32(0.6607)] 
2025-01-11 12:32:08.066913: Epoch time: 40.43 s 
2025-01-11 12:32:08.647428:  
2025-01-11 12:32:08.648431: Epoch 66 
2025-01-11 12:32:08.653049: Current learning rate: 0.00759 
2025-01-11 12:32:49.149625: train_loss -0.7406 
2025-01-11 12:32:49.150625: val_loss -0.6408 
2025-01-11 12:32:49.157142: Pseudo dice [np.float32(0.7291)] 
2025-01-11 12:32:49.160648: Epoch time: 40.5 s 
2025-01-11 12:32:49.962797:  
2025-01-11 12:32:49.962797: Epoch 67 
2025-01-11 12:32:49.967808: Current learning rate: 0.00755 
2025-01-11 12:33:30.349603: train_loss -0.7454 
2025-01-11 12:33:30.349603: val_loss -0.6589 
2025-01-11 12:33:30.356121: Pseudo dice [np.float32(0.7401)] 
2025-01-11 12:33:30.359645: Epoch time: 40.39 s 
2025-01-11 12:33:30.362151: Yayy! New best EMA pseudo Dice: 0.7045999765396118 
2025-01-11 12:33:31.127211:  
2025-01-11 12:33:31.128713: Epoch 68 
2025-01-11 12:33:31.133725: Current learning rate: 0.00751 
2025-01-11 12:34:11.556078: train_loss -0.761 
2025-01-11 12:34:11.556581: val_loss -0.6283 
2025-01-11 12:34:11.561593: Pseudo dice [np.float32(0.713)] 
2025-01-11 12:34:11.565102: Epoch time: 40.43 s 
2025-01-11 12:34:11.568610: Yayy! New best EMA pseudo Dice: 0.7053999900817871 
2025-01-11 12:34:12.353567:  
2025-01-11 12:34:12.353567: Epoch 69 
2025-01-11 12:34:12.357080: Current learning rate: 0.00748 
2025-01-11 12:34:52.698284: train_loss -0.7286 
2025-01-11 12:34:52.698284: val_loss -0.6351 
2025-01-11 12:34:52.704305: Pseudo dice [np.float32(0.6999)] 
2025-01-11 12:34:52.706814: Epoch time: 40.35 s 
2025-01-11 12:34:53.327208:  
2025-01-11 12:34:53.327208: Epoch 70 
2025-01-11 12:34:53.333234: Current learning rate: 0.00744 
2025-01-11 12:35:34.545323: train_loss -0.7684 
2025-01-11 12:35:34.545835: val_loss -0.6232 
2025-01-11 12:35:34.550454: Pseudo dice [np.float32(0.7323)] 
2025-01-11 12:35:34.554480: Epoch time: 41.22 s 
2025-01-11 12:35:34.558021: Yayy! New best EMA pseudo Dice: 0.7075999975204468 
2025-01-11 12:35:35.388609:  
2025-01-11 12:35:35.388609: Epoch 71 
2025-01-11 12:35:35.393620: Current learning rate: 0.0074 
2025-01-11 12:36:15.875835: train_loss -0.771 
2025-01-11 12:36:15.876344: val_loss -0.5762 
2025-01-11 12:36:15.882896: Pseudo dice [np.float32(0.6718)] 
2025-01-11 12:36:15.885924: Epoch time: 40.49 s 
2025-01-11 12:36:16.576816:  
2025-01-11 12:36:16.577319: Epoch 72 
2025-01-11 12:36:16.582330: Current learning rate: 0.00737 
2025-01-11 12:36:57.383429: train_loss -0.7738 
2025-01-11 12:36:57.383949: val_loss -0.6255 
2025-01-11 12:36:57.389518: Pseudo dice [np.float32(0.7156)] 
2025-01-11 12:36:57.394076: Epoch time: 40.81 s 
2025-01-11 12:36:57.945259:  
2025-01-11 12:36:57.946259: Epoch 73 
2025-01-11 12:36:57.951469: Current learning rate: 0.00733 
2025-01-11 12:37:38.306043: train_loss -0.7565 
2025-01-11 12:37:38.306043: val_loss -0.6224 
2025-01-11 12:37:38.312394: Pseudo dice [np.float32(0.7183)] 
2025-01-11 12:37:38.316905: Epoch time: 40.36 s 
2025-01-11 12:37:38.863846:  
2025-01-11 12:37:38.863846: Epoch 74 
2025-01-11 12:37:38.869897: Current learning rate: 0.00729 
2025-01-11 12:38:19.023691: train_loss -0.756 
2025-01-11 12:38:19.023691: val_loss -0.5254 
2025-01-11 12:38:19.030206: Pseudo dice [np.float32(0.6524)] 
2025-01-11 12:38:19.034717: Epoch time: 40.16 s 
2025-01-11 12:38:19.805873:  
2025-01-11 12:38:19.805873: Epoch 75 
2025-01-11 12:38:19.811972: Current learning rate: 0.00725 
2025-01-11 12:39:00.727510: train_loss -0.7701 
2025-01-11 12:39:00.728509: val_loss -0.6487 
2025-01-11 12:39:00.734026: Pseudo dice [np.float32(0.7342)] 
2025-01-11 12:39:00.738039: Epoch time: 40.92 s 
2025-01-11 12:39:01.316473:  
2025-01-11 12:39:01.316975: Epoch 76 
2025-01-11 12:39:01.321989: Current learning rate: 0.00722 
2025-01-11 12:39:42.226570: train_loss -0.7701 
2025-01-11 12:39:42.227072: val_loss -0.6451 
2025-01-11 12:39:42.232082: Pseudo dice [np.float32(0.7285)] 
2025-01-11 12:39:42.237097: Epoch time: 40.91 s 
2025-01-11 12:39:42.804010:  
2025-01-11 12:39:42.805013: Epoch 77 
2025-01-11 12:39:42.809571: Current learning rate: 0.00718 
2025-01-11 12:40:23.876631: train_loss -0.7601 
2025-01-11 12:40:23.877631: val_loss -0.6354 
2025-01-11 12:40:23.883146: Pseudo dice [np.float32(0.7204)] 
2025-01-11 12:40:23.886659: Epoch time: 41.07 s 
2025-01-11 12:40:23.889165: Yayy! New best EMA pseudo Dice: 0.7081999778747559 
2025-01-11 12:40:24.717274:  
2025-01-11 12:40:24.718279: Epoch 78 
2025-01-11 12:40:24.722871: Current learning rate: 0.00714 
2025-01-11 12:41:05.315774: train_loss -0.7589 
2025-01-11 12:41:05.315774: val_loss -0.5877 
2025-01-11 12:41:05.322357: Pseudo dice [np.float32(0.697)] 
2025-01-11 12:41:05.325977: Epoch time: 40.6 s 
2025-01-11 12:41:05.898348:  
2025-01-11 12:41:05.898348: Epoch 79 
2025-01-11 12:41:05.903360: Current learning rate: 0.0071 
2025-01-11 12:41:46.210995: train_loss -0.7866 
2025-01-11 12:41:46.211509: val_loss -0.6477 
2025-01-11 12:41:46.217615: Pseudo dice [np.float32(0.7399)] 
2025-01-11 12:41:46.220146: Epoch time: 40.31 s 
2025-01-11 12:41:46.224251: Yayy! New best EMA pseudo Dice: 0.7103000283241272 
2025-01-11 12:41:46.978458:  
2025-01-11 12:41:46.979461: Epoch 80 
2025-01-11 12:41:46.984546: Current learning rate: 0.00707 
2025-01-11 12:42:27.294348: train_loss -0.7866 
2025-01-11 12:42:27.295348: val_loss -0.6096 
2025-01-11 12:42:27.300368: Pseudo dice [np.float32(0.715)] 
2025-01-11 12:42:27.304390: Epoch time: 40.32 s 
2025-01-11 12:42:27.309408: Yayy! New best EMA pseudo Dice: 0.7107999920845032 
2025-01-11 12:42:28.258964:  
2025-01-11 12:42:28.258964: Epoch 81 
2025-01-11 12:42:28.264990: Current learning rate: 0.00703 
2025-01-11 12:43:08.599356: train_loss -0.8038 
2025-01-11 12:43:08.599356: val_loss -0.6085 
2025-01-11 12:43:08.605565: Pseudo dice [np.float32(0.7168)] 
2025-01-11 12:43:08.610147: Epoch time: 40.34 s 
2025-01-11 12:43:08.613723: Yayy! New best EMA pseudo Dice: 0.7113999724388123 
2025-01-11 12:43:09.438704:  
2025-01-11 12:43:09.438704: Epoch 82 
2025-01-11 12:43:09.444273: Current learning rate: 0.00699 
2025-01-11 12:43:49.765823: train_loss -0.7882 
2025-01-11 12:43:49.766326: val_loss -0.6163 
2025-01-11 12:43:49.771346: Pseudo dice [np.float32(0.7139)] 
2025-01-11 12:43:49.774858: Epoch time: 40.33 s 
2025-01-11 12:43:49.778876: Yayy! New best EMA pseudo Dice: 0.7117000222206116 
2025-01-11 12:43:50.706981:  
2025-01-11 12:43:50.707984: Epoch 83 
2025-01-11 12:43:50.714574: Current learning rate: 0.00696 
2025-01-11 12:44:31.035333: train_loss -0.8015 
2025-01-11 12:44:31.036336: val_loss -0.6413 
2025-01-11 12:44:31.042354: Pseudo dice [np.float32(0.7318)] 
2025-01-11 12:44:31.046367: Epoch time: 40.33 s 
2025-01-11 12:44:31.048874: Yayy! New best EMA pseudo Dice: 0.713699996471405 
2025-01-11 12:44:31.814129:  
2025-01-11 12:44:31.814129: Epoch 84 
2025-01-11 12:44:31.819219: Current learning rate: 0.00692 
2025-01-11 12:45:12.137122: train_loss -0.7951 
2025-01-11 12:45:12.137626: val_loss -0.6287 
2025-01-11 12:45:12.143642: Pseudo dice [np.float32(0.7228)] 
2025-01-11 12:45:12.147149: Epoch time: 40.32 s 
2025-01-11 12:45:12.150159: Yayy! New best EMA pseudo Dice: 0.7146000266075134 
2025-01-11 12:45:12.888282:  
2025-01-11 12:45:12.889282: Epoch 85 
2025-01-11 12:45:12.894866: Current learning rate: 0.00688 
2025-01-11 12:45:53.333896: train_loss -0.8032 
2025-01-11 12:45:53.334404: val_loss -0.6196 
2025-01-11 12:45:53.341473: Pseudo dice [np.float32(0.7194)] 
2025-01-11 12:45:53.346028: Epoch time: 40.45 s 
2025-01-11 12:45:53.349078: Yayy! New best EMA pseudo Dice: 0.7150999903678894 
2025-01-11 12:45:54.135355:  
2025-01-11 12:45:54.135355: Epoch 86 
2025-01-11 12:45:54.141438: Current learning rate: 0.00684 
2025-01-11 12:46:34.465866: train_loss -0.802 
2025-01-11 12:46:34.465866: val_loss -0.6184 
2025-01-11 12:46:34.471887: Pseudo dice [np.float32(0.7285)] 
2025-01-11 12:46:34.475898: Epoch time: 40.33 s 
2025-01-11 12:46:34.479484: Yayy! New best EMA pseudo Dice: 0.7164000272750854 
2025-01-11 12:46:35.225893:  
2025-01-11 12:46:35.226893: Epoch 87 
2025-01-11 12:46:35.231972: Current learning rate: 0.0068 
2025-01-11 12:47:15.549370: train_loss -0.8064 
2025-01-11 12:47:15.549873: val_loss -0.6194 
2025-01-11 12:47:15.555982: Pseudo dice [np.float32(0.7104)] 
2025-01-11 12:47:15.559038: Epoch time: 40.32 s 
2025-01-11 12:47:16.098536:  
2025-01-11 12:47:16.098536: Epoch 88 
2025-01-11 12:47:16.104065: Current learning rate: 0.00677 
2025-01-11 12:47:56.428405: train_loss -0.8079 
2025-01-11 12:47:56.429406: val_loss -0.6444 
2025-01-11 12:47:56.434926: Pseudo dice [np.float32(0.7471)] 
2025-01-11 12:47:56.438439: Epoch time: 40.33 s 
2025-01-11 12:47:56.441948: Yayy! New best EMA pseudo Dice: 0.7189000248908997 
2025-01-11 12:47:57.219746:  
2025-01-11 12:47:57.220747: Epoch 89 
2025-01-11 12:47:57.225798: Current learning rate: 0.00673 
2025-01-11 12:48:37.635829: train_loss -0.7957 
2025-01-11 12:48:37.635829: val_loss -0.6179 
2025-01-11 12:48:37.641397: Pseudo dice [np.float32(0.7172)] 
2025-01-11 12:48:37.645924: Epoch time: 40.42 s 
2025-01-11 12:48:38.196526:  
2025-01-11 12:48:38.196526: Epoch 90 
2025-01-11 12:48:38.201541: Current learning rate: 0.00669 
2025-01-11 12:49:18.625948: train_loss -0.8005 
2025-01-11 12:49:18.626452: val_loss -0.6348 
2025-01-11 12:49:18.631471: Pseudo dice [np.float32(0.7189)] 
2025-01-11 12:49:18.636490: Epoch time: 40.43 s 
2025-01-11 12:49:19.183367:  
2025-01-11 12:49:19.183367: Epoch 91 
2025-01-11 12:49:19.188931: Current learning rate: 0.00665 
2025-01-11 12:49:59.529036: train_loss -0.7999 
2025-01-11 12:49:59.529549: val_loss -0.6264 
2025-01-11 12:49:59.535246: Pseudo dice [np.float32(0.7179)] 
2025-01-11 12:49:59.539340: Epoch time: 40.35 s 
2025-01-11 12:50:00.095891:  
2025-01-11 12:50:00.095891: Epoch 92 
2025-01-11 12:50:00.100905: Current learning rate: 0.00662 
2025-01-11 12:50:40.422181: train_loss -0.8074 
2025-01-11 12:50:40.422181: val_loss -0.5949 
2025-01-11 12:50:40.427247: Pseudo dice [np.float32(0.7016)] 
2025-01-11 12:50:40.431892: Epoch time: 40.33 s 
2025-01-11 12:50:40.978620:  
2025-01-11 12:50:40.979123: Epoch 93 
2025-01-11 12:50:40.984134: Current learning rate: 0.00658 
2025-01-11 12:51:21.200253: train_loss -0.7965 
2025-01-11 12:51:21.200756: val_loss -0.6175 
2025-01-11 12:51:21.206770: Pseudo dice [np.float32(0.7063)] 
2025-01-11 12:51:21.210277: Epoch time: 40.22 s 
2025-01-11 12:51:21.742781:  
2025-01-11 12:51:21.744303: Epoch 94 
2025-01-11 12:51:21.749329: Current learning rate: 0.00654 
2025-01-11 12:52:01.818427: train_loss -0.806 
2025-01-11 12:52:01.819430: val_loss -0.6572 
2025-01-11 12:52:01.825480: Pseudo dice [np.float32(0.7569)] 
2025-01-11 12:52:01.828492: Epoch time: 40.08 s 
2025-01-11 12:52:01.833008: Yayy! New best EMA pseudo Dice: 0.7200000286102295 
2025-01-11 12:52:02.563518:  
2025-01-11 12:52:02.564020: Epoch 95 
2025-01-11 12:52:02.569035: Current learning rate: 0.0065 
2025-01-11 12:52:42.747803: train_loss -0.8107 
2025-01-11 12:52:42.748804: val_loss -0.6086 
2025-01-11 12:52:42.754317: Pseudo dice [np.float32(0.7206)] 
2025-01-11 12:52:42.757826: Epoch time: 40.19 s 
2025-01-11 12:52:42.761333: Yayy! New best EMA pseudo Dice: 0.7200999855995178 
2025-01-11 12:52:43.576204:  
2025-01-11 12:52:43.576204: Epoch 96 
2025-01-11 12:52:43.581218: Current learning rate: 0.00647 
2025-01-11 12:53:23.664521: train_loss -0.8131 
2025-01-11 12:53:23.665035: val_loss -0.6111 
2025-01-11 12:53:23.670650: Pseudo dice [np.float32(0.6919)] 
2025-01-11 12:53:23.673680: Epoch time: 40.09 s 
2025-01-11 12:53:24.221413:  
2025-01-11 12:53:24.221413: Epoch 97 
2025-01-11 12:53:24.226987: Current learning rate: 0.00643 
2025-01-11 12:54:04.325481: train_loss -0.8115 
2025-01-11 12:54:04.325481: val_loss -0.6717 
2025-01-11 12:54:04.332000: Pseudo dice [np.float32(0.756)] 
2025-01-11 12:54:04.335511: Epoch time: 40.11 s 
2025-01-11 12:54:04.339021: Yayy! New best EMA pseudo Dice: 0.7210999727249146 
2025-01-11 12:54:05.277153:  
2025-01-11 12:54:05.277655: Epoch 98 
2025-01-11 12:54:05.282664: Current learning rate: 0.00639 
2025-01-11 12:54:45.379019: train_loss -0.8021 
2025-01-11 12:54:45.379019: val_loss -0.6638 
2025-01-11 12:54:45.386128: Pseudo dice [np.float32(0.7586)] 
2025-01-11 12:54:45.389194: Epoch time: 40.1 s 
2025-01-11 12:54:45.392304: Yayy! New best EMA pseudo Dice: 0.7249000072479248 
2025-01-11 12:54:46.189256:  
2025-01-11 12:54:46.189256: Epoch 99 
2025-01-11 12:54:46.194839: Current learning rate: 0.00635 
2025-01-11 12:55:26.292054: train_loss -0.7909 
2025-01-11 12:55:26.293054: val_loss -0.6285 
2025-01-11 12:55:26.299573: Pseudo dice [np.float32(0.7166)] 
2025-01-11 12:55:26.303583: Epoch time: 40.1 s 
2025-01-11 12:55:27.029701:  
2025-01-11 12:55:27.030705: Epoch 100 
2025-01-11 12:55:27.035286: Current learning rate: 0.00631 
2025-01-11 12:56:07.126838: train_loss -0.8106 
2025-01-11 12:56:07.127841: val_loss -0.5719 
2025-01-11 12:56:07.133862: Pseudo dice [np.float32(0.6618)] 
2025-01-11 12:56:07.136871: Epoch time: 40.1 s 
2025-01-11 12:56:07.682451:  
2025-01-11 12:56:07.682451: Epoch 101 
2025-01-11 12:56:07.688513: Current learning rate: 0.00628 
2025-01-11 12:56:47.793139: train_loss -0.8131 
2025-01-11 12:56:47.793642: val_loss -0.6551 
2025-01-11 12:56:47.799656: Pseudo dice [np.float32(0.7401)] 
2025-01-11 12:56:47.803162: Epoch time: 40.11 s 
2025-01-11 12:56:48.356259:  
2025-01-11 12:56:48.356259: Epoch 102 
2025-01-11 12:56:48.361274: Current learning rate: 0.00624 
2025-01-11 12:57:28.456800: train_loss -0.8036 
2025-01-11 12:57:28.457304: val_loss -0.6737 
2025-01-11 12:57:28.463318: Pseudo dice [np.float32(0.763)] 
2025-01-11 12:57:28.467329: Epoch time: 40.1 s 
2025-01-11 12:57:29.016677:  
2025-01-11 12:57:29.017681: Epoch 103 
2025-01-11 12:57:29.022259: Current learning rate: 0.0062 
2025-01-11 12:58:09.128034: train_loss -0.8123 
2025-01-11 12:58:09.129039: val_loss -0.6481 
2025-01-11 12:58:09.135148: Pseudo dice [np.float32(0.7604)] 
2025-01-11 12:58:09.139285: Epoch time: 40.11 s 
2025-01-11 12:58:09.142847: Yayy! New best EMA pseudo Dice: 0.7279999852180481 
2025-01-11 12:58:09.943517:  
2025-01-11 12:58:09.944522: Epoch 104 
2025-01-11 12:58:09.949089: Current learning rate: 0.00616 
2025-01-11 12:58:50.051224: train_loss -0.8246 
2025-01-11 12:58:50.051224: val_loss -0.6288 
2025-01-11 12:58:50.057748: Pseudo dice [np.float32(0.7388)] 
2025-01-11 12:58:50.061261: Epoch time: 40.11 s 
2025-01-11 12:58:50.064769: Yayy! New best EMA pseudo Dice: 0.7289999723434448 
2025-01-11 12:58:50.872035:  
2025-01-11 12:58:50.872538: Epoch 105 
2025-01-11 12:58:50.877553: Current learning rate: 0.00612 
2025-01-11 12:59:31.008929: train_loss -0.8193 
2025-01-11 12:59:31.009933: val_loss -0.6662 
2025-01-11 12:59:31.016069: Pseudo dice [np.float32(0.7426)] 
2025-01-11 12:59:31.020666: Epoch time: 40.14 s 
2025-01-11 12:59:31.023700: Yayy! New best EMA pseudo Dice: 0.730400025844574 
2025-01-11 12:59:31.792606:  
2025-01-11 12:59:31.793109: Epoch 106 
2025-01-11 12:59:31.798121: Current learning rate: 0.00609 
2025-01-11 13:00:11.900153: train_loss -0.8179 
2025-01-11 13:00:11.901158: val_loss -0.6645 
2025-01-11 13:00:11.907671: Pseudo dice [np.float32(0.7399)] 
2025-01-11 13:00:11.911181: Epoch time: 40.11 s 
2025-01-11 13:00:11.915192: Yayy! New best EMA pseudo Dice: 0.7314000129699707 
2025-01-11 13:00:12.883296:  
2025-01-11 13:00:12.883296: Epoch 107 
2025-01-11 13:00:12.888330: Current learning rate: 0.00605 
2025-01-11 13:00:53.001677: train_loss -0.8182 
2025-01-11 13:00:53.002677: val_loss -0.5759 
2025-01-11 13:00:53.009195: Pseudo dice [np.float32(0.69)] 
2025-01-11 13:00:53.013202: Epoch time: 40.12 s 
2025-01-11 13:00:53.561354:  
2025-01-11 13:00:53.562857: Epoch 108 
2025-01-11 13:00:53.567869: Current learning rate: 0.00601 
2025-01-11 13:01:33.640521: train_loss -0.8186 
2025-01-11 13:01:33.641524: val_loss -0.6339 
2025-01-11 13:01:33.648036: Pseudo dice [np.float32(0.7302)] 
2025-01-11 13:01:33.651544: Epoch time: 40.08 s 
2025-01-11 13:01:34.202234:  
2025-01-11 13:01:34.202234: Epoch 109 
2025-01-11 13:01:34.207753: Current learning rate: 0.00597 
2025-01-11 13:02:14.317737: train_loss -0.7977 
2025-01-11 13:02:14.318738: val_loss -0.6548 
2025-01-11 13:02:14.324252: Pseudo dice [np.float32(0.7353)] 
2025-01-11 13:02:14.327760: Epoch time: 40.12 s 
2025-01-11 13:02:14.869199:  
2025-01-11 13:02:14.869199: Epoch 110 
2025-01-11 13:02:14.875254: Current learning rate: 0.00593 
2025-01-11 13:02:54.994344: train_loss -0.8127 
2025-01-11 13:02:54.995345: val_loss -0.4994 
2025-01-11 13:02:55.000869: Pseudo dice [np.float32(0.6174)] 
2025-01-11 13:02:55.005382: Epoch time: 40.13 s 
2025-01-11 13:02:55.554641:  
2025-01-11 13:02:55.554641: Epoch 111 
2025-01-11 13:02:55.560175: Current learning rate: 0.0059 
2025-01-11 13:03:35.674361: train_loss -0.7926 
2025-01-11 13:03:35.674870: val_loss -0.5543 
2025-01-11 13:03:35.680459: Pseudo dice [np.float32(0.6889)] 
2025-01-11 13:03:35.683975: Epoch time: 40.12 s 
2025-01-11 13:03:36.228593:  
2025-01-11 13:03:36.228593: Epoch 112 
2025-01-11 13:03:36.234153: Current learning rate: 0.00586 
2025-01-11 13:04:16.364053: train_loss -0.8129 
2025-01-11 13:04:16.364556: val_loss -0.6369 
2025-01-11 13:04:16.370765: Pseudo dice [np.float32(0.7337)] 
2025-01-11 13:04:16.373805: Epoch time: 40.14 s 
2025-01-11 13:04:16.923986:  
2025-01-11 13:04:16.923986: Epoch 113 
2025-01-11 13:04:16.930027: Current learning rate: 0.00582 
2025-01-11 13:04:57.032759: train_loss -0.8221 
2025-01-11 13:04:57.033262: val_loss -0.6114 
2025-01-11 13:04:57.038815: Pseudo dice [np.float32(0.7238)] 
2025-01-11 13:04:57.043422: Epoch time: 40.11 s 
2025-01-11 13:04:57.587978:  
2025-01-11 13:04:57.588982: Epoch 114 
2025-01-11 13:04:57.593540: Current learning rate: 0.00578 
2025-01-11 13:05:37.796428: train_loss -0.8216 
2025-01-11 13:05:37.796428: val_loss -0.6511 
2025-01-11 13:05:37.803501: Pseudo dice [np.float32(0.7429)] 
2025-01-11 13:05:37.807098: Epoch time: 40.21 s 
2025-01-11 13:05:38.337648:  
2025-01-11 13:05:38.337648: Epoch 115 
2025-01-11 13:05:38.342659: Current learning rate: 0.00574 
2025-01-11 13:06:18.432695: train_loss -0.8205 
2025-01-11 13:06:18.433697: val_loss -0.6234 
2025-01-11 13:06:18.439740: Pseudo dice [np.float32(0.7294)] 
2025-01-11 13:06:18.443769: Epoch time: 40.1 s 
2025-01-11 13:06:18.996763:  
2025-01-11 13:06:18.997764: Epoch 116 
2025-01-11 13:06:19.003380: Current learning rate: 0.0057 
2025-01-11 13:06:59.108729: train_loss -0.824 
2025-01-11 13:06:59.108729: val_loss -0.6397 
2025-01-11 13:06:59.114752: Pseudo dice [np.float32(0.7622)] 
2025-01-11 13:06:59.118258: Epoch time: 40.11 s 
2025-01-11 13:06:59.667496:  
2025-01-11 13:06:59.667496: Epoch 117 
2025-01-11 13:06:59.673517: Current learning rate: 0.00567 
2025-01-11 13:07:39.821621: train_loss -0.817 
2025-01-11 13:07:39.822624: val_loss -0.6212 
2025-01-11 13:07:39.828655: Pseudo dice [np.float32(0.7307)] 
2025-01-11 13:07:39.832280: Epoch time: 40.15 s 
2025-01-11 13:07:40.401305:  
2025-01-11 13:07:40.401305: Epoch 118 
2025-01-11 13:07:40.406318: Current learning rate: 0.00563 
2025-01-11 13:08:20.538734: train_loss -0.8268 
2025-01-11 13:08:20.539738: val_loss -0.6275 
2025-01-11 13:08:20.545754: Pseudo dice [np.float32(0.7231)] 
2025-01-11 13:08:20.549767: Epoch time: 40.14 s 
2025-01-11 13:08:21.108462:  
2025-01-11 13:08:21.108462: Epoch 119 
2025-01-11 13:08:21.113474: Current learning rate: 0.00559 
2025-01-11 13:09:01.197005: train_loss -0.8273 
2025-01-11 13:09:01.197005: val_loss -0.5936 
2025-01-11 13:09:01.203554: Pseudo dice [np.float32(0.6952)] 
2025-01-11 13:09:01.208063: Epoch time: 40.09 s 
2025-01-11 13:09:01.755527:  
2025-01-11 13:09:01.755527: Epoch 120 
2025-01-11 13:09:01.761548: Current learning rate: 0.00555 
2025-01-11 13:09:41.867509: train_loss -0.8241 
2025-01-11 13:09:41.869073: val_loss -0.6436 
2025-01-11 13:09:41.874619: Pseudo dice [np.float32(0.7375)] 
2025-01-11 13:09:41.878133: Epoch time: 40.11 s 
2025-01-11 13:09:42.438706:  
2025-01-11 13:09:42.438706: Epoch 121 
2025-01-11 13:09:42.444274: Current learning rate: 0.00551 
2025-01-11 13:10:22.549493: train_loss -0.8266 
2025-01-11 13:10:22.550498: val_loss -0.5927 
2025-01-11 13:10:22.556509: Pseudo dice [np.float32(0.7108)] 
2025-01-11 13:10:22.559519: Epoch time: 40.11 s 
2025-01-11 13:10:23.292548:  
2025-01-11 13:10:23.292548: Epoch 122 
2025-01-11 13:10:23.297566: Current learning rate: 0.00547 
2025-01-11 13:11:03.381241: train_loss -0.8136 
2025-01-11 13:11:03.382244: val_loss -0.5679 
2025-01-11 13:11:03.387829: Pseudo dice [np.float32(0.7065)] 
2025-01-11 13:11:03.390884: Epoch time: 40.09 s 
2025-01-11 13:11:03.939880:  
2025-01-11 13:11:03.939880: Epoch 123 
2025-01-11 13:11:03.945427: Current learning rate: 0.00544 
2025-01-11 13:11:44.022751: train_loss -0.7915 
2025-01-11 13:11:44.023256: val_loss -0.5961 
2025-01-11 13:11:44.029274: Pseudo dice [np.float32(0.6878)] 
2025-01-11 13:11:44.033287: Epoch time: 40.08 s 
2025-01-11 13:11:44.588418:  
2025-01-11 13:11:44.588920: Epoch 124 
2025-01-11 13:11:44.593980: Current learning rate: 0.0054 
2025-01-11 13:12:24.691289: train_loss -0.8077 
2025-01-11 13:12:24.691791: val_loss -0.6754 
2025-01-11 13:12:24.696803: Pseudo dice [np.float32(0.7605)] 
2025-01-11 13:12:24.700318: Epoch time: 40.1 s 
2025-01-11 13:12:25.257997:  
2025-01-11 13:12:25.257997: Epoch 125 
2025-01-11 13:12:25.263511: Current learning rate: 0.00536 
2025-01-11 13:13:05.377594: train_loss -0.8088 
2025-01-11 13:13:05.378098: val_loss -0.6189 
2025-01-11 13:13:05.384158: Pseudo dice [np.float32(0.7329)] 
2025-01-11 13:13:05.387682: Epoch time: 40.12 s 
2025-01-11 13:13:05.939714:  
2025-01-11 13:13:05.939714: Epoch 126 
2025-01-11 13:13:05.945881: Current learning rate: 0.00532 
2025-01-11 13:13:46.034264: train_loss -0.787 
2025-01-11 13:13:46.035271: val_loss -0.5926 
2025-01-11 13:13:46.040285: Pseudo dice [np.float32(0.6866)] 
2025-01-11 13:13:46.044297: Epoch time: 40.1 s 
2025-01-11 13:13:46.598857:  
2025-01-11 13:13:46.598857: Epoch 127 
2025-01-11 13:13:46.604872: Current learning rate: 0.00528 
2025-01-11 13:14:26.695975: train_loss -0.8204 
2025-01-11 13:14:26.695975: val_loss -0.6697 
2025-01-11 13:14:26.701989: Pseudo dice [np.float32(0.7734)] 
2025-01-11 13:14:26.704999: Epoch time: 40.1 s 
2025-01-11 13:14:27.284498:  
2025-01-11 13:14:27.285501: Epoch 128 
2025-01-11 13:14:27.290068: Current learning rate: 0.00524 
2025-01-11 13:15:07.396231: train_loss -0.823 
2025-01-11 13:15:07.397235: val_loss -0.6218 
2025-01-11 13:15:07.403248: Pseudo dice [np.float32(0.73)] 
2025-01-11 13:15:07.406257: Epoch time: 40.11 s 
2025-01-11 13:15:07.962255:  
2025-01-11 13:15:07.962764: Epoch 129 
2025-01-11 13:15:07.968368: Current learning rate: 0.0052 
2025-01-11 13:15:48.131920: train_loss -0.8287 
2025-01-11 13:15:48.131920: val_loss -0.6439 
2025-01-11 13:15:48.137933: Pseudo dice [np.float32(0.7545)] 
2025-01-11 13:15:48.141945: Epoch time: 40.17 s 
2025-01-11 13:15:48.909581:  
2025-01-11 13:15:48.910580: Epoch 130 
2025-01-11 13:15:48.916195: Current learning rate: 0.00517 
2025-01-11 13:16:29.003647: train_loss -0.8223 
2025-01-11 13:16:29.004154: val_loss -0.552 
2025-01-11 13:16:29.010725: Pseudo dice [np.float32(0.6831)] 
2025-01-11 13:16:29.013765: Epoch time: 40.09 s 
2025-01-11 13:16:29.569341:  
2025-01-11 13:16:29.569341: Epoch 131 
2025-01-11 13:16:29.575389: Current learning rate: 0.00513 
2025-01-11 13:17:09.661527: train_loss -0.831 
2025-01-11 13:17:09.661527: val_loss -0.6317 
2025-01-11 13:17:09.667542: Pseudo dice [np.float32(0.7427)] 
2025-01-11 13:17:09.671555: Epoch time: 40.09 s 
2025-01-11 13:17:10.223430:  
2025-01-11 13:17:10.223430: Epoch 132 
2025-01-11 13:17:10.229542: Current learning rate: 0.00509 
2025-01-11 13:17:50.315123: train_loss -0.833 
2025-01-11 13:17:50.315123: val_loss -0.6164 
2025-01-11 13:17:50.321142: Pseudo dice [np.float32(0.7021)] 
2025-01-11 13:17:50.324651: Epoch time: 40.09 s 
2025-01-11 13:17:50.880844:  
2025-01-11 13:17:50.881347: Epoch 133 
2025-01-11 13:17:50.886356: Current learning rate: 0.00505 
2025-01-11 13:18:30.964201: train_loss -0.8341 
2025-01-11 13:18:30.964201: val_loss -0.6524 
2025-01-11 13:18:30.970360: Pseudo dice [np.float32(0.7408)] 
2025-01-11 13:18:30.973926: Epoch time: 40.08 s 
2025-01-11 13:18:31.535287:  
2025-01-11 13:18:31.535287: Epoch 134 
2025-01-11 13:18:31.541405: Current learning rate: 0.00501 
2025-01-11 13:19:11.632700: train_loss -0.83 
2025-01-11 13:19:11.632700: val_loss -0.6205 
2025-01-11 13:19:11.640224: Pseudo dice [np.float32(0.7349)] 
2025-01-11 13:19:11.643738: Epoch time: 40.1 s 
2025-01-11 13:19:12.203578:  
2025-01-11 13:19:12.203578: Epoch 135 
2025-01-11 13:19:12.209703: Current learning rate: 0.00497 
2025-01-11 13:19:52.310240: train_loss -0.8326 
2025-01-11 13:19:52.311243: val_loss -0.6507 
2025-01-11 13:19:52.317318: Pseudo dice [np.float32(0.7382)] 
2025-01-11 13:19:52.320347: Epoch time: 40.11 s 
2025-01-11 13:19:52.882405:  
2025-01-11 13:19:52.882405: Epoch 136 
2025-01-11 13:19:52.887944: Current learning rate: 0.00493 
2025-01-11 13:20:32.982926: train_loss -0.8317 
2025-01-11 13:20:32.982926: val_loss -0.6042 
2025-01-11 13:20:32.988949: Pseudo dice [np.float32(0.6998)] 
2025-01-11 13:20:32.992960: Epoch time: 40.1 s 
2025-01-11 13:20:33.569293:  
2025-01-11 13:20:33.569800: Epoch 137 
2025-01-11 13:20:33.575417: Current learning rate: 0.00489 
2025-01-11 13:21:13.684145: train_loss -0.8267 
2025-01-11 13:21:13.684649: val_loss -0.6239 
2025-01-11 13:21:13.690670: Pseudo dice [np.float32(0.7035)] 
2025-01-11 13:21:13.694177: Epoch time: 40.12 s 
2025-01-11 13:21:14.418630:  
2025-01-11 13:21:14.418630: Epoch 138 
2025-01-11 13:21:14.424675: Current learning rate: 0.00485 
2025-01-11 13:21:54.517333: train_loss -0.8236 
2025-01-11 13:21:54.517333: val_loss -0.61 
2025-01-11 13:21:54.523349: Pseudo dice [np.float32(0.6865)] 
2025-01-11 13:21:54.527364: Epoch time: 40.1 s 
2025-01-11 13:21:55.101258:  
2025-01-11 13:21:55.102259: Epoch 139 
2025-01-11 13:21:55.107858: Current learning rate: 0.00482 
2025-01-11 13:22:35.184289: train_loss -0.8352 
2025-01-11 13:22:35.185292: val_loss -0.6401 
2025-01-11 13:22:35.190945: Pseudo dice [np.float32(0.7256)] 
2025-01-11 13:22:35.194518: Epoch time: 40.08 s 
2025-01-11 13:22:35.754406:  
2025-01-11 13:22:35.754406: Epoch 140 
2025-01-11 13:22:35.759963: Current learning rate: 0.00478 
2025-01-11 13:23:15.863073: train_loss -0.8398 
2025-01-11 13:23:15.863575: val_loss -0.6202 
2025-01-11 13:23:15.869593: Pseudo dice [np.float32(0.7388)] 
2025-01-11 13:23:15.873611: Epoch time: 40.11 s 
2025-01-11 13:23:16.449176:  
2025-01-11 13:23:16.449176: Epoch 141 
2025-01-11 13:23:16.454191: Current learning rate: 0.00474 
2025-01-11 13:23:56.597232: train_loss -0.8462 
2025-01-11 13:23:56.597232: val_loss -0.6182 
2025-01-11 13:23:56.604443: Pseudo dice [np.float32(0.7305)] 
2025-01-11 13:23:56.609572: Epoch time: 40.15 s 
2025-01-11 13:23:57.191246:  
2025-01-11 13:23:57.191246: Epoch 142 
2025-01-11 13:23:57.196798: Current learning rate: 0.0047 
2025-01-11 13:24:37.289196: train_loss -0.8456 
2025-01-11 13:24:37.290200: val_loss -0.6339 
2025-01-11 13:24:37.295212: Pseudo dice [np.float32(0.7473)] 
2025-01-11 13:24:37.299270: Epoch time: 40.1 s 
2025-01-11 13:24:37.869946:  
2025-01-11 13:24:37.870461: Epoch 143 
2025-01-11 13:24:37.876037: Current learning rate: 0.00466 
2025-01-11 13:25:18.001752: train_loss -0.8452 
2025-01-11 13:25:18.002755: val_loss -0.6427 
2025-01-11 13:25:18.008769: Pseudo dice [np.float32(0.7341)] 
2025-01-11 13:25:18.011780: Epoch time: 40.13 s 
2025-01-11 13:25:18.579443:  
2025-01-11 13:25:18.579443: Epoch 144 
2025-01-11 13:25:18.585463: Current learning rate: 0.00462 
2025-01-11 13:25:58.712286: train_loss -0.8497 
2025-01-11 13:25:58.712789: val_loss -0.6116 
2025-01-11 13:25:58.718803: Pseudo dice [np.float32(0.6925)] 
2025-01-11 13:25:58.722814: Epoch time: 40.13 s 
2025-01-11 13:25:59.287696:  
2025-01-11 13:25:59.288697: Epoch 145 
2025-01-11 13:25:59.294343: Current learning rate: 0.00458 
2025-01-11 13:26:39.406323: train_loss -0.8416 
2025-01-11 13:26:39.406323: val_loss -0.6557 
2025-01-11 13:26:39.412865: Pseudo dice [np.float32(0.7393)] 
2025-01-11 13:26:39.416373: Epoch time: 40.12 s 
2025-01-11 13:26:40.141609:  
2025-01-11 13:26:40.142612: Epoch 146 
2025-01-11 13:26:40.147181: Current learning rate: 0.00454 
2025-01-11 13:27:20.229314: train_loss -0.8504 
2025-01-11 13:27:20.229314: val_loss -0.6258 
2025-01-11 13:27:20.235332: Pseudo dice [np.float32(0.7451)] 
2025-01-11 13:27:20.238838: Epoch time: 40.09 s 
2025-01-11 13:27:20.800571:  
2025-01-11 13:27:20.800571: Epoch 147 
2025-01-11 13:27:20.806114: Current learning rate: 0.0045 
2025-01-11 13:28:00.910040: train_loss -0.8536 
2025-01-11 13:28:00.911042: val_loss -0.5584 
2025-01-11 13:28:00.917190: Pseudo dice [np.float32(0.6964)] 
2025-01-11 13:28:00.921263: Epoch time: 40.11 s 
2025-01-11 13:28:01.491689:  
2025-01-11 13:28:01.491689: Epoch 148 
2025-01-11 13:28:01.496723: Current learning rate: 0.00446 
2025-01-11 13:28:41.586505: train_loss -0.855 
2025-01-11 13:28:41.587510: val_loss -0.6359 
2025-01-11 13:28:41.593523: Pseudo dice [np.float32(0.7414)] 
2025-01-11 13:28:41.597534: Epoch time: 40.1 s 
2025-01-11 13:28:42.166900:  
2025-01-11 13:28:42.167901: Epoch 149 
2025-01-11 13:28:42.173522: Current learning rate: 0.00442 
2025-01-11 13:29:22.272968: train_loss -0.8421 
2025-01-11 13:29:22.273968: val_loss -0.5665 
2025-01-11 13:29:22.280485: Pseudo dice [np.float32(0.693)] 
2025-01-11 13:29:22.283989: Epoch time: 40.11 s 
2025-01-11 13:29:23.059260:  
2025-01-11 13:29:23.059260: Epoch 150 
2025-01-11 13:29:23.064821: Current learning rate: 0.00438 
2025-01-11 13:30:03.170289: train_loss -0.8375 
2025-01-11 13:30:03.170289: val_loss -0.6383 
2025-01-11 13:30:03.176306: Pseudo dice [np.float32(0.7327)] 
2025-01-11 13:30:03.179815: Epoch time: 40.11 s 
2025-01-11 13:30:03.748507:  
2025-01-11 13:30:03.749510: Epoch 151 
2025-01-11 13:30:03.753541: Current learning rate: 0.00434 
2025-01-11 13:30:43.863083: train_loss -0.8371 
2025-01-11 13:30:43.863083: val_loss -0.5971 
2025-01-11 13:30:43.869100: Pseudo dice [np.float32(0.7024)] 
2025-01-11 13:30:43.873114: Epoch time: 40.11 s 
2025-01-11 13:30:44.438547:  
2025-01-11 13:30:44.438547: Epoch 152 
2025-01-11 13:30:44.445060: Current learning rate: 0.0043 
2025-01-11 13:31:24.565612: train_loss -0.8357 
2025-01-11 13:31:24.566617: val_loss -0.5399 
2025-01-11 13:31:24.572635: Pseudo dice [np.float32(0.6582)] 
2025-01-11 13:31:24.575648: Epoch time: 40.13 s 
2025-01-11 13:31:25.134811:  
2025-01-11 13:31:25.135315: Epoch 153 
2025-01-11 13:31:25.140330: Current learning rate: 0.00427 
2025-01-11 13:32:05.352524: train_loss -0.8447 
2025-01-11 13:32:05.353030: val_loss -0.6379 
2025-01-11 13:32:05.358706: Pseudo dice [np.float32(0.7559)] 
2025-01-11 13:32:05.362276: Epoch time: 40.22 s 
2025-01-11 13:32:06.138436:  
2025-01-11 13:32:06.139440: Epoch 154 
2025-01-11 13:32:06.143980: Current learning rate: 0.00423 
2025-01-11 13:32:46.248319: train_loss -0.8351 
2025-01-11 13:32:46.249321: val_loss -0.5625 
2025-01-11 13:32:46.254842: Pseudo dice [np.float32(0.7023)] 
2025-01-11 13:32:46.258352: Epoch time: 40.11 s 
2025-01-11 13:32:46.828758:  
2025-01-11 13:32:46.828758: Epoch 155 
2025-01-11 13:32:46.834307: Current learning rate: 0.00419 
2025-01-11 13:33:26.937687: train_loss -0.8365 
2025-01-11 13:33:26.937687: val_loss -0.6168 
2025-01-11 13:33:26.943795: Pseudo dice [np.float32(0.7177)] 
2025-01-11 13:33:26.947351: Epoch time: 40.11 s 
2025-01-11 13:33:27.527456:  
2025-01-11 13:33:27.527959: Epoch 156 
2025-01-11 13:33:27.532970: Current learning rate: 0.00415 
2025-01-11 13:34:07.635740: train_loss -0.8505 
2025-01-11 13:34:07.636745: val_loss -0.597 
2025-01-11 13:34:07.641498: Pseudo dice [np.float32(0.7197)] 
2025-01-11 13:34:07.646012: Epoch time: 40.11 s 
2025-01-11 13:34:08.223472:  
2025-01-11 13:34:08.223472: Epoch 157 
2025-01-11 13:34:08.229492: Current learning rate: 0.00411 
2025-01-11 13:34:48.328733: train_loss -0.8537 
2025-01-11 13:34:48.329733: val_loss -0.6053 
2025-01-11 13:34:48.335249: Pseudo dice [np.float32(0.7392)] 
2025-01-11 13:34:48.338755: Epoch time: 40.11 s 
2025-01-11 13:34:48.918178:  
2025-01-11 13:34:48.918178: Epoch 158 
2025-01-11 13:34:48.924189: Current learning rate: 0.00407 
2025-01-11 13:35:29.053154: train_loss -0.8489 
2025-01-11 13:35:29.053154: val_loss -0.5653 
2025-01-11 13:35:29.058827: Pseudo dice [np.float32(0.6712)] 
2025-01-11 13:35:29.062859: Epoch time: 40.14 s 
2025-01-11 13:35:29.640733:  
2025-01-11 13:35:29.641737: Epoch 159 
2025-01-11 13:35:29.647350: Current learning rate: 0.00403 
2025-01-11 13:36:09.743027: train_loss -0.7972 
2025-01-11 13:36:09.744031: val_loss -0.6132 
2025-01-11 13:36:09.750553: Pseudo dice [np.float32(0.7164)] 
2025-01-11 13:36:09.754064: Epoch time: 40.1 s 
2025-01-11 13:36:10.329657:  
2025-01-11 13:36:10.329657: Epoch 160 
2025-01-11 13:36:10.334672: Current learning rate: 0.00399 
2025-01-11 13:36:50.442431: train_loss -0.823 
2025-01-11 13:36:50.442939: val_loss -0.5353 
2025-01-11 13:36:50.448997: Pseudo dice [np.float32(0.6541)] 
2025-01-11 13:36:50.452589: Epoch time: 40.11 s 
2025-01-11 13:36:51.233367:  
2025-01-11 13:36:51.233367: Epoch 161 
2025-01-11 13:36:51.238931: Current learning rate: 0.00395 
2025-01-11 13:37:31.328453: train_loss -0.8423 
2025-01-11 13:37:31.328967: val_loss -0.6344 
2025-01-11 13:37:31.335066: Pseudo dice [np.float32(0.7141)] 
2025-01-11 13:37:31.338715: Epoch time: 40.1 s 
2025-01-11 13:37:31.917973:  
2025-01-11 13:37:31.917973: Epoch 162 
2025-01-11 13:37:31.924589: Current learning rate: 0.00391 
2025-01-11 13:38:12.006712: train_loss -0.8423 
2025-01-11 13:38:12.007715: val_loss -0.5756 
2025-01-11 13:38:12.012732: Pseudo dice [np.float32(0.7114)] 
2025-01-11 13:38:12.017744: Epoch time: 40.09 s 
2025-01-11 13:38:12.583729:  
2025-01-11 13:38:12.583729: Epoch 163 
2025-01-11 13:38:12.589798: Current learning rate: 0.00387 
2025-01-11 13:38:52.689566: train_loss -0.8465 
2025-01-11 13:38:52.689566: val_loss -0.631 
2025-01-11 13:38:52.696631: Pseudo dice [np.float32(0.7329)] 
2025-01-11 13:38:52.700144: Epoch time: 40.11 s 
2025-01-11 13:38:53.272734:  
2025-01-11 13:38:53.272734: Epoch 164 
2025-01-11 13:38:53.277756: Current learning rate: 0.00383 
2025-01-11 13:39:33.391360: train_loss -0.8425 
2025-01-11 13:39:33.391360: val_loss -0.559 
2025-01-11 13:39:33.398925: Pseudo dice [np.float32(0.6723)] 
2025-01-11 13:39:33.402952: Epoch time: 40.12 s 
2025-01-11 13:39:33.963437:  
2025-01-11 13:39:33.963437: Epoch 165 
2025-01-11 13:39:33.968530: Current learning rate: 0.00379 
2025-01-11 13:40:14.133198: train_loss -0.8507 
2025-01-11 13:40:14.133198: val_loss -0.6357 
2025-01-11 13:40:14.139723: Pseudo dice [np.float32(0.7332)] 
2025-01-11 13:40:14.142229: Epoch time: 40.17 s 
2025-01-11 13:40:14.702315:  
2025-01-11 13:40:14.702315: Epoch 166 
2025-01-11 13:40:14.707830: Current learning rate: 0.00375 
2025-01-11 13:40:54.807234: train_loss -0.8517 
2025-01-11 13:40:54.807737: val_loss -0.5808 
2025-01-11 13:40:54.813883: Pseudo dice [np.float32(0.7355)] 
2025-01-11 13:40:54.817458: Epoch time: 40.11 s 
2025-01-11 13:40:55.371192:  
2025-01-11 13:40:55.372696: Epoch 167 
2025-01-11 13:40:55.377710: Current learning rate: 0.00371 
2025-01-11 13:41:35.455939: train_loss -0.8561 
2025-01-11 13:41:35.455939: val_loss -0.5267 
2025-01-11 13:41:35.462462: Pseudo dice [np.float32(0.6677)] 
2025-01-11 13:41:35.465975: Epoch time: 40.08 s 
2025-01-11 13:41:36.028179:  
2025-01-11 13:41:36.028179: Epoch 168 
2025-01-11 13:41:36.034696: Current learning rate: 0.00367 
2025-01-11 13:42:16.148919: train_loss -0.8586 
2025-01-11 13:42:16.148919: val_loss -0.5966 
2025-01-11 13:42:16.155437: Pseudo dice [np.float32(0.7219)] 
2025-01-11 13:42:16.158952: Epoch time: 40.12 s 
2025-01-11 13:42:16.921755:  
2025-01-11 13:42:16.922759: Epoch 169 
2025-01-11 13:42:16.928083: Current learning rate: 0.00363 
2025-01-11 13:42:57.000577: train_loss -0.863 
2025-01-11 13:42:57.001580: val_loss -0.5924 
2025-01-11 13:42:57.007210: Pseudo dice [np.float32(0.7157)] 
2025-01-11 13:42:57.011772: Epoch time: 40.08 s 
2025-01-11 13:42:57.572730:  
2025-01-11 13:42:57.573730: Epoch 170 
2025-01-11 13:42:57.579304: Current learning rate: 0.00359 
2025-01-11 13:43:37.661622: train_loss -0.8619 
2025-01-11 13:43:37.661622: val_loss -0.6039 
2025-01-11 13:43:37.668141: Pseudo dice [np.float32(0.707)] 
2025-01-11 13:43:37.671654: Epoch time: 40.09 s 
2025-01-11 13:43:38.234478:  
2025-01-11 13:43:38.235484: Epoch 171 
2025-01-11 13:43:38.240048: Current learning rate: 0.00355 
2025-01-11 13:44:18.300615: train_loss -0.8539 
2025-01-11 13:44:18.300615: val_loss -0.6065 
2025-01-11 13:44:18.306649: Pseudo dice [np.float32(0.7224)] 
2025-01-11 13:44:18.310173: Epoch time: 40.07 s 
2025-01-11 13:44:18.874629:  
2025-01-11 13:44:18.874629: Epoch 172 
2025-01-11 13:44:18.880649: Current learning rate: 0.00351 
2025-01-11 13:44:58.976560: train_loss -0.8622 
2025-01-11 13:44:58.976560: val_loss -0.5527 
2025-01-11 13:44:58.984079: Pseudo dice [np.float32(0.6913)] 
2025-01-11 13:44:58.987586: Epoch time: 40.1 s 
2025-01-11 13:44:59.564518:  
2025-01-11 13:44:59.564518: Epoch 173 
2025-01-11 13:44:59.570543: Current learning rate: 0.00346 
2025-01-11 13:45:39.676901: train_loss -0.8604 
2025-01-11 13:45:39.677405: val_loss -0.5469 
2025-01-11 13:45:39.682422: Pseudo dice [np.float32(0.6903)] 
2025-01-11 13:45:39.686934: Epoch time: 40.11 s 
2025-01-11 13:45:40.256151:  
2025-01-11 13:45:40.256459: Epoch 174 
2025-01-11 13:45:40.261682: Current learning rate: 0.00342 
2025-01-11 13:46:20.366415: train_loss -0.8573 
2025-01-11 13:46:20.367419: val_loss -0.5978 
2025-01-11 13:46:20.373411: Pseudo dice [np.float32(0.7103)] 
2025-01-11 13:46:20.377431: Epoch time: 40.11 s 
2025-01-11 13:46:20.939526:  
2025-01-11 13:46:20.940530: Epoch 175 
2025-01-11 13:46:20.945119: Current learning rate: 0.00338 
2025-01-11 13:47:01.057859: train_loss -0.8591 
2025-01-11 13:47:01.058363: val_loss -0.6465 
2025-01-11 13:47:01.063383: Pseudo dice [np.float32(0.7411)] 
2025-01-11 13:47:01.066897: Epoch time: 40.12 s 
2025-01-11 13:47:01.645727:  
2025-01-11 13:47:01.646730: Epoch 176 
2025-01-11 13:47:01.651318: Current learning rate: 0.00334 
2025-01-11 13:47:41.789970: train_loss -0.8623 
2025-01-11 13:47:41.789970: val_loss -0.6767 
2025-01-11 13:47:41.796486: Pseudo dice [np.float32(0.7639)] 
2025-01-11 13:47:41.799995: Epoch time: 40.14 s 
2025-01-11 13:47:42.569605:  
2025-01-11 13:47:42.569605: Epoch 177 
2025-01-11 13:47:42.575159: Current learning rate: 0.0033 
2025-01-11 13:48:22.653974: train_loss -0.8578 
2025-01-11 13:48:22.653974: val_loss -0.61 
2025-01-11 13:48:22.660490: Pseudo dice [np.float32(0.7266)] 
2025-01-11 13:48:22.664001: Epoch time: 40.08 s 
2025-01-11 13:48:23.228511:  
2025-01-11 13:48:23.228511: Epoch 178 
2025-01-11 13:48:23.234616: Current learning rate: 0.00326 
2025-01-11 13:49:03.319063: train_loss -0.8609 
2025-01-11 13:49:03.319063: val_loss -0.5493 
2025-01-11 13:49:03.325619: Pseudo dice [np.float32(0.7029)] 
2025-01-11 13:49:03.329645: Epoch time: 40.09 s 
2025-01-11 13:49:03.897466:  
2025-01-11 13:49:03.897466: Epoch 179 
2025-01-11 13:49:03.903028: Current learning rate: 0.00322 
2025-01-11 13:49:43.991270: train_loss -0.8606 
2025-01-11 13:49:43.991773: val_loss -0.6039 
2025-01-11 13:49:43.997788: Pseudo dice [np.float32(0.7141)] 
2025-01-11 13:49:44.001796: Epoch time: 40.09 s 
2025-01-11 13:49:44.567269:  
2025-01-11 13:49:44.567269: Epoch 180 
2025-01-11 13:49:44.572857: Current learning rate: 0.00318 
2025-01-11 13:50:24.626297: train_loss -0.8632 
2025-01-11 13:50:24.626800: val_loss -0.6554 
2025-01-11 13:50:24.632876: Pseudo dice [np.float32(0.7392)] 
2025-01-11 13:50:24.636527: Epoch time: 40.06 s 
2025-01-11 13:50:25.211381:  
2025-01-11 13:50:25.211891: Epoch 181 
2025-01-11 13:50:25.217074: Current learning rate: 0.00314 
2025-01-11 13:51:05.318434: train_loss -0.8619 
2025-01-11 13:51:05.318955: val_loss -0.5756 
2025-01-11 13:51:05.324009: Pseudo dice [np.float32(0.6872)] 
2025-01-11 13:51:05.328033: Epoch time: 40.11 s 
2025-01-11 13:51:05.894043:  
2025-01-11 13:51:05.895047: Epoch 182 
2025-01-11 13:51:05.899605: Current learning rate: 0.0031 
2025-01-11 13:51:45.998762: train_loss -0.867 
2025-01-11 13:51:46.000268: val_loss -0.5606 
2025-01-11 13:51:46.005910: Pseudo dice [np.float32(0.6586)] 
2025-01-11 13:51:46.009422: Epoch time: 40.1 s 
2025-01-11 13:51:46.582705:  
2025-01-11 13:51:46.582705: Epoch 183 
2025-01-11 13:51:46.588720: Current learning rate: 0.00306 
2025-01-11 13:52:26.689701: train_loss -0.8609 
2025-01-11 13:52:26.690203: val_loss -0.6328 
2025-01-11 13:52:26.696299: Pseudo dice [np.float32(0.7347)] 
2025-01-11 13:52:26.699835: Epoch time: 40.11 s 
2025-01-11 13:52:27.445309:  
2025-01-11 13:52:27.445814: Epoch 184 
2025-01-11 13:52:27.450830: Current learning rate: 0.00302 
2025-01-11 13:53:07.533584: train_loss -0.8641 
2025-01-11 13:53:07.534589: val_loss -0.6075 
2025-01-11 13:53:07.539109: Pseudo dice [np.float32(0.7086)] 
2025-01-11 13:53:07.543642: Epoch time: 40.09 s 
2025-01-11 13:53:08.109804:  
2025-01-11 13:53:08.110805: Epoch 185 
2025-01-11 13:53:08.115894: Current learning rate: 0.00297 
2025-01-11 13:53:48.178286: train_loss -0.8697 
2025-01-11 13:53:48.179814: val_loss -0.6004 
2025-01-11 13:53:48.185368: Pseudo dice [np.float32(0.7053)] 
2025-01-11 13:53:48.188879: Epoch time: 40.07 s 
2025-01-11 13:53:48.790153:  
2025-01-11 13:53:48.790153: Epoch 186 
2025-01-11 13:53:48.796669: Current learning rate: 0.00293 
2025-01-11 13:54:28.883123: train_loss -0.8585 
2025-01-11 13:54:28.884123: val_loss -0.5528 
2025-01-11 13:54:28.889697: Pseudo dice [np.float32(0.6872)] 
2025-01-11 13:54:28.893236: Epoch time: 40.09 s 
2025-01-11 13:54:29.477157:  
2025-01-11 13:54:29.478159: Epoch 187 
2025-01-11 13:54:29.483240: Current learning rate: 0.00289 
2025-01-11 13:55:09.624081: train_loss -0.867 
2025-01-11 13:55:09.624584: val_loss -0.6479 
2025-01-11 13:55:09.630606: Pseudo dice [np.float32(0.7363)] 
2025-01-11 13:55:09.633115: Epoch time: 40.15 s 
2025-01-11 13:55:10.200513:  
2025-01-11 13:55:10.201513: Epoch 188 
2025-01-11 13:55:10.206588: Current learning rate: 0.00285 
2025-01-11 13:55:50.319045: train_loss -0.8711 
2025-01-11 13:55:50.319045: val_loss -0.5664 
2025-01-11 13:55:50.325164: Pseudo dice [np.float32(0.7039)] 
2025-01-11 13:55:50.329192: Epoch time: 40.12 s 
2025-01-11 13:55:50.897989:  
2025-01-11 13:55:50.897989: Epoch 189 
2025-01-11 13:55:50.904036: Current learning rate: 0.00281 
2025-01-11 13:56:31.007520: train_loss -0.8683 
2025-01-11 13:56:31.008525: val_loss -0.6073 
2025-01-11 13:56:31.014045: Pseudo dice [np.float32(0.709)] 
2025-01-11 13:56:31.018560: Epoch time: 40.11 s 
2025-01-11 13:56:31.589130:  
2025-01-11 13:56:31.589633: Epoch 190 
2025-01-11 13:56:31.594649: Current learning rate: 0.00277 
2025-01-11 13:57:11.702105: train_loss -0.8729 
2025-01-11 13:57:11.702608: val_loss -0.6227 
2025-01-11 13:57:11.708735: Pseudo dice [np.float32(0.7314)] 
2025-01-11 13:57:11.712352: Epoch time: 40.11 s 
2025-01-11 13:57:12.277575:  
2025-01-11 13:57:12.277575: Epoch 191 
2025-01-11 13:57:12.283160: Current learning rate: 0.00273 
2025-01-11 13:57:52.405364: train_loss -0.8681 
2025-01-11 13:57:52.405364: val_loss -0.6421 
2025-01-11 13:57:52.410471: Pseudo dice [np.float32(0.7329)] 
2025-01-11 13:57:52.415020: Epoch time: 40.13 s 
2025-01-11 13:57:53.184465:  
2025-01-11 13:57:53.184465: Epoch 192 
2025-01-11 13:57:53.189545: Current learning rate: 0.00268 
2025-01-11 13:58:33.276406: train_loss -0.8698 
2025-01-11 13:58:33.276920: val_loss -0.6055 
2025-01-11 13:58:33.283092: Pseudo dice [np.float32(0.7057)] 
2025-01-11 13:58:33.287187: Epoch time: 40.09 s 
2025-01-11 13:58:33.866895:  
2025-01-11 13:58:33.866895: Epoch 193 
2025-01-11 13:58:33.871951: Current learning rate: 0.00264 
2025-01-11 13:59:13.961999: train_loss -0.8743 
2025-01-11 13:59:13.961999: val_loss -0.5976 
2025-01-11 13:59:13.968019: Pseudo dice [np.float32(0.7267)] 
2025-01-11 13:59:13.971032: Epoch time: 40.1 s 
2025-01-11 13:59:14.550907:  
2025-01-11 13:59:14.550907: Epoch 194 
2025-01-11 13:59:14.554941: Current learning rate: 0.0026 
2025-01-11 13:59:54.647783: train_loss -0.8722 
2025-01-11 13:59:54.649292: val_loss -0.5848 
2025-01-11 13:59:54.654821: Pseudo dice [np.float32(0.722)] 
2025-01-11 13:59:54.659330: Epoch time: 40.1 s 
2025-01-11 13:59:55.261784:  
2025-01-11 13:59:55.261784: Epoch 195 
2025-01-11 13:59:55.266803: Current learning rate: 0.00256 
2025-01-11 14:00:35.358019: train_loss -0.8734 
2025-01-11 14:00:35.359023: val_loss -0.5537 
2025-01-11 14:00:35.365038: Pseudo dice [np.float32(0.7086)] 
2025-01-11 14:00:35.369056: Epoch time: 40.1 s 
2025-01-11 14:00:35.948978:  
2025-01-11 14:00:35.949981: Epoch 196 
2025-01-11 14:00:35.955077: Current learning rate: 0.00252 
2025-01-11 14:01:16.032143: train_loss -0.872 
2025-01-11 14:01:16.032143: val_loss -0.5712 
2025-01-11 14:01:16.038665: Pseudo dice [np.float32(0.6828)] 
2025-01-11 14:01:16.042177: Epoch time: 40.08 s 
2025-01-11 14:01:16.630934:  
2025-01-11 14:01:16.631437: Epoch 197 
2025-01-11 14:01:16.636447: Current learning rate: 0.00248 
2025-01-11 14:01:56.726829: train_loss -0.8773 
2025-01-11 14:01:56.726829: val_loss -0.5314 
2025-01-11 14:01:56.733351: Pseudo dice [np.float32(0.6912)] 
2025-01-11 14:01:56.737864: Epoch time: 40.1 s 
2025-01-11 14:01:57.313872:  
2025-01-11 14:01:57.313872: Epoch 198 
2025-01-11 14:01:57.319444: Current learning rate: 0.00243 
2025-01-11 14:02:37.388307: train_loss -0.8712 
2025-01-11 14:02:37.388307: val_loss -0.6317 
2025-01-11 14:02:37.394323: Pseudo dice [np.float32(0.7245)] 
2025-01-11 14:02:37.397335: Epoch time: 40.07 s 
2025-01-11 14:02:38.170305:  
2025-01-11 14:02:38.170808: Epoch 199 
2025-01-11 14:02:38.175823: Current learning rate: 0.00239 
2025-01-11 14:03:18.325678: train_loss -0.8794 
2025-01-11 14:03:18.326192: val_loss -0.6884 
2025-01-11 14:03:18.332314: Pseudo dice [np.float32(0.7588)] 
2025-01-11 14:03:18.335839: Epoch time: 40.16 s 
2025-01-11 14:03:19.119627:  
2025-01-11 14:03:19.119627: Epoch 200 
2025-01-11 14:03:19.124644: Current learning rate: 0.00235 
2025-01-11 14:03:59.184442: train_loss -0.8744 
2025-01-11 14:03:59.185447: val_loss -0.6561 
2025-01-11 14:03:59.190458: Pseudo dice [np.float32(0.7572)] 
2025-01-11 14:03:59.194471: Epoch time: 40.07 s 
2025-01-11 14:03:59.770190:  
2025-01-11 14:03:59.770190: Epoch 201 
2025-01-11 14:03:59.775250: Current learning rate: 0.00231 
2025-01-11 14:04:39.854397: train_loss -0.8711 
2025-01-11 14:04:39.854397: val_loss -0.6477 
2025-01-11 14:04:39.860426: Pseudo dice [np.float32(0.7454)] 
2025-01-11 14:04:39.864625: Epoch time: 40.09 s 
2025-01-11 14:04:40.447114:  
2025-01-11 14:04:40.448114: Epoch 202 
2025-01-11 14:04:40.453761: Current learning rate: 0.00226 
2025-01-11 14:05:20.545919: train_loss -0.8708 
2025-01-11 14:05:20.546445: val_loss -0.6387 
2025-01-11 14:05:20.552063: Pseudo dice [np.float32(0.745)] 
2025-01-11 14:05:20.554611: Epoch time: 40.1 s 
2025-01-11 14:05:21.141763:  
2025-01-11 14:05:21.141763: Epoch 203 
2025-01-11 14:05:21.147309: Current learning rate: 0.00222 
2025-01-11 14:06:01.233927: train_loss -0.8779 
2025-01-11 14:06:01.234928: val_loss -0.5836 
2025-01-11 14:06:01.241449: Pseudo dice [np.float32(0.7043)] 
2025-01-11 14:06:01.245460: Epoch time: 40.09 s 
2025-01-11 14:06:01.851056:  
2025-01-11 14:06:01.851558: Epoch 204 
2025-01-11 14:06:01.856567: Current learning rate: 0.00218 
2025-01-11 14:06:41.926948: train_loss -0.8766 
2025-01-11 14:06:41.927952: val_loss -0.5948 
2025-01-11 14:06:41.934151: Pseudo dice [np.float32(0.7363)] 
2025-01-11 14:06:41.938207: Epoch time: 40.08 s 
2025-01-11 14:06:42.524681:  
2025-01-11 14:06:42.525683: Epoch 205 
2025-01-11 14:06:42.531274: Current learning rate: 0.00214 
2025-01-11 14:07:22.604702: train_loss -0.877 
2025-01-11 14:07:22.605706: val_loss -0.5482 
2025-01-11 14:07:22.611726: Pseudo dice [np.float32(0.68)] 
2025-01-11 14:07:22.614737: Epoch time: 40.08 s 
2025-01-11 14:07:23.170067:  
2025-01-11 14:07:23.171072: Epoch 206 
2025-01-11 14:07:23.176180: Current learning rate: 0.00209 
2025-01-11 14:08:03.263865: train_loss -0.8838 
2025-01-11 14:08:03.263865: val_loss -0.6266 
2025-01-11 14:08:03.271389: Pseudo dice [np.float32(0.7251)] 
2025-01-11 14:08:03.275401: Epoch time: 40.09 s 
2025-01-11 14:08:03.996917:  
2025-01-11 14:08:03.996917: Epoch 207 
2025-01-11 14:08:04.002534: Current learning rate: 0.00205 
2025-01-11 14:08:44.070158: train_loss -0.875 
2025-01-11 14:08:44.071158: val_loss -0.5121 
2025-01-11 14:08:44.076671: Pseudo dice [np.float32(0.686)] 
2025-01-11 14:08:44.080179: Epoch time: 40.07 s 
2025-01-11 14:08:44.615300:  
2025-01-11 14:08:44.615300: Epoch 208 
2025-01-11 14:08:44.620829: Current learning rate: 0.00201 
2025-01-11 14:09:24.685914: train_loss -0.8745 
2025-01-11 14:09:24.687010: val_loss -0.6073 
2025-01-11 14:09:24.692571: Pseudo dice [np.float32(0.7462)] 
2025-01-11 14:09:24.696091: Epoch time: 40.07 s 
2025-01-11 14:09:25.237408:  
2025-01-11 14:09:25.237408: Epoch 209 
2025-01-11 14:09:25.243133: Current learning rate: 0.00196 
2025-01-11 14:10:05.318685: train_loss -0.8768 
2025-01-11 14:10:05.318685: val_loss -0.6091 
2025-01-11 14:10:05.324699: Pseudo dice [np.float32(0.7201)] 
2025-01-11 14:10:05.327712: Epoch time: 40.08 s 
2025-01-11 14:10:05.869454:  
2025-01-11 14:10:05.869454: Epoch 210 
2025-01-11 14:10:05.874468: Current learning rate: 0.00192 
2025-01-11 14:10:46.024863: train_loss -0.8729 
2025-01-11 14:10:46.025863: val_loss -0.6063 
2025-01-11 14:10:46.031381: Pseudo dice [np.float32(0.7113)] 
2025-01-11 14:10:46.034889: Epoch time: 40.16 s 
2025-01-11 14:10:46.583960:  
2025-01-11 14:10:46.583960: Epoch 211 
2025-01-11 14:10:46.589482: Current learning rate: 0.00188 
2025-01-11 14:11:26.675097: train_loss -0.8786 
2025-01-11 14:11:26.675598: val_loss -0.6167 
2025-01-11 14:11:26.681620: Pseudo dice [np.float32(0.7204)] 
2025-01-11 14:11:26.685651: Epoch time: 40.09 s 
2025-01-11 14:11:27.222287:  
2025-01-11 14:11:27.222790: Epoch 212 
2025-01-11 14:11:27.227810: Current learning rate: 0.00184 
2025-01-11 14:12:07.312821: train_loss -0.8746 
2025-01-11 14:12:07.312821: val_loss -0.6213 
2025-01-11 14:12:07.320346: Pseudo dice [np.float32(0.7137)] 
2025-01-11 14:12:07.324357: Epoch time: 40.09 s 
2025-01-11 14:12:07.868842:  
2025-01-11 14:12:07.871348: Epoch 213 
2025-01-11 14:12:07.876886: Current learning rate: 0.00179 
2025-01-11 14:12:53.528996: train_loss -0.8796 
2025-01-11 14:12:53.528996: val_loss -0.5457 
2025-01-11 14:12:53.535518: Pseudo dice [np.float32(0.7166)] 
2025-01-11 14:12:53.540031: Epoch time: 45.66 s 
2025-01-11 14:12:54.090977:  
2025-01-11 14:12:54.090977: Epoch 214 
2025-01-11 14:12:54.096080: Current learning rate: 0.00175 
2025-01-11 14:13:34.542404: train_loss -0.879 
2025-01-11 14:13:34.543411: val_loss -0.6029 
2025-01-11 14:13:34.548430: Pseudo dice [np.float32(0.698)] 
2025-01-11 14:13:34.553449: Epoch time: 40.45 s 
2025-01-11 14:13:35.273091:  
2025-01-11 14:13:35.273594: Epoch 215 
2025-01-11 14:13:35.278611: Current learning rate: 0.0017 
2025-01-11 14:14:15.679355: train_loss -0.8746 
2025-01-11 14:14:15.679355: val_loss -0.6353 
2025-01-11 14:14:15.685423: Pseudo dice [np.float32(0.7316)] 
2025-01-11 14:14:15.689470: Epoch time: 40.41 s 
2025-01-11 14:14:16.238551:  
2025-01-11 14:14:16.239054: Epoch 216 
2025-01-11 14:14:16.244068: Current learning rate: 0.00166 
2025-01-11 14:14:56.644670: train_loss -0.8758 
2025-01-11 14:14:56.645675: val_loss -0.5247 
2025-01-11 14:14:56.651693: Pseudo dice [np.float32(0.6738)] 
2025-01-11 14:14:56.656708: Epoch time: 40.41 s 
2025-01-11 14:14:57.208829:  
2025-01-11 14:14:57.208829: Epoch 217 
2025-01-11 14:14:57.214873: Current learning rate: 0.00162 
2025-01-11 14:15:37.594928: train_loss -0.8817 
2025-01-11 14:15:37.595926: val_loss -0.6261 
2025-01-11 14:15:37.601442: Pseudo dice [np.float32(0.7179)] 
2025-01-11 14:15:37.604954: Epoch time: 40.39 s 
2025-01-11 14:15:38.172280:  
2025-01-11 14:15:38.173281: Epoch 218 
2025-01-11 14:15:38.178367: Current learning rate: 0.00157 
2025-01-11 14:16:18.586731: train_loss -0.8803 
2025-01-11 14:16:18.587737: val_loss -0.6144 
2025-01-11 14:16:18.593752: Pseudo dice [np.float32(0.7124)] 
2025-01-11 14:16:18.596764: Epoch time: 40.41 s 
2025-01-11 14:16:19.187212:  
2025-01-11 14:16:19.188211: Epoch 219 
2025-01-11 14:16:19.193509: Current learning rate: 0.00153 
2025-01-11 14:16:59.609934: train_loss -0.8802 
2025-01-11 14:16:59.610437: val_loss -0.5869 
2025-01-11 14:16:59.616455: Pseudo dice [np.float32(0.7068)] 
2025-01-11 14:16:59.620467: Epoch time: 40.42 s 
2025-01-11 14:17:00.165606:  
2025-01-11 14:17:00.165606: Epoch 220 
2025-01-11 14:17:00.170622: Current learning rate: 0.00148 
2025-01-11 14:17:40.593218: train_loss -0.8791 
2025-01-11 14:17:40.593720: val_loss -0.577 
2025-01-11 14:17:40.599743: Pseudo dice [np.float32(0.7081)] 
2025-01-11 14:17:40.602253: Epoch time: 40.43 s 
2025-01-11 14:17:41.147343:  
2025-01-11 14:17:41.147343: Epoch 221 
2025-01-11 14:17:41.152393: Current learning rate: 0.00144 
2025-01-11 14:18:21.394323: train_loss -0.8851 
2025-01-11 14:18:21.395328: val_loss -0.622 
2025-01-11 14:18:21.400345: Pseudo dice [np.float32(0.7367)] 
2025-01-11 14:18:21.404355: Epoch time: 40.25 s 
2025-01-11 14:18:21.941718:  
2025-01-11 14:18:21.941718: Epoch 222 
2025-01-11 14:18:21.947263: Current learning rate: 0.00139 
2025-01-11 14:19:02.130721: train_loss -0.8835 
2025-01-11 14:19:02.130721: val_loss -0.5748 
2025-01-11 14:19:02.137304: Pseudo dice [np.float32(0.6982)] 
2025-01-11 14:19:02.141488: Epoch time: 40.19 s 
2025-01-11 14:19:02.690115:  
2025-01-11 14:19:02.690115: Epoch 223 
2025-01-11 14:19:02.697278: Current learning rate: 0.00135 
2025-01-11 14:19:42.874204: train_loss -0.8815 
2025-01-11 14:19:42.875207: val_loss -0.5559 
2025-01-11 14:19:42.881222: Pseudo dice [np.float32(0.7004)] 
2025-01-11 14:19:42.885237: Epoch time: 40.19 s 
2025-01-11 14:19:43.599921:  
2025-01-11 14:19:43.600425: Epoch 224 
2025-01-11 14:19:43.605438: Current learning rate: 0.0013 
2025-01-11 14:20:23.775414: train_loss -0.8839 
2025-01-11 14:20:23.775918: val_loss -0.5711 
2025-01-11 14:20:23.781941: Pseudo dice [np.float32(0.6972)] 
2025-01-11 14:20:23.785951: Epoch time: 40.18 s 
2025-01-11 14:20:24.321983:  
2025-01-11 14:20:24.321983: Epoch 225 
2025-01-11 14:20:24.328063: Current learning rate: 0.00126 
2025-01-11 14:21:04.486938: train_loss -0.8791 
2025-01-11 14:21:04.487941: val_loss -0.6499 
2025-01-11 14:21:04.493959: Pseudo dice [np.float32(0.7398)] 
2025-01-11 14:21:04.496969: Epoch time: 40.16 s 
2025-01-11 14:21:05.036617:  
2025-01-11 14:21:05.036617: Epoch 226 
2025-01-11 14:21:05.042214: Current learning rate: 0.00121 
2025-01-11 14:21:45.176211: train_loss -0.884 
2025-01-11 14:21:45.177245: val_loss -0.6007 
2025-01-11 14:21:45.182307: Pseudo dice [np.float32(0.7482)] 
2025-01-11 14:21:45.185815: Epoch time: 40.14 s 
2025-01-11 14:21:45.730613:  
2025-01-11 14:21:45.731617: Epoch 227 
2025-01-11 14:21:45.736202: Current learning rate: 0.00117 
2025-01-11 14:22:25.973111: train_loss -0.8827 
2025-01-11 14:22:25.973111: val_loss -0.5618 
2025-01-11 14:22:25.979625: Pseudo dice [np.float32(0.6856)] 
2025-01-11 14:22:25.983134: Epoch time: 40.24 s 
2025-01-11 14:22:26.558609:  
2025-01-11 14:22:26.558609: Epoch 228 
2025-01-11 14:22:26.563621: Current learning rate: 0.00112 
2025-01-11 14:23:06.771413: train_loss -0.8854 
2025-01-11 14:23:06.771413: val_loss -0.5952 
2025-01-11 14:23:06.779086: Pseudo dice [np.float32(0.7205)] 
2025-01-11 14:23:06.782805: Epoch time: 40.21 s 
2025-01-11 14:23:07.321131:  
2025-01-11 14:23:07.321131: Epoch 229 
2025-01-11 14:23:07.326737: Current learning rate: 0.00108 
2025-01-11 14:23:47.492015: train_loss -0.885 
2025-01-11 14:23:47.492015: val_loss -0.5807 
2025-01-11 14:23:47.498034: Pseudo dice [np.float32(0.7026)] 
2025-01-11 14:23:47.502045: Epoch time: 40.17 s 
2025-01-11 14:23:48.041825:  
2025-01-11 14:23:48.042825: Epoch 230 
2025-01-11 14:23:48.048448: Current learning rate: 0.00103 
2025-01-11 14:24:28.225761: train_loss -0.89 
2025-01-11 14:24:28.227306: val_loss -0.5773 
2025-01-11 14:24:28.232322: Pseudo dice [np.float32(0.72)] 
2025-01-11 14:24:28.237027: Epoch time: 40.18 s 
2025-01-11 14:24:28.779257:  
2025-01-11 14:24:28.779257: Epoch 231 
2025-01-11 14:24:28.784273: Current learning rate: 0.00098 
2025-01-11 14:25:08.986216: train_loss -0.8831 
2025-01-11 14:25:08.987219: val_loss -0.5518 
2025-01-11 14:25:08.993234: Pseudo dice [np.float32(0.7128)] 
2025-01-11 14:25:08.996244: Epoch time: 40.21 s 
2025-01-11 14:25:09.539060:  
2025-01-11 14:25:09.539564: Epoch 232 
2025-01-11 14:25:09.544576: Current learning rate: 0.00094 
2025-01-11 14:25:49.710004: train_loss -0.8893 
2025-01-11 14:25:49.711008: val_loss -0.6212 
2025-01-11 14:25:49.717529: Pseudo dice [np.float32(0.7437)] 
2025-01-11 14:25:49.721040: Epoch time: 40.17 s 
2025-01-11 14:25:50.451218:  
2025-01-11 14:25:50.451218: Epoch 233 
2025-01-11 14:25:50.457236: Current learning rate: 0.00089 
2025-01-11 14:26:30.650223: train_loss -0.8852 
2025-01-11 14:26:30.650223: val_loss -0.5912 
2025-01-11 14:26:30.656239: Pseudo dice [np.float32(0.706)] 
2025-01-11 14:26:30.659778: Epoch time: 40.2 s 
2025-01-11 14:26:31.198723:  
2025-01-11 14:26:31.198723: Epoch 234 
2025-01-11 14:26:31.203736: Current learning rate: 0.00084 
2025-01-11 14:27:11.349808: train_loss -0.885 
2025-01-11 14:27:11.350808: val_loss -0.5398 
2025-01-11 14:27:11.357328: Pseudo dice [np.float32(0.7027)] 
2025-01-11 14:27:11.361379: Epoch time: 40.15 s 
2025-01-11 14:27:11.896957:  
2025-01-11 14:27:11.896957: Epoch 235 
2025-01-11 14:27:11.902474: Current learning rate: 0.00079 
2025-01-11 14:27:52.089357: train_loss -0.8888 
2025-01-11 14:27:52.089357: val_loss -0.5682 
2025-01-11 14:27:52.093928: Pseudo dice [np.float32(0.7029)] 
2025-01-11 14:27:52.098040: Epoch time: 40.19 s 
2025-01-11 14:27:52.650854:  
2025-01-11 14:27:52.650854: Epoch 236 
2025-01-11 14:27:52.656412: Current learning rate: 0.00075 
2025-01-11 14:28:32.852163: train_loss -0.8885 
2025-01-11 14:28:32.852163: val_loss -0.6304 
2025-01-11 14:28:32.858684: Pseudo dice [np.float32(0.7291)] 
2025-01-11 14:28:32.862197: Epoch time: 40.2 s 
2025-01-11 14:28:33.402366:  
2025-01-11 14:28:33.402878: Epoch 237 
2025-01-11 14:28:33.407994: Current learning rate: 0.0007 
2025-01-11 14:29:13.560994: train_loss -0.8893 
2025-01-11 14:29:13.561999: val_loss -0.5798 
2025-01-11 14:29:13.568518: Pseudo dice [np.float32(0.7187)] 
2025-01-11 14:29:13.572030: Epoch time: 40.16 s 
2025-01-11 14:29:14.112488:  
2025-01-11 14:29:14.112488: Epoch 238 
2025-01-11 14:29:14.118019: Current learning rate: 0.00065 
2025-01-11 14:29:54.285240: train_loss -0.8872 
2025-01-11 14:29:54.285751: val_loss -0.5492 
2025-01-11 14:29:54.290404: Pseudo dice [np.float32(0.6603)] 
2025-01-11 14:29:54.294010: Epoch time: 40.17 s 
2025-01-11 14:29:54.840342:  
2025-01-11 14:29:54.841846: Epoch 239 
2025-01-11 14:29:54.846859: Current learning rate: 0.0006 
2025-01-11 14:30:35.017486: train_loss -0.8853 
2025-01-11 14:30:35.017486: val_loss -0.548 
2025-01-11 14:30:35.023643: Pseudo dice [np.float32(0.6828)] 
2025-01-11 14:30:35.027678: Epoch time: 40.18 s 
2025-01-11 14:30:35.581336:  
2025-01-11 14:30:35.581336: Epoch 240 
2025-01-11 14:30:35.586350: Current learning rate: 0.00055 
2025-01-11 14:31:15.725674: train_loss -0.8856 
2025-01-11 14:31:15.726177: val_loss -0.6319 
2025-01-11 14:31:15.733197: Pseudo dice [np.float32(0.7372)] 
2025-01-11 14:31:15.736211: Epoch time: 40.15 s 
2025-01-11 14:31:16.285332:  
2025-01-11 14:31:16.286335: Epoch 241 
2025-01-11 14:31:16.290887: Current learning rate: 0.0005 
2025-01-11 14:31:56.548687: train_loss -0.8902 
2025-01-11 14:31:56.548687: val_loss -0.6321 
2025-01-11 14:31:56.555202: Pseudo dice [np.float32(0.7362)] 
2025-01-11 14:31:56.558711: Epoch time: 40.26 s 
2025-01-11 14:31:57.111904:  
2025-01-11 14:31:57.111904: Epoch 242 
2025-01-11 14:31:57.116924: Current learning rate: 0.00045 
2025-01-11 14:32:37.283429: train_loss -0.8884 
2025-01-11 14:32:37.283932: val_loss -0.5982 
2025-01-11 14:32:37.289955: Pseudo dice [np.float32(0.7163)] 
2025-01-11 14:32:37.293467: Epoch time: 40.17 s 
2025-01-11 14:32:37.912712:  
2025-01-11 14:32:37.912712: Epoch 243 
2025-01-11 14:32:37.919227: Current learning rate: 0.0004 
2025-01-11 14:33:18.102598: train_loss -0.8874 
2025-01-11 14:33:18.103102: val_loss -0.6307 
2025-01-11 14:33:18.108113: Pseudo dice [np.float32(0.737)] 
2025-01-11 14:33:18.111624: Epoch time: 40.19 s 
2025-01-11 14:33:18.653219:  
2025-01-11 14:33:18.654222: Epoch 244 
2025-01-11 14:33:18.658758: Current learning rate: 0.00035 
2025-01-11 14:33:58.800391: train_loss -0.8877 
2025-01-11 14:33:58.800902: val_loss -0.6027 
2025-01-11 14:33:58.806519: Pseudo dice [np.float32(0.7071)] 
2025-01-11 14:33:58.810123: Epoch time: 40.15 s 
2025-01-11 14:33:59.344540:  
2025-01-11 14:33:59.344540: Epoch 245 
2025-01-11 14:33:59.350080: Current learning rate: 0.0003 
2025-01-11 14:34:39.532117: train_loss -0.8923 
2025-01-11 14:34:39.533122: val_loss -0.6284 
2025-01-11 14:34:39.539643: Pseudo dice [np.float32(0.7351)] 
2025-01-11 14:34:39.542238: Epoch time: 40.19 s 
2025-01-11 14:34:40.085599:  
2025-01-11 14:34:40.087103: Epoch 246 
2025-01-11 14:34:40.092116: Current learning rate: 0.00024 
2025-01-11 14:35:20.263525: train_loss -0.8918 
2025-01-11 14:35:20.264029: val_loss -0.609 
2025-01-11 14:35:20.269051: Pseudo dice [np.float32(0.7289)] 
2025-01-11 14:35:20.272599: Epoch time: 40.18 s 
2025-01-11 14:35:20.862352:  
2025-01-11 14:35:20.862352: Epoch 247 
2025-01-11 14:35:20.867366: Current learning rate: 0.00019 
2025-01-11 14:36:00.996873: train_loss -0.8897 
2025-01-11 14:36:00.996873: val_loss -0.5901 
2025-01-11 14:36:01.002897: Pseudo dice [np.float32(0.7238)] 
2025-01-11 14:36:01.006405: Epoch time: 40.14 s 
2025-01-11 14:36:01.561612:  
2025-01-11 14:36:01.562114: Epoch 248 
2025-01-11 14:36:01.566678: Current learning rate: 0.00013 
2025-01-11 14:36:41.735909: train_loss -0.8893 
2025-01-11 14:36:41.735909: val_loss -0.5972 
2025-01-11 14:36:41.742437: Pseudo dice [np.float32(0.7005)] 
2025-01-11 14:36:41.745952: Epoch time: 40.18 s 
2025-01-11 14:36:42.296738:  
2025-01-11 14:36:42.297242: Epoch 249 
2025-01-11 14:36:42.302263: Current learning rate: 7e-05 
2025-01-11 14:37:22.485466: train_loss -0.8919 
2025-01-11 14:37:22.485466: val_loss -0.5657 
2025-01-11 14:37:22.491485: Pseudo dice [np.float32(0.7075)] 
2025-01-11 14:37:22.495495: Epoch time: 40.19 s 
2025-01-11 14:37:23.378783: Training done. 
2025-01-11 14:37:23.410783: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-11 14:37:23.417784: The split file contains 5 splits. 
2025-01-11 14:37:23.423788: Desired fold for training: 0 
2025-01-11 14:37:23.429785: This split has 100 training and 26 validation cases. 
2025-01-11 14:37:23.436786: predicting colon_008 
2025-01-11 14:37:23.443788: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-01-11 14:37:37.892841: predicting colon_027 
2025-01-11 14:37:37.909841: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-01-11 14:37:43.963281: predicting colon_030 
2025-01-11 14:37:43.971281: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-01-11 14:37:52.997080: predicting colon_033 
2025-01-11 14:37:53.008079: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-01-11 14:38:09.165210: predicting colon_041 
2025-01-11 14:38:09.184714: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-01-11 14:38:40.814856: predicting colon_042 
2025-01-11 14:38:40.842856: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-01-11 14:38:56.744524: predicting colon_061 
2025-01-11 14:38:56.763525: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-01-11 14:39:17.099227: predicting colon_074 
2025-01-11 14:39:17.118733: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-01-11 14:39:40.866705: predicting colon_075 
2025-01-11 14:39:40.890706: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-01-11 14:39:55.009176: predicting colon_088 
2025-01-11 14:39:55.026180: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-01-11 14:40:22.704153: predicting colon_091 
2025-01-11 14:40:22.728152: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-01-11 14:40:45.946446: predicting colon_092 
2025-01-11 14:40:45.972450: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-01-11 14:41:06.251379: predicting colon_095 
2025-01-11 14:41:06.269380: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-01-11 14:41:20.443287: predicting colon_102 
2025-01-11 14:41:20.462285: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-01-11 14:41:48.078237: predicting colon_111 
2025-01-11 14:41:48.103239: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-01-11 14:41:56.854554: predicting colon_115 
2025-01-11 14:41:56.866555: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-01-11 14:42:13.051862: predicting colon_118 
2025-01-11 14:42:13.068861: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-01-11 14:42:36.285469: predicting colon_124 
2025-01-11 14:42:36.304469: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-01-11 14:42:56.593213: predicting colon_127 
2025-01-11 14:42:56.614213: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-01-11 14:43:36.098657: predicting colon_154 
2025-01-11 14:43:36.133670: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-01-11 14:43:50.344354: predicting colon_161 
2025-01-11 14:43:50.364356: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-01-11 14:44:04.517061: predicting colon_162 
2025-01-11 14:44:04.533569: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-01-11 14:44:36.182292: predicting colon_165 
2025-01-11 14:44:36.210291: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-01-11 14:45:03.866595: predicting colon_166 
2025-01-11 14:45:03.890101: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-01-11 14:45:18.013033: predicting colon_169 
2025-01-11 14:45:18.028033: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-01-11 14:45:57.605915: predicting colon_187 
2025-01-11 14:45:57.642423: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-01-11 14:46:27.688153: Validation complete 
2025-01-11 14:46:27.688153: Mean Validation Dice:  0.4142156372683428 
