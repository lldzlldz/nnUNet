
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-19 23:33:00.894678: do_dummy_2d_data_aug: False 
2025-01-19 23:33:00.896680: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-19 23:33:00.901679: The split file contains 5 splits. 
2025-01-19 23:33:00.903681: Desired fold for training: 0 
2025-01-19 23:33:00.906681: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_avg_spacing_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [219.0, 195.0, 195.0], 'spacing': [2.052082783330685, 2.052082783330685, 2.052082783330685], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans_avg_spacing', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-01-19 23:33:07.475479: unpacking dataset... 
2025-01-19 23:33:07.707822: unpacking done... 
2025-01-19 23:33:10.664842:  
2025-01-19 23:33:10.665845: Epoch 50 
2025-01-19 23:33:10.669853: Current learning rate: 0.00631 
2025-01-19 23:33:51.845566: train_loss -0.2977 
2025-01-19 23:33:51.846101: val_loss -0.2571 
2025-01-19 23:33:51.851213: Pseudo dice [np.float32(0.44)] 
2025-01-19 23:33:51.854250: Epoch time: 41.18 s 
2025-01-19 23:33:51.857298: Yayy! New best EMA pseudo Dice: 0.4422000050544739 
2025-01-19 23:33:52.541566:  
2025-01-19 23:33:52.541566: Epoch 51 
2025-01-19 23:33:52.546580: Current learning rate: 0.00624 
2025-01-19 23:34:29.093980: train_loss -0.2924 
2025-01-19 23:34:29.094985: val_loss -0.2346 
2025-01-19 23:34:29.100503: Pseudo dice [np.float32(0.4142)] 
2025-01-19 23:34:29.104046: Epoch time: 36.55 s 
2025-01-19 23:34:29.607300:  
2025-01-19 23:34:29.607300: Epoch 52 
2025-01-19 23:34:29.612353: Current learning rate: 0.00616 
2025-01-19 23:35:06.085950: train_loss -0.2794 
2025-01-19 23:35:06.085950: val_loss -0.2704 
2025-01-19 23:35:06.091994: Pseudo dice [np.float32(0.4846)] 
2025-01-19 23:35:06.095040: Epoch time: 36.48 s 
2025-01-19 23:35:06.098367: Yayy! New best EMA pseudo Dice: 0.4438999891281128 
2025-01-19 23:35:06.769116:  
2025-01-19 23:35:06.769116: Epoch 53 
2025-01-19 23:35:06.772174: Current learning rate: 0.00609 
2025-01-19 23:35:43.192775: train_loss -0.2947 
2025-01-19 23:35:43.193277: val_loss -0.2766 
2025-01-19 23:35:43.198345: Pseudo dice [np.float32(0.5516)] 
2025-01-19 23:35:43.200866: Epoch time: 36.43 s 
2025-01-19 23:35:43.203929: Yayy! New best EMA pseudo Dice: 0.4546999931335449 
2025-01-19 23:35:43.884445:  
2025-01-19 23:35:43.884445: Epoch 54 
2025-01-19 23:35:43.887960: Current learning rate: 0.00601 
2025-01-19 23:36:20.342536: train_loss -0.314 
2025-01-19 23:36:20.343536: val_loss -0.2765 
2025-01-19 23:36:20.349052: Pseudo dice [np.float32(0.5208)] 
2025-01-19 23:36:20.351558: Epoch time: 36.46 s 
2025-01-19 23:36:20.355069: Yayy! New best EMA pseudo Dice: 0.46129998564720154 
2025-01-19 23:36:21.138913:  
2025-01-19 23:36:21.138913: Epoch 55 
2025-01-19 23:36:21.144475: Current learning rate: 0.00593 
2025-01-19 23:36:57.590818: train_loss -0.3012 
2025-01-19 23:36:57.591818: val_loss -0.2527 
2025-01-19 23:36:57.597374: Pseudo dice [np.float32(0.5262)] 
2025-01-19 23:36:57.599879: Epoch time: 36.45 s 
2025-01-19 23:36:57.603389: Yayy! New best EMA pseudo Dice: 0.46779999136924744 
2025-01-19 23:36:58.277743:  
2025-01-19 23:36:58.277743: Epoch 56 
2025-01-19 23:36:58.283328: Current learning rate: 0.00586 
2025-01-19 23:37:34.713253: train_loss -0.3139 
2025-01-19 23:37:34.713765: val_loss -0.2667 
2025-01-19 23:37:34.718868: Pseudo dice [np.float32(0.5359)] 
2025-01-19 23:37:34.721978: Epoch time: 36.44 s 
2025-01-19 23:37:34.725046: Yayy! New best EMA pseudo Dice: 0.4745999872684479 
2025-01-19 23:37:35.384550:  
2025-01-19 23:37:35.385055: Epoch 57 
2025-01-19 23:37:35.390173: Current learning rate: 0.00578 
2025-01-19 23:38:11.827534: train_loss -0.3209 
2025-01-19 23:38:11.828043: val_loss -0.2229 
2025-01-19 23:38:11.832603: Pseudo dice [np.float32(0.4343)] 
2025-01-19 23:38:11.836150: Epoch time: 36.44 s 
2025-01-19 23:38:12.331468:  
2025-01-19 23:38:12.331972: Epoch 58 
2025-01-19 23:38:12.336991: Current learning rate: 0.0057 
2025-01-19 23:38:48.746770: train_loss -0.3122 
2025-01-19 23:38:48.746770: val_loss -0.2048 
2025-01-19 23:38:48.751784: Pseudo dice [np.float32(0.4173)] 
2025-01-19 23:38:48.755292: Epoch time: 36.42 s 
2025-01-19 23:38:49.263102:  
2025-01-19 23:38:49.263102: Epoch 59 
2025-01-19 23:38:49.268131: Current learning rate: 0.00563 
2025-01-19 23:39:26.105671: train_loss -0.3196 
2025-01-19 23:39:26.105671: val_loss -0.2548 
2025-01-19 23:39:26.110758: Pseudo dice [np.float32(0.4836)] 
2025-01-19 23:39:26.114794: Epoch time: 36.84 s 
2025-01-19 23:39:26.708906:  
2025-01-19 23:39:26.709906: Epoch 60 
2025-01-19 23:39:26.714470: Current learning rate: 0.00555 
2025-01-19 23:40:03.284575: train_loss -0.3175 
2025-01-19 23:40:03.285078: val_loss -0.2444 
2025-01-19 23:40:03.290285: Pseudo dice [np.float32(0.5135)] 
2025-01-19 23:40:03.293331: Epoch time: 36.58 s 
2025-01-19 23:40:03.871297:  
2025-01-19 23:40:03.871801: Epoch 61 
2025-01-19 23:40:03.876815: Current learning rate: 0.00547 
2025-01-19 23:40:40.493591: train_loss -0.3211 
2025-01-19 23:40:40.494096: val_loss -0.2593 
2025-01-19 23:40:40.499113: Pseudo dice [np.float32(0.5291)] 
2025-01-19 23:40:40.502629: Epoch time: 36.62 s 
2025-01-19 23:40:40.504647: Yayy! New best EMA pseudo Dice: 0.47749999165534973 
2025-01-19 23:40:41.243499:  
2025-01-19 23:40:41.245001: Epoch 62 
2025-01-19 23:40:41.248512: Current learning rate: 0.0054 
2025-01-19 23:41:17.892098: train_loss -0.3121 
2025-01-19 23:41:17.892098: val_loss -0.2895 
2025-01-19 23:41:17.897176: Pseudo dice [np.float32(0.5004)] 
2025-01-19 23:41:17.899686: Epoch time: 36.65 s 
2025-01-19 23:41:17.903197: Yayy! New best EMA pseudo Dice: 0.4797999858856201 
2025-01-19 23:41:18.642950:  
2025-01-19 23:41:18.642950: Epoch 63 
2025-01-19 23:41:18.648519: Current learning rate: 0.00532 
2025-01-19 23:41:55.266402: train_loss -0.3132 
2025-01-19 23:41:55.266918: val_loss -0.2527 
2025-01-19 23:41:55.272632: Pseudo dice [np.float32(0.471)] 
2025-01-19 23:41:55.275217: Epoch time: 36.62 s 
2025-01-19 23:41:55.848893:  
2025-01-19 23:41:55.849896: Epoch 64 
2025-01-19 23:41:55.854493: Current learning rate: 0.00524 
2025-01-19 23:42:32.413655: train_loss -0.3059 
2025-01-19 23:42:32.414161: val_loss -0.2669 
2025-01-19 23:42:32.419818: Pseudo dice [np.float32(0.4667)] 
2025-01-19 23:42:32.423492: Epoch time: 36.56 s 
2025-01-19 23:42:32.989159:  
2025-01-19 23:42:32.990163: Epoch 65 
2025-01-19 23:42:32.995210: Current learning rate: 0.00517 
2025-01-19 23:43:09.594156: train_loss -0.342 
2025-01-19 23:43:09.594156: val_loss -0.263 
2025-01-19 23:43:09.600326: Pseudo dice [np.float32(0.5069)] 
2025-01-19 23:43:09.603372: Epoch time: 36.6 s 
2025-01-19 23:43:09.605917: Yayy! New best EMA pseudo Dice: 0.4805999994277954 
2025-01-19 23:43:10.356688:  
2025-01-19 23:43:10.356688: Epoch 66 
2025-01-19 23:43:10.361736: Current learning rate: 0.00509 
2025-01-19 23:43:46.952493: train_loss -0.3287 
2025-01-19 23:43:46.952493: val_loss -0.2581 
2025-01-19 23:43:46.958523: Pseudo dice [np.float32(0.5)] 
2025-01-19 23:43:46.962539: Epoch time: 36.6 s 
2025-01-19 23:43:46.966056: Yayy! New best EMA pseudo Dice: 0.48249998688697815 
2025-01-19 23:43:47.738191:  
2025-01-19 23:43:47.738191: Epoch 67 
2025-01-19 23:43:47.743851: Current learning rate: 0.00501 
2025-01-19 23:44:24.467939: train_loss -0.3223 
2025-01-19 23:44:24.468450: val_loss -0.3095 
2025-01-19 23:44:24.474598: Pseudo dice [np.float32(0.5514)] 
2025-01-19 23:44:24.477639: Epoch time: 36.73 s 
2025-01-19 23:44:24.480734: Yayy! New best EMA pseudo Dice: 0.4893999993801117 
2025-01-19 23:44:25.231132:  
2025-01-19 23:44:25.231642: Epoch 68 
2025-01-19 23:44:25.238313: Current learning rate: 0.00493 
2025-01-19 23:45:01.846657: train_loss -0.3341 
2025-01-19 23:45:01.847171: val_loss -0.314 
2025-01-19 23:45:01.852851: Pseudo dice [np.float32(0.6064)] 
2025-01-19 23:45:01.855421: Epoch time: 36.62 s 
2025-01-19 23:45:01.858471: Yayy! New best EMA pseudo Dice: 0.5011000037193298 
2025-01-19 23:45:02.614336:  
2025-01-19 23:45:02.614844: Epoch 69 
2025-01-19 23:45:02.619904: Current learning rate: 0.00485 
2025-01-19 23:45:39.222433: train_loss -0.3296 
2025-01-19 23:45:39.223432: val_loss -0.2717 
2025-01-19 23:45:39.228948: Pseudo dice [np.float32(0.5498)] 
2025-01-19 23:45:39.232462: Epoch time: 36.61 s 
2025-01-19 23:45:39.235967: Yayy! New best EMA pseudo Dice: 0.5059999823570251 
2025-01-19 23:45:40.129806:  
2025-01-19 23:45:40.129806: Epoch 70 
2025-01-19 23:45:40.134842: Current learning rate: 0.00478 
2025-01-19 23:46:16.721964: train_loss -0.3145 
2025-01-19 23:46:16.722969: val_loss -0.2642 
2025-01-19 23:46:16.729592: Pseudo dice [np.float32(0.5613)] 
2025-01-19 23:46:16.733688: Epoch time: 36.59 s 
2025-01-19 23:46:16.736232: Yayy! New best EMA pseudo Dice: 0.5115000009536743 
2025-01-19 23:46:17.498140:  
2025-01-19 23:46:17.498140: Epoch 71 
2025-01-19 23:46:17.503715: Current learning rate: 0.0047 
2025-01-19 23:46:54.139286: train_loss -0.3448 
2025-01-19 23:46:54.139844: val_loss -0.242 
2025-01-19 23:46:54.144943: Pseudo dice [np.float32(0.4696)] 
2025-01-19 23:46:54.148473: Epoch time: 36.64 s 
2025-01-19 23:46:54.735782:  
2025-01-19 23:46:54.735782: Epoch 72 
2025-01-19 23:46:54.741302: Current learning rate: 0.00462 
2025-01-19 23:47:31.376286: train_loss -0.347 
2025-01-19 23:47:31.376286: val_loss -0.2863 
2025-01-19 23:47:31.382808: Pseudo dice [np.float32(0.5553)] 
2025-01-19 23:47:31.385846: Epoch time: 36.64 s 
2025-01-19 23:47:31.388877: Yayy! New best EMA pseudo Dice: 0.5120999813079834 
2025-01-19 23:47:32.151475:  
2025-01-19 23:47:32.152479: Epoch 73 
2025-01-19 23:47:32.158043: Current learning rate: 0.00454 
2025-01-19 23:48:08.790276: train_loss -0.3401 
2025-01-19 23:48:08.791279: val_loss -0.2917 
2025-01-19 23:48:08.796848: Pseudo dice [np.float32(0.5403)] 
2025-01-19 23:48:08.800400: Epoch time: 36.64 s 
2025-01-19 23:48:08.802929: Yayy! New best EMA pseudo Dice: 0.5149000287055969 
2025-01-19 23:48:09.572714:  
2025-01-19 23:48:09.572714: Epoch 74 
2025-01-19 23:48:09.577776: Current learning rate: 0.00446 
2025-01-19 23:48:46.187100: train_loss -0.3351 
2025-01-19 23:48:46.187100: val_loss -0.24 
2025-01-19 23:48:46.193144: Pseudo dice [np.float32(0.4148)] 
2025-01-19 23:48:46.197185: Epoch time: 36.61 s 
2025-01-19 23:48:46.790308:  
2025-01-19 23:48:46.790911: Epoch 75 
2025-01-19 23:48:46.796019: Current learning rate: 0.00438 
2025-01-19 23:49:23.421378: train_loss -0.3314 
2025-01-19 23:49:23.421882: val_loss -0.2809 
2025-01-19 23:49:23.427498: Pseudo dice [np.float32(0.5301)] 
2025-01-19 23:49:23.431007: Epoch time: 36.63 s 
2025-01-19 23:49:24.015206:  
2025-01-19 23:49:24.016215: Epoch 76 
2025-01-19 23:49:24.020761: Current learning rate: 0.0043 
2025-01-19 23:50:00.467634: train_loss -0.3459 
2025-01-19 23:50:00.468145: val_loss -0.2561 
2025-01-19 23:50:00.473197: Pseudo dice [np.float32(0.4957)] 
2025-01-19 23:50:00.476273: Epoch time: 36.45 s 
2025-01-19 23:50:01.223212:  
2025-01-19 23:50:01.223717: Epoch 77 
2025-01-19 23:50:01.228772: Current learning rate: 0.00423 
2025-01-19 23:50:37.684405: train_loss -0.3399 
2025-01-19 23:50:37.685404: val_loss -0.2091 
2025-01-19 23:50:37.691031: Pseudo dice [np.float32(0.4135)] 
2025-01-19 23:50:37.693555: Epoch time: 36.46 s 
2025-01-19 23:50:38.296329:  
2025-01-19 23:50:38.296329: Epoch 78 
2025-01-19 23:50:38.301845: Current learning rate: 0.00415 
2025-01-19 23:51:14.771778: train_loss -0.3238 
2025-01-19 23:51:14.771778: val_loss -0.3152 
2025-01-19 23:51:14.780304: Pseudo dice [np.float32(0.5462)] 
2025-01-19 23:51:14.785317: Epoch time: 36.48 s 
2025-01-19 23:51:15.373776:  
2025-01-19 23:51:15.374778: Epoch 79 
2025-01-19 23:51:15.380376: Current learning rate: 0.00407 
2025-01-19 23:51:51.878963: train_loss -0.3199 
2025-01-19 23:51:51.879475: val_loss -0.3016 
2025-01-19 23:51:51.885094: Pseudo dice [np.float32(0.6362)] 
2025-01-19 23:51:51.888649: Epoch time: 36.51 s 
2025-01-19 23:51:51.891776: Yayy! New best EMA pseudo Dice: 0.5152999758720398 
2025-01-19 23:51:52.673542:  
2025-01-19 23:51:52.673542: Epoch 80 
2025-01-19 23:51:52.679080: Current learning rate: 0.00399 
2025-01-19 23:52:29.120359: train_loss -0.3445 
2025-01-19 23:52:29.120359: val_loss -0.2659 
2025-01-19 23:52:29.126877: Pseudo dice [np.float32(0.5129)] 
2025-01-19 23:52:29.129383: Epoch time: 36.45 s 
2025-01-19 23:52:29.735829:  
2025-01-19 23:52:29.735829: Epoch 81 
2025-01-19 23:52:29.742409: Current learning rate: 0.00391 
2025-01-19 23:53:06.217559: train_loss -0.3663 
2025-01-19 23:53:06.218075: val_loss -0.2707 
2025-01-19 23:53:06.223157: Pseudo dice [np.float32(0.567)] 
2025-01-19 23:53:06.227211: Epoch time: 36.48 s 
2025-01-19 23:53:06.230249: Yayy! New best EMA pseudo Dice: 0.5202999711036682 
2025-01-19 23:53:06.989364:  
2025-01-19 23:53:06.990364: Epoch 82 
2025-01-19 23:53:06.993400: Current learning rate: 0.00383 
2025-01-19 23:53:43.470304: train_loss -0.3622 
2025-01-19 23:53:43.471806: val_loss -0.2663 
2025-01-19 23:53:43.476821: Pseudo dice [np.float32(0.4524)] 
2025-01-19 23:53:43.479838: Epoch time: 36.48 s 
2025-01-19 23:53:44.031056:  
2025-01-19 23:53:44.032058: Epoch 83 
2025-01-19 23:53:44.036699: Current learning rate: 0.00375 
2025-01-19 23:54:20.513310: train_loss -0.3516 
2025-01-19 23:54:20.513828: val_loss -0.3005 
2025-01-19 23:54:20.518968: Pseudo dice [np.float32(0.6138)] 
2025-01-19 23:54:20.522022: Epoch time: 36.48 s 
2025-01-19 23:54:20.525153: Yayy! New best EMA pseudo Dice: 0.5235000252723694 
2025-01-19 23:54:21.266648:  
2025-01-19 23:54:21.266648: Epoch 84 
2025-01-19 23:54:21.272181: Current learning rate: 0.00367 
2025-01-19 23:54:57.771423: train_loss -0.3467 
2025-01-19 23:54:57.771423: val_loss -0.2429 
2025-01-19 23:54:57.776440: Pseudo dice [np.float32(0.5097)] 
2025-01-19 23:54:57.780468: Epoch time: 36.51 s 
2025-01-19 23:54:58.482342:  
2025-01-19 23:54:58.482342: Epoch 85 
2025-01-19 23:54:58.487878: Current learning rate: 0.00359 
2025-01-19 23:55:34.939869: train_loss -0.3638 
2025-01-19 23:55:34.940372: val_loss -0.282 
2025-01-19 23:55:34.945386: Pseudo dice [np.float32(0.5935)] 
2025-01-19 23:55:34.948895: Epoch time: 36.46 s 
2025-01-19 23:55:34.952426: Yayy! New best EMA pseudo Dice: 0.5292999744415283 
2025-01-19 23:55:35.676708:  
2025-01-19 23:55:35.676708: Epoch 86 
2025-01-19 23:55:35.682278: Current learning rate: 0.00351 
2025-01-19 23:56:12.147535: train_loss -0.3629 
2025-01-19 23:56:12.148534: val_loss -0.2276 
2025-01-19 23:56:12.154050: Pseudo dice [np.float32(0.5158)] 
2025-01-19 23:56:12.156555: Epoch time: 36.47 s 
2025-01-19 23:56:12.704437:  
2025-01-19 23:56:12.705441: Epoch 87 
2025-01-19 23:56:12.710512: Current learning rate: 0.00342 
2025-01-19 23:56:49.149110: train_loss -0.3579 
2025-01-19 23:56:49.149611: val_loss -0.2996 
2025-01-19 23:56:49.154701: Pseudo dice [np.float32(0.566)] 
2025-01-19 23:56:49.157308: Epoch time: 36.45 s 
2025-01-19 23:56:49.161375: Yayy! New best EMA pseudo Dice: 0.5317000150680542 
2025-01-19 23:56:49.881185:  
2025-01-19 23:56:49.882688: Epoch 88 
2025-01-19 23:56:49.887774: Current learning rate: 0.00334 
2025-01-19 23:57:26.336658: train_loss -0.3468 
2025-01-19 23:57:26.337662: val_loss -0.2355 
2025-01-19 23:57:26.343175: Pseudo dice [np.float32(0.4972)] 
2025-01-19 23:57:26.346214: Epoch time: 36.46 s 
2025-01-19 23:57:26.890433:  
2025-01-19 23:57:26.890433: Epoch 89 
2025-01-19 23:57:26.894958: Current learning rate: 0.00326 
2025-01-19 23:58:03.340081: train_loss -0.3669 
2025-01-19 23:58:03.340593: val_loss -0.256 
2025-01-19 23:58:03.345677: Pseudo dice [np.float32(0.5729)] 
2025-01-19 23:58:03.348220: Epoch time: 36.45 s 
2025-01-19 23:58:03.351261: Yayy! New best EMA pseudo Dice: 0.5327000021934509 
2025-01-19 23:58:04.076537:  
2025-01-19 23:58:04.077039: Epoch 90 
2025-01-19 23:58:04.080548: Current learning rate: 0.00318 
2025-01-19 23:58:40.538589: train_loss -0.3659 
2025-01-19 23:58:40.539095: val_loss -0.3094 
2025-01-19 23:58:40.544650: Pseudo dice [np.float32(0.6308)] 
2025-01-19 23:58:40.547679: Epoch time: 36.46 s 
2025-01-19 23:58:40.550200: Yayy! New best EMA pseudo Dice: 0.5425999760627747 
2025-01-19 23:58:41.270694:  
2025-01-19 23:58:41.270694: Epoch 91 
2025-01-19 23:58:41.274782: Current learning rate: 0.0031 
2025-01-19 23:59:17.723312: train_loss -0.3628 
2025-01-19 23:59:17.724316: val_loss -0.2696 
2025-01-19 23:59:17.729918: Pseudo dice [np.float32(0.5649)] 
2025-01-19 23:59:17.732951: Epoch time: 36.45 s 
2025-01-19 23:59:17.735983: Yayy! New best EMA pseudo Dice: 0.5447999835014343 
2025-01-19 23:59:18.457842:  
2025-01-19 23:59:18.457842: Epoch 92 
2025-01-19 23:59:18.462876: Current learning rate: 0.00302 
2025-01-19 23:59:54.905292: train_loss -0.353 
2025-01-19 23:59:54.905797: val_loss -0.3136 
2025-01-19 23:59:54.911811: Pseudo dice [np.float32(0.6063)] 
2025-01-19 23:59:54.915818: Epoch time: 36.45 s 
2025-01-19 23:59:54.918324: Yayy! New best EMA pseudo Dice: 0.5508999824523926 
2025-01-19 23:59:55.796440:  
2025-01-19 23:59:55.797446: Epoch 93 
2025-01-19 23:59:55.802514: Current learning rate: 0.00293 
2025-01-20 00:00:32.271472: train_loss -0.3572 
2025-01-20 00:00:32.271983: val_loss -0.2815 
2025-01-20 00:00:32.277136: Pseudo dice [np.float32(0.5882)] 
2025-01-20 00:00:32.280195: Epoch time: 36.48 s 
2025-01-20 00:00:32.283768: Yayy! New best EMA pseudo Dice: 0.5547000169754028 
2025-01-20 00:00:33.010699:  
2025-01-20 00:00:33.011201: Epoch 94 
2025-01-20 00:00:33.016211: Current learning rate: 0.00285 
2025-01-20 00:01:09.452536: train_loss -0.3516 
2025-01-20 00:01:09.453047: val_loss -0.2651 
2025-01-20 00:01:09.457073: Pseudo dice [np.float32(0.5235)] 
2025-01-20 00:01:09.460099: Epoch time: 36.44 s 
2025-01-20 00:01:10.016577:  
2025-01-20 00:01:10.017080: Epoch 95 
2025-01-20 00:01:10.021617: Current learning rate: 0.00277 
2025-01-20 00:01:46.441869: train_loss -0.3705 
2025-01-20 00:01:46.442371: val_loss -0.2792 
2025-01-20 00:01:46.448385: Pseudo dice [np.float32(0.5722)] 
2025-01-20 00:01:46.451914: Epoch time: 36.43 s 
2025-01-20 00:01:47.009911:  
2025-01-20 00:01:47.010914: Epoch 96 
2025-01-20 00:01:47.015440: Current learning rate: 0.00268 
2025-01-20 00:02:23.469670: train_loss -0.3705 
2025-01-20 00:02:23.470673: val_loss -0.3021 
2025-01-20 00:02:23.475684: Pseudo dice [np.float32(0.4961)] 
2025-01-20 00:02:23.479691: Epoch time: 36.46 s 
2025-01-20 00:02:24.040360:  
2025-01-20 00:02:24.040360: Epoch 97 
2025-01-20 00:02:24.045372: Current learning rate: 0.0026 
2025-01-20 00:03:00.527074: train_loss -0.3644 
2025-01-20 00:03:00.528640: val_loss -0.286 
2025-01-20 00:03:00.532713: Pseudo dice [np.float32(0.5694)] 
2025-01-20 00:03:00.537242: Epoch time: 36.49 s 
2025-01-20 00:03:01.098805:  
2025-01-20 00:03:01.098805: Epoch 98 
2025-01-20 00:03:01.103820: Current learning rate: 0.00252 
2025-01-20 00:03:37.541127: train_loss -0.3799 
2025-01-20 00:03:37.541629: val_loss -0.2646 
2025-01-20 00:03:37.547170: Pseudo dice [np.float32(0.5918)] 
2025-01-20 00:03:37.552207: Epoch time: 36.44 s 
2025-01-20 00:03:38.116266:  
2025-01-20 00:03:38.116768: Epoch 99 
2025-01-20 00:03:38.121778: Current learning rate: 0.00243 
2025-01-20 00:04:14.583234: train_loss -0.3648 
2025-01-20 00:04:14.583234: val_loss -0.2635 
2025-01-20 00:04:14.589748: Pseudo dice [np.float32(0.571)] 
2025-01-20 00:04:14.592295: Epoch time: 36.47 s 
2025-01-20 00:04:14.764729: Yayy! New best EMA pseudo Dice: 0.555899977684021 
2025-01-20 00:04:15.498709:  
2025-01-20 00:04:15.499712: Epoch 100 
2025-01-20 00:04:15.504741: Current learning rate: 0.00235 
2025-01-20 00:04:51.959546: train_loss -0.3801 
2025-01-20 00:04:51.960550: val_loss -0.26 
2025-01-20 00:04:51.966560: Pseudo dice [np.float32(0.5981)] 
2025-01-20 00:04:51.969568: Epoch time: 36.46 s 
2025-01-20 00:04:51.972074: Yayy! New best EMA pseudo Dice: 0.5601000189781189 
2025-01-20 00:04:52.712670:  
2025-01-20 00:04:52.712670: Epoch 101 
2025-01-20 00:04:52.718187: Current learning rate: 0.00226 
2025-01-20 00:05:29.184363: train_loss -0.3696 
2025-01-20 00:05:29.185369: val_loss -0.2874 
2025-01-20 00:05:29.190707: Pseudo dice [np.float32(0.505)] 
2025-01-20 00:05:29.194216: Epoch time: 36.47 s 
2025-01-20 00:05:29.924619:  
2025-01-20 00:05:29.924619: Epoch 102 
2025-01-20 00:05:29.929658: Current learning rate: 0.00218 
2025-01-20 00:06:06.410514: train_loss -0.3705 
2025-01-20 00:06:06.411018: val_loss -0.2783 
2025-01-20 00:06:06.417162: Pseudo dice [np.float32(0.5377)] 
2025-01-20 00:06:06.420312: Epoch time: 36.49 s 
2025-01-20 00:06:06.979062:  
2025-01-20 00:06:06.980059: Epoch 103 
2025-01-20 00:06:06.985075: Current learning rate: 0.00209 
2025-01-20 00:06:43.430108: train_loss -0.3819 
2025-01-20 00:06:43.430618: val_loss -0.2576 
2025-01-20 00:06:43.436722: Pseudo dice [np.float32(0.5094)] 
2025-01-20 00:06:43.439884: Epoch time: 36.45 s 
2025-01-20 00:06:44.003847:  
2025-01-20 00:06:44.004851: Epoch 104 
2025-01-20 00:06:44.009895: Current learning rate: 0.00201 
2025-01-20 00:07:20.466433: train_loss -0.3655 
2025-01-20 00:07:20.466936: val_loss -0.3059 
2025-01-20 00:07:20.472954: Pseudo dice [np.float32(0.638)] 
2025-01-20 00:07:20.476041: Epoch time: 36.46 s 
2025-01-20 00:07:21.079510:  
2025-01-20 00:07:21.080515: Epoch 105 
2025-01-20 00:07:21.086068: Current learning rate: 0.00192 
2025-01-20 00:07:57.545437: train_loss -0.3713 
2025-01-20 00:07:57.546442: val_loss -0.2983 
2025-01-20 00:07:57.550521: Pseudo dice [np.float32(0.5798)] 
2025-01-20 00:07:57.553560: Epoch time: 36.47 s 
2025-01-20 00:07:58.113030:  
2025-01-20 00:07:58.113030: Epoch 106 
2025-01-20 00:07:58.119045: Current learning rate: 0.00184 
2025-01-20 00:08:34.553712: train_loss -0.3843 
2025-01-20 00:08:34.553712: val_loss -0.273 
2025-01-20 00:08:34.560292: Pseudo dice [np.float32(0.5552)] 
2025-01-20 00:08:34.563322: Epoch time: 36.44 s 
2025-01-20 00:08:35.123242:  
2025-01-20 00:08:35.124246: Epoch 107 
2025-01-20 00:08:35.128782: Current learning rate: 0.00175 
2025-01-20 00:09:11.585825: train_loss -0.3931 
2025-01-20 00:09:11.586831: val_loss -0.2707 
2025-01-20 00:09:11.591723: Pseudo dice [np.float32(0.589)] 
2025-01-20 00:09:11.594933: Epoch time: 36.46 s 
2025-01-20 00:09:11.597439: Yayy! New best EMA pseudo Dice: 0.5622000098228455 
2025-01-20 00:09:12.333986:  
2025-01-20 00:09:12.333986: Epoch 108 
2025-01-20 00:09:12.339000: Current learning rate: 0.00166 
2025-01-20 00:09:48.782018: train_loss -0.3935 
2025-01-20 00:09:48.782533: val_loss -0.3008 
2025-01-20 00:09:48.787634: Pseudo dice [np.float32(0.5995)] 
2025-01-20 00:09:48.790679: Epoch time: 36.45 s 
2025-01-20 00:09:48.793233: Yayy! New best EMA pseudo Dice: 0.5659999847412109 
2025-01-20 00:09:49.537886:  
2025-01-20 00:09:49.537886: Epoch 109 
2025-01-20 00:09:49.542957: Current learning rate: 0.00157 
2025-01-20 00:10:25.974897: train_loss -0.3936 
2025-01-20 00:10:25.974897: val_loss -0.2499 
2025-01-20 00:10:25.982452: Pseudo dice [np.float32(0.5598)] 
2025-01-20 00:10:25.984960: Epoch time: 36.44 s 
2025-01-20 00:10:26.691099:  
2025-01-20 00:10:26.692099: Epoch 110 
2025-01-20 00:10:26.695144: Current learning rate: 0.00148 
2025-01-20 00:11:03.121213: train_loss -0.3983 
2025-01-20 00:11:03.122216: val_loss -0.2618 
2025-01-20 00:11:03.127794: Pseudo dice [np.float32(0.5512)] 
2025-01-20 00:11:03.129817: Epoch time: 36.43 s 
2025-01-20 00:11:03.692270:  
2025-01-20 00:11:03.692270: Epoch 111 
2025-01-20 00:11:03.697835: Current learning rate: 0.00139 
2025-01-20 00:11:40.169767: train_loss -0.4011 
2025-01-20 00:11:40.170773: val_loss -0.3045 
2025-01-20 00:11:40.176294: Pseudo dice [np.float32(0.6086)] 
2025-01-20 00:11:40.179850: Epoch time: 36.48 s 
2025-01-20 00:11:40.182356: Yayy! New best EMA pseudo Dice: 0.5684000253677368 
2025-01-20 00:11:40.926440:  
2025-01-20 00:11:40.926440: Epoch 112 
2025-01-20 00:11:40.932155: Current learning rate: 0.0013 
2025-01-20 00:12:17.391375: train_loss -0.3705 
2025-01-20 00:12:17.391945: val_loss -0.2643 
2025-01-20 00:12:17.397964: Pseudo dice [np.float32(0.5314)] 
2025-01-20 00:12:17.401974: Epoch time: 36.47 s 
2025-01-20 00:12:17.963457:  
2025-01-20 00:12:17.963961: Epoch 113 
2025-01-20 00:12:17.968975: Current learning rate: 0.00121 
2025-01-20 00:12:54.436427: train_loss -0.3857 
2025-01-20 00:12:54.436929: val_loss -0.322 
2025-01-20 00:12:54.442493: Pseudo dice [np.float32(0.6645)] 
2025-01-20 00:12:54.445079: Epoch time: 36.47 s 
2025-01-20 00:12:54.448596: Yayy! New best EMA pseudo Dice: 0.5746999979019165 
2025-01-20 00:12:55.173751:  
2025-01-20 00:12:55.174756: Epoch 114 
2025-01-20 00:12:55.179291: Current learning rate: 0.00112 
2025-01-20 00:13:31.660127: train_loss -0.3902 
2025-01-20 00:13:31.661128: val_loss -0.2941 
2025-01-20 00:13:31.666145: Pseudo dice [np.float32(0.5948)] 
2025-01-20 00:13:31.669154: Epoch time: 36.49 s 
2025-01-20 00:13:31.671700: Yayy! New best EMA pseudo Dice: 0.57669997215271 
2025-01-20 00:13:32.418442:  
2025-01-20 00:13:32.418442: Epoch 115 
2025-01-20 00:13:32.423465: Current learning rate: 0.00103 
2025-01-20 00:14:08.888180: train_loss -0.3823 
2025-01-20 00:14:08.889711: val_loss -0.2637 
2025-01-20 00:14:08.894875: Pseudo dice [np.float32(0.6468)] 
2025-01-20 00:14:08.898431: Epoch time: 36.47 s 
2025-01-20 00:14:08.901467: Yayy! New best EMA pseudo Dice: 0.5837000012397766 
2025-01-20 00:14:09.641200:  
2025-01-20 00:14:09.641200: Epoch 116 
2025-01-20 00:14:09.646213: Current learning rate: 0.00094 
2025-01-20 00:14:46.109238: train_loss -0.3887 
2025-01-20 00:14:46.110746: val_loss -0.3147 
2025-01-20 00:14:46.116283: Pseudo dice [np.float32(0.6234)] 
2025-01-20 00:14:46.119294: Epoch time: 36.47 s 
2025-01-20 00:14:46.122803: Yayy! New best EMA pseudo Dice: 0.5877000093460083 
2025-01-20 00:14:47.013225:  
2025-01-20 00:14:47.013728: Epoch 117 
2025-01-20 00:14:47.018742: Current learning rate: 0.00084 
2025-01-20 00:15:23.469047: train_loss -0.3905 
2025-01-20 00:15:23.469047: val_loss -0.2591 
2025-01-20 00:15:23.475063: Pseudo dice [np.float32(0.5924)] 
2025-01-20 00:15:23.477570: Epoch time: 36.46 s 
2025-01-20 00:15:23.480078: Yayy! New best EMA pseudo Dice: 0.5881999731063843 
2025-01-20 00:15:24.238483:  
2025-01-20 00:15:24.238483: Epoch 118 
2025-01-20 00:15:24.243521: Current learning rate: 0.00075 
2025-01-20 00:16:00.696911: train_loss -0.3881 
2025-01-20 00:16:00.697423: val_loss -0.2797 
2025-01-20 00:16:00.701984: Pseudo dice [np.float32(0.6335)] 
2025-01-20 00:16:00.705028: Epoch time: 36.46 s 
2025-01-20 00:16:00.707557: Yayy! New best EMA pseudo Dice: 0.5927000045776367 
2025-01-20 00:16:01.445041:  
2025-01-20 00:16:01.446039: Epoch 119 
2025-01-20 00:16:01.450597: Current learning rate: 0.00065 
2025-01-20 00:16:37.874056: train_loss -0.4049 
2025-01-20 00:16:37.874568: val_loss -0.2751 
2025-01-20 00:16:37.881146: Pseudo dice [np.float32(0.5819)] 
2025-01-20 00:16:37.883685: Epoch time: 36.43 s 
2025-01-20 00:16:38.441921:  
2025-01-20 00:16:38.442926: Epoch 120 
2025-01-20 00:16:38.447553: Current learning rate: 0.00055 
2025-01-20 00:17:14.895625: train_loss -0.3917 
2025-01-20 00:17:14.896136: val_loss -0.2722 
2025-01-20 00:17:14.900728: Pseudo dice [np.float32(0.6184)] 
2025-01-20 00:17:14.904244: Epoch time: 36.45 s 
2025-01-20 00:17:14.907376: Yayy! New best EMA pseudo Dice: 0.5942999720573425 
2025-01-20 00:17:15.663588:  
2025-01-20 00:17:15.663588: Epoch 121 
2025-01-20 00:17:15.668600: Current learning rate: 0.00045 
2025-01-20 00:17:52.130403: train_loss -0.4102 
2025-01-20 00:17:52.130403: val_loss -0.2947 
2025-01-20 00:17:52.136419: Pseudo dice [np.float32(0.6038)] 
2025-01-20 00:17:52.139925: Epoch time: 36.47 s 
2025-01-20 00:17:52.142963: Yayy! New best EMA pseudo Dice: 0.5952000021934509 
2025-01-20 00:17:52.935335:  
2025-01-20 00:17:52.935335: Epoch 122 
2025-01-20 00:17:52.941348: Current learning rate: 0.00035 
2025-01-20 00:18:29.385483: train_loss -0.3841 
2025-01-20 00:18:29.386486: val_loss -0.2614 
2025-01-20 00:18:29.392024: Pseudo dice [np.float32(0.5507)] 
2025-01-20 00:18:29.394032: Epoch time: 36.45 s 
2025-01-20 00:18:29.966181:  
2025-01-20 00:18:29.966181: Epoch 123 
2025-01-20 00:18:29.972219: Current learning rate: 0.00024 
2025-01-20 00:19:06.422118: train_loss -0.4052 
2025-01-20 00:19:06.422118: val_loss -0.2663 
2025-01-20 00:19:06.427136: Pseudo dice [np.float32(0.6302)] 
2025-01-20 00:19:06.430650: Epoch time: 36.46 s 
2025-01-20 00:19:06.997610:  
2025-01-20 00:19:06.998115: Epoch 124 
2025-01-20 00:19:07.002654: Current learning rate: 0.00013 
2025-01-20 00:19:43.435686: train_loss -0.4064 
2025-01-20 00:19:43.436193: val_loss -0.269 
2025-01-20 00:19:43.441768: Pseudo dice [np.float32(0.62)] 
2025-01-20 00:19:43.444834: Epoch time: 36.44 s 
2025-01-20 00:19:43.447871: Yayy! New best EMA pseudo Dice: 0.5972999930381775 
2025-01-20 00:19:44.599775: Training done. 
2025-01-20 00:19:44.625776: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-20 00:19:44.632778: The split file contains 5 splits. 
2025-01-20 00:19:44.637778: Desired fold for training: 0 
2025-01-20 00:19:44.640778: This split has 100 training and 26 validation cases. 
2025-01-20 00:19:44.646776: predicting colon_008 
2025-01-20 00:19:44.652777: colon_008, shape torch.Size([1, 89, 465, 465]), rank 0 
2025-01-20 00:19:52.948122: predicting colon_027 
2025-01-20 00:19:52.957123: colon_027, shape torch.Size([1, 38, 440, 440]), rank 0 
2025-01-20 00:19:58.596593: predicting colon_030 
2025-01-20 00:19:58.602107: colon_030, shape torch.Size([1, 90, 384, 384]), rank 0 
2025-01-20 00:20:02.537150: predicting colon_033 
2025-01-20 00:20:02.544150: colon_033, shape torch.Size([1, 98, 480, 480]), rank 0 
2025-01-20 00:20:10.243016: predicting colon_041 
2025-01-20 00:20:10.254015: colon_041, shape torch.Size([1, 104, 591, 591]), rank 0 
2025-01-20 00:20:22.962001: predicting colon_042 
2025-01-20 00:20:22.978002: colon_042, shape torch.Size([1, 55, 640, 640]), rank 0 
2025-01-20 00:20:35.672778: predicting colon_061 
2025-01-20 00:20:35.683777: colon_061, shape torch.Size([1, 85, 529, 529]), rank 0 
2025-01-20 00:20:45.718625: predicting colon_074 
2025-01-20 00:20:45.729132: colon_074, shape torch.Size([1, 80, 607, 607]), rank 0 
2025-01-20 00:20:58.427418: predicting colon_075 
2025-01-20 00:20:58.440928: colon_075, shape torch.Size([1, 86, 474, 474]), rank 0 
2025-01-20 00:21:06.126472: predicting colon_088 
2025-01-20 00:21:06.135472: colon_088, shape torch.Size([1, 95, 563, 563]), rank 0 
2025-01-20 00:21:16.158922: predicting colon_091 
2025-01-20 00:21:16.171922: colon_091, shape torch.Size([1, 103, 543, 543]), rank 0 
2025-01-20 00:21:26.213685: predicting colon_092 
2025-01-20 00:21:26.226685: colon_092, shape torch.Size([1, 90, 492, 492]), rank 0 
2025-01-20 00:21:33.922966: predicting colon_095 
2025-01-20 00:21:33.932966: colon_095, shape torch.Size([1, 96, 452, 452]), rank 0 
2025-01-20 00:21:41.620776: predicting colon_102 
2025-01-20 00:21:41.629775: colon_102, shape torch.Size([1, 96, 590, 590]), rank 0 
2025-01-20 00:21:54.335166: predicting colon_111 
2025-01-20 00:21:54.350167: colon_111, shape torch.Size([1, 48, 521, 521]), rank 0 
2025-01-20 00:22:04.356855: predicting colon_115 
2025-01-20 00:22:04.363855: colon_115, shape torch.Size([1, 97, 470, 470]), rank 0 
2025-01-20 00:22:12.064948: predicting colon_118 
2025-01-20 00:22:12.074951: colon_118, shape torch.Size([1, 100, 486, 486]), rank 0 
2025-01-20 00:22:19.784366: predicting colon_124 
2025-01-20 00:22:19.796384: colon_124, shape torch.Size([1, 92, 535, 535]), rank 0 
2025-01-20 00:22:29.817816: predicting colon_127 
2025-01-20 00:22:29.829815: colon_127, shape torch.Size([1, 130, 598, 598]), rank 0 
2025-01-20 00:22:55.152429: predicting colon_154 
2025-01-20 00:22:55.172430: colon_154, shape torch.Size([1, 94, 461, 461]), rank 0 
2025-01-20 00:23:02.853624: predicting colon_161 
2025-01-20 00:23:02.863625: colon_161, shape torch.Size([1, 95, 474, 474]), rank 0 
2025-01-20 00:23:10.564504: predicting colon_162 
2025-01-20 00:23:10.577504: colon_162, shape torch.Size([1, 104, 598, 598]), rank 0 
2025-01-20 00:23:23.276228: predicting colon_165 
2025-01-20 00:23:23.292228: colon_165, shape torch.Size([1, 85, 577, 577]), rank 0 
2025-01-20 00:23:35.979232: predicting colon_166 
2025-01-20 00:23:35.995230: colon_166, shape torch.Size([1, 87, 474, 474]), rank 0 
2025-01-20 00:23:46.757383: predicting colon_169 
2025-01-20 00:23:46.769383: colon_169, shape torch.Size([1, 129, 621, 621]), rank 0 
2025-01-20 00:24:13.404609: predicting colon_187 
2025-01-20 00:24:13.428608: colon_187, shape torch.Size([1, 94, 513, 513]), rank 0 
2025-01-20 00:24:30.606964: Validation complete 
2025-01-20 00:24:30.606964: Mean Validation Dice:  0.309113525488244 
