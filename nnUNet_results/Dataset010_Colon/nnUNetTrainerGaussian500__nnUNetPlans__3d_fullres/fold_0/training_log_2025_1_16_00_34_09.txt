
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-16 00:34:09.900454: do_dummy_2d_data_aug: True 
2025-01-16 00:34:09.905452: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-16 00:34:09.911454: The split file contains 5 splits. 
2025-01-16 00:34:09.913456: Desired fold for training: 0 
2025-01-16 00:34:09.916457: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2025-01-16 00:34:16.319448: unpacking dataset... 
2025-01-16 00:34:16.584178: unpacking done... 
2025-01-16 00:34:20.732428:  
2025-01-16 00:34:20.732428: Epoch 0 
2025-01-16 00:34:20.737447: Current learning rate: 0.01 
2025-01-16 00:35:08.059834: train_loss 0.0299 
2025-01-16 00:35:08.060354: val_loss -0.0329 
2025-01-16 00:35:08.065962: Pseudo dice [np.float32(0.0)] 
2025-01-16 00:35:08.068502: Epoch time: 47.33 s 
2025-01-16 00:35:08.071043: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-16 00:35:08.740813:  
2025-01-16 00:35:08.740813: Epoch 1 
2025-01-16 00:35:08.746850: Current learning rate: 0.00998 
2025-01-16 00:35:51.253001: train_loss -0.1556 
2025-01-16 00:35:51.253001: val_loss -0.1991 
2025-01-16 00:35:51.259016: Pseudo dice [np.float32(0.2923)] 
2025-01-16 00:35:51.262523: Epoch time: 42.51 s 
2025-01-16 00:35:51.265531: Yayy! New best EMA pseudo Dice: 0.029200000688433647 
2025-01-16 00:35:51.993261:  
2025-01-16 00:35:51.993778: Epoch 2 
2025-01-16 00:35:51.999457: Current learning rate: 0.00996 
2025-01-16 00:36:34.503426: train_loss -0.3352 
2025-01-16 00:36:34.503426: val_loss -0.3431 
2025-01-16 00:36:34.508966: Pseudo dice [np.float32(0.4219)] 
2025-01-16 00:36:34.512522: Epoch time: 42.51 s 
2025-01-16 00:36:34.516130: Yayy! New best EMA pseudo Dice: 0.06849999725818634 
2025-01-16 00:36:35.272208:  
2025-01-16 00:36:35.272208: Epoch 3 
2025-01-16 00:36:35.277779: Current learning rate: 0.00995 
2025-01-16 00:37:17.930082: train_loss -0.3797 
2025-01-16 00:37:17.931086: val_loss -0.4095 
2025-01-16 00:37:17.935173: Pseudo dice [np.float32(0.484)] 
2025-01-16 00:37:17.937762: Epoch time: 42.66 s 
2025-01-16 00:37:17.940272: Yayy! New best EMA pseudo Dice: 0.10999999940395355 
2025-01-16 00:37:18.711409:  
2025-01-16 00:37:18.711409: Epoch 4 
2025-01-16 00:37:18.717424: Current learning rate: 0.00993 
2025-01-16 00:38:00.292672: train_loss -0.4411 
2025-01-16 00:38:00.292672: val_loss -0.2978 
2025-01-16 00:38:00.298687: Pseudo dice [np.float32(0.3764)] 
2025-01-16 00:38:00.301196: Epoch time: 41.58 s 
2025-01-16 00:38:00.305203: Yayy! New best EMA pseudo Dice: 0.13670000433921814 
2025-01-16 00:38:01.242695:  
2025-01-16 00:38:01.242695: Epoch 5 
2025-01-16 00:38:01.248796: Current learning rate: 0.00991 
2025-01-16 00:38:42.802811: train_loss -0.4104 
2025-01-16 00:38:42.804329: val_loss -0.4226 
2025-01-16 00:38:42.809914: Pseudo dice [np.float32(0.5156)] 
2025-01-16 00:38:42.812947: Epoch time: 41.56 s 
2025-01-16 00:38:42.815479: Yayy! New best EMA pseudo Dice: 0.1746000051498413 
2025-01-16 00:38:43.591392:  
2025-01-16 00:38:43.591392: Epoch 6 
2025-01-16 00:38:43.597429: Current learning rate: 0.00989 
2025-01-16 00:39:24.957634: train_loss -0.4634 
2025-01-16 00:39:24.959152: val_loss -0.4219 
2025-01-16 00:39:24.965232: Pseudo dice [np.float32(0.508)] 
2025-01-16 00:39:24.968766: Epoch time: 41.37 s 
2025-01-16 00:39:24.971791: Yayy! New best EMA pseudo Dice: 0.2079000025987625 
2025-01-16 00:39:25.697843:  
2025-01-16 00:39:25.697843: Epoch 7 
2025-01-16 00:39:25.703969: Current learning rate: 0.00987 
2025-01-16 00:40:11.149157: train_loss -0.4828 
2025-01-16 00:40:11.149660: val_loss -0.4244 
2025-01-16 00:40:11.155681: Pseudo dice [np.float32(0.5534)] 
2025-01-16 00:40:11.158183: Epoch time: 45.45 s 
2025-01-16 00:40:11.162197: Yayy! New best EMA pseudo Dice: 0.24250000715255737 
2025-01-16 00:40:11.931210:  
2025-01-16 00:40:11.932210: Epoch 8 
2025-01-16 00:40:11.937321: Current learning rate: 0.00986 
2025-01-16 00:40:53.414057: train_loss -0.4857 
2025-01-16 00:40:53.414057: val_loss -0.4487 
2025-01-16 00:40:53.418068: Pseudo dice [np.float32(0.5309)] 
2025-01-16 00:40:53.421604: Epoch time: 41.48 s 
2025-01-16 00:40:53.424595: Yayy! New best EMA pseudo Dice: 0.27129998803138733 
2025-01-16 00:40:54.219944:  
2025-01-16 00:40:54.219944: Epoch 9 
2025-01-16 00:40:54.226070: Current learning rate: 0.00984 
2025-01-16 00:41:35.543019: train_loss -0.5249 
2025-01-16 00:41:35.544019: val_loss -0.4248 
2025-01-16 00:41:35.549540: Pseudo dice [np.float32(0.4907)] 
2025-01-16 00:41:35.552048: Epoch time: 41.32 s 
2025-01-16 00:41:35.555557: Yayy! New best EMA pseudo Dice: 0.29319998621940613 
2025-01-16 00:41:36.305138:  
2025-01-16 00:41:36.305138: Epoch 10 
2025-01-16 00:41:36.310214: Current learning rate: 0.00982 
2025-01-16 00:42:17.679546: train_loss -0.5275 
2025-01-16 00:42:17.679546: val_loss -0.4487 
2025-01-16 00:42:17.686058: Pseudo dice [np.float32(0.5667)] 
2025-01-16 00:42:17.689567: Epoch time: 41.38 s 
2025-01-16 00:42:17.692072: Yayy! New best EMA pseudo Dice: 0.3206000030040741 
2025-01-16 00:42:18.549614:  
2025-01-16 00:42:18.549614: Epoch 11 
2025-01-16 00:42:18.554122: Current learning rate: 0.0098 
2025-01-16 00:42:59.893086: train_loss -0.54 
2025-01-16 00:42:59.893609: val_loss -0.4785 
2025-01-16 00:42:59.898621: Pseudo dice [np.float32(0.5469)] 
2025-01-16 00:42:59.902133: Epoch time: 41.34 s 
2025-01-16 00:42:59.904639: Yayy! New best EMA pseudo Dice: 0.3431999981403351 
2025-01-16 00:43:00.670413:  
2025-01-16 00:43:00.670923: Epoch 12 
2025-01-16 00:43:00.674446: Current learning rate: 0.00978 
2025-01-16 00:43:41.991589: train_loss -0.5884 
2025-01-16 00:43:41.992127: val_loss -0.4968 
2025-01-16 00:43:41.996167: Pseudo dice [np.float32(0.5413)] 
2025-01-16 00:43:41.999192: Epoch time: 41.32 s 
2025-01-16 00:43:42.002231: Yayy! New best EMA pseudo Dice: 0.3630000054836273 
2025-01-16 00:43:42.942370:  
2025-01-16 00:43:42.942875: Epoch 13 
2025-01-16 00:43:42.948455: Current learning rate: 0.00977 
2025-01-16 00:44:24.294387: train_loss -0.5551 
2025-01-16 00:44:24.294907: val_loss -0.4944 
2025-01-16 00:44:24.300454: Pseudo dice [np.float32(0.631)] 
2025-01-16 00:44:24.302964: Epoch time: 41.35 s 
2025-01-16 00:44:24.306973: Yayy! New best EMA pseudo Dice: 0.3898000121116638 
2025-01-16 00:44:25.142881:  
2025-01-16 00:44:25.143881: Epoch 14 
2025-01-16 00:44:25.149025: Current learning rate: 0.00975 
2025-01-16 00:45:06.518257: train_loss -0.558 
2025-01-16 00:45:06.519256: val_loss -0.5159 
2025-01-16 00:45:06.524774: Pseudo dice [np.float32(0.5888)] 
2025-01-16 00:45:06.528285: Epoch time: 41.38 s 
2025-01-16 00:45:06.530793: Yayy! New best EMA pseudo Dice: 0.4097000062465668 
2025-01-16 00:45:07.333714:  
2025-01-16 00:45:07.333714: Epoch 15 
2025-01-16 00:45:07.339758: Current learning rate: 0.00973 
2025-01-16 00:45:48.682873: train_loss -0.5737 
2025-01-16 00:45:48.683877: val_loss -0.4347 
2025-01-16 00:45:48.688924: Pseudo dice [np.float32(0.5033)] 
2025-01-16 00:45:48.692464: Epoch time: 41.35 s 
2025-01-16 00:45:48.695495: Yayy! New best EMA pseudo Dice: 0.41909998655319214 
2025-01-16 00:45:49.493665:  
2025-01-16 00:45:49.494665: Epoch 16 
2025-01-16 00:45:49.500180: Current learning rate: 0.00971 
2025-01-16 00:46:30.886692: train_loss -0.6296 
2025-01-16 00:46:30.886692: val_loss -0.5034 
2025-01-16 00:46:30.893215: Pseudo dice [np.float32(0.6101)] 
2025-01-16 00:46:30.896732: Epoch time: 41.39 s 
2025-01-16 00:46:30.899245: Yayy! New best EMA pseudo Dice: 0.4381999969482422 
2025-01-16 00:46:31.720737:  
2025-01-16 00:46:31.721735: Epoch 17 
2025-01-16 00:46:31.726839: Current learning rate: 0.00969 
2025-01-16 00:47:13.079199: train_loss -0.5849 
2025-01-16 00:47:13.080203: val_loss -0.4503 
2025-01-16 00:47:13.086873: Pseudo dice [np.float32(0.5536)] 
2025-01-16 00:47:13.090400: Epoch time: 41.36 s 
2025-01-16 00:47:13.093555: Yayy! New best EMA pseudo Dice: 0.4496999979019165 
2025-01-16 00:47:13.905091:  
2025-01-16 00:47:13.906094: Epoch 18 
2025-01-16 00:47:13.910969: Current learning rate: 0.00968 
2025-01-16 00:47:55.262224: train_loss -0.6043 
2025-01-16 00:47:55.263227: val_loss -0.445 
2025-01-16 00:47:55.269259: Pseudo dice [np.float32(0.5676)] 
2025-01-16 00:47:55.272321: Epoch time: 41.36 s 
2025-01-16 00:47:55.275830: Yayy! New best EMA pseudo Dice: 0.46149998903274536 
2025-01-16 00:47:56.072706:  
2025-01-16 00:47:56.072706: Epoch 19 
2025-01-16 00:47:56.078219: Current learning rate: 0.00966 
2025-01-16 00:48:37.521998: train_loss -0.625 
2025-01-16 00:48:37.523001: val_loss -0.4647 
2025-01-16 00:48:37.528012: Pseudo dice [np.float32(0.6204)] 
2025-01-16 00:48:37.531539: Epoch time: 41.45 s 
2025-01-16 00:48:37.534564: Yayy! New best EMA pseudo Dice: 0.477400004863739 
2025-01-16 00:48:38.344812:  
2025-01-16 00:48:38.345314: Epoch 20 
2025-01-16 00:48:38.349329: Current learning rate: 0.00964 
2025-01-16 00:49:19.716992: train_loss -0.5912 
2025-01-16 00:49:19.718494: val_loss -0.4886 
2025-01-16 00:49:19.724513: Pseudo dice [np.float32(0.5243)] 
2025-01-16 00:49:19.727021: Epoch time: 41.37 s 
2025-01-16 00:49:19.732035: Yayy! New best EMA pseudo Dice: 0.4821000099182129 
2025-01-16 00:49:20.708205:  
2025-01-16 00:49:20.708707: Epoch 21 
2025-01-16 00:49:20.713717: Current learning rate: 0.00962 
2025-01-16 00:50:02.085778: train_loss -0.6133 
2025-01-16 00:50:02.085778: val_loss -0.4582 
2025-01-16 00:50:02.092307: Pseudo dice [np.float32(0.6069)] 
2025-01-16 00:50:02.095816: Epoch time: 41.38 s 
2025-01-16 00:50:02.098320: Yayy! New best EMA pseudo Dice: 0.49459999799728394 
2025-01-16 00:50:02.850572:  
2025-01-16 00:50:02.850572: Epoch 22 
2025-01-16 00:50:02.856592: Current learning rate: 0.0096 
2025-01-16 00:50:44.219749: train_loss -0.6318 
2025-01-16 00:50:44.220754: val_loss -0.5169 
2025-01-16 00:50:44.226767: Pseudo dice [np.float32(0.5595)] 
2025-01-16 00:50:44.229781: Epoch time: 41.37 s 
2025-01-16 00:50:44.233292: Yayy! New best EMA pseudo Dice: 0.5011000037193298 
2025-01-16 00:50:45.010618:  
2025-01-16 00:50:45.010618: Epoch 23 
2025-01-16 00:50:45.015630: Current learning rate: 0.00959 
2025-01-16 00:51:26.373909: train_loss -0.6402 
2025-01-16 00:51:26.373909: val_loss -0.4603 
2025-01-16 00:51:26.380073: Pseudo dice [np.float32(0.6044)] 
2025-01-16 00:51:26.383632: Epoch time: 41.36 s 
2025-01-16 00:51:26.386160: Yayy! New best EMA pseudo Dice: 0.5113999843597412 
2025-01-16 00:51:27.154805:  
2025-01-16 00:51:27.155804: Epoch 24 
2025-01-16 00:51:27.161320: Current learning rate: 0.00957 
2025-01-16 00:52:08.514232: train_loss -0.6253 
2025-01-16 00:52:08.514232: val_loss -0.5393 
2025-01-16 00:52:08.521314: Pseudo dice [np.float32(0.6226)] 
2025-01-16 00:52:08.524822: Epoch time: 41.36 s 
2025-01-16 00:52:08.527328: Yayy! New best EMA pseudo Dice: 0.5224999785423279 
2025-01-16 00:52:09.292942:  
2025-01-16 00:52:09.292942: Epoch 25 
2025-01-16 00:52:09.298515: Current learning rate: 0.00955 
2025-01-16 00:52:50.649321: train_loss -0.676 
2025-01-16 00:52:50.650324: val_loss -0.511 
2025-01-16 00:52:50.655334: Pseudo dice [np.float32(0.6214)] 
2025-01-16 00:52:50.657840: Epoch time: 41.36 s 
2025-01-16 00:52:50.661847: Yayy! New best EMA pseudo Dice: 0.5324000120162964 
2025-01-16 00:52:51.470497:  
2025-01-16 00:52:51.470497: Epoch 26 
2025-01-16 00:52:51.476532: Current learning rate: 0.00953 
2025-01-16 00:53:32.830242: train_loss -0.6598 
2025-01-16 00:53:32.830242: val_loss -0.4434 
2025-01-16 00:53:32.835831: Pseudo dice [np.float32(0.5721)] 
2025-01-16 00:53:32.839363: Epoch time: 41.36 s 
2025-01-16 00:53:32.842450: Yayy! New best EMA pseudo Dice: 0.5364000201225281 
2025-01-16 00:53:33.609060:  
2025-01-16 00:53:33.609060: Epoch 27 
2025-01-16 00:53:33.615627: Current learning rate: 0.00951 
2025-01-16 00:54:14.981288: train_loss -0.6569 
2025-01-16 00:54:14.981288: val_loss -0.4564 
2025-01-16 00:54:14.987812: Pseudo dice [np.float32(0.564)] 
2025-01-16 00:54:14.991324: Epoch time: 41.37 s 
2025-01-16 00:54:14.994831: Yayy! New best EMA pseudo Dice: 0.5390999913215637 
2025-01-16 00:54:15.759825:  
2025-01-16 00:54:15.760336: Epoch 28 
2025-01-16 00:54:15.765371: Current learning rate: 0.00949 
2025-01-16 00:54:57.146222: train_loss -0.6792 
2025-01-16 00:54:57.146222: val_loss -0.3174 
2025-01-16 00:54:57.151281: Pseudo dice [np.float32(0.4792)] 
2025-01-16 00:54:57.155351: Epoch time: 41.39 s 
2025-01-16 00:54:57.858538:  
2025-01-16 00:54:57.859537: Epoch 29 
2025-01-16 00:54:57.865117: Current learning rate: 0.00948 
2025-01-16 00:55:39.213381: train_loss -0.6498 
2025-01-16 00:55:39.213381: val_loss -0.3477 
2025-01-16 00:55:39.219399: Pseudo dice [np.float32(0.4529)] 
2025-01-16 00:55:39.221904: Epoch time: 41.35 s 
2025-01-16 00:55:39.783523:  
2025-01-16 00:55:39.784025: Epoch 30 
2025-01-16 00:55:39.789039: Current learning rate: 0.00946 
2025-01-16 00:56:21.143796: train_loss -0.6592 
2025-01-16 00:56:21.144299: val_loss -0.4933 
2025-01-16 00:56:21.150318: Pseudo dice [np.float32(0.563)] 
2025-01-16 00:56:21.153823: Epoch time: 41.36 s 
2025-01-16 00:56:21.710673:  
2025-01-16 00:56:21.711676: Epoch 31 
2025-01-16 00:56:21.716287: Current learning rate: 0.00944 
2025-01-16 00:57:03.100940: train_loss -0.6588 
2025-01-16 00:57:03.101445: val_loss -0.4786 
2025-01-16 00:57:03.107591: Pseudo dice [np.float32(0.5659)] 
2025-01-16 00:57:03.110640: Epoch time: 41.39 s 
2025-01-16 00:57:03.674733:  
2025-01-16 00:57:03.675236: Epoch 32 
2025-01-16 00:57:03.679788: Current learning rate: 0.00942 
2025-01-16 00:57:45.042943: train_loss -0.6995 
2025-01-16 00:57:45.043947: val_loss -0.458 
2025-01-16 00:57:45.048959: Pseudo dice [np.float32(0.6217)] 
2025-01-16 00:57:45.052467: Epoch time: 41.37 s 
2025-01-16 00:57:45.055476: Yayy! New best EMA pseudo Dice: 0.5414999723434448 
2025-01-16 00:57:45.823030:  
2025-01-16 00:57:45.823030: Epoch 33 
2025-01-16 00:57:45.829046: Current learning rate: 0.0094 
2025-01-16 00:58:27.206258: train_loss -0.6428 
2025-01-16 00:58:27.207775: val_loss -0.4618 
2025-01-16 00:58:27.213864: Pseudo dice [np.float32(0.5911)] 
2025-01-16 00:58:27.216386: Epoch time: 41.38 s 
2025-01-16 00:58:27.220426: Yayy! New best EMA pseudo Dice: 0.546500027179718 
2025-01-16 00:58:28.044817:  
2025-01-16 00:58:28.045820: Epoch 34 
2025-01-16 00:58:28.050378: Current learning rate: 0.00939 
2025-01-16 00:59:09.420738: train_loss -0.6827 
2025-01-16 00:59:09.421736: val_loss -0.4627 
2025-01-16 00:59:09.427252: Pseudo dice [np.float32(0.6235)] 
2025-01-16 00:59:09.431763: Epoch time: 41.38 s 
2025-01-16 00:59:09.434777: Yayy! New best EMA pseudo Dice: 0.5541999936103821 
2025-01-16 00:59:10.220717:  
2025-01-16 00:59:10.220717: Epoch 35 
2025-01-16 00:59:10.227293: Current learning rate: 0.00937 
2025-01-16 00:59:51.612020: train_loss -0.7035 
2025-01-16 00:59:51.612536: val_loss -0.4622 
2025-01-16 00:59:51.618638: Pseudo dice [np.float32(0.5692)] 
2025-01-16 00:59:51.622199: Epoch time: 41.39 s 
2025-01-16 00:59:51.625754: Yayy! New best EMA pseudo Dice: 0.5557000041007996 
2025-01-16 00:59:52.535424:  
2025-01-16 00:59:52.535424: Epoch 36 
2025-01-16 00:59:52.541445: Current learning rate: 0.00935 
2025-01-16 01:00:37.263787: train_loss -0.6949 
2025-01-16 01:00:37.264791: val_loss -0.4755 
2025-01-16 01:00:37.271309: Pseudo dice [np.float32(0.582)] 
2025-01-16 01:00:37.274354: Epoch time: 44.73 s 
2025-01-16 01:00:37.277387: Yayy! New best EMA pseudo Dice: 0.5583000183105469 
2025-01-16 01:00:38.232489:  
2025-01-16 01:00:38.233492: Epoch 37 
2025-01-16 01:00:38.239078: Current learning rate: 0.00933 
2025-01-16 01:01:19.596147: train_loss -0.6877 
2025-01-16 01:01:19.597147: val_loss -0.4211 
2025-01-16 01:01:19.602666: Pseudo dice [np.float32(0.5791)] 
2025-01-16 01:01:19.607176: Epoch time: 41.36 s 
2025-01-16 01:01:19.610187: Yayy! New best EMA pseudo Dice: 0.5604000091552734 
2025-01-16 01:01:20.406108:  
2025-01-16 01:01:20.406610: Epoch 38 
2025-01-16 01:01:20.411622: Current learning rate: 0.00931 
2025-01-16 01:02:01.779621: train_loss -0.6952 
2025-01-16 01:02:01.780123: val_loss -0.4134 
2025-01-16 01:02:01.785134: Pseudo dice [np.float32(0.5794)] 
2025-01-16 01:02:01.788643: Epoch time: 41.37 s 
2025-01-16 01:02:01.792148: Yayy! New best EMA pseudo Dice: 0.5623000264167786 
2025-01-16 01:02:02.630813:  
2025-01-16 01:02:02.631816: Epoch 39 
2025-01-16 01:02:02.636388: Current learning rate: 0.0093 
2025-01-16 01:02:43.996242: train_loss -0.7341 
2025-01-16 01:02:43.996242: val_loss -0.3951 
2025-01-16 01:02:44.002257: Pseudo dice [np.float32(0.5247)] 
2025-01-16 01:02:44.006270: Epoch time: 41.37 s 
2025-01-16 01:02:44.676198:  
2025-01-16 01:02:44.676198: Epoch 40 
2025-01-16 01:02:44.682250: Current learning rate: 0.00928 
2025-01-16 01:03:26.045405: train_loss -0.7083 
2025-01-16 01:03:26.046411: val_loss -0.4428 
2025-01-16 01:03:26.051974: Pseudo dice [np.float32(0.6314)] 
2025-01-16 01:03:26.055534: Epoch time: 41.37 s 
2025-01-16 01:03:26.059121: Yayy! New best EMA pseudo Dice: 0.5658000111579895 
2025-01-16 01:03:26.874274:  
2025-01-16 01:03:26.874274: Epoch 41 
2025-01-16 01:03:26.880289: Current learning rate: 0.00926 
2025-01-16 01:04:08.256329: train_loss -0.6862 
2025-01-16 01:04:08.256833: val_loss -0.4965 
2025-01-16 01:04:08.262938: Pseudo dice [np.float32(0.6458)] 
2025-01-16 01:04:08.266870: Epoch time: 41.38 s 
2025-01-16 01:04:08.270382: Yayy! New best EMA pseudo Dice: 0.5738000273704529 
2025-01-16 01:04:09.100453:  
2025-01-16 01:04:09.100453: Epoch 42 
2025-01-16 01:04:09.107551: Current learning rate: 0.00924 
2025-01-16 01:04:50.466862: train_loss -0.7066 
2025-01-16 01:04:50.467863: val_loss -0.3429 
2025-01-16 01:04:50.473405: Pseudo dice [np.float32(0.5296)] 
2025-01-16 01:04:50.476918: Epoch time: 41.37 s 
2025-01-16 01:04:51.039575:  
2025-01-16 01:04:51.040579: Epoch 43 
2025-01-16 01:04:51.045115: Current learning rate: 0.00922 
2025-01-16 01:05:32.416555: train_loss -0.7136 
2025-01-16 01:05:32.418111: val_loss -0.4067 
2025-01-16 01:05:32.424243: Pseudo dice [np.float32(0.6099)] 
2025-01-16 01:05:32.426796: Epoch time: 41.38 s 
2025-01-16 01:05:33.116552:  
2025-01-16 01:05:33.118054: Epoch 44 
2025-01-16 01:05:33.122565: Current learning rate: 0.0092 
2025-01-16 01:06:14.466187: train_loss -0.7337 
2025-01-16 01:06:14.466187: val_loss -0.5161 
2025-01-16 01:06:14.471752: Pseudo dice [np.float32(0.6421)] 
2025-01-16 01:06:14.474778: Epoch time: 41.35 s 
2025-01-16 01:06:14.478284: Yayy! New best EMA pseudo Dice: 0.580299973487854 
2025-01-16 01:06:15.254363:  
2025-01-16 01:06:15.254865: Epoch 45 
2025-01-16 01:06:15.259876: Current learning rate: 0.00919 
2025-01-16 01:06:56.609693: train_loss -0.7268 
2025-01-16 01:06:56.610698: val_loss -0.4085 
2025-01-16 01:06:56.615707: Pseudo dice [np.float32(0.5783)] 
2025-01-16 01:06:56.619213: Epoch time: 41.36 s 
2025-01-16 01:06:57.163757:  
2025-01-16 01:06:57.164277: Epoch 46 
2025-01-16 01:06:57.169333: Current learning rate: 0.00917 
2025-01-16 01:07:38.520936: train_loss -0.7276 
2025-01-16 01:07:38.521939: val_loss -0.41 
2025-01-16 01:07:38.526988: Pseudo dice [np.float32(0.5767)] 
2025-01-16 01:07:38.529495: Epoch time: 41.36 s 
2025-01-16 01:07:39.069318:  
2025-01-16 01:07:39.069821: Epoch 47 
2025-01-16 01:07:39.074832: Current learning rate: 0.00915 
2025-01-16 01:08:20.433999: train_loss -0.6977 
2025-01-16 01:08:20.433999: val_loss -0.4632 
2025-01-16 01:08:20.440552: Pseudo dice [np.float32(0.5883)] 
2025-01-16 01:08:20.443062: Epoch time: 41.37 s 
2025-01-16 01:08:20.446606: Yayy! New best EMA pseudo Dice: 0.5806000232696533 
2025-01-16 01:08:21.225024:  
2025-01-16 01:08:21.225024: Epoch 48 
2025-01-16 01:08:21.231067: Current learning rate: 0.00913 
2025-01-16 01:09:02.603746: train_loss -0.6829 
2025-01-16 01:09:02.603746: val_loss -0.4295 
2025-01-16 01:09:02.610263: Pseudo dice [np.float32(0.5693)] 
2025-01-16 01:09:02.613772: Epoch time: 41.38 s 
2025-01-16 01:09:03.174079:  
2025-01-16 01:09:03.174079: Epoch 49 
2025-01-16 01:09:03.179325: Current learning rate: 0.00911 
2025-01-16 01:09:44.552912: train_loss -0.7226 
2025-01-16 01:09:44.552912: val_loss -0.3507 
2025-01-16 01:09:44.559427: Pseudo dice [np.float32(0.5157)] 
2025-01-16 01:09:44.562936: Epoch time: 41.38 s 
2025-01-16 01:09:45.290220:  
2025-01-16 01:09:45.290220: Epoch 50 
2025-01-16 01:09:45.295767: Current learning rate: 0.0091 
2025-01-16 01:10:26.669154: train_loss -0.7164 
2025-01-16 01:10:26.670721: val_loss -0.4956 
2025-01-16 01:10:26.676301: Pseudo dice [np.float32(0.6372)] 
2025-01-16 01:10:26.678807: Epoch time: 41.38 s 
2025-01-16 01:10:27.230363:  
2025-01-16 01:10:27.231364: Epoch 51 
2025-01-16 01:10:27.236378: Current learning rate: 0.00908 
2025-01-16 01:11:08.590194: train_loss -0.7193 
2025-01-16 01:11:08.590696: val_loss -0.2698 
2025-01-16 01:11:08.595728: Pseudo dice [np.float32(0.486)] 
2025-01-16 01:11:08.599758: Epoch time: 41.36 s 
2025-01-16 01:11:09.147412:  
2025-01-16 01:11:09.147412: Epoch 52 
2025-01-16 01:11:09.152468: Current learning rate: 0.00906 
2025-01-16 01:11:50.505543: train_loss -0.6995 
2025-01-16 01:11:50.506579: val_loss -0.4631 
2025-01-16 01:11:50.511633: Pseudo dice [np.float32(0.6041)] 
2025-01-16 01:11:50.515182: Epoch time: 41.36 s 
2025-01-16 01:11:51.217574:  
2025-01-16 01:11:51.217574: Epoch 53 
2025-01-16 01:11:51.223123: Current learning rate: 0.00904 
2025-01-16 01:12:32.571053: train_loss -0.7043 
2025-01-16 01:12:32.571053: val_loss -0.2677 
2025-01-16 01:12:32.577663: Pseudo dice [np.float32(0.4445)] 
2025-01-16 01:12:32.580168: Epoch time: 41.35 s 
2025-01-16 01:12:33.126600:  
2025-01-16 01:12:33.127600: Epoch 54 
2025-01-16 01:12:33.132159: Current learning rate: 0.00902 
2025-01-16 01:13:14.498306: train_loss -0.7087 
2025-01-16 01:13:14.498306: val_loss -0.4446 
2025-01-16 01:13:14.503316: Pseudo dice [np.float32(0.632)] 
2025-01-16 01:13:14.506824: Epoch time: 41.37 s 
2025-01-16 01:13:15.057185:  
2025-01-16 01:13:15.057185: Epoch 55 
2025-01-16 01:13:15.062197: Current learning rate: 0.009 
2025-01-16 01:13:56.409544: train_loss -0.7209 
2025-01-16 01:13:56.410047: val_loss -0.4478 
2025-01-16 01:13:56.416062: Pseudo dice [np.float32(0.6182)] 
2025-01-16 01:13:56.419567: Epoch time: 41.35 s 
2025-01-16 01:13:56.971778:  
2025-01-16 01:13:56.971778: Epoch 56 
2025-01-16 01:13:56.977346: Current learning rate: 0.00899 
2025-01-16 01:14:38.313058: train_loss -0.7314 
2025-01-16 01:14:38.314061: val_loss -0.3803 
2025-01-16 01:14:38.319073: Pseudo dice [np.float32(0.5737)] 
2025-01-16 01:14:38.323080: Epoch time: 41.34 s 
2025-01-16 01:14:38.877648:  
2025-01-16 01:14:38.878651: Epoch 57 
2025-01-16 01:14:38.883717: Current learning rate: 0.00897 
2025-01-16 01:15:20.239247: train_loss -0.7497 
2025-01-16 01:15:20.239753: val_loss -0.4184 
2025-01-16 01:15:20.245311: Pseudo dice [np.float32(0.5868)] 
2025-01-16 01:15:20.249336: Epoch time: 41.36 s 
2025-01-16 01:15:20.801659:  
2025-01-16 01:15:20.802161: Epoch 58 
2025-01-16 01:15:20.806704: Current learning rate: 0.00895 
2025-01-16 01:16:02.155315: train_loss -0.6962 
2025-01-16 01:16:02.156319: val_loss -0.4335 
2025-01-16 01:16:02.162863: Pseudo dice [np.float32(0.6117)] 
2025-01-16 01:16:02.166375: Epoch time: 41.35 s 
2025-01-16 01:16:02.738594:  
2025-01-16 01:16:02.738594: Epoch 59 
2025-01-16 01:16:02.744116: Current learning rate: 0.00893 
2025-01-16 01:16:44.098123: train_loss -0.7226 
2025-01-16 01:16:44.098634: val_loss -0.3654 
2025-01-16 01:16:44.106212: Pseudo dice [np.float32(0.5685)] 
2025-01-16 01:16:44.110225: Epoch time: 41.36 s 
2025-01-16 01:16:44.674664:  
2025-01-16 01:16:44.675166: Epoch 60 
2025-01-16 01:16:44.679708: Current learning rate: 0.00891 
2025-01-16 01:17:26.030400: train_loss -0.718 
2025-01-16 01:17:26.030400: val_loss -0.3471 
2025-01-16 01:17:26.037443: Pseudo dice [np.float32(0.5115)] 
2025-01-16 01:17:26.041973: Epoch time: 41.36 s 
2025-01-16 01:17:26.752817:  
2025-01-16 01:17:26.753322: Epoch 61 
2025-01-16 01:17:26.758333: Current learning rate: 0.00889 
2025-01-16 01:18:08.119987: train_loss -0.7342 
2025-01-16 01:18:08.120491: val_loss -0.4479 
2025-01-16 01:18:08.126512: Pseudo dice [np.float32(0.6338)] 
2025-01-16 01:18:08.131545: Epoch time: 41.37 s 
2025-01-16 01:18:08.688325:  
2025-01-16 01:18:08.688325: Epoch 62 
2025-01-16 01:18:08.693336: Current learning rate: 0.00888 
2025-01-16 01:18:50.041045: train_loss -0.7315 
2025-01-16 01:18:50.042563: val_loss -0.4311 
2025-01-16 01:18:50.048805: Pseudo dice [np.float32(0.6234)] 
2025-01-16 01:18:50.051344: Epoch time: 41.35 s 
2025-01-16 01:18:50.055387: Yayy! New best EMA pseudo Dice: 0.5814999938011169 
2025-01-16 01:18:50.840618:  
2025-01-16 01:18:50.841624: Epoch 63 
2025-01-16 01:18:50.846184: Current learning rate: 0.00886 
2025-01-16 01:19:32.179572: train_loss -0.7429 
2025-01-16 01:19:32.179572: val_loss -0.3419 
2025-01-16 01:19:32.185617: Pseudo dice [np.float32(0.6016)] 
2025-01-16 01:19:32.188625: Epoch time: 41.34 s 
2025-01-16 01:19:32.192134: Yayy! New best EMA pseudo Dice: 0.5835000276565552 
2025-01-16 01:19:33.074584:  
2025-01-16 01:19:33.075584: Epoch 64 
2025-01-16 01:19:33.081176: Current learning rate: 0.00884 
2025-01-16 01:20:14.433272: train_loss -0.7418 
2025-01-16 01:20:14.434274: val_loss -0.4055 
2025-01-16 01:20:14.441432: Pseudo dice [np.float32(0.6074)] 
2025-01-16 01:20:14.444480: Epoch time: 41.36 s 
2025-01-16 01:20:14.447521: Yayy! New best EMA pseudo Dice: 0.5859000086784363 
2025-01-16 01:20:15.334273:  
2025-01-16 01:20:15.334273: Epoch 65 
2025-01-16 01:20:15.340313: Current learning rate: 0.00882 
2025-01-16 01:20:56.689723: train_loss -0.729 
2025-01-16 01:20:56.690225: val_loss -0.3624 
2025-01-16 01:20:56.695881: Pseudo dice [np.float32(0.5487)] 
2025-01-16 01:20:56.699448: Epoch time: 41.36 s 
2025-01-16 01:20:57.261304:  
2025-01-16 01:20:57.261304: Epoch 66 
2025-01-16 01:20:57.267320: Current learning rate: 0.0088 
2025-01-16 01:21:38.622089: train_loss -0.7372 
2025-01-16 01:21:38.622591: val_loss -0.4058 
2025-01-16 01:21:38.628202: Pseudo dice [np.float32(0.589)] 
2025-01-16 01:21:38.630740: Epoch time: 41.36 s 
2025-01-16 01:21:39.193210:  
2025-01-16 01:21:39.194213: Epoch 67 
2025-01-16 01:21:39.198759: Current learning rate: 0.00879 
2025-01-16 01:22:20.555451: train_loss -0.7457 
2025-01-16 01:22:20.555451: val_loss -0.3258 
2025-01-16 01:22:20.562043: Pseudo dice [np.float32(0.4351)] 
2025-01-16 01:22:20.565935: Epoch time: 41.36 s 
2025-01-16 01:22:21.137200:  
2025-01-16 01:22:21.137200: Epoch 68 
2025-01-16 01:22:21.142237: Current learning rate: 0.00877 
2025-01-16 01:23:02.525119: train_loss -0.7425 
2025-01-16 01:23:02.525627: val_loss -0.2259 
2025-01-16 01:23:02.530216: Pseudo dice [np.float32(0.4484)] 
2025-01-16 01:23:02.534266: Epoch time: 41.39 s 
2025-01-16 01:23:03.252616:  
2025-01-16 01:23:03.253119: Epoch 69 
2025-01-16 01:23:03.258130: Current learning rate: 0.00875 
2025-01-16 01:23:44.623421: train_loss -0.7688 
2025-01-16 01:23:44.623421: val_loss -0.2405 
2025-01-16 01:23:44.628491: Pseudo dice [np.float32(0.3788)] 
2025-01-16 01:23:44.632001: Epoch time: 41.37 s 
2025-01-16 01:23:45.203879:  
2025-01-16 01:23:45.203879: Epoch 70 
2025-01-16 01:23:45.208928: Current learning rate: 0.00873 
2025-01-16 01:24:26.561209: train_loss -0.7761 
2025-01-16 01:24:26.561209: val_loss -0.2979 
2025-01-16 01:24:26.565817: Pseudo dice [np.float32(0.5068)] 
2025-01-16 01:24:26.568857: Epoch time: 41.36 s 
2025-01-16 01:24:27.140349:  
2025-01-16 01:24:27.140349: Epoch 71 
2025-01-16 01:24:27.143860: Current learning rate: 0.00871 
2025-01-16 01:25:08.508770: train_loss -0.761 
2025-01-16 01:25:08.509274: val_loss -0.2467 
2025-01-16 01:25:08.514902: Pseudo dice [np.float32(0.4522)] 
2025-01-16 01:25:08.517928: Epoch time: 41.37 s 
2025-01-16 01:25:09.089719:  
2025-01-16 01:25:09.090221: Epoch 72 
2025-01-16 01:25:09.094731: Current learning rate: 0.00869 
2025-01-16 01:25:50.455283: train_loss -0.7409 
2025-01-16 01:25:50.456286: val_loss -0.2599 
2025-01-16 01:25:50.461847: Pseudo dice [np.float32(0.4583)] 
2025-01-16 01:25:50.464873: Epoch time: 41.37 s 
2025-01-16 01:25:51.032368:  
2025-01-16 01:25:51.032368: Epoch 73 
2025-01-16 01:25:51.036416: Current learning rate: 0.00868 
2025-01-16 01:26:32.402744: train_loss -0.7597 
2025-01-16 01:26:32.404261: val_loss -0.3576 
2025-01-16 01:26:32.409825: Pseudo dice [np.float32(0.547)] 
2025-01-16 01:26:32.412888: Epoch time: 41.37 s 
2025-01-16 01:26:32.983072:  
2025-01-16 01:26:32.983072: Epoch 74 
2025-01-16 01:26:32.988083: Current learning rate: 0.00866 
2025-01-16 01:27:14.343017: train_loss -0.7808 
2025-01-16 01:27:14.344017: val_loss -0.3294 
2025-01-16 01:27:14.349029: Pseudo dice [np.float32(0.452)] 
2025-01-16 01:27:14.352041: Epoch time: 41.36 s 
2025-01-16 01:27:14.928830:  
2025-01-16 01:27:14.929343: Epoch 75 
2025-01-16 01:27:14.933924: Current learning rate: 0.00864 
2025-01-16 01:27:56.292430: train_loss -0.7781 
2025-01-16 01:27:56.293979: val_loss -0.4056 
2025-01-16 01:27:56.299540: Pseudo dice [np.float32(0.6053)] 
2025-01-16 01:27:56.302557: Epoch time: 41.36 s 
2025-01-16 01:27:57.015777:  
2025-01-16 01:27:57.015777: Epoch 76 
2025-01-16 01:27:57.020815: Current learning rate: 0.00862 
2025-01-16 01:28:38.375948: train_loss -0.7606 
2025-01-16 01:28:38.375948: val_loss -0.2886 
2025-01-16 01:28:38.382054: Pseudo dice [np.float32(0.511)] 
2025-01-16 01:28:38.384557: Epoch time: 41.36 s 
2025-01-16 01:28:38.949762:  
2025-01-16 01:28:38.949762: Epoch 77 
2025-01-16 01:28:38.955367: Current learning rate: 0.0086 
2025-01-16 01:29:20.316310: train_loss -0.7533 
2025-01-16 01:29:20.316822: val_loss -0.3941 
2025-01-16 01:29:20.324447: Pseudo dice [np.float32(0.6074)] 
2025-01-16 01:29:20.328562: Epoch time: 41.37 s 
2025-01-16 01:29:20.911147:  
2025-01-16 01:29:20.912146: Epoch 78 
2025-01-16 01:29:20.917250: Current learning rate: 0.00858 
2025-01-16 01:30:02.279790: train_loss -0.7773 
2025-01-16 01:30:02.279790: val_loss -0.282 
2025-01-16 01:30:02.286347: Pseudo dice [np.float32(0.3951)] 
2025-01-16 01:30:02.292367: Epoch time: 41.37 s 
2025-01-16 01:30:02.884503:  
2025-01-16 01:30:02.884503: Epoch 79 
2025-01-16 01:30:02.889556: Current learning rate: 0.00857 
2025-01-16 01:30:44.243264: train_loss -0.7684 
2025-01-16 01:30:44.243264: val_loss -0.3932 
2025-01-16 01:30:44.249788: Pseudo dice [np.float32(0.6306)] 
2025-01-16 01:30:44.253299: Epoch time: 41.36 s 
2025-01-16 01:30:44.832374:  
2025-01-16 01:30:44.832374: Epoch 80 
2025-01-16 01:30:44.837908: Current learning rate: 0.00855 
2025-01-16 01:31:26.177195: train_loss -0.7588 
2025-01-16 01:31:26.177700: val_loss -0.4834 
2025-01-16 01:31:26.183260: Pseudo dice [np.float32(0.6365)] 
2025-01-16 01:31:26.186860: Epoch time: 41.35 s 
2025-01-16 01:31:26.764074:  
2025-01-16 01:31:26.764074: Epoch 81 
2025-01-16 01:31:26.770691: Current learning rate: 0.00853 
2025-01-16 01:32:08.135283: train_loss -0.7779 
2025-01-16 01:32:08.135787: val_loss -0.3475 
2025-01-16 01:32:08.141345: Pseudo dice [np.float32(0.5455)] 
2025-01-16 01:32:08.144382: Epoch time: 41.37 s 
2025-01-16 01:32:08.729736:  
2025-01-16 01:32:08.730249: Epoch 82 
2025-01-16 01:32:08.734822: Current learning rate: 0.00851 
2025-01-16 01:32:50.075124: train_loss -0.7873 
2025-01-16 01:32:50.076149: val_loss -0.2154 
2025-01-16 01:32:50.080693: Pseudo dice [np.float32(0.3581)] 
2025-01-16 01:32:50.084252: Epoch time: 41.35 s 
2025-01-16 01:32:50.642743:  
2025-01-16 01:32:50.643746: Epoch 83 
2025-01-16 01:32:50.648303: Current learning rate: 0.00849 
2025-01-16 01:33:31.997448: train_loss -0.7769 
2025-01-16 01:33:31.997448: val_loss -0.3862 
2025-01-16 01:33:32.003502: Pseudo dice [np.float32(0.5368)] 
2025-01-16 01:33:32.007632: Epoch time: 41.35 s 
2025-01-16 01:33:32.719621:  
2025-01-16 01:33:32.719621: Epoch 84 
2025-01-16 01:33:32.725245: Current learning rate: 0.00847 
2025-01-16 01:34:14.081694: train_loss -0.7702 
2025-01-16 01:34:14.082699: val_loss -0.3314 
2025-01-16 01:34:14.088710: Pseudo dice [np.float32(0.5649)] 
2025-01-16 01:34:14.092721: Epoch time: 41.36 s 
2025-01-16 01:34:14.639980:  
2025-01-16 01:34:14.639980: Epoch 85 
2025-01-16 01:34:14.645549: Current learning rate: 0.00846 
2025-01-16 01:34:55.993790: train_loss -0.7933 
2025-01-16 01:34:55.993790: val_loss -0.4746 
2025-01-16 01:34:56.000434: Pseudo dice [np.float32(0.6514)] 
2025-01-16 01:34:56.003980: Epoch time: 41.35 s 
2025-01-16 01:34:56.551192:  
2025-01-16 01:34:56.551192: Epoch 86 
2025-01-16 01:34:56.555216: Current learning rate: 0.00844 
2025-01-16 01:35:37.898125: train_loss -0.772 
2025-01-16 01:35:37.898630: val_loss -0.4363 
2025-01-16 01:35:37.904675: Pseudo dice [np.float32(0.5868)] 
2025-01-16 01:35:37.909251: Epoch time: 41.35 s 
2025-01-16 01:35:38.457872:  
2025-01-16 01:35:38.458379: Epoch 87 
2025-01-16 01:35:38.463391: Current learning rate: 0.00842 
2025-01-16 01:36:19.802352: train_loss -0.7956 
2025-01-16 01:36:19.802860: val_loss -0.2824 
2025-01-16 01:36:19.809445: Pseudo dice [np.float32(0.5623)] 
2025-01-16 01:36:19.813528: Epoch time: 41.35 s 
2025-01-16 01:36:20.354137:  
2025-01-16 01:36:20.355137: Epoch 88 
2025-01-16 01:36:20.360653: Current learning rate: 0.0084 
2025-01-16 01:37:01.712149: train_loss -0.7958 
2025-01-16 01:37:01.712149: val_loss -0.4488 
2025-01-16 01:37:01.719238: Pseudo dice [np.float32(0.5616)] 
2025-01-16 01:37:01.722789: Epoch time: 41.36 s 
2025-01-16 01:37:02.277512:  
2025-01-16 01:37:02.277512: Epoch 89 
2025-01-16 01:37:02.282541: Current learning rate: 0.00838 
2025-01-16 01:37:43.634163: train_loss -0.7857 
2025-01-16 01:37:43.634666: val_loss -0.4453 
2025-01-16 01:37:43.640788: Pseudo dice [np.float32(0.6626)] 
2025-01-16 01:37:43.644824: Epoch time: 41.36 s 
2025-01-16 01:37:44.189951:  
2025-01-16 01:37:44.189951: Epoch 90 
2025-01-16 01:37:44.194983: Current learning rate: 0.00836 
2025-01-16 01:38:25.581901: train_loss -0.7841 
2025-01-16 01:38:25.582404: val_loss -0.2288 
2025-01-16 01:38:25.588999: Pseudo dice [np.float32(0.2854)] 
2025-01-16 01:38:25.592035: Epoch time: 41.39 s 
2025-01-16 01:38:26.178012:  
2025-01-16 01:38:26.179015: Epoch 91 
2025-01-16 01:38:26.183578: Current learning rate: 0.00835 
2025-01-16 01:39:07.574719: train_loss -0.731 
2025-01-16 01:39:07.580903: val_loss -0.3104 
2025-01-16 01:39:07.584978: Pseudo dice [np.float32(0.5143)] 
2025-01-16 01:39:07.588003: Epoch time: 41.4 s 
2025-01-16 01:39:08.282759:  
2025-01-16 01:39:08.282759: Epoch 92 
2025-01-16 01:39:08.289330: Current learning rate: 0.00833 
2025-01-16 01:39:53.441125: train_loss -0.7678 
2025-01-16 01:39:53.441635: val_loss -0.3561 
2025-01-16 01:39:53.447265: Pseudo dice [np.float32(0.5392)] 
2025-01-16 01:39:53.451816: Epoch time: 45.16 s 
2025-01-16 01:39:53.996717:  
2025-01-16 01:39:53.997721: Epoch 93 
2025-01-16 01:39:54.003829: Current learning rate: 0.00831 
2025-01-16 01:40:35.374207: train_loss -0.7666 
2025-01-16 01:40:35.374207: val_loss -0.4229 
2025-01-16 01:40:35.380288: Pseudo dice [np.float32(0.5896)] 
2025-01-16 01:40:35.384327: Epoch time: 41.38 s 
2025-01-16 01:40:35.939162:  
2025-01-16 01:40:35.939162: Epoch 94 
2025-01-16 01:40:35.945279: Current learning rate: 0.00829 
2025-01-16 01:41:17.312427: train_loss -0.7318 
2025-01-16 01:41:17.312427: val_loss -0.4298 
2025-01-16 01:41:17.318953: Pseudo dice [np.float32(0.5487)] 
2025-01-16 01:41:17.323471: Epoch time: 41.37 s 
2025-01-16 01:41:17.867510:  
2025-01-16 01:41:17.868510: Epoch 95 
2025-01-16 01:41:17.873062: Current learning rate: 0.00827 
2025-01-16 01:41:59.247923: train_loss -0.7151 
2025-01-16 01:41:59.248924: val_loss -0.3443 
2025-01-16 01:41:59.269474: Pseudo dice [np.float32(0.5766)] 
2025-01-16 01:41:59.273982: Epoch time: 41.38 s 
2025-01-16 01:41:59.848920:  
2025-01-16 01:41:59.848920: Epoch 96 
2025-01-16 01:41:59.854473: Current learning rate: 0.00825 
2025-01-16 01:42:41.219923: train_loss -0.7587 
2025-01-16 01:42:41.220924: val_loss -0.3958 
2025-01-16 01:42:41.228474: Pseudo dice [np.float32(0.545)] 
2025-01-16 01:42:41.231519: Epoch time: 41.37 s 
2025-01-16 01:42:41.791393:  
2025-01-16 01:42:41.791897: Epoch 97 
2025-01-16 01:42:41.797915: Current learning rate: 0.00824 
2025-01-16 01:43:23.162420: train_loss -0.784 
2025-01-16 01:43:23.162420: val_loss -0.279 
2025-01-16 01:43:23.169544: Pseudo dice [np.float32(0.4447)] 
2025-01-16 01:43:23.172596: Epoch time: 41.37 s 
2025-01-16 01:43:23.724299:  
2025-01-16 01:43:23.724802: Epoch 98 
2025-01-16 01:43:23.730818: Current learning rate: 0.00822 
2025-01-16 01:44:05.087504: train_loss -0.7964 
2025-01-16 01:44:05.088022: val_loss -0.1963 
2025-01-16 01:44:05.094632: Pseudo dice [np.float32(0.3631)] 
2025-01-16 01:44:05.098225: Epoch time: 41.36 s 
2025-01-16 01:44:05.657511:  
2025-01-16 01:44:05.658033: Epoch 99 
2025-01-16 01:44:05.663101: Current learning rate: 0.0082 
2025-01-16 01:44:47.030062: train_loss -0.7954 
2025-01-16 01:44:47.030062: val_loss -0.3941 
2025-01-16 01:44:47.036163: Pseudo dice [np.float32(0.5977)] 
2025-01-16 01:44:47.039701: Epoch time: 41.37 s 
2025-01-16 01:44:47.828645:  
2025-01-16 01:44:47.829649: Epoch 100 
2025-01-16 01:44:47.833696: Current learning rate: 0.00818 
2025-01-16 01:45:29.190307: train_loss -0.799 
2025-01-16 01:45:29.190821: val_loss -0.3901 
2025-01-16 01:45:29.195910: Pseudo dice [np.float32(0.6054)] 
2025-01-16 01:45:29.200475: Epoch time: 41.36 s 
2025-01-16 01:45:29.908705:  
2025-01-16 01:45:29.909708: Epoch 101 
2025-01-16 01:45:29.914747: Current learning rate: 0.00816 
2025-01-16 01:46:11.253379: train_loss -0.8083 
2025-01-16 01:46:11.254382: val_loss -0.4065 
2025-01-16 01:46:11.260417: Pseudo dice [np.float32(0.5552)] 
2025-01-16 01:46:11.263437: Epoch time: 41.34 s 
2025-01-16 01:46:11.812536:  
2025-01-16 01:46:11.813535: Epoch 102 
2025-01-16 01:46:11.819124: Current learning rate: 0.00814 
2025-01-16 01:46:53.151757: train_loss -0.7827 
2025-01-16 01:46:53.152273: val_loss -0.4458 
2025-01-16 01:46:53.157837: Pseudo dice [np.float32(0.5923)] 
2025-01-16 01:46:53.161379: Epoch time: 41.34 s 
2025-01-16 01:46:53.713964:  
2025-01-16 01:46:53.714963: Epoch 103 
2025-01-16 01:46:53.720533: Current learning rate: 0.00813 
2025-01-16 01:47:35.087195: train_loss -0.7747 
2025-01-16 01:47:35.087698: val_loss -0.4791 
2025-01-16 01:47:35.095309: Pseudo dice [np.float32(0.6478)] 
2025-01-16 01:47:35.099384: Epoch time: 41.37 s 
2025-01-16 01:47:35.651330:  
2025-01-16 01:47:35.651330: Epoch 104 
2025-01-16 01:47:35.656341: Current learning rate: 0.00811 
2025-01-16 01:48:17.005288: train_loss -0.7978 
2025-01-16 01:48:17.005791: val_loss -0.4265 
2025-01-16 01:48:17.011808: Pseudo dice [np.float32(0.6075)] 
2025-01-16 01:48:17.015816: Epoch time: 41.36 s 
2025-01-16 01:48:17.565934:  
2025-01-16 01:48:17.566436: Epoch 105 
2025-01-16 01:48:17.571447: Current learning rate: 0.00809 
2025-01-16 01:48:58.927223: train_loss -0.7974 
2025-01-16 01:48:58.927727: val_loss -0.3992 
2025-01-16 01:48:58.934272: Pseudo dice [np.float32(0.5755)] 
2025-01-16 01:48:58.938098: Epoch time: 41.36 s 
2025-01-16 01:48:59.502576:  
2025-01-16 01:48:59.502576: Epoch 106 
2025-01-16 01:48:59.508189: Current learning rate: 0.00807 
2025-01-16 01:49:40.844244: train_loss -0.8204 
2025-01-16 01:49:40.845248: val_loss -0.2443 
2025-01-16 01:49:40.851820: Pseudo dice [np.float32(0.5113)] 
2025-01-16 01:49:40.855329: Epoch time: 41.34 s 
2025-01-16 01:49:41.415092:  
2025-01-16 01:49:41.416358: Epoch 107 
2025-01-16 01:49:41.422884: Current learning rate: 0.00805 
2025-01-16 01:50:22.774900: train_loss -0.8126 
2025-01-16 01:50:22.776407: val_loss -0.2393 
2025-01-16 01:50:22.782554: Pseudo dice [np.float32(0.3994)] 
2025-01-16 01:50:22.786598: Epoch time: 41.36 s 
2025-01-16 01:50:23.355048:  
2025-01-16 01:50:23.356051: Epoch 108 
2025-01-16 01:50:23.361687: Current learning rate: 0.00803 
2025-01-16 01:51:04.717522: train_loss -0.7906 
2025-01-16 01:51:04.718525: val_loss -0.3407 
2025-01-16 01:51:04.725052: Pseudo dice [np.float32(0.5915)] 
2025-01-16 01:51:04.728564: Epoch time: 41.36 s 
2025-01-16 01:51:05.433897:  
2025-01-16 01:51:05.434896: Epoch 109 
2025-01-16 01:51:05.440489: Current learning rate: 0.00801 
2025-01-16 01:51:46.808896: train_loss -0.7742 
2025-01-16 01:51:46.810399: val_loss -0.4338 
2025-01-16 01:51:46.816413: Pseudo dice [np.float32(0.6559)] 
2025-01-16 01:51:46.820425: Epoch time: 41.37 s 
2025-01-16 01:51:47.374410:  
2025-01-16 01:51:47.374410: Epoch 110 
2025-01-16 01:51:47.380529: Current learning rate: 0.008 
2025-01-16 01:52:28.732616: train_loss -0.7972 
2025-01-16 01:52:28.733120: val_loss -0.4074 
2025-01-16 01:52:28.739191: Pseudo dice [np.float32(0.6439)] 
2025-01-16 01:52:28.743204: Epoch time: 41.36 s 
2025-01-16 01:52:29.304789:  
2025-01-16 01:52:29.305788: Epoch 111 
2025-01-16 01:52:29.311303: Current learning rate: 0.00798 
2025-01-16 01:53:10.663733: train_loss -0.8382 
2025-01-16 01:53:10.663733: val_loss -0.3765 
2025-01-16 01:53:10.671283: Pseudo dice [np.float32(0.6306)] 
2025-01-16 01:53:10.674789: Epoch time: 41.36 s 
2025-01-16 01:53:11.233328:  
2025-01-16 01:53:11.233328: Epoch 112 
2025-01-16 01:53:11.238944: Current learning rate: 0.00796 
2025-01-16 01:53:52.593428: train_loss -0.8271 
2025-01-16 01:53:52.593933: val_loss -0.3815 
2025-01-16 01:53:52.600980: Pseudo dice [np.float32(0.6049)] 
2025-01-16 01:53:52.604020: Epoch time: 41.36 s 
2025-01-16 01:53:53.159473:  
2025-01-16 01:53:53.160479: Epoch 113 
2025-01-16 01:53:53.165489: Current learning rate: 0.00794 
2025-01-16 01:54:34.531275: train_loss -0.8139 
2025-01-16 01:54:34.531275: val_loss -0.3691 
2025-01-16 01:54:34.537794: Pseudo dice [np.float32(0.646)] 
2025-01-16 01:54:34.540816: Epoch time: 41.37 s 
2025-01-16 01:54:35.090844:  
2025-01-16 01:54:35.090844: Epoch 114 
2025-01-16 01:54:35.096893: Current learning rate: 0.00792 
2025-01-16 01:55:16.456280: train_loss -0.8167 
2025-01-16 01:55:16.456782: val_loss -0.3668 
2025-01-16 01:55:16.462796: Pseudo dice [np.float32(0.5769)] 
2025-01-16 01:55:16.466805: Epoch time: 41.37 s 
2025-01-16 01:55:17.012438:  
2025-01-16 01:55:17.012438: Epoch 115 
2025-01-16 01:55:17.018456: Current learning rate: 0.0079 
2025-01-16 01:55:58.381843: train_loss -0.8295 
2025-01-16 01:55:58.381843: val_loss -0.1266 
2025-01-16 01:55:58.386858: Pseudo dice [np.float32(0.2501)] 
2025-01-16 01:55:58.389364: Epoch time: 41.37 s 
2025-01-16 01:55:58.948030:  
2025-01-16 01:55:58.948532: Epoch 116 
2025-01-16 01:55:58.954547: Current learning rate: 0.00789 
2025-01-16 01:56:40.317861: train_loss -0.8287 
2025-01-16 01:56:40.319371: val_loss -0.3008 
2025-01-16 01:56:40.326019: Pseudo dice [np.float32(0.4644)] 
2025-01-16 01:56:40.330046: Epoch time: 41.37 s 
2025-01-16 01:56:40.889900:  
2025-01-16 01:56:40.890899: Epoch 117 
2025-01-16 01:56:40.896547: Current learning rate: 0.00787 
2025-01-16 01:57:22.255838: train_loss -0.7947 
2025-01-16 01:57:22.256840: val_loss -0.4413 
2025-01-16 01:57:22.263370: Pseudo dice [np.float32(0.57)] 
2025-01-16 01:57:22.266882: Epoch time: 41.37 s 
2025-01-16 01:57:22.979537:  
2025-01-16 01:57:22.980540: Epoch 118 
2025-01-16 01:57:22.986578: Current learning rate: 0.00785 
2025-01-16 01:58:04.358946: train_loss -0.8018 
2025-01-16 01:58:04.359949: val_loss -0.3089 
2025-01-16 01:58:04.366497: Pseudo dice [np.float32(0.5393)] 
2025-01-16 01:58:04.371005: Epoch time: 41.38 s 
2025-01-16 01:58:04.932255:  
2025-01-16 01:58:04.932255: Epoch 119 
2025-01-16 01:58:04.938272: Current learning rate: 0.00783 
2025-01-16 01:58:46.295505: train_loss -0.8216 
2025-01-16 01:58:46.296017: val_loss -0.3558 
2025-01-16 01:58:46.302675: Pseudo dice [np.float32(0.5993)] 
2025-01-16 01:58:46.306720: Epoch time: 41.36 s 
2025-01-16 01:58:46.868760:  
2025-01-16 01:58:46.869264: Epoch 120 
2025-01-16 01:58:46.874276: Current learning rate: 0.00781 
2025-01-16 01:59:28.242971: train_loss -0.8224 
2025-01-16 01:59:28.242971: val_loss -0.3328 
2025-01-16 01:59:28.249486: Pseudo dice [np.float32(0.5839)] 
2025-01-16 01:59:28.253994: Epoch time: 41.38 s 
2025-01-16 01:59:28.810173:  
2025-01-16 01:59:28.810173: Epoch 121 
2025-01-16 01:59:28.815196: Current learning rate: 0.00779 
2025-01-16 02:00:10.170144: train_loss -0.8209 
2025-01-16 02:00:10.171146: val_loss -0.3469 
2025-01-16 02:00:10.177666: Pseudo dice [np.float32(0.5437)] 
2025-01-16 02:00:10.181177: Epoch time: 41.36 s 
2025-01-16 02:00:10.735885:  
2025-01-16 02:00:10.735885: Epoch 122 
2025-01-16 02:00:10.739934: Current learning rate: 0.00777 
2025-01-16 02:00:52.105505: train_loss -0.8062 
2025-01-16 02:00:52.106508: val_loss -0.4147 
2025-01-16 02:00:52.111527: Pseudo dice [np.float32(0.5343)] 
2025-01-16 02:00:52.116235: Epoch time: 41.37 s 
2025-01-16 02:00:52.676505:  
2025-01-16 02:00:52.677505: Epoch 123 
2025-01-16 02:00:52.683075: Current learning rate: 0.00776 
2025-01-16 02:01:34.040215: train_loss -0.8215 
2025-01-16 02:01:34.041218: val_loss -0.3872 
2025-01-16 02:01:34.047733: Pseudo dice [np.float32(0.6539)] 
2025-01-16 02:01:34.050272: Epoch time: 41.36 s 
2025-01-16 02:01:34.610909:  
2025-01-16 02:01:34.611910: Epoch 124 
2025-01-16 02:01:34.615924: Current learning rate: 0.00774 
2025-01-16 02:02:15.964116: train_loss -0.8331 
2025-01-16 02:02:15.965618: val_loss -0.4423 
2025-01-16 02:02:15.971633: Pseudo dice [np.float32(0.5955)] 
2025-01-16 02:02:15.975646: Epoch time: 41.35 s 
2025-01-16 02:02:16.532707:  
2025-01-16 02:02:16.532707: Epoch 125 
2025-01-16 02:02:16.539332: Current learning rate: 0.00772 
2025-01-16 02:02:57.899432: train_loss -0.8183 
2025-01-16 02:02:57.900435: val_loss -0.2981 
2025-01-16 02:02:57.904976: Pseudo dice [np.float32(0.5586)] 
2025-01-16 02:02:57.909555: Epoch time: 41.37 s 
2025-01-16 02:02:58.616374:  
2025-01-16 02:02:58.617374: Epoch 126 
2025-01-16 02:02:58.623017: Current learning rate: 0.0077 
2025-01-16 02:03:39.975703: train_loss -0.8286 
2025-01-16 02:03:39.977218: val_loss -0.2686 
2025-01-16 02:03:39.984376: Pseudo dice [np.float32(0.4931)] 
2025-01-16 02:03:39.987908: Epoch time: 41.36 s 
2025-01-16 02:03:40.546758:  
2025-01-16 02:03:40.547271: Epoch 127 
2025-01-16 02:03:40.552388: Current learning rate: 0.00768 
2025-01-16 02:04:21.900238: train_loss -0.8349 
2025-01-16 02:04:21.900743: val_loss -0.3323 
2025-01-16 02:04:21.906345: Pseudo dice [np.float32(0.5786)] 
2025-01-16 02:04:21.910394: Epoch time: 41.35 s 
2025-01-16 02:04:22.467536:  
2025-01-16 02:04:22.467536: Epoch 128 
2025-01-16 02:04:22.472547: Current learning rate: 0.00766 
2025-01-16 02:05:03.804380: train_loss -0.8374 
2025-01-16 02:05:03.805382: val_loss -0.3558 
2025-01-16 02:05:03.811937: Pseudo dice [np.float32(0.5572)] 
2025-01-16 02:05:03.815448: Epoch time: 41.34 s 
2025-01-16 02:05:04.377524:  
2025-01-16 02:05:04.377524: Epoch 129 
2025-01-16 02:05:04.383539: Current learning rate: 0.00764 
2025-01-16 02:05:45.728168: train_loss -0.8179 
2025-01-16 02:05:45.729172: val_loss -0.2748 
2025-01-16 02:05:45.735686: Pseudo dice [np.float32(0.5304)] 
2025-01-16 02:05:45.739196: Epoch time: 41.35 s 
2025-01-16 02:05:46.296349:  
2025-01-16 02:05:46.297348: Epoch 130 
2025-01-16 02:05:46.302976: Current learning rate: 0.00763 
2025-01-16 02:06:27.657175: train_loss -0.8239 
2025-01-16 02:06:27.657691: val_loss -0.4346 
2025-01-16 02:06:27.662773: Pseudo dice [np.float32(0.5906)] 
2025-01-16 02:06:27.667392: Epoch time: 41.36 s 
2025-01-16 02:06:28.223485:  
2025-01-16 02:06:28.224488: Epoch 131 
2025-01-16 02:06:28.229548: Current learning rate: 0.00761 
2025-01-16 02:07:09.597282: train_loss -0.8079 
2025-01-16 02:07:09.598849: val_loss -0.3392 
2025-01-16 02:07:09.604977: Pseudo dice [np.float32(0.5528)] 
2025-01-16 02:07:09.608523: Epoch time: 41.37 s 
2025-01-16 02:07:10.177354:  
2025-01-16 02:07:10.177354: Epoch 132 
2025-01-16 02:07:10.182479: Current learning rate: 0.00759 
2025-01-16 02:07:51.556392: train_loss -0.8292 
2025-01-16 02:07:51.556392: val_loss -0.3448 
2025-01-16 02:07:51.561975: Pseudo dice [np.float32(0.6106)] 
2025-01-16 02:07:51.565984: Epoch time: 41.38 s 
2025-01-16 02:07:52.136667:  
2025-01-16 02:07:52.136667: Epoch 133 
2025-01-16 02:07:52.142699: Current learning rate: 0.00757 
2025-01-16 02:08:33.513306: train_loss -0.8145 
2025-01-16 02:08:33.513810: val_loss -0.2436 
2025-01-16 02:08:33.519825: Pseudo dice [np.float32(0.4666)] 
2025-01-16 02:08:33.523833: Epoch time: 41.38 s 
2025-01-16 02:08:34.234276:  
2025-01-16 02:08:34.235276: Epoch 134 
2025-01-16 02:08:34.240852: Current learning rate: 0.00755 
2025-01-16 02:09:15.593149: train_loss -0.8101 
2025-01-16 02:09:15.593659: val_loss -0.2516 
2025-01-16 02:09:15.599833: Pseudo dice [np.float32(0.4872)] 
2025-01-16 02:09:15.603359: Epoch time: 41.36 s 
2025-01-16 02:09:16.170292:  
2025-01-16 02:09:16.170799: Epoch 135 
2025-01-16 02:09:16.176813: Current learning rate: 0.00753 
2025-01-16 02:09:57.535954: train_loss -0.7701 
2025-01-16 02:09:57.536956: val_loss -0.2573 
2025-01-16 02:09:57.543044: Pseudo dice [np.float32(0.3703)] 
2025-01-16 02:09:57.547114: Epoch time: 41.37 s 
2025-01-16 02:09:58.121442:  
2025-01-16 02:09:58.122441: Epoch 136 
2025-01-16 02:09:58.127002: Current learning rate: 0.00751 
2025-01-16 02:10:39.487224: train_loss -0.7741 
2025-01-16 02:10:39.487224: val_loss -0.1893 
2025-01-16 02:10:39.493301: Pseudo dice [np.float32(0.4818)] 
2025-01-16 02:10:39.497508: Epoch time: 41.37 s 
2025-01-16 02:10:40.065356:  
2025-01-16 02:10:40.065356: Epoch 137 
2025-01-16 02:10:40.071388: Current learning rate: 0.0075 
2025-01-16 02:11:21.428962: train_loss -0.7758 
2025-01-16 02:11:21.429478: val_loss -0.2708 
2025-01-16 02:11:21.435554: Pseudo dice [np.float32(0.4413)] 
2025-01-16 02:11:21.438584: Epoch time: 41.36 s 
2025-01-16 02:11:22.006372:  
2025-01-16 02:11:22.006881: Epoch 138 
2025-01-16 02:11:22.011955: Current learning rate: 0.00748 
2025-01-16 02:12:03.360599: train_loss -0.8068 
2025-01-16 02:12:03.361102: val_loss -0.2997 
2025-01-16 02:12:03.367995: Pseudo dice [np.float32(0.4872)] 
2025-01-16 02:12:03.371554: Epoch time: 41.35 s 
2025-01-16 02:12:03.941887:  
2025-01-16 02:12:03.941887: Epoch 139 
2025-01-16 02:12:03.947906: Current learning rate: 0.00746 
2025-01-16 02:12:45.310982: train_loss -0.8145 
2025-01-16 02:12:45.311496: val_loss -0.2773 
2025-01-16 02:12:45.318197: Pseudo dice [np.float32(0.4267)] 
2025-01-16 02:12:45.323258: Epoch time: 41.37 s 
2025-01-16 02:12:45.898591:  
2025-01-16 02:12:45.899596: Epoch 140 
2025-01-16 02:12:45.904140: Current learning rate: 0.00744 
2025-01-16 02:13:27.273987: train_loss -0.8535 
2025-01-16 02:13:27.274498: val_loss -0.3741 
2025-01-16 02:13:27.279031: Pseudo dice [np.float32(0.6268)] 
2025-01-16 02:13:27.282542: Epoch time: 41.38 s 
2025-01-16 02:13:27.853759:  
2025-01-16 02:13:27.854762: Epoch 141 
2025-01-16 02:13:27.860867: Current learning rate: 0.00742 
2025-01-16 02:14:09.210763: train_loss -0.8403 
2025-01-16 02:14:09.211764: val_loss -0.3314 
2025-01-16 02:14:09.217279: Pseudo dice [np.float32(0.5509)] 
2025-01-16 02:14:09.220788: Epoch time: 41.36 s 
2025-01-16 02:14:09.943259:  
2025-01-16 02:14:09.944259: Epoch 142 
2025-01-16 02:14:09.949854: Current learning rate: 0.0074 
2025-01-16 02:14:51.310157: train_loss -0.8428 
2025-01-16 02:14:51.310699: val_loss -0.4254 
2025-01-16 02:14:51.316286: Pseudo dice [np.float32(0.622)] 
2025-01-16 02:14:51.319314: Epoch time: 41.37 s 
2025-01-16 02:14:51.885412:  
2025-01-16 02:14:51.885914: Epoch 143 
2025-01-16 02:14:51.891927: Current learning rate: 0.00738 
2025-01-16 02:15:33.231219: train_loss -0.8258 
2025-01-16 02:15:33.231219: val_loss -0.4122 
2025-01-16 02:15:33.235821: Pseudo dice [np.float32(0.6)] 
2025-01-16 02:15:33.239330: Epoch time: 41.35 s 
2025-01-16 02:15:33.814327:  
2025-01-16 02:15:33.814327: Epoch 144 
2025-01-16 02:15:33.819902: Current learning rate: 0.00737 
2025-01-16 02:16:15.168966: train_loss -0.8369 
2025-01-16 02:16:15.168966: val_loss -0.2572 
2025-01-16 02:16:15.175481: Pseudo dice [np.float32(0.4246)] 
2025-01-16 02:16:15.178990: Epoch time: 41.36 s 
2025-01-16 02:16:15.746295:  
2025-01-16 02:16:15.746295: Epoch 145 
2025-01-16 02:16:15.751884: Current learning rate: 0.00735 
2025-01-16 02:16:57.090274: train_loss -0.8457 
2025-01-16 02:16:57.090274: val_loss -0.3311 
2025-01-16 02:16:57.096318: Pseudo dice [np.float32(0.517)] 
2025-01-16 02:16:57.099839: Epoch time: 41.34 s 
2025-01-16 02:16:57.675625:  
2025-01-16 02:16:57.675625: Epoch 146 
2025-01-16 02:16:57.682260: Current learning rate: 0.00733 
2025-01-16 02:17:39.035743: train_loss -0.8461 
2025-01-16 02:17:39.035743: val_loss -0.3459 
2025-01-16 02:17:39.040754: Pseudo dice [np.float32(0.5463)] 
2025-01-16 02:17:39.044259: Epoch time: 41.36 s 
2025-01-16 02:17:39.686409:  
2025-01-16 02:17:39.687412: Epoch 147 
2025-01-16 02:17:39.693449: Current learning rate: 0.00731 
2025-01-16 02:18:21.062674: train_loss -0.8609 
2025-01-16 02:18:21.063677: val_loss -0.2986 
2025-01-16 02:18:21.069709: Pseudo dice [np.float32(0.5729)] 
2025-01-16 02:18:21.073738: Epoch time: 41.38 s 
2025-01-16 02:18:21.645064:  
2025-01-16 02:18:21.645064: Epoch 148 
2025-01-16 02:18:21.650167: Current learning rate: 0.00729 
2025-01-16 02:19:03.012435: train_loss -0.8534 
2025-01-16 02:19:03.013438: val_loss -0.3201 
2025-01-16 02:19:03.019493: Pseudo dice [np.float32(0.6032)] 
2025-01-16 02:19:03.022577: Epoch time: 41.37 s 
2025-01-16 02:19:03.592722:  
2025-01-16 02:19:03.593721: Epoch 149 
2025-01-16 02:19:03.598327: Current learning rate: 0.00727 
2025-01-16 02:19:44.969977: train_loss -0.8522 
2025-01-16 02:19:44.970978: val_loss -0.34 
2025-01-16 02:19:44.977494: Pseudo dice [np.float32(0.6015)] 
2025-01-16 02:19:44.981000: Epoch time: 41.38 s 
2025-01-16 02:19:45.790223:  
2025-01-16 02:19:45.791726: Epoch 150 
2025-01-16 02:19:45.797266: Current learning rate: 0.00725 
2025-01-16 02:20:27.150073: train_loss -0.8435 
2025-01-16 02:20:27.150073: val_loss -0.3756 
2025-01-16 02:20:27.156006: Pseudo dice [np.float32(0.6225)] 
2025-01-16 02:20:27.159548: Epoch time: 41.36 s 
2025-01-16 02:20:27.883639:  
2025-01-16 02:20:27.883639: Epoch 151 
2025-01-16 02:20:27.888651: Current learning rate: 0.00724 
2025-01-16 02:21:09.238455: train_loss -0.8504 
2025-01-16 02:21:09.239458: val_loss -0.2677 
2025-01-16 02:21:09.246019: Pseudo dice [np.float32(0.4085)] 
2025-01-16 02:21:09.251093: Epoch time: 41.36 s 
2025-01-16 02:21:09.822026:  
2025-01-16 02:21:09.822026: Epoch 152 
2025-01-16 02:21:09.828546: Current learning rate: 0.00722 
2025-01-16 02:21:51.170184: train_loss -0.8566 
2025-01-16 02:21:51.170687: val_loss -0.3801 
2025-01-16 02:21:51.176723: Pseudo dice [np.float32(0.6251)] 
2025-01-16 02:21:51.181734: Epoch time: 41.35 s 
2025-01-16 02:21:51.749986:  
2025-01-16 02:21:51.750985: Epoch 153 
2025-01-16 02:21:51.756498: Current learning rate: 0.0072 
2025-01-16 02:22:33.101612: train_loss -0.8586 
2025-01-16 02:22:33.102122: val_loss -0.355 
2025-01-16 02:22:33.108721: Pseudo dice [np.float32(0.5762)] 
2025-01-16 02:22:33.112785: Epoch time: 41.35 s 
2025-01-16 02:22:33.693283:  
2025-01-16 02:22:33.693283: Epoch 154 
2025-01-16 02:22:33.699298: Current learning rate: 0.00718 
2025-01-16 02:23:15.046656: train_loss -0.8629 
2025-01-16 02:23:15.046656: val_loss -0.2406 
2025-01-16 02:23:15.054199: Pseudo dice [np.float32(0.5678)] 
2025-01-16 02:23:15.058219: Epoch time: 41.35 s 
2025-01-16 02:23:15.636977:  
2025-01-16 02:23:15.637482: Epoch 155 
2025-01-16 02:23:15.643137: Current learning rate: 0.00716 
2025-01-16 02:23:56.992412: train_loss -0.8687 
2025-01-16 02:23:56.993415: val_loss -0.3295 
2025-01-16 02:23:56.999960: Pseudo dice [np.float32(0.5474)] 
2025-01-16 02:23:57.004472: Epoch time: 41.36 s 
2025-01-16 02:23:57.584044:  
2025-01-16 02:23:57.584044: Epoch 156 
2025-01-16 02:23:57.590637: Current learning rate: 0.00714 
2025-01-16 02:24:38.937165: train_loss -0.8327 
2025-01-16 02:24:38.937165: val_loss -0.3196 
2025-01-16 02:24:38.943222: Pseudo dice [np.float32(0.5731)] 
2025-01-16 02:24:38.947234: Epoch time: 41.35 s 
2025-01-16 02:24:39.528534:  
2025-01-16 02:24:39.528534: Epoch 157 
2025-01-16 02:24:39.535050: Current learning rate: 0.00712 
2025-01-16 02:25:20.879514: train_loss -0.8483 
2025-01-16 02:25:20.879514: val_loss -0.4103 
2025-01-16 02:25:20.886600: Pseudo dice [np.float32(0.5781)] 
2025-01-16 02:25:20.891171: Epoch time: 41.35 s 
2025-01-16 02:25:21.471741:  
2025-01-16 02:25:21.471741: Epoch 158 
2025-01-16 02:25:21.477278: Current learning rate: 0.0071 
2025-01-16 02:26:02.842522: train_loss -0.8495 
2025-01-16 02:26:02.842522: val_loss -0.3031 
2025-01-16 02:26:02.849065: Pseudo dice [np.float32(0.5454)] 
2025-01-16 02:26:02.853575: Epoch time: 41.37 s 
2025-01-16 02:26:03.577576:  
2025-01-16 02:26:03.577576: Epoch 159 
2025-01-16 02:26:03.583591: Current learning rate: 0.00709 
2025-01-16 02:26:44.927796: train_loss -0.8636 
2025-01-16 02:26:44.927796: val_loss -0.3362 
2025-01-16 02:26:44.934356: Pseudo dice [np.float32(0.5711)] 
2025-01-16 02:26:44.937894: Epoch time: 41.35 s 
2025-01-16 02:26:45.516305:  
2025-01-16 02:26:45.517305: Epoch 160 
2025-01-16 02:26:45.522822: Current learning rate: 0.00707 
2025-01-16 02:27:26.876581: train_loss -0.8613 
2025-01-16 02:27:26.876581: val_loss -0.3685 
2025-01-16 02:27:26.884087: Pseudo dice [np.float32(0.6175)] 
2025-01-16 02:27:26.889101: Epoch time: 41.36 s 
2025-01-16 02:27:27.471668:  
2025-01-16 02:27:27.472672: Epoch 161 
2025-01-16 02:27:27.478705: Current learning rate: 0.00705 
2025-01-16 02:28:08.831725: train_loss -0.8659 
2025-01-16 02:28:08.832724: val_loss -0.2361 
2025-01-16 02:28:08.839242: Pseudo dice [np.float32(0.5121)] 
2025-01-16 02:28:08.843249: Epoch time: 41.36 s 
2025-01-16 02:28:09.423537:  
2025-01-16 02:28:09.423537: Epoch 162 
2025-01-16 02:28:09.429578: Current learning rate: 0.00703 
2025-01-16 02:28:50.798113: train_loss -0.8393 
2025-01-16 02:28:50.798113: val_loss -0.3458 
2025-01-16 02:28:50.806480: Pseudo dice [np.float32(0.5012)] 
2025-01-16 02:28:50.811491: Epoch time: 41.38 s 
2025-01-16 02:28:51.394304:  
2025-01-16 02:28:51.394304: Epoch 163 
2025-01-16 02:28:51.400317: Current learning rate: 0.00701 
2025-01-16 02:29:32.754723: train_loss -0.8425 
2025-01-16 02:29:32.755726: val_loss -0.3643 
2025-01-16 02:29:32.762283: Pseudo dice [np.float32(0.5809)] 
2025-01-16 02:29:32.766332: Epoch time: 41.36 s 
2025-01-16 02:29:33.351142:  
2025-01-16 02:29:33.351142: Epoch 164 
2025-01-16 02:29:33.356153: Current learning rate: 0.00699 
2025-01-16 02:30:14.722348: train_loss -0.8552 
2025-01-16 02:30:14.722854: val_loss -0.2221 
2025-01-16 02:30:14.729008: Pseudo dice [np.float32(0.4526)] 
2025-01-16 02:30:14.733551: Epoch time: 41.37 s 
2025-01-16 02:30:15.298533:  
2025-01-16 02:30:15.298533: Epoch 165 
2025-01-16 02:30:15.304563: Current learning rate: 0.00697 
2025-01-16 02:30:56.662597: train_loss -0.8679 
2025-01-16 02:30:56.662597: val_loss -0.3267 
2025-01-16 02:30:56.668648: Pseudo dice [np.float32(0.4682)] 
2025-01-16 02:30:56.671676: Epoch time: 41.37 s 
2025-01-16 02:30:57.238403:  
2025-01-16 02:30:57.238403: Epoch 166 
2025-01-16 02:30:57.245028: Current learning rate: 0.00696 
2025-01-16 02:31:38.596320: train_loss -0.8648 
2025-01-16 02:31:38.596823: val_loss -0.307 
2025-01-16 02:31:38.602838: Pseudo dice [np.float32(0.482)] 
2025-01-16 02:31:38.606342: Epoch time: 41.36 s 
2025-01-16 02:31:39.319492:  
2025-01-16 02:31:39.320005: Epoch 167 
2025-01-16 02:31:39.325044: Current learning rate: 0.00694 
2025-01-16 02:32:20.694318: train_loss -0.866 
2025-01-16 02:32:20.694823: val_loss -0.2429 
2025-01-16 02:32:20.700417: Pseudo dice [np.float32(0.4422)] 
2025-01-16 02:32:20.704941: Epoch time: 41.38 s 
2025-01-16 02:32:21.274917:  
2025-01-16 02:32:21.274917: Epoch 168 
2025-01-16 02:32:21.279995: Current learning rate: 0.00692 
2025-01-16 02:33:02.662093: train_loss -0.8652 
2025-01-16 02:33:02.662093: val_loss -0.3292 
2025-01-16 02:33:02.669699: Pseudo dice [np.float32(0.5971)] 
2025-01-16 02:33:02.674237: Epoch time: 41.39 s 
2025-01-16 02:33:03.249274:  
2025-01-16 02:33:03.250274: Epoch 169 
2025-01-16 02:33:03.256790: Current learning rate: 0.0069 
2025-01-16 02:33:44.615953: train_loss -0.8693 
2025-01-16 02:33:44.616458: val_loss -0.3159 
2025-01-16 02:33:44.622603: Pseudo dice [np.float32(0.4833)] 
2025-01-16 02:33:44.627172: Epoch time: 41.37 s 
2025-01-16 02:33:45.210017:  
2025-01-16 02:33:45.211019: Epoch 170 
2025-01-16 02:33:45.216595: Current learning rate: 0.00688 
2025-01-16 02:34:26.576541: train_loss -0.8748 
2025-01-16 02:34:26.577045: val_loss -0.3614 
2025-01-16 02:34:26.583118: Pseudo dice [np.float32(0.5808)] 
2025-01-16 02:34:26.587126: Epoch time: 41.37 s 
2025-01-16 02:34:27.163282:  
2025-01-16 02:34:27.163282: Epoch 171 
2025-01-16 02:34:27.169358: Current learning rate: 0.00686 
2025-01-16 02:35:08.508637: train_loss -0.8815 
2025-01-16 02:35:08.509140: val_loss -0.3399 
2025-01-16 02:35:08.515712: Pseudo dice [np.float32(0.5744)] 
2025-01-16 02:35:08.518743: Epoch time: 41.35 s 
2025-01-16 02:35:09.090842:  
2025-01-16 02:35:09.090842: Epoch 172 
2025-01-16 02:35:09.096861: Current learning rate: 0.00684 
2025-01-16 02:35:50.413937: train_loss -0.8765 
2025-01-16 02:35:50.414947: val_loss -0.2964 
2025-01-16 02:35:50.423073: Pseudo dice [np.float32(0.4974)] 
2025-01-16 02:35:50.425090: Epoch time: 41.32 s 
2025-01-16 02:35:50.997305:  
2025-01-16 02:35:50.997305: Epoch 173 
2025-01-16 02:35:51.003414: Current learning rate: 0.00682 
2025-01-16 02:36:32.331274: train_loss -0.8656 
2025-01-16 02:36:32.332277: val_loss -0.3286 
2025-01-16 02:36:32.338791: Pseudo dice [np.float32(0.586)] 
2025-01-16 02:36:32.342301: Epoch time: 41.33 s 
2025-01-16 02:36:32.931160:  
2025-01-16 02:36:32.931160: Epoch 174 
2025-01-16 02:36:32.937222: Current learning rate: 0.0068 
2025-01-16 02:37:14.266368: train_loss -0.8303 
2025-01-16 02:37:14.267368: val_loss -0.2649 
2025-01-16 02:37:14.272911: Pseudo dice [np.float32(0.4091)] 
2025-01-16 02:37:14.276420: Epoch time: 41.34 s 
2025-01-16 02:37:14.996337:  
2025-01-16 02:37:14.996839: Epoch 175 
2025-01-16 02:37:15.001850: Current learning rate: 0.00679 
2025-01-16 02:37:56.351441: train_loss -0.8364 
2025-01-16 02:37:56.351957: val_loss -0.3526 
2025-01-16 02:37:56.357527: Pseudo dice [np.float32(0.5763)] 
2025-01-16 02:37:56.359573: Epoch time: 41.36 s 
2025-01-16 02:37:56.936134:  
2025-01-16 02:37:56.937134: Epoch 176 
2025-01-16 02:37:56.941693: Current learning rate: 0.00677 
2025-01-16 02:38:38.300227: train_loss -0.8539 
2025-01-16 02:38:38.300740: val_loss -0.269 
2025-01-16 02:38:38.306831: Pseudo dice [np.float32(0.4908)] 
2025-01-16 02:38:38.310399: Epoch time: 41.36 s 
2025-01-16 02:38:38.896365:  
2025-01-16 02:38:38.896365: Epoch 177 
2025-01-16 02:38:38.901903: Current learning rate: 0.00675 
2025-01-16 02:39:20.259294: train_loss -0.8616 
2025-01-16 02:39:20.259802: val_loss -0.3555 
2025-01-16 02:39:20.265849: Pseudo dice [np.float32(0.5402)] 
2025-01-16 02:39:20.269376: Epoch time: 41.36 s 
2025-01-16 02:39:20.838603:  
2025-01-16 02:39:20.838603: Epoch 178 
2025-01-16 02:39:20.843621: Current learning rate: 0.00673 
2025-01-16 02:40:02.199429: train_loss -0.8654 
2025-01-16 02:40:02.199429: val_loss -0.1574 
2025-01-16 02:40:02.205974: Pseudo dice [np.float32(0.3133)] 
2025-01-16 02:40:02.209484: Epoch time: 41.36 s 
2025-01-16 02:40:02.779248:  
2025-01-16 02:40:02.779248: Epoch 179 
2025-01-16 02:40:02.784279: Current learning rate: 0.00671 
2025-01-16 02:40:44.140234: train_loss -0.8395 
2025-01-16 02:40:44.140234: val_loss -0.3547 
2025-01-16 02:40:44.146282: Pseudo dice [np.float32(0.5523)] 
2025-01-16 02:40:44.149825: Epoch time: 41.36 s 
2025-01-16 02:40:44.722824:  
2025-01-16 02:40:44.723333: Epoch 180 
2025-01-16 02:40:44.728904: Current learning rate: 0.00669 
2025-01-16 02:41:26.070336: train_loss -0.8412 
2025-01-16 02:41:26.071837: val_loss -0.3181 
2025-01-16 02:41:26.076895: Pseudo dice [np.float32(0.4264)] 
2025-01-16 02:41:26.081443: Epoch time: 41.35 s 
2025-01-16 02:41:26.655225:  
2025-01-16 02:41:26.656224: Epoch 181 
2025-01-16 02:41:26.660782: Current learning rate: 0.00667 
2025-01-16 02:42:08.015176: train_loss -0.8355 
2025-01-16 02:42:08.015176: val_loss -0.3113 
2025-01-16 02:42:08.020310: Pseudo dice [np.float32(0.5455)] 
2025-01-16 02:42:08.024873: Epoch time: 41.36 s 
2025-01-16 02:42:08.594469:  
2025-01-16 02:42:08.595473: Epoch 182 
2025-01-16 02:42:08.600043: Current learning rate: 0.00665 
2025-01-16 02:42:49.938132: train_loss -0.8152 
2025-01-16 02:42:49.938634: val_loss -0.3191 
2025-01-16 02:42:49.944205: Pseudo dice [np.float32(0.4792)] 
2025-01-16 02:42:49.947731: Epoch time: 41.34 s 
2025-01-16 02:42:50.668955:  
2025-01-16 02:42:50.669961: Epoch 183 
2025-01-16 02:42:50.674533: Current learning rate: 0.00664 
2025-01-16 02:43:32.005352: train_loss -0.8085 
2025-01-16 02:43:32.005352: val_loss -0.2171 
2025-01-16 02:43:32.012872: Pseudo dice [np.float32(0.3879)] 
2025-01-16 02:43:32.015377: Epoch time: 41.34 s 
2025-01-16 02:43:32.591615:  
2025-01-16 02:43:32.591615: Epoch 184 
2025-01-16 02:43:32.597149: Current learning rate: 0.00662 
2025-01-16 02:44:13.950249: train_loss -0.815 
2025-01-16 02:44:13.951255: val_loss -0.2827 
2025-01-16 02:44:13.957767: Pseudo dice [np.float32(0.5067)] 
2025-01-16 02:44:13.961277: Epoch time: 41.36 s 
2025-01-16 02:44:14.540446:  
2025-01-16 02:44:14.540446: Epoch 185 
2025-01-16 02:44:14.546040: Current learning rate: 0.0066 
2025-01-16 02:44:55.894329: train_loss -0.8627 
2025-01-16 02:44:55.894836: val_loss -0.3957 
2025-01-16 02:44:55.901390: Pseudo dice [np.float32(0.6341)] 
2025-01-16 02:44:55.904929: Epoch time: 41.35 s 
2025-01-16 02:44:56.479710:  
2025-01-16 02:44:56.480709: Epoch 186 
2025-01-16 02:44:56.485258: Current learning rate: 0.00658 
2025-01-16 02:45:37.842813: train_loss -0.8511 
2025-01-16 02:45:37.844845: val_loss -0.3194 
2025-01-16 02:45:37.849914: Pseudo dice [np.float32(0.5919)] 
2025-01-16 02:45:37.853021: Epoch time: 41.36 s 
2025-01-16 02:45:38.428541:  
2025-01-16 02:45:38.428541: Epoch 187 
2025-01-16 02:45:38.434100: Current learning rate: 0.00656 
2025-01-16 02:46:19.796777: train_loss -0.8385 
2025-01-16 02:46:19.796777: val_loss -0.2745 
2025-01-16 02:46:19.802792: Pseudo dice [np.float32(0.4747)] 
2025-01-16 02:46:19.806801: Epoch time: 41.37 s 
2025-01-16 02:46:20.389303:  
2025-01-16 02:46:20.389806: Epoch 188 
2025-01-16 02:46:20.394816: Current learning rate: 0.00654 
2025-01-16 02:47:01.744635: train_loss -0.871 
2025-01-16 02:47:01.745638: val_loss -0.2636 
2025-01-16 02:47:01.751681: Pseudo dice [np.float32(0.5716)] 
2025-01-16 02:47:01.755257: Epoch time: 41.36 s 
2025-01-16 02:47:02.333617:  
2025-01-16 02:47:02.333617: Epoch 189 
2025-01-16 02:47:02.338629: Current learning rate: 0.00652 
2025-01-16 02:47:43.696827: train_loss -0.8788 
2025-01-16 02:47:43.696827: val_loss -0.2515 
2025-01-16 02:47:43.703343: Pseudo dice [np.float32(0.4417)] 
2025-01-16 02:47:43.706852: Epoch time: 41.36 s 
2025-01-16 02:47:44.386101:  
2025-01-16 02:47:44.386101: Epoch 190 
2025-01-16 02:47:44.391145: Current learning rate: 0.0065 
2025-01-16 02:48:25.748269: train_loss -0.883 
2025-01-16 02:48:25.749272: val_loss -0.2882 
2025-01-16 02:48:25.756790: Pseudo dice [np.float32(0.5741)] 
2025-01-16 02:48:25.759296: Epoch time: 41.36 s 
2025-01-16 02:48:26.485615:  
2025-01-16 02:48:26.485615: Epoch 191 
2025-01-16 02:48:26.490692: Current learning rate: 0.00648 
2025-01-16 02:49:07.841558: train_loss -0.863 
2025-01-16 02:49:07.841558: val_loss -0.3345 
2025-01-16 02:49:07.848132: Pseudo dice [np.float32(0.5642)] 
2025-01-16 02:49:07.851153: Epoch time: 41.36 s 
2025-01-16 02:49:08.433732:  
2025-01-16 02:49:08.433732: Epoch 192 
2025-01-16 02:49:08.438773: Current learning rate: 0.00647 
2025-01-16 02:49:49.799320: train_loss -0.8786 
2025-01-16 02:49:49.799834: val_loss -0.2389 
2025-01-16 02:49:49.805427: Pseudo dice [np.float32(0.5265)] 
2025-01-16 02:49:49.809520: Epoch time: 41.37 s 
2025-01-16 02:49:50.392995:  
2025-01-16 02:49:50.392995: Epoch 193 
2025-01-16 02:49:50.399550: Current learning rate: 0.00645 
2025-01-16 02:50:31.737564: train_loss -0.8795 
2025-01-16 02:50:31.737564: val_loss -0.2312 
2025-01-16 02:50:31.744077: Pseudo dice [np.float32(0.4159)] 
2025-01-16 02:50:31.747586: Epoch time: 41.35 s 
2025-01-16 02:50:32.330227:  
2025-01-16 02:50:32.330227: Epoch 194 
2025-01-16 02:50:32.335280: Current learning rate: 0.00643 
2025-01-16 02:51:13.683181: train_loss -0.8811 
2025-01-16 02:51:13.683181: val_loss -0.245 
2025-01-16 02:51:13.689195: Pseudo dice [np.float32(0.288)] 
2025-01-16 02:51:13.692701: Epoch time: 41.35 s 
2025-01-16 02:51:14.277120:  
2025-01-16 02:51:14.277120: Epoch 195 
2025-01-16 02:51:14.282130: Current learning rate: 0.00641 
2025-01-16 02:51:55.636965: train_loss -0.876 
2025-01-16 02:51:55.637468: val_loss -0.4211 
2025-01-16 02:51:55.643077: Pseudo dice [np.float32(0.5585)] 
2025-01-16 02:51:55.645614: Epoch time: 41.36 s 
2025-01-16 02:51:56.228972:  
2025-01-16 02:51:56.229474: Epoch 196 
2025-01-16 02:51:56.232983: Current learning rate: 0.00639 
2025-01-16 02:52:37.574672: train_loss -0.8622 
2025-01-16 02:52:37.574672: val_loss -0.44 
2025-01-16 02:52:37.581186: Pseudo dice [np.float32(0.6493)] 
2025-01-16 02:52:37.584617: Epoch time: 41.35 s 
2025-01-16 02:52:38.164717:  
2025-01-16 02:52:38.165718: Epoch 197 
2025-01-16 02:52:38.168773: Current learning rate: 0.00637 
2025-01-16 02:53:19.512247: train_loss -0.8671 
2025-01-16 02:53:19.512757: val_loss -0.1973 
2025-01-16 02:53:19.518903: Pseudo dice [np.float32(0.4726)] 
2025-01-16 02:53:19.521435: Epoch time: 41.35 s 
2025-01-16 02:53:20.246608:  
2025-01-16 02:53:20.247607: Epoch 198 
2025-01-16 02:53:20.253202: Current learning rate: 0.00635 
2025-01-16 02:54:01.584699: train_loss -0.8863 
2025-01-16 02:54:01.585227: val_loss -0.3717 
2025-01-16 02:54:01.590327: Pseudo dice [np.float32(0.572)] 
2025-01-16 02:54:01.593840: Epoch time: 41.34 s 
2025-01-16 02:54:02.176335:  
2025-01-16 02:54:02.176838: Epoch 199 
2025-01-16 02:54:02.180349: Current learning rate: 0.00633 
2025-01-16 02:54:43.530786: train_loss -0.8836 
2025-01-16 02:54:43.530786: val_loss -0.3881 
2025-01-16 02:54:43.534799: Pseudo dice [np.float32(0.5525)] 
2025-01-16 02:54:43.538311: Epoch time: 41.36 s 
2025-01-16 02:54:44.353089:  
2025-01-16 02:54:44.353089: Epoch 200 
2025-01-16 02:54:44.358654: Current learning rate: 0.00631 
2025-01-16 02:55:25.709137: train_loss -0.844 
2025-01-16 02:55:25.709656: val_loss -0.2599 
2025-01-16 02:55:25.715247: Pseudo dice [np.float32(0.3981)] 
2025-01-16 02:55:25.719301: Epoch time: 41.36 s 
2025-01-16 02:55:26.314643:  
2025-01-16 02:55:26.315647: Epoch 201 
2025-01-16 02:55:26.320192: Current learning rate: 0.0063 
2025-01-16 02:56:07.684874: train_loss -0.8447 
2025-01-16 02:56:07.685388: val_loss -0.3377 
2025-01-16 02:56:07.689936: Pseudo dice [np.float32(0.4979)] 
2025-01-16 02:56:07.693974: Epoch time: 41.37 s 
2025-01-16 02:56:08.290448:  
2025-01-16 02:56:08.290448: Epoch 202 
2025-01-16 02:56:08.295458: Current learning rate: 0.00628 
2025-01-16 02:56:49.648409: train_loss -0.8698 
2025-01-16 02:56:49.648923: val_loss -0.238 
2025-01-16 02:56:49.654491: Pseudo dice [np.float32(0.5088)] 
2025-01-16 02:56:49.657516: Epoch time: 41.36 s 
2025-01-16 02:56:50.241111:  
2025-01-16 02:56:50.241111: Epoch 203 
2025-01-16 02:56:50.245206: Current learning rate: 0.00626 
2025-01-16 02:57:31.600652: train_loss -0.8859 
2025-01-16 02:57:31.601657: val_loss -0.3314 
2025-01-16 02:57:31.607740: Pseudo dice [np.float32(0.48)] 
2025-01-16 02:57:31.610788: Epoch time: 41.36 s 
2025-01-16 02:57:32.201511:  
2025-01-16 02:57:32.201511: Epoch 204 
2025-01-16 02:57:32.207055: Current learning rate: 0.00624 
2025-01-16 02:58:13.552328: train_loss -0.8758 
2025-01-16 02:58:13.553331: val_loss -0.384 
2025-01-16 02:58:13.559343: Pseudo dice [np.float32(0.6357)] 
2025-01-16 02:58:13.562351: Epoch time: 41.35 s 
2025-01-16 02:58:14.144674:  
2025-01-16 02:58:14.145677: Epoch 205 
2025-01-16 02:58:14.150218: Current learning rate: 0.00622 
2025-01-16 02:58:55.508730: train_loss -0.8236 
2025-01-16 02:58:55.509236: val_loss -0.3796 
2025-01-16 02:58:55.514277: Pseudo dice [np.float32(0.5499)] 
2025-01-16 02:58:55.517428: Epoch time: 41.36 s 
2025-01-16 02:58:56.068551:  
2025-01-16 02:58:56.069053: Epoch 206 
2025-01-16 02:58:56.074065: Current learning rate: 0.0062 
2025-01-16 02:59:37.410494: train_loss -0.8223 
2025-01-16 02:59:37.410996: val_loss -0.3409 
2025-01-16 02:59:37.416579: Pseudo dice [np.float32(0.4929)] 
2025-01-16 02:59:37.420112: Epoch time: 41.34 s 
2025-01-16 02:59:38.122219:  
2025-01-16 02:59:38.123219: Epoch 207 
2025-01-16 02:59:38.128277: Current learning rate: 0.00618 
2025-01-16 03:00:19.467072: train_loss -0.8435 
2025-01-16 03:00:19.468080: val_loss -0.3266 
2025-01-16 03:00:19.474710: Pseudo dice [np.float32(0.5762)] 
2025-01-16 03:00:19.478237: Epoch time: 41.34 s 
2025-01-16 03:00:20.032776:  
2025-01-16 03:00:20.033278: Epoch 208 
2025-01-16 03:00:20.038289: Current learning rate: 0.00616 
2025-01-16 03:01:01.373971: train_loss -0.8551 
2025-01-16 03:01:01.374473: val_loss -0.2802 
2025-01-16 03:01:01.398072: Pseudo dice [np.float32(0.5597)] 
2025-01-16 03:01:01.400579: Epoch time: 41.34 s 
2025-01-16 03:01:01.959420:  
2025-01-16 03:01:01.959922: Epoch 209 
2025-01-16 03:01:01.964934: Current learning rate: 0.00614 
2025-01-16 03:01:43.288977: train_loss -0.8531 
2025-01-16 03:01:43.288977: val_loss -0.3063 
2025-01-16 03:01:43.295056: Pseudo dice [np.float32(0.5708)] 
2025-01-16 03:01:43.297589: Epoch time: 41.33 s 
2025-01-16 03:01:43.850943:  
2025-01-16 03:01:43.850943: Epoch 210 
2025-01-16 03:01:43.857505: Current learning rate: 0.00612 
2025-01-16 03:02:25.194534: train_loss -0.8484 
2025-01-16 03:02:25.195037: val_loss -0.3987 
2025-01-16 03:02:25.200608: Pseudo dice [np.float32(0.5468)] 
2025-01-16 03:02:25.204117: Epoch time: 41.34 s 
2025-01-16 03:02:25.764743:  
2025-01-16 03:02:25.764743: Epoch 211 
2025-01-16 03:02:25.770303: Current learning rate: 0.00611 
2025-01-16 03:03:07.111907: train_loss -0.8579 
2025-01-16 03:03:07.112910: val_loss -0.2844 
2025-01-16 03:03:07.119450: Pseudo dice [np.float32(0.4684)] 
2025-01-16 03:03:07.123463: Epoch time: 41.35 s 
2025-01-16 03:03:07.677700:  
2025-01-16 03:03:07.677700: Epoch 212 
2025-01-16 03:03:07.683248: Current learning rate: 0.00609 
2025-01-16 03:03:49.026638: train_loss -0.8721 
2025-01-16 03:03:49.026638: val_loss -0.3475 
2025-01-16 03:03:49.032653: Pseudo dice [np.float32(0.5654)] 
2025-01-16 03:03:49.035160: Epoch time: 41.35 s 
2025-01-16 03:03:49.590358:  
2025-01-16 03:03:49.590358: Epoch 213 
2025-01-16 03:03:49.594897: Current learning rate: 0.00607 
2025-01-16 03:04:30.930523: train_loss -0.8582 
2025-01-16 03:04:30.931027: val_loss -0.3525 
2025-01-16 03:04:30.937665: Pseudo dice [np.float32(0.4615)] 
2025-01-16 03:04:30.941695: Epoch time: 41.34 s 
2025-01-16 03:04:31.492845:  
2025-01-16 03:04:31.492845: Epoch 214 
2025-01-16 03:04:31.497857: Current learning rate: 0.00605 
2025-01-16 03:05:12.837347: train_loss -0.8688 
2025-01-16 03:05:12.837347: val_loss -0.3328 
2025-01-16 03:05:12.843959: Pseudo dice [np.float32(0.5278)] 
2025-01-16 03:05:12.847011: Epoch time: 41.35 s 
2025-01-16 03:05:13.550692:  
2025-01-16 03:05:13.550692: Epoch 215 
2025-01-16 03:05:13.555727: Current learning rate: 0.00603 
2025-01-16 03:05:54.894256: train_loss -0.8657 
2025-01-16 03:05:54.894256: val_loss -0.35 
2025-01-16 03:05:54.900276: Pseudo dice [np.float32(0.5684)] 
2025-01-16 03:05:54.903937: Epoch time: 41.34 s 
2025-01-16 03:05:55.458356:  
2025-01-16 03:05:55.458356: Epoch 216 
2025-01-16 03:05:55.463380: Current learning rate: 0.00601 
2025-01-16 03:06:36.813892: train_loss -0.8726 
2025-01-16 03:06:36.814897: val_loss -0.4066 
2025-01-16 03:06:36.820446: Pseudo dice [np.float32(0.5653)] 
2025-01-16 03:06:36.822996: Epoch time: 41.36 s 
2025-01-16 03:06:37.378392:  
2025-01-16 03:06:37.378392: Epoch 217 
2025-01-16 03:06:37.384436: Current learning rate: 0.00599 
2025-01-16 03:07:18.737590: train_loss -0.8938 
2025-01-16 03:07:18.738102: val_loss -0.289 
2025-01-16 03:07:18.743631: Pseudo dice [np.float32(0.4553)] 
2025-01-16 03:07:18.747638: Epoch time: 41.36 s 
2025-01-16 03:07:19.299029:  
2025-01-16 03:07:19.300032: Epoch 218 
2025-01-16 03:07:19.304629: Current learning rate: 0.00597 
2025-01-16 03:08:00.651869: train_loss -0.8884 
2025-01-16 03:08:00.652873: val_loss -0.2542 
2025-01-16 03:08:00.659397: Pseudo dice [np.float32(0.3973)] 
2025-01-16 03:08:00.662908: Epoch time: 41.35 s 
2025-01-16 03:08:01.217497:  
2025-01-16 03:08:01.217497: Epoch 219 
2025-01-16 03:08:01.223055: Current learning rate: 0.00595 
2025-01-16 03:08:42.570462: train_loss -0.8666 
2025-01-16 03:08:42.571478: val_loss -0.2251 
2025-01-16 03:08:42.577035: Pseudo dice [np.float32(0.3745)] 
2025-01-16 03:08:42.581068: Epoch time: 41.35 s 
2025-01-16 03:08:43.133568:  
2025-01-16 03:08:43.133568: Epoch 220 
2025-01-16 03:08:43.139103: Current learning rate: 0.00593 
2025-01-16 03:09:24.488988: train_loss -0.8622 
2025-01-16 03:09:24.490497: val_loss -0.375 
2025-01-16 03:09:24.496639: Pseudo dice [np.float32(0.5187)] 
2025-01-16 03:09:24.499167: Epoch time: 41.36 s 
2025-01-16 03:09:25.060765:  
2025-01-16 03:09:25.060765: Epoch 221 
2025-01-16 03:09:25.066299: Current learning rate: 0.00592 
2025-01-16 03:10:06.421274: train_loss -0.8737 
2025-01-16 03:10:06.421274: val_loss -0.3488 
2025-01-16 03:10:06.426836: Pseudo dice [np.float32(0.5271)] 
2025-01-16 03:10:06.430881: Epoch time: 41.36 s 
2025-01-16 03:10:07.001961:  
2025-01-16 03:10:07.002964: Epoch 222 
2025-01-16 03:10:07.008023: Current learning rate: 0.0059 
2025-01-16 03:10:48.381669: train_loss -0.8719 
2025-01-16 03:10:48.382674: val_loss -0.3187 
2025-01-16 03:10:48.388692: Pseudo dice [np.float32(0.5501)] 
2025-01-16 03:10:48.391739: Epoch time: 41.38 s 
2025-01-16 03:10:48.948891:  
2025-01-16 03:10:48.948891: Epoch 223 
2025-01-16 03:10:48.953663: Current learning rate: 0.00588 
2025-01-16 03:11:30.329949: train_loss -0.8878 
2025-01-16 03:11:30.330950: val_loss -0.2931 
2025-01-16 03:11:30.336469: Pseudo dice [np.float32(0.5065)] 
2025-01-16 03:11:30.339977: Epoch time: 41.38 s 
2025-01-16 03:11:31.048211:  
2025-01-16 03:11:31.049216: Epoch 224 
2025-01-16 03:11:31.054246: Current learning rate: 0.00586 
2025-01-16 03:12:12.422406: train_loss -0.8893 
2025-01-16 03:12:12.422909: val_loss -0.2685 
2025-01-16 03:12:12.427958: Pseudo dice [np.float32(0.475)] 
2025-01-16 03:12:12.431471: Epoch time: 41.37 s 
2025-01-16 03:12:12.982782:  
2025-01-16 03:12:12.983786: Epoch 225 
2025-01-16 03:12:12.988335: Current learning rate: 0.00584 
2025-01-16 03:12:54.355337: train_loss -0.8945 
2025-01-16 03:12:54.355840: val_loss -0.134 
2025-01-16 03:12:54.361953: Pseudo dice [np.float32(0.2494)] 
2025-01-16 03:12:54.365960: Epoch time: 41.37 s 
2025-01-16 03:12:54.920037:  
2025-01-16 03:12:54.920037: Epoch 226 
2025-01-16 03:12:54.925618: Current learning rate: 0.00582 
2025-01-16 03:13:36.297756: train_loss -0.8902 
2025-01-16 03:13:36.297756: val_loss -0.3105 
2025-01-16 03:13:36.303330: Pseudo dice [np.float32(0.5206)] 
2025-01-16 03:13:36.307355: Epoch time: 41.38 s 
2025-01-16 03:13:36.856290:  
2025-01-16 03:13:36.856290: Epoch 227 
2025-01-16 03:13:36.861846: Current learning rate: 0.0058 
2025-01-16 03:14:18.232672: train_loss -0.886 
2025-01-16 03:14:18.233180: val_loss -0.2947 
2025-01-16 03:14:18.239265: Pseudo dice [np.float32(0.4973)] 
2025-01-16 03:14:18.242825: Epoch time: 41.38 s 
2025-01-16 03:14:18.790859:  
2025-01-16 03:14:18.790859: Epoch 228 
2025-01-16 03:14:18.795368: Current learning rate: 0.00578 
2025-01-16 03:15:00.155809: train_loss -0.8757 
2025-01-16 03:15:00.155809: val_loss -0.3791 
2025-01-16 03:15:00.163440: Pseudo dice [np.float32(0.6295)] 
2025-01-16 03:15:00.168568: Epoch time: 41.36 s 
2025-01-16 03:15:00.716439:  
2025-01-16 03:15:00.717445: Epoch 229 
2025-01-16 03:15:00.721987: Current learning rate: 0.00576 
2025-01-16 03:15:42.074587: train_loss -0.8661 
2025-01-16 03:15:42.075091: val_loss -0.4389 
2025-01-16 03:15:42.080703: Pseudo dice [np.float32(0.6124)] 
2025-01-16 03:15:42.084728: Epoch time: 41.36 s 
2025-01-16 03:15:42.633189:  
2025-01-16 03:15:42.633189: Epoch 230 
2025-01-16 03:15:42.638216: Current learning rate: 0.00574 
2025-01-16 03:16:24.006284: train_loss -0.8607 
2025-01-16 03:16:24.007288: val_loss -0.2381 
2025-01-16 03:16:24.013299: Pseudo dice [np.float32(0.5073)] 
2025-01-16 03:16:24.017312: Epoch time: 41.37 s 
2025-01-16 03:16:24.580142:  
2025-01-16 03:16:24.580142: Epoch 231 
2025-01-16 03:16:24.585713: Current learning rate: 0.00572 
2025-01-16 03:17:05.953066: train_loss -0.8693 
2025-01-16 03:17:05.954064: val_loss -0.3287 
2025-01-16 03:17:05.960615: Pseudo dice [np.float32(0.6675)] 
2025-01-16 03:17:05.964122: Epoch time: 41.37 s 
2025-01-16 03:17:06.664744:  
2025-01-16 03:17:06.664744: Epoch 232 
2025-01-16 03:17:06.670313: Current learning rate: 0.0057 
2025-01-16 03:17:48.022890: train_loss -0.8898 
2025-01-16 03:17:48.023394: val_loss -0.2889 
2025-01-16 03:17:48.028406: Pseudo dice [np.float32(0.5926)] 
2025-01-16 03:17:48.031943: Epoch time: 41.36 s 
2025-01-16 03:17:48.583148:  
2025-01-16 03:17:48.583148: Epoch 233 
2025-01-16 03:17:48.588716: Current learning rate: 0.00569 
2025-01-16 03:18:29.925769: train_loss -0.8691 
2025-01-16 03:18:29.926273: val_loss -0.3102 
2025-01-16 03:18:29.931287: Pseudo dice [np.float32(0.5369)] 
2025-01-16 03:18:29.934800: Epoch time: 41.34 s 
2025-01-16 03:18:30.481549:  
2025-01-16 03:18:30.481549: Epoch 234 
2025-01-16 03:18:30.487594: Current learning rate: 0.00567 
2025-01-16 03:19:11.856123: train_loss -0.8587 
2025-01-16 03:19:11.857129: val_loss -0.349 
2025-01-16 03:19:11.863143: Pseudo dice [np.float32(0.5209)] 
2025-01-16 03:19:11.866153: Epoch time: 41.38 s 
2025-01-16 03:19:12.416176:  
2025-01-16 03:19:12.416176: Epoch 235 
2025-01-16 03:19:12.421189: Current learning rate: 0.00565 
2025-01-16 03:19:53.750794: train_loss -0.8724 
2025-01-16 03:19:53.750794: val_loss -0.3145 
2025-01-16 03:19:53.757313: Pseudo dice [np.float32(0.5215)] 
2025-01-16 03:19:53.759822: Epoch time: 41.34 s 
2025-01-16 03:19:54.312196:  
2025-01-16 03:19:54.312196: Epoch 236 
2025-01-16 03:19:54.318270: Current learning rate: 0.00563 
2025-01-16 03:20:35.660522: train_loss -0.8753 
2025-01-16 03:20:35.661522: val_loss -0.3587 
2025-01-16 03:20:35.667039: Pseudo dice [np.float32(0.5676)] 
2025-01-16 03:20:35.670550: Epoch time: 41.35 s 
2025-01-16 03:20:36.222555:  
2025-01-16 03:20:36.223057: Epoch 237 
2025-01-16 03:20:36.228072: Current learning rate: 0.00561 
2025-01-16 03:21:17.578315: train_loss -0.8663 
2025-01-16 03:21:17.579316: val_loss -0.4211 
2025-01-16 03:21:17.585382: Pseudo dice [np.float32(0.6425)] 
2025-01-16 03:21:17.588421: Epoch time: 41.36 s 
2025-01-16 03:21:18.140965:  
2025-01-16 03:21:18.141963: Epoch 238 
2025-01-16 03:21:18.147042: Current learning rate: 0.00559 
2025-01-16 03:21:59.518840: train_loss -0.8767 
2025-01-16 03:21:59.519346: val_loss -0.1904 
2025-01-16 03:21:59.524910: Pseudo dice [np.float32(0.3251)] 
2025-01-16 03:21:59.528444: Epoch time: 41.38 s 
2025-01-16 03:22:00.082215:  
2025-01-16 03:22:00.082215: Epoch 239 
2025-01-16 03:22:00.087227: Current learning rate: 0.00557 
2025-01-16 03:22:41.438504: train_loss -0.8877 
2025-01-16 03:22:41.439510: val_loss -0.2488 
2025-01-16 03:22:41.447073: Pseudo dice [np.float32(0.5415)] 
2025-01-16 03:22:41.449629: Epoch time: 41.36 s 
2025-01-16 03:22:42.009142:  
2025-01-16 03:22:42.009142: Epoch 240 
2025-01-16 03:22:42.014226: Current learning rate: 0.00555 
2025-01-16 03:23:23.365197: train_loss -0.871 
2025-01-16 03:23:23.366716: val_loss -0.4349 
2025-01-16 03:23:23.372379: Pseudo dice [np.float32(0.6485)] 
2025-01-16 03:23:23.376467: Epoch time: 41.36 s 
2025-01-16 03:23:24.091782:  
2025-01-16 03:23:24.091782: Epoch 241 
2025-01-16 03:23:24.097363: Current learning rate: 0.00553 
2025-01-16 03:24:05.439131: train_loss -0.8864 
2025-01-16 03:24:05.440635: val_loss -0.2907 
2025-01-16 03:24:05.445721: Pseudo dice [np.float32(0.5047)] 
2025-01-16 03:24:05.449229: Epoch time: 41.35 s 
2025-01-16 03:24:06.012947:  
2025-01-16 03:24:06.013463: Epoch 242 
2025-01-16 03:24:06.017507: Current learning rate: 0.00551 
2025-01-16 03:24:47.362879: train_loss -0.8801 
2025-01-16 03:24:47.363383: val_loss -0.3454 
2025-01-16 03:24:47.368397: Pseudo dice [np.float32(0.5471)] 
2025-01-16 03:24:47.371910: Epoch time: 41.35 s 
2025-01-16 03:24:47.936118:  
2025-01-16 03:24:47.937122: Epoch 243 
2025-01-16 03:24:47.941678: Current learning rate: 0.00549 
2025-01-16 03:25:29.301208: train_loss -0.8944 
2025-01-16 03:25:29.301715: val_loss -0.3871 
2025-01-16 03:25:29.307779: Pseudo dice [np.float32(0.5746)] 
2025-01-16 03:25:29.311330: Epoch time: 41.37 s 
2025-01-16 03:25:29.873783:  
2025-01-16 03:25:29.874783: Epoch 244 
2025-01-16 03:25:29.879855: Current learning rate: 0.00547 
2025-01-16 03:26:11.250736: train_loss -0.9087 
2025-01-16 03:26:11.251739: val_loss -0.3688 
2025-01-16 03:26:11.255821: Pseudo dice [np.float32(0.5557)] 
2025-01-16 03:26:11.260886: Epoch time: 41.38 s 
2025-01-16 03:26:11.824229:  
2025-01-16 03:26:11.824731: Epoch 245 
2025-01-16 03:26:11.829742: Current learning rate: 0.00546 
2025-01-16 03:26:53.176326: train_loss -0.8966 
2025-01-16 03:26:53.177325: val_loss -0.3323 
2025-01-16 03:26:53.182864: Pseudo dice [np.float32(0.6026)] 
2025-01-16 03:26:53.186373: Epoch time: 41.35 s 
2025-01-16 03:26:53.748303:  
2025-01-16 03:26:53.748303: Epoch 246 
2025-01-16 03:26:53.753313: Current learning rate: 0.00544 
2025-01-16 03:27:35.087178: train_loss -0.904 
2025-01-16 03:27:35.088177: val_loss -0.3541 
2025-01-16 03:27:35.093723: Pseudo dice [np.float32(0.5218)] 
2025-01-16 03:27:35.097231: Epoch time: 41.34 s 
2025-01-16 03:27:35.657752:  
2025-01-16 03:27:35.658737: Epoch 247 
2025-01-16 03:27:35.663763: Current learning rate: 0.00542 
2025-01-16 03:28:17.003042: train_loss -0.8857 
2025-01-16 03:28:17.004045: val_loss -0.2941 
2025-01-16 03:28:17.008592: Pseudo dice [np.float32(0.5278)] 
2025-01-16 03:28:17.013133: Epoch time: 41.35 s 
2025-01-16 03:28:17.575912:  
2025-01-16 03:28:17.576911: Epoch 248 
2025-01-16 03:28:17.582425: Current learning rate: 0.0054 
2025-01-16 03:28:58.946819: train_loss -0.8937 
2025-01-16 03:28:58.947822: val_loss -0.2735 
2025-01-16 03:28:58.953370: Pseudo dice [np.float32(0.5267)] 
2025-01-16 03:28:58.956953: Epoch time: 41.37 s 
2025-01-16 03:28:59.518888:  
2025-01-16 03:28:59.518888: Epoch 249 
2025-01-16 03:28:59.523938: Current learning rate: 0.00538 
2025-01-16 03:29:40.883919: train_loss -0.8855 
2025-01-16 03:29:40.883919: val_loss -0.2703 
2025-01-16 03:29:40.890005: Pseudo dice [np.float32(0.5931)] 
2025-01-16 03:29:40.893537: Epoch time: 41.37 s 
2025-01-16 03:29:41.811985:  
2025-01-16 03:29:41.811985: Epoch 250 
2025-01-16 03:29:41.818066: Current learning rate: 0.00536 
2025-01-16 03:30:23.183232: train_loss -0.8943 
2025-01-16 03:30:23.183743: val_loss -0.3044 
2025-01-16 03:30:23.189296: Pseudo dice [np.float32(0.5599)] 
2025-01-16 03:30:23.192326: Epoch time: 41.37 s 
2025-01-16 03:30:23.757750:  
2025-01-16 03:30:23.758749: Epoch 251 
2025-01-16 03:30:23.763814: Current learning rate: 0.00534 
2025-01-16 03:31:05.101421: train_loss -0.8978 
2025-01-16 03:31:05.101421: val_loss -0.3853 
2025-01-16 03:31:05.109024: Pseudo dice [np.float32(0.6145)] 
2025-01-16 03:31:05.113061: Epoch time: 41.34 s 
2025-01-16 03:31:05.671632:  
2025-01-16 03:31:05.671632: Epoch 252 
2025-01-16 03:31:05.675669: Current learning rate: 0.00532 
2025-01-16 03:31:47.050071: train_loss -0.8936 
2025-01-16 03:31:47.050071: val_loss -0.2209 
2025-01-16 03:31:47.055176: Pseudo dice [np.float32(0.5023)] 
2025-01-16 03:31:47.058765: Epoch time: 41.38 s 
2025-01-16 03:31:47.620142:  
2025-01-16 03:31:47.621688: Epoch 253 
2025-01-16 03:31:47.626725: Current learning rate: 0.0053 
2025-01-16 03:32:28.965197: train_loss -0.8792 
2025-01-16 03:32:28.965197: val_loss -0.3367 
2025-01-16 03:32:28.971746: Pseudo dice [np.float32(0.5998)] 
2025-01-16 03:32:28.974761: Epoch time: 41.35 s 
2025-01-16 03:32:29.539844:  
2025-01-16 03:32:29.540348: Epoch 254 
2025-01-16 03:32:29.545369: Current learning rate: 0.00528 
2025-01-16 03:33:10.912555: train_loss -0.8813 
2025-01-16 03:33:10.913559: val_loss -0.3053 
2025-01-16 03:33:10.919859: Pseudo dice [np.float32(0.6022)] 
2025-01-16 03:33:10.923381: Epoch time: 41.37 s 
2025-01-16 03:33:11.485960:  
2025-01-16 03:33:11.486462: Epoch 255 
2025-01-16 03:33:11.492488: Current learning rate: 0.00526 
2025-01-16 03:33:52.858624: train_loss -0.8961 
2025-01-16 03:33:52.859138: val_loss -0.3823 
2025-01-16 03:33:52.864220: Pseudo dice [np.float32(0.5949)] 
2025-01-16 03:33:52.867248: Epoch time: 41.37 s 
2025-01-16 03:33:53.429558:  
2025-01-16 03:33:53.430562: Epoch 256 
2025-01-16 03:33:53.436211: Current learning rate: 0.00524 
2025-01-16 03:34:34.795839: train_loss -0.9077 
2025-01-16 03:34:34.796842: val_loss -0.2461 
2025-01-16 03:34:34.802422: Pseudo dice [np.float32(0.4308)] 
2025-01-16 03:34:34.805486: Epoch time: 41.37 s 
2025-01-16 03:34:35.367203:  
2025-01-16 03:34:35.367706: Epoch 257 
2025-01-16 03:34:35.372801: Current learning rate: 0.00522 
2025-01-16 03:35:16.726118: train_loss -0.9009 
2025-01-16 03:35:16.726630: val_loss -0.2784 
2025-01-16 03:35:16.733197: Pseudo dice [np.float32(0.5729)] 
2025-01-16 03:35:16.736230: Epoch time: 41.36 s 
2025-01-16 03:35:17.450993:  
2025-01-16 03:35:17.451495: Epoch 258 
2025-01-16 03:35:17.456509: Current learning rate: 0.0052 
2025-01-16 03:35:58.812415: train_loss -0.9043 
2025-01-16 03:35:58.812415: val_loss -0.4071 
2025-01-16 03:35:58.818505: Pseudo dice [np.float32(0.6225)] 
2025-01-16 03:35:58.823120: Epoch time: 41.36 s 
2025-01-16 03:35:59.396544:  
2025-01-16 03:35:59.396544: Epoch 259 
2025-01-16 03:35:59.402059: Current learning rate: 0.00518 
2025-01-16 03:36:40.780007: train_loss -0.9119 
2025-01-16 03:36:40.781008: val_loss -0.3254 
2025-01-16 03:36:40.786550: Pseudo dice [np.float32(0.5946)] 
2025-01-16 03:36:40.791059: Epoch time: 41.38 s 
2025-01-16 03:36:41.362346:  
2025-01-16 03:36:41.363351: Epoch 260 
2025-01-16 03:36:41.368911: Current learning rate: 0.00517 
2025-01-16 03:37:22.731061: train_loss -0.8964 
2025-01-16 03:37:22.731061: val_loss -0.2696 
2025-01-16 03:37:22.738625: Pseudo dice [np.float32(0.4885)] 
2025-01-16 03:37:22.741156: Epoch time: 41.37 s 
2025-01-16 03:37:23.303036:  
2025-01-16 03:37:23.303036: Epoch 261 
2025-01-16 03:37:23.308062: Current learning rate: 0.00515 
2025-01-16 03:38:04.671978: train_loss -0.8885 
2025-01-16 03:38:04.672984: val_loss -0.3871 
2025-01-16 03:38:04.678997: Pseudo dice [np.float32(0.5866)] 
2025-01-16 03:38:04.682005: Epoch time: 41.37 s 
2025-01-16 03:38:05.249837:  
2025-01-16 03:38:05.250339: Epoch 262 
2025-01-16 03:38:05.256358: Current learning rate: 0.00513 
2025-01-16 03:38:46.622029: train_loss -0.8904 
2025-01-16 03:38:46.623534: val_loss -0.3019 
2025-01-16 03:38:46.628546: Pseudo dice [np.float32(0.5193)] 
2025-01-16 03:38:46.632054: Epoch time: 41.37 s 
2025-01-16 03:38:47.198794:  
2025-01-16 03:38:47.198794: Epoch 263 
2025-01-16 03:38:47.202817: Current learning rate: 0.00511 
2025-01-16 03:39:28.584705: train_loss -0.8804 
2025-01-16 03:39:28.585210: val_loss -0.3474 
2025-01-16 03:39:28.591289: Pseudo dice [np.float32(0.5455)] 
2025-01-16 03:39:28.594795: Epoch time: 41.39 s 
2025-01-16 03:39:29.158158:  
2025-01-16 03:39:29.158661: Epoch 264 
2025-01-16 03:39:29.163675: Current learning rate: 0.00509 
2025-01-16 03:40:10.508069: train_loss -0.8828 
2025-01-16 03:40:10.508069: val_loss -0.3285 
2025-01-16 03:40:10.516179: Pseudo dice [np.float32(0.613)] 
2025-01-16 03:40:10.519784: Epoch time: 41.35 s 
2025-01-16 03:40:11.094938:  
2025-01-16 03:40:11.094938: Epoch 265 
2025-01-16 03:40:11.099948: Current learning rate: 0.00507 
2025-01-16 03:40:52.471983: train_loss -0.8882 
2025-01-16 03:40:52.472486: val_loss -0.3309 
2025-01-16 03:40:52.477501: Pseudo dice [np.float32(0.5717)] 
2025-01-16 03:40:52.481010: Epoch time: 41.38 s 
2025-01-16 03:40:53.203518:  
2025-01-16 03:40:53.203518: Epoch 266 
2025-01-16 03:40:53.209134: Current learning rate: 0.00505 
2025-01-16 03:41:34.566689: train_loss -0.899 
2025-01-16 03:41:34.566689: val_loss -0.3338 
2025-01-16 03:41:34.572257: Pseudo dice [np.float32(0.5784)] 
2025-01-16 03:41:34.576278: Epoch time: 41.36 s 
2025-01-16 03:41:35.140665:  
2025-01-16 03:41:35.141668: Epoch 267 
2025-01-16 03:41:35.146697: Current learning rate: 0.00503 
2025-01-16 03:42:16.518826: train_loss -0.9001 
2025-01-16 03:42:16.518826: val_loss -0.3326 
2025-01-16 03:42:16.523457: Pseudo dice [np.float32(0.5595)] 
2025-01-16 03:42:16.526992: Epoch time: 41.38 s 
2025-01-16 03:42:17.102936:  
2025-01-16 03:42:17.102936: Epoch 268 
2025-01-16 03:42:17.107951: Current learning rate: 0.00501 
2025-01-16 03:42:58.465441: train_loss -0.9076 
2025-01-16 03:42:58.465955: val_loss -0.3371 
2025-01-16 03:42:58.471510: Pseudo dice [np.float32(0.5738)] 
2025-01-16 03:42:58.475052: Epoch time: 41.36 s 
2025-01-16 03:42:59.038427:  
2025-01-16 03:42:59.038427: Epoch 269 
2025-01-16 03:42:59.043971: Current learning rate: 0.00499 
2025-01-16 03:43:40.421577: train_loss -0.9055 
2025-01-16 03:43:40.422091: val_loss -0.2856 
2025-01-16 03:43:40.427159: Pseudo dice [np.float32(0.5969)] 
2025-01-16 03:43:40.429689: Epoch time: 41.38 s 
2025-01-16 03:43:40.996781:  
2025-01-16 03:43:40.996781: Epoch 270 
2025-01-16 03:43:41.002796: Current learning rate: 0.00497 
2025-01-16 03:44:22.357435: train_loss -0.9005 
2025-01-16 03:44:22.358441: val_loss -0.2807 
2025-01-16 03:44:22.365062: Pseudo dice [np.float32(0.4108)] 
2025-01-16 03:44:22.368100: Epoch time: 41.36 s 
2025-01-16 03:44:22.936737:  
2025-01-16 03:44:22.936737: Epoch 271 
2025-01-16 03:44:22.942816: Current learning rate: 0.00495 
2025-01-16 03:45:04.281967: train_loss -0.8998 
2025-01-16 03:45:04.281967: val_loss -0.3515 
2025-01-16 03:45:04.287978: Pseudo dice [np.float32(0.5845)] 
2025-01-16 03:45:04.290987: Epoch time: 41.35 s 
2025-01-16 03:45:04.854948:  
2025-01-16 03:45:04.855450: Epoch 272 
2025-01-16 03:45:04.860464: Current learning rate: 0.00493 
2025-01-16 03:45:46.226420: train_loss -0.8944 
2025-01-16 03:45:46.227424: val_loss -0.3467 
2025-01-16 03:45:46.231481: Pseudo dice [np.float32(0.5288)] 
2025-01-16 03:45:46.234585: Epoch time: 41.37 s 
2025-01-16 03:45:46.800659:  
2025-01-16 03:45:46.800659: Epoch 273 
2025-01-16 03:45:46.806674: Current learning rate: 0.00491 
2025-01-16 03:46:28.165406: train_loss -0.899 
2025-01-16 03:46:28.165406: val_loss -0.2831 
2025-01-16 03:46:28.171941: Pseudo dice [np.float32(0.5394)] 
2025-01-16 03:46:28.175465: Epoch time: 41.37 s 
2025-01-16 03:46:28.749114:  
2025-01-16 03:46:28.749114: Epoch 274 
2025-01-16 03:46:28.755196: Current learning rate: 0.00489 
2025-01-16 03:47:10.131358: train_loss -0.9 
2025-01-16 03:47:10.131358: val_loss -0.0993 
2025-01-16 03:47:10.138663: Pseudo dice [np.float32(0.2025)] 
2025-01-16 03:47:10.142716: Epoch time: 41.38 s 
2025-01-16 03:47:10.861279:  
2025-01-16 03:47:10.861279: Epoch 275 
2025-01-16 03:47:10.867869: Current learning rate: 0.00487 
2025-01-16 03:47:52.211221: train_loss -0.8637 
2025-01-16 03:47:52.211724: val_loss -0.2697 
2025-01-16 03:47:52.217738: Pseudo dice [np.float32(0.4506)] 
2025-01-16 03:47:52.221249: Epoch time: 41.35 s 
2025-01-16 03:47:52.791527:  
2025-01-16 03:47:52.791527: Epoch 276 
2025-01-16 03:47:52.796538: Current learning rate: 0.00485 
2025-01-16 03:48:34.134812: train_loss -0.889 
2025-01-16 03:48:34.135317: val_loss -0.2963 
2025-01-16 03:48:34.140864: Pseudo dice [np.float32(0.4985)] 
2025-01-16 03:48:34.144420: Epoch time: 41.34 s 
2025-01-16 03:48:34.720116:  
2025-01-16 03:48:34.720116: Epoch 277 
2025-01-16 03:48:34.724197: Current learning rate: 0.00484 
2025-01-16 03:49:16.097457: train_loss -0.8987 
2025-01-16 03:49:16.097964: val_loss -0.3997 
2025-01-16 03:49:16.104003: Pseudo dice [np.float32(0.6179)] 
2025-01-16 03:49:16.108012: Epoch time: 41.38 s 
2025-01-16 03:49:16.670112:  
2025-01-16 03:49:16.671116: Epoch 278 
2025-01-16 03:49:16.676167: Current learning rate: 0.00482 
2025-01-16 03:49:58.012542: train_loss -0.9091 
2025-01-16 03:49:58.013044: val_loss -0.3037 
2025-01-16 03:49:58.019590: Pseudo dice [np.float32(0.5913)] 
2025-01-16 03:49:58.023621: Epoch time: 41.34 s 
2025-01-16 03:49:58.590219:  
2025-01-16 03:49:58.590219: Epoch 279 
2025-01-16 03:49:58.596287: Current learning rate: 0.0048 
2025-01-16 03:50:39.915346: train_loss -0.897 
2025-01-16 03:50:39.916349: val_loss -0.2743 
2025-01-16 03:50:39.922359: Pseudo dice [np.float32(0.4758)] 
2025-01-16 03:50:39.925368: Epoch time: 41.33 s 
2025-01-16 03:50:40.494751:  
2025-01-16 03:50:40.495258: Epoch 280 
2025-01-16 03:50:40.500314: Current learning rate: 0.00478 
2025-01-16 03:51:21.826766: train_loss -0.9092 
2025-01-16 03:51:21.826766: val_loss -0.3848 
2025-01-16 03:51:21.832861: Pseudo dice [np.float32(0.5376)] 
2025-01-16 03:51:21.836935: Epoch time: 41.33 s 
2025-01-16 03:51:22.412663:  
2025-01-16 03:51:22.413663: Epoch 281 
2025-01-16 03:51:22.418215: Current learning rate: 0.00476 
2025-01-16 03:52:03.750512: train_loss -0.9131 
2025-01-16 03:52:03.751018: val_loss -0.3459 
2025-01-16 03:52:03.756055: Pseudo dice [np.float32(0.5386)] 
2025-01-16 03:52:03.759573: Epoch time: 41.34 s 
2025-01-16 03:52:04.323915:  
2025-01-16 03:52:04.323915: Epoch 282 
2025-01-16 03:52:04.329952: Current learning rate: 0.00474 
2025-01-16 03:52:45.668469: train_loss -0.9118 
2025-01-16 03:52:45.669971: val_loss -0.3279 
2025-01-16 03:52:45.676016: Pseudo dice [np.float32(0.575)] 
2025-01-16 03:52:45.678896: Epoch time: 41.35 s 
2025-01-16 03:52:46.396284:  
2025-01-16 03:52:46.396284: Epoch 283 
2025-01-16 03:52:46.401854: Current learning rate: 0.00472 
2025-01-16 03:53:27.724163: train_loss -0.9029 
2025-01-16 03:53:27.724163: val_loss -0.2395 
2025-01-16 03:53:27.731367: Pseudo dice [np.float32(0.4344)] 
2025-01-16 03:53:27.735921: Epoch time: 41.33 s 
2025-01-16 03:53:28.302376:  
2025-01-16 03:53:28.303376: Epoch 284 
2025-01-16 03:53:28.308952: Current learning rate: 0.0047 
2025-01-16 03:54:09.645071: train_loss -0.9152 
2025-01-16 03:54:09.646578: val_loss -0.201 
2025-01-16 03:54:09.652645: Pseudo dice [np.float32(0.3996)] 
2025-01-16 03:54:09.656190: Epoch time: 41.34 s 
2025-01-16 03:54:10.221757:  
2025-01-16 03:54:10.222259: Epoch 285 
2025-01-16 03:54:10.228274: Current learning rate: 0.00468 
2025-01-16 03:54:51.551268: train_loss -0.9106 
2025-01-16 03:54:51.551777: val_loss -0.2916 
2025-01-16 03:54:51.557373: Pseudo dice [np.float32(0.4571)] 
2025-01-16 03:54:51.562423: Epoch time: 41.33 s 
2025-01-16 03:54:52.128304:  
2025-01-16 03:54:52.128304: Epoch 286 
2025-01-16 03:54:52.133829: Current learning rate: 0.00466 
2025-01-16 03:55:33.465058: train_loss -0.9039 
2025-01-16 03:55:33.465058: val_loss -0.3184 
2025-01-16 03:55:33.471595: Pseudo dice [np.float32(0.5144)] 
2025-01-16 03:55:33.475103: Epoch time: 41.34 s 
2025-01-16 03:55:34.060143:  
2025-01-16 03:55:34.060645: Epoch 287 
2025-01-16 03:55:34.065656: Current learning rate: 0.00464 
2025-01-16 03:56:15.399180: train_loss -0.8996 
2025-01-16 03:56:15.399180: val_loss -0.1749 
2025-01-16 03:56:15.408284: Pseudo dice [np.float32(0.2921)] 
2025-01-16 03:56:15.411910: Epoch time: 41.34 s 
2025-01-16 03:56:15.991069:  
2025-01-16 03:56:15.991575: Epoch 288 
2025-01-16 03:56:15.996705: Current learning rate: 0.00462 
2025-01-16 03:56:57.332430: train_loss -0.8911 
2025-01-16 03:56:57.332430: val_loss -0.2495 
2025-01-16 03:56:57.337991: Pseudo dice [np.float32(0.5409)] 
2025-01-16 03:56:57.342021: Epoch time: 41.34 s 
2025-01-16 03:56:57.916175:  
2025-01-16 03:56:57.916175: Epoch 289 
2025-01-16 03:56:57.921186: Current learning rate: 0.0046 
2025-01-16 03:57:39.255821: train_loss -0.9082 
2025-01-16 03:57:39.255821: val_loss -0.2529 
2025-01-16 03:57:39.261929: Pseudo dice [np.float32(0.4421)] 
2025-01-16 03:57:39.275536: Epoch time: 41.34 s 
2025-01-16 03:57:39.855813:  
2025-01-16 03:57:39.855813: Epoch 290 
2025-01-16 03:57:39.861359: Current learning rate: 0.00458 
2025-01-16 03:58:21.200969: train_loss -0.9002 
2025-01-16 03:58:21.201475: val_loss -0.3599 
2025-01-16 03:58:21.208567: Pseudo dice [np.float32(0.4889)] 
2025-01-16 03:58:21.212091: Epoch time: 41.35 s 
2025-01-16 03:58:21.785976:  
2025-01-16 03:58:21.785976: Epoch 291 
2025-01-16 03:58:21.791521: Current learning rate: 0.00456 
2025-01-16 03:59:03.173744: train_loss -0.8943 
2025-01-16 03:59:03.174744: val_loss -0.3383 
2025-01-16 03:59:03.180297: Pseudo dice [np.float32(0.6125)] 
2025-01-16 03:59:03.183806: Epoch time: 41.39 s 
2025-01-16 03:59:03.755111:  
2025-01-16 03:59:03.756110: Epoch 292 
2025-01-16 03:59:03.761626: Current learning rate: 0.00454 
2025-01-16 03:59:45.100377: train_loss -0.9021 
2025-01-16 03:59:45.100881: val_loss -0.2903 
2025-01-16 03:59:45.106455: Pseudo dice [np.float32(0.3779)] 
2025-01-16 03:59:45.109474: Epoch time: 41.35 s 
2025-01-16 03:59:45.678287:  
2025-01-16 03:59:45.678287: Epoch 293 
2025-01-16 03:59:45.683316: Current learning rate: 0.00452 
2025-01-16 04:00:27.027128: train_loss -0.8966 
2025-01-16 04:00:27.028128: val_loss -0.281 
2025-01-16 04:00:27.033646: Pseudo dice [np.float32(0.448)] 
2025-01-16 04:00:27.038155: Epoch time: 41.35 s 
2025-01-16 04:00:27.607006:  
2025-01-16 04:00:27.608006: Epoch 294 
2025-01-16 04:00:27.613059: Current learning rate: 0.0045 
2025-01-16 04:01:08.950770: train_loss -0.896 
2025-01-16 04:01:08.950770: val_loss -0.2455 
2025-01-16 04:01:08.957346: Pseudo dice [np.float32(0.4385)] 
2025-01-16 04:01:08.960857: Epoch time: 41.34 s 
2025-01-16 04:01:09.529031:  
2025-01-16 04:01:09.529031: Epoch 295 
2025-01-16 04:01:09.535572: Current learning rate: 0.00448 
2025-01-16 04:01:50.870073: train_loss -0.9064 
2025-01-16 04:01:50.870576: val_loss -0.3954 
2025-01-16 04:01:50.876607: Pseudo dice [np.float32(0.5212)] 
2025-01-16 04:01:50.880180: Epoch time: 41.34 s 
2025-01-16 04:01:51.449937:  
2025-01-16 04:01:51.449937: Epoch 296 
2025-01-16 04:01:51.471619: Current learning rate: 0.00446 
2025-01-16 04:02:32.816412: train_loss -0.9168 
2025-01-16 04:02:32.816917: val_loss -0.3764 
2025-01-16 04:02:32.823515: Pseudo dice [np.float32(0.5202)] 
2025-01-16 04:02:32.827054: Epoch time: 41.37 s 
2025-01-16 04:02:33.398121:  
2025-01-16 04:02:33.398623: Epoch 297 
2025-01-16 04:02:33.403686: Current learning rate: 0.00444 
2025-01-16 04:03:14.759851: train_loss -0.9097 
2025-01-16 04:03:14.759851: val_loss -0.281 
2025-01-16 04:03:14.765421: Pseudo dice [np.float32(0.5024)] 
2025-01-16 04:03:14.769431: Epoch time: 41.36 s 
2025-01-16 04:03:15.351940:  
2025-01-16 04:03:15.351940: Epoch 298 
2025-01-16 04:03:15.356950: Current learning rate: 0.00442 
2025-01-16 04:03:56.704148: train_loss -0.8933 
2025-01-16 04:03:56.705151: val_loss -0.3195 
2025-01-16 04:03:56.711803: Pseudo dice [np.float32(0.4794)] 
2025-01-16 04:03:56.715349: Epoch time: 41.35 s 
2025-01-16 04:03:57.383848:  
2025-01-16 04:03:57.384851: Epoch 299 
2025-01-16 04:03:57.389894: Current learning rate: 0.0044 
2025-01-16 04:04:38.760458: train_loss -0.8557 
2025-01-16 04:04:38.761533: val_loss -0.3092 
2025-01-16 04:04:38.767111: Pseudo dice [np.float32(0.6131)] 
2025-01-16 04:04:38.770648: Epoch time: 41.38 s 
2025-01-16 04:04:39.690475:  
2025-01-16 04:04:39.691474: Epoch 300 
2025-01-16 04:04:39.697035: Current learning rate: 0.00438 
2025-01-16 04:05:21.034956: train_loss -0.9009 
2025-01-16 04:05:21.034956: val_loss -0.2435 
2025-01-16 04:05:21.042604: Pseudo dice [np.float32(0.5148)] 
2025-01-16 04:05:21.046113: Epoch time: 41.34 s 
2025-01-16 04:05:21.621902:  
2025-01-16 04:05:21.621902: Epoch 301 
2025-01-16 04:05:21.627434: Current learning rate: 0.00436 
2025-01-16 04:06:02.973649: train_loss -0.8927 
2025-01-16 04:06:02.974151: val_loss -0.2919 
2025-01-16 04:06:02.980217: Pseudo dice [np.float32(0.4478)] 
2025-01-16 04:06:02.983725: Epoch time: 41.35 s 
2025-01-16 04:06:03.558982:  
2025-01-16 04:06:03.558982: Epoch 302 
2025-01-16 04:06:03.563994: Current learning rate: 0.00434 
2025-01-16 04:06:44.923602: train_loss -0.9082 
2025-01-16 04:06:44.924105: val_loss -0.2673 
2025-01-16 04:06:44.929675: Pseudo dice [np.float32(0.4941)] 
2025-01-16 04:06:44.933215: Epoch time: 41.36 s 
2025-01-16 04:06:45.507735:  
2025-01-16 04:06:45.507735: Epoch 303 
2025-01-16 04:06:45.514289: Current learning rate: 0.00432 
2025-01-16 04:07:26.859493: train_loss -0.9041 
2025-01-16 04:07:26.860493: val_loss -0.2527 
2025-01-16 04:07:26.866589: Pseudo dice [np.float32(0.4544)] 
2025-01-16 04:07:26.870117: Epoch time: 41.35 s 
2025-01-16 04:07:27.442972:  
2025-01-16 04:07:27.442972: Epoch 304 
2025-01-16 04:07:27.448987: Current learning rate: 0.0043 
2025-01-16 04:08:08.795628: train_loss -0.9098 
2025-01-16 04:08:08.796134: val_loss -0.2477 
2025-01-16 04:08:08.802260: Pseudo dice [np.float32(0.4702)] 
2025-01-16 04:08:08.805284: Epoch time: 41.35 s 
2025-01-16 04:08:09.379532:  
2025-01-16 04:08:09.379532: Epoch 305 
2025-01-16 04:08:09.384545: Current learning rate: 0.00429 
2025-01-16 04:08:50.714290: train_loss -0.8943 
2025-01-16 04:08:50.714792: val_loss -0.3073 
2025-01-16 04:08:50.720357: Pseudo dice [np.float32(0.5852)] 
2025-01-16 04:08:50.724950: Epoch time: 41.34 s 
2025-01-16 04:08:51.297898:  
2025-01-16 04:08:51.297898: Epoch 306 
2025-01-16 04:08:51.304446: Current learning rate: 0.00427 
2025-01-16 04:09:32.641486: train_loss -0.9127 
2025-01-16 04:09:32.642491: val_loss -0.2801 
2025-01-16 04:09:32.647555: Pseudo dice [np.float32(0.5745)] 
2025-01-16 04:09:32.651592: Epoch time: 41.34 s 
2025-01-16 04:09:33.226516:  
2025-01-16 04:09:33.226516: Epoch 307 
2025-01-16 04:09:33.232059: Current learning rate: 0.00425 
2025-01-16 04:10:14.566263: train_loss -0.919 
2025-01-16 04:10:14.566770: val_loss -0.2418 
2025-01-16 04:10:14.572296: Pseudo dice [np.float32(0.4934)] 
2025-01-16 04:10:14.575806: Epoch time: 41.34 s 
2025-01-16 04:10:15.296783:  
2025-01-16 04:10:15.297780: Epoch 308 
2025-01-16 04:10:15.303356: Current learning rate: 0.00423 
2025-01-16 04:10:56.636734: train_loss -0.9228 
2025-01-16 04:10:56.637238: val_loss -0.3592 
2025-01-16 04:10:56.643386: Pseudo dice [np.float32(0.6248)] 
2025-01-16 04:10:56.647510: Epoch time: 41.34 s 
2025-01-16 04:10:57.222676:  
2025-01-16 04:10:57.222676: Epoch 309 
2025-01-16 04:10:57.228813: Current learning rate: 0.00421 
2025-01-16 04:11:38.568819: train_loss -0.9212 
2025-01-16 04:11:38.568819: val_loss -0.3779 
2025-01-16 04:11:38.574932: Pseudo dice [np.float32(0.5793)] 
2025-01-16 04:11:38.579087: Epoch time: 41.35 s 
2025-01-16 04:11:39.159529:  
2025-01-16 04:11:39.161039: Epoch 310 
2025-01-16 04:11:39.166605: Current learning rate: 0.00419 
2025-01-16 04:12:20.482093: train_loss -0.9082 
2025-01-16 04:12:20.483097: val_loss -0.1976 
2025-01-16 04:12:20.490620: Pseudo dice [np.float32(0.4176)] 
2025-01-16 04:12:20.494127: Epoch time: 41.32 s 
2025-01-16 04:12:21.072727:  
2025-01-16 04:12:21.072727: Epoch 311 
2025-01-16 04:12:21.078742: Current learning rate: 0.00417 
2025-01-16 04:13:02.406415: train_loss -0.917 
2025-01-16 04:13:02.407415: val_loss -0.3196 
2025-01-16 04:13:02.413934: Pseudo dice [np.float32(0.5459)] 
2025-01-16 04:13:02.417442: Epoch time: 41.33 s 
2025-01-16 04:13:02.990853:  
2025-01-16 04:13:02.990853: Epoch 312 
2025-01-16 04:13:02.996871: Current learning rate: 0.00415 
2025-01-16 04:13:44.330456: train_loss -0.907 
2025-01-16 04:13:44.330959: val_loss -0.2088 
2025-01-16 04:13:44.336494: Pseudo dice [np.float32(0.4446)] 
2025-01-16 04:13:44.341103: Epoch time: 41.34 s 
2025-01-16 04:13:44.913520:  
2025-01-16 04:13:44.913520: Epoch 313 
2025-01-16 04:13:44.919536: Current learning rate: 0.00413 
2025-01-16 04:14:26.281460: train_loss -0.9101 
2025-01-16 04:14:26.286508: val_loss -0.2625 
2025-01-16 04:14:26.292062: Pseudo dice [np.float32(0.5718)] 
2025-01-16 04:14:26.296073: Epoch time: 41.37 s 
2025-01-16 04:14:26.890289:  
2025-01-16 04:14:26.890791: Epoch 314 
2025-01-16 04:14:26.895805: Current learning rate: 0.00411 
2025-01-16 04:15:08.255010: train_loss -0.9172 
2025-01-16 04:15:08.256010: val_loss -0.2367 
2025-01-16 04:15:08.259528: Pseudo dice [np.float32(0.5199)] 
2025-01-16 04:15:08.264061: Epoch time: 41.37 s 
2025-01-16 04:15:08.855459:  
2025-01-16 04:15:08.855459: Epoch 315 
2025-01-16 04:15:08.860474: Current learning rate: 0.00409 
2025-01-16 04:15:50.224936: train_loss -0.9126 
2025-01-16 04:15:50.225441: val_loss -0.2629 
2025-01-16 04:15:50.230989: Pseudo dice [np.float32(0.456)] 
2025-01-16 04:15:50.234528: Epoch time: 41.37 s 
2025-01-16 04:15:50.973380:  
2025-01-16 04:15:50.974383: Epoch 316 
2025-01-16 04:15:50.978928: Current learning rate: 0.00407 
2025-01-16 04:16:32.310407: train_loss -0.9155 
2025-01-16 04:16:32.311411: val_loss -0.4091 
2025-01-16 04:16:32.317470: Pseudo dice [np.float32(0.658)] 
2025-01-16 04:16:32.320502: Epoch time: 41.34 s 
2025-01-16 04:16:32.898069:  
2025-01-16 04:16:32.898069: Epoch 317 
2025-01-16 04:16:32.904587: Current learning rate: 0.00405 
2025-01-16 04:17:14.282744: train_loss -0.9215 
2025-01-16 04:17:14.283248: val_loss -0.2694 
2025-01-16 04:17:14.289266: Pseudo dice [np.float32(0.5338)] 
2025-01-16 04:17:14.293276: Epoch time: 41.39 s 
2025-01-16 04:17:14.880220:  
2025-01-16 04:17:14.880220: Epoch 318 
2025-01-16 04:17:14.886254: Current learning rate: 0.00403 
2025-01-16 04:17:56.259578: train_loss -0.9077 
2025-01-16 04:17:56.260082: val_loss -0.0968 
2025-01-16 04:17:56.266138: Pseudo dice [np.float32(0.1983)] 
2025-01-16 04:17:56.270147: Epoch time: 41.38 s 
2025-01-16 04:17:56.845811:  
2025-01-16 04:17:56.846810: Epoch 319 
2025-01-16 04:17:56.851891: Current learning rate: 0.00401 
2025-01-16 04:18:38.224603: train_loss -0.9041 
2025-01-16 04:18:38.225633: val_loss -0.3015 
2025-01-16 04:18:38.231757: Pseudo dice [np.float32(0.51)] 
2025-01-16 04:18:38.235299: Epoch time: 41.38 s 
2025-01-16 04:18:38.818842:  
2025-01-16 04:18:38.818842: Epoch 320 
2025-01-16 04:18:38.833539: Current learning rate: 0.00399 
2025-01-16 04:19:20.185694: train_loss -0.9027 
2025-01-16 04:19:20.186226: val_loss -0.3613 
2025-01-16 04:19:20.194877: Pseudo dice [np.float32(0.5922)] 
2025-01-16 04:19:20.199465: Epoch time: 41.37 s 
2025-01-16 04:19:20.778835:  
2025-01-16 04:19:20.779834: Epoch 321 
2025-01-16 04:19:20.784913: Current learning rate: 0.00397 
2025-01-16 04:20:02.144208: train_loss -0.9054 
2025-01-16 04:20:02.145712: val_loss -0.4022 
2025-01-16 04:20:02.151758: Pseudo dice [np.float32(0.6372)] 
2025-01-16 04:20:02.155771: Epoch time: 41.37 s 
2025-01-16 04:20:02.736463:  
2025-01-16 04:20:02.737469: Epoch 322 
2025-01-16 04:20:02.743058: Current learning rate: 0.00395 
2025-01-16 04:20:44.095973: train_loss -0.9012 
2025-01-16 04:20:44.095973: val_loss -0.4088 
2025-01-16 04:20:44.102057: Pseudo dice [np.float32(0.6712)] 
2025-01-16 04:20:44.106105: Epoch time: 41.36 s 
2025-01-16 04:20:44.693977:  
2025-01-16 04:20:44.693977: Epoch 323 
2025-01-16 04:20:44.700104: Current learning rate: 0.00393 
2025-01-16 04:21:26.080724: train_loss -0.9162 
2025-01-16 04:21:26.082228: val_loss -0.327 
2025-01-16 04:21:26.089788: Pseudo dice [np.float32(0.6457)] 
2025-01-16 04:21:26.093296: Epoch time: 41.39 s 
2025-01-16 04:21:26.833441:  
2025-01-16 04:21:26.833441: Epoch 324 
2025-01-16 04:21:26.838451: Current learning rate: 0.00391 
2025-01-16 04:22:08.206457: train_loss -0.916 
2025-01-16 04:22:08.206457: val_loss -0.3447 
2025-01-16 04:22:08.212476: Pseudo dice [np.float32(0.6156)] 
2025-01-16 04:22:08.216484: Epoch time: 41.37 s 
2025-01-16 04:22:08.796148:  
2025-01-16 04:22:08.796148: Epoch 325 
2025-01-16 04:22:08.801704: Current learning rate: 0.00389 
2025-01-16 04:22:50.153403: train_loss -0.9067 
2025-01-16 04:22:50.153403: val_loss -0.2076 
2025-01-16 04:22:50.160471: Pseudo dice [np.float32(0.4612)] 
2025-01-16 04:22:50.163497: Epoch time: 41.36 s 
2025-01-16 04:22:50.753572:  
2025-01-16 04:22:50.754086: Epoch 326 
2025-01-16 04:22:50.759632: Current learning rate: 0.00387 
2025-01-16 04:23:32.116722: train_loss -0.9073 
2025-01-16 04:23:32.117232: val_loss -0.4088 
2025-01-16 04:23:32.123323: Pseudo dice [np.float32(0.6919)] 
2025-01-16 04:23:32.127349: Epoch time: 41.36 s 
2025-01-16 04:23:32.705654:  
2025-01-16 04:23:32.706654: Epoch 327 
2025-01-16 04:23:32.711202: Current learning rate: 0.00385 
2025-01-16 04:24:14.075347: train_loss -0.9212 
2025-01-16 04:24:14.076351: val_loss -0.2785 
2025-01-16 04:24:14.082433: Pseudo dice [np.float32(0.4462)] 
2025-01-16 04:24:14.086474: Epoch time: 41.37 s 
2025-01-16 04:24:14.669430:  
2025-01-16 04:24:14.669430: Epoch 328 
2025-01-16 04:24:14.675443: Current learning rate: 0.00383 
2025-01-16 04:24:56.042420: train_loss -0.9229 
2025-01-16 04:24:56.043427: val_loss -0.3747 
2025-01-16 04:24:56.048976: Pseudo dice [np.float32(0.6386)] 
2025-01-16 04:24:56.053513: Epoch time: 41.37 s 
2025-01-16 04:24:56.627281:  
2025-01-16 04:24:56.627281: Epoch 329 
2025-01-16 04:24:56.633296: Current learning rate: 0.00381 
2025-01-16 04:25:38.001488: train_loss -0.9242 
2025-01-16 04:25:38.001991: val_loss -0.2154 
2025-01-16 04:25:38.008626: Pseudo dice [np.float32(0.4916)] 
2025-01-16 04:25:38.012480: Epoch time: 41.38 s 
2025-01-16 04:25:38.594706:  
2025-01-16 04:25:38.594706: Epoch 330 
2025-01-16 04:25:38.600245: Current learning rate: 0.00379 
2025-01-16 04:26:19.973164: train_loss -0.9249 
2025-01-16 04:26:19.974171: val_loss -0.3044 
2025-01-16 04:26:19.980182: Pseudo dice [np.float32(0.5352)] 
2025-01-16 04:26:19.983191: Epoch time: 41.38 s 
2025-01-16 04:26:20.566314:  
2025-01-16 04:26:20.567318: Epoch 331 
2025-01-16 04:26:20.571868: Current learning rate: 0.00377 
2025-01-16 04:27:01.942480: train_loss -0.9143 
2025-01-16 04:27:01.942480: val_loss -0.2532 
2025-01-16 04:27:01.949049: Pseudo dice [np.float32(0.5515)] 
2025-01-16 04:27:01.952610: Epoch time: 41.38 s 
2025-01-16 04:27:02.682734:  
2025-01-16 04:27:02.682734: Epoch 332 
2025-01-16 04:27:02.688748: Current learning rate: 0.00375 
2025-01-16 04:27:44.057590: train_loss -0.9278 
2025-01-16 04:27:44.057590: val_loss -0.2572 
2025-01-16 04:27:44.064185: Pseudo dice [np.float32(0.4564)] 
2025-01-16 04:27:44.068693: Epoch time: 41.38 s 
2025-01-16 04:27:44.651192:  
2025-01-16 04:27:44.651192: Epoch 333 
2025-01-16 04:27:44.656219: Current learning rate: 0.00373 
2025-01-16 04:28:26.018437: train_loss -0.9303 
2025-01-16 04:28:26.019442: val_loss -0.2272 
2025-01-16 04:28:26.026982: Pseudo dice [np.float32(0.4175)] 
2025-01-16 04:28:26.030990: Epoch time: 41.37 s 
2025-01-16 04:28:26.622657:  
2025-01-16 04:28:26.622657: Epoch 334 
2025-01-16 04:28:26.629246: Current learning rate: 0.00371 
2025-01-16 04:29:07.989938: train_loss -0.9216 
2025-01-16 04:29:07.989938: val_loss -0.0167 
2025-01-16 04:29:07.995810: Pseudo dice [np.float32(0.092)] 
2025-01-16 04:29:07.999851: Epoch time: 41.37 s 
2025-01-16 04:29:08.585811:  
2025-01-16 04:29:08.585811: Epoch 335 
2025-01-16 04:29:08.591330: Current learning rate: 0.00369 
2025-01-16 04:29:49.965134: train_loss -0.9187 
2025-01-16 04:29:49.965636: val_loss -0.2606 
2025-01-16 04:29:49.972232: Pseudo dice [np.float32(0.5308)] 
2025-01-16 04:29:49.976291: Epoch time: 41.38 s 
2025-01-16 04:29:50.574727:  
2025-01-16 04:29:50.575727: Epoch 336 
2025-01-16 04:29:50.581352: Current learning rate: 0.00367 
2025-01-16 04:30:31.944812: train_loss -0.9141 
2025-01-16 04:30:31.945317: val_loss -0.2743 
2025-01-16 04:30:31.952333: Pseudo dice [np.float32(0.5201)] 
2025-01-16 04:30:31.956378: Epoch time: 41.37 s 
2025-01-16 04:30:32.541048:  
2025-01-16 04:30:32.541551: Epoch 337 
2025-01-16 04:30:32.547570: Current learning rate: 0.00365 
2025-01-16 04:31:13.921204: train_loss -0.9213 
2025-01-16 04:31:13.921204: val_loss -0.2554 
2025-01-16 04:31:13.927742: Pseudo dice [np.float32(0.5918)] 
2025-01-16 04:31:13.932075: Epoch time: 41.38 s 
2025-01-16 04:31:14.519335:  
2025-01-16 04:31:14.519335: Epoch 338 
2025-01-16 04:31:14.526460: Current learning rate: 0.00363 
2025-01-16 04:31:55.906533: train_loss -0.9332 
2025-01-16 04:31:55.907036: val_loss -0.3181 
2025-01-16 04:31:55.913167: Pseudo dice [np.float32(0.5702)] 
2025-01-16 04:31:55.917679: Epoch time: 41.39 s 
2025-01-16 04:31:56.503704:  
2025-01-16 04:31:56.504207: Epoch 339 
2025-01-16 04:31:56.510224: Current learning rate: 0.00361 
2025-01-16 04:32:37.870178: train_loss -0.9317 
2025-01-16 04:32:37.870178: val_loss -0.1857 
2025-01-16 04:32:37.876693: Pseudo dice [np.float32(0.3792)] 
2025-01-16 04:32:37.881206: Epoch time: 41.37 s 
2025-01-16 04:32:38.623384:  
2025-01-16 04:32:38.624384: Epoch 340 
2025-01-16 04:32:38.630019: Current learning rate: 0.00359 
2025-01-16 04:33:19.995410: train_loss -0.9172 
2025-01-16 04:33:19.996923: val_loss -0.2845 
2025-01-16 04:33:20.003097: Pseudo dice [np.float32(0.5461)] 
2025-01-16 04:33:20.007680: Epoch time: 41.37 s 
2025-01-16 04:33:20.596096:  
2025-01-16 04:33:20.597095: Epoch 341 
2025-01-16 04:33:20.602698: Current learning rate: 0.00357 
2025-01-16 04:34:01.959731: train_loss -0.9284 
2025-01-16 04:34:01.960731: val_loss -0.356 
2025-01-16 04:34:01.967254: Pseudo dice [np.float32(0.5882)] 
2025-01-16 04:34:01.971265: Epoch time: 41.36 s 
2025-01-16 04:34:02.563522:  
2025-01-16 04:34:02.564526: Epoch 342 
2025-01-16 04:34:02.570609: Current learning rate: 0.00355 
2025-01-16 04:34:43.945226: train_loss -0.9202 
2025-01-16 04:34:43.946230: val_loss -0.3134 
2025-01-16 04:34:43.952833: Pseudo dice [np.float32(0.4915)] 
2025-01-16 04:34:43.956429: Epoch time: 41.38 s 
2025-01-16 04:34:44.541996:  
2025-01-16 04:34:44.541996: Epoch 343 
2025-01-16 04:34:44.548599: Current learning rate: 0.00353 
2025-01-16 04:35:25.922318: train_loss -0.9244 
2025-01-16 04:35:25.922318: val_loss -0.3405 
2025-01-16 04:35:25.929360: Pseudo dice [np.float32(0.5547)] 
2025-01-16 04:35:25.933397: Epoch time: 41.38 s 
2025-01-16 04:35:26.518069:  
2025-01-16 04:35:26.518069: Epoch 344 
2025-01-16 04:35:26.526112: Current learning rate: 0.00351 
2025-01-16 04:36:07.894319: train_loss -0.9341 
2025-01-16 04:36:07.895823: val_loss -0.2939 
2025-01-16 04:36:07.900901: Pseudo dice [np.float32(0.5124)] 
2025-01-16 04:36:07.905913: Epoch time: 41.38 s 
2025-01-16 04:36:08.504455:  
2025-01-16 04:36:08.504958: Epoch 345 
2025-01-16 04:36:08.510972: Current learning rate: 0.00349 
2025-01-16 04:36:49.861705: train_loss -0.9338 
2025-01-16 04:36:49.861705: val_loss -0.0721 
2025-01-16 04:36:49.870225: Pseudo dice [np.float32(0.1933)] 
2025-01-16 04:36:49.875249: Epoch time: 41.36 s 
2025-01-16 04:36:50.462086:  
2025-01-16 04:36:50.462086: Epoch 346 
2025-01-16 04:36:50.469153: Current learning rate: 0.00346 
2025-01-16 04:37:31.834027: train_loss -0.9241 
2025-01-16 04:37:31.834027: val_loss -0.1775 
2025-01-16 04:37:31.840591: Pseudo dice [np.float32(0.3171)] 
2025-01-16 04:37:31.844178: Epoch time: 41.37 s 
2025-01-16 04:37:32.435645:  
2025-01-16 04:37:32.436147: Epoch 347 
2025-01-16 04:37:32.442173: Current learning rate: 0.00344 
2025-01-16 04:38:13.804240: train_loss -0.9222 
2025-01-16 04:38:13.804742: val_loss -0.1746 
2025-01-16 04:38:13.810320: Pseudo dice [np.float32(0.3645)] 
2025-01-16 04:38:13.814346: Epoch time: 41.37 s 
2025-01-16 04:38:14.560744:  
2025-01-16 04:38:14.561743: Epoch 348 
2025-01-16 04:38:14.567364: Current learning rate: 0.00342 
2025-01-16 04:38:55.924784: train_loss -0.9194 
2025-01-16 04:38:55.924784: val_loss -0.1704 
2025-01-16 04:38:55.929888: Pseudo dice [np.float32(0.4112)] 
2025-01-16 04:38:55.934978: Epoch time: 41.36 s 
2025-01-16 04:38:56.527091:  
2025-01-16 04:38:56.528091: Epoch 349 
2025-01-16 04:38:56.533675: Current learning rate: 0.0034 
2025-01-16 04:39:37.868686: train_loss -0.9241 
2025-01-16 04:39:37.869188: val_loss -0.212 
2025-01-16 04:39:37.876242: Pseudo dice [np.float32(0.4727)] 
2025-01-16 04:39:37.880828: Epoch time: 41.34 s 
2025-01-16 04:39:38.671027:  
2025-01-16 04:39:38.671027: Epoch 350 
2025-01-16 04:39:38.677551: Current learning rate: 0.00338 
2025-01-16 04:40:20.023778: train_loss -0.9314 
2025-01-16 04:40:20.024280: val_loss -0.1954 
2025-01-16 04:40:20.031385: Pseudo dice [np.float32(0.4197)] 
2025-01-16 04:40:20.035943: Epoch time: 41.35 s 
2025-01-16 04:40:20.627625:  
2025-01-16 04:40:20.627625: Epoch 351 
2025-01-16 04:40:20.633640: Current learning rate: 0.00336 
2025-01-16 04:41:01.984869: train_loss -0.9286 
2025-01-16 04:41:01.985379: val_loss -0.3614 
2025-01-16 04:41:01.991943: Pseudo dice [np.float32(0.5623)] 
2025-01-16 04:41:01.995996: Epoch time: 41.36 s 
2025-01-16 04:41:02.584140:  
2025-01-16 04:41:02.584140: Epoch 352 
2025-01-16 04:41:02.589151: Current learning rate: 0.00334 
2025-01-16 04:41:43.963869: train_loss -0.9355 
2025-01-16 04:41:43.964876: val_loss -0.3675 
2025-01-16 04:41:43.971387: Pseudo dice [np.float32(0.5712)] 
2025-01-16 04:41:43.974896: Epoch time: 41.38 s 
2025-01-16 04:41:44.557987:  
2025-01-16 04:41:44.558490: Epoch 353 
2025-01-16 04:41:44.564505: Current learning rate: 0.00332 
2025-01-16 04:42:25.947808: train_loss -0.94 
2025-01-16 04:42:25.947808: val_loss -0.2836 
2025-01-16 04:42:25.955330: Pseudo dice [np.float32(0.5662)] 
2025-01-16 04:42:25.958838: Epoch time: 41.39 s 
2025-01-16 04:42:26.556272:  
2025-01-16 04:42:26.556272: Epoch 354 
2025-01-16 04:42:26.561871: Current learning rate: 0.0033 
2025-01-16 04:43:07.930621: train_loss -0.9387 
2025-01-16 04:43:07.931626: val_loss -0.2694 
2025-01-16 04:43:07.937636: Pseudo dice [np.float32(0.5692)] 
2025-01-16 04:43:07.942434: Epoch time: 41.37 s 
2025-01-16 04:43:08.536014:  
2025-01-16 04:43:08.536014: Epoch 355 
2025-01-16 04:43:08.542057: Current learning rate: 0.00328 
2025-01-16 04:43:49.895169: train_loss -0.9393 
2025-01-16 04:43:49.896174: val_loss -0.2737 
2025-01-16 04:43:49.903233: Pseudo dice [np.float32(0.543)] 
2025-01-16 04:43:49.907269: Epoch time: 41.36 s 
2025-01-16 04:43:50.648148:  
2025-01-16 04:43:50.648148: Epoch 356 
2025-01-16 04:43:50.654165: Current learning rate: 0.00326 
2025-01-16 04:44:31.988949: train_loss -0.9385 
2025-01-16 04:44:31.989454: val_loss -0.2816 
2025-01-16 04:44:31.995470: Pseudo dice [np.float32(0.4969)] 
2025-01-16 04:44:31.999477: Epoch time: 41.34 s 
2025-01-16 04:44:32.589008:  
2025-01-16 04:44:32.589511: Epoch 357 
2025-01-16 04:44:32.594522: Current learning rate: 0.00324 
2025-01-16 04:45:13.949537: train_loss -0.934 
2025-01-16 04:45:13.950541: val_loss -0.2878 
2025-01-16 04:45:13.956721: Pseudo dice [np.float32(0.4953)] 
2025-01-16 04:45:13.960876: Epoch time: 41.36 s 
2025-01-16 04:45:14.554464:  
2025-01-16 04:45:14.555468: Epoch 358 
2025-01-16 04:45:14.562057: Current learning rate: 0.00322 
2025-01-16 04:45:55.905607: train_loss -0.9361 
2025-01-16 04:45:55.906613: val_loss -0.2107 
2025-01-16 04:45:55.912701: Pseudo dice [np.float32(0.4665)] 
2025-01-16 04:45:55.916264: Epoch time: 41.35 s 
2025-01-16 04:45:56.511530:  
2025-01-16 04:45:56.512534: Epoch 359 
2025-01-16 04:45:56.518667: Current learning rate: 0.0032 
2025-01-16 04:46:37.864133: train_loss -0.9292 
2025-01-16 04:46:37.864133: val_loss -0.2078 
2025-01-16 04:46:37.871164: Pseudo dice [np.float32(0.4194)] 
2025-01-16 04:46:37.875700: Epoch time: 41.35 s 
2025-01-16 04:46:38.470376:  
2025-01-16 04:46:38.470376: Epoch 360 
2025-01-16 04:46:38.476438: Current learning rate: 0.00318 
2025-01-16 04:47:19.830942: train_loss -0.9288 
2025-01-16 04:47:19.831948: val_loss -0.1875 
2025-01-16 04:47:19.838464: Pseudo dice [np.float32(0.492)] 
2025-01-16 04:47:19.841973: Epoch time: 41.36 s 
2025-01-16 04:47:20.442615:  
2025-01-16 04:47:20.443617: Epoch 361 
2025-01-16 04:47:20.450135: Current learning rate: 0.00316 
2025-01-16 04:48:01.808648: train_loss -0.9273 
2025-01-16 04:48:01.809159: val_loss -0.3257 
2025-01-16 04:48:01.816237: Pseudo dice [np.float32(0.5069)] 
2025-01-16 04:48:01.821397: Epoch time: 41.37 s 
2025-01-16 04:48:02.417557:  
2025-01-16 04:48:02.418066: Epoch 362 
2025-01-16 04:48:02.423632: Current learning rate: 0.00314 
2025-01-16 04:48:43.784339: train_loss -0.9212 
2025-01-16 04:48:43.785338: val_loss -0.2241 
2025-01-16 04:48:43.792406: Pseudo dice [np.float32(0.487)] 
2025-01-16 04:48:43.797014: Epoch time: 41.37 s 
2025-01-16 04:48:44.389400:  
2025-01-16 04:48:44.389904: Epoch 363 
2025-01-16 04:48:44.395919: Current learning rate: 0.00312 
2025-01-16 04:49:25.763515: train_loss -0.934 
2025-01-16 04:49:25.763515: val_loss -0.3105 
2025-01-16 04:49:25.770556: Pseudo dice [np.float32(0.5811)] 
2025-01-16 04:49:25.774587: Epoch time: 41.38 s 
2025-01-16 04:49:26.518816:  
2025-01-16 04:49:26.518816: Epoch 364 
2025-01-16 04:49:26.525904: Current learning rate: 0.0031 
2025-01-16 04:50:07.907165: train_loss -0.9324 
2025-01-16 04:50:07.907165: val_loss -0.3137 
2025-01-16 04:50:07.913681: Pseudo dice [np.float32(0.5915)] 
2025-01-16 04:50:07.918692: Epoch time: 41.39 s 
2025-01-16 04:50:08.513938:  
2025-01-16 04:50:08.514942: Epoch 365 
2025-01-16 04:50:08.525020: Current learning rate: 0.00308 
2025-01-16 04:50:49.895511: train_loss -0.9308 
2025-01-16 04:50:49.896020: val_loss -0.1731 
2025-01-16 04:50:49.903078: Pseudo dice [np.float32(0.4373)] 
2025-01-16 04:50:49.907122: Epoch time: 41.38 s 
2025-01-16 04:50:50.498868:  
2025-01-16 04:50:50.498868: Epoch 366 
2025-01-16 04:50:50.505434: Current learning rate: 0.00306 
2025-01-16 04:51:31.863825: train_loss -0.9241 
2025-01-16 04:51:31.864373: val_loss -0.3149 
2025-01-16 04:51:31.869946: Pseudo dice [np.float32(0.5512)] 
2025-01-16 04:51:31.873953: Epoch time: 41.37 s 
2025-01-16 04:51:32.472511:  
2025-01-16 04:51:32.472511: Epoch 367 
2025-01-16 04:51:32.478054: Current learning rate: 0.00304 
2025-01-16 04:52:13.835370: train_loss -0.9257 
2025-01-16 04:52:13.835370: val_loss -0.2942 
2025-01-16 04:52:13.843011: Pseudo dice [np.float32(0.4921)] 
2025-01-16 04:52:13.853107: Epoch time: 41.36 s 
2025-01-16 04:52:14.453219:  
2025-01-16 04:52:14.453723: Epoch 368 
2025-01-16 04:52:14.459737: Current learning rate: 0.00302 
2025-01-16 04:52:55.822811: train_loss -0.9268 
2025-01-16 04:52:55.823818: val_loss -0.3457 
2025-01-16 04:52:55.830453: Pseudo dice [np.float32(0.6099)] 
2025-01-16 04:52:55.834989: Epoch time: 41.37 s 
2025-01-16 04:52:56.436175:  
2025-01-16 04:52:56.436175: Epoch 369 
2025-01-16 04:52:56.443287: Current learning rate: 0.003 
2025-01-16 04:53:37.813279: train_loss -0.9346 
2025-01-16 04:53:37.813791: val_loss -0.3602 
2025-01-16 04:53:37.821408: Pseudo dice [np.float32(0.5427)] 
2025-01-16 04:53:37.825005: Epoch time: 41.38 s 
2025-01-16 04:53:38.420436:  
2025-01-16 04:53:38.421440: Epoch 370 
2025-01-16 04:53:38.427470: Current learning rate: 0.00297 
2025-01-16 04:54:19.802715: train_loss -0.929 
2025-01-16 04:54:19.802715: val_loss -0.3085 
2025-01-16 04:54:19.808784: Pseudo dice [np.float32(0.4955)] 
2025-01-16 04:54:19.813795: Epoch time: 41.38 s 
2025-01-16 04:54:20.414810:  
2025-01-16 04:54:20.414810: Epoch 371 
2025-01-16 04:54:20.421361: Current learning rate: 0.00295 
2025-01-16 04:55:01.799963: train_loss -0.9295 
2025-01-16 04:55:01.800482: val_loss -0.3437 
2025-01-16 04:55:01.807018: Pseudo dice [np.float32(0.5376)] 
2025-01-16 04:55:01.817043: Epoch time: 41.39 s 
2025-01-16 04:55:02.561800:  
2025-01-16 04:55:02.561800: Epoch 372 
2025-01-16 04:55:02.567344: Current learning rate: 0.00293 
2025-01-16 04:55:43.952895: train_loss -0.9364 
2025-01-16 04:55:43.953409: val_loss -0.2446 
2025-01-16 04:55:43.959487: Pseudo dice [np.float32(0.4539)] 
2025-01-16 04:55:43.963029: Epoch time: 41.39 s 
2025-01-16 04:55:44.571110:  
2025-01-16 04:55:44.571110: Epoch 373 
2025-01-16 04:55:44.577721: Current learning rate: 0.00291 
2025-01-16 04:56:25.929385: train_loss -0.9376 
2025-01-16 04:56:25.929902: val_loss -0.1463 
2025-01-16 04:56:25.935970: Pseudo dice [np.float32(0.3568)] 
2025-01-16 04:56:25.940562: Epoch time: 41.36 s 
2025-01-16 04:56:26.536814:  
2025-01-16 04:56:26.537814: Epoch 374 
2025-01-16 04:56:26.543332: Current learning rate: 0.00289 
2025-01-16 04:57:07.906500: train_loss -0.9408 
2025-01-16 04:57:07.907003: val_loss -0.3098 
2025-01-16 04:57:07.912603: Pseudo dice [np.float32(0.5446)] 
2025-01-16 04:57:07.917132: Epoch time: 41.37 s 
2025-01-16 04:57:08.509887:  
2025-01-16 04:57:08.510890: Epoch 375 
2025-01-16 04:57:08.516975: Current learning rate: 0.00287 
2025-01-16 04:57:49.868682: train_loss -0.9367 
2025-01-16 04:57:49.869686: val_loss -0.2775 
2025-01-16 04:57:49.876245: Pseudo dice [np.float32(0.4586)] 
2025-01-16 04:57:49.880774: Epoch time: 41.36 s 
2025-01-16 04:57:50.473170:  
2025-01-16 04:57:50.473682: Epoch 376 
2025-01-16 04:57:50.481848: Current learning rate: 0.00285 
2025-01-16 04:58:31.845449: train_loss -0.9364 
2025-01-16 04:58:31.845449: val_loss -0.3119 
2025-01-16 04:58:31.852489: Pseudo dice [np.float32(0.5508)] 
2025-01-16 04:58:31.860538: Epoch time: 41.37 s 
2025-01-16 04:58:32.458095:  
2025-01-16 04:58:32.458095: Epoch 377 
2025-01-16 04:58:32.465774: Current learning rate: 0.00283 
2025-01-16 04:59:13.826675: train_loss -0.9417 
2025-01-16 04:59:13.827678: val_loss -0.2493 
2025-01-16 04:59:13.840725: Pseudo dice [np.float32(0.4195)] 
2025-01-16 04:59:13.845238: Epoch time: 41.37 s 
2025-01-16 04:59:14.440791:  
2025-01-16 04:59:14.440791: Epoch 378 
2025-01-16 04:59:14.447383: Current learning rate: 0.00281 
2025-01-16 04:59:55.817903: train_loss -0.9376 
2025-01-16 04:59:55.818406: val_loss -0.3627 
2025-01-16 04:59:55.825020: Pseudo dice [np.float32(0.5138)] 
2025-01-16 04:59:55.836117: Epoch time: 41.38 s 
2025-01-16 04:59:56.429948:  
2025-01-16 04:59:56.430951: Epoch 379 
2025-01-16 04:59:56.437005: Current learning rate: 0.00279 
2025-01-16 05:00:37.805055: train_loss -0.9367 
2025-01-16 05:00:37.806081: val_loss -0.1708 
2025-01-16 05:00:37.812709: Pseudo dice [np.float32(0.3364)] 
2025-01-16 05:00:37.817255: Epoch time: 41.38 s 
2025-01-16 05:00:38.559721:  
2025-01-16 05:00:38.560229: Epoch 380 
2025-01-16 05:00:38.565795: Current learning rate: 0.00277 
2025-01-16 05:01:19.921014: train_loss -0.9392 
2025-01-16 05:01:19.921530: val_loss -0.4065 
2025-01-16 05:01:19.928603: Pseudo dice [np.float32(0.5403)] 
2025-01-16 05:01:19.932146: Epoch time: 41.36 s 
2025-01-16 05:01:20.531334:  
2025-01-16 05:01:20.532334: Epoch 381 
2025-01-16 05:01:20.537919: Current learning rate: 0.00275 
2025-01-16 05:02:01.895743: train_loss -0.9418 
2025-01-16 05:02:01.895743: val_loss -0.2161 
2025-01-16 05:02:01.901322: Pseudo dice [np.float32(0.432)] 
2025-01-16 05:02:01.905899: Epoch time: 41.36 s 
2025-01-16 05:02:02.505775:  
2025-01-16 05:02:02.506778: Epoch 382 
2025-01-16 05:02:02.511395: Current learning rate: 0.00273 
2025-01-16 05:02:43.869490: train_loss -0.9391 
2025-01-16 05:02:43.869993: val_loss -0.2342 
2025-01-16 05:02:43.875538: Pseudo dice [np.float32(0.4745)] 
2025-01-16 05:02:43.882575: Epoch time: 41.36 s 
2025-01-16 05:02:44.488891:  
2025-01-16 05:02:44.488891: Epoch 383 
2025-01-16 05:02:44.495517: Current learning rate: 0.00271 
2025-01-16 05:03:25.821262: train_loss -0.9445 
2025-01-16 05:03:25.821776: val_loss -0.2554 
2025-01-16 05:03:25.828344: Pseudo dice [np.float32(0.4593)] 
2025-01-16 05:03:25.831925: Epoch time: 41.33 s 
2025-01-16 05:03:26.432216:  
2025-01-16 05:03:26.432216: Epoch 384 
2025-01-16 05:03:26.442302: Current learning rate: 0.00268 
2025-01-16 05:04:07.768526: train_loss -0.9446 
2025-01-16 05:04:07.769030: val_loss -0.3202 
2025-01-16 05:04:07.775643: Pseudo dice [np.float32(0.5386)] 
2025-01-16 05:04:07.779680: Epoch time: 41.34 s 
2025-01-16 05:04:08.383205:  
2025-01-16 05:04:08.383718: Epoch 385 
2025-01-16 05:04:08.389355: Current learning rate: 0.00266 
2025-01-16 05:04:49.730102: train_loss -0.9452 
2025-01-16 05:04:49.730612: val_loss -0.3455 
2025-01-16 05:04:49.737766: Pseudo dice [np.float32(0.5541)] 
2025-01-16 05:04:49.741800: Epoch time: 41.35 s 
2025-01-16 05:04:50.349506:  
2025-01-16 05:04:50.349506: Epoch 386 
2025-01-16 05:04:50.358585: Current learning rate: 0.00264 
2025-01-16 05:05:31.712961: train_loss -0.9444 
2025-01-16 05:05:31.713966: val_loss -0.2476 
2025-01-16 05:05:31.719015: Pseudo dice [np.float32(0.5051)] 
2025-01-16 05:05:31.723549: Epoch time: 41.36 s 
2025-01-16 05:05:32.327214:  
2025-01-16 05:05:32.328213: Epoch 387 
2025-01-16 05:05:32.333801: Current learning rate: 0.00262 
2025-01-16 05:06:13.702319: train_loss -0.9438 
2025-01-16 05:06:13.702821: val_loss -0.1312 
2025-01-16 05:06:13.713536: Pseudo dice [np.float32(0.3106)] 
2025-01-16 05:06:13.723080: Epoch time: 41.38 s 
2025-01-16 05:06:14.323160:  
2025-01-16 05:06:14.324159: Epoch 388 
2025-01-16 05:06:14.329838: Current learning rate: 0.0026 
2025-01-16 05:06:55.663117: train_loss -0.943 
2025-01-16 05:06:55.664117: val_loss -0.1707 
2025-01-16 05:06:55.670149: Pseudo dice [np.float32(0.3875)] 
2025-01-16 05:06:55.675678: Epoch time: 41.34 s 
2025-01-16 05:06:56.279834:  
2025-01-16 05:06:56.279834: Epoch 389 
2025-01-16 05:06:56.284845: Current learning rate: 0.00258 
2025-01-16 05:07:37.618429: train_loss -0.943 
2025-01-16 05:07:37.619429: val_loss -0.2129 
2025-01-16 05:07:37.625476: Pseudo dice [np.float32(0.4012)] 
2025-01-16 05:07:37.630004: Epoch time: 41.34 s 
2025-01-16 05:07:38.233586:  
2025-01-16 05:07:38.233586: Epoch 390 
2025-01-16 05:07:38.239600: Current learning rate: 0.00256 
2025-01-16 05:08:19.583458: train_loss -0.9448 
2025-01-16 05:08:19.584461: val_loss -0.093 
2025-01-16 05:08:19.591055: Pseudo dice [np.float32(0.3334)] 
2025-01-16 05:08:19.604586: Epoch time: 41.35 s 
2025-01-16 05:08:20.217882:  
2025-01-16 05:08:20.218384: Epoch 391 
2025-01-16 05:08:20.224938: Current learning rate: 0.00254 
2025-01-16 05:09:01.574482: train_loss -0.9346 
2025-01-16 05:09:01.574482: val_loss -0.2441 
2025-01-16 05:09:01.581527: Pseudo dice [np.float32(0.5243)] 
2025-01-16 05:09:01.585537: Epoch time: 41.36 s 
2025-01-16 05:09:02.189618:  
2025-01-16 05:09:02.189618: Epoch 392 
2025-01-16 05:09:02.196162: Current learning rate: 0.00252 
2025-01-16 05:09:43.539838: train_loss -0.9391 
2025-01-16 05:09:43.540841: val_loss -0.2753 
2025-01-16 05:09:43.547411: Pseudo dice [np.float32(0.4828)] 
2025-01-16 05:09:43.553468: Epoch time: 41.35 s 
2025-01-16 05:09:44.153424:  
2025-01-16 05:09:44.153424: Epoch 393 
2025-01-16 05:09:44.160077: Current learning rate: 0.0025 
2025-01-16 05:10:25.499326: train_loss -0.9455 
2025-01-16 05:10:25.499829: val_loss -0.2093 
2025-01-16 05:10:25.504875: Pseudo dice [np.float32(0.406)] 
2025-01-16 05:10:25.508923: Epoch time: 41.35 s 
2025-01-16 05:10:26.118336:  
2025-01-16 05:10:26.118336: Epoch 394 
2025-01-16 05:10:26.129016: Current learning rate: 0.00248 
2025-01-16 05:11:07.474743: train_loss -0.9479 
2025-01-16 05:11:07.475245: val_loss -0.2999 
2025-01-16 05:11:07.485332: Pseudo dice [np.float32(0.5361)] 
2025-01-16 05:11:07.488866: Epoch time: 41.36 s 
2025-01-16 05:11:08.239129:  
2025-01-16 05:11:08.239635: Epoch 395 
2025-01-16 05:11:08.245672: Current learning rate: 0.00245 
2025-01-16 05:11:49.600667: train_loss -0.9341 
2025-01-16 05:11:49.601667: val_loss -0.2977 
2025-01-16 05:11:49.610690: Pseudo dice [np.float32(0.5492)] 
2025-01-16 05:11:49.614698: Epoch time: 41.36 s 
2025-01-16 05:11:50.212255:  
2025-01-16 05:11:50.213259: Epoch 396 
2025-01-16 05:11:50.219339: Current learning rate: 0.00243 
2025-01-16 05:12:31.562413: train_loss -0.9391 
2025-01-16 05:12:31.563417: val_loss -0.2705 
2025-01-16 05:12:31.570536: Pseudo dice [np.float32(0.5295)] 
2025-01-16 05:12:31.575088: Epoch time: 41.35 s 
2025-01-16 05:12:32.179660:  
2025-01-16 05:12:32.180660: Epoch 397 
2025-01-16 05:12:32.186247: Current learning rate: 0.00241 
2025-01-16 05:13:13.522490: train_loss -0.9317 
2025-01-16 05:13:13.523512: val_loss -0.3757 
2025-01-16 05:13:13.529095: Pseudo dice [np.float32(0.5936)] 
2025-01-16 05:13:13.533157: Epoch time: 41.34 s 
2025-01-16 05:13:14.134620:  
2025-01-16 05:13:14.135620: Epoch 398 
2025-01-16 05:13:14.140726: Current learning rate: 0.00239 
2025-01-16 05:13:55.484007: train_loss -0.9329 
2025-01-16 05:13:55.484509: val_loss -0.3035 
2025-01-16 05:13:55.494030: Pseudo dice [np.float32(0.5542)] 
2025-01-16 05:13:55.498040: Epoch time: 41.35 s 
2025-01-16 05:13:56.102520:  
2025-01-16 05:13:56.103523: Epoch 399 
2025-01-16 05:13:56.109620: Current learning rate: 0.00237 
2025-01-16 05:14:37.460074: train_loss -0.9426 
2025-01-16 05:14:37.460581: val_loss -0.2356 
2025-01-16 05:14:37.467707: Pseudo dice [np.float32(0.4407)] 
2025-01-16 05:14:37.475307: Epoch time: 41.36 s 
2025-01-16 05:14:38.316195:  
2025-01-16 05:14:38.317199: Epoch 400 
2025-01-16 05:14:38.323761: Current learning rate: 0.00235 
2025-01-16 05:15:19.693868: train_loss -0.9386 
2025-01-16 05:15:19.694868: val_loss -0.2422 
2025-01-16 05:15:19.701389: Pseudo dice [np.float32(0.5185)] 
2025-01-16 05:15:19.705397: Epoch time: 41.38 s 
2025-01-16 05:15:20.316462:  
2025-01-16 05:15:20.316462: Epoch 401 
2025-01-16 05:15:20.323563: Current learning rate: 0.00233 
2025-01-16 05:16:01.688756: train_loss -0.9444 
2025-01-16 05:16:01.688756: val_loss -0.3292 
2025-01-16 05:16:01.699370: Pseudo dice [np.float32(0.5935)] 
2025-01-16 05:16:01.703933: Epoch time: 41.37 s 
2025-01-16 05:16:02.369270:  
2025-01-16 05:16:02.369270: Epoch 402 
2025-01-16 05:16:02.375823: Current learning rate: 0.00231 
2025-01-16 05:16:43.735316: train_loss -0.9405 
2025-01-16 05:16:43.736318: val_loss -0.3886 
2025-01-16 05:16:43.742890: Pseudo dice [np.float32(0.5444)] 
2025-01-16 05:16:43.746917: Epoch time: 41.37 s 
2025-01-16 05:16:44.506115:  
2025-01-16 05:16:44.506115: Epoch 403 
2025-01-16 05:16:44.513154: Current learning rate: 0.00229 
2025-01-16 05:17:25.870713: train_loss -0.9333 
2025-01-16 05:17:25.871228: val_loss -0.1757 
2025-01-16 05:17:25.877343: Pseudo dice [np.float32(0.3831)] 
2025-01-16 05:17:25.881383: Epoch time: 41.37 s 
2025-01-16 05:17:26.489326:  
2025-01-16 05:17:26.489829: Epoch 404 
2025-01-16 05:17:26.495842: Current learning rate: 0.00226 
2025-01-16 05:18:07.860036: train_loss -0.9444 
2025-01-16 05:18:07.861039: val_loss -0.2007 
2025-01-16 05:18:07.867553: Pseudo dice [np.float32(0.4546)] 
2025-01-16 05:18:07.887597: Epoch time: 41.37 s 
2025-01-16 05:18:08.489538:  
2025-01-16 05:18:08.489538: Epoch 405 
2025-01-16 05:18:08.496099: Current learning rate: 0.00224 
2025-01-16 05:18:49.843347: train_loss -0.946 
2025-01-16 05:18:49.843347: val_loss -0.3507 
2025-01-16 05:18:49.850901: Pseudo dice [np.float32(0.5872)] 
2025-01-16 05:18:49.854910: Epoch time: 41.35 s 
2025-01-16 05:18:50.465676:  
2025-01-16 05:18:50.465676: Epoch 406 
2025-01-16 05:18:50.472325: Current learning rate: 0.00222 
2025-01-16 05:19:31.819505: train_loss -0.9435 
2025-01-16 05:19:31.820505: val_loss -0.1886 
2025-01-16 05:19:31.830664: Pseudo dice [np.float32(0.416)] 
2025-01-16 05:19:31.840837: Epoch time: 41.35 s 
2025-01-16 05:19:32.441374:  
2025-01-16 05:19:32.441882: Epoch 407 
2025-01-16 05:19:32.446923: Current learning rate: 0.0022 
2025-01-16 05:20:13.819720: train_loss -0.9427 
2025-01-16 05:20:13.819720: val_loss -0.198 
2025-01-16 05:20:13.827835: Pseudo dice [np.float32(0.5249)] 
2025-01-16 05:20:13.833874: Epoch time: 41.38 s 
2025-01-16 05:20:14.440856:  
2025-01-16 05:20:14.440856: Epoch 408 
2025-01-16 05:20:14.446413: Current learning rate: 0.00218 
2025-01-16 05:20:55.800556: train_loss -0.9445 
2025-01-16 05:20:55.801058: val_loss -0.1901 
2025-01-16 05:20:55.808575: Pseudo dice [np.float32(0.516)] 
2025-01-16 05:20:55.812084: Epoch time: 41.36 s 
2025-01-16 05:20:56.418430:  
2025-01-16 05:20:56.419430: Epoch 409 
2025-01-16 05:20:56.425017: Current learning rate: 0.00216 
2025-01-16 05:21:37.781200: train_loss -0.9469 
2025-01-16 05:21:37.782203: val_loss -0.3204 
2025-01-16 05:21:37.788718: Pseudo dice [np.float32(0.5693)] 
2025-01-16 05:21:37.792227: Epoch time: 41.36 s 
2025-01-16 05:21:38.406282:  
2025-01-16 05:21:38.406282: Epoch 410 
2025-01-16 05:21:38.413393: Current learning rate: 0.00214 
2025-01-16 05:22:19.754751: train_loss -0.9387 
2025-01-16 05:22:19.754751: val_loss -0.2291 
2025-01-16 05:22:19.761334: Pseudo dice [np.float32(0.4939)] 
2025-01-16 05:22:19.765923: Epoch time: 41.35 s 
2025-01-16 05:22:20.491703:  
2025-01-16 05:22:20.492206: Epoch 411 
2025-01-16 05:22:20.498224: Current learning rate: 0.00212 
2025-01-16 05:23:01.851688: train_loss -0.9466 
2025-01-16 05:23:01.851688: val_loss -0.1219 
2025-01-16 05:23:01.862738: Pseudo dice [np.float32(0.3495)] 
2025-01-16 05:23:01.866767: Epoch time: 41.36 s 
2025-01-16 05:23:02.440645:  
2025-01-16 05:23:02.440645: Epoch 412 
2025-01-16 05:23:02.450721: Current learning rate: 0.00209 
2025-01-16 05:23:43.816663: train_loss -0.9502 
2025-01-16 05:23:43.817667: val_loss -0.2061 
2025-01-16 05:23:43.826309: Pseudo dice [np.float32(0.4255)] 
2025-01-16 05:23:43.830335: Epoch time: 41.38 s 
2025-01-16 05:23:44.403566:  
2025-01-16 05:23:44.403566: Epoch 413 
2025-01-16 05:23:44.410628: Current learning rate: 0.00207 
2025-01-16 05:24:25.773857: train_loss -0.9379 
2025-01-16 05:24:25.774861: val_loss -0.2789 
2025-01-16 05:24:25.781379: Pseudo dice [np.float32(0.5382)] 
2025-01-16 05:24:25.787396: Epoch time: 41.37 s 
2025-01-16 05:24:26.363018:  
2025-01-16 05:24:26.363018: Epoch 414 
2025-01-16 05:24:26.369573: Current learning rate: 0.00205 
2025-01-16 05:25:07.718273: train_loss -0.9476 
2025-01-16 05:25:07.718775: val_loss -0.2912 
2025-01-16 05:25:07.724333: Pseudo dice [np.float32(0.5979)] 
2025-01-16 05:25:07.728986: Epoch time: 41.36 s 
2025-01-16 05:25:08.299888:  
2025-01-16 05:25:08.299888: Epoch 415 
2025-01-16 05:25:08.305956: Current learning rate: 0.00203 
2025-01-16 05:25:49.670934: train_loss -0.9479 
2025-01-16 05:25:49.671437: val_loss -0.3694 
2025-01-16 05:25:49.682099: Pseudo dice [np.float32(0.5866)] 
2025-01-16 05:25:49.691660: Epoch time: 41.37 s 
2025-01-16 05:25:50.267337:  
2025-01-16 05:25:50.267337: Epoch 416 
2025-01-16 05:25:50.272374: Current learning rate: 0.00201 
2025-01-16 05:26:31.628549: train_loss -0.9497 
2025-01-16 05:26:31.629051: val_loss -0.2366 
2025-01-16 05:26:31.637618: Pseudo dice [np.float32(0.5003)] 
2025-01-16 05:26:31.640136: Epoch time: 41.36 s 
2025-01-16 05:26:32.219010:  
2025-01-16 05:26:32.220010: Epoch 417 
2025-01-16 05:26:32.225602: Current learning rate: 0.00199 
2025-01-16 05:27:13.585136: train_loss -0.9533 
2025-01-16 05:27:13.585646: val_loss -0.3043 
2025-01-16 05:27:13.592294: Pseudo dice [np.float32(0.5438)] 
2025-01-16 05:27:13.596842: Epoch time: 41.37 s 
2025-01-16 05:27:14.175070:  
2025-01-16 05:27:14.175070: Epoch 418 
2025-01-16 05:27:14.181609: Current learning rate: 0.00196 
2025-01-16 05:27:55.532051: train_loss -0.9411 
2025-01-16 05:27:55.532553: val_loss -0.3094 
2025-01-16 05:27:55.539606: Pseudo dice [np.float32(0.5808)] 
2025-01-16 05:27:55.543632: Epoch time: 41.36 s 
2025-01-16 05:27:56.267361:  
2025-01-16 05:27:56.267361: Epoch 419 
2025-01-16 05:27:56.273379: Current learning rate: 0.00194 
2025-01-16 05:28:37.610763: train_loss -0.9457 
2025-01-16 05:28:37.611272: val_loss -0.3119 
2025-01-16 05:28:37.623984: Pseudo dice [np.float32(0.4972)] 
2025-01-16 05:28:37.628031: Epoch time: 41.34 s 
2025-01-16 05:28:38.202630:  
2025-01-16 05:28:38.202630: Epoch 420 
2025-01-16 05:28:38.208246: Current learning rate: 0.00192 
2025-01-16 05:29:19.563422: train_loss -0.9391 
2025-01-16 05:29:19.564422: val_loss -0.1909 
2025-01-16 05:29:19.570939: Pseudo dice [np.float32(0.45)] 
2025-01-16 05:29:19.578455: Epoch time: 41.36 s 
2025-01-16 05:29:20.152415:  
2025-01-16 05:29:20.152415: Epoch 421 
2025-01-16 05:29:20.165652: Current learning rate: 0.0019 
2025-01-16 05:30:01.518937: train_loss -0.9478 
2025-01-16 05:30:01.518937: val_loss -0.323 
2025-01-16 05:30:01.526489: Pseudo dice [np.float32(0.5291)] 
2025-01-16 05:30:01.530533: Epoch time: 41.37 s 
2025-01-16 05:30:02.105136:  
2025-01-16 05:30:02.106142: Epoch 422 
2025-01-16 05:30:02.116796: Current learning rate: 0.00188 
2025-01-16 05:30:43.464036: train_loss -0.9443 
2025-01-16 05:30:43.464036: val_loss -0.2219 
2025-01-16 05:30:43.472107: Pseudo dice [np.float32(0.4844)] 
2025-01-16 05:30:43.476130: Epoch time: 41.36 s 
2025-01-16 05:30:44.054358:  
2025-01-16 05:30:44.055358: Epoch 423 
2025-01-16 05:30:44.068387: Current learning rate: 0.00186 
2025-01-16 05:31:25.433166: train_loss -0.9477 
2025-01-16 05:31:25.433166: val_loss -0.2764 
2025-01-16 05:31:25.440199: Pseudo dice [np.float32(0.4631)] 
2025-01-16 05:31:25.444226: Epoch time: 41.38 s 
2025-01-16 05:31:26.018018:  
2025-01-16 05:31:26.018018: Epoch 424 
2025-01-16 05:31:26.025048: Current learning rate: 0.00184 
2025-01-16 05:32:07.399167: train_loss -0.9515 
2025-01-16 05:32:07.400171: val_loss -0.1878 
2025-01-16 05:32:07.406777: Pseudo dice [np.float32(0.4545)] 
2025-01-16 05:32:07.411310: Epoch time: 41.38 s 
2025-01-16 05:32:07.987600:  
2025-01-16 05:32:07.987600: Epoch 425 
2025-01-16 05:32:07.994148: Current learning rate: 0.00181 
2025-01-16 05:32:49.335425: train_loss -0.9447 
2025-01-16 05:32:49.336423: val_loss -0.3214 
2025-01-16 05:32:49.344476: Pseudo dice [np.float32(0.5913)] 
2025-01-16 05:32:49.348985: Epoch time: 41.35 s 
2025-01-16 05:32:49.917658:  
2025-01-16 05:32:49.918658: Epoch 426 
2025-01-16 05:32:49.924247: Current learning rate: 0.00179 
2025-01-16 05:33:31.274335: train_loss -0.9461 
2025-01-16 05:33:31.274838: val_loss -0.3832 
2025-01-16 05:33:31.281380: Pseudo dice [np.float32(0.5904)] 
2025-01-16 05:33:31.285413: Epoch time: 41.36 s 
2025-01-16 05:33:31.860767:  
2025-01-16 05:33:31.860767: Epoch 427 
2025-01-16 05:33:31.867316: Current learning rate: 0.00177 
2025-01-16 05:34:13.226469: train_loss -0.9453 
2025-01-16 05:34:13.226971: val_loss -0.1874 
2025-01-16 05:34:13.232517: Pseudo dice [np.float32(0.4293)] 
2025-01-16 05:34:13.237040: Epoch time: 41.37 s 
2025-01-16 05:34:13.962101:  
2025-01-16 05:34:13.962101: Epoch 428 
2025-01-16 05:34:13.968688: Current learning rate: 0.00175 
2025-01-16 05:34:55.318095: train_loss -0.9519 
2025-01-16 05:34:55.318607: val_loss -0.3187 
2025-01-16 05:34:55.325218: Pseudo dice [np.float32(0.4955)] 
2025-01-16 05:34:55.329297: Epoch time: 41.36 s 
2025-01-16 05:34:55.905267:  
2025-01-16 05:34:55.906271: Epoch 429 
2025-01-16 05:34:55.911355: Current learning rate: 0.00173 
2025-01-16 05:35:37.242745: train_loss -0.9494 
2025-01-16 05:35:37.243247: val_loss -0.3296 
2025-01-16 05:35:37.249813: Pseudo dice [np.float32(0.5878)] 
2025-01-16 05:35:37.253821: Epoch time: 41.34 s 
2025-01-16 05:35:37.822036:  
2025-01-16 05:35:37.822036: Epoch 430 
2025-01-16 05:35:37.828053: Current learning rate: 0.0017 
2025-01-16 05:36:19.161100: train_loss -0.9501 
2025-01-16 05:36:19.161100: val_loss -0.2669 
2025-01-16 05:36:19.168693: Pseudo dice [np.float32(0.4828)] 
2025-01-16 05:36:19.173202: Epoch time: 41.34 s 
2025-01-16 05:36:19.741891:  
2025-01-16 05:36:19.742890: Epoch 431 
2025-01-16 05:36:19.748462: Current learning rate: 0.00168 
2025-01-16 05:37:01.087558: train_loss -0.9521 
2025-01-16 05:37:01.088559: val_loss -0.3754 
2025-01-16 05:37:01.095128: Pseudo dice [np.float32(0.588)] 
2025-01-16 05:37:01.098636: Epoch time: 41.35 s 
2025-01-16 05:37:01.675907:  
2025-01-16 05:37:01.676410: Epoch 432 
2025-01-16 05:37:01.689941: Current learning rate: 0.00166 
2025-01-16 05:37:43.039121: train_loss -0.9519 
2025-01-16 05:37:43.040124: val_loss -0.1024 
2025-01-16 05:37:43.049245: Pseudo dice [np.float32(0.3066)] 
2025-01-16 05:37:43.052757: Epoch time: 41.36 s 
2025-01-16 05:37:43.622284:  
2025-01-16 05:37:43.622284: Epoch 433 
2025-01-16 05:37:43.627361: Current learning rate: 0.00164 
2025-01-16 05:38:24.983445: train_loss -0.949 
2025-01-16 05:38:24.983961: val_loss -0.318 
2025-01-16 05:38:24.991068: Pseudo dice [np.float32(0.5393)] 
2025-01-16 05:38:24.995154: Epoch time: 41.36 s 
2025-01-16 05:38:25.568958:  
2025-01-16 05:38:25.568958: Epoch 434 
2025-01-16 05:38:25.579025: Current learning rate: 0.00162 
2025-01-16 05:39:06.929866: train_loss -0.9503 
2025-01-16 05:39:06.930866: val_loss -0.2836 
2025-01-16 05:39:06.938494: Pseudo dice [np.float32(0.5577)] 
2025-01-16 05:39:06.942002: Epoch time: 41.36 s 
2025-01-16 05:39:07.510053:  
2025-01-16 05:39:07.510053: Epoch 435 
2025-01-16 05:39:07.516122: Current learning rate: 0.00159 
2025-01-16 05:39:48.875937: train_loss -0.9529 
2025-01-16 05:39:48.876441: val_loss -0.3107 
2025-01-16 05:39:48.883959: Pseudo dice [np.float32(0.5377)] 
2025-01-16 05:39:48.888467: Epoch time: 41.37 s 
2025-01-16 05:39:49.613215:  
2025-01-16 05:39:49.613215: Epoch 436 
2025-01-16 05:39:49.619780: Current learning rate: 0.00157 
2025-01-16 05:40:30.971900: train_loss -0.9412 
2025-01-16 05:40:30.971900: val_loss -0.2885 
2025-01-16 05:40:30.982044: Pseudo dice [np.float32(0.5076)] 
2025-01-16 05:40:30.985554: Epoch time: 41.36 s 
2025-01-16 05:40:31.565572:  
2025-01-16 05:40:31.566075: Epoch 437 
2025-01-16 05:40:31.576099: Current learning rate: 0.00155 
2025-01-16 05:41:12.958677: train_loss -0.948 
2025-01-16 05:41:12.959179: val_loss -0.2672 
2025-01-16 05:41:12.966194: Pseudo dice [np.float32(0.5212)] 
2025-01-16 05:41:12.969204: Epoch time: 41.39 s 
2025-01-16 05:41:13.551582:  
2025-01-16 05:41:13.552583: Epoch 438 
2025-01-16 05:41:13.567172: Current learning rate: 0.00153 
2025-01-16 05:41:54.939675: train_loss -0.9486 
2025-01-16 05:41:54.941201: val_loss -0.243 
2025-01-16 05:41:54.948793: Pseudo dice [np.float32(0.4374)] 
2025-01-16 05:41:54.952340: Epoch time: 41.39 s 
2025-01-16 05:41:55.519210:  
2025-01-16 05:41:55.519210: Epoch 439 
2025-01-16 05:41:55.526843: Current learning rate: 0.00151 
2025-01-16 05:42:36.897456: train_loss -0.9463 
2025-01-16 05:42:36.897960: val_loss -0.216 
2025-01-16 05:42:36.910490: Pseudo dice [np.float32(0.439)] 
2025-01-16 05:42:36.915002: Epoch time: 41.38 s 
2025-01-16 05:42:37.489134:  
2025-01-16 05:42:37.490134: Epoch 440 
2025-01-16 05:42:37.497206: Current learning rate: 0.00148 
2025-01-16 05:43:18.866641: train_loss -0.956 
2025-01-16 05:43:18.867646: val_loss -0.2558 
2025-01-16 05:43:18.873729: Pseudo dice [np.float32(0.4608)] 
2025-01-16 05:43:18.878279: Epoch time: 41.38 s 
2025-01-16 05:43:19.452148:  
2025-01-16 05:43:19.452148: Epoch 441 
2025-01-16 05:43:19.458694: Current learning rate: 0.00146 
2025-01-16 05:44:00.825272: train_loss -0.9476 
2025-01-16 05:44:00.825776: val_loss -0.2285 
2025-01-16 05:44:00.831869: Pseudo dice [np.float32(0.4212)] 
2025-01-16 05:44:00.836414: Epoch time: 41.37 s 
2025-01-16 05:44:01.416004:  
2025-01-16 05:44:01.417004: Epoch 442 
2025-01-16 05:44:01.427530: Current learning rate: 0.00144 
2025-01-16 05:44:42.795182: train_loss -0.9518 
2025-01-16 05:44:42.796188: val_loss -0.2548 
2025-01-16 05:44:42.802544: Pseudo dice [np.float32(0.5128)] 
2025-01-16 05:44:42.806579: Epoch time: 41.38 s 
2025-01-16 05:44:43.369400:  
2025-01-16 05:44:43.370405: Epoch 443 
2025-01-16 05:44:43.374938: Current learning rate: 0.00142 
2025-01-16 05:45:24.751195: train_loss -0.9529 
2025-01-16 05:45:24.752201: val_loss -0.2897 
2025-01-16 05:45:24.762295: Pseudo dice [np.float32(0.5821)] 
2025-01-16 05:45:24.766303: Epoch time: 41.38 s 
2025-01-16 05:45:25.338311:  
2025-01-16 05:45:25.339315: Epoch 444 
2025-01-16 05:45:25.345373: Current learning rate: 0.00139 
2025-01-16 05:46:06.715523: train_loss -0.9552 
2025-01-16 05:46:06.715523: val_loss -0.1937 
2025-01-16 05:46:06.721638: Pseudo dice [np.float32(0.4501)] 
2025-01-16 05:46:06.726260: Epoch time: 41.38 s 
2025-01-16 05:46:07.450118:  
2025-01-16 05:46:07.450118: Epoch 445 
2025-01-16 05:46:07.464813: Current learning rate: 0.00137 
2025-01-16 05:46:48.837887: train_loss -0.9547 
2025-01-16 05:46:48.838391: val_loss -0.3451 
2025-01-16 05:46:48.846534: Pseudo dice [np.float32(0.6447)] 
2025-01-16 05:46:48.849562: Epoch time: 41.39 s 
2025-01-16 05:46:49.421538:  
2025-01-16 05:46:49.422041: Epoch 446 
2025-01-16 05:46:49.428057: Current learning rate: 0.00135 
2025-01-16 05:47:30.808928: train_loss -0.9539 
2025-01-16 05:47:30.808928: val_loss -0.2354 
2025-01-16 05:47:30.815480: Pseudo dice [np.float32(0.4727)] 
2025-01-16 05:47:30.819491: Epoch time: 41.39 s 
2025-01-16 05:47:31.392739:  
2025-01-16 05:47:31.392739: Epoch 447 
2025-01-16 05:47:31.399305: Current learning rate: 0.00133 
2025-01-16 05:48:12.749257: train_loss -0.9561 
2025-01-16 05:48:12.750260: val_loss -0.2366 
2025-01-16 05:48:12.756943: Pseudo dice [np.float32(0.4162)] 
2025-01-16 05:48:12.762003: Epoch time: 41.36 s 
2025-01-16 05:48:13.340027:  
2025-01-16 05:48:13.340027: Epoch 448 
2025-01-16 05:48:13.346057: Current learning rate: 0.0013 
2025-01-16 05:48:54.721788: train_loss -0.9501 
2025-01-16 05:48:54.721788: val_loss -0.3543 
2025-01-16 05:48:54.729411: Pseudo dice [np.float32(0.5442)] 
2025-01-16 05:48:54.732449: Epoch time: 41.38 s 
2025-01-16 05:48:55.311235:  
2025-01-16 05:48:55.311235: Epoch 449 
2025-01-16 05:48:55.317773: Current learning rate: 0.00128 
2025-01-16 05:49:36.654779: train_loss -0.9491 
2025-01-16 05:49:36.655289: val_loss -0.2935 
2025-01-16 05:49:36.660898: Pseudo dice [np.float32(0.5545)] 
2025-01-16 05:49:36.664929: Epoch time: 41.34 s 
2025-01-16 05:49:37.442312:  
2025-01-16 05:49:37.442815: Epoch 450 
2025-01-16 05:49:37.448833: Current learning rate: 0.00126 
2025-01-16 05:50:18.819281: train_loss -0.9553 
2025-01-16 05:50:18.819795: val_loss -0.2867 
2025-01-16 05:50:18.825910: Pseudo dice [np.float32(0.5083)] 
2025-01-16 05:50:18.829917: Epoch time: 41.38 s 
2025-01-16 05:50:19.408204:  
2025-01-16 05:50:19.408204: Epoch 451 
2025-01-16 05:50:19.415745: Current learning rate: 0.00124 
2025-01-16 05:51:00.782458: train_loss -0.9522 
2025-01-16 05:51:00.782960: val_loss -0.2224 
2025-01-16 05:51:00.790047: Pseudo dice [np.float32(0.45)] 
2025-01-16 05:51:00.793662: Epoch time: 41.38 s 
2025-01-16 05:51:01.367089:  
2025-01-16 05:51:01.367089: Epoch 452 
2025-01-16 05:51:01.373656: Current learning rate: 0.00121 
2025-01-16 05:51:42.735899: train_loss -0.9543 
2025-01-16 05:51:42.735899: val_loss -0.198 
2025-01-16 05:51:42.743542: Pseudo dice [np.float32(0.4214)] 
2025-01-16 05:51:42.747066: Epoch time: 41.37 s 
2025-01-16 05:51:43.469815:  
2025-01-16 05:51:43.470818: Epoch 453 
2025-01-16 05:51:43.475360: Current learning rate: 0.00119 
2025-01-16 05:52:24.817630: train_loss -0.9526 
2025-01-16 05:52:24.817630: val_loss -0.2489 
2025-01-16 05:52:24.827808: Pseudo dice [np.float32(0.5062)] 
2025-01-16 05:52:24.832372: Epoch time: 41.35 s 
2025-01-16 05:52:25.408807:  
2025-01-16 05:52:25.409809: Epoch 454 
2025-01-16 05:52:25.415401: Current learning rate: 0.00117 
2025-01-16 05:53:06.771069: train_loss -0.9491 
2025-01-16 05:53:06.771571: val_loss -0.3199 
2025-01-16 05:53:06.777586: Pseudo dice [np.float32(0.5433)] 
2025-01-16 05:53:06.784100: Epoch time: 41.36 s 
2025-01-16 05:53:07.352878:  
2025-01-16 05:53:07.352878: Epoch 455 
2025-01-16 05:53:07.360929: Current learning rate: 0.00115 
2025-01-16 05:53:48.714649: train_loss -0.9529 
2025-01-16 05:53:48.715156: val_loss -0.2793 
2025-01-16 05:53:48.725850: Pseudo dice [np.float32(0.5741)] 
2025-01-16 05:53:48.730395: Epoch time: 41.36 s 
2025-01-16 05:53:49.301162:  
2025-01-16 05:53:49.301162: Epoch 456 
2025-01-16 05:53:49.306753: Current learning rate: 0.00112 
2025-01-16 05:54:30.685124: train_loss -0.9592 
2025-01-16 05:54:30.686127: val_loss -0.1596 
2025-01-16 05:54:30.692701: Pseudo dice [np.float32(0.4627)] 
2025-01-16 05:54:30.697239: Epoch time: 41.38 s 
2025-01-16 05:54:31.268282:  
2025-01-16 05:54:31.268787: Epoch 457 
2025-01-16 05:54:31.274854: Current learning rate: 0.0011 
2025-01-16 05:55:12.633757: train_loss -0.9559 
2025-01-16 05:55:12.634259: val_loss -0.2914 
2025-01-16 05:55:12.645396: Pseudo dice [np.float32(0.5351)] 
2025-01-16 05:55:12.649403: Epoch time: 41.37 s 
2025-01-16 05:55:13.221019:  
2025-01-16 05:55:13.222022: Epoch 458 
2025-01-16 05:55:13.229642: Current learning rate: 0.00108 
2025-01-16 05:55:54.575742: train_loss -0.9555 
2025-01-16 05:55:54.575742: val_loss -0.2315 
2025-01-16 05:55:54.584315: Pseudo dice [np.float32(0.5266)] 
2025-01-16 05:55:54.588323: Epoch time: 41.35 s 
2025-01-16 05:55:55.159650:  
2025-01-16 05:55:55.160151: Epoch 459 
2025-01-16 05:55:55.165163: Current learning rate: 0.00105 
2025-01-16 05:56:36.519638: train_loss -0.9518 
2025-01-16 05:56:36.519638: val_loss -0.1974 
2025-01-16 05:56:36.526718: Pseudo dice [np.float32(0.4361)] 
2025-01-16 05:56:36.530765: Epoch time: 41.36 s 
2025-01-16 05:56:37.103659:  
2025-01-16 05:56:37.104161: Epoch 460 
2025-01-16 05:56:37.109712: Current learning rate: 0.00103 
2025-01-16 05:57:18.490484: train_loss -0.952 
2025-01-16 05:57:18.490484: val_loss -0.2969 
2025-01-16 05:57:18.496998: Pseudo dice [np.float32(0.5258)] 
2025-01-16 05:57:18.500509: Epoch time: 41.39 s 
2025-01-16 05:57:19.072625:  
2025-01-16 05:57:19.073128: Epoch 461 
2025-01-16 05:57:19.079141: Current learning rate: 0.00101 
2025-01-16 05:58:00.455850: train_loss -0.9518 
2025-01-16 05:58:00.455850: val_loss -0.3453 
2025-01-16 05:58:00.462927: Pseudo dice [np.float32(0.552)] 
2025-01-16 05:58:00.468460: Epoch time: 41.38 s 
2025-01-16 05:58:01.196752:  
2025-01-16 05:58:01.197254: Epoch 462 
2025-01-16 05:58:01.203268: Current learning rate: 0.00098 
2025-01-16 05:58:42.568262: train_loss -0.9537 
2025-01-16 05:58:42.568769: val_loss -0.2466 
2025-01-16 05:58:42.577943: Pseudo dice [np.float32(0.476)] 
2025-01-16 05:58:42.581985: Epoch time: 41.37 s 
2025-01-16 05:58:43.155173:  
2025-01-16 05:58:43.155173: Epoch 463 
2025-01-16 05:58:43.161260: Current learning rate: 0.00096 
2025-01-16 05:59:24.503870: train_loss -0.9545 
2025-01-16 05:59:24.504380: val_loss -0.2169 
2025-01-16 05:59:24.510956: Pseudo dice [np.float32(0.3764)] 
2025-01-16 05:59:24.514520: Epoch time: 41.35 s 
2025-01-16 05:59:25.098915:  
2025-01-16 05:59:25.099423: Epoch 464 
2025-01-16 05:59:25.112128: Current learning rate: 0.00094 
2025-01-16 06:00:06.468596: train_loss -0.956 
2025-01-16 06:00:06.469597: val_loss -0.2885 
2025-01-16 06:00:06.476137: Pseudo dice [np.float32(0.5263)] 
2025-01-16 06:00:06.480041: Epoch time: 41.37 s 
2025-01-16 06:00:07.054958:  
2025-01-16 06:00:07.055961: Epoch 465 
2025-01-16 06:00:07.065984: Current learning rate: 0.00091 
2025-01-16 06:00:48.415998: train_loss -0.9558 
2025-01-16 06:00:48.415998: val_loss -0.2997 
2025-01-16 06:00:48.423026: Pseudo dice [np.float32(0.5112)] 
2025-01-16 06:00:48.428927: Epoch time: 41.36 s 
2025-01-16 06:00:49.001347:  
2025-01-16 06:00:49.001347: Epoch 466 
2025-01-16 06:00:49.007988: Current learning rate: 0.00089 
2025-01-16 06:01:30.381837: train_loss -0.9601 
2025-01-16 06:01:30.382838: val_loss -0.3146 
2025-01-16 06:01:30.389435: Pseudo dice [np.float32(0.5783)] 
2025-01-16 06:01:30.394450: Epoch time: 41.38 s 
2025-01-16 06:01:30.963626:  
2025-01-16 06:01:30.964129: Epoch 467 
2025-01-16 06:01:30.970146: Current learning rate: 0.00087 
2025-01-16 06:02:12.335092: train_loss -0.9609 
2025-01-16 06:02:12.335600: val_loss -0.2804 
2025-01-16 06:02:12.358349: Pseudo dice [np.float32(0.4956)] 
2025-01-16 06:02:12.361377: Epoch time: 41.37 s 
2025-01-16 06:02:12.969903:  
2025-01-16 06:02:12.970406: Epoch 468 
2025-01-16 06:02:12.975419: Current learning rate: 0.00084 
2025-01-16 06:02:54.331710: train_loss -0.956 
2025-01-16 06:02:54.331710: val_loss -0.2602 
2025-01-16 06:02:54.339331: Pseudo dice [np.float32(0.5236)] 
2025-01-16 06:02:54.343843: Epoch time: 41.36 s 
2025-01-16 06:02:54.918818:  
2025-01-16 06:02:54.918818: Epoch 469 
2025-01-16 06:02:54.924356: Current learning rate: 0.00082 
2025-01-16 06:03:36.283293: train_loss -0.9597 
2025-01-16 06:03:36.283293: val_loss -0.3657 
2025-01-16 06:03:36.289908: Pseudo dice [np.float32(0.584)] 
2025-01-16 06:03:36.293461: Epoch time: 41.37 s 
2025-01-16 06:03:37.027121:  
2025-01-16 06:03:37.027121: Epoch 470 
2025-01-16 06:03:37.034137: Current learning rate: 0.00079 
2025-01-16 06:04:18.374779: train_loss -0.9563 
2025-01-16 06:04:18.375782: val_loss -0.2186 
2025-01-16 06:04:18.383384: Pseudo dice [np.float32(0.4903)] 
2025-01-16 06:04:18.394908: Epoch time: 41.35 s 
2025-01-16 06:04:18.973579:  
2025-01-16 06:04:18.973579: Epoch 471 
2025-01-16 06:04:18.980136: Current learning rate: 0.00077 
2025-01-16 06:05:00.332722: train_loss -0.9596 
2025-01-16 06:05:00.333728: val_loss -0.2482 
2025-01-16 06:05:00.340353: Pseudo dice [np.float32(0.4505)] 
2025-01-16 06:05:00.356585: Epoch time: 41.36 s 
2025-01-16 06:05:00.928830:  
2025-01-16 06:05:00.928830: Epoch 472 
2025-01-16 06:05:00.934931: Current learning rate: 0.00075 
2025-01-16 06:05:42.285002: train_loss -0.9595 
2025-01-16 06:05:42.286006: val_loss -0.2313 
2025-01-16 06:05:42.300040: Pseudo dice [np.float32(0.3907)] 
2025-01-16 06:05:42.305050: Epoch time: 41.36 s 
2025-01-16 06:05:42.885077:  
2025-01-16 06:05:42.885077: Epoch 473 
2025-01-16 06:05:42.891648: Current learning rate: 0.00072 
2025-01-16 06:06:24.245134: train_loss -0.9564 
2025-01-16 06:06:24.245134: val_loss -0.3037 
2025-01-16 06:06:24.251648: Pseudo dice [np.float32(0.5288)] 
2025-01-16 06:06:24.255157: Epoch time: 41.36 s 
2025-01-16 06:06:24.834096:  
2025-01-16 06:06:24.835097: Epoch 474 
2025-01-16 06:06:24.842679: Current learning rate: 0.0007 
2025-01-16 06:07:06.225683: train_loss -0.9575 
2025-01-16 06:07:06.227191: val_loss -0.1602 
2025-01-16 06:07:06.234386: Pseudo dice [np.float32(0.3996)] 
2025-01-16 06:07:06.243559: Epoch time: 41.39 s 
2025-01-16 06:07:06.813866:  
2025-01-16 06:07:06.813866: Epoch 475 
2025-01-16 06:07:06.827901: Current learning rate: 0.00067 
2025-01-16 06:07:48.201017: train_loss -0.959 
2025-01-16 06:07:48.202022: val_loss -0.2113 
2025-01-16 06:07:48.211126: Pseudo dice [np.float32(0.4251)] 
2025-01-16 06:07:48.215156: Epoch time: 41.39 s 
2025-01-16 06:07:48.791220:  
2025-01-16 06:07:48.791220: Epoch 476 
2025-01-16 06:07:48.797234: Current learning rate: 0.00065 
2025-01-16 06:08:30.182289: train_loss -0.9585 
2025-01-16 06:08:30.182289: val_loss -0.2542 
2025-01-16 06:08:30.190393: Pseudo dice [np.float32(0.5022)] 
2025-01-16 06:08:30.194920: Epoch time: 41.39 s 
2025-01-16 06:08:30.772416:  
2025-01-16 06:08:30.772921: Epoch 477 
2025-01-16 06:08:30.777966: Current learning rate: 0.00063 
2025-01-16 06:09:12.149253: train_loss -0.9591 
2025-01-16 06:09:12.150258: val_loss -0.2182 
2025-01-16 06:09:12.156784: Pseudo dice [np.float32(0.4271)] 
2025-01-16 06:09:12.161301: Epoch time: 41.38 s 
2025-01-16 06:09:12.743922:  
2025-01-16 06:09:12.744925: Epoch 478 
2025-01-16 06:09:12.748949: Current learning rate: 0.0006 
2025-01-16 06:09:54.125685: train_loss -0.9512 
2025-01-16 06:09:54.126191: val_loss -0.2536 
2025-01-16 06:09:54.131740: Pseudo dice [np.float32(0.4417)] 
2025-01-16 06:09:54.136263: Epoch time: 41.38 s 
2025-01-16 06:09:54.879389:  
2025-01-16 06:09:54.879389: Epoch 479 
2025-01-16 06:09:54.885972: Current learning rate: 0.00058 
2025-01-16 06:10:36.257940: train_loss -0.9572 
2025-01-16 06:10:36.257940: val_loss -0.2283 
2025-01-16 06:10:36.265507: Pseudo dice [np.float32(0.4815)] 
2025-01-16 06:10:36.269544: Epoch time: 41.38 s 
2025-01-16 06:10:36.855438:  
2025-01-16 06:10:36.855943: Epoch 480 
2025-01-16 06:10:36.861495: Current learning rate: 0.00055 
2025-01-16 06:11:18.240476: train_loss -0.9537 
2025-01-16 06:11:18.240978: val_loss -0.3023 
2025-01-16 06:11:18.247027: Pseudo dice [np.float32(0.5046)] 
2025-01-16 06:11:18.251697: Epoch time: 41.39 s 
2025-01-16 06:11:18.836866:  
2025-01-16 06:11:18.836866: Epoch 481 
2025-01-16 06:11:18.842394: Current learning rate: 0.00053 
2025-01-16 06:12:00.202325: train_loss -0.9584 
2025-01-16 06:12:00.203328: val_loss -0.2934 
2025-01-16 06:12:00.209866: Pseudo dice [np.float32(0.5277)] 
2025-01-16 06:12:00.213377: Epoch time: 41.37 s 
2025-01-16 06:12:00.796195:  
2025-01-16 06:12:00.796697: Epoch 482 
2025-01-16 06:12:00.812739: Current learning rate: 0.0005 
2025-01-16 06:12:42.197792: train_loss -0.9569 
2025-01-16 06:12:42.198308: val_loss -0.3292 
2025-01-16 06:12:42.202862: Pseudo dice [np.float32(0.5372)] 
2025-01-16 06:12:42.210993: Epoch time: 41.4 s 
2025-01-16 06:12:42.803318:  
2025-01-16 06:12:42.803830: Epoch 483 
2025-01-16 06:12:42.809415: Current learning rate: 0.00048 
2025-01-16 06:13:24.227044: train_loss -0.9576 
2025-01-16 06:13:24.227559: val_loss -0.2334 
2025-01-16 06:13:24.233788: Pseudo dice [np.float32(0.4537)] 
2025-01-16 06:13:24.238839: Epoch time: 41.42 s 
2025-01-16 06:13:24.830469:  
2025-01-16 06:13:24.830973: Epoch 484 
2025-01-16 06:13:24.836989: Current learning rate: 0.00045 
2025-01-16 06:14:06.247756: train_loss -0.9597 
2025-01-16 06:14:06.247756: val_loss -0.2442 
2025-01-16 06:14:06.255914: Pseudo dice [np.float32(0.4707)] 
2025-01-16 06:14:06.262944: Epoch time: 41.42 s 
2025-01-16 06:14:06.861973:  
2025-01-16 06:14:06.862978: Epoch 485 
2025-01-16 06:14:06.872572: Current learning rate: 0.00043 
2025-01-16 06:14:48.301042: train_loss -0.9592 
2025-01-16 06:14:48.301644: val_loss -0.3197 
2025-01-16 06:14:48.312283: Pseudo dice [np.float32(0.5516)] 
2025-01-16 06:14:48.317820: Epoch time: 41.44 s 
2025-01-16 06:14:48.922146:  
2025-01-16 06:14:48.922146: Epoch 486 
2025-01-16 06:14:48.941687: Current learning rate: 0.0004 
2025-01-16 06:15:30.346795: train_loss -0.9582 
2025-01-16 06:15:30.348299: val_loss -0.2992 
2025-01-16 06:15:30.354316: Pseudo dice [np.float32(0.5293)] 
2025-01-16 06:15:30.358325: Epoch time: 41.43 s 
2025-01-16 06:15:31.097596:  
2025-01-16 06:15:31.098594: Epoch 487 
2025-01-16 06:15:31.103646: Current learning rate: 0.00037 
2025-01-16 06:16:12.489859: train_loss -0.9609 
2025-01-16 06:16:12.490363: val_loss -0.2449 
2025-01-16 06:16:12.496411: Pseudo dice [np.float32(0.5222)] 
2025-01-16 06:16:12.500423: Epoch time: 41.39 s 
2025-01-16 06:16:13.112149:  
2025-01-16 06:16:13.112149: Epoch 488 
2025-01-16 06:16:13.131432: Current learning rate: 0.00035 
2025-01-16 06:16:54.508373: train_loss -0.9607 
2025-01-16 06:16:54.509405: val_loss -0.2477 
2025-01-16 06:16:54.513997: Pseudo dice [np.float32(0.461)] 
2025-01-16 06:16:54.523610: Epoch time: 41.4 s 
2025-01-16 06:16:55.122103:  
2025-01-16 06:16:55.122103: Epoch 489 
2025-01-16 06:16:55.128683: Current learning rate: 0.00032 
2025-01-16 06:17:36.522820: train_loss -0.9593 
2025-01-16 06:17:36.522820: val_loss -0.2994 
2025-01-16 06:17:36.528835: Pseudo dice [np.float32(0.4619)] 
2025-01-16 06:17:36.533847: Epoch time: 41.4 s 
2025-01-16 06:17:37.123435:  
2025-01-16 06:17:37.124440: Epoch 490 
2025-01-16 06:17:37.130541: Current learning rate: 0.0003 
2025-01-16 06:18:18.514043: train_loss -0.9609 
2025-01-16 06:18:18.514043: val_loss -0.2696 
2025-01-16 06:18:18.520622: Pseudo dice [np.float32(0.491)] 
2025-01-16 06:18:18.524166: Epoch time: 41.39 s 
2025-01-16 06:18:19.123476:  
2025-01-16 06:18:19.124480: Epoch 491 
2025-01-16 06:18:19.131107: Current learning rate: 0.00027 
2025-01-16 06:19:00.520916: train_loss -0.9612 
2025-01-16 06:19:00.521456: val_loss -0.2848 
2025-01-16 06:19:00.530156: Pseudo dice [np.float32(0.5529)] 
2025-01-16 06:19:00.534233: Epoch time: 41.4 s 
2025-01-16 06:19:01.115766:  
2025-01-16 06:19:01.116770: Epoch 492 
2025-01-16 06:19:01.123353: Current learning rate: 0.00024 
2025-01-16 06:19:42.497445: train_loss -0.961 
2025-01-16 06:19:42.497445: val_loss -0.2789 
2025-01-16 06:19:42.504501: Pseudo dice [np.float32(0.4832)] 
2025-01-16 06:19:42.508531: Epoch time: 41.38 s 
2025-01-16 06:19:43.109011:  
2025-01-16 06:19:43.109011: Epoch 493 
2025-01-16 06:19:43.115091: Current learning rate: 0.00021 
2025-01-16 06:20:24.533189: train_loss -0.9602 
2025-01-16 06:20:24.534195: val_loss -0.2008 
2025-01-16 06:20:24.540752: Pseudo dice [np.float32(0.4673)] 
2025-01-16 06:20:24.545259: Epoch time: 41.42 s 
2025-01-16 06:20:25.129580:  
2025-01-16 06:20:25.129580: Epoch 494 
2025-01-16 06:20:25.136206: Current learning rate: 0.00019 
2025-01-16 06:21:06.524454: train_loss -0.9623 
2025-01-16 06:21:06.524454: val_loss -0.2288 
2025-01-16 06:21:06.533503: Pseudo dice [np.float32(0.4627)] 
2025-01-16 06:21:06.538011: Epoch time: 41.4 s 
2025-01-16 06:21:07.136229:  
2025-01-16 06:21:07.136229: Epoch 495 
2025-01-16 06:21:07.141772: Current learning rate: 0.00016 
2025-01-16 06:21:48.534541: train_loss -0.9595 
2025-01-16 06:21:48.536067: val_loss -0.2803 
2025-01-16 06:21:48.542797: Pseudo dice [np.float32(0.5378)] 
2025-01-16 06:21:48.545827: Epoch time: 41.4 s 
2025-01-16 06:21:49.291050:  
2025-01-16 06:21:49.291050: Epoch 496 
2025-01-16 06:21:49.297064: Current learning rate: 0.00013 
2025-01-16 06:22:30.685542: train_loss -0.9634 
2025-01-16 06:22:30.685542: val_loss -0.2336 
2025-01-16 06:22:30.694154: Pseudo dice [np.float32(0.4829)] 
2025-01-16 06:22:30.697695: Epoch time: 41.39 s 
2025-01-16 06:22:31.289611:  
2025-01-16 06:22:31.289611: Epoch 497 
2025-01-16 06:22:31.295672: Current learning rate: 0.0001 
2025-01-16 06:23:12.687392: train_loss -0.961 
2025-01-16 06:23:12.688397: val_loss -0.2638 
2025-01-16 06:23:12.695064: Pseudo dice [np.float32(0.4706)] 
2025-01-16 06:23:12.699107: Epoch time: 41.4 s 
2025-01-16 06:23:13.281988:  
2025-01-16 06:23:13.281988: Epoch 498 
2025-01-16 06:23:13.289555: Current learning rate: 7e-05 
2025-01-16 06:23:54.683415: train_loss -0.9614 
2025-01-16 06:23:54.683415: val_loss -0.3629 
2025-01-16 06:23:54.694231: Pseudo dice [np.float32(0.5479)] 
2025-01-16 06:23:54.700474: Epoch time: 41.4 s 
2025-01-16 06:23:55.294656:  
2025-01-16 06:23:55.294656: Epoch 499 
2025-01-16 06:23:55.300671: Current learning rate: 4e-05 
2025-01-16 06:24:36.698984: train_loss -0.9604 
2025-01-16 06:24:36.699491: val_loss -0.3168 
2025-01-16 06:24:36.706079: Pseudo dice [np.float32(0.4974)] 
2025-01-16 06:24:36.713160: Epoch time: 41.4 s 
2025-01-16 06:24:37.504445: Training done. 
2025-01-16 06:24:37.535954: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2025-01-16 06:24:37.556953: The split file contains 5 splits. 
2025-01-16 06:24:37.563953: Desired fold for training: 0 
2025-01-16 06:24:37.568952: This split has 100 training and 26 validation cases. 
2025-01-16 06:24:37.572954: predicting colon_008 
2025-01-16 06:24:37.578954: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2025-01-16 06:24:40.254253: predicting colon_027 
2025-01-16 06:24:40.271253: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2025-01-16 06:24:41.056093: predicting colon_030 
2025-01-16 06:24:41.063093: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2025-01-16 06:24:42.177565: predicting colon_033 
2025-01-16 06:24:42.189565: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2025-01-16 06:24:44.140967: predicting colon_041 
2025-01-16 06:24:44.161968: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2025-01-16 06:24:49.359951: predicting colon_042 
2025-01-16 06:24:49.390952: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2025-01-16 06:24:52.037448: predicting colon_061 
2025-01-16 06:24:52.061447: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2025-01-16 06:24:55.119900: predicting colon_074 
2025-01-16 06:24:55.140899: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2025-01-16 06:24:58.633503: predicting colon_075 
2025-01-16 06:24:58.659503: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2025-01-16 06:25:00.629926: predicting colon_088 
2025-01-16 06:25:00.642926: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2025-01-16 06:25:03.695171: predicting colon_091 
2025-01-16 06:25:03.721683: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2025-01-16 06:25:07.383682: predicting colon_092 
2025-01-16 06:25:07.403681: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2025-01-16 06:25:10.425982: predicting colon_095 
2025-01-16 06:25:10.442984: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2025-01-16 06:25:12.402897: predicting colon_102 
2025-01-16 06:25:12.422899: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2025-01-16 06:25:16.758466: predicting colon_111 
2025-01-16 06:25:16.780467: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2025-01-16 06:25:18.023144: predicting colon_115 
2025-01-16 06:25:18.032144: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2025-01-16 06:25:19.997178: predicting colon_118 
2025-01-16 06:25:20.012178: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2025-01-16 06:25:23.057515: predicting colon_124 
2025-01-16 06:25:23.075515: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2025-01-16 06:25:26.114661: predicting colon_127 
2025-01-16 06:25:26.138677: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2025-01-16 06:25:32.208264: predicting colon_154 
2025-01-16 06:25:32.248775: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2025-01-16 06:25:34.210059: predicting colon_161 
2025-01-16 06:25:34.225059: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2025-01-16 06:25:36.200170: predicting colon_162 
2025-01-16 06:25:36.216168: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2025-01-16 06:25:41.422820: predicting colon_165 
2025-01-16 06:25:41.462329: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2025-01-16 06:25:45.815010: predicting colon_166 
2025-01-16 06:25:45.838009: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2025-01-16 06:25:47.793959: predicting colon_169 
2025-01-16 06:25:47.807958: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2025-01-16 06:25:53.874671: predicting colon_187 
2025-01-16 06:25:53.918671: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2025-01-16 06:26:11.983828: Validation complete 
2025-01-16 06:26:11.984827: Mean Validation Dice:  0.29078881358956543 
