
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-16 11:28:37.765450: do_dummy_2d_data_aug: True 
2024-12-16 11:28:37.779450: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-16 11:28:37.786959: The split file contains 5 splits. 
2024-12-16 11:28:37.788959: Desired fold for training: 0 
2024-12-16 11:28:37.791959: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2024-12-16 11:28:44.401025: unpacking dataset... 
2024-12-16 11:28:44.672426: unpacking done... 
2024-12-16 11:28:47.390706:  
2024-12-16 11:28:47.394711: Epoch 0 
2024-12-16 11:28:47.397245: Current learning rate: 0.01 
2024-12-16 11:29:33.143619: train_loss 0.0424 
2024-12-16 11:29:33.149636: val_loss -0.0141 
2024-12-16 11:29:33.152649: Pseudo dice [np.float32(0.0)] 
2024-12-16 11:29:33.156157: Epoch time: 45.75 s 
2024-12-16 11:29:33.158661: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-16 11:29:33.764735:  
2024-12-16 11:29:33.770312: Epoch 1 
2024-12-16 11:29:33.772858: Current learning rate: 0.00991 
2024-12-16 11:30:15.051314: train_loss -0.016 
2024-12-16 11:30:15.056329: val_loss -0.033 
2024-12-16 11:30:15.061346: Pseudo dice [np.float32(0.0)] 
2024-12-16 11:30:15.064858: Epoch time: 41.29 s 
2024-12-16 11:30:15.574548:  
2024-12-16 11:30:15.578577: Epoch 2 
2024-12-16 11:30:15.581110: Current learning rate: 0.00982 
2024-12-16 11:30:56.801667: train_loss -0.0276 
2024-12-16 11:30:56.807758: val_loss -0.0315 
2024-12-16 11:30:56.810788: Pseudo dice [np.float32(0.0)] 
2024-12-16 11:30:56.813311: Epoch time: 41.23 s 
2024-12-16 11:30:57.340413:  
2024-12-16 11:30:57.346427: Epoch 3 
2024-12-16 11:30:57.349438: Current learning rate: 0.00973 
2024-12-16 11:31:38.543877: train_loss -0.0289 
2024-12-16 11:31:38.549395: val_loss -0.0272 
2024-12-16 11:31:38.553909: Pseudo dice [np.float32(0.0)] 
2024-12-16 11:31:38.557924: Epoch time: 41.2 s 
2024-12-16 11:31:39.073969:  
2024-12-16 11:31:39.077982: Epoch 4 
2024-12-16 11:31:39.081991: Current learning rate: 0.00964 
2024-12-16 11:32:20.274884: train_loss -0.0252 
2024-12-16 11:32:20.282412: val_loss -0.0297 
2024-12-16 11:32:20.284922: Pseudo dice [np.float32(0.0)] 
2024-12-16 11:32:20.287948: Epoch time: 41.2 s 
2024-12-16 11:32:20.931792:  
2024-12-16 11:32:20.935832: Epoch 5 
2024-12-16 11:32:20.938603: Current learning rate: 0.00955 
2024-12-16 11:33:02.120283: train_loss -0.0299 
2024-12-16 11:33:02.125298: val_loss -0.0273 
2024-12-16 11:33:02.128360: Pseudo dice [np.float32(0.0)] 
2024-12-16 11:33:02.130865: Epoch time: 41.19 s 
2024-12-16 11:33:02.631251:  
2024-12-16 11:33:02.635263: Epoch 6 
2024-12-16 11:33:02.639278: Current learning rate: 0.00946 
2024-12-16 11:33:43.832619: train_loss -0.0292 
2024-12-16 11:33:43.838135: val_loss -0.0347 
2024-12-16 11:33:43.841185: Pseudo dice [np.float32(0.0)] 
2024-12-16 11:33:43.844219: Epoch time: 41.2 s 
2024-12-16 11:33:44.352585:  
2024-12-16 11:33:44.356610: Epoch 7 
2024-12-16 11:33:44.359877: Current learning rate: 0.00937 
2024-12-16 11:34:25.567615: train_loss -0.037 
2024-12-16 11:34:25.577687: val_loss -0.0509 
2024-12-16 11:34:25.581196: Pseudo dice [np.float32(0.0)] 
2024-12-16 11:34:25.583711: Epoch time: 41.22 s 
2024-12-16 11:34:26.099804:  
2024-12-16 11:34:26.105823: Epoch 8 
2024-12-16 11:34:26.108831: Current learning rate: 0.00928 
2024-12-16 11:35:07.296007: train_loss -0.0407 
2024-12-16 11:35:07.301024: val_loss -0.0498 
2024-12-16 11:35:07.304052: Pseudo dice [np.float32(0.0)] 
2024-12-16 11:35:07.306805: Epoch time: 41.2 s 
2024-12-16 11:35:07.830023:  
2024-12-16 11:35:07.834645: Epoch 9 
2024-12-16 11:35:07.837173: Current learning rate: 0.00919 
2024-12-16 11:35:49.037700: train_loss -0.0469 
2024-12-16 11:35:49.042263: val_loss -0.0629 
2024-12-16 11:35:49.046331: Pseudo dice [np.float32(0.0263)] 
2024-12-16 11:35:49.048877: Epoch time: 41.21 s 
2024-12-16 11:35:49.051939: Yayy! New best EMA pseudo Dice: 0.0026000000070780516 
2024-12-16 11:35:49.705965:  
2024-12-16 11:35:49.711511: Epoch 10 
2024-12-16 11:35:49.714027: Current learning rate: 0.0091 
2024-12-16 11:36:30.916450: train_loss -0.0495 
2024-12-16 11:36:30.922967: val_loss -0.0271 
2024-12-16 11:36:30.926473: Pseudo dice [np.float32(0.0372)] 
2024-12-16 11:36:30.929509: Epoch time: 41.21 s 
2024-12-16 11:36:30.932047: Yayy! New best EMA pseudo Dice: 0.006099999882280827 
2024-12-16 11:36:31.597982:  
2024-12-16 11:36:31.602606: Epoch 11 
2024-12-16 11:36:31.605124: Current learning rate: 0.009 
2024-12-16 11:37:12.793111: train_loss -0.0405 
2024-12-16 11:37:12.799627: val_loss -0.0815 
2024-12-16 11:37:12.802643: Pseudo dice [np.float32(0.116)] 
2024-12-16 11:37:12.805679: Epoch time: 41.2 s 
2024-12-16 11:37:12.808185: Yayy! New best EMA pseudo Dice: 0.017100000753998756 
2024-12-16 11:37:13.471976:  
2024-12-16 11:37:13.476562: Epoch 12 
2024-12-16 11:37:13.479612: Current learning rate: 0.00891 
2024-12-16 11:37:54.668232: train_loss -0.0726 
2024-12-16 11:37:54.674847: val_loss -0.0481 
2024-12-16 11:37:54.677374: Pseudo dice [np.float32(0.0601)] 
2024-12-16 11:37:54.680399: Epoch time: 41.2 s 
2024-12-16 11:37:54.683417: Yayy! New best EMA pseudo Dice: 0.021400000900030136 
2024-12-16 11:37:55.538773:  
2024-12-16 11:37:55.544730: Epoch 13 
2024-12-16 11:37:55.548744: Current learning rate: 0.00882 
2024-12-16 11:38:36.740705: train_loss -0.0526 
2024-12-16 11:38:36.746975: val_loss -0.0679 
2024-12-16 11:38:36.750490: Pseudo dice [np.float32(0.1276)] 
2024-12-16 11:38:36.754016: Epoch time: 41.2 s 
2024-12-16 11:38:36.756531: Yayy! New best EMA pseudo Dice: 0.03200000151991844 
2024-12-16 11:38:37.415146:  
2024-12-16 11:38:37.420235: Epoch 14 
2024-12-16 11:38:37.423300: Current learning rate: 0.00873 
2024-12-16 11:39:18.618401: train_loss -0.064 
2024-12-16 11:39:18.624948: val_loss -0.0421 
2024-12-16 11:39:18.627956: Pseudo dice [np.float32(0.0753)] 
2024-12-16 11:39:18.631465: Epoch time: 41.2 s 
2024-12-16 11:39:18.633981: Yayy! New best EMA pseudo Dice: 0.03629999980330467 
2024-12-16 11:39:19.319862:  
2024-12-16 11:39:19.324879: Epoch 15 
2024-12-16 11:39:19.327384: Current learning rate: 0.00864 
2024-12-16 11:40:00.514092: train_loss -0.0483 
2024-12-16 11:40:00.521108: val_loss -0.088 
2024-12-16 11:40:00.524116: Pseudo dice [np.float32(0.1369)] 
2024-12-16 11:40:00.527623: Epoch time: 41.19 s 
2024-12-16 11:40:00.530129: Yayy! New best EMA pseudo Dice: 0.04639999940991402 
2024-12-16 11:40:01.247245:  
2024-12-16 11:40:01.252301: Epoch 16 
2024-12-16 11:40:01.255332: Current learning rate: 0.00855 
2024-12-16 11:40:42.436382: train_loss -0.071 
2024-12-16 11:40:42.443012: val_loss -0.056 
2024-12-16 11:40:42.446591: Pseudo dice [np.float32(0.1116)] 
2024-12-16 11:40:42.450109: Epoch time: 41.19 s 
2024-12-16 11:40:42.453252: Yayy! New best EMA pseudo Dice: 0.05290000140666962 
2024-12-16 11:40:43.145192:  
2024-12-16 11:40:43.150771: Epoch 17 
2024-12-16 11:40:43.153815: Current learning rate: 0.00846 
2024-12-16 11:41:24.330723: train_loss -0.0803 
2024-12-16 11:41:24.336766: val_loss -0.0672 
2024-12-16 11:41:24.339795: Pseudo dice [np.float32(0.1012)] 
2024-12-16 11:41:24.343300: Epoch time: 41.19 s 
2024-12-16 11:41:24.346312: Yayy! New best EMA pseudo Dice: 0.05770000070333481 
2024-12-16 11:41:25.057731:  
2024-12-16 11:41:25.062743: Epoch 18 
2024-12-16 11:41:25.066254: Current learning rate: 0.00836 
2024-12-16 11:42:06.259813: train_loss -0.0628 
2024-12-16 11:42:06.265332: val_loss -0.0817 
2024-12-16 11:42:06.267839: Pseudo dice [np.float32(0.1224)] 
2024-12-16 11:42:06.270349: Epoch time: 41.2 s 
2024-12-16 11:42:06.273857: Yayy! New best EMA pseudo Dice: 0.06419999897480011 
2024-12-16 11:42:06.992236:  
2024-12-16 11:42:06.997277: Epoch 19 
2024-12-16 11:42:07.000338: Current learning rate: 0.00827 
2024-12-16 11:42:48.207702: train_loss -0.069 
2024-12-16 11:42:48.214212: val_loss -0.0703 
2024-12-16 11:42:48.217721: Pseudo dice [np.float32(0.1035)] 
2024-12-16 11:42:48.220229: Epoch time: 41.22 s 
2024-12-16 11:42:48.222734: Yayy! New best EMA pseudo Dice: 0.06809999793767929 
2024-12-16 11:42:49.102210:  
2024-12-16 11:42:49.107230: Epoch 20 
2024-12-16 11:42:49.109742: Current learning rate: 0.00818 
2024-12-16 11:43:30.290826: train_loss -0.0791 
2024-12-16 11:43:30.296356: val_loss -0.091 
2024-12-16 11:43:30.299870: Pseudo dice [np.float32(0.1875)] 
2024-12-16 11:43:30.302375: Epoch time: 41.19 s 
2024-12-16 11:43:30.306381: Yayy! New best EMA pseudo Dice: 0.08009999990463257 
2024-12-16 11:43:30.985974:  
2024-12-16 11:43:30.990988: Epoch 21 
2024-12-16 11:43:30.994000: Current learning rate: 0.00809 
2024-12-16 11:44:12.189743: train_loss -0.0787 
2024-12-16 11:44:12.195383: val_loss -0.0822 
2024-12-16 11:44:12.197907: Pseudo dice [np.float32(0.1611)] 
2024-12-16 11:44:12.200987: Epoch time: 41.2 s 
2024-12-16 11:44:12.204011: Yayy! New best EMA pseudo Dice: 0.08820000290870667 
2024-12-16 11:44:12.899423:  
2024-12-16 11:44:12.904976: Epoch 22 
2024-12-16 11:44:12.907512: Current learning rate: 0.008 
2024-12-16 11:44:54.164458: train_loss -0.0869 
2024-12-16 11:44:54.169470: val_loss -0.0308 
2024-12-16 11:44:54.173484: Pseudo dice [np.float32(0.0374)] 
2024-12-16 11:44:54.175991: Epoch time: 41.27 s 
2024-12-16 11:44:54.696852:  
2024-12-16 11:44:54.701652: Epoch 23 
2024-12-16 11:44:54.704663: Current learning rate: 0.0079 
2024-12-16 11:45:35.919975: train_loss -0.0263 
2024-12-16 11:45:35.927101: val_loss -0.0508 
2024-12-16 11:45:35.930611: Pseudo dice [np.float32(0.0477)] 
2024-12-16 11:45:35.933118: Epoch time: 41.22 s 
2024-12-16 11:45:36.440130:  
2024-12-16 11:45:36.444643: Epoch 24 
2024-12-16 11:45:36.447655: Current learning rate: 0.00781 
2024-12-16 11:46:17.625898: train_loss -0.0702 
2024-12-16 11:46:17.630908: val_loss -0.0545 
2024-12-16 11:46:17.633958: Pseudo dice [np.float32(0.0701)] 
2024-12-16 11:46:17.636465: Epoch time: 41.19 s 
2024-12-16 11:46:18.156425:  
2024-12-16 11:46:18.161466: Epoch 25 
2024-12-16 11:46:18.164038: Current learning rate: 0.00772 
2024-12-16 11:46:59.346312: train_loss -0.1001 
2024-12-16 11:46:59.352823: val_loss -0.1035 
2024-12-16 11:46:59.356331: Pseudo dice [np.float32(0.1979)] 
2024-12-16 11:46:59.358837: Epoch time: 41.19 s 
2024-12-16 11:46:59.361343: Yayy! New best EMA pseudo Dice: 0.09049999713897705 
2024-12-16 11:47:00.095887:  
2024-12-16 11:47:00.101427: Epoch 26 
2024-12-16 11:47:00.103973: Current learning rate: 0.00763 
2024-12-16 11:47:41.289207: train_loss -0.0702 
2024-12-16 11:47:41.294333: val_loss -0.071 
2024-12-16 11:47:41.297422: Pseudo dice [np.float32(0.1477)] 
2024-12-16 11:47:41.300508: Epoch time: 41.19 s 
2024-12-16 11:47:41.303139: Yayy! New best EMA pseudo Dice: 0.09619999676942825 
2024-12-16 11:47:42.020024:  
2024-12-16 11:47:42.025603: Epoch 27 
2024-12-16 11:47:42.028137: Current learning rate: 0.00753 
2024-12-16 11:48:23.209638: train_loss -0.0865 
2024-12-16 11:48:23.215613: val_loss -0.0885 
2024-12-16 11:48:23.218119: Pseudo dice [np.float32(0.1184)] 
2024-12-16 11:48:23.221625: Epoch time: 41.19 s 
2024-12-16 11:48:23.224639: Yayy! New best EMA pseudo Dice: 0.09849999845027924 
2024-12-16 11:48:23.896502:  
2024-12-16 11:48:23.901544: Epoch 28 
2024-12-16 11:48:23.904654: Current learning rate: 0.00744 
2024-12-16 11:49:05.093968: train_loss -0.0856 
2024-12-16 11:49:05.098978: val_loss -0.0843 
2024-12-16 11:49:05.101485: Pseudo dice [np.float32(0.2057)] 
2024-12-16 11:49:05.104991: Epoch time: 41.2 s 
2024-12-16 11:49:05.108000: Yayy! New best EMA pseudo Dice: 0.10920000076293945 
2024-12-16 11:49:05.917395:  
2024-12-16 11:49:05.922471: Epoch 29 
2024-12-16 11:49:05.925017: Current learning rate: 0.00735 
2024-12-16 11:49:47.105026: train_loss -0.0698 
2024-12-16 11:49:47.110734: val_loss -0.103 
2024-12-16 11:49:47.113767: Pseudo dice [np.float32(0.1433)] 
2024-12-16 11:49:47.116809: Epoch time: 41.19 s 
2024-12-16 11:49:47.119838: Yayy! New best EMA pseudo Dice: 0.11259999871253967 
2024-12-16 11:49:47.783253:  
2024-12-16 11:49:47.788266: Epoch 30 
2024-12-16 11:49:47.791275: Current learning rate: 0.00725 
2024-12-16 11:50:28.961759: train_loss -0.0895 
2024-12-16 11:50:28.968312: val_loss -0.0799 
2024-12-16 11:50:28.971350: Pseudo dice [np.float32(0.1611)] 
2024-12-16 11:50:28.974368: Epoch time: 41.18 s 
2024-12-16 11:50:28.977113: Yayy! New best EMA pseudo Dice: 0.11739999800920486 
2024-12-16 11:50:29.673933:  
2024-12-16 11:50:29.678967: Epoch 31 
2024-12-16 11:50:29.681535: Current learning rate: 0.00716 
2024-12-16 11:51:10.848555: train_loss -0.1066 
2024-12-16 11:51:10.853566: val_loss -0.1262 
2024-12-16 11:51:10.856070: Pseudo dice [np.float32(0.2567)] 
2024-12-16 11:51:10.858578: Epoch time: 41.18 s 
2024-12-16 11:51:10.862088: Yayy! New best EMA pseudo Dice: 0.131400004029274 
2024-12-16 11:51:11.526676:  
2024-12-16 11:51:11.531688: Epoch 32 
2024-12-16 11:51:11.534699: Current learning rate: 0.00707 
2024-12-16 11:51:52.726397: train_loss -0.1092 
2024-12-16 11:51:52.731978: val_loss -0.103 
2024-12-16 11:51:52.734510: Pseudo dice [np.float32(0.2157)] 
2024-12-16 11:51:52.737607: Epoch time: 41.2 s 
2024-12-16 11:51:52.740204: Yayy! New best EMA pseudo Dice: 0.13979999721050262 
2024-12-16 11:51:53.414912:  
2024-12-16 11:51:53.419994: Epoch 33 
2024-12-16 11:51:53.423020: Current learning rate: 0.00697 
2024-12-16 11:52:34.608252: train_loss -0.1099 
2024-12-16 11:52:34.613364: val_loss -0.1254 
2024-12-16 11:52:34.617925: Pseudo dice [np.float32(0.177)] 
2024-12-16 11:52:34.620981: Epoch time: 41.19 s 
2024-12-16 11:52:34.624016: Yayy! New best EMA pseudo Dice: 0.14350000023841858 
2024-12-16 11:52:35.332759:  
2024-12-16 11:52:35.338342: Epoch 34 
2024-12-16 11:52:35.341437: Current learning rate: 0.00688 
2024-12-16 11:53:16.521666: train_loss -0.1031 
2024-12-16 11:53:16.526699: val_loss -0.1547 
2024-12-16 11:53:16.530205: Pseudo dice [np.float32(0.2744)] 
2024-12-16 11:53:16.533213: Epoch time: 41.19 s 
2024-12-16 11:53:16.535719: Yayy! New best EMA pseudo Dice: 0.1565999984741211 
2024-12-16 11:53:17.265409:  
2024-12-16 11:53:17.269474: Epoch 35 
2024-12-16 11:53:17.273494: Current learning rate: 0.00679 
2024-12-16 11:53:58.443630: train_loss -0.121 
2024-12-16 11:53:58.449183: val_loss -0.0928 
2024-12-16 11:53:58.452241: Pseudo dice [np.float32(0.195)] 
2024-12-16 11:53:58.455274: Epoch time: 41.18 s 
2024-12-16 11:53:58.457779: Yayy! New best EMA pseudo Dice: 0.16040000319480896 
2024-12-16 11:53:59.317588:  
2024-12-16 11:53:59.322603: Epoch 36 
2024-12-16 11:53:59.325110: Current learning rate: 0.00669 
2024-12-16 11:54:40.502728: train_loss -0.1048 
2024-12-16 11:54:40.507817: val_loss -0.0835 
2024-12-16 11:54:40.510857: Pseudo dice [np.float32(0.1197)] 
2024-12-16 11:54:40.514865: Epoch time: 41.19 s 
2024-12-16 11:54:41.037066:  
2024-12-16 11:54:41.041627: Epoch 37 
2024-12-16 11:54:41.044670: Current learning rate: 0.0066 
2024-12-16 11:55:22.225541: train_loss -0.0862 
2024-12-16 11:55:22.231076: val_loss -0.0782 
2024-12-16 11:55:22.233083: Pseudo dice [np.float32(0.111)] 
2024-12-16 11:55:22.236105: Epoch time: 41.19 s 
2024-12-16 11:55:22.765536:  
2024-12-16 11:55:22.770581: Epoch 38 
2024-12-16 11:55:22.773124: Current learning rate: 0.0065 
2024-12-16 11:56:03.961297: train_loss -0.127 
2024-12-16 11:56:03.966874: val_loss -0.107 
2024-12-16 11:56:03.969409: Pseudo dice [np.float32(0.2304)] 
2024-12-16 11:56:03.972493: Epoch time: 41.2 s 
2024-12-16 11:56:04.501947:  
2024-12-16 11:56:04.506992: Epoch 39 
2024-12-16 11:56:04.510044: Current learning rate: 0.00641 
2024-12-16 11:56:45.700112: train_loss -0.1201 
2024-12-16 11:56:45.707131: val_loss -0.0941 
2024-12-16 11:56:45.710172: Pseudo dice [np.float32(0.1502)] 
2024-12-16 11:56:45.712770: Epoch time: 41.2 s 
2024-12-16 11:56:46.259363:  
2024-12-16 11:56:46.263400: Epoch 40 
2024-12-16 11:56:46.267439: Current learning rate: 0.00631 
2024-12-16 11:57:27.457135: train_loss -0.126 
2024-12-16 11:57:27.463199: val_loss -0.073 
2024-12-16 11:57:27.465723: Pseudo dice [np.float32(0.1456)] 
2024-12-16 11:57:27.469245: Epoch time: 41.2 s 
2024-12-16 11:57:28.011615:  
2024-12-16 11:57:28.016626: Epoch 41 
2024-12-16 11:57:28.020131: Current learning rate: 0.00622 
2024-12-16 11:58:09.213166: train_loss -0.0917 
2024-12-16 11:58:09.218177: val_loss -0.0932 
2024-12-16 11:58:09.220721: Pseudo dice [np.float32(0.1839)] 
2024-12-16 11:58:09.223774: Epoch time: 41.2 s 
2024-12-16 11:58:09.732513:  
2024-12-16 11:58:09.737522: Epoch 42 
2024-12-16 11:58:09.740027: Current learning rate: 0.00612 
2024-12-16 11:58:50.911722: train_loss -0.1125 
2024-12-16 11:58:50.917761: val_loss -0.1334 
2024-12-16 11:58:50.920274: Pseudo dice [np.float32(0.3214)] 
2024-12-16 11:58:50.923839: Epoch time: 41.18 s 
2024-12-16 11:58:50.926023: Yayy! New best EMA pseudo Dice: 0.1762000024318695 
2024-12-16 11:58:51.669763:  
2024-12-16 11:58:51.674779: Epoch 43 
2024-12-16 11:58:51.677792: Current learning rate: 0.00603 
2024-12-16 11:59:32.864794: train_loss -0.1306 
2024-12-16 11:59:32.871344: val_loss -0.09 
2024-12-16 11:59:32.874856: Pseudo dice [np.float32(0.1693)] 
2024-12-16 11:59:32.877362: Epoch time: 41.2 s 
2024-12-16 11:59:33.534078:  
2024-12-16 11:59:33.539093: Epoch 44 
2024-12-16 11:59:33.541600: Current learning rate: 0.00593 
2024-12-16 12:00:14.714912: train_loss -0.1355 
2024-12-16 12:00:14.720521: val_loss -0.1561 
2024-12-16 12:00:14.722545: Pseudo dice [np.float32(0.3299)] 
2024-12-16 12:00:14.726114: Epoch time: 41.18 s 
2024-12-16 12:00:14.729082: Yayy! New best EMA pseudo Dice: 0.19099999964237213 
2024-12-16 12:00:15.446143:  
2024-12-16 12:00:15.451159: Epoch 45 
2024-12-16 12:00:15.453664: Current learning rate: 0.00584 
2024-12-16 12:00:56.632919: train_loss -0.12 
2024-12-16 12:00:56.638033: val_loss -0.0964 
2024-12-16 12:00:56.641076: Pseudo dice [np.float32(0.1878)] 
2024-12-16 12:00:56.643616: Epoch time: 41.19 s 
2024-12-16 12:00:57.145849:  
2024-12-16 12:00:57.150881: Epoch 46 
2024-12-16 12:00:57.153946: Current learning rate: 0.00574 
2024-12-16 12:01:38.335650: train_loss -0.1324 
2024-12-16 12:01:38.342212: val_loss -0.1205 
2024-12-16 12:01:38.345307: Pseudo dice [np.float32(0.2611)] 
2024-12-16 12:01:38.348845: Epoch time: 41.19 s 
2024-12-16 12:01:38.351878: Yayy! New best EMA pseudo Dice: 0.19769999384880066 
2024-12-16 12:01:39.017348:  
2024-12-16 12:01:39.022453: Epoch 47 
2024-12-16 12:01:39.026008: Current learning rate: 0.00565 
2024-12-16 12:02:20.218421: train_loss -0.1428 
2024-12-16 12:02:20.224947: val_loss -0.0956 
2024-12-16 12:02:20.228817: Pseudo dice [np.float32(0.1909)] 
2024-12-16 12:02:20.232330: Epoch time: 41.2 s 
2024-12-16 12:02:20.749797:  
2024-12-16 12:02:20.754898: Epoch 48 
2024-12-16 12:02:20.757940: Current learning rate: 0.00555 
2024-12-16 12:03:01.930786: train_loss -0.0929 
2024-12-16 12:03:01.935805: val_loss -0.1224 
2024-12-16 12:03:01.939316: Pseudo dice [np.float32(0.2033)] 
2024-12-16 12:03:01.941819: Epoch time: 41.18 s 
2024-12-16 12:03:02.467143:  
2024-12-16 12:03:02.472186: Epoch 49 
2024-12-16 12:03:02.475705: Current learning rate: 0.00546 
2024-12-16 12:03:43.660724: train_loss -0.1545 
2024-12-16 12:03:43.666750: val_loss -0.1299 
2024-12-16 12:03:43.669254: Pseudo dice [np.float32(0.2208)] 
2024-12-16 12:03:43.673270: Epoch time: 41.19 s 
2024-12-16 12:03:43.812905: Yayy! New best EMA pseudo Dice: 0.20000000298023224 
2024-12-16 12:03:44.490025:  
2024-12-16 12:03:44.495038: Epoch 50 
2024-12-16 12:03:44.498554: Current learning rate: 0.00536 
2024-12-16 12:04:25.667206: train_loss -0.133 
2024-12-16 12:04:25.672718: val_loss -0.0782 
2024-12-16 12:04:25.676228: Pseudo dice [np.float32(0.2095)] 
2024-12-16 12:04:25.680235: Epoch time: 41.18 s 
2024-12-16 12:04:25.682740: Yayy! New best EMA pseudo Dice: 0.20090000331401825 
2024-12-16 12:04:26.400297:  
2024-12-16 12:04:26.404312: Epoch 51 
2024-12-16 12:04:26.408322: Current learning rate: 0.00526 
2024-12-16 12:05:07.588622: train_loss -0.1125 
2024-12-16 12:05:07.593717: val_loss -0.1217 
2024-12-16 12:05:07.596748: Pseudo dice [np.float32(0.2345)] 
2024-12-16 12:05:07.600264: Epoch time: 41.19 s 
2024-12-16 12:05:07.603276: Yayy! New best EMA pseudo Dice: 0.20430000126361847 
2024-12-16 12:05:08.417564:  
2024-12-16 12:05:08.422581: Epoch 52 
2024-12-16 12:05:08.425091: Current learning rate: 0.00517 
2024-12-16 12:05:49.589026: train_loss -0.1558 
2024-12-16 12:05:49.595041: val_loss -0.1331 
2024-12-16 12:05:49.599050: Pseudo dice [np.float32(0.3257)] 
2024-12-16 12:05:49.602560: Epoch time: 41.17 s 
2024-12-16 12:05:49.605067: Yayy! New best EMA pseudo Dice: 0.21639999747276306 
2024-12-16 12:05:50.272037:  
2024-12-16 12:05:50.277091: Epoch 53 
2024-12-16 12:05:50.280636: Current learning rate: 0.00507 
2024-12-16 12:06:31.464689: train_loss -0.1228 
2024-12-16 12:06:31.471248: val_loss -0.1212 
2024-12-16 12:06:31.474280: Pseudo dice [np.float32(0.236)] 
2024-12-16 12:06:31.477302: Epoch time: 41.19 s 
2024-12-16 12:06:31.480847: Yayy! New best EMA pseudo Dice: 0.2184000015258789 
2024-12-16 12:06:32.148022:  
2024-12-16 12:06:32.152066: Epoch 54 
2024-12-16 12:06:32.156613: Current learning rate: 0.00497 
2024-12-16 12:07:13.418189: train_loss -0.1391 
2024-12-16 12:07:13.422713: val_loss -0.1208 
2024-12-16 12:07:13.427564: Pseudo dice [np.float32(0.3115)] 
2024-12-16 12:07:13.431072: Epoch time: 41.27 s 
2024-12-16 12:07:13.433578: Yayy! New best EMA pseudo Dice: 0.22769999504089355 
2024-12-16 12:07:14.126741:  
2024-12-16 12:07:14.132295: Epoch 55 
2024-12-16 12:07:14.136367: Current learning rate: 0.00487 
2024-12-16 12:07:55.359810: train_loss -0.1335 
2024-12-16 12:07:55.366354: val_loss -0.1028 
2024-12-16 12:07:55.369365: Pseudo dice [np.float32(0.3062)] 
2024-12-16 12:07:55.372880: Epoch time: 41.23 s 
2024-12-16 12:07:55.376384: Yayy! New best EMA pseudo Dice: 0.23549999296665192 
2024-12-16 12:07:56.048095:  
2024-12-16 12:07:56.054144: Epoch 56 
2024-12-16 12:07:56.057710: Current learning rate: 0.00478 
2024-12-16 12:08:37.244435: train_loss -0.1374 
2024-12-16 12:08:37.251007: val_loss -0.1192 
2024-12-16 12:08:37.256025: Pseudo dice [np.float32(0.2275)] 
2024-12-16 12:08:37.259533: Epoch time: 41.2 s 
2024-12-16 12:08:37.771859:  
2024-12-16 12:08:37.778375: Epoch 57 
2024-12-16 12:08:37.781883: Current learning rate: 0.00468 
2024-12-16 12:09:18.974550: train_loss -0.1214 
2024-12-16 12:09:18.980613: val_loss -0.0973 
2024-12-16 12:09:18.984653: Pseudo dice [np.float32(0.2781)] 
2024-12-16 12:09:18.988225: Epoch time: 41.2 s 
2024-12-16 12:09:18.991262: Yayy! New best EMA pseudo Dice: 0.23909999430179596 
2024-12-16 12:09:19.658099:  
2024-12-16 12:09:19.663109: Epoch 58 
2024-12-16 12:09:19.667124: Current learning rate: 0.00458 
2024-12-16 12:10:00.844858: train_loss -0.1247 
2024-12-16 12:10:00.850496: val_loss -0.1477 
2024-12-16 12:10:00.854533: Pseudo dice [np.float32(0.282)] 
2024-12-16 12:10:00.858543: Epoch time: 41.19 s 
2024-12-16 12:10:00.861057: Yayy! New best EMA pseudo Dice: 0.2433999925851822 
2024-12-16 12:10:01.614021:  
2024-12-16 12:10:01.619574: Epoch 59 
2024-12-16 12:10:01.623132: Current learning rate: 0.00448 
2024-12-16 12:10:42.788130: train_loss -0.1231 
2024-12-16 12:10:42.794153: val_loss -0.1473 
2024-12-16 12:10:42.798161: Pseudo dice [np.float32(0.287)] 
2024-12-16 12:10:42.801677: Epoch time: 41.17 s 
2024-12-16 12:10:42.805182: Yayy! New best EMA pseudo Dice: 0.24770000576972961 
2024-12-16 12:10:43.686050:  
2024-12-16 12:10:43.691647: Epoch 60 
2024-12-16 12:10:43.695682: Current learning rate: 0.00438 
2024-12-16 12:11:24.856593: train_loss -0.1401 
2024-12-16 12:11:24.862629: val_loss -0.1736 
2024-12-16 12:11:24.866141: Pseudo dice [np.float32(0.3545)] 
2024-12-16 12:11:24.870159: Epoch time: 41.17 s 
2024-12-16 12:11:24.872669: Yayy! New best EMA pseudo Dice: 0.25839999318122864 
2024-12-16 12:11:25.543722:  
2024-12-16 12:11:25.549260: Epoch 61 
2024-12-16 12:11:25.552774: Current learning rate: 0.00429 
2024-12-16 12:12:06.720445: train_loss -0.1524 
2024-12-16 12:12:06.726020: val_loss -0.1568 
2024-12-16 12:12:06.729558: Pseudo dice [np.float32(0.3512)] 
2024-12-16 12:12:06.733571: Epoch time: 41.18 s 
2024-12-16 12:12:06.737081: Yayy! New best EMA pseudo Dice: 0.2676999866962433 
2024-12-16 12:12:07.423175:  
2024-12-16 12:12:07.428200: Epoch 62 
2024-12-16 12:12:07.431926: Current learning rate: 0.00419 
2024-12-16 12:12:48.612708: train_loss -0.1699 
2024-12-16 12:12:48.618392: val_loss -0.1255 
2024-12-16 12:12:48.622502: Pseudo dice [np.float32(0.2756)] 
2024-12-16 12:12:48.626038: Epoch time: 41.19 s 
2024-12-16 12:12:48.634740: Yayy! New best EMA pseudo Dice: 0.2685000002384186 
2024-12-16 12:12:49.331525:  
2024-12-16 12:12:49.341546: Epoch 63 
2024-12-16 12:12:49.350064: Current learning rate: 0.00409 
2024-12-16 12:13:30.509934: train_loss -0.1545 
2024-12-16 12:13:30.521504: val_loss -0.1026 
2024-12-16 12:13:30.530525: Pseudo dice [np.float32(0.2499)] 
2024-12-16 12:13:30.539044: Epoch time: 41.18 s 
2024-12-16 12:13:31.062451:  
2024-12-16 12:13:31.067966: Epoch 64 
2024-12-16 12:13:31.071477: Current learning rate: 0.00399 
2024-12-16 12:14:12.245664: train_loss -0.1279 
2024-12-16 12:14:12.252190: val_loss -0.1061 
2024-12-16 12:14:12.255713: Pseudo dice [np.float32(0.2291)] 
2024-12-16 12:14:12.258222: Epoch time: 41.18 s 
2024-12-16 12:14:12.787893:  
2024-12-16 12:14:12.797993: Epoch 65 
2024-12-16 12:14:12.805616: Current learning rate: 0.00389 
2024-12-16 12:14:53.962885: train_loss -0.1464 
2024-12-16 12:14:53.967929: val_loss -0.1167 
2024-12-16 12:14:53.975573: Pseudo dice [np.float32(0.2918)] 
2024-12-16 12:14:53.983704: Epoch time: 41.17 s 
2024-12-16 12:14:54.514657:  
2024-12-16 12:14:54.519697: Epoch 66 
2024-12-16 12:14:54.529221: Current learning rate: 0.00379 
2024-12-16 12:15:35.722064: train_loss -0.1489 
2024-12-16 12:15:35.732113: val_loss -0.1528 
2024-12-16 12:15:35.740731: Pseudo dice [np.float32(0.3091)] 
2024-12-16 12:15:35.749766: Epoch time: 41.21 s 
2024-12-16 12:15:35.757293: Yayy! New best EMA pseudo Dice: 0.2700999975204468 
2024-12-16 12:15:36.525070:  
2024-12-16 12:15:36.537100: Epoch 67 
2024-12-16 12:15:36.540111: Current learning rate: 0.00369 
2024-12-16 12:16:17.748440: train_loss -0.17 
2024-12-16 12:16:17.753967: val_loss -0.1397 
2024-12-16 12:16:17.764086: Pseudo dice [np.float32(0.2103)] 
2024-12-16 12:16:17.771608: Epoch time: 41.22 s 
2024-12-16 12:16:18.467624:  
2024-12-16 12:16:18.477648: Epoch 68 
2024-12-16 12:16:18.481163: Current learning rate: 0.00359 
2024-12-16 12:16:59.676558: train_loss -0.1595 
2024-12-16 12:16:59.681568: val_loss -0.09 
2024-12-16 12:16:59.685077: Pseudo dice [np.float32(0.2911)] 
2024-12-16 12:16:59.692595: Epoch time: 41.21 s 
2024-12-16 12:17:00.219727:  
2024-12-16 12:17:00.226240: Epoch 69 
2024-12-16 12:17:00.233754: Current learning rate: 0.00349 
2024-12-16 12:17:41.405509: train_loss -0.1709 
2024-12-16 12:17:41.416568: val_loss -0.1255 
2024-12-16 12:17:41.425085: Pseudo dice [np.float32(0.2542)] 
2024-12-16 12:17:41.428102: Epoch time: 41.19 s 
2024-12-16 12:17:41.956875:  
2024-12-16 12:17:41.966551: Epoch 70 
2024-12-16 12:17:41.970675: Current learning rate: 0.00338 
2024-12-16 12:18:23.141543: train_loss -0.146 
2024-12-16 12:18:23.149081: val_loss -0.0917 
2024-12-16 12:18:23.152109: Pseudo dice [np.float32(0.2451)] 
2024-12-16 12:18:23.155675: Epoch time: 41.19 s 
2024-12-16 12:18:23.682070:  
2024-12-16 12:18:23.687648: Epoch 71 
2024-12-16 12:18:23.700331: Current learning rate: 0.00328 
2024-12-16 12:19:04.868483: train_loss -0.1465 
2024-12-16 12:19:04.878029: val_loss -0.0953 
2024-12-16 12:19:04.882052: Pseudo dice [np.float32(0.2094)] 
2024-12-16 12:19:04.884554: Epoch time: 41.19 s 
2024-12-16 12:19:05.417273:  
2024-12-16 12:19:05.430906: Epoch 72 
2024-12-16 12:19:05.440562: Current learning rate: 0.00318 
2024-12-16 12:19:46.607602: train_loss -0.1794 
2024-12-16 12:19:46.622666: val_loss -0.1111 
2024-12-16 12:19:46.626678: Pseudo dice [np.float32(0.4102)] 
2024-12-16 12:19:46.629184: Epoch time: 41.19 s 
2024-12-16 12:19:46.632693: Yayy! New best EMA pseudo Dice: 0.2732999920845032 
2024-12-16 12:19:47.412308:  
2024-12-16 12:19:47.418439: Epoch 73 
2024-12-16 12:19:47.420953: Current learning rate: 0.00308 
2024-12-16 12:20:28.584198: train_loss -0.1815 
2024-12-16 12:20:28.590113: val_loss -0.1316 
2024-12-16 12:20:28.593632: Pseudo dice [np.float32(0.2714)] 
2024-12-16 12:20:28.597190: Epoch time: 41.17 s 
2024-12-16 12:20:29.117815:  
2024-12-16 12:20:29.122872: Epoch 74 
2024-12-16 12:20:29.125931: Current learning rate: 0.00297 
2024-12-16 12:21:10.297436: train_loss -0.1828 
2024-12-16 12:21:10.302449: val_loss -0.1588 
2024-12-16 12:21:10.306959: Pseudo dice [np.float32(0.3036)] 
2024-12-16 12:21:10.309972: Epoch time: 41.18 s 
2024-12-16 12:21:10.312476: Yayy! New best EMA pseudo Dice: 0.27619999647140503 
2024-12-16 12:21:10.998129:  
2024-12-16 12:21:11.003709: Epoch 75 
2024-12-16 12:21:11.006234: Current learning rate: 0.00287 
2024-12-16 12:21:52.187508: train_loss -0.1695 
2024-12-16 12:21:52.194695: val_loss -0.1052 
2024-12-16 12:21:52.197769: Pseudo dice [np.float32(0.3514)] 
2024-12-16 12:21:52.200865: Epoch time: 41.19 s 
2024-12-16 12:21:52.203944: Yayy! New best EMA pseudo Dice: 0.28369998931884766 
2024-12-16 12:21:53.036895:  
2024-12-16 12:21:53.041929: Epoch 76 
2024-12-16 12:21:53.045461: Current learning rate: 0.00277 
2024-12-16 12:22:34.268215: train_loss -0.1846 
2024-12-16 12:22:34.274789: val_loss -0.1676 
2024-12-16 12:22:34.278301: Pseudo dice [np.float32(0.4087)] 
2024-12-16 12:22:34.280807: Epoch time: 41.23 s 
2024-12-16 12:22:34.284314: Yayy! New best EMA pseudo Dice: 0.2962000072002411 
2024-12-16 12:22:34.983366:  
2024-12-16 12:22:34.988942: Epoch 77 
2024-12-16 12:22:34.991481: Current learning rate: 0.00266 
2024-12-16 12:23:16.197651: train_loss -0.2004 
2024-12-16 12:23:16.202746: val_loss -0.165 
2024-12-16 12:23:16.206306: Pseudo dice [np.float32(0.4555)] 
2024-12-16 12:23:16.208824: Epoch time: 41.21 s 
2024-12-16 12:23:16.211751: Yayy! New best EMA pseudo Dice: 0.31209999322891235 
2024-12-16 12:23:16.894017:  
2024-12-16 12:23:16.899031: Epoch 78 
2024-12-16 12:23:16.902039: Current learning rate: 0.00256 
2024-12-16 12:23:58.093309: train_loss -0.201 
2024-12-16 12:23:58.099385: val_loss -0.1425 
2024-12-16 12:23:58.102475: Pseudo dice [np.float32(0.4555)] 
2024-12-16 12:23:58.105517: Epoch time: 41.2 s 
2024-12-16 12:23:58.108561: Yayy! New best EMA pseudo Dice: 0.3264999985694885 
2024-12-16 12:23:58.840580:  
2024-12-16 12:23:58.846108: Epoch 79 
2024-12-16 12:23:58.849138: Current learning rate: 0.00245 
2024-12-16 12:24:40.018683: train_loss -0.1942 
2024-12-16 12:24:40.024770: val_loss -0.2234 
2024-12-16 12:24:40.027818: Pseudo dice [np.float32(0.5003)] 
2024-12-16 12:24:40.030890: Epoch time: 41.18 s 
2024-12-16 12:24:40.033937: Yayy! New best EMA pseudo Dice: 0.34380000829696655 
2024-12-16 12:24:40.727528:  
2024-12-16 12:24:40.732044: Epoch 80 
2024-12-16 12:24:40.735560: Current learning rate: 0.00235 
2024-12-16 12:25:21.926654: train_loss -0.1708 
2024-12-16 12:25:21.932213: val_loss -0.0756 
2024-12-16 12:25:21.934719: Pseudo dice [np.float32(0.2089)] 
2024-12-16 12:25:21.938231: Epoch time: 41.2 s 
2024-12-16 12:25:22.472264:  
2024-12-16 12:25:22.477279: Epoch 81 
2024-12-16 12:25:22.480293: Current learning rate: 0.00224 
2024-12-16 12:26:03.654490: train_loss -0.1881 
2024-12-16 12:26:03.659506: val_loss -0.1214 
2024-12-16 12:26:03.663516: Pseudo dice [np.float32(0.217)] 
2024-12-16 12:26:03.666022: Epoch time: 41.18 s 
2024-12-16 12:26:04.205475:  
2024-12-16 12:26:04.209940: Epoch 82 
2024-12-16 12:26:04.212969: Current learning rate: 0.00214 
2024-12-16 12:26:45.368388: train_loss -0.2004 
2024-12-16 12:26:45.374908: val_loss -0.1235 
2024-12-16 12:26:45.378414: Pseudo dice [np.float32(0.3774)] 
2024-12-16 12:26:45.381959: Epoch time: 41.16 s 
2024-12-16 12:26:45.893509:  
2024-12-16 12:26:45.898524: Epoch 83 
2024-12-16 12:26:45.901533: Current learning rate: 0.00203 
2024-12-16 12:27:27.062920: train_loss -0.2054 
2024-12-16 12:27:27.067957: val_loss -0.1461 
2024-12-16 12:27:27.071024: Pseudo dice [np.float32(0.2673)] 
2024-12-16 12:27:27.074060: Epoch time: 41.17 s 
2024-12-16 12:27:27.728454:  
2024-12-16 12:27:27.734028: Epoch 84 
2024-12-16 12:27:27.736579: Current learning rate: 0.00192 
2024-12-16 12:28:08.887732: train_loss -0.1896 
2024-12-16 12:28:08.892745: val_loss -0.1572 
2024-12-16 12:28:08.896254: Pseudo dice [np.float32(0.3478)] 
2024-12-16 12:28:08.898763: Epoch time: 41.16 s 
2024-12-16 12:28:09.402020:  
2024-12-16 12:28:09.407651: Epoch 85 
2024-12-16 12:28:09.411219: Current learning rate: 0.00181 
2024-12-16 12:28:50.575916: train_loss -0.1983 
2024-12-16 12:28:50.581521: val_loss -0.1754 
2024-12-16 12:28:50.583543: Pseudo dice [np.float32(0.402)] 
2024-12-16 12:28:50.588094: Epoch time: 41.17 s 
2024-12-16 12:28:51.088803:  
2024-12-16 12:28:51.094341: Epoch 86 
2024-12-16 12:28:51.096900: Current learning rate: 0.0017 
2024-12-16 12:29:32.243169: train_loss -0.1966 
2024-12-16 12:29:32.249236: val_loss -0.1721 
2024-12-16 12:29:32.252775: Pseudo dice [np.float32(0.304)] 
2024-12-16 12:29:32.255813: Epoch time: 41.15 s 
2024-12-16 12:29:32.753838:  
2024-12-16 12:29:32.758914: Epoch 87 
2024-12-16 12:29:32.761447: Current learning rate: 0.00159 
2024-12-16 12:30:13.931947: train_loss -0.2048 
2024-12-16 12:30:13.936997: val_loss -0.1628 
2024-12-16 12:30:13.940038: Pseudo dice [np.float32(0.3311)] 
2024-12-16 12:30:13.942567: Epoch time: 41.18 s 
2024-12-16 12:30:14.441167:  
2024-12-16 12:30:14.446212: Epoch 88 
2024-12-16 12:30:14.449262: Current learning rate: 0.00148 
2024-12-16 12:30:55.627435: train_loss -0.1945 
2024-12-16 12:30:55.632998: val_loss -0.1616 
2024-12-16 12:30:55.636527: Pseudo dice [np.float32(0.2997)] 
2024-12-16 12:30:55.640108: Epoch time: 41.19 s 
2024-12-16 12:30:56.143850:  
2024-12-16 12:30:56.148863: Epoch 89 
2024-12-16 12:30:56.151870: Current learning rate: 0.00137 
2024-12-16 12:31:37.345981: train_loss -0.2088 
2024-12-16 12:31:37.353105: val_loss -0.1471 
2024-12-16 12:31:37.355614: Pseudo dice [np.float32(0.2847)] 
2024-12-16 12:31:37.359131: Epoch time: 41.2 s 
2024-12-16 12:31:37.858461:  
2024-12-16 12:31:37.863475: Epoch 90 
2024-12-16 12:31:37.866037: Current learning rate: 0.00126 
2024-12-16 12:32:19.060970: train_loss -0.2139 
2024-12-16 12:32:19.065989: val_loss -0.1715 
2024-12-16 12:32:19.068495: Pseudo dice [np.float32(0.4452)] 
2024-12-16 12:32:19.072011: Epoch time: 41.2 s 
2024-12-16 12:32:19.570681:  
2024-12-16 12:32:19.575785: Epoch 91 
2024-12-16 12:32:19.579300: Current learning rate: 0.00115 
2024-12-16 12:33:00.752592: train_loss -0.2063 
2024-12-16 12:33:00.758181: val_loss -0.1797 
2024-12-16 12:33:00.760715: Pseudo dice [np.float32(0.4175)] 
2024-12-16 12:33:00.763761: Epoch time: 41.18 s 
2024-12-16 12:33:01.269176:  
2024-12-16 12:33:01.274195: Epoch 92 
2024-12-16 12:33:01.277705: Current learning rate: 0.00103 
2024-12-16 12:33:42.439046: train_loss -0.202 
2024-12-16 12:33:42.445117: val_loss -0.1286 
2024-12-16 12:33:42.447623: Pseudo dice [np.float32(0.3165)] 
2024-12-16 12:33:42.451637: Epoch time: 41.17 s 
2024-12-16 12:33:43.105594:  
2024-12-16 12:33:43.110607: Epoch 93 
2024-12-16 12:33:43.113617: Current learning rate: 0.00091 
2024-12-16 12:34:24.287840: train_loss -0.2198 
2024-12-16 12:34:24.294421: val_loss -0.1954 
2024-12-16 12:34:24.297538: Pseudo dice [np.float32(0.3394)] 
2024-12-16 12:34:24.300591: Epoch time: 41.18 s 
2024-12-16 12:34:24.800745:  
2024-12-16 12:34:24.805789: Epoch 94 
2024-12-16 12:34:24.808354: Current learning rate: 0.00079 
2024-12-16 12:35:05.961137: train_loss -0.1863 
2024-12-16 12:35:05.965636: val_loss -0.1826 
2024-12-16 12:35:05.970654: Pseudo dice [np.float32(0.5017)] 
2024-12-16 12:35:05.974664: Epoch time: 41.16 s 
2024-12-16 12:35:05.978178: Yayy! New best EMA pseudo Dice: 0.3555000126361847 
2024-12-16 12:35:06.635727:  
2024-12-16 12:35:06.640741: Epoch 95 
2024-12-16 12:35:06.643247: Current learning rate: 0.00067 
2024-12-16 12:35:47.862609: train_loss -0.2426 
2024-12-16 12:35:47.868205: val_loss -0.1771 
2024-12-16 12:35:47.871717: Pseudo dice [np.float32(0.4432)] 
2024-12-16 12:35:47.875727: Epoch time: 41.23 s 
2024-12-16 12:35:47.878234: Yayy! New best EMA pseudo Dice: 0.364300012588501 
2024-12-16 12:35:48.542413:  
2024-12-16 12:35:48.547955: Epoch 96 
2024-12-16 12:35:48.550988: Current learning rate: 0.00055 
2024-12-16 12:36:29.745603: train_loss -0.2256 
2024-12-16 12:36:29.751680: val_loss -0.1805 
2024-12-16 12:36:29.754505: Pseudo dice [np.float32(0.5235)] 
2024-12-16 12:36:29.758026: Epoch time: 41.2 s 
2024-12-16 12:36:29.760543: Yayy! New best EMA pseudo Dice: 0.38019999861717224 
2024-12-16 12:36:30.427546:  
2024-12-16 12:36:30.431607: Epoch 97 
2024-12-16 12:36:30.435701: Current learning rate: 0.00043 
2024-12-16 12:37:11.605653: train_loss -0.2395 
2024-12-16 12:37:11.610256: val_loss -0.1776 
2024-12-16 12:37:11.612761: Pseudo dice [np.float32(0.3609)] 
2024-12-16 12:37:11.616268: Epoch time: 41.18 s 
2024-12-16 12:37:12.134326:  
2024-12-16 12:37:12.139703: Epoch 98 
2024-12-16 12:37:12.142710: Current learning rate: 0.0003 
2024-12-16 12:37:53.318278: train_loss -0.2393 
2024-12-16 12:37:53.324322: val_loss -0.1907 
2024-12-16 12:37:53.327830: Pseudo dice [np.float32(0.4479)] 
2024-12-16 12:37:53.330840: Epoch time: 41.18 s 
2024-12-16 12:37:53.334349: Yayy! New best EMA pseudo Dice: 0.38519999384880066 
2024-12-16 12:37:54.013840:  
2024-12-16 12:37:54.018849: Epoch 99 
2024-12-16 12:37:54.022357: Current learning rate: 0.00016 
2024-12-16 12:38:35.189083: train_loss -0.2144 
2024-12-16 12:38:35.195146: val_loss -0.1515 
2024-12-16 12:38:35.199176: Pseudo dice [np.float32(0.3448)] 
2024-12-16 12:38:35.202189: Epoch time: 41.18 s 
2024-12-16 12:38:35.898539: Training done. 
2024-12-16 12:38:35.932539: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-16 12:38:35.938540: The split file contains 5 splits. 
2024-12-16 12:38:35.942544: Desired fold for training: 0 
2024-12-16 12:38:35.947546: This split has 100 training and 26 validation cases. 
2024-12-16 12:38:35.950546: predicting colon_008 
2024-12-16 12:38:35.956058: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2024-12-16 12:38:51.624670: predicting colon_027 
2024-12-16 12:38:51.641669: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2024-12-16 12:38:57.629684: predicting colon_030 
2024-12-16 12:38:57.641684: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2024-12-16 12:39:06.084262: predicting colon_033 
2024-12-16 12:39:06.101262: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2024-12-16 12:39:21.085065: predicting colon_041 
2024-12-16 12:39:21.109066: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2024-12-16 12:40:01.455793: predicting colon_042 
2024-12-16 12:40:01.486792: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2024-12-16 12:40:21.729744: predicting colon_061 
2024-12-16 12:40:21.754744: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2024-12-16 12:40:45.155895: predicting colon_074 
2024-12-16 12:40:45.177893: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2024-12-16 12:41:12.159272: predicting colon_075 
2024-12-16 12:41:12.193272: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2024-12-16 12:41:27.213846: predicting colon_088 
2024-12-16 12:41:27.232844: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2024-12-16 12:41:50.665247: predicting colon_091 
2024-12-16 12:41:50.690414: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2024-12-16 12:42:18.758914: predicting colon_092 
2024-12-16 12:42:18.784420: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2024-12-16 12:42:42.164798: predicting colon_095 
2024-12-16 12:42:42.186802: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2024-12-16 12:42:57.197115: predicting colon_102 
2024-12-16 12:42:57.215623: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2024-12-16 12:43:30.884264: predicting colon_111 
2024-12-16 12:43:30.919267: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2024-12-16 12:43:40.322741: predicting colon_115 
2024-12-16 12:43:40.342249: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2024-12-16 12:43:55.350947: predicting colon_118 
2024-12-16 12:43:55.369950: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2024-12-16 12:44:18.792537: predicting colon_124 
2024-12-16 12:44:18.819536: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2024-12-16 12:44:42.220586: predicting colon_127 
2024-12-16 12:44:42.249589: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2024-12-16 12:45:29.337586: predicting colon_154 
2024-12-16 12:45:29.383586: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2024-12-16 12:45:44.409854: predicting colon_161 
2024-12-16 12:45:44.433070: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2024-12-16 12:45:59.435045: predicting colon_162 
2024-12-16 12:45:59.454041: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2024-12-16 12:46:39.862121: predicting colon_165 
2024-12-16 12:46:39.900121: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2024-12-16 12:47:13.560333: predicting colon_166 
2024-12-16 12:47:13.590363: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2024-12-16 12:47:28.588281: predicting colon_169 
2024-12-16 12:47:28.612281: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2024-12-16 12:48:15.768113: predicting colon_187 
2024-12-16 12:48:15.814622: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2024-12-16 12:48:48.213009: Validation complete 
2024-12-16 12:48:48.220010: Mean Validation Dice:  0.09465841568105496 
