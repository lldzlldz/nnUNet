
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-17 09:04:37.804457: do_dummy_2d_data_aug: True 
2024-12-17 09:04:37.806457: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-17 09:04:37.810455: The split file contains 5 splits. 
2024-12-17 09:04:37.813454: Desired fold for training: 0 
2024-12-17 09:04:37.815456: This split has 100 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [56, 192, 192], 'median_image_size_in_voxels': [150.0, 512.0, 512.0], 'spacing': [3.0, 0.78125, 0.78125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_Colon', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [5.0, 0.78125, 0.78125], 'original_median_shape_after_transp': [95, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 445.0, 'mean': 67.2009506225586, 'median': 67.0, 'min': -848.0, 'percentile_00_5': -40.0, 'percentile_99_5': 188.0, 'std': 37.13160705566406}}} 
 
2024-12-17 09:04:43.771423: unpacking dataset... 
2024-12-17 09:04:43.965671: unpacking done... 
2024-12-17 09:04:46.580941:  
2024-12-17 09:04:46.585457: Epoch 0 
2024-12-17 09:04:46.588469: Current learning rate: 0.01 
2024-12-17 09:05:32.275303: train_loss 0.0558 
2024-12-17 09:05:32.280836: val_loss -0.0112 
2024-12-17 09:05:32.283348: Pseudo dice [np.float32(0.0)] 
2024-12-17 09:05:32.285860: Epoch time: 45.69 s 
2024-12-17 09:05:32.288856: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-17 09:05:32.911726:  
2024-12-17 09:05:32.916910: Epoch 1 
2024-12-17 09:05:32.918920: Current learning rate: 0.00991 
2024-12-17 09:06:14.144237: train_loss -0.0747 
2024-12-17 09:06:14.150297: val_loss -0.1049 
2024-12-17 09:06:14.152802: Pseudo dice [np.float32(0.0)] 
2024-12-17 09:06:14.155311: Epoch time: 41.23 s 
2024-12-17 09:06:14.683363:  
2024-12-17 09:06:14.688394: Epoch 2 
2024-12-17 09:06:14.691329: Current learning rate: 0.00982 
2024-12-17 09:06:55.906241: train_loss -0.2857 
2024-12-17 09:06:55.913806: val_loss -0.2496 
2024-12-17 09:06:55.916328: Pseudo dice [np.float32(0.307)] 
2024-12-17 09:06:55.918850: Epoch time: 41.22 s 
2024-12-17 09:06:55.922374: Yayy! New best EMA pseudo Dice: 0.030700000002980232 
2024-12-17 09:06:56.636582:  
2024-12-17 09:06:56.640630: Epoch 3 
2024-12-17 09:06:56.644156: Current learning rate: 0.00973 
2024-12-17 09:07:37.870903: train_loss -0.3214 
2024-12-17 09:07:37.875446: val_loss -0.3506 
2024-12-17 09:07:37.878555: Pseudo dice [np.float32(0.4061)] 
2024-12-17 09:07:37.882066: Epoch time: 41.23 s 
2024-12-17 09:07:37.884598: Yayy! New best EMA pseudo Dice: 0.0681999996304512 
2024-12-17 09:07:38.589342:  
2024-12-17 09:07:38.595362: Epoch 4 
2024-12-17 09:07:38.598373: Current learning rate: 0.00964 
2024-12-17 09:08:19.806827: train_loss -0.434 
2024-12-17 09:08:19.812841: val_loss -0.3983 
2024-12-17 09:08:19.816347: Pseudo dice [np.float32(0.4586)] 
2024-12-17 09:08:19.818851: Epoch time: 41.22 s 
2024-12-17 09:08:19.821860: Yayy! New best EMA pseudo Dice: 0.10729999840259552 
2024-12-17 09:08:20.646929:  
2024-12-17 09:08:20.651705: Epoch 5 
2024-12-17 09:08:20.654210: Current learning rate: 0.00955 
2024-12-17 09:09:01.857856: train_loss -0.4223 
2024-12-17 09:09:01.864892: val_loss -0.4237 
2024-12-17 09:09:01.868398: Pseudo dice [np.float32(0.4826)] 
2024-12-17 09:09:01.871408: Epoch time: 41.21 s 
2024-12-17 09:09:01.873913: Yayy! New best EMA pseudo Dice: 0.14480000734329224 
2024-12-17 09:09:02.561577:  
2024-12-17 09:09:02.566602: Epoch 6 
2024-12-17 09:09:02.570300: Current learning rate: 0.00946 
2024-12-17 09:09:43.775976: train_loss -0.4861 
2024-12-17 09:09:43.781008: val_loss -0.3603 
2024-12-17 09:09:43.784036: Pseudo dice [np.float32(0.4303)] 
2024-12-17 09:09:43.786540: Epoch time: 41.22 s 
2024-12-17 09:09:43.789046: Yayy! New best EMA pseudo Dice: 0.17329999804496765 
2024-12-17 09:09:44.484091:  
2024-12-17 09:09:44.489105: Epoch 7 
2024-12-17 09:09:44.491613: Current learning rate: 0.00937 
2024-12-17 09:10:25.721177: train_loss -0.4767 
2024-12-17 09:10:25.726221: val_loss -0.4228 
2024-12-17 09:10:25.729231: Pseudo dice [np.float32(0.5236)] 
2024-12-17 09:10:25.731740: Epoch time: 41.24 s 
2024-12-17 09:10:25.734247: Yayy! New best EMA pseudo Dice: 0.20839999616146088 
2024-12-17 09:10:26.452529:  
2024-12-17 09:10:26.456952: Epoch 8 
2024-12-17 09:10:26.459963: Current learning rate: 0.00928 
2024-12-17 09:11:07.688567: train_loss -0.4758 
2024-12-17 09:11:07.695109: val_loss -0.3989 
2024-12-17 09:11:07.697616: Pseudo dice [np.float32(0.5065)] 
2024-12-17 09:11:07.700124: Epoch time: 41.24 s 
2024-12-17 09:11:07.703632: Yayy! New best EMA pseudo Dice: 0.23819999396800995 
2024-12-17 09:11:08.424611:  
2024-12-17 09:11:08.430191: Epoch 9 
2024-12-17 09:11:08.432703: Current learning rate: 0.00919 
2024-12-17 09:11:49.661904: train_loss -0.5383 
2024-12-17 09:11:49.667926: val_loss -0.3627 
2024-12-17 09:11:49.670431: Pseudo dice [np.float32(0.4757)] 
2024-12-17 09:11:49.673938: Epoch time: 41.24 s 
2024-12-17 09:11:49.676944: Yayy! New best EMA pseudo Dice: 0.26190000772476196 
2024-12-17 09:11:50.371527:  
2024-12-17 09:11:50.376581: Epoch 10 
2024-12-17 09:11:50.379720: Current learning rate: 0.0091 
2024-12-17 09:12:31.617191: train_loss -0.4998 
2024-12-17 09:12:31.623748: val_loss -0.4418 
2024-12-17 09:12:31.626798: Pseudo dice [np.float32(0.5359)] 
2024-12-17 09:12:31.628823: Epoch time: 41.25 s 
2024-12-17 09:12:31.632378: Yayy! New best EMA pseudo Dice: 0.28929999470710754 
2024-12-17 09:12:32.318951:  
2024-12-17 09:12:32.324004: Epoch 11 
2024-12-17 09:12:32.327070: Current learning rate: 0.009 
2024-12-17 09:13:13.540976: train_loss -0.5473 
2024-12-17 09:13:13.548102: val_loss -0.4382 
2024-12-17 09:13:13.550610: Pseudo dice [np.float32(0.5022)] 
2024-12-17 09:13:13.554125: Epoch time: 41.22 s 
2024-12-17 09:13:13.556631: Yayy! New best EMA pseudo Dice: 0.31060001254081726 
2024-12-17 09:13:14.245843:  
2024-12-17 09:13:14.250856: Epoch 12 
2024-12-17 09:13:14.254369: Current learning rate: 0.00891 
2024-12-17 09:13:55.463552: train_loss -0.5488 
2024-12-17 09:13:55.470102: val_loss -0.4294 
2024-12-17 09:13:55.473616: Pseudo dice [np.float32(0.536)] 
2024-12-17 09:13:55.476127: Epoch time: 41.22 s 
2024-12-17 09:13:55.479173: Yayy! New best EMA pseudo Dice: 0.33320000767707825 
2024-12-17 09:13:56.325585:  
2024-12-17 09:13:56.331279: Epoch 13 
2024-12-17 09:13:56.334338: Current learning rate: 0.00882 
2024-12-17 09:14:37.547715: train_loss -0.5717 
2024-12-17 09:14:37.553481: val_loss -0.5115 
2024-12-17 09:14:37.556495: Pseudo dice [np.float32(0.5939)] 
2024-12-17 09:14:37.559531: Epoch time: 41.22 s 
2024-12-17 09:14:37.563542: Yayy! New best EMA pseudo Dice: 0.35920000076293945 
2024-12-17 09:14:38.273922:  
2024-12-17 09:14:38.277956: Epoch 14 
2024-12-17 09:14:38.281004: Current learning rate: 0.00873 
2024-12-17 09:15:19.478743: train_loss -0.5742 
2024-12-17 09:15:19.485313: val_loss -0.395 
2024-12-17 09:15:19.488823: Pseudo dice [np.float32(0.5028)] 
2024-12-17 09:15:19.492329: Epoch time: 41.21 s 
2024-12-17 09:15:19.495337: Yayy! New best EMA pseudo Dice: 0.3736000061035156 
2024-12-17 09:15:20.206842:  
2024-12-17 09:15:20.211853: Epoch 15 
2024-12-17 09:15:20.214862: Current learning rate: 0.00864 
2024-12-17 09:16:01.408478: train_loss -0.5906 
2024-12-17 09:16:01.414916: val_loss -0.3749 
2024-12-17 09:16:01.417428: Pseudo dice [np.float32(0.5293)] 
2024-12-17 09:16:01.420946: Epoch time: 41.2 s 
2024-12-17 09:16:01.423455: Yayy! New best EMA pseudo Dice: 0.38920000195503235 
2024-12-17 09:16:02.131820:  
2024-12-17 09:16:02.136617: Epoch 16 
2024-12-17 09:16:02.140128: Current learning rate: 0.00855 
2024-12-17 09:16:43.333503: train_loss -0.6264 
2024-12-17 09:16:43.339600: val_loss -0.4117 
2024-12-17 09:16:43.343110: Pseudo dice [np.float32(0.5747)] 
2024-12-17 09:16:43.346123: Epoch time: 41.2 s 
2024-12-17 09:16:43.348629: Yayy! New best EMA pseudo Dice: 0.4077000021934509 
2024-12-17 09:16:44.067691:  
2024-12-17 09:16:44.072675: Epoch 17 
2024-12-17 09:16:44.075394: Current learning rate: 0.00846 
2024-12-17 09:17:25.287650: train_loss -0.6229 
2024-12-17 09:17:25.293694: val_loss -0.4795 
2024-12-17 09:17:25.297220: Pseudo dice [np.float32(0.5871)] 
2024-12-17 09:17:25.300249: Epoch time: 41.22 s 
2024-12-17 09:17:25.302768: Yayy! New best EMA pseudo Dice: 0.42559999227523804 
2024-12-17 09:17:26.011197:  
2024-12-17 09:17:26.016760: Epoch 18 
2024-12-17 09:17:26.020870: Current learning rate: 0.00836 
2024-12-17 09:18:07.213870: train_loss -0.6564 
2024-12-17 09:18:07.219888: val_loss -0.3795 
2024-12-17 09:18:07.223393: Pseudo dice [np.float32(0.5424)] 
2024-12-17 09:18:07.226402: Epoch time: 41.2 s 
2024-12-17 09:18:07.228906: Yayy! New best EMA pseudo Dice: 0.4372999966144562 
2024-12-17 09:18:07.942844:  
2024-12-17 09:18:07.947858: Epoch 19 
2024-12-17 09:18:07.951366: Current learning rate: 0.00827 
2024-12-17 09:18:49.162415: train_loss -0.6245 
2024-12-17 09:18:49.168425: val_loss -0.4697 
2024-12-17 09:18:49.172436: Pseudo dice [np.float32(0.6062)] 
2024-12-17 09:18:49.175944: Epoch time: 41.22 s 
2024-12-17 09:18:49.178952: Yayy! New best EMA pseudo Dice: 0.45419999957084656 
2024-12-17 09:18:49.882999:  
2024-12-17 09:18:49.888549: Epoch 20 
2024-12-17 09:18:49.891097: Current learning rate: 0.00818 
2024-12-17 09:19:31.106292: train_loss -0.6516 
2024-12-17 09:19:31.112854: val_loss -0.5197 
2024-12-17 09:19:31.116360: Pseudo dice [np.float32(0.6642)] 
2024-12-17 09:19:31.119368: Epoch time: 41.22 s 
2024-12-17 09:19:31.121874: Yayy! New best EMA pseudo Dice: 0.47519999742507935 
2024-12-17 09:19:31.986771:  
2024-12-17 09:19:31.992326: Epoch 21 
2024-12-17 09:19:31.995883: Current learning rate: 0.00809 
2024-12-17 09:20:13.185760: train_loss -0.6009 
2024-12-17 09:20:13.193303: val_loss -0.4648 
2024-12-17 09:20:13.196841: Pseudo dice [np.float32(0.5351)] 
2024-12-17 09:20:13.199871: Epoch time: 41.2 s 
2024-12-17 09:20:13.202904: Yayy! New best EMA pseudo Dice: 0.4812000095844269 
2024-12-17 09:20:13.896971:  
2024-12-17 09:20:13.902000: Epoch 22 
2024-12-17 09:20:13.905010: Current learning rate: 0.008 
2024-12-17 09:20:55.107617: train_loss -0.6242 
2024-12-17 09:20:55.113639: val_loss -0.3885 
2024-12-17 09:20:55.116735: Pseudo dice [np.float32(0.5359)] 
2024-12-17 09:20:55.120249: Epoch time: 41.21 s 
2024-12-17 09:20:55.122761: Yayy! New best EMA pseudo Dice: 0.48669999837875366 
2024-12-17 09:20:55.820155:  
2024-12-17 09:20:55.825235: Epoch 23 
2024-12-17 09:20:55.828743: Current learning rate: 0.0079 
2024-12-17 09:21:37.027100: train_loss -0.6681 
2024-12-17 09:21:37.033111: val_loss -0.4644 
2024-12-17 09:21:37.036121: Pseudo dice [np.float32(0.5989)] 
2024-12-17 09:21:37.038627: Epoch time: 41.21 s 
2024-12-17 09:21:37.042137: Yayy! New best EMA pseudo Dice: 0.49790000915527344 
2024-12-17 09:21:37.727301:  
2024-12-17 09:21:37.732039: Epoch 24 
2024-12-17 09:21:37.735551: Current learning rate: 0.00781 
2024-12-17 09:22:18.945693: train_loss -0.6623 
2024-12-17 09:22:18.952763: val_loss -0.4805 
2024-12-17 09:22:18.955807: Pseudo dice [np.float32(0.6219)] 
2024-12-17 09:22:18.958852: Epoch time: 41.22 s 
2024-12-17 09:22:18.961384: Yayy! New best EMA pseudo Dice: 0.5102999806404114 
2024-12-17 09:22:19.648118:  
2024-12-17 09:22:19.653676: Epoch 25 
2024-12-17 09:22:19.657133: Current learning rate: 0.00772 
2024-12-17 09:23:02.861984: train_loss -0.6677 
2024-12-17 09:23:02.871066: val_loss -0.4689 
2024-12-17 09:23:02.875576: Pseudo dice [np.float32(0.5816)] 
2024-12-17 09:23:02.878584: Epoch time: 43.21 s 
2024-12-17 09:23:02.881089: Yayy! New best EMA pseudo Dice: 0.5174000263214111 
2024-12-17 09:23:03.588792:  
2024-12-17 09:23:03.593838: Epoch 26 
2024-12-17 09:23:03.597378: Current learning rate: 0.00763 
2024-12-17 09:23:44.785333: train_loss -0.6605 
2024-12-17 09:23:44.791379: val_loss -0.4829 
2024-12-17 09:23:44.794351: Pseudo dice [np.float32(0.6012)] 
2024-12-17 09:23:44.797864: Epoch time: 41.2 s 
2024-12-17 09:23:44.801377: Yayy! New best EMA pseudo Dice: 0.5257999897003174 
2024-12-17 09:23:45.491430:  
2024-12-17 09:23:45.496271: Epoch 27 
2024-12-17 09:23:45.499784: Current learning rate: 0.00753 
2024-12-17 09:24:26.690803: train_loss -0.6881 
2024-12-17 09:24:26.697332: val_loss -0.4071 
2024-12-17 09:24:26.700848: Pseudo dice [np.float32(0.5756)] 
2024-12-17 09:24:26.703274: Epoch time: 41.2 s 
2024-12-17 09:24:26.706788: Yayy! New best EMA pseudo Dice: 0.5307999849319458 
2024-12-17 09:24:27.413410:  
2024-12-17 09:24:27.418969: Epoch 28 
2024-12-17 09:24:27.422518: Current learning rate: 0.00744 
2024-12-17 09:25:08.613321: train_loss -0.6738 
2024-12-17 09:25:08.620394: val_loss -0.4935 
2024-12-17 09:25:08.623420: Pseudo dice [np.float32(0.6356)] 
2024-12-17 09:25:08.626458: Epoch time: 41.2 s 
2024-12-17 09:25:08.629987: Yayy! New best EMA pseudo Dice: 0.5412999987602234 
2024-12-17 09:25:09.473115:  
2024-12-17 09:25:09.478666: Epoch 29 
2024-12-17 09:25:09.481248: Current learning rate: 0.00735 
2024-12-17 09:25:50.676571: train_loss -0.699 
2024-12-17 09:25:50.681583: val_loss -0.4068 
2024-12-17 09:25:50.685590: Pseudo dice [np.float32(0.6088)] 
2024-12-17 09:25:50.688095: Epoch time: 41.2 s 
2024-12-17 09:25:50.691604: Yayy! New best EMA pseudo Dice: 0.5479999780654907 
2024-12-17 09:25:51.400878:  
2024-12-17 09:25:51.406984: Epoch 30 
2024-12-17 09:25:51.409790: Current learning rate: 0.00725 
2024-12-17 09:26:32.626764: train_loss -0.689 
2024-12-17 09:26:32.632345: val_loss -0.4491 
2024-12-17 09:26:32.635375: Pseudo dice [np.float32(0.5582)] 
2024-12-17 09:26:32.638402: Epoch time: 41.23 s 
2024-12-17 09:26:32.640921: Yayy! New best EMA pseudo Dice: 0.5490000247955322 
2024-12-17 09:26:33.364544:  
2024-12-17 09:26:33.370662: Epoch 31 
2024-12-17 09:26:33.374191: Current learning rate: 0.00716 
2024-12-17 09:27:14.634378: train_loss -0.6717 
2024-12-17 09:27:14.640925: val_loss -0.4326 
2024-12-17 09:27:14.644435: Pseudo dice [np.float32(0.5575)] 
2024-12-17 09:27:14.648444: Epoch time: 41.27 s 
2024-12-17 09:27:14.650957: Yayy! New best EMA pseudo Dice: 0.5498999953269958 
2024-12-17 09:27:15.364879:  
2024-12-17 09:27:15.370433: Epoch 32 
2024-12-17 09:27:15.373486: Current learning rate: 0.00707 
2024-12-17 09:27:56.649112: train_loss -0.6618 
2024-12-17 09:27:56.655693: val_loss -0.462 
2024-12-17 09:27:56.659263: Pseudo dice [np.float32(0.545)] 
2024-12-17 09:27:56.662300: Epoch time: 41.28 s 
2024-12-17 09:27:57.221292:  
2024-12-17 09:27:57.225304: Epoch 33 
2024-12-17 09:27:57.229314: Current learning rate: 0.00697 
2024-12-17 09:28:38.458459: train_loss -0.6609 
2024-12-17 09:28:38.463514: val_loss -0.2797 
2024-12-17 09:28:38.467600: Pseudo dice [np.float32(0.4542)] 
2024-12-17 09:28:38.471146: Epoch time: 41.24 s 
2024-12-17 09:28:39.017314:  
2024-12-17 09:28:39.023327: Epoch 34 
2024-12-17 09:28:39.026339: Current learning rate: 0.00688 
2024-12-17 09:29:20.250471: train_loss -0.652 
2024-12-17 09:29:20.257009: val_loss -0.477 
2024-12-17 09:29:20.259514: Pseudo dice [np.float32(0.5951)] 
2024-12-17 09:29:20.263022: Epoch time: 41.23 s 
2024-12-17 09:29:20.815809:  
2024-12-17 09:29:20.820820: Epoch 35 
2024-12-17 09:29:20.823832: Current learning rate: 0.00679 
2024-12-17 09:30:02.042396: train_loss -0.7 
2024-12-17 09:30:02.048326: val_loss -0.4046 
2024-12-17 09:30:02.051832: Pseudo dice [np.float32(0.4404)] 
2024-12-17 09:30:02.054842: Epoch time: 41.23 s 
2024-12-17 09:30:02.612616:  
2024-12-17 09:30:02.617626: Epoch 36 
2024-12-17 09:30:02.620634: Current learning rate: 0.00669 
2024-12-17 09:30:43.840259: train_loss -0.7018 
2024-12-17 09:30:43.845320: val_loss -0.4327 
2024-12-17 09:30:43.849328: Pseudo dice [np.float32(0.5858)] 
2024-12-17 09:30:43.852841: Epoch time: 41.23 s 
2024-12-17 09:30:44.557818:  
2024-12-17 09:30:44.563367: Epoch 37 
2024-12-17 09:30:44.566933: Current learning rate: 0.0066 
2024-12-17 09:31:25.783025: train_loss -0.7263 
2024-12-17 09:31:25.789114: val_loss -0.5118 
2024-12-17 09:31:25.792701: Pseudo dice [np.float32(0.6428)] 
2024-12-17 09:31:25.795745: Epoch time: 41.23 s 
2024-12-17 09:31:25.798802: Yayy! New best EMA pseudo Dice: 0.5503000020980835 
2024-12-17 09:31:26.521004:  
2024-12-17 09:31:26.527028: Epoch 38 
2024-12-17 09:31:26.529537: Current learning rate: 0.0065 
2024-12-17 09:32:07.745413: train_loss -0.7021 
2024-12-17 09:32:07.751506: val_loss -0.4396 
2024-12-17 09:32:07.755060: Pseudo dice [np.float32(0.533)] 
2024-12-17 09:32:07.758141: Epoch time: 41.22 s 
2024-12-17 09:32:08.322711:  
2024-12-17 09:32:08.326732: Epoch 39 
2024-12-17 09:32:08.330255: Current learning rate: 0.00641 
2024-12-17 09:32:49.537384: train_loss -0.7213 
2024-12-17 09:32:49.542926: val_loss -0.3626 
2024-12-17 09:32:49.545953: Pseudo dice [np.float32(0.5118)] 
2024-12-17 09:32:49.549471: Epoch time: 41.22 s 
2024-12-17 09:32:50.117710:  
2024-12-17 09:32:50.122795: Epoch 40 
2024-12-17 09:32:50.125874: Current learning rate: 0.00631 
2024-12-17 09:33:31.343270: train_loss -0.6987 
2024-12-17 09:33:31.348842: val_loss -0.4556 
2024-12-17 09:33:31.352446: Pseudo dice [np.float32(0.6041)] 
2024-12-17 09:33:31.355496: Epoch time: 41.23 s 
2024-12-17 09:33:31.359053: Yayy! New best EMA pseudo Dice: 0.5508000254631042 
2024-12-17 09:33:32.092458:  
2024-12-17 09:33:32.096531: Epoch 41 
2024-12-17 09:33:32.100087: Current learning rate: 0.00622 
2024-12-17 09:34:13.319519: train_loss -0.7072 
2024-12-17 09:34:13.326033: val_loss -0.3832 
2024-12-17 09:34:13.329543: Pseudo dice [np.float32(0.6009)] 
2024-12-17 09:34:13.333049: Epoch time: 41.23 s 
2024-12-17 09:34:13.336058: Yayy! New best EMA pseudo Dice: 0.5558000206947327 
2024-12-17 09:34:14.026534:  
2024-12-17 09:34:14.032047: Epoch 42 
2024-12-17 09:34:14.035064: Current learning rate: 0.00612 
2024-12-17 09:34:55.237644: train_loss -0.7038 
2024-12-17 09:34:55.244717: val_loss -0.4683 
2024-12-17 09:34:55.247751: Pseudo dice [np.float32(0.6497)] 
2024-12-17 09:34:55.251280: Epoch time: 41.21 s 
2024-12-17 09:34:55.254814: Yayy! New best EMA pseudo Dice: 0.5651999711990356 
2024-12-17 09:34:55.952334:  
2024-12-17 09:34:55.958404: Epoch 43 
2024-12-17 09:34:55.961466: Current learning rate: 0.00603 
2024-12-17 09:35:37.187979: train_loss -0.7124 
2024-12-17 09:35:37.193543: val_loss -0.4775 
2024-12-17 09:35:37.196577: Pseudo dice [np.float32(0.6661)] 
2024-12-17 09:35:37.200164: Epoch time: 41.24 s 
2024-12-17 09:35:37.203709: Yayy! New best EMA pseudo Dice: 0.5752999782562256 
2024-12-17 09:35:37.908302:  
2024-12-17 09:35:37.914485: Epoch 44 
2024-12-17 09:35:37.917994: Current learning rate: 0.00593 
2024-12-17 09:36:19.157695: train_loss -0.7127 
2024-12-17 09:36:19.161707: val_loss -0.5313 
2024-12-17 09:36:19.165278: Pseudo dice [np.float32(0.6684)] 
2024-12-17 09:36:19.168802: Epoch time: 41.25 s 
2024-12-17 09:36:19.171840: Yayy! New best EMA pseudo Dice: 0.5845999717712402 
2024-12-17 09:36:20.004977:  
2024-12-17 09:36:20.009998: Epoch 45 
2024-12-17 09:36:20.014013: Current learning rate: 0.00584 
2024-12-17 09:37:01.223034: train_loss -0.725 
2024-12-17 09:37:01.228618: val_loss -0.4637 
2024-12-17 09:37:01.233155: Pseudo dice [np.float32(0.5604)] 
2024-12-17 09:37:01.236664: Epoch time: 41.22 s 
2024-12-17 09:37:01.781287:  
2024-12-17 09:37:01.786323: Epoch 46 
2024-12-17 09:37:01.790357: Current learning rate: 0.00574 
2024-12-17 09:37:42.985603: train_loss -0.7233 
2024-12-17 09:37:42.991616: val_loss -0.4232 
2024-12-17 09:37:42.995626: Pseudo dice [np.float32(0.6011)] 
2024-12-17 09:37:42.999135: Epoch time: 41.2 s 
2024-12-17 09:37:43.528717:  
2024-12-17 09:37:43.533742: Epoch 47 
2024-12-17 09:37:43.537825: Current learning rate: 0.00565 
2024-12-17 09:38:24.745934: train_loss -0.698 
2024-12-17 09:38:24.752475: val_loss -0.4435 
2024-12-17 09:38:24.756487: Pseudo dice [np.float32(0.5631)] 
2024-12-17 09:38:24.758993: Epoch time: 41.22 s 
2024-12-17 09:38:25.296633:  
2024-12-17 09:38:25.302203: Epoch 48 
2024-12-17 09:38:25.305351: Current learning rate: 0.00555 
2024-12-17 09:39:06.521204: train_loss -0.7338 
2024-12-17 09:39:06.528217: val_loss -0.4903 
2024-12-17 09:39:06.531227: Pseudo dice [np.float32(0.622)] 
2024-12-17 09:39:06.534735: Epoch time: 41.22 s 
2024-12-17 09:39:06.538241: Yayy! New best EMA pseudo Dice: 0.5860000252723694 
2024-12-17 09:39:07.242171:  
2024-12-17 09:39:07.247713: Epoch 49 
2024-12-17 09:39:07.250724: Current learning rate: 0.00546 
2024-12-17 09:39:48.473836: train_loss -0.7612 
2024-12-17 09:39:48.479847: val_loss -0.4877 
2024-12-17 09:39:48.482856: Pseudo dice [np.float32(0.6671)] 
2024-12-17 09:39:48.486367: Epoch time: 41.23 s 
2024-12-17 09:39:48.633485: Yayy! New best EMA pseudo Dice: 0.5940999984741211 
2024-12-17 09:39:49.337578:  
2024-12-17 09:39:49.343137: Epoch 50 
2024-12-17 09:39:49.346733: Current learning rate: 0.00536 
2024-12-17 09:40:30.563566: train_loss -0.726 
2024-12-17 09:40:30.572088: val_loss -0.481 
2024-12-17 09:40:30.575591: Pseudo dice [np.float32(0.6005)] 
2024-12-17 09:40:30.578599: Epoch time: 41.23 s 
2024-12-17 09:40:30.581104: Yayy! New best EMA pseudo Dice: 0.5946999788284302 
2024-12-17 09:40:31.280105:  
2024-12-17 09:40:31.285140: Epoch 51 
2024-12-17 09:40:31.288225: Current learning rate: 0.00526 
2024-12-17 09:41:12.514534: train_loss -0.7483 
2024-12-17 09:41:12.521076: val_loss -0.4224 
2024-12-17 09:41:12.523396: Pseudo dice [np.float32(0.6208)] 
2024-12-17 09:41:12.527498: Epoch time: 41.23 s 
2024-12-17 09:41:12.530555: Yayy! New best EMA pseudo Dice: 0.5972999930381775 
2024-12-17 09:41:13.234089:  
2024-12-17 09:41:13.239099: Epoch 52 
2024-12-17 09:41:13.243109: Current learning rate: 0.00517 
2024-12-17 09:41:54.472158: train_loss -0.7395 
2024-12-17 09:41:54.477671: val_loss -0.324 
2024-12-17 09:41:54.481186: Pseudo dice [np.float32(0.5337)] 
2024-12-17 09:41:54.484691: Epoch time: 41.24 s 
2024-12-17 09:41:55.172053:  
2024-12-17 09:41:55.177083: Epoch 53 
2024-12-17 09:41:55.180625: Current learning rate: 0.00507 
2024-12-17 09:42:36.406808: train_loss -0.7472 
2024-12-17 09:42:36.412403: val_loss -0.3789 
2024-12-17 09:42:36.416477: Pseudo dice [np.float32(0.5425)] 
2024-12-17 09:42:36.419502: Epoch time: 41.24 s 
2024-12-17 09:42:36.960608:  
2024-12-17 09:42:36.966638: Epoch 54 
2024-12-17 09:42:36.969442: Current learning rate: 0.00497 
2024-12-17 09:43:18.178348: train_loss -0.7464 
2024-12-17 09:43:18.185570: val_loss -0.2879 
2024-12-17 09:43:18.189132: Pseudo dice [np.float32(0.5063)] 
2024-12-17 09:43:18.192172: Epoch time: 41.22 s 
2024-12-17 09:43:18.739083:  
2024-12-17 09:43:18.744098: Epoch 55 
2024-12-17 09:43:18.747610: Current learning rate: 0.00487 
2024-12-17 09:43:59.976960: train_loss -0.7336 
2024-12-17 09:43:59.981972: val_loss -0.359 
2024-12-17 09:43:59.986988: Pseudo dice [np.float32(0.5287)] 
2024-12-17 09:43:59.991499: Epoch time: 41.24 s 
2024-12-17 09:44:00.538218:  
2024-12-17 09:44:00.543739: Epoch 56 
2024-12-17 09:44:00.547259: Current learning rate: 0.00478 
2024-12-17 09:44:41.778399: train_loss -0.7617 
2024-12-17 09:44:41.784459: val_loss -0.3762 
2024-12-17 09:44:41.788197: Pseudo dice [np.float32(0.5386)] 
2024-12-17 09:44:41.791712: Epoch time: 41.24 s 
2024-12-17 09:44:42.340376:  
2024-12-17 09:44:42.345391: Epoch 57 
2024-12-17 09:44:42.348901: Current learning rate: 0.00468 
2024-12-17 09:45:23.546013: train_loss -0.7448 
2024-12-17 09:45:23.551558: val_loss -0.4164 
2024-12-17 09:45:23.555070: Pseudo dice [np.float32(0.6253)] 
2024-12-17 09:45:23.558579: Epoch time: 41.21 s 
2024-12-17 09:45:24.102969:  
2024-12-17 09:45:24.108535: Epoch 58 
2024-12-17 09:45:24.111084: Current learning rate: 0.00458 
2024-12-17 09:46:05.309237: train_loss -0.7712 
2024-12-17 09:46:05.314816: val_loss -0.4756 
2024-12-17 09:46:05.318328: Pseudo dice [np.float32(0.6747)] 
2024-12-17 09:46:05.322341: Epoch time: 41.21 s 
2024-12-17 09:46:05.873712:  
2024-12-17 09:46:05.879749: Epoch 59 
2024-12-17 09:46:05.882793: Current learning rate: 0.00448 
2024-12-17 09:46:47.094759: train_loss -0.7821 
2024-12-17 09:46:47.100770: val_loss -0.2799 
2024-12-17 09:46:47.104781: Pseudo dice [np.float32(0.4886)] 
2024-12-17 09:46:47.108788: Epoch time: 41.22 s 
2024-12-17 09:46:47.792834:  
2024-12-17 09:46:47.798446: Epoch 60 
2024-12-17 09:46:47.801488: Current learning rate: 0.00438 
2024-12-17 09:47:29.008860: train_loss -0.7825 
2024-12-17 09:47:29.015383: val_loss -0.4086 
2024-12-17 09:47:29.018895: Pseudo dice [np.float32(0.5693)] 
2024-12-17 09:47:29.022408: Epoch time: 41.22 s 
2024-12-17 09:47:29.571888:  
2024-12-17 09:47:29.576451: Epoch 61 
2024-12-17 09:47:29.579508: Current learning rate: 0.00429 
2024-12-17 09:48:10.784981: train_loss -0.7695 
2024-12-17 09:48:10.792033: val_loss -0.3458 
2024-12-17 09:48:10.794573: Pseudo dice [np.float32(0.6094)] 
2024-12-17 09:48:10.799115: Epoch time: 41.21 s 
2024-12-17 09:48:11.358019:  
2024-12-17 09:48:11.363029: Epoch 62 
2024-12-17 09:48:11.366539: Current learning rate: 0.00419 
2024-12-17 09:48:52.569473: train_loss -0.7686 
2024-12-17 09:48:52.575027: val_loss -0.3813 
2024-12-17 09:48:52.579058: Pseudo dice [np.float32(0.5392)] 
2024-12-17 09:48:52.582589: Epoch time: 41.21 s 
2024-12-17 09:48:53.130267:  
2024-12-17 09:48:53.135792: Epoch 63 
2024-12-17 09:48:53.139307: Current learning rate: 0.00409 
2024-12-17 09:49:34.366323: train_loss -0.7773 
2024-12-17 09:49:34.372822: val_loss -0.3839 
2024-12-17 09:49:34.376839: Pseudo dice [np.float32(0.5748)] 
2024-12-17 09:49:34.380353: Epoch time: 41.24 s 
2024-12-17 09:49:34.928996:  
2024-12-17 09:49:34.933916: Epoch 64 
2024-12-17 09:49:34.937427: Current learning rate: 0.00399 
2024-12-17 09:50:16.137457: train_loss -0.7816 
2024-12-17 09:50:16.145045: val_loss -0.3889 
2024-12-17 09:50:16.148591: Pseudo dice [np.float32(0.5448)] 
2024-12-17 09:50:16.152602: Epoch time: 41.21 s 
2024-12-17 09:50:16.697480:  
2024-12-17 09:50:16.703047: Epoch 65 
2024-12-17 09:50:16.707106: Current learning rate: 0.00389 
2024-12-17 09:50:57.913863: train_loss -0.7918 
2024-12-17 09:50:57.920434: val_loss -0.3301 
2024-12-17 09:50:57.923481: Pseudo dice [np.float32(0.5886)] 
2024-12-17 09:50:57.926525: Epoch time: 41.22 s 
2024-12-17 09:50:58.480721:  
2024-12-17 09:50:58.484759: Epoch 66 
2024-12-17 09:50:58.488804: Current learning rate: 0.00379 
2024-12-17 09:51:39.701592: train_loss -0.7859 
2024-12-17 09:51:39.708632: val_loss -0.4531 
2024-12-17 09:51:39.712659: Pseudo dice [np.float32(0.6059)] 
2024-12-17 09:51:39.716178: Epoch time: 41.22 s 
2024-12-17 09:51:40.277212:  
2024-12-17 09:51:40.282245: Epoch 67 
2024-12-17 09:51:40.286260: Current learning rate: 0.00369 
2024-12-17 09:52:21.492882: train_loss -0.7634 
2024-12-17 09:52:21.500435: val_loss -0.3829 
2024-12-17 09:52:21.503955: Pseudo dice [np.float32(0.6186)] 
2024-12-17 09:52:21.507485: Epoch time: 41.22 s 
2024-12-17 09:52:22.211178:  
2024-12-17 09:52:22.216211: Epoch 68 
2024-12-17 09:52:22.220227: Current learning rate: 0.00359 
2024-12-17 09:53:03.419056: train_loss -0.7624 
2024-12-17 09:53:03.424670: val_loss -0.347 
2024-12-17 09:53:03.429233: Pseudo dice [np.float32(0.6068)] 
2024-12-17 09:53:03.432262: Epoch time: 41.21 s 
2024-12-17 09:53:03.993977:  
2024-12-17 09:53:03.998990: Epoch 69 
2024-12-17 09:53:04.003005: Current learning rate: 0.00349 
2024-12-17 09:53:45.184410: train_loss -0.7674 
2024-12-17 09:53:45.190949: val_loss -0.2853 
2024-12-17 09:53:45.194475: Pseudo dice [np.float32(0.4927)] 
2024-12-17 09:53:45.197999: Epoch time: 41.19 s 
2024-12-17 09:53:45.753661:  
2024-12-17 09:53:45.759673: Epoch 70 
2024-12-17 09:53:45.763683: Current learning rate: 0.00338 
2024-12-17 09:54:26.968971: train_loss -0.7851 
2024-12-17 09:54:26.974483: val_loss -0.3507 
2024-12-17 09:54:26.977993: Pseudo dice [np.float32(0.6572)] 
2024-12-17 09:54:26.982000: Epoch time: 41.22 s 
2024-12-17 09:54:27.534363:  
2024-12-17 09:54:27.539420: Epoch 71 
2024-12-17 09:54:27.542997: Current learning rate: 0.00328 
2024-12-17 09:55:08.732226: train_loss -0.7835 
2024-12-17 09:55:08.738320: val_loss -0.3211 
2024-12-17 09:55:08.742940: Pseudo dice [np.float32(0.5217)] 
2024-12-17 09:55:08.746450: Epoch time: 41.2 s 
2024-12-17 09:55:09.304317:  
2024-12-17 09:55:09.309874: Epoch 72 
2024-12-17 09:55:09.313440: Current learning rate: 0.00318 
2024-12-17 09:55:50.515665: train_loss -0.796 
2024-12-17 09:55:50.520676: val_loss -0.4179 
2024-12-17 09:55:50.524184: Pseudo dice [np.float32(0.6128)] 
2024-12-17 09:55:50.528196: Epoch time: 41.21 s 
2024-12-17 09:55:51.083044:  
2024-12-17 09:55:51.088070: Epoch 73 
2024-12-17 09:55:51.091589: Current learning rate: 0.00308 
2024-12-17 09:56:32.287216: train_loss -0.7898 
2024-12-17 09:56:32.294321: val_loss -0.4537 
2024-12-17 09:56:32.297869: Pseudo dice [np.float32(0.5666)] 
2024-12-17 09:56:32.301893: Epoch time: 41.2 s 
2024-12-17 09:56:32.865620:  
2024-12-17 09:56:32.870128: Epoch 74 
2024-12-17 09:56:32.874183: Current learning rate: 0.00297 
2024-12-17 09:57:14.077940: train_loss -0.7993 
2024-12-17 09:57:14.085243: val_loss -0.3133 
2024-12-17 09:57:14.088254: Pseudo dice [np.float32(0.5412)] 
2024-12-17 09:57:14.091767: Epoch time: 41.21 s 
2024-12-17 09:57:14.648736:  
2024-12-17 09:57:14.654249: Epoch 75 
2024-12-17 09:57:14.657757: Current learning rate: 0.00287 
2024-12-17 09:57:55.859869: train_loss -0.8056 
2024-12-17 09:57:55.867931: val_loss -0.337 
2024-12-17 09:57:55.872040: Pseudo dice [np.float32(0.5631)] 
2024-12-17 09:57:55.875565: Epoch time: 41.21 s 
2024-12-17 09:57:56.585769:  
2024-12-17 09:57:56.591828: Epoch 76 
2024-12-17 09:57:56.594893: Current learning rate: 0.00277 
2024-12-17 09:58:37.787189: train_loss -0.7937 
2024-12-17 09:58:37.792767: val_loss -0.4335 
2024-12-17 09:58:37.796800: Pseudo dice [np.float32(0.6344)] 
2024-12-17 09:58:37.799809: Epoch time: 41.2 s 
2024-12-17 09:58:38.369303:  
2024-12-17 09:58:38.374386: Epoch 77 
2024-12-17 09:58:38.377450: Current learning rate: 0.00266 
2024-12-17 09:59:19.625730: train_loss -0.8049 
2024-12-17 09:59:19.635288: val_loss -0.3908 
2024-12-17 09:59:19.638313: Pseudo dice [np.float32(0.6157)] 
2024-12-17 09:59:19.642365: Epoch time: 41.26 s 
2024-12-17 09:59:20.212490:  
2024-12-17 09:59:20.217533: Epoch 78 
2024-12-17 09:59:20.221577: Current learning rate: 0.00256 
2024-12-17 10:00:01.443875: train_loss -0.8186 
2024-12-17 10:00:01.450922: val_loss -0.393 
2024-12-17 10:00:01.455455: Pseudo dice [np.float32(0.6259)] 
2024-12-17 10:00:01.458964: Epoch time: 41.23 s 
2024-12-17 10:00:02.028094:  
2024-12-17 10:00:02.033111: Epoch 79 
2024-12-17 10:00:02.037126: Current learning rate: 0.00245 
2024-12-17 10:00:43.240063: train_loss -0.8148 
2024-12-17 10:00:43.246599: val_loss -0.2887 
2024-12-17 10:00:43.250107: Pseudo dice [np.float32(0.5027)] 
2024-12-17 10:00:43.254117: Epoch time: 41.21 s 
2024-12-17 10:00:43.824332:  
2024-12-17 10:00:43.829897: Epoch 80 
2024-12-17 10:00:43.833953: Current learning rate: 0.00235 
2024-12-17 10:01:25.028300: train_loss -0.8092 
2024-12-17 10:01:25.035815: val_loss -0.3465 
2024-12-17 10:01:25.039325: Pseudo dice [np.float32(0.5458)] 
2024-12-17 10:01:25.043331: Epoch time: 41.2 s 
2024-12-17 10:01:25.608988:  
2024-12-17 10:01:25.613016: Epoch 81 
2024-12-17 10:01:25.618083: Current learning rate: 0.00224 
2024-12-17 10:02:06.811177: train_loss -0.8211 
2024-12-17 10:02:06.817745: val_loss -0.2697 
2024-12-17 10:02:06.821293: Pseudo dice [np.float32(0.5673)] 
2024-12-17 10:02:06.825325: Epoch time: 41.2 s 
2024-12-17 10:02:07.399157:  
2024-12-17 10:02:07.404694: Epoch 82 
2024-12-17 10:02:07.408288: Current learning rate: 0.00214 
2024-12-17 10:02:48.618656: train_loss -0.8136 
2024-12-17 10:02:48.625189: val_loss -0.307 
2024-12-17 10:02:48.628790: Pseudo dice [np.float32(0.577)] 
2024-12-17 10:02:48.632813: Epoch time: 41.22 s 
2024-12-17 10:02:49.171947:  
2024-12-17 10:02:49.177012: Epoch 83 
2024-12-17 10:02:49.180522: Current learning rate: 0.00203 
2024-12-17 10:03:30.394392: train_loss -0.8238 
2024-12-17 10:03:30.399943: val_loss -0.2659 
2024-12-17 10:03:30.403680: Pseudo dice [np.float32(0.5692)] 
2024-12-17 10:03:30.406214: Epoch time: 41.22 s 
2024-12-17 10:03:31.089731:  
2024-12-17 10:03:31.096246: Epoch 84 
2024-12-17 10:03:31.099755: Current learning rate: 0.00192 
2024-12-17 10:04:12.318320: train_loss -0.8343 
2024-12-17 10:04:12.324929: val_loss -0.3418 
2024-12-17 10:04:12.328939: Pseudo dice [np.float32(0.6322)] 
2024-12-17 10:04:12.332447: Epoch time: 41.23 s 
2024-12-17 10:04:12.868855:  
2024-12-17 10:04:12.874395: Epoch 85 
2024-12-17 10:04:12.878957: Current learning rate: 0.00181 
2024-12-17 10:04:54.086574: train_loss -0.8223 
2024-12-17 10:04:54.091611: val_loss -0.2136 
2024-12-17 10:04:54.096149: Pseudo dice [np.float32(0.4139)] 
2024-12-17 10:04:54.099708: Epoch time: 41.22 s 
2024-12-17 10:04:54.634351:  
2024-12-17 10:04:54.637909: Epoch 86 
2024-12-17 10:04:54.641948: Current learning rate: 0.0017 
2024-12-17 10:05:35.839195: train_loss -0.7925 
2024-12-17 10:05:35.845262: val_loss -0.4266 
2024-12-17 10:05:35.848789: Pseudo dice [np.float32(0.6594)] 
2024-12-17 10:05:35.852350: Epoch time: 41.21 s 
2024-12-17 10:05:36.403166:  
2024-12-17 10:05:36.409719: Epoch 87 
2024-12-17 10:05:36.413240: Current learning rate: 0.00159 
2024-12-17 10:06:17.614616: train_loss -0.8132 
2024-12-17 10:06:17.621676: val_loss -0.2242 
2024-12-17 10:06:17.625205: Pseudo dice [np.float32(0.475)] 
2024-12-17 10:06:17.628775: Epoch time: 41.21 s 
2024-12-17 10:06:18.155713:  
2024-12-17 10:06:18.160740: Epoch 88 
2024-12-17 10:06:18.164781: Current learning rate: 0.00148 
2024-12-17 10:06:59.418764: train_loss -0.8238 
2024-12-17 10:06:59.425794: val_loss -0.2182 
2024-12-17 10:06:59.429302: Pseudo dice [np.float32(0.4905)] 
2024-12-17 10:06:59.433311: Epoch time: 41.26 s 
2024-12-17 10:06:59.974434:  
2024-12-17 10:06:59.980995: Epoch 89 
2024-12-17 10:06:59.985547: Current learning rate: 0.00137 
2024-12-17 10:07:41.223117: train_loss -0.834 
2024-12-17 10:07:41.229165: val_loss -0.3374 
2024-12-17 10:07:41.233692: Pseudo dice [np.float32(0.4972)] 
2024-12-17 10:07:41.237261: Epoch time: 41.25 s 
2024-12-17 10:07:41.764815:  
2024-12-17 10:07:41.770844: Epoch 90 
2024-12-17 10:07:41.774352: Current learning rate: 0.00126 
2024-12-17 10:08:22.982604: train_loss -0.8288 
2024-12-17 10:08:22.990124: val_loss -0.3271 
2024-12-17 10:08:22.994133: Pseudo dice [np.float32(0.5121)] 
2024-12-17 10:08:22.997641: Epoch time: 41.22 s 
2024-12-17 10:08:23.527148:  
2024-12-17 10:08:23.532106: Epoch 91 
2024-12-17 10:08:23.536619: Current learning rate: 0.00115 
2024-12-17 10:09:04.742826: train_loss -0.8256 
2024-12-17 10:09:04.749353: val_loss -0.3989 
2024-12-17 10:09:04.753473: Pseudo dice [np.float32(0.6142)] 
2024-12-17 10:09:04.757016: Epoch time: 41.22 s 
2024-12-17 10:09:05.443327:  
2024-12-17 10:09:05.448897: Epoch 92 
2024-12-17 10:09:05.453490: Current learning rate: 0.00103 
2024-12-17 10:09:46.669887: train_loss -0.8384 
2024-12-17 10:09:46.676930: val_loss -0.3712 
2024-12-17 10:09:46.680471: Pseudo dice [np.float32(0.5626)] 
2024-12-17 10:09:46.684059: Epoch time: 41.23 s 
2024-12-17 10:09:47.214262:  
2024-12-17 10:09:47.220276: Epoch 93 
2024-12-17 10:09:47.224295: Current learning rate: 0.00091 
2024-12-17 10:10:28.446682: train_loss -0.8141 
2024-12-17 10:10:28.453263: val_loss -0.3738 
2024-12-17 10:10:28.456776: Pseudo dice [np.float32(0.5986)] 
2024-12-17 10:10:28.460797: Epoch time: 41.23 s 
2024-12-17 10:10:29.000927:  
2024-12-17 10:10:29.007499: Epoch 94 
2024-12-17 10:10:29.011151: Current learning rate: 0.00079 
2024-12-17 10:11:10.246652: train_loss -0.8411 
2024-12-17 10:11:10.253761: val_loss -0.4067 
2024-12-17 10:11:10.257357: Pseudo dice [np.float32(0.626)] 
2024-12-17 10:11:10.261415: Epoch time: 41.25 s 
2024-12-17 10:11:10.792534:  
2024-12-17 10:11:10.798109: Epoch 95 
2024-12-17 10:11:10.801677: Current learning rate: 0.00067 
2024-12-17 10:11:52.009320: train_loss -0.8483 
2024-12-17 10:11:52.015904: val_loss -0.2888 
2024-12-17 10:11:52.018933: Pseudo dice [np.float32(0.4788)] 
2024-12-17 10:11:52.022446: Epoch time: 41.22 s 
2024-12-17 10:11:52.556694:  
2024-12-17 10:11:52.562285: Epoch 96 
2024-12-17 10:11:52.566346: Current learning rate: 0.00055 
2024-12-17 10:12:33.802565: train_loss -0.8354 
2024-12-17 10:12:33.809667: val_loss -0.4705 
2024-12-17 10:12:33.812713: Pseudo dice [np.float32(0.6238)] 
2024-12-17 10:12:33.817228: Epoch time: 41.25 s 
2024-12-17 10:12:34.364214:  
2024-12-17 10:12:34.369246: Epoch 97 
2024-12-17 10:12:34.373060: Current learning rate: 0.00043 
2024-12-17 10:13:15.597755: train_loss -0.84 
2024-12-17 10:13:15.605273: val_loss -0.2935 
2024-12-17 10:13:15.609286: Pseudo dice [np.float32(0.4795)] 
2024-12-17 10:13:15.613299: Epoch time: 41.23 s 
2024-12-17 10:13:16.166882:  
2024-12-17 10:13:16.172909: Epoch 98 
2024-12-17 10:13:16.176420: Current learning rate: 0.0003 
2024-12-17 10:13:57.387609: train_loss -0.8404 
2024-12-17 10:13:57.394157: val_loss -0.4143 
2024-12-17 10:13:57.397168: Pseudo dice [np.float32(0.5536)] 
2024-12-17 10:13:57.401681: Epoch time: 41.22 s 
2024-12-17 10:13:57.935996:  
2024-12-17 10:13:57.941562: Epoch 99 
2024-12-17 10:13:57.945622: Current learning rate: 0.00016 
2024-12-17 10:14:39.159839: train_loss -0.826 
2024-12-17 10:14:39.166358: val_loss -0.3184 
2024-12-17 10:14:39.169869: Pseudo dice [np.float32(0.5497)] 
2024-12-17 10:14:39.173377: Epoch time: 41.22 s 
2024-12-17 10:14:39.909637: Training done. 
2024-12-17 10:14:39.944638: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset010_Colon\splits_final.json 
2024-12-17 10:14:39.951641: The split file contains 5 splits. 
2024-12-17 10:14:39.956638: Desired fold for training: 0 
2024-12-17 10:14:39.961643: This split has 100 training and 26 validation cases. 
2024-12-17 10:14:39.965642: predicting colon_008 
2024-12-17 10:14:39.970642: colon_008, shape torch.Size([1, 149, 465, 465]), rank 0 
2024-12-17 10:14:42.559040: predicting colon_027 
2024-12-17 10:14:42.578127: colon_027, shape torch.Size([1, 63, 440, 440]), rank 0 
2024-12-17 10:14:43.358789: predicting colon_030 
2024-12-17 10:14:43.370793: colon_030, shape torch.Size([1, 149, 384, 384]), rank 0 
2024-12-17 10:14:44.471839: predicting colon_033 
2024-12-17 10:14:44.487343: colon_033, shape torch.Size([1, 162, 480, 480]), rank 0 
2024-12-17 10:14:46.426007: predicting colon_041 
2024-12-17 10:14:46.449009: colon_041, shape torch.Size([1, 173, 591, 591]), rank 0 
2024-12-17 10:14:51.625411: predicting colon_042 
2024-12-17 10:14:51.665414: colon_042, shape torch.Size([1, 92, 640, 640]), rank 0 
2024-12-17 10:14:54.292542: predicting colon_061 
2024-12-17 10:14:54.314543: colon_061, shape torch.Size([1, 142, 529, 529]), rank 0 
2024-12-17 10:14:57.333965: predicting colon_074 
2024-12-17 10:14:57.360969: colon_074, shape torch.Size([1, 133, 607, 607]), rank 0 
2024-12-17 10:15:00.824164: predicting colon_075 
2024-12-17 10:15:00.853163: colon_075, shape torch.Size([1, 143, 474, 474]), rank 0 
2024-12-17 10:15:02.810848: predicting colon_088 
2024-12-17 10:15:02.842848: colon_088, shape torch.Size([1, 158, 563, 563]), rank 0 
2024-12-17 10:15:05.904078: predicting colon_091 
2024-12-17 10:15:05.934079: colon_091, shape torch.Size([1, 171, 543, 543]), rank 0 
2024-12-17 10:15:09.559401: predicting colon_092 
2024-12-17 10:15:09.587915: colon_092, shape torch.Size([1, 150, 492, 492]), rank 0 
2024-12-17 10:15:12.589638: predicting colon_095 
2024-12-17 10:15:12.613640: colon_095, shape torch.Size([1, 160, 452, 452]), rank 0 
2024-12-17 10:15:14.560338: predicting colon_102 
2024-12-17 10:15:14.581339: colon_102, shape torch.Size([1, 160, 590, 590]), rank 0 
2024-12-17 10:15:18.909097: predicting colon_111 
2024-12-17 10:15:18.944097: colon_111, shape torch.Size([1, 80, 521, 521]), rank 0 
2024-12-17 10:15:20.194740: predicting colon_115 
2024-12-17 10:15:20.212740: colon_115, shape torch.Size([1, 162, 470, 470]), rank 0 
2024-12-17 10:15:22.149307: predicting colon_118 
2024-12-17 10:15:22.173311: colon_118, shape torch.Size([1, 166, 486, 486]), rank 0 
2024-12-17 10:15:25.202250: predicting colon_124 
2024-12-17 10:15:25.228250: colon_124, shape torch.Size([1, 153, 535, 535]), rank 0 
2024-12-17 10:15:28.243584: predicting colon_127 
2024-12-17 10:15:28.267584: colon_127, shape torch.Size([1, 216, 598, 598]), rank 0 
2024-12-17 10:15:34.296604: predicting colon_154 
2024-12-17 10:15:34.333605: colon_154, shape torch.Size([1, 158, 461, 461]), rank 0 
2024-12-17 10:15:36.282385: predicting colon_161 
2024-12-17 10:15:36.303893: colon_161, shape torch.Size([1, 158, 474, 474]), rank 0 
2024-12-17 10:15:38.255096: predicting colon_162 
2024-12-17 10:15:38.282100: colon_162, shape torch.Size([1, 173, 598, 598]), rank 0 
2024-12-17 10:15:43.448933: predicting colon_165 
2024-12-17 10:15:43.496444: colon_165, shape torch.Size([1, 142, 577, 577]), rank 0 
2024-12-17 10:15:47.840173: predicting colon_166 
2024-12-17 10:15:47.879173: colon_166, shape torch.Size([1, 145, 474, 474]), rank 0 
2024-12-17 10:15:49.894203: predicting colon_169 
2024-12-17 10:15:49.917648: colon_169, shape torch.Size([1, 215, 621, 621]), rank 0 
2024-12-17 10:15:56.023873: predicting colon_187 
2024-12-17 10:15:56.060873: colon_187, shape torch.Size([1, 157, 513, 513]), rank 0 
2024-12-17 10:16:12.426388: Validation complete 
2024-12-17 10:16:12.432389: Mean Validation Dice:  0.3229367049017003 
