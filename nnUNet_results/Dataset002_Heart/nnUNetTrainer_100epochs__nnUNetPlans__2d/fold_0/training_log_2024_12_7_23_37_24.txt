
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-07 23:37:24.675637: do_dummy_2d_data_aug: False 
2024-12-07 23:37:24.676635: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-07 23:37:24.681636: The split file contains 5 splits. 
2024-12-07 23:37:24.686145: Desired fold for training: 0 
2024-12-07 23:37:24.689154: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 40, 'patch_size': [320, 256], 'median_image_size_in_voxels': [320.0, 232.0], 'spacing': [1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2024-12-07 23:37:33.266788: unpacking dataset... 
2024-12-07 23:37:33.513990: unpacking done... 
2024-12-07 23:37:35.917096:  
2024-12-07 23:37:35.921111: Epoch 0 
2024-12-07 23:37:35.925116: Current learning rate: 0.01 
2024-12-07 23:38:22.632763: train_loss -0.4052 
2024-12-07 23:38:22.640865: val_loss -0.8622 
2024-12-07 23:38:22.645702: Pseudo dice [np.float32(0.8849)] 
2024-12-07 23:38:22.648212: Epoch time: 46.72 s 
2024-12-07 23:38:22.651565: Yayy! New best EMA pseudo Dice: 0.8848999738693237 
2024-12-07 23:38:23.316070:  
2024-12-07 23:38:23.321152: Epoch 1 
2024-12-07 23:38:23.325205: Current learning rate: 0.00991 
2024-12-07 23:39:03.756530: train_loss -0.8586 
2024-12-07 23:39:03.764709: val_loss -0.8867 
2024-12-07 23:39:03.769278: Pseudo dice [np.float32(0.9026)] 
2024-12-07 23:39:03.772321: Epoch time: 40.44 s 
2024-12-07 23:39:03.774863: Yayy! New best EMA pseudo Dice: 0.8866999745368958 
2024-12-07 23:39:04.527619:  
2024-12-07 23:39:04.533167: Epoch 2 
2024-12-07 23:39:04.537212: Current learning rate: 0.00982 
2024-12-07 23:39:45.078494: train_loss -0.8912 
2024-12-07 23:39:45.086098: val_loss -0.8927 
2024-12-07 23:39:45.090621: Pseudo dice [np.float32(0.9097)] 
2024-12-07 23:39:45.096144: Epoch time: 40.55 s 
2024-12-07 23:39:45.099651: Yayy! New best EMA pseudo Dice: 0.8889999985694885 
2024-12-07 23:39:45.907772:  
2024-12-07 23:39:45.912858: Epoch 3 
2024-12-07 23:39:45.916910: Current learning rate: 0.00973 
2024-12-07 23:40:25.752507: train_loss -0.9077 
2024-12-07 23:40:25.760629: val_loss -0.9061 
2024-12-07 23:40:25.765255: Pseudo dice [np.float32(0.9213)] 
2024-12-07 23:40:25.770335: Epoch time: 39.85 s 
2024-12-07 23:40:25.773870: Yayy! New best EMA pseudo Dice: 0.8921999931335449 
2024-12-07 23:40:26.534533:  
2024-12-07 23:40:26.540559: Epoch 4 
2024-12-07 23:40:26.545705: Current learning rate: 0.00964 
2024-12-07 23:41:06.580474: train_loss -0.9165 
2024-12-07 23:41:06.588997: val_loss -0.9045 
2024-12-07 23:41:06.593016: Pseudo dice [np.float32(0.9177)] 
2024-12-07 23:41:06.597534: Epoch time: 40.05 s 
2024-12-07 23:41:06.602069: Yayy! New best EMA pseudo Dice: 0.8948000073432922 
2024-12-07 23:41:07.543461:  
2024-12-07 23:41:07.549540: Epoch 5 
2024-12-07 23:41:07.553605: Current learning rate: 0.00955 
2024-12-07 23:41:48.110735: train_loss -0.9225 
2024-12-07 23:41:48.117329: val_loss -0.9012 
2024-12-07 23:41:48.124420: Pseudo dice [np.float32(0.9149)] 
2024-12-07 23:41:48.128453: Epoch time: 40.57 s 
2024-12-07 23:41:48.135559: Yayy! New best EMA pseudo Dice: 0.8967999815940857 
2024-12-07 23:41:48.958007:  
2024-12-07 23:41:48.964109: Epoch 6 
2024-12-07 23:41:48.967979: Current learning rate: 0.00946 
2024-12-07 23:42:29.459716: train_loss -0.9305 
2024-12-07 23:42:29.466248: val_loss -0.9076 
2024-12-07 23:42:29.473127: Pseudo dice [np.float32(0.9214)] 
2024-12-07 23:42:29.479147: Epoch time: 40.5 s 
2024-12-07 23:42:29.483158: Yayy! New best EMA pseudo Dice: 0.8992000222206116 
2024-12-07 23:42:30.268813:  
2024-12-07 23:42:30.274648: Epoch 7 
2024-12-07 23:42:30.281170: Current learning rate: 0.00937 
2024-12-07 23:43:11.264622: train_loss -0.9321 
2024-12-07 23:43:11.270786: val_loss -0.906 
2024-12-07 23:43:11.277408: Pseudo dice [np.float32(0.9198)] 
2024-12-07 23:43:11.282482: Epoch time: 41.0 s 
2024-12-07 23:43:11.287604: Yayy! New best EMA pseudo Dice: 0.9013000130653381 
2024-12-07 23:43:12.060224:  
2024-12-07 23:43:12.065769: Epoch 8 
2024-12-07 23:43:12.069501: Current learning rate: 0.00928 
2024-12-07 23:43:52.440467: train_loss -0.9382 
2024-12-07 23:43:52.447060: val_loss -0.9104 
2024-12-07 23:43:52.453668: Pseudo dice [np.float32(0.9214)] 
2024-12-07 23:43:52.458728: Epoch time: 40.38 s 
2024-12-07 23:43:52.462281: Yayy! New best EMA pseudo Dice: 0.9032999873161316 
2024-12-07 23:43:53.285825:  
2024-12-07 23:43:53.291453: Epoch 9 
2024-12-07 23:43:53.293982: Current learning rate: 0.00919 
2024-12-07 23:44:33.118572: train_loss -0.9399 
2024-12-07 23:44:33.126746: val_loss -0.9105 
2024-12-07 23:44:33.131841: Pseudo dice [np.float32(0.9234)] 
2024-12-07 23:44:33.135407: Epoch time: 39.83 s 
2024-12-07 23:44:33.140036: Yayy! New best EMA pseudo Dice: 0.9053000211715698 
2024-12-07 23:44:33.886274:  
2024-12-07 23:44:33.892808: Epoch 10 
2024-12-07 23:44:33.896317: Current learning rate: 0.0091 
2024-12-07 23:45:14.233624: train_loss -0.9398 
2024-12-07 23:45:14.240215: val_loss -0.9097 
2024-12-07 23:45:14.246283: Pseudo dice [np.float32(0.9228)] 
2024-12-07 23:45:14.250994: Epoch time: 40.35 s 
2024-12-07 23:45:14.257069: Yayy! New best EMA pseudo Dice: 0.9071000218391418 
2024-12-07 23:45:15.011617:  
2024-12-07 23:45:15.018223: Epoch 11 
2024-12-07 23:45:15.021815: Current learning rate: 0.009 
2024-12-07 23:45:56.678298: train_loss -0.9428 
2024-12-07 23:45:56.684815: val_loss -0.9076 
2024-12-07 23:45:56.690354: Pseudo dice [np.float32(0.9203)] 
2024-12-07 23:45:56.694934: Epoch time: 41.67 s 
2024-12-07 23:45:56.698446: Yayy! New best EMA pseudo Dice: 0.9083999991416931 
2024-12-07 23:45:57.463639:  
2024-12-07 23:45:57.470276: Epoch 12 
2024-12-07 23:45:57.475348: Current learning rate: 0.00891 
2024-12-07 23:46:38.860007: train_loss -0.9463 
2024-12-07 23:46:38.869586: val_loss -0.9133 
2024-12-07 23:46:38.874601: Pseudo dice [np.float32(0.9254)] 
2024-12-07 23:46:38.879186: Epoch time: 41.4 s 
2024-12-07 23:46:38.882196: Yayy! New best EMA pseudo Dice: 0.910099983215332 
2024-12-07 23:46:39.832713:  
2024-12-07 23:46:39.838781: Epoch 13 
2024-12-07 23:46:39.842803: Current learning rate: 0.00882 
2024-12-07 23:47:19.883880: train_loss -0.9488 
2024-12-07 23:47:19.890998: val_loss -0.9069 
2024-12-07 23:47:19.896014: Pseudo dice [np.float32(0.9192)] 
2024-12-07 23:47:19.900565: Epoch time: 40.05 s 
2024-12-07 23:47:19.904074: Yayy! New best EMA pseudo Dice: 0.9110000133514404 
2024-12-07 23:47:20.668534:  
2024-12-07 23:47:20.674646: Epoch 14 
2024-12-07 23:47:20.677674: Current learning rate: 0.00873 
2024-12-07 23:47:59.752393: train_loss -0.949 
2024-12-07 23:47:59.758927: val_loss -0.9147 
2024-12-07 23:47:59.764960: Pseudo dice [np.float32(0.9264)] 
2024-12-07 23:47:59.771164: Epoch time: 39.08 s 
2024-12-07 23:47:59.775677: Yayy! New best EMA pseudo Dice: 0.9125999808311462 
2024-12-07 23:48:00.543523:  
2024-12-07 23:48:00.548550: Epoch 15 
2024-12-07 23:48:00.552125: Current learning rate: 0.00864 
2024-12-07 23:48:39.813071: train_loss -0.9505 
2024-12-07 23:48:39.822207: val_loss -0.9172 
2024-12-07 23:48:39.827492: Pseudo dice [np.float32(0.9287)] 
2024-12-07 23:48:39.833065: Epoch time: 39.27 s 
2024-12-07 23:48:39.836106: Yayy! New best EMA pseudo Dice: 0.9142000079154968 
2024-12-07 23:48:40.607239:  
2024-12-07 23:48:40.612803: Epoch 16 
2024-12-07 23:48:40.618430: Current learning rate: 0.00855 
2024-12-07 23:49:20.970206: train_loss -0.9511 
2024-12-07 23:49:20.978751: val_loss -0.9156 
2024-12-07 23:49:20.985397: Pseudo dice [np.float32(0.9278)] 
2024-12-07 23:49:20.990432: Epoch time: 40.36 s 
2024-12-07 23:49:20.993443: Yayy! New best EMA pseudo Dice: 0.9154999852180481 
2024-12-07 23:49:21.802390:  
2024-12-07 23:49:21.807907: Epoch 17 
2024-12-07 23:49:21.814922: Current learning rate: 0.00846 
2024-12-07 23:50:01.905700: train_loss -0.9525 
2024-12-07 23:50:01.912296: val_loss -0.9124 
2024-12-07 23:50:01.917953: Pseudo dice [np.float32(0.9246)] 
2024-12-07 23:50:01.921509: Epoch time: 40.1 s 
2024-12-07 23:50:01.925571: Yayy! New best EMA pseudo Dice: 0.9164000153541565 
2024-12-07 23:50:02.721615:  
2024-12-07 23:50:02.728742: Epoch 18 
2024-12-07 23:50:02.731274: Current learning rate: 0.00836 
2024-12-07 23:50:42.624002: train_loss -0.9549 
2024-12-07 23:50:42.633524: val_loss -0.9178 
2024-12-07 23:50:42.638100: Pseudo dice [np.float32(0.9299)] 
2024-12-07 23:50:42.643011: Epoch time: 39.9 s 
2024-12-07 23:50:42.647047: Yayy! New best EMA pseudo Dice: 0.9178000092506409 
2024-12-07 23:50:43.437251:  
2024-12-07 23:50:43.444427: Epoch 19 
2024-12-07 23:50:43.448995: Current learning rate: 0.00827 
2024-12-07 23:51:24.901740: train_loss -0.9552 
2024-12-07 23:51:24.909289: val_loss -0.9137 
2024-12-07 23:51:24.913317: Pseudo dice [np.float32(0.9253)] 
2024-12-07 23:51:24.915821: Epoch time: 41.46 s 
2024-12-07 23:51:24.919907: Yayy! New best EMA pseudo Dice: 0.9185000061988831 
2024-12-07 23:51:25.685329:  
2024-12-07 23:51:25.690844: Epoch 20 
2024-12-07 23:51:25.695862: Current learning rate: 0.00818 
2024-12-07 23:52:03.594110: train_loss -0.9559 
2024-12-07 23:52:03.600628: val_loss -0.9061 
2024-12-07 23:52:03.603134: Pseudo dice [np.float32(0.9189)] 
2024-12-07 23:52:03.607647: Epoch time: 37.91 s 
2024-12-07 23:52:03.611250: Yayy! New best EMA pseudo Dice: 0.9186000227928162 
2024-12-07 23:52:04.500617:  
2024-12-07 23:52:04.506671: Epoch 21 
2024-12-07 23:52:04.509699: Current learning rate: 0.00809 
2024-12-07 23:52:42.320429: train_loss -0.957 
2024-12-07 23:52:42.326449: val_loss -0.9096 
2024-12-07 23:52:42.330844: Pseudo dice [np.float32(0.9217)] 
2024-12-07 23:52:42.333878: Epoch time: 37.82 s 
2024-12-07 23:52:42.337387: Yayy! New best EMA pseudo Dice: 0.9189000129699707 
2024-12-07 23:52:43.082821:  
2024-12-07 23:52:43.088873: Epoch 22 
2024-12-07 23:52:43.092353: Current learning rate: 0.008 
2024-12-07 23:53:21.402926: train_loss -0.9575 
2024-12-07 23:53:21.409457: val_loss -0.9095 
2024-12-07 23:53:21.414541: Pseudo dice [np.float32(0.922)] 
2024-12-07 23:53:21.418591: Epoch time: 38.32 s 
2024-12-07 23:53:21.421108: Yayy! New best EMA pseudo Dice: 0.9192000031471252 
2024-12-07 23:53:22.138476:  
2024-12-07 23:53:22.144533: Epoch 23 
2024-12-07 23:53:22.147602: Current learning rate: 0.0079 
2024-12-07 23:54:00.620328: train_loss -0.9569 
2024-12-07 23:54:00.626866: val_loss -0.9077 
2024-12-07 23:54:00.631882: Pseudo dice [np.float32(0.9203)] 
2024-12-07 23:54:00.635393: Epoch time: 38.48 s 
2024-12-07 23:54:00.637904: Yayy! New best EMA pseudo Dice: 0.9193000197410583 
2024-12-07 23:54:01.437687:  
2024-12-07 23:54:01.443232: Epoch 24 
2024-12-07 23:54:01.445795: Current learning rate: 0.00781 
2024-12-07 23:54:40.307919: train_loss -0.9584 
2024-12-07 23:54:40.313958: val_loss -0.9098 
2024-12-07 23:54:40.319556: Pseudo dice [np.float32(0.9216)] 
2024-12-07 23:54:40.323601: Epoch time: 38.87 s 
2024-12-07 23:54:40.327148: Yayy! New best EMA pseudo Dice: 0.9194999933242798 
2024-12-07 23:54:41.071652:  
2024-12-07 23:54:41.077669: Epoch 25 
2024-12-07 23:54:41.081676: Current learning rate: 0.00772 
2024-12-07 23:55:20.799997: train_loss -0.9593 
2024-12-07 23:55:20.807037: val_loss -0.9115 
2024-12-07 23:55:20.812585: Pseudo dice [np.float32(0.9238)] 
2024-12-07 23:55:20.815592: Epoch time: 39.73 s 
2024-12-07 23:55:20.820662: Yayy! New best EMA pseudo Dice: 0.9200000166893005 
2024-12-07 23:55:21.561886:  
2024-12-07 23:55:21.567400: Epoch 26 
2024-12-07 23:55:21.570908: Current learning rate: 0.00763 
2024-12-07 23:56:00.770022: train_loss -0.9596 
2024-12-07 23:56:00.776038: val_loss -0.8997 
2024-12-07 23:56:00.780056: Pseudo dice [np.float32(0.9146)] 
2024-12-07 23:56:00.785067: Epoch time: 39.21 s 
2024-12-07 23:56:01.334325:  
2024-12-07 23:56:01.340384: Epoch 27 
2024-12-07 23:56:01.343405: Current learning rate: 0.00753 
2024-12-07 23:56:40.738225: train_loss -0.9596 
2024-12-07 23:56:40.745306: val_loss -0.9103 
2024-12-07 23:56:40.749854: Pseudo dice [np.float32(0.9223)] 
2024-12-07 23:56:40.754415: Epoch time: 39.4 s 
2024-12-07 23:56:41.321932:  
2024-12-07 23:56:41.327559: Epoch 28 
2024-12-07 23:56:41.333153: Current learning rate: 0.00744 
2024-12-07 23:57:20.062181: train_loss -0.9614 
2024-12-07 23:57:20.068196: val_loss -0.9078 
2024-12-07 23:57:20.073212: Pseudo dice [np.float32(0.9205)] 
2024-12-07 23:57:20.078222: Epoch time: 38.74 s 
2024-12-07 23:57:20.791471:  
2024-12-07 23:57:20.796982: Epoch 29 
2024-12-07 23:57:20.801995: Current learning rate: 0.00735 
2024-12-07 23:57:59.698589: train_loss -0.9623 
2024-12-07 23:57:59.705636: val_loss -0.9073 
2024-12-07 23:57:59.711190: Pseudo dice [np.float32(0.9198)] 
2024-12-07 23:57:59.715714: Epoch time: 38.91 s 
2024-12-07 23:58:00.280235:  
2024-12-07 23:58:00.286251: Epoch 30 
2024-12-07 23:58:00.288755: Current learning rate: 0.00725 
2024-12-07 23:58:39.495034: train_loss -0.9624 
2024-12-07 23:58:39.502160: val_loss -0.9155 
2024-12-07 23:58:39.508268: Pseudo dice [np.float32(0.9267)] 
2024-12-07 23:58:39.511794: Epoch time: 39.22 s 
2024-12-07 23:58:39.514831: Yayy! New best EMA pseudo Dice: 0.9204999804496765 
2024-12-07 23:58:40.279283:  
2024-12-07 23:58:40.284834: Epoch 31 
2024-12-07 23:58:40.287369: Current learning rate: 0.00716 
2024-12-07 23:59:19.005663: train_loss -0.9634 
2024-12-07 23:59:19.012823: val_loss -0.9088 
2024-12-07 23:59:19.018913: Pseudo dice [np.float32(0.9209)] 
2024-12-07 23:59:19.022499: Epoch time: 38.73 s 
2024-12-07 23:59:19.026023: Yayy! New best EMA pseudo Dice: 0.9204999804496765 
2024-12-07 23:59:19.779840:  
2024-12-07 23:59:19.785883: Epoch 32 
2024-12-07 23:59:19.789443: Current learning rate: 0.00707 
2024-12-07 23:59:59.576986: train_loss -0.9627 
2024-12-07 23:59:59.583097: val_loss -0.915 
2024-12-07 23:59:59.587161: Pseudo dice [np.float32(0.9267)] 
2024-12-07 23:59:59.592301: Epoch time: 39.8 s 
2024-12-07 23:59:59.595850: Yayy! New best EMA pseudo Dice: 0.9211000204086304 
2024-12-08 00:00:00.354114:  
2024-12-08 00:00:00.359169: Epoch 33 
2024-12-08 00:00:00.362205: Current learning rate: 0.00697 
2024-12-08 00:00:40.170621: train_loss -0.9636 
2024-12-08 00:00:40.177775: val_loss -0.9135 
2024-12-08 00:00:40.184432: Pseudo dice [np.float32(0.9252)] 
2024-12-08 00:00:40.187976: Epoch time: 39.82 s 
2024-12-08 00:00:40.192022: Yayy! New best EMA pseudo Dice: 0.921500027179718 
2024-12-08 00:00:40.959682:  
2024-12-08 00:00:40.965232: Epoch 34 
2024-12-08 00:00:40.970802: Current learning rate: 0.00688 
2024-12-08 00:01:20.377624: train_loss -0.9635 
2024-12-08 00:01:20.385178: val_loss -0.9104 
2024-12-08 00:01:20.390189: Pseudo dice [np.float32(0.9226)] 
2024-12-08 00:01:20.395204: Epoch time: 39.42 s 
2024-12-08 00:01:20.399714: Yayy! New best EMA pseudo Dice: 0.9215999841690063 
2024-12-08 00:01:21.168582:  
2024-12-08 00:01:21.174109: Epoch 35 
2024-12-08 00:01:21.177188: Current learning rate: 0.00679 
2024-12-08 00:02:00.083730: train_loss -0.964 
2024-12-08 00:02:00.090845: val_loss -0.9117 
2024-12-08 00:02:00.095353: Pseudo dice [np.float32(0.9236)] 
2024-12-08 00:02:00.100870: Epoch time: 38.92 s 
2024-12-08 00:02:00.104378: Yayy! New best EMA pseudo Dice: 0.9218000173568726 
2024-12-08 00:02:00.891627:  
2024-12-08 00:02:00.897738: Epoch 36 
2024-12-08 00:02:00.902328: Current learning rate: 0.00669 
2024-12-08 00:02:40.634007: train_loss -0.9646 
2024-12-08 00:02:40.641139: val_loss -0.9136 
2024-12-08 00:02:40.646728: Pseudo dice [np.float32(0.9251)] 
2024-12-08 00:02:40.651792: Epoch time: 39.74 s 
2024-12-08 00:02:40.656407: Yayy! New best EMA pseudo Dice: 0.9222000241279602 
2024-12-08 00:02:41.582724:  
2024-12-08 00:02:41.588264: Epoch 37 
2024-12-08 00:02:41.591825: Current learning rate: 0.0066 
2024-12-08 00:03:20.569113: train_loss -0.9637 
2024-12-08 00:03:20.576670: val_loss -0.9127 
2024-12-08 00:03:20.582339: Pseudo dice [np.float32(0.924)] 
2024-12-08 00:03:20.586883: Epoch time: 38.99 s 
2024-12-08 00:03:20.591931: Yayy! New best EMA pseudo Dice: 0.9222999811172485 
2024-12-08 00:03:21.365842:  
2024-12-08 00:03:21.371397: Epoch 38 
2024-12-08 00:03:21.374927: Current learning rate: 0.0065 
2024-12-08 00:04:00.602247: train_loss -0.9647 
2024-12-08 00:04:00.608876: val_loss -0.908 
2024-12-08 00:04:00.613963: Pseudo dice [np.float32(0.9198)] 
2024-12-08 00:04:00.617512: Epoch time: 39.24 s 
2024-12-08 00:04:01.202974:  
2024-12-08 00:04:01.208537: Epoch 39 
2024-12-08 00:04:01.213131: Current learning rate: 0.00641 
2024-12-08 00:04:40.719530: train_loss -0.9647 
2024-12-08 00:04:40.727679: val_loss -0.9118 
2024-12-08 00:04:40.732730: Pseudo dice [np.float32(0.9231)] 
2024-12-08 00:04:40.736266: Epoch time: 39.52 s 
2024-12-08 00:04:41.319996:  
2024-12-08 00:04:41.326623: Epoch 40 
2024-12-08 00:04:41.331168: Current learning rate: 0.00631 
2024-12-08 00:05:20.906881: train_loss -0.9656 
2024-12-08 00:05:20.913913: val_loss -0.9128 
2024-12-08 00:05:20.918435: Pseudo dice [np.float32(0.9244)] 
2024-12-08 00:05:20.923973: Epoch time: 39.59 s 
2024-12-08 00:05:20.926990: Yayy! New best EMA pseudo Dice: 0.9223999977111816 
2024-12-08 00:05:21.774842:  
2024-12-08 00:05:21.779854: Epoch 41 
2024-12-08 00:05:21.785874: Current learning rate: 0.00622 
2024-12-08 00:06:01.539701: train_loss -0.9655 
2024-12-08 00:06:01.546224: val_loss -0.9127 
2024-12-08 00:06:01.551325: Pseudo dice [np.float32(0.9239)] 
2024-12-08 00:06:01.555876: Epoch time: 39.77 s 
2024-12-08 00:06:01.561735: Yayy! New best EMA pseudo Dice: 0.9225999712944031 
2024-12-08 00:06:02.347948:  
2024-12-08 00:06:02.353461: Epoch 42 
2024-12-08 00:06:02.359481: Current learning rate: 0.00612 
2024-12-08 00:06:41.914367: train_loss -0.9659 
2024-12-08 00:06:41.921400: val_loss -0.9069 
2024-12-08 00:06:41.928781: Pseudo dice [np.float32(0.9203)] 
2024-12-08 00:06:41.935308: Epoch time: 39.57 s 
2024-12-08 00:06:42.533750:  
2024-12-08 00:06:42.540267: Epoch 43 
2024-12-08 00:06:42.544276: Current learning rate: 0.00603 
2024-12-08 00:07:22.190712: train_loss -0.9669 
2024-12-08 00:07:22.198261: val_loss -0.9115 
2024-12-08 00:07:22.203802: Pseudo dice [np.float32(0.9235)] 
2024-12-08 00:07:22.208832: Epoch time: 39.66 s 
2024-12-08 00:07:22.786049:  
2024-12-08 00:07:22.791085: Epoch 44 
2024-12-08 00:07:22.797125: Current learning rate: 0.00593 
2024-12-08 00:08:02.105456: train_loss -0.966 
2024-12-08 00:08:02.111504: val_loss -0.9169 
2024-12-08 00:08:02.116157: Pseudo dice [np.float32(0.9277)] 
2024-12-08 00:08:02.121284: Epoch time: 39.32 s 
2024-12-08 00:08:02.125817: Yayy! New best EMA pseudo Dice: 0.9229999780654907 
2024-12-08 00:08:03.063841:  
2024-12-08 00:08:03.070364: Epoch 45 
2024-12-08 00:08:03.073972: Current learning rate: 0.00584 
2024-12-08 00:08:43.169113: train_loss -0.9665 
2024-12-08 00:08:43.176665: val_loss -0.9145 
2024-12-08 00:08:43.181720: Pseudo dice [np.float32(0.9258)] 
2024-12-08 00:08:43.185744: Epoch time: 40.11 s 
2024-12-08 00:08:43.191267: Yayy! New best EMA pseudo Dice: 0.92330002784729 
2024-12-08 00:08:43.951932:  
2024-12-08 00:08:43.957473: Epoch 46 
2024-12-08 00:08:43.960981: Current learning rate: 0.00574 
2024-12-08 00:09:24.757279: train_loss -0.9664 
2024-12-08 00:09:24.764850: val_loss -0.912 
2024-12-08 00:09:24.770409: Pseudo dice [np.float32(0.9235)] 
2024-12-08 00:09:24.774959: Epoch time: 40.81 s 
2024-12-08 00:09:24.780068: Yayy! New best EMA pseudo Dice: 0.92330002784729 
2024-12-08 00:09:25.532338:  
2024-12-08 00:09:25.537896: Epoch 47 
2024-12-08 00:09:25.542967: Current learning rate: 0.00565 
2024-12-08 00:10:04.761786: train_loss -0.9664 
2024-12-08 00:10:04.768813: val_loss -0.9171 
2024-12-08 00:10:04.773871: Pseudo dice [np.float32(0.928)] 
2024-12-08 00:10:04.779418: Epoch time: 39.23 s 
2024-12-08 00:10:04.783980: Yayy! New best EMA pseudo Dice: 0.923799991607666 
2024-12-08 00:10:05.526590:  
2024-12-08 00:10:05.532681: Epoch 48 
2024-12-08 00:10:05.535738: Current learning rate: 0.00555 
2024-12-08 00:10:44.877297: train_loss -0.9675 
2024-12-08 00:10:44.885487: val_loss -0.9142 
2024-12-08 00:10:44.890004: Pseudo dice [np.float32(0.9258)] 
2024-12-08 00:10:44.895541: Epoch time: 39.35 s 
2024-12-08 00:10:44.899098: Yayy! New best EMA pseudo Dice: 0.9240000247955322 
2024-12-08 00:10:45.645524:  
2024-12-08 00:10:45.651077: Epoch 49 
2024-12-08 00:10:45.656134: Current learning rate: 0.00546 
2024-12-08 00:11:24.762704: train_loss -0.9684 
2024-12-08 00:11:24.771334: val_loss -0.911 
2024-12-08 00:11:24.776388: Pseudo dice [np.float32(0.9232)] 
2024-12-08 00:11:24.779916: Epoch time: 39.12 s 
2024-12-08 00:11:25.512784:  
2024-12-08 00:11:25.518824: Epoch 50 
2024-12-08 00:11:25.524030: Current learning rate: 0.00536 
2024-12-08 00:12:04.846565: train_loss -0.9686 
2024-12-08 00:12:04.853077: val_loss -0.9122 
2024-12-08 00:12:04.858119: Pseudo dice [np.float32(0.9241)] 
2024-12-08 00:12:04.861150: Epoch time: 39.33 s 
2024-12-08 00:12:05.412254:  
2024-12-08 00:12:05.417354: Epoch 51 
2024-12-08 00:12:05.421014: Current learning rate: 0.00526 
2024-12-08 00:12:44.888917: train_loss -0.9691 
2024-12-08 00:12:44.896038: val_loss -0.9016 
2024-12-08 00:12:44.902653: Pseudo dice [np.float32(0.9153)] 
2024-12-08 00:12:44.906734: Epoch time: 39.48 s 
2024-12-08 00:12:45.621571:  
2024-12-08 00:12:45.627127: Epoch 52 
2024-12-08 00:12:45.629659: Current learning rate: 0.00517 
2024-12-08 00:13:25.528567: train_loss -0.9685 
2024-12-08 00:13:25.536601: val_loss -0.9135 
2024-12-08 00:13:25.542645: Pseudo dice [np.float32(0.9254)] 
2024-12-08 00:13:25.548233: Epoch time: 39.91 s 
2024-12-08 00:13:26.114562:  
2024-12-08 00:13:26.121084: Epoch 53 
2024-12-08 00:13:26.127774: Current learning rate: 0.00507 
2024-12-08 00:14:06.057051: train_loss -0.9693 
2024-12-08 00:14:06.063570: val_loss -0.9113 
2024-12-08 00:14:06.070589: Pseudo dice [np.float32(0.9233)] 
2024-12-08 00:14:06.074600: Epoch time: 39.94 s 
2024-12-08 00:14:06.674140:  
2024-12-08 00:14:06.681273: Epoch 54 
2024-12-08 00:14:06.687860: Current learning rate: 0.00497 
2024-12-08 00:14:46.874191: train_loss -0.9698 
2024-12-08 00:14:46.881736: val_loss -0.9111 
2024-12-08 00:14:46.887359: Pseudo dice [np.float32(0.9225)] 
2024-12-08 00:14:46.893884: Epoch time: 40.2 s 
2024-12-08 00:14:47.457957:  
2024-12-08 00:14:47.462983: Epoch 55 
2024-12-08 00:14:47.469817: Current learning rate: 0.00487 
2024-12-08 00:15:27.023530: train_loss -0.9693 
2024-12-08 00:15:27.031650: val_loss -0.9101 
2024-12-08 00:15:27.035975: Pseudo dice [np.float32(0.9224)] 
2024-12-08 00:15:27.041548: Epoch time: 39.57 s 
2024-12-08 00:15:27.607044:  
2024-12-08 00:15:27.613049: Epoch 56 
2024-12-08 00:15:27.617101: Current learning rate: 0.00478 
2024-12-08 00:16:06.856733: train_loss -0.97 
2024-12-08 00:16:06.864328: val_loss -0.9098 
2024-12-08 00:16:06.867356: Pseudo dice [np.float32(0.9226)] 
2024-12-08 00:16:06.871902: Epoch time: 39.25 s 
2024-12-08 00:16:07.452460:  
2024-12-08 00:16:07.459563: Epoch 57 
2024-12-08 00:16:07.463119: Current learning rate: 0.00468 
2024-12-08 00:16:46.946351: train_loss -0.9699 
2024-12-08 00:16:46.952864: val_loss -0.91 
2024-12-08 00:16:46.958632: Pseudo dice [np.float32(0.9224)] 
2024-12-08 00:16:46.963159: Epoch time: 39.49 s 
2024-12-08 00:16:47.516606:  
2024-12-08 00:16:47.521616: Epoch 58 
2024-12-08 00:16:47.525124: Current learning rate: 0.00458 
2024-12-08 00:17:27.041609: train_loss -0.9705 
2024-12-08 00:17:27.049158: val_loss -0.9115 
2024-12-08 00:17:27.054186: Pseudo dice [np.float32(0.9237)] 
2024-12-08 00:17:27.058224: Epoch time: 39.53 s 
2024-12-08 00:17:27.624529:  
2024-12-08 00:17:27.630079: Epoch 59 
2024-12-08 00:17:27.635198: Current learning rate: 0.00448 
2024-12-08 00:18:07.449504: train_loss -0.9704 
2024-12-08 00:18:07.455970: val_loss -0.9158 
2024-12-08 00:18:07.462093: Pseudo dice [np.float32(0.927)] 
2024-12-08 00:18:07.464650: Epoch time: 39.82 s 
2024-12-08 00:18:08.100468:  
2024-12-08 00:18:08.107518: Epoch 60 
2024-12-08 00:18:08.112051: Current learning rate: 0.00438 
2024-12-08 00:18:47.674145: train_loss -0.9715 
2024-12-08 00:18:47.680166: val_loss -0.9118 
2024-12-08 00:18:47.685181: Pseudo dice [np.float32(0.9237)] 
2024-12-08 00:18:47.689195: Epoch time: 39.57 s 
2024-12-08 00:18:48.443921:  
2024-12-08 00:18:48.450437: Epoch 61 
2024-12-08 00:18:48.453949: Current learning rate: 0.00429 
2024-12-08 00:19:26.923924: train_loss -0.9712 
2024-12-08 00:19:26.933475: val_loss -0.9102 
2024-12-08 00:19:26.937004: Pseudo dice [np.float32(0.9227)] 
2024-12-08 00:19:26.941526: Epoch time: 38.48 s 
2024-12-08 00:19:27.503721:  
2024-12-08 00:19:27.509762: Epoch 62 
2024-12-08 00:19:27.512833: Current learning rate: 0.00419 
2024-12-08 00:20:06.412854: train_loss -0.9711 
2024-12-08 00:20:06.419969: val_loss -0.9139 
2024-12-08 00:20:06.425595: Pseudo dice [np.float32(0.9254)] 
2024-12-08 00:20:06.430164: Epoch time: 38.91 s 
2024-12-08 00:20:07.007385:  
2024-12-08 00:20:07.013451: Epoch 63 
2024-12-08 00:20:07.017993: Current learning rate: 0.00409 
2024-12-08 00:20:46.527099: train_loss -0.9714 
2024-12-08 00:20:46.534689: val_loss -0.9132 
2024-12-08 00:20:46.539798: Pseudo dice [np.float32(0.9249)] 
2024-12-08 00:20:46.544895: Epoch time: 39.52 s 
2024-12-08 00:20:47.117869:  
2024-12-08 00:20:47.123396: Epoch 64 
2024-12-08 00:20:47.127590: Current learning rate: 0.00399 
2024-12-08 00:21:26.922642: train_loss -0.9721 
2024-12-08 00:21:26.930233: val_loss -0.9095 
2024-12-08 00:21:26.936900: Pseudo dice [np.float32(0.9216)] 
2024-12-08 00:21:26.940459: Epoch time: 39.81 s 
2024-12-08 00:21:27.515884:  
2024-12-08 00:21:27.522452: Epoch 65 
2024-12-08 00:21:27.526723: Current learning rate: 0.00389 
2024-12-08 00:22:07.336084: train_loss -0.9718 
2024-12-08 00:22:07.341610: val_loss -0.912 
2024-12-08 00:22:07.346620: Pseudo dice [np.float32(0.9248)] 
2024-12-08 00:22:07.351684: Epoch time: 39.82 s 
2024-12-08 00:22:07.990270:  
2024-12-08 00:22:07.996720: Epoch 66 
2024-12-08 00:22:08.001740: Current learning rate: 0.00379 
2024-12-08 00:22:48.208871: train_loss -0.9719 
2024-12-08 00:22:48.216389: val_loss -0.9119 
2024-12-08 00:22:48.222404: Pseudo dice [np.float32(0.9237)] 
2024-12-08 00:22:48.228417: Epoch time: 40.22 s 
2024-12-08 00:22:48.810603:  
2024-12-08 00:22:48.816217: Epoch 67 
2024-12-08 00:22:48.821288: Current learning rate: 0.00369 
2024-12-08 00:23:27.897836: train_loss -0.9716 
2024-12-08 00:23:27.905420: val_loss -0.91 
2024-12-08 00:23:27.910957: Pseudo dice [np.float32(0.9225)] 
2024-12-08 00:23:27.915485: Epoch time: 39.09 s 
2024-12-08 00:23:28.490475:  
2024-12-08 00:23:28.495511: Epoch 68 
2024-12-08 00:23:28.499047: Current learning rate: 0.00359 
2024-12-08 00:24:07.414132: train_loss -0.9723 
2024-12-08 00:24:07.421163: val_loss -0.9153 
2024-12-08 00:24:07.426706: Pseudo dice [np.float32(0.9269)] 
2024-12-08 00:24:07.431749: Epoch time: 38.92 s 
2024-12-08 00:24:08.178407:  
2024-12-08 00:24:08.183970: Epoch 69 
2024-12-08 00:24:08.188520: Current learning rate: 0.00349 
2024-12-08 00:24:47.138986: train_loss -0.9719 
2024-12-08 00:24:47.146564: val_loss -0.909 
2024-12-08 00:24:47.150089: Pseudo dice [np.float32(0.922)] 
2024-12-08 00:24:47.154819: Epoch time: 38.96 s 
2024-12-08 00:24:47.741480:  
2024-12-08 00:24:47.746995: Epoch 70 
2024-12-08 00:24:47.750504: Current learning rate: 0.00338 
2024-12-08 00:25:27.862097: train_loss -0.9724 
2024-12-08 00:25:27.868639: val_loss -0.9153 
2024-12-08 00:25:27.874660: Pseudo dice [np.float32(0.927)] 
2024-12-08 00:25:27.878435: Epoch time: 40.12 s 
2024-12-08 00:25:27.882041: Yayy! New best EMA pseudo Dice: 0.9240000247955322 
2024-12-08 00:25:28.653487:  
2024-12-08 00:25:28.660053: Epoch 71 
2024-12-08 00:25:28.664060: Current learning rate: 0.00328 
2024-12-08 00:26:08.129891: train_loss -0.9725 
2024-12-08 00:26:08.135895: val_loss -0.9127 
2024-12-08 00:26:08.140905: Pseudo dice [np.float32(0.9247)] 
2024-12-08 00:26:08.145962: Epoch time: 39.48 s 
2024-12-08 00:26:08.149985: Yayy! New best EMA pseudo Dice: 0.9240999817848206 
2024-12-08 00:26:08.923069:  
2024-12-08 00:26:08.929091: Epoch 72 
2024-12-08 00:26:08.933128: Current learning rate: 0.00318 
2024-12-08 00:26:48.617075: train_loss -0.9731 
2024-12-08 00:26:48.625195: val_loss -0.9119 
2024-12-08 00:26:48.629754: Pseudo dice [np.float32(0.9238)] 
2024-12-08 00:26:48.632820: Epoch time: 39.69 s 
2024-12-08 00:26:49.222590:  
2024-12-08 00:26:49.228190: Epoch 73 
2024-12-08 00:26:49.232262: Current learning rate: 0.00308 
2024-12-08 00:27:28.892592: train_loss -0.973 
2024-12-08 00:27:28.900126: val_loss -0.9044 
2024-12-08 00:27:28.905644: Pseudo dice [np.float32(0.9182)] 
2024-12-08 00:27:28.910655: Epoch time: 39.67 s 
2024-12-08 00:27:29.495404:  
2024-12-08 00:27:29.500921: Epoch 74 
2024-12-08 00:27:29.505931: Current learning rate: 0.00297 
2024-12-08 00:28:09.365103: train_loss -0.9733 
2024-12-08 00:28:09.372654: val_loss -0.909 
2024-12-08 00:28:09.377723: Pseudo dice [np.float32(0.9212)] 
2024-12-08 00:28:09.383859: Epoch time: 39.87 s 
2024-12-08 00:28:09.986113:  
2024-12-08 00:28:09.992212: Epoch 75 
2024-12-08 00:28:09.996744: Current learning rate: 0.00287 
2024-12-08 00:28:49.262442: train_loss -0.9727 
2024-12-08 00:28:49.270511: val_loss -0.9101 
2024-12-08 00:28:49.276576: Pseudo dice [np.float32(0.9228)] 
2024-12-08 00:28:49.280617: Epoch time: 39.28 s 
2024-12-08 00:28:50.037031:  
2024-12-08 00:28:50.042545: Epoch 76 
2024-12-08 00:28:50.047555: Current learning rate: 0.00277 
2024-12-08 00:29:29.437836: train_loss -0.9735 
2024-12-08 00:29:29.446384: val_loss -0.9095 
2024-12-08 00:29:29.453984: Pseudo dice [np.float32(0.9222)] 
2024-12-08 00:29:29.458994: Epoch time: 39.4 s 
2024-12-08 00:29:30.088574:  
2024-12-08 00:29:30.095197: Epoch 77 
2024-12-08 00:29:30.100247: Current learning rate: 0.00266 
2024-12-08 00:30:10.223450: train_loss -0.9734 
2024-12-08 00:30:10.231060: val_loss -0.912 
2024-12-08 00:30:10.236688: Pseudo dice [np.float32(0.9233)] 
2024-12-08 00:30:10.243753: Epoch time: 40.14 s 
2024-12-08 00:30:10.838631:  
2024-12-08 00:30:10.844671: Epoch 78 
2024-12-08 00:30:10.849689: Current learning rate: 0.00256 
2024-12-08 00:30:49.967049: train_loss -0.9738 
2024-12-08 00:30:49.975692: val_loss -0.9105 
2024-12-08 00:30:49.982353: Pseudo dice [np.float32(0.9232)] 
2024-12-08 00:30:49.988438: Epoch time: 39.13 s 
2024-12-08 00:30:50.616432:  
2024-12-08 00:30:50.623507: Epoch 79 
2024-12-08 00:30:50.629519: Current learning rate: 0.00245 
2024-12-08 00:31:29.951110: train_loss -0.9741 
2024-12-08 00:31:29.958631: val_loss -0.9141 
2024-12-08 00:31:29.963647: Pseudo dice [np.float32(0.9257)] 
2024-12-08 00:31:29.969710: Epoch time: 39.33 s 
2024-12-08 00:31:30.600765:  
2024-12-08 00:31:30.609899: Epoch 80 
2024-12-08 00:31:30.614974: Current learning rate: 0.00235 
2024-12-08 00:32:10.650689: train_loss -0.9742 
2024-12-08 00:32:10.657204: val_loss -0.911 
2024-12-08 00:32:10.663221: Pseudo dice [np.float32(0.9238)] 
2024-12-08 00:32:10.666725: Epoch time: 40.05 s 
2024-12-08 00:32:11.260670:  
2024-12-08 00:32:11.266763: Epoch 81 
2024-12-08 00:32:11.272842: Current learning rate: 0.00224 
2024-12-08 00:32:50.873646: train_loss -0.9748 
2024-12-08 00:32:50.882229: val_loss -0.9078 
2024-12-08 00:32:50.888208: Pseudo dice [np.float32(0.9206)] 
2024-12-08 00:32:50.892228: Epoch time: 39.61 s 
2024-12-08 00:32:51.481572:  
2024-12-08 00:32:51.488628: Epoch 82 
2024-12-08 00:32:51.492189: Current learning rate: 0.00214 
2024-12-08 00:33:31.989887: train_loss -0.9744 
2024-12-08 00:33:31.996383: val_loss -0.9095 
2024-12-08 00:33:32.002921: Pseudo dice [np.float32(0.9219)] 
2024-12-08 00:33:32.009012: Epoch time: 40.51 s 
2024-12-08 00:33:32.570395:  
2024-12-08 00:33:32.578485: Epoch 83 
2024-12-08 00:33:32.586104: Current learning rate: 0.00203 
2024-12-08 00:34:11.749265: train_loss -0.9744 
2024-12-08 00:34:11.756483: val_loss -0.9082 
2024-12-08 00:34:11.762522: Pseudo dice [np.float32(0.921)] 
2024-12-08 00:34:11.767568: Epoch time: 39.18 s 
2024-12-08 00:34:12.494650:  
2024-12-08 00:34:12.500664: Epoch 84 
2024-12-08 00:34:12.507180: Current learning rate: 0.00192 
2024-12-08 00:34:52.238924: train_loss -0.9747 
2024-12-08 00:34:52.246441: val_loss -0.9086 
2024-12-08 00:34:52.252958: Pseudo dice [np.float32(0.9218)] 
2024-12-08 00:34:52.257969: Epoch time: 39.75 s 
2024-12-08 00:34:52.811475:  
2024-12-08 00:34:52.818037: Epoch 85 
2024-12-08 00:34:52.822615: Current learning rate: 0.00181 
2024-12-08 00:35:32.509504: train_loss -0.9741 
2024-12-08 00:35:32.517022: val_loss -0.9092 
2024-12-08 00:35:32.522032: Pseudo dice [np.float32(0.9224)] 
2024-12-08 00:35:32.525539: Epoch time: 39.7 s 
2024-12-08 00:35:33.064386:  
2024-12-08 00:35:33.069938: Epoch 86 
2024-12-08 00:35:33.074999: Current learning rate: 0.0017 
2024-12-08 00:36:12.887920: train_loss -0.9748 
2024-12-08 00:36:12.895496: val_loss -0.9108 
2024-12-08 00:36:12.903100: Pseudo dice [np.float32(0.9234)] 
2024-12-08 00:36:12.909215: Epoch time: 39.82 s 
2024-12-08 00:36:13.459758:  
2024-12-08 00:36:13.467281: Epoch 87 
2024-12-08 00:36:13.472293: Current learning rate: 0.00159 
2024-12-08 00:36:53.888914: train_loss -0.975 
2024-12-08 00:36:53.897953: val_loss -0.9091 
2024-12-08 00:36:53.901982: Pseudo dice [np.float32(0.9217)] 
2024-12-08 00:36:53.906529: Epoch time: 40.43 s 
2024-12-08 00:36:54.505787:  
2024-12-08 00:36:54.512863: Epoch 88 
2024-12-08 00:36:54.518472: Current learning rate: 0.00148 
2024-12-08 00:37:34.336889: train_loss -0.9753 
2024-12-08 00:37:34.342491: val_loss -0.9123 
2024-12-08 00:37:34.346998: Pseudo dice [np.float32(0.9245)] 
2024-12-08 00:37:34.351035: Epoch time: 39.83 s 
2024-12-08 00:37:34.875467:  
2024-12-08 00:37:34.882007: Epoch 89 
2024-12-08 00:37:34.887063: Current learning rate: 0.00137 
2024-12-08 00:38:11.885824: train_loss -0.9753 
2024-12-08 00:38:11.895884: val_loss -0.9072 
2024-12-08 00:38:11.900436: Pseudo dice [np.float32(0.9203)] 
2024-12-08 00:38:11.905032: Epoch time: 37.01 s 
2024-12-08 00:38:12.467489:  
2024-12-08 00:38:12.474026: Epoch 90 
2024-12-08 00:38:12.478050: Current learning rate: 0.00126 
2024-12-08 00:38:50.628165: train_loss -0.9751 
2024-12-08 00:38:50.635751: val_loss -0.9086 
2024-12-08 00:38:50.641807: Pseudo dice [np.float32(0.9218)] 
2024-12-08 00:38:50.646889: Epoch time: 38.16 s 
2024-12-08 00:38:51.191916:  
2024-12-08 00:38:51.198560: Epoch 91 
2024-12-08 00:38:51.203595: Current learning rate: 0.00115 
2024-12-08 00:39:30.276368: train_loss -0.9752 
2024-12-08 00:39:30.283912: val_loss -0.9111 
2024-12-08 00:39:30.289946: Pseudo dice [np.float32(0.924)] 
2024-12-08 00:39:30.292987: Epoch time: 39.08 s 
2024-12-08 00:39:30.827748:  
2024-12-08 00:39:30.833781: Epoch 92 
2024-12-08 00:39:30.838319: Current learning rate: 0.00103 
2024-12-08 00:40:09.943187: train_loss -0.9757 
2024-12-08 00:40:09.951947: val_loss -0.9106 
2024-12-08 00:40:09.957028: Pseudo dice [np.float32(0.9232)] 
2024-12-08 00:40:09.962135: Epoch time: 39.12 s 
2024-12-08 00:40:10.696197:  
2024-12-08 00:40:10.703803: Epoch 93 
2024-12-08 00:40:10.706833: Current learning rate: 0.00091 
2024-12-08 00:40:50.986220: train_loss -0.9758 
2024-12-08 00:40:50.993279: val_loss -0.9095 
2024-12-08 00:40:51.008543: Pseudo dice [np.float32(0.9226)] 
2024-12-08 00:40:51.014556: Epoch time: 40.29 s 
2024-12-08 00:40:51.590794:  
2024-12-08 00:40:51.597358: Epoch 94 
2024-12-08 00:40:51.602375: Current learning rate: 0.00079 
2024-12-08 00:41:30.715890: train_loss -0.9763 
2024-12-08 00:41:30.722960: val_loss -0.911 
2024-12-08 00:41:30.729076: Pseudo dice [np.float32(0.9239)] 
2024-12-08 00:41:30.734134: Epoch time: 39.13 s 
2024-12-08 00:41:31.285485:  
2024-12-08 00:41:31.293003: Epoch 95 
2024-12-08 00:41:31.298014: Current learning rate: 0.00067 
2024-12-08 00:42:10.739956: train_loss -0.976 
2024-12-08 00:42:10.747485: val_loss -0.9071 
2024-12-08 00:42:10.752502: Pseudo dice [np.float32(0.9204)] 
2024-12-08 00:42:10.757011: Epoch time: 39.45 s 
2024-12-08 00:42:11.340749:  
2024-12-08 00:42:11.347294: Epoch 96 
2024-12-08 00:42:11.351303: Current learning rate: 0.00055 
2024-12-08 00:42:49.823452: train_loss -0.9762 
2024-12-08 00:42:49.832067: val_loss -0.9111 
2024-12-08 00:42:49.838637: Pseudo dice [np.float32(0.9244)] 
2024-12-08 00:42:49.845742: Epoch time: 38.48 s 
2024-12-08 00:42:50.441411:  
2024-12-08 00:42:50.446953: Epoch 97 
2024-12-08 00:42:50.452045: Current learning rate: 0.00043 
2024-12-08 00:43:29.197246: train_loss -0.9764 
2024-12-08 00:43:29.204808: val_loss -0.9077 
2024-12-08 00:43:29.210848: Pseudo dice [np.float32(0.9207)] 
2024-12-08 00:43:29.215866: Epoch time: 38.76 s 
2024-12-08 00:43:29.788978:  
2024-12-08 00:43:29.796552: Epoch 98 
2024-12-08 00:43:29.800086: Current learning rate: 0.0003 
2024-12-08 00:44:08.639609: train_loss -0.9764 
2024-12-08 00:44:08.647125: val_loss -0.9105 
2024-12-08 00:44:08.652138: Pseudo dice [np.float32(0.9238)] 
2024-12-08 00:44:08.657688: Epoch time: 38.85 s 
2024-12-08 00:44:09.217267:  
2024-12-08 00:44:09.224790: Epoch 99 
2024-12-08 00:44:09.229803: Current learning rate: 0.00016 
2024-12-08 00:44:47.793760: train_loss -0.9762 
2024-12-08 00:44:47.801275: val_loss -0.9108 
2024-12-08 00:44:47.808289: Pseudo dice [np.float32(0.9241)] 
2024-12-08 00:44:47.813802: Epoch time: 38.58 s 
2024-12-08 00:44:48.722617: Training done. 
2024-12-08 00:44:48.755646: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-08 00:44:48.762653: The split file contains 5 splits. 
2024-12-08 00:44:48.767925: Desired fold for training: 0 
2024-12-08 00:44:48.774923: This split has 16 training and 4 validation cases. 
2024-12-08 00:44:48.781434: predicting la_007 
2024-12-08 00:44:48.787943: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2024-12-08 00:44:50.864765: predicting la_016 
2024-12-08 00:44:50.875776: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2024-12-08 00:44:52.117545: predicting la_021 
2024-12-08 00:44:52.128049: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2024-12-08 00:44:53.560372: predicting la_024 
2024-12-08 00:44:53.570883: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2024-12-08 00:45:02.808985: Validation complete 
2024-12-08 00:45:02.815984: Mean Validation Dice:  0.9187504045199568 
