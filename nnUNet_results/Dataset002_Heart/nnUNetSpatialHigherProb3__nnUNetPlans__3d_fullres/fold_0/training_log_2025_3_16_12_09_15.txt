
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-16 12:09:15.196894: do_dummy_2d_data_aug: False 
2025-03-16 12:09:15.201160: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-16 12:09:15.206164: The split file contains 5 splits. 
2025-03-16 12:09:15.209165: Desired fold for training: 0 
2025-03-16 12:09:15.212164: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2025-03-16 12:09:22.753057: unpacking dataset... 
2025-03-16 12:09:22.926061: unpacking done... 
2025-03-16 12:09:26.939869:  
2025-03-16 12:09:26.944881: Epoch 0 
2025-03-16 12:09:26.948892: Current learning rate: 0.01 
2025-03-16 12:10:14.227527: train_loss -0.6178 
2025-03-16 12:10:14.234046: val_loss -0.8736 
2025-03-16 12:10:14.237558: Pseudo dice [np.float32(0.9029)] 
2025-03-16 12:10:14.240067: Epoch time: 47.29 s 
2025-03-16 12:10:14.244080: Yayy! New best EMA pseudo Dice: 0.902899980545044 
2025-03-16 12:10:14.893038:  
2025-03-16 12:10:14.899070: Epoch 1 
2025-03-16 12:10:14.901923: Current learning rate: 0.00991 
2025-03-16 12:10:57.660232: train_loss -0.8661 
2025-03-16 12:10:57.665824: val_loss -0.8942 
2025-03-16 12:10:57.669365: Pseudo dice [np.float32(0.9171)] 
2025-03-16 12:10:57.672405: Epoch time: 42.77 s 
2025-03-16 12:10:57.675963: Yayy! New best EMA pseudo Dice: 0.9043999910354614 
2025-03-16 12:10:58.402822:  
2025-03-16 12:10:58.408334: Epoch 2 
2025-03-16 12:10:58.411844: Current learning rate: 0.00982 
2025-03-16 12:11:41.015776: train_loss -0.8922 
2025-03-16 12:11:41.021289: val_loss -0.9067 
2025-03-16 12:11:41.024798: Pseudo dice [np.float32(0.9268)] 
2025-03-16 12:11:41.027304: Epoch time: 42.61 s 
2025-03-16 12:11:41.031312: Yayy! New best EMA pseudo Dice: 0.9065999984741211 
2025-03-16 12:11:41.905213:  
2025-03-16 12:11:41.910224: Epoch 3 
2025-03-16 12:11:41.913733: Current learning rate: 0.00973 
2025-03-16 12:12:24.619640: train_loss -0.9016 
2025-03-16 12:12:24.625189: val_loss -0.909 
2025-03-16 12:12:24.629713: Pseudo dice [np.float32(0.9305)] 
2025-03-16 12:12:24.633221: Epoch time: 42.72 s 
2025-03-16 12:12:24.635727: Yayy! New best EMA pseudo Dice: 0.9089999794960022 
2025-03-16 12:12:25.380902:  
2025-03-16 12:12:25.385913: Epoch 4 
2025-03-16 12:12:25.389421: Current learning rate: 0.00964 
2025-03-16 12:13:08.394261: train_loss -0.9118 
2025-03-16 12:13:08.399813: val_loss -0.9118 
2025-03-16 12:13:08.402821: Pseudo dice [np.float32(0.9304)] 
2025-03-16 12:13:08.406337: Epoch time: 43.01 s 
2025-03-16 12:13:08.409841: Yayy! New best EMA pseudo Dice: 0.9110999703407288 
2025-03-16 12:13:09.317266:  
2025-03-16 12:13:09.323280: Epoch 5 
2025-03-16 12:13:09.325787: Current learning rate: 0.00955 
2025-03-16 12:13:52.043651: train_loss -0.9195 
2025-03-16 12:13:52.049190: val_loss -0.9095 
2025-03-16 12:13:52.052212: Pseudo dice [np.float32(0.9284)] 
2025-03-16 12:13:52.055729: Epoch time: 42.73 s 
2025-03-16 12:13:52.058765: Yayy! New best EMA pseudo Dice: 0.9128000140190125 
2025-03-16 12:13:52.780598:  
2025-03-16 12:13:52.786653: Epoch 6 
2025-03-16 12:13:52.789683: Current learning rate: 0.00946 
2025-03-16 12:14:35.542468: train_loss -0.9244 
2025-03-16 12:14:35.548040: val_loss -0.9119 
2025-03-16 12:14:35.551553: Pseudo dice [np.float32(0.9304)] 
2025-03-16 12:14:35.554755: Epoch time: 42.76 s 
2025-03-16 12:14:35.558264: Yayy! New best EMA pseudo Dice: 0.9146000146865845 
2025-03-16 12:14:36.308427:  
2025-03-16 12:14:36.313480: Epoch 7 
2025-03-16 12:14:36.317018: Current learning rate: 0.00937 
2025-03-16 12:15:19.077297: train_loss -0.9314 
2025-03-16 12:15:19.082810: val_loss -0.9128 
2025-03-16 12:15:19.086320: Pseudo dice [np.float32(0.9315)] 
2025-03-16 12:15:19.089826: Epoch time: 42.77 s 
2025-03-16 12:15:19.092835: Yayy! New best EMA pseudo Dice: 0.9162999987602234 
2025-03-16 12:15:19.870800:  
2025-03-16 12:15:19.875840: Epoch 8 
2025-03-16 12:15:19.878360: Current learning rate: 0.00928 
2025-03-16 12:16:03.059979: train_loss -0.9327 
2025-03-16 12:16:03.065569: val_loss -0.9139 
2025-03-16 12:16:03.069106: Pseudo dice [np.float32(0.933)] 
2025-03-16 12:16:03.072670: Epoch time: 43.19 s 
2025-03-16 12:16:03.075716: Yayy! New best EMA pseudo Dice: 0.9179999828338623 
2025-03-16 12:16:03.865534:  
2025-03-16 12:16:03.871681: Epoch 9 
2025-03-16 12:16:03.874754: Current learning rate: 0.00919 
2025-03-16 12:16:47.023259: train_loss -0.9382 
2025-03-16 12:16:47.029346: val_loss -0.9159 
2025-03-16 12:16:47.032393: Pseudo dice [np.float32(0.9334)] 
2025-03-16 12:16:47.036433: Epoch time: 43.16 s 
2025-03-16 12:16:47.039550: Yayy! New best EMA pseudo Dice: 0.9194999933242798 
2025-03-16 12:16:47.783817:  
2025-03-16 12:16:47.790385: Epoch 10 
2025-03-16 12:16:47.792924: Current learning rate: 0.0091 
2025-03-16 12:17:30.872631: train_loss -0.939 
2025-03-16 12:17:30.879777: val_loss -0.917 
2025-03-16 12:17:30.882836: Pseudo dice [np.float32(0.934)] 
2025-03-16 12:17:30.886375: Epoch time: 43.09 s 
2025-03-16 12:17:30.888934: Yayy! New best EMA pseudo Dice: 0.9210000038146973 
2025-03-16 12:17:31.693639:  
2025-03-16 12:17:31.699229: Epoch 11 
2025-03-16 12:17:31.703362: Current learning rate: 0.009 
2025-03-16 12:18:14.882180: train_loss -0.9266 
2025-03-16 12:18:14.888233: val_loss -0.9082 
2025-03-16 12:18:14.891251: Pseudo dice [np.float32(0.9268)] 
2025-03-16 12:18:14.893762: Epoch time: 43.19 s 
2025-03-16 12:18:14.898275: Yayy! New best EMA pseudo Dice: 0.9215999841690063 
2025-03-16 12:18:15.630328:  
2025-03-16 12:18:15.635906: Epoch 12 
2025-03-16 12:18:15.639422: Current learning rate: 0.00891 
2025-03-16 12:18:58.574466: train_loss -0.936 
2025-03-16 12:18:58.580484: val_loss -0.922 
2025-03-16 12:18:58.582993: Pseudo dice [np.float32(0.9379)] 
2025-03-16 12:18:58.587006: Epoch time: 42.95 s 
2025-03-16 12:18:58.589518: Yayy! New best EMA pseudo Dice: 0.9232000112533569 
2025-03-16 12:18:59.475529:  
2025-03-16 12:18:59.479559: Epoch 13 
2025-03-16 12:18:59.483094: Current learning rate: 0.00882 
2025-03-16 12:19:43.277709: train_loss -0.9441 
2025-03-16 12:19:43.284766: val_loss -0.924 
2025-03-16 12:19:43.287778: Pseudo dice [np.float32(0.9398)] 
2025-03-16 12:19:43.291298: Epoch time: 43.8 s 
2025-03-16 12:19:43.295311: Yayy! New best EMA pseudo Dice: 0.9248999953269958 
2025-03-16 12:19:44.038988:  
2025-03-16 12:19:44.043636: Epoch 14 
2025-03-16 12:19:44.048544: Current learning rate: 0.00873 
2025-03-16 12:20:27.497007: train_loss -0.9454 
2025-03-16 12:20:27.503656: val_loss -0.9172 
2025-03-16 12:20:27.507217: Pseudo dice [np.float32(0.9338)] 
2025-03-16 12:20:27.511266: Epoch time: 43.46 s 
2025-03-16 12:20:27.514851: Yayy! New best EMA pseudo Dice: 0.9258000254631042 
2025-03-16 12:20:28.267238:  
2025-03-16 12:20:28.273298: Epoch 15 
2025-03-16 12:20:28.276340: Current learning rate: 0.00864 
2025-03-16 12:21:11.161345: train_loss -0.9507 
2025-03-16 12:21:11.168449: val_loss -0.917 
2025-03-16 12:21:11.171480: Pseudo dice [np.float32(0.9343)] 
2025-03-16 12:21:11.173987: Epoch time: 42.89 s 
2025-03-16 12:21:11.177500: Yayy! New best EMA pseudo Dice: 0.9265999794006348 
2025-03-16 12:21:11.957168:  
2025-03-16 12:21:11.963186: Epoch 16 
2025-03-16 12:21:11.965693: Current learning rate: 0.00855 
2025-03-16 12:21:55.527919: train_loss -0.9496 
2025-03-16 12:21:55.533585: val_loss -0.9226 
2025-03-16 12:21:55.536648: Pseudo dice [np.float32(0.9377)] 
2025-03-16 12:21:55.540702: Epoch time: 43.57 s 
2025-03-16 12:21:55.543736: Yayy! New best EMA pseudo Dice: 0.9276999831199646 
2025-03-16 12:21:56.325480:  
2025-03-16 12:21:56.332040: Epoch 17 
2025-03-16 12:21:56.334440: Current learning rate: 0.00846 
2025-03-16 12:22:39.481808: train_loss -0.9494 
2025-03-16 12:22:39.487858: val_loss -0.9208 
2025-03-16 12:22:39.491867: Pseudo dice [np.float32(0.9366)] 
2025-03-16 12:22:39.494396: Epoch time: 43.16 s 
2025-03-16 12:22:39.497904: Yayy! New best EMA pseudo Dice: 0.928600013256073 
2025-03-16 12:22:40.262922:  
2025-03-16 12:22:40.268477: Epoch 18 
2025-03-16 12:22:40.272024: Current learning rate: 0.00836 
2025-03-16 12:23:24.099746: train_loss -0.9538 
2025-03-16 12:23:24.106280: val_loss -0.9239 
2025-03-16 12:23:24.109354: Pseudo dice [np.float32(0.9398)] 
2025-03-16 12:23:24.112875: Epoch time: 43.84 s 
2025-03-16 12:23:24.116888: Yayy! New best EMA pseudo Dice: 0.9297000169754028 
2025-03-16 12:23:24.890042:  
2025-03-16 12:23:24.896081: Epoch 19 
2025-03-16 12:23:24.899128: Current learning rate: 0.00827 
2025-03-16 12:24:07.873678: train_loss -0.9542 
2025-03-16 12:24:07.879727: val_loss -0.9234 
2025-03-16 12:24:07.883746: Pseudo dice [np.float32(0.9395)] 
2025-03-16 12:24:07.887258: Epoch time: 42.98 s 
2025-03-16 12:24:07.890770: Yayy! New best EMA pseudo Dice: 0.9307000041007996 
2025-03-16 12:24:08.662458:  
2025-03-16 12:24:08.668003: Epoch 20 
2025-03-16 12:24:08.671024: Current learning rate: 0.00818 
2025-03-16 12:24:51.696496: train_loss -0.9574 
2025-03-16 12:24:51.702092: val_loss -0.9207 
2025-03-16 12:24:51.705701: Pseudo dice [np.float32(0.9373)] 
2025-03-16 12:24:51.708227: Epoch time: 43.04 s 
2025-03-16 12:24:51.711843: Yayy! New best EMA pseudo Dice: 0.9314000010490417 
2025-03-16 12:24:52.635995:  
2025-03-16 12:24:52.641530: Epoch 21 
2025-03-16 12:24:52.644571: Current learning rate: 0.00809 
2025-03-16 12:25:35.814067: train_loss -0.9592 
2025-03-16 12:25:35.820674: val_loss -0.9261 
2025-03-16 12:25:35.823707: Pseudo dice [np.float32(0.9417)] 
2025-03-16 12:25:35.827216: Epoch time: 43.18 s 
2025-03-16 12:25:35.830723: Yayy! New best EMA pseudo Dice: 0.9323999881744385 
2025-03-16 12:25:36.604111:  
2025-03-16 12:25:36.610686: Epoch 22 
2025-03-16 12:25:36.613719: Current learning rate: 0.008 
2025-03-16 12:26:19.805635: train_loss -0.9458 
2025-03-16 12:26:19.811646: val_loss -0.9199 
2025-03-16 12:26:19.814658: Pseudo dice [np.float32(0.936)] 
2025-03-16 12:26:19.818167: Epoch time: 43.2 s 
2025-03-16 12:26:19.820674: Yayy! New best EMA pseudo Dice: 0.932699978351593 
2025-03-16 12:26:20.567556:  
2025-03-16 12:26:20.573083: Epoch 23 
2025-03-16 12:26:20.576694: Current learning rate: 0.0079 
2025-03-16 12:27:03.921999: train_loss -0.9526 
2025-03-16 12:27:03.928079: val_loss -0.9184 
2025-03-16 12:27:03.933715: Pseudo dice [np.float32(0.9353)] 
2025-03-16 12:27:03.937253: Epoch time: 43.35 s 
2025-03-16 12:27:03.940778: Yayy! New best EMA pseudo Dice: 0.9330000281333923 
2025-03-16 12:27:04.673734:  
2025-03-16 12:27:04.679816: Epoch 24 
2025-03-16 12:27:04.682895: Current learning rate: 0.00781 
2025-03-16 12:27:47.489311: train_loss -0.9563 
2025-03-16 12:27:47.495393: val_loss -0.9216 
2025-03-16 12:27:47.498470: Pseudo dice [np.float32(0.9374)] 
2025-03-16 12:27:47.502481: Epoch time: 42.82 s 
2025-03-16 12:27:47.504987: Yayy! New best EMA pseudo Dice: 0.9333999752998352 
2025-03-16 12:27:48.240063:  
2025-03-16 12:27:48.245075: Epoch 25 
2025-03-16 12:27:48.248601: Current learning rate: 0.00772 
2025-03-16 12:28:30.938772: train_loss -0.9601 
2025-03-16 12:28:30.944833: val_loss -0.9221 
2025-03-16 12:28:30.948341: Pseudo dice [np.float32(0.9382)] 
2025-03-16 12:28:30.950847: Epoch time: 42.7 s 
2025-03-16 12:28:30.954855: Yayy! New best EMA pseudo Dice: 0.933899998664856 
2025-03-16 12:28:31.687479:  
2025-03-16 12:28:31.690988: Epoch 26 
2025-03-16 12:28:31.694996: Current learning rate: 0.00763 
2025-03-16 12:29:14.384907: train_loss -0.9466 
2025-03-16 12:29:14.391418: val_loss -0.9156 
2025-03-16 12:29:14.393956: Pseudo dice [np.float32(0.9318)] 
2025-03-16 12:29:14.397465: Epoch time: 42.7 s 
2025-03-16 12:29:14.951931:  
2025-03-16 12:29:14.956943: Epoch 27 
2025-03-16 12:29:14.960951: Current learning rate: 0.00753 
2025-03-16 12:29:57.743969: train_loss -0.9514 
2025-03-16 12:29:57.750099: val_loss -0.9213 
2025-03-16 12:29:57.754208: Pseudo dice [np.float32(0.9373)] 
2025-03-16 12:29:57.757248: Epoch time: 42.79 s 
2025-03-16 12:29:57.760291: Yayy! New best EMA pseudo Dice: 0.9340999722480774 
2025-03-16 12:29:58.488483:  
2025-03-16 12:29:58.494513: Epoch 28 
2025-03-16 12:29:58.498053: Current learning rate: 0.00744 
2025-03-16 12:30:41.795247: train_loss -0.9563 
2025-03-16 12:30:41.800811: val_loss -0.9257 
2025-03-16 12:30:41.804321: Pseudo dice [np.float32(0.9409)] 
2025-03-16 12:30:41.808331: Epoch time: 43.31 s 
2025-03-16 12:30:41.811851: Yayy! New best EMA pseudo Dice: 0.9347000122070312 
2025-03-16 12:30:42.693605:  
2025-03-16 12:30:42.699295: Epoch 29 
2025-03-16 12:30:42.703321: Current learning rate: 0.00735 
2025-03-16 12:31:26.609303: train_loss -0.9597 
2025-03-16 12:31:26.614818: val_loss -0.9236 
2025-03-16 12:31:26.618330: Pseudo dice [np.float32(0.9397)] 
2025-03-16 12:31:26.622335: Epoch time: 43.92 s 
2025-03-16 12:31:26.625849: Yayy! New best EMA pseudo Dice: 0.9351999759674072 
2025-03-16 12:31:27.415206:  
2025-03-16 12:31:27.422310: Epoch 30 
2025-03-16 12:31:27.425877: Current learning rate: 0.00725 
2025-03-16 12:32:11.278674: train_loss -0.9613 
2025-03-16 12:32:11.284766: val_loss -0.9254 
2025-03-16 12:32:11.288371: Pseudo dice [np.float32(0.9409)] 
2025-03-16 12:32:11.291400: Epoch time: 43.86 s 
2025-03-16 12:32:11.294925: Yayy! New best EMA pseudo Dice: 0.9358000159263611 
2025-03-16 12:32:12.035130:  
2025-03-16 12:32:12.041680: Epoch 31 
2025-03-16 12:32:12.045280: Current learning rate: 0.00716 
2025-03-16 12:32:56.083397: train_loss -0.9633 
2025-03-16 12:32:56.089917: val_loss -0.9233 
2025-03-16 12:32:56.093426: Pseudo dice [np.float32(0.9394)] 
2025-03-16 12:32:56.096932: Epoch time: 44.05 s 
2025-03-16 12:32:56.099942: Yayy! New best EMA pseudo Dice: 0.9362000226974487 
2025-03-16 12:32:56.857403:  
2025-03-16 12:32:56.863449: Epoch 32 
2025-03-16 12:32:56.866980: Current learning rate: 0.00707 
2025-03-16 12:33:40.149046: train_loss -0.9603 
2025-03-16 12:33:40.155118: val_loss -0.9225 
2025-03-16 12:33:40.158153: Pseudo dice [np.float32(0.9387)] 
2025-03-16 12:33:40.160719: Epoch time: 43.29 s 
2025-03-16 12:33:40.164249: Yayy! New best EMA pseudo Dice: 0.9363999962806702 
2025-03-16 12:33:40.911109:  
2025-03-16 12:33:40.915148: Epoch 33 
2025-03-16 12:33:40.919200: Current learning rate: 0.00697 
2025-03-16 12:34:24.044350: train_loss -0.9628 
2025-03-16 12:34:24.050363: val_loss -0.9205 
2025-03-16 12:34:24.053374: Pseudo dice [np.float32(0.938)] 
2025-03-16 12:34:24.056884: Epoch time: 43.13 s 
2025-03-16 12:34:24.060389: Yayy! New best EMA pseudo Dice: 0.9366000294685364 
2025-03-16 12:34:24.809895:  
2025-03-16 12:34:24.815458: Epoch 34 
2025-03-16 12:34:24.818488: Current learning rate: 0.00688 
2025-03-16 12:35:08.224391: train_loss -0.9657 
2025-03-16 12:35:08.231543: val_loss -0.9216 
2025-03-16 12:35:08.237198: Pseudo dice [np.float32(0.9383)] 
2025-03-16 12:35:08.239737: Epoch time: 43.41 s 
2025-03-16 12:35:08.244246: Yayy! New best EMA pseudo Dice: 0.9366999864578247 
2025-03-16 12:35:09.002546:  
2025-03-16 12:35:09.009731: Epoch 35 
2025-03-16 12:35:09.013812: Current learning rate: 0.00679 
2025-03-16 12:35:52.484582: train_loss -0.964 
2025-03-16 12:35:52.490678: val_loss -0.9222 
2025-03-16 12:35:52.493737: Pseudo dice [np.float32(0.9386)] 
2025-03-16 12:35:52.497767: Epoch time: 43.48 s 
2025-03-16 12:35:52.501305: Yayy! New best EMA pseudo Dice: 0.9369000196456909 
2025-03-16 12:35:53.387990:  
2025-03-16 12:35:53.393505: Epoch 36 
2025-03-16 12:35:53.396010: Current learning rate: 0.00669 
2025-03-16 12:36:36.969422: train_loss -0.9623 
2025-03-16 12:36:36.974430: val_loss -0.925 
2025-03-16 12:36:36.978441: Pseudo dice [np.float32(0.9408)] 
2025-03-16 12:36:36.980949: Epoch time: 43.58 s 
2025-03-16 12:36:36.984458: Yayy! New best EMA pseudo Dice: 0.9373000264167786 
2025-03-16 12:36:37.739581:  
2025-03-16 12:36:37.745218: Epoch 37 
2025-03-16 12:36:37.748767: Current learning rate: 0.0066 
2025-03-16 12:37:20.977432: train_loss -0.962 
2025-03-16 12:37:20.982999: val_loss -0.9197 
2025-03-16 12:37:20.986507: Pseudo dice [np.float32(0.9371)] 
2025-03-16 12:37:20.989422: Epoch time: 43.24 s 
2025-03-16 12:37:21.569626:  
2025-03-16 12:37:21.574658: Epoch 38 
2025-03-16 12:37:21.577668: Current learning rate: 0.0065 
2025-03-16 12:38:04.705924: train_loss -0.9646 
2025-03-16 12:38:04.710936: val_loss -0.9244 
2025-03-16 12:38:04.713442: Pseudo dice [np.float32(0.9408)] 
2025-03-16 12:38:04.717451: Epoch time: 43.14 s 
2025-03-16 12:38:04.719957: Yayy! New best EMA pseudo Dice: 0.9376000165939331 
2025-03-16 12:38:05.481519:  
2025-03-16 12:38:05.486335: Epoch 39 
2025-03-16 12:38:05.490409: Current learning rate: 0.00641 
2025-03-16 12:38:48.181618: train_loss -0.9651 
2025-03-16 12:38:48.187690: val_loss -0.9239 
2025-03-16 12:38:48.190224: Pseudo dice [np.float32(0.9405)] 
2025-03-16 12:38:48.194838: Epoch time: 42.7 s 
2025-03-16 12:38:48.197885: Yayy! New best EMA pseudo Dice: 0.9379000067710876 
2025-03-16 12:38:48.975498:  
2025-03-16 12:38:48.981012: Epoch 40 
2025-03-16 12:38:48.984520: Current learning rate: 0.00631 
2025-03-16 12:39:31.903308: train_loss -0.9647 
2025-03-16 12:39:31.910418: val_loss -0.92 
2025-03-16 12:39:31.913481: Pseudo dice [np.float32(0.9371)] 
2025-03-16 12:39:31.917067: Epoch time: 42.93 s 
2025-03-16 12:39:32.558620:  
2025-03-16 12:39:32.564138: Epoch 41 
2025-03-16 12:39:32.567647: Current learning rate: 0.00622 
2025-03-16 12:40:16.006958: train_loss -0.9581 
2025-03-16 12:40:16.012565: val_loss -0.9211 
2025-03-16 12:40:16.015676: Pseudo dice [np.float32(0.9372)] 
2025-03-16 12:40:16.019209: Epoch time: 43.45 s 
2025-03-16 12:40:16.577560:  
2025-03-16 12:40:16.582575: Epoch 42 
2025-03-16 12:40:16.586085: Current learning rate: 0.00612 
2025-03-16 12:40:59.875295: train_loss -0.9646 
2025-03-16 12:40:59.881811: val_loss -0.9204 
2025-03-16 12:40:59.884318: Pseudo dice [np.float32(0.9379)] 
2025-03-16 12:40:59.888327: Epoch time: 43.3 s 
2025-03-16 12:41:00.445943:  
2025-03-16 12:41:00.451501: Epoch 43 
2025-03-16 12:41:00.455589: Current learning rate: 0.00603 
2025-03-16 12:41:43.726243: train_loss -0.9671 
2025-03-16 12:41:43.732776: val_loss -0.9205 
2025-03-16 12:41:43.736285: Pseudo dice [np.float32(0.9377)] 
2025-03-16 12:41:43.739294: Epoch time: 43.28 s 
2025-03-16 12:41:44.456513:  
2025-03-16 12:41:44.462568: Epoch 44 
2025-03-16 12:41:44.465637: Current learning rate: 0.00593 
2025-03-16 12:42:27.137716: train_loss -0.9645 
2025-03-16 12:42:27.143297: val_loss -0.9203 
2025-03-16 12:42:27.146329: Pseudo dice [np.float32(0.9378)] 
2025-03-16 12:42:27.149836: Epoch time: 42.68 s 
2025-03-16 12:42:27.702409:  
2025-03-16 12:42:27.707959: Epoch 45 
2025-03-16 12:42:27.710479: Current learning rate: 0.00584 
2025-03-16 12:43:10.726850: train_loss -0.9669 
2025-03-16 12:43:10.733950: val_loss -0.9223 
2025-03-16 12:43:10.736988: Pseudo dice [np.float32(0.9398)] 
2025-03-16 12:43:10.741118: Epoch time: 43.02 s 
2025-03-16 12:43:10.744127: Yayy! New best EMA pseudo Dice: 0.9380000233650208 
2025-03-16 12:43:11.480839:  
2025-03-16 12:43:11.485905: Epoch 46 
2025-03-16 12:43:11.489459: Current learning rate: 0.00574 
2025-03-16 12:43:55.239668: train_loss -0.9637 
2025-03-16 12:43:55.246356: val_loss -0.9219 
2025-03-16 12:43:55.249867: Pseudo dice [np.float32(0.9388)] 
2025-03-16 12:43:55.252373: Epoch time: 43.76 s 
2025-03-16 12:43:55.255879: Yayy! New best EMA pseudo Dice: 0.9380999803543091 
2025-03-16 12:43:56.001696:  
2025-03-16 12:43:56.007304: Epoch 47 
2025-03-16 12:43:56.012979: Current learning rate: 0.00565 
2025-03-16 12:44:39.179022: train_loss -0.9659 
2025-03-16 12:44:39.184607: val_loss -0.9233 
2025-03-16 12:44:39.187211: Pseudo dice [np.float32(0.9396)] 
2025-03-16 12:44:39.190723: Epoch time: 43.18 s 
2025-03-16 12:44:39.194239: Yayy! New best EMA pseudo Dice: 0.9381999969482422 
2025-03-16 12:44:39.920110:  
2025-03-16 12:44:39.926171: Epoch 48 
2025-03-16 12:44:39.929724: Current learning rate: 0.00555 
2025-03-16 12:45:23.363190: train_loss -0.9664 
2025-03-16 12:45:23.368775: val_loss -0.9198 
2025-03-16 12:45:23.371819: Pseudo dice [np.float32(0.9375)] 
2025-03-16 12:45:23.374860: Epoch time: 43.44 s 
2025-03-16 12:45:23.932864:  
2025-03-16 12:45:23.938998: Epoch 49 
2025-03-16 12:45:23.941520: Current learning rate: 0.00546 
2025-03-16 12:46:07.911246: train_loss -0.9685 
2025-03-16 12:46:07.917338: val_loss -0.9207 
2025-03-16 12:46:07.919873: Pseudo dice [np.float32(0.9383)] 
2025-03-16 12:46:07.923918: Epoch time: 43.98 s 
2025-03-16 12:46:08.646374:  
2025-03-16 12:46:08.651937: Epoch 50 
2025-03-16 12:46:08.654489: Current learning rate: 0.00536 
2025-03-16 12:46:52.240558: train_loss -0.9677 
2025-03-16 12:46:52.246618: val_loss -0.9232 
2025-03-16 12:46:52.249626: Pseudo dice [np.float32(0.9394)] 
2025-03-16 12:46:52.253136: Epoch time: 43.59 s 
2025-03-16 12:46:52.255643: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-03-16 12:46:53.004911:  
2025-03-16 12:46:53.010999: Epoch 51 
2025-03-16 12:46:53.014032: Current learning rate: 0.00526 
2025-03-16 12:47:36.531834: train_loss -0.9679 
2025-03-16 12:47:36.538391: val_loss -0.9212 
2025-03-16 12:47:36.541899: Pseudo dice [np.float32(0.9388)] 
2025-03-16 12:47:36.545460: Epoch time: 43.53 s 
2025-03-16 12:47:36.548499: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-03-16 12:47:37.443993:  
2025-03-16 12:47:37.449558: Epoch 52 
2025-03-16 12:47:37.453085: Current learning rate: 0.00517 
2025-03-16 12:48:20.888611: train_loss -0.9672 
2025-03-16 12:48:20.894148: val_loss -0.9207 
2025-03-16 12:48:20.898172: Pseudo dice [np.float32(0.9386)] 
2025-03-16 12:48:20.901210: Epoch time: 43.44 s 
2025-03-16 12:48:20.904218: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-03-16 12:48:21.673529:  
2025-03-16 12:48:21.679566: Epoch 53 
2025-03-16 12:48:21.682464: Current learning rate: 0.00507 
2025-03-16 12:49:04.888371: train_loss -0.9708 
2025-03-16 12:49:04.893986: val_loss -0.9208 
2025-03-16 12:49:04.898128: Pseudo dice [np.float32(0.9387)] 
2025-03-16 12:49:04.901697: Epoch time: 43.21 s 
2025-03-16 12:49:04.904736: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-03-16 12:49:05.674251:  
2025-03-16 12:49:05.679261: Epoch 54 
2025-03-16 12:49:05.682770: Current learning rate: 0.00497 
2025-03-16 12:49:49.272724: train_loss -0.9701 
2025-03-16 12:49:49.278819: val_loss -0.9212 
2025-03-16 12:49:49.282339: Pseudo dice [np.float32(0.9396)] 
2025-03-16 12:49:49.285879: Epoch time: 43.6 s 
2025-03-16 12:49:49.288897: Yayy! New best EMA pseudo Dice: 0.9384999871253967 
2025-03-16 12:49:50.047911:  
2025-03-16 12:49:50.053491: Epoch 55 
2025-03-16 12:49:50.056544: Current learning rate: 0.00487 
2025-03-16 12:50:33.255751: train_loss -0.967 
2025-03-16 12:50:33.262328: val_loss -0.9194 
2025-03-16 12:50:33.265889: Pseudo dice [np.float32(0.9369)] 
2025-03-16 12:50:33.268918: Epoch time: 43.21 s 
2025-03-16 12:50:33.830755:  
2025-03-16 12:50:33.836295: Epoch 56 
2025-03-16 12:50:33.838814: Current learning rate: 0.00478 
2025-03-16 12:51:17.076015: train_loss -0.9693 
2025-03-16 12:51:17.082209: val_loss -0.923 
2025-03-16 12:51:17.085735: Pseudo dice [np.float32(0.9403)] 
2025-03-16 12:51:17.089305: Epoch time: 43.25 s 
2025-03-16 12:51:17.091846: Yayy! New best EMA pseudo Dice: 0.9384999871253967 
2025-03-16 12:51:17.817767:  
2025-03-16 12:51:17.823848: Epoch 57 
2025-03-16 12:51:17.828146: Current learning rate: 0.00468 
2025-03-16 12:52:00.981276: train_loss -0.9679 
2025-03-16 12:52:00.986876: val_loss -0.9189 
2025-03-16 12:52:00.990425: Pseudo dice [np.float32(0.9369)] 
2025-03-16 12:52:00.994473: Epoch time: 43.16 s 
2025-03-16 12:52:01.565578:  
2025-03-16 12:52:01.571711: Epoch 58 
2025-03-16 12:52:01.574748: Current learning rate: 0.00458 
2025-03-16 12:52:45.049752: train_loss -0.9654 
2025-03-16 12:52:45.056793: val_loss -0.9211 
2025-03-16 12:52:45.060406: Pseudo dice [np.float32(0.9382)] 
2025-03-16 12:52:45.062916: Epoch time: 43.49 s 
2025-03-16 12:52:45.642690:  
2025-03-16 12:52:45.648704: Epoch 59 
2025-03-16 12:52:45.652717: Current learning rate: 0.00448 
2025-03-16 12:53:28.778275: train_loss -0.9698 
2025-03-16 12:53:28.784822: val_loss -0.9213 
2025-03-16 12:53:28.787330: Pseudo dice [np.float32(0.9383)] 
2025-03-16 12:53:28.791853: Epoch time: 43.14 s 
2025-03-16 12:53:29.557192:  
2025-03-16 12:53:29.562218: Epoch 60 
2025-03-16 12:53:29.565266: Current learning rate: 0.00438 
2025-03-16 12:54:12.998590: train_loss -0.9712 
2025-03-16 12:54:13.004604: val_loss -0.9216 
2025-03-16 12:54:13.007110: Pseudo dice [np.float32(0.9392)] 
2025-03-16 12:54:13.010615: Epoch time: 43.44 s 
2025-03-16 12:54:13.590161:  
2025-03-16 12:54:13.596180: Epoch 61 
2025-03-16 12:54:13.600189: Current learning rate: 0.00429 
2025-03-16 12:54:56.453166: train_loss -0.9708 
2025-03-16 12:54:56.458746: val_loss -0.9228 
2025-03-16 12:54:56.463280: Pseudo dice [np.float32(0.9401)] 
2025-03-16 12:54:56.466849: Epoch time: 42.86 s 
2025-03-16 12:54:56.470875: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-03-16 12:54:57.211459:  
2025-03-16 12:54:57.216985: Epoch 62 
2025-03-16 12:54:57.220011: Current learning rate: 0.00419 
2025-03-16 12:55:41.095052: train_loss -0.9683 
2025-03-16 12:55:41.101150: val_loss -0.9203 
2025-03-16 12:55:41.105235: Pseudo dice [np.float32(0.9384)] 
2025-03-16 12:55:41.110246: Epoch time: 43.88 s 
2025-03-16 12:55:41.736722:  
2025-03-16 12:55:41.743378: Epoch 63 
2025-03-16 12:55:41.745921: Current learning rate: 0.00409 
2025-03-16 12:56:25.054603: train_loss -0.9705 
2025-03-16 12:56:25.061118: val_loss -0.9214 
2025-03-16 12:56:25.065627: Pseudo dice [np.float32(0.9392)] 
2025-03-16 12:56:25.069639: Epoch time: 43.32 s 
2025-03-16 12:56:25.073649: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-03-16 12:56:25.904665:  
2025-03-16 12:56:25.910703: Epoch 64 
2025-03-16 12:56:25.914752: Current learning rate: 0.00399 
2025-03-16 12:57:09.463191: train_loss -0.9708 
2025-03-16 12:57:09.469203: val_loss -0.9229 
2025-03-16 12:57:09.472212: Pseudo dice [np.float32(0.9401)] 
2025-03-16 12:57:09.475721: Epoch time: 43.56 s 
2025-03-16 12:57:09.479729: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-03-16 12:57:10.275873:  
2025-03-16 12:57:10.282470: Epoch 65 
2025-03-16 12:57:10.285010: Current learning rate: 0.00389 
2025-03-16 12:57:54.003794: train_loss -0.9725 
2025-03-16 12:57:54.009926: val_loss -0.9212 
2025-03-16 12:57:54.013450: Pseudo dice [np.float32(0.9393)] 
2025-03-16 12:57:54.017478: Epoch time: 43.73 s 
2025-03-16 12:57:54.020998: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-03-16 12:57:54.770827:  
2025-03-16 12:57:54.776893: Epoch 66 
2025-03-16 12:57:54.780462: Current learning rate: 0.00379 
2025-03-16 12:58:38.491477: train_loss -0.9714 
2025-03-16 12:58:38.498029: val_loss -0.921 
2025-03-16 12:58:38.501052: Pseudo dice [np.float32(0.939)] 
2025-03-16 12:58:38.504084: Epoch time: 43.72 s 
2025-03-16 12:58:38.507606: Yayy! New best EMA pseudo Dice: 0.9388999938964844 
2025-03-16 12:58:39.252197:  
2025-03-16 12:58:39.258226: Epoch 67 
2025-03-16 12:58:39.261738: Current learning rate: 0.00369 
2025-03-16 12:59:22.572146: train_loss -0.9718 
2025-03-16 12:59:22.578302: val_loss -0.923 
2025-03-16 12:59:22.583372: Pseudo dice [np.float32(0.9406)] 
2025-03-16 12:59:22.586414: Epoch time: 43.32 s 
2025-03-16 12:59:22.590962: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-03-16 12:59:23.508280:  
2025-03-16 12:59:23.513793: Epoch 68 
2025-03-16 12:59:23.517301: Current learning rate: 0.00359 
2025-03-16 13:00:07.153803: train_loss -0.9675 
2025-03-16 13:00:07.159316: val_loss -0.9213 
2025-03-16 13:00:07.164328: Pseudo dice [np.float32(0.9384)] 
2025-03-16 13:00:07.167837: Epoch time: 43.65 s 
2025-03-16 13:00:07.772802:  
2025-03-16 13:00:07.778390: Epoch 69 
2025-03-16 13:00:07.780975: Current learning rate: 0.00349 
2025-03-16 13:00:52.199802: train_loss -0.9681 
2025-03-16 13:00:52.205944: val_loss -0.9196 
2025-03-16 13:00:52.210036: Pseudo dice [np.float32(0.9375)] 
2025-03-16 13:00:52.214149: Epoch time: 44.43 s 
2025-03-16 13:00:52.830096:  
2025-03-16 13:00:52.835611: Epoch 70 
2025-03-16 13:00:52.840626: Current learning rate: 0.00338 
2025-03-16 13:01:37.544791: train_loss -0.9674 
2025-03-16 13:01:37.550326: val_loss -0.9224 
2025-03-16 13:01:37.554334: Pseudo dice [np.float32(0.9394)] 
2025-03-16 13:01:37.557843: Epoch time: 44.72 s 
2025-03-16 13:01:38.141660:  
2025-03-16 13:01:38.148234: Epoch 71 
2025-03-16 13:01:38.153280: Current learning rate: 0.00328 
2025-03-16 13:02:20.909278: train_loss -0.9706 
2025-03-16 13:02:20.914843: val_loss -0.9227 
2025-03-16 13:02:20.919374: Pseudo dice [np.float32(0.9402)] 
2025-03-16 13:02:20.922883: Epoch time: 42.77 s 
2025-03-16 13:02:21.502050:  
2025-03-16 13:02:21.507061: Epoch 72 
2025-03-16 13:02:21.511072: Current learning rate: 0.00318 
2025-03-16 13:03:04.286013: train_loss -0.972 
2025-03-16 13:03:04.292367: val_loss -0.9208 
2025-03-16 13:03:04.296414: Pseudo dice [np.float32(0.9384)] 
2025-03-16 13:03:04.299925: Epoch time: 42.78 s 
2025-03-16 13:03:04.882935:  
2025-03-16 13:03:04.887460: Epoch 73 
2025-03-16 13:03:04.891047: Current learning rate: 0.00308 
2025-03-16 13:03:47.583691: train_loss -0.9717 
2025-03-16 13:03:47.590230: val_loss -0.9202 
2025-03-16 13:03:47.593738: Pseudo dice [np.float32(0.9387)] 
2025-03-16 13:03:47.596746: Epoch time: 42.7 s 
2025-03-16 13:03:48.178617:  
2025-03-16 13:03:48.184130: Epoch 74 
2025-03-16 13:03:48.187645: Current learning rate: 0.00297 
2025-03-16 13:04:30.840428: train_loss -0.9723 
2025-03-16 13:04:30.846941: val_loss -0.9213 
2025-03-16 13:04:30.850453: Pseudo dice [np.float32(0.9393)] 
2025-03-16 13:04:30.853956: Epoch time: 42.66 s 
2025-03-16 13:04:31.440233:  
2025-03-16 13:04:31.443755: Epoch 75 
2025-03-16 13:04:31.446772: Current learning rate: 0.00287 
2025-03-16 13:05:14.165031: train_loss -0.9632 
2025-03-16 13:05:14.171232: val_loss -0.9276 
2025-03-16 13:05:14.175240: Pseudo dice [np.float32(0.9426)] 
2025-03-16 13:05:14.178749: Epoch time: 42.73 s 
2025-03-16 13:05:14.181255: Yayy! New best EMA pseudo Dice: 0.939300000667572 
2025-03-16 13:05:15.082756:  
2025-03-16 13:05:15.088268: Epoch 76 
2025-03-16 13:05:15.091780: Current learning rate: 0.00277 
2025-03-16 13:05:58.581602: train_loss -0.9682 
2025-03-16 13:05:58.587148: val_loss -0.9221 
2025-03-16 13:05:58.590658: Pseudo dice [np.float32(0.9398)] 
2025-03-16 13:05:58.594163: Epoch time: 43.5 s 
2025-03-16 13:05:58.597193: Yayy! New best EMA pseudo Dice: 0.9394000172615051 
2025-03-16 13:05:59.383269:  
2025-03-16 13:05:59.389810: Epoch 77 
2025-03-16 13:05:59.393322: Current learning rate: 0.00266 
2025-03-16 13:06:42.933728: train_loss -0.9721 
2025-03-16 13:06:42.939874: val_loss -0.9195 
2025-03-16 13:06:42.943390: Pseudo dice [np.float32(0.9381)] 
2025-03-16 13:06:42.946431: Epoch time: 43.55 s 
2025-03-16 13:06:43.590434:  
2025-03-16 13:06:43.596965: Epoch 78 
2025-03-16 13:06:43.600588: Current learning rate: 0.00256 
2025-03-16 13:07:28.283147: train_loss -0.9717 
2025-03-16 13:07:28.288717: val_loss -0.9207 
2025-03-16 13:07:28.292736: Pseudo dice [np.float32(0.9388)] 
2025-03-16 13:07:28.296285: Epoch time: 44.69 s 
2025-03-16 13:07:28.913786:  
2025-03-16 13:07:28.919365: Epoch 79 
2025-03-16 13:07:28.922943: Current learning rate: 0.00245 
2025-03-16 13:08:11.817862: train_loss -0.9704 
2025-03-16 13:08:11.824377: val_loss -0.9181 
2025-03-16 13:08:11.827920: Pseudo dice [np.float32(0.9368)] 
2025-03-16 13:08:11.831424: Epoch time: 42.9 s 
2025-03-16 13:08:12.382255:  
2025-03-16 13:08:12.388869: Epoch 80 
2025-03-16 13:08:12.391905: Current learning rate: 0.00235 
2025-03-16 13:08:54.954792: train_loss -0.9725 
2025-03-16 13:08:54.959802: val_loss -0.9199 
2025-03-16 13:08:54.963813: Pseudo dice [np.float32(0.9385)] 
2025-03-16 13:08:54.967321: Epoch time: 42.57 s 
2025-03-16 13:08:55.522648:  
2025-03-16 13:08:55.529166: Epoch 81 
2025-03-16 13:08:55.532674: Current learning rate: 0.00224 
2025-03-16 13:09:38.190217: train_loss -0.9736 
2025-03-16 13:09:38.196264: val_loss -0.9206 
2025-03-16 13:09:38.199795: Pseudo dice [np.float32(0.9392)] 
2025-03-16 13:09:38.202825: Epoch time: 42.67 s 
2025-03-16 13:09:38.768651:  
2025-03-16 13:09:38.774765: Epoch 82 
2025-03-16 13:09:38.777810: Current learning rate: 0.00214 
2025-03-16 13:10:21.730251: train_loss -0.9725 
2025-03-16 13:10:21.737263: val_loss -0.9198 
2025-03-16 13:10:21.740270: Pseudo dice [np.float32(0.9382)] 
2025-03-16 13:10:21.743778: Epoch time: 42.96 s 
2025-03-16 13:10:22.263987:  
2025-03-16 13:10:22.269520: Epoch 83 
2025-03-16 13:10:22.272542: Current learning rate: 0.00203 
2025-03-16 13:11:04.866210: train_loss -0.9732 
2025-03-16 13:11:04.872222: val_loss -0.9194 
2025-03-16 13:11:04.875728: Pseudo dice [np.float32(0.9389)] 
2025-03-16 13:11:04.878736: Epoch time: 42.6 s 
2025-03-16 13:11:05.558894:  
2025-03-16 13:11:05.564907: Epoch 84 
2025-03-16 13:11:05.568412: Current learning rate: 0.00192 
2025-03-16 13:11:48.131860: train_loss -0.974 
2025-03-16 13:11:48.137426: val_loss -0.9194 
2025-03-16 13:11:48.140451: Pseudo dice [np.float32(0.9385)] 
2025-03-16 13:11:48.143971: Epoch time: 42.57 s 
2025-03-16 13:11:48.677657:  
2025-03-16 13:11:48.683678: Epoch 85 
2025-03-16 13:11:48.686689: Current learning rate: 0.00181 
2025-03-16 13:12:31.287882: train_loss -0.9734 
2025-03-16 13:12:31.294899: val_loss -0.9177 
2025-03-16 13:12:31.298917: Pseudo dice [np.float32(0.9369)] 
2025-03-16 13:12:31.302923: Epoch time: 42.61 s 
2025-03-16 13:12:31.820356:  
2025-03-16 13:12:31.826921: Epoch 86 
2025-03-16 13:12:31.829453: Current learning rate: 0.0017 
2025-03-16 13:13:14.388647: train_loss -0.9728 
2025-03-16 13:13:14.395200: val_loss -0.9201 
2025-03-16 13:13:14.398734: Pseudo dice [np.float32(0.9387)] 
2025-03-16 13:13:14.403808: Epoch time: 42.57 s 
2025-03-16 13:13:14.925378:  
2025-03-16 13:13:14.931967: Epoch 87 
2025-03-16 13:13:14.934496: Current learning rate: 0.00159 
2025-03-16 13:13:57.555667: train_loss -0.9745 
2025-03-16 13:13:57.562798: val_loss -0.9235 
2025-03-16 13:13:57.566305: Pseudo dice [np.float32(0.9412)] 
2025-03-16 13:13:57.570312: Epoch time: 42.63 s 
2025-03-16 13:13:58.085834:  
2025-03-16 13:13:58.093377: Epoch 88 
2025-03-16 13:13:58.097406: Current learning rate: 0.00148 
2025-03-16 13:14:40.695218: train_loss -0.9742 
2025-03-16 13:14:40.702244: val_loss -0.9193 
2025-03-16 13:14:40.705753: Pseudo dice [np.float32(0.9387)] 
2025-03-16 13:14:40.709760: Epoch time: 42.61 s 
2025-03-16 13:14:41.232417:  
2025-03-16 13:14:41.238466: Epoch 89 
2025-03-16 13:14:41.243006: Current learning rate: 0.00137 
2025-03-16 13:15:23.847914: train_loss -0.9729 
2025-03-16 13:15:23.855936: val_loss -0.92 
2025-03-16 13:15:23.859445: Pseudo dice [np.float32(0.9386)] 
2025-03-16 13:15:23.863452: Epoch time: 42.62 s 
2025-03-16 13:15:24.379468:  
2025-03-16 13:15:24.385557: Epoch 90 
2025-03-16 13:15:24.388568: Current learning rate: 0.00126 
2025-03-16 13:16:07.070059: train_loss -0.9737 
2025-03-16 13:16:07.076576: val_loss -0.9201 
2025-03-16 13:16:07.080095: Pseudo dice [np.float32(0.9391)] 
2025-03-16 13:16:07.085105: Epoch time: 42.69 s 
2025-03-16 13:16:07.598597:  
2025-03-16 13:16:07.605110: Epoch 91 
2025-03-16 13:16:07.608618: Current learning rate: 0.00115 
2025-03-16 13:16:50.178144: train_loss -0.9745 
2025-03-16 13:16:50.184658: val_loss -0.9221 
2025-03-16 13:16:50.188163: Pseudo dice [np.float32(0.9405)] 
2025-03-16 13:16:50.192176: Epoch time: 42.58 s 
2025-03-16 13:16:50.868152:  
2025-03-16 13:16:50.875190: Epoch 92 
2025-03-16 13:16:50.878232: Current learning rate: 0.00103 
2025-03-16 13:17:33.434739: train_loss -0.9743 
2025-03-16 13:17:33.441780: val_loss -0.9209 
2025-03-16 13:17:33.445793: Pseudo dice [np.float32(0.9395)] 
2025-03-16 13:17:33.449806: Epoch time: 42.57 s 
2025-03-16 13:17:33.966339:  
2025-03-16 13:17:33.972939: Epoch 93 
2025-03-16 13:17:33.976990: Current learning rate: 0.00091 
2025-03-16 13:18:16.654248: train_loss -0.9747 
2025-03-16 13:18:16.660269: val_loss -0.9204 
2025-03-16 13:18:16.664282: Pseudo dice [np.float32(0.9392)] 
2025-03-16 13:18:16.668794: Epoch time: 42.69 s 
2025-03-16 13:18:17.205107:  
2025-03-16 13:18:17.211152: Epoch 94 
2025-03-16 13:18:17.215188: Current learning rate: 0.00079 
2025-03-16 13:18:59.890793: train_loss -0.9746 
2025-03-16 13:18:59.897388: val_loss -0.9193 
2025-03-16 13:18:59.901427: Pseudo dice [np.float32(0.9385)] 
2025-03-16 13:18:59.904949: Epoch time: 42.69 s 
2025-03-16 13:19:00.434544:  
2025-03-16 13:19:00.439629: Epoch 95 
2025-03-16 13:19:00.444701: Current learning rate: 0.00067 
2025-03-16 13:19:42.929770: train_loss -0.9743 
2025-03-16 13:19:42.937032: val_loss -0.9193 
2025-03-16 13:19:42.941090: Pseudo dice [np.float32(0.9383)] 
2025-03-16 13:19:42.945112: Epoch time: 42.5 s 
2025-03-16 13:19:43.482591:  
2025-03-16 13:19:43.489145: Epoch 96 
2025-03-16 13:19:43.493178: Current learning rate: 0.00055 
2025-03-16 13:20:25.924659: train_loss -0.9751 
2025-03-16 13:20:25.932800: val_loss -0.9201 
2025-03-16 13:20:25.936328: Pseudo dice [np.float32(0.9389)] 
2025-03-16 13:20:25.939862: Epoch time: 42.44 s 
2025-03-16 13:20:26.462978:  
2025-03-16 13:20:26.468493: Epoch 97 
2025-03-16 13:20:26.472002: Current learning rate: 0.00043 
2025-03-16 13:21:08.927058: train_loss -0.9725 
2025-03-16 13:21:08.933568: val_loss -0.9214 
2025-03-16 13:21:08.937075: Pseudo dice [np.float32(0.9401)] 
2025-03-16 13:21:08.939580: Epoch time: 42.47 s 
2025-03-16 13:21:09.462597:  
2025-03-16 13:21:09.468618: Epoch 98 
2025-03-16 13:21:09.471131: Current learning rate: 0.0003 
2025-03-16 13:21:51.886643: train_loss -0.9744 
2025-03-16 13:21:51.892652: val_loss -0.9197 
2025-03-16 13:21:51.896668: Pseudo dice [np.float32(0.9386)] 
2025-03-16 13:21:51.899172: Epoch time: 42.42 s 
2025-03-16 13:21:52.430501:  
2025-03-16 13:21:52.436016: Epoch 99 
2025-03-16 13:21:52.439525: Current learning rate: 0.00016 
2025-03-16 13:22:34.863782: train_loss -0.9749 
2025-03-16 13:22:34.869820: val_loss -0.9176 
2025-03-16 13:22:34.873354: Pseudo dice [np.float32(0.9373)] 
2025-03-16 13:22:34.876364: Epoch time: 42.43 s 
2025-03-16 13:22:35.601179: Training done. 
2025-03-16 13:22:35.626184: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-16 13:22:35.631698: The split file contains 5 splits. 
2025-03-16 13:22:35.637697: Desired fold for training: 0 
2025-03-16 13:22:35.641699: This split has 16 training and 4 validation cases. 
2025-03-16 13:22:35.647699: predicting la_007 
2025-03-16 13:22:35.651697: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2025-03-16 13:22:41.491642: predicting la_016 
2025-03-16 13:22:41.502641: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2025-03-16 13:22:43.754207: predicting la_021 
2025-03-16 13:22:43.763209: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2025-03-16 13:22:46.017732: predicting la_024 
2025-03-16 13:22:46.028731: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2025-03-16 13:22:54.906983: Validation complete 
2025-03-16 13:22:54.911982: Mean Validation Dice:  0.7851810939106064 
