
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-17 06:35:35.711220: do_dummy_2d_data_aug: False 
2025-03-17 06:35:35.713141: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-17 06:35:35.718374: The split file contains 5 splits. 
2025-03-17 06:35:35.721375: Desired fold for training: 0 
2025-03-17 06:35:35.724376: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2025-03-17 06:35:42.947244: unpacking dataset... 
2025-03-17 06:35:43.114190: unpacking done... 
2025-03-17 06:35:46.295942:  
2025-03-17 06:35:46.300955: Epoch 0 
2025-03-17 06:35:46.303966: Current learning rate: 0.01 
2025-03-17 06:36:33.193497: train_loss -0.6335 
2025-03-17 06:36:33.199267: val_loss -0.8661 
2025-03-17 06:36:33.204350: Pseudo dice [np.float32(0.8944)] 
2025-03-17 06:36:33.206862: Epoch time: 46.9 s 
2025-03-17 06:36:33.209912: Yayy! New best EMA pseudo Dice: 0.8944000005722046 
2025-03-17 06:36:33.857788:  
2025-03-17 06:36:33.863856: Epoch 1 
2025-03-17 06:36:33.867447: Current learning rate: 0.00991 
2025-03-17 06:37:16.371007: train_loss -0.8643 
2025-03-17 06:37:16.376572: val_loss -0.8946 
2025-03-17 06:37:16.380100: Pseudo dice [np.float32(0.9192)] 
2025-03-17 06:37:16.383171: Epoch time: 42.51 s 
2025-03-17 06:37:16.386227: Yayy! New best EMA pseudo Dice: 0.8968999981880188 
2025-03-17 06:37:17.108135:  
2025-03-17 06:37:17.113190: Epoch 2 
2025-03-17 06:37:17.117246: Current learning rate: 0.00982 
2025-03-17 06:37:59.583071: train_loss -0.8911 
2025-03-17 06:37:59.589731: val_loss -0.9019 
2025-03-17 06:37:59.592788: Pseudo dice [np.float32(0.9274)] 
2025-03-17 06:37:59.595827: Epoch time: 42.48 s 
2025-03-17 06:37:59.598868: Yayy! New best EMA pseudo Dice: 0.8999000191688538 
2025-03-17 06:38:00.354814:  
2025-03-17 06:38:00.361332: Epoch 3 
2025-03-17 06:38:00.364837: Current learning rate: 0.00973 
2025-03-17 06:38:42.832963: train_loss -0.8994 
2025-03-17 06:38:42.839036: val_loss -0.8995 
2025-03-17 06:38:42.842069: Pseudo dice [np.float32(0.923)] 
2025-03-17 06:38:42.845596: Epoch time: 42.48 s 
2025-03-17 06:38:42.848631: Yayy! New best EMA pseudo Dice: 0.9021999835968018 
2025-03-17 06:38:43.585356:  
2025-03-17 06:38:43.591908: Epoch 4 
2025-03-17 06:38:43.597987: Current learning rate: 0.00964 
2025-03-17 06:39:26.081422: train_loss -0.9081 
2025-03-17 06:39:26.087434: val_loss -0.9043 
2025-03-17 06:39:26.090964: Pseudo dice [np.float32(0.9245)] 
2025-03-17 06:39:26.094007: Epoch time: 42.5 s 
2025-03-17 06:39:26.096030: Yayy! New best EMA pseudo Dice: 0.9045000076293945 
2025-03-17 06:39:26.983007:  
2025-03-17 06:39:26.989100: Epoch 5 
2025-03-17 06:39:26.992160: Current learning rate: 0.00955 
2025-03-17 06:40:09.492433: train_loss -0.911 
2025-03-17 06:40:09.497551: val_loss -0.9076 
2025-03-17 06:40:09.502109: Pseudo dice [np.float32(0.927)] 
2025-03-17 06:40:09.505176: Epoch time: 42.51 s 
2025-03-17 06:40:09.508203: Yayy! New best EMA pseudo Dice: 0.9067000150680542 
2025-03-17 06:40:10.234386:  
2025-03-17 06:40:10.240488: Epoch 6 
2025-03-17 06:40:10.243035: Current learning rate: 0.00946 
2025-03-17 06:40:52.726917: train_loss -0.9056 
2025-03-17 06:40:52.732492: val_loss -0.9072 
2025-03-17 06:40:52.737040: Pseudo dice [np.float32(0.9279)] 
2025-03-17 06:40:52.740078: Epoch time: 42.49 s 
2025-03-17 06:40:52.742607: Yayy! New best EMA pseudo Dice: 0.9088000059127808 
2025-03-17 06:40:53.480228:  
2025-03-17 06:40:53.487242: Epoch 7 
2025-03-17 06:40:53.490803: Current learning rate: 0.00937 
2025-03-17 06:41:35.975364: train_loss -0.9172 
2025-03-17 06:41:35.983580: val_loss -0.9136 
2025-03-17 06:41:35.987086: Pseudo dice [np.float32(0.9324)] 
2025-03-17 06:41:35.990094: Epoch time: 42.5 s 
2025-03-17 06:41:35.992599: Yayy! New best EMA pseudo Dice: 0.9111999869346619 
2025-03-17 06:41:36.736826:  
2025-03-17 06:41:36.742895: Epoch 8 
2025-03-17 06:41:36.745430: Current learning rate: 0.00928 
2025-03-17 06:42:19.265591: train_loss -0.9234 
2025-03-17 06:42:19.272167: val_loss -0.9157 
2025-03-17 06:42:19.275223: Pseudo dice [np.float32(0.9328)] 
2025-03-17 06:42:19.278319: Epoch time: 42.53 s 
2025-03-17 06:42:19.281825: Yayy! New best EMA pseudo Dice: 0.9133999943733215 
2025-03-17 06:42:20.042243:  
2025-03-17 06:42:20.046296: Epoch 9 
2025-03-17 06:42:20.050866: Current learning rate: 0.00919 
2025-03-17 06:43:02.470350: train_loss -0.9331 
2025-03-17 06:43:02.476386: val_loss -0.9193 
2025-03-17 06:43:02.479404: Pseudo dice [np.float32(0.9367)] 
2025-03-17 06:43:02.482934: Epoch time: 42.43 s 
2025-03-17 06:43:02.485448: Yayy! New best EMA pseudo Dice: 0.9157000184059143 
2025-03-17 06:43:03.207821:  
2025-03-17 06:43:03.211873: Epoch 10 
2025-03-17 06:43:03.215995: Current learning rate: 0.0091 
2025-03-17 06:43:45.710890: train_loss -0.9313 
2025-03-17 06:43:45.716901: val_loss -0.9172 
2025-03-17 06:43:45.719908: Pseudo dice [np.float32(0.935)] 
2025-03-17 06:43:45.723417: Epoch time: 42.5 s 
2025-03-17 06:43:45.725922: Yayy! New best EMA pseudo Dice: 0.9175999760627747 
2025-03-17 06:43:46.484106:  
2025-03-17 06:43:46.489621: Epoch 11 
2025-03-17 06:43:46.493633: Current learning rate: 0.009 
2025-03-17 06:44:28.961046: train_loss -0.941 
2025-03-17 06:44:28.966130: val_loss -0.9193 
2025-03-17 06:44:28.970175: Pseudo dice [np.float32(0.9358)] 
2025-03-17 06:44:28.973294: Epoch time: 42.48 s 
2025-03-17 06:44:28.976803: Yayy! New best EMA pseudo Dice: 0.9193999767303467 
2025-03-17 06:44:29.689061:  
2025-03-17 06:44:29.695136: Epoch 12 
2025-03-17 06:44:29.698197: Current learning rate: 0.00891 
2025-03-17 06:45:12.179921: train_loss -0.9333 
2025-03-17 06:45:12.184458: val_loss -0.9151 
2025-03-17 06:45:12.187980: Pseudo dice [np.float32(0.9316)] 
2025-03-17 06:45:12.191007: Epoch time: 42.49 s 
2025-03-17 06:45:12.194094: Yayy! New best EMA pseudo Dice: 0.9207000136375427 
2025-03-17 06:45:13.068911:  
2025-03-17 06:45:13.075007: Epoch 13 
2025-03-17 06:45:13.078516: Current learning rate: 0.00882 
2025-03-17 06:45:55.524760: train_loss -0.9314 
2025-03-17 06:45:55.528308: val_loss -0.9209 
2025-03-17 06:45:55.531835: Pseudo dice [np.float32(0.9372)] 
2025-03-17 06:45:55.535369: Epoch time: 42.46 s 
2025-03-17 06:45:55.538406: Yayy! New best EMA pseudo Dice: 0.9222999811172485 
2025-03-17 06:45:56.273897:  
2025-03-17 06:45:56.279836: Epoch 14 
2025-03-17 06:45:56.283847: Current learning rate: 0.00873 
2025-03-17 06:46:38.736953: train_loss -0.9409 
2025-03-17 06:46:38.743053: val_loss -0.9197 
2025-03-17 06:46:38.746155: Pseudo dice [np.float32(0.9361)] 
2025-03-17 06:46:38.749209: Epoch time: 42.46 s 
2025-03-17 06:46:38.752259: Yayy! New best EMA pseudo Dice: 0.9236999750137329 
2025-03-17 06:46:39.492197:  
2025-03-17 06:46:39.497719: Epoch 15 
2025-03-17 06:46:39.501236: Current learning rate: 0.00864 
2025-03-17 06:47:21.952100: train_loss -0.9417 
2025-03-17 06:47:21.957663: val_loss -0.9179 
2025-03-17 06:47:21.961176: Pseudo dice [np.float32(0.9334)] 
2025-03-17 06:47:21.963683: Epoch time: 42.46 s 
2025-03-17 06:47:21.967189: Yayy! New best EMA pseudo Dice: 0.9247000217437744 
2025-03-17 06:47:22.713694:  
2025-03-17 06:47:22.719728: Epoch 16 
2025-03-17 06:47:22.722807: Current learning rate: 0.00855 
2025-03-17 06:48:05.231076: train_loss -0.9371 
2025-03-17 06:48:05.237594: val_loss -0.9118 
2025-03-17 06:48:05.240100: Pseudo dice [np.float32(0.9314)] 
2025-03-17 06:48:05.243605: Epoch time: 42.52 s 
2025-03-17 06:48:05.246612: Yayy! New best EMA pseudo Dice: 0.9253000020980835 
2025-03-17 06:48:05.998806:  
2025-03-17 06:48:06.004937: Epoch 17 
2025-03-17 06:48:06.007477: Current learning rate: 0.00846 
2025-03-17 06:48:48.500819: train_loss -0.933 
2025-03-17 06:48:48.507332: val_loss -0.92 
2025-03-17 06:48:48.509837: Pseudo dice [np.float32(0.9365)] 
2025-03-17 06:48:48.513345: Epoch time: 42.5 s 
2025-03-17 06:48:48.515851: Yayy! New best EMA pseudo Dice: 0.9264000058174133 
2025-03-17 06:48:49.265661:  
2025-03-17 06:48:49.271196: Epoch 18 
2025-03-17 06:48:49.274273: Current learning rate: 0.00836 
2025-03-17 06:49:31.742760: train_loss -0.9448 
2025-03-17 06:49:31.748307: val_loss -0.9221 
2025-03-17 06:49:31.751827: Pseudo dice [np.float32(0.9375)] 
2025-03-17 06:49:31.754848: Epoch time: 42.48 s 
2025-03-17 06:49:31.757938: Yayy! New best EMA pseudo Dice: 0.9276000261306763 
2025-03-17 06:49:32.517700:  
2025-03-17 06:49:32.523806: Epoch 19 
2025-03-17 06:49:32.527837: Current learning rate: 0.00827 
2025-03-17 06:50:14.981669: train_loss -0.9449 
2025-03-17 06:50:14.987221: val_loss -0.9189 
2025-03-17 06:50:14.990783: Pseudo dice [np.float32(0.9357)] 
2025-03-17 06:50:14.993844: Epoch time: 42.46 s 
2025-03-17 06:50:14.996889: Yayy! New best EMA pseudo Dice: 0.9283999800682068 
2025-03-17 06:50:15.757464:  
2025-03-17 06:50:15.763530: Epoch 20 
2025-03-17 06:50:15.767044: Current learning rate: 0.00818 
2025-03-17 06:50:58.247939: train_loss -0.9462 
2025-03-17 06:50:58.253964: val_loss -0.9185 
2025-03-17 06:50:58.257470: Pseudo dice [np.float32(0.9351)] 
2025-03-17 06:50:58.260485: Epoch time: 42.49 s 
2025-03-17 06:50:58.264000: Yayy! New best EMA pseudo Dice: 0.9290000200271606 
2025-03-17 06:50:59.178147:  
2025-03-17 06:50:59.183171: Epoch 21 
2025-03-17 06:50:59.187233: Current learning rate: 0.00809 
2025-03-17 06:51:41.653859: train_loss -0.9499 
2025-03-17 06:51:41.659938: val_loss -0.9213 
2025-03-17 06:51:41.662485: Pseudo dice [np.float32(0.9369)] 
2025-03-17 06:51:41.665008: Epoch time: 42.48 s 
2025-03-17 06:51:41.669659: Yayy! New best EMA pseudo Dice: 0.9297999739646912 
2025-03-17 06:51:42.393414:  
2025-03-17 06:51:42.398994: Epoch 22 
2025-03-17 06:51:42.402523: Current learning rate: 0.008 
2025-03-17 06:52:24.882945: train_loss -0.9544 
2025-03-17 06:52:24.888523: val_loss -0.9199 
2025-03-17 06:52:24.893032: Pseudo dice [np.float32(0.9362)] 
2025-03-17 06:52:24.896046: Epoch time: 42.49 s 
2025-03-17 06:52:24.900557: Yayy! New best EMA pseudo Dice: 0.9304999709129333 
2025-03-17 06:52:25.630933:  
2025-03-17 06:52:25.637051: Epoch 23 
2025-03-17 06:52:25.641079: Current learning rate: 0.0079 
2025-03-17 06:53:08.129331: train_loss -0.9523 
2025-03-17 06:53:08.134879: val_loss -0.9201 
2025-03-17 06:53:08.138388: Pseudo dice [np.float32(0.9361)] 
2025-03-17 06:53:08.142395: Epoch time: 42.5 s 
2025-03-17 06:53:08.144900: Yayy! New best EMA pseudo Dice: 0.9309999942779541 
2025-03-17 06:53:08.856580:  
2025-03-17 06:53:08.860592: Epoch 24 
2025-03-17 06:53:08.864100: Current learning rate: 0.00781 
2025-03-17 06:53:51.311875: train_loss -0.951 
2025-03-17 06:53:51.317492: val_loss -0.9231 
2025-03-17 06:53:51.320045: Pseudo dice [np.float32(0.9377)] 
2025-03-17 06:53:51.324100: Epoch time: 42.46 s 
2025-03-17 06:53:51.327159: Yayy! New best EMA pseudo Dice: 0.9316999912261963 
2025-03-17 06:53:52.087134:  
2025-03-17 06:53:52.092648: Epoch 25 
2025-03-17 06:53:52.096156: Current learning rate: 0.00772 
2025-03-17 06:54:34.619969: train_loss -0.9553 
2025-03-17 06:54:34.625983: val_loss -0.9215 
2025-03-17 06:54:34.629992: Pseudo dice [np.float32(0.9373)] 
2025-03-17 06:54:34.632497: Epoch time: 42.53 s 
2025-03-17 06:54:34.636005: Yayy! New best EMA pseudo Dice: 0.932200014591217 
2025-03-17 06:54:35.352130:  
2025-03-17 06:54:35.356168: Epoch 26 
2025-03-17 06:54:35.360265: Current learning rate: 0.00763 
2025-03-17 06:55:17.828453: train_loss -0.9586 
2025-03-17 06:55:17.833980: val_loss -0.9203 
2025-03-17 06:55:17.837491: Pseudo dice [np.float32(0.9362)] 
2025-03-17 06:55:17.841003: Epoch time: 42.48 s 
2025-03-17 06:55:17.844147: Yayy! New best EMA pseudo Dice: 0.9326000213623047 
2025-03-17 06:55:18.565819:  
2025-03-17 06:55:18.571857: Epoch 27 
2025-03-17 06:55:18.574889: Current learning rate: 0.00753 
2025-03-17 06:56:01.045239: train_loss -0.9573 
2025-03-17 06:56:01.051283: val_loss -0.9228 
2025-03-17 06:56:01.054310: Pseudo dice [np.float32(0.9388)] 
2025-03-17 06:56:01.057827: Epoch time: 42.48 s 
2025-03-17 06:56:01.060848: Yayy! New best EMA pseudo Dice: 0.9333000183105469 
2025-03-17 06:56:01.790491:  
2025-03-17 06:56:01.796060: Epoch 28 
2025-03-17 06:56:01.800678: Current learning rate: 0.00744 
2025-03-17 06:56:44.251803: train_loss -0.9577 
2025-03-17 06:56:44.257906: val_loss -0.9214 
2025-03-17 06:56:44.261938: Pseudo dice [np.float32(0.9373)] 
2025-03-17 06:56:44.264948: Epoch time: 42.46 s 
2025-03-17 06:56:44.268459: Yayy! New best EMA pseudo Dice: 0.9337000250816345 
2025-03-17 06:56:45.164807:  
2025-03-17 06:56:45.170338: Epoch 29 
2025-03-17 06:56:45.173851: Current learning rate: 0.00735 
2025-03-17 06:57:27.642735: train_loss -0.9594 
2025-03-17 06:57:27.649251: val_loss -0.9195 
2025-03-17 06:57:27.653263: Pseudo dice [np.float32(0.9363)] 
2025-03-17 06:57:27.655767: Epoch time: 42.48 s 
2025-03-17 06:57:27.659276: Yayy! New best EMA pseudo Dice: 0.933899998664856 
2025-03-17 06:57:28.403033:  
2025-03-17 06:57:28.409069: Epoch 30 
2025-03-17 06:57:28.412099: Current learning rate: 0.00725 
2025-03-17 06:58:11.237389: train_loss -0.959 
2025-03-17 06:58:11.243915: val_loss -0.9243 
2025-03-17 06:58:11.247432: Pseudo dice [np.float32(0.9397)] 
2025-03-17 06:58:11.250943: Epoch time: 42.84 s 
2025-03-17 06:58:11.253955: Yayy! New best EMA pseudo Dice: 0.934499979019165 
2025-03-17 06:58:11.988293:  
2025-03-17 06:58:11.993851: Epoch 31 
2025-03-17 06:58:11.996386: Current learning rate: 0.00716 
2025-03-17 06:58:54.495883: train_loss -0.9557 
2025-03-17 06:58:54.502009: val_loss -0.9223 
2025-03-17 06:58:54.506046: Pseudo dice [np.float32(0.9381)] 
2025-03-17 06:58:54.508702: Epoch time: 42.51 s 
2025-03-17 06:58:54.512261: Yayy! New best EMA pseudo Dice: 0.9348999857902527 
2025-03-17 06:58:55.248805:  
2025-03-17 06:58:55.253816: Epoch 32 
2025-03-17 06:58:55.257828: Current learning rate: 0.00707 
2025-03-17 06:59:37.730647: train_loss -0.9584 
2025-03-17 06:59:37.736671: val_loss -0.9211 
2025-03-17 06:59:37.740688: Pseudo dice [np.float32(0.9368)] 
2025-03-17 06:59:37.744200: Epoch time: 42.48 s 
2025-03-17 06:59:37.747713: Yayy! New best EMA pseudo Dice: 0.9351000189781189 
2025-03-17 06:59:38.495050:  
2025-03-17 06:59:38.502253: Epoch 33 
2025-03-17 06:59:38.505770: Current learning rate: 0.00697 
2025-03-17 07:00:20.976692: train_loss -0.9609 
2025-03-17 07:00:20.982777: val_loss -0.923 
2025-03-17 07:00:20.986817: Pseudo dice [np.float32(0.9384)] 
2025-03-17 07:00:20.990416: Epoch time: 42.48 s 
2025-03-17 07:00:20.993973: Yayy! New best EMA pseudo Dice: 0.9354000091552734 
2025-03-17 07:00:21.725412:  
2025-03-17 07:00:21.732447: Epoch 34 
2025-03-17 07:00:21.735976: Current learning rate: 0.00688 
2025-03-17 07:01:04.238588: train_loss -0.9614 
2025-03-17 07:01:04.244658: val_loss -0.9217 
2025-03-17 07:01:04.249705: Pseudo dice [np.float32(0.9381)] 
2025-03-17 07:01:04.253239: Epoch time: 42.51 s 
2025-03-17 07:01:04.256267: Yayy! New best EMA pseudo Dice: 0.935699999332428 
2025-03-17 07:01:04.990834:  
2025-03-17 07:01:04.998351: Epoch 35 
2025-03-17 07:01:05.001860: Current learning rate: 0.00679 
2025-03-17 07:01:47.472887: train_loss -0.9594 
2025-03-17 07:01:47.479931: val_loss -0.9241 
2025-03-17 07:01:47.484981: Pseudo dice [np.float32(0.9392)] 
2025-03-17 07:01:47.487989: Epoch time: 42.48 s 
2025-03-17 07:01:47.492500: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2025-03-17 07:01:48.242277:  
2025-03-17 07:01:48.248351: Epoch 36 
2025-03-17 07:01:48.251912: Current learning rate: 0.00669 
2025-03-17 07:02:30.758944: train_loss -0.9604 
2025-03-17 07:02:30.763990: val_loss -0.9213 
2025-03-17 07:02:30.768544: Pseudo dice [np.float32(0.9376)] 
2025-03-17 07:02:30.772094: Epoch time: 42.52 s 
2025-03-17 07:02:30.775621: Yayy! New best EMA pseudo Dice: 0.9362000226974487 
2025-03-17 07:02:31.554162:  
2025-03-17 07:02:31.560678: Epoch 37 
2025-03-17 07:02:31.564689: Current learning rate: 0.0066 
2025-03-17 07:03:14.070244: train_loss -0.9616 
2025-03-17 07:03:14.076794: val_loss -0.9218 
2025-03-17 07:03:14.080339: Pseudo dice [np.float32(0.9383)] 
2025-03-17 07:03:14.084369: Epoch time: 42.52 s 
2025-03-17 07:03:14.087913: Yayy! New best EMA pseudo Dice: 0.9363999962806702 
2025-03-17 07:03:14.987710:  
2025-03-17 07:03:14.994380: Epoch 38 
2025-03-17 07:03:14.996919: Current learning rate: 0.0065 
2025-03-17 07:03:57.520276: train_loss -0.965 
2025-03-17 07:03:57.525889: val_loss -0.9238 
2025-03-17 07:03:57.530432: Pseudo dice [np.float32(0.9399)] 
2025-03-17 07:03:57.533466: Epoch time: 42.53 s 
2025-03-17 07:03:57.537506: Yayy! New best EMA pseudo Dice: 0.9366999864578247 
2025-03-17 07:03:58.284847:  
2025-03-17 07:03:58.291376: Epoch 39 
2025-03-17 07:03:58.294913: Current learning rate: 0.00641 
2025-03-17 07:04:40.765949: train_loss -0.9639 
2025-03-17 07:04:40.772020: val_loss -0.9237 
2025-03-17 07:04:40.776051: Pseudo dice [np.float32(0.9397)] 
2025-03-17 07:04:40.779593: Epoch time: 42.48 s 
2025-03-17 07:04:40.782135: Yayy! New best EMA pseudo Dice: 0.9369999766349792 
2025-03-17 07:04:41.533121:  
2025-03-17 07:04:41.538683: Epoch 40 
2025-03-17 07:04:41.543751: Current learning rate: 0.00631 
2025-03-17 07:05:24.009311: train_loss -0.9578 
2025-03-17 07:05:24.015327: val_loss -0.9215 
2025-03-17 07:05:24.018836: Pseudo dice [np.float32(0.9381)] 
2025-03-17 07:05:24.021873: Epoch time: 42.48 s 
2025-03-17 07:05:24.025382: Yayy! New best EMA pseudo Dice: 0.9370999932289124 
2025-03-17 07:05:24.796144:  
2025-03-17 07:05:24.803202: Epoch 41 
2025-03-17 07:05:24.806816: Current learning rate: 0.00622 
2025-03-17 07:06:07.262902: train_loss -0.9633 
2025-03-17 07:06:07.268938: val_loss -0.9234 
2025-03-17 07:06:07.272542: Pseudo dice [np.float32(0.9397)] 
2025-03-17 07:06:07.276052: Epoch time: 42.47 s 
2025-03-17 07:06:07.280061: Yayy! New best EMA pseudo Dice: 0.9373999834060669 
2025-03-17 07:06:08.003434:  
2025-03-17 07:06:08.008446: Epoch 42 
2025-03-17 07:06:08.012954: Current learning rate: 0.00612 
2025-03-17 07:06:50.512769: train_loss -0.9649 
2025-03-17 07:06:50.518321: val_loss -0.924 
2025-03-17 07:06:50.522850: Pseudo dice [np.float32(0.9398)] 
2025-03-17 07:06:50.525886: Epoch time: 42.51 s 
2025-03-17 07:06:50.529917: Yayy! New best EMA pseudo Dice: 0.9376000165939331 
2025-03-17 07:06:51.253190:  
2025-03-17 07:06:51.258274: Epoch 43 
2025-03-17 07:06:51.263395: Current learning rate: 0.00603 
2025-03-17 07:07:33.745802: train_loss -0.9586 
2025-03-17 07:07:33.751915: val_loss -0.9243 
2025-03-17 07:07:33.755483: Pseudo dice [np.float32(0.9399)] 
2025-03-17 07:07:33.759094: Epoch time: 42.49 s 
2025-03-17 07:07:33.762134: Yayy! New best EMA pseudo Dice: 0.9379000067710876 
2025-03-17 07:07:34.477440:  
2025-03-17 07:07:34.483629: Epoch 44 
2025-03-17 07:07:34.487668: Current learning rate: 0.00593 
2025-03-17 07:08:16.991062: train_loss -0.9632 
2025-03-17 07:08:16.997589: val_loss -0.9234 
2025-03-17 07:08:17.001101: Pseudo dice [np.float32(0.9393)] 
2025-03-17 07:08:17.006131: Epoch time: 42.51 s 
2025-03-17 07:08:17.010146: Yayy! New best EMA pseudo Dice: 0.9380000233650208 
2025-03-17 07:08:17.758935:  
2025-03-17 07:08:17.765641: Epoch 45 
2025-03-17 07:08:17.770175: Current learning rate: 0.00584 
2025-03-17 07:09:00.223549: train_loss -0.9645 
2025-03-17 07:09:00.229645: val_loss -0.9212 
2025-03-17 07:09:00.233157: Pseudo dice [np.float32(0.9385)] 
2025-03-17 07:09:00.236664: Epoch time: 42.46 s 
2025-03-17 07:09:00.239675: Yayy! New best EMA pseudo Dice: 0.9380999803543091 
2025-03-17 07:09:01.105035:  
2025-03-17 07:09:01.110600: Epoch 46 
2025-03-17 07:09:01.114648: Current learning rate: 0.00574 
2025-03-17 07:09:43.584977: train_loss -0.9657 
2025-03-17 07:09:43.591063: val_loss -0.921 
2025-03-17 07:09:43.594085: Pseudo dice [np.float32(0.9382)] 
2025-03-17 07:09:43.597598: Epoch time: 42.48 s 
2025-03-17 07:09:43.600102: Yayy! New best EMA pseudo Dice: 0.9380999803543091 
2025-03-17 07:09:44.310459:  
2025-03-17 07:09:44.315979: Epoch 47 
2025-03-17 07:09:44.319488: Current learning rate: 0.00565 
2025-03-17 07:10:26.777818: train_loss -0.9653 
2025-03-17 07:10:26.783381: val_loss -0.9239 
2025-03-17 07:10:26.786891: Pseudo dice [np.float32(0.9403)] 
2025-03-17 07:10:26.790899: Epoch time: 42.47 s 
2025-03-17 07:10:26.794410: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-03-17 07:10:27.544170:  
2025-03-17 07:10:27.551223: Epoch 48 
2025-03-17 07:10:27.554760: Current learning rate: 0.00555 
2025-03-17 07:11:10.002925: train_loss -0.9657 
2025-03-17 07:11:10.009481: val_loss -0.921 
2025-03-17 07:11:10.012993: Pseudo dice [np.float32(0.938)] 
2025-03-17 07:11:10.017008: Epoch time: 42.46 s 
2025-03-17 07:11:10.587700:  
2025-03-17 07:11:10.593759: Epoch 49 
2025-03-17 07:11:10.597838: Current learning rate: 0.00546 
2025-03-17 07:11:53.118064: train_loss -0.9642 
2025-03-17 07:11:53.124624: val_loss -0.9212 
2025-03-17 07:11:53.128133: Pseudo dice [np.float32(0.938)] 
2025-03-17 07:11:53.131644: Epoch time: 42.53 s 
2025-03-17 07:11:53.836917:  
2025-03-17 07:11:53.842543: Epoch 50 
2025-03-17 07:11:53.847615: Current learning rate: 0.00536 
2025-03-17 07:12:36.335902: train_loss -0.965 
2025-03-17 07:12:36.342978: val_loss -0.9236 
2025-03-17 07:12:36.347039: Pseudo dice [np.float32(0.94)] 
2025-03-17 07:12:36.350598: Epoch time: 42.5 s 
2025-03-17 07:12:36.354210: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-03-17 07:12:37.081539:  
2025-03-17 07:12:37.088115: Epoch 51 
2025-03-17 07:12:37.090663: Current learning rate: 0.00526 
2025-03-17 07:13:19.584492: train_loss -0.9676 
2025-03-17 07:13:19.591014: val_loss -0.9239 
2025-03-17 07:13:19.594530: Pseudo dice [np.float32(0.9406)] 
2025-03-17 07:13:19.597040: Epoch time: 42.5 s 
2025-03-17 07:13:19.601582: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-03-17 07:13:20.332319:  
2025-03-17 07:13:20.338893: Epoch 52 
2025-03-17 07:13:20.341442: Current learning rate: 0.00517 
2025-03-17 07:14:02.813973: train_loss -0.9681 
2025-03-17 07:14:02.820536: val_loss -0.9237 
2025-03-17 07:14:02.823131: Pseudo dice [np.float32(0.9408)] 
2025-03-17 07:14:02.827255: Epoch time: 42.48 s 
2025-03-17 07:14:02.829762: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-03-17 07:14:03.563276:  
2025-03-17 07:14:03.568850: Epoch 53 
2025-03-17 07:14:03.571392: Current learning rate: 0.00507 
2025-03-17 07:14:46.026900: train_loss -0.9684 
2025-03-17 07:14:46.032060: val_loss -0.9212 
2025-03-17 07:14:46.036155: Pseudo dice [np.float32(0.9383)] 
2025-03-17 07:14:46.039731: Epoch time: 42.46 s 
2025-03-17 07:14:46.747307:  
2025-03-17 07:14:46.752340: Epoch 54 
2025-03-17 07:14:46.755888: Current learning rate: 0.00497 
2025-03-17 07:15:29.218728: train_loss -0.9688 
2025-03-17 07:15:29.224744: val_loss -0.9222 
2025-03-17 07:15:29.227755: Pseudo dice [np.float32(0.9395)] 
2025-03-17 07:15:29.231268: Epoch time: 42.47 s 
2025-03-17 07:15:29.233775: Yayy! New best EMA pseudo Dice: 0.9388999938964844 
2025-03-17 07:15:29.957508:  
2025-03-17 07:15:29.963022: Epoch 55 
2025-03-17 07:15:29.966531: Current learning rate: 0.00487 
2025-03-17 07:16:12.472658: train_loss -0.9687 
2025-03-17 07:16:12.477237: val_loss -0.9196 
2025-03-17 07:16:12.480808: Pseudo dice [np.float32(0.9377)] 
2025-03-17 07:16:12.483858: Epoch time: 42.52 s 
2025-03-17 07:16:13.042450:  
2025-03-17 07:16:13.047025: Epoch 56 
2025-03-17 07:16:13.051637: Current learning rate: 0.00478 
2025-03-17 07:16:55.507330: train_loss -0.9693 
2025-03-17 07:16:55.513348: val_loss -0.9204 
2025-03-17 07:16:55.516855: Pseudo dice [np.float32(0.9383)] 
2025-03-17 07:16:55.519863: Epoch time: 42.47 s 
2025-03-17 07:16:56.071861:  
2025-03-17 07:16:56.076628: Epoch 57 
2025-03-17 07:16:56.080140: Current learning rate: 0.00468 
2025-03-17 07:17:38.587829: train_loss -0.9686 
2025-03-17 07:17:38.594885: val_loss -0.9247 
2025-03-17 07:17:38.598397: Pseudo dice [np.float32(0.941)] 
2025-03-17 07:17:38.601903: Epoch time: 42.52 s 
2025-03-17 07:17:38.604908: Yayy! New best EMA pseudo Dice: 0.9388999938964844 
2025-03-17 07:17:39.336408:  
2025-03-17 07:17:39.341982: Epoch 58 
2025-03-17 07:17:39.345035: Current learning rate: 0.00458 
2025-03-17 07:18:21.831613: train_loss -0.9692 
2025-03-17 07:18:21.837628: val_loss -0.9223 
2025-03-17 07:18:21.840637: Pseudo dice [np.float32(0.9396)] 
2025-03-17 07:18:21.844149: Epoch time: 42.5 s 
2025-03-17 07:18:21.847660: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-03-17 07:18:22.587731:  
2025-03-17 07:18:22.593249: Epoch 59 
2025-03-17 07:18:22.596762: Current learning rate: 0.00448 
2025-03-17 07:19:05.080059: train_loss -0.9693 
2025-03-17 07:19:05.085631: val_loss -0.921 
2025-03-17 07:19:05.089160: Pseudo dice [np.float32(0.9391)] 
2025-03-17 07:19:05.092091: Epoch time: 42.49 s 
2025-03-17 07:19:05.095606: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-03-17 07:19:05.998980:  
2025-03-17 07:19:06.004554: Epoch 60 
2025-03-17 07:19:06.009215: Current learning rate: 0.00438 
2025-03-17 07:19:48.475754: train_loss -0.9683 
2025-03-17 07:19:48.481389: val_loss -0.9226 
2025-03-17 07:19:48.484048: Pseudo dice [np.float32(0.9399)] 
2025-03-17 07:19:48.488091: Epoch time: 42.48 s 
2025-03-17 07:19:48.490632: Yayy! New best EMA pseudo Dice: 0.9391000270843506 
2025-03-17 07:19:49.225176:  
2025-03-17 07:19:49.232228: Epoch 61 
2025-03-17 07:19:49.236283: Current learning rate: 0.00429 
2025-03-17 07:20:31.663011: train_loss -0.9665 
2025-03-17 07:20:31.669030: val_loss -0.9244 
2025-03-17 07:20:31.674047: Pseudo dice [np.float32(0.9411)] 
2025-03-17 07:20:31.677553: Epoch time: 42.44 s 
2025-03-17 07:20:31.682571: Yayy! New best EMA pseudo Dice: 0.939300000667572 
2025-03-17 07:20:32.578421:  
2025-03-17 07:20:32.585978: Epoch 62 
2025-03-17 07:20:32.590511: Current learning rate: 0.00419 
2025-03-17 07:21:15.039472: train_loss -0.9712 
2025-03-17 07:21:15.046523: val_loss -0.9203 
2025-03-17 07:21:15.050544: Pseudo dice [np.float32(0.9385)] 
2025-03-17 07:21:15.053556: Epoch time: 42.46 s 
2025-03-17 07:21:15.628278:  
2025-03-17 07:21:15.634851: Epoch 63 
2025-03-17 07:21:15.638884: Current learning rate: 0.00409 
2025-03-17 07:21:58.100343: train_loss -0.9702 
2025-03-17 07:21:58.106405: val_loss -0.9199 
2025-03-17 07:21:58.109429: Pseudo dice [np.float32(0.9384)] 
2025-03-17 07:21:58.111935: Epoch time: 42.47 s 
2025-03-17 07:21:58.671136:  
2025-03-17 07:21:58.676651: Epoch 64 
2025-03-17 07:21:58.680161: Current learning rate: 0.00399 
2025-03-17 07:22:41.128306: train_loss -0.9696 
2025-03-17 07:22:41.133821: val_loss -0.9211 
2025-03-17 07:22:41.137331: Pseudo dice [np.float32(0.9394)] 
2025-03-17 07:22:41.141348: Epoch time: 42.46 s 
2025-03-17 07:22:41.704777:  
2025-03-17 07:22:41.711319: Epoch 65 
2025-03-17 07:22:41.714869: Current learning rate: 0.00389 
2025-03-17 07:23:24.180022: train_loss -0.9705 
2025-03-17 07:23:24.186538: val_loss -0.9199 
2025-03-17 07:23:24.190052: Pseudo dice [np.float32(0.9384)] 
2025-03-17 07:23:24.192557: Epoch time: 42.48 s 
2025-03-17 07:23:24.763708:  
2025-03-17 07:23:24.770326: Epoch 66 
2025-03-17 07:23:24.773882: Current learning rate: 0.00379 
2025-03-17 07:24:07.260891: train_loss -0.9713 
2025-03-17 07:24:07.266958: val_loss -0.9228 
2025-03-17 07:24:07.270012: Pseudo dice [np.float32(0.9405)] 
2025-03-17 07:24:07.273537: Epoch time: 42.5 s 
2025-03-17 07:24:07.839780:  
2025-03-17 07:24:07.844812: Epoch 67 
2025-03-17 07:24:07.848350: Current learning rate: 0.00369 
2025-03-17 07:24:50.344140: train_loss -0.9699 
2025-03-17 07:24:50.349151: val_loss -0.9215 
2025-03-17 07:24:50.353159: Pseudo dice [np.float32(0.9397)] 
2025-03-17 07:24:50.356671: Epoch time: 42.51 s 
2025-03-17 07:24:50.929846:  
2025-03-17 07:24:50.934858: Epoch 68 
2025-03-17 07:24:50.938369: Current learning rate: 0.00359 
2025-03-17 07:25:33.417204: train_loss -0.9717 
2025-03-17 07:25:33.423720: val_loss -0.9194 
2025-03-17 07:25:33.428733: Pseudo dice [np.float32(0.9384)] 
2025-03-17 07:25:33.431790: Epoch time: 42.49 s 
2025-03-17 07:25:34.009007:  
2025-03-17 07:25:34.015045: Epoch 69 
2025-03-17 07:25:34.018091: Current learning rate: 0.00349 
2025-03-17 07:26:16.467971: train_loss -0.9716 
2025-03-17 07:26:16.474028: val_loss -0.92 
2025-03-17 07:26:16.477588: Pseudo dice [np.float32(0.939)] 
2025-03-17 07:26:16.480638: Epoch time: 42.46 s 
2025-03-17 07:26:17.210007:  
2025-03-17 07:26:17.215032: Epoch 70 
2025-03-17 07:26:17.219136: Current learning rate: 0.00338 
2025-03-17 07:26:59.696764: train_loss -0.9717 
2025-03-17 07:26:59.703344: val_loss -0.9205 
2025-03-17 07:26:59.706384: Pseudo dice [np.float32(0.9393)] 
2025-03-17 07:26:59.710424: Epoch time: 42.49 s 
2025-03-17 07:27:00.279753:  
2025-03-17 07:27:00.286319: Epoch 71 
2025-03-17 07:27:00.290469: Current learning rate: 0.00328 
2025-03-17 07:27:42.750882: train_loss -0.9683 
2025-03-17 07:27:42.758043: val_loss -0.9196 
2025-03-17 07:27:42.761598: Pseudo dice [np.float32(0.9386)] 
2025-03-17 07:27:42.764644: Epoch time: 42.47 s 
2025-03-17 07:27:43.336763:  
2025-03-17 07:27:43.343279: Epoch 72 
2025-03-17 07:27:43.346789: Current learning rate: 0.00318 
2025-03-17 07:28:25.834630: train_loss -0.9695 
2025-03-17 07:28:25.840437: val_loss -0.9211 
2025-03-17 07:28:25.844451: Pseudo dice [np.float32(0.9395)] 
2025-03-17 07:28:25.846959: Epoch time: 42.5 s 
2025-03-17 07:28:26.427165:  
2025-03-17 07:28:26.432755: Epoch 73 
2025-03-17 07:28:26.436272: Current learning rate: 0.00308 
2025-03-17 07:29:08.899879: train_loss -0.9714 
2025-03-17 07:29:08.905228: val_loss -0.9201 
2025-03-17 07:29:08.908743: Pseudo dice [np.float32(0.9386)] 
2025-03-17 07:29:08.912262: Epoch time: 42.47 s 
2025-03-17 07:29:09.495104:  
2025-03-17 07:29:09.500680: Epoch 74 
2025-03-17 07:29:09.503283: Current learning rate: 0.00297 
2025-03-17 07:29:51.934835: train_loss -0.9721 
2025-03-17 07:29:51.940856: val_loss -0.9208 
2025-03-17 07:29:51.944865: Pseudo dice [np.float32(0.9388)] 
2025-03-17 07:29:51.948374: Epoch time: 42.44 s 
2025-03-17 07:29:52.523734:  
2025-03-17 07:29:52.529272: Epoch 75 
2025-03-17 07:29:52.532308: Current learning rate: 0.00287 
2025-03-17 07:30:35.028325: train_loss -0.9715 
2025-03-17 07:30:35.034441: val_loss -0.9216 
2025-03-17 07:30:35.037951: Pseudo dice [np.float32(0.94)] 
2025-03-17 07:30:35.040963: Epoch time: 42.51 s 
2025-03-17 07:30:35.620284:  
2025-03-17 07:30:35.627916: Epoch 76 
2025-03-17 07:30:35.631022: Current learning rate: 0.00277 
2025-03-17 07:31:18.114940: train_loss -0.9714 
2025-03-17 07:31:18.120457: val_loss -0.9198 
2025-03-17 07:31:18.123969: Pseudo dice [np.float32(0.9391)] 
2025-03-17 07:31:18.127478: Epoch time: 42.49 s 
2025-03-17 07:31:18.699924:  
2025-03-17 07:31:18.705533: Epoch 77 
2025-03-17 07:31:18.708082: Current learning rate: 0.00266 
2025-03-17 07:32:01.162088: train_loss -0.9727 
2025-03-17 07:32:01.168105: val_loss -0.9205 
2025-03-17 07:32:01.171614: Pseudo dice [np.float32(0.9396)] 
2025-03-17 07:32:01.174631: Epoch time: 42.46 s 
2025-03-17 07:32:01.911319:  
2025-03-17 07:32:01.917886: Epoch 78 
2025-03-17 07:32:01.920939: Current learning rate: 0.00256 
2025-03-17 07:32:44.370872: train_loss -0.9725 
2025-03-17 07:32:44.376389: val_loss -0.9199 
2025-03-17 07:32:44.379901: Pseudo dice [np.float32(0.9387)] 
2025-03-17 07:32:44.383410: Epoch time: 42.46 s 
2025-03-17 07:32:44.976516:  
2025-03-17 07:32:44.981551: Epoch 79 
2025-03-17 07:32:44.984585: Current learning rate: 0.00245 
2025-03-17 07:33:27.476206: train_loss -0.971 
2025-03-17 07:33:27.482224: val_loss -0.9204 
2025-03-17 07:33:27.486237: Pseudo dice [np.float32(0.9395)] 
2025-03-17 07:33:27.489748: Epoch time: 42.5 s 
2025-03-17 07:33:28.083606:  
2025-03-17 07:33:28.089221: Epoch 80 
2025-03-17 07:33:28.091769: Current learning rate: 0.00235 
2025-03-17 07:34:10.574052: train_loss -0.9722 
2025-03-17 07:34:10.580138: val_loss -0.9214 
2025-03-17 07:34:10.583703: Pseudo dice [np.float32(0.9401)] 
2025-03-17 07:34:10.586238: Epoch time: 42.49 s 
2025-03-17 07:34:11.176878:  
2025-03-17 07:34:11.181937: Epoch 81 
2025-03-17 07:34:11.185006: Current learning rate: 0.00224 
2025-03-17 07:34:53.671732: train_loss -0.972 
2025-03-17 07:34:53.676804: val_loss -0.9194 
2025-03-17 07:34:53.681344: Pseudo dice [np.float32(0.9384)] 
2025-03-17 07:34:53.684855: Epoch time: 42.49 s 
2025-03-17 07:34:54.270186:  
2025-03-17 07:34:54.275235: Epoch 82 
2025-03-17 07:34:54.278841: Current learning rate: 0.00214 
2025-03-17 07:35:36.774099: train_loss -0.9714 
2025-03-17 07:35:36.777546: val_loss -0.9199 
2025-03-17 07:35:36.781556: Pseudo dice [np.float32(0.9391)] 
2025-03-17 07:35:36.784060: Epoch time: 42.5 s 
2025-03-17 07:35:37.341779:  
2025-03-17 07:35:37.347351: Epoch 83 
2025-03-17 07:35:37.350915: Current learning rate: 0.00203 
2025-03-17 07:36:19.822514: train_loss -0.9725 
2025-03-17 07:36:19.829068: val_loss -0.9221 
2025-03-17 07:36:19.832584: Pseudo dice [np.float32(0.9402)] 
2025-03-17 07:36:19.835089: Epoch time: 42.48 s 
2025-03-17 07:36:20.389245:  
2025-03-17 07:36:20.395286: Epoch 84 
2025-03-17 07:36:20.398334: Current learning rate: 0.00192 
2025-03-17 07:37:02.877708: train_loss -0.9723 
2025-03-17 07:37:02.883323: val_loss -0.9194 
2025-03-17 07:37:02.886908: Pseudo dice [np.float32(0.9386)] 
2025-03-17 07:37:02.890523: Epoch time: 42.49 s 
2025-03-17 07:37:03.441350:  
2025-03-17 07:37:03.446467: Epoch 85 
2025-03-17 07:37:03.449985: Current learning rate: 0.00181 
2025-03-17 07:37:45.920506: train_loss -0.9738 
2025-03-17 07:37:45.926049: val_loss -0.9202 
2025-03-17 07:37:45.929580: Pseudo dice [np.float32(0.9393)] 
2025-03-17 07:37:45.933124: Epoch time: 42.48 s 
2025-03-17 07:37:46.632221:  
2025-03-17 07:37:46.637754: Epoch 86 
2025-03-17 07:37:46.641301: Current learning rate: 0.0017 
2025-03-17 07:38:29.106654: train_loss -0.974 
2025-03-17 07:38:29.112171: val_loss -0.919 
2025-03-17 07:38:29.115683: Pseudo dice [np.float32(0.9384)] 
2025-03-17 07:38:29.119194: Epoch time: 42.48 s 
2025-03-17 07:38:29.663054:  
2025-03-17 07:38:29.668068: Epoch 87 
2025-03-17 07:38:29.671080: Current learning rate: 0.00159 
2025-03-17 07:39:12.139167: train_loss -0.9729 
2025-03-17 07:39:12.145220: val_loss -0.9218 
2025-03-17 07:39:12.148250: Pseudo dice [np.float32(0.9406)] 
2025-03-17 07:39:12.151765: Epoch time: 42.48 s 
2025-03-17 07:39:12.695398:  
2025-03-17 07:39:12.700434: Epoch 88 
2025-03-17 07:39:12.703263: Current learning rate: 0.00148 
2025-03-17 07:39:55.158711: train_loss -0.9726 
2025-03-17 07:39:55.165732: val_loss -0.9209 
2025-03-17 07:39:55.168743: Pseudo dice [np.float32(0.94)] 
2025-03-17 07:39:55.172257: Epoch time: 42.46 s 
2025-03-17 07:39:55.174763: Yayy! New best EMA pseudo Dice: 0.939300000667572 
2025-03-17 07:39:55.889776:  
2025-03-17 07:39:55.894286: Epoch 89 
2025-03-17 07:39:55.897298: Current learning rate: 0.00137 
2025-03-17 07:40:38.366416: train_loss -0.9713 
2025-03-17 07:40:38.372506: val_loss -0.9181 
2025-03-17 07:40:38.376064: Pseudo dice [np.float32(0.9383)] 
2025-03-17 07:40:38.379119: Epoch time: 42.48 s 
2025-03-17 07:40:38.919473:  
2025-03-17 07:40:38.924990: Epoch 90 
2025-03-17 07:40:38.928502: Current learning rate: 0.00126 
2025-03-17 07:41:21.388332: train_loss -0.9733 
2025-03-17 07:41:21.394346: val_loss -0.9208 
2025-03-17 07:41:21.397360: Pseudo dice [np.float32(0.9398)] 
2025-03-17 07:41:21.400920: Epoch time: 42.47 s 
2025-03-17 07:41:21.950711:  
2025-03-17 07:41:21.956278: Epoch 91 
2025-03-17 07:41:21.960366: Current learning rate: 0.00115 
2025-03-17 07:42:04.453009: train_loss -0.9743 
2025-03-17 07:42:04.459028: val_loss -0.9224 
2025-03-17 07:42:04.462534: Pseudo dice [np.float32(0.941)] 
2025-03-17 07:42:04.465540: Epoch time: 42.5 s 
2025-03-17 07:42:04.469047: Yayy! New best EMA pseudo Dice: 0.9394999742507935 
2025-03-17 07:42:05.284730:  
2025-03-17 07:42:05.290772: Epoch 92 
2025-03-17 07:42:05.293294: Current learning rate: 0.00103 
2025-03-17 07:42:47.789687: train_loss -0.9716 
2025-03-17 07:42:47.795204: val_loss -0.92 
2025-03-17 07:42:47.798714: Pseudo dice [np.float32(0.9393)] 
2025-03-17 07:42:47.802220: Epoch time: 42.51 s 
2025-03-17 07:42:48.379331:  
2025-03-17 07:42:48.385410: Epoch 93 
2025-03-17 07:42:48.388481: Current learning rate: 0.00091 
2025-03-17 07:43:30.866484: train_loss -0.9747 
2025-03-17 07:43:30.872503: val_loss -0.9195 
2025-03-17 07:43:30.876011: Pseudo dice [np.float32(0.9391)] 
2025-03-17 07:43:30.879023: Epoch time: 42.49 s 
2025-03-17 07:43:31.421353:  
2025-03-17 07:43:31.426921: Epoch 94 
2025-03-17 07:43:31.430982: Current learning rate: 0.00079 
2025-03-17 07:44:13.871345: train_loss -0.9741 
2025-03-17 07:44:13.878416: val_loss -0.9197 
2025-03-17 07:44:13.881486: Pseudo dice [np.float32(0.9392)] 
2025-03-17 07:44:13.884995: Epoch time: 42.45 s 
2025-03-17 07:44:14.590733:  
2025-03-17 07:44:14.596246: Epoch 95 
2025-03-17 07:44:14.599757: Current learning rate: 0.00067 
2025-03-17 07:44:57.056867: train_loss -0.974 
2025-03-17 07:44:57.061375: val_loss -0.9214 
2025-03-17 07:44:57.064386: Pseudo dice [np.float32(0.9402)] 
2025-03-17 07:44:57.067895: Epoch time: 42.47 s 
2025-03-17 07:44:57.071399: Yayy! New best EMA pseudo Dice: 0.9394999742507935 
2025-03-17 07:44:57.780856:  
2025-03-17 07:44:57.786413: Epoch 96 
2025-03-17 07:44:57.790032: Current learning rate: 0.00055 
2025-03-17 07:45:40.263963: train_loss -0.9733 
2025-03-17 07:45:40.270998: val_loss -0.9204 
2025-03-17 07:45:40.274505: Pseudo dice [np.float32(0.9396)] 
2025-03-17 07:45:40.278516: Epoch time: 42.48 s 
2025-03-17 07:45:40.281024: Yayy! New best EMA pseudo Dice: 0.9394999742507935 
2025-03-17 07:45:40.996834:  
2025-03-17 07:45:41.002908: Epoch 97 
2025-03-17 07:45:41.006434: Current learning rate: 0.00043 
2025-03-17 07:46:23.451917: train_loss -0.9742 
2025-03-17 07:46:23.458436: val_loss -0.9221 
2025-03-17 07:46:23.461948: Pseudo dice [np.float32(0.9411)] 
2025-03-17 07:46:23.465955: Epoch time: 42.46 s 
2025-03-17 07:46:23.468460: Yayy! New best EMA pseudo Dice: 0.9397000074386597 
2025-03-17 07:46:24.195853:  
2025-03-17 07:46:24.201441: Epoch 98 
2025-03-17 07:46:24.206010: Current learning rate: 0.0003 
2025-03-17 07:47:06.679977: train_loss -0.9748 
2025-03-17 07:47:06.685519: val_loss -0.9203 
2025-03-17 07:47:06.689533: Pseudo dice [np.float32(0.9394)] 
2025-03-17 07:47:06.692039: Epoch time: 42.48 s 
2025-03-17 07:47:07.243804:  
2025-03-17 07:47:07.249883: Epoch 99 
2025-03-17 07:47:07.252945: Current learning rate: 0.00016 
2025-03-17 07:47:49.715792: train_loss -0.9746 
2025-03-17 07:47:49.721355: val_loss -0.9209 
2025-03-17 07:47:49.725387: Pseudo dice [np.float32(0.9403)] 
2025-03-17 07:47:49.728428: Epoch time: 42.47 s 
2025-03-17 07:47:49.731466: Yayy! New best EMA pseudo Dice: 0.9397000074386597 
2025-03-17 07:47:50.646523: Training done. 
2025-03-17 07:47:50.670526: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-17 07:47:50.676524: The split file contains 5 splits. 
2025-03-17 07:47:50.682524: Desired fold for training: 0 
2025-03-17 07:47:50.686530: This split has 16 training and 4 validation cases. 
2025-03-17 07:47:50.690527: predicting la_007 
2025-03-17 07:47:50.695529: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2025-03-17 07:47:56.517230: predicting la_016 
2025-03-17 07:47:56.528229: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2025-03-17 07:47:58.785827: predicting la_021 
2025-03-17 07:47:58.794830: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2025-03-17 07:48:01.059566: predicting la_024 
2025-03-17 07:48:01.070567: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2025-03-17 07:48:10.017072: Validation complete 
2025-03-17 07:48:10.023072: Mean Validation Dice:  0.8319445269754633 
