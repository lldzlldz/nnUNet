
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-16 20:49:03.060675: do_dummy_2d_data_aug: False 
2025-03-16 20:49:03.062721: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-16 20:49:03.067720: The split file contains 5 splits. 
2025-03-16 20:49:03.070723: Desired fold for training: 0 
2025-03-16 20:49:03.072998: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2025-03-16 20:49:11.702076: unpacking dataset... 
2025-03-16 20:49:11.900147: unpacking done... 
2025-03-16 20:49:15.040783:  
2025-03-16 20:49:15.045826: Epoch 0 
2025-03-16 20:49:15.050849: Current learning rate: 0.01 
2025-03-16 20:50:03.503611: train_loss -0.5473 
2025-03-16 20:50:03.509744: val_loss -0.8362 
2025-03-16 20:50:03.512898: Pseudo dice [np.float32(0.8746)] 
2025-03-16 20:50:03.515975: Epoch time: 48.46 s 
2025-03-16 20:50:03.519631: Yayy! New best EMA pseudo Dice: 0.8745999932289124 
2025-03-16 20:50:04.211449:  
2025-03-16 20:50:04.217103: Epoch 1 
2025-03-16 20:50:04.219647: Current learning rate: 0.00991 
2025-03-16 20:50:48.110122: train_loss -0.7967 
2025-03-16 20:50:48.116132: val_loss -0.8032 
2025-03-16 20:50:48.119143: Pseudo dice [np.float32(0.8522)] 
2025-03-16 20:50:48.122653: Epoch time: 43.9 s 
2025-03-16 20:50:48.724463:  
2025-03-16 20:50:48.730506: Epoch 2 
2025-03-16 20:50:48.735363: Current learning rate: 0.00982 
2025-03-16 20:51:34.380235: train_loss -0.8346 
2025-03-16 20:51:34.386258: val_loss -0.8752 
2025-03-16 20:51:34.390266: Pseudo dice [np.float32(0.9047)] 
2025-03-16 20:51:34.392773: Epoch time: 45.66 s 
2025-03-16 20:51:34.396282: Yayy! New best EMA pseudo Dice: 0.8755999803543091 
2025-03-16 20:51:35.171464:  
2025-03-16 20:51:35.177544: Epoch 3 
2025-03-16 20:51:35.180670: Current learning rate: 0.00973 
2025-03-16 20:52:20.156943: train_loss -0.8492 
2025-03-16 20:52:20.163029: val_loss -0.8712 
2025-03-16 20:52:20.166538: Pseudo dice [np.float32(0.9008)] 
2025-03-16 20:52:20.169553: Epoch time: 44.99 s 
2025-03-16 20:52:20.173067: Yayy! New best EMA pseudo Dice: 0.8780999779701233 
2025-03-16 20:52:20.960573:  
2025-03-16 20:52:20.967222: Epoch 4 
2025-03-16 20:52:20.969770: Current learning rate: 0.00964 
2025-03-16 20:53:05.032264: train_loss -0.8626 
2025-03-16 20:53:05.039302: val_loss -0.8886 
2025-03-16 20:53:05.042811: Pseudo dice [np.float32(0.915)] 
2025-03-16 20:53:05.046320: Epoch time: 44.07 s 
2025-03-16 20:53:05.049330: Yayy! New best EMA pseudo Dice: 0.8817999958992004 
2025-03-16 20:53:06.001580:  
2025-03-16 20:53:06.007135: Epoch 5 
2025-03-16 20:53:06.010352: Current learning rate: 0.00955 
2025-03-16 20:53:49.254686: train_loss -0.8763 
2025-03-16 20:53:49.260792: val_loss -0.8849 
2025-03-16 20:53:49.264830: Pseudo dice [np.float32(0.9102)] 
2025-03-16 20:53:49.268359: Epoch time: 43.25 s 
2025-03-16 20:53:49.271929: Yayy! New best EMA pseudo Dice: 0.8845999836921692 
2025-03-16 20:53:50.063747:  
2025-03-16 20:53:50.069770: Epoch 6 
2025-03-16 20:53:50.073322: Current learning rate: 0.00946 
2025-03-16 20:54:33.111835: train_loss -0.8856 
2025-03-16 20:54:33.117909: val_loss -0.8906 
2025-03-16 20:54:33.121923: Pseudo dice [np.float32(0.9142)] 
2025-03-16 20:54:33.125487: Epoch time: 43.05 s 
2025-03-16 20:54:33.128994: Yayy! New best EMA pseudo Dice: 0.8876000046730042 
2025-03-16 20:54:33.916476:  
2025-03-16 20:54:33.921488: Epoch 7 
2025-03-16 20:54:33.925000: Current learning rate: 0.00937 
2025-03-16 20:55:16.978358: train_loss -0.8781 
2025-03-16 20:55:16.983411: val_loss -0.8861 
2025-03-16 20:55:16.986923: Pseudo dice [np.float32(0.9122)] 
2025-03-16 20:55:16.990431: Epoch time: 43.06 s 
2025-03-16 20:55:16.993956: Yayy! New best EMA pseudo Dice: 0.8899999856948853 
2025-03-16 20:55:17.778488:  
2025-03-16 20:55:17.784078: Epoch 8 
2025-03-16 20:55:17.787649: Current learning rate: 0.00928 
2025-03-16 20:56:01.208884: train_loss -0.8902 
2025-03-16 20:56:01.214966: val_loss -0.8965 
2025-03-16 20:56:01.217974: Pseudo dice [np.float32(0.9195)] 
2025-03-16 20:56:01.221484: Epoch time: 43.43 s 
2025-03-16 20:56:01.224991: Yayy! New best EMA pseudo Dice: 0.8930000066757202 
2025-03-16 20:56:02.006586:  
2025-03-16 20:56:02.012259: Epoch 9 
2025-03-16 20:56:02.016815: Current learning rate: 0.00919 
2025-03-16 20:56:45.543880: train_loss -0.8939 
2025-03-16 20:56:45.550023: val_loss -0.8953 
2025-03-16 20:56:45.553083: Pseudo dice [np.float32(0.9192)] 
2025-03-16 20:56:45.555623: Epoch time: 43.54 s 
2025-03-16 20:56:45.560787: Yayy! New best EMA pseudo Dice: 0.8956000208854675 
2025-03-16 20:56:46.318150:  
2025-03-16 20:56:46.324723: Epoch 10 
2025-03-16 20:56:46.327766: Current learning rate: 0.0091 
2025-03-16 20:57:29.463006: train_loss -0.8869 
2025-03-16 20:57:29.468538: val_loss -0.8836 
2025-03-16 20:57:29.473061: Pseudo dice [np.float32(0.9096)] 
2025-03-16 20:57:29.476088: Epoch time: 43.15 s 
2025-03-16 20:57:29.478594: Yayy! New best EMA pseudo Dice: 0.8970000147819519 
2025-03-16 20:57:30.234831:  
2025-03-16 20:57:30.240567: Epoch 11 
2025-03-16 20:57:30.244081: Current learning rate: 0.009 
2025-03-16 20:58:13.268044: train_loss -0.8882 
2025-03-16 20:58:13.273573: val_loss -0.9017 
2025-03-16 20:58:13.277085: Pseudo dice [np.float32(0.9239)] 
2025-03-16 20:58:13.279589: Epoch time: 43.03 s 
2025-03-16 20:58:13.283600: Yayy! New best EMA pseudo Dice: 0.8996999859809875 
2025-03-16 20:58:14.043966:  
2025-03-16 20:58:14.049581: Epoch 12 
2025-03-16 20:58:14.052635: Current learning rate: 0.00891 
2025-03-16 20:58:57.942466: train_loss -0.8957 
2025-03-16 20:58:57.948592: val_loss -0.9023 
2025-03-16 20:58:57.952234: Pseudo dice [np.float32(0.9233)] 
2025-03-16 20:58:57.955274: Epoch time: 43.9 s 
2025-03-16 20:58:57.958896: Yayy! New best EMA pseudo Dice: 0.9020000100135803 
2025-03-16 20:58:58.895157:  
2025-03-16 20:58:58.901207: Epoch 13 
2025-03-16 20:58:58.903908: Current learning rate: 0.00882 
2025-03-16 20:59:43.312614: train_loss -0.9047 
2025-03-16 20:59:43.318645: val_loss -0.9019 
2025-03-16 20:59:43.321268: Pseudo dice [np.float32(0.9224)] 
2025-03-16 20:59:43.325288: Epoch time: 44.42 s 
2025-03-16 20:59:43.328804: Yayy! New best EMA pseudo Dice: 0.9041000008583069 
2025-03-16 20:59:44.155442:  
2025-03-16 20:59:44.161393: Epoch 14 
2025-03-16 20:59:44.164931: Current learning rate: 0.00873 
2025-03-16 21:00:27.742502: train_loss -0.9015 
2025-03-16 21:00:27.748520: val_loss -0.9026 
2025-03-16 21:00:27.752027: Pseudo dice [np.float32(0.9244)] 
2025-03-16 21:00:27.755045: Epoch time: 43.59 s 
2025-03-16 21:00:27.758558: Yayy! New best EMA pseudo Dice: 0.9060999751091003 
2025-03-16 21:00:28.575899:  
2025-03-16 21:00:28.580915: Epoch 15 
2025-03-16 21:00:28.584933: Current learning rate: 0.00864 
2025-03-16 21:01:12.754722: train_loss -0.8962 
2025-03-16 21:01:12.761319: val_loss -0.9008 
2025-03-16 21:01:12.763827: Pseudo dice [np.float32(0.9215)] 
2025-03-16 21:01:12.767837: Epoch time: 44.18 s 
2025-03-16 21:01:12.770345: Yayy! New best EMA pseudo Dice: 0.9075999855995178 
2025-03-16 21:01:13.554574:  
2025-03-16 21:01:13.560089: Epoch 16 
2025-03-16 21:01:13.563602: Current learning rate: 0.00855 
2025-03-16 21:01:57.413431: train_loss -0.8909 
2025-03-16 21:01:57.419448: val_loss -0.9016 
2025-03-16 21:01:57.422960: Pseudo dice [np.float32(0.9223)] 
2025-03-16 21:01:57.425972: Epoch time: 43.86 s 
2025-03-16 21:01:57.429482: Yayy! New best EMA pseudo Dice: 0.9090999960899353 
2025-03-16 21:01:58.254045:  
2025-03-16 21:01:58.260093: Epoch 17 
2025-03-16 21:01:58.263171: Current learning rate: 0.00846 
2025-03-16 21:02:41.926051: train_loss -0.9112 
2025-03-16 21:02:41.931075: val_loss -0.906 
2025-03-16 21:02:41.935219: Pseudo dice [np.float32(0.9254)] 
2025-03-16 21:02:41.937725: Epoch time: 43.67 s 
2025-03-16 21:02:41.941238: Yayy! New best EMA pseudo Dice: 0.9107000231742859 
2025-03-16 21:02:42.724545:  
2025-03-16 21:02:42.731138: Epoch 18 
2025-03-16 21:02:42.734404: Current learning rate: 0.00836 
2025-03-16 21:03:27.520273: train_loss -0.9153 
2025-03-16 21:03:27.526388: val_loss -0.9119 
2025-03-16 21:03:27.529429: Pseudo dice [np.float32(0.9303)] 
2025-03-16 21:03:27.532966: Epoch time: 44.8 s 
2025-03-16 21:03:27.536522: Yayy! New best EMA pseudo Dice: 0.9126999974250793 
2025-03-16 21:03:28.329431:  
2025-03-16 21:03:28.334548: Epoch 19 
2025-03-16 21:03:28.338619: Current learning rate: 0.00827 
2025-03-16 21:04:12.179948: train_loss -0.9161 
2025-03-16 21:04:12.186966: val_loss -0.91 
2025-03-16 21:04:12.189976: Pseudo dice [np.float32(0.928)] 
2025-03-16 21:04:12.193488: Epoch time: 43.85 s 
2025-03-16 21:04:12.196997: Yayy! New best EMA pseudo Dice: 0.9142000079154968 
2025-03-16 21:04:12.996877:  
2025-03-16 21:04:13.002391: Epoch 20 
2025-03-16 21:04:13.006903: Current learning rate: 0.00818 
2025-03-16 21:04:57.013743: train_loss -0.9156 
2025-03-16 21:04:57.019832: val_loss -0.911 
2025-03-16 21:04:57.023388: Pseudo dice [np.float32(0.9282)] 
2025-03-16 21:04:57.026939: Epoch time: 44.02 s 
2025-03-16 21:04:57.030484: Yayy! New best EMA pseudo Dice: 0.9156000018119812 
2025-03-16 21:04:58.066538:  
2025-03-16 21:04:58.073203: Epoch 21 
2025-03-16 21:04:58.076777: Current learning rate: 0.00809 
2025-03-16 21:05:41.250773: train_loss -0.9237 
2025-03-16 21:05:41.256294: val_loss -0.9143 
2025-03-16 21:05:41.259835: Pseudo dice [np.float32(0.9313)] 
2025-03-16 21:05:41.262342: Epoch time: 43.18 s 
2025-03-16 21:05:41.265855: Yayy! New best EMA pseudo Dice: 0.9172000288963318 
2025-03-16 21:05:42.027429:  
2025-03-16 21:05:42.033551: Epoch 22 
2025-03-16 21:05:42.037067: Current learning rate: 0.008 
2025-03-16 21:06:25.589531: train_loss -0.9237 
2025-03-16 21:06:25.595063: val_loss -0.906 
2025-03-16 21:06:25.599086: Pseudo dice [np.float32(0.9248)] 
2025-03-16 21:06:25.602623: Epoch time: 43.56 s 
2025-03-16 21:06:25.605133: Yayy! New best EMA pseudo Dice: 0.9179999828338623 
2025-03-16 21:06:26.407140:  
2025-03-16 21:06:26.412242: Epoch 23 
2025-03-16 21:06:26.416296: Current learning rate: 0.0079 
2025-03-16 21:07:11.359978: train_loss -0.9198 
2025-03-16 21:07:11.365999: val_loss -0.899 
2025-03-16 21:07:11.369509: Pseudo dice [np.float32(0.9178)] 
2025-03-16 21:07:11.373526: Epoch time: 44.95 s 
2025-03-16 21:07:11.963253:  
2025-03-16 21:07:11.968829: Epoch 24 
2025-03-16 21:07:11.972379: Current learning rate: 0.00781 
2025-03-16 21:07:54.935794: train_loss -0.919 
2025-03-16 21:07:54.941832: val_loss -0.9159 
2025-03-16 21:07:54.945345: Pseudo dice [np.float32(0.9335)] 
2025-03-16 21:07:54.947942: Epoch time: 42.97 s 
2025-03-16 21:07:54.951453: Yayy! New best EMA pseudo Dice: 0.9194999933242798 
2025-03-16 21:07:55.730586:  
2025-03-16 21:07:55.736383: Epoch 25 
2025-03-16 21:07:55.739900: Current learning rate: 0.00772 
2025-03-16 21:08:39.094884: train_loss -0.9185 
2025-03-16 21:08:39.100483: val_loss -0.9053 
2025-03-16 21:08:39.104522: Pseudo dice [np.float32(0.923)] 
2025-03-16 21:08:39.107531: Epoch time: 43.36 s 
2025-03-16 21:08:39.110571: Yayy! New best EMA pseudo Dice: 0.9199000000953674 
2025-03-16 21:08:39.886838:  
2025-03-16 21:08:39.892433: Epoch 26 
2025-03-16 21:08:39.897015: Current learning rate: 0.00763 
2025-03-16 21:09:23.213107: train_loss -0.9232 
2025-03-16 21:09:23.218674: val_loss -0.9091 
2025-03-16 21:09:23.222716: Pseudo dice [np.float32(0.9269)] 
2025-03-16 21:09:23.226228: Epoch time: 43.33 s 
2025-03-16 21:09:23.230243: Yayy! New best EMA pseudo Dice: 0.9205999970436096 
2025-03-16 21:09:24.015241:  
2025-03-16 21:09:24.020319: Epoch 27 
2025-03-16 21:09:24.023869: Current learning rate: 0.00753 
2025-03-16 21:10:07.519767: train_loss -0.9275 
2025-03-16 21:10:07.525296: val_loss -0.9195 
2025-03-16 21:10:07.529940: Pseudo dice [np.float32(0.9353)] 
2025-03-16 21:10:07.533453: Epoch time: 43.51 s 
2025-03-16 21:10:07.535960: Yayy! New best EMA pseudo Dice: 0.921999990940094 
2025-03-16 21:10:08.469794:  
2025-03-16 21:10:08.475314: Epoch 28 
2025-03-16 21:10:08.481337: Current learning rate: 0.00744 
2025-03-16 21:10:51.908239: train_loss -0.9324 
2025-03-16 21:10:51.914297: val_loss -0.9182 
2025-03-16 21:10:51.917804: Pseudo dice [np.float32(0.934)] 
2025-03-16 21:10:51.920817: Epoch time: 43.44 s 
2025-03-16 21:10:51.924328: Yayy! New best EMA pseudo Dice: 0.9232000112533569 
2025-03-16 21:10:52.701151:  
2025-03-16 21:10:52.707225: Epoch 29 
2025-03-16 21:10:52.710782: Current learning rate: 0.00735 
2025-03-16 21:11:36.261559: train_loss -0.9284 
2025-03-16 21:11:36.267699: val_loss -0.9119 
2025-03-16 21:11:36.271300: Pseudo dice [np.float32(0.9279)] 
2025-03-16 21:11:36.274966: Epoch time: 43.56 s 
2025-03-16 21:11:36.278020: Yayy! New best EMA pseudo Dice: 0.9236999750137329 
2025-03-16 21:11:37.063497:  
2025-03-16 21:11:37.068514: Epoch 30 
2025-03-16 21:11:37.072026: Current learning rate: 0.00725 
2025-03-16 21:12:20.746602: train_loss -0.9315 
2025-03-16 21:12:20.752702: val_loss -0.9167 
2025-03-16 21:12:20.755216: Pseudo dice [np.float32(0.934)] 
2025-03-16 21:12:20.758976: Epoch time: 43.68 s 
2025-03-16 21:12:20.763039: Yayy! New best EMA pseudo Dice: 0.9247000217437744 
2025-03-16 21:12:21.525846:  
2025-03-16 21:12:21.531405: Epoch 31 
2025-03-16 21:12:21.535969: Current learning rate: 0.00716 
2025-03-16 21:13:06.146682: train_loss -0.9314 
2025-03-16 21:13:06.153729: val_loss -0.9168 
2025-03-16 21:13:06.157238: Pseudo dice [np.float32(0.933)] 
2025-03-16 21:13:06.159748: Epoch time: 44.62 s 
2025-03-16 21:13:06.163754: Yayy! New best EMA pseudo Dice: 0.925599992275238 
2025-03-16 21:13:06.934438:  
2025-03-16 21:13:06.940610: Epoch 32 
2025-03-16 21:13:06.944119: Current learning rate: 0.00707 
2025-03-16 21:13:50.673496: train_loss -0.9356 
2025-03-16 21:13:50.680620: val_loss -0.92 
2025-03-16 21:13:50.684192: Pseudo dice [np.float32(0.9354)] 
2025-03-16 21:13:50.686698: Epoch time: 43.74 s 
2025-03-16 21:13:50.690210: Yayy! New best EMA pseudo Dice: 0.9265000224113464 
2025-03-16 21:13:51.459845:  
2025-03-16 21:13:51.466488: Epoch 33 
2025-03-16 21:13:51.470055: Current learning rate: 0.00697 
2025-03-16 21:14:34.937769: train_loss -0.9362 
2025-03-16 21:14:34.943343: val_loss -0.9142 
2025-03-16 21:14:34.947875: Pseudo dice [np.float32(0.9316)] 
2025-03-16 21:14:34.950382: Epoch time: 43.48 s 
2025-03-16 21:14:34.953891: Yayy! New best EMA pseudo Dice: 0.9271000027656555 
2025-03-16 21:14:35.771920:  
2025-03-16 21:14:35.777487: Epoch 34 
2025-03-16 21:14:35.781055: Current learning rate: 0.00688 
2025-03-16 21:15:19.377745: train_loss -0.9268 
2025-03-16 21:15:19.383325: val_loss -0.9122 
2025-03-16 21:15:19.385862: Pseudo dice [np.float32(0.9289)] 
2025-03-16 21:15:19.389955: Epoch time: 43.61 s 
2025-03-16 21:15:19.392980: Yayy! New best EMA pseudo Dice: 0.9272000193595886 
2025-03-16 21:15:20.202983:  
2025-03-16 21:15:20.208594: Epoch 35 
2025-03-16 21:15:20.212180: Current learning rate: 0.00679 
2025-03-16 21:16:04.366836: train_loss -0.929 
2025-03-16 21:16:04.372419: val_loss -0.896 
2025-03-16 21:16:04.376959: Pseudo dice [np.float32(0.9162)] 
2025-03-16 21:16:04.380471: Epoch time: 44.16 s 
2025-03-16 21:16:05.161428:  
2025-03-16 21:16:05.167534: Epoch 36 
2025-03-16 21:16:05.170141: Current learning rate: 0.00669 
2025-03-16 21:16:48.611610: train_loss -0.9218 
2025-03-16 21:16:48.618273: val_loss -0.9122 
2025-03-16 21:16:48.621786: Pseudo dice [np.float32(0.9295)] 
2025-03-16 21:16:48.625801: Epoch time: 43.45 s 
2025-03-16 21:16:49.237319:  
2025-03-16 21:16:49.243838: Epoch 37 
2025-03-16 21:16:49.247352: Current learning rate: 0.0066 
2025-03-16 21:17:32.857742: train_loss -0.9289 
2025-03-16 21:17:32.864272: val_loss -0.9159 
2025-03-16 21:17:32.867790: Pseudo dice [np.float32(0.9322)] 
2025-03-16 21:17:32.871804: Epoch time: 43.62 s 
2025-03-16 21:17:33.496507:  
2025-03-16 21:17:33.501154: Epoch 38 
2025-03-16 21:17:33.505738: Current learning rate: 0.0065 
2025-03-16 21:18:16.842231: train_loss -0.9389 
2025-03-16 21:18:16.848405: val_loss -0.9167 
2025-03-16 21:18:16.851993: Pseudo dice [np.float32(0.9331)] 
2025-03-16 21:18:16.855047: Epoch time: 43.35 s 
2025-03-16 21:18:16.858096: Yayy! New best EMA pseudo Dice: 0.9276999831199646 
2025-03-16 21:18:17.639141:  
2025-03-16 21:18:17.645213: Epoch 39 
2025-03-16 21:18:17.649322: Current learning rate: 0.00641 
2025-03-16 21:19:01.130844: train_loss -0.9392 
2025-03-16 21:19:01.136857: val_loss -0.9176 
2025-03-16 21:19:01.140365: Pseudo dice [np.float32(0.9334)] 
2025-03-16 21:19:01.143373: Epoch time: 43.49 s 
2025-03-16 21:19:01.146881: Yayy! New best EMA pseudo Dice: 0.9282000064849854 
2025-03-16 21:19:01.941118:  
2025-03-16 21:19:01.946666: Epoch 40 
2025-03-16 21:19:01.950186: Current learning rate: 0.00631 
2025-03-16 21:19:45.632423: train_loss -0.9404 
2025-03-16 21:19:45.638437: val_loss -0.9212 
2025-03-16 21:19:45.641943: Pseudo dice [np.float32(0.9365)] 
2025-03-16 21:19:45.644953: Epoch time: 43.69 s 
2025-03-16 21:19:45.648463: Yayy! New best EMA pseudo Dice: 0.929099977016449 
2025-03-16 21:19:46.429903:  
2025-03-16 21:19:46.436007: Epoch 41 
2025-03-16 21:19:46.439597: Current learning rate: 0.00622 
2025-03-16 21:20:30.434393: train_loss -0.9416 
2025-03-16 21:20:30.439404: val_loss -0.9159 
2025-03-16 21:20:30.443413: Pseudo dice [np.float32(0.9322)] 
2025-03-16 21:20:30.446922: Epoch time: 44.0 s 
2025-03-16 21:20:30.449428: Yayy! New best EMA pseudo Dice: 0.9294000267982483 
2025-03-16 21:20:31.232942:  
2025-03-16 21:20:31.239507: Epoch 42 
2025-03-16 21:20:31.243549: Current learning rate: 0.00612 
2025-03-16 21:21:14.873333: train_loss -0.9407 
2025-03-16 21:21:14.879387: val_loss -0.9196 
2025-03-16 21:21:14.882428: Pseudo dice [np.float32(0.9348)] 
2025-03-16 21:21:14.886455: Epoch time: 43.64 s 
2025-03-16 21:21:14.889487: Yayy! New best EMA pseudo Dice: 0.9298999905586243 
2025-03-16 21:21:15.662058:  
2025-03-16 21:21:15.668164: Epoch 43 
2025-03-16 21:21:15.671673: Current learning rate: 0.00603 
2025-03-16 21:21:59.331422: train_loss -0.943 
2025-03-16 21:21:59.336986: val_loss -0.9168 
2025-03-16 21:21:59.340012: Pseudo dice [np.float32(0.9323)] 
2025-03-16 21:21:59.344033: Epoch time: 43.67 s 
2025-03-16 21:21:59.347042: Yayy! New best EMA pseudo Dice: 0.9301999807357788 
2025-03-16 21:22:00.311961:  
2025-03-16 21:22:00.317980: Epoch 44 
2025-03-16 21:22:00.319997: Current learning rate: 0.00593 
2025-03-16 21:22:44.161412: train_loss -0.9429 
2025-03-16 21:22:44.167504: val_loss -0.9197 
2025-03-16 21:22:44.171609: Pseudo dice [np.float32(0.9354)] 
2025-03-16 21:22:44.175205: Epoch time: 43.85 s 
2025-03-16 21:22:44.177876: Yayy! New best EMA pseudo Dice: 0.9307000041007996 
2025-03-16 21:22:44.956696:  
2025-03-16 21:22:44.963337: Epoch 45 
2025-03-16 21:22:44.966894: Current learning rate: 0.00584 
2025-03-16 21:23:28.980228: train_loss -0.9425 
2025-03-16 21:23:28.985752: val_loss -0.9241 
2025-03-16 21:23:28.989794: Pseudo dice [np.float32(0.9394)] 
2025-03-16 21:23:28.992300: Epoch time: 44.02 s 
2025-03-16 21:23:28.995809: Yayy! New best EMA pseudo Dice: 0.9315999746322632 
2025-03-16 21:23:29.780915:  
2025-03-16 21:23:29.786447: Epoch 46 
2025-03-16 21:23:29.789475: Current learning rate: 0.00574 
2025-03-16 21:24:13.883651: train_loss -0.9449 
2025-03-16 21:24:13.889585: val_loss -0.9184 
2025-03-16 21:24:13.893093: Pseudo dice [np.float32(0.9338)] 
2025-03-16 21:24:13.896106: Epoch time: 44.1 s 
2025-03-16 21:24:13.899618: Yayy! New best EMA pseudo Dice: 0.9318000078201294 
2025-03-16 21:24:14.670373:  
2025-03-16 21:24:14.675910: Epoch 47 
2025-03-16 21:24:14.679420: Current learning rate: 0.00565 
2025-03-16 21:24:59.197036: train_loss -0.9425 
2025-03-16 21:24:59.204053: val_loss -0.9196 
2025-03-16 21:24:59.208069: Pseudo dice [np.float32(0.9349)] 
2025-03-16 21:24:59.212083: Epoch time: 44.53 s 
2025-03-16 21:24:59.215594: Yayy! New best EMA pseudo Dice: 0.9320999979972839 
2025-03-16 21:24:59.973938:  
2025-03-16 21:24:59.980095: Epoch 48 
2025-03-16 21:24:59.985140: Current learning rate: 0.00555 
2025-03-16 21:25:45.516147: train_loss -0.9468 
2025-03-16 21:25:45.523263: val_loss -0.9222 
2025-03-16 21:25:45.526775: Pseudo dice [np.float32(0.9366)] 
2025-03-16 21:25:45.530785: Epoch time: 45.54 s 
2025-03-16 21:25:45.534298: Yayy! New best EMA pseudo Dice: 0.9325000047683716 
2025-03-16 21:25:46.310759:  
2025-03-16 21:25:46.316799: Epoch 49 
2025-03-16 21:25:46.319954: Current learning rate: 0.00546 
2025-03-16 21:26:30.639482: train_loss -0.9435 
2025-03-16 21:26:30.645139: val_loss -0.9189 
2025-03-16 21:26:30.649190: Pseudo dice [np.float32(0.934)] 
2025-03-16 21:26:30.652227: Epoch time: 44.33 s 
2025-03-16 21:26:30.812722: Yayy! New best EMA pseudo Dice: 0.932699978351593 
2025-03-16 21:26:31.592514:  
2025-03-16 21:26:31.598593: Epoch 50 
2025-03-16 21:26:31.601612: Current learning rate: 0.00536 
2025-03-16 21:27:16.131214: train_loss -0.9464 
2025-03-16 21:27:16.136772: val_loss -0.918 
2025-03-16 21:27:16.141286: Pseudo dice [np.float32(0.9339)] 
2025-03-16 21:27:16.144867: Epoch time: 44.54 s 
2025-03-16 21:27:16.148418: Yayy! New best EMA pseudo Dice: 0.9327999949455261 
2025-03-16 21:27:16.900129:  
2025-03-16 21:27:16.905140: Epoch 51 
2025-03-16 21:27:16.910154: Current learning rate: 0.00526 
2025-03-16 21:28:01.552036: train_loss -0.9432 
2025-03-16 21:28:01.558053: val_loss -0.917 
2025-03-16 21:28:01.561584: Pseudo dice [np.float32(0.9328)] 
2025-03-16 21:28:01.564593: Epoch time: 44.65 s 
2025-03-16 21:28:02.138732:  
2025-03-16 21:28:02.144274: Epoch 52 
2025-03-16 21:28:02.148297: Current learning rate: 0.00517 
2025-03-16 21:28:46.869625: train_loss -0.9461 
2025-03-16 21:28:46.876686: val_loss -0.9227 
2025-03-16 21:28:46.880790: Pseudo dice [np.float32(0.9374)] 
2025-03-16 21:28:46.884325: Epoch time: 44.73 s 
2025-03-16 21:28:46.887389: Yayy! New best EMA pseudo Dice: 0.9333000183105469 
2025-03-16 21:28:47.812982:  
2025-03-16 21:28:47.817637: Epoch 53 
2025-03-16 21:28:47.823171: Current learning rate: 0.00507 
2025-03-16 21:29:32.487998: train_loss -0.9469 
2025-03-16 21:29:32.494104: val_loss -0.9192 
2025-03-16 21:29:32.498141: Pseudo dice [np.float32(0.9349)] 
2025-03-16 21:29:32.501657: Epoch time: 44.68 s 
2025-03-16 21:29:32.505168: Yayy! New best EMA pseudo Dice: 0.9333999752998352 
2025-03-16 21:29:33.271965:  
2025-03-16 21:29:33.276994: Epoch 54 
2025-03-16 21:29:33.281114: Current learning rate: 0.00497 
2025-03-16 21:30:18.030431: train_loss -0.9426 
2025-03-16 21:30:18.036944: val_loss -0.9192 
2025-03-16 21:30:18.040453: Pseudo dice [np.float32(0.9345)] 
2025-03-16 21:30:18.044462: Epoch time: 44.76 s 
2025-03-16 21:30:18.047977: Yayy! New best EMA pseudo Dice: 0.9334999918937683 
2025-03-16 21:30:18.807336:  
2025-03-16 21:30:18.812472: Epoch 55 
2025-03-16 21:30:18.815984: Current learning rate: 0.00487 
2025-03-16 21:31:03.066428: train_loss -0.9483 
2025-03-16 21:31:03.071022: val_loss -0.9216 
2025-03-16 21:31:03.075034: Pseudo dice [np.float32(0.9366)] 
2025-03-16 21:31:03.078548: Epoch time: 44.26 s 
2025-03-16 21:31:03.082563: Yayy! New best EMA pseudo Dice: 0.9337999820709229 
2025-03-16 21:31:03.849935:  
2025-03-16 21:31:03.855953: Epoch 56 
2025-03-16 21:31:03.858462: Current learning rate: 0.00478 
2025-03-16 21:31:46.927692: train_loss -0.9492 
2025-03-16 21:31:46.933279: val_loss -0.9213 
2025-03-16 21:31:46.936796: Pseudo dice [np.float32(0.9363)] 
2025-03-16 21:31:46.940303: Epoch time: 43.08 s 
2025-03-16 21:31:46.943316: Yayy! New best EMA pseudo Dice: 0.9340999722480774 
2025-03-16 21:31:47.710268:  
2025-03-16 21:31:47.715291: Epoch 57 
2025-03-16 21:31:47.718307: Current learning rate: 0.00468 
2025-03-16 21:32:30.952419: train_loss -0.9508 
2025-03-16 21:32:30.959947: val_loss -0.9219 
2025-03-16 21:32:30.963466: Pseudo dice [np.float32(0.9366)] 
2025-03-16 21:32:30.966979: Epoch time: 43.24 s 
2025-03-16 21:32:30.969990: Yayy! New best EMA pseudo Dice: 0.9343000054359436 
2025-03-16 21:32:31.755667:  
2025-03-16 21:32:31.761761: Epoch 58 
2025-03-16 21:32:31.765878: Current learning rate: 0.00458 
2025-03-16 21:33:15.062960: train_loss -0.9479 
2025-03-16 21:33:15.069502: val_loss -0.9218 
2025-03-16 21:33:15.073148: Pseudo dice [np.float32(0.9368)] 
2025-03-16 21:33:15.076218: Epoch time: 43.31 s 
2025-03-16 21:33:15.079277: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2025-03-16 21:33:15.859056:  
2025-03-16 21:33:15.865238: Epoch 59 
2025-03-16 21:33:15.869831: Current learning rate: 0.00448 
2025-03-16 21:33:59.373246: train_loss -0.9508 
2025-03-16 21:33:59.379307: val_loss -0.9217 
2025-03-16 21:33:59.383325: Pseudo dice [np.float32(0.9363)] 
2025-03-16 21:33:59.386348: Epoch time: 43.52 s 
2025-03-16 21:33:59.390892: Yayy! New best EMA pseudo Dice: 0.9348000288009644 
2025-03-16 21:34:00.155180:  
2025-03-16 21:34:00.161766: Epoch 60 
2025-03-16 21:34:00.165910: Current learning rate: 0.00438 
2025-03-16 21:34:44.791984: train_loss -0.9486 
2025-03-16 21:34:44.798517: val_loss -0.921 
2025-03-16 21:34:44.802633: Pseudo dice [np.float32(0.9358)] 
2025-03-16 21:34:44.806641: Epoch time: 44.64 s 
2025-03-16 21:34:44.809675: Yayy! New best EMA pseudo Dice: 0.9348999857902527 
2025-03-16 21:34:45.705352:  
2025-03-16 21:34:45.710943: Epoch 61 
2025-03-16 21:34:45.715528: Current learning rate: 0.00429 
2025-03-16 21:35:30.485868: train_loss -0.951 
2025-03-16 21:35:30.491386: val_loss -0.9163 
2025-03-16 21:35:30.494898: Pseudo dice [np.float32(0.9323)] 
2025-03-16 21:35:30.498908: Epoch time: 44.78 s 
2025-03-16 21:35:31.062001:  
2025-03-16 21:35:31.069559: Epoch 62 
2025-03-16 21:35:31.073606: Current learning rate: 0.00419 
2025-03-16 21:36:15.916988: train_loss -0.9503 
2025-03-16 21:36:15.923140: val_loss -0.9153 
2025-03-16 21:36:15.926715: Pseudo dice [np.float32(0.9307)] 
2025-03-16 21:36:15.930778: Epoch time: 44.86 s 
2025-03-16 21:36:16.497727:  
2025-03-16 21:36:16.504293: Epoch 63 
2025-03-16 21:36:16.508329: Current learning rate: 0.00409 
2025-03-16 21:37:01.379326: train_loss -0.9447 
2025-03-16 21:37:01.386501: val_loss -0.9226 
2025-03-16 21:37:01.390531: Pseudo dice [np.float32(0.9369)] 
2025-03-16 21:37:01.395078: Epoch time: 44.88 s 
2025-03-16 21:37:01.951298:  
2025-03-16 21:37:01.956919: Epoch 64 
2025-03-16 21:37:01.962030: Current learning rate: 0.00399 
2025-03-16 21:37:47.388885: train_loss -0.9508 
2025-03-16 21:37:47.395539: val_loss -0.9193 
2025-03-16 21:37:47.399120: Pseudo dice [np.float32(0.9346)] 
2025-03-16 21:37:47.404224: Epoch time: 45.44 s 
2025-03-16 21:37:47.971916:  
2025-03-16 21:37:47.978992: Epoch 65 
2025-03-16 21:37:47.982606: Current learning rate: 0.00389 
2025-03-16 21:38:33.499899: train_loss -0.9534 
2025-03-16 21:38:33.507505: val_loss -0.9199 
2025-03-16 21:38:33.511356: Pseudo dice [np.float32(0.9355)] 
2025-03-16 21:38:33.516375: Epoch time: 45.53 s 
2025-03-16 21:38:34.084195:  
2025-03-16 21:38:34.090801: Epoch 66 
2025-03-16 21:38:34.094941: Current learning rate: 0.00379 
2025-03-16 21:39:19.167944: train_loss -0.9523 
2025-03-16 21:39:19.174594: val_loss -0.9159 
2025-03-16 21:39:19.179311: Pseudo dice [np.float32(0.9326)] 
2025-03-16 21:39:19.182886: Epoch time: 45.08 s 
2025-03-16 21:39:19.801934:  
2025-03-16 21:39:19.808534: Epoch 67 
2025-03-16 21:39:19.812634: Current learning rate: 0.00369 
2025-03-16 21:40:02.918570: train_loss -0.9553 
2025-03-16 21:40:02.924328: val_loss -0.9183 
2025-03-16 21:40:02.929373: Pseudo dice [np.float32(0.934)] 
2025-03-16 21:40:02.933510: Epoch time: 43.12 s 
2025-03-16 21:40:03.545075:  
2025-03-16 21:40:03.550603: Epoch 68 
2025-03-16 21:40:03.555123: Current learning rate: 0.00359 
2025-03-16 21:40:46.635828: train_loss -0.9547 
2025-03-16 21:40:46.641884: val_loss -0.9172 
2025-03-16 21:40:46.645898: Pseudo dice [np.float32(0.9333)] 
2025-03-16 21:40:46.649443: Epoch time: 43.09 s 
2025-03-16 21:40:47.442822:  
2025-03-16 21:40:47.448347: Epoch 69 
2025-03-16 21:40:47.453364: Current learning rate: 0.00349 
2025-03-16 21:41:30.686863: train_loss -0.9543 
2025-03-16 21:41:30.692959: val_loss -0.9207 
2025-03-16 21:41:30.697577: Pseudo dice [np.float32(0.9361)] 
2025-03-16 21:41:30.701238: Epoch time: 43.24 s 
2025-03-16 21:41:31.403560:  
2025-03-16 21:41:31.411826: Epoch 70 
2025-03-16 21:41:31.415890: Current learning rate: 0.00338 
2025-03-16 21:42:15.076412: train_loss -0.9558 
2025-03-16 21:42:15.082935: val_loss -0.9209 
2025-03-16 21:42:15.086490: Pseudo dice [np.float32(0.9364)] 
2025-03-16 21:42:15.090504: Epoch time: 43.67 s 
2025-03-16 21:42:15.717426:  
2025-03-16 21:42:15.722987: Epoch 71 
2025-03-16 21:42:15.727123: Current learning rate: 0.00328 
2025-03-16 21:42:59.676185: train_loss -0.9525 
2025-03-16 21:42:59.682843: val_loss -0.9225 
2025-03-16 21:42:59.686921: Pseudo dice [np.float32(0.9378)] 
2025-03-16 21:42:59.690459: Epoch time: 43.96 s 
2025-03-16 21:42:59.694468: Yayy! New best EMA pseudo Dice: 0.9348999857902527 
2025-03-16 21:43:00.436744:  
2025-03-16 21:43:00.442628: Epoch 72 
2025-03-16 21:43:00.446138: Current learning rate: 0.00318 
2025-03-16 21:43:44.069023: train_loss -0.9547 
2025-03-16 21:43:44.076195: val_loss -0.918 
2025-03-16 21:43:44.079707: Pseudo dice [np.float32(0.9339)] 
2025-03-16 21:43:44.083721: Epoch time: 43.63 s 
2025-03-16 21:43:44.694379:  
2025-03-16 21:43:44.699901: Epoch 73 
2025-03-16 21:43:44.704952: Current learning rate: 0.00308 
2025-03-16 21:44:27.735593: train_loss -0.9519 
2025-03-16 21:44:27.742691: val_loss -0.9164 
2025-03-16 21:44:27.746202: Pseudo dice [np.float32(0.9322)] 
2025-03-16 21:44:27.750218: Epoch time: 43.04 s 
2025-03-16 21:44:28.348860:  
2025-03-16 21:44:28.355541: Epoch 74 
2025-03-16 21:44:28.360148: Current learning rate: 0.00297 
2025-03-16 21:45:12.353986: train_loss -0.9546 
2025-03-16 21:45:12.360507: val_loss -0.9198 
2025-03-16 21:45:12.365520: Pseudo dice [np.float32(0.9354)] 
2025-03-16 21:45:12.370032: Epoch time: 44.01 s 
2025-03-16 21:45:12.940813:  
2025-03-16 21:45:12.945825: Epoch 75 
2025-03-16 21:45:12.950334: Current learning rate: 0.00287 
2025-03-16 21:45:56.299195: train_loss -0.9542 
2025-03-16 21:45:56.304774: val_loss -0.9103 
2025-03-16 21:45:56.309289: Pseudo dice [np.float32(0.9282)] 
2025-03-16 21:45:56.313350: Epoch time: 43.36 s 
2025-03-16 21:45:57.090404:  
2025-03-16 21:45:57.097035: Epoch 76 
2025-03-16 21:45:57.100607: Current learning rate: 0.00277 
2025-03-16 21:46:40.263162: train_loss -0.9518 
2025-03-16 21:46:40.270350: val_loss -0.9184 
2025-03-16 21:46:40.275368: Pseudo dice [np.float32(0.9346)] 
2025-03-16 21:46:40.278878: Epoch time: 43.17 s 
2025-03-16 21:46:40.876055:  
2025-03-16 21:46:40.882075: Epoch 77 
2025-03-16 21:46:40.886116: Current learning rate: 0.00266 
2025-03-16 21:47:24.245390: train_loss -0.9551 
2025-03-16 21:47:24.251946: val_loss -0.918 
2025-03-16 21:47:24.256963: Pseudo dice [np.float32(0.9339)] 
2025-03-16 21:47:24.261523: Epoch time: 43.37 s 
2025-03-16 21:47:24.888300:  
2025-03-16 21:47:24.893881: Epoch 78 
2025-03-16 21:47:24.898987: Current learning rate: 0.00256 
2025-03-16 21:48:07.997762: train_loss -0.9563 
2025-03-16 21:48:08.004275: val_loss -0.92 
2025-03-16 21:48:08.007786: Pseudo dice [np.float32(0.9358)] 
2025-03-16 21:48:08.011798: Epoch time: 43.11 s 
2025-03-16 21:48:08.625476:  
2025-03-16 21:48:08.632136: Epoch 79 
2025-03-16 21:48:08.635693: Current learning rate: 0.00245 
2025-03-16 21:48:51.645789: train_loss -0.9576 
2025-03-16 21:48:51.651809: val_loss -0.9215 
2025-03-16 21:48:51.655817: Pseudo dice [np.float32(0.9364)] 
2025-03-16 21:48:51.660838: Epoch time: 43.02 s 
2025-03-16 21:48:52.278963:  
2025-03-16 21:48:52.285531: Epoch 80 
2025-03-16 21:48:52.289574: Current learning rate: 0.00235 
2025-03-16 21:49:35.397054: train_loss -0.9571 
2025-03-16 21:49:35.404264: val_loss -0.9219 
2025-03-16 21:49:35.408320: Pseudo dice [np.float32(0.9373)] 
2025-03-16 21:49:35.412554: Epoch time: 43.12 s 
2025-03-16 21:49:36.018991:  
2025-03-16 21:49:36.024577: Epoch 81 
2025-03-16 21:49:36.029147: Current learning rate: 0.00224 
2025-03-16 21:50:19.028935: train_loss -0.958 
2025-03-16 21:50:19.035076: val_loss -0.9181 
2025-03-16 21:50:19.040096: Pseudo dice [np.float32(0.9342)] 
2025-03-16 21:50:19.044108: Epoch time: 43.01 s 
2025-03-16 21:50:19.650812:  
2025-03-16 21:50:19.656919: Epoch 82 
2025-03-16 21:50:19.660933: Current learning rate: 0.00214 
2025-03-16 21:51:02.681166: train_loss -0.9576 
2025-03-16 21:51:02.687710: val_loss -0.92 
2025-03-16 21:51:02.691720: Pseudo dice [np.float32(0.9359)] 
2025-03-16 21:51:02.695738: Epoch time: 43.03 s 
2025-03-16 21:51:03.280986:  
2025-03-16 21:51:03.288635: Epoch 83 
2025-03-16 21:51:03.292228: Current learning rate: 0.00203 
2025-03-16 21:51:47.288233: train_loss -0.9587 
2025-03-16 21:51:47.294327: val_loss -0.9178 
2025-03-16 21:51:47.299401: Pseudo dice [np.float32(0.9338)] 
2025-03-16 21:51:47.302915: Epoch time: 44.01 s 
2025-03-16 21:51:48.031238:  
2025-03-16 21:51:48.037293: Epoch 84 
2025-03-16 21:51:48.041902: Current learning rate: 0.00192 
2025-03-16 21:52:31.971940: train_loss -0.9574 
2025-03-16 21:52:31.980112: val_loss -0.92 
2025-03-16 21:52:31.985173: Pseudo dice [np.float32(0.9357)] 
2025-03-16 21:52:31.989190: Epoch time: 43.94 s 
2025-03-16 21:52:32.557375:  
2025-03-16 21:52:32.563515: Epoch 85 
2025-03-16 21:52:32.568529: Current learning rate: 0.00181 
2025-03-16 21:53:16.975532: train_loss -0.9581 
2025-03-16 21:53:16.981651: val_loss -0.9197 
2025-03-16 21:53:16.986683: Pseudo dice [np.float32(0.9356)] 
2025-03-16 21:53:16.990194: Epoch time: 44.42 s 
2025-03-16 21:53:17.566050:  
2025-03-16 21:53:17.572071: Epoch 86 
2025-03-16 21:53:17.576084: Current learning rate: 0.0017 
2025-03-16 21:54:01.505098: train_loss -0.9569 
2025-03-16 21:54:01.511616: val_loss -0.9228 
2025-03-16 21:54:01.516634: Pseudo dice [np.float32(0.9381)] 
2025-03-16 21:54:01.520148: Epoch time: 43.94 s 
2025-03-16 21:54:01.524157: Yayy! New best EMA pseudo Dice: 0.9351999759674072 
2025-03-16 21:54:02.265085:  
2025-03-16 21:54:02.271117: Epoch 87 
2025-03-16 21:54:02.275125: Current learning rate: 0.00159 
2025-03-16 21:54:46.226640: train_loss -0.9584 
2025-03-16 21:54:46.234225: val_loss -0.9203 
2025-03-16 21:54:46.238783: Pseudo dice [np.float32(0.9367)] 
2025-03-16 21:54:46.242809: Epoch time: 43.96 s 
2025-03-16 21:54:46.246332: Yayy! New best EMA pseudo Dice: 0.9354000091552734 
2025-03-16 21:54:46.994636:  
2025-03-16 21:54:47.001555: Epoch 88 
2025-03-16 21:54:47.006569: Current learning rate: 0.00148 
2025-03-16 21:55:31.016766: train_loss -0.9597 
2025-03-16 21:55:31.022223: val_loss -0.924 
2025-03-16 21:55:31.026725: Pseudo dice [np.float32(0.9391)] 
2025-03-16 21:55:31.031268: Epoch time: 44.02 s 
2025-03-16 21:55:31.035301: Yayy! New best EMA pseudo Dice: 0.935699999332428 
2025-03-16 21:55:31.771793:  
2025-03-16 21:55:31.777882: Epoch 89 
2025-03-16 21:55:31.782415: Current learning rate: 0.00137 
2025-03-16 21:56:15.727432: train_loss -0.9587 
2025-03-16 21:56:15.733974: val_loss -0.9224 
2025-03-16 21:56:15.738540: Pseudo dice [np.float32(0.9376)] 
2025-03-16 21:56:15.742561: Epoch time: 43.96 s 
2025-03-16 21:56:15.746576: Yayy! New best EMA pseudo Dice: 0.9358999729156494 
2025-03-16 21:56:16.492459:  
2025-03-16 21:56:16.499043: Epoch 90 
2025-03-16 21:56:16.504186: Current learning rate: 0.00126 
2025-03-16 21:57:00.486993: train_loss -0.9548 
2025-03-16 21:57:00.493569: val_loss -0.9176 
2025-03-16 21:57:00.497074: Pseudo dice [np.float32(0.9335)] 
2025-03-16 21:57:00.501086: Epoch time: 43.99 s 
2025-03-16 21:57:01.073090:  
2025-03-16 21:57:01.079686: Epoch 91 
2025-03-16 21:57:01.083724: Current learning rate: 0.00115 
2025-03-16 21:57:45.052715: train_loss -0.9589 
2025-03-16 21:57:45.058308: val_loss -0.921 
2025-03-16 21:57:45.061870: Pseudo dice [np.float32(0.9369)] 
2025-03-16 21:57:45.066478: Epoch time: 43.98 s 
2025-03-16 21:57:45.629984:  
2025-03-16 21:57:45.637091: Epoch 92 
2025-03-16 21:57:45.640617: Current learning rate: 0.00103 
2025-03-16 21:58:28.654568: train_loss -0.9586 
2025-03-16 21:58:28.660118: val_loss -0.9204 
2025-03-16 21:58:28.665154: Pseudo dice [np.float32(0.9356)] 
2025-03-16 21:58:28.669177: Epoch time: 43.02 s 
2025-03-16 21:58:29.391903:  
2025-03-16 21:58:29.396940: Epoch 93 
2025-03-16 21:58:29.401474: Current learning rate: 0.00091 
2025-03-16 21:59:12.106994: train_loss -0.9604 
2025-03-16 21:59:12.113066: val_loss -0.9216 
2025-03-16 21:59:12.117599: Pseudo dice [np.float32(0.9371)] 
2025-03-16 21:59:12.120642: Epoch time: 42.72 s 
2025-03-16 21:59:12.680818:  
2025-03-16 21:59:12.687476: Epoch 94 
2025-03-16 21:59:12.691013: Current learning rate: 0.00079 
2025-03-16 21:59:55.422334: train_loss -0.9606 
2025-03-16 21:59:55.428919: val_loss -0.917 
2025-03-16 21:59:55.432942: Pseudo dice [np.float32(0.9337)] 
2025-03-16 21:59:55.437498: Epoch time: 42.74 s 
2025-03-16 21:59:55.993474:  
2025-03-16 21:59:55.999992: Epoch 95 
2025-03-16 21:59:56.004501: Current learning rate: 0.00067 
2025-03-16 22:00:38.726921: train_loss -0.9607 
2025-03-16 22:00:38.734112: val_loss -0.9204 
2025-03-16 22:00:38.738192: Pseudo dice [np.float32(0.9363)] 
2025-03-16 22:00:38.742236: Epoch time: 42.73 s 
2025-03-16 22:00:39.296951:  
2025-03-16 22:00:39.301982: Epoch 96 
2025-03-16 22:00:39.306591: Current learning rate: 0.00055 
2025-03-16 22:01:22.023100: train_loss -0.9592 
2025-03-16 22:01:22.029667: val_loss -0.9216 
2025-03-16 22:01:22.034708: Pseudo dice [np.float32(0.9373)] 
2025-03-16 22:01:22.038257: Epoch time: 42.73 s 
2025-03-16 22:01:22.606885:  
2025-03-16 22:01:22.614489: Epoch 97 
2025-03-16 22:01:22.618497: Current learning rate: 0.00043 
2025-03-16 22:02:05.338568: train_loss -0.96 
2025-03-16 22:02:05.345721: val_loss -0.9198 
2025-03-16 22:02:05.349823: Pseudo dice [np.float32(0.936)] 
2025-03-16 22:02:05.353328: Epoch time: 42.73 s 
2025-03-16 22:02:05.357356: Yayy! New best EMA pseudo Dice: 0.9358999729156494 
2025-03-16 22:02:06.109689:  
2025-03-16 22:02:06.116739: Epoch 98 
2025-03-16 22:02:06.121773: Current learning rate: 0.0003 
2025-03-16 22:02:48.806045: train_loss -0.9591 
2025-03-16 22:02:48.813613: val_loss -0.9217 
2025-03-16 22:02:48.818144: Pseudo dice [np.float32(0.9371)] 
2025-03-16 22:02:48.822174: Epoch time: 42.7 s 
2025-03-16 22:02:48.826184: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2025-03-16 22:02:49.568601:  
2025-03-16 22:02:49.575667: Epoch 99 
2025-03-16 22:02:49.580198: Current learning rate: 0.00016 
2025-03-16 22:03:32.297326: train_loss -0.9607 
2025-03-16 22:03:32.304886: val_loss -0.9235 
2025-03-16 22:03:32.309897: Pseudo dice [np.float32(0.9388)] 
2025-03-16 22:03:32.314448: Epoch time: 42.73 s 
2025-03-16 22:03:32.317456: Yayy! New best EMA pseudo Dice: 0.9362999796867371 
2025-03-16 22:03:33.277765: Training done. 
2025-03-16 22:03:33.315370: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-16 22:03:33.322439: The split file contains 5 splits. 
2025-03-16 22:03:33.328443: Desired fold for training: 0 
2025-03-16 22:03:33.334559: This split has 16 training and 4 validation cases. 
2025-03-16 22:03:33.340560: predicting la_007 
2025-03-16 22:03:33.349598: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2025-03-16 22:03:39.316067: predicting la_016 
2025-03-16 22:03:39.328572: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2025-03-16 22:03:41.587961: predicting la_021 
2025-03-16 22:03:41.598470: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2025-03-16 22:03:43.861259: predicting la_024 
2025-03-16 22:03:43.874273: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2025-03-16 22:03:52.906165: Validation complete 
2025-03-16 22:03:52.911165: Mean Validation Dice:  0.9365339347512319 
