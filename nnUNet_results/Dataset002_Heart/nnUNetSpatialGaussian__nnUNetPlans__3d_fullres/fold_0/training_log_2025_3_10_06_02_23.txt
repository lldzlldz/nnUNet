
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-10 06:02:23.141699: do_dummy_2d_data_aug: False 
2025-03-10 06:02:23.142700: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-10 06:02:23.150701: The split file contains 5 splits. 
2025-03-10 06:02:23.153699: Desired fold for training: 0 
2025-03-10 06:02:23.155699: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2025-03-10 06:02:33.107955: unpacking dataset... 
2025-03-10 06:02:33.376969: unpacking done... 
2025-03-10 06:02:37.219494:  
2025-03-10 06:02:37.224611: Epoch 0 
2025-03-10 06:02:37.229124: Current learning rate: 0.01 
2025-03-10 06:04:09.008356: train_loss -0.6631 
2025-03-10 06:04:09.014371: val_loss -0.8918 
2025-03-10 06:04:09.017381: Pseudo dice [np.float32(0.9182)] 
2025-03-10 06:04:09.020894: Epoch time: 91.79 s 
2025-03-10 06:04:09.023400: Yayy! New best EMA pseudo Dice: 0.9182000160217285 
2025-03-10 06:04:09.643002:  
2025-03-10 06:04:09.648541: Epoch 1 
2025-03-10 06:04:09.652053: Current learning rate: 0.00991 
2025-03-10 06:05:32.318260: train_loss -0.8969 
2025-03-10 06:05:32.324777: val_loss -0.8979 
2025-03-10 06:05:32.328288: Pseudo dice [np.float32(0.9187)] 
2025-03-10 06:05:32.330795: Epoch time: 82.68 s 
2025-03-10 06:05:32.334810: Yayy! New best EMA pseudo Dice: 0.9182000160217285 
2025-03-10 06:05:33.022793:  
2025-03-10 06:05:33.028833: Epoch 2 
2025-03-10 06:05:33.032894: Current learning rate: 0.00982 
2025-03-10 06:06:55.669244: train_loss -0.9075 
2025-03-10 06:06:55.676587: val_loss -0.915 
2025-03-10 06:06:55.680099: Pseudo dice [np.float32(0.933)] 
2025-03-10 06:06:55.682610: Epoch time: 82.65 s 
2025-03-10 06:06:55.686115: Yayy! New best EMA pseudo Dice: 0.919700026512146 
2025-03-10 06:06:56.411494:  
2025-03-10 06:06:56.417007: Epoch 3 
2025-03-10 06:06:56.420518: Current learning rate: 0.00973 
2025-03-10 06:08:19.070611: train_loss -0.9228 
2025-03-10 06:08:19.076685: val_loss -0.9132 
2025-03-10 06:08:19.079304: Pseudo dice [np.float32(0.931)] 
2025-03-10 06:08:19.082818: Epoch time: 82.66 s 
2025-03-10 06:08:19.086331: Yayy! New best EMA pseudo Dice: 0.920799970626831 
2025-03-10 06:08:19.792267:  
2025-03-10 06:08:19.797783: Epoch 4 
2025-03-10 06:08:19.801293: Current learning rate: 0.00964 
2025-03-10 06:09:42.436865: train_loss -0.9344 
2025-03-10 06:09:42.442876: val_loss -0.915 
2025-03-10 06:09:42.445887: Pseudo dice [np.float32(0.9321)] 
2025-03-10 06:09:42.449398: Epoch time: 82.65 s 
2025-03-10 06:09:42.451906: Yayy! New best EMA pseudo Dice: 0.9218999743461609 
2025-03-10 06:09:43.290961:  
2025-03-10 06:09:43.297023: Epoch 5 
2025-03-10 06:09:43.300201: Current learning rate: 0.00955 
2025-03-10 06:11:05.925545: train_loss -0.9412 
2025-03-10 06:11:05.931557: val_loss -0.9182 
2025-03-10 06:11:05.934567: Pseudo dice [np.float32(0.9351)] 
2025-03-10 06:11:05.938078: Epoch time: 82.63 s 
2025-03-10 06:11:05.940585: Yayy! New best EMA pseudo Dice: 0.92330002784729 
2025-03-10 06:11:06.637426:  
2025-03-10 06:11:06.643481: Epoch 6 
2025-03-10 06:11:06.646562: Current learning rate: 0.00946 
2025-03-10 06:12:29.224669: train_loss -0.9465 
2025-03-10 06:12:29.230186: val_loss -0.9189 
2025-03-10 06:12:29.233695: Pseudo dice [np.float32(0.9356)] 
2025-03-10 06:12:29.237202: Epoch time: 82.59 s 
2025-03-10 06:12:29.240211: Yayy! New best EMA pseudo Dice: 0.9244999885559082 
2025-03-10 06:12:29.951051:  
2025-03-10 06:12:29.956573: Epoch 7 
2025-03-10 06:12:29.958580: Current learning rate: 0.00937 
2025-03-10 06:13:52.586788: train_loss -0.9502 
2025-03-10 06:13:52.592803: val_loss -0.9204 
2025-03-10 06:13:52.596310: Pseudo dice [np.float32(0.9377)] 
2025-03-10 06:13:52.599319: Epoch time: 82.64 s 
2025-03-10 06:13:52.602830: Yayy! New best EMA pseudo Dice: 0.9258000254631042 
2025-03-10 06:13:53.319751:  
2025-03-10 06:13:53.325783: Epoch 8 
2025-03-10 06:13:53.328289: Current learning rate: 0.00928 
2025-03-10 06:15:16.085292: train_loss -0.949 
2025-03-10 06:15:16.091463: val_loss -0.9224 
2025-03-10 06:15:16.094495: Pseudo dice [np.float32(0.9383)] 
2025-03-10 06:15:16.098021: Epoch time: 82.77 s 
2025-03-10 06:15:16.101049: Yayy! New best EMA pseudo Dice: 0.9271000027656555 
2025-03-10 06:15:16.834944:  
2025-03-10 06:15:16.839485: Epoch 9 
2025-03-10 06:15:16.843638: Current learning rate: 0.00919 
2025-03-10 06:16:39.523621: train_loss -0.9538 
2025-03-10 06:16:39.529642: val_loss -0.9209 
2025-03-10 06:16:39.533659: Pseudo dice [np.float32(0.9376)] 
2025-03-10 06:16:39.537166: Epoch time: 82.69 s 
2025-03-10 06:16:39.539670: Yayy! New best EMA pseudo Dice: 0.9280999898910522 
2025-03-10 06:16:40.229481:  
2025-03-10 06:16:40.234494: Epoch 10 
2025-03-10 06:16:40.238003: Current learning rate: 0.0091 
2025-03-10 06:18:02.876872: train_loss -0.956 
2025-03-10 06:18:02.882395: val_loss -0.9208 
2025-03-10 06:18:02.885909: Pseudo dice [np.float32(0.9378)] 
2025-03-10 06:18:02.889919: Epoch time: 82.65 s 
2025-03-10 06:18:02.892428: Yayy! New best EMA pseudo Dice: 0.929099977016449 
2025-03-10 06:18:03.594465:  
2025-03-10 06:18:03.599508: Epoch 11 
2025-03-10 06:18:03.603688: Current learning rate: 0.009 
2025-03-10 06:19:26.210781: train_loss -0.9474 
2025-03-10 06:19:26.216278: val_loss -0.9198 
2025-03-10 06:19:26.219950: Pseudo dice [np.float32(0.9358)] 
2025-03-10 06:19:26.222431: Epoch time: 82.62 s 
2025-03-10 06:19:26.226556: Yayy! New best EMA pseudo Dice: 0.9297999739646912 
2025-03-10 06:19:26.918725:  
2025-03-10 06:19:26.924131: Epoch 12 
2025-03-10 06:19:26.927683: Current learning rate: 0.00891 
2025-03-10 06:20:50.021375: train_loss -0.9558 
2025-03-10 06:20:50.027392: val_loss -0.9238 
2025-03-10 06:20:50.031405: Pseudo dice [np.float32(0.9398)] 
2025-03-10 06:20:50.034916: Epoch time: 83.1 s 
2025-03-10 06:20:50.037422: Yayy! New best EMA pseudo Dice: 0.9308000206947327 
2025-03-10 06:20:50.892281:  
2025-03-10 06:20:50.898859: Epoch 13 
2025-03-10 06:20:50.901463: Current learning rate: 0.00882 
2025-03-10 06:22:13.581880: train_loss -0.9537 
2025-03-10 06:22:13.587893: val_loss -0.9214 
2025-03-10 06:22:13.590903: Pseudo dice [np.float32(0.9384)] 
2025-03-10 06:22:13.594412: Epoch time: 82.69 s 
2025-03-10 06:22:13.597919: Yayy! New best EMA pseudo Dice: 0.9315000176429749 
2025-03-10 06:22:14.309436:  
2025-03-10 06:22:14.315132: Epoch 14 
2025-03-10 06:22:14.319670: Current learning rate: 0.00873 
2025-03-10 06:23:37.093268: train_loss -0.9561 
2025-03-10 06:23:37.099370: val_loss -0.9226 
2025-03-10 06:23:37.103410: Pseudo dice [np.float32(0.9396)] 
2025-03-10 06:23:37.106954: Epoch time: 82.78 s 
2025-03-10 06:23:37.109999: Yayy! New best EMA pseudo Dice: 0.9322999715805054 
2025-03-10 06:23:37.823261:  
2025-03-10 06:23:37.829328: Epoch 15 
2025-03-10 06:23:37.831951: Current learning rate: 0.00864 
2025-03-10 06:25:00.434581: train_loss -0.9585 
2025-03-10 06:25:00.441095: val_loss -0.9215 
2025-03-10 06:25:00.444606: Pseudo dice [np.float32(0.938)] 
2025-03-10 06:25:00.448617: Epoch time: 82.61 s 
2025-03-10 06:25:00.451125: Yayy! New best EMA pseudo Dice: 0.9329000115394592 
2025-03-10 06:25:01.168402:  
2025-03-10 06:25:01.174982: Epoch 16 
2025-03-10 06:25:01.177522: Current learning rate: 0.00855 
2025-03-10 06:26:23.831839: train_loss -0.9622 
2025-03-10 06:26:23.838377: val_loss -0.9209 
2025-03-10 06:26:23.842391: Pseudo dice [np.float32(0.9387)] 
2025-03-10 06:26:23.845898: Epoch time: 82.66 s 
2025-03-10 06:26:23.848908: Yayy! New best EMA pseudo Dice: 0.9334999918937683 
2025-03-10 06:26:24.572609:  
2025-03-10 06:26:24.578187: Epoch 17 
2025-03-10 06:26:24.584359: Current learning rate: 0.00846 
2025-03-10 06:27:47.285860: train_loss -0.9628 
2025-03-10 06:27:47.291876: val_loss -0.9209 
2025-03-10 06:27:47.295386: Pseudo dice [np.float32(0.9387)] 
2025-03-10 06:27:47.299402: Epoch time: 82.71 s 
2025-03-10 06:27:47.301908: Yayy! New best EMA pseudo Dice: 0.9340000152587891 
2025-03-10 06:27:48.027720:  
2025-03-10 06:27:48.033234: Epoch 18 
2025-03-10 06:27:48.036744: Current learning rate: 0.00836 
2025-03-10 06:29:10.673582: train_loss -0.9651 
2025-03-10 06:29:10.680097: val_loss -0.9219 
2025-03-10 06:29:10.683610: Pseudo dice [np.float32(0.9397)] 
2025-03-10 06:29:10.687117: Epoch time: 82.65 s 
2025-03-10 06:29:10.690128: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2025-03-10 06:29:11.403536:  
2025-03-10 06:29:11.409048: Epoch 19 
2025-03-10 06:29:11.412559: Current learning rate: 0.00827 
2025-03-10 06:30:34.100370: train_loss -0.9639 
2025-03-10 06:30:34.106456: val_loss -0.9148 
2025-03-10 06:30:34.110044: Pseudo dice [np.float32(0.9347)] 
2025-03-10 06:30:34.113108: Epoch time: 82.7 s 
2025-03-10 06:30:34.116146: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2025-03-10 06:30:34.841163:  
2025-03-10 06:30:34.847291: Epoch 20 
2025-03-10 06:30:34.850347: Current learning rate: 0.00818 
2025-03-10 06:31:57.593102: train_loss -0.9545 
2025-03-10 06:31:57.599789: val_loss -0.917 
2025-03-10 06:31:57.603297: Pseudo dice [np.float32(0.9364)] 
2025-03-10 06:31:57.607312: Epoch time: 82.75 s 
2025-03-10 06:31:57.609817: Yayy! New best EMA pseudo Dice: 0.9348000288009644 
2025-03-10 06:31:58.484376:  
2025-03-10 06:31:58.490490: Epoch 21 
2025-03-10 06:31:58.493556: Current learning rate: 0.00809 
2025-03-10 06:33:21.203313: train_loss -0.9611 
2025-03-10 06:33:21.209340: val_loss -0.9171 
2025-03-10 06:33:21.214352: Pseudo dice [np.float32(0.9357)] 
2025-03-10 06:33:21.218367: Epoch time: 82.72 s 
2025-03-10 06:33:21.220873: Yayy! New best EMA pseudo Dice: 0.9348000288009644 
2025-03-10 06:33:21.907184:  
2025-03-10 06:33:21.913224: Epoch 22 
2025-03-10 06:33:21.916748: Current learning rate: 0.008 
2025-03-10 06:34:44.593620: train_loss -0.955 
2025-03-10 06:34:44.600136: val_loss -0.9196 
2025-03-10 06:34:44.603646: Pseudo dice [np.float32(0.9361)] 
2025-03-10 06:34:44.607154: Epoch time: 82.69 s 
2025-03-10 06:34:44.610164: Yayy! New best EMA pseudo Dice: 0.9350000023841858 
2025-03-10 06:34:45.297614:  
2025-03-10 06:34:45.303128: Epoch 23 
2025-03-10 06:34:45.306637: Current learning rate: 0.0079 
2025-03-10 06:36:08.066106: train_loss -0.9596 
2025-03-10 06:36:08.072121: val_loss -0.9193 
2025-03-10 06:36:08.075629: Pseudo dice [np.float32(0.9372)] 
2025-03-10 06:36:08.078638: Epoch time: 82.77 s 
2025-03-10 06:36:08.082148: Yayy! New best EMA pseudo Dice: 0.9351999759674072 
2025-03-10 06:36:08.772904:  
2025-03-10 06:36:08.779037: Epoch 24 
2025-03-10 06:36:08.781623: Current learning rate: 0.00781 
2025-03-10 06:37:31.501445: train_loss -0.9664 
2025-03-10 06:37:31.506544: val_loss -0.9199 
2025-03-10 06:37:31.511111: Pseudo dice [np.float32(0.9384)] 
2025-03-10 06:37:31.514157: Epoch time: 82.73 s 
2025-03-10 06:37:31.517220: Yayy! New best EMA pseudo Dice: 0.9355000257492065 
2025-03-10 06:37:32.206086:  
2025-03-10 06:37:32.212150: Epoch 25 
2025-03-10 06:37:32.214750: Current learning rate: 0.00772 
2025-03-10 06:38:54.855100: train_loss -0.9685 
2025-03-10 06:38:54.860256: val_loss -0.9191 
2025-03-10 06:38:54.864310: Pseudo dice [np.float32(0.9378)] 
2025-03-10 06:38:54.867868: Epoch time: 82.65 s 
2025-03-10 06:38:54.870405: Yayy! New best EMA pseudo Dice: 0.935699999332428 
2025-03-10 06:38:55.568107:  
2025-03-10 06:38:55.574262: Epoch 26 
2025-03-10 06:38:55.577312: Current learning rate: 0.00763 
2025-03-10 06:40:18.232381: train_loss -0.966 
2025-03-10 06:40:18.238557: val_loss -0.9202 
2025-03-10 06:40:18.242122: Pseudo dice [np.float32(0.9381)] 
2025-03-10 06:40:18.245186: Epoch time: 82.67 s 
2025-03-10 06:40:18.248260: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2025-03-10 06:40:18.929721:  
2025-03-10 06:40:18.934743: Epoch 27 
2025-03-10 06:40:18.939251: Current learning rate: 0.00753 
2025-03-10 06:41:41.661597: train_loss -0.9677 
2025-03-10 06:41:41.667776: val_loss -0.9191 
2025-03-10 06:41:41.671328: Pseudo dice [np.float32(0.9379)] 
2025-03-10 06:41:41.674406: Epoch time: 82.73 s 
2025-03-10 06:41:41.678437: Yayy! New best EMA pseudo Dice: 0.9362000226974487 
2025-03-10 06:41:42.364031:  
2025-03-10 06:41:42.369547: Epoch 28 
2025-03-10 06:41:42.373057: Current learning rate: 0.00744 
2025-03-10 06:43:05.077903: train_loss -0.9686 
2025-03-10 06:43:05.082916: val_loss -0.9212 
2025-03-10 06:43:05.086426: Pseudo dice [np.float32(0.9395)] 
2025-03-10 06:43:05.090431: Epoch time: 82.71 s 
2025-03-10 06:43:05.093938: Yayy! New best EMA pseudo Dice: 0.9365000128746033 
2025-03-10 06:43:05.950595:  
2025-03-10 06:43:05.956110: Epoch 29 
2025-03-10 06:43:05.959619: Current learning rate: 0.00735 
2025-03-10 06:44:28.691507: train_loss -0.9702 
2025-03-10 06:44:28.698154: val_loss -0.9215 
2025-03-10 06:44:28.701686: Pseudo dice [np.float32(0.9402)] 
2025-03-10 06:44:28.704746: Epoch time: 82.74 s 
2025-03-10 06:44:28.708294: Yayy! New best EMA pseudo Dice: 0.9369000196456909 
2025-03-10 06:44:29.422681:  
2025-03-10 06:44:29.428722: Epoch 30 
2025-03-10 06:44:29.432347: Current learning rate: 0.00725 
2025-03-10 06:45:52.095799: train_loss -0.9705 
2025-03-10 06:45:52.101813: val_loss -0.9203 
2025-03-10 06:45:52.105823: Pseudo dice [np.float32(0.9392)] 
2025-03-10 06:45:52.109334: Epoch time: 82.67 s 
2025-03-10 06:45:52.112841: Yayy! New best EMA pseudo Dice: 0.9370999932289124 
2025-03-10 06:45:52.806551:  
2025-03-10 06:45:52.812082: Epoch 31 
2025-03-10 06:45:52.816155: Current learning rate: 0.00716 
2025-03-10 06:47:15.558701: train_loss -0.9684 
2025-03-10 06:47:15.564801: val_loss -0.9222 
2025-03-10 06:47:15.568885: Pseudo dice [np.float32(0.9402)] 
2025-03-10 06:47:15.571943: Epoch time: 82.75 s 
2025-03-10 06:47:15.574980: Yayy! New best EMA pseudo Dice: 0.9373999834060669 
2025-03-10 06:47:16.298247:  
2025-03-10 06:47:16.304323: Epoch 32 
2025-03-10 06:47:16.306856: Current learning rate: 0.00707 
2025-03-10 06:48:39.055250: train_loss -0.9697 
2025-03-10 06:48:39.061266: val_loss -0.9201 
2025-03-10 06:48:39.064773: Pseudo dice [np.float32(0.9392)] 
2025-03-10 06:48:39.067782: Epoch time: 82.76 s 
2025-03-10 06:48:39.071294: Yayy! New best EMA pseudo Dice: 0.9376000165939331 
2025-03-10 06:48:39.786127:  
2025-03-10 06:48:39.792182: Epoch 33 
2025-03-10 06:48:39.795256: Current learning rate: 0.00697 
2025-03-10 06:50:02.501214: train_loss -0.9718 
2025-03-10 06:50:02.507772: val_loss -0.9185 
2025-03-10 06:50:02.511283: Pseudo dice [np.float32(0.9386)] 
2025-03-10 06:50:02.514792: Epoch time: 82.72 s 
2025-03-10 06:50:02.517802: Yayy! New best EMA pseudo Dice: 0.9376999735832214 
2025-03-10 06:50:03.228176:  
2025-03-10 06:50:03.234370: Epoch 34 
2025-03-10 06:50:03.237884: Current learning rate: 0.00688 
2025-03-10 06:51:25.920391: train_loss -0.9702 
2025-03-10 06:51:25.926406: val_loss -0.9198 
2025-03-10 06:51:25.928913: Pseudo dice [np.float32(0.9387)] 
2025-03-10 06:51:25.932923: Epoch time: 82.69 s 
2025-03-10 06:51:25.935429: Yayy! New best EMA pseudo Dice: 0.9377999901771545 
2025-03-10 06:51:26.649881:  
2025-03-10 06:51:26.655959: Epoch 35 
2025-03-10 06:51:26.658526: Current learning rate: 0.00679 
2025-03-10 06:52:49.360761: train_loss -0.9696 
2025-03-10 06:52:49.365772: val_loss -0.9189 
2025-03-10 06:52:49.369833: Pseudo dice [np.float32(0.9386)] 
2025-03-10 06:52:49.373423: Epoch time: 82.71 s 
2025-03-10 06:52:49.376452: Yayy! New best EMA pseudo Dice: 0.9379000067710876 
2025-03-10 06:52:50.092982:  
2025-03-10 06:52:50.098498: Epoch 36 
2025-03-10 06:52:50.102009: Current learning rate: 0.00669 
2025-03-10 06:54:12.833983: train_loss -0.9728 
2025-03-10 06:54:12.840499: val_loss -0.9217 
2025-03-10 06:54:12.846517: Pseudo dice [np.float32(0.9403)] 
2025-03-10 06:54:12.851529: Epoch time: 82.74 s 
2025-03-10 06:54:12.855044: Yayy! New best EMA pseudo Dice: 0.9380999803543091 
2025-03-10 06:54:13.710016:  
2025-03-10 06:54:13.715580: Epoch 37 
2025-03-10 06:54:13.719174: Current learning rate: 0.0066 
2025-03-10 06:55:36.422978: train_loss -0.9733 
2025-03-10 06:55:36.429496: val_loss -0.9192 
2025-03-10 06:55:36.433008: Pseudo dice [np.float32(0.939)] 
2025-03-10 06:55:36.436516: Epoch time: 82.71 s 
2025-03-10 06:55:36.439526: Yayy! New best EMA pseudo Dice: 0.9381999969482422 
2025-03-10 06:55:37.145577:  
2025-03-10 06:55:37.151189: Epoch 38 
2025-03-10 06:55:37.155254: Current learning rate: 0.0065 
2025-03-10 06:56:59.812145: train_loss -0.9719 
2025-03-10 06:56:59.817720: val_loss -0.92 
2025-03-10 06:56:59.821231: Pseudo dice [np.float32(0.9395)] 
2025-03-10 06:56:59.825242: Epoch time: 82.67 s 
2025-03-10 06:56:59.827748: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-03-10 06:57:00.537823:  
2025-03-10 06:57:00.542836: Epoch 39 
2025-03-10 06:57:00.546348: Current learning rate: 0.00641 
2025-03-10 06:58:23.173887: train_loss -0.974 
2025-03-10 06:58:23.179404: val_loss -0.9188 
2025-03-10 06:58:23.182922: Pseudo dice [np.float32(0.9392)] 
2025-03-10 06:58:23.189435: Epoch time: 82.64 s 
2025-03-10 06:58:23.192942: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-03-10 06:58:23.914858:  
2025-03-10 06:58:23.921373: Epoch 40 
2025-03-10 06:58:23.924885: Current learning rate: 0.00631 
2025-03-10 06:59:46.522465: train_loss -0.974 
2025-03-10 06:59:46.528121: val_loss -0.9201 
2025-03-10 06:59:46.532192: Pseudo dice [np.float32(0.9397)] 
2025-03-10 06:59:46.535247: Epoch time: 82.61 s 
2025-03-10 06:59:46.538285: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-03-10 06:59:47.257227:  
2025-03-10 06:59:47.262295: Epoch 41 
2025-03-10 06:59:47.265874: Current learning rate: 0.00622 
2025-03-10 07:01:09.968910: train_loss -0.9708 
2025-03-10 07:01:09.974922: val_loss -0.9215 
2025-03-10 07:01:09.977931: Pseudo dice [np.float32(0.9403)] 
2025-03-10 07:01:09.981443: Epoch time: 82.71 s 
2025-03-10 07:01:09.983950: Yayy! New best EMA pseudo Dice: 0.9387000203132629 
2025-03-10 07:01:10.678301:  
2025-03-10 07:01:10.684940: Epoch 42 
2025-03-10 07:01:10.688482: Current learning rate: 0.00612 
2025-03-10 07:02:33.394182: train_loss -0.9726 
2025-03-10 07:02:33.400698: val_loss -0.9198 
2025-03-10 07:02:33.403208: Pseudo dice [np.float32(0.9394)] 
2025-03-10 07:02:33.407753: Epoch time: 82.72 s 
2025-03-10 07:02:33.410764: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-03-10 07:02:34.105191:  
2025-03-10 07:02:34.111762: Epoch 43 
2025-03-10 07:02:34.114808: Current learning rate: 0.00603 
2025-03-10 07:03:56.784878: train_loss -0.9721 
2025-03-10 07:03:56.790451: val_loss -0.9186 
2025-03-10 07:03:56.794008: Pseudo dice [np.float32(0.938)] 
2025-03-10 07:03:56.798018: Epoch time: 82.68 s 
2025-03-10 07:03:57.332144:  
2025-03-10 07:03:57.338159: Epoch 44 
2025-03-10 07:03:57.341671: Current learning rate: 0.00593 
2025-03-10 07:05:20.000175: train_loss -0.971 
2025-03-10 07:05:20.005188: val_loss -0.9219 
2025-03-10 07:05:20.009197: Pseudo dice [np.float32(0.9404)] 
2025-03-10 07:05:20.012708: Epoch time: 82.67 s 
2025-03-10 07:05:20.016213: Yayy! New best EMA pseudo Dice: 0.9388999938964844 
2025-03-10 07:05:20.853616:  
2025-03-10 07:05:20.859189: Epoch 45 
2025-03-10 07:05:20.863312: Current learning rate: 0.00584 
2025-03-10 07:06:43.684851: train_loss -0.9721 
2025-03-10 07:06:43.690415: val_loss -0.9208 
2025-03-10 07:06:43.693926: Pseudo dice [np.float32(0.9396)] 
2025-03-10 07:06:43.697936: Epoch time: 82.83 s 
2025-03-10 07:06:43.700442: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-03-10 07:06:44.376883:  
2025-03-10 07:06:44.383463: Epoch 46 
2025-03-10 07:06:44.386005: Current learning rate: 0.00574 
2025-03-10 07:08:07.030842: train_loss -0.9743 
2025-03-10 07:08:07.036908: val_loss -0.9192 
2025-03-10 07:08:07.039940: Pseudo dice [np.float32(0.939)] 
2025-03-10 07:08:07.043974: Epoch time: 82.65 s 
2025-03-10 07:08:07.047006: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-03-10 07:08:07.732681:  
2025-03-10 07:08:07.738196: Epoch 47 
2025-03-10 07:08:07.741707: Current learning rate: 0.00565 
2025-03-10 07:09:30.457484: train_loss -0.9744 
2025-03-10 07:09:30.463312: val_loss -0.9191 
2025-03-10 07:09:30.467325: Pseudo dice [np.float32(0.9394)] 
2025-03-10 07:09:30.470836: Epoch time: 82.73 s 
2025-03-10 07:09:30.473343: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-03-10 07:09:31.164346:  
2025-03-10 07:09:31.170485: Epoch 48 
2025-03-10 07:09:31.173545: Current learning rate: 0.00555 
2025-03-10 07:10:53.836241: train_loss -0.973 
2025-03-10 07:10:53.842599: val_loss -0.9202 
2025-03-10 07:10:53.845783: Pseudo dice [np.float32(0.9401)] 
2025-03-10 07:10:53.849793: Epoch time: 82.67 s 
2025-03-10 07:10:53.852299: Yayy! New best EMA pseudo Dice: 0.9391000270843506 
2025-03-10 07:10:54.541899:  
2025-03-10 07:10:54.546928: Epoch 49 
2025-03-10 07:10:54.550513: Current learning rate: 0.00546 
2025-03-10 07:12:17.253273: train_loss -0.9736 
2025-03-10 07:12:17.260289: val_loss -0.9201 
2025-03-10 07:12:17.264306: Pseudo dice [np.float32(0.9403)] 
2025-03-10 07:12:17.266812: Epoch time: 82.71 s 
2025-03-10 07:12:17.415472: Yayy! New best EMA pseudo Dice: 0.9391999840736389 
2025-03-10 07:12:18.099746:  
2025-03-10 07:12:18.105814: Epoch 50 
2025-03-10 07:12:18.108885: Current learning rate: 0.00536 
2025-03-10 07:13:40.837498: train_loss -0.9751 
2025-03-10 07:13:40.842512: val_loss -0.9213 
2025-03-10 07:13:40.846021: Pseudo dice [np.float32(0.9411)] 
2025-03-10 07:13:40.848529: Epoch time: 82.74 s 
2025-03-10 07:13:40.852540: Yayy! New best EMA pseudo Dice: 0.9394000172615051 
2025-03-10 07:13:41.551682:  
2025-03-10 07:13:41.557240: Epoch 51 
2025-03-10 07:13:41.561296: Current learning rate: 0.00526 
2025-03-10 07:15:04.258744: train_loss -0.9748 
2025-03-10 07:15:04.265259: val_loss -0.9206 
2025-03-10 07:15:04.268768: Pseudo dice [np.float32(0.9407)] 
2025-03-10 07:15:04.272277: Epoch time: 82.71 s 
2025-03-10 07:15:04.275287: Yayy! New best EMA pseudo Dice: 0.9395999908447266 
2025-03-10 07:15:04.958579:  
2025-03-10 07:15:04.964596: Epoch 52 
2025-03-10 07:15:04.967106: Current learning rate: 0.00517 
2025-03-10 07:16:27.605664: train_loss -0.9735 
2025-03-10 07:16:27.612199: val_loss -0.921 
2025-03-10 07:16:27.615710: Pseudo dice [np.float32(0.9409)] 
2025-03-10 07:16:27.618216: Epoch time: 82.65 s 
2025-03-10 07:16:27.621723: Yayy! New best EMA pseudo Dice: 0.9397000074386597 
2025-03-10 07:16:28.309008:  
2025-03-10 07:16:28.314573: Epoch 53 
2025-03-10 07:16:28.317616: Current learning rate: 0.00507 
2025-03-10 07:17:51.071438: train_loss -0.9742 
2025-03-10 07:17:51.076754: val_loss -0.9203 
2025-03-10 07:17:51.080269: Pseudo dice [np.float32(0.9408)] 
2025-03-10 07:17:51.083645: Epoch time: 82.76 s 
2025-03-10 07:17:51.086151: Yayy! New best EMA pseudo Dice: 0.9398000240325928 
2025-03-10 07:17:51.947745:  
2025-03-10 07:17:51.952825: Epoch 54 
2025-03-10 07:17:51.956907: Current learning rate: 0.00497 
2025-03-10 07:19:14.627708: train_loss -0.976 
2025-03-10 07:19:14.632720: val_loss -0.9192 
2025-03-10 07:19:14.636733: Pseudo dice [np.float32(0.9401)] 
2025-03-10 07:19:14.640243: Epoch time: 82.68 s 
2025-03-10 07:19:14.643751: Yayy! New best EMA pseudo Dice: 0.9398000240325928 
2025-03-10 07:19:15.334070:  
2025-03-10 07:19:15.339662: Epoch 55 
2025-03-10 07:19:15.344177: Current learning rate: 0.00487 
2025-03-10 07:20:38.030549: train_loss -0.9742 
2025-03-10 07:20:38.036568: val_loss -0.9186 
2025-03-10 07:20:38.040578: Pseudo dice [np.float32(0.9394)] 
2025-03-10 07:20:38.044088: Epoch time: 82.7 s 
2025-03-10 07:20:38.569628:  
2025-03-10 07:20:38.575278: Epoch 56 
2025-03-10 07:20:38.578350: Current learning rate: 0.00478 
2025-03-10 07:22:01.667199: train_loss -0.975 
2025-03-10 07:22:01.673211: val_loss -0.9196 
2025-03-10 07:22:01.676220: Pseudo dice [np.float32(0.9399)] 
2025-03-10 07:22:01.679730: Epoch time: 83.1 s 
2025-03-10 07:22:02.212276:  
2025-03-10 07:22:02.217838: Epoch 57 
2025-03-10 07:22:02.221888: Current learning rate: 0.00468 
2025-03-10 07:23:24.906344: train_loss -0.9767 
2025-03-10 07:23:24.911926: val_loss -0.92 
2025-03-10 07:23:24.915560: Pseudo dice [np.float32(0.9402)] 
2025-03-10 07:23:24.919124: Epoch time: 82.69 s 
2025-03-10 07:23:24.921862: Yayy! New best EMA pseudo Dice: 0.9398000240325928 
2025-03-10 07:23:25.612361:  
2025-03-10 07:23:25.618457: Epoch 58 
2025-03-10 07:23:25.621527: Current learning rate: 0.00458 
2025-03-10 07:24:48.255319: train_loss -0.9755 
2025-03-10 07:24:48.261835: val_loss -0.9176 
2025-03-10 07:24:48.265345: Pseudo dice [np.float32(0.9395)] 
2025-03-10 07:24:48.268853: Epoch time: 82.64 s 
2025-03-10 07:24:48.816002:  
2025-03-10 07:24:48.821566: Epoch 59 
2025-03-10 07:24:48.825633: Current learning rate: 0.00448 
2025-03-10 07:26:11.566985: train_loss -0.9764 
2025-03-10 07:26:11.572598: val_loss -0.9186 
2025-03-10 07:26:11.576653: Pseudo dice [np.float32(0.9398)] 
2025-03-10 07:26:11.579192: Epoch time: 82.75 s 
2025-03-10 07:26:12.117657:  
2025-03-10 07:26:12.122670: Epoch 60 
2025-03-10 07:26:12.125691: Current learning rate: 0.00438 
2025-03-10 07:27:34.740042: train_loss -0.9764 
2025-03-10 07:27:34.745586: val_loss -0.9189 
2025-03-10 07:27:34.749599: Pseudo dice [np.float32(0.9399)] 
2025-03-10 07:27:34.753109: Epoch time: 82.62 s 
2025-03-10 07:27:35.298018:  
2025-03-10 07:27:35.304080: Epoch 61 
2025-03-10 07:27:35.307158: Current learning rate: 0.00429 
2025-03-10 07:28:58.034369: train_loss -0.977 
2025-03-10 07:28:58.040379: val_loss -0.9199 
2025-03-10 07:28:58.044394: Pseudo dice [np.float32(0.9409)] 
2025-03-10 07:28:58.048403: Epoch time: 82.74 s 
2025-03-10 07:28:58.051913: Yayy! New best EMA pseudo Dice: 0.9398999810218811 
2025-03-10 07:28:58.905150:  
2025-03-10 07:28:58.910712: Epoch 62 
2025-03-10 07:28:58.915270: Current learning rate: 0.00419 
2025-03-10 07:30:21.644943: train_loss -0.9762 
2025-03-10 07:30:21.652462: val_loss -0.9193 
2025-03-10 07:30:21.656475: Pseudo dice [np.float32(0.9406)] 
2025-03-10 07:30:21.660986: Epoch time: 82.74 s 
2025-03-10 07:30:21.663996: Yayy! New best EMA pseudo Dice: 0.9399999976158142 
2025-03-10 07:30:22.370576:  
2025-03-10 07:30:22.376683: Epoch 63 
2025-03-10 07:30:22.379803: Current learning rate: 0.00409 
2025-03-10 07:31:45.120294: train_loss -0.9768 
2025-03-10 07:31:45.126807: val_loss -0.9189 
2025-03-10 07:31:45.131317: Pseudo dice [np.float32(0.9404)] 
2025-03-10 07:31:45.134327: Epoch time: 82.75 s 
2025-03-10 07:31:45.137838: Yayy! New best EMA pseudo Dice: 0.9399999976158142 
2025-03-10 07:31:45.844081:  
2025-03-10 07:31:45.850662: Epoch 64 
2025-03-10 07:31:45.854702: Current learning rate: 0.00399 
2025-03-10 07:33:08.474858: train_loss -0.9777 
2025-03-10 07:33:08.480448: val_loss -0.9185 
2025-03-10 07:33:08.484959: Pseudo dice [np.float32(0.9398)] 
2025-03-10 07:33:08.487968: Epoch time: 82.63 s 
2025-03-10 07:33:09.033256:  
2025-03-10 07:33:09.039325: Epoch 65 
2025-03-10 07:33:09.043926: Current learning rate: 0.00389 
2025-03-10 07:34:31.773746: train_loss -0.9774 
2025-03-10 07:34:31.781326: val_loss -0.919 
2025-03-10 07:34:31.784931: Pseudo dice [np.float32(0.9405)] 
2025-03-10 07:34:31.788529: Epoch time: 82.74 s 
2025-03-10 07:34:31.791566: Yayy! New best EMA pseudo Dice: 0.9401000142097473 
2025-03-10 07:34:32.489884:  
2025-03-10 07:34:32.495926: Epoch 66 
2025-03-10 07:34:32.499993: Current learning rate: 0.00379 
2025-03-10 07:35:55.195062: train_loss -0.9766 
2025-03-10 07:35:55.201651: val_loss -0.9188 
2025-03-10 07:35:55.206172: Pseudo dice [np.float32(0.9403)] 
2025-03-10 07:35:55.208871: Epoch time: 82.71 s 
2025-03-10 07:35:55.212907: Yayy! New best EMA pseudo Dice: 0.9401000142097473 
2025-03-10 07:35:55.917044:  
2025-03-10 07:35:55.923062: Epoch 67 
2025-03-10 07:35:55.927077: Current learning rate: 0.00369 
2025-03-10 07:37:18.597763: train_loss -0.974 
2025-03-10 07:37:18.603353: val_loss -0.9194 
2025-03-10 07:37:18.608502: Pseudo dice [np.float32(0.9402)] 
2025-03-10 07:37:18.613107: Epoch time: 82.68 s 
2025-03-10 07:37:18.617125: Yayy! New best EMA pseudo Dice: 0.9401000142097473 
2025-03-10 07:37:19.323324:  
2025-03-10 07:37:19.330467: Epoch 68 
2025-03-10 07:37:19.333973: Current learning rate: 0.00359 
2025-03-10 07:38:41.987575: train_loss -0.976 
2025-03-10 07:38:41.993593: val_loss -0.9203 
2025-03-10 07:38:41.997605: Pseudo dice [np.float32(0.9409)] 
2025-03-10 07:38:42.001117: Epoch time: 82.66 s 
2025-03-10 07:38:42.005128: Yayy! New best EMA pseudo Dice: 0.9401999711990356 
2025-03-10 07:38:42.720180:  
2025-03-10 07:38:42.725196: Epoch 69 
2025-03-10 07:38:42.728709: Current learning rate: 0.00349 
2025-03-10 07:40:05.412870: train_loss -0.9764 
2025-03-10 07:40:05.418943: val_loss -0.9192 
2025-03-10 07:40:05.423457: Pseudo dice [np.float32(0.9405)] 
2025-03-10 07:40:05.426468: Epoch time: 82.69 s 
2025-03-10 07:40:05.429984: Yayy! New best EMA pseudo Dice: 0.9401999711990356 
2025-03-10 07:40:06.275372:  
2025-03-10 07:40:06.281891: Epoch 70 
2025-03-10 07:40:06.285898: Current learning rate: 0.00338 
2025-03-10 07:41:29.060870: train_loss -0.9772 
2025-03-10 07:41:29.066389: val_loss -0.9208 
2025-03-10 07:41:29.070899: Pseudo dice [np.float32(0.9414)] 
2025-03-10 07:41:29.074919: Epoch time: 82.79 s 
2025-03-10 07:41:29.078427: Yayy! New best EMA pseudo Dice: 0.9402999877929688 
2025-03-10 07:41:29.787675:  
2025-03-10 07:41:29.793239: Epoch 71 
2025-03-10 07:41:29.800347: Current learning rate: 0.00328 
2025-03-10 07:42:52.457506: train_loss -0.9772 
2025-03-10 07:42:52.464051: val_loss -0.9177 
2025-03-10 07:42:52.468068: Pseudo dice [np.float32(0.9392)] 
2025-03-10 07:42:52.471581: Epoch time: 82.67 s 
2025-03-10 07:42:53.025332:  
2025-03-10 07:42:53.031359: Epoch 72 
2025-03-10 07:42:53.035377: Current learning rate: 0.00318 
2025-03-10 07:44:15.683249: train_loss -0.9776 
2025-03-10 07:44:15.689777: val_loss -0.9202 
2025-03-10 07:44:15.693793: Pseudo dice [np.float32(0.9412)] 
2025-03-10 07:44:15.697309: Epoch time: 82.66 s 
2025-03-10 07:44:16.243522:  
2025-03-10 07:44:16.249635: Epoch 73 
2025-03-10 07:44:16.254155: Current learning rate: 0.00308 
2025-03-10 07:45:38.916134: train_loss -0.9764 
2025-03-10 07:45:38.924667: val_loss -0.9202 
2025-03-10 07:45:38.928683: Pseudo dice [np.float32(0.9415)] 
2025-03-10 07:45:38.932200: Epoch time: 82.67 s 
2025-03-10 07:45:38.935713: Yayy! New best EMA pseudo Dice: 0.9404000043869019 
2025-03-10 07:45:39.644556:  
2025-03-10 07:45:39.651665: Epoch 74 
2025-03-10 07:45:39.655674: Current learning rate: 0.00297 
2025-03-10 07:47:02.320638: train_loss -0.9775 
2025-03-10 07:47:02.326655: val_loss -0.9192 
2025-03-10 07:47:02.330667: Pseudo dice [np.float32(0.9406)] 
2025-03-10 07:47:02.334176: Epoch time: 82.68 s 
2025-03-10 07:47:02.337683: Yayy! New best EMA pseudo Dice: 0.9404000043869019 
2025-03-10 07:47:03.052618:  
2025-03-10 07:47:03.058686: Epoch 75 
2025-03-10 07:47:03.062279: Current learning rate: 0.00287 
2025-03-10 07:48:25.725372: train_loss -0.9784 
2025-03-10 07:48:25.731386: val_loss -0.9197 
2025-03-10 07:48:25.735400: Pseudo dice [np.float32(0.9409)] 
2025-03-10 07:48:25.738911: Epoch time: 82.67 s 
2025-03-10 07:48:25.742417: Yayy! New best EMA pseudo Dice: 0.940500020980835 
2025-03-10 07:48:26.462831:  
2025-03-10 07:48:26.468372: Epoch 76 
2025-03-10 07:48:26.471882: Current learning rate: 0.00277 
2025-03-10 07:49:49.112087: train_loss -0.9782 
2025-03-10 07:49:49.118105: val_loss -0.9189 
2025-03-10 07:49:49.122118: Pseudo dice [np.float32(0.9408)] 
2025-03-10 07:49:49.125629: Epoch time: 82.65 s 
2025-03-10 07:49:49.129636: Yayy! New best EMA pseudo Dice: 0.940500020980835 
2025-03-10 07:49:49.838087:  
2025-03-10 07:49:49.844120: Epoch 77 
2025-03-10 07:49:49.848184: Current learning rate: 0.00266 
2025-03-10 07:51:12.613017: train_loss -0.977 
2025-03-10 07:51:12.619030: val_loss -0.9184 
2025-03-10 07:51:12.623044: Pseudo dice [np.float32(0.9402)] 
2025-03-10 07:51:12.626554: Epoch time: 82.78 s 
2025-03-10 07:51:13.333991:  
2025-03-10 07:51:13.339047: Epoch 78 
2025-03-10 07:51:13.343129: Current learning rate: 0.00256 
2025-03-10 07:52:36.060923: train_loss -0.9777 
2025-03-10 07:52:36.065434: val_loss -0.9199 
2025-03-10 07:52:36.068443: Pseudo dice [np.float32(0.9415)] 
2025-03-10 07:52:36.071954: Epoch time: 82.73 s 
2025-03-10 07:52:36.075965: Yayy! New best EMA pseudo Dice: 0.9405999779701233 
2025-03-10 07:52:36.796779:  
2025-03-10 07:52:36.802335: Epoch 79 
2025-03-10 07:52:36.806383: Current learning rate: 0.00245 
2025-03-10 07:53:59.507234: train_loss -0.9783 
2025-03-10 07:53:59.513393: val_loss -0.9174 
2025-03-10 07:53:59.517470: Pseudo dice [np.float32(0.9398)] 
2025-03-10 07:53:59.521014: Epoch time: 82.71 s 
2025-03-10 07:54:00.084092:  
2025-03-10 07:54:00.089606: Epoch 80 
2025-03-10 07:54:00.093118: Current learning rate: 0.00235 
2025-03-10 07:55:22.832527: train_loss -0.9771 
2025-03-10 07:55:22.838538: val_loss -0.9196 
2025-03-10 07:55:22.842554: Pseudo dice [np.float32(0.9411)] 
2025-03-10 07:55:22.846060: Epoch time: 82.75 s 
2025-03-10 07:55:23.412190:  
2025-03-10 07:55:23.417743: Epoch 81 
2025-03-10 07:55:23.421339: Current learning rate: 0.00224 
2025-03-10 07:56:46.183830: train_loss -0.9773 
2025-03-10 07:56:46.190850: val_loss -0.9185 
2025-03-10 07:56:46.194865: Pseudo dice [np.float32(0.9404)] 
2025-03-10 07:56:46.198371: Epoch time: 82.77 s 
2025-03-10 07:56:46.768929:  
2025-03-10 07:56:46.775952: Epoch 82 
2025-03-10 07:56:46.781506: Current learning rate: 0.00214 
2025-03-10 07:58:09.510260: train_loss -0.9789 
2025-03-10 07:58:09.516854: val_loss -0.918 
2025-03-10 07:58:09.520936: Pseudo dice [np.float32(0.9402)] 
2025-03-10 07:58:09.524484: Epoch time: 82.74 s 
2025-03-10 07:58:10.055257:  
2025-03-10 07:58:10.061341: Epoch 83 
2025-03-10 07:58:10.065456: Current learning rate: 0.00203 
2025-03-10 07:59:32.835144: train_loss -0.9788 
2025-03-10 07:59:32.843340: val_loss -0.919 
2025-03-10 07:59:32.849391: Pseudo dice [np.float32(0.941)] 
2025-03-10 07:59:32.852947: Epoch time: 82.78 s 
2025-03-10 07:59:33.389424:  
2025-03-10 07:59:33.395995: Epoch 84 
2025-03-10 07:59:33.400007: Current learning rate: 0.00192 
2025-03-10 08:00:56.109295: train_loss -0.9786 
2025-03-10 08:00:56.115809: val_loss -0.9177 
2025-03-10 08:00:56.119316: Pseudo dice [np.float32(0.9401)] 
2025-03-10 08:00:56.123327: Epoch time: 82.72 s 
2025-03-10 08:00:56.664380:  
2025-03-10 08:00:56.670416: Epoch 85 
2025-03-10 08:00:56.674475: Current learning rate: 0.00181 
2025-03-10 08:02:19.373428: train_loss -0.9784 
2025-03-10 08:02:19.379996: val_loss -0.9151 
2025-03-10 08:02:19.384511: Pseudo dice [np.float32(0.9387)] 
2025-03-10 08:02:19.387522: Epoch time: 82.71 s 
2025-03-10 08:02:20.056200:  
2025-03-10 08:02:20.061725: Epoch 86 
2025-03-10 08:02:20.066744: Current learning rate: 0.0017 
2025-03-10 08:03:42.748131: train_loss -0.9782 
2025-03-10 08:03:42.753145: val_loss -0.9179 
2025-03-10 08:03:42.756654: Pseudo dice [np.float32(0.9402)] 
2025-03-10 08:03:42.760666: Epoch time: 82.69 s 
2025-03-10 08:03:43.281545:  
2025-03-10 08:03:43.288070: Epoch 87 
2025-03-10 08:03:43.291575: Current learning rate: 0.00159 
2025-03-10 08:05:06.058772: train_loss -0.9781 
2025-03-10 08:05:06.064897: val_loss -0.9184 
2025-03-10 08:05:06.069578: Pseudo dice [np.float32(0.9405)] 
2025-03-10 08:05:06.073723: Epoch time: 82.78 s 
2025-03-10 08:05:06.591433:  
2025-03-10 08:05:06.598496: Epoch 88 
2025-03-10 08:05:06.602160: Current learning rate: 0.00148 
2025-03-10 08:06:29.302948: train_loss -0.979 
2025-03-10 08:06:29.308964: val_loss -0.9186 
2025-03-10 08:06:29.314482: Pseudo dice [np.float32(0.9405)] 
2025-03-10 08:06:29.317998: Epoch time: 82.71 s 
2025-03-10 08:06:29.840666:  
2025-03-10 08:06:29.845681: Epoch 89 
2025-03-10 08:06:29.850197: Current learning rate: 0.00137 
2025-03-10 08:07:52.555012: train_loss -0.9793 
2025-03-10 08:07:52.561529: val_loss -0.919 
2025-03-10 08:07:52.566040: Pseudo dice [np.float32(0.9413)] 
2025-03-10 08:07:52.570059: Epoch time: 82.72 s 
2025-03-10 08:07:53.096308:  
2025-03-10 08:07:53.102397: Epoch 90 
2025-03-10 08:07:53.107411: Current learning rate: 0.00126 
2025-03-10 08:09:15.852441: train_loss -0.979 
2025-03-10 08:09:15.859520: val_loss -0.9177 
2025-03-10 08:09:15.862583: Pseudo dice [np.float32(0.9404)] 
2025-03-10 08:09:15.866615: Epoch time: 82.76 s 
2025-03-10 08:09:16.386330:  
2025-03-10 08:09:16.392963: Epoch 91 
2025-03-10 08:09:16.396537: Current learning rate: 0.00115 
2025-03-10 08:10:39.103689: train_loss -0.9791 
2025-03-10 08:10:39.111381: val_loss -0.9181 
2025-03-10 08:10:39.114456: Pseudo dice [np.float32(0.9405)] 
2025-03-10 08:10:39.118525: Epoch time: 82.72 s 
2025-03-10 08:10:39.642293:  
2025-03-10 08:10:39.647859: Epoch 92 
2025-03-10 08:10:39.652395: Current learning rate: 0.00103 
2025-03-10 08:12:02.338576: train_loss -0.9788 
2025-03-10 08:12:02.345592: val_loss -0.9165 
2025-03-10 08:12:02.349608: Pseudo dice [np.float32(0.9397)] 
2025-03-10 08:12:02.353619: Epoch time: 82.7 s 
2025-03-10 08:12:02.871943:  
2025-03-10 08:12:02.878567: Epoch 93 
2025-03-10 08:12:02.881666: Current learning rate: 0.00091 
2025-03-10 08:13:25.679587: train_loss -0.98 
2025-03-10 08:13:25.686606: val_loss -0.9169 
2025-03-10 08:13:25.690625: Pseudo dice [np.float32(0.94)] 
2025-03-10 08:13:25.694131: Epoch time: 82.81 s 
2025-03-10 08:13:26.214160:  
2025-03-10 08:13:26.219678: Epoch 94 
2025-03-10 08:13:26.224190: Current learning rate: 0.00079 
2025-03-10 08:14:48.952182: train_loss -0.9792 
2025-03-10 08:14:48.959199: val_loss -0.9162 
2025-03-10 08:14:48.963215: Pseudo dice [np.float32(0.9396)] 
2025-03-10 08:14:48.967226: Epoch time: 82.74 s 
2025-03-10 08:14:49.642566:  
2025-03-10 08:14:49.648644: Epoch 95 
2025-03-10 08:14:49.652718: Current learning rate: 0.00067 
2025-03-10 08:16:12.347115: train_loss -0.9792 
2025-03-10 08:16:12.352702: val_loss -0.9186 
2025-03-10 08:16:12.357246: Pseudo dice [np.float32(0.941)] 
2025-03-10 08:16:12.360752: Epoch time: 82.7 s 
2025-03-10 08:16:12.882800:  
2025-03-10 08:16:12.888317: Epoch 96 
2025-03-10 08:16:12.892830: Current learning rate: 0.00055 
2025-03-10 08:17:35.556764: train_loss -0.9792 
2025-03-10 08:17:35.562787: val_loss -0.917 
2025-03-10 08:17:35.566809: Pseudo dice [np.float32(0.9397)] 
2025-03-10 08:17:35.570825: Epoch time: 82.67 s 
2025-03-10 08:17:36.099793:  
2025-03-10 08:17:36.105383: Epoch 97 
2025-03-10 08:17:36.110507: Current learning rate: 0.00043 
2025-03-10 08:18:58.896176: train_loss -0.9796 
2025-03-10 08:18:58.902834: val_loss -0.9185 
2025-03-10 08:18:58.906847: Pseudo dice [np.float32(0.9409)] 
2025-03-10 08:18:58.910358: Epoch time: 82.8 s 
2025-03-10 08:18:59.443920:  
2025-03-10 08:18:59.449488: Epoch 98 
2025-03-10 08:18:59.454592: Current learning rate: 0.0003 
2025-03-10 08:20:22.165446: train_loss -0.9793 
2025-03-10 08:20:22.171972: val_loss -0.9181 
2025-03-10 08:20:22.175488: Pseudo dice [np.float32(0.9406)] 
2025-03-10 08:20:22.179507: Epoch time: 82.72 s 
2025-03-10 08:20:22.718650:  
2025-03-10 08:20:22.725718: Epoch 99 
2025-03-10 08:20:22.729796: Current learning rate: 0.00016 
2025-03-10 08:21:45.887269: train_loss -0.9803 
2025-03-10 08:21:45.893796: val_loss -0.917 
2025-03-10 08:21:45.897311: Pseudo dice [np.float32(0.94)] 
2025-03-10 08:21:45.901331: Epoch time: 83.17 s 
2025-03-10 08:21:46.672786: Training done. 
2025-03-10 08:21:46.702786: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-10 08:21:46.713786: The split file contains 5 splits. 
2025-03-10 08:21:46.720786: Desired fold for training: 0 
2025-03-10 08:21:46.726787: This split has 16 training and 4 validation cases. 
2025-03-10 08:21:46.732790: predicting la_007 
2025-03-10 08:21:46.740790: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2025-03-10 08:21:52.715892: predicting la_016 
2025-03-10 08:21:52.727889: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2025-03-10 08:21:55.045928: predicting la_021 
2025-03-10 08:21:55.054439: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2025-03-10 08:21:57.381621: predicting la_024 
2025-03-10 08:21:57.393621: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2025-03-10 08:22:06.474752: Validation complete 
2025-03-10 08:22:06.481755: Mean Validation Dice:  0.8690197727020984 
