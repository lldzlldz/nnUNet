
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-13 07:14:50.458523: do_dummy_2d_data_aug: False 
2025-03-13 07:14:50.459523: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-13 07:14:50.467934: The split file contains 5 splits. 
2025-03-13 07:14:50.469933: Desired fold for training: 0 
2025-03-13 07:14:50.472931: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2025-03-13 07:14:58.599349: unpacking dataset... 
2025-03-13 07:14:59.240220: unpacking done... 
2025-03-13 07:15:02.500491:  
2025-03-13 07:15:02.505500: Epoch 0 
2025-03-13 07:15:02.509509: Current learning rate: 0.01 
2025-03-13 07:15:49.238376: train_loss -0.5308 
2025-03-13 07:15:49.244889: val_loss -0.8274 
2025-03-13 07:15:49.248396: Pseudo dice [np.float32(0.8696)] 
2025-03-13 07:15:49.250901: Epoch time: 46.74 s 
2025-03-13 07:15:49.254913: Yayy! New best EMA pseudo Dice: 0.8695999979972839 
2025-03-13 07:15:49.843401:  
2025-03-13 07:15:49.848413: Epoch 1 
2025-03-13 07:15:49.851920: Current learning rate: 0.00991 
2025-03-13 07:16:32.179738: train_loss -0.8039 
2025-03-13 07:16:32.185266: val_loss -0.8439 
2025-03-13 07:16:32.189276: Pseudo dice [np.float32(0.8806)] 
2025-03-13 07:16:32.192791: Epoch time: 42.34 s 
2025-03-13 07:16:32.195295: Yayy! New best EMA pseudo Dice: 0.8707000017166138 
2025-03-13 07:16:32.853134:  
2025-03-13 07:16:32.857145: Epoch 2 
2025-03-13 07:16:32.860650: Current learning rate: 0.00982 
2025-03-13 07:17:15.192165: train_loss -0.8391 
2025-03-13 07:17:15.198239: val_loss -0.8772 
2025-03-13 07:17:15.200778: Pseudo dice [np.float32(0.9073)] 
2025-03-13 07:17:15.204288: Epoch time: 42.34 s 
2025-03-13 07:17:15.207798: Yayy! New best EMA pseudo Dice: 0.8744000196456909 
2025-03-13 07:17:15.914025:  
2025-03-13 07:17:15.920071: Epoch 3 
2025-03-13 07:17:15.923091: Current learning rate: 0.00973 
2025-03-13 07:17:58.214471: train_loss -0.8548 
2025-03-13 07:17:58.221534: val_loss -0.8827 
2025-03-13 07:17:58.224040: Pseudo dice [np.float32(0.9107)] 
2025-03-13 07:17:58.227549: Epoch time: 42.3 s 
2025-03-13 07:17:58.231055: Yayy! New best EMA pseudo Dice: 0.878000020980835 
2025-03-13 07:17:58.901139:  
2025-03-13 07:17:58.906651: Epoch 4 
2025-03-13 07:17:58.910159: Current learning rate: 0.00964 
2025-03-13 07:18:41.197385: train_loss -0.8696 
2025-03-13 07:18:41.203410: val_loss -0.8924 
2025-03-13 07:18:41.206914: Pseudo dice [np.float32(0.9198)] 
2025-03-13 07:18:41.209924: Epoch time: 42.3 s 
2025-03-13 07:18:41.212428: Yayy! New best EMA pseudo Dice: 0.8822000026702881 
2025-03-13 07:18:42.014830:  
2025-03-13 07:18:42.019961: Epoch 5 
2025-03-13 07:18:42.023526: Current learning rate: 0.00955 
2025-03-13 07:19:24.274161: train_loss -0.8786 
2025-03-13 07:19:24.279734: val_loss -0.8942 
2025-03-13 07:19:24.283294: Pseudo dice [np.float32(0.9185)] 
2025-03-13 07:19:24.286328: Epoch time: 42.26 s 
2025-03-13 07:19:24.289895: Yayy! New best EMA pseudo Dice: 0.8858000040054321 
2025-03-13 07:19:24.948132:  
2025-03-13 07:19:24.953680: Epoch 6 
2025-03-13 07:19:24.958237: Current learning rate: 0.00946 
2025-03-13 07:20:07.223222: train_loss -0.8878 
2025-03-13 07:20:07.228734: val_loss -0.8965 
2025-03-13 07:20:07.232243: Pseudo dice [np.float32(0.9197)] 
2025-03-13 07:20:07.235748: Epoch time: 42.28 s 
2025-03-13 07:20:07.238757: Yayy! New best EMA pseudo Dice: 0.88919997215271 
2025-03-13 07:20:07.914041:  
2025-03-13 07:20:07.920177: Epoch 7 
2025-03-13 07:20:07.923208: Current learning rate: 0.00937 
2025-03-13 07:20:50.236545: train_loss -0.8892 
2025-03-13 07:20:50.242076: val_loss -0.8939 
2025-03-13 07:20:50.245102: Pseudo dice [np.float32(0.9176)] 
2025-03-13 07:20:50.247669: Epoch time: 42.32 s 
2025-03-13 07:20:50.250797: Yayy! New best EMA pseudo Dice: 0.8920000195503235 
2025-03-13 07:20:50.933674:  
2025-03-13 07:20:50.939786: Epoch 8 
2025-03-13 07:20:50.942366: Current learning rate: 0.00928 
2025-03-13 07:21:33.247013: train_loss -0.8987 
2025-03-13 07:21:33.253526: val_loss -0.901 
2025-03-13 07:21:33.256031: Pseudo dice [np.float32(0.9244)] 
2025-03-13 07:21:33.259547: Epoch time: 42.31 s 
2025-03-13 07:21:33.262052: Yayy! New best EMA pseudo Dice: 0.8952999711036682 
2025-03-13 07:21:33.941970:  
2025-03-13 07:21:33.946990: Epoch 9 
2025-03-13 07:21:33.949355: Current learning rate: 0.00919 
2025-03-13 07:22:16.247919: train_loss -0.8908 
2025-03-13 07:22:16.253467: val_loss -0.902 
2025-03-13 07:22:16.256484: Pseudo dice [np.float32(0.9237)] 
2025-03-13 07:22:16.259992: Epoch time: 42.31 s 
2025-03-13 07:22:16.262496: Yayy! New best EMA pseudo Dice: 0.8981000185012817 
2025-03-13 07:22:16.916203:  
2025-03-13 07:22:16.922250: Epoch 10 
2025-03-13 07:22:16.925347: Current learning rate: 0.0091 
2025-03-13 07:22:59.210922: train_loss -0.8991 
2025-03-13 07:22:59.216435: val_loss -0.9019 
2025-03-13 07:22:59.218940: Pseudo dice [np.float32(0.9239)] 
2025-03-13 07:22:59.222447: Epoch time: 42.3 s 
2025-03-13 07:22:59.226455: Yayy! New best EMA pseudo Dice: 0.9006999731063843 
2025-03-13 07:22:59.894661:  
2025-03-13 07:22:59.900173: Epoch 11 
2025-03-13 07:22:59.903684: Current learning rate: 0.009 
2025-03-13 07:23:42.203790: train_loss -0.9028 
2025-03-13 07:23:42.209835: val_loss -0.9029 
2025-03-13 07:23:42.212860: Pseudo dice [np.float32(0.9229)] 
2025-03-13 07:23:42.216406: Epoch time: 42.31 s 
2025-03-13 07:23:42.219447: Yayy! New best EMA pseudo Dice: 0.902899980545044 
2025-03-13 07:23:42.883553:  
2025-03-13 07:23:42.888563: Epoch 12 
2025-03-13 07:23:42.892070: Current learning rate: 0.00891 
2025-03-13 07:24:25.188331: train_loss -0.8936 
2025-03-13 07:24:25.193882: val_loss -0.9013 
2025-03-13 07:24:25.197389: Pseudo dice [np.float32(0.922)] 
2025-03-13 07:24:25.199896: Epoch time: 42.31 s 
2025-03-13 07:24:25.203904: Yayy! New best EMA pseudo Dice: 0.9047999978065491 
2025-03-13 07:24:26.003158:  
2025-03-13 07:24:26.008669: Epoch 13 
2025-03-13 07:24:26.011176: Current learning rate: 0.00882 
2025-03-13 07:25:08.331923: train_loss -0.9087 
2025-03-13 07:25:08.337506: val_loss -0.9122 
2025-03-13 07:25:08.340522: Pseudo dice [np.float32(0.932)] 
2025-03-13 07:25:08.344383: Epoch time: 42.33 s 
2025-03-13 07:25:08.346905: Yayy! New best EMA pseudo Dice: 0.9075000286102295 
2025-03-13 07:25:09.029611:  
2025-03-13 07:25:09.035729: Epoch 14 
2025-03-13 07:25:09.038805: Current learning rate: 0.00873 
2025-03-13 07:25:51.335491: train_loss -0.907 
2025-03-13 07:25:51.341509: val_loss -0.9095 
2025-03-13 07:25:51.345019: Pseudo dice [np.float32(0.9301)] 
2025-03-13 07:25:51.348027: Epoch time: 42.31 s 
2025-03-13 07:25:51.350536: Yayy! New best EMA pseudo Dice: 0.9097999930381775 
2025-03-13 07:25:52.032771:  
2025-03-13 07:25:52.038347: Epoch 15 
2025-03-13 07:25:52.040877: Current learning rate: 0.00864 
2025-03-13 07:26:34.329554: train_loss -0.9099 
2025-03-13 07:26:34.336082: val_loss -0.9023 
2025-03-13 07:26:34.339089: Pseudo dice [np.float32(0.9211)] 
2025-03-13 07:26:34.342597: Epoch time: 42.3 s 
2025-03-13 07:26:34.345102: Yayy! New best EMA pseudo Dice: 0.9108999967575073 
2025-03-13 07:26:35.038197:  
2025-03-13 07:26:35.043207: Epoch 16 
2025-03-13 07:26:35.046216: Current learning rate: 0.00855 
2025-03-13 07:27:17.307897: train_loss -0.9158 
2025-03-13 07:27:17.313595: val_loss -0.9127 
2025-03-13 07:27:17.317098: Pseudo dice [np.float32(0.931)] 
2025-03-13 07:27:17.320602: Epoch time: 42.27 s 
2025-03-13 07:27:17.323612: Yayy! New best EMA pseudo Dice: 0.9128999710083008 
2025-03-13 07:27:18.017261:  
2025-03-13 07:27:18.022797: Epoch 17 
2025-03-13 07:27:18.026866: Current learning rate: 0.00846 
2025-03-13 07:28:00.299563: train_loss -0.9205 
2025-03-13 07:28:00.306110: val_loss -0.9129 
2025-03-13 07:28:00.310132: Pseudo dice [np.float32(0.9312)] 
2025-03-13 07:28:00.313161: Epoch time: 42.28 s 
2025-03-13 07:28:00.316196: Yayy! New best EMA pseudo Dice: 0.9147999882698059 
2025-03-13 07:28:01.009012:  
2025-03-13 07:28:01.014570: Epoch 18 
2025-03-13 07:28:01.020160: Current learning rate: 0.00836 
2025-03-13 07:28:43.332112: train_loss -0.909 
2025-03-13 07:28:43.337624: val_loss -0.9095 
2025-03-13 07:28:43.341132: Pseudo dice [np.float32(0.9273)] 
2025-03-13 07:28:43.343642: Epoch time: 42.32 s 
2025-03-13 07:28:43.347147: Yayy! New best EMA pseudo Dice: 0.9160000085830688 
2025-03-13 07:28:44.031466:  
2025-03-13 07:28:44.038058: Epoch 19 
2025-03-13 07:28:44.040607: Current learning rate: 0.00827 
2025-03-13 07:29:26.356784: train_loss -0.9126 
2025-03-13 07:29:26.362357: val_loss -0.9069 
2025-03-13 07:29:26.366503: Pseudo dice [np.float32(0.9261)] 
2025-03-13 07:29:26.369543: Epoch time: 42.33 s 
2025-03-13 07:29:26.372578: Yayy! New best EMA pseudo Dice: 0.9169999957084656 
2025-03-13 07:29:27.056451:  
2025-03-13 07:29:27.062023: Epoch 20 
2025-03-13 07:29:27.064553: Current learning rate: 0.00818 
2025-03-13 07:30:09.363453: train_loss -0.9099 
2025-03-13 07:30:09.369018: val_loss -0.9074 
2025-03-13 07:30:09.373107: Pseudo dice [np.float32(0.9251)] 
2025-03-13 07:30:09.376161: Epoch time: 42.31 s 
2025-03-13 07:30:09.379187: Yayy! New best EMA pseudo Dice: 0.9178000092506409 
2025-03-13 07:30:10.229356:  
2025-03-13 07:30:10.234915: Epoch 21 
2025-03-13 07:30:10.237443: Current learning rate: 0.00809 
2025-03-13 07:30:52.523325: train_loss -0.9228 
2025-03-13 07:30:52.529345: val_loss -0.9162 
2025-03-13 07:30:52.532851: Pseudo dice [np.float32(0.9323)] 
2025-03-13 07:30:52.535859: Epoch time: 42.29 s 
2025-03-13 07:30:52.539367: Yayy! New best EMA pseudo Dice: 0.9193000197410583 
2025-03-13 07:30:53.206128:  
2025-03-13 07:30:53.212204: Epoch 22 
2025-03-13 07:30:53.215783: Current learning rate: 0.008 
2025-03-13 07:31:35.505963: train_loss -0.9273 
2025-03-13 07:31:35.512066: val_loss -0.9177 
2025-03-13 07:31:35.517172: Pseudo dice [np.float32(0.934)] 
2025-03-13 07:31:35.521210: Epoch time: 42.3 s 
2025-03-13 07:31:35.524765: Yayy! New best EMA pseudo Dice: 0.920799970626831 
2025-03-13 07:31:36.187896:  
2025-03-13 07:31:36.193468: Epoch 23 
2025-03-13 07:31:36.196097: Current learning rate: 0.0079 
2025-03-13 07:32:18.491298: train_loss -0.9297 
2025-03-13 07:32:18.497409: val_loss -0.9185 
2025-03-13 07:32:18.500927: Pseudo dice [np.float32(0.935)] 
2025-03-13 07:32:18.503484: Epoch time: 42.3 s 
2025-03-13 07:32:18.507571: Yayy! New best EMA pseudo Dice: 0.9222000241279602 
2025-03-13 07:32:19.167140:  
2025-03-13 07:32:19.171653: Epoch 24 
2025-03-13 07:32:19.175155: Current learning rate: 0.00781 
2025-03-13 07:33:01.465352: train_loss -0.9277 
2025-03-13 07:33:01.473032: val_loss -0.919 
2025-03-13 07:33:01.476080: Pseudo dice [np.float32(0.9358)] 
2025-03-13 07:33:01.479619: Epoch time: 42.3 s 
2025-03-13 07:33:01.482670: Yayy! New best EMA pseudo Dice: 0.9235000014305115 
2025-03-13 07:33:02.223417:  
2025-03-13 07:33:02.228929: Epoch 25 
2025-03-13 07:33:02.232436: Current learning rate: 0.00772 
2025-03-13 07:33:44.522668: train_loss -0.9272 
2025-03-13 07:33:44.528228: val_loss -0.919 
2025-03-13 07:33:44.532763: Pseudo dice [np.float32(0.9351)] 
2025-03-13 07:33:44.536272: Epoch time: 42.3 s 
2025-03-13 07:33:44.538776: Yayy! New best EMA pseudo Dice: 0.9247000217437744 
2025-03-13 07:33:45.205994:  
2025-03-13 07:33:45.211539: Epoch 26 
2025-03-13 07:33:45.215599: Current learning rate: 0.00763 
2025-03-13 07:34:27.544823: train_loss -0.9267 
2025-03-13 07:34:27.551082: val_loss -0.9183 
2025-03-13 07:34:27.554585: Pseudo dice [np.float32(0.9345)] 
2025-03-13 07:34:27.557593: Epoch time: 42.34 s 
2025-03-13 07:34:27.560099: Yayy! New best EMA pseudo Dice: 0.9257000088691711 
2025-03-13 07:34:28.216965:  
2025-03-13 07:34:28.220995: Epoch 27 
2025-03-13 07:34:28.224536: Current learning rate: 0.00753 
2025-03-13 07:35:10.505125: train_loss -0.9269 
2025-03-13 07:35:10.510728: val_loss -0.9197 
2025-03-13 07:35:10.514243: Pseudo dice [np.float32(0.9356)] 
2025-03-13 07:35:10.517319: Epoch time: 42.29 s 
2025-03-13 07:35:10.520829: Yayy! New best EMA pseudo Dice: 0.9266999959945679 
2025-03-13 07:35:11.187870:  
2025-03-13 07:35:11.193925: Epoch 28 
2025-03-13 07:35:11.198512: Current learning rate: 0.00744 
2025-03-13 07:35:53.513752: train_loss -0.9352 
2025-03-13 07:35:53.519302: val_loss -0.9216 
2025-03-13 07:35:53.522346: Pseudo dice [np.float32(0.9376)] 
2025-03-13 07:35:53.525427: Epoch time: 42.33 s 
2025-03-13 07:35:53.528941: Yayy! New best EMA pseudo Dice: 0.9277999997138977 
2025-03-13 07:35:54.335852:  
2025-03-13 07:35:54.341932: Epoch 29 
2025-03-13 07:35:54.345439: Current learning rate: 0.00735 
2025-03-13 07:36:36.641649: train_loss -0.9373 
2025-03-13 07:36:36.647206: val_loss -0.9191 
2025-03-13 07:36:36.651742: Pseudo dice [np.float32(0.9353)] 
2025-03-13 07:36:36.655251: Epoch time: 42.31 s 
2025-03-13 07:36:36.658758: Yayy! New best EMA pseudo Dice: 0.9284999966621399 
2025-03-13 07:36:37.332670:  
2025-03-13 07:36:37.337177: Epoch 30 
2025-03-13 07:36:37.340185: Current learning rate: 0.00725 
2025-03-13 07:37:19.647683: train_loss -0.9372 
2025-03-13 07:37:19.653193: val_loss -0.9178 
2025-03-13 07:37:19.656701: Pseudo dice [np.float32(0.9348)] 
2025-03-13 07:37:19.660208: Epoch time: 42.32 s 
2025-03-13 07:37:19.663215: Yayy! New best EMA pseudo Dice: 0.929099977016449 
2025-03-13 07:37:20.340332:  
2025-03-13 07:37:20.346344: Epoch 31 
2025-03-13 07:37:20.348849: Current learning rate: 0.00716 
2025-03-13 07:38:02.629562: train_loss -0.936 
2025-03-13 07:38:02.636627: val_loss -0.9185 
2025-03-13 07:38:02.639637: Pseudo dice [np.float32(0.9351)] 
2025-03-13 07:38:02.643146: Epoch time: 42.29 s 
2025-03-13 07:38:02.645660: Yayy! New best EMA pseudo Dice: 0.9297000169754028 
2025-03-13 07:38:03.337829:  
2025-03-13 07:38:03.342883: Epoch 32 
2025-03-13 07:38:03.346394: Current learning rate: 0.00707 
2025-03-13 07:38:45.629655: train_loss -0.9337 
2025-03-13 07:38:45.635217: val_loss -0.9143 
2025-03-13 07:38:45.638265: Pseudo dice [np.float32(0.9314)] 
2025-03-13 07:38:45.641290: Epoch time: 42.29 s 
2025-03-13 07:38:45.644797: Yayy! New best EMA pseudo Dice: 0.9298999905586243 
2025-03-13 07:38:46.336495:  
2025-03-13 07:38:46.342520: Epoch 33 
2025-03-13 07:38:46.346031: Current learning rate: 0.00697 
2025-03-13 07:39:28.667106: train_loss -0.9353 
2025-03-13 07:39:28.673167: val_loss -0.9212 
2025-03-13 07:39:28.675672: Pseudo dice [np.float32(0.9366)] 
2025-03-13 07:39:28.679184: Epoch time: 42.33 s 
2025-03-13 07:39:28.682689: Yayy! New best EMA pseudo Dice: 0.9305999875068665 
2025-03-13 07:39:29.368765:  
2025-03-13 07:39:29.374843: Epoch 34 
2025-03-13 07:39:29.378350: Current learning rate: 0.00688 
2025-03-13 07:40:11.688864: train_loss -0.9357 
2025-03-13 07:40:11.694880: val_loss -0.9211 
2025-03-13 07:40:11.698385: Pseudo dice [np.float32(0.9365)] 
2025-03-13 07:40:11.701393: Epoch time: 42.32 s 
2025-03-13 07:40:11.704907: Yayy! New best EMA pseudo Dice: 0.9312000274658203 
2025-03-13 07:40:12.391418:  
2025-03-13 07:40:12.397548: Epoch 35 
2025-03-13 07:40:12.403116: Current learning rate: 0.00679 
2025-03-13 07:40:54.710023: train_loss -0.9375 
2025-03-13 07:40:54.715033: val_loss -0.9163 
2025-03-13 07:40:54.719046: Pseudo dice [np.float32(0.9315)] 
2025-03-13 07:40:54.722553: Epoch time: 42.32 s 
2025-03-13 07:40:54.725063: Yayy! New best EMA pseudo Dice: 0.9312000274658203 
2025-03-13 07:40:55.549887:  
2025-03-13 07:40:55.555467: Epoch 36 
2025-03-13 07:40:55.559020: Current learning rate: 0.00669 
2025-03-13 07:41:37.816052: train_loss -0.9398 
2025-03-13 07:41:37.822582: val_loss -0.916 
2025-03-13 07:41:37.826596: Pseudo dice [np.float32(0.9324)] 
2025-03-13 07:41:37.829099: Epoch time: 42.27 s 
2025-03-13 07:41:37.832604: Yayy! New best EMA pseudo Dice: 0.9312999844551086 
2025-03-13 07:41:38.523470:  
2025-03-13 07:41:38.529025: Epoch 37 
2025-03-13 07:41:38.533074: Current learning rate: 0.0066 
2025-03-13 07:42:20.803326: train_loss -0.9427 
2025-03-13 07:42:20.809427: val_loss -0.9223 
2025-03-13 07:42:20.813484: Pseudo dice [np.float32(0.9367)] 
2025-03-13 07:42:20.817082: Epoch time: 42.28 s 
2025-03-13 07:42:20.820651: Yayy! New best EMA pseudo Dice: 0.9318000078201294 
2025-03-13 07:42:21.501901:  
2025-03-13 07:42:21.508505: Epoch 38 
2025-03-13 07:42:21.511544: Current learning rate: 0.0065 
2025-03-13 07:43:03.817669: train_loss -0.9419 
2025-03-13 07:43:03.825182: val_loss -0.921 
2025-03-13 07:43:03.829193: Pseudo dice [np.float32(0.9367)] 
2025-03-13 07:43:03.831697: Epoch time: 42.32 s 
2025-03-13 07:43:03.835205: Yayy! New best EMA pseudo Dice: 0.9322999715805054 
2025-03-13 07:43:04.514037:  
2025-03-13 07:43:04.520076: Epoch 39 
2025-03-13 07:43:04.523587: Current learning rate: 0.00641 
2025-03-13 07:43:46.810953: train_loss -0.9395 
2025-03-13 07:43:46.817009: val_loss -0.9159 
2025-03-13 07:43:46.821064: Pseudo dice [np.float32(0.9323)] 
2025-03-13 07:43:46.823569: Epoch time: 42.3 s 
2025-03-13 07:43:47.348382:  
2025-03-13 07:43:47.352970: Epoch 40 
2025-03-13 07:43:47.357019: Current learning rate: 0.00631 
2025-03-13 07:44:29.665504: train_loss -0.9392 
2025-03-13 07:44:29.672541: val_loss -0.9165 
2025-03-13 07:44:29.676049: Pseudo dice [np.float32(0.9332)] 
2025-03-13 07:44:29.678554: Epoch time: 42.32 s 
2025-03-13 07:44:29.682064: Yayy! New best EMA pseudo Dice: 0.9323999881744385 
2025-03-13 07:44:30.367390:  
2025-03-13 07:44:30.374009: Epoch 41 
2025-03-13 07:44:30.377583: Current learning rate: 0.00622 
2025-03-13 07:45:12.684205: train_loss -0.9397 
2025-03-13 07:45:12.689733: val_loss -0.9198 
2025-03-13 07:45:12.692239: Pseudo dice [np.float32(0.9354)] 
2025-03-13 07:45:12.696249: Epoch time: 42.32 s 
2025-03-13 07:45:12.698630: Yayy! New best EMA pseudo Dice: 0.932699978351593 
2025-03-13 07:45:13.356308:  
2025-03-13 07:45:13.362383: Epoch 42 
2025-03-13 07:45:13.365432: Current learning rate: 0.00612 
2025-03-13 07:45:55.639662: train_loss -0.9413 
2025-03-13 07:45:55.645684: val_loss -0.921 
2025-03-13 07:45:55.648735: Pseudo dice [np.float32(0.9362)] 
2025-03-13 07:45:55.651246: Epoch time: 42.28 s 
2025-03-13 07:45:55.655478: Yayy! New best EMA pseudo Dice: 0.9330999851226807 
2025-03-13 07:45:56.364615:  
2025-03-13 07:45:56.371188: Epoch 43 
2025-03-13 07:45:56.373725: Current learning rate: 0.00603 
2025-03-13 07:46:38.670916: train_loss -0.9426 
2025-03-13 07:46:38.676934: val_loss -0.9216 
2025-03-13 07:46:38.680438: Pseudo dice [np.float32(0.9369)] 
2025-03-13 07:46:38.683450: Epoch time: 42.31 s 
2025-03-13 07:46:38.686959: Yayy! New best EMA pseudo Dice: 0.9333999752998352 
2025-03-13 07:46:39.492754:  
2025-03-13 07:46:39.498296: Epoch 44 
2025-03-13 07:46:39.501318: Current learning rate: 0.00593 
2025-03-13 07:47:21.812023: train_loss -0.9433 
2025-03-13 07:47:21.817032: val_loss -0.9212 
2025-03-13 07:47:21.821040: Pseudo dice [np.float32(0.9359)] 
2025-03-13 07:47:21.824548: Epoch time: 42.32 s 
2025-03-13 07:47:21.827052: Yayy! New best EMA pseudo Dice: 0.9337000250816345 
2025-03-13 07:47:22.498492:  
2025-03-13 07:47:22.504045: Epoch 45 
2025-03-13 07:47:22.506578: Current learning rate: 0.00584 
2025-03-13 07:48:04.759969: train_loss -0.9416 
2025-03-13 07:48:04.766016: val_loss -0.9108 
2025-03-13 07:48:04.769578: Pseudo dice [np.float32(0.9288)] 
2025-03-13 07:48:04.772624: Epoch time: 42.26 s 
2025-03-13 07:48:05.273299:  
2025-03-13 07:48:05.279344: Epoch 46 
2025-03-13 07:48:05.282399: Current learning rate: 0.00574 
2025-03-13 07:48:47.571497: train_loss -0.9278 
2025-03-13 07:48:47.577594: val_loss -0.923 
2025-03-13 07:48:47.579612: Pseudo dice [np.float32(0.938)] 
2025-03-13 07:48:47.584179: Epoch time: 42.3 s 
2025-03-13 07:48:48.081181:  
2025-03-13 07:48:48.086233: Epoch 47 
2025-03-13 07:48:48.089747: Current learning rate: 0.00565 
2025-03-13 07:49:30.383623: train_loss -0.9395 
2025-03-13 07:49:30.389169: val_loss -0.9248 
2025-03-13 07:49:30.392694: Pseudo dice [np.float32(0.9398)] 
2025-03-13 07:49:30.396236: Epoch time: 42.3 s 
2025-03-13 07:49:30.399266: Yayy! New best EMA pseudo Dice: 0.9343000054359436 
2025-03-13 07:49:31.075639:  
2025-03-13 07:49:31.081152: Epoch 48 
2025-03-13 07:49:31.083658: Current learning rate: 0.00555 
2025-03-13 07:50:13.328782: train_loss -0.9383 
2025-03-13 07:50:13.335292: val_loss -0.9186 
2025-03-13 07:50:13.338799: Pseudo dice [np.float32(0.9342)] 
2025-03-13 07:50:13.341304: Epoch time: 42.25 s 
2025-03-13 07:50:13.845706:  
2025-03-13 07:50:13.851251: Epoch 49 
2025-03-13 07:50:13.853789: Current learning rate: 0.00546 
2025-03-13 07:50:56.124669: train_loss -0.9437 
2025-03-13 07:50:56.130270: val_loss -0.9207 
2025-03-13 07:50:56.132791: Pseudo dice [np.float32(0.9359)] 
2025-03-13 07:50:56.136845: Epoch time: 42.28 s 
2025-03-13 07:50:56.278287: Yayy! New best EMA pseudo Dice: 0.9344000220298767 
2025-03-13 07:50:56.941626:  
2025-03-13 07:50:56.946188: Epoch 50 
2025-03-13 07:50:56.949701: Current learning rate: 0.00536 
2025-03-13 07:51:39.229601: train_loss -0.9487 
2025-03-13 07:51:39.235141: val_loss -0.923 
2025-03-13 07:51:39.238691: Pseudo dice [np.float32(0.9379)] 
2025-03-13 07:51:39.241730: Epoch time: 42.29 s 
2025-03-13 07:51:39.244762: Yayy! New best EMA pseudo Dice: 0.9348000288009644 
2025-03-13 07:51:39.905122:  
2025-03-13 07:51:39.910355: Epoch 51 
2025-03-13 07:51:39.913866: Current learning rate: 0.00526 
2025-03-13 07:52:22.226062: train_loss -0.948 
2025-03-13 07:52:22.232079: val_loss -0.918 
2025-03-13 07:52:22.235584: Pseudo dice [np.float32(0.9335)] 
2025-03-13 07:52:22.238595: Epoch time: 42.32 s 
2025-03-13 07:52:22.909188:  
2025-03-13 07:52:22.914710: Epoch 52 
2025-03-13 07:52:22.919240: Current learning rate: 0.00517 
2025-03-13 07:53:05.286501: train_loss -0.9417 
2025-03-13 07:53:05.290016: val_loss -0.9205 
2025-03-13 07:53:05.294028: Pseudo dice [np.float32(0.9357)] 
2025-03-13 07:53:05.297546: Epoch time: 42.38 s 
2025-03-13 07:53:05.826317:  
2025-03-13 07:53:05.831838: Epoch 53 
2025-03-13 07:53:05.835347: Current learning rate: 0.00507 
2025-03-13 07:53:48.166635: train_loss -0.9465 
2025-03-13 07:53:48.172650: val_loss -0.9204 
2025-03-13 07:53:48.176662: Pseudo dice [np.float32(0.9361)] 
2025-03-13 07:53:48.179171: Epoch time: 42.34 s 
2025-03-13 07:53:48.183180: Yayy! New best EMA pseudo Dice: 0.9348999857902527 
2025-03-13 07:53:48.861921:  
2025-03-13 07:53:48.867481: Epoch 54 
2025-03-13 07:53:48.871104: Current learning rate: 0.00497 
2025-03-13 07:54:31.117661: train_loss -0.9498 
2025-03-13 07:54:31.123675: val_loss -0.9213 
2025-03-13 07:54:31.126683: Pseudo dice [np.float32(0.9363)] 
2025-03-13 07:54:31.129189: Epoch time: 42.26 s 
2025-03-13 07:54:31.132700: Yayy! New best EMA pseudo Dice: 0.9350000023841858 
2025-03-13 07:54:31.790782:  
2025-03-13 07:54:31.796334: Epoch 55 
2025-03-13 07:54:31.798867: Current learning rate: 0.00487 
2025-03-13 07:55:14.109491: train_loss -0.9495 
2025-03-13 07:55:14.115510: val_loss -0.9211 
2025-03-13 07:55:14.118518: Pseudo dice [np.float32(0.936)] 
2025-03-13 07:55:14.122037: Epoch time: 42.32 s 
2025-03-13 07:55:14.126044: Yayy! New best EMA pseudo Dice: 0.9351000189781189 
2025-03-13 07:55:14.799544:  
2025-03-13 07:55:14.806150: Epoch 56 
2025-03-13 07:55:14.809690: Current learning rate: 0.00478 
2025-03-13 07:55:57.084346: train_loss -0.9508 
2025-03-13 07:55:57.089862: val_loss -0.9225 
2025-03-13 07:55:57.093370: Pseudo dice [np.float32(0.9372)] 
2025-03-13 07:55:57.097378: Epoch time: 42.28 s 
2025-03-13 07:55:57.099885: Yayy! New best EMA pseudo Dice: 0.9352999925613403 
2025-03-13 07:55:57.759156:  
2025-03-13 07:55:57.764752: Epoch 57 
2025-03-13 07:55:57.768791: Current learning rate: 0.00468 
2025-03-13 07:56:40.090556: train_loss -0.9504 
2025-03-13 07:56:40.097164: val_loss -0.9212 
2025-03-13 07:56:40.100713: Pseudo dice [np.float32(0.9365)] 
2025-03-13 07:56:40.103245: Epoch time: 42.33 s 
2025-03-13 07:56:40.107327: Yayy! New best EMA pseudo Dice: 0.9355000257492065 
2025-03-13 07:56:40.773623:  
2025-03-13 07:56:40.779202: Epoch 58 
2025-03-13 07:56:40.782783: Current learning rate: 0.00458 
2025-03-13 07:57:23.111281: train_loss -0.9465 
2025-03-13 07:57:23.117295: val_loss -0.9185 
2025-03-13 07:57:23.123312: Pseudo dice [np.float32(0.9337)] 
2025-03-13 07:57:23.126320: Epoch time: 42.34 s 
2025-03-13 07:57:23.640459:  
2025-03-13 07:57:23.645983: Epoch 59 
2025-03-13 07:57:23.649521: Current learning rate: 0.00448 
2025-03-13 07:58:05.939904: train_loss -0.945 
2025-03-13 07:58:05.945917: val_loss -0.9237 
2025-03-13 07:58:05.948421: Pseudo dice [np.float32(0.9378)] 
2025-03-13 07:58:05.954935: Epoch time: 42.3 s 
2025-03-13 07:58:05.958446: Yayy! New best EMA pseudo Dice: 0.9355000257492065 
2025-03-13 07:58:06.618761:  
2025-03-13 07:58:06.624806: Epoch 60 
2025-03-13 07:58:06.627887: Current learning rate: 0.00438 
2025-03-13 07:58:48.937177: train_loss -0.9485 
2025-03-13 07:58:48.943691: val_loss -0.9224 
2025-03-13 07:58:48.946197: Pseudo dice [np.float32(0.937)] 
2025-03-13 07:58:48.949715: Epoch time: 42.32 s 
2025-03-13 07:58:48.953219: Yayy! New best EMA pseudo Dice: 0.935699999332428 
2025-03-13 07:58:49.771885:  
2025-03-13 07:58:49.778451: Epoch 61 
2025-03-13 07:58:49.780998: Current learning rate: 0.00429 
2025-03-13 07:59:32.049534: train_loss -0.9524 
2025-03-13 07:59:32.055092: val_loss -0.9216 
2025-03-13 07:59:32.058135: Pseudo dice [np.float32(0.9371)] 
2025-03-13 07:59:32.061709: Epoch time: 42.28 s 
2025-03-13 07:59:32.064775: Yayy! New best EMA pseudo Dice: 0.9358000159263611 
2025-03-13 07:59:32.759444:  
2025-03-13 07:59:32.764456: Epoch 62 
2025-03-13 07:59:32.767963: Current learning rate: 0.00419 
2025-03-13 08:00:15.034412: train_loss -0.9534 
2025-03-13 08:00:15.040425: val_loss -0.923 
2025-03-13 08:00:15.043931: Pseudo dice [np.float32(0.938)] 
2025-03-13 08:00:15.046939: Epoch time: 42.28 s 
2025-03-13 08:00:15.050446: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2025-03-13 08:00:15.725460:  
2025-03-13 08:00:15.730469: Epoch 63 
2025-03-13 08:00:15.733981: Current learning rate: 0.00409 
2025-03-13 08:00:58.046958: train_loss -0.9518 
2025-03-13 08:00:58.053010: val_loss -0.9221 
2025-03-13 08:00:58.056577: Pseudo dice [np.float32(0.9368)] 
2025-03-13 08:00:58.059147: Epoch time: 42.32 s 
2025-03-13 08:00:58.063240: Yayy! New best EMA pseudo Dice: 0.9361000061035156 
2025-03-13 08:00:58.737256:  
2025-03-13 08:00:58.742281: Epoch 64 
2025-03-13 08:00:58.746369: Current learning rate: 0.00399 
2025-03-13 08:01:41.043691: train_loss -0.9531 
2025-03-13 08:01:41.049244: val_loss -0.9191 
2025-03-13 08:01:41.052445: Pseudo dice [np.float32(0.9351)] 
2025-03-13 08:01:41.055469: Epoch time: 42.31 s 
2025-03-13 08:01:41.582381:  
2025-03-13 08:01:41.587403: Epoch 65 
2025-03-13 08:01:41.591461: Current learning rate: 0.00389 
2025-03-13 08:02:23.900604: train_loss -0.9539 
2025-03-13 08:02:23.906617: val_loss -0.9184 
2025-03-13 08:02:23.909122: Pseudo dice [np.float32(0.9342)] 
2025-03-13 08:02:23.913131: Epoch time: 42.32 s 
2025-03-13 08:02:24.432205:  
2025-03-13 08:02:24.438779: Epoch 66 
2025-03-13 08:02:24.441317: Current learning rate: 0.00379 
2025-03-13 08:03:06.750831: train_loss -0.9479 
2025-03-13 08:03:06.756364: val_loss -0.9252 
2025-03-13 08:03:06.760372: Pseudo dice [np.float32(0.9394)] 
2025-03-13 08:03:06.763880: Epoch time: 42.32 s 
2025-03-13 08:03:06.767890: Yayy! New best EMA pseudo Dice: 0.9362000226974487 
2025-03-13 08:03:07.441686:  
2025-03-13 08:03:07.447735: Epoch 67 
2025-03-13 08:03:07.450785: Current learning rate: 0.00369 
2025-03-13 08:03:49.754876: train_loss -0.9532 
2025-03-13 08:03:49.761433: val_loss -0.9254 
2025-03-13 08:03:49.764981: Pseudo dice [np.float32(0.9399)] 
2025-03-13 08:03:49.767485: Epoch time: 42.31 s 
2025-03-13 08:03:49.771002: Yayy! New best EMA pseudo Dice: 0.9366000294685364 
2025-03-13 08:03:50.447958:  
2025-03-13 08:03:50.453564: Epoch 68 
2025-03-13 08:03:50.456093: Current learning rate: 0.00359 
2025-03-13 08:04:32.769960: train_loss -0.9548 
2025-03-13 08:04:32.776977: val_loss -0.9209 
2025-03-13 08:04:32.780988: Pseudo dice [np.float32(0.9366)] 
2025-03-13 08:04:32.783493: Epoch time: 42.32 s 
2025-03-13 08:04:32.786999: Yayy! New best EMA pseudo Dice: 0.9366000294685364 
2025-03-13 08:04:33.616960:  
2025-03-13 08:04:33.623058: Epoch 69 
2025-03-13 08:04:33.625596: Current learning rate: 0.00349 
2025-03-13 08:05:15.932302: train_loss -0.9523 
2025-03-13 08:05:15.937850: val_loss -0.9231 
2025-03-13 08:05:15.940866: Pseudo dice [np.float32(0.9378)] 
2025-03-13 08:05:15.944684: Epoch time: 42.32 s 
2025-03-13 08:05:15.947205: Yayy! New best EMA pseudo Dice: 0.9366999864578247 
2025-03-13 08:05:16.669792:  
2025-03-13 08:05:16.675373: Epoch 70 
2025-03-13 08:05:16.678910: Current learning rate: 0.00338 
2025-03-13 08:05:59.001702: train_loss -0.9459 
2025-03-13 08:05:59.006743: val_loss -0.9252 
2025-03-13 08:05:59.010312: Pseudo dice [np.float32(0.9398)] 
2025-03-13 08:05:59.012868: Epoch time: 42.33 s 
2025-03-13 08:05:59.016906: Yayy! New best EMA pseudo Dice: 0.9369999766349792 
2025-03-13 08:05:59.730363:  
2025-03-13 08:05:59.735932: Epoch 71 
2025-03-13 08:05:59.739543: Current learning rate: 0.00328 
2025-03-13 08:06:42.070863: train_loss -0.9508 
2025-03-13 08:06:42.075948: val_loss -0.9229 
2025-03-13 08:06:42.079456: Pseudo dice [np.float32(0.9377)] 
2025-03-13 08:06:42.083463: Epoch time: 42.34 s 
2025-03-13 08:06:42.085968: Yayy! New best EMA pseudo Dice: 0.9370999932289124 
2025-03-13 08:06:42.775731:  
2025-03-13 08:06:42.781828: Epoch 72 
2025-03-13 08:06:42.784859: Current learning rate: 0.00318 
2025-03-13 08:07:25.096261: train_loss -0.9549 
2025-03-13 08:07:25.102775: val_loss -0.9204 
2025-03-13 08:07:25.106285: Pseudo dice [np.float32(0.936)] 
2025-03-13 08:07:25.108789: Epoch time: 42.32 s 
2025-03-13 08:07:25.643133:  
2025-03-13 08:07:25.648647: Epoch 73 
2025-03-13 08:07:25.652163: Current learning rate: 0.00308 
2025-03-13 08:08:07.968892: train_loss -0.9551 
2025-03-13 08:08:07.974905: val_loss -0.9213 
2025-03-13 08:08:07.978913: Pseudo dice [np.float32(0.9368)] 
2025-03-13 08:08:07.981419: Epoch time: 42.33 s 
2025-03-13 08:08:08.506926:  
2025-03-13 08:08:08.512469: Epoch 74 
2025-03-13 08:08:08.515020: Current learning rate: 0.00297 
2025-03-13 08:08:50.852253: train_loss -0.9547 
2025-03-13 08:08:50.858771: val_loss -0.924 
2025-03-13 08:08:50.862278: Pseudo dice [np.float32(0.9391)] 
2025-03-13 08:08:50.864792: Epoch time: 42.35 s 
2025-03-13 08:08:50.868799: Yayy! New best EMA pseudo Dice: 0.9372000098228455 
2025-03-13 08:08:51.566963:  
2025-03-13 08:08:51.572501: Epoch 75 
2025-03-13 08:08:51.575033: Current learning rate: 0.00287 
2025-03-13 08:09:33.890876: train_loss -0.9534 
2025-03-13 08:09:33.896887: val_loss -0.9201 
2025-03-13 08:09:33.899895: Pseudo dice [np.float32(0.9358)] 
2025-03-13 08:09:33.903403: Epoch time: 42.32 s 
2025-03-13 08:09:34.435928:  
2025-03-13 08:09:34.441945: Epoch 76 
2025-03-13 08:09:34.444956: Current learning rate: 0.00277 
2025-03-13 08:10:16.722431: train_loss -0.9562 
2025-03-13 08:10:16.729029: val_loss -0.9183 
2025-03-13 08:10:16.733083: Pseudo dice [np.float32(0.9341)] 
2025-03-13 08:10:16.736624: Epoch time: 42.29 s 
2025-03-13 08:10:17.406837:  
2025-03-13 08:10:17.412880: Epoch 77 
2025-03-13 08:10:17.415384: Current learning rate: 0.00266 
2025-03-13 08:10:59.726170: train_loss -0.9537 
2025-03-13 08:10:59.732229: val_loss -0.9209 
2025-03-13 08:10:59.735785: Pseudo dice [np.float32(0.9359)] 
2025-03-13 08:10:59.738319: Epoch time: 42.32 s 
2025-03-13 08:11:00.277085:  
2025-03-13 08:11:00.282093: Epoch 78 
2025-03-13 08:11:00.285608: Current learning rate: 0.00256 
2025-03-13 08:11:42.574644: train_loss -0.9523 
2025-03-13 08:11:42.581156: val_loss -0.924 
2025-03-13 08:11:42.584668: Pseudo dice [np.float32(0.9385)] 
2025-03-13 08:11:42.587172: Epoch time: 42.3 s 
2025-03-13 08:11:43.135953:  
2025-03-13 08:11:43.140962: Epoch 79 
2025-03-13 08:11:43.144476: Current learning rate: 0.00245 
2025-03-13 08:12:25.468461: train_loss -0.9571 
2025-03-13 08:12:25.474241: val_loss -0.9205 
2025-03-13 08:12:25.478248: Pseudo dice [np.float32(0.9357)] 
2025-03-13 08:12:25.480756: Epoch time: 42.33 s 
2025-03-13 08:12:26.017013:  
2025-03-13 08:12:26.022045: Epoch 80 
2025-03-13 08:12:26.024344: Current learning rate: 0.00235 
2025-03-13 08:13:08.344174: train_loss -0.9574 
2025-03-13 08:13:08.349193: val_loss -0.9213 
2025-03-13 08:13:08.352703: Pseudo dice [np.float32(0.9363)] 
2025-03-13 08:13:08.356215: Epoch time: 42.33 s 
2025-03-13 08:13:08.889817:  
2025-03-13 08:13:08.895865: Epoch 81 
2025-03-13 08:13:08.898918: Current learning rate: 0.00224 
2025-03-13 08:13:51.230049: train_loss -0.9581 
2025-03-13 08:13:51.237102: val_loss -0.9211 
2025-03-13 08:13:51.239611: Pseudo dice [np.float32(0.9362)] 
2025-03-13 08:13:51.243128: Epoch time: 42.34 s 
2025-03-13 08:13:51.776704:  
2025-03-13 08:13:51.782273: Epoch 82 
2025-03-13 08:13:51.786829: Current learning rate: 0.00214 
2025-03-13 08:14:34.094167: train_loss -0.9587 
2025-03-13 08:14:34.101297: val_loss -0.9207 
2025-03-13 08:14:34.104843: Pseudo dice [np.float32(0.9361)] 
2025-03-13 08:14:34.106862: Epoch time: 42.32 s 
2025-03-13 08:14:34.620941:  
2025-03-13 08:14:34.626472: Epoch 83 
2025-03-13 08:14:34.630024: Current learning rate: 0.00203 
2025-03-13 08:15:17.005598: train_loss -0.9578 
2025-03-13 08:15:17.010607: val_loss -0.9218 
2025-03-13 08:15:17.014619: Pseudo dice [np.float32(0.9372)] 
2025-03-13 08:15:17.018128: Epoch time: 42.39 s 
2025-03-13 08:15:17.529828:  
2025-03-13 08:15:17.535852: Epoch 84 
2025-03-13 08:15:17.539364: Current learning rate: 0.00192 
2025-03-13 08:15:59.881092: train_loss -0.9598 
2025-03-13 08:15:59.887109: val_loss -0.9191 
2025-03-13 08:15:59.890616: Pseudo dice [np.float32(0.9348)] 
2025-03-13 08:15:59.893634: Epoch time: 42.35 s 
2025-03-13 08:16:00.541965:  
2025-03-13 08:16:00.545991: Epoch 85 
2025-03-13 08:16:00.549514: Current learning rate: 0.00181 
2025-03-13 08:16:42.857511: train_loss -0.9587 
2025-03-13 08:16:42.863530: val_loss -0.9183 
2025-03-13 08:16:42.866539: Pseudo dice [np.float32(0.9342)] 
2025-03-13 08:16:42.870055: Epoch time: 42.32 s 
2025-03-13 08:16:43.372290:  
2025-03-13 08:16:43.378201: Epoch 86 
2025-03-13 08:16:43.382226: Current learning rate: 0.0017 
2025-03-13 08:17:25.699345: train_loss -0.9588 
2025-03-13 08:17:25.705920: val_loss -0.9238 
2025-03-13 08:17:25.708990: Pseudo dice [np.float32(0.9384)] 
2025-03-13 08:17:25.711526: Epoch time: 42.33 s 
2025-03-13 08:17:26.214063:  
2025-03-13 08:17:26.218088: Epoch 87 
2025-03-13 08:17:26.222123: Current learning rate: 0.00159 
2025-03-13 08:18:08.496555: train_loss -0.9606 
2025-03-13 08:18:08.502569: val_loss -0.9217 
2025-03-13 08:18:08.505578: Pseudo dice [np.float32(0.9369)] 
2025-03-13 08:18:08.510091: Epoch time: 42.28 s 
2025-03-13 08:18:09.007934:  
2025-03-13 08:18:09.013448: Epoch 88 
2025-03-13 08:18:09.016958: Current learning rate: 0.00148 
2025-03-13 08:18:51.265887: train_loss -0.9599 
2025-03-13 08:18:51.272442: val_loss -0.9211 
2025-03-13 08:18:51.275956: Pseudo dice [np.float32(0.9366)] 
2025-03-13 08:18:51.278567: Epoch time: 42.26 s 
2025-03-13 08:18:51.778281:  
2025-03-13 08:18:51.784296: Epoch 89 
2025-03-13 08:18:51.786803: Current learning rate: 0.00137 
2025-03-13 08:19:34.096960: train_loss -0.9617 
2025-03-13 08:19:34.103037: val_loss -0.9225 
2025-03-13 08:19:34.107060: Pseudo dice [np.float32(0.9377)] 
2025-03-13 08:19:34.110079: Epoch time: 42.32 s 
2025-03-13 08:19:34.611208:  
2025-03-13 08:19:34.616756: Epoch 90 
2025-03-13 08:19:34.620857: Current learning rate: 0.00126 
2025-03-13 08:20:16.934918: train_loss -0.959 
2025-03-13 08:20:16.942465: val_loss -0.9228 
2025-03-13 08:20:16.946000: Pseudo dice [np.float32(0.9383)] 
2025-03-13 08:20:16.948750: Epoch time: 42.32 s 
2025-03-13 08:20:17.455143:  
2025-03-13 08:20:17.460675: Epoch 91 
2025-03-13 08:20:17.464291: Current learning rate: 0.00115 
2025-03-13 08:20:59.783535: train_loss -0.9598 
2025-03-13 08:20:59.787460: val_loss -0.9206 
2025-03-13 08:20:59.790972: Pseudo dice [np.float32(0.9358)] 
2025-03-13 08:20:59.793997: Epoch time: 42.33 s 
2025-03-13 08:21:00.297034:  
2025-03-13 08:21:00.302669: Epoch 92 
2025-03-13 08:21:00.305699: Current learning rate: 0.00103 
2025-03-13 08:21:42.618617: train_loss -0.9587 
2025-03-13 08:21:42.623985: val_loss -0.9197 
2025-03-13 08:21:42.627500: Pseudo dice [np.float32(0.9357)] 
2025-03-13 08:21:42.631012: Epoch time: 42.32 s 
2025-03-13 08:21:43.131187:  
2025-03-13 08:21:43.137231: Epoch 93 
2025-03-13 08:21:43.140739: Current learning rate: 0.00091 
2025-03-13 08:22:25.456042: train_loss -0.9604 
2025-03-13 08:22:25.462080: val_loss -0.9197 
2025-03-13 08:22:25.465593: Pseudo dice [np.float32(0.9355)] 
2025-03-13 08:22:25.469012: Epoch time: 42.33 s 
2025-03-13 08:22:26.114949:  
2025-03-13 08:22:26.119994: Epoch 94 
2025-03-13 08:22:26.122844: Current learning rate: 0.00079 
2025-03-13 08:23:08.443891: train_loss -0.9618 
2025-03-13 08:23:08.449912: val_loss -0.9231 
2025-03-13 08:23:08.452926: Pseudo dice [np.float32(0.9384)] 
2025-03-13 08:23:08.456441: Epoch time: 42.33 s 
2025-03-13 08:23:08.960275:  
2025-03-13 08:23:08.964317: Epoch 95 
2025-03-13 08:23:08.968386: Current learning rate: 0.00067 
2025-03-13 08:23:51.291758: train_loss -0.961 
2025-03-13 08:23:51.298323: val_loss -0.9214 
2025-03-13 08:23:51.303921: Pseudo dice [np.float32(0.9367)] 
2025-03-13 08:23:51.307010: Epoch time: 42.33 s 
2025-03-13 08:23:51.807660:  
2025-03-13 08:23:51.813240: Epoch 96 
2025-03-13 08:23:51.816769: Current learning rate: 0.00055 
2025-03-13 08:24:34.135193: train_loss -0.9602 
2025-03-13 08:24:34.141216: val_loss -0.9217 
2025-03-13 08:24:34.144721: Pseudo dice [np.float32(0.937)] 
2025-03-13 08:24:34.147730: Epoch time: 42.33 s 
2025-03-13 08:24:34.674958:  
2025-03-13 08:24:34.679986: Epoch 97 
2025-03-13 08:24:34.684002: Current learning rate: 0.00043 
2025-03-13 08:25:17.011663: train_loss -0.9615 
2025-03-13 08:25:17.016681: val_loss -0.9232 
2025-03-13 08:25:17.020192: Pseudo dice [np.float32(0.9385)] 
2025-03-13 08:25:17.024199: Epoch time: 42.34 s 
2025-03-13 08:25:17.532584:  
2025-03-13 08:25:17.539150: Epoch 98 
2025-03-13 08:25:17.542677: Current learning rate: 0.0003 
2025-03-13 08:25:59.853533: train_loss -0.9591 
2025-03-13 08:25:59.858627: val_loss -0.9218 
2025-03-13 08:25:59.862655: Pseudo dice [np.float32(0.9371)] 
2025-03-13 08:25:59.866167: Epoch time: 42.32 s 
2025-03-13 08:26:00.483971:  
2025-03-13 08:26:00.488989: Epoch 99 
2025-03-13 08:26:00.492504: Current learning rate: 0.00016 
2025-03-13 08:26:42.815796: train_loss -0.9619 
2025-03-13 08:26:42.822311: val_loss -0.9213 
2025-03-13 08:26:42.826321: Pseudo dice [np.float32(0.937)] 
2025-03-13 08:26:42.829832: Epoch time: 42.33 s 
2025-03-13 08:26:43.534217: Training done. 
2025-03-13 08:26:43.580218: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-13 08:26:43.587218: The split file contains 5 splits. 
2025-03-13 08:26:43.591217: Desired fold for training: 0 
2025-03-13 08:26:43.597217: This split has 16 training and 4 validation cases. 
2025-03-13 08:26:43.602218: predicting la_007 
2025-03-13 08:26:43.609218: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2025-03-13 08:26:49.419670: predicting la_016 
2025-03-13 08:26:49.431671: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2025-03-13 08:26:51.696748: predicting la_021 
2025-03-13 08:26:51.705746: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2025-03-13 08:26:53.973256: predicting la_024 
2025-03-13 08:26:53.984254: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2025-03-13 08:27:02.811904: Validation complete 
2025-03-13 08:27:02.817903: Mean Validation Dice:  0.9358813290723897 
