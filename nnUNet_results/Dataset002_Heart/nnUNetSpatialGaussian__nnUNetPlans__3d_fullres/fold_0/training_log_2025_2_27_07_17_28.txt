
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-27 07:17:28.957337: do_dummy_2d_data_aug: False 
2025-02-27 07:17:28.958336: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-02-27 07:17:28.964770: The split file contains 5 splits. 
2025-02-27 07:17:28.967770: Desired fold for training: 0 
2025-02-27 07:17:28.970769: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2025-02-27 07:17:39.197716: unpacking dataset... 
2025-02-27 07:17:39.993328: unpacking done... 
2025-02-27 07:17:44.339263:  
2025-02-27 07:17:44.344826: Epoch 0 
2025-02-27 07:17:44.347372: Current learning rate: 0.01 
2025-02-27 07:19:16.337482: train_loss -0.655 
2025-02-27 07:19:16.344502: val_loss -0.8856 
2025-02-27 07:19:16.347517: Pseudo dice [np.float32(0.9127)] 
2025-02-27 07:19:16.351029: Epoch time: 92.0 s 
2025-02-27 07:19:16.354539: Yayy! New best EMA pseudo Dice: 0.9126999974250793 
2025-02-27 07:19:16.990844:  
2025-02-27 07:19:16.995925: Epoch 1 
2025-02-27 07:19:16.999449: Current learning rate: 0.00991 
2025-02-27 07:20:39.833081: train_loss -0.8942 
2025-02-27 07:20:39.839099: val_loss -0.9046 
2025-02-27 07:20:39.843119: Pseudo dice [np.float32(0.9259)] 
2025-02-27 07:20:39.846628: Epoch time: 82.84 s 
2025-02-27 07:20:39.849138: Yayy! New best EMA pseudo Dice: 0.9140999913215637 
2025-02-27 07:20:40.549687:  
2025-02-27 07:20:40.555803: Epoch 2 
2025-02-27 07:20:40.559311: Current learning rate: 0.00982 
2025-02-27 07:22:03.367004: train_loss -0.9119 
2025-02-27 07:22:03.372518: val_loss -0.9036 
2025-02-27 07:22:03.376029: Pseudo dice [np.float32(0.9255)] 
2025-02-27 07:22:03.380041: Epoch time: 82.82 s 
2025-02-27 07:22:03.383550: Yayy! New best EMA pseudo Dice: 0.9151999950408936 
2025-02-27 07:22:04.126378:  
2025-02-27 07:22:04.131993: Epoch 3 
2025-02-27 07:22:04.135545: Current learning rate: 0.00973 
2025-02-27 07:23:26.941134: train_loss -0.9243 
2025-02-27 07:23:26.947645: val_loss -0.9138 
2025-02-27 07:23:26.951156: Pseudo dice [np.float32(0.9329)] 
2025-02-27 07:23:26.954661: Epoch time: 82.81 s 
2025-02-27 07:23:26.957675: Yayy! New best EMA pseudo Dice: 0.9169999957084656 
2025-02-27 07:23:27.678796:  
2025-02-27 07:23:27.684315: Epoch 4 
2025-02-27 07:23:27.686822: Current learning rate: 0.00964 
2025-02-27 07:24:50.508872: train_loss -0.9353 
2025-02-27 07:24:50.514392: val_loss -0.9171 
2025-02-27 07:24:50.517905: Pseudo dice [np.float32(0.9346)] 
2025-02-27 07:24:50.520412: Epoch time: 82.83 s 
2025-02-27 07:24:50.524427: Yayy! New best EMA pseudo Dice: 0.9186999797821045 
2025-02-27 07:24:51.391686:  
2025-02-27 07:24:51.396735: Epoch 5 
2025-02-27 07:24:51.400244: Current learning rate: 0.00955 
2025-02-27 07:26:14.176916: train_loss -0.9422 
2025-02-27 07:26:14.182929: val_loss -0.9174 
2025-02-27 07:26:14.188445: Pseudo dice [np.float32(0.9345)] 
2025-02-27 07:26:14.191953: Epoch time: 82.79 s 
2025-02-27 07:26:14.195965: Yayy! New best EMA pseudo Dice: 0.9203000068664551 
2025-02-27 07:26:14.907122:  
2025-02-27 07:26:14.912639: Epoch 6 
2025-02-27 07:26:14.916149: Current learning rate: 0.00946 
2025-02-27 07:27:37.687879: train_loss -0.9473 
2025-02-27 07:27:37.693441: val_loss -0.921 
2025-02-27 07:27:37.697051: Pseudo dice [np.float32(0.9377)] 
2025-02-27 07:27:37.700077: Epoch time: 82.78 s 
2025-02-27 07:27:37.703116: Yayy! New best EMA pseudo Dice: 0.921999990940094 
2025-02-27 07:27:38.430325:  
2025-02-27 07:27:38.436391: Epoch 7 
2025-02-27 07:27:38.439462: Current learning rate: 0.00937 
2025-02-27 07:29:01.656656: train_loss -0.9517 
2025-02-27 07:29:01.662230: val_loss -0.92 
2025-02-27 07:29:01.665739: Pseudo dice [np.float32(0.9369)] 
2025-02-27 07:29:01.668749: Epoch time: 83.23 s 
2025-02-27 07:29:01.672279: Yayy! New best EMA pseudo Dice: 0.9235000014305115 
2025-02-27 07:29:02.394823:  
2025-02-27 07:29:02.400354: Epoch 8 
2025-02-27 07:29:02.403908: Current learning rate: 0.00928 
2025-02-27 07:30:25.217260: train_loss -0.9478 
2025-02-27 07:30:25.222271: val_loss -0.9178 
2025-02-27 07:30:25.225780: Pseudo dice [np.float32(0.9346)] 
2025-02-27 07:30:25.229285: Epoch time: 82.82 s 
2025-02-27 07:30:25.232294: Yayy! New best EMA pseudo Dice: 0.9246000051498413 
2025-02-27 07:30:25.962664:  
2025-02-27 07:30:25.968724: Epoch 9 
2025-02-27 07:30:25.971807: Current learning rate: 0.00919 
2025-02-27 07:31:48.912086: train_loss -0.9536 
2025-02-27 07:31:48.918103: val_loss -0.918 
2025-02-27 07:31:48.921608: Pseudo dice [np.float32(0.9356)] 
2025-02-27 07:31:48.925625: Epoch time: 82.95 s 
2025-02-27 07:31:48.928132: Yayy! New best EMA pseudo Dice: 0.9257000088691711 
2025-02-27 07:31:49.627002:  
2025-02-27 07:31:49.632036: Epoch 10 
2025-02-27 07:31:49.635690: Current learning rate: 0.0091 
2025-02-27 07:33:12.529741: train_loss -0.9557 
2025-02-27 07:33:12.536055: val_loss -0.9168 
2025-02-27 07:33:12.539567: Pseudo dice [np.float32(0.9344)] 
2025-02-27 07:33:12.543081: Epoch time: 82.9 s 
2025-02-27 07:33:12.546213: Yayy! New best EMA pseudo Dice: 0.9265999794006348 
2025-02-27 07:33:13.252582:  
2025-02-27 07:33:13.258661: Epoch 11 
2025-02-27 07:33:13.261723: Current learning rate: 0.009 
2025-02-27 07:34:36.244262: train_loss -0.9562 
2025-02-27 07:34:36.249775: val_loss -0.9182 
2025-02-27 07:34:36.253283: Pseudo dice [np.float32(0.936)] 
2025-02-27 07:34:36.256793: Epoch time: 82.99 s 
2025-02-27 07:34:36.259802: Yayy! New best EMA pseudo Dice: 0.9275000095367432 
2025-02-27 07:34:36.977764:  
2025-02-27 07:34:36.983870: Epoch 12 
2025-02-27 07:34:36.986907: Current learning rate: 0.00891 
2025-02-27 07:36:00.059771: train_loss -0.9604 
2025-02-27 07:36:00.065402: val_loss -0.9218 
2025-02-27 07:36:00.068908: Pseudo dice [np.float32(0.939)] 
2025-02-27 07:36:00.071918: Epoch time: 83.08 s 
2025-02-27 07:36:00.075427: Yayy! New best EMA pseudo Dice: 0.9286999702453613 
2025-02-27 07:36:00.944261:  
2025-02-27 07:36:00.949273: Epoch 13 
2025-02-27 07:36:00.952783: Current learning rate: 0.00882 
2025-02-27 07:37:23.671774: train_loss -0.9634 
2025-02-27 07:37:23.676843: val_loss -0.9222 
2025-02-27 07:37:23.680873: Pseudo dice [np.float32(0.9395)] 
2025-02-27 07:37:23.683882: Epoch time: 82.73 s 
2025-02-27 07:37:23.687392: Yayy! New best EMA pseudo Dice: 0.9297999739646912 
2025-02-27 07:37:24.400801:  
2025-02-27 07:37:24.405826: Epoch 14 
2025-02-27 07:37:24.409832: Current learning rate: 0.00873 
2025-02-27 07:38:47.287381: train_loss -0.9604 
2025-02-27 07:38:47.293396: val_loss -0.9187 
2025-02-27 07:38:47.296905: Pseudo dice [np.float32(0.9366)] 
2025-02-27 07:38:47.299918: Epoch time: 82.89 s 
2025-02-27 07:38:47.303428: Yayy! New best EMA pseudo Dice: 0.930400013923645 
2025-02-27 07:38:48.024631:  
2025-02-27 07:38:48.031148: Epoch 15 
2025-02-27 07:38:48.034660: Current learning rate: 0.00864 
2025-02-27 07:40:11.104814: train_loss -0.9614 
2025-02-27 07:40:11.111361: val_loss -0.9184 
2025-02-27 07:40:11.114870: Pseudo dice [np.float32(0.9364)] 
2025-02-27 07:40:11.117377: Epoch time: 83.08 s 
2025-02-27 07:40:11.121387: Yayy! New best EMA pseudo Dice: 0.9309999942779541 
2025-02-27 07:40:11.867022:  
2025-02-27 07:40:11.872200: Epoch 16 
2025-02-27 07:40:11.875755: Current learning rate: 0.00855 
2025-02-27 07:41:34.692449: train_loss -0.9616 
2025-02-27 07:41:34.698133: val_loss -0.9194 
2025-02-27 07:41:34.701154: Pseudo dice [np.float32(0.9374)] 
2025-02-27 07:41:34.704712: Epoch time: 82.83 s 
2025-02-27 07:41:34.708290: Yayy! New best EMA pseudo Dice: 0.9316999912261963 
2025-02-27 07:41:35.453378:  
2025-02-27 07:41:35.459399: Epoch 17 
2025-02-27 07:41:35.461906: Current learning rate: 0.00846 
2025-02-27 07:42:58.223383: train_loss -0.9655 
2025-02-27 07:42:58.229975: val_loss -0.9207 
2025-02-27 07:42:58.233506: Pseudo dice [np.float32(0.9386)] 
2025-02-27 07:42:58.237048: Epoch time: 82.77 s 
2025-02-27 07:42:58.240091: Yayy! New best EMA pseudo Dice: 0.9323999881744385 
2025-02-27 07:42:58.969718:  
2025-02-27 07:42:58.974511: Epoch 18 
2025-02-27 07:42:58.979023: Current learning rate: 0.00836 
2025-02-27 07:44:21.992657: train_loss -0.9673 
2025-02-27 07:44:21.998680: val_loss -0.9204 
2025-02-27 07:44:22.002820: Pseudo dice [np.float32(0.9388)] 
2025-02-27 07:44:22.006327: Epoch time: 83.02 s 
2025-02-27 07:44:22.009338: Yayy! New best EMA pseudo Dice: 0.9330000281333923 
2025-02-27 07:44:22.739786:  
2025-02-27 07:44:22.745804: Epoch 19 
2025-02-27 07:44:22.749820: Current learning rate: 0.00827 
2025-02-27 07:45:45.562263: train_loss -0.9672 
2025-02-27 07:45:45.568783: val_loss -0.9193 
2025-02-27 07:45:45.572294: Pseudo dice [np.float32(0.9378)] 
2025-02-27 07:45:45.574802: Epoch time: 82.82 s 
2025-02-27 07:45:45.578815: Yayy! New best EMA pseudo Dice: 0.9334999918937683 
2025-02-27 07:45:46.302646:  
2025-02-27 07:45:46.308186: Epoch 20 
2025-02-27 07:45:46.311748: Current learning rate: 0.00818 
2025-02-27 07:47:09.238466: train_loss -0.9663 
2025-02-27 07:47:09.244540: val_loss -0.9218 
2025-02-27 07:47:09.248054: Pseudo dice [np.float32(0.9397)] 
2025-02-27 07:47:09.251562: Epoch time: 82.94 s 
2025-02-27 07:47:09.254573: Yayy! New best EMA pseudo Dice: 0.9340999722480774 
2025-02-27 07:47:10.152549:  
2025-02-27 07:47:10.158569: Epoch 21 
2025-02-27 07:47:10.162578: Current learning rate: 0.00809 
2025-02-27 07:48:32.766739: train_loss -0.9682 
2025-02-27 07:48:32.772261: val_loss -0.9219 
2025-02-27 07:48:32.775772: Pseudo dice [np.float32(0.9404)] 
2025-02-27 07:48:32.779792: Epoch time: 82.61 s 
2025-02-27 07:48:32.782303: Yayy! New best EMA pseudo Dice: 0.9347000122070312 
2025-02-27 07:48:33.505906:  
2025-02-27 07:48:33.510926: Epoch 22 
2025-02-27 07:48:33.514444: Current learning rate: 0.008 
2025-02-27 07:49:56.297156: train_loss -0.9657 
2025-02-27 07:49:56.303668: val_loss -0.9203 
2025-02-27 07:49:56.307207: Pseudo dice [np.float32(0.939)] 
2025-02-27 07:49:56.311216: Epoch time: 82.79 s 
2025-02-27 07:49:56.314733: Yayy! New best EMA pseudo Dice: 0.9351999759674072 
2025-02-27 07:49:57.010329:  
2025-02-27 07:49:57.015949: Epoch 23 
2025-02-27 07:49:57.020003: Current learning rate: 0.0079 
2025-02-27 07:51:19.794715: train_loss -0.9679 
2025-02-27 07:51:19.800730: val_loss -0.9218 
2025-02-27 07:51:19.804745: Pseudo dice [np.float32(0.9402)] 
2025-02-27 07:51:19.808262: Epoch time: 82.78 s 
2025-02-27 07:51:19.811774: Yayy! New best EMA pseudo Dice: 0.935699999332428 
2025-02-27 07:51:20.501303:  
2025-02-27 07:51:20.507372: Epoch 24 
2025-02-27 07:51:20.510451: Current learning rate: 0.00781 
2025-02-27 07:52:43.273200: train_loss -0.9665 
2025-02-27 07:52:43.279716: val_loss -0.9205 
2025-02-27 07:52:43.283226: Pseudo dice [np.float32(0.939)] 
2025-02-27 07:52:43.286734: Epoch time: 82.77 s 
2025-02-27 07:52:43.289745: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2025-02-27 07:52:43.989528:  
2025-02-27 07:52:43.995084: Epoch 25 
2025-02-27 07:52:43.999106: Current learning rate: 0.00772 
2025-02-27 07:54:06.769844: train_loss -0.9689 
2025-02-27 07:54:06.776363: val_loss -0.917 
2025-02-27 07:54:06.779876: Pseudo dice [np.float32(0.9368)] 
2025-02-27 07:54:06.783384: Epoch time: 82.78 s 
2025-02-27 07:54:06.786395: Yayy! New best EMA pseudo Dice: 0.9361000061035156 
2025-02-27 07:54:07.486312:  
2025-02-27 07:54:07.491857: Epoch 26 
2025-02-27 07:54:07.495417: Current learning rate: 0.00763 
2025-02-27 07:55:30.281993: train_loss -0.9699 
2025-02-27 07:55:30.288009: val_loss -0.9216 
2025-02-27 07:55:30.291517: Pseudo dice [np.float32(0.9403)] 
2025-02-27 07:55:30.294527: Epoch time: 82.8 s 
2025-02-27 07:55:30.298036: Yayy! New best EMA pseudo Dice: 0.9365000128746033 
2025-02-27 07:55:30.997692:  
2025-02-27 07:55:31.003269: Epoch 27 
2025-02-27 07:55:31.007314: Current learning rate: 0.00753 
2025-02-27 07:56:53.982291: train_loss -0.9708 
2025-02-27 07:56:53.987307: val_loss -0.9186 
2025-02-27 07:56:53.990817: Pseudo dice [np.float32(0.9384)] 
2025-02-27 07:56:53.994824: Epoch time: 82.98 s 
2025-02-27 07:56:53.998337: Yayy! New best EMA pseudo Dice: 0.9366999864578247 
2025-02-27 07:56:54.705498:  
2025-02-27 07:56:54.711621: Epoch 28 
2025-02-27 07:56:54.714168: Current learning rate: 0.00744 
2025-02-27 07:58:17.896247: train_loss -0.9687 
2025-02-27 07:58:17.903281: val_loss -0.9194 
2025-02-27 07:58:17.906306: Pseudo dice [np.float32(0.9381)] 
2025-02-27 07:58:17.909814: Epoch time: 83.19 s 
2025-02-27 07:58:17.912321: Yayy! New best EMA pseudo Dice: 0.9368000030517578 
2025-02-27 07:58:18.765048:  
2025-02-27 07:58:18.771676: Epoch 29 
2025-02-27 07:58:18.774712: Current learning rate: 0.00735 
2025-02-27 07:59:41.635227: train_loss -0.9674 
2025-02-27 07:59:41.641339: val_loss -0.9181 
2025-02-27 07:59:41.644869: Pseudo dice [np.float32(0.9377)] 
2025-02-27 07:59:41.648513: Epoch time: 82.87 s 
2025-02-27 07:59:41.652556: Yayy! New best EMA pseudo Dice: 0.9369000196456909 
2025-02-27 07:59:42.362121:  
2025-02-27 07:59:42.368136: Epoch 30 
2025-02-27 07:59:42.370642: Current learning rate: 0.00725 
2025-02-27 08:01:05.299435: train_loss -0.9685 
2025-02-27 08:01:05.305446: val_loss -0.9225 
2025-02-27 08:01:05.308455: Pseudo dice [np.float32(0.9407)] 
2025-02-27 08:01:05.311963: Epoch time: 82.94 s 
2025-02-27 08:01:05.315470: Yayy! New best EMA pseudo Dice: 0.9373000264167786 
2025-02-27 08:01:06.037969:  
2025-02-27 08:01:06.043394: Epoch 31 
2025-02-27 08:01:06.046943: Current learning rate: 0.00716 
2025-02-27 08:02:29.037174: train_loss -0.966 
2025-02-27 08:02:29.043688: val_loss -0.9194 
2025-02-27 08:02:29.047196: Pseudo dice [np.float32(0.9383)] 
2025-02-27 08:02:29.049702: Epoch time: 83.0 s 
2025-02-27 08:02:29.053713: Yayy! New best EMA pseudo Dice: 0.9373999834060669 
2025-02-27 08:02:29.762106:  
2025-02-27 08:02:29.768680: Epoch 32 
2025-02-27 08:02:29.772726: Current learning rate: 0.00707 
2025-02-27 08:03:52.853548: train_loss -0.9692 
2025-02-27 08:03:52.859631: val_loss -0.9196 
2025-02-27 08:03:52.863664: Pseudo dice [np.float32(0.9387)] 
2025-02-27 08:03:52.867206: Epoch time: 83.09 s 
2025-02-27 08:03:52.871265: Yayy! New best EMA pseudo Dice: 0.9375 
2025-02-27 08:03:53.588802:  
2025-02-27 08:03:53.595440: Epoch 33 
2025-02-27 08:03:53.598484: Current learning rate: 0.00697 
2025-02-27 08:05:16.659814: train_loss -0.9709 
2025-02-27 08:05:16.666396: val_loss -0.9204 
2025-02-27 08:05:16.670426: Pseudo dice [np.float32(0.9394)] 
2025-02-27 08:05:16.673989: Epoch time: 83.07 s 
2025-02-27 08:05:16.677518: Yayy! New best EMA pseudo Dice: 0.9376999735832214 
2025-02-27 08:05:17.393936:  
2025-02-27 08:05:17.398947: Epoch 34 
2025-02-27 08:05:17.404965: Current learning rate: 0.00688 
2025-02-27 08:06:40.245592: train_loss -0.97 
2025-02-27 08:06:40.252118: val_loss -0.9216 
2025-02-27 08:06:40.256629: Pseudo dice [np.float32(0.9401)] 
2025-02-27 08:06:40.260641: Epoch time: 82.85 s 
2025-02-27 08:06:40.264148: Yayy! New best EMA pseudo Dice: 0.9379000067710876 
2025-02-27 08:06:40.995433:  
2025-02-27 08:06:41.001667: Epoch 35 
2025-02-27 08:06:41.005713: Current learning rate: 0.00679 
2025-02-27 08:08:04.082082: train_loss -0.9694 
2025-02-27 08:08:04.089146: val_loss -0.9209 
2025-02-27 08:08:04.092678: Pseudo dice [np.float32(0.9394)] 
2025-02-27 08:08:04.095711: Epoch time: 83.09 s 
2025-02-27 08:08:04.100356: Yayy! New best EMA pseudo Dice: 0.9380999803543091 
2025-02-27 08:08:04.833948:  
2025-02-27 08:08:04.841537: Epoch 36 
2025-02-27 08:08:04.845659: Current learning rate: 0.00669 
2025-02-27 08:09:27.808010: train_loss -0.9708 
2025-02-27 08:09:27.815529: val_loss -0.9209 
2025-02-27 08:09:27.819536: Pseudo dice [np.float32(0.9401)] 
2025-02-27 08:09:27.823045: Epoch time: 82.97 s 
2025-02-27 08:09:27.826553: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-02-27 08:09:28.715778:  
2025-02-27 08:09:28.722296: Epoch 37 
2025-02-27 08:09:28.725801: Current learning rate: 0.0066 
2025-02-27 08:10:51.582228: train_loss -0.9707 
2025-02-27 08:10:51.588245: val_loss -0.9206 
2025-02-27 08:10:51.592257: Pseudo dice [np.float32(0.94)] 
2025-02-27 08:10:51.595766: Epoch time: 82.87 s 
2025-02-27 08:10:51.599273: Yayy! New best EMA pseudo Dice: 0.9384999871253967 
2025-02-27 08:10:52.322619:  
2025-02-27 08:10:52.328194: Epoch 38 
2025-02-27 08:10:52.333353: Current learning rate: 0.0065 
2025-02-27 08:12:15.302155: train_loss -0.9727 
2025-02-27 08:12:15.307667: val_loss -0.9186 
2025-02-27 08:12:15.312176: Pseudo dice [np.float32(0.9388)] 
2025-02-27 08:12:15.316191: Epoch time: 82.98 s 
2025-02-27 08:12:15.320197: Yayy! New best EMA pseudo Dice: 0.9384999871253967 
2025-02-27 08:12:16.068274:  
2025-02-27 08:12:16.074364: Epoch 39 
2025-02-27 08:12:16.078433: Current learning rate: 0.00641 
2025-02-27 08:13:39.044054: train_loss -0.9691 
2025-02-27 08:13:39.051076: val_loss -0.918 
2025-02-27 08:13:39.055090: Pseudo dice [np.float32(0.9376)] 
2025-02-27 08:13:39.058595: Epoch time: 82.98 s 
2025-02-27 08:13:39.637051:  
2025-02-27 08:13:39.642638: Epoch 40 
2025-02-27 08:13:39.647223: Current learning rate: 0.00631 
2025-02-27 08:15:02.725657: train_loss -0.972 
2025-02-27 08:15:02.732175: val_loss -0.92 
2025-02-27 08:15:02.736187: Pseudo dice [np.float32(0.9394)] 
2025-02-27 08:15:02.739698: Epoch time: 83.09 s 
2025-02-27 08:15:02.743717: Yayy! New best EMA pseudo Dice: 0.9384999871253967 
2025-02-27 08:15:03.495166:  
2025-02-27 08:15:03.500721: Epoch 41 
2025-02-27 08:15:03.505871: Current learning rate: 0.00622 
2025-02-27 08:16:26.486562: train_loss -0.9731 
2025-02-27 08:16:26.492104: val_loss -0.9189 
2025-02-27 08:16:26.496128: Pseudo dice [np.float32(0.9393)] 
2025-02-27 08:16:26.499670: Epoch time: 82.99 s 
2025-02-27 08:16:26.503700: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-02-27 08:16:27.232570:  
2025-02-27 08:16:27.238214: Epoch 42 
2025-02-27 08:16:27.243264: Current learning rate: 0.00612 
2025-02-27 08:17:50.198648: train_loss -0.9697 
2025-02-27 08:17:50.203718: val_loss -0.9181 
2025-02-27 08:17:50.208890: Pseudo dice [np.float32(0.9374)] 
2025-02-27 08:17:50.211596: Epoch time: 82.97 s 
2025-02-27 08:17:50.749921:  
2025-02-27 08:17:50.756488: Epoch 43 
2025-02-27 08:17:50.760041: Current learning rate: 0.00603 
2025-02-27 08:19:13.793136: train_loss -0.9687 
2025-02-27 08:19:13.799219: val_loss -0.9211 
2025-02-27 08:19:13.803231: Pseudo dice [np.float32(0.9396)] 
2025-02-27 08:19:13.806744: Epoch time: 83.04 s 
2025-02-27 08:19:14.350806:  
2025-02-27 08:19:14.356362: Epoch 44 
2025-02-27 08:19:14.361532: Current learning rate: 0.00593 
2025-02-27 08:20:37.441822: train_loss -0.973 
2025-02-27 08:20:37.447989: val_loss -0.9189 
2025-02-27 08:20:37.452046: Pseudo dice [np.float32(0.9389)] 
2025-02-27 08:20:37.455604: Epoch time: 83.09 s 
2025-02-27 08:20:37.458246: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-02-27 08:20:38.331254:  
2025-02-27 08:20:38.336242: Epoch 45 
2025-02-27 08:20:38.340754: Current learning rate: 0.00584 
2025-02-27 08:22:01.175401: train_loss -0.9742 
2025-02-27 08:22:01.181924: val_loss -0.9177 
2025-02-27 08:22:01.185933: Pseudo dice [np.float32(0.9389)] 
2025-02-27 08:22:01.189446: Epoch time: 82.85 s 
2025-02-27 08:22:01.192952: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-02-27 08:22:01.908128:  
2025-02-27 08:22:01.912426: Epoch 46 
2025-02-27 08:22:01.915438: Current learning rate: 0.00574 
2025-02-27 08:23:24.897480: train_loss -0.9715 
2025-02-27 08:23:24.904074: val_loss -0.9197 
2025-02-27 08:23:24.907084: Pseudo dice [np.float32(0.9397)] 
2025-02-27 08:23:24.910594: Epoch time: 82.99 s 
2025-02-27 08:23:24.914104: Yayy! New best EMA pseudo Dice: 0.9387000203132629 
2025-02-27 08:23:25.614076:  
2025-02-27 08:23:25.619615: Epoch 47 
2025-02-27 08:23:25.623162: Current learning rate: 0.00565 
2025-02-27 08:24:48.461518: train_loss -0.9748 
2025-02-27 08:24:48.467547: val_loss -0.9182 
2025-02-27 08:24:48.471060: Pseudo dice [np.float32(0.939)] 
2025-02-27 08:24:48.474078: Epoch time: 82.85 s 
2025-02-27 08:24:48.477588: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-02-27 08:24:49.206388:  
2025-02-27 08:24:49.212415: Epoch 48 
2025-02-27 08:24:49.215927: Current learning rate: 0.00555 
2025-02-27 08:26:12.136429: train_loss -0.9748 
2025-02-27 08:26:12.141969: val_loss -0.9182 
2025-02-27 08:26:12.145981: Pseudo dice [np.float32(0.9391)] 
2025-02-27 08:26:12.149490: Epoch time: 82.93 s 
2025-02-27 08:26:12.153504: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-02-27 08:26:12.860712:  
2025-02-27 08:26:12.866272: Epoch 49 
2025-02-27 08:26:12.870334: Current learning rate: 0.00546 
2025-02-27 08:27:35.728012: train_loss -0.9738 
2025-02-27 08:27:35.734557: val_loss -0.9185 
2025-02-27 08:27:35.738570: Pseudo dice [np.float32(0.939)] 
2025-02-27 08:27:35.742084: Epoch time: 82.87 s 
2025-02-27 08:27:35.893142: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-02-27 08:27:36.605373:  
2025-02-27 08:27:36.611532: Epoch 50 
2025-02-27 08:27:36.615045: Current learning rate: 0.00536 
2025-02-27 08:28:59.809826: train_loss -0.9756 
2025-02-27 08:28:59.815978: val_loss -0.9188 
2025-02-27 08:28:59.819563: Pseudo dice [np.float32(0.9398)] 
2025-02-27 08:28:59.824109: Epoch time: 83.2 s 
2025-02-27 08:28:59.827160: Yayy! New best EMA pseudo Dice: 0.9388999938964844 
2025-02-27 08:29:00.542332:  
2025-02-27 08:29:00.548351: Epoch 51 
2025-02-27 08:29:00.552357: Current learning rate: 0.00526 
2025-02-27 08:30:23.365139: train_loss -0.9752 
2025-02-27 08:30:23.371660: val_loss -0.9175 
2025-02-27 08:30:23.375668: Pseudo dice [np.float32(0.9387)] 
2025-02-27 08:30:23.379180: Epoch time: 82.82 s 
2025-02-27 08:30:23.923197:  
2025-02-27 08:30:23.929298: Epoch 52 
2025-02-27 08:30:23.933357: Current learning rate: 0.00517 
2025-02-27 08:31:46.769035: train_loss -0.9741 
2025-02-27 08:31:46.774696: val_loss -0.9194 
2025-02-27 08:31:46.778733: Pseudo dice [np.float32(0.9399)] 
2025-02-27 08:31:46.782749: Epoch time: 82.85 s 
2025-02-27 08:31:46.786768: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-02-27 08:31:47.513938:  
2025-02-27 08:31:47.520455: Epoch 53 
2025-02-27 08:31:47.526475: Current learning rate: 0.00507 
2025-02-27 08:33:10.430052: train_loss -0.9757 
2025-02-27 08:33:10.435683: val_loss -0.917 
2025-02-27 08:33:10.440199: Pseudo dice [np.float32(0.9383)] 
2025-02-27 08:33:10.443236: Epoch time: 82.92 s 
2025-02-27 08:33:11.155609:  
2025-02-27 08:33:11.161123: Epoch 54 
2025-02-27 08:33:11.165635: Current learning rate: 0.00497 
2025-02-27 08:34:33.825839: train_loss -0.9755 
2025-02-27 08:34:33.830854: val_loss -0.9192 
2025-02-27 08:34:33.834863: Pseudo dice [np.float32(0.9402)] 
2025-02-27 08:34:33.838371: Epoch time: 82.67 s 
2025-02-27 08:34:33.842381: Yayy! New best EMA pseudo Dice: 0.9391000270843506 
2025-02-27 08:34:34.552075:  
2025-02-27 08:34:34.557089: Epoch 55 
2025-02-27 08:34:34.561599: Current learning rate: 0.00487 
2025-02-27 08:35:57.339223: train_loss -0.9762 
2025-02-27 08:35:57.345755: val_loss -0.9172 
2025-02-27 08:35:57.349772: Pseudo dice [np.float32(0.939)] 
2025-02-27 08:35:57.353278: Epoch time: 82.79 s 
2025-02-27 08:35:57.896997:  
2025-02-27 08:35:57.903012: Epoch 56 
2025-02-27 08:35:57.906517: Current learning rate: 0.00478 
2025-02-27 08:37:20.637463: train_loss -0.9762 
2025-02-27 08:37:20.643538: val_loss -0.915 
2025-02-27 08:37:20.647201: Pseudo dice [np.float32(0.9376)] 
2025-02-27 08:37:20.650714: Epoch time: 82.74 s 
2025-02-27 08:37:21.207016:  
2025-02-27 08:37:21.212584: Epoch 57 
2025-02-27 08:37:21.217150: Current learning rate: 0.00468 
2025-02-27 08:38:44.014780: train_loss -0.9748 
2025-02-27 08:38:44.021417: val_loss -0.9184 
2025-02-27 08:38:44.024960: Pseudo dice [np.float32(0.9387)] 
2025-02-27 08:38:44.028519: Epoch time: 82.81 s 
2025-02-27 08:38:44.576190:  
2025-02-27 08:38:44.581707: Epoch 58 
2025-02-27 08:38:44.586220: Current learning rate: 0.00458 
2025-02-27 08:40:07.466913: train_loss -0.9759 
2025-02-27 08:40:07.472468: val_loss -0.9171 
2025-02-27 08:40:07.476977: Pseudo dice [np.float32(0.9389)] 
2025-02-27 08:40:07.480991: Epoch time: 82.89 s 
2025-02-27 08:40:08.051072:  
2025-02-27 08:40:08.057089: Epoch 59 
2025-02-27 08:40:08.060592: Current learning rate: 0.00448 
2025-02-27 08:41:31.019213: train_loss -0.9761 
2025-02-27 08:41:31.025009: val_loss -0.9179 
2025-02-27 08:41:31.028550: Pseudo dice [np.float32(0.9396)] 
2025-02-27 08:41:31.031060: Epoch time: 82.97 s 
2025-02-27 08:41:31.594171:  
2025-02-27 08:41:31.598706: Epoch 60 
2025-02-27 08:41:31.602275: Current learning rate: 0.00438 
2025-02-27 08:42:54.680386: train_loss -0.9747 
2025-02-27 08:42:54.686401: val_loss -0.9171 
2025-02-27 08:42:54.690411: Pseudo dice [np.float32(0.9391)] 
2025-02-27 08:42:54.693923: Epoch time: 83.09 s 
2025-02-27 08:42:55.247804:  
2025-02-27 08:42:55.254372: Epoch 61 
2025-02-27 08:42:55.257921: Current learning rate: 0.00429 
2025-02-27 08:44:18.163603: train_loss -0.9772 
2025-02-27 08:44:18.168617: val_loss -0.9184 
2025-02-27 08:44:18.173127: Pseudo dice [np.float32(0.9396)] 
2025-02-27 08:44:18.176136: Epoch time: 82.92 s 
2025-02-27 08:44:18.886967:  
2025-02-27 08:44:18.892504: Epoch 62 
2025-02-27 08:44:18.896018: Current learning rate: 0.00419 
2025-02-27 08:45:41.604595: train_loss -0.9765 
2025-02-27 08:45:41.610614: val_loss -0.9189 
2025-02-27 08:45:41.614621: Pseudo dice [np.float32(0.9405)] 
2025-02-27 08:45:41.618129: Epoch time: 82.72 s 
2025-02-27 08:45:41.620635: Yayy! New best EMA pseudo Dice: 0.9391999840736389 
2025-02-27 08:45:42.349133:  
2025-02-27 08:45:42.355189: Epoch 63 
2025-02-27 08:45:42.360889: Current learning rate: 0.00409 
2025-02-27 08:47:05.317519: train_loss -0.9765 
2025-02-27 08:47:05.323036: val_loss -0.9165 
2025-02-27 08:47:05.326544: Pseudo dice [np.float32(0.9391)] 
2025-02-27 08:47:05.330052: Epoch time: 82.97 s 
2025-02-27 08:47:05.915509:  
2025-02-27 08:47:05.921025: Epoch 64 
2025-02-27 08:47:05.924539: Current learning rate: 0.00399 
2025-02-27 08:48:28.803332: train_loss -0.9762 
2025-02-27 08:48:28.809205: val_loss -0.9184 
2025-02-27 08:48:28.812715: Pseudo dice [np.float32(0.9398)] 
2025-02-27 08:48:28.815726: Epoch time: 82.89 s 
2025-02-27 08:48:28.819239: Yayy! New best EMA pseudo Dice: 0.9391999840736389 
2025-02-27 08:48:29.572802:  
2025-02-27 08:48:29.578317: Epoch 65 
2025-02-27 08:48:29.581826: Current learning rate: 0.00389 
2025-02-27 08:49:52.379517: train_loss -0.976 
2025-02-27 08:49:52.385533: val_loss -0.9156 
2025-02-27 08:49:52.390547: Pseudo dice [np.float32(0.938)] 
2025-02-27 08:49:52.394554: Epoch time: 82.81 s 
2025-02-27 08:49:52.956870:  
2025-02-27 08:49:52.961916: Epoch 66 
2025-02-27 08:49:52.965461: Current learning rate: 0.00379 
2025-02-27 08:51:15.796401: train_loss -0.9772 
2025-02-27 08:51:15.802913: val_loss -0.9165 
2025-02-27 08:51:15.806424: Pseudo dice [np.float32(0.9391)] 
2025-02-27 08:51:15.810432: Epoch time: 82.84 s 
2025-02-27 08:51:16.363025:  
2025-02-27 08:51:16.369065: Epoch 67 
2025-02-27 08:51:16.373220: Current learning rate: 0.00369 
2025-02-27 08:52:39.188467: train_loss -0.9775 
2025-02-27 08:52:39.194484: val_loss -0.9178 
2025-02-27 08:52:39.198495: Pseudo dice [np.float32(0.9398)] 
2025-02-27 08:52:39.202003: Epoch time: 82.83 s 
2025-02-27 08:52:39.776298:  
2025-02-27 08:52:39.781841: Epoch 68 
2025-02-27 08:52:39.786381: Current learning rate: 0.00359 
2025-02-27 08:54:02.716299: train_loss -0.9773 
2025-02-27 08:54:02.722315: val_loss -0.9163 
2025-02-27 08:54:02.726329: Pseudo dice [np.float32(0.9389)] 
2025-02-27 08:54:02.729839: Epoch time: 82.94 s 
2025-02-27 08:54:03.315942:  
2025-02-27 08:54:03.321565: Epoch 69 
2025-02-27 08:54:03.325664: Current learning rate: 0.00349 
2025-02-27 08:55:26.163610: train_loss -0.9782 
2025-02-27 08:55:26.171278: val_loss -0.916 
2025-02-27 08:55:26.175313: Pseudo dice [np.float32(0.9386)] 
2025-02-27 08:55:26.178859: Epoch time: 82.85 s 
2025-02-27 08:55:26.908460:  
2025-02-27 08:55:26.914013: Epoch 70 
2025-02-27 08:55:26.918119: Current learning rate: 0.00338 
2025-02-27 08:56:49.568463: train_loss -0.9772 
2025-02-27 08:56:49.574476: val_loss -0.9154 
2025-02-27 08:56:49.578487: Pseudo dice [np.float32(0.9385)] 
2025-02-27 08:56:49.582001: Epoch time: 82.66 s 
2025-02-27 08:56:50.156875:  
2025-02-27 08:56:50.162406: Epoch 71 
2025-02-27 08:56:50.165980: Current learning rate: 0.00328 
2025-02-27 08:58:12.904619: train_loss -0.9758 
2025-02-27 08:58:12.910634: val_loss -0.9149 
2025-02-27 08:58:12.914648: Pseudo dice [np.float32(0.9381)] 
2025-02-27 08:58:12.918158: Epoch time: 82.75 s 
2025-02-27 08:58:13.483219:  
2025-02-27 08:58:13.489291: Epoch 72 
2025-02-27 08:58:13.492418: Current learning rate: 0.00318 
2025-02-27 08:59:36.296934: train_loss -0.9779 
2025-02-27 08:59:36.303450: val_loss -0.9171 
2025-02-27 08:59:36.306958: Pseudo dice [np.float32(0.9397)] 
2025-02-27 08:59:36.310967: Epoch time: 82.81 s 
2025-02-27 08:59:36.873268:  
2025-02-27 08:59:36.878837: Epoch 73 
2025-02-27 08:59:36.883387: Current learning rate: 0.00308 
2025-02-27 09:00:59.470159: train_loss -0.978 
2025-02-27 09:00:59.476072: val_loss -0.9151 
2025-02-27 09:00:59.481084: Pseudo dice [np.float32(0.9381)] 
2025-02-27 09:00:59.484595: Epoch time: 82.6 s 
2025-02-27 09:01:00.057277:  
2025-02-27 09:01:00.063949: Epoch 74 
2025-02-27 09:01:00.068017: Current learning rate: 0.00297 
2025-02-27 09:02:22.833997: train_loss -0.9773 
2025-02-27 09:02:22.841539: val_loss -0.9158 
2025-02-27 09:02:22.845551: Pseudo dice [np.float32(0.9388)] 
2025-02-27 09:02:22.850062: Epoch time: 82.78 s 
2025-02-27 09:02:23.418027:  
2025-02-27 09:02:23.423042: Epoch 75 
2025-02-27 09:02:23.427058: Current learning rate: 0.00287 
2025-02-27 09:03:46.174946: train_loss -0.9781 
2025-02-27 09:03:46.181962: val_loss -0.9162 
2025-02-27 09:03:46.184972: Pseudo dice [np.float32(0.939)] 
2025-02-27 09:03:46.189485: Epoch time: 82.76 s 
2025-02-27 09:03:46.780169:  
2025-02-27 09:03:46.787315: Epoch 76 
2025-02-27 09:03:46.790820: Current learning rate: 0.00277 
2025-02-27 09:05:09.615239: train_loss -0.9783 
2025-02-27 09:05:09.622264: val_loss -0.9163 
2025-02-27 09:05:09.626281: Pseudo dice [np.float32(0.9395)] 
2025-02-27 09:05:09.630300: Epoch time: 82.84 s 
2025-02-27 09:05:10.209448:  
2025-02-27 09:05:10.215003: Epoch 77 
2025-02-27 09:05:10.219469: Current learning rate: 0.00266 
2025-02-27 09:06:32.973407: train_loss -0.9783 
2025-02-27 09:06:32.979429: val_loss -0.9143 
2025-02-27 09:06:32.983451: Pseudo dice [np.float32(0.9382)] 
2025-02-27 09:06:32.986967: Epoch time: 82.76 s 
2025-02-27 09:06:33.728990:  
2025-02-27 09:06:33.735045: Epoch 78 
2025-02-27 09:06:33.738838: Current learning rate: 0.00256 
2025-02-27 09:07:56.426183: train_loss -0.9789 
2025-02-27 09:07:56.432341: val_loss -0.9155 
2025-02-27 09:07:56.435898: Pseudo dice [np.float32(0.9386)] 
2025-02-27 09:07:56.439945: Epoch time: 82.7 s 
2025-02-27 09:07:57.016638:  
2025-02-27 09:07:57.023272: Epoch 79 
2025-02-27 09:07:57.025835: Current learning rate: 0.00245 
2025-02-27 09:09:19.669797: train_loss -0.9786 
2025-02-27 09:09:19.676361: val_loss -0.9166 
2025-02-27 09:09:19.680379: Pseudo dice [np.float32(0.9396)] 
2025-02-27 09:09:19.684400: Epoch time: 82.65 s 
2025-02-27 09:09:20.258410:  
2025-02-27 09:09:20.263932: Epoch 80 
2025-02-27 09:09:20.268452: Current learning rate: 0.00235 
2025-02-27 09:10:43.010080: train_loss -0.979 
2025-02-27 09:10:43.015692: val_loss -0.9157 
2025-02-27 09:10:43.020224: Pseudo dice [np.float32(0.939)] 
2025-02-27 09:10:43.023735: Epoch time: 82.75 s 
2025-02-27 09:10:43.597557:  
2025-02-27 09:10:43.605618: Epoch 81 
2025-02-27 09:10:43.609182: Current learning rate: 0.00224 
2025-02-27 09:12:06.283869: train_loss -0.9791 
2025-02-27 09:12:06.290911: val_loss -0.9169 
2025-02-27 09:12:06.294996: Pseudo dice [np.float32(0.9398)] 
2025-02-27 09:12:06.299062: Epoch time: 82.69 s 
2025-02-27 09:12:06.877131:  
2025-02-27 09:12:06.883688: Epoch 82 
2025-02-27 09:12:06.888232: Current learning rate: 0.00214 
2025-02-27 09:13:29.592866: train_loss -0.979 
2025-02-27 09:13:29.598885: val_loss -0.9162 
2025-02-27 09:13:29.603899: Pseudo dice [np.float32(0.9397)] 
2025-02-27 09:13:29.607910: Epoch time: 82.72 s 
2025-02-27 09:13:30.150584:  
2025-02-27 09:13:30.156687: Epoch 83 
2025-02-27 09:13:30.160768: Current learning rate: 0.00203 
2025-02-27 09:14:52.834581: train_loss -0.9786 
2025-02-27 09:14:52.841298: val_loss -0.9163 
2025-02-27 09:14:52.845723: Pseudo dice [np.float32(0.9394)] 
2025-02-27 09:14:52.849732: Epoch time: 82.69 s 
2025-02-27 09:14:53.395104:  
2025-02-27 09:14:53.401181: Epoch 84 
2025-02-27 09:14:53.404708: Current learning rate: 0.00192 
2025-02-27 09:16:16.008599: train_loss -0.9784 
2025-02-27 09:16:16.015147: val_loss -0.9144 
2025-02-27 09:16:16.018796: Pseudo dice [np.float32(0.9385)] 
2025-02-27 09:16:16.022820: Epoch time: 82.62 s 
2025-02-27 09:16:16.716441:  
2025-02-27 09:16:16.721496: Epoch 85 
2025-02-27 09:16:16.725056: Current learning rate: 0.00181 
2025-02-27 09:17:39.434046: train_loss -0.9792 
2025-02-27 09:17:39.439058: val_loss -0.9139 
2025-02-27 09:17:39.442569: Pseudo dice [np.float32(0.938)] 
2025-02-27 09:17:39.446579: Epoch time: 82.72 s 
2025-02-27 09:17:39.984962:  
2025-02-27 09:17:39.991551: Epoch 86 
2025-02-27 09:17:39.995102: Current learning rate: 0.0017 
2025-02-27 09:19:02.774907: train_loss -0.9784 
2025-02-27 09:19:02.781491: val_loss -0.9147 
2025-02-27 09:19:02.785505: Pseudo dice [np.float32(0.9387)] 
2025-02-27 09:19:02.789016: Epoch time: 82.79 s 
2025-02-27 09:19:03.331171:  
2025-02-27 09:19:03.337218: Epoch 87 
2025-02-27 09:19:03.341283: Current learning rate: 0.00159 
2025-02-27 09:20:26.019860: train_loss -0.9791 
2025-02-27 09:20:26.025878: val_loss -0.9159 
2025-02-27 09:20:26.029889: Pseudo dice [np.float32(0.9391)] 
2025-02-27 09:20:26.033401: Epoch time: 82.69 s 
2025-02-27 09:20:26.584499:  
2025-02-27 09:20:26.590088: Epoch 88 
2025-02-27 09:20:26.594674: Current learning rate: 0.00148 
2025-02-27 09:21:49.236865: train_loss -0.9784 
2025-02-27 09:21:49.242978: val_loss -0.9146 
2025-02-27 09:21:49.248074: Pseudo dice [np.float32(0.939)] 
2025-02-27 09:21:49.251106: Epoch time: 82.65 s 
2025-02-27 09:21:49.791617:  
2025-02-27 09:21:49.797707: Epoch 89 
2025-02-27 09:21:49.801288: Current learning rate: 0.00137 
2025-02-27 09:23:12.572509: train_loss -0.9776 
2025-02-27 09:23:12.580572: val_loss -0.9144 
2025-02-27 09:23:12.584584: Pseudo dice [np.float32(0.9384)] 
2025-02-27 09:23:12.588095: Epoch time: 82.78 s 
2025-02-27 09:23:13.129966:  
2025-02-27 09:23:13.136621: Epoch 90 
2025-02-27 09:23:13.141193: Current learning rate: 0.00126 
2025-02-27 09:24:35.874838: train_loss -0.9794 
2025-02-27 09:24:35.881422: val_loss -0.9159 
2025-02-27 09:24:35.885490: Pseudo dice [np.float32(0.9394)] 
2025-02-27 09:24:35.889602: Epoch time: 82.74 s 
2025-02-27 09:24:36.429658:  
2025-02-27 09:24:36.435806: Epoch 91 
2025-02-27 09:24:36.438889: Current learning rate: 0.00115 
2025-02-27 09:25:59.118067: train_loss -0.9789 
2025-02-27 09:25:59.124229: val_loss -0.9148 
2025-02-27 09:25:59.128287: Pseudo dice [np.float32(0.9389)] 
2025-02-27 09:25:59.131340: Epoch time: 82.69 s 
2025-02-27 09:25:59.666021:  
2025-02-27 09:25:59.672047: Epoch 92 
2025-02-27 09:25:59.676054: Current learning rate: 0.00103 
2025-02-27 09:27:22.412856: train_loss -0.9799 
2025-02-27 09:27:22.419881: val_loss -0.9149 
2025-02-27 09:27:22.422899: Pseudo dice [np.float32(0.9389)] 
2025-02-27 09:27:22.427924: Epoch time: 82.75 s 
2025-02-27 09:27:22.964244:  
2025-02-27 09:27:22.970268: Epoch 93 
2025-02-27 09:27:22.974276: Current learning rate: 0.00091 
2025-02-27 09:28:46.111562: train_loss -0.9786 
2025-02-27 09:28:46.118587: val_loss -0.9144 
2025-02-27 09:28:46.122607: Pseudo dice [np.float32(0.9385)] 
2025-02-27 09:28:46.126617: Epoch time: 83.15 s 
2025-02-27 09:28:46.838132:  
2025-02-27 09:28:46.843258: Epoch 94 
2025-02-27 09:28:46.846333: Current learning rate: 0.00079 
2025-02-27 09:30:09.556322: train_loss -0.9791 
2025-02-27 09:30:09.564346: val_loss -0.915 
2025-02-27 09:30:09.568354: Pseudo dice [np.float32(0.9389)] 
2025-02-27 09:30:09.572871: Epoch time: 82.72 s 
2025-02-27 09:30:10.120320:  
2025-02-27 09:30:10.126958: Epoch 95 
2025-02-27 09:30:10.131049: Current learning rate: 0.00067 
2025-02-27 09:31:32.769569: train_loss -0.9801 
2025-02-27 09:31:32.775634: val_loss -0.9141 
2025-02-27 09:31:32.780144: Pseudo dice [np.float32(0.9383)] 
2025-02-27 09:31:32.784160: Epoch time: 82.65 s 
2025-02-27 09:31:33.333141:  
2025-02-27 09:31:33.339746: Epoch 96 
2025-02-27 09:31:33.343314: Current learning rate: 0.00055 
2025-02-27 09:32:55.981983: train_loss -0.9798 
2025-02-27 09:32:55.989000: val_loss -0.9157 
2025-02-27 09:32:55.993015: Pseudo dice [np.float32(0.9394)] 
2025-02-27 09:32:55.997023: Epoch time: 82.65 s 
2025-02-27 09:32:56.543293:  
2025-02-27 09:32:56.549311: Epoch 97 
2025-02-27 09:32:56.553324: Current learning rate: 0.00043 
2025-02-27 09:34:19.215222: train_loss -0.9794 
2025-02-27 09:34:19.221241: val_loss -0.9156 
2025-02-27 09:34:19.225252: Pseudo dice [np.float32(0.9394)] 
2025-02-27 09:34:19.229762: Epoch time: 82.67 s 
2025-02-27 09:34:19.782470:  
2025-02-27 09:34:19.787854: Epoch 98 
2025-02-27 09:34:19.792911: Current learning rate: 0.0003 
2025-02-27 09:35:42.529444: train_loss -0.9794 
2025-02-27 09:35:42.536026: val_loss -0.9133 
2025-02-27 09:35:42.540592: Pseudo dice [np.float32(0.9379)] 
2025-02-27 09:35:42.544186: Epoch time: 82.75 s 
2025-02-27 09:35:43.098802:  
2025-02-27 09:35:43.105433: Epoch 99 
2025-02-27 09:35:43.109983: Current learning rate: 0.00016 
2025-02-27 09:37:05.801024: train_loss -0.9786 
2025-02-27 09:37:05.807548: val_loss -0.9148 
2025-02-27 09:37:05.811559: Pseudo dice [np.float32(0.9388)] 
2025-02-27 09:37:05.815068: Epoch time: 82.7 s 
2025-02-27 09:37:06.614047: Training done. 
2025-02-27 09:37:06.666050: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-02-27 09:37:06.677053: The split file contains 5 splits. 
2025-02-27 09:37:06.683056: Desired fold for training: 0 
2025-02-27 09:37:06.688565: This split has 16 training and 4 validation cases. 
2025-02-27 09:37:06.694565: predicting la_007 
2025-02-27 09:37:06.700565: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2025-02-27 09:37:12.738819: predicting la_016 
2025-02-27 09:37:12.751821: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2025-02-27 09:37:15.107691: predicting la_021 
2025-02-27 09:37:15.117691: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2025-02-27 09:37:17.482353: predicting la_024 
2025-02-27 09:37:17.492864: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2025-02-27 09:37:26.644032: Validation complete 
2025-02-27 09:37:26.650030: Mean Validation Dice:  0.8312910718090234 
