
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-26 04:10:27.257142: do_dummy_2d_data_aug: False 
2025-02-26 04:10:27.261958: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-02-26 04:10:27.267960: The split file contains 5 splits. 
2025-02-26 04:10:27.270959: Desired fold for training: 0 
2025-02-26 04:10:27.273960: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2025-02-26 04:10:35.005150: unpacking dataset... 
2025-02-26 04:10:35.186810: unpacking done... 
2025-02-26 04:10:39.272716:  
2025-02-26 04:10:39.277729: Epoch 0 
2025-02-26 04:10:39.280238: Current learning rate: 0.01 
2025-02-26 04:11:27.715087: train_loss -0.6272 
2025-02-26 04:11:27.720641: val_loss -0.8812 
2025-02-26 04:11:27.723151: Pseudo dice [np.float32(0.9096)] 
2025-02-26 04:11:27.727162: Epoch time: 48.44 s 
2025-02-26 04:11:27.730676: Yayy! New best EMA pseudo Dice: 0.909600019454956 
2025-02-26 04:11:28.297804:  
2025-02-26 04:11:28.303374: Epoch 1 
2025-02-26 04:11:28.307460: Current learning rate: 0.00991 
2025-02-26 04:12:12.304028: train_loss -0.8758 
2025-02-26 04:12:12.310653: val_loss -0.8949 
2025-02-26 04:12:12.313695: Pseudo dice [np.float32(0.9216)] 
2025-02-26 04:12:12.316759: Epoch time: 44.01 s 
2025-02-26 04:12:12.320311: Yayy! New best EMA pseudo Dice: 0.9107999801635742 
2025-02-26 04:12:12.954284:  
2025-02-26 04:12:12.960865: Epoch 2 
2025-02-26 04:12:12.964431: Current learning rate: 0.00982 
2025-02-26 04:12:56.959895: train_loss -0.897 
2025-02-26 04:12:56.966420: val_loss -0.8791 
2025-02-26 04:12:56.969934: Pseudo dice [np.float32(0.9089)] 
2025-02-26 04:12:56.972449: Epoch time: 44.01 s 
2025-02-26 04:12:57.479300:  
2025-02-26 04:12:57.485375: Epoch 3 
2025-02-26 04:12:57.489425: Current learning rate: 0.00973 
2025-02-26 04:13:41.456601: train_loss -0.9082 
2025-02-26 04:13:41.463250: val_loss -0.9087 
2025-02-26 04:13:41.466816: Pseudo dice [np.float32(0.9288)] 
2025-02-26 04:13:41.469851: Epoch time: 43.98 s 
2025-02-26 04:13:41.472896: Yayy! New best EMA pseudo Dice: 0.9124000072479248 
2025-02-26 04:13:42.116570:  
2025-02-26 04:13:42.122659: Epoch 4 
2025-02-26 04:13:42.125705: Current learning rate: 0.00964 
2025-02-26 04:14:26.067131: train_loss -0.9182 
2025-02-26 04:14:26.072653: val_loss -0.9144 
2025-02-26 04:14:26.076166: Pseudo dice [np.float32(0.9324)] 
2025-02-26 04:14:26.080182: Epoch time: 43.95 s 
2025-02-26 04:14:26.083694: Yayy! New best EMA pseudo Dice: 0.9143999814987183 
2025-02-26 04:14:26.863992:  
2025-02-26 04:14:26.869587: Epoch 5 
2025-02-26 04:14:26.873649: Current learning rate: 0.00955 
2025-02-26 04:15:10.816185: train_loss -0.9251 
2025-02-26 04:15:10.823664: val_loss -0.9169 
2025-02-26 04:15:10.828675: Pseudo dice [np.float32(0.9341)] 
2025-02-26 04:15:10.832186: Epoch time: 43.95 s 
2025-02-26 04:15:10.834694: Yayy! New best EMA pseudo Dice: 0.9164000153541565 
2025-02-26 04:15:11.472946:  
2025-02-26 04:15:11.479138: Epoch 6 
2025-02-26 04:15:11.482189: Current learning rate: 0.00946 
2025-02-26 04:15:55.409631: train_loss -0.9356 
2025-02-26 04:15:55.414717: val_loss -0.9134 
2025-02-26 04:15:55.418758: Pseudo dice [np.float32(0.9312)] 
2025-02-26 04:15:55.422269: Epoch time: 43.94 s 
2025-02-26 04:15:55.424776: Yayy! New best EMA pseudo Dice: 0.917900025844574 
2025-02-26 04:15:56.070428:  
2025-02-26 04:15:56.076457: Epoch 7 
2025-02-26 04:15:56.080085: Current learning rate: 0.00937 
2025-02-26 04:16:40.031650: train_loss -0.9388 
2025-02-26 04:16:40.037216: val_loss -0.9173 
2025-02-26 04:16:40.040727: Pseudo dice [np.float32(0.9349)] 
2025-02-26 04:16:40.044737: Epoch time: 43.96 s 
2025-02-26 04:16:40.048254: Yayy! New best EMA pseudo Dice: 0.9196000099182129 
2025-02-26 04:16:40.701340:  
2025-02-26 04:16:40.707360: Epoch 8 
2025-02-26 04:16:40.709871: Current learning rate: 0.00928 
2025-02-26 04:17:24.653728: train_loss -0.9434 
2025-02-26 04:17:24.659755: val_loss -0.9207 
2025-02-26 04:17:24.663772: Pseudo dice [np.float32(0.9372)] 
2025-02-26 04:17:24.667282: Epoch time: 43.95 s 
2025-02-26 04:17:24.670798: Yayy! New best EMA pseudo Dice: 0.9212999939918518 
2025-02-26 04:17:25.331239:  
2025-02-26 04:17:25.337291: Epoch 9 
2025-02-26 04:17:25.341360: Current learning rate: 0.00919 
2025-02-26 04:18:09.284684: train_loss -0.9462 
2025-02-26 04:18:09.290240: val_loss -0.9153 
2025-02-26 04:18:09.293748: Pseudo dice [np.float32(0.9333)] 
2025-02-26 04:18:09.297261: Epoch time: 43.95 s 
2025-02-26 04:18:09.301276: Yayy! New best EMA pseudo Dice: 0.9225000143051147 
2025-02-26 04:18:09.940305:  
2025-02-26 04:18:09.945825: Epoch 10 
2025-02-26 04:18:09.949335: Current learning rate: 0.0091 
2025-02-26 04:18:53.975555: train_loss -0.9467 
2025-02-26 04:18:53.981822: val_loss -0.9227 
2025-02-26 04:18:53.984356: Pseudo dice [np.float32(0.9387)] 
2025-02-26 04:18:53.988406: Epoch time: 44.04 s 
2025-02-26 04:18:53.992065: Yayy! New best EMA pseudo Dice: 0.9240999817848206 
2025-02-26 04:18:54.631728:  
2025-02-26 04:18:54.636928: Epoch 11 
2025-02-26 04:18:54.641449: Current learning rate: 0.009 
2025-02-26 04:19:38.605250: train_loss -0.9433 
2025-02-26 04:19:38.611306: val_loss -0.9177 
2025-02-26 04:19:38.614864: Pseudo dice [np.float32(0.9347)] 
2025-02-26 04:19:38.618428: Epoch time: 43.97 s 
2025-02-26 04:19:38.621984: Yayy! New best EMA pseudo Dice: 0.9251999855041504 
2025-02-26 04:19:39.267915:  
2025-02-26 04:19:39.272971: Epoch 12 
2025-02-26 04:19:39.277023: Current learning rate: 0.00891 
2025-02-26 04:20:23.241029: train_loss -0.939 
2025-02-26 04:20:23.247195: val_loss -0.9192 
2025-02-26 04:20:23.250768: Pseudo dice [np.float32(0.9359)] 
2025-02-26 04:20:23.253316: Epoch time: 43.97 s 
2025-02-26 04:20:23.257347: Yayy! New best EMA pseudo Dice: 0.9262999892234802 
2025-02-26 04:20:24.048999:  
2025-02-26 04:20:24.054514: Epoch 13 
2025-02-26 04:20:24.058023: Current learning rate: 0.00882 
2025-02-26 04:21:08.038542: train_loss -0.9503 
2025-02-26 04:21:08.044590: val_loss -0.9235 
2025-02-26 04:21:08.048095: Pseudo dice [np.float32(0.9397)] 
2025-02-26 04:21:08.051104: Epoch time: 43.99 s 
2025-02-26 04:21:08.055617: Yayy! New best EMA pseudo Dice: 0.9276000261306763 
2025-02-26 04:21:08.709128:  
2025-02-26 04:21:08.714693: Epoch 14 
2025-02-26 04:21:08.718250: Current learning rate: 0.00873 
2025-02-26 04:21:52.650124: train_loss -0.9511 
2025-02-26 04:21:52.657233: val_loss -0.9202 
2025-02-26 04:21:52.659783: Pseudo dice [np.float32(0.9363)] 
2025-02-26 04:21:52.663814: Epoch time: 43.94 s 
2025-02-26 04:21:52.667923: Yayy! New best EMA pseudo Dice: 0.9284999966621399 
2025-02-26 04:21:53.335352:  
2025-02-26 04:21:53.340952: Epoch 15 
2025-02-26 04:21:53.343487: Current learning rate: 0.00864 
2025-02-26 04:22:37.258278: train_loss -0.9516 
2025-02-26 04:22:37.264886: val_loss -0.9173 
2025-02-26 04:22:37.268457: Pseudo dice [np.float32(0.9352)] 
2025-02-26 04:22:37.271988: Epoch time: 43.92 s 
2025-02-26 04:22:37.275571: Yayy! New best EMA pseudo Dice: 0.929099977016449 
2025-02-26 04:22:37.934504:  
2025-02-26 04:22:37.940021: Epoch 16 
2025-02-26 04:22:37.943530: Current learning rate: 0.00855 
2025-02-26 04:23:21.878959: train_loss -0.9515 
2025-02-26 04:23:21.884488: val_loss -0.9186 
2025-02-26 04:23:21.887998: Pseudo dice [np.float32(0.9363)] 
2025-02-26 04:23:21.892008: Epoch time: 43.95 s 
2025-02-26 04:23:21.895521: Yayy! New best EMA pseudo Dice: 0.9298999905586243 
2025-02-26 04:23:22.566228:  
2025-02-26 04:23:22.571743: Epoch 17 
2025-02-26 04:23:22.575253: Current learning rate: 0.00846 
2025-02-26 04:24:06.504065: train_loss -0.9521 
2025-02-26 04:24:06.509646: val_loss -0.9226 
2025-02-26 04:24:06.512681: Pseudo dice [np.float32(0.9389)] 
2025-02-26 04:24:06.516767: Epoch time: 43.94 s 
2025-02-26 04:24:06.520839: Yayy! New best EMA pseudo Dice: 0.9308000206947327 
2025-02-26 04:24:07.181930:  
2025-02-26 04:24:07.187948: Epoch 18 
2025-02-26 04:24:07.191456: Current learning rate: 0.00836 
2025-02-26 04:24:51.138985: train_loss -0.9575 
2025-02-26 04:24:51.145118: val_loss -0.9196 
2025-02-26 04:24:51.149169: Pseudo dice [np.float32(0.937)] 
2025-02-26 04:24:51.152724: Epoch time: 43.96 s 
2025-02-26 04:24:51.155300: Yayy! New best EMA pseudo Dice: 0.9314000010490417 
2025-02-26 04:24:51.815849:  
2025-02-26 04:24:51.821870: Epoch 19 
2025-02-26 04:24:51.825378: Current learning rate: 0.00827 
2025-02-26 04:25:35.787131: train_loss -0.958 
2025-02-26 04:25:35.792688: val_loss -0.9214 
2025-02-26 04:25:35.796787: Pseudo dice [np.float32(0.9384)] 
2025-02-26 04:25:35.800885: Epoch time: 43.97 s 
2025-02-26 04:25:35.804449: Yayy! New best EMA pseudo Dice: 0.9320999979972839 
2025-02-26 04:25:36.455929:  
2025-02-26 04:25:36.461479: Epoch 20 
2025-02-26 04:25:36.465548: Current learning rate: 0.00818 
2025-02-26 04:26:20.414281: train_loss -0.9598 
2025-02-26 04:26:20.420400: val_loss -0.9208 
2025-02-26 04:26:20.423425: Pseudo dice [np.float32(0.9372)] 
2025-02-26 04:26:20.428093: Epoch time: 43.96 s 
2025-02-26 04:26:20.431653: Yayy! New best EMA pseudo Dice: 0.9326000213623047 
2025-02-26 04:26:21.242124:  
2025-02-26 04:26:21.248163: Epoch 21 
2025-02-26 04:26:21.251788: Current learning rate: 0.00809 
2025-02-26 04:27:05.216361: train_loss -0.9522 
2025-02-26 04:27:05.222929: val_loss -0.9213 
2025-02-26 04:27:05.226472: Pseudo dice [np.float32(0.9371)] 
2025-02-26 04:27:05.230000: Epoch time: 43.98 s 
2025-02-26 04:27:05.233785: Yayy! New best EMA pseudo Dice: 0.9330999851226807 
2025-02-26 04:27:05.868608:  
2025-02-26 04:27:05.875171: Epoch 22 
2025-02-26 04:27:05.878711: Current learning rate: 0.008 
2025-02-26 04:27:49.811417: train_loss -0.9546 
2025-02-26 04:27:49.817505: val_loss -0.9193 
2025-02-26 04:27:49.820549: Pseudo dice [np.float32(0.9365)] 
2025-02-26 04:27:49.824600: Epoch time: 43.94 s 
2025-02-26 04:27:49.829301: Yayy! New best EMA pseudo Dice: 0.9333999752998352 
2025-02-26 04:27:50.463108:  
2025-02-26 04:27:50.469695: Epoch 23 
2025-02-26 04:27:50.473237: Current learning rate: 0.0079 
2025-02-26 04:28:34.396601: train_loss -0.9588 
2025-02-26 04:28:34.402718: val_loss -0.9252 
2025-02-26 04:28:34.406774: Pseudo dice [np.float32(0.9409)] 
2025-02-26 04:28:34.410411: Epoch time: 43.93 s 
2025-02-26 04:28:34.414006: Yayy! New best EMA pseudo Dice: 0.9340999722480774 
2025-02-26 04:28:35.042264:  
2025-02-26 04:28:35.048796: Epoch 24 
2025-02-26 04:28:35.052308: Current learning rate: 0.00781 
2025-02-26 04:29:18.961360: train_loss -0.9635 
2025-02-26 04:29:18.968979: val_loss -0.9217 
2025-02-26 04:29:18.972714: Pseudo dice [np.float32(0.9385)] 
2025-02-26 04:29:18.976278: Epoch time: 43.92 s 
2025-02-26 04:29:18.979872: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2025-02-26 04:29:19.618363:  
2025-02-26 04:29:19.624629: Epoch 25 
2025-02-26 04:29:19.627874: Current learning rate: 0.00772 
2025-02-26 04:30:03.580926: train_loss -0.9612 
2025-02-26 04:30:03.586519: val_loss -0.9233 
2025-02-26 04:30:03.590085: Pseudo dice [np.float32(0.9404)] 
2025-02-26 04:30:03.593165: Epoch time: 43.96 s 
2025-02-26 04:30:03.596833: Yayy! New best EMA pseudo Dice: 0.9351999759674072 
2025-02-26 04:30:04.238403:  
2025-02-26 04:30:04.243920: Epoch 26 
2025-02-26 04:30:04.247428: Current learning rate: 0.00763 
2025-02-26 04:30:48.170235: train_loss -0.9659 
2025-02-26 04:30:48.176298: val_loss -0.9225 
2025-02-26 04:30:48.180449: Pseudo dice [np.float32(0.9398)] 
2025-02-26 04:30:48.183501: Epoch time: 43.93 s 
2025-02-26 04:30:48.188083: Yayy! New best EMA pseudo Dice: 0.9355999827384949 
2025-02-26 04:30:48.827103:  
2025-02-26 04:30:48.832623: Epoch 27 
2025-02-26 04:30:48.837141: Current learning rate: 0.00753 
2025-02-26 04:31:32.808555: train_loss -0.9643 
2025-02-26 04:31:32.815166: val_loss -0.923 
2025-02-26 04:31:32.818732: Pseudo dice [np.float32(0.9397)] 
2025-02-26 04:31:32.822323: Epoch time: 43.98 s 
2025-02-26 04:31:32.826438: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2025-02-26 04:31:33.470556:  
2025-02-26 04:31:33.475875: Epoch 28 
2025-02-26 04:31:33.479910: Current learning rate: 0.00744 
2025-02-26 04:32:17.434214: train_loss -0.9656 
2025-02-26 04:32:17.442239: val_loss -0.9193 
2025-02-26 04:32:17.447256: Pseudo dice [np.float32(0.9374)] 
2025-02-26 04:32:17.450773: Epoch time: 43.96 s 
2025-02-26 04:32:17.454784: Yayy! New best EMA pseudo Dice: 0.9362000226974487 
2025-02-26 04:32:18.242394:  
2025-02-26 04:32:18.248477: Epoch 29 
2025-02-26 04:32:18.252035: Current learning rate: 0.00735 
2025-02-26 04:33:02.194229: train_loss -0.9632 
2025-02-26 04:33:02.200256: val_loss -0.9225 
2025-02-26 04:33:02.204272: Pseudo dice [np.float32(0.9392)] 
2025-02-26 04:33:02.207790: Epoch time: 43.95 s 
2025-02-26 04:33:02.211801: Yayy! New best EMA pseudo Dice: 0.9365000128746033 
2025-02-26 04:33:02.864395:  
2025-02-26 04:33:02.871013: Epoch 30 
2025-02-26 04:33:02.873566: Current learning rate: 0.00725 
2025-02-26 04:33:46.849233: train_loss -0.9617 
2025-02-26 04:33:46.854838: val_loss -0.9222 
2025-02-26 04:33:46.858440: Pseudo dice [np.float32(0.9393)] 
2025-02-26 04:33:46.863088: Epoch time: 43.98 s 
2025-02-26 04:33:46.867162: Yayy! New best EMA pseudo Dice: 0.9366999864578247 
2025-02-26 04:33:47.511711:  
2025-02-26 04:33:47.518287: Epoch 31 
2025-02-26 04:33:47.521921: Current learning rate: 0.00716 
2025-02-26 04:34:31.495723: train_loss -0.9619 
2025-02-26 04:34:31.500809: val_loss -0.9223 
2025-02-26 04:34:31.504945: Pseudo dice [np.float32(0.9394)] 
2025-02-26 04:34:31.508976: Epoch time: 43.99 s 
2025-02-26 04:34:31.514589: Yayy! New best EMA pseudo Dice: 0.9369999766349792 
2025-02-26 04:34:32.158595:  
2025-02-26 04:34:32.164635: Epoch 32 
2025-02-26 04:34:32.168284: Current learning rate: 0.00707 
2025-02-26 04:35:16.141692: train_loss -0.9671 
2025-02-26 04:35:16.148311: val_loss -0.9241 
2025-02-26 04:35:16.152357: Pseudo dice [np.float32(0.9409)] 
2025-02-26 04:35:16.155929: Epoch time: 43.98 s 
2025-02-26 04:35:16.159420: Yayy! New best EMA pseudo Dice: 0.9373999834060669 
2025-02-26 04:35:16.808574:  
2025-02-26 04:35:16.814610: Epoch 33 
2025-02-26 04:35:16.818174: Current learning rate: 0.00697 
2025-02-26 04:36:00.785684: train_loss -0.9678 
2025-02-26 04:36:00.791751: val_loss -0.9212 
2025-02-26 04:36:00.795791: Pseudo dice [np.float32(0.9387)] 
2025-02-26 04:36:00.799325: Epoch time: 43.98 s 
2025-02-26 04:36:00.801410: Yayy! New best EMA pseudo Dice: 0.9375 
2025-02-26 04:36:01.459790:  
2025-02-26 04:36:01.465826: Epoch 34 
2025-02-26 04:36:01.469966: Current learning rate: 0.00688 
2025-02-26 04:36:45.416809: train_loss -0.9682 
2025-02-26 04:36:45.422361: val_loss -0.9227 
2025-02-26 04:36:45.426506: Pseudo dice [np.float32(0.94)] 
2025-02-26 04:36:45.429561: Epoch time: 43.96 s 
2025-02-26 04:36:45.434103: Yayy! New best EMA pseudo Dice: 0.9377999901771545 
2025-02-26 04:36:46.087653:  
2025-02-26 04:36:46.094205: Epoch 35 
2025-02-26 04:36:46.097797: Current learning rate: 0.00679 
2025-02-26 04:37:30.041386: train_loss -0.9693 
2025-02-26 04:37:30.047903: val_loss -0.9205 
2025-02-26 04:37:30.051414: Pseudo dice [np.float32(0.9387)] 
2025-02-26 04:37:30.055427: Epoch time: 43.95 s 
2025-02-26 04:37:30.059938: Yayy! New best EMA pseudo Dice: 0.9379000067710876 
2025-02-26 04:37:30.862298:  
2025-02-26 04:37:30.867887: Epoch 36 
2025-02-26 04:37:30.872502: Current learning rate: 0.00669 
2025-02-26 04:38:14.818888: train_loss -0.9694 
2025-02-26 04:38:14.825006: val_loss -0.9232 
2025-02-26 04:38:14.828516: Pseudo dice [np.float32(0.9407)] 
2025-02-26 04:38:14.832532: Epoch time: 43.96 s 
2025-02-26 04:38:14.836915: Yayy! New best EMA pseudo Dice: 0.9380999803543091 
2025-02-26 04:38:15.496911:  
2025-02-26 04:38:15.503434: Epoch 37 
2025-02-26 04:38:15.506940: Current learning rate: 0.0066 
2025-02-26 04:38:59.401978: train_loss -0.9694 
2025-02-26 04:38:59.407493: val_loss -0.9223 
2025-02-26 04:38:59.411005: Pseudo dice [np.float32(0.9397)] 
2025-02-26 04:38:59.415012: Epoch time: 43.91 s 
2025-02-26 04:38:59.419526: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-02-26 04:39:00.078322:  
2025-02-26 04:39:00.083854: Epoch 38 
2025-02-26 04:39:00.088498: Current learning rate: 0.0065 
2025-02-26 04:39:44.045119: train_loss -0.9697 
2025-02-26 04:39:44.051638: val_loss -0.9219 
2025-02-26 04:39:44.056150: Pseudo dice [np.float32(0.9401)] 
2025-02-26 04:39:44.060164: Epoch time: 43.97 s 
2025-02-26 04:39:44.064267: Yayy! New best EMA pseudo Dice: 0.9384999871253967 
2025-02-26 04:39:44.719009:  
2025-02-26 04:39:44.725530: Epoch 39 
2025-02-26 04:39:44.729542: Current learning rate: 0.00641 
2025-02-26 04:40:28.670993: train_loss -0.9648 
2025-02-26 04:40:28.679042: val_loss -0.9196 
2025-02-26 04:40:28.682552: Pseudo dice [np.float32(0.9369)] 
2025-02-26 04:40:28.686566: Epoch time: 43.95 s 
2025-02-26 04:40:29.199365:  
2025-02-26 04:40:29.205001: Epoch 40 
2025-02-26 04:40:29.208621: Current learning rate: 0.00631 
2025-02-26 04:41:13.190871: train_loss -0.9683 
2025-02-26 04:41:13.197543: val_loss -0.9234 
2025-02-26 04:41:13.201121: Pseudo dice [np.float32(0.9403)] 
2025-02-26 04:41:13.204674: Epoch time: 43.99 s 
2025-02-26 04:41:13.208231: Yayy! New best EMA pseudo Dice: 0.9384999871253967 
2025-02-26 04:41:13.871147:  
2025-02-26 04:41:13.877735: Epoch 41 
2025-02-26 04:41:13.880780: Current learning rate: 0.00622 
2025-02-26 04:41:57.853268: train_loss -0.9682 
2025-02-26 04:41:57.859283: val_loss -0.9207 
2025-02-26 04:41:57.863297: Pseudo dice [np.float32(0.9391)] 
2025-02-26 04:41:57.866814: Epoch time: 43.98 s 
2025-02-26 04:41:57.871829: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-02-26 04:41:58.503167:  
2025-02-26 04:41:58.509184: Epoch 42 
2025-02-26 04:41:58.513198: Current learning rate: 0.00612 
2025-02-26 04:42:42.496065: train_loss -0.9673 
2025-02-26 04:42:42.501603: val_loss -0.9235 
2025-02-26 04:42:42.506114: Pseudo dice [np.float32(0.9407)] 
2025-02-26 04:42:42.510130: Epoch time: 43.99 s 
2025-02-26 04:42:42.514140: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-02-26 04:42:43.149435:  
2025-02-26 04:42:43.155450: Epoch 43 
2025-02-26 04:42:43.158956: Current learning rate: 0.00603 
2025-02-26 04:43:27.107399: train_loss -0.968 
2025-02-26 04:43:27.112496: val_loss -0.9212 
2025-02-26 04:43:27.117559: Pseudo dice [np.float32(0.9391)] 
2025-02-26 04:43:27.121113: Epoch time: 43.96 s 
2025-02-26 04:43:27.125124: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-02-26 04:43:27.903166:  
2025-02-26 04:43:27.909684: Epoch 44 
2025-02-26 04:43:27.913192: Current learning rate: 0.00593 
2025-02-26 04:44:11.868359: train_loss -0.9709 
2025-02-26 04:44:11.875453: val_loss -0.9206 
2025-02-26 04:44:11.879963: Pseudo dice [np.float32(0.9391)] 
2025-02-26 04:44:11.882972: Epoch time: 43.97 s 
2025-02-26 04:44:11.887991: Yayy! New best EMA pseudo Dice: 0.9388999938964844 
2025-02-26 04:44:12.519812:  
2025-02-26 04:44:12.525829: Epoch 45 
2025-02-26 04:44:12.529338: Current learning rate: 0.00584 
2025-02-26 04:44:56.469023: train_loss -0.9703 
2025-02-26 04:44:56.475035: val_loss -0.9244 
2025-02-26 04:44:56.479050: Pseudo dice [np.float32(0.9415)] 
2025-02-26 04:44:56.483067: Epoch time: 43.95 s 
2025-02-26 04:44:56.486583: Yayy! New best EMA pseudo Dice: 0.9391000270843506 
2025-02-26 04:44:57.116943:  
2025-02-26 04:44:57.122465: Epoch 46 
2025-02-26 04:44:57.125974: Current learning rate: 0.00574 
2025-02-26 04:45:41.082989: train_loss -0.9711 
2025-02-26 04:45:41.089109: val_loss -0.9199 
2025-02-26 04:45:41.091664: Pseudo dice [np.float32(0.9385)] 
2025-02-26 04:45:41.095237: Epoch time: 43.97 s 
2025-02-26 04:45:41.577381:  
2025-02-26 04:45:41.583457: Epoch 47 
2025-02-26 04:45:41.586976: Current learning rate: 0.00565 
2025-02-26 04:46:25.585211: train_loss -0.971 
2025-02-26 04:46:25.591063: val_loss -0.9208 
2025-02-26 04:46:25.593623: Pseudo dice [np.float32(0.9395)] 
2025-02-26 04:46:25.596653: Epoch time: 44.01 s 
2025-02-26 04:46:26.075251:  
2025-02-26 04:46:26.080825: Epoch 48 
2025-02-26 04:46:26.084898: Current learning rate: 0.00555 
2025-02-26 04:47:10.046482: train_loss -0.9718 
2025-02-26 04:47:10.053035: val_loss -0.9213 
2025-02-26 04:47:10.056551: Pseudo dice [np.float32(0.9403)] 
2025-02-26 04:47:10.060062: Epoch time: 43.97 s 
2025-02-26 04:47:10.064076: Yayy! New best EMA pseudo Dice: 0.9391999840736389 
2025-02-26 04:47:10.710513:  
2025-02-26 04:47:10.716556: Epoch 49 
2025-02-26 04:47:10.719602: Current learning rate: 0.00546 
2025-02-26 04:47:54.637718: train_loss -0.9674 
2025-02-26 04:47:54.644743: val_loss -0.9218 
2025-02-26 04:47:54.647751: Pseudo dice [np.float32(0.9396)] 
2025-02-26 04:47:54.651267: Epoch time: 43.93 s 
2025-02-26 04:47:54.795435: Yayy! New best EMA pseudo Dice: 0.939300000667572 
2025-02-26 04:47:55.433960:  
2025-02-26 04:47:55.439501: Epoch 50 
2025-02-26 04:47:55.443552: Current learning rate: 0.00536 
2025-02-26 04:48:39.338429: train_loss -0.97 
2025-02-26 04:48:39.344448: val_loss -0.9203 
2025-02-26 04:48:39.347954: Pseudo dice [np.float32(0.9391)] 
2025-02-26 04:48:39.350963: Epoch time: 43.9 s 
2025-02-26 04:48:39.835999:  
2025-02-26 04:48:39.841566: Epoch 51 
2025-02-26 04:48:39.845121: Current learning rate: 0.00526 
2025-02-26 04:49:23.813390: train_loss -0.9712 
2025-02-26 04:49:23.820441: val_loss -0.9199 
2025-02-26 04:49:23.823481: Pseudo dice [np.float32(0.9388)] 
2025-02-26 04:49:23.827012: Epoch time: 43.98 s 
2025-02-26 04:49:24.312770:  
2025-02-26 04:49:24.318285: Epoch 52 
2025-02-26 04:49:24.321797: Current learning rate: 0.00517 
2025-02-26 04:50:08.333021: train_loss -0.9713 
2025-02-26 04:50:08.338034: val_loss -0.9192 
2025-02-26 04:50:08.341545: Pseudo dice [np.float32(0.9386)] 
2025-02-26 04:50:08.345055: Epoch time: 44.02 s 
2025-02-26 04:50:08.830846:  
2025-02-26 04:50:08.836412: Epoch 53 
2025-02-26 04:50:08.840069: Current learning rate: 0.00507 
2025-02-26 04:50:52.771206: train_loss -0.9736 
2025-02-26 04:50:52.777778: val_loss -0.9185 
2025-02-26 04:50:52.780311: Pseudo dice [np.float32(0.9383)] 
2025-02-26 04:50:52.783860: Epoch time: 43.94 s 
2025-02-26 04:50:53.267873:  
2025-02-26 04:50:53.273936: Epoch 54 
2025-02-26 04:50:53.277036: Current learning rate: 0.00497 
2025-02-26 04:51:37.240474: train_loss -0.9725 
2025-02-26 04:51:37.246627: val_loss -0.9204 
2025-02-26 04:51:37.249405: Pseudo dice [np.float32(0.9392)] 
2025-02-26 04:51:37.252920: Epoch time: 43.97 s 
2025-02-26 04:51:37.741398:  
2025-02-26 04:51:37.746958: Epoch 55 
2025-02-26 04:51:37.750582: Current learning rate: 0.00487 
2025-02-26 04:52:21.710147: train_loss -0.9735 
2025-02-26 04:52:21.715161: val_loss -0.9177 
2025-02-26 04:52:21.718705: Pseudo dice [np.float32(0.9376)] 
2025-02-26 04:52:21.722215: Epoch time: 43.97 s 
2025-02-26 04:52:22.215130:  
2025-02-26 04:52:22.220666: Epoch 56 
2025-02-26 04:52:22.224207: Current learning rate: 0.00478 
2025-02-26 04:53:06.160041: train_loss -0.972 
2025-02-26 04:53:06.166556: val_loss -0.919 
2025-02-26 04:53:06.170069: Pseudo dice [np.float32(0.9386)] 
2025-02-26 04:53:06.173574: Epoch time: 43.95 s 
2025-02-26 04:53:06.666537:  
2025-02-26 04:53:06.671590: Epoch 57 
2025-02-26 04:53:06.675173: Current learning rate: 0.00468 
2025-02-26 04:53:50.592769: train_loss -0.9737 
2025-02-26 04:53:50.597788: val_loss -0.9199 
2025-02-26 04:53:50.601407: Pseudo dice [np.float32(0.9389)] 
2025-02-26 04:53:50.604961: Epoch time: 43.93 s 
2025-02-26 04:53:51.097337:  
2025-02-26 04:53:51.102376: Epoch 58 
2025-02-26 04:53:51.105425: Current learning rate: 0.00458 
2025-02-26 04:54:35.057213: train_loss -0.973 
2025-02-26 04:54:35.062729: val_loss -0.9204 
2025-02-26 04:54:35.066238: Pseudo dice [np.float32(0.9394)] 
2025-02-26 04:54:35.069748: Epoch time: 43.96 s 
2025-02-26 04:54:35.564217:  
2025-02-26 04:54:35.569761: Epoch 59 
2025-02-26 04:54:35.572479: Current learning rate: 0.00448 
2025-02-26 04:55:19.511549: train_loss -0.9753 
2025-02-26 04:55:19.517638: val_loss -0.9196 
2025-02-26 04:55:19.520681: Pseudo dice [np.float32(0.9394)] 
2025-02-26 04:55:19.524223: Epoch time: 43.95 s 
2025-02-26 04:55:20.158684:  
2025-02-26 04:55:20.164240: Epoch 60 
2025-02-26 04:55:20.167893: Current learning rate: 0.00438 
2025-02-26 04:56:04.138612: train_loss -0.9731 
2025-02-26 04:56:04.144282: val_loss -0.9214 
2025-02-26 04:56:04.147848: Pseudo dice [np.float32(0.9399)] 
2025-02-26 04:56:04.150384: Epoch time: 43.98 s 
2025-02-26 04:56:04.644816:  
2025-02-26 04:56:04.650832: Epoch 61 
2025-02-26 04:56:04.654847: Current learning rate: 0.00429 
2025-02-26 04:56:48.546043: train_loss -0.9761 
2025-02-26 04:56:48.551560: val_loss -0.9186 
2025-02-26 04:56:48.555069: Pseudo dice [np.float32(0.9391)] 
2025-02-26 04:56:48.557577: Epoch time: 43.9 s 
2025-02-26 04:56:49.050525:  
2025-02-26 04:56:49.056041: Epoch 62 
2025-02-26 04:56:49.058548: Current learning rate: 0.00419 
2025-02-26 04:57:32.988498: train_loss -0.9739 
2025-02-26 04:57:32.994607: val_loss -0.92 
2025-02-26 04:57:32.997133: Pseudo dice [np.float32(0.9399)] 
2025-02-26 04:57:33.001273: Epoch time: 43.94 s 
2025-02-26 04:57:33.493543:  
2025-02-26 04:57:33.498563: Epoch 63 
2025-02-26 04:57:33.502073: Current learning rate: 0.00409 
2025-02-26 04:58:17.414292: train_loss -0.9739 
2025-02-26 04:58:17.419818: val_loss -0.9226 
2025-02-26 04:58:17.422852: Pseudo dice [np.float32(0.9414)] 
2025-02-26 04:58:17.426863: Epoch time: 43.92 s 
2025-02-26 04:58:17.430375: Yayy! New best EMA pseudo Dice: 0.9394000172615051 
2025-02-26 04:58:18.079478:  
2025-02-26 04:58:18.085514: Epoch 64 
2025-02-26 04:58:18.088172: Current learning rate: 0.00399 
2025-02-26 04:59:02.036960: train_loss -0.9751 
2025-02-26 04:59:02.042580: val_loss -0.9203 
2025-02-26 04:59:02.045132: Pseudo dice [np.float32(0.9399)] 
2025-02-26 04:59:02.048650: Epoch time: 43.96 s 
2025-02-26 04:59:02.052156: Yayy! New best EMA pseudo Dice: 0.9394000172615051 
2025-02-26 04:59:02.705148:  
2025-02-26 04:59:02.710208: Epoch 65 
2025-02-26 04:59:02.713768: Current learning rate: 0.00389 
2025-02-26 04:59:46.881882: train_loss -0.9745 
2025-02-26 04:59:46.887403: val_loss -0.9211 
2025-02-26 04:59:46.890915: Pseudo dice [np.float32(0.9404)] 
2025-02-26 04:59:46.893424: Epoch time: 44.18 s 
2025-02-26 04:59:46.898183: Yayy! New best EMA pseudo Dice: 0.9394999742507935 
2025-02-26 04:59:47.550071:  
2025-02-26 04:59:47.555637: Epoch 66 
2025-02-26 04:59:47.559263: Current learning rate: 0.00379 
2025-02-26 05:00:31.628032: train_loss -0.9756 
2025-02-26 05:00:31.633636: val_loss -0.9209 
2025-02-26 05:00:31.637710: Pseudo dice [np.float32(0.9405)] 
2025-02-26 05:00:31.640855: Epoch time: 44.08 s 
2025-02-26 05:00:31.644415: Yayy! New best EMA pseudo Dice: 0.9395999908447266 
2025-02-26 05:00:32.293635:  
2025-02-26 05:00:32.299672: Epoch 67 
2025-02-26 05:00:32.302773: Current learning rate: 0.00369 
2025-02-26 05:01:16.232084: train_loss -0.9737 
2025-02-26 05:01:16.238625: val_loss -0.9188 
2025-02-26 05:01:16.241634: Pseudo dice [np.float32(0.939)] 
2025-02-26 05:01:16.245143: Epoch time: 43.94 s 
2025-02-26 05:01:16.891377:  
2025-02-26 05:01:16.897417: Epoch 68 
2025-02-26 05:01:16.899926: Current learning rate: 0.00359 
2025-02-26 05:02:00.826536: train_loss -0.9758 
2025-02-26 05:02:00.832149: val_loss -0.9204 
2025-02-26 05:02:00.835720: Pseudo dice [np.float32(0.9401)] 
2025-02-26 05:02:00.838261: Epoch time: 43.94 s 
2025-02-26 05:02:01.345458:  
2025-02-26 05:02:01.351024: Epoch 69 
2025-02-26 05:02:01.356040: Current learning rate: 0.00349 
2025-02-26 05:02:45.283790: train_loss -0.9751 
2025-02-26 05:02:45.289929: val_loss -0.9178 
2025-02-26 05:02:45.292970: Pseudo dice [np.float32(0.9383)] 
2025-02-26 05:02:45.296166: Epoch time: 43.94 s 
2025-02-26 05:02:45.792461:  
2025-02-26 05:02:45.798551: Epoch 70 
2025-02-26 05:02:45.801608: Current learning rate: 0.00338 
2025-02-26 05:03:29.743175: train_loss -0.9763 
2025-02-26 05:03:29.750702: val_loss -0.9205 
2025-02-26 05:03:29.754217: Pseudo dice [np.float32(0.9402)] 
2025-02-26 05:03:29.757725: Epoch time: 43.95 s 
2025-02-26 05:03:30.263846:  
2025-02-26 05:03:30.269391: Epoch 71 
2025-02-26 05:03:30.271939: Current learning rate: 0.00328 
2025-02-26 05:04:14.224220: train_loss -0.9763 
2025-02-26 05:04:14.229810: val_loss -0.9218 
2025-02-26 05:04:14.233328: Pseudo dice [np.float32(0.9412)] 
2025-02-26 05:04:14.236838: Epoch time: 43.96 s 
2025-02-26 05:04:14.239857: Yayy! New best EMA pseudo Dice: 0.9397000074386597 
2025-02-26 05:04:14.898097:  
2025-02-26 05:04:14.903678: Epoch 72 
2025-02-26 05:04:14.906741: Current learning rate: 0.00318 
2025-02-26 05:04:58.881003: train_loss -0.9749 
2025-02-26 05:04:58.887063: val_loss -0.9183 
2025-02-26 05:04:58.890129: Pseudo dice [np.float32(0.9389)] 
2025-02-26 05:04:58.893685: Epoch time: 43.98 s 
2025-02-26 05:04:59.396709:  
2025-02-26 05:04:59.402296: Epoch 73 
2025-02-26 05:04:59.405885: Current learning rate: 0.00308 
2025-02-26 05:05:43.370493: train_loss -0.975 
2025-02-26 05:05:43.376521: val_loss -0.918 
2025-02-26 05:05:43.380025: Pseudo dice [np.float32(0.9386)] 
2025-02-26 05:05:43.383035: Epoch time: 43.97 s 
2025-02-26 05:05:43.888436:  
2025-02-26 05:05:43.894071: Epoch 74 
2025-02-26 05:05:43.897583: Current learning rate: 0.00297 
2025-02-26 05:06:27.814291: train_loss -0.9746 
2025-02-26 05:06:27.820310: val_loss -0.9194 
2025-02-26 05:06:27.822824: Pseudo dice [np.float32(0.9398)] 
2025-02-26 05:06:27.829353: Epoch time: 43.93 s 
2025-02-26 05:06:28.330798:  
2025-02-26 05:06:28.336313: Epoch 75 
2025-02-26 05:06:28.338824: Current learning rate: 0.00287 
2025-02-26 05:07:12.275239: train_loss -0.9769 
2025-02-26 05:07:12.282712: val_loss -0.9206 
2025-02-26 05:07:12.286223: Pseudo dice [np.float32(0.9407)] 
2025-02-26 05:07:12.288737: Epoch time: 43.95 s 
2025-02-26 05:07:12.937590:  
2025-02-26 05:07:12.942602: Epoch 76 
2025-02-26 05:07:12.946117: Current learning rate: 0.00277 
2025-02-26 05:07:56.860481: train_loss -0.977 
2025-02-26 05:07:56.865495: val_loss -0.9184 
2025-02-26 05:07:56.869013: Pseudo dice [np.float32(0.9391)] 
2025-02-26 05:07:56.872525: Epoch time: 43.92 s 
2025-02-26 05:07:57.372151:  
2025-02-26 05:07:57.377281: Epoch 77 
2025-02-26 05:07:57.380806: Current learning rate: 0.00266 
2025-02-26 05:08:41.302049: train_loss -0.9767 
2025-02-26 05:08:41.308057: val_loss -0.92 
2025-02-26 05:08:41.311071: Pseudo dice [np.float32(0.9401)] 
2025-02-26 05:08:41.314580: Epoch time: 43.93 s 
2025-02-26 05:08:41.826971:  
2025-02-26 05:08:41.832490: Epoch 78 
2025-02-26 05:08:41.834998: Current learning rate: 0.00256 
2025-02-26 05:09:25.753859: train_loss -0.9763 
2025-02-26 05:09:25.760401: val_loss -0.9224 
2025-02-26 05:09:25.763410: Pseudo dice [np.float32(0.9421)] 
2025-02-26 05:09:25.766918: Epoch time: 43.93 s 
2025-02-26 05:09:25.770930: Yayy! New best EMA pseudo Dice: 0.9398999810218811 
2025-02-26 05:09:26.439335:  
2025-02-26 05:09:26.444391: Epoch 79 
2025-02-26 05:09:26.448419: Current learning rate: 0.00245 
2025-02-26 05:10:10.350815: train_loss -0.9763 
2025-02-26 05:10:10.356453: val_loss -0.9186 
2025-02-26 05:10:10.360054: Pseudo dice [np.float32(0.9393)] 
2025-02-26 05:10:10.363071: Epoch time: 43.91 s 
2025-02-26 05:10:10.874139:  
2025-02-26 05:10:10.879653: Epoch 80 
2025-02-26 05:10:10.882160: Current learning rate: 0.00235 
2025-02-26 05:10:54.820044: train_loss -0.9758 
2025-02-26 05:10:54.826065: val_loss -0.9195 
2025-02-26 05:10:54.828573: Pseudo dice [np.float32(0.9399)] 
2025-02-26 05:10:54.835089: Epoch time: 43.95 s 
2025-02-26 05:10:55.344380:  
2025-02-26 05:10:55.349931: Epoch 81 
2025-02-26 05:10:55.352437: Current learning rate: 0.00224 
2025-02-26 05:11:39.333727: train_loss -0.9763 
2025-02-26 05:11:39.339294: val_loss -0.921 
2025-02-26 05:11:39.342363: Pseudo dice [np.float32(0.9409)] 
2025-02-26 05:11:39.345905: Epoch time: 43.99 s 
2025-02-26 05:11:39.348960: Yayy! New best EMA pseudo Dice: 0.9399999976158142 
2025-02-26 05:11:40.016028:  
2025-02-26 05:11:40.021030: Epoch 82 
2025-02-26 05:11:40.024543: Current learning rate: 0.00214 
2025-02-26 05:12:23.961011: train_loss -0.9762 
2025-02-26 05:12:23.966635: val_loss -0.9206 
2025-02-26 05:12:23.970169: Pseudo dice [np.float32(0.9411)] 
2025-02-26 05:12:23.973716: Epoch time: 43.95 s 
2025-02-26 05:12:23.977284: Yayy! New best EMA pseudo Dice: 0.9401000142097473 
2025-02-26 05:12:24.757812:  
2025-02-26 05:12:24.763503: Epoch 83 
2025-02-26 05:12:24.766527: Current learning rate: 0.00203 
2025-02-26 05:13:08.679160: train_loss -0.9768 
2025-02-26 05:13:08.685284: val_loss -0.9201 
2025-02-26 05:13:08.688832: Pseudo dice [np.float32(0.9404)] 
2025-02-26 05:13:08.691861: Epoch time: 43.92 s 
2025-02-26 05:13:08.695507: Yayy! New best EMA pseudo Dice: 0.9401000142097473 
2025-02-26 05:13:09.331647:  
2025-02-26 05:13:09.337718: Epoch 84 
2025-02-26 05:13:09.340781: Current learning rate: 0.00192 
2025-02-26 05:13:53.248849: train_loss -0.9772 
2025-02-26 05:13:53.256505: val_loss -0.9199 
2025-02-26 05:13:53.260095: Pseudo dice [np.float32(0.9403)] 
2025-02-26 05:13:53.263163: Epoch time: 43.92 s 
2025-02-26 05:13:53.266716: Yayy! New best EMA pseudo Dice: 0.9401000142097473 
2025-02-26 05:13:53.910166:  
2025-02-26 05:13:53.915730: Epoch 85 
2025-02-26 05:13:53.919262: Current learning rate: 0.00181 
2025-02-26 05:14:37.834243: train_loss -0.9778 
2025-02-26 05:14:37.840806: val_loss -0.9177 
2025-02-26 05:14:37.843349: Pseudo dice [np.float32(0.9387)] 
2025-02-26 05:14:37.845884: Epoch time: 43.92 s 
2025-02-26 05:14:38.329303:  
2025-02-26 05:14:38.335408: Epoch 86 
2025-02-26 05:14:38.338974: Current learning rate: 0.0017 
2025-02-26 05:15:22.288912: train_loss -0.9773 
2025-02-26 05:15:22.294928: val_loss -0.9197 
2025-02-26 05:15:22.298438: Pseudo dice [np.float32(0.9405)] 
2025-02-26 05:15:22.301448: Epoch time: 43.96 s 
2025-02-26 05:15:22.787035:  
2025-02-26 05:15:22.793109: Epoch 87 
2025-02-26 05:15:22.795741: Current learning rate: 0.00159 
2025-02-26 05:16:06.708951: train_loss -0.978 
2025-02-26 05:16:06.714846: val_loss -0.9194 
2025-02-26 05:16:06.719021: Pseudo dice [np.float32(0.9401)] 
2025-02-26 05:16:06.721572: Epoch time: 43.92 s 
2025-02-26 05:16:07.198195:  
2025-02-26 05:16:07.203719: Epoch 88 
2025-02-26 05:16:07.207227: Current learning rate: 0.00148 
2025-02-26 05:16:51.150811: train_loss -0.977 
2025-02-26 05:16:51.157960: val_loss -0.9208 
2025-02-26 05:16:51.160471: Pseudo dice [np.float32(0.9413)] 
2025-02-26 05:16:51.164036: Epoch time: 43.95 s 
2025-02-26 05:16:51.166489: Yayy! New best EMA pseudo Dice: 0.9401999711990356 
2025-02-26 05:16:51.801814:  
2025-02-26 05:16:51.807895: Epoch 89 
2025-02-26 05:16:51.810951: Current learning rate: 0.00137 
2025-02-26 05:17:35.750869: train_loss -0.9799 
2025-02-26 05:17:35.757955: val_loss -0.9212 
2025-02-26 05:17:35.761055: Pseudo dice [np.float32(0.9417)] 
2025-02-26 05:17:35.764577: Epoch time: 43.95 s 
2025-02-26 05:17:35.768264: Yayy! New best EMA pseudo Dice: 0.9402999877929688 
2025-02-26 05:17:36.401370:  
2025-02-26 05:17:36.406885: Epoch 90 
2025-02-26 05:17:36.410394: Current learning rate: 0.00126 
2025-02-26 05:18:20.331882: train_loss -0.9774 
2025-02-26 05:18:20.337898: val_loss -0.918 
2025-02-26 05:18:20.340405: Pseudo dice [np.float32(0.9391)] 
2025-02-26 05:18:20.344423: Epoch time: 43.93 s 
2025-02-26 05:18:20.823650:  
2025-02-26 05:18:20.828743: Epoch 91 
2025-02-26 05:18:20.832255: Current learning rate: 0.00115 
2025-02-26 05:19:04.773149: train_loss -0.9772 
2025-02-26 05:19:04.778815: val_loss -0.9208 
2025-02-26 05:19:04.781858: Pseudo dice [np.float32(0.9413)] 
2025-02-26 05:19:04.785383: Epoch time: 43.95 s 
2025-02-26 05:19:05.420090:  
2025-02-26 05:19:05.426252: Epoch 92 
2025-02-26 05:19:05.429370: Current learning rate: 0.00103 
2025-02-26 05:19:49.338599: train_loss -0.979 
2025-02-26 05:19:49.345174: val_loss -0.9184 
2025-02-26 05:19:49.348244: Pseudo dice [np.float32(0.9395)] 
2025-02-26 05:19:49.351928: Epoch time: 43.92 s 
2025-02-26 05:19:49.831024:  
2025-02-26 05:19:49.836587: Epoch 93 
2025-02-26 05:19:49.840634: Current learning rate: 0.00091 
2025-02-26 05:20:33.790474: train_loss -0.9781 
2025-02-26 05:20:33.795990: val_loss -0.9179 
2025-02-26 05:20:33.799501: Pseudo dice [np.float32(0.9395)] 
2025-02-26 05:20:33.803510: Epoch time: 43.96 s 
2025-02-26 05:20:34.286205:  
2025-02-26 05:20:34.291750: Epoch 94 
2025-02-26 05:20:34.295868: Current learning rate: 0.00079 
2025-02-26 05:21:18.245284: train_loss -0.9784 
2025-02-26 05:21:18.250820: val_loss -0.9191 
2025-02-26 05:21:18.254332: Pseudo dice [np.float32(0.94)] 
2025-02-26 05:21:18.257840: Epoch time: 43.96 s 
2025-02-26 05:21:18.738575:  
2025-02-26 05:21:18.744617: Epoch 95 
2025-02-26 05:21:18.748154: Current learning rate: 0.00067 
2025-02-26 05:22:02.688791: train_loss -0.9776 
2025-02-26 05:22:02.694797: val_loss -0.9185 
2025-02-26 05:22:02.697807: Pseudo dice [np.float32(0.94)] 
2025-02-26 05:22:02.701319: Epoch time: 43.95 s 
2025-02-26 05:22:03.180870:  
2025-02-26 05:22:03.186920: Epoch 96 
2025-02-26 05:22:03.189978: Current learning rate: 0.00055 
2025-02-26 05:22:47.128495: train_loss -0.9757 
2025-02-26 05:22:47.134598: val_loss -0.9172 
2025-02-26 05:22:47.137718: Pseudo dice [np.float32(0.9388)] 
2025-02-26 05:22:47.141250: Epoch time: 43.95 s 
2025-02-26 05:22:47.631807:  
2025-02-26 05:22:47.637347: Epoch 97 
2025-02-26 05:22:47.640898: Current learning rate: 0.00043 
2025-02-26 05:23:31.591229: train_loss -0.9788 
2025-02-26 05:23:31.596841: val_loss -0.9178 
2025-02-26 05:23:31.600370: Pseudo dice [np.float32(0.9397)] 
2025-02-26 05:23:31.604028: Epoch time: 43.96 s 
2025-02-26 05:23:32.092074:  
2025-02-26 05:23:32.098232: Epoch 98 
2025-02-26 05:23:32.102277: Current learning rate: 0.0003 
2025-02-26 05:24:16.022968: train_loss -0.9784 
2025-02-26 05:24:16.028599: val_loss -0.9163 
2025-02-26 05:24:16.032108: Pseudo dice [np.float32(0.9385)] 
2025-02-26 05:24:16.036123: Epoch time: 43.93 s 
2025-02-26 05:24:16.519901:  
2025-02-26 05:24:16.525422: Epoch 99 
2025-02-26 05:24:16.528932: Current learning rate: 0.00016 
2025-02-26 05:25:00.454863: train_loss -0.9794 
2025-02-26 05:25:00.461469: val_loss -0.9198 
2025-02-26 05:25:00.464586: Pseudo dice [np.float32(0.9406)] 
2025-02-26 05:25:00.468164: Epoch time: 43.94 s 
2025-02-26 05:25:01.299904: Training done. 
2025-02-26 05:25:01.325905: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-02-26 05:25:01.332904: The split file contains 5 splits. 
2025-02-26 05:25:01.337907: Desired fold for training: 0 
2025-02-26 05:25:01.343905: This split has 16 training and 4 validation cases. 
2025-02-26 05:25:01.349905: predicting la_007 
2025-02-26 05:25:01.356905: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2025-02-26 05:25:07.383554: predicting la_016 
2025-02-26 05:25:07.395555: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2025-02-26 05:25:09.738153: predicting la_021 
2025-02-26 05:25:09.747154: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2025-02-26 05:25:12.091213: predicting la_024 
2025-02-26 05:25:12.100213: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2025-02-26 05:25:21.175405: Validation complete 
2025-02-26 05:25:21.181404: Mean Validation Dice:  0.8320725265248571 
