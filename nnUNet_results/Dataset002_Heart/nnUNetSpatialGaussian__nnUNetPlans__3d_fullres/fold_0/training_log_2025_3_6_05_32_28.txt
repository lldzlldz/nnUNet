
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-06 05:32:28.982933: do_dummy_2d_data_aug: False 
2025-03-06 05:32:28.984756: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-06 05:32:28.990758: The split file contains 5 splits. 
2025-03-06 05:32:28.993758: Desired fold for training: 0 
2025-03-06 05:32:28.996758: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2025-03-06 05:32:38.941176: unpacking dataset... 
2025-03-06 05:32:39.151962: unpacking done... 
2025-03-06 05:32:43.549742:  
2025-03-06 05:32:43.555291: Epoch 0 
2025-03-06 05:32:43.557883: Current learning rate: 0.01 
2025-03-06 05:34:12.934141: train_loss -0.6595 
2025-03-06 05:34:12.940159: val_loss -0.8911 
2025-03-06 05:34:12.944172: Pseudo dice [np.float32(0.9182)] 
2025-03-06 05:34:12.946681: Epoch time: 89.38 s 
2025-03-06 05:34:12.950192: Yayy! New best EMA pseudo Dice: 0.9182000160217285 
2025-03-06 05:34:13.577703:  
2025-03-06 05:34:13.581731: Epoch 1 
2025-03-06 05:34:13.585778: Current learning rate: 0.00991 
2025-03-06 05:35:35.028465: train_loss -0.8888 
2025-03-06 05:35:35.034202: val_loss -0.9027 
2025-03-06 05:35:35.037282: Pseudo dice [np.float32(0.9243)] 
2025-03-06 05:35:35.039835: Epoch time: 81.45 s 
2025-03-06 05:35:35.042404: Yayy! New best EMA pseudo Dice: 0.9187999963760376 
2025-03-06 05:35:35.760069:  
2025-03-06 05:35:35.765642: Epoch 2 
2025-03-06 05:35:35.768192: Current learning rate: 0.00982 
2025-03-06 05:36:57.256511: train_loss -0.9105 
2025-03-06 05:36:57.262525: val_loss -0.9089 
2025-03-06 05:36:57.266032: Pseudo dice [np.float32(0.929)] 
2025-03-06 05:36:57.269040: Epoch time: 81.5 s 
2025-03-06 05:36:57.272550: Yayy! New best EMA pseudo Dice: 0.9197999835014343 
2025-03-06 05:36:58.016794:  
2025-03-06 05:36:58.022334: Epoch 3 
2025-03-06 05:36:58.025364: Current learning rate: 0.00973 
2025-03-06 05:38:19.479383: train_loss -0.926 
2025-03-06 05:38:19.485899: val_loss -0.9138 
2025-03-06 05:38:19.488406: Pseudo dice [np.float32(0.9321)] 
2025-03-06 05:38:19.491916: Epoch time: 81.46 s 
2025-03-06 05:38:19.495423: Yayy! New best EMA pseudo Dice: 0.9210000038146973 
2025-03-06 05:38:20.205714:  
2025-03-06 05:38:20.211229: Epoch 4 
2025-03-06 05:38:20.214738: Current learning rate: 0.00964 
2025-03-06 05:39:41.703234: train_loss -0.9344 
2025-03-06 05:39:41.709279: val_loss -0.9168 
2025-03-06 05:39:41.711787: Pseudo dice [np.float32(0.9339)] 
2025-03-06 05:39:41.715796: Epoch time: 81.5 s 
2025-03-06 05:39:41.719306: Yayy! New best EMA pseudo Dice: 0.9222999811172485 
2025-03-06 05:39:42.588825:  
2025-03-06 05:39:42.594838: Epoch 5 
2025-03-06 05:39:42.597847: Current learning rate: 0.00955 
2025-03-06 05:41:04.046517: train_loss -0.9401 
2025-03-06 05:41:04.051528: val_loss -0.9178 
2025-03-06 05:41:04.055537: Pseudo dice [np.float32(0.9345)] 
2025-03-06 05:41:04.058048: Epoch time: 81.46 s 
2025-03-06 05:41:04.061561: Yayy! New best EMA pseudo Dice: 0.9235000014305115 
2025-03-06 05:41:04.780469:  
2025-03-06 05:41:04.786098: Epoch 6 
2025-03-06 05:41:04.789120: Current learning rate: 0.00946 
2025-03-06 05:42:26.200140: train_loss -0.9434 
2025-03-06 05:42:26.205659: val_loss -0.9184 
2025-03-06 05:42:26.209166: Pseudo dice [np.float32(0.9352)] 
2025-03-06 05:42:26.212176: Epoch time: 81.42 s 
2025-03-06 05:42:26.214682: Yayy! New best EMA pseudo Dice: 0.9247000217437744 
2025-03-06 05:42:26.934067:  
2025-03-06 05:42:26.938105: Epoch 7 
2025-03-06 05:42:26.942115: Current learning rate: 0.00937 
2025-03-06 05:43:48.407124: train_loss -0.9465 
2025-03-06 05:43:48.413139: val_loss -0.9204 
2025-03-06 05:43:48.416647: Pseudo dice [np.float32(0.9367)] 
2025-03-06 05:43:48.419666: Epoch time: 81.47 s 
2025-03-06 05:43:48.422174: Yayy! New best EMA pseudo Dice: 0.9258999824523926 
2025-03-06 05:43:49.157520:  
2025-03-06 05:43:49.163545: Epoch 8 
2025-03-06 05:43:49.167053: Current learning rate: 0.00928 
2025-03-06 05:45:10.653710: train_loss -0.953 
2025-03-06 05:45:10.659311: val_loss -0.921 
2025-03-06 05:45:10.661820: Pseudo dice [np.float32(0.9376)] 
2025-03-06 05:45:10.665333: Epoch time: 81.5 s 
2025-03-06 05:45:10.667841: Yayy! New best EMA pseudo Dice: 0.9271000027656555 
2025-03-06 05:45:11.409137:  
2025-03-06 05:45:11.414700: Epoch 9 
2025-03-06 05:45:11.417233: Current learning rate: 0.00919 
2025-03-06 05:46:32.900362: train_loss -0.9576 
2025-03-06 05:46:32.906060: val_loss -0.9206 
2025-03-06 05:46:32.909566: Pseudo dice [np.float32(0.9373)] 
2025-03-06 05:46:32.912573: Epoch time: 81.49 s 
2025-03-06 05:46:32.915180: Yayy! New best EMA pseudo Dice: 0.9280999898910522 
2025-03-06 05:46:33.612234:  
2025-03-06 05:46:33.618362: Epoch 10 
2025-03-06 05:46:33.620872: Current learning rate: 0.0091 
2025-03-06 05:47:55.044227: train_loss -0.958 
2025-03-06 05:47:55.050240: val_loss -0.9204 
2025-03-06 05:47:55.054255: Pseudo dice [np.float32(0.9375)] 
2025-03-06 05:47:55.056762: Epoch time: 81.43 s 
2025-03-06 05:47:55.060272: Yayy! New best EMA pseudo Dice: 0.9290000200271606 
2025-03-06 05:47:55.777541:  
2025-03-06 05:47:55.783575: Epoch 11 
2025-03-06 05:47:55.786080: Current learning rate: 0.009 
2025-03-06 05:49:17.177272: train_loss -0.9591 
2025-03-06 05:49:17.183285: val_loss -0.9218 
2025-03-06 05:49:17.186298: Pseudo dice [np.float32(0.9381)] 
2025-03-06 05:49:17.189811: Epoch time: 81.4 s 
2025-03-06 05:49:17.193319: Yayy! New best EMA pseudo Dice: 0.9298999905586243 
2025-03-06 05:49:17.908121:  
2025-03-06 05:49:17.913147: Epoch 12 
2025-03-06 05:49:17.915699: Current learning rate: 0.00891 
2025-03-06 05:50:39.402950: train_loss -0.9579 
2025-03-06 05:50:39.408024: val_loss -0.9194 
2025-03-06 05:50:39.411575: Pseudo dice [np.float32(0.9366)] 
2025-03-06 05:50:39.414628: Epoch time: 81.5 s 
2025-03-06 05:50:39.418134: Yayy! New best EMA pseudo Dice: 0.9305999875068665 
2025-03-06 05:50:40.289859:  
2025-03-06 05:50:40.294621: Epoch 13 
2025-03-06 05:50:40.298129: Current learning rate: 0.00882 
2025-03-06 05:52:01.761256: train_loss -0.9562 
2025-03-06 05:52:01.768773: val_loss -0.9201 
2025-03-06 05:52:01.772282: Pseudo dice [np.float32(0.9369)] 
2025-03-06 05:52:01.774788: Epoch time: 81.47 s 
2025-03-06 05:52:01.778797: Yayy! New best EMA pseudo Dice: 0.9312000274658203 
2025-03-06 05:52:02.502929:  
2025-03-06 05:52:02.507961: Epoch 14 
2025-03-06 05:52:02.510478: Current learning rate: 0.00873 
2025-03-06 05:53:23.961638: train_loss -0.9585 
2025-03-06 05:53:23.967170: val_loss -0.9215 
2025-03-06 05:53:23.970191: Pseudo dice [np.float32(0.9378)] 
2025-03-06 05:53:23.973709: Epoch time: 81.46 s 
2025-03-06 05:53:23.976727: Yayy! New best EMA pseudo Dice: 0.9319000244140625 
2025-03-06 05:53:24.711043:  
2025-03-06 05:53:24.718033: Epoch 15 
2025-03-06 05:53:24.721085: Current learning rate: 0.00864 
2025-03-06 05:54:46.157677: train_loss -0.9621 
2025-03-06 05:54:46.162717: val_loss -0.9199 
2025-03-06 05:54:46.165251: Pseudo dice [np.float32(0.9372)] 
2025-03-06 05:54:46.169296: Epoch time: 81.45 s 
2025-03-06 05:54:46.172394: Yayy! New best EMA pseudo Dice: 0.9323999881744385 
2025-03-06 05:54:46.898181:  
2025-03-06 05:54:46.903699: Epoch 16 
2025-03-06 05:54:46.906206: Current learning rate: 0.00855 
2025-03-06 05:56:08.400201: train_loss -0.9573 
2025-03-06 05:56:08.405212: val_loss -0.9184 
2025-03-06 05:56:08.408723: Pseudo dice [np.float32(0.9346)] 
2025-03-06 05:56:08.412229: Epoch time: 81.5 s 
2025-03-06 05:56:08.415238: Yayy! New best EMA pseudo Dice: 0.932699978351593 
2025-03-06 05:56:09.151110:  
2025-03-06 05:56:09.156678: Epoch 17 
2025-03-06 05:56:09.160730: Current learning rate: 0.00846 
2025-03-06 05:57:30.598061: train_loss -0.955 
2025-03-06 05:57:30.603576: val_loss -0.9214 
2025-03-06 05:57:30.607086: Pseudo dice [np.float32(0.9376)] 
2025-03-06 05:57:30.609592: Epoch time: 81.45 s 
2025-03-06 05:57:30.613603: Yayy! New best EMA pseudo Dice: 0.9332000017166138 
2025-03-06 05:57:31.338036:  
2025-03-06 05:57:31.343616: Epoch 18 
2025-03-06 05:57:31.346081: Current learning rate: 0.00836 
2025-03-06 05:58:52.926274: train_loss -0.9591 
2025-03-06 05:58:52.932365: val_loss -0.9212 
2025-03-06 05:58:52.934876: Pseudo dice [np.float32(0.9377)] 
2025-03-06 05:58:52.938436: Epoch time: 81.59 s 
2025-03-06 05:58:52.941992: Yayy! New best EMA pseudo Dice: 0.9336000084877014 
2025-03-06 05:58:53.667886:  
2025-03-06 05:58:53.673955: Epoch 19 
2025-03-06 05:58:53.677465: Current learning rate: 0.00827 
2025-03-06 06:00:15.206217: train_loss -0.9598 
2025-03-06 06:00:15.211229: val_loss -0.923 
2025-03-06 06:00:15.214739: Pseudo dice [np.float32(0.9391)] 
2025-03-06 06:00:15.218246: Epoch time: 81.54 s 
2025-03-06 06:00:15.221256: Yayy! New best EMA pseudo Dice: 0.9341999888420105 
2025-03-06 06:00:16.097913:  
2025-03-06 06:00:16.102974: Epoch 20 
2025-03-06 06:00:16.106528: Current learning rate: 0.00818 
2025-03-06 06:01:37.506930: train_loss -0.9644 
2025-03-06 06:01:37.511941: val_loss -0.9213 
2025-03-06 06:01:37.515485: Pseudo dice [np.float32(0.9382)] 
2025-03-06 06:01:37.518992: Epoch time: 81.41 s 
2025-03-06 06:01:37.522002: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2025-03-06 06:01:38.254735:  
2025-03-06 06:01:38.261319: Epoch 21 
2025-03-06 06:01:38.263864: Current learning rate: 0.00809 
2025-03-06 06:02:59.711165: train_loss -0.9672 
2025-03-06 06:02:59.716180: val_loss -0.9214 
2025-03-06 06:02:59.719699: Pseudo dice [np.float32(0.939)] 
2025-03-06 06:02:59.723709: Epoch time: 81.46 s 
2025-03-06 06:02:59.726255: Yayy! New best EMA pseudo Dice: 0.9350000023841858 
2025-03-06 06:03:00.426513:  
2025-03-06 06:03:00.433173: Epoch 22 
2025-03-06 06:03:00.435725: Current learning rate: 0.008 
2025-03-06 06:04:21.881988: train_loss -0.9648 
2025-03-06 06:04:21.889021: val_loss -0.9227 
2025-03-06 06:04:21.892533: Pseudo dice [np.float32(0.9392)] 
2025-03-06 06:04:21.896038: Epoch time: 81.46 s 
2025-03-06 06:04:21.899046: Yayy! New best EMA pseudo Dice: 0.9354000091552734 
2025-03-06 06:04:22.598825:  
2025-03-06 06:04:22.603837: Epoch 23 
2025-03-06 06:04:22.607348: Current learning rate: 0.0079 
2025-03-06 06:05:44.028184: train_loss -0.9655 
2025-03-06 06:05:44.034703: val_loss -0.9217 
2025-03-06 06:05:44.038212: Pseudo dice [np.float32(0.9391)] 
2025-03-06 06:05:44.040723: Epoch time: 81.43 s 
2025-03-06 06:05:44.044751: Yayy! New best EMA pseudo Dice: 0.9358000159263611 
2025-03-06 06:05:44.739451:  
2025-03-06 06:05:44.745549: Epoch 24 
2025-03-06 06:05:44.748688: Current learning rate: 0.00781 
2025-03-06 06:07:06.171055: train_loss -0.9697 
2025-03-06 06:07:06.178573: val_loss -0.918 
2025-03-06 06:07:06.182089: Pseudo dice [np.float32(0.9371)] 
2025-03-06 06:07:06.184597: Epoch time: 81.43 s 
2025-03-06 06:07:06.188606: Yayy! New best EMA pseudo Dice: 0.9358999729156494 
2025-03-06 06:07:06.899575:  
2025-03-06 06:07:06.905618: Epoch 25 
2025-03-06 06:07:06.908668: Current learning rate: 0.00772 
2025-03-06 06:08:28.384718: train_loss -0.9697 
2025-03-06 06:08:28.390728: val_loss -0.9215 
2025-03-06 06:08:28.394734: Pseudo dice [np.float32(0.9394)] 
2025-03-06 06:08:28.398239: Epoch time: 81.49 s 
2025-03-06 06:08:28.400748: Yayy! New best EMA pseudo Dice: 0.9362999796867371 
2025-03-06 06:08:29.100418:  
2025-03-06 06:08:29.104431: Epoch 26 
2025-03-06 06:08:29.108446: Current learning rate: 0.00763 
2025-03-06 06:09:50.607509: train_loss -0.9674 
2025-03-06 06:09:50.613614: val_loss -0.9178 
2025-03-06 06:09:50.617124: Pseudo dice [np.float32(0.9357)] 
2025-03-06 06:09:50.619633: Epoch time: 81.51 s 
2025-03-06 06:09:51.159203:  
2025-03-06 06:09:51.164719: Epoch 27 
2025-03-06 06:09:51.168229: Current learning rate: 0.00753 
2025-03-06 06:11:12.593125: train_loss -0.9659 
2025-03-06 06:11:12.599145: val_loss -0.9197 
2025-03-06 06:11:12.603160: Pseudo dice [np.float32(0.9376)] 
2025-03-06 06:11:12.605666: Epoch time: 81.43 s 
2025-03-06 06:11:12.609184: Yayy! New best EMA pseudo Dice: 0.9363999962806702 
2025-03-06 06:11:13.454138:  
2025-03-06 06:11:13.459770: Epoch 28 
2025-03-06 06:11:13.463346: Current learning rate: 0.00744 
2025-03-06 06:12:34.921467: train_loss -0.9697 
2025-03-06 06:12:34.927492: val_loss -0.9229 
2025-03-06 06:12:34.930003: Pseudo dice [np.float32(0.9405)] 
2025-03-06 06:12:34.934012: Epoch time: 81.47 s 
2025-03-06 06:12:34.936517: Yayy! New best EMA pseudo Dice: 0.9368000030517578 
2025-03-06 06:12:35.637175:  
2025-03-06 06:12:35.642773: Epoch 29 
2025-03-06 06:12:35.646339: Current learning rate: 0.00735 
2025-03-06 06:13:57.092526: train_loss -0.9706 
2025-03-06 06:13:57.098548: val_loss -0.9207 
2025-03-06 06:13:57.102075: Pseudo dice [np.float32(0.9391)] 
2025-03-06 06:13:57.105337: Epoch time: 81.46 s 
2025-03-06 06:13:57.107842: Yayy! New best EMA pseudo Dice: 0.9369999766349792 
2025-03-06 06:13:57.816874:  
2025-03-06 06:13:57.822425: Epoch 30 
2025-03-06 06:13:57.825992: Current learning rate: 0.00725 
2025-03-06 06:15:19.272179: train_loss -0.9718 
2025-03-06 06:15:19.277694: val_loss -0.9196 
2025-03-06 06:15:19.280202: Pseudo dice [np.float32(0.9389)] 
2025-03-06 06:15:19.283711: Epoch time: 81.46 s 
2025-03-06 06:15:19.286218: Yayy! New best EMA pseudo Dice: 0.9372000098228455 
2025-03-06 06:15:20.012790:  
2025-03-06 06:15:20.017841: Epoch 31 
2025-03-06 06:15:20.021414: Current learning rate: 0.00716 
2025-03-06 06:16:41.533466: train_loss -0.969 
2025-03-06 06:16:41.540071: val_loss -0.9206 
2025-03-06 06:16:41.542577: Pseudo dice [np.float32(0.9395)] 
2025-03-06 06:16:41.546086: Epoch time: 81.52 s 
2025-03-06 06:16:41.548594: Yayy! New best EMA pseudo Dice: 0.9373999834060669 
2025-03-06 06:16:42.265805:  
2025-03-06 06:16:42.271319: Epoch 32 
2025-03-06 06:16:42.273825: Current learning rate: 0.00707 
2025-03-06 06:18:03.776885: train_loss -0.9718 
2025-03-06 06:18:03.782901: val_loss -0.9209 
2025-03-06 06:18:03.786408: Pseudo dice [np.float32(0.9391)] 
2025-03-06 06:18:03.789418: Epoch time: 81.51 s 
2025-03-06 06:18:03.791925: Yayy! New best EMA pseudo Dice: 0.9376000165939331 
2025-03-06 06:18:04.498212:  
2025-03-06 06:18:04.503265: Epoch 33 
2025-03-06 06:18:04.506321: Current learning rate: 0.00697 
2025-03-06 06:19:25.992686: train_loss -0.9622 
2025-03-06 06:19:25.997749: val_loss -0.9165 
2025-03-06 06:19:26.001790: Pseudo dice [np.float32(0.9339)] 
2025-03-06 06:19:26.004323: Epoch time: 81.49 s 
2025-03-06 06:19:26.566708:  
2025-03-06 06:19:26.572737: Epoch 34 
2025-03-06 06:19:26.576246: Current learning rate: 0.00688 
2025-03-06 06:20:48.113235: train_loss -0.9663 
2025-03-06 06:20:48.118246: val_loss -0.9215 
2025-03-06 06:20:48.122256: Pseudo dice [np.float32(0.9393)] 
2025-03-06 06:20:48.124762: Epoch time: 81.55 s 
2025-03-06 06:20:48.834275:  
2025-03-06 06:20:48.839323: Epoch 35 
2025-03-06 06:20:48.843392: Current learning rate: 0.00679 
2025-03-06 06:22:10.305758: train_loss -0.9694 
2025-03-06 06:22:10.310929: val_loss -0.921 
2025-03-06 06:22:10.314480: Pseudo dice [np.float32(0.9396)] 
2025-03-06 06:22:10.317029: Epoch time: 81.47 s 
2025-03-06 06:22:10.319043: Yayy! New best EMA pseudo Dice: 0.9376999735832214 
2025-03-06 06:22:11.038937:  
2025-03-06 06:22:11.043993: Epoch 36 
2025-03-06 06:22:11.047502: Current learning rate: 0.00669 
2025-03-06 06:23:32.694800: train_loss -0.9714 
2025-03-06 06:23:32.699845: val_loss -0.9207 
2025-03-06 06:23:32.703357: Pseudo dice [np.float32(0.9393)] 
2025-03-06 06:23:32.707367: Epoch time: 81.66 s 
2025-03-06 06:23:32.709873: Yayy! New best EMA pseudo Dice: 0.9377999901771545 
2025-03-06 06:23:33.437505:  
2025-03-06 06:23:33.443516: Epoch 37 
2025-03-06 06:23:33.446525: Current learning rate: 0.0066 
2025-03-06 06:24:54.919933: train_loss -0.9709 
2025-03-06 06:24:54.924945: val_loss -0.9211 
2025-03-06 06:24:54.928455: Pseudo dice [np.float32(0.9398)] 
2025-03-06 06:24:54.930961: Epoch time: 81.48 s 
2025-03-06 06:24:54.934973: Yayy! New best EMA pseudo Dice: 0.9380000233650208 
2025-03-06 06:24:55.665503:  
2025-03-06 06:24:55.671018: Epoch 38 
2025-03-06 06:24:55.674527: Current learning rate: 0.0065 
2025-03-06 06:26:17.116182: train_loss -0.9696 
2025-03-06 06:26:17.121193: val_loss -0.919 
2025-03-06 06:26:17.124704: Pseudo dice [np.float32(0.938)] 
2025-03-06 06:26:17.128711: Epoch time: 81.45 s 
2025-03-06 06:26:17.131216: Yayy! New best EMA pseudo Dice: 0.9380000233650208 
2025-03-06 06:26:17.859784:  
2025-03-06 06:26:17.864818: Epoch 39 
2025-03-06 06:26:17.868355: Current learning rate: 0.00641 
2025-03-06 06:27:39.355028: train_loss -0.9726 
2025-03-06 06:27:39.360039: val_loss -0.9192 
2025-03-06 06:27:39.363549: Pseudo dice [np.float32(0.9387)] 
2025-03-06 06:27:39.366055: Epoch time: 81.5 s 
2025-03-06 06:27:39.370066: Yayy! New best EMA pseudo Dice: 0.9380999803543091 
2025-03-06 06:27:40.102341:  
2025-03-06 06:27:40.108393: Epoch 40 
2025-03-06 06:27:40.111416: Current learning rate: 0.00631 
2025-03-06 06:29:01.605956: train_loss -0.9734 
2025-03-06 06:29:01.611473: val_loss -0.9191 
2025-03-06 06:29:01.614984: Pseudo dice [np.float32(0.9386)] 
2025-03-06 06:29:01.617489: Epoch time: 81.5 s 
2025-03-06 06:29:01.621506: Yayy! New best EMA pseudo Dice: 0.9380999803543091 
2025-03-06 06:29:02.350924:  
2025-03-06 06:29:02.356562: Epoch 41 
2025-03-06 06:29:02.359571: Current learning rate: 0.00622 
2025-03-06 06:30:23.905614: train_loss -0.9729 
2025-03-06 06:30:23.911484: val_loss -0.9195 
2025-03-06 06:30:23.915034: Pseudo dice [np.float32(0.9391)] 
2025-03-06 06:30:23.917540: Epoch time: 81.55 s 
2025-03-06 06:30:23.921055: Yayy! New best EMA pseudo Dice: 0.9381999969482422 
2025-03-06 06:30:24.625939:  
2025-03-06 06:30:24.630009: Epoch 42 
2025-03-06 06:30:24.633535: Current learning rate: 0.00612 
2025-03-06 06:31:46.097667: train_loss -0.9721 
2025-03-06 06:31:46.105686: val_loss -0.9193 
2025-03-06 06:31:46.110197: Pseudo dice [np.float32(0.9387)] 
2025-03-06 06:31:46.113205: Epoch time: 81.47 s 
2025-03-06 06:31:46.116715: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-03-06 06:31:46.979053:  
2025-03-06 06:31:46.983923: Epoch 43 
2025-03-06 06:31:46.987435: Current learning rate: 0.00603 
2025-03-06 06:33:08.398558: train_loss -0.9721 
2025-03-06 06:33:08.404632: val_loss -0.9192 
2025-03-06 06:33:08.408140: Pseudo dice [np.float32(0.9384)] 
2025-03-06 06:33:08.411157: Epoch time: 81.42 s 
2025-03-06 06:33:08.413668: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-03-06 06:33:09.107148:  
2025-03-06 06:33:09.111671: Epoch 44 
2025-03-06 06:33:09.115237: Current learning rate: 0.00593 
2025-03-06 06:34:30.497590: train_loss -0.973 
2025-03-06 06:34:30.502605: val_loss -0.919 
2025-03-06 06:34:30.506614: Pseudo dice [np.float32(0.9384)] 
2025-03-06 06:34:30.509119: Epoch time: 81.39 s 
2025-03-06 06:34:30.512628: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-03-06 06:34:31.215215:  
2025-03-06 06:34:31.220733: Epoch 45 
2025-03-06 06:34:31.224245: Current learning rate: 0.00584 
2025-03-06 06:35:52.650301: train_loss -0.9741 
2025-03-06 06:35:52.655846: val_loss -0.9159 
2025-03-06 06:35:52.659355: Pseudo dice [np.float32(0.9367)] 
2025-03-06 06:35:52.662860: Epoch time: 81.44 s 
2025-03-06 06:35:53.193672:  
2025-03-06 06:35:53.199802: Epoch 46 
2025-03-06 06:35:53.202830: Current learning rate: 0.00574 
2025-03-06 06:37:14.708770: train_loss -0.9668 
2025-03-06 06:37:14.715802: val_loss -0.9199 
2025-03-06 06:37:14.719311: Pseudo dice [np.float32(0.9383)] 
2025-03-06 06:37:14.721817: Epoch time: 81.52 s 
2025-03-06 06:37:15.257366:  
2025-03-06 06:37:15.262404: Epoch 47 
2025-03-06 06:37:15.265428: Current learning rate: 0.00565 
2025-03-06 06:38:36.766275: train_loss -0.971 
2025-03-06 06:38:36.771374: val_loss -0.922 
2025-03-06 06:38:36.774883: Pseudo dice [np.float32(0.9401)] 
2025-03-06 06:38:36.777390: Epoch time: 81.51 s 
2025-03-06 06:38:36.781398: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-03-06 06:38:37.482776:  
2025-03-06 06:38:37.487786: Epoch 48 
2025-03-06 06:38:37.491296: Current learning rate: 0.00555 
2025-03-06 06:39:58.919099: train_loss -0.9745 
2025-03-06 06:39:58.925114: val_loss -0.9189 
2025-03-06 06:39:58.928620: Pseudo dice [np.float32(0.9387)] 
2025-03-06 06:39:58.931629: Epoch time: 81.44 s 
2025-03-06 06:39:58.934134: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-03-06 06:39:59.635618:  
2025-03-06 06:39:59.641157: Epoch 49 
2025-03-06 06:39:59.644671: Current learning rate: 0.00546 
2025-03-06 06:41:21.090791: train_loss -0.9746 
2025-03-06 06:41:21.096807: val_loss -0.9187 
2025-03-06 06:41:21.100815: Pseudo dice [np.float32(0.9386)] 
2025-03-06 06:41:21.103322: Epoch time: 81.46 s 
2025-03-06 06:41:21.252574: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-03-06 06:41:21.953348:  
2025-03-06 06:41:21.958923: Epoch 50 
2025-03-06 06:41:21.961462: Current learning rate: 0.00536 
2025-03-06 06:42:43.421610: train_loss -0.9751 
2025-03-06 06:42:43.427624: val_loss -0.9179 
2025-03-06 06:42:43.431633: Pseudo dice [np.float32(0.9382)] 
2025-03-06 06:42:43.434141: Epoch time: 81.47 s 
2025-03-06 06:42:44.116777:  
2025-03-06 06:42:44.122433: Epoch 51 
2025-03-06 06:42:44.125969: Current learning rate: 0.00526 
2025-03-06 06:44:05.580734: train_loss -0.9752 
2025-03-06 06:44:05.586746: val_loss -0.9187 
2025-03-06 06:44:05.589758: Pseudo dice [np.float32(0.9388)] 
2025-03-06 06:44:05.593267: Epoch time: 81.46 s 
2025-03-06 06:44:05.596773: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-03-06 06:44:06.304279:  
2025-03-06 06:44:06.309290: Epoch 52 
2025-03-06 06:44:06.311796: Current learning rate: 0.00517 
2025-03-06 06:45:27.804381: train_loss -0.975 
2025-03-06 06:45:27.810898: val_loss -0.9165 
2025-03-06 06:45:27.813403: Pseudo dice [np.float32(0.9375)] 
2025-03-06 06:45:27.816914: Epoch time: 81.5 s 
2025-03-06 06:45:28.357204:  
2025-03-06 06:45:28.362234: Epoch 53 
2025-03-06 06:45:28.365261: Current learning rate: 0.00507 
2025-03-06 06:46:49.849583: train_loss -0.9732 
2025-03-06 06:46:49.855597: val_loss -0.9172 
2025-03-06 06:46:49.858107: Pseudo dice [np.float32(0.9376)] 
2025-03-06 06:46:49.861613: Epoch time: 81.49 s 
2025-03-06 06:46:50.406042:  
2025-03-06 06:46:50.412115: Epoch 54 
2025-03-06 06:46:50.415184: Current learning rate: 0.00497 
2025-03-06 06:48:11.979785: train_loss -0.9726 
2025-03-06 06:48:11.985799: val_loss -0.9192 
2025-03-06 06:48:11.988307: Pseudo dice [np.float32(0.939)] 
2025-03-06 06:48:11.992316: Epoch time: 81.57 s 
2025-03-06 06:48:12.536389:  
2025-03-06 06:48:12.541436: Epoch 55 
2025-03-06 06:48:12.544351: Current learning rate: 0.00487 
2025-03-06 06:49:34.065981: train_loss -0.9746 
2025-03-06 06:49:34.072494: val_loss -0.9181 
2025-03-06 06:49:34.076005: Pseudo dice [np.float32(0.9383)] 
2025-03-06 06:49:34.079511: Epoch time: 81.53 s 
2025-03-06 06:49:34.617285:  
2025-03-06 06:49:34.622298: Epoch 56 
2025-03-06 06:49:34.625807: Current learning rate: 0.00478 
2025-03-06 06:50:56.161432: train_loss -0.975 
2025-03-06 06:50:56.167450: val_loss -0.9167 
2025-03-06 06:50:56.171460: Pseudo dice [np.float32(0.9379)] 
2025-03-06 06:50:56.174978: Epoch time: 81.55 s 
2025-03-06 06:50:56.721265:  
2025-03-06 06:50:56.726277: Epoch 57 
2025-03-06 06:50:56.730788: Current learning rate: 0.00468 
2025-03-06 06:52:18.229549: train_loss -0.9748 
2025-03-06 06:52:18.235690: val_loss -0.9177 
2025-03-06 06:52:18.238203: Pseudo dice [np.float32(0.9382)] 
2025-03-06 06:52:18.241765: Epoch time: 81.51 s 
2025-03-06 06:52:18.788567:  
2025-03-06 06:52:18.797424: Epoch 58 
2025-03-06 06:52:18.800473: Current learning rate: 0.00458 
2025-03-06 06:53:40.269261: train_loss -0.9761 
2025-03-06 06:53:40.274271: val_loss -0.9176 
2025-03-06 06:53:40.278284: Pseudo dice [np.float32(0.9386)] 
2025-03-06 06:53:40.280794: Epoch time: 81.48 s 
2025-03-06 06:53:40.983771:  
2025-03-06 06:53:40.988784: Epoch 59 
2025-03-06 06:53:40.993293: Current learning rate: 0.00448 
2025-03-06 06:55:02.504150: train_loss -0.9769 
2025-03-06 06:55:02.511192: val_loss -0.9182 
2025-03-06 06:55:02.514704: Pseudo dice [np.float32(0.939)] 
2025-03-06 06:55:02.518712: Epoch time: 81.52 s 
2025-03-06 06:55:03.068988:  
2025-03-06 06:55:03.074507: Epoch 60 
2025-03-06 06:55:03.078020: Current learning rate: 0.00438 
2025-03-06 06:56:24.529045: train_loss -0.9765 
2025-03-06 06:56:24.535171: val_loss -0.9186 
2025-03-06 06:56:24.539181: Pseudo dice [np.float32(0.9389)] 
2025-03-06 06:56:24.542692: Epoch time: 81.46 s 
2025-03-06 06:56:25.093833:  
2025-03-06 06:56:25.099397: Epoch 61 
2025-03-06 06:56:25.103446: Current learning rate: 0.00429 
2025-03-06 06:57:46.556066: train_loss -0.9766 
2025-03-06 06:57:46.561151: val_loss -0.918 
2025-03-06 06:57:46.565728: Pseudo dice [np.float32(0.9386)] 
2025-03-06 06:57:46.568800: Epoch time: 81.46 s 
2025-03-06 06:57:46.571849: Yayy! New best EMA pseudo Dice: 0.9384999871253967 
2025-03-06 06:57:47.300097:  
2025-03-06 06:57:47.305681: Epoch 62 
2025-03-06 06:57:47.309739: Current learning rate: 0.00419 
2025-03-06 06:59:08.695667: train_loss -0.9769 
2025-03-06 06:59:08.702187: val_loss -0.9186 
2025-03-06 06:59:08.706197: Pseudo dice [np.float32(0.9393)] 
2025-03-06 06:59:08.709708: Epoch time: 81.4 s 
2025-03-06 06:59:08.713714: Yayy! New best EMA pseudo Dice: 0.9384999871253967 
2025-03-06 06:59:09.429206:  
2025-03-06 06:59:09.435745: Epoch 63 
2025-03-06 06:59:09.439879: Current learning rate: 0.00409 
2025-03-06 07:00:30.900682: train_loss -0.9776 
2025-03-06 07:00:30.907714: val_loss -0.9171 
2025-03-06 07:00:30.911222: Pseudo dice [np.float32(0.9386)] 
2025-03-06 07:00:30.915230: Epoch time: 81.47 s 
2025-03-06 07:00:30.918739: Yayy! New best EMA pseudo Dice: 0.9384999871253967 
2025-03-06 07:00:31.634519:  
2025-03-06 07:00:31.640117: Epoch 64 
2025-03-06 07:00:31.643692: Current learning rate: 0.00399 
2025-03-06 07:01:53.115603: train_loss -0.9775 
2025-03-06 07:01:53.121629: val_loss -0.9185 
2025-03-06 07:01:53.125648: Pseudo dice [np.float32(0.9394)] 
2025-03-06 07:01:53.129160: Epoch time: 81.48 s 
2025-03-06 07:01:53.132676: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-03-06 07:01:53.843975:  
2025-03-06 07:01:53.849488: Epoch 65 
2025-03-06 07:01:53.852997: Current learning rate: 0.00389 
2025-03-06 07:03:15.279907: train_loss -0.9785 
2025-03-06 07:03:15.285922: val_loss -0.9185 
2025-03-06 07:03:15.289931: Pseudo dice [np.float32(0.9393)] 
2025-03-06 07:03:15.294440: Epoch time: 81.44 s 
2025-03-06 07:03:15.298452: Yayy! New best EMA pseudo Dice: 0.9387000203132629 
2025-03-06 07:03:16.148075:  
2025-03-06 07:03:16.154152: Epoch 66 
2025-03-06 07:03:16.158188: Current learning rate: 0.00379 
2025-03-06 07:04:37.646085: train_loss -0.9767 
2025-03-06 07:04:37.653179: val_loss -0.9176 
2025-03-06 07:04:37.656805: Pseudo dice [np.float32(0.9387)] 
2025-03-06 07:04:37.661339: Epoch time: 81.5 s 
2025-03-06 07:04:37.664385: Yayy! New best EMA pseudo Dice: 0.9387000203132629 
2025-03-06 07:04:38.376168:  
2025-03-06 07:04:38.382192: Epoch 67 
2025-03-06 07:04:38.385206: Current learning rate: 0.00369 
2025-03-06 07:05:59.832582: train_loss -0.9758 
2025-03-06 07:05:59.841110: val_loss -0.9173 
2025-03-06 07:05:59.846123: Pseudo dice [np.float32(0.9385)] 
2025-03-06 07:05:59.850131: Epoch time: 81.46 s 
2025-03-06 07:06:00.420724:  
2025-03-06 07:06:00.427237: Epoch 68 
2025-03-06 07:06:00.430747: Current learning rate: 0.00359 
2025-03-06 07:07:22.015501: train_loss -0.977 
2025-03-06 07:07:22.022014: val_loss -0.9168 
2025-03-06 07:07:22.025523: Pseudo dice [np.float32(0.9386)] 
2025-03-06 07:07:22.029531: Epoch time: 81.59 s 
2025-03-06 07:07:22.591356:  
2025-03-06 07:07:22.597331: Epoch 69 
2025-03-06 07:07:22.601356: Current learning rate: 0.00349 
2025-03-06 07:08:44.037286: train_loss -0.9769 
2025-03-06 07:08:44.042836: val_loss -0.9185 
2025-03-06 07:08:44.047367: Pseudo dice [np.float32(0.9395)] 
2025-03-06 07:08:44.051414: Epoch time: 81.45 s 
2025-03-06 07:08:44.054948: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-03-06 07:08:44.779502:  
2025-03-06 07:08:44.785627: Epoch 70 
2025-03-06 07:08:44.789709: Current learning rate: 0.00338 
2025-03-06 07:10:06.227219: train_loss -0.9767 
2025-03-06 07:10:06.233735: val_loss -0.9165 
2025-03-06 07:10:06.237245: Pseudo dice [np.float32(0.9383)] 
2025-03-06 07:10:06.241253: Epoch time: 81.45 s 
2025-03-06 07:10:06.802697:  
2025-03-06 07:10:06.808241: Epoch 71 
2025-03-06 07:10:06.811778: Current learning rate: 0.00328 
2025-03-06 07:11:28.280713: train_loss -0.977 
2025-03-06 07:11:28.287354: val_loss -0.9184 
2025-03-06 07:11:28.291414: Pseudo dice [np.float32(0.9391)] 
2025-03-06 07:11:28.295480: Epoch time: 81.48 s 
2025-03-06 07:11:28.859114:  
2025-03-06 07:11:28.865144: Epoch 72 
2025-03-06 07:11:28.869659: Current learning rate: 0.00318 
2025-03-06 07:12:50.431665: train_loss -0.9756 
2025-03-06 07:12:50.436730: val_loss -0.916 
2025-03-06 07:12:50.441348: Pseudo dice [np.float32(0.9374)] 
2025-03-06 07:12:50.445403: Epoch time: 81.57 s 
2025-03-06 07:12:51.010072:  
2025-03-06 07:12:51.015630: Epoch 73 
2025-03-06 07:12:51.020208: Current learning rate: 0.00308 
2025-03-06 07:14:12.492114: train_loss -0.977 
2025-03-06 07:14:12.499648: val_loss -0.9188 
2025-03-06 07:14:12.503664: Pseudo dice [np.float32(0.9395)] 
2025-03-06 07:14:12.507177: Epoch time: 81.48 s 
2025-03-06 07:14:13.220749:  
2025-03-06 07:14:13.226823: Epoch 74 
2025-03-06 07:14:13.230884: Current learning rate: 0.00297 
2025-03-06 07:15:34.720153: train_loss -0.9773 
2025-03-06 07:15:34.726667: val_loss -0.9193 
2025-03-06 07:15:34.730176: Pseudo dice [np.float32(0.9398)] 
2025-03-06 07:15:34.734185: Epoch time: 81.5 s 
2025-03-06 07:15:34.737697: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-03-06 07:15:35.459936:  
2025-03-06 07:15:35.465513: Epoch 75 
2025-03-06 07:15:35.470619: Current learning rate: 0.00287 
2025-03-06 07:16:56.949866: train_loss -0.978 
2025-03-06 07:16:56.955398: val_loss -0.9185 
2025-03-06 07:16:56.959409: Pseudo dice [np.float32(0.9396)] 
2025-03-06 07:16:56.962918: Epoch time: 81.49 s 
2025-03-06 07:16:56.967932: Yayy! New best EMA pseudo Dice: 0.9388999938964844 
2025-03-06 07:16:57.686878:  
2025-03-06 07:16:57.693501: Epoch 76 
2025-03-06 07:16:57.697531: Current learning rate: 0.00277 
2025-03-06 07:18:19.224849: train_loss -0.9778 
2025-03-06 07:18:19.230899: val_loss -0.9186 
2025-03-06 07:18:19.234427: Pseudo dice [np.float32(0.9397)] 
2025-03-06 07:18:19.238187: Epoch time: 81.54 s 
2025-03-06 07:18:19.242205: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-03-06 07:18:19.968109:  
2025-03-06 07:18:19.974147: Epoch 77 
2025-03-06 07:18:19.978206: Current learning rate: 0.00266 
2025-03-06 07:19:41.482082: train_loss -0.9783 
2025-03-06 07:19:41.488096: val_loss -0.918 
2025-03-06 07:19:41.492118: Pseudo dice [np.float32(0.9395)] 
2025-03-06 07:19:41.496125: Epoch time: 81.51 s 
2025-03-06 07:19:41.499634: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-03-06 07:19:42.236903:  
2025-03-06 07:19:42.243502: Epoch 78 
2025-03-06 07:19:42.247066: Current learning rate: 0.00256 
2025-03-06 07:21:03.759819: train_loss -0.9785 
2025-03-06 07:21:03.765834: val_loss -0.9183 
2025-03-06 07:21:03.769846: Pseudo dice [np.float32(0.9396)] 
2025-03-06 07:21:03.773355: Epoch time: 81.52 s 
2025-03-06 07:21:03.777366: Yayy! New best EMA pseudo Dice: 0.9391000270843506 
2025-03-06 07:21:04.511774:  
2025-03-06 07:21:04.517789: Epoch 79 
2025-03-06 07:21:04.521798: Current learning rate: 0.00245 
2025-03-06 07:22:26.412228: train_loss -0.9778 
2025-03-06 07:22:26.418341: val_loss -0.9172 
2025-03-06 07:22:26.421467: Pseudo dice [np.float32(0.939)] 
2025-03-06 07:22:26.426601: Epoch time: 81.9 s 
2025-03-06 07:22:26.996879:  
2025-03-06 07:22:27.002918: Epoch 80 
2025-03-06 07:22:27.007429: Current learning rate: 0.00235 
2025-03-06 07:23:48.399939: train_loss -0.9768 
2025-03-06 07:23:48.406455: val_loss -0.9184 
2025-03-06 07:23:48.409969: Pseudo dice [np.float32(0.9399)] 
2025-03-06 07:23:48.413975: Epoch time: 81.4 s 
2025-03-06 07:23:48.417488: Yayy! New best EMA pseudo Dice: 0.9391000270843506 
2025-03-06 07:23:49.146865:  
2025-03-06 07:23:49.152947: Epoch 81 
2025-03-06 07:23:49.155504: Current learning rate: 0.00224 
2025-03-06 07:25:10.642695: train_loss -0.9782 
2025-03-06 07:25:10.648709: val_loss -0.9169 
2025-03-06 07:25:10.652719: Pseudo dice [np.float32(0.9387)] 
2025-03-06 07:25:10.656230: Epoch time: 81.5 s 
2025-03-06 07:25:11.380240:  
2025-03-06 07:25:11.385317: Epoch 82 
2025-03-06 07:25:11.389883: Current learning rate: 0.00214 
2025-03-06 07:26:32.825980: train_loss -0.9785 
2025-03-06 07:26:32.832560: val_loss -0.9178 
2025-03-06 07:26:32.836065: Pseudo dice [np.float32(0.9395)] 
2025-03-06 07:26:32.839074: Epoch time: 81.45 s 
2025-03-06 07:26:33.381835:  
2025-03-06 07:26:33.388443: Epoch 83 
2025-03-06 07:26:33.390991: Current learning rate: 0.00203 
2025-03-06 07:27:54.836215: train_loss -0.9785 
2025-03-06 07:27:54.842830: val_loss -0.9163 
2025-03-06 07:27:54.846363: Pseudo dice [np.float32(0.9386)] 
2025-03-06 07:27:54.850402: Epoch time: 81.46 s 
2025-03-06 07:27:55.386577:  
2025-03-06 07:27:55.392256: Epoch 84 
2025-03-06 07:27:55.396795: Current learning rate: 0.00192 
2025-03-06 07:29:16.881004: train_loss -0.979 
2025-03-06 07:29:16.887021: val_loss -0.9166 
2025-03-06 07:29:16.889531: Pseudo dice [np.float32(0.9388)] 
2025-03-06 07:29:16.893542: Epoch time: 81.49 s 
2025-03-06 07:29:17.435859:  
2025-03-06 07:29:17.441433: Epoch 85 
2025-03-06 07:29:17.443985: Current learning rate: 0.00181 
2025-03-06 07:30:38.945319: train_loss -0.9777 
2025-03-06 07:30:38.950885: val_loss -0.9174 
2025-03-06 07:30:38.954978: Pseudo dice [np.float32(0.9394)] 
2025-03-06 07:30:38.957480: Epoch time: 81.51 s 
2025-03-06 07:30:39.490207:  
2025-03-06 07:30:39.495836: Epoch 86 
2025-03-06 07:30:39.499351: Current learning rate: 0.0017 
2025-03-06 07:32:01.012347: train_loss -0.9792 
2025-03-06 07:32:01.018425: val_loss -0.9156 
2025-03-06 07:32:01.021494: Pseudo dice [np.float32(0.9378)] 
2025-03-06 07:32:01.025052: Epoch time: 81.52 s 
2025-03-06 07:32:01.555290:  
2025-03-06 07:32:01.560819: Epoch 87 
2025-03-06 07:32:01.565873: Current learning rate: 0.00159 
2025-03-06 07:33:23.011154: train_loss -0.9786 
2025-03-06 07:33:23.017172: val_loss -0.9157 
2025-03-06 07:33:23.021183: Pseudo dice [np.float32(0.9384)] 
2025-03-06 07:33:23.024694: Epoch time: 81.46 s 
2025-03-06 07:33:23.555364:  
2025-03-06 07:33:23.560396: Epoch 88 
2025-03-06 07:33:23.563931: Current learning rate: 0.00148 
2025-03-06 07:34:44.963857: train_loss -0.9785 
2025-03-06 07:34:44.968868: val_loss -0.9169 
2025-03-06 07:34:44.972382: Pseudo dice [np.float32(0.939)] 
2025-03-06 07:34:44.975888: Epoch time: 81.41 s 
2025-03-06 07:34:45.509971:  
2025-03-06 07:34:45.516494: Epoch 89 
2025-03-06 07:34:45.520059: Current learning rate: 0.00137 
2025-03-06 07:36:07.091658: train_loss -0.9785 
2025-03-06 07:36:07.096672: val_loss -0.9175 
2025-03-06 07:36:07.100178: Pseudo dice [np.float32(0.9396)] 
2025-03-06 07:36:07.103189: Epoch time: 81.58 s 
2025-03-06 07:36:07.788703:  
2025-03-06 07:36:07.794234: Epoch 90 
2025-03-06 07:36:07.797748: Current learning rate: 0.00126 
2025-03-06 07:37:29.254953: train_loss -0.9785 
2025-03-06 07:37:29.261466: val_loss -0.917 
2025-03-06 07:37:29.263973: Pseudo dice [np.float32(0.939)] 
2025-03-06 07:37:29.267483: Epoch time: 81.47 s 
2025-03-06 07:37:29.797337:  
2025-03-06 07:37:29.802880: Epoch 91 
2025-03-06 07:37:29.806451: Current learning rate: 0.00115 
2025-03-06 07:38:51.289006: train_loss -0.9771 
2025-03-06 07:38:51.295026: val_loss -0.9181 
2025-03-06 07:38:51.298533: Pseudo dice [np.float32(0.9398)] 
2025-03-06 07:38:51.301541: Epoch time: 81.49 s 
2025-03-06 07:38:51.841181:  
2025-03-06 07:38:51.846755: Epoch 92 
2025-03-06 07:38:51.849297: Current learning rate: 0.00103 
2025-03-06 07:40:13.339785: train_loss -0.9781 
2025-03-06 07:40:13.346306: val_loss -0.9162 
2025-03-06 07:40:13.348813: Pseudo dice [np.float32(0.9387)] 
2025-03-06 07:40:13.352322: Epoch time: 81.5 s 
2025-03-06 07:40:13.885142:  
2025-03-06 07:40:13.891746: Epoch 93 
2025-03-06 07:40:13.898337: Current learning rate: 0.00091 
2025-03-06 07:41:35.340939: train_loss -0.9795 
2025-03-06 07:41:35.345858: val_loss -0.9168 
2025-03-06 07:41:35.349386: Pseudo dice [np.float32(0.9392)] 
2025-03-06 07:41:35.351418: Epoch time: 81.46 s 
2025-03-06 07:41:35.886798:  
2025-03-06 07:41:35.892336: Epoch 94 
2025-03-06 07:41:35.895361: Current learning rate: 0.00079 
2025-03-06 07:42:57.371358: train_loss -0.9794 
2025-03-06 07:42:57.376375: val_loss -0.9167 
2025-03-06 07:42:57.380387: Pseudo dice [np.float32(0.939)] 
2025-03-06 07:42:57.382894: Epoch time: 81.49 s 
2025-03-06 07:42:57.915459:  
2025-03-06 07:42:57.920976: Epoch 95 
2025-03-06 07:42:57.924485: Current learning rate: 0.00067 
2025-03-06 07:44:19.386112: train_loss -0.9776 
2025-03-06 07:44:19.391224: val_loss -0.9169 
2025-03-06 07:44:19.395232: Pseudo dice [np.float32(0.9391)] 
2025-03-06 07:44:19.398740: Epoch time: 81.47 s 
2025-03-06 07:44:19.942030:  
2025-03-06 07:44:19.947592: Epoch 96 
2025-03-06 07:44:19.950145: Current learning rate: 0.00055 
2025-03-06 07:45:41.496908: train_loss -0.979 
2025-03-06 07:45:41.502924: val_loss -0.917 
2025-03-06 07:45:41.506933: Pseudo dice [np.float32(0.9392)] 
2025-03-06 07:45:41.509441: Epoch time: 81.56 s 
2025-03-06 07:45:42.050803:  
2025-03-06 07:45:42.056373: Epoch 97 
2025-03-06 07:45:42.059917: Current learning rate: 0.00043 
2025-03-06 07:47:03.499015: train_loss -0.9789 
2025-03-06 07:47:03.505030: val_loss -0.9162 
2025-03-06 07:47:03.507537: Pseudo dice [np.float32(0.9387)] 
2025-03-06 07:47:03.511046: Epoch time: 81.45 s 
2025-03-06 07:47:04.061422:  
2025-03-06 07:47:04.066435: Epoch 98 
2025-03-06 07:47:04.069947: Current learning rate: 0.0003 
2025-03-06 07:48:25.598945: train_loss -0.9789 
2025-03-06 07:48:25.604591: val_loss -0.9171 
2025-03-06 07:48:25.608601: Pseudo dice [np.float32(0.9394)] 
2025-03-06 07:48:25.612111: Epoch time: 81.54 s 
2025-03-06 07:48:26.316796:  
2025-03-06 07:48:26.322382: Epoch 99 
2025-03-06 07:48:26.326426: Current learning rate: 0.00016 
2025-03-06 07:49:47.728733: train_loss -0.9801 
2025-03-06 07:49:47.734781: val_loss -0.9172 
2025-03-06 07:49:47.738816: Pseudo dice [np.float32(0.9394)] 
2025-03-06 07:49:47.741323: Epoch time: 81.41 s 
2025-03-06 07:49:48.516595: Training done. 
2025-03-06 07:49:48.568597: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-06 07:49:48.580594: The split file contains 5 splits. 
2025-03-06 07:49:48.586594: Desired fold for training: 0 
2025-03-06 07:49:48.590597: This split has 16 training and 4 validation cases. 
2025-03-06 07:49:48.595595: predicting la_007 
2025-03-06 07:49:48.600603: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2025-03-06 07:49:54.593106: predicting la_016 
2025-03-06 07:49:54.605111: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2025-03-06 07:49:56.940349: predicting la_021 
2025-03-06 07:49:56.949348: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2025-03-06 07:49:59.288520: predicting la_024 
2025-03-06 07:49:59.299520: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2025-03-06 07:50:08.440362: Validation complete 
2025-03-06 07:50:08.445362: Mean Validation Dice:  0.8835304219388286 
