
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-11 13:50:58.489369: do_dummy_2d_data_aug: False 
2025-03-11 13:50:58.490374: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-11 13:50:58.498689: The split file contains 5 splits. 
2025-03-11 13:50:58.499694: Desired fold for training: 0 
2025-03-11 13:50:58.504166: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2025-03-11 13:51:07.859080: unpacking dataset... 
2025-03-11 13:51:08.580266: unpacking done... 
2025-03-11 13:51:11.881006:  
2025-03-11 13:51:11.886115: Epoch 0 
2025-03-11 13:51:11.889765: Current learning rate: 0.01 
2025-03-11 13:52:00.465756: train_loss -0.6329 
2025-03-11 13:52:00.471866: val_loss -0.8752 
2025-03-11 13:52:00.474911: Pseudo dice [np.float32(0.9046)] 
2025-03-11 13:52:00.478460: Epoch time: 48.59 s 
2025-03-11 13:52:00.480986: Yayy! New best EMA pseudo Dice: 0.9046000242233276 
2025-03-11 13:52:01.132025:  
2025-03-11 13:52:01.137680: Epoch 1 
2025-03-11 13:52:01.141713: Current learning rate: 0.00991 
2025-03-11 13:52:45.089782: train_loss -0.8734 
2025-03-11 13:52:45.095942: val_loss -0.8942 
2025-03-11 13:52:45.099286: Pseudo dice [np.float32(0.9209)] 
2025-03-11 13:52:45.102373: Epoch time: 43.96 s 
2025-03-11 13:52:45.105975: Yayy! New best EMA pseudo Dice: 0.9061999917030334 
2025-03-11 13:52:45.831667:  
2025-03-11 13:52:45.837842: Epoch 2 
2025-03-11 13:52:45.840685: Current learning rate: 0.00982 
2025-03-11 13:53:29.814926: train_loss -0.8825 
2025-03-11 13:53:29.821082: val_loss -0.9004 
2025-03-11 13:53:29.824751: Pseudo dice [np.float32(0.9228)] 
2025-03-11 13:53:29.827836: Epoch time: 43.98 s 
2025-03-11 13:53:29.831437: Yayy! New best EMA pseudo Dice: 0.907800018787384 
2025-03-11 13:53:30.574351:  
2025-03-11 13:53:30.579935: Epoch 3 
2025-03-11 13:53:30.583987: Current learning rate: 0.00973 
2025-03-11 13:54:14.559587: train_loss -0.9005 
2025-03-11 13:54:14.566186: val_loss -0.8996 
2025-03-11 13:54:14.569741: Pseudo dice [np.float32(0.9207)] 
2025-03-11 13:54:14.572268: Epoch time: 43.99 s 
2025-03-11 13:54:14.575808: Yayy! New best EMA pseudo Dice: 0.9090999960899353 
2025-03-11 13:54:15.308192:  
2025-03-11 13:54:15.313779: Epoch 4 
2025-03-11 13:54:15.317353: Current learning rate: 0.00964 
2025-03-11 13:54:59.313462: train_loss -0.9102 
2025-03-11 13:54:59.320018: val_loss -0.9053 
2025-03-11 13:54:59.323561: Pseudo dice [np.float32(0.9268)] 
2025-03-11 13:54:59.326084: Epoch time: 44.01 s 
2025-03-11 13:54:59.329623: Yayy! New best EMA pseudo Dice: 0.9108999967575073 
2025-03-11 13:55:00.374729:  
2025-03-11 13:55:00.379789: Epoch 5 
2025-03-11 13:55:00.383321: Current learning rate: 0.00955 
2025-03-11 13:55:44.335410: train_loss -0.9192 
2025-03-11 13:55:44.341710: val_loss -0.9124 
2025-03-11 13:55:44.347435: Pseudo dice [np.float32(0.9326)] 
2025-03-11 13:55:44.351633: Epoch time: 43.96 s 
2025-03-11 13:55:44.355582: Yayy! New best EMA pseudo Dice: 0.913100004196167 
2025-03-11 13:55:45.068945:  
2025-03-11 13:55:45.075145: Epoch 6 
2025-03-11 13:55:45.078265: Current learning rate: 0.00946 
2025-03-11 13:56:29.037819: train_loss -0.9263 
2025-03-11 13:56:29.044022: val_loss -0.9142 
2025-03-11 13:56:29.047171: Pseudo dice [np.float32(0.9326)] 
2025-03-11 13:56:29.050819: Epoch time: 43.97 s 
2025-03-11 13:56:29.054449: Yayy! New best EMA pseudo Dice: 0.9150000214576721 
2025-03-11 13:56:29.772804:  
2025-03-11 13:56:29.778954: Epoch 7 
2025-03-11 13:56:29.782456: Current learning rate: 0.00937 
2025-03-11 13:57:13.750308: train_loss -0.9343 
2025-03-11 13:57:13.756363: val_loss -0.9183 
2025-03-11 13:57:13.760410: Pseudo dice [np.float32(0.935)] 
2025-03-11 13:57:13.762941: Epoch time: 43.98 s 
2025-03-11 13:57:13.766992: Yayy! New best EMA pseudo Dice: 0.9169999957084656 
2025-03-11 13:57:14.508923:  
2025-03-11 13:57:14.514608: Epoch 8 
2025-03-11 13:57:14.517535: Current learning rate: 0.00928 
2025-03-11 13:57:58.486715: train_loss -0.9332 
2025-03-11 13:57:58.492766: val_loss -0.9193 
2025-03-11 13:57:58.496835: Pseudo dice [np.float32(0.936)] 
2025-03-11 13:57:58.500887: Epoch time: 43.98 s 
2025-03-11 13:57:58.503954: Yayy! New best EMA pseudo Dice: 0.9189000129699707 
2025-03-11 13:57:59.261936:  
2025-03-11 13:57:59.268022: Epoch 9 
2025-03-11 13:57:59.271663: Current learning rate: 0.00919 
2025-03-11 13:58:43.214603: train_loss -0.9345 
2025-03-11 13:58:43.220793: val_loss -0.9123 
2025-03-11 13:58:43.223997: Pseudo dice [np.float32(0.9302)] 
2025-03-11 13:58:43.227074: Epoch time: 43.95 s 
2025-03-11 13:58:43.230226: Yayy! New best EMA pseudo Dice: 0.9200999736785889 
2025-03-11 13:58:43.955927:  
2025-03-11 13:58:43.961616: Epoch 10 
2025-03-11 13:58:43.965247: Current learning rate: 0.0091 
2025-03-11 13:59:29.672652: train_loss -0.9398 
2025-03-11 13:59:29.678703: val_loss -0.9173 
2025-03-11 13:59:29.682103: Pseudo dice [np.float32(0.9337)] 
2025-03-11 13:59:29.686239: Epoch time: 45.72 s 
2025-03-11 13:59:29.689347: Yayy! New best EMA pseudo Dice: 0.9214000105857849 
2025-03-11 13:59:30.406602:  
2025-03-11 13:59:30.411656: Epoch 11 
2025-03-11 13:59:30.415711: Current learning rate: 0.009 
2025-03-11 14:00:14.353778: train_loss -0.9462 
2025-03-11 14:00:14.360357: val_loss -0.9205 
2025-03-11 14:00:14.363892: Pseudo dice [np.float32(0.9372)] 
2025-03-11 14:00:14.367413: Epoch time: 43.95 s 
2025-03-11 14:00:14.370943: Yayy! New best EMA pseudo Dice: 0.9229999780654907 
2025-03-11 14:00:15.101768:  
2025-03-11 14:00:15.107946: Epoch 12 
2025-03-11 14:00:15.111478: Current learning rate: 0.00891 
2025-03-11 14:00:59.038657: train_loss -0.9477 
2025-03-11 14:00:59.044983: val_loss -0.919 
2025-03-11 14:00:59.048230: Pseudo dice [np.float32(0.9362)] 
2025-03-11 14:00:59.051359: Epoch time: 43.94 s 
2025-03-11 14:00:59.054526: Yayy! New best EMA pseudo Dice: 0.9243000149726868 
2025-03-11 14:00:59.929574:  
2025-03-11 14:00:59.934661: Epoch 13 
2025-03-11 14:00:59.938719: Current learning rate: 0.00882 
2025-03-11 14:01:43.849672: train_loss -0.9518 
2025-03-11 14:01:43.855418: val_loss -0.9219 
2025-03-11 14:01:43.859053: Pseudo dice [np.float32(0.9383)] 
2025-03-11 14:01:43.861650: Epoch time: 43.92 s 
2025-03-11 14:01:43.865445: Yayy! New best EMA pseudo Dice: 0.9257000088691711 
2025-03-11 14:01:44.629724:  
2025-03-11 14:01:44.635502: Epoch 14 
2025-03-11 14:01:44.639320: Current learning rate: 0.00873 
2025-03-11 14:02:28.589149: train_loss -0.9497 
2025-03-11 14:02:28.595127: val_loss -0.9212 
2025-03-11 14:02:28.598714: Pseudo dice [np.float32(0.9375)] 
2025-03-11 14:02:28.602312: Epoch time: 43.96 s 
2025-03-11 14:02:28.605376: Yayy! New best EMA pseudo Dice: 0.9269000291824341 
2025-03-11 14:02:29.342853:  
2025-03-11 14:02:29.348700: Epoch 15 
2025-03-11 14:02:29.352292: Current learning rate: 0.00864 
2025-03-11 14:03:13.293603: train_loss -0.9469 
2025-03-11 14:03:13.299659: val_loss -0.9212 
2025-03-11 14:03:13.302182: Pseudo dice [np.float32(0.9368)] 
2025-03-11 14:03:13.305729: Epoch time: 43.95 s 
2025-03-11 14:03:13.309757: Yayy! New best EMA pseudo Dice: 0.9279000163078308 
2025-03-11 14:03:14.044811:  
2025-03-11 14:03:14.049886: Epoch 16 
2025-03-11 14:03:14.053919: Current learning rate: 0.00855 
2025-03-11 14:03:58.018114: train_loss -0.9518 
2025-03-11 14:03:58.023814: val_loss -0.9199 
2025-03-11 14:03:58.027442: Pseudo dice [np.float32(0.9365)] 
2025-03-11 14:03:58.030579: Epoch time: 43.97 s 
2025-03-11 14:03:58.034191: Yayy! New best EMA pseudo Dice: 0.9287999868392944 
2025-03-11 14:03:58.775385:  
2025-03-11 14:03:58.781082: Epoch 17 
2025-03-11 14:03:58.784142: Current learning rate: 0.00846 
2025-03-11 14:04:42.707081: train_loss -0.9569 
2025-03-11 14:04:42.712844: val_loss -0.9189 
2025-03-11 14:04:42.716473: Pseudo dice [np.float32(0.9361)] 
2025-03-11 14:04:42.719954: Epoch time: 43.93 s 
2025-03-11 14:04:42.723077: Yayy! New best EMA pseudo Dice: 0.9294999837875366 
2025-03-11 14:04:43.474072:  
2025-03-11 14:04:43.479772: Epoch 18 
2025-03-11 14:04:43.482900: Current learning rate: 0.00836 
2025-03-11 14:05:27.395902: train_loss -0.9584 
2025-03-11 14:05:27.401588: val_loss -0.9206 
2025-03-11 14:05:27.405184: Pseudo dice [np.float32(0.9377)] 
2025-03-11 14:05:27.407767: Epoch time: 43.92 s 
2025-03-11 14:05:27.410828: Yayy! New best EMA pseudo Dice: 0.9302999973297119 
2025-03-11 14:05:28.146974:  
2025-03-11 14:05:28.153039: Epoch 19 
2025-03-11 14:05:28.156084: Current learning rate: 0.00827 
2025-03-11 14:06:12.085728: train_loss -0.9597 
2025-03-11 14:06:12.091391: val_loss -0.9216 
2025-03-11 14:06:12.094975: Pseudo dice [np.float32(0.938)] 
2025-03-11 14:06:12.098478: Epoch time: 43.94 s 
2025-03-11 14:06:12.102078: Yayy! New best EMA pseudo Dice: 0.9311000108718872 
2025-03-11 14:06:12.861179:  
2025-03-11 14:06:12.866882: Epoch 20 
2025-03-11 14:06:12.870615: Current learning rate: 0.00818 
2025-03-11 14:06:56.837946: train_loss -0.9606 
2025-03-11 14:06:56.844091: val_loss -0.9201 
2025-03-11 14:06:56.847670: Pseudo dice [np.float32(0.9368)] 
2025-03-11 14:06:56.850733: Epoch time: 43.98 s 
2025-03-11 14:06:56.854523: Yayy! New best EMA pseudo Dice: 0.9315999746322632 
2025-03-11 14:06:57.747937:  
2025-03-11 14:06:57.752201: Epoch 21 
2025-03-11 14:06:57.755740: Current learning rate: 0.00809 
2025-03-11 14:07:41.699005: train_loss -0.9609 
2025-03-11 14:07:41.704814: val_loss -0.921 
2025-03-11 14:07:41.708385: Pseudo dice [np.float32(0.9383)] 
2025-03-11 14:07:41.712143: Epoch time: 43.95 s 
2025-03-11 14:07:41.715326: Yayy! New best EMA pseudo Dice: 0.9322999715805054 
2025-03-11 14:07:42.429010:  
2025-03-11 14:07:42.435169: Epoch 22 
2025-03-11 14:07:42.438765: Current learning rate: 0.008 
2025-03-11 14:08:26.373451: train_loss -0.9608 
2025-03-11 14:08:26.379592: val_loss -0.9194 
2025-03-11 14:08:26.383266: Pseudo dice [np.float32(0.9367)] 
2025-03-11 14:08:26.385791: Epoch time: 43.94 s 
2025-03-11 14:08:26.389328: Yayy! New best EMA pseudo Dice: 0.9327999949455261 
2025-03-11 14:08:27.107061:  
2025-03-11 14:08:27.113711: Epoch 23 
2025-03-11 14:08:27.116976: Current learning rate: 0.0079 
2025-03-11 14:09:11.100369: train_loss -0.9624 
2025-03-11 14:09:11.106547: val_loss -0.9194 
2025-03-11 14:09:11.109639: Pseudo dice [np.float32(0.9367)] 
2025-03-11 14:09:11.114298: Epoch time: 43.99 s 
2025-03-11 14:09:11.117978: Yayy! New best EMA pseudo Dice: 0.9330999851226807 
2025-03-11 14:09:11.831443:  
2025-03-11 14:09:11.837043: Epoch 24 
2025-03-11 14:09:11.840103: Current learning rate: 0.00781 
2025-03-11 14:09:55.738245: train_loss -0.9642 
2025-03-11 14:09:55.744020: val_loss -0.9193 
2025-03-11 14:09:55.747610: Pseudo dice [np.float32(0.9365)] 
2025-03-11 14:09:55.751203: Epoch time: 43.91 s 
2025-03-11 14:09:55.754738: Yayy! New best EMA pseudo Dice: 0.9334999918937683 
2025-03-11 14:09:56.473978:  
2025-03-11 14:09:56.481101: Epoch 25 
2025-03-11 14:09:56.484705: Current learning rate: 0.00772 
2025-03-11 14:10:40.386175: train_loss -0.9644 
2025-03-11 14:10:40.392456: val_loss -0.9232 
2025-03-11 14:10:40.396099: Pseudo dice [np.float32(0.94)] 
2025-03-11 14:10:40.399280: Epoch time: 43.91 s 
2025-03-11 14:10:40.402966: Yayy! New best EMA pseudo Dice: 0.9340999722480774 
2025-03-11 14:10:41.116805:  
2025-03-11 14:10:41.121848: Epoch 26 
2025-03-11 14:10:41.125371: Current learning rate: 0.00763 
2025-03-11 14:11:25.048041: train_loss -0.9613 
2025-03-11 14:11:25.054114: val_loss -0.9191 
2025-03-11 14:11:25.058151: Pseudo dice [np.float32(0.937)] 
2025-03-11 14:11:25.061689: Epoch time: 43.93 s 
2025-03-11 14:11:25.064204: Yayy! New best EMA pseudo Dice: 0.9344000220298767 
2025-03-11 14:11:25.782414:  
2025-03-11 14:11:25.788026: Epoch 27 
2025-03-11 14:11:25.791266: Current learning rate: 0.00753 
2025-03-11 14:12:09.748905: train_loss -0.9622 
2025-03-11 14:12:09.754490: val_loss -0.92 
2025-03-11 14:12:09.758559: Pseudo dice [np.float32(0.9375)] 
2025-03-11 14:12:09.761609: Epoch time: 43.97 s 
2025-03-11 14:12:09.764197: Yayy! New best EMA pseudo Dice: 0.9347000122070312 
2025-03-11 14:12:10.626659:  
2025-03-11 14:12:10.632706: Epoch 28 
2025-03-11 14:12:10.635732: Current learning rate: 0.00744 
2025-03-11 14:12:54.563887: train_loss -0.9608 
2025-03-11 14:12:54.570640: val_loss -0.9234 
2025-03-11 14:12:54.573689: Pseudo dice [np.float32(0.9393)] 
2025-03-11 14:12:54.578212: Epoch time: 43.94 s 
2025-03-11 14:12:54.581268: Yayy! New best EMA pseudo Dice: 0.9351999759674072 
2025-03-11 14:12:55.299242:  
2025-03-11 14:12:55.305538: Epoch 29 
2025-03-11 14:12:55.309139: Current learning rate: 0.00735 
2025-03-11 14:13:39.228196: train_loss -0.9643 
2025-03-11 14:13:39.234132: val_loss -0.9217 
2025-03-11 14:13:39.236673: Pseudo dice [np.float32(0.9387)] 
2025-03-11 14:13:39.240819: Epoch time: 43.93 s 
2025-03-11 14:13:39.244403: Yayy! New best EMA pseudo Dice: 0.9355000257492065 
2025-03-11 14:13:39.979033:  
2025-03-11 14:13:39.985645: Epoch 30 
2025-03-11 14:13:39.989250: Current learning rate: 0.00725 
2025-03-11 14:14:23.915234: train_loss -0.9662 
2025-03-11 14:14:23.921395: val_loss -0.9225 
2025-03-11 14:14:23.925038: Pseudo dice [np.float32(0.9393)] 
2025-03-11 14:14:23.928251: Epoch time: 43.94 s 
2025-03-11 14:14:23.930910: Yayy! New best EMA pseudo Dice: 0.9358999729156494 
2025-03-11 14:14:24.661040:  
2025-03-11 14:14:24.666915: Epoch 31 
2025-03-11 14:14:24.670527: Current learning rate: 0.00716 
2025-03-11 14:15:08.618464: train_loss -0.9645 
2025-03-11 14:15:08.624556: val_loss -0.9195 
2025-03-11 14:15:08.628081: Pseudo dice [np.float32(0.9372)] 
2025-03-11 14:15:08.631629: Epoch time: 43.96 s 
2025-03-11 14:15:08.635224: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2025-03-11 14:15:09.377104:  
2025-03-11 14:15:09.383451: Epoch 32 
2025-03-11 14:15:09.387009: Current learning rate: 0.00707 
2025-03-11 14:15:53.373377: train_loss -0.9659 
2025-03-11 14:15:53.379661: val_loss -0.924 
2025-03-11 14:15:53.383255: Pseudo dice [np.float32(0.9406)] 
2025-03-11 14:15:53.386871: Epoch time: 44.0 s 
2025-03-11 14:15:53.389921: Yayy! New best EMA pseudo Dice: 0.9365000128746033 
2025-03-11 14:15:54.125979:  
2025-03-11 14:15:54.131607: Epoch 33 
2025-03-11 14:15:54.135484: Current learning rate: 0.00697 
2025-03-11 14:16:38.169481: train_loss -0.9683 
2025-03-11 14:16:38.175759: val_loss -0.9212 
2025-03-11 14:16:38.179397: Pseudo dice [np.float32(0.9391)] 
2025-03-11 14:16:38.183248: Epoch time: 44.04 s 
2025-03-11 14:16:38.186372: Yayy! New best EMA pseudo Dice: 0.9366999864578247 
2025-03-11 14:16:38.912400:  
2025-03-11 14:16:38.919019: Epoch 34 
2025-03-11 14:16:38.922574: Current learning rate: 0.00688 
2025-03-11 14:17:22.967224: train_loss -0.9681 
2025-03-11 14:17:22.972359: val_loss -0.9223 
2025-03-11 14:17:22.977050: Pseudo dice [np.float32(0.9399)] 
2025-03-11 14:17:22.981172: Epoch time: 44.05 s 
2025-03-11 14:17:22.985282: Yayy! New best EMA pseudo Dice: 0.9370999932289124 
2025-03-11 14:17:23.758830:  
2025-03-11 14:17:23.764927: Epoch 35 
2025-03-11 14:17:23.768515: Current learning rate: 0.00679 
2025-03-11 14:18:07.716084: train_loss -0.9685 
2025-03-11 14:18:07.722256: val_loss -0.9201 
2025-03-11 14:18:07.725832: Pseudo dice [np.float32(0.9386)] 
2025-03-11 14:18:07.729362: Epoch time: 43.96 s 
2025-03-11 14:18:07.732912: Yayy! New best EMA pseudo Dice: 0.9372000098228455 
2025-03-11 14:18:08.637959:  
2025-03-11 14:18:08.643076: Epoch 36 
2025-03-11 14:18:08.646609: Current learning rate: 0.00669 
2025-03-11 14:18:52.564345: train_loss -0.9681 
2025-03-11 14:18:52.570579: val_loss -0.9212 
2025-03-11 14:18:52.574192: Pseudo dice [np.float32(0.9391)] 
2025-03-11 14:18:52.577357: Epoch time: 43.93 s 
2025-03-11 14:18:52.580934: Yayy! New best EMA pseudo Dice: 0.9373999834060669 
2025-03-11 14:18:53.337668:  
2025-03-11 14:18:53.343247: Epoch 37 
2025-03-11 14:18:53.346310: Current learning rate: 0.0066 
2025-03-11 14:19:37.270125: train_loss -0.9694 
2025-03-11 14:19:37.276390: val_loss -0.9247 
2025-03-11 14:19:37.279989: Pseudo dice [np.float32(0.9413)] 
2025-03-11 14:19:37.283235: Epoch time: 43.93 s 
2025-03-11 14:19:37.286431: Yayy! New best EMA pseudo Dice: 0.9377999901771545 
2025-03-11 14:19:38.025275:  
2025-03-11 14:19:38.031187: Epoch 38 
2025-03-11 14:19:38.034747: Current learning rate: 0.0065 
2025-03-11 14:20:21.978301: train_loss -0.9686 
2025-03-11 14:20:21.985029: val_loss -0.9246 
2025-03-11 14:20:21.988140: Pseudo dice [np.float32(0.9418)] 
2025-03-11 14:20:21.991677: Epoch time: 43.95 s 
2025-03-11 14:20:21.995298: Yayy! New best EMA pseudo Dice: 0.9381999969482422 
2025-03-11 14:20:22.741136:  
2025-03-11 14:20:22.747248: Epoch 39 
2025-03-11 14:20:22.750900: Current learning rate: 0.00641 
2025-03-11 14:21:06.717223: train_loss -0.9688 
2025-03-11 14:21:06.724359: val_loss -0.9208 
2025-03-11 14:21:06.727993: Pseudo dice [np.float32(0.9396)] 
2025-03-11 14:21:06.731624: Epoch time: 43.98 s 
2025-03-11 14:21:06.735286: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-03-11 14:21:07.481841:  
2025-03-11 14:21:07.487007: Epoch 40 
2025-03-11 14:21:07.490642: Current learning rate: 0.00631 
2025-03-11 14:21:51.442607: train_loss -0.97 
2025-03-11 14:21:51.448762: val_loss -0.9223 
2025-03-11 14:21:51.452351: Pseudo dice [np.float32(0.9405)] 
2025-03-11 14:21:51.455951: Epoch time: 43.96 s 
2025-03-11 14:21:51.459110: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-03-11 14:21:52.204586:  
2025-03-11 14:21:52.210233: Epoch 41 
2025-03-11 14:21:52.214411: Current learning rate: 0.00622 
2025-03-11 14:22:36.170747: train_loss -0.9702 
2025-03-11 14:22:36.177561: val_loss -0.9231 
2025-03-11 14:22:36.181168: Pseudo dice [np.float32(0.9405)] 
2025-03-11 14:22:36.184805: Epoch time: 43.97 s 
2025-03-11 14:22:36.187916: Yayy! New best EMA pseudo Dice: 0.9387999773025513 
2025-03-11 14:22:36.908177:  
2025-03-11 14:22:36.914297: Epoch 42 
2025-03-11 14:22:36.917843: Current learning rate: 0.00612 
2025-03-11 14:23:20.884968: train_loss -0.9683 
2025-03-11 14:23:20.891669: val_loss -0.9236 
2025-03-11 14:23:20.895766: Pseudo dice [np.float32(0.9409)] 
2025-03-11 14:23:20.899402: Epoch time: 43.98 s 
2025-03-11 14:23:20.902748: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-03-11 14:23:21.622323:  
2025-03-11 14:23:21.628739: Epoch 43 
2025-03-11 14:23:21.632892: Current learning rate: 0.00603 
2025-03-11 14:24:05.609018: train_loss -0.9666 
2025-03-11 14:24:05.615175: val_loss -0.9244 
2025-03-11 14:24:05.618917: Pseudo dice [np.float32(0.9419)] 
2025-03-11 14:24:05.622550: Epoch time: 43.99 s 
2025-03-11 14:24:05.626200: Yayy! New best EMA pseudo Dice: 0.939300000667572 
2025-03-11 14:24:06.494108:  
2025-03-11 14:24:06.500381: Epoch 44 
2025-03-11 14:24:06.504517: Current learning rate: 0.00593 
2025-03-11 14:24:50.411695: train_loss -0.9705 
2025-03-11 14:24:50.418435: val_loss -0.9202 
2025-03-11 14:24:50.422041: Pseudo dice [np.float32(0.9389)] 
2025-03-11 14:24:50.426113: Epoch time: 43.92 s 
2025-03-11 14:24:50.971538:  
2025-03-11 14:24:50.977661: Epoch 45 
2025-03-11 14:24:50.980728: Current learning rate: 0.00584 
2025-03-11 14:25:34.872068: train_loss -0.9716 
2025-03-11 14:25:34.878691: val_loss -0.9229 
2025-03-11 14:25:34.882235: Pseudo dice [np.float32(0.9412)] 
2025-03-11 14:25:34.886263: Epoch time: 43.9 s 
2025-03-11 14:25:34.889808: Yayy! New best EMA pseudo Dice: 0.9394000172615051 
2025-03-11 14:25:35.601483:  
2025-03-11 14:25:35.607747: Epoch 46 
2025-03-11 14:25:35.611889: Current learning rate: 0.00574 
2025-03-11 14:26:19.567578: train_loss -0.9718 
2025-03-11 14:26:19.573719: val_loss -0.9226 
2025-03-11 14:26:19.577993: Pseudo dice [np.float32(0.9407)] 
2025-03-11 14:26:19.582020: Epoch time: 43.97 s 
2025-03-11 14:26:19.585666: Yayy! New best EMA pseudo Dice: 0.9394999742507935 
2025-03-11 14:26:20.293315:  
2025-03-11 14:26:20.299013: Epoch 47 
2025-03-11 14:26:20.303166: Current learning rate: 0.00565 
2025-03-11 14:27:04.238942: train_loss -0.9726 
2025-03-11 14:27:04.243988: val_loss -0.9235 
2025-03-11 14:27:04.247526: Pseudo dice [np.float32(0.9416)] 
2025-03-11 14:27:04.251050: Epoch time: 43.95 s 
2025-03-11 14:27:04.254074: Yayy! New best EMA pseudo Dice: 0.9398000240325928 
2025-03-11 14:27:04.967462:  
2025-03-11 14:27:04.973565: Epoch 48 
2025-03-11 14:27:04.976599: Current learning rate: 0.00555 
2025-03-11 14:27:48.934071: train_loss -0.9703 
2025-03-11 14:27:48.940334: val_loss -0.921 
2025-03-11 14:27:48.943905: Pseudo dice [np.float32(0.9394)] 
2025-03-11 14:27:48.947443: Epoch time: 43.97 s 
2025-03-11 14:27:49.494901:  
2025-03-11 14:27:49.500549: Epoch 49 
2025-03-11 14:27:49.503611: Current learning rate: 0.00546 
2025-03-11 14:28:33.448134: train_loss -0.9718 
2025-03-11 14:28:33.454799: val_loss -0.9228 
2025-03-11 14:28:33.458374: Pseudo dice [np.float32(0.941)] 
2025-03-11 14:28:33.460919: Epoch time: 43.95 s 
2025-03-11 14:28:33.616607: Yayy! New best EMA pseudo Dice: 0.9398999810218811 
2025-03-11 14:28:34.344405:  
2025-03-11 14:28:34.350653: Epoch 50 
2025-03-11 14:28:34.353773: Current learning rate: 0.00536 
2025-03-11 14:29:18.324247: train_loss -0.973 
2025-03-11 14:29:18.330529: val_loss -0.9226 
2025-03-11 14:29:18.334149: Pseudo dice [np.float32(0.941)] 
2025-03-11 14:29:18.337260: Epoch time: 43.98 s 
2025-03-11 14:29:18.340380: Yayy! New best EMA pseudo Dice: 0.9399999976158142 
2025-03-11 14:29:19.055367:  
2025-03-11 14:29:19.061566: Epoch 51 
2025-03-11 14:29:19.065207: Current learning rate: 0.00526 
2025-03-11 14:30:02.981593: train_loss -0.9722 
2025-03-11 14:30:02.987641: val_loss -0.9235 
2025-03-11 14:30:02.991165: Pseudo dice [np.float32(0.9419)] 
2025-03-11 14:30:02.994205: Epoch time: 43.93 s 
2025-03-11 14:30:02.996722: Yayy! New best EMA pseudo Dice: 0.9401999711990356 
2025-03-11 14:30:03.714513:  
2025-03-11 14:30:03.720115: Epoch 52 
2025-03-11 14:30:03.724375: Current learning rate: 0.00517 
2025-03-11 14:30:47.743712: train_loss -0.9734 
2025-03-11 14:30:47.749356: val_loss -0.9222 
2025-03-11 14:30:47.752923: Pseudo dice [np.float32(0.941)] 
2025-03-11 14:30:47.756479: Epoch time: 44.03 s 
2025-03-11 14:30:47.760092: Yayy! New best EMA pseudo Dice: 0.9401999711990356 
2025-03-11 14:30:48.517728:  
2025-03-11 14:30:48.523094: Epoch 53 
2025-03-11 14:30:48.526787: Current learning rate: 0.00507 
2025-03-11 14:31:32.438479: train_loss -0.9737 
2025-03-11 14:31:32.444330: val_loss -0.9203 
2025-03-11 14:31:32.447899: Pseudo dice [np.float32(0.9396)] 
2025-03-11 14:31:32.450419: Epoch time: 43.92 s 
2025-03-11 14:31:33.002818:  
2025-03-11 14:31:33.008376: Epoch 54 
2025-03-11 14:31:33.011398: Current learning rate: 0.00497 
2025-03-11 14:32:16.931309: train_loss -0.9729 
2025-03-11 14:32:16.937045: val_loss -0.9243 
2025-03-11 14:32:16.940802: Pseudo dice [np.float32(0.942)] 
2025-03-11 14:32:16.944047: Epoch time: 43.93 s 
2025-03-11 14:32:16.947125: Yayy! New best EMA pseudo Dice: 0.9404000043869019 
2025-03-11 14:32:17.675586:  
2025-03-11 14:32:17.681279: Epoch 55 
2025-03-11 14:32:17.684883: Current learning rate: 0.00487 
2025-03-11 14:33:01.630368: train_loss -0.9737 
2025-03-11 14:33:01.636568: val_loss -0.9225 
2025-03-11 14:33:01.640257: Pseudo dice [np.float32(0.9409)] 
2025-03-11 14:33:01.643380: Epoch time: 43.96 s 
2025-03-11 14:33:01.647028: Yayy! New best EMA pseudo Dice: 0.9404000043869019 
2025-03-11 14:33:02.362963:  
2025-03-11 14:33:02.369164: Epoch 56 
2025-03-11 14:33:02.372241: Current learning rate: 0.00478 
2025-03-11 14:33:46.309672: train_loss -0.9746 
2025-03-11 14:33:46.315917: val_loss -0.9212 
2025-03-11 14:33:46.319022: Pseudo dice [np.float32(0.9406)] 
2025-03-11 14:33:46.322593: Epoch time: 43.95 s 
2025-03-11 14:33:46.325638: Yayy! New best EMA pseudo Dice: 0.9404000043869019 
2025-03-11 14:33:47.042271:  
2025-03-11 14:33:47.048759: Epoch 57 
2025-03-11 14:33:47.051870: Current learning rate: 0.00468 
2025-03-11 14:34:30.989075: train_loss -0.974 
2025-03-11 14:34:30.995192: val_loss -0.9198 
2025-03-11 14:34:30.998738: Pseudo dice [np.float32(0.9397)] 
2025-03-11 14:34:31.002303: Epoch time: 43.95 s 
2025-03-11 14:34:31.556314:  
2025-03-11 14:34:31.561841: Epoch 58 
2025-03-11 14:34:31.565385: Current learning rate: 0.00458 
2025-03-11 14:35:15.515604: train_loss -0.973 
2025-03-11 14:35:15.522423: val_loss -0.9233 
2025-03-11 14:35:15.525987: Pseudo dice [np.float32(0.942)] 
2025-03-11 14:35:15.529076: Epoch time: 43.96 s 
2025-03-11 14:35:15.532868: Yayy! New best EMA pseudo Dice: 0.940500020980835 
2025-03-11 14:35:16.259719:  
2025-03-11 14:35:16.265995: Epoch 59 
2025-03-11 14:35:16.270117: Current learning rate: 0.00448 
2025-03-11 14:36:00.240950: train_loss -0.9718 
2025-03-11 14:36:00.246525: val_loss -0.9222 
2025-03-11 14:36:00.250068: Pseudo dice [np.float32(0.9411)] 
2025-03-11 14:36:00.253592: Epoch time: 43.98 s 
2025-03-11 14:36:00.256617: Yayy! New best EMA pseudo Dice: 0.9405999779701233 
2025-03-11 14:36:01.132187:  
2025-03-11 14:36:01.137738: Epoch 60 
2025-03-11 14:36:01.140768: Current learning rate: 0.00438 
2025-03-11 14:36:45.089218: train_loss -0.9725 
2025-03-11 14:36:45.094965: val_loss -0.922 
2025-03-11 14:36:45.098614: Pseudo dice [np.float32(0.9411)] 
2025-03-11 14:36:45.101696: Epoch time: 43.96 s 
2025-03-11 14:36:45.105810: Yayy! New best EMA pseudo Dice: 0.9405999779701233 
2025-03-11 14:36:45.846873:  
2025-03-11 14:36:45.852498: Epoch 61 
2025-03-11 14:36:45.856278: Current learning rate: 0.00429 
2025-03-11 14:37:29.771800: train_loss -0.974 
2025-03-11 14:37:29.777963: val_loss -0.9231 
2025-03-11 14:37:29.781508: Pseudo dice [np.float32(0.9419)] 
2025-03-11 14:37:29.784547: Epoch time: 43.93 s 
2025-03-11 14:37:29.788142: Yayy! New best EMA pseudo Dice: 0.9408000111579895 
2025-03-11 14:37:30.518693:  
2025-03-11 14:37:30.524302: Epoch 62 
2025-03-11 14:37:30.527856: Current learning rate: 0.00419 
2025-03-11 14:38:14.469317: train_loss -0.9706 
2025-03-11 14:38:14.474124: val_loss -0.9229 
2025-03-11 14:38:14.477671: Pseudo dice [np.float32(0.9412)] 
2025-03-11 14:38:14.481303: Epoch time: 43.95 s 
2025-03-11 14:38:14.484430: Yayy! New best EMA pseudo Dice: 0.9408000111579895 
2025-03-11 14:38:15.219380:  
2025-03-11 14:38:15.224948: Epoch 63 
2025-03-11 14:38:15.227992: Current learning rate: 0.00409 
2025-03-11 14:38:59.149749: train_loss -0.9717 
2025-03-11 14:38:59.156329: val_loss -0.9226 
2025-03-11 14:38:59.159439: Pseudo dice [np.float32(0.941)] 
2025-03-11 14:38:59.163276: Epoch time: 43.93 s 
2025-03-11 14:38:59.166912: Yayy! New best EMA pseudo Dice: 0.9408000111579895 
2025-03-11 14:38:59.894125:  
2025-03-11 14:38:59.900217: Epoch 64 
2025-03-11 14:38:59.904059: Current learning rate: 0.00399 
2025-03-11 14:39:43.819321: train_loss -0.9718 
2025-03-11 14:39:43.825418: val_loss -0.9218 
2025-03-11 14:39:43.828563: Pseudo dice [np.float32(0.9411)] 
2025-03-11 14:39:43.832642: Epoch time: 43.93 s 
2025-03-11 14:39:43.835697: Yayy! New best EMA pseudo Dice: 0.9408000111579895 
2025-03-11 14:39:44.569196:  
2025-03-11 14:39:44.575407: Epoch 65 
2025-03-11 14:39:44.579022: Current learning rate: 0.00389 
2025-03-11 14:40:28.553513: train_loss -0.9749 
2025-03-11 14:40:28.559643: val_loss -0.922 
2025-03-11 14:40:28.562759: Pseudo dice [np.float32(0.9411)] 
2025-03-11 14:40:28.566678: Epoch time: 43.98 s 
2025-03-11 14:40:28.570288: Yayy! New best EMA pseudo Dice: 0.9409000277519226 
2025-03-11 14:40:29.314203:  
2025-03-11 14:40:29.319931: Epoch 66 
2025-03-11 14:40:29.322986: Current learning rate: 0.00379 
2025-03-11 14:41:13.255571: train_loss -0.9738 
2025-03-11 14:41:13.263759: val_loss -0.9251 
2025-03-11 14:41:13.268325: Pseudo dice [np.float32(0.943)] 
2025-03-11 14:41:13.271882: Epoch time: 43.94 s 
2025-03-11 14:41:13.274938: Yayy! New best EMA pseudo Dice: 0.941100001335144 
2025-03-11 14:41:14.005738:  
2025-03-11 14:41:14.011773: Epoch 67 
2025-03-11 14:41:14.015361: Current learning rate: 0.00369 
2025-03-11 14:41:57.957736: train_loss -0.9753 
2025-03-11 14:41:57.964799: val_loss -0.9229 
2025-03-11 14:41:57.967833: Pseudo dice [np.float32(0.9421)] 
2025-03-11 14:41:57.971362: Epoch time: 43.95 s 
2025-03-11 14:41:57.974890: Yayy! New best EMA pseudo Dice: 0.9412000179290771 
2025-03-11 14:41:58.912389:  
2025-03-11 14:41:58.918510: Epoch 68 
2025-03-11 14:41:58.921614: Current learning rate: 0.00359 
2025-03-11 14:42:42.842797: train_loss -0.976 
2025-03-11 14:42:42.849356: val_loss -0.9233 
2025-03-11 14:42:42.852392: Pseudo dice [np.float32(0.9421)] 
2025-03-11 14:42:42.855443: Epoch time: 43.93 s 
2025-03-11 14:42:42.858973: Yayy! New best EMA pseudo Dice: 0.9412999749183655 
2025-03-11 14:42:43.613503:  
2025-03-11 14:42:43.619241: Epoch 69 
2025-03-11 14:42:43.623315: Current learning rate: 0.00349 
2025-03-11 14:43:27.570231: train_loss -0.9743 
2025-03-11 14:43:27.576465: val_loss -0.9234 
2025-03-11 14:43:27.580044: Pseudo dice [np.float32(0.9426)] 
2025-03-11 14:43:27.583186: Epoch time: 43.96 s 
2025-03-11 14:43:27.586484: Yayy! New best EMA pseudo Dice: 0.9413999915122986 
2025-03-11 14:43:28.327300:  
2025-03-11 14:43:28.333365: Epoch 70 
2025-03-11 14:43:28.336399: Current learning rate: 0.00338 
2025-03-11 14:44:12.277921: train_loss -0.9748 
2025-03-11 14:44:12.284133: val_loss -0.9206 
2025-03-11 14:44:12.287688: Pseudo dice [np.float32(0.9408)] 
2025-03-11 14:44:12.290745: Epoch time: 43.95 s 
2025-03-11 14:44:12.868585:  
2025-03-11 14:44:12.874309: Epoch 71 
2025-03-11 14:44:12.877417: Current learning rate: 0.00328 
2025-03-11 14:44:56.795357: train_loss -0.9755 
2025-03-11 14:44:56.801053: val_loss -0.9201 
2025-03-11 14:44:56.807341: Pseudo dice [np.float32(0.9402)] 
2025-03-11 14:44:56.810973: Epoch time: 43.93 s 
2025-03-11 14:44:57.377762:  
2025-03-11 14:44:57.383511: Epoch 72 
2025-03-11 14:44:57.387153: Current learning rate: 0.00318 
2025-03-11 14:45:41.329073: train_loss -0.9767 
2025-03-11 14:45:41.334881: val_loss -0.9198 
2025-03-11 14:45:41.338519: Pseudo dice [np.float32(0.9397)] 
2025-03-11 14:45:41.341610: Epoch time: 43.95 s 
2025-03-11 14:45:41.912596:  
2025-03-11 14:45:41.918828: Epoch 73 
2025-03-11 14:45:41.921946: Current learning rate: 0.00308 
2025-03-11 14:46:25.967711: train_loss -0.9742 
2025-03-11 14:46:25.974251: val_loss -0.923 
2025-03-11 14:46:25.977279: Pseudo dice [np.float32(0.9419)] 
2025-03-11 14:46:25.980868: Epoch time: 44.06 s 
2025-03-11 14:46:26.551455:  
2025-03-11 14:46:26.558138: Epoch 74 
2025-03-11 14:46:26.561697: Current learning rate: 0.00297 
2025-03-11 14:47:10.476825: train_loss -0.9762 
2025-03-11 14:47:10.482873: val_loss -0.921 
2025-03-11 14:47:10.485906: Pseudo dice [np.float32(0.9411)] 
2025-03-11 14:47:10.489422: Epoch time: 43.93 s 
2025-03-11 14:47:11.060579:  
2025-03-11 14:47:11.066712: Epoch 75 
2025-03-11 14:47:11.070288: Current learning rate: 0.00287 
2025-03-11 14:47:55.084714: train_loss -0.9772 
2025-03-11 14:47:55.090779: val_loss -0.9234 
2025-03-11 14:47:55.094321: Pseudo dice [np.float32(0.9425)] 
2025-03-11 14:47:55.097358: Epoch time: 44.02 s 
2025-03-11 14:47:55.830081:  
2025-03-11 14:47:55.836141: Epoch 76 
2025-03-11 14:47:55.839686: Current learning rate: 0.00277 
2025-03-11 14:48:39.732876: train_loss -0.9762 
2025-03-11 14:48:39.739089: val_loss -0.9241 
2025-03-11 14:48:39.742737: Pseudo dice [np.float32(0.9432)] 
2025-03-11 14:48:39.745923: Epoch time: 43.9 s 
2025-03-11 14:48:39.749040: Yayy! New best EMA pseudo Dice: 0.9415000081062317 
2025-03-11 14:48:40.487223:  
2025-03-11 14:48:40.492980: Epoch 77 
2025-03-11 14:48:40.496615: Current learning rate: 0.00266 
2025-03-11 14:49:24.431229: train_loss -0.9764 
2025-03-11 14:49:24.437487: val_loss -0.9218 
2025-03-11 14:49:24.441270: Pseudo dice [np.float32(0.9415)] 
2025-03-11 14:49:24.444533: Epoch time: 43.94 s 
2025-03-11 14:49:25.030819:  
2025-03-11 14:49:25.036448: Epoch 78 
2025-03-11 14:49:25.039611: Current learning rate: 0.00256 
2025-03-11 14:50:08.915624: train_loss -0.9766 
2025-03-11 14:50:08.922248: val_loss -0.9213 
2025-03-11 14:50:08.925013: Pseudo dice [np.float32(0.9413)] 
2025-03-11 14:50:08.928922: Epoch time: 43.89 s 
2025-03-11 14:50:09.535066:  
2025-03-11 14:50:09.540172: Epoch 79 
2025-03-11 14:50:09.544257: Current learning rate: 0.00245 
2025-03-11 14:50:53.424037: train_loss -0.9765 
2025-03-11 14:50:53.428177: val_loss -0.9212 
2025-03-11 14:50:53.431788: Pseudo dice [np.float32(0.9412)] 
2025-03-11 14:50:53.435405: Epoch time: 43.89 s 
2025-03-11 14:50:54.017056:  
2025-03-11 14:50:54.023349: Epoch 80 
2025-03-11 14:50:54.027002: Current learning rate: 0.00235 
2025-03-11 14:51:37.937520: train_loss -0.9767 
2025-03-11 14:51:37.943788: val_loss -0.9223 
2025-03-11 14:51:37.946904: Pseudo dice [np.float32(0.9412)] 
2025-03-11 14:51:37.950605: Epoch time: 43.92 s 
2025-03-11 14:51:38.529529:  
2025-03-11 14:51:38.535701: Epoch 81 
2025-03-11 14:51:38.539295: Current learning rate: 0.00224 
2025-03-11 14:52:22.434767: train_loss -0.9759 
2025-03-11 14:52:22.442299: val_loss -0.9236 
2025-03-11 14:52:22.445406: Pseudo dice [np.float32(0.9428)] 
2025-03-11 14:52:22.449089: Epoch time: 43.91 s 
2025-03-11 14:52:22.452212: Yayy! New best EMA pseudo Dice: 0.9416000247001648 
2025-03-11 14:52:23.197234:  
2025-03-11 14:52:23.202912: Epoch 82 
2025-03-11 14:52:23.206564: Current learning rate: 0.00214 
2025-03-11 14:53:07.127846: train_loss -0.9743 
2025-03-11 14:53:07.132503: val_loss -0.9219 
2025-03-11 14:53:07.136083: Pseudo dice [np.float32(0.9413)] 
2025-03-11 14:53:07.139131: Epoch time: 43.93 s 
2025-03-11 14:53:07.687099:  
2025-03-11 14:53:07.693249: Epoch 83 
2025-03-11 14:53:07.696855: Current learning rate: 0.00203 
2025-03-11 14:53:51.605498: train_loss -0.9755 
2025-03-11 14:53:51.611559: val_loss -0.9211 
2025-03-11 14:53:51.614591: Pseudo dice [np.float32(0.9409)] 
2025-03-11 14:53:51.618619: Epoch time: 43.92 s 
2025-03-11 14:53:52.330247:  
2025-03-11 14:53:52.333795: Epoch 84 
2025-03-11 14:53:52.337819: Current learning rate: 0.00192 
2025-03-11 14:54:36.224818: train_loss -0.9743 
2025-03-11 14:54:36.230933: val_loss -0.9203 
2025-03-11 14:54:36.234612: Pseudo dice [np.float32(0.9399)] 
2025-03-11 14:54:36.237696: Epoch time: 43.9 s 
2025-03-11 14:54:36.794412:  
2025-03-11 14:54:36.800132: Epoch 85 
2025-03-11 14:54:36.803697: Current learning rate: 0.00181 
2025-03-11 14:55:20.669763: train_loss -0.9764 
2025-03-11 14:55:20.675884: val_loss -0.9208 
2025-03-11 14:55:20.679581: Pseudo dice [np.float32(0.9406)] 
2025-03-11 14:55:20.682843: Epoch time: 43.88 s 
2025-03-11 14:55:21.232456:  
2025-03-11 14:55:21.238614: Epoch 86 
2025-03-11 14:55:21.241674: Current learning rate: 0.0017 
2025-03-11 14:56:05.153746: train_loss -0.9765 
2025-03-11 14:56:05.159907: val_loss -0.922 
2025-03-11 14:56:05.163008: Pseudo dice [np.float32(0.9415)] 
2025-03-11 14:56:05.166164: Epoch time: 43.92 s 
2025-03-11 14:56:05.714239:  
2025-03-11 14:56:05.719475: Epoch 87 
2025-03-11 14:56:05.723529: Current learning rate: 0.00159 
2025-03-11 14:56:49.646828: train_loss -0.9754 
2025-03-11 14:56:49.652965: val_loss -0.9209 
2025-03-11 14:56:49.656705: Pseudo dice [np.float32(0.9408)] 
2025-03-11 14:56:49.659340: Epoch time: 43.93 s 
2025-03-11 14:56:50.203867:  
2025-03-11 14:56:50.209972: Epoch 88 
2025-03-11 14:56:50.212496: Current learning rate: 0.00148 
2025-03-11 14:57:34.104566: train_loss -0.9767 
2025-03-11 14:57:34.110621: val_loss -0.9226 
2025-03-11 14:57:34.113658: Pseudo dice [np.float32(0.9418)] 
2025-03-11 14:57:34.117763: Epoch time: 43.9 s 
2025-03-11 14:57:34.663961:  
2025-03-11 14:57:34.669149: Epoch 89 
2025-03-11 14:57:34.672263: Current learning rate: 0.00137 
2025-03-11 14:58:18.591508: train_loss -0.9762 
2025-03-11 14:58:18.597079: val_loss -0.9218 
2025-03-11 14:58:18.601575: Pseudo dice [np.float32(0.9419)] 
2025-03-11 14:58:18.604790: Epoch time: 43.93 s 
2025-03-11 14:58:19.149469:  
2025-03-11 14:58:19.155077: Epoch 90 
2025-03-11 14:58:19.158162: Current learning rate: 0.00126 
2025-03-11 14:59:03.132784: train_loss -0.9771 
2025-03-11 14:59:03.139035: val_loss -0.9212 
2025-03-11 14:59:03.142678: Pseudo dice [np.float32(0.9416)] 
2025-03-11 14:59:03.145741: Epoch time: 43.98 s 
2025-03-11 14:59:03.683726:  
2025-03-11 14:59:03.688801: Epoch 91 
2025-03-11 14:59:03.692894: Current learning rate: 0.00115 
2025-03-11 14:59:47.547625: train_loss -0.9773 
2025-03-11 14:59:47.553240: val_loss -0.9219 
2025-03-11 14:59:47.556845: Pseudo dice [np.float32(0.9415)] 
2025-03-11 14:59:47.560432: Epoch time: 43.86 s 
2025-03-11 14:59:48.116822:  
2025-03-11 14:59:48.122432: Epoch 92 
2025-03-11 14:59:48.126132: Current learning rate: 0.00103 
2025-03-11 15:00:32.139863: train_loss -0.9768 
2025-03-11 15:00:32.145993: val_loss -0.9211 
2025-03-11 15:00:32.149580: Pseudo dice [np.float32(0.9415)] 
2025-03-11 15:00:32.152752: Epoch time: 44.02 s 
2025-03-11 15:00:32.705335:  
2025-03-11 15:00:32.710978: Epoch 93 
2025-03-11 15:00:32.714547: Current learning rate: 0.00091 
2025-03-11 15:01:16.650724: train_loss -0.9749 
2025-03-11 15:01:16.656753: val_loss -0.9223 
2025-03-11 15:01:16.660323: Pseudo dice [np.float32(0.9422)] 
2025-03-11 15:01:16.663447: Epoch time: 43.95 s 
2025-03-11 15:01:17.213204:  
2025-03-11 15:01:17.219274: Epoch 94 
2025-03-11 15:01:17.222956: Current learning rate: 0.00079 
2025-03-11 15:02:01.102495: train_loss -0.977 
2025-03-11 15:02:01.108209: val_loss -0.9224 
2025-03-11 15:02:01.112367: Pseudo dice [np.float32(0.9422)] 
2025-03-11 15:02:01.115649: Epoch time: 43.89 s 
2025-03-11 15:02:01.656720:  
2025-03-11 15:02:01.662297: Epoch 95 
2025-03-11 15:02:01.665928: Current learning rate: 0.00067 
2025-03-11 15:02:45.556769: train_loss -0.9782 
2025-03-11 15:02:45.562460: val_loss -0.9196 
2025-03-11 15:02:45.566102: Pseudo dice [np.float32(0.9404)] 
2025-03-11 15:02:45.569220: Epoch time: 43.9 s 
2025-03-11 15:02:46.113627:  
2025-03-11 15:02:46.119246: Epoch 96 
2025-03-11 15:02:46.122369: Current learning rate: 0.00055 
2025-03-11 15:03:30.006477: train_loss -0.9779 
2025-03-11 15:03:30.012734: val_loss -0.9207 
2025-03-11 15:03:30.016338: Pseudo dice [np.float32(0.9411)] 
2025-03-11 15:03:30.019916: Epoch time: 43.89 s 
2025-03-11 15:03:30.575105:  
2025-03-11 15:03:30.580815: Epoch 97 
2025-03-11 15:03:30.584190: Current learning rate: 0.00043 
2025-03-11 15:04:14.522457: train_loss -0.9781 
2025-03-11 15:04:14.528239: val_loss -0.9211 
2025-03-11 15:04:14.532369: Pseudo dice [np.float32(0.9416)] 
2025-03-11 15:04:14.535218: Epoch time: 43.95 s 
2025-03-11 15:04:15.090379:  
2025-03-11 15:04:15.096442: Epoch 98 
2025-03-11 15:04:15.099577: Current learning rate: 0.0003 
2025-03-11 15:04:59.013174: train_loss -0.9778 
2025-03-11 15:04:59.019259: val_loss -0.9208 
2025-03-11 15:04:59.022789: Pseudo dice [np.float32(0.9415)] 
2025-03-11 15:04:59.026835: Epoch time: 43.92 s 
2025-03-11 15:04:59.579412:  
2025-03-11 15:04:59.584978: Epoch 99 
2025-03-11 15:04:59.588509: Current learning rate: 0.00016 
2025-03-11 15:05:43.531547: train_loss -0.9776 
2025-03-11 15:05:43.537816: val_loss -0.9231 
2025-03-11 15:05:43.541431: Pseudo dice [np.float32(0.9423)] 
2025-03-11 15:05:43.545120: Epoch time: 43.95 s 
2025-03-11 15:05:44.314562: Training done. 
2025-03-11 15:05:44.346109: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-11 15:05:44.353583: The split file contains 5 splits. 
2025-03-11 15:05:44.359179: Desired fold for training: 0 
2025-03-11 15:05:44.365115: This split has 16 training and 4 validation cases. 
2025-03-11 15:05:44.369873: predicting la_007 
2025-03-11 15:05:44.375124: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2025-03-11 15:05:50.450215: predicting la_016 
2025-03-11 15:05:50.462209: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2025-03-11 15:05:52.818581: predicting la_021 
2025-03-11 15:05:52.828731: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2025-03-11 15:05:55.185673: predicting la_024 
2025-03-11 15:05:55.197723: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2025-03-11 15:06:04.759784: Validation complete 
2025-03-11 15:06:04.766637: Mean Validation Dice:  0.8891513958408095 
