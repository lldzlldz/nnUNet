
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-07 16:19:05.335757: do_dummy_2d_data_aug: False 
2024-12-07 16:19:05.336758: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-07 16:19:05.344128: The split file contains 5 splits. 
2024-12-07 16:19:05.347127: Desired fold for training: 0 
2024-12-07 16:19:05.349129: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 40, 'patch_size': [320, 256], 'median_image_size_in_voxels': [320.0, 232.0], 'spacing': [1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2024-12-07 16:19:11.791291: unpacking dataset... 
2024-12-07 16:19:11.977920: unpacking done... 
2024-12-07 16:19:14.124317:  
2024-12-07 16:19:14.128473: Epoch 0 
2024-12-07 16:19:14.131541: Current learning rate: 0.01 
2024-12-07 16:19:50.956022: train_loss -0.6183 
2024-12-07 16:19:50.962035: val_loss -0.8771 
2024-12-07 16:19:50.964541: Pseudo dice [np.float32(0.8984)] 
2024-12-07 16:19:50.967046: Epoch time: 36.83 s 
2024-12-07 16:19:50.970551: Yayy! New best EMA pseudo Dice: 0.8984000086784363 
2024-12-07 16:19:51.618437:  
2024-12-07 16:19:51.622480: Epoch 1 
2024-12-07 16:19:51.626002: Current learning rate: 0.00991 
2024-12-07 16:20:25.052054: train_loss -0.9428 
2024-12-07 16:20:25.057632: val_loss -0.8909 
2024-12-07 16:20:25.061668: Pseudo dice [np.float32(0.9087)] 
2024-12-07 16:20:25.064764: Epoch time: 33.43 s 
2024-12-07 16:20:25.067802: Yayy! New best EMA pseudo Dice: 0.8995000123977661 
2024-12-07 16:20:25.809099:  
2024-12-07 16:20:25.814726: Epoch 2 
2024-12-07 16:20:25.817797: Current learning rate: 0.00982 
2024-12-07 16:20:59.055558: train_loss -0.9601 
2024-12-07 16:20:59.061117: val_loss -0.8779 
2024-12-07 16:20:59.064153: Pseudo dice [np.float32(0.8996)] 
2024-12-07 16:20:59.067201: Epoch time: 33.25 s 
2024-12-07 16:20:59.069834: Yayy! New best EMA pseudo Dice: 0.8995000123977661 
2024-12-07 16:20:59.833501:  
2024-12-07 16:20:59.839050: Epoch 3 
2024-12-07 16:20:59.841578: Current learning rate: 0.00973 
2024-12-07 16:21:33.491206: train_loss -0.9679 
2024-12-07 16:21:33.497787: val_loss -0.8827 
2024-12-07 16:21:33.500334: Pseudo dice [np.float32(0.9033)] 
2024-12-07 16:21:33.503938: Epoch time: 33.66 s 
2024-12-07 16:21:33.506477: Yayy! New best EMA pseudo Dice: 0.8999000191688538 
2024-12-07 16:21:34.240219:  
2024-12-07 16:21:34.247812: Epoch 4 
2024-12-07 16:21:34.250871: Current learning rate: 0.00964 
2024-12-07 16:22:07.615637: train_loss -0.972 
2024-12-07 16:22:07.621204: val_loss -0.8804 
2024-12-07 16:22:07.623538: Pseudo dice [np.float32(0.9014)] 
2024-12-07 16:22:07.627758: Epoch time: 33.38 s 
2024-12-07 16:22:07.630478: Yayy! New best EMA pseudo Dice: 0.8999999761581421 
2024-12-07 16:22:08.384710:  
2024-12-07 16:22:08.388758: Epoch 5 
2024-12-07 16:22:08.392328: Current learning rate: 0.00955 
2024-12-07 16:22:41.839477: train_loss -0.9745 
2024-12-07 16:22:41.845541: val_loss -0.8802 
2024-12-07 16:22:41.849323: Pseudo dice [np.float32(0.9022)] 
2024-12-07 16:22:41.851496: Epoch time: 33.46 s 
2024-12-07 16:22:41.854027: Yayy! New best EMA pseudo Dice: 0.9002000093460083 
2024-12-07 16:22:42.705568:  
2024-12-07 16:22:42.711590: Epoch 6 
2024-12-07 16:22:42.714095: Current learning rate: 0.00946 
2024-12-07 16:23:17.479137: train_loss -0.9772 
2024-12-07 16:23:17.484236: val_loss -0.8833 
2024-12-07 16:23:17.487304: Pseudo dice [np.float32(0.9045)] 
2024-12-07 16:23:17.490868: Epoch time: 34.77 s 
2024-12-07 16:23:17.493929: Yayy! New best EMA pseudo Dice: 0.9006999731063843 
2024-12-07 16:23:18.228497:  
2024-12-07 16:23:18.234083: Epoch 7 
2024-12-07 16:23:18.237136: Current learning rate: 0.00937 
2024-12-07 16:23:52.994999: train_loss -0.9794 
2024-12-07 16:23:53.001079: val_loss -0.8838 
2024-12-07 16:23:53.003620: Pseudo dice [np.float32(0.9057)] 
2024-12-07 16:23:53.007663: Epoch time: 34.77 s 
2024-12-07 16:23:53.010198: Yayy! New best EMA pseudo Dice: 0.901199996471405 
2024-12-07 16:23:53.753533:  
2024-12-07 16:23:53.759213: Epoch 8 
2024-12-07 16:23:53.761761: Current learning rate: 0.00928 
2024-12-07 16:24:27.592501: train_loss -0.9798 
2024-12-07 16:24:27.597460: val_loss -0.8837 
2024-12-07 16:24:27.600873: Pseudo dice [np.float32(0.906)] 
2024-12-07 16:24:27.603399: Epoch time: 33.84 s 
2024-12-07 16:24:27.607365: Yayy! New best EMA pseudo Dice: 0.9016000032424927 
2024-12-07 16:24:28.357395:  
2024-12-07 16:24:28.362525: Epoch 9 
2024-12-07 16:24:28.365569: Current learning rate: 0.00919 
2024-12-07 16:25:01.109924: train_loss -0.9812 
2024-12-07 16:25:01.117305: val_loss -0.8868 
2024-12-07 16:25:01.119811: Pseudo dice [np.float32(0.9086)] 
2024-12-07 16:25:01.123359: Epoch time: 32.75 s 
2024-12-07 16:25:01.126272: Yayy! New best EMA pseudo Dice: 0.9023000001907349 
2024-12-07 16:25:01.858829:  
2024-12-07 16:25:01.863834: Epoch 10 
2024-12-07 16:25:01.866854: Current learning rate: 0.0091 
2024-12-07 16:25:34.700426: train_loss -0.982 
2024-12-07 16:25:34.705900: val_loss -0.8812 
2024-12-07 16:25:34.708956: Pseudo dice [np.float32(0.9043)] 
2024-12-07 16:25:34.712446: Epoch time: 32.84 s 
2024-12-07 16:25:34.715026: Yayy! New best EMA pseudo Dice: 0.9024999737739563 
2024-12-07 16:25:35.432868:  
2024-12-07 16:25:35.438804: Epoch 11 
2024-12-07 16:25:35.442552: Current learning rate: 0.009 
2024-12-07 16:26:08.660053: train_loss -0.9821 
2024-12-07 16:26:08.667157: val_loss -0.8833 
2024-12-07 16:26:08.670213: Pseudo dice [np.float32(0.906)] 
2024-12-07 16:26:08.672755: Epoch time: 33.23 s 
2024-12-07 16:26:08.675295: Yayy! New best EMA pseudo Dice: 0.902899980545044 
2024-12-07 16:26:09.397727:  
2024-12-07 16:26:09.404846: Epoch 12 
2024-12-07 16:26:09.407899: Current learning rate: 0.00891 
2024-12-07 16:26:41.966733: train_loss -0.9837 
2024-12-07 16:26:41.971835: val_loss -0.8824 
2024-12-07 16:26:41.974891: Pseudo dice [np.float32(0.9052)] 
2024-12-07 16:26:41.977436: Epoch time: 32.57 s 
2024-12-07 16:26:41.979970: Yayy! New best EMA pseudo Dice: 0.9031000137329102 
2024-12-07 16:26:42.862457:  
2024-12-07 16:26:42.867520: Epoch 13 
2024-12-07 16:26:42.870055: Current learning rate: 0.00882 
2024-12-07 16:27:15.774797: train_loss -0.9841 
2024-12-07 16:27:15.780678: val_loss -0.8783 
2024-12-07 16:27:15.785234: Pseudo dice [np.float32(0.902)] 
2024-12-07 16:27:15.789499: Epoch time: 32.91 s 
2024-12-07 16:27:16.361666:  
2024-12-07 16:27:16.366966: Epoch 14 
2024-12-07 16:27:16.370804: Current learning rate: 0.00873 
2024-12-07 16:27:49.228854: train_loss -0.9846 
2024-12-07 16:27:49.235909: val_loss -0.8786 
2024-12-07 16:27:49.239298: Pseudo dice [np.float32(0.9034)] 
2024-12-07 16:27:49.241321: Epoch time: 32.87 s 
2024-12-07 16:27:49.813502:  
2024-12-07 16:27:49.818985: Epoch 15 
2024-12-07 16:27:49.821490: Current learning rate: 0.00864 
2024-12-07 16:28:22.756934: train_loss -0.9847 
2024-12-07 16:28:22.762518: val_loss -0.8811 
2024-12-07 16:28:22.765570: Pseudo dice [np.float32(0.9048)] 
2024-12-07 16:28:22.768109: Epoch time: 32.94 s 
2024-12-07 16:28:22.771659: Yayy! New best EMA pseudo Dice: 0.9031999707221985 
2024-12-07 16:28:23.520440:  
2024-12-07 16:28:23.525523: Epoch 16 
2024-12-07 16:28:23.528066: Current learning rate: 0.00855 
2024-12-07 16:28:56.298234: train_loss -0.985 
2024-12-07 16:28:56.303823: val_loss -0.8714 
2024-12-07 16:28:56.306869: Pseudo dice [np.float32(0.8973)] 
2024-12-07 16:28:56.310410: Epoch time: 32.78 s 
2024-12-07 16:28:56.882373:  
2024-12-07 16:28:56.889096: Epoch 17 
2024-12-07 16:28:56.892148: Current learning rate: 0.00846 
2024-12-07 16:29:29.772533: train_loss -0.9852 
2024-12-07 16:29:29.779063: val_loss -0.8801 
2024-12-07 16:29:29.781922: Pseudo dice [np.float32(0.9037)] 
2024-12-07 16:29:29.784963: Epoch time: 32.89 s 
2024-12-07 16:29:30.358315:  
2024-12-07 16:29:30.363806: Epoch 18 
2024-12-07 16:29:30.365892: Current learning rate: 0.00836 
2024-12-07 16:30:03.395040: train_loss -0.9858 
2024-12-07 16:30:03.401169: val_loss -0.884 
2024-12-07 16:30:03.404711: Pseudo dice [np.float32(0.9072)] 
2024-12-07 16:30:03.407769: Epoch time: 33.04 s 
2024-12-07 16:30:03.983352:  
2024-12-07 16:30:03.988457: Epoch 19 
2024-12-07 16:30:03.991544: Current learning rate: 0.00827 
2024-12-07 16:30:37.167067: train_loss -0.9863 
2024-12-07 16:30:37.172194: val_loss -0.8819 
2024-12-07 16:30:37.175813: Pseudo dice [np.float32(0.9048)] 
2024-12-07 16:30:37.179322: Epoch time: 33.19 s 
2024-12-07 16:30:37.180826: Yayy! New best EMA pseudo Dice: 0.9032999873161316 
2024-12-07 16:30:38.097144:  
2024-12-07 16:30:38.104272: Epoch 20 
2024-12-07 16:30:38.107327: Current learning rate: 0.00818 
2024-12-07 16:31:11.438610: train_loss -0.9867 
2024-12-07 16:31:11.445742: val_loss -0.8789 
2024-12-07 16:31:11.449557: Pseudo dice [np.float32(0.9036)] 
2024-12-07 16:31:11.453069: Epoch time: 33.34 s 
2024-12-07 16:31:11.456146: Yayy! New best EMA pseudo Dice: 0.9034000039100647 
2024-12-07 16:31:12.225990:  
2024-12-07 16:31:12.231698: Epoch 21 
2024-12-07 16:31:12.234251: Current learning rate: 0.00809 
2024-12-07 16:31:45.160457: train_loss -0.9866 
2024-12-07 16:31:45.166017: val_loss -0.882 
2024-12-07 16:31:45.168509: Pseudo dice [np.float32(0.9059)] 
2024-12-07 16:31:45.172035: Epoch time: 32.93 s 
2024-12-07 16:31:45.175385: Yayy! New best EMA pseudo Dice: 0.9035999774932861 
2024-12-07 16:31:45.915470:  
2024-12-07 16:31:45.920510: Epoch 22 
2024-12-07 16:31:45.924047: Current learning rate: 0.008 
2024-12-07 16:32:18.805502: train_loss -0.987 
2024-12-07 16:32:18.812715: val_loss -0.8784 
2024-12-07 16:32:18.816808: Pseudo dice [np.float32(0.9031)] 
2024-12-07 16:32:18.820894: Epoch time: 32.89 s 
2024-12-07 16:32:19.371992:  
2024-12-07 16:32:19.375948: Epoch 23 
2024-12-07 16:32:19.380270: Current learning rate: 0.0079 
2024-12-07 16:32:52.169919: train_loss -0.9873 
2024-12-07 16:32:52.176990: val_loss -0.8771 
2024-12-07 16:32:52.180069: Pseudo dice [np.float32(0.9013)] 
2024-12-07 16:32:52.182600: Epoch time: 32.8 s 
2024-12-07 16:32:52.725461:  
2024-12-07 16:32:52.731518: Epoch 24 
2024-12-07 16:32:52.735067: Current learning rate: 0.00781 
2024-12-07 16:33:25.515141: train_loss -0.9875 
2024-12-07 16:33:25.522358: val_loss -0.8868 
2024-12-07 16:33:25.525423: Pseudo dice [np.float32(0.9094)] 
2024-12-07 16:33:25.527456: Epoch time: 32.79 s 
2024-12-07 16:33:25.529993: Yayy! New best EMA pseudo Dice: 0.9039000272750854 
2024-12-07 16:33:26.280235:  
2024-12-07 16:33:26.285816: Epoch 25 
2024-12-07 16:33:26.288348: Current learning rate: 0.00772 
2024-12-07 16:33:59.113570: train_loss -0.9877 
2024-12-07 16:33:59.118681: val_loss -0.8753 
2024-12-07 16:33:59.122224: Pseudo dice [np.float32(0.9007)] 
2024-12-07 16:33:59.125289: Epoch time: 32.83 s 
2024-12-07 16:33:59.689857:  
2024-12-07 16:33:59.694822: Epoch 26 
2024-12-07 16:33:59.697872: Current learning rate: 0.00763 
2024-12-07 16:34:32.604221: train_loss -0.9879 
2024-12-07 16:34:32.609823: val_loss -0.8801 
2024-12-07 16:34:32.613641: Pseudo dice [np.float32(0.904)] 
2024-12-07 16:34:32.616707: Epoch time: 32.92 s 
2024-12-07 16:34:33.178540:  
2024-12-07 16:34:33.184454: Epoch 27 
2024-12-07 16:34:33.187361: Current learning rate: 0.00753 
2024-12-07 16:35:06.038719: train_loss -0.988 
2024-12-07 16:35:06.043806: val_loss -0.8797 
2024-12-07 16:35:06.047630: Pseudo dice [np.float32(0.9043)] 
2024-12-07 16:35:06.051187: Epoch time: 32.86 s 
2024-12-07 16:35:06.773034:  
2024-12-07 16:35:06.778989: Epoch 28 
2024-12-07 16:35:06.782005: Current learning rate: 0.00744 
2024-12-07 16:35:39.611759: train_loss -0.9884 
2024-12-07 16:35:39.619200: val_loss -0.8774 
2024-12-07 16:35:39.624628: Pseudo dice [np.float32(0.9016)] 
2024-12-07 16:35:39.626653: Epoch time: 32.84 s 
2024-12-07 16:35:40.192428:  
2024-12-07 16:35:40.197519: Epoch 29 
2024-12-07 16:35:40.200921: Current learning rate: 0.00735 
2024-12-07 16:36:13.077086: train_loss -0.9888 
2024-12-07 16:36:13.083173: val_loss -0.8823 
2024-12-07 16:36:13.086634: Pseudo dice [np.float32(0.906)] 
2024-12-07 16:36:13.089701: Epoch time: 32.89 s 
2024-12-07 16:36:13.664508:  
2024-12-07 16:36:13.669865: Epoch 30 
2024-12-07 16:36:13.672401: Current learning rate: 0.00725 
2024-12-07 16:36:46.163967: train_loss -0.9887 
2024-12-07 16:36:46.169066: val_loss -0.8842 
2024-12-07 16:36:46.174128: Pseudo dice [np.float32(0.9072)] 
2024-12-07 16:36:46.176656: Epoch time: 32.5 s 
2024-12-07 16:36:46.181195: Yayy! New best EMA pseudo Dice: 0.9041000008583069 
2024-12-07 16:36:46.924996:  
2024-12-07 16:36:46.930051: Epoch 31 
2024-12-07 16:36:46.932596: Current learning rate: 0.00716 
2024-12-07 16:37:19.515870: train_loss -0.9886 
2024-12-07 16:37:19.521507: val_loss -0.8808 
2024-12-07 16:37:19.524578: Pseudo dice [np.float32(0.9042)] 
2024-12-07 16:37:19.528170: Epoch time: 32.59 s 
2024-12-07 16:37:19.530724: Yayy! New best EMA pseudo Dice: 0.9041000008583069 
2024-12-07 16:37:20.287659:  
2024-12-07 16:37:20.293231: Epoch 32 
2024-12-07 16:37:20.295761: Current learning rate: 0.00707 
2024-12-07 16:37:52.873307: train_loss -0.9886 
2024-12-07 16:37:52.879380: val_loss -0.886 
2024-12-07 16:37:52.883441: Pseudo dice [np.float32(0.908)] 
2024-12-07 16:37:52.886988: Epoch time: 32.58 s 
2024-12-07 16:37:52.889519: Yayy! New best EMA pseudo Dice: 0.9045000076293945 
2024-12-07 16:37:53.650159:  
2024-12-07 16:37:53.655117: Epoch 33 
2024-12-07 16:37:53.659160: Current learning rate: 0.00697 
2024-12-07 16:38:26.629018: train_loss -0.9895 
2024-12-07 16:38:26.634089: val_loss -0.883 
2024-12-07 16:38:26.636648: Pseudo dice [np.float32(0.9067)] 
2024-12-07 16:38:26.640692: Epoch time: 32.98 s 
2024-12-07 16:38:26.644239: Yayy! New best EMA pseudo Dice: 0.904699981212616 
2024-12-07 16:38:27.396888:  
2024-12-07 16:38:27.402529: Epoch 34 
2024-12-07 16:38:27.405070: Current learning rate: 0.00688 
2024-12-07 16:39:01.493552: train_loss -0.9893 
2024-12-07 16:39:01.499281: val_loss -0.8793 
2024-12-07 16:39:01.503067: Pseudo dice [np.float32(0.9037)] 
2024-12-07 16:39:01.506304: Epoch time: 34.1 s 
2024-12-07 16:39:02.244594:  
2024-12-07 16:39:02.251214: Epoch 35 
2024-12-07 16:39:02.254264: Current learning rate: 0.00679 
2024-12-07 16:39:36.033576: train_loss -0.989 
2024-12-07 16:39:36.040211: val_loss -0.8796 
2024-12-07 16:39:36.043103: Pseudo dice [np.float32(0.9037)] 
2024-12-07 16:39:36.045879: Epoch time: 33.79 s 
2024-12-07 16:39:36.634208:  
2024-12-07 16:39:36.639862: Epoch 36 
2024-12-07 16:39:36.643428: Current learning rate: 0.00669 
2024-12-07 16:40:09.877378: train_loss -0.9893 
2024-12-07 16:40:09.884122: val_loss -0.8835 
2024-12-07 16:40:09.887632: Pseudo dice [np.float32(0.9065)] 
2024-12-07 16:40:09.890676: Epoch time: 33.24 s 
2024-12-07 16:40:10.472737:  
2024-12-07 16:40:10.477688: Epoch 37 
2024-12-07 16:40:10.480919: Current learning rate: 0.0066 
2024-12-07 16:40:43.420311: train_loss -0.9892 
2024-12-07 16:40:43.425989: val_loss -0.8825 
2024-12-07 16:40:43.429018: Pseudo dice [np.float32(0.9054)] 
2024-12-07 16:40:43.431553: Epoch time: 32.95 s 
2024-12-07 16:40:43.435069: Yayy! New best EMA pseudo Dice: 0.9047999978065491 
2024-12-07 16:40:44.198179:  
2024-12-07 16:40:44.203242: Epoch 38 
2024-12-07 16:40:44.205781: Current learning rate: 0.0065 
2024-12-07 16:41:17.263947: train_loss -0.99 
2024-12-07 16:41:17.270505: val_loss -0.8845 
2024-12-07 16:41:17.274383: Pseudo dice [np.float32(0.9076)] 
2024-12-07 16:41:17.278088: Epoch time: 33.07 s 
2024-12-07 16:41:17.281166: Yayy! New best EMA pseudo Dice: 0.9050999879837036 
2024-12-07 16:41:18.059007:  
2024-12-07 16:41:18.064538: Epoch 39 
2024-12-07 16:41:18.067144: Current learning rate: 0.00641 
2024-12-07 16:41:51.297421: train_loss -0.9898 
2024-12-07 16:41:51.303496: val_loss -0.8821 
2024-12-07 16:41:51.306870: Pseudo dice [np.float32(0.9055)] 
2024-12-07 16:41:51.309443: Epoch time: 33.24 s 
2024-12-07 16:41:51.313033: Yayy! New best EMA pseudo Dice: 0.9050999879837036 
2024-12-07 16:41:52.100935:  
2024-12-07 16:41:52.105990: Epoch 40 
2024-12-07 16:41:52.109035: Current learning rate: 0.00631 
2024-12-07 16:42:25.207836: train_loss -0.9898 
2024-12-07 16:42:25.215029: val_loss -0.8861 
2024-12-07 16:42:25.218993: Pseudo dice [np.float32(0.9088)] 
2024-12-07 16:42:25.222174: Epoch time: 33.11 s 
2024-12-07 16:42:25.225408: Yayy! New best EMA pseudo Dice: 0.9054999947547913 
2024-12-07 16:42:25.996921:  
2024-12-07 16:42:26.001539: Epoch 41 
2024-12-07 16:42:26.004081: Current learning rate: 0.00622 
2024-12-07 16:42:59.010622: train_loss -0.9902 
2024-12-07 16:42:59.015699: val_loss -0.8874 
2024-12-07 16:42:59.018242: Pseudo dice [np.float32(0.9092)] 
2024-12-07 16:42:59.022806: Epoch time: 33.01 s 
2024-12-07 16:42:59.025856: Yayy! New best EMA pseudo Dice: 0.9057999849319458 
2024-12-07 16:42:59.756837:  
2024-12-07 16:42:59.761915: Epoch 42 
2024-12-07 16:42:59.764449: Current learning rate: 0.00612 
2024-12-07 16:43:33.082756: train_loss -0.9898 
2024-12-07 16:43:33.089267: val_loss -0.8807 
2024-12-07 16:43:33.093316: Pseudo dice [np.float32(0.9045)] 
2024-12-07 16:43:33.096353: Epoch time: 33.33 s 
2024-12-07 16:43:33.806309:  
2024-12-07 16:43:33.811232: Epoch 43 
2024-12-07 16:43:33.813846: Current learning rate: 0.00603 
2024-12-07 16:44:07.098482: train_loss -0.9905 
2024-12-07 16:44:07.104074: val_loss -0.8824 
2024-12-07 16:44:07.107147: Pseudo dice [np.float32(0.9047)] 
2024-12-07 16:44:07.110172: Epoch time: 33.29 s 
2024-12-07 16:44:07.665497:  
2024-12-07 16:44:07.670508: Epoch 44 
2024-12-07 16:44:07.673013: Current learning rate: 0.00593 
2024-12-07 16:44:40.914243: train_loss -0.9904 
2024-12-07 16:44:40.920767: val_loss -0.8796 
2024-12-07 16:44:40.923911: Pseudo dice [np.float32(0.9034)] 
2024-12-07 16:44:40.927475: Epoch time: 33.25 s 
2024-12-07 16:44:41.493935:  
2024-12-07 16:44:41.498874: Epoch 45 
2024-12-07 16:44:41.502378: Current learning rate: 0.00584 
2024-12-07 16:45:14.570588: train_loss -0.9903 
2024-12-07 16:45:14.575981: val_loss -0.882 
2024-12-07 16:45:14.579015: Pseudo dice [np.float32(0.905)] 
2024-12-07 16:45:14.581561: Epoch time: 33.08 s 
2024-12-07 16:45:15.139369:  
2024-12-07 16:45:15.144286: Epoch 46 
2024-12-07 16:45:15.147811: Current learning rate: 0.00574 
2024-12-07 16:45:48.412520: train_loss -0.9906 
2024-12-07 16:45:48.418159: val_loss -0.8823 
2024-12-07 16:45:48.421211: Pseudo dice [np.float32(0.9054)] 
2024-12-07 16:45:48.424772: Epoch time: 33.27 s 
2024-12-07 16:45:48.975193:  
2024-12-07 16:45:48.980771: Epoch 47 
2024-12-07 16:45:48.984250: Current learning rate: 0.00565 
2024-12-07 16:46:21.953484: train_loss -0.9908 
2024-12-07 16:46:21.958316: val_loss -0.8847 
2024-12-07 16:46:21.962102: Pseudo dice [np.float32(0.9073)] 
2024-12-07 16:46:21.965367: Epoch time: 32.98 s 
2024-12-07 16:46:22.516838:  
2024-12-07 16:46:22.521903: Epoch 48 
2024-12-07 16:46:22.525663: Current learning rate: 0.00555 
2024-12-07 16:46:55.574686: train_loss -0.9903 
2024-12-07 16:46:55.582846: val_loss -0.8781 
2024-12-07 16:46:55.586879: Pseudo dice [np.float32(0.902)] 
2024-12-07 16:46:55.590522: Epoch time: 33.06 s 
2024-12-07 16:46:56.147283:  
2024-12-07 16:46:56.152630: Epoch 49 
2024-12-07 16:46:56.156155: Current learning rate: 0.00546 
2024-12-07 16:47:29.175999: train_loss -0.9906 
2024-12-07 16:47:29.181271: val_loss -0.8831 
2024-12-07 16:47:29.185311: Pseudo dice [np.float32(0.9053)] 
2024-12-07 16:47:29.188363: Epoch time: 33.03 s 
2024-12-07 16:47:29.900834:  
2024-12-07 16:47:29.905971: Epoch 50 
2024-12-07 16:47:29.909050: Current learning rate: 0.00536 
2024-12-07 16:48:03.140143: train_loss -0.9908 
2024-12-07 16:48:03.146717: val_loss -0.8807 
2024-12-07 16:48:03.150253: Pseudo dice [np.float32(0.9038)] 
2024-12-07 16:48:03.153301: Epoch time: 33.24 s 
2024-12-07 16:48:03.885451:  
2024-12-07 16:48:03.890537: Epoch 51 
2024-12-07 16:48:03.893128: Current learning rate: 0.00526 
2024-12-07 16:48:37.234092: train_loss -0.991 
2024-12-07 16:48:37.239705: val_loss -0.8843 
2024-12-07 16:48:37.243251: Pseudo dice [np.float32(0.9069)] 
2024-12-07 16:48:37.245791: Epoch time: 33.35 s 
2024-12-07 16:48:37.802904:  
2024-12-07 16:48:37.807602: Epoch 52 
2024-12-07 16:48:37.812206: Current learning rate: 0.00517 
2024-12-07 16:49:11.646264: train_loss -0.9913 
2024-12-07 16:49:11.653707: val_loss -0.8808 
2024-12-07 16:49:11.658170: Pseudo dice [np.float32(0.9044)] 
2024-12-07 16:49:11.661684: Epoch time: 33.84 s 
2024-12-07 16:49:12.219451:  
2024-12-07 16:49:12.224538: Epoch 53 
2024-12-07 16:49:12.228048: Current learning rate: 0.00507 
2024-12-07 16:49:45.548232: train_loss -0.9912 
2024-12-07 16:49:45.554517: val_loss -0.8799 
2024-12-07 16:49:45.557857: Pseudo dice [np.float32(0.9031)] 
2024-12-07 16:49:45.560910: Epoch time: 33.33 s 
2024-12-07 16:49:46.127702:  
2024-12-07 16:49:46.132375: Epoch 54 
2024-12-07 16:49:46.135436: Current learning rate: 0.00497 
2024-12-07 16:50:19.350246: train_loss -0.9908 
2024-12-07 16:50:19.356229: val_loss -0.8855 
2024-12-07 16:50:19.359870: Pseudo dice [np.float32(0.9076)] 
2024-12-07 16:50:19.363448: Epoch time: 33.22 s 
2024-12-07 16:50:19.946305:  
2024-12-07 16:50:19.951017: Epoch 55 
2024-12-07 16:50:19.956066: Current learning rate: 0.00487 
2024-12-07 16:50:53.364098: train_loss -0.9913 
2024-12-07 16:50:53.369329: val_loss -0.8811 
2024-12-07 16:50:53.373384: Pseudo dice [np.float32(0.9042)] 
2024-12-07 16:50:53.376016: Epoch time: 33.42 s 
2024-12-07 16:50:53.935241:  
2024-12-07 16:50:53.941331: Epoch 56 
2024-12-07 16:50:53.944372: Current learning rate: 0.00478 
2024-12-07 16:51:27.614865: train_loss -0.9913 
2024-12-07 16:51:27.621678: val_loss -0.8808 
2024-12-07 16:51:27.625808: Pseudo dice [np.float32(0.9036)] 
2024-12-07 16:51:27.629195: Epoch time: 33.68 s 
2024-12-07 16:51:28.217535:  
2024-12-07 16:51:28.223102: Epoch 57 
2024-12-07 16:51:28.226617: Current learning rate: 0.00468 
2024-12-07 16:52:01.897435: train_loss -0.9915 
2024-12-07 16:52:01.903842: val_loss -0.884 
2024-12-07 16:52:01.907808: Pseudo dice [np.float32(0.9063)] 
2024-12-07 16:52:01.911052: Epoch time: 33.68 s 
2024-12-07 16:52:02.616266:  
2024-12-07 16:52:02.621664: Epoch 58 
2024-12-07 16:52:02.625211: Current learning rate: 0.00458 
2024-12-07 16:52:35.887185: train_loss -0.9914 
2024-12-07 16:52:35.894369: val_loss -0.8835 
2024-12-07 16:52:35.897919: Pseudo dice [np.float32(0.906)] 
2024-12-07 16:52:35.901454: Epoch time: 33.27 s 
2024-12-07 16:52:36.466489:  
2024-12-07 16:52:36.471738: Epoch 59 
2024-12-07 16:52:36.474888: Current learning rate: 0.00448 
2024-12-07 16:53:09.645762: train_loss -0.9916 
2024-12-07 16:53:09.650820: val_loss -0.8809 
2024-12-07 16:53:09.654370: Pseudo dice [np.float32(0.9037)] 
2024-12-07 16:53:09.656897: Epoch time: 33.18 s 
2024-12-07 16:53:10.222532:  
2024-12-07 16:53:10.227447: Epoch 60 
2024-12-07 16:53:10.230866: Current learning rate: 0.00438 
2024-12-07 16:53:43.096100: train_loss -0.9915 
2024-12-07 16:53:43.103195: val_loss -0.8816 
2024-12-07 16:53:43.106764: Pseudo dice [np.float32(0.9043)] 
2024-12-07 16:53:43.109292: Epoch time: 32.88 s 
2024-12-07 16:53:43.678397:  
2024-12-07 16:53:43.683070: Epoch 61 
2024-12-07 16:53:43.686557: Current learning rate: 0.00429 
2024-12-07 16:54:16.561244: train_loss -0.9919 
2024-12-07 16:54:16.566309: val_loss -0.8833 
2024-12-07 16:54:16.569841: Pseudo dice [np.float32(0.9062)] 
2024-12-07 16:54:16.572369: Epoch time: 32.88 s 
2024-12-07 16:54:17.139715:  
2024-12-07 16:54:17.145475: Epoch 62 
2024-12-07 16:54:17.149017: Current learning rate: 0.00419 
2024-12-07 16:54:50.006531: train_loss -0.9916 
2024-12-07 16:54:50.013035: val_loss -0.8795 
2024-12-07 16:54:50.016116: Pseudo dice [np.float32(0.9034)] 
2024-12-07 16:54:50.019475: Epoch time: 32.87 s 
2024-12-07 16:54:50.585189:  
2024-12-07 16:54:50.590243: Epoch 63 
2024-12-07 16:54:50.593282: Current learning rate: 0.00409 
2024-12-07 16:55:23.466937: train_loss -0.9917 
2024-12-07 16:55:23.471997: val_loss -0.8807 
2024-12-07 16:55:23.474525: Pseudo dice [np.float32(0.9045)] 
2024-12-07 16:55:23.478063: Epoch time: 32.88 s 
2024-12-07 16:55:24.048696:  
2024-12-07 16:55:24.054296: Epoch 64 
2024-12-07 16:55:24.057333: Current learning rate: 0.00399 
2024-12-07 16:55:56.950731: train_loss -0.9917 
2024-12-07 16:55:56.957375: val_loss -0.8834 
2024-12-07 16:55:56.961441: Pseudo dice [np.float32(0.9059)] 
2024-12-07 16:55:56.963668: Epoch time: 32.9 s 
2024-12-07 16:55:57.535758:  
2024-12-07 16:55:57.540825: Epoch 65 
2024-12-07 16:55:57.543894: Current learning rate: 0.00389 
2024-12-07 16:56:30.412065: train_loss -0.9919 
2024-12-07 16:56:30.416680: val_loss -0.8812 
2024-12-07 16:56:30.420724: Pseudo dice [np.float32(0.905)] 
2024-12-07 16:56:30.423380: Epoch time: 32.88 s 
2024-12-07 16:56:31.142241:  
2024-12-07 16:56:31.147337: Epoch 66 
2024-12-07 16:56:31.149857: Current learning rate: 0.00379 
2024-12-07 16:57:03.992209: train_loss -0.9918 
2024-12-07 16:57:03.997774: val_loss -0.8817 
2024-12-07 16:57:04.000365: Pseudo dice [np.float32(0.9049)] 
2024-12-07 16:57:04.003899: Epoch time: 32.85 s 
2024-12-07 16:57:04.567906:  
2024-12-07 16:57:04.572473: Epoch 67 
2024-12-07 16:57:04.575521: Current learning rate: 0.00369 
2024-12-07 16:57:37.445139: train_loss -0.9918 
2024-12-07 16:57:37.450734: val_loss -0.8846 
2024-12-07 16:57:37.453771: Pseudo dice [np.float32(0.9069)] 
2024-12-07 16:57:37.457344: Epoch time: 32.88 s 
2024-12-07 16:57:38.036439:  
2024-12-07 16:57:38.042045: Epoch 68 
2024-12-07 16:57:38.045091: Current learning rate: 0.00359 
2024-12-07 16:58:10.920144: train_loss -0.9918 
2024-12-07 16:58:10.925710: val_loss -0.8839 
2024-12-07 16:58:10.928246: Pseudo dice [np.float32(0.9067)] 
2024-12-07 16:58:10.933342: Epoch time: 32.88 s 
2024-12-07 16:58:11.515993:  
2024-12-07 16:58:11.521791: Epoch 69 
2024-12-07 16:58:11.524830: Current learning rate: 0.00349 
2024-12-07 16:58:44.125506: train_loss -0.9923 
2024-12-07 16:58:44.130578: val_loss -0.8811 
2024-12-07 16:58:44.134110: Pseudo dice [np.float32(0.9035)] 
2024-12-07 16:58:44.137664: Epoch time: 32.61 s 
2024-12-07 16:58:44.709467:  
2024-12-07 16:58:44.715048: Epoch 70 
2024-12-07 16:58:44.717573: Current learning rate: 0.00338 
2024-12-07 16:59:17.048144: train_loss -0.9926 
2024-12-07 16:59:17.055737: val_loss -0.8857 
2024-12-07 16:59:17.060826: Pseudo dice [np.float32(0.907)] 
2024-12-07 16:59:17.063356: Epoch time: 32.34 s 
2024-12-07 16:59:17.635285:  
2024-12-07 16:59:17.640352: Epoch 71 
2024-12-07 16:59:17.644382: Current learning rate: 0.00328 
2024-12-07 16:59:49.980468: train_loss -0.9926 
2024-12-07 16:59:49.985528: val_loss -0.879 
2024-12-07 16:59:49.990591: Pseudo dice [np.float32(0.9024)] 
2024-12-07 16:59:49.995151: Epoch time: 32.35 s 
2024-12-07 16:59:50.576075:  
2024-12-07 16:59:50.581131: Epoch 72 
2024-12-07 16:59:50.585695: Current learning rate: 0.00318 
2024-12-07 17:00:22.901764: train_loss -0.9926 
2024-12-07 17:00:22.909353: val_loss -0.8835 
2024-12-07 17:00:22.911888: Pseudo dice [np.float32(0.9063)] 
2024-12-07 17:00:22.916430: Epoch time: 32.33 s 
2024-12-07 17:00:23.640605:  
2024-12-07 17:00:23.646765: Epoch 73 
2024-12-07 17:00:23.649314: Current learning rate: 0.00308 
2024-12-07 17:00:55.963167: train_loss -0.9927 
2024-12-07 17:00:55.968742: val_loss -0.8846 
2024-12-07 17:00:55.971275: Pseudo dice [np.float32(0.907)] 
2024-12-07 17:00:55.973799: Epoch time: 32.32 s 
2024-12-07 17:00:56.550672:  
2024-12-07 17:00:56.557263: Epoch 74 
2024-12-07 17:00:56.560301: Current learning rate: 0.00297 
2024-12-07 17:01:28.884893: train_loss -0.9924 
2024-12-07 17:01:28.890970: val_loss -0.8794 
2024-12-07 17:01:28.895043: Pseudo dice [np.float32(0.9032)] 
2024-12-07 17:01:28.898093: Epoch time: 32.33 s 
2024-12-07 17:01:29.474835:  
2024-12-07 17:01:29.480397: Epoch 75 
2024-12-07 17:01:29.482929: Current learning rate: 0.00287 
2024-12-07 17:02:01.811765: train_loss -0.9924 
2024-12-07 17:02:01.817342: val_loss -0.8828 
2024-12-07 17:02:01.819868: Pseudo dice [np.float32(0.9061)] 
2024-12-07 17:02:01.822412: Epoch time: 32.34 s 
2024-12-07 17:02:02.405976:  
2024-12-07 17:02:02.411035: Epoch 76 
2024-12-07 17:02:02.414069: Current learning rate: 0.00277 
2024-12-07 17:02:34.746485: train_loss -0.9924 
2024-12-07 17:02:34.753113: val_loss -0.8852 
2024-12-07 17:02:34.756644: Pseudo dice [np.float32(0.908)] 
2024-12-07 17:02:34.759701: Epoch time: 32.34 s 
2024-12-07 17:02:35.341680:  
2024-12-07 17:02:35.346734: Epoch 77 
2024-12-07 17:02:35.349257: Current learning rate: 0.00266 
2024-12-07 17:03:07.676848: train_loss -0.9926 
2024-12-07 17:03:07.681932: val_loss -0.884 
2024-12-07 17:03:07.684459: Pseudo dice [np.float32(0.9072)] 
2024-12-07 17:03:07.689523: Epoch time: 32.34 s 
2024-12-07 17:03:08.277039:  
2024-12-07 17:03:08.282605: Epoch 78 
2024-12-07 17:03:08.285130: Current learning rate: 0.00256 
2024-12-07 17:03:40.613333: train_loss -0.9924 
2024-12-07 17:03:40.619898: val_loss -0.8843 
2024-12-07 17:03:40.623462: Pseudo dice [np.float32(0.9069)] 
2024-12-07 17:03:40.626505: Epoch time: 32.34 s 
2024-12-07 17:03:41.210439:  
2024-12-07 17:03:41.216013: Epoch 79 
2024-12-07 17:03:41.218560: Current learning rate: 0.00245 
2024-12-07 17:04:13.533942: train_loss -0.9928 
2024-12-07 17:04:13.538989: val_loss -0.882 
2024-12-07 17:04:13.542042: Pseudo dice [np.float32(0.9055)] 
2024-12-07 17:04:13.546595: Epoch time: 32.33 s 
2024-12-07 17:04:14.128037:  
2024-12-07 17:04:14.133089: Epoch 80 
2024-12-07 17:04:14.136674: Current learning rate: 0.00235 
2024-12-07 17:04:50.485631: train_loss -0.9923 
2024-12-07 17:04:50.493226: val_loss -0.8814 
2024-12-07 17:04:50.495758: Pseudo dice [np.float32(0.9044)] 
2024-12-07 17:04:50.498323: Epoch time: 36.36 s 
2024-12-07 17:04:51.265604:  
2024-12-07 17:04:51.269663: Epoch 81 
2024-12-07 17:04:51.273698: Current learning rate: 0.00224 
2024-12-07 17:05:24.456128: train_loss -0.9927 
2024-12-07 17:05:24.463102: val_loss -0.8822 
2024-12-07 17:05:24.466165: Pseudo dice [np.float32(0.9051)] 
2024-12-07 17:05:24.468479: Epoch time: 33.19 s 
2024-12-07 17:05:25.055172:  
2024-12-07 17:05:25.060711: Epoch 82 
2024-12-07 17:05:25.063626: Current learning rate: 0.00214 
2024-12-07 17:05:57.965462: train_loss -0.9925 
2024-12-07 17:05:57.972775: val_loss -0.8831 
2024-12-07 17:05:57.975858: Pseudo dice [np.float32(0.906)] 
2024-12-07 17:05:57.978882: Epoch time: 32.91 s 
2024-12-07 17:05:58.531895:  
2024-12-07 17:05:58.537962: Epoch 83 
2024-12-07 17:05:58.540993: Current learning rate: 0.00203 
2024-12-07 17:06:31.107008: train_loss -0.9927 
2024-12-07 17:06:31.112577: val_loss -0.8835 
2024-12-07 17:06:31.115614: Pseudo dice [np.float32(0.9061)] 
2024-12-07 17:06:31.118432: Epoch time: 32.58 s 
2024-12-07 17:06:31.678290:  
2024-12-07 17:06:31.683879: Epoch 84 
2024-12-07 17:06:31.686918: Current learning rate: 0.00192 
2024-12-07 17:07:04.401423: train_loss -0.9933 
2024-12-07 17:07:04.407919: val_loss -0.8849 
2024-12-07 17:07:04.411299: Pseudo dice [np.float32(0.908)] 
2024-12-07 17:07:04.414326: Epoch time: 32.72 s 
2024-12-07 17:07:04.417263: Yayy! New best EMA pseudo Dice: 0.9059000015258789 
2024-12-07 17:07:05.150492:  
2024-12-07 17:07:05.155707: Epoch 85 
2024-12-07 17:07:05.159336: Current learning rate: 0.00181 
2024-12-07 17:07:37.711699: train_loss -0.9931 
2024-12-07 17:07:37.716262: val_loss -0.8811 
2024-12-07 17:07:37.720817: Pseudo dice [np.float32(0.9045)] 
2024-12-07 17:07:37.723342: Epoch time: 32.56 s 
2024-12-07 17:07:38.271264:  
2024-12-07 17:07:38.276844: Epoch 86 
2024-12-07 17:07:38.279880: Current learning rate: 0.0017 
2024-12-07 17:08:11.372420: train_loss -0.9927 
2024-12-07 17:08:11.379354: val_loss -0.8837 
2024-12-07 17:08:11.382256: Pseudo dice [np.float32(0.9062)] 
2024-12-07 17:08:11.384821: Epoch time: 33.1 s 
2024-12-07 17:08:11.933805:  
2024-12-07 17:08:11.938837: Epoch 87 
2024-12-07 17:08:11.941938: Current learning rate: 0.00159 
2024-12-07 17:08:44.511813: train_loss -0.9931 
2024-12-07 17:08:44.517277: val_loss -0.8816 
2024-12-07 17:08:44.520139: Pseudo dice [np.float32(0.9049)] 
2024-12-07 17:08:44.523705: Epoch time: 32.58 s 
2024-12-07 17:08:45.219515:  
2024-12-07 17:08:45.224585: Epoch 88 
2024-12-07 17:08:45.228630: Current learning rate: 0.00148 
2024-12-07 17:09:17.786180: train_loss -0.9927 
2024-12-07 17:09:17.792635: val_loss -0.8832 
2024-12-07 17:09:17.796382: Pseudo dice [np.float32(0.9059)] 
2024-12-07 17:09:17.799904: Epoch time: 32.57 s 
2024-12-07 17:09:18.350096:  
2024-12-07 17:09:18.354988: Epoch 89 
2024-12-07 17:09:18.358064: Current learning rate: 0.00137 
2024-12-07 17:09:50.957233: train_loss -0.9932 
2024-12-07 17:09:50.962276: val_loss -0.8835 
2024-12-07 17:09:50.964803: Pseudo dice [np.float32(0.9062)] 
2024-12-07 17:09:50.968836: Epoch time: 32.61 s 
2024-12-07 17:09:51.520655:  
2024-12-07 17:09:51.526231: Epoch 90 
2024-12-07 17:09:51.529261: Current learning rate: 0.00126 
2024-12-07 17:10:24.659101: train_loss -0.9926 
2024-12-07 17:10:24.665118: val_loss -0.8796 
2024-12-07 17:10:24.669143: Pseudo dice [np.float32(0.9031)] 
2024-12-07 17:10:24.672527: Epoch time: 33.14 s 
2024-12-07 17:10:25.223035:  
2024-12-07 17:10:25.227933: Epoch 91 
2024-12-07 17:10:25.230784: Current learning rate: 0.00115 
2024-12-07 17:10:58.065801: train_loss -0.9932 
2024-12-07 17:10:58.071868: val_loss -0.8852 
2024-12-07 17:10:58.074397: Pseudo dice [np.float32(0.9079)] 
2024-12-07 17:10:58.078459: Epoch time: 32.84 s 
2024-12-07 17:10:58.628532:  
2024-12-07 17:10:58.633582: Epoch 92 
2024-12-07 17:10:58.636106: Current learning rate: 0.00103 
2024-12-07 17:11:31.368635: train_loss -0.9933 
2024-12-07 17:11:31.376228: val_loss -0.8829 
2024-12-07 17:11:31.378785: Pseudo dice [np.float32(0.9058)] 
2024-12-07 17:11:31.383332: Epoch time: 32.74 s 
2024-12-07 17:11:31.939679:  
2024-12-07 17:11:31.945274: Epoch 93 
2024-12-07 17:11:31.948310: Current learning rate: 0.00091 
2024-12-07 17:12:04.826806: train_loss -0.9931 
2024-12-07 17:12:04.832205: val_loss -0.8813 
2024-12-07 17:12:04.835754: Pseudo dice [np.float32(0.9049)] 
2024-12-07 17:12:04.839142: Epoch time: 32.89 s 
2024-12-07 17:12:05.398936:  
2024-12-07 17:12:05.404194: Epoch 94 
2024-12-07 17:12:05.407614: Current learning rate: 0.00079 
2024-12-07 17:12:38.457373: train_loss -0.9935 
2024-12-07 17:12:38.464660: val_loss -0.8837 
2024-12-07 17:12:38.468954: Pseudo dice [np.float32(0.9064)] 
2024-12-07 17:12:38.472793: Epoch time: 33.06 s 
2024-12-07 17:12:39.028438:  
2024-12-07 17:12:39.033498: Epoch 95 
2024-12-07 17:12:39.036028: Current learning rate: 0.00067 
2024-12-07 17:13:12.146482: train_loss -0.9934 
2024-12-07 17:13:12.151556: val_loss -0.8835 
2024-12-07 17:13:12.155604: Pseudo dice [np.float32(0.9063)] 
2024-12-07 17:13:12.159147: Epoch time: 33.12 s 
2024-12-07 17:13:12.711442:  
2024-12-07 17:13:12.718024: Epoch 96 
2024-12-07 17:13:12.722068: Current learning rate: 0.00055 
2024-12-07 17:13:45.422606: train_loss -0.9935 
2024-12-07 17:13:45.429707: val_loss -0.8801 
2024-12-07 17:13:45.432570: Pseudo dice [np.float32(0.9037)] 
2024-12-07 17:13:45.435106: Epoch time: 32.71 s 
2024-12-07 17:13:45.996046:  
2024-12-07 17:13:46.001611: Epoch 97 
2024-12-07 17:13:46.004673: Current learning rate: 0.00043 
2024-12-07 17:14:18.574856: train_loss -0.9934 
2024-12-07 17:14:18.579939: val_loss -0.8797 
2024-12-07 17:14:18.584997: Pseudo dice [np.float32(0.9036)] 
2024-12-07 17:14:18.587526: Epoch time: 32.58 s 
2024-12-07 17:14:19.149453:  
2024-12-07 17:14:19.154501: Epoch 98 
2024-12-07 17:14:19.157035: Current learning rate: 0.0003 
2024-12-07 17:14:51.709864: train_loss -0.9934 
2024-12-07 17:14:51.715881: val_loss -0.8825 
2024-12-07 17:14:51.718936: Pseudo dice [np.float32(0.9052)] 
2024-12-07 17:14:51.721740: Epoch time: 32.56 s 
2024-12-07 17:14:52.282562:  
2024-12-07 17:14:52.287654: Epoch 99 
2024-12-07 17:14:52.290573: Current learning rate: 0.00016 
2024-12-07 17:15:24.837017: train_loss -0.9935 
2024-12-07 17:15:24.844636: val_loss -0.884 
2024-12-07 17:15:24.849694: Pseudo dice [np.float32(0.9065)] 
2024-12-07 17:15:24.852228: Epoch time: 32.56 s 
2024-12-07 17:15:25.631891: Training done. 
2024-12-07 17:15:25.663441: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-07 17:15:25.663441: The split file contains 5 splits. 
2024-12-07 17:15:25.663441: Desired fold for training: 0 
2024-12-07 17:15:25.679127: This split has 16 training and 4 validation cases. 
2024-12-07 17:15:25.679127: predicting la_007 
2024-12-07 17:15:25.679127: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2024-12-07 17:15:26.385299: predicting la_016 
2024-12-07 17:15:26.401066: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2024-12-07 17:15:26.747210: predicting la_021 
2024-12-07 17:15:26.762931: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2024-12-07 17:15:27.091021: predicting la_024 
2024-12-07 17:15:27.106860: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2024-12-07 17:15:34.333997: Validation complete 
2024-12-07 17:15:34.342597: Mean Validation Dice:  0.8975040676892767 
