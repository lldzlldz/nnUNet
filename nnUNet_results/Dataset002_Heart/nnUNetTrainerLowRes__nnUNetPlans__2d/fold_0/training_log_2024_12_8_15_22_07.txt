
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-08 15:22:07.829509: do_dummy_2d_data_aug: False 
2024-12-08 15:22:07.831513: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-08 15:22:07.834677: The split file contains 5 splits. 
2024-12-08 15:22:07.834677: Desired fold for training: 0 
2024-12-08 15:22:07.842844: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 40, 'patch_size': [320, 256], 'median_image_size_in_voxels': [320.0, 232.0], 'spacing': [1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2024-12-08 15:22:14.105346: unpacking dataset... 
2024-12-08 15:22:14.286172: unpacking done... 
2024-12-08 15:22:17.197776:  
2024-12-08 15:22:17.200850: Epoch 0 
2024-12-08 15:22:17.203394: Current learning rate: 0.01 
2024-12-08 15:22:52.665857: train_loss -0.6251 
2024-12-08 15:22:52.670954: val_loss -0.8586 
2024-12-08 15:22:52.673507: Pseudo dice [np.float32(0.8824)] 
2024-12-08 15:22:52.677123: Epoch time: 35.47 s 
2024-12-08 15:22:52.679679: Yayy! New best EMA pseudo Dice: 0.8823999762535095 
2024-12-08 15:22:53.329557:  
2024-12-08 15:22:53.334703: Epoch 1 
2024-12-08 15:22:53.338294: Current learning rate: 0.00991 
2024-12-08 15:23:25.648147: train_loss -0.9419 
2024-12-08 15:23:25.654761: val_loss -0.87 
2024-12-08 15:23:25.656795: Pseudo dice [np.float32(0.8927)] 
2024-12-08 15:23:25.659324: Epoch time: 32.32 s 
2024-12-08 15:23:25.661854: Yayy! New best EMA pseudo Dice: 0.883400022983551 
2024-12-08 15:23:26.398971:  
2024-12-08 15:23:26.404544: Epoch 2 
2024-12-08 15:23:26.407649: Current learning rate: 0.00982 
2024-12-08 15:23:58.714492: train_loss -0.9596 
2024-12-08 15:23:58.719559: val_loss -0.8815 
2024-12-08 15:23:58.722610: Pseudo dice [np.float32(0.9016)] 
2024-12-08 15:23:58.725205: Epoch time: 32.32 s 
2024-12-08 15:23:58.727737: Yayy! New best EMA pseudo Dice: 0.885200023651123 
2024-12-08 15:23:59.511941:  
2024-12-08 15:23:59.517056: Epoch 3 
2024-12-08 15:23:59.519597: Current learning rate: 0.00973 
2024-12-08 15:24:31.820630: train_loss -0.9672 
2024-12-08 15:24:31.827263: val_loss -0.8713 
2024-12-08 15:24:31.829804: Pseudo dice [np.float32(0.8943)] 
2024-12-08 15:24:31.832345: Epoch time: 32.31 s 
2024-12-08 15:24:31.834892: Yayy! New best EMA pseudo Dice: 0.8860999941825867 
2024-12-08 15:24:32.591886:  
2024-12-08 15:24:32.597975: Epoch 4 
2024-12-08 15:24:32.601055: Current learning rate: 0.00964 
2024-12-08 15:25:04.915872: train_loss -0.9717 
2024-12-08 15:25:04.923021: val_loss -0.878 
2024-12-08 15:25:04.926095: Pseudo dice [np.float32(0.9003)] 
2024-12-08 15:25:04.930655: Epoch time: 32.32 s 
2024-12-08 15:25:04.933772: Yayy! New best EMA pseudo Dice: 0.887499988079071 
2024-12-08 15:25:05.699023:  
2024-12-08 15:25:05.704623: Epoch 5 
2024-12-08 15:25:05.707184: Current learning rate: 0.00955 
2024-12-08 15:25:38.067179: train_loss -0.9754 
2024-12-08 15:25:38.073309: val_loss -0.8701 
2024-12-08 15:25:38.076389: Pseudo dice [np.float32(0.8941)] 
2024-12-08 15:25:38.079447: Epoch time: 32.37 s 
2024-12-08 15:25:38.081482: Yayy! New best EMA pseudo Dice: 0.8881999850273132 
2024-12-08 15:25:38.820283:  
2024-12-08 15:25:38.825379: Epoch 6 
2024-12-08 15:25:38.828956: Current learning rate: 0.00946 
2024-12-08 15:26:11.137333: train_loss -0.9777 
2024-12-08 15:26:11.145499: val_loss -0.8733 
2024-12-08 15:26:11.149580: Pseudo dice [np.float32(0.8973)] 
2024-12-08 15:26:11.152633: Epoch time: 32.32 s 
2024-12-08 15:26:11.156230: Yayy! New best EMA pseudo Dice: 0.8891000151634216 
2024-12-08 15:26:11.901427:  
2024-12-08 15:26:11.907015: Epoch 7 
2024-12-08 15:26:11.910087: Current learning rate: 0.00937 
2024-12-08 15:26:44.198047: train_loss -0.9787 
2024-12-08 15:26:44.203118: val_loss -0.8783 
2024-12-08 15:26:44.205657: Pseudo dice [np.float32(0.9013)] 
2024-12-08 15:26:44.208225: Epoch time: 32.3 s 
2024-12-08 15:26:44.210765: Yayy! New best EMA pseudo Dice: 0.8902999758720398 
2024-12-08 15:26:44.958153:  
2024-12-08 15:26:44.963226: Epoch 8 
2024-12-08 15:26:44.966326: Current learning rate: 0.00928 
2024-12-08 15:27:17.283149: train_loss -0.9796 
2024-12-08 15:27:17.289758: val_loss -0.8795 
2024-12-08 15:27:17.294834: Pseudo dice [np.float32(0.9017)] 
2024-12-08 15:27:17.297377: Epoch time: 32.33 s 
2024-12-08 15:27:17.299917: Yayy! New best EMA pseudo Dice: 0.8914999961853027 
2024-12-08 15:27:18.067732:  
2024-12-08 15:27:18.073824: Epoch 9 
2024-12-08 15:27:18.076931: Current learning rate: 0.00919 
2024-12-08 15:27:45.211935: train_loss -0.9807 
2024-12-08 15:27:45.217005: val_loss -0.8759 
2024-12-08 15:27:45.219549: Pseudo dice [np.float32(0.8992)] 
2024-12-08 15:27:45.224112: Epoch time: 27.14 s 
2024-12-08 15:27:45.227193: Yayy! New best EMA pseudo Dice: 0.8921999931335449 
2024-12-08 15:27:45.977105:  
2024-12-08 15:27:45.982168: Epoch 10 
2024-12-08 15:27:45.985754: Current learning rate: 0.0091 
2024-12-08 15:28:18.301568: train_loss -0.9819 
2024-12-08 15:28:18.309188: val_loss -0.8822 
2024-12-08 15:28:18.311734: Pseudo dice [np.float32(0.905)] 
2024-12-08 15:28:18.314276: Epoch time: 32.33 s 
2024-12-08 15:28:18.318837: Yayy! New best EMA pseudo Dice: 0.8934999704360962 
2024-12-08 15:28:19.059207:  
2024-12-08 15:28:19.064841: Epoch 11 
2024-12-08 15:28:19.067391: Current learning rate: 0.009 
2024-12-08 15:28:51.373250: train_loss -0.9832 
2024-12-08 15:28:51.377319: val_loss -0.878 
2024-12-08 15:28:51.381891: Pseudo dice [np.float32(0.9016)] 
2024-12-08 15:28:51.384433: Epoch time: 32.31 s 
2024-12-08 15:28:51.387000: Yayy! New best EMA pseudo Dice: 0.8942999839782715 
2024-12-08 15:28:52.123684:  
2024-12-08 15:28:52.129291: Epoch 12 
2024-12-08 15:28:52.132861: Current learning rate: 0.00891 
2024-12-08 15:29:24.443366: train_loss -0.9831 
2024-12-08 15:29:24.448437: val_loss -0.8811 
2024-12-08 15:29:24.453553: Pseudo dice [np.float32(0.9032)] 
2024-12-08 15:29:24.456094: Epoch time: 32.32 s 
2024-12-08 15:29:24.458639: Yayy! New best EMA pseudo Dice: 0.8952000141143799 
2024-12-08 15:29:25.359942:  
2024-12-08 15:29:25.365023: Epoch 13 
2024-12-08 15:29:25.368638: Current learning rate: 0.00882 
2024-12-08 15:29:57.649647: train_loss -0.9842 
2024-12-08 15:29:57.654748: val_loss -0.8803 
2024-12-08 15:29:57.657817: Pseudo dice [np.float32(0.9031)] 
2024-12-08 15:29:57.660871: Epoch time: 32.29 s 
2024-12-08 15:29:57.664496: Yayy! New best EMA pseudo Dice: 0.8960000276565552 
2024-12-08 15:29:58.408342:  
2024-12-08 15:29:58.413443: Epoch 14 
2024-12-08 15:29:58.415997: Current learning rate: 0.00873 
2024-12-08 15:30:30.719719: train_loss -0.9843 
2024-12-08 15:30:30.725356: val_loss -0.8791 
2024-12-08 15:30:30.730445: Pseudo dice [np.float32(0.9022)] 
2024-12-08 15:30:30.732986: Epoch time: 32.31 s 
2024-12-08 15:30:30.735593: Yayy! New best EMA pseudo Dice: 0.8966000080108643 
2024-12-08 15:30:31.493368:  
2024-12-08 15:30:31.498459: Epoch 15 
2024-12-08 15:30:31.501006: Current learning rate: 0.00864 
2024-12-08 15:31:03.804716: train_loss -0.9849 
2024-12-08 15:31:03.810304: val_loss -0.8785 
2024-12-08 15:31:03.812920: Pseudo dice [np.float32(0.9013)] 
2024-12-08 15:31:03.815459: Epoch time: 32.31 s 
2024-12-08 15:31:03.817986: Yayy! New best EMA pseudo Dice: 0.8970999717712402 
2024-12-08 15:31:04.595828:  
2024-12-08 15:31:04.600401: Epoch 16 
2024-12-08 15:31:04.603972: Current learning rate: 0.00855 
2024-12-08 15:31:36.899715: train_loss -0.9851 
2024-12-08 15:31:36.905814: val_loss -0.8764 
2024-12-08 15:31:36.912425: Pseudo dice [np.float32(0.9004)] 
2024-12-08 15:31:36.915989: Epoch time: 32.3 s 
2024-12-08 15:31:36.918536: Yayy! New best EMA pseudo Dice: 0.8974000215530396 
2024-12-08 15:31:37.692193:  
2024-12-08 15:31:37.699325: Epoch 17 
2024-12-08 15:31:37.701875: Current learning rate: 0.00846 
2024-12-08 15:32:10.001258: train_loss -0.9859 
2024-12-08 15:32:10.006860: val_loss -0.874 
2024-12-08 15:32:10.008893: Pseudo dice [np.float32(0.8993)] 
2024-12-08 15:32:10.011431: Epoch time: 32.31 s 
2024-12-08 15:32:10.016052: Yayy! New best EMA pseudo Dice: 0.897599995136261 
2024-12-08 15:32:10.761817:  
2024-12-08 15:32:10.766900: Epoch 18 
2024-12-08 15:32:10.769985: Current learning rate: 0.00836 
2024-12-08 15:32:43.080839: train_loss -0.9859 
2024-12-08 15:32:43.087952: val_loss -0.8758 
2024-12-08 15:32:43.091027: Pseudo dice [np.float32(0.8992)] 
2024-12-08 15:32:43.093556: Epoch time: 32.32 s 
2024-12-08 15:32:43.096084: Yayy! New best EMA pseudo Dice: 0.8978000283241272 
2024-12-08 15:32:43.853411:  
2024-12-08 15:32:43.858989: Epoch 19 
2024-12-08 15:32:43.862561: Current learning rate: 0.00827 
2024-12-08 15:33:16.170252: train_loss -0.9862 
2024-12-08 15:33:16.175831: val_loss -0.8804 
2024-12-08 15:33:16.178420: Pseudo dice [np.float32(0.904)] 
2024-12-08 15:33:16.180951: Epoch time: 32.32 s 
2024-12-08 15:33:16.183481: Yayy! New best EMA pseudo Dice: 0.8984000086784363 
2024-12-08 15:33:16.953960:  
2024-12-08 15:33:16.959587: Epoch 20 
2024-12-08 15:33:16.962131: Current learning rate: 0.00818 
2024-12-08 15:33:49.266529: train_loss -0.9868 
2024-12-08 15:33:49.274647: val_loss -0.882 
2024-12-08 15:33:49.277211: Pseudo dice [np.float32(0.9044)] 
2024-12-08 15:33:49.279742: Epoch time: 32.31 s 
2024-12-08 15:33:49.282271: Yayy! New best EMA pseudo Dice: 0.8989999890327454 
2024-12-08 15:33:50.200601:  
2024-12-08 15:33:50.205714: Epoch 21 
2024-12-08 15:33:50.209294: Current learning rate: 0.00809 
2024-12-08 15:34:22.519367: train_loss -0.987 
2024-12-08 15:34:22.524464: val_loss -0.8799 
2024-12-08 15:34:22.527018: Pseudo dice [np.float32(0.9031)] 
2024-12-08 15:34:22.531630: Epoch time: 32.32 s 
2024-12-08 15:34:22.534689: Yayy! New best EMA pseudo Dice: 0.899399995803833 
2024-12-08 15:34:23.274283:  
2024-12-08 15:34:23.278851: Epoch 22 
2024-12-08 15:34:23.281915: Current learning rate: 0.008 
2024-12-08 15:34:55.585181: train_loss -0.9873 
2024-12-08 15:34:55.590811: val_loss -0.8811 
2024-12-08 15:34:55.595954: Pseudo dice [np.float32(0.9032)] 
2024-12-08 15:34:55.598509: Epoch time: 32.31 s 
2024-12-08 15:34:55.601057: Yayy! New best EMA pseudo Dice: 0.8998000025749207 
2024-12-08 15:34:56.337246:  
2024-12-08 15:34:56.342381: Epoch 23 
2024-12-08 15:34:56.345965: Current learning rate: 0.0079 
2024-12-08 15:35:28.649644: train_loss -0.987 
2024-12-08 15:35:28.655254: val_loss -0.8763 
2024-12-08 15:35:28.659388: Pseudo dice [np.float32(0.8996)] 
2024-12-08 15:35:28.662938: Epoch time: 32.31 s 
2024-12-08 15:35:29.219132:  
2024-12-08 15:35:29.224247: Epoch 24 
2024-12-08 15:35:29.227843: Current learning rate: 0.00781 
2024-12-08 15:36:01.551468: train_loss -0.9875 
2024-12-08 15:36:01.558605: val_loss -0.8802 
2024-12-08 15:36:01.561725: Pseudo dice [np.float32(0.9034)] 
2024-12-08 15:36:01.564278: Epoch time: 32.33 s 
2024-12-08 15:36:01.568854: Yayy! New best EMA pseudo Dice: 0.9000999927520752 
2024-12-08 15:36:02.321430:  
2024-12-08 15:36:02.327111: Epoch 25 
2024-12-08 15:36:02.330202: Current learning rate: 0.00772 
2024-12-08 15:36:34.631607: train_loss -0.9881 
2024-12-08 15:36:34.636210: val_loss -0.8813 
2024-12-08 15:36:34.638801: Pseudo dice [np.float32(0.9042)] 
2024-12-08 15:36:34.641355: Epoch time: 32.31 s 
2024-12-08 15:36:34.646441: Yayy! New best EMA pseudo Dice: 0.9004999995231628 
2024-12-08 15:36:35.383226:  
2024-12-08 15:36:35.388312: Epoch 26 
2024-12-08 15:36:35.390864: Current learning rate: 0.00763 
2024-12-08 15:37:07.709602: train_loss -0.9881 
2024-12-08 15:37:07.716221: val_loss -0.8808 
2024-12-08 15:37:07.721301: Pseudo dice [np.float32(0.9029)] 
2024-12-08 15:37:07.723845: Epoch time: 32.33 s 
2024-12-08 15:37:07.727473: Yayy! New best EMA pseudo Dice: 0.9007999897003174 
2024-12-08 15:37:08.467945:  
2024-12-08 15:37:08.473068: Epoch 27 
2024-12-08 15:37:08.476128: Current learning rate: 0.00753 
2024-12-08 15:37:40.785639: train_loss -0.9882 
2024-12-08 15:37:40.791761: val_loss -0.8749 
2024-12-08 15:37:40.795328: Pseudo dice [np.float32(0.8995)] 
2024-12-08 15:37:40.797383: Epoch time: 32.32 s 
2024-12-08 15:37:41.498804:  
2024-12-08 15:37:41.504932: Epoch 28 
2024-12-08 15:37:41.508519: Current learning rate: 0.00744 
2024-12-08 15:38:13.800125: train_loss -0.9886 
2024-12-08 15:38:13.806331: val_loss -0.879 
2024-12-08 15:38:13.810942: Pseudo dice [np.float32(0.9016)] 
2024-12-08 15:38:13.813483: Epoch time: 32.3 s 
2024-12-08 15:38:14.378186:  
2024-12-08 15:38:14.383852: Epoch 29 
2024-12-08 15:38:14.386937: Current learning rate: 0.00735 
2024-12-08 15:38:46.679609: train_loss -0.9892 
2024-12-08 15:38:46.684681: val_loss -0.8781 
2024-12-08 15:38:46.689234: Pseudo dice [np.float32(0.9011)] 
2024-12-08 15:38:46.692301: Epoch time: 32.3 s 
2024-12-08 15:38:46.694831: Yayy! New best EMA pseudo Dice: 0.9007999897003174 
2024-12-08 15:38:47.456622:  
2024-12-08 15:38:47.461703: Epoch 30 
2024-12-08 15:38:47.464797: Current learning rate: 0.00725 
2024-12-08 15:39:19.773829: train_loss -0.9885 
2024-12-08 15:39:19.780462: val_loss -0.8822 
2024-12-08 15:39:19.783001: Pseudo dice [np.float32(0.9055)] 
2024-12-08 15:39:19.785541: Epoch time: 32.32 s 
2024-12-08 15:39:19.790102: Yayy! New best EMA pseudo Dice: 0.901199996471405 
2024-12-08 15:39:20.531206:  
2024-12-08 15:39:20.536831: Epoch 31 
2024-12-08 15:39:20.541898: Current learning rate: 0.00716 
2024-12-08 15:39:52.853317: train_loss -0.9893 
2024-12-08 15:39:52.858926: val_loss -0.8854 
2024-12-08 15:39:52.863487: Pseudo dice [np.float32(0.9081)] 
2024-12-08 15:39:52.866584: Epoch time: 32.32 s 
2024-12-08 15:39:52.869123: Yayy! New best EMA pseudo Dice: 0.9018999934196472 
2024-12-08 15:39:53.605351:  
2024-12-08 15:39:53.610428: Epoch 32 
2024-12-08 15:39:53.613487: Current learning rate: 0.00707 
2024-12-08 15:40:25.915473: train_loss -0.9891 
2024-12-08 15:40:25.922559: val_loss -0.8782 
2024-12-08 15:40:25.925645: Pseudo dice [np.float32(0.9013)] 
2024-12-08 15:40:25.929204: Epoch time: 32.31 s 
2024-12-08 15:40:26.496452:  
2024-12-08 15:40:26.502109: Epoch 33 
2024-12-08 15:40:26.504655: Current learning rate: 0.00697 
2024-12-08 15:40:58.811084: train_loss -0.989 
2024-12-08 15:40:58.816190: val_loss -0.877 
2024-12-08 15:40:58.819748: Pseudo dice [np.float32(0.9011)] 
2024-12-08 15:40:58.822283: Epoch time: 32.31 s 
2024-12-08 15:40:59.381422:  
2024-12-08 15:40:59.386503: Epoch 34 
2024-12-08 15:40:59.390072: Current learning rate: 0.00688 
2024-12-08 15:41:31.730571: train_loss -0.9889 
2024-12-08 15:41:31.735647: val_loss -0.8792 
2024-12-08 15:41:31.738182: Pseudo dice [np.float32(0.9025)] 
2024-12-08 15:41:31.740717: Epoch time: 32.35 s 
2024-12-08 15:41:32.318583:  
2024-12-08 15:41:32.325190: Epoch 35 
2024-12-08 15:41:32.328253: Current learning rate: 0.00679 
2024-12-08 15:42:04.656998: train_loss -0.9895 
2024-12-08 15:42:04.662099: val_loss -0.8819 
2024-12-08 15:42:04.664641: Pseudo dice [np.float32(0.9041)] 
2024-12-08 15:42:04.667187: Epoch time: 32.34 s 
2024-12-08 15:42:04.671241: Yayy! New best EMA pseudo Dice: 0.9021000266075134 
2024-12-08 15:42:05.577002:  
2024-12-08 15:42:05.583110: Epoch 36 
2024-12-08 15:42:05.586692: Current learning rate: 0.00669 
2024-12-08 15:42:37.922633: train_loss -0.9899 
2024-12-08 15:42:37.927701: val_loss -0.8805 
2024-12-08 15:42:37.932831: Pseudo dice [np.float32(0.9032)] 
2024-12-08 15:42:37.935376: Epoch time: 32.35 s 
2024-12-08 15:42:37.937918: Yayy! New best EMA pseudo Dice: 0.9021999835968018 
2024-12-08 15:42:38.700927:  
2024-12-08 15:42:38.705003: Epoch 37 
2024-12-08 15:42:38.708562: Current learning rate: 0.0066 
2024-12-08 15:43:11.021198: train_loss -0.9896 
2024-12-08 15:43:11.026836: val_loss -0.8792 
2024-12-08 15:43:11.029389: Pseudo dice [np.float32(0.9016)] 
2024-12-08 15:43:11.032943: Epoch time: 32.32 s 
2024-12-08 15:43:11.624534:  
2024-12-08 15:43:11.629110: Epoch 38 
2024-12-08 15:43:11.632173: Current learning rate: 0.0065 
2024-12-08 15:43:43.945369: train_loss -0.9894 
2024-12-08 15:43:43.953025: val_loss -0.8858 
2024-12-08 15:43:43.955572: Pseudo dice [np.float32(0.9071)] 
2024-12-08 15:43:43.958113: Epoch time: 32.32 s 
2024-12-08 15:43:43.960652: Yayy! New best EMA pseudo Dice: 0.9025999903678894 
2024-12-08 15:43:44.723368:  
2024-12-08 15:43:44.727943: Epoch 39 
2024-12-08 15:43:44.731045: Current learning rate: 0.00641 
2024-12-08 15:44:17.062507: train_loss -0.9901 
2024-12-08 15:44:17.067119: val_loss -0.8821 
2024-12-08 15:44:17.069671: Pseudo dice [np.float32(0.905)] 
2024-12-08 15:44:17.074236: Epoch time: 32.34 s 
2024-12-08 15:44:17.077341: Yayy! New best EMA pseudo Dice: 0.902899980545044 
2024-12-08 15:44:17.852479:  
2024-12-08 15:44:17.859646: Epoch 40 
2024-12-08 15:44:17.862777: Current learning rate: 0.00631 
2024-12-08 15:44:50.179183: train_loss -0.99 
2024-12-08 15:44:50.184323: val_loss -0.8778 
2024-12-08 15:44:50.187963: Pseudo dice [np.float32(0.9016)] 
2024-12-08 15:44:50.190008: Epoch time: 32.33 s 
2024-12-08 15:44:50.790720:  
2024-12-08 15:44:50.795359: Epoch 41 
2024-12-08 15:44:50.798447: Current learning rate: 0.00622 
2024-12-08 15:45:23.111039: train_loss -0.9901 
2024-12-08 15:45:23.117696: val_loss -0.8792 
2024-12-08 15:45:23.121277: Pseudo dice [np.float32(0.9017)] 
2024-12-08 15:45:23.123831: Epoch time: 32.32 s 
2024-12-08 15:45:23.688106:  
2024-12-08 15:45:23.693265: Epoch 42 
2024-12-08 15:45:23.695816: Current learning rate: 0.00612 
2024-12-08 15:45:56.010719: train_loss -0.9901 
2024-12-08 15:45:56.016361: val_loss -0.8806 
2024-12-08 15:45:56.018940: Pseudo dice [np.float32(0.904)] 
2024-12-08 15:45:56.022013: Epoch time: 32.32 s 
2024-12-08 15:45:56.584990:  
2024-12-08 15:45:56.589616: Epoch 43 
2024-12-08 15:45:56.592710: Current learning rate: 0.00603 
2024-12-08 15:46:28.926926: train_loss -0.9905 
2024-12-08 15:46:28.934100: val_loss -0.8846 
2024-12-08 15:46:28.938222: Pseudo dice [np.float32(0.9062)] 
2024-12-08 15:46:28.941309: Epoch time: 32.34 s 
2024-12-08 15:46:28.944374: Yayy! New best EMA pseudo Dice: 0.9031000137329102 
2024-12-08 15:46:29.831785:  
2024-12-08 15:46:29.835348: Epoch 44 
2024-12-08 15:46:29.839428: Current learning rate: 0.00593 
2024-12-08 15:47:02.149723: train_loss -0.9905 
2024-12-08 15:47:02.154897: val_loss -0.8812 
2024-12-08 15:47:02.157968: Pseudo dice [np.float32(0.9038)] 
2024-12-08 15:47:02.161041: Epoch time: 32.32 s 
2024-12-08 15:47:02.163613: Yayy! New best EMA pseudo Dice: 0.9031999707221985 
2024-12-08 15:47:02.911129:  
2024-12-08 15:47:02.916264: Epoch 45 
2024-12-08 15:47:02.918831: Current learning rate: 0.00584 
2024-12-08 15:47:35.229983: train_loss -0.9902 
2024-12-08 15:47:35.235593: val_loss -0.8801 
2024-12-08 15:47:35.240181: Pseudo dice [np.float32(0.9042)] 
2024-12-08 15:47:35.243254: Epoch time: 32.32 s 
2024-12-08 15:47:35.245808: Yayy! New best EMA pseudo Dice: 0.9032999873161316 
2024-12-08 15:47:35.990258:  
2024-12-08 15:47:35.995907: Epoch 46 
2024-12-08 15:47:35.998992: Current learning rate: 0.00574 
2024-12-08 15:48:08.309748: train_loss -0.9906 
2024-12-08 15:48:08.314348: val_loss -0.88 
2024-12-08 15:48:08.319453: Pseudo dice [np.float32(0.9032)] 
2024-12-08 15:48:08.321987: Epoch time: 32.32 s 
2024-12-08 15:48:08.883537:  
2024-12-08 15:48:08.889695: Epoch 47 
2024-12-08 15:48:08.892247: Current learning rate: 0.00565 
2024-12-08 15:48:41.220820: train_loss -0.991 
2024-12-08 15:48:41.226409: val_loss -0.8805 
2024-12-08 15:48:41.231549: Pseudo dice [np.float32(0.9033)] 
2024-12-08 15:48:41.234088: Epoch time: 32.34 s 
2024-12-08 15:48:41.789020:  
2024-12-08 15:48:41.795633: Epoch 48 
2024-12-08 15:48:41.798698: Current learning rate: 0.00555 
2024-12-08 15:49:14.108296: train_loss -0.9911 
2024-12-08 15:49:14.113891: val_loss -0.8849 
2024-12-08 15:49:14.116436: Pseudo dice [np.float32(0.9064)] 
2024-12-08 15:49:14.119038: Epoch time: 32.32 s 
2024-12-08 15:49:14.121577: Yayy! New best EMA pseudo Dice: 0.9035999774932861 
2024-12-08 15:49:14.856766:  
2024-12-08 15:49:14.861841: Epoch 49 
2024-12-08 15:49:14.864382: Current learning rate: 0.00546 
2024-12-08 15:49:47.176445: train_loss -0.991 
2024-12-08 15:49:47.183020: val_loss -0.8808 
2024-12-08 15:49:47.186604: Pseudo dice [np.float32(0.9044)] 
2024-12-08 15:49:47.189172: Epoch time: 32.32 s 
2024-12-08 15:49:47.355544: Yayy! New best EMA pseudo Dice: 0.9036999940872192 
2024-12-08 15:49:48.079771:  
2024-12-08 15:49:48.085389: Epoch 50 
2024-12-08 15:49:48.088472: Current learning rate: 0.00536 
2024-12-08 15:50:20.416015: train_loss -0.9906 
2024-12-08 15:50:20.421629: val_loss -0.8836 
2024-12-08 15:50:20.424170: Pseudo dice [np.float32(0.9058)] 
2024-12-08 15:50:20.426711: Epoch time: 32.34 s 
2024-12-08 15:50:20.429245: Yayy! New best EMA pseudo Dice: 0.9039000272750854 
2024-12-08 15:50:21.174704:  
2024-12-08 15:50:21.179779: Epoch 51 
2024-12-08 15:50:21.182352: Current learning rate: 0.00526 
2024-12-08 15:50:53.488801: train_loss -0.991 
2024-12-08 15:50:53.496464: val_loss -0.8811 
2024-12-08 15:50:53.499014: Pseudo dice [np.float32(0.9048)] 
2024-12-08 15:50:53.501544: Epoch time: 32.32 s 
2024-12-08 15:50:53.504075: Yayy! New best EMA pseudo Dice: 0.9039999842643738 
2024-12-08 15:50:54.396537:  
2024-12-08 15:50:54.401099: Epoch 52 
2024-12-08 15:50:54.404651: Current learning rate: 0.00517 
2024-12-08 15:51:31.192809: train_loss -0.991 
2024-12-08 15:51:31.198391: val_loss -0.8798 
2024-12-08 15:51:31.200933: Pseudo dice [np.float32(0.9029)] 
2024-12-08 15:51:31.205019: Epoch time: 36.8 s 
2024-12-08 15:51:31.776328:  
2024-12-08 15:51:31.781916: Epoch 53 
2024-12-08 15:51:31.784994: Current learning rate: 0.00507 
2024-12-08 15:52:04.270117: train_loss -0.9914 
2024-12-08 15:52:04.275707: val_loss -0.8861 
2024-12-08 15:52:04.280351: Pseudo dice [np.float32(0.9077)] 
2024-12-08 15:52:04.283412: Epoch time: 32.49 s 
2024-12-08 15:52:04.286463: Yayy! New best EMA pseudo Dice: 0.9042999744415283 
2024-12-08 15:52:05.031040:  
2024-12-08 15:52:05.038134: Epoch 54 
2024-12-08 15:52:05.041193: Current learning rate: 0.00497 
2024-12-08 15:52:37.523380: train_loss -0.9908 
2024-12-08 15:52:37.528440: val_loss -0.8839 
2024-12-08 15:52:37.530978: Pseudo dice [np.float32(0.9059)] 
2024-12-08 15:52:37.533529: Epoch time: 32.49 s 
2024-12-08 15:52:37.538085: Yayy! New best EMA pseudo Dice: 0.9043999910354614 
2024-12-08 15:52:38.288355:  
2024-12-08 15:52:38.293431: Epoch 55 
2024-12-08 15:52:38.295973: Current learning rate: 0.00487 
2024-12-08 15:53:10.776189: train_loss -0.9919 
2024-12-08 15:53:10.781766: val_loss -0.8837 
2024-12-08 15:53:10.784338: Pseudo dice [np.float32(0.9061)] 
2024-12-08 15:53:10.789429: Epoch time: 32.49 s 
2024-12-08 15:53:10.791967: Yayy! New best EMA pseudo Dice: 0.9046000242233276 
2024-12-08 15:53:11.545665:  
2024-12-08 15:53:11.552836: Epoch 56 
2024-12-08 15:53:11.555389: Current learning rate: 0.00478 
2024-12-08 15:53:44.045220: train_loss -0.9913 
2024-12-08 15:53:44.050816: val_loss -0.8811 
2024-12-08 15:53:44.053366: Pseudo dice [np.float32(0.9051)] 
2024-12-08 15:53:44.055420: Epoch time: 32.5 s 
2024-12-08 15:53:44.059977: Yayy! New best EMA pseudo Dice: 0.9046000242233276 
2024-12-08 15:53:44.804656:  
2024-12-08 15:53:44.810248: Epoch 57 
2024-12-08 15:53:44.813359: Current learning rate: 0.00468 
2024-12-08 15:54:17.296600: train_loss -0.9915 
2024-12-08 15:54:17.304199: val_loss -0.8834 
2024-12-08 15:54:17.306761: Pseudo dice [np.float32(0.9061)] 
2024-12-08 15:54:17.310829: Epoch time: 32.49 s 
2024-12-08 15:54:17.312869: Yayy! New best EMA pseudo Dice: 0.9047999978065491 
2024-12-08 15:54:18.058733:  
2024-12-08 15:54:18.063812: Epoch 58 
2024-12-08 15:54:18.066906: Current learning rate: 0.00458 
2024-12-08 15:54:50.545457: train_loss -0.9917 
2024-12-08 15:54:50.550514: val_loss -0.8839 
2024-12-08 15:54:50.553049: Pseudo dice [np.float32(0.9064)] 
2024-12-08 15:54:50.557616: Epoch time: 32.49 s 
2024-12-08 15:54:50.560685: Yayy! New best EMA pseudo Dice: 0.9049000144004822 
2024-12-08 15:54:51.302620:  
2024-12-08 15:54:51.308246: Epoch 59 
2024-12-08 15:54:51.310797: Current learning rate: 0.00448 
2024-12-08 15:55:23.858608: train_loss -0.9922 
2024-12-08 15:55:23.864234: val_loss -0.8816 
2024-12-08 15:55:23.868790: Pseudo dice [np.float32(0.904)] 
2024-12-08 15:55:23.871891: Epoch time: 32.56 s 
2024-12-08 15:55:24.597826:  
2024-12-08 15:55:24.602938: Epoch 60 
2024-12-08 15:55:24.606526: Current learning rate: 0.00438 
2024-12-08 15:55:57.357713: train_loss -0.9918 
2024-12-08 15:55:57.364851: val_loss -0.8824 
2024-12-08 15:55:57.367905: Pseudo dice [np.float32(0.9047)] 
2024-12-08 15:55:57.370447: Epoch time: 32.76 s 
2024-12-08 15:55:58.008021:  
2024-12-08 15:55:58.014160: Epoch 61 
2024-12-08 15:55:58.017232: Current learning rate: 0.00429 
2024-12-08 15:56:31.114382: train_loss -0.9918 
2024-12-08 15:56:31.120841: val_loss -0.8766 
2024-12-08 15:56:31.123869: Pseudo dice [np.float32(0.8996)] 
2024-12-08 15:56:31.126773: Epoch time: 33.11 s 
2024-12-08 15:56:31.700515:  
2024-12-08 15:56:31.705594: Epoch 62 
2024-12-08 15:56:31.708686: Current learning rate: 0.00419 
2024-12-08 15:57:04.552724: train_loss -0.9913 
2024-12-08 15:57:04.557888: val_loss -0.8814 
2024-12-08 15:57:04.561496: Pseudo dice [np.float32(0.9049)] 
2024-12-08 15:57:04.565051: Epoch time: 32.85 s 
2024-12-08 15:57:05.141189:  
2024-12-08 15:57:05.146250: Epoch 63 
2024-12-08 15:57:05.148792: Current learning rate: 0.00409 
2024-12-08 15:57:37.746923: train_loss -0.9917 
2024-12-08 15:57:37.751990: val_loss -0.8819 
2024-12-08 15:57:37.756551: Pseudo dice [np.float32(0.9042)] 
2024-12-08 15:57:37.759099: Epoch time: 32.61 s 
2024-12-08 15:57:38.337487:  
2024-12-08 15:57:38.342577: Epoch 64 
2024-12-08 15:57:38.346150: Current learning rate: 0.00399 
2024-12-08 15:58:11.016384: train_loss -0.9915 
2024-12-08 15:58:11.021997: val_loss -0.8834 
2024-12-08 15:58:11.024540: Pseudo dice [np.float32(0.9061)] 
2024-12-08 15:58:11.027093: Epoch time: 32.68 s 
2024-12-08 15:58:11.601683:  
2024-12-08 15:58:11.607303: Epoch 65 
2024-12-08 15:58:11.610399: Current learning rate: 0.00389 
2024-12-08 15:58:44.799840: train_loss -0.9916 
2024-12-08 15:58:44.805447: val_loss -0.8829 
2024-12-08 15:58:44.808573: Pseudo dice [np.float32(0.906)] 
2024-12-08 15:58:44.811138: Epoch time: 33.2 s 
2024-12-08 15:58:45.388859:  
2024-12-08 15:58:45.393973: Epoch 66 
2024-12-08 15:58:45.397047: Current learning rate: 0.00379 
2024-12-08 15:59:18.936487: train_loss -0.9918 
2024-12-08 15:59:18.942712: val_loss -0.8834 
2024-12-08 15:59:18.948133: Pseudo dice [np.float32(0.9065)] 
2024-12-08 15:59:18.953563: Epoch time: 33.55 s 
2024-12-08 15:59:19.546077:  
2024-12-08 15:59:19.550853: Epoch 67 
2024-12-08 15:59:19.553898: Current learning rate: 0.00369 
2024-12-08 15:59:53.217703: train_loss -0.9921 
2024-12-08 15:59:53.223965: val_loss -0.8823 
2024-12-08 15:59:53.227210: Pseudo dice [np.float32(0.9055)] 
2024-12-08 15:59:53.230428: Epoch time: 33.67 s 
2024-12-08 15:59:53.966273:  
2024-12-08 15:59:53.971206: Epoch 68 
2024-12-08 15:59:53.973766: Current learning rate: 0.00359 
2024-12-08 16:00:27.579584: train_loss -0.9918 
2024-12-08 16:00:27.586995: val_loss -0.8876 
2024-12-08 16:00:27.590080: Pseudo dice [np.float32(0.9096)] 
2024-12-08 16:00:27.595849: Epoch time: 33.61 s 
2024-12-08 16:00:27.599307: Yayy! New best EMA pseudo Dice: 0.9053999781608582 
2024-12-08 16:00:28.373797:  
2024-12-08 16:00:28.380434: Epoch 69 
2024-12-08 16:00:28.383488: Current learning rate: 0.00349 
2024-12-08 16:01:01.320440: train_loss -0.9926 
2024-12-08 16:01:01.327148: val_loss -0.8811 
2024-12-08 16:01:01.329699: Pseudo dice [np.float32(0.9035)] 
2024-12-08 16:01:01.334775: Epoch time: 32.95 s 
2024-12-08 16:01:01.935143:  
2024-12-08 16:01:01.940754: Epoch 70 
2024-12-08 16:01:01.943810: Current learning rate: 0.00338 
2024-12-08 16:01:35.402941: train_loss -0.9923 
2024-12-08 16:01:35.409513: val_loss -0.8806 
2024-12-08 16:01:35.412633: Pseudo dice [np.float32(0.904)] 
2024-12-08 16:01:35.416583: Epoch time: 33.47 s 
2024-12-08 16:01:36.007713:  
2024-12-08 16:01:36.013393: Epoch 71 
2024-12-08 16:01:36.016585: Current learning rate: 0.00328 
2024-12-08 16:02:09.192746: train_loss -0.9921 
2024-12-08 16:02:09.200587: val_loss -0.8778 
2024-12-08 16:02:09.205627: Pseudo dice [np.float32(0.9001)] 
2024-12-08 16:02:09.210005: Epoch time: 33.19 s 
2024-12-08 16:02:09.814544:  
2024-12-08 16:02:09.819479: Epoch 72 
2024-12-08 16:02:09.823029: Current learning rate: 0.00318 
2024-12-08 16:02:43.031027: train_loss -0.9924 
2024-12-08 16:02:43.037106: val_loss -0.8797 
2024-12-08 16:02:43.041221: Pseudo dice [np.float32(0.903)] 
2024-12-08 16:02:43.043761: Epoch time: 33.22 s 
2024-12-08 16:02:43.644702:  
2024-12-08 16:02:43.651288: Epoch 73 
2024-12-08 16:02:43.654928: Current learning rate: 0.00308 
2024-12-08 16:03:16.388274: train_loss -0.9926 
2024-12-08 16:03:16.396414: val_loss -0.8811 
2024-12-08 16:03:16.400975: Pseudo dice [np.float32(0.9039)] 
2024-12-08 16:03:16.403556: Epoch time: 32.74 s 
2024-12-08 16:03:16.987995:  
2024-12-08 16:03:16.993585: Epoch 74 
2024-12-08 16:03:16.997152: Current learning rate: 0.00297 
2024-12-08 16:03:49.682313: train_loss -0.9926 
2024-12-08 16:03:49.687912: val_loss -0.8814 
2024-12-08 16:03:49.691363: Pseudo dice [np.float32(0.9041)] 
2024-12-08 16:03:49.694949: Epoch time: 32.7 s 
2024-12-08 16:03:50.284116:  
2024-12-08 16:03:50.289735: Epoch 75 
2024-12-08 16:03:50.292276: Current learning rate: 0.00287 
2024-12-08 16:04:23.056654: train_loss -0.9922 
2024-12-08 16:04:23.064144: val_loss -0.8825 
2024-12-08 16:04:23.067724: Pseudo dice [np.float32(0.9049)] 
2024-12-08 16:04:23.071530: Epoch time: 32.77 s 
2024-12-08 16:04:23.815920:  
2024-12-08 16:04:23.821066: Epoch 76 
2024-12-08 16:04:23.826195: Current learning rate: 0.00277 
2024-12-08 16:04:56.469776: train_loss -0.9924 
2024-12-08 16:04:56.475425: val_loss -0.8839 
2024-12-08 16:04:56.478475: Pseudo dice [np.float32(0.9061)] 
2024-12-08 16:04:56.482531: Epoch time: 32.66 s 
2024-12-08 16:04:57.076827:  
2024-12-08 16:04:57.082416: Epoch 77 
2024-12-08 16:04:57.084963: Current learning rate: 0.00266 
2024-12-08 16:05:30.095222: train_loss -0.9931 
2024-12-08 16:05:30.102585: val_loss -0.8788 
2024-12-08 16:05:30.106958: Pseudo dice [np.float32(0.9022)] 
2024-12-08 16:05:30.111240: Epoch time: 33.02 s 
2024-12-08 16:05:30.706191:  
2024-12-08 16:05:30.712044: Epoch 78 
2024-12-08 16:05:30.716941: Current learning rate: 0.00256 
2024-12-08 16:06:03.492091: train_loss -0.9923 
2024-12-08 16:06:03.497159: val_loss -0.8843 
2024-12-08 16:06:03.500730: Pseudo dice [np.float32(0.9057)] 
2024-12-08 16:06:03.504859: Epoch time: 32.79 s 
2024-12-08 16:06:04.099957:  
2024-12-08 16:06:04.105227: Epoch 79 
2024-12-08 16:06:04.108491: Current learning rate: 0.00245 
2024-12-08 16:06:36.790877: train_loss -0.9924 
2024-12-08 16:06:36.798346: val_loss -0.8829 
2024-12-08 16:06:36.801553: Pseudo dice [np.float32(0.9049)] 
2024-12-08 16:06:36.804704: Epoch time: 32.69 s 
2024-12-08 16:06:37.399528:  
2024-12-08 16:06:37.404623: Epoch 80 
2024-12-08 16:06:37.408694: Current learning rate: 0.00235 
2024-12-08 16:07:10.131303: train_loss -0.9928 
2024-12-08 16:07:10.136977: val_loss -0.8826 
2024-12-08 16:07:10.140817: Pseudo dice [np.float32(0.9054)] 
2024-12-08 16:07:10.144333: Epoch time: 32.73 s 
2024-12-08 16:07:10.733425:  
2024-12-08 16:07:10.739170: Epoch 81 
2024-12-08 16:07:10.742826: Current learning rate: 0.00224 
2024-12-08 16:07:43.778875: train_loss -0.9923 
2024-12-08 16:07:43.784892: val_loss -0.8814 
2024-12-08 16:07:43.788905: Pseudo dice [np.float32(0.9048)] 
2024-12-08 16:07:43.792414: Epoch time: 33.05 s 
2024-12-08 16:07:44.379809:  
2024-12-08 16:07:44.385323: Epoch 82 
2024-12-08 16:07:44.388833: Current learning rate: 0.00214 
2024-12-08 16:08:17.453342: train_loss -0.9925 
2024-12-08 16:08:17.461863: val_loss -0.881 
2024-12-08 16:08:17.465872: Pseudo dice [np.float32(0.9034)] 
2024-12-08 16:08:17.469387: Epoch time: 33.07 s 
2024-12-08 16:08:18.239584:  
2024-12-08 16:08:18.245131: Epoch 83 
2024-12-08 16:08:18.248744: Current learning rate: 0.00203 
2024-12-08 16:08:50.933071: train_loss -0.9927 
2024-12-08 16:08:50.938684: val_loss -0.884 
2024-12-08 16:08:50.942765: Pseudo dice [np.float32(0.9059)] 
2024-12-08 16:08:50.945805: Epoch time: 32.69 s 
2024-12-08 16:08:51.501945:  
2024-12-08 16:08:51.507020: Epoch 84 
2024-12-08 16:08:51.510609: Current learning rate: 0.00192 
2024-12-08 16:09:24.401358: train_loss -0.9932 
2024-12-08 16:09:24.408987: val_loss -0.8795 
2024-12-08 16:09:24.414055: Pseudo dice [np.float32(0.9026)] 
2024-12-08 16:09:24.416675: Epoch time: 32.9 s 
2024-12-08 16:09:24.970303:  
2024-12-08 16:09:24.976515: Epoch 85 
2024-12-08 16:09:24.979621: Current learning rate: 0.00181 
2024-12-08 16:09:58.134228: train_loss -0.9926 
2024-12-08 16:09:58.139893: val_loss -0.881 
2024-12-08 16:09:58.142432: Pseudo dice [np.float32(0.9038)] 
2024-12-08 16:09:58.147576: Epoch time: 33.16 s 
2024-12-08 16:09:58.698950:  
2024-12-08 16:09:58.704605: Epoch 86 
2024-12-08 16:09:58.706649: Current learning rate: 0.0017 
2024-12-08 16:10:32.130863: train_loss -0.9932 
2024-12-08 16:10:32.137019: val_loss -0.8805 
2024-12-08 16:10:32.139570: Pseudo dice [np.float32(0.9031)] 
2024-12-08 16:10:32.143625: Epoch time: 33.43 s 
2024-12-08 16:10:32.694043:  
2024-12-08 16:10:32.699637: Epoch 87 
2024-12-08 16:10:32.703691: Current learning rate: 0.00159 
2024-12-08 16:11:05.431636: train_loss -0.9933 
2024-12-08 16:11:05.437802: val_loss -0.8793 
2024-12-08 16:11:05.439847: Pseudo dice [np.float32(0.9034)] 
2024-12-08 16:11:05.444997: Epoch time: 32.74 s 
2024-12-08 16:11:05.993553:  
2024-12-08 16:11:05.999739: Epoch 88 
2024-12-08 16:11:06.002292: Current learning rate: 0.00148 
2024-12-08 16:11:39.301725: train_loss -0.9929 
2024-12-08 16:11:39.306826: val_loss -0.8761 
2024-12-08 16:11:39.311915: Pseudo dice [np.float32(0.9012)] 
2024-12-08 16:11:39.315998: Epoch time: 33.31 s 
2024-12-08 16:11:39.867163:  
2024-12-08 16:11:39.873302: Epoch 89 
2024-12-08 16:11:39.876891: Current learning rate: 0.00137 
2024-12-08 16:12:12.729904: train_loss -0.9932 
2024-12-08 16:12:12.736190: val_loss -0.8832 
2024-12-08 16:12:12.739785: Pseudo dice [np.float32(0.9059)] 
2024-12-08 16:12:12.743362: Epoch time: 32.86 s 
2024-12-08 16:12:13.339702:  
2024-12-08 16:12:13.345259: Epoch 90 
2024-12-08 16:12:13.348424: Current learning rate: 0.00126 
2024-12-08 16:12:45.734152: train_loss -0.9931 
2024-12-08 16:12:45.741876: val_loss -0.8806 
2024-12-08 16:12:45.744926: Pseudo dice [np.float32(0.9028)] 
2024-12-08 16:12:45.748555: Epoch time: 32.4 s 
2024-12-08 16:12:46.451766:  
2024-12-08 16:12:46.456594: Epoch 91 
2024-12-08 16:12:46.460106: Current learning rate: 0.00115 
2024-12-08 16:13:18.872423: train_loss -0.993 
2024-12-08 16:13:18.878524: val_loss -0.8819 
2024-12-08 16:13:18.883150: Pseudo dice [np.float32(0.9046)] 
2024-12-08 16:13:18.887180: Epoch time: 32.42 s 
2024-12-08 16:13:19.436543:  
2024-12-08 16:13:19.442188: Epoch 92 
2024-12-08 16:13:19.445697: Current learning rate: 0.00103 
2024-12-08 16:13:51.831465: train_loss -0.9927 
2024-12-08 16:13:51.838659: val_loss -0.8812 
2024-12-08 16:13:51.842739: Pseudo dice [np.float32(0.9038)] 
2024-12-08 16:13:51.846274: Epoch time: 32.4 s 
2024-12-08 16:13:52.398963:  
2024-12-08 16:13:52.404501: Epoch 93 
2024-12-08 16:13:52.408011: Current learning rate: 0.00091 
2024-12-08 16:14:24.794189: train_loss -0.9935 
2024-12-08 16:14:24.800335: val_loss -0.8824 
2024-12-08 16:14:24.803883: Pseudo dice [np.float32(0.9053)] 
2024-12-08 16:14:24.808080: Epoch time: 32.4 s 
2024-12-08 16:14:25.354636:  
2024-12-08 16:14:25.361695: Epoch 94 
2024-12-08 16:14:25.365316: Current learning rate: 0.00079 
2024-12-08 16:14:57.772920: train_loss -0.9931 
2024-12-08 16:14:57.779618: val_loss -0.8819 
2024-12-08 16:14:57.783670: Pseudo dice [np.float32(0.9055)] 
2024-12-08 16:14:57.787775: Epoch time: 32.42 s 
2024-12-08 16:14:58.338980:  
2024-12-08 16:14:58.344494: Epoch 95 
2024-12-08 16:14:58.348595: Current learning rate: 0.00067 
2024-12-08 16:15:30.758320: train_loss -0.9932 
2024-12-08 16:15:30.764945: val_loss -0.8825 
2024-12-08 16:15:30.768513: Pseudo dice [np.float32(0.9055)] 
2024-12-08 16:15:30.771547: Epoch time: 32.42 s 
2024-12-08 16:15:31.325657:  
2024-12-08 16:15:31.331218: Epoch 96 
2024-12-08 16:15:31.334861: Current learning rate: 0.00055 
2024-12-08 16:16:03.731118: train_loss -0.9933 
2024-12-08 16:16:03.738184: val_loss -0.8808 
2024-12-08 16:16:03.741744: Pseudo dice [np.float32(0.9044)] 
2024-12-08 16:16:03.746321: Epoch time: 32.41 s 
2024-12-08 16:16:04.306412:  
2024-12-08 16:16:04.311459: Epoch 97 
2024-12-08 16:16:04.315496: Current learning rate: 0.00043 
2024-12-08 16:16:36.709308: train_loss -0.9932 
2024-12-08 16:16:36.715087: val_loss -0.8822 
2024-12-08 16:16:36.719181: Pseudo dice [np.float32(0.9052)] 
2024-12-08 16:16:36.722749: Epoch time: 32.4 s 
2024-12-08 16:16:37.285142:  
2024-12-08 16:16:37.288743: Epoch 98 
2024-12-08 16:16:37.292323: Current learning rate: 0.0003 
2024-12-08 16:17:09.846681: train_loss -0.9934 
2024-12-08 16:17:09.852828: val_loss -0.8794 
2024-12-08 16:17:09.856985: Pseudo dice [np.float32(0.9026)] 
2024-12-08 16:17:09.860034: Epoch time: 32.56 s 
2024-12-08 16:17:10.418934:  
2024-12-08 16:17:10.424060: Epoch 99 
2024-12-08 16:17:10.427578: Current learning rate: 0.00016 
2024-12-08 16:17:42.858042: train_loss -0.9937 
2024-12-08 16:17:42.864088: val_loss -0.8819 
2024-12-08 16:17:42.867618: Pseudo dice [np.float32(0.9048)] 
2024-12-08 16:17:42.871815: Epoch time: 32.44 s 
2024-12-08 16:17:43.796633: Training done. 
2024-12-08 16:17:43.827122: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-08 16:17:43.833321: The split file contains 5 splits. 
2024-12-08 16:17:43.838321: Desired fold for training: 0 
2024-12-08 16:17:43.842322: This split has 16 training and 4 validation cases. 
2024-12-08 16:17:43.846522: predicting la_007 
2024-12-08 16:17:43.851522: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2024-12-08 16:17:44.557109: predicting la_016 
2024-12-08 16:17:44.570185: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2024-12-08 16:17:44.863820: predicting la_021 
2024-12-08 16:17:44.872822: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2024-12-08 16:17:45.220519: predicting la_024 
2024-12-08 16:17:45.230659: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2024-12-08 16:17:52.477179: Validation complete 
2024-12-08 16:17:52.483295: Mean Validation Dice:  0.8960982500779822 
