
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-08 08:08:00.192345: do_dummy_2d_data_aug: False 
2024-12-08 08:08:00.192345: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-08 08:08:00.202876: The split file contains 5 splits. 
2024-12-08 08:08:00.202876: Desired fold for training: 0 
2024-12-08 08:08:00.202876: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 40, 'patch_size': [320, 256], 'median_image_size_in_voxels': [320.0, 232.0], 'spacing': [1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2024-12-08 08:08:06.400285: unpacking dataset... 
2024-12-08 08:08:06.583696: unpacking done... 
2024-12-08 08:08:08.705980:  
2024-12-08 08:08:08.711099: Epoch 0 
2024-12-08 08:08:08.713654: Current learning rate: 0.01 
2024-12-08 08:08:44.081669: train_loss -0.6116 
2024-12-08 08:08:44.089323: val_loss -0.8695 
2024-12-08 08:08:44.091868: Pseudo dice [np.float32(0.8915)] 
2024-12-08 08:08:44.094399: Epoch time: 35.38 s 
2024-12-08 08:08:44.096929: Yayy! New best EMA pseudo Dice: 0.8914999961853027 
2024-12-08 08:08:44.738560:  
2024-12-08 08:08:44.744696: Epoch 1 
2024-12-08 08:08:44.748256: Current learning rate: 0.00991 
2024-12-08 08:09:16.982182: train_loss -0.9393 
2024-12-08 08:09:16.989311: val_loss -0.8756 
2024-12-08 08:09:16.992865: Pseudo dice [np.float32(0.8953)] 
2024-12-08 08:09:16.995961: Epoch time: 32.24 s 
2024-12-08 08:09:16.998520: Yayy! New best EMA pseudo Dice: 0.8917999863624573 
2024-12-08 08:09:17.738232:  
2024-12-08 08:09:17.742786: Epoch 2 
2024-12-08 08:09:17.745868: Current learning rate: 0.00982 
2024-12-08 08:09:49.989356: train_loss -0.9591 
2024-12-08 08:09:49.994481: val_loss -0.8702 
2024-12-08 08:09:49.999046: Pseudo dice [np.float32(0.892)] 
2024-12-08 08:09:50.002117: Epoch time: 32.25 s 
2024-12-08 08:09:50.004658: Yayy! New best EMA pseudo Dice: 0.8919000029563904 
2024-12-08 08:09:50.766193:  
2024-12-08 08:09:50.771856: Epoch 3 
2024-12-08 08:09:50.774910: Current learning rate: 0.00973 
2024-12-08 08:10:23.008724: train_loss -0.9674 
2024-12-08 08:10:23.015331: val_loss -0.8778 
2024-12-08 08:10:23.018029: Pseudo dice [np.float32(0.8994)] 
2024-12-08 08:10:23.021091: Epoch time: 32.24 s 
2024-12-08 08:10:23.024153: Yayy! New best EMA pseudo Dice: 0.8925999999046326 
2024-12-08 08:10:23.759125:  
2024-12-08 08:10:23.764231: Epoch 4 
2024-12-08 08:10:23.767298: Current learning rate: 0.00964 
2024-12-08 08:10:56.016747: train_loss -0.9721 
2024-12-08 08:10:56.021820: val_loss -0.8752 
2024-12-08 08:10:56.025877: Pseudo dice [np.float32(0.8976)] 
2024-12-08 08:10:56.028452: Epoch time: 32.26 s 
2024-12-08 08:10:56.032003: Yayy! New best EMA pseudo Dice: 0.8931000232696533 
2024-12-08 08:10:56.901103:  
2024-12-08 08:10:56.906768: Epoch 5 
2024-12-08 08:10:56.909848: Current learning rate: 0.00955 
2024-12-08 08:11:29.153585: train_loss -0.9746 
2024-12-08 08:11:29.158651: val_loss -0.8758 
2024-12-08 08:11:29.163781: Pseudo dice [np.float32(0.8981)] 
2024-12-08 08:11:29.166325: Epoch time: 32.25 s 
2024-12-08 08:11:29.168867: Yayy! New best EMA pseudo Dice: 0.8935999870300293 
2024-12-08 08:11:29.893172:  
2024-12-08 08:11:29.898266: Epoch 6 
2024-12-08 08:11:29.900802: Current learning rate: 0.00946 
2024-12-08 08:12:02.129676: train_loss -0.9774 
2024-12-08 08:12:02.136363: val_loss -0.877 
2024-12-08 08:12:02.139956: Pseudo dice [np.float32(0.8997)] 
2024-12-08 08:12:02.141991: Epoch time: 32.24 s 
2024-12-08 08:12:02.144521: Yayy! New best EMA pseudo Dice: 0.8942000269889832 
2024-12-08 08:12:02.881524:  
2024-12-08 08:12:02.887117: Epoch 7 
2024-12-08 08:12:02.889660: Current learning rate: 0.00937 
2024-12-08 08:12:35.125495: train_loss -0.9786 
2024-12-08 08:12:35.131577: val_loss -0.8748 
2024-12-08 08:12:35.135659: Pseudo dice [np.float32(0.8976)] 
2024-12-08 08:12:35.138200: Epoch time: 32.24 s 
2024-12-08 08:12:35.141756: Yayy! New best EMA pseudo Dice: 0.8945000171661377 
2024-12-08 08:12:35.885324:  
2024-12-08 08:12:35.890943: Epoch 8 
2024-12-08 08:12:35.893998: Current learning rate: 0.00928 
2024-12-08 08:13:08.123074: train_loss -0.9801 
2024-12-08 08:13:08.130182: val_loss -0.877 
2024-12-08 08:13:08.133247: Pseudo dice [np.float32(0.9004)] 
2024-12-08 08:13:08.135884: Epoch time: 32.24 s 
2024-12-08 08:13:08.138417: Yayy! New best EMA pseudo Dice: 0.8950999975204468 
2024-12-08 08:13:08.893753:  
2024-12-08 08:13:08.899894: Epoch 9 
2024-12-08 08:13:08.902432: Current learning rate: 0.00919 
2024-12-08 08:13:41.149998: train_loss -0.9808 
2024-12-08 08:13:41.157640: val_loss -0.8737 
2024-12-08 08:13:41.160172: Pseudo dice [np.float32(0.898)] 
2024-12-08 08:13:41.162704: Epoch time: 32.26 s 
2024-12-08 08:13:41.165233: Yayy! New best EMA pseudo Dice: 0.8953999876976013 
2024-12-08 08:13:41.884460:  
2024-12-08 08:13:41.890549: Epoch 10 
2024-12-08 08:13:41.894095: Current learning rate: 0.0091 
2024-12-08 08:14:14.145501: train_loss -0.9817 
2024-12-08 08:14:14.151632: val_loss -0.8774 
2024-12-08 08:14:14.154686: Pseudo dice [np.float32(0.9005)] 
2024-12-08 08:14:14.158252: Epoch time: 32.26 s 
2024-12-08 08:14:14.160789: Yayy! New best EMA pseudo Dice: 0.8959000110626221 
2024-12-08 08:14:14.880873:  
2024-12-08 08:14:14.886016: Epoch 11 
2024-12-08 08:14:14.888547: Current learning rate: 0.009 
2024-12-08 08:14:47.124008: train_loss -0.9829 
2024-12-08 08:14:47.129070: val_loss -0.875 
2024-12-08 08:14:47.131632: Pseudo dice [np.float32(0.8992)] 
2024-12-08 08:14:47.136717: Epoch time: 32.24 s 
2024-12-08 08:14:47.139258: Yayy! New best EMA pseudo Dice: 0.8962000012397766 
2024-12-08 08:14:47.867068:  
2024-12-08 08:14:47.872658: Epoch 12 
2024-12-08 08:14:47.875200: Current learning rate: 0.00891 
2024-12-08 08:15:20.122359: train_loss -0.983 
2024-12-08 08:15:20.128518: val_loss -0.8736 
2024-12-08 08:15:20.132068: Pseudo dice [np.float32(0.899)] 
2024-12-08 08:15:20.135120: Epoch time: 32.26 s 
2024-12-08 08:15:20.138169: Yayy! New best EMA pseudo Dice: 0.8964999914169312 
2024-12-08 08:15:21.018684:  
2024-12-08 08:15:21.023763: Epoch 13 
2024-12-08 08:15:21.026822: Current learning rate: 0.00882 
2024-12-08 08:15:53.277343: train_loss -0.9834 
2024-12-08 08:15:53.282996: val_loss -0.8774 
2024-12-08 08:15:53.285553: Pseudo dice [np.float32(0.902)] 
2024-12-08 08:15:53.288091: Epoch time: 32.26 s 
2024-12-08 08:15:53.293216: Yayy! New best EMA pseudo Dice: 0.8970999717712402 
2024-12-08 08:15:54.026553:  
2024-12-08 08:15:54.032647: Epoch 14 
2024-12-08 08:15:54.035189: Current learning rate: 0.00873 
2024-12-08 08:16:26.281622: train_loss -0.9841 
2024-12-08 08:16:26.289231: val_loss -0.8814 
2024-12-08 08:16:26.291769: Pseudo dice [np.float32(0.9045)] 
2024-12-08 08:16:26.296887: Epoch time: 32.26 s 
2024-12-08 08:16:26.299432: Yayy! New best EMA pseudo Dice: 0.8978000283241272 
2024-12-08 08:16:27.051484:  
2024-12-08 08:16:27.057570: Epoch 15 
2024-12-08 08:16:27.060659: Current learning rate: 0.00864 
2024-12-08 08:16:59.306412: train_loss -0.9844 
2024-12-08 08:16:59.310966: val_loss -0.8802 
2024-12-08 08:16:59.315528: Pseudo dice [np.float32(0.9029)] 
2024-12-08 08:16:59.318615: Epoch time: 32.25 s 
2024-12-08 08:16:59.321151: Yayy! New best EMA pseudo Dice: 0.8982999920845032 
2024-12-08 08:17:00.069251:  
2024-12-08 08:17:00.073825: Epoch 16 
2024-12-08 08:17:00.076893: Current learning rate: 0.00855 
2024-12-08 08:17:32.348912: train_loss -0.9849 
2024-12-08 08:17:32.355029: val_loss -0.8798 
2024-12-08 08:17:32.359124: Pseudo dice [np.float32(0.9033)] 
2024-12-08 08:17:32.361669: Epoch time: 32.28 s 
2024-12-08 08:17:32.364205: Yayy! New best EMA pseudo Dice: 0.8988000154495239 
2024-12-08 08:17:33.116911:  
2024-12-08 08:17:33.120456: Epoch 17 
2024-12-08 08:17:33.124555: Current learning rate: 0.00846 
2024-12-08 08:18:05.364402: train_loss -0.985 
2024-12-08 08:18:05.370008: val_loss -0.8748 
2024-12-08 08:18:05.372551: Pseudo dice [np.float32(0.8993)] 
2024-12-08 08:18:05.375099: Epoch time: 32.25 s 
2024-12-08 08:18:05.379651: Yayy! New best EMA pseudo Dice: 0.8988999724388123 
2024-12-08 08:18:06.129520:  
2024-12-08 08:18:06.135129: Epoch 18 
2024-12-08 08:18:06.138675: Current learning rate: 0.00836 
2024-12-08 08:18:38.374948: train_loss -0.9852 
2024-12-08 08:18:38.381120: val_loss -0.8737 
2024-12-08 08:18:38.385164: Pseudo dice [np.float32(0.8989)] 
2024-12-08 08:18:38.388234: Epoch time: 32.24 s 
2024-12-08 08:18:38.390811: Yayy! New best EMA pseudo Dice: 0.8988999724388123 
2024-12-08 08:18:39.140847:  
2024-12-08 08:18:39.146084: Epoch 19 
2024-12-08 08:18:39.150648: Current learning rate: 0.00827 
2024-12-08 08:19:11.397116: train_loss -0.9857 
2024-12-08 08:19:11.402182: val_loss -0.8804 
2024-12-08 08:19:11.405293: Pseudo dice [np.float32(0.9046)] 
2024-12-08 08:19:11.407834: Epoch time: 32.26 s 
2024-12-08 08:19:11.410892: Yayy! New best EMA pseudo Dice: 0.899399995803833 
2024-12-08 08:19:12.173600:  
2024-12-08 08:19:12.179188: Epoch 20 
2024-12-08 08:19:12.181728: Current learning rate: 0.00818 
2024-12-08 08:19:44.418271: train_loss -0.9864 
2024-12-08 08:19:44.425355: val_loss -0.8799 
2024-12-08 08:19:44.428454: Pseudo dice [np.float32(0.9041)] 
2024-12-08 08:19:44.430988: Epoch time: 32.24 s 
2024-12-08 08:19:44.433527: Yayy! New best EMA pseudo Dice: 0.8999000191688538 
2024-12-08 08:19:45.325615:  
2024-12-08 08:19:45.330719: Epoch 21 
2024-12-08 08:19:45.334286: Current learning rate: 0.00809 
2024-12-08 08:20:17.565928: train_loss -0.9858 
2024-12-08 08:20:17.571560: val_loss -0.8801 
2024-12-08 08:20:17.574124: Pseudo dice [np.float32(0.9038)] 
2024-12-08 08:20:17.576657: Epoch time: 32.24 s 
2024-12-08 08:20:17.579187: Yayy! New best EMA pseudo Dice: 0.9003000259399414 
2024-12-08 08:20:18.303222:  
2024-12-08 08:20:18.308856: Epoch 22 
2024-12-08 08:20:18.311927: Current learning rate: 0.008 
2024-12-08 08:20:50.543556: train_loss -0.9867 
2024-12-08 08:20:50.549189: val_loss -0.8769 
2024-12-08 08:20:50.553746: Pseudo dice [np.float32(0.9012)] 
2024-12-08 08:20:50.556814: Epoch time: 32.24 s 
2024-12-08 08:20:50.559348: Yayy! New best EMA pseudo Dice: 0.9003999829292297 
2024-12-08 08:20:51.280135:  
2024-12-08 08:20:51.285748: Epoch 23 
2024-12-08 08:20:51.288306: Current learning rate: 0.0079 
2024-12-08 08:21:23.517894: train_loss -0.9872 
2024-12-08 08:21:23.522971: val_loss -0.8785 
2024-12-08 08:21:23.525509: Pseudo dice [np.float32(0.9033)] 
2024-12-08 08:21:23.528074: Epoch time: 32.24 s 
2024-12-08 08:21:23.532648: Yayy! New best EMA pseudo Dice: 0.9006999731063843 
2024-12-08 08:21:24.250464:  
2024-12-08 08:21:24.255535: Epoch 24 
2024-12-08 08:21:24.259208: Current learning rate: 0.00781 
2024-12-08 08:21:56.490859: train_loss -0.9877 
2024-12-08 08:21:56.495923: val_loss -0.8758 
2024-12-08 08:21:56.498484: Pseudo dice [np.float32(0.9005)] 
2024-12-08 08:21:56.503037: Epoch time: 32.24 s 
2024-12-08 08:21:57.053444:  
2024-12-08 08:21:57.058589: Epoch 25 
2024-12-08 08:21:57.061651: Current learning rate: 0.00772 
2024-12-08 08:22:29.286433: train_loss -0.9874 
2024-12-08 08:22:29.291016: val_loss -0.8784 
2024-12-08 08:22:29.294578: Pseudo dice [np.float32(0.9024)] 
2024-12-08 08:22:29.298141: Epoch time: 32.23 s 
2024-12-08 08:22:29.300191: Yayy! New best EMA pseudo Dice: 0.9007999897003174 
2024-12-08 08:22:30.027941:  
2024-12-08 08:22:30.034536: Epoch 26 
2024-12-08 08:22:30.038188: Current learning rate: 0.00763 
2024-12-08 08:23:02.277802: train_loss -0.9874 
2024-12-08 08:23:02.284948: val_loss -0.8814 
2024-12-08 08:23:02.288021: Pseudo dice [np.float32(0.9055)] 
2024-12-08 08:23:02.290558: Epoch time: 32.25 s 
2024-12-08 08:23:02.293096: Yayy! New best EMA pseudo Dice: 0.9013000130653381 
2024-12-08 08:23:03.017725:  
2024-12-08 08:23:03.022814: Epoch 27 
2024-12-08 08:23:03.025365: Current learning rate: 0.00753 
2024-12-08 08:23:35.252059: train_loss -0.9876 
2024-12-08 08:23:35.257139: val_loss -0.8816 
2024-12-08 08:23:35.262232: Pseudo dice [np.float32(0.9053)] 
2024-12-08 08:23:35.264777: Epoch time: 32.23 s 
2024-12-08 08:23:35.267343: Yayy! New best EMA pseudo Dice: 0.9017000198364258 
2024-12-08 08:23:36.136076:  
2024-12-08 08:23:36.141675: Epoch 28 
2024-12-08 08:23:36.144723: Current learning rate: 0.00744 
2024-12-08 08:24:08.380793: train_loss -0.9882 
2024-12-08 08:24:08.385369: val_loss -0.8783 
2024-12-08 08:24:08.390521: Pseudo dice [np.float32(0.9023)] 
2024-12-08 08:24:08.393073: Epoch time: 32.24 s 
2024-12-08 08:24:08.395615: Yayy! New best EMA pseudo Dice: 0.9017999768257141 
2024-12-08 08:24:09.128335:  
2024-12-08 08:24:09.134948: Epoch 29 
2024-12-08 08:24:09.138046: Current learning rate: 0.00735 
2024-12-08 08:24:41.362598: train_loss -0.9888 
2024-12-08 08:24:41.367669: val_loss -0.8752 
2024-12-08 08:24:41.370238: Pseudo dice [np.float32(0.8998)] 
2024-12-08 08:24:41.374799: Epoch time: 32.23 s 
2024-12-08 08:24:41.933558:  
2024-12-08 08:24:41.939186: Epoch 30 
2024-12-08 08:24:41.942249: Current learning rate: 0.00725 
2024-12-08 08:25:14.172479: train_loss -0.9882 
2024-12-08 08:25:14.178631: val_loss -0.8753 
2024-12-08 08:25:14.181680: Pseudo dice [np.float32(0.9)] 
2024-12-08 08:25:14.183714: Epoch time: 32.24 s 
2024-12-08 08:25:14.747420:  
2024-12-08 08:25:14.753022: Epoch 31 
2024-12-08 08:25:14.755618: Current learning rate: 0.00716 
2024-12-08 08:25:46.985831: train_loss -0.9883 
2024-12-08 08:25:46.991427: val_loss -0.8815 
2024-12-08 08:25:46.993977: Pseudo dice [np.float32(0.9061)] 
2024-12-08 08:25:46.996544: Epoch time: 32.24 s 
2024-12-08 08:25:46.999080: Yayy! New best EMA pseudo Dice: 0.9018999934196472 
2024-12-08 08:25:47.746097:  
2024-12-08 08:25:47.751688: Epoch 32 
2024-12-08 08:25:47.754823: Current learning rate: 0.00707 
2024-12-08 08:26:19.989346: train_loss -0.9887 
2024-12-08 08:26:19.996459: val_loss -0.8779 
2024-12-08 08:26:19.999518: Pseudo dice [np.float32(0.9026)] 
2024-12-08 08:26:20.002059: Epoch time: 32.24 s 
2024-12-08 08:26:20.006623: Yayy! New best EMA pseudo Dice: 0.9020000100135803 
2024-12-08 08:26:20.748577:  
2024-12-08 08:26:20.753680: Epoch 33 
2024-12-08 08:26:20.756226: Current learning rate: 0.00697 
2024-12-08 08:26:53.006950: train_loss -0.9893 
2024-12-08 08:26:53.012565: val_loss -0.8791 
2024-12-08 08:26:53.015684: Pseudo dice [np.float32(0.9034)] 
2024-12-08 08:26:53.018744: Epoch time: 32.26 s 
2024-12-08 08:26:53.021284: Yayy! New best EMA pseudo Dice: 0.9021000266075134 
2024-12-08 08:26:53.764154:  
2024-12-08 08:26:53.769234: Epoch 34 
2024-12-08 08:26:53.773282: Current learning rate: 0.00688 
2024-12-08 08:27:26.023862: train_loss -0.9888 
2024-12-08 08:27:26.030953: val_loss -0.8801 
2024-12-08 08:27:26.034059: Pseudo dice [np.float32(0.9044)] 
2024-12-08 08:27:26.036597: Epoch time: 32.26 s 
2024-12-08 08:27:26.039141: Yayy! New best EMA pseudo Dice: 0.9023000001907349 
2024-12-08 08:27:26.932064:  
2024-12-08 08:27:26.937706: Epoch 35 
2024-12-08 08:27:26.940784: Current learning rate: 0.00679 
2024-12-08 08:27:59.169001: train_loss -0.9886 
2024-12-08 08:27:59.174074: val_loss -0.8792 
2024-12-08 08:27:59.177159: Pseudo dice [np.float32(0.9034)] 
2024-12-08 08:27:59.181195: Epoch time: 32.24 s 
2024-12-08 08:27:59.184242: Yayy! New best EMA pseudo Dice: 0.902400016784668 
2024-12-08 08:27:59.940084:  
2024-12-08 08:27:59.945182: Epoch 36 
2024-12-08 08:27:59.948278: Current learning rate: 0.00669 
2024-12-08 08:28:32.203472: train_loss -0.9887 
2024-12-08 08:28:32.209068: val_loss -0.8807 
2024-12-08 08:28:32.211629: Pseudo dice [np.float32(0.9029)] 
2024-12-08 08:28:32.216182: Epoch time: 32.27 s 
2024-12-08 08:28:32.219273: Yayy! New best EMA pseudo Dice: 0.9024999737739563 
2024-12-08 08:28:32.973279:  
2024-12-08 08:28:32.979399: Epoch 37 
2024-12-08 08:28:32.981940: Current learning rate: 0.0066 
2024-12-08 08:29:05.219124: train_loss -0.9888 
2024-12-08 08:29:05.225732: val_loss -0.8774 
2024-12-08 08:29:05.230803: Pseudo dice [np.float32(0.9012)] 
2024-12-08 08:29:05.233338: Epoch time: 32.25 s 
2024-12-08 08:29:05.806728:  
2024-12-08 08:29:05.811793: Epoch 38 
2024-12-08 08:29:05.814332: Current learning rate: 0.0065 
2024-12-08 08:29:38.047068: train_loss -0.9893 
2024-12-08 08:29:38.052132: val_loss -0.8801 
2024-12-08 08:29:38.057204: Pseudo dice [np.float32(0.9038)] 
2024-12-08 08:29:38.059783: Epoch time: 32.24 s 
2024-12-08 08:29:38.062844: Yayy! New best EMA pseudo Dice: 0.9024999737739563 
2024-12-08 08:29:38.807606:  
2024-12-08 08:29:38.812682: Epoch 39 
2024-12-08 08:29:38.816731: Current learning rate: 0.00641 
2024-12-08 08:30:11.063625: train_loss -0.9896 
2024-12-08 08:30:11.069700: val_loss -0.8768 
2024-12-08 08:30:11.073810: Pseudo dice [np.float32(0.901)] 
2024-12-08 08:30:11.077358: Epoch time: 32.26 s 
2024-12-08 08:30:11.654784:  
2024-12-08 08:30:11.661418: Epoch 40 
2024-12-08 08:30:11.663965: Current learning rate: 0.00631 
2024-12-08 08:30:43.910260: train_loss -0.9898 
2024-12-08 08:30:43.915925: val_loss -0.8785 
2024-12-08 08:30:43.919495: Pseudo dice [np.float32(0.9033)] 
2024-12-08 08:30:43.922038: Epoch time: 32.26 s 
2024-12-08 08:30:44.501138:  
2024-12-08 08:30:44.506203: Epoch 41 
2024-12-08 08:30:44.508739: Current learning rate: 0.00622 
2024-12-08 08:31:16.759839: train_loss -0.9898 
2024-12-08 08:31:16.767512: val_loss -0.878 
2024-12-08 08:31:16.770049: Pseudo dice [np.float32(0.9022)] 
2024-12-08 08:31:16.772579: Epoch time: 32.26 s 
2024-12-08 08:31:17.318649:  
2024-12-08 08:31:17.323726: Epoch 42 
2024-12-08 08:31:17.326775: Current learning rate: 0.00612 
2024-12-08 08:31:49.567726: train_loss -0.9899 
2024-12-08 08:31:49.572801: val_loss -0.8755 
2024-12-08 08:31:49.577359: Pseudo dice [np.float32(0.8997)] 
2024-12-08 08:31:49.580441: Epoch time: 32.25 s 
2024-12-08 08:31:50.275519:  
2024-12-08 08:31:50.282112: Epoch 43 
2024-12-08 08:31:50.285735: Current learning rate: 0.00603 
2024-12-08 08:32:22.526605: train_loss -0.9901 
2024-12-08 08:32:22.533704: val_loss -0.8832 
2024-12-08 08:32:22.536787: Pseudo dice [np.float32(0.9064)] 
2024-12-08 08:32:22.539852: Epoch time: 32.25 s 
2024-12-08 08:32:22.542395: Yayy! New best EMA pseudo Dice: 0.9025999903678894 
2024-12-08 08:32:23.275768:  
2024-12-08 08:32:23.281356: Epoch 44 
2024-12-08 08:32:23.285424: Current learning rate: 0.00593 
2024-12-08 08:32:55.519523: train_loss -0.9905 
2024-12-08 08:32:55.524596: val_loss -0.8814 
2024-12-08 08:32:55.529667: Pseudo dice [np.float32(0.9059)] 
2024-12-08 08:32:55.532215: Epoch time: 32.24 s 
2024-12-08 08:32:55.534780: Yayy! New best EMA pseudo Dice: 0.902899980545044 
2024-12-08 08:32:56.263117:  
2024-12-08 08:32:56.268744: Epoch 45 
2024-12-08 08:32:56.271817: Current learning rate: 0.00584 
2024-12-08 08:33:28.517953: train_loss -0.99 
2024-12-08 08:33:28.525601: val_loss -0.8771 
2024-12-08 08:33:28.529162: Pseudo dice [np.float32(0.9016)] 
2024-12-08 08:33:28.531696: Epoch time: 32.25 s 
2024-12-08 08:33:29.071039:  
2024-12-08 08:33:29.077150: Epoch 46 
2024-12-08 08:33:29.080199: Current learning rate: 0.00574 
2024-12-08 08:34:01.326942: train_loss -0.9901 
2024-12-08 08:34:01.332539: val_loss -0.8802 
2024-12-08 08:34:01.334558: Pseudo dice [np.float32(0.9055)] 
2024-12-08 08:34:01.337104: Epoch time: 32.26 s 
2024-12-08 08:34:01.341741: Yayy! New best EMA pseudo Dice: 0.902999997138977 
2024-12-08 08:34:02.066341:  
2024-12-08 08:34:02.071415: Epoch 47 
2024-12-08 08:34:02.074990: Current learning rate: 0.00565 
2024-12-08 08:34:34.325352: train_loss -0.9901 
2024-12-08 08:34:34.331978: val_loss -0.879 
2024-12-08 08:34:34.335561: Pseudo dice [np.float32(0.903)] 
2024-12-08 08:34:34.338097: Epoch time: 32.26 s 
2024-12-08 08:34:34.882140:  
2024-12-08 08:34:34.887733: Epoch 48 
2024-12-08 08:34:34.890270: Current learning rate: 0.00555 
2024-12-08 08:35:07.146933: train_loss -0.9902 
2024-12-08 08:35:07.152526: val_loss -0.8798 
2024-12-08 08:35:07.155097: Pseudo dice [np.float32(0.9037)] 
2024-12-08 08:35:07.157631: Epoch time: 32.26 s 
2024-12-08 08:35:07.160162: Yayy! New best EMA pseudo Dice: 0.9031000137329102 
2024-12-08 08:35:07.894659:  
2024-12-08 08:35:07.899849: Epoch 49 
2024-12-08 08:35:07.902389: Current learning rate: 0.00546 
2024-12-08 08:35:40.152294: train_loss -0.9904 
2024-12-08 08:35:40.157359: val_loss -0.8776 
2024-12-08 08:35:40.161413: Pseudo dice [np.float32(0.9021)] 
2024-12-08 08:35:40.165049: Epoch time: 32.26 s 
2024-12-08 08:35:40.868164:  
2024-12-08 08:35:40.873771: Epoch 50 
2024-12-08 08:35:40.876318: Current learning rate: 0.00536 
2024-12-08 08:36:13.126385: train_loss -0.9907 
2024-12-08 08:36:13.131475: val_loss -0.8764 
2024-12-08 08:36:13.134035: Pseudo dice [np.float32(0.9012)] 
2024-12-08 08:36:13.137585: Epoch time: 32.26 s 
2024-12-08 08:36:13.831199:  
2024-12-08 08:36:13.836283: Epoch 51 
2024-12-08 08:36:13.839336: Current learning rate: 0.00526 
2024-12-08 08:36:46.080681: train_loss -0.9908 
2024-12-08 08:36:46.086279: val_loss -0.8781 
2024-12-08 08:36:46.090356: Pseudo dice [np.float32(0.9016)] 
2024-12-08 08:36:46.093427: Epoch time: 32.25 s 
2024-12-08 08:36:46.645838:  
2024-12-08 08:36:46.650914: Epoch 52 
2024-12-08 08:36:46.654474: Current learning rate: 0.00517 
2024-12-08 08:37:18.903257: train_loss -0.991 
2024-12-08 08:37:18.908335: val_loss -0.8762 
2024-12-08 08:37:18.912910: Pseudo dice [np.float32(0.9012)] 
2024-12-08 08:37:18.915451: Epoch time: 32.26 s 
2024-12-08 08:37:19.470048:  
2024-12-08 08:37:19.475627: Epoch 53 
2024-12-08 08:37:19.478207: Current learning rate: 0.00507 
2024-12-08 08:37:51.710320: train_loss -0.9904 
2024-12-08 08:37:51.717919: val_loss -0.877 
2024-12-08 08:37:51.720495: Pseudo dice [np.float32(0.9015)] 
2024-12-08 08:37:51.723035: Epoch time: 32.24 s 
2024-12-08 08:37:52.277079:  
2024-12-08 08:37:52.282146: Epoch 54 
2024-12-08 08:37:52.284675: Current learning rate: 0.00497 
2024-12-08 08:38:24.521093: train_loss -0.9909 
2024-12-08 08:38:24.526714: val_loss -0.8791 
2024-12-08 08:38:24.529250: Pseudo dice [np.float32(0.9037)] 
2024-12-08 08:38:24.533799: Epoch time: 32.25 s 
2024-12-08 08:38:25.086143:  
2024-12-08 08:38:25.091243: Epoch 55 
2024-12-08 08:38:25.094306: Current learning rate: 0.00487 
2024-12-08 08:38:57.336863: train_loss -0.9908 
2024-12-08 08:38:57.341988: val_loss -0.8758 
2024-12-08 08:38:57.344524: Pseudo dice [np.float32(0.9013)] 
2024-12-08 08:38:57.349073: Epoch time: 32.25 s 
2024-12-08 08:38:57.905237:  
2024-12-08 08:38:57.911320: Epoch 56 
2024-12-08 08:38:57.914881: Current learning rate: 0.00478 
2024-12-08 08:39:30.155535: train_loss -0.991 
2024-12-08 08:39:30.163149: val_loss -0.8777 
2024-12-08 08:39:30.166726: Pseudo dice [np.float32(0.9028)] 
2024-12-08 08:39:30.169260: Epoch time: 32.25 s 
2024-12-08 08:39:30.726016:  
2024-12-08 08:39:30.731112: Epoch 57 
2024-12-08 08:39:30.733665: Current learning rate: 0.00468 
2024-12-08 08:40:02.987430: train_loss -0.9913 
2024-12-08 08:40:02.992489: val_loss -0.8759 
2024-12-08 08:40:02.997585: Pseudo dice [np.float32(0.8997)] 
2024-12-08 08:40:03.000134: Epoch time: 32.26 s 
2024-12-08 08:40:03.558114:  
2024-12-08 08:40:03.564246: Epoch 58 
2024-12-08 08:40:03.566790: Current learning rate: 0.00458 
2024-12-08 08:40:35.816403: train_loss -0.9913 
2024-12-08 08:40:35.823004: val_loss -0.8796 
2024-12-08 08:40:35.826062: Pseudo dice [np.float32(0.902)] 
2024-12-08 08:40:35.828657: Epoch time: 32.26 s 
2024-12-08 08:40:36.535130:  
2024-12-08 08:40:36.540244: Epoch 59 
2024-12-08 08:40:36.543308: Current learning rate: 0.00448 
2024-12-08 08:41:08.800715: train_loss -0.9913 
2024-12-08 08:41:08.805789: val_loss -0.8833 
2024-12-08 08:41:08.810381: Pseudo dice [np.float32(0.9074)] 
2024-12-08 08:41:08.813468: Epoch time: 32.27 s 
2024-12-08 08:41:09.379280:  
2024-12-08 08:41:09.384899: Epoch 60 
2024-12-08 08:41:09.387451: Current learning rate: 0.00438 
2024-12-08 08:41:41.630973: train_loss -0.9911 
2024-12-08 08:41:41.636037: val_loss -0.8791 
2024-12-08 08:41:41.641189: Pseudo dice [np.float32(0.9025)] 
2024-12-08 08:41:41.643731: Epoch time: 32.25 s 
2024-12-08 08:41:42.204660:  
2024-12-08 08:41:42.209777: Epoch 61 
2024-12-08 08:41:42.213834: Current learning rate: 0.00429 
2024-12-08 08:42:14.464517: train_loss -0.9911 
2024-12-08 08:42:14.468612: val_loss -0.8806 
2024-12-08 08:42:14.473167: Pseudo dice [np.float32(0.9042)] 
2024-12-08 08:42:14.476223: Epoch time: 32.26 s 
2024-12-08 08:42:15.038962:  
2024-12-08 08:42:15.045583: Epoch 62 
2024-12-08 08:42:15.048124: Current learning rate: 0.00419 
2024-12-08 08:42:47.292162: train_loss -0.9915 
2024-12-08 08:42:47.299756: val_loss -0.8798 
2024-12-08 08:42:47.302340: Pseudo dice [np.float32(0.9043)] 
2024-12-08 08:42:47.304881: Epoch time: 32.25 s 
2024-12-08 08:42:47.869687:  
2024-12-08 08:42:47.874752: Epoch 63 
2024-12-08 08:42:47.877285: Current learning rate: 0.00409 
2024-12-08 08:43:20.121293: train_loss -0.9914 
2024-12-08 08:43:20.127427: val_loss -0.8804 
2024-12-08 08:43:20.132499: Pseudo dice [np.float32(0.9034)] 
2024-12-08 08:43:20.135042: Epoch time: 32.25 s 
2024-12-08 08:43:20.702546:  
2024-12-08 08:43:20.707642: Epoch 64 
2024-12-08 08:43:20.711210: Current learning rate: 0.00399 
2024-12-08 08:43:52.948322: train_loss -0.9916 
2024-12-08 08:43:52.953410: val_loss -0.8821 
2024-12-08 08:43:52.956535: Pseudo dice [np.float32(0.9063)] 
2024-12-08 08:43:52.959081: Epoch time: 32.25 s 
2024-12-08 08:43:52.961619: Yayy! New best EMA pseudo Dice: 0.9032999873161316 
2024-12-08 08:43:53.712057:  
2024-12-08 08:43:53.717659: Epoch 65 
2024-12-08 08:43:53.720242: Current learning rate: 0.00389 
2024-12-08 08:44:25.972669: train_loss -0.9913 
2024-12-08 08:44:25.979767: val_loss -0.8824 
2024-12-08 08:44:25.982850: Pseudo dice [np.float32(0.9059)] 
2024-12-08 08:44:25.985395: Epoch time: 32.26 s 
2024-12-08 08:44:25.987925: Yayy! New best EMA pseudo Dice: 0.9035999774932861 
2024-12-08 08:44:26.725377:  
2024-12-08 08:44:26.731023: Epoch 66 
2024-12-08 08:44:26.734084: Current learning rate: 0.00379 
2024-12-08 08:44:58.975586: train_loss -0.9915 
2024-12-08 08:44:58.980705: val_loss -0.8811 
2024-12-08 08:44:58.983245: Pseudo dice [np.float32(0.9051)] 
2024-12-08 08:44:58.988366: Epoch time: 32.25 s 
2024-12-08 08:44:58.990919: Yayy! New best EMA pseudo Dice: 0.9038000106811523 
2024-12-08 08:44:59.884349:  
2024-12-08 08:44:59.889993: Epoch 67 
2024-12-08 08:44:59.892547: Current learning rate: 0.00369 
2024-12-08 08:45:32.149796: train_loss -0.9918 
2024-12-08 08:45:32.157441: val_loss -0.8847 
2024-12-08 08:45:32.162573: Pseudo dice [np.float32(0.9076)] 
2024-12-08 08:45:32.165635: Epoch time: 32.27 s 
2024-12-08 08:45:32.170194: Yayy! New best EMA pseudo Dice: 0.9041000008583069 
2024-12-08 08:45:32.923005:  
2024-12-08 08:45:32.929089: Epoch 68 
2024-12-08 08:45:32.933154: Current learning rate: 0.00359 
2024-12-08 08:46:05.179069: train_loss -0.9918 
2024-12-08 08:46:05.185163: val_loss -0.8757 
2024-12-08 08:46:05.188224: Pseudo dice [np.float32(0.8998)] 
2024-12-08 08:46:05.192822: Epoch time: 32.26 s 
2024-12-08 08:46:05.767663:  
2024-12-08 08:46:05.772749: Epoch 69 
2024-12-08 08:46:05.776797: Current learning rate: 0.00349 
2024-12-08 08:46:38.026979: train_loss -0.9916 
2024-12-08 08:46:38.034111: val_loss -0.8797 
2024-12-08 08:46:38.041215: Pseudo dice [np.float32(0.9025)] 
2024-12-08 08:46:38.043831: Epoch time: 32.26 s 
2024-12-08 08:46:38.612889:  
2024-12-08 08:46:38.618516: Epoch 70 
2024-12-08 08:46:38.621557: Current learning rate: 0.00338 
2024-12-08 08:47:10.875676: train_loss -0.9921 
2024-12-08 08:47:10.880748: val_loss -0.8778 
2024-12-08 08:47:10.885859: Pseudo dice [np.float32(0.9014)] 
2024-12-08 08:47:10.888397: Epoch time: 32.26 s 
2024-12-08 08:47:11.460972:  
2024-12-08 08:47:11.468669: Epoch 71 
2024-12-08 08:47:11.473254: Current learning rate: 0.00328 
2024-12-08 08:47:43.721230: train_loss -0.9919 
2024-12-08 08:47:43.728842: val_loss -0.8787 
2024-12-08 08:47:43.733918: Pseudo dice [np.float32(0.9027)] 
2024-12-08 08:47:43.737061: Epoch time: 32.26 s 
2024-12-08 08:47:44.311703:  
2024-12-08 08:47:44.317342: Epoch 72 
2024-12-08 08:47:44.319890: Current learning rate: 0.00318 
2024-12-08 08:48:16.574888: train_loss -0.9921 
2024-12-08 08:48:16.579963: val_loss -0.8819 
2024-12-08 08:48:16.587057: Pseudo dice [np.float32(0.9057)] 
2024-12-08 08:48:16.590127: Epoch time: 32.26 s 
2024-12-08 08:48:17.163813:  
2024-12-08 08:48:17.169434: Epoch 73 
2024-12-08 08:48:17.171981: Current learning rate: 0.00308 
2024-12-08 08:48:49.406621: train_loss -0.992 
2024-12-08 08:48:49.414790: val_loss -0.8792 
2024-12-08 08:48:49.419882: Pseudo dice [np.float32(0.903)] 
2024-12-08 08:48:49.424426: Epoch time: 32.24 s 
2024-12-08 08:48:50.139390:  
2024-12-08 08:48:50.145052: Epoch 74 
2024-12-08 08:48:50.147593: Current learning rate: 0.00297 
2024-12-08 08:49:22.403498: train_loss -0.9924 
2024-12-08 08:49:22.409624: val_loss -0.8794 
2024-12-08 08:49:22.412685: Pseudo dice [np.float32(0.9033)] 
2024-12-08 08:49:22.417313: Epoch time: 32.27 s 
2024-12-08 08:49:22.988755:  
2024-12-08 08:49:22.994889: Epoch 75 
2024-12-08 08:49:22.998976: Current learning rate: 0.00287 
2024-12-08 08:49:55.226601: train_loss -0.9921 
2024-12-08 08:49:55.233726: val_loss -0.8786 
2024-12-08 08:49:55.238854: Pseudo dice [np.float32(0.903)] 
2024-12-08 08:49:55.243946: Epoch time: 32.24 s 
2024-12-08 08:49:55.814095:  
2024-12-08 08:49:55.820235: Epoch 76 
2024-12-08 08:49:55.823797: Current learning rate: 0.00277 
2024-12-08 08:50:28.057179: train_loss -0.9926 
2024-12-08 08:50:28.062796: val_loss -0.8821 
2024-12-08 08:50:28.065339: Pseudo dice [np.float32(0.9065)] 
2024-12-08 08:50:28.070423: Epoch time: 32.24 s 
2024-12-08 08:50:28.641915:  
2024-12-08 08:50:28.647003: Epoch 77 
2024-12-08 08:50:28.649546: Current learning rate: 0.00266 
2024-12-08 08:51:00.906934: train_loss -0.992 
2024-12-08 08:51:00.915562: val_loss -0.8787 
2024-12-08 08:51:00.919646: Pseudo dice [np.float32(0.9026)] 
2024-12-08 08:51:00.923212: Epoch time: 32.27 s 
2024-12-08 08:51:01.504233:  
2024-12-08 08:51:01.510838: Epoch 78 
2024-12-08 08:51:01.514449: Current learning rate: 0.00256 
2024-12-08 08:51:33.748087: train_loss -0.9922 
2024-12-08 08:51:33.755724: val_loss -0.8773 
2024-12-08 08:51:33.760803: Pseudo dice [np.float32(0.901)] 
2024-12-08 08:51:33.763361: Epoch time: 32.24 s 
2024-12-08 08:51:34.344336:  
2024-12-08 08:51:34.349955: Epoch 79 
2024-12-08 08:51:34.352526: Current learning rate: 0.00245 
2024-12-08 08:52:06.595761: train_loss -0.9928 
2024-12-08 08:52:06.602276: val_loss -0.8765 
2024-12-08 08:52:06.606790: Pseudo dice [np.float32(0.9005)] 
2024-12-08 08:52:06.609937: Epoch time: 32.25 s 
2024-12-08 08:52:07.193925:  
2024-12-08 08:52:07.199524: Epoch 80 
2024-12-08 08:52:07.204103: Current learning rate: 0.00235 
2024-12-08 08:52:39.455950: train_loss -0.9923 
2024-12-08 08:52:39.461025: val_loss -0.876 
2024-12-08 08:52:39.466113: Pseudo dice [np.float32(0.9004)] 
2024-12-08 08:52:39.470253: Epoch time: 32.26 s 
2024-12-08 08:52:40.203475:  
2024-12-08 08:52:40.211102: Epoch 81 
2024-12-08 08:52:40.215235: Current learning rate: 0.00224 
2024-12-08 08:53:12.466742: train_loss -0.9926 
2024-12-08 08:53:12.473376: val_loss -0.8812 
2024-12-08 08:53:12.475913: Pseudo dice [np.float32(0.9051)] 
2024-12-08 08:53:12.480996: Epoch time: 32.26 s 
2024-12-08 08:53:13.067902:  
2024-12-08 08:53:13.074001: Epoch 82 
2024-12-08 08:53:13.078046: Current learning rate: 0.00214 
2024-12-08 08:53:45.324807: train_loss -0.9923 
2024-12-08 08:53:45.332465: val_loss -0.8766 
2024-12-08 08:53:45.335009: Pseudo dice [np.float32(0.9012)] 
2024-12-08 08:53:45.340088: Epoch time: 32.26 s 
2024-12-08 08:53:45.892457:  
2024-12-08 08:53:45.897617: Epoch 83 
2024-12-08 08:53:45.902706: Current learning rate: 0.00203 
2024-12-08 08:54:18.150555: train_loss -0.9925 
2024-12-08 08:54:18.156140: val_loss -0.8823 
2024-12-08 08:54:18.161304: Pseudo dice [np.float32(0.9054)] 
2024-12-08 08:54:18.163847: Epoch time: 32.26 s 
2024-12-08 08:54:18.725991:  
2024-12-08 08:54:18.731602: Epoch 84 
2024-12-08 08:54:18.736712: Current learning rate: 0.00192 
2024-12-08 08:54:52.899797: train_loss -0.9925 
2024-12-08 08:54:52.907445: val_loss -0.879 
2024-12-08 08:54:52.909994: Pseudo dice [np.float32(0.903)] 
2024-12-08 08:54:52.915077: Epoch time: 34.18 s 
2024-12-08 08:54:53.473669:  
2024-12-08 08:54:53.480288: Epoch 85 
2024-12-08 08:54:53.484433: Current learning rate: 0.00181 
2024-12-08 08:55:25.726420: train_loss -0.993 
2024-12-08 08:55:25.733048: val_loss -0.8806 
2024-12-08 08:55:25.736111: Pseudo dice [np.float32(0.9041)] 
2024-12-08 08:55:25.740661: Epoch time: 32.25 s 
2024-12-08 08:55:26.290085:  
2024-12-08 08:55:26.295194: Epoch 86 
2024-12-08 08:55:26.299263: Current learning rate: 0.0017 
2024-12-08 08:55:58.548379: train_loss -0.9928 
2024-12-08 08:55:58.554494: val_loss -0.8781 
2024-12-08 08:55:58.559068: Pseudo dice [np.float32(0.9026)] 
2024-12-08 08:55:58.562707: Epoch time: 32.26 s 
2024-12-08 08:55:59.109522:  
2024-12-08 08:55:59.115128: Epoch 87 
2024-12-08 08:55:59.118686: Current learning rate: 0.00159 
2024-12-08 08:56:31.369214: train_loss -0.9931 
2024-12-08 08:56:31.375804: val_loss -0.8802 
2024-12-08 08:56:31.380424: Pseudo dice [np.float32(0.9038)] 
2024-12-08 08:56:31.383994: Epoch time: 32.26 s 
2024-12-08 08:56:31.934646:  
2024-12-08 08:56:31.941230: Epoch 88 
2024-12-08 08:56:31.944885: Current learning rate: 0.00148 
2024-12-08 08:57:04.180566: train_loss -0.9926 
2024-12-08 08:57:04.186701: val_loss -0.8802 
2024-12-08 08:57:04.190778: Pseudo dice [np.float32(0.9042)] 
2024-12-08 08:57:04.194346: Epoch time: 32.25 s 
2024-12-08 08:57:04.902791:  
2024-12-08 08:57:04.908895: Epoch 89 
2024-12-08 08:57:04.912971: Current learning rate: 0.00137 
2024-12-08 08:57:37.161258: train_loss -0.9924 
2024-12-08 08:57:37.168890: val_loss -0.8824 
2024-12-08 08:57:37.171433: Pseudo dice [np.float32(0.9053)] 
2024-12-08 08:57:37.176509: Epoch time: 32.26 s 
2024-12-08 08:57:37.728335:  
2024-12-08 08:57:37.735972: Epoch 90 
2024-12-08 08:57:37.739535: Current learning rate: 0.00126 
2024-12-08 08:58:09.989661: train_loss -0.9925 
2024-12-08 08:58:09.994740: val_loss -0.8801 
2024-12-08 08:58:09.999828: Pseudo dice [np.float32(0.9036)] 
2024-12-08 08:58:10.004392: Epoch time: 32.26 s 
2024-12-08 08:58:10.551413:  
2024-12-08 08:58:10.558042: Epoch 91 
2024-12-08 08:58:10.562613: Current learning rate: 0.00115 
2024-12-08 08:58:42.809636: train_loss -0.993 
2024-12-08 08:58:42.816803: val_loss -0.8762 
2024-12-08 08:58:42.821883: Pseudo dice [np.float32(0.9005)] 
2024-12-08 08:58:42.826978: Epoch time: 32.26 s 
2024-12-08 08:58:43.377270:  
2024-12-08 08:58:43.384892: Epoch 92 
2024-12-08 08:58:43.387500: Current learning rate: 0.00103 
2024-12-08 08:59:15.633763: train_loss -0.9933 
2024-12-08 08:59:15.639884: val_loss -0.8821 
2024-12-08 08:59:15.644449: Pseudo dice [np.float32(0.9058)] 
2024-12-08 08:59:15.647015: Epoch time: 32.26 s 
2024-12-08 08:59:16.196644:  
2024-12-08 08:59:16.201731: Epoch 93 
2024-12-08 08:59:16.206293: Current learning rate: 0.00091 
2024-12-08 08:59:48.456567: train_loss -0.9933 
2024-12-08 08:59:48.463209: val_loss -0.8784 
2024-12-08 08:59:48.468297: Pseudo dice [np.float32(0.903)] 
2024-12-08 08:59:48.470841: Epoch time: 32.26 s 
2024-12-08 08:59:49.025221:  
2024-12-08 08:59:49.031849: Epoch 94 
2024-12-08 08:59:49.035421: Current learning rate: 0.00079 
2024-12-08 09:00:21.265797: train_loss -0.9927 
2024-12-08 09:00:21.274988: val_loss -0.8796 
2024-12-08 09:00:21.278561: Pseudo dice [np.float32(0.9037)] 
2024-12-08 09:00:21.282623: Epoch time: 32.24 s 
2024-12-08 09:00:21.832186:  
2024-12-08 09:00:21.838793: Epoch 95 
2024-12-08 09:00:21.842373: Current learning rate: 0.00067 
2024-12-08 09:00:54.089785: train_loss -0.9936 
2024-12-08 09:00:54.097419: val_loss -0.8795 
2024-12-08 09:00:54.099964: Pseudo dice [np.float32(0.9035)] 
2024-12-08 09:00:54.105062: Epoch time: 32.26 s 
2024-12-08 09:00:54.656709:  
2024-12-08 09:00:54.662351: Epoch 96 
2024-12-08 09:00:54.667431: Current learning rate: 0.00055 
2024-12-08 09:01:26.912205: train_loss -0.993 
2024-12-08 09:01:26.919825: val_loss -0.8793 
2024-12-08 09:01:26.924906: Pseudo dice [np.float32(0.9028)] 
2024-12-08 09:01:26.930058: Epoch time: 32.26 s 
2024-12-08 09:01:27.633281:  
2024-12-08 09:01:27.639386: Epoch 97 
2024-12-08 09:01:27.643467: Current learning rate: 0.00043 
2024-12-08 09:01:59.878347: train_loss -0.9929 
2024-12-08 09:01:59.886034: val_loss -0.8789 
2024-12-08 09:01:59.890593: Pseudo dice [np.float32(0.9036)] 
2024-12-08 09:01:59.893654: Epoch time: 32.25 s 
2024-12-08 09:02:00.454964:  
2024-12-08 09:02:00.460556: Epoch 98 
2024-12-08 09:02:00.464665: Current learning rate: 0.0003 
2024-12-08 09:02:32.708002: train_loss -0.9933 
2024-12-08 09:02:32.715616: val_loss -0.8792 
2024-12-08 09:02:32.718202: Pseudo dice [np.float32(0.9034)] 
2024-12-08 09:02:32.723299: Epoch time: 32.25 s 
2024-12-08 09:02:33.280107:  
2024-12-08 09:02:33.285755: Epoch 99 
2024-12-08 09:02:33.289307: Current learning rate: 0.00016 
2024-12-08 09:03:05.528951: train_loss -0.9934 
2024-12-08 09:03:05.534531: val_loss -0.8807 
2024-12-08 09:03:05.537590: Pseudo dice [np.float32(0.9044)] 
2024-12-08 09:03:05.542711: Epoch time: 32.25 s 
2024-12-08 09:03:06.304655: Training done. 
2024-12-08 09:03:06.332320: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-08 09:03:06.340547: The split file contains 5 splits. 
2024-12-08 09:03:06.348558: Desired fold for training: 0 
2024-12-08 09:03:06.348558: This split has 16 training and 4 validation cases. 
2024-12-08 09:03:06.356688: predicting la_007 
2024-12-08 09:03:06.364712: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2024-12-08 09:03:07.028745: predicting la_016 
2024-12-08 09:03:07.036805: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2024-12-08 09:03:07.335320: predicting la_021 
2024-12-08 09:03:07.351359: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2024-12-08 09:03:07.690864: predicting la_024 
2024-12-08 09:03:07.699161: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2024-12-08 09:03:14.892524: Validation complete 
2024-12-08 09:03:14.896563: Mean Validation Dice:  0.8953007155437511 
