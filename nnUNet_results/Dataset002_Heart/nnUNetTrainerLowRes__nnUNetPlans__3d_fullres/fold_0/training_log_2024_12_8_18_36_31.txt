
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-08 18:36:31.394083: do_dummy_2d_data_aug: False 
2024-12-08 18:36:31.394083: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-08 18:36:31.402391: The split file contains 5 splits. 
2024-12-08 18:36:31.402391: Desired fold for training: 0 
2024-12-08 18:36:31.402391: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2024-12-08 18:36:37.669562: unpacking dataset... 
2024-12-08 18:36:37.856078: unpacking done... 
2024-12-08 18:36:40.670886:  
2024-12-08 18:36:40.676059: Epoch 0 
2024-12-08 18:36:40.678699: Current learning rate: 0.01 
2024-12-08 18:37:26.668587: train_loss -0.6842 
2024-12-08 18:37:26.673696: val_loss -0.8947 
2024-12-08 18:37:26.676236: Pseudo dice [np.float32(0.9201)] 
2024-12-08 18:37:26.678776: Epoch time: 46.0 s 
2024-12-08 18:37:26.683856: Yayy! New best EMA pseudo Dice: 0.9200999736785889 
2024-12-08 18:37:27.261033:  
2024-12-08 18:37:27.266115: Epoch 1 
2024-12-08 18:37:27.269172: Current learning rate: 0.00991 
2024-12-08 18:38:09.103215: train_loss -0.9194 
2024-12-08 18:38:09.107771: val_loss -0.9096 
2024-12-08 18:38:09.112912: Pseudo dice [np.float32(0.93)] 
2024-12-08 18:38:09.115453: Epoch time: 41.84 s 
2024-12-08 18:38:09.117995: Yayy! New best EMA pseudo Dice: 0.9211000204086304 
2024-12-08 18:38:09.783000:  
2024-12-08 18:38:09.788127: Epoch 2 
2024-12-08 18:38:09.791182: Current learning rate: 0.00982 
2024-12-08 18:38:51.616393: train_loss -0.9383 
2024-12-08 18:38:51.623025: val_loss -0.9098 
2024-12-08 18:38:51.626090: Pseudo dice [np.float32(0.9303)] 
2024-12-08 18:38:51.629149: Epoch time: 41.83 s 
2024-12-08 18:38:51.631687: Yayy! New best EMA pseudo Dice: 0.921999990940094 
2024-12-08 18:38:52.308536:  
2024-12-08 18:38:52.313603: Epoch 3 
2024-12-08 18:38:52.317173: Current learning rate: 0.00973 
2024-12-08 18:39:34.133448: train_loss -0.9511 
2024-12-08 18:39:34.138560: val_loss -0.9135 
2024-12-08 18:39:34.143130: Pseudo dice [np.float32(0.9328)] 
2024-12-08 18:39:34.146186: Epoch time: 41.83 s 
2024-12-08 18:39:34.148724: Yayy! New best EMA pseudo Dice: 0.9230999946594238 
2024-12-08 18:39:34.819875:  
2024-12-08 18:39:34.825474: Epoch 4 
2024-12-08 18:39:34.828574: Current learning rate: 0.00964 
2024-12-08 18:40:16.646544: train_loss -0.9551 
2024-12-08 18:40:16.651188: val_loss -0.9094 
2024-12-08 18:40:16.653723: Pseudo dice [np.float32(0.9309)] 
2024-12-08 18:40:16.656269: Epoch time: 41.83 s 
2024-12-08 18:40:16.660314: Yayy! New best EMA pseudo Dice: 0.9239000082015991 
2024-12-08 18:40:17.461170:  
2024-12-08 18:40:17.467312: Epoch 5 
2024-12-08 18:40:17.470861: Current learning rate: 0.00955 
2024-12-08 18:40:59.285963: train_loss -0.9551 
2024-12-08 18:40:59.292081: val_loss -0.9114 
2024-12-08 18:40:59.294117: Pseudo dice [np.float32(0.932)] 
2024-12-08 18:40:59.298169: Epoch time: 41.82 s 
2024-12-08 18:40:59.300773: Yayy! New best EMA pseudo Dice: 0.9247000217437744 
2024-12-08 18:40:59.950224:  
2024-12-08 18:40:59.957342: Epoch 6 
2024-12-08 18:40:59.960419: Current learning rate: 0.00946 
2024-12-08 18:41:41.785524: train_loss -0.9615 
2024-12-08 18:41:41.790680: val_loss -0.9088 
2024-12-08 18:41:41.793225: Pseudo dice [np.float32(0.9311)] 
2024-12-08 18:41:41.795767: Epoch time: 41.84 s 
2024-12-08 18:41:41.798306: Yayy! New best EMA pseudo Dice: 0.9253000020980835 
2024-12-08 18:41:42.473682:  
2024-12-08 18:41:42.479312: Epoch 7 
2024-12-08 18:41:42.481851: Current learning rate: 0.00937 
2024-12-08 18:42:24.303665: train_loss -0.965 
2024-12-08 18:42:24.309261: val_loss -0.9078 
2024-12-08 18:42:24.312316: Pseudo dice [np.float32(0.9303)] 
2024-12-08 18:42:24.314859: Epoch time: 41.83 s 
2024-12-08 18:42:24.316916: Yayy! New best EMA pseudo Dice: 0.9258000254631042 
2024-12-08 18:42:24.989407:  
2024-12-08 18:42:24.995003: Epoch 8 
2024-12-08 18:42:24.997540: Current learning rate: 0.00928 
2024-12-08 18:43:06.797668: train_loss -0.9685 
2024-12-08 18:43:06.804357: val_loss -0.9065 
2024-12-08 18:43:06.806906: Pseudo dice [np.float32(0.9298)] 
2024-12-08 18:43:06.809957: Epoch time: 41.81 s 
2024-12-08 18:43:06.813011: Yayy! New best EMA pseudo Dice: 0.9261999726295471 
2024-12-08 18:43:07.487103:  
2024-12-08 18:43:07.492228: Epoch 9 
2024-12-08 18:43:07.494762: Current learning rate: 0.00919 
2024-12-08 18:43:49.314444: train_loss -0.9711 
2024-12-08 18:43:49.322055: val_loss -0.9067 
2024-12-08 18:43:49.324659: Pseudo dice [np.float32(0.9309)] 
2024-12-08 18:43:49.327207: Epoch time: 41.83 s 
2024-12-08 18:43:49.329749: Yayy! New best EMA pseudo Dice: 0.9266999959945679 
2024-12-08 18:43:49.974796:  
2024-12-08 18:43:49.980892: Epoch 10 
2024-12-08 18:43:49.984476: Current learning rate: 0.0091 
2024-12-08 18:44:31.800146: train_loss -0.9709 
2024-12-08 18:44:31.807759: val_loss -0.9082 
2024-12-08 18:44:31.810298: Pseudo dice [np.float32(0.9313)] 
2024-12-08 18:44:31.812830: Epoch time: 41.83 s 
2024-12-08 18:44:31.815433: Yayy! New best EMA pseudo Dice: 0.9272000193595886 
2024-12-08 18:44:32.473842:  
2024-12-08 18:44:32.478962: Epoch 11 
2024-12-08 18:44:32.482516: Current learning rate: 0.009 
2024-12-08 18:45:14.302981: train_loss -0.9701 
2024-12-08 18:45:14.309055: val_loss -0.9093 
2024-12-08 18:45:14.312112: Pseudo dice [np.float32(0.9323)] 
2024-12-08 18:45:14.314650: Epoch time: 41.83 s 
2024-12-08 18:45:14.317269: Yayy! New best EMA pseudo Dice: 0.9276999831199646 
2024-12-08 18:45:14.973438:  
2024-12-08 18:45:14.978511: Epoch 12 
2024-12-08 18:45:14.981047: Current learning rate: 0.00891 
2024-12-08 18:45:56.801557: train_loss -0.9739 
2024-12-08 18:45:56.807645: val_loss -0.9063 
2024-12-08 18:45:56.810177: Pseudo dice [np.float32(0.9312)] 
2024-12-08 18:45:56.814252: Epoch time: 41.83 s 
2024-12-08 18:45:56.817806: Yayy! New best EMA pseudo Dice: 0.9279999732971191 
2024-12-08 18:45:57.628243:  
2024-12-08 18:45:57.633815: Epoch 13 
2024-12-08 18:45:57.636353: Current learning rate: 0.00882 
2024-12-08 18:46:39.448568: train_loss -0.9755 
2024-12-08 18:46:39.456210: val_loss -0.9058 
2024-12-08 18:46:39.458746: Pseudo dice [np.float32(0.9312)] 
2024-12-08 18:46:39.461286: Epoch time: 41.82 s 
2024-12-08 18:46:39.463817: Yayy! New best EMA pseudo Dice: 0.9283000230789185 
2024-12-08 18:46:40.133541:  
2024-12-08 18:46:40.139146: Epoch 14 
2024-12-08 18:46:40.142227: Current learning rate: 0.00873 
2024-12-08 18:47:21.978639: train_loss -0.9767 
2024-12-08 18:47:21.983737: val_loss -0.9082 
2024-12-08 18:47:21.988311: Pseudo dice [np.float32(0.9333)] 
2024-12-08 18:47:21.991429: Epoch time: 41.85 s 
2024-12-08 18:47:21.993979: Yayy! New best EMA pseudo Dice: 0.9287999868392944 
2024-12-08 18:47:22.669870:  
2024-12-08 18:47:22.675974: Epoch 15 
2024-12-08 18:47:22.680574: Current learning rate: 0.00864 
2024-12-08 18:48:04.486129: train_loss -0.9761 
2024-12-08 18:48:04.491253: val_loss -0.9084 
2024-12-08 18:48:04.495799: Pseudo dice [np.float32(0.9334)] 
2024-12-08 18:48:04.498861: Epoch time: 41.82 s 
2024-12-08 18:48:04.501394: Yayy! New best EMA pseudo Dice: 0.9293000102043152 
2024-12-08 18:48:05.174427:  
2024-12-08 18:48:05.181055: Epoch 16 
2024-12-08 18:48:05.183587: Current learning rate: 0.00855 
2024-12-08 18:48:46.989119: train_loss -0.9766 
2024-12-08 18:48:46.996228: val_loss -0.9064 
2024-12-08 18:48:46.998766: Pseudo dice [np.float32(0.9325)] 
2024-12-08 18:48:47.001322: Epoch time: 41.81 s 
2024-12-08 18:48:47.003858: Yayy! New best EMA pseudo Dice: 0.9296000003814697 
2024-12-08 18:48:47.690290:  
2024-12-08 18:48:47.695880: Epoch 17 
2024-12-08 18:48:47.698421: Current learning rate: 0.00846 
2024-12-08 18:49:29.545973: train_loss -0.9781 
2024-12-08 18:49:29.553572: val_loss -0.9047 
2024-12-08 18:49:29.556138: Pseudo dice [np.float32(0.9316)] 
2024-12-08 18:49:29.558683: Epoch time: 41.86 s 
2024-12-08 18:49:29.561217: Yayy! New best EMA pseudo Dice: 0.9297999739646912 
2024-12-08 18:49:30.248321:  
2024-12-08 18:49:30.254946: Epoch 18 
2024-12-08 18:49:30.257490: Current learning rate: 0.00836 
2024-12-08 18:50:12.070976: train_loss -0.9786 
2024-12-08 18:50:12.076049: val_loss -0.9074 
2024-12-08 18:50:12.078585: Pseudo dice [np.float32(0.9336)] 
2024-12-08 18:50:12.081163: Epoch time: 41.82 s 
2024-12-08 18:50:12.083694: Yayy! New best EMA pseudo Dice: 0.9301999807357788 
2024-12-08 18:50:12.760367:  
2024-12-08 18:50:12.767516: Epoch 19 
2024-12-08 18:50:12.770582: Current learning rate: 0.00827 
2024-12-08 18:50:54.587004: train_loss -0.9782 
2024-12-08 18:50:54.594628: val_loss -0.9056 
2024-12-08 18:50:54.597163: Pseudo dice [np.float32(0.9326)] 
2024-12-08 18:50:54.599700: Epoch time: 41.83 s 
2024-12-08 18:50:54.602296: Yayy! New best EMA pseudo Dice: 0.930400013923645 
2024-12-08 18:50:55.280948:  
2024-12-08 18:50:55.286030: Epoch 20 
2024-12-08 18:50:55.288569: Current learning rate: 0.00818 
2024-12-08 18:51:37.103632: train_loss -0.9796 
2024-12-08 18:51:37.110266: val_loss -0.9064 
2024-12-08 18:51:37.113327: Pseudo dice [np.float32(0.9326)] 
2024-12-08 18:51:37.115350: Epoch time: 41.82 s 
2024-12-08 18:51:37.117882: Yayy! New best EMA pseudo Dice: 0.9307000041007996 
2024-12-08 18:51:37.946138:  
2024-12-08 18:51:37.952785: Epoch 21 
2024-12-08 18:51:37.956351: Current learning rate: 0.00809 
2024-12-08 18:52:19.789210: train_loss -0.981 
2024-12-08 18:52:19.794296: val_loss -0.906 
2024-12-08 18:52:19.797339: Pseudo dice [np.float32(0.9333)] 
2024-12-08 18:52:19.800426: Epoch time: 41.84 s 
2024-12-08 18:52:19.802963: Yayy! New best EMA pseudo Dice: 0.930899977684021 
2024-12-08 18:52:20.459876:  
2024-12-08 18:52:20.465017: Epoch 22 
2024-12-08 18:52:20.468577: Current learning rate: 0.008 
2024-12-08 18:53:02.291460: train_loss -0.9795 
2024-12-08 18:53:02.297563: val_loss -0.9083 
2024-12-08 18:53:02.300097: Pseudo dice [np.float32(0.9348)] 
2024-12-08 18:53:02.302686: Epoch time: 41.83 s 
2024-12-08 18:53:02.307248: Yayy! New best EMA pseudo Dice: 0.9312999844551086 
2024-12-08 18:53:02.972430:  
2024-12-08 18:53:02.978024: Epoch 23 
2024-12-08 18:53:02.980567: Current learning rate: 0.0079 
2024-12-08 18:53:44.794789: train_loss -0.9807 
2024-12-08 18:53:44.801895: val_loss -0.907 
2024-12-08 18:53:44.804490: Pseudo dice [np.float32(0.934)] 
2024-12-08 18:53:44.808056: Epoch time: 41.82 s 
2024-12-08 18:53:44.810593: Yayy! New best EMA pseudo Dice: 0.9315999746322632 
2024-12-08 18:53:45.467128:  
2024-12-08 18:53:45.473220: Epoch 24 
2024-12-08 18:53:45.475756: Current learning rate: 0.00781 
2024-12-08 18:54:27.303992: train_loss -0.9801 
2024-12-08 18:54:27.309070: val_loss -0.9056 
2024-12-08 18:54:27.312632: Pseudo dice [np.float32(0.9335)] 
2024-12-08 18:54:27.315205: Epoch time: 41.84 s 
2024-12-08 18:54:27.318249: Yayy! New best EMA pseudo Dice: 0.9318000078201294 
2024-12-08 18:54:27.977940:  
2024-12-08 18:54:27.983007: Epoch 25 
2024-12-08 18:54:27.986604: Current learning rate: 0.00772 
2024-12-08 18:55:09.810421: train_loss -0.9808 
2024-12-08 18:55:09.815497: val_loss -0.9058 
2024-12-08 18:55:09.818028: Pseudo dice [np.float32(0.9338)] 
2024-12-08 18:55:09.820588: Epoch time: 41.83 s 
2024-12-08 18:55:09.825661: Yayy! New best EMA pseudo Dice: 0.9319999814033508 
2024-12-08 18:55:10.486022:  
2024-12-08 18:55:10.492116: Epoch 26 
2024-12-08 18:55:10.495227: Current learning rate: 0.00763 
2024-12-08 18:55:52.306670: train_loss -0.982 
2024-12-08 18:55:52.312766: val_loss -0.904 
2024-12-08 18:55:52.315298: Pseudo dice [np.float32(0.9332)] 
2024-12-08 18:55:52.317828: Epoch time: 41.82 s 
2024-12-08 18:55:52.321902: Yayy! New best EMA pseudo Dice: 0.9320999979972839 
2024-12-08 18:55:52.978615:  
2024-12-08 18:55:52.983685: Epoch 27 
2024-12-08 18:55:52.986223: Current learning rate: 0.00753 
2024-12-08 18:56:34.807894: train_loss -0.9827 
2024-12-08 18:56:34.814021: val_loss -0.9052 
2024-12-08 18:56:34.816567: Pseudo dice [np.float32(0.9342)] 
2024-12-08 18:56:34.820124: Epoch time: 41.83 s 
2024-12-08 18:56:34.823175: Yayy! New best EMA pseudo Dice: 0.9322999715805054 
2024-12-08 18:56:35.484804:  
2024-12-08 18:56:35.491446: Epoch 28 
2024-12-08 18:56:35.494491: Current learning rate: 0.00744 
2024-12-08 18:57:17.331113: train_loss -0.981 
2024-12-08 18:57:17.338217: val_loss -0.906 
2024-12-08 18:57:17.341339: Pseudo dice [np.float32(0.9341)] 
2024-12-08 18:57:17.343879: Epoch time: 41.85 s 
2024-12-08 18:57:17.347459: Yayy! New best EMA pseudo Dice: 0.9325000047683716 
2024-12-08 18:57:18.142366:  
2024-12-08 18:57:18.147443: Epoch 29 
2024-12-08 18:57:18.150996: Current learning rate: 0.00735 
2024-12-08 18:57:59.977586: train_loss -0.9815 
2024-12-08 18:57:59.982687: val_loss -0.903 
2024-12-08 18:57:59.986766: Pseudo dice [np.float32(0.9324)] 
2024-12-08 18:57:59.989817: Epoch time: 41.84 s 
2024-12-08 18:58:00.507801:  
2024-12-08 18:58:00.512883: Epoch 30 
2024-12-08 18:58:00.515937: Current learning rate: 0.00725 
2024-12-08 18:58:42.342210: train_loss -0.9826 
2024-12-08 18:58:42.349343: val_loss -0.9052 
2024-12-08 18:58:42.351879: Pseudo dice [np.float32(0.9341)] 
2024-12-08 18:58:42.354416: Epoch time: 41.83 s 
2024-12-08 18:58:42.358974: Yayy! New best EMA pseudo Dice: 0.9326000213623047 
2024-12-08 18:58:43.024069:  
2024-12-08 18:58:43.029151: Epoch 31 
2024-12-08 18:58:43.032212: Current learning rate: 0.00716 
2024-12-08 18:59:24.856364: train_loss -0.9826 
2024-12-08 18:59:24.861965: val_loss -0.9051 
2024-12-08 18:59:24.864501: Pseudo dice [np.float32(0.9341)] 
2024-12-08 18:59:24.867032: Epoch time: 41.83 s 
2024-12-08 18:59:24.869609: Yayy! New best EMA pseudo Dice: 0.9327999949455261 
2024-12-08 18:59:25.538246:  
2024-12-08 18:59:25.543374: Epoch 32 
2024-12-08 18:59:25.545923: Current learning rate: 0.00707 
2024-12-08 19:00:07.364651: train_loss -0.9821 
2024-12-08 19:00:07.370258: val_loss -0.9038 
2024-12-08 19:00:07.372792: Pseudo dice [np.float32(0.9328)] 
2024-12-08 19:00:07.375323: Epoch time: 41.83 s 
2024-12-08 19:00:07.888171:  
2024-12-08 19:00:07.894766: Epoch 33 
2024-12-08 19:00:07.897824: Current learning rate: 0.00697 
2024-12-08 19:00:49.717590: train_loss -0.9825 
2024-12-08 19:00:49.725277: val_loss -0.9058 
2024-12-08 19:00:49.727818: Pseudo dice [np.float32(0.9346)] 
2024-12-08 19:00:49.730357: Epoch time: 41.83 s 
2024-12-08 19:00:49.732892: Yayy! New best EMA pseudo Dice: 0.9330000281333923 
2024-12-08 19:00:50.401116:  
2024-12-08 19:00:50.407206: Epoch 34 
2024-12-08 19:00:50.410322: Current learning rate: 0.00688 
2024-12-08 19:01:32.214155: train_loss -0.9829 
2024-12-08 19:01:32.219754: val_loss -0.9057 
2024-12-08 19:01:32.222296: Pseudo dice [np.float32(0.9349)] 
2024-12-08 19:01:32.224836: Epoch time: 41.81 s 
2024-12-08 19:01:32.227441: Yayy! New best EMA pseudo Dice: 0.9332000017166138 
2024-12-08 19:01:33.015337:  
2024-12-08 19:01:33.021021: Epoch 35 
2024-12-08 19:01:33.024079: Current learning rate: 0.00679 
2024-12-08 19:02:14.845280: train_loss -0.9828 
2024-12-08 19:02:14.852896: val_loss -0.9052 
2024-12-08 19:02:14.855431: Pseudo dice [np.float32(0.9344)] 
2024-12-08 19:02:14.857967: Epoch time: 41.83 s 
2024-12-08 19:02:14.862572: Yayy! New best EMA pseudo Dice: 0.9333000183105469 
2024-12-08 19:02:15.542382:  
2024-12-08 19:02:15.547976: Epoch 36 
2024-12-08 19:02:15.550545: Current learning rate: 0.00669 
2024-12-08 19:02:57.366911: train_loss -0.9834 
2024-12-08 19:02:57.374531: val_loss -0.9056 
2024-12-08 19:02:57.377093: Pseudo dice [np.float32(0.9354)] 
2024-12-08 19:02:57.379639: Epoch time: 41.82 s 
2024-12-08 19:02:57.384198: Yayy! New best EMA pseudo Dice: 0.9334999918937683 
2024-12-08 19:02:58.233436:  
2024-12-08 19:02:58.238556: Epoch 37 
2024-12-08 19:02:58.241611: Current learning rate: 0.0066 
2024-12-08 19:03:40.078074: train_loss -0.9841 
2024-12-08 19:03:40.085711: val_loss -0.9047 
2024-12-08 19:03:40.088247: Pseudo dice [np.float32(0.935)] 
2024-12-08 19:03:40.090788: Epoch time: 41.85 s 
2024-12-08 19:03:40.093322: Yayy! New best EMA pseudo Dice: 0.9336000084877014 
2024-12-08 19:03:40.771014:  
2024-12-08 19:03:40.776145: Epoch 38 
2024-12-08 19:03:40.778686: Current learning rate: 0.0065 
2024-12-08 19:04:22.604991: train_loss -0.9837 
2024-12-08 19:04:22.610075: val_loss -0.9048 
2024-12-08 19:04:22.612659: Pseudo dice [np.float32(0.9351)] 
2024-12-08 19:04:22.615204: Epoch time: 41.83 s 
2024-12-08 19:04:22.619753: Yayy! New best EMA pseudo Dice: 0.9337999820709229 
2024-12-08 19:04:23.306835:  
2024-12-08 19:04:23.311941: Epoch 39 
2024-12-08 19:04:23.315001: Current learning rate: 0.00641 
2024-12-08 19:05:05.141217: train_loss -0.9846 
2024-12-08 19:05:05.146864: val_loss -0.9057 
2024-12-08 19:05:05.149399: Pseudo dice [np.float32(0.9357)] 
2024-12-08 19:05:05.151935: Epoch time: 41.83 s 
2024-12-08 19:05:05.156488: Yayy! New best EMA pseudo Dice: 0.9340000152587891 
2024-12-08 19:05:05.845272:  
2024-12-08 19:05:05.850340: Epoch 40 
2024-12-08 19:05:05.853884: Current learning rate: 0.00631 
2024-12-08 19:05:47.666305: train_loss -0.9831 
2024-12-08 19:05:47.672427: val_loss -0.9058 
2024-12-08 19:05:47.674962: Pseudo dice [np.float32(0.935)] 
2024-12-08 19:05:47.679012: Epoch time: 41.82 s 
2024-12-08 19:05:47.682568: Yayy! New best EMA pseudo Dice: 0.9340999722480774 
2024-12-08 19:05:48.369498:  
2024-12-08 19:05:48.375585: Epoch 41 
2024-12-08 19:05:48.378194: Current learning rate: 0.00622 
2024-12-08 19:06:30.189089: train_loss -0.9845 
2024-12-08 19:06:30.196702: val_loss -0.9036 
2024-12-08 19:06:30.199238: Pseudo dice [np.float32(0.935)] 
2024-12-08 19:06:30.201866: Epoch time: 41.82 s 
2024-12-08 19:06:30.204402: Yayy! New best EMA pseudo Dice: 0.9341999888420105 
2024-12-08 19:06:30.861372:  
2024-12-08 19:06:30.866437: Epoch 42 
2024-12-08 19:06:30.868968: Current learning rate: 0.00612 
2024-12-08 19:07:12.700274: train_loss -0.984 
2024-12-08 19:07:12.706872: val_loss -0.9049 
2024-12-08 19:07:12.709457: Pseudo dice [np.float32(0.935)] 
2024-12-08 19:07:12.713010: Epoch time: 41.84 s 
2024-12-08 19:07:12.715544: Yayy! New best EMA pseudo Dice: 0.9343000054359436 
2024-12-08 19:07:13.367817:  
2024-12-08 19:07:13.374928: Epoch 43 
2024-12-08 19:07:13.377985: Current learning rate: 0.00603 
2024-12-08 19:07:55.207787: train_loss -0.9851 
2024-12-08 19:07:55.215408: val_loss -0.9059 
2024-12-08 19:07:55.217949: Pseudo dice [np.float32(0.9363)] 
2024-12-08 19:07:55.220521: Epoch time: 41.84 s 
2024-12-08 19:07:55.223056: Yayy! New best EMA pseudo Dice: 0.934499979019165 
2024-12-08 19:07:55.880516:  
2024-12-08 19:07:55.886116: Epoch 44 
2024-12-08 19:07:55.888655: Current learning rate: 0.00593 
2024-12-08 19:08:37.704147: train_loss -0.9845 
2024-12-08 19:08:37.711761: val_loss -0.9025 
2024-12-08 19:08:37.716316: Pseudo dice [np.float32(0.9332)] 
2024-12-08 19:08:37.719435: Epoch time: 41.82 s 
2024-12-08 19:08:38.373092:  
2024-12-08 19:08:38.379190: Epoch 45 
2024-12-08 19:08:38.381727: Current learning rate: 0.00584 
2024-12-08 19:09:20.210257: train_loss -0.984 
2024-12-08 19:09:20.215327: val_loss -0.905 
2024-12-08 19:09:20.217866: Pseudo dice [np.float32(0.935)] 
2024-12-08 19:09:20.221917: Epoch time: 41.84 s 
2024-12-08 19:09:20.717173:  
2024-12-08 19:09:20.722343: Epoch 46 
2024-12-08 19:09:20.724880: Current learning rate: 0.00574 
2024-12-08 19:10:02.537219: train_loss -0.9841 
2024-12-08 19:10:02.542893: val_loss -0.9044 
2024-12-08 19:10:02.549998: Pseudo dice [np.float32(0.935)] 
2024-12-08 19:10:02.553067: Epoch time: 41.82 s 
2024-12-08 19:10:02.555601: Yayy! New best EMA pseudo Dice: 0.934499979019165 
2024-12-08 19:10:03.214195:  
2024-12-08 19:10:03.219820: Epoch 47 
2024-12-08 19:10:03.223442: Current learning rate: 0.00565 
2024-12-08 19:10:45.040329: train_loss -0.9858 
2024-12-08 19:10:45.045928: val_loss -0.9027 
2024-12-08 19:10:45.050489: Pseudo dice [np.float32(0.934)] 
2024-12-08 19:10:45.053592: Epoch time: 41.83 s 
2024-12-08 19:10:45.551719:  
2024-12-08 19:10:45.557353: Epoch 48 
2024-12-08 19:10:45.560899: Current learning rate: 0.00555 
2024-12-08 19:11:27.387732: train_loss -0.9861 
2024-12-08 19:11:27.392852: val_loss -0.9036 
2024-12-08 19:11:27.395394: Pseudo dice [np.float32(0.9348)] 
2024-12-08 19:11:27.399957: Epoch time: 41.84 s 
2024-12-08 19:11:27.902222:  
2024-12-08 19:11:27.907287: Epoch 49 
2024-12-08 19:11:27.909820: Current learning rate: 0.00546 
2024-12-08 19:12:09.728763: train_loss -0.9867 
2024-12-08 19:12:09.734907: val_loss -0.9019 
2024-12-08 19:12:09.737440: Pseudo dice [np.float32(0.9342)] 
2024-12-08 19:12:09.741484: Epoch time: 41.83 s 
2024-12-08 19:12:10.383913:  
2024-12-08 19:12:10.389029: Epoch 50 
2024-12-08 19:12:10.392092: Current learning rate: 0.00536 
2024-12-08 19:12:52.202982: train_loss -0.986 
2024-12-08 19:12:52.210598: val_loss -0.9036 
2024-12-08 19:12:52.213135: Pseudo dice [np.float32(0.9351)] 
2024-12-08 19:12:52.215747: Epoch time: 41.82 s 
2024-12-08 19:12:52.218289: Yayy! New best EMA pseudo Dice: 0.934499979019165 
2024-12-08 19:12:52.946252:  
2024-12-08 19:12:52.951873: Epoch 51 
2024-12-08 19:12:52.954414: Current learning rate: 0.00526 
2024-12-08 19:13:34.766786: train_loss -0.9853 
2024-12-08 19:13:34.771385: val_loss -0.9032 
2024-12-08 19:13:34.774951: Pseudo dice [np.float32(0.9347)] 
2024-12-08 19:13:34.776989: Epoch time: 41.82 s 
2024-12-08 19:13:34.779009: Yayy! New best EMA pseudo Dice: 0.934499979019165 
2024-12-08 19:13:35.444374:  
2024-12-08 19:13:35.449969: Epoch 52 
2024-12-08 19:13:35.452510: Current learning rate: 0.00517 
2024-12-08 19:14:17.269194: train_loss -0.9849 
2024-12-08 19:14:17.274832: val_loss -0.9027 
2024-12-08 19:14:17.276854: Pseudo dice [np.float32(0.9343)] 
2024-12-08 19:14:17.281418: Epoch time: 41.82 s 
2024-12-08 19:14:17.931328:  
2024-12-08 19:14:17.937449: Epoch 53 
2024-12-08 19:14:17.940499: Current learning rate: 0.00507 
2024-12-08 19:14:59.769525: train_loss -0.9853 
2024-12-08 19:14:59.777650: val_loss -0.9041 
2024-12-08 19:14:59.780738: Pseudo dice [np.float32(0.9356)] 
2024-12-08 19:14:59.783797: Epoch time: 41.84 s 
2024-12-08 19:14:59.786336: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2024-12-08 19:15:00.449478:  
2024-12-08 19:15:00.454665: Epoch 54 
2024-12-08 19:15:00.457258: Current learning rate: 0.00497 
2024-12-08 19:15:42.276648: train_loss -0.9863 
2024-12-08 19:15:42.281725: val_loss -0.9052 
2024-12-08 19:15:42.286291: Pseudo dice [np.float32(0.936)] 
2024-12-08 19:15:42.289354: Epoch time: 41.83 s 
2024-12-08 19:15:42.291931: Yayy! New best EMA pseudo Dice: 0.9347000122070312 
2024-12-08 19:15:42.956240:  
2024-12-08 19:15:42.961878: Epoch 55 
2024-12-08 19:15:42.964414: Current learning rate: 0.00487 
2024-12-08 19:16:24.780792: train_loss -0.9854 
2024-12-08 19:16:24.785861: val_loss -0.9033 
2024-12-08 19:16:24.788392: Pseudo dice [np.float32(0.9358)] 
2024-12-08 19:16:24.790924: Epoch time: 41.82 s 
2024-12-08 19:16:24.795008: Yayy! New best EMA pseudo Dice: 0.9348000288009644 
2024-12-08 19:16:25.454972:  
2024-12-08 19:16:25.460056: Epoch 56 
2024-12-08 19:16:25.463125: Current learning rate: 0.00478 
2024-12-08 19:17:07.280248: train_loss -0.9851 
2024-12-08 19:17:07.286360: val_loss -0.9014 
2024-12-08 19:17:07.288898: Pseudo dice [np.float32(0.9339)] 
2024-12-08 19:17:07.291976: Epoch time: 41.83 s 
2024-12-08 19:17:07.801847:  
2024-12-08 19:17:07.806412: Epoch 57 
2024-12-08 19:17:07.812104: Current learning rate: 0.00468 
2024-12-08 19:17:49.623565: train_loss -0.9857 
2024-12-08 19:17:49.631191: val_loss -0.9026 
2024-12-08 19:17:49.633727: Pseudo dice [np.float32(0.9348)] 
2024-12-08 19:17:49.636259: Epoch time: 41.82 s 
2024-12-08 19:17:50.157456:  
2024-12-08 19:17:50.162551: Epoch 58 
2024-12-08 19:17:50.165102: Current learning rate: 0.00458 
2024-12-08 19:18:31.984951: train_loss -0.9862 
2024-12-08 19:18:31.990026: val_loss -0.9038 
2024-12-08 19:18:31.995121: Pseudo dice [np.float32(0.9357)] 
2024-12-08 19:18:31.997667: Epoch time: 41.83 s 
2024-12-08 19:18:32.000199: Yayy! New best EMA pseudo Dice: 0.9348000288009644 
2024-12-08 19:18:32.664682:  
2024-12-08 19:18:32.670317: Epoch 59 
2024-12-08 19:18:32.672860: Current learning rate: 0.00448 
2024-12-08 19:19:14.500479: train_loss -0.9873 
2024-12-08 19:19:14.507597: val_loss -0.9008 
2024-12-08 19:19:14.510139: Pseudo dice [np.float32(0.935)] 
2024-12-08 19:19:14.512674: Epoch time: 41.84 s 
2024-12-08 19:19:14.515216: Yayy! New best EMA pseudo Dice: 0.9348000288009644 
2024-12-08 19:19:15.187848:  
2024-12-08 19:19:15.192910: Epoch 60 
2024-12-08 19:19:15.195440: Current learning rate: 0.00438 
2024-12-08 19:19:57.017210: train_loss -0.9854 
2024-12-08 19:19:57.023788: val_loss -0.9044 
2024-12-08 19:19:57.027374: Pseudo dice [np.float32(0.9357)] 
2024-12-08 19:19:57.029906: Epoch time: 41.83 s 
2024-12-08 19:19:57.032438: Yayy! New best EMA pseudo Dice: 0.9348999857902527 
2024-12-08 19:19:57.839070:  
2024-12-08 19:19:57.844648: Epoch 61 
2024-12-08 19:19:57.847729: Current learning rate: 0.00429 
2024-12-08 19:20:40.025890: train_loss -0.9871 
2024-12-08 19:20:40.030964: val_loss -0.9032 
2024-12-08 19:20:40.033498: Pseudo dice [np.float32(0.9357)] 
2024-12-08 19:20:40.038132: Epoch time: 42.19 s 
2024-12-08 19:20:40.041194: Yayy! New best EMA pseudo Dice: 0.9350000023841858 
2024-12-08 19:20:40.711194:  
2024-12-08 19:20:40.718314: Epoch 62 
2024-12-08 19:20:40.721371: Current learning rate: 0.00419 
2024-12-08 19:21:22.537915: train_loss -0.9863 
2024-12-08 19:21:22.544041: val_loss -0.903 
2024-12-08 19:21:22.547606: Pseudo dice [np.float32(0.9353)] 
2024-12-08 19:21:22.550146: Epoch time: 41.83 s 
2024-12-08 19:21:22.552682: Yayy! New best EMA pseudo Dice: 0.9350000023841858 
2024-12-08 19:21:23.227700:  
2024-12-08 19:21:23.233289: Epoch 63 
2024-12-08 19:21:23.235825: Current learning rate: 0.00409 
2024-12-08 19:22:05.053166: train_loss -0.9882 
2024-12-08 19:22:05.059798: val_loss -0.9012 
2024-12-08 19:22:05.062916: Pseudo dice [np.float32(0.9356)] 
2024-12-08 19:22:05.064952: Epoch time: 41.83 s 
2024-12-08 19:22:05.069004: Yayy! New best EMA pseudo Dice: 0.9351000189781189 
2024-12-08 19:22:05.752492:  
2024-12-08 19:22:05.759610: Epoch 64 
2024-12-08 19:22:05.762669: Current learning rate: 0.00399 
2024-12-08 19:22:47.588154: train_loss -0.9868 
2024-12-08 19:22:47.595766: val_loss -0.9007 
2024-12-08 19:22:47.598300: Pseudo dice [np.float32(0.9343)] 
2024-12-08 19:22:47.603436: Epoch time: 41.84 s 
2024-12-08 19:22:48.115330:  
2024-12-08 19:22:48.120408: Epoch 65 
2024-12-08 19:22:48.122975: Current learning rate: 0.00389 
2024-12-08 19:23:29.962030: train_loss -0.9871 
2024-12-08 19:23:29.967153: val_loss -0.9032 
2024-12-08 19:23:29.971710: Pseudo dice [np.float32(0.9359)] 
2024-12-08 19:23:29.974767: Epoch time: 41.85 s 
2024-12-08 19:23:29.977304: Yayy! New best EMA pseudo Dice: 0.9351000189781189 
2024-12-08 19:23:30.645505:  
2024-12-08 19:23:30.652617: Epoch 66 
2024-12-08 19:23:30.655697: Current learning rate: 0.00379 
2024-12-08 19:24:12.468673: train_loss -0.987 
2024-12-08 19:24:12.473782: val_loss -0.9027 
2024-12-08 19:24:12.478866: Pseudo dice [np.float32(0.9355)] 
2024-12-08 19:24:12.481410: Epoch time: 41.82 s 
2024-12-08 19:24:12.483951: Yayy! New best EMA pseudo Dice: 0.9351999759674072 
2024-12-08 19:24:13.203290:  
2024-12-08 19:24:13.208898: Epoch 67 
2024-12-08 19:24:13.212937: Current learning rate: 0.00369 
2024-12-08 19:24:55.027671: train_loss -0.9878 
2024-12-08 19:24:55.035311: val_loss -0.9003 
2024-12-08 19:24:55.038859: Pseudo dice [np.float32(0.9345)] 
2024-12-08 19:24:55.041398: Epoch time: 41.82 s 
2024-12-08 19:24:55.566491:  
2024-12-08 19:24:55.571564: Epoch 68 
2024-12-08 19:24:55.574101: Current learning rate: 0.00359 
2024-12-08 19:25:37.398957: train_loss -0.9873 
2024-12-08 19:25:37.404060: val_loss -0.8999 
2024-12-08 19:25:37.408108: Pseudo dice [np.float32(0.9344)] 
2024-12-08 19:25:37.411660: Epoch time: 41.83 s 
2024-12-08 19:25:38.087596:  
2024-12-08 19:25:38.093240: Epoch 69 
2024-12-08 19:25:38.095780: Current learning rate: 0.00349 
2024-12-08 19:26:19.925554: train_loss -0.9877 
2024-12-08 19:26:19.931710: val_loss -0.9002 
2024-12-08 19:26:19.936785: Pseudo dice [np.float32(0.9345)] 
2024-12-08 19:26:19.939326: Epoch time: 41.84 s 
2024-12-08 19:26:20.459527:  
2024-12-08 19:26:20.464644: Epoch 70 
2024-12-08 19:26:20.468696: Current learning rate: 0.00338 
2024-12-08 19:27:02.285310: train_loss -0.9866 
2024-12-08 19:27:02.291397: val_loss -0.9004 
2024-12-08 19:27:02.294498: Pseudo dice [np.float32(0.9343)] 
2024-12-08 19:27:02.299056: Epoch time: 41.83 s 
2024-12-08 19:27:02.821849:  
2024-12-08 19:27:02.826928: Epoch 71 
2024-12-08 19:27:02.831518: Current learning rate: 0.00328 
2024-12-08 19:27:44.641477: train_loss -0.9876 
2024-12-08 19:27:44.649084: val_loss -0.9006 
2024-12-08 19:27:44.653666: Pseudo dice [np.float32(0.9343)] 
2024-12-08 19:27:44.656718: Epoch time: 41.82 s 
2024-12-08 19:27:45.185066:  
2024-12-08 19:27:45.190165: Epoch 72 
2024-12-08 19:27:45.194721: Current learning rate: 0.00318 
2024-12-08 19:28:27.017917: train_loss -0.987 
2024-12-08 19:28:27.022990: val_loss -0.8982 
2024-12-08 19:28:27.027102: Pseudo dice [np.float32(0.9337)] 
2024-12-08 19:28:27.030654: Epoch time: 41.83 s 
2024-12-08 19:28:27.552183:  
2024-12-08 19:28:27.557776: Epoch 73 
2024-12-08 19:28:27.560314: Current learning rate: 0.00308 
2024-12-08 19:29:09.389640: train_loss -0.9873 
2024-12-08 19:29:09.396734: val_loss -0.9007 
2024-12-08 19:29:09.399273: Pseudo dice [np.float32(0.9347)] 
2024-12-08 19:29:09.401855: Epoch time: 41.84 s 
2024-12-08 19:29:09.926383:  
2024-12-08 19:29:09.931489: Epoch 74 
2024-12-08 19:29:09.936570: Current learning rate: 0.00297 
2024-12-08 19:29:51.748463: train_loss -0.9867 
2024-12-08 19:29:51.755612: val_loss -0.9001 
2024-12-08 19:29:51.760686: Pseudo dice [np.float32(0.9345)] 
2024-12-08 19:29:51.765247: Epoch time: 41.82 s 
2024-12-08 19:29:52.287311:  
2024-12-08 19:29:52.292375: Epoch 75 
2024-12-08 19:29:52.295930: Current learning rate: 0.00287 
2024-12-08 19:30:34.117741: train_loss -0.9873 
2024-12-08 19:30:34.122813: val_loss -0.901 
2024-12-08 19:30:34.126865: Pseudo dice [np.float32(0.9354)] 
2024-12-08 19:30:34.130469: Epoch time: 41.83 s 
2024-12-08 19:30:34.652339:  
2024-12-08 19:30:34.658946: Epoch 76 
2024-12-08 19:30:34.662540: Current learning rate: 0.00277 
2024-12-08 19:31:16.518518: train_loss -0.9871 
2024-12-08 19:31:16.526158: val_loss -0.8994 
2024-12-08 19:31:16.528700: Pseudo dice [np.float32(0.9336)] 
2024-12-08 19:31:16.533776: Epoch time: 41.87 s 
2024-12-08 19:31:17.216929:  
2024-12-08 19:31:17.223049: Epoch 77 
2024-12-08 19:31:17.226595: Current learning rate: 0.00266 
2024-12-08 19:31:59.037283: train_loss -0.9876 
2024-12-08 19:31:59.044383: val_loss -0.8985 
2024-12-08 19:31:59.048453: Pseudo dice [np.float32(0.934)] 
2024-12-08 19:31:59.052037: Epoch time: 41.82 s 
2024-12-08 19:31:59.607931:  
2024-12-08 19:31:59.613535: Epoch 78 
2024-12-08 19:31:59.616118: Current learning rate: 0.00256 
2024-12-08 19:32:41.437326: train_loss -0.9874 
2024-12-08 19:32:41.442922: val_loss -0.8992 
2024-12-08 19:32:41.447993: Pseudo dice [np.float32(0.9347)] 
2024-12-08 19:32:41.450570: Epoch time: 41.83 s 
2024-12-08 19:32:41.990012:  
2024-12-08 19:32:41.996606: Epoch 79 
2024-12-08 19:32:42.000165: Current learning rate: 0.00245 
2024-12-08 19:33:23.819395: train_loss -0.9878 
2024-12-08 19:33:23.826541: val_loss -0.8975 
2024-12-08 19:33:23.829082: Pseudo dice [np.float32(0.9333)] 
2024-12-08 19:33:23.834159: Epoch time: 41.83 s 
2024-12-08 19:33:24.368638:  
2024-12-08 19:33:24.373703: Epoch 80 
2024-12-08 19:33:24.377753: Current learning rate: 0.00235 
2024-12-08 19:34:06.186372: train_loss -0.9883 
2024-12-08 19:34:06.193487: val_loss -0.8998 
2024-12-08 19:34:06.196029: Pseudo dice [np.float32(0.9348)] 
2024-12-08 19:34:06.201147: Epoch time: 41.82 s 
2024-12-08 19:34:06.732278:  
2024-12-08 19:34:06.738398: Epoch 81 
2024-12-08 19:34:06.743481: Current learning rate: 0.00224 
2024-12-08 19:34:48.560843: train_loss -0.9885 
2024-12-08 19:34:48.569011: val_loss -0.8981 
2024-12-08 19:34:48.571553: Pseudo dice [np.float32(0.9342)] 
2024-12-08 19:34:48.576625: Epoch time: 41.83 s 
2024-12-08 19:34:49.112487:  
2024-12-08 19:34:49.119588: Epoch 82 
2024-12-08 19:34:49.123212: Current learning rate: 0.00214 
2024-12-08 19:35:30.926497: train_loss -0.9885 
2024-12-08 19:35:30.932091: val_loss -0.8984 
2024-12-08 19:35:30.937199: Pseudo dice [np.float32(0.9343)] 
2024-12-08 19:35:30.940759: Epoch time: 41.81 s 
2024-12-08 19:35:31.447614:  
2024-12-08 19:35:31.453208: Epoch 83 
2024-12-08 19:35:31.458312: Current learning rate: 0.00203 
2024-12-08 19:36:13.278727: train_loss -0.9884 
2024-12-08 19:36:13.286374: val_loss -0.9001 
2024-12-08 19:36:13.289425: Pseudo dice [np.float32(0.9352)] 
2024-12-08 19:36:13.294574: Epoch time: 41.83 s 
2024-12-08 19:36:13.940402:  
2024-12-08 19:36:13.946523: Epoch 84 
2024-12-08 19:36:13.950581: Current learning rate: 0.00192 
2024-12-08 19:36:55.759138: train_loss -0.9883 
2024-12-08 19:36:55.765749: val_loss -0.8985 
2024-12-08 19:36:55.770815: Pseudo dice [np.float32(0.934)] 
2024-12-08 19:36:55.774887: Epoch time: 41.82 s 
2024-12-08 19:36:56.278937:  
2024-12-08 19:36:56.284529: Epoch 85 
2024-12-08 19:36:56.287067: Current learning rate: 0.00181 
2024-12-08 19:37:38.101625: train_loss -0.9882 
2024-12-08 19:37:38.106796: val_loss -0.9009 
2024-12-08 19:37:38.109871: Pseudo dice [np.float32(0.9358)] 
2024-12-08 19:37:38.114421: Epoch time: 41.82 s 
2024-12-08 19:37:38.609622:  
2024-12-08 19:37:38.617301: Epoch 86 
2024-12-08 19:37:38.619846: Current learning rate: 0.0017 
2024-12-08 19:38:20.436507: train_loss -0.9893 
2024-12-08 19:38:20.444167: val_loss -0.8995 
2024-12-08 19:38:20.449243: Pseudo dice [np.float32(0.935)] 
2024-12-08 19:38:20.453798: Epoch time: 41.83 s 
2024-12-08 19:38:21.001116:  
2024-12-08 19:38:21.006183: Epoch 87 
2024-12-08 19:38:21.010234: Current learning rate: 0.00159 
2024-12-08 19:39:02.834430: train_loss -0.989 
2024-12-08 19:39:02.840030: val_loss -0.8988 
2024-12-08 19:39:02.845142: Pseudo dice [np.float32(0.9349)] 
2024-12-08 19:39:02.847678: Epoch time: 41.83 s 
2024-12-08 19:39:03.342562:  
2024-12-08 19:39:03.348654: Epoch 88 
2024-12-08 19:39:03.351733: Current learning rate: 0.00148 
2024-12-08 19:39:45.170758: train_loss -0.9894 
2024-12-08 19:39:45.175858: val_loss -0.8967 
2024-12-08 19:39:45.178391: Pseudo dice [np.float32(0.9336)] 
2024-12-08 19:39:45.181959: Epoch time: 41.83 s 
2024-12-08 19:39:45.681666:  
2024-12-08 19:39:45.687254: Epoch 89 
2024-12-08 19:39:45.690304: Current learning rate: 0.00137 
2024-12-08 19:40:27.514083: train_loss -0.9878 
2024-12-08 19:40:27.521730: val_loss -0.8991 
2024-12-08 19:40:27.524270: Pseudo dice [np.float32(0.9349)] 
2024-12-08 19:40:27.526803: Epoch time: 41.83 s 
2024-12-08 19:40:28.023638:  
2024-12-08 19:40:28.029243: Epoch 90 
2024-12-08 19:40:28.031785: Current learning rate: 0.00126 
2024-12-08 19:41:09.865584: train_loss -0.9886 
2024-12-08 19:41:09.872688: val_loss -0.8986 
2024-12-08 19:41:09.875246: Pseudo dice [np.float32(0.9349)] 
2024-12-08 19:41:09.877779: Epoch time: 41.84 s 
2024-12-08 19:41:10.387963:  
2024-12-08 19:41:10.393550: Epoch 91 
2024-12-08 19:41:10.396597: Current learning rate: 0.00115 
2024-12-08 19:41:52.222590: train_loss -0.9884 
2024-12-08 19:41:52.227691: val_loss -0.8983 
2024-12-08 19:41:52.244398: Pseudo dice [np.float32(0.9349)] 
2024-12-08 19:41:52.247437: Epoch time: 41.83 s 
2024-12-08 19:41:52.743428:  
2024-12-08 19:41:52.748511: Epoch 92 
2024-12-08 19:41:52.751051: Current learning rate: 0.00103 
2024-12-08 19:42:34.580051: train_loss -0.9893 
2024-12-08 19:42:34.587700: val_loss -0.8985 
2024-12-08 19:42:34.590244: Pseudo dice [np.float32(0.9344)] 
2024-12-08 19:42:34.593293: Epoch time: 41.84 s 
2024-12-08 19:42:35.245704:  
2024-12-08 19:42:35.251297: Epoch 93 
2024-12-08 19:42:35.254353: Current learning rate: 0.00091 
2024-12-08 19:43:17.079127: train_loss -0.9895 
2024-12-08 19:43:17.084722: val_loss -0.8996 
2024-12-08 19:43:17.087307: Pseudo dice [np.float32(0.9353)] 
2024-12-08 19:43:17.091870: Epoch time: 41.83 s 
2024-12-08 19:43:17.587813:  
2024-12-08 19:43:17.592916: Epoch 94 
2024-12-08 19:43:17.595453: Current learning rate: 0.00079 
2024-12-08 19:43:59.422673: train_loss -0.9893 
2024-12-08 19:43:59.429772: val_loss -0.8973 
2024-12-08 19:43:59.432313: Pseudo dice [np.float32(0.9344)] 
2024-12-08 19:43:59.434852: Epoch time: 41.84 s 
2024-12-08 19:43:59.935815:  
2024-12-08 19:43:59.940875: Epoch 95 
2024-12-08 19:43:59.943410: Current learning rate: 0.00067 
2024-12-08 19:44:41.755252: train_loss -0.9894 
2024-12-08 19:44:41.762348: val_loss -0.8977 
2024-12-08 19:44:41.765440: Pseudo dice [np.float32(0.9345)] 
2024-12-08 19:44:41.767989: Epoch time: 41.82 s 
2024-12-08 19:44:42.264566:  
2024-12-08 19:44:42.270713: Epoch 96 
2024-12-08 19:44:42.273254: Current learning rate: 0.00055 
2024-12-08 19:45:24.105840: train_loss -0.988 
2024-12-08 19:45:24.111943: val_loss -0.8992 
2024-12-08 19:45:24.115487: Pseudo dice [np.float32(0.9352)] 
2024-12-08 19:45:24.118569: Epoch time: 41.84 s 
2024-12-08 19:45:24.623806:  
2024-12-08 19:45:24.628946: Epoch 97 
2024-12-08 19:45:24.631493: Current learning rate: 0.00043 
2024-12-08 19:46:06.457464: train_loss -0.9893 
2024-12-08 19:46:06.463094: val_loss -0.8977 
2024-12-08 19:46:06.467144: Pseudo dice [np.float32(0.9342)] 
2024-12-08 19:46:06.470197: Epoch time: 41.83 s 
2024-12-08 19:46:06.977765:  
2024-12-08 19:46:06.983391: Epoch 98 
2024-12-08 19:46:06.986437: Current learning rate: 0.0003 
2024-12-08 19:46:48.801329: train_loss -0.9903 
2024-12-08 19:46:48.806434: val_loss -0.8976 
2024-12-08 19:46:48.808985: Pseudo dice [np.float32(0.9344)] 
2024-12-08 19:46:48.811525: Epoch time: 41.82 s 
2024-12-08 19:46:49.316815:  
2024-12-08 19:46:49.322911: Epoch 99 
2024-12-08 19:46:49.325955: Current learning rate: 0.00016 
2024-12-08 19:47:31.141135: train_loss -0.9887 
2024-12-08 19:47:31.147724: val_loss -0.8985 
2024-12-08 19:47:31.150256: Pseudo dice [np.float32(0.9353)] 
2024-12-08 19:47:31.153809: Epoch time: 41.82 s 
2024-12-08 19:47:31.854487: Training done. 
2024-12-08 19:47:31.879134: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-08 19:47:31.887235: The split file contains 5 splits. 
2024-12-08 19:47:31.887235: Desired fold for training: 0 
2024-12-08 19:47:31.895689: This split has 16 training and 4 validation cases. 
2024-12-08 19:47:31.895689: predicting la_007 
2024-12-08 19:47:31.903815: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2024-12-08 19:47:33.366761: predicting la_016 
2024-12-08 19:47:33.374966: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2024-12-08 19:47:33.673457: predicting la_021 
2024-12-08 19:47:33.681598: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2024-12-08 19:47:33.992988: predicting la_024 
2024-12-08 19:47:34.001436: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2024-12-08 19:47:41.106410: Validation complete 
2024-12-08 19:47:41.112767: Mean Validation Dice:  0.9314446362296676 
