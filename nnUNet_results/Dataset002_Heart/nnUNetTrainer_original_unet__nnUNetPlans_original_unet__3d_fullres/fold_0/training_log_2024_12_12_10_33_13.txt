
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-12 10:33:13.694357: do_dummy_2d_data_aug: False 
2024-12-12 10:33:13.695357: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-12 10:33:13.702517: The split file contains 5 splits. 
2024-12-12 10:33:13.704516: Desired fold for training: 0 
2024-12-12 10:33:13.707516: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_original_unet_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans_original_unet', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2024-12-12 10:33:22.667792: unpacking dataset... 
2024-12-12 10:33:23.311043: unpacking done... 
2024-12-12 10:33:26.140116:  
2024-12-12 10:33:26.144127: Epoch 0 
2024-12-12 10:33:26.147631: Current learning rate: 0.01 
2024-12-12 10:34:13.640146: train_loss -0.5129 
2024-12-12 10:34:13.645679: val_loss -0.7753 
2024-12-12 10:34:13.648184: Pseudo dice [np.float32(0.8318)] 
2024-12-12 10:34:13.651695: Epoch time: 47.5 s 
2024-12-12 10:34:13.654201: Yayy! New best EMA pseudo Dice: 0.8317999839782715 
2024-12-12 10:34:14.299281:  
2024-12-12 10:34:14.304336: Epoch 1 
2024-12-12 10:34:14.306885: Current learning rate: 0.00991 
2024-12-12 10:34:57.389800: train_loss -0.7907 
2024-12-12 10:34:57.395402: val_loss -0.8622 
2024-12-12 10:34:57.398452: Pseudo dice [np.float32(0.8986)] 
2024-12-12 10:34:57.402994: Epoch time: 43.09 s 
2024-12-12 10:34:57.405515: Yayy! New best EMA pseudo Dice: 0.8385000228881836 
2024-12-12 10:34:58.134401:  
2024-12-12 10:34:58.139415: Epoch 2 
2024-12-12 10:34:58.142923: Current learning rate: 0.00982 
2024-12-12 10:35:41.248596: train_loss -0.8266 
2024-12-12 10:35:41.254612: val_loss -0.8751 
2024-12-12 10:35:41.257118: Pseudo dice [np.float32(0.9069)] 
2024-12-12 10:35:41.260626: Epoch time: 43.11 s 
2024-12-12 10:35:41.263636: Yayy! New best EMA pseudo Dice: 0.8453999757766724 
2024-12-12 10:35:42.016975:  
2024-12-12 10:35:42.022007: Epoch 3 
2024-12-12 10:35:42.025061: Current learning rate: 0.00973 
2024-12-12 10:36:25.108661: train_loss -0.8388 
2024-12-12 10:36:25.114179: val_loss -0.862 
2024-12-12 10:36:25.117690: Pseudo dice [np.float32(0.8919)] 
2024-12-12 10:36:25.120197: Epoch time: 43.09 s 
2024-12-12 10:36:25.123705: Yayy! New best EMA pseudo Dice: 0.8500000238418579 
2024-12-12 10:36:25.857563:  
2024-12-12 10:36:25.863200: Epoch 4 
2024-12-12 10:36:25.865726: Current learning rate: 0.00964 
2024-12-12 10:37:08.961242: train_loss -0.8649 
2024-12-12 10:37:08.966290: val_loss -0.8942 
2024-12-12 10:37:08.969799: Pseudo dice [np.float32(0.9182)] 
2024-12-12 10:37:08.972306: Epoch time: 43.1 s 
2024-12-12 10:37:08.975811: Yayy! New best EMA pseudo Dice: 0.8568000197410583 
2024-12-12 10:37:09.859746:  
2024-12-12 10:37:09.865292: Epoch 5 
2024-12-12 10:37:09.868343: Current learning rate: 0.00955 
2024-12-12 10:37:52.946224: train_loss -0.8805 
2024-12-12 10:37:52.951804: val_loss -0.8934 
2024-12-12 10:37:52.954310: Pseudo dice [np.float32(0.9184)] 
2024-12-12 10:37:52.957819: Epoch time: 43.09 s 
2024-12-12 10:37:52.960325: Yayy! New best EMA pseudo Dice: 0.8629999756813049 
2024-12-12 10:37:53.670466:  
2024-12-12 10:37:53.676025: Epoch 6 
2024-12-12 10:37:53.680119: Current learning rate: 0.00946 
2024-12-12 10:38:36.808074: train_loss -0.8623 
2024-12-12 10:38:36.813085: val_loss -0.8925 
2024-12-12 10:38:36.816593: Pseudo dice [np.float32(0.9176)] 
2024-12-12 10:38:36.819099: Epoch time: 43.14 s 
2024-12-12 10:38:36.822608: Yayy! New best EMA pseudo Dice: 0.8684999942779541 
2024-12-12 10:38:37.545136:  
2024-12-12 10:38:37.550671: Epoch 7 
2024-12-12 10:38:37.554217: Current learning rate: 0.00937 
2024-12-12 10:39:20.662325: train_loss -0.8644 
2024-12-12 10:39:20.667837: val_loss -0.8924 
2024-12-12 10:39:20.671346: Pseudo dice [np.float32(0.9159)] 
2024-12-12 10:39:20.673852: Epoch time: 43.12 s 
2024-12-12 10:39:20.677358: Yayy! New best EMA pseudo Dice: 0.873199999332428 
2024-12-12 10:39:21.415499:  
2024-12-12 10:39:21.421015: Epoch 8 
2024-12-12 10:39:21.424524: Current learning rate: 0.00928 
2024-12-12 10:40:04.541839: train_loss -0.8857 
2024-12-12 10:40:04.546929: val_loss -0.894 
2024-12-12 10:40:04.550452: Pseudo dice [np.float32(0.9175)] 
2024-12-12 10:40:04.553475: Epoch time: 43.13 s 
2024-12-12 10:40:04.556498: Yayy! New best EMA pseudo Dice: 0.8776000142097473 
2024-12-12 10:40:05.302695:  
2024-12-12 10:40:05.307706: Epoch 9 
2024-12-12 10:40:05.311214: Current learning rate: 0.00919 
2024-12-12 10:40:48.403937: train_loss -0.8903 
2024-12-12 10:40:48.409951: val_loss -0.9003 
2024-12-12 10:40:48.413463: Pseudo dice [np.float32(0.9228)] 
2024-12-12 10:40:48.416474: Epoch time: 43.1 s 
2024-12-12 10:40:48.419983: Yayy! New best EMA pseudo Dice: 0.8822000026702881 
2024-12-12 10:40:49.130490:  
2024-12-12 10:40:49.136547: Epoch 10 
2024-12-12 10:40:49.139594: Current learning rate: 0.0091 
2024-12-12 10:41:32.216638: train_loss -0.897 
2024-12-12 10:41:32.221656: val_loss -0.9068 
2024-12-12 10:41:32.225168: Pseudo dice [np.float32(0.929)] 
2024-12-12 10:41:32.228680: Epoch time: 43.09 s 
2024-12-12 10:41:32.231693: Yayy! New best EMA pseudo Dice: 0.8867999911308289 
2024-12-12 10:41:32.963722:  
2024-12-12 10:41:32.969249: Epoch 11 
2024-12-12 10:41:32.972850: Current learning rate: 0.009 
2024-12-12 10:42:16.058711: train_loss -0.897 
2024-12-12 10:42:16.064341: val_loss -0.9051 
2024-12-12 10:42:16.067849: Pseudo dice [np.float32(0.9281)] 
2024-12-12 10:42:16.071356: Epoch time: 43.1 s 
2024-12-12 10:42:16.074367: Yayy! New best EMA pseudo Dice: 0.890999972820282 
2024-12-12 10:42:16.792429:  
2024-12-12 10:42:16.795940: Epoch 12 
2024-12-12 10:42:16.799500: Current learning rate: 0.00891 
2024-12-12 10:42:59.897308: train_loss -0.8949 
2024-12-12 10:42:59.902455: val_loss -0.9063 
2024-12-12 10:42:59.905965: Pseudo dice [np.float32(0.9278)] 
2024-12-12 10:42:59.908469: Epoch time: 43.11 s 
2024-12-12 10:42:59.910975: Yayy! New best EMA pseudo Dice: 0.894599974155426 
2024-12-12 10:43:00.788816:  
2024-12-12 10:43:00.794850: Epoch 13 
2024-12-12 10:43:00.797878: Current learning rate: 0.00882 
2024-12-12 10:43:43.846779: train_loss -0.8972 
2024-12-12 10:43:43.851850: val_loss -0.9072 
2024-12-12 10:43:43.854390: Pseudo dice [np.float32(0.928)] 
2024-12-12 10:43:43.857899: Epoch time: 43.06 s 
2024-12-12 10:43:43.860405: Yayy! New best EMA pseudo Dice: 0.8980000019073486 
2024-12-12 10:43:44.582335:  
2024-12-12 10:43:44.587902: Epoch 14 
2024-12-12 10:43:44.591472: Current learning rate: 0.00873 
2024-12-12 10:44:27.683025: train_loss -0.9013 
2024-12-12 10:44:27.687069: val_loss -0.9121 
2024-12-12 10:44:27.690639: Pseudo dice [np.float32(0.9314)] 
2024-12-12 10:44:27.693145: Epoch time: 43.1 s 
2024-12-12 10:44:27.696655: Yayy! New best EMA pseudo Dice: 0.9013000130653381 
2024-12-12 10:44:28.440431:  
2024-12-12 10:44:28.445442: Epoch 15 
2024-12-12 10:44:28.447948: Current learning rate: 0.00864 
2024-12-12 10:45:11.586554: train_loss -0.9095 
2024-12-12 10:45:11.592122: val_loss -0.9068 
2024-12-12 10:45:11.595130: Pseudo dice [np.float32(0.9265)] 
2024-12-12 10:45:11.598639: Epoch time: 43.15 s 
2024-12-12 10:45:11.601145: Yayy! New best EMA pseudo Dice: 0.9038000106811523 
2024-12-12 10:45:12.337411:  
2024-12-12 10:45:12.343491: Epoch 16 
2024-12-12 10:45:12.346569: Current learning rate: 0.00855 
2024-12-12 10:45:55.450812: train_loss -0.909 
2024-12-12 10:45:55.456373: val_loss -0.9107 
2024-12-12 10:45:55.459958: Pseudo dice [np.float32(0.9308)] 
2024-12-12 10:45:55.463502: Epoch time: 43.11 s 
2024-12-12 10:45:55.466541: Yayy! New best EMA pseudo Dice: 0.906499981880188 
2024-12-12 10:45:56.202961:  
2024-12-12 10:45:56.208498: Epoch 17 
2024-12-12 10:45:56.212048: Current learning rate: 0.00846 
2024-12-12 10:46:39.267897: train_loss -0.9119 
2024-12-12 10:46:39.272965: val_loss -0.9121 
2024-12-12 10:46:39.276077: Pseudo dice [np.float32(0.9305)] 
2024-12-12 10:46:39.279141: Epoch time: 43.07 s 
2024-12-12 10:46:39.282651: Yayy! New best EMA pseudo Dice: 0.9089000225067139 
2024-12-12 10:46:40.023729:  
2024-12-12 10:46:40.028273: Epoch 18 
2024-12-12 10:46:40.033347: Current learning rate: 0.00836 
2024-12-12 10:47:23.174302: train_loss -0.8989 
2024-12-12 10:47:23.178930: val_loss -0.9116 
2024-12-12 10:47:23.181468: Pseudo dice [np.float32(0.9318)] 
2024-12-12 10:47:23.185031: Epoch time: 43.15 s 
2024-12-12 10:47:23.188054: Yayy! New best EMA pseudo Dice: 0.9111999869346619 
2024-12-12 10:47:23.931871:  
2024-12-12 10:47:23.937408: Epoch 19 
2024-12-12 10:47:23.939915: Current learning rate: 0.00827 
2024-12-12 10:48:07.023430: train_loss -0.9148 
2024-12-12 10:48:07.028966: val_loss -0.9146 
2024-12-12 10:48:07.031475: Pseudo dice [np.float32(0.9318)] 
2024-12-12 10:48:07.035484: Epoch time: 43.09 s 
2024-12-12 10:48:07.037990: Yayy! New best EMA pseudo Dice: 0.9132999777793884 
2024-12-12 10:48:07.777987:  
2024-12-12 10:48:07.783535: Epoch 20 
2024-12-12 10:48:07.787080: Current learning rate: 0.00818 
2024-12-12 10:48:50.841659: train_loss -0.917 
2024-12-12 10:48:50.847800: val_loss -0.9136 
2024-12-12 10:48:50.850842: Pseudo dice [np.float32(0.9324)] 
2024-12-12 10:48:50.854384: Epoch time: 43.06 s 
2024-12-12 10:48:50.857437: Yayy! New best EMA pseudo Dice: 0.9151999950408936 
2024-12-12 10:48:51.760061:  
2024-12-12 10:48:51.765119: Epoch 21 
2024-12-12 10:48:51.768669: Current learning rate: 0.00809 
2024-12-12 10:49:34.842838: train_loss -0.9185 
2024-12-12 10:49:34.848851: val_loss -0.9163 
2024-12-12 10:49:34.851361: Pseudo dice [np.float32(0.9339)] 
2024-12-12 10:49:34.854867: Epoch time: 43.08 s 
2024-12-12 10:49:34.857877: Yayy! New best EMA pseudo Dice: 0.9171000123023987 
2024-12-12 10:49:35.570617:  
2024-12-12 10:49:35.575143: Epoch 22 
2024-12-12 10:49:35.578701: Current learning rate: 0.008 
2024-12-12 10:50:18.703621: train_loss -0.9186 
2024-12-12 10:50:18.707684: val_loss -0.9129 
2024-12-12 10:50:18.711339: Pseudo dice [np.float32(0.9315)] 
2024-12-12 10:50:18.714408: Epoch time: 43.13 s 
2024-12-12 10:50:18.717918: Yayy! New best EMA pseudo Dice: 0.9185000061988831 
2024-12-12 10:50:19.427821:  
2024-12-12 10:50:19.433885: Epoch 23 
2024-12-12 10:50:19.436450: Current learning rate: 0.0079 
2024-12-12 10:51:02.522197: train_loss -0.919 
2024-12-12 10:51:02.527713: val_loss -0.8933 
2024-12-12 10:51:02.531223: Pseudo dice [np.float32(0.918)] 
2024-12-12 10:51:02.534729: Epoch time: 43.09 s 
2024-12-12 10:51:03.068736:  
2024-12-12 10:51:03.074798: Epoch 24 
2024-12-12 10:51:03.077942: Current learning rate: 0.00781 
2024-12-12 10:51:46.154424: train_loss -0.9031 
2024-12-12 10:51:46.160163: val_loss -0.9152 
2024-12-12 10:51:46.163204: Pseudo dice [np.float32(0.9327)] 
2024-12-12 10:51:46.166740: Epoch time: 43.09 s 
2024-12-12 10:51:46.170277: Yayy! New best EMA pseudo Dice: 0.9199000000953674 
2024-12-12 10:51:46.886350:  
2024-12-12 10:51:46.891910: Epoch 25 
2024-12-12 10:51:46.895567: Current learning rate: 0.00772 
2024-12-12 10:52:30.019723: train_loss -0.9175 
2024-12-12 10:52:30.025863: val_loss -0.9168 
2024-12-12 10:52:30.029374: Pseudo dice [np.float32(0.934)] 
2024-12-12 10:52:30.032887: Epoch time: 43.13 s 
2024-12-12 10:52:30.036020: Yayy! New best EMA pseudo Dice: 0.9212999939918518 
2024-12-12 10:52:30.757037:  
2024-12-12 10:52:30.762595: Epoch 26 
2024-12-12 10:52:30.766632: Current learning rate: 0.00763 
2024-12-12 10:53:13.824580: train_loss -0.916 
2024-12-12 10:53:13.830145: val_loss -0.9157 
2024-12-12 10:53:13.832690: Pseudo dice [np.float32(0.9331)] 
2024-12-12 10:53:13.835721: Epoch time: 43.07 s 
2024-12-12 10:53:13.839342: Yayy! New best EMA pseudo Dice: 0.9225000143051147 
2024-12-12 10:53:14.562689:  
2024-12-12 10:53:14.567700: Epoch 27 
2024-12-12 10:53:14.571713: Current learning rate: 0.00753 
2024-12-12 10:53:57.646862: train_loss -0.9254 
2024-12-12 10:53:57.652063: val_loss -0.9157 
2024-12-12 10:53:57.654570: Pseudo dice [np.float32(0.9334)] 
2024-12-12 10:53:57.658078: Epoch time: 43.08 s 
2024-12-12 10:53:57.661585: Yayy! New best EMA pseudo Dice: 0.9236000180244446 
2024-12-12 10:53:58.532911:  
2024-12-12 10:53:58.539429: Epoch 28 
2024-12-12 10:53:58.541940: Current learning rate: 0.00744 
2024-12-12 10:54:41.702040: train_loss -0.9273 
2024-12-12 10:54:41.707684: val_loss -0.9178 
2024-12-12 10:54:41.710224: Pseudo dice [np.float32(0.9339)] 
2024-12-12 10:54:41.714264: Epoch time: 43.17 s 
2024-12-12 10:54:41.717321: Yayy! New best EMA pseudo Dice: 0.9246000051498413 
2024-12-12 10:54:42.488238:  
2024-12-12 10:54:42.493818: Epoch 29 
2024-12-12 10:54:42.496363: Current learning rate: 0.00735 
2024-12-12 10:55:25.695384: train_loss -0.9308 
2024-12-12 10:55:25.701400: val_loss -0.9211 
2024-12-12 10:55:25.704409: Pseudo dice [np.float32(0.9366)] 
2024-12-12 10:55:25.706915: Epoch time: 43.21 s 
2024-12-12 10:55:25.710424: Yayy! New best EMA pseudo Dice: 0.9258000254631042 
2024-12-12 10:55:26.453914:  
2024-12-12 10:55:26.458926: Epoch 30 
2024-12-12 10:55:26.462435: Current learning rate: 0.00725 
2024-12-12 10:56:09.575228: train_loss -0.9306 
2024-12-12 10:56:09.581746: val_loss -0.9184 
2024-12-12 10:56:09.584252: Pseudo dice [np.float32(0.9346)] 
2024-12-12 10:56:09.587760: Epoch time: 43.12 s 
2024-12-12 10:56:09.590267: Yayy! New best EMA pseudo Dice: 0.9266999959945679 
2024-12-12 10:56:10.309854:  
2024-12-12 10:56:10.314910: Epoch 31 
2024-12-12 10:56:10.317475: Current learning rate: 0.00716 
2024-12-12 10:56:53.431877: train_loss -0.9302 
2024-12-12 10:56:53.437480: val_loss -0.916 
2024-12-12 10:56:53.440527: Pseudo dice [np.float32(0.9329)] 
2024-12-12 10:56:53.444053: Epoch time: 43.12 s 
2024-12-12 10:56:53.447080: Yayy! New best EMA pseudo Dice: 0.927299976348877 
2024-12-12 10:56:54.189316:  
2024-12-12 10:56:54.194839: Epoch 32 
2024-12-12 10:56:54.198353: Current learning rate: 0.00707 
2024-12-12 10:57:37.314456: train_loss -0.9324 
2024-12-12 10:57:37.319466: val_loss -0.9211 
2024-12-12 10:57:37.323476: Pseudo dice [np.float32(0.9364)] 
2024-12-12 10:57:37.326991: Epoch time: 43.13 s 
2024-12-12 10:57:37.329495: Yayy! New best EMA pseudo Dice: 0.9282000064849854 
2024-12-12 10:57:38.067728:  
2024-12-12 10:57:38.072618: Epoch 33 
2024-12-12 10:57:38.075126: Current learning rate: 0.00697 
2024-12-12 10:58:21.184952: train_loss -0.9335 
2024-12-12 10:58:21.190028: val_loss -0.9223 
2024-12-12 10:58:21.193062: Pseudo dice [np.float32(0.938)] 
2024-12-12 10:58:21.196576: Epoch time: 43.12 s 
2024-12-12 10:58:21.199083: Yayy! New best EMA pseudo Dice: 0.9291999936103821 
2024-12-12 10:58:21.928584:  
2024-12-12 10:58:21.932626: Epoch 34 
2024-12-12 10:58:21.935680: Current learning rate: 0.00688 
2024-12-12 10:59:05.071805: train_loss -0.9363 
2024-12-12 10:59:05.078367: val_loss -0.918 
2024-12-12 10:59:05.080875: Pseudo dice [np.float32(0.9344)] 
2024-12-12 10:59:05.084982: Epoch time: 43.14 s 
2024-12-12 10:59:05.087488: Yayy! New best EMA pseudo Dice: 0.9297000169754028 
2024-12-12 10:59:05.828805:  
2024-12-12 10:59:05.834435: Epoch 35 
2024-12-12 10:59:05.836968: Current learning rate: 0.00679 
2024-12-12 10:59:48.924513: train_loss -0.936 
2024-12-12 10:59:48.930070: val_loss -0.9179 
2024-12-12 10:59:48.933079: Pseudo dice [np.float32(0.9337)] 
2024-12-12 10:59:48.936592: Epoch time: 43.1 s 
2024-12-12 10:59:48.939098: Yayy! New best EMA pseudo Dice: 0.9301000237464905 
2024-12-12 10:59:49.671301:  
2024-12-12 10:59:49.676895: Epoch 36 
2024-12-12 10:59:49.680512: Current learning rate: 0.00669 
2024-12-12 11:00:32.790591: train_loss -0.936 
2024-12-12 11:00:32.795682: val_loss -0.9195 
2024-12-12 11:00:32.799192: Pseudo dice [np.float32(0.9349)] 
2024-12-12 11:00:32.802700: Epoch time: 43.12 s 
2024-12-12 11:00:32.805710: Yayy! New best EMA pseudo Dice: 0.9305999875068665 
2024-12-12 11:00:33.698363:  
2024-12-12 11:00:33.703375: Epoch 37 
2024-12-12 11:00:33.706885: Current learning rate: 0.0066 
2024-12-12 11:01:16.813838: train_loss -0.9307 
2024-12-12 11:01:16.818912: val_loss -0.9177 
2024-12-12 11:01:16.821978: Pseudo dice [np.float32(0.9332)] 
2024-12-12 11:01:16.824516: Epoch time: 43.12 s 
2024-12-12 11:01:16.827052: Yayy! New best EMA pseudo Dice: 0.9308000206947327 
2024-12-12 11:01:17.562758:  
2024-12-12 11:01:17.567797: Epoch 38 
2024-12-12 11:01:17.570835: Current learning rate: 0.0065 
2024-12-12 11:02:00.703055: train_loss -0.9335 
2024-12-12 11:02:00.708115: val_loss -0.9153 
2024-12-12 11:02:00.710649: Pseudo dice [np.float32(0.9318)] 
2024-12-12 11:02:00.714752: Epoch time: 43.14 s 
2024-12-12 11:02:00.717792: Yayy! New best EMA pseudo Dice: 0.930899977684021 
2024-12-12 11:02:01.452265:  
2024-12-12 11:02:01.457294: Epoch 39 
2024-12-12 11:02:01.460825: Current learning rate: 0.00641 
2024-12-12 11:02:44.593273: train_loss -0.9372 
2024-12-12 11:02:44.598786: val_loss -0.9226 
2024-12-12 11:02:44.602296: Pseudo dice [np.float32(0.9376)] 
2024-12-12 11:02:44.606328: Epoch time: 43.14 s 
2024-12-12 11:02:44.608834: Yayy! New best EMA pseudo Dice: 0.9315999746322632 
2024-12-12 11:02:45.348361:  
2024-12-12 11:02:45.353373: Epoch 40 
2024-12-12 11:02:45.356881: Current learning rate: 0.00631 
2024-12-12 11:03:28.489031: train_loss -0.9285 
2024-12-12 11:03:28.494546: val_loss -0.9128 
2024-12-12 11:03:28.498055: Pseudo dice [np.float32(0.931)] 
2024-12-12 11:03:28.500560: Epoch time: 43.14 s 
2024-12-12 11:03:29.074344:  
2024-12-12 11:03:29.079120: Epoch 41 
2024-12-12 11:03:29.082632: Current learning rate: 0.00622 
2024-12-12 11:04:12.199793: train_loss -0.9239 
2024-12-12 11:04:12.207420: val_loss -0.9199 
2024-12-12 11:04:12.211968: Pseudo dice [np.float32(0.9352)] 
2024-12-12 11:04:12.215122: Epoch time: 43.13 s 
2024-12-12 11:04:12.218177: Yayy! New best EMA pseudo Dice: 0.9319000244140625 
2024-12-12 11:04:12.938301:  
2024-12-12 11:04:12.943316: Epoch 42 
2024-12-12 11:04:12.946325: Current learning rate: 0.00612 
2024-12-12 11:04:56.169604: train_loss -0.9307 
2024-12-12 11:04:56.174689: val_loss -0.9174 
2024-12-12 11:04:56.178200: Pseudo dice [np.float32(0.9342)] 
2024-12-12 11:04:56.182213: Epoch time: 43.23 s 
2024-12-12 11:04:56.184720: Yayy! New best EMA pseudo Dice: 0.9320999979972839 
2024-12-12 11:04:56.901230:  
2024-12-12 11:04:56.906858: Epoch 43 
2024-12-12 11:04:56.909917: Current learning rate: 0.00603 
2024-12-12 11:05:40.005602: train_loss -0.9368 
2024-12-12 11:05:40.011287: val_loss -0.9201 
2024-12-12 11:05:40.014441: Pseudo dice [np.float32(0.9361)] 
2024-12-12 11:05:40.017553: Epoch time: 43.11 s 
2024-12-12 11:05:40.020134: Yayy! New best EMA pseudo Dice: 0.9325000047683716 
2024-12-12 11:05:40.884635:  
2024-12-12 11:05:40.889711: Epoch 44 
2024-12-12 11:05:40.893297: Current learning rate: 0.00593 
2024-12-12 11:06:23.966451: train_loss -0.9418 
2024-12-12 11:06:23.971650: val_loss -0.9217 
2024-12-12 11:06:23.975232: Pseudo dice [np.float32(0.9366)] 
2024-12-12 11:06:23.978319: Epoch time: 43.08 s 
2024-12-12 11:06:23.980890: Yayy! New best EMA pseudo Dice: 0.9329000115394592 
2024-12-12 11:06:24.686827:  
2024-12-12 11:06:24.692504: Epoch 45 
2024-12-12 11:06:24.695059: Current learning rate: 0.00584 
2024-12-12 11:07:07.773232: train_loss -0.9426 
2024-12-12 11:07:07.778252: val_loss -0.9206 
2024-12-12 11:07:07.783271: Pseudo dice [np.float32(0.9359)] 
2024-12-12 11:07:07.786781: Epoch time: 43.09 s 
2024-12-12 11:07:07.789796: Yayy! New best EMA pseudo Dice: 0.9332000017166138 
2024-12-12 11:07:08.505195:  
2024-12-12 11:07:08.510737: Epoch 46 
2024-12-12 11:07:08.513369: Current learning rate: 0.00574 
2024-12-12 11:07:51.604277: train_loss -0.9418 
2024-12-12 11:07:51.608837: val_loss -0.9209 
2024-12-12 11:07:51.611877: Pseudo dice [np.float32(0.9357)] 
2024-12-12 11:07:51.614450: Epoch time: 43.1 s 
2024-12-12 11:07:51.617997: Yayy! New best EMA pseudo Dice: 0.9334999918937683 
2024-12-12 11:07:52.317607:  
2024-12-12 11:07:52.323158: Epoch 47 
2024-12-12 11:07:52.325686: Current learning rate: 0.00565 
2024-12-12 11:08:35.444796: train_loss -0.9445 
2024-12-12 11:08:35.450355: val_loss -0.9211 
2024-12-12 11:08:35.453389: Pseudo dice [np.float32(0.936)] 
2024-12-12 11:08:35.456415: Epoch time: 43.13 s 
2024-12-12 11:08:35.459434: Yayy! New best EMA pseudo Dice: 0.9337000250816345 
2024-12-12 11:08:36.164888:  
2024-12-12 11:08:36.170444: Epoch 48 
2024-12-12 11:08:36.172973: Current learning rate: 0.00555 
2024-12-12 11:09:19.263465: train_loss -0.9418 
2024-12-12 11:09:19.270536: val_loss -0.9201 
2024-12-12 11:09:19.273580: Pseudo dice [np.float32(0.9349)] 
2024-12-12 11:09:19.276095: Epoch time: 43.1 s 
2024-12-12 11:09:19.279616: Yayy! New best EMA pseudo Dice: 0.9337999820709229 
2024-12-12 11:09:20.009578:  
2024-12-12 11:09:20.015719: Epoch 49 
2024-12-12 11:09:20.018241: Current learning rate: 0.00546 
2024-12-12 11:10:03.103107: train_loss -0.9457 
2024-12-12 11:10:03.108283: val_loss -0.9232 
2024-12-12 11:10:03.111799: Pseudo dice [np.float32(0.9374)] 
2024-12-12 11:10:03.114848: Epoch time: 43.09 s 
2024-12-12 11:10:03.267167: Yayy! New best EMA pseudo Dice: 0.9341999888420105 
2024-12-12 11:10:03.992006:  
2024-12-12 11:10:03.997114: Epoch 50 
2024-12-12 11:10:04.001271: Current learning rate: 0.00536 
2024-12-12 11:10:47.143839: train_loss -0.9438 
2024-12-12 11:10:47.148981: val_loss -0.9208 
2024-12-12 11:10:47.151521: Pseudo dice [np.float32(0.9357)] 
2024-12-12 11:10:47.155550: Epoch time: 43.15 s 
2024-12-12 11:10:47.158558: Yayy! New best EMA pseudo Dice: 0.9344000220298767 
2024-12-12 11:10:47.870356:  
2024-12-12 11:10:47.875370: Epoch 51 
2024-12-12 11:10:47.878880: Current learning rate: 0.00526 
2024-12-12 11:11:30.968679: train_loss -0.9449 
2024-12-12 11:11:30.974245: val_loss -0.9235 
2024-12-12 11:11:30.976751: Pseudo dice [np.float32(0.9379)] 
2024-12-12 11:11:30.980261: Epoch time: 43.1 s 
2024-12-12 11:11:30.982769: Yayy! New best EMA pseudo Dice: 0.9347000122070312 
2024-12-12 11:11:31.855745:  
2024-12-12 11:11:31.860681: Epoch 52 
2024-12-12 11:11:31.864193: Current learning rate: 0.00517 
2024-12-12 11:12:14.955522: train_loss -0.9412 
2024-12-12 11:12:14.960705: val_loss -0.9211 
2024-12-12 11:12:14.964217: Pseudo dice [np.float32(0.9355)] 
2024-12-12 11:12:14.967725: Epoch time: 43.1 s 
2024-12-12 11:12:14.970737: Yayy! New best EMA pseudo Dice: 0.9348000288009644 
2024-12-12 11:12:15.688951:  
2024-12-12 11:12:15.694496: Epoch 53 
2024-12-12 11:12:15.698087: Current learning rate: 0.00507 
2024-12-12 11:12:58.763385: train_loss -0.9402 
2024-12-12 11:12:58.768927: val_loss -0.9218 
2024-12-12 11:12:58.772436: Pseudo dice [np.float32(0.9366)] 
2024-12-12 11:12:58.776461: Epoch time: 43.08 s 
2024-12-12 11:12:58.778969: Yayy! New best EMA pseudo Dice: 0.9350000023841858 
2024-12-12 11:12:59.487301:  
2024-12-12 11:12:59.492879: Epoch 54 
2024-12-12 11:12:59.495924: Current learning rate: 0.00497 
2024-12-12 11:13:42.567455: train_loss -0.9469 
2024-12-12 11:13:42.573972: val_loss -0.9222 
2024-12-12 11:13:42.576478: Pseudo dice [np.float32(0.9367)] 
2024-12-12 11:13:42.579987: Epoch time: 43.08 s 
2024-12-12 11:13:42.582492: Yayy! New best EMA pseudo Dice: 0.9351000189781189 
2024-12-12 11:13:43.304133:  
2024-12-12 11:13:43.309677: Epoch 55 
2024-12-12 11:13:43.313218: Current learning rate: 0.00487 
2024-12-12 11:14:26.380924: train_loss -0.9457 
2024-12-12 11:14:26.385969: val_loss -0.923 
2024-12-12 11:14:26.389477: Pseudo dice [np.float32(0.9374)] 
2024-12-12 11:14:26.392982: Epoch time: 43.08 s 
2024-12-12 11:14:26.395990: Yayy! New best EMA pseudo Dice: 0.9354000091552734 
2024-12-12 11:14:27.113537:  
2024-12-12 11:14:27.119558: Epoch 56 
2024-12-12 11:14:27.122224: Current learning rate: 0.00478 
2024-12-12 11:15:10.185790: train_loss -0.9391 
2024-12-12 11:15:10.191343: val_loss -0.9168 
2024-12-12 11:15:10.194369: Pseudo dice [np.float32(0.9331)] 
2024-12-12 11:15:10.197875: Epoch time: 43.07 s 
2024-12-12 11:15:10.747099:  
2024-12-12 11:15:10.752126: Epoch 57 
2024-12-12 11:15:10.755663: Current learning rate: 0.00468 
2024-12-12 11:15:53.870741: train_loss -0.942 
2024-12-12 11:15:53.876338: val_loss -0.9232 
2024-12-12 11:15:53.879373: Pseudo dice [np.float32(0.9379)] 
2024-12-12 11:15:53.881897: Epoch time: 43.12 s 
2024-12-12 11:15:53.885947: Yayy! New best EMA pseudo Dice: 0.9354000091552734 
2024-12-12 11:15:54.595789:  
2024-12-12 11:15:54.601346: Epoch 58 
2024-12-12 11:15:54.604995: Current learning rate: 0.00458 
2024-12-12 11:16:37.681286: train_loss -0.9451 
2024-12-12 11:16:37.686334: val_loss -0.9199 
2024-12-12 11:16:37.690465: Pseudo dice [np.float32(0.9348)] 
2024-12-12 11:16:37.693000: Epoch time: 43.09 s 
2024-12-12 11:16:38.250366:  
2024-12-12 11:16:38.254908: Epoch 59 
2024-12-12 11:16:38.258065: Current learning rate: 0.00448 
2024-12-12 11:17:21.330318: train_loss -0.9474 
2024-12-12 11:17:21.336916: val_loss -0.9212 
2024-12-12 11:17:21.340540: Pseudo dice [np.float32(0.9355)] 
2024-12-12 11:17:21.344104: Epoch time: 43.08 s 
2024-12-12 11:17:21.896522:  
2024-12-12 11:17:21.901545: Epoch 60 
2024-12-12 11:17:21.904051: Current learning rate: 0.00438 
2024-12-12 11:18:04.977684: train_loss -0.9462 
2024-12-12 11:18:04.982268: val_loss -0.9207 
2024-12-12 11:18:04.985371: Pseudo dice [np.float32(0.9356)] 
2024-12-12 11:18:04.988415: Epoch time: 43.08 s 
2024-12-12 11:18:05.701675:  
2024-12-12 11:18:05.706689: Epoch 61 
2024-12-12 11:18:05.710202: Current learning rate: 0.00429 
2024-12-12 11:18:48.815040: train_loss -0.9446 
2024-12-12 11:18:48.821124: val_loss -0.9214 
2024-12-12 11:18:48.824135: Pseudo dice [np.float32(0.9362)] 
2024-12-12 11:18:48.827647: Epoch time: 43.11 s 
2024-12-12 11:18:48.830155: Yayy! New best EMA pseudo Dice: 0.9355000257492065 
2024-12-12 11:18:49.564934:  
2024-12-12 11:18:49.570487: Epoch 62 
2024-12-12 11:18:49.574566: Current learning rate: 0.00419 
2024-12-12 11:19:32.667689: train_loss -0.9489 
2024-12-12 11:19:32.672267: val_loss -0.92 
2024-12-12 11:19:32.675318: Pseudo dice [np.float32(0.9348)] 
2024-12-12 11:19:32.678490: Epoch time: 43.1 s 
2024-12-12 11:19:33.240557:  
2024-12-12 11:19:33.246109: Epoch 63 
2024-12-12 11:19:33.249669: Current learning rate: 0.00409 
2024-12-12 11:20:16.385783: train_loss -0.9469 
2024-12-12 11:20:16.391406: val_loss -0.9203 
2024-12-12 11:20:16.393960: Pseudo dice [np.float32(0.9352)] 
2024-12-12 11:20:16.397987: Epoch time: 43.15 s 
2024-12-12 11:20:16.971606:  
2024-12-12 11:20:16.975620: Epoch 64 
2024-12-12 11:20:16.978125: Current learning rate: 0.00399 
2024-12-12 11:21:00.090701: train_loss -0.9501 
2024-12-12 11:21:00.095342: val_loss -0.9213 
2024-12-12 11:21:00.099421: Pseudo dice [np.float32(0.9361)] 
2024-12-12 11:21:00.101959: Epoch time: 43.12 s 
2024-12-12 11:21:00.670373:  
2024-12-12 11:21:00.674916: Epoch 65 
2024-12-12 11:21:00.677942: Current learning rate: 0.00389 
2024-12-12 11:21:43.804152: train_loss -0.9519 
2024-12-12 11:21:43.809163: val_loss -0.9181 
2024-12-12 11:21:43.811671: Pseudo dice [np.float32(0.9332)] 
2024-12-12 11:21:43.815180: Epoch time: 43.14 s 
2024-12-12 11:21:44.377020:  
2024-12-12 11:21:44.382578: Epoch 66 
2024-12-12 11:21:44.386136: Current learning rate: 0.00379 
2024-12-12 11:22:27.522658: train_loss -0.9523 
2024-12-12 11:22:27.527718: val_loss -0.9219 
2024-12-12 11:22:27.530260: Pseudo dice [np.float32(0.9361)] 
2024-12-12 11:22:27.534305: Epoch time: 43.15 s 
2024-12-12 11:22:28.090862:  
2024-12-12 11:22:28.096404: Epoch 67 
2024-12-12 11:22:28.099464: Current learning rate: 0.00369 
2024-12-12 11:23:11.223306: train_loss -0.9523 
2024-12-12 11:23:11.228873: val_loss -0.9235 
2024-12-12 11:23:11.231916: Pseudo dice [np.float32(0.9377)] 
2024-12-12 11:23:11.234957: Epoch time: 43.13 s 
2024-12-12 11:23:11.237481: Yayy! New best EMA pseudo Dice: 0.9355000257492065 
2024-12-12 11:23:11.977110:  
2024-12-12 11:23:11.982664: Epoch 68 
2024-12-12 11:23:11.985700: Current learning rate: 0.00359 
2024-12-12 11:23:55.093962: train_loss -0.9515 
2024-12-12 11:23:55.098973: val_loss -0.9201 
2024-12-12 11:23:55.101482: Pseudo dice [np.float32(0.9347)] 
2024-12-12 11:23:55.104988: Epoch time: 43.12 s 
2024-12-12 11:23:55.831578:  
2024-12-12 11:23:55.837704: Epoch 69 
2024-12-12 11:23:55.841218: Current learning rate: 0.00349 
2024-12-12 11:24:38.994276: train_loss -0.9516 
2024-12-12 11:24:39.000774: val_loss -0.9185 
2024-12-12 11:24:39.004318: Pseudo dice [np.float32(0.9339)] 
2024-12-12 11:24:39.007352: Epoch time: 43.16 s 
2024-12-12 11:24:39.578010:  
2024-12-12 11:24:39.583023: Epoch 70 
2024-12-12 11:24:39.586532: Current learning rate: 0.00338 
2024-12-12 11:25:22.723006: train_loss -0.9513 
2024-12-12 11:25:22.728065: val_loss -0.9213 
2024-12-12 11:25:22.730602: Pseudo dice [np.float32(0.9361)] 
2024-12-12 11:25:22.734110: Epoch time: 43.15 s 
2024-12-12 11:25:23.293590:  
2024-12-12 11:25:23.299599: Epoch 71 
2024-12-12 11:25:23.302662: Current learning rate: 0.00328 
2024-12-12 11:26:06.448403: train_loss -0.9501 
2024-12-12 11:26:06.454988: val_loss -0.9188 
2024-12-12 11:26:06.458613: Pseudo dice [np.float32(0.9341)] 
2024-12-12 11:26:06.462188: Epoch time: 43.15 s 
2024-12-12 11:26:07.027449:  
2024-12-12 11:26:07.032566: Epoch 72 
2024-12-12 11:26:07.035112: Current learning rate: 0.00318 
2024-12-12 11:26:50.115212: train_loss -0.9524 
2024-12-12 11:26:50.120845: val_loss -0.9215 
2024-12-12 11:26:50.123914: Pseudo dice [np.float32(0.9361)] 
2024-12-12 11:26:50.127922: Epoch time: 43.09 s 
2024-12-12 11:26:50.687155:  
2024-12-12 11:26:50.691728: Epoch 73 
2024-12-12 11:26:50.694265: Current learning rate: 0.00308 
2024-12-12 11:27:33.806959: train_loss -0.9521 
2024-12-12 11:27:33.813012: val_loss -0.9214 
2024-12-12 11:27:33.816062: Pseudo dice [np.float32(0.9363)] 
2024-12-12 11:27:33.819105: Epoch time: 43.12 s 
2024-12-12 11:27:34.382105:  
2024-12-12 11:27:34.387648: Epoch 74 
2024-12-12 11:27:34.391213: Current learning rate: 0.00297 
2024-12-12 11:28:17.538433: train_loss -0.9504 
2024-12-12 11:28:17.543950: val_loss -0.9203 
2024-12-12 11:28:17.546459: Pseudo dice [np.float32(0.9356)] 
2024-12-12 11:28:17.549968: Epoch time: 43.16 s 
2024-12-12 11:28:18.110152:  
2024-12-12 11:28:18.115177: Epoch 75 
2024-12-12 11:28:18.118724: Current learning rate: 0.00287 
2024-12-12 11:29:01.262246: train_loss -0.9503 
2024-12-12 11:29:01.267863: val_loss -0.9196 
2024-12-12 11:29:01.270921: Pseudo dice [np.float32(0.9348)] 
2024-12-12 11:29:01.273441: Epoch time: 43.15 s 
2024-12-12 11:29:01.833951:  
2024-12-12 11:29:01.839165: Epoch 76 
2024-12-12 11:29:01.842675: Current learning rate: 0.00277 
2024-12-12 11:29:45.009336: train_loss -0.9542 
2024-12-12 11:29:45.016857: val_loss -0.9228 
2024-12-12 11:29:45.021368: Pseudo dice [np.float32(0.9371)] 
2024-12-12 11:29:45.024380: Epoch time: 43.18 s 
2024-12-12 11:29:45.027888: Yayy! New best EMA pseudo Dice: 0.9355999827384949 
2024-12-12 11:29:45.920713:  
2024-12-12 11:29:45.926260: Epoch 77 
2024-12-12 11:29:45.930849: Current learning rate: 0.00266 
2024-12-12 11:30:29.032800: train_loss -0.9526 
2024-12-12 11:30:29.037854: val_loss -0.9219 
2024-12-12 11:30:29.041366: Pseudo dice [np.float32(0.9366)] 
2024-12-12 11:30:29.044876: Epoch time: 43.11 s 
2024-12-12 11:30:29.047888: Yayy! New best EMA pseudo Dice: 0.935699999332428 
2024-12-12 11:30:29.799838:  
2024-12-12 11:30:29.804863: Epoch 78 
2024-12-12 11:30:29.808420: Current learning rate: 0.00256 
2024-12-12 11:31:12.901698: train_loss -0.9485 
2024-12-12 11:31:12.907232: val_loss -0.9201 
2024-12-12 11:31:12.909745: Pseudo dice [np.float32(0.9352)] 
2024-12-12 11:31:12.913253: Epoch time: 43.1 s 
2024-12-12 11:31:13.485802:  
2024-12-12 11:31:13.491891: Epoch 79 
2024-12-12 11:31:13.495522: Current learning rate: 0.00245 
2024-12-12 11:31:56.607150: train_loss -0.9456 
2024-12-12 11:31:56.613135: val_loss -0.9233 
2024-12-12 11:31:56.617147: Pseudo dice [np.float32(0.9374)] 
2024-12-12 11:31:56.619652: Epoch time: 43.12 s 
2024-12-12 11:31:56.623161: Yayy! New best EMA pseudo Dice: 0.9358000159263611 
2024-12-12 11:31:57.364758:  
2024-12-12 11:31:57.369769: Epoch 80 
2024-12-12 11:31:57.373785: Current learning rate: 0.00235 
2024-12-12 11:32:40.464792: train_loss -0.9492 
2024-12-12 11:32:40.470808: val_loss -0.9221 
2024-12-12 11:32:40.474320: Pseudo dice [np.float32(0.9369)] 
2024-12-12 11:32:40.477329: Epoch time: 43.1 s 
2024-12-12 11:32:40.480837: Yayy! New best EMA pseudo Dice: 0.9358999729156494 
2024-12-12 11:32:41.225690:  
2024-12-12 11:32:41.231248: Epoch 81 
2024-12-12 11:32:41.234849: Current learning rate: 0.00224 
2024-12-12 11:33:24.340596: train_loss -0.9513 
2024-12-12 11:33:24.346645: val_loss -0.923 
2024-12-12 11:33:24.350200: Pseudo dice [np.float32(0.9371)] 
2024-12-12 11:33:24.353249: Epoch time: 43.11 s 
2024-12-12 11:33:24.355780: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2024-12-12 11:33:25.105892:  
2024-12-12 11:33:25.110917: Epoch 82 
2024-12-12 11:33:25.113887: Current learning rate: 0.00214 
2024-12-12 11:34:08.222079: train_loss -0.9541 
2024-12-12 11:34:08.228023: val_loss -0.9206 
2024-12-12 11:34:08.230530: Pseudo dice [np.float32(0.9356)] 
2024-12-12 11:34:08.234542: Epoch time: 43.12 s 
2024-12-12 11:34:08.774230:  
2024-12-12 11:34:08.779794: Epoch 83 
2024-12-12 11:34:08.783381: Current learning rate: 0.00203 
2024-12-12 11:34:51.884141: train_loss -0.9468 
2024-12-12 11:34:51.889195: val_loss -0.9203 
2024-12-12 11:34:51.892705: Pseudo dice [np.float32(0.935)] 
2024-12-12 11:34:51.895214: Epoch time: 43.11 s 
2024-12-12 11:34:52.434578:  
2024-12-12 11:34:52.441098: Epoch 84 
2024-12-12 11:34:52.444603: Current learning rate: 0.00192 
2024-12-12 11:35:35.546173: train_loss -0.9534 
2024-12-12 11:35:35.551183: val_loss -0.9218 
2024-12-12 11:35:35.554693: Pseudo dice [np.float32(0.9364)] 
2024-12-12 11:35:35.557199: Epoch time: 43.11 s 
2024-12-12 11:35:36.255771:  
2024-12-12 11:35:36.261339: Epoch 85 
2024-12-12 11:35:36.264523: Current learning rate: 0.00181 
2024-12-12 11:36:19.356633: train_loss -0.9517 
2024-12-12 11:36:19.362221: val_loss -0.9229 
2024-12-12 11:36:19.365731: Pseudo dice [np.float32(0.9369)] 
2024-12-12 11:36:19.368239: Epoch time: 43.1 s 
2024-12-12 11:36:19.372246: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2024-12-12 11:36:20.078350:  
2024-12-12 11:36:20.082933: Epoch 86 
2024-12-12 11:36:20.086488: Current learning rate: 0.0017 
2024-12-12 11:37:03.197160: train_loss -0.9558 
2024-12-12 11:37:03.203330: val_loss -0.9225 
2024-12-12 11:37:03.206428: Pseudo dice [np.float32(0.9369)] 
2024-12-12 11:37:03.209506: Epoch time: 43.12 s 
2024-12-12 11:37:03.212574: Yayy! New best EMA pseudo Dice: 0.9361000061035156 
2024-12-12 11:37:03.922814:  
2024-12-12 11:37:03.928352: Epoch 87 
2024-12-12 11:37:03.931902: Current learning rate: 0.00159 
2024-12-12 11:37:47.040406: train_loss -0.9564 
2024-12-12 11:37:47.045919: val_loss -0.9205 
2024-12-12 11:37:47.049429: Pseudo dice [np.float32(0.9356)] 
2024-12-12 11:37:47.051937: Epoch time: 43.12 s 
2024-12-12 11:37:47.583094:  
2024-12-12 11:37:47.587121: Epoch 88 
2024-12-12 11:37:47.590660: Current learning rate: 0.00148 
2024-12-12 11:38:30.674421: train_loss -0.9573 
2024-12-12 11:38:30.679959: val_loss -0.9202 
2024-12-12 11:38:30.682465: Pseudo dice [np.float32(0.9353)] 
2024-12-12 11:38:30.685971: Epoch time: 43.09 s 
2024-12-12 11:38:31.227526:  
2024-12-12 11:38:31.233085: Epoch 89 
2024-12-12 11:38:31.236667: Current learning rate: 0.00137 
2024-12-12 11:39:14.348869: train_loss -0.9561 
2024-12-12 11:39:14.354458: val_loss -0.9195 
2024-12-12 11:39:14.356974: Pseudo dice [np.float32(0.9345)] 
2024-12-12 11:39:14.360422: Epoch time: 43.12 s 
2024-12-12 11:39:14.893876:  
2024-12-12 11:39:14.899886: Epoch 90 
2024-12-12 11:39:14.902894: Current learning rate: 0.00126 
2024-12-12 11:39:57.997633: train_loss -0.9564 
2024-12-12 11:39:58.003171: val_loss -0.9216 
2024-12-12 11:39:58.007184: Pseudo dice [np.float32(0.9357)] 
2024-12-12 11:39:58.009690: Epoch time: 43.1 s 
2024-12-12 11:39:58.549808:  
2024-12-12 11:39:58.555347: Epoch 91 
2024-12-12 11:39:58.559455: Current learning rate: 0.00115 
2024-12-12 11:40:41.667296: train_loss -0.9556 
2024-12-12 11:40:41.672307: val_loss -0.9205 
2024-12-12 11:40:41.675816: Pseudo dice [np.float32(0.9351)] 
2024-12-12 11:40:41.679325: Epoch time: 43.12 s 
2024-12-12 11:40:42.214511:  
2024-12-12 11:40:42.219545: Epoch 92 
2024-12-12 11:40:42.222790: Current learning rate: 0.00103 
2024-12-12 11:41:25.314126: train_loss -0.956 
2024-12-12 11:41:25.321224: val_loss -0.9205 
2024-12-12 11:41:25.323735: Pseudo dice [np.float32(0.9354)] 
2024-12-12 11:41:25.327745: Epoch time: 43.1 s 
2024-12-12 11:41:25.867459:  
2024-12-12 11:41:25.873312: Epoch 93 
2024-12-12 11:41:25.875818: Current learning rate: 0.00091 
2024-12-12 11:42:08.953272: train_loss -0.9566 
2024-12-12 11:42:08.958284: val_loss -0.9199 
2024-12-12 11:42:08.962296: Pseudo dice [np.float32(0.9349)] 
2024-12-12 11:42:08.964803: Epoch time: 43.09 s 
2024-12-12 11:42:09.666228:  
2024-12-12 11:42:09.671277: Epoch 94 
2024-12-12 11:42:09.673800: Current learning rate: 0.00079 
2024-12-12 11:42:52.791713: train_loss -0.9559 
2024-12-12 11:42:52.797281: val_loss -0.9207 
2024-12-12 11:42:52.801321: Pseudo dice [np.float32(0.9355)] 
2024-12-12 11:42:52.804365: Epoch time: 43.13 s 
2024-12-12 11:42:53.364422:  
2024-12-12 11:42:53.368515: Epoch 95 
2024-12-12 11:42:53.373103: Current learning rate: 0.00067 
2024-12-12 11:43:36.524883: train_loss -0.9577 
2024-12-12 11:43:36.529970: val_loss -0.9221 
2024-12-12 11:43:36.534583: Pseudo dice [np.float32(0.9369)] 
2024-12-12 11:43:36.537137: Epoch time: 43.16 s 
2024-12-12 11:43:37.078530:  
2024-12-12 11:43:37.084073: Epoch 96 
2024-12-12 11:43:37.087102: Current learning rate: 0.00055 
2024-12-12 11:44:20.219261: train_loss -0.9572 
2024-12-12 11:44:20.225277: val_loss -0.9222 
2024-12-12 11:44:20.228287: Pseudo dice [np.float32(0.9368)] 
2024-12-12 11:44:20.231796: Epoch time: 43.14 s 
2024-12-12 11:44:20.774019:  
2024-12-12 11:44:20.779075: Epoch 97 
2024-12-12 11:44:20.782146: Current learning rate: 0.00043 
2024-12-12 11:45:05.545574: train_loss -0.9563 
2024-12-12 11:45:05.551196: val_loss -0.922 
2024-12-12 11:45:05.553749: Pseudo dice [np.float32(0.9367)] 
2024-12-12 11:45:05.557788: Epoch time: 44.77 s 
2024-12-12 11:45:06.105467:  
2024-12-12 11:45:06.111121: Epoch 98 
2024-12-12 11:45:06.114199: Current learning rate: 0.0003 
2024-12-12 11:45:49.201881: train_loss -0.9587 
2024-12-12 11:45:49.208430: val_loss -0.9218 
2024-12-12 11:45:49.210942: Pseudo dice [np.float32(0.9366)] 
2024-12-12 11:45:49.214452: Epoch time: 43.1 s 
2024-12-12 11:45:49.764021:  
2024-12-12 11:45:49.770051: Epoch 99 
2024-12-12 11:45:49.772564: Current learning rate: 0.00016 
2024-12-12 11:46:36.364287: train_loss -0.9584 
2024-12-12 11:46:36.369301: val_loss -0.9211 
2024-12-12 11:46:36.372812: Pseudo dice [np.float32(0.9357)] 
2024-12-12 11:46:36.375824: Epoch time: 46.6 s 
2024-12-12 11:46:37.521501: Training done. 
2024-12-12 11:46:37.602012: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-12 11:46:37.610012: The split file contains 5 splits. 
2024-12-12 11:46:37.617012: Desired fold for training: 0 
2024-12-12 11:46:37.623012: This split has 16 training and 4 validation cases. 
2024-12-12 11:46:37.629013: predicting la_007 
2024-12-12 11:46:37.636012: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2024-12-12 11:46:44.091671: predicting la_016 
2024-12-12 11:46:44.103178: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2024-12-12 11:46:46.502174: predicting la_021 
2024-12-12 11:46:46.510174: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2024-12-12 11:46:48.917758: predicting la_024 
2024-12-12 11:46:48.926760: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2024-12-12 11:46:58.137015: Validation complete 
2024-12-12 11:46:58.143013: Mean Validation Dice:  0.9348694212086288 
