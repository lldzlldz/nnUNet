
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-16 02:27:49.884466: do_dummy_2d_data_aug: False 
2025-03-16 02:27:49.889466: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-16 02:27:49.892466: The split file contains 5 splits. 
2025-03-16 02:27:49.895466: Desired fold for training: 0 
2025-03-16 02:27:49.898466: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2025-03-16 02:27:57.004724: unpacking dataset... 
2025-03-16 02:27:57.173493: unpacking done... 
2025-03-16 02:28:00.149082:  
2025-03-16 02:28:00.154092: Epoch 0 
2025-03-16 02:28:00.157109: Current learning rate: 0.01 
2025-03-16 02:28:46.860741: train_loss -0.5954 
2025-03-16 02:28:46.865751: val_loss -0.8568 
2025-03-16 02:28:46.869768: Pseudo dice [np.float32(0.8895)] 
2025-03-16 02:28:46.873283: Epoch time: 46.71 s 
2025-03-16 02:28:46.875792: Yayy! New best EMA pseudo Dice: 0.8895000219345093 
2025-03-16 02:28:47.471010:  
2025-03-16 02:28:47.477080: Epoch 1 
2025-03-16 02:28:47.480128: Current learning rate: 0.00991 
2025-03-16 02:29:29.858737: train_loss -0.8591 
2025-03-16 02:29:29.864750: val_loss -0.8846 
2025-03-16 02:29:29.868258: Pseudo dice [np.float32(0.9119)] 
2025-03-16 02:29:29.871272: Epoch time: 42.39 s 
2025-03-16 02:29:29.874782: Yayy! New best EMA pseudo Dice: 0.8917999863624573 
2025-03-16 02:29:30.547171:  
2025-03-16 02:29:30.551683: Epoch 2 
2025-03-16 02:29:30.554694: Current learning rate: 0.00982 
2025-03-16 02:30:12.927285: train_loss -0.8876 
2025-03-16 02:30:12.933800: val_loss -0.8974 
2025-03-16 02:30:12.937313: Pseudo dice [np.float32(0.9209)] 
2025-03-16 02:30:12.939824: Epoch time: 42.38 s 
2025-03-16 02:30:12.943330: Yayy! New best EMA pseudo Dice: 0.8946999907493591 
2025-03-16 02:30:13.642765:  
2025-03-16 02:30:13.648309: Epoch 3 
2025-03-16 02:30:13.650853: Current learning rate: 0.00973 
2025-03-16 02:30:56.018753: train_loss -0.8967 
2025-03-16 02:30:56.024771: val_loss -0.9053 
2025-03-16 02:30:56.027278: Pseudo dice [np.float32(0.9265)] 
2025-03-16 02:30:56.031286: Epoch time: 42.38 s 
2025-03-16 02:30:56.033792: Yayy! New best EMA pseudo Dice: 0.8978999853134155 
2025-03-16 02:30:56.711907:  
2025-03-16 02:30:56.716944: Epoch 4 
2025-03-16 02:30:56.720026: Current learning rate: 0.00964 
2025-03-16 02:31:39.123014: train_loss -0.9033 
2025-03-16 02:31:39.129624: val_loss -0.9076 
2025-03-16 02:31:39.132656: Pseudo dice [np.float32(0.9275)] 
2025-03-16 02:31:39.135174: Epoch time: 42.41 s 
2025-03-16 02:31:39.138694: Yayy! New best EMA pseudo Dice: 0.9007999897003174 
2025-03-16 02:31:39.943857:  
2025-03-16 02:31:39.949412: Epoch 5 
2025-03-16 02:31:39.952998: Current learning rate: 0.00955 
2025-03-16 02:32:22.385196: train_loss -0.9087 
2025-03-16 02:32:22.391265: val_loss -0.9118 
2025-03-16 02:32:22.393293: Pseudo dice [np.float32(0.9298)] 
2025-03-16 02:32:22.397354: Epoch time: 42.44 s 
2025-03-16 02:32:22.400943: Yayy! New best EMA pseudo Dice: 0.9036999940872192 
2025-03-16 02:32:23.081733:  
2025-03-16 02:32:23.087261: Epoch 6 
2025-03-16 02:32:23.089782: Current learning rate: 0.00946 
2025-03-16 02:33:05.470692: train_loss -0.9225 
2025-03-16 02:33:05.476219: val_loss -0.915 
2025-03-16 02:33:05.478723: Pseudo dice [np.float32(0.9333)] 
2025-03-16 02:33:05.482230: Epoch time: 42.39 s 
2025-03-16 02:33:05.486238: Yayy! New best EMA pseudo Dice: 0.9067000150680542 
2025-03-16 02:33:06.151910:  
2025-03-16 02:33:06.156438: Epoch 7 
2025-03-16 02:33:06.158981: Current learning rate: 0.00937 
2025-03-16 02:33:48.565052: train_loss -0.9248 
2025-03-16 02:33:48.570622: val_loss -0.9194 
2025-03-16 02:33:48.573128: Pseudo dice [np.float32(0.9367)] 
2025-03-16 02:33:48.577142: Epoch time: 42.41 s 
2025-03-16 02:33:48.579648: Yayy! New best EMA pseudo Dice: 0.9096999764442444 
2025-03-16 02:33:49.259475:  
2025-03-16 02:33:49.264992: Epoch 8 
2025-03-16 02:33:49.267499: Current learning rate: 0.00928 
2025-03-16 02:34:31.732475: train_loss -0.9266 
2025-03-16 02:34:31.738499: val_loss -0.9116 
2025-03-16 02:34:31.741698: Pseudo dice [np.float32(0.9284)] 
2025-03-16 02:34:31.745204: Epoch time: 42.47 s 
2025-03-16 02:34:31.747708: Yayy! New best EMA pseudo Dice: 0.9115999937057495 
2025-03-16 02:34:32.433166:  
2025-03-16 02:34:32.438717: Epoch 9 
2025-03-16 02:34:32.441261: Current learning rate: 0.00919 
2025-03-16 02:35:14.819453: train_loss -0.9262 
2025-03-16 02:35:14.825030: val_loss -0.9163 
2025-03-16 02:35:14.828066: Pseudo dice [np.float32(0.9329)] 
2025-03-16 02:35:14.830637: Epoch time: 42.39 s 
2025-03-16 02:35:14.834213: Yayy! New best EMA pseudo Dice: 0.9136999845504761 
2025-03-16 02:35:15.502853:  
2025-03-16 02:35:15.507879: Epoch 10 
2025-03-16 02:35:15.510469: Current learning rate: 0.0091 
2025-03-16 02:35:57.844512: train_loss -0.9346 
2025-03-16 02:35:57.849132: val_loss -0.9177 
2025-03-16 02:35:57.853305: Pseudo dice [np.float32(0.9353)] 
2025-03-16 02:35:57.856871: Epoch time: 42.34 s 
2025-03-16 02:35:57.859416: Yayy! New best EMA pseudo Dice: 0.9158999919891357 
2025-03-16 02:35:58.535357:  
2025-03-16 02:35:58.540894: Epoch 11 
2025-03-16 02:35:58.544406: Current learning rate: 0.009 
2025-03-16 02:36:40.952292: train_loss -0.9376 
2025-03-16 02:36:40.958355: val_loss -0.9176 
2025-03-16 02:36:40.964441: Pseudo dice [np.float32(0.9347)] 
2025-03-16 02:36:40.967950: Epoch time: 42.42 s 
2025-03-16 02:36:40.971465: Yayy! New best EMA pseudo Dice: 0.9176999926567078 
2025-03-16 02:36:41.634820:  
2025-03-16 02:36:41.640365: Epoch 12 
2025-03-16 02:36:41.643471: Current learning rate: 0.00891 
2025-03-16 02:37:24.018640: train_loss -0.9344 
2025-03-16 02:37:24.023675: val_loss -0.9207 
2025-03-16 02:37:24.027729: Pseudo dice [np.float32(0.9366)] 
2025-03-16 02:37:24.031329: Epoch time: 42.38 s 
2025-03-16 02:37:24.033465: Yayy! New best EMA pseudo Dice: 0.9196000099182129 
2025-03-16 02:37:24.848717:  
2025-03-16 02:37:24.854252: Epoch 13 
2025-03-16 02:37:24.856762: Current learning rate: 0.00882 
2025-03-16 02:38:07.257269: train_loss -0.9149 
2025-03-16 02:38:07.262872: val_loss -0.9134 
2025-03-16 02:38:07.265900: Pseudo dice [np.float32(0.9303)] 
2025-03-16 02:38:07.269418: Epoch time: 42.41 s 
2025-03-16 02:38:07.271932: Yayy! New best EMA pseudo Dice: 0.9207000136375427 
2025-03-16 02:38:07.965994:  
2025-03-16 02:38:07.971033: Epoch 14 
2025-03-16 02:38:07.974549: Current learning rate: 0.00873 
2025-03-16 02:38:50.397933: train_loss -0.925 
2025-03-16 02:38:50.404446: val_loss -0.9175 
2025-03-16 02:38:50.406953: Pseudo dice [np.float32(0.9338)] 
2025-03-16 02:38:50.410465: Epoch time: 42.43 s 
2025-03-16 02:38:50.412972: Yayy! New best EMA pseudo Dice: 0.921999990940094 
2025-03-16 02:38:51.092709:  
2025-03-16 02:38:51.098736: Epoch 15 
2025-03-16 02:38:51.102248: Current learning rate: 0.00864 
2025-03-16 02:39:33.529143: train_loss -0.9329 
2025-03-16 02:39:33.535160: val_loss -0.9185 
2025-03-16 02:39:33.539173: Pseudo dice [np.float32(0.9345)] 
2025-03-16 02:39:33.541681: Epoch time: 42.44 s 
2025-03-16 02:39:33.545194: Yayy! New best EMA pseudo Dice: 0.92330002784729 
2025-03-16 02:39:34.224327:  
2025-03-16 02:39:34.229846: Epoch 16 
2025-03-16 02:39:34.231853: Current learning rate: 0.00855 
2025-03-16 02:40:16.659758: train_loss -0.9301 
2025-03-16 02:40:16.664853: val_loss -0.9152 
2025-03-16 02:40:16.667400: Pseudo dice [np.float32(0.9325)] 
2025-03-16 02:40:16.671978: Epoch time: 42.44 s 
2025-03-16 02:40:16.676668: Yayy! New best EMA pseudo Dice: 0.9241999983787537 
2025-03-16 02:40:17.366525:  
2025-03-16 02:40:17.371540: Epoch 17 
2025-03-16 02:40:17.374904: Current learning rate: 0.00846 
2025-03-16 02:40:59.767623: train_loss -0.935 
2025-03-16 02:40:59.772663: val_loss -0.9231 
2025-03-16 02:40:59.776278: Pseudo dice [np.float32(0.9389)] 
2025-03-16 02:40:59.779423: Epoch time: 42.4 s 
2025-03-16 02:40:59.782564: Yayy! New best EMA pseudo Dice: 0.925599992275238 
2025-03-16 02:41:00.467699:  
2025-03-16 02:41:00.473224: Epoch 18 
2025-03-16 02:41:00.476740: Current learning rate: 0.00836 
2025-03-16 02:41:42.868135: train_loss -0.9397 
2025-03-16 02:41:42.873677: val_loss -0.9197 
2025-03-16 02:41:42.877565: Pseudo dice [np.float32(0.9355)] 
2025-03-16 02:41:42.880071: Epoch time: 42.4 s 
2025-03-16 02:41:42.884584: Yayy! New best EMA pseudo Dice: 0.9265999794006348 
2025-03-16 02:41:43.580979:  
2025-03-16 02:41:43.586494: Epoch 19 
2025-03-16 02:41:43.589001: Current learning rate: 0.00827 
2025-03-16 02:42:26.030426: train_loss -0.9427 
2025-03-16 02:42:26.035962: val_loss -0.922 
2025-03-16 02:42:26.039071: Pseudo dice [np.float32(0.9376)] 
2025-03-16 02:42:26.042587: Epoch time: 42.45 s 
2025-03-16 02:42:26.046078: Yayy! New best EMA pseudo Dice: 0.9276999831199646 
2025-03-16 02:42:26.737606:  
2025-03-16 02:42:26.743654: Epoch 20 
2025-03-16 02:42:26.746720: Current learning rate: 0.00818 
2025-03-16 02:43:09.131581: train_loss -0.9458 
2025-03-16 02:43:09.137204: val_loss -0.9203 
2025-03-16 02:43:09.140718: Pseudo dice [np.float32(0.9362)] 
2025-03-16 02:43:09.143226: Epoch time: 42.39 s 
2025-03-16 02:43:09.147237: Yayy! New best EMA pseudo Dice: 0.928600013256073 
2025-03-16 02:43:09.983554:  
2025-03-16 02:43:09.989086: Epoch 21 
2025-03-16 02:43:09.992149: Current learning rate: 0.00809 
2025-03-16 02:43:52.388215: train_loss -0.9487 
2025-03-16 02:43:52.393237: val_loss -0.9234 
2025-03-16 02:43:52.397248: Pseudo dice [np.float32(0.9389)] 
2025-03-16 02:43:52.400763: Epoch time: 42.41 s 
2025-03-16 02:43:52.403269: Yayy! New best EMA pseudo Dice: 0.9296000003814697 
2025-03-16 02:43:53.080869:  
2025-03-16 02:43:53.086975: Epoch 22 
2025-03-16 02:43:53.090487: Current learning rate: 0.008 
2025-03-16 02:44:35.487882: train_loss -0.951 
2025-03-16 02:44:35.492900: val_loss -0.9192 
2025-03-16 02:44:35.496410: Pseudo dice [np.float32(0.9359)] 
2025-03-16 02:44:35.500416: Epoch time: 42.41 s 
2025-03-16 02:44:35.502920: Yayy! New best EMA pseudo Dice: 0.9301999807357788 
2025-03-16 02:44:36.166095:  
2025-03-16 02:44:36.171641: Epoch 23 
2025-03-16 02:44:36.174674: Current learning rate: 0.0079 
2025-03-16 02:45:18.581019: train_loss -0.949 
2025-03-16 02:45:18.586034: val_loss -0.917 
2025-03-16 02:45:18.590144: Pseudo dice [np.float32(0.9334)] 
2025-03-16 02:45:18.593150: Epoch time: 42.42 s 
2025-03-16 02:45:18.596656: Yayy! New best EMA pseudo Dice: 0.9304999709129333 
2025-03-16 02:45:19.254521:  
2025-03-16 02:45:19.260576: Epoch 24 
2025-03-16 02:45:19.263644: Current learning rate: 0.00781 
2025-03-16 02:46:01.665159: train_loss -0.9468 
2025-03-16 02:46:01.670733: val_loss -0.9123 
2025-03-16 02:46:01.672935: Pseudo dice [np.float32(0.9299)] 
2025-03-16 02:46:01.676442: Epoch time: 42.41 s 
2025-03-16 02:46:02.185051:  
2025-03-16 02:46:02.190601: Epoch 25 
2025-03-16 02:46:02.194165: Current learning rate: 0.00772 
2025-03-16 02:46:44.596961: train_loss -0.9445 
2025-03-16 02:46:44.603547: val_loss -0.92 
2025-03-16 02:46:44.607110: Pseudo dice [np.float32(0.9359)] 
2025-03-16 02:46:44.610187: Epoch time: 42.41 s 
2025-03-16 02:46:44.612722: Yayy! New best EMA pseudo Dice: 0.9309999942779541 
2025-03-16 02:46:45.280363:  
2025-03-16 02:46:45.286382: Epoch 26 
2025-03-16 02:46:45.290393: Current learning rate: 0.00763 
2025-03-16 02:47:27.712530: train_loss -0.9478 
2025-03-16 02:47:27.717541: val_loss -0.9216 
2025-03-16 02:47:27.721056: Pseudo dice [np.float32(0.9376)] 
2025-03-16 02:47:27.724562: Epoch time: 42.43 s 
2025-03-16 02:47:27.727578: Yayy! New best EMA pseudo Dice: 0.9316999912261963 
2025-03-16 02:47:28.397454:  
2025-03-16 02:47:28.403110: Epoch 27 
2025-03-16 02:47:28.407123: Current learning rate: 0.00753 
2025-03-16 02:48:10.828913: train_loss -0.9535 
2025-03-16 02:48:10.834338: val_loss -0.9223 
2025-03-16 02:48:10.837852: Pseudo dice [np.float32(0.938)] 
2025-03-16 02:48:10.841401: Epoch time: 42.43 s 
2025-03-16 02:48:10.844756: Yayy! New best EMA pseudo Dice: 0.9322999715805054 
2025-03-16 02:48:11.511371:  
2025-03-16 02:48:11.516945: Epoch 28 
2025-03-16 02:48:11.519493: Current learning rate: 0.00744 
2025-03-16 02:48:53.962260: train_loss -0.9565 
2025-03-16 02:48:53.967311: val_loss -0.9209 
2025-03-16 02:48:53.970821: Pseudo dice [np.float32(0.937)] 
2025-03-16 02:48:53.974328: Epoch time: 42.45 s 
2025-03-16 02:48:53.977337: Yayy! New best EMA pseudo Dice: 0.9327999949455261 
2025-03-16 02:48:54.787118:  
2025-03-16 02:48:54.792678: Epoch 29 
2025-03-16 02:48:54.795720: Current learning rate: 0.00735 
2025-03-16 02:49:37.184690: train_loss -0.957 
2025-03-16 02:49:37.191210: val_loss -0.9232 
2025-03-16 02:49:37.196777: Pseudo dice [np.float32(0.9388)] 
2025-03-16 02:49:37.199323: Epoch time: 42.4 s 
2025-03-16 02:49:37.204410: Yayy! New best EMA pseudo Dice: 0.9333999752998352 
2025-03-16 02:49:37.882622:  
2025-03-16 02:49:37.888655: Epoch 30 
2025-03-16 02:49:37.891160: Current learning rate: 0.00725 
2025-03-16 02:50:20.305483: train_loss -0.9578 
2025-03-16 02:50:20.311517: val_loss -0.9215 
2025-03-16 02:50:20.314650: Pseudo dice [np.float32(0.9379)] 
2025-03-16 02:50:20.318158: Epoch time: 42.42 s 
2025-03-16 02:50:20.321168: Yayy! New best EMA pseudo Dice: 0.9337999820709229 
2025-03-16 02:50:21.006186:  
2025-03-16 02:50:21.012227: Epoch 31 
2025-03-16 02:50:21.015737: Current learning rate: 0.00716 
2025-03-16 02:51:03.452485: train_loss -0.958 
2025-03-16 02:51:03.458559: val_loss -0.9194 
2025-03-16 02:51:03.462514: Pseudo dice [np.float32(0.9359)] 
2025-03-16 02:51:03.465075: Epoch time: 42.45 s 
2025-03-16 02:51:03.468134: Yayy! New best EMA pseudo Dice: 0.9340000152587891 
2025-03-16 02:51:04.138982:  
2025-03-16 02:51:04.144579: Epoch 32 
2025-03-16 02:51:04.147639: Current learning rate: 0.00707 
2025-03-16 02:51:46.512070: train_loss -0.957 
2025-03-16 02:51:46.518137: val_loss -0.9208 
2025-03-16 02:51:46.520158: Pseudo dice [np.float32(0.9374)] 
2025-03-16 02:51:46.524235: Epoch time: 42.37 s 
2025-03-16 02:51:46.527352: Yayy! New best EMA pseudo Dice: 0.9344000220298767 
2025-03-16 02:51:47.203756:  
2025-03-16 02:51:47.209268: Epoch 33 
2025-03-16 02:51:47.211777: Current learning rate: 0.00697 
2025-03-16 02:52:29.648543: train_loss -0.9589 
2025-03-16 02:52:29.654101: val_loss -0.916 
2025-03-16 02:52:29.658107: Pseudo dice [np.float32(0.9344)] 
2025-03-16 02:52:29.661618: Epoch time: 42.45 s 
2025-03-16 02:52:30.184720:  
2025-03-16 02:52:30.190271: Epoch 34 
2025-03-16 02:52:30.192789: Current learning rate: 0.00688 
2025-03-16 02:53:12.603572: train_loss -0.9593 
2025-03-16 02:53:12.608615: val_loss -0.9205 
2025-03-16 02:53:12.612129: Pseudo dice [np.float32(0.937)] 
2025-03-16 02:53:12.615638: Epoch time: 42.42 s 
2025-03-16 02:53:12.618144: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2025-03-16 02:53:13.308750:  
2025-03-16 02:53:13.314264: Epoch 35 
2025-03-16 02:53:13.317780: Current learning rate: 0.00679 
2025-03-16 02:53:55.708186: train_loss -0.9594 
2025-03-16 02:53:55.713716: val_loss -0.9157 
2025-03-16 02:53:55.716227: Pseudo dice [np.float32(0.9334)] 
2025-03-16 02:53:55.720237: Epoch time: 42.4 s 
2025-03-16 02:53:56.244065:  
2025-03-16 02:53:56.250136: Epoch 36 
2025-03-16 02:53:56.253188: Current learning rate: 0.00669 
2025-03-16 02:54:38.649170: train_loss -0.9515 
2025-03-16 02:54:38.655172: val_loss -0.9205 
2025-03-16 02:54:38.657680: Pseudo dice [np.float32(0.9359)] 
2025-03-16 02:54:38.661691: Epoch time: 42.41 s 
2025-03-16 02:54:38.664200: Yayy! New best EMA pseudo Dice: 0.9347000122070312 
2025-03-16 02:54:39.499274:  
2025-03-16 02:54:39.504881: Epoch 37 
2025-03-16 02:54:39.507933: Current learning rate: 0.0066 
2025-03-16 02:55:21.887484: train_loss -0.9576 
2025-03-16 02:55:21.894077: val_loss -0.9212 
2025-03-16 02:55:21.897688: Pseudo dice [np.float32(0.9375)] 
2025-03-16 02:55:21.900339: Epoch time: 42.39 s 
2025-03-16 02:55:21.903868: Yayy! New best EMA pseudo Dice: 0.9348999857902527 
2025-03-16 02:55:22.600783:  
2025-03-16 02:55:22.608301: Epoch 38 
2025-03-16 02:55:22.613315: Current learning rate: 0.0065 
2025-03-16 02:56:05.018425: train_loss -0.9594 
2025-03-16 02:56:05.024587: val_loss -0.9197 
2025-03-16 02:56:05.027092: Pseudo dice [np.float32(0.9371)] 
2025-03-16 02:56:05.030598: Epoch time: 42.42 s 
2025-03-16 02:56:05.034102: Yayy! New best EMA pseudo Dice: 0.9351000189781189 
2025-03-16 02:56:05.714424:  
2025-03-16 02:56:05.719434: Epoch 39 
2025-03-16 02:56:05.722444: Current learning rate: 0.00641 
2025-03-16 02:56:48.148239: train_loss -0.9562 
2025-03-16 02:56:48.153289: val_loss -0.9207 
2025-03-16 02:56:48.156801: Pseudo dice [np.float32(0.9373)] 
2025-03-16 02:56:48.160815: Epoch time: 42.43 s 
2025-03-16 02:56:48.163321: Yayy! New best EMA pseudo Dice: 0.9354000091552734 
2025-03-16 02:56:48.860893:  
2025-03-16 02:56:48.865939: Epoch 40 
2025-03-16 02:56:48.869607: Current learning rate: 0.00631 
2025-03-16 02:57:31.286472: train_loss -0.9587 
2025-03-16 02:57:31.291488: val_loss -0.9199 
2025-03-16 02:57:31.295001: Pseudo dice [np.float32(0.9365)] 
2025-03-16 02:57:31.299015: Epoch time: 42.43 s 
2025-03-16 02:57:31.301527: Yayy! New best EMA pseudo Dice: 0.9355000257492065 
2025-03-16 02:57:32.004930:  
2025-03-16 02:57:32.010692: Epoch 41 
2025-03-16 02:57:32.014205: Current learning rate: 0.00622 
2025-03-16 02:58:14.425464: train_loss -0.9591 
2025-03-16 02:58:14.431150: val_loss -0.9241 
2025-03-16 02:58:14.434197: Pseudo dice [np.float32(0.9397)] 
2025-03-16 02:58:14.437248: Epoch time: 42.42 s 
2025-03-16 02:58:14.440774: Yayy! New best EMA pseudo Dice: 0.9358999729156494 
2025-03-16 02:58:15.105289:  
2025-03-16 02:58:15.110349: Epoch 42 
2025-03-16 02:58:15.113863: Current learning rate: 0.00612 
2025-03-16 02:58:57.505217: train_loss -0.9625 
2025-03-16 02:58:57.510240: val_loss -0.9237 
2025-03-16 02:58:57.514251: Pseudo dice [np.float32(0.9398)] 
2025-03-16 02:58:57.517761: Epoch time: 42.4 s 
2025-03-16 02:58:57.520268: Yayy! New best EMA pseudo Dice: 0.9362999796867371 
2025-03-16 02:58:58.185477:  
2025-03-16 02:58:58.191532: Epoch 43 
2025-03-16 02:58:58.194602: Current learning rate: 0.00603 
2025-03-16 02:59:40.559686: train_loss -0.9616 
2025-03-16 02:59:40.566211: val_loss -0.9235 
2025-03-16 02:59:40.569723: Pseudo dice [np.float32(0.9393)] 
2025-03-16 02:59:40.572230: Epoch time: 42.37 s 
2025-03-16 02:59:40.575737: Yayy! New best EMA pseudo Dice: 0.9366000294685364 
2025-03-16 02:59:41.252928:  
2025-03-16 02:59:41.257963: Epoch 44 
2025-03-16 02:59:41.261026: Current learning rate: 0.00593 
2025-03-16 03:00:23.642869: train_loss -0.9626 
2025-03-16 03:00:23.648907: val_loss -0.9194 
2025-03-16 03:00:23.652826: Pseudo dice [np.float32(0.9367)] 
2025-03-16 03:00:23.655885: Epoch time: 42.39 s 
2025-03-16 03:00:23.659396: Yayy! New best EMA pseudo Dice: 0.9366000294685364 
2025-03-16 03:00:24.482301:  
2025-03-16 03:00:24.488334: Epoch 45 
2025-03-16 03:00:24.491430: Current learning rate: 0.00584 
2025-03-16 03:01:06.888705: train_loss -0.958 
2025-03-16 03:01:06.894719: val_loss -0.9201 
2025-03-16 03:01:06.897227: Pseudo dice [np.float32(0.9363)] 
2025-03-16 03:01:06.901239: Epoch time: 42.41 s 
2025-03-16 03:01:07.408851:  
2025-03-16 03:01:07.414915: Epoch 46 
2025-03-16 03:01:07.417980: Current learning rate: 0.00574 
2025-03-16 03:01:49.793534: train_loss -0.9616 
2025-03-16 03:01:49.798548: val_loss -0.9211 
2025-03-16 03:01:49.802058: Pseudo dice [np.float32(0.9374)] 
2025-03-16 03:01:49.806068: Epoch time: 42.38 s 
2025-03-16 03:01:49.808572: Yayy! New best EMA pseudo Dice: 0.9366999864578247 
2025-03-16 03:01:50.464910:  
2025-03-16 03:01:50.470463: Epoch 47 
2025-03-16 03:01:50.473509: Current learning rate: 0.00565 
2025-03-16 03:02:32.858970: train_loss -0.9574 
2025-03-16 03:02:32.864990: val_loss -0.9221 
2025-03-16 03:02:32.868009: Pseudo dice [np.float32(0.9378)] 
2025-03-16 03:02:32.871517: Epoch time: 42.39 s 
2025-03-16 03:02:32.875020: Yayy! New best EMA pseudo Dice: 0.9368000030517578 
2025-03-16 03:02:33.537493:  
2025-03-16 03:02:33.544050: Epoch 48 
2025-03-16 03:02:33.547067: Current learning rate: 0.00555 
2025-03-16 03:03:15.954170: train_loss -0.9616 
2025-03-16 03:03:15.959212: val_loss -0.9225 
2025-03-16 03:03:15.961750: Pseudo dice [np.float32(0.9389)] 
2025-03-16 03:03:15.965823: Epoch time: 42.42 s 
2025-03-16 03:03:15.968898: Yayy! New best EMA pseudo Dice: 0.9369999766349792 
2025-03-16 03:03:16.630160:  
2025-03-16 03:03:16.635672: Epoch 49 
2025-03-16 03:03:16.639181: Current learning rate: 0.00546 
2025-03-16 03:03:59.002122: train_loss -0.9643 
2025-03-16 03:03:59.007653: val_loss -0.9204 
2025-03-16 03:03:59.011167: Pseudo dice [np.float32(0.9374)] 
2025-03-16 03:03:59.014675: Epoch time: 42.37 s 
2025-03-16 03:03:59.156793: Yayy! New best EMA pseudo Dice: 0.9369999766349792 
2025-03-16 03:03:59.819533:  
2025-03-16 03:03:59.825077: Epoch 50 
2025-03-16 03:03:59.827615: Current learning rate: 0.00536 
2025-03-16 03:04:42.231987: train_loss -0.963 
2025-03-16 03:04:42.238011: val_loss -0.9203 
2025-03-16 03:04:42.240520: Pseudo dice [np.float32(0.9372)] 
2025-03-16 03:04:42.244086: Epoch time: 42.41 s 
2025-03-16 03:04:42.247126: Yayy! New best EMA pseudo Dice: 0.9369999766349792 
2025-03-16 03:04:42.926486:  
2025-03-16 03:04:42.931999: Epoch 51 
2025-03-16 03:04:42.934509: Current learning rate: 0.00526 
2025-03-16 03:05:25.285404: train_loss -0.9646 
2025-03-16 03:05:25.291564: val_loss -0.9214 
2025-03-16 03:05:25.295112: Pseudo dice [np.float32(0.9383)] 
2025-03-16 03:05:25.298132: Epoch time: 42.36 s 
2025-03-16 03:05:25.301663: Yayy! New best EMA pseudo Dice: 0.9372000098228455 
2025-03-16 03:05:25.968643:  
2025-03-16 03:05:25.974259: Epoch 52 
2025-03-16 03:05:25.977819: Current learning rate: 0.00517 
2025-03-16 03:06:08.374406: train_loss -0.9631 
2025-03-16 03:06:08.380417: val_loss -0.92 
2025-03-16 03:06:08.383429: Pseudo dice [np.float32(0.9371)] 
2025-03-16 03:06:08.386939: Epoch time: 42.41 s 
2025-03-16 03:06:08.901138:  
2025-03-16 03:06:08.906166: Epoch 53 
2025-03-16 03:06:08.909171: Current learning rate: 0.00507 
2025-03-16 03:06:51.382540: train_loss -0.966 
2025-03-16 03:06:51.387562: val_loss -0.9237 
2025-03-16 03:06:51.391577: Pseudo dice [np.float32(0.9401)] 
2025-03-16 03:06:51.394087: Epoch time: 42.48 s 
2025-03-16 03:06:51.397601: Yayy! New best EMA pseudo Dice: 0.9373999834060669 
2025-03-16 03:06:52.071727:  
2025-03-16 03:06:52.077248: Epoch 54 
2025-03-16 03:06:52.080357: Current learning rate: 0.00497 
2025-03-16 03:07:34.509869: train_loss -0.9645 
2025-03-16 03:07:34.517187: val_loss -0.9233 
2025-03-16 03:07:34.519694: Pseudo dice [np.float32(0.9399)] 
2025-03-16 03:07:34.523207: Epoch time: 42.44 s 
2025-03-16 03:07:34.526714: Yayy! New best EMA pseudo Dice: 0.9376999735832214 
2025-03-16 03:07:35.196890:  
2025-03-16 03:07:35.202448: Epoch 55 
2025-03-16 03:07:35.206527: Current learning rate: 0.00487 
2025-03-16 03:08:17.592317: train_loss -0.9645 
2025-03-16 03:08:17.597495: val_loss -0.9198 
2025-03-16 03:08:17.601007: Pseudo dice [np.float32(0.9373)] 
2025-03-16 03:08:17.604517: Epoch time: 42.4 s 
2025-03-16 03:08:18.120790:  
2025-03-16 03:08:18.126302: Epoch 56 
2025-03-16 03:08:18.129813: Current learning rate: 0.00478 
2025-03-16 03:09:00.517486: train_loss -0.9616 
2025-03-16 03:09:00.523499: val_loss -0.9234 
2025-03-16 03:09:00.526007: Pseudo dice [np.float32(0.9397)] 
2025-03-16 03:09:00.530017: Epoch time: 42.4 s 
2025-03-16 03:09:00.532523: Yayy! New best EMA pseudo Dice: 0.9379000067710876 
2025-03-16 03:09:01.197512:  
2025-03-16 03:09:01.203079: Epoch 57 
2025-03-16 03:09:01.206631: Current learning rate: 0.00468 
2025-03-16 03:09:43.626281: train_loss -0.9612 
2025-03-16 03:09:43.631352: val_loss -0.9217 
2025-03-16 03:09:43.635425: Pseudo dice [np.float32(0.9384)] 
2025-03-16 03:09:43.639060: Epoch time: 42.43 s 
2025-03-16 03:09:43.642611: Yayy! New best EMA pseudo Dice: 0.9379000067710876 
2025-03-16 03:09:44.307353:  
2025-03-16 03:09:44.312876: Epoch 58 
2025-03-16 03:09:44.316389: Current learning rate: 0.00458 
2025-03-16 03:10:26.757850: train_loss -0.9652 
2025-03-16 03:10:26.763911: val_loss -0.9211 
2025-03-16 03:10:26.766922: Pseudo dice [np.float32(0.9382)] 
2025-03-16 03:10:26.770436: Epoch time: 42.45 s 
2025-03-16 03:10:26.773941: Yayy! New best EMA pseudo Dice: 0.9379000067710876 
2025-03-16 03:10:27.459507:  
2025-03-16 03:10:27.464347: Epoch 59 
2025-03-16 03:10:27.467859: Current learning rate: 0.00448 
2025-03-16 03:11:09.860030: train_loss -0.9663 
2025-03-16 03:11:09.865707: val_loss -0.9218 
2025-03-16 03:11:09.869230: Pseudo dice [np.float32(0.9384)] 
2025-03-16 03:11:09.872279: Epoch time: 42.4 s 
2025-03-16 03:11:09.875373: Yayy! New best EMA pseudo Dice: 0.9380000233650208 
2025-03-16 03:11:10.550805:  
2025-03-16 03:11:10.557374: Epoch 60 
2025-03-16 03:11:10.559971: Current learning rate: 0.00438 
2025-03-16 03:11:52.975960: train_loss -0.9635 
2025-03-16 03:11:52.981975: val_loss -0.926 
2025-03-16 03:11:52.984987: Pseudo dice [np.float32(0.9414)] 
2025-03-16 03:11:52.988498: Epoch time: 42.43 s 
2025-03-16 03:11:52.992507: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-03-16 03:11:53.661199:  
2025-03-16 03:11:53.666712: Epoch 61 
2025-03-16 03:11:53.670223: Current learning rate: 0.00429 
2025-03-16 03:12:36.100639: train_loss -0.964 
2025-03-16 03:12:36.107226: val_loss -0.922 
2025-03-16 03:12:36.110821: Pseudo dice [np.float32(0.9388)] 
2025-03-16 03:12:36.114854: Epoch time: 42.44 s 
2025-03-16 03:12:36.117880: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-03-16 03:12:36.933449:  
2025-03-16 03:12:36.939062: Epoch 62 
2025-03-16 03:12:36.942574: Current learning rate: 0.00419 
2025-03-16 03:13:19.379741: train_loss -0.9671 
2025-03-16 03:13:19.385358: val_loss -0.9223 
2025-03-16 03:13:19.389429: Pseudo dice [np.float32(0.9388)] 
2025-03-16 03:13:19.392476: Epoch time: 42.45 s 
2025-03-16 03:13:19.396124: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-03-16 03:13:20.075087:  
2025-03-16 03:13:20.080102: Epoch 63 
2025-03-16 03:13:20.084235: Current learning rate: 0.00409 
2025-03-16 03:14:02.527290: train_loss -0.9662 
2025-03-16 03:14:02.532299: val_loss -0.9238 
2025-03-16 03:14:02.536314: Pseudo dice [np.float32(0.9402)] 
2025-03-16 03:14:02.539824: Epoch time: 42.45 s 
2025-03-16 03:14:02.543833: Yayy! New best EMA pseudo Dice: 0.9386000037193298 
2025-03-16 03:14:03.216632:  
2025-03-16 03:14:03.222250: Epoch 64 
2025-03-16 03:14:03.225798: Current learning rate: 0.00399 
2025-03-16 03:14:45.576260: train_loss -0.9663 
2025-03-16 03:14:45.581860: val_loss -0.9225 
2025-03-16 03:14:45.585915: Pseudo dice [np.float32(0.9393)] 
2025-03-16 03:14:45.589491: Epoch time: 42.36 s 
2025-03-16 03:14:45.592525: Yayy! New best EMA pseudo Dice: 0.9387000203132629 
2025-03-16 03:14:46.269887:  
2025-03-16 03:14:46.275934: Epoch 65 
2025-03-16 03:14:46.279543: Current learning rate: 0.00389 
2025-03-16 03:15:28.656737: train_loss -0.966 
2025-03-16 03:15:28.662823: val_loss -0.9218 
2025-03-16 03:15:28.666418: Pseudo dice [np.float32(0.9389)] 
2025-03-16 03:15:28.669965: Epoch time: 42.39 s 
2025-03-16 03:15:28.673578: Yayy! New best EMA pseudo Dice: 0.9387000203132629 
2025-03-16 03:15:29.345508:  
2025-03-16 03:15:29.351030: Epoch 66 
2025-03-16 03:15:29.354543: Current learning rate: 0.00379 
2025-03-16 03:16:11.766589: train_loss -0.9667 
2025-03-16 03:16:11.772125: val_loss -0.9222 
2025-03-16 03:16:11.775641: Pseudo dice [np.float32(0.939)] 
2025-03-16 03:16:11.779659: Epoch time: 42.42 s 
2025-03-16 03:16:11.782176: Yayy! New best EMA pseudo Dice: 0.9387000203132629 
2025-03-16 03:16:12.465013:  
2025-03-16 03:16:12.470109: Epoch 67 
2025-03-16 03:16:12.474210: Current learning rate: 0.00369 
2025-03-16 03:16:54.823261: train_loss -0.969 
2025-03-16 03:16:54.829376: val_loss -0.9256 
2025-03-16 03:16:54.832401: Pseudo dice [np.float32(0.9418)] 
2025-03-16 03:16:54.836333: Epoch time: 42.36 s 
2025-03-16 03:16:54.839849: Yayy! New best EMA pseudo Dice: 0.9390000104904175 
2025-03-16 03:16:55.529598:  
2025-03-16 03:16:55.535142: Epoch 68 
2025-03-16 03:16:55.539655: Current learning rate: 0.00359 
2025-03-16 03:17:37.957090: train_loss -0.9663 
2025-03-16 03:17:37.963106: val_loss -0.9226 
2025-03-16 03:17:37.966117: Pseudo dice [np.float32(0.9399)] 
2025-03-16 03:17:37.969626: Epoch time: 42.43 s 
2025-03-16 03:17:37.973133: Yayy! New best EMA pseudo Dice: 0.9391000270843506 
2025-03-16 03:17:38.791455:  
2025-03-16 03:17:38.797006: Epoch 69 
2025-03-16 03:17:38.801054: Current learning rate: 0.00349 
2025-03-16 03:18:21.208507: train_loss -0.9677 
2025-03-16 03:18:21.214051: val_loss -0.922 
2025-03-16 03:18:21.218059: Pseudo dice [np.float32(0.9393)] 
2025-03-16 03:18:21.221565: Epoch time: 42.42 s 
2025-03-16 03:18:21.225571: Yayy! New best EMA pseudo Dice: 0.9391000270843506 
2025-03-16 03:18:21.909379:  
2025-03-16 03:18:21.914894: Epoch 70 
2025-03-16 03:18:21.919403: Current learning rate: 0.00338 
2025-03-16 03:19:04.380072: train_loss -0.9676 
2025-03-16 03:19:04.385590: val_loss -0.9216 
2025-03-16 03:19:04.389102: Pseudo dice [np.float32(0.9389)] 
2025-03-16 03:19:04.393114: Epoch time: 42.47 s 
2025-03-16 03:19:04.925891:  
2025-03-16 03:19:04.931437: Epoch 71 
2025-03-16 03:19:04.934518: Current learning rate: 0.00328 
2025-03-16 03:19:47.352155: train_loss -0.9689 
2025-03-16 03:19:47.357201: val_loss -0.9237 
2025-03-16 03:19:47.361300: Pseudo dice [np.float32(0.9406)] 
2025-03-16 03:19:47.364812: Epoch time: 42.43 s 
2025-03-16 03:19:47.367320: Yayy! New best EMA pseudo Dice: 0.939300000667572 
2025-03-16 03:19:48.053392:  
2025-03-16 03:19:48.059451: Epoch 72 
2025-03-16 03:19:48.062527: Current learning rate: 0.00318 
2025-03-16 03:20:30.467595: train_loss -0.9698 
2025-03-16 03:20:30.473130: val_loss -0.922 
2025-03-16 03:20:30.476639: Pseudo dice [np.float32(0.9397)] 
2025-03-16 03:20:30.479149: Epoch time: 42.42 s 
2025-03-16 03:20:30.483163: Yayy! New best EMA pseudo Dice: 0.939300000667572 
2025-03-16 03:20:31.166265:  
2025-03-16 03:20:31.171779: Epoch 73 
2025-03-16 03:20:31.177801: Current learning rate: 0.00308 
2025-03-16 03:21:13.600730: train_loss -0.97 
2025-03-16 03:21:13.606808: val_loss -0.9225 
2025-03-16 03:21:13.609410: Pseudo dice [np.float32(0.9396)] 
2025-03-16 03:21:13.613975: Epoch time: 42.44 s 
2025-03-16 03:21:13.617023: Yayy! New best EMA pseudo Dice: 0.939300000667572 
2025-03-16 03:21:14.304091:  
2025-03-16 03:21:14.309615: Epoch 74 
2025-03-16 03:21:14.312624: Current learning rate: 0.00297 
2025-03-16 03:21:56.707674: train_loss -0.9683 
2025-03-16 03:21:56.714192: val_loss -0.9232 
2025-03-16 03:21:56.716697: Pseudo dice [np.float32(0.9403)] 
2025-03-16 03:21:56.720707: Epoch time: 42.4 s 
2025-03-16 03:21:56.724225: Yayy! New best EMA pseudo Dice: 0.9394000172615051 
2025-03-16 03:21:57.419250:  
2025-03-16 03:21:57.424770: Epoch 75 
2025-03-16 03:21:57.428284: Current learning rate: 0.00287 
2025-03-16 03:22:39.850903: train_loss -0.9677 
2025-03-16 03:22:39.856079: val_loss -0.9237 
2025-03-16 03:22:39.859639: Pseudo dice [np.float32(0.9404)] 
2025-03-16 03:22:39.863224: Epoch time: 42.43 s 
2025-03-16 03:22:39.866260: Yayy! New best EMA pseudo Dice: 0.9394999742507935 
2025-03-16 03:22:40.557448:  
2025-03-16 03:22:40.563002: Epoch 76 
2025-03-16 03:22:40.566519: Current learning rate: 0.00277 
2025-03-16 03:23:22.991879: train_loss -0.9686 
2025-03-16 03:23:22.996889: val_loss -0.9232 
2025-03-16 03:23:23.000400: Pseudo dice [np.float32(0.9399)] 
2025-03-16 03:23:23.003907: Epoch time: 42.43 s 
2025-03-16 03:23:23.006917: Yayy! New best EMA pseudo Dice: 0.9395999908447266 
2025-03-16 03:23:23.825082:  
2025-03-16 03:23:23.830164: Epoch 77 
2025-03-16 03:23:23.832709: Current learning rate: 0.00266 
2025-03-16 03:24:06.281170: train_loss -0.9683 
2025-03-16 03:24:06.286701: val_loss -0.9241 
2025-03-16 03:24:06.290717: Pseudo dice [np.float32(0.9408)] 
2025-03-16 03:24:06.294227: Epoch time: 42.46 s 
2025-03-16 03:24:06.296734: Yayy! New best EMA pseudo Dice: 0.9397000074386597 
2025-03-16 03:24:07.002123:  
2025-03-16 03:24:07.007176: Epoch 78 
2025-03-16 03:24:07.010127: Current learning rate: 0.00256 
2025-03-16 03:24:49.394291: train_loss -0.9687 
2025-03-16 03:24:49.399397: val_loss -0.9241 
2025-03-16 03:24:49.403024: Pseudo dice [np.float32(0.9409)] 
2025-03-16 03:24:49.406657: Epoch time: 42.39 s 
2025-03-16 03:24:49.410260: Yayy! New best EMA pseudo Dice: 0.9398000240325928 
2025-03-16 03:24:50.111217:  
2025-03-16 03:24:50.116322: Epoch 79 
2025-03-16 03:24:50.119847: Current learning rate: 0.00245 
2025-03-16 03:25:32.540166: train_loss -0.9675 
2025-03-16 03:25:32.546736: val_loss -0.9237 
2025-03-16 03:25:32.549244: Pseudo dice [np.float32(0.9404)] 
2025-03-16 03:25:32.552764: Epoch time: 42.43 s 
2025-03-16 03:25:32.556274: Yayy! New best EMA pseudo Dice: 0.9398999810218811 
2025-03-16 03:25:33.246838:  
2025-03-16 03:25:33.250686: Epoch 80 
2025-03-16 03:25:33.254205: Current learning rate: 0.00235 
2025-03-16 03:26:15.657929: train_loss -0.9703 
2025-03-16 03:26:15.663493: val_loss -0.9222 
2025-03-16 03:26:15.667128: Pseudo dice [np.float32(0.9397)] 
2025-03-16 03:26:15.669653: Epoch time: 42.41 s 
2025-03-16 03:26:16.205035:  
2025-03-16 03:26:16.211323: Epoch 81 
2025-03-16 03:26:16.215362: Current learning rate: 0.00224 
2025-03-16 03:26:58.637593: train_loss -0.97 
2025-03-16 03:26:58.643153: val_loss -0.9217 
2025-03-16 03:26:58.647720: Pseudo dice [np.float32(0.9393)] 
2025-03-16 03:26:58.651232: Epoch time: 42.43 s 
2025-03-16 03:26:59.188541:  
2025-03-16 03:26:59.194097: Epoch 82 
2025-03-16 03:26:59.197672: Current learning rate: 0.00214 
2025-03-16 03:27:41.575862: train_loss -0.9703 
2025-03-16 03:27:41.581880: val_loss -0.9235 
2025-03-16 03:27:41.585898: Pseudo dice [np.float32(0.9406)] 
2025-03-16 03:27:41.588406: Epoch time: 42.39 s 
2025-03-16 03:27:41.592919: Yayy! New best EMA pseudo Dice: 0.9398999810218811 
2025-03-16 03:27:42.261675:  
2025-03-16 03:27:42.266233: Epoch 83 
2025-03-16 03:27:42.269291: Current learning rate: 0.00203 
2025-03-16 03:28:24.638301: train_loss -0.9709 
2025-03-16 03:28:24.644318: val_loss -0.922 
2025-03-16 03:28:24.647331: Pseudo dice [np.float32(0.9397)] 
2025-03-16 03:28:24.650843: Epoch time: 42.38 s 
2025-03-16 03:28:25.153949:  
2025-03-16 03:28:25.159504: Epoch 84 
2025-03-16 03:28:25.162045: Current learning rate: 0.00192 
2025-03-16 03:29:07.563493: train_loss -0.9714 
2025-03-16 03:29:07.569038: val_loss -0.924 
2025-03-16 03:29:07.572563: Pseudo dice [np.float32(0.9413)] 
2025-03-16 03:29:07.576107: Epoch time: 42.41 s 
2025-03-16 03:29:07.579144: Yayy! New best EMA pseudo Dice: 0.9399999976158142 
2025-03-16 03:29:08.395488:  
2025-03-16 03:29:08.401032: Epoch 85 
2025-03-16 03:29:08.404113: Current learning rate: 0.00181 
2025-03-16 03:29:50.806963: train_loss -0.9697 
2025-03-16 03:29:50.812975: val_loss -0.9219 
2025-03-16 03:29:50.815989: Pseudo dice [np.float32(0.9394)] 
2025-03-16 03:29:50.819499: Epoch time: 42.41 s 
2025-03-16 03:29:51.320073:  
2025-03-16 03:29:51.325133: Epoch 86 
2025-03-16 03:29:51.329186: Current learning rate: 0.0017 
2025-03-16 03:30:33.713667: train_loss -0.9707 
2025-03-16 03:30:33.719183: val_loss -0.9222 
2025-03-16 03:30:33.722694: Pseudo dice [np.float32(0.94)] 
2025-03-16 03:30:33.726200: Epoch time: 42.39 s 
2025-03-16 03:30:34.264302:  
2025-03-16 03:30:34.271829: Epoch 87 
2025-03-16 03:30:34.274338: Current learning rate: 0.00159 
2025-03-16 03:31:16.691880: train_loss -0.9713 
2025-03-16 03:31:16.697896: val_loss -0.9232 
2025-03-16 03:31:16.700404: Pseudo dice [np.float32(0.9405)] 
2025-03-16 03:31:16.703911: Epoch time: 42.43 s 
2025-03-16 03:31:16.706922: Yayy! New best EMA pseudo Dice: 0.9399999976158142 
2025-03-16 03:31:17.365393:  
2025-03-16 03:31:17.371459: Epoch 88 
2025-03-16 03:31:17.374522: Current learning rate: 0.00148 
2025-03-16 03:31:59.739487: train_loss -0.9701 
2025-03-16 03:31:59.746194: val_loss -0.9227 
2025-03-16 03:31:59.749233: Pseudo dice [np.float32(0.9402)] 
2025-03-16 03:31:59.752849: Epoch time: 42.37 s 
2025-03-16 03:31:59.755381: Yayy! New best EMA pseudo Dice: 0.9399999976158142 
2025-03-16 03:32:00.411124:  
2025-03-16 03:32:00.416169: Epoch 89 
2025-03-16 03:32:00.419712: Current learning rate: 0.00137 
2025-03-16 03:32:42.774129: train_loss -0.9715 
2025-03-16 03:32:42.780146: val_loss -0.9232 
2025-03-16 03:32:42.783656: Pseudo dice [np.float32(0.9407)] 
2025-03-16 03:32:42.786665: Epoch time: 42.36 s 
2025-03-16 03:32:42.790179: Yayy! New best EMA pseudo Dice: 0.9401000142097473 
2025-03-16 03:32:43.450395:  
2025-03-16 03:32:43.455947: Epoch 90 
2025-03-16 03:32:43.460530: Current learning rate: 0.00126 
2025-03-16 03:33:25.857857: train_loss -0.9699 
2025-03-16 03:33:25.862872: val_loss -0.9216 
2025-03-16 03:33:25.866884: Pseudo dice [np.float32(0.9393)] 
2025-03-16 03:33:25.870396: Epoch time: 42.41 s 
2025-03-16 03:33:26.367519:  
2025-03-16 03:33:26.372534: Epoch 91 
2025-03-16 03:33:26.376046: Current learning rate: 0.00115 
2025-03-16 03:34:08.762766: train_loss -0.9693 
2025-03-16 03:34:08.768879: val_loss -0.9221 
2025-03-16 03:34:08.772461: Pseudo dice [np.float32(0.9396)] 
2025-03-16 03:34:08.775972: Epoch time: 42.4 s 
2025-03-16 03:34:09.284841:  
2025-03-16 03:34:09.288922: Epoch 92 
2025-03-16 03:34:09.292983: Current learning rate: 0.00103 
2025-03-16 03:34:51.743269: train_loss -0.9706 
2025-03-16 03:34:51.749289: val_loss -0.9211 
2025-03-16 03:34:51.752796: Pseudo dice [np.float32(0.9393)] 
2025-03-16 03:34:51.755806: Epoch time: 42.46 s 
2025-03-16 03:34:52.401484:  
2025-03-16 03:34:52.407515: Epoch 93 
2025-03-16 03:34:52.410588: Current learning rate: 0.00091 
2025-03-16 03:35:34.784784: train_loss -0.9713 
2025-03-16 03:35:34.790375: val_loss -0.9239 
2025-03-16 03:35:34.792953: Pseudo dice [np.float32(0.9413)] 
2025-03-16 03:35:34.797009: Epoch time: 42.38 s 
2025-03-16 03:35:35.299344:  
2025-03-16 03:35:35.304903: Epoch 94 
2025-03-16 03:35:35.308498: Current learning rate: 0.00079 
2025-03-16 03:36:17.709392: train_loss -0.9709 
2025-03-16 03:36:17.716043: val_loss -0.9231 
2025-03-16 03:36:17.719624: Pseudo dice [np.float32(0.9405)] 
2025-03-16 03:36:17.722150: Epoch time: 42.41 s 
2025-03-16 03:36:17.726221: Yayy! New best EMA pseudo Dice: 0.9401000142097473 
2025-03-16 03:36:18.379054:  
2025-03-16 03:36:18.384160: Epoch 95 
2025-03-16 03:36:18.388742: Current learning rate: 0.00067 
2025-03-16 03:37:00.823211: train_loss -0.9714 
2025-03-16 03:37:00.828831: val_loss -0.9212 
2025-03-16 03:37:00.832398: Pseudo dice [np.float32(0.9395)] 
2025-03-16 03:37:00.834538: Epoch time: 42.44 s 
2025-03-16 03:37:01.337401:  
2025-03-16 03:37:01.342967: Epoch 96 
2025-03-16 03:37:01.346521: Current learning rate: 0.00055 
2025-03-16 03:37:43.777761: train_loss -0.9709 
2025-03-16 03:37:43.783360: val_loss -0.923 
2025-03-16 03:37:43.787422: Pseudo dice [np.float32(0.9405)] 
2025-03-16 03:37:43.789441: Epoch time: 42.44 s 
2025-03-16 03:37:44.300453:  
2025-03-16 03:37:44.305465: Epoch 97 
2025-03-16 03:37:44.308977: Current learning rate: 0.00043 
2025-03-16 03:38:26.739007: train_loss -0.9718 
2025-03-16 03:38:26.744078: val_loss -0.9207 
2025-03-16 03:38:26.748649: Pseudo dice [np.float32(0.939)] 
2025-03-16 03:38:26.752161: Epoch time: 42.44 s 
2025-03-16 03:38:27.264651:  
2025-03-16 03:38:27.270163: Epoch 98 
2025-03-16 03:38:27.273670: Current learning rate: 0.0003 
2025-03-16 03:39:09.695918: train_loss -0.97 
2025-03-16 03:39:09.700443: val_loss -0.922 
2025-03-16 03:39:09.703950: Pseudo dice [np.float32(0.9399)] 
2025-03-16 03:39:09.707458: Epoch time: 42.43 s 
2025-03-16 03:39:10.218768:  
2025-03-16 03:39:10.224325: Epoch 99 
2025-03-16 03:39:10.227364: Current learning rate: 0.00016 
2025-03-16 03:39:52.594166: train_loss -0.9718 
2025-03-16 03:39:52.599722: val_loss -0.9216 
2025-03-16 03:39:52.603229: Pseudo dice [np.float32(0.9398)] 
2025-03-16 03:39:52.605733: Epoch time: 42.38 s 
2025-03-16 03:39:53.319022: Training done. 
2025-03-16 03:39:53.346023: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2025-03-16 03:39:53.352022: The split file contains 5 splits. 
2025-03-16 03:39:53.357023: Desired fold for training: 0 
2025-03-16 03:39:53.360023: This split has 16 training and 4 validation cases. 
2025-03-16 03:39:53.364024: predicting la_007 
2025-03-16 03:39:53.369022: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2025-03-16 03:39:59.182599: predicting la_016 
2025-03-16 03:39:59.193599: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2025-03-16 03:40:01.446049: predicting la_021 
2025-03-16 03:40:01.456050: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2025-03-16 03:40:03.710571: predicting la_024 
2025-03-16 03:40:03.720570: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2025-03-16 03:40:12.529261: Validation complete 
2025-03-16 03:40:12.534259: Mean Validation Dice:  0.8397193484837211 
