2024-12-15 00:19:33.377511: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.5 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-15 00:19:33.382508: self.oversample_foreground_percent 0.6 
2024-12-15 00:19:34.003361: do_dummy_2d_data_aug: False 
2024-12-15 00:19:34.008362: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-15 00:19:34.010360: The split file contains 5 splits. 
2024-12-15 00:19:34.013363: Desired fold for training: 0 
2024-12-15 00:19:34.016361: This split has 16 training and 4 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 5, 'patch_size': [56, 160, 128], 'median_image_size_in_voxels': [115.0, 320.0, 232.0], 'spacing': [1.3700000047683716, 1.25, 1.25], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset002_Heart', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [1.3700000047683716, 1.25, 1.25], 'original_median_shape_after_transp': [115, 320, 232], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1996.0, 'mean': 1090.214599609375, 'median': 1097.0, 'min': 165.0, 'percentile_00_5': 598.0, 'percentile_99_5': 1521.0, 'std': 165.1737823486328}}} 
 
2024-12-15 00:19:41.691813: unpacking dataset... 
2024-12-15 00:19:41.926144: unpacking done... 
2024-12-15 00:19:44.258022:  
2024-12-15 00:19:44.262033: Epoch 50 
2024-12-15 00:19:44.264542: Current learning rate: 0.00536 
2024-12-15 00:20:38.913173: train_loss -0.9428 
2024-12-15 00:20:38.919689: val_loss -0.9214 
2024-12-15 00:20:38.922196: Pseudo dice [np.float32(0.9418)] 
2024-12-15 00:20:38.924704: Epoch time: 54.66 s 
2024-12-15 00:20:38.928217: Yayy! New best EMA pseudo Dice: 0.9397000074386597 
2024-12-15 00:20:39.636197:  
2024-12-15 00:20:39.641233: Epoch 51 
2024-12-15 00:20:39.644766: Current learning rate: 0.00526 
2024-12-15 00:21:27.647614: train_loss -0.9482 
2024-12-15 00:21:27.653261: val_loss -0.9173 
2024-12-15 00:21:27.657293: Pseudo dice [np.float32(0.9389)] 
2024-12-15 00:21:27.660339: Epoch time: 48.01 s 
2024-12-15 00:21:28.227022:  
2024-12-15 00:21:28.232575: Epoch 52 
2024-12-15 00:21:28.235590: Current learning rate: 0.00517 
2024-12-15 00:22:15.978072: train_loss -0.9527 
2024-12-15 00:22:15.985221: val_loss -0.9203 
2024-12-15 00:22:15.989303: Pseudo dice [np.float32(0.9415)] 
2024-12-15 00:22:15.992346: Epoch time: 47.75 s 
2024-12-15 00:22:15.995369: Yayy! New best EMA pseudo Dice: 0.9398000240325928 
2024-12-15 00:22:16.720597:  
2024-12-15 00:22:16.725638: Epoch 53 
2024-12-15 00:22:16.728661: Current learning rate: 0.00507 
2024-12-15 00:23:03.975320: train_loss -0.9531 
2024-12-15 00:23:03.981352: val_loss -0.9206 
2024-12-15 00:23:03.984908: Pseudo dice [np.float32(0.9416)] 
2024-12-15 00:23:03.986926: Epoch time: 47.26 s 
2024-12-15 00:23:03.989473: Yayy! New best EMA pseudo Dice: 0.9399999976158142 
2024-12-15 00:23:04.719364:  
2024-12-15 00:23:04.724948: Epoch 54 
2024-12-15 00:23:04.727994: Current learning rate: 0.00497 
2024-12-15 00:23:52.846309: train_loss -0.9511 
2024-12-15 00:23:52.851319: val_loss -0.9209 
2024-12-15 00:23:52.854828: Pseudo dice [np.float32(0.9412)] 
2024-12-15 00:23:52.857334: Epoch time: 48.13 s 
2024-12-15 00:23:52.859840: Yayy! New best EMA pseudo Dice: 0.9401000142097473 
2024-12-15 00:23:53.711243:  
2024-12-15 00:23:53.716795: Epoch 55 
2024-12-15 00:23:53.720367: Current learning rate: 0.00487 
2024-12-15 00:24:41.680679: train_loss -0.9525 
2024-12-15 00:24:41.685749: val_loss -0.9233 
2024-12-15 00:24:41.688774: Pseudo dice [np.float32(0.9436)] 
2024-12-15 00:24:41.691318: Epoch time: 47.97 s 
2024-12-15 00:24:41.694841: Yayy! New best EMA pseudo Dice: 0.9404000043869019 
2024-12-15 00:24:42.427185:  
2024-12-15 00:24:42.432750: Epoch 56 
2024-12-15 00:24:42.436298: Current learning rate: 0.00478 
2024-12-15 00:25:29.939760: train_loss -0.9529 
2024-12-15 00:25:29.944806: val_loss -0.9218 
2024-12-15 00:25:29.948315: Pseudo dice [np.float32(0.9419)] 
2024-12-15 00:25:29.951820: Epoch time: 47.51 s 
2024-12-15 00:25:29.954828: Yayy! New best EMA pseudo Dice: 0.9405999779701233 
2024-12-15 00:25:30.692777:  
2024-12-15 00:25:30.697824: Epoch 57 
2024-12-15 00:25:30.700893: Current learning rate: 0.00468 
2024-12-15 00:26:19.289573: train_loss -0.9551 
2024-12-15 00:26:19.295584: val_loss -0.918 
2024-12-15 00:26:19.298593: Pseudo dice [np.float32(0.9394)] 
2024-12-15 00:26:19.301099: Epoch time: 48.6 s 
2024-12-15 00:26:19.854659:  
2024-12-15 00:26:19.859694: Epoch 58 
2024-12-15 00:26:19.863228: Current learning rate: 0.00458 
2024-12-15 00:27:07.834847: train_loss -0.9549 
2024-12-15 00:27:07.840861: val_loss -0.9221 
2024-12-15 00:27:07.843869: Pseudo dice [np.float32(0.9424)] 
2024-12-15 00:27:07.847377: Epoch time: 47.98 s 
2024-12-15 00:27:07.849883: Yayy! New best EMA pseudo Dice: 0.9406999945640564 
2024-12-15 00:27:08.572770:  
2024-12-15 00:27:08.578283: Epoch 59 
2024-12-15 00:27:08.580789: Current learning rate: 0.00448 
2024-12-15 00:27:56.609029: train_loss -0.9538 
2024-12-15 00:27:56.614583: val_loss -0.9239 
2024-12-15 00:27:56.618109: Pseudo dice [np.float32(0.9437)] 
2024-12-15 00:27:56.621638: Epoch time: 48.04 s 
2024-12-15 00:27:56.624674: Yayy! New best EMA pseudo Dice: 0.9409999847412109 
2024-12-15 00:27:57.351778:  
2024-12-15 00:27:57.357331: Epoch 60 
2024-12-15 00:27:57.360928: Current learning rate: 0.00438 
2024-12-15 00:28:45.236765: train_loss -0.9553 
2024-12-15 00:28:45.241776: val_loss -0.9225 
2024-12-15 00:28:45.244784: Pseudo dice [np.float32(0.9427)] 
2024-12-15 00:28:45.247813: Epoch time: 47.89 s 
2024-12-15 00:28:45.250881: Yayy! New best EMA pseudo Dice: 0.941100001335144 
2024-12-15 00:28:46.002215:  
2024-12-15 00:28:46.007230: Epoch 61 
2024-12-15 00:28:46.010240: Current learning rate: 0.00429 
2024-12-15 00:29:34.495713: train_loss -0.9559 
2024-12-15 00:29:34.501226: val_loss -0.921 
2024-12-15 00:29:34.504758: Pseudo dice [np.float32(0.9418)] 
2024-12-15 00:29:34.507265: Epoch time: 48.49 s 
2024-12-15 00:29:34.510770: Yayy! New best EMA pseudo Dice: 0.9412000179290771 
2024-12-15 00:29:35.239391:  
2024-12-15 00:29:35.244403: Epoch 62 
2024-12-15 00:29:35.246908: Current learning rate: 0.00419 
2024-12-15 00:30:23.311035: train_loss -0.9553 
2024-12-15 00:30:23.316046: val_loss -0.9218 
2024-12-15 00:30:23.319555: Pseudo dice [np.float32(0.9428)] 
2024-12-15 00:30:23.322061: Epoch time: 48.07 s 
2024-12-15 00:30:23.325570: Yayy! New best EMA pseudo Dice: 0.9413999915122986 
2024-12-15 00:30:24.215174:  
2024-12-15 00:30:24.220725: Epoch 63 
2024-12-15 00:30:24.223763: Current learning rate: 0.00409 
2024-12-15 00:31:12.175940: train_loss -0.9541 
2024-12-15 00:31:12.181590: val_loss -0.9217 
2024-12-15 00:31:12.184130: Pseudo dice [np.float32(0.9421)] 
2024-12-15 00:31:12.188688: Epoch time: 47.96 s 
2024-12-15 00:31:12.191736: Yayy! New best EMA pseudo Dice: 0.9413999915122986 
2024-12-15 00:31:12.909433:  
2024-12-15 00:31:12.914948: Epoch 64 
2024-12-15 00:31:12.917453: Current learning rate: 0.00399 
2024-12-15 00:32:05.304132: train_loss -0.9537 
2024-12-15 00:32:05.311654: val_loss -0.9218 
2024-12-15 00:32:05.314160: Pseudo dice [np.float32(0.9426)] 
2024-12-15 00:32:05.317670: Epoch time: 52.4 s 
2024-12-15 00:32:05.320175: Yayy! New best EMA pseudo Dice: 0.9416000247001648 
2024-12-15 00:32:06.064424:  
2024-12-15 00:32:06.069468: Epoch 65 
2024-12-15 00:32:06.071988: Current learning rate: 0.00389 
2024-12-15 00:32:54.338223: train_loss -0.9572 
2024-12-15 00:32:54.344239: val_loss -0.9232 
2024-12-15 00:32:54.347746: Pseudo dice [np.float32(0.9436)] 
2024-12-15 00:32:54.350754: Epoch time: 48.28 s 
2024-12-15 00:32:54.353260: Yayy! New best EMA pseudo Dice: 0.9417999982833862 
2024-12-15 00:32:55.083566:  
2024-12-15 00:32:55.088616: Epoch 66 
2024-12-15 00:32:55.091153: Current learning rate: 0.00379 
2024-12-15 00:33:44.828405: train_loss -0.9567 
2024-12-15 00:33:44.833996: val_loss -0.9215 
2024-12-15 00:33:44.836519: Pseudo dice [np.float32(0.9422)] 
2024-12-15 00:33:44.840542: Epoch time: 49.75 s 
2024-12-15 00:33:44.843076: Yayy! New best EMA pseudo Dice: 0.9417999982833862 
2024-12-15 00:33:45.573126:  
2024-12-15 00:33:45.578137: Epoch 67 
2024-12-15 00:33:45.581147: Current learning rate: 0.00369 
2024-12-15 00:34:34.178663: train_loss -0.9574 
2024-12-15 00:34:34.184299: val_loss -0.9222 
2024-12-15 00:34:34.187359: Pseudo dice [np.float32(0.943)] 
2024-12-15 00:34:34.190395: Epoch time: 48.61 s 
2024-12-15 00:34:34.193427: Yayy! New best EMA pseudo Dice: 0.9419000148773193 
2024-12-15 00:34:34.926306:  
2024-12-15 00:34:34.931324: Epoch 68 
2024-12-15 00:34:34.933833: Current learning rate: 0.00359 
2024-12-15 00:35:23.214904: train_loss -0.9571 
2024-12-15 00:35:23.220974: val_loss -0.9224 
2024-12-15 00:35:23.224520: Pseudo dice [np.float32(0.9429)] 
2024-12-15 00:35:23.227547: Epoch time: 48.29 s 
2024-12-15 00:35:23.230063: Yayy! New best EMA pseudo Dice: 0.9419999718666077 
2024-12-15 00:35:23.980139:  
2024-12-15 00:35:23.984780: Epoch 69 
2024-12-15 00:35:23.988300: Current learning rate: 0.00349 
2024-12-15 00:36:12.083485: train_loss -0.9581 
2024-12-15 00:36:12.089508: val_loss -0.9227 
2024-12-15 00:36:12.093518: Pseudo dice [np.float32(0.9436)] 
2024-12-15 00:36:12.096542: Epoch time: 48.1 s 
2024-12-15 00:36:12.099076: Yayy! New best EMA pseudo Dice: 0.9422000050544739 
2024-12-15 00:36:12.832412:  
2024-12-15 00:36:12.837445: Epoch 70 
2024-12-15 00:36:12.841018: Current learning rate: 0.00338 
2024-12-15 00:37:01.018058: train_loss -0.9581 
2024-12-15 00:37:01.023664: val_loss -0.9207 
2024-12-15 00:37:01.027201: Pseudo dice [np.float32(0.9417)] 
2024-12-15 00:37:01.029711: Epoch time: 48.19 s 
2024-12-15 00:37:01.753350:  
2024-12-15 00:37:01.759368: Epoch 71 
2024-12-15 00:37:01.762875: Current learning rate: 0.00328 
2024-12-15 00:37:50.018180: train_loss -0.9597 
2024-12-15 00:37:50.023696: val_loss -0.9226 
2024-12-15 00:37:50.026206: Pseudo dice [np.float32(0.9437)] 
2024-12-15 00:37:50.029763: Epoch time: 48.27 s 
2024-12-15 00:37:50.032274: Yayy! New best EMA pseudo Dice: 0.942300021648407 
2024-12-15 00:37:50.781194:  
2024-12-15 00:37:50.787324: Epoch 72 
2024-12-15 00:37:50.790421: Current learning rate: 0.00318 
2024-12-15 00:38:39.522009: train_loss -0.9581 
2024-12-15 00:38:39.528027: val_loss -0.9244 
2024-12-15 00:38:39.531533: Pseudo dice [np.float32(0.9442)] 
2024-12-15 00:38:39.534544: Epoch time: 48.74 s 
2024-12-15 00:38:39.537051: Yayy! New best EMA pseudo Dice: 0.9424999952316284 
2024-12-15 00:38:40.287633:  
2024-12-15 00:38:40.292647: Epoch 73 
2024-12-15 00:38:40.296158: Current learning rate: 0.00308 
2024-12-15 00:39:28.035062: train_loss -0.9594 
2024-12-15 00:39:28.041580: val_loss -0.922 
2024-12-15 00:39:28.044087: Pseudo dice [np.float32(0.9426)] 
2024-12-15 00:39:28.048674: Epoch time: 47.75 s 
2024-12-15 00:39:28.052295: Yayy! New best EMA pseudo Dice: 0.9424999952316284 
2024-12-15 00:39:28.815035:  
2024-12-15 00:39:28.820694: Epoch 74 
2024-12-15 00:39:28.824258: Current learning rate: 0.00297 
2024-12-15 00:40:16.677432: train_loss -0.9584 
2024-12-15 00:40:16.683951: val_loss -0.9219 
2024-12-15 00:40:16.687471: Pseudo dice [np.float32(0.9427)] 
2024-12-15 00:40:16.691482: Epoch time: 47.86 s 
2024-12-15 00:40:16.694991: Yayy! New best EMA pseudo Dice: 0.9424999952316284 
2024-12-15 00:40:17.450585:  
2024-12-15 00:40:17.457195: Epoch 75 
2024-12-15 00:40:17.460772: Current learning rate: 0.00287 
2024-12-15 00:41:05.693821: train_loss -0.9586 
2024-12-15 00:41:05.699340: val_loss -0.9237 
2024-12-15 00:41:05.702851: Pseudo dice [np.float32(0.9442)] 
2024-12-15 00:41:05.705357: Epoch time: 48.24 s 
2024-12-15 00:41:05.709369: Yayy! New best EMA pseudo Dice: 0.9427000284194946 
2024-12-15 00:41:06.458309:  
2024-12-15 00:41:06.463868: Epoch 76 
2024-12-15 00:41:06.466892: Current learning rate: 0.00277 
2024-12-15 00:41:54.838934: train_loss -0.9591 
2024-12-15 00:41:54.844947: val_loss -0.9235 
2024-12-15 00:41:54.847959: Pseudo dice [np.float32(0.9435)] 
2024-12-15 00:41:54.851505: Epoch time: 48.38 s 
2024-12-15 00:41:54.854010: Yayy! New best EMA pseudo Dice: 0.942799985408783 
2024-12-15 00:41:55.613955:  
2024-12-15 00:41:55.619468: Epoch 77 
2024-12-15 00:41:55.621974: Current learning rate: 0.00266 
2024-12-15 00:42:43.481907: train_loss -0.9597 
2024-12-15 00:42:43.488953: val_loss -0.9211 
2024-12-15 00:42:43.491458: Pseudo dice [np.float32(0.9426)] 
2024-12-15 00:42:43.494967: Epoch time: 47.87 s 
2024-12-15 00:42:44.080684:  
2024-12-15 00:42:44.086198: Epoch 78 
2024-12-15 00:42:44.088703: Current learning rate: 0.00256 
2024-12-15 00:43:31.841687: train_loss -0.9592 
2024-12-15 00:43:31.847201: val_loss -0.9217 
2024-12-15 00:43:31.850711: Pseudo dice [np.float32(0.9427)] 
2024-12-15 00:43:31.854216: Epoch time: 47.76 s 
2024-12-15 00:43:32.604228:  
2024-12-15 00:43:32.609261: Epoch 79 
2024-12-15 00:43:32.612814: Current learning rate: 0.00245 
2024-12-15 00:44:21.117315: train_loss -0.9601 
2024-12-15 00:44:21.123393: val_loss -0.9219 
2024-12-15 00:44:21.126445: Pseudo dice [np.float32(0.9427)] 
2024-12-15 00:44:21.129992: Epoch time: 48.51 s 
2024-12-15 00:44:21.719389:  
2024-12-15 00:44:21.724906: Epoch 80 
2024-12-15 00:44:21.728415: Current learning rate: 0.00235 
2024-12-15 00:45:09.953777: train_loss -0.9608 
2024-12-15 00:45:09.959334: val_loss -0.9205 
2024-12-15 00:45:09.962367: Pseudo dice [np.float32(0.9421)] 
2024-12-15 00:45:09.965894: Epoch time: 48.24 s 
2024-12-15 00:45:10.560475:  
2024-12-15 00:45:10.566043: Epoch 81 
2024-12-15 00:45:10.569072: Current learning rate: 0.00224 
2024-12-15 00:45:59.144687: train_loss -0.9604 
2024-12-15 00:45:59.150778: val_loss -0.9225 
2024-12-15 00:45:59.154325: Pseudo dice [np.float32(0.9434)] 
2024-12-15 00:45:59.157437: Epoch time: 48.58 s 
2024-12-15 00:45:59.750118:  
2024-12-15 00:45:59.756181: Epoch 82 
2024-12-15 00:45:59.759249: Current learning rate: 0.00214 
2024-12-15 00:46:47.615592: train_loss -0.9608 
2024-12-15 00:46:47.621709: val_loss -0.9241 
2024-12-15 00:46:47.625274: Pseudo dice [np.float32(0.9438)] 
2024-12-15 00:46:47.628311: Epoch time: 47.87 s 
2024-12-15 00:46:47.630841: Yayy! New best EMA pseudo Dice: 0.942799985408783 
2024-12-15 00:46:48.352287:  
2024-12-15 00:46:48.357855: Epoch 83 
2024-12-15 00:46:48.360405: Current learning rate: 0.00203 
2024-12-15 00:47:36.886227: train_loss -0.9608 
2024-12-15 00:47:36.892242: val_loss -0.9206 
2024-12-15 00:47:36.895748: Pseudo dice [np.float32(0.9423)] 
2024-12-15 00:47:36.898755: Epoch time: 48.53 s 
2024-12-15 00:47:37.458392:  
2024-12-15 00:47:37.463403: Epoch 84 
2024-12-15 00:47:37.467915: Current learning rate: 0.00192 
2024-12-15 00:48:26.214539: train_loss -0.9611 
2024-12-15 00:48:26.221052: val_loss -0.921 
2024-12-15 00:48:26.224561: Pseudo dice [np.float32(0.9431)] 
2024-12-15 00:48:26.227093: Epoch time: 48.76 s 
2024-12-15 00:48:26.787865:  
2024-12-15 00:48:26.793430: Epoch 85 
2024-12-15 00:48:26.796475: Current learning rate: 0.00181 
2024-12-15 00:49:14.996487: train_loss -0.9599 
2024-12-15 00:49:15.002540: val_loss -0.9219 
2024-12-15 00:49:15.006597: Pseudo dice [np.float32(0.9426)] 
2024-12-15 00:49:15.009142: Epoch time: 48.21 s 
2024-12-15 00:49:15.558209:  
2024-12-15 00:49:15.563249: Epoch 86 
2024-12-15 00:49:15.566783: Current learning rate: 0.0017 
2024-12-15 00:50:03.779330: train_loss -0.9612 
2024-12-15 00:50:03.785500: val_loss -0.9208 
2024-12-15 00:50:03.788052: Pseudo dice [np.float32(0.9424)] 
2024-12-15 00:50:03.791605: Epoch time: 48.22 s 
2024-12-15 00:50:04.492088:  
2024-12-15 00:50:04.497705: Epoch 87 
2024-12-15 00:50:04.501723: Current learning rate: 0.00159 
2024-12-15 00:50:52.241934: train_loss -0.9615 
2024-12-15 00:50:52.247575: val_loss -0.9222 
2024-12-15 00:50:52.250614: Pseudo dice [np.float32(0.943)] 
2024-12-15 00:50:52.254622: Epoch time: 47.75 s 
2024-12-15 00:50:52.815379:  
2024-12-15 00:50:52.820901: Epoch 88 
2024-12-15 00:50:52.823926: Current learning rate: 0.00148 
2024-12-15 00:51:41.059819: train_loss -0.9619 
2024-12-15 00:51:41.065866: val_loss -0.9232 
2024-12-15 00:51:41.068895: Pseudo dice [np.float32(0.9441)] 
2024-12-15 00:51:41.072443: Epoch time: 48.24 s 
2024-12-15 00:51:41.075499: Yayy! New best EMA pseudo Dice: 0.9429000020027161 
2024-12-15 00:51:41.792830:  
2024-12-15 00:51:41.798373: Epoch 89 
2024-12-15 00:51:41.801931: Current learning rate: 0.00137 
2024-12-15 00:52:29.595127: train_loss -0.9608 
2024-12-15 00:52:29.600731: val_loss -0.9226 
2024-12-15 00:52:29.604268: Pseudo dice [np.float32(0.9439)] 
2024-12-15 00:52:29.607806: Epoch time: 47.8 s 
2024-12-15 00:52:29.611327: Yayy! New best EMA pseudo Dice: 0.9430000185966492 
2024-12-15 00:52:30.345020:  
2024-12-15 00:52:30.350566: Epoch 90 
2024-12-15 00:52:30.353598: Current learning rate: 0.00126 
2024-12-15 00:53:18.412226: train_loss -0.9618 
2024-12-15 00:53:18.417851: val_loss -0.9224 
2024-12-15 00:53:18.421391: Pseudo dice [np.float32(0.9435)] 
2024-12-15 00:53:18.424429: Epoch time: 48.07 s 
2024-12-15 00:53:18.428461: Yayy! New best EMA pseudo Dice: 0.9430999755859375 
2024-12-15 00:53:19.165868:  
2024-12-15 00:53:19.171402: Epoch 91 
2024-12-15 00:53:19.174432: Current learning rate: 0.00115 
2024-12-15 00:54:07.505666: train_loss -0.9614 
2024-12-15 00:54:07.511682: val_loss -0.9226 
2024-12-15 00:54:07.515689: Pseudo dice [np.float32(0.9433)] 
2024-12-15 00:54:07.518195: Epoch time: 48.34 s 
2024-12-15 00:54:07.521708: Yayy! New best EMA pseudo Dice: 0.9430999755859375 
2024-12-15 00:54:08.250822:  
2024-12-15 00:54:08.255852: Epoch 92 
2024-12-15 00:54:08.259360: Current learning rate: 0.00103 
2024-12-15 00:54:55.589457: train_loss -0.9618 
2024-12-15 00:54:55.595005: val_loss -0.9229 
2024-12-15 00:54:55.598526: Pseudo dice [np.float32(0.9441)] 
2024-12-15 00:54:55.602049: Epoch time: 47.34 s 
2024-12-15 00:54:55.605121: Yayy! New best EMA pseudo Dice: 0.9431999921798706 
2024-12-15 00:54:56.327674:  
2024-12-15 00:54:56.333188: Epoch 93 
2024-12-15 00:54:56.336700: Current learning rate: 0.00091 
2024-12-15 00:55:44.294562: train_loss -0.9623 
2024-12-15 00:55:44.301141: val_loss -0.9208 
2024-12-15 00:55:44.305154: Pseudo dice [np.float32(0.9426)] 
2024-12-15 00:55:44.307660: Epoch time: 47.97 s 
2024-12-15 00:55:44.850351:  
2024-12-15 00:55:44.855912: Epoch 94 
2024-12-15 00:55:44.858467: Current learning rate: 0.00079 
2024-12-15 00:56:32.508649: train_loss -0.9622 
2024-12-15 00:56:32.514230: val_loss -0.924 
2024-12-15 00:56:32.517256: Pseudo dice [np.float32(0.9445)] 
2024-12-15 00:56:32.519762: Epoch time: 47.66 s 
2024-12-15 00:56:32.523769: Yayy! New best EMA pseudo Dice: 0.9433000087738037 
2024-12-15 00:56:33.227525:  
2024-12-15 00:56:33.233088: Epoch 95 
2024-12-15 00:56:33.236123: Current learning rate: 0.00067 
2024-12-15 00:57:20.676003: train_loss -0.9624 
2024-12-15 00:57:20.682600: val_loss -0.9229 
2024-12-15 00:57:20.686179: Pseudo dice [np.float32(0.9438)] 
2024-12-15 00:57:20.689211: Epoch time: 47.45 s 
2024-12-15 00:57:20.692739: Yayy! New best EMA pseudo Dice: 0.9433000087738037 
2024-12-15 00:57:21.573842:  
2024-12-15 00:57:21.580477: Epoch 96 
2024-12-15 00:57:21.584547: Current learning rate: 0.00055 
2024-12-15 00:58:09.046623: train_loss -0.9628 
2024-12-15 00:58:09.053183: val_loss -0.9216 
2024-12-15 00:58:09.056260: Pseudo dice [np.float32(0.9432)] 
2024-12-15 00:58:09.059803: Epoch time: 47.47 s 
2024-12-15 00:58:09.603627:  
2024-12-15 00:58:09.609144: Epoch 97 
2024-12-15 00:58:09.611653: Current learning rate: 0.00043 
2024-12-15 00:58:56.649077: train_loss -0.961 
2024-12-15 00:58:56.654665: val_loss -0.9229 
2024-12-15 00:58:56.657171: Pseudo dice [np.float32(0.9441)] 
2024-12-15 00:58:56.660679: Epoch time: 47.05 s 
2024-12-15 00:58:56.663185: Yayy! New best EMA pseudo Dice: 0.9434000253677368 
2024-12-15 00:58:57.377190:  
2024-12-15 00:58:57.382292: Epoch 98 
2024-12-15 00:58:57.385334: Current learning rate: 0.0003 
2024-12-15 00:59:45.541121: train_loss -0.962 
2024-12-15 00:59:45.546643: val_loss -0.9232 
2024-12-15 00:59:45.550673: Pseudo dice [np.float32(0.9438)] 
2024-12-15 00:59:45.553681: Epoch time: 48.16 s 
2024-12-15 00:59:45.557189: Yayy! New best EMA pseudo Dice: 0.9434000253677368 
2024-12-15 00:59:46.272647:  
2024-12-15 00:59:46.277658: Epoch 99 
2024-12-15 00:59:46.280667: Current learning rate: 0.00016 
2024-12-15 01:00:33.904438: train_loss -0.9637 
2024-12-15 01:00:33.910950: val_loss -0.9231 
2024-12-15 01:00:33.913456: Pseudo dice [np.float32(0.944)] 
2024-12-15 01:00:33.916965: Epoch time: 47.63 s 
2024-12-15 01:00:33.919470: Yayy! New best EMA pseudo Dice: 0.9434999823570251 
2024-12-15 01:00:34.850825: Training done. 
2024-12-15 01:00:34.879827: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset002_Heart\splits_final.json 
2024-12-15 01:00:34.885827: The split file contains 5 splits. 
2024-12-15 01:00:34.889827: Desired fold for training: 0 
2024-12-15 01:00:34.892828: This split has 16 training and 4 validation cases. 
2024-12-15 01:00:34.896827: predicting la_007 
2024-12-15 01:00:34.901827: la_007, shape torch.Size([1, 130, 320, 244]), rank 0 
2024-12-15 01:00:38.302356: predicting la_016 
2024-12-15 01:00:38.313362: la_016, shape torch.Size([1, 90, 316, 196]), rank 0 
2024-12-15 01:00:40.757509: predicting la_021 
2024-12-15 01:00:40.766510: la_021, shape torch.Size([1, 100, 320, 228]), rank 0 
2024-12-15 01:00:43.103456: predicting la_024 
2024-12-15 01:00:43.113958: la_024, shape torch.Size([1, 120, 320, 232]), rank 0 
2024-12-15 01:00:52.830959: Validation complete 
2024-12-15 01:00:52.835465: Mean Validation Dice:  0.9367558029185767 
