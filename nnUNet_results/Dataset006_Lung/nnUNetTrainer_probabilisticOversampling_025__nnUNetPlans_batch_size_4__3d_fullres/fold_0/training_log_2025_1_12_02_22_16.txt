2025-01-12 02:22:16.248747: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.25 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-12 02:22:16.252747: self.oversample_foreground_percent 0.2 
2025-01-12 02:22:16.255749: do_dummy_2d_data_aug: False 
2025-01-12 02:22:16.259749: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2025-01-12 02:22:16.265749: The split file contains 5 splits. 
2025-01-12 02:22:16.267749: Desired fold for training: 0 
2025-01-12 02:22:16.269749: This split has 50 training and 13 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 5, 'patch_size': [64, 128, 128], 'median_image_size_in_voxels': [252.0, 512.0, 512.0], 'spacing': [1.244979977607727, 0.78515625, 0.78515625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset006_Lung', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [1.244979977607727, 0.78515625, 0.78515625], 'original_median_shape_after_transp': [252, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2671.0, 'mean': -273.4598083496094, 'median': -162.0, 'min': -1024.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 311.0, 'std': 346.9495849609375}}} 
 
2025-01-12 02:22:24.471331: unpacking dataset... 
2025-01-12 02:22:24.660523: unpacking done... 
2025-01-12 02:22:27.049107:  
2025-01-12 02:22:27.049107: Epoch 0 
2025-01-12 02:22:27.054125: Current learning rate: 0.01 
2025-01-12 02:23:13.970005: train_loss 0.0493 
2025-01-12 02:23:13.971007: val_loss -0.1452 
2025-01-12 02:23:13.976525: Pseudo dice [np.float32(0.0)] 
2025-01-12 02:23:13.980037: Epoch time: 46.92 s 
2025-01-12 02:23:13.983604: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-12 02:23:14.640702:  
2025-01-12 02:23:14.640702: Epoch 1 
2025-01-12 02:23:14.646220: Current learning rate: 0.00996 
2025-01-12 02:23:57.087158: train_loss -0.1904 
2025-01-12 02:23:57.087158: val_loss -0.4428 
2025-01-12 02:23:57.093222: Pseudo dice [np.float32(0.4554)] 
2025-01-12 02:23:57.096731: Epoch time: 42.45 s 
2025-01-12 02:23:57.099236: Yayy! New best EMA pseudo Dice: 0.045499999076128006 
2025-01-12 02:23:57.817995:  
2025-01-12 02:23:57.817995: Epoch 2 
2025-01-12 02:23:57.823459: Current learning rate: 0.00993 
2025-01-12 02:24:40.248196: train_loss -0.2624 
2025-01-12 02:24:40.248704: val_loss -0.3853 
2025-01-12 02:24:40.254544: Pseudo dice [np.float32(0.3597)] 
2025-01-12 02:24:40.257053: Epoch time: 42.43 s 
2025-01-12 02:24:40.260222: Yayy! New best EMA pseudo Dice: 0.07699999958276749 
2025-01-12 02:24:41.043048:  
2025-01-12 02:24:41.043048: Epoch 3 
2025-01-12 02:24:41.048614: Current learning rate: 0.00989 
2025-01-12 02:25:23.472689: train_loss -0.3754 
2025-01-12 02:25:23.473197: val_loss -0.4851 
2025-01-12 02:25:23.480335: Pseudo dice [np.float32(0.4768)] 
2025-01-12 02:25:23.483902: Epoch time: 42.43 s 
2025-01-12 02:25:23.487561: Yayy! New best EMA pseudo Dice: 0.1168999969959259 
2025-01-12 02:25:24.209509:  
2025-01-12 02:25:24.210512: Epoch 4 
2025-01-12 02:25:24.215063: Current learning rate: 0.00986 
2025-01-12 02:26:06.614355: train_loss -0.4089 
2025-01-12 02:26:06.614934: val_loss -0.57 
2025-01-12 02:26:06.620542: Pseudo dice [np.float32(0.5959)] 
2025-01-12 02:26:06.624084: Epoch time: 42.4 s 
2025-01-12 02:26:06.626634: Yayy! New best EMA pseudo Dice: 0.1648000031709671 
2025-01-12 02:26:07.514891:  
2025-01-12 02:26:07.515398: Epoch 5 
2025-01-12 02:26:07.520467: Current learning rate: 0.00982 
2025-01-12 02:26:49.939433: train_loss -0.414 
2025-01-12 02:26:49.940438: val_loss -0.5581 
2025-01-12 02:26:49.945980: Pseudo dice [np.float32(0.5307)] 
2025-01-12 02:26:49.949513: Epoch time: 42.43 s 
2025-01-12 02:26:49.952525: Yayy! New best EMA pseudo Dice: 0.2013999968767166 
2025-01-12 02:26:50.677430:  
2025-01-12 02:26:50.678433: Epoch 6 
2025-01-12 02:26:50.682991: Current learning rate: 0.00978 
2025-01-12 02:27:33.358714: train_loss -0.376 
2025-01-12 02:27:33.359217: val_loss -0.5768 
2025-01-12 02:27:33.364228: Pseudo dice [np.float32(0.5905)] 
2025-01-12 02:27:33.367736: Epoch time: 42.68 s 
2025-01-12 02:27:33.370242: Yayy! New best EMA pseudo Dice: 0.2402999997138977 
2025-01-12 02:27:34.091941:  
2025-01-12 02:27:34.091941: Epoch 7 
2025-01-12 02:27:34.097545: Current learning rate: 0.00975 
2025-01-12 02:28:16.542214: train_loss -0.4796 
2025-01-12 02:28:16.543215: val_loss -0.5849 
2025-01-12 02:28:16.548226: Pseudo dice [np.float32(0.5948)] 
2025-01-12 02:28:16.551237: Epoch time: 42.45 s 
2025-01-12 02:28:16.554746: Yayy! New best EMA pseudo Dice: 0.2757999897003174 
2025-01-12 02:28:17.291150:  
2025-01-12 02:28:17.291150: Epoch 8 
2025-01-12 02:28:17.296180: Current learning rate: 0.00971 
2025-01-12 02:28:59.767487: train_loss -0.5153 
2025-01-12 02:28:59.768495: val_loss -0.6857 
2025-01-12 02:28:59.774507: Pseudo dice [np.float32(0.7146)] 
2025-01-12 02:28:59.777520: Epoch time: 42.48 s 
2025-01-12 02:28:59.780028: Yayy! New best EMA pseudo Dice: 0.3197000026702881 
2025-01-12 02:29:00.541469:  
2025-01-12 02:29:00.541469: Epoch 9 
2025-01-12 02:29:00.546482: Current learning rate: 0.00968 
2025-01-12 02:29:42.977232: train_loss -0.4812 
2025-01-12 02:29:42.978236: val_loss -0.6609 
2025-01-12 02:29:42.984251: Pseudo dice [np.float32(0.6488)] 
2025-01-12 02:29:42.987260: Epoch time: 42.44 s 
2025-01-12 02:29:42.989766: Yayy! New best EMA pseudo Dice: 0.35260000824928284 
2025-01-12 02:29:43.709343:  
2025-01-12 02:29:43.710346: Epoch 10 
2025-01-12 02:29:43.714888: Current learning rate: 0.00964 
2025-01-12 02:30:26.141267: train_loss -0.513 
2025-01-12 02:30:26.141783: val_loss -0.6261 
2025-01-12 02:30:26.146836: Pseudo dice [np.float32(0.6327)] 
2025-01-12 02:30:26.150367: Epoch time: 42.43 s 
2025-01-12 02:30:26.153393: Yayy! New best EMA pseudo Dice: 0.3806000053882599 
2025-01-12 02:30:26.869941:  
2025-01-12 02:30:26.870444: Epoch 11 
2025-01-12 02:30:26.873952: Current learning rate: 0.0096 
2025-01-12 02:31:09.249421: train_loss -0.5092 
2025-01-12 02:31:09.249924: val_loss -0.5304 
2025-01-12 02:31:09.253990: Pseudo dice [np.float32(0.5488)] 
2025-01-12 02:31:09.257509: Epoch time: 42.38 s 
2025-01-12 02:31:09.260024: Yayy! New best EMA pseudo Dice: 0.39739999175071716 
2025-01-12 02:31:09.986991:  
2025-01-12 02:31:09.986991: Epoch 12 
2025-01-12 02:31:09.992022: Current learning rate: 0.00957 
2025-01-12 02:31:52.436494: train_loss -0.5154 
2025-01-12 02:31:52.437000: val_loss -0.6463 
2025-01-12 02:31:52.442570: Pseudo dice [np.float32(0.6906)] 
2025-01-12 02:31:52.445619: Epoch time: 42.45 s 
2025-01-12 02:31:52.448141: Yayy! New best EMA pseudo Dice: 0.42669999599456787 
2025-01-12 02:31:53.316993:  
2025-01-12 02:31:53.317996: Epoch 13 
2025-01-12 02:31:53.322562: Current learning rate: 0.00953 
2025-01-12 02:32:35.761927: train_loss -0.526 
2025-01-12 02:32:35.762927: val_loss -0.6536 
2025-01-12 02:32:35.766938: Pseudo dice [np.float32(0.6707)] 
2025-01-12 02:32:35.769444: Epoch time: 42.45 s 
2025-01-12 02:32:35.771949: Yayy! New best EMA pseudo Dice: 0.4510999917984009 
2025-01-12 02:32:36.498687:  
2025-01-12 02:32:36.499189: Epoch 14 
2025-01-12 02:32:36.504200: Current learning rate: 0.00949 
2025-01-12 02:33:18.723745: train_loss -0.5375 
2025-01-12 02:33:18.724247: val_loss -0.6649 
2025-01-12 02:33:18.729780: Pseudo dice [np.float32(0.7099)] 
2025-01-12 02:33:18.732799: Epoch time: 42.23 s 
2025-01-12 02:33:18.735816: Yayy! New best EMA pseudo Dice: 0.47699999809265137 
2025-01-12 02:33:19.473044:  
2025-01-12 02:33:19.473044: Epoch 15 
2025-01-12 02:33:19.478109: Current learning rate: 0.00946 
2025-01-12 02:34:01.743158: train_loss -0.5878 
2025-01-12 02:34:01.743660: val_loss -0.6129 
2025-01-12 02:34:01.748671: Pseudo dice [np.float32(0.666)] 
2025-01-12 02:34:01.752180: Epoch time: 42.27 s 
2025-01-12 02:34:01.755685: Yayy! New best EMA pseudo Dice: 0.4959000051021576 
2025-01-12 02:34:02.495853:  
2025-01-12 02:34:02.496853: Epoch 16 
2025-01-12 02:34:02.501920: Current learning rate: 0.00942 
2025-01-12 02:34:44.776016: train_loss -0.542 
2025-01-12 02:34:44.776518: val_loss -0.6529 
2025-01-12 02:34:44.781529: Pseudo dice [np.float32(0.704)] 
2025-01-12 02:34:44.785038: Epoch time: 42.28 s 
2025-01-12 02:34:44.787544: Yayy! New best EMA pseudo Dice: 0.516700029373169 
2025-01-12 02:34:45.531673:  
2025-01-12 02:34:45.532186: Epoch 17 
2025-01-12 02:34:45.537196: Current learning rate: 0.00939 
2025-01-12 02:35:27.772262: train_loss -0.5574 
2025-01-12 02:35:27.773266: val_loss -0.6392 
2025-01-12 02:35:27.779361: Pseudo dice [np.float32(0.6907)] 
2025-01-12 02:35:27.782398: Epoch time: 42.24 s 
2025-01-12 02:35:27.784929: Yayy! New best EMA pseudo Dice: 0.5340999960899353 
2025-01-12 02:35:28.521124:  
2025-01-12 02:35:28.522127: Epoch 18 
2025-01-12 02:35:28.526679: Current learning rate: 0.00935 
2025-01-12 02:36:10.761797: train_loss -0.5027 
2025-01-12 02:36:10.761797: val_loss -0.6375 
2025-01-12 02:36:10.767425: Pseudo dice [np.float32(0.6674)] 
2025-01-12 02:36:10.769443: Epoch time: 42.24 s 
2025-01-12 02:36:10.773501: Yayy! New best EMA pseudo Dice: 0.5473999977111816 
2025-01-12 02:36:11.507062:  
2025-01-12 02:36:11.508569: Epoch 19 
2025-01-12 02:36:11.513666: Current learning rate: 0.00931 
2025-01-12 02:36:53.749752: train_loss -0.5626 
2025-01-12 02:36:53.750778: val_loss -0.5795 
2025-01-12 02:36:53.755935: Pseudo dice [np.float32(0.6536)] 
2025-01-12 02:36:53.759477: Epoch time: 42.24 s 
2025-01-12 02:36:53.761995: Yayy! New best EMA pseudo Dice: 0.5580999851226807 
2025-01-12 02:36:54.510378:  
2025-01-12 02:36:54.510890: Epoch 20 
2025-01-12 02:36:54.515944: Current learning rate: 0.00928 
2025-01-12 02:37:36.744690: train_loss -0.4826 
2025-01-12 02:37:36.744690: val_loss -0.5585 
2025-01-12 02:37:36.750705: Pseudo dice [np.float32(0.5502)] 
2025-01-12 02:37:36.753713: Epoch time: 42.23 s 
2025-01-12 02:37:37.494302:  
2025-01-12 02:37:37.494302: Epoch 21 
2025-01-12 02:37:37.499855: Current learning rate: 0.00924 
2025-01-12 02:38:19.729450: train_loss -0.5609 
2025-01-12 02:38:19.730455: val_loss -0.5844 
2025-01-12 02:38:19.735474: Pseudo dice [np.float32(0.607)] 
2025-01-12 02:38:19.739491: Epoch time: 42.24 s 
2025-01-12 02:38:19.742000: Yayy! New best EMA pseudo Dice: 0.5622000098228455 
2025-01-12 02:38:20.474042:  
2025-01-12 02:38:20.474042: Epoch 22 
2025-01-12 02:38:20.480067: Current learning rate: 0.0092 
2025-01-12 02:39:02.725507: train_loss -0.5503 
2025-01-12 02:39:02.726010: val_loss -0.6814 
2025-01-12 02:39:02.730650: Pseudo dice [np.float32(0.7072)] 
2025-01-12 02:39:02.734686: Epoch time: 42.25 s 
2025-01-12 02:39:02.737709: Yayy! New best EMA pseudo Dice: 0.57669997215271 
2025-01-12 02:39:03.464175:  
2025-01-12 02:39:03.464175: Epoch 23 
2025-01-12 02:39:03.469816: Current learning rate: 0.00917 
2025-01-12 02:39:45.718649: train_loss -0.5855 
2025-01-12 02:39:45.718649: val_loss -0.5961 
2025-01-12 02:39:45.724750: Pseudo dice [np.float32(0.6778)] 
2025-01-12 02:39:45.727796: Epoch time: 42.25 s 
2025-01-12 02:39:45.730819: Yayy! New best EMA pseudo Dice: 0.5867999792098999 
2025-01-12 02:39:46.446097:  
2025-01-12 02:39:46.447097: Epoch 24 
2025-01-12 02:39:46.452638: Current learning rate: 0.00913 
2025-01-12 02:40:28.687512: train_loss -0.5602 
2025-01-12 02:40:28.688017: val_loss -0.5918 
2025-01-12 02:40:28.693029: Pseudo dice [np.float32(0.6371)] 
2025-01-12 02:40:28.696537: Epoch time: 42.24 s 
2025-01-12 02:40:28.700042: Yayy! New best EMA pseudo Dice: 0.5918999910354614 
2025-01-12 02:40:29.416144:  
2025-01-12 02:40:29.417147: Epoch 25 
2025-01-12 02:40:29.421710: Current learning rate: 0.0091 
2025-01-12 02:41:11.649626: train_loss -0.545 
2025-01-12 02:41:11.650624: val_loss -0.6383 
2025-01-12 02:41:11.656138: Pseudo dice [np.float32(0.6851)] 
2025-01-12 02:41:11.658644: Epoch time: 42.23 s 
2025-01-12 02:41:11.662153: Yayy! New best EMA pseudo Dice: 0.6011999845504761 
2025-01-12 02:41:12.379189:  
2025-01-12 02:41:12.379189: Epoch 26 
2025-01-12 02:41:12.385238: Current learning rate: 0.00906 
2025-01-12 02:41:54.617092: train_loss -0.5766 
2025-01-12 02:41:54.617612: val_loss -0.6815 
2025-01-12 02:41:54.623625: Pseudo dice [np.float32(0.7583)] 
2025-01-12 02:41:54.626132: Epoch time: 42.24 s 
2025-01-12 02:41:54.630140: Yayy! New best EMA pseudo Dice: 0.6169000267982483 
2025-01-12 02:41:55.348623:  
2025-01-12 02:41:55.348623: Epoch 27 
2025-01-12 02:41:55.354725: Current learning rate: 0.00902 
2025-01-12 02:42:37.606435: train_loss -0.5413 
2025-01-12 02:42:37.606938: val_loss -0.7111 
2025-01-12 02:42:37.611952: Pseudo dice [np.float32(0.7582)] 
2025-01-12 02:42:37.615462: Epoch time: 42.26 s 
2025-01-12 02:42:37.618967: Yayy! New best EMA pseudo Dice: 0.6309999823570251 
2025-01-12 02:42:38.349395:  
2025-01-12 02:42:38.349395: Epoch 28 
2025-01-12 02:42:38.354410: Current learning rate: 0.00899 
2025-01-12 02:43:20.595819: train_loss -0.5926 
2025-01-12 02:43:20.596822: val_loss -0.589 
2025-01-12 02:43:20.601891: Pseudo dice [np.float32(0.6392)] 
2025-01-12 02:43:20.604926: Epoch time: 42.25 s 
2025-01-12 02:43:20.607435: Yayy! New best EMA pseudo Dice: 0.6317999958992004 
2025-01-12 02:43:21.491898:  
2025-01-12 02:43:21.491898: Epoch 29 
2025-01-12 02:43:21.498009: Current learning rate: 0.00895 
2025-01-12 02:44:03.717166: train_loss -0.5963 
2025-01-12 02:44:03.717669: val_loss -0.6882 
2025-01-12 02:44:03.722687: Pseudo dice [np.float32(0.7017)] 
2025-01-12 02:44:03.726202: Epoch time: 42.23 s 
2025-01-12 02:44:03.729710: Yayy! New best EMA pseudo Dice: 0.6388000249862671 
2025-01-12 02:44:04.478198:  
2025-01-12 02:44:04.478701: Epoch 30 
2025-01-12 02:44:04.483295: Current learning rate: 0.00891 
2025-01-12 02:44:46.713207: train_loss -0.5412 
2025-01-12 02:44:46.713716: val_loss -0.6645 
2025-01-12 02:44:46.718297: Pseudo dice [np.float32(0.7179)] 
2025-01-12 02:44:46.720850: Epoch time: 42.24 s 
2025-01-12 02:44:46.724910: Yayy! New best EMA pseudo Dice: 0.6467000246047974 
2025-01-12 02:44:47.471672:  
2025-01-12 02:44:47.471672: Epoch 31 
2025-01-12 02:44:47.477218: Current learning rate: 0.00888 
2025-01-12 02:45:29.693535: train_loss -0.5815 
2025-01-12 02:45:29.694038: val_loss -0.5688 
2025-01-12 02:45:29.699075: Pseudo dice [np.float32(0.6007)] 
2025-01-12 02:45:29.702098: Epoch time: 42.22 s 
2025-01-12 02:45:30.273792:  
2025-01-12 02:45:30.273792: Epoch 32 
2025-01-12 02:45:30.279893: Current learning rate: 0.00884 
2025-01-12 02:46:12.519042: train_loss -0.5825 
2025-01-12 02:46:12.519546: val_loss -0.6288 
2025-01-12 02:46:12.525111: Pseudo dice [np.float32(0.6444)] 
2025-01-12 02:46:12.528166: Epoch time: 42.25 s 
2025-01-12 02:46:13.087890:  
2025-01-12 02:46:13.087890: Epoch 33 
2025-01-12 02:46:13.092903: Current learning rate: 0.0088 
2025-01-12 02:46:55.303752: train_loss -0.5963 
2025-01-12 02:46:55.304758: val_loss -0.5893 
2025-01-12 02:46:55.310783: Pseudo dice [np.float32(0.655)] 
2025-01-12 02:46:55.313296: Epoch time: 42.22 s 
2025-01-12 02:46:55.870159:  
2025-01-12 02:46:55.871164: Epoch 34 
2025-01-12 02:46:55.876245: Current learning rate: 0.00877 
2025-01-12 02:47:38.090558: train_loss -0.5543 
2025-01-12 02:47:38.090558: val_loss -0.7047 
2025-01-12 02:47:38.097217: Pseudo dice [np.float32(0.7724)] 
2025-01-12 02:47:38.099766: Epoch time: 42.22 s 
2025-01-12 02:47:38.103312: Yayy! New best EMA pseudo Dice: 0.656499981880188 
2025-01-12 02:47:38.847080:  
2025-01-12 02:47:38.848085: Epoch 35 
2025-01-12 02:47:38.853113: Current learning rate: 0.00873 
2025-01-12 02:48:21.080683: train_loss -0.589 
2025-01-12 02:48:21.081682: val_loss -0.6296 
2025-01-12 02:48:21.086701: Pseudo dice [np.float32(0.6856)] 
2025-01-12 02:48:21.089714: Epoch time: 42.23 s 
2025-01-12 02:48:21.092263: Yayy! New best EMA pseudo Dice: 0.6593999862670898 
2025-01-12 02:48:21.983127:  
2025-01-12 02:48:21.984127: Epoch 36 
2025-01-12 02:48:21.990649: Current learning rate: 0.00869 
2025-01-12 02:49:04.222707: train_loss -0.6213 
2025-01-12 02:49:04.222707: val_loss -0.6113 
2025-01-12 02:49:04.228793: Pseudo dice [np.float32(0.668)] 
2025-01-12 02:49:04.231919: Epoch time: 42.24 s 
2025-01-12 02:49:04.234981: Yayy! New best EMA pseudo Dice: 0.6603000164031982 
2025-01-12 02:49:04.971499:  
2025-01-12 02:49:04.972502: Epoch 37 
2025-01-12 02:49:04.977063: Current learning rate: 0.00866 
2025-01-12 02:49:47.230968: train_loss -0.5759 
2025-01-12 02:49:47.232470: val_loss -0.6042 
2025-01-12 02:49:47.237483: Pseudo dice [np.float32(0.6949)] 
2025-01-12 02:49:47.240994: Epoch time: 42.26 s 
2025-01-12 02:49:47.243501: Yayy! New best EMA pseudo Dice: 0.6636999845504761 
2025-01-12 02:49:47.984481:  
2025-01-12 02:49:47.984481: Epoch 38 
2025-01-12 02:49:47.989499: Current learning rate: 0.00862 
2025-01-12 02:50:30.197568: train_loss -0.5858 
2025-01-12 02:50:30.198572: val_loss -0.6197 
2025-01-12 02:50:30.203695: Pseudo dice [np.float32(0.6264)] 
2025-01-12 02:50:30.207297: Epoch time: 42.21 s 
2025-01-12 02:50:30.778323:  
2025-01-12 02:50:30.778323: Epoch 39 
2025-01-12 02:50:30.783404: Current learning rate: 0.00858 
2025-01-12 02:51:12.993543: train_loss -0.5605 
2025-01-12 02:51:12.994053: val_loss -0.6131 
2025-01-12 02:51:12.999094: Pseudo dice [np.float32(0.6499)] 
2025-01-12 02:51:13.002620: Epoch time: 42.22 s 
2025-01-12 02:51:13.581099:  
2025-01-12 02:51:13.581099: Epoch 40 
2025-01-12 02:51:13.586143: Current learning rate: 0.00855 
2025-01-12 02:51:55.844352: train_loss -0.6102 
2025-01-12 02:51:55.845862: val_loss -0.6053 
2025-01-12 02:51:55.851454: Pseudo dice [np.float32(0.666)] 
2025-01-12 02:51:55.854517: Epoch time: 42.26 s 
2025-01-12 02:51:56.441605:  
2025-01-12 02:51:56.441605: Epoch 41 
2025-01-12 02:51:56.447141: Current learning rate: 0.00851 
2025-01-12 02:52:38.676120: train_loss -0.5819 
2025-01-12 02:52:38.676623: val_loss -0.6863 
2025-01-12 02:52:38.682284: Pseudo dice [np.float32(0.745)] 
2025-01-12 02:52:38.685865: Epoch time: 42.24 s 
2025-01-12 02:52:38.688411: Yayy! New best EMA pseudo Dice: 0.6682000160217285 
2025-01-12 02:52:39.417060:  
2025-01-12 02:52:39.418060: Epoch 42 
2025-01-12 02:52:39.422632: Current learning rate: 0.00847 
2025-01-12 02:53:21.691058: train_loss -0.5974 
2025-01-12 02:53:21.691573: val_loss -0.6557 
2025-01-12 02:53:21.698168: Pseudo dice [np.float32(0.6515)] 
2025-01-12 02:53:21.701191: Epoch time: 42.27 s 
2025-01-12 02:53:22.260806:  
2025-01-12 02:53:22.260806: Epoch 43 
2025-01-12 02:53:22.265832: Current learning rate: 0.00844 
2025-01-12 02:54:04.523683: train_loss -0.5567 
2025-01-12 02:54:04.523683: val_loss -0.6289 
2025-01-12 02:54:04.528717: Pseudo dice [np.float32(0.7041)] 
2025-01-12 02:54:04.532740: Epoch time: 42.26 s 
2025-01-12 02:54:04.535759: Yayy! New best EMA pseudo Dice: 0.6703000068664551 
2025-01-12 02:54:05.431463:  
2025-01-12 02:54:05.431463: Epoch 44 
2025-01-12 02:54:05.436473: Current learning rate: 0.0084 
2025-01-12 02:54:47.687503: train_loss -0.6283 
2025-01-12 02:54:47.687503: val_loss -0.7082 
2025-01-12 02:54:47.693524: Pseudo dice [np.float32(0.7338)] 
2025-01-12 02:54:47.696536: Epoch time: 42.26 s 
2025-01-12 02:54:47.699044: Yayy! New best EMA pseudo Dice: 0.6765999794006348 
2025-01-12 02:54:48.433015:  
2025-01-12 02:54:48.433015: Epoch 45 
2025-01-12 02:54:48.438574: Current learning rate: 0.00836 
2025-01-12 02:55:30.703198: train_loss -0.6108 
2025-01-12 02:55:30.703198: val_loss -0.6665 
2025-01-12 02:55:30.709230: Pseudo dice [np.float32(0.7071)] 
2025-01-12 02:55:30.712301: Epoch time: 42.27 s 
2025-01-12 02:55:30.715824: Yayy! New best EMA pseudo Dice: 0.6797000169754028 
2025-01-12 02:55:31.436082:  
2025-01-12 02:55:31.436082: Epoch 46 
2025-01-12 02:55:31.441132: Current learning rate: 0.00833 
2025-01-12 02:56:13.696171: train_loss -0.6049 
2025-01-12 02:56:13.696674: val_loss -0.6911 
2025-01-12 02:56:13.701684: Pseudo dice [np.float32(0.7302)] 
2025-01-12 02:56:13.705193: Epoch time: 42.26 s 
2025-01-12 02:56:13.707699: Yayy! New best EMA pseudo Dice: 0.6848000288009644 
2025-01-12 02:56:14.431276:  
2025-01-12 02:56:14.432281: Epoch 47 
2025-01-12 02:56:14.436830: Current learning rate: 0.00829 
2025-01-12 02:56:56.676692: train_loss -0.613 
2025-01-12 02:56:56.677206: val_loss -0.5765 
2025-01-12 02:56:56.680749: Pseudo dice [np.float32(0.6529)] 
2025-01-12 02:56:56.684760: Epoch time: 42.25 s 
2025-01-12 02:56:57.239471:  
2025-01-12 02:56:57.239471: Epoch 48 
2025-01-12 02:56:57.243493: Current learning rate: 0.00825 
2025-01-12 02:57:39.503024: train_loss -0.566 
2025-01-12 02:57:39.503532: val_loss -0.6569 
2025-01-12 02:57:39.509089: Pseudo dice [np.float32(0.7378)] 
2025-01-12 02:57:39.512214: Epoch time: 42.26 s 
2025-01-12 02:57:39.515256: Yayy! New best EMA pseudo Dice: 0.6872000098228455 
2025-01-12 02:57:40.258460:  
2025-01-12 02:57:40.258965: Epoch 49 
2025-01-12 02:57:40.263474: Current learning rate: 0.00822 
2025-01-12 02:58:22.493090: train_loss -0.6105 
2025-01-12 02:58:22.493090: val_loss -0.7262 
2025-01-12 02:58:22.499114: Pseudo dice [np.float32(0.783)] 
2025-01-12 02:58:22.502624: Epoch time: 42.24 s 
2025-01-12 02:58:22.656249: Yayy! New best EMA pseudo Dice: 0.6967999935150146 
2025-01-12 02:58:23.376864:  
2025-01-12 02:58:23.376864: Epoch 50 
2025-01-12 02:58:23.382443: Current learning rate: 0.00818 
2025-01-12 02:59:05.616466: train_loss -0.6147 
2025-01-12 02:59:05.617466: val_loss -0.6522 
2025-01-12 02:59:05.622988: Pseudo dice [np.float32(0.7283)] 
2025-01-12 02:59:05.626500: Epoch time: 42.24 s 
2025-01-12 02:59:05.629006: Yayy! New best EMA pseudo Dice: 0.6998999714851379 
2025-01-12 02:59:06.365913:  
2025-01-12 02:59:06.365913: Epoch 51 
2025-01-12 02:59:06.370926: Current learning rate: 0.00814 
2025-01-12 02:59:48.599212: train_loss -0.5817 
2025-01-12 02:59:48.600214: val_loss -0.6752 
2025-01-12 02:59:48.605235: Pseudo dice [np.float32(0.7576)] 
2025-01-12 02:59:48.608750: Epoch time: 42.23 s 
2025-01-12 02:59:48.611764: Yayy! New best EMA pseudo Dice: 0.7056999802589417 
2025-01-12 02:59:49.517568:  
2025-01-12 02:59:49.518072: Epoch 52 
2025-01-12 02:59:49.522583: Current learning rate: 0.00811 
2025-01-12 03:00:31.771586: train_loss -0.6241 
2025-01-12 03:00:31.772091: val_loss -0.6183 
2025-01-12 03:00:31.778186: Pseudo dice [np.float32(0.6729)] 
2025-01-12 03:00:31.781754: Epoch time: 42.26 s 
2025-01-12 03:00:32.344824:  
2025-01-12 03:00:32.345828: Epoch 53 
2025-01-12 03:00:32.351366: Current learning rate: 0.00807 
2025-01-12 03:01:14.608607: train_loss -0.5861 
2025-01-12 03:01:14.608607: val_loss -0.6484 
2025-01-12 03:01:14.615126: Pseudo dice [np.float32(0.6986)] 
2025-01-12 03:01:14.618638: Epoch time: 42.26 s 
2025-01-12 03:01:15.194466:  
2025-01-12 03:01:15.195472: Epoch 54 
2025-01-12 03:01:15.200530: Current learning rate: 0.00803 
2025-01-12 03:01:57.449217: train_loss -0.5742 
2025-01-12 03:01:57.450221: val_loss -0.672 
2025-01-12 03:01:57.455233: Pseudo dice [np.float32(0.722)] 
2025-01-12 03:01:57.459246: Epoch time: 42.26 s 
2025-01-12 03:01:58.025607:  
2025-01-12 03:01:58.025607: Epoch 55 
2025-01-12 03:01:58.031139: Current learning rate: 0.008 
2025-01-12 03:02:40.307370: train_loss -0.5923 
2025-01-12 03:02:40.307910: val_loss -0.6637 
2025-01-12 03:02:40.313486: Pseudo dice [np.float32(0.7446)] 
2025-01-12 03:02:40.317091: Epoch time: 42.28 s 
2025-01-12 03:02:40.320165: Yayy! New best EMA pseudo Dice: 0.7081000208854675 
2025-01-12 03:02:41.059969:  
2025-01-12 03:02:41.059969: Epoch 56 
2025-01-12 03:02:41.066039: Current learning rate: 0.00796 
2025-01-12 03:03:23.298928: train_loss -0.6234 
2025-01-12 03:03:23.299437: val_loss -0.7415 
2025-01-12 03:03:23.304974: Pseudo dice [np.float32(0.7932)] 
2025-01-12 03:03:23.308987: Epoch time: 42.24 s 
2025-01-12 03:03:23.312498: Yayy! New best EMA pseudo Dice: 0.7166000008583069 
2025-01-12 03:03:24.056319:  
2025-01-12 03:03:24.057319: Epoch 57 
2025-01-12 03:03:24.061867: Current learning rate: 0.00792 
2025-01-12 03:04:06.283548: train_loss -0.6165 
2025-01-12 03:04:06.284064: val_loss -0.7229 
2025-01-12 03:04:06.289123: Pseudo dice [np.float32(0.7798)] 
2025-01-12 03:04:06.292684: Epoch time: 42.23 s 
2025-01-12 03:04:06.296284: Yayy! New best EMA pseudo Dice: 0.7228999733924866 
2025-01-12 03:04:07.032318:  
2025-01-12 03:04:07.032318: Epoch 58 
2025-01-12 03:04:07.037374: Current learning rate: 0.00789 
2025-01-12 03:04:49.299133: train_loss -0.5714 
2025-01-12 03:04:49.299643: val_loss -0.6284 
2025-01-12 03:04:49.305765: Pseudo dice [np.float32(0.6917)] 
2025-01-12 03:04:49.309358: Epoch time: 42.27 s 
2025-01-12 03:04:49.876912:  
2025-01-12 03:04:49.877418: Epoch 59 
2025-01-12 03:04:49.882051: Current learning rate: 0.00785 
2025-01-12 03:05:32.151507: train_loss -0.6116 
2025-01-12 03:05:32.151507: val_loss -0.6798 
2025-01-12 03:05:32.157523: Pseudo dice [np.float32(0.7601)] 
2025-01-12 03:05:32.161031: Epoch time: 42.28 s 
2025-01-12 03:05:32.164042: Yayy! New best EMA pseudo Dice: 0.723800003528595 
2025-01-12 03:05:33.054667:  
2025-01-12 03:05:33.055661: Epoch 60 
2025-01-12 03:05:33.061182: Current learning rate: 0.00781 
2025-01-12 03:06:15.257615: train_loss -0.6406 
2025-01-12 03:06:15.258621: val_loss -0.7227 
2025-01-12 03:06:15.262828: Pseudo dice [np.float32(0.7932)] 
2025-01-12 03:06:15.266405: Epoch time: 42.2 s 
2025-01-12 03:06:15.269041: Yayy! New best EMA pseudo Dice: 0.7307999730110168 
2025-01-12 03:06:16.007701:  
2025-01-12 03:06:16.007701: Epoch 61 
2025-01-12 03:06:16.013719: Current learning rate: 0.00777 
2025-01-12 03:06:58.252467: train_loss -0.5963 
2025-01-12 03:06:58.253467: val_loss -0.6242 
2025-01-12 03:06:58.259990: Pseudo dice [np.float32(0.6903)] 
2025-01-12 03:06:58.262496: Epoch time: 42.25 s 
2025-01-12 03:06:58.820486:  
2025-01-12 03:06:58.821492: Epoch 62 
2025-01-12 03:06:58.826039: Current learning rate: 0.00774 
2025-01-12 03:07:41.089793: train_loss -0.6224 
2025-01-12 03:07:41.089793: val_loss -0.6963 
2025-01-12 03:07:41.095845: Pseudo dice [np.float32(0.7791)] 
2025-01-12 03:07:41.099891: Epoch time: 42.27 s 
2025-01-12 03:07:41.103420: Yayy! New best EMA pseudo Dice: 0.7319999933242798 
2025-01-12 03:07:41.836325:  
2025-01-12 03:07:41.837330: Epoch 63 
2025-01-12 03:07:41.841879: Current learning rate: 0.0077 
2025-01-12 03:08:24.057211: train_loss -0.6236 
2025-01-12 03:08:24.057721: val_loss -0.6518 
2025-01-12 03:08:24.063442: Pseudo dice [np.float32(0.7303)] 
2025-01-12 03:08:24.067027: Epoch time: 42.22 s 
2025-01-12 03:08:24.628135:  
2025-01-12 03:08:24.628135: Epoch 64 
2025-01-12 03:08:24.634153: Current learning rate: 0.00766 
2025-01-12 03:09:06.853657: train_loss -0.6328 
2025-01-12 03:09:06.854657: val_loss -0.683 
2025-01-12 03:09:06.861189: Pseudo dice [np.float32(0.7581)] 
2025-01-12 03:09:06.865205: Epoch time: 42.23 s 
2025-01-12 03:09:06.868720: Yayy! New best EMA pseudo Dice: 0.7343999743461609 
2025-01-12 03:09:07.607245:  
2025-01-12 03:09:07.607245: Epoch 65 
2025-01-12 03:09:07.612796: Current learning rate: 0.00763 
2025-01-12 03:09:49.835759: train_loss -0.6474 
2025-01-12 03:09:49.837280: val_loss -0.6608 
2025-01-12 03:09:49.842370: Pseudo dice [np.float32(0.7128)] 
2025-01-12 03:09:49.845960: Epoch time: 42.23 s 
2025-01-12 03:09:50.414174:  
2025-01-12 03:09:50.414174: Epoch 66 
2025-01-12 03:09:50.419206: Current learning rate: 0.00759 
2025-01-12 03:10:32.637575: train_loss -0.6373 
2025-01-12 03:10:32.638579: val_loss -0.6535 
2025-01-12 03:10:32.643591: Pseudo dice [np.float32(0.7648)] 
2025-01-12 03:10:32.647101: Epoch time: 42.22 s 
2025-01-12 03:10:32.650111: Yayy! New best EMA pseudo Dice: 0.7354999780654907 
2025-01-12 03:10:33.395142:  
2025-01-12 03:10:33.395142: Epoch 67 
2025-01-12 03:10:33.400198: Current learning rate: 0.00755 
2025-01-12 03:11:15.629390: train_loss -0.6395 
2025-01-12 03:11:15.629898: val_loss -0.7073 
2025-01-12 03:11:15.634933: Pseudo dice [np.float32(0.776)] 
2025-01-12 03:11:15.638455: Epoch time: 42.24 s 
2025-01-12 03:11:15.640495: Yayy! New best EMA pseudo Dice: 0.7396000027656555 
2025-01-12 03:11:16.552032:  
2025-01-12 03:11:16.552032: Epoch 68 
2025-01-12 03:11:16.557081: Current learning rate: 0.00751 
2025-01-12 03:11:58.781854: train_loss -0.6441 
2025-01-12 03:11:58.782854: val_loss -0.6845 
2025-01-12 03:11:58.788375: Pseudo dice [np.float32(0.7447)] 
2025-01-12 03:11:58.791888: Epoch time: 42.23 s 
2025-01-12 03:11:58.794397: Yayy! New best EMA pseudo Dice: 0.7401000261306763 
2025-01-12 03:11:59.548380:  
2025-01-12 03:11:59.548380: Epoch 69 
2025-01-12 03:11:59.551397: Current learning rate: 0.00748 
2025-01-12 03:12:41.776721: train_loss -0.6715 
2025-01-12 03:12:41.777235: val_loss -0.5432 
2025-01-12 03:12:41.782805: Pseudo dice [np.float32(0.6322)] 
2025-01-12 03:12:41.785898: Epoch time: 42.23 s 
2025-01-12 03:12:42.365224:  
2025-01-12 03:12:42.365224: Epoch 70 
2025-01-12 03:12:42.370234: Current learning rate: 0.00744 
2025-01-12 03:13:24.559309: train_loss -0.6136 
2025-01-12 03:13:24.559812: val_loss -0.6479 
2025-01-12 03:13:24.564825: Pseudo dice [np.float32(0.7256)] 
2025-01-12 03:13:24.568337: Epoch time: 42.19 s 
2025-01-12 03:13:25.147126:  
2025-01-12 03:13:25.147628: Epoch 71 
2025-01-12 03:13:25.152729: Current learning rate: 0.0074 
2025-01-12 03:14:07.376004: train_loss -0.6556 
2025-01-12 03:14:07.376004: val_loss -0.6591 
2025-01-12 03:14:07.381020: Pseudo dice [np.float32(0.7199)] 
2025-01-12 03:14:07.385031: Epoch time: 42.23 s 
2025-01-12 03:14:07.965484:  
2025-01-12 03:14:07.965484: Epoch 72 
2025-01-12 03:14:07.970495: Current learning rate: 0.00737 
2025-01-12 03:14:50.187787: train_loss -0.6602 
2025-01-12 03:14:50.188295: val_loss -0.6407 
2025-01-12 03:14:50.193332: Pseudo dice [np.float32(0.6783)] 
2025-01-12 03:14:50.197358: Epoch time: 42.22 s 
2025-01-12 03:14:50.777158:  
2025-01-12 03:14:50.777158: Epoch 73 
2025-01-12 03:14:50.782768: Current learning rate: 0.00733 
2025-01-12 03:15:32.998466: train_loss -0.6537 
2025-01-12 03:15:32.998968: val_loss -0.6982 
2025-01-12 03:15:33.004605: Pseudo dice [np.float32(0.763)] 
2025-01-12 03:15:33.008657: Epoch time: 42.22 s 
2025-01-12 03:15:33.583072:  
2025-01-12 03:15:33.584074: Epoch 74 
2025-01-12 03:15:33.589130: Current learning rate: 0.00729 
2025-01-12 03:16:15.830487: train_loss -0.6477 
2025-01-12 03:16:15.831489: val_loss -0.6493 
2025-01-12 03:16:15.837013: Pseudo dice [np.float32(0.7509)] 
2025-01-12 03:16:15.840529: Epoch time: 42.25 s 
2025-01-12 03:16:16.410993:  
2025-01-12 03:16:16.412497: Epoch 75 
2025-01-12 03:16:16.416006: Current learning rate: 0.00725 
2025-01-12 03:16:58.652902: train_loss -0.6381 
2025-01-12 03:16:58.653405: val_loss -0.6403 
2025-01-12 03:16:58.658423: Pseudo dice [np.float32(0.6674)] 
2025-01-12 03:16:58.661938: Epoch time: 42.24 s 
2025-01-12 03:16:59.377570:  
2025-01-12 03:16:59.377570: Epoch 76 
2025-01-12 03:16:59.383121: Current learning rate: 0.00722 
2025-01-12 03:17:41.597335: train_loss -0.6481 
2025-01-12 03:17:41.597335: val_loss -0.5479 
2025-01-12 03:17:41.602352: Pseudo dice [np.float32(0.6688)] 
2025-01-12 03:17:41.605868: Epoch time: 42.22 s 
2025-01-12 03:17:42.173642:  
2025-01-12 03:17:42.173642: Epoch 77 
2025-01-12 03:17:42.176667: Current learning rate: 0.00718 
2025-01-12 03:18:24.403248: train_loss -0.6072 
2025-01-12 03:18:24.403750: val_loss -0.6687 
2025-01-12 03:18:24.410770: Pseudo dice [np.float32(0.7062)] 
2025-01-12 03:18:24.413780: Epoch time: 42.23 s 
2025-01-12 03:18:24.987018:  
2025-01-12 03:18:24.987018: Epoch 78 
2025-01-12 03:18:24.992569: Current learning rate: 0.00714 
2025-01-12 03:19:07.224373: train_loss -0.61 
2025-01-12 03:19:07.224875: val_loss -0.62 
2025-01-12 03:19:07.229891: Pseudo dice [np.float32(0.6834)] 
2025-01-12 03:19:07.233405: Epoch time: 42.24 s 
2025-01-12 03:19:07.818787:  
2025-01-12 03:19:07.818787: Epoch 79 
2025-01-12 03:19:07.823816: Current learning rate: 0.0071 
2025-01-12 03:19:50.060462: train_loss -0.6683 
2025-01-12 03:19:50.060976: val_loss -0.6699 
2025-01-12 03:19:50.066068: Pseudo dice [np.float32(0.7354)] 
2025-01-12 03:19:50.070099: Epoch time: 42.24 s 
2025-01-12 03:19:50.646987:  
2025-01-12 03:19:50.647987: Epoch 80 
2025-01-12 03:19:50.653065: Current learning rate: 0.00707 
2025-01-12 03:20:32.877104: train_loss -0.687 
2025-01-12 03:20:32.878105: val_loss -0.6249 
2025-01-12 03:20:32.883627: Pseudo dice [np.float32(0.6645)] 
2025-01-12 03:20:32.887143: Epoch time: 42.23 s 
2025-01-12 03:20:33.472695:  
2025-01-12 03:20:33.473695: Epoch 81 
2025-01-12 03:20:33.478809: Current learning rate: 0.00703 
2025-01-12 03:21:15.720087: train_loss -0.6262 
2025-01-12 03:21:15.721092: val_loss -0.7135 
2025-01-12 03:21:15.726109: Pseudo dice [np.float32(0.7512)] 
2025-01-12 03:21:15.728620: Epoch time: 42.25 s 
2025-01-12 03:21:16.311862:  
2025-01-12 03:21:16.311862: Epoch 82 
2025-01-12 03:21:16.316877: Current learning rate: 0.00699 
2025-01-12 03:21:58.533682: train_loss -0.6243 
2025-01-12 03:21:58.533682: val_loss -0.6817 
2025-01-12 03:21:58.540277: Pseudo dice [np.float32(0.7263)] 
2025-01-12 03:21:58.543371: Epoch time: 42.22 s 
2025-01-12 03:21:59.092880:  
2025-01-12 03:21:59.093879: Epoch 83 
2025-01-12 03:21:59.098939: Current learning rate: 0.00696 
2025-01-12 03:22:41.365315: train_loss -0.6389 
2025-01-12 03:22:41.365823: val_loss -0.7222 
2025-01-12 03:22:41.370939: Pseudo dice [np.float32(0.7693)] 
2025-01-12 03:22:41.374465: Epoch time: 42.27 s 
2025-01-12 03:22:42.082787:  
2025-01-12 03:22:42.083788: Epoch 84 
2025-01-12 03:22:42.086831: Current learning rate: 0.00692 
2025-01-12 03:23:24.311396: train_loss -0.6439 
2025-01-12 03:23:24.312403: val_loss -0.6895 
2025-01-12 03:23:24.317416: Pseudo dice [np.float32(0.7298)] 
2025-01-12 03:23:24.319924: Epoch time: 42.23 s 
2025-01-12 03:23:24.867203:  
2025-01-12 03:23:24.867203: Epoch 85 
2025-01-12 03:23:24.872218: Current learning rate: 0.00688 
2025-01-12 03:24:07.113849: train_loss -0.6372 
2025-01-12 03:24:07.114358: val_loss -0.7332 
2025-01-12 03:24:07.120432: Pseudo dice [np.float32(0.8022)] 
2025-01-12 03:24:07.123468: Epoch time: 42.25 s 
2025-01-12 03:24:07.680907:  
2025-01-12 03:24:07.681415: Epoch 86 
2025-01-12 03:24:07.685952: Current learning rate: 0.00684 
2025-01-12 03:24:49.928629: train_loss -0.6408 
2025-01-12 03:24:49.929631: val_loss -0.6307 
2025-01-12 03:24:49.935154: Pseudo dice [np.float32(0.6515)] 
2025-01-12 03:24:49.937663: Epoch time: 42.25 s 
2025-01-12 03:24:50.495620:  
2025-01-12 03:24:50.495620: Epoch 87 
2025-01-12 03:24:50.500636: Current learning rate: 0.0068 
2025-01-12 03:25:32.738238: train_loss -0.643 
2025-01-12 03:25:32.738238: val_loss -0.7195 
2025-01-12 03:25:32.743253: Pseudo dice [np.float32(0.7461)] 
2025-01-12 03:25:32.746764: Epoch time: 42.24 s 
2025-01-12 03:25:33.293324:  
2025-01-12 03:25:33.294327: Epoch 88 
2025-01-12 03:25:33.299189: Current learning rate: 0.00677 
2025-01-12 03:26:15.534695: train_loss -0.6525 
2025-01-12 03:26:15.535700: val_loss -0.6921 
2025-01-12 03:26:15.539709: Pseudo dice [np.float32(0.7769)] 
2025-01-12 03:26:15.543219: Epoch time: 42.24 s 
2025-01-12 03:26:16.087143:  
2025-01-12 03:26:16.088143: Epoch 89 
2025-01-12 03:26:16.092699: Current learning rate: 0.00673 
2025-01-12 03:26:58.329825: train_loss -0.6681 
2025-01-12 03:26:58.329825: val_loss -0.6734 
2025-01-12 03:26:58.335840: Pseudo dice [np.float32(0.721)] 
2025-01-12 03:26:58.338850: Epoch time: 42.24 s 
2025-01-12 03:26:58.889182:  
2025-01-12 03:26:58.889182: Epoch 90 
2025-01-12 03:26:58.894213: Current learning rate: 0.00669 
2025-01-12 03:27:41.132831: train_loss -0.6995 
2025-01-12 03:27:41.133833: val_loss -0.7445 
2025-01-12 03:27:41.139856: Pseudo dice [np.float32(0.7783)] 
2025-01-12 03:27:41.142869: Epoch time: 42.24 s 
2025-01-12 03:27:41.687194:  
2025-01-12 03:27:41.688191: Epoch 91 
2025-01-12 03:27:41.695795: Current learning rate: 0.00665 
2025-01-12 03:28:23.952690: train_loss -0.692 
2025-01-12 03:28:23.952690: val_loss -0.702 
2025-01-12 03:28:23.957707: Pseudo dice [np.float32(0.7997)] 
2025-01-12 03:28:23.961222: Epoch time: 42.26 s 
2025-01-12 03:28:23.964737: Yayy! New best EMA pseudo Dice: 0.7404000163078308 
2025-01-12 03:28:24.833685:  
2025-01-12 03:28:24.834684: Epoch 92 
2025-01-12 03:28:24.839729: Current learning rate: 0.00662 
2025-01-12 03:29:07.064016: train_loss -0.646 
2025-01-12 03:29:07.064524: val_loss -0.6353 
2025-01-12 03:29:07.070138: Pseudo dice [np.float32(0.6883)] 
2025-01-12 03:29:07.073267: Epoch time: 42.23 s 
2025-01-12 03:29:07.621249:  
2025-01-12 03:29:07.622256: Epoch 93 
2025-01-12 03:29:07.627314: Current learning rate: 0.00658 
2025-01-12 03:29:49.898289: train_loss -0.6535 
2025-01-12 03:29:49.899294: val_loss -0.5753 
2025-01-12 03:29:49.904307: Pseudo dice [np.float32(0.6337)] 
2025-01-12 03:29:49.908318: Epoch time: 42.28 s 
2025-01-12 03:29:50.456277:  
2025-01-12 03:29:50.456780: Epoch 94 
2025-01-12 03:29:50.461792: Current learning rate: 0.00654 
2025-01-12 03:30:32.689529: train_loss -0.626 
2025-01-12 03:30:32.690040: val_loss -0.6817 
2025-01-12 03:30:32.695081: Pseudo dice [np.float32(0.757)] 
2025-01-12 03:30:32.698115: Epoch time: 42.23 s 
2025-01-12 03:30:33.252254:  
2025-01-12 03:30:33.253253: Epoch 95 
2025-01-12 03:30:33.258267: Current learning rate: 0.0065 
2025-01-12 03:31:15.492388: train_loss -0.6613 
2025-01-12 03:31:15.493389: val_loss -0.703 
2025-01-12 03:31:15.498907: Pseudo dice [np.float32(0.7717)] 
2025-01-12 03:31:15.501416: Epoch time: 42.24 s 
2025-01-12 03:31:16.062516:  
2025-01-12 03:31:16.062516: Epoch 96 
2025-01-12 03:31:16.067558: Current learning rate: 0.00647 
2025-01-12 03:31:58.283705: train_loss -0.6015 
2025-01-12 03:31:58.283705: val_loss -0.6666 
2025-01-12 03:31:58.289726: Pseudo dice [np.float32(0.6834)] 
2025-01-12 03:31:58.292740: Epoch time: 42.22 s 
2025-01-12 03:31:58.855100:  
2025-01-12 03:31:58.856105: Epoch 97 
2025-01-12 03:31:58.860659: Current learning rate: 0.00643 
2025-01-12 03:32:41.118311: train_loss -0.6978 
2025-01-12 03:32:41.118821: val_loss -0.6854 
2025-01-12 03:32:41.124470: Pseudo dice [np.float32(0.7573)] 
2025-01-12 03:32:41.128045: Epoch time: 42.26 s 
2025-01-12 03:32:41.691537:  
2025-01-12 03:32:41.691537: Epoch 98 
2025-01-12 03:32:41.696632: Current learning rate: 0.00639 
2025-01-12 03:33:23.944608: train_loss -0.6539 
2025-01-12 03:33:23.945612: val_loss -0.6171 
2025-01-12 03:33:23.952205: Pseudo dice [np.float32(0.6922)] 
2025-01-12 03:33:23.955227: Epoch time: 42.25 s 
2025-01-12 03:33:24.516690:  
2025-01-12 03:33:24.517691: Epoch 99 
2025-01-12 03:33:24.523277: Current learning rate: 0.00635 
2025-01-12 03:34:06.737286: train_loss -0.6528 
2025-01-12 03:34:06.738286: val_loss -0.7288 
2025-01-12 03:34:06.743806: Pseudo dice [np.float32(0.8004)] 
2025-01-12 03:34:06.747322: Epoch time: 42.22 s 
2025-01-12 03:34:07.639815:  
2025-01-12 03:34:07.639815: Epoch 100 
2025-01-12 03:34:07.645873: Current learning rate: 0.00631 
2025-01-12 03:34:49.872194: train_loss -0.6995 
2025-01-12 03:34:49.872194: val_loss -0.6115 
2025-01-12 03:34:49.878308: Pseudo dice [np.float32(0.6717)] 
2025-01-12 03:34:49.881368: Epoch time: 42.23 s 
2025-01-12 03:34:50.443014:  
2025-01-12 03:34:50.443522: Epoch 101 
2025-01-12 03:34:50.448566: Current learning rate: 0.00628 
2025-01-12 03:35:32.701612: train_loss -0.666 
2025-01-12 03:35:32.702615: val_loss -0.7153 
2025-01-12 03:35:32.707634: Pseudo dice [np.float32(0.7854)] 
2025-01-12 03:35:32.711646: Epoch time: 42.26 s 
2025-01-12 03:35:33.268246:  
2025-01-12 03:35:33.268246: Epoch 102 
2025-01-12 03:35:33.273793: Current learning rate: 0.00624 
2025-01-12 03:36:15.492457: train_loss -0.6711 
2025-01-12 03:36:15.492457: val_loss -0.6855 
2025-01-12 03:36:15.498474: Pseudo dice [np.float32(0.7885)] 
2025-01-12 03:36:15.500983: Epoch time: 42.23 s 
2025-01-12 03:36:16.065366:  
2025-01-12 03:36:16.066870: Epoch 103 
2025-01-12 03:36:16.071438: Current learning rate: 0.0062 
2025-01-12 03:36:58.269551: train_loss -0.6683 
2025-01-12 03:36:58.270555: val_loss -0.6728 
2025-01-12 03:36:58.275594: Pseudo dice [np.float32(0.7215)] 
2025-01-12 03:36:58.279615: Epoch time: 42.21 s 
2025-01-12 03:36:58.835780:  
2025-01-12 03:36:58.835780: Epoch 104 
2025-01-12 03:36:58.841908: Current learning rate: 0.00616 
2025-01-12 03:37:41.078984: train_loss -0.6716 
2025-01-12 03:37:41.078984: val_loss -0.6935 
2025-01-12 03:37:41.085005: Pseudo dice [np.float32(0.7444)] 
2025-01-12 03:37:41.088514: Epoch time: 42.24 s 
2025-01-12 03:37:41.644844:  
2025-01-12 03:37:41.645848: Epoch 105 
2025-01-12 03:37:41.650398: Current learning rate: 0.00612 
2025-01-12 03:38:23.906962: train_loss -0.67 
2025-01-12 03:38:23.907489: val_loss -0.5871 
2025-01-12 03:38:23.914509: Pseudo dice [np.float32(0.6983)] 
2025-01-12 03:38:23.917524: Epoch time: 42.26 s 
2025-01-12 03:38:24.475446:  
2025-01-12 03:38:24.475446: Epoch 106 
2025-01-12 03:38:24.480994: Current learning rate: 0.00609 
2025-01-12 03:39:06.743148: train_loss -0.668 
2025-01-12 03:39:06.743148: val_loss -0.682 
2025-01-12 03:39:06.749783: Pseudo dice [np.float32(0.7226)] 
2025-01-12 03:39:06.753304: Epoch time: 42.27 s 
2025-01-12 03:39:07.318502:  
2025-01-12 03:39:07.319005: Epoch 107 
2025-01-12 03:39:07.324018: Current learning rate: 0.00605 
2025-01-12 03:39:49.533782: train_loss -0.6895 
2025-01-12 03:39:49.534787: val_loss -0.6798 
2025-01-12 03:39:49.540380: Pseudo dice [np.float32(0.7614)] 
2025-01-12 03:39:49.543427: Epoch time: 42.22 s 
2025-01-12 03:39:50.263090:  
2025-01-12 03:39:50.263090: Epoch 108 
2025-01-12 03:39:50.268166: Current learning rate: 0.00601 
2025-01-12 03:40:32.447783: train_loss -0.7018 
2025-01-12 03:40:32.447783: val_loss -0.6759 
2025-01-12 03:40:32.453798: Pseudo dice [np.float32(0.7085)] 
2025-01-12 03:40:32.456809: Epoch time: 42.19 s 
2025-01-12 03:40:33.022727:  
2025-01-12 03:40:33.023729: Epoch 109 
2025-01-12 03:40:33.029845: Current learning rate: 0.00597 
2025-01-12 03:41:15.246603: train_loss -0.6738 
2025-01-12 03:41:15.247111: val_loss -0.6959 
2025-01-12 03:41:15.252773: Pseudo dice [np.float32(0.7391)] 
2025-01-12 03:41:15.255837: Epoch time: 42.22 s 
2025-01-12 03:41:15.821761:  
2025-01-12 03:41:15.821761: Epoch 110 
2025-01-12 03:41:15.826260: Current learning rate: 0.00593 
2025-01-12 03:41:58.048162: train_loss -0.7143 
2025-01-12 03:41:58.049165: val_loss -0.6364 
2025-01-12 03:41:58.054772: Pseudo dice [np.float32(0.7062)] 
2025-01-12 03:41:58.057281: Epoch time: 42.23 s 
2025-01-12 03:41:58.624490:  
2025-01-12 03:41:58.624490: Epoch 111 
2025-01-12 03:41:58.630504: Current learning rate: 0.0059 
2025-01-12 03:42:40.853835: train_loss -0.681 
2025-01-12 03:42:40.853835: val_loss -0.6678 
2025-01-12 03:42:40.859857: Pseudo dice [np.float32(0.7302)] 
2025-01-12 03:42:40.863367: Epoch time: 42.23 s 
2025-01-12 03:42:41.424038:  
2025-01-12 03:42:41.425042: Epoch 112 
2025-01-12 03:42:41.429107: Current learning rate: 0.00586 
2025-01-12 03:43:23.644019: train_loss -0.7 
2025-01-12 03:43:23.644019: val_loss -0.6011 
2025-01-12 03:43:23.651540: Pseudo dice [np.float32(0.7169)] 
2025-01-12 03:43:23.655052: Epoch time: 42.22 s 
2025-01-12 03:43:24.217247:  
2025-01-12 03:43:24.217247: Epoch 113 
2025-01-12 03:43:24.222992: Current learning rate: 0.00582 
2025-01-12 03:44:06.448622: train_loss -0.6836 
2025-01-12 03:44:06.449134: val_loss -0.6487 
2025-01-12 03:44:06.454775: Pseudo dice [np.float32(0.7058)] 
2025-01-12 03:44:06.457836: Epoch time: 42.23 s 
2025-01-12 03:44:07.012866:  
2025-01-12 03:44:07.012866: Epoch 114 
2025-01-12 03:44:07.018395: Current learning rate: 0.00578 
2025-01-12 03:44:49.254272: train_loss -0.653 
2025-01-12 03:44:49.254774: val_loss -0.6472 
2025-01-12 03:44:49.260795: Pseudo dice [np.float32(0.7293)] 
2025-01-12 03:44:49.264309: Epoch time: 42.24 s 
2025-01-12 03:44:49.813828:  
2025-01-12 03:44:49.814330: Epoch 115 
2025-01-12 03:44:49.819376: Current learning rate: 0.00574 
2025-01-12 03:45:32.031900: train_loss -0.6444 
2025-01-12 03:45:32.032925: val_loss -0.7248 
2025-01-12 03:45:32.037983: Pseudo dice [np.float32(0.8025)] 
2025-01-12 03:45:32.042530: Epoch time: 42.22 s 
2025-01-12 03:45:32.761680:  
2025-01-12 03:45:32.762184: Epoch 116 
2025-01-12 03:45:32.766695: Current learning rate: 0.0057 
2025-01-12 03:46:14.988130: train_loss -0.721 
2025-01-12 03:46:14.988130: val_loss -0.6894 
2025-01-12 03:46:14.994202: Pseudo dice [np.float32(0.7334)] 
2025-01-12 03:46:14.997716: Epoch time: 42.23 s 
2025-01-12 03:46:15.561162:  
2025-01-12 03:46:15.561162: Epoch 117 
2025-01-12 03:46:15.567107: Current learning rate: 0.00567 
2025-01-12 03:46:57.801533: train_loss -0.6558 
2025-01-12 03:46:57.802037: val_loss -0.65 
2025-01-12 03:46:57.807050: Pseudo dice [np.float32(0.7456)] 
2025-01-12 03:46:57.810560: Epoch time: 42.24 s 
2025-01-12 03:46:58.374215:  
2025-01-12 03:46:58.374718: Epoch 118 
2025-01-12 03:46:58.379732: Current learning rate: 0.00563 
2025-01-12 03:47:40.632908: train_loss -0.669 
2025-01-12 03:47:40.633912: val_loss -0.6315 
2025-01-12 03:47:40.638924: Pseudo dice [np.float32(0.7158)] 
2025-01-12 03:47:40.642939: Epoch time: 42.26 s 
2025-01-12 03:47:41.203090:  
2025-01-12 03:47:41.203090: Epoch 119 
2025-01-12 03:47:41.208104: Current learning rate: 0.00559 
2025-01-12 03:48:23.481568: train_loss -0.6311 
2025-01-12 03:48:23.482079: val_loss -0.6644 
2025-01-12 03:48:23.487256: Pseudo dice [np.float32(0.7435)] 
2025-01-12 03:48:23.490820: Epoch time: 42.28 s 
2025-01-12 03:48:24.060225:  
2025-01-12 03:48:24.060225: Epoch 120 
2025-01-12 03:48:24.065237: Current learning rate: 0.00555 
2025-01-12 03:49:06.294508: train_loss -0.6249 
2025-01-12 03:49:06.295512: val_loss -0.7139 
2025-01-12 03:49:06.300534: Pseudo dice [np.float32(0.7901)] 
2025-01-12 03:49:06.304554: Epoch time: 42.23 s 
2025-01-12 03:49:06.862361:  
2025-01-12 03:49:06.863366: Epoch 121 
2025-01-12 03:49:06.867918: Current learning rate: 0.00551 
2025-01-12 03:49:49.128550: train_loss -0.6748 
2025-01-12 03:49:49.129053: val_loss -0.6759 
2025-01-12 03:49:49.134068: Pseudo dice [np.float32(0.7909)] 
2025-01-12 03:49:49.137579: Epoch time: 42.27 s 
2025-01-12 03:49:49.140087: Yayy! New best EMA pseudo Dice: 0.7454000115394592 
2025-01-12 03:49:49.888627:  
2025-01-12 03:49:49.888627: Epoch 122 
2025-01-12 03:49:49.894167: Current learning rate: 0.00547 
2025-01-12 03:50:32.099502: train_loss -0.6315 
2025-01-12 03:50:32.099502: val_loss -0.6584 
2025-01-12 03:50:32.105516: Pseudo dice [np.float32(0.7465)] 
2025-01-12 03:50:32.109021: Epoch time: 42.21 s 
2025-01-12 03:50:32.112030: Yayy! New best EMA pseudo Dice: 0.7455000281333923 
2025-01-12 03:50:32.847030:  
2025-01-12 03:50:32.848030: Epoch 123 
2025-01-12 03:50:32.853075: Current learning rate: 0.00544 
2025-01-12 03:51:15.127414: train_loss -0.6605 
2025-01-12 03:51:15.127414: val_loss -0.7083 
2025-01-12 03:51:15.133483: Pseudo dice [np.float32(0.7832)] 
2025-01-12 03:51:15.137016: Epoch time: 42.28 s 
2025-01-12 03:51:15.140045: Yayy! New best EMA pseudo Dice: 0.7491999864578247 
2025-01-12 03:51:16.035553:  
2025-01-12 03:51:16.036056: Epoch 124 
2025-01-12 03:51:16.039565: Current learning rate: 0.0054 
2025-01-12 03:51:58.280312: train_loss -0.6264 
2025-01-12 03:51:58.280312: val_loss -0.6347 
2025-01-12 03:51:58.284838: Pseudo dice [np.float32(0.6902)] 
2025-01-12 03:51:58.287274: Epoch time: 42.25 s 
2025-01-12 03:51:58.856624:  
2025-01-12 03:51:58.856624: Epoch 125 
2025-01-12 03:51:58.861638: Current learning rate: 0.00536 
2025-01-12 03:52:41.081232: train_loss -0.6892 
2025-01-12 03:52:41.081232: val_loss -0.665 
2025-01-12 03:52:41.087249: Pseudo dice [np.float32(0.7369)] 
2025-01-12 03:52:41.090258: Epoch time: 42.23 s 
2025-01-12 03:52:41.653476:  
2025-01-12 03:52:41.654479: Epoch 126 
2025-01-12 03:52:41.659511: Current learning rate: 0.00532 
2025-01-12 03:53:23.892852: train_loss -0.6868 
2025-01-12 03:53:23.892852: val_loss -0.6508 
2025-01-12 03:53:23.900459: Pseudo dice [np.float32(0.7532)] 
2025-01-12 03:53:23.903063: Epoch time: 42.24 s 
2025-01-12 03:53:24.481658:  
2025-01-12 03:53:24.481658: Epoch 127 
2025-01-12 03:53:24.487213: Current learning rate: 0.00528 
2025-01-12 03:54:06.724029: train_loss -0.6758 
2025-01-12 03:54:06.725028: val_loss -0.7322 
2025-01-12 03:54:06.730544: Pseudo dice [np.float32(0.7837)] 
2025-01-12 03:54:06.734055: Epoch time: 42.24 s 
2025-01-12 03:54:07.302301:  
2025-01-12 03:54:07.303805: Epoch 128 
2025-01-12 03:54:07.308817: Current learning rate: 0.00524 
2025-01-12 03:54:49.549217: train_loss -0.665 
2025-01-12 03:54:49.550221: val_loss -0.6979 
2025-01-12 03:54:49.555237: Pseudo dice [np.float32(0.7632)] 
2025-01-12 03:54:49.559252: Epoch time: 42.25 s 
2025-01-12 03:54:49.562766: Yayy! New best EMA pseudo Dice: 0.7493000030517578 
2025-01-12 03:54:50.300517:  
2025-01-12 03:54:50.301516: Epoch 129 
2025-01-12 03:54:50.307033: Current learning rate: 0.0052 
2025-01-12 03:55:32.574576: train_loss -0.697 
2025-01-12 03:55:32.575579: val_loss -0.7641 
2025-01-12 03:55:32.581101: Pseudo dice [np.float32(0.8145)] 
2025-01-12 03:55:32.584614: Epoch time: 42.27 s 
2025-01-12 03:55:32.587126: Yayy! New best EMA pseudo Dice: 0.7558000087738037 
2025-01-12 03:55:33.324529:  
2025-01-12 03:55:33.325530: Epoch 130 
2025-01-12 03:55:33.330601: Current learning rate: 0.00517 
2025-01-12 03:56:15.568023: train_loss -0.7042 
2025-01-12 03:56:15.569022: val_loss -0.7199 
2025-01-12 03:56:15.574545: Pseudo dice [np.float32(0.7806)] 
2025-01-12 03:56:15.578061: Epoch time: 42.24 s 
2025-01-12 03:56:15.580572: Yayy! New best EMA pseudo Dice: 0.7583000063896179 
2025-01-12 03:56:16.475976:  
2025-01-12 03:56:16.475976: Epoch 131 
2025-01-12 03:56:16.482007: Current learning rate: 0.00513 
2025-01-12 03:56:58.686245: train_loss -0.6939 
2025-01-12 03:56:58.687245: val_loss -0.7572 
2025-01-12 03:56:58.692764: Pseudo dice [np.float32(0.8222)] 
2025-01-12 03:56:58.695272: Epoch time: 42.21 s 
2025-01-12 03:56:58.698782: Yayy! New best EMA pseudo Dice: 0.7646999955177307 
2025-01-12 03:56:59.433948:  
2025-01-12 03:56:59.434454: Epoch 132 
2025-01-12 03:56:59.439514: Current learning rate: 0.00509 
2025-01-12 03:57:41.683896: train_loss -0.7009 
2025-01-12 03:57:41.685402: val_loss -0.7058 
2025-01-12 03:57:41.690957: Pseudo dice [np.float32(0.7745)] 
2025-01-12 03:57:41.693984: Epoch time: 42.25 s 
2025-01-12 03:57:41.697012: Yayy! New best EMA pseudo Dice: 0.7656999826431274 
2025-01-12 03:57:42.425566:  
2025-01-12 03:57:42.425566: Epoch 133 
2025-01-12 03:57:42.431686: Current learning rate: 0.00505 
2025-01-12 03:58:24.689007: train_loss -0.7475 
2025-01-12 03:58:24.689509: val_loss -0.694 
2025-01-12 03:58:24.694531: Pseudo dice [np.float32(0.7682)] 
2025-01-12 03:58:24.698042: Epoch time: 42.26 s 
2025-01-12 03:58:24.700554: Yayy! New best EMA pseudo Dice: 0.7659000158309937 
2025-01-12 03:58:25.442989:  
2025-01-12 03:58:25.443988: Epoch 134 
2025-01-12 03:58:25.449055: Current learning rate: 0.00501 
2025-01-12 03:59:07.687673: train_loss -0.7227 
2025-01-12 03:59:07.688175: val_loss -0.7036 
2025-01-12 03:59:07.694190: Pseudo dice [np.float32(0.762)] 
2025-01-12 03:59:07.696695: Epoch time: 42.24 s 
2025-01-12 03:59:08.265227:  
2025-01-12 03:59:08.265227: Epoch 135 
2025-01-12 03:59:08.271242: Current learning rate: 0.00497 
2025-01-12 03:59:50.524206: train_loss -0.711 
2025-01-12 03:59:50.524708: val_loss -0.7434 
2025-01-12 03:59:50.530254: Pseudo dice [np.float32(0.796)] 
2025-01-12 03:59:50.532812: Epoch time: 42.26 s 
2025-01-12 03:59:50.535853: Yayy! New best EMA pseudo Dice: 0.7685999870300293 
2025-01-12 03:59:51.278866:  
2025-01-12 03:59:51.278866: Epoch 136 
2025-01-12 03:59:51.283878: Current learning rate: 0.00493 
2025-01-12 04:00:33.513594: train_loss -0.7207 
2025-01-12 04:00:33.514597: val_loss -0.7025 
2025-01-12 04:00:33.519610: Pseudo dice [np.float32(0.768)] 
2025-01-12 04:00:33.523620: Epoch time: 42.24 s 
2025-01-12 04:00:34.088764:  
2025-01-12 04:00:34.089764: Epoch 137 
2025-01-12 04:00:34.092796: Current learning rate: 0.00489 
2025-01-12 04:01:16.337666: train_loss -0.7314 
2025-01-12 04:01:16.338181: val_loss -0.7144 
2025-01-12 04:01:16.343225: Pseudo dice [np.float32(0.7583)] 
2025-01-12 04:01:16.346760: Epoch time: 42.25 s 
2025-01-12 04:01:16.915541:  
2025-01-12 04:01:16.916546: Epoch 138 
2025-01-12 04:01:16.921601: Current learning rate: 0.00485 
2025-01-12 04:01:59.152903: train_loss -0.7162 
2025-01-12 04:01:59.153413: val_loss -0.6736 
2025-01-12 04:01:59.158464: Pseudo dice [np.float32(0.7298)] 
2025-01-12 04:01:59.161994: Epoch time: 42.24 s 
2025-01-12 04:01:59.882598:  
2025-01-12 04:01:59.883598: Epoch 139 
2025-01-12 04:01:59.888724: Current learning rate: 0.00482 
2025-01-12 04:02:42.147558: train_loss -0.6884 
2025-01-12 04:02:42.148067: val_loss -0.7126 
2025-01-12 04:02:42.153635: Pseudo dice [np.float32(0.7811)] 
2025-01-12 04:02:42.156685: Epoch time: 42.26 s 
2025-01-12 04:02:42.725959:  
2025-01-12 04:02:42.725959: Epoch 140 
2025-01-12 04:02:42.730971: Current learning rate: 0.00478 
2025-01-12 04:03:24.967574: train_loss -0.7264 
2025-01-12 04:03:24.968076: val_loss -0.7061 
2025-01-12 04:03:24.974171: Pseudo dice [np.float32(0.7725)] 
2025-01-12 04:03:24.976692: Epoch time: 42.24 s 
2025-01-12 04:03:25.544956:  
2025-01-12 04:03:25.544956: Epoch 141 
2025-01-12 04:03:25.549968: Current learning rate: 0.00474 
2025-01-12 04:04:07.793355: train_loss -0.6976 
2025-01-12 04:04:07.793355: val_loss -0.6956 
2025-01-12 04:04:07.798368: Pseudo dice [np.float32(0.7575)] 
2025-01-12 04:04:07.801877: Epoch time: 42.25 s 
2025-01-12 04:04:08.375687:  
2025-01-12 04:04:08.375687: Epoch 142 
2025-01-12 04:04:08.383270: Current learning rate: 0.0047 
2025-01-12 04:04:50.651491: train_loss -0.7412 
2025-01-12 04:04:50.651998: val_loss -0.6936 
2025-01-12 04:04:50.657115: Pseudo dice [np.float32(0.7266)] 
2025-01-12 04:04:50.660625: Epoch time: 42.28 s 
2025-01-12 04:04:51.236183:  
2025-01-12 04:04:51.236183: Epoch 143 
2025-01-12 04:04:51.241212: Current learning rate: 0.00466 
2025-01-12 04:05:33.471801: train_loss -0.7308 
2025-01-12 04:05:33.471801: val_loss -0.7537 
2025-01-12 04:05:33.479333: Pseudo dice [np.float32(0.8192)] 
2025-01-12 04:05:33.483849: Epoch time: 42.24 s 
2025-01-12 04:05:34.051135:  
2025-01-12 04:05:34.052135: Epoch 144 
2025-01-12 04:05:34.055654: Current learning rate: 0.00462 
2025-01-12 04:06:16.288552: train_loss -0.7215 
2025-01-12 04:06:16.289553: val_loss -0.7045 
2025-01-12 04:06:16.295070: Pseudo dice [np.float32(0.7592)] 
2025-01-12 04:06:16.298579: Epoch time: 42.24 s 
2025-01-12 04:06:16.870057:  
2025-01-12 04:06:16.870057: Epoch 145 
2025-01-12 04:06:16.875644: Current learning rate: 0.00458 
2025-01-12 04:06:59.123544: train_loss -0.7121 
2025-01-12 04:06:59.125053: val_loss -0.6594 
2025-01-12 04:06:59.130630: Pseudo dice [np.float32(0.7096)] 
2025-01-12 04:06:59.133135: Epoch time: 42.25 s 
2025-01-12 04:06:59.705139:  
2025-01-12 04:06:59.705641: Epoch 146 
2025-01-12 04:06:59.709198: Current learning rate: 0.00454 
2025-01-12 04:07:41.944838: train_loss -0.7292 
2025-01-12 04:07:41.945341: val_loss -0.7229 
2025-01-12 04:07:41.950352: Pseudo dice [np.float32(0.802)] 
2025-01-12 04:07:41.953897: Epoch time: 42.24 s 
2025-01-12 04:07:42.680052:  
2025-01-12 04:07:42.680052: Epoch 147 
2025-01-12 04:07:42.685079: Current learning rate: 0.0045 
2025-01-12 04:08:24.935894: train_loss -0.721 
2025-01-12 04:08:24.936398: val_loss -0.6869 
2025-01-12 04:08:24.942449: Pseudo dice [np.float32(0.7461)] 
2025-01-12 04:08:24.945472: Epoch time: 42.26 s 
2025-01-12 04:08:25.514974:  
2025-01-12 04:08:25.514974: Epoch 148 
2025-01-12 04:08:25.520027: Current learning rate: 0.00446 
2025-01-12 04:09:07.722083: train_loss -0.7029 
2025-01-12 04:09:07.723586: val_loss -0.7161 
2025-01-12 04:09:07.728597: Pseudo dice [np.float32(0.778)] 
2025-01-12 04:09:07.732106: Epoch time: 42.21 s 
2025-01-12 04:09:08.302904:  
2025-01-12 04:09:08.302904: Epoch 149 
2025-01-12 04:09:08.308450: Current learning rate: 0.00442 
2025-01-12 04:09:50.554899: train_loss -0.6901 
2025-01-12 04:09:50.555899: val_loss -0.7027 
2025-01-12 04:09:50.561414: Pseudo dice [np.float32(0.7308)] 
2025-01-12 04:09:50.564925: Epoch time: 42.25 s 
2025-01-12 04:09:51.328481:  
2025-01-12 04:09:51.329486: Epoch 150 
2025-01-12 04:09:51.336066: Current learning rate: 0.00438 
2025-01-12 04:10:33.588813: train_loss -0.6813 
2025-01-12 04:10:33.589323: val_loss -0.7202 
2025-01-12 04:10:33.594982: Pseudo dice [np.float32(0.7935)] 
2025-01-12 04:10:33.598067: Epoch time: 42.26 s 
2025-01-12 04:10:34.176032:  
2025-01-12 04:10:34.177036: Epoch 151 
2025-01-12 04:10:34.181081: Current learning rate: 0.00434 
2025-01-12 04:11:16.416213: train_loss -0.7236 
2025-01-12 04:11:16.416725: val_loss -0.6765 
2025-01-12 04:11:16.422314: Pseudo dice [np.float32(0.7714)] 
2025-01-12 04:11:16.425917: Epoch time: 42.24 s 
2025-01-12 04:11:17.000773:  
2025-01-12 04:11:17.000773: Epoch 152 
2025-01-12 04:11:17.006349: Current learning rate: 0.0043 
2025-01-12 04:11:59.253531: train_loss -0.713 
2025-01-12 04:11:59.254036: val_loss -0.5672 
2025-01-12 04:11:59.259055: Pseudo dice [np.float32(0.5648)] 
2025-01-12 04:11:59.262570: Epoch time: 42.25 s 
2025-01-12 04:11:59.826440:  
2025-01-12 04:11:59.827446: Epoch 153 
2025-01-12 04:11:59.831997: Current learning rate: 0.00427 
2025-01-12 04:12:42.062378: train_loss -0.7335 
2025-01-12 04:12:42.063378: val_loss -0.6614 
2025-01-12 04:12:42.068895: Pseudo dice [np.float32(0.7064)] 
2025-01-12 04:12:42.072405: Epoch time: 42.24 s 
2025-01-12 04:12:42.651071:  
2025-01-12 04:12:42.651071: Epoch 154 
2025-01-12 04:12:42.656177: Current learning rate: 0.00423 
2025-01-12 04:13:24.896802: train_loss -0.7116 
2025-01-12 04:13:24.897801: val_loss -0.6951 
2025-01-12 04:13:24.903322: Pseudo dice [np.float32(0.7494)] 
2025-01-12 04:13:24.906836: Epoch time: 42.25 s 
2025-01-12 04:13:25.636721:  
2025-01-12 04:13:25.636721: Epoch 155 
2025-01-12 04:13:25.642738: Current learning rate: 0.00419 
2025-01-12 04:14:07.836540: train_loss -0.7378 
2025-01-12 04:14:07.837055: val_loss -0.7353 
2025-01-12 04:14:07.840622: Pseudo dice [np.float32(0.8149)] 
2025-01-12 04:14:07.845246: Epoch time: 42.2 s 
2025-01-12 04:14:08.421838:  
2025-01-12 04:14:08.422844: Epoch 156 
2025-01-12 04:14:08.427395: Current learning rate: 0.00415 
2025-01-12 04:14:50.635185: train_loss -0.6956 
2025-01-12 04:14:50.635698: val_loss -0.6923 
2025-01-12 04:14:50.641747: Pseudo dice [np.float32(0.7402)] 
2025-01-12 04:14:50.645275: Epoch time: 42.21 s 
2025-01-12 04:14:51.221729:  
2025-01-12 04:14:51.222727: Epoch 157 
2025-01-12 04:14:51.227757: Current learning rate: 0.00411 
2025-01-12 04:15:33.457848: train_loss -0.7332 
2025-01-12 04:15:33.458351: val_loss -0.6585 
2025-01-12 04:15:33.465378: Pseudo dice [np.float32(0.7284)] 
2025-01-12 04:15:33.468391: Epoch time: 42.24 s 
2025-01-12 04:15:34.047423:  
2025-01-12 04:15:34.048428: Epoch 158 
2025-01-12 04:15:34.052963: Current learning rate: 0.00407 
2025-01-12 04:16:16.299939: train_loss -0.7305 
2025-01-12 04:16:16.299939: val_loss -0.6552 
2025-01-12 04:16:16.306455: Pseudo dice [np.float32(0.7406)] 
2025-01-12 04:16:16.308962: Epoch time: 42.25 s 
2025-01-12 04:16:16.900232:  
2025-01-12 04:16:16.900232: Epoch 159 
2025-01-12 04:16:16.905843: Current learning rate: 0.00403 
2025-01-12 04:16:59.146664: train_loss -0.764 
2025-01-12 04:16:59.146664: val_loss -0.6433 
2025-01-12 04:16:59.151805: Pseudo dice [np.float32(0.7225)] 
2025-01-12 04:16:59.155350: Epoch time: 42.25 s 
2025-01-12 04:16:59.746151:  
2025-01-12 04:16:59.746151: Epoch 160 
2025-01-12 04:16:59.751163: Current learning rate: 0.00399 
2025-01-12 04:17:41.993956: train_loss -0.7329 
2025-01-12 04:17:41.993956: val_loss -0.6743 
2025-01-12 04:17:41.999542: Pseudo dice [np.float32(0.7266)] 
2025-01-12 04:17:42.003056: Epoch time: 42.25 s 
2025-01-12 04:17:42.589585:  
2025-01-12 04:17:42.589585: Epoch 161 
2025-01-12 04:17:42.594597: Current learning rate: 0.00395 
2025-01-12 04:18:24.900432: train_loss -0.7401 
2025-01-12 04:18:24.900432: val_loss -0.7192 
2025-01-12 04:18:24.906452: Pseudo dice [np.float32(0.7588)] 
2025-01-12 04:18:24.908959: Epoch time: 42.31 s 
2025-01-12 04:18:25.494649:  
2025-01-12 04:18:25.494649: Epoch 162 
2025-01-12 04:18:25.499660: Current learning rate: 0.00391 
2025-01-12 04:19:07.747371: train_loss -0.733 
2025-01-12 04:19:07.747877: val_loss -0.682 
2025-01-12 04:19:07.754064: Pseudo dice [np.float32(0.7333)] 
2025-01-12 04:19:07.757146: Epoch time: 42.25 s 
2025-01-12 04:19:08.505862:  
2025-01-12 04:19:08.506381: Epoch 163 
2025-01-12 04:19:08.511454: Current learning rate: 0.00387 
2025-01-12 04:19:50.735067: train_loss -0.7324 
2025-01-12 04:19:50.735579: val_loss -0.6235 
2025-01-12 04:19:50.741241: Pseudo dice [np.float32(0.6966)] 
2025-01-12 04:19:50.744318: Epoch time: 42.23 s 
2025-01-12 04:19:51.329672:  
2025-01-12 04:19:51.329672: Epoch 164 
2025-01-12 04:19:51.334684: Current learning rate: 0.00383 
2025-01-12 04:20:33.580441: train_loss -0.712 
2025-01-12 04:20:33.580441: val_loss -0.7408 
2025-01-12 04:20:33.586462: Pseudo dice [np.float32(0.7911)] 
2025-01-12 04:20:33.589968: Epoch time: 42.25 s 
2025-01-12 04:20:34.162102:  
2025-01-12 04:20:34.163106: Epoch 165 
2025-01-12 04:20:34.167702: Current learning rate: 0.00379 
2025-01-12 04:21:16.433659: train_loss -0.7483 
2025-01-12 04:21:16.434663: val_loss -0.6144 
2025-01-12 04:21:16.440395: Pseudo dice [np.float32(0.6827)] 
2025-01-12 04:21:16.443452: Epoch time: 42.27 s 
2025-01-12 04:21:17.004484:  
2025-01-12 04:21:17.004484: Epoch 166 
2025-01-12 04:21:17.010074: Current learning rate: 0.00375 
2025-01-12 04:21:59.235028: train_loss -0.7249 
2025-01-12 04:21:59.236033: val_loss -0.663 
2025-01-12 04:21:59.241214: Pseudo dice [np.float32(0.7592)] 
2025-01-12 04:21:59.244727: Epoch time: 42.23 s 
2025-01-12 04:21:59.802068:  
2025-01-12 04:21:59.803074: Epoch 167 
2025-01-12 04:21:59.807616: Current learning rate: 0.00371 
2025-01-12 04:22:42.049694: train_loss -0.7364 
2025-01-12 04:22:42.050698: val_loss -0.6476 
2025-01-12 04:22:42.056219: Pseudo dice [np.float32(0.7725)] 
2025-01-12 04:22:42.058729: Epoch time: 42.25 s 
2025-01-12 04:22:42.625340:  
2025-01-12 04:22:42.626337: Epoch 168 
2025-01-12 04:22:42.631352: Current learning rate: 0.00367 
2025-01-12 04:23:24.862319: train_loss -0.7355 
2025-01-12 04:23:24.863324: val_loss -0.5917 
2025-01-12 04:23:24.869341: Pseudo dice [np.float32(0.6564)] 
2025-01-12 04:23:24.872354: Epoch time: 42.24 s 
2025-01-12 04:23:25.445475:  
2025-01-12 04:23:25.446475: Epoch 169 
2025-01-12 04:23:25.451063: Current learning rate: 0.00363 
2025-01-12 04:24:07.657341: train_loss -0.7113 
2025-01-12 04:24:07.657341: val_loss -0.732 
2025-01-12 04:24:07.663356: Pseudo dice [np.float32(0.7697)] 
2025-01-12 04:24:07.666365: Epoch time: 42.21 s 
2025-01-12 04:24:08.241252:  
2025-01-12 04:24:08.241252: Epoch 170 
2025-01-12 04:24:08.246286: Current learning rate: 0.00359 
2025-01-12 04:24:50.519754: train_loss -0.728 
2025-01-12 04:24:50.520265: val_loss -0.7523 
2025-01-12 04:24:50.525394: Pseudo dice [np.float32(0.8078)] 
2025-01-12 04:24:50.528942: Epoch time: 42.28 s 
2025-01-12 04:24:51.243545:  
2025-01-12 04:24:51.244546: Epoch 171 
2025-01-12 04:24:51.249641: Current learning rate: 0.00355 
2025-01-12 04:25:33.504010: train_loss -0.7286 
2025-01-12 04:25:33.504010: val_loss -0.6963 
2025-01-12 04:25:33.510033: Pseudo dice [np.float32(0.7403)] 
2025-01-12 04:25:33.513543: Epoch time: 42.26 s 
2025-01-12 04:25:34.088535:  
2025-01-12 04:25:34.088535: Epoch 172 
2025-01-12 04:25:34.093637: Current learning rate: 0.00351 
2025-01-12 04:26:16.319530: train_loss -0.7181 
2025-01-12 04:26:16.320531: val_loss -0.6593 
2025-01-12 04:26:16.326049: Pseudo dice [np.float32(0.7073)] 
2025-01-12 04:26:16.329560: Epoch time: 42.23 s 
2025-01-12 04:26:16.909647:  
2025-01-12 04:26:16.909647: Epoch 173 
2025-01-12 04:26:16.914750: Current learning rate: 0.00346 
2025-01-12 04:26:59.153989: train_loss -0.7392 
2025-01-12 04:26:59.154503: val_loss -0.66 
2025-01-12 04:26:59.161633: Pseudo dice [np.float32(0.7476)] 
2025-01-12 04:26:59.164141: Epoch time: 42.25 s 
2025-01-12 04:26:59.748497:  
2025-01-12 04:26:59.749501: Epoch 174 
2025-01-12 04:26:59.754060: Current learning rate: 0.00342 
2025-01-12 04:27:42.000132: train_loss -0.7253 
2025-01-12 04:27:42.000634: val_loss -0.6349 
2025-01-12 04:27:42.005647: Pseudo dice [np.float32(0.6938)] 
2025-01-12 04:27:42.009157: Epoch time: 42.25 s 
2025-01-12 04:27:42.590374:  
2025-01-12 04:27:42.590374: Epoch 175 
2025-01-12 04:27:42.595554: Current learning rate: 0.00338 
2025-01-12 04:28:24.859196: train_loss -0.7348 
2025-01-12 04:28:24.860197: val_loss -0.643 
2025-01-12 04:28:24.865720: Pseudo dice [np.float32(0.7162)] 
2025-01-12 04:28:24.868231: Epoch time: 42.27 s 
2025-01-12 04:28:25.447985:  
2025-01-12 04:28:25.448489: Epoch 176 
2025-01-12 04:28:25.453503: Current learning rate: 0.00334 
2025-01-12 04:29:07.675150: train_loss -0.7227 
2025-01-12 04:29:07.675654: val_loss -0.6598 
2025-01-12 04:29:07.680670: Pseudo dice [np.float32(0.7336)] 
2025-01-12 04:29:07.684180: Epoch time: 42.23 s 
2025-01-12 04:29:08.263624:  
2025-01-12 04:29:08.264627: Epoch 177 
2025-01-12 04:29:08.270173: Current learning rate: 0.0033 
2025-01-12 04:29:50.505182: train_loss -0.7023 
2025-01-12 04:29:50.505182: val_loss -0.6783 
2025-01-12 04:29:50.511205: Pseudo dice [np.float32(0.7673)] 
2025-01-12 04:29:50.513717: Epoch time: 42.24 s 
2025-01-12 04:29:51.093318:  
2025-01-12 04:29:51.093318: Epoch 178 
2025-01-12 04:29:51.098373: Current learning rate: 0.00326 
2025-01-12 04:30:33.339251: train_loss -0.7503 
2025-01-12 04:30:33.340256: val_loss -0.6071 
2025-01-12 04:30:33.346269: Pseudo dice [np.float32(0.6518)] 
2025-01-12 04:30:33.349281: Epoch time: 42.25 s 
2025-01-12 04:30:34.075970:  
2025-01-12 04:30:34.075970: Epoch 179 
2025-01-12 04:30:34.081078: Current learning rate: 0.00322 
2025-01-12 04:31:16.304057: train_loss -0.7492 
2025-01-12 04:31:16.304057: val_loss -0.726 
2025-01-12 04:31:16.310075: Pseudo dice [np.float32(0.7642)] 
2025-01-12 04:31:16.312583: Epoch time: 42.23 s 
2025-01-12 04:31:16.887928:  
2025-01-12 04:31:16.887928: Epoch 180 
2025-01-12 04:31:16.892999: Current learning rate: 0.00318 
2025-01-12 04:31:59.123817: train_loss -0.7424 
2025-01-12 04:31:59.124822: val_loss -0.6387 
2025-01-12 04:31:59.129893: Pseudo dice [np.float32(0.6978)] 
2025-01-12 04:31:59.133998: Epoch time: 42.24 s 
2025-01-12 04:31:59.712963:  
2025-01-12 04:31:59.712963: Epoch 181 
2025-01-12 04:31:59.718003: Current learning rate: 0.00314 
2025-01-12 04:32:41.935432: train_loss -0.7359 
2025-01-12 04:32:41.935432: val_loss -0.6843 
2025-01-12 04:32:41.941447: Pseudo dice [np.float32(0.77)] 
2025-01-12 04:32:41.944457: Epoch time: 42.22 s 
2025-01-12 04:32:42.519434:  
2025-01-12 04:32:42.520437: Epoch 182 
2025-01-12 04:32:42.525485: Current learning rate: 0.0031 
2025-01-12 04:33:24.756487: train_loss -0.7337 
2025-01-12 04:33:24.756995: val_loss -0.7659 
2025-01-12 04:33:24.762603: Pseudo dice [np.float32(0.7968)] 
2025-01-12 04:33:24.765657: Epoch time: 42.24 s 
2025-01-12 04:33:25.341773:  
2025-01-12 04:33:25.341773: Epoch 183 
2025-01-12 04:33:25.347328: Current learning rate: 0.00306 
2025-01-12 04:34:07.591280: train_loss -0.7248 
2025-01-12 04:34:07.591280: val_loss -0.7021 
2025-01-12 04:34:07.596900: Pseudo dice [np.float32(0.7374)] 
2025-01-12 04:34:07.600912: Epoch time: 42.25 s 
2025-01-12 04:34:08.170733:  
2025-01-12 04:34:08.171731: Epoch 184 
2025-01-12 04:34:08.176284: Current learning rate: 0.00302 
2025-01-12 04:34:50.390787: train_loss -0.7089 
2025-01-12 04:34:50.391296: val_loss -0.667 
2025-01-12 04:34:50.396511: Pseudo dice [np.float32(0.753)] 
2025-01-12 04:34:50.400043: Epoch time: 42.22 s 
2025-01-12 04:34:50.972866:  
2025-01-12 04:34:50.973866: Epoch 185 
2025-01-12 04:34:50.978941: Current learning rate: 0.00297 
2025-01-12 04:35:33.196385: train_loss -0.7007 
2025-01-12 04:35:33.196888: val_loss -0.5572 
2025-01-12 04:35:33.201906: Pseudo dice [np.float32(0.6367)] 
2025-01-12 04:35:33.205421: Epoch time: 42.22 s 
2025-01-12 04:35:33.787910:  
2025-01-12 04:35:33.788426: Epoch 186 
2025-01-12 04:35:33.793012: Current learning rate: 0.00293 
2025-01-12 04:36:16.125272: train_loss -0.7391 
2025-01-12 04:36:16.125272: val_loss -0.7178 
2025-01-12 04:36:16.130368: Pseudo dice [np.float32(0.808)] 
2025-01-12 04:36:16.134403: Epoch time: 42.34 s 
2025-01-12 04:36:16.714852:  
2025-01-12 04:36:16.714852: Epoch 187 
2025-01-12 04:36:16.719901: Current learning rate: 0.00289 
2025-01-12 04:36:58.928947: train_loss -0.7709 
2025-01-12 04:36:58.928947: val_loss -0.6912 
2025-01-12 04:36:58.933967: Pseudo dice [np.float32(0.7759)] 
2025-01-12 04:36:58.937484: Epoch time: 42.22 s 
2025-01-12 04:36:59.524365:  
2025-01-12 04:36:59.524871: Epoch 188 
2025-01-12 04:36:59.529450: Current learning rate: 0.00285 
2025-01-12 04:37:41.735325: train_loss -0.762 
2025-01-12 04:37:41.736329: val_loss -0.6766 
2025-01-12 04:37:41.741345: Pseudo dice [np.float32(0.7433)] 
2025-01-12 04:37:41.744854: Epoch time: 42.21 s 
2025-01-12 04:37:42.319111:  
2025-01-12 04:37:42.319111: Epoch 189 
2025-01-12 04:37:42.324674: Current learning rate: 0.00281 
2025-01-12 04:38:24.567572: train_loss -0.7469 
2025-01-12 04:38:24.567572: val_loss -0.6322 
2025-01-12 04:38:24.573193: Pseudo dice [np.float32(0.7376)] 
2025-01-12 04:38:24.576722: Epoch time: 42.25 s 
2025-01-12 04:38:25.151865:  
2025-01-12 04:38:25.152864: Epoch 190 
2025-01-12 04:38:25.157434: Current learning rate: 0.00277 
2025-01-12 04:39:07.369588: train_loss -0.7458 
2025-01-12 04:39:07.370593: val_loss -0.6914 
2025-01-12 04:39:07.375606: Pseudo dice [np.float32(0.7679)] 
2025-01-12 04:39:07.379114: Epoch time: 42.22 s 
2025-01-12 04:39:07.954800:  
2025-01-12 04:39:07.955804: Epoch 191 
2025-01-12 04:39:07.960423: Current learning rate: 0.00273 
2025-01-12 04:39:50.212194: train_loss -0.7612 
2025-01-12 04:39:50.213218: val_loss -0.7013 
2025-01-12 04:39:50.218302: Pseudo dice [np.float32(0.7632)] 
2025-01-12 04:39:50.222882: Epoch time: 42.26 s 
2025-01-12 04:39:50.796469:  
2025-01-12 04:39:50.796469: Epoch 192 
2025-01-12 04:39:50.802157: Current learning rate: 0.00268 
2025-01-12 04:40:33.035788: train_loss -0.7734 
2025-01-12 04:40:33.036787: val_loss -0.6007 
2025-01-12 04:40:33.042309: Pseudo dice [np.float32(0.6831)] 
2025-01-12 04:40:33.044818: Epoch time: 42.24 s 
2025-01-12 04:40:33.626911:  
2025-01-12 04:40:33.627911: Epoch 193 
2025-01-12 04:40:33.632972: Current learning rate: 0.00264 
2025-01-12 04:41:15.841830: train_loss -0.7689 
2025-01-12 04:41:15.842830: val_loss -0.7703 
2025-01-12 04:41:15.848347: Pseudo dice [np.float32(0.8263)] 
2025-01-12 04:41:15.851858: Epoch time: 42.21 s 
2025-01-12 04:41:16.576047:  
2025-01-12 04:41:16.577047: Epoch 194 
2025-01-12 04:41:16.582638: Current learning rate: 0.0026 
2025-01-12 04:41:58.796262: train_loss -0.7525 
2025-01-12 04:41:58.796765: val_loss -0.7275 
2025-01-12 04:41:58.801307: Pseudo dice [np.float32(0.8065)] 
2025-01-12 04:41:58.804329: Epoch time: 42.22 s 
2025-01-12 04:41:59.374975:  
2025-01-12 04:41:59.374975: Epoch 195 
2025-01-12 04:41:59.379989: Current learning rate: 0.00256 
2025-01-12 04:42:41.603873: train_loss -0.7318 
2025-01-12 04:42:41.603873: val_loss -0.7291 
2025-01-12 04:42:41.609911: Pseudo dice [np.float32(0.7959)] 
2025-01-12 04:42:41.612934: Epoch time: 42.23 s 
2025-01-12 04:42:42.183482:  
2025-01-12 04:42:42.183482: Epoch 196 
2025-01-12 04:42:42.188529: Current learning rate: 0.00252 
2025-01-12 04:43:24.405768: train_loss -0.7518 
2025-01-12 04:43:24.405768: val_loss -0.7243 
2025-01-12 04:43:24.410284: Pseudo dice [np.float32(0.7618)] 
2025-01-12 04:43:24.413298: Epoch time: 42.22 s 
2025-01-12 04:43:24.985304:  
2025-01-12 04:43:24.986311: Epoch 197 
2025-01-12 04:43:24.990901: Current learning rate: 0.00248 
2025-01-12 04:44:07.198444: train_loss -0.742 
2025-01-12 04:44:07.198444: val_loss -0.7276 
2025-01-12 04:44:07.204963: Pseudo dice [np.float32(0.7739)] 
2025-01-12 04:44:07.207473: Epoch time: 42.21 s 
2025-01-12 04:44:07.788209:  
2025-01-12 04:44:07.789459: Epoch 198 
2025-01-12 04:44:07.794353: Current learning rate: 0.00243 
2025-01-12 04:44:49.996973: train_loss -0.7521 
2025-01-12 04:44:49.997972: val_loss -0.7132 
2025-01-12 04:44:50.003492: Pseudo dice [np.float32(0.7405)] 
2025-01-12 04:44:50.007007: Epoch time: 42.21 s 
2025-01-12 04:44:50.587651:  
2025-01-12 04:44:50.587651: Epoch 199 
2025-01-12 04:44:50.592664: Current learning rate: 0.00239 
2025-01-12 04:45:32.815206: train_loss -0.7109 
2025-01-12 04:45:32.815718: val_loss -0.6788 
2025-01-12 04:45:32.820263: Pseudo dice [np.float32(0.7486)] 
2025-01-12 04:45:32.823793: Epoch time: 42.23 s 
2025-01-12 04:45:33.589063:  
2025-01-12 04:45:33.590066: Epoch 200 
2025-01-12 04:45:33.594864: Current learning rate: 0.00235 
2025-01-12 04:46:15.840788: train_loss -0.7324 
2025-01-12 04:46:15.841792: val_loss -0.7119 
2025-01-12 04:46:15.847345: Pseudo dice [np.float32(0.7627)] 
2025-01-12 04:46:15.850372: Epoch time: 42.25 s 
2025-01-12 04:46:16.431694:  
2025-01-12 04:46:16.432695: Epoch 201 
2025-01-12 04:46:16.437758: Current learning rate: 0.00231 
2025-01-12 04:46:58.662463: train_loss -0.7529 
2025-01-12 04:46:58.667475: val_loss -0.6934 
2025-01-12 04:46:58.671487: Pseudo dice [np.float32(0.7506)] 
2025-01-12 04:46:58.674998: Epoch time: 42.23 s 
2025-01-12 04:46:59.415040:  
2025-01-12 04:46:59.415040: Epoch 202 
2025-01-12 04:46:59.420052: Current learning rate: 0.00226 
2025-01-12 04:47:41.634913: train_loss -0.7599 
2025-01-12 04:47:41.634913: val_loss -0.7249 
2025-01-12 04:47:41.639929: Pseudo dice [np.float32(0.7532)] 
2025-01-12 04:47:41.643940: Epoch time: 42.22 s 
2025-01-12 04:47:42.229992:  
2025-01-12 04:47:42.229992: Epoch 203 
2025-01-12 04:47:42.234502: Current learning rate: 0.00222 
2025-01-12 04:48:24.473914: train_loss -0.742 
2025-01-12 04:48:24.474416: val_loss -0.6559 
2025-01-12 04:48:24.479430: Pseudo dice [np.float32(0.739)] 
2025-01-12 04:48:24.482940: Epoch time: 42.24 s 
2025-01-12 04:48:25.072946:  
2025-01-12 04:48:25.072946: Epoch 204 
2025-01-12 04:48:25.078018: Current learning rate: 0.00218 
2025-01-12 04:49:07.253411: train_loss -0.783 
2025-01-12 04:49:07.254411: val_loss -0.7052 
2025-01-12 04:49:07.259933: Pseudo dice [np.float32(0.765)] 
2025-01-12 04:49:07.263443: Epoch time: 42.18 s 
2025-01-12 04:49:07.847374:  
2025-01-12 04:49:07.847877: Epoch 205 
2025-01-12 04:49:07.852922: Current learning rate: 0.00214 
2025-01-12 04:49:50.070682: train_loss -0.7666 
2025-01-12 04:49:50.070682: val_loss -0.7435 
2025-01-12 04:49:50.077203: Pseudo dice [np.float32(0.8073)] 
2025-01-12 04:49:50.079713: Epoch time: 42.22 s 
2025-01-12 04:49:50.627575:  
2025-01-12 04:49:50.628578: Epoch 206 
2025-01-12 04:49:50.633612: Current learning rate: 0.00209 
2025-01-12 04:50:32.888148: train_loss -0.7697 
2025-01-12 04:50:32.888724: val_loss -0.7177 
2025-01-12 04:50:32.892277: Pseudo dice [np.float32(0.7777)] 
2025-01-12 04:50:32.895341: Epoch time: 42.26 s 
2025-01-12 04:50:33.443877:  
2025-01-12 04:50:33.443877: Epoch 207 
2025-01-12 04:50:33.448891: Current learning rate: 0.00205 
2025-01-12 04:51:15.688076: train_loss -0.7392 
2025-01-12 04:51:15.689079: val_loss -0.7428 
2025-01-12 04:51:15.693614: Pseudo dice [np.float32(0.795)] 
2025-01-12 04:51:15.697142: Epoch time: 42.24 s 
2025-01-12 04:51:16.241914:  
2025-01-12 04:51:16.241914: Epoch 208 
2025-01-12 04:51:16.246947: Current learning rate: 0.00201 
2025-01-12 04:51:58.495868: train_loss -0.7643 
2025-01-12 04:51:58.495868: val_loss -0.7427 
2025-01-12 04:51:58.501892: Pseudo dice [np.float32(0.807)] 
2025-01-12 04:51:58.504404: Epoch time: 42.25 s 
2025-01-12 04:51:58.508415: Yayy! New best EMA pseudo Dice: 0.7700999975204468 
2025-01-12 04:51:59.229713:  
2025-01-12 04:51:59.229713: Epoch 209 
2025-01-12 04:51:59.235283: Current learning rate: 0.00196 
2025-01-12 04:52:41.495227: train_loss -0.7743 
2025-01-12 04:52:41.495730: val_loss -0.7762 
2025-01-12 04:52:41.501388: Pseudo dice [np.float32(0.8233)] 
2025-01-12 04:52:41.503932: Epoch time: 42.27 s 
2025-01-12 04:52:41.506482: Yayy! New best EMA pseudo Dice: 0.7753999829292297 
2025-01-12 04:52:42.229325:  
2025-01-12 04:52:42.229325: Epoch 210 
2025-01-12 04:52:42.232838: Current learning rate: 0.00192 
2025-01-12 04:53:24.454813: train_loss -0.7815 
2025-01-12 04:53:24.454813: val_loss -0.7184 
2025-01-12 04:53:24.460832: Pseudo dice [np.float32(0.7663)] 
2025-01-12 04:53:24.463844: Epoch time: 42.23 s 
2025-01-12 04:53:25.162721:  
2025-01-12 04:53:25.163725: Epoch 211 
2025-01-12 04:53:25.168743: Current learning rate: 0.00188 
2025-01-12 04:54:07.406963: train_loss -0.7563 
2025-01-12 04:54:07.407966: val_loss -0.6961 
2025-01-12 04:54:07.412993: Pseudo dice [np.float32(0.7591)] 
2025-01-12 04:54:07.416017: Epoch time: 42.24 s 
2025-01-12 04:54:07.958555:  
2025-01-12 04:54:07.959558: Epoch 212 
2025-01-12 04:54:07.964111: Current learning rate: 0.00184 
2025-01-12 04:54:50.194407: train_loss -0.7477 
2025-01-12 04:54:50.195407: val_loss -0.6162 
2025-01-12 04:54:50.200921: Pseudo dice [np.float32(0.7419)] 
2025-01-12 04:54:50.204430: Epoch time: 42.24 s 
2025-01-12 04:54:50.747828:  
2025-01-12 04:54:50.747828: Epoch 213 
2025-01-12 04:54:50.753361: Current learning rate: 0.00179 
2025-01-12 04:55:32.962350: train_loss -0.7619 
2025-01-12 04:55:32.962854: val_loss -0.738 
2025-01-12 04:55:32.967866: Pseudo dice [np.float32(0.7973)] 
2025-01-12 04:55:32.971375: Epoch time: 42.22 s 
2025-01-12 04:55:33.508791:  
2025-01-12 04:55:33.508791: Epoch 214 
2025-01-12 04:55:33.514348: Current learning rate: 0.00175 
2025-01-12 04:56:15.739739: train_loss -0.7743 
2025-01-12 04:56:15.739739: val_loss -0.7407 
2025-01-12 04:56:15.746763: Pseudo dice [np.float32(0.7923)] 
2025-01-12 04:56:15.749774: Epoch time: 42.23 s 
2025-01-12 04:56:16.290753:  
2025-01-12 04:56:16.291265: Epoch 215 
2025-01-12 04:56:16.296309: Current learning rate: 0.0017 
2025-01-12 04:56:58.522877: train_loss -0.7552 
2025-01-12 04:56:58.524383: val_loss -0.6646 
2025-01-12 04:56:58.529489: Pseudo dice [np.float32(0.7301)] 
2025-01-12 04:56:58.533026: Epoch time: 42.23 s 
2025-01-12 04:56:59.074696:  
2025-01-12 04:56:59.075701: Epoch 216 
2025-01-12 04:56:59.080266: Current learning rate: 0.00166 
2025-01-12 04:57:41.305487: train_loss -0.7455 
2025-01-12 04:57:41.305991: val_loss -0.6856 
2025-01-12 04:57:41.311009: Pseudo dice [np.float32(0.6972)] 
2025-01-12 04:57:41.314520: Epoch time: 42.23 s 
2025-01-12 04:57:41.875220:  
2025-01-12 04:57:41.876224: Epoch 217 
2025-01-12 04:57:41.880841: Current learning rate: 0.00162 
2025-01-12 04:58:24.146425: train_loss -0.7725 
2025-01-12 04:58:24.147426: val_loss -0.6997 
2025-01-12 04:58:24.152436: Pseudo dice [np.float32(0.7749)] 
2025-01-12 04:58:24.155444: Epoch time: 42.27 s 
2025-01-12 04:58:24.696475:  
2025-01-12 04:58:24.697475: Epoch 218 
2025-01-12 04:58:24.701486: Current learning rate: 0.00157 
2025-01-12 04:59:06.899669: train_loss -0.7702 
2025-01-12 04:59:06.900181: val_loss -0.5879 
2025-01-12 04:59:06.905717: Pseudo dice [np.float32(0.5897)] 
2025-01-12 04:59:06.908225: Epoch time: 42.2 s 
2025-01-12 04:59:07.451978:  
2025-01-12 04:59:07.451978: Epoch 219 
2025-01-12 04:59:07.456988: Current learning rate: 0.00153 
2025-01-12 04:59:49.673005: train_loss -0.7678 
2025-01-12 04:59:49.673005: val_loss -0.6875 
2025-01-12 04:59:49.679594: Pseudo dice [np.float32(0.7584)] 
2025-01-12 04:59:49.682704: Epoch time: 42.22 s 
2025-01-12 04:59:50.376961:  
2025-01-12 04:59:50.376961: Epoch 220 
2025-01-12 04:59:50.381973: Current learning rate: 0.00148 
2025-01-12 05:00:32.570032: train_loss -0.7633 
2025-01-12 05:00:32.570032: val_loss -0.7231 
2025-01-12 05:00:32.574040: Pseudo dice [np.float32(0.7554)] 
2025-01-12 05:00:32.577549: Epoch time: 42.19 s 
2025-01-12 05:00:33.121392:  
2025-01-12 05:00:33.121392: Epoch 221 
2025-01-12 05:00:33.126408: Current learning rate: 0.00144 
2025-01-12 05:01:15.364338: train_loss -0.7824 
2025-01-12 05:01:15.364846: val_loss -0.7051 
2025-01-12 05:01:15.369894: Pseudo dice [np.float32(0.7852)] 
2025-01-12 05:01:15.373920: Epoch time: 42.24 s 
2025-01-12 05:01:15.914284:  
2025-01-12 05:01:15.914284: Epoch 222 
2025-01-12 05:01:15.919837: Current learning rate: 0.00139 
2025-01-12 05:01:58.153670: train_loss -0.7786 
2025-01-12 05:01:58.154673: val_loss -0.6832 
2025-01-12 05:01:58.159685: Pseudo dice [np.float32(0.7767)] 
2025-01-12 05:01:58.163692: Epoch time: 42.24 s 
2025-01-12 05:01:58.800402:  
2025-01-12 05:01:58.800402: Epoch 223 
2025-01-12 05:01:58.805435: Current learning rate: 0.00135 
2025-01-12 05:02:41.021081: train_loss -0.765 
2025-01-12 05:02:41.021589: val_loss -0.6794 
2025-01-12 05:02:41.027625: Pseudo dice [np.float32(0.7696)] 
2025-01-12 05:02:41.030644: Epoch time: 42.22 s 
2025-01-12 05:02:41.578727:  
2025-01-12 05:02:41.579731: Epoch 224 
2025-01-12 05:02:41.584265: Current learning rate: 0.0013 
2025-01-12 05:03:23.808591: train_loss -0.7608 
2025-01-12 05:03:23.809102: val_loss -0.5682 
2025-01-12 05:03:23.813673: Pseudo dice [np.float32(0.6303)] 
2025-01-12 05:03:23.816703: Epoch time: 42.23 s 
2025-01-12 05:03:24.359117:  
2025-01-12 05:03:24.359622: Epoch 225 
2025-01-12 05:03:24.364634: Current learning rate: 0.00126 
2025-01-12 05:04:06.587310: train_loss -0.7642 
2025-01-12 05:04:06.587825: val_loss -0.6888 
2025-01-12 05:04:06.592907: Pseudo dice [np.float32(0.7338)] 
2025-01-12 05:04:06.595459: Epoch time: 42.23 s 
2025-01-12 05:04:07.133696:  
2025-01-12 05:04:07.134700: Epoch 226 
2025-01-12 05:04:07.139724: Current learning rate: 0.00121 
2025-01-12 05:04:49.385698: train_loss -0.7716 
2025-01-12 05:04:49.386701: val_loss -0.6648 
2025-01-12 05:04:49.391713: Pseudo dice [np.float32(0.7734)] 
2025-01-12 05:04:49.395722: Epoch time: 42.25 s 
2025-01-12 05:04:49.937529:  
2025-01-12 05:04:49.938529: Epoch 227 
2025-01-12 05:04:49.943600: Current learning rate: 0.00117 
2025-01-12 05:05:32.135693: train_loss -0.7847 
2025-01-12 05:05:32.136696: val_loss -0.6901 
2025-01-12 05:05:32.141711: Pseudo dice [np.float32(0.7568)] 
2025-01-12 05:05:32.145720: Epoch time: 42.2 s 
2025-01-12 05:05:32.685340:  
2025-01-12 05:05:32.685340: Epoch 228 
2025-01-12 05:05:32.690880: Current learning rate: 0.00112 
2025-01-12 05:06:14.958063: train_loss -0.7814 
2025-01-12 05:06:14.958570: val_loss -0.5934 
2025-01-12 05:06:14.964177: Pseudo dice [np.float32(0.7451)] 
2025-01-12 05:06:14.967241: Epoch time: 42.27 s 
2025-01-12 05:06:15.667700:  
2025-01-12 05:06:15.667700: Epoch 229 
2025-01-12 05:06:15.673266: Current learning rate: 0.00108 
2025-01-12 05:06:57.889287: train_loss -0.7775 
2025-01-12 05:06:57.889287: val_loss -0.7103 
2025-01-12 05:06:57.895298: Pseudo dice [np.float32(0.761)] 
2025-01-12 05:06:57.898305: Epoch time: 42.22 s 
2025-01-12 05:06:58.447069:  
2025-01-12 05:06:58.447069: Epoch 230 
2025-01-12 05:06:58.452099: Current learning rate: 0.00103 
2025-01-12 05:07:40.663779: train_loss -0.7764 
2025-01-12 05:07:40.664778: val_loss -0.6647 
2025-01-12 05:07:40.668789: Pseudo dice [np.float32(0.7501)] 
2025-01-12 05:07:40.672796: Epoch time: 42.22 s 
2025-01-12 05:07:41.218127:  
2025-01-12 05:07:41.218630: Epoch 231 
2025-01-12 05:07:41.223266: Current learning rate: 0.00098 
2025-01-12 05:08:23.468493: train_loss -0.7956 
2025-01-12 05:08:23.468995: val_loss -0.7142 
2025-01-12 05:08:23.474011: Pseudo dice [np.float32(0.7781)] 
2025-01-12 05:08:23.477519: Epoch time: 42.25 s 
2025-01-12 05:08:24.021872:  
2025-01-12 05:08:24.021872: Epoch 232 
2025-01-12 05:08:24.026891: Current learning rate: 0.00094 
2025-01-12 05:09:06.241246: train_loss -0.7803 
2025-01-12 05:09:06.242250: val_loss -0.6092 
2025-01-12 05:09:06.247265: Pseudo dice [np.float32(0.7409)] 
2025-01-12 05:09:06.250770: Epoch time: 42.22 s 
2025-01-12 05:09:06.796709:  
2025-01-12 05:09:06.796709: Epoch 233 
2025-01-12 05:09:06.801720: Current learning rate: 0.00089 
2025-01-12 05:09:49.022344: train_loss -0.7567 
2025-01-12 05:09:49.022344: val_loss -0.5734 
2025-01-12 05:09:49.028357: Pseudo dice [np.float32(0.5679)] 
2025-01-12 05:09:49.030863: Epoch time: 42.23 s 
2025-01-12 05:09:49.574379:  
2025-01-12 05:09:49.574379: Epoch 234 
2025-01-12 05:09:49.578443: Current learning rate: 0.00084 
2025-01-12 05:10:31.785907: train_loss -0.7807 
2025-01-12 05:10:31.786911: val_loss -0.676 
2025-01-12 05:10:31.792922: Pseudo dice [np.float32(0.7554)] 
2025-01-12 05:10:31.795936: Epoch time: 42.21 s 
2025-01-12 05:10:32.339163:  
2025-01-12 05:10:32.339163: Epoch 235 
2025-01-12 05:10:32.344209: Current learning rate: 0.00079 
2025-01-12 05:11:14.585803: train_loss -0.7964 
2025-01-12 05:11:14.586806: val_loss -0.6843 
2025-01-12 05:11:14.591818: Pseudo dice [np.float32(0.7558)] 
2025-01-12 05:11:14.595826: Epoch time: 42.25 s 
2025-01-12 05:11:15.134686:  
2025-01-12 05:11:15.134686: Epoch 236 
2025-01-12 05:11:15.139709: Current learning rate: 0.00075 
2025-01-12 05:11:57.366398: train_loss -0.7864 
2025-01-12 05:11:57.366398: val_loss -0.6375 
2025-01-12 05:11:57.372481: Pseudo dice [np.float32(0.7248)] 
2025-01-12 05:11:57.375521: Epoch time: 42.23 s 
2025-01-12 05:11:57.917120:  
2025-01-12 05:11:57.918124: Epoch 237 
2025-01-12 05:11:57.922692: Current learning rate: 0.0007 
2025-01-12 05:12:40.166471: train_loss -0.7844 
2025-01-12 05:12:40.168506: val_loss -0.7016 
2025-01-12 05:12:40.173585: Pseudo dice [np.float32(0.7551)] 
2025-01-12 05:12:40.176634: Epoch time: 42.25 s 
2025-01-12 05:12:40.875217:  
2025-01-12 05:12:40.876739: Epoch 238 
2025-01-12 05:12:40.881266: Current learning rate: 0.00065 
2025-01-12 05:13:23.113143: train_loss -0.7977 
2025-01-12 05:13:23.114146: val_loss -0.6175 
2025-01-12 05:13:23.120659: Pseudo dice [np.float32(0.674)] 
2025-01-12 05:13:23.124167: Epoch time: 42.24 s 
2025-01-12 05:13:23.667990:  
2025-01-12 05:13:23.668994: Epoch 239 
2025-01-12 05:13:23.673548: Current learning rate: 0.0006 
2025-01-12 05:14:05.889564: train_loss -0.7851 
2025-01-12 05:14:05.890067: val_loss -0.6877 
2025-01-12 05:14:05.894596: Pseudo dice [np.float32(0.7506)] 
2025-01-12 05:14:05.898102: Epoch time: 42.22 s 
2025-01-12 05:14:06.447883:  
2025-01-12 05:14:06.448386: Epoch 240 
2025-01-12 05:14:06.453396: Current learning rate: 0.00055 
2025-01-12 05:14:48.667358: train_loss -0.7902 
2025-01-12 05:14:48.667358: val_loss -0.6609 
2025-01-12 05:14:48.673369: Pseudo dice [np.float32(0.7435)] 
2025-01-12 05:14:48.676378: Epoch time: 42.22 s 
2025-01-12 05:14:49.223221:  
2025-01-12 05:14:49.223723: Epoch 241 
2025-01-12 05:14:49.228736: Current learning rate: 0.0005 
2025-01-12 05:15:31.450647: train_loss -0.78 
2025-01-12 05:15:31.450647: val_loss -0.6215 
2025-01-12 05:15:31.456721: Pseudo dice [np.float32(0.6916)] 
2025-01-12 05:15:31.459279: Epoch time: 42.23 s 
2025-01-12 05:15:32.006383:  
2025-01-12 05:15:32.006383: Epoch 242 
2025-01-12 05:15:32.011394: Current learning rate: 0.00045 
2025-01-12 05:16:14.228002: train_loss -0.8044 
2025-01-12 05:16:14.229004: val_loss -0.6779 
2025-01-12 05:16:14.234021: Pseudo dice [np.float32(0.7489)] 
2025-01-12 05:16:14.237532: Epoch time: 42.22 s 
2025-01-12 05:16:14.791259:  
2025-01-12 05:16:14.791259: Epoch 243 
2025-01-12 05:16:14.796270: Current learning rate: 0.0004 
2025-01-12 05:16:57.003594: train_loss -0.7924 
2025-01-12 05:16:57.003594: val_loss -0.6889 
2025-01-12 05:16:57.009632: Pseudo dice [np.float32(0.7652)] 
2025-01-12 05:16:57.012152: Epoch time: 42.21 s 
2025-01-12 05:16:57.563550:  
2025-01-12 05:16:57.564053: Epoch 244 
2025-01-12 05:16:57.569075: Current learning rate: 0.00035 
2025-01-12 05:17:39.785810: train_loss -0.7825 
2025-01-12 05:17:39.785810: val_loss -0.6985 
2025-01-12 05:17:39.791821: Pseudo dice [np.float32(0.7787)] 
2025-01-12 05:17:39.794856: Epoch time: 42.22 s 
2025-01-12 05:17:40.352116:  
2025-01-12 05:17:40.352116: Epoch 245 
2025-01-12 05:17:40.357128: Current learning rate: 0.0003 
2025-01-12 05:18:22.578932: train_loss -0.7661 
2025-01-12 05:18:22.579932: val_loss -0.5281 
2025-01-12 05:18:22.586448: Pseudo dice [np.float32(0.6136)] 
2025-01-12 05:18:22.588953: Epoch time: 42.23 s 
2025-01-12 05:18:23.294555:  
2025-01-12 05:18:23.294555: Epoch 246 
2025-01-12 05:18:23.298582: Current learning rate: 0.00024 
2025-01-12 05:19:05.513214: train_loss -0.7739 
2025-01-12 05:19:05.513214: val_loss -0.6599 
2025-01-12 05:19:05.518226: Pseudo dice [np.float32(0.7113)] 
2025-01-12 05:19:05.520732: Epoch time: 42.22 s 
2025-01-12 05:19:06.072511:  
2025-01-12 05:19:06.072511: Epoch 247 
2025-01-12 05:19:06.077554: Current learning rate: 0.00019 
2025-01-12 05:19:48.303699: train_loss -0.8112 
2025-01-12 05:19:48.303699: val_loss -0.6943 
2025-01-12 05:19:48.309756: Pseudo dice [np.float32(0.751)] 
2025-01-12 05:19:48.312764: Epoch time: 42.23 s 
2025-01-12 05:19:48.864547:  
2025-01-12 05:19:48.865551: Epoch 248 
2025-01-12 05:19:48.870570: Current learning rate: 0.00013 
2025-01-12 05:20:31.090727: train_loss -0.8031 
2025-01-12 05:20:31.090727: val_loss -0.671 
2025-01-12 05:20:31.097314: Pseudo dice [np.float32(0.7674)] 
2025-01-12 05:20:31.100338: Epoch time: 42.23 s 
2025-01-12 05:20:31.653756:  
2025-01-12 05:20:31.653756: Epoch 249 
2025-01-12 05:20:31.659273: Current learning rate: 7e-05 
2025-01-12 05:21:13.859583: train_loss -0.7906 
2025-01-12 05:21:13.860586: val_loss -0.7106 
2025-01-12 05:21:13.865598: Pseudo dice [np.float32(0.7784)] 
2025-01-12 05:21:13.869103: Epoch time: 42.21 s 
2025-01-12 05:21:14.627771: Training done. 
2025-01-12 05:21:14.653770: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2025-01-12 05:21:14.665771: The split file contains 5 splits. 
2025-01-12 05:21:14.670773: Desired fold for training: 0 
2025-01-12 05:21:14.677773: This split has 50 training and 13 validation cases. 
2025-01-12 05:21:14.684279: predicting lung_006 
2025-01-12 05:21:14.689278: lung_006, shape torch.Size([1, 285, 637, 637]), rank 0 
2025-01-12 05:22:03.202282: predicting lung_010 
2025-01-12 05:22:03.252792: lung_010, shape torch.Size([1, 242, 390, 390]), rank 0 
2025-01-12 05:22:22.040977: predicting lung_033 
2025-01-12 05:22:22.055977: lung_033, shape torch.Size([1, 260, 535, 535]), rank 0 
2025-01-12 05:23:00.080140: predicting lung_034 
2025-01-12 05:23:00.110140: lung_034, shape torch.Size([1, 296, 586, 586]), rank 0 
2025-01-12 05:23:54.316576: predicting lung_041 
2025-01-12 05:23:54.365575: lung_041, shape torch.Size([1, 240, 535, 535]), rank 0 
2025-01-12 05:24:27.763948: predicting lung_042 
2025-01-12 05:24:27.792948: lung_042, shape torch.Size([1, 251, 478, 478]), rank 0 
2025-01-12 05:24:53.424201: predicting lung_046 
2025-01-12 05:24:53.448710: lung_046, shape torch.Size([1, 226, 509, 509]), rank 0 
2025-01-12 05:25:18.992354: predicting lung_048 
2025-01-12 05:25:19.017354: lung_048, shape torch.Size([1, 259, 531, 531]), rank 0 
2025-01-12 05:25:57.204916: predicting lung_059 
2025-01-12 05:25:57.233915: lung_059, shape torch.Size([1, 218, 535, 535]), rank 0 
2025-01-12 05:26:25.838484: predicting lung_065 
2025-01-12 05:26:25.864483: lung_065, shape torch.Size([1, 257, 474, 474]), rank 0 
2025-01-12 05:26:55.106551: predicting lung_066 
2025-01-12 05:26:55.130552: lung_066, shape torch.Size([1, 241, 578, 578]), rank 0 
2025-01-12 05:27:37.312975: predicting lung_070 
2025-01-12 05:27:37.346487: lung_070, shape torch.Size([1, 266, 497, 497]), rank 0 
2025-01-12 05:28:06.603563: predicting lung_079 
2025-01-12 05:28:06.629563: lung_079, shape torch.Size([1, 251, 606, 606]), rank 0 
2025-01-12 05:29:00.201311: Validation complete 
2025-01-12 05:29:00.201311: Mean Validation Dice:  0.6991103137330327 
