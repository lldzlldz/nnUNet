2024-12-16 00:15:31.478822: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.75 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-16 00:15:31.481925: self.oversample_foreground_percent 0.8 
2024-12-16 00:15:31.485925: do_dummy_2d_data_aug: False 
2024-12-16 00:15:31.489938: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2024-12-16 00:15:31.494940: The split file contains 5 splits. 
2024-12-16 00:15:31.496941: Desired fold for training: 0 
2024-12-16 00:15:31.499452: This split has 50 training and 13 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 5, 'patch_size': [64, 128, 128], 'median_image_size_in_voxels': [252.0, 512.0, 512.0], 'spacing': [1.244979977607727, 0.78515625, 0.78515625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset006_Lung', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [1.244979977607727, 0.78515625, 0.78515625], 'original_median_shape_after_transp': [252, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2671.0, 'mean': -273.4598083496094, 'median': -162.0, 'min': -1024.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 311.0, 'std': 346.9495849609375}}} 
 
2024-12-16 00:15:39.764556: unpacking dataset... 
2024-12-16 00:15:39.961007: unpacking done... 
2024-12-16 00:15:42.265671:  
2024-12-16 00:15:42.270682: Epoch 0 
2024-12-16 00:15:42.274191: Current learning rate: 0.01 
2024-12-16 00:16:30.359909: train_loss -0.0905 
2024-12-16 00:16:30.365919: val_loss -0.4611 
2024-12-16 00:16:30.368927: Pseudo dice [np.float32(0.5797)] 
2024-12-16 00:16:30.371433: Epoch time: 48.09 s 
2024-12-16 00:16:30.373939: Yayy! New best EMA pseudo Dice: 0.5796999931335449 
2024-12-16 00:16:31.042633:  
2024-12-16 00:16:31.048179: Epoch 1 
2024-12-16 00:16:31.050690: Current learning rate: 0.00991 
2024-12-16 00:17:14.931877: train_loss -0.4145 
2024-12-16 00:17:14.937907: val_loss -0.5696 
2024-12-16 00:17:14.940924: Pseudo dice [np.float32(0.6583)] 
2024-12-16 00:17:14.944438: Epoch time: 43.89 s 
2024-12-16 00:17:14.946824: Yayy! New best EMA pseudo Dice: 0.5875999927520752 
2024-12-16 00:17:15.655433:  
2024-12-16 00:17:15.661458: Epoch 2 
2024-12-16 00:17:15.663967: Current learning rate: 0.00982 
2024-12-16 00:17:59.072293: train_loss -0.4829 
2024-12-16 00:17:59.079450: val_loss -0.5259 
2024-12-16 00:17:59.082482: Pseudo dice [np.float32(0.6083)] 
2024-12-16 00:17:59.085006: Epoch time: 43.42 s 
2024-12-16 00:17:59.087530: Yayy! New best EMA pseudo Dice: 0.5896000266075134 
2024-12-16 00:17:59.857927:  
2024-12-16 00:17:59.863963: Epoch 3 
2024-12-16 00:17:59.866490: Current learning rate: 0.00973 
2024-12-16 00:18:43.174279: train_loss -0.5466 
2024-12-16 00:18:43.179289: val_loss -0.6022 
2024-12-16 00:18:43.182795: Pseudo dice [np.float32(0.709)] 
2024-12-16 00:18:43.185802: Epoch time: 43.32 s 
2024-12-16 00:18:43.188365: Yayy! New best EMA pseudo Dice: 0.6015999913215637 
2024-12-16 00:18:43.931446:  
2024-12-16 00:18:43.936564: Epoch 4 
2024-12-16 00:18:43.939585: Current learning rate: 0.00964 
2024-12-16 00:19:27.179441: train_loss -0.578 
2024-12-16 00:19:27.185015: val_loss -0.6205 
2024-12-16 00:19:27.188085: Pseudo dice [np.float32(0.7308)] 
2024-12-16 00:19:27.190606: Epoch time: 43.25 s 
2024-12-16 00:19:27.194138: Yayy! New best EMA pseudo Dice: 0.6144999861717224 
2024-12-16 00:19:28.071634:  
2024-12-16 00:19:28.076659: Epoch 5 
2024-12-16 00:19:28.079179: Current learning rate: 0.00955 
2024-12-16 00:20:11.109591: train_loss -0.5794 
2024-12-16 00:20:11.116305: val_loss -0.6327 
2024-12-16 00:20:11.118824: Pseudo dice [np.float32(0.7306)] 
2024-12-16 00:20:11.122018: Epoch time: 43.04 s 
2024-12-16 00:20:11.125056: Yayy! New best EMA pseudo Dice: 0.6261000037193298 
2024-12-16 00:20:11.842573:  
2024-12-16 00:20:11.848177: Epoch 6 
2024-12-16 00:20:11.850726: Current learning rate: 0.00946 
2024-12-16 00:20:55.872293: train_loss -0.5991 
2024-12-16 00:20:55.877309: val_loss -0.5813 
2024-12-16 00:20:55.880820: Pseudo dice [np.float32(0.6389)] 
2024-12-16 00:20:55.883329: Epoch time: 44.03 s 
2024-12-16 00:20:55.885840: Yayy! New best EMA pseudo Dice: 0.6273999810218811 
2024-12-16 00:20:56.622638:  
2024-12-16 00:20:56.626672: Epoch 7 
2024-12-16 00:20:56.630204: Current learning rate: 0.00937 
2024-12-16 00:21:40.987363: train_loss -0.6101 
2024-12-16 00:21:40.992877: val_loss -0.6953 
2024-12-16 00:21:40.996386: Pseudo dice [np.float32(0.768)] 
2024-12-16 00:21:40.999896: Epoch time: 44.37 s 
2024-12-16 00:21:41.002918: Yayy! New best EMA pseudo Dice: 0.6413999795913696 
2024-12-16 00:21:41.740638:  
2024-12-16 00:21:41.746301: Epoch 8 
2024-12-16 00:21:41.749882: Current learning rate: 0.00928 
2024-12-16 00:22:25.410569: train_loss -0.6442 
2024-12-16 00:22:25.416108: val_loss -0.651 
2024-12-16 00:22:25.419614: Pseudo dice [np.float32(0.7281)] 
2024-12-16 00:22:25.422652: Epoch time: 43.67 s 
2024-12-16 00:22:25.425159: Yayy! New best EMA pseudo Dice: 0.6500999927520752 
2024-12-16 00:22:26.191358:  
2024-12-16 00:22:26.196942: Epoch 9 
2024-12-16 00:22:26.199978: Current learning rate: 0.00919 
2024-12-16 00:23:09.574192: train_loss -0.6838 
2024-12-16 00:23:09.578777: val_loss -0.6747 
2024-12-16 00:23:09.582838: Pseudo dice [np.float32(0.7492)] 
2024-12-16 00:23:09.585891: Epoch time: 43.38 s 
2024-12-16 00:23:09.588429: Yayy! New best EMA pseudo Dice: 0.6600000262260437 
2024-12-16 00:23:10.300565:  
2024-12-16 00:23:10.307637: Epoch 10 
2024-12-16 00:23:10.311753: Current learning rate: 0.0091 
2024-12-16 00:23:56.819257: train_loss -0.6997 
2024-12-16 00:23:56.825281: val_loss -0.6677 
2024-12-16 00:23:56.827791: Pseudo dice [np.float32(0.7422)] 
2024-12-16 00:23:56.832823: Epoch time: 46.52 s 
2024-12-16 00:23:56.836332: Yayy! New best EMA pseudo Dice: 0.6682000160217285 
2024-12-16 00:23:57.582302:  
2024-12-16 00:23:57.587817: Epoch 11 
2024-12-16 00:23:57.590323: Current learning rate: 0.009 
2024-12-16 00:24:40.677479: train_loss -0.6872 
2024-12-16 00:24:40.683049: val_loss -0.6995 
2024-12-16 00:24:40.686150: Pseudo dice [np.float32(0.764)] 
2024-12-16 00:24:40.689178: Epoch time: 43.1 s 
2024-12-16 00:24:40.691699: Yayy! New best EMA pseudo Dice: 0.6777999997138977 
2024-12-16 00:24:41.442444:  
2024-12-16 00:24:41.447518: Epoch 12 
2024-12-16 00:24:41.450038: Current learning rate: 0.00891 
2024-12-16 00:25:25.963240: train_loss -0.6846 
2024-12-16 00:25:25.969325: val_loss -0.7749 
2024-12-16 00:25:25.972833: Pseudo dice [np.float32(0.8282)] 
2024-12-16 00:25:25.975883: Epoch time: 44.52 s 
2024-12-16 00:25:25.978390: Yayy! New best EMA pseudo Dice: 0.6929000020027161 
2024-12-16 00:25:26.895309:  
2024-12-16 00:25:26.899344: Epoch 13 
2024-12-16 00:25:26.902855: Current learning rate: 0.00882 
2024-12-16 00:26:10.818998: train_loss -0.6357 
2024-12-16 00:26:10.824024: val_loss -0.6344 
2024-12-16 00:26:10.828053: Pseudo dice [np.float32(0.7278)] 
2024-12-16 00:26:10.830735: Epoch time: 43.92 s 
2024-12-16 00:26:10.833259: Yayy! New best EMA pseudo Dice: 0.6963000297546387 
2024-12-16 00:26:11.579462:  
2024-12-16 00:26:11.585083: Epoch 14 
2024-12-16 00:26:11.588137: Current learning rate: 0.00873 
2024-12-16 00:26:55.568295: train_loss -0.6649 
2024-12-16 00:26:55.573353: val_loss -0.6712 
2024-12-16 00:26:55.576892: Pseudo dice [np.float32(0.7469)] 
2024-12-16 00:26:55.579927: Epoch time: 43.99 s 
2024-12-16 00:26:55.582487: Yayy! New best EMA pseudo Dice: 0.7013999819755554 
2024-12-16 00:26:56.329031:  
2024-12-16 00:26:56.334075: Epoch 15 
2024-12-16 00:26:56.337085: Current learning rate: 0.00864 
2024-12-16 00:27:40.324132: train_loss -0.6677 
2024-12-16 00:27:40.329664: val_loss -0.6489 
2024-12-16 00:27:40.333178: Pseudo dice [np.float32(0.7214)] 
2024-12-16 00:27:40.335686: Epoch time: 44.0 s 
2024-12-16 00:27:40.339714: Yayy! New best EMA pseudo Dice: 0.7034000158309937 
2024-12-16 00:27:41.090688:  
2024-12-16 00:27:41.095750: Epoch 16 
2024-12-16 00:27:41.098809: Current learning rate: 0.00855 
2024-12-16 00:28:25.281740: train_loss -0.7021 
2024-12-16 00:28:25.288784: val_loss -0.6752 
2024-12-16 00:28:25.292310: Pseudo dice [np.float32(0.7504)] 
2024-12-16 00:28:25.295816: Epoch time: 44.19 s 
2024-12-16 00:28:25.298824: Yayy! New best EMA pseudo Dice: 0.7081000208854675 
2024-12-16 00:28:26.059165:  
2024-12-16 00:28:26.064252: Epoch 17 
2024-12-16 00:28:26.066790: Current learning rate: 0.00846 
2024-12-16 00:29:11.084894: train_loss -0.723 
2024-12-16 00:29:11.089905: val_loss -0.7626 
2024-12-16 00:29:11.093437: Pseudo dice [np.float32(0.809)] 
2024-12-16 00:29:11.095943: Epoch time: 45.03 s 
2024-12-16 00:29:11.099950: Yayy! New best EMA pseudo Dice: 0.7182000279426575 
2024-12-16 00:29:11.840485:  
2024-12-16 00:29:11.846078: Epoch 18 
2024-12-16 00:29:11.849095: Current learning rate: 0.00836 
2024-12-16 00:29:56.057693: train_loss -0.7421 
2024-12-16 00:29:56.063262: val_loss -0.7445 
2024-12-16 00:29:56.066789: Pseudo dice [np.float32(0.8055)] 
2024-12-16 00:29:56.069814: Epoch time: 44.22 s 
2024-12-16 00:29:56.072842: Yayy! New best EMA pseudo Dice: 0.7268999814987183 
2024-12-16 00:29:56.818965:  
2024-12-16 00:29:56.824014: Epoch 19 
2024-12-16 00:29:56.827581: Current learning rate: 0.00827 
2024-12-16 00:30:39.671824: train_loss -0.7009 
2024-12-16 00:30:39.676857: val_loss -0.7485 
2024-12-16 00:30:39.680866: Pseudo dice [np.float32(0.8024)] 
2024-12-16 00:30:39.683880: Epoch time: 42.85 s 
2024-12-16 00:30:39.686909: Yayy! New best EMA pseudo Dice: 0.734499990940094 
2024-12-16 00:30:40.420455:  
2024-12-16 00:30:40.425489: Epoch 20 
2024-12-16 00:30:40.429017: Current learning rate: 0.00818 
2024-12-16 00:31:23.326584: train_loss -0.7166 
2024-12-16 00:31:23.334104: val_loss -0.7101 
2024-12-16 00:31:23.336616: Pseudo dice [np.float32(0.7766)] 
2024-12-16 00:31:23.340128: Epoch time: 42.91 s 
2024-12-16 00:31:23.342635: Yayy! New best EMA pseudo Dice: 0.7386999726295471 
2024-12-16 00:31:24.235127:  
2024-12-16 00:31:24.240685: Epoch 21 
2024-12-16 00:31:24.245739: Current learning rate: 0.00809 
2024-12-16 00:32:06.792437: train_loss -0.7458 
2024-12-16 00:32:06.797971: val_loss -0.7062 
2024-12-16 00:32:06.801479: Pseudo dice [np.float32(0.7578)] 
2024-12-16 00:32:06.804986: Epoch time: 42.56 s 
2024-12-16 00:32:06.808015: Yayy! New best EMA pseudo Dice: 0.7405999898910522 
2024-12-16 00:32:07.528538:  
2024-12-16 00:32:07.535070: Epoch 22 
2024-12-16 00:32:07.538587: Current learning rate: 0.008 
2024-12-16 00:32:49.978741: train_loss -0.7318 
2024-12-16 00:32:49.983788: val_loss -0.7606 
2024-12-16 00:32:49.987821: Pseudo dice [np.float32(0.8063)] 
2024-12-16 00:32:49.990929: Epoch time: 42.45 s 
2024-12-16 00:32:49.993994: Yayy! New best EMA pseudo Dice: 0.7472000122070312 
2024-12-16 00:32:50.716462:  
2024-12-16 00:32:50.721491: Epoch 23 
2024-12-16 00:32:50.724500: Current learning rate: 0.0079 
2024-12-16 00:33:33.209164: train_loss -0.7522 
2024-12-16 00:33:33.215708: val_loss -0.7219 
2024-12-16 00:33:33.219241: Pseudo dice [np.float32(0.7781)] 
2024-12-16 00:33:33.222266: Epoch time: 42.49 s 
2024-12-16 00:33:33.225346: Yayy! New best EMA pseudo Dice: 0.7502999901771545 
2024-12-16 00:33:33.936197:  
2024-12-16 00:33:33.941777: Epoch 24 
2024-12-16 00:33:33.945812: Current learning rate: 0.00781 
2024-12-16 00:34:16.454904: train_loss -0.7248 
2024-12-16 00:34:16.460448: val_loss -0.7582 
2024-12-16 00:34:16.463472: Pseudo dice [np.float32(0.8066)] 
2024-12-16 00:34:16.466486: Epoch time: 42.52 s 
2024-12-16 00:34:16.468995: Yayy! New best EMA pseudo Dice: 0.7559000253677368 
2024-12-16 00:34:17.179498:  
2024-12-16 00:34:17.185085: Epoch 25 
2024-12-16 00:34:17.188654: Current learning rate: 0.00772 
2024-12-16 00:34:59.703357: train_loss -0.727 
2024-12-16 00:34:59.708871: val_loss -0.7207 
2024-12-16 00:34:59.711380: Pseudo dice [np.float32(0.7851)] 
2024-12-16 00:34:59.714890: Epoch time: 42.52 s 
2024-12-16 00:34:59.717397: Yayy! New best EMA pseudo Dice: 0.7588000297546387 
2024-12-16 00:35:00.446515:  
2024-12-16 00:35:00.452077: Epoch 26 
2024-12-16 00:35:00.454615: Current learning rate: 0.00763 
2024-12-16 00:35:42.920962: train_loss -0.7256 
2024-12-16 00:35:42.927046: val_loss -0.7308 
2024-12-16 00:35:42.930099: Pseudo dice [np.float32(0.7871)] 
2024-12-16 00:35:42.933125: Epoch time: 42.47 s 
2024-12-16 00:35:42.935460: Yayy! New best EMA pseudo Dice: 0.7616000175476074 
2024-12-16 00:35:43.655404:  
2024-12-16 00:35:43.660936: Epoch 27 
2024-12-16 00:35:43.665527: Current learning rate: 0.00753 
2024-12-16 00:36:26.697375: train_loss -0.7277 
2024-12-16 00:36:26.702950: val_loss -0.765 
2024-12-16 00:36:26.706542: Pseudo dice [np.float32(0.8156)] 
2024-12-16 00:36:26.709467: Epoch time: 43.04 s 
2024-12-16 00:36:26.711977: Yayy! New best EMA pseudo Dice: 0.7670000195503235 
2024-12-16 00:36:27.445906:  
2024-12-16 00:36:27.449932: Epoch 28 
2024-12-16 00:36:27.453939: Current learning rate: 0.00744 
2024-12-16 00:37:09.967226: train_loss -0.7572 
2024-12-16 00:37:09.973763: val_loss -0.7446 
2024-12-16 00:37:09.975799: Pseudo dice [np.float32(0.8154)] 
2024-12-16 00:37:09.979841: Epoch time: 42.52 s 
2024-12-16 00:37:09.982849: Yayy! New best EMA pseudo Dice: 0.7718999981880188 
2024-12-16 00:37:10.858808:  
2024-12-16 00:37:10.864349: Epoch 29 
2024-12-16 00:37:10.867890: Current learning rate: 0.00735 
2024-12-16 00:37:53.315502: train_loss -0.7555 
2024-12-16 00:37:53.321052: val_loss -0.7296 
2024-12-16 00:37:53.323573: Pseudo dice [np.float32(0.7912)] 
2024-12-16 00:37:53.327191: Epoch time: 42.46 s 
2024-12-16 00:37:53.330251: Yayy! New best EMA pseudo Dice: 0.7738000154495239 
2024-12-16 00:37:54.060475:  
2024-12-16 00:37:54.066570: Epoch 30 
2024-12-16 00:37:54.069625: Current learning rate: 0.00725 
2024-12-16 00:38:36.527106: train_loss -0.7559 
2024-12-16 00:38:36.533243: val_loss -0.7168 
2024-12-16 00:38:36.536268: Pseudo dice [np.float32(0.7778)] 
2024-12-16 00:38:36.540308: Epoch time: 42.47 s 
2024-12-16 00:38:36.542816: Yayy! New best EMA pseudo Dice: 0.7742000222206116 
2024-12-16 00:38:37.266531:  
2024-12-16 00:38:37.272104: Epoch 31 
2024-12-16 00:38:37.276651: Current learning rate: 0.00716 
2024-12-16 00:39:19.754948: train_loss -0.761 
2024-12-16 00:39:19.760984: val_loss -0.758 
2024-12-16 00:39:19.763746: Pseudo dice [np.float32(0.8129)] 
2024-12-16 00:39:19.766256: Epoch time: 42.49 s 
2024-12-16 00:39:19.769769: Yayy! New best EMA pseudo Dice: 0.7781000137329102 
2024-12-16 00:39:20.496519:  
2024-12-16 00:39:20.502081: Epoch 32 
2024-12-16 00:39:20.505673: Current learning rate: 0.00707 
2024-12-16 00:40:02.982674: train_loss -0.7789 
2024-12-16 00:40:02.988765: val_loss -0.7585 
2024-12-16 00:40:02.991854: Pseudo dice [np.float32(0.8022)] 
2024-12-16 00:40:02.994907: Epoch time: 42.49 s 
2024-12-16 00:40:02.997959: Yayy! New best EMA pseudo Dice: 0.7804999947547913 
2024-12-16 00:40:03.789623:  
2024-12-16 00:40:03.795161: Epoch 33 
2024-12-16 00:40:03.798190: Current learning rate: 0.00697 
2024-12-16 00:40:46.499218: train_loss -0.7587 
2024-12-16 00:40:46.504781: val_loss -0.7517 
2024-12-16 00:40:46.507289: Pseudo dice [np.float32(0.8128)] 
2024-12-16 00:40:46.510802: Epoch time: 42.71 s 
2024-12-16 00:40:46.516810: Yayy! New best EMA pseudo Dice: 0.7836999893188477 
2024-12-16 00:40:47.389633:  
2024-12-16 00:40:47.395181: Epoch 34 
2024-12-16 00:40:47.398189: Current learning rate: 0.00688 
2024-12-16 00:41:30.279927: train_loss -0.7644 
2024-12-16 00:41:30.285460: val_loss -0.7702 
2024-12-16 00:41:30.288969: Pseudo dice [np.float32(0.8191)] 
2024-12-16 00:41:30.291476: Epoch time: 42.89 s 
2024-12-16 00:41:30.294484: Yayy! New best EMA pseudo Dice: 0.7872999906539917 
2024-12-16 00:41:31.032677:  
2024-12-16 00:41:31.037760: Epoch 35 
2024-12-16 00:41:31.041806: Current learning rate: 0.00679 
2024-12-16 00:42:13.573078: train_loss -0.7871 
2024-12-16 00:42:13.579029: val_loss -0.742 
2024-12-16 00:42:13.582060: Pseudo dice [np.float32(0.8084)] 
2024-12-16 00:42:13.585620: Epoch time: 42.54 s 
2024-12-16 00:42:13.588677: Yayy! New best EMA pseudo Dice: 0.7893999814987183 
2024-12-16 00:42:14.343695:  
2024-12-16 00:42:14.348726: Epoch 36 
2024-12-16 00:42:14.352382: Current learning rate: 0.00669 
2024-12-16 00:42:56.876574: train_loss -0.786 
2024-12-16 00:42:56.882256: val_loss -0.679 
2024-12-16 00:42:56.885325: Pseudo dice [np.float32(0.7639)] 
2024-12-16 00:42:56.887837: Epoch time: 42.53 s 
2024-12-16 00:42:57.623375:  
2024-12-16 00:42:57.628422: Epoch 37 
2024-12-16 00:42:57.631468: Current learning rate: 0.0066 
2024-12-16 00:43:40.119152: train_loss -0.7586 
2024-12-16 00:43:40.125743: val_loss -0.7716 
2024-12-16 00:43:40.127760: Pseudo dice [np.float32(0.8279)] 
2024-12-16 00:43:40.132394: Epoch time: 42.5 s 
2024-12-16 00:43:40.135437: Yayy! New best EMA pseudo Dice: 0.7908999919891357 
2024-12-16 00:43:40.877829:  
2024-12-16 00:43:40.882841: Epoch 38 
2024-12-16 00:43:40.885851: Current learning rate: 0.0065 
2024-12-16 00:44:23.434817: train_loss -0.7625 
2024-12-16 00:44:23.439931: val_loss -0.7475 
2024-12-16 00:44:23.443559: Pseudo dice [np.float32(0.8055)] 
2024-12-16 00:44:23.446641: Epoch time: 42.56 s 
2024-12-16 00:44:23.449712: Yayy! New best EMA pseudo Dice: 0.7924000024795532 
2024-12-16 00:44:24.201524:  
2024-12-16 00:44:24.206506: Epoch 39 
2024-12-16 00:44:24.209524: Current learning rate: 0.00641 
2024-12-16 00:45:06.739537: train_loss -0.7849 
2024-12-16 00:45:06.745092: val_loss -0.7368 
2024-12-16 00:45:06.747600: Pseudo dice [np.float32(0.7901)] 
2024-12-16 00:45:06.750651: Epoch time: 42.54 s 
2024-12-16 00:45:07.331279:  
2024-12-16 00:45:07.336336: Epoch 40 
2024-12-16 00:45:07.339388: Current learning rate: 0.00631 
2024-12-16 00:45:50.102228: train_loss -0.7762 
2024-12-16 00:45:50.107242: val_loss -0.751 
2024-12-16 00:45:50.110760: Pseudo dice [np.float32(0.8114)] 
2024-12-16 00:45:50.113271: Epoch time: 42.77 s 
2024-12-16 00:45:50.116779: Yayy! New best EMA pseudo Dice: 0.7940999865531921 
2024-12-16 00:45:50.868309:  
2024-12-16 00:45:50.873244: Epoch 41 
2024-12-16 00:45:50.876754: Current learning rate: 0.00622 
2024-12-16 00:46:33.445499: train_loss -0.786 
2024-12-16 00:46:33.451512: val_loss -0.7526 
2024-12-16 00:46:33.454605: Pseudo dice [np.float32(0.811)] 
2024-12-16 00:46:33.457111: Epoch time: 42.58 s 
2024-12-16 00:46:33.460621: Yayy! New best EMA pseudo Dice: 0.795799970626831 
2024-12-16 00:46:34.188278:  
2024-12-16 00:46:34.193331: Epoch 42 
2024-12-16 00:46:34.196841: Current learning rate: 0.00612 
2024-12-16 00:47:16.719843: train_loss -0.7863 
2024-12-16 00:47:16.726029: val_loss -0.7787 
2024-12-16 00:47:16.728051: Pseudo dice [np.float32(0.8391)] 
2024-12-16 00:47:16.731593: Epoch time: 42.53 s 
2024-12-16 00:47:16.735155: Yayy! New best EMA pseudo Dice: 0.8001000285148621 
2024-12-16 00:47:17.453131:  
2024-12-16 00:47:17.458157: Epoch 43 
2024-12-16 00:47:17.461168: Current learning rate: 0.00603 
2024-12-16 00:48:00.927693: train_loss -0.7718 
2024-12-16 00:48:00.934209: val_loss -0.7612 
2024-12-16 00:48:00.937720: Pseudo dice [np.float32(0.8129)] 
2024-12-16 00:48:00.940229: Epoch time: 43.48 s 
2024-12-16 00:48:00.942736: Yayy! New best EMA pseudo Dice: 0.8014000058174133 
2024-12-16 00:48:01.702394:  
2024-12-16 00:48:01.707428: Epoch 44 
2024-12-16 00:48:01.709934: Current learning rate: 0.00593 
2024-12-16 00:48:44.719810: train_loss -0.809 
2024-12-16 00:48:44.726921: val_loss -0.7067 
2024-12-16 00:48:44.729453: Pseudo dice [np.float32(0.7934)] 
2024-12-16 00:48:44.733495: Epoch time: 43.02 s 
2024-12-16 00:48:45.457163:  
2024-12-16 00:48:45.462205: Epoch 45 
2024-12-16 00:48:45.465721: Current learning rate: 0.00584 
2024-12-16 00:49:29.059186: train_loss -0.8065 
2024-12-16 00:49:29.065209: val_loss -0.7397 
2024-12-16 00:49:29.067719: Pseudo dice [np.float32(0.8045)] 
2024-12-16 00:49:29.071733: Epoch time: 43.6 s 
2024-12-16 00:49:29.623708:  
2024-12-16 00:49:29.628719: Epoch 46 
2024-12-16 00:49:29.631225: Current learning rate: 0.00574 
2024-12-16 00:50:12.966770: train_loss -0.8087 
2024-12-16 00:50:12.972367: val_loss -0.7711 
2024-12-16 00:50:12.974902: Pseudo dice [np.float32(0.8234)] 
2024-12-16 00:50:12.978454: Epoch time: 43.34 s 
2024-12-16 00:50:12.981505: Yayy! New best EMA pseudo Dice: 0.8032000064849854 
2024-12-16 00:50:13.723911:  
2024-12-16 00:50:13.728973: Epoch 47 
2024-12-16 00:50:13.731525: Current learning rate: 0.00565 
2024-12-16 00:50:57.093158: train_loss -0.813 
2024-12-16 00:50:57.098721: val_loss -0.7516 
2024-12-16 00:50:57.101772: Pseudo dice [np.float32(0.8108)] 
2024-12-16 00:50:57.104315: Epoch time: 43.37 s 
2024-12-16 00:50:57.108392: Yayy! New best EMA pseudo Dice: 0.8040000200271606 
2024-12-16 00:50:57.837487:  
2024-12-16 00:50:57.841555: Epoch 48 
2024-12-16 00:50:57.845666: Current learning rate: 0.00555 
2024-12-16 00:51:41.371327: train_loss -0.7996 
2024-12-16 00:51:41.376339: val_loss -0.7162 
2024-12-16 00:51:41.380351: Pseudo dice [np.float32(0.7676)] 
2024-12-16 00:51:41.383861: Epoch time: 43.54 s 
2024-12-16 00:51:41.942994:  
2024-12-16 00:51:41.947552: Epoch 49 
2024-12-16 00:51:41.951109: Current learning rate: 0.00546 
2024-12-16 00:52:25.615839: train_loss -0.8186 
2024-12-16 00:52:25.619857: val_loss -0.716 
2024-12-16 00:52:25.623374: Pseudo dice [np.float32(0.7893)] 
2024-12-16 00:52:25.626884: Epoch time: 43.67 s 
2024-12-16 00:52:26.397472:  
2024-12-16 00:52:26.403016: Epoch 50 
2024-12-16 00:52:26.405637: Current learning rate: 0.00536 
2024-12-16 00:53:09.286252: train_loss -0.8226 
2024-12-16 00:53:09.290827: val_loss -0.7208 
2024-12-16 00:53:09.294920: Pseudo dice [np.float32(0.7767)] 
2024-12-16 00:53:09.298481: Epoch time: 42.89 s 
2024-12-16 00:53:09.856626:  
2024-12-16 00:53:09.861135: Epoch 51 
2024-12-16 00:53:09.864145: Current learning rate: 0.00526 
2024-12-16 00:53:53.476293: train_loss -0.8069 
2024-12-16 00:53:53.482892: val_loss -0.7701 
2024-12-16 00:53:53.486429: Pseudo dice [np.float32(0.8229)] 
2024-12-16 00:53:53.489471: Epoch time: 43.62 s 
2024-12-16 00:53:54.050587:  
2024-12-16 00:53:54.055663: Epoch 52 
2024-12-16 00:53:54.059190: Current learning rate: 0.00517 
2024-12-16 00:54:37.542568: train_loss -0.7905 
2024-12-16 00:54:37.549149: val_loss -0.6962 
2024-12-16 00:54:37.552196: Pseudo dice [np.float32(0.7759)] 
2024-12-16 00:54:37.555236: Epoch time: 43.49 s 
2024-12-16 00:54:38.266937:  
2024-12-16 00:54:38.271504: Epoch 53 
2024-12-16 00:54:38.275075: Current learning rate: 0.00507 
2024-12-16 00:55:21.850546: train_loss -0.7828 
2024-12-16 00:55:21.856576: val_loss -0.7537 
2024-12-16 00:55:21.860127: Pseudo dice [np.float32(0.8016)] 
2024-12-16 00:55:21.862225: Epoch time: 43.58 s 
2024-12-16 00:55:22.451056:  
2024-12-16 00:55:22.455615: Epoch 54 
2024-12-16 00:55:22.459123: Current learning rate: 0.00497 
2024-12-16 00:56:06.034393: train_loss -0.7946 
2024-12-16 00:56:06.040554: val_loss -0.7257 
2024-12-16 00:56:06.044130: Pseudo dice [np.float32(0.8047)] 
2024-12-16 00:56:06.046680: Epoch time: 43.58 s 
2024-12-16 00:56:06.598097:  
2024-12-16 00:56:06.603654: Epoch 55 
2024-12-16 00:56:06.606714: Current learning rate: 0.00487 
2024-12-16 00:56:50.999387: train_loss -0.826 
2024-12-16 00:56:51.004423: val_loss -0.7816 
2024-12-16 00:56:51.007935: Pseudo dice [np.float32(0.8223)] 
2024-12-16 00:56:51.010443: Epoch time: 44.4 s 
2024-12-16 00:56:51.567314:  
2024-12-16 00:56:51.571358: Epoch 56 
2024-12-16 00:56:51.575400: Current learning rate: 0.00478 
2024-12-16 00:57:35.370579: train_loss -0.82 
2024-12-16 00:57:35.376143: val_loss -0.6494 
2024-12-16 00:57:35.380154: Pseudo dice [np.float32(0.7289)] 
2024-12-16 00:57:35.383669: Epoch time: 43.8 s 
2024-12-16 00:57:35.941720:  
2024-12-16 00:57:35.946734: Epoch 57 
2024-12-16 00:57:35.949744: Current learning rate: 0.00468 
2024-12-16 00:58:19.711507: train_loss -0.7932 
2024-12-16 00:58:19.716739: val_loss -0.7387 
2024-12-16 00:58:19.720302: Pseudo dice [np.float32(0.7975)] 
2024-12-16 00:58:19.723411: Epoch time: 43.77 s 
2024-12-16 00:58:20.286607:  
2024-12-16 00:58:20.292151: Epoch 58 
2024-12-16 00:58:20.295169: Current learning rate: 0.00458 
2024-12-16 00:59:04.020187: train_loss -0.8081 
2024-12-16 00:59:04.025727: val_loss -0.7386 
2024-12-16 00:59:04.029760: Pseudo dice [np.float32(0.7972)] 
2024-12-16 00:59:04.032781: Epoch time: 43.73 s 
2024-12-16 00:59:04.595836:  
2024-12-16 00:59:04.601444: Epoch 59 
2024-12-16 00:59:04.604999: Current learning rate: 0.00448 
2024-12-16 00:59:47.994622: train_loss -0.8076 
2024-12-16 00:59:48.000727: val_loss -0.7353 
2024-12-16 00:59:48.003239: Pseudo dice [np.float32(0.7963)] 
2024-12-16 00:59:48.007252: Epoch time: 43.4 s 
2024-12-16 00:59:48.577597:  
2024-12-16 00:59:48.581692: Epoch 60 
2024-12-16 00:59:48.584828: Current learning rate: 0.00438 
2024-12-16 01:00:32.414567: train_loss -0.817 
2024-12-16 01:00:32.420189: val_loss -0.7707 
2024-12-16 01:00:32.424803: Pseudo dice [np.float32(0.8155)] 
2024-12-16 01:00:32.427910: Epoch time: 43.84 s 
2024-12-16 01:00:33.165896:  
2024-12-16 01:00:33.170909: Epoch 61 
2024-12-16 01:00:33.173416: Current learning rate: 0.00429 
2024-12-16 01:01:16.602231: train_loss -0.8178 
2024-12-16 01:01:16.607244: val_loss -0.7498 
2024-12-16 01:01:16.610754: Pseudo dice [np.float32(0.8081)] 
2024-12-16 01:01:16.613263: Epoch time: 43.44 s 
2024-12-16 01:01:17.217934:  
2024-12-16 01:01:17.223012: Epoch 62 
2024-12-16 01:01:17.226066: Current learning rate: 0.00419 
2024-12-16 01:02:00.728308: train_loss -0.8371 
2024-12-16 01:02:00.734364: val_loss -0.732 
2024-12-16 01:02:00.737926: Pseudo dice [np.float32(0.7946)] 
2024-12-16 01:02:00.741172: Epoch time: 43.51 s 
2024-12-16 01:02:01.330743:  
2024-12-16 01:02:01.336300: Epoch 63 
2024-12-16 01:02:01.338834: Current learning rate: 0.00409 
2024-12-16 01:02:45.087059: train_loss -0.8358 
2024-12-16 01:02:45.093076: val_loss -0.7103 
2024-12-16 01:02:45.097085: Pseudo dice [np.float32(0.8024)] 
2024-12-16 01:02:45.099592: Epoch time: 43.76 s 
2024-12-16 01:02:45.672118:  
2024-12-16 01:02:45.676664: Epoch 64 
2024-12-16 01:02:45.681760: Current learning rate: 0.00399 
2024-12-16 01:03:28.957901: train_loss -0.8275 
2024-12-16 01:03:28.964417: val_loss -0.7496 
2024-12-16 01:03:28.967456: Pseudo dice [np.float32(0.8006)] 
2024-12-16 01:03:28.969968: Epoch time: 43.29 s 
2024-12-16 01:03:29.549333:  
2024-12-16 01:03:29.553372: Epoch 65 
2024-12-16 01:03:29.557439: Current learning rate: 0.00389 
2024-12-16 01:04:13.512719: train_loss -0.8002 
2024-12-16 01:04:13.518742: val_loss -0.6551 
2024-12-16 01:04:13.522253: Pseudo dice [np.float32(0.7519)] 
2024-12-16 01:04:13.525265: Epoch time: 43.96 s 
2024-12-16 01:04:14.104327:  
2024-12-16 01:04:14.109451: Epoch 66 
2024-12-16 01:04:14.112502: Current learning rate: 0.00379 
2024-12-16 01:04:57.364686: train_loss -0.8061 
2024-12-16 01:04:57.370782: val_loss -0.7457 
2024-12-16 01:04:57.373312: Pseudo dice [np.float32(0.8016)] 
2024-12-16 01:04:57.377349: Epoch time: 43.26 s 
2024-12-16 01:04:57.946700:  
2024-12-16 01:04:57.951256: Epoch 67 
2024-12-16 01:04:57.955275: Current learning rate: 0.00369 
2024-12-16 01:05:41.263594: train_loss -0.8188 
2024-12-16 01:05:41.268682: val_loss -0.6544 
2024-12-16 01:05:41.272742: Pseudo dice [np.float32(0.7178)] 
2024-12-16 01:05:41.275774: Epoch time: 43.32 s 
2024-12-16 01:05:41.857102:  
2024-12-16 01:05:41.862114: Epoch 68 
2024-12-16 01:05:41.865124: Current learning rate: 0.00359 
2024-12-16 01:06:25.168136: train_loss -0.8021 
2024-12-16 01:06:25.174201: val_loss -0.7537 
2024-12-16 01:06:25.178240: Pseudo dice [np.float32(0.8098)] 
2024-12-16 01:06:25.181301: Epoch time: 43.31 s 
2024-12-16 01:06:25.908053:  
2024-12-16 01:06:25.914067: Epoch 69 
2024-12-16 01:06:25.917078: Current learning rate: 0.00349 
2024-12-16 01:07:09.239157: train_loss -0.8048 
2024-12-16 01:07:09.245201: val_loss -0.7278 
2024-12-16 01:07:09.248708: Pseudo dice [np.float32(0.7763)] 
2024-12-16 01:07:09.251719: Epoch time: 43.33 s 
2024-12-16 01:07:09.918051:  
2024-12-16 01:07:09.923568: Epoch 70 
2024-12-16 01:07:09.926074: Current learning rate: 0.00338 
2024-12-16 01:07:53.402133: train_loss -0.8124 
2024-12-16 01:07:53.407786: val_loss -0.746 
2024-12-16 01:07:53.410857: Pseudo dice [np.float32(0.7764)] 
2024-12-16 01:07:53.413401: Epoch time: 43.49 s 
2024-12-16 01:07:53.989968:  
2024-12-16 01:07:53.995638: Epoch 71 
2024-12-16 01:07:53.998172: Current learning rate: 0.00328 
2024-12-16 01:08:37.515019: train_loss -0.8301 
2024-12-16 01:08:37.521086: val_loss -0.7492 
2024-12-16 01:08:37.524121: Pseudo dice [np.float32(0.8027)] 
2024-12-16 01:08:37.527636: Epoch time: 43.53 s 
2024-12-16 01:08:38.105395:  
2024-12-16 01:08:38.110435: Epoch 72 
2024-12-16 01:08:38.112945: Current learning rate: 0.00318 
2024-12-16 01:09:21.899557: train_loss -0.8398 
2024-12-16 01:09:21.905072: val_loss -0.7534 
2024-12-16 01:09:21.908583: Pseudo dice [np.float32(0.806)] 
2024-12-16 01:09:21.911092: Epoch time: 43.8 s 
2024-12-16 01:09:22.490373:  
2024-12-16 01:09:22.495384: Epoch 73 
2024-12-16 01:09:22.497891: Current learning rate: 0.00308 
2024-12-16 01:10:05.936387: train_loss -0.8408 
2024-12-16 01:10:05.941427: val_loss -0.7513 
2024-12-16 01:10:05.945453: Pseudo dice [np.float32(0.8112)] 
2024-12-16 01:10:05.948478: Epoch time: 43.45 s 
2024-12-16 01:10:06.534357:  
2024-12-16 01:10:06.538961: Epoch 74 
2024-12-16 01:10:06.542514: Current learning rate: 0.00297 
2024-12-16 01:10:50.023488: train_loss -0.8474 
2024-12-16 01:10:50.028503: val_loss -0.7578 
2024-12-16 01:10:50.032011: Pseudo dice [np.float32(0.8207)] 
2024-12-16 01:10:50.035022: Epoch time: 43.49 s 
2024-12-16 01:10:50.613783:  
2024-12-16 01:10:50.618889: Epoch 75 
2024-12-16 01:10:50.621409: Current learning rate: 0.00287 
2024-12-16 01:11:34.338591: train_loss -0.8457 
2024-12-16 01:11:34.345117: val_loss -0.754 
2024-12-16 01:11:34.348626: Pseudo dice [np.float32(0.8097)] 
2024-12-16 01:11:34.351638: Epoch time: 43.73 s 
2024-12-16 01:11:34.935466:  
2024-12-16 01:11:34.940532: Epoch 76 
2024-12-16 01:11:34.943044: Current learning rate: 0.00277 
2024-12-16 01:12:18.676975: train_loss -0.8532 
2024-12-16 01:12:18.683502: val_loss -0.7037 
2024-12-16 01:12:18.687016: Pseudo dice [np.float32(0.7657)] 
2024-12-16 01:12:18.691032: Epoch time: 43.74 s 
2024-12-16 01:12:19.421009:  
2024-12-16 01:12:19.426566: Epoch 77 
2024-12-16 01:12:19.429143: Current learning rate: 0.00266 
2024-12-16 01:13:03.308278: train_loss -0.8414 
2024-12-16 01:13:03.313291: val_loss -0.7147 
2024-12-16 01:13:03.316801: Pseudo dice [np.float32(0.786)] 
2024-12-16 01:13:03.319811: Epoch time: 43.89 s 
2024-12-16 01:13:03.910304:  
2024-12-16 01:13:03.915866: Epoch 78 
2024-12-16 01:13:03.919400: Current learning rate: 0.00256 
2024-12-16 01:13:47.217497: train_loss -0.8484 
2024-12-16 01:13:47.224143: val_loss -0.7387 
2024-12-16 01:13:47.226676: Pseudo dice [np.float32(0.8072)] 
2024-12-16 01:13:47.230199: Epoch time: 43.31 s 
2024-12-16 01:13:47.834448:  
2024-12-16 01:13:47.839488: Epoch 79 
2024-12-16 01:13:47.842998: Current learning rate: 0.00245 
2024-12-16 01:14:31.408509: train_loss -0.8475 
2024-12-16 01:14:31.415129: val_loss -0.7215 
2024-12-16 01:14:31.418241: Pseudo dice [np.float32(0.7885)] 
2024-12-16 01:14:31.421304: Epoch time: 43.57 s 
2024-12-16 01:14:32.027992:  
2024-12-16 01:14:32.033541: Epoch 80 
2024-12-16 01:14:32.036629: Current learning rate: 0.00235 
2024-12-16 01:15:15.465408: train_loss -0.8516 
2024-12-16 01:15:15.470419: val_loss -0.7777 
2024-12-16 01:15:15.474430: Pseudo dice [np.float32(0.8202)] 
2024-12-16 01:15:15.476937: Epoch time: 43.44 s 
2024-12-16 01:15:16.081295:  
2024-12-16 01:15:16.086308: Epoch 81 
2024-12-16 01:15:16.088815: Current learning rate: 0.00224 
2024-12-16 01:15:59.862124: train_loss -0.8327 
2024-12-16 01:15:59.867643: val_loss -0.7349 
2024-12-16 01:15:59.871156: Pseudo dice [np.float32(0.7912)] 
2024-12-16 01:15:59.873661: Epoch time: 43.78 s 
2024-12-16 01:16:00.470658:  
2024-12-16 01:16:00.476255: Epoch 82 
2024-12-16 01:16:00.479342: Current learning rate: 0.00214 
2024-12-16 01:16:44.249810: train_loss -0.8193 
2024-12-16 01:16:44.255847: val_loss -0.7263 
2024-12-16 01:16:44.258862: Pseudo dice [np.float32(0.7835)] 
2024-12-16 01:16:44.261372: Epoch time: 43.78 s 
2024-12-16 01:16:44.821524:  
2024-12-16 01:16:44.827103: Epoch 83 
2024-12-16 01:16:44.830149: Current learning rate: 0.00203 
2024-12-16 01:17:28.279344: train_loss -0.8503 
2024-12-16 01:17:28.287108: val_loss -0.722 
2024-12-16 01:17:28.290623: Pseudo dice [np.float32(0.7973)] 
2024-12-16 01:17:28.293660: Epoch time: 43.46 s 
2024-12-16 01:17:28.855699:  
2024-12-16 01:17:28.860631: Epoch 84 
2024-12-16 01:17:28.863183: Current learning rate: 0.00192 
2024-12-16 01:18:13.023525: train_loss -0.851 
2024-12-16 01:18:13.029073: val_loss -0.7587 
2024-12-16 01:18:13.032106: Pseudo dice [np.float32(0.8152)] 
2024-12-16 01:18:13.035132: Epoch time: 44.17 s 
2024-12-16 01:18:13.748655:  
2024-12-16 01:18:13.753692: Epoch 85 
2024-12-16 01:18:13.756788: Current learning rate: 0.00181 
2024-12-16 01:18:58.210002: train_loss -0.8444 
2024-12-16 01:18:58.216024: val_loss -0.7278 
2024-12-16 01:18:58.220037: Pseudo dice [np.float32(0.781)] 
2024-12-16 01:18:58.222548: Epoch time: 44.46 s 
2024-12-16 01:18:58.780321:  
2024-12-16 01:18:58.785337: Epoch 86 
2024-12-16 01:18:58.787843: Current learning rate: 0.0017 
2024-12-16 01:19:42.197644: train_loss -0.8557 
2024-12-16 01:19:42.203701: val_loss -0.7184 
2024-12-16 01:19:42.206212: Pseudo dice [np.float32(0.785)] 
2024-12-16 01:19:42.209727: Epoch time: 43.42 s 
2024-12-16 01:19:42.751280:  
2024-12-16 01:19:42.756316: Epoch 87 
2024-12-16 01:19:42.759864: Current learning rate: 0.00159 
2024-12-16 01:20:26.322617: train_loss -0.8556 
2024-12-16 01:20:26.329174: val_loss -0.7141 
2024-12-16 01:20:26.332211: Pseudo dice [np.float32(0.7706)] 
2024-12-16 01:20:26.335247: Epoch time: 43.57 s 
2024-12-16 01:20:26.887355:  
2024-12-16 01:20:26.892368: Epoch 88 
2024-12-16 01:20:26.895877: Current learning rate: 0.00148 
2024-12-16 01:21:10.544068: train_loss -0.8597 
2024-12-16 01:21:10.550227: val_loss -0.727 
2024-12-16 01:21:10.554263: Pseudo dice [np.float32(0.8047)] 
2024-12-16 01:21:10.557329: Epoch time: 43.66 s 
2024-12-16 01:21:11.102271:  
2024-12-16 01:21:11.108421: Epoch 89 
2024-12-16 01:21:11.111462: Current learning rate: 0.00137 
2024-12-16 01:21:54.441642: train_loss -0.8454 
2024-12-16 01:21:54.447164: val_loss -0.7282 
2024-12-16 01:21:54.450679: Pseudo dice [np.float32(0.8108)] 
2024-12-16 01:21:54.454690: Epoch time: 43.34 s 
2024-12-16 01:21:54.999235:  
2024-12-16 01:21:55.003785: Epoch 90 
2024-12-16 01:21:55.007335: Current learning rate: 0.00126 
2024-12-16 01:22:38.510042: train_loss -0.8557 
2024-12-16 01:22:38.516088: val_loss -0.7498 
2024-12-16 01:22:38.520119: Pseudo dice [np.float32(0.8024)] 
2024-12-16 01:22:38.523643: Epoch time: 43.51 s 
2024-12-16 01:22:39.045499:  
2024-12-16 01:22:39.050543: Epoch 91 
2024-12-16 01:22:39.053593: Current learning rate: 0.00115 
2024-12-16 01:23:21.714697: train_loss -0.8562 
2024-12-16 01:23:21.720211: val_loss -0.7566 
2024-12-16 01:23:21.724253: Pseudo dice [np.float32(0.8104)] 
2024-12-16 01:23:21.727805: Epoch time: 42.67 s 
2024-12-16 01:23:22.251150:  
2024-12-16 01:23:22.256204: Epoch 92 
2024-12-16 01:23:22.260237: Current learning rate: 0.00103 
2024-12-16 01:24:04.942759: train_loss -0.8618 
2024-12-16 01:24:04.948292: val_loss -0.7391 
2024-12-16 01:24:04.951801: Pseudo dice [np.float32(0.8065)] 
2024-12-16 01:24:04.955830: Epoch time: 42.69 s 
2024-12-16 01:24:05.623923:  
2024-12-16 01:24:05.629437: Epoch 93 
2024-12-16 01:24:05.632948: Current learning rate: 0.00091 
2024-12-16 01:24:48.312260: train_loss -0.8548 
2024-12-16 01:24:48.317777: val_loss -0.6763 
2024-12-16 01:24:48.321287: Pseudo dice [np.float32(0.751)] 
2024-12-16 01:24:48.325295: Epoch time: 42.69 s 
2024-12-16 01:24:48.842651:  
2024-12-16 01:24:48.847694: Epoch 94 
2024-12-16 01:24:48.851216: Current learning rate: 0.00079 
2024-12-16 01:25:31.511533: train_loss -0.8643 
2024-12-16 01:25:31.518548: val_loss -0.7255 
2024-12-16 01:25:31.521557: Pseudo dice [np.float32(0.7944)] 
2024-12-16 01:25:31.526067: Epoch time: 42.67 s 
2024-12-16 01:25:32.043661:  
2024-12-16 01:25:32.048672: Epoch 95 
2024-12-16 01:25:32.052181: Current learning rate: 0.00067 
2024-12-16 01:26:14.699575: train_loss -0.8628 
2024-12-16 01:26:14.704587: val_loss -0.7645 
2024-12-16 01:26:14.708096: Pseudo dice [np.float32(0.8251)] 
2024-12-16 01:26:14.712106: Epoch time: 42.66 s 
2024-12-16 01:26:15.231598:  
2024-12-16 01:26:15.237233: Epoch 96 
2024-12-16 01:26:15.240276: Current learning rate: 0.00055 
2024-12-16 01:26:57.894796: train_loss -0.8589 
2024-12-16 01:26:57.900826: val_loss -0.7222 
2024-12-16 01:26:57.904339: Pseudo dice [np.float32(0.7769)] 
2024-12-16 01:26:57.908368: Epoch time: 42.66 s 
2024-12-16 01:26:58.432496:  
2024-12-16 01:26:58.438524: Epoch 97 
2024-12-16 01:26:58.442033: Current learning rate: 0.00043 
2024-12-16 01:27:41.240702: train_loss -0.8561 
2024-12-16 01:27:41.246761: val_loss -0.7287 
2024-12-16 01:27:41.250865: Pseudo dice [np.float32(0.7874)] 
2024-12-16 01:27:41.254962: Epoch time: 42.81 s 
2024-12-16 01:27:41.781044:  
2024-12-16 01:27:41.786594: Epoch 98 
2024-12-16 01:27:41.789671: Current learning rate: 0.0003 
2024-12-16 01:28:24.467637: train_loss -0.8578 
2024-12-16 01:28:24.473179: val_loss -0.7309 
2024-12-16 01:28:24.477186: Pseudo dice [np.float32(0.8057)] 
2024-12-16 01:28:24.480695: Epoch time: 42.69 s 
2024-12-16 01:28:25.005718:  
2024-12-16 01:28:25.011785: Epoch 99 
2024-12-16 01:28:25.014847: Current learning rate: 0.00016 
2024-12-16 01:29:07.662970: train_loss -0.855 
2024-12-16 01:29:07.667989: val_loss -0.7192 
2024-12-16 01:29:07.672505: Pseudo dice [np.float32(0.7819)] 
2024-12-16 01:29:07.677665: Epoch time: 42.66 s 
2024-12-16 01:29:08.404743: Training done. 
2024-12-16 01:29:08.436268: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2024-12-16 01:29:08.443779: The split file contains 5 splits. 
2024-12-16 01:29:08.449013: Desired fold for training: 0 
2024-12-16 01:29:08.454516: This split has 50 training and 13 validation cases. 
2024-12-16 01:29:08.460031: predicting lung_006 
2024-12-16 01:29:08.465033: lung_006, shape torch.Size([1, 285, 637, 637]), rank 0 
2024-12-16 01:29:56.962125: predicting lung_010 
2024-12-16 01:29:57.024132: lung_010, shape torch.Size([1, 242, 390, 390]), rank 0 
2024-12-16 01:30:15.834756: predicting lung_033 
2024-12-16 01:30:15.858765: lung_033, shape torch.Size([1, 260, 535, 535]), rank 0 
2024-12-16 01:30:54.090259: predicting lung_034 
2024-12-16 01:30:54.132791: lung_034, shape torch.Size([1, 296, 586, 586]), rank 0 
2024-12-16 01:31:48.398139: predicting lung_041 
2024-12-16 01:31:48.454188: lung_041, shape torch.Size([1, 240, 535, 535]), rank 0 
2024-12-16 01:32:21.898084: predicting lung_042 
2024-12-16 01:32:21.939111: lung_042, shape torch.Size([1, 251, 478, 478]), rank 0 
2024-12-16 01:32:47.407254: predicting lung_046 
2024-12-16 01:32:47.444790: lung_046, shape torch.Size([1, 226, 509, 509]), rank 0 
2024-12-16 01:33:12.880558: predicting lung_048 
2024-12-16 01:33:12.914369: lung_048, shape torch.Size([1, 259, 531, 531]), rank 0 
2024-12-16 01:33:50.966162: predicting lung_059 
2024-12-16 01:33:51.008199: lung_059, shape torch.Size([1, 218, 535, 535]), rank 0 
2024-12-16 01:34:25.115972: predicting lung_065 
2024-12-16 01:34:25.146492: lung_065, shape torch.Size([1, 257, 474, 474]), rank 0 
2024-12-16 01:34:54.805115: predicting lung_066 
2024-12-16 01:34:54.833629: lung_066, shape torch.Size([1, 241, 578, 578]), rank 0 
2024-12-16 01:35:37.115535: predicting lung_070 
2024-12-16 01:35:37.155205: lung_070, shape torch.Size([1, 266, 497, 497]), rank 0 
2024-12-16 01:36:07.373055: predicting lung_079 
2024-12-16 01:36:07.406395: lung_079, shape torch.Size([1, 251, 606, 606]), rank 0 
2024-12-16 01:37:00.723345: Validation complete 
2024-12-16 01:37:00.727852: Mean Validation Dice:  0.6806175247884219 
