2025-01-12 13:06:13.772370: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.5 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-12 13:06:13.776374: self.oversample_foreground_percent 0.6 
2025-01-12 13:06:13.780371: do_dummy_2d_data_aug: False 
2025-01-12 13:06:13.783376: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2025-01-12 13:06:13.786375: The split file contains 5 splits. 
2025-01-12 13:06:13.788375: Desired fold for training: 0 
2025-01-12 13:06:13.791379: This split has 50 training and 13 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 5, 'patch_size': [64, 128, 128], 'median_image_size_in_voxels': [252.0, 512.0, 512.0], 'spacing': [1.244979977607727, 0.78515625, 0.78515625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset006_Lung', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [1.244979977607727, 0.78515625, 0.78515625], 'original_median_shape_after_transp': [252, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2671.0, 'mean': -273.4598083496094, 'median': -162.0, 'min': -1024.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 311.0, 'std': 346.9495849609375}}} 
 
2025-01-12 13:06:21.695985: unpacking dataset... 
2025-01-12 13:06:21.881645: unpacking done... 
2025-01-12 13:06:24.959617:  
2025-01-12 13:06:24.959617: Epoch 0 
2025-01-12 13:06:24.964627: Current learning rate: 0.01 
2025-01-12 13:07:11.563278: train_loss -0.0707 
2025-01-12 13:07:11.563781: val_loss -0.5058 
2025-01-12 13:07:11.570312: Pseudo dice [np.float32(0.596)] 
2025-01-12 13:07:11.575327: Epoch time: 46.6 s 
2025-01-12 13:07:11.579341: Yayy! New best EMA pseudo Dice: 0.5960000157356262 
2025-01-12 13:07:12.171291:  
2025-01-12 13:07:12.171291: Epoch 1 
2025-01-12 13:07:12.177307: Current learning rate: 0.00998 
2025-01-12 13:07:54.389403: train_loss -0.3609 
2025-01-12 13:07:54.389403: val_loss -0.6282 
2025-01-12 13:07:54.397505: Pseudo dice [np.float32(0.7179)] 
2025-01-12 13:07:54.401094: Epoch time: 42.22 s 
2025-01-12 13:07:54.404188: Yayy! New best EMA pseudo Dice: 0.6082000136375427 
2025-01-12 13:07:55.048914:  
2025-01-12 13:07:55.048914: Epoch 2 
2025-01-12 13:07:55.053928: Current learning rate: 0.00996 
2025-01-12 13:08:37.289320: train_loss -0.4365 
2025-01-12 13:08:37.290319: val_loss -0.5507 
2025-01-12 13:08:37.295833: Pseudo dice [np.float32(0.6366)] 
2025-01-12 13:08:37.300346: Epoch time: 42.24 s 
2025-01-12 13:08:37.303355: Yayy! New best EMA pseudo Dice: 0.6110000014305115 
2025-01-12 13:08:37.983535:  
2025-01-12 13:08:37.984541: Epoch 3 
2025-01-12 13:08:37.989712: Current learning rate: 0.00995 
2025-01-12 13:09:20.249573: train_loss -0.5222 
2025-01-12 13:09:20.249573: val_loss -0.6443 
2025-01-12 13:09:20.255192: Pseudo dice [np.float32(0.7463)] 
2025-01-12 13:09:20.259854: Epoch time: 42.27 s 
2025-01-12 13:09:20.263010: Yayy! New best EMA pseudo Dice: 0.6244999766349792 
2025-01-12 13:09:20.911913:  
2025-01-12 13:09:20.911913: Epoch 4 
2025-01-12 13:09:20.917988: Current learning rate: 0.00993 
2025-01-12 13:10:03.180633: train_loss -0.5781 
2025-01-12 13:10:03.180633: val_loss -0.5098 
2025-01-12 13:10:03.187655: Pseudo dice [np.float32(0.5861)] 
2025-01-12 13:10:03.190663: Epoch time: 42.27 s 
2025-01-12 13:10:03.810560:  
2025-01-12 13:10:03.811063: Epoch 5 
2025-01-12 13:10:03.816073: Current learning rate: 0.00991 
2025-01-12 13:10:46.084921: train_loss -0.543 
2025-01-12 13:10:46.085428: val_loss -0.5853 
2025-01-12 13:10:46.090974: Pseudo dice [np.float32(0.6899)] 
2025-01-12 13:10:46.095981: Epoch time: 42.28 s 
2025-01-12 13:10:46.099488: Yayy! New best EMA pseudo Dice: 0.6276000142097473 
2025-01-12 13:10:46.756732:  
2025-01-12 13:10:46.757734: Epoch 6 
2025-01-12 13:10:46.761308: Current learning rate: 0.00989 
2025-01-12 13:11:29.024507: train_loss -0.543 
2025-01-12 13:11:29.024507: val_loss -0.583 
2025-01-12 13:11:29.030528: Pseudo dice [np.float32(0.6715)] 
2025-01-12 13:11:29.034539: Epoch time: 42.27 s 
2025-01-12 13:11:29.038051: Yayy! New best EMA pseudo Dice: 0.6320000290870667 
2025-01-12 13:11:29.704746:  
2025-01-12 13:11:29.704746: Epoch 7 
2025-01-12 13:11:29.710762: Current learning rate: 0.00987 
2025-01-12 13:12:12.151516: train_loss -0.5796 
2025-01-12 13:12:12.151516: val_loss -0.632 
2025-01-12 13:12:12.157587: Pseudo dice [np.float32(0.7258)] 
2025-01-12 13:12:12.161624: Epoch time: 42.45 s 
2025-01-12 13:12:12.164252: Yayy! New best EMA pseudo Dice: 0.6413999795913696 
2025-01-12 13:12:12.986485:  
2025-01-12 13:12:12.986988: Epoch 8 
2025-01-12 13:12:12.993004: Current learning rate: 0.00986 
2025-01-12 13:12:55.251061: train_loss -0.6115 
2025-01-12 13:12:55.251061: val_loss -0.6818 
2025-01-12 13:12:55.258585: Pseudo dice [np.float32(0.7531)] 
2025-01-12 13:12:55.263602: Epoch time: 42.27 s 
2025-01-12 13:12:55.267109: Yayy! New best EMA pseudo Dice: 0.6525999903678894 
2025-01-12 13:12:55.945333:  
2025-01-12 13:12:55.945333: Epoch 9 
2025-01-12 13:12:55.951357: Current learning rate: 0.00984 
2025-01-12 13:13:38.238106: train_loss -0.5784 
2025-01-12 13:13:38.238106: val_loss -0.6827 
2025-01-12 13:13:38.244703: Pseudo dice [np.float32(0.7598)] 
2025-01-12 13:13:38.248216: Epoch time: 42.29 s 
2025-01-12 13:13:38.254241: Yayy! New best EMA pseudo Dice: 0.6632999777793884 
2025-01-12 13:13:38.910230:  
2025-01-12 13:13:38.911233: Epoch 10 
2025-01-12 13:13:38.916311: Current learning rate: 0.00982 
2025-01-12 13:14:21.192908: train_loss -0.6149 
2025-01-12 13:14:21.192908: val_loss -0.6418 
2025-01-12 13:14:21.199429: Pseudo dice [np.float32(0.7224)] 
2025-01-12 13:14:21.202944: Epoch time: 42.28 s 
2025-01-12 13:14:21.206954: Yayy! New best EMA pseudo Dice: 0.6692000031471252 
2025-01-12 13:14:21.858823:  
2025-01-12 13:14:21.858823: Epoch 11 
2025-01-12 13:14:21.864401: Current learning rate: 0.0098 
2025-01-12 13:15:04.103900: train_loss -0.6277 
2025-01-12 13:15:04.104407: val_loss -0.7363 
2025-01-12 13:15:04.109972: Pseudo dice [np.float32(0.8037)] 
2025-01-12 13:15:04.113497: Epoch time: 42.25 s 
2025-01-12 13:15:04.116013: Yayy! New best EMA pseudo Dice: 0.6826000213623047 
2025-01-12 13:15:04.767185:  
2025-01-12 13:15:04.767185: Epoch 12 
2025-01-12 13:15:04.772743: Current learning rate: 0.00978 
2025-01-12 13:15:47.026101: train_loss -0.6295 
2025-01-12 13:15:47.026603: val_loss -0.7148 
2025-01-12 13:15:47.031613: Pseudo dice [np.float32(0.7901)] 
2025-01-12 13:15:47.036121: Epoch time: 42.26 s 
2025-01-12 13:15:47.039129: Yayy! New best EMA pseudo Dice: 0.6934000253677368 
2025-01-12 13:15:47.843337:  
2025-01-12 13:15:47.844336: Epoch 13 
2025-01-12 13:15:47.850003: Current learning rate: 0.00977 
2025-01-12 13:16:30.075104: train_loss -0.6176 
2025-01-12 13:16:30.075104: val_loss -0.71 
2025-01-12 13:16:30.080729: Pseudo dice [np.float32(0.7928)] 
2025-01-12 13:16:30.085299: Epoch time: 42.23 s 
2025-01-12 13:16:30.087849: Yayy! New best EMA pseudo Dice: 0.7032999992370605 
2025-01-12 13:16:30.745657:  
2025-01-12 13:16:30.746167: Epoch 14 
2025-01-12 13:16:30.751210: Current learning rate: 0.00975 
2025-01-12 13:17:12.953865: train_loss -0.6509 
2025-01-12 13:17:12.953865: val_loss -0.6246 
2025-01-12 13:17:12.960885: Pseudo dice [np.float32(0.7137)] 
2025-01-12 13:17:12.963894: Epoch time: 42.21 s 
2025-01-12 13:17:12.967437: Yayy! New best EMA pseudo Dice: 0.7044000029563904 
2025-01-12 13:17:13.624860:  
2025-01-12 13:17:13.624860: Epoch 15 
2025-01-12 13:17:13.630949: Current learning rate: 0.00973 
2025-01-12 13:17:55.652183: train_loss -0.6281 
2025-01-12 13:17:55.652183: val_loss -0.7327 
2025-01-12 13:17:55.659215: Pseudo dice [np.float32(0.7996)] 
2025-01-12 13:17:55.662726: Epoch time: 42.03 s 
2025-01-12 13:17:55.666738: Yayy! New best EMA pseudo Dice: 0.7139000296592712 
2025-01-12 13:17:56.325494:  
2025-01-12 13:17:56.325494: Epoch 16 
2025-01-12 13:17:56.331628: Current learning rate: 0.00971 
2025-01-12 13:18:38.356362: train_loss -0.6389 
2025-01-12 13:18:38.356865: val_loss -0.6542 
2025-01-12 13:18:38.362495: Pseudo dice [np.float32(0.7549)] 
2025-01-12 13:18:38.366073: Epoch time: 42.03 s 
2025-01-12 13:18:38.370194: Yayy! New best EMA pseudo Dice: 0.7179999947547913 
2025-01-12 13:18:39.051809:  
2025-01-12 13:18:39.052312: Epoch 17 
2025-01-12 13:18:39.057330: Current learning rate: 0.00969 
2025-01-12 13:19:21.067909: train_loss -0.6677 
2025-01-12 13:19:21.068909: val_loss -0.6919 
2025-01-12 13:19:21.074430: Pseudo dice [np.float32(0.7768)] 
2025-01-12 13:19:21.078941: Epoch time: 42.02 s 
2025-01-12 13:19:21.081950: Yayy! New best EMA pseudo Dice: 0.7239000201225281 
2025-01-12 13:19:21.744748:  
2025-01-12 13:19:21.745748: Epoch 18 
2025-01-12 13:19:21.751313: Current learning rate: 0.00968 
2025-01-12 13:20:03.792177: train_loss -0.6193 
2025-01-12 13:20:03.792685: val_loss -0.6911 
2025-01-12 13:20:03.798261: Pseudo dice [np.float32(0.7771)] 
2025-01-12 13:20:03.801811: Epoch time: 42.05 s 
2025-01-12 13:20:03.805824: Yayy! New best EMA pseudo Dice: 0.729200005531311 
2025-01-12 13:20:04.470831:  
2025-01-12 13:20:04.470831: Epoch 19 
2025-01-12 13:20:04.475845: Current learning rate: 0.00966 
2025-01-12 13:20:46.496927: train_loss -0.6421 
2025-01-12 13:20:46.497929: val_loss -0.7392 
2025-01-12 13:20:46.503454: Pseudo dice [np.float32(0.8088)] 
2025-01-12 13:20:46.508467: Epoch time: 42.03 s 
2025-01-12 13:20:46.510974: Yayy! New best EMA pseudo Dice: 0.7372000217437744 
2025-01-12 13:20:47.181492:  
2025-01-12 13:20:47.182498: Epoch 20 
2025-01-12 13:20:47.187060: Current learning rate: 0.00964 
2025-01-12 13:21:29.190016: train_loss -0.6482 
2025-01-12 13:21:29.191023: val_loss -0.7047 
2025-01-12 13:21:29.197032: Pseudo dice [np.float32(0.7615)] 
2025-01-12 13:21:29.201045: Epoch time: 42.01 s 
2025-01-12 13:21:29.204083: Yayy! New best EMA pseudo Dice: 0.7396000027656555 
2025-01-12 13:21:30.011726:  
2025-01-12 13:21:30.012235: Epoch 21 
2025-01-12 13:21:30.017309: Current learning rate: 0.00962 
2025-01-12 13:22:12.014188: train_loss -0.6524 
2025-01-12 13:22:12.014188: val_loss -0.667 
2025-01-12 13:22:12.020211: Pseudo dice [np.float32(0.7271)] 
2025-01-12 13:22:12.025223: Epoch time: 42.0 s 
2025-01-12 13:22:12.506236:  
2025-01-12 13:22:12.506236: Epoch 22 
2025-01-12 13:22:12.512345: Current learning rate: 0.0096 
2025-01-12 13:22:54.510546: train_loss -0.6698 
2025-01-12 13:22:54.512053: val_loss -0.6443 
2025-01-12 13:22:54.518074: Pseudo dice [np.float32(0.7259)] 
2025-01-12 13:22:54.521583: Epoch time: 42.0 s 
2025-01-12 13:22:55.008000:  
2025-01-12 13:22:55.008000: Epoch 23 
2025-01-12 13:22:55.014049: Current learning rate: 0.00959 
2025-01-12 13:23:36.994939: train_loss -0.6837 
2025-01-12 13:23:36.994939: val_loss -0.6737 
2025-01-12 13:23:37.000663: Pseudo dice [np.float32(0.7362)] 
2025-01-12 13:23:37.004174: Epoch time: 41.99 s 
2025-01-12 13:23:37.483963:  
2025-01-12 13:23:37.483963: Epoch 24 
2025-01-12 13:23:37.490036: Current learning rate: 0.00957 
2025-01-12 13:24:19.506867: train_loss -0.6669 
2025-01-12 13:24:19.507871: val_loss -0.6308 
2025-01-12 13:24:19.513942: Pseudo dice [np.float32(0.7229)] 
2025-01-12 13:24:19.517991: Epoch time: 42.02 s 
2025-01-12 13:24:19.998463:  
2025-01-12 13:24:19.999463: Epoch 25 
2025-01-12 13:24:20.005041: Current learning rate: 0.00955 
2025-01-12 13:25:02.016662: train_loss -0.6811 
2025-01-12 13:25:02.016662: val_loss -0.7142 
2025-01-12 13:25:02.022235: Pseudo dice [np.float32(0.7864)] 
2025-01-12 13:25:02.027885: Epoch time: 42.02 s 
2025-01-12 13:25:02.033460: Yayy! New best EMA pseudo Dice: 0.7407000064849854 
2025-01-12 13:25:02.872898:  
2025-01-12 13:25:02.872898: Epoch 26 
2025-01-12 13:25:02.877941: Current learning rate: 0.00953 
2025-01-12 13:25:44.888194: train_loss -0.684 
2025-01-12 13:25:44.889198: val_loss -0.7398 
2025-01-12 13:25:44.894274: Pseudo dice [np.float32(0.8018)] 
2025-01-12 13:25:44.898902: Epoch time: 42.02 s 
2025-01-12 13:25:44.902448: Yayy! New best EMA pseudo Dice: 0.7468000054359436 
2025-01-12 13:25:45.555616:  
2025-01-12 13:25:45.555616: Epoch 27 
2025-01-12 13:25:45.561147: Current learning rate: 0.00951 
2025-01-12 13:26:27.581588: train_loss -0.6691 
2025-01-12 13:26:27.581588: val_loss -0.6252 
2025-01-12 13:26:27.587601: Pseudo dice [np.float32(0.6917)] 
2025-01-12 13:26:27.591607: Epoch time: 42.03 s 
2025-01-12 13:26:28.079161:  
2025-01-12 13:26:28.079161: Epoch 28 
2025-01-12 13:26:28.084680: Current learning rate: 0.00949 
2025-01-12 13:27:10.104877: train_loss -0.6902 
2025-01-12 13:27:10.104877: val_loss -0.6794 
2025-01-12 13:27:10.111390: Pseudo dice [np.float32(0.735)] 
2025-01-12 13:27:10.114901: Epoch time: 42.03 s 
2025-01-12 13:27:10.741196:  
2025-01-12 13:27:10.742196: Epoch 29 
2025-01-12 13:27:10.746777: Current learning rate: 0.00948 
2025-01-12 13:27:52.733984: train_loss -0.6982 
2025-01-12 13:27:52.733984: val_loss -0.7457 
2025-01-12 13:27:52.740005: Pseudo dice [np.float32(0.7977)] 
2025-01-12 13:27:52.743011: Epoch time: 41.99 s 
2025-01-12 13:27:53.241640:  
2025-01-12 13:27:53.241640: Epoch 30 
2025-01-12 13:27:53.246656: Current learning rate: 0.00946 
2025-01-12 13:28:35.263454: train_loss -0.6905 
2025-01-12 13:28:35.263454: val_loss -0.7349 
2025-01-12 13:28:35.269466: Pseudo dice [np.float32(0.7948)] 
2025-01-12 13:28:35.273475: Epoch time: 42.02 s 
2025-01-12 13:28:35.276982: Yayy! New best EMA pseudo Dice: 0.7512000203132629 
2025-01-12 13:28:35.930502:  
2025-01-12 13:28:35.931505: Epoch 31 
2025-01-12 13:28:35.936053: Current learning rate: 0.00944 
2025-01-12 13:29:17.937582: train_loss -0.7349 
2025-01-12 13:29:17.938585: val_loss -0.7376 
2025-01-12 13:29:17.943595: Pseudo dice [np.float32(0.8044)] 
2025-01-12 13:29:17.947602: Epoch time: 42.01 s 
2025-01-12 13:29:17.952109: Yayy! New best EMA pseudo Dice: 0.7565000057220459 
2025-01-12 13:29:18.599151:  
2025-01-12 13:29:18.599151: Epoch 32 
2025-01-12 13:29:18.604282: Current learning rate: 0.00942 
2025-01-12 13:30:00.623566: train_loss -0.7047 
2025-01-12 13:30:00.623566: val_loss -0.5497 
2025-01-12 13:30:00.630584: Pseudo dice [np.float32(0.6487)] 
2025-01-12 13:30:00.635602: Epoch time: 42.03 s 
2025-01-12 13:30:01.130604:  
2025-01-12 13:30:01.131107: Epoch 33 
2025-01-12 13:30:01.136116: Current learning rate: 0.0094 
2025-01-12 13:30:43.155991: train_loss -0.6842 
2025-01-12 13:30:43.155991: val_loss -0.6986 
2025-01-12 13:30:43.162019: Pseudo dice [np.float32(0.7655)] 
2025-01-12 13:30:43.167044: Epoch time: 42.03 s 
2025-01-12 13:30:43.668005:  
2025-01-12 13:30:43.668507: Epoch 34 
2025-01-12 13:30:43.673519: Current learning rate: 0.00939 
2025-01-12 13:31:25.698515: train_loss -0.6772 
2025-01-12 13:31:25.698515: val_loss -0.6464 
2025-01-12 13:31:25.704543: Pseudo dice [np.float32(0.7091)] 
2025-01-12 13:31:25.708555: Epoch time: 42.03 s 
2025-01-12 13:31:26.209521:  
2025-01-12 13:31:26.209521: Epoch 35 
2025-01-12 13:31:26.215590: Current learning rate: 0.00937 
2025-01-12 13:32:08.240245: train_loss -0.7244 
2025-01-12 13:32:08.240768: val_loss -0.7114 
2025-01-12 13:32:08.246905: Pseudo dice [np.float32(0.7716)] 
2025-01-12 13:32:08.250991: Epoch time: 42.03 s 
2025-01-12 13:32:08.755835:  
2025-01-12 13:32:08.755835: Epoch 36 
2025-01-12 13:32:08.760853: Current learning rate: 0.00935 
2025-01-12 13:32:50.784639: train_loss -0.6988 
2025-01-12 13:32:50.784639: val_loss -0.7426 
2025-01-12 13:32:50.791163: Pseudo dice [np.float32(0.8116)] 
2025-01-12 13:32:50.794674: Epoch time: 42.03 s 
2025-01-12 13:32:51.433582:  
2025-01-12 13:32:51.434581: Epoch 37 
2025-01-12 13:32:51.439775: Current learning rate: 0.00933 
2025-01-12 13:33:33.455363: train_loss -0.6827 
2025-01-12 13:33:33.455363: val_loss -0.6259 
2025-01-12 13:33:33.461385: Pseudo dice [np.float32(0.7085)] 
2025-01-12 13:33:33.465401: Epoch time: 42.02 s 
2025-01-12 13:33:33.969651:  
2025-01-12 13:33:33.970155: Epoch 38 
2025-01-12 13:33:33.975174: Current learning rate: 0.00931 
2025-01-12 13:34:15.993819: train_loss -0.6997 
2025-01-12 13:34:15.993819: val_loss -0.6687 
2025-01-12 13:34:16.000459: Pseudo dice [np.float32(0.7442)] 
2025-01-12 13:34:16.003976: Epoch time: 42.03 s 
2025-01-12 13:34:16.508798:  
2025-01-12 13:34:16.508798: Epoch 39 
2025-01-12 13:34:16.514406: Current learning rate: 0.0093 
2025-01-12 13:34:58.522214: train_loss -0.728 
2025-01-12 13:34:58.522214: val_loss -0.7749 
2025-01-12 13:34:58.529739: Pseudo dice [np.float32(0.8187)] 
2025-01-12 13:34:58.533249: Epoch time: 42.01 s 
2025-01-12 13:34:59.049326:  
2025-01-12 13:34:59.049326: Epoch 40 
2025-01-12 13:34:59.054933: Current learning rate: 0.00928 
2025-01-12 13:35:41.047287: train_loss -0.7479 
2025-01-12 13:35:41.048798: val_loss -0.7081 
2025-01-12 13:35:41.053878: Pseudo dice [np.float32(0.7781)] 
2025-01-12 13:35:41.057488: Epoch time: 42.0 s 
2025-01-12 13:35:41.061037: Yayy! New best EMA pseudo Dice: 0.7574999928474426 
2025-01-12 13:35:41.753182:  
2025-01-12 13:35:41.753182: Epoch 41 
2025-01-12 13:35:41.758758: Current learning rate: 0.00926 
2025-01-12 13:36:23.742343: train_loss -0.746 
2025-01-12 13:36:23.743344: val_loss -0.6932 
2025-01-12 13:36:23.748869: Pseudo dice [np.float32(0.7645)] 
2025-01-12 13:36:23.752384: Epoch time: 41.99 s 
2025-01-12 13:36:23.756398: Yayy! New best EMA pseudo Dice: 0.7581999897956848 
2025-01-12 13:36:24.557696:  
2025-01-12 13:36:24.558201: Epoch 42 
2025-01-12 13:36:24.563216: Current learning rate: 0.00924 
2025-01-12 13:37:06.569517: train_loss -0.7386 
2025-01-12 13:37:06.570519: val_loss -0.6728 
2025-01-12 13:37:06.575532: Pseudo dice [np.float32(0.7638)] 
2025-01-12 13:37:06.579543: Epoch time: 42.01 s 
2025-01-12 13:37:06.583053: Yayy! New best EMA pseudo Dice: 0.7588000297546387 
2025-01-12 13:37:07.225384:  
2025-01-12 13:37:07.225384: Epoch 43 
2025-01-12 13:37:07.230952: Current learning rate: 0.00922 
2025-01-12 13:37:49.228109: train_loss -0.7379 
2025-01-12 13:37:49.229111: val_loss -0.7617 
2025-01-12 13:37:49.234631: Pseudo dice [np.float32(0.8129)] 
2025-01-12 13:37:49.238145: Epoch time: 42.0 s 
2025-01-12 13:37:49.242167: Yayy! New best EMA pseudo Dice: 0.76419997215271 
2025-01-12 13:37:49.896566:  
2025-01-12 13:37:49.896566: Epoch 44 
2025-01-12 13:37:49.901622: Current learning rate: 0.0092 
2025-01-12 13:38:31.919474: train_loss -0.7469 
2025-01-12 13:38:31.919976: val_loss -0.7299 
2025-01-12 13:38:31.925507: Pseudo dice [np.float32(0.7963)] 
2025-01-12 13:38:31.930538: Epoch time: 42.02 s 
2025-01-12 13:38:31.933722: Yayy! New best EMA pseudo Dice: 0.7674000263214111 
2025-01-12 13:38:32.759322:  
2025-01-12 13:38:32.759322: Epoch 45 
2025-01-12 13:38:32.764336: Current learning rate: 0.00919 
2025-01-12 13:39:14.772369: train_loss -0.7203 
2025-01-12 13:39:14.772369: val_loss -0.7262 
2025-01-12 13:39:14.778882: Pseudo dice [np.float32(0.7881)] 
2025-01-12 13:39:14.781391: Epoch time: 42.01 s 
2025-01-12 13:39:14.784961: Yayy! New best EMA pseudo Dice: 0.7695000171661377 
2025-01-12 13:39:15.435685:  
2025-01-12 13:39:15.435685: Epoch 46 
2025-01-12 13:39:15.440715: Current learning rate: 0.00917 
2025-01-12 13:39:57.462250: train_loss -0.7084 
2025-01-12 13:39:57.462250: val_loss -0.7591 
2025-01-12 13:39:57.468277: Pseudo dice [np.float32(0.8139)] 
2025-01-12 13:39:57.472287: Epoch time: 42.03 s 
2025-01-12 13:39:57.475795: Yayy! New best EMA pseudo Dice: 0.7738999724388123 
2025-01-12 13:39:58.126978:  
2025-01-12 13:39:58.126978: Epoch 47 
2025-01-12 13:39:58.134025: Current learning rate: 0.00915 
2025-01-12 13:40:40.140543: train_loss -0.7418 
2025-01-12 13:40:40.141049: val_loss -0.6461 
2025-01-12 13:40:40.146059: Pseudo dice [np.float32(0.7297)] 
2025-01-12 13:40:40.150565: Epoch time: 42.01 s 
2025-01-12 13:40:40.638643:  
2025-01-12 13:40:40.638643: Epoch 48 
2025-01-12 13:40:40.643788: Current learning rate: 0.00913 
2025-01-12 13:41:22.650205: train_loss -0.7378 
2025-01-12 13:41:22.650713: val_loss -0.7298 
2025-01-12 13:41:22.655736: Pseudo dice [np.float32(0.7512)] 
2025-01-12 13:41:22.659259: Epoch time: 42.01 s 
2025-01-12 13:41:23.151408:  
2025-01-12 13:41:23.151408: Epoch 49 
2025-01-12 13:41:23.156981: Current learning rate: 0.00911 
2025-01-12 13:42:05.158398: train_loss -0.7333 
2025-01-12 13:42:05.159403: val_loss -0.7174 
2025-01-12 13:42:05.164417: Pseudo dice [np.float32(0.7807)] 
2025-01-12 13:42:05.168422: Epoch time: 42.01 s 
2025-01-12 13:42:05.813315:  
2025-01-12 13:42:05.813315: Epoch 50 
2025-01-12 13:42:05.818830: Current learning rate: 0.0091 
2025-01-12 13:42:47.828432: train_loss -0.7195 
2025-01-12 13:42:47.828432: val_loss -0.6364 
2025-01-12 13:42:47.834461: Pseudo dice [np.float32(0.7162)] 
2025-01-12 13:42:47.838478: Epoch time: 42.02 s 
2025-01-12 13:42:48.327436:  
2025-01-12 13:42:48.328435: Epoch 51 
2025-01-12 13:42:48.334036: Current learning rate: 0.00908 
2025-01-12 13:43:30.345166: train_loss -0.7024 
2025-01-12 13:43:30.346170: val_loss -0.6413 
2025-01-12 13:43:30.351687: Pseudo dice [np.float32(0.7124)] 
2025-01-12 13:43:30.355201: Epoch time: 42.02 s 
2025-01-12 13:43:30.851191:  
2025-01-12 13:43:30.851711: Epoch 52 
2025-01-12 13:43:30.856781: Current learning rate: 0.00906 
2025-01-12 13:44:12.866443: train_loss -0.6931 
2025-01-12 13:44:12.866443: val_loss -0.7095 
2025-01-12 13:44:12.872452: Pseudo dice [np.float32(0.7847)] 
2025-01-12 13:44:12.876463: Epoch time: 42.02 s 
2025-01-12 13:44:13.510596:  
2025-01-12 13:44:13.510596: Epoch 53 
2025-01-12 13:44:13.515613: Current learning rate: 0.00904 
2025-01-12 13:44:55.522247: train_loss -0.7405 
2025-01-12 13:44:55.523246: val_loss -0.739 
2025-01-12 13:44:55.528766: Pseudo dice [np.float32(0.758)] 
2025-01-12 13:44:55.532278: Epoch time: 42.01 s 
2025-01-12 13:44:56.027795:  
2025-01-12 13:44:56.027795: Epoch 54 
2025-01-12 13:44:56.033946: Current learning rate: 0.00902 
2025-01-12 13:45:38.031249: train_loss -0.7359 
2025-01-12 13:45:38.031770: val_loss -0.6709 
2025-01-12 13:45:38.037358: Pseudo dice [np.float32(0.6986)] 
2025-01-12 13:45:38.041246: Epoch time: 42.0 s 
2025-01-12 13:45:38.535822:  
2025-01-12 13:45:38.535822: Epoch 55 
2025-01-12 13:45:38.541395: Current learning rate: 0.009 
2025-01-12 13:46:20.536948: train_loss -0.7506 
2025-01-12 13:46:20.537461: val_loss -0.7053 
2025-01-12 13:46:20.543634: Pseudo dice [np.float32(0.7666)] 
2025-01-12 13:46:20.547176: Epoch time: 42.0 s 
2025-01-12 13:46:21.047307:  
2025-01-12 13:46:21.047307: Epoch 56 
2025-01-12 13:46:21.052819: Current learning rate: 0.00899 
2025-01-12 13:47:03.072664: train_loss -0.7436 
2025-01-12 13:47:03.072664: val_loss -0.7357 
2025-01-12 13:47:03.079204: Pseudo dice [np.float32(0.7967)] 
2025-01-12 13:47:03.083224: Epoch time: 42.03 s 
2025-01-12 13:47:03.579937:  
2025-01-12 13:47:03.579937: Epoch 57 
2025-01-12 13:47:03.585484: Current learning rate: 0.00897 
2025-01-12 13:47:45.595059: train_loss -0.7501 
2025-01-12 13:47:45.595576: val_loss -0.7428 
2025-01-12 13:47:45.601235: Pseudo dice [np.float32(0.8024)] 
2025-01-12 13:47:45.605324: Epoch time: 42.02 s 
2025-01-12 13:47:46.098600:  
2025-01-12 13:47:46.098600: Epoch 58 
2025-01-12 13:47:46.102636: Current learning rate: 0.00895 
2025-01-12 13:48:28.136077: train_loss -0.7636 
2025-01-12 13:48:28.136601: val_loss -0.7137 
2025-01-12 13:48:28.141681: Pseudo dice [np.float32(0.7787)] 
2025-01-12 13:48:28.145236: Epoch time: 42.04 s 
2025-01-12 13:48:28.643291:  
2025-01-12 13:48:28.643291: Epoch 59 
2025-01-12 13:48:28.649401: Current learning rate: 0.00893 
2025-01-12 13:49:10.680554: train_loss -0.7717 
2025-01-12 13:49:10.681558: val_loss -0.7321 
2025-01-12 13:49:10.686873: Pseudo dice [np.float32(0.7946)] 
2025-01-12 13:49:10.690385: Epoch time: 42.04 s 
2025-01-12 13:49:11.195690:  
2025-01-12 13:49:11.196199: Epoch 60 
2025-01-12 13:49:11.201270: Current learning rate: 0.00891 
2025-01-12 13:49:53.272509: train_loss -0.771 
2025-01-12 13:49:53.273022: val_loss -0.7337 
2025-01-12 13:49:53.278173: Pseudo dice [np.float32(0.8056)] 
2025-01-12 13:49:53.282295: Epoch time: 42.08 s 
2025-01-12 13:49:53.784551:  
2025-01-12 13:49:53.785553: Epoch 61 
2025-01-12 13:49:53.790674: Current learning rate: 0.00889 
2025-01-12 13:50:35.814244: train_loss -0.7832 
2025-01-12 13:50:35.814244: val_loss -0.7027 
2025-01-12 13:50:35.820803: Pseudo dice [np.float32(0.7856)] 
2025-01-12 13:50:35.824318: Epoch time: 42.03 s 
2025-01-12 13:50:36.470684:  
2025-01-12 13:50:36.470684: Epoch 62 
2025-01-12 13:50:36.476785: Current learning rate: 0.00888 
2025-01-12 13:51:18.493464: train_loss -0.7791 
2025-01-12 13:51:18.493464: val_loss -0.776 
2025-01-12 13:51:18.498524: Pseudo dice [np.float32(0.8216)] 
2025-01-12 13:51:18.503589: Epoch time: 42.02 s 
2025-01-12 13:51:18.507726: Yayy! New best EMA pseudo Dice: 0.7784000039100647 
2025-01-12 13:51:19.172719:  
2025-01-12 13:51:19.172719: Epoch 63 
2025-01-12 13:51:19.178283: Current learning rate: 0.00886 
2025-01-12 13:52:01.209481: train_loss -0.8004 
2025-01-12 13:52:01.210987: val_loss -0.6692 
2025-01-12 13:52:01.217010: Pseudo dice [np.float32(0.7611)] 
2025-01-12 13:52:01.219529: Epoch time: 42.04 s 
2025-01-12 13:52:01.726044:  
2025-01-12 13:52:01.727048: Epoch 64 
2025-01-12 13:52:01.732599: Current learning rate: 0.00884 
2025-01-12 13:52:43.768281: train_loss -0.7954 
2025-01-12 13:52:43.768281: val_loss -0.7174 
2025-01-12 13:52:43.773856: Pseudo dice [np.float32(0.7585)] 
2025-01-12 13:52:43.779459: Epoch time: 42.04 s 
2025-01-12 13:52:44.286792:  
2025-01-12 13:52:44.287796: Epoch 65 
2025-01-12 13:52:44.292406: Current learning rate: 0.00882 
2025-01-12 13:53:26.297690: train_loss -0.768 
2025-01-12 13:53:26.297690: val_loss -0.7213 
2025-01-12 13:53:26.303714: Pseudo dice [np.float32(0.7849)] 
2025-01-12 13:53:26.307724: Epoch time: 42.01 s 
2025-01-12 13:53:26.813164:  
2025-01-12 13:53:26.813164: Epoch 66 
2025-01-12 13:53:26.818178: Current learning rate: 0.0088 
2025-01-12 13:54:08.888341: train_loss -0.7802 
2025-01-12 13:54:08.889341: val_loss -0.6728 
2025-01-12 13:54:08.894861: Pseudo dice [np.float32(0.7267)] 
2025-01-12 13:54:08.898379: Epoch time: 42.08 s 
2025-01-12 13:54:09.400849:  
2025-01-12 13:54:09.400849: Epoch 67 
2025-01-12 13:54:09.406081: Current learning rate: 0.00879 
2025-01-12 13:54:51.428154: train_loss -0.7787 
2025-01-12 13:54:51.428154: val_loss -0.695 
2025-01-12 13:54:51.434185: Pseudo dice [np.float32(0.7604)] 
2025-01-12 13:54:51.437697: Epoch time: 42.03 s 
2025-01-12 13:54:51.943992:  
2025-01-12 13:54:51.943992: Epoch 68 
2025-01-12 13:54:51.950023: Current learning rate: 0.00877 
2025-01-12 13:55:33.965113: train_loss -0.7394 
2025-01-12 13:55:33.965113: val_loss -0.6679 
2025-01-12 13:55:33.970654: Pseudo dice [np.float32(0.7287)] 
2025-01-12 13:55:33.975168: Epoch time: 42.02 s 
2025-01-12 13:55:34.488649:  
2025-01-12 13:55:34.489655: Epoch 69 
2025-01-12 13:55:34.494221: Current learning rate: 0.00875 
2025-01-12 13:56:16.489541: train_loss -0.735 
2025-01-12 13:56:16.489541: val_loss -0.7774 
2025-01-12 13:56:16.495068: Pseudo dice [np.float32(0.82)] 
2025-01-12 13:56:16.499078: Epoch time: 42.0 s 
2025-01-12 13:56:17.143564:  
2025-01-12 13:56:17.143564: Epoch 70 
2025-01-12 13:56:17.148626: Current learning rate: 0.00873 
2025-01-12 13:56:59.191608: train_loss -0.7535 
2025-01-12 13:56:59.192121: val_loss -0.6984 
2025-01-12 13:56:59.197742: Pseudo dice [np.float32(0.77)] 
2025-01-12 13:56:59.201783: Epoch time: 42.05 s 
2025-01-12 13:56:59.709436:  
2025-01-12 13:56:59.709436: Epoch 71 
2025-01-12 13:56:59.714967: Current learning rate: 0.00871 
2025-01-12 13:57:41.736892: train_loss -0.7285 
2025-01-12 13:57:41.736892: val_loss -0.6863 
2025-01-12 13:57:41.741910: Pseudo dice [np.float32(0.7568)] 
2025-01-12 13:57:41.746924: Epoch time: 42.03 s 
2025-01-12 13:57:42.254901:  
2025-01-12 13:57:42.254901: Epoch 72 
2025-01-12 13:57:42.260921: Current learning rate: 0.00869 
2025-01-12 13:58:24.285501: train_loss -0.7739 
2025-01-12 13:58:24.286022: val_loss -0.7543 
2025-01-12 13:58:24.291061: Pseudo dice [np.float32(0.8039)] 
2025-01-12 13:58:24.294149: Epoch time: 42.03 s 
2025-01-12 13:58:24.805589:  
2025-01-12 13:58:24.805589: Epoch 73 
2025-01-12 13:58:24.811148: Current learning rate: 0.00868 
2025-01-12 13:59:06.840950: train_loss -0.7738 
2025-01-12 13:59:06.841954: val_loss -0.7631 
2025-01-12 13:59:06.848505: Pseudo dice [np.float32(0.8149)] 
2025-01-12 13:59:06.853606: Epoch time: 42.04 s 
2025-01-12 13:59:07.363519:  
2025-01-12 13:59:07.363519: Epoch 74 
2025-01-12 13:59:07.369084: Current learning rate: 0.00866 
2025-01-12 13:59:49.378924: train_loss -0.7826 
2025-01-12 13:59:49.379927: val_loss -0.7102 
2025-01-12 13:59:49.385444: Pseudo dice [np.float32(0.7597)] 
2025-01-12 13:59:49.388953: Epoch time: 42.02 s 
2025-01-12 13:59:49.898673:  
2025-01-12 13:59:49.898673: Epoch 75 
2025-01-12 13:59:49.904213: Current learning rate: 0.00864 
2025-01-12 14:00:31.908746: train_loss -0.7623 
2025-01-12 14:00:31.908746: val_loss -0.714 
2025-01-12 14:00:31.914284: Pseudo dice [np.float32(0.7704)] 
2025-01-12 14:00:31.919293: Epoch time: 42.01 s 
2025-01-12 14:00:32.424815:  
2025-01-12 14:00:32.424815: Epoch 76 
2025-01-12 14:00:32.430836: Current learning rate: 0.00862 
2025-01-12 14:01:14.430579: train_loss -0.7746 
2025-01-12 14:01:14.430579: val_loss -0.7404 
2025-01-12 14:01:14.436599: Pseudo dice [np.float32(0.7816)] 
2025-01-12 14:01:14.440616: Epoch time: 42.01 s 
2025-01-12 14:01:14.952124:  
2025-01-12 14:01:14.952124: Epoch 77 
2025-01-12 14:01:14.957641: Current learning rate: 0.0086 
2025-01-12 14:01:57.030018: train_loss -0.7951 
2025-01-12 14:01:57.030018: val_loss -0.6687 
2025-01-12 14:01:57.035037: Pseudo dice [np.float32(0.7441)] 
2025-01-12 14:01:57.040054: Epoch time: 42.08 s 
2025-01-12 14:01:57.555422:  
2025-01-12 14:01:57.555422: Epoch 78 
2025-01-12 14:01:57.560945: Current learning rate: 0.00858 
2025-01-12 14:02:39.567393: train_loss -0.8104 
2025-01-12 14:02:39.567901: val_loss -0.6377 
2025-01-12 14:02:39.573985: Pseudo dice [np.float32(0.7253)] 
2025-01-12 14:02:39.577533: Epoch time: 42.01 s 
2025-01-12 14:02:40.094731:  
2025-01-12 14:02:40.094731: Epoch 79 
2025-01-12 14:02:40.099257: Current learning rate: 0.00857 
2025-01-12 14:03:22.093796: train_loss -0.8007 
2025-01-12 14:03:22.093796: val_loss -0.6234 
2025-01-12 14:03:22.099432: Pseudo dice [np.float32(0.7009)] 
2025-01-12 14:03:22.103019: Epoch time: 42.0 s 
2025-01-12 14:03:22.618849:  
2025-01-12 14:03:22.618849: Epoch 80 
2025-01-12 14:03:22.624418: Current learning rate: 0.00855 
2025-01-12 14:04:04.618362: train_loss -0.7976 
2025-01-12 14:04:04.618362: val_loss -0.6411 
2025-01-12 14:04:04.624378: Pseudo dice [np.float32(0.7178)] 
2025-01-12 14:04:04.628390: Epoch time: 42.0 s 
2025-01-12 14:04:05.143109:  
2025-01-12 14:04:05.144110: Epoch 81 
2025-01-12 14:04:05.149184: Current learning rate: 0.00853 
2025-01-12 14:04:47.143487: train_loss -0.7986 
2025-01-12 14:04:47.144000: val_loss -0.7178 
2025-01-12 14:04:47.149553: Pseudo dice [np.float32(0.7921)] 
2025-01-12 14:04:47.153078: Epoch time: 42.0 s 
2025-01-12 14:04:47.668840:  
2025-01-12 14:04:47.669843: Epoch 82 
2025-01-12 14:04:47.674403: Current learning rate: 0.00851 
2025-01-12 14:05:29.659379: train_loss -0.7688 
2025-01-12 14:05:29.660379: val_loss -0.7489 
2025-01-12 14:05:29.665908: Pseudo dice [np.float32(0.811)] 
2025-01-12 14:05:29.670416: Epoch time: 41.99 s 
2025-01-12 14:05:30.157916:  
2025-01-12 14:05:30.158918: Epoch 83 
2025-01-12 14:05:30.163474: Current learning rate: 0.00849 
2025-01-12 14:06:12.180336: train_loss -0.7844 
2025-01-12 14:06:12.180848: val_loss -0.7133 
2025-01-12 14:06:12.186473: Pseudo dice [np.float32(0.7685)] 
2025-01-12 14:06:12.189518: Epoch time: 42.02 s 
2025-01-12 14:06:12.680993:  
2025-01-12 14:06:12.681997: Epoch 84 
2025-01-12 14:06:12.686571: Current learning rate: 0.00847 
2025-01-12 14:06:54.686627: train_loss -0.7602 
2025-01-12 14:06:54.687634: val_loss -0.6976 
2025-01-12 14:06:54.692648: Pseudo dice [np.float32(0.7516)] 
2025-01-12 14:06:54.696655: Epoch time: 42.01 s 
2025-01-12 14:06:55.323221:  
2025-01-12 14:06:55.323221: Epoch 85 
2025-01-12 14:06:55.328753: Current learning rate: 0.00846 
2025-01-12 14:07:37.354245: train_loss -0.7803 
2025-01-12 14:07:37.354245: val_loss -0.7356 
2025-01-12 14:07:37.359276: Pseudo dice [np.float32(0.8063)] 
2025-01-12 14:07:37.364304: Epoch time: 42.03 s 
2025-01-12 14:07:37.854151:  
2025-01-12 14:07:37.854151: Epoch 86 
2025-01-12 14:07:37.859703: Current learning rate: 0.00844 
2025-01-12 14:08:19.859418: train_loss -0.7902 
2025-01-12 14:08:19.859922: val_loss -0.691 
2025-01-12 14:08:19.864942: Pseudo dice [np.float32(0.765)] 
2025-01-12 14:08:19.869450: Epoch time: 42.01 s 
2025-01-12 14:08:20.361154:  
2025-01-12 14:08:20.361154: Epoch 87 
2025-01-12 14:08:20.366178: Current learning rate: 0.00842 
2025-01-12 14:09:02.358639: train_loss -0.7647 
2025-01-12 14:09:02.359163: val_loss -0.513 
2025-01-12 14:09:02.366292: Pseudo dice [np.float32(0.5591)] 
2025-01-12 14:09:02.371851: Epoch time: 42.0 s 
2025-01-12 14:09:02.860787:  
2025-01-12 14:09:02.860787: Epoch 88 
2025-01-12 14:09:02.866330: Current learning rate: 0.0084 
2025-01-12 14:09:44.863962: train_loss -0.738 
2025-01-12 14:09:44.863962: val_loss -0.6946 
2025-01-12 14:09:44.870023: Pseudo dice [np.float32(0.7784)] 
2025-01-12 14:09:44.873605: Epoch time: 42.0 s 
2025-01-12 14:09:45.363163:  
2025-01-12 14:09:45.363163: Epoch 89 
2025-01-12 14:09:45.368172: Current learning rate: 0.00838 
2025-01-12 14:10:27.380906: train_loss -0.7696 
2025-01-12 14:10:27.381911: val_loss -0.7591 
2025-01-12 14:10:27.387926: Pseudo dice [np.float32(0.7954)] 
2025-01-12 14:10:27.391942: Epoch time: 42.02 s 
2025-01-12 14:10:27.886272:  
2025-01-12 14:10:27.886272: Epoch 90 
2025-01-12 14:10:27.892955: Current learning rate: 0.00836 
2025-01-12 14:11:09.889727: train_loss -0.7907 
2025-01-12 14:11:09.889727: val_loss -0.7446 
2025-01-12 14:11:09.896288: Pseudo dice [np.float32(0.8086)] 
2025-01-12 14:11:09.901314: Epoch time: 42.0 s 
2025-01-12 14:11:10.393073:  
2025-01-12 14:11:10.393073: Epoch 91 
2025-01-12 14:11:10.399084: Current learning rate: 0.00835 
2025-01-12 14:11:52.404374: train_loss -0.8236 
2025-01-12 14:11:52.405375: val_loss -0.6848 
2025-01-12 14:11:52.411895: Pseudo dice [np.float32(0.7585)] 
2025-01-12 14:11:52.418407: Epoch time: 42.01 s 
2025-01-12 14:11:52.906088:  
2025-01-12 14:11:52.907094: Epoch 92 
2025-01-12 14:11:52.912659: Current learning rate: 0.00833 
2025-01-12 14:12:34.924697: train_loss -0.8058 
2025-01-12 14:12:34.926209: val_loss -0.7325 
2025-01-12 14:12:34.932293: Pseudo dice [np.float32(0.7895)] 
2025-01-12 14:12:34.936936: Epoch time: 42.02 s 
2025-01-12 14:12:35.432069:  
2025-01-12 14:12:35.432069: Epoch 93 
2025-01-12 14:12:35.438132: Current learning rate: 0.00831 
2025-01-12 14:13:17.441189: train_loss -0.8147 
2025-01-12 14:13:17.441189: val_loss -0.7383 
2025-01-12 14:13:17.448204: Pseudo dice [np.float32(0.7861)] 
2025-01-12 14:13:17.452214: Epoch time: 42.01 s 
2025-01-12 14:13:18.094042:  
2025-01-12 14:13:18.094042: Epoch 94 
2025-01-12 14:13:18.100082: Current learning rate: 0.00829 
2025-01-12 14:14:00.130310: train_loss -0.807 
2025-01-12 14:14:00.130814: val_loss -0.7306 
2025-01-12 14:14:00.136833: Pseudo dice [np.float32(0.7793)] 
2025-01-12 14:14:00.141849: Epoch time: 42.04 s 
2025-01-12 14:14:00.636191:  
2025-01-12 14:14:00.636191: Epoch 95 
2025-01-12 14:14:00.642738: Current learning rate: 0.00827 
2025-01-12 14:14:42.677402: train_loss -0.6983 
2025-01-12 14:14:42.678405: val_loss -0.6997 
2025-01-12 14:14:42.686014: Pseudo dice [np.float32(0.76)] 
2025-01-12 14:14:42.692132: Epoch time: 42.04 s 
2025-01-12 14:14:43.187493:  
2025-01-12 14:14:43.187493: Epoch 96 
2025-01-12 14:14:43.194545: Current learning rate: 0.00825 
2025-01-12 14:15:25.225325: train_loss -0.7586 
2025-01-12 14:15:25.225325: val_loss -0.64 
2025-01-12 14:15:25.232869: Pseudo dice [np.float32(0.7206)] 
2025-01-12 14:15:25.238853: Epoch time: 42.04 s 
2025-01-12 14:15:25.741169:  
2025-01-12 14:15:25.741169: Epoch 97 
2025-01-12 14:15:25.748182: Current learning rate: 0.00824 
2025-01-12 14:16:07.761515: train_loss -0.7876 
2025-01-12 14:16:07.761515: val_loss -0.702 
2025-01-12 14:16:07.770150: Pseudo dice [np.float32(0.7583)] 
2025-01-12 14:16:07.775725: Epoch time: 42.02 s 
2025-01-12 14:16:08.281719:  
2025-01-12 14:16:08.281719: Epoch 98 
2025-01-12 14:16:08.287735: Current learning rate: 0.00822 
2025-01-12 14:16:50.315287: train_loss -0.7747 
2025-01-12 14:16:50.315287: val_loss -0.7924 
2025-01-12 14:16:50.322809: Pseudo dice [np.float32(0.817)] 
2025-01-12 14:16:50.328826: Epoch time: 42.03 s 
2025-01-12 14:16:50.831830:  
2025-01-12 14:16:50.832836: Epoch 99 
2025-01-12 14:16:50.838869: Current learning rate: 0.0082 
2025-01-12 14:17:32.842630: train_loss -0.802 
2025-01-12 14:17:32.843630: val_loss -0.6834 
2025-01-12 14:17:32.850184: Pseudo dice [np.float32(0.7597)] 
2025-01-12 14:17:32.855198: Epoch time: 42.01 s 
2025-01-12 14:17:33.522286:  
2025-01-12 14:17:33.523291: Epoch 100 
2025-01-12 14:17:33.527322: Current learning rate: 0.00818 
2025-01-12 14:18:15.540619: train_loss -0.7975 
2025-01-12 14:18:15.540619: val_loss -0.6677 
2025-01-12 14:18:15.546632: Pseudo dice [np.float32(0.7466)] 
2025-01-12 14:18:15.551642: Epoch time: 42.02 s 
2025-01-12 14:18:16.054239:  
2025-01-12 14:18:16.054239: Epoch 101 
2025-01-12 14:18:16.060780: Current learning rate: 0.00816 
2025-01-12 14:18:58.077839: train_loss -0.8222 
2025-01-12 14:18:58.078349: val_loss -0.6753 
2025-01-12 14:18:58.084150: Pseudo dice [np.float32(0.7641)] 
2025-01-12 14:18:58.089174: Epoch time: 42.02 s 
2025-01-12 14:18:58.728898:  
2025-01-12 14:18:58.728898: Epoch 102 
2025-01-12 14:18:58.735428: Current learning rate: 0.00814 
2025-01-12 14:19:40.741483: train_loss -0.8217 
2025-01-12 14:19:40.741483: val_loss -0.6752 
2025-01-12 14:19:40.748999: Pseudo dice [np.float32(0.7561)] 
2025-01-12 14:19:40.754012: Epoch time: 42.01 s 
2025-01-12 14:19:41.252129:  
2025-01-12 14:19:41.253133: Epoch 103 
2025-01-12 14:19:41.259246: Current learning rate: 0.00813 
2025-01-12 14:20:23.256132: train_loss -0.8156 
2025-01-12 14:20:23.256132: val_loss -0.7235 
2025-01-12 14:20:23.263659: Pseudo dice [np.float32(0.7384)] 
2025-01-12 14:20:23.270184: Epoch time: 42.0 s 
2025-01-12 14:20:23.777941:  
2025-01-12 14:20:23.777941: Epoch 104 
2025-01-12 14:20:23.783965: Current learning rate: 0.00811 
2025-01-12 14:21:05.793991: train_loss -0.776 
2025-01-12 14:21:05.794497: val_loss -0.7584 
2025-01-12 14:21:05.801519: Pseudo dice [np.float32(0.8137)] 
2025-01-12 14:21:05.807036: Epoch time: 42.02 s 
2025-01-12 14:21:06.309798:  
2025-01-12 14:21:06.310800: Epoch 105 
2025-01-12 14:21:06.316841: Current learning rate: 0.00809 
2025-01-12 14:21:48.323238: train_loss -0.7848 
2025-01-12 14:21:48.323238: val_loss -0.6083 
2025-01-12 14:21:48.330260: Pseudo dice [np.float32(0.7198)] 
2025-01-12 14:21:48.334789: Epoch time: 42.01 s 
2025-01-12 14:21:48.835986:  
2025-01-12 14:21:48.836490: Epoch 106 
2025-01-12 14:21:48.842508: Current learning rate: 0.00807 
2025-01-12 14:22:30.847997: train_loss -0.7681 
2025-01-12 14:22:30.847997: val_loss -0.6962 
2025-01-12 14:22:30.856033: Pseudo dice [np.float32(0.7802)] 
2025-01-12 14:22:30.861046: Epoch time: 42.01 s 
2025-01-12 14:22:31.365180:  
2025-01-12 14:22:31.365180: Epoch 107 
2025-01-12 14:22:31.371201: Current learning rate: 0.00805 
2025-01-12 14:23:13.383094: train_loss -0.7972 
2025-01-12 14:23:13.383596: val_loss -0.7051 
2025-01-12 14:23:13.389672: Pseudo dice [np.float32(0.7765)] 
2025-01-12 14:23:13.394286: Epoch time: 42.02 s 
2025-01-12 14:23:13.895394:  
2025-01-12 14:23:13.895903: Epoch 108 
2025-01-12 14:23:13.902091: Current learning rate: 0.00803 
2025-01-12 14:23:55.903573: train_loss -0.8025 
2025-01-12 14:23:55.904086: val_loss -0.6917 
2025-01-12 14:23:55.910634: Pseudo dice [np.float32(0.7687)] 
2025-01-12 14:23:55.916257: Epoch time: 42.01 s 
2025-01-12 14:23:56.419197:  
2025-01-12 14:23:56.419197: Epoch 109 
2025-01-12 14:23:56.425794: Current learning rate: 0.00801 
2025-01-12 14:24:38.456365: train_loss -0.7843 
2025-01-12 14:24:38.457368: val_loss -0.7473 
2025-01-12 14:24:38.463971: Pseudo dice [np.float32(0.8153)] 
2025-01-12 14:24:38.469033: Epoch time: 42.04 s 
2025-01-12 14:24:39.111191:  
2025-01-12 14:24:39.112189: Epoch 110 
2025-01-12 14:24:39.117767: Current learning rate: 0.008 
2025-01-12 14:25:21.099416: train_loss -0.7904 
2025-01-12 14:25:21.099416: val_loss -0.6619 
2025-01-12 14:25:21.106043: Pseudo dice [np.float32(0.7323)] 
2025-01-12 14:25:21.111668: Epoch time: 41.99 s 
2025-01-12 14:25:21.612374:  
2025-01-12 14:25:21.612877: Epoch 111 
2025-01-12 14:25:21.618894: Current learning rate: 0.00798 
2025-01-12 14:26:03.625739: train_loss -0.7807 
2025-01-12 14:26:03.626246: val_loss -0.7625 
2025-01-12 14:26:03.634914: Pseudo dice [np.float32(0.8114)] 
2025-01-12 14:26:03.641559: Epoch time: 42.01 s 
2025-01-12 14:26:04.144682:  
2025-01-12 14:26:04.145187: Epoch 112 
2025-01-12 14:26:04.150207: Current learning rate: 0.00796 
2025-01-12 14:26:46.145892: train_loss -0.7902 
2025-01-12 14:26:46.146396: val_loss -0.6592 
2025-01-12 14:26:46.152926: Pseudo dice [np.float32(0.739)] 
2025-01-12 14:26:46.158030: Epoch time: 42.0 s 
2025-01-12 14:26:46.669705:  
2025-01-12 14:26:46.670709: Epoch 113 
2025-01-12 14:26:46.675267: Current learning rate: 0.00794 
2025-01-12 14:27:28.657825: train_loss -0.8066 
2025-01-12 14:27:28.658327: val_loss -0.6429 
2025-01-12 14:27:28.665381: Pseudo dice [np.float32(0.7271)] 
2025-01-12 14:27:28.670046: Epoch time: 41.99 s 
2025-01-12 14:27:29.164983:  
2025-01-12 14:27:29.164983: Epoch 114 
2025-01-12 14:27:29.171005: Current learning rate: 0.00792 
2025-01-12 14:28:11.191230: train_loss -0.8245 
2025-01-12 14:28:11.192232: val_loss -0.7602 
2025-01-12 14:28:11.198750: Pseudo dice [np.float32(0.8)] 
2025-01-12 14:28:11.203764: Epoch time: 42.03 s 
2025-01-12 14:28:11.700789:  
2025-01-12 14:28:11.700789: Epoch 115 
2025-01-12 14:28:11.707344: Current learning rate: 0.0079 
2025-01-12 14:28:53.703101: train_loss -0.8202 
2025-01-12 14:28:53.703617: val_loss -0.7204 
2025-01-12 14:28:53.710161: Pseudo dice [np.float32(0.7753)] 
2025-01-12 14:28:53.715177: Epoch time: 42.0 s 
2025-01-12 14:28:54.214865:  
2025-01-12 14:28:54.215864: Epoch 116 
2025-01-12 14:28:54.221473: Current learning rate: 0.00789 
2025-01-12 14:29:36.194670: train_loss -0.8189 
2025-01-12 14:29:36.195172: val_loss -0.7178 
2025-01-12 14:29:36.201185: Pseudo dice [np.float32(0.7813)] 
2025-01-12 14:29:36.206698: Epoch time: 41.98 s 
2025-01-12 14:29:36.712269:  
2025-01-12 14:29:36.712269: Epoch 117 
2025-01-12 14:29:36.717818: Current learning rate: 0.00787 
2025-01-12 14:30:18.736853: train_loss -0.8247 
2025-01-12 14:30:18.736853: val_loss -0.7583 
2025-01-12 14:30:18.742419: Pseudo dice [np.float32(0.8103)] 
2025-01-12 14:30:18.747446: Epoch time: 42.03 s 
2025-01-12 14:30:19.393797:  
2025-01-12 14:30:19.393797: Epoch 118 
2025-01-12 14:30:19.398310: Current learning rate: 0.00785 
2025-01-12 14:31:01.406074: train_loss -0.8072 
2025-01-12 14:31:01.406578: val_loss -0.709 
2025-01-12 14:31:01.412162: Pseudo dice [np.float32(0.7672)] 
2025-01-12 14:31:01.416225: Epoch time: 42.01 s 
2025-01-12 14:31:01.922743:  
2025-01-12 14:31:01.922743: Epoch 119 
2025-01-12 14:31:01.928760: Current learning rate: 0.00783 
2025-01-12 14:31:43.928801: train_loss -0.7877 
2025-01-12 14:31:43.929804: val_loss -0.6978 
2025-01-12 14:31:43.935819: Pseudo dice [np.float32(0.7627)] 
2025-01-12 14:31:43.939829: Epoch time: 42.01 s 
2025-01-12 14:31:44.441142:  
2025-01-12 14:31:44.442142: Epoch 120 
2025-01-12 14:31:44.447155: Current learning rate: 0.00781 
2025-01-12 14:32:26.437587: train_loss -0.7664 
2025-01-12 14:32:26.438088: val_loss -0.7559 
2025-01-12 14:32:26.443099: Pseudo dice [np.float32(0.8062)] 
2025-01-12 14:32:26.447608: Epoch time: 42.0 s 
2025-01-12 14:32:26.953874:  
2025-01-12 14:32:26.953874: Epoch 121 
2025-01-12 14:32:26.959909: Current learning rate: 0.00779 
2025-01-12 14:33:08.964599: train_loss -0.7947 
2025-01-12 14:33:08.964599: val_loss -0.7201 
2025-01-12 14:33:08.972124: Pseudo dice [np.float32(0.7775)] 
2025-01-12 14:33:08.976636: Epoch time: 42.01 s 
2025-01-12 14:33:09.476658:  
2025-01-12 14:33:09.476658: Epoch 122 
2025-01-12 14:33:09.482191: Current learning rate: 0.00777 
2025-01-12 14:33:51.490119: train_loss -0.816 
2025-01-12 14:33:51.490119: val_loss -0.6332 
2025-01-12 14:33:51.496686: Pseudo dice [np.float32(0.7345)] 
2025-01-12 14:33:51.500803: Epoch time: 42.01 s 
2025-01-12 14:33:52.008804:  
2025-01-12 14:33:52.008804: Epoch 123 
2025-01-12 14:33:52.012868: Current learning rate: 0.00776 
2025-01-12 14:34:39.643366: train_loss -0.7802 
2025-01-12 14:34:39.643366: val_loss -0.7164 
2025-01-12 14:34:39.648379: Pseudo dice [np.float32(0.7753)] 
2025-01-12 14:34:39.653392: Epoch time: 47.63 s 
2025-01-12 14:34:40.189974:  
2025-01-12 14:34:40.189974: Epoch 124 
2025-01-12 14:34:40.195486: Current learning rate: 0.00774 
2025-01-12 14:35:23.539738: train_loss -0.8105 
2025-01-12 14:35:23.539738: val_loss -0.7116 
2025-01-12 14:35:23.545762: Pseudo dice [np.float32(0.7767)] 
2025-01-12 14:35:23.548270: Epoch time: 43.35 s 
2025-01-12 14:35:24.164721:  
2025-01-12 14:35:24.165720: Epoch 125 
2025-01-12 14:35:24.171346: Current learning rate: 0.00772 
2025-01-12 14:36:07.652265: train_loss -0.753 
2025-01-12 14:36:07.652265: val_loss -0.6178 
2025-01-12 14:36:07.658288: Pseudo dice [np.float32(0.7188)] 
2025-01-12 14:36:07.662299: Epoch time: 43.49 s 
2025-01-12 14:36:08.411660:  
2025-01-12 14:36:08.411660: Epoch 126 
2025-01-12 14:36:08.416693: Current learning rate: 0.0077 
2025-01-12 14:36:51.920224: train_loss -0.7797 
2025-01-12 14:36:51.921730: val_loss -0.7819 
2025-01-12 14:36:51.927750: Pseudo dice [np.float32(0.8302)] 
2025-01-12 14:36:51.930259: Epoch time: 43.51 s 
2025-01-12 14:36:52.509589:  
2025-01-12 14:36:52.510589: Epoch 127 
2025-01-12 14:36:52.513640: Current learning rate: 0.00768 
2025-01-12 14:37:36.306807: train_loss -0.7863 
2025-01-12 14:37:36.306807: val_loss -0.6686 
2025-01-12 14:37:36.313359: Pseudo dice [np.float32(0.7207)] 
2025-01-12 14:37:36.316367: Epoch time: 43.8 s 
2025-01-12 14:37:36.910097:  
2025-01-12 14:37:36.910097: Epoch 128 
2025-01-12 14:37:36.916123: Current learning rate: 0.00766 
2025-01-12 14:38:20.494393: train_loss -0.7978 
2025-01-12 14:38:20.494896: val_loss -0.6333 
2025-01-12 14:38:20.499909: Pseudo dice [np.float32(0.6786)] 
2025-01-12 14:38:20.503421: Epoch time: 43.59 s 
2025-01-12 14:38:21.078970:  
2025-01-12 14:38:21.079973: Epoch 129 
2025-01-12 14:38:21.084639: Current learning rate: 0.00764 
2025-01-12 14:39:04.738213: train_loss -0.8043 
2025-01-12 14:39:04.738715: val_loss -0.7189 
2025-01-12 14:39:04.744311: Pseudo dice [np.float32(0.7533)] 
2025-01-12 14:39:04.747350: Epoch time: 43.66 s 
2025-01-12 14:39:05.322366:  
2025-01-12 14:39:05.323366: Epoch 130 
2025-01-12 14:39:05.328459: Current learning rate: 0.00763 
2025-01-12 14:39:48.062696: train_loss -0.7943 
2025-01-12 14:39:48.062696: val_loss -0.643 
2025-01-12 14:39:48.069210: Pseudo dice [np.float32(0.7249)] 
2025-01-12 14:39:48.072720: Epoch time: 42.74 s 
2025-01-12 14:39:48.657032:  
2025-01-12 14:39:48.657032: Epoch 131 
2025-01-12 14:39:48.662084: Current learning rate: 0.00761 
2025-01-12 14:40:31.088921: train_loss -0.787 
2025-01-12 14:40:31.089922: val_loss -0.7745 
2025-01-12 14:40:31.095437: Pseudo dice [np.float32(0.8147)] 
2025-01-12 14:40:31.098947: Epoch time: 42.43 s 
2025-01-12 14:40:31.679580:  
2025-01-12 14:40:31.679580: Epoch 132 
2025-01-12 14:40:31.684591: Current learning rate: 0.00759 
2025-01-12 14:41:14.095366: train_loss -0.7726 
2025-01-12 14:41:14.095925: val_loss -0.7017 
2025-01-12 14:41:14.103540: Pseudo dice [np.float32(0.7508)] 
2025-01-12 14:41:14.107087: Epoch time: 42.42 s 
2025-01-12 14:41:14.683528:  
2025-01-12 14:41:14.683528: Epoch 133 
2025-01-12 14:41:14.688539: Current learning rate: 0.00757 
2025-01-12 14:41:57.178485: train_loss -0.7839 
2025-01-12 14:41:57.179484: val_loss -0.6953 
2025-01-12 14:41:57.183501: Pseudo dice [np.float32(0.7677)] 
2025-01-12 14:41:57.186007: Epoch time: 42.5 s 
2025-01-12 14:41:57.768268:  
2025-01-12 14:41:57.768268: Epoch 134 
2025-01-12 14:41:57.773279: Current learning rate: 0.00755 
2025-01-12 14:42:40.535961: train_loss -0.7794 
2025-01-12 14:42:40.536465: val_loss -0.668 
2025-01-12 14:42:40.541485: Pseudo dice [np.float32(0.7434)] 
2025-01-12 14:42:40.544997: Epoch time: 42.77 s 
2025-01-12 14:42:41.154897:  
2025-01-12 14:42:41.154897: Epoch 135 
2025-01-12 14:42:41.159941: Current learning rate: 0.00753 
2025-01-12 14:43:23.959402: train_loss -0.8209 
2025-01-12 14:43:23.959909: val_loss -0.7271 
2025-01-12 14:43:23.965530: Pseudo dice [np.float32(0.7813)] 
2025-01-12 14:43:23.969717: Epoch time: 42.81 s 
2025-01-12 14:43:24.522183:  
2025-01-12 14:43:24.522686: Epoch 136 
2025-01-12 14:43:24.526196: Current learning rate: 0.00751 
2025-01-12 14:44:07.137063: train_loss -0.8274 
2025-01-12 14:44:07.138081: val_loss -0.7508 
2025-01-12 14:44:07.143261: Pseudo dice [np.float32(0.79)] 
2025-01-12 14:44:07.146291: Epoch time: 42.62 s 
2025-01-12 14:44:07.723049:  
2025-01-12 14:44:07.724053: Epoch 137 
2025-01-12 14:44:07.729916: Current learning rate: 0.0075 
2025-01-12 14:44:50.954221: train_loss -0.8118 
2025-01-12 14:44:50.954221: val_loss -0.6201 
2025-01-12 14:44:50.959236: Pseudo dice [np.float32(0.687)] 
2025-01-12 14:44:50.961746: Epoch time: 43.23 s 
2025-01-12 14:44:51.550539:  
2025-01-12 14:44:51.551539: Epoch 138 
2025-01-12 14:44:51.557089: Current learning rate: 0.00748 
2025-01-12 14:45:34.464390: train_loss -0.8094 
2025-01-12 14:45:34.464390: val_loss -0.7152 
2025-01-12 14:45:34.470932: Pseudo dice [np.float32(0.7899)] 
2025-01-12 14:45:34.473953: Epoch time: 42.91 s 
2025-01-12 14:45:35.077179:  
2025-01-12 14:45:35.078707: Epoch 139 
2025-01-12 14:45:35.083396: Current learning rate: 0.00746 
2025-01-12 14:46:18.246220: train_loss -0.8241 
2025-01-12 14:46:18.246723: val_loss -0.6966 
2025-01-12 14:46:18.254242: Pseudo dice [np.float32(0.7529)] 
2025-01-12 14:46:18.259260: Epoch time: 43.17 s 
2025-01-12 14:46:18.849512:  
2025-01-12 14:46:18.850023: Epoch 140 
2025-01-12 14:46:18.855167: Current learning rate: 0.00744 
2025-01-12 14:47:01.859597: train_loss -0.8207 
2025-01-12 14:47:01.860101: val_loss -0.6932 
2025-01-12 14:47:01.864619: Pseudo dice [np.float32(0.7806)] 
2025-01-12 14:47:01.868805: Epoch time: 43.01 s 
2025-01-12 14:47:02.461117:  
2025-01-12 14:47:02.461117: Epoch 141 
2025-01-12 14:47:02.465235: Current learning rate: 0.00742 
2025-01-12 14:47:45.838410: train_loss -0.8394 
2025-01-12 14:47:45.838410: val_loss -0.7216 
2025-01-12 14:47:45.844058: Pseudo dice [np.float32(0.7847)] 
2025-01-12 14:47:45.846723: Epoch time: 43.38 s 
2025-01-12 14:47:46.587392:  
2025-01-12 14:47:46.587392: Epoch 142 
2025-01-12 14:47:46.592403: Current learning rate: 0.0074 
2025-01-12 14:48:29.448210: train_loss -0.8261 
2025-01-12 14:48:29.449214: val_loss -0.7887 
2025-01-12 14:48:29.454228: Pseudo dice [np.float32(0.8331)] 
2025-01-12 14:48:29.458241: Epoch time: 42.86 s 
2025-01-12 14:48:30.042988:  
2025-01-12 14:48:30.042988: Epoch 143 
2025-01-12 14:48:30.048005: Current learning rate: 0.00738 
2025-01-12 14:49:13.024632: train_loss -0.8288 
2025-01-12 14:49:13.025635: val_loss -0.7745 
2025-01-12 14:49:13.030650: Pseudo dice [np.float32(0.8222)] 
2025-01-12 14:49:13.034659: Epoch time: 42.98 s 
2025-01-12 14:49:13.618145:  
2025-01-12 14:49:13.619148: Epoch 144 
2025-01-12 14:49:13.624249: Current learning rate: 0.00737 
2025-01-12 14:49:57.251405: train_loss -0.8016 
2025-01-12 14:49:57.251405: val_loss -0.5648 
2025-01-12 14:49:57.257419: Pseudo dice [np.float32(0.6232)] 
2025-01-12 14:49:57.260430: Epoch time: 43.63 s 
2025-01-12 14:49:58.041385:  
2025-01-12 14:49:58.042390: Epoch 145 
2025-01-12 14:49:58.046977: Current learning rate: 0.00735 
2025-01-12 14:50:41.965600: train_loss -0.8027 
2025-01-12 14:50:41.966603: val_loss -0.7476 
2025-01-12 14:50:41.972747: Pseudo dice [np.float32(0.7978)] 
2025-01-12 14:50:41.978348: Epoch time: 43.92 s 
2025-01-12 14:50:42.567374:  
2025-01-12 14:50:42.568374: Epoch 146 
2025-01-12 14:50:42.573449: Current learning rate: 0.00733 
2025-01-12 14:51:25.793285: train_loss -0.8101 
2025-01-12 14:51:25.793789: val_loss -0.7173 
2025-01-12 14:51:25.798373: Pseudo dice [np.float32(0.7386)] 
2025-01-12 14:51:25.801981: Epoch time: 43.23 s 
2025-01-12 14:51:26.398134:  
2025-01-12 14:51:26.398134: Epoch 147 
2025-01-12 14:51:26.402261: Current learning rate: 0.00731 
2025-01-12 14:52:09.832092: train_loss -0.8123 
2025-01-12 14:52:09.832598: val_loss -0.7321 
2025-01-12 14:52:09.836680: Pseudo dice [np.float32(0.7735)] 
2025-01-12 14:52:09.840340: Epoch time: 43.43 s 
2025-01-12 14:52:10.437240:  
2025-01-12 14:52:10.438239: Epoch 148 
2025-01-12 14:52:10.441301: Current learning rate: 0.00729 
2025-01-12 14:52:53.199610: train_loss -0.8174 
2025-01-12 14:52:53.200609: val_loss -0.7122 
2025-01-12 14:52:53.204624: Pseudo dice [np.float32(0.7775)] 
2025-01-12 14:52:53.207724: Epoch time: 42.76 s 
2025-01-12 14:52:53.804829:  
2025-01-12 14:52:53.804829: Epoch 149 
2025-01-12 14:52:53.810405: Current learning rate: 0.00727 
2025-01-12 14:53:36.313181: train_loss -0.7957 
2025-01-12 14:53:36.313693: val_loss -0.7449 
2025-01-12 14:53:36.320867: Pseudo dice [np.float32(0.7847)] 
2025-01-12 14:53:36.323940: Epoch time: 42.51 s 
2025-01-12 14:53:37.163385:  
2025-01-12 14:53:37.163385: Epoch 150 
2025-01-12 14:53:37.169407: Current learning rate: 0.00725 
2025-01-12 14:54:19.716981: train_loss -0.7918 
2025-01-12 14:54:19.716981: val_loss -0.7301 
2025-01-12 14:54:19.722602: Pseudo dice [np.float32(0.7894)] 
2025-01-12 14:54:19.725676: Epoch time: 42.55 s 
2025-01-12 14:54:20.466022:  
2025-01-12 14:54:20.466022: Epoch 151 
2025-01-12 14:54:20.472092: Current learning rate: 0.00724 
2025-01-12 14:55:02.953609: train_loss -0.8032 
2025-01-12 14:55:02.954608: val_loss -0.7138 
2025-01-12 14:55:02.960132: Pseudo dice [np.float32(0.7755)] 
2025-01-12 14:55:02.963642: Epoch time: 42.49 s 
2025-01-12 14:55:03.550077:  
2025-01-12 14:55:03.550579: Epoch 152 
2025-01-12 14:55:03.555669: Current learning rate: 0.00722 
2025-01-12 14:55:46.070331: train_loss -0.8203 
2025-01-12 14:55:46.070331: val_loss -0.7355 
2025-01-12 14:55:46.075883: Pseudo dice [np.float32(0.7978)] 
2025-01-12 14:55:46.079903: Epoch time: 42.52 s 
2025-01-12 14:55:46.677207:  
2025-01-12 14:55:46.677207: Epoch 153 
2025-01-12 14:55:46.682291: Current learning rate: 0.0072 
2025-01-12 14:56:29.283359: train_loss -0.8399 
2025-01-12 14:56:29.284360: val_loss -0.6915 
2025-01-12 14:56:29.293432: Pseudo dice [np.float32(0.7575)] 
2025-01-12 14:56:29.297443: Epoch time: 42.61 s 
2025-01-12 14:56:29.890405:  
2025-01-12 14:56:29.890405: Epoch 154 
2025-01-12 14:56:29.895418: Current learning rate: 0.00718 
2025-01-12 14:57:12.415568: train_loss -0.8415 
2025-01-12 14:57:12.416080: val_loss -0.6273 
2025-01-12 14:57:12.421637: Pseudo dice [np.float32(0.7169)] 
2025-01-12 14:57:12.424167: Epoch time: 42.53 s 
2025-01-12 14:57:13.012432:  
2025-01-12 14:57:13.012432: Epoch 155 
2025-01-12 14:57:13.018456: Current learning rate: 0.00716 
2025-01-12 14:57:55.538360: train_loss -0.8149 
2025-01-12 14:57:55.538360: val_loss -0.7378 
2025-01-12 14:57:55.544451: Pseudo dice [np.float32(0.7963)] 
2025-01-12 14:57:55.547593: Epoch time: 42.53 s 
2025-01-12 14:57:56.138743:  
2025-01-12 14:57:56.138743: Epoch 156 
2025-01-12 14:57:56.144858: Current learning rate: 0.00714 
2025-01-12 14:58:38.450171: train_loss -0.8245 
2025-01-12 14:58:38.450677: val_loss -0.6917 
2025-01-12 14:58:38.455637: Pseudo dice [np.float32(0.7465)] 
2025-01-12 14:58:38.459356: Epoch time: 42.31 s 
2025-01-12 14:58:39.048063:  
2025-01-12 14:58:39.048063: Epoch 157 
2025-01-12 14:58:39.053600: Current learning rate: 0.00712 
2025-01-12 14:59:21.286852: train_loss -0.8196 
2025-01-12 14:59:21.287876: val_loss -0.66 
2025-01-12 14:59:21.295481: Pseudo dice [np.float32(0.7365)] 
2025-01-12 14:59:21.298586: Epoch time: 42.24 s 
2025-01-12 14:59:22.040959:  
2025-01-12 14:59:22.040959: Epoch 158 
2025-01-12 14:59:22.046710: Current learning rate: 0.0071 
2025-01-12 15:00:04.389364: train_loss -0.8176 
2025-01-12 15:00:04.390367: val_loss -0.7525 
2025-01-12 15:00:04.396383: Pseudo dice [np.float32(0.7998)] 
2025-01-12 15:00:04.399606: Epoch time: 42.35 s 
2025-01-12 15:00:04.997353:  
2025-01-12 15:00:04.997353: Epoch 159 
2025-01-12 15:00:05.003018: Current learning rate: 0.00709 
2025-01-12 15:00:47.284739: train_loss -0.8295 
2025-01-12 15:00:47.284739: val_loss -0.6902 
2025-01-12 15:00:47.293440: Pseudo dice [np.float32(0.7774)] 
2025-01-12 15:00:47.295950: Epoch time: 42.29 s 
2025-01-12 15:00:47.885067:  
2025-01-12 15:00:47.885067: Epoch 160 
2025-01-12 15:00:47.890186: Current learning rate: 0.00707 
2025-01-12 15:01:30.131482: train_loss -0.8426 
2025-01-12 15:01:30.131996: val_loss -0.74 
2025-01-12 15:01:30.137174: Pseudo dice [np.float32(0.7914)] 
2025-01-12 15:01:30.141239: Epoch time: 42.25 s 
2025-01-12 15:01:30.743684:  
2025-01-12 15:01:30.744683: Epoch 161 
2025-01-12 15:01:30.750320: Current learning rate: 0.00705 
2025-01-12 15:02:13.039932: train_loss -0.8349 
2025-01-12 15:02:13.039932: val_loss -0.717 
2025-01-12 15:02:13.043567: Pseudo dice [np.float32(0.7807)] 
2025-01-12 15:02:13.047737: Epoch time: 42.3 s 
2025-01-12 15:02:13.655210:  
2025-01-12 15:02:13.656214: Epoch 162 
2025-01-12 15:02:13.660798: Current learning rate: 0.00703 
2025-01-12 15:02:55.947715: train_loss -0.84 
2025-01-12 15:02:55.948230: val_loss -0.7254 
2025-01-12 15:02:55.953840: Pseudo dice [np.float32(0.7678)] 
2025-01-12 15:02:55.957392: Epoch time: 42.29 s 
2025-01-12 15:02:56.549610:  
2025-01-12 15:02:56.549610: Epoch 163 
2025-01-12 15:02:56.555350: Current learning rate: 0.00701 
2025-01-12 15:03:38.877069: train_loss -0.8391 
2025-01-12 15:03:38.878076: val_loss -0.6394 
2025-01-12 15:03:38.884734: Pseudo dice [np.float32(0.7136)] 
2025-01-12 15:03:38.889445: Epoch time: 42.33 s 
2025-01-12 15:03:39.492042:  
2025-01-12 15:03:39.492580: Epoch 164 
2025-01-12 15:03:39.497260: Current learning rate: 0.00699 
2025-01-12 15:04:21.765804: train_loss -0.838 
2025-01-12 15:04:21.766402: val_loss -0.7451 
2025-01-12 15:04:21.772047: Pseudo dice [np.float32(0.7956)] 
2025-01-12 15:04:21.774584: Epoch time: 42.27 s 
2025-01-12 15:04:22.352546:  
2025-01-12 15:04:22.353055: Epoch 165 
2025-01-12 15:04:22.357722: Current learning rate: 0.00697 
2025-01-12 15:05:04.682746: train_loss -0.8003 
2025-01-12 15:05:04.682746: val_loss -0.7152 
2025-01-12 15:05:04.688872: Pseudo dice [np.float32(0.7666)] 
2025-01-12 15:05:04.691380: Epoch time: 42.33 s 
2025-01-12 15:05:05.427570:  
2025-01-12 15:05:05.428574: Epoch 166 
2025-01-12 15:05:05.433120: Current learning rate: 0.00696 
2025-01-12 15:05:47.740561: train_loss -0.8375 
2025-01-12 15:05:47.740561: val_loss -0.6472 
2025-01-12 15:05:47.747176: Pseudo dice [np.float32(0.7101)] 
2025-01-12 15:05:47.750218: Epoch time: 42.31 s 
2025-01-12 15:05:48.330391:  
2025-01-12 15:05:48.330391: Epoch 167 
2025-01-12 15:05:48.335402: Current learning rate: 0.00694 
2025-01-12 15:06:30.621140: train_loss -0.8352 
2025-01-12 15:06:30.621655: val_loss -0.6828 
2025-01-12 15:06:30.626901: Pseudo dice [np.float32(0.767)] 
2025-01-12 15:06:30.630466: Epoch time: 42.29 s 
2025-01-12 15:06:31.219971:  
2025-01-12 15:06:31.220492: Epoch 168 
2025-01-12 15:06:31.225614: Current learning rate: 0.00692 
2025-01-12 15:07:13.540243: train_loss -0.8392 
2025-01-12 15:07:13.541753: val_loss -0.7152 
2025-01-12 15:07:13.547508: Pseudo dice [np.float32(0.7866)] 
2025-01-12 15:07:13.551035: Epoch time: 42.32 s 
2025-01-12 15:07:14.156739:  
2025-01-12 15:07:14.156739: Epoch 169 
2025-01-12 15:07:14.162280: Current learning rate: 0.0069 
2025-01-12 15:07:56.484155: train_loss -0.8352 
2025-01-12 15:07:56.485163: val_loss -0.6857 
2025-01-12 15:07:56.490769: Pseudo dice [np.float32(0.7501)] 
2025-01-12 15:07:56.493817: Epoch time: 42.33 s 
2025-01-12 15:07:57.076107:  
2025-01-12 15:07:57.076107: Epoch 170 
2025-01-12 15:07:57.081204: Current learning rate: 0.00688 
2025-01-12 15:08:41.464345: train_loss -0.8493 
2025-01-12 15:08:41.464926: val_loss -0.7188 
2025-01-12 15:08:41.470565: Pseudo dice [np.float32(0.7879)] 
2025-01-12 15:08:41.475696: Epoch time: 44.39 s 
2025-01-12 15:08:42.236546:  
2025-01-12 15:08:42.236546: Epoch 171 
2025-01-12 15:08:42.241580: Current learning rate: 0.00686 
2025-01-12 15:09:24.524933: train_loss -0.8077 
2025-01-12 15:09:24.525936: val_loss -0.6725 
2025-01-12 15:09:24.531026: Pseudo dice [np.float32(0.7491)] 
2025-01-12 15:09:24.535037: Epoch time: 42.29 s 
2025-01-12 15:09:25.120351:  
2025-01-12 15:09:25.120859: Epoch 172 
2025-01-12 15:09:25.125904: Current learning rate: 0.00684 
2025-01-12 15:10:07.405827: train_loss -0.7995 
2025-01-12 15:10:07.405827: val_loss -0.6842 
2025-01-12 15:10:07.411558: Pseudo dice [np.float32(0.7855)] 
2025-01-12 15:10:07.415596: Epoch time: 42.29 s 
2025-01-12 15:10:08.002396:  
2025-01-12 15:10:08.002396: Epoch 173 
2025-01-12 15:10:08.008021: Current learning rate: 0.00682 
2025-01-12 15:10:50.279282: train_loss -0.8338 
2025-01-12 15:10:50.279791: val_loss -0.6378 
2025-01-12 15:10:50.285375: Pseudo dice [np.float32(0.7282)] 
2025-01-12 15:10:50.288540: Epoch time: 42.28 s 
2025-01-12 15:10:51.025763:  
2025-01-12 15:10:51.025763: Epoch 174 
2025-01-12 15:10:51.029922: Current learning rate: 0.0068 
2025-01-12 15:11:33.284572: train_loss -0.83 
2025-01-12 15:11:33.286155: val_loss -0.7109 
2025-01-12 15:11:33.291788: Pseudo dice [np.float32(0.7827)] 
2025-01-12 15:11:33.294819: Epoch time: 42.26 s 
2025-01-12 15:11:33.879932:  
2025-01-12 15:11:33.879932: Epoch 175 
2025-01-12 15:11:33.885545: Current learning rate: 0.00679 
2025-01-12 15:12:16.147032: train_loss -0.847 
2025-01-12 15:12:16.147649: val_loss -0.7477 
2025-01-12 15:12:16.152742: Pseudo dice [np.float32(0.797)] 
2025-01-12 15:12:16.156317: Epoch time: 42.27 s 
2025-01-12 15:12:16.745405:  
2025-01-12 15:12:16.745405: Epoch 176 
2025-01-12 15:12:16.751025: Current learning rate: 0.00677 
2025-01-12 15:12:59.010088: train_loss -0.826 
2025-01-12 15:12:59.010088: val_loss -0.7181 
2025-01-12 15:12:59.016102: Pseudo dice [np.float32(0.7865)] 
2025-01-12 15:12:59.019708: Epoch time: 42.27 s 
2025-01-12 15:12:59.609529:  
2025-01-12 15:12:59.609529: Epoch 177 
2025-01-12 15:12:59.615046: Current learning rate: 0.00675 
2025-01-12 15:13:41.890582: train_loss -0.8144 
2025-01-12 15:13:41.891587: val_loss -0.7664 
2025-01-12 15:13:41.896597: Pseudo dice [np.float32(0.811)] 
2025-01-12 15:13:41.900259: Epoch time: 42.28 s 
2025-01-12 15:13:42.512776:  
2025-01-12 15:13:42.513284: Epoch 178 
2025-01-12 15:13:42.519962: Current learning rate: 0.00673 
2025-01-12 15:14:24.773527: train_loss -0.8355 
2025-01-12 15:14:24.773527: val_loss -0.7163 
2025-01-12 15:14:24.779978: Pseudo dice [np.float32(0.7834)] 
2025-01-12 15:14:24.783648: Epoch time: 42.26 s 
2025-01-12 15:14:25.366947:  
2025-01-12 15:14:25.367452: Epoch 179 
2025-01-12 15:14:25.373051: Current learning rate: 0.00671 
2025-01-12 15:15:07.661272: train_loss -0.8144 
2025-01-12 15:15:07.661272: val_loss -0.728 
2025-01-12 15:15:07.667951: Pseudo dice [np.float32(0.7681)] 
2025-01-12 15:15:07.670972: Epoch time: 42.29 s 
2025-01-12 15:15:08.263442:  
2025-01-12 15:15:08.263442: Epoch 180 
2025-01-12 15:15:08.267541: Current learning rate: 0.00669 
2025-01-12 15:15:50.516197: train_loss -0.8235 
2025-01-12 15:15:50.517789: val_loss -0.6792 
2025-01-12 15:15:50.523911: Pseudo dice [np.float32(0.7491)] 
2025-01-12 15:15:50.528060: Epoch time: 42.25 s 
2025-01-12 15:15:51.113711:  
2025-01-12 15:15:51.113711: Epoch 181 
2025-01-12 15:15:51.119328: Current learning rate: 0.00667 
2025-01-12 15:16:33.410917: train_loss -0.838 
2025-01-12 15:16:33.411420: val_loss -0.7432 
2025-01-12 15:16:33.417091: Pseudo dice [np.float32(0.797)] 
2025-01-12 15:16:33.420668: Epoch time: 42.3 s 
2025-01-12 15:16:34.158118:  
2025-01-12 15:16:34.158118: Epoch 182 
2025-01-12 15:16:34.163189: Current learning rate: 0.00665 
2025-01-12 15:17:16.438262: train_loss -0.8537 
2025-01-12 15:17:16.438262: val_loss -0.7281 
2025-01-12 15:17:16.444834: Pseudo dice [np.float32(0.7917)] 
2025-01-12 15:17:16.448051: Epoch time: 42.28 s 
2025-01-12 15:17:17.071845:  
2025-01-12 15:17:17.072372: Epoch 183 
2025-01-12 15:17:17.077053: Current learning rate: 0.00664 
2025-01-12 15:17:59.332556: train_loss -0.7578 
2025-01-12 15:17:59.332556: val_loss -0.6953 
2025-01-12 15:17:59.337853: Pseudo dice [np.float32(0.748)] 
2025-01-12 15:17:59.341363: Epoch time: 42.26 s 
2025-01-12 15:17:59.931944:  
2025-01-12 15:17:59.931944: Epoch 184 
2025-01-12 15:17:59.936573: Current learning rate: 0.00662 
2025-01-12 15:18:42.197335: train_loss -0.7825 
2025-01-12 15:18:42.197842: val_loss -0.6942 
2025-01-12 15:18:42.205443: Pseudo dice [np.float32(0.7597)] 
2025-01-12 15:18:42.209106: Epoch time: 42.27 s 
2025-01-12 15:18:42.800646:  
2025-01-12 15:18:42.800646: Epoch 185 
2025-01-12 15:18:42.806182: Current learning rate: 0.0066 
2025-01-12 15:19:25.063664: train_loss -0.7931 
2025-01-12 15:19:25.063664: val_loss -0.7045 
2025-01-12 15:19:25.070271: Pseudo dice [np.float32(0.7668)] 
2025-01-12 15:19:25.073786: Epoch time: 42.26 s 
2025-01-12 15:19:25.660837:  
2025-01-12 15:19:25.661842: Epoch 186 
2025-01-12 15:19:25.665904: Current learning rate: 0.00658 
2025-01-12 15:20:07.901044: train_loss -0.8213 
2025-01-12 15:20:07.902548: val_loss -0.7059 
2025-01-12 15:20:07.906060: Pseudo dice [np.float32(0.7586)] 
2025-01-12 15:20:07.908668: Epoch time: 42.24 s 
2025-01-12 15:20:08.499761:  
2025-01-12 15:20:08.500268: Epoch 187 
2025-01-12 15:20:08.504818: Current learning rate: 0.00656 
2025-01-12 15:20:50.797725: train_loss -0.8439 
2025-01-12 15:20:50.798233: val_loss -0.7433 
2025-01-12 15:20:50.803856: Pseudo dice [np.float32(0.7987)] 
2025-01-12 15:20:50.807582: Epoch time: 42.3 s 
2025-01-12 15:20:51.396616:  
2025-01-12 15:20:51.396616: Epoch 188 
2025-01-12 15:20:51.402271: Current learning rate: 0.00654 
2025-01-12 15:21:33.681320: train_loss -0.829 
2025-01-12 15:21:33.681823: val_loss -0.6746 
2025-01-12 15:21:33.687468: Pseudo dice [np.float32(0.72)] 
2025-01-12 15:21:33.690983: Epoch time: 42.29 s 
2025-01-12 15:21:34.295058:  
2025-01-12 15:21:34.295058: Epoch 189 
2025-01-12 15:21:34.298676: Current learning rate: 0.00652 
2025-01-12 15:22:16.564066: train_loss -0.8099 
2025-01-12 15:22:16.564569: val_loss -0.7487 
2025-01-12 15:22:16.569706: Pseudo dice [np.float32(0.811)] 
2025-01-12 15:22:16.572488: Epoch time: 42.27 s 
2025-01-12 15:22:17.323128:  
2025-01-12 15:22:17.323128: Epoch 190 
2025-01-12 15:22:17.328752: Current learning rate: 0.0065 
2025-01-12 15:22:59.628874: train_loss -0.7949 
2025-01-12 15:22:59.629389: val_loss -0.7569 
2025-01-12 15:22:59.634984: Pseudo dice [np.float32(0.8044)] 
2025-01-12 15:22:59.637623: Epoch time: 42.31 s 
2025-01-12 15:23:00.233986:  
2025-01-12 15:23:00.234489: Epoch 191 
2025-01-12 15:23:00.239105: Current learning rate: 0.00648 
2025-01-12 15:23:42.501680: train_loss -0.8157 
2025-01-12 15:23:42.501680: val_loss -0.6439 
2025-01-12 15:23:42.506762: Pseudo dice [np.float32(0.7257)] 
2025-01-12 15:23:42.510896: Epoch time: 42.27 s 
2025-01-12 15:23:43.109526:  
2025-01-12 15:23:43.109526: Epoch 192 
2025-01-12 15:23:43.115104: Current learning rate: 0.00647 
2025-01-12 15:24:25.370544: train_loss -0.8347 
2025-01-12 15:24:25.370544: val_loss -0.7001 
2025-01-12 15:24:25.376156: Pseudo dice [np.float32(0.7641)] 
2025-01-12 15:24:25.380263: Epoch time: 42.26 s 
2025-01-12 15:24:25.987276:  
2025-01-12 15:24:25.988280: Epoch 193 
2025-01-12 15:24:25.993355: Current learning rate: 0.00645 
2025-01-12 15:25:08.257190: train_loss -0.8438 
2025-01-12 15:25:08.257698: val_loss -0.682 
2025-01-12 15:25:08.263343: Pseudo dice [np.float32(0.7608)] 
2025-01-12 15:25:08.266458: Epoch time: 42.27 s 
2025-01-12 15:25:08.865206:  
2025-01-12 15:25:08.865206: Epoch 194 
2025-01-12 15:25:08.870392: Current learning rate: 0.00643 
2025-01-12 15:25:51.142389: train_loss -0.8351 
2025-01-12 15:25:51.143393: val_loss -0.6822 
2025-01-12 15:25:51.148550: Pseudo dice [np.float32(0.7652)] 
2025-01-12 15:25:51.152559: Epoch time: 42.28 s 
2025-01-12 15:25:51.752467:  
2025-01-12 15:25:51.752467: Epoch 195 
2025-01-12 15:25:51.757594: Current learning rate: 0.00641 
2025-01-12 15:26:34.028761: train_loss -0.8125 
2025-01-12 15:26:34.029281: val_loss -0.6042 
2025-01-12 15:26:34.034866: Pseudo dice [np.float32(0.7197)] 
2025-01-12 15:26:34.038473: Epoch time: 42.28 s 
2025-01-12 15:26:34.635003:  
2025-01-12 15:26:34.635003: Epoch 196 
2025-01-12 15:26:34.640673: Current learning rate: 0.00639 
2025-01-12 15:27:16.907986: train_loss -0.8206 
2025-01-12 15:27:16.907986: val_loss -0.7594 
2025-01-12 15:27:16.914256: Pseudo dice [np.float32(0.813)] 
2025-01-12 15:27:16.917378: Epoch time: 42.27 s 
2025-01-12 15:27:17.670980:  
2025-01-12 15:27:17.672483: Epoch 197 
2025-01-12 15:27:17.677494: Current learning rate: 0.00637 
2025-01-12 15:27:59.949402: train_loss -0.8324 
2025-01-12 15:27:59.950402: val_loss -0.7228 
2025-01-12 15:27:59.955921: Pseudo dice [np.float32(0.796)] 
2025-01-12 15:27:59.958550: Epoch time: 42.28 s 
2025-01-12 15:28:00.557465:  
2025-01-12 15:28:00.558470: Epoch 198 
2025-01-12 15:28:00.563510: Current learning rate: 0.00635 
2025-01-12 15:28:42.818577: train_loss -0.8203 
2025-01-12 15:28:42.819596: val_loss -0.7593 
2025-01-12 15:28:42.824744: Pseudo dice [np.float32(0.802)] 
2025-01-12 15:28:42.827905: Epoch time: 42.26 s 
2025-01-12 15:28:43.433835:  
2025-01-12 15:28:43.433835: Epoch 199 
2025-01-12 15:28:43.438953: Current learning rate: 0.00633 
2025-01-12 15:29:25.692469: train_loss -0.8433 
2025-01-12 15:29:25.692971: val_loss -0.7052 
2025-01-12 15:29:25.698598: Pseudo dice [np.float32(0.7644)] 
2025-01-12 15:29:25.701103: Epoch time: 42.26 s 
2025-01-12 15:29:26.558089:  
2025-01-12 15:29:26.558600: Epoch 200 
2025-01-12 15:29:26.564214: Current learning rate: 0.00631 
2025-01-12 15:30:08.832416: train_loss -0.8413 
2025-01-12 15:30:08.832937: val_loss -0.6813 
2025-01-12 15:30:08.838167: Pseudo dice [np.float32(0.7432)] 
2025-01-12 15:30:08.841676: Epoch time: 42.27 s 
2025-01-12 15:30:09.441932:  
2025-01-12 15:30:09.441932: Epoch 201 
2025-01-12 15:30:09.447029: Current learning rate: 0.0063 
2025-01-12 15:30:51.740395: train_loss -0.8184 
2025-01-12 15:30:51.740395: val_loss -0.7156 
2025-01-12 15:30:51.746409: Pseudo dice [np.float32(0.7782)] 
2025-01-12 15:30:51.750008: Epoch time: 42.3 s 
2025-01-12 15:30:52.345456:  
2025-01-12 15:30:52.346965: Epoch 202 
2025-01-12 15:30:52.350613: Current learning rate: 0.00628 
2025-01-12 15:31:34.615005: train_loss -0.8355 
2025-01-12 15:31:34.615508: val_loss -0.7557 
2025-01-12 15:31:34.621218: Pseudo dice [np.float32(0.8138)] 
2025-01-12 15:31:34.624752: Epoch time: 42.27 s 
2025-01-12 15:31:35.224776:  
2025-01-12 15:31:35.225785: Epoch 203 
2025-01-12 15:31:35.230393: Current learning rate: 0.00626 
2025-01-12 15:32:17.500446: train_loss -0.8349 
2025-01-12 15:32:17.501450: val_loss -0.6977 
2025-01-12 15:32:17.507059: Pseudo dice [np.float32(0.7704)] 
2025-01-12 15:32:17.510071: Epoch time: 42.28 s 
2025-01-12 15:32:18.112059:  
2025-01-12 15:32:18.112561: Epoch 204 
2025-01-12 15:32:18.118164: Current learning rate: 0.00624 
2025-01-12 15:33:00.416056: train_loss -0.7863 
2025-01-12 15:33:00.417155: val_loss -0.7199 
2025-01-12 15:33:00.422313: Pseudo dice [np.float32(0.7861)] 
2025-01-12 15:33:00.425340: Epoch time: 42.3 s 
2025-01-12 15:33:01.183996:  
2025-01-12 15:33:01.184504: Epoch 205 
2025-01-12 15:33:01.189602: Current learning rate: 0.00622 
2025-01-12 15:33:43.499594: train_loss -0.828 
2025-01-12 15:33:43.500097: val_loss -0.7389 
2025-01-12 15:33:43.505667: Pseudo dice [np.float32(0.7906)] 
2025-01-12 15:33:43.508311: Epoch time: 42.32 s 
2025-01-12 15:33:44.073962:  
2025-01-12 15:33:44.073962: Epoch 206 
2025-01-12 15:33:44.079639: Current learning rate: 0.0062 
2025-01-12 15:34:26.359264: train_loss -0.8274 
2025-01-12 15:34:26.359784: val_loss -0.6801 
2025-01-12 15:34:26.365345: Pseudo dice [np.float32(0.7521)] 
2025-01-12 15:34:26.367971: Epoch time: 42.29 s 
2025-01-12 15:34:26.940169:  
2025-01-12 15:34:26.941172: Epoch 207 
2025-01-12 15:34:26.946324: Current learning rate: 0.00618 
2025-01-12 15:35:09.252653: train_loss -0.8239 
2025-01-12 15:35:09.253162: val_loss -0.7518 
2025-01-12 15:35:09.258852: Pseudo dice [np.float32(0.8111)] 
2025-01-12 15:35:09.261903: Epoch time: 42.31 s 
2025-01-12 15:35:09.264946: Yayy! New best EMA pseudo Dice: 0.7785000205039978 
2025-01-12 15:35:10.099615:  
2025-01-12 15:35:10.100127: Epoch 208 
2025-01-12 15:35:10.105238: Current learning rate: 0.00616 
2025-01-12 15:35:52.381956: train_loss -0.793 
2025-01-12 15:35:52.381956: val_loss -0.767 
2025-01-12 15:35:52.388208: Pseudo dice [np.float32(0.8104)] 
2025-01-12 15:35:52.391748: Epoch time: 42.28 s 
2025-01-12 15:35:52.394285: Yayy! New best EMA pseudo Dice: 0.7817000150680542 
2025-01-12 15:35:53.210347:  
2025-01-12 15:35:53.210850: Epoch 209 
2025-01-12 15:35:53.216465: Current learning rate: 0.00614 
2025-01-12 15:36:35.515793: train_loss -0.8039 
2025-01-12 15:36:35.516296: val_loss -0.765 
2025-01-12 15:36:35.521421: Pseudo dice [np.float32(0.8149)] 
2025-01-12 15:36:35.525428: Epoch time: 42.31 s 
2025-01-12 15:36:35.528053: Yayy! New best EMA pseudo Dice: 0.7850000262260437 
2025-01-12 15:36:36.598000:  
2025-01-12 15:36:36.599003: Epoch 210 
2025-01-12 15:36:36.604028: Current learning rate: 0.00612 
2025-01-12 15:37:18.879138: train_loss -0.8455 
2025-01-12 15:37:18.879138: val_loss -0.7091 
2025-01-12 15:37:18.885652: Pseudo dice [np.float32(0.7784)] 
2025-01-12 15:37:18.888158: Epoch time: 42.28 s 
2025-01-12 15:37:19.475633:  
2025-01-12 15:37:19.475633: Epoch 211 
2025-01-12 15:37:19.480644: Current learning rate: 0.00611 
2025-01-12 15:38:01.745802: train_loss -0.8441 
2025-01-12 15:38:01.746310: val_loss -0.7912 
2025-01-12 15:38:01.751993: Pseudo dice [np.float32(0.8357)] 
2025-01-12 15:38:01.755529: Epoch time: 42.27 s 
2025-01-12 15:38:01.758657: Yayy! New best EMA pseudo Dice: 0.7894999980926514 
2025-01-12 15:38:02.564807:  
2025-01-12 15:38:02.565810: Epoch 212 
2025-01-12 15:38:02.571474: Current learning rate: 0.00609 
2025-01-12 15:38:44.838041: train_loss -0.8516 
2025-01-12 15:38:44.838547: val_loss -0.7575 
2025-01-12 15:38:44.843603: Pseudo dice [np.float32(0.8083)] 
2025-01-12 15:38:44.846785: Epoch time: 42.27 s 
2025-01-12 15:38:44.849850: Yayy! New best EMA pseudo Dice: 0.7914000153541565 
2025-01-12 15:38:45.778720:  
2025-01-12 15:38:45.778720: Epoch 213 
2025-01-12 15:38:45.784829: Current learning rate: 0.00607 
2025-01-12 15:39:28.027373: train_loss -0.8325 
2025-01-12 15:39:28.027889: val_loss -0.7377 
2025-01-12 15:39:28.032901: Pseudo dice [np.float32(0.8006)] 
2025-01-12 15:39:28.037010: Epoch time: 42.25 s 
2025-01-12 15:39:28.040045: Yayy! New best EMA pseudo Dice: 0.7922999858856201 
2025-01-12 15:39:28.845999:  
2025-01-12 15:39:28.845999: Epoch 214 
2025-01-12 15:39:28.851153: Current learning rate: 0.00605 
2025-01-12 15:40:11.124142: train_loss -0.8393 
2025-01-12 15:40:11.124645: val_loss -0.6612 
2025-01-12 15:40:11.130278: Pseudo dice [np.float32(0.7357)] 
2025-01-12 15:40:11.132788: Epoch time: 42.28 s 
2025-01-12 15:40:11.703588:  
2025-01-12 15:40:11.703588: Epoch 215 
2025-01-12 15:40:11.709722: Current learning rate: 0.00603 
2025-01-12 15:40:53.996028: train_loss -0.839 
2025-01-12 15:40:53.997135: val_loss -0.7076 
2025-01-12 15:40:54.002148: Pseudo dice [np.float32(0.7681)] 
2025-01-12 15:40:54.005661: Epoch time: 42.29 s 
2025-01-12 15:40:54.574993:  
2025-01-12 15:40:54.575997: Epoch 216 
2025-01-12 15:40:54.581136: Current learning rate: 0.00601 
2025-01-12 15:41:36.822979: train_loss -0.8378 
2025-01-12 15:41:36.823983: val_loss -0.6814 
2025-01-12 15:41:36.829620: Pseudo dice [np.float32(0.745)] 
2025-01-12 15:41:36.833214: Epoch time: 42.25 s 
2025-01-12 15:41:37.401855:  
2025-01-12 15:41:37.402366: Epoch 217 
2025-01-12 15:41:37.407501: Current learning rate: 0.00599 
2025-01-12 15:42:19.694742: train_loss -0.8373 
2025-01-12 15:42:19.695244: val_loss -0.7407 
2025-01-12 15:42:19.700365: Pseudo dice [np.float32(0.7948)] 
2025-01-12 15:42:19.703874: Epoch time: 42.29 s 
2025-01-12 15:42:20.279509:  
2025-01-12 15:42:20.280011: Epoch 218 
2025-01-12 15:42:20.285080: Current learning rate: 0.00597 
2025-01-12 15:43:02.557499: train_loss -0.8395 
2025-01-12 15:43:02.558014: val_loss -0.6881 
2025-01-12 15:43:02.563063: Pseudo dice [np.float32(0.7458)] 
2025-01-12 15:43:02.566706: Epoch time: 42.28 s 
2025-01-12 15:43:03.138973:  
2025-01-12 15:43:03.139973: Epoch 219 
2025-01-12 15:43:03.145046: Current learning rate: 0.00595 
2025-01-12 15:43:45.429307: train_loss -0.857 
2025-01-12 15:43:45.429811: val_loss -0.6599 
2025-01-12 15:43:45.435824: Pseudo dice [np.float32(0.7376)] 
2025-01-12 15:43:45.438414: Epoch time: 42.29 s 
2025-01-12 15:43:46.003584:  
2025-01-12 15:43:46.004588: Epoch 220 
2025-01-12 15:43:46.009764: Current learning rate: 0.00593 
2025-01-12 15:44:28.267166: train_loss -0.852 
2025-01-12 15:44:28.267672: val_loss -0.7155 
2025-01-12 15:44:28.273748: Pseudo dice [np.float32(0.7935)] 
2025-01-12 15:44:28.276859: Epoch time: 42.26 s 
2025-01-12 15:44:28.851047:  
2025-01-12 15:44:28.851047: Epoch 221 
2025-01-12 15:44:28.856072: Current learning rate: 0.00592 
2025-01-12 15:45:11.109432: train_loss -0.8555 
2025-01-12 15:45:11.109939: val_loss -0.7461 
2025-01-12 15:45:11.115502: Pseudo dice [np.float32(0.7478)] 
2025-01-12 15:45:11.118632: Epoch time: 42.26 s 
2025-01-12 15:45:11.840901:  
2025-01-12 15:45:11.840901: Epoch 222 
2025-01-12 15:45:11.846621: Current learning rate: 0.0059 
2025-01-12 15:45:54.082574: train_loss -0.8213 
2025-01-12 15:45:54.083578: val_loss -0.7008 
2025-01-12 15:45:54.089249: Pseudo dice [np.float32(0.7774)] 
2025-01-12 15:45:54.091758: Epoch time: 42.24 s 
2025-01-12 15:45:54.654498:  
2025-01-12 15:45:54.654498: Epoch 223 
2025-01-12 15:45:54.660664: Current learning rate: 0.00588 
2025-01-12 15:46:36.919074: train_loss -0.8601 
2025-01-12 15:46:36.919576: val_loss -0.6849 
2025-01-12 15:46:36.925137: Pseudo dice [np.float32(0.7724)] 
2025-01-12 15:46:36.928645: Epoch time: 42.27 s 
2025-01-12 15:46:37.494109:  
2025-01-12 15:46:37.494109: Epoch 224 
2025-01-12 15:46:37.499358: Current learning rate: 0.00586 
2025-01-12 15:47:19.756546: train_loss -0.8588 
2025-01-12 15:47:19.757097: val_loss -0.7174 
2025-01-12 15:47:19.763172: Pseudo dice [np.float32(0.7858)] 
2025-01-12 15:47:19.766303: Epoch time: 42.26 s 
2025-01-12 15:47:20.329801:  
2025-01-12 15:47:20.330307: Epoch 225 
2025-01-12 15:47:20.335375: Current learning rate: 0.00584 
2025-01-12 15:48:02.578162: train_loss -0.8678 
2025-01-12 15:48:02.578162: val_loss -0.6862 
2025-01-12 15:48:02.584730: Pseudo dice [np.float32(0.7592)] 
2025-01-12 15:48:02.588374: Epoch time: 42.25 s 
2025-01-12 15:48:03.155571:  
2025-01-12 15:48:03.155571: Epoch 226 
2025-01-12 15:48:03.160242: Current learning rate: 0.00582 
2025-01-12 15:48:45.439967: train_loss -0.8625 
2025-01-12 15:48:45.439967: val_loss -0.6894 
2025-01-12 15:48:45.445986: Pseudo dice [np.float32(0.7464)] 
2025-01-12 15:48:45.448592: Epoch time: 42.29 s 
2025-01-12 15:48:46.019638:  
2025-01-12 15:48:46.020141: Epoch 227 
2025-01-12 15:48:46.025151: Current learning rate: 0.0058 
2025-01-12 15:49:28.269730: train_loss -0.8258 
2025-01-12 15:49:28.270233: val_loss -0.7057 
2025-01-12 15:49:28.275771: Pseudo dice [np.float32(0.7816)] 
2025-01-12 15:49:28.278388: Epoch time: 42.25 s 
2025-01-12 15:49:28.846236:  
2025-01-12 15:49:28.847327: Epoch 228 
2025-01-12 15:49:28.852904: Current learning rate: 0.00578 
2025-01-12 15:50:11.086734: train_loss -0.8337 
2025-01-12 15:50:11.087320: val_loss -0.7115 
2025-01-12 15:50:11.093903: Pseudo dice [np.float32(0.7981)] 
2025-01-12 15:50:11.097586: Epoch time: 42.24 s 
2025-01-12 15:50:11.659847:  
2025-01-12 15:50:11.660349: Epoch 229 
2025-01-12 15:50:11.665360: Current learning rate: 0.00576 
2025-01-12 15:50:53.872534: train_loss -0.8229 
2025-01-12 15:50:53.873042: val_loss -0.658 
2025-01-12 15:50:53.879705: Pseudo dice [np.float32(0.7487)] 
2025-01-12 15:50:53.882740: Epoch time: 42.21 s 
2025-01-12 15:50:54.448491:  
2025-01-12 15:50:54.448491: Epoch 230 
2025-01-12 15:50:54.454018: Current learning rate: 0.00574 
2025-01-12 15:51:36.696006: train_loss -0.8245 
2025-01-12 15:51:36.697515: val_loss -0.6616 
2025-01-12 15:51:36.703101: Pseudo dice [np.float32(0.7538)] 
2025-01-12 15:51:36.705621: Epoch time: 42.25 s 
2025-01-12 15:51:37.419851:  
2025-01-12 15:51:37.420355: Epoch 231 
2025-01-12 15:51:37.425375: Current learning rate: 0.00572 
2025-01-12 15:52:19.668683: train_loss -0.8389 
2025-01-12 15:52:19.669186: val_loss -0.7322 
2025-01-12 15:52:19.675208: Pseudo dice [np.float32(0.805)] 
2025-01-12 15:52:19.678313: Epoch time: 42.25 s 
2025-01-12 15:52:20.244986:  
2025-01-12 15:52:20.244986: Epoch 232 
2025-01-12 15:52:20.250722: Current learning rate: 0.0057 
2025-01-12 15:53:02.507124: train_loss -0.8541 
2025-01-12 15:53:02.507657: val_loss -0.6699 
2025-01-12 15:53:02.513217: Pseudo dice [np.float32(0.7707)] 
2025-01-12 15:53:02.517364: Epoch time: 42.26 s 
2025-01-12 15:53:03.079573:  
2025-01-12 15:53:03.080087: Epoch 233 
2025-01-12 15:53:03.085171: Current learning rate: 0.00569 
2025-01-12 15:53:45.363568: train_loss -0.8716 
2025-01-12 15:53:45.365071: val_loss -0.7074 
2025-01-12 15:53:45.371177: Pseudo dice [np.float32(0.7888)] 
2025-01-12 15:53:45.375191: Epoch time: 42.28 s 
2025-01-12 15:53:45.936111:  
2025-01-12 15:53:45.937190: Epoch 234 
2025-01-12 15:53:45.942267: Current learning rate: 0.00567 
2025-01-12 15:54:28.251397: train_loss -0.8536 
2025-01-12 15:54:28.251900: val_loss -0.6952 
2025-01-12 15:54:28.256455: Pseudo dice [np.float32(0.7785)] 
2025-01-12 15:54:28.260563: Epoch time: 42.32 s 
2025-01-12 15:54:28.824958:  
2025-01-12 15:54:28.825465: Epoch 235 
2025-01-12 15:54:28.829681: Current learning rate: 0.00565 
2025-01-12 15:55:11.097011: train_loss -0.8687 
2025-01-12 15:55:11.098015: val_loss -0.7166 
2025-01-12 15:55:11.103538: Pseudo dice [np.float32(0.7832)] 
2025-01-12 15:55:11.107126: Epoch time: 42.27 s 
2025-01-12 15:55:11.678952:  
2025-01-12 15:55:11.679455: Epoch 236 
2025-01-12 15:55:11.684019: Current learning rate: 0.00563 
2025-01-12 15:55:53.948838: train_loss -0.8692 
2025-01-12 15:55:53.949349: val_loss -0.7094 
2025-01-12 15:55:53.954916: Pseudo dice [np.float32(0.771)] 
2025-01-12 15:55:53.958032: Epoch time: 42.27 s 
2025-01-12 15:55:54.521891:  
2025-01-12 15:55:54.522393: Epoch 237 
2025-01-12 15:55:54.527438: Current learning rate: 0.00561 
2025-01-12 15:56:36.800959: train_loss -0.8589 
2025-01-12 15:56:36.801958: val_loss -0.6907 
2025-01-12 15:56:36.807560: Pseudo dice [np.float32(0.7737)] 
2025-01-12 15:56:36.810067: Epoch time: 42.28 s 
2025-01-12 15:56:37.380234:  
2025-01-12 15:56:37.381238: Epoch 238 
2025-01-12 15:56:37.385808: Current learning rate: 0.00559 
2025-01-12 15:57:19.649600: train_loss -0.852 
2025-01-12 15:57:19.650603: val_loss -0.7683 
2025-01-12 15:57:19.655617: Pseudo dice [np.float32(0.8196)] 
2025-01-12 15:57:19.659125: Epoch time: 42.27 s 
2025-01-12 15:57:20.380259:  
2025-01-12 15:57:20.380762: Epoch 239 
2025-01-12 15:57:20.385805: Current learning rate: 0.00557 
2025-01-12 15:58:02.601212: train_loss -0.8501 
2025-01-12 15:58:02.601721: val_loss -0.7579 
2025-01-12 15:58:02.607359: Pseudo dice [np.float32(0.8072)] 
2025-01-12 15:58:02.610400: Epoch time: 42.22 s 
2025-01-12 15:58:03.180893:  
2025-01-12 15:58:03.181411: Epoch 240 
2025-01-12 15:58:03.186554: Current learning rate: 0.00555 
2025-01-12 15:58:45.420588: train_loss -0.8559 
2025-01-12 15:58:45.421095: val_loss -0.7503 
2025-01-12 15:58:45.426159: Pseudo dice [np.float32(0.8212)] 
2025-01-12 15:58:45.429790: Epoch time: 42.24 s 
2025-01-12 15:58:46.004215:  
2025-01-12 15:58:46.004215: Epoch 241 
2025-01-12 15:58:46.009748: Current learning rate: 0.00553 
2025-01-12 15:59:28.296714: train_loss -0.8561 
2025-01-12 15:59:28.297225: val_loss -0.7505 
2025-01-12 15:59:28.302832: Pseudo dice [np.float32(0.7883)] 
2025-01-12 15:59:28.305894: Epoch time: 42.29 s 
2025-01-12 15:59:28.876058:  
2025-01-12 15:59:28.877061: Epoch 242 
2025-01-12 15:59:28.882098: Current learning rate: 0.00551 
2025-01-12 16:00:11.125953: train_loss -0.8486 
2025-01-12 16:00:11.125953: val_loss -0.7345 
2025-01-12 16:00:11.132106: Pseudo dice [np.float32(0.7757)] 
2025-01-12 16:00:11.135652: Epoch time: 42.25 s 
2025-01-12 16:00:11.708385:  
2025-01-12 16:00:11.708385: Epoch 243 
2025-01-12 16:00:11.714963: Current learning rate: 0.00549 
2025-01-12 16:00:53.981210: train_loss -0.8555 
2025-01-12 16:00:53.981210: val_loss -0.7256 
2025-01-12 16:00:53.987341: Pseudo dice [np.float32(0.798)] 
2025-01-12 16:00:53.990855: Epoch time: 42.27 s 
2025-01-12 16:00:54.560349:  
2025-01-12 16:00:54.560349: Epoch 244 
2025-01-12 16:00:54.566027: Current learning rate: 0.00547 
2025-01-12 16:01:36.842220: train_loss -0.8437 
2025-01-12 16:01:36.842732: val_loss -0.7791 
2025-01-12 16:01:36.848408: Pseudo dice [np.float32(0.8191)] 
2025-01-12 16:01:36.851431: Epoch time: 42.28 s 
2025-01-12 16:01:37.423742:  
2025-01-12 16:01:37.425253: Epoch 245 
2025-01-12 16:01:37.430380: Current learning rate: 0.00546 
2025-01-12 16:02:19.691466: train_loss -0.8619 
2025-01-12 16:02:19.691466: val_loss -0.7122 
2025-01-12 16:02:19.697576: Pseudo dice [np.float32(0.7803)] 
2025-01-12 16:02:19.702607: Epoch time: 42.27 s 
2025-01-12 16:02:20.276812:  
2025-01-12 16:02:20.276812: Epoch 246 
2025-01-12 16:02:20.281875: Current learning rate: 0.00544 
2025-01-12 16:03:02.529681: train_loss -0.861 
2025-01-12 16:03:02.530183: val_loss -0.7496 
2025-01-12 16:03:02.535725: Pseudo dice [np.float32(0.807)] 
2025-01-12 16:03:02.539244: Epoch time: 42.25 s 
2025-01-12 16:03:03.273879:  
2025-01-12 16:03:03.273879: Epoch 247 
2025-01-12 16:03:03.278487: Current learning rate: 0.00542 
2025-01-12 16:03:45.529908: train_loss -0.8393 
2025-01-12 16:03:45.529908: val_loss -0.7399 
2025-01-12 16:03:45.535971: Pseudo dice [np.float32(0.814)] 
2025-01-12 16:03:45.538586: Epoch time: 42.26 s 
2025-01-12 16:03:45.542092: Yayy! New best EMA pseudo Dice: 0.7930999994277954 
2025-01-12 16:03:46.410417:  
2025-01-12 16:03:46.410417: Epoch 248 
2025-01-12 16:03:46.415428: Current learning rate: 0.0054 
2025-01-12 16:04:28.665019: train_loss -0.814 
2025-01-12 16:04:28.665019: val_loss -0.7669 
2025-01-12 16:04:28.670669: Pseudo dice [np.float32(0.8179)] 
2025-01-12 16:04:28.674065: Epoch time: 42.26 s 
2025-01-12 16:04:28.676575: Yayy! New best EMA pseudo Dice: 0.7955999970436096 
2025-01-12 16:04:29.508724:  
2025-01-12 16:04:29.509226: Epoch 249 
2025-01-12 16:04:29.514344: Current learning rate: 0.00538 
2025-01-12 16:05:11.764033: train_loss -0.8489 
2025-01-12 16:05:11.765033: val_loss -0.7854 
2025-01-12 16:05:11.770146: Pseudo dice [np.float32(0.825)] 
2025-01-12 16:05:11.773660: Epoch time: 42.26 s 
2025-01-12 16:05:11.960522: Yayy! New best EMA pseudo Dice: 0.7985000014305115 
2025-01-12 16:05:12.782028:  
2025-01-12 16:05:12.782526: Epoch 250 
2025-01-12 16:05:12.787770: Current learning rate: 0.00536 
2025-01-12 16:05:55.035882: train_loss -0.8528 
2025-01-12 16:05:55.036396: val_loss -0.7656 
2025-01-12 16:05:55.042523: Pseudo dice [np.float32(0.8118)] 
2025-01-12 16:05:55.045058: Epoch time: 42.26 s 
2025-01-12 16:05:55.048105: Yayy! New best EMA pseudo Dice: 0.7998999953269958 
2025-01-12 16:05:55.865029:  
2025-01-12 16:05:55.866032: Epoch 251 
2025-01-12 16:05:55.871063: Current learning rate: 0.00534 
2025-01-12 16:06:38.160140: train_loss -0.8655 
2025-01-12 16:06:38.161143: val_loss -0.7682 
2025-01-12 16:06:38.166337: Pseudo dice [np.float32(0.8139)] 
2025-01-12 16:06:38.169439: Epoch time: 42.3 s 
2025-01-12 16:06:38.172947: Yayy! New best EMA pseudo Dice: 0.8012999892234802 
2025-01-12 16:06:38.995915:  
2025-01-12 16:06:38.996418: Epoch 252 
2025-01-12 16:06:39.001622: Current learning rate: 0.00532 
2025-01-12 16:07:21.279455: train_loss -0.8743 
2025-01-12 16:07:21.280461: val_loss -0.7752 
2025-01-12 16:07:21.285580: Pseudo dice [np.float32(0.8178)] 
2025-01-12 16:07:21.289746: Epoch time: 42.28 s 
2025-01-12 16:07:21.292777: Yayy! New best EMA pseudo Dice: 0.8029000163078308 
2025-01-12 16:07:22.134095:  
2025-01-12 16:07:22.134095: Epoch 253 
2025-01-12 16:07:22.139751: Current learning rate: 0.0053 
2025-01-12 16:08:04.386880: train_loss -0.8666 
2025-01-12 16:08:04.387399: val_loss -0.7991 
2025-01-12 16:08:04.393416: Pseudo dice [np.float32(0.8421)] 
2025-01-12 16:08:04.395922: Epoch time: 42.25 s 
2025-01-12 16:08:04.399931: Yayy! New best EMA pseudo Dice: 0.8068000078201294 
2025-01-12 16:08:05.220979:  
2025-01-12 16:08:05.221485: Epoch 254 
2025-01-12 16:08:05.227132: Current learning rate: 0.00528 
2025-01-12 16:08:47.480524: train_loss -0.8583 
2025-01-12 16:08:47.481033: val_loss -0.7678 
2025-01-12 16:08:47.486570: Pseudo dice [np.float32(0.8227)] 
2025-01-12 16:08:47.489171: Epoch time: 42.26 s 
2025-01-12 16:08:47.492683: Yayy! New best EMA pseudo Dice: 0.8083999752998352 
2025-01-12 16:08:48.278296:  
2025-01-12 16:08:48.279299: Epoch 255 
2025-01-12 16:08:48.284368: Current learning rate: 0.00526 
2025-01-12 16:09:30.554869: train_loss -0.8683 
2025-01-12 16:09:30.555873: val_loss -0.674 
2025-01-12 16:09:30.561544: Pseudo dice [np.float32(0.7407)] 
2025-01-12 16:09:30.564590: Epoch time: 42.28 s 
2025-01-12 16:09:31.290227:  
2025-01-12 16:09:31.290227: Epoch 256 
2025-01-12 16:09:31.295767: Current learning rate: 0.00524 
2025-01-12 16:10:13.546507: train_loss -0.8723 
2025-01-12 16:10:13.546507: val_loss -0.7028 
2025-01-12 16:10:13.552612: Pseudo dice [np.float32(0.7586)] 
2025-01-12 16:10:13.555581: Epoch time: 42.26 s 
2025-01-12 16:10:14.132747:  
2025-01-12 16:10:14.133262: Epoch 257 
2025-01-12 16:10:14.137872: Current learning rate: 0.00522 
2025-01-12 16:10:56.395914: train_loss -0.854 
2025-01-12 16:10:56.395914: val_loss -0.7816 
2025-01-12 16:10:56.401012: Pseudo dice [np.float32(0.8287)] 
2025-01-12 16:10:56.405023: Epoch time: 42.26 s 
2025-01-12 16:10:56.977647:  
2025-01-12 16:10:56.977647: Epoch 258 
2025-01-12 16:10:56.982658: Current learning rate: 0.0052 
2025-01-12 16:11:39.281425: train_loss -0.8278 
2025-01-12 16:11:39.282428: val_loss -0.6744 
2025-01-12 16:11:39.288067: Pseudo dice [np.float32(0.7442)] 
2025-01-12 16:11:39.291607: Epoch time: 42.3 s 
2025-01-12 16:11:39.866167:  
2025-01-12 16:11:39.866677: Epoch 259 
2025-01-12 16:11:39.871249: Current learning rate: 0.00518 
2025-01-12 16:12:22.123626: train_loss -0.7985 
2025-01-12 16:12:22.124629: val_loss -0.754 
2025-01-12 16:12:22.129838: Pseudo dice [np.float32(0.8013)] 
2025-01-12 16:12:22.133374: Epoch time: 42.26 s 
2025-01-12 16:12:22.711272:  
2025-01-12 16:12:22.712272: Epoch 260 
2025-01-12 16:12:22.716841: Current learning rate: 0.00517 
2025-01-12 16:13:04.975374: train_loss -0.8042 
2025-01-12 16:13:04.976377: val_loss -0.6551 
2025-01-12 16:13:04.981488: Pseudo dice [np.float32(0.6451)] 
2025-01-12 16:13:04.985001: Epoch time: 42.26 s 
2025-01-12 16:13:05.561233:  
2025-01-12 16:13:05.561233: Epoch 261 
2025-01-12 16:13:05.566339: Current learning rate: 0.00515 
2025-01-12 16:13:47.830725: train_loss -0.7875 
2025-01-12 16:13:47.831236: val_loss -0.7471 
2025-01-12 16:13:47.836882: Pseudo dice [np.float32(0.7967)] 
2025-01-12 16:13:47.840397: Epoch time: 42.27 s 
2025-01-12 16:13:48.422284:  
2025-01-12 16:13:48.423287: Epoch 262 
2025-01-12 16:13:48.428444: Current learning rate: 0.00513 
2025-01-12 16:14:30.691413: train_loss -0.8269 
2025-01-12 16:14:30.691920: val_loss -0.7781 
2025-01-12 16:14:30.697591: Pseudo dice [np.float32(0.8203)] 
2025-01-12 16:14:30.700623: Epoch time: 42.27 s 
2025-01-12 16:14:31.280890:  
2025-01-12 16:14:31.280890: Epoch 263 
2025-01-12 16:14:31.284925: Current learning rate: 0.00511 
2025-01-12 16:15:13.526657: train_loss -0.8469 
2025-01-12 16:15:13.527169: val_loss -0.772 
2025-01-12 16:15:13.532734: Pseudo dice [np.float32(0.8212)] 
2025-01-12 16:15:13.535774: Epoch time: 42.25 s 
2025-01-12 16:15:14.267813:  
2025-01-12 16:15:14.268817: Epoch 264 
2025-01-12 16:15:14.274423: Current learning rate: 0.00509 
2025-01-12 16:15:56.505448: train_loss -0.8066 
2025-01-12 16:15:56.506029: val_loss -0.7548 
2025-01-12 16:15:56.511681: Pseudo dice [np.float32(0.8023)] 
2025-01-12 16:15:56.515244: Epoch time: 42.24 s 
2025-01-12 16:15:57.092254:  
2025-01-12 16:15:57.092254: Epoch 265 
2025-01-12 16:15:57.097401: Current learning rate: 0.00507 
2025-01-12 16:16:39.347016: train_loss -0.7803 
2025-01-12 16:16:39.347016: val_loss -0.7234 
2025-01-12 16:16:39.352628: Pseudo dice [np.float32(0.7783)] 
2025-01-12 16:16:39.355675: Epoch time: 42.26 s 
2025-01-12 16:16:39.932416:  
2025-01-12 16:16:39.932920: Epoch 266 
2025-01-12 16:16:39.937512: Current learning rate: 0.00505 
2025-01-12 16:17:22.185270: train_loss -0.825 
2025-01-12 16:17:22.185773: val_loss -0.7135 
2025-01-12 16:17:22.191520: Pseudo dice [np.float32(0.7825)] 
2025-01-12 16:17:22.195026: Epoch time: 42.25 s 
2025-01-12 16:17:22.768550:  
2025-01-12 16:17:22.769554: Epoch 267 
2025-01-12 16:17:22.774646: Current learning rate: 0.00503 
2025-01-12 16:18:05.020875: train_loss -0.8344 
2025-01-12 16:18:05.021898: val_loss -0.7166 
2025-01-12 16:18:05.027112: Pseudo dice [np.float32(0.7837)] 
2025-01-12 16:18:05.030155: Epoch time: 42.25 s 
2025-01-12 16:18:05.609234:  
2025-01-12 16:18:05.609234: Epoch 268 
2025-01-12 16:18:05.614925: Current learning rate: 0.00501 
2025-01-12 16:18:47.879939: train_loss -0.8194 
2025-01-12 16:18:47.880442: val_loss -0.6554 
2025-01-12 16:18:47.886057: Pseudo dice [np.float32(0.7347)] 
2025-01-12 16:18:47.889674: Epoch time: 42.27 s 
2025-01-12 16:18:48.467982:  
2025-01-12 16:18:48.468982: Epoch 269 
2025-01-12 16:18:48.474599: Current learning rate: 0.00499 
2025-01-12 16:19:30.733305: train_loss -0.8317 
2025-01-12 16:19:30.733305: val_loss -0.7142 
2025-01-12 16:19:30.739448: Pseudo dice [np.float32(0.7775)] 
2025-01-12 16:19:30.743003: Epoch time: 42.27 s 
2025-01-12 16:19:31.319835:  
2025-01-12 16:19:31.319835: Epoch 270 
2025-01-12 16:19:31.325397: Current learning rate: 0.00497 
2025-01-12 16:20:10.247375: train_loss -0.827 
2025-01-12 16:20:10.247886: val_loss -0.6533 
2025-01-12 16:20:10.253057: Pseudo dice [np.float32(0.7313)] 
2025-01-12 16:20:10.256580: Epoch time: 38.93 s 
2025-01-12 16:20:10.839259:  
2025-01-12 16:20:10.839259: Epoch 271 
2025-01-12 16:20:10.844934: Current learning rate: 0.00495 
2025-01-12 16:20:53.103158: train_loss -0.8421 
2025-01-12 16:20:53.104660: val_loss -0.7612 
2025-01-12 16:20:53.109672: Pseudo dice [np.float32(0.8113)] 
2025-01-12 16:20:53.113777: Epoch time: 42.26 s 
2025-01-12 16:20:53.841615:  
2025-01-12 16:20:53.841615: Epoch 272 
2025-01-12 16:20:53.849226: Current learning rate: 0.00493 
2025-01-12 16:21:36.132004: train_loss -0.8457 
2025-01-12 16:21:36.132584: val_loss -0.7024 
2025-01-12 16:21:36.138181: Pseudo dice [np.float32(0.7442)] 
2025-01-12 16:21:36.141228: Epoch time: 42.29 s 
2025-01-12 16:21:36.722572:  
2025-01-12 16:21:36.722572: Epoch 273 
2025-01-12 16:21:36.728710: Current learning rate: 0.00491 
2025-01-12 16:22:18.964432: train_loss -0.8374 
2025-01-12 16:22:18.964432: val_loss -0.7175 
2025-01-12 16:22:18.971083: Pseudo dice [np.float32(0.7672)] 
2025-01-12 16:22:18.974693: Epoch time: 42.24 s 
2025-01-12 16:22:19.551932:  
2025-01-12 16:22:19.551932: Epoch 274 
2025-01-12 16:22:19.559176: Current learning rate: 0.00489 
2025-01-12 16:23:01.814534: train_loss -0.8476 
2025-01-12 16:23:01.815535: val_loss -0.7871 
2025-01-12 16:23:01.821048: Pseudo dice [np.float32(0.8283)] 
2025-01-12 16:23:01.823671: Epoch time: 42.26 s 
2025-01-12 16:23:02.404253:  
2025-01-12 16:23:02.405257: Epoch 275 
2025-01-12 16:23:02.409819: Current learning rate: 0.00487 
2025-01-12 16:23:44.675338: train_loss -0.8658 
2025-01-12 16:23:44.675850: val_loss -0.7093 
2025-01-12 16:23:44.680925: Pseudo dice [np.float32(0.7764)] 
2025-01-12 16:23:44.684068: Epoch time: 42.27 s 
2025-01-12 16:23:45.285731:  
2025-01-12 16:23:45.286251: Epoch 276 
2025-01-12 16:23:45.291334: Current learning rate: 0.00485 
2025-01-12 16:24:27.587542: train_loss -0.868 
2025-01-12 16:24:27.587542: val_loss -0.6893 
2025-01-12 16:24:27.593559: Pseudo dice [np.float32(0.77)] 
2025-01-12 16:24:27.596568: Epoch time: 42.3 s 
2025-01-12 16:24:28.183400:  
2025-01-12 16:24:28.183909: Epoch 277 
2025-01-12 16:24:28.188458: Current learning rate: 0.00484 
2025-01-12 16:25:10.452171: train_loss -0.8565 
2025-01-12 16:25:10.452731: val_loss -0.69 
2025-01-12 16:25:10.457803: Pseudo dice [np.float32(0.771)] 
2025-01-12 16:25:10.461833: Epoch time: 42.27 s 
2025-01-12 16:25:11.048627:  
2025-01-12 16:25:11.048627: Epoch 278 
2025-01-12 16:25:11.054717: Current learning rate: 0.00482 
2025-01-12 16:25:53.327413: train_loss -0.8613 
2025-01-12 16:25:53.327413: val_loss -0.728 
2025-01-12 16:25:53.334107: Pseudo dice [np.float32(0.7864)] 
2025-01-12 16:25:53.337168: Epoch time: 42.28 s 
2025-01-12 16:25:53.923273:  
2025-01-12 16:25:53.923273: Epoch 279 
2025-01-12 16:25:53.928823: Current learning rate: 0.0048 
2025-01-12 16:26:36.232099: train_loss -0.8633 
2025-01-12 16:26:36.233103: val_loss -0.761 
2025-01-12 16:26:36.238215: Pseudo dice [np.float32(0.806)] 
2025-01-12 16:26:36.241722: Epoch time: 42.31 s 
2025-01-12 16:26:36.975975:  
2025-01-12 16:26:36.975975: Epoch 280 
2025-01-12 16:26:36.982024: Current learning rate: 0.00478 
2025-01-12 16:27:19.250353: train_loss -0.8565 
2025-01-12 16:27:19.251351: val_loss -0.6284 
2025-01-12 16:27:19.256492: Pseudo dice [np.float32(0.7139)] 
2025-01-12 16:27:19.260044: Epoch time: 42.27 s 
2025-01-12 16:27:19.840269:  
2025-01-12 16:27:19.840771: Epoch 281 
2025-01-12 16:27:19.846397: Current learning rate: 0.00476 
2025-01-12 16:28:02.098869: train_loss -0.8666 
2025-01-12 16:28:02.099371: val_loss -0.7146 
2025-01-12 16:28:02.105007: Pseudo dice [np.float32(0.7704)] 
2025-01-12 16:28:02.108056: Epoch time: 42.26 s 
2025-01-12 16:28:02.687266:  
2025-01-12 16:28:02.687266: Epoch 282 
2025-01-12 16:28:02.692935: Current learning rate: 0.00474 
2025-01-12 16:28:44.975015: train_loss -0.8709 
2025-01-12 16:28:44.975015: val_loss -0.7913 
2025-01-12 16:28:44.981554: Pseudo dice [np.float32(0.8398)] 
2025-01-12 16:28:44.984174: Epoch time: 42.29 s 
2025-01-12 16:28:45.567679:  
2025-01-12 16:28:45.569182: Epoch 283 
2025-01-12 16:28:45.574284: Current learning rate: 0.00472 
2025-01-12 16:29:27.797649: train_loss -0.8455 
2025-01-12 16:29:27.797649: val_loss -0.7083 
2025-01-12 16:29:27.803751: Pseudo dice [np.float32(0.7723)] 
2025-01-12 16:29:27.807266: Epoch time: 42.23 s 
2025-01-12 16:29:28.387989:  
2025-01-12 16:29:28.388492: Epoch 284 
2025-01-12 16:29:28.393638: Current learning rate: 0.0047 
2025-01-12 16:30:10.646521: train_loss -0.8358 
2025-01-12 16:30:10.647525: val_loss -0.7555 
2025-01-12 16:30:10.654139: Pseudo dice [np.float32(0.8092)] 
2025-01-12 16:30:10.657772: Epoch time: 42.26 s 
2025-01-12 16:30:11.246142:  
2025-01-12 16:30:11.246142: Epoch 285 
2025-01-12 16:30:11.251154: Current learning rate: 0.00468 
2025-01-12 16:30:53.499845: train_loss -0.8238 
2025-01-12 16:30:53.500351: val_loss -0.7024 
2025-01-12 16:30:53.505998: Pseudo dice [np.float32(0.7683)] 
2025-01-12 16:30:53.509030: Epoch time: 42.26 s 
2025-01-12 16:30:54.091836:  
2025-01-12 16:30:54.092840: Epoch 286 
2025-01-12 16:30:54.098250: Current learning rate: 0.00466 
2025-01-12 16:31:36.375563: train_loss -0.8553 
2025-01-12 16:31:36.376074: val_loss -0.7265 
2025-01-12 16:31:36.381149: Pseudo dice [np.float32(0.7771)] 
2025-01-12 16:31:36.384749: Epoch time: 42.28 s 
2025-01-12 16:31:36.973419:  
2025-01-12 16:31:36.973419: Epoch 287 
2025-01-12 16:31:36.979502: Current learning rate: 0.00464 
2025-01-12 16:32:19.252703: train_loss -0.8321 
2025-01-12 16:32:19.253287: val_loss -0.6807 
2025-01-12 16:32:19.258382: Pseudo dice [np.float32(0.7481)] 
2025-01-12 16:32:19.261909: Epoch time: 42.28 s 
2025-01-12 16:32:20.009158:  
2025-01-12 16:32:20.009158: Epoch 288 
2025-01-12 16:32:20.013776: Current learning rate: 0.00462 
2025-01-12 16:33:02.277255: train_loss -0.8371 
2025-01-12 16:33:02.277255: val_loss -0.7157 
2025-01-12 16:33:02.283350: Pseudo dice [np.float32(0.7713)] 
2025-01-12 16:33:02.286366: Epoch time: 42.27 s 
2025-01-12 16:33:02.875948:  
2025-01-12 16:33:02.876450: Epoch 289 
2025-01-12 16:33:02.880958: Current learning rate: 0.0046 
2025-01-12 16:33:45.135164: train_loss -0.8477 
2025-01-12 16:33:45.136167: val_loss -0.7716 
2025-01-12 16:33:45.141206: Pseudo dice [np.float32(0.8177)] 
2025-01-12 16:33:45.144386: Epoch time: 42.26 s 
2025-01-12 16:33:45.728257:  
2025-01-12 16:33:45.728257: Epoch 290 
2025-01-12 16:33:45.733966: Current learning rate: 0.00458 
2025-01-12 16:34:28.011754: train_loss -0.8619 
2025-01-12 16:34:28.012262: val_loss -0.6898 
2025-01-12 16:34:28.017959: Pseudo dice [np.float32(0.7728)] 
2025-01-12 16:34:28.021026: Epoch time: 42.28 s 
2025-01-12 16:34:28.610990:  
2025-01-12 16:34:28.610990: Epoch 291 
2025-01-12 16:34:28.616654: Current learning rate: 0.00456 
2025-01-12 16:35:13.181183: train_loss -0.8685 
2025-01-12 16:35:13.181183: val_loss -0.7093 
2025-01-12 16:35:13.188397: Pseudo dice [np.float32(0.7798)] 
2025-01-12 16:35:13.193502: Epoch time: 44.57 s 
2025-01-12 16:35:13.779931:  
2025-01-12 16:35:13.779931: Epoch 292 
2025-01-12 16:35:13.785550: Current learning rate: 0.00454 
2025-01-12 16:35:56.035912: train_loss -0.8506 
2025-01-12 16:35:56.035912: val_loss -0.7477 
2025-01-12 16:35:56.041927: Pseudo dice [np.float32(0.7934)] 
2025-01-12 16:35:56.045936: Epoch time: 42.26 s 
2025-01-12 16:35:56.635582:  
2025-01-12 16:35:56.635582: Epoch 293 
2025-01-12 16:35:56.641149: Current learning rate: 0.00452 
2025-01-12 16:36:38.896120: train_loss -0.8426 
2025-01-12 16:36:38.896120: val_loss -0.7035 
2025-01-12 16:36:38.902137: Pseudo dice [np.float32(0.772)] 
2025-01-12 16:36:38.904770: Epoch time: 42.26 s 
2025-01-12 16:36:39.496211:  
2025-01-12 16:36:39.496718: Epoch 294 
2025-01-12 16:36:39.501285: Current learning rate: 0.0045 
2025-01-12 16:37:21.775006: train_loss -0.8632 
2025-01-12 16:37:21.775526: val_loss -0.653 
2025-01-12 16:37:21.781598: Pseudo dice [np.float32(0.7421)] 
2025-01-12 16:37:21.784722: Epoch time: 42.28 s 
2025-01-12 16:37:22.378416:  
2025-01-12 16:37:22.378416: Epoch 295 
2025-01-12 16:37:22.383508: Current learning rate: 0.00448 
2025-01-12 16:38:04.658128: train_loss -0.8713 
2025-01-12 16:38:04.658637: val_loss -0.7195 
2025-01-12 16:38:04.663850: Pseudo dice [np.float32(0.7743)] 
2025-01-12 16:38:04.667426: Epoch time: 42.28 s 
2025-01-12 16:38:05.416439:  
2025-01-12 16:38:05.416439: Epoch 296 
2025-01-12 16:38:05.421453: Current learning rate: 0.00446 
2025-01-12 16:38:47.702660: train_loss -0.8645 
2025-01-12 16:38:47.703172: val_loss -0.6739 
2025-01-12 16:38:47.709292: Pseudo dice [np.float32(0.7546)] 
2025-01-12 16:38:47.712322: Epoch time: 42.29 s 
2025-01-12 16:38:48.302613:  
2025-01-12 16:38:48.302613: Epoch 297 
2025-01-12 16:38:48.307153: Current learning rate: 0.00444 
2025-01-12 16:39:30.622177: train_loss -0.8707 
2025-01-12 16:39:30.622177: val_loss -0.705 
2025-01-12 16:39:30.629340: Pseudo dice [np.float32(0.7754)] 
2025-01-12 16:39:30.631846: Epoch time: 42.32 s 
2025-01-12 16:39:31.226637:  
2025-01-12 16:39:31.226637: Epoch 298 
2025-01-12 16:39:31.231690: Current learning rate: 0.00442 
2025-01-12 16:40:13.530205: train_loss -0.8605 
2025-01-12 16:40:13.530714: val_loss -0.7664 
2025-01-12 16:40:13.535869: Pseudo dice [np.float32(0.8107)] 
2025-01-12 16:40:13.539897: Epoch time: 42.3 s 
2025-01-12 16:40:14.135561:  
2025-01-12 16:40:14.136064: Epoch 299 
2025-01-12 16:40:14.140623: Current learning rate: 0.0044 
2025-01-12 16:40:56.461330: train_loss -0.8757 
2025-01-12 16:40:56.461836: val_loss -0.729 
2025-01-12 16:40:56.467477: Pseudo dice [np.float32(0.7913)] 
2025-01-12 16:40:56.471008: Epoch time: 42.33 s 
2025-01-12 16:40:57.314768:  
2025-01-12 16:40:57.315090: Epoch 300 
2025-01-12 16:40:57.318680: Current learning rate: 0.00438 
2025-01-12 16:41:39.617268: train_loss -0.872 
2025-01-12 16:41:39.618271: val_loss -0.766 
2025-01-12 16:41:39.623541: Pseudo dice [np.float32(0.8238)] 
2025-01-12 16:41:39.627082: Epoch time: 42.3 s 
2025-01-12 16:41:40.234837:  
2025-01-12 16:41:40.234837: Epoch 301 
2025-01-12 16:41:40.241132: Current learning rate: 0.00436 
2025-01-12 16:42:22.535688: train_loss -0.8785 
2025-01-12 16:42:22.536213: val_loss -0.6716 
2025-01-12 16:42:22.541305: Pseudo dice [np.float32(0.7429)] 
2025-01-12 16:42:22.544425: Epoch time: 42.3 s 
2025-01-12 16:42:23.153752:  
2025-01-12 16:42:23.154085: Epoch 302 
2025-01-12 16:42:23.159172: Current learning rate: 0.00434 
2025-01-12 16:43:05.485819: train_loss -0.8724 
2025-01-12 16:43:05.486822: val_loss -0.677 
2025-01-12 16:43:05.491969: Pseudo dice [np.float32(0.7545)] 
2025-01-12 16:43:05.495615: Epoch time: 42.33 s 
2025-01-12 16:43:06.102120:  
2025-01-12 16:43:06.102623: Epoch 303 
2025-01-12 16:43:06.107259: Current learning rate: 0.00432 
2025-01-12 16:43:48.416665: train_loss -0.8648 
2025-01-12 16:43:48.417176: val_loss -0.7371 
2025-01-12 16:43:48.422995: Pseudo dice [np.float32(0.7834)] 
2025-01-12 16:43:48.426581: Epoch time: 42.32 s 
2025-01-12 16:43:49.017267:  
2025-01-12 16:43:49.017267: Epoch 304 
2025-01-12 16:43:49.022323: Current learning rate: 0.0043 
2025-01-12 16:44:31.336813: train_loss -0.8724 
2025-01-12 16:44:31.337337: val_loss -0.6384 
2025-01-12 16:44:31.344033: Pseudo dice [np.float32(0.7205)] 
2025-01-12 16:44:31.347125: Epoch time: 42.32 s 
2025-01-12 16:44:32.096662:  
2025-01-12 16:44:32.096662: Epoch 305 
2025-01-12 16:44:32.101172: Current learning rate: 0.00429 
2025-01-12 16:45:14.405647: train_loss -0.8675 
2025-01-12 16:45:14.406157: val_loss -0.7584 
2025-01-12 16:45:14.411252: Pseudo dice [np.float32(0.8042)] 
2025-01-12 16:45:14.414409: Epoch time: 42.31 s 
2025-01-12 16:45:15.006000:  
2025-01-12 16:45:15.006514: Epoch 306 
2025-01-12 16:45:15.011608: Current learning rate: 0.00427 
2025-01-12 16:45:57.360204: train_loss -0.8681 
2025-01-12 16:45:57.360725: val_loss -0.724 
2025-01-12 16:45:57.365874: Pseudo dice [np.float32(0.787)] 
2025-01-12 16:45:57.369932: Epoch time: 42.35 s 
2025-01-12 16:45:57.973327:  
2025-01-12 16:45:57.974839: Epoch 307 
2025-01-12 16:45:57.979401: Current learning rate: 0.00425 
2025-01-12 16:46:40.304324: train_loss -0.8746 
2025-01-12 16:46:40.305357: val_loss -0.6598 
2025-01-12 16:46:40.310561: Pseudo dice [np.float32(0.7434)] 
2025-01-12 16:46:40.314345: Epoch time: 42.33 s 
2025-01-12 16:46:40.912814:  
2025-01-12 16:46:40.913319: Epoch 308 
2025-01-12 16:46:40.918391: Current learning rate: 0.00423 
2025-01-12 16:47:23.236816: train_loss -0.8787 
2025-01-12 16:47:23.236816: val_loss -0.7203 
2025-01-12 16:47:23.241829: Pseudo dice [np.float32(0.787)] 
2025-01-12 16:47:23.246068: Epoch time: 42.33 s 
2025-01-12 16:47:23.835150:  
2025-01-12 16:47:23.836149: Epoch 309 
2025-01-12 16:47:23.841718: Current learning rate: 0.00421 
2025-01-12 16:48:06.128310: train_loss -0.8732 
2025-01-12 16:48:06.128815: val_loss -0.7616 
2025-01-12 16:48:06.134491: Pseudo dice [np.float32(0.8247)] 
2025-01-12 16:48:06.137558: Epoch time: 42.29 s 
2025-01-12 16:48:06.738138:  
2025-01-12 16:48:06.739647: Epoch 310 
2025-01-12 16:48:06.743761: Current learning rate: 0.00419 
2025-01-12 16:48:49.031693: train_loss -0.8825 
2025-01-12 16:48:49.032205: val_loss -0.6893 
2025-01-12 16:48:49.038396: Pseudo dice [np.float32(0.7788)] 
2025-01-12 16:48:49.041453: Epoch time: 42.29 s 
2025-01-12 16:48:49.650265:  
2025-01-12 16:48:49.650265: Epoch 311 
2025-01-12 16:48:49.655915: Current learning rate: 0.00417 
2025-01-12 16:49:31.997725: train_loss -0.8768 
2025-01-12 16:49:31.998244: val_loss -0.717 
2025-01-12 16:49:32.003887: Pseudo dice [np.float32(0.7811)] 
2025-01-12 16:49:32.006913: Epoch time: 42.35 s 
2025-01-12 16:49:32.616363:  
2025-01-12 16:49:32.616873: Epoch 312 
2025-01-12 16:49:32.621915: Current learning rate: 0.00415 
2025-01-12 16:50:14.977572: train_loss -0.8808 
2025-01-12 16:50:14.978081: val_loss -0.7255 
2025-01-12 16:50:14.984216: Pseudo dice [np.float32(0.7705)] 
2025-01-12 16:50:14.987766: Epoch time: 42.36 s 
2025-01-12 16:50:15.745538:  
2025-01-12 16:50:15.746055: Epoch 313 
2025-01-12 16:50:15.750657: Current learning rate: 0.00413 
2025-01-12 16:50:58.037843: train_loss -0.8674 
2025-01-12 16:50:58.037843: val_loss -0.7739 
2025-01-12 16:50:58.044510: Pseudo dice [np.float32(0.8157)] 
2025-01-12 16:50:58.048105: Epoch time: 42.29 s 
2025-01-12 16:50:58.657327:  
2025-01-12 16:50:58.657327: Epoch 314 
2025-01-12 16:50:58.662443: Current learning rate: 0.00411 
2025-01-12 16:51:40.988155: train_loss -0.8691 
2025-01-12 16:51:40.989178: val_loss -0.6828 
2025-01-12 16:51:40.994334: Pseudo dice [np.float32(0.7509)] 
2025-01-12 16:51:40.997864: Epoch time: 42.33 s 
2025-01-12 16:51:41.599793:  
2025-01-12 16:51:41.599793: Epoch 315 
2025-01-12 16:51:41.605913: Current learning rate: 0.00409 
2025-01-12 16:52:23.908994: train_loss -0.8741 
2025-01-12 16:52:23.909496: val_loss -0.7176 
2025-01-12 16:52:23.914666: Pseudo dice [np.float32(0.7838)] 
2025-01-12 16:52:23.918698: Epoch time: 42.31 s 
2025-01-12 16:52:24.540523:  
2025-01-12 16:52:24.540523: Epoch 316 
2025-01-12 16:52:24.547048: Current learning rate: 0.00407 
2025-01-12 16:53:06.850312: train_loss -0.8672 
2025-01-12 16:53:06.850820: val_loss -0.6779 
2025-01-12 16:53:06.856522: Pseudo dice [np.float32(0.7634)] 
2025-01-12 16:53:06.860597: Epoch time: 42.31 s 
2025-01-12 16:53:07.459985:  
2025-01-12 16:53:07.459985: Epoch 317 
2025-01-12 16:53:07.465692: Current learning rate: 0.00405 
2025-01-12 16:53:49.753038: train_loss -0.8694 
2025-01-12 16:53:49.753553: val_loss -0.6817 
2025-01-12 16:53:49.758653: Pseudo dice [np.float32(0.7468)] 
2025-01-12 16:53:49.761697: Epoch time: 42.29 s 
2025-01-12 16:53:50.354194:  
2025-01-12 16:53:50.355200: Epoch 318 
2025-01-12 16:53:50.359752: Current learning rate: 0.00403 
2025-01-12 16:54:32.689730: train_loss -0.8738 
2025-01-12 16:54:32.690242: val_loss -0.7211 
2025-01-12 16:54:32.694888: Pseudo dice [np.float32(0.7953)] 
2025-01-12 16:54:32.698914: Epoch time: 42.34 s 
2025-01-12 16:54:33.294421:  
2025-01-12 16:54:33.294421: Epoch 319 
2025-01-12 16:54:33.299471: Current learning rate: 0.00401 
2025-01-12 16:55:15.625590: train_loss -0.8617 
2025-01-12 16:55:15.626594: val_loss -0.7448 
2025-01-12 16:55:15.632611: Pseudo dice [np.float32(0.7981)] 
2025-01-12 16:55:15.635704: Epoch time: 42.33 s 
2025-01-12 16:55:16.226758:  
2025-01-12 16:55:16.227763: Epoch 320 
2025-01-12 16:55:16.232913: Current learning rate: 0.00399 
2025-01-12 16:55:58.529079: train_loss -0.8504 
2025-01-12 16:55:58.529601: val_loss -0.7292 
2025-01-12 16:55:58.535305: Pseudo dice [np.float32(0.7916)] 
2025-01-12 16:55:58.538419: Epoch time: 42.3 s 
2025-01-12 16:55:59.285624:  
2025-01-12 16:55:59.286136: Epoch 321 
2025-01-12 16:55:59.291211: Current learning rate: 0.00397 
2025-01-12 16:56:41.616049: train_loss -0.8569 
2025-01-12 16:56:41.616558: val_loss -0.7755 
2025-01-12 16:56:41.622133: Pseudo dice [np.float32(0.8228)] 
2025-01-12 16:56:41.625287: Epoch time: 42.33 s 
2025-01-12 16:56:42.218241:  
2025-01-12 16:56:42.218745: Epoch 322 
2025-01-12 16:56:42.223315: Current learning rate: 0.00395 
2025-01-12 16:57:24.541676: train_loss -0.8608 
2025-01-12 16:57:24.542986: val_loss -0.7183 
2025-01-12 16:57:24.548525: Pseudo dice [np.float32(0.7836)] 
2025-01-12 16:57:24.551538: Epoch time: 42.32 s 
2025-01-12 16:57:25.154503:  
2025-01-12 16:57:25.154503: Epoch 323 
2025-01-12 16:57:25.161074: Current learning rate: 0.00393 
2025-01-12 16:58:07.478321: train_loss -0.8769 
2025-01-12 16:58:07.479327: val_loss -0.7403 
2025-01-12 16:58:07.484975: Pseudo dice [np.float32(0.7898)] 
2025-01-12 16:58:07.488039: Epoch time: 42.32 s 
2025-01-12 16:58:08.092063:  
2025-01-12 16:58:08.092063: Epoch 324 
2025-01-12 16:58:08.097173: Current learning rate: 0.00391 
2025-01-12 16:58:50.380210: train_loss -0.862 
2025-01-12 16:58:50.380210: val_loss -0.7493 
2025-01-12 16:58:50.385906: Pseudo dice [np.float32(0.8039)] 
2025-01-12 16:58:50.389436: Epoch time: 42.29 s 
2025-01-12 16:58:50.997351:  
2025-01-12 16:58:50.998355: Epoch 325 
2025-01-12 16:58:51.003969: Current learning rate: 0.00389 
2025-01-12 16:59:33.307540: train_loss -0.8804 
2025-01-12 16:59:33.308046: val_loss -0.7488 
2025-01-12 16:59:33.313686: Pseudo dice [np.float32(0.8136)] 
2025-01-12 16:59:33.317221: Epoch time: 42.31 s 
2025-01-12 16:59:33.923925:  
2025-01-12 16:59:33.924928: Epoch 326 
2025-01-12 16:59:33.930008: Current learning rate: 0.00387 
2025-01-12 17:00:18.458487: train_loss -0.875 
2025-01-12 17:00:18.459495: val_loss -0.7491 
2025-01-12 17:00:18.464553: Pseudo dice [np.float32(0.7963)] 
2025-01-12 17:00:18.468567: Epoch time: 44.54 s 
2025-01-12 17:00:19.077506:  
2025-01-12 17:00:19.077506: Epoch 327 
2025-01-12 17:00:19.083522: Current learning rate: 0.00385 
2025-01-12 17:01:01.951278: train_loss -0.8596 
2025-01-12 17:01:01.951278: val_loss -0.6955 
2025-01-12 17:01:01.957389: Pseudo dice [np.float32(0.77)] 
2025-01-12 17:01:01.961487: Epoch time: 42.88 s 
2025-01-12 17:01:02.732848:  
2025-01-12 17:01:02.733365: Epoch 328 
2025-01-12 17:01:02.738420: Current learning rate: 0.00383 
2025-01-12 17:01:45.540377: train_loss -0.8713 
2025-01-12 17:01:45.540377: val_loss -0.6554 
2025-01-12 17:01:45.544992: Pseudo dice [np.float32(0.727)] 
2025-01-12 17:01:45.547506: Epoch time: 42.81 s 
2025-01-12 17:01:46.151906:  
2025-01-12 17:01:46.151906: Epoch 329 
2025-01-12 17:01:46.157456: Current learning rate: 0.00381 
2025-01-12 17:02:28.772069: train_loss -0.8825 
2025-01-12 17:02:28.772575: val_loss -0.7445 
2025-01-12 17:02:28.777661: Pseudo dice [np.float32(0.801)] 
2025-01-12 17:02:28.781755: Epoch time: 42.62 s 
2025-01-12 17:02:29.391534:  
2025-01-12 17:02:29.391534: Epoch 330 
2025-01-12 17:02:29.397614: Current learning rate: 0.00379 
2025-01-12 17:03:11.970600: train_loss -0.8826 
2025-01-12 17:03:11.971600: val_loss -0.6967 
2025-01-12 17:03:11.977118: Pseudo dice [np.float32(0.7489)] 
2025-01-12 17:03:11.979628: Epoch time: 42.58 s 
2025-01-12 17:03:12.599279:  
2025-01-12 17:03:12.599279: Epoch 331 
2025-01-12 17:03:12.605355: Current learning rate: 0.00377 
2025-01-12 17:03:55.202782: train_loss -0.8674 
2025-01-12 17:03:55.203285: val_loss -0.695 
2025-01-12 17:03:55.208912: Pseudo dice [np.float32(0.7582)] 
2025-01-12 17:03:55.211452: Epoch time: 42.6 s 
2025-01-12 17:03:55.832449:  
2025-01-12 17:03:55.832953: Epoch 332 
2025-01-12 17:03:55.837968: Current learning rate: 0.00375 
2025-01-12 17:04:38.410888: train_loss -0.8308 
2025-01-12 17:04:38.410888: val_loss -0.7205 
2025-01-12 17:04:38.417011: Pseudo dice [np.float32(0.7665)] 
2025-01-12 17:04:38.419168: Epoch time: 42.58 s 
2025-01-12 17:04:39.035597:  
2025-01-12 17:04:39.036602: Epoch 333 
2025-01-12 17:04:39.041125: Current learning rate: 0.00373 
2025-01-12 17:05:21.653674: train_loss -0.8402 
2025-01-12 17:05:21.654673: val_loss -0.7177 
2025-01-12 17:05:21.660191: Pseudo dice [np.float32(0.7709)] 
2025-01-12 17:05:21.663701: Epoch time: 42.62 s 
2025-01-12 17:05:22.275675:  
2025-01-12 17:05:22.275675: Epoch 334 
2025-01-12 17:05:22.280687: Current learning rate: 0.00371 
2025-01-12 17:06:04.844775: train_loss -0.8578 
2025-01-12 17:06:04.845283: val_loss -0.7551 
2025-01-12 17:06:04.850899: Pseudo dice [np.float32(0.8117)] 
2025-01-12 17:06:04.854415: Epoch time: 42.57 s 
2025-01-12 17:06:05.474168:  
2025-01-12 17:06:05.475172: Epoch 335 
2025-01-12 17:06:05.479729: Current learning rate: 0.00369 
2025-01-12 17:06:48.269638: train_loss -0.8616 
2025-01-12 17:06:48.270143: val_loss -0.7236 
2025-01-12 17:06:48.275161: Pseudo dice [np.float32(0.7734)] 
2025-01-12 17:06:48.278679: Epoch time: 42.8 s 
2025-01-12 17:06:49.065233:  
2025-01-12 17:06:49.066236: Epoch 336 
2025-01-12 17:06:49.071767: Current learning rate: 0.00367 
2025-01-12 17:07:31.979089: train_loss -0.8714 
2025-01-12 17:07:31.979592: val_loss -0.7279 
2025-01-12 17:07:31.985162: Pseudo dice [np.float32(0.7771)] 
2025-01-12 17:07:31.989727: Epoch time: 42.91 s 
2025-01-12 17:07:32.563637:  
2025-01-12 17:07:32.563637: Epoch 337 
2025-01-12 17:07:32.569201: Current learning rate: 0.00365 
2025-01-12 17:08:15.213098: train_loss -0.876 
2025-01-12 17:08:15.213098: val_loss -0.7622 
2025-01-12 17:08:15.218520: Pseudo dice [np.float32(0.8114)] 
2025-01-12 17:08:15.222033: Epoch time: 42.65 s 
2025-01-12 17:08:15.895919:  
2025-01-12 17:08:15.896919: Epoch 338 
2025-01-12 17:08:15.902550: Current learning rate: 0.00363 
2025-01-12 17:08:58.450848: train_loss -0.8631 
2025-01-12 17:08:58.451852: val_loss -0.6303 
2025-01-12 17:08:58.458066: Pseudo dice [np.float32(0.7018)] 
2025-01-12 17:08:58.462110: Epoch time: 42.56 s 
2025-01-12 17:08:59.046746:  
2025-01-12 17:08:59.046746: Epoch 339 
2025-01-12 17:08:59.051780: Current learning rate: 0.00361 
2025-01-12 17:09:41.594860: train_loss -0.8401 
2025-01-12 17:09:41.594860: val_loss -0.7101 
2025-01-12 17:09:41.600882: Pseudo dice [np.float32(0.7685)] 
2025-01-12 17:09:41.604398: Epoch time: 42.55 s 
2025-01-12 17:09:42.184597:  
2025-01-12 17:09:42.185100: Epoch 340 
2025-01-12 17:09:42.190113: Current learning rate: 0.00359 
2025-01-12 17:10:24.725361: train_loss -0.8385 
2025-01-12 17:10:24.726364: val_loss -0.6599 
2025-01-12 17:10:24.731376: Pseudo dice [np.float32(0.7182)] 
2025-01-12 17:10:24.735386: Epoch time: 42.54 s 
2025-01-12 17:10:25.310321:  
2025-01-12 17:10:25.311325: Epoch 341 
2025-01-12 17:10:25.317884: Current learning rate: 0.00357 
2025-01-12 17:11:07.884228: train_loss -0.8721 
2025-01-12 17:11:07.884731: val_loss -0.6359 
2025-01-12 17:11:07.889751: Pseudo dice [np.float32(0.7173)] 
2025-01-12 17:11:07.893264: Epoch time: 42.57 s 
2025-01-12 17:11:08.469397:  
2025-01-12 17:11:08.470400: Epoch 342 
2025-01-12 17:11:08.475490: Current learning rate: 0.00355 
2025-01-12 17:11:51.058979: train_loss -0.8732 
2025-01-12 17:11:51.059496: val_loss -0.737 
2025-01-12 17:11:51.064540: Pseudo dice [np.float32(0.7986)] 
2025-01-12 17:11:51.069143: Epoch time: 42.59 s 
2025-01-12 17:11:51.648478:  
2025-01-12 17:11:51.648980: Epoch 343 
2025-01-12 17:11:51.654103: Current learning rate: 0.00353 
2025-01-12 17:12:34.224343: train_loss -0.8793 
2025-01-12 17:12:34.224849: val_loss -0.7382 
2025-01-12 17:12:34.229889: Pseudo dice [np.float32(0.8114)] 
2025-01-12 17:12:34.234031: Epoch time: 42.58 s 
2025-01-12 17:12:34.972178:  
2025-01-12 17:12:34.972178: Epoch 344 
2025-01-12 17:12:34.978838: Current learning rate: 0.00351 
2025-01-12 17:13:17.296067: train_loss -0.8608 
2025-01-12 17:13:17.296573: val_loss -0.6815 
2025-01-12 17:13:17.301609: Pseudo dice [np.float32(0.7452)] 
2025-01-12 17:13:17.306622: Epoch time: 42.32 s 
2025-01-12 17:13:17.884419:  
2025-01-12 17:13:17.884419: Epoch 345 
2025-01-12 17:13:17.889570: Current learning rate: 0.00349 
2025-01-12 17:14:00.214052: train_loss -0.8624 
2025-01-12 17:14:00.214052: val_loss -0.692 
2025-01-12 17:14:00.220211: Pseudo dice [np.float32(0.766)] 
2025-01-12 17:14:00.224368: Epoch time: 42.33 s 
2025-01-12 17:14:00.794242:  
2025-01-12 17:14:00.794242: Epoch 346 
2025-01-12 17:14:00.799841: Current learning rate: 0.00346 
2025-01-12 17:14:43.125262: train_loss -0.8666 
2025-01-12 17:14:43.125262: val_loss -0.7092 
2025-01-12 17:14:43.130788: Pseudo dice [np.float32(0.7737)] 
2025-01-12 17:14:43.134965: Epoch time: 42.33 s 
2025-01-12 17:14:43.714104:  
2025-01-12 17:14:43.714614: Epoch 347 
2025-01-12 17:14:43.720196: Current learning rate: 0.00344 
2025-01-12 17:15:26.044982: train_loss -0.8598 
2025-01-12 17:15:26.045985: val_loss -0.7657 
2025-01-12 17:15:26.052559: Pseudo dice [np.float32(0.8097)] 
2025-01-12 17:15:26.056144: Epoch time: 42.33 s 
2025-01-12 17:15:26.632221:  
2025-01-12 17:15:26.633286: Epoch 348 
2025-01-12 17:15:26.637827: Current learning rate: 0.00342 
2025-01-12 17:16:08.944987: train_loss -0.8636 
2025-01-12 17:16:08.945987: val_loss -0.7524 
2025-01-12 17:16:08.951502: Pseudo dice [np.float32(0.8021)] 
2025-01-12 17:16:08.955084: Epoch time: 42.31 s 
2025-01-12 17:16:09.526699:  
2025-01-12 17:16:09.527202: Epoch 349 
2025-01-12 17:16:09.532917: Current learning rate: 0.0034 
2025-01-12 17:16:51.836996: train_loss -0.8696 
2025-01-12 17:16:51.837996: val_loss -0.7313 
2025-01-12 17:16:51.843512: Pseudo dice [np.float32(0.7919)] 
2025-01-12 17:16:51.847029: Epoch time: 42.31 s 
2025-01-12 17:16:52.639790:  
2025-01-12 17:16:52.639790: Epoch 350 
2025-01-12 17:16:52.645949: Current learning rate: 0.00338 
2025-01-12 17:17:34.978668: train_loss -0.8668 
2025-01-12 17:17:34.979180: val_loss -0.7178 
2025-01-12 17:17:34.987479: Pseudo dice [np.float32(0.7877)] 
2025-01-12 17:17:34.991564: Epoch time: 42.34 s 
2025-01-12 17:17:35.566967:  
2025-01-12 17:17:35.566967: Epoch 351 
2025-01-12 17:17:35.572002: Current learning rate: 0.00336 
2025-01-12 17:18:17.914442: train_loss -0.8697 
2025-01-12 17:18:17.914442: val_loss -0.7394 
2025-01-12 17:18:17.920554: Pseudo dice [np.float32(0.7891)] 
2025-01-12 17:18:17.923743: Epoch time: 42.35 s 
2025-01-12 17:18:18.655172:  
2025-01-12 17:18:18.655172: Epoch 352 
2025-01-12 17:18:18.660314: Current learning rate: 0.00334 
2025-01-12 17:19:00.990986: train_loss -0.8657 
2025-01-12 17:19:00.991497: val_loss -0.761 
2025-01-12 17:19:00.997278: Pseudo dice [np.float32(0.8045)] 
2025-01-12 17:19:01.000813: Epoch time: 42.34 s 
2025-01-12 17:19:01.570060:  
2025-01-12 17:19:01.570569: Epoch 353 
2025-01-12 17:19:01.574778: Current learning rate: 0.00332 
2025-01-12 17:19:43.878289: train_loss -0.8706 
2025-01-12 17:19:43.878799: val_loss -0.7242 
2025-01-12 17:19:43.884530: Pseudo dice [np.float32(0.7834)] 
2025-01-12 17:19:43.888067: Epoch time: 42.31 s 
2025-01-12 17:19:44.485900:  
2025-01-12 17:19:44.486899: Epoch 354 
2025-01-12 17:19:44.490416: Current learning rate: 0.0033 
2025-01-12 17:20:26.825830: train_loss -0.8776 
2025-01-12 17:20:26.826343: val_loss -0.7521 
2025-01-12 17:20:26.831425: Pseudo dice [np.float32(0.8101)] 
2025-01-12 17:20:26.834931: Epoch time: 42.34 s 
2025-01-12 17:20:27.418886:  
2025-01-12 17:20:27.418886: Epoch 355 
2025-01-12 17:20:27.424060: Current learning rate: 0.00328 
2025-01-12 17:21:09.737519: train_loss -0.8756 
2025-01-12 17:21:09.738027: val_loss -0.6897 
2025-01-12 17:21:09.743789: Pseudo dice [np.float32(0.7593)] 
2025-01-12 17:21:09.747374: Epoch time: 42.32 s 
2025-01-12 17:21:10.326771:  
2025-01-12 17:21:10.327284: Epoch 356 
2025-01-12 17:21:10.332369: Current learning rate: 0.00326 
2025-01-12 17:21:52.635848: train_loss -0.8774 
2025-01-12 17:21:52.636851: val_loss -0.7198 
2025-01-12 17:21:52.643475: Pseudo dice [np.float32(0.7914)] 
2025-01-12 17:21:52.648082: Epoch time: 42.31 s 
2025-01-12 17:21:53.218781:  
2025-01-12 17:21:53.218781: Epoch 357 
2025-01-12 17:21:53.223699: Current learning rate: 0.00324 
2025-01-12 17:22:35.563415: train_loss -0.872 
2025-01-12 17:22:35.564418: val_loss -0.7514 
2025-01-12 17:22:35.569957: Pseudo dice [np.float32(0.8065)] 
2025-01-12 17:22:35.573652: Epoch time: 42.35 s 
2025-01-12 17:22:36.151578:  
2025-01-12 17:22:36.152086: Epoch 358 
2025-01-12 17:22:36.157706: Current learning rate: 0.00322 
2025-01-12 17:23:18.502099: train_loss -0.8764 
2025-01-12 17:23:18.502099: val_loss -0.7657 
2025-01-12 17:23:18.508145: Pseudo dice [np.float32(0.8091)] 
2025-01-12 17:23:18.511779: Epoch time: 42.35 s 
2025-01-12 17:23:19.226534:  
2025-01-12 17:23:19.227539: Epoch 359 
2025-01-12 17:23:19.233075: Current learning rate: 0.0032 
2025-01-12 17:24:01.580638: train_loss -0.8719 
2025-01-12 17:24:01.581144: val_loss -0.7453 
2025-01-12 17:24:01.586679: Pseudo dice [np.float32(0.7989)] 
2025-01-12 17:24:01.590850: Epoch time: 42.35 s 
2025-01-12 17:24:02.164630:  
2025-01-12 17:24:02.164630: Epoch 360 
2025-01-12 17:24:02.169699: Current learning rate: 0.00318 
2025-01-12 17:24:44.503495: train_loss -0.8789 
2025-01-12 17:24:44.504009: val_loss -0.7482 
2025-01-12 17:24:44.510028: Pseudo dice [np.float32(0.7993)] 
2025-01-12 17:24:44.513538: Epoch time: 42.34 s 
2025-01-12 17:24:45.089926:  
2025-01-12 17:24:45.089926: Epoch 361 
2025-01-12 17:24:45.095374: Current learning rate: 0.00316 
2025-01-12 17:25:27.401959: train_loss -0.876 
2025-01-12 17:25:27.401959: val_loss -0.6871 
2025-01-12 17:25:27.408112: Pseudo dice [np.float32(0.7606)] 
2025-01-12 17:25:27.412125: Epoch time: 42.31 s 
2025-01-12 17:25:27.988241:  
2025-01-12 17:25:27.988241: Epoch 362 
2025-01-12 17:25:27.993897: Current learning rate: 0.00314 
2025-01-12 17:26:10.349872: train_loss -0.8743 
2025-01-12 17:26:10.349872: val_loss -0.7032 
2025-01-12 17:26:10.356253: Pseudo dice [np.float32(0.7533)] 
2025-01-12 17:26:10.361843: Epoch time: 42.36 s 
2025-01-12 17:26:10.938003:  
2025-01-12 17:26:10.938512: Epoch 363 
2025-01-12 17:26:10.943556: Current learning rate: 0.00312 
2025-01-12 17:26:53.267492: train_loss -0.8599 
2025-01-12 17:26:53.267492: val_loss -0.6976 
2025-01-12 17:26:53.274195: Pseudo dice [np.float32(0.7651)] 
2025-01-12 17:26:53.277230: Epoch time: 42.33 s 
2025-01-12 17:26:53.853611:  
2025-01-12 17:26:53.853611: Epoch 364 
2025-01-12 17:26:53.859628: Current learning rate: 0.0031 
2025-01-12 17:27:36.196575: train_loss -0.8708 
2025-01-12 17:27:36.196575: val_loss -0.7114 
2025-01-12 17:27:36.202192: Pseudo dice [np.float32(0.7751)] 
2025-01-12 17:27:36.207404: Epoch time: 42.34 s 
2025-01-12 17:27:36.782510:  
2025-01-12 17:27:36.783578: Epoch 365 
2025-01-12 17:27:36.789175: Current learning rate: 0.00308 
2025-01-12 17:28:19.129173: train_loss -0.8782 
2025-01-12 17:28:19.129173: val_loss -0.7537 
2025-01-12 17:28:19.135198: Pseudo dice [np.float32(0.8089)] 
2025-01-12 17:28:19.138430: Epoch time: 42.35 s 
2025-01-12 17:28:19.715510:  
2025-01-12 17:28:19.716012: Epoch 366 
2025-01-12 17:28:19.721025: Current learning rate: 0.00306 
2025-01-12 17:29:02.075773: train_loss -0.8779 
2025-01-12 17:29:02.076280: val_loss -0.7657 
2025-01-12 17:29:02.082984: Pseudo dice [np.float32(0.8204)] 
2025-01-12 17:29:02.086542: Epoch time: 42.36 s 
2025-01-12 17:29:02.804910:  
2025-01-12 17:29:02.805944: Epoch 367 
2025-01-12 17:29:02.811517: Current learning rate: 0.00304 
2025-01-12 17:29:45.140003: train_loss -0.88 
2025-01-12 17:29:45.140505: val_loss -0.7902 
2025-01-12 17:29:45.146163: Pseudo dice [np.float32(0.8367)] 
2025-01-12 17:29:45.150752: Epoch time: 42.34 s 
2025-01-12 17:29:45.729899:  
2025-01-12 17:29:45.730903: Epoch 368 
2025-01-12 17:29:45.736072: Current learning rate: 0.00302 
2025-01-12 17:30:28.041731: train_loss -0.8748 
2025-01-12 17:30:28.041731: val_loss -0.7572 
2025-01-12 17:30:28.047698: Pseudo dice [np.float32(0.808)] 
2025-01-12 17:30:28.051360: Epoch time: 42.31 s 
2025-01-12 17:30:28.653999:  
2025-01-12 17:30:28.655002: Epoch 369 
2025-01-12 17:30:28.659559: Current learning rate: 0.003 
2025-01-12 17:31:11.007053: train_loss -0.8881 
2025-01-12 17:31:11.007556: val_loss -0.7443 
2025-01-12 17:31:11.013306: Pseudo dice [np.float32(0.797)] 
2025-01-12 17:31:11.016880: Epoch time: 42.35 s 
2025-01-12 17:31:11.601492:  
2025-01-12 17:31:11.601492: Epoch 370 
2025-01-12 17:31:11.607673: Current learning rate: 0.00297 
2025-01-12 17:31:53.914654: train_loss -0.8859 
2025-01-12 17:31:53.915163: val_loss -0.7498 
2025-01-12 17:31:53.921274: Pseudo dice [np.float32(0.8043)] 
2025-01-12 17:31:53.925455: Epoch time: 42.31 s 
2025-01-12 17:31:54.512248:  
2025-01-12 17:31:54.512248: Epoch 371 
2025-01-12 17:31:54.518399: Current learning rate: 0.00295 
2025-01-12 17:32:36.829241: train_loss -0.875 
2025-01-12 17:32:36.830248: val_loss -0.7313 
2025-01-12 17:32:36.835943: Pseudo dice [np.float32(0.7951)] 
2025-01-12 17:32:36.839956: Epoch time: 42.32 s 
2025-01-12 17:32:37.419071:  
2025-01-12 17:32:37.419577: Epoch 372 
2025-01-12 17:32:37.424910: Current learning rate: 0.00293 
2025-01-12 17:33:19.736369: train_loss -0.8778 
2025-01-12 17:33:19.736369: val_loss -0.7566 
2025-01-12 17:33:19.742464: Pseudo dice [np.float32(0.8179)] 
2025-01-12 17:33:19.746644: Epoch time: 42.32 s 
2025-01-12 17:33:20.325684:  
2025-01-12 17:33:20.326793: Epoch 373 
2025-01-12 17:33:20.331346: Current learning rate: 0.00291 
2025-01-12 17:34:02.666845: train_loss -0.8441 
2025-01-12 17:34:02.668360: val_loss -0.7119 
2025-01-12 17:34:02.673551: Pseudo dice [np.float32(0.7808)] 
2025-01-12 17:34:02.677627: Epoch time: 42.34 s 
2025-01-12 17:34:03.249089:  
2025-01-12 17:34:03.249089: Epoch 374 
2025-01-12 17:34:03.254797: Current learning rate: 0.00289 
2025-01-12 17:34:45.561469: train_loss -0.8688 
2025-01-12 17:34:45.561469: val_loss -0.7521 
2025-01-12 17:34:45.567747: Pseudo dice [np.float32(0.8131)] 
2025-01-12 17:34:45.571757: Epoch time: 42.31 s 
2025-01-12 17:34:46.294963:  
2025-01-12 17:34:46.294963: Epoch 375 
2025-01-12 17:34:46.300091: Current learning rate: 0.00287 
2025-01-12 17:35:28.618009: train_loss -0.8645 
2025-01-12 17:35:28.618522: val_loss -0.8022 
2025-01-12 17:35:28.624249: Pseudo dice [np.float32(0.842)] 
2025-01-12 17:35:28.627786: Epoch time: 42.32 s 
2025-01-12 17:35:29.212947:  
2025-01-12 17:35:29.214014: Epoch 376 
2025-01-12 17:35:29.219146: Current learning rate: 0.00285 
2025-01-12 17:36:11.572202: train_loss -0.886 
2025-01-12 17:36:11.572202: val_loss -0.7673 
2025-01-12 17:36:11.578396: Pseudo dice [np.float32(0.8184)] 
2025-01-12 17:36:11.581498: Epoch time: 42.36 s 
2025-01-12 17:36:12.157865:  
2025-01-12 17:36:12.157865: Epoch 377 
2025-01-12 17:36:12.163898: Current learning rate: 0.00283 
2025-01-12 17:36:54.498593: train_loss -0.8837 
2025-01-12 17:36:54.499107: val_loss -0.7787 
2025-01-12 17:36:54.504499: Pseudo dice [np.float32(0.8231)] 
2025-01-12 17:36:54.509012: Epoch time: 42.34 s 
2025-01-12 17:36:55.084692:  
2025-01-12 17:36:55.084692: Epoch 378 
2025-01-12 17:36:55.090845: Current learning rate: 0.00281 
2025-01-12 17:37:37.426905: train_loss -0.876 
2025-01-12 17:37:37.427413: val_loss -0.7351 
2025-01-12 17:37:37.433971: Pseudo dice [np.float32(0.7971)] 
2025-01-12 17:37:37.438358: Epoch time: 42.34 s 
2025-01-12 17:37:38.013950:  
2025-01-12 17:37:38.013950: Epoch 379 
2025-01-12 17:37:38.018959: Current learning rate: 0.00279 
2025-01-12 17:38:20.336724: train_loss -0.8772 
2025-01-12 17:38:20.336724: val_loss -0.7518 
2025-01-12 17:38:20.342331: Pseudo dice [np.float32(0.8108)] 
2025-01-12 17:38:20.346502: Epoch time: 42.32 s 
2025-01-12 17:38:20.937983:  
2025-01-12 17:38:20.937983: Epoch 380 
2025-01-12 17:38:20.943596: Current learning rate: 0.00277 
2025-01-12 17:39:03.270916: train_loss -0.8732 
2025-01-12 17:39:03.271424: val_loss -0.7088 
2025-01-12 17:39:03.277104: Pseudo dice [np.float32(0.7837)] 
2025-01-12 17:39:03.282099: Epoch time: 42.33 s 
2025-01-12 17:39:03.857854:  
2025-01-12 17:39:03.858360: Epoch 381 
2025-01-12 17:39:03.863659: Current learning rate: 0.00275 
2025-01-12 17:39:46.157772: train_loss -0.8797 
2025-01-12 17:39:46.158280: val_loss -0.6935 
2025-01-12 17:39:46.164581: Pseudo dice [np.float32(0.7815)] 
2025-01-12 17:39:46.170153: Epoch time: 42.3 s 
2025-01-12 17:39:46.903383:  
2025-01-12 17:39:46.903383: Epoch 382 
2025-01-12 17:39:46.909452: Current learning rate: 0.00273 
2025-01-12 17:40:29.205697: train_loss -0.882 
2025-01-12 17:40:29.206205: val_loss -0.7585 
2025-01-12 17:40:29.211903: Pseudo dice [np.float32(0.8059)] 
2025-01-12 17:40:29.215550: Epoch time: 42.3 s 
2025-01-12 17:40:29.796372:  
2025-01-12 17:40:29.796886: Epoch 383 
2025-01-12 17:40:29.801954: Current learning rate: 0.00271 
2025-01-12 17:41:12.100785: train_loss -0.8795 
2025-01-12 17:41:12.101295: val_loss -0.716 
2025-01-12 17:41:12.105324: Pseudo dice [np.float32(0.7774)] 
2025-01-12 17:41:12.108862: Epoch time: 42.31 s 
2025-01-12 17:41:12.691820:  
2025-01-12 17:41:12.691820: Epoch 384 
2025-01-12 17:41:12.697081: Current learning rate: 0.00268 
2025-01-12 17:41:55.000615: train_loss -0.8832 
2025-01-12 17:41:55.001127: val_loss -0.7152 
2025-01-12 17:41:55.006750: Pseudo dice [np.float32(0.7758)] 
2025-01-12 17:41:55.010297: Epoch time: 42.31 s 
2025-01-12 17:41:55.604788:  
2025-01-12 17:41:55.604788: Epoch 385 
2025-01-12 17:41:55.609855: Current learning rate: 0.00266 
2025-01-12 17:42:37.967962: train_loss -0.8853 
2025-01-12 17:42:37.968474: val_loss -0.6872 
2025-01-12 17:42:37.974510: Pseudo dice [np.float32(0.7604)] 
2025-01-12 17:42:37.978031: Epoch time: 42.36 s 
2025-01-12 17:42:38.566576:  
2025-01-12 17:42:38.567584: Epoch 386 
2025-01-12 17:42:38.573115: Current learning rate: 0.00264 
2025-01-12 17:43:20.896050: train_loss -0.8897 
2025-01-12 17:43:20.896554: val_loss -0.7436 
2025-01-12 17:43:20.902571: Pseudo dice [np.float32(0.7992)] 
2025-01-12 17:43:20.906226: Epoch time: 42.33 s 
2025-01-12 17:43:21.478663:  
2025-01-12 17:43:21.479666: Epoch 387 
2025-01-12 17:43:21.484245: Current learning rate: 0.00262 
2025-01-12 17:44:03.821974: train_loss -0.8799 
2025-01-12 17:44:03.822579: val_loss -0.6897 
2025-01-12 17:44:03.828660: Pseudo dice [np.float32(0.7665)] 
2025-01-12 17:44:03.832242: Epoch time: 42.34 s 
2025-01-12 17:44:04.410743:  
2025-01-12 17:44:04.411795: Epoch 388 
2025-01-12 17:44:04.416837: Current learning rate: 0.0026 
2025-01-12 17:44:46.709894: train_loss -0.8874 
2025-01-12 17:44:46.709894: val_loss -0.712 
2025-01-12 17:44:46.716594: Pseudo dice [np.float32(0.7795)] 
2025-01-12 17:44:46.720611: Epoch time: 42.3 s 
2025-01-12 17:44:47.291708:  
2025-01-12 17:44:47.291708: Epoch 389 
2025-01-12 17:44:47.297117: Current learning rate: 0.00258 
2025-01-12 17:45:29.621955: train_loss -0.8849 
2025-01-12 17:45:29.622570: val_loss -0.7367 
2025-01-12 17:45:29.628112: Pseudo dice [np.float32(0.8018)] 
2025-01-12 17:45:29.632752: Epoch time: 42.33 s 
2025-01-12 17:45:30.357486:  
2025-01-12 17:45:30.357999: Epoch 390 
2025-01-12 17:45:30.362554: Current learning rate: 0.00256 
2025-01-12 17:46:12.674175: train_loss -0.8883 
2025-01-12 17:46:12.674678: val_loss -0.7663 
2025-01-12 17:46:12.680008: Pseudo dice [np.float32(0.8218)] 
2025-01-12 17:46:12.685158: Epoch time: 42.32 s 
2025-01-12 17:46:13.265623:  
2025-01-12 17:46:13.266131: Epoch 391 
2025-01-12 17:46:13.271199: Current learning rate: 0.00254 
2025-01-12 17:46:55.600818: train_loss -0.8909 
2025-01-12 17:46:55.601820: val_loss -0.7275 
2025-01-12 17:46:55.607515: Pseudo dice [np.float32(0.7903)] 
2025-01-12 17:46:55.610529: Epoch time: 42.34 s 
2025-01-12 17:46:56.189883:  
2025-01-12 17:46:56.190886: Epoch 392 
2025-01-12 17:46:56.196570: Current learning rate: 0.00252 
2025-01-12 17:47:38.548224: train_loss -0.8876 
2025-01-12 17:47:38.548740: val_loss -0.7123 
2025-01-12 17:47:38.556492: Pseudo dice [np.float32(0.7836)] 
2025-01-12 17:47:38.561509: Epoch time: 42.36 s 
2025-01-12 17:47:39.134850:  
2025-01-12 17:47:39.135854: Epoch 393 
2025-01-12 17:47:39.141519: Current learning rate: 0.0025 
2025-01-12 17:48:21.440232: train_loss -0.8826 
2025-01-12 17:48:21.441268: val_loss -0.7008 
2025-01-12 17:48:21.446516: Pseudo dice [np.float32(0.7623)] 
2025-01-12 17:48:21.450068: Epoch time: 42.31 s 
2025-01-12 17:48:22.026997:  
2025-01-12 17:48:22.027542: Epoch 394 
2025-01-12 17:48:22.032589: Current learning rate: 0.00248 
2025-01-12 17:49:04.338174: train_loss -0.8774 
2025-01-12 17:49:04.338681: val_loss -0.6684 
2025-01-12 17:49:04.344657: Pseudo dice [np.float32(0.7456)] 
2025-01-12 17:49:04.348330: Epoch time: 42.31 s 
2025-01-12 17:49:04.922076:  
2025-01-12 17:49:04.922688: Epoch 395 
2025-01-12 17:49:04.927839: Current learning rate: 0.00245 
2025-01-12 17:49:47.233914: train_loss -0.8648 
2025-01-12 17:49:47.234421: val_loss -0.6673 
2025-01-12 17:49:47.240060: Pseudo dice [np.float32(0.7626)] 
2025-01-12 17:49:47.244220: Epoch time: 42.31 s 
2025-01-12 17:49:47.821635:  
2025-01-12 17:49:47.822142: Epoch 396 
2025-01-12 17:49:47.827866: Current learning rate: 0.00243 
2025-01-12 17:50:30.158028: train_loss -0.8611 
2025-01-12 17:50:30.158531: val_loss -0.6957 
2025-01-12 17:50:30.164239: Pseudo dice [np.float32(0.737)] 
2025-01-12 17:50:30.168302: Epoch time: 42.34 s 
2025-01-12 17:50:30.746803:  
2025-01-12 17:50:30.747355: Epoch 397 
2025-01-12 17:50:30.751928: Current learning rate: 0.00241 
2025-01-12 17:51:13.065247: train_loss -0.8577 
2025-01-12 17:51:13.065768: val_loss -0.7543 
2025-01-12 17:51:13.070785: Pseudo dice [np.float32(0.7959)] 
2025-01-12 17:51:13.073978: Epoch time: 42.32 s 
2025-01-12 17:51:13.784870:  
2025-01-12 17:51:13.785886: Epoch 398 
2025-01-12 17:51:13.791459: Current learning rate: 0.00239 
2025-01-12 17:51:56.116687: train_loss -0.8543 
2025-01-12 17:51:56.117201: val_loss -0.7129 
2025-01-12 17:51:56.122924: Pseudo dice [np.float32(0.7848)] 
2025-01-12 17:51:56.127533: Epoch time: 42.33 s 
2025-01-12 17:51:56.704990:  
2025-01-12 17:51:56.704990: Epoch 399 
2025-01-12 17:51:56.711534: Current learning rate: 0.00237 
2025-01-12 17:52:39.013348: train_loss -0.8453 
2025-01-12 17:52:39.013863: val_loss -0.6657 
2025-01-12 17:52:39.019571: Pseudo dice [np.float32(0.7363)] 
2025-01-12 17:52:39.024267: Epoch time: 42.31 s 
2025-01-12 17:52:39.829251:  
2025-01-12 17:52:39.829251: Epoch 400 
2025-01-12 17:52:39.835475: Current learning rate: 0.00235 
2025-01-12 17:53:22.121515: train_loss -0.8463 
2025-01-12 17:53:22.122518: val_loss -0.6484 
2025-01-12 17:53:22.127542: Pseudo dice [np.float32(0.7521)] 
2025-01-12 17:53:22.131557: Epoch time: 42.29 s 
2025-01-12 17:53:22.709756:  
2025-01-12 17:53:22.709756: Epoch 401 
2025-01-12 17:53:22.715034: Current learning rate: 0.00233 
2025-01-12 17:54:05.030510: train_loss -0.8444 
2025-01-12 17:54:05.030510: val_loss -0.6982 
2025-01-12 17:54:05.036702: Pseudo dice [np.float32(0.7598)] 
2025-01-12 17:54:05.040731: Epoch time: 42.32 s 
2025-01-12 17:54:05.619073:  
2025-01-12 17:54:05.620077: Epoch 402 
2025-01-12 17:54:05.625250: Current learning rate: 0.00231 
2025-01-12 17:54:47.939191: train_loss -0.852 
2025-01-12 17:54:47.939701: val_loss -0.6871 
2025-01-12 17:54:47.945111: Pseudo dice [np.float32(0.7482)] 
2025-01-12 17:54:47.948782: Epoch time: 42.32 s 
2025-01-12 17:54:48.525712:  
2025-01-12 17:54:48.525712: Epoch 403 
2025-01-12 17:54:48.531261: Current learning rate: 0.00229 
2025-01-12 17:55:30.838054: train_loss -0.8756 
2025-01-12 17:55:30.838533: val_loss -0.7078 
2025-01-12 17:55:30.843788: Pseudo dice [np.float32(0.7691)] 
2025-01-12 17:55:30.847871: Epoch time: 42.31 s 
2025-01-12 17:55:31.426995:  
2025-01-12 17:55:31.426995: Epoch 404 
2025-01-12 17:55:31.432595: Current learning rate: 0.00226 
2025-01-12 17:56:13.770640: train_loss -0.8681 
2025-01-12 17:56:13.771643: val_loss -0.7473 
2025-01-12 17:56:13.777364: Pseudo dice [np.float32(0.7956)] 
2025-01-12 17:56:13.781468: Epoch time: 42.34 s 
2025-01-12 17:56:14.500805:  
2025-01-12 17:56:14.501322: Epoch 405 
2025-01-12 17:56:14.505875: Current learning rate: 0.00224 
2025-01-12 17:56:56.830843: train_loss -0.8673 
2025-01-12 17:56:56.837051: val_loss -0.7162 
2025-01-12 17:56:56.840618: Pseudo dice [np.float32(0.7753)] 
2025-01-12 17:56:56.844808: Epoch time: 42.33 s 
2025-01-12 17:56:57.418778:  
2025-01-12 17:56:57.419781: Epoch 406 
2025-01-12 17:56:57.424515: Current learning rate: 0.00222 
2025-01-12 17:57:39.738315: train_loss -0.8788 
2025-01-12 17:57:39.744521: val_loss -0.665 
2025-01-12 17:57:39.748102: Pseudo dice [np.float32(0.7271)] 
2025-01-12 17:57:39.752666: Epoch time: 42.32 s 
2025-01-12 17:57:40.328708:  
2025-01-12 17:57:40.329711: Epoch 407 
2025-01-12 17:57:40.333863: Current learning rate: 0.0022 
2025-01-12 17:58:22.638309: train_loss -0.8711 
2025-01-12 17:58:22.638827: val_loss -0.7162 
2025-01-12 17:58:22.645883: Pseudo dice [np.float32(0.7886)] 
2025-01-12 17:58:22.649418: Epoch time: 42.31 s 
2025-01-12 17:58:23.228535:  
2025-01-12 17:58:23.229049: Epoch 408 
2025-01-12 17:58:23.233766: Current learning rate: 0.00218 
2025-01-12 17:59:05.589252: train_loss -0.8838 
2025-01-12 17:59:05.589252: val_loss -0.681 
2025-01-12 17:59:05.595381: Pseudo dice [np.float32(0.7547)] 
2025-01-12 17:59:05.599395: Epoch time: 42.36 s 
2025-01-12 17:59:06.176005:  
2025-01-12 17:59:06.176005: Epoch 409 
2025-01-12 17:59:06.181021: Current learning rate: 0.00216 
2025-01-12 17:59:48.465270: train_loss -0.8878 
2025-01-12 17:59:48.465772: val_loss -0.6518 
2025-01-12 17:59:48.471880: Pseudo dice [np.float32(0.7476)] 
2025-01-12 17:59:48.475705: Epoch time: 42.29 s 
2025-01-12 17:59:49.052066:  
2025-01-12 17:59:49.053148: Epoch 410 
2025-01-12 17:59:49.058203: Current learning rate: 0.00214 
2025-01-12 18:00:31.379246: train_loss -0.8792 
2025-01-12 18:00:31.380249: val_loss -0.7042 
2025-01-12 18:00:31.385937: Pseudo dice [np.float32(0.7748)] 
2025-01-12 18:00:31.389013: Epoch time: 42.33 s 
2025-01-12 18:00:31.936248:  
2025-01-12 18:00:31.937253: Epoch 411 
2025-01-12 18:00:31.942277: Current learning rate: 0.00212 
2025-01-12 18:01:14.267627: train_loss -0.8815 
2025-01-12 18:01:14.268137: val_loss -0.7399 
2025-01-12 18:01:14.273778: Pseudo dice [np.float32(0.8015)] 
2025-01-12 18:01:14.277340: Epoch time: 42.33 s 
2025-01-12 18:01:14.823733:  
2025-01-12 18:01:14.824240: Epoch 412 
2025-01-12 18:01:14.828331: Current learning rate: 0.00209 
2025-01-12 18:01:57.122846: train_loss -0.8868 
2025-01-12 18:01:57.123973: val_loss -0.7434 
2025-01-12 18:01:57.129990: Pseudo dice [np.float32(0.8067)] 
2025-01-12 18:01:57.133999: Epoch time: 42.3 s 
2025-01-12 18:01:57.829329:  
2025-01-12 18:01:57.830838: Epoch 413 
2025-01-12 18:01:57.835951: Current learning rate: 0.00207 
2025-01-12 18:02:40.145232: train_loss -0.889 
2025-01-12 18:02:40.145232: val_loss -0.6919 
2025-01-12 18:02:40.151263: Pseudo dice [np.float32(0.7759)] 
2025-01-12 18:02:40.155397: Epoch time: 42.32 s 
2025-01-12 18:02:40.711211:  
2025-01-12 18:02:40.711211: Epoch 414 
2025-01-12 18:02:40.717017: Current learning rate: 0.00205 
2025-01-12 18:03:23.040327: train_loss -0.8717 
2025-01-12 18:03:23.040837: val_loss -0.704 
2025-01-12 18:03:23.046028: Pseudo dice [np.float32(0.7809)] 
2025-01-12 18:03:23.049125: Epoch time: 42.33 s 
2025-01-12 18:03:23.597091:  
2025-01-12 18:03:23.597091: Epoch 415 
2025-01-12 18:03:23.603128: Current learning rate: 0.00203 
2025-01-12 18:04:05.922178: train_loss -0.8819 
2025-01-12 18:04:05.922178: val_loss -0.7424 
2025-01-12 18:04:05.927962: Pseudo dice [np.float32(0.7893)] 
2025-01-12 18:04:05.932517: Epoch time: 42.33 s 
2025-01-12 18:04:06.475970:  
2025-01-12 18:04:06.476976: Epoch 416 
2025-01-12 18:04:06.481535: Current learning rate: 0.00201 
2025-01-12 18:04:48.775223: train_loss -0.8859 
2025-01-12 18:04:48.775783: val_loss -0.6903 
2025-01-12 18:04:48.781387: Pseudo dice [np.float32(0.7657)] 
2025-01-12 18:04:48.785053: Epoch time: 42.3 s 
2025-01-12 18:04:49.327986:  
2025-01-12 18:04:49.327986: Epoch 417 
2025-01-12 18:04:49.333958: Current learning rate: 0.00199 
2025-01-12 18:05:31.665031: train_loss -0.8873 
2025-01-12 18:05:31.665031: val_loss -0.7504 
2025-01-12 18:05:31.670578: Pseudo dice [np.float32(0.8065)] 
2025-01-12 18:05:31.674588: Epoch time: 42.34 s 
2025-01-12 18:05:32.216421:  
2025-01-12 18:05:32.216421: Epoch 418 
2025-01-12 18:05:32.222011: Current learning rate: 0.00196 
2025-01-12 18:06:14.542491: train_loss -0.8813 
2025-01-12 18:06:14.542491: val_loss -0.7185 
2025-01-12 18:06:14.549122: Pseudo dice [np.float32(0.7709)] 
2025-01-12 18:06:14.554292: Epoch time: 42.33 s 
2025-01-12 18:06:15.097728:  
2025-01-12 18:06:15.097728: Epoch 419 
2025-01-12 18:06:15.102859: Current learning rate: 0.00194 
2025-01-12 18:06:57.406780: train_loss -0.8959 
2025-01-12 18:06:57.407289: val_loss -0.7122 
2025-01-12 18:06:57.412931: Pseudo dice [np.float32(0.7772)] 
2025-01-12 18:06:57.416596: Epoch time: 42.31 s 
2025-01-12 18:06:57.958539:  
2025-01-12 18:06:57.959041: Epoch 420 
2025-01-12 18:06:57.964155: Current learning rate: 0.00192 
2025-01-12 18:07:40.279192: train_loss -0.8914 
2025-01-12 18:07:40.279702: val_loss -0.7826 
2025-01-12 18:07:40.285955: Pseudo dice [np.float32(0.8294)] 
2025-01-12 18:07:40.289490: Epoch time: 42.32 s 
2025-01-12 18:07:40.832909:  
2025-01-12 18:07:40.833416: Epoch 421 
2025-01-12 18:07:40.838009: Current learning rate: 0.0019 
2025-01-12 18:08:23.147085: train_loss -0.8889 
2025-01-12 18:08:23.147085: val_loss -0.7612 
2025-01-12 18:08:23.152652: Pseudo dice [np.float32(0.8066)] 
2025-01-12 18:08:23.156828: Epoch time: 42.31 s 
2025-01-12 18:08:23.846254:  
2025-01-12 18:08:23.846768: Epoch 422 
2025-01-12 18:08:23.851903: Current learning rate: 0.00188 
2025-01-12 18:09:06.195018: train_loss -0.8868 
2025-01-12 18:09:06.195018: val_loss -0.7204 
2025-01-12 18:09:06.201538: Pseudo dice [np.float32(0.7803)] 
2025-01-12 18:09:06.205096: Epoch time: 42.35 s 
2025-01-12 18:09:06.750202:  
2025-01-12 18:09:06.750202: Epoch 423 
2025-01-12 18:09:06.756355: Current learning rate: 0.00186 
2025-01-12 18:09:49.071544: train_loss -0.8872 
2025-01-12 18:09:49.072548: val_loss -0.7299 
2025-01-12 18:09:49.078224: Pseudo dice [np.float32(0.791)] 
2025-01-12 18:09:49.082269: Epoch time: 42.32 s 
2025-01-12 18:09:49.626965:  
2025-01-12 18:09:49.627473: Epoch 424 
2025-01-12 18:09:49.633041: Current learning rate: 0.00184 
2025-01-12 18:10:31.929602: train_loss -0.8875 
2025-01-12 18:10:31.930112: val_loss -0.6869 
2025-01-12 18:10:31.936287: Pseudo dice [np.float32(0.7353)] 
2025-01-12 18:10:31.939888: Epoch time: 42.3 s 
2025-01-12 18:10:32.488525:  
2025-01-12 18:10:32.489534: Epoch 425 
2025-01-12 18:10:32.494525: Current learning rate: 0.00181 
2025-01-12 18:11:14.776462: train_loss -0.8845 
2025-01-12 18:11:14.777219: val_loss -0.742 
2025-01-12 18:11:14.781885: Pseudo dice [np.float32(0.8069)] 
2025-01-12 18:11:14.786068: Epoch time: 42.29 s 
2025-01-12 18:11:15.335219:  
2025-01-12 18:11:15.335219: Epoch 426 
2025-01-12 18:11:15.340759: Current learning rate: 0.00179 
2025-01-12 18:11:57.658566: train_loss -0.887 
2025-01-12 18:11:57.659070: val_loss -0.7293 
2025-01-12 18:11:57.665167: Pseudo dice [np.float32(0.7933)] 
2025-01-12 18:11:57.669223: Epoch time: 42.32 s 
2025-01-12 18:11:58.213808:  
2025-01-12 18:11:58.214316: Epoch 427 
2025-01-12 18:11:58.219881: Current learning rate: 0.00177 
2025-01-12 18:12:40.509102: train_loss -0.8862 
2025-01-12 18:12:40.510604: val_loss -0.7313 
2025-01-12 18:12:40.516732: Pseudo dice [np.float32(0.7939)] 
2025-01-12 18:12:40.519241: Epoch time: 42.3 s 
2025-01-12 18:12:41.071764:  
2025-01-12 18:12:41.071764: Epoch 428 
2025-01-12 18:12:41.077361: Current learning rate: 0.00175 
2025-01-12 18:13:23.344333: train_loss -0.8871 
2025-01-12 18:13:23.344333: val_loss -0.7036 
2025-01-12 18:13:23.350847: Pseudo dice [np.float32(0.7666)] 
2025-01-12 18:13:23.354354: Epoch time: 42.27 s 
2025-01-12 18:13:23.897157:  
2025-01-12 18:13:23.897157: Epoch 429 
2025-01-12 18:13:23.903224: Current learning rate: 0.00173 
2025-01-12 18:14:06.214437: train_loss -0.8856 
2025-01-12 18:14:06.214437: val_loss -0.7212 
2025-01-12 18:14:06.219979: Pseudo dice [np.float32(0.7915)] 
2025-01-12 18:14:06.224651: Epoch time: 42.32 s 
2025-01-12 18:14:06.768234:  
2025-01-12 18:14:06.768234: Epoch 430 
2025-01-12 18:14:06.773369: Current learning rate: 0.0017 
2025-01-12 18:14:49.062460: train_loss -0.8828 
2025-01-12 18:14:49.064034: val_loss -0.725 
2025-01-12 18:14:49.070060: Pseudo dice [np.float32(0.7846)] 
2025-01-12 18:14:49.074198: Epoch time: 42.29 s 
2025-01-12 18:14:49.761806:  
2025-01-12 18:14:49.762931: Epoch 431 
2025-01-12 18:14:49.767980: Current learning rate: 0.00168 
2025-01-12 18:15:32.029737: train_loss -0.8918 
2025-01-12 18:15:32.030626: val_loss -0.75 
2025-01-12 18:15:32.036340: Pseudo dice [np.float32(0.8129)] 
2025-01-12 18:15:32.039849: Epoch time: 42.27 s 
2025-01-12 18:15:32.578042:  
2025-01-12 18:15:32.579614: Epoch 432 
2025-01-12 18:15:32.584842: Current learning rate: 0.00166 
2025-01-12 18:16:14.843038: train_loss -0.8905 
2025-01-12 18:16:14.844041: val_loss -0.7284 
2025-01-12 18:16:14.850111: Pseudo dice [np.float32(0.7844)] 
2025-01-12 18:16:14.854260: Epoch time: 42.26 s 
2025-01-12 18:16:15.397402:  
2025-01-12 18:16:15.397402: Epoch 433 
2025-01-12 18:16:15.403458: Current learning rate: 0.00164 
2025-01-12 18:16:57.671621: train_loss -0.8878 
2025-01-12 18:16:57.672250: val_loss -0.7358 
2025-01-12 18:16:57.677974: Pseudo dice [np.float32(0.801)] 
2025-01-12 18:16:57.681564: Epoch time: 42.28 s 
2025-01-12 18:16:58.224543:  
2025-01-12 18:16:58.225547: Epoch 434 
2025-01-12 18:16:58.230083: Current learning rate: 0.00162 
2025-01-12 18:17:40.515765: train_loss -0.8893 
2025-01-12 18:17:40.516274: val_loss -0.7503 
2025-01-12 18:17:40.522206: Pseudo dice [np.float32(0.7899)] 
2025-01-12 18:17:40.525749: Epoch time: 42.29 s 
2025-01-12 18:17:41.071275:  
2025-01-12 18:17:41.071780: Epoch 435 
2025-01-12 18:17:41.076977: Current learning rate: 0.00159 
2025-01-12 18:18:23.372241: train_loss -0.8913 
2025-01-12 18:18:23.372241: val_loss -0.7525 
2025-01-12 18:18:23.378345: Pseudo dice [np.float32(0.8151)] 
2025-01-12 18:18:23.382403: Epoch time: 42.3 s 
2025-01-12 18:18:23.922583:  
2025-01-12 18:18:23.923168: Epoch 436 
2025-01-12 18:18:23.927743: Current learning rate: 0.00157 
2025-01-12 18:19:06.236125: train_loss -0.8907 
2025-01-12 18:19:06.236629: val_loss -0.7604 
2025-01-12 18:19:06.242381: Pseudo dice [np.float32(0.8061)] 
2025-01-12 18:19:06.247124: Epoch time: 42.31 s 
2025-01-12 18:19:06.787009:  
2025-01-12 18:19:06.787009: Epoch 437 
2025-01-12 18:19:06.792666: Current learning rate: 0.00155 
2025-01-12 18:19:49.058936: train_loss -0.8925 
2025-01-12 18:19:49.059443: val_loss -0.6946 
2025-01-12 18:19:49.064639: Pseudo dice [np.float32(0.7752)] 
2025-01-12 18:19:49.068685: Epoch time: 42.27 s 
2025-01-12 18:19:49.610538:  
2025-01-12 18:19:49.611047: Epoch 438 
2025-01-12 18:19:49.616172: Current learning rate: 0.00153 
2025-01-12 18:20:31.924577: train_loss -0.8812 
2025-01-12 18:20:31.924577: val_loss -0.7042 
2025-01-12 18:20:31.932105: Pseudo dice [np.float32(0.7656)] 
2025-01-12 18:20:31.934732: Epoch time: 42.32 s 
2025-01-12 18:20:32.483355:  
2025-01-12 18:20:32.483355: Epoch 439 
2025-01-12 18:20:32.488013: Current learning rate: 0.00151 
2025-01-12 18:21:14.885735: train_loss -0.8775 
2025-01-12 18:21:14.885735: val_loss -0.7709 
2025-01-12 18:21:14.891781: Pseudo dice [np.float32(0.8175)] 
2025-01-12 18:21:14.894942: Epoch time: 42.4 s 
2025-01-12 18:21:15.438720:  
2025-01-12 18:21:15.439722: Epoch 440 
2025-01-12 18:21:15.444795: Current learning rate: 0.00148 
2025-01-12 18:21:57.763822: train_loss -0.8688 
2025-01-12 18:21:57.764827: val_loss -0.7477 
2025-01-12 18:21:57.769360: Pseudo dice [np.float32(0.8004)] 
2025-01-12 18:21:57.774084: Epoch time: 42.33 s 
2025-01-12 18:21:58.315696:  
2025-01-12 18:21:58.315696: Epoch 441 
2025-01-12 18:21:58.320791: Current learning rate: 0.00146 
2025-01-12 18:22:40.627154: train_loss -0.886 
2025-01-12 18:22:40.627663: val_loss -0.7528 
2025-01-12 18:22:40.633367: Pseudo dice [np.float32(0.8152)] 
2025-01-12 18:22:40.636955: Epoch time: 42.31 s 
2025-01-12 18:22:41.182556:  
2025-01-12 18:22:41.182556: Epoch 442 
2025-01-12 18:22:41.186697: Current learning rate: 0.00144 
2025-01-12 18:23:23.483996: train_loss -0.8918 
2025-01-12 18:23:23.483996: val_loss -0.7732 
2025-01-12 18:23:23.489593: Pseudo dice [np.float32(0.8198)] 
2025-01-12 18:23:23.495610: Epoch time: 42.3 s 
2025-01-12 18:23:24.035022:  
2025-01-12 18:23:24.036042: Epoch 443 
2025-01-12 18:23:24.041115: Current learning rate: 0.00142 
2025-01-12 18:24:06.358685: train_loss -0.8959 
2025-01-12 18:24:06.359187: val_loss -0.7233 
2025-01-12 18:24:06.364896: Pseudo dice [np.float32(0.7794)] 
2025-01-12 18:24:06.368995: Epoch time: 42.32 s 
2025-01-12 18:24:06.912779:  
2025-01-12 18:24:06.912779: Epoch 444 
2025-01-12 18:24:06.917500: Current learning rate: 0.00139 
2025-01-12 18:24:49.237476: train_loss -0.8748 
2025-01-12 18:24:49.237476: val_loss -0.7245 
2025-01-12 18:24:49.244613: Pseudo dice [np.float32(0.7662)] 
2025-01-12 18:24:49.248128: Epoch time: 42.33 s 
2025-01-12 18:24:49.792786:  
2025-01-12 18:24:49.792786: Epoch 445 
2025-01-12 18:24:49.796411: Current learning rate: 0.00137 
2025-01-12 18:25:32.122806: train_loss -0.8875 
2025-01-12 18:25:32.123308: val_loss -0.7673 
2025-01-12 18:25:32.128899: Pseudo dice [np.float32(0.8144)] 
2025-01-12 18:25:32.132931: Epoch time: 42.33 s 
2025-01-12 18:25:32.674941:  
2025-01-12 18:25:32.675947: Epoch 446 
2025-01-12 18:25:32.681127: Current learning rate: 0.00135 
2025-01-12 18:26:14.987422: train_loss -0.8957 
2025-01-12 18:26:14.987422: val_loss -0.7536 
2025-01-12 18:26:14.993435: Pseudo dice [np.float32(0.8003)] 
2025-01-12 18:26:14.997443: Epoch time: 42.31 s 
2025-01-12 18:26:15.540856:  
2025-01-12 18:26:15.541368: Epoch 447 
2025-01-12 18:26:15.545944: Current learning rate: 0.00133 
2025-01-12 18:26:57.865544: train_loss -0.8866 
2025-01-12 18:26:57.866053: val_loss -0.7081 
2025-01-12 18:26:57.871627: Pseudo dice [np.float32(0.7779)] 
2025-01-12 18:26:57.876171: Epoch time: 42.33 s 
2025-01-12 18:26:58.571876:  
2025-01-12 18:26:58.571876: Epoch 448 
2025-01-12 18:26:58.577368: Current learning rate: 0.0013 
2025-01-12 18:27:40.884718: train_loss -0.8885 
2025-01-12 18:27:40.884718: val_loss -0.7624 
2025-01-12 18:27:40.891263: Pseudo dice [np.float32(0.8231)] 
2025-01-12 18:27:40.894797: Epoch time: 42.31 s 
2025-01-12 18:27:41.436946:  
2025-01-12 18:27:41.436946: Epoch 449 
2025-01-12 18:27:41.443301: Current learning rate: 0.00128 
2025-01-12 18:28:23.754932: train_loss -0.8912 
2025-01-12 18:28:23.755933: val_loss -0.7282 
2025-01-12 18:28:23.761451: Pseudo dice [np.float32(0.7959)] 
2025-01-12 18:28:23.765959: Epoch time: 42.32 s 
2025-01-12 18:28:24.623250:  
2025-01-12 18:28:24.623758: Epoch 450 
2025-01-12 18:28:24.628796: Current learning rate: 0.00126 
2025-01-12 18:29:06.974955: train_loss -0.8932 
2025-01-12 18:29:06.974955: val_loss -0.7341 
2025-01-12 18:29:06.981084: Pseudo dice [np.float32(0.781)] 
2025-01-12 18:29:06.985125: Epoch time: 42.35 s 
2025-01-12 18:29:07.531945:  
2025-01-12 18:29:07.532456: Epoch 451 
2025-01-12 18:29:07.537107: Current learning rate: 0.00124 
2025-01-12 18:29:49.856533: train_loss -0.8901 
2025-01-12 18:29:49.857043: val_loss -0.7277 
2025-01-12 18:29:49.863237: Pseudo dice [np.float32(0.7867)] 
2025-01-12 18:29:49.867321: Epoch time: 42.33 s 
2025-01-12 18:29:50.412962:  
2025-01-12 18:29:50.414042: Epoch 452 
2025-01-12 18:29:50.419134: Current learning rate: 0.00121 
2025-01-12 18:30:32.746732: train_loss -0.8863 
2025-01-12 18:30:32.746732: val_loss -0.7388 
2025-01-12 18:30:32.752904: Pseudo dice [np.float32(0.7965)] 
2025-01-12 18:30:32.756927: Epoch time: 42.33 s 
2025-01-12 18:30:33.313779:  
2025-01-12 18:30:33.314781: Epoch 453 
2025-01-12 18:30:33.320352: Current learning rate: 0.00119 
2025-01-12 18:31:15.649494: train_loss -0.8949 
2025-01-12 18:31:15.649494: val_loss -0.766 
2025-01-12 18:31:15.655934: Pseudo dice [np.float32(0.8187)] 
2025-01-12 18:31:15.659017: Epoch time: 42.34 s 
2025-01-12 18:31:16.199435:  
2025-01-12 18:31:16.199949: Epoch 454 
2025-01-12 18:31:16.205531: Current learning rate: 0.00117 
2025-01-12 18:31:58.497275: train_loss -0.8922 
2025-01-12 18:31:58.497782: val_loss -0.7542 
2025-01-12 18:31:58.503394: Pseudo dice [np.float32(0.807)] 
2025-01-12 18:31:58.507667: Epoch time: 42.3 s 
2025-01-12 18:31:59.052144:  
2025-01-12 18:31:59.052144: Epoch 455 
2025-01-12 18:31:59.057286: Current learning rate: 0.00115 
2025-01-12 18:32:41.306477: train_loss -0.8965 
2025-01-12 18:32:41.306985: val_loss -0.7652 
2025-01-12 18:32:41.312598: Pseudo dice [np.float32(0.8016)] 
2025-01-12 18:32:41.316432: Epoch time: 42.26 s 
2025-01-12 18:32:41.859015:  
2025-01-12 18:32:41.859015: Epoch 456 
2025-01-12 18:32:41.865039: Current learning rate: 0.00112 
2025-01-12 18:33:24.206594: train_loss -0.8922 
2025-01-12 18:33:24.207629: val_loss -0.7251 
2025-01-12 18:33:24.213372: Pseudo dice [np.float32(0.7825)] 
2025-01-12 18:33:24.216425: Epoch time: 42.35 s 
2025-01-12 18:33:24.761372:  
2025-01-12 18:33:24.762378: Epoch 457 
2025-01-12 18:33:24.767050: Current learning rate: 0.0011 
2025-01-12 18:34:07.076992: train_loss -0.8816 
2025-01-12 18:34:07.076992: val_loss -0.7444 
2025-01-12 18:34:07.084096: Pseudo dice [np.float32(0.7942)] 
2025-01-12 18:34:07.089478: Epoch time: 42.32 s 
2025-01-12 18:34:07.789602:  
2025-01-12 18:34:07.790606: Epoch 458 
2025-01-12 18:34:07.795047: Current learning rate: 0.00108 
2025-01-12 18:34:50.122170: train_loss -0.8919 
2025-01-12 18:34:50.123303: val_loss -0.7125 
2025-01-12 18:34:50.128950: Pseudo dice [np.float32(0.7737)] 
2025-01-12 18:34:50.132460: Epoch time: 42.33 s 
2025-01-12 18:34:50.680065:  
2025-01-12 18:34:50.681095: Epoch 459 
2025-01-12 18:34:50.685790: Current learning rate: 0.00105 
2025-01-12 18:35:33.045454: train_loss -0.8888 
2025-01-12 18:35:33.045959: val_loss -0.7729 
2025-01-12 18:35:33.051559: Pseudo dice [np.float32(0.8071)] 
2025-01-12 18:35:33.055188: Epoch time: 42.37 s 
2025-01-12 18:35:33.599817:  
2025-01-12 18:35:33.600820: Epoch 460 
2025-01-12 18:35:33.606036: Current learning rate: 0.00103 
2025-01-12 18:36:15.935993: train_loss -0.8887 
2025-01-12 18:36:15.935993: val_loss -0.7279 
2025-01-12 18:36:15.942100: Pseudo dice [np.float32(0.7941)] 
2025-01-12 18:36:15.945761: Epoch time: 42.34 s 
2025-01-12 18:36:16.486794:  
2025-01-12 18:36:16.486794: Epoch 461 
2025-01-12 18:36:16.493027: Current learning rate: 0.00101 
2025-01-12 18:36:58.841898: train_loss -0.8912 
2025-01-12 18:36:58.841898: val_loss -0.7667 
2025-01-12 18:36:58.848474: Pseudo dice [np.float32(0.8127)] 
2025-01-12 18:36:58.852489: Epoch time: 42.36 s 
2025-01-12 18:36:59.395161:  
2025-01-12 18:36:59.395680: Epoch 462 
2025-01-12 18:36:59.400734: Current learning rate: 0.00098 
2025-01-12 18:37:41.724638: train_loss -0.89 
2025-01-12 18:37:41.724638: val_loss -0.773 
2025-01-12 18:37:41.731260: Pseudo dice [np.float32(0.824)] 
2025-01-12 18:37:41.734434: Epoch time: 42.33 s 
2025-01-12 18:37:42.292017:  
2025-01-12 18:37:42.292017: Epoch 463 
2025-01-12 18:37:42.297118: Current learning rate: 0.00096 
2025-01-12 18:38:24.623838: train_loss -0.8925 
2025-01-12 18:38:24.624842: val_loss -0.7902 
2025-01-12 18:38:24.629945: Pseudo dice [np.float32(0.84)] 
2025-01-12 18:38:24.634705: Epoch time: 42.33 s 
2025-01-12 18:38:25.180811:  
2025-01-12 18:38:25.181322: Epoch 464 
2025-01-12 18:38:25.186326: Current learning rate: 0.00094 
2025-01-12 18:39:07.492311: train_loss -0.896 
2025-01-12 18:39:07.492311: val_loss -0.7569 
2025-01-12 18:39:07.497392: Pseudo dice [np.float32(0.8085)] 
2025-01-12 18:39:07.501994: Epoch time: 42.31 s 
2025-01-12 18:39:08.046895:  
2025-01-12 18:39:08.047404: Epoch 465 
2025-01-12 18:39:08.052489: Current learning rate: 0.00091 
2025-01-12 18:39:50.374642: train_loss -0.8943 
2025-01-12 18:39:50.374642: val_loss -0.7418 
2025-01-12 18:39:50.381682: Pseudo dice [np.float32(0.8086)] 
2025-01-12 18:39:50.384827: Epoch time: 42.33 s 
2025-01-12 18:39:51.073355:  
2025-01-12 18:39:51.073355: Epoch 466 
2025-01-12 18:39:51.079426: Current learning rate: 0.00089 
2025-01-12 18:40:33.387849: train_loss -0.8954 
2025-01-12 18:40:33.387849: val_loss -0.7739 
2025-01-12 18:40:33.394060: Pseudo dice [np.float32(0.8236)] 
2025-01-12 18:40:33.397614: Epoch time: 42.31 s 
2025-01-12 18:40:33.934651:  
2025-01-12 18:40:33.934651: Epoch 467 
2025-01-12 18:40:33.940744: Current learning rate: 0.00087 
2025-01-12 18:41:16.231935: train_loss -0.8969 
2025-01-12 18:41:16.231935: val_loss -0.7495 
2025-01-12 18:41:16.238251: Pseudo dice [np.float32(0.8032)] 
2025-01-12 18:41:16.241804: Epoch time: 42.3 s 
2025-01-12 18:41:16.782884:  
2025-01-12 18:41:16.782884: Epoch 468 
2025-01-12 18:41:16.789066: Current learning rate: 0.00084 
2025-01-12 18:41:59.062871: train_loss -0.8913 
2025-01-12 18:41:59.062871: val_loss -0.7017 
2025-01-12 18:41:59.069403: Pseudo dice [np.float32(0.7728)] 
2025-01-12 18:41:59.072920: Epoch time: 42.28 s 
2025-01-12 18:41:59.613366:  
2025-01-12 18:41:59.613366: Epoch 469 
2025-01-12 18:41:59.618942: Current learning rate: 0.00082 
2025-01-12 18:42:41.960256: train_loss -0.8973 
2025-01-12 18:42:41.960256: val_loss -0.7527 
2025-01-12 18:42:41.966913: Pseudo dice [np.float32(0.8001)] 
2025-01-12 18:42:41.970427: Epoch time: 42.35 s 
2025-01-12 18:42:42.531859:  
2025-01-12 18:42:42.531859: Epoch 470 
2025-01-12 18:42:42.537443: Current learning rate: 0.00079 
2025-01-12 18:43:24.841189: train_loss -0.8903 
2025-01-12 18:43:24.841189: val_loss -0.7901 
2025-01-12 18:43:24.847379: Pseudo dice [np.float32(0.8349)] 
2025-01-12 18:43:24.850991: Epoch time: 42.31 s 
2025-01-12 18:43:25.390005:  
2025-01-12 18:43:25.391006: Epoch 471 
2025-01-12 18:43:25.396168: Current learning rate: 0.00077 
2025-01-12 18:44:07.734529: train_loss -0.8916 
2025-01-12 18:44:07.734529: val_loss -0.741 
2025-01-12 18:44:07.740644: Pseudo dice [np.float32(0.8044)] 
2025-01-12 18:44:07.744355: Epoch time: 42.34 s 
2025-01-12 18:44:08.285203:  
2025-01-12 18:44:08.285203: Epoch 472 
2025-01-12 18:44:08.290743: Current learning rate: 0.00075 
2025-01-12 18:44:50.617836: train_loss -0.8951 
2025-01-12 18:44:50.617836: val_loss -0.7634 
2025-01-12 18:44:50.624062: Pseudo dice [np.float32(0.8199)] 
2025-01-12 18:44:50.627608: Epoch time: 42.33 s 
2025-01-12 18:44:51.168569:  
2025-01-12 18:44:51.168569: Epoch 473 
2025-01-12 18:44:51.173770: Current learning rate: 0.00072 
2025-01-12 18:45:33.525294: train_loss -0.8967 
2025-01-12 18:45:33.525294: val_loss -0.7387 
2025-01-12 18:45:33.531822: Pseudo dice [np.float32(0.8104)] 
2025-01-12 18:45:33.534516: Epoch time: 42.36 s 
2025-01-12 18:45:34.077366:  
2025-01-12 18:45:34.077872: Epoch 474 
2025-01-12 18:45:34.083107: Current learning rate: 0.0007 
2025-01-12 18:46:16.402258: train_loss -0.8886 
2025-01-12 18:46:16.402258: val_loss -0.761 
2025-01-12 18:46:16.408478: Pseudo dice [np.float32(0.8206)] 
2025-01-12 18:46:16.412056: Epoch time: 42.33 s 
2025-01-12 18:46:16.415800: Yayy! New best EMA pseudo Dice: 0.8087000250816345 
2025-01-12 18:46:17.339195:  
2025-01-12 18:46:17.339195: Epoch 475 
2025-01-12 18:46:17.344869: Current learning rate: 0.00067 
2025-01-12 18:46:59.644326: train_loss -0.8775 
2025-01-12 18:46:59.644326: val_loss -0.7525 
2025-01-12 18:46:59.650941: Pseudo dice [np.float32(0.8071)] 
2025-01-12 18:46:59.653642: Epoch time: 42.31 s 
2025-01-12 18:47:00.206287:  
2025-01-12 18:47:00.206287: Epoch 476 
2025-01-12 18:47:00.212348: Current learning rate: 0.00065 
2025-01-12 18:47:42.546866: train_loss -0.8942 
2025-01-12 18:47:42.547368: val_loss -0.7506 
2025-01-12 18:47:42.553412: Pseudo dice [np.float32(0.8048)] 
2025-01-12 18:47:42.556894: Epoch time: 42.34 s 
2025-01-12 18:47:43.107183:  
2025-01-12 18:47:43.107183: Epoch 477 
2025-01-12 18:47:43.113083: Current learning rate: 0.00063 
2025-01-12 18:48:25.436696: train_loss -0.8953 
2025-01-12 18:48:25.437207: val_loss -0.7463 
2025-01-12 18:48:25.442755: Pseudo dice [np.float32(0.8081)] 
2025-01-12 18:48:25.446942: Epoch time: 42.33 s 
2025-01-12 18:48:25.997923:  
2025-01-12 18:48:25.998431: Epoch 478 
2025-01-12 18:48:26.005673: Current learning rate: 0.0006 
2025-01-12 18:49:08.330226: train_loss -0.8983 
2025-01-12 18:49:08.331730: val_loss -0.7684 
2025-01-12 18:49:08.337380: Pseudo dice [np.float32(0.8167)] 
2025-01-12 18:49:08.341388: Epoch time: 42.33 s 
2025-01-12 18:49:08.345412: Yayy! New best EMA pseudo Dice: 0.8090000152587891 
2025-01-12 18:49:09.154514:  
2025-01-12 18:49:09.154514: Epoch 479 
2025-01-12 18:49:09.160580: Current learning rate: 0.00058 
2025-01-12 18:49:51.516083: train_loss -0.8956 
2025-01-12 18:49:51.517107: val_loss -0.7534 
2025-01-12 18:49:51.523836: Pseudo dice [np.float32(0.8133)] 
2025-01-12 18:49:51.527952: Epoch time: 42.36 s 
2025-01-12 18:49:51.532369: Yayy! New best EMA pseudo Dice: 0.809499979019165 
2025-01-12 18:49:52.326560:  
2025-01-12 18:49:52.327566: Epoch 480 
2025-01-12 18:49:52.331608: Current learning rate: 0.00055 
2025-01-12 18:50:34.632309: train_loss -0.8983 
2025-01-12 18:50:34.632309: val_loss -0.7853 
2025-01-12 18:50:34.638907: Pseudo dice [np.float32(0.8356)] 
2025-01-12 18:50:34.642927: Epoch time: 42.31 s 
2025-01-12 18:50:34.646843: Yayy! New best EMA pseudo Dice: 0.8120999932289124 
2025-01-12 18:50:35.448454:  
2025-01-12 18:50:35.448961: Epoch 481 
2025-01-12 18:50:35.454526: Current learning rate: 0.00053 
2025-01-12 18:51:17.762658: train_loss -0.8989 
2025-01-12 18:51:17.764163: val_loss -0.7473 
2025-01-12 18:51:17.770283: Pseudo dice [np.float32(0.8052)] 
2025-01-12 18:51:17.773819: Epoch time: 42.31 s 
2025-01-12 18:51:18.331123:  
2025-01-12 18:51:18.331633: Epoch 482 
2025-01-12 18:51:18.336683: Current learning rate: 0.0005 
2025-01-12 18:52:00.655452: train_loss -0.8901 
2025-01-12 18:52:00.655452: val_loss -0.7409 
2025-01-12 18:52:00.661001: Pseudo dice [np.float32(0.8032)] 
2025-01-12 18:52:00.664151: Epoch time: 42.32 s 
2025-01-12 18:52:01.369499:  
2025-01-12 18:52:01.369499: Epoch 483 
2025-01-12 18:52:01.375041: Current learning rate: 0.00048 
2025-01-12 18:52:43.678253: train_loss -0.8898 
2025-01-12 18:52:43.678253: val_loss -0.7501 
2025-01-12 18:52:43.684403: Pseudo dice [np.float32(0.8095)] 
2025-01-12 18:52:43.687984: Epoch time: 42.31 s 
2025-01-12 18:52:44.250386:  
2025-01-12 18:52:44.250386: Epoch 484 
2025-01-12 18:52:44.255011: Current learning rate: 0.00045 
2025-01-12 18:53:26.596659: train_loss -0.8956 
2025-01-12 18:53:26.597172: val_loss -0.7688 
2025-01-12 18:53:26.604626: Pseudo dice [np.float32(0.8083)] 
2025-01-12 18:53:26.610243: Epoch time: 42.35 s 
2025-01-12 18:53:27.159379:  
2025-01-12 18:53:27.159891: Epoch 485 
2025-01-12 18:53:27.164540: Current learning rate: 0.00043 
2025-01-12 18:54:09.483844: train_loss -0.8944 
2025-01-12 18:54:09.483844: val_loss -0.734 
2025-01-12 18:54:09.489931: Pseudo dice [np.float32(0.7935)] 
2025-01-12 18:54:09.493424: Epoch time: 42.32 s 
2025-01-12 18:54:10.054735:  
2025-01-12 18:54:10.056241: Epoch 486 
2025-01-12 18:54:10.061875: Current learning rate: 0.0004 
2025-01-12 18:54:52.359901: train_loss -0.891 
2025-01-12 18:54:52.359901: val_loss -0.7504 
2025-01-12 18:54:52.366191: Pseudo dice [np.float32(0.8076)] 
2025-01-12 18:54:52.369385: Epoch time: 42.31 s 
2025-01-12 18:54:52.920264:  
2025-01-12 18:54:52.920772: Epoch 487 
2025-01-12 18:54:52.926490: Current learning rate: 0.00037 
2025-01-12 18:55:35.227026: train_loss -0.8997 
2025-01-12 18:55:35.228030: val_loss -0.7319 
2025-01-12 18:55:35.233742: Pseudo dice [np.float32(0.7866)] 
2025-01-12 18:55:35.237836: Epoch time: 42.31 s 
2025-01-12 18:55:35.794122:  
2025-01-12 18:55:35.794122: Epoch 488 
2025-01-12 18:55:35.799709: Current learning rate: 0.00035 
2025-01-12 18:56:18.137333: train_loss -0.8948 
2025-01-12 18:56:18.138840: val_loss -0.7647 
2025-01-12 18:56:18.144487: Pseudo dice [np.float32(0.8142)] 
2025-01-12 18:56:18.148065: Epoch time: 42.34 s 
2025-01-12 18:56:18.697850:  
2025-01-12 18:56:18.697850: Epoch 489 
2025-01-12 18:56:18.702876: Current learning rate: 0.00032 
2025-01-12 18:57:01.041697: train_loss -0.8962 
2025-01-12 18:57:01.042204: val_loss -0.7648 
2025-01-12 18:57:01.047373: Pseudo dice [np.float32(0.8125)] 
2025-01-12 18:57:01.053556: Epoch time: 42.34 s 
2025-01-12 18:57:01.605277:  
2025-01-12 18:57:01.605277: Epoch 490 
2025-01-12 18:57:01.610469: Current learning rate: 0.0003 
2025-01-12 18:57:43.935283: train_loss -0.898 
2025-01-12 18:57:43.936289: val_loss -0.7579 
2025-01-12 18:57:43.942371: Pseudo dice [np.float32(0.8108)] 
2025-01-12 18:57:43.946601: Epoch time: 42.33 s 
2025-01-12 18:57:44.504478:  
2025-01-12 18:57:44.504992: Epoch 491 
2025-01-12 18:57:44.510064: Current learning rate: 0.00027 
2025-01-12 18:58:26.844214: train_loss -0.8953 
2025-01-12 18:58:26.844214: val_loss -0.7548 
2025-01-12 18:58:26.850285: Pseudo dice [np.float32(0.816)] 
2025-01-12 18:58:26.853627: Epoch time: 42.34 s 
2025-01-12 18:58:27.558401:  
2025-01-12 18:58:27.558923: Epoch 492 
2025-01-12 18:58:27.563570: Current learning rate: 0.00024 
2025-01-12 18:59:10.868244: train_loss -0.8935 
2025-01-12 18:59:10.868754: val_loss -0.7813 
2025-01-12 18:59:10.874947: Pseudo dice [np.float32(0.8281)] 
2025-01-12 18:59:10.880008: Epoch time: 43.31 s 
2025-01-12 18:59:11.563142:  
2025-01-12 18:59:11.563647: Epoch 493 
2025-01-12 18:59:11.569287: Current learning rate: 0.00021 
2025-01-12 18:59:55.214931: train_loss -0.8972 
2025-01-12 18:59:55.215438: val_loss -0.7682 
2025-01-12 18:59:55.220984: Pseudo dice [np.float32(0.8111)] 
2025-01-12 18:59:55.224517: Epoch time: 43.65 s 
2025-01-12 18:59:55.777556:  
2025-01-12 18:59:55.777556: Epoch 494 
2025-01-12 18:59:55.782631: Current learning rate: 0.00019 
2025-01-12 19:00:38.110204: train_loss -0.8994 
2025-01-12 19:00:38.110709: val_loss -0.7461 
2025-01-12 19:00:38.115900: Pseudo dice [np.float32(0.8069)] 
2025-01-12 19:00:38.118535: Epoch time: 42.33 s 
2025-01-12 19:00:38.671594:  
2025-01-12 19:00:38.671594: Epoch 495 
2025-01-12 19:00:38.676749: Current learning rate: 0.00016 
2025-01-12 19:01:20.977802: train_loss -0.9041 
2025-01-12 19:01:20.978304: val_loss -0.6953 
2025-01-12 19:01:20.983987: Pseudo dice [np.float32(0.7747)] 
2025-01-12 19:01:20.987999: Epoch time: 42.31 s 
2025-01-12 19:01:21.552625:  
2025-01-12 19:01:21.553700: Epoch 496 
2025-01-12 19:01:21.559284: Current learning rate: 0.00013 
2025-01-12 19:02:03.859001: train_loss -0.9007 
2025-01-12 19:02:03.859001: val_loss -0.7376 
2025-01-12 19:02:03.865660: Pseudo dice [np.float32(0.7955)] 
2025-01-12 19:02:03.869232: Epoch time: 42.31 s 
2025-01-12 19:02:04.468048:  
2025-01-12 19:02:04.468048: Epoch 497 
2025-01-12 19:02:04.473710: Current learning rate: 0.0001 
2025-01-12 19:02:46.782462: train_loss -0.8921 
2025-01-12 19:02:46.782462: val_loss -0.7613 
2025-01-12 19:02:46.788477: Pseudo dice [np.float32(0.8203)] 
2025-01-12 19:02:46.792496: Epoch time: 42.32 s 
2025-01-12 19:02:47.344557:  
2025-01-12 19:02:47.344557: Epoch 498 
2025-01-12 19:02:47.350134: Current learning rate: 7e-05 
2025-01-12 19:03:29.691626: train_loss -0.8994 
2025-01-12 19:03:29.692629: val_loss -0.7265 
2025-01-12 19:03:29.698285: Pseudo dice [np.float32(0.7893)] 
2025-01-12 19:03:29.701792: Epoch time: 42.35 s 
2025-01-12 19:03:30.252231:  
2025-01-12 19:03:30.252231: Epoch 499 
2025-01-12 19:03:30.258406: Current learning rate: 4e-05 
2025-01-12 19:04:12.569934: train_loss -0.8992 
2025-01-12 19:04:12.569934: val_loss -0.7589 
2025-01-12 19:04:12.576116: Pseudo dice [np.float32(0.8114)] 
2025-01-12 19:04:12.580149: Epoch time: 42.32 s 
2025-01-12 19:04:13.498741: Training done. 
2025-01-12 19:04:13.530337: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2025-01-12 19:04:13.542205: The split file contains 5 splits. 
2025-01-12 19:04:13.548955: Desired fold for training: 0 
2025-01-12 19:04:13.554156: This split has 50 training and 13 validation cases. 
2025-01-12 19:04:13.559156: predicting lung_006 
2025-01-12 19:04:13.564321: lung_006, shape torch.Size([1, 285, 637, 637]), rank 0 
2025-01-12 19:05:02.051267: predicting lung_010 
2025-01-12 19:05:02.093967: lung_010, shape torch.Size([1, 242, 390, 390]), rank 0 
2025-01-12 19:05:20.896966: predicting lung_033 
2025-01-12 19:05:20.911091: lung_033, shape torch.Size([1, 260, 535, 535]), rank 0 
2025-01-12 19:05:58.849612: predicting lung_034 
2025-01-12 19:05:58.877406: lung_034, shape torch.Size([1, 296, 586, 586]), rank 0 
2025-01-12 19:06:53.009784: predicting lung_041 
2025-01-12 19:06:53.046297: lung_041, shape torch.Size([1, 240, 535, 535]), rank 0 
2025-01-12 19:07:26.334926: predicting lung_042 
2025-01-12 19:07:26.360110: lung_042, shape torch.Size([1, 251, 478, 478]), rank 0 
2025-01-12 19:07:51.841238: predicting lung_046 
2025-01-12 19:07:51.863161: lung_046, shape torch.Size([1, 226, 509, 509]), rank 0 
2025-01-12 19:08:17.362984: predicting lung_048 
2025-01-12 19:08:17.386230: lung_048, shape torch.Size([1, 259, 531, 531]), rank 0 
2025-01-12 19:08:55.360544: predicting lung_059 
2025-01-12 19:08:55.387845: lung_059, shape torch.Size([1, 218, 535, 535]), rank 0 
2025-01-12 19:09:23.855113: predicting lung_065 
2025-01-12 19:09:23.880380: lung_065, shape torch.Size([1, 257, 474, 474]), rank 0 
2025-01-12 19:09:52.997619: predicting lung_066 
2025-01-12 19:09:53.019619: lung_066, shape torch.Size([1, 241, 578, 578]), rank 0 
2025-01-12 19:10:35.176144: predicting lung_070 
2025-01-12 19:10:35.206457: lung_070, shape torch.Size([1, 266, 497, 497]), rank 0 
2025-01-12 19:11:04.411507: predicting lung_079 
2025-01-12 19:11:04.436841: lung_079, shape torch.Size([1, 251, 606, 606]), rank 0 
2025-01-12 19:11:56.655618: Validation complete 
2025-01-12 19:11:56.655618: Mean Validation Dice:  0.7220616781636922 
