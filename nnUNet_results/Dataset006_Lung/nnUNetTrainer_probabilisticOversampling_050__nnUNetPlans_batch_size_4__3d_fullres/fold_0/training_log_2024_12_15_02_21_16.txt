2024-12-15 02:21:16.851756: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.5 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-15 02:21:16.856755: self.oversample_foreground_percent 0.6 
2024-12-15 02:21:16.860756: do_dummy_2d_data_aug: False 
2024-12-15 02:21:16.863759: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2024-12-15 02:21:16.868756: The split file contains 5 splits. 
2024-12-15 02:21:16.871756: Desired fold for training: 0 
2024-12-15 02:21:16.873755: This split has 50 training and 13 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 5, 'patch_size': [64, 128, 128], 'median_image_size_in_voxels': [252.0, 512.0, 512.0], 'spacing': [1.244979977607727, 0.78515625, 0.78515625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset006_Lung', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [1.244979977607727, 0.78515625, 0.78515625], 'original_median_shape_after_transp': [252, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2671.0, 'mean': -273.4598083496094, 'median': -162.0, 'min': -1024.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 311.0, 'std': 346.9495849609375}}} 
 
2024-12-15 02:21:34.899776: unpacking dataset... 
2024-12-15 02:21:49.143085: unpacking done... 
2024-12-15 02:21:51.800627:  
2024-12-15 02:21:51.805636: Epoch 0 
2024-12-15 02:21:51.809140: Current learning rate: 0.01 
2024-12-15 02:22:39.305872: train_loss -0.0522 
2024-12-15 02:22:39.311960: val_loss -0.525 
2024-12-15 02:22:39.315523: Pseudo dice [np.float32(0.614)] 
2024-12-15 02:22:39.318071: Epoch time: 47.51 s 
2024-12-15 02:22:39.321663: Yayy! New best EMA pseudo Dice: 0.6140000224113464 
2024-12-15 02:22:39.976417:  
2024-12-15 02:22:39.981978: Epoch 1 
2024-12-15 02:22:39.984522: Current learning rate: 0.00991 
2024-12-15 02:23:22.818019: train_loss -0.4207 
2024-12-15 02:23:22.823533: val_loss -0.5824 
2024-12-15 02:23:22.827042: Pseudo dice [np.float32(0.6534)] 
2024-12-15 02:23:22.829548: Epoch time: 42.84 s 
2024-12-15 02:23:22.833054: Yayy! New best EMA pseudo Dice: 0.6179999709129333 
2024-12-15 02:23:23.549110:  
2024-12-15 02:23:23.555141: Epoch 2 
2024-12-15 02:23:23.558666: Current learning rate: 0.00982 
2024-12-15 02:24:06.909719: train_loss -0.4793 
2024-12-15 02:24:06.914763: val_loss -0.6046 
2024-12-15 02:24:06.918401: Pseudo dice [np.float32(0.6852)] 
2024-12-15 02:24:06.921925: Epoch time: 43.36 s 
2024-12-15 02:24:06.924948: Yayy! New best EMA pseudo Dice: 0.6247000098228455 
2024-12-15 02:24:07.713930:  
2024-12-15 02:24:07.720097: Epoch 3 
2024-12-15 02:24:07.724657: Current learning rate: 0.00973 
2024-12-15 02:24:52.350024: train_loss -0.4711 
2024-12-15 02:24:52.356049: val_loss -0.587 
2024-12-15 02:24:52.360073: Pseudo dice [np.float32(0.6753)] 
2024-12-15 02:24:52.363587: Epoch time: 44.64 s 
2024-12-15 02:24:52.367598: Yayy! New best EMA pseudo Dice: 0.629800021648407 
2024-12-15 02:24:53.113786:  
2024-12-15 02:24:53.119855: Epoch 4 
2024-12-15 02:24:53.122936: Current learning rate: 0.00964 
2024-12-15 02:25:37.798548: train_loss -0.5083 
2024-12-15 02:25:37.804603: val_loss -0.6328 
2024-12-15 02:25:37.808612: Pseudo dice [np.float32(0.7187)] 
2024-12-15 02:25:37.811163: Epoch time: 44.69 s 
2024-12-15 02:25:37.814677: Yayy! New best EMA pseudo Dice: 0.6385999917984009 
2024-12-15 02:25:38.679340:  
2024-12-15 02:25:38.684387: Epoch 5 
2024-12-15 02:25:38.687903: Current learning rate: 0.00955 
2024-12-15 02:26:22.838399: train_loss -0.5245 
2024-12-15 02:26:22.844417: val_loss -0.6817 
2024-12-15 02:26:22.848430: Pseudo dice [np.float32(0.7577)] 
2024-12-15 02:26:22.851943: Epoch time: 44.16 s 
2024-12-15 02:26:22.854449: Yayy! New best EMA pseudo Dice: 0.650600016117096 
2024-12-15 02:26:23.585230:  
2024-12-15 02:26:23.592298: Epoch 6 
2024-12-15 02:26:23.595886: Current learning rate: 0.00946 
2024-12-15 02:27:08.085152: train_loss -0.5429 
2024-12-15 02:27:08.091188: val_loss -0.5778 
2024-12-15 02:27:08.093868: Pseudo dice [np.float32(0.6647)] 
2024-12-15 02:27:08.097392: Epoch time: 44.5 s 
2024-12-15 02:27:08.099913: Yayy! New best EMA pseudo Dice: 0.6520000100135803 
2024-12-15 02:27:08.825525:  
2024-12-15 02:27:08.831077: Epoch 7 
2024-12-15 02:27:08.834653: Current learning rate: 0.00937 
2024-12-15 02:27:52.099273: train_loss -0.5377 
2024-12-15 02:27:52.105294: val_loss -0.6186 
2024-12-15 02:27:52.109346: Pseudo dice [np.float32(0.6983)] 
2024-12-15 02:27:52.112860: Epoch time: 43.27 s 
2024-12-15 02:27:52.116870: Yayy! New best EMA pseudo Dice: 0.6565999984741211 
2024-12-15 02:27:52.858811:  
2024-12-15 02:27:52.864376: Epoch 8 
2024-12-15 02:27:52.867517: Current learning rate: 0.00928 
2024-12-15 02:28:36.305283: train_loss -0.5406 
2024-12-15 02:28:36.310801: val_loss -0.5681 
2024-12-15 02:28:36.314309: Pseudo dice [np.float32(0.6547)] 
2024-12-15 02:28:36.317815: Epoch time: 43.45 s 
2024-12-15 02:28:36.904268:  
2024-12-15 02:28:36.909819: Epoch 9 
2024-12-15 02:28:36.913362: Current learning rate: 0.00919 
2024-12-15 02:29:20.419043: train_loss -0.5518 
2024-12-15 02:29:20.425061: val_loss -0.5894 
2024-12-15 02:29:20.428568: Pseudo dice [np.float32(0.6725)] 
2024-12-15 02:29:20.431576: Epoch time: 43.52 s 
2024-12-15 02:29:20.434082: Yayy! New best EMA pseudo Dice: 0.6579999923706055 
2024-12-15 02:29:21.158490:  
2024-12-15 02:29:21.164101: Epoch 10 
2024-12-15 02:29:21.167119: Current learning rate: 0.0091 
2024-12-15 02:30:05.067136: train_loss -0.5784 
2024-12-15 02:30:05.072182: val_loss -0.6088 
2024-12-15 02:30:05.075691: Pseudo dice [np.float32(0.7179)] 
2024-12-15 02:30:05.079754: Epoch time: 43.91 s 
2024-12-15 02:30:05.082260: Yayy! New best EMA pseudo Dice: 0.6639999747276306 
2024-12-15 02:30:05.811282:  
2024-12-15 02:30:05.816294: Epoch 11 
2024-12-15 02:30:05.818800: Current learning rate: 0.009 
2024-12-15 02:30:49.916019: train_loss -0.6093 
2024-12-15 02:30:49.921536: val_loss -0.6134 
2024-12-15 02:30:49.924042: Pseudo dice [np.float32(0.6754)] 
2024-12-15 02:30:49.927553: Epoch time: 44.11 s 
2024-12-15 02:30:49.930058: Yayy! New best EMA pseudo Dice: 0.6651999950408936 
2024-12-15 02:30:50.665244:  
2024-12-15 02:30:50.670509: Epoch 12 
2024-12-15 02:30:50.673015: Current learning rate: 0.00891 
2024-12-15 02:31:34.396826: train_loss -0.6223 
2024-12-15 02:31:34.402844: val_loss -0.6829 
2024-12-15 02:31:34.406351: Pseudo dice [np.float32(0.7583)] 
2024-12-15 02:31:34.409361: Epoch time: 43.73 s 
2024-12-15 02:31:34.412871: Yayy! New best EMA pseudo Dice: 0.6744999885559082 
2024-12-15 02:31:35.299441:  
2024-12-15 02:31:35.304957: Epoch 13 
2024-12-15 02:31:35.307464: Current learning rate: 0.00882 
2024-12-15 02:32:19.119835: train_loss -0.6305 
2024-12-15 02:32:19.125429: val_loss -0.6437 
2024-12-15 02:32:19.128469: Pseudo dice [np.float32(0.7213)] 
2024-12-15 02:32:19.132034: Epoch time: 43.82 s 
2024-12-15 02:32:19.134543: Yayy! New best EMA pseudo Dice: 0.6791999936103821 
2024-12-15 02:32:19.870551:  
2024-12-15 02:32:19.876134: Epoch 14 
2024-12-15 02:32:19.879717: Current learning rate: 0.00873 
2024-12-15 02:33:03.593059: train_loss -0.638 
2024-12-15 02:33:03.599069: val_loss -0.7188 
2024-12-15 02:33:03.602121: Pseudo dice [np.float32(0.7834)] 
2024-12-15 02:33:03.604626: Epoch time: 43.72 s 
2024-12-15 02:33:03.608135: Yayy! New best EMA pseudo Dice: 0.6895999908447266 
2024-12-15 02:33:04.347729:  
2024-12-15 02:33:04.353280: Epoch 15 
2024-12-15 02:33:04.355820: Current learning rate: 0.00864 
2024-12-15 02:33:48.119996: train_loss -0.6312 
2024-12-15 02:33:48.125013: val_loss -0.6203 
2024-12-15 02:33:48.129528: Pseudo dice [np.float32(0.6998)] 
2024-12-15 02:33:48.133546: Epoch time: 43.77 s 
2024-12-15 02:33:48.136557: Yayy! New best EMA pseudo Dice: 0.6905999779701233 
2024-12-15 02:33:48.889257:  
2024-12-15 02:33:48.894874: Epoch 16 
2024-12-15 02:33:48.898383: Current learning rate: 0.00855 
2024-12-15 02:34:32.593477: train_loss -0.6566 
2024-12-15 02:34:32.599111: val_loss -0.6281 
2024-12-15 02:34:32.602665: Pseudo dice [np.float32(0.6895)] 
2024-12-15 02:34:32.605201: Epoch time: 43.7 s 
2024-12-15 02:34:33.217685:  
2024-12-15 02:34:33.223241: Epoch 17 
2024-12-15 02:34:33.225776: Current learning rate: 0.00846 
2024-12-15 02:35:16.820227: train_loss -0.6173 
2024-12-15 02:35:16.825744: val_loss -0.6496 
2024-12-15 02:35:16.829261: Pseudo dice [np.float32(0.7422)] 
2024-12-15 02:35:16.832767: Epoch time: 43.6 s 
2024-12-15 02:35:16.835780: Yayy! New best EMA pseudo Dice: 0.6956999897956848 
2024-12-15 02:35:17.589769:  
2024-12-15 02:35:17.595329: Epoch 18 
2024-12-15 02:35:17.598371: Current learning rate: 0.00836 
2024-12-15 02:36:01.431392: train_loss -0.6608 
2024-12-15 02:36:01.437416: val_loss -0.7233 
2024-12-15 02:36:01.441437: Pseudo dice [np.float32(0.7809)] 
2024-12-15 02:36:01.444950: Epoch time: 43.84 s 
2024-12-15 02:36:01.448464: Yayy! New best EMA pseudo Dice: 0.704200029373169 
2024-12-15 02:36:02.208517:  
2024-12-15 02:36:02.214113: Epoch 19 
2024-12-15 02:36:02.217152: Current learning rate: 0.00827 
2024-12-15 02:36:45.462648: train_loss -0.6486 
2024-12-15 02:36:45.469276: val_loss -0.6692 
2024-12-15 02:36:45.472941: Pseudo dice [np.float32(0.7485)] 
2024-12-15 02:36:45.476032: Epoch time: 43.26 s 
2024-12-15 02:36:45.478566: Yayy! New best EMA pseudo Dice: 0.7085999846458435 
2024-12-15 02:36:46.222400:  
2024-12-15 02:36:46.227418: Epoch 20 
2024-12-15 02:36:46.230932: Current learning rate: 0.00818 
2024-12-15 02:37:29.048338: train_loss -0.6765 
2024-12-15 02:37:29.054355: val_loss -0.7143 
2024-12-15 02:37:29.058365: Pseudo dice [np.float32(0.7648)] 
2024-12-15 02:37:29.061877: Epoch time: 42.83 s 
2024-12-15 02:37:29.064384: Yayy! New best EMA pseudo Dice: 0.7142000198364258 
2024-12-15 02:37:29.988532:  
2024-12-15 02:37:29.992565: Epoch 21 
2024-12-15 02:37:29.995094: Current learning rate: 0.00809 
2024-12-15 02:38:12.553629: train_loss -0.6592 
2024-12-15 02:38:12.559189: val_loss -0.4926 
2024-12-15 02:38:12.562715: Pseudo dice [np.float32(0.5817)] 
2024-12-15 02:38:12.565743: Epoch time: 42.57 s 
2024-12-15 02:38:13.124826:  
2024-12-15 02:38:13.130412: Epoch 22 
2024-12-15 02:38:13.133447: Current learning rate: 0.008 
2024-12-15 02:38:55.705067: train_loss -0.635 
2024-12-15 02:38:55.711083: val_loss -0.7395 
2024-12-15 02:38:55.714095: Pseudo dice [np.float32(0.7918)] 
2024-12-15 02:38:55.717609: Epoch time: 42.58 s 
2024-12-15 02:38:56.276301:  
2024-12-15 02:38:56.281349: Epoch 23 
2024-12-15 02:38:56.284408: Current learning rate: 0.0079 
2024-12-15 02:39:38.867527: train_loss -0.6992 
2024-12-15 02:39:38.874052: val_loss -0.6616 
2024-12-15 02:39:38.877568: Pseudo dice [np.float32(0.7549)] 
2024-12-15 02:39:38.880076: Epoch time: 42.59 s 
2024-12-15 02:39:38.883586: Yayy! New best EMA pseudo Dice: 0.7145000100135803 
2024-12-15 02:39:39.595031:  
2024-12-15 02:39:39.600042: Epoch 24 
2024-12-15 02:39:39.603551: Current learning rate: 0.00781 
2024-12-15 02:40:22.177987: train_loss -0.6738 
2024-12-15 02:40:22.183503: val_loss -0.7291 
2024-12-15 02:40:22.187014: Pseudo dice [np.float32(0.7943)] 
2024-12-15 02:40:22.190518: Epoch time: 42.58 s 
2024-12-15 02:40:22.193527: Yayy! New best EMA pseudo Dice: 0.7225000262260437 
2024-12-15 02:40:22.915700:  
2024-12-15 02:40:22.921212: Epoch 25 
2024-12-15 02:40:22.924721: Current learning rate: 0.00772 
2024-12-15 02:41:05.513836: train_loss -0.6975 
2024-12-15 02:41:05.519469: val_loss -0.6459 
2024-12-15 02:41:05.523004: Pseudo dice [np.float32(0.7055)] 
2024-12-15 02:41:05.526562: Epoch time: 42.6 s 
2024-12-15 02:41:06.076809:  
2024-12-15 02:41:06.081851: Epoch 26 
2024-12-15 02:41:06.085370: Current learning rate: 0.00763 
2024-12-15 02:41:48.624351: train_loss -0.6442 
2024-12-15 02:41:48.629994: val_loss -0.6807 
2024-12-15 02:41:48.633030: Pseudo dice [np.float32(0.7651)] 
2024-12-15 02:41:48.636554: Epoch time: 42.55 s 
2024-12-15 02:41:48.639191: Yayy! New best EMA pseudo Dice: 0.7251999974250793 
2024-12-15 02:41:49.354171:  
2024-12-15 02:41:49.359725: Epoch 27 
2024-12-15 02:41:49.362278: Current learning rate: 0.00753 
2024-12-15 02:42:31.936940: train_loss -0.675 
2024-12-15 02:42:31.943456: val_loss -0.7488 
2024-12-15 02:42:31.946965: Pseudo dice [np.float32(0.7955)] 
2024-12-15 02:42:31.949471: Epoch time: 42.58 s 
2024-12-15 02:42:31.952976: Yayy! New best EMA pseudo Dice: 0.7322999835014343 
2024-12-15 02:42:32.677590:  
2024-12-15 02:42:32.683103: Epoch 28 
2024-12-15 02:42:32.685609: Current learning rate: 0.00744 
2024-12-15 02:43:15.354174: train_loss -0.7089 
2024-12-15 02:43:15.359192: val_loss -0.6734 
2024-12-15 02:43:15.363210: Pseudo dice [np.float32(0.759)] 
2024-12-15 02:43:15.366722: Epoch time: 42.68 s 
2024-12-15 02:43:15.369231: Yayy! New best EMA pseudo Dice: 0.7348999977111816 
2024-12-15 02:43:16.236393:  
2024-12-15 02:43:16.241424: Epoch 29 
2024-12-15 02:43:16.244452: Current learning rate: 0.00735 
2024-12-15 02:43:58.599307: train_loss -0.7111 
2024-12-15 02:43:58.605823: val_loss -0.6657 
2024-12-15 02:43:58.609332: Pseudo dice [np.float32(0.7308)] 
2024-12-15 02:43:58.613339: Epoch time: 42.36 s 
2024-12-15 02:43:59.177751:  
2024-12-15 02:43:59.182861: Epoch 30 
2024-12-15 02:43:59.185411: Current learning rate: 0.00725 
2024-12-15 02:44:41.538463: train_loss -0.7105 
2024-12-15 02:44:41.543498: val_loss -0.6946 
2024-12-15 02:44:41.548021: Pseudo dice [np.float32(0.7779)] 
2024-12-15 02:44:41.551046: Epoch time: 42.36 s 
2024-12-15 02:44:41.554565: Yayy! New best EMA pseudo Dice: 0.7389000058174133 
2024-12-15 02:44:42.281441:  
2024-12-15 02:44:42.286953: Epoch 31 
2024-12-15 02:44:42.290462: Current learning rate: 0.00716 
2024-12-15 02:45:24.668761: train_loss -0.7158 
2024-12-15 02:45:24.674277: val_loss -0.7338 
2024-12-15 02:45:24.677786: Pseudo dice [np.float32(0.7954)] 
2024-12-15 02:45:24.680292: Epoch time: 42.39 s 
2024-12-15 02:45:24.683798: Yayy! New best EMA pseudo Dice: 0.7444999814033508 
2024-12-15 02:45:25.411798:  
2024-12-15 02:45:25.415805: Epoch 32 
2024-12-15 02:45:25.419313: Current learning rate: 0.00707 
2024-12-15 02:46:07.803597: train_loss -0.7392 
2024-12-15 02:46:07.808734: val_loss -0.6299 
2024-12-15 02:46:07.812765: Pseudo dice [np.float32(0.7176)] 
2024-12-15 02:46:07.815792: Epoch time: 42.39 s 
2024-12-15 02:46:08.383357:  
2024-12-15 02:46:08.388380: Epoch 33 
2024-12-15 02:46:08.392402: Current learning rate: 0.00697 
2024-12-15 02:46:50.761937: train_loss -0.708 
2024-12-15 02:46:50.767575: val_loss -0.5946 
2024-12-15 02:46:50.770600: Pseudo dice [np.float32(0.6934)] 
2024-12-15 02:46:50.774621: Epoch time: 42.38 s 
2024-12-15 02:46:51.336065:  
2024-12-15 02:46:51.341077: Epoch 34 
2024-12-15 02:46:51.344085: Current learning rate: 0.00688 
2024-12-15 02:47:33.731700: train_loss -0.7201 
2024-12-15 02:47:33.737749: val_loss -0.6611 
2024-12-15 02:47:33.740818: Pseudo dice [np.float32(0.7626)] 
2024-12-15 02:47:33.743343: Epoch time: 42.4 s 
2024-12-15 02:47:34.313351:  
2024-12-15 02:47:34.318920: Epoch 35 
2024-12-15 02:47:34.321971: Current learning rate: 0.00679 
2024-12-15 02:48:16.660971: train_loss -0.7321 
2024-12-15 02:48:16.666542: val_loss -0.7087 
2024-12-15 02:48:16.670106: Pseudo dice [np.float32(0.7814)] 
2024-12-15 02:48:16.673652: Epoch time: 42.35 s 
2024-12-15 02:48:17.242823:  
2024-12-15 02:48:17.248336: Epoch 36 
2024-12-15 02:48:17.250841: Current learning rate: 0.00669 
2024-12-15 02:48:59.582838: train_loss -0.7439 
2024-12-15 02:48:59.587924: val_loss -0.6559 
2024-12-15 02:48:59.591977: Pseudo dice [np.float32(0.719)] 
2024-12-15 02:48:59.595036: Epoch time: 42.34 s 
2024-12-15 02:49:00.321614:  
2024-12-15 02:49:00.326631: Epoch 37 
2024-12-15 02:49:00.329140: Current learning rate: 0.0066 
2024-12-15 02:49:42.671110: train_loss -0.7231 
2024-12-15 02:49:42.677120: val_loss -0.7027 
2024-12-15 02:49:42.681133: Pseudo dice [np.float32(0.7566)] 
2024-12-15 02:49:42.683639: Epoch time: 42.35 s 
2024-12-15 02:49:43.253707:  
2024-12-15 02:49:43.257730: Epoch 38 
2024-12-15 02:49:43.261256: Current learning rate: 0.0065 
2024-12-15 02:50:25.589342: train_loss -0.7047 
2024-12-15 02:50:25.593350: val_loss -0.5893 
2024-12-15 02:50:25.596859: Pseudo dice [np.float32(0.7213)] 
2024-12-15 02:50:25.599364: Epoch time: 42.34 s 
2024-12-15 02:50:26.170812:  
2024-12-15 02:50:26.176392: Epoch 39 
2024-12-15 02:50:26.179953: Current learning rate: 0.00641 
2024-12-15 02:51:08.530333: train_loss -0.665 
2024-12-15 02:51:08.535881: val_loss -0.6945 
2024-12-15 02:51:08.539905: Pseudo dice [np.float32(0.7401)] 
2024-12-15 02:51:08.542924: Epoch time: 42.36 s 
2024-12-15 02:51:09.122383:  
2024-12-15 02:51:09.127394: Epoch 40 
2024-12-15 02:51:09.130402: Current learning rate: 0.00631 
2024-12-15 02:51:51.488503: train_loss -0.7202 
2024-12-15 02:51:51.494588: val_loss -0.7556 
2024-12-15 02:51:51.497622: Pseudo dice [np.float32(0.8144)] 
2024-12-15 02:51:51.500704: Epoch time: 42.37 s 
2024-12-15 02:51:51.503766: Yayy! New best EMA pseudo Dice: 0.7480000257492065 
2024-12-15 02:51:52.252436:  
2024-12-15 02:51:52.257446: Epoch 41 
2024-12-15 02:51:52.260955: Current learning rate: 0.00622 
2024-12-15 02:52:34.620706: train_loss -0.7071 
2024-12-15 02:52:34.626223: val_loss -0.7123 
2024-12-15 02:52:34.629731: Pseudo dice [np.float32(0.7763)] 
2024-12-15 02:52:34.633739: Epoch time: 42.37 s 
2024-12-15 02:52:34.636244: Yayy! New best EMA pseudo Dice: 0.7508000135421753 
2024-12-15 02:52:35.350670:  
2024-12-15 02:52:35.356197: Epoch 42 
2024-12-15 02:52:35.359221: Current learning rate: 0.00612 
2024-12-15 02:53:17.672269: train_loss -0.7157 
2024-12-15 02:53:17.677802: val_loss -0.6879 
2024-12-15 02:53:17.680825: Pseudo dice [np.float32(0.7463)] 
2024-12-15 02:53:17.684344: Epoch time: 42.32 s 
2024-12-15 02:53:18.233339:  
2024-12-15 02:53:18.238394: Epoch 43 
2024-12-15 02:53:18.241928: Current learning rate: 0.00603 
2024-12-15 02:54:00.589939: train_loss -0.6923 
2024-12-15 02:54:00.595453: val_loss -0.6693 
2024-12-15 02:54:00.598962: Pseudo dice [np.float32(0.7441)] 
2024-12-15 02:54:00.602467: Epoch time: 42.36 s 
2024-12-15 02:54:01.305133:  
2024-12-15 02:54:01.310646: Epoch 44 
2024-12-15 02:54:01.314156: Current learning rate: 0.00593 
2024-12-15 02:54:43.644138: train_loss -0.7158 
2024-12-15 02:54:43.649149: val_loss -0.7335 
2024-12-15 02:54:43.652658: Pseudo dice [np.float32(0.8007)] 
2024-12-15 02:54:43.655163: Epoch time: 42.34 s 
2024-12-15 02:54:43.659171: Yayy! New best EMA pseudo Dice: 0.754800021648407 
2024-12-15 02:54:44.377556:  
2024-12-15 02:54:44.381566: Epoch 45 
2024-12-15 02:54:44.384072: Current learning rate: 0.00584 
2024-12-15 02:55:26.743214: train_loss -0.7577 
2024-12-15 02:55:26.747222: val_loss -0.7254 
2024-12-15 02:55:26.751730: Pseudo dice [np.float32(0.7747)] 
2024-12-15 02:55:26.754741: Epoch time: 42.37 s 
2024-12-15 02:55:26.757246: Yayy! New best EMA pseudo Dice: 0.7567999958992004 
2024-12-15 02:55:27.470374:  
2024-12-15 02:55:27.475928: Epoch 46 
2024-12-15 02:55:27.478963: Current learning rate: 0.00574 
2024-12-15 02:56:09.869622: train_loss -0.7616 
2024-12-15 02:56:09.875637: val_loss -0.6754 
2024-12-15 02:56:09.879646: Pseudo dice [np.float32(0.7597)] 
2024-12-15 02:56:09.883154: Epoch time: 42.4 s 
2024-12-15 02:56:09.885660: Yayy! New best EMA pseudo Dice: 0.757099986076355 
2024-12-15 02:56:10.586796:  
2024-12-15 02:56:10.592356: Epoch 47 
2024-12-15 02:56:10.595912: Current learning rate: 0.00565 
2024-12-15 02:56:52.942732: train_loss -0.757 
2024-12-15 02:56:52.947743: val_loss -0.7124 
2024-12-15 02:56:52.951252: Pseudo dice [np.float32(0.7736)] 
2024-12-15 02:56:52.955260: Epoch time: 42.36 s 
2024-12-15 02:56:52.957766: Yayy! New best EMA pseudo Dice: 0.7587000131607056 
2024-12-15 02:56:53.671636:  
2024-12-15 02:56:53.676645: Epoch 48 
2024-12-15 02:56:53.680154: Current learning rate: 0.00555 
2024-12-15 02:57:36.038563: train_loss -0.7615 
2024-12-15 02:57:36.044640: val_loss -0.7103 
2024-12-15 02:57:36.048177: Pseudo dice [np.float32(0.7784)] 
2024-12-15 02:57:36.051224: Epoch time: 42.37 s 
2024-12-15 02:57:36.054852: Yayy! New best EMA pseudo Dice: 0.760699987411499 
2024-12-15 02:57:36.771658:  
2024-12-15 02:57:36.776669: Epoch 49 
2024-12-15 02:57:36.780178: Current learning rate: 0.00546 
2024-12-15 02:58:19.108547: train_loss -0.7694 
2024-12-15 02:58:19.113601: val_loss -0.6518 
2024-12-15 02:58:19.117637: Pseudo dice [np.float32(0.7464)] 
2024-12-15 02:58:19.120693: Epoch time: 42.34 s 
2024-12-15 02:58:19.819100:  
2024-12-15 02:58:19.824131: Epoch 50 
2024-12-15 02:58:19.827179: Current learning rate: 0.00536 
2024-12-15 02:59:02.148038: train_loss -0.7795 
2024-12-15 02:59:02.154053: val_loss -0.6714 
2024-12-15 02:59:02.157061: Pseudo dice [np.float32(0.7549)] 
2024-12-15 02:59:02.159567: Epoch time: 42.33 s 
2024-12-15 02:59:02.710802:  
2024-12-15 02:59:02.715827: Epoch 51 
2024-12-15 02:59:02.718835: Current learning rate: 0.00526 
2024-12-15 02:59:45.120782: train_loss -0.7965 
2024-12-15 02:59:45.126328: val_loss -0.6725 
2024-12-15 02:59:45.130381: Pseudo dice [np.float32(0.7184)] 
2024-12-15 02:59:45.133463: Epoch time: 42.41 s 
2024-12-15 02:59:45.680127:  
2024-12-15 02:59:45.683638: Epoch 52 
2024-12-15 02:59:45.686674: Current learning rate: 0.00517 
2024-12-15 03:00:28.066612: train_loss -0.7844 
2024-12-15 03:00:28.072378: val_loss -0.6641 
2024-12-15 03:00:28.076416: Pseudo dice [np.float32(0.7191)] 
2024-12-15 03:00:28.080055: Epoch time: 42.39 s 
2024-12-15 03:00:28.788380:  
2024-12-15 03:00:28.793916: Epoch 53 
2024-12-15 03:00:28.796948: Current learning rate: 0.00507 
2024-12-15 03:01:11.151991: train_loss -0.7757 
2024-12-15 03:01:11.158007: val_loss -0.7363 
2024-12-15 03:01:11.162016: Pseudo dice [np.float32(0.8005)] 
2024-12-15 03:01:11.165525: Epoch time: 42.36 s 
2024-12-15 03:01:11.725690:  
2024-12-15 03:01:11.731286: Epoch 54 
2024-12-15 03:01:11.734827: Current learning rate: 0.00497 
2024-12-15 03:01:54.099460: train_loss -0.7732 
2024-12-15 03:01:54.104977: val_loss -0.7227 
2024-12-15 03:01:54.107482: Pseudo dice [np.float32(0.7491)] 
2024-12-15 03:01:54.110992: Epoch time: 42.37 s 
2024-12-15 03:01:54.664748:  
2024-12-15 03:01:54.668773: Epoch 55 
2024-12-15 03:01:54.672879: Current learning rate: 0.00487 
2024-12-15 03:02:37.049311: train_loss -0.7867 
2024-12-15 03:02:37.054823: val_loss -0.6952 
2024-12-15 03:02:37.058332: Pseudo dice [np.float32(0.7697)] 
2024-12-15 03:02:37.060839: Epoch time: 42.39 s 
2024-12-15 03:02:37.612823:  
2024-12-15 03:02:37.617857: Epoch 56 
2024-12-15 03:02:37.621371: Current learning rate: 0.00478 
2024-12-15 03:03:19.988582: train_loss -0.7439 
2024-12-15 03:03:19.994595: val_loss -0.7191 
2024-12-15 03:03:19.997604: Pseudo dice [np.float32(0.769)] 
2024-12-15 03:03:20.001113: Epoch time: 42.38 s 
2024-12-15 03:03:20.559460:  
2024-12-15 03:03:20.564494: Epoch 57 
2024-12-15 03:03:20.568079: Current learning rate: 0.00468 
2024-12-15 03:04:02.936828: train_loss -0.7819 
2024-12-15 03:04:02.942417: val_loss -0.7192 
2024-12-15 03:04:02.946524: Pseudo dice [np.float32(0.7755)] 
2024-12-15 03:04:02.949580: Epoch time: 42.38 s 
2024-12-15 03:04:03.501997:  
2024-12-15 03:04:03.507021: Epoch 58 
2024-12-15 03:04:03.509195: Current learning rate: 0.00458 
2024-12-15 03:04:45.879920: train_loss -0.7719 
2024-12-15 03:04:45.884031: val_loss -0.6644 
2024-12-15 03:04:45.886572: Pseudo dice [np.float32(0.7443)] 
2024-12-15 03:04:45.890617: Epoch time: 42.38 s 
2024-12-15 03:04:46.444058:  
2024-12-15 03:04:46.448599: Epoch 59 
2024-12-15 03:04:46.452189: Current learning rate: 0.00448 
2024-12-15 03:05:28.820930: train_loss -0.7956 
2024-12-15 03:05:28.826532: val_loss -0.6439 
2024-12-15 03:05:28.830061: Pseudo dice [np.float32(0.7024)] 
2024-12-15 03:05:28.832709: Epoch time: 42.38 s 
2024-12-15 03:05:29.395665:  
2024-12-15 03:05:29.401211: Epoch 60 
2024-12-15 03:05:29.405254: Current learning rate: 0.00438 
2024-12-15 03:06:11.778679: train_loss -0.7839 
2024-12-15 03:06:11.784690: val_loss -0.6887 
2024-12-15 03:06:11.787701: Pseudo dice [np.float32(0.7559)] 
2024-12-15 03:06:11.791211: Epoch time: 42.38 s 
2024-12-15 03:06:12.507487:  
2024-12-15 03:06:12.512011: Epoch 61 
2024-12-15 03:06:12.515049: Current learning rate: 0.00429 
2024-12-15 03:06:54.877823: train_loss -0.7953 
2024-12-15 03:06:54.882918: val_loss -0.7273 
2024-12-15 03:06:54.886447: Pseudo dice [np.float32(0.7863)] 
2024-12-15 03:06:54.890067: Epoch time: 42.37 s 
2024-12-15 03:06:55.453569:  
2024-12-15 03:06:55.458597: Epoch 62 
2024-12-15 03:06:55.461331: Current learning rate: 0.00419 
2024-12-15 03:07:37.881722: train_loss -0.7788 
2024-12-15 03:07:37.887738: val_loss -0.7618 
2024-12-15 03:07:37.891243: Pseudo dice [np.float32(0.8264)] 
2024-12-15 03:07:37.894253: Epoch time: 42.43 s 
2024-12-15 03:07:37.897764: Yayy! New best EMA pseudo Dice: 0.7633000016212463 
2024-12-15 03:07:38.627329:  
2024-12-15 03:07:38.632874: Epoch 63 
2024-12-15 03:07:38.636919: Current learning rate: 0.00409 
2024-12-15 03:08:21.014966: train_loss -0.7874 
2024-12-15 03:08:21.020481: val_loss -0.7208 
2024-12-15 03:08:21.023994: Pseudo dice [np.float32(0.7866)] 
2024-12-15 03:08:21.027500: Epoch time: 42.39 s 
2024-12-15 03:08:21.030510: Yayy! New best EMA pseudo Dice: 0.7656999826431274 
2024-12-15 03:08:21.764851:  
2024-12-15 03:08:21.770911: Epoch 64 
2024-12-15 03:08:21.773963: Current learning rate: 0.00399 
2024-12-15 03:09:04.140378: train_loss -0.8104 
2024-12-15 03:09:04.146429: val_loss -0.7402 
2024-12-15 03:09:04.150457: Pseudo dice [np.float32(0.8026)] 
2024-12-15 03:09:04.153479: Epoch time: 42.38 s 
2024-12-15 03:09:04.156542: Yayy! New best EMA pseudo Dice: 0.7694000005722046 
2024-12-15 03:09:04.895209:  
2024-12-15 03:09:04.900722: Epoch 65 
2024-12-15 03:09:04.904234: Current learning rate: 0.00389 
2024-12-15 03:09:47.289637: train_loss -0.7982 
2024-12-15 03:09:47.295206: val_loss -0.7241 
2024-12-15 03:09:47.298719: Pseudo dice [np.float32(0.7946)] 
2024-12-15 03:09:47.302223: Epoch time: 42.4 s 
2024-12-15 03:09:47.305232: Yayy! New best EMA pseudo Dice: 0.7718999981880188 
2024-12-15 03:09:48.032867:  
2024-12-15 03:09:48.038400: Epoch 66 
2024-12-15 03:09:48.041908: Current learning rate: 0.00379 
2024-12-15 03:10:30.382433: train_loss -0.798 
2024-12-15 03:10:30.387989: val_loss -0.7323 
2024-12-15 03:10:30.392014: Pseudo dice [np.float32(0.8055)] 
2024-12-15 03:10:30.395054: Epoch time: 42.35 s 
2024-12-15 03:10:30.398085: Yayy! New best EMA pseudo Dice: 0.7753000259399414 
2024-12-15 03:10:31.131478:  
2024-12-15 03:10:31.137071: Epoch 67 
2024-12-15 03:10:31.140640: Current learning rate: 0.00369 
2024-12-15 03:11:13.461846: train_loss -0.8099 
2024-12-15 03:11:13.467864: val_loss -0.7743 
2024-12-15 03:11:13.470368: Pseudo dice [np.float32(0.8266)] 
2024-12-15 03:11:13.473873: Epoch time: 42.33 s 
2024-12-15 03:11:13.476882: Yayy! New best EMA pseudo Dice: 0.7803999781608582 
2024-12-15 03:11:14.213425:  
2024-12-15 03:11:14.218436: Epoch 68 
2024-12-15 03:11:14.221943: Current learning rate: 0.00359 
2024-12-15 03:11:56.573551: train_loss -0.7731 
2024-12-15 03:11:56.580099: val_loss -0.7417 
2024-12-15 03:11:56.583119: Pseudo dice [np.float32(0.788)] 
2024-12-15 03:11:56.586170: Epoch time: 42.36 s 
2024-12-15 03:11:56.589212: Yayy! New best EMA pseudo Dice: 0.7810999751091003 
2024-12-15 03:11:57.492750:  
2024-12-15 03:11:57.498306: Epoch 69 
2024-12-15 03:11:57.502359: Current learning rate: 0.00349 
2024-12-15 03:12:39.861815: train_loss -0.7754 
2024-12-15 03:12:39.867330: val_loss -0.7639 
2024-12-15 03:12:39.870841: Pseudo dice [np.float32(0.8172)] 
2024-12-15 03:12:39.874849: Epoch time: 42.37 s 
2024-12-15 03:12:39.877355: Yayy! New best EMA pseudo Dice: 0.7847999930381775 
2024-12-15 03:12:40.621351:  
2024-12-15 03:12:40.627474: Epoch 70 
2024-12-15 03:12:40.630527: Current learning rate: 0.00338 
2024-12-15 03:13:23.011516: train_loss -0.8003 
2024-12-15 03:13:23.018121: val_loss -0.7682 
2024-12-15 03:13:23.021697: Pseudo dice [np.float32(0.826)] 
2024-12-15 03:13:23.025748: Epoch time: 42.39 s 
2024-12-15 03:13:23.028874: Yayy! New best EMA pseudo Dice: 0.7889000177383423 
2024-12-15 03:13:23.797299:  
2024-12-15 03:13:23.802814: Epoch 71 
2024-12-15 03:13:23.805320: Current learning rate: 0.00328 
2024-12-15 03:14:06.170210: train_loss -0.8052 
2024-12-15 03:14:06.175760: val_loss -0.7351 
2024-12-15 03:14:06.179771: Pseudo dice [np.float32(0.7949)] 
2024-12-15 03:14:06.183283: Epoch time: 42.37 s 
2024-12-15 03:14:06.186790: Yayy! New best EMA pseudo Dice: 0.7894999980926514 
2024-12-15 03:14:06.932287:  
2024-12-15 03:14:06.936867: Epoch 72 
2024-12-15 03:14:06.939921: Current learning rate: 0.00318 
2024-12-15 03:14:49.292277: train_loss -0.7969 
2024-12-15 03:14:49.297981: val_loss -0.7135 
2024-12-15 03:14:49.301055: Pseudo dice [np.float32(0.7716)] 
2024-12-15 03:14:49.305642: Epoch time: 42.36 s 
2024-12-15 03:14:49.888450:  
2024-12-15 03:14:49.894001: Epoch 73 
2024-12-15 03:14:49.896537: Current learning rate: 0.00308 
2024-12-15 03:15:32.264211: train_loss -0.7943 
2024-12-15 03:15:32.269327: val_loss -0.7522 
2024-12-15 03:15:32.273399: Pseudo dice [np.float32(0.7925)] 
2024-12-15 03:15:32.275955: Epoch time: 42.38 s 
2024-12-15 03:15:32.858713:  
2024-12-15 03:15:32.864244: Epoch 74 
2024-12-15 03:15:32.867841: Current learning rate: 0.00297 
2024-12-15 03:16:15.208508: train_loss -0.8063 
2024-12-15 03:16:15.213027: val_loss -0.7716 
2024-12-15 03:16:15.217564: Pseudo dice [np.float32(0.8193)] 
2024-12-15 03:16:15.221075: Epoch time: 42.35 s 
2024-12-15 03:16:15.223581: Yayy! New best EMA pseudo Dice: 0.7912999987602234 
2024-12-15 03:16:15.970380:  
2024-12-15 03:16:15.976920: Epoch 75 
2024-12-15 03:16:15.980483: Current learning rate: 0.00287 
2024-12-15 03:16:58.334647: train_loss -0.8042 
2024-12-15 03:16:58.340663: val_loss -0.7074 
2024-12-15 03:16:58.343172: Pseudo dice [np.float32(0.7159)] 
2024-12-15 03:16:58.347185: Epoch time: 42.36 s 
2024-12-15 03:16:58.925101:  
2024-12-15 03:16:58.930669: Epoch 76 
2024-12-15 03:16:58.933230: Current learning rate: 0.00277 
2024-12-15 03:17:41.313174: train_loss -0.7893 
2024-12-15 03:17:41.319196: val_loss -0.7579 
2024-12-15 03:17:41.322209: Pseudo dice [np.float32(0.8083)] 
2024-12-15 03:17:41.325727: Epoch time: 42.39 s 
2024-12-15 03:17:42.063576:  
2024-12-15 03:17:42.069618: Epoch 77 
2024-12-15 03:17:42.072128: Current learning rate: 0.00266 
2024-12-15 03:18:24.405637: train_loss -0.7967 
2024-12-15 03:18:24.410650: val_loss -0.764 
2024-12-15 03:18:24.414161: Pseudo dice [np.float32(0.82)] 
2024-12-15 03:18:24.417670: Epoch time: 42.34 s 
2024-12-15 03:18:25.002264:  
2024-12-15 03:18:25.007826: Epoch 78 
2024-12-15 03:18:25.011936: Current learning rate: 0.00256 
2024-12-15 03:19:07.355473: train_loss -0.8127 
2024-12-15 03:19:07.361491: val_loss -0.7848 
2024-12-15 03:19:07.364998: Pseudo dice [np.float32(0.8243)] 
2024-12-15 03:19:07.368011: Epoch time: 42.35 s 
2024-12-15 03:19:07.373025: Yayy! New best EMA pseudo Dice: 0.7930999994277954 
2024-12-15 03:19:08.121076:  
2024-12-15 03:19:08.125129: Epoch 79 
2024-12-15 03:19:08.127686: Current learning rate: 0.00245 
2024-12-15 03:19:50.470675: train_loss -0.8178 
2024-12-15 03:19:50.475691: val_loss -0.7406 
2024-12-15 03:19:50.479202: Pseudo dice [np.float32(0.7819)] 
2024-12-15 03:19:50.482214: Epoch time: 42.35 s 
2024-12-15 03:19:51.072692:  
2024-12-15 03:19:51.078263: Epoch 80 
2024-12-15 03:19:51.081857: Current learning rate: 0.00235 
2024-12-15 03:20:33.483872: train_loss -0.8009 
2024-12-15 03:20:33.490976: val_loss -0.7287 
2024-12-15 03:20:33.495007: Pseudo dice [np.float32(0.7876)] 
2024-12-15 03:20:33.497563: Epoch time: 42.41 s 
2024-12-15 03:20:34.090520:  
2024-12-15 03:20:34.095561: Epoch 81 
2024-12-15 03:20:34.098533: Current learning rate: 0.00224 
2024-12-15 03:21:16.476850: train_loss -0.8239 
2024-12-15 03:21:16.481913: val_loss -0.7512 
2024-12-15 03:21:16.485962: Pseudo dice [np.float32(0.8013)] 
2024-12-15 03:21:16.490602: Epoch time: 42.39 s 
2024-12-15 03:21:17.074284:  
2024-12-15 03:21:17.079143: Epoch 82 
2024-12-15 03:21:17.081650: Current learning rate: 0.00214 
2024-12-15 03:21:59.439994: train_loss -0.8274 
2024-12-15 03:21:59.446028: val_loss -0.7096 
2024-12-15 03:21:59.452057: Pseudo dice [np.float32(0.7766)] 
2024-12-15 03:21:59.456076: Epoch time: 42.37 s 
2024-12-15 03:22:00.016699:  
2024-12-15 03:22:00.022718: Epoch 83 
2024-12-15 03:22:00.026731: Current learning rate: 0.00203 
2024-12-15 03:22:42.379503: train_loss -0.8096 
2024-12-15 03:22:42.385105: val_loss -0.6606 
2024-12-15 03:22:42.387660: Pseudo dice [np.float32(0.7386)] 
2024-12-15 03:22:42.392837: Epoch time: 42.36 s 
2024-12-15 03:22:42.946764:  
2024-12-15 03:22:42.950279: Epoch 84 
2024-12-15 03:22:42.953332: Current learning rate: 0.00192 
2024-12-15 03:23:25.301972: train_loss -0.8196 
2024-12-15 03:23:25.306990: val_loss -0.6827 
2024-12-15 03:23:25.310995: Pseudo dice [np.float32(0.7553)] 
2024-12-15 03:23:25.313502: Epoch time: 42.36 s 
2024-12-15 03:23:25.869409:  
2024-12-15 03:23:25.874430: Epoch 85 
2024-12-15 03:23:25.876936: Current learning rate: 0.00181 
2024-12-15 03:24:08.262357: train_loss -0.8233 
2024-12-15 03:24:08.267381: val_loss -0.7488 
2024-12-15 03:24:08.271387: Pseudo dice [np.float32(0.8119)] 
2024-12-15 03:24:08.273897: Epoch time: 42.39 s 
2024-12-15 03:24:08.985802:  
2024-12-15 03:24:08.990823: Epoch 86 
2024-12-15 03:24:08.994339: Current learning rate: 0.0017 
2024-12-15 03:24:51.358368: train_loss -0.8213 
2024-12-15 03:24:51.364893: val_loss -0.7232 
2024-12-15 03:24:51.368401: Pseudo dice [np.float32(0.7709)] 
2024-12-15 03:24:51.370905: Epoch time: 42.37 s 
2024-12-15 03:24:51.927556:  
2024-12-15 03:24:51.933093: Epoch 87 
2024-12-15 03:24:51.936106: Current learning rate: 0.00159 
2024-12-15 03:25:34.339824: train_loss -0.8201 
2024-12-15 03:25:34.346353: val_loss -0.7412 
2024-12-15 03:25:34.349865: Pseudo dice [np.float32(0.7982)] 
2024-12-15 03:25:34.353372: Epoch time: 42.41 s 
2024-12-15 03:25:34.905275:  
2024-12-15 03:25:34.910332: Epoch 88 
2024-12-15 03:25:34.912414: Current learning rate: 0.00148 
2024-12-15 03:26:17.285473: train_loss -0.828 
2024-12-15 03:26:17.291143: val_loss -0.7941 
2024-12-15 03:26:17.294743: Pseudo dice [np.float32(0.8287)] 
2024-12-15 03:26:17.297791: Epoch time: 42.38 s 
2024-12-15 03:26:17.843463:  
2024-12-15 03:26:17.848481: Epoch 89 
2024-12-15 03:26:17.850987: Current learning rate: 0.00137 
2024-12-15 03:27:00.186404: train_loss -0.8318 
2024-12-15 03:27:00.192423: val_loss -0.7301 
2024-12-15 03:27:00.194928: Pseudo dice [np.float32(0.7882)] 
2024-12-15 03:27:00.198946: Epoch time: 42.34 s 
2024-12-15 03:27:00.750668:  
2024-12-15 03:27:00.755680: Epoch 90 
2024-12-15 03:27:00.758690: Current learning rate: 0.00126 
2024-12-15 03:27:43.131474: train_loss -0.8138 
2024-12-15 03:27:43.137496: val_loss -0.7433 
2024-12-15 03:27:43.141001: Pseudo dice [np.float32(0.7991)] 
2024-12-15 03:27:43.144007: Epoch time: 42.38 s 
2024-12-15 03:27:43.698964:  
2024-12-15 03:27:43.704531: Epoch 91 
2024-12-15 03:27:43.707598: Current learning rate: 0.00115 
2024-12-15 03:28:26.050709: train_loss -0.8197 
2024-12-15 03:28:26.056229: val_loss -0.742 
2024-12-15 03:28:26.058736: Pseudo dice [np.float32(0.7767)] 
2024-12-15 03:28:26.062249: Epoch time: 42.35 s 
2024-12-15 03:28:26.622935:  
2024-12-15 03:28:26.628455: Epoch 92 
2024-12-15 03:28:26.630960: Current learning rate: 0.00103 
2024-12-15 03:29:09.005303: train_loss -0.8255 
2024-12-15 03:29:09.010442: val_loss -0.7766 
2024-12-15 03:29:09.012971: Pseudo dice [np.float32(0.8136)] 
2024-12-15 03:29:09.016997: Epoch time: 42.38 s 
2024-12-15 03:29:09.566697:  
2024-12-15 03:29:09.572236: Epoch 93 
2024-12-15 03:29:09.575265: Current learning rate: 0.00091 
2024-12-15 03:29:51.921449: train_loss -0.8357 
2024-12-15 03:29:51.927469: val_loss -0.7354 
2024-12-15 03:29:51.930976: Pseudo dice [np.float32(0.7912)] 
2024-12-15 03:29:51.933987: Epoch time: 42.36 s 
2024-12-15 03:29:52.635952:  
2024-12-15 03:29:52.642092: Epoch 94 
2024-12-15 03:29:52.645146: Current learning rate: 0.00079 
2024-12-15 03:30:35.053914: train_loss -0.8344 
2024-12-15 03:30:35.058983: val_loss -0.7383 
2024-12-15 03:30:35.062790: Pseudo dice [np.float32(0.7902)] 
2024-12-15 03:30:35.066303: Epoch time: 42.42 s 
2024-12-15 03:30:35.618659:  
2024-12-15 03:30:35.624228: Epoch 95 
2024-12-15 03:30:35.628283: Current learning rate: 0.00067 
2024-12-15 03:31:18.262705: train_loss -0.8339 
2024-12-15 03:31:18.268732: val_loss -0.6984 
2024-12-15 03:31:18.272744: Pseudo dice [np.float32(0.7691)] 
2024-12-15 03:31:18.276253: Epoch time: 42.64 s 
2024-12-15 03:31:18.845655:  
2024-12-15 03:31:18.851751: Epoch 96 
2024-12-15 03:31:18.855426: Current learning rate: 0.00055 
2024-12-15 03:32:01.194404: train_loss -0.8368 
2024-12-15 03:32:01.200015: val_loss -0.7411 
2024-12-15 03:32:01.203527: Pseudo dice [np.float32(0.7873)] 
2024-12-15 03:32:01.207031: Epoch time: 42.35 s 
2024-12-15 03:32:01.758896:  
2024-12-15 03:32:01.763949: Epoch 97 
2024-12-15 03:32:01.767458: Current learning rate: 0.00043 
2024-12-15 03:32:44.115524: train_loss -0.8403 
2024-12-15 03:32:44.121123: val_loss -0.777 
2024-12-15 03:32:44.124641: Pseudo dice [np.float32(0.819)] 
2024-12-15 03:32:44.128145: Epoch time: 42.36 s 
2024-12-15 03:32:44.685695:  
2024-12-15 03:32:44.690706: Epoch 98 
2024-12-15 03:32:44.694221: Current learning rate: 0.0003 
2024-12-15 03:33:27.054433: train_loss -0.8374 
2024-12-15 03:33:27.060478: val_loss -0.7418 
2024-12-15 03:33:27.063512: Pseudo dice [np.float32(0.793)] 
2024-12-15 03:33:27.067039: Epoch time: 42.37 s 
2024-12-15 03:33:27.632423:  
2024-12-15 03:33:27.638568: Epoch 99 
2024-12-15 03:33:27.641645: Current learning rate: 0.00016 
2024-12-15 03:34:10.000322: train_loss -0.8279 
2024-12-15 03:34:10.006839: val_loss -0.7455 
2024-12-15 03:34:10.009346: Pseudo dice [np.float32(0.8031)] 
2024-12-15 03:34:10.012855: Epoch time: 42.37 s 
2024-12-15 03:34:10.016864: Yayy! New best EMA pseudo Dice: 0.7932000160217285 
2024-12-15 03:34:10.952852: Training done. 
2024-12-15 03:34:10.977367: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2024-12-15 03:34:10.983366: The split file contains 5 splits. 
2024-12-15 03:34:10.988366: Desired fold for training: 0 
2024-12-15 03:34:10.991365: This split has 50 training and 13 validation cases. 
2024-12-15 03:34:10.995368: predicting lung_006 
2024-12-15 03:34:11.000368: lung_006, shape torch.Size([1, 285, 637, 637]), rank 0 
2024-12-15 03:34:59.593594: predicting lung_010 
2024-12-15 03:34:59.646107: lung_010, shape torch.Size([1, 242, 390, 390]), rank 0 
2024-12-15 03:35:18.441745: predicting lung_033 
2024-12-15 03:35:18.462745: lung_033, shape torch.Size([1, 260, 535, 535]), rank 0 
2024-12-15 03:35:56.667026: predicting lung_034 
2024-12-15 03:35:56.702027: lung_034, shape torch.Size([1, 296, 586, 586]), rank 0 
2024-12-15 03:36:51.023915: predicting lung_041 
2024-12-15 03:36:51.070425: lung_041, shape torch.Size([1, 240, 535, 535]), rank 0 
2024-12-15 03:37:24.447605: predicting lung_042 
2024-12-15 03:37:24.492115: lung_042, shape torch.Size([1, 251, 478, 478]), rank 0 
2024-12-15 03:37:50.098205: predicting lung_046 
2024-12-15 03:37:50.128715: lung_046, shape torch.Size([1, 226, 509, 509]), rank 0 
2024-12-15 03:38:15.709597: predicting lung_048 
2024-12-15 03:38:15.739108: lung_048, shape torch.Size([1, 259, 531, 531]), rank 0 
2024-12-15 03:38:53.935185: predicting lung_059 
2024-12-15 03:38:53.971691: lung_059, shape torch.Size([1, 218, 535, 535]), rank 0 
2024-12-15 03:39:22.604644: predicting lung_065 
2024-12-15 03:39:22.642647: lung_065, shape torch.Size([1, 257, 474, 474]), rank 0 
2024-12-15 03:39:51.853872: predicting lung_066 
2024-12-15 03:39:51.889377: lung_066, shape torch.Size([1, 241, 578, 578]), rank 0 
2024-12-15 03:40:34.117949: predicting lung_070 
2024-12-15 03:40:34.162949: lung_070, shape torch.Size([1, 266, 497, 497]), rank 0 
2024-12-15 03:41:03.403169: predicting lung_079 
2024-12-15 03:41:03.435333: lung_079, shape torch.Size([1, 251, 606, 606]), rank 0 
2024-12-15 03:41:57.208450: Validation complete 
2024-12-15 03:41:57.214449: Mean Validation Dice:  0.6972130740742953 
