2025-01-12 09:09:00.540836: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.5 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-12 09:09:00.544836: self.oversample_foreground_percent 0.6 
2025-01-12 09:09:00.550348: do_dummy_2d_data_aug: False 
2025-01-12 09:09:00.554193: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2025-01-12 09:09:00.556194: The split file contains 5 splits. 
2025-01-12 09:09:00.559193: Desired fold for training: 0 
2025-01-12 09:09:00.561193: This split has 50 training and 13 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 5, 'patch_size': [64, 128, 128], 'median_image_size_in_voxels': [252.0, 512.0, 512.0], 'spacing': [1.244979977607727, 0.78515625, 0.78515625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset006_Lung', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [1.244979977607727, 0.78515625, 0.78515625], 'original_median_shape_after_transp': [252, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2671.0, 'mean': -273.4598083496094, 'median': -162.0, 'min': -1024.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 311.0, 'std': 346.9495849609375}}} 
 
2025-01-12 09:09:08.607657: unpacking dataset... 
2025-01-12 09:09:08.790401: unpacking done... 
2025-01-12 09:09:11.987698:  
2025-01-12 09:09:11.987698: Epoch 0 
2025-01-12 09:09:11.992712: Current learning rate: 0.01 
2025-01-12 09:09:59.044456: train_loss -0.0678 
2025-01-12 09:09:59.045460: val_loss -0.5313 
2025-01-12 09:09:59.050473: Pseudo dice [np.float32(0.6113)] 
2025-01-12 09:09:59.052979: Epoch time: 47.06 s 
2025-01-12 09:09:59.056988: Yayy! New best EMA pseudo Dice: 0.611299991607666 
2025-01-12 09:09:59.694506:  
2025-01-12 09:09:59.694506: Epoch 1 
2025-01-12 09:09:59.699599: Current learning rate: 0.00996 
2025-01-12 09:10:42.298635: train_loss -0.392 
2025-01-12 09:10:42.299137: val_loss -0.6699 
2025-01-12 09:10:42.304151: Pseudo dice [np.float32(0.7556)] 
2025-01-12 09:10:42.308659: Epoch time: 42.6 s 
2025-01-12 09:10:42.312671: Yayy! New best EMA pseudo Dice: 0.6256999969482422 
2025-01-12 09:10:43.069217:  
2025-01-12 09:10:43.069217: Epoch 2 
2025-01-12 09:10:43.074751: Current learning rate: 0.00993 
2025-01-12 09:11:25.672924: train_loss -0.4323 
2025-01-12 09:11:25.673927: val_loss -0.6216 
2025-01-12 09:11:25.678939: Pseudo dice [np.float32(0.7034)] 
2025-01-12 09:11:25.682446: Epoch time: 42.6 s 
2025-01-12 09:11:25.685453: Yayy! New best EMA pseudo Dice: 0.6334999799728394 
2025-01-12 09:11:26.468230:  
2025-01-12 09:11:26.468230: Epoch 3 
2025-01-12 09:11:26.475410: Current learning rate: 0.00989 
2025-01-12 09:12:09.129868: train_loss -0.4962 
2025-01-12 09:12:09.129868: val_loss -0.6691 
2025-01-12 09:12:09.135882: Pseudo dice [np.float32(0.736)] 
2025-01-12 09:12:09.139891: Epoch time: 42.66 s 
2025-01-12 09:12:09.142397: Yayy! New best EMA pseudo Dice: 0.6437000036239624 
2025-01-12 09:12:09.870530:  
2025-01-12 09:12:09.871529: Epoch 4 
2025-01-12 09:12:09.876585: Current learning rate: 0.00986 
2025-01-12 09:12:52.526480: train_loss -0.5409 
2025-01-12 09:12:52.526985: val_loss -0.6485 
2025-01-12 09:12:52.532005: Pseudo dice [np.float32(0.714)] 
2025-01-12 09:12:52.536514: Epoch time: 42.66 s 
2025-01-12 09:12:52.540532: Yayy! New best EMA pseudo Dice: 0.6507999897003174 
2025-01-12 09:12:53.419396:  
2025-01-12 09:12:53.419396: Epoch 5 
2025-01-12 09:12:53.423014: Current learning rate: 0.00982 
2025-01-12 09:13:36.084696: train_loss -0.5262 
2025-01-12 09:13:36.085220: val_loss -0.5769 
2025-01-12 09:13:36.090821: Pseudo dice [np.float32(0.6723)] 
2025-01-12 09:13:36.093341: Epoch time: 42.67 s 
2025-01-12 09:13:36.097915: Yayy! New best EMA pseudo Dice: 0.652899980545044 
2025-01-12 09:13:36.852546:  
2025-01-12 09:13:36.852546: Epoch 6 
2025-01-12 09:13:36.857579: Current learning rate: 0.00978 
2025-01-12 09:14:19.497778: train_loss -0.5673 
2025-01-12 09:14:19.497778: val_loss -0.5873 
2025-01-12 09:14:19.504297: Pseudo dice [np.float32(0.6803)] 
2025-01-12 09:14:19.508806: Epoch time: 42.65 s 
2025-01-12 09:14:19.511814: Yayy! New best EMA pseudo Dice: 0.6556000113487244 
2025-01-12 09:14:20.256321:  
2025-01-12 09:14:20.257320: Epoch 7 
2025-01-12 09:14:20.262894: Current learning rate: 0.00975 
2025-01-12 09:15:02.904017: train_loss -0.5769 
2025-01-12 09:15:02.904017: val_loss -0.6795 
2025-01-12 09:15:02.910032: Pseudo dice [np.float32(0.7436)] 
2025-01-12 09:15:02.913044: Epoch time: 42.65 s 
2025-01-12 09:15:02.916555: Yayy! New best EMA pseudo Dice: 0.6643999814987183 
2025-01-12 09:15:03.654506:  
2025-01-12 09:15:03.654506: Epoch 8 
2025-01-12 09:15:03.659536: Current learning rate: 0.00971 
2025-01-12 09:15:46.421034: train_loss -0.5502 
2025-01-12 09:15:46.422039: val_loss -0.5488 
2025-01-12 09:15:46.427050: Pseudo dice [np.float32(0.6363)] 
2025-01-12 09:15:46.431066: Epoch time: 42.77 s 
2025-01-12 09:15:46.967944:  
2025-01-12 09:15:46.968948: Epoch 9 
2025-01-12 09:15:46.973534: Current learning rate: 0.00968 
2025-01-12 09:16:29.602401: train_loss -0.5835 
2025-01-12 09:16:29.602401: val_loss -0.6857 
2025-01-12 09:16:29.608418: Pseudo dice [np.float32(0.7667)] 
2025-01-12 09:16:29.611430: Epoch time: 42.63 s 
2025-01-12 09:16:29.614943: Yayy! New best EMA pseudo Dice: 0.6721000075340271 
2025-01-12 09:16:30.378979:  
2025-01-12 09:16:30.378979: Epoch 10 
2025-01-12 09:16:30.384530: Current learning rate: 0.00964 
2025-01-12 09:17:13.026607: train_loss -0.6122 
2025-01-12 09:17:13.026607: val_loss -0.5723 
2025-01-12 09:17:13.032622: Pseudo dice [np.float32(0.6879)] 
2025-01-12 09:17:13.035634: Epoch time: 42.65 s 
2025-01-12 09:17:13.039147: Yayy! New best EMA pseudo Dice: 0.6736999750137329 
2025-01-12 09:17:13.816921:  
2025-01-12 09:17:13.817430: Epoch 11 
2025-01-12 09:17:13.822468: Current learning rate: 0.0096 
2025-01-12 09:17:56.481514: train_loss -0.6326 
2025-01-12 09:17:56.481514: val_loss -0.687 
2025-01-12 09:17:56.487111: Pseudo dice [np.float32(0.7575)] 
2025-01-12 09:17:56.491148: Epoch time: 42.67 s 
2025-01-12 09:17:56.494247: Yayy! New best EMA pseudo Dice: 0.6820999979972839 
2025-01-12 09:17:57.263815:  
2025-01-12 09:17:57.263815: Epoch 12 
2025-01-12 09:17:57.268840: Current learning rate: 0.00957 
2025-01-12 09:18:39.928128: train_loss -0.6791 
2025-01-12 09:18:39.928128: val_loss -0.653 
2025-01-12 09:18:39.933827: Pseudo dice [np.float32(0.7297)] 
2025-01-12 09:18:39.937849: Epoch time: 42.67 s 
2025-01-12 09:18:39.940358: Yayy! New best EMA pseudo Dice: 0.6868000030517578 
2025-01-12 09:18:40.872276:  
2025-01-12 09:18:40.872276: Epoch 13 
2025-01-12 09:18:40.877808: Current learning rate: 0.00953 
2025-01-12 09:19:23.559790: train_loss -0.6523 
2025-01-12 09:19:23.560795: val_loss -0.6212 
2025-01-12 09:19:23.565811: Pseudo dice [np.float32(0.7001)] 
2025-01-12 09:19:23.569824: Epoch time: 42.69 s 
2025-01-12 09:19:23.573336: Yayy! New best EMA pseudo Dice: 0.6881999969482422 
2025-01-12 09:19:24.353008:  
2025-01-12 09:19:24.353008: Epoch 14 
2025-01-12 09:19:24.358023: Current learning rate: 0.00949 
2025-01-12 09:20:06.975360: train_loss -0.6769 
2025-01-12 09:20:06.975864: val_loss -0.6693 
2025-01-12 09:20:06.981440: Pseudo dice [np.float32(0.7306)] 
2025-01-12 09:20:06.984479: Epoch time: 42.62 s 
2025-01-12 09:20:06.988014: Yayy! New best EMA pseudo Dice: 0.6923999786376953 
2025-01-12 09:20:07.759837:  
2025-01-12 09:20:07.760838: Epoch 15 
2025-01-12 09:20:07.766442: Current learning rate: 0.00946 
2025-01-12 09:20:50.296306: train_loss -0.6841 
2025-01-12 09:20:50.296306: val_loss -0.7563 
2025-01-12 09:20:50.301316: Pseudo dice [np.float32(0.8146)] 
2025-01-12 09:20:50.305325: Epoch time: 42.54 s 
2025-01-12 09:20:50.308834: Yayy! New best EMA pseudo Dice: 0.7045999765396118 
2025-01-12 09:20:51.050615:  
2025-01-12 09:20:51.050615: Epoch 16 
2025-01-12 09:20:51.055659: Current learning rate: 0.00942 
2025-01-12 09:21:33.492514: train_loss -0.6952 
2025-01-12 09:21:33.492514: val_loss -0.7358 
2025-01-12 09:21:33.499596: Pseudo dice [np.float32(0.8055)] 
2025-01-12 09:21:33.502673: Epoch time: 42.44 s 
2025-01-12 09:21:33.506317: Yayy! New best EMA pseudo Dice: 0.7146999835968018 
2025-01-12 09:21:34.264762:  
2025-01-12 09:21:34.264762: Epoch 17 
2025-01-12 09:21:34.269775: Current learning rate: 0.00939 
2025-01-12 09:22:16.725280: train_loss -0.6893 
2025-01-12 09:22:16.726280: val_loss -0.7502 
2025-01-12 09:22:16.731800: Pseudo dice [np.float32(0.8224)] 
2025-01-12 09:22:16.735313: Epoch time: 42.46 s 
2025-01-12 09:22:16.738821: Yayy! New best EMA pseudo Dice: 0.7254999876022339 
2025-01-12 09:22:17.476980:  
2025-01-12 09:22:17.477483: Epoch 18 
2025-01-12 09:22:17.481023: Current learning rate: 0.00935 
2025-01-12 09:22:59.932979: train_loss -0.6481 
2025-01-12 09:22:59.932979: val_loss -0.6059 
2025-01-12 09:22:59.939512: Pseudo dice [np.float32(0.6984)] 
2025-01-12 09:22:59.943035: Epoch time: 42.46 s 
2025-01-12 09:23:00.473965:  
2025-01-12 09:23:00.473965: Epoch 19 
2025-01-12 09:23:00.480017: Current learning rate: 0.00931 
2025-01-12 09:23:42.911841: train_loss -0.6466 
2025-01-12 09:23:42.911841: val_loss -0.661 
2025-01-12 09:23:42.917849: Pseudo dice [np.float32(0.7307)] 
2025-01-12 09:23:42.921872: Epoch time: 42.44 s 
2025-01-12 09:23:43.452093:  
2025-01-12 09:23:43.452595: Epoch 20 
2025-01-12 09:23:43.457605: Current learning rate: 0.00928 
2025-01-12 09:24:25.861499: train_loss -0.5777 
2025-01-12 09:24:25.862501: val_loss -0.6607 
2025-01-12 09:24:25.868017: Pseudo dice [np.float32(0.7304)] 
2025-01-12 09:24:25.871534: Epoch time: 42.41 s 
2025-01-12 09:24:26.551476:  
2025-01-12 09:24:26.551979: Epoch 21 
2025-01-12 09:24:26.556998: Current learning rate: 0.00924 
2025-01-12 09:25:08.984156: train_loss -0.6563 
2025-01-12 09:25:08.984156: val_loss -0.7104 
2025-01-12 09:25:08.989717: Pseudo dice [np.float32(0.7901)] 
2025-01-12 09:25:08.992252: Epoch time: 42.43 s 
2025-01-12 09:25:08.996921: Yayy! New best EMA pseudo Dice: 0.7307999730110168 
2025-01-12 09:25:09.696529:  
2025-01-12 09:25:09.697031: Epoch 22 
2025-01-12 09:25:09.702050: Current learning rate: 0.0092 
2025-01-12 09:25:52.123474: train_loss -0.6697 
2025-01-12 09:25:52.123474: val_loss -0.6804 
2025-01-12 09:25:52.129486: Pseudo dice [np.float32(0.7515)] 
2025-01-12 09:25:52.133001: Epoch time: 42.43 s 
2025-01-12 09:25:52.136010: Yayy! New best EMA pseudo Dice: 0.7329000234603882 
2025-01-12 09:25:52.898515:  
2025-01-12 09:25:52.898515: Epoch 23 
2025-01-12 09:25:52.904091: Current learning rate: 0.00917 
2025-01-12 09:26:35.337276: train_loss -0.6849 
2025-01-12 09:26:35.337788: val_loss -0.6526 
2025-01-12 09:26:35.342883: Pseudo dice [np.float32(0.7256)] 
2025-01-12 09:26:35.345429: Epoch time: 42.44 s 
2025-01-12 09:26:35.850712:  
2025-01-12 09:26:35.850712: Epoch 24 
2025-01-12 09:26:35.855788: Current learning rate: 0.00913 
2025-01-12 09:27:18.316614: train_loss -0.6961 
2025-01-12 09:27:18.317127: val_loss -0.7243 
2025-01-12 09:27:18.322716: Pseudo dice [np.float32(0.8008)] 
2025-01-12 09:27:18.326261: Epoch time: 42.47 s 
2025-01-12 09:27:18.329868: Yayy! New best EMA pseudo Dice: 0.7390000224113464 
2025-01-12 09:27:19.056838:  
2025-01-12 09:27:19.056838: Epoch 25 
2025-01-12 09:27:19.062419: Current learning rate: 0.0091 
2025-01-12 09:28:01.528356: train_loss -0.715 
2025-01-12 09:28:01.528870: val_loss -0.7495 
2025-01-12 09:28:01.534409: Pseudo dice [np.float32(0.7927)] 
2025-01-12 09:28:01.538418: Epoch time: 42.47 s 
2025-01-12 09:28:01.541932: Yayy! New best EMA pseudo Dice: 0.7444000244140625 
2025-01-12 09:28:02.272533:  
2025-01-12 09:28:02.272533: Epoch 26 
2025-01-12 09:28:02.277543: Current learning rate: 0.00906 
2025-01-12 09:28:44.737388: train_loss -0.7026 
2025-01-12 09:28:44.737935: val_loss -0.7459 
2025-01-12 09:28:44.742494: Pseudo dice [np.float32(0.7978)] 
2025-01-12 09:28:44.746012: Epoch time: 42.47 s 
2025-01-12 09:28:44.750026: Yayy! New best EMA pseudo Dice: 0.7497000098228455 
2025-01-12 09:28:45.506467:  
2025-01-12 09:28:45.507472: Epoch 27 
2025-01-12 09:28:45.512056: Current learning rate: 0.00902 
2025-01-12 09:29:27.997619: train_loss -0.7031 
2025-01-12 09:29:27.998621: val_loss -0.6698 
2025-01-12 09:29:28.004136: Pseudo dice [np.float32(0.7406)] 
2025-01-12 09:29:28.008651: Epoch time: 42.49 s 
2025-01-12 09:29:28.521816:  
2025-01-12 09:29:28.521816: Epoch 28 
2025-01-12 09:29:28.527402: Current learning rate: 0.00899 
2025-01-12 09:30:10.994209: train_loss -0.6893 
2025-01-12 09:30:10.995210: val_loss -0.7112 
2025-01-12 09:30:11.000734: Pseudo dice [np.float32(0.7767)] 
2025-01-12 09:30:11.004249: Epoch time: 42.47 s 
2025-01-12 09:30:11.007762: Yayy! New best EMA pseudo Dice: 0.7516000270843506 
2025-01-12 09:30:11.916940:  
2025-01-12 09:30:11.916940: Epoch 29 
2025-01-12 09:30:11.922525: Current learning rate: 0.00895 
2025-01-12 09:30:54.397690: train_loss -0.7079 
2025-01-12 09:30:54.397690: val_loss -0.6072 
2025-01-12 09:30:54.404203: Pseudo dice [np.float32(0.7063)] 
2025-01-12 09:30:54.407713: Epoch time: 42.48 s 
2025-01-12 09:30:54.937409:  
2025-01-12 09:30:54.937409: Epoch 30 
2025-01-12 09:30:54.943455: Current learning rate: 0.00891 
2025-01-12 09:31:37.395776: train_loss -0.6915 
2025-01-12 09:31:37.395776: val_loss -0.7134 
2025-01-12 09:31:37.401789: Pseudo dice [np.float32(0.7863)] 
2025-01-12 09:31:37.405297: Epoch time: 42.46 s 
2025-01-12 09:31:37.932869:  
2025-01-12 09:31:37.932869: Epoch 31 
2025-01-12 09:31:37.937878: Current learning rate: 0.00888 
2025-01-12 09:32:20.355471: train_loss -0.6923 
2025-01-12 09:32:20.355974: val_loss -0.7559 
2025-01-12 09:32:20.361074: Pseudo dice [np.float32(0.7967)] 
2025-01-12 09:32:20.364639: Epoch time: 42.42 s 
2025-01-12 09:32:20.368251: Yayy! New best EMA pseudo Dice: 0.7555999755859375 
2025-01-12 09:32:21.141553:  
2025-01-12 09:32:21.142556: Epoch 32 
2025-01-12 09:32:21.147108: Current learning rate: 0.00884 
2025-01-12 09:33:03.629411: train_loss -0.7172 
2025-01-12 09:33:03.629921: val_loss -0.693 
2025-01-12 09:33:03.634956: Pseudo dice [np.float32(0.7546)] 
2025-01-12 09:33:03.638978: Epoch time: 42.49 s 
2025-01-12 09:33:04.166918:  
2025-01-12 09:33:04.166918: Epoch 33 
2025-01-12 09:33:04.172477: Current learning rate: 0.0088 
2025-01-12 09:33:46.630238: train_loss -0.7208 
2025-01-12 09:33:46.630740: val_loss -0.7455 
2025-01-12 09:33:46.636277: Pseudo dice [np.float32(0.7947)] 
2025-01-12 09:33:46.638793: Epoch time: 42.46 s 
2025-01-12 09:33:46.642849: Yayy! New best EMA pseudo Dice: 0.7594000101089478 
2025-01-12 09:33:47.401581:  
2025-01-12 09:33:47.402586: Epoch 34 
2025-01-12 09:33:47.407136: Current learning rate: 0.00877 
2025-01-12 09:34:29.850390: train_loss -0.7416 
2025-01-12 09:34:29.850892: val_loss -0.6239 
2025-01-12 09:34:29.855906: Pseudo dice [np.float32(0.7106)] 
2025-01-12 09:34:29.859419: Epoch time: 42.45 s 
2025-01-12 09:34:30.396031:  
2025-01-12 09:34:30.397035: Epoch 35 
2025-01-12 09:34:30.401595: Current learning rate: 0.00873 
2025-01-12 09:35:12.848032: train_loss -0.6964 
2025-01-12 09:35:12.849536: val_loss -0.6981 
2025-01-12 09:35:12.854549: Pseudo dice [np.float32(0.7693)] 
2025-01-12 09:35:12.858061: Epoch time: 42.45 s 
2025-01-12 09:35:13.401780:  
2025-01-12 09:35:13.402783: Epoch 36 
2025-01-12 09:35:13.407856: Current learning rate: 0.00869 
2025-01-12 09:35:55.885969: train_loss -0.72 
2025-01-12 09:35:55.885969: val_loss -0.7406 
2025-01-12 09:35:55.891979: Pseudo dice [np.float32(0.7997)] 
2025-01-12 09:35:55.894989: Epoch time: 42.48 s 
2025-01-12 09:35:55.898500: Yayy! New best EMA pseudo Dice: 0.7603999972343445 
2025-01-12 09:35:56.812907:  
2025-01-12 09:35:56.813904: Epoch 37 
2025-01-12 09:35:56.818952: Current learning rate: 0.00866 
2025-01-12 09:36:39.289841: train_loss -0.7263 
2025-01-12 09:36:39.290344: val_loss -0.6673 
2025-01-12 09:36:39.295884: Pseudo dice [np.float32(0.7388)] 
2025-01-12 09:36:39.299915: Epoch time: 42.48 s 
2025-01-12 09:36:39.831412:  
2025-01-12 09:36:39.831412: Epoch 38 
2025-01-12 09:36:39.836433: Current learning rate: 0.00862 
2025-01-12 09:37:22.262232: train_loss -0.7447 
2025-01-12 09:37:22.263235: val_loss -0.7315 
2025-01-12 09:37:22.268251: Pseudo dice [np.float32(0.8036)] 
2025-01-12 09:37:22.272262: Epoch time: 42.43 s 
2025-01-12 09:37:22.275774: Yayy! New best EMA pseudo Dice: 0.7627000212669373 
2025-01-12 09:37:23.023310:  
2025-01-12 09:37:23.024313: Epoch 39 
2025-01-12 09:37:23.028861: Current learning rate: 0.00858 
2025-01-12 09:38:05.460442: train_loss -0.7545 
2025-01-12 09:38:05.460442: val_loss -0.7107 
2025-01-12 09:38:05.466573: Pseudo dice [np.float32(0.7768)] 
2025-01-12 09:38:05.469284: Epoch time: 42.44 s 
2025-01-12 09:38:05.473328: Yayy! New best EMA pseudo Dice: 0.76419997215271 
2025-01-12 09:38:06.265935:  
2025-01-12 09:38:06.265935: Epoch 40 
2025-01-12 09:38:06.271004: Current learning rate: 0.00855 
2025-01-12 09:38:48.702918: train_loss -0.7274 
2025-01-12 09:38:48.702918: val_loss -0.6959 
2025-01-12 09:38:48.708963: Pseudo dice [np.float32(0.7719)] 
2025-01-12 09:38:48.711988: Epoch time: 42.44 s 
2025-01-12 09:38:48.715024: Yayy! New best EMA pseudo Dice: 0.7649000287055969 
2025-01-12 09:38:49.461529:  
2025-01-12 09:38:49.461529: Epoch 41 
2025-01-12 09:38:49.466560: Current learning rate: 0.00851 
2025-01-12 09:39:31.926862: train_loss -0.67 
2025-01-12 09:39:31.927371: val_loss -0.7315 
2025-01-12 09:39:31.932988: Pseudo dice [np.float32(0.8002)] 
2025-01-12 09:39:31.936548: Epoch time: 42.47 s 
2025-01-12 09:39:31.940102: Yayy! New best EMA pseudo Dice: 0.7684999704360962 
2025-01-12 09:39:32.663418:  
2025-01-12 09:39:32.664418: Epoch 42 
2025-01-12 09:39:32.668967: Current learning rate: 0.00847 
2025-01-12 09:40:15.111803: train_loss -0.6927 
2025-01-12 09:40:15.111803: val_loss -0.7477 
2025-01-12 09:40:15.116813: Pseudo dice [np.float32(0.8065)] 
2025-01-12 09:40:15.120325: Epoch time: 42.45 s 
2025-01-12 09:40:15.123834: Yayy! New best EMA pseudo Dice: 0.7723000049591064 
2025-01-12 09:40:15.852057:  
2025-01-12 09:40:15.853062: Epoch 43 
2025-01-12 09:40:15.857621: Current learning rate: 0.00844 
2025-01-12 09:40:58.307169: train_loss -0.7233 
2025-01-12 09:40:58.307678: val_loss -0.6776 
2025-01-12 09:40:58.313755: Pseudo dice [np.float32(0.7481)] 
2025-01-12 09:40:58.316266: Epoch time: 42.46 s 
2025-01-12 09:40:58.835281:  
2025-01-12 09:40:58.835281: Epoch 44 
2025-01-12 09:40:58.840821: Current learning rate: 0.0084 
2025-01-12 09:41:41.263402: train_loss -0.6973 
2025-01-12 09:41:41.264407: val_loss -0.7344 
2025-01-12 09:41:41.270428: Pseudo dice [np.float32(0.7834)] 
2025-01-12 09:41:41.273440: Epoch time: 42.43 s 
2025-01-12 09:41:41.930876:  
2025-01-12 09:41:41.930876: Epoch 45 
2025-01-12 09:41:41.935948: Current learning rate: 0.00836 
2025-01-12 09:42:24.375770: train_loss -0.7172 
2025-01-12 09:42:24.376276: val_loss -0.734 
2025-01-12 09:42:24.381377: Pseudo dice [np.float32(0.7989)] 
2025-01-12 09:42:24.384480: Epoch time: 42.45 s 
2025-01-12 09:42:24.389028: Yayy! New best EMA pseudo Dice: 0.7739999890327454 
2025-01-12 09:42:25.163061:  
2025-01-12 09:42:25.163563: Epoch 46 
2025-01-12 09:42:25.168574: Current learning rate: 0.00833 
2025-01-12 09:43:07.608300: train_loss -0.7398 
2025-01-12 09:43:07.608300: val_loss -0.7695 
2025-01-12 09:43:07.614324: Pseudo dice [np.float32(0.8262)] 
2025-01-12 09:43:07.617840: Epoch time: 42.45 s 
2025-01-12 09:43:07.621147: Yayy! New best EMA pseudo Dice: 0.77920001745224 
2025-01-12 09:43:08.355664:  
2025-01-12 09:43:08.356663: Epoch 47 
2025-01-12 09:43:08.362180: Current learning rate: 0.00829 
2025-01-12 09:43:50.817980: train_loss -0.7616 
2025-01-12 09:43:50.818986: val_loss -0.7378 
2025-01-12 09:43:50.824555: Pseudo dice [np.float32(0.8015)] 
2025-01-12 09:43:50.828065: Epoch time: 42.46 s 
2025-01-12 09:43:50.832072: Yayy! New best EMA pseudo Dice: 0.7814000248908997 
2025-01-12 09:43:51.578953:  
2025-01-12 09:43:51.580469: Epoch 48 
2025-01-12 09:43:51.585597: Current learning rate: 0.00825 
2025-01-12 09:44:34.038213: train_loss -0.7825 
2025-01-12 09:44:34.038213: val_loss -0.7626 
2025-01-12 09:44:34.044233: Pseudo dice [np.float32(0.8148)] 
2025-01-12 09:44:34.048245: Epoch time: 42.46 s 
2025-01-12 09:44:34.051756: Yayy! New best EMA pseudo Dice: 0.7847999930381775 
2025-01-12 09:44:34.834846:  
2025-01-12 09:44:34.835850: Epoch 49 
2025-01-12 09:44:34.840878: Current learning rate: 0.00822 
2025-01-12 09:45:17.276978: train_loss -0.7787 
2025-01-12 09:45:17.277981: val_loss -0.696 
2025-01-12 09:45:17.283001: Pseudo dice [np.float32(0.7768)] 
2025-01-12 09:45:17.286514: Epoch time: 42.44 s 
2025-01-12 09:45:18.023401:  
2025-01-12 09:45:18.023401: Epoch 50 
2025-01-12 09:45:18.027511: Current learning rate: 0.00818 
2025-01-12 09:46:00.471169: train_loss -0.7791 
2025-01-12 09:46:00.471672: val_loss -0.7503 
2025-01-12 09:46:00.477684: Pseudo dice [np.float32(0.7915)] 
2025-01-12 09:46:00.480197: Epoch time: 42.45 s 
2025-01-12 09:46:01.008496:  
2025-01-12 09:46:01.009495: Epoch 51 
2025-01-12 09:46:01.014560: Current learning rate: 0.00814 
2025-01-12 09:46:43.463145: train_loss -0.7322 
2025-01-12 09:46:43.463145: val_loss -0.693 
2025-01-12 09:46:43.469159: Pseudo dice [np.float32(0.739)] 
2025-01-12 09:46:43.473170: Epoch time: 42.45 s 
2025-01-12 09:46:43.998593:  
2025-01-12 09:46:43.998593: Epoch 52 
2025-01-12 09:46:44.004177: Current learning rate: 0.00811 
2025-01-12 09:47:26.466946: train_loss -0.7257 
2025-01-12 09:47:26.467949: val_loss -0.6724 
2025-01-12 09:47:26.472959: Pseudo dice [np.float32(0.7249)] 
2025-01-12 09:47:26.476966: Epoch time: 42.47 s 
2025-01-12 09:47:26.997588:  
2025-01-12 09:47:26.998594: Epoch 53 
2025-01-12 09:47:27.003139: Current learning rate: 0.00807 
2025-01-12 09:48:09.495814: train_loss -0.6936 
2025-01-12 09:48:09.495814: val_loss -0.6777 
2025-01-12 09:48:09.501831: Pseudo dice [np.float32(0.733)] 
2025-01-12 09:48:09.504842: Epoch time: 42.5 s 
2025-01-12 09:48:10.181174:  
2025-01-12 09:48:10.181678: Epoch 54 
2025-01-12 09:48:10.186724: Current learning rate: 0.00803 
2025-01-12 09:48:52.661543: train_loss -0.7509 
2025-01-12 09:48:52.661543: val_loss -0.7087 
2025-01-12 09:48:52.666556: Pseudo dice [np.float32(0.7726)] 
2025-01-12 09:48:52.670068: Epoch time: 42.48 s 
2025-01-12 09:48:53.202372:  
2025-01-12 09:48:53.202372: Epoch 55 
2025-01-12 09:48:53.207930: Current learning rate: 0.008 
2025-01-12 09:49:35.657628: train_loss -0.7721 
2025-01-12 09:49:35.658630: val_loss -0.6743 
2025-01-12 09:49:35.664171: Pseudo dice [np.float32(0.7272)] 
2025-01-12 09:49:35.668679: Epoch time: 42.46 s 
2025-01-12 09:49:36.211143:  
2025-01-12 09:49:36.211143: Epoch 56 
2025-01-12 09:49:36.216246: Current learning rate: 0.00796 
2025-01-12 09:50:18.673314: train_loss -0.752 
2025-01-12 09:50:18.673314: val_loss -0.7366 
2025-01-12 09:50:18.680330: Pseudo dice [np.float32(0.7899)] 
2025-01-12 09:50:18.684349: Epoch time: 42.46 s 
2025-01-12 09:50:19.213750:  
2025-01-12 09:50:19.213750: Epoch 57 
2025-01-12 09:50:19.219774: Current learning rate: 0.00792 
2025-01-12 09:51:01.681731: train_loss -0.7382 
2025-01-12 09:51:01.682233: val_loss -0.6921 
2025-01-12 09:51:01.687247: Pseudo dice [np.float32(0.7673)] 
2025-01-12 09:51:01.691765: Epoch time: 42.47 s 
2025-01-12 09:51:02.215026:  
2025-01-12 09:51:02.216030: Epoch 58 
2025-01-12 09:51:02.220603: Current learning rate: 0.00789 
2025-01-12 09:51:44.717665: train_loss -0.7526 
2025-01-12 09:51:44.718708: val_loss -0.7627 
2025-01-12 09:51:44.724792: Pseudo dice [np.float32(0.8126)] 
2025-01-12 09:51:44.729380: Epoch time: 42.5 s 
2025-01-12 09:51:45.257578:  
2025-01-12 09:51:45.257578: Epoch 59 
2025-01-12 09:51:45.263602: Current learning rate: 0.00785 
2025-01-12 09:52:27.748982: train_loss -0.7521 
2025-01-12 09:52:27.748982: val_loss -0.651 
2025-01-12 09:52:27.755556: Pseudo dice [np.float32(0.7298)] 
2025-01-12 09:52:27.759574: Epoch time: 42.49 s 
2025-01-12 09:52:28.295058:  
2025-01-12 09:52:28.295058: Epoch 60 
2025-01-12 09:52:28.301094: Current learning rate: 0.00781 
2025-01-12 09:53:10.751533: train_loss -0.7572 
2025-01-12 09:53:10.751533: val_loss -0.7145 
2025-01-12 09:53:10.758049: Pseudo dice [np.float32(0.7651)] 
2025-01-12 09:53:10.762057: Epoch time: 42.46 s 
2025-01-12 09:53:11.291835:  
2025-01-12 09:53:11.291835: Epoch 61 
2025-01-12 09:53:11.297860: Current learning rate: 0.00777 
2025-01-12 09:53:53.757637: train_loss -0.775 
2025-01-12 09:53:53.758143: val_loss -0.7212 
2025-01-12 09:53:53.763693: Pseudo dice [np.float32(0.7876)] 
2025-01-12 09:53:53.768230: Epoch time: 42.47 s 
2025-01-12 09:53:54.433911:  
2025-01-12 09:53:54.434414: Epoch 62 
2025-01-12 09:53:54.439424: Current learning rate: 0.00774 
2025-01-12 09:54:36.888369: train_loss -0.7789 
2025-01-12 09:54:36.888871: val_loss -0.7731 
2025-01-12 09:54:36.894418: Pseudo dice [np.float32(0.8237)] 
2025-01-12 09:54:36.899463: Epoch time: 42.46 s 
2025-01-12 09:54:37.430979:  
2025-01-12 09:54:37.431481: Epoch 63 
2025-01-12 09:54:37.436499: Current learning rate: 0.0077 
2025-01-12 09:55:19.856465: train_loss -0.7675 
2025-01-12 09:55:19.856987: val_loss -0.7616 
2025-01-12 09:55:19.862589: Pseudo dice [np.float32(0.8079)] 
2025-01-12 09:55:19.867192: Epoch time: 42.43 s 
2025-01-12 09:55:20.395487:  
2025-01-12 09:55:20.395487: Epoch 64 
2025-01-12 09:55:20.401029: Current learning rate: 0.00766 
2025-01-12 09:56:02.843556: train_loss -0.7778 
2025-01-12 09:56:02.843556: val_loss -0.7472 
2025-01-12 09:56:02.850069: Pseudo dice [np.float32(0.795)] 
2025-01-12 09:56:02.853579: Epoch time: 42.45 s 
2025-01-12 09:56:03.393279:  
2025-01-12 09:56:03.395786: Epoch 65 
2025-01-12 09:56:03.400398: Current learning rate: 0.00763 
2025-01-12 09:56:45.841995: train_loss -0.7848 
2025-01-12 09:56:45.843002: val_loss -0.7632 
2025-01-12 09:56:45.848071: Pseudo dice [np.float32(0.8156)] 
2025-01-12 09:56:45.851084: Epoch time: 42.45 s 
2025-01-12 09:56:46.391647:  
2025-01-12 09:56:46.391647: Epoch 66 
2025-01-12 09:56:46.396695: Current learning rate: 0.00759 
2025-01-12 09:57:28.844754: train_loss -0.7772 
2025-01-12 09:57:28.845258: val_loss -0.7393 
2025-01-12 09:57:28.850271: Pseudo dice [np.float32(0.7954)] 
2025-01-12 09:57:28.853779: Epoch time: 42.45 s 
2025-01-12 09:57:28.856284: Yayy! New best EMA pseudo Dice: 0.785099983215332 
2025-01-12 09:57:29.646149:  
2025-01-12 09:57:29.646149: Epoch 67 
2025-01-12 09:57:29.651215: Current learning rate: 0.00755 
2025-01-12 09:58:12.066111: train_loss -0.7952 
2025-01-12 09:58:12.066111: val_loss -0.6989 
2025-01-12 09:58:12.072130: Pseudo dice [np.float32(0.766)] 
2025-01-12 09:58:12.075639: Epoch time: 42.42 s 
2025-01-12 09:58:12.620735:  
2025-01-12 09:58:12.620735: Epoch 68 
2025-01-12 09:58:12.625749: Current learning rate: 0.00751 
2025-01-12 09:58:55.039233: train_loss -0.7915 
2025-01-12 09:58:55.040238: val_loss -0.6945 
2025-01-12 09:58:55.045915: Pseudo dice [np.float32(0.7322)] 
2025-01-12 09:58:55.049031: Epoch time: 42.42 s 
2025-01-12 09:58:55.591773:  
2025-01-12 09:58:55.592276: Epoch 69 
2025-01-12 09:58:55.597288: Current learning rate: 0.00748 
2025-01-12 09:59:37.995565: train_loss -0.7848 
2025-01-12 09:59:37.995565: val_loss -0.7508 
2025-01-12 09:59:38.001578: Pseudo dice [np.float32(0.7967)] 
2025-01-12 09:59:38.004586: Epoch time: 42.4 s 
2025-01-12 09:59:38.692102:  
2025-01-12 09:59:38.693103: Epoch 70 
2025-01-12 09:59:38.698207: Current learning rate: 0.00744 
2025-01-12 10:00:21.130786: train_loss -0.7767 
2025-01-12 10:00:21.130786: val_loss -0.7078 
2025-01-12 10:00:21.136798: Pseudo dice [np.float32(0.7119)] 
2025-01-12 10:00:21.139806: Epoch time: 42.44 s 
2025-01-12 10:00:21.678493:  
2025-01-12 10:00:21.679497: Epoch 71 
2025-01-12 10:00:21.684046: Current learning rate: 0.0074 
2025-01-12 10:01:04.102882: train_loss -0.7725 
2025-01-12 10:01:04.103885: val_loss -0.7705 
2025-01-12 10:01:04.108898: Pseudo dice [np.float32(0.8111)] 
2025-01-12 10:01:04.112910: Epoch time: 42.42 s 
2025-01-12 10:01:04.651581:  
2025-01-12 10:01:04.652585: Epoch 72 
2025-01-12 10:01:04.657623: Current learning rate: 0.00737 
2025-01-12 10:01:47.098562: train_loss -0.7629 
2025-01-12 10:01:47.098562: val_loss -0.7462 
2025-01-12 10:01:47.104575: Pseudo dice [np.float32(0.7887)] 
2025-01-12 10:01:47.108588: Epoch time: 42.45 s 
2025-01-12 10:01:47.652729:  
2025-01-12 10:01:47.652729: Epoch 73 
2025-01-12 10:01:47.657765: Current learning rate: 0.00733 
2025-01-12 10:02:30.086169: train_loss -0.7593 
2025-01-12 10:02:30.086169: val_loss -0.6889 
2025-01-12 10:02:30.091302: Pseudo dice [np.float32(0.7724)] 
2025-01-12 10:02:30.095370: Epoch time: 42.43 s 
2025-01-12 10:02:30.632909:  
2025-01-12 10:02:30.632909: Epoch 74 
2025-01-12 10:02:30.638922: Current learning rate: 0.00729 
2025-01-12 10:03:13.068325: train_loss -0.6419 
2025-01-12 10:03:13.068325: val_loss -0.746 
2025-01-12 10:03:13.073778: Pseudo dice [np.float32(0.8221)] 
2025-01-12 10:03:13.077294: Epoch time: 42.44 s 
2025-01-12 10:03:13.620725:  
2025-01-12 10:03:13.620725: Epoch 75 
2025-01-12 10:03:13.625832: Current learning rate: 0.00725 
2025-01-12 10:03:56.045092: train_loss -0.7445 
2025-01-12 10:03:56.045595: val_loss -0.6319 
2025-01-12 10:03:56.050606: Pseudo dice [np.float32(0.6947)] 
2025-01-12 10:03:56.054117: Epoch time: 42.42 s 
2025-01-12 10:03:56.592870:  
2025-01-12 10:03:56.593873: Epoch 76 
2025-01-12 10:03:56.598941: Current learning rate: 0.00722 
2025-01-12 10:04:39.023517: train_loss -0.7729 
2025-01-12 10:04:39.024035: val_loss -0.7329 
2025-01-12 10:04:39.029587: Pseudo dice [np.float32(0.8043)] 
2025-01-12 10:04:39.033154: Epoch time: 42.43 s 
2025-01-12 10:04:39.583367:  
2025-01-12 10:04:39.583870: Epoch 77 
2025-01-12 10:04:39.588519: Current learning rate: 0.00718 
2025-01-12 10:05:22.037971: train_loss -0.7933 
2025-01-12 10:05:22.038973: val_loss -0.721 
2025-01-12 10:05:22.044492: Pseudo dice [np.float32(0.7839)] 
2025-01-12 10:05:22.048006: Epoch time: 42.46 s 
2025-01-12 10:05:22.744170:  
2025-01-12 10:05:22.745173: Epoch 78 
2025-01-12 10:05:22.750284: Current learning rate: 0.00714 
2025-01-12 10:06:05.178751: train_loss -0.7912 
2025-01-12 10:06:05.178751: val_loss -0.704 
2025-01-12 10:06:05.184763: Pseudo dice [np.float32(0.7671)] 
2025-01-12 10:06:05.188280: Epoch time: 42.43 s 
2025-01-12 10:06:05.740313:  
2025-01-12 10:06:05.740313: Epoch 79 
2025-01-12 10:06:05.745909: Current learning rate: 0.0071 
2025-01-12 10:06:48.203468: train_loss -0.7949 
2025-01-12 10:06:48.203973: val_loss -0.7341 
2025-01-12 10:06:48.208993: Pseudo dice [np.float32(0.7845)] 
2025-01-12 10:06:48.212510: Epoch time: 42.46 s 
2025-01-12 10:06:48.762859:  
2025-01-12 10:06:48.763860: Epoch 80 
2025-01-12 10:06:48.768980: Current learning rate: 0.00707 
2025-01-12 10:07:31.221148: train_loss -0.7794 
2025-01-12 10:07:31.221658: val_loss -0.6507 
2025-01-12 10:07:31.227255: Pseudo dice [np.float32(0.7693)] 
2025-01-12 10:07:31.230314: Epoch time: 42.46 s 
2025-01-12 10:07:31.785156:  
2025-01-12 10:07:31.785156: Epoch 81 
2025-01-12 10:07:31.790152: Current learning rate: 0.00703 
2025-01-12 10:08:14.254433: train_loss -0.7904 
2025-01-12 10:08:14.254433: val_loss -0.7416 
2025-01-12 10:08:14.260447: Pseudo dice [np.float32(0.8041)] 
2025-01-12 10:08:14.264465: Epoch time: 42.47 s 
2025-01-12 10:08:14.814163:  
2025-01-12 10:08:14.814163: Epoch 82 
2025-01-12 10:08:14.819248: Current learning rate: 0.00699 
2025-01-12 10:08:57.283617: train_loss -0.7912 
2025-01-12 10:08:57.283617: val_loss -0.7217 
2025-01-12 10:08:57.289630: Pseudo dice [np.float32(0.8107)] 
2025-01-12 10:08:57.292144: Epoch time: 42.47 s 
2025-01-12 10:08:57.815993:  
2025-01-12 10:08:57.815993: Epoch 83 
2025-01-12 10:08:57.821006: Current learning rate: 0.00696 
2025-01-12 10:09:40.288834: train_loss -0.7982 
2025-01-12 10:09:40.289349: val_loss -0.7365 
2025-01-12 10:09:40.294955: Pseudo dice [np.float32(0.7882)] 
2025-01-12 10:09:40.298004: Epoch time: 42.47 s 
2025-01-12 10:09:40.818249:  
2025-01-12 10:09:40.818249: Epoch 84 
2025-01-12 10:09:40.823265: Current learning rate: 0.00692 
2025-01-12 10:10:23.301129: train_loss -0.8093 
2025-01-12 10:10:23.302129: val_loss -0.6656 
2025-01-12 10:10:23.307641: Pseudo dice [np.float32(0.7109)] 
2025-01-12 10:10:23.311155: Epoch time: 42.48 s 
2025-01-12 10:10:23.831323:  
2025-01-12 10:10:23.832321: Epoch 85 
2025-01-12 10:10:23.837409: Current learning rate: 0.00688 
2025-01-12 10:11:06.275058: train_loss -0.799 
2025-01-12 10:11:06.275058: val_loss -0.7275 
2025-01-12 10:11:06.281614: Pseudo dice [np.float32(0.7914)] 
2025-01-12 10:11:06.284662: Epoch time: 42.44 s 
2025-01-12 10:11:06.973772:  
2025-01-12 10:11:06.973772: Epoch 86 
2025-01-12 10:11:06.979355: Current learning rate: 0.00684 
2025-01-12 10:11:49.425906: train_loss -0.8062 
2025-01-12 10:11:49.426909: val_loss -0.7119 
2025-01-12 10:11:49.431920: Pseudo dice [np.float32(0.7857)] 
2025-01-12 10:11:49.435929: Epoch time: 42.45 s 
2025-01-12 10:11:49.953366:  
2025-01-12 10:11:49.954368: Epoch 87 
2025-01-12 10:11:49.958943: Current learning rate: 0.0068 
2025-01-12 10:12:32.403538: train_loss -0.798 
2025-01-12 10:12:32.404538: val_loss -0.7523 
2025-01-12 10:12:32.410062: Pseudo dice [np.float32(0.8045)] 
2025-01-12 10:12:32.413579: Epoch time: 42.45 s 
2025-01-12 10:12:32.947646:  
2025-01-12 10:12:32.948649: Epoch 88 
2025-01-12 10:12:32.955209: Current learning rate: 0.00677 
2025-01-12 10:13:15.413639: train_loss -0.8006 
2025-01-12 10:13:15.414142: val_loss -0.7635 
2025-01-12 10:13:15.419153: Pseudo dice [np.float32(0.8097)] 
2025-01-12 10:13:15.422671: Epoch time: 42.47 s 
2025-01-12 10:13:15.948301:  
2025-01-12 10:13:15.949305: Epoch 89 
2025-01-12 10:13:15.953910: Current learning rate: 0.00673 
2025-01-12 10:13:58.425470: train_loss -0.816 
2025-01-12 10:13:58.425470: val_loss -0.7053 
2025-01-12 10:13:58.430568: Pseudo dice [np.float32(0.774)] 
2025-01-12 10:13:58.434640: Epoch time: 42.48 s 
2025-01-12 10:13:58.965032:  
2025-01-12 10:13:58.965032: Epoch 90 
2025-01-12 10:13:58.970070: Current learning rate: 0.00669 
2025-01-12 10:14:41.420718: train_loss -0.8157 
2025-01-12 10:14:41.420718: val_loss -0.7663 
2025-01-12 10:14:41.426486: Pseudo dice [np.float32(0.8153)] 
2025-01-12 10:14:41.429997: Epoch time: 42.46 s 
2025-01-12 10:14:41.433005: Yayy! New best EMA pseudo Dice: 0.7858999967575073 
2025-01-12 10:14:42.208853:  
2025-01-12 10:14:42.208853: Epoch 91 
2025-01-12 10:14:42.213903: Current learning rate: 0.00665 
2025-01-12 10:15:24.659272: train_loss -0.8008 
2025-01-12 10:15:24.659272: val_loss -0.7244 
2025-01-12 10:15:24.665353: Pseudo dice [np.float32(0.7796)] 
2025-01-12 10:15:24.668976: Epoch time: 42.45 s 
2025-01-12 10:15:25.185460:  
2025-01-12 10:15:25.186459: Epoch 92 
2025-01-12 10:15:25.191507: Current learning rate: 0.00662 
2025-01-12 10:16:07.623158: train_loss -0.7921 
2025-01-12 10:16:07.624158: val_loss -0.6715 
2025-01-12 10:16:07.629673: Pseudo dice [np.float32(0.7564)] 
2025-01-12 10:16:07.633188: Epoch time: 42.44 s 
2025-01-12 10:16:08.152275:  
2025-01-12 10:16:08.153278: Epoch 93 
2025-01-12 10:16:08.157854: Current learning rate: 0.00658 
2025-01-12 10:16:50.592541: train_loss -0.8126 
2025-01-12 10:16:50.592541: val_loss -0.7229 
2025-01-12 10:16:50.598555: Pseudo dice [np.float32(0.7811)] 
2025-01-12 10:16:50.601058: Epoch time: 42.44 s 
2025-01-12 10:16:51.130863:  
2025-01-12 10:16:51.130863: Epoch 94 
2025-01-12 10:16:51.136403: Current learning rate: 0.00654 
2025-01-12 10:17:33.668421: train_loss -0.8263 
2025-01-12 10:17:33.668421: val_loss -0.7403 
2025-01-12 10:17:33.675940: Pseudo dice [np.float32(0.8065)] 
2025-01-12 10:17:33.679445: Epoch time: 42.54 s 
2025-01-12 10:17:34.353301:  
2025-01-12 10:17:34.353301: Epoch 95 
2025-01-12 10:17:34.358314: Current learning rate: 0.0065 
2025-01-12 10:18:16.937211: train_loss -0.8276 
2025-01-12 10:18:16.938722: val_loss -0.7477 
2025-01-12 10:18:16.944326: Pseudo dice [np.float32(0.7943)] 
2025-01-12 10:18:16.947837: Epoch time: 42.58 s 
2025-01-12 10:18:17.470201:  
2025-01-12 10:18:17.470704: Epoch 96 
2025-01-12 10:18:17.475715: Current learning rate: 0.00647 
2025-01-12 10:19:00.001865: train_loss -0.8245 
2025-01-12 10:19:00.002369: val_loss -0.7058 
2025-01-12 10:19:00.008392: Pseudo dice [np.float32(0.7792)] 
2025-01-12 10:19:00.013410: Epoch time: 42.53 s 
2025-01-12 10:19:00.555353:  
2025-01-12 10:19:00.555353: Epoch 97 
2025-01-12 10:19:00.560950: Current learning rate: 0.00643 
2025-01-12 10:19:43.137048: train_loss -0.8082 
2025-01-12 10:19:43.138048: val_loss -0.7202 
2025-01-12 10:19:43.143567: Pseudo dice [np.float32(0.7703)] 
2025-01-12 10:19:43.146074: Epoch time: 42.58 s 
2025-01-12 10:19:43.677590:  
2025-01-12 10:19:43.677590: Epoch 98 
2025-01-12 10:19:43.683156: Current learning rate: 0.00639 
2025-01-12 10:20:26.232028: train_loss -0.8113 
2025-01-12 10:20:26.232028: val_loss -0.7515 
2025-01-12 10:20:26.238091: Pseudo dice [np.float32(0.807)] 
2025-01-12 10:20:26.241141: Epoch time: 42.55 s 
2025-01-12 10:20:26.777091:  
2025-01-12 10:20:26.777091: Epoch 99 
2025-01-12 10:20:26.782129: Current learning rate: 0.00635 
2025-01-12 10:21:09.361355: train_loss -0.8192 
2025-01-12 10:21:09.362362: val_loss -0.7434 
2025-01-12 10:21:09.367369: Pseudo dice [np.float32(0.797)] 
2025-01-12 10:21:09.371377: Epoch time: 42.59 s 
2025-01-12 10:21:09.544680: Yayy! New best EMA pseudo Dice: 0.7870000004768372 
2025-01-12 10:21:10.297176:  
2025-01-12 10:21:10.297176: Epoch 100 
2025-01-12 10:21:10.302196: Current learning rate: 0.00631 
2025-01-12 10:21:52.841191: train_loss -0.8172 
2025-01-12 10:21:52.841693: val_loss -0.7401 
2025-01-12 10:21:52.847711: Pseudo dice [np.float32(0.7919)] 
2025-01-12 10:21:52.850220: Epoch time: 42.54 s 
2025-01-12 10:21:52.855234: Yayy! New best EMA pseudo Dice: 0.7875000238418579 
2025-01-12 10:21:53.616698:  
2025-01-12 10:21:53.616698: Epoch 101 
2025-01-12 10:21:53.622247: Current learning rate: 0.00628 
2025-01-12 10:22:36.191825: train_loss -0.7873 
2025-01-12 10:22:36.192831: val_loss -0.7103 
2025-01-12 10:22:36.199349: Pseudo dice [np.float32(0.7801)] 
2025-01-12 10:22:36.202862: Epoch time: 42.58 s 
2025-01-12 10:22:36.740911:  
2025-01-12 10:22:36.740911: Epoch 102 
2025-01-12 10:22:36.746113: Current learning rate: 0.00624 
2025-01-12 10:23:19.304141: train_loss -0.778 
2025-01-12 10:23:19.304645: val_loss -0.73 
2025-01-12 10:23:19.309662: Pseudo dice [np.float32(0.7826)] 
2025-01-12 10:23:19.313174: Epoch time: 42.56 s 
2025-01-12 10:23:19.990026:  
2025-01-12 10:23:19.990026: Epoch 103 
2025-01-12 10:23:19.995540: Current learning rate: 0.0062 
2025-01-12 10:24:02.554779: train_loss -0.7739 
2025-01-12 10:24:02.554779: val_loss -0.7619 
2025-01-12 10:24:02.560793: Pseudo dice [np.float32(0.8226)] 
2025-01-12 10:24:02.564808: Epoch time: 42.57 s 
2025-01-12 10:24:02.568320: Yayy! New best EMA pseudo Dice: 0.789900004863739 
2025-01-12 10:24:03.315587:  
2025-01-12 10:24:03.316090: Epoch 104 
2025-01-12 10:24:03.321103: Current learning rate: 0.00616 
2025-01-12 10:24:45.854948: train_loss -0.8068 
2025-01-12 10:24:45.855950: val_loss -0.7561 
2025-01-12 10:24:45.860960: Pseudo dice [np.float32(0.821)] 
2025-01-12 10:24:45.865002: Epoch time: 42.54 s 
2025-01-12 10:24:45.868515: Yayy! New best EMA pseudo Dice: 0.7930999994277954 
2025-01-12 10:24:46.665021:  
2025-01-12 10:24:46.665021: Epoch 105 
2025-01-12 10:24:46.670564: Current learning rate: 0.00612 
2025-01-12 10:25:29.248551: train_loss -0.8084 
2025-01-12 10:25:29.249555: val_loss -0.6798 
2025-01-12 10:25:29.254573: Pseudo dice [np.float32(0.7538)] 
2025-01-12 10:25:29.259587: Epoch time: 42.58 s 
2025-01-12 10:25:29.792135:  
2025-01-12 10:25:29.793138: Epoch 106 
2025-01-12 10:25:29.798187: Current learning rate: 0.00609 
2025-01-12 10:26:12.467745: train_loss -0.8293 
2025-01-12 10:26:12.468246: val_loss -0.7264 
2025-01-12 10:26:12.473816: Pseudo dice [np.float32(0.7912)] 
2025-01-12 10:26:12.476353: Epoch time: 42.68 s 
2025-01-12 10:26:13.070686:  
2025-01-12 10:26:13.070686: Epoch 107 
2025-01-12 10:26:13.076750: Current learning rate: 0.00605 
2025-01-12 10:26:55.731251: train_loss -0.8264 
2025-01-12 10:26:55.732253: val_loss -0.7142 
2025-01-12 10:26:55.737774: Pseudo dice [np.float32(0.7713)] 
2025-01-12 10:26:55.741286: Epoch time: 42.66 s 
2025-01-12 10:26:56.271553:  
2025-01-12 10:26:56.271553: Epoch 108 
2025-01-12 10:26:56.277674: Current learning rate: 0.00601 
2025-01-12 10:27:38.894378: train_loss -0.7991 
2025-01-12 10:27:38.895385: val_loss -0.7153 
2025-01-12 10:27:38.900397: Pseudo dice [np.float32(0.7822)] 
2025-01-12 10:27:38.904409: Epoch time: 42.62 s 
2025-01-12 10:27:39.550547:  
2025-01-12 10:27:39.550547: Epoch 109 
2025-01-12 10:27:39.557284: Current learning rate: 0.00597 
2025-01-12 10:28:22.174624: train_loss -0.8022 
2025-01-12 10:28:22.175135: val_loss -0.75 
2025-01-12 10:28:22.180878: Pseudo dice [np.float32(0.8012)] 
2025-01-12 10:28:22.184449: Epoch time: 42.62 s 
2025-01-12 10:28:22.837544:  
2025-01-12 10:28:22.838545: Epoch 110 
2025-01-12 10:28:22.841602: Current learning rate: 0.00593 
2025-01-12 10:29:05.444917: train_loss -0.8063 
2025-01-12 10:29:05.444917: val_loss -0.7486 
2025-01-12 10:29:05.450936: Pseudo dice [np.float32(0.8152)] 
2025-01-12 10:29:05.454445: Epoch time: 42.61 s 
2025-01-12 10:29:05.990298:  
2025-01-12 10:29:05.990298: Epoch 111 
2025-01-12 10:29:05.996813: Current learning rate: 0.0059 
2025-01-12 10:29:48.565160: train_loss -0.8075 
2025-01-12 10:29:48.565160: val_loss -0.7342 
2025-01-12 10:29:48.571173: Pseudo dice [np.float32(0.8029)] 
2025-01-12 10:29:48.574692: Epoch time: 42.57 s 
2025-01-12 10:29:49.243640:  
2025-01-12 10:29:49.243640: Epoch 112 
2025-01-12 10:29:49.249227: Current learning rate: 0.00586 
2025-01-12 10:30:31.797337: train_loss -0.8259 
2025-01-12 10:30:31.797337: val_loss -0.7772 
2025-01-12 10:30:31.803347: Pseudo dice [np.float32(0.832)] 
2025-01-12 10:30:31.807359: Epoch time: 42.55 s 
2025-01-12 10:30:31.811371: Yayy! New best EMA pseudo Dice: 0.7961999773979187 
2025-01-12 10:30:32.609591:  
2025-01-12 10:30:32.609591: Epoch 113 
2025-01-12 10:30:32.614604: Current learning rate: 0.00582 
2025-01-12 10:31:15.178910: train_loss -0.8177 
2025-01-12 10:31:15.178910: val_loss -0.7457 
2025-01-12 10:31:15.184924: Pseudo dice [np.float32(0.799)] 
2025-01-12 10:31:15.188440: Epoch time: 42.57 s 
2025-01-12 10:31:15.191450: Yayy! New best EMA pseudo Dice: 0.796500027179718 
2025-01-12 10:31:15.970077:  
2025-01-12 10:31:15.971076: Epoch 114 
2025-01-12 10:31:15.976150: Current learning rate: 0.00578 
2025-01-12 10:31:58.551607: train_loss -0.8339 
2025-01-12 10:31:58.552109: val_loss -0.7211 
2025-01-12 10:31:58.558133: Pseudo dice [np.float32(0.7837)] 
2025-01-12 10:31:58.560639: Epoch time: 42.58 s 
2025-01-12 10:31:59.093724:  
2025-01-12 10:31:59.094727: Epoch 115 
2025-01-12 10:31:59.099319: Current learning rate: 0.00574 
2025-01-12 10:32:41.672513: train_loss -0.8237 
2025-01-12 10:32:41.672513: val_loss -0.7586 
2025-01-12 10:32:41.679026: Pseudo dice [np.float32(0.8243)] 
2025-01-12 10:32:41.682536: Epoch time: 42.58 s 
2025-01-12 10:32:41.686549: Yayy! New best EMA pseudo Dice: 0.7980999946594238 
2025-01-12 10:32:42.477823:  
2025-01-12 10:32:42.477823: Epoch 116 
2025-01-12 10:32:42.483366: Current learning rate: 0.0057 
2025-01-12 10:33:25.025685: train_loss -0.8297 
2025-01-12 10:33:25.026691: val_loss -0.7193 
2025-01-12 10:33:25.031700: Pseudo dice [np.float32(0.7802)] 
2025-01-12 10:33:25.035720: Epoch time: 42.55 s 
2025-01-12 10:33:25.567262:  
2025-01-12 10:33:25.567262: Epoch 117 
2025-01-12 10:33:25.573293: Current learning rate: 0.00567 
2025-01-12 10:34:08.164562: train_loss -0.796 
2025-01-12 10:34:08.165071: val_loss -0.7236 
2025-01-12 10:34:08.170657: Pseudo dice [np.float32(0.7926)] 
2025-01-12 10:34:08.174194: Epoch time: 42.6 s 
2025-01-12 10:34:08.713542:  
2025-01-12 10:34:08.713542: Epoch 118 
2025-01-12 10:34:08.718620: Current learning rate: 0.00563 
2025-01-12 10:34:51.322439: train_loss -0.8064 
2025-01-12 10:34:51.322439: val_loss -0.7636 
2025-01-12 10:34:51.328959: Pseudo dice [np.float32(0.8216)] 
2025-01-12 10:34:51.331467: Epoch time: 42.61 s 
2025-01-12 10:34:51.334981: Yayy! New best EMA pseudo Dice: 0.7985000014305115 
2025-01-12 10:34:52.073698:  
2025-01-12 10:34:52.073698: Epoch 119 
2025-01-12 10:34:52.079299: Current learning rate: 0.00559 
2025-01-12 10:35:34.654687: train_loss -0.8181 
2025-01-12 10:35:34.655693: val_loss -0.7501 
2025-01-12 10:35:34.661262: Pseudo dice [np.float32(0.8056)] 
2025-01-12 10:35:34.664798: Epoch time: 42.58 s 
2025-01-12 10:35:34.667382: Yayy! New best EMA pseudo Dice: 0.7991999983787537 
2025-01-12 10:35:35.418006:  
2025-01-12 10:35:35.418006: Epoch 120 
2025-01-12 10:35:35.426145: Current learning rate: 0.00555 
2025-01-12 10:36:18.023281: train_loss -0.8293 
2025-01-12 10:36:18.023281: val_loss -0.7133 
2025-01-12 10:36:18.029405: Pseudo dice [np.float32(0.7761)] 
2025-01-12 10:36:18.032454: Epoch time: 42.61 s 
2025-01-12 10:36:18.716339:  
2025-01-12 10:36:18.716339: Epoch 121 
2025-01-12 10:36:18.720943: Current learning rate: 0.00551 
2025-01-12 10:37:01.249903: train_loss -0.8332 
2025-01-12 10:37:01.250407: val_loss -0.7647 
2025-01-12 10:37:01.255419: Pseudo dice [np.float32(0.8109)] 
2025-01-12 10:37:01.260441: Epoch time: 42.53 s 
2025-01-12 10:37:01.800212:  
2025-01-12 10:37:01.800212: Epoch 122 
2025-01-12 10:37:01.805767: Current learning rate: 0.00547 
2025-01-12 10:37:44.382107: train_loss -0.834 
2025-01-12 10:37:44.382107: val_loss -0.7581 
2025-01-12 10:37:44.389625: Pseudo dice [np.float32(0.8117)] 
2025-01-12 10:37:44.392129: Epoch time: 42.58 s 
2025-01-12 10:37:44.396141: Yayy! New best EMA pseudo Dice: 0.7997000217437744 
2025-01-12 10:37:45.168932:  
2025-01-12 10:37:45.169436: Epoch 123 
2025-01-12 10:37:45.174449: Current learning rate: 0.00544 
2025-01-12 10:38:27.727277: train_loss -0.8199 
2025-01-12 10:38:27.727277: val_loss -0.7578 
2025-01-12 10:38:27.733295: Pseudo dice [np.float32(0.8086)] 
2025-01-12 10:38:27.736802: Epoch time: 42.56 s 
2025-01-12 10:38:27.739811: Yayy! New best EMA pseudo Dice: 0.800599992275238 
2025-01-12 10:38:28.539999:  
2025-01-12 10:38:28.540501: Epoch 124 
2025-01-12 10:38:28.544016: Current learning rate: 0.0054 
2025-01-12 10:39:11.140026: train_loss -0.8264 
2025-01-12 10:39:11.140026: val_loss -0.6265 
2025-01-12 10:39:11.146552: Pseudo dice [np.float32(0.6593)] 
2025-01-12 10:39:11.150066: Epoch time: 42.6 s 
2025-01-12 10:39:11.688620:  
2025-01-12 10:39:11.689620: Epoch 125 
2025-01-12 10:39:11.695133: Current learning rate: 0.00536 
2025-01-12 10:39:54.242349: train_loss -0.81 
2025-01-12 10:39:54.242864: val_loss -0.7385 
2025-01-12 10:39:54.247994: Pseudo dice [np.float32(0.7991)] 
2025-01-12 10:39:54.252536: Epoch time: 42.55 s 
2025-01-12 10:39:54.792181:  
2025-01-12 10:39:54.792684: Epoch 126 
2025-01-12 10:39:54.797696: Current learning rate: 0.00532 
2025-01-12 10:40:37.386082: train_loss -0.8059 
2025-01-12 10:40:37.386082: val_loss -0.7517 
2025-01-12 10:40:37.393595: Pseudo dice [np.float32(0.8013)] 
2025-01-12 10:40:37.397610: Epoch time: 42.59 s 
2025-01-12 10:40:37.937237:  
2025-01-12 10:40:37.938239: Epoch 127 
2025-01-12 10:40:37.942997: Current learning rate: 0.00528 
2025-01-12 10:41:20.554080: train_loss -0.7912 
2025-01-12 10:41:20.554080: val_loss -0.7173 
2025-01-12 10:41:20.560594: Pseudo dice [np.float32(0.7844)] 
2025-01-12 10:41:20.564107: Epoch time: 42.62 s 
2025-01-12 10:41:21.101841:  
2025-01-12 10:41:21.102845: Epoch 128 
2025-01-12 10:41:21.107883: Current learning rate: 0.00524 
2025-01-12 10:42:03.710109: train_loss -0.79 
2025-01-12 10:42:03.711111: val_loss -0.7298 
2025-01-12 10:42:03.716628: Pseudo dice [np.float32(0.8023)] 
2025-01-12 10:42:03.720140: Epoch time: 42.61 s 
2025-01-12 10:42:04.397474:  
2025-01-12 10:42:04.397987: Epoch 129 
2025-01-12 10:42:04.403057: Current learning rate: 0.0052 
2025-01-12 10:42:46.975675: train_loss -0.8003 
2025-01-12 10:42:46.975675: val_loss -0.7436 
2025-01-12 10:42:46.981747: Pseudo dice [np.float32(0.7862)] 
2025-01-12 10:42:46.984783: Epoch time: 42.58 s 
2025-01-12 10:42:47.533691:  
2025-01-12 10:42:47.533691: Epoch 130 
2025-01-12 10:42:47.537725: Current learning rate: 0.00517 
2025-01-12 10:43:30.169333: train_loss -0.7954 
2025-01-12 10:43:30.174344: val_loss -0.7229 
2025-01-12 10:43:30.178357: Pseudo dice [np.float32(0.7579)] 
2025-01-12 10:43:30.182867: Epoch time: 42.64 s 
2025-01-12 10:43:30.737751:  
2025-01-12 10:43:30.738756: Epoch 131 
2025-01-12 10:43:30.742289: Current learning rate: 0.00513 
2025-01-12 10:44:13.327255: train_loss -0.7861 
2025-01-12 10:44:13.327778: val_loss -0.6363 
2025-01-12 10:44:13.333389: Pseudo dice [np.float32(0.7322)] 
2025-01-12 10:44:13.335922: Epoch time: 42.59 s 
2025-01-12 10:44:13.882585:  
2025-01-12 10:44:13.882585: Epoch 132 
2025-01-12 10:44:13.888191: Current learning rate: 0.00509 
2025-01-12 10:44:56.554749: train_loss -0.7985 
2025-01-12 10:44:56.555749: val_loss -0.6764 
2025-01-12 10:44:56.561265: Pseudo dice [np.float32(0.7645)] 
2025-01-12 10:44:56.563771: Epoch time: 42.67 s 
2025-01-12 10:44:57.118605:  
2025-01-12 10:44:57.119110: Epoch 133 
2025-01-12 10:44:57.124121: Current learning rate: 0.00505 
2025-01-12 10:45:39.711390: train_loss -0.8152 
2025-01-12 10:45:39.711390: val_loss -0.7114 
2025-01-12 10:45:39.717952: Pseudo dice [np.float32(0.7653)] 
2025-01-12 10:45:39.721599: Epoch time: 42.59 s 
2025-01-12 10:45:40.263144:  
2025-01-12 10:45:40.263645: Epoch 134 
2025-01-12 10:45:40.268658: Current learning rate: 0.00501 
2025-01-12 10:46:22.842196: train_loss -0.8081 
2025-01-12 10:46:22.842196: val_loss -0.7396 
2025-01-12 10:46:22.848214: Pseudo dice [np.float32(0.7936)] 
2025-01-12 10:46:22.852226: Epoch time: 42.58 s 
2025-01-12 10:46:23.397325:  
2025-01-12 10:46:23.397325: Epoch 135 
2025-01-12 10:46:23.402877: Current learning rate: 0.00497 
2025-01-12 10:47:05.988144: train_loss -0.8372 
2025-01-12 10:47:05.988144: val_loss -0.756 
2025-01-12 10:47:05.994155: Pseudo dice [np.float32(0.8118)] 
2025-01-12 10:47:05.998169: Epoch time: 42.59 s 
2025-01-12 10:47:06.546240:  
2025-01-12 10:47:06.546240: Epoch 136 
2025-01-12 10:47:06.551803: Current learning rate: 0.00493 
2025-01-12 10:47:49.141523: train_loss -0.8282 
2025-01-12 10:47:49.142043: val_loss -0.746 
2025-01-12 10:47:49.147055: Pseudo dice [np.float32(0.8125)] 
2025-01-12 10:47:49.150567: Epoch time: 42.6 s 
2025-01-12 10:47:49.836421:  
2025-01-12 10:47:49.836421: Epoch 137 
2025-01-12 10:47:49.840471: Current learning rate: 0.00489 
2025-01-12 10:48:32.395761: train_loss -0.8163 
2025-01-12 10:48:32.396271: val_loss -0.6737 
2025-01-12 10:48:32.401867: Pseudo dice [np.float32(0.757)] 
2025-01-12 10:48:32.406444: Epoch time: 42.56 s 
2025-01-12 10:48:32.955587:  
2025-01-12 10:48:32.956586: Epoch 138 
2025-01-12 10:48:32.961652: Current learning rate: 0.00485 
2025-01-12 10:49:15.532180: train_loss -0.8126 
2025-01-12 10:49:15.532683: val_loss -0.7442 
2025-01-12 10:49:15.538697: Pseudo dice [np.float32(0.7964)] 
2025-01-12 10:49:15.542202: Epoch time: 42.58 s 
2025-01-12 10:49:16.092022:  
2025-01-12 10:49:16.092022: Epoch 139 
2025-01-12 10:49:16.097033: Current learning rate: 0.00482 
2025-01-12 10:49:58.682053: train_loss -0.8366 
2025-01-12 10:49:58.683058: val_loss -0.6927 
2025-01-12 10:49:58.688075: Pseudo dice [np.float32(0.7485)] 
2025-01-12 10:49:58.692087: Epoch time: 42.59 s 
2025-01-12 10:49:59.246343:  
2025-01-12 10:49:59.247344: Epoch 140 
2025-01-12 10:49:59.252417: Current learning rate: 0.00478 
2025-01-12 10:50:41.806891: train_loss -0.8218 
2025-01-12 10:50:41.807432: val_loss -0.7175 
2025-01-12 10:50:41.813063: Pseudo dice [np.float32(0.7776)] 
2025-01-12 10:50:41.816130: Epoch time: 42.56 s 
2025-01-12 10:50:42.361245:  
2025-01-12 10:50:42.361245: Epoch 141 
2025-01-12 10:50:42.366874: Current learning rate: 0.00474 
2025-01-12 10:51:24.945575: train_loss -0.8384 
2025-01-12 10:51:24.946077: val_loss -0.7506 
2025-01-12 10:51:24.951087: Pseudo dice [np.float32(0.8099)] 
2025-01-12 10:51:24.954603: Epoch time: 42.58 s 
2025-01-12 10:51:25.501463:  
2025-01-12 10:51:25.501463: Epoch 142 
2025-01-12 10:51:25.507494: Current learning rate: 0.0047 
2025-01-12 10:52:08.047096: train_loss -0.8446 
2025-01-12 10:52:08.048097: val_loss -0.6645 
2025-01-12 10:52:08.053622: Pseudo dice [np.float32(0.7521)] 
2025-01-12 10:52:08.057136: Epoch time: 42.55 s 
2025-01-12 10:52:08.604912:  
2025-01-12 10:52:08.605915: Epoch 143 
2025-01-12 10:52:08.611541: Current learning rate: 0.00466 
2025-01-12 10:52:51.155470: train_loss -0.8105 
2025-01-12 10:52:51.155972: val_loss -0.6302 
2025-01-12 10:52:51.160992: Pseudo dice [np.float32(0.681)] 
2025-01-12 10:52:51.166012: Epoch time: 42.55 s 
2025-01-12 10:52:51.708624:  
2025-01-12 10:52:51.708624: Epoch 144 
2025-01-12 10:52:51.713681: Current learning rate: 0.00462 
2025-01-12 10:53:34.305580: train_loss -0.8261 
2025-01-12 10:53:34.305580: val_loss -0.6984 
2025-01-12 10:53:34.311599: Pseudo dice [np.float32(0.7719)] 
2025-01-12 10:53:34.314108: Epoch time: 42.6 s 
2025-01-12 10:53:35.008941:  
2025-01-12 10:53:35.009944: Epoch 145 
2025-01-12 10:53:35.014532: Current learning rate: 0.00458 
2025-01-12 10:54:17.613422: train_loss -0.8177 
2025-01-12 10:54:17.613934: val_loss -0.7551 
2025-01-12 10:54:17.619540: Pseudo dice [np.float32(0.7921)] 
2025-01-12 10:54:17.623068: Epoch time: 42.6 s 
2025-01-12 10:54:18.171506:  
2025-01-12 10:54:18.172510: Epoch 146 
2025-01-12 10:54:18.177567: Current learning rate: 0.00454 
2025-01-12 10:55:00.758240: train_loss -0.8182 
2025-01-12 10:55:00.758240: val_loss -0.7238 
2025-01-12 10:55:00.764259: Pseudo dice [np.float32(0.7875)] 
2025-01-12 10:55:00.767771: Epoch time: 42.59 s 
2025-01-12 10:55:01.334875:  
2025-01-12 10:55:01.335377: Epoch 147 
2025-01-12 10:55:01.340388: Current learning rate: 0.0045 
2025-01-12 10:55:43.925830: train_loss -0.8348 
2025-01-12 10:55:43.926335: val_loss -0.7288 
2025-01-12 10:55:43.932942: Pseudo dice [np.float32(0.7896)] 
2025-01-12 10:55:43.936952: Epoch time: 42.59 s 
2025-01-12 10:55:44.483715:  
2025-01-12 10:55:44.483715: Epoch 148 
2025-01-12 10:55:44.489282: Current learning rate: 0.00446 
2025-01-12 10:56:27.084974: train_loss -0.8467 
2025-01-12 10:56:27.084974: val_loss -0.7145 
2025-01-12 10:56:27.091540: Pseudo dice [np.float32(0.7678)] 
2025-01-12 10:56:27.095052: Epoch time: 42.6 s 
2025-01-12 10:56:27.639234:  
2025-01-12 10:56:27.639234: Epoch 149 
2025-01-12 10:56:27.644772: Current learning rate: 0.00442 
2025-01-12 10:57:10.233309: train_loss -0.8423 
2025-01-12 10:57:10.233820: val_loss -0.7238 
2025-01-12 10:57:10.238881: Pseudo dice [np.float32(0.7844)] 
2025-01-12 10:57:10.242931: Epoch time: 42.6 s 
2025-01-12 10:57:11.024774:  
2025-01-12 10:57:11.025277: Epoch 150 
2025-01-12 10:57:11.030288: Current learning rate: 0.00438 
2025-01-12 10:57:53.646450: train_loss -0.8457 
2025-01-12 10:57:53.647451: val_loss -0.7225 
2025-01-12 10:57:53.652968: Pseudo dice [np.float32(0.7921)] 
2025-01-12 10:57:53.656480: Epoch time: 42.62 s 
2025-01-12 10:57:54.205142:  
2025-01-12 10:57:54.205142: Epoch 151 
2025-01-12 10:57:54.210692: Current learning rate: 0.00434 
2025-01-12 10:58:36.797639: train_loss -0.8366 
2025-01-12 10:58:36.798142: val_loss -0.6716 
2025-01-12 10:58:36.804164: Pseudo dice [np.float32(0.7529)] 
2025-01-12 10:58:36.806673: Epoch time: 42.59 s 
2025-01-12 10:58:37.362207:  
2025-01-12 10:58:37.362207: Epoch 152 
2025-01-12 10:58:37.366240: Current learning rate: 0.0043 
2025-01-12 10:59:19.962003: train_loss -0.8511 
2025-01-12 10:59:19.963006: val_loss -0.7123 
2025-01-12 10:59:19.968555: Pseudo dice [np.float32(0.7848)] 
2025-01-12 10:59:19.972105: Epoch time: 42.6 s 
2025-01-12 10:59:20.661209:  
2025-01-12 10:59:20.661209: Epoch 153 
2025-01-12 10:59:20.665720: Current learning rate: 0.00427 
2025-01-12 11:00:03.256821: train_loss -0.8518 
2025-01-12 11:00:03.257329: val_loss -0.7045 
2025-01-12 11:00:03.262968: Pseudo dice [np.float32(0.764)] 
2025-01-12 11:00:03.266028: Epoch time: 42.6 s 
2025-01-12 11:00:03.827230:  
2025-01-12 11:00:03.827230: Epoch 154 
2025-01-12 11:00:03.832805: Current learning rate: 0.00423 
2025-01-12 11:00:46.427271: train_loss -0.8477 
2025-01-12 11:00:46.427781: val_loss -0.7044 
2025-01-12 11:00:46.433897: Pseudo dice [np.float32(0.7806)] 
2025-01-12 11:00:46.437441: Epoch time: 42.6 s 
2025-01-12 11:00:46.998420:  
2025-01-12 11:00:46.998420: Epoch 155 
2025-01-12 11:00:47.003433: Current learning rate: 0.00419 
2025-01-12 11:01:29.613123: train_loss -0.8466 
2025-01-12 11:01:29.613123: val_loss -0.7819 
2025-01-12 11:01:29.619193: Pseudo dice [np.float32(0.8232)] 
2025-01-12 11:01:29.622304: Epoch time: 42.62 s 
2025-01-12 11:01:30.180784:  
2025-01-12 11:01:30.180784: Epoch 156 
2025-01-12 11:01:30.186321: Current learning rate: 0.00415 
2025-01-12 11:02:12.788970: train_loss -0.8426 
2025-01-12 11:02:12.788970: val_loss -0.6555 
2025-01-12 11:02:12.795556: Pseudo dice [np.float32(0.7271)] 
2025-01-12 11:02:12.798620: Epoch time: 42.61 s 
2025-01-12 11:02:13.367747:  
2025-01-12 11:02:13.367747: Epoch 157 
2025-01-12 11:02:13.372822: Current learning rate: 0.00411 
2025-01-12 11:02:55.923061: train_loss -0.8392 
2025-01-12 11:02:55.923566: val_loss -0.7221 
2025-01-12 11:02:55.929656: Pseudo dice [np.float32(0.783)] 
2025-01-12 11:02:55.933166: Epoch time: 42.56 s 
2025-01-12 11:02:56.491813:  
2025-01-12 11:02:56.492315: Epoch 158 
2025-01-12 11:02:56.497327: Current learning rate: 0.00407 
2025-01-12 11:03:39.073567: train_loss -0.8503 
2025-01-12 11:03:39.074566: val_loss -0.7567 
2025-01-12 11:03:39.081087: Pseudo dice [np.float32(0.7952)] 
2025-01-12 11:03:39.085096: Epoch time: 42.58 s 
2025-01-12 11:03:39.640591:  
2025-01-12 11:03:39.641591: Epoch 159 
2025-01-12 11:03:39.647171: Current learning rate: 0.00403 
2025-01-12 11:04:22.286368: train_loss -0.8531 
2025-01-12 11:04:22.287368: val_loss -0.701 
2025-01-12 11:04:22.292884: Pseudo dice [np.float32(0.7772)] 
2025-01-12 11:04:22.295391: Epoch time: 42.65 s 
2025-01-12 11:04:22.860599:  
2025-01-12 11:04:22.861600: Epoch 160 
2025-01-12 11:04:22.866209: Current learning rate: 0.00399 
2025-01-12 11:05:05.433939: train_loss -0.8504 
2025-01-12 11:05:05.433939: val_loss -0.7068 
2025-01-12 11:05:05.439955: Pseudo dice [np.float32(0.7868)] 
2025-01-12 11:05:05.442970: Epoch time: 42.57 s 
2025-01-12 11:05:06.155367:  
2025-01-12 11:05:06.155367: Epoch 161 
2025-01-12 11:05:06.160448: Current learning rate: 0.00395 
2025-01-12 11:05:48.718414: train_loss -0.86 
2025-01-12 11:05:48.718925: val_loss -0.6944 
2025-01-12 11:05:48.723501: Pseudo dice [np.float32(0.7562)] 
2025-01-12 11:05:48.728124: Epoch time: 42.56 s 
2025-01-12 11:05:49.287212:  
2025-01-12 11:05:49.287212: Epoch 162 
2025-01-12 11:05:49.293364: Current learning rate: 0.00391 
2025-01-12 11:06:31.829274: train_loss -0.8551 
2025-01-12 11:06:31.830278: val_loss -0.7171 
2025-01-12 11:06:31.835017: Pseudo dice [np.float32(0.7931)] 
2025-01-12 11:06:31.838530: Epoch time: 42.54 s 
2025-01-12 11:06:32.404119:  
2025-01-12 11:06:32.404624: Epoch 163 
2025-01-12 11:06:32.409635: Current learning rate: 0.00387 
2025-01-12 11:07:15.001622: train_loss -0.8475 
2025-01-12 11:07:15.001622: val_loss -0.7963 
2025-01-12 11:07:15.007643: Pseudo dice [np.float32(0.8356)] 
2025-01-12 11:07:15.011655: Epoch time: 42.6 s 
2025-01-12 11:07:15.575211:  
2025-01-12 11:07:15.575211: Epoch 164 
2025-01-12 11:07:15.581298: Current learning rate: 0.00383 
2025-01-12 11:07:58.157567: train_loss -0.8464 
2025-01-12 11:07:58.158078: val_loss -0.7311 
2025-01-12 11:07:58.163646: Pseudo dice [np.float32(0.7934)] 
2025-01-12 11:07:58.167200: Epoch time: 42.58 s 
2025-01-12 11:07:58.712384:  
2025-01-12 11:07:58.712887: Epoch 165 
2025-01-12 11:07:58.717899: Current learning rate: 0.00379 
2025-01-12 11:08:41.307446: train_loss -0.8325 
2025-01-12 11:08:41.308446: val_loss -0.7507 
2025-01-12 11:08:41.313965: Pseudo dice [np.float32(0.793)] 
2025-01-12 11:08:41.317482: Epoch time: 42.6 s 
2025-01-12 11:08:41.862717:  
2025-01-12 11:08:41.863233: Epoch 166 
2025-01-12 11:08:41.868364: Current learning rate: 0.00375 
2025-01-12 11:09:24.440809: train_loss -0.8405 
2025-01-12 11:09:24.441809: val_loss -0.7509 
2025-01-12 11:09:24.447324: Pseudo dice [np.float32(0.8009)] 
2025-01-12 11:09:24.450832: Epoch time: 42.58 s 
2025-01-12 11:09:25.001565:  
2025-01-12 11:09:25.002066: Epoch 167 
2025-01-12 11:09:25.007086: Current learning rate: 0.00371 
2025-01-12 11:10:07.571918: train_loss -0.8395 
2025-01-12 11:10:07.572422: val_loss -0.7364 
2025-01-12 11:10:07.577446: Pseudo dice [np.float32(0.7965)] 
2025-01-12 11:10:07.580965: Epoch time: 42.57 s 
2025-01-12 11:10:08.135795:  
2025-01-12 11:10:08.135795: Epoch 168 
2025-01-12 11:10:08.141346: Current learning rate: 0.00367 
2025-01-12 11:10:50.703598: train_loss -0.8241 
2025-01-12 11:10:50.704108: val_loss -0.724 
2025-01-12 11:10:50.709145: Pseudo dice [np.float32(0.789)] 
2025-01-12 11:10:50.713169: Epoch time: 42.57 s 
2025-01-12 11:10:51.400189:  
2025-01-12 11:10:51.400189: Epoch 169 
2025-01-12 11:10:51.405209: Current learning rate: 0.00363 
2025-01-12 11:11:33.938458: train_loss -0.8366 
2025-01-12 11:11:33.939459: val_loss -0.7577 
2025-01-12 11:11:33.944976: Pseudo dice [np.float32(0.805)] 
2025-01-12 11:11:33.948492: Epoch time: 42.54 s 
2025-01-12 11:11:34.503241:  
2025-01-12 11:11:34.503241: Epoch 170 
2025-01-12 11:11:34.509261: Current learning rate: 0.00359 
2025-01-12 11:12:17.051033: train_loss -0.85 
2025-01-12 11:12:17.051033: val_loss -0.7323 
2025-01-12 11:12:17.057054: Pseudo dice [np.float32(0.7899)] 
2025-01-12 11:12:17.061067: Epoch time: 42.55 s 
2025-01-12 11:12:17.612375:  
2025-01-12 11:12:17.613378: Epoch 171 
2025-01-12 11:12:17.617966: Current learning rate: 0.00355 
2025-01-12 11:13:00.190925: train_loss -0.8569 
2025-01-12 11:13:00.191925: val_loss -0.7084 
2025-01-12 11:13:00.197448: Pseudo dice [np.float32(0.7851)] 
2025-01-12 11:13:00.200962: Epoch time: 42.58 s 
2025-01-12 11:13:00.755542:  
2025-01-12 11:13:00.756545: Epoch 172 
2025-01-12 11:13:00.761135: Current learning rate: 0.00351 
2025-01-12 11:13:43.312831: train_loss -0.837 
2025-01-12 11:13:43.313832: val_loss -0.7037 
2025-01-12 11:13:43.319350: Pseudo dice [np.float32(0.7837)] 
2025-01-12 11:13:43.322858: Epoch time: 42.56 s 
2025-01-12 11:13:43.875349:  
2025-01-12 11:13:43.875349: Epoch 173 
2025-01-12 11:13:43.881011: Current learning rate: 0.00346 
2025-01-12 11:14:26.453738: train_loss -0.8438 
2025-01-12 11:14:26.454743: val_loss -0.7137 
2025-01-12 11:14:26.459764: Pseudo dice [np.float32(0.7646)] 
2025-01-12 11:14:26.463270: Epoch time: 42.58 s 
2025-01-12 11:14:27.020240:  
2025-01-12 11:14:27.020240: Epoch 174 
2025-01-12 11:14:27.025304: Current learning rate: 0.00342 
2025-01-12 11:15:09.599474: train_loss -0.8447 
2025-01-12 11:15:09.599474: val_loss -0.7808 
2025-01-12 11:15:09.605992: Pseudo dice [np.float32(0.8224)] 
2025-01-12 11:15:09.609504: Epoch time: 42.58 s 
2025-01-12 11:15:10.159047:  
2025-01-12 11:15:10.159047: Epoch 175 
2025-01-12 11:15:10.164594: Current learning rate: 0.00338 
2025-01-12 11:15:52.718719: train_loss -0.8415 
2025-01-12 11:15:52.719726: val_loss -0.7359 
2025-01-12 11:15:52.724735: Pseudo dice [np.float32(0.8075)] 
2025-01-12 11:15:52.728754: Epoch time: 42.56 s 
2025-01-12 11:15:53.280859:  
2025-01-12 11:15:53.281862: Epoch 176 
2025-01-12 11:15:53.286440: Current learning rate: 0.00334 
2025-01-12 11:16:35.876958: train_loss -0.8105 
2025-01-12 11:16:35.877465: val_loss -0.7492 
2025-01-12 11:16:35.882482: Pseudo dice [np.float32(0.8053)] 
2025-01-12 11:16:35.885995: Epoch time: 42.6 s 
2025-01-12 11:16:36.576009:  
2025-01-12 11:16:36.577009: Epoch 177 
2025-01-12 11:16:36.581575: Current learning rate: 0.0033 
2025-01-12 11:17:19.172541: train_loss -0.8311 
2025-01-12 11:17:19.174089: val_loss -0.6738 
2025-01-12 11:17:19.179106: Pseudo dice [np.float32(0.7625)] 
2025-01-12 11:17:19.182635: Epoch time: 42.6 s 
2025-01-12 11:17:19.741242:  
2025-01-12 11:17:19.741745: Epoch 178 
2025-01-12 11:17:19.746279: Current learning rate: 0.00326 
2025-01-12 11:18:02.298417: train_loss -0.849 
2025-01-12 11:18:02.298920: val_loss -0.7208 
2025-01-12 11:18:02.304618: Pseudo dice [np.float32(0.7809)] 
2025-01-12 11:18:02.307188: Epoch time: 42.56 s 
2025-01-12 11:18:02.869555:  
2025-01-12 11:18:02.870057: Epoch 179 
2025-01-12 11:18:02.875070: Current learning rate: 0.00322 
2025-01-12 11:18:45.446365: train_loss -0.8591 
2025-01-12 11:18:45.447364: val_loss -0.7217 
2025-01-12 11:18:45.452876: Pseudo dice [np.float32(0.7915)] 
2025-01-12 11:18:45.456389: Epoch time: 42.58 s 
2025-01-12 11:18:46.009040:  
2025-01-12 11:18:46.009040: Epoch 180 
2025-01-12 11:18:46.014602: Current learning rate: 0.00318 
2025-01-12 11:19:28.593311: train_loss -0.8573 
2025-01-12 11:19:28.594311: val_loss -0.6837 
2025-01-12 11:19:28.599830: Pseudo dice [np.float32(0.7585)] 
2025-01-12 11:19:28.602338: Epoch time: 42.58 s 
2025-01-12 11:19:29.154253:  
2025-01-12 11:19:29.154755: Epoch 181 
2025-01-12 11:19:29.159768: Current learning rate: 0.00314 
2025-01-12 11:20:11.742902: train_loss -0.8552 
2025-01-12 11:20:11.743410: val_loss -0.6991 
2025-01-12 11:20:11.748957: Pseudo dice [np.float32(0.7636)] 
2025-01-12 11:20:11.751477: Epoch time: 42.59 s 
2025-01-12 11:20:12.301672:  
2025-01-12 11:20:12.301672: Epoch 182 
2025-01-12 11:20:12.307192: Current learning rate: 0.0031 
2025-01-12 11:20:54.890620: train_loss -0.8515 
2025-01-12 11:20:54.890620: val_loss -0.6193 
2025-01-12 11:20:54.896636: Pseudo dice [np.float32(0.7276)] 
2025-01-12 11:20:54.900646: Epoch time: 42.59 s 
2025-01-12 11:20:55.450368:  
2025-01-12 11:20:55.450870: Epoch 183 
2025-01-12 11:20:55.455880: Current learning rate: 0.00306 
2025-01-12 11:21:38.030227: train_loss -0.8498 
2025-01-12 11:21:38.030227: val_loss -0.7129 
2025-01-12 11:21:38.036744: Pseudo dice [np.float32(0.7775)] 
2025-01-12 11:21:38.039248: Epoch time: 42.58 s 
2025-01-12 11:21:38.602047:  
2025-01-12 11:21:38.602047: Epoch 184 
2025-01-12 11:21:38.607597: Current learning rate: 0.00302 
2025-01-12 11:22:21.172302: train_loss -0.8489 
2025-01-12 11:22:21.172857: val_loss -0.7157 
2025-01-12 11:22:21.178436: Pseudo dice [np.float32(0.7822)] 
2025-01-12 11:22:21.180957: Epoch time: 42.57 s 
2025-01-12 11:22:21.884284:  
2025-01-12 11:22:21.884786: Epoch 185 
2025-01-12 11:22:21.889299: Current learning rate: 0.00297 
2025-01-12 11:23:04.442938: train_loss -0.8534 
2025-01-12 11:23:04.443939: val_loss -0.7606 
2025-01-12 11:23:04.449461: Pseudo dice [np.float32(0.8145)] 
2025-01-12 11:23:04.452973: Epoch time: 42.56 s 
2025-01-12 11:23:05.013457:  
2025-01-12 11:23:05.013457: Epoch 186 
2025-01-12 11:23:05.018468: Current learning rate: 0.00293 
2025-01-12 11:23:47.609830: train_loss -0.8631 
2025-01-12 11:23:47.610829: val_loss -0.7737 
2025-01-12 11:23:47.616344: Pseudo dice [np.float32(0.8233)] 
2025-01-12 11:23:47.618850: Epoch time: 42.6 s 
2025-01-12 11:23:48.180286:  
2025-01-12 11:23:48.181290: Epoch 187 
2025-01-12 11:23:48.185844: Current learning rate: 0.00289 
2025-01-12 11:24:30.723086: train_loss -0.8667 
2025-01-12 11:24:30.723086: val_loss -0.7734 
2025-01-12 11:24:30.728099: Pseudo dice [np.float32(0.8196)] 
2025-01-12 11:24:30.731605: Epoch time: 42.54 s 
2025-01-12 11:24:31.292491:  
2025-01-12 11:24:31.292491: Epoch 188 
2025-01-12 11:24:31.298042: Current learning rate: 0.00285 
2025-01-12 11:25:13.870240: train_loss -0.8621 
2025-01-12 11:25:13.870240: val_loss -0.7418 
2025-01-12 11:25:13.876252: Pseudo dice [np.float32(0.8074)] 
2025-01-12 11:25:13.879758: Epoch time: 42.58 s 
2025-01-12 11:25:14.435120:  
2025-01-12 11:25:14.435120: Epoch 189 
2025-01-12 11:25:14.439751: Current learning rate: 0.00281 
2025-01-12 11:25:56.988062: train_loss -0.8681 
2025-01-12 11:25:56.989063: val_loss -0.6681 
2025-01-12 11:25:56.994590: Pseudo dice [np.float32(0.7655)] 
2025-01-12 11:25:56.998099: Epoch time: 42.55 s 
2025-01-12 11:25:57.554373:  
2025-01-12 11:25:57.554373: Epoch 190 
2025-01-12 11:25:57.558933: Current learning rate: 0.00277 
2025-01-12 11:26:40.129430: train_loss -0.8624 
2025-01-12 11:26:40.129938: val_loss -0.7822 
2025-01-12 11:26:40.136055: Pseudo dice [np.float32(0.8317)] 
2025-01-12 11:26:40.139644: Epoch time: 42.58 s 
2025-01-12 11:26:40.710006:  
2025-01-12 11:26:40.710006: Epoch 191 
2025-01-12 11:26:40.713515: Current learning rate: 0.00273 
2025-01-12 11:27:23.278082: train_loss -0.8688 
2025-01-12 11:27:23.278082: val_loss -0.7515 
2025-01-12 11:27:23.284144: Pseudo dice [np.float32(0.7928)] 
2025-01-12 11:27:23.287199: Epoch time: 42.57 s 
2025-01-12 11:27:23.847647:  
2025-01-12 11:27:23.848650: Epoch 192 
2025-01-12 11:27:23.853201: Current learning rate: 0.00268 
2025-01-12 11:28:06.400082: train_loss -0.8609 
2025-01-12 11:28:06.400082: val_loss -0.7028 
2025-01-12 11:28:06.405177: Pseudo dice [np.float32(0.7719)] 
2025-01-12 11:28:06.409834: Epoch time: 42.55 s 
2025-01-12 11:28:07.117105:  
2025-01-12 11:28:07.117609: Epoch 193 
2025-01-12 11:28:07.122620: Current learning rate: 0.00264 
2025-01-12 11:28:49.682971: train_loss -0.8617 
2025-01-12 11:28:49.683474: val_loss -0.6892 
2025-01-12 11:28:49.689492: Pseudo dice [np.float32(0.7434)] 
2025-01-12 11:28:49.692002: Epoch time: 42.57 s 
2025-01-12 11:28:50.253956:  
2025-01-12 11:28:50.254960: Epoch 194 
2025-01-12 11:28:50.260578: Current learning rate: 0.0026 
2025-01-12 11:29:38.077878: train_loss -0.8346 
2025-01-12 11:29:38.077878: val_loss -0.6822 
2025-01-12 11:29:38.083898: Pseudo dice [np.float32(0.7231)] 
2025-01-12 11:29:38.086958: Epoch time: 47.82 s 
2025-01-12 11:29:38.647966:  
2025-01-12 11:29:38.648966: Epoch 195 
2025-01-12 11:29:38.654581: Current learning rate: 0.00256 
2025-01-12 11:30:21.250822: train_loss -0.852 
2025-01-12 11:30:21.250822: val_loss -0.7361 
2025-01-12 11:30:21.257408: Pseudo dice [np.float32(0.807)] 
2025-01-12 11:30:21.260958: Epoch time: 42.6 s 
2025-01-12 11:30:21.825555:  
2025-01-12 11:30:21.825555: Epoch 196 
2025-01-12 11:30:21.830603: Current learning rate: 0.00252 
2025-01-12 11:31:04.314070: train_loss -0.863 
2025-01-12 11:31:04.315070: val_loss -0.6599 
2025-01-12 11:31:04.320585: Pseudo dice [np.float32(0.7402)] 
2025-01-12 11:31:04.324095: Epoch time: 42.49 s 
2025-01-12 11:31:04.885314:  
2025-01-12 11:31:04.885314: Epoch 197 
2025-01-12 11:31:04.890326: Current learning rate: 0.00248 
2025-01-12 11:31:47.422993: train_loss -0.8711 
2025-01-12 11:31:47.423994: val_loss -0.6915 
2025-01-12 11:31:47.430512: Pseudo dice [np.float32(0.7648)] 
2025-01-12 11:31:47.434516: Epoch time: 42.54 s 
2025-01-12 11:31:48.002028:  
2025-01-12 11:31:48.002028: Epoch 198 
2025-01-12 11:31:48.006554: Current learning rate: 0.00243 
2025-01-12 11:32:30.518400: train_loss -0.8581 
2025-01-12 11:32:30.518905: val_loss -0.7444 
2025-01-12 11:32:30.523915: Pseudo dice [np.float32(0.8062)] 
2025-01-12 11:32:30.527426: Epoch time: 42.52 s 
2025-01-12 11:32:31.088612:  
2025-01-12 11:32:31.089612: Epoch 199 
2025-01-12 11:32:31.095188: Current learning rate: 0.00239 
2025-01-12 11:33:13.594654: train_loss -0.8662 
2025-01-12 11:33:13.595657: val_loss -0.7736 
2025-01-12 11:33:13.599683: Pseudo dice [np.float32(0.8329)] 
2025-01-12 11:33:13.603195: Epoch time: 42.51 s 
2025-01-12 11:33:14.562882:  
2025-01-12 11:33:14.562882: Epoch 200 
2025-01-12 11:33:14.567941: Current learning rate: 0.00235 
2025-01-12 11:33:57.071435: train_loss -0.8643 
2025-01-12 11:33:57.071941: val_loss -0.757 
2025-01-12 11:33:57.077482: Pseudo dice [np.float32(0.8212)] 
2025-01-12 11:33:57.081510: Epoch time: 42.51 s 
2025-01-12 11:33:57.642832:  
2025-01-12 11:33:57.642832: Epoch 201 
2025-01-12 11:33:57.648393: Current learning rate: 0.00231 
2025-01-12 11:34:40.161441: train_loss -0.8578 
2025-01-12 11:34:40.161942: val_loss -0.7433 
2025-01-12 11:34:40.167956: Pseudo dice [np.float32(0.8094)] 
2025-01-12 11:34:40.171966: Epoch time: 42.52 s 
2025-01-12 11:34:40.733149:  
2025-01-12 11:34:40.733149: Epoch 202 
2025-01-12 11:34:40.739227: Current learning rate: 0.00226 
2025-01-12 11:35:23.243376: train_loss -0.8688 
2025-01-12 11:35:23.243886: val_loss -0.7161 
2025-01-12 11:35:23.248997: Pseudo dice [np.float32(0.799)] 
2025-01-12 11:35:23.252932: Epoch time: 42.51 s 
2025-01-12 11:35:23.813857:  
2025-01-12 11:35:23.813857: Epoch 203 
2025-01-12 11:35:23.819396: Current learning rate: 0.00222 
2025-01-12 11:36:06.365217: train_loss -0.8734 
2025-01-12 11:36:06.365217: val_loss -0.7148 
2025-01-12 11:36:06.372337: Pseudo dice [np.float32(0.7929)] 
2025-01-12 11:36:06.375368: Epoch time: 42.55 s 
2025-01-12 11:36:06.943249:  
2025-01-12 11:36:06.944253: Epoch 204 
2025-01-12 11:36:06.947903: Current learning rate: 0.00218 
2025-01-12 11:36:49.448301: train_loss -0.8692 
2025-01-12 11:36:49.448821: val_loss -0.7167 
2025-01-12 11:36:49.453914: Pseudo dice [np.float32(0.7958)] 
2025-01-12 11:36:49.457476: Epoch time: 42.5 s 
2025-01-12 11:36:50.029438:  
2025-01-12 11:36:50.029438: Epoch 205 
2025-01-12 11:36:50.034958: Current learning rate: 0.00214 
2025-01-12 11:37:32.566324: train_loss -0.8593 
2025-01-12 11:37:32.567894: val_loss -0.7408 
2025-01-12 11:37:32.572927: Pseudo dice [np.float32(0.803)] 
2025-01-12 11:37:32.576944: Epoch time: 42.54 s 
2025-01-12 11:37:33.112642:  
2025-01-12 11:37:33.112642: Epoch 206 
2025-01-12 11:37:33.117662: Current learning rate: 0.00209 
2025-01-12 11:38:15.645597: train_loss -0.8664 
2025-01-12 11:38:15.646107: val_loss -0.7409 
2025-01-12 11:38:15.652208: Pseudo dice [np.float32(0.8159)] 
2025-01-12 11:38:15.654756: Epoch time: 42.53 s 
2025-01-12 11:38:16.186392:  
2025-01-12 11:38:16.187395: Epoch 207 
2025-01-12 11:38:16.192497: Current learning rate: 0.00205 
2025-01-12 11:38:58.699057: train_loss -0.8702 
2025-01-12 11:38:58.699564: val_loss -0.6452 
2025-01-12 11:38:58.704601: Pseudo dice [np.float32(0.7345)] 
2025-01-12 11:38:58.709639: Epoch time: 42.51 s 
2025-01-12 11:38:59.387770:  
2025-01-12 11:38:59.387770: Epoch 208 
2025-01-12 11:38:59.392780: Current learning rate: 0.00201 
2025-01-12 11:39:41.891270: train_loss -0.8694 
2025-01-12 11:39:41.892273: val_loss -0.7409 
2025-01-12 11:39:41.897787: Pseudo dice [np.float32(0.8093)] 
2025-01-12 11:39:41.901303: Epoch time: 42.5 s 
2025-01-12 11:39:42.438858:  
2025-01-12 11:39:42.439862: Epoch 209 
2025-01-12 11:39:42.443894: Current learning rate: 0.00196 
2025-01-12 11:40:24.913965: train_loss -0.8657 
2025-01-12 11:40:24.913965: val_loss -0.719 
2025-01-12 11:40:24.919980: Pseudo dice [np.float32(0.7836)] 
2025-01-12 11:40:24.924000: Epoch time: 42.48 s 
2025-01-12 11:40:25.452713:  
2025-01-12 11:40:25.452713: Epoch 210 
2025-01-12 11:40:25.457759: Current learning rate: 0.00192 
2025-01-12 11:41:07.948449: train_loss -0.8743 
2025-01-12 11:41:07.948951: val_loss -0.7673 
2025-01-12 11:41:07.953961: Pseudo dice [np.float32(0.817)] 
2025-01-12 11:41:07.957470: Epoch time: 42.5 s 
2025-01-12 11:41:08.489352:  
2025-01-12 11:41:08.489856: Epoch 211 
2025-01-12 11:41:08.494866: Current learning rate: 0.00188 
2025-01-12 11:41:50.955067: train_loss -0.8738 
2025-01-12 11:41:50.956074: val_loss -0.7143 
2025-01-12 11:41:50.960816: Pseudo dice [np.float32(0.7764)] 
2025-01-12 11:41:50.964330: Epoch time: 42.47 s 
2025-01-12 11:41:51.499436:  
2025-01-12 11:41:51.500440: Epoch 212 
2025-01-12 11:41:51.504986: Current learning rate: 0.00184 
2025-01-12 11:42:33.987186: train_loss -0.8606 
2025-01-12 11:42:33.988189: val_loss -0.687 
2025-01-12 11:42:33.993830: Pseudo dice [np.float32(0.7594)] 
2025-01-12 11:42:33.997378: Epoch time: 42.49 s 
2025-01-12 11:42:34.538151:  
2025-01-12 11:42:34.538151: Epoch 213 
2025-01-12 11:42:34.543684: Current learning rate: 0.00179 
2025-01-12 11:43:17.046544: train_loss -0.8604 
2025-01-12 11:43:17.046544: val_loss -0.696 
2025-01-12 11:43:17.051556: Pseudo dice [np.float32(0.7629)] 
2025-01-12 11:43:17.056069: Epoch time: 42.51 s 
2025-01-12 11:43:17.686892:  
2025-01-12 11:43:17.687892: Epoch 214 
2025-01-12 11:43:17.693409: Current learning rate: 0.00175 
2025-01-12 11:44:00.134149: train_loss -0.8616 
2025-01-12 11:44:00.135149: val_loss -0.622 
2025-01-12 11:44:00.140661: Pseudo dice [np.float32(0.7182)] 
2025-01-12 11:44:00.144174: Epoch time: 42.45 s 
2025-01-12 11:44:00.671810:  
2025-01-12 11:44:00.671810: Epoch 215 
2025-01-12 11:44:00.677368: Current learning rate: 0.0017 
2025-01-12 11:44:43.150700: train_loss -0.8589 
2025-01-12 11:44:43.150700: val_loss -0.7513 
2025-01-12 11:44:43.156311: Pseudo dice [np.float32(0.814)] 
2025-01-12 11:44:43.159819: Epoch time: 42.48 s 
2025-01-12 11:44:43.837189:  
2025-01-12 11:44:43.837693: Epoch 216 
2025-01-12 11:44:43.842703: Current learning rate: 0.00166 
2025-01-12 11:45:26.275891: train_loss -0.8693 
2025-01-12 11:45:26.276403: val_loss -0.7716 
2025-01-12 11:45:26.281954: Pseudo dice [np.float32(0.819)] 
2025-01-12 11:45:26.285485: Epoch time: 42.44 s 
2025-01-12 11:45:26.811040:  
2025-01-12 11:45:26.812046: Epoch 217 
2025-01-12 11:45:26.816091: Current learning rate: 0.00162 
2025-01-12 11:46:09.283349: train_loss -0.8665 
2025-01-12 11:46:09.284356: val_loss -0.7442 
2025-01-12 11:46:09.290452: Pseudo dice [np.float32(0.8036)] 
2025-01-12 11:46:09.295682: Epoch time: 42.47 s 
2025-01-12 11:46:09.829928:  
2025-01-12 11:46:09.830926: Epoch 218 
2025-01-12 11:46:09.835996: Current learning rate: 0.00157 
2025-01-12 11:46:52.354782: train_loss -0.8625 
2025-01-12 11:46:52.354782: val_loss -0.7437 
2025-01-12 11:46:52.360801: Pseudo dice [np.float32(0.8089)] 
2025-01-12 11:46:52.363814: Epoch time: 42.52 s 
2025-01-12 11:46:52.899064:  
2025-01-12 11:46:52.899566: Epoch 219 
2025-01-12 11:46:52.904578: Current learning rate: 0.00153 
2025-01-12 11:47:35.457771: train_loss -0.8722 
2025-01-12 11:47:35.457771: val_loss -0.7066 
2025-01-12 11:47:35.462789: Pseudo dice [np.float32(0.785)] 
2025-01-12 11:47:35.466806: Epoch time: 42.56 s 
2025-01-12 11:47:36.006716:  
2025-01-12 11:47:36.006716: Epoch 220 
2025-01-12 11:47:36.011747: Current learning rate: 0.00148 
2025-01-12 11:48:18.522696: train_loss -0.8661 
2025-01-12 11:48:18.523206: val_loss -0.7262 
2025-01-12 11:48:18.528848: Pseudo dice [np.float32(0.8002)] 
2025-01-12 11:48:18.531897: Epoch time: 42.52 s 
2025-01-12 11:48:19.061370:  
2025-01-12 11:48:19.062370: Epoch 221 
2025-01-12 11:48:19.065419: Current learning rate: 0.00144 
2025-01-12 11:49:01.556648: train_loss -0.8621 
2025-01-12 11:49:01.556648: val_loss -0.7768 
2025-01-12 11:49:01.562663: Pseudo dice [np.float32(0.8328)] 
2025-01-12 11:49:01.565674: Epoch time: 42.5 s 
2025-01-12 11:49:02.094824:  
2025-01-12 11:49:02.095327: Epoch 222 
2025-01-12 11:49:02.100341: Current learning rate: 0.00139 
2025-01-12 11:49:44.577377: train_loss -0.8716 
2025-01-12 11:49:44.578382: val_loss -0.7698 
2025-01-12 11:49:44.583440: Pseudo dice [np.float32(0.8174)] 
2025-01-12 11:49:44.587452: Epoch time: 42.48 s 
2025-01-12 11:49:45.126697:  
2025-01-12 11:49:45.127206: Epoch 223 
2025-01-12 11:49:45.133277: Current learning rate: 0.00135 
2025-01-12 11:50:27.623036: train_loss -0.875 
2025-01-12 11:50:27.623538: val_loss -0.7287 
2025-01-12 11:50:27.628548: Pseudo dice [np.float32(0.7857)] 
2025-01-12 11:50:27.633059: Epoch time: 42.5 s 
2025-01-12 11:50:28.166776:  
2025-01-12 11:50:28.166776: Epoch 224 
2025-01-12 11:50:28.171819: Current learning rate: 0.0013 
2025-01-12 11:51:10.672955: train_loss -0.8698 
2025-01-12 11:51:10.673959: val_loss -0.7548 
2025-01-12 11:51:10.678970: Pseudo dice [np.float32(0.8191)] 
2025-01-12 11:51:10.682983: Epoch time: 42.51 s 
2025-01-12 11:51:11.362605:  
2025-01-12 11:51:11.363109: Epoch 225 
2025-01-12 11:51:11.367659: Current learning rate: 0.00126 
2025-01-12 11:51:53.853232: train_loss -0.8735 
2025-01-12 11:51:53.853232: val_loss -0.7242 
2025-01-12 11:51:53.859243: Pseudo dice [np.float32(0.7927)] 
2025-01-12 11:51:53.862251: Epoch time: 42.49 s 
2025-01-12 11:51:54.395831:  
2025-01-12 11:51:54.395831: Epoch 226 
2025-01-12 11:51:54.401389: Current learning rate: 0.00121 
2025-01-12 11:52:36.873344: train_loss -0.8773 
2025-01-12 11:52:36.874349: val_loss -0.7144 
2025-01-12 11:52:36.879362: Pseudo dice [np.float32(0.7989)] 
2025-01-12 11:52:36.883372: Epoch time: 42.48 s 
2025-01-12 11:52:37.416611:  
2025-01-12 11:52:37.416611: Epoch 227 
2025-01-12 11:52:37.422684: Current learning rate: 0.00117 
2025-01-12 11:53:19.901512: train_loss -0.8699 
2025-01-12 11:53:19.902015: val_loss -0.6808 
2025-01-12 11:53:19.907026: Pseudo dice [np.float32(0.7782)] 
2025-01-12 11:53:19.910535: Epoch time: 42.48 s 
2025-01-12 11:53:20.442171:  
2025-01-12 11:53:20.442673: Epoch 228 
2025-01-12 11:53:20.447687: Current learning rate: 0.00112 
2025-01-12 11:54:02.912691: train_loss -0.8722 
2025-01-12 11:54:02.913693: val_loss -0.7173 
2025-01-12 11:54:02.918709: Pseudo dice [np.float32(0.7884)] 
2025-01-12 11:54:02.922724: Epoch time: 42.47 s 
2025-01-12 11:54:03.450534:  
2025-01-12 11:54:03.450534: Epoch 229 
2025-01-12 11:54:03.455549: Current learning rate: 0.00108 
2025-01-12 11:54:45.947737: train_loss -0.8763 
2025-01-12 11:54:45.947737: val_loss -0.7181 
2025-01-12 11:54:45.953745: Pseudo dice [np.float32(0.8087)] 
2025-01-12 11:54:45.956753: Epoch time: 42.5 s 
2025-01-12 11:54:46.487917:  
2025-01-12 11:54:46.487917: Epoch 230 
2025-01-12 11:54:46.493490: Current learning rate: 0.00103 
2025-01-12 11:55:29.004661: train_loss -0.8777 
2025-01-12 11:55:29.004661: val_loss -0.7546 
2025-01-12 11:55:29.009676: Pseudo dice [np.float32(0.8149)] 
2025-01-12 11:55:29.013188: Epoch time: 42.52 s 
2025-01-12 11:55:29.544008:  
2025-01-12 11:55:29.544008: Epoch 231 
2025-01-12 11:55:29.549026: Current learning rate: 0.00098 
2025-01-12 11:56:12.056977: train_loss -0.8769 
2025-01-12 11:56:12.056977: val_loss -0.7388 
2025-01-12 11:56:12.063026: Pseudo dice [np.float32(0.8008)] 
2025-01-12 11:56:12.065531: Epoch time: 42.51 s 
2025-01-12 11:56:12.592479:  
2025-01-12 11:56:12.592479: Epoch 232 
2025-01-12 11:56:12.597493: Current learning rate: 0.00094 
2025-01-12 11:56:55.112522: train_loss -0.8806 
2025-01-12 11:56:55.113024: val_loss -0.756 
2025-01-12 11:56:55.118040: Pseudo dice [np.float32(0.817)] 
2025-01-12 11:56:55.121552: Epoch time: 42.52 s 
2025-01-12 11:56:55.653061:  
2025-01-12 11:56:55.653564: Epoch 233 
2025-01-12 11:56:55.658575: Current learning rate: 0.00089 
2025-01-12 11:57:38.163833: train_loss -0.879 
2025-01-12 11:57:38.163833: val_loss -0.6796 
2025-01-12 11:57:38.168895: Pseudo dice [np.float32(0.7507)] 
2025-01-12 11:57:38.173013: Epoch time: 42.51 s 
2025-01-12 11:57:38.851697:  
2025-01-12 11:57:38.852199: Epoch 234 
2025-01-12 11:57:38.857218: Current learning rate: 0.00084 
2025-01-12 11:58:21.331194: train_loss -0.8827 
2025-01-12 11:58:21.331194: val_loss -0.7065 
2025-01-12 11:58:21.337204: Pseudo dice [np.float32(0.7831)] 
2025-01-12 11:58:21.340219: Epoch time: 42.48 s 
2025-01-12 11:58:21.876491:  
2025-01-12 11:58:21.876491: Epoch 235 
2025-01-12 11:58:21.882518: Current learning rate: 0.00079 
2025-01-12 11:59:04.372438: train_loss -0.8752 
2025-01-12 11:59:04.372941: val_loss -0.7732 
2025-01-12 11:59:04.377952: Pseudo dice [np.float32(0.8092)] 
2025-01-12 11:59:04.381470: Epoch time: 42.5 s 
2025-01-12 11:59:04.909211:  
2025-01-12 11:59:04.909211: Epoch 236 
2025-01-12 11:59:04.914790: Current learning rate: 0.00075 
2025-01-12 11:59:47.406239: train_loss -0.8814 
2025-01-12 11:59:47.406239: val_loss -0.7245 
2025-01-12 11:59:47.412256: Pseudo dice [np.float32(0.786)] 
2025-01-12 11:59:47.416263: Epoch time: 42.5 s 
2025-01-12 11:59:47.945968:  
2025-01-12 11:59:47.947480: Epoch 237 
2025-01-12 11:59:47.952518: Current learning rate: 0.0007 
2025-01-12 12:00:30.436360: train_loss -0.8817 
2025-01-12 12:00:30.436864: val_loss -0.7754 
2025-01-12 12:00:30.441879: Pseudo dice [np.float32(0.8257)] 
2025-01-12 12:00:30.445392: Epoch time: 42.49 s 
2025-01-12 12:00:30.981659:  
2025-01-12 12:00:30.981659: Epoch 238 
2025-01-12 12:00:30.987215: Current learning rate: 0.00065 
2025-01-12 12:01:13.497666: train_loss -0.8757 
2025-01-12 12:01:13.497666: val_loss -0.699 
2025-01-12 12:01:13.502679: Pseudo dice [np.float32(0.7926)] 
2025-01-12 12:01:13.505184: Epoch time: 42.52 s 
2025-01-12 12:01:14.034457:  
2025-01-12 12:01:14.034457: Epoch 239 
2025-01-12 12:01:14.039470: Current learning rate: 0.0006 
2025-01-12 12:01:56.527345: train_loss -0.8752 
2025-01-12 12:01:56.527345: val_loss -0.7506 
2025-01-12 12:01:56.532859: Pseudo dice [np.float32(0.8038)] 
2025-01-12 12:01:56.536371: Epoch time: 42.49 s 
2025-01-12 12:01:57.073226:  
2025-01-12 12:01:57.073226: Epoch 240 
2025-01-12 12:01:57.078779: Current learning rate: 0.00055 
2025-01-12 12:02:39.582897: train_loss -0.8802 
2025-01-12 12:02:39.582897: val_loss -0.7114 
2025-01-12 12:02:39.588913: Pseudo dice [np.float32(0.7797)] 
2025-01-12 12:02:39.592423: Epoch time: 42.51 s 
2025-01-12 12:02:40.128450:  
2025-01-12 12:02:40.128450: Epoch 241 
2025-01-12 12:02:40.134043: Current learning rate: 0.0005 
2025-01-12 12:03:22.598048: train_loss -0.8803 
2025-01-12 12:03:22.598048: val_loss -0.6577 
2025-01-12 12:03:22.605572: Pseudo dice [np.float32(0.741)] 
2025-01-12 12:03:22.609087: Epoch time: 42.47 s 
2025-01-12 12:03:23.147678:  
2025-01-12 12:03:23.148191: Epoch 242 
2025-01-12 12:03:23.153248: Current learning rate: 0.00045 
2025-01-12 12:04:05.600072: train_loss -0.8747 
2025-01-12 12:04:05.601072: val_loss -0.7523 
2025-01-12 12:04:05.606587: Pseudo dice [np.float32(0.814)] 
2025-01-12 12:04:05.610097: Epoch time: 42.45 s 
2025-01-12 12:04:06.302721:  
2025-01-12 12:04:06.303231: Epoch 243 
2025-01-12 12:04:06.307772: Current learning rate: 0.0004 
2025-01-12 12:04:48.768008: train_loss -0.8737 
2025-01-12 12:04:48.769011: val_loss -0.7693 
2025-01-12 12:04:48.774527: Pseudo dice [np.float32(0.815)] 
2025-01-12 12:04:48.780149: Epoch time: 42.47 s 
2025-01-12 12:04:49.319674:  
2025-01-12 12:04:49.320679: Epoch 244 
2025-01-12 12:04:49.325217: Current learning rate: 0.00035 
2025-01-12 12:05:31.842128: train_loss -0.8732 
2025-01-12 12:05:31.842128: val_loss -0.715 
2025-01-12 12:05:31.847143: Pseudo dice [np.float32(0.7945)] 
2025-01-12 12:05:31.850655: Epoch time: 42.52 s 
2025-01-12 12:05:32.393729:  
2025-01-12 12:05:32.393729: Epoch 245 
2025-01-12 12:05:32.398740: Current learning rate: 0.0003 
2025-01-12 12:06:14.923521: train_loss -0.8762 
2025-01-12 12:06:14.924526: val_loss -0.7138 
2025-01-12 12:06:14.929542: Pseudo dice [np.float32(0.7891)] 
2025-01-12 12:06:14.933553: Epoch time: 42.53 s 
2025-01-12 12:06:15.474182:  
2025-01-12 12:06:15.474182: Epoch 246 
2025-01-12 12:06:15.480251: Current learning rate: 0.00024 
2025-01-12 12:06:57.966662: train_loss -0.8716 
2025-01-12 12:06:57.966662: val_loss -0.7408 
2025-01-12 12:06:57.973176: Pseudo dice [np.float32(0.7921)] 
2025-01-12 12:06:57.977684: Epoch time: 42.49 s 
2025-01-12 12:06:58.514917:  
2025-01-12 12:06:58.515916: Epoch 247 
2025-01-12 12:06:58.521431: Current learning rate: 0.00019 
2025-01-12 12:07:41.044287: train_loss -0.8727 
2025-01-12 12:07:41.044792: val_loss -0.7233 
2025-01-12 12:07:41.049806: Pseudo dice [np.float32(0.7938)] 
2025-01-12 12:07:41.053357: Epoch time: 42.53 s 
2025-01-12 12:07:41.599134:  
2025-01-12 12:07:41.599134: Epoch 248 
2025-01-12 12:07:41.604174: Current learning rate: 0.00013 
2025-01-12 12:08:24.114075: train_loss -0.8788 
2025-01-12 12:08:24.114075: val_loss -0.7274 
2025-01-12 12:08:24.120595: Pseudo dice [np.float32(0.7908)] 
2025-01-12 12:08:24.124107: Epoch time: 42.52 s 
2025-01-12 12:08:24.660427:  
2025-01-12 12:08:24.660427: Epoch 249 
2025-01-12 12:08:24.665483: Current learning rate: 7e-05 
2025-01-12 12:09:07.178749: train_loss -0.8783 
2025-01-12 12:09:07.179752: val_loss -0.7715 
2025-01-12 12:09:07.184771: Pseudo dice [np.float32(0.8243)] 
2025-01-12 12:09:07.188278: Epoch time: 42.52 s 
2025-01-12 12:09:07.935516: Training done. 
2025-01-12 12:09:07.969517: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2025-01-12 12:09:07.979517: The split file contains 5 splits. 
2025-01-12 12:09:07.983517: Desired fold for training: 0 
2025-01-12 12:09:07.987517: This split has 50 training and 13 validation cases. 
2025-01-12 12:09:07.992517: predicting lung_006 
2025-01-12 12:09:07.998517: lung_006, shape torch.Size([1, 285, 637, 637]), rank 0 
2025-01-12 12:09:56.487612: predicting lung_010 
2025-01-12 12:09:56.530612: lung_010, shape torch.Size([1, 242, 390, 390]), rank 0 
2025-01-12 12:10:15.404237: predicting lung_033 
2025-01-12 12:10:15.419236: lung_033, shape torch.Size([1, 260, 535, 535]), rank 0 
2025-01-12 12:10:53.569881: predicting lung_034 
2025-01-12 12:10:53.597884: lung_034, shape torch.Size([1, 296, 586, 586]), rank 0 
2025-01-12 12:11:47.976481: predicting lung_041 
2025-01-12 12:11:48.013481: lung_041, shape torch.Size([1, 240, 535, 535]), rank 0 
2025-01-12 12:12:21.385879: predicting lung_042 
2025-01-12 12:12:21.422879: lung_042, shape torch.Size([1, 251, 478, 478]), rank 0 
2025-01-12 12:12:46.899697: predicting lung_046 
2025-01-12 12:12:46.921696: lung_046, shape torch.Size([1, 226, 509, 509]), rank 0 
2025-01-12 12:13:12.400783: predicting lung_048 
2025-01-12 12:13:12.430782: lung_048, shape torch.Size([1, 259, 531, 531]), rank 0 
2025-01-12 12:13:50.613872: predicting lung_059 
2025-01-12 12:13:50.650994: lung_059, shape torch.Size([1, 218, 535, 535]), rank 0 
2025-01-12 12:14:19.203396: predicting lung_065 
2025-01-12 12:14:19.234905: lung_065, shape torch.Size([1, 257, 474, 474]), rank 0 
2025-01-12 12:14:48.334494: predicting lung_066 
2025-01-12 12:14:48.356004: lung_066, shape torch.Size([1, 241, 578, 578]), rank 0 
2025-01-12 12:15:30.523703: predicting lung_070 
2025-01-12 12:15:30.567703: lung_070, shape torch.Size([1, 266, 497, 497]), rank 0 
2025-01-12 12:15:59.808540: predicting lung_079 
2025-01-12 12:15:59.832539: lung_079, shape torch.Size([1, 251, 606, 606]), rank 0 
2025-01-12 12:16:52.909287: Validation complete 
2025-01-12 12:16:52.910288: Mean Validation Dice:  0.7253639874401642 
