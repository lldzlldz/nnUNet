
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-08 00:32:58.240856: do_dummy_2d_data_aug: False 
2025-01-08 00:32:58.246358: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2025-01-08 00:32:58.251864: The split file contains 5 splits. 
2025-01-08 00:32:58.253865: Desired fold for training: 0 
2025-01-08 00:32:58.256367: This split has 50 training and 13 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_avg_spacing_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [252.0, 512.0, 512.0], 'spacing': [1.244979977607727, 0.78515625, 0.78515625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset006_Lung', 'plans_name': 'nnUNetPlans_avg_spacing', 'original_median_spacing_after_transp': [1.244979977607727, 0.78515625, 0.78515625], 'original_median_shape_after_transp': [252, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2671.0, 'mean': -273.4598083496094, 'median': -162.0, 'min': -1024.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 311.0, 'std': 346.9495849609375}}} 
 
2025-01-08 00:33:10.735374: unpacking dataset... 
2025-01-08 00:33:25.760138: unpacking done... 
2025-01-08 00:33:30.418293:  
2025-01-08 00:33:30.418293: Epoch 0 
2025-01-08 00:33:30.423309: Current learning rate: 0.01 
2025-01-08 00:34:29.365839: train_loss 0.0501 
2025-01-08 00:34:29.365839: val_loss -0.1528 
2025-01-08 00:34:29.372360: Pseudo dice [np.float32(0.0)] 
2025-01-08 00:34:29.375874: Epoch time: 58.95 s 
2025-01-08 00:34:29.379387: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-08 00:34:30.077936:  
2025-01-08 00:34:30.077936: Epoch 1 
2025-01-08 00:34:30.083460: Current learning rate: 0.00998 
2025-01-08 00:35:23.718046: train_loss -0.2093 
2025-01-08 00:35:23.719049: val_loss -0.3126 
2025-01-08 00:35:23.724733: Pseudo dice [np.float32(0.23)] 
2025-01-08 00:35:23.728362: Epoch time: 53.64 s 
2025-01-08 00:35:23.731419: Yayy! New best EMA pseudo Dice: 0.023000000044703484 
2025-01-08 00:35:24.484969:  
2025-01-08 00:35:24.485974: Epoch 2 
2025-01-08 00:35:24.491595: Current learning rate: 0.00996 
2025-01-08 00:36:18.119516: train_loss -0.3646 
2025-01-08 00:36:18.119516: val_loss -0.5521 
2025-01-08 00:36:18.125532: Pseudo dice [np.float32(0.6066)] 
2025-01-08 00:36:18.129038: Epoch time: 53.63 s 
2025-01-08 00:36:18.132050: Yayy! New best EMA pseudo Dice: 0.08139999955892563 
2025-01-08 00:36:18.950415:  
2025-01-08 00:36:18.950415: Epoch 3 
2025-01-08 00:36:18.956931: Current learning rate: 0.00995 
2025-01-08 00:37:12.586865: train_loss -0.3884 
2025-01-08 00:37:12.587868: val_loss -0.4789 
2025-01-08 00:37:12.593430: Pseudo dice [np.float32(0.5404)] 
2025-01-08 00:37:12.596944: Epoch time: 53.64 s 
2025-01-08 00:37:12.599960: Yayy! New best EMA pseudo Dice: 0.12729999423027039 
2025-01-08 00:37:13.405679:  
2025-01-08 00:37:13.406682: Epoch 4 
2025-01-08 00:37:13.411243: Current learning rate: 0.00993 
2025-01-08 00:38:07.045929: train_loss -0.4369 
2025-01-08 00:38:07.046456: val_loss -0.6403 
2025-01-08 00:38:07.051470: Pseudo dice [np.float32(0.6677)] 
2025-01-08 00:38:07.056039: Epoch time: 53.64 s 
2025-01-08 00:38:07.059055: Yayy! New best EMA pseudo Dice: 0.18129999935626984 
2025-01-08 00:38:08.010257:  
2025-01-08 00:38:08.011759: Epoch 5 
2025-01-08 00:38:08.016807: Current learning rate: 0.00991 
2025-01-08 00:39:01.652485: train_loss -0.455 
2025-01-08 00:39:01.652485: val_loss -0.6216 
2025-01-08 00:39:01.659082: Pseudo dice [np.float32(0.5607)] 
2025-01-08 00:39:01.663098: Epoch time: 53.64 s 
2025-01-08 00:39:01.666109: Yayy! New best EMA pseudo Dice: 0.219200000166893 
2025-01-08 00:39:02.457602:  
2025-01-08 00:39:02.457602: Epoch 6 
2025-01-08 00:39:02.463708: Current learning rate: 0.00989 
2025-01-08 00:39:56.003710: train_loss -0.4835 
2025-01-08 00:39:56.004213: val_loss -0.6048 
2025-01-08 00:39:56.009769: Pseudo dice [np.float32(0.6868)] 
2025-01-08 00:39:56.012797: Epoch time: 53.55 s 
2025-01-08 00:39:56.016302: Yayy! New best EMA pseudo Dice: 0.26600000262260437 
2025-01-08 00:39:56.777098:  
2025-01-08 00:39:56.778101: Epoch 7 
2025-01-08 00:39:56.783191: Current learning rate: 0.00987 
2025-01-08 00:40:50.394924: train_loss -0.4336 
2025-01-08 00:40:50.396427: val_loss -0.5797 
2025-01-08 00:40:50.401567: Pseudo dice [np.float32(0.6873)] 
2025-01-08 00:40:50.405100: Epoch time: 53.62 s 
2025-01-08 00:40:50.407627: Yayy! New best EMA pseudo Dice: 0.30809998512268066 
2025-01-08 00:40:51.229100:  
2025-01-08 00:40:51.230105: Epoch 8 
2025-01-08 00:40:51.234669: Current learning rate: 0.00986 
2025-01-08 00:41:44.845466: train_loss -0.4831 
2025-01-08 00:41:44.846470: val_loss -0.6377 
2025-01-08 00:41:44.852049: Pseudo dice [np.float32(0.6998)] 
2025-01-08 00:41:44.855135: Epoch time: 53.62 s 
2025-01-08 00:41:44.858646: Yayy! New best EMA pseudo Dice: 0.3472999930381775 
2025-01-08 00:41:45.687045:  
2025-01-08 00:41:45.687045: Epoch 9 
2025-01-08 00:41:45.692057: Current learning rate: 0.00984 
2025-01-08 00:42:39.281411: train_loss -0.4512 
2025-01-08 00:42:39.281411: val_loss -0.6381 
2025-01-08 00:42:39.287929: Pseudo dice [np.float32(0.6608)] 
2025-01-08 00:42:39.291437: Epoch time: 53.6 s 
2025-01-08 00:42:39.293946: Yayy! New best EMA pseudo Dice: 0.37869998812675476 
2025-01-08 00:42:40.083352:  
2025-01-08 00:42:40.083853: Epoch 10 
2025-01-08 00:42:40.088875: Current learning rate: 0.00982 
2025-01-08 00:43:33.657339: train_loss -0.5282 
2025-01-08 00:43:33.657847: val_loss -0.61 
2025-01-08 00:43:33.663442: Pseudo dice [np.float32(0.63)] 
2025-01-08 00:43:33.666673: Epoch time: 53.57 s 
2025-01-08 00:43:33.669186: Yayy! New best EMA pseudo Dice: 0.40380001068115234 
2025-01-08 00:43:34.440361:  
2025-01-08 00:43:34.440361: Epoch 11 
2025-01-08 00:43:34.446409: Current learning rate: 0.0098 
2025-01-08 00:44:28.103562: train_loss -0.5221 
2025-01-08 00:44:28.104073: val_loss -0.6488 
2025-01-08 00:44:28.109620: Pseudo dice [np.float32(0.724)] 
2025-01-08 00:44:28.112130: Epoch time: 53.66 s 
2025-01-08 00:44:28.115730: Yayy! New best EMA pseudo Dice: 0.4357999861240387 
2025-01-08 00:44:28.878001:  
2025-01-08 00:44:28.878505: Epoch 12 
2025-01-08 00:44:28.883526: Current learning rate: 0.00978 
2025-01-08 00:45:22.559471: train_loss -0.5584 
2025-01-08 00:45:22.560474: val_loss -0.6513 
2025-01-08 00:45:22.566055: Pseudo dice [np.float32(0.694)] 
2025-01-08 00:45:22.568566: Epoch time: 53.68 s 
2025-01-08 00:45:22.572085: Yayy! New best EMA pseudo Dice: 0.46160000562667847 
2025-01-08 00:45:23.490888:  
2025-01-08 00:45:23.490888: Epoch 13 
2025-01-08 00:45:23.495993: Current learning rate: 0.00977 
2025-01-08 00:46:17.120551: train_loss -0.5902 
2025-01-08 00:46:17.122053: val_loss -0.5666 
2025-01-08 00:46:17.128080: Pseudo dice [np.float32(0.5711)] 
2025-01-08 00:46:17.131589: Epoch time: 53.63 s 
2025-01-08 00:46:17.134601: Yayy! New best EMA pseudo Dice: 0.4726000130176544 
2025-01-08 00:46:17.942848:  
2025-01-08 00:46:17.943852: Epoch 14 
2025-01-08 00:46:17.949371: Current learning rate: 0.00975 
2025-01-08 00:47:11.609125: train_loss -0.5598 
2025-01-08 00:47:11.610631: val_loss -0.6678 
2025-01-08 00:47:11.615645: Pseudo dice [np.float32(0.7272)] 
2025-01-08 00:47:11.619195: Epoch time: 53.67 s 
2025-01-08 00:47:11.621379: Yayy! New best EMA pseudo Dice: 0.49799999594688416 
2025-01-08 00:47:12.433793:  
2025-01-08 00:47:12.434802: Epoch 15 
2025-01-08 00:47:12.439404: Current learning rate: 0.00973 
2025-01-08 00:48:06.107476: train_loss -0.5859 
2025-01-08 00:48:06.108480: val_loss -0.69 
2025-01-08 00:48:06.114588: Pseudo dice [np.float32(0.7511)] 
2025-01-08 00:48:06.117622: Epoch time: 53.67 s 
2025-01-08 00:48:06.121135: Yayy! New best EMA pseudo Dice: 0.5232999920845032 
2025-01-08 00:48:06.937225:  
2025-01-08 00:48:06.937225: Epoch 16 
2025-01-08 00:48:06.942242: Current learning rate: 0.00971 
2025-01-08 00:49:00.576837: train_loss -0.5821 
2025-01-08 00:49:00.577340: val_loss -0.5567 
2025-01-08 00:49:00.582956: Pseudo dice [np.float32(0.6179)] 
2025-01-08 00:49:00.586485: Epoch time: 53.64 s 
2025-01-08 00:49:00.591908: Yayy! New best EMA pseudo Dice: 0.532800018787384 
2025-01-08 00:49:01.419494:  
2025-01-08 00:49:01.419494: Epoch 17 
2025-01-08 00:49:01.424508: Current learning rate: 0.00969 
2025-01-08 00:49:55.122885: train_loss -0.5257 
2025-01-08 00:49:55.123394: val_loss -0.6826 
2025-01-08 00:49:55.128024: Pseudo dice [np.float32(0.7667)] 
2025-01-08 00:49:55.131565: Epoch time: 53.7 s 
2025-01-08 00:49:55.134628: Yayy! New best EMA pseudo Dice: 0.5562000274658203 
2025-01-08 00:49:55.949343:  
2025-01-08 00:49:55.949343: Epoch 18 
2025-01-08 00:49:55.954900: Current learning rate: 0.00968 
2025-01-08 00:50:49.669099: train_loss -0.5639 
2025-01-08 00:50:49.669605: val_loss -0.6862 
2025-01-08 00:50:49.675094: Pseudo dice [np.float32(0.7381)] 
2025-01-08 00:50:49.677665: Epoch time: 53.72 s 
2025-01-08 00:50:49.681179: Yayy! New best EMA pseudo Dice: 0.574400007724762 
2025-01-08 00:50:50.515470:  
2025-01-08 00:50:50.515470: Epoch 19 
2025-01-08 00:50:50.521561: Current learning rate: 0.00966 
2025-01-08 00:51:44.210107: train_loss -0.5639 
2025-01-08 00:51:44.211106: val_loss -0.6181 
2025-01-08 00:51:44.216629: Pseudo dice [np.float32(0.6876)] 
2025-01-08 00:51:44.220142: Epoch time: 53.7 s 
2025-01-08 00:51:44.223650: Yayy! New best EMA pseudo Dice: 0.5856999754905701 
2025-01-08 00:51:45.171942:  
2025-01-08 00:51:45.171942: Epoch 20 
2025-01-08 00:51:45.177961: Current learning rate: 0.00964 
2025-01-08 00:52:38.887154: train_loss -0.5736 
2025-01-08 00:52:38.887154: val_loss -0.6318 
2025-01-08 00:52:38.893174: Pseudo dice [np.float32(0.6751)] 
2025-01-08 00:52:38.896690: Epoch time: 53.72 s 
2025-01-08 00:52:38.899789: Yayy! New best EMA pseudo Dice: 0.5946000218391418 
2025-01-08 00:52:39.716306:  
2025-01-08 00:52:39.716829: Epoch 21 
2025-01-08 00:52:39.722416: Current learning rate: 0.00962 
2025-01-08 00:53:33.392713: train_loss -0.6055 
2025-01-08 00:53:33.392713: val_loss -0.6397 
2025-01-08 00:53:33.397679: Pseudo dice [np.float32(0.6719)] 
2025-01-08 00:53:33.403530: Epoch time: 53.68 s 
2025-01-08 00:53:33.408550: Yayy! New best EMA pseudo Dice: 0.602400004863739 
2025-01-08 00:53:34.200754:  
2025-01-08 00:53:34.201758: Epoch 22 
2025-01-08 00:53:34.206336: Current learning rate: 0.0096 
2025-01-08 00:54:27.857713: train_loss -0.5975 
2025-01-08 00:54:27.858220: val_loss -0.6592 
2025-01-08 00:54:27.863251: Pseudo dice [np.float32(0.7222)] 
2025-01-08 00:54:27.866768: Epoch time: 53.66 s 
2025-01-08 00:54:27.869744: Yayy! New best EMA pseudo Dice: 0.6144000291824341 
2025-01-08 00:54:28.664586:  
2025-01-08 00:54:28.665589: Epoch 23 
2025-01-08 00:54:28.670144: Current learning rate: 0.00959 
2025-01-08 00:55:22.248409: train_loss -0.5829 
2025-01-08 00:55:22.248919: val_loss -0.6674 
2025-01-08 00:55:22.254540: Pseudo dice [np.float32(0.7509)] 
2025-01-08 00:55:22.258051: Epoch time: 53.58 s 
2025-01-08 00:55:22.261199: Yayy! New best EMA pseudo Dice: 0.628000020980835 
2025-01-08 00:55:23.011062:  
2025-01-08 00:55:23.011564: Epoch 24 
2025-01-08 00:55:23.016575: Current learning rate: 0.00957 
2025-01-08 00:56:16.615206: train_loss -0.5785 
2025-01-08 00:56:16.616709: val_loss -0.6306 
2025-01-08 00:56:16.623233: Pseudo dice [np.float32(0.6951)] 
2025-01-08 00:56:16.626751: Epoch time: 53.61 s 
2025-01-08 00:56:16.629257: Yayy! New best EMA pseudo Dice: 0.6347000002861023 
2025-01-08 00:56:17.427386:  
2025-01-08 00:56:17.427889: Epoch 25 
2025-01-08 00:56:17.432937: Current learning rate: 0.00955 
2025-01-08 00:57:11.080076: train_loss -0.5833 
2025-01-08 00:57:11.081079: val_loss -0.5342 
2025-01-08 00:57:11.086099: Pseudo dice [np.float32(0.5883)] 
2025-01-08 00:57:11.090265: Epoch time: 53.65 s 
2025-01-08 00:57:11.646595:  
2025-01-08 00:57:11.647118: Epoch 26 
2025-01-08 00:57:11.652130: Current learning rate: 0.00953 
2025-01-08 00:58:05.266701: train_loss -0.5448 
2025-01-08 00:58:05.267208: val_loss -0.6635 
2025-01-08 00:58:05.272761: Pseudo dice [np.float32(0.7291)] 
2025-01-08 00:58:05.275190: Epoch time: 53.62 s 
2025-01-08 00:58:05.279205: Yayy! New best EMA pseudo Dice: 0.6399999856948853 
2025-01-08 00:58:06.112358:  
2025-01-08 00:58:06.112358: Epoch 27 
2025-01-08 00:58:06.117987: Current learning rate: 0.00951 
2025-01-08 00:58:59.822417: train_loss -0.5702 
2025-01-08 00:58:59.822417: val_loss -0.4885 
2025-01-08 00:58:59.828547: Pseudo dice [np.float32(0.4692)] 
2025-01-08 00:58:59.832556: Epoch time: 53.71 s 
2025-01-08 00:59:00.542093:  
2025-01-08 00:59:00.543093: Epoch 28 
2025-01-08 00:59:00.549154: Current learning rate: 0.00949 
2025-01-08 00:59:54.113424: train_loss -0.5459 
2025-01-08 00:59:54.113424: val_loss -0.6658 
2025-01-08 00:59:54.119476: Pseudo dice [np.float32(0.7426)] 
2025-01-08 00:59:54.122511: Epoch time: 53.57 s 
2025-01-08 00:59:54.681104:  
2025-01-08 00:59:54.682104: Epoch 29 
2025-01-08 00:59:54.687182: Current learning rate: 0.00948 
2025-01-08 01:00:48.302221: train_loss -0.5772 
2025-01-08 01:00:48.302221: val_loss -0.6077 
2025-01-08 01:00:48.307828: Pseudo dice [np.float32(0.6464)] 
2025-01-08 01:00:48.310365: Epoch time: 53.62 s 
2025-01-08 01:00:48.880297:  
2025-01-08 01:00:48.881297: Epoch 30 
2025-01-08 01:00:48.886898: Current learning rate: 0.00946 
2025-01-08 01:01:42.422327: train_loss -0.627 
2025-01-08 01:01:42.422327: val_loss -0.649 
2025-01-08 01:01:42.427897: Pseudo dice [np.float32(0.7254)] 
2025-01-08 01:01:42.430933: Epoch time: 53.54 s 
2025-01-08 01:01:42.434943: Yayy! New best EMA pseudo Dice: 0.6449999809265137 
2025-01-08 01:01:43.207745:  
2025-01-08 01:01:43.207745: Epoch 31 
2025-01-08 01:01:43.212763: Current learning rate: 0.00944 
2025-01-08 01:02:36.827911: train_loss -0.5657 
2025-01-08 01:02:36.828422: val_loss -0.6289 
2025-01-08 01:02:36.834058: Pseudo dice [np.float32(0.6826)] 
2025-01-08 01:02:36.838132: Epoch time: 53.62 s 
2025-01-08 01:02:36.841166: Yayy! New best EMA pseudo Dice: 0.6486999988555908 
2025-01-08 01:02:37.636873:  
2025-01-08 01:02:37.638376: Epoch 32 
2025-01-08 01:02:37.643402: Current learning rate: 0.00942 
2025-01-08 01:03:31.148672: train_loss -0.5904 
2025-01-08 01:03:31.149676: val_loss -0.6392 
2025-01-08 01:03:31.154687: Pseudo dice [np.float32(0.723)] 
2025-01-08 01:03:31.158695: Epoch time: 53.51 s 
2025-01-08 01:03:31.162203: Yayy! New best EMA pseudo Dice: 0.6561999917030334 
2025-01-08 01:03:31.973464:  
2025-01-08 01:03:31.973967: Epoch 33 
2025-01-08 01:03:31.978977: Current learning rate: 0.0094 
2025-01-08 01:04:25.525182: train_loss -0.6434 
2025-01-08 01:04:25.525692: val_loss -0.6693 
2025-01-08 01:04:25.531231: Pseudo dice [np.float32(0.7235)] 
2025-01-08 01:04:25.535240: Epoch time: 53.55 s 
2025-01-08 01:04:25.538750: Yayy! New best EMA pseudo Dice: 0.6628999710083008 
2025-01-08 01:04:26.309877:  
2025-01-08 01:04:26.310380: Epoch 34 
2025-01-08 01:04:26.315422: Current learning rate: 0.00939 
2025-01-08 01:05:19.886900: train_loss -0.6397 
2025-01-08 01:05:19.886900: val_loss -0.5533 
2025-01-08 01:05:19.892918: Pseudo dice [np.float32(0.6334)] 
2025-01-08 01:05:19.896426: Epoch time: 53.58 s 
2025-01-08 01:05:20.622811:  
2025-01-08 01:05:20.622811: Epoch 35 
2025-01-08 01:05:20.628857: Current learning rate: 0.00937 
2025-01-08 01:06:14.198873: train_loss -0.595 
2025-01-08 01:06:14.200376: val_loss -0.6432 
2025-01-08 01:06:14.205423: Pseudo dice [np.float32(0.7313)] 
2025-01-08 01:06:14.208967: Epoch time: 53.58 s 
2025-01-08 01:06:14.212472: Yayy! New best EMA pseudo Dice: 0.6671000123023987 
2025-01-08 01:06:15.043019:  
2025-01-08 01:06:15.044022: Epoch 36 
2025-01-08 01:06:15.048606: Current learning rate: 0.00935 
2025-01-08 01:07:08.651616: train_loss -0.5646 
2025-01-08 01:07:08.651616: val_loss -0.644 
2025-01-08 01:07:08.657202: Pseudo dice [np.float32(0.6884)] 
2025-01-08 01:07:08.659723: Epoch time: 53.61 s 
2025-01-08 01:07:08.663543: Yayy! New best EMA pseudo Dice: 0.6692000031471252 
2025-01-08 01:07:09.447874:  
2025-01-08 01:07:09.447874: Epoch 37 
2025-01-08 01:07:09.453017: Current learning rate: 0.00933 
2025-01-08 01:08:03.088570: train_loss -0.6221 
2025-01-08 01:08:03.089086: val_loss -0.7276 
2025-01-08 01:08:03.093657: Pseudo dice [np.float32(0.7641)] 
2025-01-08 01:08:03.097709: Epoch time: 53.64 s 
2025-01-08 01:08:03.100760: Yayy! New best EMA pseudo Dice: 0.6786999702453613 
2025-01-08 01:08:03.891027:  
2025-01-08 01:08:03.891027: Epoch 38 
2025-01-08 01:08:03.897046: Current learning rate: 0.00931 
2025-01-08 01:08:57.512794: train_loss -0.643 
2025-01-08 01:08:57.512794: val_loss -0.7404 
2025-01-08 01:08:57.520488: Pseudo dice [np.float32(0.7915)] 
2025-01-08 01:08:57.524044: Epoch time: 53.62 s 
2025-01-08 01:08:57.526612: Yayy! New best EMA pseudo Dice: 0.6899999976158142 
2025-01-08 01:08:58.308591:  
2025-01-08 01:08:58.308591: Epoch 39 
2025-01-08 01:08:58.314652: Current learning rate: 0.0093 
2025-01-08 01:09:51.952269: train_loss -0.664 
2025-01-08 01:09:51.952779: val_loss -0.6446 
2025-01-08 01:09:51.958918: Pseudo dice [np.float32(0.7397)] 
2025-01-08 01:09:51.963046: Epoch time: 53.64 s 
2025-01-08 01:09:51.966086: Yayy! New best EMA pseudo Dice: 0.6949999928474426 
2025-01-08 01:09:52.764634:  
2025-01-08 01:09:52.764634: Epoch 40 
2025-01-08 01:09:52.770361: Current learning rate: 0.00928 
2025-01-08 01:10:46.440895: train_loss -0.6326 
2025-01-08 01:10:46.441399: val_loss -0.6971 
2025-01-08 01:10:46.446974: Pseudo dice [np.float32(0.7668)] 
2025-01-08 01:10:46.449982: Epoch time: 53.68 s 
2025-01-08 01:10:46.453491: Yayy! New best EMA pseudo Dice: 0.7020999789237976 
2025-01-08 01:10:47.290559:  
2025-01-08 01:10:47.291563: Epoch 41 
2025-01-08 01:10:47.296985: Current learning rate: 0.00926 
2025-01-08 01:11:40.906115: train_loss -0.6425 
2025-01-08 01:11:40.907121: val_loss -0.6709 
2025-01-08 01:11:40.913383: Pseudo dice [np.float32(0.7637)] 
2025-01-08 01:11:40.916933: Epoch time: 53.62 s 
2025-01-08 01:11:40.919969: Yayy! New best EMA pseudo Dice: 0.708299994468689 
2025-01-08 01:11:41.724996:  
2025-01-08 01:11:41.725499: Epoch 42 
2025-01-08 01:11:41.730511: Current learning rate: 0.00924 
2025-01-08 01:12:35.425945: train_loss -0.6523 
2025-01-08 01:12:35.425945: val_loss -0.6751 
2025-01-08 01:12:35.430956: Pseudo dice [np.float32(0.7653)] 
2025-01-08 01:12:35.434476: Epoch time: 53.7 s 
2025-01-08 01:12:35.437494: Yayy! New best EMA pseudo Dice: 0.7139999866485596 
2025-01-08 01:12:36.432819:  
2025-01-08 01:12:36.432819: Epoch 43 
2025-01-08 01:12:36.439380: Current learning rate: 0.00922 
2025-01-08 01:13:30.094421: train_loss -0.6714 
2025-01-08 01:13:30.094945: val_loss -0.7412 
2025-01-08 01:13:30.100024: Pseudo dice [np.float32(0.7945)] 
2025-01-08 01:13:30.103062: Epoch time: 53.66 s 
2025-01-08 01:13:30.106101: Yayy! New best EMA pseudo Dice: 0.722000002861023 
2025-01-08 01:13:30.916584:  
2025-01-08 01:13:30.916584: Epoch 44 
2025-01-08 01:13:30.922141: Current learning rate: 0.0092 
2025-01-08 01:14:24.517540: train_loss -0.6765 
2025-01-08 01:14:24.519048: val_loss -0.6346 
2025-01-08 01:14:24.524653: Pseudo dice [np.float32(0.7954)] 
2025-01-08 01:14:24.527240: Epoch time: 53.6 s 
2025-01-08 01:14:24.530652: Yayy! New best EMA pseudo Dice: 0.7293999791145325 
2025-01-08 01:14:25.302828:  
2025-01-08 01:14:25.302828: Epoch 45 
2025-01-08 01:14:25.308501: Current learning rate: 0.00919 
2025-01-08 01:15:18.867983: train_loss -0.6246 
2025-01-08 01:15:18.867983: val_loss -0.6281 
2025-01-08 01:15:18.873994: Pseudo dice [np.float32(0.6929)] 
2025-01-08 01:15:18.877049: Epoch time: 53.57 s 
2025-01-08 01:15:19.432522:  
2025-01-08 01:15:19.433525: Epoch 46 
2025-01-08 01:15:19.439158: Current learning rate: 0.00917 
2025-01-08 01:16:12.987440: train_loss -0.5986 
2025-01-08 01:16:12.987942: val_loss -0.6403 
2025-01-08 01:16:12.993535: Pseudo dice [np.float32(0.7005)] 
2025-01-08 01:16:12.996084: Epoch time: 53.55 s 
2025-01-08 01:16:13.546629:  
2025-01-08 01:16:13.547131: Epoch 47 
2025-01-08 01:16:13.552175: Current learning rate: 0.00915 
2025-01-08 01:17:07.093992: train_loss -0.6139 
2025-01-08 01:17:07.095513: val_loss -0.651 
2025-01-08 01:17:07.101714: Pseudo dice [np.float32(0.688)] 
2025-01-08 01:17:07.106287: Epoch time: 53.55 s 
2025-01-08 01:17:07.668993:  
2025-01-08 01:17:07.668993: Epoch 48 
2025-01-08 01:17:07.674047: Current learning rate: 0.00913 
2025-01-08 01:18:01.227722: train_loss -0.6109 
2025-01-08 01:18:01.228725: val_loss -0.4571 
2025-01-08 01:18:01.234386: Pseudo dice [np.float32(0.3885)] 
2025-01-08 01:18:01.237405: Epoch time: 53.56 s 
2025-01-08 01:18:01.792446:  
2025-01-08 01:18:01.793449: Epoch 49 
2025-01-08 01:18:01.798027: Current learning rate: 0.00911 
2025-01-08 01:18:55.209161: train_loss -0.5799 
2025-01-08 01:18:55.209161: val_loss -0.6085 
2025-01-08 01:18:55.215235: Pseudo dice [np.float32(0.638)] 
2025-01-08 01:18:55.217741: Epoch time: 53.42 s 
2025-01-08 01:18:56.003044:  
2025-01-08 01:18:56.003547: Epoch 50 
2025-01-08 01:18:56.008559: Current learning rate: 0.0091 
2025-01-08 01:19:49.621383: train_loss -0.6118 
2025-01-08 01:19:49.621383: val_loss -0.6771 
2025-01-08 01:19:49.628951: Pseudo dice [np.float32(0.7523)] 
2025-01-08 01:19:49.631457: Epoch time: 53.62 s 
2025-01-08 01:19:50.340248:  
2025-01-08 01:19:50.340750: Epoch 51 
2025-01-08 01:19:50.345761: Current learning rate: 0.00908 
2025-01-08 01:20:43.898032: train_loss -0.6549 
2025-01-08 01:20:43.898542: val_loss -0.661 
2025-01-08 01:20:43.904160: Pseudo dice [np.float32(0.7399)] 
2025-01-08 01:20:43.907671: Epoch time: 53.56 s 
2025-01-08 01:20:44.463941:  
2025-01-08 01:20:44.464444: Epoch 52 
2025-01-08 01:20:44.469454: Current learning rate: 0.00906 
2025-01-08 01:21:38.038952: train_loss -0.6555 
2025-01-08 01:21:38.038952: val_loss -0.6948 
2025-01-08 01:21:38.044971: Pseudo dice [np.float32(0.7814)] 
2025-01-08 01:21:38.048475: Epoch time: 53.58 s 
2025-01-08 01:21:38.611269:  
2025-01-08 01:21:38.612789: Epoch 53 
2025-01-08 01:21:38.616080: Current learning rate: 0.00904 
2025-01-08 01:22:32.244683: train_loss -0.6191 
2025-01-08 01:22:32.245686: val_loss -0.6955 
2025-01-08 01:22:32.250708: Pseudo dice [np.float32(0.7523)] 
2025-01-08 01:22:32.253181: Epoch time: 53.63 s 
2025-01-08 01:22:32.818557:  
2025-01-08 01:22:32.820076: Epoch 54 
2025-01-08 01:22:32.825137: Current learning rate: 0.00902 
2025-01-08 01:23:26.528683: train_loss -0.6516 
2025-01-08 01:23:26.530198: val_loss -0.6589 
2025-01-08 01:23:26.535318: Pseudo dice [np.float32(0.6833)] 
2025-01-08 01:23:26.538366: Epoch time: 53.71 s 
2025-01-08 01:23:27.097151:  
2025-01-08 01:23:27.097151: Epoch 55 
2025-01-08 01:23:27.102700: Current learning rate: 0.009 
2025-01-08 01:24:20.783654: train_loss -0.6658 
2025-01-08 01:24:20.784157: val_loss -0.7475 
2025-01-08 01:24:20.789288: Pseudo dice [np.float32(0.8028)] 
2025-01-08 01:24:20.792336: Epoch time: 53.69 s 
2025-01-08 01:24:21.359119:  
2025-01-08 01:24:21.359119: Epoch 56 
2025-01-08 01:24:21.364634: Current learning rate: 0.00899 
2025-01-08 01:25:15.039884: train_loss -0.6649 
2025-01-08 01:25:15.039884: val_loss -0.722 
2025-01-08 01:25:15.046423: Pseudo dice [np.float32(0.809)] 
2025-01-08 01:25:15.049456: Epoch time: 53.68 s 
2025-01-08 01:25:15.605797:  
2025-01-08 01:25:15.605797: Epoch 57 
2025-01-08 01:25:15.611851: Current learning rate: 0.00897 
2025-01-08 01:26:09.328478: train_loss -0.6524 
2025-01-08 01:26:09.329478: val_loss -0.6735 
2025-01-08 01:26:09.335031: Pseudo dice [np.float32(0.7553)] 
2025-01-08 01:26:09.337573: Epoch time: 53.72 s 
2025-01-08 01:26:09.896345:  
2025-01-08 01:26:09.896345: Epoch 58 
2025-01-08 01:26:09.901881: Current learning rate: 0.00895 
2025-01-08 01:27:03.597054: train_loss -0.6779 
2025-01-08 01:27:03.597054: val_loss -0.7174 
2025-01-08 01:27:03.603568: Pseudo dice [np.float32(0.7607)] 
2025-01-08 01:27:03.606073: Epoch time: 53.7 s 
2025-01-08 01:27:03.609582: Yayy! New best EMA pseudo Dice: 0.7307999730110168 
2025-01-08 01:27:04.559834:  
2025-01-08 01:27:04.560835: Epoch 59 
2025-01-08 01:27:04.565922: Current learning rate: 0.00893 
2025-01-08 01:27:58.246179: train_loss -0.6904 
2025-01-08 01:27:58.246179: val_loss -0.7307 
2025-01-08 01:27:58.252723: Pseudo dice [np.float32(0.7671)] 
2025-01-08 01:27:58.256260: Epoch time: 53.69 s 
2025-01-08 01:27:58.259287: Yayy! New best EMA pseudo Dice: 0.7343999743461609 
2025-01-08 01:27:59.027480:  
2025-01-08 01:27:59.027987: Epoch 60 
2025-01-08 01:27:59.033070: Current learning rate: 0.00891 
2025-01-08 01:28:52.716790: train_loss -0.6494 
2025-01-08 01:28:52.717293: val_loss -0.6523 
2025-01-08 01:28:52.722347: Pseudo dice [np.float32(0.7178)] 
2025-01-08 01:28:52.725464: Epoch time: 53.69 s 
2025-01-08 01:28:53.295043:  
2025-01-08 01:28:53.295043: Epoch 61 
2025-01-08 01:28:53.300594: Current learning rate: 0.00889 
2025-01-08 01:29:47.009879: train_loss -0.6007 
2025-01-08 01:29:47.010881: val_loss -0.6447 
2025-01-08 01:29:47.015898: Pseudo dice [np.float32(0.7339)] 
2025-01-08 01:29:47.018468: Epoch time: 53.72 s 
2025-01-08 01:29:47.587173:  
2025-01-08 01:29:47.587173: Epoch 62 
2025-01-08 01:29:47.592186: Current learning rate: 0.00888 
2025-01-08 01:30:41.273899: train_loss -0.6687 
2025-01-08 01:30:41.273899: val_loss -0.7013 
2025-01-08 01:30:41.279915: Pseudo dice [np.float32(0.7258)] 
2025-01-08 01:30:41.282420: Epoch time: 53.69 s 
2025-01-08 01:30:41.851348:  
2025-01-08 01:30:41.851348: Epoch 63 
2025-01-08 01:30:41.856905: Current learning rate: 0.00886 
2025-01-08 01:31:35.582535: train_loss -0.6152 
2025-01-08 01:31:35.583540: val_loss -0.6571 
2025-01-08 01:31:35.590064: Pseudo dice [np.float32(0.7287)] 
2025-01-08 01:31:35.597118: Epoch time: 53.73 s 
2025-01-08 01:31:36.274851:  
2025-01-08 01:31:36.275354: Epoch 64 
2025-01-08 01:31:36.280971: Current learning rate: 0.00884 
2025-01-08 01:32:30.040664: train_loss -0.6438 
2025-01-08 01:32:30.041673: val_loss -0.6579 
2025-01-08 01:32:30.046745: Pseudo dice [np.float32(0.7092)] 
2025-01-08 01:32:30.049511: Epoch time: 53.77 s 
2025-01-08 01:32:30.617598:  
2025-01-08 01:32:30.618101: Epoch 65 
2025-01-08 01:32:30.623141: Current learning rate: 0.00882 
2025-01-08 01:33:24.395850: train_loss -0.6576 
2025-01-08 01:33:24.396353: val_loss -0.7349 
2025-01-08 01:33:24.401946: Pseudo dice [np.float32(0.7818)] 
2025-01-08 01:33:24.404452: Epoch time: 53.78 s 
2025-01-08 01:33:24.406957: Yayy! New best EMA pseudo Dice: 0.7347999811172485 
2025-01-08 01:33:25.193150:  
2025-01-08 01:33:25.193676: Epoch 66 
2025-01-08 01:33:25.198687: Current learning rate: 0.0088 
2025-01-08 01:34:18.880878: train_loss -0.6188 
2025-01-08 01:34:18.881381: val_loss -0.6032 
2025-01-08 01:34:18.886393: Pseudo dice [np.float32(0.6647)] 
2025-01-08 01:34:18.889901: Epoch time: 53.69 s 
2025-01-08 01:34:19.616508:  
2025-01-08 01:34:19.616508: Epoch 67 
2025-01-08 01:34:19.621522: Current learning rate: 0.00879 
2025-01-08 01:35:13.456060: train_loss -0.6252 
2025-01-08 01:35:13.457064: val_loss -0.676 
2025-01-08 01:35:13.462276: Pseudo dice [np.float32(0.7398)] 
2025-01-08 01:35:13.466285: Epoch time: 53.84 s 
2025-01-08 01:35:14.041648:  
2025-01-08 01:35:14.041648: Epoch 68 
2025-01-08 01:35:14.048210: Current learning rate: 0.00877 
2025-01-08 01:36:03.474692: train_loss -0.6497 
2025-01-08 01:36:03.476202: val_loss -0.6787 
2025-01-08 01:36:03.481380: Pseudo dice [np.float32(0.7617)] 
2025-01-08 01:36:03.484429: Epoch time: 49.43 s 
2025-01-08 01:36:04.088212:  
2025-01-08 01:36:04.089212: Epoch 69 
2025-01-08 01:36:04.094289: Current learning rate: 0.00875 
2025-01-08 01:36:49.203254: train_loss -0.6786 
2025-01-08 01:36:49.204253: val_loss -0.6542 
2025-01-08 01:36:49.209769: Pseudo dice [np.float32(0.7355)] 
2025-01-08 01:36:49.213277: Epoch time: 45.12 s 
2025-01-08 01:36:49.795872:  
2025-01-08 01:36:49.796875: Epoch 70 
2025-01-08 01:36:49.803432: Current learning rate: 0.00873 
2025-01-08 01:37:34.899961: train_loss -0.6449 
2025-01-08 01:37:34.900474: val_loss -0.7061 
2025-01-08 01:37:34.905539: Pseudo dice [np.float32(0.7603)] 
2025-01-08 01:37:34.909573: Epoch time: 45.1 s 
2025-01-08 01:37:34.912666: Yayy! New best EMA pseudo Dice: 0.7353000044822693 
2025-01-08 01:37:35.653459:  
2025-01-08 01:37:35.653459: Epoch 71 
2025-01-08 01:37:35.659030: Current learning rate: 0.00871 
2025-01-08 01:38:20.317638: train_loss -0.6736 
2025-01-08 01:38:20.318144: val_loss -0.607 
2025-01-08 01:38:20.324179: Pseudo dice [np.float32(0.716)] 
2025-01-08 01:38:20.326697: Epoch time: 44.66 s 
2025-01-08 01:38:20.911370:  
2025-01-08 01:38:20.911370: Epoch 72 
2025-01-08 01:38:20.916955: Current learning rate: 0.00869 
2025-01-08 01:39:05.565383: train_loss -0.6825 
2025-01-08 01:39:05.566386: val_loss -0.5914 
2025-01-08 01:39:05.571398: Pseudo dice [np.float32(0.6207)] 
2025-01-08 01:39:05.575920: Epoch time: 44.66 s 
2025-01-08 01:39:06.167354:  
2025-01-08 01:39:06.168354: Epoch 73 
2025-01-08 01:39:06.172915: Current learning rate: 0.00868 
2025-01-08 01:39:50.755742: train_loss -0.699 
2025-01-08 01:39:50.756742: val_loss -0.627 
2025-01-08 01:39:50.762255: Pseudo dice [np.float32(0.7094)] 
2025-01-08 01:39:50.765781: Epoch time: 44.59 s 
2025-01-08 01:39:51.345968:  
2025-01-08 01:39:51.347487: Epoch 74 
2025-01-08 01:39:51.351050: Current learning rate: 0.00866 
2025-01-08 01:40:35.912874: train_loss -0.6517 
2025-01-08 01:40:35.913873: val_loss -0.6919 
2025-01-08 01:40:35.919387: Pseudo dice [np.float32(0.7409)] 
2025-01-08 01:40:35.922896: Epoch time: 44.57 s 
2025-01-08 01:40:36.658315:  
2025-01-08 01:40:36.659318: Epoch 75 
2025-01-08 01:40:36.662832: Current learning rate: 0.00864 
2025-01-08 01:41:21.194663: train_loss -0.6541 
2025-01-08 01:41:21.194663: val_loss -0.7549 
2025-01-08 01:41:21.200674: Pseudo dice [np.float32(0.81)] 
2025-01-08 01:41:21.203682: Epoch time: 44.54 s 
2025-01-08 01:41:21.787759:  
2025-01-08 01:41:21.788762: Epoch 76 
2025-01-08 01:41:21.793784: Current learning rate: 0.00862 
2025-01-08 01:42:06.337703: train_loss -0.684 
2025-01-08 01:42:06.337703: val_loss -0.6731 
2025-01-08 01:42:06.343750: Pseudo dice [np.float32(0.7204)] 
2025-01-08 01:42:06.347283: Epoch time: 44.55 s 
2025-01-08 01:42:06.925164:  
2025-01-08 01:42:06.925666: Epoch 77 
2025-01-08 01:42:06.930677: Current learning rate: 0.0086 
2025-01-08 01:42:51.428827: train_loss -0.6934 
2025-01-08 01:42:51.429827: val_loss -0.6778 
2025-01-08 01:42:51.436347: Pseudo dice [np.float32(0.7082)] 
2025-01-08 01:42:51.440355: Epoch time: 44.5 s 
2025-01-08 01:42:52.031032:  
2025-01-08 01:42:52.031032: Epoch 78 
2025-01-08 01:42:52.036043: Current learning rate: 0.00858 
2025-01-08 01:43:36.637119: train_loss -0.6811 
2025-01-08 01:43:36.637119: val_loss -0.6325 
2025-01-08 01:43:36.643134: Pseudo dice [np.float32(0.7057)] 
2025-01-08 01:43:36.646640: Epoch time: 44.61 s 
2025-01-08 01:43:37.242981:  
2025-01-08 01:43:37.243985: Epoch 79 
2025-01-08 01:43:37.250092: Current learning rate: 0.00857 
2025-01-08 01:44:21.809083: train_loss -0.6745 
2025-01-08 01:44:21.809585: val_loss -0.4904 
2025-01-08 01:44:21.815181: Pseudo dice [np.float32(0.626)] 
2025-01-08 01:44:21.817719: Epoch time: 44.57 s 
2025-01-08 01:44:22.411450:  
2025-01-08 01:44:22.411960: Epoch 80 
2025-01-08 01:44:22.417000: Current learning rate: 0.00855 
2025-01-08 01:45:06.938440: train_loss -0.6112 
2025-01-08 01:45:06.939439: val_loss -0.6993 
2025-01-08 01:45:06.945008: Pseudo dice [np.float32(0.6944)] 
2025-01-08 01:45:06.948047: Epoch time: 44.53 s 
2025-01-08 01:45:07.535473:  
2025-01-08 01:45:07.536473: Epoch 81 
2025-01-08 01:45:07.542094: Current learning rate: 0.00853 
2025-01-08 01:45:52.111058: train_loss -0.6669 
2025-01-08 01:45:52.111561: val_loss -0.6724 
2025-01-08 01:45:52.116603: Pseudo dice [np.float32(0.6947)] 
2025-01-08 01:45:52.119629: Epoch time: 44.58 s 
2025-01-08 01:45:52.857774:  
2025-01-08 01:45:52.858778: Epoch 82 
2025-01-08 01:45:52.863828: Current learning rate: 0.00851 
2025-01-08 01:46:37.445940: train_loss -0.6425 
2025-01-08 01:46:37.447448: val_loss -0.6441 
2025-01-08 01:46:37.452470: Pseudo dice [np.float32(0.6684)] 
2025-01-08 01:46:37.455982: Epoch time: 44.59 s 
2025-01-08 01:46:38.018836:  
2025-01-08 01:46:38.019338: Epoch 83 
2025-01-08 01:46:38.024381: Current learning rate: 0.00849 
2025-01-08 01:47:22.587425: train_loss -0.625 
2025-01-08 01:47:22.587425: val_loss -0.6228 
2025-01-08 01:47:22.593971: Pseudo dice [np.float32(0.7031)] 
2025-01-08 01:47:22.597001: Epoch time: 44.57 s 
2025-01-08 01:47:23.162524:  
2025-01-08 01:47:23.162524: Epoch 84 
2025-01-08 01:47:23.168074: Current learning rate: 0.00847 
2025-01-08 01:48:07.689329: train_loss -0.6911 
2025-01-08 01:48:07.689833: val_loss -0.6931 
2025-01-08 01:48:07.695848: Pseudo dice [np.float32(0.7278)] 
2025-01-08 01:48:07.698354: Epoch time: 44.53 s 
2025-01-08 01:48:08.266887:  
2025-01-08 01:48:08.267404: Epoch 85 
2025-01-08 01:48:08.271950: Current learning rate: 0.00846 
2025-01-08 01:48:52.831560: train_loss -0.6723 
2025-01-08 01:48:52.832559: val_loss -0.6396 
2025-01-08 01:48:52.838587: Pseudo dice [np.float32(0.7242)] 
2025-01-08 01:48:52.843126: Epoch time: 44.57 s 
2025-01-08 01:48:53.405302:  
2025-01-08 01:48:53.405302: Epoch 86 
2025-01-08 01:48:53.410868: Current learning rate: 0.00844 
2025-01-08 01:49:37.955931: train_loss -0.6647 
2025-01-08 01:49:37.956931: val_loss -0.6857 
2025-01-08 01:49:37.962447: Pseudo dice [np.float32(0.736)] 
2025-01-08 01:49:37.965957: Epoch time: 44.55 s 
2025-01-08 01:49:38.528457:  
2025-01-08 01:49:38.529457: Epoch 87 
2025-01-08 01:49:38.535136: Current learning rate: 0.00842 
2025-01-08 01:50:23.121574: train_loss -0.6645 
2025-01-08 01:50:23.121574: val_loss -0.6954 
2025-01-08 01:50:23.126585: Pseudo dice [np.float32(0.7338)] 
2025-01-08 01:50:23.130097: Epoch time: 44.59 s 
2025-01-08 01:50:23.689546:  
2025-01-08 01:50:23.689546: Epoch 88 
2025-01-08 01:50:23.695100: Current learning rate: 0.0084 
2025-01-08 01:51:08.388911: train_loss -0.6713 
2025-01-08 01:51:08.389914: val_loss -0.6117 
2025-01-08 01:51:08.394973: Pseudo dice [np.float32(0.7261)] 
2025-01-08 01:51:08.398478: Epoch time: 44.7 s 
2025-01-08 01:51:08.956973:  
2025-01-08 01:51:08.956973: Epoch 89 
2025-01-08 01:51:08.962527: Current learning rate: 0.00838 
2025-01-08 01:51:53.546650: train_loss -0.6954 
2025-01-08 01:51:53.546650: val_loss -0.6538 
2025-01-08 01:51:53.552712: Pseudo dice [np.float32(0.623)] 
2025-01-08 01:51:53.555802: Epoch time: 44.59 s 
2025-01-08 01:51:54.270894:  
2025-01-08 01:51:54.271405: Epoch 90 
2025-01-08 01:51:54.276445: Current learning rate: 0.00836 
2025-01-08 01:52:38.869545: train_loss -0.6525 
2025-01-08 01:52:38.870056: val_loss -0.745 
2025-01-08 01:52:38.876117: Pseudo dice [np.float32(0.8059)] 
2025-01-08 01:52:38.878634: Epoch time: 44.6 s 
2025-01-08 01:52:39.441392:  
2025-01-08 01:52:39.441895: Epoch 91 
2025-01-08 01:52:39.446916: Current learning rate: 0.00835 
2025-01-08 01:53:24.003946: train_loss -0.681 
2025-01-08 01:53:24.004456: val_loss -0.743 
2025-01-08 01:53:24.010497: Pseudo dice [np.float32(0.8114)] 
2025-01-08 01:53:24.014031: Epoch time: 44.56 s 
2025-01-08 01:53:24.572907:  
2025-01-08 01:53:24.572907: Epoch 92 
2025-01-08 01:53:24.578441: Current learning rate: 0.00833 
2025-01-08 01:54:09.137292: train_loss -0.6992 
2025-01-08 01:54:09.138304: val_loss -0.6627 
2025-01-08 01:54:09.144343: Pseudo dice [np.float32(0.7333)] 
2025-01-08 01:54:09.149924: Epoch time: 44.57 s 
2025-01-08 01:54:09.709787:  
2025-01-08 01:54:09.710790: Epoch 93 
2025-01-08 01:54:09.714318: Current learning rate: 0.00831 
2025-01-08 01:54:54.219239: train_loss -0.708 
2025-01-08 01:54:54.220748: val_loss -0.6394 
2025-01-08 01:54:54.226894: Pseudo dice [np.float32(0.7112)] 
2025-01-08 01:54:54.230426: Epoch time: 44.51 s 
2025-01-08 01:54:54.795454:  
2025-01-08 01:54:54.795454: Epoch 94 
2025-01-08 01:54:54.801491: Current learning rate: 0.00829 
2025-01-08 01:55:39.225349: train_loss -0.6998 
2025-01-08 01:55:39.225349: val_loss -0.7381 
2025-01-08 01:55:39.230861: Pseudo dice [np.float32(0.7946)] 
2025-01-08 01:55:39.234386: Epoch time: 44.43 s 
2025-01-08 01:55:39.794450:  
2025-01-08 01:55:39.794450: Epoch 95 
2025-01-08 01:55:39.801092: Current learning rate: 0.00827 
2025-01-08 01:56:23.186771: train_loss -0.6878 
2025-01-08 01:56:23.187774: val_loss -0.7119 
2025-01-08 01:56:23.192785: Pseudo dice [np.float32(0.779)] 
2025-01-08 01:56:23.196793: Epoch time: 43.39 s 
2025-01-08 01:56:23.199298: Yayy! New best EMA pseudo Dice: 0.7369999885559082 
2025-01-08 01:56:24.028279:  
2025-01-08 01:56:24.028279: Epoch 96 
2025-01-08 01:56:24.034339: Current learning rate: 0.00825 
2025-01-08 01:57:07.453332: train_loss -0.6946 
2025-01-08 01:57:07.453834: val_loss -0.6798 
2025-01-08 01:57:07.458844: Pseudo dice [np.float32(0.7556)] 
2025-01-08 01:57:07.462353: Epoch time: 43.43 s 
2025-01-08 01:57:07.465859: Yayy! New best EMA pseudo Dice: 0.7389000058174133 
2025-01-08 01:57:08.271349:  
2025-01-08 01:57:08.272349: Epoch 97 
2025-01-08 01:57:08.277427: Current learning rate: 0.00824 
2025-01-08 01:57:51.672975: train_loss -0.7105 
2025-01-08 01:57:51.673477: val_loss -0.6876 
2025-01-08 01:57:51.678487: Pseudo dice [np.float32(0.7083)] 
2025-01-08 01:57:51.681996: Epoch time: 43.4 s 
2025-01-08 01:57:52.251366:  
2025-01-08 01:57:52.251366: Epoch 98 
2025-01-08 01:57:52.257434: Current learning rate: 0.00822 
2025-01-08 01:58:35.675723: train_loss -0.7174 
2025-01-08 01:58:35.677230: val_loss -0.6661 
2025-01-08 01:58:35.682788: Pseudo dice [np.float32(0.7461)] 
2025-01-08 01:58:35.686298: Epoch time: 43.42 s 
2025-01-08 01:58:36.474810:  
2025-01-08 01:58:36.475314: Epoch 99 
2025-01-08 01:58:36.479825: Current learning rate: 0.0082 
2025-01-08 01:59:19.888621: train_loss -0.6969 
2025-01-08 01:59:19.889621: val_loss -0.5526 
2025-01-08 01:59:19.895135: Pseudo dice [np.float32(0.6781)] 
2025-01-08 01:59:19.898157: Epoch time: 43.41 s 
2025-01-08 01:59:20.715683:  
2025-01-08 01:59:20.716687: Epoch 100 
2025-01-08 01:59:20.721251: Current learning rate: 0.00818 
2025-01-08 02:00:04.113487: train_loss -0.6504 
2025-01-08 02:00:04.113487: val_loss -0.7041 
2025-01-08 02:00:04.120003: Pseudo dice [np.float32(0.7692)] 
2025-01-08 02:00:04.123513: Epoch time: 43.4 s 
2025-01-08 02:00:04.693260:  
2025-01-08 02:00:04.693260: Epoch 101 
2025-01-08 02:00:04.698804: Current learning rate: 0.00816 
2025-01-08 02:00:48.089127: train_loss -0.6977 
2025-01-08 02:00:48.089629: val_loss -0.6491 
2025-01-08 02:00:48.095228: Pseudo dice [np.float32(0.725)] 
2025-01-08 02:00:48.098287: Epoch time: 43.4 s 
2025-01-08 02:00:48.667058:  
2025-01-08 02:00:48.667058: Epoch 102 
2025-01-08 02:00:48.673093: Current learning rate: 0.00814 
2025-01-08 02:01:32.054697: train_loss -0.7082 
2025-01-08 02:01:32.055700: val_loss -0.6715 
2025-01-08 02:01:32.061300: Pseudo dice [np.float32(0.7299)] 
2025-01-08 02:01:32.064842: Epoch time: 43.39 s 
2025-01-08 02:01:32.628751:  
2025-01-08 02:01:32.628751: Epoch 103 
2025-01-08 02:01:32.634266: Current learning rate: 0.00813 
2025-01-08 02:02:16.040910: train_loss -0.66 
2025-01-08 02:02:16.042412: val_loss -0.6456 
2025-01-08 02:02:16.048427: Pseudo dice [np.float32(0.746)] 
2025-01-08 02:02:16.050932: Epoch time: 43.41 s 
2025-01-08 02:02:16.616575:  
2025-01-08 02:02:16.616575: Epoch 104 
2025-01-08 02:02:16.622111: Current learning rate: 0.00811 
2025-01-08 02:03:00.040215: train_loss -0.6797 
2025-01-08 02:03:00.040724: val_loss -0.7043 
2025-01-08 02:03:00.045766: Pseudo dice [np.float32(0.7763)] 
2025-01-08 02:03:00.050291: Epoch time: 43.42 s 
2025-01-08 02:03:00.618853:  
2025-01-08 02:03:00.618853: Epoch 105 
2025-01-08 02:03:00.624391: Current learning rate: 0.00809 
2025-01-08 02:03:44.069278: train_loss -0.6908 
2025-01-08 02:03:44.070789: val_loss -0.7008 
2025-01-08 02:03:44.076363: Pseudo dice [np.float32(0.7312)] 
2025-01-08 02:03:44.079901: Epoch time: 43.45 s 
2025-01-08 02:03:44.801349:  
2025-01-08 02:03:44.801349: Epoch 106 
2025-01-08 02:03:44.806898: Current learning rate: 0.00807 
2025-01-08 02:04:28.167689: train_loss -0.6966 
2025-01-08 02:04:28.168695: val_loss -0.7006 
2025-01-08 02:04:28.174704: Pseudo dice [np.float32(0.7724)] 
2025-01-08 02:04:28.177711: Epoch time: 43.37 s 
2025-01-08 02:04:28.180216: Yayy! New best EMA pseudo Dice: 0.7415000200271606 
2025-01-08 02:04:29.005306:  
2025-01-08 02:04:29.005809: Epoch 107 
2025-01-08 02:04:29.010821: Current learning rate: 0.00805 
2025-01-08 02:05:12.383842: train_loss -0.686 
2025-01-08 02:05:12.384845: val_loss -0.6033 
2025-01-08 02:05:12.389864: Pseudo dice [np.float32(0.7248)] 
2025-01-08 02:05:12.393878: Epoch time: 43.38 s 
2025-01-08 02:05:12.971686:  
2025-01-08 02:05:12.971686: Epoch 108 
2025-01-08 02:05:12.976712: Current learning rate: 0.00803 
2025-01-08 02:05:56.364506: train_loss -0.7137 
2025-01-08 02:05:56.365509: val_loss -0.6185 
2025-01-08 02:05:56.371102: Pseudo dice [np.float32(0.7115)] 
2025-01-08 02:05:56.374642: Epoch time: 43.39 s 
2025-01-08 02:05:56.953385:  
2025-01-08 02:05:56.953385: Epoch 109 
2025-01-08 02:05:56.958929: Current learning rate: 0.00801 
2025-01-08 02:06:40.383344: train_loss -0.671 
2025-01-08 02:06:40.384348: val_loss -0.6422 
2025-01-08 02:06:40.390866: Pseudo dice [np.float32(0.6982)] 
2025-01-08 02:06:40.393372: Epoch time: 43.43 s 
2025-01-08 02:06:40.963045:  
2025-01-08 02:06:40.963045: Epoch 110 
2025-01-08 02:06:40.969610: Current learning rate: 0.008 
2025-01-08 02:07:24.393088: train_loss -0.6545 
2025-01-08 02:07:24.394092: val_loss -0.668 
2025-01-08 02:07:24.400217: Pseudo dice [np.float32(0.6992)] 
2025-01-08 02:07:24.402750: Epoch time: 43.43 s 
2025-01-08 02:07:24.973105:  
2025-01-08 02:07:24.973105: Epoch 111 
2025-01-08 02:07:24.978716: Current learning rate: 0.00798 
2025-01-08 02:08:08.386428: train_loss -0.7235 
2025-01-08 02:08:08.386428: val_loss -0.6341 
2025-01-08 02:08:08.392969: Pseudo dice [np.float32(0.6711)] 
2025-01-08 02:08:08.395504: Epoch time: 43.41 s 
2025-01-08 02:08:08.959233:  
2025-01-08 02:08:08.959737: Epoch 112 
2025-01-08 02:08:08.964751: Current learning rate: 0.00796 
2025-01-08 02:08:52.373968: train_loss -0.6939 
2025-01-08 02:08:52.374971: val_loss -0.6943 
2025-01-08 02:08:52.380490: Pseudo dice [np.float32(0.746)] 
2025-01-08 02:08:52.384000: Epoch time: 43.42 s 
2025-01-08 02:08:52.948184:  
2025-01-08 02:08:52.948184: Epoch 113 
2025-01-08 02:08:52.954242: Current learning rate: 0.00794 
2025-01-08 02:09:36.343621: train_loss -0.7153 
2025-01-08 02:09:36.344134: val_loss -0.7119 
2025-01-08 02:09:36.349839: Pseudo dice [np.float32(0.7918)] 
2025-01-08 02:09:36.353393: Epoch time: 43.4 s 
2025-01-08 02:09:36.921117:  
2025-01-08 02:09:36.922116: Epoch 114 
2025-01-08 02:09:36.926719: Current learning rate: 0.00792 
2025-01-08 02:10:20.359840: train_loss -0.7066 
2025-01-08 02:10:20.360840: val_loss -0.6672 
2025-01-08 02:10:20.367359: Pseudo dice [np.float32(0.7282)] 
2025-01-08 02:10:20.370868: Epoch time: 43.44 s 
2025-01-08 02:10:21.090110:  
2025-01-08 02:10:21.091110: Epoch 115 
2025-01-08 02:10:21.095663: Current learning rate: 0.0079 
2025-01-08 02:11:04.505667: train_loss -0.6845 
2025-01-08 02:11:04.506176: val_loss -0.6854 
2025-01-08 02:11:04.512737: Pseudo dice [np.float32(0.77)] 
2025-01-08 02:11:04.515934: Epoch time: 43.42 s 
2025-01-08 02:11:05.085063:  
2025-01-08 02:11:05.085063: Epoch 116 
2025-01-08 02:11:05.090076: Current learning rate: 0.00789 
2025-01-08 02:11:48.483034: train_loss -0.69 
2025-01-08 02:11:48.484536: val_loss -0.695 
2025-01-08 02:11:48.488047: Pseudo dice [np.float32(0.7732)] 
2025-01-08 02:11:48.492058: Epoch time: 43.4 s 
2025-01-08 02:11:49.058551:  
2025-01-08 02:11:49.059054: Epoch 117 
2025-01-08 02:11:49.064068: Current learning rate: 0.00787 
2025-01-08 02:12:32.455348: train_loss -0.7123 
2025-01-08 02:12:32.455864: val_loss -0.7079 
2025-01-08 02:12:32.461473: Pseudo dice [np.float32(0.7791)] 
2025-01-08 02:12:32.465524: Epoch time: 43.4 s 
2025-01-08 02:12:32.468030: Yayy! New best EMA pseudo Dice: 0.7437000274658203 
2025-01-08 02:12:33.292613:  
2025-01-08 02:12:33.293618: Epoch 118 
2025-01-08 02:12:33.298679: Current learning rate: 0.00785 
2025-01-08 02:13:16.691292: train_loss -0.7214 
2025-01-08 02:13:16.692804: val_loss -0.7544 
2025-01-08 02:13:16.698858: Pseudo dice [np.float32(0.8296)] 
2025-01-08 02:13:16.703387: Epoch time: 43.4 s 
2025-01-08 02:13:16.706419: Yayy! New best EMA pseudo Dice: 0.7523000240325928 
2025-01-08 02:13:17.522191:  
2025-01-08 02:13:17.523195: Epoch 119 
2025-01-08 02:13:17.528262: Current learning rate: 0.00783 
2025-01-08 02:14:00.935114: train_loss -0.7133 
2025-01-08 02:14:00.935628: val_loss -0.7173 
2025-01-08 02:14:00.940680: Pseudo dice [np.float32(0.8043)] 
2025-01-08 02:14:00.944210: Epoch time: 43.41 s 
2025-01-08 02:14:00.947238: Yayy! New best EMA pseudo Dice: 0.7574999928474426 
2025-01-08 02:14:01.721568:  
2025-01-08 02:14:01.721568: Epoch 120 
2025-01-08 02:14:01.727169: Current learning rate: 0.00781 
2025-01-08 02:14:45.182394: train_loss -0.6722 
2025-01-08 02:14:45.182902: val_loss -0.7198 
2025-01-08 02:14:45.188984: Pseudo dice [np.float32(0.7849)] 
2025-01-08 02:14:45.192030: Epoch time: 43.46 s 
2025-01-08 02:14:45.194592: Yayy! New best EMA pseudo Dice: 0.760200023651123 
2025-01-08 02:14:45.958199:  
2025-01-08 02:14:45.958199: Epoch 121 
2025-01-08 02:14:45.963764: Current learning rate: 0.00779 
2025-01-08 02:15:29.390132: train_loss -0.7211 
2025-01-08 02:15:29.390639: val_loss -0.7391 
2025-01-08 02:15:29.396279: Pseudo dice [np.float32(0.8014)] 
2025-01-08 02:15:29.399857: Epoch time: 43.43 s 
2025-01-08 02:15:29.402917: Yayy! New best EMA pseudo Dice: 0.7642999887466431 
2025-01-08 02:15:30.216789:  
2025-01-08 02:15:30.217788: Epoch 122 
2025-01-08 02:15:30.222358: Current learning rate: 0.00777 
2025-01-08 02:16:13.639386: train_loss -0.7402 
2025-01-08 02:16:13.640389: val_loss -0.72 
2025-01-08 02:16:13.645937: Pseudo dice [np.float32(0.7953)] 
2025-01-08 02:16:13.648990: Epoch time: 43.42 s 
2025-01-08 02:16:13.652025: Yayy! New best EMA pseudo Dice: 0.7674000263214111 
2025-01-08 02:16:14.627956:  
2025-01-08 02:16:14.627956: Epoch 123 
2025-01-08 02:16:14.633997: Current learning rate: 0.00776 
2025-01-08 02:16:58.014796: train_loss -0.7182 
2025-01-08 02:16:58.015799: val_loss -0.7285 
2025-01-08 02:16:58.021373: Pseudo dice [np.float32(0.8044)] 
2025-01-08 02:16:58.024900: Epoch time: 43.39 s 
2025-01-08 02:16:58.027471: Yayy! New best EMA pseudo Dice: 0.7710999846458435 
2025-01-08 02:16:58.799389:  
2025-01-08 02:16:58.800398: Epoch 124 
2025-01-08 02:16:58.805934: Current learning rate: 0.00774 
2025-01-08 02:17:42.181746: train_loss -0.739 
2025-01-08 02:17:42.181746: val_loss -0.6666 
2025-01-08 02:17:42.187847: Pseudo dice [np.float32(0.6883)] 
2025-01-08 02:17:42.191897: Epoch time: 43.38 s 
2025-01-08 02:17:42.768085:  
2025-01-08 02:17:42.769087: Epoch 125 
2025-01-08 02:17:42.774160: Current learning rate: 0.00772 
2025-01-08 02:18:26.162989: train_loss -0.7478 
2025-01-08 02:18:26.162989: val_loss -0.7027 
2025-01-08 02:18:26.170004: Pseudo dice [np.float32(0.7732)] 
2025-01-08 02:18:26.173028: Epoch time: 43.4 s 
2025-01-08 02:18:26.740999:  
2025-01-08 02:18:26.741999: Epoch 126 
2025-01-08 02:18:26.746569: Current learning rate: 0.0077 
2025-01-08 02:19:10.186319: train_loss -0.676 
2025-01-08 02:19:10.187323: val_loss -0.7367 
2025-01-08 02:19:10.193838: Pseudo dice [np.float32(0.7816)] 
2025-01-08 02:19:10.197346: Epoch time: 43.45 s 
2025-01-08 02:19:10.766855:  
2025-01-08 02:19:10.766855: Epoch 127 
2025-01-08 02:19:10.772920: Current learning rate: 0.00768 
2025-01-08 02:19:54.139780: train_loss -0.6439 
2025-01-08 02:19:54.139780: val_loss -0.6386 
2025-01-08 02:19:54.145841: Pseudo dice [np.float32(0.7134)] 
2025-01-08 02:19:54.149921: Epoch time: 43.37 s 
2025-01-08 02:19:54.719179:  
2025-01-08 02:19:54.719681: Epoch 128 
2025-01-08 02:19:54.724692: Current learning rate: 0.00766 
2025-01-08 02:20:38.144195: train_loss -0.6909 
2025-01-08 02:20:38.144195: val_loss -0.7097 
2025-01-08 02:20:38.150709: Pseudo dice [np.float32(0.7656)] 
2025-01-08 02:20:38.154217: Epoch time: 43.43 s 
2025-01-08 02:20:38.729375:  
2025-01-08 02:20:38.729375: Epoch 129 
2025-01-08 02:20:38.734904: Current learning rate: 0.00764 
2025-01-08 02:21:22.100795: train_loss -0.6947 
2025-01-08 02:21:22.101798: val_loss -0.7227 
2025-01-08 02:21:22.106812: Pseudo dice [np.float32(0.7586)] 
2025-01-08 02:21:22.110820: Epoch time: 43.37 s 
2025-01-08 02:21:22.680207:  
2025-01-08 02:21:22.680207: Epoch 130 
2025-01-08 02:21:22.686241: Current learning rate: 0.00763 
2025-01-08 02:22:06.077024: train_loss -0.6999 
2025-01-08 02:22:06.078033: val_loss -0.6885 
2025-01-08 02:22:06.083659: Pseudo dice [np.float32(0.7225)] 
2025-01-08 02:22:06.087190: Epoch time: 43.4 s 
2025-01-08 02:22:06.806047:  
2025-01-08 02:22:06.807050: Epoch 131 
2025-01-08 02:22:06.812072: Current learning rate: 0.00761 
2025-01-08 02:22:50.218996: train_loss -0.7043 
2025-01-08 02:22:50.219499: val_loss -0.6728 
2025-01-08 02:22:50.225579: Pseudo dice [np.float32(0.7507)] 
2025-01-08 02:22:50.228107: Epoch time: 43.41 s 
2025-01-08 02:22:50.796761:  
2025-01-08 02:22:50.797765: Epoch 132 
2025-01-08 02:22:50.802326: Current learning rate: 0.00759 
2025-01-08 02:23:34.210254: train_loss -0.6708 
2025-01-08 02:23:34.211761: val_loss -0.6294 
2025-01-08 02:23:34.217470: Pseudo dice [np.float32(0.7289)] 
2025-01-08 02:23:34.220511: Epoch time: 43.41 s 
2025-01-08 02:23:34.788310:  
2025-01-08 02:23:34.788310: Epoch 133 
2025-01-08 02:23:34.792349: Current learning rate: 0.00757 
2025-01-08 02:24:18.186063: train_loss -0.6794 
2025-01-08 02:24:18.186565: val_loss -0.6937 
2025-01-08 02:24:18.192580: Pseudo dice [np.float32(0.7963)] 
2025-01-08 02:24:18.196587: Epoch time: 43.4 s 
2025-01-08 02:24:18.768471:  
2025-01-08 02:24:18.768471: Epoch 134 
2025-01-08 02:24:18.774487: Current learning rate: 0.00755 
2025-01-08 02:25:02.186004: train_loss -0.6931 
2025-01-08 02:25:02.186506: val_loss -0.6121 
2025-01-08 02:25:02.192521: Pseudo dice [np.float32(0.6552)] 
2025-01-08 02:25:02.196027: Epoch time: 43.42 s 
2025-01-08 02:25:02.781219:  
2025-01-08 02:25:02.781219: Epoch 135 
2025-01-08 02:25:02.786782: Current learning rate: 0.00753 
2025-01-08 02:25:46.217945: train_loss -0.7266 
2025-01-08 02:25:46.218949: val_loss -0.6848 
2025-01-08 02:25:46.226470: Pseudo dice [np.float32(0.6607)] 
2025-01-08 02:25:46.230484: Epoch time: 43.44 s 
2025-01-08 02:25:46.926839:  
2025-01-08 02:25:46.927842: Epoch 136 
2025-01-08 02:25:46.932455: Current learning rate: 0.00751 
2025-01-08 02:26:30.329938: train_loss -0.7246 
2025-01-08 02:26:30.330951: val_loss -0.6536 
2025-01-08 02:26:30.336517: Pseudo dice [np.float32(0.7393)] 
2025-01-08 02:26:30.339569: Epoch time: 43.4 s 
2025-01-08 02:26:30.914671:  
2025-01-08 02:26:30.914671: Epoch 137 
2025-01-08 02:26:30.920219: Current learning rate: 0.0075 
2025-01-08 02:27:14.327993: train_loss -0.6829 
2025-01-08 02:27:14.328997: val_loss -0.6983 
2025-01-08 02:27:14.334012: Pseudo dice [np.float32(0.7798)] 
2025-01-08 02:27:14.337517: Epoch time: 43.41 s 
2025-01-08 02:27:14.935570:  
2025-01-08 02:27:14.936080: Epoch 138 
2025-01-08 02:27:14.941121: Current learning rate: 0.00748 
2025-01-08 02:27:58.331478: train_loss -0.7048 
2025-01-08 02:27:58.331981: val_loss -0.7886 
2025-01-08 02:27:58.337995: Pseudo dice [np.float32(0.8343)] 
2025-01-08 02:27:58.341503: Epoch time: 43.4 s 
2025-01-08 02:27:59.063815:  
2025-01-08 02:27:59.064325: Epoch 139 
2025-01-08 02:27:59.069469: Current learning rate: 0.00746 
2025-01-08 02:28:42.487909: train_loss -0.7378 
2025-01-08 02:28:42.488413: val_loss -0.7181 
2025-01-08 02:28:42.494462: Pseudo dice [np.float32(0.7667)] 
2025-01-08 02:28:42.497978: Epoch time: 43.42 s 
2025-01-08 02:28:43.069789:  
2025-01-08 02:28:43.069789: Epoch 140 
2025-01-08 02:28:43.075356: Current learning rate: 0.00744 
2025-01-08 02:29:26.464560: train_loss -0.6599 
2025-01-08 02:29:26.465064: val_loss -0.6997 
2025-01-08 02:29:26.471109: Pseudo dice [np.float32(0.7364)] 
2025-01-08 02:29:26.474659: Epoch time: 43.4 s 
2025-01-08 02:29:27.142848:  
2025-01-08 02:29:27.142848: Epoch 141 
2025-01-08 02:29:27.147866: Current learning rate: 0.00742 
2025-01-08 02:30:10.539648: train_loss -0.7114 
2025-01-08 02:30:10.540651: val_loss -0.6661 
2025-01-08 02:30:10.546293: Pseudo dice [np.float32(0.7433)] 
2025-01-08 02:30:10.549821: Epoch time: 43.4 s 
2025-01-08 02:30:11.130167:  
2025-01-08 02:30:11.130669: Epoch 142 
2025-01-08 02:30:11.135712: Current learning rate: 0.0074 
2025-01-08 02:30:54.597605: train_loss -0.7188 
2025-01-08 02:30:54.598634: val_loss -0.701 
2025-01-08 02:30:54.604208: Pseudo dice [np.float32(0.7637)] 
2025-01-08 02:30:54.607735: Epoch time: 43.47 s 
2025-01-08 02:30:55.182594:  
2025-01-08 02:30:55.182594: Epoch 143 
2025-01-08 02:30:55.186103: Current learning rate: 0.00738 
2025-01-08 02:31:38.612032: train_loss -0.7189 
2025-01-08 02:31:38.612535: val_loss -0.6444 
2025-01-08 02:31:38.617679: Pseudo dice [np.float32(0.6968)] 
2025-01-08 02:31:38.620718: Epoch time: 43.43 s 
2025-01-08 02:31:39.193243:  
2025-01-08 02:31:39.193243: Epoch 144 
2025-01-08 02:31:39.198778: Current learning rate: 0.00737 
2025-01-08 02:32:22.627645: train_loss -0.6705 
2025-01-08 02:32:22.628147: val_loss -0.5013 
2025-01-08 02:32:22.633689: Pseudo dice [np.float32(0.4507)] 
2025-01-08 02:32:22.636758: Epoch time: 43.44 s 
2025-01-08 02:32:23.209594:  
2025-01-08 02:32:23.210097: Epoch 145 
2025-01-08 02:32:23.215717: Current learning rate: 0.00735 
2025-01-08 02:33:06.657753: train_loss -0.7079 
2025-01-08 02:33:06.658274: val_loss -0.7292 
2025-01-08 02:33:06.663867: Pseudo dice [np.float32(0.7658)] 
2025-01-08 02:33:06.666406: Epoch time: 43.45 s 
2025-01-08 02:33:07.243160:  
2025-01-08 02:33:07.243664: Epoch 146 
2025-01-08 02:33:07.248673: Current learning rate: 0.00733 
2025-01-08 02:33:50.705535: train_loss -0.6739 
2025-01-08 02:33:50.706046: val_loss -0.7458 
2025-01-08 02:33:50.711124: Pseudo dice [np.float32(0.8033)] 
2025-01-08 02:33:50.715163: Epoch time: 43.46 s 
2025-01-08 02:33:51.439130:  
2025-01-08 02:33:51.440129: Epoch 147 
2025-01-08 02:33:51.445235: Current learning rate: 0.00731 
2025-01-08 02:34:34.846126: train_loss -0.6903 
2025-01-08 02:34:34.847179: val_loss -0.6454 
2025-01-08 02:34:34.851213: Pseudo dice [np.float32(0.7352)] 
2025-01-08 02:34:34.854264: Epoch time: 43.41 s 
2025-01-08 02:34:35.431329:  
2025-01-08 02:34:35.431329: Epoch 148 
2025-01-08 02:34:35.437490: Current learning rate: 0.00729 
2025-01-08 02:35:18.850778: train_loss -0.6957 
2025-01-08 02:35:18.851782: val_loss -0.6668 
2025-01-08 02:35:18.857793: Pseudo dice [np.float32(0.7554)] 
2025-01-08 02:35:18.860801: Epoch time: 43.42 s 
2025-01-08 02:35:19.435960:  
2025-01-08 02:35:19.435960: Epoch 149 
2025-01-08 02:35:19.441090: Current learning rate: 0.00727 
2025-01-08 02:36:02.864781: train_loss -0.7195 
2025-01-08 02:36:02.865287: val_loss -0.7515 
2025-01-08 02:36:02.873364: Pseudo dice [np.float32(0.8086)] 
2025-01-08 02:36:02.877397: Epoch time: 43.43 s 
2025-01-08 02:36:03.707891:  
2025-01-08 02:36:03.707891: Epoch 150 
2025-01-08 02:36:03.714449: Current learning rate: 0.00725 
2025-01-08 02:36:47.089965: train_loss -0.7134 
2025-01-08 02:36:47.090467: val_loss -0.7924 
2025-01-08 02:36:47.096545: Pseudo dice [np.float32(0.8343)] 
2025-01-08 02:36:47.099569: Epoch time: 43.38 s 
2025-01-08 02:36:47.673847:  
2025-01-08 02:36:47.673847: Epoch 151 
2025-01-08 02:36:47.679384: Current learning rate: 0.00724 
2025-01-08 02:37:31.094090: train_loss -0.7236 
2025-01-08 02:37:31.095102: val_loss -0.6924 
2025-01-08 02:37:31.100142: Pseudo dice [np.float32(0.7532)] 
2025-01-08 02:37:31.104168: Epoch time: 43.42 s 
2025-01-08 02:37:31.678924:  
2025-01-08 02:37:31.678924: Epoch 152 
2025-01-08 02:37:31.684454: Current learning rate: 0.00722 
2025-01-08 02:38:15.064586: train_loss -0.7082 
2025-01-08 02:38:15.066088: val_loss -0.7281 
2025-01-08 02:38:15.072103: Pseudo dice [np.float32(0.7952)] 
2025-01-08 02:38:15.074609: Epoch time: 43.39 s 
2025-01-08 02:38:15.646186:  
2025-01-08 02:38:15.646186: Epoch 153 
2025-01-08 02:38:15.651741: Current learning rate: 0.0072 
2025-01-08 02:38:59.048077: train_loss -0.7206 
2025-01-08 02:38:59.049080: val_loss -0.682 
2025-01-08 02:38:59.054642: Pseudo dice [np.float32(0.7204)] 
2025-01-08 02:38:59.058172: Epoch time: 43.4 s 
2025-01-08 02:38:59.645597:  
2025-01-08 02:38:59.646100: Epoch 154 
2025-01-08 02:38:59.651112: Current learning rate: 0.00718 
2025-01-08 02:39:43.060693: train_loss -0.6909 
2025-01-08 02:39:43.061209: val_loss -0.7217 
2025-01-08 02:39:43.067273: Pseudo dice [np.float32(0.7719)] 
2025-01-08 02:39:43.070297: Epoch time: 43.42 s 
2025-01-08 02:39:43.798760:  
2025-01-08 02:39:43.799764: Epoch 155 
2025-01-08 02:39:43.804814: Current learning rate: 0.00716 
2025-01-08 02:40:27.202705: train_loss -0.7143 
2025-01-08 02:40:27.203218: val_loss -0.7167 
2025-01-08 02:40:27.208783: Pseudo dice [np.float32(0.7459)] 
2025-01-08 02:40:27.212839: Epoch time: 43.4 s 
2025-01-08 02:40:27.792267:  
2025-01-08 02:40:27.793271: Epoch 156 
2025-01-08 02:40:27.797317: Current learning rate: 0.00714 
2025-01-08 02:41:11.211219: train_loss -0.7364 
2025-01-08 02:41:11.211721: val_loss -0.7047 
2025-01-08 02:41:11.219241: Pseudo dice [np.float32(0.7825)] 
2025-01-08 02:41:11.224252: Epoch time: 43.42 s 
2025-01-08 02:41:11.812982:  
2025-01-08 02:41:11.813484: Epoch 157 
2025-01-08 02:41:11.818497: Current learning rate: 0.00712 
2025-01-08 02:41:55.247359: train_loss -0.7285 
2025-01-08 02:41:55.248865: val_loss -0.7378 
2025-01-08 02:41:55.254410: Pseudo dice [np.float32(0.787)] 
2025-01-08 02:41:55.257443: Epoch time: 43.44 s 
2025-01-08 02:41:55.838380:  
2025-01-08 02:41:55.838886: Epoch 158 
2025-01-08 02:41:55.843920: Current learning rate: 0.0071 
2025-01-08 02:42:39.240379: train_loss -0.7095 
2025-01-08 02:42:39.240881: val_loss -0.684 
2025-01-08 02:42:39.246899: Pseudo dice [np.float32(0.6985)] 
2025-01-08 02:42:39.250405: Epoch time: 43.4 s 
2025-01-08 02:42:39.836341:  
2025-01-08 02:42:39.836843: Epoch 159 
2025-01-08 02:42:39.840869: Current learning rate: 0.00709 
2025-01-08 02:43:23.268055: train_loss -0.7416 
2025-01-08 02:43:23.268568: val_loss -0.6962 
2025-01-08 02:43:23.274583: Pseudo dice [np.float32(0.8018)] 
2025-01-08 02:43:23.278087: Epoch time: 43.43 s 
2025-01-08 02:43:23.869197:  
2025-01-08 02:43:23.869699: Epoch 160 
2025-01-08 02:43:23.874711: Current learning rate: 0.00707 
2025-01-08 02:44:07.307618: train_loss -0.7474 
2025-01-08 02:44:07.308616: val_loss -0.691 
2025-01-08 02:44:07.314131: Pseudo dice [np.float32(0.77)] 
2025-01-08 02:44:07.317640: Epoch time: 43.44 s 
2025-01-08 02:44:07.906023:  
2025-01-08 02:44:07.907026: Epoch 161 
2025-01-08 02:44:07.911599: Current learning rate: 0.00705 
2025-01-08 02:44:51.328063: train_loss -0.7735 
2025-01-08 02:44:51.329063: val_loss -0.6001 
2025-01-08 02:44:51.334577: Pseudo dice [np.float32(0.6442)] 
2025-01-08 02:44:51.338086: Epoch time: 43.42 s 
2025-01-08 02:44:51.922181:  
2025-01-08 02:44:51.922181: Epoch 162 
2025-01-08 02:44:51.927716: Current learning rate: 0.00703 
2025-01-08 02:45:35.318270: train_loss -0.7449 
2025-01-08 02:45:35.318817: val_loss -0.7112 
2025-01-08 02:45:35.324428: Pseudo dice [np.float32(0.7772)] 
2025-01-08 02:45:35.328456: Epoch time: 43.4 s 
2025-01-08 02:45:36.059742:  
2025-01-08 02:45:36.060742: Epoch 163 
2025-01-08 02:45:36.066337: Current learning rate: 0.00701 
2025-01-08 02:46:19.424665: train_loss -0.7616 
2025-01-08 02:46:19.425179: val_loss -0.7036 
2025-01-08 02:46:19.431230: Pseudo dice [np.float32(0.8002)] 
2025-01-08 02:46:19.434759: Epoch time: 43.36 s 
2025-01-08 02:46:20.014430:  
2025-01-08 02:46:20.014430: Epoch 164 
2025-01-08 02:46:20.020986: Current learning rate: 0.00699 
2025-01-08 02:47:03.418197: train_loss -0.7306 
2025-01-08 02:47:03.418701: val_loss -0.716 
2025-01-08 02:47:03.424248: Pseudo dice [np.float32(0.7907)] 
2025-01-08 02:47:03.427277: Epoch time: 43.4 s 
2025-01-08 02:47:04.019906:  
2025-01-08 02:47:04.019906: Epoch 165 
2025-01-08 02:47:04.024922: Current learning rate: 0.00697 
2025-01-08 02:47:47.453637: train_loss -0.7173 
2025-01-08 02:47:47.454141: val_loss -0.7151 
2025-01-08 02:47:47.460261: Pseudo dice [np.float32(0.7695)] 
2025-01-08 02:47:47.463268: Epoch time: 43.44 s 
2025-01-08 02:47:48.033295:  
2025-01-08 02:47:48.033295: Epoch 166 
2025-01-08 02:47:48.038338: Current learning rate: 0.00696 
2025-01-08 02:48:31.447661: train_loss -0.6963 
2025-01-08 02:48:31.449164: val_loss -0.6874 
2025-01-08 02:48:31.454176: Pseudo dice [np.float32(0.7349)] 
2025-01-08 02:48:31.457685: Epoch time: 43.41 s 
2025-01-08 02:48:32.033491:  
2025-01-08 02:48:32.034494: Epoch 167 
2025-01-08 02:48:32.039531: Current learning rate: 0.00694 
2025-01-08 02:49:15.425797: train_loss -0.6658 
2025-01-08 02:49:15.426307: val_loss -0.743 
2025-01-08 02:49:15.432356: Pseudo dice [np.float32(0.7984)] 
2025-01-08 02:49:15.435384: Epoch time: 43.39 s 
2025-01-08 02:49:16.009223:  
2025-01-08 02:49:16.009725: Epoch 168 
2025-01-08 02:49:16.014737: Current learning rate: 0.00692 
2025-01-08 02:49:59.407888: train_loss -0.7143 
2025-01-08 02:49:59.408412: val_loss -0.6913 
2025-01-08 02:49:59.414427: Pseudo dice [np.float32(0.7686)] 
2025-01-08 02:49:59.416933: Epoch time: 43.4 s 
2025-01-08 02:49:59.999918:  
2025-01-08 02:50:00.000921: Epoch 169 
2025-01-08 02:50:00.004964: Current learning rate: 0.0069 
2025-01-08 02:50:43.407200: train_loss -0.6992 
2025-01-08 02:50:43.407200: val_loss -0.6176 
2025-01-08 02:50:43.412727: Pseudo dice [np.float32(0.6555)] 
2025-01-08 02:50:43.416756: Epoch time: 43.41 s 
2025-01-08 02:50:43.998285:  
2025-01-08 02:50:43.998285: Epoch 170 
2025-01-08 02:50:44.003845: Current learning rate: 0.00688 
2025-01-08 02:51:27.380548: train_loss -0.7279 
2025-01-08 02:51:27.382051: val_loss -0.5697 
2025-01-08 02:51:27.389068: Pseudo dice [np.float32(0.7266)] 
2025-01-08 02:51:27.392076: Epoch time: 43.38 s 
2025-01-08 02:51:28.119859:  
2025-01-08 02:51:28.120858: Epoch 171 
2025-01-08 02:51:28.126448: Current learning rate: 0.00686 
2025-01-08 02:52:11.591327: train_loss -0.7259 
2025-01-08 02:52:11.591327: val_loss -0.7172 
2025-01-08 02:52:11.597364: Pseudo dice [np.float32(0.8065)] 
2025-01-08 02:52:11.600873: Epoch time: 43.47 s 
2025-01-08 02:52:12.179594:  
2025-01-08 02:52:12.180597: Epoch 172 
2025-01-08 02:52:12.185628: Current learning rate: 0.00684 
2025-01-08 02:52:55.633406: train_loss -0.7381 
2025-01-08 02:52:55.633914: val_loss -0.7429 
2025-01-08 02:52:55.640021: Pseudo dice [np.float32(0.7864)] 
2025-01-08 02:52:55.643086: Epoch time: 43.45 s 
2025-01-08 02:52:56.227874:  
2025-01-08 02:52:56.228877: Epoch 173 
2025-01-08 02:52:56.233429: Current learning rate: 0.00682 
2025-01-08 02:53:39.637266: train_loss -0.7709 
2025-01-08 02:53:39.637770: val_loss -0.719 
2025-01-08 02:53:39.643869: Pseudo dice [np.float32(0.8112)] 
2025-01-08 02:53:39.646931: Epoch time: 43.41 s 
2025-01-08 02:53:40.231828:  
2025-01-08 02:53:40.232828: Epoch 174 
2025-01-08 02:53:40.237898: Current learning rate: 0.0068 
2025-01-08 02:54:23.617847: train_loss -0.7323 
2025-01-08 02:54:23.617847: val_loss -0.739 
2025-01-08 02:54:23.624361: Pseudo dice [np.float32(0.7964)] 
2025-01-08 02:54:23.627869: Epoch time: 43.39 s 
2025-01-08 02:54:24.210190:  
2025-01-08 02:54:24.210696: Epoch 175 
2025-01-08 02:54:24.215738: Current learning rate: 0.00679 
2025-01-08 02:55:07.612599: train_loss -0.7269 
2025-01-08 02:55:07.613102: val_loss -0.7224 
2025-01-08 02:55:07.619203: Pseudo dice [np.float32(0.8266)] 
2025-01-08 02:55:07.621225: Epoch time: 43.4 s 
2025-01-08 02:55:07.625274: Yayy! New best EMA pseudo Dice: 0.772599995136261 
2025-01-08 02:55:08.466129:  
2025-01-08 02:55:08.467134: Epoch 176 
2025-01-08 02:55:08.471684: Current learning rate: 0.00677 
2025-01-08 02:55:51.866735: train_loss -0.7456 
2025-01-08 02:55:51.867738: val_loss -0.692 
2025-01-08 02:55:51.872859: Pseudo dice [np.float32(0.6972)] 
2025-01-08 02:55:51.876402: Epoch time: 43.4 s 
2025-01-08 02:55:52.449215:  
2025-01-08 02:55:52.450214: Epoch 177 
2025-01-08 02:55:52.455261: Current learning rate: 0.00675 
2025-01-08 02:56:35.902807: train_loss -0.7429 
2025-01-08 02:56:35.902807: val_loss -0.6614 
2025-01-08 02:56:35.910383: Pseudo dice [np.float32(0.732)] 
2025-01-08 02:56:35.913447: Epoch time: 43.45 s 
2025-01-08 02:56:36.493737:  
2025-01-08 02:56:36.493737: Epoch 178 
2025-01-08 02:56:36.498753: Current learning rate: 0.00673 
2025-01-08 02:57:19.899174: train_loss -0.7652 
2025-01-08 02:57:19.899174: val_loss -0.6989 
2025-01-08 02:57:19.905730: Pseudo dice [np.float32(0.7781)] 
2025-01-08 02:57:19.908826: Epoch time: 43.41 s 
2025-01-08 02:57:20.637085:  
2025-01-08 02:57:20.637085: Epoch 179 
2025-01-08 02:57:20.642099: Current learning rate: 0.00671 
2025-01-08 02:58:04.037576: train_loss -0.7585 
2025-01-08 02:58:04.038604: val_loss -0.7156 
2025-01-08 02:58:04.043195: Pseudo dice [np.float32(0.8073)] 
2025-01-08 02:58:04.047289: Epoch time: 43.4 s 
2025-01-08 02:58:04.618467:  
2025-01-08 02:58:04.619466: Epoch 180 
2025-01-08 02:58:04.624570: Current learning rate: 0.00669 
2025-01-08 02:58:48.049234: train_loss -0.7298 
2025-01-08 02:58:48.050239: val_loss -0.66 
2025-01-08 02:58:48.056351: Pseudo dice [np.float32(0.7155)] 
2025-01-08 02:58:48.058954: Epoch time: 43.43 s 
2025-01-08 02:58:48.636746:  
2025-01-08 02:58:48.636746: Epoch 181 
2025-01-08 02:58:48.641261: Current learning rate: 0.00667 
2025-01-08 02:59:32.032699: train_loss -0.7537 
2025-01-08 02:59:32.033202: val_loss -0.6712 
2025-01-08 02:59:32.038217: Pseudo dice [np.float32(0.7186)] 
2025-01-08 02:59:32.041727: Epoch time: 43.4 s 
2025-01-08 02:59:32.616421:  
2025-01-08 02:59:32.616924: Epoch 182 
2025-01-08 02:59:32.621938: Current learning rate: 0.00665 
2025-01-08 03:00:16.061455: train_loss -0.7258 
2025-01-08 03:00:16.061957: val_loss -0.6152 
2025-01-08 03:00:16.067980: Pseudo dice [np.float32(0.6977)] 
2025-01-08 03:00:16.070484: Epoch time: 43.45 s 
2025-01-08 03:00:16.642631:  
2025-01-08 03:00:16.644131: Epoch 183 
2025-01-08 03:00:16.648640: Current learning rate: 0.00664 
2025-01-08 03:01:00.099157: train_loss -0.7378 
2025-01-08 03:01:00.099157: val_loss -0.6348 
2025-01-08 03:01:00.105238: Pseudo dice [np.float32(0.7242)] 
2025-01-08 03:01:00.107805: Epoch time: 43.46 s 
2025-01-08 03:01:00.686036:  
2025-01-08 03:01:00.687043: Epoch 184 
2025-01-08 03:01:00.691594: Current learning rate: 0.00662 
2025-01-08 03:01:44.094128: train_loss -0.7481 
2025-01-08 03:01:44.094128: val_loss -0.7315 
2025-01-08 03:01:44.100714: Pseudo dice [np.float32(0.7989)] 
2025-01-08 03:01:44.103821: Epoch time: 43.41 s 
2025-01-08 03:01:44.681262:  
2025-01-08 03:01:44.682260: Epoch 185 
2025-01-08 03:01:44.687277: Current learning rate: 0.0066 
2025-01-08 03:02:28.115279: train_loss -0.7447 
2025-01-08 03:02:28.116284: val_loss -0.6864 
2025-01-08 03:02:28.122303: Pseudo dice [np.float32(0.7456)] 
2025-01-08 03:02:28.125314: Epoch time: 43.44 s 
2025-01-08 03:02:28.700983:  
2025-01-08 03:02:28.701986: Epoch 186 
2025-01-08 03:02:28.706641: Current learning rate: 0.00658 
2025-01-08 03:03:12.159408: train_loss -0.7173 
2025-01-08 03:03:12.160412: val_loss -0.7307 
2025-01-08 03:03:12.165425: Pseudo dice [np.float32(0.7515)] 
2025-01-08 03:03:12.169439: Epoch time: 43.46 s 
2025-01-08 03:03:12.910763:  
2025-01-08 03:03:12.910763: Epoch 187 
2025-01-08 03:03:12.916321: Current learning rate: 0.00656 
2025-01-08 03:03:56.327834: train_loss -0.7165 
2025-01-08 03:03:56.328838: val_loss -0.7216 
2025-01-08 03:03:56.334464: Pseudo dice [np.float32(0.775)] 
2025-01-08 03:03:56.337557: Epoch time: 43.42 s 
2025-01-08 03:03:56.923881:  
2025-01-08 03:03:56.924392: Epoch 188 
2025-01-08 03:03:56.928959: Current learning rate: 0.00654 
2025-01-08 03:04:40.293724: train_loss -0.7373 
2025-01-08 03:04:40.294226: val_loss -0.6353 
2025-01-08 03:04:40.300243: Pseudo dice [np.float32(0.7219)] 
2025-01-08 03:04:40.302749: Epoch time: 43.37 s 
2025-01-08 03:04:40.884771:  
2025-01-08 03:04:40.884771: Epoch 189 
2025-01-08 03:04:40.890895: Current learning rate: 0.00652 
2025-01-08 03:05:24.260997: train_loss -0.7366 
2025-01-08 03:05:24.261499: val_loss -0.6735 
2025-01-08 03:05:24.267076: Pseudo dice [np.float32(0.7441)] 
2025-01-08 03:05:24.270598: Epoch time: 43.38 s 
2025-01-08 03:05:24.860230:  
2025-01-08 03:05:24.861231: Epoch 190 
2025-01-08 03:05:24.866298: Current learning rate: 0.0065 
2025-01-08 03:06:08.270397: train_loss -0.6896 
2025-01-08 03:06:08.270397: val_loss -0.7126 
2025-01-08 03:06:08.276540: Pseudo dice [np.float32(0.7904)] 
2025-01-08 03:06:08.280156: Epoch time: 43.41 s 
2025-01-08 03:06:08.858027:  
2025-01-08 03:06:08.859031: Epoch 191 
2025-01-08 03:06:08.864623: Current learning rate: 0.00648 
2025-01-08 03:06:52.301051: train_loss -0.7288 
2025-01-08 03:06:52.301558: val_loss -0.7158 
2025-01-08 03:06:52.308717: Pseudo dice [np.float32(0.7707)] 
2025-01-08 03:06:52.311793: Epoch time: 43.44 s 
2025-01-08 03:06:52.924472:  
2025-01-08 03:06:52.925477: Epoch 192 
2025-01-08 03:06:52.930509: Current learning rate: 0.00647 
2025-01-08 03:07:36.330297: train_loss -0.7499 
2025-01-08 03:07:36.330803: val_loss -0.722 
2025-01-08 03:07:36.335817: Pseudo dice [np.float32(0.7879)] 
2025-01-08 03:07:36.339328: Epoch time: 43.41 s 
2025-01-08 03:07:36.937582:  
2025-01-08 03:07:36.937582: Epoch 193 
2025-01-08 03:07:36.942698: Current learning rate: 0.00645 
2025-01-08 03:08:20.335282: train_loss -0.7146 
2025-01-08 03:08:20.336286: val_loss -0.6971 
2025-01-08 03:08:20.341543: Pseudo dice [np.float32(0.7101)] 
2025-01-08 03:08:20.345050: Epoch time: 43.4 s 
2025-01-08 03:08:20.938358:  
2025-01-08 03:08:20.938358: Epoch 194 
2025-01-08 03:08:20.943369: Current learning rate: 0.00643 
2025-01-08 03:09:04.357668: train_loss -0.7491 
2025-01-08 03:09:04.358676: val_loss -0.6958 
2025-01-08 03:09:04.364286: Pseudo dice [np.float32(0.7685)] 
2025-01-08 03:09:04.367332: Epoch time: 43.42 s 
2025-01-08 03:09:05.116461:  
2025-01-08 03:09:05.116968: Epoch 195 
2025-01-08 03:09:05.122545: Current learning rate: 0.00641 
2025-01-08 03:09:48.522865: train_loss -0.7747 
2025-01-08 03:09:48.523444: val_loss -0.6558 
2025-01-08 03:09:48.527657: Pseudo dice [np.float32(0.692)] 
2025-01-08 03:09:48.531738: Epoch time: 43.41 s 
2025-01-08 03:09:49.122742:  
2025-01-08 03:09:49.122742: Epoch 196 
2025-01-08 03:09:49.126785: Current learning rate: 0.00639 
2025-01-08 03:10:32.513521: train_loss -0.7715 
2025-01-08 03:10:32.513521: val_loss -0.7103 
2025-01-08 03:10:32.519538: Pseudo dice [np.float32(0.7558)] 
2025-01-08 03:10:32.523045: Epoch time: 43.39 s 
2025-01-08 03:10:33.119186:  
2025-01-08 03:10:33.119186: Epoch 197 
2025-01-08 03:10:33.124735: Current learning rate: 0.00637 
2025-01-08 03:11:16.489472: train_loss -0.742 
2025-01-08 03:11:16.490476: val_loss -0.6606 
2025-01-08 03:11:16.495639: Pseudo dice [np.float32(0.7286)] 
2025-01-08 03:11:16.499180: Epoch time: 43.37 s 
2025-01-08 03:11:17.082447:  
2025-01-08 03:11:17.082447: Epoch 198 
2025-01-08 03:11:17.088464: Current learning rate: 0.00635 
2025-01-08 03:12:00.486586: train_loss -0.75 
2025-01-08 03:12:00.486586: val_loss -0.7362 
2025-01-08 03:12:00.493103: Pseudo dice [np.float32(0.8013)] 
2025-01-08 03:12:00.496649: Epoch time: 43.4 s 
2025-01-08 03:12:01.079781:  
2025-01-08 03:12:01.080779: Epoch 199 
2025-01-08 03:12:01.086356: Current learning rate: 0.00633 
2025-01-08 03:12:44.469043: train_loss -0.7381 
2025-01-08 03:12:44.469544: val_loss -0.7104 
2025-01-08 03:12:44.475107: Pseudo dice [np.float32(0.7495)] 
2025-01-08 03:12:44.478621: Epoch time: 43.39 s 
2025-01-08 03:12:45.278366:  
2025-01-08 03:12:45.278366: Epoch 200 
2025-01-08 03:12:45.283922: Current learning rate: 0.00631 
2025-01-08 03:13:28.643512: train_loss -0.7744 
2025-01-08 03:13:28.644015: val_loss -0.6714 
2025-01-08 03:13:28.649033: Pseudo dice [np.float32(0.7404)] 
2025-01-08 03:13:28.652544: Epoch time: 43.37 s 
2025-01-08 03:13:29.237028:  
2025-01-08 03:13:29.238033: Epoch 201 
2025-01-08 03:13:29.242552: Current learning rate: 0.0063 
2025-01-08 03:14:12.631369: train_loss -0.7392 
2025-01-08 03:14:12.632390: val_loss -0.6604 
2025-01-08 03:14:12.637488: Pseudo dice [np.float32(0.7214)] 
2025-01-08 03:14:12.641549: Epoch time: 43.39 s 
2025-01-08 03:14:13.227518:  
2025-01-08 03:14:13.228515: Epoch 202 
2025-01-08 03:14:13.233577: Current learning rate: 0.00628 
2025-01-08 03:14:56.654050: train_loss -0.7302 
2025-01-08 03:14:56.654050: val_loss -0.7097 
2025-01-08 03:14:56.659625: Pseudo dice [np.float32(0.7377)] 
2025-01-08 03:14:56.662653: Epoch time: 43.43 s 
2025-01-08 03:14:57.398447:  
2025-01-08 03:14:57.399446: Epoch 203 
2025-01-08 03:14:57.405049: Current learning rate: 0.00626 
2025-01-08 03:15:40.775151: train_loss -0.766 
2025-01-08 03:15:40.775151: val_loss -0.7269 
2025-01-08 03:15:40.779162: Pseudo dice [np.float32(0.7856)] 
2025-01-08 03:15:40.782673: Epoch time: 43.38 s 
2025-01-08 03:15:41.362513:  
2025-01-08 03:15:41.362513: Epoch 204 
2025-01-08 03:15:41.367542: Current learning rate: 0.00624 
2025-01-08 03:16:24.774043: train_loss -0.7507 
2025-01-08 03:16:24.775046: val_loss -0.7741 
2025-01-08 03:16:24.780606: Pseudo dice [np.float32(0.8234)] 
2025-01-08 03:16:24.785781: Epoch time: 43.41 s 
2025-01-08 03:16:25.372037:  
2025-01-08 03:16:25.372037: Epoch 205 
2025-01-08 03:16:25.378057: Current learning rate: 0.00622 
2025-01-08 03:17:08.788993: train_loss -0.7716 
2025-01-08 03:17:08.789508: val_loss -0.7563 
2025-01-08 03:17:08.795591: Pseudo dice [np.float32(0.7922)] 
2025-01-08 03:17:08.799149: Epoch time: 43.42 s 
2025-01-08 03:17:09.601891:  
2025-01-08 03:17:09.603396: Epoch 206 
2025-01-08 03:17:09.608414: Current learning rate: 0.0062 
2025-01-08 03:17:53.046501: train_loss -0.7663 
2025-01-08 03:17:53.047506: val_loss -0.699 
2025-01-08 03:17:53.053527: Pseudo dice [np.float32(0.7493)] 
2025-01-08 03:17:53.056539: Epoch time: 43.44 s 
2025-01-08 03:17:53.606660:  
2025-01-08 03:17:53.606660: Epoch 207 
2025-01-08 03:17:53.611733: Current learning rate: 0.00618 
2025-01-08 03:18:37.017991: train_loss -0.7363 
2025-01-08 03:18:37.018493: val_loss -0.6996 
2025-01-08 03:18:37.024027: Pseudo dice [np.float32(0.7734)] 
2025-01-08 03:18:37.027540: Epoch time: 43.41 s 
2025-01-08 03:18:37.606447:  
2025-01-08 03:18:37.606447: Epoch 208 
2025-01-08 03:18:37.612288: Current learning rate: 0.00616 
2025-01-08 03:19:21.013157: train_loss -0.748 
2025-01-08 03:19:21.014161: val_loss -0.6746 
2025-01-08 03:19:21.019714: Pseudo dice [np.float32(0.7248)] 
2025-01-08 03:19:21.023282: Epoch time: 43.41 s 
2025-01-08 03:19:21.580492:  
2025-01-08 03:19:21.580492: Epoch 209 
2025-01-08 03:19:21.585508: Current learning rate: 0.00614 
2025-01-08 03:20:04.939165: train_loss -0.7625 
2025-01-08 03:20:04.940170: val_loss -0.7689 
2025-01-08 03:20:04.945695: Pseudo dice [np.float32(0.831)] 
2025-01-08 03:20:04.949208: Epoch time: 43.36 s 
2025-01-08 03:20:05.510354:  
2025-01-08 03:20:05.510869: Epoch 210 
2025-01-08 03:20:05.515440: Current learning rate: 0.00612 
2025-01-08 03:20:48.976728: train_loss -0.7596 
2025-01-08 03:20:48.977230: val_loss -0.7396 
2025-01-08 03:20:48.982243: Pseudo dice [np.float32(0.7937)] 
2025-01-08 03:20:48.985755: Epoch time: 43.47 s 
2025-01-08 03:20:49.551826:  
2025-01-08 03:20:49.552830: Epoch 211 
2025-01-08 03:20:49.557912: Current learning rate: 0.00611 
2025-01-08 03:21:32.945038: train_loss -0.7657 
2025-01-08 03:21:32.946542: val_loss -0.7168 
2025-01-08 03:21:32.952566: Pseudo dice [np.float32(0.7485)] 
2025-01-08 03:21:32.955073: Epoch time: 43.39 s 
2025-01-08 03:21:33.675870:  
2025-01-08 03:21:33.675870: Epoch 212 
2025-01-08 03:21:33.681969: Current learning rate: 0.00609 
2025-01-08 03:22:17.101158: train_loss -0.7775 
2025-01-08 03:22:17.102158: val_loss -0.6692 
2025-01-08 03:22:17.107675: Pseudo dice [np.float32(0.6919)] 
2025-01-08 03:22:17.111185: Epoch time: 43.43 s 
2025-01-08 03:22:17.678741:  
2025-01-08 03:22:17.679243: Epoch 213 
2025-01-08 03:22:17.684262: Current learning rate: 0.00607 
2025-01-08 03:23:01.085027: train_loss -0.7594 
2025-01-08 03:23:01.085530: val_loss -0.6866 
2025-01-08 03:23:01.091638: Pseudo dice [np.float32(0.7609)] 
2025-01-08 03:23:01.095646: Epoch time: 43.41 s 
2025-01-08 03:23:01.662820:  
2025-01-08 03:23:01.662820: Epoch 214 
2025-01-08 03:23:01.667839: Current learning rate: 0.00605 
2025-01-08 03:23:45.034897: train_loss -0.7558 
2025-01-08 03:23:45.035443: val_loss -0.7169 
2025-01-08 03:23:45.041533: Pseudo dice [np.float32(0.7684)] 
2025-01-08 03:23:45.044564: Epoch time: 43.37 s 
2025-01-08 03:23:45.608326:  
2025-01-08 03:23:45.608326: Epoch 215 
2025-01-08 03:23:45.614396: Current learning rate: 0.00603 
2025-01-08 03:24:28.994672: train_loss -0.7309 
2025-01-08 03:24:28.995677: val_loss -0.6796 
2025-01-08 03:24:29.000639: Pseudo dice [np.float32(0.7231)] 
2025-01-08 03:24:29.004856: Epoch time: 43.39 s 
2025-01-08 03:24:29.565585:  
2025-01-08 03:24:29.566615: Epoch 216 
2025-01-08 03:24:29.571227: Current learning rate: 0.00601 
2025-01-08 03:25:12.967376: train_loss -0.7759 
2025-01-08 03:25:12.967890: val_loss -0.7127 
2025-01-08 03:25:12.973480: Pseudo dice [np.float32(0.775)] 
2025-01-08 03:25:12.976118: Epoch time: 43.4 s 
2025-01-08 03:25:13.542139:  
2025-01-08 03:25:13.542642: Epoch 217 
2025-01-08 03:25:13.547655: Current learning rate: 0.00599 
2025-01-08 03:25:56.978571: train_loss -0.7673 
2025-01-08 03:25:56.979575: val_loss -0.7498 
2025-01-08 03:25:56.986145: Pseudo dice [np.float32(0.8249)] 
2025-01-08 03:25:56.988710: Epoch time: 43.44 s 
2025-01-08 03:25:57.555639:  
2025-01-08 03:25:57.555639: Epoch 218 
2025-01-08 03:25:57.561190: Current learning rate: 0.00597 
2025-01-08 03:26:40.981180: train_loss -0.7657 
2025-01-08 03:26:40.981180: val_loss -0.6891 
2025-01-08 03:26:40.987200: Pseudo dice [np.float32(0.718)] 
2025-01-08 03:26:40.989708: Epoch time: 43.43 s 
2025-01-08 03:26:41.550374:  
2025-01-08 03:26:41.550374: Epoch 219 
2025-01-08 03:26:41.555933: Current learning rate: 0.00595 
2025-01-08 03:27:25.008718: train_loss -0.7877 
2025-01-08 03:27:25.008718: val_loss -0.661 
2025-01-08 03:27:25.014309: Pseudo dice [np.float32(0.7389)] 
2025-01-08 03:27:25.017381: Epoch time: 43.46 s 
2025-01-08 03:27:25.730436:  
2025-01-08 03:27:25.730436: Epoch 220 
2025-01-08 03:27:25.735525: Current learning rate: 0.00593 
2025-01-08 03:28:09.141644: train_loss -0.7907 
2025-01-08 03:28:09.142152: val_loss -0.6872 
2025-01-08 03:28:09.146764: Pseudo dice [np.float32(0.7456)] 
2025-01-08 03:28:09.149866: Epoch time: 43.41 s 
2025-01-08 03:28:09.732111:  
2025-01-08 03:28:09.732111: Epoch 221 
2025-01-08 03:28:09.738288: Current learning rate: 0.00592 
2025-01-08 03:28:53.150023: train_loss -0.775 
2025-01-08 03:28:53.150540: val_loss -0.6667 
2025-01-08 03:28:53.156155: Pseudo dice [np.float32(0.7366)] 
2025-01-08 03:28:53.158719: Epoch time: 43.42 s 
2025-01-08 03:28:53.723184:  
2025-01-08 03:28:53.723184: Epoch 222 
2025-01-08 03:28:53.728195: Current learning rate: 0.0059 
2025-01-08 03:29:37.131690: train_loss -0.7479 
2025-01-08 03:29:37.131690: val_loss -0.7138 
2025-01-08 03:29:37.138208: Pseudo dice [np.float32(0.7961)] 
2025-01-08 03:29:37.141721: Epoch time: 43.41 s 
2025-01-08 03:29:37.695148:  
2025-01-08 03:29:37.695148: Epoch 223 
2025-01-08 03:29:37.700203: Current learning rate: 0.00588 
2025-01-08 03:30:21.144387: train_loss -0.7401 
2025-01-08 03:30:21.144387: val_loss -0.7097 
2025-01-08 03:30:21.151155: Pseudo dice [np.float32(0.7609)] 
2025-01-08 03:30:21.154272: Epoch time: 43.45 s 
2025-01-08 03:30:21.700327:  
2025-01-08 03:30:21.700327: Epoch 224 
2025-01-08 03:30:21.706433: Current learning rate: 0.00586 
2025-01-08 03:31:05.099009: train_loss -0.6894 
2025-01-08 03:31:05.100511: val_loss -0.7339 
2025-01-08 03:31:05.106530: Pseudo dice [np.float32(0.7841)] 
2025-01-08 03:31:05.110038: Epoch time: 43.4 s 
2025-01-08 03:31:05.658426:  
2025-01-08 03:31:05.658426: Epoch 225 
2025-01-08 03:31:05.664509: Current learning rate: 0.00584 
2025-01-08 03:31:49.070570: train_loss -0.7472 
2025-01-08 03:31:49.070570: val_loss -0.7138 
2025-01-08 03:31:49.076591: Pseudo dice [np.float32(0.7706)] 
2025-01-08 03:31:49.080103: Epoch time: 43.41 s 
2025-01-08 03:31:49.628018:  
2025-01-08 03:31:49.628018: Epoch 226 
2025-01-08 03:31:49.633031: Current learning rate: 0.00582 
2025-01-08 03:32:33.060867: train_loss -0.7577 
2025-01-08 03:32:33.060867: val_loss -0.724 
2025-01-08 03:32:33.066960: Pseudo dice [np.float32(0.7787)] 
2025-01-08 03:32:33.070570: Epoch time: 43.43 s 
2025-01-08 03:32:33.620629:  
2025-01-08 03:32:33.621133: Epoch 227 
2025-01-08 03:32:33.626149: Current learning rate: 0.0058 
2025-01-08 03:33:17.087091: train_loss -0.7471 
2025-01-08 03:33:17.087611: val_loss -0.7495 
2025-01-08 03:33:17.092625: Pseudo dice [np.float32(0.8123)] 
2025-01-08 03:33:17.096136: Epoch time: 43.47 s 
2025-01-08 03:33:17.643593:  
2025-01-08 03:33:17.643593: Epoch 228 
2025-01-08 03:33:17.648608: Current learning rate: 0.00578 
2025-01-08 03:34:01.058799: train_loss -0.7409 
2025-01-08 03:34:01.058799: val_loss -0.6645 
2025-01-08 03:34:01.065026: Pseudo dice [np.float32(0.7413)] 
2025-01-08 03:34:01.068221: Epoch time: 43.42 s 
2025-01-08 03:34:01.771722:  
2025-01-08 03:34:01.772721: Epoch 229 
2025-01-08 03:34:01.777779: Current learning rate: 0.00576 
2025-01-08 03:34:45.154399: train_loss -0.7741 
2025-01-08 03:34:45.154916: val_loss -0.6992 
2025-01-08 03:34:45.160494: Pseudo dice [np.float32(0.7549)] 
2025-01-08 03:34:45.163557: Epoch time: 43.38 s 
2025-01-08 03:34:45.709843:  
2025-01-08 03:34:45.709843: Epoch 230 
2025-01-08 03:34:45.714859: Current learning rate: 0.00574 
2025-01-08 03:35:29.078341: train_loss -0.7782 
2025-01-08 03:35:29.079849: val_loss -0.7656 
2025-01-08 03:35:29.085400: Pseudo dice [np.float32(0.8034)] 
2025-01-08 03:35:29.088434: Epoch time: 43.37 s 
2025-01-08 03:35:29.643298:  
2025-01-08 03:35:29.644303: Epoch 231 
2025-01-08 03:35:29.649351: Current learning rate: 0.00572 
2025-01-08 03:36:13.075436: train_loss -0.7528 
2025-01-08 03:36:13.075946: val_loss -0.7284 
2025-01-08 03:36:13.081019: Pseudo dice [np.float32(0.804)] 
2025-01-08 03:36:13.085099: Epoch time: 43.43 s 
2025-01-08 03:36:13.632925:  
2025-01-08 03:36:13.632925: Epoch 232 
2025-01-08 03:36:13.638991: Current learning rate: 0.0057 
2025-01-08 03:36:57.013339: train_loss -0.7763 
2025-01-08 03:36:57.014847: val_loss -0.7061 
2025-01-08 03:36:57.019959: Pseudo dice [np.float32(0.7551)] 
2025-01-08 03:36:57.023467: Epoch time: 43.38 s 
2025-01-08 03:36:57.571328:  
2025-01-08 03:36:57.571328: Epoch 233 
2025-01-08 03:36:57.576376: Current learning rate: 0.00569 
2025-01-08 03:37:41.001221: train_loss -0.7708 
2025-01-08 03:37:41.002223: val_loss -0.7069 
2025-01-08 03:37:41.007814: Pseudo dice [np.float32(0.7414)] 
2025-01-08 03:37:41.010952: Epoch time: 43.43 s 
2025-01-08 03:37:41.561932:  
2025-01-08 03:37:41.562935: Epoch 234 
2025-01-08 03:37:41.567478: Current learning rate: 0.00567 
2025-01-08 03:38:24.976466: train_loss -0.7687 
2025-01-08 03:38:24.976466: val_loss -0.6961 
2025-01-08 03:38:24.982581: Pseudo dice [np.float32(0.7378)] 
2025-01-08 03:38:24.985786: Epoch time: 43.41 s 
2025-01-08 03:38:25.542176:  
2025-01-08 03:38:25.542176: Epoch 235 
2025-01-08 03:38:25.548195: Current learning rate: 0.00565 
2025-01-08 03:39:08.947573: train_loss -0.7713 
2025-01-08 03:39:08.948575: val_loss -0.6438 
2025-01-08 03:39:08.955093: Pseudo dice [np.float32(0.6632)] 
2025-01-08 03:39:08.958111: Epoch time: 43.41 s 
2025-01-08 03:39:09.518173:  
2025-01-08 03:39:09.518173: Epoch 236 
2025-01-08 03:39:09.523775: Current learning rate: 0.00563 
2025-01-08 03:39:52.931043: train_loss -0.7833 
2025-01-08 03:39:52.932043: val_loss -0.7179 
2025-01-08 03:39:52.936060: Pseudo dice [np.float32(0.7796)] 
2025-01-08 03:39:52.938565: Epoch time: 43.41 s 
2025-01-08 03:39:53.496083:  
2025-01-08 03:39:53.496586: Epoch 237 
2025-01-08 03:39:53.501598: Current learning rate: 0.00561 
2025-01-08 03:40:36.940406: train_loss -0.7931 
2025-01-08 03:40:36.940912: val_loss -0.6961 
2025-01-08 03:40:36.946243: Pseudo dice [np.float32(0.7588)] 
2025-01-08 03:40:36.949336: Epoch time: 43.45 s 
2025-01-08 03:40:37.669808:  
2025-01-08 03:40:37.670324: Epoch 238 
2025-01-08 03:40:37.674920: Current learning rate: 0.00559 
2025-01-08 03:41:21.075371: train_loss -0.7466 
2025-01-08 03:41:21.075882: val_loss -0.6693 
2025-01-08 03:41:21.081571: Pseudo dice [np.float32(0.7313)] 
2025-01-08 03:41:21.084650: Epoch time: 43.41 s 
2025-01-08 03:41:21.640596:  
2025-01-08 03:41:21.640596: Epoch 239 
2025-01-08 03:41:21.646709: Current learning rate: 0.00557 
2025-01-08 03:42:05.078342: train_loss -0.7171 
2025-01-08 03:42:05.078342: val_loss -0.7134 
2025-01-08 03:42:05.084644: Pseudo dice [np.float32(0.7993)] 
2025-01-08 03:42:05.087810: Epoch time: 43.44 s 
2025-01-08 03:42:05.654663:  
2025-01-08 03:42:05.655664: Epoch 240 
2025-01-08 03:42:05.660244: Current learning rate: 0.00555 
2025-01-08 03:42:49.073950: train_loss -0.7398 
2025-01-08 03:42:49.075453: val_loss -0.7195 
2025-01-08 03:42:49.080466: Pseudo dice [np.float32(0.7583)] 
2025-01-08 03:42:49.084487: Epoch time: 43.42 s 
2025-01-08 03:42:49.659485:  
2025-01-08 03:42:49.659485: Epoch 241 
2025-01-08 03:42:49.665615: Current learning rate: 0.00553 
2025-01-08 03:43:33.084963: train_loss -0.7405 
2025-01-08 03:43:33.085465: val_loss -0.6965 
2025-01-08 03:43:33.091487: Pseudo dice [np.float32(0.7692)] 
2025-01-08 03:43:33.093996: Epoch time: 43.43 s 
2025-01-08 03:43:33.659548:  
2025-01-08 03:43:33.660547: Epoch 242 
2025-01-08 03:43:33.665097: Current learning rate: 0.00551 
2025-01-08 03:44:17.086001: train_loss -0.789 
2025-01-08 03:44:17.086001: val_loss -0.7129 
2025-01-08 03:44:17.092268: Pseudo dice [np.float32(0.7976)] 
2025-01-08 03:44:17.094779: Epoch time: 43.43 s 
2025-01-08 03:44:17.665726:  
2025-01-08 03:44:17.665726: Epoch 243 
2025-01-08 03:44:17.669757: Current learning rate: 0.00549 
2025-01-08 03:45:01.071899: train_loss -0.7487 
2025-01-08 03:45:01.072905: val_loss -0.7561 
2025-01-08 03:45:01.078916: Pseudo dice [np.float32(0.8084)] 
2025-01-08 03:45:01.081946: Epoch time: 43.41 s 
2025-01-08 03:45:01.643572:  
2025-01-08 03:45:01.644576: Epoch 244 
2025-01-08 03:45:01.649130: Current learning rate: 0.00547 
2025-01-08 03:45:45.036330: train_loss -0.7275 
2025-01-08 03:45:45.036330: val_loss -0.6698 
2025-01-08 03:45:45.041934: Pseudo dice [np.float32(0.7296)] 
2025-01-08 03:45:45.045473: Epoch time: 43.39 s 
2025-01-08 03:45:45.611718:  
2025-01-08 03:45:45.611718: Epoch 245 
2025-01-08 03:45:45.616806: Current learning rate: 0.00546 
2025-01-08 03:46:29.029440: train_loss -0.6646 
2025-01-08 03:46:29.030441: val_loss -0.6729 
2025-01-08 03:46:29.035960: Pseudo dice [np.float32(0.715)] 
2025-01-08 03:46:29.038980: Epoch time: 43.42 s 
2025-01-08 03:46:29.607080:  
2025-01-08 03:46:29.607591: Epoch 246 
2025-01-08 03:46:29.612655: Current learning rate: 0.00544 
2025-01-08 03:47:13.018753: train_loss -0.6991 
2025-01-08 03:47:13.019266: val_loss -0.7196 
2025-01-08 03:47:13.023892: Pseudo dice [np.float32(0.6877)] 
2025-01-08 03:47:13.027008: Epoch time: 43.41 s 
2025-01-08 03:47:13.744016:  
2025-01-08 03:47:13.744520: Epoch 247 
2025-01-08 03:47:13.749537: Current learning rate: 0.00542 
2025-01-08 03:47:57.221576: train_loss -0.7074 
2025-01-08 03:47:57.222083: val_loss -0.7121 
2025-01-08 03:47:57.227775: Pseudo dice [np.float32(0.7887)] 
2025-01-08 03:47:57.231480: Epoch time: 43.48 s 
2025-01-08 03:47:57.783953:  
2025-01-08 03:47:57.783953: Epoch 248 
2025-01-08 03:47:57.789091: Current learning rate: 0.0054 
2025-01-08 03:48:41.190933: train_loss -0.7337 
2025-01-08 03:48:41.191436: val_loss -0.6707 
2025-01-08 03:48:41.196448: Pseudo dice [np.float32(0.6887)] 
2025-01-08 03:48:41.199959: Epoch time: 43.41 s 
2025-01-08 03:48:41.753436:  
2025-01-08 03:48:41.753436: Epoch 249 
2025-01-08 03:48:41.758993: Current learning rate: 0.00538 
2025-01-08 03:49:25.234239: train_loss -0.733 
2025-01-08 03:49:25.234741: val_loss -0.7297 
2025-01-08 03:49:25.240757: Pseudo dice [np.float32(0.7876)] 
2025-01-08 03:49:25.244266: Epoch time: 43.48 s 
2025-01-08 03:49:26.049608:  
2025-01-08 03:49:26.049608: Epoch 250 
2025-01-08 03:49:26.055160: Current learning rate: 0.00536 
2025-01-08 03:50:09.478295: train_loss -0.7285 
2025-01-08 03:50:09.479326: val_loss -0.7093 
2025-01-08 03:50:09.483896: Pseudo dice [np.float32(0.7994)] 
2025-01-08 03:50:09.487958: Epoch time: 43.43 s 
2025-01-08 03:50:10.047780:  
2025-01-08 03:50:10.047780: Epoch 251 
2025-01-08 03:50:10.053305: Current learning rate: 0.00534 
2025-01-08 03:50:53.460175: train_loss -0.7727 
2025-01-08 03:50:53.460682: val_loss -0.7032 
2025-01-08 03:50:53.468261: Pseudo dice [np.float32(0.7776)] 
2025-01-08 03:50:53.472300: Epoch time: 43.41 s 
2025-01-08 03:50:54.025064:  
2025-01-08 03:50:54.025567: Epoch 252 
2025-01-08 03:50:54.030077: Current learning rate: 0.00532 
2025-01-08 03:51:37.455772: train_loss -0.7668 
2025-01-08 03:51:37.455772: val_loss -0.6582 
2025-01-08 03:51:37.461788: Pseudo dice [np.float32(0.755)] 
2025-01-08 03:51:37.465297: Epoch time: 43.43 s 
2025-01-08 03:51:38.027333:  
2025-01-08 03:51:38.027333: Epoch 253 
2025-01-08 03:51:38.032345: Current learning rate: 0.0053 
2025-01-08 03:52:21.485966: train_loss -0.7703 
2025-01-08 03:52:21.486473: val_loss -0.6467 
2025-01-08 03:52:21.492562: Pseudo dice [np.float32(0.728)] 
2025-01-08 03:52:21.495604: Epoch time: 43.46 s 
2025-01-08 03:52:22.051000:  
2025-01-08 03:52:22.052000: Epoch 254 
2025-01-08 03:52:22.057108: Current learning rate: 0.00528 
2025-01-08 03:53:05.445499: train_loss -0.7772 
2025-01-08 03:53:05.446499: val_loss -0.7129 
2025-01-08 03:53:05.452022: Pseudo dice [np.float32(0.8091)] 
2025-01-08 03:53:05.455535: Epoch time: 43.39 s 
2025-01-08 03:53:06.156751:  
2025-01-08 03:53:06.158252: Epoch 255 
2025-01-08 03:53:06.163268: Current learning rate: 0.00526 
2025-01-08 03:53:49.567473: train_loss -0.7678 
2025-01-08 03:53:49.568508: val_loss -0.6801 
2025-01-08 03:53:49.573636: Pseudo dice [np.float32(0.7287)] 
2025-01-08 03:53:49.576669: Epoch time: 43.41 s 
2025-01-08 03:53:50.135399:  
2025-01-08 03:53:50.135399: Epoch 256 
2025-01-08 03:53:50.140429: Current learning rate: 0.00524 
2025-01-08 03:54:33.583307: train_loss -0.751 
2025-01-08 03:54:33.584311: val_loss -0.7098 
2025-01-08 03:54:33.590322: Pseudo dice [np.float32(0.7013)] 
2025-01-08 03:54:33.593331: Epoch time: 43.45 s 
2025-01-08 03:54:34.160952:  
2025-01-08 03:54:34.161459: Epoch 257 
2025-01-08 03:54:34.166559: Current learning rate: 0.00522 
2025-01-08 03:55:17.551591: train_loss -0.759 
2025-01-08 03:55:17.552094: val_loss -0.7023 
2025-01-08 03:55:17.558165: Pseudo dice [np.float32(0.7625)] 
2025-01-08 03:55:17.561194: Epoch time: 43.39 s 
2025-01-08 03:55:18.131118:  
2025-01-08 03:55:18.131118: Epoch 258 
2025-01-08 03:55:18.137180: Current learning rate: 0.0052 
2025-01-08 03:56:01.592266: train_loss -0.7452 
2025-01-08 03:56:01.592773: val_loss -0.7052 
2025-01-08 03:56:01.598456: Pseudo dice [np.float32(0.757)] 
2025-01-08 03:56:01.601553: Epoch time: 43.46 s 
2025-01-08 03:56:02.162057:  
2025-01-08 03:56:02.162560: Epoch 259 
2025-01-08 03:56:02.167090: Current learning rate: 0.00518 
2025-01-08 03:56:45.569602: train_loss -0.783 
2025-01-08 03:56:45.570117: val_loss -0.6596 
2025-01-08 03:56:45.575679: Pseudo dice [np.float32(0.7717)] 
2025-01-08 03:56:45.579751: Epoch time: 43.41 s 
2025-01-08 03:56:46.139863:  
2025-01-08 03:56:46.140365: Epoch 260 
2025-01-08 03:56:46.145406: Current learning rate: 0.00517 
2025-01-08 03:57:29.548783: train_loss -0.7833 
2025-01-08 03:57:29.548783: val_loss -0.7256 
2025-01-08 03:57:29.555299: Pseudo dice [np.float32(0.8078)] 
2025-01-08 03:57:29.557804: Epoch time: 43.41 s 
2025-01-08 03:57:30.122452:  
2025-01-08 03:57:30.122954: Epoch 261 
2025-01-08 03:57:30.127966: Current learning rate: 0.00515 
2025-01-08 03:58:13.538311: train_loss -0.7675 
2025-01-08 03:58:13.538311: val_loss -0.6896 
2025-01-08 03:58:13.544826: Pseudo dice [np.float32(0.7751)] 
2025-01-08 03:58:13.548336: Epoch time: 43.42 s 
2025-01-08 03:58:14.112421:  
2025-01-08 03:58:14.112421: Epoch 262 
2025-01-08 03:58:14.117434: Current learning rate: 0.00513 
2025-01-08 03:58:57.531852: train_loss -0.7848 
2025-01-08 03:58:57.531852: val_loss -0.6679 
2025-01-08 03:58:57.537868: Pseudo dice [np.float32(0.7251)] 
2025-01-08 03:58:57.541374: Epoch time: 43.42 s 
2025-01-08 03:58:58.110768:  
2025-01-08 03:58:58.111270: Epoch 263 
2025-01-08 03:58:58.114779: Current learning rate: 0.00511 
2025-01-08 03:59:41.524868: train_loss -0.786 
2025-01-08 03:59:41.524868: val_loss -0.7533 
2025-01-08 03:59:41.529880: Pseudo dice [np.float32(0.8193)] 
2025-01-08 03:59:41.532386: Epoch time: 43.42 s 
2025-01-08 03:59:42.243233:  
2025-01-08 03:59:42.243233: Epoch 264 
2025-01-08 03:59:42.248764: Current learning rate: 0.00509 
2025-01-08 04:00:25.664697: train_loss -0.7654 
2025-01-08 04:00:25.665205: val_loss -0.7458 
2025-01-08 04:00:25.670757: Pseudo dice [np.float32(0.7858)] 
2025-01-08 04:00:25.673793: Epoch time: 43.42 s 
2025-01-08 04:00:26.241913:  
2025-01-08 04:00:26.241913: Epoch 265 
2025-01-08 04:00:26.246953: Current learning rate: 0.00507 
2025-01-08 04:01:09.645312: train_loss -0.7392 
2025-01-08 04:01:09.645312: val_loss -0.6563 
2025-01-08 04:01:09.652398: Pseudo dice [np.float32(0.7679)] 
2025-01-08 04:01:09.655445: Epoch time: 43.4 s 
2025-01-08 04:01:10.235069:  
2025-01-08 04:01:10.235069: Epoch 266 
2025-01-08 04:01:10.240607: Current learning rate: 0.00505 
2025-01-08 04:01:53.710985: train_loss -0.736 
2025-01-08 04:01:53.711487: val_loss -0.6949 
2025-01-08 04:01:53.716500: Pseudo dice [np.float32(0.7251)] 
2025-01-08 04:01:53.720539: Epoch time: 43.48 s 
2025-01-08 04:01:54.296679:  
2025-01-08 04:01:54.297182: Epoch 267 
2025-01-08 04:01:54.302194: Current learning rate: 0.00503 
2025-01-08 04:02:37.703052: train_loss -0.7694 
2025-01-08 04:02:37.703560: val_loss -0.7017 
2025-01-08 04:02:37.708616: Pseudo dice [np.float32(0.7713)] 
2025-01-08 04:02:37.713160: Epoch time: 43.41 s 
2025-01-08 04:02:38.282835:  
2025-01-08 04:02:38.282835: Epoch 268 
2025-01-08 04:02:38.287850: Current learning rate: 0.00501 
2025-01-08 04:03:21.702202: train_loss -0.7613 
2025-01-08 04:03:21.702705: val_loss -0.686 
2025-01-08 04:03:21.708769: Pseudo dice [np.float32(0.755)] 
2025-01-08 04:03:21.711798: Epoch time: 43.42 s 
2025-01-08 04:03:22.274019:  
2025-01-08 04:03:22.274019: Epoch 269 
2025-01-08 04:03:22.279055: Current learning rate: 0.00499 
2025-01-08 04:04:05.701487: train_loss -0.7794 
2025-01-08 04:04:05.703026: val_loss -0.7169 
2025-01-08 04:04:05.709052: Pseudo dice [np.float32(0.8014)] 
2025-01-08 04:04:05.712066: Epoch time: 43.43 s 
2025-01-08 04:04:06.279229:  
2025-01-08 04:04:06.280232: Epoch 270 
2025-01-08 04:04:06.284780: Current learning rate: 0.00497 
2025-01-08 04:04:49.699785: train_loss -0.7629 
2025-01-08 04:04:49.699785: val_loss -0.7048 
2025-01-08 04:04:49.704796: Pseudo dice [np.float32(0.7833)] 
2025-01-08 04:04:49.708306: Epoch time: 43.42 s 
2025-01-08 04:04:50.274916:  
2025-01-08 04:04:50.274916: Epoch 271 
2025-01-08 04:04:50.279941: Current learning rate: 0.00495 
2025-01-08 04:05:33.679680: train_loss -0.7778 
2025-01-08 04:05:33.680684: val_loss -0.7061 
2025-01-08 04:05:33.685697: Pseudo dice [np.float32(0.7454)] 
2025-01-08 04:05:33.689704: Epoch time: 43.41 s 
2025-01-08 04:05:34.404170:  
2025-01-08 04:05:34.405169: Epoch 272 
2025-01-08 04:05:34.409753: Current learning rate: 0.00493 
2025-01-08 04:06:17.848754: train_loss -0.792 
2025-01-08 04:06:17.848754: val_loss -0.7117 
2025-01-08 04:06:17.854289: Pseudo dice [np.float32(0.782)] 
2025-01-08 04:06:17.858298: Epoch time: 43.44 s 
2025-01-08 04:06:18.424883:  
2025-01-08 04:06:18.424883: Epoch 273 
2025-01-08 04:06:18.430415: Current learning rate: 0.00491 
2025-01-08 04:07:01.828470: train_loss -0.7935 
2025-01-08 04:07:01.828973: val_loss -0.7516 
2025-01-08 04:07:01.833993: Pseudo dice [np.float32(0.8181)] 
2025-01-08 04:07:01.837505: Epoch time: 43.4 s 
2025-01-08 04:07:02.399687:  
2025-01-08 04:07:02.399687: Epoch 274 
2025-01-08 04:07:02.405753: Current learning rate: 0.00489 
2025-01-08 04:07:45.801345: train_loss -0.8127 
2025-01-08 04:07:45.802350: val_loss -0.7062 
2025-01-08 04:07:45.807873: Pseudo dice [np.float32(0.7401)] 
2025-01-08 04:07:45.811385: Epoch time: 43.4 s 
2025-01-08 04:07:46.373744:  
2025-01-08 04:07:46.373744: Epoch 275 
2025-01-08 04:07:46.379382: Current learning rate: 0.00487 
2025-01-08 04:08:29.747092: train_loss -0.8062 
2025-01-08 04:08:29.748595: val_loss -0.7091 
2025-01-08 04:08:29.755610: Pseudo dice [np.float32(0.7942)] 
2025-01-08 04:08:29.759623: Epoch time: 43.37 s 
2025-01-08 04:08:30.320488:  
2025-01-08 04:08:30.320989: Epoch 276 
2025-01-08 04:08:30.324605: Current learning rate: 0.00485 
2025-01-08 04:09:13.698388: train_loss -0.8116 
2025-01-08 04:09:13.699392: val_loss -0.7716 
2025-01-08 04:09:13.704945: Pseudo dice [np.float32(0.8219)] 
2025-01-08 04:09:13.707971: Epoch time: 43.38 s 
2025-01-08 04:09:13.710997: Yayy! New best EMA pseudo Dice: 0.7767999768257141 
2025-01-08 04:09:14.484482:  
2025-01-08 04:09:14.485484: Epoch 277 
2025-01-08 04:09:14.490515: Current learning rate: 0.00484 
2025-01-08 04:09:57.881695: train_loss -0.7897 
2025-01-08 04:09:57.882203: val_loss -0.7156 
2025-01-08 04:09:57.888278: Pseudo dice [np.float32(0.7894)] 
2025-01-08 04:09:57.891838: Epoch time: 43.4 s 
2025-01-08 04:09:57.894895: Yayy! New best EMA pseudo Dice: 0.7781000137329102 
2025-01-08 04:09:58.697543:  
2025-01-08 04:09:58.697543: Epoch 278 
2025-01-08 04:09:58.702576: Current learning rate: 0.00482 
2025-01-08 04:10:42.104870: train_loss -0.776 
2025-01-08 04:10:42.105869: val_loss -0.6835 
2025-01-08 04:10:42.113387: Pseudo dice [np.float32(0.7366)] 
2025-01-08 04:10:42.118399: Epoch time: 43.41 s 
2025-01-08 04:10:42.682492:  
2025-01-08 04:10:42.682492: Epoch 279 
2025-01-08 04:10:42.690038: Current learning rate: 0.0048 
2025-01-08 04:11:26.085639: train_loss -0.8112 
2025-01-08 04:11:26.085639: val_loss -0.6661 
2025-01-08 04:11:26.091664: Pseudo dice [np.float32(0.705)] 
2025-01-08 04:11:26.094678: Epoch time: 43.4 s 
2025-01-08 04:11:26.660228:  
2025-01-08 04:11:26.660731: Epoch 280 
2025-01-08 04:11:26.665747: Current learning rate: 0.00478 
2025-01-08 04:12:10.071634: train_loss -0.7928 
2025-01-08 04:12:10.072140: val_loss -0.5881 
2025-01-08 04:12:10.077715: Pseudo dice [np.float32(0.7221)] 
2025-01-08 04:12:10.081274: Epoch time: 43.41 s 
2025-01-08 04:12:10.807992:  
2025-01-08 04:12:10.808499: Epoch 281 
2025-01-08 04:12:10.815042: Current learning rate: 0.00476 
2025-01-08 04:12:54.199078: train_loss -0.785 
2025-01-08 04:12:54.199579: val_loss -0.6823 
2025-01-08 04:12:54.205635: Pseudo dice [np.float32(0.7457)] 
2025-01-08 04:12:54.208155: Epoch time: 43.39 s 
2025-01-08 04:12:54.774559:  
2025-01-08 04:12:54.774559: Epoch 282 
2025-01-08 04:12:54.779667: Current learning rate: 0.00474 
2025-01-08 04:13:38.163604: train_loss -0.7792 
2025-01-08 04:13:38.164106: val_loss -0.7725 
2025-01-08 04:13:38.170190: Pseudo dice [np.float32(0.8257)] 
2025-01-08 04:13:38.173221: Epoch time: 43.39 s 
2025-01-08 04:13:38.742026:  
2025-01-08 04:13:38.742541: Epoch 283 
2025-01-08 04:13:38.747585: Current learning rate: 0.00472 
2025-01-08 04:14:22.158774: train_loss -0.7477 
2025-01-08 04:14:22.160280: val_loss -0.7111 
2025-01-08 04:14:22.165836: Pseudo dice [np.float32(0.7799)] 
2025-01-08 04:14:22.168865: Epoch time: 43.42 s 
2025-01-08 04:14:22.732531:  
2025-01-08 04:14:22.733534: Epoch 284 
2025-01-08 04:14:22.738590: Current learning rate: 0.0047 
2025-01-08 04:15:06.157882: train_loss -0.7344 
2025-01-08 04:15:06.158389: val_loss -0.67 
2025-01-08 04:15:06.163433: Pseudo dice [np.float32(0.7333)] 
2025-01-08 04:15:06.166966: Epoch time: 43.43 s 
2025-01-08 04:15:06.726549:  
2025-01-08 04:15:06.726549: Epoch 285 
2025-01-08 04:15:06.731592: Current learning rate: 0.00468 
2025-01-08 04:15:50.151589: train_loss -0.7685 
2025-01-08 04:15:50.152590: val_loss -0.7388 
2025-01-08 04:15:50.158105: Pseudo dice [np.float32(0.784)] 
2025-01-08 04:15:50.162614: Epoch time: 43.43 s 
2025-01-08 04:15:50.723435:  
2025-01-08 04:15:50.723435: Epoch 286 
2025-01-08 04:15:50.728970: Current learning rate: 0.00466 
2025-01-08 04:16:34.126256: train_loss -0.802 
2025-01-08 04:16:34.127758: val_loss -0.6391 
2025-01-08 04:16:34.132771: Pseudo dice [np.float32(0.6805)] 
2025-01-08 04:16:34.135786: Epoch time: 43.4 s 
2025-01-08 04:16:34.711728:  
2025-01-08 04:16:34.712732: Epoch 287 
2025-01-08 04:16:34.717752: Current learning rate: 0.00464 
2025-01-08 04:17:18.105600: train_loss -0.7814 
2025-01-08 04:17:18.106109: val_loss -0.6783 
2025-01-08 04:17:18.111680: Pseudo dice [np.float32(0.6521)] 
2025-01-08 04:17:18.115216: Epoch time: 43.39 s 
2025-01-08 04:17:18.684708:  
2025-01-08 04:17:18.684708: Epoch 288 
2025-01-08 04:17:18.690237: Current learning rate: 0.00462 
2025-01-08 04:18:02.173401: train_loss -0.7546 
2025-01-08 04:18:02.173401: val_loss -0.7026 
2025-01-08 04:18:02.179417: Pseudo dice [np.float32(0.7726)] 
2025-01-08 04:18:02.182923: Epoch time: 43.49 s 
2025-01-08 04:18:02.761482:  
2025-01-08 04:18:02.761482: Epoch 289 
2025-01-08 04:18:02.767034: Current learning rate: 0.0046 
2025-01-08 04:18:46.234171: train_loss -0.7551 
2025-01-08 04:18:46.234680: val_loss -0.7012 
2025-01-08 04:18:46.239774: Pseudo dice [np.float32(0.6997)] 
2025-01-08 04:18:46.244318: Epoch time: 43.47 s 
2025-01-08 04:18:46.816277:  
2025-01-08 04:18:46.816277: Epoch 290 
2025-01-08 04:18:46.821288: Current learning rate: 0.00458 
2025-01-08 04:19:30.200674: train_loss -0.7826 
2025-01-08 04:19:30.201191: val_loss -0.6745 
2025-01-08 04:19:30.207216: Pseudo dice [np.float32(0.6382)] 
2025-01-08 04:19:30.210721: Epoch time: 43.38 s 
2025-01-08 04:19:30.780524:  
2025-01-08 04:19:30.781026: Epoch 291 
2025-01-08 04:19:30.786039: Current learning rate: 0.00456 
2025-01-08 04:20:14.181033: train_loss -0.7604 
2025-01-08 04:20:14.181536: val_loss -0.7376 
2025-01-08 04:20:14.185049: Pseudo dice [np.float32(0.7941)] 
2025-01-08 04:20:14.189066: Epoch time: 43.4 s 
2025-01-08 04:20:14.762946:  
2025-01-08 04:20:14.762946: Epoch 292 
2025-01-08 04:20:14.767975: Current learning rate: 0.00454 
2025-01-08 04:20:58.142164: train_loss -0.7666 
2025-01-08 04:20:58.142673: val_loss -0.772 
2025-01-08 04:20:58.148267: Pseudo dice [np.float32(0.7969)] 
2025-01-08 04:20:58.150774: Epoch time: 43.38 s 
2025-01-08 04:20:58.729022:  
2025-01-08 04:20:58.730021: Epoch 293 
2025-01-08 04:20:58.735606: Current learning rate: 0.00452 
2025-01-08 04:21:42.150211: train_loss -0.7703 
2025-01-08 04:21:42.151215: val_loss -0.6947 
2025-01-08 04:21:42.157847: Pseudo dice [np.float32(0.7601)] 
2025-01-08 04:21:42.162404: Epoch time: 43.42 s 
2025-01-08 04:21:42.730265:  
2025-01-08 04:21:42.731265: Epoch 294 
2025-01-08 04:21:42.734331: Current learning rate: 0.0045 
2025-01-08 04:22:26.134090: train_loss -0.7869 
2025-01-08 04:22:26.135095: val_loss -0.6661 
2025-01-08 04:22:26.140106: Pseudo dice [np.float32(0.7088)] 
2025-01-08 04:22:26.143618: Epoch time: 43.4 s 
2025-01-08 04:22:26.710575:  
2025-01-08 04:22:26.711089: Epoch 295 
2025-01-08 04:22:26.715626: Current learning rate: 0.00448 
2025-01-08 04:23:10.105264: train_loss -0.7865 
2025-01-08 04:23:10.106266: val_loss -0.7169 
2025-01-08 04:23:10.111288: Pseudo dice [np.float32(0.7498)] 
2025-01-08 04:23:10.114802: Epoch time: 43.4 s 
2025-01-08 04:23:10.686707:  
2025-01-08 04:23:10.686707: Epoch 296 
2025-01-08 04:23:10.691744: Current learning rate: 0.00446 
2025-01-08 04:23:54.082507: train_loss -0.7793 
2025-01-08 04:23:54.083009: val_loss -0.6357 
2025-01-08 04:23:54.090530: Pseudo dice [np.float32(0.6513)] 
2025-01-08 04:23:54.094040: Epoch time: 43.4 s 
2025-01-08 04:23:54.669580:  
2025-01-08 04:23:54.669580: Epoch 297 
2025-01-08 04:23:54.674596: Current learning rate: 0.00444 
2025-01-08 04:24:38.055608: train_loss -0.783 
2025-01-08 04:24:38.055608: val_loss -0.7196 
2025-01-08 04:24:38.061620: Pseudo dice [np.float32(0.7899)] 
2025-01-08 04:24:38.064628: Epoch time: 43.39 s 
2025-01-08 04:24:38.778405:  
2025-01-08 04:24:38.779405: Epoch 298 
2025-01-08 04:24:38.784921: Current learning rate: 0.00442 
2025-01-08 04:25:22.202147: train_loss -0.7774 
2025-01-08 04:25:22.202654: val_loss -0.7086 
2025-01-08 04:25:22.207706: Pseudo dice [np.float32(0.7889)] 
2025-01-08 04:25:22.211739: Epoch time: 43.42 s 
2025-01-08 04:25:22.786029:  
2025-01-08 04:25:22.786029: Epoch 299 
2025-01-08 04:25:22.791556: Current learning rate: 0.0044 
2025-01-08 04:26:06.192071: train_loss -0.781 
2025-01-08 04:26:06.192583: val_loss -0.6802 
2025-01-08 04:26:06.197634: Pseudo dice [np.float32(0.7221)] 
2025-01-08 04:26:06.201164: Epoch time: 43.41 s 
2025-01-08 04:26:07.043259:  
2025-01-08 04:26:07.043259: Epoch 300 
2025-01-08 04:26:07.048862: Current learning rate: 0.00438 
2025-01-08 04:26:50.420539: train_loss -0.7994 
2025-01-08 04:26:50.421539: val_loss -0.5488 
2025-01-08 04:26:50.427052: Pseudo dice [np.float32(0.6257)] 
2025-01-08 04:26:50.430562: Epoch time: 43.38 s 
2025-01-08 04:26:50.999192:  
2025-01-08 04:26:51.000195: Epoch 301 
2025-01-08 04:26:51.006248: Current learning rate: 0.00436 
2025-01-08 04:27:34.413862: train_loss -0.7787 
2025-01-08 04:27:34.414865: val_loss -0.7068 
2025-01-08 04:27:34.420022: Pseudo dice [np.float32(0.7622)] 
2025-01-08 04:27:34.423038: Epoch time: 43.41 s 
2025-01-08 04:27:34.992299:  
2025-01-08 04:27:34.992808: Epoch 302 
2025-01-08 04:27:34.998365: Current learning rate: 0.00434 
2025-01-08 04:28:18.425186: train_loss -0.7729 
2025-01-08 04:28:18.426190: val_loss -0.687 
2025-01-08 04:28:18.431714: Pseudo dice [np.float32(0.7574)] 
2025-01-08 04:28:18.434223: Epoch time: 43.43 s 
2025-01-08 04:28:19.004674:  
2025-01-08 04:28:19.005678: Epoch 303 
2025-01-08 04:28:19.010228: Current learning rate: 0.00432 
2025-01-08 04:29:02.445892: train_loss -0.7617 
2025-01-08 04:29:02.446895: val_loss -0.6248 
2025-01-08 04:29:02.452932: Pseudo dice [np.float32(0.6159)] 
2025-01-08 04:29:02.455960: Epoch time: 43.44 s 
2025-01-08 04:29:03.023305:  
2025-01-08 04:29:03.023305: Epoch 304 
2025-01-08 04:29:03.028341: Current learning rate: 0.0043 
2025-01-08 04:29:46.424365: train_loss -0.8045 
2025-01-08 04:29:46.424868: val_loss -0.7209 
2025-01-08 04:29:46.430486: Pseudo dice [np.float32(0.7804)] 
2025-01-08 04:29:46.433008: Epoch time: 43.4 s 
2025-01-08 04:29:47.009676:  
2025-01-08 04:29:47.009676: Epoch 305 
2025-01-08 04:29:47.015192: Current learning rate: 0.00429 
2025-01-08 04:30:30.420393: train_loss -0.788 
2025-01-08 04:30:30.421899: val_loss -0.737 
2025-01-08 04:30:30.426938: Pseudo dice [np.float32(0.7888)] 
2025-01-08 04:30:30.429961: Epoch time: 43.41 s 
2025-01-08 04:30:31.151342:  
2025-01-08 04:30:31.151342: Epoch 306 
2025-01-08 04:30:31.157401: Current learning rate: 0.00427 
2025-01-08 04:31:14.568393: train_loss -0.8029 
2025-01-08 04:31:14.569397: val_loss -0.7255 
2025-01-08 04:31:14.575004: Pseudo dice [np.float32(0.7696)] 
2025-01-08 04:31:14.578038: Epoch time: 43.42 s 
2025-01-08 04:31:15.150156:  
2025-01-08 04:31:15.150663: Epoch 307 
2025-01-08 04:31:15.155699: Current learning rate: 0.00425 
2025-01-08 04:31:58.540986: train_loss -0.8 
2025-01-08 04:31:58.541986: val_loss -0.7707 
2025-01-08 04:31:58.547501: Pseudo dice [np.float32(0.8197)] 
2025-01-08 04:31:58.551011: Epoch time: 43.39 s 
2025-01-08 04:31:59.120584:  
2025-01-08 04:31:59.121584: Epoch 308 
2025-01-08 04:31:59.126146: Current learning rate: 0.00423 
2025-01-08 04:32:42.541327: train_loss -0.8005 
2025-01-08 04:32:42.542327: val_loss -0.7082 
2025-01-08 04:32:42.547841: Pseudo dice [np.float32(0.7806)] 
2025-01-08 04:32:42.550910: Epoch time: 43.42 s 
2025-01-08 04:32:43.127527:  
2025-01-08 04:32:43.128530: Epoch 309 
2025-01-08 04:32:43.133073: Current learning rate: 0.00421 
2025-01-08 04:33:26.539252: train_loss -0.7876 
2025-01-08 04:33:26.540261: val_loss -0.6968 
2025-01-08 04:33:26.545329: Pseudo dice [np.float32(0.799)] 
2025-01-08 04:33:26.548872: Epoch time: 43.41 s 
2025-01-08 04:33:27.124079:  
2025-01-08 04:33:27.124079: Epoch 310 
2025-01-08 04:33:27.129626: Current learning rate: 0.00419 
2025-01-08 04:34:10.569430: train_loss -0.8149 
2025-01-08 04:34:10.569932: val_loss -0.709 
2025-01-08 04:34:10.575497: Pseudo dice [np.float32(0.8014)] 
2025-01-08 04:34:10.578039: Epoch time: 43.45 s 
2025-01-08 04:34:11.160424:  
2025-01-08 04:34:11.161428: Epoch 311 
2025-01-08 04:34:11.166508: Current learning rate: 0.00417 
2025-01-08 04:34:54.551082: train_loss -0.7947 
2025-01-08 04:34:54.551082: val_loss -0.7211 
2025-01-08 04:34:54.557096: Pseudo dice [np.float32(0.7697)] 
2025-01-08 04:34:54.560606: Epoch time: 43.39 s 
2025-01-08 04:34:55.145607:  
2025-01-08 04:34:55.146607: Epoch 312 
2025-01-08 04:34:55.151762: Current learning rate: 0.00415 
2025-01-08 04:35:38.576373: train_loss -0.7589 
2025-01-08 04:35:38.576891: val_loss -0.722 
2025-01-08 04:35:38.582508: Pseudo dice [np.float32(0.7527)] 
2025-01-08 04:35:38.586029: Epoch time: 43.43 s 
2025-01-08 04:35:39.164655:  
2025-01-08 04:35:39.165157: Epoch 313 
2025-01-08 04:35:39.170169: Current learning rate: 0.00413 
2025-01-08 04:36:22.599119: train_loss -0.7928 
2025-01-08 04:36:22.600122: val_loss -0.7422 
2025-01-08 04:36:22.606139: Pseudo dice [np.float32(0.7838)] 
2025-01-08 04:36:22.609147: Epoch time: 43.44 s 
2025-01-08 04:36:23.336828:  
2025-01-08 04:36:23.337829: Epoch 314 
2025-01-08 04:36:23.342852: Current learning rate: 0.00411 
2025-01-08 04:37:06.752363: train_loss -0.7946 
2025-01-08 04:37:06.752363: val_loss -0.7559 
2025-01-08 04:37:06.758937: Pseudo dice [np.float32(0.752)] 
2025-01-08 04:37:06.762013: Epoch time: 43.42 s 
2025-01-08 04:37:07.353567:  
2025-01-08 04:37:07.353567: Epoch 315 
2025-01-08 04:37:07.359110: Current learning rate: 0.00409 
2025-01-08 04:37:50.765369: train_loss -0.7906 
2025-01-08 04:37:50.765878: val_loss -0.7649 
2025-01-08 04:37:50.771944: Pseudo dice [np.float32(0.818)] 
2025-01-08 04:37:50.774474: Epoch time: 43.41 s 
2025-01-08 04:37:51.354290:  
2025-01-08 04:37:51.354290: Epoch 316 
2025-01-08 04:37:51.360326: Current learning rate: 0.00407 
2025-01-08 04:38:34.736564: train_loss -0.8026 
2025-01-08 04:38:34.737073: val_loss -0.6564 
2025-01-08 04:38:34.742141: Pseudo dice [np.float32(0.7135)] 
2025-01-08 04:38:34.746169: Epoch time: 43.38 s 
2025-01-08 04:38:35.316555:  
2025-01-08 04:38:35.317559: Epoch 317 
2025-01-08 04:38:35.322617: Current learning rate: 0.00405 
2025-01-08 04:39:18.775939: train_loss -0.7883 
2025-01-08 04:39:18.777440: val_loss -0.6951 
2025-01-08 04:39:18.783456: Pseudo dice [np.float32(0.7213)] 
2025-01-08 04:39:18.786470: Epoch time: 43.46 s 
2025-01-08 04:39:19.359869:  
2025-01-08 04:39:19.360371: Epoch 318 
2025-01-08 04:39:19.364881: Current learning rate: 0.00403 
2025-01-08 04:40:02.766098: train_loss -0.803 
2025-01-08 04:40:02.767160: val_loss -0.7523 
2025-01-08 04:40:02.772212: Pseudo dice [np.float32(0.7988)] 
2025-01-08 04:40:02.775740: Epoch time: 43.41 s 
2025-01-08 04:40:03.357965:  
2025-01-08 04:40:03.357965: Epoch 319 
2025-01-08 04:40:03.363511: Current learning rate: 0.00401 
2025-01-08 04:40:46.736112: train_loss -0.7913 
2025-01-08 04:40:46.736112: val_loss -0.6373 
2025-01-08 04:40:46.742132: Pseudo dice [np.float32(0.7165)] 
2025-01-08 04:40:46.745637: Epoch time: 43.38 s 
2025-01-08 04:40:47.325117:  
2025-01-08 04:40:47.325117: Epoch 320 
2025-01-08 04:40:47.330130: Current learning rate: 0.00399 
2025-01-08 04:41:30.736289: train_loss -0.7932 
2025-01-08 04:41:30.737290: val_loss -0.7493 
2025-01-08 04:41:30.742806: Pseudo dice [np.float32(0.8044)] 
2025-01-08 04:41:30.746316: Epoch time: 43.41 s 
2025-01-08 04:41:31.323132:  
2025-01-08 04:41:31.323634: Epoch 321 
2025-01-08 04:41:31.327144: Current learning rate: 0.00397 
2025-01-08 04:42:14.764881: train_loss -0.7886 
2025-01-08 04:42:14.764881: val_loss -0.7221 
2025-01-08 04:42:14.770896: Pseudo dice [np.float32(0.8061)] 
2025-01-08 04:42:14.774402: Epoch time: 43.44 s 
2025-01-08 04:42:15.349761:  
2025-01-08 04:42:15.349761: Epoch 322 
2025-01-08 04:42:15.354798: Current learning rate: 0.00395 
2025-01-08 04:42:58.775048: train_loss -0.7963 
2025-01-08 04:42:58.776051: val_loss -0.7101 
2025-01-08 04:42:58.781069: Pseudo dice [np.float32(0.7609)] 
2025-01-08 04:42:58.783582: Epoch time: 43.43 s 
2025-01-08 04:42:59.509272:  
2025-01-08 04:42:59.509272: Epoch 323 
2025-01-08 04:42:59.512781: Current learning rate: 0.00393 
2025-01-08 04:43:42.918355: train_loss -0.8083 
2025-01-08 04:43:42.918860: val_loss -0.7099 
2025-01-08 04:43:42.924946: Pseudo dice [np.float32(0.7728)] 
2025-01-08 04:43:42.927467: Epoch time: 43.41 s 
2025-01-08 04:43:43.503087:  
2025-01-08 04:43:43.504091: Epoch 324 
2025-01-08 04:43:43.508634: Current learning rate: 0.00391 
2025-01-08 04:44:26.897489: train_loss -0.7646 
2025-01-08 04:44:26.897489: val_loss -0.7589 
2025-01-08 04:44:26.903505: Pseudo dice [np.float32(0.8143)] 
2025-01-08 04:44:26.907025: Epoch time: 43.39 s 
2025-01-08 04:44:27.485750:  
2025-01-08 04:44:27.486252: Epoch 325 
2025-01-08 04:44:27.491264: Current learning rate: 0.00389 
2025-01-08 04:45:10.907882: train_loss -0.7913 
2025-01-08 04:45:10.908882: val_loss -0.7194 
2025-01-08 04:45:10.914397: Pseudo dice [np.float32(0.7947)] 
2025-01-08 04:45:10.917411: Epoch time: 43.42 s 
2025-01-08 04:45:11.494173:  
2025-01-08 04:45:11.494675: Epoch 326 
2025-01-08 04:45:11.499700: Current learning rate: 0.00387 
2025-01-08 04:45:54.894839: train_loss -0.8132 
2025-01-08 04:45:54.895342: val_loss -0.7835 
2025-01-08 04:45:54.900946: Pseudo dice [np.float32(0.8334)] 
2025-01-08 04:45:54.903968: Epoch time: 43.4 s 
2025-01-08 04:45:54.906473: Yayy! New best EMA pseudo Dice: 0.779699981212616 
2025-01-08 04:45:55.717372:  
2025-01-08 04:45:55.718376: Epoch 327 
2025-01-08 04:45:55.722924: Current learning rate: 0.00385 
2025-01-08 04:46:39.122077: train_loss -0.7937 
2025-01-08 04:46:39.123100: val_loss -0.6933 
2025-01-08 04:46:39.128186: Pseudo dice [np.float32(0.7818)] 
2025-01-08 04:46:39.131763: Epoch time: 43.4 s 
2025-01-08 04:46:39.134857: Yayy! New best EMA pseudo Dice: 0.7799000144004822 
2025-01-08 04:46:39.925256:  
2025-01-08 04:46:39.925760: Epoch 328 
2025-01-08 04:46:39.930772: Current learning rate: 0.00383 
2025-01-08 04:47:23.333117: train_loss -0.7864 
2025-01-08 04:47:23.338880: val_loss -0.7705 
2025-01-08 04:47:23.342471: Pseudo dice [np.float32(0.7954)] 
2025-01-08 04:47:23.345012: Epoch time: 43.41 s 
2025-01-08 04:47:23.348055: Yayy! New best EMA pseudo Dice: 0.7814000248908997 
2025-01-08 04:47:24.133886:  
2025-01-08 04:47:24.133886: Epoch 329 
2025-01-08 04:47:24.138947: Current learning rate: 0.00381 
2025-01-08 04:48:07.535709: train_loss -0.8144 
2025-01-08 04:48:07.536713: val_loss -0.7554 
2025-01-08 04:48:07.541728: Pseudo dice [np.float32(0.7837)] 
2025-01-08 04:48:07.545752: Epoch time: 43.4 s 
2025-01-08 04:48:07.548287: Yayy! New best EMA pseudo Dice: 0.7817000150680542 
2025-01-08 04:48:08.376565:  
2025-01-08 04:48:08.376565: Epoch 330 
2025-01-08 04:48:08.381538: Current learning rate: 0.00379 
2025-01-08 04:48:51.837765: train_loss -0.7961 
2025-01-08 04:48:51.838274: val_loss -0.6929 
2025-01-08 04:48:51.843946: Pseudo dice [np.float32(0.7192)] 
2025-01-08 04:48:51.847710: Epoch time: 43.46 s 
2025-01-08 04:48:52.582973:  
2025-01-08 04:48:52.582973: Epoch 331 
2025-01-08 04:48:52.587986: Current learning rate: 0.00377 
2025-01-08 04:49:36.017752: train_loss -0.8149 
2025-01-08 04:49:36.018256: val_loss -0.6915 
2025-01-08 04:49:36.024283: Pseudo dice [np.float32(0.6955)] 
2025-01-08 04:49:36.027793: Epoch time: 43.44 s 
2025-01-08 04:49:36.610032:  
2025-01-08 04:49:36.610032: Epoch 332 
2025-01-08 04:49:36.614544: Current learning rate: 0.00375 
2025-01-08 04:50:20.036465: train_loss -0.8152 
2025-01-08 04:50:20.036465: val_loss -0.7192 
2025-01-08 04:50:20.041571: Pseudo dice [np.float32(0.7911)] 
2025-01-08 04:50:20.046152: Epoch time: 43.43 s 
2025-01-08 04:50:20.648791:  
2025-01-08 04:50:20.648791: Epoch 333 
2025-01-08 04:50:20.654356: Current learning rate: 0.00373 
2025-01-08 04:51:04.097693: train_loss -0.8 
2025-01-08 04:51:04.098207: val_loss -0.6155 
2025-01-08 04:51:04.104812: Pseudo dice [np.float32(0.6784)] 
2025-01-08 04:51:04.107850: Epoch time: 43.45 s 
2025-01-08 04:51:04.679684:  
2025-01-08 04:51:04.679684: Epoch 334 
2025-01-08 04:51:04.685756: Current learning rate: 0.00371 
2025-01-08 04:51:48.118263: train_loss -0.7885 
2025-01-08 04:51:48.119773: val_loss -0.7242 
2025-01-08 04:51:48.125384: Pseudo dice [np.float32(0.8034)] 
2025-01-08 04:51:48.127890: Epoch time: 43.44 s 
2025-01-08 04:51:48.707912:  
2025-01-08 04:51:48.707912: Epoch 335 
2025-01-08 04:51:48.712929: Current learning rate: 0.00369 
2025-01-08 04:52:32.168332: train_loss -0.7433 
2025-01-08 04:52:32.169336: val_loss -0.7751 
2025-01-08 04:52:32.175427: Pseudo dice [np.float32(0.8241)] 
2025-01-08 04:52:32.178484: Epoch time: 43.46 s 
2025-01-08 04:52:32.755461:  
2025-01-08 04:52:32.756462: Epoch 336 
2025-01-08 04:52:32.761020: Current learning rate: 0.00367 
2025-01-08 04:53:16.192756: train_loss -0.785 
2025-01-08 04:53:16.192756: val_loss -0.7884 
2025-01-08 04:53:16.199379: Pseudo dice [np.float32(0.828)] 
2025-01-08 04:53:16.202890: Epoch time: 43.44 s 
2025-01-08 04:53:16.786800:  
2025-01-08 04:53:16.786800: Epoch 337 
2025-01-08 04:53:16.792351: Current learning rate: 0.00365 
2025-01-08 04:54:00.245126: train_loss -0.7543 
2025-01-08 04:54:00.246630: val_loss -0.6978 
2025-01-08 04:54:00.251674: Pseudo dice [np.float32(0.7367)] 
2025-01-08 04:54:00.255183: Epoch time: 43.46 s 
2025-01-08 04:54:00.836363:  
2025-01-08 04:54:00.836363: Epoch 338 
2025-01-08 04:54:00.841428: Current learning rate: 0.00363 
2025-01-08 04:54:44.225300: train_loss -0.7742 
2025-01-08 04:54:44.226300: val_loss -0.772 
2025-01-08 04:54:44.231330: Pseudo dice [np.float32(0.8147)] 
2025-01-08 04:54:44.235363: Epoch time: 43.39 s 
2025-01-08 04:54:44.963879:  
2025-01-08 04:54:44.964382: Epoch 339 
2025-01-08 04:54:44.969396: Current learning rate: 0.00361 
2025-01-08 04:55:28.367634: train_loss -0.7708 
2025-01-08 04:55:28.368638: val_loss -0.7921 
2025-01-08 04:55:28.374331: Pseudo dice [np.float32(0.8471)] 
2025-01-08 04:55:28.377843: Epoch time: 43.4 s 
2025-01-08 04:55:28.380349: Yayy! New best EMA pseudo Dice: 0.7838000059127808 
2025-01-08 04:55:29.230647:  
2025-01-08 04:55:29.231150: Epoch 340 
2025-01-08 04:55:29.234661: Current learning rate: 0.00359 
2025-01-08 04:56:12.654534: train_loss -0.8124 
2025-01-08 04:56:12.654534: val_loss -0.7293 
2025-01-08 04:56:12.660619: Pseudo dice [np.float32(0.7565)] 
2025-01-08 04:56:12.664151: Epoch time: 43.42 s 
2025-01-08 04:56:13.246898:  
2025-01-08 04:56:13.247402: Epoch 341 
2025-01-08 04:56:13.252418: Current learning rate: 0.00357 
2025-01-08 04:56:56.643234: train_loss -0.8112 
2025-01-08 04:56:56.644235: val_loss -0.7518 
2025-01-08 04:56:56.649755: Pseudo dice [np.float32(0.8099)] 
2025-01-08 04:56:56.653269: Epoch time: 43.4 s 
2025-01-08 04:56:56.656843: Yayy! New best EMA pseudo Dice: 0.7839999794960022 
2025-01-08 04:56:57.457273:  
2025-01-08 04:56:57.458276: Epoch 342 
2025-01-08 04:56:57.462903: Current learning rate: 0.00355 
2025-01-08 04:57:40.885332: train_loss -0.7739 
2025-01-08 04:57:40.885332: val_loss -0.6922 
2025-01-08 04:57:40.891850: Pseudo dice [np.float32(0.7684)] 
2025-01-08 04:57:40.894356: Epoch time: 43.43 s 
2025-01-08 04:57:41.484756:  
2025-01-08 04:57:41.485760: Epoch 343 
2025-01-08 04:57:41.490308: Current learning rate: 0.00353 
2025-01-08 04:58:24.910752: train_loss -0.7957 
2025-01-08 04:58:24.911263: val_loss -0.7175 
2025-01-08 04:58:24.916894: Pseudo dice [np.float32(0.7337)] 
2025-01-08 04:58:24.919608: Epoch time: 43.43 s 
2025-01-08 04:58:25.507930:  
2025-01-08 04:58:25.508930: Epoch 344 
2025-01-08 04:58:25.513943: Current learning rate: 0.00351 
2025-01-08 04:59:08.915138: train_loss -0.7971 
2025-01-08 04:59:08.915648: val_loss -0.6722 
2025-01-08 04:59:08.921730: Pseudo dice [np.float32(0.7191)] 
2025-01-08 04:59:08.924806: Epoch time: 43.41 s 
2025-01-08 04:59:09.519045:  
2025-01-08 04:59:09.519556: Epoch 345 
2025-01-08 04:59:09.524606: Current learning rate: 0.00349 
2025-01-08 04:59:52.910340: train_loss -0.8079 
2025-01-08 04:59:52.911341: val_loss -0.7026 
2025-01-08 04:59:52.919361: Pseudo dice [np.float32(0.7528)] 
2025-01-08 04:59:52.924426: Epoch time: 43.39 s 
2025-01-08 04:59:53.510663:  
2025-01-08 04:59:53.510663: Epoch 346 
2025-01-08 04:59:53.515739: Current learning rate: 0.00346 
2025-01-08 05:00:36.957048: train_loss -0.8015 
2025-01-08 05:00:36.957048: val_loss -0.6417 
2025-01-08 05:00:36.963563: Pseudo dice [np.float32(0.7082)] 
2025-01-08 05:00:36.966069: Epoch time: 43.45 s 
2025-01-08 05:00:37.717399:  
2025-01-08 05:00:37.718398: Epoch 347 
2025-01-08 05:00:37.723464: Current learning rate: 0.00344 
2025-01-08 05:01:21.145187: train_loss -0.7936 
2025-01-08 05:01:21.146692: val_loss -0.7013 
2025-01-08 05:01:21.151711: Pseudo dice [np.float32(0.7228)] 
2025-01-08 05:01:21.155266: Epoch time: 43.43 s 
2025-01-08 05:01:21.749004:  
2025-01-08 05:01:21.750008: Epoch 348 
2025-01-08 05:01:21.755128: Current learning rate: 0.00342 
2025-01-08 05:02:05.148343: train_loss -0.8122 
2025-01-08 05:02:05.148850: val_loss -0.6569 
2025-01-08 05:02:05.154974: Pseudo dice [np.float32(0.6939)] 
2025-01-08 05:02:05.158093: Epoch time: 43.4 s 
2025-01-08 05:02:05.749330:  
2025-01-08 05:02:05.749330: Epoch 349 
2025-01-08 05:02:05.754342: Current learning rate: 0.0034 
2025-01-08 05:02:49.194447: train_loss -0.8175 
2025-01-08 05:02:49.194447: val_loss -0.6782 
2025-01-08 05:02:49.200969: Pseudo dice [np.float32(0.7018)] 
2025-01-08 05:02:49.203476: Epoch time: 43.45 s 
2025-01-08 05:02:50.002444:  
2025-01-08 05:02:50.003448: Epoch 350 
2025-01-08 05:02:50.008405: Current learning rate: 0.00338 
2025-01-08 05:03:33.394806: train_loss -0.8138 
2025-01-08 05:03:33.395309: val_loss -0.678 
2025-01-08 05:03:33.400330: Pseudo dice [np.float32(0.7684)] 
2025-01-08 05:03:33.403840: Epoch time: 43.39 s 
2025-01-08 05:03:33.995918:  
2025-01-08 05:03:33.995918: Epoch 351 
2025-01-08 05:03:34.001000: Current learning rate: 0.00336 
2025-01-08 05:04:17.373172: train_loss -0.8169 
2025-01-08 05:04:17.373675: val_loss -0.7533 
2025-01-08 05:04:17.379239: Pseudo dice [np.float32(0.8205)] 
2025-01-08 05:04:17.382282: Epoch time: 43.38 s 
2025-01-08 05:04:17.967415:  
2025-01-08 05:04:17.968419: Epoch 352 
2025-01-08 05:04:17.973509: Current learning rate: 0.00334 
2025-01-08 05:05:01.373890: train_loss -0.7905 
2025-01-08 05:05:01.373890: val_loss -0.7852 
2025-01-08 05:05:01.380587: Pseudo dice [np.float32(0.8393)] 
2025-01-08 05:05:01.384095: Epoch time: 43.41 s 
2025-01-08 05:05:01.972206:  
2025-01-08 05:05:01.972206: Epoch 353 
2025-01-08 05:05:01.977333: Current learning rate: 0.00332 
2025-01-08 05:05:45.378608: train_loss -0.7885 
2025-01-08 05:05:45.379111: val_loss -0.6915 
2025-01-08 05:05:45.385129: Pseudo dice [np.float32(0.7398)] 
2025-01-08 05:05:45.388635: Epoch time: 43.41 s 
2025-01-08 05:05:45.989668:  
2025-01-08 05:05:45.989668: Epoch 354 
2025-01-08 05:05:45.994682: Current learning rate: 0.0033 
2025-01-08 05:06:29.373955: train_loss -0.7982 
2025-01-08 05:06:29.375459: val_loss -0.7204 
2025-01-08 05:06:29.380481: Pseudo dice [np.float32(0.7686)] 
2025-01-08 05:06:29.383994: Epoch time: 43.39 s 
2025-01-08 05:06:29.965750:  
2025-01-08 05:06:29.966253: Epoch 355 
2025-01-08 05:06:29.971292: Current learning rate: 0.00328 
2025-01-08 05:07:13.381227: train_loss -0.8191 
2025-01-08 05:07:13.381740: val_loss -0.7265 
2025-01-08 05:07:13.386816: Pseudo dice [np.float32(0.7857)] 
2025-01-08 05:07:13.390858: Epoch time: 43.42 s 
2025-01-08 05:07:14.129377:  
2025-01-08 05:07:14.129881: Epoch 356 
2025-01-08 05:07:14.136897: Current learning rate: 0.00326 
2025-01-08 05:07:57.545408: train_loss -0.8023 
2025-01-08 05:07:57.546425: val_loss -0.7273 
2025-01-08 05:07:57.553104: Pseudo dice [np.float32(0.7759)] 
2025-01-08 05:07:57.557117: Epoch time: 43.42 s 
2025-01-08 05:07:58.141897:  
2025-01-08 05:07:58.141897: Epoch 357 
2025-01-08 05:07:58.147447: Current learning rate: 0.00324 
2025-01-08 05:08:41.530833: train_loss -0.8043 
2025-01-08 05:08:41.531838: val_loss -0.6906 
2025-01-08 05:08:41.536853: Pseudo dice [np.float32(0.7792)] 
2025-01-08 05:08:41.540863: Epoch time: 43.39 s 
2025-01-08 05:08:42.129196:  
2025-01-08 05:08:42.130195: Epoch 358 
2025-01-08 05:08:42.135289: Current learning rate: 0.00322 
2025-01-08 05:09:25.521663: train_loss -0.822 
2025-01-08 05:09:25.522666: val_loss -0.7212 
2025-01-08 05:09:25.527194: Pseudo dice [np.float32(0.7844)] 
2025-01-08 05:09:25.531306: Epoch time: 43.39 s 
2025-01-08 05:09:26.108769:  
2025-01-08 05:09:26.109773: Epoch 359 
2025-01-08 05:09:26.114823: Current learning rate: 0.0032 
2025-01-08 05:10:09.522866: train_loss -0.8043 
2025-01-08 05:10:09.523867: val_loss -0.705 
2025-01-08 05:10:09.529384: Pseudo dice [np.float32(0.7552)] 
2025-01-08 05:10:09.533894: Epoch time: 43.41 s 
2025-01-08 05:10:10.112645:  
2025-01-08 05:10:10.112645: Epoch 360 
2025-01-08 05:10:10.118705: Current learning rate: 0.00318 
2025-01-08 05:10:53.494985: train_loss -0.8136 
2025-01-08 05:10:53.496016: val_loss -0.7555 
2025-01-08 05:10:53.501671: Pseudo dice [np.float32(0.8118)] 
2025-01-08 05:10:53.504211: Epoch time: 43.38 s 
2025-01-08 05:10:54.085672:  
2025-01-08 05:10:54.086676: Epoch 361 
2025-01-08 05:10:54.092215: Current learning rate: 0.00316 
2025-01-08 05:11:37.526651: train_loss -0.8082 
2025-01-08 05:11:37.527155: val_loss -0.7189 
2025-01-08 05:11:37.532840: Pseudo dice [np.float32(0.7654)] 
2025-01-08 05:11:37.536405: Epoch time: 43.44 s 
2025-01-08 05:11:38.115895:  
2025-01-08 05:11:38.115895: Epoch 362 
2025-01-08 05:11:38.121086: Current learning rate: 0.00314 
2025-01-08 05:12:21.568462: train_loss -0.816 
2025-01-08 05:12:21.569465: val_loss -0.7365 
2025-01-08 05:12:21.576985: Pseudo dice [np.float32(0.7655)] 
2025-01-08 05:12:21.580996: Epoch time: 43.45 s 
2025-01-08 05:12:22.169331:  
2025-01-08 05:12:22.170876: Epoch 363 
2025-01-08 05:12:22.175932: Current learning rate: 0.00312 
2025-01-08 05:13:05.566690: train_loss -0.7855 
2025-01-08 05:13:05.566690: val_loss -0.7177 
2025-01-08 05:13:05.572708: Pseudo dice [np.float32(0.7613)] 
2025-01-08 05:13:05.576215: Epoch time: 43.4 s 
2025-01-08 05:13:06.309556:  
2025-01-08 05:13:06.310556: Epoch 364 
2025-01-08 05:13:06.315628: Current learning rate: 0.0031 
2025-01-08 05:13:49.689533: train_loss -0.7956 
2025-01-08 05:13:49.690035: val_loss -0.6584 
2025-01-08 05:13:49.696329: Pseudo dice [np.float32(0.6977)] 
2025-01-08 05:13:49.699346: Epoch time: 43.38 s 
2025-01-08 05:13:50.278978:  
2025-01-08 05:13:50.279982: Epoch 365 
2025-01-08 05:13:50.284586: Current learning rate: 0.00308 
2025-01-08 05:14:33.710540: train_loss -0.7686 
2025-01-08 05:14:33.711051: val_loss -0.7382 
2025-01-08 05:14:33.716109: Pseudo dice [np.float32(0.7957)] 
2025-01-08 05:14:33.720136: Epoch time: 43.43 s 
2025-01-08 05:14:34.316700:  
2025-01-08 05:14:34.316700: Epoch 366 
2025-01-08 05:14:34.321750: Current learning rate: 0.00306 
2025-01-08 05:15:17.747717: train_loss -0.8315 
2025-01-08 05:15:17.747717: val_loss -0.6993 
2025-01-08 05:15:17.752263: Pseudo dice [np.float32(0.7634)] 
2025-01-08 05:15:17.755309: Epoch time: 43.43 s 
2025-01-08 05:15:18.356255:  
2025-01-08 05:15:18.357260: Epoch 367 
2025-01-08 05:15:18.362843: Current learning rate: 0.00304 
2025-01-08 05:16:01.811524: train_loss -0.8062 
2025-01-08 05:16:01.812524: val_loss -0.6853 
2025-01-08 05:16:01.818044: Pseudo dice [np.float32(0.7524)] 
2025-01-08 05:16:01.821555: Epoch time: 43.46 s 
2025-01-08 05:16:02.412164:  
2025-01-08 05:16:02.412164: Epoch 368 
2025-01-08 05:16:02.418179: Current learning rate: 0.00302 
2025-01-08 05:16:45.831143: train_loss -0.8103 
2025-01-08 05:16:45.831654: val_loss -0.7549 
2025-01-08 05:16:45.837250: Pseudo dice [np.float32(0.8151)] 
2025-01-08 05:16:45.840384: Epoch time: 43.42 s 
2025-01-08 05:16:46.429960:  
2025-01-08 05:16:46.429960: Epoch 369 
2025-01-08 05:16:46.436569: Current learning rate: 0.003 
2025-01-08 05:17:29.861696: train_loss -0.8091 
2025-01-08 05:17:29.862199: val_loss -0.732 
2025-01-08 05:17:29.868219: Pseudo dice [np.float32(0.7938)] 
2025-01-08 05:17:29.872230: Epoch time: 43.43 s 
2025-01-08 05:17:30.468911:  
2025-01-08 05:17:30.468911: Epoch 370 
2025-01-08 05:17:30.473923: Current learning rate: 0.00297 
2025-01-08 05:18:13.909957: train_loss -0.8191 
2025-01-08 05:18:13.910957: val_loss -0.7553 
2025-01-08 05:18:13.916471: Pseudo dice [np.float32(0.8198)] 
2025-01-08 05:18:13.919980: Epoch time: 43.44 s 
2025-01-08 05:18:14.513340:  
2025-01-08 05:18:14.513340: Epoch 371 
2025-01-08 05:18:14.518396: Current learning rate: 0.00295 
2025-01-08 05:18:57.941504: train_loss -0.8073 
2025-01-08 05:18:57.942010: val_loss -0.6789 
2025-01-08 05:18:57.948129: Pseudo dice [np.float32(0.7722)] 
2025-01-08 05:18:57.951693: Epoch time: 43.43 s 
2025-01-08 05:18:58.708988:  
2025-01-08 05:18:58.709992: Epoch 372 
2025-01-08 05:18:58.714547: Current learning rate: 0.00293 
2025-01-08 05:19:42.082785: train_loss -0.8182 
2025-01-08 05:19:42.083289: val_loss -0.6856 
2025-01-08 05:19:42.088851: Pseudo dice [np.float32(0.7768)] 
2025-01-08 05:19:42.091391: Epoch time: 43.37 s 
2025-01-08 05:19:42.683694:  
2025-01-08 05:19:42.684694: Epoch 373 
2025-01-08 05:19:42.690271: Current learning rate: 0.00291 
2025-01-08 05:20:26.099869: train_loss -0.8181 
2025-01-08 05:20:26.100373: val_loss -0.6971 
2025-01-08 05:20:26.106389: Pseudo dice [np.float32(0.7639)] 
2025-01-08 05:20:26.108896: Epoch time: 43.42 s 
2025-01-08 05:20:26.695812:  
2025-01-08 05:20:26.695812: Epoch 374 
2025-01-08 05:20:26.700824: Current learning rate: 0.00289 
2025-01-08 05:21:10.140285: train_loss -0.8123 
2025-01-08 05:21:10.141285: val_loss -0.7192 
2025-01-08 05:21:10.146799: Pseudo dice [np.float32(0.7386)] 
2025-01-08 05:21:10.150309: Epoch time: 43.44 s 
2025-01-08 05:21:10.799223:  
2025-01-08 05:21:10.800227: Epoch 375 
2025-01-08 05:21:10.804845: Current learning rate: 0.00287 
2025-01-08 05:21:54.242390: train_loss -0.8304 
2025-01-08 05:21:54.242895: val_loss -0.7328 
2025-01-08 05:21:54.248489: Pseudo dice [np.float32(0.7608)] 
2025-01-08 05:21:54.251518: Epoch time: 43.44 s 
2025-01-08 05:21:54.834509:  
2025-01-08 05:21:54.834509: Epoch 376 
2025-01-08 05:21:54.840109: Current learning rate: 0.00285 
2025-01-08 05:22:38.267465: train_loss -0.8263 
2025-01-08 05:22:38.267975: val_loss -0.6957 
2025-01-08 05:22:38.274055: Pseudo dice [np.float32(0.7463)] 
2025-01-08 05:22:38.277600: Epoch time: 43.43 s 
2025-01-08 05:22:38.867082:  
2025-01-08 05:22:38.867585: Epoch 377 
2025-01-08 05:22:38.872600: Current learning rate: 0.00283 
2025-01-08 05:23:22.319130: train_loss -0.8091 
2025-01-08 05:23:22.319634: val_loss -0.7332 
2025-01-08 05:23:22.325326: Pseudo dice [np.float32(0.802)] 
2025-01-08 05:23:22.328918: Epoch time: 43.45 s 
2025-01-08 05:23:22.914641:  
2025-01-08 05:23:22.915646: Epoch 378 
2025-01-08 05:23:22.920236: Current learning rate: 0.00281 
2025-01-08 05:24:06.350838: train_loss -0.8248 
2025-01-08 05:24:06.352340: val_loss -0.6439 
2025-01-08 05:24:06.358366: Pseudo dice [np.float32(0.7054)] 
2025-01-08 05:24:06.361877: Epoch time: 43.44 s 
2025-01-08 05:24:06.942555:  
2025-01-08 05:24:06.943058: Epoch 379 
2025-01-08 05:24:06.948071: Current learning rate: 0.00279 
2025-01-08 05:24:50.385765: train_loss -0.8243 
2025-01-08 05:24:50.386309: val_loss -0.7296 
2025-01-08 05:24:50.393129: Pseudo dice [np.float32(0.7731)] 
2025-01-08 05:24:50.395668: Epoch time: 43.44 s 
2025-01-08 05:24:51.128407:  
2025-01-08 05:24:51.128407: Epoch 380 
2025-01-08 05:24:51.134068: Current learning rate: 0.00277 
2025-01-08 05:25:34.560205: train_loss -0.8246 
2025-01-08 05:25:34.561210: val_loss -0.7386 
2025-01-08 05:25:34.567225: Pseudo dice [np.float32(0.7986)] 
2025-01-08 05:25:34.570236: Epoch time: 43.43 s 
2025-01-08 05:25:35.151059:  
2025-01-08 05:25:35.152063: Epoch 381 
2025-01-08 05:25:35.158102: Current learning rate: 0.00275 
2025-01-08 05:26:18.622379: train_loss -0.829 
2025-01-08 05:26:18.622885: val_loss -0.7141 
2025-01-08 05:26:18.628487: Pseudo dice [np.float32(0.7439)] 
2025-01-08 05:26:18.631752: Epoch time: 43.47 s 
2025-01-08 05:26:19.219462:  
2025-01-08 05:26:19.220466: Epoch 382 
2025-01-08 05:26:19.225574: Current learning rate: 0.00273 
2025-01-08 05:27:02.634870: train_loss -0.8238 
2025-01-08 05:27:02.636375: val_loss -0.7494 
2025-01-08 05:27:02.642153: Pseudo dice [np.float32(0.8097)] 
2025-01-08 05:27:02.645380: Epoch time: 43.42 s 
2025-01-08 05:27:03.232627:  
2025-01-08 05:27:03.232627: Epoch 383 
2025-01-08 05:27:03.238225: Current learning rate: 0.00271 
2025-01-08 05:27:46.660833: train_loss -0.8242 
2025-01-08 05:27:46.661343: val_loss -0.7416 
2025-01-08 05:27:46.668554: Pseudo dice [np.float32(0.7814)] 
2025-01-08 05:27:46.671858: Epoch time: 43.43 s 
2025-01-08 05:27:47.263065:  
2025-01-08 05:27:47.263065: Epoch 384 
2025-01-08 05:27:47.269102: Current learning rate: 0.00268 
2025-01-08 05:28:30.664915: train_loss -0.8134 
2025-01-08 05:28:30.665917: val_loss -0.7151 
2025-01-08 05:28:30.672045: Pseudo dice [np.float32(0.7657)] 
2025-01-08 05:28:30.675590: Epoch time: 43.4 s 
2025-01-08 05:28:31.265321:  
2025-01-08 05:28:31.265321: Epoch 385 
2025-01-08 05:28:31.269359: Current learning rate: 0.00266 
2025-01-08 05:29:14.733991: train_loss -0.8311 
2025-01-08 05:29:14.733991: val_loss -0.7889 
2025-01-08 05:29:14.740515: Pseudo dice [np.float32(0.807)] 
2025-01-08 05:29:14.744026: Epoch time: 43.47 s 
2025-01-08 05:29:15.343969:  
2025-01-08 05:29:15.344974: Epoch 386 
2025-01-08 05:29:15.349523: Current learning rate: 0.00264 
2025-01-08 05:29:58.749530: train_loss -0.8201 
2025-01-08 05:29:58.749530: val_loss -0.6083 
2025-01-08 05:29:58.756052: Pseudo dice [np.float32(0.6763)] 
2025-01-08 05:29:58.759563: Epoch time: 43.41 s 
2025-01-08 05:29:59.357249:  
2025-01-08 05:29:59.357249: Epoch 387 
2025-01-08 05:29:59.361272: Current learning rate: 0.00262 
2025-01-08 05:30:42.781188: train_loss -0.8298 
2025-01-08 05:30:42.781188: val_loss -0.727 
2025-01-08 05:30:42.787208: Pseudo dice [np.float32(0.7716)] 
2025-01-08 05:30:42.789714: Epoch time: 43.42 s 
2025-01-08 05:30:43.545025:  
2025-01-08 05:30:43.545025: Epoch 388 
2025-01-08 05:30:43.551041: Current learning rate: 0.0026 
2025-01-08 05:31:26.960700: train_loss -0.8054 
2025-01-08 05:31:26.960700: val_loss -0.7396 
2025-01-08 05:31:26.967835: Pseudo dice [np.float32(0.7711)] 
2025-01-08 05:31:26.971386: Epoch time: 43.42 s 
2025-01-08 05:31:27.588309:  
2025-01-08 05:31:27.588309: Epoch 389 
2025-01-08 05:31:27.593323: Current learning rate: 0.00258 
2025-01-08 05:32:11.041980: train_loss -0.8235 
2025-01-08 05:32:11.042482: val_loss -0.7198 
2025-01-08 05:32:11.048108: Pseudo dice [np.float32(0.7723)] 
2025-01-08 05:32:11.051170: Epoch time: 43.46 s 
2025-01-08 05:32:11.718531:  
2025-01-08 05:32:11.719534: Epoch 390 
2025-01-08 05:32:11.725121: Current learning rate: 0.00256 
2025-01-08 05:32:55.123008: train_loss -0.8093 
2025-01-08 05:32:55.124013: val_loss -0.7057 
2025-01-08 05:32:55.128592: Pseudo dice [np.float32(0.7721)] 
2025-01-08 05:32:55.131649: Epoch time: 43.4 s 
2025-01-08 05:32:55.731121:  
2025-01-08 05:32:55.731121: Epoch 391 
2025-01-08 05:32:55.736219: Current learning rate: 0.00254 
2025-01-08 05:33:39.183108: train_loss -0.8292 
2025-01-08 05:33:39.183611: val_loss -0.6718 
2025-01-08 05:33:39.189203: Pseudo dice [np.float32(0.7207)] 
2025-01-08 05:33:39.191740: Epoch time: 43.45 s 
2025-01-08 05:33:39.793499:  
2025-01-08 05:33:39.793499: Epoch 392 
2025-01-08 05:33:39.799520: Current learning rate: 0.00252 
2025-01-08 05:34:23.208170: train_loss -0.7862 
2025-01-08 05:34:23.208170: val_loss -0.6679 
2025-01-08 05:34:23.215214: Pseudo dice [np.float32(0.7413)] 
2025-01-08 05:34:23.218723: Epoch time: 43.42 s 
2025-01-08 05:34:23.822406:  
2025-01-08 05:34:23.822406: Epoch 393 
2025-01-08 05:34:23.827443: Current learning rate: 0.0025 
2025-01-08 05:35:07.240146: train_loss -0.8026 
2025-01-08 05:35:07.241652: val_loss -0.7391 
2025-01-08 05:35:07.246669: Pseudo dice [np.float32(0.8065)] 
2025-01-08 05:35:07.250207: Epoch time: 43.42 s 
2025-01-08 05:35:07.853421:  
2025-01-08 05:35:07.854425: Epoch 394 
2025-01-08 05:35:07.860002: Current learning rate: 0.00248 
2025-01-08 05:35:51.254323: train_loss -0.8014 
2025-01-08 05:35:51.254323: val_loss -0.6117 
2025-01-08 05:35:51.261384: Pseudo dice [np.float32(0.6795)] 
2025-01-08 05:35:51.264894: Epoch time: 43.4 s 
2025-01-08 05:35:52.011877:  
2025-01-08 05:35:52.012880: Epoch 395 
2025-01-08 05:35:52.019979: Current learning rate: 0.00245 
2025-01-08 05:36:35.390625: train_loss -0.8164 
2025-01-08 05:36:35.391626: val_loss -0.7413 
2025-01-08 05:36:35.397142: Pseudo dice [np.float32(0.8113)] 
2025-01-08 05:36:35.400651: Epoch time: 43.38 s 
2025-01-08 05:36:35.994251:  
2025-01-08 05:36:35.994757: Epoch 396 
2025-01-08 05:36:35.999871: Current learning rate: 0.00243 
2025-01-08 05:37:19.402144: train_loss -0.8008 
2025-01-08 05:37:19.402144: val_loss -0.6637 
2025-01-08 05:37:19.408159: Pseudo dice [np.float32(0.7303)] 
2025-01-08 05:37:19.412168: Epoch time: 43.41 s 
2025-01-08 05:37:20.002928:  
2025-01-08 05:37:20.002928: Epoch 397 
2025-01-08 05:37:20.006977: Current learning rate: 0.00241 
2025-01-08 05:38:03.420955: train_loss -0.8159 
2025-01-08 05:38:03.421959: val_loss -0.7022 
2025-01-08 05:38:03.426970: Pseudo dice [np.float32(0.762)] 
2025-01-08 05:38:03.430978: Epoch time: 43.42 s 
2025-01-08 05:38:04.029842:  
2025-01-08 05:38:04.029842: Epoch 398 
2025-01-08 05:38:04.035404: Current learning rate: 0.00239 
2025-01-08 05:38:47.466401: train_loss -0.7943 
2025-01-08 05:38:47.466921: val_loss -0.7242 
2025-01-08 05:38:47.471997: Pseudo dice [np.float32(0.7783)] 
2025-01-08 05:38:47.475582: Epoch time: 43.44 s 
2025-01-08 05:38:48.072195:  
2025-01-08 05:38:48.072195: Epoch 399 
2025-01-08 05:38:48.077735: Current learning rate: 0.00237 
2025-01-08 05:39:31.497203: train_loss -0.7899 
2025-01-08 05:39:31.498203: val_loss -0.6084 
2025-01-08 05:39:31.503716: Pseudo dice [np.float32(0.6237)] 
2025-01-08 05:39:31.506762: Epoch time: 43.43 s 
2025-01-08 05:39:32.312343:  
2025-01-08 05:39:32.312846: Epoch 400 
2025-01-08 05:39:32.317859: Current learning rate: 0.00235 
2025-01-08 05:40:15.746189: train_loss -0.7912 
2025-01-08 05:40:15.746189: val_loss -0.7443 
2025-01-08 05:40:15.752204: Pseudo dice [np.float32(0.8113)] 
2025-01-08 05:40:15.756212: Epoch time: 43.43 s 
2025-01-08 05:40:16.354378:  
2025-01-08 05:40:16.354378: Epoch 401 
2025-01-08 05:40:16.360475: Current learning rate: 0.00233 
2025-01-08 05:40:59.742985: train_loss -0.815 
2025-01-08 05:40:59.743490: val_loss -0.671 
2025-01-08 05:40:59.750041: Pseudo dice [np.float32(0.748)] 
2025-01-08 05:40:59.753577: Epoch time: 43.39 s 
2025-01-08 05:41:00.358283:  
2025-01-08 05:41:00.359286: Epoch 402 
2025-01-08 05:41:00.364860: Current learning rate: 0.00231 
2025-01-08 05:41:43.778372: train_loss -0.8063 
2025-01-08 05:41:43.778372: val_loss -0.6551 
2025-01-08 05:41:43.783942: Pseudo dice [np.float32(0.7325)] 
2025-01-08 05:41:43.787469: Epoch time: 43.42 s 
2025-01-08 05:41:44.535059:  
2025-01-08 05:41:44.535059: Epoch 403 
2025-01-08 05:41:44.540658: Current learning rate: 0.00229 
2025-01-08 05:42:27.962707: train_loss -0.8316 
2025-01-08 05:42:27.963706: val_loss -0.6869 
2025-01-08 05:42:27.969219: Pseudo dice [np.float32(0.7031)] 
2025-01-08 05:42:27.972727: Epoch time: 43.43 s 
2025-01-08 05:42:28.569422:  
2025-01-08 05:42:28.569924: Epoch 404 
2025-01-08 05:42:28.575495: Current learning rate: 0.00226 
2025-01-08 05:43:11.975811: train_loss -0.8193 
2025-01-08 05:43:11.975811: val_loss -0.7203 
2025-01-08 05:43:11.982323: Pseudo dice [np.float32(0.7647)] 
2025-01-08 05:43:11.985836: Epoch time: 43.41 s 
2025-01-08 05:43:12.586930:  
2025-01-08 05:43:12.587433: Epoch 405 
2025-01-08 05:43:12.592445: Current learning rate: 0.00224 
2025-01-08 05:43:55.967365: train_loss -0.8274 
2025-01-08 05:43:55.968368: val_loss -0.7516 
2025-01-08 05:43:55.973885: Pseudo dice [np.float32(0.8116)] 
2025-01-08 05:43:55.977394: Epoch time: 43.38 s 
2025-01-08 05:43:56.579856:  
2025-01-08 05:43:56.579856: Epoch 406 
2025-01-08 05:43:56.585953: Current learning rate: 0.00222 
2025-01-08 05:44:39.973844: train_loss -0.8172 
2025-01-08 05:44:39.974856: val_loss -0.7517 
2025-01-08 05:44:39.979892: Pseudo dice [np.float32(0.7908)] 
2025-01-08 05:44:39.984424: Epoch time: 43.39 s 
2025-01-08 05:44:40.585867:  
2025-01-08 05:44:40.585867: Epoch 407 
2025-01-08 05:44:40.591434: Current learning rate: 0.0022 
2025-01-08 05:45:23.993876: train_loss -0.8245 
2025-01-08 05:45:23.994879: val_loss -0.7436 
2025-01-08 05:45:24.000931: Pseudo dice [np.float32(0.8034)] 
2025-01-08 05:45:24.003955: Epoch time: 43.41 s 
2025-01-08 05:45:24.603846:  
2025-01-08 05:45:24.603846: Epoch 408 
2025-01-08 05:45:24.609952: Current learning rate: 0.00218 
2025-01-08 05:46:07.995948: train_loss -0.8281 
2025-01-08 05:46:07.996461: val_loss -0.7077 
2025-01-08 05:46:08.001506: Pseudo dice [np.float32(0.7768)] 
2025-01-08 05:46:08.005050: Epoch time: 43.39 s 
2025-01-08 05:46:08.599616:  
2025-01-08 05:46:08.599616: Epoch 409 
2025-01-08 05:46:08.605129: Current learning rate: 0.00216 
2025-01-08 05:46:52.019286: train_loss -0.8262 
2025-01-08 05:46:52.020289: val_loss -0.7384 
2025-01-08 05:46:52.027804: Pseudo dice [np.float32(0.7907)] 
2025-01-08 05:46:52.031310: Epoch time: 43.42 s 
2025-01-08 05:46:52.622089:  
2025-01-08 05:46:52.622089: Epoch 410 
2025-01-08 05:46:52.627099: Current learning rate: 0.00214 
2025-01-08 05:47:36.041378: train_loss -0.8208 
2025-01-08 05:47:36.041378: val_loss -0.6822 
2025-01-08 05:47:36.047893: Pseudo dice [np.float32(0.7688)] 
2025-01-08 05:47:36.051401: Epoch time: 43.42 s 
2025-01-08 05:47:36.763083:  
2025-01-08 05:47:36.764083: Epoch 411 
2025-01-08 05:47:36.769148: Current learning rate: 0.00212 
2025-01-08 05:48:20.159018: train_loss -0.8281 
2025-01-08 05:48:20.160525: val_loss -0.762 
2025-01-08 05:48:20.166212: Pseudo dice [np.float32(0.8151)] 
2025-01-08 05:48:20.169726: Epoch time: 43.4 s 
2025-01-08 05:48:20.737313:  
2025-01-08 05:48:20.738317: Epoch 412 
2025-01-08 05:48:20.742872: Current learning rate: 0.00209 
2025-01-08 05:49:04.160450: train_loss -0.8245 
2025-01-08 05:49:04.161453: val_loss -0.6983 
2025-01-08 05:49:04.167464: Pseudo dice [np.float32(0.7584)] 
2025-01-08 05:49:04.170982: Epoch time: 43.42 s 
2025-01-08 05:49:04.734667:  
2025-01-08 05:49:04.735170: Epoch 413 
2025-01-08 05:49:04.742293: Current learning rate: 0.00207 
2025-01-08 05:49:48.195998: train_loss -0.832 
2025-01-08 05:49:48.197504: val_loss -0.7499 
2025-01-08 05:49:48.203047: Pseudo dice [np.float32(0.7848)] 
2025-01-08 05:49:48.208590: Epoch time: 43.46 s 
2025-01-08 05:49:48.770543:  
2025-01-08 05:49:48.770543: Epoch 414 
2025-01-08 05:49:48.776080: Current learning rate: 0.00205 
2025-01-08 05:50:32.208631: train_loss -0.8268 
2025-01-08 05:50:32.208631: val_loss -0.7911 
2025-01-08 05:50:32.214646: Pseudo dice [np.float32(0.829)] 
2025-01-08 05:50:32.218674: Epoch time: 43.44 s 
2025-01-08 05:50:32.784112:  
2025-01-08 05:50:32.785115: Epoch 415 
2025-01-08 05:50:32.790126: Current learning rate: 0.00203 
2025-01-08 05:51:16.202933: train_loss -0.8226 
2025-01-08 05:51:16.203437: val_loss -0.7049 
2025-01-08 05:51:16.209032: Pseudo dice [np.float32(0.7529)] 
2025-01-08 05:51:16.213118: Epoch time: 43.42 s 
2025-01-08 05:51:16.779222:  
2025-01-08 05:51:16.780226: Epoch 416 
2025-01-08 05:51:16.785321: Current learning rate: 0.00201 
2025-01-08 05:52:00.176289: train_loss -0.8284 
2025-01-08 05:52:00.176289: val_loss -0.7318 
2025-01-08 05:52:00.182316: Pseudo dice [np.float32(0.7746)] 
2025-01-08 05:52:00.185823: Epoch time: 43.4 s 
2025-01-08 05:52:00.758138:  
2025-01-08 05:52:00.758138: Epoch 417 
2025-01-08 05:52:00.763671: Current learning rate: 0.00199 
2025-01-08 05:52:44.193819: train_loss -0.8338 
2025-01-08 05:52:44.194834: val_loss -0.6761 
2025-01-08 05:52:44.199881: Pseudo dice [np.float32(0.7375)] 
2025-01-08 05:52:44.203905: Epoch time: 43.44 s 
2025-01-08 05:52:44.771893:  
2025-01-08 05:52:44.771893: Epoch 418 
2025-01-08 05:52:44.776906: Current learning rate: 0.00196 
2025-01-08 05:53:28.153552: train_loss -0.809 
2025-01-08 05:53:28.155581: val_loss -0.6975 
2025-01-08 05:53:28.160661: Pseudo dice [np.float32(0.7584)] 
2025-01-08 05:53:28.164171: Epoch time: 43.38 s 
2025-01-08 05:53:28.878940:  
2025-01-08 05:53:28.879443: Epoch 419 
2025-01-08 05:53:28.884455: Current learning rate: 0.00194 
2025-01-08 05:54:12.263735: train_loss -0.8323 
2025-01-08 05:54:12.264738: val_loss -0.72 
2025-01-08 05:54:12.270404: Pseudo dice [np.float32(0.7764)] 
2025-01-08 05:54:12.272910: Epoch time: 43.39 s 
2025-01-08 05:54:12.855068:  
2025-01-08 05:54:12.855581: Epoch 420 
2025-01-08 05:54:12.861224: Current learning rate: 0.00192 
2025-01-08 05:54:56.235343: train_loss -0.8256 
2025-01-08 05:54:56.235343: val_loss -0.6968 
2025-01-08 05:54:56.241904: Pseudo dice [np.float32(0.7684)] 
2025-01-08 05:54:56.245450: Epoch time: 43.38 s 
2025-01-08 05:54:56.810534:  
2025-01-08 05:54:56.811044: Epoch 421 
2025-01-08 05:54:56.816616: Current learning rate: 0.0019 
2025-01-08 05:55:40.190543: train_loss -0.8227 
2025-01-08 05:55:40.191057: val_loss -0.6841 
2025-01-08 05:55:40.196138: Pseudo dice [np.float32(0.7246)] 
2025-01-08 05:55:40.200673: Epoch time: 43.38 s 
2025-01-08 05:55:40.770265:  
2025-01-08 05:55:40.771269: Epoch 422 
2025-01-08 05:55:40.776867: Current learning rate: 0.00188 
2025-01-08 05:56:24.197539: train_loss -0.8237 
2025-01-08 05:56:24.197539: val_loss -0.7647 
2025-01-08 05:56:24.204051: Pseudo dice [np.float32(0.8271)] 
2025-01-08 05:56:24.206558: Epoch time: 43.43 s 
2025-01-08 05:56:24.766924:  
2025-01-08 05:56:24.767924: Epoch 423 
2025-01-08 05:56:24.772003: Current learning rate: 0.00186 
2025-01-08 05:57:08.182559: train_loss -0.8317 
2025-01-08 05:57:08.183067: val_loss -0.6974 
2025-01-08 05:57:08.188662: Pseudo dice [np.float32(0.7164)] 
2025-01-08 05:57:08.191684: Epoch time: 43.42 s 
2025-01-08 05:57:08.754848:  
2025-01-08 05:57:08.754848: Epoch 424 
2025-01-08 05:57:08.760905: Current learning rate: 0.00184 
2025-01-08 05:57:52.181064: train_loss -0.8276 
2025-01-08 05:57:52.181567: val_loss -0.7055 
2025-01-08 05:57:52.185606: Pseudo dice [np.float32(0.7664)] 
2025-01-08 05:57:52.189128: Epoch time: 43.43 s 
2025-01-08 05:57:52.750068:  
2025-01-08 05:57:52.750068: Epoch 425 
2025-01-08 05:57:52.756129: Current learning rate: 0.00181 
2025-01-08 05:58:36.127007: train_loss -0.8344 
2025-01-08 05:58:36.128011: val_loss -0.7734 
2025-01-08 05:58:36.134020: Pseudo dice [np.float32(0.8277)] 
2025-01-08 05:58:36.137028: Epoch time: 43.38 s 
2025-01-08 05:58:36.702846:  
2025-01-08 05:58:36.703846: Epoch 426 
2025-01-08 05:58:36.708402: Current learning rate: 0.00179 
2025-01-08 05:59:20.125739: train_loss -0.8353 
2025-01-08 05:59:20.126242: val_loss -0.7472 
2025-01-08 05:59:20.132292: Pseudo dice [np.float32(0.7773)] 
2025-01-08 05:59:20.134809: Epoch time: 43.42 s 
2025-01-08 05:59:20.705875:  
2025-01-08 05:59:20.706879: Epoch 427 
2025-01-08 05:59:20.711439: Current learning rate: 0.00177 
2025-01-08 06:00:04.157964: train_loss -0.8367 
2025-01-08 06:00:04.157964: val_loss -0.757 
2025-01-08 06:00:04.163975: Pseudo dice [np.float32(0.82)] 
2025-01-08 06:00:04.166983: Epoch time: 43.45 s 
2025-01-08 06:00:04.875558:  
2025-01-08 06:00:04.876561: Epoch 428 
2025-01-08 06:00:04.881111: Current learning rate: 0.00175 
2025-01-08 06:00:48.282455: train_loss -0.8445 
2025-01-08 06:00:48.283470: val_loss -0.6421 
2025-01-08 06:00:48.289037: Pseudo dice [np.float32(0.7157)] 
2025-01-08 06:00:48.292080: Epoch time: 43.41 s 
2025-01-08 06:00:48.856216:  
2025-01-08 06:00:48.856721: Epoch 429 
2025-01-08 06:00:48.862299: Current learning rate: 0.00173 
2025-01-08 06:01:32.275369: train_loss -0.8278 
2025-01-08 06:01:32.275872: val_loss -0.7622 
2025-01-08 06:01:32.281894: Pseudo dice [np.float32(0.8106)] 
2025-01-08 06:01:32.285405: Epoch time: 43.42 s 
2025-01-08 06:01:32.846347:  
2025-01-08 06:01:32.847350: Epoch 430 
2025-01-08 06:01:32.851911: Current learning rate: 0.0017 
2025-01-08 06:02:16.306327: train_loss -0.8255 
2025-01-08 06:02:16.307330: val_loss -0.6626 
2025-01-08 06:02:16.312374: Pseudo dice [np.float32(0.679)] 
2025-01-08 06:02:16.315440: Epoch time: 43.46 s 
2025-01-08 06:02:16.874345:  
2025-01-08 06:02:16.874345: Epoch 431 
2025-01-08 06:02:16.879904: Current learning rate: 0.00168 
2025-01-08 06:03:00.320640: train_loss -0.833 
2025-01-08 06:03:00.321142: val_loss -0.7742 
2025-01-08 06:03:00.327251: Pseudo dice [np.float32(0.8168)] 
2025-01-08 06:03:00.330796: Epoch time: 43.45 s 
2025-01-08 06:03:00.897400:  
2025-01-08 06:03:00.898400: Epoch 432 
2025-01-08 06:03:00.903460: Current learning rate: 0.00166 
2025-01-08 06:03:44.346727: train_loss -0.8397 
2025-01-08 06:03:44.347729: val_loss -0.7329 
2025-01-08 06:03:44.353287: Pseudo dice [np.float32(0.798)] 
2025-01-08 06:03:44.356835: Epoch time: 43.45 s 
2025-01-08 06:03:44.916682:  
2025-01-08 06:03:44.916682: Epoch 433 
2025-01-08 06:03:44.922709: Current learning rate: 0.00164 
2025-01-08 06:04:28.292497: train_loss -0.8223 
2025-01-08 06:04:28.293003: val_loss -0.7406 
2025-01-08 06:04:28.298549: Pseudo dice [np.float32(0.808)] 
2025-01-08 06:04:28.302113: Epoch time: 43.38 s 
2025-01-08 06:04:28.862168:  
2025-01-08 06:04:28.862168: Epoch 434 
2025-01-08 06:04:28.867705: Current learning rate: 0.00162 
2025-01-08 06:05:12.298316: train_loss -0.8182 
2025-01-08 06:05:12.299319: val_loss -0.7178 
2025-01-08 06:05:12.305387: Pseudo dice [np.float32(0.7949)] 
2025-01-08 06:05:12.308415: Epoch time: 43.44 s 
2025-01-08 06:05:12.863956:  
2025-01-08 06:05:12.864959: Epoch 435 
2025-01-08 06:05:12.869519: Current learning rate: 0.00159 
2025-01-08 06:05:56.306414: train_loss -0.8245 
2025-01-08 06:05:56.306924: val_loss -0.6957 
2025-01-08 06:05:56.312505: Pseudo dice [np.float32(0.7484)] 
2025-01-08 06:05:56.316056: Epoch time: 43.44 s 
2025-01-08 06:05:56.876312:  
2025-01-08 06:05:56.877312: Epoch 436 
2025-01-08 06:05:56.880364: Current learning rate: 0.00157 
2025-01-08 06:06:40.258199: train_loss -0.8307 
2025-01-08 06:06:40.258708: val_loss -0.7207 
2025-01-08 06:06:40.263754: Pseudo dice [np.float32(0.7563)] 
2025-01-08 06:06:40.267298: Epoch time: 43.38 s 
2025-01-08 06:06:40.979186:  
2025-01-08 06:06:40.979186: Epoch 437 
2025-01-08 06:06:40.984698: Current learning rate: 0.00155 
2025-01-08 06:07:24.368260: train_loss -0.8401 
2025-01-08 06:07:24.369260: val_loss -0.6967 
2025-01-08 06:07:24.374891: Pseudo dice [np.float32(0.7367)] 
2025-01-08 06:07:24.378431: Epoch time: 43.39 s 
2025-01-08 06:07:24.932685:  
2025-01-08 06:07:24.932685: Epoch 438 
2025-01-08 06:07:24.938248: Current learning rate: 0.00153 
2025-01-08 06:08:08.316207: train_loss -0.8242 
2025-01-08 06:08:08.317710: val_loss -0.6687 
2025-01-08 06:08:08.323725: Pseudo dice [np.float32(0.6991)] 
2025-01-08 06:08:08.326230: Epoch time: 43.38 s 
2025-01-08 06:08:08.887337:  
2025-01-08 06:08:08.887337: Epoch 439 
2025-01-08 06:08:08.892347: Current learning rate: 0.00151 
2025-01-08 06:08:52.313205: train_loss -0.8155 
2025-01-08 06:08:52.313708: val_loss -0.7233 
2025-01-08 06:08:52.319254: Pseudo dice [np.float32(0.7855)] 
2025-01-08 06:08:52.322773: Epoch time: 43.43 s 
2025-01-08 06:08:52.880827:  
2025-01-08 06:08:52.881831: Epoch 440 
2025-01-08 06:08:52.886387: Current learning rate: 0.00148 
2025-01-08 06:09:36.270176: train_loss -0.8097 
2025-01-08 06:09:36.271185: val_loss -0.7617 
2025-01-08 06:09:36.276842: Pseudo dice [np.float32(0.8219)] 
2025-01-08 06:09:36.279881: Epoch time: 43.39 s 
2025-01-08 06:09:36.841328:  
2025-01-08 06:09:36.841831: Epoch 441 
2025-01-08 06:09:36.847386: Current learning rate: 0.00146 
2025-01-08 06:10:20.285822: train_loss -0.8428 
2025-01-08 06:10:20.286334: val_loss -0.7518 
2025-01-08 06:10:20.292980: Pseudo dice [np.float32(0.7688)] 
2025-01-08 06:10:20.296109: Epoch time: 43.45 s 
2025-01-08 06:10:20.868243:  
2025-01-08 06:10:20.868243: Epoch 442 
2025-01-08 06:10:20.874806: Current learning rate: 0.00144 
2025-01-08 06:11:04.253937: train_loss -0.8368 
2025-01-08 06:11:04.254447: val_loss -0.7643 
2025-01-08 06:11:04.260491: Pseudo dice [np.float32(0.8155)] 
2025-01-08 06:11:04.263511: Epoch time: 43.39 s 
2025-01-08 06:11:04.819995:  
2025-01-08 06:11:04.820999: Epoch 443 
2025-01-08 06:11:04.825565: Current learning rate: 0.00142 
2025-01-08 06:11:48.213709: train_loss -0.8279 
2025-01-08 06:11:48.213709: val_loss -0.7093 
2025-01-08 06:11:48.220223: Pseudo dice [np.float32(0.7636)] 
2025-01-08 06:11:48.223732: Epoch time: 43.39 s 
2025-01-08 06:11:48.779188:  
2025-01-08 06:11:48.780187: Epoch 444 
2025-01-08 06:11:48.785822: Current learning rate: 0.00139 
2025-01-08 06:12:32.144844: train_loss -0.8145 
2025-01-08 06:12:32.145346: val_loss -0.6979 
2025-01-08 06:12:32.151976: Pseudo dice [np.float32(0.7668)] 
2025-01-08 06:12:32.155029: Epoch time: 43.37 s 
2025-01-08 06:12:32.709397:  
2025-01-08 06:12:32.710401: Epoch 445 
2025-01-08 06:12:32.714967: Current learning rate: 0.00137 
2025-01-08 06:13:16.119464: train_loss -0.8566 
2025-01-08 06:13:16.120470: val_loss -0.7019 
2025-01-08 06:13:16.126981: Pseudo dice [np.float32(0.7775)] 
2025-01-08 06:13:16.130489: Epoch time: 43.41 s 
2025-01-08 06:13:16.841081:  
2025-01-08 06:13:16.841081: Epoch 446 
2025-01-08 06:13:16.846093: Current learning rate: 0.00135 
2025-01-08 06:14:00.254511: train_loss -0.8287 
2025-01-08 06:14:00.254511: val_loss -0.7551 
2025-01-08 06:14:00.261026: Pseudo dice [np.float32(0.8318)] 
2025-01-08 06:14:00.264536: Epoch time: 43.41 s 
2025-01-08 06:14:00.825978:  
2025-01-08 06:14:00.826977: Epoch 447 
2025-01-08 06:14:00.832032: Current learning rate: 0.00133 
2025-01-08 06:14:44.196973: train_loss -0.8294 
2025-01-08 06:14:44.198480: val_loss -0.7749 
2025-01-08 06:14:44.204091: Pseudo dice [np.float32(0.7973)] 
2025-01-08 06:14:44.207607: Epoch time: 43.37 s 
2025-01-08 06:14:44.766841:  
2025-01-08 06:14:44.767845: Epoch 448 
2025-01-08 06:14:44.772932: Current learning rate: 0.0013 
2025-01-08 06:15:28.153621: train_loss -0.8331 
2025-01-08 06:15:28.154134: val_loss -0.6727 
2025-01-08 06:15:28.160768: Pseudo dice [np.float32(0.7163)] 
2025-01-08 06:15:28.164963: Epoch time: 43.39 s 
2025-01-08 06:15:28.720642:  
2025-01-08 06:15:28.720642: Epoch 449 
2025-01-08 06:15:28.727160: Current learning rate: 0.00128 
2025-01-08 06:16:12.101313: train_loss -0.8336 
2025-01-08 06:16:12.101822: val_loss -0.7278 
2025-01-08 06:16:12.107858: Pseudo dice [np.float32(0.7772)] 
2025-01-08 06:16:12.110881: Epoch time: 43.38 s 
2025-01-08 06:16:12.883235:  
2025-01-08 06:16:12.884233: Epoch 450 
2025-01-08 06:16:12.889295: Current learning rate: 0.00126 
2025-01-08 06:16:56.270367: train_loss -0.8451 
2025-01-08 06:16:56.271367: val_loss -0.682 
2025-01-08 06:16:56.276884: Pseudo dice [np.float32(0.7202)] 
2025-01-08 06:16:56.280396: Epoch time: 43.39 s 
2025-01-08 06:16:56.831808:  
2025-01-08 06:16:56.832808: Epoch 451 
2025-01-08 06:16:56.837357: Current learning rate: 0.00124 
2025-01-08 06:17:40.266817: train_loss -0.8511 
2025-01-08 06:17:40.266817: val_loss -0.7336 
2025-01-08 06:17:40.272833: Pseudo dice [np.float32(0.7863)] 
2025-01-08 06:17:40.276844: Epoch time: 43.44 s 
2025-01-08 06:17:40.830819:  
2025-01-08 06:17:40.830819: Epoch 452 
2025-01-08 06:17:40.837383: Current learning rate: 0.00121 
2025-01-08 06:18:24.256694: train_loss -0.8236 
2025-01-08 06:18:24.257203: val_loss -0.714 
2025-01-08 06:18:24.262732: Pseudo dice [np.float32(0.7356)] 
2025-01-08 06:18:24.266247: Epoch time: 43.43 s 
2025-01-08 06:18:24.822176:  
2025-01-08 06:18:24.822176: Epoch 453 
2025-01-08 06:18:24.827244: Current learning rate: 0.00119 
2025-01-08 06:19:08.244073: train_loss -0.8505 
2025-01-08 06:19:08.244622: val_loss -0.7437 
2025-01-08 06:19:08.250386: Pseudo dice [np.float32(0.8105)] 
2025-01-08 06:19:08.253448: Epoch time: 43.42 s 
2025-01-08 06:19:08.954334:  
2025-01-08 06:19:08.955334: Epoch 454 
2025-01-08 06:19:08.960400: Current learning rate: 0.00117 
2025-01-08 06:19:52.374859: train_loss -0.8281 
2025-01-08 06:19:52.375362: val_loss -0.7441 
2025-01-08 06:19:52.382883: Pseudo dice [np.float32(0.8054)] 
2025-01-08 06:19:52.385900: Epoch time: 43.42 s 
2025-01-08 06:19:52.945443:  
2025-01-08 06:19:52.945443: Epoch 455 
2025-01-08 06:19:52.951081: Current learning rate: 0.00115 
2025-01-08 06:20:36.353435: train_loss -0.8492 
2025-01-08 06:20:36.353435: val_loss -0.7761 
2025-01-08 06:20:36.359952: Pseudo dice [np.float32(0.8381)] 
2025-01-08 06:20:36.363462: Epoch time: 43.41 s 
2025-01-08 06:20:36.922704:  
2025-01-08 06:20:36.922704: Epoch 456 
2025-01-08 06:20:36.927718: Current learning rate: 0.00112 
2025-01-08 06:21:20.305343: train_loss -0.8345 
2025-01-08 06:21:20.306376: val_loss -0.7284 
2025-01-08 06:21:20.312034: Pseudo dice [np.float32(0.7455)] 
2025-01-08 06:21:20.315669: Epoch time: 43.38 s 
2025-01-08 06:21:20.883111:  
2025-01-08 06:21:20.884114: Epoch 457 
2025-01-08 06:21:20.889644: Current learning rate: 0.0011 
2025-01-08 06:22:04.298027: train_loss -0.8466 
2025-01-08 06:22:04.299030: val_loss -0.813 
2025-01-08 06:22:04.305647: Pseudo dice [np.float32(0.8565)] 
2025-01-08 06:22:04.309182: Epoch time: 43.41 s 
2025-01-08 06:22:04.311701: Yayy! New best EMA pseudo Dice: 0.7857999801635742 
2025-01-08 06:22:05.126764:  
2025-01-08 06:22:05.127267: Epoch 458 
2025-01-08 06:22:05.132808: Current learning rate: 0.00108 
2025-01-08 06:22:48.579276: train_loss -0.8392 
2025-01-08 06:22:48.579783: val_loss -0.7128 
2025-01-08 06:22:48.587336: Pseudo dice [np.float32(0.7879)] 
2025-01-08 06:22:48.589853: Epoch time: 43.45 s 
2025-01-08 06:22:48.592370: Yayy! New best EMA pseudo Dice: 0.7860000133514404 
2025-01-08 06:22:49.394929:  
2025-01-08 06:22:49.395932: Epoch 459 
2025-01-08 06:22:49.401456: Current learning rate: 0.00105 
2025-01-08 06:23:32.813106: train_loss -0.8338 
2025-01-08 06:23:32.813106: val_loss -0.7298 
2025-01-08 06:23:32.820249: Pseudo dice [np.float32(0.756)] 
2025-01-08 06:23:32.824301: Epoch time: 43.42 s 
2025-01-08 06:23:33.397693:  
2025-01-08 06:23:33.398693: Epoch 460 
2025-01-08 06:23:33.403796: Current learning rate: 0.00103 
2025-01-08 06:24:16.840137: train_loss -0.8409 
2025-01-08 06:24:16.841141: val_loss -0.7723 
2025-01-08 06:24:16.847654: Pseudo dice [np.float32(0.805)] 
2025-01-08 06:24:16.851163: Epoch time: 43.44 s 
2025-01-08 06:24:17.422258:  
2025-01-08 06:24:17.422762: Epoch 461 
2025-01-08 06:24:17.427770: Current learning rate: 0.00101 
2025-01-08 06:25:00.816711: train_loss -0.8303 
2025-01-08 06:25:00.816711: val_loss -0.7767 
2025-01-08 06:25:00.822722: Pseudo dice [np.float32(0.8185)] 
2025-01-08 06:25:00.825732: Epoch time: 43.39 s 
2025-01-08 06:25:00.829241: Yayy! New best EMA pseudo Dice: 0.7886000275611877 
2025-01-08 06:25:01.668855:  
2025-01-08 06:25:01.668855: Epoch 462 
2025-01-08 06:25:01.674409: Current learning rate: 0.00098 
2025-01-08 06:25:45.083659: train_loss -0.8415 
2025-01-08 06:25:45.083659: val_loss -0.7587 
2025-01-08 06:25:45.089801: Pseudo dice [np.float32(0.7869)] 
2025-01-08 06:25:45.093564: Epoch time: 43.42 s 
2025-01-08 06:25:45.819426:  
2025-01-08 06:25:45.819426: Epoch 463 
2025-01-08 06:25:45.824461: Current learning rate: 0.00096 
2025-01-08 06:26:29.272617: train_loss -0.8285 
2025-01-08 06:26:29.273620: val_loss -0.7373 
2025-01-08 06:26:29.279519: Pseudo dice [np.float32(0.7719)] 
2025-01-08 06:26:29.282621: Epoch time: 43.45 s 
2025-01-08 06:26:29.845437:  
2025-01-08 06:26:29.845437: Epoch 464 
2025-01-08 06:26:29.851000: Current learning rate: 0.00094 
2025-01-08 06:27:13.299093: train_loss -0.8386 
2025-01-08 06:27:13.299596: val_loss -0.6949 
2025-01-08 06:27:13.305619: Pseudo dice [np.float32(0.7141)] 
2025-01-08 06:27:13.309126: Epoch time: 43.46 s 
2025-01-08 06:27:13.879959:  
2025-01-08 06:27:13.880461: Epoch 465 
2025-01-08 06:27:13.886602: Current learning rate: 0.00091 
2025-01-08 06:27:57.323042: train_loss -0.8484 
2025-01-08 06:27:57.323635: val_loss -0.8099 
2025-01-08 06:27:57.329727: Pseudo dice [np.float32(0.8578)] 
2025-01-08 06:27:57.332256: Epoch time: 43.44 s 
2025-01-08 06:27:57.890202:  
2025-01-08 06:27:57.890202: Epoch 466 
2025-01-08 06:27:57.895218: Current learning rate: 0.00089 
2025-01-08 06:28:41.299643: train_loss -0.8319 
2025-01-08 06:28:41.300682: val_loss -0.7291 
2025-01-08 06:28:41.306273: Pseudo dice [np.float32(0.772)] 
2025-01-08 06:28:41.308779: Epoch time: 43.41 s 
2025-01-08 06:28:41.865961:  
2025-01-08 06:28:41.866961: Epoch 467 
2025-01-08 06:28:41.874053: Current learning rate: 0.00087 
2025-01-08 06:29:25.284878: train_loss -0.8487 
2025-01-08 06:29:25.284878: val_loss -0.7404 
2025-01-08 06:29:25.290903: Pseudo dice [np.float32(0.8085)] 
2025-01-08 06:29:25.294915: Epoch time: 43.42 s 
2025-01-08 06:29:25.852694:  
2025-01-08 06:29:25.852694: Epoch 468 
2025-01-08 06:29:25.858223: Current learning rate: 0.00084 
2025-01-08 06:30:09.253452: train_loss -0.8462 
2025-01-08 06:30:09.253452: val_loss -0.7939 
2025-01-08 06:30:09.260073: Pseudo dice [np.float32(0.8433)] 
2025-01-08 06:30:09.263606: Epoch time: 43.4 s 
2025-01-08 06:30:09.266132: Yayy! New best EMA pseudo Dice: 0.7936000227928162 
2025-01-08 06:30:10.054134:  
2025-01-08 06:30:10.054134: Epoch 469 
2025-01-08 06:30:10.059693: Current learning rate: 0.00082 
2025-01-08 06:30:53.491499: train_loss -0.8418 
2025-01-08 06:30:53.493006: val_loss -0.7328 
2025-01-08 06:30:53.500031: Pseudo dice [np.float32(0.7999)] 
2025-01-08 06:30:53.503042: Epoch time: 43.44 s 
2025-01-08 06:30:53.506556: Yayy! New best EMA pseudo Dice: 0.7942000031471252 
2025-01-08 06:30:54.280690:  
2025-01-08 06:30:54.281693: Epoch 470 
2025-01-08 06:30:54.286249: Current learning rate: 0.00079 
2025-01-08 06:31:37.673787: train_loss -0.8409 
2025-01-08 06:31:37.674792: val_loss -0.7579 
2025-01-08 06:31:37.681304: Pseudo dice [np.float32(0.8009)] 
2025-01-08 06:31:37.683810: Epoch time: 43.39 s 
2025-01-08 06:31:37.687364: Yayy! New best EMA pseudo Dice: 0.7949000000953674 
2025-01-08 06:31:38.491859:  
2025-01-08 06:31:38.491859: Epoch 471 
2025-01-08 06:31:38.497514: Current learning rate: 0.00077 
2025-01-08 06:32:21.977048: train_loss -0.8416 
2025-01-08 06:32:21.978049: val_loss -0.7003 
2025-01-08 06:32:21.983562: Pseudo dice [np.float32(0.7494)] 
2025-01-08 06:32:21.987071: Epoch time: 43.49 s 
2025-01-08 06:32:22.554836:  
2025-01-08 06:32:22.554836: Epoch 472 
2025-01-08 06:32:22.560374: Current learning rate: 0.00075 
2025-01-08 06:33:05.926154: train_loss -0.8516 
2025-01-08 06:33:05.927157: val_loss -0.7797 
2025-01-08 06:33:05.933172: Pseudo dice [np.float32(0.8271)] 
2025-01-08 06:33:05.936212: Epoch time: 43.37 s 
2025-01-08 06:33:06.497883:  
2025-01-08 06:33:06.497883: Epoch 473 
2025-01-08 06:33:06.502894: Current learning rate: 0.00072 
2025-01-08 06:33:49.878215: train_loss -0.8257 
2025-01-08 06:33:49.879217: val_loss -0.7534 
2025-01-08 06:33:49.884236: Pseudo dice [np.float32(0.7863)] 
2025-01-08 06:33:49.888253: Epoch time: 43.38 s 
2025-01-08 06:33:50.448994:  
2025-01-08 06:33:50.449513: Epoch 474 
2025-01-08 06:33:50.454525: Current learning rate: 0.0007 
2025-01-08 06:34:33.820812: train_loss -0.8409 
2025-01-08 06:34:33.820812: val_loss -0.7121 
2025-01-08 06:34:33.826827: Pseudo dice [np.float32(0.7635)] 
2025-01-08 06:34:33.830866: Epoch time: 43.37 s 
2025-01-08 06:34:34.388625:  
2025-01-08 06:34:34.388625: Epoch 475 
2025-01-08 06:34:34.393134: Current learning rate: 0.00067 
2025-01-08 06:35:17.776505: train_loss -0.8467 
2025-01-08 06:35:17.777505: val_loss -0.7036 
2025-01-08 06:35:17.783018: Pseudo dice [np.float32(0.733)] 
2025-01-08 06:35:17.785566: Epoch time: 43.39 s 
2025-01-08 06:35:18.360068:  
2025-01-08 06:35:18.360068: Epoch 476 
2025-01-08 06:35:18.365626: Current learning rate: 0.00065 
2025-01-08 06:36:01.741641: train_loss -0.8572 
2025-01-08 06:36:01.742645: val_loss -0.7758 
2025-01-08 06:36:01.748692: Pseudo dice [np.float32(0.8)] 
2025-01-08 06:36:01.751720: Epoch time: 43.38 s 
2025-01-08 06:36:02.311901:  
2025-01-08 06:36:02.311901: Epoch 477 
2025-01-08 06:36:02.317940: Current learning rate: 0.00063 
2025-01-08 06:36:45.733670: train_loss -0.8514 
2025-01-08 06:36:45.734174: val_loss -0.6609 
2025-01-08 06:36:45.739705: Pseudo dice [np.float32(0.6428)] 
2025-01-08 06:36:45.742728: Epoch time: 43.42 s 
2025-01-08 06:36:46.311198:  
2025-01-08 06:36:46.312203: Epoch 478 
2025-01-08 06:36:46.316759: Current learning rate: 0.0006 
2025-01-08 06:37:29.755019: train_loss -0.8499 
2025-01-08 06:37:29.756028: val_loss -0.7048 
2025-01-08 06:37:29.762059: Pseudo dice [np.float32(0.7276)] 
2025-01-08 06:37:29.765077: Epoch time: 43.44 s 
2025-01-08 06:37:30.341254:  
2025-01-08 06:37:30.342766: Epoch 479 
2025-01-08 06:37:30.347842: Current learning rate: 0.00058 
2025-01-08 06:38:13.750780: train_loss -0.8392 
2025-01-08 06:38:13.750780: val_loss -0.7639 
2025-01-08 06:38:13.756798: Pseudo dice [np.float32(0.8139)] 
2025-01-08 06:38:13.760301: Epoch time: 43.41 s 
2025-01-08 06:38:14.479747:  
2025-01-08 06:38:14.480751: Epoch 480 
2025-01-08 06:38:14.485373: Current learning rate: 0.00055 
2025-01-08 06:38:57.914589: train_loss -0.8495 
2025-01-08 06:38:57.915592: val_loss -0.7261 
2025-01-08 06:38:57.920696: Pseudo dice [np.float32(0.7905)] 
2025-01-08 06:38:57.924216: Epoch time: 43.43 s 
2025-01-08 06:38:58.490700:  
2025-01-08 06:38:58.490700: Epoch 481 
2025-01-08 06:38:58.496792: Current learning rate: 0.00053 
2025-01-08 06:39:41.892092: train_loss -0.8418 
2025-01-08 06:39:41.892596: val_loss -0.7893 
2025-01-08 06:39:41.898611: Pseudo dice [np.float32(0.8486)] 
2025-01-08 06:39:41.900625: Epoch time: 43.4 s 
2025-01-08 06:39:42.465126:  
2025-01-08 06:39:42.466125: Epoch 482 
2025-01-08 06:39:42.471187: Current learning rate: 0.0005 
2025-01-08 06:40:25.848336: train_loss -0.8495 
2025-01-08 06:40:25.849843: val_loss -0.7407 
2025-01-08 06:40:25.855386: Pseudo dice [np.float32(0.8152)] 
2025-01-08 06:40:25.858993: Epoch time: 43.38 s 
2025-01-08 06:40:26.429693:  
2025-01-08 06:40:26.429693: Epoch 483 
2025-01-08 06:40:26.435731: Current learning rate: 0.00048 
2025-01-08 06:41:09.814406: train_loss -0.8363 
2025-01-08 06:41:09.815409: val_loss -0.7038 
2025-01-08 06:41:09.821088: Pseudo dice [np.float32(0.7532)] 
2025-01-08 06:41:09.824143: Epoch time: 43.39 s 
2025-01-08 06:41:10.400652:  
2025-01-08 06:41:10.401652: Epoch 484 
2025-01-08 06:41:10.407312: Current learning rate: 0.00045 
2025-01-08 06:41:53.796061: train_loss -0.8387 
2025-01-08 06:41:53.796061: val_loss -0.751 
2025-01-08 06:41:53.802578: Pseudo dice [np.float32(0.8032)] 
2025-01-08 06:41:53.807086: Epoch time: 43.4 s 
2025-01-08 06:41:54.380314:  
2025-01-08 06:41:54.380818: Epoch 485 
2025-01-08 06:41:54.385827: Current learning rate: 0.00043 
2025-01-08 06:42:37.762714: train_loss -0.8456 
2025-01-08 06:42:37.763217: val_loss -0.7306 
2025-01-08 06:42:37.768229: Pseudo dice [np.float32(0.767)] 
2025-01-08 06:42:37.771738: Epoch time: 43.38 s 
2025-01-08 06:42:38.343895:  
2025-01-08 06:42:38.343895: Epoch 486 
2025-01-08 06:42:38.350034: Current learning rate: 0.0004 
2025-01-08 06:43:21.745004: train_loss -0.8166 
2025-01-08 06:43:21.745507: val_loss -0.672 
2025-01-08 06:43:21.751562: Pseudo dice [np.float32(0.7055)] 
2025-01-08 06:43:21.755081: Epoch time: 43.4 s 
2025-01-08 06:43:22.325709:  
2025-01-08 06:43:22.325709: Epoch 487 
2025-01-08 06:43:22.330736: Current learning rate: 0.00037 
2025-01-08 06:44:05.738873: train_loss -0.8496 
2025-01-08 06:44:05.739876: val_loss -0.7863 
2025-01-08 06:44:05.745887: Pseudo dice [np.float32(0.8424)] 
2025-01-08 06:44:05.748894: Epoch time: 43.41 s 
2025-01-08 06:44:06.322836:  
2025-01-08 06:44:06.322836: Epoch 488 
2025-01-08 06:44:06.327871: Current learning rate: 0.00035 
2025-01-08 06:44:49.748229: train_loss -0.8528 
2025-01-08 06:44:49.748732: val_loss -0.7666 
2025-01-08 06:44:49.753241: Pseudo dice [np.float32(0.792)] 
2025-01-08 06:44:49.756251: Epoch time: 43.43 s 
2025-01-08 06:44:50.486053:  
2025-01-08 06:44:50.487053: Epoch 489 
2025-01-08 06:44:50.492117: Current learning rate: 0.00032 
2025-01-08 06:45:33.869052: train_loss -0.8458 
2025-01-08 06:45:33.869052: val_loss -0.7772 
2025-01-08 06:45:33.875565: Pseudo dice [np.float32(0.8257)] 
2025-01-08 06:45:33.879074: Epoch time: 43.38 s 
2025-01-08 06:45:34.455164:  
2025-01-08 06:45:34.456161: Epoch 490 
2025-01-08 06:45:34.461829: Current learning rate: 0.0003 
2025-01-08 06:46:17.883109: train_loss -0.8475 
2025-01-08 06:46:17.883617: val_loss -0.7449 
2025-01-08 06:46:17.890153: Pseudo dice [np.float32(0.8062)] 
2025-01-08 06:46:17.893169: Epoch time: 43.43 s 
2025-01-08 06:46:18.463017:  
2025-01-08 06:46:18.464021: Epoch 491 
2025-01-08 06:46:18.468067: Current learning rate: 0.00027 
2025-01-08 06:47:01.879661: train_loss -0.8476 
2025-01-08 06:47:01.880164: val_loss -0.7084 
2025-01-08 06:47:01.886213: Pseudo dice [np.float32(0.7752)] 
2025-01-08 06:47:01.889735: Epoch time: 43.42 s 
2025-01-08 06:47:02.464519:  
2025-01-08 06:47:02.465523: Epoch 492 
2025-01-08 06:47:02.470583: Current learning rate: 0.00024 
2025-01-08 06:47:45.879805: train_loss -0.8645 
2025-01-08 06:47:45.880308: val_loss -0.6722 
2025-01-08 06:47:45.886826: Pseudo dice [np.float32(0.7151)] 
2025-01-08 06:47:45.890352: Epoch time: 43.42 s 
2025-01-08 06:47:46.461202:  
2025-01-08 06:47:46.461202: Epoch 493 
2025-01-08 06:47:46.466213: Current learning rate: 0.00021 
2025-01-08 06:48:29.864428: train_loss -0.8388 
2025-01-08 06:48:29.865432: val_loss -0.7512 
2025-01-08 06:48:29.871444: Pseudo dice [np.float32(0.813)] 
2025-01-08 06:48:29.874452: Epoch time: 43.4 s 
2025-01-08 06:48:30.445418:  
2025-01-08 06:48:30.446421: Epoch 494 
2025-01-08 06:48:30.451969: Current learning rate: 0.00019 
2025-01-08 06:49:13.865879: train_loss -0.855 
2025-01-08 06:49:13.866882: val_loss -0.816 
2025-01-08 06:49:13.872917: Pseudo dice [np.float32(0.853)] 
2025-01-08 06:49:13.875940: Epoch time: 43.42 s 
2025-01-08 06:49:14.449386:  
2025-01-08 06:49:14.449386: Epoch 495 
2025-01-08 06:49:14.454402: Current learning rate: 0.00016 
2025-01-08 06:49:57.850945: train_loss -0.8541 
2025-01-08 06:49:57.851948: val_loss -0.7014 
2025-01-08 06:49:57.858520: Pseudo dice [np.float32(0.761)] 
2025-01-08 06:49:57.861042: Epoch time: 43.4 s 
2025-01-08 06:49:58.438117:  
2025-01-08 06:49:58.438117: Epoch 496 
2025-01-08 06:49:58.443128: Current learning rate: 0.00013 
2025-01-08 06:50:41.841121: train_loss -0.857 
2025-01-08 06:50:41.842124: val_loss -0.6865 
2025-01-08 06:50:41.847175: Pseudo dice [np.float32(0.764)] 
2025-01-08 06:50:41.851183: Epoch time: 43.4 s 
2025-01-08 06:50:42.416913:  
2025-01-08 06:50:42.417913: Epoch 497 
2025-01-08 06:50:42.423427: Current learning rate: 0.0001 
2025-01-08 06:51:25.856424: train_loss -0.862 
2025-01-08 06:51:25.856930: val_loss -0.7712 
2025-01-08 06:51:25.862469: Pseudo dice [np.float32(0.8158)] 
2025-01-08 06:51:25.866491: Epoch time: 43.44 s 
2025-01-08 06:51:26.595862:  
2025-01-08 06:51:26.595862: Epoch 498 
2025-01-08 06:51:26.601415: Current learning rate: 7e-05 
2025-01-08 06:52:10.024795: train_loss -0.8607 
2025-01-08 06:52:10.026297: val_loss -0.7425 
2025-01-08 06:52:10.032313: Pseudo dice [np.float32(0.7933)] 
2025-01-08 06:52:10.035818: Epoch time: 43.43 s 
2025-01-08 06:52:10.612545:  
2025-01-08 06:52:10.612545: Epoch 499 
2025-01-08 06:52:10.617554: Current learning rate: 4e-05 
2025-01-08 06:52:54.015347: train_loss -0.8339 
2025-01-08 06:52:54.016347: val_loss -0.7103 
2025-01-08 06:52:54.021861: Pseudo dice [np.float32(0.7014)] 
2025-01-08 06:52:54.025369: Epoch time: 43.4 s 
2025-01-08 06:52:54.824263: Training done. 
2025-01-08 06:52:54.847263: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2025-01-08 06:52:54.858262: The split file contains 5 splits. 
2025-01-08 06:52:54.863269: Desired fold for training: 0 
2025-01-08 06:52:54.867270: This split has 50 training and 13 validation cases. 
2025-01-08 06:52:54.871268: predicting lung_006 
2025-01-08 06:52:54.876269: lung_006, shape torch.Size([1, 285, 637, 637]), rank 0 
2025-01-08 06:53:50.670093: predicting lung_010 
2025-01-08 06:53:50.716093: lung_010, shape torch.Size([1, 242, 390, 390]), rank 0 
2025-01-08 06:54:08.715578: predicting lung_033 
2025-01-08 06:54:08.731084: lung_033, shape torch.Size([1, 260, 535, 535]), rank 0 
2025-01-08 06:54:42.326483: predicting lung_034 
2025-01-08 06:54:42.356993: lung_034, shape torch.Size([1, 296, 586, 586]), rank 0 
2025-01-08 06:55:37.354242: predicting lung_041 
2025-01-08 06:55:37.393749: lung_041, shape torch.Size([1, 240, 535, 535]), rank 0 
2025-01-08 06:56:05.492500: predicting lung_042 
2025-01-08 06:56:05.523008: lung_042, shape torch.Size([1, 251, 478, 478]), rank 0 
2025-01-08 06:56:27.966934: predicting lung_046 
2025-01-08 06:56:27.990935: lung_046, shape torch.Size([1, 226, 509, 509]), rank 0 
2025-01-08 06:56:55.999866: predicting lung_048 
2025-01-08 06:56:56.021870: lung_048, shape torch.Size([1, 259, 531, 531]), rank 0 
2025-01-08 06:57:29.655379: predicting lung_059 
2025-01-08 06:57:29.694379: lung_059, shape torch.Size([1, 218, 535, 535]), rank 0 
2025-01-08 06:57:57.714395: predicting lung_065 
2025-01-08 06:57:57.741395: lung_065, shape torch.Size([1, 257, 474, 474]), rank 0 
2025-01-08 06:58:20.168688: predicting lung_066 
2025-01-08 06:58:20.193197: lung_066, shape torch.Size([1, 241, 578, 578]), rank 0 
2025-01-08 06:59:07.343433: predicting lung_070 
2025-01-08 06:59:07.377433: lung_070, shape torch.Size([1, 266, 497, 497]), rank 0 
2025-01-08 06:59:41.098015: predicting lung_079 
2025-01-08 06:59:41.123015: lung_079, shape torch.Size([1, 251, 606, 606]), rank 0 
2025-01-08 07:00:39.617281: Validation complete 
2025-01-08 07:00:39.617281: Mean Validation Dice:  0.6675241653612546 
