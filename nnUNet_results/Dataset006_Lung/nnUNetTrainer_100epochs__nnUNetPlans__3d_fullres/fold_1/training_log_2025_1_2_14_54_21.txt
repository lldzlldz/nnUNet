
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-02 14:54:21.523321: do_dummy_2d_data_aug: False 
2025-01-02 14:54:21.528321: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2025-01-02 14:54:21.534319: The split file contains 5 splits. 
2025-01-02 14:54:21.536320: Desired fold for training: 1 
2025-01-02 14:54:21.539319: This split has 50 training and 13 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [252.0, 512.0, 512.0], 'spacing': [1.244979977607727, 0.78515625, 0.78515625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset006_Lung', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.244979977607727, 0.78515625, 0.78515625], 'original_median_shape_after_transp': [252, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2671.0, 'mean': -273.4598083496094, 'median': -162.0, 'min': -1024.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 311.0, 'std': 346.9495849609375}}} 
 
2025-01-02 14:54:29.767853: unpacking dataset... 
2025-01-02 14:54:29.972243: unpacking done... 
2025-01-02 14:54:33.587581:  
2025-01-02 14:54:33.587581: Epoch 0 
2025-01-02 14:54:33.593128: Current learning rate: 0.01 
2025-01-02 14:55:20.693425: train_loss -0.0032 
2025-01-02 14:55:20.694425: val_loss 0.0863 
2025-01-02 14:55:20.699942: Pseudo dice [np.float32(0.0003)] 
2025-01-02 14:55:20.703458: Epoch time: 47.11 s 
2025-01-02 14:55:20.705968: Yayy! New best EMA pseudo Dice: 0.0003000000142492354 
2025-01-02 14:55:21.432297:  
2025-01-02 14:55:21.432297: Epoch 1 
2025-01-02 14:55:21.437831: Current learning rate: 0.00991 
2025-01-02 14:56:04.044900: train_loss -0.3941 
2025-01-02 14:56:04.044900: val_loss -0.2062 
2025-01-02 14:56:04.050910: Pseudo dice [np.float32(0.1946)] 
2025-01-02 14:56:04.053921: Epoch time: 42.61 s 
2025-01-02 14:56:04.057433: Yayy! New best EMA pseudo Dice: 0.01979999989271164 
2025-01-02 14:56:04.870908:  
2025-01-02 14:56:04.870908: Epoch 2 
2025-01-02 14:56:04.876946: Current learning rate: 0.00982 
2025-01-02 14:56:47.390621: train_loss -0.4755 
2025-01-02 14:56:47.390621: val_loss -0.0162 
2025-01-02 14:56:47.396636: Pseudo dice [np.float32(0.0419)] 
2025-01-02 14:56:47.400144: Epoch time: 42.52 s 
2025-01-02 14:56:47.403152: Yayy! New best EMA pseudo Dice: 0.02199999988079071 
2025-01-02 14:56:48.235702:  
2025-01-02 14:56:48.235702: Epoch 3 
2025-01-02 14:56:48.241733: Current learning rate: 0.00973 
2025-01-02 14:57:30.810400: train_loss -0.4757 
2025-01-02 14:57:30.810400: val_loss -0.183 
2025-01-02 14:57:30.816913: Pseudo dice [np.float32(0.2445)] 
2025-01-02 14:57:30.820422: Epoch time: 42.58 s 
2025-01-02 14:57:30.822928: Yayy! New best EMA pseudo Dice: 0.044199999421834946 
2025-01-02 14:57:31.644044:  
2025-01-02 14:57:31.644044: Epoch 4 
2025-01-02 14:57:31.650062: Current learning rate: 0.00964 
2025-01-02 14:58:14.207957: train_loss -0.4983 
2025-01-02 14:58:14.207957: val_loss -0.2145 
2025-01-02 14:58:14.213974: Pseudo dice [np.float32(0.1309)] 
2025-01-02 14:58:14.217483: Epoch time: 42.57 s 
2025-01-02 14:58:14.220493: Yayy! New best EMA pseudo Dice: 0.05290000140666962 
2025-01-02 14:58:15.155141:  
2025-01-02 14:58:15.155141: Epoch 5 
2025-01-02 14:58:15.160692: Current learning rate: 0.00955 
2025-01-02 14:58:57.772745: train_loss -0.5243 
2025-01-02 14:58:57.774248: val_loss -0.1083 
2025-01-02 14:58:57.778760: Pseudo dice [np.float32(0.1033)] 
2025-01-02 14:58:57.781775: Epoch time: 42.62 s 
2025-01-02 14:58:57.785288: Yayy! New best EMA pseudo Dice: 0.05790000036358833 
2025-01-02 14:58:58.596969:  
2025-01-02 14:58:58.597969: Epoch 6 
2025-01-02 14:58:58.603608: Current learning rate: 0.00946 
2025-01-02 14:59:41.151899: train_loss -0.5468 
2025-01-02 14:59:41.152898: val_loss -0.2587 
2025-01-02 14:59:41.158419: Pseudo dice [np.float32(0.1271)] 
2025-01-02 14:59:41.161932: Epoch time: 42.55 s 
2025-01-02 14:59:41.165442: Yayy! New best EMA pseudo Dice: 0.06480000168085098 
2025-01-02 14:59:41.993042:  
2025-01-02 14:59:41.994047: Epoch 7 
2025-01-02 14:59:41.999149: Current learning rate: 0.00937 
2025-01-02 15:00:24.546738: train_loss -0.5496 
2025-01-02 15:00:24.546738: val_loss -0.3589 
2025-01-02 15:00:24.553263: Pseudo dice [np.float32(0.3047)] 
2025-01-02 15:00:24.556776: Epoch time: 42.55 s 
2025-01-02 15:00:24.559787: Yayy! New best EMA pseudo Dice: 0.08879999816417694 
2025-01-02 15:00:25.350780:  
2025-01-02 15:00:25.351284: Epoch 8 
2025-01-02 15:00:25.354795: Current learning rate: 0.00928 
2025-01-02 15:01:07.900029: train_loss -0.5876 
2025-01-02 15:01:07.900029: val_loss -0.162 
2025-01-02 15:01:07.906049: Pseudo dice [np.float32(0.1061)] 
2025-01-02 15:01:07.910063: Epoch time: 42.55 s 
2025-01-02 15:01:07.912570: Yayy! New best EMA pseudo Dice: 0.09059999883174896 
2025-01-02 15:01:08.760871:  
2025-01-02 15:01:08.760871: Epoch 9 
2025-01-02 15:01:08.764917: Current learning rate: 0.00919 
2025-01-02 15:01:51.346215: train_loss -0.6318 
2025-01-02 15:01:51.347220: val_loss -0.2309 
2025-01-02 15:01:51.353745: Pseudo dice [np.float32(0.115)] 
2025-01-02 15:01:51.357257: Epoch time: 42.59 s 
2025-01-02 15:01:51.359763: Yayy! New best EMA pseudo Dice: 0.09300000220537186 
2025-01-02 15:01:52.231035:  
2025-01-02 15:01:52.232040: Epoch 10 
2025-01-02 15:01:52.236599: Current learning rate: 0.0091 
2025-01-02 15:02:34.819603: train_loss -0.613 
2025-01-02 15:02:34.820180: val_loss -0.1475 
2025-01-02 15:02:34.825310: Pseudo dice [np.float32(0.0938)] 
2025-01-02 15:02:34.828859: Epoch time: 42.59 s 
2025-01-02 15:02:34.831920: Yayy! New best EMA pseudo Dice: 0.09309999644756317 
2025-01-02 15:02:35.651292:  
2025-01-02 15:02:35.652291: Epoch 11 
2025-01-02 15:02:35.657905: Current learning rate: 0.009 
2025-01-02 15:03:18.260968: train_loss -0.5867 
2025-01-02 15:03:18.261971: val_loss -0.1558 
2025-01-02 15:03:18.268488: Pseudo dice [np.float32(0.1228)] 
2025-01-02 15:03:18.272001: Epoch time: 42.61 s 
2025-01-02 15:03:18.274508: Yayy! New best EMA pseudo Dice: 0.09610000252723694 
2025-01-02 15:03:19.062564:  
2025-01-02 15:03:19.062564: Epoch 12 
2025-01-02 15:03:19.068091: Current learning rate: 0.00891 
2025-01-02 15:04:01.641052: train_loss -0.5891 
2025-01-02 15:04:01.641052: val_loss -0.3699 
2025-01-02 15:04:01.647066: Pseudo dice [np.float32(0.2383)] 
2025-01-02 15:04:01.650076: Epoch time: 42.58 s 
2025-01-02 15:04:01.652583: Yayy! New best EMA pseudo Dice: 0.11029999703168869 
2025-01-02 15:04:02.629278:  
2025-01-02 15:04:02.629278: Epoch 13 
2025-01-02 15:04:02.635387: Current learning rate: 0.00882 
2025-01-02 15:04:45.229563: train_loss -0.6145 
2025-01-02 15:04:45.230568: val_loss -0.3424 
2025-01-02 15:04:45.236190: Pseudo dice [np.float32(0.2145)] 
2025-01-02 15:04:45.239212: Epoch time: 42.6 s 
2025-01-02 15:04:45.242234: Yayy! New best EMA pseudo Dice: 0.12070000171661377 
2025-01-02 15:04:46.072548:  
2025-01-02 15:04:46.072548: Epoch 14 
2025-01-02 15:04:46.077579: Current learning rate: 0.00873 
2025-01-02 15:05:28.678292: train_loss -0.6229 
2025-01-02 15:05:28.679293: val_loss -0.2849 
2025-01-02 15:05:28.684812: Pseudo dice [np.float32(0.2122)] 
2025-01-02 15:05:28.688323: Epoch time: 42.61 s 
2025-01-02 15:05:28.691833: Yayy! New best EMA pseudo Dice: 0.1298999935388565 
2025-01-02 15:05:29.483958:  
2025-01-02 15:05:29.485463: Epoch 15 
2025-01-02 15:05:29.491077: Current learning rate: 0.00864 
2025-01-02 15:06:12.056456: train_loss -0.5966 
2025-01-02 15:06:12.056961: val_loss -0.3947 
2025-01-02 15:06:12.062540: Pseudo dice [np.float32(0.3463)] 
2025-01-02 15:06:12.065576: Epoch time: 42.57 s 
2025-01-02 15:06:12.068101: Yayy! New best EMA pseudo Dice: 0.15150000154972076 
2025-01-02 15:06:12.910910:  
2025-01-02 15:06:12.911910: Epoch 16 
2025-01-02 15:06:12.917488: Current learning rate: 0.00855 
2025-01-02 15:06:55.509279: train_loss -0.6114 
2025-01-02 15:06:55.509782: val_loss -0.2766 
2025-01-02 15:06:55.514884: Pseudo dice [np.float32(0.2089)] 
2025-01-02 15:06:55.519094: Epoch time: 42.6 s 
2025-01-02 15:06:55.522105: Yayy! New best EMA pseudo Dice: 0.15719999372959137 
2025-01-02 15:06:56.378183:  
2025-01-02 15:06:56.378183: Epoch 17 
2025-01-02 15:06:56.383740: Current learning rate: 0.00846 
2025-01-02 15:07:38.920539: train_loss -0.6746 
2025-01-02 15:07:38.921046: val_loss -0.3428 
2025-01-02 15:07:38.927622: Pseudo dice [np.float32(0.1956)] 
2025-01-02 15:07:38.931165: Epoch time: 42.54 s 
2025-01-02 15:07:38.934691: Yayy! New best EMA pseudo Dice: 0.16110000014305115 
2025-01-02 15:07:39.770501:  
2025-01-02 15:07:39.770501: Epoch 18 
2025-01-02 15:07:39.776515: Current learning rate: 0.00836 
2025-01-02 15:08:22.445545: train_loss -0.6659 
2025-01-02 15:08:22.446548: val_loss -0.231 
2025-01-02 15:08:22.453096: Pseudo dice [np.float32(0.139)] 
2025-01-02 15:08:22.457606: Epoch time: 42.68 s 
2025-01-02 15:08:23.058972:  
2025-01-02 15:08:23.059975: Epoch 19 
2025-01-02 15:08:23.064522: Current learning rate: 0.00827 
2025-01-02 15:09:05.707843: train_loss -0.6497 
2025-01-02 15:09:05.708354: val_loss -0.43 
2025-01-02 15:09:05.714494: Pseudo dice [np.float32(0.2563)] 
2025-01-02 15:09:05.718529: Epoch time: 42.65 s 
2025-01-02 15:09:05.721570: Yayy! New best EMA pseudo Dice: 0.16859999299049377 
2025-01-02 15:09:06.660134:  
2025-01-02 15:09:06.661138: Epoch 20 
2025-01-02 15:09:06.665693: Current learning rate: 0.00818 
2025-01-02 15:09:49.251049: train_loss -0.6379 
2025-01-02 15:09:49.252052: val_loss -0.3663 
2025-01-02 15:09:49.257063: Pseudo dice [np.float32(0.2583)] 
2025-01-02 15:09:49.261070: Epoch time: 42.59 s 
2025-01-02 15:09:49.264579: Yayy! New best EMA pseudo Dice: 0.17759999632835388 
2025-01-02 15:09:50.086076:  
2025-01-02 15:09:50.086076: Epoch 21 
2025-01-02 15:09:50.091639: Current learning rate: 0.00809 
2025-01-02 15:10:32.628674: train_loss -0.6686 
2025-01-02 15:10:32.629197: val_loss -0.3728 
2025-01-02 15:10:32.633735: Pseudo dice [np.float32(0.191)] 
2025-01-02 15:10:32.637054: Epoch time: 42.54 s 
2025-01-02 15:10:32.640566: Yayy! New best EMA pseudo Dice: 0.17890000343322754 
2025-01-02 15:10:33.431689:  
2025-01-02 15:10:33.431689: Epoch 22 
2025-01-02 15:10:33.437251: Current learning rate: 0.008 
2025-01-02 15:11:16.006779: train_loss -0.6798 
2025-01-02 15:11:16.007782: val_loss -0.3375 
2025-01-02 15:11:16.013800: Pseudo dice [np.float32(0.2113)] 
2025-01-02 15:11:16.016815: Epoch time: 42.58 s 
2025-01-02 15:11:16.021327: Yayy! New best EMA pseudo Dice: 0.18219999969005585 
2025-01-02 15:11:16.791048:  
2025-01-02 15:11:16.791048: Epoch 23 
2025-01-02 15:11:16.797160: Current learning rate: 0.0079 
2025-01-02 15:11:59.356358: train_loss -0.6439 
2025-01-02 15:11:59.356864: val_loss -0.2183 
2025-01-02 15:11:59.363931: Pseudo dice [np.float32(0.1281)] 
2025-01-02 15:11:59.367785: Epoch time: 42.57 s 
2025-01-02 15:11:59.979507:  
2025-01-02 15:11:59.980509: Epoch 24 
2025-01-02 15:11:59.985590: Current learning rate: 0.00781 
2025-01-02 15:12:42.561109: train_loss -0.6127 
2025-01-02 15:12:42.562113: val_loss -0.4067 
2025-01-02 15:12:42.567632: Pseudo dice [np.float32(0.2787)] 
2025-01-02 15:12:42.571150: Epoch time: 42.58 s 
2025-01-02 15:12:42.574322: Yayy! New best EMA pseudo Dice: 0.18690000474452972 
2025-01-02 15:12:43.337151:  
2025-01-02 15:12:43.337151: Epoch 25 
2025-01-02 15:12:43.343170: Current learning rate: 0.00772 
2025-01-02 15:13:25.881713: train_loss -0.6569 
2025-01-02 15:13:25.883214: val_loss -0.3572 
2025-01-02 15:13:25.889235: Pseudo dice [np.float32(0.2968)] 
2025-01-02 15:13:25.893244: Epoch time: 42.55 s 
2025-01-02 15:13:25.896752: Yayy! New best EMA pseudo Dice: 0.19789999723434448 
2025-01-02 15:13:26.717838:  
2025-01-02 15:13:26.718838: Epoch 26 
2025-01-02 15:13:26.724448: Current learning rate: 0.00763 
2025-01-02 15:14:09.246245: train_loss -0.6824 
2025-01-02 15:14:09.246747: val_loss -0.3313 
2025-01-02 15:14:09.252763: Pseudo dice [np.float32(0.2229)] 
2025-01-02 15:14:09.256271: Epoch time: 42.53 s 
2025-01-02 15:14:09.259284: Yayy! New best EMA pseudo Dice: 0.2003999948501587 
2025-01-02 15:14:10.038533:  
2025-01-02 15:14:10.038533: Epoch 27 
2025-01-02 15:14:10.044660: Current learning rate: 0.00753 
2025-01-02 15:14:52.576202: train_loss -0.6704 
2025-01-02 15:14:52.577201: val_loss -0.1796 
2025-01-02 15:14:52.582717: Pseudo dice [np.float32(0.1285)] 
2025-01-02 15:14:52.586228: Epoch time: 42.54 s 
2025-01-02 15:14:53.325066:  
2025-01-02 15:14:53.325066: Epoch 28 
2025-01-02 15:14:53.330627: Current learning rate: 0.00744 
2025-01-02 15:15:35.932859: train_loss -0.6765 
2025-01-02 15:15:35.933859: val_loss -0.3636 
2025-01-02 15:15:35.940378: Pseudo dice [np.float32(0.3428)] 
2025-01-02 15:15:35.944391: Epoch time: 42.61 s 
2025-01-02 15:15:35.947902: Yayy! New best EMA pseudo Dice: 0.20819999277591705 
2025-01-02 15:15:36.717608:  
2025-01-02 15:15:36.717608: Epoch 29 
2025-01-02 15:15:36.723137: Current learning rate: 0.00735 
2025-01-02 15:16:19.311320: train_loss -0.6199 
2025-01-02 15:16:19.312324: val_loss -0.3455 
2025-01-02 15:16:19.318337: Pseudo dice [np.float32(0.1089)] 
2025-01-02 15:16:19.321356: Epoch time: 42.59 s 
2025-01-02 15:16:19.932381:  
2025-01-02 15:16:19.932381: Epoch 30 
2025-01-02 15:16:19.937394: Current learning rate: 0.00725 
2025-01-02 15:17:02.445844: train_loss -0.6794 
2025-01-02 15:17:02.447351: val_loss -0.4858 
2025-01-02 15:17:02.452934: Pseudo dice [np.float32(0.3935)] 
2025-01-02 15:17:02.455981: Epoch time: 42.51 s 
2025-01-02 15:17:02.459579: Yayy! New best EMA pseudo Dice: 0.21780000627040863 
2025-01-02 15:17:03.246843:  
2025-01-02 15:17:03.246843: Epoch 31 
2025-01-02 15:17:03.252866: Current learning rate: 0.00716 
2025-01-02 15:17:45.801335: train_loss -0.6747 
2025-01-02 15:17:45.802335: val_loss -0.3457 
2025-01-02 15:17:45.807849: Pseudo dice [np.float32(0.1487)] 
2025-01-02 15:17:45.811363: Epoch time: 42.55 s 
2025-01-02 15:17:46.406289:  
2025-01-02 15:17:46.407290: Epoch 32 
2025-01-02 15:17:46.412424: Current learning rate: 0.00707 
2025-01-02 15:18:28.919850: train_loss -0.6475 
2025-01-02 15:18:28.920854: val_loss -0.3143 
2025-01-02 15:18:28.927367: Pseudo dice [np.float32(0.3164)] 
2025-01-02 15:18:28.930881: Epoch time: 42.51 s 
2025-01-02 15:18:28.934893: Yayy! New best EMA pseudo Dice: 0.22139999270439148 
2025-01-02 15:18:29.725184:  
2025-01-02 15:18:29.726187: Epoch 33 
2025-01-02 15:18:29.729724: Current learning rate: 0.00697 
2025-01-02 15:19:12.268767: train_loss -0.6981 
2025-01-02 15:19:12.269770: val_loss -0.3667 
2025-01-02 15:19:12.276289: Pseudo dice [np.float32(0.2539)] 
2025-01-02 15:19:12.279800: Epoch time: 42.54 s 
2025-01-02 15:19:12.283308: Yayy! New best EMA pseudo Dice: 0.22470000386238098 
2025-01-02 15:19:13.117592:  
2025-01-02 15:19:13.117592: Epoch 34 
2025-01-02 15:19:13.123127: Current learning rate: 0.00688 
2025-01-02 15:19:55.703846: train_loss -0.6741 
2025-01-02 15:19:55.703846: val_loss -0.3505 
2025-01-02 15:19:55.709863: Pseudo dice [np.float32(0.2345)] 
2025-01-02 15:19:55.713874: Epoch time: 42.59 s 
2025-01-02 15:19:55.717384: Yayy! New best EMA pseudo Dice: 0.2257000058889389 
2025-01-02 15:19:56.586899:  
2025-01-02 15:19:56.587351: Epoch 35 
2025-01-02 15:19:56.593431: Current learning rate: 0.00679 
2025-01-02 15:20:39.166666: train_loss -0.6765 
2025-01-02 15:20:39.167176: val_loss -0.4913 
2025-01-02 15:20:39.172844: Pseudo dice [np.float32(0.4554)] 
2025-01-02 15:20:39.176630: Epoch time: 42.58 s 
2025-01-02 15:20:39.179698: Yayy! New best EMA pseudo Dice: 0.24860000610351562 
2025-01-02 15:20:40.273057:  
2025-01-02 15:20:40.273057: Epoch 36 
2025-01-02 15:20:40.278592: Current learning rate: 0.00669 
2025-01-02 15:21:22.809059: train_loss -0.6799 
2025-01-02 15:21:22.809575: val_loss -0.3286 
2025-01-02 15:21:22.816270: Pseudo dice [np.float32(0.2335)] 
2025-01-02 15:21:22.819841: Epoch time: 42.54 s 
2025-01-02 15:21:23.400505:  
2025-01-02 15:21:23.400505: Epoch 37 
2025-01-02 15:21:23.406057: Current learning rate: 0.0066 
2025-01-02 15:22:05.972558: train_loss -0.6984 
2025-01-02 15:22:05.973061: val_loss -0.2799 
2025-01-02 15:22:05.978073: Pseudo dice [np.float32(0.1926)] 
2025-01-02 15:22:05.981584: Epoch time: 42.57 s 
2025-01-02 15:22:06.565360:  
2025-01-02 15:22:06.565863: Epoch 38 
2025-01-02 15:22:06.570936: Current learning rate: 0.0065 
2025-01-02 15:22:49.213651: train_loss -0.6957 
2025-01-02 15:22:49.214651: val_loss -0.2618 
2025-01-02 15:22:49.221174: Pseudo dice [np.float32(0.1643)] 
2025-01-02 15:22:49.225186: Epoch time: 42.65 s 
2025-01-02 15:22:49.819981:  
2025-01-02 15:22:49.819981: Epoch 39 
2025-01-02 15:22:49.824585: Current learning rate: 0.00641 
2025-01-02 15:23:32.372695: train_loss -0.6519 
2025-01-02 15:23:32.372695: val_loss -0.3792 
2025-01-02 15:23:32.377774: Pseudo dice [np.float32(0.3849)] 
2025-01-02 15:23:32.382853: Epoch time: 42.55 s 
2025-01-02 15:23:32.385390: Yayy! New best EMA pseudo Dice: 0.24899999797344208 
2025-01-02 15:23:33.172186:  
2025-01-02 15:23:33.172186: Epoch 40 
2025-01-02 15:23:33.178412: Current learning rate: 0.00631 
2025-01-02 15:24:15.740758: train_loss -0.7091 
2025-01-02 15:24:15.740758: val_loss -0.497 
2025-01-02 15:24:15.746774: Pseudo dice [np.float32(0.3455)] 
2025-01-02 15:24:15.750798: Epoch time: 42.57 s 
2025-01-02 15:24:15.754315: Yayy! New best EMA pseudo Dice: 0.25870001316070557 
2025-01-02 15:24:16.619395:  
2025-01-02 15:24:16.619395: Epoch 41 
2025-01-02 15:24:16.624513: Current learning rate: 0.00622 
2025-01-02 15:24:59.158766: train_loss -0.6913 
2025-01-02 15:24:59.159269: val_loss -0.3865 
2025-01-02 15:24:59.165288: Pseudo dice [np.float32(0.2887)] 
2025-01-02 15:24:59.168813: Epoch time: 42.54 s 
2025-01-02 15:24:59.171844: Yayy! New best EMA pseudo Dice: 0.26170000433921814 
2025-01-02 15:25:00.021796:  
2025-01-02 15:25:00.021796: Epoch 42 
2025-01-02 15:25:00.027823: Current learning rate: 0.00612 
2025-01-02 15:25:42.569160: train_loss -0.6923 
2025-01-02 15:25:42.569160: val_loss -0.3844 
2025-01-02 15:25:42.575752: Pseudo dice [np.float32(0.2683)] 
2025-01-02 15:25:42.578851: Epoch time: 42.55 s 
2025-01-02 15:25:42.582417: Yayy! New best EMA pseudo Dice: 0.2623000144958496 
2025-01-02 15:25:43.406957:  
2025-01-02 15:25:43.406957: Epoch 43 
2025-01-02 15:25:43.411991: Current learning rate: 0.00603 
2025-01-02 15:26:25.957935: train_loss -0.7231 
2025-01-02 15:26:25.957935: val_loss -0.3261 
2025-01-02 15:26:25.964547: Pseudo dice [np.float32(0.2633)] 
2025-01-02 15:26:25.968081: Epoch time: 42.55 s 
2025-01-02 15:26:25.971112: Yayy! New best EMA pseudo Dice: 0.2624000012874603 
2025-01-02 15:26:26.998569:  
2025-01-02 15:26:27.000572: Epoch 44 
2025-01-02 15:26:27.006662: Current learning rate: 0.00593 
2025-01-02 15:27:09.537060: train_loss -0.6909 
2025-01-02 15:27:09.537584: val_loss -0.5119 
2025-01-02 15:27:09.543684: Pseudo dice [np.float32(0.4889)] 
2025-01-02 15:27:09.547196: Epoch time: 42.54 s 
2025-01-02 15:27:09.550209: Yayy! New best EMA pseudo Dice: 0.2851000130176544 
2025-01-02 15:27:10.333767:  
2025-01-02 15:27:10.333767: Epoch 45 
2025-01-02 15:27:10.339782: Current learning rate: 0.00584 
2025-01-02 15:27:52.907285: train_loss -0.6679 
2025-01-02 15:27:52.913801: val_loss -0.1809 
2025-01-02 15:27:52.918313: Pseudo dice [np.float32(0.11)] 
2025-01-02 15:27:52.921323: Epoch time: 42.58 s 
2025-01-02 15:27:53.503168:  
2025-01-02 15:27:53.503168: Epoch 46 
2025-01-02 15:27:53.509184: Current learning rate: 0.00574 
2025-01-02 15:28:36.062842: train_loss -0.7076 
2025-01-02 15:28:36.062842: val_loss -0.234 
2025-01-02 15:28:36.069362: Pseudo dice [np.float32(0.2542)] 
2025-01-02 15:28:36.072875: Epoch time: 42.56 s 
2025-01-02 15:28:36.661574:  
2025-01-02 15:28:36.662077: Epoch 47 
2025-01-02 15:28:36.665588: Current learning rate: 0.00565 
2025-01-02 15:29:19.236535: train_loss -0.6975 
2025-01-02 15:29:19.237079: val_loss -0.384 
2025-01-02 15:29:19.243457: Pseudo dice [np.float32(0.3068)] 
2025-01-02 15:29:19.247509: Epoch time: 42.58 s 
2025-01-02 15:29:19.830321:  
2025-01-02 15:29:19.831324: Epoch 48 
2025-01-02 15:29:19.835870: Current learning rate: 0.00555 
2025-01-02 15:30:02.478896: train_loss -0.7183 
2025-01-02 15:30:02.478896: val_loss -0.4192 
2025-01-02 15:30:02.485080: Pseudo dice [np.float32(0.3364)] 
2025-01-02 15:30:02.489107: Epoch time: 42.65 s 
2025-01-02 15:30:03.059776:  
2025-01-02 15:30:03.059776: Epoch 49 
2025-01-02 15:30:03.065305: Current learning rate: 0.00546 
2025-01-02 15:30:45.616071: train_loss -0.6933 
2025-01-02 15:30:45.616576: val_loss -0.4265 
2025-01-02 15:30:45.621590: Pseudo dice [np.float32(0.429)] 
2025-01-02 15:30:45.625099: Epoch time: 42.56 s 
2025-01-02 15:30:45.798936: Yayy! New best EMA pseudo Dice: 0.2921000123023987 
2025-01-02 15:30:46.683906:  
2025-01-02 15:30:46.683906: Epoch 50 
2025-01-02 15:30:46.688917: Current learning rate: 0.00536 
2025-01-02 15:31:35.504449: train_loss -0.7152 
2025-01-02 15:31:35.504953: val_loss -0.4212 
2025-01-02 15:31:35.511110: Pseudo dice [np.float32(0.3795)] 
2025-01-02 15:31:35.514138: Epoch time: 48.82 s 
2025-01-02 15:31:35.518152: Yayy! New best EMA pseudo Dice: 0.30090001225471497 
2025-01-02 15:31:36.313594:  
2025-01-02 15:31:36.313594: Epoch 51 
2025-01-02 15:31:36.319306: Current learning rate: 0.00526 
2025-01-02 15:32:20.239131: train_loss -0.6622 
2025-01-02 15:32:20.239131: val_loss -0.4237 
2025-01-02 15:32:20.245148: Pseudo dice [np.float32(0.2725)] 
2025-01-02 15:32:20.249187: Epoch time: 43.93 s 
2025-01-02 15:32:20.947197:  
2025-01-02 15:32:20.947197: Epoch 52 
2025-01-02 15:32:20.952209: Current learning rate: 0.00517 
2025-01-02 15:33:05.412017: train_loss -0.7204 
2025-01-02 15:33:05.412017: val_loss -0.4283 
2025-01-02 15:33:05.417596: Pseudo dice [np.float32(0.318)] 
2025-01-02 15:33:05.420623: Epoch time: 44.47 s 
2025-01-02 15:33:06.026943:  
2025-01-02 15:33:06.027944: Epoch 53 
2025-01-02 15:33:06.033014: Current learning rate: 0.00507 
2025-01-02 15:33:50.448154: train_loss -0.7077 
2025-01-02 15:33:50.449159: val_loss -0.5067 
2025-01-02 15:33:50.456688: Pseudo dice [np.float32(0.6044)] 
2025-01-02 15:33:50.463210: Epoch time: 44.42 s 
2025-01-02 15:33:50.465721: Yayy! New best EMA pseudo Dice: 0.3305000066757202 
2025-01-02 15:33:51.217371:  
2025-01-02 15:33:51.217875: Epoch 54 
2025-01-02 15:33:51.222889: Current learning rate: 0.00497 
2025-01-02 15:34:35.225206: train_loss -0.7189 
2025-01-02 15:34:35.225206: val_loss -0.5613 
2025-01-02 15:34:35.230219: Pseudo dice [np.float32(0.5508)] 
2025-01-02 15:34:35.232726: Epoch time: 44.01 s 
2025-01-02 15:34:35.236234: Yayy! New best EMA pseudo Dice: 0.35249999165534973 
2025-01-02 15:34:36.033445:  
2025-01-02 15:34:36.033445: Epoch 55 
2025-01-02 15:34:36.040011: Current learning rate: 0.00487 
