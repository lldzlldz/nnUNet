
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-02 02:30:55.988613: do_dummy_2d_data_aug: False 
2025-01-02 02:30:55.993553: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2025-01-02 02:30:55.995881: The split file contains 5 splits. 
2025-01-02 02:30:55.998879: Desired fold for training: 0 
2025-01-02 02:30:56.001881: This split has 50 training and 13 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [80, 192, 160], 'median_image_size_in_voxels': [252.0, 512.0, 512.0], 'spacing': [1.244979977607727, 0.78515625, 0.78515625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset006_Lung', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.244979977607727, 0.78515625, 0.78515625], 'original_median_shape_after_transp': [252, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2671.0, 'mean': -273.4598083496094, 'median': -162.0, 'min': -1024.0, 'percentile_00_5': -1024.0, 'percentile_99_5': 311.0, 'std': 346.9495849609375}}} 
 
2025-01-02 02:31:09.819682: unpacking dataset... 
2025-01-02 02:31:26.818755: unpacking done... 
2025-01-02 02:31:31.765750:  
2025-01-02 02:31:31.765750: Epoch 0 
2025-01-02 02:31:31.770761: Current learning rate: 0.01 
2025-01-02 02:32:19.996517: train_loss 0.083 
2025-01-02 02:32:19.997522: val_loss -0.1049 
2025-01-02 02:32:20.005041: Pseudo dice [np.float32(0.0)] 
2025-01-02 02:32:20.009559: Epoch time: 48.23 s 
2025-01-02 02:32:20.013689: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-02 02:32:20.682334:  
2025-01-02 02:32:20.682334: Epoch 1 
2025-01-02 02:32:20.688400: Current learning rate: 0.00996 
2025-01-02 02:33:04.046384: train_loss -0.1255 
2025-01-02 02:33:04.047425: val_loss -0.4019 
2025-01-02 02:33:04.053040: Pseudo dice [np.float32(0.4347)] 
2025-01-02 02:33:04.056663: Epoch time: 43.36 s 
2025-01-02 02:33:04.060189: Yayy! New best EMA pseudo Dice: 0.04349999874830246 
2025-01-02 02:33:04.808831:  
2025-01-02 02:33:04.808831: Epoch 2 
2025-01-02 02:33:04.816853: Current learning rate: 0.00993 
2025-01-02 02:33:49.002888: train_loss -0.2913 
2025-01-02 02:33:49.003891: val_loss -0.4387 
2025-01-02 02:33:49.009960: Pseudo dice [np.float32(0.3786)] 
2025-01-02 02:33:49.014505: Epoch time: 44.2 s 
2025-01-02 02:33:49.019095: Yayy! New best EMA pseudo Dice: 0.07699999958276749 
2025-01-02 02:33:49.768670:  
2025-01-02 02:33:49.768670: Epoch 3 
2025-01-02 02:33:49.774686: Current learning rate: 0.00989 
2025-01-02 02:34:33.153626: train_loss -0.3905 
2025-01-02 02:34:33.153626: val_loss -0.4938 
2025-01-02 02:34:33.159641: Pseudo dice [np.float32(0.48)] 
2025-01-02 02:34:33.163649: Epoch time: 43.39 s 
2025-01-02 02:34:33.167162: Yayy! New best EMA pseudo Dice: 0.11729999631643295 
2025-01-02 02:34:33.891793:  
2025-01-02 02:34:33.892296: Epoch 4 
2025-01-02 02:34:33.897314: Current learning rate: 0.00986 
2025-01-02 02:35:16.727697: train_loss -0.4487 
2025-01-02 02:35:16.728701: val_loss -0.6157 
2025-01-02 02:35:16.734224: Pseudo dice [np.float32(0.6729)] 
2025-01-02 02:35:16.737776: Epoch time: 42.84 s 
2025-01-02 02:35:16.740869: Yayy! New best EMA pseudo Dice: 0.1728000044822693 
2025-01-02 02:35:17.591966:  
2025-01-02 02:35:17.592969: Epoch 5 
2025-01-02 02:35:17.597530: Current learning rate: 0.00982 
2025-01-02 02:36:00.476626: train_loss -0.4587 
2025-01-02 02:36:00.477139: val_loss -0.5682 
2025-01-02 02:36:00.483180: Pseudo dice [np.float32(0.5587)] 
2025-01-02 02:36:00.485875: Epoch time: 42.89 s 
2025-01-02 02:36:00.489470: Yayy! New best EMA pseudo Dice: 0.21140000224113464 
2025-01-02 02:36:01.205045:  
2025-01-02 02:36:01.206049: Epoch 6 
2025-01-02 02:36:01.210607: Current learning rate: 0.00978 
2025-01-02 02:36:43.943604: train_loss -0.506 
2025-01-02 02:36:43.943604: val_loss -0.5633 
2025-01-02 02:36:43.949621: Pseudo dice [np.float32(0.5862)] 
2025-01-02 02:36:43.953630: Epoch time: 42.74 s 
2025-01-02 02:36:43.956136: Yayy! New best EMA pseudo Dice: 0.24889999628067017 
2025-01-02 02:36:44.694529:  
2025-01-02 02:36:44.694529: Epoch 7 
2025-01-02 02:36:44.700561: Current learning rate: 0.00975 
2025-01-02 02:37:27.424028: train_loss -0.422 
2025-01-02 02:37:27.425028: val_loss -0.4475 
2025-01-02 02:37:27.431554: Pseudo dice [np.float32(0.501)] 
2025-01-02 02:37:27.435564: Epoch time: 42.73 s 
2025-01-02 02:37:27.440576: Yayy! New best EMA pseudo Dice: 0.27410000562667847 
2025-01-02 02:37:28.200513:  
2025-01-02 02:37:28.200513: Epoch 8 
2025-01-02 02:37:28.206051: Current learning rate: 0.00971 
2025-01-02 02:38:10.950552: train_loss -0.4348 
2025-01-02 02:38:10.951066: val_loss -0.5432 
2025-01-02 02:38:10.955145: Pseudo dice [np.float32(0.5132)] 
2025-01-02 02:38:10.958230: Epoch time: 42.75 s 
2025-01-02 02:38:10.961256: Yayy! New best EMA pseudo Dice: 0.2980000078678131 
2025-01-02 02:38:11.713566:  
2025-01-02 02:38:11.714074: Epoch 9 
2025-01-02 02:38:11.719126: Current learning rate: 0.00968 
2025-01-02 02:38:54.477236: train_loss -0.4591 
2025-01-02 02:38:54.478746: val_loss -0.5514 
2025-01-02 02:38:54.484346: Pseudo dice [np.float32(0.5084)] 
2025-01-02 02:38:54.487909: Epoch time: 42.76 s 
2025-01-02 02:38:54.491437: Yayy! New best EMA pseudo Dice: 0.3190000057220459 
2025-01-02 02:38:55.206007:  
2025-01-02 02:38:55.207010: Epoch 10 
2025-01-02 02:38:55.211569: Current learning rate: 0.00964 
2025-01-02 02:39:37.923559: train_loss -0.5185 
2025-01-02 02:39:37.924563: val_loss -0.6078 
2025-01-02 02:39:37.930577: Pseudo dice [np.float32(0.6594)] 
2025-01-02 02:39:37.933585: Epoch time: 42.72 s 
2025-01-02 02:39:37.937094: Yayy! New best EMA pseudo Dice: 0.3531000018119812 
2025-01-02 02:39:38.667729:  
2025-01-02 02:39:38.667729: Epoch 11 
2025-01-02 02:39:38.673766: Current learning rate: 0.0096 
2025-01-02 02:40:21.352556: train_loss -0.4755 
2025-01-02 02:40:21.352556: val_loss -0.6361 
2025-01-02 02:40:21.361095: Pseudo dice [np.float32(0.6889)] 
2025-01-02 02:40:21.369632: Epoch time: 42.69 s 
2025-01-02 02:40:21.375159: Yayy! New best EMA pseudo Dice: 0.38670000433921814 
2025-01-02 02:40:22.153067:  
2025-01-02 02:40:22.153067: Epoch 12 
2025-01-02 02:40:22.159106: Current learning rate: 0.00957 
2025-01-02 02:41:05.042703: train_loss -0.5025 
2025-01-02 02:41:05.044209: val_loss -0.534 
2025-01-02 02:41:05.049730: Pseudo dice [np.float32(0.6092)] 
2025-01-02 02:41:05.052291: Epoch time: 42.89 s 
2025-01-02 02:41:05.055801: Yayy! New best EMA pseudo Dice: 0.4088999927043915 
2025-01-02 02:41:05.954876:  
2025-01-02 02:41:05.955380: Epoch 13 
2025-01-02 02:41:05.960402: Current learning rate: 0.00953 
2025-01-02 02:41:48.701913: train_loss -0.4852 
2025-01-02 02:41:48.702426: val_loss -0.677 
2025-01-02 02:41:48.708562: Pseudo dice [np.float32(0.6753)] 
2025-01-02 02:41:48.712092: Epoch time: 42.75 s 
2025-01-02 02:41:48.714613: Yayy! New best EMA pseudo Dice: 0.43560001254081726 
2025-01-02 02:41:49.462184:  
2025-01-02 02:41:49.462184: Epoch 14 
2025-01-02 02:41:49.468833: Current learning rate: 0.00949 
2025-01-02 02:42:32.211256: train_loss -0.5358 
2025-01-02 02:42:32.211766: val_loss -0.6207 
2025-01-02 02:42:32.218313: Pseudo dice [np.float32(0.712)] 
2025-01-02 02:42:32.221364: Epoch time: 42.75 s 
2025-01-02 02:42:32.224394: Yayy! New best EMA pseudo Dice: 0.46320000290870667 
2025-01-02 02:42:32.974915:  
2025-01-02 02:42:32.974915: Epoch 15 
2025-01-02 02:42:32.980930: Current learning rate: 0.00946 
2025-01-02 02:43:15.710907: train_loss -0.5512 
2025-01-02 02:43:15.710907: val_loss -0.5511 
2025-01-02 02:43:15.716922: Pseudo dice [np.float32(0.5802)] 
2025-01-02 02:43:15.720428: Epoch time: 42.74 s 
2025-01-02 02:43:15.723436: Yayy! New best EMA pseudo Dice: 0.4749000072479248 
2025-01-02 02:43:16.466134:  
2025-01-02 02:43:16.466134: Epoch 16 
2025-01-02 02:43:16.473168: Current learning rate: 0.00942 
2025-01-02 02:43:59.187512: train_loss -0.5431 
2025-01-02 02:43:59.188511: val_loss -0.5457 
2025-01-02 02:43:59.195029: Pseudo dice [np.float32(0.6093)] 
2025-01-02 02:43:59.198547: Epoch time: 42.72 s 
2025-01-02 02:43:59.201556: Yayy! New best EMA pseudo Dice: 0.48829999566078186 
2025-01-02 02:43:59.953470:  
2025-01-02 02:43:59.953470: Epoch 17 
2025-01-02 02:43:59.958574: Current learning rate: 0.00939 
2025-01-02 02:44:42.723618: train_loss -0.5274 
2025-01-02 02:44:42.724122: val_loss -0.6244 
2025-01-02 02:44:42.730137: Pseudo dice [np.float32(0.6652)] 
2025-01-02 02:44:42.733646: Epoch time: 42.77 s 
2025-01-02 02:44:42.736654: Yayy! New best EMA pseudo Dice: 0.5059999823570251 
2025-01-02 02:44:43.491693:  
2025-01-02 02:44:43.491693: Epoch 18 
2025-01-02 02:44:43.498240: Current learning rate: 0.00935 
2025-01-02 02:45:26.311546: train_loss -0.5961 
2025-01-02 02:45:26.313052: val_loss -0.6172 
2025-01-02 02:45:26.318670: Pseudo dice [np.float32(0.6672)] 
2025-01-02 02:45:26.321736: Epoch time: 42.82 s 
2025-01-02 02:45:26.325247: Yayy! New best EMA pseudo Dice: 0.5220999717712402 
2025-01-02 02:45:27.089189:  
2025-01-02 02:45:27.089189: Epoch 19 
2025-01-02 02:45:27.095209: Current learning rate: 0.00931 
2025-01-02 02:46:09.608732: train_loss -0.5823 
2025-01-02 02:46:09.609735: val_loss -0.6596 
2025-01-02 02:46:09.615748: Pseudo dice [np.float32(0.7034)] 
2025-01-02 02:46:09.618757: Epoch time: 42.52 s 
2025-01-02 02:46:09.622267: Yayy! New best EMA pseudo Dice: 0.5403000116348267 
2025-01-02 02:46:10.517172:  
2025-01-02 02:46:10.517674: Epoch 20 
2025-01-02 02:46:10.522701: Current learning rate: 0.00928 
2025-01-02 02:46:53.071700: train_loss -0.5668 
2025-01-02 02:46:53.072210: val_loss -0.6503 
2025-01-02 02:46:53.078366: Pseudo dice [np.float32(0.6678)] 
2025-01-02 02:46:53.082444: Epoch time: 42.56 s 
2025-01-02 02:46:53.085502: Yayy! New best EMA pseudo Dice: 0.5529999732971191 
2025-01-02 02:46:53.852892:  
2025-01-02 02:46:53.852892: Epoch 21 
2025-01-02 02:46:53.859483: Current learning rate: 0.00924 
2025-01-02 02:47:36.389324: train_loss -0.5743 
2025-01-02 02:47:36.389835: val_loss -0.6354 
2025-01-02 02:47:36.395920: Pseudo dice [np.float32(0.6567)] 
2025-01-02 02:47:36.398445: Epoch time: 42.54 s 
2025-01-02 02:47:36.402484: Yayy! New best EMA pseudo Dice: 0.5633999705314636 
2025-01-02 02:47:37.121611:  
2025-01-02 02:47:37.121611: Epoch 22 
2025-01-02 02:47:37.127687: Current learning rate: 0.0092 
2025-01-02 02:48:19.642805: train_loss -0.546 
2025-01-02 02:48:19.643307: val_loss -0.6636 
2025-01-02 02:48:19.649379: Pseudo dice [np.float32(0.7566)] 
2025-01-02 02:48:19.652974: Epoch time: 42.52 s 
2025-01-02 02:48:19.656005: Yayy! New best EMA pseudo Dice: 0.5827000141143799 
2025-01-02 02:48:20.383480:  
2025-01-02 02:48:20.383480: Epoch 23 
2025-01-02 02:48:20.389017: Current learning rate: 0.00917 
2025-01-02 02:49:02.929045: train_loss -0.6018 
2025-01-02 02:49:02.930548: val_loss -0.6721 
2025-01-02 02:49:02.936564: Pseudo dice [np.float32(0.6782)] 
2025-01-02 02:49:02.940092: Epoch time: 42.55 s 
2025-01-02 02:49:02.943141: Yayy! New best EMA pseudo Dice: 0.5922999978065491 
2025-01-02 02:49:03.661351:  
2025-01-02 02:49:03.661351: Epoch 24 
2025-01-02 02:49:03.666928: Current learning rate: 0.00913 
2025-01-02 02:49:46.279379: train_loss -0.5689 
2025-01-02 02:49:46.280384: val_loss -0.5946 
2025-01-02 02:49:46.287090: Pseudo dice [np.float32(0.6608)] 
2025-01-02 02:49:46.292140: Epoch time: 42.62 s 
2025-01-02 02:49:46.295670: Yayy! New best EMA pseudo Dice: 0.5990999937057495 
2025-01-02 02:49:47.031109:  
2025-01-02 02:49:47.031109: Epoch 25 
2025-01-02 02:49:47.036122: Current learning rate: 0.0091 
2025-01-02 02:50:29.592672: train_loss -0.5851 
2025-01-02 02:50:29.593176: val_loss -0.5138 
2025-01-02 02:50:29.599510: Pseudo dice [np.float32(0.6813)] 
2025-01-02 02:50:29.602546: Epoch time: 42.56 s 
2025-01-02 02:50:29.606096: Yayy! New best EMA pseudo Dice: 0.6072999835014343 
2025-01-02 02:50:30.325929:  
2025-01-02 02:50:30.326937: Epoch 26 
2025-01-02 02:50:30.336499: Current learning rate: 0.00906 
2025-01-02 02:51:12.874953: train_loss -0.6046 
2025-01-02 02:51:12.875455: val_loss -0.677 
2025-01-02 02:51:12.881474: Pseudo dice [np.float32(0.7413)] 
2025-01-02 02:51:12.884987: Epoch time: 42.55 s 
2025-01-02 02:51:12.888009: Yayy! New best EMA pseudo Dice: 0.6207000017166138 
2025-01-02 02:51:13.628941:  
2025-01-02 02:51:13.628941: Epoch 27 
2025-01-02 02:51:13.633956: Current learning rate: 0.00902 
2025-01-02 02:51:56.214299: train_loss -0.6117 
2025-01-02 02:51:56.214299: val_loss -0.6176 
2025-01-02 02:51:56.220314: Pseudo dice [np.float32(0.6679)] 
2025-01-02 02:51:56.225329: Epoch time: 42.59 s 
2025-01-02 02:51:56.229338: Yayy! New best EMA pseudo Dice: 0.6254000067710876 
2025-01-02 02:51:57.108040:  
2025-01-02 02:51:57.108040: Epoch 28 
2025-01-02 02:51:57.116563: Current learning rate: 0.00899 
2025-01-02 02:52:39.654688: train_loss -0.5895 
2025-01-02 02:52:39.655193: val_loss -0.7263 
2025-01-02 02:52:39.661211: Pseudo dice [np.float32(0.79)] 
2025-01-02 02:52:39.665222: Epoch time: 42.55 s 
2025-01-02 02:52:39.667731: Yayy! New best EMA pseudo Dice: 0.6419000029563904 
2025-01-02 02:52:40.386534:  
2025-01-02 02:52:40.387534: Epoch 29 
2025-01-02 02:52:40.393137: Current learning rate: 0.00895 
2025-01-02 02:53:22.998028: train_loss -0.5791 
2025-01-02 02:53:22.999032: val_loss -0.6365 
2025-01-02 02:53:23.005102: Pseudo dice [np.float32(0.6946)] 
2025-01-02 02:53:23.008905: Epoch time: 42.61 s 
2025-01-02 02:53:23.011506: Yayy! New best EMA pseudo Dice: 0.6471999883651733 
2025-01-02 02:53:23.754356:  
2025-01-02 02:53:23.754356: Epoch 30 
2025-01-02 02:53:23.759910: Current learning rate: 0.00891 
2025-01-02 02:54:06.337891: train_loss -0.5798 
2025-01-02 02:54:06.337891: val_loss -0.7184 
2025-01-02 02:54:06.343907: Pseudo dice [np.float32(0.7785)] 
2025-01-02 02:54:06.347415: Epoch time: 42.58 s 
2025-01-02 02:54:06.352929: Yayy! New best EMA pseudo Dice: 0.6603000164031982 
2025-01-02 02:54:07.093872:  
2025-01-02 02:54:07.094374: Epoch 31 
2025-01-02 02:54:07.100393: Current learning rate: 0.00888 
2025-01-02 02:54:49.632881: train_loss -0.6142 
2025-01-02 02:54:49.633903: val_loss -0.7099 
2025-01-02 02:54:49.639506: Pseudo dice [np.float32(0.7943)] 
2025-01-02 02:54:49.642636: Epoch time: 42.54 s 
2025-01-02 02:54:49.645698: Yayy! New best EMA pseudo Dice: 0.6736999750137329 
2025-01-02 02:54:50.389728:  
2025-01-02 02:54:50.390732: Epoch 32 
2025-01-02 02:54:50.395283: Current learning rate: 0.00884 
2025-01-02 02:55:33.006694: train_loss -0.5337 
2025-01-02 02:55:33.006694: val_loss -0.622 
2025-01-02 02:55:33.013220: Pseudo dice [np.float32(0.7084)] 
2025-01-02 02:55:33.015729: Epoch time: 42.62 s 
2025-01-02 02:55:33.018746: Yayy! New best EMA pseudo Dice: 0.6772000193595886 
2025-01-02 02:55:33.764421:  
2025-01-02 02:55:33.764421: Epoch 33 
2025-01-02 02:55:33.769589: Current learning rate: 0.0088 
2025-01-02 02:56:16.339846: train_loss -0.6144 
2025-01-02 02:56:16.339846: val_loss -0.5896 
2025-01-02 02:56:16.346871: Pseudo dice [np.float32(0.6832)] 
2025-01-02 02:56:16.349883: Epoch time: 42.58 s 
2025-01-02 02:56:16.353395: Yayy! New best EMA pseudo Dice: 0.6777999997138977 
2025-01-02 02:56:17.114442:  
2025-01-02 02:56:17.114945: Epoch 34 
2025-01-02 02:56:17.123542: Current learning rate: 0.00877 
2025-01-02 02:56:59.662930: train_loss -0.634 
2025-01-02 02:56:59.663933: val_loss -0.6455 
2025-01-02 02:56:59.669590: Pseudo dice [np.float32(0.7247)] 
2025-01-02 02:56:59.673150: Epoch time: 42.55 s 
2025-01-02 02:56:59.675655: Yayy! New best EMA pseudo Dice: 0.6825000047683716 
2025-01-02 02:57:00.453793:  
2025-01-02 02:57:00.454798: Epoch 35 
2025-01-02 02:57:00.463003: Current learning rate: 0.00873 
2025-01-02 02:57:42.997602: train_loss -0.6274 
2025-01-02 02:57:42.998109: val_loss -0.5723 
2025-01-02 02:57:43.003879: Pseudo dice [np.float32(0.624)] 
2025-01-02 02:57:43.008608: Epoch time: 42.54 s 
2025-01-02 02:57:43.743505:  
2025-01-02 02:57:43.744506: Epoch 36 
2025-01-02 02:57:43.751128: Current learning rate: 0.00869 
2025-01-02 02:58:26.251558: train_loss -0.5767 
2025-01-02 02:58:26.251558: val_loss -0.6457 
2025-01-02 02:58:26.257678: Pseudo dice [np.float32(0.7004)] 
2025-01-02 02:58:26.260972: Epoch time: 42.51 s 
2025-01-02 02:58:26.841526:  
2025-01-02 02:58:26.841526: Epoch 37 
2025-01-02 02:58:26.850177: Current learning rate: 0.00866 
2025-01-02 02:59:09.369524: train_loss -0.6373 
2025-01-02 02:59:09.369524: val_loss -0.6605 
2025-01-02 02:59:09.379050: Pseudo dice [np.float32(0.7067)] 
2025-01-02 02:59:09.382060: Epoch time: 42.53 s 
2025-01-02 02:59:09.970135:  
2025-01-02 02:59:09.970135: Epoch 38 
2025-01-02 02:59:09.978761: Current learning rate: 0.00862 
2025-01-02 02:59:52.532879: train_loss -0.6178 
2025-01-02 02:59:52.533883: val_loss -0.6718 
2025-01-02 02:59:52.540397: Pseudo dice [np.float32(0.7257)] 
2025-01-02 02:59:52.542930: Epoch time: 42.56 s 
2025-01-02 02:59:52.546549: Yayy! New best EMA pseudo Dice: 0.6862000226974487 
2025-01-02 02:59:53.320025:  
2025-01-02 02:59:53.321026: Epoch 39 
2025-01-02 02:59:53.326250: Current learning rate: 0.00858 
2025-01-02 03:00:35.798057: train_loss -0.6156 
2025-01-02 03:00:35.799066: val_loss -0.6872 
2025-01-02 03:00:35.804724: Pseudo dice [np.float32(0.7494)] 
2025-01-02 03:00:35.809767: Epoch time: 42.48 s 
2025-01-02 03:00:35.812788: Yayy! New best EMA pseudo Dice: 0.6924999952316284 
2025-01-02 03:00:36.582007:  
2025-01-02 03:00:36.582007: Epoch 40 
2025-01-02 03:00:36.588648: Current learning rate: 0.00855 
2025-01-02 03:01:19.105818: train_loss -0.628 
2025-01-02 03:01:19.106818: val_loss -0.6816 
2025-01-02 03:01:19.115841: Pseudo dice [np.float32(0.7539)] 
2025-01-02 03:01:19.121904: Epoch time: 42.52 s 
2025-01-02 03:01:19.124912: Yayy! New best EMA pseudo Dice: 0.6985999941825867 
2025-01-02 03:01:19.891850:  
2025-01-02 03:01:19.891850: Epoch 41 
2025-01-02 03:01:19.898448: Current learning rate: 0.00851 
2025-01-02 03:02:02.424994: train_loss -0.6139 
2025-01-02 03:02:02.424994: val_loss -0.594 
2025-01-02 03:02:02.431515: Pseudo dice [np.float32(0.6342)] 
2025-01-02 03:02:02.435067: Epoch time: 42.53 s 
2025-01-02 03:02:02.994936:  
2025-01-02 03:02:02.994936: Epoch 42 
2025-01-02 03:02:03.001015: Current learning rate: 0.00847 
2025-01-02 03:02:45.528019: train_loss -0.6067 
2025-01-02 03:02:45.528527: val_loss -0.7142 
2025-01-02 03:02:45.534127: Pseudo dice [np.float32(0.7778)] 
2025-01-02 03:02:45.538188: Epoch time: 42.53 s 
2025-01-02 03:02:45.541221: Yayy! New best EMA pseudo Dice: 0.7006999850273132 
2025-01-02 03:02:46.425638:  
2025-01-02 03:02:46.425638: Epoch 43 
2025-01-02 03:02:46.431205: Current learning rate: 0.00844 
2025-01-02 03:03:28.980414: train_loss -0.6515 
2025-01-02 03:03:28.981433: val_loss -0.6591 
2025-01-02 03:03:28.987536: Pseudo dice [np.float32(0.7464)] 
2025-01-02 03:03:28.990584: Epoch time: 42.56 s 
2025-01-02 03:03:28.993645: Yayy! New best EMA pseudo Dice: 0.705299973487854 
2025-01-02 03:03:29.719342:  
2025-01-02 03:03:29.720342: Epoch 44 
2025-01-02 03:03:29.725947: Current learning rate: 0.0084 
2025-01-02 03:04:12.269088: train_loss -0.6362 
2025-01-02 03:04:12.269088: val_loss -0.7064 
2025-01-02 03:04:12.275606: Pseudo dice [np.float32(0.7721)] 
2025-01-02 03:04:12.279114: Epoch time: 42.55 s 
2025-01-02 03:04:12.282124: Yayy! New best EMA pseudo Dice: 0.7120000123977661 
2025-01-02 03:04:13.010947:  
2025-01-02 03:04:13.010947: Epoch 45 
2025-01-02 03:04:13.017035: Current learning rate: 0.00836 
2025-01-02 03:04:55.508241: train_loss -0.639 
2025-01-02 03:04:55.508752: val_loss -0.7275 
2025-01-02 03:04:55.512779: Pseudo dice [np.float32(0.7942)] 
2025-01-02 03:04:55.516315: Epoch time: 42.5 s 
2025-01-02 03:04:55.518833: Yayy! New best EMA pseudo Dice: 0.7202000021934509 
2025-01-02 03:04:56.257690:  
2025-01-02 03:04:56.258694: Epoch 46 
2025-01-02 03:04:56.262740: Current learning rate: 0.00833 
2025-01-02 03:05:38.786056: train_loss -0.631 
2025-01-02 03:05:38.786559: val_loss -0.748 
2025-01-02 03:05:38.792573: Pseudo dice [np.float32(0.7683)] 
2025-01-02 03:05:38.796079: Epoch time: 42.53 s 
2025-01-02 03:05:38.799124: Yayy! New best EMA pseudo Dice: 0.7250000238418579 
2025-01-02 03:05:39.520205:  
2025-01-02 03:05:39.520205: Epoch 47 
2025-01-02 03:05:39.525216: Current learning rate: 0.00829 
2025-01-02 03:06:22.053116: train_loss -0.6508 
2025-01-02 03:06:22.053116: val_loss -0.6289 
2025-01-02 03:06:22.060637: Pseudo dice [np.float32(0.6029)] 
2025-01-02 03:06:22.064142: Epoch time: 42.53 s 
2025-01-02 03:06:22.620996:  
2025-01-02 03:06:22.620996: Epoch 48 
2025-01-02 03:06:22.627569: Current learning rate: 0.00825 
2025-01-02 03:07:05.136835: train_loss -0.6242 
2025-01-02 03:07:05.137343: val_loss -0.6902 
2025-01-02 03:07:05.143419: Pseudo dice [np.float32(0.7402)] 
2025-01-02 03:07:05.146427: Epoch time: 42.52 s 
2025-01-02 03:07:05.709774:  
2025-01-02 03:07:05.710774: Epoch 49 
2025-01-02 03:07:05.716290: Current learning rate: 0.00822 
2025-01-02 03:07:48.234114: train_loss -0.5886 
2025-01-02 03:07:48.234617: val_loss -0.6772 
2025-01-02 03:07:48.240794: Pseudo dice [np.float32(0.7412)] 
2025-01-02 03:07:48.243340: Epoch time: 42.52 s 
2025-01-02 03:07:48.958144:  
2025-01-02 03:07:48.959149: Epoch 50 
2025-01-02 03:07:48.963690: Current learning rate: 0.00818 
2025-01-02 03:08:31.513436: train_loss -0.6048 
2025-01-02 03:08:31.513942: val_loss -0.7123 
2025-01-02 03:08:31.520028: Pseudo dice [np.float32(0.7653)] 
2025-01-02 03:08:31.523581: Epoch time: 42.56 s 
2025-01-02 03:08:32.232491:  
2025-01-02 03:08:32.232491: Epoch 51 
2025-01-02 03:08:32.239053: Current learning rate: 0.00814 
2025-01-02 03:09:14.776307: train_loss -0.6124 
2025-01-02 03:09:14.782880: val_loss -0.7024 
2025-01-02 03:09:14.785407: Pseudo dice [np.float32(0.7532)] 
2025-01-02 03:09:14.789435: Epoch time: 42.54 s 
2025-01-02 03:09:14.792459: Yayy! New best EMA pseudo Dice: 0.7258999943733215 
2025-01-02 03:09:15.531642:  
2025-01-02 03:09:15.531642: Epoch 52 
2025-01-02 03:09:15.538249: Current learning rate: 0.00811 
2025-01-02 03:09:58.061146: train_loss -0.6261 
2025-01-02 03:09:58.061146: val_loss -0.6461 
2025-01-02 03:09:58.071256: Pseudo dice [np.float32(0.7116)] 
2025-01-02 03:09:58.076293: Epoch time: 42.53 s 
2025-01-02 03:09:58.635281:  
2025-01-02 03:09:58.635281: Epoch 53 
2025-01-02 03:09:58.640863: Current learning rate: 0.00807 
2025-01-02 03:10:41.142716: train_loss -0.6427 
2025-01-02 03:10:41.143713: val_loss -0.6375 
2025-01-02 03:10:41.149228: Pseudo dice [np.float32(0.666)] 
2025-01-02 03:10:41.151734: Epoch time: 42.51 s 
2025-01-02 03:10:41.711832:  
2025-01-02 03:10:41.711832: Epoch 54 
2025-01-02 03:10:41.717868: Current learning rate: 0.00803 
2025-01-02 03:11:24.243968: train_loss -0.6527 
2025-01-02 03:11:24.244472: val_loss -0.6861 
2025-01-02 03:11:24.250492: Pseudo dice [np.float32(0.6972)] 
2025-01-02 03:11:24.254004: Epoch time: 42.53 s 
2025-01-02 03:11:24.817943:  
2025-01-02 03:11:24.818446: Epoch 55 
2025-01-02 03:11:24.824461: Current learning rate: 0.008 
2025-01-02 03:12:07.381086: train_loss -0.621 
2025-01-02 03:12:07.381589: val_loss -0.7033 
2025-01-02 03:12:07.387661: Pseudo dice [np.float32(0.7428)] 
2025-01-02 03:12:07.390177: Epoch time: 42.56 s 
2025-01-02 03:12:07.948896:  
2025-01-02 03:12:07.948896: Epoch 56 
2025-01-02 03:12:07.954910: Current learning rate: 0.00796 
2025-01-02 03:12:50.460009: train_loss -0.6069 
2025-01-02 03:12:50.461512: val_loss -0.6996 
2025-01-02 03:12:50.466523: Pseudo dice [np.float32(0.7734)] 
2025-01-02 03:12:50.470033: Epoch time: 42.51 s 
2025-01-02 03:12:51.036679:  
2025-01-02 03:12:51.037682: Epoch 57 
2025-01-02 03:12:51.043780: Current learning rate: 0.00792 
2025-01-02 03:13:33.553216: train_loss -0.667 
2025-01-02 03:13:33.553724: val_loss -0.6902 
2025-01-02 03:13:33.559964: Pseudo dice [np.float32(0.7482)] 
2025-01-02 03:13:33.567075: Epoch time: 42.52 s 
2025-01-02 03:13:33.573200: Yayy! New best EMA pseudo Dice: 0.7268999814987183 
2025-01-02 03:13:34.315582:  
2025-01-02 03:13:34.315582: Epoch 58 
2025-01-02 03:13:34.324108: Current learning rate: 0.00789 
2025-01-02 03:14:16.896895: train_loss -0.6098 
2025-01-02 03:14:16.897398: val_loss -0.6591 
2025-01-02 03:14:16.905918: Pseudo dice [np.float32(0.7009)] 
2025-01-02 03:14:16.909956: Epoch time: 42.58 s 
2025-01-02 03:14:17.634498:  
2025-01-02 03:14:17.635498: Epoch 59 
2025-01-02 03:14:17.641121: Current learning rate: 0.00785 
2025-01-02 03:15:00.162961: train_loss -0.6578 
2025-01-02 03:15:00.163464: val_loss -0.6542 
2025-01-02 03:15:00.172025: Pseudo dice [np.float32(0.6688)] 
2025-01-02 03:15:00.178539: Epoch time: 42.53 s 
2025-01-02 03:15:00.740483:  
2025-01-02 03:15:00.740483: Epoch 60 
2025-01-02 03:15:00.745586: Current learning rate: 0.00781 
2025-01-02 03:15:43.251501: train_loss -0.6572 
2025-01-02 03:15:43.252501: val_loss -0.6903 
2025-01-02 03:15:43.258014: Pseudo dice [np.float32(0.7523)] 
2025-01-02 03:15:43.261033: Epoch time: 42.51 s 
2025-01-02 03:15:43.822191:  
2025-01-02 03:15:43.822191: Epoch 61 
2025-01-02 03:15:43.828208: Current learning rate: 0.00777 
2025-01-02 03:16:26.341073: train_loss -0.6575 
2025-01-02 03:16:26.342583: val_loss -0.6719 
2025-01-02 03:16:26.348702: Pseudo dice [np.float32(0.7501)] 
2025-01-02 03:16:26.352760: Epoch time: 42.52 s 
2025-01-02 03:16:26.918084:  
2025-01-02 03:16:26.919090: Epoch 62 
2025-01-02 03:16:26.925198: Current learning rate: 0.00774 
2025-01-02 03:17:16.692607: train_loss -0.7019 
2025-01-02 03:17:16.693111: val_loss -0.7463 
2025-01-02 03:17:16.701257: Pseudo dice [np.float32(0.7892)] 
2025-01-02 03:17:16.705436: Epoch time: 49.77 s 
2025-01-02 03:17:16.708539: Yayy! New best EMA pseudo Dice: 0.7312999963760376 
2025-01-02 03:17:17.564581:  
2025-01-02 03:17:17.564581: Epoch 63 
2025-01-02 03:17:17.570597: Current learning rate: 0.0077 
2025-01-02 03:18:01.383238: train_loss -0.6693 
2025-01-02 03:18:01.384244: val_loss -0.6581 
2025-01-02 03:18:01.391770: Pseudo dice [np.float32(0.7356)] 
2025-01-02 03:18:01.398288: Epoch time: 43.82 s 
2025-01-02 03:18:01.405307: Yayy! New best EMA pseudo Dice: 0.7318000197410583 
2025-01-02 03:18:02.287843:  
2025-01-02 03:18:02.288346: Epoch 64 
2025-01-02 03:18:02.295869: Current learning rate: 0.00766 
2025-01-02 03:18:45.941718: train_loss -0.6461 
2025-01-02 03:18:45.942722: val_loss -0.6692 
2025-01-02 03:18:45.948736: Pseudo dice [np.float32(0.7145)] 
2025-01-02 03:18:45.952748: Epoch time: 43.65 s 
2025-01-02 03:18:46.559598:  
2025-01-02 03:18:46.559598: Epoch 65 
2025-01-02 03:18:46.565631: Current learning rate: 0.00763 
2025-01-02 03:19:30.402974: train_loss -0.637 
2025-01-02 03:19:30.402974: val_loss -0.6439 
2025-01-02 03:19:30.410000: Pseudo dice [np.float32(0.7194)] 
2025-01-02 03:19:30.414011: Epoch time: 43.84 s 
2025-01-02 03:19:30.974648:  
2025-01-02 03:19:30.975151: Epoch 66 
2025-01-02 03:19:30.981170: Current learning rate: 0.00759 
2025-01-02 03:20:13.626962: train_loss -0.6378 
2025-01-02 03:20:13.627962: val_loss -0.7189 
2025-01-02 03:20:13.634483: Pseudo dice [np.float32(0.7497)] 
2025-01-02 03:20:13.638494: Epoch time: 42.65 s 
2025-01-02 03:20:14.360437:  
2025-01-02 03:20:14.360940: Epoch 67 
2025-01-02 03:20:14.365952: Current learning rate: 0.00755 
2025-01-02 03:20:56.985107: train_loss -0.6576 
2025-01-02 03:20:56.986111: val_loss -0.6488 
2025-01-02 03:20:56.992767: Pseudo dice [np.float32(0.6923)] 
2025-01-02 03:20:56.996345: Epoch time: 42.63 s 
2025-01-02 03:20:57.570398:  
2025-01-02 03:20:57.570398: Epoch 68 
2025-01-02 03:20:57.577003: Current learning rate: 0.00751 
2025-01-02 03:21:40.213254: train_loss -0.609 
2025-01-02 03:21:40.214254: val_loss -0.667 
2025-01-02 03:21:40.220774: Pseudo dice [np.float32(0.7094)] 
2025-01-02 03:21:40.224788: Epoch time: 42.64 s 
2025-01-02 03:21:40.804879:  
2025-01-02 03:21:40.805884: Epoch 69 
2025-01-02 03:21:40.810786: Current learning rate: 0.00748 
2025-01-02 03:22:23.488971: train_loss -0.6254 
2025-01-02 03:22:23.489474: val_loss -0.6635 
2025-01-02 03:22:23.495494: Pseudo dice [np.float32(0.7469)] 
2025-01-02 03:22:23.499504: Epoch time: 42.68 s 
2025-01-02 03:22:24.089276:  
2025-01-02 03:22:24.089276: Epoch 70 
2025-01-02 03:22:24.095352: Current learning rate: 0.00744 
2025-01-02 03:23:06.737249: train_loss -0.623 
2025-01-02 03:23:06.737249: val_loss -0.7127 
2025-01-02 03:23:06.743772: Pseudo dice [np.float32(0.7958)] 
2025-01-02 03:23:06.748282: Epoch time: 42.65 s 
2025-01-02 03:23:06.751826: Yayy! New best EMA pseudo Dice: 0.7343999743461609 
2025-01-02 03:23:07.509703:  
2025-01-02 03:23:07.510704: Epoch 71 
2025-01-02 03:23:07.516222: Current learning rate: 0.0074 
2025-01-02 03:23:50.163157: train_loss -0.6418 
2025-01-02 03:23:50.164160: val_loss -0.6225 
2025-01-02 03:23:50.170677: Pseudo dice [np.float32(0.6403)] 
2025-01-02 03:23:50.174184: Epoch time: 42.65 s 
2025-01-02 03:23:50.755435:  
2025-01-02 03:23:50.755947: Epoch 72 
2025-01-02 03:23:50.761000: Current learning rate: 0.00737 
2025-01-02 03:24:33.408450: train_loss -0.6392 
2025-01-02 03:24:33.409956: val_loss -0.742 
2025-01-02 03:24:33.415499: Pseudo dice [np.float32(0.8143)] 
2025-01-02 03:24:33.419284: Epoch time: 42.65 s 
2025-01-02 03:24:33.995603:  
2025-01-02 03:24:33.995603: Epoch 73 
2025-01-02 03:24:34.001166: Current learning rate: 0.00733 
2025-01-02 03:25:16.712605: train_loss -0.5933 
2025-01-02 03:25:16.712605: val_loss -0.6356 
2025-01-02 03:25:16.719620: Pseudo dice [np.float32(0.7344)] 
2025-01-02 03:25:16.722629: Epoch time: 42.72 s 
2025-01-02 03:25:17.304338:  
2025-01-02 03:25:17.305339: Epoch 74 
2025-01-02 03:25:17.310942: Current learning rate: 0.00729 
2025-01-02 03:26:00.128031: train_loss -0.6191 
2025-01-02 03:26:00.129030: val_loss -0.643 
2025-01-02 03:26:00.135552: Pseudo dice [np.float32(0.721)] 
2025-01-02 03:26:00.139057: Epoch time: 42.82 s 
2025-01-02 03:26:00.873810:  
2025-01-02 03:26:00.874312: Epoch 75 
2025-01-02 03:26:00.879323: Current learning rate: 0.00725 
2025-01-02 03:26:43.530823: train_loss -0.6577 
2025-01-02 03:26:43.531326: val_loss -0.7271 
2025-01-02 03:26:43.537340: Pseudo dice [np.float32(0.7893)] 
2025-01-02 03:26:43.540846: Epoch time: 42.66 s 
2025-01-02 03:26:43.543854: Yayy! New best EMA pseudo Dice: 0.7383000254631042 
2025-01-02 03:26:44.289504:  
2025-01-02 03:26:44.289504: Epoch 76 
2025-01-02 03:26:44.295519: Current learning rate: 0.00722 
2025-01-02 03:27:26.952873: train_loss -0.6343 
2025-01-02 03:27:26.952873: val_loss -0.6775 
2025-01-02 03:27:26.959389: Pseudo dice [np.float32(0.773)] 
2025-01-02 03:27:26.963900: Epoch time: 42.66 s 
2025-01-02 03:27:26.967425: Yayy! New best EMA pseudo Dice: 0.7418000102043152 
2025-01-02 03:27:27.730616:  
2025-01-02 03:27:27.731620: Epoch 77 
2025-01-02 03:27:27.736173: Current learning rate: 0.00718 
2025-01-02 03:28:10.393704: train_loss -0.6591 
2025-01-02 03:28:10.393704: val_loss -0.7079 
2025-01-02 03:28:10.400218: Pseudo dice [np.float32(0.7593)] 
2025-01-02 03:28:10.404230: Epoch time: 42.66 s 
2025-01-02 03:28:10.407785: Yayy! New best EMA pseudo Dice: 0.7434999942779541 
2025-01-02 03:28:11.172988:  
2025-01-02 03:28:11.173490: Epoch 78 
2025-01-02 03:28:11.179511: Current learning rate: 0.00714 
2025-01-02 03:28:53.873512: train_loss -0.66 
2025-01-02 03:28:53.874014: val_loss -0.7088 
2025-01-02 03:28:53.880034: Pseudo dice [np.float32(0.7739)] 
2025-01-02 03:28:53.884046: Epoch time: 42.7 s 
2025-01-02 03:28:53.887556: Yayy! New best EMA pseudo Dice: 0.7465999722480774 
2025-01-02 03:28:54.649740:  
2025-01-02 03:28:54.650745: Epoch 79 
2025-01-02 03:28:54.655293: Current learning rate: 0.0071 
2025-01-02 03:29:37.353100: train_loss -0.6158 
2025-01-02 03:29:37.354113: val_loss -0.6846 
2025-01-02 03:29:37.360697: Pseudo dice [np.float32(0.7436)] 
2025-01-02 03:29:37.364264: Epoch time: 42.7 s 
2025-01-02 03:29:37.956931:  
2025-01-02 03:29:37.956931: Epoch 80 
2025-01-02 03:29:37.962991: Current learning rate: 0.00707 
2025-01-02 03:30:20.689994: train_loss -0.6752 
2025-01-02 03:30:20.690498: val_loss -0.7106 
2025-01-02 03:30:20.696522: Pseudo dice [np.float32(0.7675)] 
2025-01-02 03:30:20.700532: Epoch time: 42.73 s 
2025-01-02 03:30:20.704042: Yayy! New best EMA pseudo Dice: 0.7483999729156494 
2025-01-02 03:30:21.470600:  
2025-01-02 03:30:21.470600: Epoch 81 
2025-01-02 03:30:21.476191: Current learning rate: 0.00703 
2025-01-02 03:31:04.030246: train_loss -0.658 
2025-01-02 03:31:04.031251: val_loss -0.6898 
2025-01-02 03:31:04.038881: Pseudo dice [np.float32(0.6849)] 
2025-01-02 03:31:04.041425: Epoch time: 42.56 s 
2025-01-02 03:31:04.635981:  
2025-01-02 03:31:04.636494: Epoch 82 
2025-01-02 03:31:04.642623: Current learning rate: 0.00699 
2025-01-02 03:31:47.201441: train_loss -0.6781 
2025-01-02 03:31:47.202444: val_loss -0.7155 
2025-01-02 03:31:47.209356: Pseudo dice [np.float32(0.7315)] 
2025-01-02 03:31:47.213368: Epoch time: 42.57 s 
2025-01-02 03:31:47.934947:  
2025-01-02 03:31:47.934947: Epoch 83 
2025-01-02 03:31:47.940089: Current learning rate: 0.00696 
2025-01-02 03:32:35.463457: train_loss -0.661 
2025-01-02 03:32:35.463457: val_loss -0.7077 
2025-01-02 03:32:35.469981: Pseudo dice [np.float32(0.7928)] 
2025-01-02 03:32:35.473492: Epoch time: 47.53 s 
2025-01-02 03:32:36.034786:  
2025-01-02 03:32:36.035786: Epoch 84 
2025-01-02 03:32:36.041428: Current learning rate: 0.00692 
2025-01-02 03:33:18.713953: train_loss -0.7059 
2025-01-02 03:33:18.713953: val_loss -0.6777 
2025-01-02 03:33:18.721005: Pseudo dice [np.float32(0.7382)] 
2025-01-02 03:33:18.724619: Epoch time: 42.68 s 
2025-01-02 03:33:19.282343:  
2025-01-02 03:33:19.282343: Epoch 85 
2025-01-02 03:33:19.288470: Current learning rate: 0.00688 
2025-01-02 03:34:01.999014: train_loss -0.684 
2025-01-02 03:34:01.999532: val_loss -0.6351 
2025-01-02 03:34:02.005228: Pseudo dice [np.float32(0.7187)] 
2025-01-02 03:34:02.007773: Epoch time: 42.72 s 
2025-01-02 03:34:02.566874:  
2025-01-02 03:34:02.567877: Epoch 86 
2025-01-02 03:34:02.572698: Current learning rate: 0.00684 
2025-01-02 03:34:45.242419: train_loss -0.6953 
2025-01-02 03:34:45.242419: val_loss -0.6422 
2025-01-02 03:34:45.248430: Pseudo dice [np.float32(0.6913)] 
2025-01-02 03:34:45.251988: Epoch time: 42.67 s 
2025-01-02 03:34:45.813061:  
2025-01-02 03:34:45.814068: Epoch 87 
2025-01-02 03:34:45.819606: Current learning rate: 0.0068 
2025-01-02 03:35:28.520268: train_loss -0.6698 
2025-01-02 03:35:28.521272: val_loss -0.6478 
2025-01-02 03:35:28.527786: Pseudo dice [np.float32(0.7276)] 
2025-01-02 03:35:28.530294: Epoch time: 42.71 s 
2025-01-02 03:35:29.087688:  
2025-01-02 03:35:29.087688: Epoch 88 
2025-01-02 03:35:29.093758: Current learning rate: 0.00677 
2025-01-02 03:36:11.846108: train_loss -0.5944 
2025-01-02 03:36:11.847613: val_loss -0.6943 
2025-01-02 03:36:11.853321: Pseudo dice [np.float32(0.743)] 
2025-01-02 03:36:11.859038: Epoch time: 42.76 s 
2025-01-02 03:36:12.423582:  
2025-01-02 03:36:12.423582: Epoch 89 
2025-01-02 03:36:12.432735: Current learning rate: 0.00673 
2025-01-02 03:36:55.149457: train_loss -0.6583 
2025-01-02 03:36:55.150480: val_loss -0.6645 
2025-01-02 03:36:55.156544: Pseudo dice [np.float32(0.715)] 
2025-01-02 03:36:55.160619: Epoch time: 42.73 s 
2025-01-02 03:36:55.723013:  
2025-01-02 03:36:55.723516: Epoch 90 
2025-01-02 03:36:55.728529: Current learning rate: 0.00669 
2025-01-02 03:37:38.627036: train_loss -0.6649 
2025-01-02 03:37:38.627538: val_loss -0.6817 
2025-01-02 03:37:38.633628: Pseudo dice [np.float32(0.7157)] 
2025-01-02 03:37:38.636167: Epoch time: 42.91 s 
2025-01-02 03:37:39.376426:  
2025-01-02 03:37:39.377434: Epoch 91 
2025-01-02 03:37:39.382004: Current learning rate: 0.00665 
2025-01-02 03:38:22.156017: train_loss -0.6542 
2025-01-02 03:38:22.157019: val_loss -0.7083 
2025-01-02 03:38:22.163539: Pseudo dice [np.float32(0.7556)] 
2025-01-02 03:38:22.167048: Epoch time: 42.78 s 
2025-01-02 03:38:22.732047:  
2025-01-02 03:38:22.732555: Epoch 92 
2025-01-02 03:38:22.738116: Current learning rate: 0.00662 
2025-01-02 03:39:05.464466: train_loss -0.6581 
2025-01-02 03:39:05.464969: val_loss -0.7037 
2025-01-02 03:39:05.470989: Pseudo dice [np.float32(0.7536)] 
2025-01-02 03:39:05.473496: Epoch time: 42.73 s 
2025-01-02 03:39:06.033267:  
2025-01-02 03:39:06.033267: Epoch 93 
2025-01-02 03:39:06.039313: Current learning rate: 0.00658 
2025-01-02 03:39:48.743628: train_loss -0.6931 
2025-01-02 03:39:48.744138: val_loss -0.7134 
2025-01-02 03:39:48.750258: Pseudo dice [np.float32(0.7745)] 
2025-01-02 03:39:48.753808: Epoch time: 42.71 s 
2025-01-02 03:39:49.307730:  
2025-01-02 03:39:49.307730: Epoch 94 
2025-01-02 03:39:49.313846: Current learning rate: 0.00654 
2025-01-02 03:40:32.019913: train_loss -0.6854 
2025-01-02 03:40:32.019913: val_loss -0.7043 
2025-01-02 03:40:32.026433: Pseudo dice [np.float32(0.7854)] 
2025-01-02 03:40:32.030445: Epoch time: 42.71 s 
2025-01-02 03:40:32.583096:  
2025-01-02 03:40:32.583600: Epoch 95 
2025-01-02 03:40:32.589679: Current learning rate: 0.0065 
2025-01-02 03:41:15.228530: train_loss -0.6753 
2025-01-02 03:41:15.229034: val_loss -0.6634 
2025-01-02 03:41:15.235059: Pseudo dice [np.float32(0.7094)] 
2025-01-02 03:41:15.239070: Epoch time: 42.65 s 
2025-01-02 03:41:15.788304:  
2025-01-02 03:41:15.788304: Epoch 96 
2025-01-02 03:41:15.794977: Current learning rate: 0.00647 
2025-01-02 03:41:58.555423: train_loss -0.6893 
2025-01-02 03:41:58.556424: val_loss -0.7404 
2025-01-02 03:41:58.561946: Pseudo dice [np.float32(0.7791)] 
2025-01-02 03:41:58.565459: Epoch time: 42.77 s 
2025-01-02 03:41:59.133104:  
2025-01-02 03:41:59.134104: Epoch 97 
2025-01-02 03:41:59.139699: Current learning rate: 0.00643 
2025-01-02 03:42:41.915523: train_loss -0.6927 
2025-01-02 03:42:41.917025: val_loss -0.7453 
2025-01-02 03:42:41.922036: Pseudo dice [np.float32(0.7823)] 
2025-01-02 03:42:41.925545: Epoch time: 42.78 s 
2025-01-02 03:42:41.929053: Yayy! New best EMA pseudo Dice: 0.7491999864578247 
2025-01-02 03:42:42.731800:  
2025-01-02 03:42:42.731800: Epoch 98 
2025-01-02 03:42:42.737868: Current learning rate: 0.00639 
2025-01-02 03:43:25.287920: train_loss -0.6543 
2025-01-02 03:43:25.288423: val_loss -0.7011 
2025-01-02 03:43:25.295448: Pseudo dice [np.float32(0.7919)] 
2025-01-02 03:43:25.300462: Epoch time: 42.56 s 
2025-01-02 03:43:25.303999: Yayy! New best EMA pseudo Dice: 0.7534000277519226 
2025-01-02 03:43:26.041757:  
2025-01-02 03:43:26.042762: Epoch 99 
2025-01-02 03:43:26.048820: Current learning rate: 0.00635 
2025-01-02 03:44:08.546246: train_loss -0.6898 
2025-01-02 03:44:08.546750: val_loss -0.6588 
2025-01-02 03:44:08.552775: Pseudo dice [np.float32(0.7221)] 
2025-01-02 03:44:08.556791: Epoch time: 42.5 s 
2025-01-02 03:44:09.461430:  
2025-01-02 03:44:09.461430: Epoch 100 
2025-01-02 03:44:09.467986: Current learning rate: 0.00631 
2025-01-02 03:44:51.941736: train_loss -0.6826 
2025-01-02 03:44:51.942740: val_loss -0.7144 
2025-01-02 03:44:51.949389: Pseudo dice [np.float32(0.7771)] 
2025-01-02 03:44:51.953900: Epoch time: 42.48 s 
2025-01-02 03:44:52.528882:  
2025-01-02 03:44:52.528882: Epoch 101 
2025-01-02 03:44:52.534897: Current learning rate: 0.00628 
2025-01-02 03:45:40.689132: train_loss -0.6813 
2025-01-02 03:45:40.689132: val_loss -0.6232 
2025-01-02 03:45:40.695835: Pseudo dice [np.float32(0.6487)] 
2025-01-02 03:45:40.700418: Epoch time: 48.16 s 
2025-01-02 03:45:41.231636:  
2025-01-02 03:45:41.231636: Epoch 102 
2025-01-02 03:45:41.238204: Current learning rate: 0.00624 
2025-01-02 03:46:24.339573: train_loss -0.6985 
2025-01-02 03:46:24.339573: val_loss -0.6949 
2025-01-02 03:46:24.346648: Pseudo dice [np.float32(0.7606)] 
2025-01-02 03:46:24.352173: Epoch time: 43.11 s 
2025-01-02 03:46:24.886015:  
2025-01-02 03:46:24.886015: Epoch 103 
2025-01-02 03:46:24.892100: Current learning rate: 0.0062 
2025-01-02 03:47:08.896838: train_loss -0.7126 
2025-01-02 03:47:08.897345: val_loss -0.6456 
2025-01-02 03:47:08.903908: Pseudo dice [np.float32(0.6802)] 
2025-01-02 03:47:08.906940: Epoch time: 44.01 s 
2025-01-02 03:47:09.513902:  
2025-01-02 03:47:09.513902: Epoch 104 
2025-01-02 03:47:09.520448: Current learning rate: 0.00616 
2025-01-02 03:47:52.783286: train_loss -0.7372 
2025-01-02 03:47:52.790406: val_loss -0.7382 
2025-01-02 03:47:52.794917: Pseudo dice [np.float32(0.7911)] 
2025-01-02 03:47:52.798434: Epoch time: 43.27 s 
2025-01-02 03:47:53.398511:  
2025-01-02 03:47:53.398511: Epoch 105 
2025-01-02 03:47:53.405704: Current learning rate: 0.00612 
2025-01-02 03:48:36.268089: train_loss -0.7359 
2025-01-02 03:48:36.269093: val_loss -0.7365 
2025-01-02 03:48:36.275611: Pseudo dice [np.float32(0.7964)] 
2025-01-02 03:48:36.279121: Epoch time: 42.87 s 
2025-01-02 03:48:36.872666:  
2025-01-02 03:48:36.873168: Epoch 106 
2025-01-02 03:48:36.879187: Current learning rate: 0.00609 
2025-01-02 03:49:19.550491: train_loss -0.7083 
2025-01-02 03:49:19.551491: val_loss -0.7362 
2025-01-02 03:49:19.558014: Pseudo dice [np.float32(0.81)] 
2025-01-02 03:49:19.562023: Epoch time: 42.68 s 
2025-01-02 03:49:19.565532: Yayy! New best EMA pseudo Dice: 0.7547000050544739 
2025-01-02 03:49:20.405934:  
2025-01-02 03:49:20.405934: Epoch 107 
2025-01-02 03:49:20.410993: Current learning rate: 0.00605 
2025-01-02 03:50:03.155528: train_loss -0.7028 
2025-01-02 03:50:03.156533: val_loss -0.7626 
2025-01-02 03:50:03.163078: Pseudo dice [np.float32(0.8152)] 
2025-01-02 03:50:03.167588: Epoch time: 42.75 s 
2025-01-02 03:50:03.171603: Yayy! New best EMA pseudo Dice: 0.7608000040054321 
2025-01-02 03:50:04.183930:  
2025-01-02 03:50:04.183930: Epoch 108 
2025-01-02 03:50:04.190482: Current learning rate: 0.00601 
2025-01-02 03:50:46.845900: train_loss -0.718 
2025-01-02 03:50:46.847403: val_loss -0.6326 
2025-01-02 03:50:46.853418: Pseudo dice [np.float32(0.7408)] 
2025-01-02 03:50:46.857427: Epoch time: 42.66 s 
2025-01-02 03:50:47.470824:  
2025-01-02 03:50:47.471826: Epoch 109 
2025-01-02 03:50:47.477415: Current learning rate: 0.00597 
2025-01-02 03:51:30.103133: train_loss -0.7284 
2025-01-02 03:51:30.103636: val_loss -0.7329 
2025-01-02 03:51:30.110169: Pseudo dice [np.float32(0.8066)] 
2025-01-02 03:51:30.114747: Epoch time: 42.63 s 
2025-01-02 03:51:30.118260: Yayy! New best EMA pseudo Dice: 0.7634999752044678 
2025-01-02 03:51:30.977873:  
2025-01-02 03:51:30.977873: Epoch 110 
2025-01-02 03:51:30.984498: Current learning rate: 0.00593 
2025-01-02 03:52:13.673168: train_loss -0.6476 
2025-01-02 03:52:13.674172: val_loss -0.6145 
2025-01-02 03:52:13.680687: Pseudo dice [np.float32(0.7225)] 
2025-01-02 03:52:13.685197: Epoch time: 42.7 s 
2025-01-02 03:52:14.317438:  
2025-01-02 03:52:14.318443: Epoch 111 
2025-01-02 03:52:14.324514: Current learning rate: 0.0059 
2025-01-02 03:52:57.384112: train_loss -0.7101 
2025-01-02 03:52:57.384112: val_loss -0.7391 
2025-01-02 03:52:57.392270: Pseudo dice [np.float32(0.7761)] 
2025-01-02 03:52:57.396782: Epoch time: 43.07 s 
2025-01-02 03:52:57.981487:  
2025-01-02 03:52:57.982488: Epoch 112 
2025-01-02 03:52:57.988077: Current learning rate: 0.00586 
2025-01-02 03:53:40.800854: train_loss -0.7233 
2025-01-02 03:53:40.801391: val_loss -0.7198 
2025-01-02 03:53:40.808056: Pseudo dice [np.float32(0.7956)] 
2025-01-02 03:53:40.812609: Epoch time: 42.82 s 
2025-01-02 03:53:40.816186: Yayy! New best EMA pseudo Dice: 0.7645999789237976 
2025-01-02 03:53:41.676993:  
2025-01-02 03:53:41.677998: Epoch 113 
2025-01-02 03:53:41.684576: Current learning rate: 0.00582 
2025-01-02 03:54:24.393612: train_loss -0.7278 
2025-01-02 03:54:24.393612: val_loss -0.5408 
2025-01-02 03:54:24.399632: Pseudo dice [np.float32(0.6335)] 
2025-01-02 03:54:24.404644: Epoch time: 42.72 s 
2025-01-02 03:54:25.004803:  
2025-01-02 03:54:25.004803: Epoch 114 
2025-01-02 03:54:25.012488: Current learning rate: 0.00578 
2025-01-02 03:55:07.686760: train_loss -0.7078 
2025-01-02 03:55:07.688263: val_loss -0.732 
2025-01-02 03:55:07.695828: Pseudo dice [np.float32(0.8087)] 
2025-01-02 03:55:07.700840: Epoch time: 42.68 s 
2025-01-02 03:55:08.292025:  
2025-01-02 03:55:08.293025: Epoch 115 
2025-01-02 03:55:08.298625: Current learning rate: 0.00574 
2025-01-02 03:55:50.981477: train_loss -0.7274 
2025-01-02 03:55:50.981981: val_loss -0.7421 
2025-01-02 03:55:50.989501: Pseudo dice [np.float32(0.7876)] 
2025-01-02 03:55:50.995102: Epoch time: 42.69 s 
2025-01-02 03:55:51.869656:  
2025-01-02 03:55:51.870160: Epoch 116 
2025-01-02 03:55:51.877682: Current learning rate: 0.0057 
2025-01-02 03:56:34.603624: train_loss -0.7215 
2025-01-02 03:56:34.604127: val_loss -0.6617 
2025-01-02 03:56:34.612213: Pseudo dice [np.float32(0.7105)] 
2025-01-02 03:56:34.616263: Epoch time: 42.73 s 
2025-01-02 03:56:35.375867:  
2025-01-02 03:56:35.376370: Epoch 117 
2025-01-02 03:56:35.383959: Current learning rate: 0.00567 
2025-01-02 03:57:18.086873: train_loss -0.6833 
2025-01-02 03:57:18.087877: val_loss -0.6489 
2025-01-02 03:57:18.093890: Pseudo dice [np.float32(0.6928)] 
2025-01-02 03:57:18.099433: Epoch time: 42.71 s 
2025-01-02 03:57:18.696657:  
2025-01-02 03:57:18.697655: Epoch 118 
2025-01-02 03:57:18.703727: Current learning rate: 0.00563 
2025-01-02 03:58:01.376128: train_loss -0.6868 
2025-01-02 03:58:01.376128: val_loss -0.7264 
2025-01-02 03:58:01.383647: Pseudo dice [np.float32(0.7798)] 
2025-01-02 03:58:01.388661: Epoch time: 42.68 s 
2025-01-02 03:58:02.039514:  
2025-01-02 03:58:02.040525: Epoch 119 
2025-01-02 03:58:02.048193: Current learning rate: 0.00559 
2025-01-02 03:58:44.532428: train_loss -0.694 
2025-01-02 03:58:44.532428: val_loss -0.6498 
2025-01-02 03:58:44.539951: Pseudo dice [np.float32(0.7551)] 
2025-01-02 03:58:44.543491: Epoch time: 42.49 s 
2025-01-02 03:58:45.121571:  
2025-01-02 03:58:45.121571: Epoch 120 
2025-01-02 03:58:45.129137: Current learning rate: 0.00555 
2025-01-02 03:59:27.609883: train_loss -0.7243 
2025-01-02 03:59:27.610387: val_loss -0.6978 
2025-01-02 03:59:27.617913: Pseudo dice [np.float32(0.7454)] 
2025-01-02 03:59:27.623452: Epoch time: 42.49 s 
2025-01-02 03:59:28.209433:  
2025-01-02 03:59:28.209433: Epoch 121 
2025-01-02 03:59:28.217126: Current learning rate: 0.00551 
2025-01-02 04:00:10.710984: train_loss -0.7114 
2025-01-02 04:00:10.711496: val_loss -0.6517 
2025-01-02 04:00:10.719164: Pseudo dice [np.float32(0.6608)] 
2025-01-02 04:00:10.724296: Epoch time: 42.5 s 
2025-01-02 04:00:11.330707:  
2025-01-02 04:00:11.332256: Epoch 122 
2025-01-02 04:00:11.339887: Current learning rate: 0.00547 
2025-01-02 04:00:53.882365: train_loss -0.7207 
2025-01-02 04:00:53.883365: val_loss -0.6478 
2025-01-02 04:00:53.890886: Pseudo dice [np.float32(0.7302)] 
2025-01-02 04:00:53.896402: Epoch time: 42.55 s 
2025-01-02 04:00:54.481523:  
2025-01-02 04:00:54.482526: Epoch 123 
2025-01-02 04:00:54.487075: Current learning rate: 0.00544 
2025-01-02 04:01:36.993427: train_loss -0.7202 
2025-01-02 04:01:36.995021: val_loss -0.7217 
2025-01-02 04:01:37.001683: Pseudo dice [np.float32(0.7943)] 
2025-01-02 04:01:37.006745: Epoch time: 42.51 s 
2025-01-02 04:01:37.926120:  
2025-01-02 04:01:37.926623: Epoch 124 
2025-01-02 04:01:37.934147: Current learning rate: 0.0054 
2025-01-02 04:02:20.464736: train_loss -0.7288 
2025-01-02 04:02:20.466245: val_loss -0.6643 
2025-01-02 04:02:20.473830: Pseudo dice [np.float32(0.7454)] 
2025-01-02 04:02:20.478889: Epoch time: 42.54 s 
2025-01-02 04:02:21.095676:  
2025-01-02 04:02:21.095676: Epoch 125 
2025-01-02 04:02:21.103200: Current learning rate: 0.00536 
2025-01-02 04:03:03.621467: train_loss -0.7365 
2025-01-02 04:03:03.621467: val_loss -0.7017 
2025-01-02 04:03:03.628987: Pseudo dice [np.float32(0.7505)] 
2025-01-02 04:03:03.633998: Epoch time: 42.53 s 
2025-01-02 04:03:04.221890:  
2025-01-02 04:03:04.222394: Epoch 126 
2025-01-02 04:03:04.228412: Current learning rate: 0.00532 
2025-01-02 04:03:46.703868: train_loss -0.6965 
2025-01-02 04:03:46.704868: val_loss -0.7306 
2025-01-02 04:03:46.711392: Pseudo dice [np.float32(0.812)] 
2025-01-02 04:03:46.715427: Epoch time: 42.48 s 
2025-01-02 04:03:47.324052:  
2025-01-02 04:03:47.325555: Epoch 127 
2025-01-02 04:03:47.332573: Current learning rate: 0.00528 
2025-01-02 04:04:29.844161: train_loss -0.7294 
2025-01-02 04:04:29.844664: val_loss -0.7349 
2025-01-02 04:04:29.852184: Pseudo dice [np.float32(0.7988)] 
2025-01-02 04:04:29.858203: Epoch time: 42.52 s 
2025-01-02 04:04:30.456415:  
2025-01-02 04:04:30.456415: Epoch 128 
2025-01-02 04:04:30.464635: Current learning rate: 0.00524 
2025-01-02 04:05:12.940498: train_loss -0.7169 
2025-01-02 04:05:12.942002: val_loss -0.7196 
2025-01-02 04:05:12.949522: Pseudo dice [np.float32(0.7512)] 
2025-01-02 04:05:12.954536: Epoch time: 42.49 s 
2025-01-02 04:05:13.546156:  
2025-01-02 04:05:13.546156: Epoch 129 
2025-01-02 04:05:13.552722: Current learning rate: 0.0052 
2025-01-02 04:05:56.061034: train_loss -0.7047 
2025-01-02 04:05:56.062035: val_loss -0.712 
2025-01-02 04:05:56.070057: Pseudo dice [np.float32(0.758)] 
2025-01-02 04:05:56.075070: Epoch time: 42.52 s 
2025-01-02 04:05:56.678190:  
2025-01-02 04:05:56.678693: Epoch 130 
2025-01-02 04:05:56.687214: Current learning rate: 0.00517 
2025-01-02 04:06:39.220255: train_loss -0.6955 
2025-01-02 04:06:39.220767: val_loss -0.7556 
2025-01-02 04:06:39.228615: Pseudo dice [np.float32(0.8144)] 
2025-01-02 04:06:39.234630: Epoch time: 42.54 s 
2025-01-02 04:06:39.876116:  
2025-01-02 04:06:39.877121: Epoch 131 
2025-01-02 04:06:39.884313: Current learning rate: 0.00513 
2025-01-02 04:07:22.402206: train_loss -0.6979 
2025-01-02 04:07:22.402206: val_loss -0.7495 
2025-01-02 04:07:22.410732: Pseudo dice [np.float32(0.8135)] 
2025-01-02 04:07:22.415744: Epoch time: 42.53 s 
2025-01-02 04:07:22.420757: Yayy! New best EMA pseudo Dice: 0.7681000232696533 
2025-01-02 04:07:23.274661:  
2025-01-02 04:07:23.275661: Epoch 132 
2025-01-02 04:07:23.283249: Current learning rate: 0.00509 
2025-01-02 04:08:05.782564: train_loss -0.7103 
2025-01-02 04:08:05.783068: val_loss -0.7106 
2025-01-02 04:08:05.790593: Pseudo dice [np.float32(0.7461)] 
2025-01-02 04:08:05.796215: Epoch time: 42.51 s 
2025-01-02 04:08:06.559106:  
2025-01-02 04:08:06.559106: Epoch 133 
2025-01-02 04:08:06.566674: Current learning rate: 0.00505 
2025-01-02 04:08:48.969524: train_loss -0.729 
2025-01-02 04:08:48.969524: val_loss -0.6942 
2025-01-02 04:08:48.976746: Pseudo dice [np.float32(0.7583)] 
2025-01-02 04:08:48.980299: Epoch time: 42.41 s 
2025-01-02 04:08:49.573073:  
2025-01-02 04:08:49.573073: Epoch 134 
2025-01-02 04:08:49.581362: Current learning rate: 0.00501 
2025-01-02 04:09:32.051799: train_loss -0.7261 
2025-01-02 04:09:32.052306: val_loss -0.6895 
2025-01-02 04:09:32.060555: Pseudo dice [np.float32(0.7397)] 
2025-01-02 04:09:32.066164: Epoch time: 42.48 s 
2025-01-02 04:09:32.682405:  
2025-01-02 04:09:32.683410: Epoch 135 
2025-01-02 04:09:32.690533: Current learning rate: 0.00497 
2025-01-02 04:10:15.204552: train_loss -0.688 
2025-01-02 04:10:15.205056: val_loss -0.6849 
2025-01-02 04:10:15.213259: Pseudo dice [np.float32(0.7149)] 
2025-01-02 04:10:15.217480: Epoch time: 42.52 s 
2025-01-02 04:10:15.829912:  
2025-01-02 04:10:15.829912: Epoch 136 
2025-01-02 04:10:15.838039: Current learning rate: 0.00493 
2025-01-02 04:10:58.323092: train_loss -0.6941 
2025-01-02 04:10:58.324095: val_loss -0.6878 
2025-01-02 04:10:58.331616: Pseudo dice [np.float32(0.7912)] 
2025-01-02 04:10:58.335144: Epoch time: 42.49 s 
2025-01-02 04:10:58.958698:  
2025-01-02 04:10:58.958698: Epoch 137 
2025-01-02 04:10:58.963889: Current learning rate: 0.00489 
2025-01-02 04:11:41.446389: train_loss -0.6961 
2025-01-02 04:11:41.446389: val_loss -0.7052 
2025-01-02 04:11:41.453950: Pseudo dice [np.float32(0.7599)] 
2025-01-02 04:11:41.459004: Epoch time: 42.49 s 
2025-01-02 04:11:42.062699:  
2025-01-02 04:11:42.063703: Epoch 138 
2025-01-02 04:11:42.069782: Current learning rate: 0.00485 
2025-01-02 04:12:24.597769: train_loss -0.7321 
2025-01-02 04:12:24.598831: val_loss -0.7389 
2025-01-02 04:12:24.604666: Pseudo dice [np.float32(0.7724)] 
2025-01-02 04:12:24.608229: Epoch time: 42.54 s 
2025-01-02 04:12:25.206019:  
2025-01-02 04:12:25.207024: Epoch 139 
2025-01-02 04:12:25.213608: Current learning rate: 0.00482 
2025-01-02 04:13:07.695685: train_loss -0.7075 
2025-01-02 04:13:07.696713: val_loss -0.7067 
2025-01-02 04:13:07.702809: Pseudo dice [np.float32(0.7143)] 
2025-01-02 04:13:07.707578: Epoch time: 42.49 s 
2025-01-02 04:13:08.312189:  
2025-01-02 04:13:08.313192: Epoch 140 
2025-01-02 04:13:08.317748: Current learning rate: 0.00478 
2025-01-02 04:13:50.807770: train_loss -0.7211 
2025-01-02 04:13:50.807770: val_loss -0.7567 
2025-01-02 04:13:50.812282: Pseudo dice [np.float32(0.8268)] 
2025-01-02 04:13:50.815291: Epoch time: 42.5 s 
2025-01-02 04:13:51.559218:  
2025-01-02 04:13:51.560222: Epoch 141 
2025-01-02 04:13:51.564786: Current learning rate: 0.00474 
2025-01-02 04:14:34.046461: train_loss -0.7336 
2025-01-02 04:14:34.046978: val_loss -0.7537 
2025-01-02 04:14:34.053148: Pseudo dice [np.float32(0.8167)] 
2025-01-02 04:14:34.056721: Epoch time: 42.49 s 
2025-01-02 04:14:34.060304: Yayy! New best EMA pseudo Dice: 0.769599974155426 
2025-01-02 04:14:34.907306:  
2025-01-02 04:14:34.907809: Epoch 142 
2025-01-02 04:14:34.913824: Current learning rate: 0.0047 
2025-01-02 04:15:17.388928: train_loss -0.7466 
2025-01-02 04:15:17.389432: val_loss -0.716 
2025-01-02 04:15:17.395457: Pseudo dice [np.float32(0.7515)] 
2025-01-02 04:15:17.399468: Epoch time: 42.48 s 
2025-01-02 04:15:17.987733:  
2025-01-02 04:15:17.988736: Epoch 143 
2025-01-02 04:15:17.993299: Current learning rate: 0.00466 
2025-01-02 04:16:00.434754: train_loss -0.7429 
2025-01-02 04:16:00.435754: val_loss -0.6653 
2025-01-02 04:16:00.441271: Pseudo dice [np.float32(0.7097)] 
2025-01-02 04:16:00.444781: Epoch time: 42.45 s 
2025-01-02 04:16:01.051442:  
2025-01-02 04:16:01.051442: Epoch 144 
2025-01-02 04:16:01.057488: Current learning rate: 0.00462 
2025-01-02 04:16:43.508401: train_loss -0.7379 
2025-01-02 04:16:43.508911: val_loss -0.7287 
2025-01-02 04:16:43.515139: Pseudo dice [np.float32(0.776)] 
2025-01-02 04:16:43.519227: Epoch time: 42.46 s 
2025-01-02 04:16:44.098922:  
2025-01-02 04:16:44.099925: Epoch 145 
2025-01-02 04:16:44.106281: Current learning rate: 0.00458 
2025-01-02 04:17:26.617703: train_loss -0.7355 
2025-01-02 04:17:26.617703: val_loss -0.7023 
2025-01-02 04:17:26.624339: Pseudo dice [np.float32(0.8062)] 
2025-01-02 04:17:26.626845: Epoch time: 42.52 s 
2025-01-02 04:17:27.220862:  
2025-01-02 04:17:27.221365: Epoch 146 
2025-01-02 04:17:27.226894: Current learning rate: 0.00454 
2025-01-02 04:18:09.716248: train_loss -0.7597 
2025-01-02 04:18:09.717253: val_loss -0.6598 
2025-01-02 04:18:09.723775: Pseudo dice [np.float32(0.7195)] 
2025-01-02 04:18:09.727287: Epoch time: 42.5 s 
2025-01-02 04:18:10.312530:  
2025-01-02 04:18:10.313536: Epoch 147 
2025-01-02 04:18:10.319608: Current learning rate: 0.0045 
2025-01-02 04:18:52.820973: train_loss -0.7622 
2025-01-02 04:18:52.820973: val_loss -0.7505 
2025-01-02 04:18:52.827045: Pseudo dice [np.float32(0.778)] 
2025-01-02 04:18:52.830606: Epoch time: 42.51 s 
2025-01-02 04:18:53.440806:  
2025-01-02 04:18:53.440806: Epoch 148 
2025-01-02 04:18:53.446905: Current learning rate: 0.00446 
2025-01-02 04:19:35.931866: train_loss -0.7133 
2025-01-02 04:19:35.932369: val_loss -0.7279 
2025-01-02 04:19:35.938391: Pseudo dice [np.float32(0.7522)] 
2025-01-02 04:19:35.942402: Epoch time: 42.49 s 
2025-01-02 04:19:36.743811:  
2025-01-02 04:19:36.743811: Epoch 149 
2025-01-02 04:19:36.749899: Current learning rate: 0.00442 
2025-01-02 04:20:19.264761: train_loss -0.7504 
2025-01-02 04:20:19.265264: val_loss -0.7356 
2025-01-02 04:20:19.271279: Pseudo dice [np.float32(0.7826)] 
2025-01-02 04:20:19.275290: Epoch time: 42.52 s 
2025-01-02 04:20:20.076385:  
2025-01-02 04:20:20.076385: Epoch 150 
2025-01-02 04:20:20.083999: Current learning rate: 0.00438 
2025-01-02 04:21:02.581315: train_loss -0.7526 
2025-01-02 04:21:02.581315: val_loss -0.6522 
2025-01-02 04:21:02.587332: Pseudo dice [np.float32(0.7023)] 
2025-01-02 04:21:02.591341: Epoch time: 42.51 s 
2025-01-02 04:21:03.266629:  
2025-01-02 04:21:03.266629: Epoch 151 
2025-01-02 04:21:03.273050: Current learning rate: 0.00434 
2025-01-02 04:21:45.742399: train_loss -0.6922 
2025-01-02 04:21:45.742399: val_loss -0.6654 
2025-01-02 04:21:45.749923: Pseudo dice [np.float32(0.6761)] 
2025-01-02 04:21:45.753467: Epoch time: 42.48 s 
2025-01-02 04:21:46.377514:  
2025-01-02 04:21:46.377514: Epoch 152 
2025-01-02 04:21:46.384699: Current learning rate: 0.0043 
2025-01-02 04:22:28.883312: train_loss -0.7547 
2025-01-02 04:22:28.884317: val_loss -0.7352 
2025-01-02 04:22:28.890975: Pseudo dice [np.float32(0.813)] 
2025-01-02 04:22:28.895060: Epoch time: 42.51 s 
2025-01-02 04:22:29.510505:  
2025-01-02 04:22:29.511505: Epoch 153 
2025-01-02 04:22:29.517665: Current learning rate: 0.00427 
2025-01-02 04:23:11.970962: train_loss -0.7392 
2025-01-02 04:23:11.971968: val_loss -0.6989 
2025-01-02 04:23:11.979494: Pseudo dice [np.float32(0.7938)] 
2025-01-02 04:23:11.984538: Epoch time: 42.46 s 
2025-01-02 04:23:12.614771:  
2025-01-02 04:23:12.615776: Epoch 154 
2025-01-02 04:23:12.622369: Current learning rate: 0.00423 
2025-01-02 04:23:55.102299: train_loss -0.7315 
2025-01-02 04:23:55.102299: val_loss -0.7319 
2025-01-02 04:23:55.108815: Pseudo dice [np.float32(0.7774)] 
2025-01-02 04:23:55.112327: Epoch time: 42.49 s 
2025-01-02 04:23:55.758980:  
2025-01-02 04:23:55.759980: Epoch 155 
2025-01-02 04:23:55.766504: Current learning rate: 0.00419 
2025-01-02 04:24:38.215030: train_loss -0.7364 
2025-01-02 04:24:38.215583: val_loss -0.7562 
2025-01-02 04:24:38.222691: Pseudo dice [np.float32(0.8223)] 
2025-01-02 04:24:38.226710: Epoch time: 42.46 s 
2025-01-02 04:24:38.893964:  
2025-01-02 04:24:38.893964: Epoch 156 
2025-01-02 04:24:38.900560: Current learning rate: 0.00415 
2025-01-02 04:25:21.377617: train_loss -0.7537 
2025-01-02 04:25:21.377617: val_loss -0.6775 
2025-01-02 04:25:21.384636: Pseudo dice [np.float32(0.754)] 
2025-01-02 04:25:21.388738: Epoch time: 42.48 s 
2025-01-02 04:25:22.161612:  
2025-01-02 04:25:22.162615: Epoch 157 
2025-01-02 04:25:22.168674: Current learning rate: 0.00411 
2025-01-02 04:26:04.698977: train_loss -0.7699 
2025-01-02 04:26:04.699982: val_loss -0.7242 
2025-01-02 04:26:04.706506: Pseudo dice [np.float32(0.8027)] 
2025-01-02 04:26:04.710017: Epoch time: 42.54 s 
2025-01-02 04:26:04.714029: Yayy! New best EMA pseudo Dice: 0.7703999876976013 
2025-01-02 04:26:05.561538:  
2025-01-02 04:26:05.562543: Epoch 158 
2025-01-02 04:26:05.568634: Current learning rate: 0.00407 
2025-01-02 04:26:53.104586: train_loss -0.7539 
2025-01-02 04:26:53.105592: val_loss -0.6718 
2025-01-02 04:26:53.112131: Pseudo dice [np.float32(0.7212)] 
2025-01-02 04:26:53.115171: Epoch time: 47.54 s 
2025-01-02 04:26:53.725727:  
2025-01-02 04:26:53.725727: Epoch 159 
2025-01-02 04:26:53.732244: Current learning rate: 0.00403 
2025-01-02 04:27:36.922648: train_loss -0.7467 
2025-01-02 04:27:36.923656: val_loss -0.7324 
2025-01-02 04:27:36.930229: Pseudo dice [np.float32(0.8121)] 
2025-01-02 04:27:36.933743: Epoch time: 43.2 s 
2025-01-02 04:27:37.537339:  
2025-01-02 04:27:37.537339: Epoch 160 
2025-01-02 04:27:37.543415: Current learning rate: 0.00399 
2025-01-02 04:28:20.830551: train_loss -0.7344 
2025-01-02 04:28:20.831059: val_loss -0.7477 
2025-01-02 04:28:20.838168: Pseudo dice [np.float32(0.7884)] 
2025-01-02 04:28:20.841798: Epoch time: 43.29 s 
2025-01-02 04:28:20.846324: Yayy! New best EMA pseudo Dice: 0.7718999981880188 
2025-01-02 04:28:21.630623:  
2025-01-02 04:28:21.631623: Epoch 161 
2025-01-02 04:28:21.636867: Current learning rate: 0.00395 
2025-01-02 04:29:04.282495: train_loss -0.7625 
2025-01-02 04:29:04.284004: val_loss -0.7556 
2025-01-02 04:29:04.292035: Pseudo dice [np.float32(0.8039)] 
2025-01-02 04:29:04.295066: Epoch time: 42.65 s 
2025-01-02 04:29:04.299072: Yayy! New best EMA pseudo Dice: 0.7750999927520752 
2025-01-02 04:29:05.064955:  
2025-01-02 04:29:05.065457: Epoch 162 
2025-01-02 04:29:05.072758: Current learning rate: 0.00391 
2025-01-02 04:29:47.646539: train_loss -0.7653 
2025-01-02 04:29:47.647541: val_loss -0.7293 
2025-01-02 04:29:47.652557: Pseudo dice [np.float32(0.7728)] 
2025-01-02 04:29:47.657072: Epoch time: 42.58 s 
2025-01-02 04:29:48.240007:  
2025-01-02 04:29:48.240007: Epoch 163 
2025-01-02 04:29:48.247525: Current learning rate: 0.00387 
2025-01-02 04:30:30.820457: train_loss -0.7573 
2025-01-02 04:30:30.821509: val_loss -0.714 
2025-01-02 04:30:30.827080: Pseudo dice [np.float32(0.7568)] 
2025-01-02 04:30:30.830626: Epoch time: 42.58 s 
2025-01-02 04:30:31.563892:  
2025-01-02 04:30:31.564896: Epoch 164 
2025-01-02 04:30:31.570975: Current learning rate: 0.00383 
2025-01-02 04:31:14.122416: train_loss -0.7708 
2025-01-02 04:31:14.122999: val_loss -0.7607 
2025-01-02 04:31:14.128592: Pseudo dice [np.float32(0.8356)] 
2025-01-02 04:31:14.133685: Epoch time: 42.56 s 
2025-01-02 04:31:14.138291: Yayy! New best EMA pseudo Dice: 0.7792999744415283 
2025-01-02 04:31:14.878865:  
2025-01-02 04:31:14.878865: Epoch 165 
2025-01-02 04:31:14.886384: Current learning rate: 0.00379 
2025-01-02 04:31:57.440628: train_loss -0.7472 
2025-01-02 04:31:57.440628: val_loss -0.763 
2025-01-02 04:31:57.448193: Pseudo dice [np.float32(0.8109)] 
2025-01-02 04:31:57.453240: Epoch time: 42.56 s 
2025-01-02 04:31:57.458284: Yayy! New best EMA pseudo Dice: 0.7825000286102295 
2025-01-02 04:31:58.197123:  
2025-01-02 04:31:58.197123: Epoch 166 
2025-01-02 04:31:58.203215: Current learning rate: 0.00375 
2025-01-02 04:32:40.745626: train_loss -0.7301 
2025-01-02 04:32:40.746132: val_loss -0.7387 
2025-01-02 04:32:40.752762: Pseudo dice [np.float32(0.8177)] 
2025-01-02 04:32:40.756800: Epoch time: 42.55 s 
2025-01-02 04:32:40.760374: Yayy! New best EMA pseudo Dice: 0.7860000133514404 
2025-01-02 04:32:41.497064:  
2025-01-02 04:32:41.497064: Epoch 167 
2025-01-02 04:32:41.503079: Current learning rate: 0.00371 
2025-01-02 04:33:24.044840: train_loss -0.7388 
2025-01-02 04:33:24.045843: val_loss -0.6918 
2025-01-02 04:33:24.053424: Pseudo dice [np.float32(0.7511)] 
2025-01-02 04:33:24.057965: Epoch time: 42.55 s 
2025-01-02 04:33:24.634184:  
2025-01-02 04:33:24.634687: Epoch 168 
2025-01-02 04:33:24.641703: Current learning rate: 0.00367 
2025-01-02 04:34:07.401224: train_loss -0.7598 
2025-01-02 04:34:07.401738: val_loss -0.7106 
2025-01-02 04:34:07.407787: Pseudo dice [np.float32(0.777)] 
2025-01-02 04:34:07.411833: Epoch time: 42.77 s 
2025-01-02 04:34:07.983773:  
2025-01-02 04:34:07.984771: Epoch 169 
2025-01-02 04:34:07.990418: Current learning rate: 0.00363 
2025-01-02 04:34:50.573365: train_loss -0.7805 
2025-01-02 04:34:50.574368: val_loss -0.6804 
2025-01-02 04:34:50.580977: Pseudo dice [np.float32(0.7758)] 
2025-01-02 04:34:50.585001: Epoch time: 42.59 s 
2025-01-02 04:34:51.154752:  
2025-01-02 04:34:51.155254: Epoch 170 
2025-01-02 04:34:51.162268: Current learning rate: 0.00359 
2025-01-02 04:35:33.712230: train_loss -0.7638 
2025-01-02 04:35:33.714759: val_loss -0.6723 
2025-01-02 04:35:33.721880: Pseudo dice [np.float32(0.746)] 
2025-01-02 04:35:33.725453: Epoch time: 42.56 s 
2025-01-02 04:35:34.294844:  
2025-01-02 04:35:34.295844: Epoch 171 
2025-01-02 04:35:34.301445: Current learning rate: 0.00355 
2025-01-02 04:36:16.837262: train_loss -0.7554 
2025-01-02 04:36:16.837765: val_loss -0.7116 
2025-01-02 04:36:16.844817: Pseudo dice [np.float32(0.7744)] 
2025-01-02 04:36:16.849349: Epoch time: 42.54 s 
2025-01-02 04:36:17.425715:  
2025-01-02 04:36:17.426715: Epoch 172 
2025-01-02 04:36:17.433740: Current learning rate: 0.00351 
2025-01-02 04:37:00.034661: train_loss -0.7706 
2025-01-02 04:37:00.035163: val_loss -0.7469 
2025-01-02 04:37:00.042682: Pseudo dice [np.float32(0.7744)] 
2025-01-02 04:37:00.047747: Epoch time: 42.61 s 
2025-01-02 04:37:00.779753:  
2025-01-02 04:37:00.780256: Epoch 173 
2025-01-02 04:37:00.786272: Current learning rate: 0.00346 
2025-01-02 04:37:43.311033: train_loss -0.7365 
2025-01-02 04:37:43.312032: val_loss -0.7699 
2025-01-02 04:37:43.318549: Pseudo dice [np.float32(0.8297)] 
2025-01-02 04:37:43.322558: Epoch time: 42.53 s 
2025-01-02 04:37:43.896631:  
2025-01-02 04:37:43.896631: Epoch 174 
2025-01-02 04:37:43.904739: Current learning rate: 0.00342 
2025-01-02 04:38:26.583048: train_loss -0.7494 
2025-01-02 04:38:26.584046: val_loss -0.7154 
2025-01-02 04:38:26.590075: Pseudo dice [np.float32(0.7723)] 
2025-01-02 04:38:26.594628: Epoch time: 42.69 s 
2025-01-02 04:38:27.168548:  
2025-01-02 04:38:27.168548: Epoch 175 
2025-01-02 04:38:27.174575: Current learning rate: 0.00338 
2025-01-02 04:39:09.612169: train_loss -0.777 
2025-01-02 04:39:09.613168: val_loss -0.7138 
2025-01-02 04:39:09.618680: Pseudo dice [np.float32(0.7826)] 
2025-01-02 04:39:09.623192: Epoch time: 42.44 s 
2025-01-02 04:39:10.190838:  
2025-01-02 04:39:10.191340: Epoch 176 
2025-01-02 04:39:10.197355: Current learning rate: 0.00334 
2025-01-02 04:39:52.582755: train_loss -0.7822 
2025-01-02 04:39:52.583755: val_loss -0.7654 
2025-01-02 04:39:52.590271: Pseudo dice [np.float32(0.8251)] 
2025-01-02 04:39:52.594280: Epoch time: 42.39 s 
2025-01-02 04:39:53.165301:  
2025-01-02 04:39:53.166301: Epoch 177 
2025-01-02 04:39:53.173950: Current learning rate: 0.0033 
2025-01-02 04:40:35.585013: train_loss -0.7529 
2025-01-02 04:40:35.586017: val_loss -0.7408 
2025-01-02 04:40:35.592607: Pseudo dice [np.float32(0.8009)] 
2025-01-02 04:40:35.596131: Epoch time: 42.42 s 
2025-01-02 04:40:35.600183: Yayy! New best EMA pseudo Dice: 0.7874000072479248 
2025-01-02 04:40:36.348329:  
2025-01-02 04:40:36.348329: Epoch 178 
2025-01-02 04:40:36.354885: Current learning rate: 0.00326 
2025-01-02 04:41:18.772661: train_loss -0.771 
2025-01-02 04:41:18.772661: val_loss -0.7023 
2025-01-02 04:41:18.779178: Pseudo dice [np.float32(0.7497)] 
2025-01-02 04:41:18.783795: Epoch time: 42.43 s 
2025-01-02 04:41:19.352870:  
2025-01-02 04:41:19.352870: Epoch 179 
2025-01-02 04:41:19.359493: Current learning rate: 0.00322 
2025-01-02 04:42:01.796006: train_loss -0.7991 
2025-01-02 04:42:01.796513: val_loss -0.7299 
2025-01-02 04:42:01.803560: Pseudo dice [np.float32(0.8016)] 
2025-01-02 04:42:01.807588: Epoch time: 42.44 s 
2025-01-02 04:42:02.389502:  
2025-01-02 04:42:02.390502: Epoch 180 
2025-01-02 04:42:02.397615: Current learning rate: 0.00318 
2025-01-02 04:42:44.823419: train_loss -0.7689 
2025-01-02 04:42:44.824419: val_loss -0.7133 
2025-01-02 04:42:44.830935: Pseudo dice [np.float32(0.7896)] 
2025-01-02 04:42:44.834944: Epoch time: 42.43 s 
2025-01-02 04:42:45.564225:  
2025-01-02 04:42:45.565225: Epoch 181 
2025-01-02 04:42:45.570873: Current learning rate: 0.00314 
2025-01-02 04:43:27.986463: train_loss -0.765 
2025-01-02 04:43:27.987965: val_loss -0.7605 
2025-01-02 04:43:27.993986: Pseudo dice [np.float32(0.8223)] 
2025-01-02 04:43:27.997995: Epoch time: 42.42 s 
2025-01-02 04:43:28.002522: Yayy! New best EMA pseudo Dice: 0.7894999980926514 
2025-01-02 04:43:28.750641:  
2025-01-02 04:43:28.751641: Epoch 182 
2025-01-02 04:43:28.756713: Current learning rate: 0.0031 
2025-01-02 04:44:11.145533: train_loss -0.7728 
2025-01-02 04:44:11.146536: val_loss -0.6437 
2025-01-02 04:44:11.154057: Pseudo dice [np.float32(0.7398)] 
2025-01-02 04:44:11.157562: Epoch time: 42.39 s 
2025-01-02 04:44:11.740247:  
2025-01-02 04:44:11.740247: Epoch 183 
2025-01-02 04:44:11.748777: Current learning rate: 0.00306 
2025-01-02 04:44:54.166981: train_loss -0.7809 
2025-01-02 04:44:54.167487: val_loss -0.7513 
2025-01-02 04:44:54.173552: Pseudo dice [np.float32(0.8015)] 
2025-01-02 04:44:54.178092: Epoch time: 42.43 s 
2025-01-02 04:44:54.747970:  
2025-01-02 04:44:54.748974: Epoch 184 
2025-01-02 04:44:54.755083: Current learning rate: 0.00302 
2025-01-02 04:45:37.145841: train_loss -0.7846 
2025-01-02 04:45:37.145841: val_loss -0.6753 
2025-01-02 04:45:37.153401: Pseudo dice [np.float32(0.7504)] 
2025-01-02 04:45:37.157926: Epoch time: 42.4 s 
2025-01-02 04:45:37.727508:  
2025-01-02 04:45:37.727508: Epoch 185 
2025-01-02 04:45:37.734668: Current learning rate: 0.00297 
2025-01-02 04:46:20.107912: train_loss -0.7719 
2025-01-02 04:46:20.108916: val_loss -0.6928 
2025-01-02 04:46:20.115527: Pseudo dice [np.float32(0.7328)] 
2025-01-02 04:46:20.119051: Epoch time: 42.38 s 
2025-01-02 04:46:20.689173:  
2025-01-02 04:46:20.689675: Epoch 186 
2025-01-02 04:46:20.696693: Current learning rate: 0.00293 
2025-01-02 04:47:03.136760: train_loss -0.7721 
2025-01-02 04:47:03.137760: val_loss -0.725 
2025-01-02 04:47:03.143274: Pseudo dice [np.float32(0.8018)] 
2025-01-02 04:47:03.146784: Epoch time: 42.45 s 
2025-01-02 04:47:03.725045:  
2025-01-02 04:47:03.725045: Epoch 187 
2025-01-02 04:47:03.732212: Current learning rate: 0.00289 
2025-01-02 04:47:46.162372: train_loss -0.7571 
2025-01-02 04:47:46.162372: val_loss -0.7041 
2025-01-02 04:47:46.170011: Pseudo dice [np.float32(0.7439)] 
2025-01-02 04:47:46.174564: Epoch time: 42.44 s 
2025-01-02 04:47:46.749994:  
2025-01-02 04:47:46.749994: Epoch 188 
2025-01-02 04:47:46.756558: Current learning rate: 0.00285 
2025-01-02 04:48:29.191128: train_loss -0.7714 
2025-01-02 04:48:29.191128: val_loss -0.7292 
2025-01-02 04:48:29.198644: Pseudo dice [np.float32(0.7732)] 
2025-01-02 04:48:29.202154: Epoch time: 42.44 s 
2025-01-02 04:48:29.933074:  
2025-01-02 04:48:29.934074: Epoch 189 
2025-01-02 04:48:29.939674: Current learning rate: 0.00281 
2025-01-02 04:49:12.387281: train_loss -0.7568 
2025-01-02 04:49:12.387281: val_loss -0.7336 
2025-01-02 04:49:12.394798: Pseudo dice [np.float32(0.7904)] 
2025-01-02 04:49:12.399329: Epoch time: 42.45 s 
2025-01-02 04:49:12.966393:  
2025-01-02 04:49:12.966393: Epoch 190 
2025-01-02 04:49:12.972948: Current learning rate: 0.00277 
2025-01-02 04:49:55.394184: train_loss -0.7556 
2025-01-02 04:49:55.394686: val_loss -0.6871 
2025-01-02 04:49:55.401701: Pseudo dice [np.float32(0.7557)] 
2025-01-02 04:49:55.406228: Epoch time: 42.43 s 
2025-01-02 04:49:55.976969:  
2025-01-02 04:49:55.977472: Epoch 191 
2025-01-02 04:49:55.983487: Current learning rate: 0.00273 
2025-01-02 04:50:38.405071: train_loss -0.742 
2025-01-02 04:50:38.406074: val_loss -0.7217 
2025-01-02 04:50:38.412587: Pseudo dice [np.float32(0.7822)] 
2025-01-02 04:50:38.417601: Epoch time: 42.43 s 
2025-01-02 04:50:39.002074:  
2025-01-02 04:50:39.002577: Epoch 192 
2025-01-02 04:50:39.008598: Current learning rate: 0.00268 
2025-01-02 04:51:21.422414: train_loss -0.7595 
2025-01-02 04:51:21.423413: val_loss -0.7441 
2025-01-02 04:51:21.429933: Pseudo dice [np.float32(0.8322)] 
2025-01-02 04:51:21.433939: Epoch time: 42.42 s 
2025-01-02 04:51:22.016964:  
2025-01-02 04:51:22.017467: Epoch 193 
2025-01-02 04:51:22.023489: Current learning rate: 0.00264 
2025-01-02 04:52:04.425707: train_loss -0.7908 
2025-01-02 04:52:04.426710: val_loss -0.731 
2025-01-02 04:52:04.433223: Pseudo dice [np.float32(0.7734)] 
2025-01-02 04:52:04.437732: Epoch time: 42.41 s 
2025-01-02 04:52:05.016419:  
2025-01-02 04:52:05.016922: Epoch 194 
2025-01-02 04:52:05.021933: Current learning rate: 0.0026 
2025-01-02 04:52:47.390640: train_loss -0.7959 
2025-01-02 04:52:47.391639: val_loss -0.6456 
2025-01-02 04:52:47.398156: Pseudo dice [np.float32(0.7264)] 
2025-01-02 04:52:47.402678: Epoch time: 42.38 s 
2025-01-02 04:52:47.983491:  
2025-01-02 04:52:47.984496: Epoch 195 
2025-01-02 04:52:47.991039: Current learning rate: 0.00256 
2025-01-02 04:53:30.439978: train_loss -0.7731 
2025-01-02 04:53:30.440981: val_loss -0.7024 
2025-01-02 04:53:30.446999: Pseudo dice [np.float32(0.7346)] 
2025-01-02 04:53:30.452054: Epoch time: 42.46 s 
2025-01-02 04:53:31.031806:  
2025-01-02 04:53:31.032813: Epoch 196 
2025-01-02 04:53:31.038455: Current learning rate: 0.00252 
2025-01-02 04:54:13.518770: train_loss -0.8033 
2025-01-02 04:54:13.519774: val_loss -0.6699 
2025-01-02 04:54:13.526345: Pseudo dice [np.float32(0.7664)] 
2025-01-02 04:54:13.530925: Epoch time: 42.49 s 
2025-01-02 04:54:14.103372:  
2025-01-02 04:54:14.104378: Epoch 197 
2025-01-02 04:54:14.109979: Current learning rate: 0.00248 
2025-01-02 04:54:56.554751: train_loss -0.7977 
2025-01-02 04:54:56.555280: val_loss -0.7022 
2025-01-02 04:54:56.562458: Pseudo dice [np.float32(0.7858)] 
2025-01-02 04:54:56.566483: Epoch time: 42.45 s 
2025-01-02 04:54:57.150783:  
2025-01-02 04:54:57.151786: Epoch 198 
2025-01-02 04:54:57.157823: Current learning rate: 0.00243 
2025-01-02 04:55:39.574878: train_loss -0.804 
2025-01-02 04:55:39.575390: val_loss -0.6557 
2025-01-02 04:55:39.581529: Pseudo dice [np.float32(0.7577)] 
2025-01-02 04:55:39.586122: Epoch time: 42.42 s 
2025-01-02 04:55:40.174280:  
2025-01-02 04:55:40.174280: Epoch 199 
2025-01-02 04:55:40.180862: Current learning rate: 0.00239 
2025-01-02 04:56:22.607414: train_loss -0.786 
2025-01-02 04:56:22.607916: val_loss -0.7702 
2025-01-02 04:56:22.613540: Pseudo dice [np.float32(0.8386)] 
2025-01-02 04:56:22.618124: Epoch time: 42.43 s 
2025-01-02 04:56:23.373659:  
2025-01-02 04:56:23.374161: Epoch 200 
2025-01-02 04:56:23.380178: Current learning rate: 0.00235 
2025-01-02 04:57:05.795383: train_loss -0.7642 
2025-01-02 04:57:05.795886: val_loss -0.7054 
2025-01-02 04:57:05.801901: Pseudo dice [np.float32(0.8013)] 
2025-01-02 04:57:05.805910: Epoch time: 42.42 s 
2025-01-02 04:57:06.393093:  
2025-01-02 04:57:06.393093: Epoch 201 
2025-01-02 04:57:06.399703: Current learning rate: 0.00231 
2025-01-02 04:57:48.793262: train_loss -0.8064 
2025-01-02 04:57:48.793262: val_loss -0.7403 
2025-01-02 04:57:48.800799: Pseudo dice [np.float32(0.8087)] 
2025-01-02 04:57:48.805812: Epoch time: 42.4 s 
2025-01-02 04:57:49.392842:  
2025-01-02 04:57:49.393345: Epoch 202 
2025-01-02 04:57:49.399363: Current learning rate: 0.00226 
2025-01-02 04:58:31.833441: train_loss -0.8032 
2025-01-02 04:58:31.834447: val_loss -0.676 
2025-01-02 04:58:31.840962: Pseudo dice [np.float32(0.784)] 
2025-01-02 04:58:31.844473: Epoch time: 42.44 s 
2025-01-02 04:58:32.433895:  
2025-01-02 04:58:32.434898: Epoch 203 
2025-01-02 04:58:32.440956: Current learning rate: 0.00222 
2025-01-02 04:59:14.899203: train_loss -0.8033 
2025-01-02 04:59:14.899710: val_loss -0.6982 
2025-01-02 04:59:14.906880: Pseudo dice [np.float32(0.8122)] 
2025-01-02 04:59:14.910433: Epoch time: 42.47 s 
2025-01-02 04:59:15.659796:  
2025-01-02 04:59:15.660795: Epoch 204 
2025-01-02 04:59:15.666373: Current learning rate: 0.00218 
2025-01-02 04:59:58.047656: train_loss -0.8135 
2025-01-02 04:59:58.048668: val_loss -0.7372 
2025-01-02 04:59:58.055369: Pseudo dice [np.float32(0.8115)] 
2025-01-02 04:59:58.059119: Epoch time: 42.39 s 
2025-01-02 04:59:58.642099:  
2025-01-02 04:59:58.642099: Epoch 205 
2025-01-02 04:59:58.649115: Current learning rate: 0.00214 
2025-01-02 05:00:41.050814: train_loss -0.7784 
2025-01-02 05:00:41.051317: val_loss -0.7219 
2025-01-02 05:00:41.057342: Pseudo dice [np.float32(0.7604)] 
2025-01-02 05:00:41.062355: Epoch time: 42.41 s 
2025-01-02 05:00:41.618019:  
2025-01-02 05:00:41.619018: Epoch 206 
2025-01-02 05:00:41.624607: Current learning rate: 0.00209 
2025-01-02 05:01:24.048877: train_loss -0.79 
2025-01-02 05:01:24.049876: val_loss -0.7185 
2025-01-02 05:01:24.055396: Pseudo dice [np.float32(0.7551)] 
2025-01-02 05:01:24.058908: Epoch time: 42.43 s 
2025-01-02 05:01:24.605515:  
2025-01-02 05:01:24.606514: Epoch 207 
2025-01-02 05:01:24.612101: Current learning rate: 0.00205 
2025-01-02 05:02:07.025261: train_loss -0.7953 
2025-01-02 05:02:07.025261: val_loss -0.7025 
2025-01-02 05:02:07.032787: Pseudo dice [np.float32(0.7657)] 
2025-01-02 05:02:07.037312: Epoch time: 42.42 s 
2025-01-02 05:02:07.582351:  
2025-01-02 05:02:07.582351: Epoch 208 
2025-01-02 05:02:07.588368: Current learning rate: 0.00201 
2025-01-02 05:02:50.003326: train_loss -0.7923 
2025-01-02 05:02:50.003326: val_loss -0.6544 
2025-01-02 05:02:50.009851: Pseudo dice [np.float32(0.6586)] 
2025-01-02 05:02:50.014866: Epoch time: 42.42 s 
2025-01-02 05:02:50.558097:  
2025-01-02 05:02:50.558097: Epoch 209 
2025-01-02 05:02:50.564986: Current learning rate: 0.00196 
2025-01-02 05:03:32.986484: train_loss -0.8095 
2025-01-02 05:03:32.987489: val_loss -0.7665 
2025-01-02 05:03:32.994008: Pseudo dice [np.float32(0.8189)] 
2025-01-02 05:03:32.997027: Epoch time: 42.43 s 
2025-01-02 05:03:33.543543:  
2025-01-02 05:03:33.544548: Epoch 210 
2025-01-02 05:03:33.551121: Current learning rate: 0.00192 
2025-01-02 05:04:15.940992: train_loss -0.8098 
2025-01-02 05:04:15.940992: val_loss -0.734 
2025-01-02 05:04:15.947008: Pseudo dice [np.float32(0.7984)] 
2025-01-02 05:04:15.950575: Epoch time: 42.4 s 
2025-01-02 05:04:16.496521:  
2025-01-02 05:04:16.496521: Epoch 211 
2025-01-02 05:04:16.502537: Current learning rate: 0.00188 
2025-01-02 05:04:58.907485: train_loss -0.7897 
2025-01-02 05:04:58.908487: val_loss -0.6913 
2025-01-02 05:04:58.915001: Pseudo dice [np.float32(0.7878)] 
2025-01-02 05:04:58.919106: Epoch time: 42.41 s 
2025-01-02 05:04:59.467444:  
2025-01-02 05:04:59.467444: Epoch 212 
2025-01-02 05:04:59.473532: Current learning rate: 0.00184 
2025-01-02 05:05:41.871197: train_loss -0.7909 
2025-01-02 05:05:41.871701: val_loss -0.6902 
2025-01-02 05:05:41.878391: Pseudo dice [np.float32(0.6971)] 
2025-01-02 05:05:41.882959: Epoch time: 42.41 s 
2025-01-02 05:05:42.594044:  
2025-01-02 05:05:42.594044: Epoch 213 
2025-01-02 05:05:42.600605: Current learning rate: 0.00179 
2025-01-02 05:06:24.962838: train_loss -0.7911 
2025-01-02 05:06:24.963342: val_loss -0.6922 
2025-01-02 05:06:24.970869: Pseudo dice [np.float32(0.7458)] 
2025-01-02 05:06:24.975384: Epoch time: 42.37 s 
2025-01-02 05:06:25.520061:  
2025-01-02 05:06:25.520061: Epoch 214 
2025-01-02 05:06:25.528157: Current learning rate: 0.00175 
2025-01-02 05:07:07.937576: train_loss -0.7913 
2025-01-02 05:07:07.938578: val_loss -0.6511 
2025-01-02 05:07:07.945094: Pseudo dice [np.float32(0.7693)] 
2025-01-02 05:07:07.949604: Epoch time: 42.42 s 
2025-01-02 05:07:08.495771:  
2025-01-02 05:07:08.495771: Epoch 215 
2025-01-02 05:07:08.502379: Current learning rate: 0.0017 
2025-01-02 05:07:50.851809: train_loss -0.8033 
2025-01-02 05:07:50.852310: val_loss -0.7326 
2025-01-02 05:07:50.858331: Pseudo dice [np.float32(0.8052)] 
2025-01-02 05:07:50.862343: Epoch time: 42.36 s 
2025-01-02 05:07:51.411327:  
2025-01-02 05:07:51.412330: Epoch 216 
2025-01-02 05:07:51.418382: Current learning rate: 0.00166 
2025-01-02 05:08:33.826913: train_loss -0.8002 
2025-01-02 05:08:33.827919: val_loss -0.665 
2025-01-02 05:08:33.834008: Pseudo dice [np.float32(0.7389)] 
2025-01-02 05:08:33.838086: Epoch time: 42.42 s 
2025-01-02 05:08:34.385133:  
2025-01-02 05:08:34.386137: Epoch 217 
2025-01-02 05:08:34.392204: Current learning rate: 0.00162 
2025-01-02 05:09:16.809860: train_loss -0.7957 
2025-01-02 05:09:16.810864: val_loss -0.7656 
2025-01-02 05:09:16.817387: Pseudo dice [np.float32(0.8411)] 
2025-01-02 05:09:16.822404: Epoch time: 42.42 s 
2025-01-02 05:09:17.377391:  
2025-01-02 05:09:17.377895: Epoch 218 
2025-01-02 05:09:17.384911: Current learning rate: 0.00157 
2025-01-02 05:09:59.785783: train_loss -0.7987 
2025-01-02 05:09:59.785783: val_loss -0.6582 
2025-01-02 05:09:59.792833: Pseudo dice [np.float32(0.7606)] 
2025-01-02 05:09:59.796420: Epoch time: 42.41 s 
2025-01-02 05:10:00.346337:  
2025-01-02 05:10:00.346337: Epoch 219 
2025-01-02 05:10:00.352403: Current learning rate: 0.00153 
2025-01-02 05:10:42.770127: train_loss -0.7892 
2025-01-02 05:10:42.771127: val_loss -0.6714 
2025-01-02 05:10:42.776663: Pseudo dice [np.float32(0.7767)] 
2025-01-02 05:10:42.780201: Epoch time: 42.42 s 
2025-01-02 05:10:43.325468:  
2025-01-02 05:10:43.325970: Epoch 220 
2025-01-02 05:10:43.330982: Current learning rate: 0.00148 
2025-01-02 05:11:25.731370: train_loss -0.8075 
2025-01-02 05:11:25.731873: val_loss -0.6972 
2025-01-02 05:11:25.737423: Pseudo dice [np.float32(0.787)] 
2025-01-02 05:11:25.744545: Epoch time: 42.41 s 
2025-01-02 05:11:26.288467:  
2025-01-02 05:11:26.288467: Epoch 221 
2025-01-02 05:11:26.294021: Current learning rate: 0.00144 
2025-01-02 05:12:08.778119: train_loss -0.7999 
2025-01-02 05:12:08.778623: val_loss -0.6296 
2025-01-02 05:12:08.786151: Pseudo dice [np.float32(0.6761)] 
2025-01-02 05:12:08.789664: Epoch time: 42.49 s 
2025-01-02 05:12:09.336531:  
2025-01-02 05:12:09.336531: Epoch 222 
2025-01-02 05:12:09.342596: Current learning rate: 0.00139 
2025-01-02 05:12:51.747864: train_loss -0.8111 
2025-01-02 05:12:51.748863: val_loss -0.6313 
2025-01-02 05:12:51.755386: Pseudo dice [np.float32(0.7006)] 
2025-01-02 05:12:51.761929: Epoch time: 42.41 s 
2025-01-02 05:12:52.308025:  
2025-01-02 05:12:52.308534: Epoch 223 
2025-01-02 05:12:52.315185: Current learning rate: 0.00135 
2025-01-02 05:13:34.700015: train_loss -0.8097 
2025-01-02 05:13:34.700015: val_loss -0.652 
2025-01-02 05:13:34.705032: Pseudo dice [np.float32(0.7534)] 
2025-01-02 05:13:34.710051: Epoch time: 42.39 s 
2025-01-02 05:13:35.252155:  
2025-01-02 05:13:35.252658: Epoch 224 
2025-01-02 05:13:35.258676: Current learning rate: 0.0013 
2025-01-02 05:14:17.693795: train_loss -0.7939 
2025-01-02 05:14:17.693795: val_loss -0.7016 
2025-01-02 05:14:17.700983: Pseudo dice [np.float32(0.8)] 
2025-01-02 05:14:17.705495: Epoch time: 42.44 s 
2025-01-02 05:14:18.248022:  
2025-01-02 05:14:18.248022: Epoch 225 
2025-01-02 05:14:18.254040: Current learning rate: 0.00126 
2025-01-02 05:15:00.641386: train_loss -0.8119 
2025-01-02 05:15:00.642390: val_loss -0.7189 
2025-01-02 05:15:00.647407: Pseudo dice [np.float32(0.7732)] 
2025-01-02 05:15:00.651417: Epoch time: 42.39 s 
2025-01-02 05:15:01.197483:  
2025-01-02 05:15:01.198488: Epoch 226 
2025-01-02 05:15:01.204699: Current learning rate: 0.00121 
2025-01-02 05:15:43.607431: train_loss -0.799 
2025-01-02 05:15:43.608433: val_loss -0.6566 
2025-01-02 05:15:43.613955: Pseudo dice [np.float32(0.7175)] 
2025-01-02 05:15:43.618467: Epoch time: 42.41 s 
2025-01-02 05:15:44.162597:  
2025-01-02 05:15:44.163602: Epoch 227 
2025-01-02 05:15:44.169774: Current learning rate: 0.00117 
2025-01-02 05:16:26.523747: train_loss -0.8036 
2025-01-02 05:16:26.523747: val_loss -0.6974 
2025-01-02 05:16:26.531270: Pseudo dice [np.float32(0.7627)] 
2025-01-02 05:16:26.535278: Epoch time: 42.36 s 
2025-01-02 05:16:27.082757:  
2025-01-02 05:16:27.082757: Epoch 228 
2025-01-02 05:16:27.089334: Current learning rate: 0.00112 
2025-01-02 05:17:09.482136: train_loss -0.814 
2025-01-02 05:17:09.483139: val_loss -0.7922 
2025-01-02 05:17:09.489662: Pseudo dice [np.float32(0.8589)] 
2025-01-02 05:17:09.494192: Epoch time: 42.4 s 
2025-01-02 05:17:10.045002:  
2025-01-02 05:17:10.046006: Epoch 229 
2025-01-02 05:17:10.052150: Current learning rate: 0.00108 
2025-01-02 05:17:52.431899: train_loss -0.8177 
2025-01-02 05:17:52.432899: val_loss -0.6672 
2025-01-02 05:17:52.439418: Pseudo dice [np.float32(0.7258)] 
2025-01-02 05:17:52.444945: Epoch time: 42.39 s 
2025-01-02 05:17:53.381334:  
2025-01-02 05:17:53.382337: Epoch 230 
2025-01-02 05:17:53.388427: Current learning rate: 0.00103 
2025-01-02 05:18:35.790388: train_loss -0.7836 
2025-01-02 05:18:35.791450: val_loss -0.7381 
2025-01-02 05:18:35.797542: Pseudo dice [np.float32(0.7746)] 
2025-01-02 05:18:35.802095: Epoch time: 42.41 s 
2025-01-02 05:18:36.353101:  
2025-01-02 05:18:36.353101: Epoch 231 
2025-01-02 05:18:36.360696: Current learning rate: 0.00098 
2025-01-02 05:19:18.776474: train_loss -0.8091 
2025-01-02 05:19:18.777480: val_loss -0.7215 
2025-01-02 05:19:18.783995: Pseudo dice [np.float32(0.7906)] 
2025-01-02 05:19:18.787504: Epoch time: 42.42 s 
2025-01-02 05:19:19.336839:  
2025-01-02 05:19:19.337843: Epoch 232 
2025-01-02 05:19:19.342870: Current learning rate: 0.00094 
2025-01-02 05:20:01.728141: train_loss -0.8069 
2025-01-02 05:20:01.729644: val_loss -0.6795 
2025-01-02 05:20:01.734658: Pseudo dice [np.float32(0.8035)] 
2025-01-02 05:20:01.739169: Epoch time: 42.39 s 
2025-01-02 05:20:02.285506:  
2025-01-02 05:20:02.285506: Epoch 233 
2025-01-02 05:20:02.290524: Current learning rate: 0.00089 
2025-01-02 05:20:44.694095: train_loss -0.8062 
2025-01-02 05:20:44.694095: val_loss -0.7254 
2025-01-02 05:20:44.700616: Pseudo dice [np.float32(0.8074)] 
2025-01-02 05:20:44.704167: Epoch time: 42.41 s 
2025-01-02 05:20:45.262320:  
2025-01-02 05:20:45.262320: Epoch 234 
2025-01-02 05:20:45.267388: Current learning rate: 0.00084 
2025-01-02 05:21:27.672720: train_loss -0.816 
2025-01-02 05:21:27.674224: val_loss -0.6849 
2025-01-02 05:21:27.680252: Pseudo dice [np.float32(0.7612)] 
2025-01-02 05:21:27.682761: Epoch time: 42.41 s 
2025-01-02 05:21:28.223564:  
2025-01-02 05:21:28.224569: Epoch 235 
2025-01-02 05:21:28.230625: Current learning rate: 0.00079 
2025-01-02 05:22:10.628440: train_loss -0.8227 
2025-01-02 05:22:10.629455: val_loss -0.6626 
2025-01-02 05:22:10.636523: Pseudo dice [np.float32(0.7228)] 
2025-01-02 05:22:10.640593: Epoch time: 42.41 s 
2025-01-02 05:22:11.178974:  
2025-01-02 05:22:11.179980: Epoch 236 
2025-01-02 05:22:11.186587: Current learning rate: 0.00075 
2025-01-02 05:22:53.577455: train_loss -0.8085 
2025-01-02 05:22:53.577455: val_loss -0.6946 
2025-01-02 05:22:53.584981: Pseudo dice [np.float32(0.7743)] 
2025-01-02 05:22:53.588993: Epoch time: 42.4 s 
2025-01-02 05:22:54.127281:  
2025-01-02 05:22:54.127281: Epoch 237 
2025-01-02 05:22:54.132871: Current learning rate: 0.0007 
2025-01-02 05:23:36.530935: train_loss -0.8145 
2025-01-02 05:23:36.530935: val_loss -0.7493 
2025-01-02 05:23:36.538453: Pseudo dice [np.float32(0.8298)] 
2025-01-02 05:23:36.541962: Epoch time: 42.4 s 
2025-01-02 05:23:37.084114:  
2025-01-02 05:23:37.084114: Epoch 238 
2025-01-02 05:23:37.090131: Current learning rate: 0.00065 
2025-01-02 05:24:19.461059: train_loss -0.8217 
2025-01-02 05:24:19.461561: val_loss -0.665 
2025-01-02 05:24:19.467577: Pseudo dice [np.float32(0.7506)] 
2025-01-02 05:24:19.471589: Epoch time: 42.38 s 
2025-01-02 05:24:20.174276:  
2025-01-02 05:24:20.174276: Epoch 239 
2025-01-02 05:24:20.180383: Current learning rate: 0.0006 
2025-01-02 05:25:02.587255: train_loss -0.8273 
2025-01-02 05:25:02.588255: val_loss -0.6742 
2025-01-02 05:25:02.593271: Pseudo dice [np.float32(0.7111)] 
2025-01-02 05:25:02.596285: Epoch time: 42.41 s 
2025-01-02 05:25:03.150169:  
2025-01-02 05:25:03.151172: Epoch 240 
2025-01-02 05:25:03.157758: Current learning rate: 0.00055 
2025-01-02 05:25:45.524493: train_loss -0.7978 
2025-01-02 05:25:45.525498: val_loss -0.6911 
2025-01-02 05:25:45.532017: Pseudo dice [np.float32(0.7495)] 
2025-01-02 05:25:45.537028: Epoch time: 42.37 s 
2025-01-02 05:25:46.089097:  
2025-01-02 05:25:46.089097: Epoch 241 
2025-01-02 05:25:46.096114: Current learning rate: 0.0005 
2025-01-02 05:26:28.484092: train_loss -0.8047 
2025-01-02 05:26:28.484092: val_loss -0.6377 
2025-01-02 05:26:28.491613: Pseudo dice [np.float32(0.7486)] 
2025-01-02 05:26:28.498636: Epoch time: 42.4 s 
2025-01-02 05:26:29.055179:  
2025-01-02 05:26:29.056178: Epoch 242 
2025-01-02 05:26:29.062288: Current learning rate: 0.00045 
2025-01-02 05:27:11.422504: train_loss -0.8201 
2025-01-02 05:27:11.423007: val_loss -0.6936 
2025-01-02 05:27:11.428022: Pseudo dice [np.float32(0.7537)] 
2025-01-02 05:27:11.432534: Epoch time: 42.37 s 
2025-01-02 05:27:11.988194:  
2025-01-02 05:27:11.988194: Epoch 243 
2025-01-02 05:27:11.994787: Current learning rate: 0.0004 
2025-01-02 05:27:54.393955: train_loss -0.8211 
2025-01-02 05:27:54.394960: val_loss -0.6887 
2025-01-02 05:27:54.401477: Pseudo dice [np.float32(0.7741)] 
2025-01-02 05:27:54.406005: Epoch time: 42.41 s 
2025-01-02 05:27:54.967570:  
2025-01-02 05:27:54.967570: Epoch 244 
2025-01-02 05:27:54.972623: Current learning rate: 0.00035 
2025-01-02 05:28:37.401201: train_loss -0.7988 
2025-01-02 05:28:37.402201: val_loss -0.7379 
2025-01-02 05:28:37.407722: Pseudo dice [np.float32(0.8103)] 
2025-01-02 05:28:37.412791: Epoch time: 42.43 s 
2025-01-02 05:28:37.972533:  
2025-01-02 05:28:37.973534: Epoch 245 
2025-01-02 05:28:37.979052: Current learning rate: 0.0003 
2025-01-02 05:29:20.367083: train_loss -0.8359 
2025-01-02 05:29:20.367596: val_loss -0.7275 
2025-01-02 05:29:20.374648: Pseudo dice [np.float32(0.7945)] 
2025-01-02 05:29:20.379667: Epoch time: 42.39 s 
2025-01-02 05:29:20.940286:  
2025-01-02 05:29:20.941290: Epoch 246 
2025-01-02 05:29:20.947863: Current learning rate: 0.00024 
2025-01-02 05:30:03.358295: train_loss -0.8151 
2025-01-02 05:30:03.358295: val_loss -0.6675 
2025-01-02 05:30:03.365827: Pseudo dice [np.float32(0.7772)] 
2025-01-02 05:30:03.369842: Epoch time: 42.42 s 
2025-01-02 05:30:03.925456:  
2025-01-02 05:30:03.925456: Epoch 247 
2025-01-02 05:30:03.931571: Current learning rate: 0.00019 
2025-01-02 05:30:46.290862: train_loss -0.8152 
2025-01-02 05:30:46.291862: val_loss -0.6684 
2025-01-02 05:30:46.298381: Pseudo dice [np.float32(0.7621)] 
2025-01-02 05:30:46.301887: Epoch time: 42.37 s 
2025-01-02 05:30:47.014064:  
2025-01-02 05:30:47.015069: Epoch 248 
2025-01-02 05:30:47.021641: Current learning rate: 0.00013 
2025-01-02 05:31:29.402204: train_loss -0.8203 
2025-01-02 05:31:29.402706: val_loss -0.7553 
2025-01-02 05:31:29.407721: Pseudo dice [np.float32(0.8179)] 
2025-01-02 05:31:29.412253: Epoch time: 42.39 s 
2025-01-02 05:31:29.959864:  
2025-01-02 05:31:29.960366: Epoch 249 
2025-01-02 05:31:29.966383: Current learning rate: 7e-05 
2025-01-02 05:32:12.368427: train_loss -0.8313 
2025-01-02 05:32:12.369426: val_loss -0.6808 
2025-01-02 05:32:12.375947: Pseudo dice [np.float32(0.7543)] 
2025-01-02 05:32:12.379958: Epoch time: 42.41 s 
2025-01-02 05:32:13.155301: Training done. 
2025-01-02 05:32:13.192811: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset006_Lung\splits_final.json 
2025-01-02 05:32:13.205810: The split file contains 5 splits. 
2025-01-02 05:32:13.212810: Desired fold for training: 0 
2025-01-02 05:32:13.244812: This split has 50 training and 13 validation cases. 
2025-01-02 05:32:13.253814: predicting lung_006 
2025-01-02 05:32:13.262813: lung_006, shape torch.Size([1, 285, 637, 637]), rank 0 
2025-01-02 05:33:09.064995: predicting lung_010 
2025-01-02 05:33:09.108504: lung_010, shape torch.Size([1, 242, 390, 390]), rank 0 
2025-01-02 05:33:27.103204: predicting lung_033 
2025-01-02 05:33:27.124709: lung_033, shape torch.Size([1, 260, 535, 535]), rank 0 
2025-01-02 05:34:00.822737: predicting lung_034 
2025-01-02 05:34:00.851245: lung_034, shape torch.Size([1, 296, 586, 586]), rank 0 
2025-01-02 05:34:55.797773: predicting lung_041 
2025-01-02 05:34:55.835773: lung_041, shape torch.Size([1, 240, 535, 535]), rank 0 
2025-01-02 05:35:23.947560: predicting lung_042 
2025-01-02 05:35:23.983562: lung_042, shape torch.Size([1, 251, 478, 478]), rank 0 
2025-01-02 05:35:46.439102: predicting lung_046 
2025-01-02 05:35:46.464102: lung_046, shape torch.Size([1, 226, 509, 509]), rank 0 
2025-01-02 05:36:14.499257: predicting lung_048 
2025-01-02 05:36:14.523260: lung_048, shape torch.Size([1, 259, 531, 531]), rank 0 
2025-01-02 05:36:48.267924: predicting lung_059 
2025-01-02 05:36:48.296924: lung_059, shape torch.Size([1, 218, 535, 535]), rank 0 
2025-01-02 05:37:16.366257: predicting lung_065 
2025-01-02 05:37:16.389763: lung_065, shape torch.Size([1, 257, 474, 474]), rank 0 
2025-01-02 05:37:38.850417: predicting lung_066 
2025-01-02 05:37:38.872419: lung_066, shape torch.Size([1, 241, 578, 578]), rank 0 
2025-01-02 05:38:26.023739: predicting lung_070 
2025-01-02 05:38:26.065739: lung_070, shape torch.Size([1, 266, 497, 497]), rank 0 
2025-01-02 05:38:59.773866: predicting lung_079 
2025-01-02 05:38:59.797867: lung_079, shape torch.Size([1, 251, 606, 606]), rank 0 
2025-01-02 05:39:58.779735: Validation complete 
2025-01-02 05:39:58.780736: Mean Validation Dice:  0.6107010188645823 
