
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-27 09:50:06.079175: do_dummy_2d_data_aug: True 
2025-02-27 09:50:06.084174: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset005_Prostate\splits_final.json 
2025-02-27 09:50:06.090914: The split file contains 5 splits. 
2025-02-27 09:50:06.093918: Desired fold for training: 0 
2025-02-27 09:50:06.095918: This split has 25 training and 7 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [20, 320, 256], 'median_image_size_in_voxels': [20.0, 320.0, 319.0], 'spacing': [3.5999999046325684, 0.625, 0.625], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset005_Prostate', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.5999999046325684, 0.625, 0.625], 'original_median_shape_after_transp': [20, 320, 320], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1326.0, 'mean': 350.18780517578125, 'median': 327.0, 'min': 0.0, 'percentile_00_5': 83.0, 'percentile_99_5': 822.0, 'std': 139.9563751220703}, '1': {'max': 3698.0, 'mean': 1351.1083984375, 'median': 1364.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 2563.0, 'std': 376.4326477050781}}} 
 
2025-02-27 09:50:15.573223: unpacking dataset... 
2025-02-27 09:50:16.075261: unpacking done... 
2025-02-27 09:50:19.480035:  
2025-02-27 09:50:19.485055: Epoch 0 
2025-02-27 09:50:19.489065: Current learning rate: 0.01 
2025-02-27 09:51:40.757538: train_loss -0.3105 
2025-02-27 09:51:40.765062: val_loss -0.5656 
2025-02-27 09:51:40.768572: Pseudo dice [np.float32(0.4698), np.float32(0.7902)] 
2025-02-27 09:51:40.771583: Epoch time: 81.28 s 
2025-02-27 09:51:40.774089: Yayy! New best EMA pseudo Dice: 0.6299999952316284 
2025-02-27 09:51:41.489665:  
2025-02-27 09:51:41.495182: Epoch 1 
2025-02-27 09:51:41.497689: Current learning rate: 0.00991 
2025-02-27 09:52:55.206046: train_loss -0.6973 
2025-02-27 09:52:55.212064: val_loss -0.6517 
2025-02-27 09:52:55.214568: Pseudo dice [np.float32(0.5875), np.float32(0.8579)] 
2025-02-27 09:52:55.218075: Epoch time: 73.72 s 
2025-02-27 09:52:55.221086: Yayy! New best EMA pseudo Dice: 0.6392999887466431 
2025-02-27 09:52:56.028064:  
2025-02-27 09:52:56.033103: Epoch 2 
2025-02-27 09:52:56.036695: Current learning rate: 0.00982 
2025-02-27 09:54:09.770743: train_loss -0.7825 
2025-02-27 09:54:09.775841: val_loss -0.6855 
2025-02-27 09:54:09.779350: Pseudo dice [np.float32(0.6101), np.float32(0.8742)] 
2025-02-27 09:54:09.783359: Epoch time: 73.74 s 
2025-02-27 09:54:09.786870: Yayy! New best EMA pseudo Dice: 0.6495000123977661 
2025-02-27 09:54:10.614588:  
2025-02-27 09:54:10.619633: Epoch 3 
2025-02-27 09:54:10.623142: Current learning rate: 0.00973 
2025-02-27 09:55:24.371933: train_loss -0.8091 
2025-02-27 09:55:24.377949: val_loss -0.6863 
2025-02-27 09:55:24.381456: Pseudo dice [np.float32(0.6256), np.float32(0.8666)] 
2025-02-27 09:55:24.384468: Epoch time: 73.76 s 
2025-02-27 09:55:24.387978: Yayy! New best EMA pseudo Dice: 0.6592000126838684 
2025-02-27 09:55:25.205352:  
2025-02-27 09:55:25.210912: Epoch 4 
2025-02-27 09:55:25.213449: Current learning rate: 0.00964 
2025-02-27 09:56:38.933914: train_loss -0.8332 
2025-02-27 09:56:38.940554: val_loss -0.6889 
2025-02-27 09:56:38.943564: Pseudo dice [np.float32(0.6343), np.float32(0.87)] 
2025-02-27 09:56:38.947073: Epoch time: 73.73 s 
2025-02-27 09:56:38.949579: Yayy! New best EMA pseudo Dice: 0.6685000061988831 
2025-02-27 09:56:39.904408:  
2025-02-27 09:56:39.909959: Epoch 5 
2025-02-27 09:56:39.914006: Current learning rate: 0.00955 
2025-02-27 09:57:53.624953: train_loss -0.854 
2025-02-27 09:57:53.629968: val_loss -0.6976 
2025-02-27 09:57:53.633477: Pseudo dice [np.float32(0.6497), np.float32(0.8759)] 
2025-02-27 09:57:53.637485: Epoch time: 73.72 s 
2025-02-27 09:57:53.640995: Yayy! New best EMA pseudo Dice: 0.6779000163078308 
2025-02-27 09:57:54.458143:  
2025-02-27 09:57:54.463163: Epoch 6 
2025-02-27 09:57:54.466196: Current learning rate: 0.00946 
2025-02-27 09:59:08.198908: train_loss -0.8732 
2025-02-27 09:59:08.206039: val_loss -0.694 
2025-02-27 09:59:08.209550: Pseudo dice [np.float32(0.6489), np.float32(0.8819)] 
2025-02-27 09:59:08.213058: Epoch time: 73.74 s 
2025-02-27 09:59:08.216068: Yayy! New best EMA pseudo Dice: 0.6866999864578247 
2025-02-27 09:59:09.016497:  
2025-02-27 09:59:09.022063: Epoch 7 
2025-02-27 09:59:09.026096: Current learning rate: 0.00937 
2025-02-27 10:00:22.734949: train_loss -0.8787 
2025-02-27 10:00:22.741548: val_loss -0.6879 
2025-02-27 10:00:22.744054: Pseudo dice [np.float32(0.6457), np.float32(0.8829)] 
2025-02-27 10:00:22.748565: Epoch time: 73.72 s 
2025-02-27 10:00:22.751574: Yayy! New best EMA pseudo Dice: 0.6944000124931335 
2025-02-27 10:00:23.554771:  
2025-02-27 10:00:23.559584: Epoch 8 
2025-02-27 10:00:23.563100: Current learning rate: 0.00928 
2025-02-27 10:01:37.239564: train_loss -0.8899 
2025-02-27 10:01:37.246088: val_loss -0.705 
2025-02-27 10:01:37.249592: Pseudo dice [np.float32(0.6704), np.float32(0.884)] 
2025-02-27 10:01:37.252603: Epoch time: 73.69 s 
2025-02-27 10:01:37.255109: Yayy! New best EMA pseudo Dice: 0.7027000188827515 
2025-02-27 10:01:38.079023:  
2025-02-27 10:01:38.084599: Epoch 9 
2025-02-27 10:01:38.088660: Current learning rate: 0.00919 
2025-02-27 10:02:51.812876: train_loss -0.8954 
2025-02-27 10:02:51.819579: val_loss -0.6979 
2025-02-27 10:02:51.823122: Pseudo dice [np.float32(0.6598), np.float32(0.8822)] 
2025-02-27 10:02:51.826222: Epoch time: 73.73 s 
2025-02-27 10:02:51.829796: Yayy! New best EMA pseudo Dice: 0.7095000147819519 
2025-02-27 10:02:52.627932:  
2025-02-27 10:02:52.633452: Epoch 10 
2025-02-27 10:02:52.636962: Current learning rate: 0.0091 
2025-02-27 10:04:06.350129: train_loss -0.8941 
2025-02-27 10:04:06.356684: val_loss -0.7009 
2025-02-27 10:04:06.359713: Pseudo dice [np.float32(0.6572), np.float32(0.8856)] 
2025-02-27 10:04:06.362747: Epoch time: 73.72 s 
2025-02-27 10:04:06.365269: Yayy! New best EMA pseudo Dice: 0.7156999707221985 
2025-02-27 10:04:07.148322:  
2025-02-27 10:04:07.153835: Epoch 11 
2025-02-27 10:04:07.157347: Current learning rate: 0.009 
2025-02-27 10:05:20.857339: train_loss -0.8959 
2025-02-27 10:05:20.862350: val_loss -0.7009 
2025-02-27 10:05:20.865860: Pseudo dice [np.float32(0.6654), np.float32(0.8883)] 
2025-02-27 10:05:20.869870: Epoch time: 73.71 s 
2025-02-27 10:05:20.872894: Yayy! New best EMA pseudo Dice: 0.7218000292778015 
2025-02-27 10:05:21.663332:  
2025-02-27 10:05:21.668362: Epoch 12 
2025-02-27 10:05:21.671398: Current learning rate: 0.00891 
2025-02-27 10:06:35.400078: train_loss -0.9041 
2025-02-27 10:06:35.407601: val_loss -0.6893 
2025-02-27 10:06:35.410106: Pseudo dice [np.float32(0.6565), np.float32(0.8846)] 
2025-02-27 10:06:35.413616: Epoch time: 73.74 s 
2025-02-27 10:06:35.416662: Yayy! New best EMA pseudo Dice: 0.7267000079154968 
2025-02-27 10:06:36.366908:  
2025-02-27 10:06:36.372444: Epoch 13 
2025-02-27 10:06:36.375506: Current learning rate: 0.00882 
2025-02-27 10:07:50.074786: train_loss -0.904 
2025-02-27 10:07:50.080801: val_loss -0.7003 
2025-02-27 10:07:50.084309: Pseudo dice [np.float32(0.6738), np.float32(0.8849)] 
2025-02-27 10:07:50.087317: Epoch time: 73.71 s 
2025-02-27 10:07:50.089823: Yayy! New best EMA pseudo Dice: 0.7319999933242798 
2025-02-27 10:07:50.899515:  
2025-02-27 10:07:50.904526: Epoch 14 
2025-02-27 10:07:50.908037: Current learning rate: 0.00873 
2025-02-27 10:09:04.601998: train_loss -0.9068 
2025-02-27 10:09:04.608015: val_loss -0.6986 
2025-02-27 10:09:04.611520: Pseudo dice [np.float32(0.6694), np.float32(0.8887)] 
2025-02-27 10:09:04.614529: Epoch time: 73.7 s 
2025-02-27 10:09:04.618037: Yayy! New best EMA pseudo Dice: 0.7366999983787537 
2025-02-27 10:09:05.416201:  
2025-02-27 10:09:05.420213: Epoch 15 
2025-02-27 10:09:05.422720: Current learning rate: 0.00864 
2025-02-27 10:10:19.105732: train_loss -0.9108 
2025-02-27 10:10:19.109750: val_loss -0.6969 
2025-02-27 10:10:19.113770: Pseudo dice [np.float32(0.6723), np.float32(0.8879)] 
2025-02-27 10:10:19.116281: Epoch time: 73.69 s 
2025-02-27 10:10:19.119796: Yayy! New best EMA pseudo Dice: 0.7409999966621399 
2025-02-27 10:10:19.936220:  
2025-02-27 10:10:19.942340: Epoch 16 
2025-02-27 10:10:19.945117: Current learning rate: 0.00855 
2025-02-27 10:11:33.660914: train_loss -0.9189 
2025-02-27 10:11:33.668093: val_loss -0.6898 
2025-02-27 10:11:33.672130: Pseudo dice [np.float32(0.6677), np.float32(0.886)] 
2025-02-27 10:11:33.674637: Epoch time: 73.73 s 
2025-02-27 10:11:33.678143: Yayy! New best EMA pseudo Dice: 0.7445999979972839 
2025-02-27 10:11:34.501986:  
2025-02-27 10:11:34.506996: Epoch 17 
2025-02-27 10:11:34.510505: Current learning rate: 0.00846 
2025-02-27 10:12:48.236611: train_loss -0.9174 
2025-02-27 10:12:48.243131: val_loss -0.6982 
2025-02-27 10:12:48.247141: Pseudo dice [np.float32(0.6817), np.float32(0.885)] 
2025-02-27 10:12:48.249647: Epoch time: 73.74 s 
2025-02-27 10:12:48.253155: Yayy! New best EMA pseudo Dice: 0.7484999895095825 
2025-02-27 10:12:49.073675:  
2025-02-27 10:12:49.079292: Epoch 18 
2025-02-27 10:12:49.083353: Current learning rate: 0.00836 
2025-02-27 10:14:02.829121: train_loss -0.9162 
2025-02-27 10:14:02.834243: val_loss -0.6947 
2025-02-27 10:14:02.838303: Pseudo dice [np.float32(0.6737), np.float32(0.8875)] 
2025-02-27 10:14:02.841855: Epoch time: 73.76 s 
2025-02-27 10:14:02.844386: Yayy! New best EMA pseudo Dice: 0.7516999840736389 
2025-02-27 10:14:03.652866:  
2025-02-27 10:14:03.659532: Epoch 19 
2025-02-27 10:14:03.662074: Current learning rate: 0.00827 
2025-02-27 10:15:17.410714: train_loss -0.9167 
2025-02-27 10:15:17.416230: val_loss -0.6946 
2025-02-27 10:15:17.419744: Pseudo dice [np.float32(0.6673), np.float32(0.888)] 
2025-02-27 10:15:17.423248: Epoch time: 73.76 s 
2025-02-27 10:15:17.426257: Yayy! New best EMA pseudo Dice: 0.7542999982833862 
2025-02-27 10:15:18.379225:  
2025-02-27 10:15:18.384804: Epoch 20 
2025-02-27 10:15:18.388318: Current learning rate: 0.00818 
2025-02-27 10:16:32.077755: train_loss -0.9202 
2025-02-27 10:16:32.083768: val_loss -0.695 
2025-02-27 10:16:32.086778: Pseudo dice [np.float32(0.6736), np.float32(0.8884)] 
2025-02-27 10:16:32.089284: Epoch time: 73.7 s 
2025-02-27 10:16:32.092795: Yayy! New best EMA pseudo Dice: 0.7570000290870667 
2025-02-27 10:16:32.915276:  
2025-02-27 10:16:32.919881: Epoch 21 
2025-02-27 10:16:32.924447: Current learning rate: 0.00809 
2025-02-27 10:17:46.621673: train_loss -0.9149 
2025-02-27 10:17:46.627216: val_loss -0.7029 
2025-02-27 10:17:46.631228: Pseudo dice [np.float32(0.6834), np.float32(0.8898)] 
2025-02-27 10:17:46.634738: Epoch time: 73.71 s 
2025-02-27 10:17:46.637244: Yayy! New best EMA pseudo Dice: 0.7598999738693237 
2025-02-27 10:17:47.435730:  
2025-02-27 10:17:47.441344: Epoch 22 
2025-02-27 10:17:47.445403: Current learning rate: 0.008 
2025-02-27 10:19:01.207888: train_loss -0.9238 
2025-02-27 10:19:01.214472: val_loss -0.6976 
2025-02-27 10:19:01.217555: Pseudo dice [np.float32(0.6816), np.float32(0.8913)] 
2025-02-27 10:19:01.220594: Epoch time: 73.77 s 
2025-02-27 10:19:01.224161: Yayy! New best EMA pseudo Dice: 0.7626000046730042 
2025-02-27 10:19:02.021001:  
2025-02-27 10:19:02.026516: Epoch 23 
2025-02-27 10:19:02.030025: Current learning rate: 0.0079 
2025-02-27 10:20:15.831549: train_loss -0.9243 
2025-02-27 10:20:15.839071: val_loss -0.6998 
2025-02-27 10:20:15.843083: Pseudo dice [np.float32(0.6834), np.float32(0.8899)] 
2025-02-27 10:20:15.847596: Epoch time: 73.81 s 
2025-02-27 10:20:15.850606: Yayy! New best EMA pseudo Dice: 0.7649999856948853 
2025-02-27 10:20:16.641678:  
2025-02-27 10:20:16.646730: Epoch 24 
2025-02-27 10:20:16.650240: Current learning rate: 0.00781 
2025-02-27 10:21:30.433099: train_loss -0.9277 
2025-02-27 10:21:30.439736: val_loss -0.6868 
2025-02-27 10:21:30.443323: Pseudo dice [np.float32(0.6703), np.float32(0.8866)] 
2025-02-27 10:21:30.446410: Epoch time: 73.79 s 
2025-02-27 10:21:30.450029: Yayy! New best EMA pseudo Dice: 0.7663000226020813 
2025-02-27 10:21:31.254101:  
2025-02-27 10:21:31.260200: Epoch 25 
2025-02-27 10:21:31.263257: Current learning rate: 0.00772 
2025-02-27 10:22:45.096881: train_loss -0.9224 
2025-02-27 10:22:45.103397: val_loss -0.6873 
2025-02-27 10:22:45.106463: Pseudo dice [np.float32(0.6735), np.float32(0.8855)] 
2025-02-27 10:22:45.109495: Epoch time: 73.84 s 
2025-02-27 10:22:45.113507: Yayy! New best EMA pseudo Dice: 0.7675999999046326 
2025-02-27 10:22:45.913869:  
2025-02-27 10:22:45.919934: Epoch 26 
2025-02-27 10:22:45.922560: Current learning rate: 0.00763 
2025-02-27 10:23:59.778128: train_loss -0.9215 
2025-02-27 10:23:59.785147: val_loss -0.6903 
2025-02-27 10:23:59.788157: Pseudo dice [np.float32(0.6795), np.float32(0.8837)] 
2025-02-27 10:23:59.791669: Epoch time: 73.87 s 
2025-02-27 10:23:59.794175: Yayy! New best EMA pseudo Dice: 0.7689999938011169 
2025-02-27 10:24:00.644736:  
2025-02-27 10:24:00.649748: Epoch 27 
2025-02-27 10:24:00.653258: Current learning rate: 0.00753 
2025-02-27 10:25:14.438484: train_loss -0.9236 
2025-02-27 10:25:14.445004: val_loss -0.6916 
2025-02-27 10:25:14.448514: Pseudo dice [np.float32(0.6794), np.float32(0.8849)] 
2025-02-27 10:25:14.450753: Epoch time: 73.8 s 
2025-02-27 10:25:14.454787: Yayy! New best EMA pseudo Dice: 0.7703999876976013 
2025-02-27 10:25:15.419649:  
2025-02-27 10:25:15.425726: Epoch 28 
2025-02-27 10:25:15.429338: Current learning rate: 0.00744 
2025-02-27 10:26:29.170366: train_loss -0.9277 
2025-02-27 10:26:29.175883: val_loss -0.679 
2025-02-27 10:26:29.179393: Pseudo dice [np.float32(0.6694), np.float32(0.8829)] 
2025-02-27 10:26:29.181898: Epoch time: 73.75 s 
2025-02-27 10:26:29.185405: Yayy! New best EMA pseudo Dice: 0.7709000110626221 
2025-02-27 10:26:29.978446:  
2025-02-27 10:26:29.984590: Epoch 29 
2025-02-27 10:26:29.987620: Current learning rate: 0.00735 
2025-02-27 10:27:43.715292: train_loss -0.9328 
2025-02-27 10:27:43.721843: val_loss -0.6827 
2025-02-27 10:27:43.725352: Pseudo dice [np.float32(0.6745), np.float32(0.8866)] 
2025-02-27 10:27:43.727863: Epoch time: 73.74 s 
2025-02-27 10:27:43.731367: Yayy! New best EMA pseudo Dice: 0.7718999981880188 
2025-02-27 10:27:44.524888:  
2025-02-27 10:27:44.531042: Epoch 30 
2025-02-27 10:27:44.534111: Current learning rate: 0.00725 
2025-02-27 10:28:58.610626: train_loss -0.9209 
2025-02-27 10:28:58.617139: val_loss -0.6831 
2025-02-27 10:28:58.619644: Pseudo dice [np.float32(0.6653), np.float32(0.8859)] 
2025-02-27 10:28:58.623155: Epoch time: 74.09 s 
2025-02-27 10:28:58.626660: Yayy! New best EMA pseudo Dice: 0.7723000049591064 
2025-02-27 10:28:59.423991:  
2025-02-27 10:28:59.429615: Epoch 31 
2025-02-27 10:28:59.433671: Current learning rate: 0.00716 
2025-02-27 10:30:13.178418: train_loss -0.9212 
2025-02-27 10:30:13.184941: val_loss -0.6911 
2025-02-27 10:30:13.189002: Pseudo dice [np.float32(0.6848), np.float32(0.8864)] 
2025-02-27 10:30:13.192029: Epoch time: 73.75 s 
2025-02-27 10:30:13.196037: Yayy! New best EMA pseudo Dice: 0.7735999822616577 
2025-02-27 10:30:14.006244:  
2025-02-27 10:30:14.012320: Epoch 32 
2025-02-27 10:30:14.014865: Current learning rate: 0.00707 
2025-02-27 10:31:27.770444: train_loss -0.9264 
2025-02-27 10:31:27.775625: val_loss -0.6849 
2025-02-27 10:31:27.779163: Pseudo dice [np.float32(0.6765), np.float32(0.8865)] 
2025-02-27 10:31:27.782218: Epoch time: 73.76 s 
2025-02-27 10:31:27.785731: Yayy! New best EMA pseudo Dice: 0.774399995803833 
2025-02-27 10:31:28.585144:  
2025-02-27 10:31:28.591184: Epoch 33 
2025-02-27 10:31:28.594218: Current learning rate: 0.00697 
2025-02-27 10:32:42.360201: train_loss -0.9259 
2025-02-27 10:32:42.367223: val_loss -0.6878 
2025-02-27 10:32:42.370232: Pseudo dice [np.float32(0.6806), np.float32(0.8881)] 
2025-02-27 10:32:42.373741: Epoch time: 73.78 s 
2025-02-27 10:32:42.376247: Yayy! New best EMA pseudo Dice: 0.7753999829292297 
2025-02-27 10:32:43.192742:  
2025-02-27 10:32:43.198806: Epoch 34 
2025-02-27 10:32:43.201938: Current learning rate: 0.00688 
2025-02-27 10:33:57.079569: train_loss -0.9363 
2025-02-27 10:33:57.086860: val_loss -0.6903 
2025-02-27 10:33:57.090373: Pseudo dice [np.float32(0.6812), np.float32(0.8903)] 
2025-02-27 10:33:57.093387: Epoch time: 73.89 s 
2025-02-27 10:33:57.095916: Yayy! New best EMA pseudo Dice: 0.7764000296592712 
2025-02-27 10:33:58.107644:  
2025-02-27 10:33:58.114182: Epoch 35 
2025-02-27 10:33:58.117732: Current learning rate: 0.00679 
2025-02-27 10:35:11.926926: train_loss -0.9406 
2025-02-27 10:35:11.934980: val_loss -0.6842 
2025-02-27 10:35:11.938013: Pseudo dice [np.float32(0.6744), np.float32(0.8878)] 
2025-02-27 10:35:11.941522: Epoch time: 73.82 s 
2025-02-27 10:35:11.944541: Yayy! New best EMA pseudo Dice: 0.7768999934196472 
2025-02-27 10:35:12.768296:  
2025-02-27 10:35:12.773198: Epoch 36 
2025-02-27 10:35:12.779219: Current learning rate: 0.00669 
2025-02-27 10:36:26.514511: train_loss -0.9263 
2025-02-27 10:36:26.521530: val_loss -0.6856 
2025-02-27 10:36:26.525088: Pseudo dice [np.float32(0.6795), np.float32(0.8868)] 
2025-02-27 10:36:26.528128: Epoch time: 73.75 s 
2025-02-27 10:36:26.530636: Yayy! New best EMA pseudo Dice: 0.7774999737739563 
2025-02-27 10:36:27.353570:  
2025-02-27 10:36:27.358633: Epoch 37 
2025-02-27 10:36:27.361181: Current learning rate: 0.0066 
2025-02-27 10:37:41.241763: train_loss -0.9325 
2025-02-27 10:37:41.247808: val_loss -0.6799 
2025-02-27 10:37:41.250818: Pseudo dice [np.float32(0.6735), np.float32(0.8865)] 
2025-02-27 10:37:41.254336: Epoch time: 73.89 s 
2025-02-27 10:37:41.257845: Yayy! New best EMA pseudo Dice: 0.7778000235557556 
2025-02-27 10:37:42.077243:  
2025-02-27 10:37:42.082772: Epoch 38 
2025-02-27 10:37:42.086795: Current learning rate: 0.0065 
2025-02-27 10:38:55.818534: train_loss -0.9321 
2025-02-27 10:38:55.826572: val_loss -0.6811 
2025-02-27 10:38:55.830084: Pseudo dice [np.float32(0.6727), np.float32(0.8863)] 
2025-02-27 10:38:55.834091: Epoch time: 73.74 s 
2025-02-27 10:38:55.836597: Yayy! New best EMA pseudo Dice: 0.777899980545044 
2025-02-27 10:38:56.645627:  
2025-02-27 10:38:56.650639: Epoch 39 
2025-02-27 10:38:56.653147: Current learning rate: 0.00641 
2025-02-27 10:40:10.387060: train_loss -0.9299 
2025-02-27 10:40:10.392734: val_loss -0.6793 
2025-02-27 10:40:10.397530: Pseudo dice [np.float32(0.673), np.float32(0.8867)] 
2025-02-27 10:40:10.400581: Epoch time: 73.74 s 
2025-02-27 10:40:10.403599: Yayy! New best EMA pseudo Dice: 0.7781000137329102 
2025-02-27 10:40:11.239199:  
2025-02-27 10:40:11.244235: Epoch 40 
2025-02-27 10:40:11.246525: Current learning rate: 0.00631 
2025-02-27 10:41:25.138906: train_loss -0.9321 
2025-02-27 10:41:25.145423: val_loss -0.6815 
2025-02-27 10:41:25.148932: Pseudo dice [np.float32(0.6778), np.float32(0.8856)] 
2025-02-27 10:41:25.151438: Epoch time: 73.9 s 
2025-02-27 10:41:25.154944: Yayy! New best EMA pseudo Dice: 0.7785000205039978 
2025-02-27 10:41:26.071533:  
2025-02-27 10:41:26.076544: Epoch 41 
2025-02-27 10:41:26.080052: Current learning rate: 0.00622 
2025-02-27 10:42:39.980161: train_loss -0.9338 
2025-02-27 10:42:39.987680: val_loss -0.6773 
2025-02-27 10:42:39.991189: Pseudo dice [np.float32(0.674), np.float32(0.8865)] 
2025-02-27 10:42:39.994205: Epoch time: 73.91 s 
2025-02-27 10:42:39.996711: Yayy! New best EMA pseudo Dice: 0.7786999940872192 
2025-02-27 10:42:41.035909:  
2025-02-27 10:42:41.042537: Epoch 42 
2025-02-27 10:42:41.045085: Current learning rate: 0.00612 
2025-02-27 10:43:54.850933: train_loss -0.9383 
2025-02-27 10:43:54.856557: val_loss -0.6777 
2025-02-27 10:43:54.860066: Pseudo dice [np.float32(0.6767), np.float32(0.8868)] 
2025-02-27 10:43:54.862573: Epoch time: 73.81 s 
2025-02-27 10:43:54.866080: Yayy! New best EMA pseudo Dice: 0.7789999842643738 
2025-02-27 10:43:55.655886:  
2025-02-27 10:43:55.661507: Epoch 43 
2025-02-27 10:43:55.664053: Current learning rate: 0.00603 
2025-02-27 10:45:09.456961: train_loss -0.9277 
2025-02-27 10:45:09.461979: val_loss -0.6783 
2025-02-27 10:45:09.466022: Pseudo dice [np.float32(0.6738), np.float32(0.8868)] 
2025-02-27 10:45:09.468529: Epoch time: 73.8 s 
2025-02-27 10:45:09.472038: Yayy! New best EMA pseudo Dice: 0.7791000008583069 
2025-02-27 10:45:10.281774:  
2025-02-27 10:45:10.287331: Epoch 44 
2025-02-27 10:45:10.290371: Current learning rate: 0.00593 
2025-02-27 10:46:24.168324: train_loss -0.9403 
2025-02-27 10:46:24.175844: val_loss -0.6859 
2025-02-27 10:46:24.178349: Pseudo dice [np.float32(0.681), np.float32(0.8892)] 
2025-02-27 10:46:24.181883: Epoch time: 73.89 s 
2025-02-27 10:46:24.186531: Yayy! New best EMA pseudo Dice: 0.779699981212616 
2025-02-27 10:46:25.043235:  
2025-02-27 10:46:25.048246: Epoch 45 
2025-02-27 10:46:25.051755: Current learning rate: 0.00584 
2025-02-27 10:47:38.944348: train_loss -0.934 
2025-02-27 10:47:38.950377: val_loss -0.6781 
2025-02-27 10:47:38.953401: Pseudo dice [np.float32(0.6778), np.float32(0.8839)] 
2025-02-27 10:47:38.956907: Epoch time: 73.9 s 
2025-02-27 10:47:38.960925: Yayy! New best EMA pseudo Dice: 0.7797999978065491 
2025-02-27 10:47:39.742413:  
2025-02-27 10:47:39.747929: Epoch 46 
2025-02-27 10:47:39.751439: Current learning rate: 0.00574 
2025-02-27 10:48:53.744474: train_loss -0.9356 
2025-02-27 10:48:53.750492: val_loss -0.687 
2025-02-27 10:48:53.754000: Pseudo dice [np.float32(0.6843), np.float32(0.8917)] 
2025-02-27 10:48:53.757011: Epoch time: 74.0 s 
2025-02-27 10:48:53.759516: Yayy! New best EMA pseudo Dice: 0.7806000113487244 
2025-02-27 10:48:54.551672:  
2025-02-27 10:48:54.557761: Epoch 47 
2025-02-27 10:48:54.560804: Current learning rate: 0.00565 
2025-02-27 10:50:08.472927: train_loss -0.9293 
2025-02-27 10:50:08.478950: val_loss -0.6738 
2025-02-27 10:50:08.482957: Pseudo dice [np.float32(0.6709), np.float32(0.8863)] 
2025-02-27 10:50:08.485463: Epoch time: 73.92 s 
2025-02-27 10:50:09.036982:  
2025-02-27 10:50:09.042513: Epoch 48 
2025-02-27 10:50:09.046023: Current learning rate: 0.00555 
2025-02-27 10:51:22.986992: train_loss -0.936 
2025-02-27 10:51:22.993007: val_loss -0.6789 
2025-02-27 10:51:22.997018: Pseudo dice [np.float32(0.6742), np.float32(0.8882)] 
2025-02-27 10:51:22.999569: Epoch time: 73.95 s 
2025-02-27 10:51:23.561549:  
2025-02-27 10:51:23.567065: Epoch 49 
2025-02-27 10:51:23.569570: Current learning rate: 0.00546 
2025-02-27 10:52:37.637871: train_loss -0.9431 
2025-02-27 10:52:37.645400: val_loss -0.6739 
2025-02-27 10:52:37.647407: Pseudo dice [np.float32(0.6779), np.float32(0.8864)] 
2025-02-27 10:52:37.651523: Epoch time: 74.08 s 
2025-02-27 10:52:37.867791: Yayy! New best EMA pseudo Dice: 0.7807000279426575 
2025-02-27 10:52:38.844915:  
2025-02-27 10:52:38.850093: Epoch 50 
2025-02-27 10:52:38.853615: Current learning rate: 0.00536 
2025-02-27 10:53:52.777029: train_loss -0.9383 
2025-02-27 10:53:52.784053: val_loss -0.6765 
2025-02-27 10:53:52.787063: Pseudo dice [np.float32(0.6813), np.float32(0.8871)] 
2025-02-27 10:53:52.790572: Epoch time: 73.93 s 
2025-02-27 10:53:52.793078: Yayy! New best EMA pseudo Dice: 0.781000018119812 
2025-02-27 10:53:53.657698:  
2025-02-27 10:53:53.663244: Epoch 51 
2025-02-27 10:53:53.667344: Current learning rate: 0.00526 
2025-02-27 10:55:07.500170: train_loss -0.9405 
2025-02-27 10:55:07.506689: val_loss -0.6665 
2025-02-27 10:55:07.509195: Pseudo dice [np.float32(0.6666), np.float32(0.8863)] 
2025-02-27 10:55:07.512878: Epoch time: 73.84 s 
2025-02-27 10:55:08.078299:  
2025-02-27 10:55:08.083134: Epoch 52 
2025-02-27 10:55:08.086647: Current learning rate: 0.00517 
2025-02-27 10:56:21.925536: train_loss -0.9403 
2025-02-27 10:56:21.932068: val_loss -0.6708 
2025-02-27 10:56:21.935643: Pseudo dice [np.float32(0.6781), np.float32(0.8852)] 
2025-02-27 10:56:21.937871: Epoch time: 73.85 s 
2025-02-27 10:56:22.503598:  
2025-02-27 10:56:22.508650: Epoch 53 
2025-02-27 10:56:22.512339: Current learning rate: 0.00507 
2025-02-27 10:57:36.375333: train_loss -0.9293 
2025-02-27 10:57:36.382358: val_loss -0.6784 
2025-02-27 10:57:36.385370: Pseudo dice [np.float32(0.6815), np.float32(0.8876)] 
2025-02-27 10:57:36.387880: Epoch time: 73.87 s 
2025-02-27 10:57:36.391399: Yayy! New best EMA pseudo Dice: 0.7810999751091003 
2025-02-27 10:57:37.258426:  
2025-02-27 10:57:37.264484: Epoch 54 
2025-02-27 10:57:37.267747: Current learning rate: 0.00497 
2025-02-27 10:58:51.300076: train_loss -0.9364 
2025-02-27 10:58:51.305672: val_loss -0.6751 
2025-02-27 10:58:51.310314: Pseudo dice [np.float32(0.6785), np.float32(0.8861)] 
2025-02-27 10:58:51.313885: Epoch time: 74.04 s 
2025-02-27 10:58:51.316392: Yayy! New best EMA pseudo Dice: 0.7811999917030334 
2025-02-27 10:58:52.199424:  
2025-02-27 10:58:52.204942: Epoch 55 
2025-02-27 10:58:52.207448: Current learning rate: 0.00487 
2025-02-27 11:00:06.434820: train_loss -0.9393 
2025-02-27 11:00:06.440840: val_loss -0.6825 
2025-02-27 11:00:06.444349: Pseudo dice [np.float32(0.6872), np.float32(0.8883)] 
2025-02-27 11:00:06.447360: Epoch time: 74.24 s 
2025-02-27 11:00:06.450816: Yayy! New best EMA pseudo Dice: 0.7817999720573425 
2025-02-27 11:00:07.334491:  
2025-02-27 11:00:07.339505: Epoch 56 
2025-02-27 11:00:07.343016: Current learning rate: 0.00478 
2025-02-27 11:01:21.472565: train_loss -0.9353 
2025-02-27 11:01:21.479079: val_loss -0.6766 
2025-02-27 11:01:21.482589: Pseudo dice [np.float32(0.6777), np.float32(0.8895)] 
2025-02-27 11:01:21.485097: Epoch time: 74.14 s 
2025-02-27 11:01:21.489110: Yayy! New best EMA pseudo Dice: 0.7820000052452087 
2025-02-27 11:01:22.285964:  
2025-02-27 11:01:22.291618: Epoch 57 
2025-02-27 11:01:22.295664: Current learning rate: 0.00468 
2025-02-27 11:02:36.304773: train_loss -0.9438 
2025-02-27 11:02:36.310820: val_loss -0.6696 
2025-02-27 11:02:36.314515: Pseudo dice [np.float32(0.6695), np.float32(0.8874)] 
2025-02-27 11:02:36.318095: Epoch time: 74.02 s 
2025-02-27 11:02:37.035507:  
2025-02-27 11:02:37.041079: Epoch 58 
2025-02-27 11:02:37.043625: Current learning rate: 0.00458 
2025-02-27 11:03:50.822045: train_loss -0.9313 
2025-02-27 11:03:50.828084: val_loss -0.6773 
2025-02-27 11:03:50.831800: Pseudo dice [np.float32(0.68), np.float32(0.8874)] 
2025-02-27 11:03:50.834310: Epoch time: 73.79 s 
2025-02-27 11:03:51.405256:  
2025-02-27 11:03:51.410199: Epoch 59 
2025-02-27 11:03:51.413713: Current learning rate: 0.00448 
2025-02-27 11:05:05.202846: train_loss -0.9419 
2025-02-27 11:05:05.211432: val_loss -0.6712 
2025-02-27 11:05:05.216129: Pseudo dice [np.float32(0.6752), np.float32(0.8886)] 
2025-02-27 11:05:05.219168: Epoch time: 73.8 s 
2025-02-27 11:05:05.792680:  
2025-02-27 11:05:05.798256: Epoch 60 
2025-02-27 11:05:05.801306: Current learning rate: 0.00438 
2025-02-27 11:06:19.649677: train_loss -0.9431 
2025-02-27 11:06:19.655706: val_loss -0.6729 
2025-02-27 11:06:19.659209: Pseudo dice [np.float32(0.6782), np.float32(0.8876)] 
2025-02-27 11:06:19.662223: Epoch time: 73.86 s 
2025-02-27 11:06:20.229960:  
2025-02-27 11:06:20.234980: Epoch 61 
2025-02-27 11:06:20.238499: Current learning rate: 0.00429 
2025-02-27 11:07:34.243850: train_loss -0.9404 
2025-02-27 11:07:34.249992: val_loss -0.671 
2025-02-27 11:07:34.253090: Pseudo dice [np.float32(0.677), np.float32(0.8854)] 
2025-02-27 11:07:34.256247: Epoch time: 74.02 s 
2025-02-27 11:07:34.836507:  
2025-02-27 11:07:34.842065: Epoch 62 
2025-02-27 11:07:34.845203: Current learning rate: 0.00419 
2025-02-27 11:08:48.828445: train_loss -0.9382 
2025-02-27 11:08:48.834605: val_loss -0.668 
2025-02-27 11:08:48.837160: Pseudo dice [np.float32(0.6736), np.float32(0.8865)] 
2025-02-27 11:08:48.841233: Epoch time: 73.99 s 
2025-02-27 11:08:49.411577:  
2025-02-27 11:08:49.416673: Epoch 63 
2025-02-27 11:08:49.420242: Current learning rate: 0.00409 
2025-02-27 11:10:03.442903: train_loss -0.9383 
2025-02-27 11:10:03.449921: val_loss -0.6774 
2025-02-27 11:10:03.452932: Pseudo dice [np.float32(0.679), np.float32(0.8888)] 
2025-02-27 11:10:03.456470: Epoch time: 74.03 s 
2025-02-27 11:10:04.023289:  
2025-02-27 11:10:04.029367: Epoch 64 
2025-02-27 11:10:04.032928: Current learning rate: 0.00399 
2025-02-27 11:11:18.114210: train_loss -0.9447 
2025-02-27 11:11:18.120727: val_loss -0.664 
2025-02-27 11:11:18.124238: Pseudo dice [np.float32(0.6689), np.float32(0.8877)] 
2025-02-27 11:11:18.127813: Epoch time: 74.09 s 
2025-02-27 11:11:18.703292:  
2025-02-27 11:11:18.709347: Epoch 65 
2025-02-27 11:11:18.712859: Current learning rate: 0.00389 
2025-02-27 11:12:32.800320: train_loss -0.934 
2025-02-27 11:12:32.807843: val_loss -0.6717 
2025-02-27 11:12:32.810350: Pseudo dice [np.float32(0.6789), np.float32(0.8888)] 
2025-02-27 11:12:32.816367: Epoch time: 74.1 s 
2025-02-27 11:12:33.547283:  
2025-02-27 11:12:33.552848: Epoch 66 
2025-02-27 11:12:33.556402: Current learning rate: 0.00379 
2025-02-27 11:13:47.325285: train_loss -0.9347 
2025-02-27 11:13:47.330861: val_loss -0.6655 
2025-02-27 11:13:47.334465: Pseudo dice [np.float32(0.6736), np.float32(0.8855)] 
2025-02-27 11:13:47.336974: Epoch time: 73.78 s 
2025-02-27 11:13:47.901602:  
2025-02-27 11:13:47.907148: Epoch 67 
2025-02-27 11:13:47.910706: Current learning rate: 0.00369 
2025-02-27 11:15:01.584487: train_loss -0.9408 
2025-02-27 11:15:01.589500: val_loss -0.6681 
2025-02-27 11:15:01.593010: Pseudo dice [np.float32(0.6761), np.float32(0.8873)] 
2025-02-27 11:15:01.595520: Epoch time: 73.68 s 
2025-02-27 11:15:02.165208:  
2025-02-27 11:15:02.170221: Epoch 68 
2025-02-27 11:15:02.173733: Current learning rate: 0.00359 
2025-02-27 11:16:15.919835: train_loss -0.9424 
2025-02-27 11:16:15.925933: val_loss -0.6692 
2025-02-27 11:16:15.928971: Pseudo dice [np.float32(0.6724), np.float32(0.8891)] 
2025-02-27 11:16:15.932016: Epoch time: 73.76 s 
2025-02-27 11:16:16.503902:  
2025-02-27 11:16:16.508937: Epoch 69 
2025-02-27 11:16:16.511163: Current learning rate: 0.00349 
2025-02-27 11:17:30.218250: train_loss -0.9417 
2025-02-27 11:17:30.224290: val_loss -0.6669 
2025-02-27 11:17:30.227323: Pseudo dice [np.float32(0.6765), np.float32(0.889)] 
2025-02-27 11:17:30.230842: Epoch time: 73.72 s 
2025-02-27 11:17:30.801785:  
2025-02-27 11:17:30.807307: Epoch 70 
2025-02-27 11:17:30.809817: Current learning rate: 0.00338 
2025-02-27 11:18:44.596514: train_loss -0.9413 
2025-02-27 11:18:44.600532: val_loss -0.6602 
2025-02-27 11:18:44.604049: Pseudo dice [np.float32(0.6697), np.float32(0.8865)] 
2025-02-27 11:18:44.607562: Epoch time: 73.8 s 
2025-02-27 11:18:45.178334:  
2025-02-27 11:18:45.183917: Epoch 71 
2025-02-27 11:18:45.187488: Current learning rate: 0.00328 
2025-02-27 11:19:58.930453: train_loss -0.9443 
2025-02-27 11:19:58.936471: val_loss -0.6759 
2025-02-27 11:19:58.940480: Pseudo dice [np.float32(0.6804), np.float32(0.8898)] 
2025-02-27 11:19:58.943993: Epoch time: 73.75 s 
2025-02-27 11:19:59.532183:  
2025-02-27 11:19:59.537198: Epoch 72 
2025-02-27 11:19:59.540210: Current learning rate: 0.00318 
2025-02-27 11:21:13.333693: train_loss -0.9366 
2025-02-27 11:21:13.341326: val_loss -0.6628 
2025-02-27 11:21:13.344368: Pseudo dice [np.float32(0.665), np.float32(0.8884)] 
2025-02-27 11:21:13.346879: Epoch time: 73.8 s 
2025-02-27 11:21:14.091975:  
2025-02-27 11:21:14.095003: Epoch 73 
2025-02-27 11:21:14.099605: Current learning rate: 0.00308 
2025-02-27 11:22:31.089585: train_loss -0.9386 
2025-02-27 11:22:31.096668: val_loss -0.6713 
2025-02-27 11:22:31.099720: Pseudo dice [np.float32(0.6778), np.float32(0.8894)] 
2025-02-27 11:22:31.102397: Epoch time: 77.0 s 
2025-02-27 11:22:31.678660:  
2025-02-27 11:22:31.684827: Epoch 74 
2025-02-27 11:22:31.687910: Current learning rate: 0.00297 
2025-02-27 11:23:45.418223: train_loss -0.9355 
2025-02-27 11:23:45.424349: val_loss -0.6659 
2025-02-27 11:23:45.428361: Pseudo dice [np.float32(0.6739), np.float32(0.8882)] 
2025-02-27 11:23:45.430867: Epoch time: 73.74 s 
2025-02-27 11:23:46.013474:  
2025-02-27 11:23:46.019052: Epoch 75 
2025-02-27 11:23:46.022100: Current learning rate: 0.00287 
2025-02-27 11:24:59.796760: train_loss -0.936 
2025-02-27 11:24:59.802777: val_loss -0.6655 
2025-02-27 11:24:59.806286: Pseudo dice [np.float32(0.6772), np.float32(0.8877)] 
2025-02-27 11:24:59.810304: Epoch time: 73.78 s 
2025-02-27 11:25:00.385970:  
2025-02-27 11:25:00.391548: Epoch 76 
2025-02-27 11:25:00.394113: Current learning rate: 0.00277 
2025-02-27 11:26:14.130773: train_loss -0.9435 
2025-02-27 11:26:14.136886: val_loss -0.6605 
2025-02-27 11:26:14.139933: Pseudo dice [np.float32(0.6701), np.float32(0.8883)] 
2025-02-27 11:26:14.142977: Epoch time: 73.75 s 
2025-02-27 11:26:14.719814:  
2025-02-27 11:26:14.724848: Epoch 77 
2025-02-27 11:26:14.727767: Current learning rate: 0.00266 
2025-02-27 11:27:28.613229: train_loss -0.9395 
2025-02-27 11:27:28.619842: val_loss -0.6697 
2025-02-27 11:27:28.623384: Pseudo dice [np.float32(0.6804), np.float32(0.8873)] 
2025-02-27 11:27:28.626133: Epoch time: 73.89 s 
2025-02-27 11:27:29.233231:  
2025-02-27 11:27:29.239379: Epoch 78 
2025-02-27 11:27:29.242455: Current learning rate: 0.00256 
2025-02-27 11:28:43.175179: train_loss -0.938 
2025-02-27 11:28:43.182707: val_loss -0.6684 
2025-02-27 11:28:43.186219: Pseudo dice [np.float32(0.6833), np.float32(0.8866)] 
2025-02-27 11:28:43.190289: Epoch time: 73.94 s 
2025-02-27 11:28:43.783789:  
2025-02-27 11:28:43.788809: Epoch 79 
2025-02-27 11:28:43.792326: Current learning rate: 0.00245 
2025-02-27 11:29:58.207473: train_loss -0.9366 
2025-02-27 11:29:58.213991: val_loss -0.6653 
2025-02-27 11:29:58.217504: Pseudo dice [np.float32(0.6768), np.float32(0.8889)] 
2025-02-27 11:29:58.220009: Epoch time: 74.43 s 
2025-02-27 11:29:58.805814:  
2025-02-27 11:29:58.811902: Epoch 80 
2025-02-27 11:29:58.814944: Current learning rate: 0.00235 
2025-02-27 11:31:12.860605: train_loss -0.9415 
2025-02-27 11:31:12.866123: val_loss -0.6706 
2025-02-27 11:31:12.869635: Pseudo dice [np.float32(0.6831), np.float32(0.8888)] 
2025-02-27 11:31:12.873146: Epoch time: 74.05 s 
2025-02-27 11:31:12.876159: Yayy! New best EMA pseudo Dice: 0.7822999954223633 
2025-02-27 11:31:13.706121:  
2025-02-27 11:31:13.710135: Epoch 81 
2025-02-27 11:31:13.712643: Current learning rate: 0.00224 
2025-02-27 11:32:27.500065: train_loss -0.9393 
2025-02-27 11:32:27.504591: val_loss -0.6659 
2025-02-27 11:32:27.508107: Pseudo dice [np.float32(0.6849), np.float32(0.8854)] 
2025-02-27 11:32:27.511492: Epoch time: 73.79 s 
2025-02-27 11:32:27.513998: Yayy! New best EMA pseudo Dice: 0.7825999855995178 
2025-02-27 11:32:28.331982:  
2025-02-27 11:32:28.337525: Epoch 82 
2025-02-27 11:32:28.341092: Current learning rate: 0.00214 
2025-02-27 11:33:42.044478: train_loss -0.9419 
2025-02-27 11:33:42.050617: val_loss -0.6658 
2025-02-27 11:33:42.053661: Pseudo dice [np.float32(0.6749), np.float32(0.8874)] 
2025-02-27 11:33:42.056185: Epoch time: 73.71 s 
2025-02-27 11:33:42.602443:  
2025-02-27 11:33:42.607957: Epoch 83 
2025-02-27 11:33:42.610462: Current learning rate: 0.00203 
2025-02-27 11:34:56.353924: train_loss -0.9468 
2025-02-27 11:34:56.360483: val_loss -0.6621 
2025-02-27 11:34:56.363518: Pseudo dice [np.float32(0.6789), np.float32(0.8874)] 
2025-02-27 11:34:56.366592: Epoch time: 73.75 s 
2025-02-27 11:34:56.918097:  
2025-02-27 11:34:56.923110: Epoch 84 
2025-02-27 11:34:56.926624: Current learning rate: 0.00192 
2025-02-27 11:36:10.659010: train_loss -0.9364 
2025-02-27 11:36:10.663551: val_loss -0.6671 
2025-02-27 11:36:10.667063: Pseudo dice [np.float32(0.6817), np.float32(0.888)] 
2025-02-27 11:36:10.669572: Epoch time: 73.74 s 
2025-02-27 11:36:10.673585: Yayy! New best EMA pseudo Dice: 0.782800018787384 
2025-02-27 11:36:11.466961:  
2025-02-27 11:36:11.472018: Epoch 85 
2025-02-27 11:36:11.475585: Current learning rate: 0.00181 
2025-02-27 11:37:25.207038: train_loss -0.9457 
2025-02-27 11:37:25.213622: val_loss -0.6597 
2025-02-27 11:37:25.217199: Pseudo dice [np.float32(0.6731), np.float32(0.8886)] 
2025-02-27 11:37:25.219318: Epoch time: 73.74 s 
2025-02-27 11:37:25.774004:  
2025-02-27 11:37:25.779112: Epoch 86 
2025-02-27 11:37:25.782627: Current learning rate: 0.0017 
2025-02-27 11:38:39.523176: train_loss -0.9435 
2025-02-27 11:38:39.528285: val_loss -0.664 
2025-02-27 11:38:39.532430: Pseudo dice [np.float32(0.6742), np.float32(0.89)] 
2025-02-27 11:38:39.534971: Epoch time: 73.75 s 
2025-02-27 11:38:40.074171:  
2025-02-27 11:38:40.079199: Epoch 87 
2025-02-27 11:38:40.082251: Current learning rate: 0.00159 
2025-02-27 11:39:53.862732: train_loss -0.9477 
2025-02-27 11:39:53.868309: val_loss -0.6533 
2025-02-27 11:39:53.871820: Pseudo dice [np.float32(0.6676), np.float32(0.8881)] 
2025-02-27 11:39:53.874327: Epoch time: 73.79 s 
2025-02-27 11:39:54.579953:  
2025-02-27 11:39:54.584981: Epoch 88 
2025-02-27 11:39:54.587291: Current learning rate: 0.00148 
2025-02-27 11:41:08.377329: train_loss -0.941 
2025-02-27 11:41:08.383881: val_loss -0.6617 
2025-02-27 11:41:08.387392: Pseudo dice [np.float32(0.6794), np.float32(0.8865)] 
2025-02-27 11:41:08.389898: Epoch time: 73.8 s 
2025-02-27 11:41:08.930028:  
2025-02-27 11:41:08.935544: Epoch 89 
2025-02-27 11:41:08.939055: Current learning rate: 0.00137 
2025-02-27 11:42:22.680264: train_loss -0.9483 
2025-02-27 11:42:22.686784: val_loss -0.6635 
2025-02-27 11:42:22.689290: Pseudo dice [np.float32(0.6805), np.float32(0.8865)] 
2025-02-27 11:42:22.692799: Epoch time: 73.75 s 
2025-02-27 11:42:23.230128:  
2025-02-27 11:42:23.235183: Epoch 90 
2025-02-27 11:42:23.239274: Current learning rate: 0.00126 
2025-02-27 11:43:36.979572: train_loss -0.9418 
2025-02-27 11:43:36.986085: val_loss -0.6521 
2025-02-27 11:43:36.989598: Pseudo dice [np.float32(0.6685), np.float32(0.8893)] 
2025-02-27 11:43:36.992104: Epoch time: 73.75 s 
2025-02-27 11:43:37.534900:  
2025-02-27 11:43:37.540958: Epoch 91 
2025-02-27 11:43:37.544015: Current learning rate: 0.00115 
2025-02-27 11:44:51.285199: train_loss -0.9434 
2025-02-27 11:44:51.291773: val_loss -0.6636 
2025-02-27 11:44:51.295326: Pseudo dice [np.float32(0.6743), np.float32(0.8904)] 
2025-02-27 11:44:51.298837: Epoch time: 73.75 s 
2025-02-27 11:44:51.847403:  
2025-02-27 11:44:51.852414: Epoch 92 
2025-02-27 11:44:51.855923: Current learning rate: 0.00103 
2025-02-27 11:46:05.694141: train_loss -0.9467 
2025-02-27 11:46:05.700258: val_loss -0.6665 
2025-02-27 11:46:05.702765: Pseudo dice [np.float32(0.6784), np.float32(0.8888)] 
2025-02-27 11:46:05.708776: Epoch time: 73.85 s 
2025-02-27 11:46:06.272939:  
2025-02-27 11:46:06.278457: Epoch 93 
2025-02-27 11:46:06.281975: Current learning rate: 0.00091 
2025-02-27 11:47:20.077365: train_loss -0.9327 
2025-02-27 11:47:20.082381: val_loss -0.6633 
2025-02-27 11:47:20.085890: Pseudo dice [np.float32(0.6812), np.float32(0.8896)] 
2025-02-27 11:47:20.089396: Epoch time: 73.81 s 
2025-02-27 11:47:20.638975:  
2025-02-27 11:47:20.643987: Epoch 94 
2025-02-27 11:47:20.647497: Current learning rate: 0.00079 
2025-02-27 11:48:34.439011: train_loss -0.9468 
2025-02-27 11:48:34.444053: val_loss -0.6607 
2025-02-27 11:48:34.448062: Pseudo dice [np.float32(0.6781), np.float32(0.8882)] 
2025-02-27 11:48:34.450571: Epoch time: 73.8 s 
2025-02-27 11:48:35.006214:  
2025-02-27 11:48:35.012333: Epoch 95 
2025-02-27 11:48:35.015368: Current learning rate: 0.00067 
2025-02-27 11:49:48.823752: train_loss -0.9476 
2025-02-27 11:49:48.829399: val_loss -0.6624 
2025-02-27 11:49:48.834413: Pseudo dice [np.float32(0.6772), np.float32(0.8879)] 
2025-02-27 11:49:48.837920: Epoch time: 73.82 s 
2025-02-27 11:49:49.545238:  
2025-02-27 11:49:49.550272: Epoch 96 
2025-02-27 11:49:49.554402: Current learning rate: 0.00055 
2025-02-27 11:51:03.308120: train_loss -0.9416 
2025-02-27 11:51:03.314668: val_loss -0.6605 
2025-02-27 11:51:03.317528: Pseudo dice [np.float32(0.6835), np.float32(0.8878)] 
2025-02-27 11:51:03.321044: Epoch time: 73.76 s 
2025-02-27 11:51:03.324190: Yayy! New best EMA pseudo Dice: 0.7828999757766724 
2025-02-27 11:51:04.126058:  
2025-02-27 11:51:04.131584: Epoch 97 
2025-02-27 11:51:04.134610: Current learning rate: 0.00043 
2025-02-27 11:52:17.902337: train_loss -0.9442 
2025-02-27 11:52:17.908383: val_loss -0.6635 
2025-02-27 11:52:17.912393: Pseudo dice [np.float32(0.6851), np.float32(0.8866)] 
2025-02-27 11:52:17.915901: Epoch time: 73.78 s 
2025-02-27 11:52:17.918411: Yayy! New best EMA pseudo Dice: 0.7832000255584717 
2025-02-27 11:52:18.717119:  
2025-02-27 11:52:18.722676: Epoch 98 
2025-02-27 11:52:18.725710: Current learning rate: 0.0003 
2025-02-27 11:53:32.493356: train_loss -0.9413 
2025-02-27 11:53:32.501465: val_loss -0.6596 
2025-02-27 11:53:32.505046: Pseudo dice [np.float32(0.6765), np.float32(0.8873)] 
2025-02-27 11:53:32.507070: Epoch time: 73.78 s 
2025-02-27 11:53:33.144972:  
2025-02-27 11:53:33.151045: Epoch 99 
2025-02-27 11:53:33.154554: Current learning rate: 0.00016 
2025-02-27 11:54:46.922528: train_loss -0.9505 
2025-02-27 11:54:46.927722: val_loss -0.6631 
2025-02-27 11:54:46.931831: Pseudo dice [np.float32(0.6834), np.float32(0.8883)] 
2025-02-27 11:54:46.935396: Epoch time: 73.78 s 
2025-02-27 11:54:46.938033: Yayy! New best EMA pseudo Dice: 0.78329998254776 
2025-02-27 11:54:48.022265: Training done. 
2025-02-27 11:54:48.048569: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset005_Prostate\splits_final.json 
2025-02-27 11:54:48.054569: The split file contains 5 splits. 
2025-02-27 11:54:48.059569: Desired fold for training: 0 
2025-02-27 11:54:48.063570: This split has 25 training and 7 validation cases. 
2025-02-27 11:54:48.067574: predicting prostate_00 
2025-02-27 11:54:48.074569: prostate_00, shape torch.Size([2, 17, 307, 307]), rank 0 
2025-02-27 11:54:49.071128: predicting prostate_04 
2025-02-27 11:54:49.079131: prostate_04, shape torch.Size([2, 17, 306, 307]), rank 0 
2025-02-27 11:54:49.424820: predicting prostate_14 
2025-02-27 11:54:49.432826: prostate_14, shape torch.Size([2, 20, 320, 319]), rank 0 
2025-02-27 11:54:49.779454: predicting prostate_20 
2025-02-27 11:54:49.788455: prostate_20, shape torch.Size([2, 20, 320, 320]), rank 0 
2025-02-27 11:54:50.134303: predicting prostate_25 
2025-02-27 11:54:50.142305: prostate_25, shape torch.Size([2, 19, 320, 319]), rank 0 
2025-02-27 11:54:50.487866: predicting prostate_31 
2025-02-27 11:54:50.497869: prostate_31, shape torch.Size([2, 20, 320, 319]), rank 0 
2025-02-27 11:54:50.841887: predicting prostate_42 
2025-02-27 11:54:50.849920: prostate_42, shape torch.Size([2, 22, 320, 319]), rank 0 
2025-02-27 11:54:58.450139: Validation complete 
2025-02-27 11:54:58.456136: Mean Validation Dice:  0.7460155646330345 
