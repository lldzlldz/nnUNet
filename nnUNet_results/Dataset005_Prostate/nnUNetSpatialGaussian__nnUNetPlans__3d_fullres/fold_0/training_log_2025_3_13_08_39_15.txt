
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-13 08:39:15.680612: do_dummy_2d_data_aug: True 
2025-03-13 08:39:15.682909: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset005_Prostate\splits_final.json 
2025-03-13 08:39:15.689913: The split file contains 5 splits. 
2025-03-13 08:39:15.691912: Desired fold for training: 0 
2025-03-13 08:39:15.694912: This split has 25 training and 7 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [20, 320, 256], 'median_image_size_in_voxels': [20.0, 320.0, 319.0], 'spacing': [3.5999999046325684, 0.625, 0.625], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset005_Prostate', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.5999999046325684, 0.625, 0.625], 'original_median_shape_after_transp': [20, 320, 320], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1326.0, 'mean': 350.18780517578125, 'median': 327.0, 'min': 0.0, 'percentile_00_5': 83.0, 'percentile_99_5': 822.0, 'std': 139.9563751220703}, '1': {'max': 3698.0, 'mean': 1351.1083984375, 'median': 1364.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 2563.0, 'std': 376.4326477050781}}} 
 
2025-03-13 08:39:23.540272: unpacking dataset... 
2025-03-13 08:39:24.032693: unpacking done... 
2025-03-13 08:39:26.996606:  
2025-03-13 08:39:27.001621: Epoch 0 
2025-03-13 08:39:27.005635: Current learning rate: 0.01 
2025-03-13 08:40:08.044719: train_loss -0.1701 
2025-03-13 08:40:08.050785: val_loss -0.426 
2025-03-13 08:40:08.053808: Pseudo dice [np.float32(0.3214), np.float32(0.7005)] 
2025-03-13 08:40:08.057413: Epoch time: 41.05 s 
2025-03-13 08:40:08.060762: Yayy! New best EMA pseudo Dice: 0.5109999775886536 
2025-03-13 08:40:08.717598:  
2025-03-13 08:40:08.723146: Epoch 1 
2025-03-13 08:40:08.726688: Current learning rate: 0.00991 
2025-03-13 08:40:45.608555: train_loss -0.4723 
2025-03-13 08:40:45.614568: val_loss -0.5195 
2025-03-13 08:40:45.617577: Pseudo dice [np.float32(0.4061), np.float32(0.7525)] 
2025-03-13 08:40:45.621085: Epoch time: 36.89 s 
2025-03-13 08:40:45.624593: Yayy! New best EMA pseudo Dice: 0.517799973487854 
2025-03-13 08:40:46.361865:  
2025-03-13 08:40:46.366882: Epoch 2 
2025-03-13 08:40:46.370399: Current learning rate: 0.00982 
2025-03-13 08:41:23.235380: train_loss -0.5405 
2025-03-13 08:41:23.241895: val_loss -0.6265 
2025-03-13 08:41:23.244406: Pseudo dice [np.float32(0.579), np.float32(0.8293)] 
2025-03-13 08:41:23.247916: Epoch time: 36.87 s 
2025-03-13 08:41:23.251936: Yayy! New best EMA pseudo Dice: 0.5364000201225281 
2025-03-13 08:41:24.020082:  
2025-03-13 08:41:24.026173: Epoch 3 
2025-03-13 08:41:24.030260: Current learning rate: 0.00973 
2025-03-13 08:42:00.896765: train_loss -0.6189 
2025-03-13 08:42:00.903278: val_loss -0.5567 
2025-03-13 08:42:00.906789: Pseudo dice [np.float32(0.4823), np.float32(0.7987)] 
2025-03-13 08:42:00.910295: Epoch time: 36.88 s 
2025-03-13 08:42:00.913306: Yayy! New best EMA pseudo Dice: 0.5468000173568726 
2025-03-13 08:42:01.666026:  
2025-03-13 08:42:01.672616: Epoch 4 
2025-03-13 08:42:01.675651: Current learning rate: 0.00964 
2025-03-13 08:42:38.523904: train_loss -0.6509 
2025-03-13 08:42:38.531243: val_loss -0.6486 
2025-03-13 08:42:38.535269: Pseudo dice [np.float32(0.5937), np.float32(0.8476)] 
2025-03-13 08:42:38.539795: Epoch time: 36.86 s 
2025-03-13 08:42:38.542315: Yayy! New best EMA pseudo Dice: 0.5641999840736389 
2025-03-13 08:42:39.414102:  
2025-03-13 08:42:39.420675: Epoch 5 
2025-03-13 08:42:39.423215: Current learning rate: 0.00955 
2025-03-13 08:43:16.264167: train_loss -0.6739 
2025-03-13 08:43:16.269730: val_loss -0.6379 
2025-03-13 08:43:16.273756: Pseudo dice [np.float32(0.5708), np.float32(0.8593)] 
2025-03-13 08:43:16.276770: Epoch time: 36.85 s 
2025-03-13 08:43:16.280280: Yayy! New best EMA pseudo Dice: 0.5792999863624573 
2025-03-13 08:43:17.020965:  
2025-03-13 08:43:17.025983: Epoch 6 
2025-03-13 08:43:17.029499: Current learning rate: 0.00946 
2025-03-13 08:43:53.907240: train_loss -0.691 
2025-03-13 08:43:53.913264: val_loss -0.6442 
2025-03-13 08:43:53.916770: Pseudo dice [np.float32(0.5566), np.float32(0.8663)] 
2025-03-13 08:43:53.919785: Epoch time: 36.89 s 
2025-03-13 08:43:53.923295: Yayy! New best EMA pseudo Dice: 0.5924999713897705 
2025-03-13 08:43:54.724351:  
2025-03-13 08:43:54.729900: Epoch 7 
2025-03-13 08:43:54.733239: Current learning rate: 0.00937 
2025-03-13 08:44:31.586196: train_loss -0.7246 
2025-03-13 08:44:31.591806: val_loss -0.6324 
2025-03-13 08:44:31.594332: Pseudo dice [np.float32(0.575), np.float32(0.8427)] 
2025-03-13 08:44:31.598372: Epoch time: 36.86 s 
2025-03-13 08:44:31.601923: Yayy! New best EMA pseudo Dice: 0.6040999889373779 
2025-03-13 08:44:32.365184:  
2025-03-13 08:44:32.370209: Epoch 8 
2025-03-13 08:44:32.373770: Current learning rate: 0.00928 
2025-03-13 08:45:09.244746: train_loss -0.7232 
2025-03-13 08:45:09.250769: val_loss -0.6481 
2025-03-13 08:45:09.253275: Pseudo dice [np.float32(0.5649), np.float32(0.8712)] 
2025-03-13 08:45:09.257284: Epoch time: 36.88 s 
2025-03-13 08:45:09.260798: Yayy! New best EMA pseudo Dice: 0.6154999732971191 
2025-03-13 08:45:10.028307:  
2025-03-13 08:45:10.033855: Epoch 9 
2025-03-13 08:45:10.037008: Current learning rate: 0.00919 
2025-03-13 08:45:46.941743: train_loss -0.7417 
2025-03-13 08:45:46.947756: val_loss -0.6527 
2025-03-13 08:45:46.951269: Pseudo dice [np.float32(0.5774), np.float32(0.8594)] 
2025-03-13 08:45:46.954283: Epoch time: 36.91 s 
2025-03-13 08:45:46.957800: Yayy! New best EMA pseudo Dice: 0.6258000135421753 
2025-03-13 08:45:47.700135:  
2025-03-13 08:45:47.705670: Epoch 10 
2025-03-13 08:45:47.708678: Current learning rate: 0.0091 
2025-03-13 08:46:24.582483: train_loss -0.7585 
2025-03-13 08:46:24.588592: val_loss -0.6848 
2025-03-13 08:46:24.592130: Pseudo dice [np.float32(0.6074), np.float32(0.882)] 
2025-03-13 08:46:24.594729: Epoch time: 36.88 s 
2025-03-13 08:46:24.598777: Yayy! New best EMA pseudo Dice: 0.6377000212669373 
2025-03-13 08:46:25.350959:  
2025-03-13 08:46:25.358059: Epoch 11 
2025-03-13 08:46:25.361117: Current learning rate: 0.009 
2025-03-13 08:47:02.226914: train_loss -0.7809 
2025-03-13 08:47:02.233433: val_loss -0.689 
2025-03-13 08:47:02.236944: Pseudo dice [np.float32(0.6201), np.float32(0.8727)] 
2025-03-13 08:47:02.240452: Epoch time: 36.88 s 
2025-03-13 08:47:02.243459: Yayy! New best EMA pseudo Dice: 0.6485999822616577 
2025-03-13 08:47:02.982949:  
2025-03-13 08:47:02.988460: Epoch 12 
2025-03-13 08:47:02.991977: Current learning rate: 0.00891 
2025-03-13 08:47:39.861602: train_loss -0.7719 
2025-03-13 08:47:39.868172: val_loss -0.6785 
2025-03-13 08:47:39.870240: Pseudo dice [np.float32(0.6171), np.float32(0.87)] 
2025-03-13 08:47:39.874800: Epoch time: 36.88 s 
2025-03-13 08:47:39.878309: Yayy! New best EMA pseudo Dice: 0.6581000089645386 
2025-03-13 08:47:40.765869:  
2025-03-13 08:47:40.771932: Epoch 13 
2025-03-13 08:47:40.775012: Current learning rate: 0.00882 
2025-03-13 08:48:17.630561: train_loss -0.78 
2025-03-13 08:48:17.636635: val_loss -0.7146 
2025-03-13 08:48:17.639643: Pseudo dice [np.float32(0.6649), np.float32(0.8798)] 
2025-03-13 08:48:17.643162: Epoch time: 36.87 s 
2025-03-13 08:48:17.646672: Yayy! New best EMA pseudo Dice: 0.6694999933242798 
2025-03-13 08:48:18.407147:  
2025-03-13 08:48:18.412659: Epoch 14 
2025-03-13 08:48:18.416166: Current learning rate: 0.00873 
2025-03-13 08:48:55.293556: train_loss -0.7868 
2025-03-13 08:48:55.299072: val_loss -0.6845 
2025-03-13 08:48:55.302580: Pseudo dice [np.float32(0.6219), np.float32(0.8756)] 
2025-03-13 08:48:55.306086: Epoch time: 36.89 s 
2025-03-13 08:48:55.309094: Yayy! New best EMA pseudo Dice: 0.6773999929428101 
2025-03-13 08:48:56.077615:  
2025-03-13 08:48:56.083153: Epoch 15 
2025-03-13 08:48:56.086706: Current learning rate: 0.00864 
2025-03-13 08:49:32.957019: train_loss -0.7849 
2025-03-13 08:49:32.962058: val_loss -0.7008 
2025-03-13 08:49:32.966147: Pseudo dice [np.float32(0.636), np.float32(0.8756)] 
2025-03-13 08:49:32.969721: Epoch time: 36.88 s 
2025-03-13 08:49:32.972240: Yayy! New best EMA pseudo Dice: 0.6852999925613403 
2025-03-13 08:49:33.731523:  
2025-03-13 08:49:33.736708: Epoch 16 
2025-03-13 08:49:33.740218: Current learning rate: 0.00855 
2025-03-13 08:50:10.607298: train_loss -0.8005 
2025-03-13 08:50:10.613348: val_loss -0.7153 
2025-03-13 08:50:10.616852: Pseudo dice [np.float32(0.6553), np.float32(0.884)] 
2025-03-13 08:50:10.619860: Epoch time: 36.88 s 
2025-03-13 08:50:10.623369: Yayy! New best EMA pseudo Dice: 0.6937000155448914 
2025-03-13 08:50:11.386176:  
2025-03-13 08:50:11.392689: Epoch 17 
2025-03-13 08:50:11.396198: Current learning rate: 0.00846 
2025-03-13 08:50:48.270521: train_loss -0.8133 
2025-03-13 08:50:48.276533: val_loss -0.6957 
2025-03-13 08:50:48.280546: Pseudo dice [np.float32(0.6284), np.float32(0.8813)] 
2025-03-13 08:50:48.283050: Epoch time: 36.89 s 
2025-03-13 08:50:48.287066: Yayy! New best EMA pseudo Dice: 0.6998000144958496 
2025-03-13 08:50:49.044449:  
2025-03-13 08:50:49.049966: Epoch 18 
2025-03-13 08:50:49.053475: Current learning rate: 0.00836 
2025-03-13 08:51:25.929734: train_loss -0.8076 
2025-03-13 08:51:25.936333: val_loss -0.6816 
2025-03-13 08:51:25.939397: Pseudo dice [np.float32(0.6234), np.float32(0.8657)] 
2025-03-13 08:51:25.942441: Epoch time: 36.89 s 
2025-03-13 08:51:25.945976: Yayy! New best EMA pseudo Dice: 0.7042999863624573 
2025-03-13 08:51:26.720361:  
2025-03-13 08:51:26.726971: Epoch 19 
2025-03-13 08:51:26.731981: Current learning rate: 0.00827 
2025-03-13 08:52:03.596635: train_loss -0.8212 
2025-03-13 08:52:03.602255: val_loss -0.706 
2025-03-13 08:52:03.605814: Pseudo dice [np.float32(0.6543), np.float32(0.8782)] 
2025-03-13 08:52:03.608840: Epoch time: 36.88 s 
2025-03-13 08:52:03.612346: Yayy! New best EMA pseudo Dice: 0.7105000019073486 
2025-03-13 08:52:04.523501:  
2025-03-13 08:52:04.529524: Epoch 20 
2025-03-13 08:52:04.532037: Current learning rate: 0.00818 
2025-03-13 08:52:41.390884: train_loss -0.8056 
2025-03-13 08:52:41.397913: val_loss -0.6837 
2025-03-13 08:52:41.401098: Pseudo dice [np.float32(0.6113), np.float32(0.8729)] 
2025-03-13 08:52:41.405107: Epoch time: 36.87 s 
2025-03-13 08:52:41.407618: Yayy! New best EMA pseudo Dice: 0.7135999798774719 
2025-03-13 08:52:42.187262:  
2025-03-13 08:52:42.193610: Epoch 21 
2025-03-13 08:52:42.197119: Current learning rate: 0.00809 
2025-03-13 08:53:19.054663: train_loss -0.8101 
2025-03-13 08:53:19.060224: val_loss -0.6854 
2025-03-13 08:53:19.064246: Pseudo dice [np.float32(0.619), np.float32(0.8819)] 
2025-03-13 08:53:19.067767: Epoch time: 36.87 s 
2025-03-13 08:53:19.069961: Yayy! New best EMA pseudo Dice: 0.7172999978065491 
2025-03-13 08:53:19.807727:  
2025-03-13 08:53:19.813282: Epoch 22 
2025-03-13 08:53:19.815816: Current learning rate: 0.008 
2025-03-13 08:53:56.676218: train_loss -0.8285 
2025-03-13 08:53:56.683263: val_loss -0.7048 
2025-03-13 08:53:56.687278: Pseudo dice [np.float32(0.6494), np.float32(0.8835)] 
2025-03-13 08:53:56.689784: Epoch time: 36.87 s 
2025-03-13 08:53:56.693290: Yayy! New best EMA pseudo Dice: 0.7221999764442444 
2025-03-13 08:53:57.449163:  
2025-03-13 08:53:57.454772: Epoch 23 
2025-03-13 08:53:57.458811: Current learning rate: 0.0079 
2025-03-13 08:54:34.329551: train_loss -0.826 
2025-03-13 08:54:34.336161: val_loss -0.6837 
2025-03-13 08:54:34.339231: Pseudo dice [np.float32(0.6255), np.float32(0.8759)] 
2025-03-13 08:54:34.343275: Epoch time: 36.88 s 
2025-03-13 08:54:34.346306: Yayy! New best EMA pseudo Dice: 0.7250999808311462 
2025-03-13 08:54:35.092562:  
2025-03-13 08:54:35.098689: Epoch 24 
2025-03-13 08:54:35.101767: Current learning rate: 0.00781 
2025-03-13 08:55:11.957545: train_loss -0.8149 
2025-03-13 08:55:11.963570: val_loss -0.7232 
2025-03-13 08:55:11.967087: Pseudo dice [np.float32(0.6623), np.float32(0.8928)] 
2025-03-13 08:55:11.970098: Epoch time: 36.86 s 
2025-03-13 08:55:11.973615: Yayy! New best EMA pseudo Dice: 0.7303000092506409 
2025-03-13 08:55:12.720036:  
2025-03-13 08:55:12.725045: Epoch 25 
2025-03-13 08:55:12.728561: Current learning rate: 0.00772 
2025-03-13 08:55:49.626732: train_loss -0.8331 
2025-03-13 08:55:49.632270: val_loss -0.7187 
2025-03-13 08:55:49.636801: Pseudo dice [np.float32(0.6598), np.float32(0.8848)] 
2025-03-13 08:55:49.639311: Epoch time: 36.91 s 
2025-03-13 08:55:49.642829: Yayy! New best EMA pseudo Dice: 0.734499990940094 
2025-03-13 08:55:50.382939:  
2025-03-13 08:55:50.388474: Epoch 26 
2025-03-13 08:55:50.392025: Current learning rate: 0.00763 
2025-03-13 08:56:27.281334: train_loss -0.8392 
2025-03-13 08:56:27.286909: val_loss -0.706 
2025-03-13 08:56:27.290939: Pseudo dice [np.float32(0.6449), np.float32(0.8867)] 
2025-03-13 08:56:27.293951: Epoch time: 36.9 s 
2025-03-13 08:56:27.297463: Yayy! New best EMA pseudo Dice: 0.7376999855041504 
2025-03-13 08:56:28.075011:  
2025-03-13 08:56:28.081537: Epoch 27 
2025-03-13 08:56:28.086547: Current learning rate: 0.00753 
2025-03-13 08:57:04.961147: train_loss -0.8359 
2025-03-13 08:57:04.967159: val_loss -0.7008 
2025-03-13 08:57:04.971171: Pseudo dice [np.float32(0.6407), np.float32(0.8778)] 
2025-03-13 08:57:04.973678: Epoch time: 36.89 s 
2025-03-13 08:57:04.977193: Yayy! New best EMA pseudo Dice: 0.739799976348877 
2025-03-13 08:57:05.867645:  
2025-03-13 08:57:05.873197: Epoch 28 
2025-03-13 08:57:05.876767: Current learning rate: 0.00744 
2025-03-13 08:57:42.724370: train_loss -0.8491 
2025-03-13 08:57:42.730921: val_loss -0.7222 
2025-03-13 08:57:42.734510: Pseudo dice [np.float32(0.6706), np.float32(0.8939)] 
2025-03-13 08:57:42.738022: Epoch time: 36.86 s 
2025-03-13 08:57:42.741528: Yayy! New best EMA pseudo Dice: 0.7440999746322632 
2025-03-13 08:57:43.481042:  
2025-03-13 08:57:43.486613: Epoch 29 
2025-03-13 08:57:43.489702: Current learning rate: 0.00735 
2025-03-13 08:58:20.353417: train_loss -0.8356 
2025-03-13 08:58:20.359961: val_loss -0.7167 
2025-03-13 08:58:20.363450: Pseudo dice [np.float32(0.6647), np.float32(0.8837)] 
2025-03-13 08:58:20.366459: Epoch time: 36.87 s 
2025-03-13 08:58:20.369973: Yayy! New best EMA pseudo Dice: 0.7470999956130981 
2025-03-13 08:58:21.137708:  
2025-03-13 08:58:21.142721: Epoch 30 
2025-03-13 08:58:21.146231: Current learning rate: 0.00725 
2025-03-13 08:58:57.992443: train_loss -0.8419 
2025-03-13 08:58:57.998027: val_loss -0.7231 
2025-03-13 08:58:58.003123: Pseudo dice [np.float32(0.6702), np.float32(0.8889)] 
2025-03-13 08:58:58.006167: Epoch time: 36.85 s 
2025-03-13 08:58:58.008700: Yayy! New best EMA pseudo Dice: 0.7502999901771545 
2025-03-13 08:58:58.750968:  
2025-03-13 08:58:58.756003: Epoch 31 
2025-03-13 08:58:58.758780: Current learning rate: 0.00716 
2025-03-13 08:59:35.651507: train_loss -0.8424 
2025-03-13 08:59:35.657524: val_loss -0.7294 
2025-03-13 08:59:35.661534: Pseudo dice [np.float32(0.6827), np.float32(0.8913)] 
2025-03-13 08:59:35.665047: Epoch time: 36.9 s 
2025-03-13 08:59:35.667553: Yayy! New best EMA pseudo Dice: 0.7540000081062317 
2025-03-13 08:59:36.452573:  
2025-03-13 08:59:36.457601: Epoch 32 
2025-03-13 08:59:36.461191: Current learning rate: 0.00707 
2025-03-13 09:00:13.352167: train_loss -0.8654 
2025-03-13 09:00:13.358687: val_loss -0.7233 
2025-03-13 09:00:13.362199: Pseudo dice [np.float32(0.6692), np.float32(0.89)] 
2025-03-13 09:00:13.366206: Epoch time: 36.9 s 
2025-03-13 09:00:13.368714: Yayy! New best EMA pseudo Dice: 0.7565000057220459 
2025-03-13 09:00:14.178386:  
2025-03-13 09:00:14.184582: Epoch 33 
2025-03-13 09:00:14.186615: Current learning rate: 0.00697 
2025-03-13 09:00:51.062523: train_loss -0.8592 
2025-03-13 09:00:51.068035: val_loss -0.7295 
2025-03-13 09:00:51.071545: Pseudo dice [np.float32(0.6769), np.float32(0.8923)] 
2025-03-13 09:00:51.075554: Epoch time: 36.88 s 
2025-03-13 09:00:51.078059: Yayy! New best EMA pseudo Dice: 0.7594000101089478 
2025-03-13 09:00:51.824382:  
2025-03-13 09:00:51.829953: Epoch 34 
2025-03-13 09:00:51.833514: Current learning rate: 0.00688 
2025-03-13 09:01:28.723413: train_loss -0.8713 
2025-03-13 09:01:28.731062: val_loss -0.7286 
2025-03-13 09:01:28.736104: Pseudo dice [np.float32(0.676), np.float32(0.8924)] 
2025-03-13 09:01:28.738613: Epoch time: 36.9 s 
2025-03-13 09:01:28.742123: Yayy! New best EMA pseudo Dice: 0.7617999911308289 
2025-03-13 09:01:29.638522:  
2025-03-13 09:01:29.643618: Epoch 35 
2025-03-13 09:01:29.647125: Current learning rate: 0.00679 
2025-03-13 09:02:06.512330: train_loss -0.865 
2025-03-13 09:02:06.517862: val_loss -0.7223 
2025-03-13 09:02:06.521875: Pseudo dice [np.float32(0.6688), np.float32(0.8911)] 
2025-03-13 09:02:06.524381: Epoch time: 36.87 s 
2025-03-13 09:02:06.527892: Yayy! New best EMA pseudo Dice: 0.7635999917984009 
2025-03-13 09:02:07.299697:  
2025-03-13 09:02:07.303745: Epoch 36 
2025-03-13 09:02:07.308654: Current learning rate: 0.00669 
2025-03-13 09:02:44.185743: train_loss -0.8586 
2025-03-13 09:02:44.192272: val_loss -0.7353 
2025-03-13 09:02:44.195782: Pseudo dice [np.float32(0.6861), np.float32(0.8982)] 
2025-03-13 09:02:44.199295: Epoch time: 36.89 s 
2025-03-13 09:02:44.202303: Yayy! New best EMA pseudo Dice: 0.7664999961853027 
2025-03-13 09:02:44.957740:  
2025-03-13 09:02:44.963318: Epoch 37 
2025-03-13 09:02:44.965860: Current learning rate: 0.0066 
2025-03-13 09:03:21.825430: train_loss -0.8662 
2025-03-13 09:03:21.831481: val_loss -0.7174 
2025-03-13 09:03:21.834540: Pseudo dice [np.float32(0.663), np.float32(0.8863)] 
2025-03-13 09:03:21.838050: Epoch time: 36.87 s 
2025-03-13 09:03:21.841556: Yayy! New best EMA pseudo Dice: 0.767300009727478 
2025-03-13 09:03:22.609293:  
2025-03-13 09:03:22.614844: Epoch 38 
2025-03-13 09:03:22.617383: Current learning rate: 0.0065 
2025-03-13 09:03:59.494874: train_loss -0.863 
2025-03-13 09:03:59.500530: val_loss -0.7185 
2025-03-13 09:03:59.504561: Pseudo dice [np.float32(0.6654), np.float32(0.8852)] 
2025-03-13 09:03:59.508158: Epoch time: 36.89 s 
2025-03-13 09:03:59.511706: Yayy! New best EMA pseudo Dice: 0.7681000232696533 
2025-03-13 09:04:00.284878:  
2025-03-13 09:04:00.290417: Epoch 39 
2025-03-13 09:04:00.293473: Current learning rate: 0.00641 
2025-03-13 09:04:37.183084: train_loss -0.8693 
2025-03-13 09:04:37.189608: val_loss -0.7355 
2025-03-13 09:04:37.193121: Pseudo dice [np.float32(0.689), np.float32(0.8959)] 
2025-03-13 09:04:37.197136: Epoch time: 36.9 s 
2025-03-13 09:04:37.200647: Yayy! New best EMA pseudo Dice: 0.7705000042915344 
2025-03-13 09:04:37.969727:  
2025-03-13 09:04:37.975276: Epoch 40 
2025-03-13 09:04:37.978826: Current learning rate: 0.00631 
2025-03-13 09:05:14.866770: train_loss -0.8759 
2025-03-13 09:05:14.873296: val_loss -0.7457 
2025-03-13 09:05:14.876801: Pseudo dice [np.float32(0.7092), np.float32(0.8918)] 
2025-03-13 09:05:14.879816: Epoch time: 36.9 s 
2025-03-13 09:05:14.884323: Yayy! New best EMA pseudo Dice: 0.7735000252723694 
2025-03-13 09:05:15.661210:  
2025-03-13 09:05:15.666809: Epoch 41 
2025-03-13 09:05:15.670371: Current learning rate: 0.00622 
2025-03-13 09:05:52.535200: train_loss -0.882 
2025-03-13 09:05:52.542716: val_loss -0.7241 
2025-03-13 09:05:52.546724: Pseudo dice [np.float32(0.676), np.float32(0.8904)] 
2025-03-13 09:05:52.550240: Epoch time: 36.87 s 
2025-03-13 09:05:52.553743: Yayy! New best EMA pseudo Dice: 0.7745000123977661 
2025-03-13 09:05:53.286710:  
2025-03-13 09:05:53.292726: Epoch 42 
2025-03-13 09:05:53.296232: Current learning rate: 0.00612 
2025-03-13 09:06:30.170059: train_loss -0.8708 
2025-03-13 09:06:30.176599: val_loss -0.7124 
2025-03-13 09:06:30.180106: Pseudo dice [np.float32(0.6585), np.float32(0.8917)] 
2025-03-13 09:06:30.184114: Epoch time: 36.88 s 
2025-03-13 09:06:30.187621: Yayy! New best EMA pseudo Dice: 0.7746000289916992 
2025-03-13 09:06:31.066859:  
2025-03-13 09:06:31.072875: Epoch 43 
2025-03-13 09:06:31.076885: Current learning rate: 0.00603 
2025-03-13 09:07:07.940252: train_loss -0.8714 
2025-03-13 09:07:07.946301: val_loss -0.7242 
2025-03-13 09:07:07.950354: Pseudo dice [np.float32(0.6718), np.float32(0.8927)] 
2025-03-13 09:07:07.953922: Epoch time: 36.87 s 
2025-03-13 09:07:07.956951: Yayy! New best EMA pseudo Dice: 0.7753000259399414 
2025-03-13 09:07:08.706188:  
2025-03-13 09:07:08.712732: Epoch 44 
2025-03-13 09:07:08.716237: Current learning rate: 0.00593 
2025-03-13 09:07:45.607133: train_loss -0.8794 
2025-03-13 09:07:45.614770: val_loss -0.712 
2025-03-13 09:07:45.618322: Pseudo dice [np.float32(0.6538), np.float32(0.8922)] 
2025-03-13 09:07:45.622367: Epoch time: 36.9 s 
2025-03-13 09:07:46.141168:  
2025-03-13 09:07:46.147202: Epoch 45 
2025-03-13 09:07:46.151243: Current learning rate: 0.00584 
2025-03-13 09:08:23.010645: train_loss -0.8771 
2025-03-13 09:08:23.015721: val_loss -0.7233 
2025-03-13 09:08:23.020820: Pseudo dice [np.float32(0.6835), np.float32(0.8897)] 
2025-03-13 09:08:23.023345: Epoch time: 36.87 s 
2025-03-13 09:08:23.027502: Yayy! New best EMA pseudo Dice: 0.776199996471405 
2025-03-13 09:08:23.773743:  
2025-03-13 09:08:23.779105: Epoch 46 
2025-03-13 09:08:23.784118: Current learning rate: 0.00574 
2025-03-13 09:09:00.657111: train_loss -0.8795 
2025-03-13 09:09:00.663730: val_loss -0.7116 
2025-03-13 09:09:00.667268: Pseudo dice [np.float32(0.6559), np.float32(0.8871)] 
2025-03-13 09:09:00.671303: Epoch time: 36.88 s 
2025-03-13 09:09:01.181806:  
2025-03-13 09:09:01.187322: Epoch 47 
2025-03-13 09:09:01.190830: Current learning rate: 0.00565 
2025-03-13 09:09:38.062574: train_loss -0.8867 
2025-03-13 09:09:38.068595: val_loss -0.7267 
2025-03-13 09:09:38.072611: Pseudo dice [np.float32(0.6826), np.float32(0.8908)] 
2025-03-13 09:09:38.077128: Epoch time: 36.88 s 
2025-03-13 09:09:38.080271: Yayy! New best EMA pseudo Dice: 0.7768999934196472 
2025-03-13 09:09:38.826839:  
2025-03-13 09:09:38.832933: Epoch 48 
2025-03-13 09:09:38.835986: Current learning rate: 0.00555 
2025-03-13 09:10:15.718411: train_loss -0.8807 
2025-03-13 09:10:15.724004: val_loss -0.7291 
2025-03-13 09:10:15.728618: Pseudo dice [np.float32(0.6835), np.float32(0.893)] 
2025-03-13 09:10:15.732170: Epoch time: 36.89 s 
2025-03-13 09:10:15.735675: Yayy! New best EMA pseudo Dice: 0.777999997138977 
2025-03-13 09:10:16.549870:  
2025-03-13 09:10:16.555389: Epoch 49 
2025-03-13 09:10:16.559952: Current learning rate: 0.00546 
2025-03-13 09:10:53.455176: train_loss -0.8864 
2025-03-13 09:10:53.462697: val_loss -0.731 
2025-03-13 09:10:53.466708: Pseudo dice [np.float32(0.6872), np.float32(0.891)] 
2025-03-13 09:10:53.470721: Epoch time: 36.91 s 
2025-03-13 09:10:53.671449: Yayy! New best EMA pseudo Dice: 0.7791000008583069 
2025-03-13 09:10:54.583033:  
2025-03-13 09:10:54.588615: Epoch 50 
2025-03-13 09:10:54.593708: Current learning rate: 0.00536 
2025-03-13 09:11:31.465679: train_loss -0.886 
2025-03-13 09:11:31.472730: val_loss -0.7325 
2025-03-13 09:11:31.476761: Pseudo dice [np.float32(0.6865), np.float32(0.8935)] 
2025-03-13 09:11:31.480775: Epoch time: 36.88 s 
2025-03-13 09:11:31.484784: Yayy! New best EMA pseudo Dice: 0.7802000045776367 
2025-03-13 09:11:32.225391:  
2025-03-13 09:11:32.231993: Epoch 51 
2025-03-13 09:11:32.236045: Current learning rate: 0.00526 
2025-03-13 09:12:09.121597: train_loss -0.8784 
2025-03-13 09:12:09.128195: val_loss -0.7077 
2025-03-13 09:12:09.131700: Pseudo dice [np.float32(0.6511), np.float32(0.8919)] 
2025-03-13 09:12:09.135711: Epoch time: 36.9 s 
2025-03-13 09:12:09.655025:  
2025-03-13 09:12:09.661062: Epoch 52 
2025-03-13 09:12:09.665101: Current learning rate: 0.00517 
2025-03-13 09:12:46.542794: train_loss -0.8868 
2025-03-13 09:12:46.550429: val_loss -0.721 
2025-03-13 09:12:46.553944: Pseudo dice [np.float32(0.6675), np.float32(0.8934)] 
2025-03-13 09:12:46.557959: Epoch time: 36.89 s 
2025-03-13 09:12:47.077753:  
2025-03-13 09:12:47.083332: Epoch 53 
2025-03-13 09:12:47.087914: Current learning rate: 0.00507 
2025-03-13 09:13:23.970762: train_loss -0.8867 
2025-03-13 09:13:23.976827: val_loss -0.7247 
2025-03-13 09:13:23.981838: Pseudo dice [np.float32(0.6722), np.float32(0.8954)] 
2025-03-13 09:13:23.985346: Epoch time: 36.89 s 
2025-03-13 09:13:24.539302:  
2025-03-13 09:13:24.546373: Epoch 54 
2025-03-13 09:13:24.550461: Current learning rate: 0.00497 
2025-03-13 09:14:01.449045: train_loss -0.8988 
2025-03-13 09:14:01.456223: val_loss -0.7055 
2025-03-13 09:14:01.459753: Pseudo dice [np.float32(0.6562), np.float32(0.8868)] 
2025-03-13 09:14:01.463295: Epoch time: 36.91 s 
2025-03-13 09:14:01.981572:  
2025-03-13 09:14:01.988160: Epoch 55 
2025-03-13 09:14:01.992224: Current learning rate: 0.00487 
2025-03-13 09:14:38.862550: train_loss -0.8946 
2025-03-13 09:14:38.870738: val_loss -0.7144 
2025-03-13 09:14:38.874340: Pseudo dice [np.float32(0.6739), np.float32(0.8857)] 
2025-03-13 09:14:38.877896: Epoch time: 36.88 s 
2025-03-13 09:14:39.409106:  
2025-03-13 09:14:39.415622: Epoch 56 
2025-03-13 09:14:39.419630: Current learning rate: 0.00478 
2025-03-13 09:15:16.277629: train_loss -0.8901 
2025-03-13 09:15:16.283646: val_loss -0.7123 
2025-03-13 09:15:16.287656: Pseudo dice [np.float32(0.6604), np.float32(0.8895)] 
2025-03-13 09:15:16.292165: Epoch time: 36.87 s 
2025-03-13 09:15:16.822421:  
2025-03-13 09:15:16.828982: Epoch 57 
2025-03-13 09:15:16.832561: Current learning rate: 0.00468 
2025-03-13 09:15:53.713909: train_loss -0.8808 
2025-03-13 09:15:53.721528: val_loss -0.7289 
2025-03-13 09:15:53.725113: Pseudo dice [np.float32(0.6948), np.float32(0.8891)] 
2025-03-13 09:15:53.729185: Epoch time: 36.89 s 
2025-03-13 09:15:54.411108:  
2025-03-13 09:15:54.418169: Epoch 58 
2025-03-13 09:15:54.422222: Current learning rate: 0.00458 
2025-03-13 09:16:31.296897: train_loss -0.8809 
2025-03-13 09:16:31.303451: val_loss -0.7178 
2025-03-13 09:16:31.307961: Pseudo dice [np.float32(0.6736), np.float32(0.8937)] 
2025-03-13 09:16:31.311977: Epoch time: 36.89 s 
2025-03-13 09:16:31.315989: Yayy! New best EMA pseudo Dice: 0.7803999781608582 
2025-03-13 09:16:32.090004:  
2025-03-13 09:16:32.095022: Epoch 59 
2025-03-13 09:16:32.099541: Current learning rate: 0.00448 
2025-03-13 09:17:08.959158: train_loss -0.8877 
2025-03-13 09:17:08.966224: val_loss -0.7194 
2025-03-13 09:17:08.970235: Pseudo dice [np.float32(0.6698), np.float32(0.893)] 
2025-03-13 09:17:08.974257: Epoch time: 36.87 s 
2025-03-13 09:17:08.977773: Yayy! New best EMA pseudo Dice: 0.7804999947547913 
2025-03-13 09:17:09.752062:  
2025-03-13 09:17:09.757586: Epoch 60 
2025-03-13 09:17:09.762095: Current learning rate: 0.00438 
2025-03-13 09:17:46.625768: train_loss -0.8931 
2025-03-13 09:17:46.633822: val_loss -0.7221 
2025-03-13 09:17:46.637331: Pseudo dice [np.float32(0.6741), np.float32(0.8906)] 
2025-03-13 09:17:46.641349: Epoch time: 36.87 s 
2025-03-13 09:17:46.645859: Yayy! New best EMA pseudo Dice: 0.7807000279426575 
2025-03-13 09:17:47.398218:  
2025-03-13 09:17:47.404276: Epoch 61 
2025-03-13 09:17:47.408354: Current learning rate: 0.00429 
2025-03-13 09:18:24.285965: train_loss -0.881 
2025-03-13 09:18:24.292337: val_loss -0.7225 
2025-03-13 09:18:24.296916: Pseudo dice [np.float32(0.6836), np.float32(0.8892)] 
2025-03-13 09:18:24.301432: Epoch time: 36.89 s 
2025-03-13 09:18:24.305453: Yayy! New best EMA pseudo Dice: 0.7811999917030334 
2025-03-13 09:18:25.112482:  
2025-03-13 09:18:25.118570: Epoch 62 
2025-03-13 09:18:25.122076: Current learning rate: 0.00419 
2025-03-13 09:19:01.991976: train_loss -0.8963 
2025-03-13 09:19:01.997515: val_loss -0.7164 
2025-03-13 09:19:02.002060: Pseudo dice [np.float32(0.6737), np.float32(0.8887)] 
2025-03-13 09:19:02.005568: Epoch time: 36.88 s 
2025-03-13 09:19:02.537076:  
2025-03-13 09:19:02.543094: Epoch 63 
2025-03-13 09:19:02.546601: Current learning rate: 0.00409 
2025-03-13 09:19:39.427894: train_loss -0.8883 
2025-03-13 09:19:39.435974: val_loss -0.7208 
2025-03-13 09:19:39.440984: Pseudo dice [np.float32(0.6746), np.float32(0.8948)] 
2025-03-13 09:19:39.445492: Epoch time: 36.89 s 
2025-03-13 09:19:39.456017: Yayy! New best EMA pseudo Dice: 0.7815999984741211 
2025-03-13 09:19:40.228183:  
2025-03-13 09:19:40.240845: Epoch 64 
2025-03-13 09:19:40.251867: Current learning rate: 0.00399 
2025-03-13 09:20:17.123987: train_loss -0.8904 
2025-03-13 09:20:17.137434: val_loss -0.7158 
2025-03-13 09:20:17.142496: Pseudo dice [np.float32(0.6736), np.float32(0.887)] 
2025-03-13 09:20:17.146559: Epoch time: 36.9 s 
2025-03-13 09:20:17.672606:  
2025-03-13 09:20:17.679167: Epoch 65 
2025-03-13 09:20:17.682793: Current learning rate: 0.00389 
2025-03-13 09:20:54.556535: train_loss -0.9028 
2025-03-13 09:20:54.564072: val_loss -0.7127 
2025-03-13 09:20:54.568589: Pseudo dice [np.float32(0.6708), np.float32(0.8865)] 
2025-03-13 09:20:54.573142: Epoch time: 36.88 s 
2025-03-13 09:20:55.261703:  
2025-03-13 09:20:55.268507: Epoch 66 
2025-03-13 09:20:55.272568: Current learning rate: 0.00379 
2025-03-13 09:21:32.159298: train_loss -0.9031 
2025-03-13 09:21:32.166425: val_loss -0.718 
2025-03-13 09:21:32.169971: Pseudo dice [np.float32(0.6712), np.float32(0.891)] 
2025-03-13 09:21:32.173866: Epoch time: 36.9 s 
2025-03-13 09:21:32.701170:  
2025-03-13 09:21:32.707245: Epoch 67 
2025-03-13 09:21:32.711910: Current learning rate: 0.00369 
2025-03-13 09:22:09.577781: train_loss -0.8963 
2025-03-13 09:22:09.584939: val_loss -0.7138 
2025-03-13 09:22:09.589010: Pseudo dice [np.float32(0.663), np.float32(0.894)] 
2025-03-13 09:22:09.592558: Epoch time: 36.88 s 
2025-03-13 09:22:10.137605:  
2025-03-13 09:22:10.143159: Epoch 68 
2025-03-13 09:22:10.146701: Current learning rate: 0.00359 
2025-03-13 09:22:47.040073: train_loss -0.9066 
2025-03-13 09:22:47.046776: val_loss -0.7081 
2025-03-13 09:22:47.050334: Pseudo dice [np.float32(0.6659), np.float32(0.8844)] 
2025-03-13 09:22:47.054392: Epoch time: 36.9 s 
2025-03-13 09:22:47.597696:  
2025-03-13 09:22:47.603740: Epoch 69 
2025-03-13 09:22:47.606822: Current learning rate: 0.00349 
2025-03-13 09:23:24.467886: train_loss -0.8913 
2025-03-13 09:23:24.475009: val_loss -0.7042 
2025-03-13 09:23:24.479061: Pseudo dice [np.float32(0.6605), np.float32(0.8865)] 
2025-03-13 09:23:24.483098: Epoch time: 36.87 s 
2025-03-13 09:23:25.070783:  
2025-03-13 09:23:25.077388: Epoch 70 
2025-03-13 09:23:25.079939: Current learning rate: 0.00338 
2025-03-13 09:24:01.970104: train_loss -0.9095 
2025-03-13 09:24:01.977716: val_loss -0.7087 
2025-03-13 09:24:01.981257: Pseudo dice [np.float32(0.6688), np.float32(0.8868)] 
2025-03-13 09:24:01.985298: Epoch time: 36.9 s 
2025-03-13 09:24:02.528925:  
2025-03-13 09:24:02.535484: Epoch 71 
2025-03-13 09:24:02.539499: Current learning rate: 0.00328 
2025-03-13 09:24:39.421947: train_loss -0.9028 
2025-03-13 09:24:39.430474: val_loss -0.7113 
2025-03-13 09:24:39.435486: Pseudo dice [np.float32(0.6661), np.float32(0.8886)] 
2025-03-13 09:24:39.439498: Epoch time: 36.89 s 
2025-03-13 09:24:39.977954:  
2025-03-13 09:24:39.985039: Epoch 72 
2025-03-13 09:24:39.989077: Current learning rate: 0.00318 
2025-03-13 09:25:16.841453: train_loss -0.8969 
2025-03-13 09:25:16.849061: val_loss -0.7102 
2025-03-13 09:25:16.852629: Pseudo dice [np.float32(0.6704), np.float32(0.8878)] 
2025-03-13 09:25:16.856636: Epoch time: 36.86 s 
2025-03-13 09:25:17.536506:  
2025-03-13 09:25:17.542095: Epoch 73 
2025-03-13 09:25:17.546649: Current learning rate: 0.00308 
2025-03-13 09:25:54.394230: train_loss -0.9043 
2025-03-13 09:25:54.401395: val_loss -0.7171 
2025-03-13 09:25:54.405455: Pseudo dice [np.float32(0.674), np.float32(0.8917)] 
2025-03-13 09:25:54.409527: Epoch time: 36.86 s 
2025-03-13 09:25:55.001993:  
2025-03-13 09:25:55.008740: Epoch 74 
2025-03-13 09:25:55.012312: Current learning rate: 0.00297 
2025-03-13 09:26:31.878040: train_loss -0.9082 
2025-03-13 09:26:31.884668: val_loss -0.7011 
2025-03-13 09:26:31.888716: Pseudo dice [np.float32(0.6608), np.float32(0.8874)] 
2025-03-13 09:26:31.892258: Epoch time: 36.88 s 
2025-03-13 09:26:32.423464:  
2025-03-13 09:26:32.428985: Epoch 75 
2025-03-13 09:26:32.433499: Current learning rate: 0.00287 
2025-03-13 09:27:09.310271: train_loss -0.9042 
2025-03-13 09:27:09.317317: val_loss -0.7022 
2025-03-13 09:27:09.321386: Pseudo dice [np.float32(0.6543), np.float32(0.8895)] 
2025-03-13 09:27:09.325575: Epoch time: 36.89 s 
2025-03-13 09:27:09.871288:  
2025-03-13 09:27:09.876800: Epoch 76 
2025-03-13 09:27:09.881315: Current learning rate: 0.00277 
2025-03-13 09:27:46.752061: train_loss -0.9044 
2025-03-13 09:27:46.759682: val_loss -0.7191 
2025-03-13 09:27:46.764274: Pseudo dice [np.float32(0.6776), np.float32(0.891)] 
2025-03-13 09:27:46.768347: Epoch time: 36.88 s 
2025-03-13 09:27:47.308011:  
2025-03-13 09:27:47.314056: Epoch 77 
2025-03-13 09:27:47.318126: Current learning rate: 0.00266 
2025-03-13 09:28:24.185123: train_loss -0.9122 
2025-03-13 09:28:24.190703: val_loss -0.7148 
2025-03-13 09:28:24.195297: Pseudo dice [np.float32(0.6774), np.float32(0.8882)] 
2025-03-13 09:28:24.199805: Epoch time: 36.88 s 
2025-03-13 09:28:24.800882:  
2025-03-13 09:28:24.806905: Epoch 78 
2025-03-13 09:28:24.810922: Current learning rate: 0.00256 
2025-03-13 09:29:01.703070: train_loss -0.9022 
2025-03-13 09:29:01.710620: val_loss -0.7111 
2025-03-13 09:29:01.714852: Pseudo dice [np.float32(0.6621), np.float32(0.8908)] 
2025-03-13 09:29:01.718894: Epoch time: 36.9 s 
2025-03-13 09:29:02.263485:  
2025-03-13 09:29:02.269508: Epoch 79 
2025-03-13 09:29:02.273526: Current learning rate: 0.00245 
2025-03-13 09:29:39.138762: train_loss -0.9103 
2025-03-13 09:29:39.144834: val_loss -0.7048 
2025-03-13 09:29:39.149415: Pseudo dice [np.float32(0.6604), np.float32(0.8912)] 
2025-03-13 09:29:39.153440: Epoch time: 36.88 s 
2025-03-13 09:29:39.713622:  
2025-03-13 09:29:39.721176: Epoch 80 
2025-03-13 09:29:39.725221: Current learning rate: 0.00235 
2025-03-13 09:30:16.591622: train_loss -0.9083 
2025-03-13 09:30:16.598635: val_loss -0.7081 
2025-03-13 09:30:16.602653: Pseudo dice [np.float32(0.6692), np.float32(0.888)] 
2025-03-13 09:30:16.606660: Epoch time: 36.88 s 
2025-03-13 09:30:17.298058:  
2025-03-13 09:30:17.304480: Epoch 81 
2025-03-13 09:30:17.308993: Current learning rate: 0.00224 
2025-03-13 09:30:54.176293: train_loss -0.8955 
2025-03-13 09:30:54.184437: val_loss -0.7033 
2025-03-13 09:30:54.189004: Pseudo dice [np.float32(0.6628), np.float32(0.8866)] 
2025-03-13 09:30:54.192041: Epoch time: 36.88 s 
2025-03-13 09:30:54.791518:  
2025-03-13 09:30:54.798033: Epoch 82 
2025-03-13 09:30:54.802042: Current learning rate: 0.00214 
2025-03-13 09:31:31.667535: train_loss -0.9143 
2025-03-13 09:31:31.674883: val_loss -0.7117 
2025-03-13 09:31:31.678199: Pseudo dice [np.float32(0.6697), np.float32(0.8925)] 
2025-03-13 09:31:31.683208: Epoch time: 36.88 s 
2025-03-13 09:31:32.201752:  
2025-03-13 09:31:32.207773: Epoch 83 
2025-03-13 09:31:32.211796: Current learning rate: 0.00203 
2025-03-13 09:32:09.054448: train_loss -0.9099 
2025-03-13 09:32:09.060504: val_loss -0.7073 
2025-03-13 09:32:09.065037: Pseudo dice [np.float32(0.6684), np.float32(0.8925)] 
2025-03-13 09:32:09.069074: Epoch time: 36.85 s 
2025-03-13 09:32:09.596496:  
2025-03-13 09:32:09.602518: Epoch 84 
2025-03-13 09:32:09.607033: Current learning rate: 0.00192 
2025-03-13 09:32:46.477913: train_loss -0.9113 
2025-03-13 09:32:46.485458: val_loss -0.7043 
2025-03-13 09:32:46.489472: Pseudo dice [np.float32(0.662), np.float32(0.8904)] 
2025-03-13 09:32:46.493981: Epoch time: 36.88 s 
2025-03-13 09:32:47.011182:  
2025-03-13 09:32:47.018697: Epoch 85 
2025-03-13 09:32:47.022704: Current learning rate: 0.00181 
2025-03-13 09:33:23.885890: train_loss -0.9113 
2025-03-13 09:33:23.892981: val_loss -0.6962 
2025-03-13 09:33:23.896516: Pseudo dice [np.float32(0.6544), np.float32(0.8889)] 
2025-03-13 09:33:23.900525: Epoch time: 36.87 s 
2025-03-13 09:33:24.427077:  
2025-03-13 09:33:24.433091: Epoch 86 
2025-03-13 09:33:24.437102: Current learning rate: 0.0017 
2025-03-13 09:34:01.321923: train_loss -0.9204 
2025-03-13 09:34:01.329438: val_loss -0.7018 
2025-03-13 09:34:01.333947: Pseudo dice [np.float32(0.6568), np.float32(0.8915)] 
2025-03-13 09:34:01.337958: Epoch time: 36.9 s 
2025-03-13 09:34:01.936392:  
2025-03-13 09:34:01.941904: Epoch 87 
2025-03-13 09:34:01.946913: Current learning rate: 0.00159 
2025-03-13 09:34:38.822332: train_loss -0.9167 
2025-03-13 09:34:38.828867: val_loss -0.7107 
2025-03-13 09:34:38.833375: Pseudo dice [np.float32(0.6727), np.float32(0.8903)] 
2025-03-13 09:34:38.836384: Epoch time: 36.89 s 
2025-03-13 09:34:39.355523:  
2025-03-13 09:34:39.361579: Epoch 88 
2025-03-13 09:34:39.365101: Current learning rate: 0.00148 
2025-03-13 09:35:16.228389: train_loss -0.9027 
2025-03-13 09:35:16.234171: val_loss -0.7037 
2025-03-13 09:35:16.238182: Pseudo dice [np.float32(0.6669), np.float32(0.8898)] 
2025-03-13 09:35:16.241692: Epoch time: 36.87 s 
2025-03-13 09:35:16.894749:  
2025-03-13 09:35:16.901883: Epoch 89 
2025-03-13 09:35:16.904919: Current learning rate: 0.00137 
2025-03-13 09:35:53.779095: train_loss -0.9157 
2025-03-13 09:35:53.786609: val_loss -0.6981 
2025-03-13 09:35:53.791628: Pseudo dice [np.float32(0.6591), np.float32(0.8892)] 
2025-03-13 09:35:53.795134: Epoch time: 36.88 s 
2025-03-13 09:35:54.308449:  
2025-03-13 09:35:54.314485: Epoch 90 
2025-03-13 09:35:54.319499: Current learning rate: 0.00126 
2025-03-13 09:36:31.170209: train_loss -0.9183 
2025-03-13 09:36:31.176734: val_loss -0.7061 
2025-03-13 09:36:31.181244: Pseudo dice [np.float32(0.6687), np.float32(0.8885)] 
2025-03-13 09:36:31.185256: Epoch time: 36.86 s 
2025-03-13 09:36:31.701295:  
2025-03-13 09:36:31.708909: Epoch 91 
2025-03-13 09:36:31.712953: Current learning rate: 0.00115 
2025-03-13 09:37:08.548834: train_loss -0.9068 
2025-03-13 09:37:08.555870: val_loss -0.7171 
2025-03-13 09:37:08.560382: Pseudo dice [np.float32(0.6826), np.float32(0.8915)] 
2025-03-13 09:37:08.564398: Epoch time: 36.85 s 
2025-03-13 09:37:09.081255:  
2025-03-13 09:37:09.087813: Epoch 92 
2025-03-13 09:37:09.091854: Current learning rate: 0.00103 
2025-03-13 09:37:45.956063: train_loss -0.9149 
2025-03-13 09:37:45.963590: val_loss -0.7006 
2025-03-13 09:37:45.968611: Pseudo dice [np.float32(0.6628), np.float32(0.8904)] 
2025-03-13 09:37:45.973124: Epoch time: 36.88 s 
2025-03-13 09:37:46.487607:  
2025-03-13 09:37:46.493695: Epoch 93 
2025-03-13 09:37:46.497706: Current learning rate: 0.00091 
2025-03-13 09:38:23.376951: train_loss -0.9231 
2025-03-13 09:38:23.384021: val_loss -0.7054 
2025-03-13 09:38:23.388032: Pseudo dice [np.float32(0.6654), np.float32(0.8923)] 
2025-03-13 09:38:23.392040: Epoch time: 36.89 s 
2025-03-13 09:38:23.926556:  
2025-03-13 09:38:23.933122: Epoch 94 
2025-03-13 09:38:23.936658: Current learning rate: 0.00079 
2025-03-13 09:39:00.793249: train_loss -0.9235 
2025-03-13 09:39:00.800337: val_loss -0.7021 
2025-03-13 09:39:00.804958: Pseudo dice [np.float32(0.6645), np.float32(0.8913)] 
2025-03-13 09:39:00.808964: Epoch time: 36.87 s 
2025-03-13 09:39:01.321932:  
2025-03-13 09:39:01.328964: Epoch 95 
2025-03-13 09:39:01.332983: Current learning rate: 0.00067 
2025-03-13 09:39:38.205126: train_loss -0.9267 
2025-03-13 09:39:38.214148: val_loss -0.7036 
2025-03-13 09:39:38.220164: Pseudo dice [np.float32(0.6737), np.float32(0.8905)] 
2025-03-13 09:39:38.225176: Epoch time: 36.88 s 
2025-03-13 09:39:38.746370:  
2025-03-13 09:39:38.753920: Epoch 96 
2025-03-13 09:39:38.758933: Current learning rate: 0.00055 
2025-03-13 09:40:15.633923: train_loss -0.9181 
2025-03-13 09:40:15.641015: val_loss -0.6978 
2025-03-13 09:40:15.645562: Pseudo dice [np.float32(0.6657), np.float32(0.8894)] 
2025-03-13 09:40:15.649107: Epoch time: 36.89 s 
2025-03-13 09:40:16.322122:  
2025-03-13 09:40:16.328686: Epoch 97 
2025-03-13 09:40:16.334712: Current learning rate: 0.00043 
2025-03-13 09:40:53.219961: train_loss -0.9113 
2025-03-13 09:40:53.228545: val_loss -0.7065 
2025-03-13 09:40:53.233116: Pseudo dice [np.float32(0.6752), np.float32(0.8898)] 
2025-03-13 09:40:53.238132: Epoch time: 36.9 s 
2025-03-13 09:40:53.764488:  
2025-03-13 09:40:53.770532: Epoch 98 
2025-03-13 09:40:53.775651: Current learning rate: 0.0003 
2025-03-13 09:41:30.649175: train_loss -0.9113 
2025-03-13 09:41:30.656787: val_loss -0.7051 
2025-03-13 09:41:30.661358: Pseudo dice [np.float32(0.6712), np.float32(0.891)] 
2025-03-13 09:41:30.666418: Epoch time: 36.89 s 
2025-03-13 09:41:31.192237:  
2025-03-13 09:41:31.199327: Epoch 99 
2025-03-13 09:41:31.204353: Current learning rate: 0.00016 
2025-03-13 09:42:08.084032: train_loss -0.9238 
2025-03-13 09:42:08.091611: val_loss -0.7093 
2025-03-13 09:42:08.096624: Pseudo dice [np.float32(0.6736), np.float32(0.8904)] 
2025-03-13 09:42:08.100635: Epoch time: 36.89 s 
2025-03-13 09:42:08.878828: Training done. 
2025-03-13 09:42:08.903832: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset005_Prostate\splits_final.json 
2025-03-13 09:42:08.910832: The split file contains 5 splits. 
2025-03-13 09:42:08.916830: Desired fold for training: 0 
2025-03-13 09:42:08.921831: This split has 25 training and 7 validation cases. 
2025-03-13 09:42:08.925831: predicting prostate_00 
2025-03-13 09:42:08.933831: prostate_00, shape torch.Size([2, 17, 307, 307]), rank 0 
2025-03-13 09:42:09.947695: predicting prostate_04 
2025-03-13 09:42:09.956694: prostate_04, shape torch.Size([2, 17, 306, 307]), rank 0 
2025-03-13 09:42:10.286790: predicting prostate_14 
2025-03-13 09:42:10.294796: prostate_14, shape torch.Size([2, 20, 320, 319]), rank 0 
2025-03-13 09:42:10.623793: predicting prostate_20 
2025-03-13 09:42:10.632791: prostate_20, shape torch.Size([2, 20, 320, 320]), rank 0 
2025-03-13 09:42:10.962791: predicting prostate_25 
2025-03-13 09:42:10.971792: prostate_25, shape torch.Size([2, 19, 320, 319]), rank 0 
2025-03-13 09:42:11.304793: predicting prostate_31 
2025-03-13 09:42:11.312794: prostate_31, shape torch.Size([2, 20, 320, 319]), rank 0 
2025-03-13 09:42:11.643790: predicting prostate_42 
2025-03-13 09:42:11.652790: prostate_42, shape torch.Size([2, 22, 320, 319]), rank 0 
2025-03-13 09:42:18.974647: Validation complete 
2025-03-13 09:42:18.980647: Mean Validation Dice:  0.7808159455024364 
