
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-26 05:37:34.842162: do_dummy_2d_data_aug: True 
2025-02-26 05:37:34.844714: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset005_Prostate\splits_final.json 
2025-02-26 05:37:34.852718: The split file contains 5 splits. 
2025-02-26 05:37:34.855718: Desired fold for training: 0 
2025-02-26 05:37:34.857719: This split has 25 training and 7 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [20, 320, 256], 'median_image_size_in_voxels': [20.0, 320.0, 319.0], 'spacing': [3.5999999046325684, 0.625, 0.625], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset005_Prostate', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.5999999046325684, 0.625, 0.625], 'original_median_shape_after_transp': [20, 320, 320], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1326.0, 'mean': 350.18780517578125, 'median': 327.0, 'min': 0.0, 'percentile_00_5': 83.0, 'percentile_99_5': 822.0, 'std': 139.9563751220703}, '1': {'max': 3698.0, 'mean': 1351.1083984375, 'median': 1364.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 2563.0, 'std': 376.4326477050781}}} 
 
2025-02-26 05:37:42.087205: unpacking dataset... 
2025-02-26 05:37:42.266747: unpacking done... 
2025-02-26 05:37:45.333339:  
2025-02-26 05:37:45.339360: Epoch 0 
2025-02-26 05:37:45.342450: Current learning rate: 0.01 
2025-02-26 05:38:27.896205: train_loss -0.224 
2025-02-26 05:38:27.901771: val_loss -0.5325 
2025-02-26 05:38:27.904314: Pseudo dice [np.float32(0.4229), np.float32(0.7298)] 
2025-02-26 05:38:27.908433: Epoch time: 42.56 s 
2025-02-26 05:38:27.912028: Yayy! New best EMA pseudo Dice: 0.5763999819755554 
2025-02-26 05:38:28.546536:  
2025-02-26 05:38:28.552600: Epoch 1 
2025-02-26 05:38:28.555244: Current learning rate: 0.00991 
2025-02-26 05:39:06.811236: train_loss -0.5556 
2025-02-26 05:39:06.817331: val_loss -0.6788 
2025-02-26 05:39:06.820995: Pseudo dice [np.float32(0.6528), np.float32(0.8542)] 
2025-02-26 05:39:06.823524: Epoch time: 38.27 s 
2025-02-26 05:39:06.828598: Yayy! New best EMA pseudo Dice: 0.5940999984741211 
2025-02-26 05:39:07.527009:  
2025-02-26 05:39:07.533114: Epoch 2 
2025-02-26 05:39:07.536622: Current learning rate: 0.00982 
2025-02-26 05:39:45.767189: train_loss -0.6809 
2025-02-26 05:39:45.773197: val_loss -0.6925 
2025-02-26 05:39:45.776211: Pseudo dice [np.float32(0.6503), np.float32(0.8709)] 
2025-02-26 05:39:45.779719: Epoch time: 38.24 s 
2025-02-26 05:39:45.783732: Yayy! New best EMA pseudo Dice: 0.6107000112533569 
2025-02-26 05:39:46.509190:  
2025-02-26 05:39:46.514729: Epoch 3 
2025-02-26 05:39:46.518267: Current learning rate: 0.00973 
2025-02-26 05:40:24.719521: train_loss -0.7043 
2025-02-26 05:40:24.725044: val_loss -0.6748 
2025-02-26 05:40:24.728555: Pseudo dice [np.float32(0.6177), np.float32(0.8757)] 
2025-02-26 05:40:24.731070: Epoch time: 38.21 s 
2025-02-26 05:40:24.735084: Yayy! New best EMA pseudo Dice: 0.6243000030517578 
2025-02-26 05:40:25.459271:  
2025-02-26 05:40:25.464299: Epoch 4 
2025-02-26 05:40:25.468189: Current learning rate: 0.00964 
2025-02-26 05:41:03.664276: train_loss -0.751 
2025-02-26 05:41:03.670371: val_loss -0.7109 
2025-02-26 05:41:03.673912: Pseudo dice [np.float32(0.6564), np.float32(0.8786)] 
2025-02-26 05:41:03.676986: Epoch time: 38.21 s 
2025-02-26 05:41:03.680619: Yayy! New best EMA pseudo Dice: 0.638700008392334 
2025-02-26 05:41:04.531681:  
2025-02-26 05:41:04.536724: Epoch 5 
2025-02-26 05:41:04.540232: Current learning rate: 0.00955 
2025-02-26 05:41:42.748497: train_loss -0.7752 
2025-02-26 05:41:42.755180: val_loss -0.7249 
2025-02-26 05:41:42.758774: Pseudo dice [np.float32(0.6735), np.float32(0.8872)] 
2025-02-26 05:41:42.761847: Epoch time: 38.22 s 
2025-02-26 05:41:42.765502: Yayy! New best EMA pseudo Dice: 0.6528000235557556 
2025-02-26 05:41:43.483000:  
2025-02-26 05:41:43.489582: Epoch 6 
2025-02-26 05:41:43.493141: Current learning rate: 0.00946 
2025-02-26 05:42:21.702672: train_loss -0.8087 
2025-02-26 05:42:21.708681: val_loss -0.7218 
2025-02-26 05:42:21.711690: Pseudo dice [np.float32(0.666), np.float32(0.8862)] 
2025-02-26 05:42:21.715200: Epoch time: 38.22 s 
2025-02-26 05:42:21.719213: Yayy! New best EMA pseudo Dice: 0.6651999950408936 
2025-02-26 05:42:22.437595:  
2025-02-26 05:42:22.443702: Epoch 7 
2025-02-26 05:42:22.447273: Current learning rate: 0.00937 
2025-02-26 05:43:00.654589: train_loss -0.8213 
2025-02-26 05:43:00.660165: val_loss -0.7162 
2025-02-26 05:43:00.663673: Pseudo dice [np.float32(0.6609), np.float32(0.885)] 
2025-02-26 05:43:00.666183: Epoch time: 38.22 s 
2025-02-26 05:43:00.670197: Yayy! New best EMA pseudo Dice: 0.6758999824523926 
2025-02-26 05:43:01.399933:  
2025-02-26 05:43:01.404983: Epoch 8 
2025-02-26 05:43:01.407192: Current learning rate: 0.00928 
2025-02-26 05:43:39.616809: train_loss -0.8362 
2025-02-26 05:43:39.622904: val_loss -0.7075 
2025-02-26 05:43:39.625460: Pseudo dice [np.float32(0.6448), np.float32(0.888)] 
2025-02-26 05:43:39.629521: Epoch time: 38.22 s 
2025-02-26 05:43:39.633211: Yayy! New best EMA pseudo Dice: 0.6850000023841858 
2025-02-26 05:43:40.369527:  
2025-02-26 05:43:40.375554: Epoch 9 
2025-02-26 05:43:40.379061: Current learning rate: 0.00919 
2025-02-26 05:44:18.576491: train_loss -0.8438 
2025-02-26 05:44:18.581618: val_loss -0.7132 
2025-02-26 05:44:18.585141: Pseudo dice [np.float32(0.6644), np.float32(0.8863)] 
2025-02-26 05:44:18.588205: Epoch time: 38.21 s 
2025-02-26 05:44:18.591732: Yayy! New best EMA pseudo Dice: 0.6940000057220459 
2025-02-26 05:44:19.295434:  
2025-02-26 05:44:19.300955: Epoch 10 
2025-02-26 05:44:19.304471: Current learning rate: 0.0091 
2025-02-26 05:44:57.502948: train_loss -0.8407 
2025-02-26 05:44:57.509016: val_loss -0.7038 
2025-02-26 05:44:57.512055: Pseudo dice [np.float32(0.6497), np.float32(0.8847)] 
2025-02-26 05:44:57.515269: Epoch time: 38.21 s 
2025-02-26 05:44:57.519329: Yayy! New best EMA pseudo Dice: 0.7013000249862671 
2025-02-26 05:44:58.231279:  
2025-02-26 05:44:58.236821: Epoch 11 
2025-02-26 05:44:58.239866: Current learning rate: 0.009 
2025-02-26 05:45:36.433838: train_loss -0.855 
2025-02-26 05:45:36.438926: val_loss -0.7055 
2025-02-26 05:45:36.442453: Pseudo dice [np.float32(0.6493), np.float32(0.8865)] 
2025-02-26 05:45:36.446024: Epoch time: 38.2 s 
2025-02-26 05:45:36.449071: Yayy! New best EMA pseudo Dice: 0.7080000042915344 
2025-02-26 05:45:37.299690:  
2025-02-26 05:45:37.305750: Epoch 12 
2025-02-26 05:45:37.308806: Current learning rate: 0.00891 
2025-02-26 05:46:15.518183: train_loss -0.8558 
2025-02-26 05:46:15.523260: val_loss -0.7136 
2025-02-26 05:46:15.527294: Pseudo dice [np.float32(0.6713), np.float32(0.8824)] 
2025-02-26 05:46:15.530827: Epoch time: 38.22 s 
2025-02-26 05:46:15.533913: Yayy! New best EMA pseudo Dice: 0.714900016784668 
2025-02-26 05:46:16.257591:  
2025-02-26 05:46:16.263252: Epoch 13 
2025-02-26 05:46:16.266840: Current learning rate: 0.00882 
2025-02-26 05:46:54.451868: train_loss -0.8652 
2025-02-26 05:46:54.458060: val_loss -0.7202 
2025-02-26 05:46:54.461110: Pseudo dice [np.float32(0.6838), np.float32(0.8819)] 
2025-02-26 05:46:54.464166: Epoch time: 38.19 s 
2025-02-26 05:46:54.467773: Yayy! New best EMA pseudo Dice: 0.7217000126838684 
2025-02-26 05:46:55.183735:  
2025-02-26 05:46:55.189250: Epoch 14 
2025-02-26 05:46:55.192761: Current learning rate: 0.00873 
2025-02-26 05:47:33.392830: train_loss -0.8675 
2025-02-26 05:47:33.397846: val_loss -0.7201 
2025-02-26 05:47:33.401863: Pseudo dice [np.float32(0.6707), np.float32(0.889)] 
2025-02-26 05:47:33.404373: Epoch time: 38.21 s 
2025-02-26 05:47:33.407889: Yayy! New best EMA pseudo Dice: 0.7275000214576721 
2025-02-26 05:47:34.123154:  
2025-02-26 05:47:34.128303: Epoch 15 
2025-02-26 05:47:34.131819: Current learning rate: 0.00864 
2025-02-26 05:48:12.324711: train_loss -0.8699 
2025-02-26 05:48:12.330782: val_loss -0.7059 
2025-02-26 05:48:12.333799: Pseudo dice [np.float32(0.6579), np.float32(0.8859)] 
2025-02-26 05:48:12.337370: Epoch time: 38.2 s 
2025-02-26 05:48:12.341017: Yayy! New best EMA pseudo Dice: 0.7318999767303467 
2025-02-26 05:48:13.061377:  
2025-02-26 05:48:13.067980: Epoch 16 
2025-02-26 05:48:13.070533: Current learning rate: 0.00855 
2025-02-26 05:48:51.256831: train_loss -0.8726 
2025-02-26 05:48:51.263462: val_loss -0.6942 
2025-02-26 05:48:51.266977: Pseudo dice [np.float32(0.6361), np.float32(0.885)] 
2025-02-26 05:48:51.270568: Epoch time: 38.2 s 
2025-02-26 05:48:51.274721: Yayy! New best EMA pseudo Dice: 0.7347999811172485 
2025-02-26 05:48:52.004436:  
2025-02-26 05:48:52.009956: Epoch 17 
2025-02-26 05:48:52.013470: Current learning rate: 0.00846 
2025-02-26 05:49:30.214960: train_loss -0.8781 
2025-02-26 05:49:30.220979: val_loss -0.7208 
2025-02-26 05:49:30.224995: Pseudo dice [np.float32(0.6831), np.float32(0.8872)] 
2025-02-26 05:49:30.228507: Epoch time: 38.21 s 
2025-02-26 05:49:30.231016: Yayy! New best EMA pseudo Dice: 0.739799976348877 
2025-02-26 05:49:30.954805:  
2025-02-26 05:49:30.959869: Epoch 18 
2025-02-26 05:49:30.962990: Current learning rate: 0.00836 
2025-02-26 05:50:09.163010: train_loss -0.8784 
2025-02-26 05:50:09.168103: val_loss -0.6954 
2025-02-26 05:50:09.171641: Pseudo dice [np.float32(0.6543), np.float32(0.8831)] 
2025-02-26 05:50:09.174656: Epoch time: 38.21 s 
2025-02-26 05:50:09.178303: Yayy! New best EMA pseudo Dice: 0.7426999807357788 
2025-02-26 05:50:09.901274:  
2025-02-26 05:50:09.906292: Epoch 19 
2025-02-26 05:50:09.909801: Current learning rate: 0.00827 
2025-02-26 05:50:48.102727: train_loss -0.8901 
2025-02-26 05:50:48.109767: val_loss -0.724 
2025-02-26 05:50:48.113277: Pseudo dice [np.float32(0.6872), np.float32(0.8901)] 
2025-02-26 05:50:48.116789: Epoch time: 38.2 s 
2025-02-26 05:50:48.119803: Yayy! New best EMA pseudo Dice: 0.7473000288009644 
2025-02-26 05:50:48.984812:  
2025-02-26 05:50:48.990436: Epoch 20 
2025-02-26 05:50:48.994005: Current learning rate: 0.00818 
2025-02-26 05:51:27.179585: train_loss -0.9022 
2025-02-26 05:51:27.185594: val_loss -0.7116 
2025-02-26 05:51:27.189608: Pseudo dice [np.float32(0.6735), np.float32(0.8903)] 
2025-02-26 05:51:27.192113: Epoch time: 38.19 s 
2025-02-26 05:51:27.196126: Yayy! New best EMA pseudo Dice: 0.7508000135421753 
2025-02-26 05:51:27.928272:  
2025-02-26 05:51:27.933295: Epoch 21 
2025-02-26 05:51:27.936809: Current learning rate: 0.00809 
2025-02-26 05:52:06.126102: train_loss -0.9067 
2025-02-26 05:52:06.132221: val_loss -0.724 
2025-02-26 05:52:06.135729: Pseudo dice [np.float32(0.6897), np.float32(0.8922)] 
2025-02-26 05:52:06.138740: Epoch time: 38.2 s 
2025-02-26 05:52:06.142251: Yayy! New best EMA pseudo Dice: 0.754800021648407 
2025-02-26 05:52:06.852389:  
2025-02-26 05:52:06.857907: Epoch 22 
2025-02-26 05:52:06.861415: Current learning rate: 0.008 
2025-02-26 05:52:45.052432: train_loss -0.9027 
2025-02-26 05:52:45.059020: val_loss -0.7084 
2025-02-26 05:52:45.062152: Pseudo dice [np.float32(0.6714), np.float32(0.8901)] 
2025-02-26 05:52:45.065702: Epoch time: 38.2 s 
2025-02-26 05:52:45.068744: Yayy! New best EMA pseudo Dice: 0.7573999762535095 
2025-02-26 05:52:45.776055:  
2025-02-26 05:52:45.781569: Epoch 23 
2025-02-26 05:52:45.785086: Current learning rate: 0.0079 
2025-02-26 05:53:23.981004: train_loss -0.9012 
2025-02-26 05:53:23.986598: val_loss -0.7143 
2025-02-26 05:53:23.989637: Pseudo dice [np.float32(0.6756), np.float32(0.8879)] 
2025-02-26 05:53:23.993298: Epoch time: 38.21 s 
2025-02-26 05:53:23.996342: Yayy! New best EMA pseudo Dice: 0.7598000168800354 
2025-02-26 05:53:24.695530:  
2025-02-26 05:53:24.701070: Epoch 24 
2025-02-26 05:53:24.704582: Current learning rate: 0.00781 
2025-02-26 05:54:02.896594: train_loss -0.9062 
2025-02-26 05:54:02.901639: val_loss -0.7202 
2025-02-26 05:54:02.906301: Pseudo dice [np.float32(0.692), np.float32(0.8894)] 
2025-02-26 05:54:02.909314: Epoch time: 38.2 s 
2025-02-26 05:54:02.913477: Yayy! New best EMA pseudo Dice: 0.7628999948501587 
2025-02-26 05:54:03.616356:  
2025-02-26 05:54:03.621876: Epoch 25 
2025-02-26 05:54:03.625389: Current learning rate: 0.00772 
2025-02-26 05:54:41.832900: train_loss -0.9014 
2025-02-26 05:54:41.838952: val_loss -0.6992 
2025-02-26 05:54:41.841579: Pseudo dice [np.float32(0.6616), np.float32(0.8843)] 
2025-02-26 05:54:41.846170: Epoch time: 38.22 s 
2025-02-26 05:54:41.849681: Yayy! New best EMA pseudo Dice: 0.7638999819755554 
2025-02-26 05:54:42.554867:  
2025-02-26 05:54:42.560443: Epoch 26 
2025-02-26 05:54:42.565014: Current learning rate: 0.00763 
2025-02-26 05:55:20.758155: train_loss -0.9016 
2025-02-26 05:55:20.763166: val_loss -0.724 
2025-02-26 05:55:20.769692: Pseudo dice [np.float32(0.6939), np.float32(0.8908)] 
2025-02-26 05:55:20.774208: Epoch time: 38.2 s 
2025-02-26 05:55:20.777221: Yayy! New best EMA pseudo Dice: 0.7667999863624573 
2025-02-26 05:55:21.482290:  
2025-02-26 05:55:21.488322: Epoch 27 
2025-02-26 05:55:21.491837: Current learning rate: 0.00753 
2025-02-26 05:55:59.707911: train_loss -0.9098 
2025-02-26 05:55:59.714476: val_loss -0.7156 
2025-02-26 05:55:59.717512: Pseudo dice [np.float32(0.6854), np.float32(0.8886)] 
2025-02-26 05:55:59.721125: Epoch time: 38.23 s 
2025-02-26 05:55:59.723296: Yayy! New best EMA pseudo Dice: 0.7688000202178955 
2025-02-26 05:56:00.575431:  
2025-02-26 05:56:00.580945: Epoch 28 
2025-02-26 05:56:00.584453: Current learning rate: 0.00744 
2025-02-26 05:56:38.785839: train_loss -0.9059 
2025-02-26 05:56:38.791861: val_loss -0.7049 
2025-02-26 05:56:38.794371: Pseudo dice [np.float32(0.6766), np.float32(0.8825)] 
2025-02-26 05:56:38.798383: Epoch time: 38.21 s 
2025-02-26 05:56:38.801895: Yayy! New best EMA pseudo Dice: 0.7699000239372253 
2025-02-26 05:56:39.516636:  
2025-02-26 05:56:39.522189: Epoch 29 
2025-02-26 05:56:39.525226: Current learning rate: 0.00735 
2025-02-26 05:57:17.727113: train_loss -0.9085 
2025-02-26 05:57:17.733129: val_loss -0.7038 
2025-02-26 05:57:17.737142: Pseudo dice [np.float32(0.6684), np.float32(0.8902)] 
2025-02-26 05:57:17.740653: Epoch time: 38.21 s 
2025-02-26 05:57:17.744169: Yayy! New best EMA pseudo Dice: 0.770799994468689 
2025-02-26 05:57:18.459531:  
2025-02-26 05:57:18.464141: Epoch 30 
2025-02-26 05:57:18.467187: Current learning rate: 0.00725 
2025-02-26 05:57:56.644174: train_loss -0.9009 
2025-02-26 05:57:56.651192: val_loss -0.7172 
2025-02-26 05:57:56.654204: Pseudo dice [np.float32(0.6881), np.float32(0.8912)] 
2025-02-26 05:57:56.657716: Epoch time: 38.19 s 
2025-02-26 05:57:56.661226: Yayy! New best EMA pseudo Dice: 0.7727000117301941 
2025-02-26 05:57:57.376953:  
2025-02-26 05:57:57.382498: Epoch 31 
2025-02-26 05:57:57.386063: Current learning rate: 0.00716 
2025-02-26 05:58:35.585316: train_loss -0.903 
2025-02-26 05:58:35.591999: val_loss -0.7079 
2025-02-26 05:58:35.595119: Pseudo dice [np.float32(0.6734), np.float32(0.8874)] 
2025-02-26 05:58:35.598308: Epoch time: 38.21 s 
2025-02-26 05:58:35.602321: Yayy! New best EMA pseudo Dice: 0.7735000252723694 
2025-02-26 05:58:36.319125:  
2025-02-26 05:58:36.324682: Epoch 32 
2025-02-26 05:58:36.328193: Current learning rate: 0.00707 
2025-02-26 05:59:14.531046: train_loss -0.9112 
2025-02-26 05:59:14.536657: val_loss -0.6965 
2025-02-26 05:59:14.540228: Pseudo dice [np.float32(0.6604), np.float32(0.8828)] 
2025-02-26 05:59:14.543766: Epoch time: 38.21 s 
2025-02-26 05:59:15.041602:  
2025-02-26 05:59:15.047138: Epoch 33 
2025-02-26 05:59:15.050677: Current learning rate: 0.00697 
2025-02-26 05:59:53.365943: train_loss -0.9176 
2025-02-26 05:59:53.372118: val_loss -0.708 
2025-02-26 05:59:53.375191: Pseudo dice [np.float32(0.6768), np.float32(0.8894)] 
2025-02-26 05:59:53.378744: Epoch time: 38.33 s 
2025-02-26 05:59:53.381893: Yayy! New best EMA pseudo Dice: 0.7742999792098999 
2025-02-26 05:59:54.101012:  
2025-02-26 05:59:54.107246: Epoch 34 
2025-02-26 05:59:54.110793: Current learning rate: 0.00688 
2025-02-26 06:00:32.539415: train_loss -0.9024 
2025-02-26 06:00:32.545075: val_loss -0.7011 
2025-02-26 06:00:32.548651: Pseudo dice [np.float32(0.6653), np.float32(0.8891)] 
2025-02-26 06:00:32.551721: Epoch time: 38.44 s 
2025-02-26 06:00:32.555265: Yayy! New best EMA pseudo Dice: 0.7745000123977661 
2025-02-26 06:00:33.287339:  
2025-02-26 06:00:33.292903: Epoch 35 
2025-02-26 06:00:33.295952: Current learning rate: 0.00679 
2025-02-26 06:01:11.575799: train_loss -0.9088 
2025-02-26 06:01:11.582344: val_loss -0.7179 
2025-02-26 06:01:11.585373: Pseudo dice [np.float32(0.6854), np.float32(0.8968)] 
2025-02-26 06:01:11.588958: Epoch time: 38.29 s 
2025-02-26 06:01:11.592009: Yayy! New best EMA pseudo Dice: 0.776199996471405 
2025-02-26 06:01:12.314854:  
2025-02-26 06:01:12.321151: Epoch 36 
2025-02-26 06:01:12.325172: Current learning rate: 0.00669 
2025-02-26 06:01:50.532955: train_loss -0.9137 
2025-02-26 06:01:50.541005: val_loss -0.7085 
2025-02-26 06:01:50.544510: Pseudo dice [np.float32(0.674), np.float32(0.8943)] 
2025-02-26 06:01:50.547522: Epoch time: 38.22 s 
2025-02-26 06:01:50.552034: Yayy! New best EMA pseudo Dice: 0.7770000100135803 
2025-02-26 06:01:51.277039:  
2025-02-26 06:01:51.281887: Epoch 37 
2025-02-26 06:01:51.285921: Current learning rate: 0.0066 
2025-02-26 06:02:29.492472: train_loss -0.9149 
2025-02-26 06:02:29.497496: val_loss -0.6983 
2025-02-26 06:02:29.501511: Pseudo dice [np.float32(0.6652), np.float32(0.8876)] 
2025-02-26 06:02:29.505032: Epoch time: 38.22 s 
2025-02-26 06:02:30.017014:  
2025-02-26 06:02:30.022053: Epoch 38 
2025-02-26 06:02:30.026139: Current learning rate: 0.0065 
2025-02-26 06:03:08.226589: train_loss -0.9046 
2025-02-26 06:03:08.232160: val_loss -0.7183 
2025-02-26 06:03:08.236213: Pseudo dice [np.float32(0.6902), np.float32(0.8923)] 
2025-02-26 06:03:08.240805: Epoch time: 38.21 s 
2025-02-26 06:03:08.244384: Yayy! New best EMA pseudo Dice: 0.7784000039100647 
2025-02-26 06:03:08.971250:  
2025-02-26 06:03:08.976297: Epoch 39 
2025-02-26 06:03:08.979857: Current learning rate: 0.00641 
2025-02-26 06:03:47.180931: train_loss -0.9119 
2025-02-26 06:03:47.186482: val_loss -0.707 
2025-02-26 06:03:47.189157: Pseudo dice [np.float32(0.6802), np.float32(0.8909)] 
2025-02-26 06:03:47.192708: Epoch time: 38.21 s 
2025-02-26 06:03:47.196291: Yayy! New best EMA pseudo Dice: 0.7791000008583069 
2025-02-26 06:03:47.924648:  
2025-02-26 06:03:47.930707: Epoch 40 
2025-02-26 06:03:47.934304: Current learning rate: 0.00631 
2025-02-26 06:04:26.160129: train_loss -0.9169 
2025-02-26 06:04:26.166203: val_loss -0.7118 
2025-02-26 06:04:26.169715: Pseudo dice [np.float32(0.6876), np.float32(0.8902)] 
2025-02-26 06:04:26.172223: Epoch time: 38.24 s 
2025-02-26 06:04:26.176236: Yayy! New best EMA pseudo Dice: 0.7800999879837036 
2025-02-26 06:04:26.901781:  
2025-02-26 06:04:26.907298: Epoch 41 
2025-02-26 06:04:26.910923: Current learning rate: 0.00622 
2025-02-26 06:05:05.112507: train_loss -0.9228 
2025-02-26 06:05:05.118615: val_loss -0.7011 
2025-02-26 06:05:05.122124: Pseudo dice [np.float32(0.6754), np.float32(0.8871)] 
2025-02-26 06:05:05.126136: Epoch time: 38.21 s 
2025-02-26 06:05:05.129647: Yayy! New best EMA pseudo Dice: 0.7802000045776367 
2025-02-26 06:05:05.833651:  
2025-02-26 06:05:05.839173: Epoch 42 
2025-02-26 06:05:05.842691: Current learning rate: 0.00612 
2025-02-26 06:05:44.035434: train_loss -0.9212 
2025-02-26 06:05:44.041586: val_loss -0.7147 
2025-02-26 06:05:44.044613: Pseudo dice [np.float32(0.6889), np.float32(0.8906)] 
2025-02-26 06:05:44.049165: Epoch time: 38.2 s 
2025-02-26 06:05:44.053247: Yayy! New best EMA pseudo Dice: 0.7810999751091003 
2025-02-26 06:05:44.900728:  
2025-02-26 06:05:44.906282: Epoch 43 
2025-02-26 06:05:44.910829: Current learning rate: 0.00603 
2025-02-26 06:06:23.106602: train_loss -0.9165 
2025-02-26 06:06:23.112201: val_loss -0.703 
2025-02-26 06:06:23.116231: Pseudo dice [np.float32(0.6756), np.float32(0.8891)] 
2025-02-26 06:06:23.119771: Epoch time: 38.21 s 
2025-02-26 06:06:23.123337: Yayy! New best EMA pseudo Dice: 0.7813000082969666 
2025-02-26 06:06:23.832536:  
2025-02-26 06:06:23.838617: Epoch 44 
2025-02-26 06:06:23.842684: Current learning rate: 0.00593 
2025-02-26 06:07:02.052043: train_loss -0.9257 
2025-02-26 06:07:02.058658: val_loss -0.6951 
2025-02-26 06:07:02.062300: Pseudo dice [np.float32(0.6684), np.float32(0.8901)] 
2025-02-26 06:07:02.066368: Epoch time: 38.22 s 
2025-02-26 06:07:02.558248:  
2025-02-26 06:07:02.564837: Epoch 45 
2025-02-26 06:07:02.568390: Current learning rate: 0.00584 
2025-02-26 06:07:40.767439: train_loss -0.9145 
2025-02-26 06:07:40.773571: val_loss -0.703 
2025-02-26 06:07:40.776083: Pseudo dice [np.float32(0.6784), np.float32(0.8879)] 
2025-02-26 06:07:40.779803: Epoch time: 38.21 s 
2025-02-26 06:07:40.783319: Yayy! New best EMA pseudo Dice: 0.7813000082969666 
2025-02-26 06:07:41.487494:  
2025-02-26 06:07:41.492609: Epoch 46 
2025-02-26 06:07:41.496203: Current learning rate: 0.00574 
2025-02-26 06:08:19.700302: train_loss -0.9295 
2025-02-26 06:08:19.705819: val_loss -0.703 
2025-02-26 06:08:19.709334: Pseudo dice [np.float32(0.6739), np.float32(0.8902)] 
2025-02-26 06:08:19.713341: Epoch time: 38.21 s 
2025-02-26 06:08:19.716855: Yayy! New best EMA pseudo Dice: 0.7813000082969666 
2025-02-26 06:08:20.425395:  
2025-02-26 06:08:20.431441: Epoch 47 
2025-02-26 06:08:20.434996: Current learning rate: 0.00565 
2025-02-26 06:08:58.623506: train_loss -0.9294 
2025-02-26 06:08:58.629161: val_loss -0.7106 
2025-02-26 06:08:58.633174: Pseudo dice [np.float32(0.6896), np.float32(0.89)] 
2025-02-26 06:08:58.636687: Epoch time: 38.2 s 
2025-02-26 06:08:58.640698: Yayy! New best EMA pseudo Dice: 0.7821999788284302 
2025-02-26 06:08:59.343895:  
2025-02-26 06:08:59.350517: Epoch 48 
2025-02-26 06:08:59.354595: Current learning rate: 0.00555 
2025-02-26 06:09:37.557017: train_loss -0.9305 
2025-02-26 06:09:37.563624: val_loss -0.708 
2025-02-26 06:09:37.567223: Pseudo dice [np.float32(0.6863), np.float32(0.8881)] 
2025-02-26 06:09:37.571281: Epoch time: 38.21 s 
2025-02-26 06:09:37.575375: Yayy! New best EMA pseudo Dice: 0.7827000021934509 
2025-02-26 06:09:38.282309:  
2025-02-26 06:09:38.287867: Epoch 49 
2025-02-26 06:09:38.292445: Current learning rate: 0.00546 
2025-02-26 06:10:16.499995: train_loss -0.907 
2025-02-26 06:10:16.506005: val_loss -0.6963 
2025-02-26 06:10:16.510018: Pseudo dice [np.float32(0.669), np.float32(0.8905)] 
2025-02-26 06:10:16.513523: Epoch time: 38.22 s 
2025-02-26 06:10:17.195883:  
2025-02-26 06:10:17.201942: Epoch 50 
2025-02-26 06:10:17.205998: Current learning rate: 0.00536 
2025-02-26 06:10:55.395876: train_loss -0.9082 
2025-02-26 06:10:55.403405: val_loss -0.7084 
2025-02-26 06:10:55.407422: Pseudo dice [np.float32(0.6899), np.float32(0.8909)] 
2025-02-26 06:10:55.410935: Epoch time: 38.2 s 
2025-02-26 06:10:55.414943: Yayy! New best EMA pseudo Dice: 0.7832000255584717 
2025-02-26 06:10:56.268005:  
2025-02-26 06:10:56.273595: Epoch 51 
2025-02-26 06:10:56.277702: Current learning rate: 0.00526 
2025-02-26 06:11:34.487704: train_loss -0.926 
2025-02-26 06:11:34.493859: val_loss -0.7018 
2025-02-26 06:11:34.498018: Pseudo dice [np.float32(0.6761), np.float32(0.8913)] 
2025-02-26 06:11:34.501590: Epoch time: 38.22 s 
2025-02-26 06:11:34.505697: Yayy! New best EMA pseudo Dice: 0.7832000255584717 
2025-02-26 06:11:35.220637:  
2025-02-26 06:11:35.227210: Epoch 52 
2025-02-26 06:11:35.230787: Current learning rate: 0.00517 
2025-02-26 06:12:13.413781: train_loss -0.9234 
2025-02-26 06:12:13.419807: val_loss -0.7064 
2025-02-26 06:12:13.423813: Pseudo dice [np.float32(0.6861), np.float32(0.891)] 
2025-02-26 06:12:13.428326: Epoch time: 38.19 s 
2025-02-26 06:12:13.432342: Yayy! New best EMA pseudo Dice: 0.7838000059127808 
2025-02-26 06:12:14.145504:  
2025-02-26 06:12:14.152606: Epoch 53 
2025-02-26 06:12:14.156741: Current learning rate: 0.00507 
2025-02-26 06:12:52.325221: train_loss -0.9245 
2025-02-26 06:12:52.331263: val_loss -0.7103 
2025-02-26 06:12:52.335273: Pseudo dice [np.float32(0.6879), np.float32(0.8951)] 
2025-02-26 06:12:52.338784: Epoch time: 38.18 s 
2025-02-26 06:12:52.342797: Yayy! New best EMA pseudo Dice: 0.784500002861023 
2025-02-26 06:12:53.064903:  
2025-02-26 06:12:53.070420: Epoch 54 
2025-02-26 06:12:53.074931: Current learning rate: 0.00497 
2025-02-26 06:13:31.277315: train_loss -0.932 
2025-02-26 06:13:31.283458: val_loss -0.6808 
2025-02-26 06:13:31.287508: Pseudo dice [np.float32(0.6613), np.float32(0.8858)] 
2025-02-26 06:13:31.290570: Epoch time: 38.21 s 
2025-02-26 06:13:31.785159:  
2025-02-26 06:13:31.791182: Epoch 55 
2025-02-26 06:13:31.795201: Current learning rate: 0.00487 
2025-02-26 06:14:09.985754: train_loss -0.922 
2025-02-26 06:14:09.992316: val_loss -0.7088 
2025-02-26 06:14:09.995892: Pseudo dice [np.float32(0.6787), np.float32(0.8958)] 
2025-02-26 06:14:10.000036: Epoch time: 38.2 s 
2025-02-26 06:14:10.493488:  
2025-02-26 06:14:10.499026: Epoch 56 
2025-02-26 06:14:10.502537: Current learning rate: 0.00478 
2025-02-26 06:14:48.719319: train_loss -0.9157 
2025-02-26 06:14:48.725511: val_loss -0.6926 
2025-02-26 06:14:48.729882: Pseudo dice [np.float32(0.6671), np.float32(0.8876)] 
2025-02-26 06:14:48.733963: Epoch time: 38.23 s 
2025-02-26 06:14:49.226933:  
2025-02-26 06:14:49.231951: Epoch 57 
2025-02-26 06:14:49.236464: Current learning rate: 0.00468 
2025-02-26 06:15:27.455703: train_loss -0.9249 
2025-02-26 06:15:27.461786: val_loss -0.6794 
2025-02-26 06:15:27.466328: Pseudo dice [np.float32(0.6478), np.float32(0.8876)] 
2025-02-26 06:15:27.469838: Epoch time: 38.23 s 
2025-02-26 06:15:27.966869:  
2025-02-26 06:15:27.972440: Epoch 58 
2025-02-26 06:15:27.977606: Current learning rate: 0.00458 
2025-02-26 06:16:06.176449: train_loss -0.9305 
2025-02-26 06:16:06.181459: val_loss -0.6962 
2025-02-26 06:16:06.185474: Pseudo dice [np.float32(0.6753), np.float32(0.8899)] 
2025-02-26 06:16:06.187980: Epoch time: 38.21 s 
2025-02-26 06:16:06.838074:  
2025-02-26 06:16:06.843335: Epoch 59 
2025-02-26 06:16:06.846888: Current learning rate: 0.00448 
2025-02-26 06:16:45.032979: train_loss -0.9356 
2025-02-26 06:16:45.038518: val_loss -0.6985 
2025-02-26 06:16:45.042027: Pseudo dice [np.float32(0.6785), np.float32(0.8917)] 
2025-02-26 06:16:45.044536: Epoch time: 38.2 s 
2025-02-26 06:16:45.544505:  
2025-02-26 06:16:45.550023: Epoch 60 
2025-02-26 06:16:45.552533: Current learning rate: 0.00438 
2025-02-26 06:17:23.754977: train_loss -0.9215 
2025-02-26 06:17:23.761093: val_loss -0.704 
2025-02-26 06:17:23.764138: Pseudo dice [np.float32(0.6849), np.float32(0.889)] 
2025-02-26 06:17:23.767171: Epoch time: 38.21 s 
2025-02-26 06:17:24.264879:  
2025-02-26 06:17:24.270946: Epoch 61 
2025-02-26 06:17:24.276545: Current learning rate: 0.00429 
2025-02-26 06:18:02.484066: train_loss -0.9231 
2025-02-26 06:18:02.489695: val_loss -0.7101 
2025-02-26 06:18:02.493329: Pseudo dice [np.float32(0.69), np.float32(0.896)] 
2025-02-26 06:18:02.497431: Epoch time: 38.22 s 
2025-02-26 06:18:02.999469:  
2025-02-26 06:18:03.005547: Epoch 62 
2025-02-26 06:18:03.009261: Current learning rate: 0.00419 
2025-02-26 06:18:41.203172: train_loss -0.9289 
2025-02-26 06:18:41.209361: val_loss -0.6827 
2025-02-26 06:18:41.212421: Pseudo dice [np.float32(0.6601), np.float32(0.89)] 
2025-02-26 06:18:41.215504: Epoch time: 38.2 s 
2025-02-26 06:18:41.715733:  
2025-02-26 06:18:41.720753: Epoch 63 
2025-02-26 06:18:41.724263: Current learning rate: 0.00409 
2025-02-26 06:19:19.922764: train_loss -0.9282 
2025-02-26 06:19:19.927872: val_loss -0.6942 
2025-02-26 06:19:19.931450: Pseudo dice [np.float32(0.6767), np.float32(0.8895)] 
2025-02-26 06:19:19.934538: Epoch time: 38.21 s 
2025-02-26 06:19:20.437539:  
2025-02-26 06:19:20.443115: Epoch 64 
2025-02-26 06:19:20.446157: Current learning rate: 0.00399 
2025-02-26 06:19:58.650113: train_loss -0.921 
2025-02-26 06:19:58.657629: val_loss -0.6827 
2025-02-26 06:19:58.661137: Pseudo dice [np.float32(0.6663), np.float32(0.8882)] 
2025-02-26 06:19:58.664149: Epoch time: 38.21 s 
2025-02-26 06:19:59.159332:  
2025-02-26 06:19:59.164852: Epoch 65 
2025-02-26 06:19:59.167364: Current learning rate: 0.00389 
2025-02-26 06:20:37.367785: train_loss -0.9334 
2025-02-26 06:20:37.372957: val_loss -0.696 
2025-02-26 06:20:37.376476: Pseudo dice [np.float32(0.679), np.float32(0.8914)] 
2025-02-26 06:20:37.380492: Epoch time: 38.21 s 
2025-02-26 06:20:37.877994:  
2025-02-26 06:20:37.883572: Epoch 66 
2025-02-26 06:20:37.887131: Current learning rate: 0.00379 
2025-02-26 06:21:16.068692: train_loss -0.9378 
2025-02-26 06:21:16.075209: val_loss -0.6895 
2025-02-26 06:21:16.078717: Pseudo dice [np.float32(0.6637), np.float32(0.8915)] 
2025-02-26 06:21:16.081227: Epoch time: 38.19 s 
2025-02-26 06:21:16.722472:  
2025-02-26 06:21:16.728599: Epoch 67 
2025-02-26 06:21:16.731674: Current learning rate: 0.00369 
2025-02-26 06:21:54.929712: train_loss -0.9337 
2025-02-26 06:21:54.935284: val_loss -0.6897 
2025-02-26 06:21:54.941476: Pseudo dice [np.float32(0.6699), np.float32(0.8917)] 
2025-02-26 06:21:54.944527: Epoch time: 38.21 s 
2025-02-26 06:21:55.451773:  
2025-02-26 06:21:55.457872: Epoch 68 
2025-02-26 06:21:55.461018: Current learning rate: 0.00359 
2025-02-26 06:22:33.647666: train_loss -0.9392 
2025-02-26 06:22:33.653351: val_loss -0.7009 
2025-02-26 06:22:33.656415: Pseudo dice [np.float32(0.6846), np.float32(0.8934)] 
2025-02-26 06:22:33.659950: Epoch time: 38.2 s 
2025-02-26 06:22:34.166310:  
2025-02-26 06:22:34.171828: Epoch 69 
2025-02-26 06:22:34.174335: Current learning rate: 0.00349 
2025-02-26 06:23:12.371555: train_loss -0.9297 
2025-02-26 06:23:12.377582: val_loss -0.6865 
2025-02-26 06:23:12.381596: Pseudo dice [np.float32(0.6607), np.float32(0.8898)] 
2025-02-26 06:23:12.384942: Epoch time: 38.21 s 
2025-02-26 06:23:12.890557:  
2025-02-26 06:23:12.896074: Epoch 70 
2025-02-26 06:23:12.899588: Current learning rate: 0.00338 
2025-02-26 06:23:51.085507: train_loss -0.9332 
2025-02-26 06:23:51.091224: val_loss -0.7127 
2025-02-26 06:23:51.093742: Pseudo dice [np.float32(0.6937), np.float32(0.8965)] 
2025-02-26 06:23:51.097270: Epoch time: 38.2 s 
2025-02-26 06:23:51.609612:  
2025-02-26 06:23:51.614625: Epoch 71 
2025-02-26 06:23:51.618134: Current learning rate: 0.00328 
2025-02-26 06:24:29.816061: train_loss -0.9207 
2025-02-26 06:24:29.821625: val_loss -0.6931 
2025-02-26 06:24:29.825635: Pseudo dice [np.float32(0.6738), np.float32(0.8932)] 
2025-02-26 06:24:29.828141: Epoch time: 38.21 s 
2025-02-26 06:24:30.345491:  
2025-02-26 06:24:30.352125: Epoch 72 
2025-02-26 06:24:30.354678: Current learning rate: 0.00318 
2025-02-26 06:25:08.559412: train_loss -0.9398 
2025-02-26 06:25:08.565001: val_loss -0.6992 
2025-02-26 06:25:08.568047: Pseudo dice [np.float32(0.686), np.float32(0.8924)] 
2025-02-26 06:25:08.571080: Epoch time: 38.21 s 
2025-02-26 06:25:09.079907:  
2025-02-26 06:25:09.085425: Epoch 73 
2025-02-26 06:25:09.088941: Current learning rate: 0.00308 
2025-02-26 06:25:47.311952: train_loss -0.9381 
2025-02-26 06:25:47.317001: val_loss -0.6957 
2025-02-26 06:25:47.320563: Pseudo dice [np.float32(0.6844), np.float32(0.89)] 
2025-02-26 06:25:47.324087: Epoch time: 38.23 s 
2025-02-26 06:25:47.844378:  
2025-02-26 06:25:47.849392: Epoch 74 
2025-02-26 06:25:47.852901: Current learning rate: 0.00297 
2025-02-26 06:26:26.074429: train_loss -0.9238 
2025-02-26 06:26:26.080446: val_loss -0.69 
2025-02-26 06:26:26.083457: Pseudo dice [np.float32(0.6712), np.float32(0.8928)] 
2025-02-26 06:26:26.086968: Epoch time: 38.23 s 
2025-02-26 06:26:26.745391:  
2025-02-26 06:26:26.751450: Epoch 75 
2025-02-26 06:26:26.754961: Current learning rate: 0.00287 
2025-02-26 06:27:04.955576: train_loss -0.9387 
2025-02-26 06:27:04.960652: val_loss -0.691 
2025-02-26 06:27:04.964178: Pseudo dice [np.float32(0.6737), np.float32(0.8924)] 
2025-02-26 06:27:04.967231: Epoch time: 38.21 s 
2025-02-26 06:27:05.472891:  
2025-02-26 06:27:05.478026: Epoch 76 
2025-02-26 06:27:05.482549: Current learning rate: 0.00277 
2025-02-26 06:27:43.678460: train_loss -0.9298 
2025-02-26 06:27:43.684012: val_loss -0.6922 
2025-02-26 06:27:43.687066: Pseudo dice [np.float32(0.6815), np.float32(0.8915)] 
2025-02-26 06:27:43.690616: Epoch time: 38.21 s 
2025-02-26 06:27:44.196863:  
2025-02-26 06:27:44.202409: Epoch 77 
2025-02-26 06:27:44.206462: Current learning rate: 0.00266 
2025-02-26 06:28:22.413321: train_loss -0.94 
2025-02-26 06:28:22.419363: val_loss -0.68 
2025-02-26 06:28:22.423136: Pseudo dice [np.float32(0.6745), np.float32(0.8884)] 
2025-02-26 06:28:22.425648: Epoch time: 38.22 s 
2025-02-26 06:28:22.943777:  
2025-02-26 06:28:22.949352: Epoch 78 
2025-02-26 06:28:22.953389: Current learning rate: 0.00256 
2025-02-26 06:29:01.147259: train_loss -0.9449 
2025-02-26 06:29:01.152910: val_loss -0.6769 
2025-02-26 06:29:01.155973: Pseudo dice [np.float32(0.6598), np.float32(0.8907)] 
2025-02-26 06:29:01.159016: Epoch time: 38.2 s 
2025-02-26 06:29:01.676759:  
2025-02-26 06:29:01.681790: Epoch 79 
2025-02-26 06:29:01.684426: Current learning rate: 0.00245 
2025-02-26 06:29:39.881610: train_loss -0.9338 
2025-02-26 06:29:39.887191: val_loss -0.6921 
2025-02-26 06:29:39.889777: Pseudo dice [np.float32(0.6814), np.float32(0.8896)] 
2025-02-26 06:29:39.893337: Epoch time: 38.21 s 
2025-02-26 06:29:40.408374:  
2025-02-26 06:29:40.413420: Epoch 80 
2025-02-26 06:29:40.417192: Current learning rate: 0.00235 
2025-02-26 06:30:18.627463: train_loss -0.9328 
2025-02-26 06:30:18.632551: val_loss -0.6888 
2025-02-26 06:30:18.636560: Pseudo dice [np.float32(0.677), np.float32(0.8914)] 
2025-02-26 06:30:18.640073: Epoch time: 38.22 s 
2025-02-26 06:30:19.153559:  
2025-02-26 06:30:19.158734: Epoch 81 
2025-02-26 06:30:19.162244: Current learning rate: 0.00224 
2025-02-26 06:30:57.355737: train_loss -0.9286 
2025-02-26 06:30:57.361854: val_loss -0.6909 
2025-02-26 06:30:57.364546: Pseudo dice [np.float32(0.6847), np.float32(0.8925)] 
2025-02-26 06:30:57.368590: Epoch time: 38.2 s 
2025-02-26 06:30:58.026538:  
2025-02-26 06:30:58.031570: Epoch 82 
2025-02-26 06:30:58.034388: Current learning rate: 0.00214 
2025-02-26 06:31:36.235841: train_loss -0.9405 
2025-02-26 06:31:36.241913: val_loss -0.6849 
2025-02-26 06:31:36.244969: Pseudo dice [np.float32(0.6779), np.float32(0.8908)] 
2025-02-26 06:31:36.248035: Epoch time: 38.21 s 
2025-02-26 06:31:36.737083:  
2025-02-26 06:31:36.742730: Epoch 83 
2025-02-26 06:31:36.746242: Current learning rate: 0.00203 
2025-02-26 06:32:14.927008: train_loss -0.9293 
2025-02-26 06:32:14.932621: val_loss -0.685 
2025-02-26 06:32:14.936134: Pseudo dice [np.float32(0.6766), np.float32(0.889)] 
2025-02-26 06:32:14.939643: Epoch time: 38.19 s 
2025-02-26 06:32:15.436101:  
2025-02-26 06:32:15.441114: Epoch 84 
2025-02-26 06:32:15.444626: Current learning rate: 0.00192 
2025-02-26 06:32:53.634334: train_loss -0.9367 
2025-02-26 06:32:53.639251: val_loss -0.6919 
2025-02-26 06:32:53.643348: Pseudo dice [np.float32(0.6811), np.float32(0.8938)] 
2025-02-26 06:32:53.646491: Epoch time: 38.2 s 
2025-02-26 06:32:54.131735:  
2025-02-26 06:32:54.136752: Epoch 85 
2025-02-26 06:32:54.140263: Current learning rate: 0.00181 
2025-02-26 06:33:32.324733: train_loss -0.942 
2025-02-26 06:33:32.331250: val_loss -0.6882 
2025-02-26 06:33:32.334761: Pseudo dice [np.float32(0.6824), np.float32(0.8914)] 
2025-02-26 06:33:32.337275: Epoch time: 38.19 s 
2025-02-26 06:33:32.825769:  
2025-02-26 06:33:32.830782: Epoch 86 
2025-02-26 06:33:32.834295: Current learning rate: 0.0017 
2025-02-26 06:34:11.029489: train_loss -0.9414 
2025-02-26 06:34:11.035588: val_loss -0.6877 
2025-02-26 06:34:11.038140: Pseudo dice [np.float32(0.6751), np.float32(0.8928)] 
2025-02-26 06:34:11.042173: Epoch time: 38.21 s 
2025-02-26 06:34:11.523711:  
2025-02-26 06:34:11.528735: Epoch 87 
2025-02-26 06:34:11.532351: Current learning rate: 0.00159 
2025-02-26 06:34:49.745630: train_loss -0.9358 
2025-02-26 06:34:49.751322: val_loss -0.6759 
2025-02-26 06:34:49.754372: Pseudo dice [np.float32(0.6655), np.float32(0.8929)] 
2025-02-26 06:34:49.757924: Epoch time: 38.22 s 
2025-02-26 06:34:50.242851:  
2025-02-26 06:34:50.248448: Epoch 88 
2025-02-26 06:34:50.252004: Current learning rate: 0.00148 
2025-02-26 06:35:28.462006: train_loss -0.9405 
2025-02-26 06:35:28.468683: val_loss -0.6855 
2025-02-26 06:35:28.471725: Pseudo dice [np.float32(0.6815), np.float32(0.8908)] 
2025-02-26 06:35:28.475288: Epoch time: 38.22 s 
2025-02-26 06:35:28.962852:  
2025-02-26 06:35:28.969042: Epoch 89 
2025-02-26 06:35:28.972580: Current learning rate: 0.00137 
2025-02-26 06:36:07.178210: train_loss -0.9419 
2025-02-26 06:36:07.185255: val_loss -0.6758 
2025-02-26 06:36:07.188768: Pseudo dice [np.float32(0.6664), np.float32(0.8914)] 
2025-02-26 06:36:07.192779: Epoch time: 38.22 s 
2025-02-26 06:36:07.828616:  
2025-02-26 06:36:07.834131: Epoch 90 
2025-02-26 06:36:07.837639: Current learning rate: 0.00126 
2025-02-26 06:36:46.031090: train_loss -0.9448 
2025-02-26 06:36:46.036743: val_loss -0.661 
2025-02-26 06:36:46.040304: Pseudo dice [np.float32(0.6523), np.float32(0.8889)] 
2025-02-26 06:36:46.043356: Epoch time: 38.2 s 
2025-02-26 06:36:46.540025:  
2025-02-26 06:36:46.546220: Epoch 91 
2025-02-26 06:36:46.549743: Current learning rate: 0.00115 
2025-02-26 06:37:24.747777: train_loss -0.9438 
2025-02-26 06:37:24.753931: val_loss -0.6779 
2025-02-26 06:37:24.756444: Pseudo dice [np.float32(0.6721), np.float32(0.8923)] 
2025-02-26 06:37:24.760503: Epoch time: 38.21 s 
2025-02-26 06:37:25.245807:  
2025-02-26 06:37:25.250853: Epoch 92 
2025-02-26 06:37:25.253585: Current learning rate: 0.00103 
2025-02-26 06:38:03.456043: train_loss -0.9386 
2025-02-26 06:38:03.463140: val_loss -0.6868 
2025-02-26 06:38:03.466761: Pseudo dice [np.float32(0.679), np.float32(0.8926)] 
2025-02-26 06:38:03.469496: Epoch time: 38.21 s 
2025-02-26 06:38:03.951780:  
2025-02-26 06:38:03.957297: Epoch 93 
2025-02-26 06:38:03.960809: Current learning rate: 0.00091 
2025-02-26 06:38:42.181016: train_loss -0.9285 
2025-02-26 06:38:42.187566: val_loss -0.6966 
2025-02-26 06:38:42.190577: Pseudo dice [np.float32(0.692), np.float32(0.8951)] 
2025-02-26 06:38:42.194089: Epoch time: 38.23 s 
2025-02-26 06:38:42.680261:  
2025-02-26 06:38:42.686320: Epoch 94 
2025-02-26 06:38:42.689353: Current learning rate: 0.00079 
2025-02-26 06:39:20.888435: train_loss -0.9418 
2025-02-26 06:39:20.894044: val_loss -0.6877 
2025-02-26 06:39:20.897200: Pseudo dice [np.float32(0.6796), np.float32(0.8937)] 
2025-02-26 06:39:20.900738: Epoch time: 38.21 s 
2025-02-26 06:39:21.385094:  
2025-02-26 06:39:21.390610: Epoch 95 
2025-02-26 06:39:21.394118: Current learning rate: 0.00067 
2025-02-26 06:39:59.599365: train_loss -0.9314 
2025-02-26 06:39:59.605986: val_loss -0.687 
2025-02-26 06:39:59.609034: Pseudo dice [np.float32(0.6836), np.float32(0.8926)] 
2025-02-26 06:39:59.611575: Epoch time: 38.22 s 
2025-02-26 06:40:00.099008:  
2025-02-26 06:40:00.104021: Epoch 96 
2025-02-26 06:40:00.107530: Current learning rate: 0.00055 
2025-02-26 06:40:38.322273: train_loss -0.9503 
2025-02-26 06:40:38.327818: val_loss -0.6794 
2025-02-26 06:40:38.331831: Pseudo dice [np.float32(0.6748), np.float32(0.8922)] 
2025-02-26 06:40:38.335344: Epoch time: 38.22 s 
2025-02-26 06:40:38.825440:  
2025-02-26 06:40:38.830994: Epoch 97 
2025-02-26 06:40:38.835042: Current learning rate: 0.00043 
2025-02-26 06:41:17.037039: train_loss -0.9465 
2025-02-26 06:41:17.043195: val_loss -0.6801 
2025-02-26 06:41:17.046254: Pseudo dice [np.float32(0.6798), np.float32(0.892)] 
2025-02-26 06:41:17.049833: Epoch time: 38.21 s 
2025-02-26 06:41:17.557377:  
2025-02-26 06:41:17.562891: Epoch 98 
2025-02-26 06:41:17.566403: Current learning rate: 0.0003 
2025-02-26 06:41:55.847564: train_loss -0.9384 
2025-02-26 06:41:55.853580: val_loss -0.6757 
2025-02-26 06:41:55.856591: Pseudo dice [np.float32(0.6693), np.float32(0.8919)] 
2025-02-26 06:41:55.860101: Epoch time: 38.29 s 
2025-02-26 06:41:56.349921:  
2025-02-26 06:41:56.355443: Epoch 99 
2025-02-26 06:41:56.358960: Current learning rate: 0.00016 
2025-02-26 06:42:34.544367: train_loss -0.9358 
2025-02-26 06:42:34.549964: val_loss -0.6869 
2025-02-26 06:42:34.554084: Pseudo dice [np.float32(0.6863), np.float32(0.8943)] 
2025-02-26 06:42:34.556633: Epoch time: 38.2 s 
2025-02-26 06:42:34.561217: Yayy! New best EMA pseudo Dice: 0.7846999764442444 
2025-02-26 06:42:35.537655: Training done. 
2025-02-26 06:42:35.570656: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset005_Prostate\splits_final.json 
2025-02-26 06:42:35.576656: The split file contains 5 splits. 
2025-02-26 06:42:35.580656: Desired fold for training: 0 
2025-02-26 06:42:35.584659: This split has 25 training and 7 validation cases. 
2025-02-26 06:42:35.590657: predicting prostate_00 
2025-02-26 06:42:35.596662: prostate_00, shape torch.Size([2, 17, 307, 307]), rank 0 
2025-02-26 06:42:36.540318: predicting prostate_04 
2025-02-26 06:42:36.548345: prostate_04, shape torch.Size([2, 17, 306, 307]), rank 0 
2025-02-26 06:42:36.891957: predicting prostate_14 
2025-02-26 06:42:36.899960: prostate_14, shape torch.Size([2, 20, 320, 319]), rank 0 
2025-02-26 06:42:37.242277: predicting prostate_20 
2025-02-26 06:42:37.250279: prostate_20, shape torch.Size([2, 20, 320, 320]), rank 0 
2025-02-26 06:42:37.594355: predicting prostate_25 
2025-02-26 06:42:37.603356: prostate_25, shape torch.Size([2, 19, 320, 319]), rank 0 
2025-02-26 06:42:37.950388: predicting prostate_31 
2025-02-26 06:42:37.958389: prostate_31, shape torch.Size([2, 20, 320, 319]), rank 0 
2025-02-26 06:42:38.302563: predicting prostate_42 
2025-02-26 06:42:38.310069: prostate_42, shape torch.Size([2, 22, 320, 319]), rank 0 
2025-02-26 06:42:45.882341: Validation complete 
2025-02-26 06:42:45.887341: Mean Validation Dice:  0.7090658901377362 
