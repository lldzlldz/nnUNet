
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-11 15:18:49.179828: do_dummy_2d_data_aug: True 
2025-03-11 15:18:49.181996: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset005_Prostate\splits_final.json 
2025-03-11 15:18:49.189688: The split file contains 5 splits. 
2025-03-11 15:18:49.191930: Desired fold for training: 0 
2025-03-11 15:18:49.195148: This split has 25 training and 7 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [20, 320, 256], 'median_image_size_in_voxels': [20.0, 320.0, 319.0], 'spacing': [3.5999999046325684, 0.625, 0.625], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset005_Prostate', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.5999999046325684, 0.625, 0.625], 'original_median_shape_after_transp': [20, 320, 320], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1326.0, 'mean': 350.18780517578125, 'median': 327.0, 'min': 0.0, 'percentile_00_5': 83.0, 'percentile_99_5': 822.0, 'std': 139.9563751220703}, '1': {'max': 3698.0, 'mean': 1351.1083984375, 'median': 1364.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 2563.0, 'std': 376.4326477050781}}} 
 
2025-03-11 15:18:57.686843: unpacking dataset... 
2025-03-11 15:18:58.209686: unpacking done... 
2025-03-11 15:19:01.304430:  
2025-03-11 15:19:01.309479: Epoch 0 
2025-03-11 15:19:01.313508: Current learning rate: 0.01 
2025-03-11 15:19:43.970592: train_loss -0.1792 
2025-03-11 15:19:43.976895: val_loss -0.4982 
2025-03-11 15:19:43.980604: Pseudo dice [np.float32(0.3943), np.float32(0.8297)] 
2025-03-11 15:19:43.983299: Epoch time: 42.67 s 
2025-03-11 15:19:43.987079: Yayy! New best EMA pseudo Dice: 0.6119999885559082 
2025-03-11 15:19:44.696503:  
2025-03-11 15:19:44.702270: Epoch 1 
2025-03-11 15:19:44.705962: Current learning rate: 0.00991 
2025-03-11 15:20:22.982688: train_loss -0.5285 
2025-03-11 15:20:22.991064: val_loss -0.6238 
2025-03-11 15:20:22.994178: Pseudo dice [np.float32(0.5578), np.float32(0.8495)] 
2025-03-11 15:20:22.997780: Epoch time: 38.29 s 
2025-03-11 15:20:23.000926: Yayy! New best EMA pseudo Dice: 0.6212000250816345 
2025-03-11 15:20:23.793922:  
2025-03-11 15:20:23.799709: Epoch 2 
2025-03-11 15:20:23.802799: Current learning rate: 0.00982 
2025-03-11 15:21:02.058412: train_loss -0.6447 
2025-03-11 15:21:02.064194: val_loss -0.5871 
2025-03-11 15:21:02.068635: Pseudo dice [np.float32(0.5263), np.float32(0.8024)] 
2025-03-11 15:21:02.071903: Epoch time: 38.27 s 
2025-03-11 15:21:02.075182: Yayy! New best EMA pseudo Dice: 0.6255000233650208 
2025-03-11 15:21:02.922193:  
2025-03-11 15:21:02.928319: Epoch 3 
2025-03-11 15:21:02.931401: Current learning rate: 0.00973 
2025-03-11 15:21:41.234249: train_loss -0.674 
2025-03-11 15:21:41.239997: val_loss -0.6516 
2025-03-11 15:21:41.243607: Pseudo dice [np.float32(0.6013), np.float32(0.8489)] 
2025-03-11 15:21:41.247201: Epoch time: 38.31 s 
2025-03-11 15:21:41.250275: Yayy! New best EMA pseudo Dice: 0.6353999972343445 
2025-03-11 15:21:42.058695:  
2025-03-11 15:21:42.065474: Epoch 4 
2025-03-11 15:21:42.068609: Current learning rate: 0.00964 
2025-03-11 15:22:20.351308: train_loss -0.7131 
2025-03-11 15:22:20.357589: val_loss -0.6374 
2025-03-11 15:22:20.360611: Pseudo dice [np.float32(0.5785), np.float32(0.8388)] 
2025-03-11 15:22:20.364140: Epoch time: 38.29 s 
2025-03-11 15:22:20.367841: Yayy! New best EMA pseudo Dice: 0.642799973487854 
2025-03-11 15:22:21.306279:  
2025-03-11 15:22:21.313282: Epoch 5 
2025-03-11 15:22:21.316867: Current learning rate: 0.00955 
2025-03-11 15:22:59.548595: train_loss -0.7592 
2025-03-11 15:22:59.554857: val_loss -0.7004 
2025-03-11 15:22:59.558503: Pseudo dice [np.float32(0.6511), np.float32(0.872)] 
2025-03-11 15:22:59.561622: Epoch time: 38.24 s 
2025-03-11 15:22:59.565256: Yayy! New best EMA pseudo Dice: 0.6546000242233276 
2025-03-11 15:23:00.363529:  
2025-03-11 15:23:00.368747: Epoch 6 
2025-03-11 15:23:00.371870: Current learning rate: 0.00946 
2025-03-11 15:23:38.635499: train_loss -0.7831 
2025-03-11 15:23:38.641166: val_loss -0.6895 
2025-03-11 15:23:38.644384: Pseudo dice [np.float32(0.6362), np.float32(0.8722)] 
2025-03-11 15:23:38.648037: Epoch time: 38.27 s 
2025-03-11 15:23:38.651132: Yayy! New best EMA pseudo Dice: 0.6646000146865845 
2025-03-11 15:23:39.464348:  
2025-03-11 15:23:39.470008: Epoch 7 
2025-03-11 15:23:39.473560: Current learning rate: 0.00937 
2025-03-11 15:24:17.710442: train_loss -0.7978 
2025-03-11 15:24:17.716158: val_loss -0.6776 
2025-03-11 15:24:17.720214: Pseudo dice [np.float32(0.6307), np.float32(0.8682)] 
2025-03-11 15:24:17.722769: Epoch time: 38.25 s 
2025-03-11 15:24:17.726383: Yayy! New best EMA pseudo Dice: 0.6730999946594238 
2025-03-11 15:24:18.559507:  
2025-03-11 15:24:18.565266: Epoch 8 
2025-03-11 15:24:18.568896: Current learning rate: 0.00928 
2025-03-11 15:24:56.834996: train_loss -0.8081 
2025-03-11 15:24:56.841192: val_loss -0.6944 
2025-03-11 15:24:56.845438: Pseudo dice [np.float32(0.6488), np.float32(0.8743)] 
2025-03-11 15:24:56.849063: Epoch time: 38.28 s 
2025-03-11 15:24:56.852177: Yayy! New best EMA pseudo Dice: 0.6819000244140625 
2025-03-11 15:24:57.688290:  
2025-03-11 15:24:57.694383: Epoch 9 
2025-03-11 15:24:57.698411: Current learning rate: 0.00919 
2025-03-11 15:25:35.962909: train_loss -0.8222 
2025-03-11 15:25:35.969478: val_loss -0.7027 
2025-03-11 15:25:35.972589: Pseudo dice [np.float32(0.6468), np.float32(0.8755)] 
2025-03-11 15:25:35.976148: Epoch time: 38.28 s 
2025-03-11 15:25:35.979316: Yayy! New best EMA pseudo Dice: 0.6898000240325928 
2025-03-11 15:25:36.812043:  
2025-03-11 15:25:36.817737: Epoch 10 
2025-03-11 15:25:36.821354: Current learning rate: 0.0091 
2025-03-11 15:26:15.077962: train_loss -0.8288 
2025-03-11 15:26:15.084671: val_loss -0.694 
2025-03-11 15:26:15.088771: Pseudo dice [np.float32(0.6395), np.float32(0.8822)] 
2025-03-11 15:26:15.091878: Epoch time: 38.27 s 
2025-03-11 15:26:15.094996: Yayy! New best EMA pseudo Dice: 0.6970000267028809 
2025-03-11 15:26:15.895302:  
2025-03-11 15:26:15.900876: Epoch 11 
2025-03-11 15:26:15.905241: Current learning rate: 0.009 
2025-03-11 15:26:54.145916: train_loss -0.8333 
2025-03-11 15:26:54.152068: val_loss -0.7135 
2025-03-11 15:26:54.155703: Pseudo dice [np.float32(0.6669), np.float32(0.8842)] 
2025-03-11 15:26:54.158870: Epoch time: 38.25 s 
2025-03-11 15:26:54.162032: Yayy! New best EMA pseudo Dice: 0.704800009727478 
2025-03-11 15:26:54.947220:  
2025-03-11 15:26:54.952393: Epoch 12 
2025-03-11 15:26:54.955980: Current learning rate: 0.00891 
2025-03-11 15:27:33.228618: train_loss -0.8433 
2025-03-11 15:27:33.235312: val_loss -0.704 
2025-03-11 15:27:33.239085: Pseudo dice [np.float32(0.6598), np.float32(0.8803)] 
2025-03-11 15:27:33.242757: Epoch time: 38.28 s 
2025-03-11 15:27:33.246630: Yayy! New best EMA pseudo Dice: 0.7113000154495239 
2025-03-11 15:27:34.212620:  
2025-03-11 15:27:34.218765: Epoch 13 
2025-03-11 15:27:34.221916: Current learning rate: 0.00882 
2025-03-11 15:28:12.457141: train_loss -0.8404 
2025-03-11 15:28:12.462971: val_loss -0.7024 
2025-03-11 15:28:12.466118: Pseudo dice [np.float32(0.649), np.float32(0.8791)] 
2025-03-11 15:28:12.468693: Epoch time: 38.25 s 
2025-03-11 15:28:12.472276: Yayy! New best EMA pseudo Dice: 0.7166000008583069 
2025-03-11 15:28:13.282692:  
2025-03-11 15:28:13.288395: Epoch 14 
2025-03-11 15:28:13.291991: Current learning rate: 0.00873 
2025-03-11 15:28:51.528211: train_loss -0.8497 
2025-03-11 15:28:51.534562: val_loss -0.6903 
2025-03-11 15:28:51.537677: Pseudo dice [np.float32(0.6331), np.float32(0.873)] 
2025-03-11 15:28:51.540765: Epoch time: 38.25 s 
2025-03-11 15:28:51.543825: Yayy! New best EMA pseudo Dice: 0.7202000021934509 
2025-03-11 15:28:52.352148:  
2025-03-11 15:28:52.357842: Epoch 15 
2025-03-11 15:28:52.360939: Current learning rate: 0.00864 
2025-03-11 15:29:30.629506: train_loss -0.864 
2025-03-11 15:29:30.634718: val_loss -0.7024 
2025-03-11 15:29:30.639333: Pseudo dice [np.float32(0.651), np.float32(0.8777)] 
2025-03-11 15:29:30.642490: Epoch time: 38.28 s 
2025-03-11 15:29:30.645653: Yayy! New best EMA pseudo Dice: 0.7246999740600586 
2025-03-11 15:29:31.461663:  
2025-03-11 15:29:31.469480: Epoch 16 
2025-03-11 15:29:31.473114: Current learning rate: 0.00855 
2025-03-11 15:30:09.733484: train_loss -0.853 
2025-03-11 15:30:09.740226: val_loss -0.6976 
2025-03-11 15:30:09.743342: Pseudo dice [np.float32(0.644), np.float32(0.8847)] 
2025-03-11 15:30:09.747007: Epoch time: 38.27 s 
2025-03-11 15:30:09.750103: Yayy! New best EMA pseudo Dice: 0.728600025177002 
2025-03-11 15:30:10.568570:  
2025-03-11 15:30:10.574239: Epoch 17 
2025-03-11 15:30:10.577555: Current learning rate: 0.00846 
2025-03-11 15:30:48.823528: train_loss -0.8775 
2025-03-11 15:30:48.829573: val_loss -0.7028 
2025-03-11 15:30:48.833628: Pseudo dice [np.float32(0.6567), np.float32(0.8817)] 
2025-03-11 15:30:48.836795: Epoch time: 38.26 s 
2025-03-11 15:30:48.840860: Yayy! New best EMA pseudo Dice: 0.732699990272522 
2025-03-11 15:30:49.666669:  
2025-03-11 15:30:49.672360: Epoch 18 
2025-03-11 15:30:49.676419: Current learning rate: 0.00836 
2025-03-11 15:31:27.960741: train_loss -0.8657 
2025-03-11 15:31:27.967315: val_loss -0.7023 
2025-03-11 15:31:27.970859: Pseudo dice [np.float32(0.6434), np.float32(0.8882)] 
2025-03-11 15:31:27.974397: Epoch time: 38.29 s 
2025-03-11 15:31:27.977948: Yayy! New best EMA pseudo Dice: 0.7360000014305115 
2025-03-11 15:31:28.797845:  
2025-03-11 15:31:28.804467: Epoch 19 
2025-03-11 15:31:28.808258: Current learning rate: 0.00827 
2025-03-11 15:32:07.151343: train_loss -0.8722 
2025-03-11 15:32:07.157973: val_loss -0.7058 
2025-03-11 15:32:07.161689: Pseudo dice [np.float32(0.6619), np.float32(0.8856)] 
2025-03-11 15:32:07.164826: Epoch time: 38.35 s 
2025-03-11 15:32:07.168424: Yayy! New best EMA pseudo Dice: 0.739799976348877 
2025-03-11 15:32:08.002674:  
2025-03-11 15:32:08.008412: Epoch 20 
2025-03-11 15:32:08.012120: Current learning rate: 0.00818 
2025-03-11 15:32:46.281797: train_loss -0.8744 
2025-03-11 15:32:46.289039: val_loss -0.7028 
2025-03-11 15:32:46.292131: Pseudo dice [np.float32(0.6494), np.float32(0.889)] 
2025-03-11 15:32:46.295872: Epoch time: 38.28 s 
2025-03-11 15:32:46.298962: Yayy! New best EMA pseudo Dice: 0.7426999807357788 
2025-03-11 15:32:47.122158:  
2025-03-11 15:32:47.128807: Epoch 21 
2025-03-11 15:32:47.132421: Current learning rate: 0.00809 
2025-03-11 15:33:25.378768: train_loss -0.8696 
2025-03-11 15:33:25.384989: val_loss -0.6978 
2025-03-11 15:33:25.388067: Pseudo dice [np.float32(0.6594), np.float32(0.8774)] 
2025-03-11 15:33:25.391769: Epoch time: 38.26 s 
2025-03-11 15:33:25.395487: Yayy! New best EMA pseudo Dice: 0.7452999949455261 
2025-03-11 15:33:26.202664:  
2025-03-11 15:33:26.208349: Epoch 22 
2025-03-11 15:33:26.212014: Current learning rate: 0.008 
2025-03-11 15:34:04.475907: train_loss -0.8887 
2025-03-11 15:34:04.482142: val_loss -0.7159 
2025-03-11 15:34:04.485797: Pseudo dice [np.float32(0.6697), np.float32(0.8882)] 
2025-03-11 15:34:04.489423: Epoch time: 38.27 s 
2025-03-11 15:34:04.492514: Yayy! New best EMA pseudo Dice: 0.7487000226974487 
2025-03-11 15:34:05.292459:  
2025-03-11 15:34:05.298148: Epoch 23 
2025-03-11 15:34:05.301203: Current learning rate: 0.0079 
2025-03-11 15:34:43.553784: train_loss -0.8869 
2025-03-11 15:34:43.561506: val_loss -0.7119 
2025-03-11 15:34:43.565101: Pseudo dice [np.float32(0.6703), np.float32(0.8948)] 
2025-03-11 15:34:43.568207: Epoch time: 38.26 s 
2025-03-11 15:34:43.571783: Yayy! New best EMA pseudo Dice: 0.7519999742507935 
2025-03-11 15:34:44.352813:  
2025-03-11 15:34:44.359053: Epoch 24 
2025-03-11 15:34:44.362144: Current learning rate: 0.00781 
2025-03-11 15:35:22.627295: train_loss -0.8758 
2025-03-11 15:35:22.633554: val_loss -0.6968 
2025-03-11 15:35:22.637181: Pseudo dice [np.float32(0.6482), np.float32(0.8852)] 
2025-03-11 15:35:22.640260: Epoch time: 38.27 s 
2025-03-11 15:35:22.643895: Yayy! New best EMA pseudo Dice: 0.7534999847412109 
2025-03-11 15:35:23.429594:  
2025-03-11 15:35:23.435269: Epoch 25 
2025-03-11 15:35:23.438980: Current learning rate: 0.00772 
2025-03-11 15:36:01.673722: train_loss -0.8974 
2025-03-11 15:36:01.679461: val_loss -0.713 
2025-03-11 15:36:01.683123: Pseudo dice [np.float32(0.6719), np.float32(0.8877)] 
2025-03-11 15:36:01.686321: Epoch time: 38.24 s 
2025-03-11 15:36:01.689553: Yayy! New best EMA pseudo Dice: 0.7560999989509583 
2025-03-11 15:36:02.538129:  
2025-03-11 15:36:02.543932: Epoch 26 
2025-03-11 15:36:02.546537: Current learning rate: 0.00763 
2025-03-11 15:36:40.788867: train_loss -0.89 
2025-03-11 15:36:40.793922: val_loss -0.7094 
2025-03-11 15:36:40.798464: Pseudo dice [np.float32(0.6729), np.float32(0.8909)] 
2025-03-11 15:36:40.801511: Epoch time: 38.25 s 
2025-03-11 15:36:40.805041: Yayy! New best EMA pseudo Dice: 0.7587000131607056 
2025-03-11 15:36:41.737184:  
2025-03-11 15:36:41.741865: Epoch 27 
2025-03-11 15:36:41.745417: Current learning rate: 0.00753 
2025-03-11 15:37:20.017482: train_loss -0.8971 
2025-03-11 15:37:20.023575: val_loss -0.7223 
2025-03-11 15:37:20.029810: Pseudo dice [np.float32(0.6839), np.float32(0.895)] 
2025-03-11 15:37:20.035289: Epoch time: 38.28 s 
2025-03-11 15:37:20.041260: Yayy! New best EMA pseudo Dice: 0.7617999911308289 
2025-03-11 15:37:20.902668:  
2025-03-11 15:37:20.908305: Epoch 28 
2025-03-11 15:37:20.911890: Current learning rate: 0.00744 
2025-03-11 15:37:59.159178: train_loss -0.8901 
2025-03-11 15:37:59.165230: val_loss -0.7208 
2025-03-11 15:37:59.169305: Pseudo dice [np.float32(0.6883), np.float32(0.8904)] 
2025-03-11 15:37:59.171854: Epoch time: 38.26 s 
2025-03-11 15:37:59.175887: Yayy! New best EMA pseudo Dice: 0.7645000219345093 
2025-03-11 15:37:59.999438:  
2025-03-11 15:38:00.002965: Epoch 29 
2025-03-11 15:38:00.006002: Current learning rate: 0.00735 
2025-03-11 15:38:38.257331: train_loss -0.9072 
2025-03-11 15:38:38.263933: val_loss -0.6981 
2025-03-11 15:38:38.267469: Pseudo dice [np.float32(0.6592), np.float32(0.8848)] 
2025-03-11 15:38:38.269988: Epoch time: 38.26 s 
2025-03-11 15:38:38.274520: Yayy! New best EMA pseudo Dice: 0.7652999758720398 
2025-03-11 15:38:39.095719:  
2025-03-11 15:38:39.101473: Epoch 30 
2025-03-11 15:38:39.105093: Current learning rate: 0.00725 
2025-03-11 15:39:17.375526: train_loss -0.907 
2025-03-11 15:39:17.381443: val_loss -0.7143 
2025-03-11 15:39:17.385072: Pseudo dice [np.float32(0.6812), np.float32(0.8868)] 
2025-03-11 15:39:17.388673: Epoch time: 38.28 s 
2025-03-11 15:39:17.391793: Yayy! New best EMA pseudo Dice: 0.7671999931335449 
2025-03-11 15:39:18.201988:  
2025-03-11 15:39:18.207068: Epoch 31 
2025-03-11 15:39:18.211141: Current learning rate: 0.00716 
2025-03-11 15:39:56.462185: train_loss -0.9024 
2025-03-11 15:39:56.468320: val_loss -0.7118 
2025-03-11 15:39:56.471931: Pseudo dice [np.float32(0.6689), np.float32(0.8904)] 
2025-03-11 15:39:56.475561: Epoch time: 38.26 s 
2025-03-11 15:39:56.478637: Yayy! New best EMA pseudo Dice: 0.7684000134468079 
2025-03-11 15:39:57.280926:  
2025-03-11 15:39:57.286543: Epoch 32 
2025-03-11 15:39:57.289587: Current learning rate: 0.00707 
2025-03-11 15:40:35.568227: train_loss -0.9053 
2025-03-11 15:40:35.573761: val_loss -0.7081 
2025-03-11 15:40:35.577389: Pseudo dice [np.float32(0.6766), np.float32(0.889)] 
2025-03-11 15:40:35.580156: Epoch time: 38.29 s 
2025-03-11 15:40:35.583850: Yayy! New best EMA pseudo Dice: 0.7698000073432922 
2025-03-11 15:40:36.391711:  
2025-03-11 15:40:36.397409: Epoch 33 
2025-03-11 15:40:36.401236: Current learning rate: 0.00697 
2025-03-11 15:41:14.660227: train_loss -0.8949 
2025-03-11 15:41:14.666935: val_loss -0.7149 
2025-03-11 15:41:14.670007: Pseudo dice [np.float32(0.6789), np.float32(0.8895)] 
2025-03-11 15:41:14.673180: Epoch time: 38.27 s 
2025-03-11 15:41:14.678967: Yayy! New best EMA pseudo Dice: 0.7713000178337097 
2025-03-11 15:41:15.494237:  
2025-03-11 15:41:15.500206: Epoch 34 
2025-03-11 15:41:15.503285: Current learning rate: 0.00688 
2025-03-11 15:41:53.764375: train_loss -0.9058 
2025-03-11 15:41:53.770721: val_loss -0.7118 
2025-03-11 15:41:53.774455: Pseudo dice [np.float32(0.6743), np.float32(0.8892)] 
2025-03-11 15:41:53.777628: Epoch time: 38.27 s 
2025-03-11 15:41:53.780194: Yayy! New best EMA pseudo Dice: 0.7723000049591064 
2025-03-11 15:41:54.738581:  
2025-03-11 15:41:54.744866: Epoch 35 
2025-03-11 15:41:54.747929: Current learning rate: 0.00679 
2025-03-11 15:42:33.017480: train_loss -0.9099 
2025-03-11 15:42:33.024118: val_loss -0.7067 
2025-03-11 15:42:33.027314: Pseudo dice [np.float32(0.6713), np.float32(0.8877)] 
2025-03-11 15:42:33.030465: Epoch time: 38.28 s 
2025-03-11 15:42:33.033659: Yayy! New best EMA pseudo Dice: 0.7730000019073486 
2025-03-11 15:42:33.859978:  
2025-03-11 15:42:33.865100: Epoch 36 
2025-03-11 15:42:33.869257: Current learning rate: 0.00669 
2025-03-11 15:43:12.150654: train_loss -0.9127 
2025-03-11 15:43:12.156768: val_loss -0.6859 
2025-03-11 15:43:12.160310: Pseudo dice [np.float32(0.6512), np.float32(0.885)] 
2025-03-11 15:43:12.163347: Epoch time: 38.29 s 
2025-03-11 15:43:12.736833:  
2025-03-11 15:43:12.742916: Epoch 37 
2025-03-11 15:43:12.746492: Current learning rate: 0.0066 
2025-03-11 15:43:51.033527: train_loss -0.9107 
2025-03-11 15:43:51.040248: val_loss -0.7026 
2025-03-11 15:43:51.044956: Pseudo dice [np.float32(0.6625), np.float32(0.8923)] 
2025-03-11 15:43:51.047555: Epoch time: 38.3 s 
2025-03-11 15:43:51.627385:  
2025-03-11 15:43:51.633622: Epoch 38 
2025-03-11 15:43:51.637622: Current learning rate: 0.0065 
2025-03-11 15:44:29.902415: train_loss -0.9105 
2025-03-11 15:44:29.908991: val_loss -0.7106 
2025-03-11 15:44:29.913611: Pseudo dice [np.float32(0.6769), np.float32(0.8915)] 
2025-03-11 15:44:29.917681: Epoch time: 38.28 s 
2025-03-11 15:44:29.920708: Yayy! New best EMA pseudo Dice: 0.7741000056266785 
2025-03-11 15:44:30.739336:  
2025-03-11 15:44:30.744923: Epoch 39 
2025-03-11 15:44:30.748496: Current learning rate: 0.00641 
2025-03-11 15:45:09.007957: train_loss -0.9164 
2025-03-11 15:45:09.014694: val_loss -0.693 
2025-03-11 15:45:09.018306: Pseudo dice [np.float32(0.657), np.float32(0.8874)] 
2025-03-11 15:45:09.021399: Epoch time: 38.27 s 
2025-03-11 15:45:09.617272:  
2025-03-11 15:45:09.622910: Epoch 40 
2025-03-11 15:45:09.626531: Current learning rate: 0.00631 
2025-03-11 15:45:47.877388: train_loss -0.9131 
2025-03-11 15:45:47.883111: val_loss -0.6971 
2025-03-11 15:45:47.886323: Pseudo dice [np.float32(0.6573), np.float32(0.8872)] 
2025-03-11 15:45:47.889858: Epoch time: 38.26 s 
2025-03-11 15:45:48.474770:  
2025-03-11 15:45:48.480826: Epoch 41 
2025-03-11 15:45:48.483853: Current learning rate: 0.00622 
2025-03-11 15:46:26.816079: train_loss -0.9147 
2025-03-11 15:46:26.822251: val_loss -0.7116 
2025-03-11 15:46:26.825897: Pseudo dice [np.float32(0.6809), np.float32(0.8879)] 
2025-03-11 15:46:26.829464: Epoch time: 38.34 s 
2025-03-11 15:46:26.832554: Yayy! New best EMA pseudo Dice: 0.7748000025749207 
2025-03-11 15:46:27.813161:  
2025-03-11 15:46:27.819079: Epoch 42 
2025-03-11 15:46:27.822369: Current learning rate: 0.00612 
2025-03-11 15:47:06.180731: train_loss -0.9214 
2025-03-11 15:47:06.186968: val_loss -0.688 
2025-03-11 15:47:06.190566: Pseudo dice [np.float32(0.6508), np.float32(0.8903)] 
2025-03-11 15:47:06.193626: Epoch time: 38.37 s 
2025-03-11 15:47:06.752955:  
2025-03-11 15:47:06.759120: Epoch 43 
2025-03-11 15:47:06.762150: Current learning rate: 0.00603 
2025-03-11 15:47:45.140843: train_loss -0.9188 
2025-03-11 15:47:45.147027: val_loss -0.7156 
2025-03-11 15:47:45.149601: Pseudo dice [np.float32(0.694), np.float32(0.8897)] 
2025-03-11 15:47:45.153573: Epoch time: 38.39 s 
2025-03-11 15:47:45.156634: Yayy! New best EMA pseudo Dice: 0.776199996471405 
2025-03-11 15:47:45.955338:  
2025-03-11 15:47:45.960566: Epoch 44 
2025-03-11 15:47:45.964187: Current learning rate: 0.00593 
2025-03-11 15:48:24.210111: train_loss -0.9179 
2025-03-11 15:48:24.216832: val_loss -0.695 
2025-03-11 15:48:24.220006: Pseudo dice [np.float32(0.6632), np.float32(0.8874)] 
2025-03-11 15:48:24.223094: Epoch time: 38.26 s 
2025-03-11 15:48:24.782482:  
2025-03-11 15:48:24.789217: Epoch 45 
2025-03-11 15:48:24.792331: Current learning rate: 0.00584 
2025-03-11 15:49:03.078796: train_loss -0.9108 
2025-03-11 15:49:03.084886: val_loss -0.7007 
2025-03-11 15:49:03.088427: Pseudo dice [np.float32(0.6697), np.float32(0.8902)] 
2025-03-11 15:49:03.091992: Epoch time: 38.3 s 
2025-03-11 15:49:03.094517: Yayy! New best EMA pseudo Dice: 0.7764999866485596 
2025-03-11 15:49:03.892437:  
2025-03-11 15:49:03.899079: Epoch 46 
2025-03-11 15:49:03.904003: Current learning rate: 0.00574 
2025-03-11 15:49:42.186032: train_loss -0.9148 
2025-03-11 15:49:42.192164: val_loss -0.7054 
2025-03-11 15:49:42.196276: Pseudo dice [np.float32(0.6669), np.float32(0.8912)] 
2025-03-11 15:49:42.200883: Epoch time: 38.29 s 
2025-03-11 15:49:42.203961: Yayy! New best EMA pseudo Dice: 0.7767000198364258 
2025-03-11 15:49:42.992362:  
2025-03-11 15:49:42.998685: Epoch 47 
2025-03-11 15:49:43.002247: Current learning rate: 0.00565 
2025-03-11 15:50:21.296168: train_loss -0.9175 
2025-03-11 15:50:21.302750: val_loss -0.6929 
2025-03-11 15:50:21.306304: Pseudo dice [np.float32(0.6636), np.float32(0.8857)] 
2025-03-11 15:50:21.310332: Epoch time: 38.3 s 
2025-03-11 15:50:21.883996:  
2025-03-11 15:50:21.889557: Epoch 48 
2025-03-11 15:50:21.893097: Current learning rate: 0.00555 
2025-03-11 15:51:00.165792: train_loss -0.9118 
2025-03-11 15:51:00.171878: val_loss -0.6905 
2025-03-11 15:51:00.175290: Pseudo dice [np.float32(0.6514), np.float32(0.8877)] 
2025-03-11 15:51:00.178875: Epoch time: 38.28 s 
2025-03-11 15:51:00.758148:  
2025-03-11 15:51:00.764318: Epoch 49 
2025-03-11 15:51:00.767899: Current learning rate: 0.00546 
2025-03-11 15:51:39.050591: train_loss -0.9073 
2025-03-11 15:51:39.057456: val_loss -0.7044 
2025-03-11 15:51:39.060809: Pseudo dice [np.float32(0.672), np.float32(0.8905)] 
2025-03-11 15:51:39.063933: Epoch time: 38.29 s 
2025-03-11 15:51:40.000093:  
2025-03-11 15:51:40.006148: Epoch 50 
2025-03-11 15:51:40.009176: Current learning rate: 0.00536 
2025-03-11 15:52:18.295073: train_loss -0.9286 
2025-03-11 15:52:18.301331: val_loss -0.7113 
2025-03-11 15:52:18.304943: Pseudo dice [np.float32(0.6776), np.float32(0.8933)] 
2025-03-11 15:52:18.307660: Epoch time: 38.3 s 
2025-03-11 15:52:18.311448: Yayy! New best EMA pseudo Dice: 0.7773000001907349 
2025-03-11 15:52:19.139053:  
2025-03-11 15:52:19.144809: Epoch 51 
2025-03-11 15:52:19.147906: Current learning rate: 0.00526 
2025-03-11 15:52:57.420374: train_loss -0.9096 
2025-03-11 15:52:57.426681: val_loss -0.7073 
2025-03-11 15:52:57.429797: Pseudo dice [np.float32(0.6732), np.float32(0.8909)] 
2025-03-11 15:52:57.433398: Epoch time: 38.28 s 
2025-03-11 15:52:57.436524: Yayy! New best EMA pseudo Dice: 0.7777000069618225 
2025-03-11 15:52:58.232590:  
2025-03-11 15:52:58.238330: Epoch 52 
2025-03-11 15:52:58.241945: Current learning rate: 0.00517 
2025-03-11 15:53:36.513441: train_loss -0.9197 
2025-03-11 15:53:36.519657: val_loss -0.7061 
2025-03-11 15:53:36.523321: Pseudo dice [np.float32(0.6792), np.float32(0.8915)] 
2025-03-11 15:53:36.526429: Epoch time: 38.28 s 
2025-03-11 15:53:36.529542: Yayy! New best EMA pseudo Dice: 0.7785000205039978 
2025-03-11 15:53:37.345155:  
2025-03-11 15:53:37.350907: Epoch 53 
2025-03-11 15:53:37.354548: Current learning rate: 0.00507 
2025-03-11 15:54:15.618290: train_loss -0.9201 
2025-03-11 15:54:15.624495: val_loss -0.7177 
2025-03-11 15:54:15.628095: Pseudo dice [np.float32(0.691), np.float32(0.8929)] 
2025-03-11 15:54:15.631714: Epoch time: 38.27 s 
2025-03-11 15:54:15.634908: Yayy! New best EMA pseudo Dice: 0.7799000144004822 
2025-03-11 15:54:16.434300:  
2025-03-11 15:54:16.440239: Epoch 54 
2025-03-11 15:54:16.444422: Current learning rate: 0.00497 
2025-03-11 15:54:54.686764: train_loss -0.9246 
2025-03-11 15:54:54.692513: val_loss -0.7017 
2025-03-11 15:54:54.696644: Pseudo dice [np.float32(0.6702), np.float32(0.8933)] 
2025-03-11 15:54:54.699826: Epoch time: 38.25 s 
2025-03-11 15:54:54.703463: Yayy! New best EMA pseudo Dice: 0.7799999713897705 
2025-03-11 15:54:55.517097:  
2025-03-11 15:54:55.522248: Epoch 55 
2025-03-11 15:54:55.526631: Current learning rate: 0.00487 
2025-03-11 15:55:33.799809: train_loss -0.9154 
2025-03-11 15:55:33.805439: val_loss -0.6998 
2025-03-11 15:55:33.809512: Pseudo dice [np.float32(0.6756), np.float32(0.8884)] 
2025-03-11 15:55:33.812608: Epoch time: 38.28 s 
2025-03-11 15:55:33.815702: Yayy! New best EMA pseudo Dice: 0.7802000045776367 
2025-03-11 15:55:34.628034:  
2025-03-11 15:55:34.633714: Epoch 56 
2025-03-11 15:55:34.637315: Current learning rate: 0.00478 
2025-03-11 15:56:12.893367: train_loss -0.9221 
2025-03-11 15:56:12.900699: val_loss -0.6897 
2025-03-11 15:56:12.904299: Pseudo dice [np.float32(0.6554), np.float32(0.8906)] 
2025-03-11 15:56:12.907962: Epoch time: 38.27 s 
2025-03-11 15:56:13.474542:  
2025-03-11 15:56:13.480379: Epoch 57 
2025-03-11 15:56:13.483826: Current learning rate: 0.00468 
2025-03-11 15:56:51.766536: train_loss -0.9068 
2025-03-11 15:56:51.772574: val_loss -0.6981 
2025-03-11 15:56:51.776097: Pseudo dice [np.float32(0.6685), np.float32(0.8914)] 
2025-03-11 15:56:51.779118: Epoch time: 38.29 s 
2025-03-11 15:56:52.586075:  
2025-03-11 15:56:52.592253: Epoch 58 
2025-03-11 15:56:52.595833: Current learning rate: 0.00458 
2025-03-11 15:57:30.853623: train_loss -0.9263 
2025-03-11 15:57:30.859717: val_loss -0.6917 
2025-03-11 15:57:30.863381: Pseudo dice [np.float32(0.6626), np.float32(0.8898)] 
2025-03-11 15:57:30.866958: Epoch time: 38.27 s 
2025-03-11 15:57:31.436775:  
2025-03-11 15:57:31.442338: Epoch 59 
2025-03-11 15:57:31.446365: Current learning rate: 0.00448 
2025-03-11 15:58:09.721819: train_loss -0.918 
2025-03-11 15:58:09.729047: val_loss -0.7094 
2025-03-11 15:58:09.732147: Pseudo dice [np.float32(0.6919), np.float32(0.891)] 
2025-03-11 15:58:09.736225: Epoch time: 38.29 s 
2025-03-11 15:58:09.739923: Yayy! New best EMA pseudo Dice: 0.7803999781608582 
2025-03-11 15:58:10.555470:  
2025-03-11 15:58:10.560540: Epoch 60 
2025-03-11 15:58:10.564123: Current learning rate: 0.00438 
2025-03-11 15:58:48.849419: train_loss -0.936 
2025-03-11 15:58:48.855114: val_loss -0.6991 
2025-03-11 15:58:48.858860: Pseudo dice [np.float32(0.6781), np.float32(0.8898)] 
2025-03-11 15:58:48.862005: Epoch time: 38.29 s 
2025-03-11 15:58:48.865678: Yayy! New best EMA pseudo Dice: 0.7807999849319458 
2025-03-11 15:58:49.687022:  
2025-03-11 15:58:49.692704: Epoch 61 
2025-03-11 15:58:49.695787: Current learning rate: 0.00429 
2025-03-11 15:59:27.969711: train_loss -0.9291 
2025-03-11 15:59:27.976000: val_loss -0.6995 
2025-03-11 15:59:27.979625: Pseudo dice [np.float32(0.6743), np.float32(0.8895)] 
2025-03-11 15:59:27.982747: Epoch time: 38.28 s 
2025-03-11 15:59:27.985908: Yayy! New best EMA pseudo Dice: 0.7809000015258789 
2025-03-11 15:59:28.813930:  
2025-03-11 15:59:28.819329: Epoch 62 
2025-03-11 15:59:28.822388: Current learning rate: 0.00419 
2025-03-11 16:00:07.098864: train_loss -0.9388 
2025-03-11 16:00:07.105441: val_loss -0.7021 
2025-03-11 16:00:07.108999: Pseudo dice [np.float32(0.6863), np.float32(0.8886)] 
2025-03-11 16:00:07.112039: Epoch time: 38.29 s 
2025-03-11 16:00:07.115655: Yayy! New best EMA pseudo Dice: 0.7815999984741211 
2025-03-11 16:00:07.917031:  
2025-03-11 16:00:07.923251: Epoch 63 
2025-03-11 16:00:07.926336: Current learning rate: 0.00409 
2025-03-11 16:00:46.250846: train_loss -0.9333 
2025-03-11 16:00:46.257066: val_loss -0.7007 
2025-03-11 16:00:46.260176: Pseudo dice [np.float32(0.6822), np.float32(0.8911)] 
2025-03-11 16:00:46.264269: Epoch time: 38.33 s 
2025-03-11 16:00:46.267391: Yayy! New best EMA pseudo Dice: 0.7821000218391418 
2025-03-11 16:00:47.079404:  
2025-03-11 16:00:47.084517: Epoch 64 
2025-03-11 16:00:47.089097: Current learning rate: 0.00399 
2025-03-11 16:01:25.355586: train_loss -0.9268 
2025-03-11 16:01:25.361650: val_loss -0.6975 
2025-03-11 16:01:25.364690: Pseudo dice [np.float32(0.6753), np.float32(0.891)] 
2025-03-11 16:01:25.368217: Epoch time: 38.28 s 
2025-03-11 16:01:25.371756: Yayy! New best EMA pseudo Dice: 0.7821999788284302 
2025-03-11 16:01:26.320302:  
2025-03-11 16:01:26.325537: Epoch 65 
2025-03-11 16:01:26.329162: Current learning rate: 0.00389 
2025-03-11 16:02:04.591292: train_loss -0.9326 
2025-03-11 16:02:04.597356: val_loss -0.7071 
2025-03-11 16:02:04.600886: Pseudo dice [np.float32(0.6893), np.float32(0.8939)] 
2025-03-11 16:02:04.604421: Epoch time: 38.27 s 
2025-03-11 16:02:04.607464: Yayy! New best EMA pseudo Dice: 0.7831000089645386 
2025-03-11 16:02:05.427847:  
2025-03-11 16:02:05.434411: Epoch 66 
2025-03-11 16:02:05.437454: Current learning rate: 0.00379 
2025-03-11 16:02:43.704828: train_loss -0.92 
2025-03-11 16:02:43.711187: val_loss -0.6965 
2025-03-11 16:02:43.714298: Pseudo dice [np.float32(0.672), np.float32(0.8937)] 
2025-03-11 16:02:43.717840: Epoch time: 38.28 s 
2025-03-11 16:02:44.287270:  
2025-03-11 16:02:44.292418: Epoch 67 
2025-03-11 16:02:44.296020: Current learning rate: 0.00369 
2025-03-11 16:03:22.558884: train_loss -0.9304 
2025-03-11 16:03:22.565480: val_loss -0.6959 
2025-03-11 16:03:22.569041: Pseudo dice [np.float32(0.6708), np.float32(0.893)] 
2025-03-11 16:03:22.572068: Epoch time: 38.27 s 
2025-03-11 16:03:23.161655:  
2025-03-11 16:03:23.167336: Epoch 68 
2025-03-11 16:03:23.170972: Current learning rate: 0.00359 
2025-03-11 16:04:01.436937: train_loss -0.9258 
2025-03-11 16:04:01.444703: val_loss -0.7083 
2025-03-11 16:04:01.447888: Pseudo dice [np.float32(0.6889), np.float32(0.8932)] 
2025-03-11 16:04:01.451513: Epoch time: 38.28 s 
2025-03-11 16:04:01.455152: Yayy! New best EMA pseudo Dice: 0.7838000059127808 
2025-03-11 16:04:02.301075:  
2025-03-11 16:04:02.307295: Epoch 69 
2025-03-11 16:04:02.310937: Current learning rate: 0.00349 
2025-03-11 16:04:40.600165: train_loss -0.9405 
2025-03-11 16:04:40.607244: val_loss -0.6937 
2025-03-11 16:04:40.611312: Pseudo dice [np.float32(0.669), np.float32(0.8921)] 
2025-03-11 16:04:40.615344: Epoch time: 38.3 s 
2025-03-11 16:04:41.196001:  
2025-03-11 16:04:41.202675: Epoch 70 
2025-03-11 16:04:41.206435: Current learning rate: 0.00338 
2025-03-11 16:05:19.494983: train_loss -0.9343 
2025-03-11 16:05:19.502418: val_loss -0.7006 
2025-03-11 16:05:19.506527: Pseudo dice [np.float32(0.6857), np.float32(0.8891)] 
2025-03-11 16:05:19.510660: Epoch time: 38.3 s 
2025-03-11 16:05:19.514898: Yayy! New best EMA pseudo Dice: 0.7839000225067139 
2025-03-11 16:05:20.343156:  
2025-03-11 16:05:20.353301: Epoch 71 
2025-03-11 16:05:20.357913: Current learning rate: 0.00328 
2025-03-11 16:05:58.626237: train_loss -0.9201 
2025-03-11 16:05:58.632875: val_loss -0.6943 
2025-03-11 16:05:58.640447: Pseudo dice [np.float32(0.6679), np.float32(0.8898)] 
2025-03-11 16:05:58.643975: Epoch time: 38.28 s 
2025-03-11 16:05:59.225087:  
2025-03-11 16:05:59.231792: Epoch 72 
2025-03-11 16:05:59.235394: Current learning rate: 0.00318 
2025-03-11 16:06:37.507064: train_loss -0.9361 
2025-03-11 16:06:37.514209: val_loss -0.7052 
2025-03-11 16:06:37.518378: Pseudo dice [np.float32(0.6903), np.float32(0.8906)] 
2025-03-11 16:06:37.525063: Epoch time: 38.28 s 
2025-03-11 16:06:37.528616: Yayy! New best EMA pseudo Dice: 0.7840999960899353 
2025-03-11 16:06:38.516662:  
2025-03-11 16:06:38.523811: Epoch 73 
2025-03-11 16:06:38.527463: Current learning rate: 0.00308 
2025-03-11 16:07:16.776939: train_loss -0.9366 
2025-03-11 16:07:16.783870: val_loss -0.6944 
2025-03-11 16:07:16.786961: Pseudo dice [np.float32(0.6789), np.float32(0.8912)] 
2025-03-11 16:07:16.791657: Epoch time: 38.26 s 
2025-03-11 16:07:16.795796: Yayy! New best EMA pseudo Dice: 0.7842000126838684 
2025-03-11 16:07:17.618291:  
2025-03-11 16:07:17.624396: Epoch 74 
2025-03-11 16:07:17.629494: Current learning rate: 0.00297 
2025-03-11 16:07:55.872309: train_loss -0.9365 
2025-03-11 16:07:55.884053: val_loss -0.6978 
2025-03-11 16:07:55.888718: Pseudo dice [np.float32(0.676), np.float32(0.8934)] 
2025-03-11 16:07:55.892297: Epoch time: 38.26 s 
2025-03-11 16:07:55.895934: Yayy! New best EMA pseudo Dice: 0.7842000126838684 
2025-03-11 16:07:56.742180:  
2025-03-11 16:07:56.748786: Epoch 75 
2025-03-11 16:07:56.757858: Current learning rate: 0.00287 
2025-03-11 16:08:35.016099: train_loss -0.9306 
2025-03-11 16:08:35.022523: val_loss -0.696 
2025-03-11 16:08:35.035107: Pseudo dice [np.float32(0.6761), np.float32(0.8925)] 
2025-03-11 16:08:35.049044: Epoch time: 38.27 s 
2025-03-11 16:08:35.059531: Yayy! New best EMA pseudo Dice: 0.7842000126838684 
2025-03-11 16:08:35.895387:  
2025-03-11 16:08:35.902659: Epoch 76 
2025-03-11 16:08:35.906784: Current learning rate: 0.00277 
2025-03-11 16:09:14.173154: train_loss -0.9305 
2025-03-11 16:09:14.180914: val_loss -0.6972 
2025-03-11 16:09:14.185253: Pseudo dice [np.float32(0.6736), np.float32(0.8945)] 
2025-03-11 16:09:14.189299: Epoch time: 38.28 s 
2025-03-11 16:09:14.788933:  
2025-03-11 16:09:14.795232: Epoch 77 
2025-03-11 16:09:14.799381: Current learning rate: 0.00266 
2025-03-11 16:09:53.051936: train_loss -0.9391 
2025-03-11 16:09:53.058585: val_loss -0.696 
2025-03-11 16:09:53.063135: Pseudo dice [np.float32(0.6817), np.float32(0.8927)] 
2025-03-11 16:09:53.069221: Epoch time: 38.26 s 
2025-03-11 16:09:53.077227: Yayy! New best EMA pseudo Dice: 0.784500002861023 
2025-03-11 16:09:53.902366:  
2025-03-11 16:09:53.908589: Epoch 78 
2025-03-11 16:09:53.912677: Current learning rate: 0.00256 
2025-03-11 16:10:32.185830: train_loss -0.9272 
2025-03-11 16:10:32.191452: val_loss -0.6881 
2025-03-11 16:10:32.195509: Pseudo dice [np.float32(0.6662), np.float32(0.8944)] 
2025-03-11 16:10:32.200689: Epoch time: 38.28 s 
2025-03-11 16:10:32.794268:  
2025-03-11 16:10:32.802006: Epoch 79 
2025-03-11 16:10:32.807400: Current learning rate: 0.00245 
2025-03-11 16:11:11.081963: train_loss -0.9259 
2025-03-11 16:11:11.089609: val_loss -0.6857 
2025-03-11 16:11:11.097203: Pseudo dice [np.float32(0.6698), np.float32(0.8897)] 
2025-03-11 16:11:11.101303: Epoch time: 38.29 s 
2025-03-11 16:11:11.866255:  
2025-03-11 16:11:11.872315: Epoch 80 
2025-03-11 16:11:11.875416: Current learning rate: 0.00235 
2025-03-11 16:11:50.208421: train_loss -0.9373 
2025-03-11 16:11:50.214643: val_loss -0.6972 
2025-03-11 16:11:50.226068: Pseudo dice [np.float32(0.6874), np.float32(0.8922)] 
2025-03-11 16:11:50.237839: Epoch time: 38.34 s 
2025-03-11 16:11:50.833444:  
2025-03-11 16:11:50.839493: Epoch 81 
2025-03-11 16:11:50.850088: Current learning rate: 0.00224 
2025-03-11 16:12:29.155126: train_loss -0.9283 
2025-03-11 16:12:29.160805: val_loss -0.6719 
2025-03-11 16:12:29.164963: Pseudo dice [np.float32(0.6491), np.float32(0.887)] 
2025-03-11 16:12:29.169104: Epoch time: 38.32 s 
2025-03-11 16:12:29.767154:  
2025-03-11 16:12:29.780792: Epoch 82 
2025-03-11 16:12:29.784833: Current learning rate: 0.00214 
2025-03-11 16:13:08.078634: train_loss -0.9404 
2025-03-11 16:13:08.093401: val_loss -0.6824 
2025-03-11 16:13:08.104634: Pseudo dice [np.float32(0.6605), np.float32(0.8911)] 
2025-03-11 16:13:08.108797: Epoch time: 38.31 s 
2025-03-11 16:13:08.674194:  
2025-03-11 16:13:08.679848: Epoch 83 
2025-03-11 16:13:08.691807: Current learning rate: 0.00203 
2025-03-11 16:13:47.001783: train_loss -0.9386 
2025-03-11 16:13:47.007833: val_loss -0.6973 
2025-03-11 16:13:47.011376: Pseudo dice [np.float32(0.6801), np.float32(0.8906)] 
2025-03-11 16:13:47.014951: Epoch time: 38.33 s 
2025-03-11 16:13:47.579134:  
2025-03-11 16:13:47.584650: Epoch 84 
2025-03-11 16:13:47.597073: Current learning rate: 0.00192 
2025-03-11 16:14:25.903507: train_loss -0.9353 
2025-03-11 16:14:25.910181: val_loss -0.6852 
2025-03-11 16:14:25.913724: Pseudo dice [np.float32(0.6705), np.float32(0.8937)] 
2025-03-11 16:14:25.917778: Epoch time: 38.33 s 
2025-03-11 16:14:26.471504:  
2025-03-11 16:14:26.477071: Epoch 85 
2025-03-11 16:14:26.489198: Current learning rate: 0.00181 
2025-03-11 16:15:04.795422: train_loss -0.937 
2025-03-11 16:15:04.803594: val_loss -0.6836 
2025-03-11 16:15:04.817240: Pseudo dice [np.float32(0.6599), np.float32(0.8937)] 
2025-03-11 16:15:04.821283: Epoch time: 38.32 s 
2025-03-11 16:15:05.401179:  
2025-03-11 16:15:05.405230: Epoch 86 
2025-03-11 16:15:05.409220: Current learning rate: 0.0017 
2025-03-11 16:15:43.712636: train_loss -0.9377 
2025-03-11 16:15:43.719947: val_loss -0.6899 
2025-03-11 16:15:43.723554: Pseudo dice [np.float32(0.6799), np.float32(0.8913)] 
2025-03-11 16:15:43.738133: Epoch time: 38.31 s 
2025-03-11 16:15:44.333129:  
2025-03-11 16:15:44.348717: Epoch 87 
2025-03-11 16:15:44.353883: Current learning rate: 0.00159 
2025-03-11 16:16:22.631726: train_loss -0.9311 
2025-03-11 16:16:22.639362: val_loss -0.6918 
2025-03-11 16:16:22.642895: Pseudo dice [np.float32(0.6843), np.float32(0.8929)] 
2025-03-11 16:16:22.646943: Epoch time: 38.3 s 
2025-03-11 16:16:23.355583:  
2025-03-11 16:16:23.361696: Epoch 88 
2025-03-11 16:16:23.365233: Current learning rate: 0.00148 
2025-03-11 16:17:01.783517: train_loss -0.9282 
2025-03-11 16:17:01.790256: val_loss -0.7002 
2025-03-11 16:17:01.795398: Pseudo dice [np.float32(0.6851), np.float32(0.8954)] 
2025-03-11 16:17:01.800026: Epoch time: 38.43 s 
2025-03-11 16:17:02.357234:  
2025-03-11 16:17:02.374908: Epoch 89 
2025-03-11 16:17:02.380343: Current learning rate: 0.00137 
2025-03-11 16:17:40.678633: train_loss -0.9428 
2025-03-11 16:17:40.686197: val_loss -0.6937 
2025-03-11 16:17:40.690726: Pseudo dice [np.float32(0.68), np.float32(0.8954)] 
2025-03-11 16:17:40.695270: Epoch time: 38.32 s 
2025-03-11 16:17:41.248244:  
2025-03-11 16:17:41.255090: Epoch 90 
2025-03-11 16:17:41.258651: Current learning rate: 0.00126 
2025-03-11 16:18:19.636816: train_loss -0.9328 
2025-03-11 16:18:19.647665: val_loss -0.685 
2025-03-11 16:18:19.651850: Pseudo dice [np.float32(0.673), np.float32(0.8899)] 
2025-03-11 16:18:19.656068: Epoch time: 38.39 s 
2025-03-11 16:18:20.211628:  
2025-03-11 16:18:20.217741: Epoch 91 
2025-03-11 16:18:20.221783: Current learning rate: 0.00115 
2025-03-11 16:18:58.510485: train_loss -0.9441 
2025-03-11 16:18:58.517751: val_loss -0.6914 
2025-03-11 16:18:58.521874: Pseudo dice [np.float32(0.6781), np.float32(0.8931)] 
2025-03-11 16:18:58.526087: Epoch time: 38.3 s 
2025-03-11 16:18:59.097811:  
2025-03-11 16:18:59.106023: Epoch 92 
2025-03-11 16:18:59.110139: Current learning rate: 0.00103 
2025-03-11 16:19:37.389889: train_loss -0.9366 
2025-03-11 16:19:37.396746: val_loss -0.6753 
2025-03-11 16:19:37.401378: Pseudo dice [np.float32(0.6653), np.float32(0.8915)] 
2025-03-11 16:19:37.405549: Epoch time: 38.29 s 
2025-03-11 16:19:37.980266:  
2025-03-11 16:19:37.986991: Epoch 93 
2025-03-11 16:19:37.990079: Current learning rate: 0.00091 
2025-03-11 16:20:16.277746: train_loss -0.9408 
2025-03-11 16:20:16.285533: val_loss -0.6923 
2025-03-11 16:20:16.289590: Pseudo dice [np.float32(0.6775), np.float32(0.8918)] 
2025-03-11 16:20:16.293109: Epoch time: 38.3 s 
2025-03-11 16:20:16.848411:  
2025-03-11 16:20:16.854698: Epoch 94 
2025-03-11 16:20:16.858821: Current learning rate: 0.00079 
2025-03-11 16:20:55.153488: train_loss -0.9372 
2025-03-11 16:20:55.160212: val_loss -0.6949 
2025-03-11 16:20:55.164462: Pseudo dice [np.float32(0.6858), np.float32(0.8926)] 
2025-03-11 16:20:55.168615: Epoch time: 38.31 s 
2025-03-11 16:20:55.719450:  
2025-03-11 16:20:55.726265: Epoch 95 
2025-03-11 16:20:55.733102: Current learning rate: 0.00067 
2025-03-11 16:21:34.006527: train_loss -0.9466 
2025-03-11 16:21:34.015363: val_loss -0.6798 
2025-03-11 16:21:34.019521: Pseudo dice [np.float32(0.6658), np.float32(0.8919)] 
2025-03-11 16:21:34.022694: Epoch time: 38.29 s 
2025-03-11 16:21:34.733806:  
2025-03-11 16:21:34.742041: Epoch 96 
2025-03-11 16:21:34.746100: Current learning rate: 0.00055 
2025-03-11 16:22:13.017423: train_loss -0.9428 
2025-03-11 16:22:13.024102: val_loss -0.681 
2025-03-11 16:22:13.028293: Pseudo dice [np.float32(0.6672), np.float32(0.8918)] 
2025-03-11 16:22:13.032444: Epoch time: 38.28 s 
2025-03-11 16:22:13.595452:  
2025-03-11 16:22:13.608212: Epoch 97 
2025-03-11 16:22:13.618301: Current learning rate: 0.00043 
2025-03-11 16:22:51.888532: train_loss -0.9389 
2025-03-11 16:22:51.895044: val_loss -0.6914 
2025-03-11 16:22:51.899698: Pseudo dice [np.float32(0.6817), np.float32(0.8921)] 
2025-03-11 16:22:51.903281: Epoch time: 38.29 s 
2025-03-11 16:22:52.495594:  
2025-03-11 16:22:52.501952: Epoch 98 
2025-03-11 16:22:52.506059: Current learning rate: 0.0003 
2025-03-11 16:23:30.759531: train_loss -0.9311 
2025-03-11 16:23:30.765744: val_loss -0.6895 
2025-03-11 16:23:30.771286: Pseudo dice [np.float32(0.6798), np.float32(0.8918)] 
2025-03-11 16:23:30.774881: Epoch time: 38.26 s 
2025-03-11 16:23:31.365546:  
2025-03-11 16:23:31.372163: Epoch 99 
2025-03-11 16:23:31.381828: Current learning rate: 0.00016 
2025-03-11 16:24:09.658737: train_loss -0.9323 
2025-03-11 16:24:09.666808: val_loss -0.6866 
2025-03-11 16:24:09.669844: Pseudo dice [np.float32(0.6784), np.float32(0.8915)] 
2025-03-11 16:24:09.673872: Epoch time: 38.29 s 
2025-03-11 16:24:10.520126: Training done. 
2025-03-11 16:24:10.555668: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset005_Prostate\splits_final.json 
2025-03-11 16:24:10.562359: The split file contains 5 splits. 
2025-03-11 16:24:10.569168: Desired fold for training: 0 
2025-03-11 16:24:10.575656: This split has 25 training and 7 validation cases. 
2025-03-11 16:24:10.587579: predicting prostate_00 
2025-03-11 16:24:10.600484: prostate_00, shape torch.Size([2, 17, 307, 307]), rank 0 
2025-03-11 16:24:11.563887: predicting prostate_04 
2025-03-11 16:24:11.573236: prostate_04, shape torch.Size([2, 17, 306, 307]), rank 0 
2025-03-11 16:24:11.924176: predicting prostate_14 
2025-03-11 16:24:11.932902: prostate_14, shape torch.Size([2, 20, 320, 319]), rank 0 
2025-03-11 16:24:12.279499: predicting prostate_20 
2025-03-11 16:24:12.287765: prostate_20, shape torch.Size([2, 20, 320, 320]), rank 0 
2025-03-11 16:24:12.632662: predicting prostate_25 
2025-03-11 16:24:12.643731: prostate_25, shape torch.Size([2, 19, 320, 319]), rank 0 
2025-03-11 16:24:12.993438: predicting prostate_31 
2025-03-11 16:24:13.004268: prostate_31, shape torch.Size([2, 20, 320, 319]), rank 0 
2025-03-11 16:24:13.351747: predicting prostate_42 
2025-03-11 16:24:13.360373: prostate_42, shape torch.Size([2, 22, 320, 319]), rank 0 
2025-03-11 16:24:21.348711: Validation complete 
2025-03-11 16:24:21.354888: Mean Validation Dice:  0.740269605052586 
