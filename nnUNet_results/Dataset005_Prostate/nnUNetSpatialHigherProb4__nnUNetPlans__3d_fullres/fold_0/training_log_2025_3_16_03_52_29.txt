
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-16 03:52:29.157134: do_dummy_2d_data_aug: True 
2025-03-16 03:52:29.159134: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset005_Prostate\splits_final.json 
2025-03-16 03:52:29.166133: The split file contains 5 splits. 
2025-03-16 03:52:29.168132: Desired fold for training: 0 
2025-03-16 03:52:29.171133: This split has 25 training and 7 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [20, 320, 256], 'median_image_size_in_voxels': [20.0, 320.0, 319.0], 'spacing': [3.5999999046325684, 0.625, 0.625], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': [32, 64, 128, 256, 320, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [1, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset005_Prostate', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.5999999046325684, 0.625, 0.625], 'original_median_shape_after_transp': [20, 320, 320], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1326.0, 'mean': 350.18780517578125, 'median': 327.0, 'min': 0.0, 'percentile_00_5': 83.0, 'percentile_99_5': 822.0, 'std': 139.9563751220703}, '1': {'max': 3698.0, 'mean': 1351.1083984375, 'median': 1364.0, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 2563.0, 'std': 376.4326477050781}}} 
 
2025-03-16 03:52:35.967834: unpacking dataset... 
2025-03-16 03:52:36.142459: unpacking done... 
2025-03-16 03:52:39.169966:  
2025-03-16 03:52:39.175521: Epoch 0 
2025-03-16 03:52:39.178071: Current learning rate: 0.01 
2025-03-16 03:53:20.263676: train_loss -0.1771 
2025-03-16 03:53:20.269721: val_loss -0.5664 
2025-03-16 03:53:20.272228: Pseudo dice [np.float32(0.4754), np.float32(0.804)] 
2025-03-16 03:53:20.276234: Epoch time: 41.09 s 
2025-03-16 03:53:20.278738: Yayy! New best EMA pseudo Dice: 0.6396999955177307 
2025-03-16 03:53:20.943454:  
2025-03-16 03:53:20.948986: Epoch 1 
2025-03-16 03:53:20.951533: Current learning rate: 0.00991 
2025-03-16 03:53:57.816273: train_loss -0.5549 
2025-03-16 03:53:57.821332: val_loss -0.6624 
2025-03-16 03:53:57.825369: Pseudo dice [np.float32(0.6207), np.float32(0.8607)] 
2025-03-16 03:53:57.828413: Epoch time: 36.87 s 
2025-03-16 03:53:57.831457: Yayy! New best EMA pseudo Dice: 0.6498000025749207 
2025-03-16 03:53:58.561343:  
2025-03-16 03:53:58.566867: Epoch 2 
2025-03-16 03:53:58.570378: Current learning rate: 0.00982 
2025-03-16 03:54:35.441028: train_loss -0.6124 
2025-03-16 03:54:35.447140: val_loss -0.6629 
2025-03-16 03:54:35.450209: Pseudo dice [np.float32(0.6043), np.float32(0.859)] 
2025-03-16 03:54:35.453762: Epoch time: 36.88 s 
2025-03-16 03:54:35.455990: Yayy! New best EMA pseudo Dice: 0.6579999923706055 
2025-03-16 03:54:36.207924:  
2025-03-16 03:54:36.213946: Epoch 3 
2025-03-16 03:54:36.217456: Current learning rate: 0.00973 
2025-03-16 03:55:13.069044: train_loss -0.7048 
2025-03-16 03:55:13.074647: val_loss -0.6715 
2025-03-16 03:55:13.078707: Pseudo dice [np.float32(0.6233), np.float32(0.861)] 
2025-03-16 03:55:13.081295: Epoch time: 36.86 s 
2025-03-16 03:55:13.084806: Yayy! New best EMA pseudo Dice: 0.6664000153541565 
2025-03-16 03:55:13.820890:  
2025-03-16 03:55:13.826431: Epoch 4 
2025-03-16 03:55:13.829738: Current learning rate: 0.00964 
2025-03-16 03:55:50.660861: train_loss -0.7193 
2025-03-16 03:55:50.668464: val_loss -0.6719 
2025-03-16 03:55:50.671977: Pseudo dice [np.float32(0.6141), np.float32(0.8548)] 
2025-03-16 03:55:50.674483: Epoch time: 36.84 s 
2025-03-16 03:55:50.678494: Yayy! New best EMA pseudo Dice: 0.6732000112533569 
2025-03-16 03:55:51.565103:  
2025-03-16 03:55:51.571263: Epoch 5 
2025-03-16 03:55:51.573807: Current learning rate: 0.00955 
2025-03-16 03:56:28.410434: train_loss -0.7408 
2025-03-16 03:56:28.415512: val_loss -0.6911 
2025-03-16 03:56:28.419027: Pseudo dice [np.float32(0.6357), np.float32(0.8659)] 
2025-03-16 03:56:28.422533: Epoch time: 36.85 s 
2025-03-16 03:56:28.425544: Yayy! New best EMA pseudo Dice: 0.6809999942779541 
2025-03-16 03:56:29.153653:  
2025-03-16 03:56:29.159182: Epoch 6 
2025-03-16 03:56:29.162266: Current learning rate: 0.00946 
2025-03-16 03:57:06.010657: train_loss -0.7669 
2025-03-16 03:57:06.016201: val_loss -0.6958 
2025-03-16 03:57:06.018719: Pseudo dice [np.float32(0.6482), np.float32(0.8735)] 
2025-03-16 03:57:06.022355: Epoch time: 36.86 s 
2025-03-16 03:57:06.024656: Yayy! New best EMA pseudo Dice: 0.6890000104904175 
2025-03-16 03:57:06.759722:  
2025-03-16 03:57:06.765256: Epoch 7 
2025-03-16 03:57:06.768768: Current learning rate: 0.00937 
2025-03-16 03:57:43.636416: train_loss -0.8045 
2025-03-16 03:57:43.642967: val_loss -0.6991 
2025-03-16 03:57:43.647000: Pseudo dice [np.float32(0.6472), np.float32(0.8749)] 
2025-03-16 03:57:43.649525: Epoch time: 36.88 s 
2025-03-16 03:57:43.653050: Yayy! New best EMA pseudo Dice: 0.6962000131607056 
2025-03-16 03:57:44.405350:  
2025-03-16 03:57:44.410895: Epoch 8 
2025-03-16 03:57:44.414408: Current learning rate: 0.00928 
2025-03-16 03:58:21.260276: train_loss -0.7959 
2025-03-16 03:58:21.266834: val_loss -0.6556 
2025-03-16 03:58:21.269897: Pseudo dice [np.float32(0.6023), np.float32(0.8729)] 
2025-03-16 03:58:21.272435: Epoch time: 36.86 s 
2025-03-16 03:58:21.274971: Yayy! New best EMA pseudo Dice: 0.7002999782562256 
2025-03-16 03:58:22.029232:  
2025-03-16 03:58:22.035350: Epoch 9 
2025-03-16 03:58:22.038907: Current learning rate: 0.00919 
2025-03-16 03:58:58.878141: train_loss -0.8029 
2025-03-16 03:58:58.883190: val_loss -0.6827 
2025-03-16 03:58:58.886704: Pseudo dice [np.float32(0.6178), np.float32(0.8748)] 
2025-03-16 03:58:58.890215: Epoch time: 36.85 s 
2025-03-16 03:58:58.893223: Yayy! New best EMA pseudo Dice: 0.7049000263214111 
2025-03-16 03:58:59.632037:  
2025-03-16 03:58:59.637049: Epoch 10 
2025-03-16 03:58:59.640559: Current learning rate: 0.0091 
2025-03-16 03:59:36.500867: train_loss -0.8138 
2025-03-16 03:59:36.506908: val_loss -0.6981 
2025-03-16 03:59:36.509933: Pseudo dice [np.float32(0.6461), np.float32(0.8796)] 
2025-03-16 03:59:36.513444: Epoch time: 36.87 s 
2025-03-16 03:59:36.516952: Yayy! New best EMA pseudo Dice: 0.7106999754905701 
2025-03-16 03:59:37.250713:  
2025-03-16 03:59:37.255740: Epoch 11 
2025-03-16 03:59:37.259257: Current learning rate: 0.009 
2025-03-16 04:00:14.105474: train_loss -0.8352 
2025-03-16 04:00:14.110565: val_loss -0.6986 
2025-03-16 04:00:14.114081: Pseudo dice [np.float32(0.6504), np.float32(0.8787)] 
2025-03-16 04:00:14.118092: Epoch time: 36.86 s 
2025-03-16 04:00:14.121607: Yayy! New best EMA pseudo Dice: 0.7160999774932861 
2025-03-16 04:00:14.858494:  
2025-03-16 04:00:14.864151: Epoch 12 
2025-03-16 04:00:14.866707: Current learning rate: 0.00891 
2025-03-16 04:00:51.710141: train_loss -0.8375 
2025-03-16 04:00:51.719162: val_loss -0.6821 
2025-03-16 04:00:51.722670: Pseudo dice [np.float32(0.6359), np.float32(0.8691)] 
2025-03-16 04:00:51.726691: Epoch time: 36.85 s 
2025-03-16 04:00:51.730203: Yayy! New best EMA pseudo Dice: 0.7196999788284302 
2025-03-16 04:00:52.616324:  
2025-03-16 04:00:52.621861: Epoch 13 
2025-03-16 04:00:52.625412: Current learning rate: 0.00882 
2025-03-16 04:01:29.468570: train_loss -0.8403 
2025-03-16 04:01:29.474275: val_loss -0.6956 
2025-03-16 04:01:29.477827: Pseudo dice [np.float32(0.646), np.float32(0.882)] 
2025-03-16 04:01:29.480844: Epoch time: 36.85 s 
2025-03-16 04:01:29.484367: Yayy! New best EMA pseudo Dice: 0.7242000102996826 
2025-03-16 04:01:30.234459:  
2025-03-16 04:01:30.240077: Epoch 14 
2025-03-16 04:01:30.243616: Current learning rate: 0.00873 
2025-03-16 04:02:07.075327: train_loss -0.8495 
2025-03-16 04:02:07.080865: val_loss -0.6785 
2025-03-16 04:02:07.084875: Pseudo dice [np.float32(0.6185), np.float32(0.876)] 
2025-03-16 04:02:07.088385: Epoch time: 36.84 s 
2025-03-16 04:02:07.091891: Yayy! New best EMA pseudo Dice: 0.7264999747276306 
2025-03-16 04:02:07.842485:  
2025-03-16 04:02:07.848567: Epoch 15 
2025-03-16 04:02:07.851669: Current learning rate: 0.00864 
2025-03-16 04:02:44.697227: train_loss -0.8596 
2025-03-16 04:02:44.704741: val_loss -0.6939 
2025-03-16 04:02:44.708751: Pseudo dice [np.float32(0.6469), np.float32(0.8765)] 
2025-03-16 04:02:44.712268: Epoch time: 36.86 s 
2025-03-16 04:02:44.715772: Yayy! New best EMA pseudo Dice: 0.7300000190734863 
2025-03-16 04:02:45.484221:  
2025-03-16 04:02:45.489735: Epoch 16 
2025-03-16 04:02:45.493251: Current learning rate: 0.00855 
2025-03-16 04:03:22.344980: train_loss -0.8502 
2025-03-16 04:03:22.351493: val_loss -0.6958 
2025-03-16 04:03:22.355009: Pseudo dice [np.float32(0.6459), np.float32(0.8815)] 
2025-03-16 04:03:22.360025: Epoch time: 36.86 s 
2025-03-16 04:03:22.362531: Yayy! New best EMA pseudo Dice: 0.7333999872207642 
2025-03-16 04:03:23.129080:  
2025-03-16 04:03:23.134653: Epoch 17 
2025-03-16 04:03:23.138695: Current learning rate: 0.00846 
2025-03-16 04:03:59.977878: train_loss -0.8602 
2025-03-16 04:03:59.983943: val_loss -0.7106 
2025-03-16 04:03:59.987530: Pseudo dice [np.float32(0.6637), np.float32(0.884)] 
2025-03-16 04:03:59.990592: Epoch time: 36.85 s 
2025-03-16 04:03:59.993643: Yayy! New best EMA pseudo Dice: 0.7373999953269958 
2025-03-16 04:04:00.746722:  
2025-03-16 04:04:00.752279: Epoch 18 
2025-03-16 04:04:00.756344: Current learning rate: 0.00836 
2025-03-16 04:04:37.605631: train_loss -0.861 
2025-03-16 04:04:37.611802: val_loss -0.6933 
2025-03-16 04:04:37.615357: Pseudo dice [np.float32(0.6478), np.float32(0.8755)] 
2025-03-16 04:04:37.619428: Epoch time: 36.86 s 
2025-03-16 04:04:37.622470: Yayy! New best EMA pseudo Dice: 0.739799976348877 
2025-03-16 04:04:38.390238:  
2025-03-16 04:04:38.395304: Epoch 19 
2025-03-16 04:04:38.398832: Current learning rate: 0.00827 
2025-03-16 04:05:15.222851: train_loss -0.8713 
2025-03-16 04:05:15.228399: val_loss -0.7004 
2025-03-16 04:05:15.231939: Pseudo dice [np.float32(0.654), np.float32(0.8797)] 
2025-03-16 04:05:15.235949: Epoch time: 36.83 s 
2025-03-16 04:05:15.239460: Yayy! New best EMA pseudo Dice: 0.7425000071525574 
2025-03-16 04:05:16.129742:  
2025-03-16 04:05:16.135255: Epoch 20 
2025-03-16 04:05:16.138766: Current learning rate: 0.00818 
2025-03-16 04:05:52.969972: train_loss -0.8819 
2025-03-16 04:05:52.976488: val_loss -0.7007 
2025-03-16 04:05:52.979999: Pseudo dice [np.float32(0.6426), np.float32(0.8869)] 
2025-03-16 04:05:52.983506: Epoch time: 36.84 s 
2025-03-16 04:05:52.986516: Yayy! New best EMA pseudo Dice: 0.7447999715805054 
2025-03-16 04:05:53.791866:  
2025-03-16 04:05:53.796875: Epoch 21 
2025-03-16 04:05:53.800390: Current learning rate: 0.00809 
2025-03-16 04:06:30.659756: train_loss -0.8788 
2025-03-16 04:06:30.666882: val_loss -0.7118 
2025-03-16 04:06:30.669408: Pseudo dice [np.float32(0.665), np.float32(0.8883)] 
2025-03-16 04:06:30.673502: Epoch time: 36.87 s 
2025-03-16 04:06:30.676060: Yayy! New best EMA pseudo Dice: 0.7480000257492065 
2025-03-16 04:06:31.408897:  
2025-03-16 04:06:31.414471: Epoch 22 
2025-03-16 04:06:31.418524: Current learning rate: 0.008 
2025-03-16 04:07:08.270859: train_loss -0.883 
2025-03-16 04:07:08.277879: val_loss -0.7097 
2025-03-16 04:07:08.281966: Pseudo dice [np.float32(0.6662), np.float32(0.8877)] 
2025-03-16 04:07:08.284471: Epoch time: 36.86 s 
2025-03-16 04:07:08.287978: Yayy! New best EMA pseudo Dice: 0.7508999705314636 
2025-03-16 04:07:09.019996:  
2025-03-16 04:07:09.025541: Epoch 23 
2025-03-16 04:07:09.029645: Current learning rate: 0.0079 
2025-03-16 04:07:45.866267: train_loss -0.8795 
2025-03-16 04:07:45.873323: val_loss -0.7076 
2025-03-16 04:07:45.877361: Pseudo dice [np.float32(0.6644), np.float32(0.881)] 
2025-03-16 04:07:45.880371: Epoch time: 36.85 s 
2025-03-16 04:07:45.883883: Yayy! New best EMA pseudo Dice: 0.753000020980835 
2025-03-16 04:07:46.619083:  
2025-03-16 04:07:46.624606: Epoch 24 
2025-03-16 04:07:46.628120: Current learning rate: 0.00781 
2025-03-16 04:08:23.474363: train_loss -0.8874 
2025-03-16 04:08:23.480436: val_loss -0.706 
2025-03-16 04:08:23.483502: Pseudo dice [np.float32(0.6619), np.float32(0.8784)] 
2025-03-16 04:08:23.486008: Epoch time: 36.86 s 
2025-03-16 04:08:23.489520: Yayy! New best EMA pseudo Dice: 0.754800021648407 
2025-03-16 04:08:24.233461:  
2025-03-16 04:08:24.238469: Epoch 25 
2025-03-16 04:08:24.241976: Current learning rate: 0.00772 
2025-03-16 04:09:01.073200: train_loss -0.8832 
2025-03-16 04:09:01.078716: val_loss -0.6999 
2025-03-16 04:09:01.082224: Pseudo dice [np.float32(0.6587), np.float32(0.8832)] 
2025-03-16 04:09:01.086230: Epoch time: 36.84 s 
2025-03-16 04:09:01.089737: Yayy! New best EMA pseudo Dice: 0.7563999891281128 
2025-03-16 04:09:01.837317:  
2025-03-16 04:09:01.843325: Epoch 26 
2025-03-16 04:09:01.846337: Current learning rate: 0.00763 
2025-03-16 04:09:38.707587: train_loss -0.8964 
2025-03-16 04:09:38.714165: val_loss -0.7008 
2025-03-16 04:09:38.717817: Pseudo dice [np.float32(0.6567), np.float32(0.8829)] 
2025-03-16 04:09:38.721328: Epoch time: 36.87 s 
2025-03-16 04:09:38.724336: Yayy! New best EMA pseudo Dice: 0.7577000260353088 
2025-03-16 04:09:39.614031:  
2025-03-16 04:09:39.620784: Epoch 27 
2025-03-16 04:09:39.623326: Current learning rate: 0.00753 
2025-03-16 04:10:16.453008: train_loss -0.9048 
2025-03-16 04:10:16.459133: val_loss -0.701 
2025-03-16 04:10:16.462195: Pseudo dice [np.float32(0.6582), np.float32(0.8839)] 
2025-03-16 04:10:16.466251: Epoch time: 36.84 s 
2025-03-16 04:10:16.469855: Yayy! New best EMA pseudo Dice: 0.7590000033378601 
2025-03-16 04:10:17.236854:  
2025-03-16 04:10:17.243375: Epoch 28 
2025-03-16 04:10:17.246886: Current learning rate: 0.00744 
2025-03-16 04:10:54.092937: train_loss -0.8819 
2025-03-16 04:10:54.100509: val_loss -0.6782 
2025-03-16 04:10:54.104520: Pseudo dice [np.float32(0.6245), np.float32(0.8818)] 
2025-03-16 04:10:54.108033: Epoch time: 36.86 s 
2025-03-16 04:10:54.625070:  
2025-03-16 04:10:54.631595: Epoch 29 
2025-03-16 04:10:54.635108: Current learning rate: 0.00735 
2025-03-16 04:11:31.460468: train_loss -0.8981 
2025-03-16 04:11:31.467006: val_loss -0.7089 
2025-03-16 04:11:31.469514: Pseudo dice [np.float32(0.6682), np.float32(0.8867)] 
2025-03-16 04:11:31.473029: Epoch time: 36.84 s 
2025-03-16 04:11:31.477040: Yayy! New best EMA pseudo Dice: 0.7603999972343445 
2025-03-16 04:11:32.221566:  
2025-03-16 04:11:32.226597: Epoch 30 
2025-03-16 04:11:32.230165: Current learning rate: 0.00725 
2025-03-16 04:12:09.062070: train_loss -0.9024 
2025-03-16 04:12:09.068187: val_loss -0.7041 
2025-03-16 04:12:09.071223: Pseudo dice [np.float32(0.6602), np.float32(0.8885)] 
2025-03-16 04:12:09.075248: Epoch time: 36.84 s 
2025-03-16 04:12:09.078307: Yayy! New best EMA pseudo Dice: 0.7617999911308289 
2025-03-16 04:12:09.837432:  
2025-03-16 04:12:09.841455: Epoch 31 
2025-03-16 04:12:09.845498: Current learning rate: 0.00716 
2025-03-16 04:12:46.700171: train_loss -0.8957 
2025-03-16 04:12:46.706846: val_loss -0.7084 
2025-03-16 04:12:46.709361: Pseudo dice [np.float32(0.6729), np.float32(0.8865)] 
2025-03-16 04:12:46.712866: Epoch time: 36.86 s 
2025-03-16 04:12:46.715881: Yayy! New best EMA pseudo Dice: 0.7634999752044678 
2025-03-16 04:12:47.500111:  
2025-03-16 04:12:47.505687: Epoch 32 
2025-03-16 04:12:47.508790: Current learning rate: 0.00707 
2025-03-16 04:13:24.370506: train_loss -0.894 
2025-03-16 04:13:24.376530: val_loss -0.705 
2025-03-16 04:13:24.380039: Pseudo dice [np.float32(0.6673), np.float32(0.8872)] 
2025-03-16 04:13:24.383051: Epoch time: 36.87 s 
2025-03-16 04:13:24.386567: Yayy! New best EMA pseudo Dice: 0.7649000287055969 
2025-03-16 04:13:25.138441:  
2025-03-16 04:13:25.144617: Epoch 33 
2025-03-16 04:13:25.148129: Current learning rate: 0.00697 
2025-03-16 04:14:02.027219: train_loss -0.9005 
2025-03-16 04:14:02.033364: val_loss -0.6982 
2025-03-16 04:14:02.037385: Pseudo dice [np.float32(0.663), np.float32(0.8795)] 
2025-03-16 04:14:02.039896: Epoch time: 36.89 s 
2025-03-16 04:14:02.043415: Yayy! New best EMA pseudo Dice: 0.765500009059906 
2025-03-16 04:14:02.797422:  
2025-03-16 04:14:02.802935: Epoch 34 
2025-03-16 04:14:02.806447: Current learning rate: 0.00688 
2025-03-16 04:14:39.656652: train_loss -0.8943 
2025-03-16 04:14:39.661661: val_loss -0.6935 
2025-03-16 04:14:39.665170: Pseudo dice [np.float32(0.6479), np.float32(0.8849)] 
2025-03-16 04:14:39.668674: Epoch time: 36.86 s 
2025-03-16 04:14:39.671679: Yayy! New best EMA pseudo Dice: 0.7656000256538391 
2025-03-16 04:14:40.580955:  
2025-03-16 04:14:40.585966: Epoch 35 
2025-03-16 04:14:40.589977: Current learning rate: 0.00679 
2025-03-16 04:15:17.449510: train_loss -0.8986 
2025-03-16 04:15:17.456061: val_loss -0.6965 
2025-03-16 04:15:17.458573: Pseudo dice [np.float32(0.6594), np.float32(0.8861)] 
2025-03-16 04:15:17.462080: Epoch time: 36.87 s 
2025-03-16 04:15:17.465584: Yayy! New best EMA pseudo Dice: 0.7663000226020813 
2025-03-16 04:15:18.223794:  
2025-03-16 04:15:18.229406: Epoch 36 
2025-03-16 04:15:18.232975: Current learning rate: 0.00669 
2025-03-16 04:15:55.091764: train_loss -0.9 
2025-03-16 04:15:55.099324: val_loss -0.702 
2025-03-16 04:15:55.101831: Pseudo dice [np.float32(0.6679), np.float32(0.8825)] 
2025-03-16 04:15:55.105340: Epoch time: 36.87 s 
2025-03-16 04:15:55.108350: Yayy! New best EMA pseudo Dice: 0.7671999931335449 
2025-03-16 04:15:55.861053:  
2025-03-16 04:15:55.866598: Epoch 37 
2025-03-16 04:15:55.869460: Current learning rate: 0.0066 
2025-03-16 04:16:32.741133: train_loss -0.9067 
2025-03-16 04:16:32.747149: val_loss -0.7071 
2025-03-16 04:16:32.750159: Pseudo dice [np.float32(0.6701), np.float32(0.8874)] 
2025-03-16 04:16:32.753671: Epoch time: 36.88 s 
2025-03-16 04:16:32.756177: Yayy! New best EMA pseudo Dice: 0.7684000134468079 
2025-03-16 04:16:33.512455:  
2025-03-16 04:16:33.518468: Epoch 38 
2025-03-16 04:16:33.521476: Current learning rate: 0.0065 
2025-03-16 04:17:10.385665: train_loss -0.8998 
2025-03-16 04:17:10.391730: val_loss -0.6978 
2025-03-16 04:17:10.394128: Pseudo dice [np.float32(0.6552), np.float32(0.8864)] 
2025-03-16 04:17:10.398710: Epoch time: 36.87 s 
2025-03-16 04:17:10.401221: Yayy! New best EMA pseudo Dice: 0.7685999870300293 
2025-03-16 04:17:11.173663:  
2025-03-16 04:17:11.179180: Epoch 39 
2025-03-16 04:17:11.182692: Current learning rate: 0.00641 
2025-03-16 04:17:48.031976: train_loss -0.907 
2025-03-16 04:17:48.039613: val_loss -0.6983 
2025-03-16 04:17:48.043653: Pseudo dice [np.float32(0.6586), np.float32(0.8868)] 
2025-03-16 04:17:48.046722: Epoch time: 36.86 s 
2025-03-16 04:17:48.049786: Yayy! New best EMA pseudo Dice: 0.7689999938011169 
2025-03-16 04:17:48.823424:  
2025-03-16 04:17:48.828435: Epoch 40 
2025-03-16 04:17:48.831946: Current learning rate: 0.00631 
2025-03-16 04:18:25.680601: train_loss -0.9086 
2025-03-16 04:18:25.686617: val_loss -0.6981 
2025-03-16 04:18:25.689628: Pseudo dice [np.float32(0.6639), np.float32(0.8869)] 
2025-03-16 04:18:25.693141: Epoch time: 36.86 s 
2025-03-16 04:18:25.695648: Yayy! New best EMA pseudo Dice: 0.7696999907493591 
2025-03-16 04:18:26.461931:  
2025-03-16 04:18:26.467028: Epoch 41 
2025-03-16 04:18:26.470539: Current learning rate: 0.00622 
2025-03-16 04:19:03.327009: train_loss -0.9095 
2025-03-16 04:19:03.334537: val_loss -0.696 
2025-03-16 04:19:03.338048: Pseudo dice [np.float32(0.6602), np.float32(0.8825)] 
2025-03-16 04:19:03.340554: Epoch time: 36.87 s 
2025-03-16 04:19:03.344057: Yayy! New best EMA pseudo Dice: 0.7698000073432922 
2025-03-16 04:19:04.233826:  
2025-03-16 04:19:04.238836: Epoch 42 
2025-03-16 04:19:04.242848: Current learning rate: 0.00612 
2025-03-16 04:19:41.105188: train_loss -0.8985 
2025-03-16 04:19:41.111272: val_loss -0.7029 
2025-03-16 04:19:41.114795: Pseudo dice [np.float32(0.6729), np.float32(0.8859)] 
2025-03-16 04:19:41.117301: Epoch time: 36.87 s 
2025-03-16 04:19:41.120811: Yayy! New best EMA pseudo Dice: 0.770799994468689 
2025-03-16 04:19:41.864264:  
2025-03-16 04:19:41.869274: Epoch 43 
2025-03-16 04:19:41.871781: Current learning rate: 0.00603 
2025-03-16 04:20:18.714453: train_loss -0.9153 
2025-03-16 04:20:18.720535: val_loss -0.6929 
2025-03-16 04:20:18.723603: Pseudo dice [np.float32(0.6588), np.float32(0.8865)] 
2025-03-16 04:20:18.727132: Epoch time: 36.85 s 
2025-03-16 04:20:18.730158: Yayy! New best EMA pseudo Dice: 0.7710000276565552 
2025-03-16 04:20:19.540062:  
2025-03-16 04:20:19.545580: Epoch 44 
2025-03-16 04:20:19.549095: Current learning rate: 0.00593 
2025-03-16 04:20:56.392795: train_loss -0.896 
2025-03-16 04:20:56.398368: val_loss -0.6885 
2025-03-16 04:20:56.402908: Pseudo dice [np.float32(0.6495), np.float32(0.8831)] 
2025-03-16 04:20:56.406422: Epoch time: 36.85 s 
2025-03-16 04:20:56.918888:  
2025-03-16 04:20:56.924913: Epoch 45 
2025-03-16 04:20:56.926922: Current learning rate: 0.00584 
2025-03-16 04:21:33.780927: train_loss -0.9068 
2025-03-16 04:21:33.787975: val_loss -0.7104 
2025-03-16 04:21:33.791487: Pseudo dice [np.float32(0.6864), np.float32(0.8837)] 
2025-03-16 04:21:33.795500: Epoch time: 36.86 s 
2025-03-16 04:21:33.799015: Yayy! New best EMA pseudo Dice: 0.7720000147819519 
2025-03-16 04:21:34.543025:  
2025-03-16 04:21:34.548606: Epoch 46 
2025-03-16 04:21:34.551954: Current learning rate: 0.00574 
2025-03-16 04:22:11.436718: train_loss -0.907 
2025-03-16 04:22:11.443341: val_loss -0.6971 
2025-03-16 04:22:11.446931: Pseudo dice [np.float32(0.6621), np.float32(0.889)] 
2025-03-16 04:22:11.450493: Epoch time: 36.89 s 
2025-03-16 04:22:11.453001: Yayy! New best EMA pseudo Dice: 0.7723000049591064 
2025-03-16 04:22:12.198866:  
2025-03-16 04:22:12.204395: Epoch 47 
2025-03-16 04:22:12.207436: Current learning rate: 0.00565 
2025-03-16 04:22:49.084965: train_loss -0.915 
2025-03-16 04:22:49.091595: val_loss -0.6989 
2025-03-16 04:22:49.095135: Pseudo dice [np.float32(0.6677), np.float32(0.8861)] 
2025-03-16 04:22:49.097648: Epoch time: 36.89 s 
2025-03-16 04:22:49.101166: Yayy! New best EMA pseudo Dice: 0.7728000283241272 
2025-03-16 04:22:49.860424:  
2025-03-16 04:22:49.865979: Epoch 48 
2025-03-16 04:22:49.869011: Current learning rate: 0.00555 
2025-03-16 04:23:26.723298: train_loss -0.9148 
2025-03-16 04:23:26.730818: val_loss -0.6939 
2025-03-16 04:23:26.734830: Pseudo dice [np.float32(0.6606), np.float32(0.8848)] 
2025-03-16 04:23:26.739338: Epoch time: 36.86 s 
2025-03-16 04:23:27.401328:  
2025-03-16 04:23:27.407399: Epoch 49 
2025-03-16 04:23:27.410949: Current learning rate: 0.00546 
2025-03-16 04:24:04.270437: train_loss -0.9134 
2025-03-16 04:24:04.275981: val_loss -0.7056 
2025-03-16 04:24:04.279493: Pseudo dice [np.float32(0.6775), np.float32(0.8869)] 
2025-03-16 04:24:04.283016: Epoch time: 36.87 s 
2025-03-16 04:24:04.484901: Yayy! New best EMA pseudo Dice: 0.7736999988555908 
2025-03-16 04:24:05.232459:  
2025-03-16 04:24:05.237977: Epoch 50 
2025-03-16 04:24:05.241489: Current learning rate: 0.00536 
2025-03-16 04:24:42.100980: train_loss -0.9112 
2025-03-16 04:24:42.106040: val_loss -0.6908 
2025-03-16 04:24:42.110076: Pseudo dice [np.float32(0.6604), np.float32(0.8831)] 
2025-03-16 04:24:42.113084: Epoch time: 36.87 s 
2025-03-16 04:24:42.630242:  
2025-03-16 04:24:42.636269: Epoch 51 
2025-03-16 04:24:42.638776: Current learning rate: 0.00526 
2025-03-16 04:25:19.492838: train_loss -0.9063 
2025-03-16 04:25:19.499924: val_loss -0.7069 
2025-03-16 04:25:19.502966: Pseudo dice [np.float32(0.6818), np.float32(0.8889)] 
2025-03-16 04:25:19.505998: Epoch time: 36.86 s 
2025-03-16 04:25:19.509527: Yayy! New best EMA pseudo Dice: 0.7746999859809875 
2025-03-16 04:25:20.259798:  
2025-03-16 04:25:20.264858: Epoch 52 
2025-03-16 04:25:20.268375: Current learning rate: 0.00517 
2025-03-16 04:25:57.108981: train_loss -0.9094 
2025-03-16 04:25:57.115502: val_loss -0.7033 
2025-03-16 04:25:57.119517: Pseudo dice [np.float32(0.675), np.float32(0.8882)] 
2025-03-16 04:25:57.123027: Epoch time: 36.85 s 
2025-03-16 04:25:57.125535: Yayy! New best EMA pseudo Dice: 0.7753999829292297 
2025-03-16 04:25:57.881741:  
2025-03-16 04:25:57.887754: Epoch 53 
2025-03-16 04:25:57.891768: Current learning rate: 0.00507 
2025-03-16 04:26:34.754491: train_loss -0.9178 
2025-03-16 04:26:34.761066: val_loss -0.6943 
2025-03-16 04:26:34.764571: Pseudo dice [np.float32(0.6661), np.float32(0.8878)] 
2025-03-16 04:26:34.767579: Epoch time: 36.87 s 
2025-03-16 04:26:34.773590: Yayy! New best EMA pseudo Dice: 0.775600016117096 
2025-03-16 04:26:35.521633:  
2025-03-16 04:26:35.528203: Epoch 54 
2025-03-16 04:26:35.530797: Current learning rate: 0.00497 
2025-03-16 04:27:12.370615: train_loss -0.9105 
2025-03-16 04:27:12.377157: val_loss -0.688 
2025-03-16 04:27:12.380673: Pseudo dice [np.float32(0.6599), np.float32(0.8841)] 
2025-03-16 04:27:12.384691: Epoch time: 36.85 s 
2025-03-16 04:27:12.908418:  
2025-03-16 04:27:12.915041: Epoch 55 
2025-03-16 04:27:12.918080: Current learning rate: 0.00487 
2025-03-16 04:27:49.779657: train_loss -0.9102 
2025-03-16 04:27:49.787203: val_loss -0.6894 
2025-03-16 04:27:49.792217: Pseudo dice [np.float32(0.6576), np.float32(0.8861)] 
2025-03-16 04:27:49.796231: Epoch time: 36.87 s 
2025-03-16 04:27:50.329655:  
2025-03-16 04:27:50.335169: Epoch 56 
2025-03-16 04:27:50.339682: Current learning rate: 0.00478 
2025-03-16 04:28:27.198005: train_loss -0.9208 
2025-03-16 04:28:27.204125: val_loss -0.6984 
2025-03-16 04:28:27.207186: Pseudo dice [np.float32(0.6671), np.float32(0.8893)] 
2025-03-16 04:28:27.213705: Epoch time: 36.87 s 
2025-03-16 04:28:27.874993:  
2025-03-16 04:28:27.881549: Epoch 57 
2025-03-16 04:28:27.884191: Current learning rate: 0.00468 
2025-03-16 04:29:04.720687: train_loss -0.9196 
2025-03-16 04:29:04.727321: val_loss -0.6982 
2025-03-16 04:29:04.731350: Pseudo dice [np.float32(0.6704), np.float32(0.8902)] 
2025-03-16 04:29:04.734931: Epoch time: 36.85 s 
2025-03-16 04:29:04.738447: Yayy! New best EMA pseudo Dice: 0.7756999731063843 
2025-03-16 04:29:05.491304:  
2025-03-16 04:29:05.496313: Epoch 58 
2025-03-16 04:29:05.499827: Current learning rate: 0.00458 
2025-03-16 04:29:42.350069: train_loss -0.9147 
2025-03-16 04:29:42.355603: val_loss -0.6863 
2025-03-16 04:29:42.359113: Pseudo dice [np.float32(0.6614), np.float32(0.8836)] 
2025-03-16 04:29:42.361619: Epoch time: 36.86 s 
2025-03-16 04:29:42.891266:  
2025-03-16 04:29:42.896786: Epoch 59 
2025-03-16 04:29:42.900298: Current learning rate: 0.00448 
2025-03-16 04:30:19.730096: train_loss -0.9196 
2025-03-16 04:30:19.736618: val_loss -0.6938 
2025-03-16 04:30:19.740183: Pseudo dice [np.float32(0.668), np.float32(0.8866)] 
2025-03-16 04:30:19.743210: Epoch time: 36.84 s 
2025-03-16 04:30:20.273381:  
2025-03-16 04:30:20.278423: Epoch 60 
2025-03-16 04:30:20.281288: Current learning rate: 0.00438 
2025-03-16 04:30:57.129036: train_loss -0.9232 
2025-03-16 04:30:57.136187: val_loss -0.6849 
2025-03-16 04:30:57.139282: Pseudo dice [np.float32(0.6597), np.float32(0.8851)] 
2025-03-16 04:30:57.142338: Epoch time: 36.86 s 
2025-03-16 04:30:57.668669:  
2025-03-16 04:30:57.674277: Epoch 61 
2025-03-16 04:30:57.677341: Current learning rate: 0.00429 
2025-03-16 04:31:34.511195: train_loss -0.9184 
2025-03-16 04:31:34.516254: val_loss -0.6947 
2025-03-16 04:31:34.519814: Pseudo dice [np.float32(0.6702), np.float32(0.8866)] 
2025-03-16 04:31:34.522849: Epoch time: 36.84 s 
2025-03-16 04:31:35.049623:  
2025-03-16 04:31:35.055243: Epoch 62 
2025-03-16 04:31:35.058284: Current learning rate: 0.00419 
2025-03-16 04:32:11.920068: train_loss -0.926 
2025-03-16 04:32:11.926081: val_loss -0.6905 
2025-03-16 04:32:11.929591: Pseudo dice [np.float32(0.6604), np.float32(0.8876)] 
2025-03-16 04:32:11.932603: Epoch time: 36.87 s 
2025-03-16 04:32:12.458236:  
2025-03-16 04:32:12.464535: Epoch 63 
2025-03-16 04:32:12.468057: Current learning rate: 0.00409 
2025-03-16 04:32:49.321851: train_loss -0.9136 
2025-03-16 04:32:49.327711: val_loss -0.6965 
2025-03-16 04:32:49.331223: Pseudo dice [np.float32(0.6812), np.float32(0.8858)] 
2025-03-16 04:32:49.334739: Epoch time: 36.86 s 
2025-03-16 04:32:49.337751: Yayy! New best EMA pseudo Dice: 0.776199996471405 
2025-03-16 04:32:50.097231:  
2025-03-16 04:32:50.102256: Epoch 64 
2025-03-16 04:32:50.105287: Current learning rate: 0.00399 
2025-03-16 04:33:26.985370: train_loss -0.9243 
2025-03-16 04:33:26.991392: val_loss -0.6911 
2025-03-16 04:33:26.995025: Pseudo dice [np.float32(0.6681), np.float32(0.8835)] 
2025-03-16 04:33:26.998155: Epoch time: 36.89 s 
2025-03-16 04:33:27.682055:  
2025-03-16 04:33:27.687568: Epoch 65 
2025-03-16 04:33:27.691075: Current learning rate: 0.00389 
2025-03-16 04:34:04.532826: train_loss -0.921 
2025-03-16 04:34:04.539398: val_loss -0.6892 
2025-03-16 04:34:04.542479: Pseudo dice [np.float32(0.6626), np.float32(0.8909)] 
2025-03-16 04:34:04.545991: Epoch time: 36.85 s 
2025-03-16 04:34:04.549498: Yayy! New best EMA pseudo Dice: 0.776199996471405 
2025-03-16 04:34:05.321856:  
2025-03-16 04:34:05.327922: Epoch 66 
2025-03-16 04:34:05.330962: Current learning rate: 0.00379 
2025-03-16 04:34:42.171295: train_loss -0.9218 
2025-03-16 04:34:42.177335: val_loss -0.6923 
2025-03-16 04:34:42.180882: Pseudo dice [np.float32(0.6704), np.float32(0.8863)] 
2025-03-16 04:34:42.183410: Epoch time: 36.85 s 
2025-03-16 04:34:42.185935: Yayy! New best EMA pseudo Dice: 0.7764999866485596 
2025-03-16 04:34:42.936893:  
2025-03-16 04:34:42.943513: Epoch 67 
2025-03-16 04:34:42.946072: Current learning rate: 0.00369 
2025-03-16 04:35:19.787228: train_loss -0.9331 
2025-03-16 04:35:19.792747: val_loss -0.6991 
2025-03-16 04:35:19.796259: Pseudo dice [np.float32(0.6756), np.float32(0.8898)] 
2025-03-16 04:35:19.799766: Epoch time: 36.85 s 
2025-03-16 04:35:19.802775: Yayy! New best EMA pseudo Dice: 0.7771000266075134 
2025-03-16 04:35:20.573494:  
2025-03-16 04:35:20.580007: Epoch 68 
2025-03-16 04:35:20.583515: Current learning rate: 0.00359 
2025-03-16 04:35:57.436288: train_loss -0.9239 
2025-03-16 04:35:57.442329: val_loss -0.6919 
2025-03-16 04:35:57.445390: Pseudo dice [np.float32(0.672), np.float32(0.8866)] 
2025-03-16 04:35:57.448956: Epoch time: 36.86 s 
2025-03-16 04:35:57.452487: Yayy! New best EMA pseudo Dice: 0.7773000001907349 
2025-03-16 04:35:58.203487:  
2025-03-16 04:35:58.209622: Epoch 69 
2025-03-16 04:35:58.213172: Current learning rate: 0.00349 
2025-03-16 04:36:35.053668: train_loss -0.9274 
2025-03-16 04:36:35.058681: val_loss -0.6793 
2025-03-16 04:36:35.062693: Pseudo dice [np.float32(0.6614), np.float32(0.883)] 
2025-03-16 04:36:35.066204: Epoch time: 36.85 s 
2025-03-16 04:36:35.601112:  
2025-03-16 04:36:35.607166: Epoch 70 
2025-03-16 04:36:35.609767: Current learning rate: 0.00338 
2025-03-16 04:37:12.467006: train_loss -0.93 
2025-03-16 04:37:12.472567: val_loss -0.701 
2025-03-16 04:37:12.475595: Pseudo dice [np.float32(0.6833), np.float32(0.8877)] 
2025-03-16 04:37:12.479607: Epoch time: 36.87 s 
2025-03-16 04:37:12.482158: Yayy! New best EMA pseudo Dice: 0.7777000069618225 
2025-03-16 04:37:13.245101:  
2025-03-16 04:37:13.250646: Epoch 71 
2025-03-16 04:37:13.254686: Current learning rate: 0.00328 
2025-03-16 04:37:50.107650: train_loss -0.9217 
2025-03-16 04:37:50.113181: val_loss -0.6812 
2025-03-16 04:37:50.117189: Pseudo dice [np.float32(0.6688), np.float32(0.8844)] 
2025-03-16 04:37:50.120706: Epoch time: 36.86 s 
2025-03-16 04:37:50.802063:  
2025-03-16 04:37:50.807085: Epoch 72 
2025-03-16 04:37:50.810597: Current learning rate: 0.00318 
2025-03-16 04:38:27.659089: train_loss -0.9098 
2025-03-16 04:38:27.665133: val_loss -0.6788 
2025-03-16 04:38:27.668144: Pseudo dice [np.float32(0.6603), np.float32(0.881)] 
2025-03-16 04:38:27.671657: Epoch time: 36.86 s 
2025-03-16 04:38:28.234848:  
2025-03-16 04:38:28.240444: Epoch 73 
2025-03-16 04:38:28.244015: Current learning rate: 0.00308 
2025-03-16 04:39:05.113153: train_loss -0.9228 
2025-03-16 04:39:05.119732: val_loss -0.6833 
2025-03-16 04:39:05.122785: Pseudo dice [np.float32(0.6632), np.float32(0.8837)] 
2025-03-16 04:39:05.125836: Epoch time: 36.88 s 
2025-03-16 04:39:05.669421:  
2025-03-16 04:39:05.674467: Epoch 74 
2025-03-16 04:39:05.677974: Current learning rate: 0.00297 
2025-03-16 04:39:42.544670: train_loss -0.9277 
2025-03-16 04:39:42.549767: val_loss -0.6801 
2025-03-16 04:39:42.553324: Pseudo dice [np.float32(0.6594), np.float32(0.8834)] 
2025-03-16 04:39:42.556861: Epoch time: 36.88 s 
2025-03-16 04:39:43.090805:  
2025-03-16 04:39:43.095835: Epoch 75 
2025-03-16 04:39:43.098837: Current learning rate: 0.00287 
2025-03-16 04:40:19.963532: train_loss -0.9222 
2025-03-16 04:40:19.970081: val_loss -0.6846 
2025-03-16 04:40:19.973092: Pseudo dice [np.float32(0.6651), np.float32(0.8855)] 
2025-03-16 04:40:19.976600: Epoch time: 36.87 s 
2025-03-16 04:40:20.514525:  
2025-03-16 04:40:20.520563: Epoch 76 
2025-03-16 04:40:20.524086: Current learning rate: 0.00277 
2025-03-16 04:40:57.361170: train_loss -0.9233 
2025-03-16 04:40:57.368272: val_loss -0.6877 
2025-03-16 04:40:57.371385: Pseudo dice [np.float32(0.6757), np.float32(0.8814)] 
2025-03-16 04:40:57.374965: Epoch time: 36.85 s 
2025-03-16 04:40:57.911058:  
2025-03-16 04:40:57.916613: Epoch 77 
2025-03-16 04:40:57.919122: Current learning rate: 0.00266 
2025-03-16 04:41:34.758100: train_loss -0.9328 
2025-03-16 04:41:34.764125: val_loss -0.6883 
2025-03-16 04:41:34.768135: Pseudo dice [np.float32(0.6784), np.float32(0.8853)] 
2025-03-16 04:41:34.770642: Epoch time: 36.85 s 
2025-03-16 04:41:35.321784:  
2025-03-16 04:41:35.326839: Epoch 78 
2025-03-16 04:41:35.330363: Current learning rate: 0.00256 
2025-03-16 04:42:12.170423: train_loss -0.9305 
2025-03-16 04:42:12.176475: val_loss -0.6877 
2025-03-16 04:42:12.180487: Pseudo dice [np.float32(0.672), np.float32(0.8863)] 
2025-03-16 04:42:12.184000: Epoch time: 36.85 s 
2025-03-16 04:42:12.722499:  
2025-03-16 04:42:12.728593: Epoch 79 
2025-03-16 04:42:12.731659: Current learning rate: 0.00245 
2025-03-16 04:42:49.557327: train_loss -0.9313 
2025-03-16 04:42:49.563374: val_loss -0.6826 
2025-03-16 04:42:49.565892: Pseudo dice [np.float32(0.666), np.float32(0.887)] 
2025-03-16 04:42:49.570014: Epoch time: 36.83 s 
2025-03-16 04:42:50.256609:  
2025-03-16 04:42:50.262132: Epoch 80 
2025-03-16 04:42:50.265642: Current learning rate: 0.00235 
2025-03-16 04:43:27.144583: train_loss -0.9281 
2025-03-16 04:43:27.151735: val_loss -0.6858 
2025-03-16 04:43:27.154794: Pseudo dice [np.float32(0.6707), np.float32(0.8874)] 
2025-03-16 04:43:27.157848: Epoch time: 36.89 s 
2025-03-16 04:43:27.708211:  
2025-03-16 04:43:27.713464: Epoch 81 
2025-03-16 04:43:27.716524: Current learning rate: 0.00224 
2025-03-16 04:44:04.571131: train_loss -0.9279 
2025-03-16 04:44:04.577450: val_loss -0.6729 
2025-03-16 04:44:04.581020: Pseudo dice [np.float32(0.6594), np.float32(0.8835)] 
2025-03-16 04:44:04.584080: Epoch time: 36.86 s 
2025-03-16 04:44:05.129710:  
2025-03-16 04:44:05.135257: Epoch 82 
2025-03-16 04:44:05.138831: Current learning rate: 0.00214 
2025-03-16 04:44:42.011084: train_loss -0.9266 
2025-03-16 04:44:42.017097: val_loss -0.6752 
2025-03-16 04:44:42.019605: Pseudo dice [np.float32(0.6624), np.float32(0.8866)] 
2025-03-16 04:44:42.023620: Epoch time: 36.88 s 
2025-03-16 04:44:42.538231:  
2025-03-16 04:44:42.543743: Epoch 83 
2025-03-16 04:44:42.547292: Current learning rate: 0.00203 
2025-03-16 04:45:19.398292: train_loss -0.9362 
2025-03-16 04:45:19.403896: val_loss -0.683 
2025-03-16 04:45:19.408484: Pseudo dice [np.float32(0.6714), np.float32(0.883)] 
2025-03-16 04:45:19.411552: Epoch time: 36.86 s 
2025-03-16 04:45:19.932537:  
2025-03-16 04:45:19.937589: Epoch 84 
2025-03-16 04:45:19.941102: Current learning rate: 0.00192 
2025-03-16 04:45:56.797019: train_loss -0.9209 
2025-03-16 04:45:56.805054: val_loss -0.679 
2025-03-16 04:45:56.808088: Pseudo dice [np.float32(0.6648), np.float32(0.8869)] 
2025-03-16 04:45:56.811595: Epoch time: 36.86 s 
2025-03-16 04:45:57.321447:  
2025-03-16 04:45:57.327054: Epoch 85 
2025-03-16 04:45:57.330599: Current learning rate: 0.00181 
2025-03-16 04:46:34.179099: train_loss -0.9287 
2025-03-16 04:46:34.185119: val_loss -0.6853 
2025-03-16 04:46:34.187625: Pseudo dice [np.float32(0.6752), np.float32(0.8865)] 
2025-03-16 04:46:34.191639: Epoch time: 36.86 s 
2025-03-16 04:46:34.706372:  
2025-03-16 04:46:34.712489: Epoch 86 
2025-03-16 04:46:34.715535: Current learning rate: 0.0017 
2025-03-16 04:47:11.572379: train_loss -0.9351 
2025-03-16 04:47:11.578498: val_loss -0.6699 
2025-03-16 04:47:11.582060: Pseudo dice [np.float32(0.6565), np.float32(0.8865)] 
2025-03-16 04:47:11.585118: Epoch time: 36.87 s 
2025-03-16 04:47:12.087629:  
2025-03-16 04:47:12.094143: Epoch 87 
2025-03-16 04:47:12.098155: Current learning rate: 0.00159 
2025-03-16 04:47:48.949948: train_loss -0.9231 
2025-03-16 04:47:48.955486: val_loss -0.6715 
2025-03-16 04:47:48.959002: Pseudo dice [np.float32(0.6572), np.float32(0.8861)] 
2025-03-16 04:47:48.961511: Epoch time: 36.86 s 
2025-03-16 04:47:49.626932:  
2025-03-16 04:47:49.632464: Epoch 88 
2025-03-16 04:47:49.635975: Current learning rate: 0.00148 
2025-03-16 04:48:26.474989: train_loss -0.9309 
2025-03-16 04:48:26.481010: val_loss -0.6785 
2025-03-16 04:48:26.485026: Pseudo dice [np.float32(0.6689), np.float32(0.8841)] 
2025-03-16 04:48:26.487535: Epoch time: 36.85 s 
2025-03-16 04:48:26.998103:  
2025-03-16 04:48:27.003126: Epoch 89 
2025-03-16 04:48:27.006643: Current learning rate: 0.00137 
2025-03-16 04:49:03.861300: train_loss -0.9347 
2025-03-16 04:49:03.868904: val_loss -0.6719 
2025-03-16 04:49:03.872419: Pseudo dice [np.float32(0.6564), np.float32(0.8863)] 
2025-03-16 04:49:03.874929: Epoch time: 36.86 s 
2025-03-16 04:49:04.388959:  
2025-03-16 04:49:04.394999: Epoch 90 
2025-03-16 04:49:04.398034: Current learning rate: 0.00126 
2025-03-16 04:49:41.247883: train_loss -0.9276 
2025-03-16 04:49:41.254503: val_loss -0.668 
2025-03-16 04:49:41.258074: Pseudo dice [np.float32(0.6506), np.float32(0.8886)] 
2025-03-16 04:49:41.260631: Epoch time: 36.86 s 
2025-03-16 04:49:41.780146:  
2025-03-16 04:49:41.785679: Epoch 91 
2025-03-16 04:49:41.789240: Current learning rate: 0.00115 
2025-03-16 04:50:18.633853: train_loss -0.9403 
2025-03-16 04:50:18.640887: val_loss -0.6789 
2025-03-16 04:50:18.643187: Pseudo dice [np.float32(0.6679), np.float32(0.8864)] 
2025-03-16 04:50:18.647736: Epoch time: 36.85 s 
2025-03-16 04:50:19.164738:  
2025-03-16 04:50:19.170278: Epoch 92 
2025-03-16 04:50:19.173350: Current learning rate: 0.00103 
2025-03-16 04:50:56.042955: train_loss -0.9291 
2025-03-16 04:50:56.047968: val_loss -0.671 
2025-03-16 04:50:56.051485: Pseudo dice [np.float32(0.6581), np.float32(0.8869)] 
2025-03-16 04:50:56.053997: Epoch time: 36.88 s 
2025-03-16 04:50:56.558551:  
2025-03-16 04:50:56.563572: Epoch 93 
2025-03-16 04:50:56.567091: Current learning rate: 0.00091 
2025-03-16 04:51:33.424088: train_loss -0.9316 
2025-03-16 04:51:33.429681: val_loss -0.6643 
2025-03-16 04:51:33.433200: Pseudo dice [np.float32(0.6573), np.float32(0.8868)] 
2025-03-16 04:51:33.436306: Epoch time: 36.87 s 
2025-03-16 04:51:33.947129:  
2025-03-16 04:51:33.952149: Epoch 94 
2025-03-16 04:51:33.955661: Current learning rate: 0.00079 
2025-03-16 04:52:10.822355: train_loss -0.9383 
2025-03-16 04:52:10.828418: val_loss -0.6786 
2025-03-16 04:52:10.831463: Pseudo dice [np.float32(0.6694), np.float32(0.8884)] 
2025-03-16 04:52:10.834001: Epoch time: 36.88 s 
2025-03-16 04:52:11.343358:  
2025-03-16 04:52:11.349408: Epoch 95 
2025-03-16 04:52:11.353004: Current learning rate: 0.00067 
2025-03-16 04:52:48.210047: train_loss -0.9222 
2025-03-16 04:52:48.216077: val_loss -0.6729 
2025-03-16 04:52:48.219576: Pseudo dice [np.float32(0.6608), np.float32(0.8838)] 
2025-03-16 04:52:48.222588: Epoch time: 36.87 s 
2025-03-16 04:52:48.882192:  
2025-03-16 04:52:48.887968: Epoch 96 
2025-03-16 04:52:48.891491: Current learning rate: 0.00055 
2025-03-16 04:53:25.742775: train_loss -0.929 
2025-03-16 04:53:25.747873: val_loss -0.6773 
2025-03-16 04:53:25.750416: Pseudo dice [np.float32(0.669), np.float32(0.8863)] 
2025-03-16 04:53:25.754459: Epoch time: 36.86 s 
2025-03-16 04:53:26.269473:  
2025-03-16 04:53:26.275010: Epoch 97 
2025-03-16 04:53:26.278528: Current learning rate: 0.00043 
2025-03-16 04:54:03.116321: train_loss -0.934 
2025-03-16 04:54:03.122389: val_loss -0.6663 
2025-03-16 04:54:03.125900: Pseudo dice [np.float32(0.6606), np.float32(0.8868)] 
2025-03-16 04:54:03.128907: Epoch time: 36.85 s 
2025-03-16 04:54:03.643791:  
2025-03-16 04:54:03.648801: Epoch 98 
2025-03-16 04:54:03.652312: Current learning rate: 0.0003 
2025-03-16 04:54:40.496591: train_loss -0.9348 
2025-03-16 04:54:40.502145: val_loss -0.6731 
2025-03-16 04:54:40.505692: Pseudo dice [np.float32(0.666), np.float32(0.8837)] 
2025-03-16 04:54:40.509724: Epoch time: 36.85 s 
2025-03-16 04:54:41.025843:  
2025-03-16 04:54:41.031369: Epoch 99 
2025-03-16 04:54:41.034875: Current learning rate: 0.00016 
2025-03-16 04:55:17.878244: train_loss -0.9284 
2025-03-16 04:55:17.883823: val_loss -0.6716 
2025-03-16 04:55:17.886869: Pseudo dice [np.float32(0.6628), np.float32(0.8858)] 
2025-03-16 04:55:17.890909: Epoch time: 36.85 s 
2025-03-16 04:55:18.661943: Training done. 
2025-03-16 04:55:18.692943: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset005_Prostate\splits_final.json 
2025-03-16 04:55:18.698946: The split file contains 5 splits. 
2025-03-16 04:55:18.704944: Desired fold for training: 0 
2025-03-16 04:55:18.709946: This split has 25 training and 7 validation cases. 
2025-03-16 04:55:18.713946: predicting prostate_00 
2025-03-16 04:55:18.719945: prostate_00, shape torch.Size([2, 17, 307, 307]), rank 0 
2025-03-16 04:55:19.766204: predicting prostate_04 
2025-03-16 04:55:19.773205: prostate_04, shape torch.Size([2, 17, 306, 307]), rank 0 
2025-03-16 04:55:20.103027: predicting prostate_14 
2025-03-16 04:55:20.110029: prostate_14, shape torch.Size([2, 20, 320, 319]), rank 0 
2025-03-16 04:55:20.438570: predicting prostate_20 
2025-03-16 04:55:20.445575: prostate_20, shape torch.Size([2, 20, 320, 320]), rank 0 
2025-03-16 04:55:20.775144: predicting prostate_25 
2025-03-16 04:55:20.783146: prostate_25, shape torch.Size([2, 19, 320, 319]), rank 0 
2025-03-16 04:55:21.118553: predicting prostate_31 
2025-03-16 04:55:21.126552: prostate_31, shape torch.Size([2, 20, 320, 319]), rank 0 
2025-03-16 04:55:21.455710: predicting prostate_42 
2025-03-16 04:55:21.464215: prostate_42, shape torch.Size([2, 22, 320, 319]), rank 0 
2025-03-16 04:55:28.752654: Validation complete 
2025-03-16 04:55:28.758654: Mean Validation Dice:  0.6587350801445407 
