2024-12-13 01:40:45.076146: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.33 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-13 01:40:45.080651: self.oversample_foreground_percent 0.3333333333333333 
2024-12-13 01:40:45.084651: do_dummy_2d_data_aug: False 
2024-12-13 01:40:45.181011: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-13 01:40:45.187013: The split file contains 5 splits. 
2024-12-13 01:40:45.190011: Desired fold for training: 0 
2024-12-13 01:40:45.193510: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 105, 'patch_size': [192, 160], 'median_image_size_in_voxels': [169.0, 138.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2024-12-13 01:41:20.288543: unpacking dataset... 
2024-12-13 01:41:20.583954: unpacking done... 
2024-12-13 01:41:22.164803:  
2024-12-13 01:41:22.169816: Epoch 0 
2024-12-13 01:41:22.173861: Current learning rate: 0.01 
2024-12-13 01:42:04.635405: train_loss -0.3378 
2024-12-13 01:42:04.641491: val_loss -0.5966 
2024-12-13 01:42:04.647549: Pseudo dice [np.float32(0.7307), np.float32(0.539), np.float32(0.8141)] 
2024-12-13 01:42:04.654091: Epoch time: 42.47 s 
2024-12-13 01:42:04.659139: Yayy! New best EMA pseudo Dice: 0.694599986076355 
2024-12-13 01:42:05.260584:  
2024-12-13 01:42:05.265607: Epoch 1 
2024-12-13 01:42:05.268723: Current learning rate: 0.00991 
2024-12-13 01:42:44.135756: train_loss -0.6671 
2024-12-13 01:42:44.142335: val_loss -0.6813 
2024-12-13 01:42:44.149375: Pseudo dice [np.float32(0.7852), np.float32(0.6446), np.float32(0.8254)] 
2024-12-13 01:42:44.153970: Epoch time: 38.88 s 
2024-12-13 01:42:44.159503: Yayy! New best EMA pseudo Dice: 0.7002999782562256 
2024-12-13 01:42:44.821455:  
2024-12-13 01:42:44.827023: Epoch 2 
2024-12-13 01:42:44.830617: Current learning rate: 0.00982 
2024-12-13 01:43:23.743849: train_loss -0.716 
2024-12-13 01:43:23.750018: val_loss -0.6996 
2024-12-13 01:43:23.756353: Pseudo dice [np.float32(0.797), np.float32(0.6507), np.float32(0.8412)] 
2024-12-13 01:43:23.762114: Epoch time: 38.92 s 
2024-12-13 01:43:23.768688: Yayy! New best EMA pseudo Dice: 0.70660001039505 
2024-12-13 01:43:24.460826:  
2024-12-13 01:43:24.465842: Epoch 3 
2024-12-13 01:43:24.470856: Current learning rate: 0.00973 
2024-12-13 01:44:04.032064: train_loss -0.7328 
2024-12-13 01:44:04.038708: val_loss -0.7167 
2024-12-13 01:44:04.043265: Pseudo dice [np.float32(0.8067), np.float32(0.6788), np.float32(0.8452)] 
2024-12-13 01:44:04.048417: Epoch time: 39.57 s 
2024-12-13 01:44:04.054503: Yayy! New best EMA pseudo Dice: 0.7135999798774719 
2024-12-13 01:44:04.728092:  
2024-12-13 01:44:04.735616: Epoch 4 
2024-12-13 01:44:04.739627: Current learning rate: 0.00964 
2024-12-13 01:44:44.225141: train_loss -0.7432 
2024-12-13 01:44:44.231290: val_loss -0.7291 
2024-12-13 01:44:44.238101: Pseudo dice [np.float32(0.8134), np.float32(0.6912), np.float32(0.8471)] 
2024-12-13 01:44:44.244795: Epoch time: 39.5 s 
2024-12-13 01:44:44.251522: Yayy! New best EMA pseudo Dice: 0.7206000089645386 
2024-12-13 01:44:45.095565:  
2024-12-13 01:44:45.100577: Epoch 5 
2024-12-13 01:44:45.104086: Current learning rate: 0.00955 
2024-12-13 01:45:24.669913: train_loss -0.7531 
2024-12-13 01:45:24.676435: val_loss -0.7211 
2024-12-13 01:45:24.682454: Pseudo dice [np.float32(0.8103), np.float32(0.6795), np.float32(0.8459)] 
2024-12-13 01:45:24.688474: Epoch time: 39.57 s 
2024-12-13 01:45:24.693992: Yayy! New best EMA pseudo Dice: 0.7264000177383423 
2024-12-13 01:45:25.351372:  
2024-12-13 01:45:25.357496: Epoch 6 
2024-12-13 01:45:25.360101: Current learning rate: 0.00946 
2024-12-13 01:46:04.781623: train_loss -0.7626 
2024-12-13 01:46:04.787801: val_loss -0.737 
2024-12-13 01:46:04.794857: Pseudo dice [np.float32(0.8137), np.float32(0.7032), np.float32(0.8543)] 
2024-12-13 01:46:04.800925: Epoch time: 39.43 s 
2024-12-13 01:46:04.805944: Yayy! New best EMA pseudo Dice: 0.7328000068664551 
2024-12-13 01:46:05.474891:  
2024-12-13 01:46:05.479917: Epoch 7 
2024-12-13 01:46:05.485768: Current learning rate: 0.00937 
2024-12-13 01:46:44.668965: train_loss -0.761 
2024-12-13 01:46:44.676996: val_loss -0.7371 
2024-12-13 01:46:44.682015: Pseudo dice [np.float32(0.8146), np.float32(0.6985), np.float32(0.8584)] 
2024-12-13 01:46:44.687030: Epoch time: 39.2 s 
2024-12-13 01:46:44.692044: Yayy! New best EMA pseudo Dice: 0.7386000156402588 
2024-12-13 01:46:45.362951:  
2024-12-13 01:46:45.369542: Epoch 8 
2024-12-13 01:46:45.373595: Current learning rate: 0.00928 
2024-12-13 01:47:24.248696: train_loss -0.7676 
2024-12-13 01:47:24.255333: val_loss -0.7459 
2024-12-13 01:47:24.260982: Pseudo dice [np.float32(0.8164), np.float32(0.7178), np.float32(0.8585)] 
2024-12-13 01:47:24.266611: Epoch time: 38.89 s 
2024-12-13 01:47:24.270145: Yayy! New best EMA pseudo Dice: 0.7444999814033508 
2024-12-13 01:47:24.960534:  
2024-12-13 01:47:24.965544: Epoch 9 
2024-12-13 01:47:24.968555: Current learning rate: 0.00919 
2024-12-13 01:48:04.344480: train_loss -0.7711 
2024-12-13 01:48:04.351020: val_loss -0.7403 
2024-12-13 01:48:04.357542: Pseudo dice [np.float32(0.8158), np.float32(0.7034), np.float32(0.8578)] 
2024-12-13 01:48:04.362609: Epoch time: 39.38 s 
2024-12-13 01:48:04.366125: Yayy! New best EMA pseudo Dice: 0.7493000030517578 
2024-12-13 01:48:05.035362:  
2024-12-13 01:48:05.040376: Epoch 10 
2024-12-13 01:48:05.045401: Current learning rate: 0.0091 
2024-12-13 01:48:44.518690: train_loss -0.7719 
2024-12-13 01:48:44.524779: val_loss -0.7391 
2024-12-13 01:48:44.530914: Pseudo dice [np.float32(0.8154), np.float32(0.6886), np.float32(0.8629)] 
2024-12-13 01:48:44.537591: Epoch time: 39.48 s 
2024-12-13 01:48:44.544199: Yayy! New best EMA pseudo Dice: 0.7531999945640564 
2024-12-13 01:48:45.217547:  
2024-12-13 01:48:45.223104: Epoch 11 
2024-12-13 01:48:45.226685: Current learning rate: 0.009 
2024-12-13 01:49:24.653829: train_loss -0.7752 
2024-12-13 01:49:24.662970: val_loss -0.7487 
2024-12-13 01:49:24.668038: Pseudo dice [np.float32(0.8197), np.float32(0.7153), np.float32(0.8596)] 
2024-12-13 01:49:24.674124: Epoch time: 39.44 s 
2024-12-13 01:49:24.679175: Yayy! New best EMA pseudo Dice: 0.7577000260353088 
2024-12-13 01:49:25.513078:  
2024-12-13 01:49:25.518090: Epoch 12 
2024-12-13 01:49:25.523105: Current learning rate: 0.00891 
2024-12-13 01:50:06.156783: train_loss -0.7759 
2024-12-13 01:50:06.164684: val_loss -0.7523 
2024-12-13 01:50:06.171220: Pseudo dice [np.float32(0.823), np.float32(0.7193), np.float32(0.8613)] 
2024-12-13 01:50:06.175275: Epoch time: 40.64 s 
2024-12-13 01:50:06.181303: Yayy! New best EMA pseudo Dice: 0.7620999813079834 
2024-12-13 01:50:06.858788:  
2024-12-13 01:50:06.864334: Epoch 13 
2024-12-13 01:50:06.871464: Current learning rate: 0.00882 
2024-12-13 01:50:46.929162: train_loss -0.778 
2024-12-13 01:50:46.936781: val_loss -0.7516 
2024-12-13 01:50:46.941902: Pseudo dice [np.float32(0.8232), np.float32(0.7128), np.float32(0.8652)] 
2024-12-13 01:50:46.945484: Epoch time: 40.07 s 
2024-12-13 01:50:46.952188: Yayy! New best EMA pseudo Dice: 0.7659000158309937 
2024-12-13 01:50:47.628016:  
2024-12-13 01:50:47.633548: Epoch 14 
2024-12-13 01:50:47.639600: Current learning rate: 0.00873 
2024-12-13 01:51:27.398733: train_loss -0.7833 
2024-12-13 01:51:27.404803: val_loss -0.7447 
2024-12-13 01:51:27.411351: Pseudo dice [np.float32(0.8219), np.float32(0.7036), np.float32(0.86)] 
2024-12-13 01:51:27.415861: Epoch time: 39.77 s 
2024-12-13 01:51:27.420910: Yayy! New best EMA pseudo Dice: 0.7688000202178955 
2024-12-13 01:51:28.097214:  
2024-12-13 01:51:28.102753: Epoch 15 
2024-12-13 01:51:28.107118: Current learning rate: 0.00864 
2024-12-13 01:52:07.313435: train_loss -0.7842 
2024-12-13 01:52:07.320538: val_loss -0.7455 
2024-12-13 01:52:07.326106: Pseudo dice [np.float32(0.8227), np.float32(0.7039), np.float32(0.8585)] 
2024-12-13 01:52:07.332138: Epoch time: 39.22 s 
2024-12-13 01:52:07.338694: Yayy! New best EMA pseudo Dice: 0.7714999914169312 
2024-12-13 01:52:08.021818:  
2024-12-13 01:52:08.026906: Epoch 16 
2024-12-13 01:52:08.032036: Current learning rate: 0.00855 
2024-12-13 01:52:47.287858: train_loss -0.7854 
2024-12-13 01:52:47.296420: val_loss -0.7533 
2024-12-13 01:52:47.301957: Pseudo dice [np.float32(0.8233), np.float32(0.7221), np.float32(0.861)] 
2024-12-13 01:52:47.306969: Epoch time: 39.27 s 
2024-12-13 01:52:47.313993: Yayy! New best EMA pseudo Dice: 0.7745000123977661 
2024-12-13 01:52:47.997720:  
2024-12-13 01:52:48.003790: Epoch 17 
2024-12-13 01:52:48.006839: Current learning rate: 0.00846 
2024-12-13 01:53:26.777812: train_loss -0.7863 
2024-12-13 01:53:26.785354: val_loss -0.7526 
2024-12-13 01:53:26.791375: Pseudo dice [np.float32(0.8221), np.float32(0.7249), np.float32(0.8591)] 
2024-12-13 01:53:26.796802: Epoch time: 38.78 s 
2024-12-13 01:53:26.801820: Yayy! New best EMA pseudo Dice: 0.7773000001907349 
2024-12-13 01:53:27.481118:  
2024-12-13 01:53:27.486131: Epoch 18 
2024-12-13 01:53:27.490643: Current learning rate: 0.00836 
2024-12-13 01:54:06.805934: train_loss -0.7883 
2024-12-13 01:54:06.814028: val_loss -0.7502 
2024-12-13 01:54:06.820148: Pseudo dice [np.float32(0.822), np.float32(0.7109), np.float32(0.8607)] 
2024-12-13 01:54:06.827186: Epoch time: 39.33 s 
2024-12-13 01:54:06.834233: Yayy! New best EMA pseudo Dice: 0.7792999744415283 
2024-12-13 01:54:07.532505:  
2024-12-13 01:54:07.539596: Epoch 19 
2024-12-13 01:54:07.543161: Current learning rate: 0.00827 
2024-12-13 01:54:47.147834: train_loss -0.7901 
2024-12-13 01:54:47.154627: val_loss -0.7497 
2024-12-13 01:54:47.163210: Pseudo dice [np.float32(0.8193), np.float32(0.7112), np.float32(0.8681)] 
2024-12-13 01:54:47.168229: Epoch time: 39.62 s 
2024-12-13 01:54:47.174789: Yayy! New best EMA pseudo Dice: 0.7814000248908997 
2024-12-13 01:54:48.051523:  
2024-12-13 01:54:48.058326: Epoch 20 
2024-12-13 01:54:48.062378: Current learning rate: 0.00818 
2024-12-13 01:55:26.937099: train_loss -0.7938 
2024-12-13 01:55:26.944705: val_loss -0.7445 
2024-12-13 01:55:26.949821: Pseudo dice [np.float32(0.819), np.float32(0.7008), np.float32(0.8603)] 
2024-12-13 01:55:26.957348: Epoch time: 38.89 s 
2024-12-13 01:55:26.962436: Yayy! New best EMA pseudo Dice: 0.7825999855995178 
2024-12-13 01:55:27.639397:  
2024-12-13 01:55:27.644010: Epoch 21 
2024-12-13 01:55:27.647517: Current learning rate: 0.00809 
2024-12-13 01:56:06.615925: train_loss -0.7917 
2024-12-13 01:56:06.624107: val_loss -0.7533 
2024-12-13 01:56:06.629709: Pseudo dice [np.float32(0.8225), np.float32(0.7218), np.float32(0.8606)] 
2024-12-13 01:56:06.636416: Epoch time: 38.98 s 
2024-12-13 01:56:06.641014: Yayy! New best EMA pseudo Dice: 0.784500002861023 
2024-12-13 01:56:07.315347:  
2024-12-13 01:56:07.322403: Epoch 22 
2024-12-13 01:56:07.327456: Current learning rate: 0.008 
2024-12-13 01:56:47.397203: train_loss -0.7932 
2024-12-13 01:56:47.405202: val_loss -0.7483 
2024-12-13 01:56:47.411932: Pseudo dice [np.float32(0.822), np.float32(0.7099), np.float32(0.8627)] 
2024-12-13 01:56:47.417960: Epoch time: 40.08 s 
2024-12-13 01:56:47.421970: Yayy! New best EMA pseudo Dice: 0.7857999801635742 
2024-12-13 01:56:48.080196:  
2024-12-13 01:56:48.085244: Epoch 23 
2024-12-13 01:56:48.089375: Current learning rate: 0.0079 
2024-12-13 01:57:27.038697: train_loss -0.7963 
2024-12-13 01:57:27.044296: val_loss -0.7492 
2024-12-13 01:57:27.050908: Pseudo dice [np.float32(0.8213), np.float32(0.7062), np.float32(0.8645)] 
2024-12-13 01:57:27.057132: Epoch time: 38.96 s 
2024-12-13 01:57:27.063269: Yayy! New best EMA pseudo Dice: 0.7870000004768372 
2024-12-13 01:57:27.714574:  
2024-12-13 01:57:27.720105: Epoch 24 
2024-12-13 01:57:27.725125: Current learning rate: 0.00781 
2024-12-13 01:58:06.414213: train_loss -0.7971 
2024-12-13 01:58:06.422910: val_loss -0.7545 
2024-12-13 01:58:06.427529: Pseudo dice [np.float32(0.8272), np.float32(0.7074), np.float32(0.8646)] 
2024-12-13 01:58:06.431037: Epoch time: 38.7 s 
2024-12-13 01:58:06.437562: Yayy! New best EMA pseudo Dice: 0.7882999777793884 
2024-12-13 01:58:07.106494:  
2024-12-13 01:58:07.112579: Epoch 25 
2024-12-13 01:58:07.115631: Current learning rate: 0.00772 
2024-12-13 01:58:46.943688: train_loss -0.7983 
2024-12-13 01:58:46.951877: val_loss -0.7492 
2024-12-13 01:58:46.958022: Pseudo dice [np.float32(0.8171), np.float32(0.7138), np.float32(0.8662)] 
2024-12-13 01:58:46.964135: Epoch time: 39.84 s 
2024-12-13 01:58:46.970610: Yayy! New best EMA pseudo Dice: 0.7893000245094299 
2024-12-13 01:58:47.656558:  
2024-12-13 01:58:47.663227: Epoch 26 
2024-12-13 01:58:47.668405: Current learning rate: 0.00763 
2024-12-13 01:59:27.830986: train_loss -0.7996 
2024-12-13 01:59:27.838592: val_loss -0.7548 
2024-12-13 01:59:27.845026: Pseudo dice [np.float32(0.8227), np.float32(0.7244), np.float32(0.8651)] 
2024-12-13 01:59:27.850156: Epoch time: 40.17 s 
2024-12-13 01:59:27.853716: Yayy! New best EMA pseudo Dice: 0.7907999753952026 
2024-12-13 01:59:28.517467:  
2024-12-13 01:59:28.523011: Epoch 27 
2024-12-13 01:59:28.525551: Current learning rate: 0.00753 
2024-12-13 02:00:07.199070: train_loss -0.7998 
2024-12-13 02:00:07.208732: val_loss -0.7571 
2024-12-13 02:00:07.216834: Pseudo dice [np.float32(0.8243), np.float32(0.7265), np.float32(0.8661)] 
2024-12-13 02:00:07.221847: Epoch time: 38.68 s 
2024-12-13 02:00:07.227898: Yayy! New best EMA pseudo Dice: 0.7922999858856201 
2024-12-13 02:00:08.057827:  
2024-12-13 02:00:08.063381: Epoch 28 
2024-12-13 02:00:08.068432: Current learning rate: 0.00744 
2024-12-13 02:00:47.550908: train_loss -0.8008 
2024-12-13 02:00:47.556450: val_loss -0.7481 
2024-12-13 02:00:47.561505: Pseudo dice [np.float32(0.8254), np.float32(0.6953), np.float32(0.8683)] 
2024-12-13 02:00:47.567528: Epoch time: 39.49 s 
2024-12-13 02:00:47.571573: Yayy! New best EMA pseudo Dice: 0.7926999926567078 
2024-12-13 02:00:48.239808:  
2024-12-13 02:00:48.244827: Epoch 29 
2024-12-13 02:00:48.249847: Current learning rate: 0.00735 
2024-12-13 02:01:28.074189: train_loss -0.805 
2024-12-13 02:01:28.081784: val_loss -0.7552 
2024-12-13 02:01:28.088894: Pseudo dice [np.float32(0.8246), np.float32(0.7077), np.float32(0.8723)] 
2024-12-13 02:01:28.093492: Epoch time: 39.84 s 
2024-12-13 02:01:28.099023: Yayy! New best EMA pseudo Dice: 0.7936000227928162 
2024-12-13 02:01:28.778971:  
2024-12-13 02:01:28.784528: Epoch 30 
2024-12-13 02:01:28.790615: Current learning rate: 0.00725 
2024-12-13 02:02:08.255774: train_loss -0.8022 
2024-12-13 02:02:08.262349: val_loss -0.7467 
2024-12-13 02:02:08.267886: Pseudo dice [np.float32(0.8249), np.float32(0.7014), np.float32(0.859)] 
2024-12-13 02:02:08.272430: Epoch time: 39.48 s 
2024-12-13 02:02:08.279527: Yayy! New best EMA pseudo Dice: 0.7936999797821045 
2024-12-13 02:02:08.952774:  
2024-12-13 02:02:08.957597: Epoch 31 
2024-12-13 02:02:08.962728: Current learning rate: 0.00716 
2024-12-13 02:02:48.905563: train_loss -0.8049 
2024-12-13 02:02:48.912678: val_loss -0.7649 
2024-12-13 02:02:48.917697: Pseudo dice [np.float32(0.8318), np.float32(0.7281), np.float32(0.8676)] 
2024-12-13 02:02:48.924720: Epoch time: 39.95 s 
2024-12-13 02:02:48.930243: Yayy! New best EMA pseudo Dice: 0.7953000068664551 
2024-12-13 02:02:49.614280:  
2024-12-13 02:02:49.619800: Epoch 32 
2024-12-13 02:02:49.625820: Current learning rate: 0.00707 
2024-12-13 02:03:29.520145: train_loss -0.8032 
2024-12-13 02:03:29.527675: val_loss -0.757 
2024-12-13 02:03:29.533692: Pseudo dice [np.float32(0.8244), np.float32(0.7235), np.float32(0.8624)] 
2024-12-13 02:03:29.540223: Epoch time: 39.91 s 
2024-12-13 02:03:29.545239: Yayy! New best EMA pseudo Dice: 0.7961000204086304 
2024-12-13 02:03:30.225305:  
2024-12-13 02:03:30.230838: Epoch 33 
2024-12-13 02:03:30.235359: Current learning rate: 0.00697 
2024-12-13 02:04:09.586013: train_loss -0.8046 
2024-12-13 02:04:09.595062: val_loss -0.7555 
2024-12-13 02:04:09.600152: Pseudo dice [np.float32(0.8226), np.float32(0.7198), np.float32(0.8668)] 
2024-12-13 02:04:09.606549: Epoch time: 39.36 s 
2024-12-13 02:04:09.611566: Yayy! New best EMA pseudo Dice: 0.7968000173568726 
2024-12-13 02:04:10.284372:  
2024-12-13 02:04:10.289921: Epoch 34 
2024-12-13 02:04:10.292454: Current learning rate: 0.00688 
2024-12-13 02:04:49.232721: train_loss -0.8073 
2024-12-13 02:04:49.240244: val_loss -0.7626 
2024-12-13 02:04:49.246342: Pseudo dice [np.float32(0.8312), np.float32(0.7267), np.float32(0.8693)] 
2024-12-13 02:04:49.250365: Epoch time: 38.95 s 
2024-12-13 02:04:49.255382: Yayy! New best EMA pseudo Dice: 0.7979999780654907 
2024-12-13 02:04:49.939660:  
2024-12-13 02:04:49.945193: Epoch 35 
2024-12-13 02:04:49.948748: Current learning rate: 0.00679 
2024-12-13 02:05:29.108199: train_loss -0.8051 
2024-12-13 02:05:29.115793: val_loss -0.7517 
2024-12-13 02:05:29.121864: Pseudo dice [np.float32(0.8249), np.float32(0.71), np.float32(0.8628)] 
2024-12-13 02:05:29.127460: Epoch time: 39.17 s 
2024-12-13 02:05:29.134626: Yayy! New best EMA pseudo Dice: 0.7980999946594238 
2024-12-13 02:05:30.005929:  
2024-12-13 02:05:30.013681: Epoch 36 
2024-12-13 02:05:30.017778: Current learning rate: 0.00669 
2024-12-13 02:06:09.973475: train_loss -0.8059 
2024-12-13 02:06:09.979083: val_loss -0.7532 
2024-12-13 02:06:09.986198: Pseudo dice [np.float32(0.8202), np.float32(0.7142), np.float32(0.8666)] 
2024-12-13 02:06:09.991216: Epoch time: 39.97 s 
2024-12-13 02:06:09.995731: Yayy! New best EMA pseudo Dice: 0.7983999848365784 
2024-12-13 02:06:10.666076:  
2024-12-13 02:06:10.671596: Epoch 37 
2024-12-13 02:06:10.677618: Current learning rate: 0.0066 
2024-12-13 02:06:49.333474: train_loss -0.8083 
2024-12-13 02:06:49.339600: val_loss -0.7479 
2024-12-13 02:06:49.345291: Pseudo dice [np.float32(0.8254), np.float32(0.7016), np.float32(0.8599)] 
2024-12-13 02:06:49.350882: Epoch time: 38.67 s 
2024-12-13 02:06:49.908700:  
2024-12-13 02:06:49.914232: Epoch 38 
2024-12-13 02:06:49.919334: Current learning rate: 0.0065 
2024-12-13 02:07:29.066783: train_loss -0.8081 
2024-12-13 02:07:29.073395: val_loss -0.7561 
2024-12-13 02:07:29.080416: Pseudo dice [np.float32(0.8272), np.float32(0.7116), np.float32(0.8728)] 
2024-12-13 02:07:29.086988: Epoch time: 39.16 s 
2024-12-13 02:07:29.091007: Yayy! New best EMA pseudo Dice: 0.7986999750137329 
2024-12-13 02:07:29.773836:  
2024-12-13 02:07:29.778877: Epoch 39 
2024-12-13 02:07:29.783376: Current learning rate: 0.00641 
2024-12-13 02:08:08.412029: train_loss -0.8094 
2024-12-13 02:08:08.419254: val_loss -0.7622 
2024-12-13 02:08:08.426440: Pseudo dice [np.float32(0.8268), np.float32(0.7337), np.float32(0.8672)] 
2024-12-13 02:08:08.431510: Epoch time: 38.64 s 
2024-12-13 02:08:08.435096: Yayy! New best EMA pseudo Dice: 0.7997000217437744 
2024-12-13 02:08:09.119316:  
2024-12-13 02:08:09.125339: Epoch 40 
2024-12-13 02:08:09.129354: Current learning rate: 0.00631 
2024-12-13 02:08:47.875093: train_loss -0.8097 
2024-12-13 02:08:47.882668: val_loss -0.75 
2024-12-13 02:08:47.890762: Pseudo dice [np.float32(0.822), np.float32(0.7163), np.float32(0.8619)] 
2024-12-13 02:08:47.896916: Epoch time: 38.76 s 
2024-12-13 02:08:47.901485: Yayy! New best EMA pseudo Dice: 0.7997999787330627 
2024-12-13 02:08:48.609252:  
2024-12-13 02:08:48.615372: Epoch 41 
2024-12-13 02:08:48.620990: Current learning rate: 0.00622 
2024-12-13 02:09:27.545522: train_loss -0.81 
2024-12-13 02:09:27.552645: val_loss -0.7571 
2024-12-13 02:09:27.557260: Pseudo dice [np.float32(0.8194), np.float32(0.7334), np.float32(0.8587)] 
2024-12-13 02:09:27.564382: Epoch time: 38.94 s 
2024-12-13 02:09:27.569010: Yayy! New best EMA pseudo Dice: 0.8001999855041504 
2024-12-13 02:09:28.222355:  
2024-12-13 02:09:28.227926: Epoch 42 
2024-12-13 02:09:28.232488: Current learning rate: 0.00612 
2024-12-13 02:10:07.109882: train_loss -0.8136 
2024-12-13 02:10:07.116467: val_loss -0.7537 
2024-12-13 02:10:07.121484: Pseudo dice [np.float32(0.8276), np.float32(0.7102), np.float32(0.8666)] 
2024-12-13 02:10:07.128016: Epoch time: 38.89 s 
2024-12-13 02:10:07.133034: Yayy! New best EMA pseudo Dice: 0.8003000020980835 
2024-12-13 02:10:07.791909:  
2024-12-13 02:10:07.797481: Epoch 43 
2024-12-13 02:10:07.802620: Current learning rate: 0.00603 
2024-12-13 02:10:46.611725: train_loss -0.813 
2024-12-13 02:10:46.618786: val_loss -0.7625 
2024-12-13 02:10:46.624967: Pseudo dice [np.float32(0.8308), np.float32(0.7324), np.float32(0.866)] 
2024-12-13 02:10:46.629986: Epoch time: 38.82 s 
2024-12-13 02:10:46.637501: Yayy! New best EMA pseudo Dice: 0.8011999726295471 
2024-12-13 02:10:47.502079:  
2024-12-13 02:10:47.508129: Epoch 44 
2024-12-13 02:10:47.513143: Current learning rate: 0.00593 
2024-12-13 02:11:26.597037: train_loss -0.8138 
2024-12-13 02:11:26.606681: val_loss -0.7592 
2024-12-13 02:11:26.612349: Pseudo dice [np.float32(0.8277), np.float32(0.7267), np.float32(0.8635)] 
2024-12-13 02:11:26.618442: Epoch time: 39.1 s 
2024-12-13 02:11:26.624136: Yayy! New best EMA pseudo Dice: 0.8016999959945679 
2024-12-13 02:11:27.286576:  
2024-12-13 02:11:27.291628: Epoch 45 
2024-12-13 02:11:27.296301: Current learning rate: 0.00584 
2024-12-13 02:12:06.319043: train_loss -0.8145 
2024-12-13 02:12:06.325622: val_loss -0.7527 
2024-12-13 02:12:06.331741: Pseudo dice [np.float32(0.8265), np.float32(0.7051), np.float32(0.8673)] 
2024-12-13 02:12:06.337305: Epoch time: 39.03 s 
2024-12-13 02:12:06.882957:  
2024-12-13 02:12:06.887977: Epoch 46 
2024-12-13 02:12:06.890995: Current learning rate: 0.00574 
2024-12-13 02:12:46.031637: train_loss -0.8147 
2024-12-13 02:12:46.038764: val_loss -0.7606 
2024-12-13 02:12:46.044030: Pseudo dice [np.float32(0.8288), np.float32(0.7286), np.float32(0.8666)] 
2024-12-13 02:12:46.050266: Epoch time: 39.15 s 
2024-12-13 02:12:46.057681: Yayy! New best EMA pseudo Dice: 0.8022000193595886 
2024-12-13 02:12:46.711160:  
2024-12-13 02:12:46.716713: Epoch 47 
2024-12-13 02:12:46.721814: Current learning rate: 0.00565 
2024-12-13 02:13:25.569792: train_loss -0.8166 
2024-12-13 02:13:25.577303: val_loss -0.7626 
2024-12-13 02:13:25.584263: Pseudo dice [np.float32(0.8252), np.float32(0.7404), np.float32(0.8632)] 
2024-12-13 02:13:25.590833: Epoch time: 38.86 s 
2024-12-13 02:13:25.595448: Yayy! New best EMA pseudo Dice: 0.8029000163078308 
2024-12-13 02:13:26.254721:  
2024-12-13 02:13:26.259737: Epoch 48 
2024-12-13 02:13:26.263248: Current learning rate: 0.00555 
2024-12-13 02:14:05.337825: train_loss -0.8172 
2024-12-13 02:14:05.343849: val_loss -0.7559 
2024-12-13 02:14:05.350173: Pseudo dice [np.float32(0.8254), np.float32(0.7182), np.float32(0.8675)] 
2024-12-13 02:14:05.355196: Epoch time: 39.09 s 
2024-12-13 02:14:05.361224: Yayy! New best EMA pseudo Dice: 0.8029999732971191 
2024-12-13 02:14:06.031165:  
2024-12-13 02:14:06.037694: Epoch 49 
2024-12-13 02:14:06.041703: Current learning rate: 0.00546 
2024-12-13 02:14:46.049517: train_loss -0.8145 
2024-12-13 02:14:46.055610: val_loss -0.7571 
2024-12-13 02:14:46.061706: Pseudo dice [np.float32(0.8289), np.float32(0.7075), np.float32(0.8725)] 
2024-12-13 02:14:46.067746: Epoch time: 40.02 s 
2024-12-13 02:14:46.709173:  
2024-12-13 02:14:46.714713: Epoch 50 
2024-12-13 02:14:46.718256: Current learning rate: 0.00536 
2024-12-13 02:15:25.244049: train_loss -0.8186 
2024-12-13 02:15:25.251556: val_loss -0.7576 
2024-12-13 02:15:25.257188: Pseudo dice [np.float32(0.8305), np.float32(0.721), np.float32(0.8633)] 
2024-12-13 02:15:25.261707: Epoch time: 38.54 s 
2024-12-13 02:15:25.267244: Yayy! New best EMA pseudo Dice: 0.8032000064849854 
2024-12-13 02:15:25.929330:  
2024-12-13 02:15:25.935159: Epoch 51 
2024-12-13 02:15:25.939170: Current learning rate: 0.00526 
2024-12-13 02:16:04.295966: train_loss -0.8183 
2024-12-13 02:16:04.302058: val_loss -0.7559 
2024-12-13 02:16:04.308164: Pseudo dice [np.float32(0.8265), np.float32(0.7164), np.float32(0.868)] 
2024-12-13 02:16:04.312868: Epoch time: 38.37 s 
2024-12-13 02:16:04.317948: Yayy! New best EMA pseudo Dice: 0.8032000064849854 
2024-12-13 02:16:04.979112:  
2024-12-13 02:16:04.985132: Epoch 52 
2024-12-13 02:16:04.988648: Current learning rate: 0.00517 
2024-12-13 02:16:44.650731: train_loss -0.8189 
2024-12-13 02:16:44.656362: val_loss -0.763 
2024-12-13 02:16:44.661952: Pseudo dice [np.float32(0.8333), np.float32(0.7179), np.float32(0.874)] 
2024-12-13 02:16:44.666968: Epoch time: 39.67 s 
2024-12-13 02:16:44.674658: Yayy! New best EMA pseudo Dice: 0.8036999702453613 
2024-12-13 02:16:45.340840:  
2024-12-13 02:16:45.346384: Epoch 53 
2024-12-13 02:16:45.352100: Current learning rate: 0.00507 
2024-12-13 02:17:25.522309: train_loss -0.8192 
2024-12-13 02:17:25.528897: val_loss -0.7566 
2024-12-13 02:17:25.535640: Pseudo dice [np.float32(0.8251), np.float32(0.7212), np.float32(0.8643)] 
2024-12-13 02:17:25.540170: Epoch time: 40.18 s 
2024-12-13 02:17:26.092741:  
2024-12-13 02:17:26.099332: Epoch 54 
2024-12-13 02:17:26.103928: Current learning rate: 0.00497 
2024-12-13 02:18:05.573877: train_loss -0.8193 
2024-12-13 02:18:05.579798: val_loss -0.7646 
2024-12-13 02:18:05.584910: Pseudo dice [np.float32(0.8275), np.float32(0.733), np.float32(0.8686)] 
2024-12-13 02:18:05.590032: Epoch time: 39.48 s 
2024-12-13 02:18:05.595131: Yayy! New best EMA pseudo Dice: 0.8043000102043152 
2024-12-13 02:18:06.247205:  
2024-12-13 02:18:06.252244: Epoch 55 
2024-12-13 02:18:06.257168: Current learning rate: 0.00487 
2024-12-13 02:18:45.111848: train_loss -0.8206 
2024-12-13 02:18:45.119421: val_loss -0.7581 
2024-12-13 02:18:45.124023: Pseudo dice [np.float32(0.8268), np.float32(0.7137), np.float32(0.8685)] 
2024-12-13 02:18:45.128116: Epoch time: 38.87 s 
2024-12-13 02:18:45.675856:  
2024-12-13 02:18:45.681376: Epoch 56 
2024-12-13 02:18:45.684931: Current learning rate: 0.00478 
2024-12-13 02:19:24.463462: train_loss -0.8199 
2024-12-13 02:19:24.471098: val_loss -0.7531 
2024-12-13 02:19:24.476776: Pseudo dice [np.float32(0.8226), np.float32(0.7097), np.float32(0.8669)] 
2024-12-13 02:19:24.481793: Epoch time: 38.79 s 
2024-12-13 02:19:25.024544:  
2024-12-13 02:19:25.031178: Epoch 57 
2024-12-13 02:19:25.035743: Current learning rate: 0.00468 
2024-12-13 02:20:04.218209: train_loss -0.82 
2024-12-13 02:20:04.224229: val_loss -0.7589 
2024-12-13 02:20:04.228248: Pseudo dice [np.float32(0.8285), np.float32(0.715), np.float32(0.872)] 
2024-12-13 02:20:04.234269: Epoch time: 39.19 s 
2024-12-13 02:20:04.770256:  
2024-12-13 02:20:04.775338: Epoch 58 
2024-12-13 02:20:04.779983: Current learning rate: 0.00458 
2024-12-13 02:20:43.846455: train_loss -0.8221 
2024-12-13 02:20:43.854650: val_loss -0.7577 
2024-12-13 02:20:43.860679: Pseudo dice [np.float32(0.8256), np.float32(0.7142), np.float32(0.8722)] 
2024-12-13 02:20:43.867228: Epoch time: 39.08 s 
2024-12-13 02:20:44.448601:  
2024-12-13 02:20:44.455677: Epoch 59 
2024-12-13 02:20:44.460802: Current learning rate: 0.00448 
2024-12-13 02:21:23.654450: train_loss -0.8216 
2024-12-13 02:21:23.660285: val_loss -0.7577 
2024-12-13 02:21:23.667312: Pseudo dice [np.float32(0.8276), np.float32(0.7203), np.float32(0.8694)] 
2024-12-13 02:21:23.671332: Epoch time: 39.21 s 
2024-12-13 02:21:24.386360:  
2024-12-13 02:21:24.391923: Epoch 60 
2024-12-13 02:21:24.395447: Current learning rate: 0.00438 
2024-12-13 02:22:03.268732: train_loss -0.8226 
2024-12-13 02:22:03.276923: val_loss -0.7635 
2024-12-13 02:22:03.284116: Pseudo dice [np.float32(0.8277), np.float32(0.7293), np.float32(0.8711)] 
2024-12-13 02:22:03.289728: Epoch time: 38.88 s 
2024-12-13 02:22:03.294895: Yayy! New best EMA pseudo Dice: 0.8046000003814697 
2024-12-13 02:22:03.966769:  
2024-12-13 02:22:03.972794: Epoch 61 
2024-12-13 02:22:03.976813: Current learning rate: 0.00429 
2024-12-13 02:22:42.530647: train_loss -0.8223 
2024-12-13 02:22:42.537775: val_loss -0.7597 
2024-12-13 02:22:42.542877: Pseudo dice [np.float32(0.8231), np.float32(0.7371), np.float32(0.8616)] 
2024-12-13 02:22:42.548900: Epoch time: 38.56 s 
2024-12-13 02:22:42.553476: Yayy! New best EMA pseudo Dice: 0.8048999905586243 
2024-12-13 02:22:43.223398:  
2024-12-13 02:22:43.228481: Epoch 62 
2024-12-13 02:22:43.233497: Current learning rate: 0.00419 
2024-12-13 02:23:22.155963: train_loss -0.8211 
2024-12-13 02:23:22.164090: val_loss -0.7581 
2024-12-13 02:23:22.169677: Pseudo dice [np.float32(0.8247), np.float32(0.7287), np.float32(0.8666)] 
2024-12-13 02:23:22.176764: Epoch time: 38.93 s 
2024-12-13 02:23:22.182334: Yayy! New best EMA pseudo Dice: 0.8051000237464905 
2024-12-13 02:23:22.852246:  
2024-12-13 02:23:22.858762: Epoch 63 
2024-12-13 02:23:22.864782: Current learning rate: 0.00409 
2024-12-13 02:24:02.171010: train_loss -0.8242 
2024-12-13 02:24:02.178240: val_loss -0.7656 
2024-12-13 02:24:02.183411: Pseudo dice [np.float32(0.8262), np.float32(0.7381), np.float32(0.8695)] 
2024-12-13 02:24:02.190124: Epoch time: 39.32 s 
2024-12-13 02:24:02.195797: Yayy! New best EMA pseudo Dice: 0.8057000041007996 
2024-12-13 02:24:02.875996:  
2024-12-13 02:24:02.881031: Epoch 64 
2024-12-13 02:24:02.884642: Current learning rate: 0.00399 
2024-12-13 02:24:41.716029: train_loss -0.8245 
2024-12-13 02:24:41.720736: val_loss -0.7632 
2024-12-13 02:24:41.727330: Pseudo dice [np.float32(0.828), np.float32(0.7282), np.float32(0.872)] 
2024-12-13 02:24:41.732869: Epoch time: 38.84 s 
2024-12-13 02:24:41.738925: Yayy! New best EMA pseudo Dice: 0.8061000108718872 
2024-12-13 02:24:42.410119:  
2024-12-13 02:24:42.414773: Epoch 65 
2024-12-13 02:24:42.420376: Current learning rate: 0.00389 
2024-12-13 02:25:22.739885: train_loss -0.8222 
2024-12-13 02:25:22.747937: val_loss -0.7558 
2024-12-13 02:25:22.753029: Pseudo dice [np.float32(0.8254), np.float32(0.7163), np.float32(0.8653)] 
2024-12-13 02:25:22.759047: Epoch time: 40.33 s 
2024-12-13 02:25:23.316306:  
2024-12-13 02:25:23.322872: Epoch 66 
2024-12-13 02:25:23.327025: Current learning rate: 0.00379 
2024-12-13 02:26:02.332091: train_loss -0.8235 
2024-12-13 02:26:02.339699: val_loss -0.7593 
2024-12-13 02:26:02.346843: Pseudo dice [np.float32(0.8283), np.float32(0.7269), np.float32(0.8646)] 
2024-12-13 02:26:02.351992: Epoch time: 39.02 s 
2024-12-13 02:26:02.912424:  
2024-12-13 02:26:02.919057: Epoch 67 
2024-12-13 02:26:02.924159: Current learning rate: 0.00369 
2024-12-13 02:26:43.183910: train_loss -0.8249 
2024-12-13 02:26:43.190950: val_loss -0.7602 
2024-12-13 02:26:43.196486: Pseudo dice [np.float32(0.8278), np.float32(0.7238), np.float32(0.8673)] 
2024-12-13 02:26:43.203649: Epoch time: 40.27 s 
2024-12-13 02:26:43.779510:  
2024-12-13 02:26:43.785943: Epoch 68 
2024-12-13 02:26:43.790062: Current learning rate: 0.00359 
2024-12-13 02:27:25.287592: train_loss -0.8261 
2024-12-13 02:27:25.295708: val_loss -0.7517 
2024-12-13 02:27:25.299719: Pseudo dice [np.float32(0.8167), np.float32(0.7166), np.float32(0.8674)] 
2024-12-13 02:27:25.306776: Epoch time: 41.51 s 
2024-12-13 02:27:25.884014:  
2024-12-13 02:27:25.889035: Epoch 69 
2024-12-13 02:27:25.895623: Current learning rate: 0.00349 
2024-12-13 02:28:04.736821: train_loss -0.8262 
2024-12-13 02:28:04.745499: val_loss -0.7592 
2024-12-13 02:28:04.753662: Pseudo dice [np.float32(0.829), np.float32(0.721), np.float32(0.8674)] 
2024-12-13 02:28:04.758741: Epoch time: 38.85 s 
2024-12-13 02:28:05.319830:  
2024-12-13 02:28:05.324838: Epoch 70 
2024-12-13 02:28:05.329158: Current learning rate: 0.00338 
2024-12-13 02:28:43.146720: train_loss -0.8278 
2024-12-13 02:28:43.152307: val_loss -0.7584 
2024-12-13 02:28:43.157327: Pseudo dice [np.float32(0.825), np.float32(0.7253), np.float32(0.8677)] 
2024-12-13 02:28:43.161928: Epoch time: 37.83 s 
2024-12-13 02:28:43.693682:  
2024-12-13 02:28:43.699236: Epoch 71 
2024-12-13 02:28:43.703295: Current learning rate: 0.00328 
2024-12-13 02:29:21.929546: train_loss -0.8272 
2024-12-13 02:29:21.935641: val_loss -0.7567 
2024-12-13 02:29:21.941202: Pseudo dice [np.float32(0.8291), np.float32(0.7153), np.float32(0.8686)] 
2024-12-13 02:29:21.947316: Epoch time: 38.24 s 
2024-12-13 02:29:22.480774:  
2024-12-13 02:29:22.485905: Epoch 72 
2024-12-13 02:29:22.490417: Current learning rate: 0.00318 
2024-12-13 02:30:00.901463: train_loss -0.8271 
2024-12-13 02:30:00.906507: val_loss -0.7525 
2024-12-13 02:30:00.910015: Pseudo dice [np.float32(0.824), np.float32(0.7144), np.float32(0.8653)] 
2024-12-13 02:30:00.916093: Epoch time: 38.42 s 
2024-12-13 02:30:01.447297:  
2024-12-13 02:30:01.452836: Epoch 73 
2024-12-13 02:30:01.457350: Current learning rate: 0.00308 
2024-12-13 02:30:40.775897: train_loss -0.8291 
2024-12-13 02:30:40.782558: val_loss -0.7619 
2024-12-13 02:30:40.787138: Pseudo dice [np.float32(0.8267), np.float32(0.7264), np.float32(0.869)] 
2024-12-13 02:30:40.793272: Epoch time: 39.33 s 
2024-12-13 02:30:41.352125:  
2024-12-13 02:30:41.357642: Epoch 74 
2024-12-13 02:30:41.361179: Current learning rate: 0.00297 
2024-12-13 02:31:20.347394: train_loss -0.8268 
2024-12-13 02:31:20.353554: val_loss -0.7527 
2024-12-13 02:31:20.359160: Pseudo dice [np.float32(0.8214), np.float32(0.7121), np.float32(0.8689)] 
2024-12-13 02:31:20.363270: Epoch time: 39.0 s 
2024-12-13 02:31:20.908805:  
2024-12-13 02:31:20.914375: Epoch 75 
2024-12-13 02:31:20.919472: Current learning rate: 0.00287 
2024-12-13 02:31:59.504606: train_loss -0.8301 
2024-12-13 02:31:59.510226: val_loss -0.7612 
2024-12-13 02:31:59.516760: Pseudo dice [np.float32(0.8264), np.float32(0.7332), np.float32(0.863)] 
2024-12-13 02:31:59.521302: Epoch time: 38.6 s 
2024-12-13 02:32:00.251636:  
2024-12-13 02:32:00.256654: Epoch 76 
2024-12-13 02:32:00.261672: Current learning rate: 0.00277 
2024-12-13 02:32:40.175330: train_loss -0.8299 
2024-12-13 02:32:40.182464: val_loss -0.7606 
2024-12-13 02:32:40.188017: Pseudo dice [np.float32(0.8283), np.float32(0.73), np.float32(0.8645)] 
2024-12-13 02:32:40.192563: Epoch time: 39.92 s 
2024-12-13 02:32:40.775194:  
2024-12-13 02:32:40.781337: Epoch 77 
2024-12-13 02:32:40.785378: Current learning rate: 0.00266 
2024-12-13 02:33:19.822844: train_loss -0.8303 
2024-12-13 02:33:19.830504: val_loss -0.7605 
2024-12-13 02:33:19.836600: Pseudo dice [np.float32(0.8297), np.float32(0.7173), np.float32(0.8746)] 
2024-12-13 02:33:19.843123: Epoch time: 39.05 s 
2024-12-13 02:33:20.401444:  
2024-12-13 02:33:20.407463: Epoch 78 
2024-12-13 02:33:20.410975: Current learning rate: 0.00256 
2024-12-13 02:33:59.586833: train_loss -0.8302 
2024-12-13 02:33:59.593358: val_loss -0.7587 
2024-12-13 02:33:59.599419: Pseudo dice [np.float32(0.8256), np.float32(0.729), np.float32(0.8645)] 
2024-12-13 02:33:59.605443: Epoch time: 39.19 s 
2024-12-13 02:34:00.181033:  
2024-12-13 02:34:00.185086: Epoch 79 
2024-12-13 02:34:00.189669: Current learning rate: 0.00245 
2024-12-13 02:34:38.981201: train_loss -0.8301 
2024-12-13 02:34:38.987783: val_loss -0.7604 
2024-12-13 02:34:38.992687: Pseudo dice [np.float32(0.8294), np.float32(0.7245), np.float32(0.8686)] 
2024-12-13 02:34:38.996202: Epoch time: 38.8 s 
2024-12-13 02:34:39.551817:  
2024-12-13 02:34:39.556970: Epoch 80 
2024-12-13 02:34:39.560534: Current learning rate: 0.00235 
2024-12-13 02:35:18.605891: train_loss -0.8307 
2024-12-13 02:35:18.612406: val_loss -0.7571 
2024-12-13 02:35:18.618429: Pseudo dice [np.float32(0.8288), np.float32(0.7133), np.float32(0.8677)] 
2024-12-13 02:35:18.622446: Epoch time: 39.05 s 
2024-12-13 02:35:19.179049:  
2024-12-13 02:35:19.184597: Epoch 81 
2024-12-13 02:35:19.189702: Current learning rate: 0.00224 
2024-12-13 02:35:57.951781: train_loss -0.8304 
2024-12-13 02:35:57.958864: val_loss -0.759 
2024-12-13 02:35:57.963424: Pseudo dice [np.float32(0.8292), np.float32(0.7164), np.float32(0.8669)] 
2024-12-13 02:35:57.968052: Epoch time: 38.77 s 
2024-12-13 02:35:58.558552:  
2024-12-13 02:35:58.563576: Epoch 82 
2024-12-13 02:35:58.567090: Current learning rate: 0.00214 
2024-12-13 02:36:37.879950: train_loss -0.8297 
2024-12-13 02:36:37.886636: val_loss -0.7576 
2024-12-13 02:36:37.892691: Pseudo dice [np.float32(0.8258), np.float32(0.7206), np.float32(0.8692)] 
2024-12-13 02:36:37.897289: Epoch time: 39.32 s 
2024-12-13 02:36:38.446041:  
2024-12-13 02:36:38.452068: Epoch 83 
2024-12-13 02:36:38.457373: Current learning rate: 0.00203 
2024-12-13 02:37:18.009291: train_loss -0.8313 
2024-12-13 02:37:18.017084: val_loss -0.7631 
2024-12-13 02:37:18.024771: Pseudo dice [np.float32(0.8277), np.float32(0.733), np.float32(0.868)] 
2024-12-13 02:37:18.029335: Epoch time: 39.56 s 
2024-12-13 02:37:18.746591:  
2024-12-13 02:37:18.752111: Epoch 84 
2024-12-13 02:37:18.756647: Current learning rate: 0.00192 
2024-12-13 02:37:58.232000: train_loss -0.8307 
2024-12-13 02:37:58.238697: val_loss -0.7568 
2024-12-13 02:37:58.244317: Pseudo dice [np.float32(0.8285), np.float32(0.7159), np.float32(0.8679)] 
2024-12-13 02:37:58.249971: Epoch time: 39.49 s 
2024-12-13 02:37:58.784672:  
2024-12-13 02:37:58.790711: Epoch 85 
2024-12-13 02:37:58.794728: Current learning rate: 0.00181 
2024-12-13 02:38:37.925120: train_loss -0.8315 
2024-12-13 02:38:37.930655: val_loss -0.7573 
2024-12-13 02:38:37.938188: Pseudo dice [np.float32(0.8321), np.float32(0.7091), np.float32(0.8699)] 
2024-12-13 02:38:37.942698: Epoch time: 39.14 s 
2024-12-13 02:38:38.476743:  
2024-12-13 02:38:38.482282: Epoch 86 
2024-12-13 02:38:38.485408: Current learning rate: 0.0017 
2024-12-13 02:39:18.050179: train_loss -0.8342 
2024-12-13 02:39:18.058341: val_loss -0.757 
2024-12-13 02:39:18.063963: Pseudo dice [np.float32(0.8283), np.float32(0.7164), np.float32(0.8671)] 
2024-12-13 02:39:18.069084: Epoch time: 39.57 s 
2024-12-13 02:39:18.610423:  
2024-12-13 02:39:18.617014: Epoch 87 
2024-12-13 02:39:18.621526: Current learning rate: 0.00159 
2024-12-13 02:39:57.725047: train_loss -0.8343 
2024-12-13 02:39:57.731574: val_loss -0.76 
2024-12-13 02:39:57.735587: Pseudo dice [np.float32(0.8324), np.float32(0.7194), np.float32(0.8686)] 
2024-12-13 02:39:57.740102: Epoch time: 39.11 s 
2024-12-13 02:39:58.273203:  
2024-12-13 02:39:58.279801: Epoch 88 
2024-12-13 02:39:58.283864: Current learning rate: 0.00148 
2024-12-13 02:40:37.368514: train_loss -0.8341 
2024-12-13 02:40:37.375109: val_loss -0.7549 
2024-12-13 02:40:37.381765: Pseudo dice [np.float32(0.827), np.float32(0.7138), np.float32(0.8669)] 
2024-12-13 02:40:37.387375: Epoch time: 39.1 s 
2024-12-13 02:40:37.934407:  
2024-12-13 02:40:37.940449: Epoch 89 
2024-12-13 02:40:37.944460: Current learning rate: 0.00137 
2024-12-13 02:41:17.330039: train_loss -0.833 
2024-12-13 02:41:17.337616: val_loss -0.7535 
2024-12-13 02:41:17.344166: Pseudo dice [np.float32(0.8239), np.float32(0.7114), np.float32(0.8684)] 
2024-12-13 02:41:17.349723: Epoch time: 39.4 s 
2024-12-13 02:41:17.881942:  
2024-12-13 02:41:17.886992: Epoch 90 
2024-12-13 02:41:17.892017: Current learning rate: 0.00126 
2024-12-13 02:41:57.362894: train_loss -0.8335 
2024-12-13 02:41:57.370180: val_loss -0.7618 
2024-12-13 02:41:57.374715: Pseudo dice [np.float32(0.8266), np.float32(0.7273), np.float32(0.8686)] 
2024-12-13 02:41:57.382292: Epoch time: 39.48 s 
2024-12-13 02:41:57.916261:  
2024-12-13 02:41:57.921778: Epoch 91 
2024-12-13 02:41:57.925291: Current learning rate: 0.00115 
2024-12-13 02:42:36.913630: train_loss -0.8346 
2024-12-13 02:42:36.922251: val_loss -0.7604 
2024-12-13 02:42:36.927318: Pseudo dice [np.float32(0.8254), np.float32(0.7228), np.float32(0.8716)] 
2024-12-13 02:42:36.932384: Epoch time: 39.0 s 
2024-12-13 02:42:37.644257:  
2024-12-13 02:42:37.649300: Epoch 92 
2024-12-13 02:42:37.652945: Current learning rate: 0.00103 
2024-12-13 02:43:17.528560: train_loss -0.8341 
2024-12-13 02:43:17.537234: val_loss -0.7582 
2024-12-13 02:43:17.542457: Pseudo dice [np.float32(0.8218), np.float32(0.7294), np.float32(0.8646)] 
2024-12-13 02:43:17.549084: Epoch time: 39.89 s 
2024-12-13 02:43:18.096785:  
2024-12-13 02:43:18.101799: Epoch 93 
2024-12-13 02:43:18.105310: Current learning rate: 0.00091 
2024-12-13 02:43:58.122174: train_loss -0.8369 
2024-12-13 02:43:58.128782: val_loss -0.7589 
2024-12-13 02:43:58.132849: Pseudo dice [np.float32(0.8238), np.float32(0.7238), np.float32(0.8692)] 
2024-12-13 02:43:58.139391: Epoch time: 40.03 s 
2024-12-13 02:43:58.692566:  
2024-12-13 02:43:58.698585: Epoch 94 
2024-12-13 02:43:58.702596: Current learning rate: 0.00079 
2024-12-13 02:44:38.732068: train_loss -0.8339 
2024-12-13 02:44:38.739597: val_loss -0.7574 
2024-12-13 02:44:38.746128: Pseudo dice [np.float32(0.8234), np.float32(0.7314), np.float32(0.8638)] 
2024-12-13 02:44:38.750191: Epoch time: 40.04 s 
2024-12-13 02:44:39.287605:  
2024-12-13 02:44:39.294212: Epoch 95 
2024-12-13 02:44:39.299300: Current learning rate: 0.00067 
2024-12-13 02:45:18.812787: train_loss -0.8372 
2024-12-13 02:45:18.820395: val_loss -0.7557 
2024-12-13 02:45:18.827468: Pseudo dice [np.float32(0.8239), np.float32(0.7173), np.float32(0.8714)] 
2024-12-13 02:45:18.832536: Epoch time: 39.52 s 
2024-12-13 02:45:19.356149:  
2024-12-13 02:45:19.362851: Epoch 96 
2024-12-13 02:45:19.367393: Current learning rate: 0.00055 
2024-12-13 02:45:59.005338: train_loss -0.8378 
2024-12-13 02:45:59.012676: val_loss -0.7554 
2024-12-13 02:45:59.018713: Pseudo dice [np.float32(0.8283), np.float32(0.7132), np.float32(0.8659)] 
2024-12-13 02:45:59.025657: Epoch time: 39.65 s 
2024-12-13 02:45:59.571074:  
2024-12-13 02:45:59.576601: Epoch 97 
2024-12-13 02:45:59.579623: Current learning rate: 0.00043 
2024-12-13 02:46:37.952864: train_loss -0.8365 
2024-12-13 02:46:37.958477: val_loss -0.757 
2024-12-13 02:46:37.965538: Pseudo dice [np.float32(0.8299), np.float32(0.7167), np.float32(0.866)] 
2024-12-13 02:46:37.970558: Epoch time: 38.38 s 
2024-12-13 02:46:38.518911:  
2024-12-13 02:46:38.524446: Epoch 98 
2024-12-13 02:46:38.530016: Current learning rate: 0.0003 
2024-12-13 02:47:18.410370: train_loss -0.8393 
2024-12-13 02:47:18.418924: val_loss -0.7541 
2024-12-13 02:47:18.426477: Pseudo dice [np.float32(0.8252), np.float32(0.7195), np.float32(0.8655)] 
2024-12-13 02:47:18.432520: Epoch time: 39.89 s 
2024-12-13 02:47:18.975867:  
2024-12-13 02:47:18.981387: Epoch 99 
2024-12-13 02:47:18.984903: Current learning rate: 0.00016 
2024-12-13 02:47:58.797950: train_loss -0.8369 
2024-12-13 02:47:58.803630: val_loss -0.7658 
2024-12-13 02:47:58.810283: Pseudo dice [np.float32(0.8304), np.float32(0.7363), np.float32(0.8723)] 
2024-12-13 02:47:58.815863: Epoch time: 39.82 s 
2024-12-13 02:47:59.601953: Training done. 
2024-12-13 02:47:59.655524: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-13 02:47:59.671050: The split file contains 5 splits. 
2024-12-13 02:47:59.678496: Desired fold for training: 0 
2024-12-13 02:47:59.685001: This split has 387 training and 97 validation cases. 
2024-12-13 02:47:59.692006: predicting BRATS_010 
2024-12-13 02:47:59.703090: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2024-12-13 02:48:01.795046: predicting BRATS_011 
2024-12-13 02:48:01.809662: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2024-12-13 02:48:03.522358: predicting BRATS_012 
2024-12-13 02:48:03.534492: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-13 02:48:05.367702: predicting BRATS_018 
2024-12-13 02:48:05.386722: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2024-12-13 02:48:07.382777: predicting BRATS_020 
2024-12-13 02:48:07.396555: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2024-12-13 02:48:09.280865: predicting BRATS_028 
2024-12-13 02:48:09.295054: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2024-12-13 02:48:11.083477: predicting BRATS_029 
2024-12-13 02:48:11.098042: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2024-12-13 02:48:12.881231: predicting BRATS_032 
2024-12-13 02:48:12.893743: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2024-12-13 02:48:14.755486: predicting BRATS_034 
2024-12-13 02:48:14.768509: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2024-12-13 02:48:16.597844: predicting BRATS_041 
2024-12-13 02:48:16.611354: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2024-12-13 02:48:18.429310: predicting BRATS_042 
2024-12-13 02:48:18.445822: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2024-12-13 02:48:20.209912: predicting BRATS_047 
2024-12-13 02:48:20.222423: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-13 02:48:21.893462: predicting BRATS_049 
2024-12-13 02:48:21.906971: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-13 02:48:23.595895: predicting BRATS_053 
2024-12-13 02:48:23.613477: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-13 02:48:25.286135: predicting BRATS_056 
2024-12-13 02:48:25.299152: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-13 02:48:26.961771: predicting BRATS_057 
2024-12-13 02:48:26.975146: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-13 02:48:28.593642: predicting BRATS_067 
2024-12-13 02:48:28.606149: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-13 02:48:30.248782: predicting BRATS_069 
2024-12-13 02:48:30.267120: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-13 02:48:31.917061: predicting BRATS_085 
2024-12-13 02:48:31.931162: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2024-12-13 02:48:33.493892: predicting BRATS_086 
2024-12-13 02:48:33.506404: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2024-12-13 02:48:35.116697: predicting BRATS_088 
2024-12-13 02:48:35.131242: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2024-12-13 02:48:36.780881: predicting BRATS_091 
2024-12-13 02:48:36.795393: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2024-12-13 02:48:38.421451: predicting BRATS_098 
2024-12-13 02:48:38.436463: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2024-12-13 02:48:40.158140: predicting BRATS_100 
2024-12-13 02:48:40.172165: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-13 02:48:41.736390: predicting BRATS_101 
2024-12-13 02:48:41.751410: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-13 02:48:43.301471: predicting BRATS_102 
2024-12-13 02:48:43.314852: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2024-12-13 02:48:45.069703: predicting BRATS_104 
2024-12-13 02:48:45.083220: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2024-12-13 02:48:46.771521: predicting BRATS_111 
2024-12-13 02:48:46.786874: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2024-12-13 02:48:48.417823: predicting BRATS_116 
2024-12-13 02:48:48.432836: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2024-12-13 02:48:50.105734: predicting BRATS_135 
2024-12-13 02:48:50.120446: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2024-12-13 02:48:51.765963: predicting BRATS_136 
2024-12-13 02:48:51.780979: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2024-12-13 02:48:53.407953: predicting BRATS_138 
2024-12-13 02:48:53.420977: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2024-12-13 02:48:55.051557: predicting BRATS_145 
2024-12-13 02:48:55.066065: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2024-12-13 02:48:56.713515: predicting BRATS_149 
2024-12-13 02:48:56.727023: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2024-12-13 02:48:58.412045: predicting BRATS_155 
2024-12-13 02:48:58.426558: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-13 02:49:00.082377: predicting BRATS_157 
2024-12-13 02:49:00.096887: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-13 02:49:01.750796: predicting BRATS_158 
2024-12-13 02:49:01.768313: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-13 02:49:03.440915: predicting BRATS_159 
2024-12-13 02:49:03.455150: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-13 02:49:05.024301: predicting BRATS_163 
2024-12-13 02:49:05.037362: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2024-12-13 02:49:06.727631: predicting BRATS_164 
2024-12-13 02:49:06.741647: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2024-12-13 02:49:08.342332: predicting BRATS_169 
2024-12-13 02:49:08.354935: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2024-12-13 02:49:10.075464: predicting BRATS_176 
2024-12-13 02:49:10.089974: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2024-12-13 02:49:11.763476: predicting BRATS_181 
2024-12-13 02:49:11.775987: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2024-12-13 02:49:13.474654: predicting BRATS_183 
2024-12-13 02:49:13.488159: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-13 02:49:15.173898: predicting BRATS_184 
2024-12-13 02:49:15.187410: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-13 02:49:16.896076: predicting BRATS_187 
2024-12-13 02:49:16.908586: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-13 02:49:18.586052: predicting BRATS_192 
2024-12-13 02:49:18.602561: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2024-12-13 02:49:20.195771: predicting BRATS_198 
2024-12-13 02:49:20.210055: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2024-12-13 02:49:21.929924: predicting BRATS_207 
2024-12-13 02:49:21.944949: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-13 02:49:23.555983: predicting BRATS_208 
2024-12-13 02:49:23.570033: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-13 02:49:25.206973: predicting BRATS_218 
2024-12-13 02:49:25.221478: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2024-12-13 02:49:26.971395: predicting BRATS_220 
2024-12-13 02:49:26.985991: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2024-12-13 02:49:28.675326: predicting BRATS_224 
2024-12-13 02:49:28.688621: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2024-12-13 02:49:30.354021: predicting BRATS_230 
2024-12-13 02:49:30.368547: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2024-12-13 02:49:32.008663: predicting BRATS_271 
2024-12-13 02:49:32.021169: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2024-12-13 02:49:33.710373: predicting BRATS_282 
2024-12-13 02:49:33.724387: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2024-12-13 02:49:35.376960: predicting BRATS_284 
2024-12-13 02:49:35.393052: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2024-12-13 02:49:36.967661: predicting BRATS_287 
2024-12-13 02:49:36.980698: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-13 02:49:38.618988: predicting BRATS_290 
2024-12-13 02:49:38.631492: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2024-12-13 02:49:40.291997: predicting BRATS_291 
2024-12-13 02:49:40.307028: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2024-12-13 02:49:41.999962: predicting BRATS_292 
2024-12-13 02:49:42.012475: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2024-12-13 02:49:43.664861: predicting BRATS_293 
2024-12-13 02:49:43.679927: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2024-12-13 02:49:45.469051: predicting BRATS_300 
2024-12-13 02:49:45.485127: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2024-12-13 02:49:47.216668: predicting BRATS_305 
2024-12-13 02:49:47.231180: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2024-12-13 02:49:48.977608: predicting BRATS_311 
2024-12-13 02:49:48.992625: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2024-12-13 02:49:50.725823: predicting BRATS_314 
2024-12-13 02:49:50.741340: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2024-12-13 02:49:52.474765: predicting BRATS_321 
2024-12-13 02:49:52.489779: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2024-12-13 02:49:54.249688: predicting BRATS_328 
2024-12-13 02:49:54.264192: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2024-12-13 02:49:56.060322: predicting BRATS_329 
2024-12-13 02:49:56.072829: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2024-12-13 02:49:57.677429: predicting BRATS_335 
2024-12-13 02:49:57.691942: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2024-12-13 02:49:59.436397: predicting BRATS_343 
2024-12-13 02:49:59.450917: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2024-12-13 02:50:01.187917: predicting BRATS_350 
2024-12-13 02:50:01.202941: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2024-12-13 02:50:02.874501: predicting BRATS_351 
2024-12-13 02:50:02.887133: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2024-12-13 02:50:04.554312: predicting BRATS_356 
2024-12-13 02:50:04.566819: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2024-12-13 02:50:06.427254: predicting BRATS_366 
2024-12-13 02:50:06.440771: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2024-12-13 02:50:08.208266: predicting BRATS_367 
2024-12-13 02:50:08.221772: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2024-12-13 02:50:10.110530: predicting BRATS_374 
2024-12-13 02:50:10.125037: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2024-12-13 02:50:11.949389: predicting BRATS_376 
2024-12-13 02:50:11.963613: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2024-12-13 02:50:13.762547: predicting BRATS_377 
2024-12-13 02:50:13.778444: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2024-12-13 02:50:15.576527: predicting BRATS_378 
2024-12-13 02:50:15.589152: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2024-12-13 02:50:17.418115: predicting BRATS_379 
2024-12-13 02:50:17.431632: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2024-12-13 02:50:19.245930: predicting BRATS_384 
2024-12-13 02:50:19.262953: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2024-12-13 02:50:20.885897: predicting BRATS_386 
2024-12-13 02:50:20.898904: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2024-12-13 02:50:22.625589: predicting BRATS_394 
2024-12-13 02:50:22.640425: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-13 02:50:24.416487: predicting BRATS_398 
2024-12-13 02:50:24.430501: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2024-12-13 02:50:26.243655: predicting BRATS_400 
2024-12-13 02:50:26.258665: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2024-12-13 02:50:28.115909: predicting BRATS_432 
2024-12-13 02:50:28.132464: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2024-12-13 02:50:29.912997: predicting BRATS_437 
2024-12-13 02:50:29.926010: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-13 02:50:31.570295: predicting BRATS_445 
2024-12-13 02:50:31.584801: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2024-12-13 02:50:33.551626: predicting BRATS_446 
2024-12-13 02:50:33.564135: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2024-12-13 02:50:35.298435: predicting BRATS_450 
2024-12-13 02:50:35.312457: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2024-12-13 02:50:36.964690: predicting BRATS_452 
2024-12-13 02:50:36.978832: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2024-12-13 02:50:38.689569: predicting BRATS_460 
2024-12-13 02:50:38.705154: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2024-12-13 02:50:40.450015: predicting BRATS_470 
2024-12-13 02:50:40.464533: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2024-12-13 02:50:42.244874: predicting BRATS_472 
2024-12-13 02:50:42.258997: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2024-12-13 02:50:43.997292: predicting BRATS_473 
2024-12-13 02:50:44.010043: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2024-12-13 02:50:45.551191: predicting BRATS_482 
2024-12-13 02:50:45.564702: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2024-12-13 02:50:55.640253: Validation complete 
2024-12-13 02:50:55.646760: Mean Validation Dice:  0.7141750472189706 
