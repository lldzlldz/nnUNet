
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-16 23:01:21.796064: do_dummy_2d_data_aug: False 
2025-03-16 23:01:21.823835: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-16 23:01:21.911413: The split file contains 5 splits. 
2025-03-16 23:01:21.915918: Desired fold for training: 0 
2025-03-16 23:01:21.918114: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2025-03-16 23:01:54.463449: unpacking dataset... 
2025-03-16 23:01:55.154250: unpacking done... 
2025-03-16 23:01:58.025727:  
2025-03-16 23:01:58.030744: Epoch 0 
2025-03-16 23:01:58.034751: Current learning rate: 0.01 
2025-03-16 23:02:40.878904: train_loss -0.2796 
2025-03-16 23:02:40.886570: val_loss -0.3743 
2025-03-16 23:02:40.891687: Pseudo dice [np.float32(0.6613), np.float32(0.4568), np.float32(0.7477)] 
2025-03-16 23:02:40.895764: Epoch time: 42.85 s 
2025-03-16 23:02:40.899310: Yayy! New best EMA pseudo Dice: 0.6219000220298767 
2025-03-16 23:02:41.595808:  
2025-03-16 23:02:41.601876: Epoch 1 
2025-03-16 23:02:41.604934: Current learning rate: 0.00991 
2025-03-16 23:03:20.099089: train_loss -0.4838 
2025-03-16 23:03:20.104151: val_loss -0.5006 
2025-03-16 23:03:20.107698: Pseudo dice [np.float32(0.7479), np.float32(0.5854), np.float32(0.8053)] 
2025-03-16 23:03:20.110735: Epoch time: 38.5 s 
2025-03-16 23:03:20.113766: Yayy! New best EMA pseudo Dice: 0.6309999823570251 
2025-03-16 23:03:20.884787:  
2025-03-16 23:03:20.891302: Epoch 2 
2025-03-16 23:03:20.894815: Current learning rate: 0.00982 
2025-03-16 23:03:59.476415: train_loss -0.5408 
2025-03-16 23:03:59.483019: val_loss -0.5475 
2025-03-16 23:03:59.486535: Pseudo dice [np.float32(0.7499), np.float32(0.665), np.float32(0.8289)] 
2025-03-16 23:03:59.490566: Epoch time: 38.59 s 
2025-03-16 23:03:59.493073: Yayy! New best EMA pseudo Dice: 0.6427000164985657 
2025-03-16 23:04:00.300281:  
2025-03-16 23:04:00.305862: Epoch 3 
2025-03-16 23:04:00.308368: Current learning rate: 0.00973 
2025-03-16 23:04:38.754688: train_loss -0.5292 
2025-03-16 23:04:38.761289: val_loss -0.5227 
2025-03-16 23:04:38.764845: Pseudo dice [np.float32(0.7598), np.float32(0.5023), np.float32(0.8023)] 
2025-03-16 23:04:38.768428: Epoch time: 38.46 s 
2025-03-16 23:04:38.771976: Yayy! New best EMA pseudo Dice: 0.6471999883651733 
2025-03-16 23:04:39.542595:  
2025-03-16 23:04:39.549193: Epoch 4 
2025-03-16 23:04:39.552788: Current learning rate: 0.00964 
2025-03-16 23:05:17.969491: train_loss -0.5788 
2025-03-16 23:05:17.975553: val_loss -0.5834 
2025-03-16 23:05:17.980653: Pseudo dice [np.float32(0.7742), np.float32(0.6437), np.float32(0.8142)] 
2025-03-16 23:05:17.984741: Epoch time: 38.43 s 
2025-03-16 23:05:17.988254: Yayy! New best EMA pseudo Dice: 0.6568999886512756 
2025-03-16 23:05:18.899370:  
2025-03-16 23:05:18.904886: Epoch 5 
2025-03-16 23:05:18.908396: Current learning rate: 0.00955 
2025-03-16 23:05:57.347763: train_loss -0.5965 
2025-03-16 23:05:57.353834: val_loss -0.5718 
2025-03-16 23:05:57.357443: Pseudo dice [np.float32(0.8086), np.float32(0.6675), np.float32(0.8194)] 
2025-03-16 23:05:57.360519: Epoch time: 38.45 s 
2025-03-16 23:05:57.363054: Yayy! New best EMA pseudo Dice: 0.6676999926567078 
2025-03-16 23:05:58.131598:  
2025-03-16 23:05:58.136666: Epoch 6 
2025-03-16 23:05:58.139862: Current learning rate: 0.00946 
2025-03-16 23:06:36.630904: train_loss -0.5935 
2025-03-16 23:06:36.637573: val_loss -0.5771 
2025-03-16 23:06:36.640820: Pseudo dice [np.float32(0.7886), np.float32(0.6411), np.float32(0.8433)] 
2025-03-16 23:06:36.644859: Epoch time: 38.5 s 
2025-03-16 23:06:36.648404: Yayy! New best EMA pseudo Dice: 0.6766999959945679 
2025-03-16 23:06:37.490004:  
2025-03-16 23:06:37.495523: Epoch 7 
2025-03-16 23:06:37.499037: Current learning rate: 0.00937 
2025-03-16 23:07:16.543463: train_loss -0.5765 
2025-03-16 23:07:16.549035: val_loss -0.5471 
2025-03-16 23:07:16.553097: Pseudo dice [np.float32(0.7706), np.float32(0.5424), np.float32(0.8198)] 
2025-03-16 23:07:16.556678: Epoch time: 39.05 s 
2025-03-16 23:07:16.559715: Yayy! New best EMA pseudo Dice: 0.6801999807357788 
2025-03-16 23:07:17.416641:  
2025-03-16 23:07:17.423824: Epoch 8 
2025-03-16 23:07:17.427895: Current learning rate: 0.00928 
2025-03-16 23:07:56.505988: train_loss -0.6061 
2025-03-16 23:07:56.513505: val_loss -0.5764 
2025-03-16 23:07:56.517016: Pseudo dice [np.float32(0.7915), np.float32(0.6338), np.float32(0.8355)] 
2025-03-16 23:07:56.520524: Epoch time: 39.09 s 
2025-03-16 23:07:56.523577: Yayy! New best EMA pseudo Dice: 0.6875 
2025-03-16 23:07:57.318496:  
2025-03-16 23:07:57.324096: Epoch 9 
2025-03-16 23:07:57.327157: Current learning rate: 0.00919 
2025-03-16 23:08:36.289645: train_loss -0.6158 
2025-03-16 23:08:36.295706: val_loss -0.5817 
2025-03-16 23:08:36.299228: Pseudo dice [np.float32(0.8076), np.float32(0.6519), np.float32(0.8064)] 
2025-03-16 23:08:36.302285: Epoch time: 38.97 s 
2025-03-16 23:08:36.305806: Yayy! New best EMA pseudo Dice: 0.6942999958992004 
2025-03-16 23:08:37.083125:  
2025-03-16 23:08:37.088215: Epoch 10 
2025-03-16 23:08:37.091727: Current learning rate: 0.0091 
2025-03-16 23:09:15.633220: train_loss -0.6088 
2025-03-16 23:09:15.639378: val_loss -0.5389 
2025-03-16 23:09:15.642936: Pseudo dice [np.float32(0.7671), np.float32(0.5998), np.float32(0.8227)] 
2025-03-16 23:09:15.645995: Epoch time: 38.55 s 
2025-03-16 23:09:15.649139: Yayy! New best EMA pseudo Dice: 0.6977999806404114 
2025-03-16 23:09:16.417842:  
2025-03-16 23:09:16.423365: Epoch 11 
2025-03-16 23:09:16.425872: Current learning rate: 0.009 
2025-03-16 23:09:54.897992: train_loss -0.618 
2025-03-16 23:09:54.905028: val_loss -0.5844 
2025-03-16 23:09:54.909580: Pseudo dice [np.float32(0.7895), np.float32(0.6642), np.float32(0.8318)] 
2025-03-16 23:09:54.913594: Epoch time: 38.48 s 
2025-03-16 23:09:54.918258: Yayy! New best EMA pseudo Dice: 0.704200029373169 
2025-03-16 23:09:55.690955:  
2025-03-16 23:09:55.694982: Epoch 12 
2025-03-16 23:09:55.698021: Current learning rate: 0.00891 
2025-03-16 23:10:34.296008: train_loss -0.6254 
2025-03-16 23:10:34.302597: val_loss -0.585 
2025-03-16 23:10:34.305829: Pseudo dice [np.float32(0.8108), np.float32(0.626), np.float32(0.8128)] 
2025-03-16 23:10:34.310271: Epoch time: 38.61 s 
2025-03-16 23:10:34.312846: Yayy! New best EMA pseudo Dice: 0.7088000178337097 
2025-03-16 23:10:35.252040:  
2025-03-16 23:10:35.258568: Epoch 13 
2025-03-16 23:10:35.263083: Current learning rate: 0.00882 
2025-03-16 23:11:13.689100: train_loss -0.6404 
2025-03-16 23:11:13.696309: val_loss -0.5916 
2025-03-16 23:11:13.699378: Pseudo dice [np.float32(0.8156), np.float32(0.6656), np.float32(0.8121)] 
2025-03-16 23:11:13.702990: Epoch time: 38.44 s 
2025-03-16 23:11:13.706031: Yayy! New best EMA pseudo Dice: 0.7143999934196472 
2025-03-16 23:11:14.490287:  
2025-03-16 23:11:14.496453: Epoch 14 
2025-03-16 23:11:14.500022: Current learning rate: 0.00873 
2025-03-16 23:11:52.884521: train_loss -0.6311 
2025-03-16 23:11:52.891116: val_loss -0.603 
2025-03-16 23:11:52.894153: Pseudo dice [np.float32(0.7872), np.float32(0.6697), np.float32(0.8372)] 
2025-03-16 23:11:52.897673: Epoch time: 38.39 s 
2025-03-16 23:11:52.901180: Yayy! New best EMA pseudo Dice: 0.7193999886512756 
2025-03-16 23:11:53.692524:  
2025-03-16 23:11:53.698561: Epoch 15 
2025-03-16 23:11:53.702598: Current learning rate: 0.00864 
2025-03-16 23:12:32.223500: train_loss -0.6449 
2025-03-16 23:12:32.232024: val_loss -0.5607 
2025-03-16 23:12:32.236032: Pseudo dice [np.float32(0.7836), np.float32(0.6526), np.float32(0.8143)] 
2025-03-16 23:12:32.239542: Epoch time: 38.53 s 
2025-03-16 23:12:32.243552: Yayy! New best EMA pseudo Dice: 0.7225000262260437 
2025-03-16 23:12:33.036444:  
2025-03-16 23:12:33.041457: Epoch 16 
2025-03-16 23:12:33.044969: Current learning rate: 0.00855 
2025-03-16 23:13:11.554733: train_loss -0.6365 
2025-03-16 23:13:11.561368: val_loss -0.5897 
2025-03-16 23:13:11.565418: Pseudo dice [np.float32(0.8007), np.float32(0.6242), np.float32(0.7948)] 
2025-03-16 23:13:11.568447: Epoch time: 38.52 s 
2025-03-16 23:13:11.571357: Yayy! New best EMA pseudo Dice: 0.7242000102996826 
2025-03-16 23:13:12.394174:  
2025-03-16 23:13:12.400229: Epoch 17 
2025-03-16 23:13:12.404300: Current learning rate: 0.00846 
2025-03-16 23:13:51.090784: train_loss -0.653 
2025-03-16 23:13:51.097416: val_loss -0.6045 
2025-03-16 23:13:51.100982: Pseudo dice [np.float32(0.7996), np.float32(0.6294), np.float32(0.8416)] 
2025-03-16 23:13:51.106088: Epoch time: 38.7 s 
2025-03-16 23:13:51.108659: Yayy! New best EMA pseudo Dice: 0.7275000214576721 
2025-03-16 23:13:51.974438:  
2025-03-16 23:13:51.980486: Epoch 18 
2025-03-16 23:13:51.983567: Current learning rate: 0.00836 
2025-03-16 23:14:30.862392: train_loss -0.6457 
2025-03-16 23:14:30.869048: val_loss -0.5928 
2025-03-16 23:14:30.873639: Pseudo dice [np.float32(0.8029), np.float32(0.6803), np.float32(0.8188)] 
2025-03-16 23:14:30.877673: Epoch time: 38.89 s 
2025-03-16 23:14:30.880802: Yayy! New best EMA pseudo Dice: 0.7315000295639038 
2025-03-16 23:14:31.677575:  
2025-03-16 23:14:31.683092: Epoch 19 
2025-03-16 23:14:31.686601: Current learning rate: 0.00827 
2025-03-16 23:15:10.862932: train_loss -0.6271 
2025-03-16 23:15:10.870455: val_loss -0.5937 
2025-03-16 23:15:10.873964: Pseudo dice [np.float32(0.7911), np.float32(0.6525), np.float32(0.8305)] 
2025-03-16 23:15:10.877976: Epoch time: 39.19 s 
2025-03-16 23:15:10.881488: Yayy! New best EMA pseudo Dice: 0.7340999841690063 
2025-03-16 23:15:11.846232:  
2025-03-16 23:15:11.852776: Epoch 20 
2025-03-16 23:15:11.856338: Current learning rate: 0.00818 
2025-03-16 23:15:50.802356: train_loss -0.6528 
2025-03-16 23:15:50.808403: val_loss -0.5985 
2025-03-16 23:15:50.811702: Pseudo dice [np.float32(0.8042), np.float32(0.6587), np.float32(0.8299)] 
2025-03-16 23:15:50.816866: Epoch time: 38.96 s 
2025-03-16 23:15:50.820399: Yayy! New best EMA pseudo Dice: 0.7371000051498413 
2025-03-16 23:15:51.652920:  
2025-03-16 23:15:51.658486: Epoch 21 
2025-03-16 23:15:51.663147: Current learning rate: 0.00809 
2025-03-16 23:16:30.953343: train_loss -0.6639 
2025-03-16 23:16:30.959512: val_loss -0.6012 
2025-03-16 23:16:30.963079: Pseudo dice [np.float32(0.7973), np.float32(0.6825), np.float32(0.8438)] 
2025-03-16 23:16:30.966616: Epoch time: 39.3 s 
2025-03-16 23:16:30.969683: Yayy! New best EMA pseudo Dice: 0.7408999800682068 
2025-03-16 23:16:31.801835:  
2025-03-16 23:16:31.807876: Epoch 22 
2025-03-16 23:16:31.810916: Current learning rate: 0.008 
2025-03-16 23:17:10.755268: train_loss -0.6516 
2025-03-16 23:17:10.762392: val_loss -0.6255 
2025-03-16 23:17:10.766989: Pseudo dice [np.float32(0.8118), np.float32(0.7319), np.float32(0.838)] 
2025-03-16 23:17:10.770542: Epoch time: 38.95 s 
2025-03-16 23:17:10.775093: Yayy! New best EMA pseudo Dice: 0.7462000250816345 
2025-03-16 23:17:11.603062:  
2025-03-16 23:17:11.609098: Epoch 23 
2025-03-16 23:17:11.614173: Current learning rate: 0.0079 
2025-03-16 23:17:50.571108: train_loss -0.6494 
2025-03-16 23:17:50.577217: val_loss -0.624 
2025-03-16 23:17:50.580883: Pseudo dice [np.float32(0.8055), np.float32(0.6943), np.float32(0.8089)] 
2025-03-16 23:17:50.585540: Epoch time: 38.97 s 
2025-03-16 23:17:50.590059: Yayy! New best EMA pseudo Dice: 0.7484999895095825 
2025-03-16 23:17:51.409805:  
2025-03-16 23:17:51.414851: Epoch 24 
2025-03-16 23:17:51.418416: Current learning rate: 0.00781 
2025-03-16 23:18:32.049618: train_loss -0.6559 
2025-03-16 23:18:32.058167: val_loss -0.6142 
2025-03-16 23:18:32.064692: Pseudo dice [np.float32(0.8169), np.float32(0.6963), np.float32(0.8431)] 
2025-03-16 23:18:32.069296: Epoch time: 40.64 s 
2025-03-16 23:18:32.072326: Yayy! New best EMA pseudo Dice: 0.7522000074386597 
2025-03-16 23:18:32.882364:  
2025-03-16 23:18:32.887917: Epoch 25 
2025-03-16 23:18:32.891972: Current learning rate: 0.00772 
2025-03-16 23:19:14.750479: train_loss -0.6425 
2025-03-16 23:19:14.757076: val_loss -0.6219 
2025-03-16 23:19:14.761131: Pseudo dice [np.float32(0.823), np.float32(0.6508), np.float32(0.8186)] 
2025-03-16 23:19:14.764737: Epoch time: 41.87 s 
2025-03-16 23:19:14.768844: Yayy! New best EMA pseudo Dice: 0.7534000277519226 
2025-03-16 23:19:15.535042:  
2025-03-16 23:19:15.541639: Epoch 26 
2025-03-16 23:19:15.544186: Current learning rate: 0.00763 
2025-03-16 23:19:57.159075: train_loss -0.6682 
2025-03-16 23:19:57.165653: val_loss -0.596 
2025-03-16 23:19:57.169767: Pseudo dice [np.float32(0.7932), np.float32(0.6181), np.float32(0.8459)] 
2025-03-16 23:19:57.173310: Epoch time: 41.62 s 
2025-03-16 23:19:57.993599:  
2025-03-16 23:19:57.999114: Epoch 27 
2025-03-16 23:19:58.002624: Current learning rate: 0.00753 
2025-03-16 23:20:40.172765: train_loss -0.6483 
2025-03-16 23:20:40.178818: val_loss -0.606 
2025-03-16 23:20:40.182827: Pseudo dice [np.float32(0.8), np.float32(0.671), np.float32(0.8419)] 
2025-03-16 23:20:40.186427: Epoch time: 42.18 s 
2025-03-16 23:20:40.188933: Yayy! New best EMA pseudo Dice: 0.7551000118255615 
2025-03-16 23:20:40.977629:  
2025-03-16 23:20:40.983193: Epoch 28 
2025-03-16 23:20:40.986753: Current learning rate: 0.00744 
2025-03-16 23:21:20.202166: train_loss -0.6595 
2025-03-16 23:21:20.208274: val_loss -0.6209 
2025-03-16 23:21:20.212323: Pseudo dice [np.float32(0.7989), np.float32(0.7009), np.float32(0.8393)] 
2025-03-16 23:21:20.215409: Epoch time: 39.23 s 
2025-03-16 23:21:20.218963: Yayy! New best EMA pseudo Dice: 0.7574999928474426 
2025-03-16 23:21:21.012308:  
2025-03-16 23:21:21.017435: Epoch 29 
2025-03-16 23:21:21.022392: Current learning rate: 0.00735 
2025-03-16 23:21:59.968007: train_loss -0.658 
2025-03-16 23:21:59.974021: val_loss -0.5804 
2025-03-16 23:21:59.977526: Pseudo dice [np.float32(0.8004), np.float32(0.6785), np.float32(0.8392)] 
2025-03-16 23:21:59.981540: Epoch time: 38.96 s 
2025-03-16 23:21:59.984066: Yayy! New best EMA pseudo Dice: 0.7590000033378601 
2025-03-16 23:22:00.770569:  
2025-03-16 23:22:00.776670: Epoch 30 
2025-03-16 23:22:00.779211: Current learning rate: 0.00725 
2025-03-16 23:22:39.840147: train_loss -0.6707 
2025-03-16 23:22:39.847342: val_loss -0.6046 
2025-03-16 23:22:39.850852: Pseudo dice [np.float32(0.785), np.float32(0.6731), np.float32(0.8494)] 
2025-03-16 23:22:39.854892: Epoch time: 39.07 s 
2025-03-16 23:22:39.858402: Yayy! New best EMA pseudo Dice: 0.7601000070571899 
2025-03-16 23:22:40.663382:  
2025-03-16 23:22:40.669950: Epoch 31 
2025-03-16 23:22:40.672976: Current learning rate: 0.00716 
2025-03-16 23:23:21.500654: train_loss -0.6767 
2025-03-16 23:23:21.507217: val_loss -0.6274 
2025-03-16 23:23:21.510826: Pseudo dice [np.float32(0.8064), np.float32(0.6617), np.float32(0.8572)] 
2025-03-16 23:23:21.514387: Epoch time: 40.84 s 
2025-03-16 23:23:21.518920: Yayy! New best EMA pseudo Dice: 0.7616000175476074 
2025-03-16 23:23:22.304288:  
2025-03-16 23:23:22.310799: Epoch 32 
2025-03-16 23:23:22.314307: Current learning rate: 0.00707 
2025-03-16 23:24:01.749551: train_loss -0.6667 
2025-03-16 23:24:01.757152: val_loss -0.6273 
2025-03-16 23:24:01.761294: Pseudo dice [np.float32(0.8156), np.float32(0.6992), np.float32(0.8397)] 
2025-03-16 23:24:01.763843: Epoch time: 39.45 s 
2025-03-16 23:24:01.767873: Yayy! New best EMA pseudo Dice: 0.7638999819755554 
2025-03-16 23:24:02.545432:  
2025-03-16 23:24:02.551028: Epoch 33 
2025-03-16 23:24:02.554539: Current learning rate: 0.00697 
2025-03-16 23:24:41.601811: train_loss -0.6548 
2025-03-16 23:24:41.609002: val_loss -0.6183 
2025-03-16 23:24:41.612607: Pseudo dice [np.float32(0.7936), np.float32(0.7173), np.float32(0.8311)] 
2025-03-16 23:24:41.615660: Epoch time: 39.06 s 
2025-03-16 23:24:41.619676: Yayy! New best EMA pseudo Dice: 0.7656000256538391 
2025-03-16 23:24:42.568017:  
2025-03-16 23:24:42.573090: Epoch 34 
2025-03-16 23:24:42.576787: Current learning rate: 0.00688 
2025-03-16 23:25:21.940703: train_loss -0.6726 
2025-03-16 23:25:21.947847: val_loss -0.6298 
2025-03-16 23:25:21.950958: Pseudo dice [np.float32(0.811), np.float32(0.6676), np.float32(0.8595)] 
2025-03-16 23:25:21.954507: Epoch time: 39.37 s 
2025-03-16 23:25:21.958544: Yayy! New best EMA pseudo Dice: 0.7669000029563904 
2025-03-16 23:25:22.926747:  
2025-03-16 23:25:22.930764: Epoch 35 
2025-03-16 23:25:22.935782: Current learning rate: 0.00679 
2025-03-16 23:26:01.552036: train_loss -0.6709 
2025-03-16 23:26:01.558661: val_loss -0.6376 
2025-03-16 23:26:01.562173: Pseudo dice [np.float32(0.8216), np.float32(0.661), np.float32(0.8493)] 
2025-03-16 23:26:01.566190: Epoch time: 38.63 s 
2025-03-16 23:26:01.569793: Yayy! New best EMA pseudo Dice: 0.7680000066757202 
2025-03-16 23:26:02.405803:  
2025-03-16 23:26:02.411843: Epoch 36 
2025-03-16 23:26:02.415359: Current learning rate: 0.00669 
2025-03-16 23:26:41.312807: train_loss -0.6603 
2025-03-16 23:26:41.319395: val_loss -0.6103 
2025-03-16 23:26:41.322945: Pseudo dice [np.float32(0.797), np.float32(0.6732), np.float32(0.8446)] 
2025-03-16 23:26:41.326484: Epoch time: 38.91 s 
2025-03-16 23:26:41.330136: Yayy! New best EMA pseudo Dice: 0.7682999968528748 
2025-03-16 23:26:42.160325:  
2025-03-16 23:26:42.165338: Epoch 37 
2025-03-16 23:26:42.168849: Current learning rate: 0.0066 
2025-03-16 23:27:23.002991: train_loss -0.6756 
2025-03-16 23:27:23.009655: val_loss -0.6509 
2025-03-16 23:27:23.013737: Pseudo dice [np.float32(0.8307), np.float32(0.6829), np.float32(0.8444)] 
2025-03-16 23:27:23.017310: Epoch time: 40.84 s 
2025-03-16 23:27:23.020468: Yayy! New best EMA pseudo Dice: 0.7700999975204468 
2025-03-16 23:27:23.836083:  
2025-03-16 23:27:23.841097: Epoch 38 
2025-03-16 23:27:23.844642: Current learning rate: 0.0065 
2025-03-16 23:28:05.073545: train_loss -0.6761 
2025-03-16 23:28:05.078626: val_loss -0.6357 
2025-03-16 23:28:05.083699: Pseudo dice [np.float32(0.8), np.float32(0.7205), np.float32(0.8465)] 
2025-03-16 23:28:05.087739: Epoch time: 41.24 s 
2025-03-16 23:28:05.091284: Yayy! New best EMA pseudo Dice: 0.7720000147819519 
2025-03-16 23:28:05.914729:  
2025-03-16 23:28:05.920286: Epoch 39 
2025-03-16 23:28:05.923795: Current learning rate: 0.00641 
2025-03-16 23:28:47.211015: train_loss -0.678 
2025-03-16 23:28:47.217657: val_loss -0.6155 
2025-03-16 23:28:47.221282: Pseudo dice [np.float32(0.8067), np.float32(0.6716), np.float32(0.8255)] 
2025-03-16 23:28:47.224823: Epoch time: 41.3 s 
2025-03-16 23:28:47.872067:  
2025-03-16 23:28:47.877604: Epoch 40 
2025-03-16 23:28:47.881154: Current learning rate: 0.00631 
2025-03-16 23:29:29.463291: train_loss -0.6783 
2025-03-16 23:29:29.469361: val_loss -0.622 
2025-03-16 23:29:29.473459: Pseudo dice [np.float32(0.8096), np.float32(0.6859), np.float32(0.8468)] 
2025-03-16 23:29:29.476477: Epoch time: 41.59 s 
2025-03-16 23:29:29.479995: Yayy! New best EMA pseudo Dice: 0.7724999785423279 
2025-03-16 23:29:30.315688:  
2025-03-16 23:29:30.322271: Epoch 41 
2025-03-16 23:29:30.326396: Current learning rate: 0.00622 
2025-03-16 23:30:11.944084: train_loss -0.669 
2025-03-16 23:30:11.949715: val_loss -0.6365 
2025-03-16 23:30:11.953791: Pseudo dice [np.float32(0.8173), np.float32(0.6956), np.float32(0.8512)] 
2025-03-16 23:30:11.956403: Epoch time: 41.63 s 
2025-03-16 23:30:11.960471: Yayy! New best EMA pseudo Dice: 0.7741000056266785 
2025-03-16 23:30:12.889669:  
2025-03-16 23:30:12.894683: Epoch 42 
2025-03-16 23:30:12.899199: Current learning rate: 0.00612 
2025-03-16 23:30:54.389007: train_loss -0.6809 
2025-03-16 23:30:54.395052: val_loss -0.6518 
2025-03-16 23:30:54.399085: Pseudo dice [np.float32(0.8315), np.float32(0.6834), np.float32(0.8421)] 
2025-03-16 23:30:54.401596: Epoch time: 41.5 s 
2025-03-16 23:30:54.405112: Yayy! New best EMA pseudo Dice: 0.7752000093460083 
2025-03-16 23:30:55.184188:  
2025-03-16 23:30:55.190285: Epoch 43 
2025-03-16 23:30:55.193365: Current learning rate: 0.00603 
2025-03-16 23:31:36.605007: train_loss -0.693 
2025-03-16 23:31:36.614208: val_loss -0.6322 
2025-03-16 23:31:36.620270: Pseudo dice [np.float32(0.8321), np.float32(0.7053), np.float32(0.8481)] 
2025-03-16 23:31:36.623862: Epoch time: 41.42 s 
2025-03-16 23:31:36.626369: Yayy! New best EMA pseudo Dice: 0.7771999835968018 
2025-03-16 23:31:37.400626:  
2025-03-16 23:31:37.406760: Epoch 44 
2025-03-16 23:31:37.409858: Current learning rate: 0.00593 
2025-03-16 23:32:18.748777: train_loss -0.6814 
2025-03-16 23:32:18.754861: val_loss -0.6477 
2025-03-16 23:32:18.758438: Pseudo dice [np.float32(0.8225), np.float32(0.698), np.float32(0.8602)] 
2025-03-16 23:32:18.762028: Epoch time: 41.35 s 
2025-03-16 23:32:18.765631: Yayy! New best EMA pseudo Dice: 0.7789000272750854 
2025-03-16 23:32:19.548337:  
2025-03-16 23:32:19.553878: Epoch 45 
2025-03-16 23:32:19.557396: Current learning rate: 0.00584 
2025-03-16 23:33:00.735968: train_loss -0.6745 
2025-03-16 23:33:00.742549: val_loss -0.6392 
2025-03-16 23:33:00.748085: Pseudo dice [np.float32(0.8222), np.float32(0.6869), np.float32(0.8551)] 
2025-03-16 23:33:00.751613: Epoch time: 41.19 s 
2025-03-16 23:33:00.754125: Yayy! New best EMA pseudo Dice: 0.7797999978065491 
2025-03-16 23:33:01.517553:  
2025-03-16 23:33:01.523093: Epoch 46 
2025-03-16 23:33:01.526121: Current learning rate: 0.00574 
2025-03-16 23:33:42.735670: train_loss -0.6898 
2025-03-16 23:33:42.743312: val_loss -0.6236 
2025-03-16 23:33:42.747881: Pseudo dice [np.float32(0.7908), np.float32(0.6919), np.float32(0.8262)] 
2025-03-16 23:33:42.751458: Epoch time: 41.22 s 
2025-03-16 23:33:43.483820:  
2025-03-16 23:33:43.489955: Epoch 47 
2025-03-16 23:33:43.493471: Current learning rate: 0.00565 
2025-03-16 23:34:24.920694: train_loss -0.6874 
2025-03-16 23:34:24.928212: val_loss -0.6316 
2025-03-16 23:34:24.931722: Pseudo dice [np.float32(0.8169), np.float32(0.6998), np.float32(0.8508)] 
2025-03-16 23:34:24.935228: Epoch time: 41.44 s 
2025-03-16 23:34:24.939245: Yayy! New best EMA pseudo Dice: 0.7797999978065491 
2025-03-16 23:34:25.746579:  
2025-03-16 23:34:25.753263: Epoch 48 
2025-03-16 23:34:25.757283: Current learning rate: 0.00555 
2025-03-16 23:35:07.308599: train_loss -0.6842 
2025-03-16 23:35:07.315703: val_loss -0.6459 
2025-03-16 23:35:07.319292: Pseudo dice [np.float32(0.8132), np.float32(0.7113), np.float32(0.8497)] 
2025-03-16 23:35:07.322884: Epoch time: 41.56 s 
2025-03-16 23:35:07.325928: Yayy! New best EMA pseudo Dice: 0.781000018119812 
2025-03-16 23:35:08.265903:  
2025-03-16 23:35:08.271563: Epoch 49 
2025-03-16 23:35:08.276119: Current learning rate: 0.00546 
2025-03-16 23:35:49.770761: train_loss -0.6904 
2025-03-16 23:35:49.778906: val_loss -0.6348 
2025-03-16 23:35:49.782439: Pseudo dice [np.float32(0.8191), np.float32(0.7108), np.float32(0.8469)] 
2025-03-16 23:35:49.786029: Epoch time: 41.51 s 
2025-03-16 23:35:49.950534: Yayy! New best EMA pseudo Dice: 0.7821000218391418 
2025-03-16 23:35:50.724953:  
2025-03-16 23:35:50.730993: Epoch 50 
2025-03-16 23:35:50.734035: Current learning rate: 0.00536 
2025-03-16 23:36:31.774948: train_loss -0.686 
2025-03-16 23:36:31.781045: val_loss -0.6358 
2025-03-16 23:36:31.784088: Pseudo dice [np.float32(0.8152), np.float32(0.6945), np.float32(0.8477)] 
2025-03-16 23:36:31.788119: Epoch time: 41.05 s 
2025-03-16 23:36:31.791226: Yayy! New best EMA pseudo Dice: 0.7825000286102295 
2025-03-16 23:36:32.601712:  
2025-03-16 23:36:32.607290: Epoch 51 
2025-03-16 23:36:32.609836: Current learning rate: 0.00526 
2025-03-16 23:37:11.937597: train_loss -0.6917 
2025-03-16 23:37:11.944636: val_loss -0.6437 
2025-03-16 23:37:11.947653: Pseudo dice [np.float32(0.817), np.float32(0.6997), np.float32(0.8362)] 
2025-03-16 23:37:11.951166: Epoch time: 39.34 s 
2025-03-16 23:37:11.955182: Yayy! New best EMA pseudo Dice: 0.7825999855995178 
2025-03-16 23:37:12.741712:  
2025-03-16 23:37:12.746758: Epoch 52 
2025-03-16 23:37:12.750267: Current learning rate: 0.00517 
2025-03-16 23:37:51.910063: train_loss -0.691 
2025-03-16 23:37:51.916078: val_loss -0.643 
2025-03-16 23:37:51.920089: Pseudo dice [np.float32(0.8229), np.float32(0.6872), np.float32(0.8535)] 
2025-03-16 23:37:51.923598: Epoch time: 39.17 s 
2025-03-16 23:37:51.927609: Yayy! New best EMA pseudo Dice: 0.7832000255584717 
2025-03-16 23:37:52.710197:  
2025-03-16 23:37:52.715209: Epoch 53 
2025-03-16 23:37:52.718721: Current learning rate: 0.00507 
2025-03-16 23:38:31.314101: train_loss -0.6898 
2025-03-16 23:38:31.321160: val_loss -0.6235 
2025-03-16 23:38:31.324196: Pseudo dice [np.float32(0.8278), np.float32(0.6807), np.float32(0.8356)] 
2025-03-16 23:38:31.328251: Epoch time: 38.61 s 
2025-03-16 23:38:31.940252:  
2025-03-16 23:38:31.946806: Epoch 54 
2025-03-16 23:38:31.949911: Current learning rate: 0.00497 
2025-03-16 23:39:10.949672: train_loss -0.6949 
2025-03-16 23:39:10.956707: val_loss -0.6465 
2025-03-16 23:39:10.960721: Pseudo dice [np.float32(0.8225), np.float32(0.7078), np.float32(0.8491)] 
2025-03-16 23:39:10.963731: Epoch time: 39.01 s 
2025-03-16 23:39:10.967258: Yayy! New best EMA pseudo Dice: 0.7839999794960022 
2025-03-16 23:39:11.761810:  
2025-03-16 23:39:11.767886: Epoch 55 
2025-03-16 23:39:11.770949: Current learning rate: 0.00487 
2025-03-16 23:39:50.668523: train_loss -0.676 
2025-03-16 23:39:50.674132: val_loss -0.6528 
2025-03-16 23:39:50.678685: Pseudo dice [np.float32(0.8258), np.float32(0.732), np.float32(0.8459)] 
2025-03-16 23:39:50.681732: Epoch time: 38.91 s 
2025-03-16 23:39:50.684272: Yayy! New best EMA pseudo Dice: 0.7857000231742859 
2025-03-16 23:39:51.466306:  
2025-03-16 23:39:51.471337: Epoch 56 
2025-03-16 23:39:51.474855: Current learning rate: 0.00478 
2025-03-16 23:40:30.353612: train_loss -0.6952 
2025-03-16 23:40:30.360167: val_loss -0.6255 
2025-03-16 23:40:30.363696: Pseudo dice [np.float32(0.8213), np.float32(0.6603), np.float32(0.8347)] 
2025-03-16 23:40:30.367225: Epoch time: 38.89 s 
2025-03-16 23:40:31.137144:  
2025-03-16 23:40:31.142726: Epoch 57 
2025-03-16 23:40:31.147334: Current learning rate: 0.00468 
2025-03-16 23:41:09.972427: train_loss -0.6899 
2025-03-16 23:41:09.979442: val_loss -0.6252 
2025-03-16 23:41:09.983454: Pseudo dice [np.float32(0.8173), np.float32(0.6726), np.float32(0.8696)] 
2025-03-16 23:41:09.986961: Epoch time: 38.84 s 
2025-03-16 23:41:10.585514:  
2025-03-16 23:41:10.591579: Epoch 58 
2025-03-16 23:41:10.594652: Current learning rate: 0.00458 
2025-03-16 23:41:49.293864: train_loss -0.7005 
2025-03-16 23:41:49.299940: val_loss -0.6431 
2025-03-16 23:41:49.303953: Pseudo dice [np.float32(0.8205), np.float32(0.7243), np.float32(0.8667)] 
2025-03-16 23:41:49.307469: Epoch time: 38.71 s 
2025-03-16 23:41:49.309975: Yayy! New best EMA pseudo Dice: 0.7864999771118164 
2025-03-16 23:41:50.111959:  
2025-03-16 23:41:50.118006: Epoch 59 
2025-03-16 23:41:50.121051: Current learning rate: 0.00448 
2025-03-16 23:42:29.056792: train_loss -0.6914 
2025-03-16 23:42:29.062968: val_loss -0.637 
2025-03-16 23:42:29.067511: Pseudo dice [np.float32(0.8295), np.float32(0.6714), np.float32(0.8415)] 
2025-03-16 23:42:29.071026: Epoch time: 38.95 s 
2025-03-16 23:42:29.682702:  
2025-03-16 23:42:29.686716: Epoch 60 
2025-03-16 23:42:29.690222: Current learning rate: 0.00438 
2025-03-16 23:43:08.734283: train_loss -0.7007 
2025-03-16 23:43:08.741347: val_loss -0.6544 
2025-03-16 23:43:08.744883: Pseudo dice [np.float32(0.8202), np.float32(0.7152), np.float32(0.8551)] 
2025-03-16 23:43:08.748395: Epoch time: 39.05 s 
2025-03-16 23:43:08.750406: Yayy! New best EMA pseudo Dice: 0.7870000004768372 
2025-03-16 23:43:09.539190:  
2025-03-16 23:43:09.544644: Epoch 61 
2025-03-16 23:43:09.548457: Current learning rate: 0.00429 
2025-03-16 23:43:48.427352: train_loss -0.6986 
2025-03-16 23:43:48.434411: val_loss -0.6671 
2025-03-16 23:43:48.437149: Pseudo dice [np.float32(0.8084), np.float32(0.7362), np.float32(0.8438)] 
2025-03-16 23:43:48.443186: Epoch time: 38.89 s 
2025-03-16 23:43:48.447224: Yayy! New best EMA pseudo Dice: 0.7878999710083008 
2025-03-16 23:43:49.250630:  
2025-03-16 23:43:49.255747: Epoch 62 
2025-03-16 23:43:49.259341: Current learning rate: 0.00419 
2025-03-16 23:44:28.219959: train_loss -0.6983 
2025-03-16 23:44:28.227062: val_loss -0.6394 
2025-03-16 23:44:28.231136: Pseudo dice [np.float32(0.8178), np.float32(0.7231), np.float32(0.8545)] 
2025-03-16 23:44:28.234261: Epoch time: 38.97 s 
2025-03-16 23:44:28.237811: Yayy! New best EMA pseudo Dice: 0.7889999747276306 
2025-03-16 23:44:29.035043:  
2025-03-16 23:44:29.041565: Epoch 63 
2025-03-16 23:44:29.046077: Current learning rate: 0.00409 
2025-03-16 23:45:08.177157: train_loss -0.7046 
2025-03-16 23:45:08.185433: val_loss -0.6531 
2025-03-16 23:45:08.191608: Pseudo dice [np.float32(0.8314), np.float32(0.6877), np.float32(0.87)] 
2025-03-16 23:45:08.196345: Epoch time: 39.14 s 
2025-03-16 23:45:08.201010: Yayy! New best EMA pseudo Dice: 0.7896999716758728 
2025-03-16 23:45:09.036836:  
2025-03-16 23:45:09.043923: Epoch 64 
2025-03-16 23:45:09.048012: Current learning rate: 0.00399 
2025-03-16 23:45:47.915482: train_loss -0.6953 
2025-03-16 23:45:47.925186: val_loss -0.6308 
2025-03-16 23:45:47.929265: Pseudo dice [np.float32(0.8107), np.float32(0.708), np.float32(0.8556)] 
2025-03-16 23:45:47.932840: Epoch time: 38.88 s 
2025-03-16 23:45:47.936405: Yayy! New best EMA pseudo Dice: 0.789900004863739 
2025-03-16 23:45:48.887807:  
2025-03-16 23:45:48.893094: Epoch 65 
2025-03-16 23:45:48.898150: Current learning rate: 0.00389 
2025-03-16 23:46:28.062835: train_loss -0.7001 
2025-03-16 23:46:28.069955: val_loss -0.6181 
2025-03-16 23:46:28.073096: Pseudo dice [np.float32(0.8224), np.float32(0.6494), np.float32(0.8679)] 
2025-03-16 23:46:28.078187: Epoch time: 39.18 s 
2025-03-16 23:46:28.683594:  
2025-03-16 23:46:28.690210: Epoch 66 
2025-03-16 23:46:28.695270: Current learning rate: 0.00379 
2025-03-16 23:47:07.482865: train_loss -0.7002 
2025-03-16 23:47:07.490457: val_loss -0.6504 
2025-03-16 23:47:07.494035: Pseudo dice [np.float32(0.8261), np.float32(0.7144), np.float32(0.8673)] 
2025-03-16 23:47:07.498083: Epoch time: 38.8 s 
2025-03-16 23:47:07.502124: Yayy! New best EMA pseudo Dice: 0.7903000116348267 
2025-03-16 23:47:08.331888:  
2025-03-16 23:47:08.337952: Epoch 67 
2025-03-16 23:47:08.342529: Current learning rate: 0.00369 
2025-03-16 23:47:47.470608: train_loss -0.6996 
2025-03-16 23:47:47.478177: val_loss -0.6637 
2025-03-16 23:47:47.481734: Pseudo dice [np.float32(0.8327), np.float32(0.7105), np.float32(0.853)] 
2025-03-16 23:47:47.485755: Epoch time: 39.14 s 
2025-03-16 23:47:47.489772: Yayy! New best EMA pseudo Dice: 0.791100025177002 
2025-03-16 23:47:48.286294:  
2025-03-16 23:47:48.291867: Epoch 68 
2025-03-16 23:47:48.295919: Current learning rate: 0.00359 
2025-03-16 23:48:27.455350: train_loss -0.7024 
2025-03-16 23:48:27.462872: val_loss -0.6637 
2025-03-16 23:48:27.469398: Pseudo dice [np.float32(0.8366), np.float32(0.7058), np.float32(0.8567)] 
2025-03-16 23:48:27.474414: Epoch time: 39.17 s 
2025-03-16 23:48:27.479428: Yayy! New best EMA pseudo Dice: 0.7919999957084656 
2025-03-16 23:48:28.348136:  
2025-03-16 23:48:28.354209: Epoch 69 
2025-03-16 23:48:28.358277: Current learning rate: 0.00349 
2025-03-16 23:49:07.152608: train_loss -0.7054 
2025-03-16 23:49:07.159132: val_loss -0.6207 
2025-03-16 23:49:07.164148: Pseudo dice [np.float32(0.8114), np.float32(0.6874), np.float32(0.8639)] 
2025-03-16 23:49:07.168663: Epoch time: 38.81 s 
2025-03-16 23:49:07.872576:  
2025-03-16 23:49:07.879196: Epoch 70 
2025-03-16 23:49:07.883735: Current learning rate: 0.00338 
2025-03-16 23:49:46.875062: train_loss -0.7128 
2025-03-16 23:49:46.882582: val_loss -0.6561 
2025-03-16 23:49:46.886094: Pseudo dice [np.float32(0.8286), np.float32(0.7295), np.float32(0.8519)] 
2025-03-16 23:49:46.890104: Epoch time: 39.0 s 
2025-03-16 23:49:46.893616: Yayy! New best EMA pseudo Dice: 0.7926999926567078 
2025-03-16 23:49:47.719894:  
2025-03-16 23:49:47.725409: Epoch 71 
2025-03-16 23:49:47.729920: Current learning rate: 0.00328 
2025-03-16 23:50:26.394799: train_loss -0.7132 
2025-03-16 23:50:26.399862: val_loss -0.6216 
2025-03-16 23:50:26.404403: Pseudo dice [np.float32(0.8265), np.float32(0.6838), np.float32(0.8637)] 
2025-03-16 23:50:26.407955: Epoch time: 38.68 s 
2025-03-16 23:50:27.094812:  
2025-03-16 23:50:27.102804: Epoch 72 
2025-03-16 23:50:27.107413: Current learning rate: 0.00318 
2025-03-16 23:51:06.494307: train_loss -0.7126 
2025-03-16 23:51:06.501925: val_loss -0.6447 
2025-03-16 23:51:06.505450: Pseudo dice [np.float32(0.8057), np.float32(0.7285), np.float32(0.8647)] 
2025-03-16 23:51:06.509985: Epoch time: 39.4 s 
2025-03-16 23:51:06.515516: Yayy! New best EMA pseudo Dice: 0.7932999730110168 
2025-03-16 23:51:07.529155:  
2025-03-16 23:51:07.535736: Epoch 73 
2025-03-16 23:51:07.539821: Current learning rate: 0.00308 
2025-03-16 23:51:46.962329: train_loss -0.7131 
2025-03-16 23:51:46.970434: val_loss -0.6561 
2025-03-16 23:51:46.974972: Pseudo dice [np.float32(0.8298), np.float32(0.7366), np.float32(0.8642)] 
2025-03-16 23:51:46.979033: Epoch time: 39.43 s 
2025-03-16 23:51:46.983074: Yayy! New best EMA pseudo Dice: 0.7950000166893005 
2025-03-16 23:51:47.928939:  
2025-03-16 23:51:47.935960: Epoch 74 
2025-03-16 23:51:47.941006: Current learning rate: 0.00297 
2025-03-16 23:52:27.449142: train_loss -0.6969 
2025-03-16 23:52:27.456161: val_loss -0.6482 
2025-03-16 23:52:27.461177: Pseudo dice [np.float32(0.8251), np.float32(0.7293), np.float32(0.8493)] 
2025-03-16 23:52:27.466695: Epoch time: 39.52 s 
2025-03-16 23:52:27.472712: Yayy! New best EMA pseudo Dice: 0.7955999970436096 
2025-03-16 23:52:28.398003:  
2025-03-16 23:52:28.404041: Epoch 75 
2025-03-16 23:52:28.408094: Current learning rate: 0.00287 
2025-03-16 23:53:07.493918: train_loss -0.7039 
2025-03-16 23:53:07.501495: val_loss -0.678 
2025-03-16 23:53:07.506120: Pseudo dice [np.float32(0.846), np.float32(0.7021), np.float32(0.8692)] 
2025-03-16 23:53:07.509268: Epoch time: 39.1 s 
2025-03-16 23:53:07.512779: Yayy! New best EMA pseudo Dice: 0.7965999841690063 
2025-03-16 23:53:08.314981:  
2025-03-16 23:53:08.322107: Epoch 76 
2025-03-16 23:53:08.325158: Current learning rate: 0.00277 
2025-03-16 23:53:46.867014: train_loss -0.7177 
2025-03-16 23:53:46.873060: val_loss -0.6732 
2025-03-16 23:53:46.877585: Pseudo dice [np.float32(0.848), np.float32(0.7348), np.float32(0.8597)] 
2025-03-16 23:53:46.882113: Epoch time: 38.55 s 
2025-03-16 23:53:46.885622: Yayy! New best EMA pseudo Dice: 0.7983999848365784 
2025-03-16 23:53:47.685242:  
2025-03-16 23:53:47.690819: Epoch 77 
2025-03-16 23:53:47.695368: Current learning rate: 0.00266 
2025-03-16 23:54:26.190564: train_loss -0.7198 
2025-03-16 23:54:26.197755: val_loss -0.6839 
2025-03-16 23:54:26.201812: Pseudo dice [np.float32(0.8487), np.float32(0.7276), np.float32(0.8682)] 
2025-03-16 23:54:26.205363: Epoch time: 38.51 s 
2025-03-16 23:54:26.209476: Yayy! New best EMA pseudo Dice: 0.800000011920929 
2025-03-16 23:54:27.068489:  
2025-03-16 23:54:27.074088: Epoch 78 
2025-03-16 23:54:27.079216: Current learning rate: 0.00256 
2025-03-16 23:55:05.586556: train_loss -0.7057 
2025-03-16 23:55:05.594989: val_loss -0.6838 
2025-03-16 23:55:05.599687: Pseudo dice [np.float32(0.8453), np.float32(0.7455), np.float32(0.8727)] 
2025-03-16 23:55:05.602860: Epoch time: 38.52 s 
2025-03-16 23:55:05.607445: Yayy! New best EMA pseudo Dice: 0.8021000027656555 
2025-03-16 23:55:06.419049:  
2025-03-16 23:55:06.425628: Epoch 79 
2025-03-16 23:55:06.429213: Current learning rate: 0.00245 
2025-03-16 23:55:44.975625: train_loss -0.706 
2025-03-16 23:55:44.982740: val_loss -0.659 
2025-03-16 23:55:44.986773: Pseudo dice [np.float32(0.8382), np.float32(0.7281), np.float32(0.8476)] 
2025-03-16 23:55:44.990311: Epoch time: 38.56 s 
2025-03-16 23:55:44.994844: Yayy! New best EMA pseudo Dice: 0.8023999929428101 
2025-03-16 23:55:45.800359:  
2025-03-16 23:55:45.806948: Epoch 80 
2025-03-16 23:55:45.812040: Current learning rate: 0.00235 
2025-03-16 23:56:24.320695: train_loss -0.7088 
2025-03-16 23:56:24.326830: val_loss -0.6473 
2025-03-16 23:56:24.331409: Pseudo dice [np.float32(0.8333), np.float32(0.7072), np.float32(0.8609)] 
2025-03-16 23:56:24.334965: Epoch time: 38.52 s 
2025-03-16 23:56:25.128361:  
2025-03-16 23:56:25.135435: Epoch 81 
2025-03-16 23:56:25.139988: Current learning rate: 0.00224 
2025-03-16 23:57:03.613572: train_loss -0.7101 
2025-03-16 23:57:03.620144: val_loss -0.6555 
2025-03-16 23:57:03.624259: Pseudo dice [np.float32(0.8339), np.float32(0.7232), np.float32(0.8658)] 
2025-03-16 23:57:03.627769: Epoch time: 38.49 s 
2025-03-16 23:57:03.631777: Yayy! New best EMA pseudo Dice: 0.8026999831199646 
2025-03-16 23:57:04.442791:  
2025-03-16 23:57:04.450011: Epoch 82 
2025-03-16 23:57:04.454097: Current learning rate: 0.00214 
2025-03-16 23:57:42.925315: train_loss -0.7159 
2025-03-16 23:57:42.932916: val_loss -0.6444 
2025-03-16 23:57:42.937477: Pseudo dice [np.float32(0.8424), np.float32(0.7121), np.float32(0.864)] 
2025-03-16 23:57:42.941193: Epoch time: 38.48 s 
2025-03-16 23:57:42.944741: Yayy! New best EMA pseudo Dice: 0.8030999898910522 
2025-03-16 23:57:43.743792:  
2025-03-16 23:57:43.748878: Epoch 83 
2025-03-16 23:57:43.754036: Current learning rate: 0.00203 
2025-03-16 23:58:22.257332: train_loss -0.7192 
2025-03-16 23:58:22.262405: val_loss -0.6678 
2025-03-16 23:58:22.265932: Pseudo dice [np.float32(0.8356), np.float32(0.7), np.float32(0.8527)] 
2025-03-16 23:58:22.269473: Epoch time: 38.51 s 
2025-03-16 23:58:22.859642:  
2025-03-16 23:58:22.865784: Epoch 84 
2025-03-16 23:58:22.869851: Current learning rate: 0.00192 
2025-03-16 23:59:01.429528: train_loss -0.7183 
2025-03-16 23:59:01.437182: val_loss -0.6336 
2025-03-16 23:59:01.441703: Pseudo dice [np.float32(0.8332), np.float32(0.6951), np.float32(0.8474)] 
2025-03-16 23:59:01.445742: Epoch time: 38.57 s 
2025-03-16 23:59:02.038506:  
2025-03-16 23:59:02.044047: Epoch 85 
2025-03-16 23:59:02.047605: Current learning rate: 0.00181 
2025-03-16 23:59:40.480294: train_loss -0.7221 
2025-03-16 23:59:40.486839: val_loss -0.6624 
2025-03-16 23:59:40.491348: Pseudo dice [np.float32(0.8211), np.float32(0.7374), np.float32(0.8597)] 
2025-03-16 23:59:40.494874: Epoch time: 38.44 s 
2025-03-16 23:59:41.081301:  
2025-03-16 23:59:41.087814: Epoch 86 
2025-03-16 23:59:41.091324: Current learning rate: 0.0017 
2025-03-17 00:00:19.564538: train_loss -0.7082 
2025-03-17 00:00:19.571691: val_loss -0.6429 
2025-03-17 00:00:19.576263: Pseudo dice [np.float32(0.8244), np.float32(0.6805), np.float32(0.8692)] 
2025-03-17 00:00:19.580298: Epoch time: 38.48 s 
2025-03-17 00:00:20.179031:  
2025-03-17 00:00:20.186561: Epoch 87 
2025-03-17 00:00:20.192123: Current learning rate: 0.00159 
2025-03-17 00:00:58.755933: train_loss -0.7116 
2025-03-17 00:00:58.763985: val_loss -0.6789 
2025-03-17 00:00:58.767515: Pseudo dice [np.float32(0.8386), np.float32(0.6948), np.float32(0.8652)] 
2025-03-17 00:00:58.771147: Epoch time: 38.58 s 
2025-03-17 00:00:59.368720:  
2025-03-17 00:00:59.375807: Epoch 88 
2025-03-17 00:00:59.380891: Current learning rate: 0.00148 
2025-03-17 00:01:38.029447: train_loss -0.7172 
2025-03-17 00:01:38.037567: val_loss -0.6629 
2025-03-17 00:01:38.042175: Pseudo dice [np.float32(0.8427), np.float32(0.7168), np.float32(0.8646)] 
2025-03-17 00:01:38.046232: Epoch time: 38.66 s 
2025-03-17 00:01:38.628995:  
2025-03-17 00:01:38.635611: Epoch 89 
2025-03-17 00:01:38.640172: Current learning rate: 0.00137 
2025-03-17 00:02:17.081019: train_loss -0.7197 
2025-03-17 00:02:17.087176: val_loss -0.6671 
2025-03-17 00:02:17.091756: Pseudo dice [np.float32(0.8307), np.float32(0.7454), np.float32(0.8592)] 
2025-03-17 00:02:17.095264: Epoch time: 38.45 s 
2025-03-17 00:02:17.686769:  
2025-03-17 00:02:17.693321: Epoch 90 
2025-03-17 00:02:17.697857: Current learning rate: 0.00126 
2025-03-17 00:02:56.153058: train_loss -0.7206 
2025-03-17 00:02:56.160633: val_loss -0.6583 
2025-03-17 00:02:56.164659: Pseudo dice [np.float32(0.8315), np.float32(0.7306), np.float32(0.8661)] 
2025-03-17 00:02:56.168738: Epoch time: 38.47 s 
2025-03-17 00:02:56.172338: Yayy! New best EMA pseudo Dice: 0.8030999898910522 
2025-03-17 00:02:56.934366:  
2025-03-17 00:02:56.940380: Epoch 91 
2025-03-17 00:02:56.944389: Current learning rate: 0.00115 
2025-03-17 00:03:35.255158: train_loss -0.722 
2025-03-17 00:03:35.261173: val_loss -0.6489 
2025-03-17 00:03:35.265181: Pseudo dice [np.float32(0.8338), np.float32(0.7409), np.float32(0.866)] 
2025-03-17 00:03:35.270195: Epoch time: 38.32 s 
2025-03-17 00:03:35.273703: Yayy! New best EMA pseudo Dice: 0.8041999936103821 
2025-03-17 00:03:36.026902:  
2025-03-17 00:03:36.032972: Epoch 92 
2025-03-17 00:03:36.036538: Current learning rate: 0.00103 
2025-03-17 00:04:14.383835: train_loss -0.7231 
2025-03-17 00:04:14.391390: val_loss -0.6923 
2025-03-17 00:04:14.395923: Pseudo dice [np.float32(0.8466), np.float32(0.7028), np.float32(0.8714)] 
2025-03-17 00:04:14.400005: Epoch time: 38.36 s 
2025-03-17 00:04:14.403510: Yayy! New best EMA pseudo Dice: 0.8044000267982483 
2025-03-17 00:04:15.193793:  
2025-03-17 00:04:15.199439: Epoch 93 
2025-03-17 00:04:15.201984: Current learning rate: 0.00091 
2025-03-17 00:04:59.112092: train_loss -0.7284 
2025-03-17 00:04:59.119859: val_loss -0.6701 
2025-03-17 00:04:59.124405: Pseudo dice [np.float32(0.8296), np.float32(0.7684), np.float32(0.8557)] 
2025-03-17 00:04:59.129505: Epoch time: 43.92 s 
2025-03-17 00:04:59.134018: Yayy! New best EMA pseudo Dice: 0.8058000206947327 
2025-03-17 00:04:59.902486:  
2025-03-17 00:04:59.909070: Epoch 94 
2025-03-17 00:04:59.913165: Current learning rate: 0.00079 
2025-03-17 00:05:39.412705: train_loss -0.7225 
2025-03-17 00:05:39.419827: val_loss -0.6397 
2025-03-17 00:05:39.424464: Pseudo dice [np.float32(0.8332), np.float32(0.7154), np.float32(0.8659)] 
2025-03-17 00:05:39.428540: Epoch time: 39.51 s 
2025-03-17 00:05:40.022680:  
2025-03-17 00:05:40.028695: Epoch 95 
2025-03-17 00:05:40.032736: Current learning rate: 0.00067 
2025-03-17 00:06:19.385290: train_loss -0.7343 
2025-03-17 00:06:19.392339: val_loss -0.6536 
2025-03-17 00:06:19.396496: Pseudo dice [np.float32(0.8248), np.float32(0.7432), np.float32(0.848)] 
2025-03-17 00:06:19.401032: Epoch time: 39.36 s 
2025-03-17 00:06:20.001260:  
2025-03-17 00:06:20.007787: Epoch 96 
2025-03-17 00:06:20.012302: Current learning rate: 0.00055 
2025-03-17 00:06:59.649561: train_loss -0.7244 
2025-03-17 00:06:59.656116: val_loss -0.6326 
2025-03-17 00:06:59.660132: Pseudo dice [np.float32(0.8251), np.float32(0.6847), np.float32(0.862)] 
2025-03-17 00:06:59.665143: Epoch time: 39.65 s 
2025-03-17 00:07:00.231689:  
2025-03-17 00:07:00.238763: Epoch 97 
2025-03-17 00:07:00.242770: Current learning rate: 0.00043 
2025-03-17 00:07:38.992721: train_loss -0.7303 
2025-03-17 00:07:38.999766: val_loss -0.6755 
2025-03-17 00:07:39.003894: Pseudo dice [np.float32(0.8417), np.float32(0.7173), np.float32(0.8502)] 
2025-03-17 00:07:39.008486: Epoch time: 38.76 s 
2025-03-17 00:07:39.575405:  
2025-03-17 00:07:39.581477: Epoch 98 
2025-03-17 00:07:39.586033: Current learning rate: 0.0003 
2025-03-17 00:08:18.403540: train_loss -0.7248 
2025-03-17 00:08:18.410574: val_loss -0.6631 
2025-03-17 00:08:18.416460: Pseudo dice [np.float32(0.8348), np.float32(0.7042), np.float32(0.8774)] 
2025-03-17 00:08:18.422471: Epoch time: 38.83 s 
2025-03-17 00:08:18.990287:  
2025-03-17 00:08:18.997340: Epoch 99 
2025-03-17 00:08:19.002537: Current learning rate: 0.00016 
2025-03-17 00:08:57.635668: train_loss -0.7285 
2025-03-17 00:08:57.642761: val_loss -0.6617 
2025-03-17 00:08:57.648333: Pseudo dice [np.float32(0.8369), np.float32(0.7488), np.float32(0.8609)] 
2025-03-17 00:08:57.654385: Epoch time: 38.65 s 
2025-03-17 00:08:58.419352: Training done. 
2025-03-17 00:08:58.465812: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-17 00:08:58.475321: The split file contains 5 splits. 
2025-03-17 00:08:58.482833: Desired fold for training: 0 
2025-03-17 00:08:58.489960: This split has 387 training and 97 validation cases. 
2025-03-17 00:08:58.498470: predicting BRATS_010 
2025-03-17 00:08:58.508991: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2025-03-17 00:09:00.625363: predicting BRATS_011 
2025-03-17 00:09:00.640380: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2025-03-17 00:09:01.948102: predicting BRATS_012 
2025-03-17 00:09:01.960612: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-17 00:09:03.310345: predicting BRATS_018 
2025-03-17 00:09:03.322850: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2025-03-17 00:09:04.634323: predicting BRATS_020 
2025-03-17 00:09:04.648839: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2025-03-17 00:09:05.957349: predicting BRATS_028 
2025-03-17 00:09:05.971859: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-03-17 00:09:07.274611: predicting BRATS_029 
2025-03-17 00:09:07.287120: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-03-17 00:09:08.598422: predicting BRATS_032 
2025-03-17 00:09:08.612922: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2025-03-17 00:09:09.918717: predicting BRATS_034 
2025-03-17 00:09:09.932222: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2025-03-17 00:09:11.283708: predicting BRATS_041 
2025-03-17 00:09:11.298721: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2025-03-17 00:09:12.613181: predicting BRATS_042 
2025-03-17 00:09:12.628188: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2025-03-17 00:09:13.936741: predicting BRATS_047 
2025-03-17 00:09:13.953259: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-17 00:09:15.265252: predicting BRATS_049 
2025-03-17 00:09:15.279266: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-17 00:09:16.589237: predicting BRATS_053 
2025-03-17 00:09:16.603747: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-17 00:09:17.941148: predicting BRATS_056 
2025-03-17 00:09:17.954663: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-17 00:09:19.259255: predicting BRATS_057 
2025-03-17 00:09:19.273759: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-17 00:09:20.579404: predicting BRATS_067 
2025-03-17 00:09:20.591918: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-17 00:09:21.898326: predicting BRATS_069 
2025-03-17 00:09:21.912902: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-17 00:09:23.221542: predicting BRATS_085 
2025-03-17 00:09:23.236622: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2025-03-17 00:09:23.910917: predicting BRATS_086 
2025-03-17 00:09:23.923938: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2025-03-17 00:09:25.233767: predicting BRATS_088 
2025-03-17 00:09:25.248773: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2025-03-17 00:09:26.555016: predicting BRATS_091 
2025-03-17 00:09:26.570026: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-03-17 00:09:27.913111: predicting BRATS_098 
2025-03-17 00:09:27.929625: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2025-03-17 00:09:29.270989: predicting BRATS_100 
2025-03-17 00:09:29.284394: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-17 00:09:29.971992: predicting BRATS_101 
2025-03-17 00:09:29.987472: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-17 00:09:30.671194: predicting BRATS_102 
2025-03-17 00:09:30.686467: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2025-03-17 00:09:31.993280: predicting BRATS_104 
2025-03-17 00:09:32.007789: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2025-03-17 00:09:33.330513: predicting BRATS_111 
2025-03-17 00:09:33.344023: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2025-03-17 00:09:34.683950: predicting BRATS_116 
2025-03-17 00:09:34.698456: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2025-03-17 00:09:36.107609: predicting BRATS_135 
2025-03-17 00:09:36.122346: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-03-17 00:09:37.495563: predicting BRATS_136 
2025-03-17 00:09:37.510581: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-03-17 00:09:38.815649: predicting BRATS_138 
2025-03-17 00:09:38.830659: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2025-03-17 00:09:40.139764: predicting BRATS_145 
2025-03-17 00:09:40.155294: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2025-03-17 00:09:41.459764: predicting BRATS_149 
2025-03-17 00:09:41.475279: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2025-03-17 00:09:42.785267: predicting BRATS_155 
2025-03-17 00:09:42.800273: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-17 00:09:44.113844: predicting BRATS_157 
2025-03-17 00:09:44.128472: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-17 00:09:45.433432: predicting BRATS_158 
2025-03-17 00:09:45.450444: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-17 00:09:46.759210: predicting BRATS_159 
2025-03-17 00:09:46.774224: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-17 00:09:48.076152: predicting BRATS_163 
2025-03-17 00:09:48.093173: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-03-17 00:09:49.398520: predicting BRATS_164 
2025-03-17 00:09:49.414533: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2025-03-17 00:09:50.719751: predicting BRATS_169 
2025-03-17 00:09:50.734266: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2025-03-17 00:09:52.041000: predicting BRATS_176 
2025-03-17 00:09:52.056563: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-03-17 00:09:53.363057: predicting BRATS_181 
2025-03-17 00:09:53.379568: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2025-03-17 00:09:54.687465: predicting BRATS_183 
2025-03-17 00:09:54.703484: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-17 00:09:56.013239: predicting BRATS_184 
2025-03-17 00:09:56.029255: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-17 00:09:57.339738: predicting BRATS_187 
2025-03-17 00:09:57.355756: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-17 00:09:58.663522: predicting BRATS_192 
2025-03-17 00:09:58.678568: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2025-03-17 00:09:59.983234: predicting BRATS_198 
2025-03-17 00:09:59.996740: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-03-17 00:10:01.339272: predicting BRATS_207 
2025-03-17 00:10:01.355291: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-17 00:10:02.662792: predicting BRATS_208 
2025-03-17 00:10:02.676303: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-17 00:10:03.986906: predicting BRATS_218 
2025-03-17 00:10:04.013437: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-03-17 00:10:05.335351: predicting BRATS_220 
2025-03-17 00:10:05.360365: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2025-03-17 00:10:06.666909: predicting BRATS_224 
2025-03-17 00:10:06.689925: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2025-03-17 00:10:07.999600: predicting BRATS_230 
2025-03-17 00:10:08.025121: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2025-03-17 00:10:09.333083: predicting BRATS_271 
2025-03-17 00:10:09.355607: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2025-03-17 00:10:10.663056: predicting BRATS_282 
2025-03-17 00:10:10.689070: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2025-03-17 00:10:11.995186: predicting BRATS_284 
2025-03-17 00:10:12.020734: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2025-03-17 00:10:13.321405: predicting BRATS_287 
2025-03-17 00:10:13.344436: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-17 00:10:14.650041: predicting BRATS_290 
2025-03-17 00:10:14.678568: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2025-03-17 00:10:15.987680: predicting BRATS_291 
2025-03-17 00:10:16.009700: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-03-17 00:10:17.345040: predicting BRATS_292 
2025-03-17 00:10:17.371060: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2025-03-17 00:10:18.672538: predicting BRATS_293 
2025-03-17 00:10:18.699945: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2025-03-17 00:10:20.009695: predicting BRATS_300 
2025-03-17 00:10:20.037218: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2025-03-17 00:10:21.343930: predicting BRATS_305 
2025-03-17 00:10:21.369953: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2025-03-17 00:10:22.677184: predicting BRATS_311 
2025-03-17 00:10:22.703704: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2025-03-17 00:10:24.010422: predicting BRATS_314 
2025-03-17 00:10:24.041569: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2025-03-17 00:10:25.356067: predicting BRATS_321 
2025-03-17 00:10:25.390593: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-03-17 00:10:26.701313: predicting BRATS_328 
2025-03-17 00:10:26.731844: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2025-03-17 00:10:27.408009: predicting BRATS_329 
2025-03-17 00:10:27.433536: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2025-03-17 00:10:28.739580: predicting BRATS_335 
2025-03-17 00:10:28.765611: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2025-03-17 00:10:30.072284: predicting BRATS_343 
2025-03-17 00:10:30.098806: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2025-03-17 00:10:31.406499: predicting BRATS_350 
2025-03-17 00:10:31.434017: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2025-03-17 00:10:32.110008: predicting BRATS_351 
2025-03-17 00:10:32.135523: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2025-03-17 00:10:32.805043: predicting BRATS_356 
2025-03-17 00:10:32.826065: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2025-03-17 00:10:33.508762: predicting BRATS_366 
2025-03-17 00:10:33.534282: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2025-03-17 00:10:34.838858: predicting BRATS_367 
2025-03-17 00:10:34.863883: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2025-03-17 00:10:36.191833: predicting BRATS_374 
2025-03-17 00:10:36.220372: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2025-03-17 00:10:37.525198: predicting BRATS_376 
2025-03-17 00:10:37.553215: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2025-03-17 00:10:38.858742: predicting BRATS_377 
2025-03-17 00:10:38.886262: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2025-03-17 00:10:40.195462: predicting BRATS_378 
2025-03-17 00:10:40.223482: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2025-03-17 00:10:41.527988: predicting BRATS_379 
2025-03-17 00:10:41.557513: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2025-03-17 00:10:42.875609: predicting BRATS_384 
2025-03-17 00:10:42.903627: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2025-03-17 00:10:44.257171: predicting BRATS_386 
2025-03-17 00:10:44.285424: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-03-17 00:10:45.595819: predicting BRATS_394 
2025-03-17 00:10:45.623839: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-17 00:10:46.928009: predicting BRATS_398 
2025-03-17 00:10:46.952615: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2025-03-17 00:10:48.263740: predicting BRATS_400 
2025-03-17 00:10:48.293803: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2025-03-17 00:10:49.618529: predicting BRATS_432 
2025-03-17 00:10:49.648062: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2025-03-17 00:10:50.953361: predicting BRATS_437 
2025-03-17 00:10:50.976884: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-17 00:10:52.287559: predicting BRATS_445 
2025-03-17 00:10:52.311573: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2025-03-17 00:10:53.626459: predicting BRATS_446 
2025-03-17 00:10:53.653476: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-03-17 00:10:54.988252: predicting BRATS_450 
2025-03-17 00:10:55.017634: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2025-03-17 00:10:56.318635: predicting BRATS_452 
2025-03-17 00:10:56.344546: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2025-03-17 00:10:57.656810: predicting BRATS_460 
2025-03-17 00:10:57.685837: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2025-03-17 00:10:59.002263: predicting BRATS_470 
2025-03-17 00:10:59.027804: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-03-17 00:11:00.338086: predicting BRATS_472 
2025-03-17 00:11:00.367612: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2025-03-17 00:11:01.672686: predicting BRATS_473 
2025-03-17 00:11:01.700219: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2025-03-17 00:11:02.376029: predicting BRATS_482 
2025-03-17 00:11:02.403046: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2025-03-17 00:11:10.864886: Validation complete 
2025-03-17 00:11:10.871398: Mean Validation Dice:  0.7312848525938186 
