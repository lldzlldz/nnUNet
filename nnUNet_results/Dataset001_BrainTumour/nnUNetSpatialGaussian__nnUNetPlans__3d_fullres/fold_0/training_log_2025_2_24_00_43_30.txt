
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-24 00:43:30.346795: do_dummy_2d_data_aug: False 
2025-02-24 00:43:30.353801: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-02-24 00:43:30.365801: The split file contains 5 splits. 
2025-02-24 00:43:30.370310: Desired fold for training: 0 
2025-02-24 00:43:30.374310: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2025-02-24 00:44:04.209989: unpacking dataset... 
2025-02-24 00:44:17.362977: unpacking done... 
2025-02-24 00:44:21.982276:  
2025-02-24 00:44:21.987286: Epoch 0 
2025-02-24 00:44:21.991299: Current learning rate: 0.01 
2025-02-24 00:45:05.819019: train_loss -0.2948 
2025-02-24 00:45:05.825037: val_loss -0.4427 
2025-02-24 00:45:05.830055: Pseudo dice [np.float32(0.6458), np.float32(0.5629), np.float32(0.7806)] 
2025-02-24 00:45:05.835577: Epoch time: 43.84 s 
2025-02-24 00:45:05.841599: Yayy! New best EMA pseudo Dice: 0.663100004196167 
2025-02-24 00:45:06.442303:  
2025-02-24 00:45:06.448365: Epoch 1 
2025-02-24 00:45:06.451427: Current learning rate: 0.00996 
2025-02-24 00:45:46.190255: train_loss -0.4649 
2025-02-24 00:45:46.197288: val_loss -0.4744 
2025-02-24 00:45:46.200795: Pseudo dice [np.float32(0.663), np.float32(0.5392), np.float32(0.783)] 
2025-02-24 00:45:46.204804: Epoch time: 39.75 s 
2025-02-24 00:45:46.703672:  
2025-02-24 00:45:46.709255: Epoch 2 
2025-02-24 00:45:46.713838: Current learning rate: 0.00993 
2025-02-24 00:46:26.425388: train_loss -0.5225 
2025-02-24 00:46:26.431448: val_loss -0.4898 
2025-02-24 00:46:26.436025: Pseudo dice [np.float32(0.7323), np.float32(0.5564), np.float32(0.7855)] 
2025-02-24 00:46:26.439549: Epoch time: 39.72 s 
2025-02-24 00:46:26.443603: Yayy! New best EMA pseudo Dice: 0.6657999753952026 
2025-02-24 00:46:27.115705:  
2025-02-24 00:46:27.120718: Epoch 3 
2025-02-24 00:46:27.124234: Current learning rate: 0.00989 
2025-02-24 00:47:06.905092: train_loss -0.5568 
2025-02-24 00:47:06.910815: val_loss -0.5174 
2025-02-24 00:47:06.914349: Pseudo dice [np.float32(0.7494), np.float32(0.6102), np.float32(0.7916)] 
2025-02-24 00:47:06.918435: Epoch time: 39.79 s 
2025-02-24 00:47:06.922950: Yayy! New best EMA pseudo Dice: 0.6708999872207642 
2025-02-24 00:47:07.582696:  
2025-02-24 00:47:07.588792: Epoch 4 
2025-02-24 00:47:07.591820: Current learning rate: 0.00986 
2025-02-24 00:47:47.323162: train_loss -0.5776 
2025-02-24 00:47:47.329845: val_loss -0.555 
2025-02-24 00:47:47.335419: Pseudo dice [np.float32(0.7588), np.float32(0.6416), np.float32(0.8033)] 
2025-02-24 00:47:47.340474: Epoch time: 39.74 s 
2025-02-24 00:47:47.345582: Yayy! New best EMA pseudo Dice: 0.677299976348877 
2025-02-24 00:47:48.139800:  
2025-02-24 00:47:48.145842: Epoch 5 
2025-02-24 00:47:48.149367: Current learning rate: 0.00982 
2025-02-24 00:48:28.099269: train_loss -0.6033 
2025-02-24 00:48:28.106876: val_loss -0.5608 
2025-02-24 00:48:28.113560: Pseudo dice [np.float32(0.7787), np.float32(0.6422), np.float32(0.8215)] 
2025-02-24 00:48:28.118711: Epoch time: 39.96 s 
2025-02-24 00:48:28.123805: Yayy! New best EMA pseudo Dice: 0.6843000054359436 
2025-02-24 00:48:28.778339:  
2025-02-24 00:48:28.783983: Epoch 6 
2025-02-24 00:48:28.788032: Current learning rate: 0.00978 
2025-02-24 00:49:08.526896: train_loss -0.6187 
2025-02-24 00:49:08.534567: val_loss -0.5453 
2025-02-24 00:49:08.539119: Pseudo dice [np.float32(0.7693), np.float32(0.6105), np.float32(0.8402)] 
2025-02-24 00:49:08.543233: Epoch time: 39.75 s 
2025-02-24 00:49:08.548449: Yayy! New best EMA pseudo Dice: 0.6898999810218811 
2025-02-24 00:49:09.205983:  
2025-02-24 00:49:09.211508: Epoch 7 
2025-02-24 00:49:09.216522: Current learning rate: 0.00975 
2025-02-24 00:49:49.010309: train_loss -0.6283 
2025-02-24 00:49:49.017831: val_loss -0.5652 
2025-02-24 00:49:49.022762: Pseudo dice [np.float32(0.7878), np.float32(0.6297), np.float32(0.8325)] 
2025-02-24 00:49:49.028795: Epoch time: 39.81 s 
2025-02-24 00:49:49.033813: Yayy! New best EMA pseudo Dice: 0.695900022983551 
2025-02-24 00:49:49.707302:  
2025-02-24 00:49:49.712861: Epoch 8 
2025-02-24 00:49:49.717484: Current learning rate: 0.00971 
2025-02-24 00:50:29.458421: train_loss -0.6301 
2025-02-24 00:50:29.465969: val_loss -0.6176 
2025-02-24 00:50:29.471006: Pseudo dice [np.float32(0.8024), np.float32(0.6708), np.float32(0.8228)] 
2025-02-24 00:50:29.477043: Epoch time: 39.75 s 
2025-02-24 00:50:29.483067: Yayy! New best EMA pseudo Dice: 0.7027999758720398 
2025-02-24 00:50:30.163458:  
2025-02-24 00:50:30.169626: Epoch 9 
2025-02-24 00:50:30.172688: Current learning rate: 0.00968 
2025-02-24 00:51:09.939593: train_loss -0.6067 
2025-02-24 00:51:09.946365: val_loss -0.5767 
2025-02-24 00:51:09.951972: Pseudo dice [np.float32(0.7821), np.float32(0.6248), np.float32(0.8109)] 
2025-02-24 00:51:09.957047: Epoch time: 39.78 s 
2025-02-24 00:51:09.960126: Yayy! New best EMA pseudo Dice: 0.7064999938011169 
2025-02-24 00:51:10.611889:  
2025-02-24 00:51:10.616903: Epoch 10 
2025-02-24 00:51:10.621422: Current learning rate: 0.00964 
2025-02-24 00:51:50.381484: train_loss -0.6259 
2025-02-24 00:51:50.388602: val_loss -0.5811 
2025-02-24 00:51:50.392137: Pseudo dice [np.float32(0.8021), np.float32(0.6216), np.float32(0.8187)] 
2025-02-24 00:51:50.396220: Epoch time: 39.77 s 
2025-02-24 00:51:50.399275: Yayy! New best EMA pseudo Dice: 0.7106000185012817 
2025-02-24 00:51:51.058011:  
2025-02-24 00:51:51.064077: Epoch 11 
2025-02-24 00:51:51.067700: Current learning rate: 0.0096 
2025-02-24 00:52:30.852723: train_loss -0.6411 
2025-02-24 00:52:30.858364: val_loss -0.5882 
2025-02-24 00:52:30.862448: Pseudo dice [np.float32(0.793), np.float32(0.6913), np.float32(0.838)] 
2025-02-24 00:52:30.866002: Epoch time: 39.8 s 
2025-02-24 00:52:30.870596: Yayy! New best EMA pseudo Dice: 0.7168999910354614 
2025-02-24 00:52:31.538630:  
2025-02-24 00:52:31.545218: Epoch 12 
2025-02-24 00:52:31.549343: Current learning rate: 0.00957 
2025-02-24 00:53:11.348756: train_loss -0.637 
2025-02-24 00:53:11.354837: val_loss -0.551 
2025-02-24 00:53:11.359378: Pseudo dice [np.float32(0.7882), np.float32(0.6163), np.float32(0.8198)] 
2025-02-24 00:53:11.362931: Epoch time: 39.81 s 
2025-02-24 00:53:11.367471: Yayy! New best EMA pseudo Dice: 0.7193999886512756 
2025-02-24 00:53:12.182541:  
2025-02-24 00:53:12.189635: Epoch 13 
2025-02-24 00:53:12.193645: Current learning rate: 0.00953 
2025-02-24 00:53:51.728476: train_loss -0.6355 
2025-02-24 00:53:51.734991: val_loss -0.5843 
2025-02-24 00:53:51.740003: Pseudo dice [np.float32(0.7892), np.float32(0.6803), np.float32(0.8434)] 
2025-02-24 00:53:51.746019: Epoch time: 39.55 s 
2025-02-24 00:53:51.750572: Yayy! New best EMA pseudo Dice: 0.7245000004768372 
2025-02-24 00:53:52.411860:  
2025-02-24 00:53:52.417966: Epoch 14 
2025-02-24 00:53:52.421527: Current learning rate: 0.00949 
2025-02-24 00:54:31.823910: train_loss -0.6533 
2025-02-24 00:54:31.830548: val_loss -0.6055 
2025-02-24 00:54:31.834618: Pseudo dice [np.float32(0.799), np.float32(0.6783), np.float32(0.8623)] 
2025-02-24 00:54:31.839691: Epoch time: 39.41 s 
2025-02-24 00:54:31.844813: Yayy! New best EMA pseudo Dice: 0.7300999760627747 
2025-02-24 00:54:32.530685:  
2025-02-24 00:54:32.536923: Epoch 15 
2025-02-24 00:54:32.540473: Current learning rate: 0.00946 
2025-02-24 00:55:11.912418: train_loss -0.6564 
2025-02-24 00:55:11.919171: val_loss -0.6065 
2025-02-24 00:55:11.923239: Pseudo dice [np.float32(0.8152), np.float32(0.6376), np.float32(0.8283)] 
2025-02-24 00:55:11.928292: Epoch time: 39.38 s 
2025-02-24 00:55:11.935462: Yayy! New best EMA pseudo Dice: 0.7330999970436096 
2025-02-24 00:55:12.623993:  
2025-02-24 00:55:12.630013: Epoch 16 
2025-02-24 00:55:12.634019: Current learning rate: 0.00942 
2025-02-24 00:55:56.007385: train_loss -0.6499 
2025-02-24 00:55:56.015048: val_loss -0.5817 
2025-02-24 00:55:56.018620: Pseudo dice [np.float32(0.7955), np.float32(0.6191), np.float32(0.8483)] 
2025-02-24 00:55:56.022772: Epoch time: 43.38 s 
2025-02-24 00:55:56.027864: Yayy! New best EMA pseudo Dice: 0.7351999878883362 
2025-02-24 00:55:56.712722:  
2025-02-24 00:55:56.719304: Epoch 17 
2025-02-24 00:55:56.722920: Current learning rate: 0.00939 
2025-02-24 00:56:36.091199: train_loss -0.6619 
2025-02-24 00:56:36.098369: val_loss -0.5856 
2025-02-24 00:56:36.103126: Pseudo dice [np.float32(0.7682), np.float32(0.6427), np.float32(0.8064)] 
2025-02-24 00:56:36.107835: Epoch time: 39.38 s 
2025-02-24 00:56:36.112859: Yayy! New best EMA pseudo Dice: 0.7355999946594238 
2025-02-24 00:56:36.785013:  
2025-02-24 00:56:36.791578: Epoch 18 
2025-02-24 00:56:36.796320: Current learning rate: 0.00935 
2025-02-24 00:57:16.208300: train_loss -0.6601 
2025-02-24 00:57:16.214927: val_loss -0.5974 
2025-02-24 00:57:16.218994: Pseudo dice [np.float32(0.8054), np.float32(0.6765), np.float32(0.8528)] 
2025-02-24 00:57:16.222679: Epoch time: 39.42 s 
2025-02-24 00:57:16.227224: Yayy! New best EMA pseudo Dice: 0.7398999929428101 
2025-02-24 00:57:16.903327:  
2025-02-24 00:57:16.908850: Epoch 19 
2025-02-24 00:57:16.912367: Current learning rate: 0.00931 
2025-02-24 00:57:56.347498: train_loss -0.6649 
2025-02-24 00:57:56.354520: val_loss -0.6173 
2025-02-24 00:57:56.358574: Pseudo dice [np.float32(0.8255), np.float32(0.7069), np.float32(0.8518)] 
2025-02-24 00:57:56.362606: Epoch time: 39.45 s 
2025-02-24 00:57:56.367639: Yayy! New best EMA pseudo Dice: 0.7454000115394592 
2025-02-24 00:57:57.190015:  
2025-02-24 00:57:57.195029: Epoch 20 
2025-02-24 00:57:57.199540: Current learning rate: 0.00928 
2025-02-24 00:58:36.614309: train_loss -0.6743 
2025-02-24 00:58:36.620369: val_loss -0.5988 
2025-02-24 00:58:36.625082: Pseudo dice [np.float32(0.799), np.float32(0.6377), np.float32(0.8402)] 
2025-02-24 00:58:36.628652: Epoch time: 39.42 s 
2025-02-24 00:58:36.631764: Yayy! New best EMA pseudo Dice: 0.7466999888420105 
2025-02-24 00:58:37.320750:  
2025-02-24 00:58:37.326307: Epoch 21 
2025-02-24 00:58:37.330872: Current learning rate: 0.00924 
2025-02-24 00:59:16.750824: train_loss -0.6731 
2025-02-24 00:59:16.756925: val_loss -0.6381 
2025-02-24 00:59:16.761897: Pseudo dice [np.float32(0.8024), np.float32(0.7377), np.float32(0.8464)] 
2025-02-24 00:59:16.766791: Epoch time: 39.43 s 
2025-02-24 00:59:16.771303: Yayy! New best EMA pseudo Dice: 0.7516000270843506 
2025-02-24 00:59:17.441609:  
2025-02-24 00:59:17.448134: Epoch 22 
2025-02-24 00:59:17.451642: Current learning rate: 0.0092 
2025-02-24 00:59:57.238720: train_loss -0.6829 
2025-02-24 00:59:57.245791: val_loss -0.5822 
2025-02-24 00:59:57.251877: Pseudo dice [np.float32(0.7935), np.float32(0.6639), np.float32(0.8388)] 
2025-02-24 00:59:57.259926: Epoch time: 39.8 s 
2025-02-24 00:59:57.264936: Yayy! New best EMA pseudo Dice: 0.753000020980835 
2025-02-24 00:59:57.926893:  
2025-02-24 00:59:57.931933: Epoch 23 
2025-02-24 00:59:57.935964: Current learning rate: 0.00917 
2025-02-24 01:00:37.305136: train_loss -0.6755 
2025-02-24 01:00:37.311907: val_loss -0.5863 
2025-02-24 01:00:37.316922: Pseudo dice [np.float32(0.8086), np.float32(0.6767), np.float32(0.8391)] 
2025-02-24 01:00:37.322940: Epoch time: 39.38 s 
2025-02-24 01:00:37.329456: Yayy! New best EMA pseudo Dice: 0.7552000284194946 
2025-02-24 01:00:37.994964:  
2025-02-24 01:00:38.001037: Epoch 24 
2025-02-24 01:00:38.005181: Current learning rate: 0.00913 
2025-02-24 01:01:17.422872: train_loss -0.6801 
2025-02-24 01:01:17.429559: val_loss -0.6217 
2025-02-24 01:01:17.433616: Pseudo dice [np.float32(0.8094), np.float32(0.7177), np.float32(0.8481)] 
2025-02-24 01:01:17.438709: Epoch time: 39.43 s 
2025-02-24 01:01:17.444829: Yayy! New best EMA pseudo Dice: 0.7588000297546387 
2025-02-24 01:01:18.103954:  
2025-02-24 01:01:18.109974: Epoch 25 
2025-02-24 01:01:18.113982: Current learning rate: 0.0091 
2025-02-24 01:01:57.503410: train_loss -0.6704 
2025-02-24 01:01:57.510487: val_loss -0.6304 
2025-02-24 01:01:57.513544: Pseudo dice [np.float32(0.8355), np.float32(0.6721), np.float32(0.8523)] 
2025-02-24 01:01:57.519076: Epoch time: 39.4 s 
2025-02-24 01:01:57.523595: Yayy! New best EMA pseudo Dice: 0.7616000175476074 
2025-02-24 01:01:58.187393:  
2025-02-24 01:01:58.192910: Epoch 26 
2025-02-24 01:01:58.196422: Current learning rate: 0.00906 
2025-02-24 01:02:37.660813: train_loss -0.6628 
2025-02-24 01:02:37.667981: val_loss -0.6189 
2025-02-24 01:02:37.673568: Pseudo dice [np.float32(0.8245), np.float32(0.6506), np.float32(0.8511)] 
2025-02-24 01:02:37.678584: Epoch time: 39.47 s 
2025-02-24 01:02:37.684605: Yayy! New best EMA pseudo Dice: 0.7630000114440918 
2025-02-24 01:02:38.358920:  
2025-02-24 01:02:38.363930: Epoch 27 
2025-02-24 01:02:38.367441: Current learning rate: 0.00902 
2025-02-24 01:03:17.806321: train_loss -0.689 
2025-02-24 01:03:17.813847: val_loss -0.6009 
2025-02-24 01:03:17.820364: Pseudo dice [np.float32(0.8115), np.float32(0.6557), np.float32(0.8531)] 
2025-02-24 01:03:17.825376: Epoch time: 39.45 s 
2025-02-24 01:03:17.830518: Yayy! New best EMA pseudo Dice: 0.7639999985694885 
2025-02-24 01:03:18.640587:  
2025-02-24 01:03:18.647206: Epoch 28 
2025-02-24 01:03:18.650768: Current learning rate: 0.00899 
2025-02-24 01:03:58.035566: train_loss -0.6841 
2025-02-24 01:03:58.042585: val_loss -0.6348 
2025-02-24 01:03:58.046599: Pseudo dice [np.float32(0.8104), np.float32(0.6664), np.float32(0.8436)] 
2025-02-24 01:03:58.050606: Epoch time: 39.39 s 
2025-02-24 01:03:58.054116: Yayy! New best EMA pseudo Dice: 0.7649999856948853 
2025-02-24 01:03:58.715335:  
2025-02-24 01:03:58.721469: Epoch 29 
2025-02-24 01:03:58.724529: Current learning rate: 0.00895 
2025-02-24 01:04:38.193125: train_loss -0.6848 
2025-02-24 01:04:38.201733: val_loss -0.6341 
2025-02-24 01:04:38.206752: Pseudo dice [np.float32(0.8274), np.float32(0.6936), np.float32(0.8608)] 
2025-02-24 01:04:38.212767: Epoch time: 39.48 s 
2025-02-24 01:04:38.217826: Yayy! New best EMA pseudo Dice: 0.7678999900817871 
2025-02-24 01:04:38.884945:  
2025-02-24 01:04:38.888992: Epoch 30 
2025-02-24 01:04:38.893041: Current learning rate: 0.00891 
2025-02-24 01:05:18.342718: train_loss -0.6972 
2025-02-24 01:05:18.348731: val_loss -0.6484 
2025-02-24 01:05:18.354743: Pseudo dice [np.float32(0.8191), np.float32(0.7442), np.float32(0.8352)] 
2025-02-24 01:05:18.360256: Epoch time: 39.46 s 
2025-02-24 01:05:18.365267: Yayy! New best EMA pseudo Dice: 0.7710000276565552 
2025-02-24 01:05:19.033577:  
2025-02-24 01:05:19.039670: Epoch 31 
2025-02-24 01:05:19.043333: Current learning rate: 0.00888 
2025-02-24 01:05:58.473799: train_loss -0.6867 
2025-02-24 01:05:58.480518: val_loss -0.6279 
2025-02-24 01:05:58.484094: Pseudo dice [np.float32(0.8043), np.float32(0.671), np.float32(0.8684)] 
2025-02-24 01:05:58.487684: Epoch time: 39.44 s 
2025-02-24 01:05:58.491871: Yayy! New best EMA pseudo Dice: 0.7720999717712402 
2025-02-24 01:05:59.159848:  
2025-02-24 01:05:59.166457: Epoch 32 
2025-02-24 01:05:59.170089: Current learning rate: 0.00884 
2025-02-24 01:06:38.595335: train_loss -0.699 
2025-02-24 01:06:38.603364: val_loss -0.6462 
2025-02-24 01:06:38.607873: Pseudo dice [np.float32(0.8092), np.float32(0.7026), np.float32(0.8522)] 
2025-02-24 01:06:38.611892: Epoch time: 39.44 s 
2025-02-24 01:06:38.618409: Yayy! New best EMA pseudo Dice: 0.7735999822616577 
2025-02-24 01:06:39.281652:  
2025-02-24 01:06:39.288301: Epoch 33 
2025-02-24 01:06:39.293919: Current learning rate: 0.0088 
2025-02-24 01:07:18.686380: train_loss -0.6803 
2025-02-24 01:07:18.693009: val_loss -0.6424 
2025-02-24 01:07:18.697044: Pseudo dice [np.float32(0.8069), np.float32(0.7264), np.float32(0.855)] 
2025-02-24 01:07:18.701671: Epoch time: 39.4 s 
2025-02-24 01:07:18.707227: Yayy! New best EMA pseudo Dice: 0.7759000062942505 
2025-02-24 01:07:19.377896:  
2025-02-24 01:07:19.383523: Epoch 34 
2025-02-24 01:07:19.387085: Current learning rate: 0.00877 
2025-02-24 01:07:58.770499: train_loss -0.6877 
2025-02-24 01:07:58.777070: val_loss -0.6002 
2025-02-24 01:07:58.783693: Pseudo dice [np.float32(0.8025), np.float32(0.6658), np.float32(0.8549)] 
2025-02-24 01:07:58.790219: Epoch time: 39.39 s 
2025-02-24 01:07:59.455987:  
2025-02-24 01:07:59.461040: Epoch 35 
2025-02-24 01:07:59.464581: Current learning rate: 0.00873 
2025-02-24 01:08:38.872223: train_loss -0.689 
2025-02-24 01:08:38.878244: val_loss -0.6088 
2025-02-24 01:08:38.882262: Pseudo dice [np.float32(0.8114), np.float32(0.6889), np.float32(0.8291)] 
2025-02-24 01:08:38.886775: Epoch time: 39.42 s 
2025-02-24 01:08:39.405116:  
2025-02-24 01:08:39.411194: Epoch 36 
2025-02-24 01:08:39.415255: Current learning rate: 0.00869 
2025-02-24 01:09:18.834090: train_loss -0.6958 
2025-02-24 01:09:18.840607: val_loss -0.6193 
2025-02-24 01:09:18.845621: Pseudo dice [np.float32(0.8018), np.float32(0.6414), np.float32(0.8592)] 
2025-02-24 01:09:18.850135: Epoch time: 39.43 s 
2025-02-24 01:09:19.374385:  
2025-02-24 01:09:19.379958: Epoch 37 
2025-02-24 01:09:19.384547: Current learning rate: 0.00866 
2025-02-24 01:09:58.756881: train_loss -0.7043 
2025-02-24 01:09:58.764403: val_loss -0.6297 
2025-02-24 01:09:58.769413: Pseudo dice [np.float32(0.8151), np.float32(0.6991), np.float32(0.8672)] 
2025-02-24 01:09:58.775925: Epoch time: 39.38 s 
2025-02-24 01:09:58.783442: Yayy! New best EMA pseudo Dice: 0.7768999934196472 
2025-02-24 01:09:59.444964:  
2025-02-24 01:09:59.450482: Epoch 38 
2025-02-24 01:09:59.456464: Current learning rate: 0.00862 
2025-02-24 01:10:38.869838: train_loss -0.6983 
2025-02-24 01:10:38.877507: val_loss -0.6326 
2025-02-24 01:10:38.881911: Pseudo dice [np.float32(0.8247), np.float32(0.6701), np.float32(0.8676)] 
2025-02-24 01:10:38.885928: Epoch time: 39.43 s 
2025-02-24 01:10:38.890952: Yayy! New best EMA pseudo Dice: 0.777899980545044 
2025-02-24 01:10:39.562273:  
2025-02-24 01:10:39.568423: Epoch 39 
2025-02-24 01:10:39.571937: Current learning rate: 0.00858 
2025-02-24 01:11:18.970424: train_loss -0.7138 
2025-02-24 01:11:18.977592: val_loss -0.6194 
2025-02-24 01:11:18.983163: Pseudo dice [np.float32(0.8202), np.float32(0.7031), np.float32(0.8401)] 
2025-02-24 01:11:18.988335: Epoch time: 39.41 s 
2025-02-24 01:11:18.993919: Yayy! New best EMA pseudo Dice: 0.7789000272750854 
2025-02-24 01:11:19.688684:  
2025-02-24 01:11:19.693727: Epoch 40 
2025-02-24 01:11:19.697648: Current learning rate: 0.00855 
2025-02-24 01:11:59.104877: train_loss -0.7076 
2025-02-24 01:11:59.111001: val_loss -0.6483 
2025-02-24 01:11:59.116069: Pseudo dice [np.float32(0.8322), np.float32(0.7117), np.float32(0.8599)] 
2025-02-24 01:11:59.121220: Epoch time: 39.42 s 
2025-02-24 01:11:59.126807: Yayy! New best EMA pseudo Dice: 0.7810999751091003 
2025-02-24 01:11:59.805473:  
2025-02-24 01:11:59.812027: Epoch 41 
2025-02-24 01:11:59.817042: Current learning rate: 0.00851 
2025-02-24 01:12:39.248314: train_loss -0.7051 
2025-02-24 01:12:39.255830: val_loss -0.6209 
2025-02-24 01:12:39.263345: Pseudo dice [np.float32(0.8176), np.float32(0.6838), np.float32(0.8533)] 
2025-02-24 01:12:39.269361: Epoch time: 39.44 s 
2025-02-24 01:12:39.275372: Yayy! New best EMA pseudo Dice: 0.781499981880188 
2025-02-24 01:12:40.072902:  
2025-02-24 01:12:40.079423: Epoch 42 
2025-02-24 01:12:40.083438: Current learning rate: 0.00847 
2025-02-24 01:13:19.464145: train_loss -0.7031 
2025-02-24 01:13:19.471272: val_loss -0.629 
2025-02-24 01:13:19.476853: Pseudo dice [np.float32(0.7954), np.float32(0.7134), np.float32(0.8271)] 
2025-02-24 01:13:19.481594: Epoch time: 39.39 s 
2025-02-24 01:13:19.981743:  
2025-02-24 01:13:19.987255: Epoch 43 
2025-02-24 01:13:19.990772: Current learning rate: 0.00844 
2025-02-24 01:13:59.402232: train_loss -0.7116 
2025-02-24 01:13:59.408880: val_loss -0.6236 
2025-02-24 01:13:59.414055: Pseudo dice [np.float32(0.8112), np.float32(0.6916), np.float32(0.8487)] 
2025-02-24 01:13:59.420168: Epoch time: 39.42 s 
2025-02-24 01:13:59.915419:  
2025-02-24 01:13:59.921445: Epoch 44 
2025-02-24 01:13:59.924952: Current learning rate: 0.0084 
2025-02-24 01:14:39.342573: train_loss -0.6972 
2025-02-24 01:14:39.349210: val_loss -0.6195 
2025-02-24 01:14:39.352769: Pseudo dice [np.float32(0.8216), np.float32(0.6586), np.float32(0.849)] 
2025-02-24 01:14:39.356837: Epoch time: 39.43 s 
2025-02-24 01:14:39.857148:  
2025-02-24 01:14:39.862710: Epoch 45 
2025-02-24 01:14:39.866260: Current learning rate: 0.00836 
2025-02-24 01:15:19.227160: train_loss -0.6962 
2025-02-24 01:15:19.234177: val_loss -0.633 
2025-02-24 01:15:19.238194: Pseudo dice [np.float32(0.791), np.float32(0.695), np.float32(0.8662)] 
2025-02-24 01:15:19.242204: Epoch time: 39.37 s 
2025-02-24 01:15:19.743942:  
2025-02-24 01:15:19.748955: Epoch 46 
2025-02-24 01:15:19.752466: Current learning rate: 0.00833 
2025-02-24 01:15:59.178459: train_loss -0.7114 
2025-02-24 01:15:59.185472: val_loss -0.629 
2025-02-24 01:15:59.191991: Pseudo dice [np.float32(0.7962), np.float32(0.6743), np.float32(0.858)] 
2025-02-24 01:15:59.198536: Epoch time: 39.44 s 
2025-02-24 01:15:59.697546:  
2025-02-24 01:15:59.703656: Epoch 47 
2025-02-24 01:15:59.707724: Current learning rate: 0.00829 
2025-02-24 01:16:39.137119: train_loss -0.7062 
2025-02-24 01:16:39.143322: val_loss -0.6571 
2025-02-24 01:16:39.148364: Pseudo dice [np.float32(0.8336), np.float32(0.7096), np.float32(0.8626)] 
2025-02-24 01:16:39.153951: Epoch time: 39.44 s 
2025-02-24 01:16:39.159098: Yayy! New best EMA pseudo Dice: 0.7828999757766724 
2025-02-24 01:16:39.794553:  
2025-02-24 01:16:39.800609: Epoch 48 
2025-02-24 01:16:39.803722: Current learning rate: 0.00825 
2025-02-24 01:17:19.255688: train_loss -0.717 
2025-02-24 01:17:19.262712: val_loss -0.6348 
2025-02-24 01:17:19.268235: Pseudo dice [np.float32(0.8113), np.float32(0.7336), np.float32(0.8683)] 
2025-02-24 01:17:19.273294: Epoch time: 39.46 s 
2025-02-24 01:17:19.278309: Yayy! New best EMA pseudo Dice: 0.7850000262260437 
2025-02-24 01:17:19.941389:  
2025-02-24 01:17:19.946401: Epoch 49 
2025-02-24 01:17:19.949915: Current learning rate: 0.00822 
2025-02-24 01:17:59.437415: train_loss -0.7071 
2025-02-24 01:17:59.443026: val_loss -0.6351 
2025-02-24 01:17:59.448051: Pseudo dice [np.float32(0.8215), np.float32(0.69), np.float32(0.8601)] 
2025-02-24 01:17:59.453066: Epoch time: 39.5 s 
2025-02-24 01:17:59.597309: Yayy! New best EMA pseudo Dice: 0.7856000065803528 
2025-02-24 01:18:00.390907:  
2025-02-24 01:18:00.396958: Epoch 50 
2025-02-24 01:18:00.399987: Current learning rate: 0.00818 
2025-02-24 01:18:39.787499: train_loss -0.7079 
2025-02-24 01:18:39.794604: val_loss -0.6505 
2025-02-24 01:18:39.797305: Pseudo dice [np.float32(0.8235), np.float32(0.7333), np.float32(0.861)] 
2025-02-24 01:18:39.801391: Epoch time: 39.4 s 
2025-02-24 01:18:39.805946: Yayy! New best EMA pseudo Dice: 0.7875999808311462 
2025-02-24 01:18:40.467702:  
2025-02-24 01:18:40.473813: Epoch 51 
2025-02-24 01:18:40.477374: Current learning rate: 0.00814 
2025-02-24 01:19:19.884358: train_loss -0.7218 
2025-02-24 01:19:19.889882: val_loss -0.6009 
2025-02-24 01:19:19.894902: Pseudo dice [np.float32(0.8131), np.float32(0.6596), np.float32(0.8527)] 
2025-02-24 01:19:19.898420: Epoch time: 39.42 s 
2025-02-24 01:19:20.403962:  
2025-02-24 01:19:20.409508: Epoch 52 
2025-02-24 01:19:20.413558: Current learning rate: 0.00811 
2025-02-24 01:19:59.790280: train_loss -0.7118 
2025-02-24 01:19:59.797888: val_loss -0.6652 
2025-02-24 01:19:59.802961: Pseudo dice [np.float32(0.7957), np.float32(0.7442), np.float32(0.8643)] 
2025-02-24 01:19:59.809608: Epoch time: 39.39 s 
2025-02-24 01:19:59.814179: Yayy! New best EMA pseudo Dice: 0.7878999710083008 
2025-02-24 01:20:00.484446:  
2025-02-24 01:20:00.490516: Epoch 53 
2025-02-24 01:20:00.493569: Current learning rate: 0.00807 
2025-02-24 01:20:39.947522: train_loss -0.7171 
2025-02-24 01:20:39.955084: val_loss -0.6222 
2025-02-24 01:20:39.959634: Pseudo dice [np.float32(0.8046), np.float32(0.7013), np.float32(0.8614)] 
2025-02-24 01:20:39.965811: Epoch time: 39.46 s 
2025-02-24 01:20:39.970589: Yayy! New best EMA pseudo Dice: 0.7879999876022339 
2025-02-24 01:20:40.632225:  
2025-02-24 01:20:40.638815: Epoch 54 
2025-02-24 01:20:40.642414: Current learning rate: 0.00803 
2025-02-24 01:21:20.095382: train_loss -0.715 
2025-02-24 01:21:20.102915: val_loss -0.6165 
2025-02-24 01:21:20.106427: Pseudo dice [np.float32(0.8034), np.float32(0.7323), np.float32(0.8405)] 
2025-02-24 01:21:20.111450: Epoch time: 39.46 s 
2025-02-24 01:21:20.115468: Yayy! New best EMA pseudo Dice: 0.7883999943733215 
2025-02-24 01:21:20.777740:  
2025-02-24 01:21:20.784331: Epoch 55 
2025-02-24 01:21:20.788421: Current learning rate: 0.008 
2025-02-24 01:22:00.184312: train_loss -0.7179 
2025-02-24 01:22:00.190983: val_loss -0.6547 
2025-02-24 01:22:00.194527: Pseudo dice [np.float32(0.8394), np.float32(0.6804), np.float32(0.8623)] 
2025-02-24 01:22:00.199119: Epoch time: 39.41 s 
2025-02-24 01:22:00.202209: Yayy! New best EMA pseudo Dice: 0.7889999747276306 
2025-02-24 01:22:00.871824:  
2025-02-24 01:22:00.878409: Epoch 56 
2025-02-24 01:22:00.883495: Current learning rate: 0.00796 
2025-02-24 01:22:40.336276: train_loss -0.722 
2025-02-24 01:22:40.343353: val_loss -0.6471 
2025-02-24 01:22:40.348439: Pseudo dice [np.float32(0.8147), np.float32(0.7205), np.float32(0.8507)] 
2025-02-24 01:22:40.352091: Epoch time: 39.46 s 
2025-02-24 01:22:40.356166: Yayy! New best EMA pseudo Dice: 0.7896000146865845 
2025-02-24 01:22:41.028042:  
2025-02-24 01:22:41.033651: Epoch 57 
2025-02-24 01:22:41.037208: Current learning rate: 0.00792 
2025-02-24 01:23:20.498033: train_loss -0.725 
2025-02-24 01:23:20.505561: val_loss -0.6252 
2025-02-24 01:23:20.510575: Pseudo dice [np.float32(0.8208), np.float32(0.6282), np.float32(0.8641)] 
2025-02-24 01:23:20.516135: Epoch time: 39.47 s 
2025-02-24 01:23:21.168200:  
2025-02-24 01:23:21.173715: Epoch 58 
2025-02-24 01:23:21.177225: Current learning rate: 0.00789 
2025-02-24 01:24:00.568505: train_loss -0.723 
2025-02-24 01:24:00.574020: val_loss -0.5958 
2025-02-24 01:24:00.579036: Pseudo dice [np.float32(0.7888), np.float32(0.6509), np.float32(0.8422)] 
2025-02-24 01:24:00.585060: Epoch time: 39.4 s 
2025-02-24 01:24:01.090290:  
2025-02-24 01:24:01.095844: Epoch 59 
2025-02-24 01:24:01.098889: Current learning rate: 0.00785 
2025-02-24 01:24:40.544160: train_loss -0.7206 
2025-02-24 01:24:40.550233: val_loss -0.5875 
2025-02-24 01:24:40.553905: Pseudo dice [np.float32(0.7952), np.float32(0.6174), np.float32(0.8459)] 
2025-02-24 01:24:40.556437: Epoch time: 39.45 s 
2025-02-24 01:24:41.069327:  
2025-02-24 01:24:41.073969: Epoch 60 
2025-02-24 01:24:41.078539: Current learning rate: 0.00781 
2025-02-24 01:25:20.497007: train_loss -0.7255 
2025-02-24 01:25:20.502090: val_loss -0.6394 
2025-02-24 01:25:20.509330: Pseudo dice [np.float32(0.8193), np.float32(0.7199), np.float32(0.865)] 
2025-02-24 01:25:20.514427: Epoch time: 39.43 s 
2025-02-24 01:25:21.024119:  
2025-02-24 01:25:21.030677: Epoch 61 
2025-02-24 01:25:21.033738: Current learning rate: 0.00777 
2025-02-24 01:26:00.445420: train_loss -0.7295 
2025-02-24 01:26:00.452028: val_loss -0.6456 
2025-02-24 01:26:00.457125: Pseudo dice [np.float32(0.8261), np.float32(0.6887), np.float32(0.8648)] 
2025-02-24 01:26:00.462169: Epoch time: 39.42 s 
2025-02-24 01:26:00.973813:  
2025-02-24 01:26:00.978837: Epoch 62 
2025-02-24 01:26:00.982913: Current learning rate: 0.00774 
2025-02-24 01:26:40.405187: train_loss -0.7246 
2025-02-24 01:26:40.411706: val_loss -0.6351 
2025-02-24 01:26:40.415740: Pseudo dice [np.float32(0.821), np.float32(0.7261), np.float32(0.859)] 
2025-02-24 01:26:40.419303: Epoch time: 39.43 s 
2025-02-24 01:26:40.928690:  
2025-02-24 01:26:40.933839: Epoch 63 
2025-02-24 01:26:40.936872: Current learning rate: 0.0077 
2025-02-24 01:27:20.390009: train_loss -0.7204 
2025-02-24 01:27:20.396197: val_loss -0.6511 
2025-02-24 01:27:20.399732: Pseudo dice [np.float32(0.84), np.float32(0.6895), np.float32(0.8665)] 
2025-02-24 01:27:20.403763: Epoch time: 39.46 s 
2025-02-24 01:27:20.918324:  
2025-02-24 01:27:20.923840: Epoch 64 
2025-02-24 01:27:20.927349: Current learning rate: 0.00766 
2025-02-24 01:28:00.329994: train_loss -0.7259 
2025-02-24 01:28:00.337051: val_loss -0.6277 
2025-02-24 01:28:00.340082: Pseudo dice [np.float32(0.8121), np.float32(0.7137), np.float32(0.8391)] 
2025-02-24 01:28:00.343606: Epoch time: 39.41 s 
2025-02-24 01:28:00.853628:  
2025-02-24 01:28:00.859185: Epoch 65 
2025-02-24 01:28:00.861729: Current learning rate: 0.00763 
2025-02-24 01:28:40.322015: train_loss -0.7316 
2025-02-24 01:28:40.328612: val_loss -0.6308 
2025-02-24 01:28:40.331632: Pseudo dice [np.float32(0.828), np.float32(0.7261), np.float32(0.8511)] 
2025-02-24 01:28:40.335143: Epoch time: 39.47 s 
2025-02-24 01:28:40.990340:  
2025-02-24 01:28:40.995903: Epoch 66 
2025-02-24 01:28:41.000036: Current learning rate: 0.00759 
2025-02-24 01:29:20.442944: train_loss -0.7246 
2025-02-24 01:29:20.448463: val_loss -0.6531 
2025-02-24 01:29:20.452974: Pseudo dice [np.float32(0.8321), np.float32(0.7058), np.float32(0.8788)] 
2025-02-24 01:29:20.456988: Epoch time: 39.45 s 
2025-02-24 01:29:20.460997: Yayy! New best EMA pseudo Dice: 0.7907999753952026 
2025-02-24 01:29:21.120377:  
2025-02-24 01:29:21.125435: Epoch 67 
2025-02-24 01:29:21.129005: Current learning rate: 0.00755 
2025-02-24 01:30:00.531596: train_loss -0.7286 
2025-02-24 01:30:00.537627: val_loss -0.6484 
2025-02-24 01:30:00.542650: Pseudo dice [np.float32(0.8333), np.float32(0.6852), np.float32(0.8832)] 
2025-02-24 01:30:00.547194: Epoch time: 39.41 s 
2025-02-24 01:30:00.552210: Yayy! New best EMA pseudo Dice: 0.7918000221252441 
2025-02-24 01:30:01.224875:  
2025-02-24 01:30:01.230112: Epoch 68 
2025-02-24 01:30:01.233631: Current learning rate: 0.00751 
2025-02-24 01:30:40.646277: train_loss -0.7325 
2025-02-24 01:30:40.652339: val_loss -0.6424 
2025-02-24 01:30:40.656667: Pseudo dice [np.float32(0.826), np.float32(0.718), np.float32(0.8579)] 
2025-02-24 01:30:40.660181: Epoch time: 39.42 s 
2025-02-24 01:30:40.664202: Yayy! New best EMA pseudo Dice: 0.7925999760627747 
2025-02-24 01:30:41.335889:  
2025-02-24 01:30:41.341443: Epoch 69 
2025-02-24 01:30:41.345473: Current learning rate: 0.00748 
2025-02-24 01:31:20.777892: train_loss -0.7324 
2025-02-24 01:31:20.782906: val_loss -0.6186 
2025-02-24 01:31:20.787415: Pseudo dice [np.float32(0.8142), np.float32(0.6402), np.float32(0.8451)] 
2025-02-24 01:31:20.791425: Epoch time: 39.44 s 
2025-02-24 01:31:21.310663:  
2025-02-24 01:31:21.316210: Epoch 70 
2025-02-24 01:31:21.319776: Current learning rate: 0.00744 
2025-02-24 01:32:00.692638: train_loss -0.7323 
2025-02-24 01:32:00.698842: val_loss -0.6546 
2025-02-24 01:32:00.702440: Pseudo dice [np.float32(0.8301), np.float32(0.6913), np.float32(0.8555)] 
2025-02-24 01:32:00.706009: Epoch time: 39.38 s 
2025-02-24 01:32:01.228222:  
2025-02-24 01:32:01.233783: Epoch 71 
2025-02-24 01:32:01.237339: Current learning rate: 0.0074 
2025-02-24 01:32:40.735160: train_loss -0.727 
2025-02-24 01:32:40.741686: val_loss -0.624 
2025-02-24 01:32:40.746203: Pseudo dice [np.float32(0.8265), np.float32(0.6801), np.float32(0.855)] 
2025-02-24 01:32:40.750224: Epoch time: 39.51 s 
2025-02-24 01:32:41.263373:  
2025-02-24 01:32:41.268954: Epoch 72 
2025-02-24 01:32:41.272612: Current learning rate: 0.00737 
2025-02-24 01:33:20.688418: train_loss -0.7318 
2025-02-24 01:33:20.693931: val_loss -0.6504 
2025-02-24 01:33:20.698941: Pseudo dice [np.float32(0.812), np.float32(0.7103), np.float32(0.8596)] 
2025-02-24 01:33:20.703950: Epoch time: 39.43 s 
2025-02-24 01:33:21.361057:  
2025-02-24 01:33:21.367166: Epoch 73 
2025-02-24 01:33:21.370827: Current learning rate: 0.00733 
2025-02-24 01:34:00.776532: train_loss -0.7369 
2025-02-24 01:34:00.783096: val_loss -0.6371 
2025-02-24 01:34:00.787161: Pseudo dice [np.float32(0.8224), np.float32(0.7039), np.float32(0.8705)] 
2025-02-24 01:34:00.790738: Epoch time: 39.42 s 
2025-02-24 01:34:01.303915:  
2025-02-24 01:34:01.309473: Epoch 74 
2025-02-24 01:34:01.315054: Current learning rate: 0.00729 
2025-02-24 01:34:40.784025: train_loss -0.7174 
2025-02-24 01:34:40.790607: val_loss -0.6452 
2025-02-24 01:34:40.794620: Pseudo dice [np.float32(0.838), np.float32(0.6572), np.float32(0.8349)] 
2025-02-24 01:34:40.799146: Epoch time: 39.48 s 
2025-02-24 01:34:41.320142:  
2025-02-24 01:34:41.325693: Epoch 75 
2025-02-24 01:34:41.328226: Current learning rate: 0.00725 
2025-02-24 01:35:20.757474: train_loss -0.7326 
2025-02-24 01:35:20.763050: val_loss -0.6369 
2025-02-24 01:35:20.766772: Pseudo dice [np.float32(0.8247), np.float32(0.6693), np.float32(0.8683)] 
2025-02-24 01:35:20.772500: Epoch time: 39.44 s 
2025-02-24 01:35:21.290626:  
2025-02-24 01:35:21.297174: Epoch 76 
2025-02-24 01:35:21.300739: Current learning rate: 0.00722 
2025-02-24 01:36:00.718670: train_loss -0.7311 
2025-02-24 01:36:00.725732: val_loss -0.6745 
2025-02-24 01:36:00.732762: Pseudo dice [np.float32(0.8279), np.float32(0.7092), np.float32(0.877)] 
2025-02-24 01:36:00.738775: Epoch time: 39.43 s 
2025-02-24 01:36:01.255433:  
2025-02-24 01:36:01.261482: Epoch 77 
2025-02-24 01:36:01.265539: Current learning rate: 0.00718 
2025-02-24 01:36:40.710832: train_loss -0.7366 
2025-02-24 01:36:40.718369: val_loss -0.6173 
2025-02-24 01:36:40.725390: Pseudo dice [np.float32(0.8267), np.float32(0.7078), np.float32(0.8611)] 
2025-02-24 01:36:40.731922: Epoch time: 39.46 s 
2025-02-24 01:36:41.257863:  
2025-02-24 01:36:41.263882: Epoch 78 
2025-02-24 01:36:41.267898: Current learning rate: 0.00714 
2025-02-24 01:37:20.656514: train_loss -0.7426 
2025-02-24 01:37:20.663535: val_loss -0.6178 
2025-02-24 01:37:20.670061: Pseudo dice [np.float32(0.8052), np.float32(0.6974), np.float32(0.8387)] 
2025-02-24 01:37:20.677590: Epoch time: 39.4 s 
2025-02-24 01:37:21.202264:  
2025-02-24 01:37:21.207898: Epoch 79 
2025-02-24 01:37:21.212476: Current learning rate: 0.0071 
2025-02-24 01:38:00.654394: train_loss -0.7301 
2025-02-24 01:38:00.660916: val_loss -0.6544 
2025-02-24 01:38:00.668444: Pseudo dice [np.float32(0.8073), np.float32(0.7156), np.float32(0.8566)] 
2025-02-24 01:38:00.675973: Epoch time: 39.45 s 
2025-02-24 01:38:01.203857:  
2025-02-24 01:38:01.209373: Epoch 80 
2025-02-24 01:38:01.214396: Current learning rate: 0.00707 
2025-02-24 01:38:40.686188: train_loss -0.7347 
2025-02-24 01:38:40.695341: val_loss -0.664 
2025-02-24 01:38:40.701059: Pseudo dice [np.float32(0.8392), np.float32(0.7318), np.float32(0.8604)] 
2025-02-24 01:38:40.706081: Epoch time: 39.48 s 
2025-02-24 01:38:40.712110: Yayy! New best EMA pseudo Dice: 0.792900025844574 
2025-02-24 01:38:41.535150:  
2025-02-24 01:38:41.541767: Epoch 81 
2025-02-24 01:38:41.546523: Current learning rate: 0.00703 
2025-02-24 01:39:20.968322: train_loss -0.7447 
2025-02-24 01:39:20.973897: val_loss -0.6525 
2025-02-24 01:39:20.979551: Pseudo dice [np.float32(0.8371), np.float32(0.7173), np.float32(0.8737)] 
2025-02-24 01:39:20.985575: Epoch time: 39.43 s 
2025-02-24 01:39:20.990595: Yayy! New best EMA pseudo Dice: 0.7944999933242798 
2025-02-24 01:39:21.673786:  
2025-02-24 01:39:21.679300: Epoch 82 
2025-02-24 01:39:21.683812: Current learning rate: 0.00699 
2025-02-24 01:40:01.106022: train_loss -0.7513 
2025-02-24 01:40:01.113577: val_loss -0.6361 
2025-02-24 01:40:01.120123: Pseudo dice [np.float32(0.812), np.float32(0.688), np.float32(0.8559)] 
2025-02-24 01:40:01.125684: Epoch time: 39.43 s 
2025-02-24 01:40:01.622998:  
2025-02-24 01:40:01.629580: Epoch 83 
2025-02-24 01:40:01.633159: Current learning rate: 0.00696 
2025-02-24 01:40:41.083123: train_loss -0.7327 
2025-02-24 01:40:41.090880: val_loss -0.63 
2025-02-24 01:40:41.095465: Pseudo dice [np.float32(0.8204), np.float32(0.7147), np.float32(0.8668)] 
2025-02-24 01:40:41.102214: Epoch time: 39.46 s 
2025-02-24 01:40:41.604150:  
2025-02-24 01:40:41.610675: Epoch 84 
2025-02-24 01:40:41.615184: Current learning rate: 0.00692 
2025-02-24 01:41:21.025277: train_loss -0.7399 
2025-02-24 01:41:21.031974: val_loss -0.6551 
2025-02-24 01:41:21.038072: Pseudo dice [np.float32(0.8352), np.float32(0.7241), np.float32(0.8588)] 
2025-02-24 01:41:21.044653: Epoch time: 39.42 s 
2025-02-24 01:41:21.050254: Yayy! New best EMA pseudo Dice: 0.7954999804496765 
2025-02-24 01:41:21.689894:  
2025-02-24 01:41:21.696475: Epoch 85 
2025-02-24 01:41:21.700543: Current learning rate: 0.00688 
2025-02-24 01:42:01.124252: train_loss -0.7402 
2025-02-24 01:42:01.131275: val_loss -0.6407 
2025-02-24 01:42:01.136796: Pseudo dice [np.float32(0.8271), np.float32(0.7244), np.float32(0.8509)] 
2025-02-24 01:42:01.141308: Epoch time: 39.43 s 
2025-02-24 01:42:01.145326: Yayy! New best EMA pseudo Dice: 0.7960000038146973 
2025-02-24 01:42:01.800701:  
2025-02-24 01:42:01.806725: Epoch 86 
2025-02-24 01:42:01.810744: Current learning rate: 0.00684 
2025-02-24 01:42:41.287435: train_loss -0.746 
2025-02-24 01:42:41.294968: val_loss -0.6474 
2025-02-24 01:42:41.302495: Pseudo dice [np.float32(0.8228), np.float32(0.7271), np.float32(0.8568)] 
2025-02-24 01:42:41.309515: Epoch time: 39.49 s 
2025-02-24 01:42:41.315644: Yayy! New best EMA pseudo Dice: 0.7965999841690063 
2025-02-24 01:42:41.971979:  
2025-02-24 01:42:41.978617: Epoch 87 
2025-02-24 01:42:41.983160: Current learning rate: 0.0068 
2025-02-24 01:43:21.443214: train_loss -0.7403 
2025-02-24 01:43:21.450304: val_loss -0.6735 
2025-02-24 01:43:21.454360: Pseudo dice [np.float32(0.8428), np.float32(0.7035), np.float32(0.8739)] 
2025-02-24 01:43:21.458922: Epoch time: 39.47 s 
2025-02-24 01:43:21.463486: Yayy! New best EMA pseudo Dice: 0.7975999712944031 
2025-02-24 01:43:22.123130:  
2025-02-24 01:43:22.128143: Epoch 88 
2025-02-24 01:43:22.132653: Current learning rate: 0.00677 
2025-02-24 01:44:01.522718: train_loss -0.7387 
2025-02-24 01:44:01.530233: val_loss -0.6515 
2025-02-24 01:44:01.533741: Pseudo dice [np.float32(0.8282), np.float32(0.6933), np.float32(0.8675)] 
2025-02-24 01:44:01.541257: Epoch time: 39.4 s 
2025-02-24 01:44:02.188572:  
2025-02-24 01:44:02.194599: Epoch 89 
2025-02-24 01:44:02.198605: Current learning rate: 0.00673 
2025-02-24 01:44:41.587677: train_loss -0.7438 
2025-02-24 01:44:41.596307: val_loss -0.6485 
2025-02-24 01:44:41.602826: Pseudo dice [np.float32(0.821), np.float32(0.7417), np.float32(0.8516)] 
2025-02-24 01:44:41.608902: Epoch time: 39.4 s 
2025-02-24 01:44:41.612923: Yayy! New best EMA pseudo Dice: 0.7982000112533569 
2025-02-24 01:44:42.272745:  
2025-02-24 01:44:42.278774: Epoch 90 
2025-02-24 01:44:42.282781: Current learning rate: 0.00669 
2025-02-24 01:45:21.683639: train_loss -0.7427 
2025-02-24 01:45:21.690154: val_loss -0.6377 
2025-02-24 01:45:21.695169: Pseudo dice [np.float32(0.8222), np.float32(0.7204), np.float32(0.859)] 
2025-02-24 01:45:21.701192: Epoch time: 39.41 s 
2025-02-24 01:45:21.706208: Yayy! New best EMA pseudo Dice: 0.7985000014305115 
2025-02-24 01:45:22.379223:  
2025-02-24 01:45:22.385103: Epoch 91 
2025-02-24 01:45:22.389114: Current learning rate: 0.00665 
2025-02-24 01:46:01.781189: train_loss -0.7428 
2025-02-24 01:46:01.790813: val_loss -0.6329 
2025-02-24 01:46:01.797893: Pseudo dice [np.float32(0.8274), np.float32(0.7281), np.float32(0.8683)] 
2025-02-24 01:46:01.804975: Epoch time: 39.4 s 
2025-02-24 01:46:01.812136: Yayy! New best EMA pseudo Dice: 0.7993999719619751 
2025-02-24 01:46:02.478140:  
2025-02-24 01:46:02.484197: Epoch 92 
2025-02-24 01:46:02.488252: Current learning rate: 0.00662 
2025-02-24 01:46:41.890733: train_loss -0.7395 
2025-02-24 01:46:41.897830: val_loss -0.6536 
2025-02-24 01:46:41.902430: Pseudo dice [np.float32(0.833), np.float32(0.7063), np.float32(0.875)] 
2025-02-24 01:46:41.907132: Epoch time: 39.41 s 
2025-02-24 01:46:41.911698: Yayy! New best EMA pseudo Dice: 0.7998999953269958 
2025-02-24 01:46:42.569236:  
2025-02-24 01:46:42.575282: Epoch 93 
2025-02-24 01:46:42.578860: Current learning rate: 0.00658 
2025-02-24 01:47:21.986899: train_loss -0.7563 
2025-02-24 01:47:21.993432: val_loss -0.6349 
2025-02-24 01:47:21.998447: Pseudo dice [np.float32(0.8126), np.float32(0.7234), np.float32(0.8529)] 
2025-02-24 01:47:22.004469: Epoch time: 39.42 s 
2025-02-24 01:47:22.507717:  
2025-02-24 01:47:22.513294: Epoch 94 
2025-02-24 01:47:22.517341: Current learning rate: 0.00654 
2025-02-24 01:48:01.880016: train_loss -0.7488 
2025-02-24 01:48:01.886630: val_loss -0.6354 
2025-02-24 01:48:01.891190: Pseudo dice [np.float32(0.821), np.float32(0.6952), np.float32(0.8672)] 
2025-02-24 01:48:01.896343: Epoch time: 39.37 s 
2025-02-24 01:48:02.393084:  
2025-02-24 01:48:02.398111: Epoch 95 
2025-02-24 01:48:02.401654: Current learning rate: 0.0065 
2025-02-24 01:48:41.785197: train_loss -0.7422 
2025-02-24 01:48:41.791215: val_loss -0.6685 
2025-02-24 01:48:41.796235: Pseudo dice [np.float32(0.8424), np.float32(0.7414), np.float32(0.8615)] 
2025-02-24 01:48:41.801256: Epoch time: 39.39 s 
2025-02-24 01:48:41.806272: Yayy! New best EMA pseudo Dice: 0.8007000088691711 
2025-02-24 01:48:42.470220:  
2025-02-24 01:48:42.475756: Epoch 96 
2025-02-24 01:48:42.478792: Current learning rate: 0.00647 
2025-02-24 01:49:21.933338: train_loss -0.7428 
2025-02-24 01:49:21.940417: val_loss -0.6448 
2025-02-24 01:49:21.943969: Pseudo dice [np.float32(0.8228), np.float32(0.7014), np.float32(0.8379)] 
2025-02-24 01:49:21.948565: Epoch time: 39.46 s 
2025-02-24 01:49:22.611708:  
2025-02-24 01:49:22.618280: Epoch 97 
2025-02-24 01:49:22.621832: Current learning rate: 0.00643 
2025-02-24 01:50:01.954299: train_loss -0.7514 
2025-02-24 01:50:01.961400: val_loss -0.6613 
2025-02-24 01:50:01.964435: Pseudo dice [np.float32(0.827), np.float32(0.6822), np.float32(0.8497)] 
2025-02-24 01:50:01.968418: Epoch time: 39.34 s 
2025-02-24 01:50:02.478307:  
2025-02-24 01:50:02.483866: Epoch 98 
2025-02-24 01:50:02.487391: Current learning rate: 0.00639 
2025-02-24 01:50:41.951603: train_loss -0.7462 
2025-02-24 01:50:41.960243: val_loss -0.6337 
2025-02-24 01:50:41.963863: Pseudo dice [np.float32(0.8374), np.float32(0.7038), np.float32(0.8597)] 
2025-02-24 01:50:41.968396: Epoch time: 39.47 s 
2025-02-24 01:50:42.474910:  
2025-02-24 01:50:42.480465: Epoch 99 
2025-02-24 01:50:42.485045: Current learning rate: 0.00635 
2025-02-24 01:51:21.940348: train_loss -0.7472 
2025-02-24 01:51:21.947432: val_loss -0.6235 
2025-02-24 01:51:21.951446: Pseudo dice [np.float32(0.8196), np.float32(0.6938), np.float32(0.867)] 
2025-02-24 01:51:21.956460: Epoch time: 39.47 s 
2025-02-24 01:51:22.612266:  
2025-02-24 01:51:22.618428: Epoch 100 
2025-02-24 01:51:22.622504: Current learning rate: 0.00631 
2025-02-24 01:52:02.034146: train_loss -0.7564 
2025-02-24 01:52:02.041699: val_loss -0.6625 
2025-02-24 01:52:02.046914: Pseudo dice [np.float32(0.8427), np.float32(0.6824), np.float32(0.8575)] 
2025-02-24 01:52:02.053490: Epoch time: 39.42 s 
2025-02-24 01:52:02.563141:  
2025-02-24 01:52:02.568663: Epoch 101 
2025-02-24 01:52:02.572179: Current learning rate: 0.00628 
2025-02-24 01:52:42.016571: train_loss -0.755 
2025-02-24 01:52:42.024148: val_loss -0.6342 
2025-02-24 01:52:42.027685: Pseudo dice [np.float32(0.8205), np.float32(0.6534), np.float32(0.8779)] 
2025-02-24 01:52:42.031281: Epoch time: 39.45 s 
2025-02-24 01:52:42.543337:  
2025-02-24 01:52:42.549419: Epoch 102 
2025-02-24 01:52:42.552974: Current learning rate: 0.00624 
2025-02-24 01:53:21.927906: train_loss -0.7513 
2025-02-24 01:53:21.934428: val_loss -0.6437 
2025-02-24 01:53:21.938436: Pseudo dice [np.float32(0.8274), np.float32(0.7186), np.float32(0.8592)] 
2025-02-24 01:53:21.942944: Epoch time: 39.38 s 
2025-02-24 01:53:22.452459:  
2025-02-24 01:53:22.459036: Epoch 103 
2025-02-24 01:53:22.461580: Current learning rate: 0.0062 
2025-02-24 01:54:01.867975: train_loss -0.7439 
2025-02-24 01:54:01.874671: val_loss -0.6443 
2025-02-24 01:54:01.878738: Pseudo dice [np.float32(0.8321), np.float32(0.7356), np.float32(0.8552)] 
2025-02-24 01:54:01.882264: Epoch time: 39.42 s 
2025-02-24 01:54:02.391902:  
2025-02-24 01:54:02.397478: Epoch 104 
2025-02-24 01:54:02.402067: Current learning rate: 0.00616 
2025-02-24 01:54:41.829627: train_loss -0.7464 
2025-02-24 01:54:41.836177: val_loss -0.6378 
2025-02-24 01:54:41.841194: Pseudo dice [np.float32(0.8255), np.float32(0.7236), np.float32(0.8729)] 
2025-02-24 01:54:41.847216: Epoch time: 39.44 s 
2025-02-24 01:54:42.506426:  
2025-02-24 01:54:42.514016: Epoch 105 
2025-02-24 01:54:42.517076: Current learning rate: 0.00612 
2025-02-24 01:55:21.891143: train_loss -0.7475 
2025-02-24 01:55:21.897727: val_loss -0.6488 
2025-02-24 01:55:21.901233: Pseudo dice [np.float32(0.8375), np.float32(0.6937), np.float32(0.873)] 
2025-02-24 01:55:21.904245: Epoch time: 39.38 s 
2025-02-24 01:55:22.412740:  
2025-02-24 01:55:22.417761: Epoch 106 
2025-02-24 01:55:22.421782: Current learning rate: 0.00609 
2025-02-24 01:56:01.780415: train_loss -0.749 
2025-02-24 01:56:01.787940: val_loss -0.651 
2025-02-24 01:56:01.792956: Pseudo dice [np.float32(0.8214), np.float32(0.703), np.float32(0.8476)] 
2025-02-24 01:56:01.798475: Epoch time: 39.37 s 
2025-02-24 01:56:02.305932:  
2025-02-24 01:56:02.312545: Epoch 107 
2025-02-24 01:56:02.316091: Current learning rate: 0.00605 
2025-02-24 01:56:41.713039: train_loss -0.7521 
2025-02-24 01:56:41.720309: val_loss -0.6597 
2025-02-24 01:56:41.725897: Pseudo dice [np.float32(0.8266), np.float32(0.706), np.float32(0.8751)] 
2025-02-24 01:56:41.730974: Epoch time: 39.41 s 
2025-02-24 01:56:42.240626:  
2025-02-24 01:56:42.246755: Epoch 108 
2025-02-24 01:56:42.250264: Current learning rate: 0.00601 
2025-02-24 01:57:21.653246: train_loss -0.752 
2025-02-24 01:57:21.660764: val_loss -0.5922 
2025-02-24 01:57:21.665781: Pseudo dice [np.float32(0.8172), np.float32(0.6604), np.float32(0.8428)] 
2025-02-24 01:57:21.669797: Epoch time: 39.41 s 
2025-02-24 01:57:22.182043:  
2025-02-24 01:57:22.187561: Epoch 109 
2025-02-24 01:57:22.191073: Current learning rate: 0.00597 
2025-02-24 01:58:01.573099: train_loss -0.7508 
2025-02-24 01:58:01.580321: val_loss -0.6509 
2025-02-24 01:58:01.585982: Pseudo dice [np.float32(0.8443), np.float32(0.7213), np.float32(0.863)] 
2025-02-24 01:58:01.592167: Epoch time: 39.39 s 
2025-02-24 01:58:02.099796:  
2025-02-24 01:58:02.104810: Epoch 110 
2025-02-24 01:58:02.108319: Current learning rate: 0.00593 
2025-02-24 01:58:41.542912: train_loss -0.7514 
2025-02-24 01:58:41.550449: val_loss -0.6588 
2025-02-24 01:58:41.555464: Pseudo dice [np.float32(0.8464), np.float32(0.7261), np.float32(0.8553)] 
2025-02-24 01:58:41.562346: Epoch time: 39.44 s 
2025-02-24 01:58:42.086796:  
2025-02-24 01:58:42.091674: Epoch 111 
2025-02-24 01:58:42.096186: Current learning rate: 0.0059 
2025-02-24 01:59:21.545149: train_loss -0.7532 
2025-02-24 01:59:21.551671: val_loss -0.6727 
2025-02-24 01:59:21.556225: Pseudo dice [np.float32(0.8352), np.float32(0.7377), np.float32(0.8647)] 
2025-02-24 01:59:21.559288: Epoch time: 39.46 s 
2025-02-24 01:59:22.068494:  
2025-02-24 01:59:22.074509: Epoch 112 
2025-02-24 01:59:22.078017: Current learning rate: 0.00586 
2025-02-24 02:00:01.829136: train_loss -0.7487 
2025-02-24 02:00:01.836660: val_loss -0.6295 
2025-02-24 02:00:01.843181: Pseudo dice [np.float32(0.8196), np.float32(0.6828), np.float32(0.86)] 
2025-02-24 02:00:01.850206: Epoch time: 39.76 s 
2025-02-24 02:00:02.498816:  
2025-02-24 02:00:02.505412: Epoch 113 
2025-02-24 02:00:02.508551: Current learning rate: 0.00582 
2025-02-24 02:00:41.885409: train_loss -0.7511 
2025-02-24 02:00:41.891488: val_loss -0.6696 
2025-02-24 02:00:41.898036: Pseudo dice [np.float32(0.8328), np.float32(0.7358), np.float32(0.8693)] 
2025-02-24 02:00:41.901584: Epoch time: 39.39 s 
2025-02-24 02:00:42.405649:  
2025-02-24 02:00:42.411190: Epoch 114 
2025-02-24 02:00:42.415237: Current learning rate: 0.00578 
2025-02-24 02:01:21.768194: train_loss -0.7519 
2025-02-24 02:01:21.774796: val_loss -0.6298 
2025-02-24 02:01:21.778831: Pseudo dice [np.float32(0.8213), np.float32(0.7058), np.float32(0.8645)] 
2025-02-24 02:01:21.781906: Epoch time: 39.36 s 
2025-02-24 02:01:22.285021:  
2025-02-24 02:01:22.290658: Epoch 115 
2025-02-24 02:01:22.294699: Current learning rate: 0.00574 
2025-02-24 02:02:01.621039: train_loss -0.7612 
2025-02-24 02:02:01.627555: val_loss -0.6334 
2025-02-24 02:02:01.632566: Pseudo dice [np.float32(0.828), np.float32(0.7206), np.float32(0.8622)] 
2025-02-24 02:02:01.637082: Epoch time: 39.34 s 
2025-02-24 02:02:02.151329:  
2025-02-24 02:02:02.156891: Epoch 116 
2025-02-24 02:02:02.160421: Current learning rate: 0.0057 
2025-02-24 02:02:41.519227: train_loss -0.7602 
2025-02-24 02:02:41.525745: val_loss -0.6226 
2025-02-24 02:02:41.530759: Pseudo dice [np.float32(0.8238), np.float32(0.6949), np.float32(0.8416)] 
2025-02-24 02:02:41.535775: Epoch time: 39.37 s 
2025-02-24 02:02:42.043112:  
2025-02-24 02:02:42.048124: Epoch 117 
2025-02-24 02:02:42.052639: Current learning rate: 0.00567 
2025-02-24 02:03:21.443828: train_loss -0.7528 
2025-02-24 02:03:21.451348: val_loss -0.622 
2025-02-24 02:03:21.455858: Pseudo dice [np.float32(0.8364), np.float32(0.6652), np.float32(0.8722)] 
2025-02-24 02:03:21.461374: Epoch time: 39.4 s 
2025-02-24 02:03:21.973145:  
2025-02-24 02:03:21.978693: Epoch 118 
2025-02-24 02:03:21.982739: Current learning rate: 0.00563 
2025-02-24 02:04:01.358988: train_loss -0.7565 
2025-02-24 02:04:01.367191: val_loss -0.6466 
2025-02-24 02:04:01.372771: Pseudo dice [np.float32(0.8199), np.float32(0.7316), np.float32(0.8746)] 
2025-02-24 02:04:01.379861: Epoch time: 39.39 s 
2025-02-24 02:04:01.888283:  
2025-02-24 02:04:01.894338: Epoch 119 
2025-02-24 02:04:01.897864: Current learning rate: 0.00559 
2025-02-24 02:04:41.321338: train_loss -0.7573 
2025-02-24 02:04:41.327942: val_loss -0.6578 
2025-02-24 02:04:41.334155: Pseudo dice [np.float32(0.8231), np.float32(0.7485), np.float32(0.8752)] 
2025-02-24 02:04:41.340800: Epoch time: 39.43 s 
2025-02-24 02:04:41.347605: Yayy! New best EMA pseudo Dice: 0.8008000254631042 
2025-02-24 02:04:41.999423:  
2025-02-24 02:04:42.005441: Epoch 120 
2025-02-24 02:04:42.008949: Current learning rate: 0.00555 
2025-02-24 02:05:21.482496: train_loss -0.7631 
2025-02-24 02:05:21.490022: val_loss -0.6266 
2025-02-24 02:05:21.495034: Pseudo dice [np.float32(0.8016), np.float32(0.7487), np.float32(0.8806)] 
2025-02-24 02:05:21.501051: Epoch time: 39.48 s 
2025-02-24 02:05:21.508571: Yayy! New best EMA pseudo Dice: 0.801800012588501 
2025-02-24 02:05:22.334644:  
2025-02-24 02:05:22.339672: Epoch 121 
2025-02-24 02:05:22.343357: Current learning rate: 0.00551 
2025-02-24 02:06:01.760044: train_loss -0.7584 
2025-02-24 02:06:01.767063: val_loss -0.6616 
2025-02-24 02:06:01.772582: Pseudo dice [np.float32(0.8144), np.float32(0.73), np.float32(0.861)] 
2025-02-24 02:06:01.778613: Epoch time: 39.43 s 
2025-02-24 02:06:01.785131: Yayy! New best EMA pseudo Dice: 0.801800012588501 
2025-02-24 02:06:02.459284:  
2025-02-24 02:06:02.464849: Epoch 122 
2025-02-24 02:06:02.468894: Current learning rate: 0.00547 
2025-02-24 02:06:41.880022: train_loss -0.753 
2025-02-24 02:06:41.887126: val_loss -0.6575 
2025-02-24 02:06:41.892242: Pseudo dice [np.float32(0.847), np.float32(0.7075), np.float32(0.872)] 
2025-02-24 02:06:41.897257: Epoch time: 39.42 s 
2025-02-24 02:06:41.900767: Yayy! New best EMA pseudo Dice: 0.8025000095367432 
2025-02-24 02:06:42.571944:  
2025-02-24 02:06:42.578028: Epoch 123 
2025-02-24 02:06:42.581542: Current learning rate: 0.00544 
2025-02-24 02:07:21.940157: train_loss -0.7553 
2025-02-24 02:07:21.947934: val_loss -0.6177 
2025-02-24 02:07:21.952075: Pseudo dice [np.float32(0.816), np.float32(0.694), np.float32(0.8611)] 
2025-02-24 02:07:21.958205: Epoch time: 39.37 s 
2025-02-24 02:07:22.468013:  
2025-02-24 02:07:22.473583: Epoch 124 
2025-02-24 02:07:22.477744: Current learning rate: 0.0054 
2025-02-24 02:08:01.866274: train_loss -0.7606 
2025-02-24 02:08:01.872794: val_loss -0.616 
2025-02-24 02:08:01.877820: Pseudo dice [np.float32(0.8258), np.float32(0.7365), np.float32(0.8689)] 
2025-02-24 02:08:01.884386: Epoch time: 39.4 s 
2025-02-24 02:08:02.401451:  
2025-02-24 02:08:02.406011: Epoch 125 
2025-02-24 02:08:02.410567: Current learning rate: 0.00536 
2025-02-24 02:08:41.798232: train_loss -0.7552 
2025-02-24 02:08:41.804483: val_loss -0.6576 
2025-02-24 02:08:41.808561: Pseudo dice [np.float32(0.8338), np.float32(0.7151), np.float32(0.8573)] 
2025-02-24 02:08:41.813097: Epoch time: 39.4 s 
2025-02-24 02:08:42.320898:  
2025-02-24 02:08:42.326957: Epoch 126 
2025-02-24 02:08:42.329511: Current learning rate: 0.00532 
2025-02-24 02:09:21.700462: train_loss -0.7584 
2025-02-24 02:09:21.706982: val_loss -0.6338 
2025-02-24 02:09:21.710992: Pseudo dice [np.float32(0.8418), np.float32(0.7203), np.float32(0.8574)] 
2025-02-24 02:09:21.714502: Epoch time: 39.38 s 
2025-02-24 02:09:21.718521: Yayy! New best EMA pseudo Dice: 0.8026000261306763 
2025-02-24 02:09:22.370353:  
2025-02-24 02:09:22.375964: Epoch 127 
2025-02-24 02:09:22.379559: Current learning rate: 0.00528 
2025-02-24 02:10:01.840085: train_loss -0.7618 
2025-02-24 02:10:01.848239: val_loss -0.6535 
2025-02-24 02:10:01.853254: Pseudo dice [np.float32(0.835), np.float32(0.7214), np.float32(0.8629)] 
2025-02-24 02:10:01.857790: Epoch time: 39.47 s 
2025-02-24 02:10:01.862803: Yayy! New best EMA pseudo Dice: 0.8029999732971191 
2025-02-24 02:10:02.533317:  
2025-02-24 02:10:02.538853: Epoch 128 
2025-02-24 02:10:02.542427: Current learning rate: 0.00524 
2025-02-24 02:10:41.952040: train_loss -0.7613 
2025-02-24 02:10:41.959152: val_loss -0.6468 
2025-02-24 02:10:41.964212: Pseudo dice [np.float32(0.8358), np.float32(0.7081), np.float32(0.8793)] 
2025-02-24 02:10:41.970839: Epoch time: 39.42 s 
2025-02-24 02:10:41.976454: Yayy! New best EMA pseudo Dice: 0.8034999966621399 
2025-02-24 02:10:42.789205:  
2025-02-24 02:10:42.796243: Epoch 129 
2025-02-24 02:10:42.799750: Current learning rate: 0.0052 
2025-02-24 02:11:22.189198: train_loss -0.7625 
2025-02-24 02:11:22.197365: val_loss -0.6382 
2025-02-24 02:11:22.202382: Pseudo dice [np.float32(0.8227), np.float32(0.702), np.float32(0.8554)] 
2025-02-24 02:11:22.207394: Epoch time: 39.4 s 
2025-02-24 02:11:22.720510:  
2025-02-24 02:11:22.727065: Epoch 130 
2025-02-24 02:11:22.730607: Current learning rate: 0.00517 
2025-02-24 02:12:02.072397: train_loss -0.7656 
2025-02-24 02:12:02.079917: val_loss -0.6351 
2025-02-24 02:12:02.087445: Pseudo dice [np.float32(0.8057), np.float32(0.6954), np.float32(0.8619)] 
2025-02-24 02:12:02.092026: Epoch time: 39.35 s 
2025-02-24 02:12:02.600610:  
2025-02-24 02:12:02.606706: Epoch 131 
2025-02-24 02:12:02.610217: Current learning rate: 0.00513 
2025-02-24 02:12:42.157255: train_loss -0.7602 
2025-02-24 02:12:42.163779: val_loss -0.6423 
2025-02-24 02:12:42.169802: Pseudo dice [np.float32(0.825), np.float32(0.708), np.float32(0.8617)] 
2025-02-24 02:12:42.176322: Epoch time: 39.56 s 
2025-02-24 02:12:42.692909:  
2025-02-24 02:12:42.698426: Epoch 132 
2025-02-24 02:12:42.701935: Current learning rate: 0.00509 
2025-02-24 02:13:22.148889: train_loss -0.7646 
2025-02-24 02:13:22.156062: val_loss -0.6477 
2025-02-24 02:13:22.161127: Pseudo dice [np.float32(0.8296), np.float32(0.717), np.float32(0.8388)] 
2025-02-24 02:13:22.164749: Epoch time: 39.46 s 
2025-02-24 02:13:22.678086:  
2025-02-24 02:13:22.683102: Epoch 133 
2025-02-24 02:13:22.686621: Current learning rate: 0.00505 
2025-02-24 02:14:02.048517: train_loss -0.7662 
2025-02-24 02:14:02.056041: val_loss -0.6656 
2025-02-24 02:14:02.060555: Pseudo dice [np.float32(0.828), np.float32(0.7149), np.float32(0.8817)] 
2025-02-24 02:14:02.066079: Epoch time: 39.37 s 
2025-02-24 02:14:02.580851:  
2025-02-24 02:14:02.586874: Epoch 134 
2025-02-24 02:14:02.590376: Current learning rate: 0.00501 
2025-02-24 02:14:42.062772: train_loss -0.7641 
2025-02-24 02:14:42.069286: val_loss -0.6171 
2025-02-24 02:14:42.073801: Pseudo dice [np.float32(0.8167), np.float32(0.7143), np.float32(0.8573)] 
2025-02-24 02:14:42.077818: Epoch time: 39.48 s 
2025-02-24 02:14:42.597711:  
2025-02-24 02:14:42.603731: Epoch 135 
2025-02-24 02:14:42.607234: Current learning rate: 0.00497 
2025-02-24 02:15:22.028615: train_loss -0.768 
2025-02-24 02:15:22.034792: val_loss -0.6403 
2025-02-24 02:15:22.039980: Pseudo dice [np.float32(0.8158), np.float32(0.7116), np.float32(0.8564)] 
2025-02-24 02:15:22.045599: Epoch time: 39.43 s 
2025-02-24 02:15:22.567147:  
2025-02-24 02:15:22.572663: Epoch 136 
2025-02-24 02:15:22.576176: Current learning rate: 0.00493 
2025-02-24 02:16:01.926960: train_loss -0.7688 
2025-02-24 02:16:01.935184: val_loss -0.6685 
2025-02-24 02:16:01.941279: Pseudo dice [np.float32(0.821), np.float32(0.7194), np.float32(0.8584)] 
2025-02-24 02:16:01.947899: Epoch time: 39.36 s 
2025-02-24 02:16:02.616340:  
2025-02-24 02:16:02.622359: Epoch 137 
2025-02-24 02:16:02.624868: Current learning rate: 0.00489 
2025-02-24 02:16:41.976469: train_loss -0.767 
2025-02-24 02:16:41.982981: val_loss -0.6572 
2025-02-24 02:16:41.986492: Pseudo dice [np.float32(0.8414), np.float32(0.7377), np.float32(0.8708)] 
2025-02-24 02:16:41.990503: Epoch time: 39.36 s 
2025-02-24 02:16:42.506786:  
2025-02-24 02:16:42.512337: Epoch 138 
2025-02-24 02:16:42.516415: Current learning rate: 0.00485 
2025-02-24 02:17:21.914529: train_loss -0.7698 
2025-02-24 02:17:21.922158: val_loss -0.6316 
2025-02-24 02:17:21.927753: Pseudo dice [np.float32(0.811), np.float32(0.7513), np.float32(0.8732)] 
2025-02-24 02:17:21.933769: Epoch time: 39.41 s 
2025-02-24 02:17:22.455696:  
2025-02-24 02:17:22.461222: Epoch 139 
2025-02-24 02:17:22.464791: Current learning rate: 0.00482 
2025-02-24 02:18:01.742747: train_loss -0.7713 
2025-02-24 02:18:01.749270: val_loss -0.6222 
2025-02-24 02:18:01.754284: Pseudo dice [np.float32(0.8125), np.float32(0.7487), np.float32(0.846)] 
2025-02-24 02:18:01.758299: Epoch time: 39.29 s 
2025-02-24 02:18:02.273716:  
2025-02-24 02:18:02.279245: Epoch 140 
2025-02-24 02:18:02.282779: Current learning rate: 0.00478 
2025-02-24 02:18:41.677633: train_loss -0.7721 
2025-02-24 02:18:41.685217: val_loss -0.6297 
2025-02-24 02:18:41.690229: Pseudo dice [np.float32(0.8238), np.float32(0.7207), np.float32(0.8712)] 
2025-02-24 02:18:41.696246: Epoch time: 39.4 s 
2025-02-24 02:18:42.210792:  
2025-02-24 02:18:42.214804: Epoch 141 
2025-02-24 02:18:42.218812: Current learning rate: 0.00474 
2025-02-24 02:19:21.581281: train_loss -0.7606 
2025-02-24 02:19:21.588300: val_loss -0.6652 
2025-02-24 02:19:21.592316: Pseudo dice [np.float32(0.8275), np.float32(0.7489), np.float32(0.8761)] 
2025-02-24 02:19:21.596326: Epoch time: 39.37 s 
2025-02-24 02:19:21.599838: Yayy! New best EMA pseudo Dice: 0.8043000102043152 
2025-02-24 02:19:22.276166:  
2025-02-24 02:19:22.282197: Epoch 142 
2025-02-24 02:19:22.285797: Current learning rate: 0.0047 
2025-02-24 02:20:01.705622: train_loss -0.7665 
2025-02-24 02:20:01.711673: val_loss -0.6389 
2025-02-24 02:20:01.715341: Pseudo dice [np.float32(0.8254), np.float32(0.6822), np.float32(0.8717)] 
2025-02-24 02:20:01.719268: Epoch time: 39.43 s 
2025-02-24 02:20:02.247316:  
2025-02-24 02:20:02.253394: Epoch 143 
2025-02-24 02:20:02.257006: Current learning rate: 0.00466 
2025-02-24 02:20:41.624262: train_loss -0.7636 
2025-02-24 02:20:41.630802: val_loss -0.6313 
2025-02-24 02:20:41.634806: Pseudo dice [np.float32(0.8315), np.float32(0.7064), np.float32(0.8772)] 
2025-02-24 02:20:41.639824: Epoch time: 39.38 s 
2025-02-24 02:20:42.156124:  
2025-02-24 02:20:42.161644: Epoch 144 
2025-02-24 02:20:42.165379: Current learning rate: 0.00462 
2025-02-24 02:21:21.552790: train_loss -0.763 
2025-02-24 02:21:21.558881: val_loss -0.6433 
2025-02-24 02:21:21.564901: Pseudo dice [np.float32(0.8259), np.float32(0.7173), np.float32(0.8608)] 
2025-02-24 02:21:21.569918: Epoch time: 39.4 s 
2025-02-24 02:21:22.235348:  
2025-02-24 02:21:22.241375: Epoch 145 
2025-02-24 02:21:22.244879: Current learning rate: 0.00458 
2025-02-24 02:22:01.542156: train_loss -0.7625 
2025-02-24 02:22:01.548672: val_loss -0.6297 
2025-02-24 02:22:01.552216: Pseudo dice [np.float32(0.8336), np.float32(0.7114), np.float32(0.8378)] 
2025-02-24 02:22:01.555725: Epoch time: 39.31 s 
2025-02-24 02:22:02.081546:  
2025-02-24 02:22:02.087131: Epoch 146 
2025-02-24 02:22:02.090172: Current learning rate: 0.00454 
2025-02-24 02:22:41.404282: train_loss -0.7706 
2025-02-24 02:22:41.411870: val_loss -0.649 
2025-02-24 02:22:41.415884: Pseudo dice [np.float32(0.8221), np.float32(0.6977), np.float32(0.8826)] 
2025-02-24 02:22:41.420947: Epoch time: 39.32 s 
2025-02-24 02:22:41.938335:  
2025-02-24 02:22:41.944874: Epoch 147 
2025-02-24 02:22:41.948429: Current learning rate: 0.0045 
2025-02-24 02:23:21.331650: train_loss -0.7717 
2025-02-24 02:23:21.337670: val_loss -0.6252 
2025-02-24 02:23:21.342686: Pseudo dice [np.float32(0.8165), np.float32(0.6989), np.float32(0.8599)] 
2025-02-24 02:23:21.347697: Epoch time: 39.39 s 
2025-02-24 02:23:21.863467:  
2025-02-24 02:23:21.869548: Epoch 148 
2025-02-24 02:23:21.873059: Current learning rate: 0.00446 
2025-02-24 02:24:01.261431: train_loss -0.7644 
2025-02-24 02:24:01.268448: val_loss -0.6515 
2025-02-24 02:24:01.271459: Pseudo dice [np.float32(0.8348), np.float32(0.7584), np.float32(0.87)] 
2025-02-24 02:24:01.275972: Epoch time: 39.4 s 
2025-02-24 02:24:01.797326:  
2025-02-24 02:24:01.803385: Epoch 149 
2025-02-24 02:24:01.806937: Current learning rate: 0.00442 
2025-02-24 02:24:41.200632: train_loss -0.7717 
2025-02-24 02:24:41.208179: val_loss -0.6455 
2025-02-24 02:24:41.212806: Pseudo dice [np.float32(0.8255), np.float32(0.7198), np.float32(0.8785)] 
2025-02-24 02:24:41.217872: Epoch time: 39.4 s 
2025-02-24 02:24:41.881849:  
2025-02-24 02:24:41.887867: Epoch 150 
2025-02-24 02:24:41.891884: Current learning rate: 0.00438 
2025-02-24 02:25:21.282159: train_loss -0.7655 
2025-02-24 02:25:21.289179: val_loss -0.595 
2025-02-24 02:25:21.295705: Pseudo dice [np.float32(0.8135), np.float32(0.6941), np.float32(0.851)] 
2025-02-24 02:25:21.302228: Epoch time: 39.4 s 
2025-02-24 02:25:21.817565:  
2025-02-24 02:25:21.824149: Epoch 151 
2025-02-24 02:25:21.827299: Current learning rate: 0.00434 
2025-02-24 02:26:01.172656: train_loss -0.7721 
2025-02-24 02:26:01.179255: val_loss -0.6582 
2025-02-24 02:26:01.184271: Pseudo dice [np.float32(0.8359), np.float32(0.7264), np.float32(0.8673)] 
2025-02-24 02:26:01.190787: Epoch time: 39.36 s 
2025-02-24 02:26:01.712822:  
2025-02-24 02:26:01.718339: Epoch 152 
2025-02-24 02:26:01.721847: Current learning rate: 0.0043 
2025-02-24 02:26:41.109130: train_loss -0.7746 
2025-02-24 02:26:41.115356: val_loss -0.6226 
2025-02-24 02:26:41.119376: Pseudo dice [np.float32(0.8261), np.float32(0.7017), np.float32(0.8668)] 
2025-02-24 02:26:41.123898: Epoch time: 39.4 s 
2025-02-24 02:26:41.802215:  
2025-02-24 02:26:41.808312: Epoch 153 
2025-02-24 02:26:41.811876: Current learning rate: 0.00427 
2025-02-24 02:27:21.147636: train_loss -0.7686 
2025-02-24 02:27:21.154865: val_loss -0.6238 
2025-02-24 02:27:21.160386: Pseudo dice [np.float32(0.8225), np.float32(0.6855), np.float32(0.8768)] 
2025-02-24 02:27:21.166409: Epoch time: 39.35 s 
2025-02-24 02:27:21.695391:  
2025-02-24 02:27:21.701496: Epoch 154 
2025-02-24 02:27:21.705025: Current learning rate: 0.00423 
2025-02-24 02:28:01.150819: train_loss -0.7709 
2025-02-24 02:28:01.157331: val_loss -0.6441 
2025-02-24 02:28:01.160843: Pseudo dice [np.float32(0.8512), np.float32(0.7167), np.float32(0.8727)] 
2025-02-24 02:28:01.164854: Epoch time: 39.46 s 
2025-02-24 02:28:01.689264:  
2025-02-24 02:28:01.694782: Epoch 155 
2025-02-24 02:28:01.698289: Current learning rate: 0.00419 
2025-02-24 02:28:41.079230: train_loss -0.7698 
2025-02-24 02:28:41.086744: val_loss -0.6268 
2025-02-24 02:28:41.092759: Pseudo dice [np.float32(0.8447), np.float32(0.7048), np.float32(0.8738)] 
2025-02-24 02:28:41.099273: Epoch time: 39.39 s 
2025-02-24 02:28:41.630015:  
2025-02-24 02:28:41.636085: Epoch 156 
2025-02-24 02:28:41.639206: Current learning rate: 0.00415 
2025-02-24 02:29:21.046972: train_loss -0.7679 
2025-02-24 02:29:21.054687: val_loss -0.6741 
2025-02-24 02:29:21.059701: Pseudo dice [np.float32(0.8367), np.float32(0.7071), np.float32(0.8624)] 
2025-02-24 02:29:21.065219: Epoch time: 39.42 s 
2025-02-24 02:29:21.599397:  
2025-02-24 02:29:21.604914: Epoch 157 
2025-02-24 02:29:21.608424: Current learning rate: 0.00411 
2025-02-24 02:30:01.003978: train_loss -0.7712 
2025-02-24 02:30:01.009505: val_loss -0.66 
2025-02-24 02:30:01.014622: Pseudo dice [np.float32(0.85), np.float32(0.7065), np.float32(0.8655)] 
2025-02-24 02:30:01.018716: Epoch time: 39.41 s 
2025-02-24 02:30:01.550569:  
2025-02-24 02:30:01.557220: Epoch 158 
2025-02-24 02:30:01.560794: Current learning rate: 0.00407 
2025-02-24 02:30:40.930837: train_loss -0.7673 
2025-02-24 02:30:40.937961: val_loss -0.6248 
2025-02-24 02:30:40.942012: Pseudo dice [np.float32(0.8234), np.float32(0.7006), np.float32(0.8436)] 
2025-02-24 02:30:40.945696: Epoch time: 39.38 s 
2025-02-24 02:30:41.476859:  
2025-02-24 02:30:41.482913: Epoch 159 
2025-02-24 02:30:41.487438: Current learning rate: 0.00403 
2025-02-24 02:31:20.884265: train_loss -0.7672 
2025-02-24 02:31:20.890364: val_loss -0.6535 
2025-02-24 02:31:20.895435: Pseudo dice [np.float32(0.8361), np.float32(0.7289), np.float32(0.8687)] 
2025-02-24 02:31:20.900025: Epoch time: 39.41 s 
2025-02-24 02:31:21.569856:  
2025-02-24 02:31:21.574914: Epoch 160 
2025-02-24 02:31:21.578572: Current learning rate: 0.00399 
2025-02-24 02:32:00.886969: train_loss -0.7774 
2025-02-24 02:32:00.893983: val_loss -0.6517 
2025-02-24 02:32:00.899498: Pseudo dice [np.float32(0.85), np.float32(0.7203), np.float32(0.859)] 
2025-02-24 02:32:00.904516: Epoch time: 39.32 s 
2025-02-24 02:32:01.434909:  
2025-02-24 02:32:01.441025: Epoch 161 
2025-02-24 02:32:01.444583: Current learning rate: 0.00395 
2025-02-24 02:32:40.827504: train_loss -0.7792 
2025-02-24 02:32:40.833580: val_loss -0.6339 
2025-02-24 02:32:40.836694: Pseudo dice [np.float32(0.8323), np.float32(0.6923), np.float32(0.8562)] 
2025-02-24 02:32:40.840206: Epoch time: 39.39 s 
2025-02-24 02:32:41.369217:  
2025-02-24 02:32:41.374772: Epoch 162 
2025-02-24 02:32:41.378889: Current learning rate: 0.00391 
2025-02-24 02:33:20.711955: train_loss -0.7776 
2025-02-24 02:33:20.718104: val_loss -0.6294 
2025-02-24 02:33:20.722701: Pseudo dice [np.float32(0.8171), np.float32(0.7378), np.float32(0.8633)] 
2025-02-24 02:33:20.727807: Epoch time: 39.34 s 
2025-02-24 02:33:21.254635:  
2025-02-24 02:33:21.260153: Epoch 163 
2025-02-24 02:33:21.263666: Current learning rate: 0.00387 
2025-02-24 02:34:00.604351: train_loss -0.7792 
2025-02-24 02:34:00.611958: val_loss -0.6228 
2025-02-24 02:34:00.617527: Pseudo dice [np.float32(0.8298), np.float32(0.7062), np.float32(0.8567)] 
2025-02-24 02:34:00.624172: Epoch time: 39.35 s 
2025-02-24 02:34:01.157728:  
2025-02-24 02:34:01.163829: Epoch 164 
2025-02-24 02:34:01.166375: Current learning rate: 0.00383 
2025-02-24 02:34:40.526121: train_loss -0.7771 
2025-02-24 02:34:40.531738: val_loss -0.6456 
2025-02-24 02:34:40.535782: Pseudo dice [np.float32(0.8393), np.float32(0.6982), np.float32(0.8612)] 
2025-02-24 02:34:40.539360: Epoch time: 39.37 s 
2025-02-24 02:34:41.054224:  
2025-02-24 02:34:41.059235: Epoch 165 
2025-02-24 02:34:41.062748: Current learning rate: 0.00379 
2025-02-24 02:35:20.482322: train_loss -0.7743 
2025-02-24 02:35:20.488842: val_loss -0.6538 
2025-02-24 02:35:20.494864: Pseudo dice [np.float32(0.8202), np.float32(0.7219), np.float32(0.8686)] 
2025-02-24 02:35:20.501389: Epoch time: 39.43 s 
2025-02-24 02:35:21.017080:  
2025-02-24 02:35:21.023110: Epoch 166 
2025-02-24 02:35:21.026619: Current learning rate: 0.00375 
2025-02-24 02:36:00.461794: train_loss -0.7699 
2025-02-24 02:36:00.468323: val_loss -0.6625 
2025-02-24 02:36:00.471840: Pseudo dice [np.float32(0.8383), np.float32(0.7766), np.float32(0.8676)] 
2025-02-24 02:36:00.475860: Epoch time: 39.44 s 
2025-02-24 02:36:00.479234: Yayy! New best EMA pseudo Dice: 0.8047999739646912 
2025-02-24 02:36:01.128595:  
2025-02-24 02:36:01.135179: Epoch 167 
2025-02-24 02:36:01.138806: Current learning rate: 0.00371 
2025-02-24 02:36:40.538178: train_loss -0.7735 
2025-02-24 02:36:40.544703: val_loss -0.6409 
2025-02-24 02:36:40.551227: Pseudo dice [np.float32(0.8272), np.float32(0.6931), np.float32(0.8685)] 
2025-02-24 02:36:40.558249: Epoch time: 39.41 s 
2025-02-24 02:36:41.232614:  
2025-02-24 02:36:41.238198: Epoch 168 
2025-02-24 02:36:41.241845: Current learning rate: 0.00367 
2025-02-24 02:37:20.552635: train_loss -0.7695 
2025-02-24 02:37:20.559149: val_loss -0.6391 
2025-02-24 02:37:20.565161: Pseudo dice [np.float32(0.8182), np.float32(0.7305), np.float32(0.8617)] 
2025-02-24 02:37:20.570171: Epoch time: 39.32 s 
2025-02-24 02:37:21.097591:  
2025-02-24 02:37:21.102602: Epoch 169 
2025-02-24 02:37:21.106120: Current learning rate: 0.00363 
2025-02-24 02:38:00.473010: train_loss -0.7712 
2025-02-24 02:38:00.480098: val_loss -0.6546 
2025-02-24 02:38:00.483664: Pseudo dice [np.float32(0.8376), np.float32(0.7304), np.float32(0.8618)] 
2025-02-24 02:38:00.486763: Epoch time: 39.38 s 
2025-02-24 02:38:01.007068:  
2025-02-24 02:38:01.013093: Epoch 170 
2025-02-24 02:38:01.016605: Current learning rate: 0.00359 
2025-02-24 02:38:40.350118: train_loss -0.777 
2025-02-24 02:38:40.356150: val_loss -0.6275 
2025-02-24 02:38:40.360159: Pseudo dice [np.float32(0.8342), np.float32(0.7129), np.float32(0.8695)] 
2025-02-24 02:38:40.363671: Epoch time: 39.34 s 
2025-02-24 02:38:40.879969:  
2025-02-24 02:38:40.885525: Epoch 171 
2025-02-24 02:38:40.888058: Current learning rate: 0.00355 
2025-02-24 02:39:20.240225: train_loss -0.7687 
2025-02-24 02:39:20.245783: val_loss -0.6023 
2025-02-24 02:39:20.250798: Pseudo dice [np.float32(0.8186), np.float32(0.6788), np.float32(0.8609)] 
2025-02-24 02:39:20.254310: Epoch time: 39.36 s 
2025-02-24 02:39:20.772725:  
2025-02-24 02:39:20.777393: Epoch 172 
2025-02-24 02:39:20.781426: Current learning rate: 0.00351 
2025-02-24 02:40:00.108934: train_loss -0.7783 
2025-02-24 02:40:00.117059: val_loss -0.6375 
2025-02-24 02:40:00.122082: Pseudo dice [np.float32(0.8209), np.float32(0.7395), np.float32(0.8755)] 
2025-02-24 02:40:00.128636: Epoch time: 39.34 s 
2025-02-24 02:40:00.645868:  
2025-02-24 02:40:00.651445: Epoch 173 
2025-02-24 02:40:00.654987: Current learning rate: 0.00346 
2025-02-24 02:40:40.068557: train_loss -0.7733 
2025-02-24 02:40:40.075665: val_loss -0.6256 
2025-02-24 02:40:40.081733: Pseudo dice [np.float32(0.8339), np.float32(0.6972), np.float32(0.8598)] 
2025-02-24 02:40:40.088262: Epoch time: 39.42 s 
2025-02-24 02:40:40.620390:  
2025-02-24 02:40:40.626408: Epoch 174 
2025-02-24 02:40:40.629914: Current learning rate: 0.00342 
2025-02-24 02:41:19.991917: train_loss -0.7835 
2025-02-24 02:41:19.997847: val_loss -0.6141 
2025-02-24 02:41:20.002868: Pseudo dice [np.float32(0.8299), np.float32(0.6906), np.float32(0.8719)] 
2025-02-24 02:41:20.009386: Epoch time: 39.37 s 
2025-02-24 02:41:20.532245:  
2025-02-24 02:41:20.537803: Epoch 175 
2025-02-24 02:41:20.541880: Current learning rate: 0.00338 
2025-02-24 02:41:59.944705: train_loss -0.7809 
2025-02-24 02:41:59.953723: val_loss -0.6721 
2025-02-24 02:41:59.963249: Pseudo dice [np.float32(0.8355), np.float32(0.7214), np.float32(0.8727)] 
2025-02-24 02:41:59.968768: Epoch time: 39.41 s 
2025-02-24 02:42:00.636413:  
2025-02-24 02:42:00.641994: Epoch 176 
2025-02-24 02:42:00.646041: Current learning rate: 0.00334 
2025-02-24 02:42:40.026258: train_loss -0.779 
2025-02-24 02:42:40.032859: val_loss -0.6585 
2025-02-24 02:42:40.037871: Pseudo dice [np.float32(0.8155), np.float32(0.7057), np.float32(0.8661)] 
2025-02-24 02:42:40.043897: Epoch time: 39.39 s 
2025-02-24 02:42:40.559262:  
2025-02-24 02:42:40.564777: Epoch 177 
2025-02-24 02:42:40.568287: Current learning rate: 0.0033 
2025-02-24 02:43:19.917335: train_loss -0.7814 
2025-02-24 02:43:19.924419: val_loss -0.6532 
2025-02-24 02:43:19.931006: Pseudo dice [np.float32(0.832), np.float32(0.6862), np.float32(0.873)] 
2025-02-24 02:43:19.938080: Epoch time: 39.36 s 
2025-02-24 02:43:20.457139:  
2025-02-24 02:43:20.462163: Epoch 178 
2025-02-24 02:43:20.468279: Current learning rate: 0.00326 
2025-02-24 02:43:59.918924: train_loss -0.7649 
2025-02-24 02:43:59.925533: val_loss -0.6468 
2025-02-24 02:43:59.930633: Pseudo dice [np.float32(0.8351), np.float32(0.7201), np.float32(0.8771)] 
2025-02-24 02:43:59.936363: Epoch time: 39.46 s 
2025-02-24 02:44:00.460312:  
2025-02-24 02:44:00.466327: Epoch 179 
2025-02-24 02:44:00.469834: Current learning rate: 0.00322 
2025-02-24 02:44:39.834076: train_loss -0.7749 
2025-02-24 02:44:39.841649: val_loss -0.6532 
2025-02-24 02:44:39.847700: Pseudo dice [np.float32(0.8319), np.float32(0.724), np.float32(0.8558)] 
2025-02-24 02:44:39.854358: Epoch time: 39.37 s 
2025-02-24 02:44:40.372819:  
2025-02-24 02:44:40.377831: Epoch 180 
2025-02-24 02:44:40.381342: Current learning rate: 0.00318 
2025-02-24 02:45:19.777300: train_loss -0.7676 
2025-02-24 02:45:19.783403: val_loss -0.6406 
2025-02-24 02:45:19.786998: Pseudo dice [np.float32(0.8244), np.float32(0.7184), np.float32(0.8474)] 
2025-02-24 02:45:19.790044: Epoch time: 39.4 s 
2025-02-24 02:45:20.311672:  
2025-02-24 02:45:20.317212: Epoch 181 
2025-02-24 02:45:20.321338: Current learning rate: 0.00314 
2025-02-24 02:45:59.711571: train_loss -0.7708 
2025-02-24 02:45:59.718084: val_loss -0.6411 
2025-02-24 02:45:59.724099: Pseudo dice [np.float32(0.8314), np.float32(0.7096), np.float32(0.8547)] 
2025-02-24 02:45:59.730614: Epoch time: 39.4 s 
2025-02-24 02:46:00.256007:  
2025-02-24 02:46:00.262079: Epoch 182 
2025-02-24 02:46:00.266199: Current learning rate: 0.0031 
2025-02-24 02:46:39.672906: train_loss -0.7809 
2025-02-24 02:46:39.680584: val_loss -0.658 
2025-02-24 02:46:39.684093: Pseudo dice [np.float32(0.813), np.float32(0.7389), np.float32(0.8719)] 
2025-02-24 02:46:39.688105: Epoch time: 39.42 s 
2025-02-24 02:46:40.214181:  
2025-02-24 02:46:40.220323: Epoch 183 
2025-02-24 02:46:40.223379: Current learning rate: 0.00306 
2025-02-24 02:47:19.764066: train_loss -0.7746 
2025-02-24 02:47:19.770578: val_loss -0.6159 
2025-02-24 02:47:19.774086: Pseudo dice [np.float32(0.8139), np.float32(0.7009), np.float32(0.8569)] 
2025-02-24 02:47:19.778122: Epoch time: 39.55 s 
2025-02-24 02:47:20.301340:  
2025-02-24 02:47:20.307394: Epoch 184 
2025-02-24 02:47:20.311536: Current learning rate: 0.00302 
2025-02-24 02:47:59.720140: train_loss -0.7752 
2025-02-24 02:47:59.727659: val_loss -0.653 
2025-02-24 02:47:59.732169: Pseudo dice [np.float32(0.8351), np.float32(0.7312), np.float32(0.8611)] 
2025-02-24 02:47:59.737823: Epoch time: 39.42 s 
2025-02-24 02:48:00.261118:  
2025-02-24 02:48:00.266162: Epoch 185 
2025-02-24 02:48:00.270193: Current learning rate: 0.00297 
2025-02-24 02:48:39.695317: train_loss -0.7751 
2025-02-24 02:48:39.702916: val_loss -0.6649 
2025-02-24 02:48:39.708082: Pseudo dice [np.float32(0.8319), np.float32(0.7505), np.float32(0.8785)] 
2025-02-24 02:48:39.713680: Epoch time: 39.44 s 
2025-02-24 02:48:40.240205:  
2025-02-24 02:48:40.245783: Epoch 186 
2025-02-24 02:48:40.248890: Current learning rate: 0.00293 
2025-02-24 02:49:19.641047: train_loss -0.7878 
2025-02-24 02:49:19.647568: val_loss -0.6483 
2025-02-24 02:49:19.652583: Pseudo dice [np.float32(0.8207), np.float32(0.7137), np.float32(0.8628)] 
2025-02-24 02:49:19.659105: Epoch time: 39.4 s 
2025-02-24 02:49:20.182427:  
2025-02-24 02:49:20.187522: Epoch 187 
2025-02-24 02:49:20.191113: Current learning rate: 0.00289 
2025-02-24 02:49:59.597895: train_loss -0.7746 
2025-02-24 02:49:59.604412: val_loss -0.6448 
2025-02-24 02:49:59.609426: Pseudo dice [np.float32(0.8287), np.float32(0.7122), np.float32(0.848)] 
2025-02-24 02:49:59.615445: Epoch time: 39.42 s 
2025-02-24 02:50:00.140074:  
2025-02-24 02:50:00.144818: Epoch 188 
2025-02-24 02:50:00.148329: Current learning rate: 0.00285 
2025-02-24 02:50:39.545756: train_loss -0.7802 
2025-02-24 02:50:39.552272: val_loss -0.6464 
2025-02-24 02:50:39.559793: Pseudo dice [np.float32(0.8421), np.float32(0.7294), np.float32(0.875)] 
2025-02-24 02:50:39.566307: Epoch time: 39.41 s 
2025-02-24 02:50:40.094307:  
2025-02-24 02:50:40.099836: Epoch 189 
2025-02-24 02:50:40.103460: Current learning rate: 0.00281 
2025-02-24 02:51:19.468386: train_loss -0.7811 
2025-02-24 02:51:19.474953: val_loss -0.6416 
2025-02-24 02:51:19.479547: Pseudo dice [np.float32(0.8428), np.float32(0.6872), np.float32(0.864)] 
2025-02-24 02:51:19.485215: Epoch time: 39.38 s 
2025-02-24 02:51:20.008190:  
2025-02-24 02:51:20.013213: Epoch 190 
2025-02-24 02:51:20.017267: Current learning rate: 0.00277 
2025-02-24 02:51:59.429052: train_loss -0.7826 
2025-02-24 02:51:59.436577: val_loss -0.6337 
2025-02-24 02:51:59.441591: Pseudo dice [np.float32(0.835), np.float32(0.7166), np.float32(0.8728)] 
2025-02-24 02:51:59.447613: Epoch time: 39.42 s 
2025-02-24 02:52:00.117424:  
2025-02-24 02:52:00.123442: Epoch 191 
2025-02-24 02:52:00.126954: Current learning rate: 0.00273 
2025-02-24 02:52:39.553880: train_loss -0.7727 
2025-02-24 02:52:39.560403: val_loss -0.6744 
2025-02-24 02:52:39.563915: Pseudo dice [np.float32(0.8379), np.float32(0.7543), np.float32(0.8696)] 
2025-02-24 02:52:39.567422: Epoch time: 39.44 s 
2025-02-24 02:52:39.570434: Yayy! New best EMA pseudo Dice: 0.8054999709129333 
2025-02-24 02:52:40.241452:  
2025-02-24 02:52:40.247006: Epoch 192 
2025-02-24 02:52:40.249547: Current learning rate: 0.00268 
2025-02-24 02:53:19.598972: train_loss -0.7794 
2025-02-24 02:53:19.605081: val_loss -0.6485 
2025-02-24 02:53:19.608645: Pseudo dice [np.float32(0.8308), np.float32(0.6936), np.float32(0.8677)] 
2025-02-24 02:53:19.612214: Epoch time: 39.36 s 
2025-02-24 02:53:20.135860:  
2025-02-24 02:53:20.141935: Epoch 193 
2025-02-24 02:53:20.145552: Current learning rate: 0.00264 
2025-02-24 02:53:59.551802: train_loss -0.779 
2025-02-24 02:53:59.558822: val_loss -0.6122 
2025-02-24 02:53:59.561833: Pseudo dice [np.float32(0.8243), np.float32(0.7305), np.float32(0.8589)] 
2025-02-24 02:53:59.566461: Epoch time: 39.42 s 
2025-02-24 02:54:00.093097:  
2025-02-24 02:54:00.099662: Epoch 194 
2025-02-24 02:54:00.102216: Current learning rate: 0.0026 
2025-02-24 02:54:39.485887: train_loss -0.7794 
2025-02-24 02:54:39.492024: val_loss -0.6516 
2025-02-24 02:54:39.496566: Pseudo dice [np.float32(0.8407), np.float32(0.72), np.float32(0.8638)] 
2025-02-24 02:54:39.499616: Epoch time: 39.39 s 
2025-02-24 02:54:40.029397:  
2025-02-24 02:54:40.035425: Epoch 195 
2025-02-24 02:54:40.037932: Current learning rate: 0.00256 
2025-02-24 02:55:19.472009: train_loss -0.7872 
2025-02-24 02:55:19.477147: val_loss -0.6574 
2025-02-24 02:55:19.483237: Pseudo dice [np.float32(0.8235), np.float32(0.6944), np.float32(0.8698)] 
2025-02-24 02:55:19.486786: Epoch time: 39.44 s 
2025-02-24 02:55:20.017181:  
2025-02-24 02:55:20.022716: Epoch 196 
2025-02-24 02:55:20.026298: Current learning rate: 0.00252 
2025-02-24 02:55:59.369597: train_loss -0.7864 
2025-02-24 02:55:59.374672: val_loss -0.6578 
2025-02-24 02:55:59.378821: Pseudo dice [np.float32(0.8281), np.float32(0.735), np.float32(0.8701)] 
2025-02-24 02:55:59.382389: Epoch time: 39.35 s 
2025-02-24 02:55:59.906434:  
2025-02-24 02:55:59.912953: Epoch 197 
2025-02-24 02:55:59.917975: Current learning rate: 0.00248 
2025-02-24 02:56:39.346076: train_loss -0.7847 
2025-02-24 02:56:39.352596: val_loss -0.6611 
2025-02-24 02:56:39.357111: Pseudo dice [np.float32(0.8329), np.float32(0.7154), np.float32(0.8722)] 
2025-02-24 02:56:39.361127: Epoch time: 39.44 s 
2025-02-24 02:56:39.890789:  
2025-02-24 02:56:39.895835: Epoch 198 
2025-02-24 02:56:39.899345: Current learning rate: 0.00243 
2025-02-24 02:57:19.370495: train_loss -0.7772 
2025-02-24 02:57:19.377096: val_loss -0.6523 
2025-02-24 02:57:19.381719: Pseudo dice [np.float32(0.8201), np.float32(0.7445), np.float32(0.875)] 
2025-02-24 02:57:19.386307: Epoch time: 39.48 s 
2025-02-24 02:57:19.392047: Yayy! New best EMA pseudo Dice: 0.805899977684021 
2025-02-24 02:57:20.216363:  
2025-02-24 02:57:20.221524: Epoch 199 
2025-02-24 02:57:20.225102: Current learning rate: 0.00239 
2025-02-24 02:57:59.590409: train_loss -0.7844 
2025-02-24 02:57:59.596423: val_loss -0.6671 
2025-02-24 02:57:59.601943: Pseudo dice [np.float32(0.8243), np.float32(0.7356), np.float32(0.8694)] 
2025-02-24 02:57:59.606960: Epoch time: 39.38 s 
2025-02-24 02:57:59.756412: Yayy! New best EMA pseudo Dice: 0.8062000274658203 
2025-02-24 02:58:00.447330:  
2025-02-24 02:58:00.453418: Epoch 200 
2025-02-24 02:58:00.456465: Current learning rate: 0.00235 
2025-02-24 02:58:39.836755: train_loss -0.7892 
2025-02-24 02:58:39.844275: val_loss -0.6285 
2025-02-24 02:58:39.849297: Pseudo dice [np.float32(0.8346), np.float32(0.7086), np.float32(0.8643)] 
2025-02-24 02:58:39.855810: Epoch time: 39.39 s 
2025-02-24 02:58:40.387686:  
2025-02-24 02:58:40.393624: Epoch 201 
2025-02-24 02:58:40.397631: Current learning rate: 0.00231 
2025-02-24 02:59:19.816226: train_loss -0.7846 
2025-02-24 02:59:19.821924: val_loss -0.617 
2025-02-24 02:59:19.825958: Pseudo dice [np.float32(0.8196), np.float32(0.6984), np.float32(0.853)] 
2025-02-24 02:59:19.829525: Epoch time: 39.43 s 
2025-02-24 02:59:20.361667:  
2025-02-24 02:59:20.367706: Epoch 202 
2025-02-24 02:59:20.371223: Current learning rate: 0.00226 
2025-02-24 03:00:00.054897: train_loss -0.7951 
2025-02-24 03:00:00.061412: val_loss -0.632 
2025-02-24 03:00:00.067430: Pseudo dice [np.float32(0.8171), np.float32(0.723), np.float32(0.8647)] 
2025-02-24 03:00:00.073948: Epoch time: 39.69 s 
2025-02-24 03:00:00.607887:  
2025-02-24 03:00:00.613450: Epoch 203 
2025-02-24 03:00:00.615994: Current learning rate: 0.00222 
2025-02-24 03:00:39.970270: train_loss -0.7915 
2025-02-24 03:00:39.977798: val_loss -0.6473 
2025-02-24 03:00:39.982816: Pseudo dice [np.float32(0.833), np.float32(0.7275), np.float32(0.8714)] 
2025-02-24 03:00:39.986826: Epoch time: 39.36 s 
2025-02-24 03:00:40.518255:  
2025-02-24 03:00:40.524329: Epoch 204 
2025-02-24 03:00:40.527383: Current learning rate: 0.00218 
2025-02-24 03:01:19.919684: train_loss -0.7848 
2025-02-24 03:01:19.926806: val_loss -0.621 
2025-02-24 03:01:19.932925: Pseudo dice [np.float32(0.8128), np.float32(0.7131), np.float32(0.8688)] 
2025-02-24 03:01:19.939046: Epoch time: 39.4 s 
2025-02-24 03:01:20.468784:  
2025-02-24 03:01:20.473808: Epoch 205 
2025-02-24 03:01:20.477317: Current learning rate: 0.00214 
2025-02-24 03:01:59.866106: train_loss -0.7881 
2025-02-24 03:01:59.872627: val_loss -0.6601 
2025-02-24 03:01:59.876132: Pseudo dice [np.float32(0.8377), np.float32(0.7289), np.float32(0.8766)] 
2025-02-24 03:01:59.879139: Epoch time: 39.4 s 
2025-02-24 03:02:00.528023:  
2025-02-24 03:02:00.533613: Epoch 206 
2025-02-24 03:02:00.538126: Current learning rate: 0.00209 
2025-02-24 03:02:39.904103: train_loss -0.7891 
2025-02-24 03:02:39.910801: val_loss -0.6849 
2025-02-24 03:02:39.914817: Pseudo dice [np.float32(0.8418), np.float32(0.7633), np.float32(0.8861)] 
2025-02-24 03:02:39.918329: Epoch time: 39.38 s 
2025-02-24 03:02:39.923349: Yayy! New best EMA pseudo Dice: 0.8076000213623047 
2025-02-24 03:02:40.572534:  
2025-02-24 03:02:40.578090: Epoch 207 
2025-02-24 03:02:40.582208: Current learning rate: 0.00205 
2025-02-24 03:03:20.000727: train_loss -0.7874 
2025-02-24 03:03:20.006529: val_loss -0.6462 
2025-02-24 03:03:20.011038: Pseudo dice [np.float32(0.8154), np.float32(0.7278), np.float32(0.8645)] 
2025-02-24 03:03:20.014050: Epoch time: 39.43 s 
2025-02-24 03:03:20.519313:  
2025-02-24 03:03:20.525331: Epoch 208 
2025-02-24 03:03:20.528839: Current learning rate: 0.00201 
2025-02-24 03:03:59.877870: train_loss -0.7883 
2025-02-24 03:03:59.885480: val_loss -0.6367 
2025-02-24 03:03:59.890051: Pseudo dice [np.float32(0.8207), np.float32(0.6727), np.float32(0.8668)] 
2025-02-24 03:03:59.893114: Epoch time: 39.36 s 
2025-02-24 03:04:00.396145:  
2025-02-24 03:04:00.401230: Epoch 209 
2025-02-24 03:04:00.405254: Current learning rate: 0.00196 
2025-02-24 03:04:39.780805: train_loss -0.7874 
2025-02-24 03:04:39.788045: val_loss -0.6429 
2025-02-24 03:04:39.791100: Pseudo dice [np.float32(0.8321), np.float32(0.6951), np.float32(0.8662)] 
2025-02-24 03:04:39.795686: Epoch time: 39.39 s 
2025-02-24 03:04:40.301485:  
2025-02-24 03:04:40.306497: Epoch 210 
2025-02-24 03:04:40.310005: Current learning rate: 0.00192 
2025-02-24 03:05:19.630695: train_loss -0.7867 
2025-02-24 03:05:19.637213: val_loss -0.6485 
2025-02-24 03:05:19.642227: Pseudo dice [np.float32(0.826), np.float32(0.7147), np.float32(0.8549)] 
2025-02-24 03:05:19.648246: Epoch time: 39.33 s 
2025-02-24 03:05:20.154724:  
2025-02-24 03:05:20.160333: Epoch 211 
2025-02-24 03:05:20.163366: Current learning rate: 0.00188 
2025-02-24 03:05:59.487629: train_loss -0.7884 
2025-02-24 03:05:59.494679: val_loss -0.6432 
2025-02-24 03:05:59.500729: Pseudo dice [np.float32(0.8286), np.float32(0.7171), np.float32(0.8619)] 
2025-02-24 03:05:59.507415: Epoch time: 39.33 s 
2025-02-24 03:06:00.007896:  
2025-02-24 03:06:00.014038: Epoch 212 
2025-02-24 03:06:00.019055: Current learning rate: 0.00184 
2025-02-24 03:06:39.389353: train_loss -0.7917 
2025-02-24 03:06:39.396052: val_loss -0.6318 
2025-02-24 03:06:39.400604: Pseudo dice [np.float32(0.8383), np.float32(0.7131), np.float32(0.8602)] 
2025-02-24 03:06:39.406263: Epoch time: 39.38 s 
2025-02-24 03:06:39.910813:  
2025-02-24 03:06:39.915827: Epoch 213 
2025-02-24 03:06:39.919339: Current learning rate: 0.00179 
2025-02-24 03:07:19.337178: train_loss -0.789 
2025-02-24 03:07:19.344735: val_loss -0.6609 
2025-02-24 03:07:19.349244: Pseudo dice [np.float32(0.8398), np.float32(0.7109), np.float32(0.8796)] 
2025-02-24 03:07:19.353259: Epoch time: 39.43 s 
2025-02-24 03:07:20.002974:  
2025-02-24 03:07:20.009015: Epoch 214 
2025-02-24 03:07:20.012683: Current learning rate: 0.00175 
2025-02-24 03:07:59.347763: train_loss -0.7934 
2025-02-24 03:07:59.354882: val_loss -0.6489 
2025-02-24 03:07:59.358269: Pseudo dice [np.float32(0.8226), np.float32(0.7105), np.float32(0.8604)] 
2025-02-24 03:07:59.361783: Epoch time: 39.35 s 
2025-02-24 03:07:59.859731:  
2025-02-24 03:07:59.865247: Epoch 215 
2025-02-24 03:07:59.868757: Current learning rate: 0.0017 
2025-02-24 03:08:39.208157: train_loss -0.7843 
2025-02-24 03:08:39.215263: val_loss -0.6716 
2025-02-24 03:08:39.221338: Pseudo dice [np.float32(0.8561), np.float32(0.6801), np.float32(0.8871)] 
2025-02-24 03:08:39.224408: Epoch time: 39.35 s 
2025-02-24 03:08:39.726297:  
2025-02-24 03:08:39.731861: Epoch 216 
2025-02-24 03:08:39.734904: Current learning rate: 0.00166 
2025-02-24 03:09:19.198911: train_loss -0.7882 
2025-02-24 03:09:19.205426: val_loss -0.6443 
2025-02-24 03:09:19.210440: Pseudo dice [np.float32(0.8243), np.float32(0.7326), np.float32(0.8809)] 
2025-02-24 03:09:19.215973: Epoch time: 39.47 s 
2025-02-24 03:09:19.713629:  
2025-02-24 03:09:19.720201: Epoch 217 
2025-02-24 03:09:19.723747: Current learning rate: 0.00162 
2025-02-24 03:09:59.101596: train_loss -0.7942 
2025-02-24 03:09:59.109118: val_loss -0.6528 
2025-02-24 03:09:59.114132: Pseudo dice [np.float32(0.8291), np.float32(0.7286), np.float32(0.8885)] 
2025-02-24 03:09:59.118141: Epoch time: 39.39 s 
2025-02-24 03:09:59.618864:  
2025-02-24 03:09:59.623880: Epoch 218 
2025-02-24 03:09:59.627392: Current learning rate: 0.00157 
2025-02-24 03:10:38.999144: train_loss -0.7881 
2025-02-24 03:10:39.007334: val_loss -0.6244 
2025-02-24 03:10:39.012427: Pseudo dice [np.float32(0.8155), np.float32(0.703), np.float32(0.8556)] 
2025-02-24 03:10:39.016494: Epoch time: 39.38 s 
2025-02-24 03:10:39.512901:  
2025-02-24 03:10:39.517931: Epoch 219 
2025-02-24 03:10:39.521530: Current learning rate: 0.00153 
2025-02-24 03:11:18.988019: train_loss -0.7871 
2025-02-24 03:11:18.994561: val_loss -0.6783 
2025-02-24 03:11:19.000593: Pseudo dice [np.float32(0.8477), np.float32(0.736), np.float32(0.8705)] 
2025-02-24 03:11:19.007135: Epoch time: 39.48 s 
2025-02-24 03:11:19.504923:  
2025-02-24 03:11:19.510446: Epoch 220 
2025-02-24 03:11:19.513957: Current learning rate: 0.00148 
2025-02-24 03:11:58.913614: train_loss -0.7912 
2025-02-24 03:11:58.922328: val_loss -0.624 
2025-02-24 03:11:58.928868: Pseudo dice [np.float32(0.8358), np.float32(0.7025), np.float32(0.8663)] 
2025-02-24 03:11:58.936172: Epoch time: 39.41 s 
2025-02-24 03:11:59.434750:  
2025-02-24 03:11:59.439786: Epoch 221 
2025-02-24 03:11:59.443305: Current learning rate: 0.00144 
2025-02-24 03:12:38.812940: train_loss -0.788 
2025-02-24 03:12:38.818990: val_loss -0.5864 
2025-02-24 03:12:38.823035: Pseudo dice [np.float32(0.826), np.float32(0.6336), np.float32(0.8508)] 
2025-02-24 03:12:38.829093: Epoch time: 39.38 s 
2025-02-24 03:12:39.332615:  
2025-02-24 03:12:39.338131: Epoch 222 
2025-02-24 03:12:39.341646: Current learning rate: 0.00139 
2025-02-24 03:13:18.707773: train_loss -0.7913 
2025-02-24 03:13:18.714815: val_loss -0.6609 
2025-02-24 03:13:18.719846: Pseudo dice [np.float32(0.8276), np.float32(0.7702), np.float32(0.8724)] 
2025-02-24 03:13:18.724690: Epoch time: 39.38 s 
2025-02-24 03:13:19.375262:  
2025-02-24 03:13:19.381838: Epoch 223 
2025-02-24 03:13:19.384917: Current learning rate: 0.00135 
2025-02-24 03:13:58.767561: train_loss -0.7948 
2025-02-24 03:13:58.773619: val_loss -0.6827 
2025-02-24 03:13:58.778512: Pseudo dice [np.float32(0.8483), np.float32(0.7399), np.float32(0.8546)] 
2025-02-24 03:13:58.784128: Epoch time: 39.39 s 
2025-02-24 03:13:59.279736:  
2025-02-24 03:13:59.285315: Epoch 224 
2025-02-24 03:13:59.288873: Current learning rate: 0.0013 
2025-02-24 03:14:38.708693: train_loss -0.7882 
2025-02-24 03:14:38.716210: val_loss -0.6048 
2025-02-24 03:14:38.722723: Pseudo dice [np.float32(0.7983), np.float32(0.6892), np.float32(0.8607)] 
2025-02-24 03:14:38.728736: Epoch time: 39.43 s 
2025-02-24 03:14:39.232997:  
2025-02-24 03:14:39.238572: Epoch 225 
2025-02-24 03:14:39.242138: Current learning rate: 0.00126 
2025-02-24 03:15:18.625840: train_loss -0.7887 
2025-02-24 03:15:18.632869: val_loss -0.658 
2025-02-24 03:15:18.637508: Pseudo dice [np.float32(0.834), np.float32(0.7576), np.float32(0.862)] 
2025-02-24 03:15:18.642528: Epoch time: 39.39 s 
2025-02-24 03:15:19.146408:  
2025-02-24 03:15:19.151930: Epoch 226 
2025-02-24 03:15:19.155446: Current learning rate: 0.00121 
2025-02-24 03:15:58.542538: train_loss -0.7882 
2025-02-24 03:15:58.549585: val_loss -0.6761 
2025-02-24 03:15:58.554598: Pseudo dice [np.float32(0.8226), np.float32(0.7449), np.float32(0.8671)] 
2025-02-24 03:15:58.561612: Epoch time: 39.4 s 
2025-02-24 03:15:59.061840:  
2025-02-24 03:15:59.067884: Epoch 227 
2025-02-24 03:15:59.071440: Current learning rate: 0.00117 
2025-02-24 03:16:38.438235: train_loss -0.7878 
2025-02-24 03:16:38.444864: val_loss -0.6331 
2025-02-24 03:16:38.449378: Pseudo dice [np.float32(0.8111), np.float32(0.6942), np.float32(0.858)] 
2025-02-24 03:16:38.453397: Epoch time: 39.38 s 
2025-02-24 03:16:38.954499:  
2025-02-24 03:16:38.959513: Epoch 228 
2025-02-24 03:16:38.963024: Current learning rate: 0.00112 
2025-02-24 03:17:18.348204: train_loss -0.7921 
2025-02-24 03:17:18.354773: val_loss -0.6244 
2025-02-24 03:17:18.360288: Pseudo dice [np.float32(0.8211), np.float32(0.6863), np.float32(0.8637)] 
2025-02-24 03:17:18.364796: Epoch time: 39.39 s 
2025-02-24 03:17:18.865491:  
2025-02-24 03:17:18.871065: Epoch 229 
2025-02-24 03:17:18.875116: Current learning rate: 0.00108 
2025-02-24 03:17:58.279101: train_loss -0.7908 
2025-02-24 03:17:58.286268: val_loss -0.6748 
2025-02-24 03:17:58.289320: Pseudo dice [np.float32(0.8478), np.float32(0.723), np.float32(0.8762)] 
2025-02-24 03:17:58.294423: Epoch time: 39.41 s 
2025-02-24 03:17:58.801481:  
2025-02-24 03:17:58.807035: Epoch 230 
2025-02-24 03:17:58.810161: Current learning rate: 0.00103 
2025-02-24 03:18:38.200327: train_loss -0.7967 
2025-02-24 03:18:38.205842: val_loss -0.6469 
2025-02-24 03:18:38.210857: Pseudo dice [np.float32(0.8181), np.float32(0.7159), np.float32(0.8722)] 
2025-02-24 03:18:38.216882: Epoch time: 39.4 s 
2025-02-24 03:18:38.865577:  
2025-02-24 03:18:38.871092: Epoch 231 
2025-02-24 03:18:38.874602: Current learning rate: 0.00098 
2025-02-24 03:19:18.255257: train_loss -0.7922 
2025-02-24 03:19:18.262355: val_loss -0.6365 
2025-02-24 03:19:18.267457: Pseudo dice [np.float32(0.8161), np.float32(0.7049), np.float32(0.8683)] 
2025-02-24 03:19:18.272557: Epoch time: 39.39 s 
2025-02-24 03:19:18.773059:  
2025-02-24 03:19:18.778133: Epoch 232 
2025-02-24 03:19:18.781680: Current learning rate: 0.00094 
2025-02-24 03:19:58.184225: train_loss -0.7925 
2025-02-24 03:19:58.190885: val_loss -0.6514 
2025-02-24 03:19:58.195990: Pseudo dice [np.float32(0.8285), np.float32(0.6985), np.float32(0.8502)] 
2025-02-24 03:19:58.202125: Epoch time: 39.41 s 
2025-02-24 03:19:58.701006:  
2025-02-24 03:19:58.707066: Epoch 233 
2025-02-24 03:19:58.710095: Current learning rate: 0.00089 
2025-02-24 03:20:38.079789: train_loss -0.7924 
2025-02-24 03:20:38.085810: val_loss -0.6509 
2025-02-24 03:20:38.089824: Pseudo dice [np.float32(0.845), np.float32(0.7414), np.float32(0.861)] 
2025-02-24 03:20:38.093338: Epoch time: 39.38 s 
2025-02-24 03:20:38.589771:  
2025-02-24 03:20:38.594783: Epoch 234 
2025-02-24 03:20:38.598291: Current learning rate: 0.00084 
2025-02-24 03:21:17.992061: train_loss -0.7939 
2025-02-24 03:21:17.998610: val_loss -0.6593 
2025-02-24 03:21:18.003620: Pseudo dice [np.float32(0.8442), np.float32(0.6957), np.float32(0.8782)] 
2025-02-24 03:21:18.008129: Epoch time: 39.4 s 
2025-02-24 03:21:18.506543:  
2025-02-24 03:21:18.512058: Epoch 235 
2025-02-24 03:21:18.515570: Current learning rate: 0.00079 
2025-02-24 03:21:57.891810: train_loss -0.7908 
2025-02-24 03:21:57.899353: val_loss -0.6512 
2025-02-24 03:21:57.905388: Pseudo dice [np.float32(0.8238), np.float32(0.7521), np.float32(0.8733)] 
2025-02-24 03:21:57.912056: Epoch time: 39.39 s 
2025-02-24 03:21:58.417980:  
2025-02-24 03:21:58.423553: Epoch 236 
2025-02-24 03:21:58.426587: Current learning rate: 0.00075 
2025-02-24 03:22:37.829842: train_loss -0.7944 
2025-02-24 03:22:37.836568: val_loss -0.6762 
2025-02-24 03:22:37.840144: Pseudo dice [np.float32(0.8474), np.float32(0.7737), np.float32(0.8776)] 
2025-02-24 03:22:37.844719: Epoch time: 39.41 s 
2025-02-24 03:22:38.340592:  
2025-02-24 03:22:38.346108: Epoch 237 
2025-02-24 03:22:38.349618: Current learning rate: 0.0007 
2025-02-24 03:23:17.800645: train_loss -0.796 
2025-02-24 03:23:17.806680: val_loss -0.6493 
2025-02-24 03:23:17.809864: Pseudo dice [np.float32(0.8312), np.float32(0.7147), np.float32(0.8563)] 
2025-02-24 03:23:17.813889: Epoch time: 39.46 s 
2025-02-24 03:23:18.321684:  
2025-02-24 03:23:18.327258: Epoch 238 
2025-02-24 03:23:18.331280: Current learning rate: 0.00065 
2025-02-24 03:23:57.702746: train_loss -0.7917 
2025-02-24 03:23:57.709795: val_loss -0.6767 
2025-02-24 03:23:57.714356: Pseudo dice [np.float32(0.8488), np.float32(0.7548), np.float32(0.8682)] 
2025-02-24 03:23:57.720010: Epoch time: 39.38 s 
2025-02-24 03:23:57.726653: Yayy! New best EMA pseudo Dice: 0.8084999918937683 
2025-02-24 03:23:58.366368:  
2025-02-24 03:23:58.371884: Epoch 239 
2025-02-24 03:23:58.375394: Current learning rate: 0.0006 
2025-02-24 03:24:37.749868: train_loss -0.8014 
2025-02-24 03:24:37.754960: val_loss -0.6257 
2025-02-24 03:24:37.758501: Pseudo dice [np.float32(0.8252), np.float32(0.707), np.float32(0.8564)] 
2025-02-24 03:24:37.763613: Epoch time: 39.38 s 
2025-02-24 03:24:38.425467:  
2025-02-24 03:24:38.430479: Epoch 240 
2025-02-24 03:24:38.433988: Current learning rate: 0.00055 
2025-02-24 03:25:17.840908: train_loss -0.7945 
2025-02-24 03:25:17.847425: val_loss -0.6366 
2025-02-24 03:25:17.852434: Pseudo dice [np.float32(0.8286), np.float32(0.7209), np.float32(0.8872)] 
2025-02-24 03:25:17.858451: Epoch time: 39.42 s 
2025-02-24 03:25:18.367034:  
2025-02-24 03:25:18.372571: Epoch 241 
2025-02-24 03:25:18.376131: Current learning rate: 0.0005 
2025-02-24 03:25:57.867125: train_loss -0.8017 
2025-02-24 03:25:57.872708: val_loss -0.6494 
2025-02-24 03:25:57.876770: Pseudo dice [np.float32(0.8347), np.float32(0.6974), np.float32(0.8739)] 
2025-02-24 03:25:57.879835: Epoch time: 39.5 s 
2025-02-24 03:25:58.391430:  
2025-02-24 03:25:58.396611: Epoch 242 
2025-02-24 03:25:58.400144: Current learning rate: 0.00045 
2025-02-24 03:26:37.799007: train_loss -0.7952 
2025-02-24 03:26:37.805582: val_loss -0.6691 
2025-02-24 03:26:37.809161: Pseudo dice [np.float32(0.8359), np.float32(0.7467), np.float32(0.8717)] 
2025-02-24 03:26:37.812677: Epoch time: 39.41 s 
2025-02-24 03:26:38.320374:  
2025-02-24 03:26:38.325387: Epoch 243 
2025-02-24 03:26:38.328897: Current learning rate: 0.0004 
2025-02-24 03:27:17.734901: train_loss -0.7949 
2025-02-24 03:27:17.741920: val_loss -0.6396 
2025-02-24 03:27:17.745935: Pseudo dice [np.float32(0.839), np.float32(0.7049), np.float32(0.861)] 
2025-02-24 03:27:17.752459: Epoch time: 39.42 s 
2025-02-24 03:27:18.263645:  
2025-02-24 03:27:18.269176: Epoch 244 
2025-02-24 03:27:18.272714: Current learning rate: 0.00035 
2025-02-24 03:27:57.591022: train_loss -0.8014 
2025-02-24 03:27:57.597592: val_loss -0.6427 
2025-02-24 03:27:57.602186: Pseudo dice [np.float32(0.8412), np.float32(0.7099), np.float32(0.8644)] 
2025-02-24 03:27:57.607810: Epoch time: 39.33 s 
2025-02-24 03:27:58.117347:  
2025-02-24 03:27:58.122392: Epoch 245 
2025-02-24 03:27:58.125985: Current learning rate: 0.0003 
2025-02-24 03:28:37.597453: train_loss -0.8012 
2025-02-24 03:28:37.603977: val_loss -0.6676 
2025-02-24 03:28:37.607491: Pseudo dice [np.float32(0.8563), np.float32(0.7364), np.float32(0.8732)] 
2025-02-24 03:28:37.611502: Epoch time: 39.48 s 
2025-02-24 03:28:37.616014: Yayy! New best EMA pseudo Dice: 0.8087999820709229 
2025-02-24 03:28:38.267426:  
2025-02-24 03:28:38.272863: Epoch 246 
2025-02-24 03:28:38.276385: Current learning rate: 0.00024 
2025-02-24 03:29:17.667232: train_loss -0.7996 
2025-02-24 03:29:17.673894: val_loss -0.6372 
2025-02-24 03:29:17.678911: Pseudo dice [np.float32(0.8268), np.float32(0.7008), np.float32(0.8696)] 
2025-02-24 03:29:17.681418: Epoch time: 39.4 s 
2025-02-24 03:29:18.194653:  
2025-02-24 03:29:18.200209: Epoch 247 
2025-02-24 03:29:18.203874: Current learning rate: 0.00019 
2025-02-24 03:29:57.621089: train_loss -0.7945 
2025-02-24 03:29:57.629133: val_loss -0.6198 
2025-02-24 03:29:57.635699: Pseudo dice [np.float32(0.8329), np.float32(0.7037), np.float32(0.8671)] 
2025-02-24 03:29:57.641722: Epoch time: 39.43 s 
2025-02-24 03:29:58.313679:  
2025-02-24 03:29:58.319240: Epoch 248 
2025-02-24 03:29:58.323324: Current learning rate: 0.00013 
2025-02-24 03:30:37.722625: train_loss -0.8038 
2025-02-24 03:30:37.728298: val_loss -0.6122 
2025-02-24 03:30:37.731856: Pseudo dice [np.float32(0.8264), np.float32(0.6823), np.float32(0.8698)] 
2025-02-24 03:30:37.734056: Epoch time: 39.41 s 
2025-02-24 03:30:38.245360:  
2025-02-24 03:30:38.250945: Epoch 249 
2025-02-24 03:30:38.254590: Current learning rate: 7e-05 
2025-02-24 03:31:17.675949: train_loss -0.7922 
2025-02-24 03:31:17.682477: val_loss -0.6542 
2025-02-24 03:31:17.689000: Pseudo dice [np.float32(0.8454), np.float32(0.7013), np.float32(0.8756)] 
2025-02-24 03:31:17.696030: Epoch time: 39.43 s 
2025-02-24 03:31:18.398697: Training done. 
2025-02-24 03:31:18.437703: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-02-24 03:31:18.450703: The split file contains 5 splits. 
2025-02-24 03:31:18.455702: Desired fold for training: 0 
2025-02-24 03:31:18.460705: This split has 387 training and 97 validation cases. 
2025-02-24 03:31:18.466703: predicting BRATS_010 
2025-02-24 03:31:18.472702: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2025-02-24 03:31:20.485368: predicting BRATS_011 
2025-02-24 03:31:20.497368: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2025-02-24 03:31:21.835583: predicting BRATS_012 
2025-02-24 03:31:21.846586: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-02-24 03:31:23.201772: predicting BRATS_018 
2025-02-24 03:31:23.212772: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2025-02-24 03:31:24.598871: predicting BRATS_020 
2025-02-24 03:31:24.611380: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2025-02-24 03:31:25.956371: predicting BRATS_028 
2025-02-24 03:31:25.969370: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-02-24 03:31:27.304799: predicting BRATS_029 
2025-02-24 03:31:27.317799: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-02-24 03:31:28.678536: predicting BRATS_032 
2025-02-24 03:31:28.689539: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2025-02-24 03:31:30.020200: predicting BRATS_034 
2025-02-24 03:31:30.032201: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2025-02-24 03:31:31.392606: predicting BRATS_041 
2025-02-24 03:31:31.406114: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2025-02-24 03:31:32.776562: predicting BRATS_042 
2025-02-24 03:31:32.791564: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2025-02-24 03:31:34.178140: predicting BRATS_047 
2025-02-24 03:31:34.189139: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-02-24 03:31:35.576486: predicting BRATS_049 
2025-02-24 03:31:35.588487: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-02-24 03:31:36.925483: predicting BRATS_053 
2025-02-24 03:31:36.937482: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-02-24 03:31:38.311864: predicting BRATS_056 
2025-02-24 03:31:38.322865: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-02-24 03:31:39.667603: predicting BRATS_057 
2025-02-24 03:31:39.678602: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-02-24 03:31:41.017180: predicting BRATS_067 
2025-02-24 03:31:41.032179: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-02-24 03:31:42.378945: predicting BRATS_069 
2025-02-24 03:31:42.389945: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-02-24 03:31:43.732889: predicting BRATS_085 
2025-02-24 03:31:43.743890: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2025-02-24 03:31:44.457386: predicting BRATS_086 
2025-02-24 03:31:44.468388: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2025-02-24 03:31:45.806435: predicting BRATS_088 
2025-02-24 03:31:45.819942: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2025-02-24 03:31:47.171689: predicting BRATS_091 
2025-02-24 03:31:47.189688: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-02-24 03:31:48.589313: predicting BRATS_098 
2025-02-24 03:31:48.602316: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2025-02-24 03:31:49.941448: predicting BRATS_100 
2025-02-24 03:31:49.954450: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-02-24 03:31:50.662846: predicting BRATS_101 
2025-02-24 03:31:50.674845: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-02-24 03:31:51.369448: predicting BRATS_102 
2025-02-24 03:31:51.381447: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2025-02-24 03:31:52.720363: predicting BRATS_104 
2025-02-24 03:31:52.734361: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2025-02-24 03:31:54.070012: predicting BRATS_111 
2025-02-24 03:31:54.084012: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2025-02-24 03:31:55.417036: predicting BRATS_116 
2025-02-24 03:31:55.430036: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2025-02-24 03:31:56.767427: predicting BRATS_135 
2025-02-24 03:31:56.780426: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-02-24 03:31:58.119364: predicting BRATS_136 
2025-02-24 03:31:58.132361: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-02-24 03:31:59.486455: predicting BRATS_138 
2025-02-24 03:31:59.501454: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2025-02-24 03:32:00.852508: predicting BRATS_145 
2025-02-24 03:32:00.863507: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2025-02-24 03:32:02.204831: predicting BRATS_149 
2025-02-24 03:32:02.216830: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2025-02-24 03:32:03.595236: predicting BRATS_155 
2025-02-24 03:32:03.608240: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-02-24 03:32:04.966233: predicting BRATS_157 
2025-02-24 03:32:04.980233: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-02-24 03:32:06.315897: predicting BRATS_158 
2025-02-24 03:32:06.327406: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-02-24 03:32:07.666753: predicting BRATS_159 
2025-02-24 03:32:07.679751: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-02-24 03:32:09.034588: predicting BRATS_163 
2025-02-24 03:32:09.046587: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-02-24 03:32:10.423198: predicting BRATS_164 
2025-02-24 03:32:10.434703: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2025-02-24 03:32:11.775195: predicting BRATS_169 
2025-02-24 03:32:11.788197: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2025-02-24 03:32:13.127120: predicting BRATS_176 
2025-02-24 03:32:13.139124: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-02-24 03:32:14.477545: predicting BRATS_181 
2025-02-24 03:32:14.489545: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2025-02-24 03:32:15.826580: predicting BRATS_183 
2025-02-24 03:32:15.839780: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-02-24 03:32:17.199328: predicting BRATS_184 
2025-02-24 03:32:17.211327: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-02-24 03:32:18.576037: predicting BRATS_187 
2025-02-24 03:32:18.589036: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-02-24 03:32:19.947965: predicting BRATS_192 
2025-02-24 03:32:19.959966: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2025-02-24 03:32:21.312403: predicting BRATS_198 
2025-02-24 03:32:21.324405: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-02-24 03:32:22.674043: predicting BRATS_207 
2025-02-24 03:32:22.687044: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-02-24 03:32:24.047937: predicting BRATS_208 
2025-02-24 03:32:24.063937: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-02-24 03:32:25.410398: predicting BRATS_218 
2025-02-24 03:32:25.421400: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-02-24 03:32:26.763139: predicting BRATS_220 
2025-02-24 03:32:26.776139: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2025-02-24 03:32:28.135207: predicting BRATS_224 
2025-02-24 03:32:28.148717: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2025-02-24 03:32:29.534122: predicting BRATS_230 
2025-02-24 03:32:29.546627: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2025-02-24 03:32:30.938472: predicting BRATS_271 
2025-02-24 03:32:30.949476: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2025-02-24 03:32:32.288482: predicting BRATS_282 
2025-02-24 03:32:32.302482: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2025-02-24 03:32:33.655182: predicting BRATS_284 
2025-02-24 03:32:33.668183: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2025-02-24 03:32:35.016651: predicting BRATS_287 
2025-02-24 03:32:35.028654: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-02-24 03:32:36.396048: predicting BRATS_290 
2025-02-24 03:32:36.409049: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2025-02-24 03:32:37.760713: predicting BRATS_291 
2025-02-24 03:32:37.774712: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-02-24 03:32:39.118699: predicting BRATS_292 
2025-02-24 03:32:39.129702: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2025-02-24 03:32:40.462622: predicting BRATS_293 
2025-02-24 03:32:40.474623: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2025-02-24 03:32:41.851787: predicting BRATS_300 
2025-02-24 03:32:41.865787: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2025-02-24 03:32:43.254184: predicting BRATS_305 
2025-02-24 03:32:43.267184: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2025-02-24 03:32:44.638977: predicting BRATS_311 
2025-02-24 03:32:44.652485: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2025-02-24 03:32:45.996382: predicting BRATS_314 
2025-02-24 03:32:46.009381: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2025-02-24 03:32:47.371444: predicting BRATS_321 
2025-02-24 03:32:47.388448: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-02-24 03:32:48.746081: predicting BRATS_328 
2025-02-24 03:32:48.759584: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2025-02-24 03:32:49.448027: predicting BRATS_329 
2025-02-24 03:32:49.459026: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2025-02-24 03:32:50.795521: predicting BRATS_335 
2025-02-24 03:32:50.810521: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2025-02-24 03:32:52.159483: predicting BRATS_343 
2025-02-24 03:32:52.175486: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2025-02-24 03:32:53.524720: predicting BRATS_350 
2025-02-24 03:32:53.536723: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2025-02-24 03:32:54.279928: predicting BRATS_351 
2025-02-24 03:32:54.290929: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2025-02-24 03:32:54.982408: predicting BRATS_356 
2025-02-24 03:32:54.995409: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2025-02-24 03:32:55.689892: predicting BRATS_366 
2025-02-24 03:32:55.701892: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2025-02-24 03:32:57.059452: predicting BRATS_367 
2025-02-24 03:32:57.071453: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2025-02-24 03:32:58.434710: predicting BRATS_374 
2025-02-24 03:32:58.446713: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2025-02-24 03:32:59.795589: predicting BRATS_376 
2025-02-24 03:32:59.806589: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2025-02-24 03:33:01.166816: predicting BRATS_377 
2025-02-24 03:33:01.179817: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2025-02-24 03:33:02.571052: predicting BRATS_378 
2025-02-24 03:33:02.584051: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2025-02-24 03:33:03.937761: predicting BRATS_379 
2025-02-24 03:33:03.950766: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2025-02-24 03:33:05.296869: predicting BRATS_384 
2025-02-24 03:33:05.308870: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2025-02-24 03:33:06.644746: predicting BRATS_386 
2025-02-24 03:33:06.657746: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-02-24 03:33:08.018399: predicting BRATS_394 
2025-02-24 03:33:08.030398: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-02-24 03:33:09.367684: predicting BRATS_398 
2025-02-24 03:33:09.382684: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2025-02-24 03:33:10.730685: predicting BRATS_400 
2025-02-24 03:33:10.741684: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2025-02-24 03:33:12.098478: predicting BRATS_432 
2025-02-24 03:33:12.110476: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2025-02-24 03:33:13.465709: predicting BRATS_437 
2025-02-24 03:33:13.478710: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-02-24 03:33:14.883810: predicting BRATS_445 
2025-02-24 03:33:14.895808: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2025-02-24 03:33:16.230575: predicting BRATS_446 
2025-02-24 03:33:16.243577: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-02-24 03:33:17.620805: predicting BRATS_450 
2025-02-24 03:33:17.633804: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2025-02-24 03:33:19.002556: predicting BRATS_452 
2025-02-24 03:33:19.014555: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2025-02-24 03:33:20.356372: predicting BRATS_460 
2025-02-24 03:33:20.368883: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2025-02-24 03:33:21.742129: predicting BRATS_470 
2025-02-24 03:33:21.755133: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-02-24 03:33:23.144162: predicting BRATS_472 
2025-02-24 03:33:23.157165: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2025-02-24 03:33:24.513610: predicting BRATS_473 
2025-02-24 03:33:24.525610: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2025-02-24 03:33:25.216910: predicting BRATS_482 
2025-02-24 03:33:25.228911: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2025-02-24 03:33:33.737755: Validation complete 
2025-02-24 03:33:33.743755: Mean Validation Dice:  0.7215398004250685 
