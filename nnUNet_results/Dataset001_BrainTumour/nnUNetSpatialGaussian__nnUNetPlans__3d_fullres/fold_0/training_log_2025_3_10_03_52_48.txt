
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-10 03:52:48.404689: do_dummy_2d_data_aug: False 
2025-03-10 03:52:48.411690: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-10 03:52:48.418196: The split file contains 5 splits. 
2025-03-10 03:52:48.421197: Desired fold for training: 0 
2025-03-10 03:52:48.424197: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2025-03-10 03:53:22.479200: unpacking dataset... 
2025-03-10 03:53:23.143383: unpacking done... 
2025-03-10 03:53:26.897317:  
2025-03-10 03:53:26.902344: Epoch 0 
2025-03-10 03:53:26.905856: Current learning rate: 0.01 
2025-03-10 03:54:49.419272: train_loss -0.3087 
2025-03-10 03:54:49.426794: val_loss -0.4664 
2025-03-10 03:54:49.430803: Pseudo dice [np.float32(0.7025), np.float32(0.5725), np.float32(0.7716)] 
2025-03-10 03:54:49.434315: Epoch time: 82.52 s 
2025-03-10 03:54:49.437828: Yayy! New best EMA pseudo Dice: 0.682200014591217 
2025-03-10 03:54:50.100716:  
2025-03-10 03:54:50.105727: Epoch 1 
2025-03-10 03:54:50.109237: Current learning rate: 0.00991 
2025-03-10 03:56:05.397409: train_loss -0.5317 
2025-03-10 03:56:05.404988: val_loss -0.5335 
2025-03-10 03:56:05.408498: Pseudo dice [np.float32(0.7566), np.float32(0.5655), np.float32(0.8137)] 
2025-03-10 03:56:05.411510: Epoch time: 75.3 s 
2025-03-10 03:56:05.415024: Yayy! New best EMA pseudo Dice: 0.6851000189781189 
2025-03-10 03:56:06.125862:  
2025-03-10 03:56:06.129377: Epoch 2 
2025-03-10 03:56:06.132884: Current learning rate: 0.00982 
2025-03-10 03:57:21.399453: train_loss -0.5845 
2025-03-10 03:57:21.406719: val_loss -0.5609 
2025-03-10 03:57:21.410739: Pseudo dice [np.float32(0.7677), np.float32(0.6366), np.float32(0.813)] 
2025-03-10 03:57:21.414254: Epoch time: 75.27 s 
2025-03-10 03:57:21.417772: Yayy! New best EMA pseudo Dice: 0.690500020980835 
2025-03-10 03:57:22.160787:  
2025-03-10 03:57:22.166406: Epoch 3 
2025-03-10 03:57:22.169448: Current learning rate: 0.00973 
2025-03-10 03:58:37.577776: train_loss -0.6142 
2025-03-10 03:58:37.584477: val_loss -0.5548 
2025-03-10 03:58:37.588085: Pseudo dice [np.float32(0.7808), np.float32(0.6092), np.float32(0.8317)] 
2025-03-10 03:58:37.591740: Epoch time: 75.42 s 
2025-03-10 03:58:37.595272: Yayy! New best EMA pseudo Dice: 0.6955000162124634 
2025-03-10 03:58:38.322345:  
2025-03-10 03:58:38.327389: Epoch 4 
2025-03-10 03:58:38.332000: Current learning rate: 0.00964 
2025-03-10 03:59:53.415900: train_loss -0.6289 
2025-03-10 03:59:53.422266: val_loss -0.6043 
2025-03-10 03:59:53.425675: Pseudo dice [np.float32(0.8001), np.float32(0.6708), np.float32(0.8325)] 
2025-03-10 03:59:53.429185: Epoch time: 75.09 s 
2025-03-10 03:59:53.431691: Yayy! New best EMA pseudo Dice: 0.7027999758720398 
2025-03-10 03:59:54.307860:  
2025-03-10 03:59:54.312872: Epoch 5 
2025-03-10 03:59:54.315881: Current learning rate: 0.00955 
2025-03-10 04:01:09.560169: train_loss -0.6352 
2025-03-10 04:01:09.566735: val_loss -0.5848 
2025-03-10 04:01:09.570281: Pseudo dice [np.float32(0.7862), np.float32(0.6769), np.float32(0.8205)] 
2025-03-10 04:01:09.573817: Epoch time: 75.25 s 
2025-03-10 04:01:09.577350: Yayy! New best EMA pseudo Dice: 0.7085999846458435 
2025-03-10 04:01:10.293841:  
2025-03-10 04:01:10.301286: Epoch 6 
2025-03-10 04:01:10.303793: Current learning rate: 0.00946 
2025-03-10 04:02:25.493558: train_loss -0.6472 
2025-03-10 04:02:25.501077: val_loss -0.5971 
2025-03-10 04:02:25.504137: Pseudo dice [np.float32(0.7938), np.float32(0.6536), np.float32(0.8248)] 
2025-03-10 04:02:25.507646: Epoch time: 75.2 s 
2025-03-10 04:02:25.510153: Yayy! New best EMA pseudo Dice: 0.7135000228881836 
2025-03-10 04:02:26.245894:  
2025-03-10 04:02:26.250692: Epoch 7 
2025-03-10 04:02:26.254204: Current learning rate: 0.00937 
2025-03-10 04:03:41.490064: train_loss -0.6529 
2025-03-10 04:03:41.496582: val_loss -0.5888 
2025-03-10 04:03:41.500091: Pseudo dice [np.float32(0.7948), np.float32(0.6428), np.float32(0.8294)] 
2025-03-10 04:03:41.504097: Epoch time: 75.25 s 
2025-03-10 04:03:41.507604: Yayy! New best EMA pseudo Dice: 0.7177000045776367 
2025-03-10 04:03:42.235859:  
2025-03-10 04:03:42.241439: Epoch 8 
2025-03-10 04:03:42.244502: Current learning rate: 0.00928 
2025-03-10 04:04:57.196195: train_loss -0.6608 
2025-03-10 04:04:57.202793: val_loss -0.582 
2025-03-10 04:04:57.207340: Pseudo dice [np.float32(0.798), np.float32(0.6552), np.float32(0.8145)] 
2025-03-10 04:04:57.210405: Epoch time: 74.96 s 
2025-03-10 04:04:57.214951: Yayy! New best EMA pseudo Dice: 0.7214999794960022 
2025-03-10 04:04:57.951880:  
2025-03-10 04:04:57.956912: Epoch 9 
2025-03-10 04:04:57.959247: Current learning rate: 0.00919 
2025-03-10 04:06:12.987669: train_loss -0.6654 
2025-03-10 04:06:12.993638: val_loss -0.6051 
2025-03-10 04:06:12.997187: Pseudo dice [np.float32(0.8044), np.float32(0.6853), np.float32(0.8474)] 
2025-03-10 04:06:13.000719: Epoch time: 75.04 s 
2025-03-10 04:06:13.003295: Yayy! New best EMA pseudo Dice: 0.7272999882698059 
2025-03-10 04:06:13.724142:  
2025-03-10 04:06:13.729691: Epoch 10 
2025-03-10 04:06:13.732203: Current learning rate: 0.0091 
2025-03-10 04:07:28.877146: train_loss -0.6691 
2025-03-10 04:07:28.882712: val_loss -0.6262 
2025-03-10 04:07:28.885723: Pseudo dice [np.float32(0.824), np.float32(0.6979), np.float32(0.8514)] 
2025-03-10 04:07:28.889234: Epoch time: 75.15 s 
2025-03-10 04:07:28.892741: Yayy! New best EMA pseudo Dice: 0.7336999773979187 
2025-03-10 04:07:29.598440:  
2025-03-10 04:07:29.603956: Epoch 11 
2025-03-10 04:07:29.607465: Current learning rate: 0.009 
2025-03-10 04:08:45.164336: train_loss -0.6818 
2025-03-10 04:08:45.171863: val_loss -0.6092 
2025-03-10 04:08:45.177381: Pseudo dice [np.float32(0.8043), np.float32(0.6721), np.float32(0.8442)] 
2025-03-10 04:08:45.180895: Epoch time: 75.57 s 
2025-03-10 04:08:45.184406: Yayy! New best EMA pseudo Dice: 0.7376000285148621 
2025-03-10 04:08:45.919063:  
2025-03-10 04:08:45.925185: Epoch 12 
2025-03-10 04:08:45.928240: Current learning rate: 0.00891 
2025-03-10 04:10:01.158561: train_loss -0.688 
2025-03-10 04:10:01.165581: val_loss -0.6133 
2025-03-10 04:10:01.168593: Pseudo dice [np.float32(0.8095), np.float32(0.6814), np.float32(0.8405)] 
2025-03-10 04:10:01.172107: Epoch time: 75.24 s 
2025-03-10 04:10:01.176120: Yayy! New best EMA pseudo Dice: 0.741599977016449 
2025-03-10 04:10:02.056120:  
2025-03-10 04:10:02.060134: Epoch 13 
2025-03-10 04:10:02.064142: Current learning rate: 0.00882 
2025-03-10 04:11:17.010555: train_loss -0.6897 
2025-03-10 04:11:17.018713: val_loss -0.6087 
2025-03-10 04:11:17.022360: Pseudo dice [np.float32(0.8002), np.float32(0.6575), np.float32(0.8517)] 
2025-03-10 04:11:17.025506: Epoch time: 74.96 s 
2025-03-10 04:11:17.029017: Yayy! New best EMA pseudo Dice: 0.7444000244140625 
2025-03-10 04:11:17.759163:  
2025-03-10 04:11:17.764205: Epoch 14 
2025-03-10 04:11:17.767732: Current learning rate: 0.00873 
2025-03-10 04:12:33.203751: train_loss -0.6844 
2025-03-10 04:12:33.210333: val_loss -0.618 
2025-03-10 04:12:33.213864: Pseudo dice [np.float32(0.8086), np.float32(0.6937), np.float32(0.8402)] 
2025-03-10 04:12:33.217173: Epoch time: 75.44 s 
2025-03-10 04:12:33.220499: Yayy! New best EMA pseudo Dice: 0.7480999827384949 
2025-03-10 04:12:33.959203:  
2025-03-10 04:12:33.964823: Epoch 15 
2025-03-10 04:12:33.967889: Current learning rate: 0.00864 
2025-03-10 04:13:49.087304: train_loss -0.6873 
2025-03-10 04:13:49.092902: val_loss -0.6303 
2025-03-10 04:13:49.097414: Pseudo dice [np.float32(0.8181), np.float32(0.7162), np.float32(0.8441)] 
2025-03-10 04:13:49.100429: Epoch time: 75.13 s 
2025-03-10 04:13:49.103943: Yayy! New best EMA pseudo Dice: 0.7524999976158142 
2025-03-10 04:13:49.834932:  
2025-03-10 04:13:49.840948: Epoch 16 
2025-03-10 04:13:49.843454: Current learning rate: 0.00855 
2025-03-10 04:15:05.329573: train_loss -0.6954 
2025-03-10 04:15:05.339600: val_loss -0.6449 
2025-03-10 04:15:05.345116: Pseudo dice [np.float32(0.8182), np.float32(0.6933), np.float32(0.8488)] 
2025-03-10 04:15:05.348627: Epoch time: 75.5 s 
2025-03-10 04:15:05.352642: Yayy! New best EMA pseudo Dice: 0.7559999823570251 
2025-03-10 04:15:06.090003:  
2025-03-10 04:15:06.095107: Epoch 17 
2025-03-10 04:15:06.098616: Current learning rate: 0.00846 
2025-03-10 04:16:21.152314: train_loss -0.6975 
2025-03-10 04:16:21.161304: val_loss -0.6283 
2025-03-10 04:16:21.165369: Pseudo dice [np.float32(0.8201), np.float32(0.6842), np.float32(0.8518)] 
2025-03-10 04:16:21.168519: Epoch time: 75.06 s 
2025-03-10 04:16:21.171601: Yayy! New best EMA pseudo Dice: 0.758899986743927 
2025-03-10 04:16:21.916888:  
2025-03-10 04:16:21.922975: Epoch 18 
2025-03-10 04:16:21.926514: Current learning rate: 0.00836 
2025-03-10 04:17:37.339166: train_loss -0.7017 
2025-03-10 04:17:37.346688: val_loss -0.6567 
2025-03-10 04:17:37.351705: Pseudo dice [np.float32(0.8307), np.float32(0.7279), np.float32(0.8569)] 
2025-03-10 04:17:37.355242: Epoch time: 75.42 s 
2025-03-10 04:17:37.358276: Yayy! New best EMA pseudo Dice: 0.7634999752044678 
2025-03-10 04:17:38.107741:  
2025-03-10 04:17:38.113338: Epoch 19 
2025-03-10 04:17:38.116915: Current learning rate: 0.00827 
2025-03-10 04:18:53.404501: train_loss -0.7015 
2025-03-10 04:18:53.412027: val_loss -0.6109 
2025-03-10 04:18:53.415537: Pseudo dice [np.float32(0.8014), np.float32(0.6966), np.float32(0.8579)] 
2025-03-10 04:18:53.418549: Epoch time: 75.3 s 
2025-03-10 04:18:53.422063: Yayy! New best EMA pseudo Dice: 0.7656999826431274 
2025-03-10 04:18:54.309129:  
2025-03-10 04:18:54.315219: Epoch 20 
2025-03-10 04:18:54.318729: Current learning rate: 0.00818 
2025-03-10 04:20:09.345102: train_loss -0.7058 
2025-03-10 04:20:09.352333: val_loss -0.6211 
2025-03-10 04:20:09.356405: Pseudo dice [np.float32(0.8208), np.float32(0.6821), np.float32(0.8587)] 
2025-03-10 04:20:09.359488: Epoch time: 75.04 s 
2025-03-10 04:20:09.363087: Yayy! New best EMA pseudo Dice: 0.7678999900817871 
2025-03-10 04:20:10.104076:  
2025-03-10 04:20:10.109653: Epoch 21 
2025-03-10 04:20:10.113258: Current learning rate: 0.00809 
2025-03-10 04:21:25.941974: train_loss -0.7148 
2025-03-10 04:21:25.948492: val_loss -0.6287 
2025-03-10 04:21:25.953009: Pseudo dice [np.float32(0.8335), np.float32(0.704), np.float32(0.8535)] 
2025-03-10 04:21:25.956020: Epoch time: 75.84 s 
2025-03-10 04:21:25.960560: Yayy! New best EMA pseudo Dice: 0.770799994468689 
2025-03-10 04:21:26.685250:  
2025-03-10 04:21:26.689276: Epoch 22 
2025-03-10 04:21:26.692971: Current learning rate: 0.008 
2025-03-10 04:22:41.747433: train_loss -0.7139 
2025-03-10 04:22:41.753955: val_loss -0.6288 
2025-03-10 04:22:41.757964: Pseudo dice [np.float32(0.8221), np.float32(0.6949), np.float32(0.8647)] 
2025-03-10 04:22:41.761479: Epoch time: 75.06 s 
2025-03-10 04:22:41.765014: Yayy! New best EMA pseudo Dice: 0.7731000185012817 
2025-03-10 04:22:42.477196:  
2025-03-10 04:22:42.482715: Epoch 23 
2025-03-10 04:22:42.486227: Current learning rate: 0.0079 
2025-03-10 04:23:57.718408: train_loss -0.7168 
2025-03-10 04:23:57.726055: val_loss -0.6433 
2025-03-10 04:23:57.730120: Pseudo dice [np.float32(0.8213), np.float32(0.7093), np.float32(0.8562)] 
2025-03-10 04:23:57.733203: Epoch time: 75.24 s 
2025-03-10 04:23:57.736758: Yayy! New best EMA pseudo Dice: 0.7753000259399414 
2025-03-10 04:23:58.439596:  
2025-03-10 04:23:58.444611: Epoch 24 
2025-03-10 04:23:58.448122: Current learning rate: 0.00781 
2025-03-10 04:25:13.291783: train_loss -0.7217 
2025-03-10 04:25:13.299304: val_loss -0.6463 
2025-03-10 04:25:13.304323: Pseudo dice [np.float32(0.8317), np.float32(0.7208), np.float32(0.8715)] 
2025-03-10 04:25:13.309339: Epoch time: 74.85 s 
2025-03-10 04:25:13.312351: Yayy! New best EMA pseudo Dice: 0.7785999774932861 
2025-03-10 04:25:14.021781:  
2025-03-10 04:25:14.027294: Epoch 25 
2025-03-10 04:25:14.030803: Current learning rate: 0.00772 
2025-03-10 04:26:29.274961: train_loss -0.7225 
2025-03-10 04:26:29.282015: val_loss -0.6516 
2025-03-10 04:26:29.285053: Pseudo dice [np.float32(0.8256), np.float32(0.7188), np.float32(0.8689)] 
2025-03-10 04:26:29.288672: Epoch time: 75.25 s 
2025-03-10 04:26:29.292216: Yayy! New best EMA pseudo Dice: 0.7811999917030334 
2025-03-10 04:26:30.010392:  
2025-03-10 04:26:30.016909: Epoch 26 
2025-03-10 04:26:30.020421: Current learning rate: 0.00763 
2025-03-10 04:27:45.274207: train_loss -0.7209 
2025-03-10 04:27:45.280222: val_loss -0.6523 
2025-03-10 04:27:45.284236: Pseudo dice [np.float32(0.829), np.float32(0.721), np.float32(0.8704)] 
2025-03-10 04:27:45.287750: Epoch time: 75.26 s 
2025-03-10 04:27:45.291258: Yayy! New best EMA pseudo Dice: 0.7836999893188477 
2025-03-10 04:27:46.012271:  
2025-03-10 04:27:46.018396: Epoch 27 
2025-03-10 04:27:46.021479: Current learning rate: 0.00753 
2025-03-10 04:29:01.475078: train_loss -0.727 
2025-03-10 04:29:01.483237: val_loss -0.6468 
2025-03-10 04:29:01.486819: Pseudo dice [np.float32(0.8267), np.float32(0.7048), np.float32(0.8633)] 
2025-03-10 04:29:01.490347: Epoch time: 75.46 s 
2025-03-10 04:29:01.492960: Yayy! New best EMA pseudo Dice: 0.7851999998092651 
2025-03-10 04:29:02.366917:  
2025-03-10 04:29:02.369939: Epoch 28 
2025-03-10 04:29:02.374021: Current learning rate: 0.00744 
2025-03-10 04:30:17.298148: train_loss -0.7282 
2025-03-10 04:30:17.304667: val_loss -0.6407 
2025-03-10 04:30:17.308174: Pseudo dice [np.float32(0.8275), np.float32(0.7019), np.float32(0.8588)] 
2025-03-10 04:30:17.311185: Epoch time: 74.93 s 
2025-03-10 04:30:17.314698: Yayy! New best EMA pseudo Dice: 0.786300003528595 
2025-03-10 04:30:18.031710:  
2025-03-10 04:30:18.035766: Epoch 29 
2025-03-10 04:30:18.038315: Current learning rate: 0.00735 
2025-03-10 04:31:33.043037: train_loss -0.729 
2025-03-10 04:31:33.049556: val_loss -0.639 
2025-03-10 04:31:33.052063: Pseudo dice [np.float32(0.8192), np.float32(0.705), np.float32(0.8561)] 
2025-03-10 04:31:33.055574: Epoch time: 75.01 s 
2025-03-10 04:31:33.059589: Yayy! New best EMA pseudo Dice: 0.7870000004768372 
2025-03-10 04:31:33.787811:  
2025-03-10 04:31:33.793339: Epoch 30 
2025-03-10 04:31:33.796669: Current learning rate: 0.00725 
2025-03-10 04:32:49.086877: train_loss -0.7286 
2025-03-10 04:32:49.093897: val_loss -0.6409 
2025-03-10 04:32:49.098914: Pseudo dice [np.float32(0.8215), np.float32(0.7214), np.float32(0.8462)] 
2025-03-10 04:32:49.101927: Epoch time: 75.3 s 
2025-03-10 04:32:49.105445: Yayy! New best EMA pseudo Dice: 0.7878999710083008 
2025-03-10 04:32:49.811594:  
2025-03-10 04:32:49.816611: Epoch 31 
2025-03-10 04:32:49.820620: Current learning rate: 0.00716 
2025-03-10 04:34:04.759187: train_loss -0.7271 
2025-03-10 04:34:04.766710: val_loss -0.6256 
2025-03-10 04:34:04.770224: Pseudo dice [np.float32(0.8211), np.float32(0.6858), np.float32(0.8473)] 
2025-03-10 04:34:04.773729: Epoch time: 74.95 s 
2025-03-10 04:34:05.332063:  
2025-03-10 04:34:05.338141: Epoch 32 
2025-03-10 04:34:05.341199: Current learning rate: 0.00707 
2025-03-10 04:35:20.801940: train_loss -0.7375 
2025-03-10 04:35:20.808465: val_loss -0.645 
2025-03-10 04:35:20.810977: Pseudo dice [np.float32(0.8244), np.float32(0.7272), np.float32(0.8537)] 
2025-03-10 04:35:20.814491: Epoch time: 75.47 s 
2025-03-10 04:35:20.818507: Yayy! New best EMA pseudo Dice: 0.7889999747276306 
2025-03-10 04:35:21.525152:  
2025-03-10 04:35:21.528789: Epoch 33 
2025-03-10 04:35:21.532849: Current learning rate: 0.00697 
2025-03-10 04:36:36.838270: train_loss -0.7325 
2025-03-10 04:36:36.843821: val_loss -0.6199 
2025-03-10 04:36:36.848375: Pseudo dice [np.float32(0.8203), np.float32(0.7037), np.float32(0.8566)] 
2025-03-10 04:36:36.851885: Epoch time: 75.31 s 
2025-03-10 04:36:36.854393: Yayy! New best EMA pseudo Dice: 0.7894999980926514 
2025-03-10 04:36:37.592332:  
2025-03-10 04:36:37.597881: Epoch 34 
2025-03-10 04:36:37.600926: Current learning rate: 0.00688 
2025-03-10 04:37:52.982809: train_loss -0.7386 
2025-03-10 04:37:52.989331: val_loss -0.6355 
2025-03-10 04:37:52.993345: Pseudo dice [np.float32(0.82), np.float32(0.7172), np.float32(0.8628)] 
2025-03-10 04:37:52.995852: Epoch time: 75.39 s 
2025-03-10 04:37:52.999363: Yayy! New best EMA pseudo Dice: 0.7904999852180481 
2025-03-10 04:37:53.738235:  
2025-03-10 04:37:53.744262: Epoch 35 
2025-03-10 04:37:53.747777: Current learning rate: 0.00679 
2025-03-10 04:39:09.017711: train_loss -0.7355 
2025-03-10 04:39:09.025236: val_loss -0.6583 
2025-03-10 04:39:09.029244: Pseudo dice [np.float32(0.8388), np.float32(0.7214), np.float32(0.8598)] 
2025-03-10 04:39:09.032750: Epoch time: 75.28 s 
2025-03-10 04:39:09.035255: Yayy! New best EMA pseudo Dice: 0.7921000123023987 
2025-03-10 04:39:09.928284:  
2025-03-10 04:39:09.933801: Epoch 36 
2025-03-10 04:39:09.937314: Current learning rate: 0.00669 
2025-03-10 04:40:25.028993: train_loss -0.7447 
2025-03-10 04:40:25.034008: val_loss -0.6652 
2025-03-10 04:40:25.037553: Pseudo dice [np.float32(0.8296), np.float32(0.7261), np.float32(0.8536)] 
2025-03-10 04:40:25.041104: Epoch time: 75.1 s 
2025-03-10 04:40:25.044673: Yayy! New best EMA pseudo Dice: 0.7932000160217285 
2025-03-10 04:40:25.770058:  
2025-03-10 04:40:25.775498: Epoch 37 
2025-03-10 04:40:25.777505: Current learning rate: 0.0066 
2025-03-10 04:41:40.805148: train_loss -0.7402 
2025-03-10 04:41:40.812667: val_loss -0.622 
2025-03-10 04:41:40.816171: Pseudo dice [np.float32(0.8159), np.float32(0.6993), np.float32(0.8613)] 
2025-03-10 04:41:40.819178: Epoch time: 75.04 s 
2025-03-10 04:41:41.416141:  
2025-03-10 04:41:41.422216: Epoch 38 
2025-03-10 04:41:41.425860: Current learning rate: 0.0065 
2025-03-10 04:42:56.690576: train_loss -0.7456 
2025-03-10 04:42:56.697165: val_loss -0.6422 
2025-03-10 04:42:56.699279: Pseudo dice [np.float32(0.8217), np.float32(0.7115), np.float32(0.8604)] 
2025-03-10 04:42:56.703813: Epoch time: 75.27 s 
2025-03-10 04:42:56.706320: Yayy! New best EMA pseudo Dice: 0.7936000227928162 
2025-03-10 04:42:57.418369:  
2025-03-10 04:42:57.422941: Epoch 39 
2025-03-10 04:42:57.425969: Current learning rate: 0.00641 
2025-03-10 04:44:12.511421: train_loss -0.7457 
2025-03-10 04:44:12.518944: val_loss -0.6293 
2025-03-10 04:44:12.522963: Pseudo dice [np.float32(0.8159), np.float32(0.704), np.float32(0.8521)] 
2025-03-10 04:44:12.526474: Epoch time: 75.09 s 
2025-03-10 04:44:13.102915:  
2025-03-10 04:44:13.108436: Epoch 40 
2025-03-10 04:44:13.111947: Current learning rate: 0.00631 
2025-03-10 04:45:28.197918: train_loss -0.7492 
2025-03-10 04:45:28.205813: val_loss -0.6625 
2025-03-10 04:45:28.208822: Pseudo dice [np.float32(0.8257), np.float32(0.7148), np.float32(0.875)] 
2025-03-10 04:45:28.212329: Epoch time: 75.1 s 
2025-03-10 04:45:28.215835: Yayy! New best EMA pseudo Dice: 0.7944999933242798 
2025-03-10 04:45:28.931235:  
2025-03-10 04:45:28.936754: Epoch 41 
2025-03-10 04:45:28.940262: Current learning rate: 0.00622 
2025-03-10 04:46:44.376854: train_loss -0.7469 
2025-03-10 04:46:44.383497: val_loss -0.6576 
2025-03-10 04:46:44.387560: Pseudo dice [np.float32(0.8243), np.float32(0.7251), np.float32(0.8658)] 
2025-03-10 04:46:44.390642: Epoch time: 75.45 s 
2025-03-10 04:46:44.394263: Yayy! New best EMA pseudo Dice: 0.7955999970436096 
2025-03-10 04:46:45.105432:  
2025-03-10 04:46:45.111018: Epoch 42 
2025-03-10 04:46:45.114053: Current learning rate: 0.00612 
2025-03-10 04:48:00.376944: train_loss -0.7514 
2025-03-10 04:48:00.383463: val_loss -0.6345 
2025-03-10 04:48:00.386972: Pseudo dice [np.float32(0.8178), np.float32(0.7478), np.float32(0.8711)] 
2025-03-10 04:48:00.389983: Epoch time: 75.27 s 
2025-03-10 04:48:00.393538: Yayy! New best EMA pseudo Dice: 0.7972000241279602 
2025-03-10 04:48:01.099359:  
2025-03-10 04:48:01.107040: Epoch 43 
2025-03-10 04:48:01.110586: Current learning rate: 0.00603 
2025-03-10 04:49:16.180453: train_loss -0.7459 
2025-03-10 04:49:16.187978: val_loss -0.6281 
2025-03-10 04:49:16.192489: Pseudo dice [np.float32(0.8246), np.float32(0.7028), np.float32(0.8646)] 
2025-03-10 04:49:16.196505: Epoch time: 75.08 s 
2025-03-10 04:49:16.200013: Yayy! New best EMA pseudo Dice: 0.7972000241279602 
2025-03-10 04:49:17.062223:  
2025-03-10 04:49:17.068736: Epoch 44 
2025-03-10 04:49:17.072246: Current learning rate: 0.00593 
2025-03-10 04:50:32.069962: train_loss -0.7545 
2025-03-10 04:50:32.077043: val_loss -0.6414 
2025-03-10 04:50:32.083114: Pseudo dice [np.float32(0.8266), np.float32(0.7064), np.float32(0.8602)] 
2025-03-10 04:50:32.086686: Epoch time: 75.01 s 
2025-03-10 04:50:32.090786: Yayy! New best EMA pseudo Dice: 0.7972999811172485 
2025-03-10 04:50:32.797726:  
2025-03-10 04:50:32.804344: Epoch 45 
2025-03-10 04:50:32.808406: Current learning rate: 0.00584 
2025-03-10 04:51:47.860665: train_loss -0.7526 
2025-03-10 04:51:47.868300: val_loss -0.646 
2025-03-10 04:51:47.872352: Pseudo dice [np.float32(0.8233), np.float32(0.7041), np.float32(0.8663)] 
2025-03-10 04:51:47.876402: Epoch time: 75.06 s 
2025-03-10 04:51:47.880526: Yayy! New best EMA pseudo Dice: 0.7972999811172485 
2025-03-10 04:51:48.582968:  
2025-03-10 04:51:48.589488: Epoch 46 
2025-03-10 04:51:48.593503: Current learning rate: 0.00574 
2025-03-10 04:53:03.848930: train_loss -0.7492 
2025-03-10 04:53:03.856101: val_loss -0.6467 
2025-03-10 04:53:03.860113: Pseudo dice [np.float32(0.8229), np.float32(0.6958), np.float32(0.8629)] 
2025-03-10 04:53:03.864124: Epoch time: 75.27 s 
2025-03-10 04:53:04.434589:  
2025-03-10 04:53:04.440531: Epoch 47 
2025-03-10 04:53:04.444100: Current learning rate: 0.00565 
2025-03-10 04:54:19.826818: train_loss -0.7584 
2025-03-10 04:54:19.835834: val_loss -0.6293 
2025-03-10 04:54:19.838868: Pseudo dice [np.float32(0.8138), np.float32(0.7085), np.float32(0.8589)] 
2025-03-10 04:54:19.843488: Epoch time: 75.39 s 
2025-03-10 04:54:20.381075:  
2025-03-10 04:54:20.386703: Epoch 48 
2025-03-10 04:54:20.390733: Current learning rate: 0.00555 
2025-03-10 04:55:35.404910: train_loss -0.7596 
2025-03-10 04:55:35.412427: val_loss -0.6245 
2025-03-10 04:55:35.416440: Pseudo dice [np.float32(0.8174), np.float32(0.6926), np.float32(0.8738)] 
2025-03-10 04:55:35.420450: Epoch time: 75.02 s 
2025-03-10 04:55:35.973287:  
2025-03-10 04:55:35.978846: Epoch 49 
2025-03-10 04:55:35.982901: Current learning rate: 0.00546 
2025-03-10 04:56:51.119412: train_loss -0.7538 
2025-03-10 04:56:51.126935: val_loss -0.6415 
2025-03-10 04:56:51.132998: Pseudo dice [np.float32(0.8311), np.float32(0.6878), np.float32(0.8741)] 
2025-03-10 04:56:51.139667: Epoch time: 75.15 s 
2025-03-10 04:56:51.842232:  
2025-03-10 04:56:51.848813: Epoch 50 
2025-03-10 04:56:51.852937: Current learning rate: 0.00536 
2025-03-10 04:58:06.945705: train_loss -0.7529 
2025-03-10 04:58:06.953225: val_loss -0.643 
2025-03-10 04:58:06.957235: Pseudo dice [np.float32(0.8264), np.float32(0.7111), np.float32(0.8545)] 
2025-03-10 04:58:06.960745: Epoch time: 75.1 s 
2025-03-10 04:58:07.553514:  
2025-03-10 04:58:07.560094: Epoch 51 
2025-03-10 04:58:07.562641: Current learning rate: 0.00526 
2025-03-10 04:59:22.542436: train_loss -0.7646 
2025-03-10 04:59:22.550460: val_loss -0.6321 
2025-03-10 04:59:22.553969: Pseudo dice [np.float32(0.8129), np.float32(0.7298), np.float32(0.8614)] 
2025-03-10 04:59:22.557979: Epoch time: 74.99 s 
2025-03-10 04:59:23.289923:  
2025-03-10 04:59:23.297945: Epoch 52 
2025-03-10 04:59:23.302960: Current learning rate: 0.00517 
2025-03-10 05:00:38.327515: train_loss -0.7562 
2025-03-10 05:00:38.335039: val_loss -0.6529 
2025-03-10 05:00:38.339051: Pseudo dice [np.float32(0.8282), np.float32(0.7158), np.float32(0.8656)] 
2025-03-10 05:00:38.342563: Epoch time: 75.04 s 
2025-03-10 05:00:38.346575: Yayy! New best EMA pseudo Dice: 0.7976999878883362 
2025-03-10 05:00:39.054868:  
2025-03-10 05:00:39.060502: Epoch 53 
2025-03-10 05:00:39.064095: Current learning rate: 0.00507 
2025-03-10 05:01:54.365233: train_loss -0.7555 
2025-03-10 05:01:54.372756: val_loss -0.6541 
2025-03-10 05:01:54.377772: Pseudo dice [np.float32(0.8481), np.float32(0.697), np.float32(0.8805)] 
2025-03-10 05:01:54.381285: Epoch time: 75.31 s 
2025-03-10 05:01:54.385294: Yayy! New best EMA pseudo Dice: 0.798799991607666 
2025-03-10 05:01:55.092674:  
2025-03-10 05:01:55.098280: Epoch 54 
2025-03-10 05:01:55.103348: Current learning rate: 0.00497 
2025-03-10 05:03:10.218367: train_loss -0.7626 
2025-03-10 05:03:10.225892: val_loss -0.6345 
2025-03-10 05:03:10.229903: Pseudo dice [np.float32(0.8247), np.float32(0.7017), np.float32(0.8733)] 
2025-03-10 05:03:10.234413: Epoch time: 75.13 s 
2025-03-10 05:03:10.237953: Yayy! New best EMA pseudo Dice: 0.7989000082015991 
2025-03-10 05:03:10.969452:  
2025-03-10 05:03:10.975549: Epoch 55 
2025-03-10 05:03:10.980057: Current learning rate: 0.00487 
2025-03-10 05:04:25.990873: train_loss -0.7615 
2025-03-10 05:04:25.997949: val_loss -0.6515 
2025-03-10 05:04:26.001959: Pseudo dice [np.float32(0.8212), np.float32(0.7255), np.float32(0.8641)] 
2025-03-10 05:04:26.005471: Epoch time: 75.02 s 
2025-03-10 05:04:26.009479: Yayy! New best EMA pseudo Dice: 0.7993999719619751 
2025-03-10 05:04:26.721963:  
2025-03-10 05:04:26.727979: Epoch 56 
2025-03-10 05:04:26.731990: Current learning rate: 0.00478 
2025-03-10 05:05:41.925861: train_loss -0.7599 
2025-03-10 05:05:41.933383: val_loss -0.6533 
2025-03-10 05:05:41.936890: Pseudo dice [np.float32(0.8363), np.float32(0.7277), np.float32(0.8652)] 
2025-03-10 05:05:41.940907: Epoch time: 75.2 s 
2025-03-10 05:05:41.944917: Yayy! New best EMA pseudo Dice: 0.8004000186920166 
2025-03-10 05:05:42.682841:  
2025-03-10 05:05:42.687884: Epoch 57 
2025-03-10 05:05:42.690937: Current learning rate: 0.00468 
2025-03-10 05:06:57.888385: train_loss -0.7623 
2025-03-10 05:06:57.895908: val_loss -0.6336 
2025-03-10 05:06:57.900419: Pseudo dice [np.float32(0.823), np.float32(0.7225), np.float32(0.8631)] 
2025-03-10 05:06:57.904433: Epoch time: 75.21 s 
2025-03-10 05:06:57.908444: Yayy! New best EMA pseudo Dice: 0.8007000088691711 
2025-03-10 05:06:58.626359:  
2025-03-10 05:06:58.632424: Epoch 58 
2025-03-10 05:06:58.636696: Current learning rate: 0.00458 
2025-03-10 05:08:13.894457: train_loss -0.7629 
2025-03-10 05:08:13.902986: val_loss -0.6534 
2025-03-10 05:08:13.907004: Pseudo dice [np.float32(0.8337), np.float32(0.7031), np.float32(0.867)] 
2025-03-10 05:08:13.911015: Epoch time: 75.27 s 
2025-03-10 05:08:13.914528: Yayy! New best EMA pseudo Dice: 0.8007000088691711 
2025-03-10 05:08:14.650660:  
2025-03-10 05:08:14.657739: Epoch 59 
2025-03-10 05:08:14.661365: Current learning rate: 0.00448 
2025-03-10 05:09:29.974199: train_loss -0.7656 
2025-03-10 05:09:29.981848: val_loss -0.6313 
2025-03-10 05:09:29.986569: Pseudo dice [np.float32(0.8187), np.float32(0.715), np.float32(0.8598)] 
2025-03-10 05:09:29.990159: Epoch time: 75.32 s 
2025-03-10 05:09:30.703362:  
2025-03-10 05:09:30.708954: Epoch 60 
2025-03-10 05:09:30.712964: Current learning rate: 0.00438 
2025-03-10 05:10:45.768789: train_loss -0.7585 
2025-03-10 05:10:45.776316: val_loss -0.6529 
2025-03-10 05:10:45.781332: Pseudo dice [np.float32(0.8293), np.float32(0.7067), np.float32(0.8674)] 
2025-03-10 05:10:45.785359: Epoch time: 75.07 s 
2025-03-10 05:10:46.343062:  
2025-03-10 05:10:46.350171: Epoch 61 
2025-03-10 05:10:46.353721: Current learning rate: 0.00429 
2025-03-10 05:12:02.011478: train_loss -0.769 
2025-03-10 05:12:02.020010: val_loss -0.6312 
2025-03-10 05:12:02.024021: Pseudo dice [np.float32(0.8202), np.float32(0.7204), np.float32(0.8703)] 
2025-03-10 05:12:02.027534: Epoch time: 75.67 s 
2025-03-10 05:12:02.031545: Yayy! New best EMA pseudo Dice: 0.8008000254631042 
2025-03-10 05:12:02.729781:  
2025-03-10 05:12:02.733816: Epoch 62 
2025-03-10 05:12:02.737864: Current learning rate: 0.00419 
2025-03-10 05:13:17.944662: train_loss -0.7665 
2025-03-10 05:13:17.952180: val_loss -0.6534 
2025-03-10 05:13:17.956191: Pseudo dice [np.float32(0.8392), np.float32(0.72), np.float32(0.8681)] 
2025-03-10 05:13:17.959702: Epoch time: 75.22 s 
2025-03-10 05:13:17.964715: Yayy! New best EMA pseudo Dice: 0.8016999959945679 
2025-03-10 05:13:18.690839:  
2025-03-10 05:13:18.701462: Epoch 63 
2025-03-10 05:13:18.706071: Current learning rate: 0.00409 
2025-03-10 05:14:33.777058: train_loss -0.7718 
2025-03-10 05:14:33.786261: val_loss -0.6445 
2025-03-10 05:14:33.790927: Pseudo dice [np.float32(0.8284), np.float32(0.7074), np.float32(0.8691)] 
2025-03-10 05:14:33.794523: Epoch time: 75.09 s 
2025-03-10 05:14:34.370129:  
2025-03-10 05:14:34.375710: Epoch 64 
2025-03-10 05:14:34.380281: Current learning rate: 0.00399 
2025-03-10 05:15:49.703079: train_loss -0.7615 
2025-03-10 05:15:49.710611: val_loss -0.6329 
2025-03-10 05:15:49.714632: Pseudo dice [np.float32(0.8299), np.float32(0.7295), np.float32(0.8489)] 
2025-03-10 05:15:49.719149: Epoch time: 75.33 s 
2025-03-10 05:15:49.723169: Yayy! New best EMA pseudo Dice: 0.801800012588501 
2025-03-10 05:15:50.423198:  
2025-03-10 05:15:50.430252: Epoch 65 
2025-03-10 05:15:50.433789: Current learning rate: 0.00389 
2025-03-10 05:17:05.702524: train_loss -0.7692 
2025-03-10 05:17:05.709733: val_loss -0.6373 
2025-03-10 05:17:05.714044: Pseudo dice [np.float32(0.8311), np.float32(0.7076), np.float32(0.8497)] 
2025-03-10 05:17:05.718244: Epoch time: 75.28 s 
2025-03-10 05:17:06.301484:  
2025-03-10 05:17:06.307639: Epoch 66 
2025-03-10 05:17:06.310713: Current learning rate: 0.00379 
2025-03-10 05:18:21.559652: train_loss -0.7732 
2025-03-10 05:18:21.566277: val_loss -0.641 
2025-03-10 05:18:21.570387: Pseudo dice [np.float32(0.8429), np.float32(0.7438), np.float32(0.8642)] 
2025-03-10 05:18:21.574396: Epoch time: 75.26 s 
2025-03-10 05:18:21.577906: Yayy! New best EMA pseudo Dice: 0.8027999997138977 
2025-03-10 05:18:22.279413:  
2025-03-10 05:18:22.285924: Epoch 67 
2025-03-10 05:18:22.289434: Current learning rate: 0.00369 
2025-03-10 05:19:37.410093: train_loss -0.7775 
2025-03-10 05:19:37.418122: val_loss -0.6314 
2025-03-10 05:19:37.422636: Pseudo dice [np.float32(0.8226), np.float32(0.6963), np.float32(0.84)] 
2025-03-10 05:19:37.425647: Epoch time: 75.13 s 
2025-03-10 05:19:38.173514:  
2025-03-10 05:19:38.179606: Epoch 68 
2025-03-10 05:19:38.184132: Current learning rate: 0.00359 
2025-03-10 05:20:53.510064: train_loss -0.7729 
2025-03-10 05:20:53.518169: val_loss -0.6451 
2025-03-10 05:20:53.521770: Pseudo dice [np.float32(0.8354), np.float32(0.7134), np.float32(0.8658)] 
2025-03-10 05:20:53.525283: Epoch time: 75.34 s 
2025-03-10 05:20:54.090541:  
2025-03-10 05:20:54.094555: Epoch 69 
2025-03-10 05:20:54.099571: Current learning rate: 0.00349 
2025-03-10 05:22:09.028458: train_loss -0.7736 
2025-03-10 05:22:09.036096: val_loss -0.6253 
2025-03-10 05:22:09.040140: Pseudo dice [np.float32(0.8112), np.float32(0.6888), np.float32(0.8468)] 
2025-03-10 05:22:09.044175: Epoch time: 74.94 s 
2025-03-10 05:22:09.622099:  
2025-03-10 05:22:09.628058: Epoch 70 
2025-03-10 05:22:09.632070: Current learning rate: 0.00338 
2025-03-10 05:23:24.532847: train_loss -0.7703 
2025-03-10 05:23:24.540950: val_loss -0.6588 
2025-03-10 05:23:24.545570: Pseudo dice [np.float32(0.8306), np.float32(0.747), np.float32(0.8743)] 
2025-03-10 05:23:24.551127: Epoch time: 74.91 s 
2025-03-10 05:23:25.130924:  
2025-03-10 05:23:25.136944: Epoch 71 
2025-03-10 05:23:25.140957: Current learning rate: 0.00328 
2025-03-10 05:24:40.192068: train_loss -0.7699 
2025-03-10 05:24:40.200595: val_loss -0.6235 
2025-03-10 05:24:40.205613: Pseudo dice [np.float32(0.8221), np.float32(0.7245), np.float32(0.87)] 
2025-03-10 05:24:40.209636: Epoch time: 75.06 s 
2025-03-10 05:24:40.787762:  
2025-03-10 05:24:40.793824: Epoch 72 
2025-03-10 05:24:40.797876: Current learning rate: 0.00318 
2025-03-10 05:25:56.096500: train_loss -0.7729 
2025-03-10 05:25:56.103730: val_loss -0.6436 
2025-03-10 05:25:56.108752: Pseudo dice [np.float32(0.8296), np.float32(0.7374), np.float32(0.8598)] 
2025-03-10 05:25:56.112266: Epoch time: 75.31 s 
2025-03-10 05:25:56.696901:  
2025-03-10 05:25:56.703425: Epoch 73 
2025-03-10 05:25:56.706939: Current learning rate: 0.00308 
2025-03-10 05:27:11.927575: train_loss -0.7771 
2025-03-10 05:27:11.935143: val_loss -0.6381 
2025-03-10 05:27:11.939685: Pseudo dice [np.float32(0.8304), np.float32(0.6979), np.float32(0.8662)] 
2025-03-10 05:27:11.943234: Epoch time: 75.23 s 
2025-03-10 05:27:12.521190:  
2025-03-10 05:27:12.526758: Epoch 74 
2025-03-10 05:27:12.531817: Current learning rate: 0.00297 
2025-03-10 05:28:27.737265: train_loss -0.7754 
2025-03-10 05:28:27.745793: val_loss -0.6332 
2025-03-10 05:28:27.749802: Pseudo dice [np.float32(0.8352), np.float32(0.6828), np.float32(0.8593)] 
2025-03-10 05:28:27.754811: Epoch time: 75.22 s 
2025-03-10 05:28:28.468530:  
2025-03-10 05:28:28.475157: Epoch 75 
2025-03-10 05:28:28.480222: Current learning rate: 0.00287 
2025-03-10 05:29:43.279265: train_loss -0.7763 
2025-03-10 05:29:43.286850: val_loss -0.6288 
2025-03-10 05:29:43.290859: Pseudo dice [np.float32(0.8228), np.float32(0.6895), np.float32(0.8655)] 
2025-03-10 05:29:43.295368: Epoch time: 74.81 s 
2025-03-10 05:29:43.882782:  
2025-03-10 05:29:43.889835: Epoch 76 
2025-03-10 05:29:43.893911: Current learning rate: 0.00277 
2025-03-10 05:30:58.926628: train_loss -0.7703 
2025-03-10 05:30:58.935164: val_loss -0.6444 
2025-03-10 05:30:58.939730: Pseudo dice [np.float32(0.8315), np.float32(0.7515), np.float32(0.851)] 
2025-03-10 05:30:58.944745: Epoch time: 75.04 s 
2025-03-10 05:30:59.511521:  
2025-03-10 05:30:59.518156: Epoch 77 
2025-03-10 05:30:59.522735: Current learning rate: 0.00266 
2025-03-10 05:32:14.421602: train_loss -0.7751 
2025-03-10 05:32:14.429123: val_loss -0.6639 
2025-03-10 05:32:14.433697: Pseudo dice [np.float32(0.8405), np.float32(0.7319), np.float32(0.8689)] 
2025-03-10 05:32:14.437278: Epoch time: 74.91 s 
2025-03-10 05:32:15.014222:  
2025-03-10 05:32:15.020839: Epoch 78 
2025-03-10 05:32:15.024897: Current learning rate: 0.00256 
2025-03-10 05:33:30.076379: train_loss -0.7759 
2025-03-10 05:33:30.084976: val_loss -0.6494 
2025-03-10 05:33:30.089013: Pseudo dice [np.float32(0.8261), np.float32(0.7259), np.float32(0.8637)] 
2025-03-10 05:33:30.092581: Epoch time: 75.06 s 
2025-03-10 05:33:30.097636: Yayy! New best EMA pseudo Dice: 0.8029000163078308 
2025-03-10 05:33:30.823915:  
2025-03-10 05:33:30.829935: Epoch 79 
2025-03-10 05:33:30.833953: Current learning rate: 0.00245 
2025-03-10 05:34:45.968773: train_loss -0.7787 
2025-03-10 05:34:45.976895: val_loss -0.6574 
2025-03-10 05:34:45.981467: Pseudo dice [np.float32(0.8306), np.float32(0.7391), np.float32(0.8711)] 
2025-03-10 05:34:45.986165: Epoch time: 75.15 s 
2025-03-10 05:34:45.990294: Yayy! New best EMA pseudo Dice: 0.8039000034332275 
2025-03-10 05:34:46.735693:  
2025-03-10 05:34:46.742224: Epoch 80 
2025-03-10 05:34:46.746248: Current learning rate: 0.00235 
2025-03-10 05:36:02.387485: train_loss -0.7806 
2025-03-10 05:36:02.395096: val_loss -0.6549 
2025-03-10 05:36:02.400459: Pseudo dice [np.float32(0.8328), np.float32(0.707), np.float32(0.87)] 
2025-03-10 05:36:02.405031: Epoch time: 75.65 s 
2025-03-10 05:36:03.005933:  
2025-03-10 05:36:03.012459: Epoch 81 
2025-03-10 05:36:03.016476: Current learning rate: 0.00224 
2025-03-10 05:37:18.199892: train_loss -0.7798 
2025-03-10 05:37:18.207455: val_loss -0.6345 
2025-03-10 05:37:18.211984: Pseudo dice [np.float32(0.8236), np.float32(0.7119), np.float32(0.8626)] 
2025-03-10 05:37:18.216656: Epoch time: 75.19 s 
2025-03-10 05:37:18.798993:  
2025-03-10 05:37:18.805015: Epoch 82 
2025-03-10 05:37:18.810035: Current learning rate: 0.00214 
2025-03-10 05:38:34.238065: train_loss -0.7744 
2025-03-10 05:38:34.247148: val_loss -0.6393 
2025-03-10 05:38:34.251752: Pseudo dice [np.float32(0.8283), np.float32(0.7016), np.float32(0.8718)] 
2025-03-10 05:38:34.256320: Epoch time: 75.44 s 
2025-03-10 05:38:34.981745:  
2025-03-10 05:38:34.987824: Epoch 83 
2025-03-10 05:38:34.991941: Current learning rate: 0.00203 
2025-03-10 05:39:50.116943: train_loss -0.7772 
2025-03-10 05:39:50.124474: val_loss -0.6482 
2025-03-10 05:39:50.129492: Pseudo dice [np.float32(0.8282), np.float32(0.739), np.float32(0.8561)] 
2025-03-10 05:39:50.133008: Epoch time: 75.14 s 
2025-03-10 05:39:50.708603:  
2025-03-10 05:39:50.715238: Epoch 84 
2025-03-10 05:39:50.719321: Current learning rate: 0.00192 
2025-03-10 05:41:05.947244: train_loss -0.7817 
2025-03-10 05:41:05.954777: val_loss -0.6561 
2025-03-10 05:41:05.959792: Pseudo dice [np.float32(0.8368), np.float32(0.7331), np.float32(0.8684)] 
2025-03-10 05:41:05.963308: Epoch time: 75.24 s 
2025-03-10 05:41:05.968325: Yayy! New best EMA pseudo Dice: 0.8044999837875366 
2025-03-10 05:41:06.664274:  
2025-03-10 05:41:06.670803: Epoch 85 
2025-03-10 05:41:06.674819: Current learning rate: 0.00181 
2025-03-10 05:42:22.134132: train_loss -0.7785 
2025-03-10 05:42:22.141651: val_loss -0.6336 
2025-03-10 05:42:22.146667: Pseudo dice [np.float32(0.828), np.float32(0.7127), np.float32(0.8672)] 
2025-03-10 05:42:22.151681: Epoch time: 75.47 s 
2025-03-10 05:42:22.717318:  
2025-03-10 05:42:22.722336: Epoch 86 
2025-03-10 05:42:22.725848: Current learning rate: 0.0017 
2025-03-10 05:43:38.018452: train_loss -0.7819 
2025-03-10 05:43:38.028060: val_loss -0.6244 
2025-03-10 05:43:38.034577: Pseudo dice [np.float32(0.8098), np.float32(0.6812), np.float32(0.8653)] 
2025-03-10 05:43:38.039591: Epoch time: 75.3 s 
2025-03-10 05:43:38.588464:  
2025-03-10 05:43:38.594484: Epoch 87 
2025-03-10 05:43:38.598497: Current learning rate: 0.00159 
2025-03-10 05:44:53.568185: train_loss -0.7819 
2025-03-10 05:44:53.576215: val_loss -0.6528 
2025-03-10 05:44:53.581230: Pseudo dice [np.float32(0.8332), np.float32(0.7083), np.float32(0.8784)] 
2025-03-10 05:44:53.586245: Epoch time: 74.98 s 
2025-03-10 05:44:54.137161:  
2025-03-10 05:44:54.141782: Epoch 88 
2025-03-10 05:44:54.146891: Current learning rate: 0.00148 
2025-03-10 05:46:09.096680: train_loss -0.7822 
2025-03-10 05:46:09.104708: val_loss -0.6488 
2025-03-10 05:46:09.109729: Pseudo dice [np.float32(0.832), np.float32(0.7097), np.float32(0.866)] 
2025-03-10 05:46:09.114242: Epoch time: 74.96 s 
2025-03-10 05:46:09.655735:  
2025-03-10 05:46:09.661918: Epoch 89 
2025-03-10 05:46:09.666492: Current learning rate: 0.00137 
2025-03-10 05:47:25.184780: train_loss -0.7844 
2025-03-10 05:47:25.192809: val_loss -0.6287 
2025-03-10 05:47:25.197832: Pseudo dice [np.float32(0.8232), np.float32(0.7138), np.float32(0.8749)] 
2025-03-10 05:47:25.202853: Epoch time: 75.53 s 
2025-03-10 05:47:25.748333:  
2025-03-10 05:47:25.754359: Epoch 90 
2025-03-10 05:47:25.758378: Current learning rate: 0.00126 
2025-03-10 05:48:40.997480: train_loss -0.7881 
2025-03-10 05:48:41.005007: val_loss -0.6359 
2025-03-10 05:48:41.009517: Pseudo dice [np.float32(0.8272), np.float32(0.727), np.float32(0.8632)] 
2025-03-10 05:48:41.013529: Epoch time: 75.25 s 
2025-03-10 05:48:41.705559:  
2025-03-10 05:48:41.713242: Epoch 91 
2025-03-10 05:48:41.717329: Current learning rate: 0.00115 
2025-03-10 05:49:56.638908: train_loss -0.7833 
2025-03-10 05:49:56.647438: val_loss -0.6525 
2025-03-10 05:49:56.652448: Pseudo dice [np.float32(0.8204), np.float32(0.7345), np.float32(0.8635)] 
2025-03-10 05:49:56.657558: Epoch time: 74.93 s 
2025-03-10 05:49:57.204414:  
2025-03-10 05:49:57.210934: Epoch 92 
2025-03-10 05:49:57.215944: Current learning rate: 0.00103 
2025-03-10 05:51:12.448172: train_loss -0.79 
2025-03-10 05:51:12.456410: val_loss -0.6479 
2025-03-10 05:51:12.460987: Pseudo dice [np.float32(0.8296), np.float32(0.6917), np.float32(0.8716)] 
2025-03-10 05:51:12.465066: Epoch time: 75.24 s 
2025-03-10 05:51:13.014321:  
2025-03-10 05:51:13.020843: Epoch 93 
2025-03-10 05:51:13.024867: Current learning rate: 0.00091 
2025-03-10 05:52:28.073659: train_loss -0.7829 
2025-03-10 05:52:28.081317: val_loss -0.6339 
2025-03-10 05:52:28.085974: Pseudo dice [np.float32(0.8108), np.float32(0.7167), np.float32(0.8801)] 
2025-03-10 05:52:28.090983: Epoch time: 75.06 s 
2025-03-10 05:52:28.635406:  
2025-03-10 05:52:28.641044: Epoch 94 
2025-03-10 05:52:28.646610: Current learning rate: 0.00079 
2025-03-10 05:53:43.738991: train_loss -0.7864 
2025-03-10 05:53:43.746203: val_loss -0.6488 
2025-03-10 05:53:43.751343: Pseudo dice [np.float32(0.834), np.float32(0.721), np.float32(0.8706)] 
2025-03-10 05:53:43.755903: Epoch time: 75.1 s 
2025-03-10 05:53:44.297137:  
2025-03-10 05:53:44.304255: Epoch 95 
2025-03-10 05:53:44.308338: Current learning rate: 0.00067 
2025-03-10 05:54:59.108674: train_loss -0.7875 
2025-03-10 05:54:59.117199: val_loss -0.6497 
2025-03-10 05:54:59.121213: Pseudo dice [np.float32(0.8287), np.float32(0.7256), np.float32(0.866)] 
2025-03-10 05:54:59.126230: Epoch time: 74.81 s 
2025-03-10 05:54:59.667892:  
2025-03-10 05:54:59.675008: Epoch 96 
2025-03-10 05:54:59.679137: Current learning rate: 0.00055 
2025-03-10 05:56:14.738575: train_loss -0.7892 
2025-03-10 05:56:14.746130: val_loss -0.651 
2025-03-10 05:56:14.751147: Pseudo dice [np.float32(0.8355), np.float32(0.7273), np.float32(0.8719)] 
2025-03-10 05:56:14.756165: Epoch time: 75.07 s 
2025-03-10 05:56:14.759676: Yayy! New best EMA pseudo Dice: 0.8046000003814697 
2025-03-10 05:56:15.470054:  
2025-03-10 05:56:15.476105: Epoch 97 
2025-03-10 05:56:15.480140: Current learning rate: 0.00043 
2025-03-10 05:57:30.423458: train_loss -0.7844 
2025-03-10 05:57:30.430985: val_loss -0.6533 
2025-03-10 05:57:30.436001: Pseudo dice [np.float32(0.8372), np.float32(0.7119), np.float32(0.8705)] 
2025-03-10 05:57:30.439514: Epoch time: 74.95 s 
2025-03-10 05:57:30.444531: Yayy! New best EMA pseudo Dice: 0.8047999739646912 
2025-03-10 05:57:31.168252:  
2025-03-10 05:57:31.174769: Epoch 98 
2025-03-10 05:57:31.178781: Current learning rate: 0.0003 
2025-03-10 05:58:46.325784: train_loss -0.7898 
2025-03-10 05:58:46.333812: val_loss -0.6347 
2025-03-10 05:58:46.338325: Pseudo dice [np.float32(0.823), np.float32(0.7283), np.float32(0.8746)] 
2025-03-10 05:58:46.342340: Epoch time: 75.16 s 
2025-03-10 05:58:46.346351: Yayy! New best EMA pseudo Dice: 0.8051999807357788 
2025-03-10 05:58:47.227175:  
2025-03-10 05:58:47.232733: Epoch 99 
2025-03-10 05:58:47.237298: Current learning rate: 0.00016 
2025-03-10 06:00:02.273654: train_loss -0.7867 
2025-03-10 06:00:02.282184: val_loss -0.6676 
2025-03-10 06:00:02.288077: Pseudo dice [np.float32(0.8495), np.float32(0.7295), np.float32(0.8743)] 
2025-03-10 06:00:02.292270: Epoch time: 75.05 s 
2025-03-10 06:00:02.296341: Yayy! New best EMA pseudo Dice: 0.8064000010490417 
2025-03-10 06:00:03.232726: Training done. 
2025-03-10 06:00:03.267727: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-10 06:00:03.275726: The split file contains 5 splits. 
2025-03-10 06:00:03.282726: Desired fold for training: 0 
2025-03-10 06:00:03.287726: This split has 387 training and 97 validation cases. 
2025-03-10 06:00:03.293729: predicting BRATS_010 
2025-03-10 06:00:03.302727: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2025-03-10 06:00:05.401735: predicting BRATS_011 
2025-03-10 06:00:05.414738: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2025-03-10 06:00:06.743032: predicting BRATS_012 
2025-03-10 06:00:06.755032: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-10 06:00:08.130192: predicting BRATS_018 
2025-03-10 06:00:08.143700: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2025-03-10 06:00:09.504860: predicting BRATS_020 
2025-03-10 06:00:09.517867: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2025-03-10 06:00:10.853016: predicting BRATS_028 
2025-03-10 06:00:10.867015: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-03-10 06:00:12.195738: predicting BRATS_029 
2025-03-10 06:00:12.209738: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-03-10 06:00:13.543765: predicting BRATS_032 
2025-03-10 06:00:13.558765: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2025-03-10 06:00:14.921948: predicting BRATS_034 
2025-03-10 06:00:14.934464: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2025-03-10 06:00:16.272198: predicting BRATS_041 
2025-03-10 06:00:16.287196: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2025-03-10 06:00:17.629135: predicting BRATS_042 
2025-03-10 06:00:17.644640: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2025-03-10 06:00:18.980841: predicting BRATS_047 
2025-03-10 06:00:18.995840: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-10 06:00:20.333122: predicting BRATS_049 
2025-03-10 06:00:20.347631: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-10 06:00:21.702914: predicting BRATS_053 
2025-03-10 06:00:21.714917: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-10 06:00:23.047880: predicting BRATS_056 
2025-03-10 06:00:23.058881: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-10 06:00:24.391116: predicting BRATS_057 
2025-03-10 06:00:24.405115: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-10 06:00:25.739419: predicting BRATS_067 
2025-03-10 06:00:25.752418: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-10 06:00:27.108084: predicting BRATS_069 
2025-03-10 06:00:27.123087: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-10 06:00:28.458483: predicting BRATS_085 
2025-03-10 06:00:28.473483: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2025-03-10 06:00:29.182208: predicting BRATS_086 
2025-03-10 06:00:29.194207: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2025-03-10 06:00:30.559162: predicting BRATS_088 
2025-03-10 06:00:30.575161: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2025-03-10 06:00:31.913843: predicting BRATS_091 
2025-03-10 06:00:31.927847: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-03-10 06:00:33.267090: predicting BRATS_098 
2025-03-10 06:00:33.280091: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2025-03-10 06:00:34.652323: predicting BRATS_100 
2025-03-10 06:00:34.666323: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-10 06:00:35.381582: predicting BRATS_101 
2025-03-10 06:00:35.394582: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-10 06:00:36.105632: predicting BRATS_102 
2025-03-10 06:00:36.119634: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2025-03-10 06:00:37.452709: predicting BRATS_104 
2025-03-10 06:00:37.465710: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2025-03-10 06:00:38.800425: predicting BRATS_111 
2025-03-10 06:00:38.814427: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2025-03-10 06:00:40.178778: predicting BRATS_116 
2025-03-10 06:00:40.192776: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2025-03-10 06:00:41.529642: predicting BRATS_135 
2025-03-10 06:00:41.544647: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-03-10 06:00:42.878887: predicting BRATS_136 
2025-03-10 06:00:42.891887: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-03-10 06:00:44.224367: predicting BRATS_138 
2025-03-10 06:00:44.238373: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2025-03-10 06:00:45.597764: predicting BRATS_145 
2025-03-10 06:00:45.611765: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2025-03-10 06:00:46.946776: predicting BRATS_149 
2025-03-10 06:00:46.961288: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2025-03-10 06:00:48.345158: predicting BRATS_155 
2025-03-10 06:00:48.358663: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-10 06:00:49.740522: predicting BRATS_157 
2025-03-10 06:00:49.755028: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-10 06:00:51.089469: predicting BRATS_158 
2025-03-10 06:00:51.105465: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-10 06:00:52.441355: predicting BRATS_159 
2025-03-10 06:00:52.457861: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-10 06:00:53.805037: predicting BRATS_163 
2025-03-10 06:00:53.817040: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-03-10 06:00:55.151864: predicting BRATS_164 
2025-03-10 06:00:55.164373: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2025-03-10 06:00:56.509831: predicting BRATS_169 
2025-03-10 06:00:56.520833: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2025-03-10 06:00:57.857973: predicting BRATS_176 
2025-03-10 06:00:57.871973: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-03-10 06:00:59.232898: predicting BRATS_181 
2025-03-10 06:00:59.246902: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2025-03-10 06:01:00.588044: predicting BRATS_183 
2025-03-10 06:01:00.602047: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-10 06:01:01.967217: predicting BRATS_184 
2025-03-10 06:01:01.980217: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-10 06:01:03.313552: predicting BRATS_187 
2025-03-10 06:01:03.326554: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-10 06:01:04.666753: predicting BRATS_192 
2025-03-10 06:01:04.678751: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2025-03-10 06:01:06.010397: predicting BRATS_198 
2025-03-10 06:01:06.023396: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-03-10 06:01:07.394440: predicting BRATS_207 
2025-03-10 06:01:07.409440: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-10 06:01:08.744733: predicting BRATS_208 
2025-03-10 06:01:08.758740: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-10 06:01:10.094579: predicting BRATS_218 
2025-03-10 06:01:10.108578: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-03-10 06:01:11.487354: predicting BRATS_220 
2025-03-10 06:01:11.502357: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2025-03-10 06:01:12.839329: predicting BRATS_224 
2025-03-10 06:01:12.852327: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2025-03-10 06:01:14.228328: predicting BRATS_230 
2025-03-10 06:01:14.242330: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2025-03-10 06:01:15.577280: predicting BRATS_271 
2025-03-10 06:01:15.591281: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2025-03-10 06:01:16.955849: predicting BRATS_282 
2025-03-10 06:01:16.970352: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2025-03-10 06:01:18.309473: predicting BRATS_284 
2025-03-10 06:01:18.324473: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2025-03-10 06:01:19.654123: predicting BRATS_287 
2025-03-10 06:01:19.666128: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-10 06:01:21.004242: predicting BRATS_290 
2025-03-10 06:01:21.018243: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2025-03-10 06:01:22.390894: predicting BRATS_291 
2025-03-10 06:01:22.405893: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-03-10 06:01:23.735621: predicting BRATS_292 
2025-03-10 06:01:23.747622: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2025-03-10 06:01:25.085020: predicting BRATS_293 
2025-03-10 06:01:25.100020: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2025-03-10 06:01:26.437570: predicting BRATS_300 
2025-03-10 06:01:26.450571: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2025-03-10 06:01:27.790948: predicting BRATS_305 
2025-03-10 06:01:27.805948: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2025-03-10 06:01:29.144839: predicting BRATS_311 
2025-03-10 06:01:29.159839: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2025-03-10 06:01:30.550797: predicting BRATS_314 
2025-03-10 06:01:30.564803: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2025-03-10 06:01:31.903394: predicting BRATS_321 
2025-03-10 06:01:31.918393: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-03-10 06:01:33.254969: predicting BRATS_328 
2025-03-10 06:01:33.268972: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2025-03-10 06:01:33.995734: predicting BRATS_329 
2025-03-10 06:01:34.009738: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2025-03-10 06:01:35.344984: predicting BRATS_335 
2025-03-10 06:01:35.358986: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2025-03-10 06:01:36.697715: predicting BRATS_343 
2025-03-10 06:01:36.711715: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2025-03-10 06:01:38.056324: predicting BRATS_350 
2025-03-10 06:01:38.072326: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2025-03-10 06:01:38.761806: predicting BRATS_351 
2025-03-10 06:01:38.774810: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2025-03-10 06:01:39.464870: predicting BRATS_356 
2025-03-10 06:01:39.478874: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2025-03-10 06:01:40.204798: predicting BRATS_366 
2025-03-10 06:01:40.217798: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2025-03-10 06:01:41.552975: predicting BRATS_367 
2025-03-10 06:01:41.565975: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2025-03-10 06:01:42.907999: predicting BRATS_374 
2025-03-10 06:01:42.920998: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2025-03-10 06:01:44.255805: predicting BRATS_376 
2025-03-10 06:01:44.269812: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2025-03-10 06:01:45.606275: predicting BRATS_377 
2025-03-10 06:01:45.618275: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2025-03-10 06:01:47.010530: predicting BRATS_378 
2025-03-10 06:01:47.024528: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2025-03-10 06:01:48.364014: predicting BRATS_379 
2025-03-10 06:01:48.378020: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2025-03-10 06:01:49.717555: predicting BRATS_384 
2025-03-10 06:01:49.731555: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2025-03-10 06:01:51.073709: predicting BRATS_386 
2025-03-10 06:01:51.091217: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-03-10 06:01:52.431797: predicting BRATS_394 
2025-03-10 06:01:52.446793: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-10 06:01:53.779580: predicting BRATS_398 
2025-03-10 06:01:53.793086: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2025-03-10 06:01:55.132100: predicting BRATS_400 
2025-03-10 06:01:55.147101: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2025-03-10 06:01:56.497005: predicting BRATS_432 
2025-03-10 06:01:56.511004: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2025-03-10 06:01:57.848696: predicting BRATS_437 
2025-03-10 06:01:57.863698: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-10 06:01:59.197787: predicting BRATS_445 
2025-03-10 06:01:59.212787: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2025-03-10 06:02:00.547661: predicting BRATS_446 
2025-03-10 06:02:00.558661: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-03-10 06:02:01.893685: predicting BRATS_450 
2025-03-10 06:02:01.908191: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2025-03-10 06:02:03.277526: predicting BRATS_452 
2025-03-10 06:02:03.291530: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2025-03-10 06:02:04.656763: predicting BRATS_460 
2025-03-10 06:02:04.670763: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2025-03-10 06:02:06.019468: predicting BRATS_470 
2025-03-10 06:02:06.033469: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-03-10 06:02:07.393429: predicting BRATS_472 
2025-03-10 06:02:07.406935: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2025-03-10 06:02:08.737971: predicting BRATS_473 
2025-03-10 06:02:08.750971: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2025-03-10 06:02:09.455968: predicting BRATS_482 
2025-03-10 06:02:09.467969: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2025-03-10 06:02:17.960566: Validation complete 
2025-03-10 06:02:17.966566: Mean Validation Dice:  0.7228472631524152 
