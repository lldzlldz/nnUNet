
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-11 12:39:36.305664: do_dummy_2d_data_aug: False 
2025-03-11 12:39:36.308050: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-11 12:39:36.314694: The split file contains 5 splits. 
2025-03-11 12:39:36.317232: Desired fold for training: 0 
2025-03-11 12:39:36.320982: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2025-03-11 12:40:09.996167: unpacking dataset... 
2025-03-11 12:40:25.499924: unpacking done... 
2025-03-11 12:40:30.564063:  
2025-03-11 12:40:30.569368: Epoch 0 
2025-03-11 12:40:30.573520: Current learning rate: 0.01 
2025-03-11 12:41:15.900513: train_loss -0.2508 
2025-03-11 12:41:15.908026: val_loss -0.4137 
2025-03-11 12:41:15.911633: Pseudo dice [np.float32(0.6845), np.float32(0.4266), np.float32(0.7486)] 
2025-03-11 12:41:15.915218: Epoch time: 45.34 s 
2025-03-11 12:41:15.918339: Yayy! New best EMA pseudo Dice: 0.6198999881744385 
2025-03-11 12:41:16.613198:  
2025-03-11 12:41:16.618802: Epoch 1 
2025-03-11 12:41:16.622793: Current learning rate: 0.00991 
2025-03-11 12:41:58.112509: train_loss -0.4884 
2025-03-11 12:41:58.118691: val_loss -0.4735 
2025-03-11 12:41:58.122426: Pseudo dice [np.float32(0.7109), np.float32(0.4949), np.float32(0.7661)] 
2025-03-11 12:41:58.127629: Epoch time: 41.5 s 
2025-03-11 12:41:58.131253: Yayy! New best EMA pseudo Dice: 0.6237000226974487 
2025-03-11 12:41:58.893441:  
2025-03-11 12:41:58.900175: Epoch 2 
2025-03-11 12:41:58.904387: Current learning rate: 0.00982 
2025-03-11 12:42:39.601937: train_loss -0.5461 
2025-03-11 12:42:39.608126: val_loss -0.5373 
2025-03-11 12:42:39.612307: Pseudo dice [np.float32(0.7347), np.float32(0.6046), np.float32(0.8152)] 
2025-03-11 12:42:39.616021: Epoch time: 40.71 s 
2025-03-11 12:42:39.619132: Yayy! New best EMA pseudo Dice: 0.6330999732017517 
2025-03-11 12:42:40.389989:  
2025-03-11 12:42:40.396607: Epoch 3 
2025-03-11 12:42:40.400752: Current learning rate: 0.00973 
2025-03-11 12:43:21.283423: train_loss -0.5497 
2025-03-11 12:43:21.289074: val_loss -0.5034 
2025-03-11 12:43:21.292676: Pseudo dice [np.float32(0.7612), np.float32(0.5721), np.float32(0.7663)] 
2025-03-11 12:43:21.296224: Epoch time: 40.89 s 
2025-03-11 12:43:21.299835: Yayy! New best EMA pseudo Dice: 0.6398000121116638 
2025-03-11 12:43:22.039852:  
2025-03-11 12:43:22.047434: Epoch 4 
2025-03-11 12:43:22.053670: Current learning rate: 0.00964 
2025-03-11 12:44:02.988104: train_loss -0.5674 
2025-03-11 12:44:02.994884: val_loss -0.5435 
2025-03-11 12:44:02.999012: Pseudo dice [np.float32(0.7618), np.float32(0.6043), np.float32(0.8173)] 
2025-03-11 12:44:03.002639: Epoch time: 40.95 s 
2025-03-11 12:44:03.007778: Yayy! New best EMA pseudo Dice: 0.6485999822616577 
2025-03-11 12:44:03.897804:  
2025-03-11 12:44:03.903217: Epoch 5 
2025-03-11 12:44:03.906602: Current learning rate: 0.00955 
2025-03-11 12:44:44.531947: train_loss -0.5919 
2025-03-11 12:44:44.539132: val_loss -0.5281 
2025-03-11 12:44:44.543867: Pseudo dice [np.float32(0.7905), np.float32(0.5921), np.float32(0.8105)] 
2025-03-11 12:44:44.547481: Epoch time: 40.64 s 
2025-03-11 12:44:44.551648: Yayy! New best EMA pseudo Dice: 0.6567999720573425 
2025-03-11 12:44:45.287707:  
2025-03-11 12:44:45.292796: Epoch 6 
2025-03-11 12:44:45.296370: Current learning rate: 0.00946 
2025-03-11 12:45:26.637134: train_loss -0.5975 
2025-03-11 12:45:26.643824: val_loss -0.5325 
2025-03-11 12:45:26.647583: Pseudo dice [np.float32(0.7753), np.float32(0.5671), np.float32(0.798)] 
2025-03-11 12:45:26.651389: Epoch time: 41.35 s 
2025-03-11 12:45:26.654467: Yayy! New best EMA pseudo Dice: 0.6625000238418579 
2025-03-11 12:45:27.395474:  
2025-03-11 12:45:27.399618: Epoch 7 
2025-03-11 12:45:27.403236: Current learning rate: 0.00937 
2025-03-11 12:46:07.415557: train_loss -0.5981 
2025-03-11 12:46:07.421966: val_loss -0.5924 
2025-03-11 12:46:07.425622: Pseudo dice [np.float32(0.781), np.float32(0.6511), np.float32(0.8444)] 
2025-03-11 12:46:07.429347: Epoch time: 40.02 s 
2025-03-11 12:46:07.432431: Yayy! New best EMA pseudo Dice: 0.6721000075340271 
2025-03-11 12:46:08.181515:  
2025-03-11 12:46:08.187781: Epoch 8 
2025-03-11 12:46:08.192941: Current learning rate: 0.00928 
2025-03-11 12:46:48.175245: train_loss -0.6167 
2025-03-11 12:46:48.182580: val_loss -0.581 
2025-03-11 12:46:48.186019: Pseudo dice [np.float32(0.7933), np.float32(0.6359), np.float32(0.828)] 
2025-03-11 12:46:48.189096: Epoch time: 39.99 s 
2025-03-11 12:46:48.192259: Yayy! New best EMA pseudo Dice: 0.6801999807357788 
2025-03-11 12:46:48.943871:  
2025-03-11 12:46:48.949537: Epoch 9 
2025-03-11 12:46:48.953072: Current learning rate: 0.00919 
2025-03-11 12:47:29.363652: train_loss -0.6244 
2025-03-11 12:47:29.370433: val_loss -0.5909 
2025-03-11 12:47:29.374047: Pseudo dice [np.float32(0.7802), np.float32(0.6787), np.float32(0.807)] 
2025-03-11 12:47:29.377663: Epoch time: 40.42 s 
2025-03-11 12:47:29.380827: Yayy! New best EMA pseudo Dice: 0.6876999735832214 
2025-03-11 12:47:30.118838:  
2025-03-11 12:47:30.124744: Epoch 10 
2025-03-11 12:47:30.130310: Current learning rate: 0.0091 
2025-03-11 12:48:10.963946: train_loss -0.6383 
2025-03-11 12:48:10.970902: val_loss -0.6001 
2025-03-11 12:48:10.975471: Pseudo dice [np.float32(0.8087), np.float32(0.5863), np.float32(0.8509)] 
2025-03-11 12:48:10.979081: Epoch time: 40.85 s 
2025-03-11 12:48:10.983283: Yayy! New best EMA pseudo Dice: 0.6937999725341797 
2025-03-11 12:48:11.735548:  
2025-03-11 12:48:11.741735: Epoch 11 
2025-03-11 12:48:11.745984: Current learning rate: 0.009 
2025-03-11 12:48:53.449301: train_loss -0.6378 
2025-03-11 12:48:53.456391: val_loss -0.5935 
2025-03-11 12:48:53.460016: Pseudo dice [np.float32(0.7979), np.float32(0.646), np.float32(0.8452)] 
2025-03-11 12:48:53.464707: Epoch time: 41.71 s 
2025-03-11 12:48:53.468326: Yayy! New best EMA pseudo Dice: 0.7006999850273132 
2025-03-11 12:48:54.206664:  
2025-03-11 12:48:54.212402: Epoch 12 
2025-03-11 12:48:54.216000: Current learning rate: 0.00891 
2025-03-11 12:49:35.207957: train_loss -0.6361 
2025-03-11 12:49:35.214237: val_loss -0.6051 
2025-03-11 12:49:35.219998: Pseudo dice [np.float32(0.7975), np.float32(0.6625), np.float32(0.8273)] 
2025-03-11 12:49:35.223626: Epoch time: 41.0 s 
2025-03-11 12:49:35.226824: Yayy! New best EMA pseudo Dice: 0.7069000005722046 
2025-03-11 12:49:36.136231:  
2025-03-11 12:49:36.142470: Epoch 13 
2025-03-11 12:49:36.146637: Current learning rate: 0.00882 
2025-03-11 12:50:16.730186: train_loss -0.6261 
2025-03-11 12:50:16.737627: val_loss -0.5942 
2025-03-11 12:50:16.741253: Pseudo dice [np.float32(0.8062), np.float32(0.6503), np.float32(0.8382)] 
2025-03-11 12:50:16.744458: Epoch time: 40.59 s 
2025-03-11 12:50:16.748852: Yayy! New best EMA pseudo Dice: 0.7127000093460083 
2025-03-11 12:50:17.500159:  
2025-03-11 12:50:17.505468: Epoch 14 
2025-03-11 12:50:17.509154: Current learning rate: 0.00873 
2025-03-11 12:50:58.283140: train_loss -0.6633 
2025-03-11 12:50:58.291544: val_loss -0.594 
2025-03-11 12:50:58.296773: Pseudo dice [np.float32(0.7987), np.float32(0.6715), np.float32(0.8307)] 
2025-03-11 12:50:58.301950: Epoch time: 40.78 s 
2025-03-11 12:50:58.309077: Yayy! New best EMA pseudo Dice: 0.7181000113487244 
2025-03-11 12:50:59.056983:  
2025-03-11 12:50:59.062161: Epoch 15 
2025-03-11 12:50:59.065786: Current learning rate: 0.00864 
2025-03-11 12:51:40.346505: train_loss -0.6465 
2025-03-11 12:51:40.354299: val_loss -0.5909 
2025-03-11 12:51:40.358546: Pseudo dice [np.float32(0.8018), np.float32(0.6131), np.float32(0.7963)] 
2025-03-11 12:51:40.362159: Epoch time: 41.29 s 
2025-03-11 12:51:40.365405: Yayy! New best EMA pseudo Dice: 0.7200000286102295 
2025-03-11 12:51:41.121425:  
2025-03-11 12:51:41.127093: Epoch 16 
2025-03-11 12:51:41.130800: Current learning rate: 0.00855 
2025-03-11 12:52:22.052464: train_loss -0.6601 
2025-03-11 12:52:22.059397: val_loss -0.6112 
2025-03-11 12:52:22.064054: Pseudo dice [np.float32(0.7974), np.float32(0.7197), np.float32(0.8338)] 
2025-03-11 12:52:22.068198: Epoch time: 40.93 s 
2025-03-11 12:52:22.071879: Yayy! New best EMA pseudo Dice: 0.7264000177383423 
2025-03-11 12:52:22.830623:  
2025-03-11 12:52:22.837011: Epoch 17 
2025-03-11 12:52:22.840123: Current learning rate: 0.00846 
2025-03-11 12:53:03.867052: train_loss -0.6651 
2025-03-11 12:53:03.873234: val_loss -0.5649 
2025-03-11 12:53:03.876881: Pseudo dice [np.float32(0.7983), np.float32(0.6374), np.float32(0.8119)] 
2025-03-11 12:53:03.880692: Epoch time: 41.04 s 
2025-03-11 12:53:03.884358: Yayy! New best EMA pseudo Dice: 0.728600025177002 
2025-03-11 12:53:04.633660:  
2025-03-11 12:53:04.639370: Epoch 18 
2025-03-11 12:53:04.642443: Current learning rate: 0.00836 
2025-03-11 12:53:45.437467: train_loss -0.6511 
2025-03-11 12:53:45.444137: val_loss -0.6505 
2025-03-11 12:53:45.448342: Pseudo dice [np.float32(0.8297), np.float32(0.7156), np.float32(0.867)] 
2025-03-11 12:53:45.453546: Epoch time: 40.8 s 
2025-03-11 12:53:45.458254: Yayy! New best EMA pseudo Dice: 0.7361999750137329 
2025-03-11 12:53:46.237724:  
2025-03-11 12:53:46.243505: Epoch 19 
2025-03-11 12:53:46.247138: Current learning rate: 0.00827 
2025-03-11 12:54:27.221266: train_loss -0.6492 
2025-03-11 12:54:27.232225: val_loss -0.6294 
2025-03-11 12:54:27.237884: Pseudo dice [np.float32(0.8121), np.float32(0.7066), np.float32(0.8554)] 
2025-03-11 12:54:27.242527: Epoch time: 40.98 s 
2025-03-11 12:54:27.246239: Yayy! New best EMA pseudo Dice: 0.7416999936103821 
2025-03-11 12:54:27.999629:  
2025-03-11 12:54:28.006405: Epoch 20 
2025-03-11 12:54:28.010025: Current learning rate: 0.00818 
2025-03-11 12:55:09.192726: train_loss -0.6531 
2025-03-11 12:55:09.200695: val_loss -0.6353 
2025-03-11 12:55:09.206459: Pseudo dice [np.float32(0.829), np.float32(0.675), np.float32(0.8399)] 
2025-03-11 12:55:09.210657: Epoch time: 41.19 s 
2025-03-11 12:55:09.214935: Yayy! New best EMA pseudo Dice: 0.7457000017166138 
2025-03-11 12:55:10.149829:  
2025-03-11 12:55:10.156063: Epoch 21 
2025-03-11 12:55:10.159579: Current learning rate: 0.00809 
2025-03-11 12:55:50.929577: train_loss -0.6673 
2025-03-11 12:55:50.936786: val_loss -0.6105 
2025-03-11 12:55:50.941487: Pseudo dice [np.float32(0.795), np.float32(0.6613), np.float32(0.8444)] 
2025-03-11 12:55:50.945111: Epoch time: 40.78 s 
2025-03-11 12:55:50.948190: Yayy! New best EMA pseudo Dice: 0.7477999925613403 
2025-03-11 12:55:51.697253:  
2025-03-11 12:55:51.702973: Epoch 22 
2025-03-11 12:55:51.706586: Current learning rate: 0.008 
2025-03-11 12:56:32.827214: train_loss -0.6726 
2025-03-11 12:56:32.834455: val_loss -0.6143 
2025-03-11 12:56:32.839156: Pseudo dice [np.float32(0.8107), np.float32(0.7006), np.float32(0.8248)] 
2025-03-11 12:56:32.842803: Epoch time: 41.13 s 
2025-03-11 12:56:32.846503: Yayy! New best EMA pseudo Dice: 0.7508999705314636 
2025-03-11 12:56:33.595523:  
2025-03-11 12:56:33.601220: Epoch 23 
2025-03-11 12:56:33.604858: Current learning rate: 0.0079 
2025-03-11 12:57:14.178728: train_loss -0.676 
2025-03-11 12:57:14.185467: val_loss -0.6043 
2025-03-11 12:57:14.189672: Pseudo dice [np.float32(0.8035), np.float32(0.7062), np.float32(0.8252)] 
2025-03-11 12:57:14.194221: Epoch time: 40.58 s 
2025-03-11 12:57:14.197850: Yayy! New best EMA pseudo Dice: 0.753600001335144 
2025-03-11 12:57:14.944042:  
2025-03-11 12:57:14.950637: Epoch 24 
2025-03-11 12:57:14.954783: Current learning rate: 0.00781 
2025-03-11 12:57:55.314159: train_loss -0.676 
2025-03-11 12:57:55.321991: val_loss -0.6212 
2025-03-11 12:57:55.325620: Pseudo dice [np.float32(0.7973), np.float32(0.6906), np.float32(0.8454)] 
2025-03-11 12:57:55.329328: Epoch time: 40.37 s 
2025-03-11 12:57:55.332944: Yayy! New best EMA pseudo Dice: 0.7559999823570251 
2025-03-11 12:57:56.189509:  
2025-03-11 12:57:56.195058: Epoch 25 
2025-03-11 12:57:56.199326: Current learning rate: 0.00772 
2025-03-11 12:58:37.309425: train_loss -0.6774 
2025-03-11 12:58:37.317091: val_loss -0.6163 
2025-03-11 12:58:37.321048: Pseudo dice [np.float32(0.8185), np.float32(0.6954), np.float32(0.8359)] 
2025-03-11 12:58:37.324615: Epoch time: 41.12 s 
2025-03-11 12:58:37.328405: Yayy! New best EMA pseudo Dice: 0.7588000297546387 
2025-03-11 12:58:38.150348:  
2025-03-11 12:58:38.156473: Epoch 26 
2025-03-11 12:58:38.160052: Current learning rate: 0.00763 
2025-03-11 12:59:18.999635: train_loss -0.6771 
2025-03-11 12:59:19.006412: val_loss -0.6382 
2025-03-11 12:59:19.010093: Pseudo dice [np.float32(0.8128), np.float32(0.7373), np.float32(0.8426)] 
2025-03-11 12:59:19.014309: Epoch time: 40.85 s 
2025-03-11 12:59:19.018330: Yayy! New best EMA pseudo Dice: 0.7626000046730042 
2025-03-11 12:59:19.761362:  
2025-03-11 12:59:19.767460: Epoch 27 
2025-03-11 12:59:19.770562: Current learning rate: 0.00753 
2025-03-11 12:59:59.938398: train_loss -0.669 
2025-03-11 12:59:59.945847: val_loss -0.6504 
2025-03-11 12:59:59.953522: Pseudo dice [np.float32(0.8274), np.float32(0.6988), np.float32(0.8636)] 
2025-03-11 12:59:59.957681: Epoch time: 40.18 s 
2025-03-11 12:59:59.961280: Yayy! New best EMA pseudo Dice: 0.765999972820282 
2025-03-11 13:00:00.698662:  
2025-03-11 13:00:00.704305: Epoch 28 
2025-03-11 13:00:00.708390: Current learning rate: 0.00744 
2025-03-11 13:00:41.126091: train_loss -0.6741 
2025-03-11 13:00:41.132716: val_loss -0.6089 
2025-03-11 13:00:41.136249: Pseudo dice [np.float32(0.8016), np.float32(0.6712), np.float32(0.8251)] 
2025-03-11 13:00:41.139780: Epoch time: 40.43 s 
2025-03-11 13:00:41.708319:  
2025-03-11 13:00:41.713439: Epoch 29 
2025-03-11 13:00:41.716520: Current learning rate: 0.00735 
2025-03-11 13:01:21.821432: train_loss -0.6835 
2025-03-11 13:01:21.828494: val_loss -0.6449 
2025-03-11 13:01:21.832114: Pseudo dice [np.float32(0.8308), np.float32(0.7026), np.float32(0.8433)] 
2025-03-11 13:01:21.836254: Epoch time: 40.11 s 
2025-03-11 13:01:21.840016: Yayy! New best EMA pseudo Dice: 0.7685999870300293 
2025-03-11 13:01:22.583826:  
2025-03-11 13:01:22.589339: Epoch 30 
2025-03-11 13:01:22.592974: Current learning rate: 0.00725 
2025-03-11 13:02:02.720019: train_loss -0.6886 
2025-03-11 13:02:02.726955: val_loss -0.6466 
2025-03-11 13:02:02.730601: Pseudo dice [np.float32(0.8066), np.float32(0.697), np.float32(0.8439)] 
2025-03-11 13:02:02.734285: Epoch time: 40.14 s 
2025-03-11 13:02:02.737337: Yayy! New best EMA pseudo Dice: 0.7699999809265137 
2025-03-11 13:02:03.486659:  
2025-03-11 13:02:03.492395: Epoch 31 
2025-03-11 13:02:03.495981: Current learning rate: 0.00716 
2025-03-11 13:02:43.639269: train_loss -0.6871 
2025-03-11 13:02:43.646327: val_loss -0.6514 
2025-03-11 13:02:43.649364: Pseudo dice [np.float32(0.8401), np.float32(0.7111), np.float32(0.8372)] 
2025-03-11 13:02:43.653387: Epoch time: 40.15 s 
2025-03-11 13:02:43.656725: Yayy! New best EMA pseudo Dice: 0.772599995136261 
2025-03-11 13:02:44.421597:  
2025-03-11 13:02:44.427382: Epoch 32 
2025-03-11 13:02:44.431146: Current learning rate: 0.00707 
2025-03-11 13:03:24.614123: train_loss -0.695 
2025-03-11 13:03:24.620174: val_loss -0.6229 
2025-03-11 13:03:24.623811: Pseudo dice [np.float32(0.8238), np.float32(0.669), np.float32(0.8403)] 
2025-03-11 13:03:24.627498: Epoch time: 40.19 s 
2025-03-11 13:03:24.630590: Yayy! New best EMA pseudo Dice: 0.7731999754905701 
2025-03-11 13:03:25.378369:  
2025-03-11 13:03:25.383653: Epoch 33 
2025-03-11 13:03:25.386269: Current learning rate: 0.00697 
2025-03-11 13:04:05.453368: train_loss -0.6922 
2025-03-11 13:04:05.460129: val_loss -0.6399 
2025-03-11 13:04:05.464907: Pseudo dice [np.float32(0.8197), np.float32(0.7336), np.float32(0.8432)] 
2025-03-11 13:04:05.467468: Epoch time: 40.08 s 
2025-03-11 13:04:05.472143: Yayy! New best EMA pseudo Dice: 0.7756999731063843 
2025-03-11 13:04:06.225628:  
2025-03-11 13:04:06.231905: Epoch 34 
2025-03-11 13:04:06.235087: Current learning rate: 0.00688 
2025-03-11 13:04:46.260585: train_loss -0.7018 
2025-03-11 13:04:46.267066: val_loss -0.6038 
2025-03-11 13:04:46.270676: Pseudo dice [np.float32(0.7923), np.float32(0.6997), np.float32(0.8449)] 
2025-03-11 13:04:46.273723: Epoch time: 40.04 s 
2025-03-11 13:04:46.277407: Yayy! New best EMA pseudo Dice: 0.7760000228881836 
2025-03-11 13:04:47.038139:  
2025-03-11 13:04:47.043888: Epoch 35 
2025-03-11 13:04:47.046980: Current learning rate: 0.00679 
2025-03-11 13:05:27.151488: train_loss -0.7103 
2025-03-11 13:05:27.157626: val_loss -0.6171 
2025-03-11 13:05:27.160729: Pseudo dice [np.float32(0.8166), np.float32(0.7051), np.float32(0.8563)] 
2025-03-11 13:05:27.164464: Epoch time: 40.11 s 
2025-03-11 13:05:27.168089: Yayy! New best EMA pseudo Dice: 0.7777000069618225 
2025-03-11 13:05:28.105802:  
2025-03-11 13:05:28.112058: Epoch 36 
2025-03-11 13:05:28.115707: Current learning rate: 0.00669 
2025-03-11 13:06:08.269002: train_loss -0.706 
2025-03-11 13:06:08.275980: val_loss -0.608 
2025-03-11 13:06:08.279315: Pseudo dice [np.float32(0.8042), np.float32(0.674), np.float32(0.829)] 
2025-03-11 13:06:08.282937: Epoch time: 40.16 s 
2025-03-11 13:06:08.871381:  
2025-03-11 13:06:08.877501: Epoch 37 
2025-03-11 13:06:08.881080: Current learning rate: 0.0066 
2025-03-11 13:06:49.134620: train_loss -0.7047 
2025-03-11 13:06:49.141894: val_loss -0.632 
2025-03-11 13:06:49.146565: Pseudo dice [np.float32(0.8189), np.float32(0.6979), np.float32(0.8599)] 
2025-03-11 13:06:49.150204: Epoch time: 40.26 s 
2025-03-11 13:06:49.153798: Yayy! New best EMA pseudo Dice: 0.7784000039100647 
2025-03-11 13:06:49.910165:  
2025-03-11 13:06:49.915635: Epoch 38 
2025-03-11 13:06:49.919546: Current learning rate: 0.0065 
2025-03-11 13:07:30.255192: train_loss -0.7037 
2025-03-11 13:07:30.261471: val_loss -0.6688 
2025-03-11 13:07:30.265079: Pseudo dice [np.float32(0.8309), np.float32(0.6904), np.float32(0.8688)] 
2025-03-11 13:07:30.268786: Epoch time: 40.35 s 
2025-03-11 13:07:30.271929: Yayy! New best EMA pseudo Dice: 0.7802000045776367 
2025-03-11 13:07:31.035749:  
2025-03-11 13:07:31.041483: Epoch 39 
2025-03-11 13:07:31.045783: Current learning rate: 0.00641 
2025-03-11 13:08:11.254209: train_loss -0.7018 
2025-03-11 13:08:11.261724: val_loss -0.6299 
2025-03-11 13:08:11.265505: Pseudo dice [np.float32(0.8134), np.float32(0.7116), np.float32(0.8592)] 
2025-03-11 13:08:11.270319: Epoch time: 40.22 s 
2025-03-11 13:08:11.274021: Yayy! New best EMA pseudo Dice: 0.7817000150680542 
2025-03-11 13:08:12.051198:  
2025-03-11 13:08:12.057134: Epoch 40 
2025-03-11 13:08:12.060515: Current learning rate: 0.00631 
2025-03-11 13:08:52.228756: train_loss -0.7002 
2025-03-11 13:08:52.235169: val_loss -0.6478 
2025-03-11 13:08:52.239540: Pseudo dice [np.float32(0.8261), np.float32(0.7078), np.float32(0.8443)] 
2025-03-11 13:08:52.242591: Epoch time: 40.18 s 
2025-03-11 13:08:52.246831: Yayy! New best EMA pseudo Dice: 0.782800018787384 
2025-03-11 13:08:53.017482:  
2025-03-11 13:08:53.022652: Epoch 41 
2025-03-11 13:08:53.026096: Current learning rate: 0.00622 
2025-03-11 13:09:33.244321: train_loss -0.7144 
2025-03-11 13:09:33.250176: val_loss -0.6311 
2025-03-11 13:09:33.253735: Pseudo dice [np.float32(0.8195), np.float32(0.7353), np.float32(0.8444)] 
2025-03-11 13:09:33.257600: Epoch time: 40.23 s 
2025-03-11 13:09:33.260909: Yayy! New best EMA pseudo Dice: 0.784500002861023 
2025-03-11 13:09:33.987412:  
2025-03-11 13:09:33.994765: Epoch 42 
2025-03-11 13:09:33.999850: Current learning rate: 0.00612 
2025-03-11 13:10:14.234287: train_loss -0.7111 
2025-03-11 13:10:14.241097: val_loss -0.6222 
2025-03-11 13:10:14.244691: Pseudo dice [np.float32(0.8181), np.float32(0.6752), np.float32(0.8561)] 
2025-03-11 13:10:14.248236: Epoch time: 40.25 s 
2025-03-11 13:10:14.827902:  
2025-03-11 13:10:14.833792: Epoch 43 
2025-03-11 13:10:14.837411: Current learning rate: 0.00603 
2025-03-11 13:10:55.139626: train_loss -0.7179 
2025-03-11 13:10:55.146434: val_loss -0.6106 
2025-03-11 13:10:55.150027: Pseudo dice [np.float32(0.8283), np.float32(0.6822), np.float32(0.8575)] 
2025-03-11 13:10:55.153129: Epoch time: 40.31 s 
2025-03-11 13:10:55.156769: Yayy! New best EMA pseudo Dice: 0.7847999930381775 
2025-03-11 13:10:56.062569:  
2025-03-11 13:10:56.068323: Epoch 44 
2025-03-11 13:10:56.071582: Current learning rate: 0.00593 
2025-03-11 13:11:36.288437: train_loss -0.7149 
2025-03-11 13:11:36.296723: val_loss -0.6745 
2025-03-11 13:11:36.300918: Pseudo dice [np.float32(0.8342), np.float32(0.7238), np.float32(0.8695)] 
2025-03-11 13:11:36.304727: Epoch time: 40.23 s 
2025-03-11 13:11:36.307992: Yayy! New best EMA pseudo Dice: 0.7872999906539917 
2025-03-11 13:11:37.042330:  
2025-03-11 13:11:37.048652: Epoch 45 
2025-03-11 13:11:37.051739: Current learning rate: 0.00584 
2025-03-11 13:12:17.272160: train_loss -0.7274 
2025-03-11 13:12:17.278927: val_loss -0.6504 
2025-03-11 13:12:17.283048: Pseudo dice [np.float32(0.8217), np.float32(0.7329), np.float32(0.8507)] 
2025-03-11 13:12:17.287165: Epoch time: 40.23 s 
2025-03-11 13:12:17.291271: Yayy! New best EMA pseudo Dice: 0.7886999845504761 
2025-03-11 13:12:18.074338:  
2025-03-11 13:12:18.081407: Epoch 46 
2025-03-11 13:12:18.085518: Current learning rate: 0.00574 
2025-03-11 13:12:57.954728: train_loss -0.7193 
2025-03-11 13:12:57.964090: val_loss -0.6322 
2025-03-11 13:12:57.968642: Pseudo dice [np.float32(0.8338), np.float32(0.688), np.float32(0.8489)] 
2025-03-11 13:12:57.972788: Epoch time: 39.88 s 
2025-03-11 13:12:57.977494: Yayy! New best EMA pseudo Dice: 0.7889000177383423 
2025-03-11 13:12:58.712108:  
2025-03-11 13:12:58.719002: Epoch 47 
2025-03-11 13:12:58.723080: Current learning rate: 0.00565 
2025-03-11 13:13:38.530862: train_loss -0.7242 
2025-03-11 13:13:38.538788: val_loss -0.6599 
2025-03-11 13:13:38.543575: Pseudo dice [np.float32(0.8232), np.float32(0.7256), np.float32(0.8611)] 
2025-03-11 13:13:38.547904: Epoch time: 39.82 s 
2025-03-11 13:13:38.551504: Yayy! New best EMA pseudo Dice: 0.7903000116348267 
2025-03-11 13:13:39.288725:  
2025-03-11 13:13:39.294799: Epoch 48 
2025-03-11 13:13:39.299323: Current learning rate: 0.00555 
2025-03-11 13:14:19.021060: train_loss -0.7226 
2025-03-11 13:14:19.027787: val_loss -0.6398 
2025-03-11 13:14:19.032070: Pseudo dice [np.float32(0.826), np.float32(0.7288), np.float32(0.846)] 
2025-03-11 13:14:19.035149: Epoch time: 39.73 s 
2025-03-11 13:14:19.039475: Yayy! New best EMA pseudo Dice: 0.7912999987602234 
2025-03-11 13:14:19.785342:  
2025-03-11 13:14:19.791578: Epoch 49 
2025-03-11 13:14:19.795180: Current learning rate: 0.00546 
2025-03-11 13:14:59.602701: train_loss -0.7178 
2025-03-11 13:14:59.610175: val_loss -0.6421 
2025-03-11 13:14:59.614954: Pseudo dice [np.float32(0.8035), np.float32(0.746), np.float32(0.8495)] 
2025-03-11 13:14:59.618770: Epoch time: 39.82 s 
2025-03-11 13:14:59.784422: Yayy! New best EMA pseudo Dice: 0.7921000123023987 
2025-03-11 13:15:00.521059:  
2025-03-11 13:15:00.527218: Epoch 50 
2025-03-11 13:15:00.530943: Current learning rate: 0.00536 
2025-03-11 13:15:40.414000: train_loss -0.7239 
2025-03-11 13:15:40.421946: val_loss -0.6459 
2025-03-11 13:15:40.426040: Pseudo dice [np.float32(0.8212), np.float32(0.7036), np.float32(0.859)] 
2025-03-11 13:15:40.429664: Epoch time: 39.89 s 
2025-03-11 13:15:40.432900: Yayy! New best EMA pseudo Dice: 0.7924000024795532 
2025-03-11 13:15:41.181039:  
2025-03-11 13:15:41.187266: Epoch 51 
2025-03-11 13:15:41.190832: Current learning rate: 0.00526 
2025-03-11 13:16:20.776613: train_loss -0.7198 
2025-03-11 13:16:20.782727: val_loss -0.6561 
2025-03-11 13:16:20.786490: Pseudo dice [np.float32(0.83), np.float32(0.7445), np.float32(0.8368)] 
2025-03-11 13:16:20.790261: Epoch time: 39.6 s 
2025-03-11 13:16:20.793826: Yayy! New best EMA pseudo Dice: 0.7935000061988831 
2025-03-11 13:16:21.712323:  
2025-03-11 13:16:21.718547: Epoch 52 
2025-03-11 13:16:21.722146: Current learning rate: 0.00517 
2025-03-11 13:17:01.354313: train_loss -0.7288 
2025-03-11 13:17:01.360402: val_loss -0.6118 
2025-03-11 13:17:01.363432: Pseudo dice [np.float32(0.8132), np.float32(0.6787), np.float32(0.8339)] 
2025-03-11 13:17:01.366967: Epoch time: 39.64 s 
2025-03-11 13:17:01.945858:  
2025-03-11 13:17:01.951564: Epoch 53 
2025-03-11 13:17:01.955169: Current learning rate: 0.00507 
2025-03-11 13:17:41.490003: train_loss -0.7279 
2025-03-11 13:17:41.495720: val_loss -0.6715 
2025-03-11 13:17:41.498765: Pseudo dice [np.float32(0.8301), np.float32(0.7377), np.float32(0.8568)] 
2025-03-11 13:17:41.502962: Epoch time: 39.54 s 
2025-03-11 13:17:42.086624:  
2025-03-11 13:17:42.092278: Epoch 54 
2025-03-11 13:17:42.095854: Current learning rate: 0.00497 
2025-03-11 13:18:21.625017: train_loss -0.7234 
2025-03-11 13:18:21.632760: val_loss -0.6296 
2025-03-11 13:18:21.636392: Pseudo dice [np.float32(0.815), np.float32(0.6926), np.float32(0.8596)] 
2025-03-11 13:18:21.640075: Epoch time: 39.54 s 
2025-03-11 13:18:22.207179:  
2025-03-11 13:18:22.213418: Epoch 55 
2025-03-11 13:18:22.216507: Current learning rate: 0.00487 
2025-03-11 13:19:01.833986: train_loss -0.7271 
2025-03-11 13:19:01.840741: val_loss -0.6193 
2025-03-11 13:19:01.844886: Pseudo dice [np.float32(0.8115), np.float32(0.7111), np.float32(0.8752)] 
2025-03-11 13:19:01.848480: Epoch time: 39.63 s 
2025-03-11 13:19:01.851515: Yayy! New best EMA pseudo Dice: 0.7936000227928162 
2025-03-11 13:19:02.583453:  
2025-03-11 13:19:02.589200: Epoch 56 
2025-03-11 13:19:02.592313: Current learning rate: 0.00478 
2025-03-11 13:19:42.218832: train_loss -0.7314 
2025-03-11 13:19:42.225084: val_loss -0.6516 
2025-03-11 13:19:42.228716: Pseudo dice [np.float32(0.833), np.float32(0.6767), np.float32(0.8628)] 
2025-03-11 13:19:42.231838: Epoch time: 39.64 s 
2025-03-11 13:19:42.796175:  
2025-03-11 13:19:42.801930: Epoch 57 
2025-03-11 13:19:42.805675: Current learning rate: 0.00468 
2025-03-11 13:20:22.399500: train_loss -0.7293 
2025-03-11 13:20:22.406140: val_loss -0.6405 
2025-03-11 13:20:22.409859: Pseudo dice [np.float32(0.8273), np.float32(0.6778), np.float32(0.8613)] 
2025-03-11 13:20:22.414030: Epoch time: 39.6 s 
2025-03-11 13:20:22.979465:  
2025-03-11 13:20:22.985861: Epoch 58 
2025-03-11 13:20:22.989763: Current learning rate: 0.00458 
2025-03-11 13:21:02.590003: train_loss -0.7279 
2025-03-11 13:21:02.597848: val_loss -0.6452 
2025-03-11 13:21:02.601499: Pseudo dice [np.float32(0.8326), np.float32(0.7127), np.float32(0.8687)] 
2025-03-11 13:21:02.605094: Epoch time: 39.61 s 
2025-03-11 13:21:02.608332: Yayy! New best EMA pseudo Dice: 0.7940000295639038 
2025-03-11 13:21:03.355981:  
2025-03-11 13:21:03.361714: Epoch 59 
2025-03-11 13:21:03.365746: Current learning rate: 0.00448 
2025-03-11 13:21:43.021203: train_loss -0.7277 
2025-03-11 13:21:43.029842: val_loss -0.637 
2025-03-11 13:21:43.033448: Pseudo dice [np.float32(0.836), np.float32(0.7285), np.float32(0.8479)] 
2025-03-11 13:21:43.037668: Epoch time: 39.67 s 
2025-03-11 13:21:43.040951: Yayy! New best EMA pseudo Dice: 0.7950000166893005 
2025-03-11 13:21:43.939485:  
2025-03-11 13:21:43.945181: Epoch 60 
2025-03-11 13:21:43.948785: Current learning rate: 0.00438 
2025-03-11 13:22:23.506889: train_loss -0.7297 
2025-03-11 13:22:23.514058: val_loss -0.6361 
2025-03-11 13:22:23.518255: Pseudo dice [np.float32(0.8201), np.float32(0.6905), np.float32(0.8531)] 
2025-03-11 13:22:23.521821: Epoch time: 39.57 s 
2025-03-11 13:22:24.179742:  
2025-03-11 13:22:24.185345: Epoch 61 
2025-03-11 13:22:24.188401: Current learning rate: 0.00429 
2025-03-11 13:23:03.795954: train_loss -0.7484 
2025-03-11 13:23:03.802817: val_loss -0.6097 
2025-03-11 13:23:03.806488: Pseudo dice [np.float32(0.8158), np.float32(0.6789), np.float32(0.8408)] 
2025-03-11 13:23:03.809072: Epoch time: 39.62 s 
2025-03-11 13:23:04.392207:  
2025-03-11 13:23:04.398407: Epoch 62 
2025-03-11 13:23:04.401995: Current learning rate: 0.00419 
2025-03-11 13:23:44.001570: train_loss -0.7363 
2025-03-11 13:23:44.011782: val_loss -0.6248 
2025-03-11 13:23:44.015323: Pseudo dice [np.float32(0.8159), np.float32(0.6853), np.float32(0.8582)] 
2025-03-11 13:23:44.019412: Epoch time: 39.61 s 
2025-03-11 13:23:44.594008:  
2025-03-11 13:23:44.599627: Epoch 63 
2025-03-11 13:23:44.603197: Current learning rate: 0.00409 
2025-03-11 13:24:24.169711: train_loss -0.7325 
2025-03-11 13:24:24.176964: val_loss -0.607 
2025-03-11 13:24:24.180068: Pseudo dice [np.float32(0.8127), np.float32(0.6857), np.float32(0.8586)] 
2025-03-11 13:24:24.183432: Epoch time: 39.58 s 
2025-03-11 13:24:24.768402:  
2025-03-11 13:24:24.773536: Epoch 64 
2025-03-11 13:24:24.777931: Current learning rate: 0.00399 
2025-03-11 13:25:04.445243: train_loss -0.7463 
2025-03-11 13:25:04.451501: val_loss -0.6445 
2025-03-11 13:25:04.455636: Pseudo dice [np.float32(0.8115), np.float32(0.7105), np.float32(0.8635)] 
2025-03-11 13:25:04.459279: Epoch time: 39.68 s 
2025-03-11 13:25:05.067987:  
2025-03-11 13:25:05.073179: Epoch 65 
2025-03-11 13:25:05.076757: Current learning rate: 0.00389 
2025-03-11 13:25:44.653411: train_loss -0.7417 
2025-03-11 13:25:44.661651: val_loss -0.6337 
2025-03-11 13:25:44.665268: Pseudo dice [np.float32(0.8257), np.float32(0.6944), np.float32(0.8704)] 
2025-03-11 13:25:44.668869: Epoch time: 39.59 s 
2025-03-11 13:25:45.250982:  
2025-03-11 13:25:45.256496: Epoch 66 
2025-03-11 13:25:45.260093: Current learning rate: 0.00379 
2025-03-11 13:26:24.826345: train_loss -0.7392 
2025-03-11 13:26:24.832888: val_loss -0.6437 
2025-03-11 13:26:24.836477: Pseudo dice [np.float32(0.8236), np.float32(0.7323), np.float32(0.8695)] 
2025-03-11 13:26:24.840015: Epoch time: 39.58 s 
2025-03-11 13:26:25.425972:  
2025-03-11 13:26:25.431530: Epoch 67 
2025-03-11 13:26:25.435561: Current learning rate: 0.00369 
2025-03-11 13:27:05.106144: train_loss -0.7393 
2025-03-11 13:27:05.113952: val_loss -0.6331 
2025-03-11 13:27:05.117527: Pseudo dice [np.float32(0.812), np.float32(0.6982), np.float32(0.87)] 
2025-03-11 13:27:05.121617: Epoch time: 39.68 s 
2025-03-11 13:27:05.865575:  
2025-03-11 13:27:05.871261: Epoch 68 
2025-03-11 13:27:05.874382: Current learning rate: 0.00359 
2025-03-11 13:27:45.468671: train_loss -0.7366 
2025-03-11 13:27:45.478312: val_loss -0.6556 
2025-03-11 13:27:45.482382: Pseudo dice [np.float32(0.8244), np.float32(0.7351), np.float32(0.8694)] 
2025-03-11 13:27:45.486947: Epoch time: 39.6 s 
2025-03-11 13:27:45.490505: Yayy! New best EMA pseudo Dice: 0.7954999804496765 
2025-03-11 13:27:46.236367:  
2025-03-11 13:27:46.241916: Epoch 69 
2025-03-11 13:27:46.244944: Current learning rate: 0.00349 
2025-03-11 13:28:25.753618: train_loss -0.7336 
2025-03-11 13:28:25.760261: val_loss -0.6589 
2025-03-11 13:28:25.764154: Pseudo dice [np.float32(0.8133), np.float32(0.7416), np.float32(0.8624)] 
2025-03-11 13:28:25.767738: Epoch time: 39.52 s 
2025-03-11 13:28:25.771342: Yayy! New best EMA pseudo Dice: 0.796500027179718 
2025-03-11 13:28:26.531716:  
2025-03-11 13:28:26.537897: Epoch 70 
2025-03-11 13:28:26.541667: Current learning rate: 0.00338 
2025-03-11 13:29:06.230998: train_loss -0.7457 
2025-03-11 13:29:06.237546: val_loss -0.6746 
2025-03-11 13:29:06.241066: Pseudo dice [np.float32(0.8488), np.float32(0.6987), np.float32(0.8594)] 
2025-03-11 13:29:06.245278: Epoch time: 39.7 s 
2025-03-11 13:29:06.248174: Yayy! New best EMA pseudo Dice: 0.7971000075340271 
2025-03-11 13:29:07.016928:  
2025-03-11 13:29:07.021507: Epoch 71 
2025-03-11 13:29:07.025041: Current learning rate: 0.00328 
2025-03-11 13:29:46.638850: train_loss -0.7419 
2025-03-11 13:29:46.646143: val_loss -0.6205 
2025-03-11 13:29:46.652950: Pseudo dice [np.float32(0.8189), np.float32(0.6956), np.float32(0.8517)] 
2025-03-11 13:29:46.657110: Epoch time: 39.62 s 
2025-03-11 13:29:47.253561:  
2025-03-11 13:29:47.258673: Epoch 72 
2025-03-11 13:29:47.262240: Current learning rate: 0.00318 
2025-03-11 13:30:26.840579: train_loss -0.7405 
2025-03-11 13:30:26.847384: val_loss -0.6491 
2025-03-11 13:30:26.851006: Pseudo dice [np.float32(0.8254), np.float32(0.6801), np.float32(0.8739)] 
2025-03-11 13:30:26.854578: Epoch time: 39.59 s 
2025-03-11 13:30:27.445345:  
2025-03-11 13:30:27.450511: Epoch 73 
2025-03-11 13:30:27.454364: Current learning rate: 0.00308 
2025-03-11 13:31:07.160079: train_loss -0.7508 
2025-03-11 13:31:07.167308: val_loss -0.6382 
2025-03-11 13:31:07.170919: Pseudo dice [np.float32(0.827), np.float32(0.7258), np.float32(0.8634)] 
2025-03-11 13:31:07.174589: Epoch time: 39.72 s 
2025-03-11 13:31:07.770921:  
2025-03-11 13:31:07.775993: Epoch 74 
2025-03-11 13:31:07.779842: Current learning rate: 0.00297 
2025-03-11 13:31:47.395028: train_loss -0.7446 
2025-03-11 13:31:47.402319: val_loss -0.6505 
2025-03-11 13:31:47.406312: Pseudo dice [np.float32(0.8318), np.float32(0.7028), np.float32(0.8663)] 
2025-03-11 13:31:47.409409: Epoch time: 39.63 s 
2025-03-11 13:31:47.413021: Yayy! New best EMA pseudo Dice: 0.7972000241279602 
2025-03-11 13:31:48.164140:  
2025-03-11 13:31:48.169246: Epoch 75 
2025-03-11 13:31:48.173260: Current learning rate: 0.00287 
2025-03-11 13:32:27.879575: train_loss -0.745 
2025-03-11 13:32:27.884681: val_loss -0.6405 
2025-03-11 13:32:27.888364: Pseudo dice [np.float32(0.8343), np.float32(0.6853), np.float32(0.8517)] 
2025-03-11 13:32:27.891592: Epoch time: 39.72 s 
2025-03-11 13:32:28.650515:  
2025-03-11 13:32:28.656133: Epoch 76 
2025-03-11 13:32:28.658703: Current learning rate: 0.00277 
2025-03-11 13:33:08.140807: train_loss -0.7503 
2025-03-11 13:33:08.147994: val_loss -0.6432 
2025-03-11 13:33:08.152176: Pseudo dice [np.float32(0.8191), np.float32(0.7234), np.float32(0.8534)] 
2025-03-11 13:33:08.154725: Epoch time: 39.49 s 
2025-03-11 13:33:08.740438:  
2025-03-11 13:33:08.746018: Epoch 77 
2025-03-11 13:33:08.750618: Current learning rate: 0.00266 
2025-03-11 13:33:48.302462: train_loss -0.7527 
2025-03-11 13:33:48.309705: val_loss -0.6195 
2025-03-11 13:33:48.312747: Pseudo dice [np.float32(0.8259), np.float32(0.7051), np.float32(0.8449)] 
2025-03-11 13:33:48.316438: Epoch time: 39.56 s 
2025-03-11 13:33:48.950757:  
2025-03-11 13:33:48.956466: Epoch 78 
2025-03-11 13:33:48.960274: Current learning rate: 0.00256 
2025-03-11 13:34:28.479016: train_loss -0.7518 
2025-03-11 13:34:28.486008: val_loss -0.6558 
2025-03-11 13:34:28.490138: Pseudo dice [np.float32(0.8454), np.float32(0.7197), np.float32(0.8567)] 
2025-03-11 13:34:28.493250: Epoch time: 39.53 s 
2025-03-11 13:34:28.497336: Yayy! New best EMA pseudo Dice: 0.7973999977111816 
2025-03-11 13:34:29.254019:  
2025-03-11 13:34:29.258902: Epoch 79 
2025-03-11 13:34:29.263387: Current learning rate: 0.00245 
2025-03-11 13:35:08.838013: train_loss -0.7519 
2025-03-11 13:35:08.844924: val_loss -0.6406 
2025-03-11 13:35:08.849019: Pseudo dice [np.float32(0.8262), np.float32(0.7531), np.float32(0.8731)] 
2025-03-11 13:35:08.853059: Epoch time: 39.58 s 
2025-03-11 13:35:08.856586: Yayy! New best EMA pseudo Dice: 0.7993999719619751 
2025-03-11 13:35:09.634978:  
2025-03-11 13:35:09.639102: Epoch 80 
2025-03-11 13:35:09.642814: Current learning rate: 0.00235 
2025-03-11 13:35:49.302311: train_loss -0.7456 
2025-03-11 13:35:49.309451: val_loss -0.6442 
2025-03-11 13:35:49.313612: Pseudo dice [np.float32(0.835), np.float32(0.6954), np.float32(0.8773)] 
2025-03-11 13:35:49.316216: Epoch time: 39.67 s 
2025-03-11 13:35:49.320708: Yayy! New best EMA pseudo Dice: 0.7997000217437744 
2025-03-11 13:35:50.106131:  
2025-03-11 13:35:50.111692: Epoch 81 
2025-03-11 13:35:50.115242: Current learning rate: 0.00224 
2025-03-11 13:36:29.731586: train_loss -0.7433 
2025-03-11 13:36:29.739418: val_loss -0.6538 
2025-03-11 13:36:29.743528: Pseudo dice [np.float32(0.8411), np.float32(0.738), np.float32(0.8642)] 
2025-03-11 13:36:29.747100: Epoch time: 39.63 s 
2025-03-11 13:36:29.750770: Yayy! New best EMA pseudo Dice: 0.8011999726295471 
2025-03-11 13:36:30.522964:  
2025-03-11 13:36:30.528779: Epoch 82 
2025-03-11 13:36:30.532454: Current learning rate: 0.00214 
2025-03-11 13:37:10.086832: train_loss -0.7584 
2025-03-11 13:37:10.094191: val_loss -0.6293 
2025-03-11 13:37:10.097826: Pseudo dice [np.float32(0.8369), np.float32(0.7175), np.float32(0.852)] 
2025-03-11 13:37:10.101438: Epoch time: 39.56 s 
2025-03-11 13:37:10.105151: Yayy! New best EMA pseudo Dice: 0.8012999892234802 
2025-03-11 13:37:10.850054:  
2025-03-11 13:37:10.855604: Epoch 83 
2025-03-11 13:37:10.859148: Current learning rate: 0.00203 
2025-03-11 13:37:50.481367: train_loss -0.7592 
2025-03-11 13:37:50.488234: val_loss -0.6098 
2025-03-11 13:37:50.491636: Pseudo dice [np.float32(0.7996), np.float32(0.6736), np.float32(0.8388)] 
2025-03-11 13:37:50.495153: Epoch time: 39.63 s 
2025-03-11 13:37:51.223880:  
2025-03-11 13:37:51.229951: Epoch 84 
2025-03-11 13:37:51.233480: Current learning rate: 0.00192 
2025-03-11 13:38:30.823406: train_loss -0.7595 
2025-03-11 13:38:30.829541: val_loss -0.6375 
2025-03-11 13:38:30.834081: Pseudo dice [np.float32(0.8213), np.float32(0.6455), np.float32(0.8918)] 
2025-03-11 13:38:30.837630: Epoch time: 39.6 s 
2025-03-11 13:38:31.404877:  
2025-03-11 13:38:31.410939: Epoch 85 
2025-03-11 13:38:31.414460: Current learning rate: 0.00181 
2025-03-11 13:39:11.005013: train_loss -0.7567 
2025-03-11 13:39:11.012322: val_loss -0.6505 
2025-03-11 13:39:11.015948: Pseudo dice [np.float32(0.8198), np.float32(0.7171), np.float32(0.8782)] 
2025-03-11 13:39:11.018547: Epoch time: 39.6 s 
2025-03-11 13:39:11.584930:  
2025-03-11 13:39:11.590750: Epoch 86 
2025-03-11 13:39:11.594361: Current learning rate: 0.0017 
2025-03-11 13:39:51.178210: train_loss -0.757 
2025-03-11 13:39:51.184507: val_loss -0.6244 
2025-03-11 13:39:51.189201: Pseudo dice [np.float32(0.8101), np.float32(0.6874), np.float32(0.8523)] 
2025-03-11 13:39:51.192749: Epoch time: 39.59 s 
2025-03-11 13:39:51.760325:  
2025-03-11 13:39:51.765911: Epoch 87 
2025-03-11 13:39:51.769439: Current learning rate: 0.00159 
2025-03-11 13:40:31.359599: train_loss -0.7613 
2025-03-11 13:40:31.364182: val_loss -0.6342 
2025-03-11 13:40:31.368628: Pseudo dice [np.float32(0.8117), np.float32(0.681), np.float32(0.8767)] 
2025-03-11 13:40:31.372809: Epoch time: 39.6 s 
2025-03-11 13:40:31.935671:  
2025-03-11 13:40:31.941337: Epoch 88 
2025-03-11 13:40:31.944963: Current learning rate: 0.00148 
2025-03-11 13:41:11.554147: train_loss -0.7648 
2025-03-11 13:41:11.561247: val_loss -0.6258 
2025-03-11 13:41:11.564821: Pseudo dice [np.float32(0.8181), np.float32(0.7034), np.float32(0.858)] 
2025-03-11 13:41:11.568387: Epoch time: 39.62 s 
2025-03-11 13:41:12.127937:  
2025-03-11 13:41:12.133497: Epoch 89 
2025-03-11 13:41:12.137112: Current learning rate: 0.00137 
2025-03-11 13:41:51.743088: train_loss -0.7599 
2025-03-11 13:41:51.750306: val_loss -0.6256 
2025-03-11 13:41:51.753880: Pseudo dice [np.float32(0.8321), np.float32(0.7207), np.float32(0.861)] 
2025-03-11 13:41:51.757633: Epoch time: 39.62 s 
2025-03-11 13:41:52.330101:  
2025-03-11 13:41:52.335802: Epoch 90 
2025-03-11 13:41:52.339430: Current learning rate: 0.00126 
2025-03-11 13:42:31.960649: train_loss -0.7579 
2025-03-11 13:42:31.967364: val_loss -0.658 
2025-03-11 13:42:31.971107: Pseudo dice [np.float32(0.8264), np.float32(0.7355), np.float32(0.8622)] 
2025-03-11 13:42:31.974893: Epoch time: 39.63 s 
2025-03-11 13:42:32.543588:  
2025-03-11 13:42:32.549171: Epoch 91 
2025-03-11 13:42:32.552700: Current learning rate: 0.00115 
2025-03-11 13:43:12.177900: train_loss -0.7644 
2025-03-11 13:43:12.182762: val_loss -0.6495 
2025-03-11 13:43:12.186401: Pseudo dice [np.float32(0.8353), np.float32(0.7037), np.float32(0.8543)] 
2025-03-11 13:43:12.190621: Epoch time: 39.64 s 
2025-03-11 13:43:12.761383:  
2025-03-11 13:43:12.767414: Epoch 92 
2025-03-11 13:43:12.771435: Current learning rate: 0.00103 
2025-03-11 13:43:52.420122: train_loss -0.7641 
2025-03-11 13:43:52.425279: val_loss -0.6736 
2025-03-11 13:43:52.429434: Pseudo dice [np.float32(0.8406), np.float32(0.7256), np.float32(0.8635)] 
2025-03-11 13:43:52.433020: Epoch time: 39.66 s 
2025-03-11 13:43:53.160067:  
2025-03-11 13:43:53.165950: Epoch 93 
2025-03-11 13:43:53.170062: Current learning rate: 0.00091 
2025-03-11 13:44:32.695500: train_loss -0.7595 
2025-03-11 13:44:32.701871: val_loss -0.6438 
2025-03-11 13:44:32.705472: Pseudo dice [np.float32(0.837), np.float32(0.7), np.float32(0.8683)] 
2025-03-11 13:44:32.709180: Epoch time: 39.54 s 
2025-03-11 13:44:33.271286:  
2025-03-11 13:44:33.276328: Epoch 94 
2025-03-11 13:44:33.280393: Current learning rate: 0.00079 
2025-03-11 13:45:12.896691: train_loss -0.7612 
2025-03-11 13:45:12.902910: val_loss -0.6417 
2025-03-11 13:45:12.906508: Pseudo dice [np.float32(0.8266), np.float32(0.7222), np.float32(0.8674)] 
2025-03-11 13:45:12.910062: Epoch time: 39.63 s 
2025-03-11 13:45:13.485648:  
2025-03-11 13:45:13.491779: Epoch 95 
2025-03-11 13:45:13.495637: Current learning rate: 0.00067 
2025-03-11 13:45:53.131469: train_loss -0.7612 
2025-03-11 13:45:53.138704: val_loss -0.684 
2025-03-11 13:45:53.142295: Pseudo dice [np.float32(0.8426), np.float32(0.727), np.float32(0.8811)] 
2025-03-11 13:45:53.146938: Epoch time: 39.65 s 
2025-03-11 13:45:53.150562: Yayy! New best EMA pseudo Dice: 0.8014000058174133 
2025-03-11 13:45:53.865377:  
2025-03-11 13:45:53.871198: Epoch 96 
2025-03-11 13:45:53.874930: Current learning rate: 0.00055 
2025-03-11 13:46:33.414308: train_loss -0.7644 
2025-03-11 13:46:33.421127: val_loss -0.6191 
2025-03-11 13:46:33.425242: Pseudo dice [np.float32(0.8221), np.float32(0.7334), np.float32(0.8622)] 
2025-03-11 13:46:33.429339: Epoch time: 39.55 s 
2025-03-11 13:46:33.432985: Yayy! New best EMA pseudo Dice: 0.8019000291824341 
2025-03-11 13:46:34.185854:  
2025-03-11 13:46:34.192574: Epoch 97 
2025-03-11 13:46:34.196230: Current learning rate: 0.00043 
2025-03-11 13:47:13.863093: train_loss -0.7711 
2025-03-11 13:47:13.871168: val_loss -0.6643 
2025-03-11 13:47:13.874698: Pseudo dice [np.float32(0.8428), np.float32(0.7598), np.float32(0.8686)] 
2025-03-11 13:47:13.878826: Epoch time: 39.68 s 
2025-03-11 13:47:13.882407: Yayy! New best EMA pseudo Dice: 0.804099977016449 
2025-03-11 13:47:14.630899:  
2025-03-11 13:47:14.636732: Epoch 98 
2025-03-11 13:47:14.639824: Current learning rate: 0.0003 
2025-03-11 13:47:54.158454: train_loss -0.7692 
2025-03-11 13:47:54.165753: val_loss -0.6418 
2025-03-11 13:47:54.169364: Pseudo dice [np.float32(0.8101), np.float32(0.7471), np.float32(0.8613)] 
2025-03-11 13:47:54.172986: Epoch time: 39.53 s 
2025-03-11 13:47:54.176644: Yayy! New best EMA pseudo Dice: 0.8043000102043152 
2025-03-11 13:47:54.925580:  
2025-03-11 13:47:54.931717: Epoch 99 
2025-03-11 13:47:54.935084: Current learning rate: 0.00016 
2025-03-11 13:48:34.477623: train_loss -0.7602 
2025-03-11 13:48:34.484843: val_loss -0.6663 
2025-03-11 13:48:34.488485: Pseudo dice [np.float32(0.8379), np.float32(0.7508), np.float32(0.8718)] 
2025-03-11 13:48:34.492064: Epoch time: 39.55 s 
2025-03-11 13:48:34.495835: Yayy! New best EMA pseudo Dice: 0.805899977684021 
2025-03-11 13:48:35.447934: Training done. 
2025-03-11 13:48:35.490658: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-11 13:48:35.498182: The split file contains 5 splits. 
2025-03-11 13:48:35.506738: Desired fold for training: 0 
2025-03-11 13:48:35.513148: This split has 387 training and 97 validation cases. 
2025-03-11 13:48:35.519911: predicting BRATS_010 
2025-03-11 13:48:35.529566: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2025-03-11 13:48:37.626988: predicting BRATS_011 
2025-03-11 13:48:37.639150: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2025-03-11 13:48:38.996022: predicting BRATS_012 
2025-03-11 13:48:39.006965: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-11 13:48:40.387184: predicting BRATS_018 
2025-03-11 13:48:40.399999: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2025-03-11 13:48:41.780822: predicting BRATS_020 
2025-03-11 13:48:41.792510: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2025-03-11 13:48:43.177971: predicting BRATS_028 
2025-03-11 13:48:43.192838: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-03-11 13:48:44.579701: predicting BRATS_029 
2025-03-11 13:48:44.593545: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-03-11 13:48:45.945811: predicting BRATS_032 
2025-03-11 13:48:45.959207: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2025-03-11 13:48:47.350774: predicting BRATS_034 
2025-03-11 13:48:47.365121: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2025-03-11 13:48:48.715752: predicting BRATS_041 
2025-03-11 13:48:48.731348: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2025-03-11 13:48:50.085860: predicting BRATS_042 
2025-03-11 13:48:50.101153: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2025-03-11 13:48:51.475935: predicting BRATS_047 
2025-03-11 13:48:51.489894: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-11 13:48:52.878036: predicting BRATS_049 
2025-03-11 13:48:52.892133: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-11 13:48:54.242710: predicting BRATS_053 
2025-03-11 13:48:54.257010: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-11 13:48:55.603173: predicting BRATS_056 
2025-03-11 13:48:55.619163: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-11 13:48:56.976755: predicting BRATS_057 
2025-03-11 13:48:56.989107: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-11 13:48:58.340556: predicting BRATS_067 
2025-03-11 13:48:58.354033: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-11 13:48:59.703442: predicting BRATS_069 
2025-03-11 13:48:59.717993: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-11 13:49:01.080705: predicting BRATS_085 
2025-03-11 13:49:01.093279: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2025-03-11 13:49:01.832804: predicting BRATS_086 
2025-03-11 13:49:01.846808: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2025-03-11 13:49:03.244354: predicting BRATS_088 
2025-03-11 13:49:03.259731: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2025-03-11 13:49:04.614435: predicting BRATS_091 
2025-03-11 13:49:04.629385: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-03-11 13:49:05.979565: predicting BRATS_098 
2025-03-11 13:49:05.994009: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2025-03-11 13:49:07.357300: predicting BRATS_100 
2025-03-11 13:49:07.372792: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-11 13:49:08.068294: predicting BRATS_101 
2025-03-11 13:49:08.084986: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-11 13:49:08.789265: predicting BRATS_102 
2025-03-11 13:49:08.804506: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2025-03-11 13:49:10.158665: predicting BRATS_104 
2025-03-11 13:49:10.172103: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2025-03-11 13:49:11.547050: predicting BRATS_111 
2025-03-11 13:49:11.562894: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2025-03-11 13:49:12.911262: predicting BRATS_116 
2025-03-11 13:49:12.926886: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2025-03-11 13:49:14.273518: predicting BRATS_135 
2025-03-11 13:49:14.288899: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-03-11 13:49:15.661628: predicting BRATS_136 
2025-03-11 13:49:15.675849: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-03-11 13:49:17.048315: predicting BRATS_138 
2025-03-11 13:49:17.061408: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2025-03-11 13:49:18.442333: predicting BRATS_145 
2025-03-11 13:49:18.456520: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2025-03-11 13:49:19.805516: predicting BRATS_149 
2025-03-11 13:49:19.820652: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2025-03-11 13:49:21.224520: predicting BRATS_155 
2025-03-11 13:49:21.240591: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-11 13:49:22.640584: predicting BRATS_157 
2025-03-11 13:49:22.656667: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-11 13:49:24.048585: predicting BRATS_158 
2025-03-11 13:49:24.064291: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-11 13:49:25.450717: predicting BRATS_159 
2025-03-11 13:49:25.464762: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-11 13:49:26.822540: predicting BRATS_163 
2025-03-11 13:49:26.836504: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-03-11 13:49:28.208636: predicting BRATS_164 
2025-03-11 13:49:28.226371: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2025-03-11 13:49:29.585751: predicting BRATS_169 
2025-03-11 13:49:29.597944: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2025-03-11 13:49:30.945818: predicting BRATS_176 
2025-03-11 13:49:30.961766: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-03-11 13:49:32.341713: predicting BRATS_181 
2025-03-11 13:49:32.356522: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2025-03-11 13:49:33.762016: predicting BRATS_183 
2025-03-11 13:49:33.776948: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-11 13:49:35.165812: predicting BRATS_184 
2025-03-11 13:49:35.178746: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-11 13:49:36.530843: predicting BRATS_187 
2025-03-11 13:49:36.546845: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-11 13:49:37.930327: predicting BRATS_192 
2025-03-11 13:49:37.944709: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2025-03-11 13:49:39.313806: predicting BRATS_198 
2025-03-11 13:49:39.326536: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-03-11 13:49:40.702375: predicting BRATS_207 
2025-03-11 13:49:40.716854: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-11 13:49:42.067112: predicting BRATS_208 
2025-03-11 13:49:42.081536: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-11 13:49:43.454345: predicting BRATS_218 
2025-03-11 13:49:43.468554: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-03-11 13:49:44.825792: predicting BRATS_220 
2025-03-11 13:49:44.841923: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2025-03-11 13:49:46.217834: predicting BRATS_224 
2025-03-11 13:49:46.234067: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2025-03-11 13:49:47.613663: predicting BRATS_230 
2025-03-11 13:49:47.631299: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2025-03-11 13:49:49.017278: predicting BRATS_271 
2025-03-11 13:49:49.030221: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2025-03-11 13:49:50.392788: predicting BRATS_282 
2025-03-11 13:49:50.409491: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2025-03-11 13:49:51.767490: predicting BRATS_284 
2025-03-11 13:49:51.784677: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2025-03-11 13:49:53.161320: predicting BRATS_287 
2025-03-11 13:49:53.175503: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-11 13:49:54.557361: predicting BRATS_290 
2025-03-11 13:49:54.573277: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2025-03-11 13:49:55.953065: predicting BRATS_291 
2025-03-11 13:49:55.967797: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-03-11 13:49:57.320863: predicting BRATS_292 
2025-03-11 13:49:57.336000: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2025-03-11 13:49:58.733586: predicting BRATS_293 
2025-03-11 13:49:58.748778: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2025-03-11 13:50:00.155220: predicting BRATS_300 
2025-03-11 13:50:00.171928: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2025-03-11 13:50:01.553401: predicting BRATS_305 
2025-03-11 13:50:01.568979: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2025-03-11 13:50:02.971765: predicting BRATS_311 
2025-03-11 13:50:02.988558: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2025-03-11 13:50:04.341340: predicting BRATS_314 
2025-03-11 13:50:04.357113: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2025-03-11 13:50:05.727278: predicting BRATS_321 
2025-03-11 13:50:05.744184: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-03-11 13:50:07.097172: predicting BRATS_328 
2025-03-11 13:50:07.112535: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2025-03-11 13:50:07.818978: predicting BRATS_329 
2025-03-11 13:50:07.833136: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2025-03-11 13:50:09.192090: predicting BRATS_335 
2025-03-11 13:50:09.207161: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2025-03-11 13:50:10.583451: predicting BRATS_343 
2025-03-11 13:50:10.598176: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2025-03-11 13:50:11.963185: predicting BRATS_350 
2025-03-11 13:50:11.979003: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2025-03-11 13:50:12.680717: predicting BRATS_351 
2025-03-11 13:50:12.694890: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2025-03-11 13:50:13.411121: predicting BRATS_356 
2025-03-11 13:50:13.424687: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2025-03-11 13:50:14.135775: predicting BRATS_366 
2025-03-11 13:50:14.150089: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2025-03-11 13:50:15.548881: predicting BRATS_367 
2025-03-11 13:50:15.564094: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2025-03-11 13:50:16.963517: predicting BRATS_374 
2025-03-11 13:50:16.979130: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2025-03-11 13:50:18.332562: predicting BRATS_376 
2025-03-11 13:50:18.346929: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2025-03-11 13:50:19.710064: predicting BRATS_377 
2025-03-11 13:50:19.723257: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2025-03-11 13:50:21.077972: predicting BRATS_378 
2025-03-11 13:50:21.093765: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2025-03-11 13:50:22.477161: predicting BRATS_379 
2025-03-11 13:50:22.491984: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2025-03-11 13:50:23.879929: predicting BRATS_384 
2025-03-11 13:50:23.895916: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2025-03-11 13:50:25.268148: predicting BRATS_386 
2025-03-11 13:50:25.282689: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-03-11 13:50:26.661407: predicting BRATS_394 
2025-03-11 13:50:26.677157: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-11 13:50:28.030298: predicting BRATS_398 
2025-03-11 13:50:28.045120: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2025-03-11 13:50:29.397375: predicting BRATS_400 
2025-03-11 13:50:29.412588: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2025-03-11 13:50:30.785130: predicting BRATS_432 
2025-03-11 13:50:30.799231: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2025-03-11 13:50:32.153927: predicting BRATS_437 
2025-03-11 13:50:32.168910: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-11 13:50:33.519337: predicting BRATS_445 
2025-03-11 13:50:33.532252: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2025-03-11 13:50:34.908487: predicting BRATS_446 
2025-03-11 13:50:34.923505: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-03-11 13:50:36.277618: predicting BRATS_450 
2025-03-11 13:50:36.293666: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2025-03-11 13:50:37.678886: predicting BRATS_452 
2025-03-11 13:50:37.693236: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2025-03-11 13:50:39.081208: predicting BRATS_460 
2025-03-11 13:50:39.096431: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2025-03-11 13:50:40.456306: predicting BRATS_470 
2025-03-11 13:50:40.471387: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-03-11 13:50:41.861738: predicting BRATS_472 
2025-03-11 13:50:41.878225: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2025-03-11 13:50:43.243606: predicting BRATS_473 
2025-03-11 13:50:43.256275: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2025-03-11 13:50:44.008593: predicting BRATS_482 
2025-03-11 13:50:44.025412: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2025-03-11 13:50:52.847385: Validation complete 
2025-03-11 13:50:52.851921: Mean Validation Dice:  0.7236154370469534 
