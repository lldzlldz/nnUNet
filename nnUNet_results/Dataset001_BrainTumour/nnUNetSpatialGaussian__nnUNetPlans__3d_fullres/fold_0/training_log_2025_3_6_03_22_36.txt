
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-06 03:22:36.387077: do_dummy_2d_data_aug: False 
2025-03-06 03:22:36.391076: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-06 03:22:36.399071: The split file contains 5 splits. 
2025-03-06 03:22:36.401067: Desired fold for training: 0 
2025-03-06 03:22:36.404068: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2025-03-06 03:23:10.518761: unpacking dataset... 
2025-03-06 03:23:11.183597: unpacking done... 
2025-03-06 03:23:14.058171:  
2025-03-06 03:23:14.063184: Epoch 0 
2025-03-06 03:23:14.065691: Current learning rate: 0.01 
2025-03-06 03:24:36.437158: train_loss -0.3026 
2025-03-06 03:24:36.443677: val_loss -0.449 
2025-03-06 03:24:36.447191: Pseudo dice [np.float32(0.6969), np.float32(0.5086), np.float32(0.7696)] 
2025-03-06 03:24:36.450697: Epoch time: 82.38 s 
2025-03-06 03:24:36.453711: Yayy! New best EMA pseudo Dice: 0.6583999991416931 
2025-03-06 03:24:37.122169:  
2025-03-06 03:24:37.128186: Epoch 1 
2025-03-06 03:24:37.130692: Current learning rate: 0.00991 
2025-03-06 03:25:52.498239: train_loss -0.5409 
2025-03-06 03:25:52.505285: val_loss -0.5672 
2025-03-06 03:25:52.508307: Pseudo dice [np.float32(0.7595), np.float32(0.6438), np.float32(0.8329)] 
2025-03-06 03:25:52.511835: Epoch time: 75.38 s 
2025-03-06 03:25:52.514350: Yayy! New best EMA pseudo Dice: 0.6671000123023987 
2025-03-06 03:25:53.221023:  
2025-03-06 03:25:53.225081: Epoch 2 
2025-03-06 03:25:53.227623: Current learning rate: 0.00982 
2025-03-06 03:27:08.496322: train_loss -0.5899 
2025-03-06 03:27:08.503336: val_loss -0.5767 
2025-03-06 03:27:08.506344: Pseudo dice [np.float32(0.7973), np.float32(0.641), np.float32(0.8195)] 
2025-03-06 03:27:08.509852: Epoch time: 75.28 s 
2025-03-06 03:27:08.512358: Yayy! New best EMA pseudo Dice: 0.675599992275238 
2025-03-06 03:27:09.246699:  
2025-03-06 03:27:09.252213: Epoch 3 
2025-03-06 03:27:09.254719: Current learning rate: 0.00973 
2025-03-06 03:28:24.715127: train_loss -0.6101 
2025-03-06 03:28:24.722141: val_loss -0.5885 
2025-03-06 03:28:24.726156: Pseudo dice [np.float32(0.7897), np.float32(0.6453), np.float32(0.8076)] 
2025-03-06 03:28:24.729661: Epoch time: 75.47 s 
2025-03-06 03:28:24.732670: Yayy! New best EMA pseudo Dice: 0.6827999949455261 
2025-03-06 03:28:25.483816:  
2025-03-06 03:28:25.488832: Epoch 4 
2025-03-06 03:28:25.492342: Current learning rate: 0.00964 
2025-03-06 03:29:40.764007: train_loss -0.6318 
2025-03-06 03:29:40.770520: val_loss -0.5813 
2025-03-06 03:29:40.773026: Pseudo dice [np.float32(0.7955), np.float32(0.628), np.float32(0.8274)] 
2025-03-06 03:29:40.776535: Epoch time: 75.28 s 
2025-03-06 03:29:40.780040: Yayy! New best EMA pseudo Dice: 0.6895999908447266 
2025-03-06 03:29:41.644396:  
2025-03-06 03:29:41.649937: Epoch 5 
2025-03-06 03:29:41.652973: Current learning rate: 0.00955 
2025-03-06 03:30:56.977663: train_loss -0.6297 
2025-03-06 03:30:56.985345: val_loss -0.6064 
2025-03-06 03:30:56.989412: Pseudo dice [np.float32(0.7907), np.float32(0.6729), np.float32(0.8417)] 
2025-03-06 03:30:56.992445: Epoch time: 75.33 s 
2025-03-06 03:30:56.995998: Yayy! New best EMA pseudo Dice: 0.6974999904632568 
2025-03-06 03:30:57.709024:  
2025-03-06 03:30:57.714032: Epoch 6 
2025-03-06 03:30:57.716538: Current learning rate: 0.00946 
2025-03-06 03:32:13.343284: train_loss -0.6424 
2025-03-06 03:32:13.350828: val_loss -0.5994 
2025-03-06 03:32:13.353864: Pseudo dice [np.float32(0.7793), np.float32(0.6859), np.float32(0.836)] 
2025-03-06 03:32:13.356916: Epoch time: 75.64 s 
2025-03-06 03:32:13.359951: Yayy! New best EMA pseudo Dice: 0.7044000029563904 
2025-03-06 03:32:14.095870:  
2025-03-06 03:32:14.100391: Epoch 7 
2025-03-06 03:32:14.104401: Current learning rate: 0.00937 
2025-03-06 03:33:29.455164: train_loss -0.6554 
2025-03-06 03:33:29.462322: val_loss -0.6106 
2025-03-06 03:33:29.465874: Pseudo dice [np.float32(0.8044), np.float32(0.6691), np.float32(0.8262)] 
2025-03-06 03:33:29.468915: Epoch time: 75.36 s 
2025-03-06 03:33:29.472460: Yayy! New best EMA pseudo Dice: 0.7106000185012817 
2025-03-06 03:33:30.200805:  
2025-03-06 03:33:30.206942: Epoch 8 
2025-03-06 03:33:30.210004: Current learning rate: 0.00928 
2025-03-06 03:34:45.530391: train_loss -0.6605 
2025-03-06 03:34:45.535951: val_loss -0.6204 
2025-03-06 03:34:45.538984: Pseudo dice [np.float32(0.8092), np.float32(0.7046), np.float32(0.8268)] 
2025-03-06 03:34:45.542593: Epoch time: 75.33 s 
2025-03-06 03:34:45.545117: Yayy! New best EMA pseudo Dice: 0.7175999879837036 
2025-03-06 03:34:46.297168:  
2025-03-06 03:34:46.301691: Epoch 9 
2025-03-06 03:34:46.304203: Current learning rate: 0.00919 
2025-03-06 03:36:01.840204: train_loss -0.6658 
2025-03-06 03:36:01.846727: val_loss -0.6231 
2025-03-06 03:36:01.849237: Pseudo dice [np.float32(0.8031), np.float32(0.7001), np.float32(0.8449)] 
2025-03-06 03:36:01.852751: Epoch time: 75.54 s 
2025-03-06 03:36:01.856263: Yayy! New best EMA pseudo Dice: 0.7240999937057495 
2025-03-06 03:36:02.561345:  
2025-03-06 03:36:02.568455: Epoch 10 
2025-03-06 03:36:02.571532: Current learning rate: 0.0091 
2025-03-06 03:37:17.817441: train_loss -0.6783 
2025-03-06 03:37:17.824638: val_loss -0.5997 
2025-03-06 03:37:17.827686: Pseudo dice [np.float32(0.8005), np.float32(0.6756), np.float32(0.8323)] 
2025-03-06 03:37:17.830743: Epoch time: 75.26 s 
2025-03-06 03:37:17.833302: Yayy! New best EMA pseudo Dice: 0.728600025177002 
2025-03-06 03:37:18.557533:  
2025-03-06 03:37:18.562575: Epoch 11 
2025-03-06 03:37:18.565607: Current learning rate: 0.009 
2025-03-06 03:38:34.164343: train_loss -0.6832 
2025-03-06 03:38:34.170996: val_loss -0.6086 
2025-03-06 03:38:34.174520: Pseudo dice [np.float32(0.8141), np.float32(0.6814), np.float32(0.8245)] 
2025-03-06 03:38:34.177620: Epoch time: 75.61 s 
2025-03-06 03:38:34.180685: Yayy! New best EMA pseudo Dice: 0.7330999970436096 
2025-03-06 03:38:34.894772:  
2025-03-06 03:38:34.900407: Epoch 12 
2025-03-06 03:38:34.902942: Current learning rate: 0.00891 
2025-03-06 03:39:50.195298: train_loss -0.6846 
2025-03-06 03:39:50.202452: val_loss -0.6284 
2025-03-06 03:39:50.206021: Pseudo dice [np.float32(0.829), np.float32(0.6769), np.float32(0.8422)] 
2025-03-06 03:39:50.209076: Epoch time: 75.3 s 
2025-03-06 03:39:50.212127: Yayy! New best EMA pseudo Dice: 0.738099992275238 
2025-03-06 03:39:51.091044:  
2025-03-06 03:39:51.096058: Epoch 13 
2025-03-06 03:39:51.099566: Current learning rate: 0.00882 
2025-03-06 03:41:06.244375: train_loss -0.6819 
2025-03-06 03:41:06.251895: val_loss -0.6089 
2025-03-06 03:41:06.255915: Pseudo dice [np.float32(0.8199), np.float32(0.6879), np.float32(0.8446)] 
2025-03-06 03:41:06.258423: Epoch time: 75.15 s 
2025-03-06 03:41:06.261934: Yayy! New best EMA pseudo Dice: 0.7426999807357788 
2025-03-06 03:41:06.984154:  
2025-03-06 03:41:06.989164: Epoch 14 
2025-03-06 03:41:06.992672: Current learning rate: 0.00873 
2025-03-06 03:42:22.277874: train_loss -0.698 
2025-03-06 03:42:22.284446: val_loss -0.6318 
2025-03-06 03:42:22.289958: Pseudo dice [np.float32(0.819), np.float32(0.7216), np.float32(0.8542)] 
2025-03-06 03:42:22.293467: Epoch time: 75.29 s 
2025-03-06 03:42:22.296972: Yayy! New best EMA pseudo Dice: 0.748199999332428 
2025-03-06 03:42:23.042430:  
2025-03-06 03:42:23.048494: Epoch 15 
2025-03-06 03:42:23.051041: Current learning rate: 0.00864 
2025-03-06 03:43:38.252895: train_loss -0.699 
2025-03-06 03:43:38.258913: val_loss -0.6321 
2025-03-06 03:43:38.262419: Pseudo dice [np.float32(0.8264), np.float32(0.7114), np.float32(0.8564)] 
2025-03-06 03:43:38.265428: Epoch time: 75.21 s 
2025-03-06 03:43:38.267933: Yayy! New best EMA pseudo Dice: 0.7531999945640564 
2025-03-06 03:43:39.008086:  
2025-03-06 03:43:39.013649: Epoch 16 
2025-03-06 03:43:39.016692: Current learning rate: 0.00855 
2025-03-06 03:44:54.260890: train_loss -0.7039 
2025-03-06 03:44:54.267455: val_loss -0.6317 
2025-03-06 03:44:54.270998: Pseudo dice [np.float32(0.8211), np.float32(0.7164), np.float32(0.8546)] 
2025-03-06 03:44:54.274032: Epoch time: 75.25 s 
2025-03-06 03:44:54.277564: Yayy! New best EMA pseudo Dice: 0.7576000094413757 
2025-03-06 03:44:55.032783:  
2025-03-06 03:44:55.038334: Epoch 17 
2025-03-06 03:44:55.041914: Current learning rate: 0.00846 
2025-03-06 03:46:10.287244: train_loss -0.6981 
2025-03-06 03:46:10.295768: val_loss -0.6281 
2025-03-06 03:46:10.299779: Pseudo dice [np.float32(0.8234), np.float32(0.6994), np.float32(0.8518)] 
2025-03-06 03:46:10.302284: Epoch time: 75.25 s 
2025-03-06 03:46:10.305790: Yayy! New best EMA pseudo Dice: 0.7609999775886536 
2025-03-06 03:46:11.050563:  
2025-03-06 03:46:11.054602: Epoch 18 
2025-03-06 03:46:11.058630: Current learning rate: 0.00836 
2025-03-06 03:47:26.377005: train_loss -0.7076 
2025-03-06 03:47:26.383592: val_loss -0.6417 
2025-03-06 03:47:26.387601: Pseudo dice [np.float32(0.8288), np.float32(0.7055), np.float32(0.8451)] 
2025-03-06 03:47:26.390107: Epoch time: 75.33 s 
2025-03-06 03:47:26.393617: Yayy! New best EMA pseudo Dice: 0.76419997215271 
2025-03-06 03:47:27.132385:  
2025-03-06 03:47:27.138450: Epoch 19 
2025-03-06 03:47:27.141510: Current learning rate: 0.00827 
2025-03-06 03:48:42.257423: train_loss -0.7173 
2025-03-06 03:48:42.262935: val_loss -0.6232 
2025-03-06 03:48:42.266446: Pseudo dice [np.float32(0.8129), np.float32(0.672), np.float32(0.8455)] 
2025-03-06 03:48:42.270452: Epoch time: 75.13 s 
2025-03-06 03:48:42.272958: Yayy! New best EMA pseudo Dice: 0.765500009059906 
2025-03-06 03:48:43.148832:  
2025-03-06 03:48:43.154374: Epoch 20 
2025-03-06 03:48:43.158392: Current learning rate: 0.00818 
2025-03-06 03:49:58.727801: train_loss -0.7109 
2025-03-06 03:49:58.734885: val_loss -0.6336 
2025-03-06 03:49:58.738943: Pseudo dice [np.float32(0.8179), np.float32(0.7268), np.float32(0.8479)] 
2025-03-06 03:49:58.742053: Epoch time: 75.58 s 
2025-03-06 03:49:58.745653: Yayy! New best EMA pseudo Dice: 0.7687000036239624 
2025-03-06 03:49:59.502764:  
2025-03-06 03:49:59.508492: Epoch 21 
2025-03-06 03:49:59.512002: Current learning rate: 0.00809 
2025-03-06 03:51:14.618998: train_loss -0.7214 
2025-03-06 03:51:14.624595: val_loss -0.6315 
2025-03-06 03:51:14.628662: Pseudo dice [np.float32(0.8244), np.float32(0.692), np.float32(0.8508)] 
2025-03-06 03:51:14.632744: Epoch time: 75.12 s 
2025-03-06 03:51:14.635323: Yayy! New best EMA pseudo Dice: 0.7706999778747559 
2025-03-06 03:51:15.357914:  
2025-03-06 03:51:15.363965: Epoch 22 
2025-03-06 03:51:15.367043: Current learning rate: 0.008 
2025-03-06 03:52:30.404834: train_loss -0.7169 
2025-03-06 03:52:30.411355: val_loss -0.6266 
2025-03-06 03:52:30.414866: Pseudo dice [np.float32(0.8264), np.float32(0.6989), np.float32(0.8591)] 
2025-03-06 03:52:30.418879: Epoch time: 75.05 s 
2025-03-06 03:52:30.422390: Yayy! New best EMA pseudo Dice: 0.7731000185012817 
2025-03-06 03:52:31.141398:  
2025-03-06 03:52:31.147343: Epoch 23 
2025-03-06 03:52:31.150850: Current learning rate: 0.0079 
2025-03-06 03:53:46.599133: train_loss -0.7281 
2025-03-06 03:53:46.605148: val_loss -0.6239 
2025-03-06 03:53:46.609155: Pseudo dice [np.float32(0.8197), np.float32(0.6967), np.float32(0.8597)] 
2025-03-06 03:53:46.612668: Epoch time: 75.46 s 
2025-03-06 03:53:46.616676: Yayy! New best EMA pseudo Dice: 0.7749999761581421 
2025-03-06 03:53:47.315736:  
2025-03-06 03:53:47.322251: Epoch 24 
2025-03-06 03:53:47.324756: Current learning rate: 0.00781 
2025-03-06 03:55:02.588574: train_loss -0.7188 
2025-03-06 03:55:02.595181: val_loss -0.648 
2025-03-06 03:55:02.598239: Pseudo dice [np.float32(0.8299), np.float32(0.7193), np.float32(0.8567)] 
2025-03-06 03:55:02.602272: Epoch time: 75.27 s 
2025-03-06 03:55:02.605314: Yayy! New best EMA pseudo Dice: 0.7777000069618225 
2025-03-06 03:55:03.324184:  
2025-03-06 03:55:03.329196: Epoch 25 
2025-03-06 03:55:03.332705: Current learning rate: 0.00772 
2025-03-06 03:56:18.792258: train_loss -0.7215 
2025-03-06 03:56:18.799777: val_loss -0.6461 
2025-03-06 03:56:18.803794: Pseudo dice [np.float32(0.8232), np.float32(0.715), np.float32(0.8639)] 
2025-03-06 03:56:18.807299: Epoch time: 75.47 s 
2025-03-06 03:56:18.810308: Yayy! New best EMA pseudo Dice: 0.7799999713897705 
2025-03-06 03:56:19.539263:  
2025-03-06 03:56:19.545858: Epoch 26 
2025-03-06 03:56:19.549386: Current learning rate: 0.00763 
2025-03-06 03:57:34.708752: train_loss -0.7249 
2025-03-06 03:57:34.716273: val_loss -0.6333 
2025-03-06 03:57:34.719782: Pseudo dice [np.float32(0.8166), np.float32(0.7176), np.float32(0.8533)] 
2025-03-06 03:57:34.723288: Epoch time: 75.17 s 
2025-03-06 03:57:34.726299: Yayy! New best EMA pseudo Dice: 0.7815999984741211 
2025-03-06 03:57:35.441720:  
2025-03-06 03:57:35.447286: Epoch 27 
2025-03-06 03:57:35.451902: Current learning rate: 0.00753 
2025-03-06 03:58:50.959073: train_loss -0.7296 
2025-03-06 03:58:50.965092: val_loss -0.6448 
2025-03-06 03:58:50.969099: Pseudo dice [np.float32(0.8343), np.float32(0.7094), np.float32(0.8557)] 
2025-03-06 03:58:50.972608: Epoch time: 75.52 s 
2025-03-06 03:58:50.975117: Yayy! New best EMA pseudo Dice: 0.7833999991416931 
2025-03-06 03:58:51.840134:  
2025-03-06 03:58:51.845697: Epoch 28 
2025-03-06 03:58:51.850330: Current learning rate: 0.00744 
2025-03-06 04:00:06.884891: train_loss -0.7266 
2025-03-06 04:00:06.890906: val_loss -0.6362 
2025-03-06 04:00:06.894920: Pseudo dice [np.float32(0.823), np.float32(0.691), np.float32(0.8656)] 
2025-03-06 04:00:06.897426: Epoch time: 75.04 s 
2025-03-06 04:00:06.900935: Yayy! New best EMA pseudo Dice: 0.7843999862670898 
2025-03-06 04:00:07.644983:  
2025-03-06 04:00:07.650535: Epoch 29 
2025-03-06 04:00:07.653625: Current learning rate: 0.00735 
2025-03-06 04:01:23.002199: train_loss -0.7245 
2025-03-06 04:01:23.009284: val_loss -0.6382 
2025-03-06 04:01:23.013377: Pseudo dice [np.float32(0.8299), np.float32(0.6922), np.float32(0.8599)] 
2025-03-06 04:01:23.016927: Epoch time: 75.36 s 
2025-03-06 04:01:23.019968: Yayy! New best EMA pseudo Dice: 0.7853999733924866 
2025-03-06 04:01:23.753851:  
2025-03-06 04:01:23.757866: Epoch 30 
2025-03-06 04:01:23.761407: Current learning rate: 0.00725 
2025-03-06 04:02:39.051430: train_loss -0.7334 
2025-03-06 04:02:39.057955: val_loss -0.6625 
2025-03-06 04:02:39.061970: Pseudo dice [np.float32(0.8307), np.float32(0.7128), np.float32(0.8631)] 
2025-03-06 04:02:39.065482: Epoch time: 75.3 s 
2025-03-06 04:02:39.068990: Yayy! New best EMA pseudo Dice: 0.7870000004768372 
2025-03-06 04:02:39.810019:  
2025-03-06 04:02:39.816166: Epoch 31 
2025-03-06 04:02:39.819676: Current learning rate: 0.00716 
2025-03-06 04:03:55.258763: train_loss -0.741 
2025-03-06 04:03:55.265781: val_loss -0.6234 
2025-03-06 04:03:55.268790: Pseudo dice [np.float32(0.8223), np.float32(0.7142), np.float32(0.8464)] 
2025-03-06 04:03:55.272299: Epoch time: 75.45 s 
2025-03-06 04:03:55.275807: Yayy! New best EMA pseudo Dice: 0.7878000140190125 
2025-03-06 04:03:56.003837:  
2025-03-06 04:03:56.007958: Epoch 32 
2025-03-06 04:03:56.011513: Current learning rate: 0.00707 
2025-03-06 04:05:11.358139: train_loss -0.7299 
2025-03-06 04:05:11.365661: val_loss -0.6471 
2025-03-06 04:05:11.369171: Pseudo dice [np.float32(0.8181), np.float32(0.727), np.float32(0.8599)] 
2025-03-06 04:05:11.372731: Epoch time: 75.36 s 
2025-03-06 04:05:11.375763: Yayy! New best EMA pseudo Dice: 0.7892000079154968 
2025-03-06 04:05:12.104907:  
2025-03-06 04:05:12.111649: Epoch 33 
2025-03-06 04:05:12.115194: Current learning rate: 0.00697 
2025-03-06 04:06:27.600706: train_loss -0.7297 
2025-03-06 04:06:27.607222: val_loss -0.6479 
2025-03-06 04:06:27.611732: Pseudo dice [np.float32(0.8267), np.float32(0.7195), np.float32(0.8709)] 
2025-03-06 04:06:27.614745: Epoch time: 75.49 s 
2025-03-06 04:06:27.618259: Yayy! New best EMA pseudo Dice: 0.7907999753952026 
2025-03-06 04:06:28.341700:  
2025-03-06 04:06:28.346776: Epoch 34 
2025-03-06 04:06:28.350847: Current learning rate: 0.00688 
2025-03-06 04:07:43.767189: train_loss -0.7407 
2025-03-06 04:07:43.773789: val_loss -0.6392 
2025-03-06 04:07:43.777334: Pseudo dice [np.float32(0.826), np.float32(0.6973), np.float32(0.877)] 
2025-03-06 04:07:43.780860: Epoch time: 75.43 s 
2025-03-06 04:07:43.784613: Yayy! New best EMA pseudo Dice: 0.791700005531311 
2025-03-06 04:07:44.544694:  
2025-03-06 04:07:44.549710: Epoch 35 
2025-03-06 04:07:44.553768: Current learning rate: 0.00679 
2025-03-06 04:08:59.929112: train_loss -0.7479 
2025-03-06 04:08:59.936175: val_loss -0.646 
2025-03-06 04:08:59.939268: Pseudo dice [np.float32(0.8246), np.float32(0.6989), np.float32(0.8564)] 
2025-03-06 04:08:59.943279: Epoch time: 75.39 s 
2025-03-06 04:08:59.945786: Yayy! New best EMA pseudo Dice: 0.7918999791145325 
2025-03-06 04:09:00.838698:  
2025-03-06 04:09:00.843751: Epoch 36 
2025-03-06 04:09:00.847343: Current learning rate: 0.00669 
2025-03-06 04:10:15.769985: train_loss -0.7436 
2025-03-06 04:10:15.776863: val_loss -0.6267 
2025-03-06 04:10:15.780387: Pseudo dice [np.float32(0.8296), np.float32(0.6815), np.float32(0.8518)] 
2025-03-06 04:10:15.783919: Epoch time: 74.93 s 
2025-03-06 04:10:16.358859:  
2025-03-06 04:10:16.364458: Epoch 37 
2025-03-06 04:10:16.366994: Current learning rate: 0.0066 
2025-03-06 04:11:31.725641: train_loss -0.7449 
2025-03-06 04:11:31.732162: val_loss -0.6503 
2025-03-06 04:11:31.736675: Pseudo dice [np.float32(0.8366), np.float32(0.7136), np.float32(0.8648)] 
2025-03-06 04:11:31.739688: Epoch time: 75.37 s 
2025-03-06 04:11:31.743199: Yayy! New best EMA pseudo Dice: 0.7928000092506409 
2025-03-06 04:11:32.487878:  
2025-03-06 04:11:32.493461: Epoch 38 
2025-03-06 04:11:32.498069: Current learning rate: 0.0065 
2025-03-06 04:12:48.004915: train_loss -0.7462 
2025-03-06 04:12:48.012054: val_loss -0.6407 
2025-03-06 04:12:48.016221: Pseudo dice [np.float32(0.8295), np.float32(0.7152), np.float32(0.8714)] 
2025-03-06 04:12:48.019736: Epoch time: 75.52 s 
2025-03-06 04:12:48.022748: Yayy! New best EMA pseudo Dice: 0.7940999865531921 
2025-03-06 04:12:48.766919:  
2025-03-06 04:12:48.773497: Epoch 39 
2025-03-06 04:12:48.777508: Current learning rate: 0.00641 
2025-03-06 04:14:04.184791: train_loss -0.7416 
2025-03-06 04:14:04.193332: val_loss -0.6256 
2025-03-06 04:14:04.197007: Pseudo dice [np.float32(0.8242), np.float32(0.6466), np.float32(0.8662)] 
2025-03-06 04:14:04.200019: Epoch time: 75.42 s 
2025-03-06 04:14:04.783765:  
2025-03-06 04:14:04.787803: Epoch 40 
2025-03-06 04:14:04.792369: Current learning rate: 0.00631 
2025-03-06 04:15:19.902883: train_loss -0.7496 
2025-03-06 04:15:19.909461: val_loss -0.6385 
2025-03-06 04:15:19.913472: Pseudo dice [np.float32(0.8231), np.float32(0.7), np.float32(0.8649)] 
2025-03-06 04:15:19.919494: Epoch time: 75.12 s 
2025-03-06 04:15:20.498512:  
2025-03-06 04:15:20.505102: Epoch 41 
2025-03-06 04:15:20.508127: Current learning rate: 0.00622 
2025-03-06 04:16:36.307611: train_loss -0.7425 
2025-03-06 04:16:36.314848: val_loss -0.6387 
2025-03-06 04:16:36.318384: Pseudo dice [np.float32(0.827), np.float32(0.6816), np.float32(0.8575)] 
2025-03-06 04:16:36.322439: Epoch time: 75.81 s 
2025-03-06 04:16:36.879092:  
2025-03-06 04:16:36.884607: Epoch 42 
2025-03-06 04:16:36.888116: Current learning rate: 0.00612 
2025-03-06 04:17:52.149883: train_loss -0.7506 
2025-03-06 04:17:52.158406: val_loss -0.644 
2025-03-06 04:17:52.162417: Pseudo dice [np.float32(0.8323), np.float32(0.7144), np.float32(0.8617)] 
2025-03-06 04:17:52.166427: Epoch time: 75.27 s 
2025-03-06 04:17:52.876288:  
2025-03-06 04:17:52.881851: Epoch 43 
2025-03-06 04:17:52.886541: Current learning rate: 0.00603 
2025-03-06 04:19:08.256956: train_loss -0.7514 
2025-03-06 04:19:08.264021: val_loss -0.6465 
2025-03-06 04:19:08.268034: Pseudo dice [np.float32(0.8329), np.float32(0.6975), np.float32(0.8695)] 
2025-03-06 04:19:08.271541: Epoch time: 75.38 s 
2025-03-06 04:19:08.274552: Yayy! New best EMA pseudo Dice: 0.7942000031471252 
2025-03-06 04:19:08.971293:  
2025-03-06 04:19:08.977809: Epoch 44 
2025-03-06 04:19:08.981317: Current learning rate: 0.00593 
2025-03-06 04:20:24.379294: train_loss -0.756 
2025-03-06 04:20:24.387448: val_loss -0.6495 
2025-03-06 04:20:24.392031: Pseudo dice [np.float32(0.8322), np.float32(0.7241), np.float32(0.874)] 
2025-03-06 04:20:24.395574: Epoch time: 75.41 s 
2025-03-06 04:20:24.399741: Yayy! New best EMA pseudo Dice: 0.795799970626831 
2025-03-06 04:20:25.116534:  
2025-03-06 04:20:25.121606: Epoch 45 
2025-03-06 04:20:25.125749: Current learning rate: 0.00584 
2025-03-06 04:21:40.705505: train_loss -0.7533 
2025-03-06 04:21:40.712522: val_loss -0.6278 
2025-03-06 04:21:40.716537: Pseudo dice [np.float32(0.8102), np.float32(0.7145), np.float32(0.8503)] 
2025-03-06 04:21:40.720546: Epoch time: 75.59 s 
2025-03-06 04:21:41.278105:  
2025-03-06 04:21:41.283136: Epoch 46 
2025-03-06 04:21:41.286721: Current learning rate: 0.00574 
2025-03-06 04:22:56.730649: train_loss -0.7584 
2025-03-06 04:22:56.737171: val_loss -0.6476 
2025-03-06 04:22:56.740683: Pseudo dice [np.float32(0.8295), np.float32(0.7096), np.float32(0.8813)] 
2025-03-06 04:22:56.744695: Epoch time: 75.45 s 
2025-03-06 04:22:56.748205: Yayy! New best EMA pseudo Dice: 0.796500027179718 
2025-03-06 04:22:57.457693:  
2025-03-06 04:22:57.463766: Epoch 47 
2025-03-06 04:22:57.467805: Current learning rate: 0.00565 
2025-03-06 04:24:12.739072: train_loss -0.7514 
2025-03-06 04:24:12.746602: val_loss -0.6437 
2025-03-06 04:24:12.750612: Pseudo dice [np.float32(0.83), np.float32(0.7253), np.float32(0.8569)] 
2025-03-06 04:24:12.754125: Epoch time: 75.28 s 
2025-03-06 04:24:12.758138: Yayy! New best EMA pseudo Dice: 0.7972999811172485 
2025-03-06 04:24:13.476485:  
2025-03-06 04:24:13.482541: Epoch 48 
2025-03-06 04:24:13.485666: Current learning rate: 0.00555 
2025-03-06 04:25:28.976435: train_loss -0.7506 
2025-03-06 04:25:28.982950: val_loss -0.6493 
2025-03-06 04:25:28.986460: Pseudo dice [np.float32(0.8281), np.float32(0.7169), np.float32(0.861)] 
2025-03-06 04:25:28.990469: Epoch time: 75.5 s 
2025-03-06 04:25:28.993979: Yayy! New best EMA pseudo Dice: 0.7976999878883362 
2025-03-06 04:25:29.724384:  
2025-03-06 04:25:29.729904: Epoch 49 
2025-03-06 04:25:29.733439: Current learning rate: 0.00546 
2025-03-06 04:26:45.184619: train_loss -0.7465 
2025-03-06 04:26:45.191137: val_loss -0.6349 
2025-03-06 04:26:45.195646: Pseudo dice [np.float32(0.8262), np.float32(0.7029), np.float32(0.8596)] 
2025-03-06 04:26:45.198658: Epoch time: 75.46 s 
2025-03-06 04:26:45.919586:  
2025-03-06 04:26:45.925651: Epoch 50 
2025-03-06 04:26:45.929179: Current learning rate: 0.00536 
2025-03-06 04:28:01.108072: train_loss -0.7653 
2025-03-06 04:28:01.114258: val_loss -0.632 
2025-03-06 04:28:01.118817: Pseudo dice [np.float32(0.829), np.float32(0.6862), np.float32(0.871)] 
2025-03-06 04:28:01.122392: Epoch time: 75.19 s 
2025-03-06 04:28:01.844266:  
2025-03-06 04:28:01.850781: Epoch 51 
2025-03-06 04:28:01.854289: Current learning rate: 0.00526 
2025-03-06 04:29:17.404449: train_loss -0.7614 
2025-03-06 04:29:17.411565: val_loss -0.6295 
2025-03-06 04:29:17.415109: Pseudo dice [np.float32(0.8189), np.float32(0.7147), np.float32(0.8504)] 
2025-03-06 04:29:17.417729: Epoch time: 75.56 s 
2025-03-06 04:29:17.976078:  
2025-03-06 04:29:17.980874: Epoch 52 
2025-03-06 04:29:17.983407: Current learning rate: 0.00517 
2025-03-06 04:30:33.420317: train_loss -0.7596 
2025-03-06 04:30:33.426930: val_loss -0.6455 
2025-03-06 04:30:33.430024: Pseudo dice [np.float32(0.827), np.float32(0.7003), np.float32(0.8646)] 
2025-03-06 04:30:33.433536: Epoch time: 75.45 s 
2025-03-06 04:30:33.989429:  
2025-03-06 04:30:33.995441: Epoch 53 
2025-03-06 04:30:33.998450: Current learning rate: 0.00507 
2025-03-06 04:31:49.439108: train_loss -0.7611 
2025-03-06 04:31:49.445129: val_loss -0.6349 
2025-03-06 04:31:49.449143: Pseudo dice [np.float32(0.8245), np.float32(0.6694), np.float32(0.8609)] 
2025-03-06 04:31:49.452651: Epoch time: 75.45 s 
2025-03-06 04:31:50.016308:  
2025-03-06 04:31:50.021927: Epoch 54 
2025-03-06 04:31:50.024969: Current learning rate: 0.00497 
2025-03-06 04:33:05.534922: train_loss -0.7656 
2025-03-06 04:33:05.541440: val_loss -0.6506 
2025-03-06 04:33:05.546013: Pseudo dice [np.float32(0.8384), np.float32(0.7174), np.float32(0.8588)] 
2025-03-06 04:33:05.549070: Epoch time: 75.52 s 
2025-03-06 04:33:06.116027:  
2025-03-06 04:33:06.121589: Epoch 55 
2025-03-06 04:33:06.124598: Current learning rate: 0.00487 
2025-03-06 04:34:21.469859: train_loss -0.7661 
2025-03-06 04:34:21.475440: val_loss -0.6448 
2025-03-06 04:34:21.477989: Pseudo dice [np.float32(0.8296), np.float32(0.7327), np.float32(0.8599)] 
2025-03-06 04:34:21.482525: Epoch time: 75.35 s 
2025-03-06 04:34:21.485035: Yayy! New best EMA pseudo Dice: 0.7979000210762024 
2025-03-06 04:34:22.203577:  
2025-03-06 04:34:22.209130: Epoch 56 
2025-03-06 04:34:22.212147: Current learning rate: 0.00478 
2025-03-06 04:35:37.496425: train_loss -0.762 
2025-03-06 04:35:37.502484: val_loss -0.6429 
2025-03-06 04:35:37.505993: Pseudo dice [np.float32(0.834), np.float32(0.7255), np.float32(0.8619)] 
2025-03-06 04:35:37.509501: Epoch time: 75.29 s 
2025-03-06 04:35:37.512514: Yayy! New best EMA pseudo Dice: 0.798799991607666 
2025-03-06 04:35:38.243981:  
2025-03-06 04:35:38.249109: Epoch 57 
2025-03-06 04:35:38.252632: Current learning rate: 0.00468 
2025-03-06 04:36:53.629809: train_loss -0.763 
2025-03-06 04:36:53.637480: val_loss -0.625 
2025-03-06 04:36:53.641008: Pseudo dice [np.float32(0.8205), np.float32(0.6975), np.float32(0.8589)] 
2025-03-06 04:36:53.643531: Epoch time: 75.39 s 
2025-03-06 04:36:54.211608:  
2025-03-06 04:36:54.216118: Epoch 58 
2025-03-06 04:36:54.219128: Current learning rate: 0.00458 
2025-03-06 04:38:09.960341: train_loss -0.7662 
2025-03-06 04:38:09.965358: val_loss -0.6386 
2025-03-06 04:38:09.968871: Pseudo dice [np.float32(0.8301), np.float32(0.6883), np.float32(0.8582)] 
2025-03-06 04:38:09.972379: Epoch time: 75.75 s 
2025-03-06 04:38:10.759003:  
2025-03-06 04:38:10.763080: Epoch 59 
2025-03-06 04:38:10.766623: Current learning rate: 0.00448 
2025-03-06 04:39:26.311220: train_loss -0.7649 
2025-03-06 04:39:26.317298: val_loss -0.6503 
2025-03-06 04:39:26.320340: Pseudo dice [np.float32(0.8199), np.float32(0.7134), np.float32(0.8686)] 
2025-03-06 04:39:26.323923: Epoch time: 75.55 s 
2025-03-06 04:39:26.888321:  
2025-03-06 04:39:26.893390: Epoch 60 
2025-03-06 04:39:26.896450: Current learning rate: 0.00438 
2025-03-06 04:40:42.218008: train_loss -0.7689 
2025-03-06 04:40:42.224599: val_loss -0.631 
2025-03-06 04:40:42.228641: Pseudo dice [np.float32(0.8324), np.float32(0.7003), np.float32(0.8664)] 
2025-03-06 04:40:42.231841: Epoch time: 75.33 s 
2025-03-06 04:40:42.812707:  
2025-03-06 04:40:42.815740: Epoch 61 
2025-03-06 04:40:42.819359: Current learning rate: 0.00429 
2025-03-06 04:41:58.044757: train_loss -0.7625 
2025-03-06 04:41:58.051270: val_loss -0.659 
2025-03-06 04:41:58.054779: Pseudo dice [np.float32(0.8269), np.float32(0.7132), np.float32(0.8725)] 
2025-03-06 04:41:58.057285: Epoch time: 75.23 s 
2025-03-06 04:41:58.623177:  
2025-03-06 04:41:58.628188: Epoch 62 
2025-03-06 04:41:58.631197: Current learning rate: 0.00419 
2025-03-06 04:43:13.980497: train_loss -0.7693 
2025-03-06 04:43:13.987563: val_loss -0.6423 
2025-03-06 04:43:13.990691: Pseudo dice [np.float32(0.8344), np.float32(0.7221), np.float32(0.8626)] 
2025-03-06 04:43:13.993772: Epoch time: 75.36 s 
2025-03-06 04:43:13.996826: Yayy! New best EMA pseudo Dice: 0.7993999719619751 
2025-03-06 04:43:14.713979:  
2025-03-06 04:43:14.719494: Epoch 63 
2025-03-06 04:43:14.723004: Current learning rate: 0.00409 
2025-03-06 04:44:30.238726: train_loss -0.7689 
2025-03-06 04:44:30.245245: val_loss -0.6593 
2025-03-06 04:44:30.248757: Pseudo dice [np.float32(0.8467), np.float32(0.7317), np.float32(0.8751)] 
2025-03-06 04:44:30.252268: Epoch time: 75.53 s 
2025-03-06 04:44:30.255937: Yayy! New best EMA pseudo Dice: 0.8012999892234802 
2025-03-06 04:44:30.999657:  
2025-03-06 04:44:31.005720: Epoch 64 
2025-03-06 04:44:31.009250: Current learning rate: 0.00399 
2025-03-06 04:45:46.534760: train_loss -0.771 
2025-03-06 04:45:46.540773: val_loss -0.659 
2025-03-06 04:45:46.544784: Pseudo dice [np.float32(0.8414), np.float32(0.7413), np.float32(0.8461)] 
2025-03-06 04:45:46.548294: Epoch time: 75.54 s 
2025-03-06 04:45:46.550799: Yayy! New best EMA pseudo Dice: 0.8021000027656555 
2025-03-06 04:45:47.286366:  
2025-03-06 04:45:47.291377: Epoch 65 
2025-03-06 04:45:47.294887: Current learning rate: 0.00389 
2025-03-06 04:47:02.804737: train_loss -0.7733 
2025-03-06 04:47:02.811264: val_loss -0.629 
2025-03-06 04:47:02.813773: Pseudo dice [np.float32(0.8151), np.float32(0.7229), np.float32(0.8538)] 
2025-03-06 04:47:02.817784: Epoch time: 75.52 s 
2025-03-06 04:47:03.412415:  
2025-03-06 04:47:03.417946: Epoch 66 
2025-03-06 04:47:03.421454: Current learning rate: 0.00379 
2025-03-06 04:48:18.833755: train_loss -0.7728 
2025-03-06 04:48:18.839773: val_loss -0.6351 
2025-03-06 04:48:18.843781: Pseudo dice [np.float32(0.8356), np.float32(0.704), np.float32(0.8497)] 
2025-03-06 04:48:18.847292: Epoch time: 75.42 s 
2025-03-06 04:48:19.596238:  
2025-03-06 04:48:19.601353: Epoch 67 
2025-03-06 04:48:19.604196: Current learning rate: 0.00369 
2025-03-06 04:49:35.040575: train_loss -0.7677 
2025-03-06 04:49:35.047088: val_loss -0.6401 
2025-03-06 04:49:35.050598: Pseudo dice [np.float32(0.8341), np.float32(0.6985), np.float32(0.8587)] 
2025-03-06 04:49:35.053105: Epoch time: 75.44 s 
2025-03-06 04:49:35.629637:  
2025-03-06 04:49:35.636654: Epoch 68 
2025-03-06 04:49:35.641667: Current learning rate: 0.00359 
2025-03-06 04:50:50.743573: train_loss -0.7686 
2025-03-06 04:50:50.750589: val_loss -0.6536 
2025-03-06 04:50:50.754151: Pseudo dice [np.float32(0.8342), np.float32(0.7185), np.float32(0.8582)] 
2025-03-06 04:50:50.757189: Epoch time: 75.12 s 
2025-03-06 04:50:51.348610:  
2025-03-06 04:50:51.355205: Epoch 69 
2025-03-06 04:50:51.357752: Current learning rate: 0.00349 
2025-03-06 04:52:06.903426: train_loss -0.7721 
2025-03-06 04:52:06.908523: val_loss -0.6484 
2025-03-06 04:52:06.913188: Pseudo dice [np.float32(0.8375), np.float32(0.7225), np.float32(0.8474)] 
2025-03-06 04:52:06.916754: Epoch time: 75.55 s 
2025-03-06 04:52:07.493030:  
2025-03-06 04:52:07.499085: Epoch 70 
2025-03-06 04:52:07.502205: Current learning rate: 0.00338 
2025-03-06 04:53:22.661810: train_loss -0.7701 
2025-03-06 04:53:22.667826: val_loss -0.6556 
2025-03-06 04:53:22.670837: Pseudo dice [np.float32(0.8407), np.float32(0.7111), np.float32(0.8754)] 
2025-03-06 04:53:22.674348: Epoch time: 75.17 s 
2025-03-06 04:53:23.285152:  
2025-03-06 04:53:23.291304: Epoch 71 
2025-03-06 04:53:23.294844: Current learning rate: 0.00328 
2025-03-06 04:54:38.806896: train_loss -0.7694 
2025-03-06 04:54:38.815423: val_loss -0.6279 
2025-03-06 04:54:38.819435: Pseudo dice [np.float32(0.8309), np.float32(0.6835), np.float32(0.8706)] 
2025-03-06 04:54:38.822947: Epoch time: 75.52 s 
2025-03-06 04:54:39.399337:  
2025-03-06 04:54:39.404350: Epoch 72 
2025-03-06 04:54:39.407858: Current learning rate: 0.00318 
2025-03-06 04:55:54.849775: train_loss -0.7715 
2025-03-06 04:55:54.856294: val_loss -0.6614 
2025-03-06 04:55:54.859803: Pseudo dice [np.float32(0.8458), np.float32(0.7452), np.float32(0.8657)] 
2025-03-06 04:55:54.863310: Epoch time: 75.45 s 
2025-03-06 04:55:54.866320: Yayy! New best EMA pseudo Dice: 0.8029999732971191 
2025-03-06 04:55:55.607477:  
2025-03-06 04:55:55.613528: Epoch 73 
2025-03-06 04:55:55.617036: Current learning rate: 0.00308 
2025-03-06 04:57:10.906783: train_loss -0.7776 
2025-03-06 04:57:10.913801: val_loss -0.6466 
2025-03-06 04:57:10.917827: Pseudo dice [np.float32(0.8255), np.float32(0.7006), np.float32(0.862)] 
2025-03-06 04:57:10.921334: Epoch time: 75.3 s 
2025-03-06 04:57:11.666241:  
2025-03-06 04:57:11.671814: Epoch 74 
2025-03-06 04:57:11.674366: Current learning rate: 0.00297 
2025-03-06 04:58:26.800706: train_loss -0.7707 
2025-03-06 04:58:26.806725: val_loss -0.6363 
2025-03-06 04:58:26.810235: Pseudo dice [np.float32(0.8315), np.float32(0.7212), np.float32(0.8694)] 
2025-03-06 04:58:26.813245: Epoch time: 75.13 s 
2025-03-06 04:58:27.409512:  
2025-03-06 04:58:27.414524: Epoch 75 
2025-03-06 04:58:27.418038: Current learning rate: 0.00287 
2025-03-06 04:59:42.620140: train_loss -0.7749 
2025-03-06 04:59:42.627663: val_loss -0.6546 
2025-03-06 04:59:42.630688: Pseudo dice [np.float32(0.837), np.float32(0.7308), np.float32(0.8772)] 
2025-03-06 04:59:42.633724: Epoch time: 75.21 s 
2025-03-06 04:59:42.637236: Yayy! New best EMA pseudo Dice: 0.8040000200271606 
2025-03-06 04:59:43.360757:  
2025-03-06 04:59:43.366833: Epoch 76 
2025-03-06 04:59:43.370428: Current learning rate: 0.00277 
2025-03-06 05:00:58.784188: train_loss -0.7781 
2025-03-06 05:00:58.790203: val_loss -0.6436 
2025-03-06 05:00:58.794219: Pseudo dice [np.float32(0.8328), np.float32(0.7176), np.float32(0.8715)] 
2025-03-06 05:00:58.796725: Epoch time: 75.42 s 
2025-03-06 05:00:58.800238: Yayy! New best EMA pseudo Dice: 0.8044000267982483 
2025-03-06 05:00:59.547587:  
2025-03-06 05:00:59.551150: Epoch 77 
2025-03-06 05:00:59.555217: Current learning rate: 0.00266 
2025-03-06 05:02:14.945986: train_loss -0.7764 
2025-03-06 05:02:14.952501: val_loss -0.6526 
2025-03-06 05:02:14.956013: Pseudo dice [np.float32(0.842), np.float32(0.721), np.float32(0.8692)] 
2025-03-06 05:02:14.959520: Epoch time: 75.4 s 
2025-03-06 05:02:14.962531: Yayy! New best EMA pseudo Dice: 0.8050000071525574 
2025-03-06 05:02:15.731828:  
2025-03-06 05:02:15.736840: Epoch 78 
2025-03-06 05:02:15.740348: Current learning rate: 0.00256 
2025-03-06 05:03:31.370959: train_loss -0.7795 
2025-03-06 05:03:31.378476: val_loss -0.6299 
2025-03-06 05:03:31.384500: Pseudo dice [np.float32(0.82), np.float32(0.6942), np.float32(0.8635)] 
2025-03-06 05:03:31.388513: Epoch time: 75.64 s 
2025-03-06 05:03:31.965476:  
2025-03-06 05:03:31.971559: Epoch 79 
2025-03-06 05:03:31.975070: Current learning rate: 0.00245 
2025-03-06 05:04:47.630308: train_loss -0.7775 
2025-03-06 05:04:47.637230: val_loss -0.6606 
2025-03-06 05:04:47.640775: Pseudo dice [np.float32(0.8304), np.float32(0.723), np.float32(0.8625)] 
2025-03-06 05:04:47.644904: Epoch time: 75.66 s 
2025-03-06 05:04:48.247229:  
2025-03-06 05:04:48.253284: Epoch 80 
2025-03-06 05:04:48.256341: Current learning rate: 0.00235 
2025-03-06 05:06:03.550369: train_loss -0.7785 
2025-03-06 05:06:03.556545: val_loss -0.6625 
2025-03-06 05:06:03.560631: Pseudo dice [np.float32(0.8433), np.float32(0.7354), np.float32(0.8786)] 
2025-03-06 05:06:03.564199: Epoch time: 75.3 s 
2025-03-06 05:06:03.567294: Yayy! New best EMA pseudo Dice: 0.805400013923645 
2025-03-06 05:06:04.299408:  
2025-03-06 05:06:04.305465: Epoch 81 
2025-03-06 05:06:04.309036: Current learning rate: 0.00224 
2025-03-06 05:07:19.720456: train_loss -0.7765 
2025-03-06 05:07:19.727071: val_loss -0.6457 
2025-03-06 05:07:19.730612: Pseudo dice [np.float32(0.8393), np.float32(0.7506), np.float32(0.86)] 
2025-03-06 05:07:19.733321: Epoch time: 75.42 s 
2025-03-06 05:07:19.736870: Yayy! New best EMA pseudo Dice: 0.8065000176429749 
2025-03-06 05:07:20.662262:  
2025-03-06 05:07:20.668848: Epoch 82 
2025-03-06 05:07:20.671395: Current learning rate: 0.00214 
2025-03-06 05:08:36.033969: train_loss -0.7817 
2025-03-06 05:08:36.040986: val_loss -0.6542 
2025-03-06 05:08:36.043995: Pseudo dice [np.float32(0.8308), np.float32(0.7338), np.float32(0.8662)] 
2025-03-06 05:08:36.048505: Epoch time: 75.37 s 
2025-03-06 05:08:36.051518: Yayy! New best EMA pseudo Dice: 0.8069000244140625 
2025-03-06 05:08:36.795552:  
2025-03-06 05:08:36.801116: Epoch 83 
2025-03-06 05:08:36.803657: Current learning rate: 0.00203 
2025-03-06 05:09:52.129717: train_loss -0.7793 
2025-03-06 05:09:52.136771: val_loss -0.6478 
2025-03-06 05:09:52.139924: Pseudo dice [np.float32(0.8278), np.float32(0.7062), np.float32(0.8607)] 
2025-03-06 05:09:52.143434: Epoch time: 75.33 s 
2025-03-06 05:09:52.705311:  
2025-03-06 05:09:52.710829: Epoch 84 
2025-03-06 05:09:52.714339: Current learning rate: 0.00192 
2025-03-06 05:11:08.179847: train_loss -0.7819 
2025-03-06 05:11:08.186927: val_loss -0.656 
2025-03-06 05:11:08.190495: Pseudo dice [np.float32(0.8335), np.float32(0.7104), np.float32(0.8727)] 
2025-03-06 05:11:08.193144: Epoch time: 75.48 s 
2025-03-06 05:11:08.766907:  
2025-03-06 05:11:08.772469: Epoch 85 
2025-03-06 05:11:08.775003: Current learning rate: 0.00181 
2025-03-06 05:12:24.091719: train_loss -0.7833 
2025-03-06 05:12:24.098762: val_loss -0.6419 
2025-03-06 05:12:24.101826: Pseudo dice [np.float32(0.8273), np.float32(0.692), np.float32(0.8648)] 
2025-03-06 05:12:24.105335: Epoch time: 75.33 s 
2025-03-06 05:12:24.657231:  
2025-03-06 05:12:24.663288: Epoch 86 
2025-03-06 05:12:24.666353: Current learning rate: 0.0017 
2025-03-06 05:13:39.699120: train_loss -0.7772 
2025-03-06 05:13:39.706139: val_loss -0.6545 
2025-03-06 05:13:39.709150: Pseudo dice [np.float32(0.8357), np.float32(0.7291), np.float32(0.8704)] 
2025-03-06 05:13:39.712667: Epoch time: 75.04 s 
2025-03-06 05:13:40.265970:  
2025-03-06 05:13:40.269481: Epoch 87 
2025-03-06 05:13:40.273538: Current learning rate: 0.00159 
2025-03-06 05:14:55.663686: train_loss -0.7843 
2025-03-06 05:14:55.671209: val_loss -0.6359 
2025-03-06 05:14:55.674719: Pseudo dice [np.float32(0.8219), np.float32(0.7235), np.float32(0.8589)] 
2025-03-06 05:14:55.677225: Epoch time: 75.4 s 
2025-03-06 05:14:56.236305:  
2025-03-06 05:14:56.241820: Epoch 88 
2025-03-06 05:14:56.244326: Current learning rate: 0.00148 
2025-03-06 05:16:11.560665: train_loss -0.7797 
2025-03-06 05:16:11.567687: val_loss -0.6489 
2025-03-06 05:16:11.570698: Pseudo dice [np.float32(0.8269), np.float32(0.7259), np.float32(0.8729)] 
2025-03-06 05:16:11.574212: Epoch time: 75.33 s 
2025-03-06 05:16:12.138580:  
2025-03-06 05:16:12.143615: Epoch 89 
2025-03-06 05:16:12.147173: Current learning rate: 0.00137 
2025-03-06 05:17:27.568254: train_loss -0.7886 
2025-03-06 05:17:27.574355: val_loss -0.654 
2025-03-06 05:17:27.577868: Pseudo dice [np.float32(0.8303), np.float32(0.7424), np.float32(0.8749)] 
2025-03-06 05:17:27.581882: Epoch time: 75.43 s 
2025-03-06 05:17:28.293281:  
2025-03-06 05:17:28.298797: Epoch 90 
2025-03-06 05:17:28.301303: Current learning rate: 0.00126 
2025-03-06 05:18:43.635689: train_loss -0.7824 
2025-03-06 05:18:43.641852: val_loss -0.6328 
2025-03-06 05:18:43.645366: Pseudo dice [np.float32(0.829), np.float32(0.7203), np.float32(0.8545)] 
2025-03-06 05:18:43.649375: Epoch time: 75.34 s 
2025-03-06 05:18:44.196951:  
2025-03-06 05:18:44.201980: Epoch 91 
2025-03-06 05:18:44.205586: Current learning rate: 0.00115 
2025-03-06 05:19:59.578612: train_loss -0.7887 
2025-03-06 05:19:59.586139: val_loss -0.6545 
2025-03-06 05:19:59.589653: Pseudo dice [np.float32(0.8236), np.float32(0.7261), np.float32(0.868)] 
2025-03-06 05:19:59.592665: Epoch time: 75.38 s 
2025-03-06 05:20:00.158680:  
2025-03-06 05:20:00.163691: Epoch 92 
2025-03-06 05:20:00.167199: Current learning rate: 0.00103 
2025-03-06 05:21:15.397092: train_loss -0.7838 
2025-03-06 05:21:15.401603: val_loss -0.6708 
2025-03-06 05:21:15.404613: Pseudo dice [np.float32(0.8387), np.float32(0.7331), np.float32(0.8714)] 
2025-03-06 05:21:15.408123: Epoch time: 75.24 s 
2025-03-06 05:21:15.966403:  
2025-03-06 05:21:15.971955: Epoch 93 
2025-03-06 05:21:15.974495: Current learning rate: 0.00091 
2025-03-06 05:22:31.521752: train_loss -0.7857 
2025-03-06 05:22:31.527874: val_loss -0.6376 
2025-03-06 05:22:31.531884: Pseudo dice [np.float32(0.8289), np.float32(0.676), np.float32(0.8717)] 
2025-03-06 05:22:31.535395: Epoch time: 75.56 s 
2025-03-06 05:22:32.095078:  
2025-03-06 05:22:32.100096: Epoch 94 
2025-03-06 05:22:32.103606: Current learning rate: 0.00079 
2025-03-06 05:23:47.587205: train_loss -0.787 
2025-03-06 05:23:47.594293: val_loss -0.6587 
2025-03-06 05:23:47.598383: Pseudo dice [np.float32(0.835), np.float32(0.7466), np.float32(0.8688)] 
2025-03-06 05:23:47.601544: Epoch time: 75.49 s 
2025-03-06 05:23:48.159605:  
2025-03-06 05:23:48.164670: Epoch 95 
2025-03-06 05:23:48.168221: Current learning rate: 0.00067 
2025-03-06 05:25:03.604900: train_loss -0.7885 
2025-03-06 05:25:03.611620: val_loss -0.6472 
2025-03-06 05:25:03.614130: Pseudo dice [np.float32(0.8397), np.float32(0.7131), np.float32(0.8588)] 
2025-03-06 05:25:03.618141: Epoch time: 75.45 s 
2025-03-06 05:25:04.195309:  
2025-03-06 05:25:04.200822: Epoch 96 
2025-03-06 05:25:04.204331: Current learning rate: 0.00055 
2025-03-06 05:26:19.667779: train_loss -0.7865 
2025-03-06 05:26:19.675298: val_loss -0.6437 
2025-03-06 05:26:19.678805: Pseudo dice [np.float32(0.8339), np.float32(0.7099), np.float32(0.8647)] 
2025-03-06 05:26:19.681814: Epoch time: 75.47 s 
2025-03-06 05:26:20.245025:  
2025-03-06 05:26:20.250036: Epoch 97 
2025-03-06 05:26:20.253547: Current learning rate: 0.00043 
2025-03-06 05:27:35.580713: train_loss -0.7889 
2025-03-06 05:27:35.587730: val_loss -0.6394 
2025-03-06 05:27:35.590740: Pseudo dice [np.float32(0.8336), np.float32(0.7065), np.float32(0.8575)] 
2025-03-06 05:27:35.594249: Epoch time: 75.34 s 
2025-03-06 05:27:36.327640:  
2025-03-06 05:27:36.333703: Epoch 98 
2025-03-06 05:27:36.336816: Current learning rate: 0.0003 
2025-03-06 05:28:51.714680: train_loss -0.7866 
2025-03-06 05:28:51.724780: val_loss -0.644 
2025-03-06 05:28:51.730358: Pseudo dice [np.float32(0.8351), np.float32(0.7246), np.float32(0.8611)] 
2025-03-06 05:28:51.733428: Epoch time: 75.39 s 
2025-03-06 05:28:52.304258:  
2025-03-06 05:28:52.309144: Epoch 99 
2025-03-06 05:28:52.312654: Current learning rate: 0.00016 
2025-03-06 05:30:07.844831: train_loss -0.7842 
2025-03-06 05:30:07.849844: val_loss -0.6558 
2025-03-06 05:30:07.853357: Pseudo dice [np.float32(0.8308), np.float32(0.7101), np.float32(0.8525)] 
2025-03-06 05:30:07.857367: Epoch time: 75.54 s 
2025-03-06 05:30:08.623945: Training done. 
2025-03-06 05:30:08.670946: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-06 05:30:08.682951: The split file contains 5 splits. 
2025-03-06 05:30:08.687951: Desired fold for training: 0 
2025-03-06 05:30:08.692950: This split has 387 training and 97 validation cases. 
2025-03-06 05:30:08.699462: predicting BRATS_010 
2025-03-06 05:30:08.705459: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2025-03-06 05:30:10.754971: predicting BRATS_011 
2025-03-06 05:30:10.766971: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2025-03-06 05:30:12.097946: predicting BRATS_012 
2025-03-06 05:30:12.110944: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-06 05:30:13.459968: predicting BRATS_018 
2025-03-06 05:30:13.471968: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2025-03-06 05:30:14.818586: predicting BRATS_020 
2025-03-06 05:30:14.831586: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2025-03-06 05:30:16.173249: predicting BRATS_028 
2025-03-06 05:30:16.186252: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-03-06 05:30:17.537053: predicting BRATS_029 
2025-03-06 05:30:17.550053: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-03-06 05:30:18.899651: predicting BRATS_032 
2025-03-06 05:30:18.913651: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2025-03-06 05:30:20.272444: predicting BRATS_034 
2025-03-06 05:30:20.286447: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2025-03-06 05:30:21.627816: predicting BRATS_041 
2025-03-06 05:30:21.641816: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2025-03-06 05:30:23.020999: predicting BRATS_042 
2025-03-06 05:30:23.032999: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2025-03-06 05:30:24.399859: predicting BRATS_047 
2025-03-06 05:30:24.412863: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-06 05:30:25.764245: predicting BRATS_049 
2025-03-06 05:30:25.777244: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-06 05:30:27.121417: predicting BRATS_053 
2025-03-06 05:30:27.134417: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-06 05:30:28.472157: predicting BRATS_056 
2025-03-06 05:30:28.483157: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-06 05:30:29.821647: predicting BRATS_057 
2025-03-06 05:30:29.834648: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-06 05:30:31.199728: predicting BRATS_067 
2025-03-06 05:30:31.212240: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-06 05:30:32.599837: predicting BRATS_069 
2025-03-06 05:30:32.613172: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-06 05:30:33.953259: predicting BRATS_085 
2025-03-06 05:30:33.966258: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2025-03-06 05:30:34.700554: predicting BRATS_086 
2025-03-06 05:30:34.713718: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2025-03-06 05:30:36.057225: predicting BRATS_088 
2025-03-06 05:30:36.070225: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2025-03-06 05:30:37.421515: predicting BRATS_091 
2025-03-06 05:30:37.434516: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-03-06 05:30:38.774622: predicting BRATS_098 
2025-03-06 05:30:38.788623: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2025-03-06 05:30:40.129088: predicting BRATS_100 
2025-03-06 05:30:40.143089: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-06 05:30:40.859949: predicting BRATS_101 
2025-03-06 05:30:40.873950: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-06 05:30:41.557698: predicting BRATS_102 
2025-03-06 05:30:41.571700: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2025-03-06 05:30:42.912675: predicting BRATS_104 
2025-03-06 05:30:42.926183: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2025-03-06 05:30:44.296090: predicting BRATS_111 
2025-03-06 05:30:44.309093: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2025-03-06 05:30:45.650023: predicting BRATS_116 
2025-03-06 05:30:45.663023: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2025-03-06 05:30:47.006452: predicting BRATS_135 
2025-03-06 05:30:47.020963: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-03-06 05:30:48.370448: predicting BRATS_136 
2025-03-06 05:30:48.384450: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-03-06 05:30:49.727265: predicting BRATS_138 
2025-03-06 05:30:49.740263: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2025-03-06 05:30:51.079318: predicting BRATS_145 
2025-03-06 05:30:51.092319: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2025-03-06 05:30:52.429107: predicting BRATS_149 
2025-03-06 05:30:52.443108: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2025-03-06 05:30:53.788136: predicting BRATS_155 
2025-03-06 05:30:53.804135: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-06 05:30:55.147661: predicting BRATS_157 
2025-03-06 05:30:55.161661: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-06 05:30:56.553726: predicting BRATS_158 
2025-03-06 05:30:56.567728: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-06 05:30:57.912132: predicting BRATS_159 
2025-03-06 05:30:57.924638: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-06 05:30:59.288363: predicting BRATS_163 
2025-03-06 05:30:59.301362: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-03-06 05:31:00.644342: predicting BRATS_164 
2025-03-06 05:31:00.657345: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2025-03-06 05:31:02.007961: predicting BRATS_169 
2025-03-06 05:31:02.018966: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2025-03-06 05:31:03.387360: predicting BRATS_176 
2025-03-06 05:31:03.401363: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-03-06 05:31:04.775519: predicting BRATS_181 
2025-03-06 05:31:04.787518: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2025-03-06 05:31:06.131589: predicting BRATS_183 
2025-03-06 05:31:06.146654: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-06 05:31:07.495953: predicting BRATS_184 
2025-03-06 05:31:07.510955: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-06 05:31:08.858352: predicting BRATS_187 
2025-03-06 05:31:08.873353: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-06 05:31:10.237952: predicting BRATS_192 
2025-03-06 05:31:10.249953: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2025-03-06 05:31:11.588610: predicting BRATS_198 
2025-03-06 05:31:11.601610: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-03-06 05:31:12.977314: predicting BRATS_207 
2025-03-06 05:31:12.992315: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-06 05:31:14.331612: predicting BRATS_208 
2025-03-06 05:31:14.344631: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-06 05:31:15.680472: predicting BRATS_218 
2025-03-06 05:31:15.692473: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-03-06 05:31:17.079416: predicting BRATS_220 
2025-03-06 05:31:17.093416: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2025-03-06 05:31:18.466826: predicting BRATS_224 
2025-03-06 05:31:18.480828: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2025-03-06 05:31:19.824290: predicting BRATS_230 
2025-03-06 05:31:19.838294: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2025-03-06 05:31:21.175959: predicting BRATS_271 
2025-03-06 05:31:21.188958: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2025-03-06 05:31:22.545292: predicting BRATS_282 
2025-03-06 05:31:22.560291: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2025-03-06 05:31:23.903439: predicting BRATS_284 
2025-03-06 05:31:23.917439: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2025-03-06 05:31:25.253444: predicting BRATS_287 
2025-03-06 05:31:25.266444: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-06 05:31:26.653989: predicting BRATS_290 
2025-03-06 05:31:26.667990: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2025-03-06 05:31:28.011416: predicting BRATS_291 
2025-03-06 05:31:28.025417: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-03-06 05:31:29.371546: predicting BRATS_292 
2025-03-06 05:31:29.384546: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2025-03-06 05:31:30.724660: predicting BRATS_293 
2025-03-06 05:31:30.737666: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2025-03-06 05:31:32.084177: predicting BRATS_300 
2025-03-06 05:31:32.099179: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2025-03-06 05:31:33.448365: predicting BRATS_305 
2025-03-06 05:31:33.462873: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2025-03-06 05:31:34.804751: predicting BRATS_311 
2025-03-06 05:31:34.819754: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2025-03-06 05:31:36.160827: predicting BRATS_314 
2025-03-06 05:31:36.175830: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2025-03-06 05:31:37.529129: predicting BRATS_321 
2025-03-06 05:31:37.543132: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-03-06 05:31:38.883739: predicting BRATS_328 
2025-03-06 05:31:38.897738: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2025-03-06 05:31:39.585736: predicting BRATS_329 
2025-03-06 05:31:39.599736: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2025-03-06 05:31:40.991055: predicting BRATS_335 
2025-03-06 05:31:41.005055: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2025-03-06 05:31:42.351383: predicting BRATS_343 
2025-03-06 05:31:42.364478: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2025-03-06 05:31:43.712610: predicting BRATS_350 
2025-03-06 05:31:43.726609: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2025-03-06 05:31:44.428724: predicting BRATS_351 
2025-03-06 05:31:44.441729: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2025-03-06 05:31:45.161076: predicting BRATS_356 
2025-03-06 05:31:45.175076: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2025-03-06 05:31:45.872563: predicting BRATS_366 
2025-03-06 05:31:45.885564: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2025-03-06 05:31:47.223090: predicting BRATS_367 
2025-03-06 05:31:47.236089: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2025-03-06 05:31:48.583509: predicting BRATS_374 
2025-03-06 05:31:48.597509: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2025-03-06 05:31:49.937812: predicting BRATS_376 
2025-03-06 05:31:49.950818: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2025-03-06 05:31:51.297070: predicting BRATS_377 
2025-03-06 05:31:51.311071: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2025-03-06 05:31:52.658681: predicting BRATS_378 
2025-03-06 05:31:52.676859: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2025-03-06 05:31:54.032928: predicting BRATS_379 
2025-03-06 05:31:54.047934: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2025-03-06 05:31:55.392273: predicting BRATS_384 
2025-03-06 05:31:55.407272: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2025-03-06 05:31:56.747132: predicting BRATS_386 
2025-03-06 05:31:56.764645: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-03-06 05:31:58.102449: predicting BRATS_394 
2025-03-06 05:31:58.117451: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-06 05:31:59.461209: predicting BRATS_398 
2025-03-06 05:31:59.475244: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2025-03-06 05:32:00.840650: predicting BRATS_400 
2025-03-06 05:32:00.855655: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2025-03-06 05:32:02.220680: predicting BRATS_432 
2025-03-06 05:32:02.237681: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2025-03-06 05:32:03.598649: predicting BRATS_437 
2025-03-06 05:32:03.613652: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-06 05:32:04.986083: predicting BRATS_445 
2025-03-06 05:32:05.001082: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2025-03-06 05:32:06.360392: predicting BRATS_446 
2025-03-06 05:32:06.374901: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-03-06 05:32:07.718806: predicting BRATS_450 
2025-03-06 05:32:07.733806: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2025-03-06 05:32:09.073134: predicting BRATS_452 
2025-03-06 05:32:09.087137: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2025-03-06 05:32:10.430392: predicting BRATS_460 
2025-03-06 05:32:10.445395: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2025-03-06 05:32:11.793007: predicting BRATS_470 
2025-03-06 05:32:11.808007: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-03-06 05:32:13.151200: predicting BRATS_472 
2025-03-06 05:32:13.167203: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2025-03-06 05:32:14.511724: predicting BRATS_473 
2025-03-06 05:32:14.525726: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2025-03-06 05:32:15.216139: predicting BRATS_482 
2025-03-06 05:32:15.230140: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2025-03-06 05:32:23.655413: Validation complete 
2025-03-06 05:32:23.660636: Mean Validation Dice:  0.7226482716441495 
