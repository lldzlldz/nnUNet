
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-26 02:59:36.570377: do_dummy_2d_data_aug: False 
2025-02-26 02:59:36.622626: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-02-26 02:59:36.632135: The split file contains 5 splits. 
2025-02-26 02:59:36.636133: Desired fold for training: 0 
2025-02-26 02:59:36.639135: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2025-02-26 03:00:10.386996: unpacking dataset... 
2025-02-26 03:00:11.084696: unpacking done... 
2025-02-26 03:00:14.908799:  
2025-02-26 03:00:14.913814: Epoch 0 
2025-02-26 03:00:14.916824: Current learning rate: 0.01 
2025-02-26 03:00:59.757015: train_loss -0.2763 
2025-02-26 03:00:59.764218: val_loss -0.403 
2025-02-26 03:00:59.769794: Pseudo dice [np.float32(0.658), np.float32(0.4795), np.float32(0.7257)] 
2025-02-26 03:00:59.775988: Epoch time: 44.85 s 
2025-02-26 03:00:59.781753: Yayy! New best EMA pseudo Dice: 0.6211000084877014 
2025-02-26 03:01:00.405458:  
2025-02-26 03:01:00.411708: Epoch 1 
2025-02-26 03:01:00.415267: Current learning rate: 0.00991 
2025-02-26 03:01:41.517398: train_loss -0.4769 
2025-02-26 03:01:41.525523: val_loss -0.4492 
2025-02-26 03:01:41.530048: Pseudo dice [np.float32(0.6948), np.float32(0.5613), np.float32(0.779)] 
2025-02-26 03:01:41.535582: Epoch time: 41.11 s 
2025-02-26 03:01:41.541602: Yayy! New best EMA pseudo Dice: 0.626800000667572 
2025-02-26 03:01:42.201667:  
2025-02-26 03:01:42.207331: Epoch 2 
2025-02-26 03:01:42.210358: Current learning rate: 0.00982 
2025-02-26 03:02:23.374540: train_loss -0.5245 
2025-02-26 03:02:23.381730: val_loss -0.4885 
2025-02-26 03:02:23.384748: Pseudo dice [np.float32(0.7365), np.float32(0.5407), np.float32(0.7877)] 
2025-02-26 03:02:23.388257: Epoch time: 41.17 s 
2025-02-26 03:02:23.391767: Yayy! New best EMA pseudo Dice: 0.6328999996185303 
2025-02-26 03:02:24.087341:  
2025-02-26 03:02:24.092352: Epoch 3 
2025-02-26 03:02:24.095861: Current learning rate: 0.00973 
2025-02-26 03:03:05.140242: train_loss -0.5538 
2025-02-26 03:03:05.146868: val_loss -0.4995 
2025-02-26 03:03:05.152420: Pseudo dice [np.float32(0.767), np.float32(0.5364), np.float32(0.7922)] 
2025-02-26 03:03:05.159483: Epoch time: 41.05 s 
2025-02-26 03:03:05.164084: Yayy! New best EMA pseudo Dice: 0.6395000219345093 
2025-02-26 03:03:05.839480:  
2025-02-26 03:03:05.844493: Epoch 4 
2025-02-26 03:03:05.848006: Current learning rate: 0.00964 
2025-02-26 03:03:46.996212: train_loss -0.5907 
2025-02-26 03:03:47.004753: val_loss -0.5674 
2025-02-26 03:03:47.010299: Pseudo dice [np.float32(0.7714), np.float32(0.6087), np.float32(0.8221)] 
2025-02-26 03:03:47.015316: Epoch time: 41.16 s 
2025-02-26 03:03:47.019826: Yayy! New best EMA pseudo Dice: 0.6489999890327454 
2025-02-26 03:03:47.826172:  
2025-02-26 03:03:47.831726: Epoch 5 
2025-02-26 03:03:47.836349: Current learning rate: 0.00955 
2025-02-26 03:04:29.053655: train_loss -0.5941 
2025-02-26 03:04:29.058680: val_loss -0.5329 
2025-02-26 03:04:29.065701: Pseudo dice [np.float32(0.7686), np.float32(0.5577), np.float32(0.8149)] 
2025-02-26 03:04:29.071223: Epoch time: 41.23 s 
2025-02-26 03:04:29.077333: Yayy! New best EMA pseudo Dice: 0.6553999781608582 
2025-02-26 03:04:29.751011:  
2025-02-26 03:04:29.757090: Epoch 6 
2025-02-26 03:04:29.760780: Current learning rate: 0.00946 
2025-02-26 03:05:10.895201: train_loss -0.6083 
2025-02-26 03:05:10.902301: val_loss -0.5924 
2025-02-26 03:05:10.908128: Pseudo dice [np.float32(0.8078), np.float32(0.6305), np.float32(0.8382)] 
2025-02-26 03:05:10.912683: Epoch time: 41.15 s 
2025-02-26 03:05:10.916803: Yayy! New best EMA pseudo Dice: 0.6657999753952026 
2025-02-26 03:05:11.584956:  
2025-02-26 03:05:11.590976: Epoch 7 
2025-02-26 03:05:11.593480: Current learning rate: 0.00937 
2025-02-26 03:05:52.699878: train_loss -0.6044 
2025-02-26 03:05:52.707399: val_loss -0.5519 
2025-02-26 03:05:52.713420: Pseudo dice [np.float32(0.783), np.float32(0.6488), np.float32(0.7959)] 
2025-02-26 03:05:52.719943: Epoch time: 41.12 s 
2025-02-26 03:05:52.724958: Yayy! New best EMA pseudo Dice: 0.6735000014305115 
2025-02-26 03:05:53.401504:  
2025-02-26 03:05:53.405515: Epoch 8 
2025-02-26 03:05:53.409024: Current learning rate: 0.00928 
2025-02-26 03:06:34.468760: train_loss -0.6185 
2025-02-26 03:06:34.476284: val_loss -0.5871 
2025-02-26 03:06:34.482804: Pseudo dice [np.float32(0.7815), np.float32(0.6534), np.float32(0.8262)] 
2025-02-26 03:06:34.488826: Epoch time: 41.07 s 
2025-02-26 03:06:34.494877: Yayy! New best EMA pseudo Dice: 0.6815000176429749 
2025-02-26 03:06:35.183594:  
2025-02-26 03:06:35.189646: Epoch 9 
2025-02-26 03:06:35.192686: Current learning rate: 0.00919 
2025-02-26 03:07:16.164246: train_loss -0.6371 
2025-02-26 03:07:16.171771: val_loss -0.5568 
2025-02-26 03:07:16.175287: Pseudo dice [np.float32(0.7856), np.float32(0.6445), np.float32(0.8498)] 
2025-02-26 03:07:16.179302: Epoch time: 40.98 s 
2025-02-26 03:07:16.182814: Yayy! New best EMA pseudo Dice: 0.689300000667572 
2025-02-26 03:07:16.841098:  
2025-02-26 03:07:16.847144: Epoch 10 
2025-02-26 03:07:16.850666: Current learning rate: 0.0091 
2025-02-26 03:07:57.868643: train_loss -0.6381 
2025-02-26 03:07:57.875163: val_loss -0.5858 
2025-02-26 03:07:57.879175: Pseudo dice [np.float32(0.7962), np.float32(0.6586), np.float32(0.8205)] 
2025-02-26 03:07:57.885194: Epoch time: 41.03 s 
2025-02-26 03:07:57.890210: Yayy! New best EMA pseudo Dice: 0.6962000131607056 
2025-02-26 03:07:58.562665:  
2025-02-26 03:07:58.568181: Epoch 11 
2025-02-26 03:07:58.571690: Current learning rate: 0.009 
2025-02-26 03:08:39.621273: train_loss -0.6395 
2025-02-26 03:08:39.627795: val_loss -0.59 
2025-02-26 03:08:39.632809: Pseudo dice [np.float32(0.7977), np.float32(0.681), np.float32(0.8329)] 
2025-02-26 03:08:39.637529: Epoch time: 41.06 s 
2025-02-26 03:08:39.643556: Yayy! New best EMA pseudo Dice: 0.7037000060081482 
2025-02-26 03:08:40.310412:  
2025-02-26 03:08:40.316463: Epoch 12 
2025-02-26 03:08:40.319968: Current learning rate: 0.00891 
2025-02-26 03:09:21.375812: train_loss -0.6331 
2025-02-26 03:09:21.382825: val_loss -0.5842 
2025-02-26 03:09:21.387837: Pseudo dice [np.float32(0.7977), np.float32(0.6331), np.float32(0.8004)] 
2025-02-26 03:09:21.391905: Epoch time: 41.07 s 
2025-02-26 03:09:21.396078: Yayy! New best EMA pseudo Dice: 0.7077000141143799 
2025-02-26 03:09:22.229819:  
2025-02-26 03:09:22.235486: Epoch 13 
2025-02-26 03:09:22.239505: Current learning rate: 0.00882 
2025-02-26 03:10:02.337128: train_loss -0.6395 
2025-02-26 03:10:02.341893: val_loss -0.5822 
2025-02-26 03:10:02.346543: Pseudo dice [np.float32(0.7977), np.float32(0.6487), np.float32(0.8152)] 
2025-02-26 03:10:02.351556: Epoch time: 40.11 s 
2025-02-26 03:10:02.356072: Yayy! New best EMA pseudo Dice: 0.7123000025749207 
2025-02-26 03:10:03.028405:  
2025-02-26 03:10:03.035003: Epoch 14 
2025-02-26 03:10:03.038055: Current learning rate: 0.00873 
2025-02-26 03:10:42.829080: train_loss -0.6509 
2025-02-26 03:10:42.836115: val_loss -0.5915 
2025-02-26 03:10:42.842654: Pseudo dice [np.float32(0.7866), np.float32(0.6615), np.float32(0.8407)] 
2025-02-26 03:10:42.850253: Epoch time: 39.8 s 
2025-02-26 03:10:42.855778: Yayy! New best EMA pseudo Dice: 0.7174000144004822 
2025-02-26 03:10:43.535333:  
2025-02-26 03:10:43.541380: Epoch 15 
2025-02-26 03:10:43.544431: Current learning rate: 0.00864 
2025-02-26 03:11:23.255306: train_loss -0.6497 
2025-02-26 03:11:23.261865: val_loss -0.6149 
2025-02-26 03:11:23.265450: Pseudo dice [np.float32(0.8031), np.float32(0.6835), np.float32(0.8245)] 
2025-02-26 03:11:23.269111: Epoch time: 39.72 s 
2025-02-26 03:11:23.272154: Yayy! New best EMA pseudo Dice: 0.7226999998092651 
2025-02-26 03:11:23.950345:  
2025-02-26 03:11:23.955863: Epoch 16 
2025-02-26 03:11:23.959372: Current learning rate: 0.00855 
2025-02-26 03:12:03.712418: train_loss -0.6597 
2025-02-26 03:12:03.719934: val_loss -0.6027 
2025-02-26 03:12:03.726450: Pseudo dice [np.float32(0.8058), np.float32(0.6172), np.float32(0.8395)] 
2025-02-26 03:12:03.732465: Epoch time: 39.76 s 
2025-02-26 03:12:03.737473: Yayy! New best EMA pseudo Dice: 0.7257999777793884 
2025-02-26 03:12:04.418388:  
2025-02-26 03:12:04.424409: Epoch 17 
2025-02-26 03:12:04.426924: Current learning rate: 0.00846 
2025-02-26 03:12:44.287452: train_loss -0.6669 
2025-02-26 03:12:44.295002: val_loss -0.6185 
2025-02-26 03:12:44.300012: Pseudo dice [np.float32(0.8009), np.float32(0.6681), np.float32(0.8484)] 
2025-02-26 03:12:44.305024: Epoch time: 39.87 s 
2025-02-26 03:12:44.310091: Yayy! New best EMA pseudo Dice: 0.7304999828338623 
2025-02-26 03:12:44.998475:  
2025-02-26 03:12:45.004491: Epoch 18 
2025-02-26 03:12:45.006999: Current learning rate: 0.00836 
2025-02-26 03:13:24.804304: train_loss -0.6584 
2025-02-26 03:13:24.811323: val_loss -0.6219 
2025-02-26 03:13:24.815342: Pseudo dice [np.float32(0.8081), np.float32(0.6731), np.float32(0.8362)] 
2025-02-26 03:13:24.820357: Epoch time: 39.81 s 
2025-02-26 03:13:24.826880: Yayy! New best EMA pseudo Dice: 0.7347000241279602 
2025-02-26 03:13:25.510133:  
2025-02-26 03:13:25.516720: Epoch 19 
2025-02-26 03:13:25.519267: Current learning rate: 0.00827 
2025-02-26 03:14:05.328070: train_loss -0.6697 
2025-02-26 03:14:05.335768: val_loss -0.6132 
2025-02-26 03:14:05.340306: Pseudo dice [np.float32(0.8196), np.float32(0.6673), np.float32(0.8362)] 
2025-02-26 03:14:05.343335: Epoch time: 39.82 s 
2025-02-26 03:14:05.347875: Yayy! New best EMA pseudo Dice: 0.7386000156402588 
2025-02-26 03:14:06.175749:  
2025-02-26 03:14:06.181886: Epoch 20 
2025-02-26 03:14:06.185483: Current learning rate: 0.00818 
2025-02-26 03:14:45.951017: train_loss -0.6709 
2025-02-26 03:14:45.958088: val_loss -0.6011 
2025-02-26 03:14:45.962600: Pseudo dice [np.float32(0.8003), np.float32(0.6602), np.float32(0.8182)] 
2025-02-26 03:14:45.965609: Epoch time: 39.78 s 
2025-02-26 03:14:45.970222: Yayy! New best EMA pseudo Dice: 0.7407000064849854 
2025-02-26 03:14:46.658379:  
2025-02-26 03:14:46.664899: Epoch 21 
2025-02-26 03:14:46.668410: Current learning rate: 0.00809 
2025-02-26 03:15:26.476822: train_loss -0.6644 
2025-02-26 03:15:26.484687: val_loss -0.5924 
2025-02-26 03:15:26.489732: Pseudo dice [np.float32(0.7822), np.float32(0.6635), np.float32(0.8501)] 
2025-02-26 03:15:26.496887: Epoch time: 39.82 s 
2025-02-26 03:15:26.502938: Yayy! New best EMA pseudo Dice: 0.7432000041007996 
2025-02-26 03:15:27.171121:  
2025-02-26 03:15:27.176251: Epoch 22 
2025-02-26 03:15:27.179762: Current learning rate: 0.008 
2025-02-26 03:16:07.077961: train_loss -0.6671 
2025-02-26 03:16:07.083478: val_loss -0.5951 
2025-02-26 03:16:07.087996: Pseudo dice [np.float32(0.7908), np.float32(0.6979), np.float32(0.8097)] 
2025-02-26 03:16:07.091009: Epoch time: 39.91 s 
2025-02-26 03:16:07.095521: Yayy! New best EMA pseudo Dice: 0.7455000281333923 
2025-02-26 03:16:07.743536:  
2025-02-26 03:16:07.749233: Epoch 23 
2025-02-26 03:16:07.752828: Current learning rate: 0.0079 
2025-02-26 03:16:47.545934: train_loss -0.6618 
2025-02-26 03:16:47.551952: val_loss -0.6322 
2025-02-26 03:16:47.556480: Pseudo dice [np.float32(0.8122), np.float32(0.6975), np.float32(0.8489)] 
2025-02-26 03:16:47.560667: Epoch time: 39.8 s 
2025-02-26 03:16:47.564236: Yayy! New best EMA pseudo Dice: 0.7495999932289124 
2025-02-26 03:16:48.212991:  
2025-02-26 03:16:48.218065: Epoch 24 
2025-02-26 03:16:48.221604: Current learning rate: 0.00781 
2025-02-26 03:17:27.983866: train_loss -0.6697 
2025-02-26 03:17:27.992396: val_loss -0.609 
2025-02-26 03:17:27.996406: Pseudo dice [np.float32(0.8072), np.float32(0.6626), np.float32(0.8455)] 
2025-02-26 03:17:28.000917: Epoch time: 39.77 s 
2025-02-26 03:17:28.006440: Yayy! New best EMA pseudo Dice: 0.751800000667572 
2025-02-26 03:17:28.674224:  
2025-02-26 03:17:28.680289: Epoch 25 
2025-02-26 03:17:28.683340: Current learning rate: 0.00772 
2025-02-26 03:18:08.498126: train_loss -0.6745 
2025-02-26 03:18:08.504793: val_loss -0.6241 
2025-02-26 03:18:08.508864: Pseudo dice [np.float32(0.8211), np.float32(0.6863), np.float32(0.8511)] 
2025-02-26 03:18:08.512375: Epoch time: 39.82 s 
2025-02-26 03:18:08.516387: Yayy! New best EMA pseudo Dice: 0.7552000284194946 
2025-02-26 03:18:09.180300:  
2025-02-26 03:18:09.185313: Epoch 26 
2025-02-26 03:18:09.188821: Current learning rate: 0.00763 
2025-02-26 03:18:49.052158: train_loss -0.6673 
2025-02-26 03:18:49.059250: val_loss -0.6059 
2025-02-26 03:18:49.063272: Pseudo dice [np.float32(0.808), np.float32(0.6547), np.float32(0.8362)] 
2025-02-26 03:18:49.067810: Epoch time: 39.87 s 
2025-02-26 03:18:49.071838: Yayy! New best EMA pseudo Dice: 0.7562999725341797 
2025-02-26 03:18:49.727858:  
2025-02-26 03:18:49.733934: Epoch 27 
2025-02-26 03:18:49.736991: Current learning rate: 0.00753 
2025-02-26 03:19:29.505097: train_loss -0.6869 
2025-02-26 03:19:29.510674: val_loss -0.644 
2025-02-26 03:19:29.515287: Pseudo dice [np.float32(0.8241), np.float32(0.7331), np.float32(0.8512)] 
2025-02-26 03:19:29.521303: Epoch time: 39.78 s 
2025-02-26 03:19:29.526311: Yayy! New best EMA pseudo Dice: 0.7609999775886536 
2025-02-26 03:19:30.193793:  
2025-02-26 03:19:30.199333: Epoch 28 
2025-02-26 03:19:30.202882: Current learning rate: 0.00744 
2025-02-26 03:20:10.030050: train_loss -0.6866 
2025-02-26 03:20:10.037202: val_loss -0.6118 
2025-02-26 03:20:10.041234: Pseudo dice [np.float32(0.796), np.float32(0.6783), np.float32(0.8354)] 
2025-02-26 03:20:10.045286: Epoch time: 39.84 s 
2025-02-26 03:20:10.051342: Yayy! New best EMA pseudo Dice: 0.761900007724762 
2025-02-26 03:20:10.883060:  
2025-02-26 03:20:10.888656: Epoch 29 
2025-02-26 03:20:10.892726: Current learning rate: 0.00735 
2025-02-26 03:20:50.655921: train_loss -0.6742 
2025-02-26 03:20:50.663224: val_loss -0.6028 
2025-02-26 03:20:50.666737: Pseudo dice [np.float32(0.8181), np.float32(0.6768), np.float32(0.8132)] 
2025-02-26 03:20:50.671755: Epoch time: 39.77 s 
2025-02-26 03:20:50.675767: Yayy! New best EMA pseudo Dice: 0.7626000046730042 
2025-02-26 03:20:51.348921:  
2025-02-26 03:20:51.354441: Epoch 30 
2025-02-26 03:20:51.357960: Current learning rate: 0.00725 
2025-02-26 03:21:31.165076: train_loss -0.6893 
2025-02-26 03:21:31.172228: val_loss -0.6288 
2025-02-26 03:21:31.177243: Pseudo dice [np.float32(0.8134), np.float32(0.6924), np.float32(0.8657)] 
2025-02-26 03:21:31.183266: Epoch time: 39.82 s 
2025-02-26 03:21:31.188283: Yayy! New best EMA pseudo Dice: 0.7653999924659729 
2025-02-26 03:21:31.850312:  
2025-02-26 03:21:31.855829: Epoch 31 
2025-02-26 03:21:31.859341: Current learning rate: 0.00716 
2025-02-26 03:22:11.682732: train_loss -0.6889 
2025-02-26 03:22:11.688286: val_loss -0.6185 
2025-02-26 03:22:11.693308: Pseudo dice [np.float32(0.7811), np.float32(0.6994), np.float32(0.8523)] 
2025-02-26 03:22:11.697923: Epoch time: 39.83 s 
2025-02-26 03:22:11.700449: Yayy! New best EMA pseudo Dice: 0.7666000127792358 
2025-02-26 03:22:12.358202:  
2025-02-26 03:22:12.363721: Epoch 32 
2025-02-26 03:22:12.367233: Current learning rate: 0.00707 
2025-02-26 03:22:52.146539: train_loss -0.7031 
2025-02-26 03:22:52.153057: val_loss -0.6206 
2025-02-26 03:22:52.156565: Pseudo dice [np.float32(0.8069), np.float32(0.675), np.float32(0.8591)] 
2025-02-26 03:22:52.160075: Epoch time: 39.79 s 
2025-02-26 03:22:52.164092: Yayy! New best EMA pseudo Dice: 0.7680000066757202 
2025-02-26 03:22:52.836800:  
2025-02-26 03:22:52.842909: Epoch 33 
2025-02-26 03:22:52.845963: Current learning rate: 0.00697 
2025-02-26 03:23:32.695667: train_loss -0.7023 
2025-02-26 03:23:32.702732: val_loss -0.6546 
2025-02-26 03:23:32.707276: Pseudo dice [np.float32(0.8192), np.float32(0.7324), np.float32(0.8668)] 
2025-02-26 03:23:32.712845: Epoch time: 39.86 s 
2025-02-26 03:23:32.718410: Yayy! New best EMA pseudo Dice: 0.7717999815940857 
2025-02-26 03:23:33.386608:  
2025-02-26 03:23:33.392124: Epoch 34 
2025-02-26 03:23:33.395636: Current learning rate: 0.00688 
2025-02-26 03:24:13.229047: train_loss -0.6978 
2025-02-26 03:24:13.236568: val_loss -0.6089 
2025-02-26 03:24:13.241099: Pseudo dice [np.float32(0.7942), np.float32(0.6837), np.float32(0.8382)] 
2025-02-26 03:24:13.245136: Epoch time: 39.84 s 
2025-02-26 03:24:13.249148: Yayy! New best EMA pseudo Dice: 0.7717999815940857 
2025-02-26 03:24:13.932826:  
2025-02-26 03:24:13.938308: Epoch 35 
2025-02-26 03:24:13.941348: Current learning rate: 0.00679 
2025-02-26 03:24:53.716380: train_loss -0.7038 
2025-02-26 03:24:53.723899: val_loss -0.6105 
2025-02-26 03:24:53.728920: Pseudo dice [np.float32(0.8197), np.float32(0.6323), np.float32(0.8228)] 
2025-02-26 03:24:53.732936: Epoch time: 39.78 s 
2025-02-26 03:24:54.397951:  
2025-02-26 03:24:54.402965: Epoch 36 
2025-02-26 03:24:54.406476: Current learning rate: 0.00669 
2025-02-26 03:25:34.288445: train_loss -0.6922 
2025-02-26 03:25:34.296013: val_loss -0.6362 
2025-02-26 03:25:34.301039: Pseudo dice [np.float32(0.8046), np.float32(0.731), np.float32(0.8397)] 
2025-02-26 03:25:34.307560: Epoch time: 39.89 s 
2025-02-26 03:25:34.312577: Yayy! New best EMA pseudo Dice: 0.772599995136261 
2025-02-26 03:25:34.975555:  
2025-02-26 03:25:34.980568: Epoch 37 
2025-02-26 03:25:34.984080: Current learning rate: 0.0066 
2025-02-26 03:26:14.872597: train_loss -0.709 
2025-02-26 03:26:14.879702: val_loss -0.6193 
2025-02-26 03:26:14.885305: Pseudo dice [np.float32(0.8191), np.float32(0.6746), np.float32(0.8317)] 
2025-02-26 03:26:14.890365: Epoch time: 39.9 s 
2025-02-26 03:26:14.894402: Yayy! New best EMA pseudo Dice: 0.7728999853134155 
2025-02-26 03:26:15.573028:  
2025-02-26 03:26:15.577627: Epoch 38 
2025-02-26 03:26:15.581680: Current learning rate: 0.0065 
2025-02-26 03:26:55.370820: train_loss -0.6978 
2025-02-26 03:26:55.378339: val_loss -0.6445 
2025-02-26 03:26:55.381845: Pseudo dice [np.float32(0.839), np.float32(0.7009), np.float32(0.8612)] 
2025-02-26 03:26:55.385857: Epoch time: 39.8 s 
2025-02-26 03:26:55.389369: Yayy! New best EMA pseudo Dice: 0.775600016117096 
2025-02-26 03:26:56.078413:  
2025-02-26 03:26:56.083426: Epoch 39 
2025-02-26 03:26:56.086942: Current learning rate: 0.00641 
2025-02-26 03:27:35.998938: train_loss -0.7003 
2025-02-26 03:27:36.005258: val_loss -0.6284 
2025-02-26 03:27:36.008826: Pseudo dice [np.float32(0.8154), np.float32(0.7259), np.float32(0.8438)] 
2025-02-26 03:27:36.011880: Epoch time: 39.92 s 
2025-02-26 03:27:36.017486: Yayy! New best EMA pseudo Dice: 0.7774999737739563 
2025-02-26 03:27:36.706485:  
2025-02-26 03:27:36.711498: Epoch 40 
2025-02-26 03:27:36.715014: Current learning rate: 0.00631 
2025-02-26 03:28:16.608262: train_loss -0.7101 
2025-02-26 03:28:16.616289: val_loss -0.5941 
2025-02-26 03:28:16.622307: Pseudo dice [np.float32(0.7916), np.float32(0.7127), np.float32(0.8507)] 
2025-02-26 03:28:16.628918: Epoch time: 39.9 s 
2025-02-26 03:28:16.634507: Yayy! New best EMA pseudo Dice: 0.7782999873161316 
2025-02-26 03:28:17.327108:  
2025-02-26 03:28:17.332133: Epoch 41 
2025-02-26 03:28:17.335649: Current learning rate: 0.00622 
2025-02-26 03:28:57.255788: train_loss -0.6965 
2025-02-26 03:28:57.262577: val_loss -0.6584 
2025-02-26 03:28:57.265587: Pseudo dice [np.float32(0.8331), np.float32(0.7042), np.float32(0.846)] 
2025-02-26 03:28:57.270657: Epoch time: 39.93 s 
2025-02-26 03:28:57.275673: Yayy! New best EMA pseudo Dice: 0.7799000144004822 
2025-02-26 03:28:57.932289:  
2025-02-26 03:28:57.937318: Epoch 42 
2025-02-26 03:28:57.941211: Current learning rate: 0.00612 
2025-02-26 03:29:37.779418: train_loss -0.7023 
2025-02-26 03:29:37.785933: val_loss -0.6652 
2025-02-26 03:29:37.793453: Pseudo dice [np.float32(0.823), np.float32(0.7306), np.float32(0.8674)] 
2025-02-26 03:29:37.799469: Epoch time: 39.85 s 
2025-02-26 03:29:37.806123: Yayy! New best EMA pseudo Dice: 0.7825999855995178 
2025-02-26 03:29:38.463450:  
2025-02-26 03:29:38.469097: Epoch 43 
2025-02-26 03:29:38.472125: Current learning rate: 0.00603 
2025-02-26 03:30:18.320822: train_loss -0.7136 
2025-02-26 03:30:18.328480: val_loss -0.6162 
2025-02-26 03:30:18.334497: Pseudo dice [np.float32(0.8161), np.float32(0.6942), np.float32(0.8519)] 
2025-02-26 03:30:18.339509: Epoch time: 39.86 s 
2025-02-26 03:30:18.346022: Yayy! New best EMA pseudo Dice: 0.7831000089645386 
2025-02-26 03:30:19.161386:  
2025-02-26 03:30:19.167513: Epoch 44 
2025-02-26 03:30:19.170558: Current learning rate: 0.00593 
2025-02-26 03:30:59.050205: train_loss -0.7131 
2025-02-26 03:30:59.056221: val_loss -0.6256 
2025-02-26 03:30:59.060240: Pseudo dice [np.float32(0.8122), np.float32(0.716), np.float32(0.8435)] 
2025-02-26 03:30:59.063747: Epoch time: 39.89 s 
2025-02-26 03:30:59.066758: Yayy! New best EMA pseudo Dice: 0.7838000059127808 
2025-02-26 03:30:59.731360:  
2025-02-26 03:30:59.737886: Epoch 45 
2025-02-26 03:30:59.741903: Current learning rate: 0.00584 
2025-02-26 03:31:39.553607: train_loss -0.7128 
2025-02-26 03:31:39.559691: val_loss -0.6551 
2025-02-26 03:31:39.563799: Pseudo dice [np.float32(0.8274), np.float32(0.7017), np.float32(0.8412)] 
2025-02-26 03:31:39.567455: Epoch time: 39.82 s 
2025-02-26 03:31:39.570965: Yayy! New best EMA pseudo Dice: 0.784500002861023 
2025-02-26 03:31:40.234868:  
2025-02-26 03:31:40.239879: Epoch 46 
2025-02-26 03:31:40.243398: Current learning rate: 0.00574 
2025-02-26 03:32:20.062210: train_loss -0.7077 
2025-02-26 03:32:20.069881: val_loss -0.6459 
2025-02-26 03:32:20.075426: Pseudo dice [np.float32(0.8315), np.float32(0.682), np.float32(0.8572)] 
2025-02-26 03:32:20.081126: Epoch time: 39.83 s 
2025-02-26 03:32:20.086285: Yayy! New best EMA pseudo Dice: 0.7850000262260437 
2025-02-26 03:32:20.746203:  
2025-02-26 03:32:20.751293: Epoch 47 
2025-02-26 03:32:20.754806: Current learning rate: 0.00565 
2025-02-26 03:33:00.648134: train_loss -0.7092 
2025-02-26 03:33:00.655659: val_loss -0.6495 
2025-02-26 03:33:00.661673: Pseudo dice [np.float32(0.8421), np.float32(0.7328), np.float32(0.8645)] 
2025-02-26 03:33:00.668187: Epoch time: 39.9 s 
2025-02-26 03:33:00.675203: Yayy! New best EMA pseudo Dice: 0.7878999710083008 
2025-02-26 03:33:01.326866:  
2025-02-26 03:33:01.332382: Epoch 48 
2025-02-26 03:33:01.335892: Current learning rate: 0.00555 
2025-02-26 03:33:41.102245: train_loss -0.7204 
2025-02-26 03:33:41.108294: val_loss -0.6131 
2025-02-26 03:33:41.110974: Pseudo dice [np.float32(0.8166), np.float32(0.6645), np.float32(0.8367)] 
2025-02-26 03:33:41.114487: Epoch time: 39.78 s 
2025-02-26 03:33:41.611059:  
2025-02-26 03:33:41.616615: Epoch 49 
2025-02-26 03:33:41.620181: Current learning rate: 0.00546 
2025-02-26 03:34:21.411641: train_loss -0.7076 
2025-02-26 03:34:21.420274: val_loss -0.6273 
2025-02-26 03:34:21.425829: Pseudo dice [np.float32(0.8172), np.float32(0.6911), np.float32(0.8599)] 
2025-02-26 03:34:21.430853: Epoch time: 39.8 s 
2025-02-26 03:34:22.082277:  
2025-02-26 03:34:22.088796: Epoch 50 
2025-02-26 03:34:22.092306: Current learning rate: 0.00536 
2025-02-26 03:35:01.952749: train_loss -0.7103 
2025-02-26 03:35:01.960322: val_loss -0.6435 
2025-02-26 03:35:01.966974: Pseudo dice [np.float32(0.818), np.float32(0.7005), np.float32(0.8612)] 
2025-02-26 03:35:01.973077: Epoch time: 39.87 s 
2025-02-26 03:35:02.476851:  
2025-02-26 03:35:02.481841: Epoch 51 
2025-02-26 03:35:02.485969: Current learning rate: 0.00526 
2025-02-26 03:35:42.319137: train_loss -0.7221 
2025-02-26 03:35:42.326255: val_loss -0.6292 
2025-02-26 03:35:42.332429: Pseudo dice [np.float32(0.829), np.float32(0.6785), np.float32(0.8428)] 
2025-02-26 03:35:42.338010: Epoch time: 39.84 s 
2025-02-26 03:35:42.844982:  
2025-02-26 03:35:42.850499: Epoch 52 
2025-02-26 03:35:42.854015: Current learning rate: 0.00517 
2025-02-26 03:36:22.689069: train_loss -0.7119 
2025-02-26 03:36:22.696667: val_loss -0.6549 
2025-02-26 03:36:22.701191: Pseudo dice [np.float32(0.8347), np.float32(0.7091), np.float32(0.8442)] 
2025-02-26 03:36:22.705222: Epoch time: 39.85 s 
2025-02-26 03:36:23.362785:  
2025-02-26 03:36:23.368916: Epoch 53 
2025-02-26 03:36:23.371951: Current learning rate: 0.00507 
2025-02-26 03:37:03.205886: train_loss -0.7266 
2025-02-26 03:37:03.213419: val_loss -0.6295 
2025-02-26 03:37:03.217435: Pseudo dice [np.float32(0.8141), np.float32(0.651), np.float32(0.8532)] 
2025-02-26 03:37:03.220951: Epoch time: 39.84 s 
2025-02-26 03:37:03.726135:  
2025-02-26 03:37:03.732655: Epoch 54 
2025-02-26 03:37:03.736166: Current learning rate: 0.00497 
2025-02-26 03:37:43.598948: train_loss -0.7317 
2025-02-26 03:37:43.606023: val_loss -0.6223 
2025-02-26 03:37:43.611073: Pseudo dice [np.float32(0.818), np.float32(0.6781), np.float32(0.851)] 
2025-02-26 03:37:43.616645: Epoch time: 39.87 s 
2025-02-26 03:37:44.128382:  
2025-02-26 03:37:44.134462: Epoch 55 
2025-02-26 03:37:44.138051: Current learning rate: 0.00487 
2025-02-26 03:38:24.008912: train_loss -0.7322 
2025-02-26 03:38:24.016427: val_loss -0.662 
2025-02-26 03:38:24.021437: Pseudo dice [np.float32(0.8378), np.float32(0.7133), np.float32(0.8657)] 
2025-02-26 03:38:24.028010: Epoch time: 39.88 s 
2025-02-26 03:38:24.032103: Yayy! New best EMA pseudo Dice: 0.7878999710083008 
2025-02-26 03:38:24.679275:  
2025-02-26 03:38:24.684836: Epoch 56 
2025-02-26 03:38:24.688441: Current learning rate: 0.00478 
2025-02-26 03:39:04.529273: train_loss -0.719 
2025-02-26 03:39:04.538468: val_loss -0.6129 
2025-02-26 03:39:04.543511: Pseudo dice [np.float32(0.8152), np.float32(0.6703), np.float32(0.8306)] 
2025-02-26 03:39:04.548240: Epoch time: 39.85 s 
2025-02-26 03:39:05.051024:  
2025-02-26 03:39:05.057620: Epoch 57 
2025-02-26 03:39:05.061236: Current learning rate: 0.00468 
2025-02-26 03:39:44.889001: train_loss -0.7258 
2025-02-26 03:39:44.896578: val_loss -0.6453 
2025-02-26 03:39:44.901109: Pseudo dice [np.float32(0.8248), np.float32(0.7564), np.float32(0.8608)] 
2025-02-26 03:39:44.905187: Epoch time: 39.84 s 
2025-02-26 03:39:44.908861: Yayy! New best EMA pseudo Dice: 0.7890999913215637 
2025-02-26 03:39:45.578069:  
2025-02-26 03:39:45.583123: Epoch 58 
2025-02-26 03:39:45.586756: Current learning rate: 0.00458 
2025-02-26 03:40:25.378503: train_loss -0.7222 
2025-02-26 03:40:25.386025: val_loss -0.6175 
2025-02-26 03:40:25.390038: Pseudo dice [np.float32(0.798), np.float32(0.7017), np.float32(0.8468)] 
2025-02-26 03:40:25.394551: Epoch time: 39.8 s 
2025-02-26 03:40:25.909672:  
2025-02-26 03:40:25.914729: Epoch 59 
2025-02-26 03:40:25.917152: Current learning rate: 0.00448 
2025-02-26 03:41:05.729640: train_loss -0.7401 
2025-02-26 03:41:05.735217: val_loss -0.6366 
2025-02-26 03:41:05.739846: Pseudo dice [np.float32(0.8263), np.float32(0.7105), np.float32(0.8584)] 
2025-02-26 03:41:05.743877: Epoch time: 39.82 s 
2025-02-26 03:41:05.748035: Yayy! New best EMA pseudo Dice: 0.7893999814987183 
2025-02-26 03:41:06.415920:  
2025-02-26 03:41:06.421106: Epoch 60 
2025-02-26 03:41:06.425151: Current learning rate: 0.00438 
2025-02-26 03:41:46.274300: train_loss -0.7336 
2025-02-26 03:41:46.281334: val_loss -0.6581 
2025-02-26 03:41:46.284451: Pseudo dice [np.float32(0.8338), np.float32(0.7173), np.float32(0.8675)] 
2025-02-26 03:41:46.288494: Epoch time: 39.86 s 
2025-02-26 03:41:46.292071: Yayy! New best EMA pseudo Dice: 0.791100025177002 
2025-02-26 03:41:47.120887:  
2025-02-26 03:41:47.126968: Epoch 61 
2025-02-26 03:41:47.130519: Current learning rate: 0.00429 
2025-02-26 03:42:26.950741: train_loss -0.747 
2025-02-26 03:42:26.959256: val_loss -0.6403 
2025-02-26 03:42:26.964772: Pseudo dice [np.float32(0.8376), np.float32(0.692), np.float32(0.8548)] 
2025-02-26 03:42:26.969788: Epoch time: 39.83 s 
2025-02-26 03:42:26.973300: Yayy! New best EMA pseudo Dice: 0.7914000153541565 
2025-02-26 03:42:27.648490:  
2025-02-26 03:42:27.653512: Epoch 62 
2025-02-26 03:42:27.657031: Current learning rate: 0.00419 
2025-02-26 03:43:07.484759: train_loss -0.7394 
2025-02-26 03:43:07.492280: val_loss -0.6648 
2025-02-26 03:43:07.495787: Pseudo dice [np.float32(0.8274), np.float32(0.7208), np.float32(0.8644)] 
2025-02-26 03:43:07.498797: Epoch time: 39.84 s 
2025-02-26 03:43:07.503314: Yayy! New best EMA pseudo Dice: 0.7926999926567078 
2025-02-26 03:43:08.203163:  
2025-02-26 03:43:08.208677: Epoch 63 
2025-02-26 03:43:08.212185: Current learning rate: 0.00409 
2025-02-26 03:43:47.998928: train_loss -0.7354 
2025-02-26 03:43:48.005524: val_loss -0.6458 
2025-02-26 03:43:48.011882: Pseudo dice [np.float32(0.8168), np.float32(0.6986), np.float32(0.8559)] 
2025-02-26 03:43:48.017043: Epoch time: 39.8 s 
2025-02-26 03:43:48.532704:  
2025-02-26 03:43:48.537296: Epoch 64 
2025-02-26 03:43:48.542873: Current learning rate: 0.00399 
2025-02-26 03:44:28.349489: train_loss -0.7441 
2025-02-26 03:44:28.356096: val_loss -0.6355 
2025-02-26 03:44:28.361115: Pseudo dice [np.float32(0.8316), np.float32(0.6876), np.float32(0.8674)] 
2025-02-26 03:44:28.365125: Epoch time: 39.82 s 
2025-02-26 03:44:28.370142: Yayy! New best EMA pseudo Dice: 0.7928000092506409 
2025-02-26 03:44:29.036442:  
2025-02-26 03:44:29.042503: Epoch 65 
2025-02-26 03:44:29.045541: Current learning rate: 0.00389 
2025-02-26 03:45:08.763636: train_loss -0.7459 
2025-02-26 03:45:08.770159: val_loss -0.6396 
2025-02-26 03:45:08.775174: Pseudo dice [np.float32(0.8162), np.float32(0.7221), np.float32(0.8528)] 
2025-02-26 03:45:08.779691: Epoch time: 39.73 s 
2025-02-26 03:45:08.784705: Yayy! New best EMA pseudo Dice: 0.7932000160217285 
2025-02-26 03:45:09.463676:  
2025-02-26 03:45:09.469744: Epoch 66 
2025-02-26 03:45:09.473255: Current learning rate: 0.00379 
2025-02-26 03:45:49.338368: train_loss -0.7279 
2025-02-26 03:45:49.346493: val_loss -0.6014 
2025-02-26 03:45:49.350034: Pseudo dice [np.float32(0.8068), np.float32(0.6579), np.float32(0.8616)] 
2025-02-26 03:45:49.353089: Epoch time: 39.87 s 
2025-02-26 03:45:49.864330:  
2025-02-26 03:45:49.869341: Epoch 67 
2025-02-26 03:45:49.872856: Current learning rate: 0.00369 
2025-02-26 03:46:29.683570: train_loss -0.7375 
2025-02-26 03:46:29.690597: val_loss -0.6753 
2025-02-26 03:46:29.694164: Pseudo dice [np.float32(0.8398), np.float32(0.7456), np.float32(0.8649)] 
2025-02-26 03:46:29.699240: Epoch time: 39.82 s 
2025-02-26 03:46:29.704794: Yayy! New best EMA pseudo Dice: 0.7940000295639038 
2025-02-26 03:46:30.382632:  
2025-02-26 03:46:30.388673: Epoch 68 
2025-02-26 03:46:30.391727: Current learning rate: 0.00359 
2025-02-26 03:47:10.217723: train_loss -0.7337 
2025-02-26 03:47:10.224004: val_loss -0.6345 
2025-02-26 03:47:10.227648: Pseudo dice [np.float32(0.8303), np.float32(0.6778), np.float32(0.8684)] 
2025-02-26 03:47:10.231226: Epoch time: 39.84 s 
2025-02-26 03:47:10.900228:  
2025-02-26 03:47:10.906300: Epoch 69 
2025-02-26 03:47:10.909814: Current learning rate: 0.00349 
2025-02-26 03:47:50.726186: train_loss -0.739 
2025-02-26 03:47:50.733211: val_loss -0.6493 
2025-02-26 03:47:50.739740: Pseudo dice [np.float32(0.8265), np.float32(0.7282), np.float32(0.8537)] 
2025-02-26 03:47:50.744756: Epoch time: 39.83 s 
2025-02-26 03:47:50.748767: Yayy! New best EMA pseudo Dice: 0.794700026512146 
2025-02-26 03:47:51.426684:  
2025-02-26 03:47:51.432202: Epoch 70 
2025-02-26 03:47:51.437212: Current learning rate: 0.00338 
2025-02-26 03:48:31.212807: train_loss -0.7354 
2025-02-26 03:48:31.219429: val_loss -0.6565 
2025-02-26 03:48:31.223438: Pseudo dice [np.float32(0.823), np.float32(0.7343), np.float32(0.8529)] 
2025-02-26 03:48:31.228010: Epoch time: 39.79 s 
2025-02-26 03:48:31.232159: Yayy! New best EMA pseudo Dice: 0.7955999970436096 
2025-02-26 03:48:31.925679:  
2025-02-26 03:48:31.930713: Epoch 71 
2025-02-26 03:48:31.934585: Current learning rate: 0.00328 
2025-02-26 03:49:11.726821: train_loss -0.7366 
2025-02-26 03:49:11.734369: val_loss -0.6234 
2025-02-26 03:49:11.737876: Pseudo dice [np.float32(0.8139), np.float32(0.6777), np.float32(0.8727)] 
2025-02-26 03:49:11.740897: Epoch time: 39.8 s 
2025-02-26 03:49:12.264935:  
2025-02-26 03:49:12.270547: Epoch 72 
2025-02-26 03:49:12.273078: Current learning rate: 0.00318 
2025-02-26 03:49:52.047434: train_loss -0.7389 
2025-02-26 03:49:52.053477: val_loss -0.6558 
2025-02-26 03:49:52.056989: Pseudo dice [np.float32(0.8269), np.float32(0.7133), np.float32(0.8762)] 
2025-02-26 03:49:52.060094: Epoch time: 39.78 s 
2025-02-26 03:49:52.063605: Yayy! New best EMA pseudo Dice: 0.7958999872207642 
2025-02-26 03:49:52.752965:  
2025-02-26 03:49:52.757999: Epoch 73 
2025-02-26 03:49:52.761594: Current learning rate: 0.00308 
2025-02-26 03:50:32.584735: train_loss -0.7468 
2025-02-26 03:50:32.592476: val_loss -0.6651 
2025-02-26 03:50:32.597564: Pseudo dice [np.float32(0.8263), np.float32(0.7616), np.float32(0.8582)] 
2025-02-26 03:50:32.603572: Epoch time: 39.83 s 
2025-02-26 03:50:32.607590: Yayy! New best EMA pseudo Dice: 0.7978000044822693 
2025-02-26 03:50:33.295530:  
2025-02-26 03:50:33.302136: Epoch 74 
2025-02-26 03:50:33.304657: Current learning rate: 0.00297 
2025-02-26 03:51:13.110881: train_loss -0.7402 
2025-02-26 03:51:13.118057: val_loss -0.6501 
2025-02-26 03:51:13.122672: Pseudo dice [np.float32(0.8291), np.float32(0.7231), np.float32(0.8674)] 
2025-02-26 03:51:13.126817: Epoch time: 39.82 s 
2025-02-26 03:51:13.130366: Yayy! New best EMA pseudo Dice: 0.7986999750137329 
2025-02-26 03:51:13.824327:  
2025-02-26 03:51:13.829870: Epoch 75 
2025-02-26 03:51:13.833428: Current learning rate: 0.00287 
2025-02-26 03:51:53.677819: train_loss -0.7542 
2025-02-26 03:51:53.685351: val_loss -0.6587 
2025-02-26 03:51:53.690454: Pseudo dice [np.float32(0.8194), np.float32(0.7347), np.float32(0.8748)] 
2025-02-26 03:51:53.695471: Epoch time: 39.85 s 
2025-02-26 03:51:53.698982: Yayy! New best EMA pseudo Dice: 0.7997999787330627 
2025-02-26 03:51:54.385135:  
2025-02-26 03:51:54.390650: Epoch 76 
2025-02-26 03:51:54.393156: Current learning rate: 0.00277 
2025-02-26 03:52:34.176686: train_loss -0.7506 
2025-02-26 03:52:34.182776: val_loss -0.6689 
2025-02-26 03:52:34.186838: Pseudo dice [np.float32(0.8273), np.float32(0.7014), np.float32(0.8804)] 
2025-02-26 03:52:34.190372: Epoch time: 39.79 s 
2025-02-26 03:52:34.194444: Yayy! New best EMA pseudo Dice: 0.8001000285148621 
2025-02-26 03:52:35.053800:  
2025-02-26 03:52:35.059323: Epoch 77 
2025-02-26 03:52:35.062831: Current learning rate: 0.00266 
2025-02-26 03:53:14.894914: train_loss -0.7564 
2025-02-26 03:53:14.900940: val_loss -0.6597 
2025-02-26 03:53:14.904955: Pseudo dice [np.float32(0.8278), np.float32(0.7298), np.float32(0.8689)] 
2025-02-26 03:53:14.908473: Epoch time: 39.84 s 
2025-02-26 03:53:14.912488: Yayy! New best EMA pseudo Dice: 0.8009999990463257 
2025-02-26 03:53:15.602551:  
2025-02-26 03:53:15.606563: Epoch 78 
2025-02-26 03:53:15.610068: Current learning rate: 0.00256 
2025-02-26 03:53:55.429315: train_loss -0.7445 
2025-02-26 03:53:55.435909: val_loss -0.6393 
2025-02-26 03:53:55.438919: Pseudo dice [np.float32(0.8305), np.float32(0.7046), np.float32(0.8736)] 
2025-02-26 03:53:55.442432: Epoch time: 39.83 s 
2025-02-26 03:53:55.446443: Yayy! New best EMA pseudo Dice: 0.8011999726295471 
2025-02-26 03:53:56.144177:  
2025-02-26 03:53:56.150297: Epoch 79 
2025-02-26 03:53:56.155891: Current learning rate: 0.00245 
2025-02-26 03:54:35.954155: train_loss -0.7451 
2025-02-26 03:54:35.960815: val_loss -0.6578 
2025-02-26 03:54:35.964880: Pseudo dice [np.float32(0.8461), np.float32(0.7028), np.float32(0.8613)] 
2025-02-26 03:54:35.968486: Epoch time: 39.81 s 
2025-02-26 03:54:35.972570: Yayy! New best EMA pseudo Dice: 0.8014000058174133 
2025-02-26 03:54:36.663885:  
2025-02-26 03:54:36.668900: Epoch 80 
2025-02-26 03:54:36.672412: Current learning rate: 0.00235 
2025-02-26 03:55:16.482166: train_loss -0.7508 
2025-02-26 03:55:16.489309: val_loss -0.6019 
2025-02-26 03:55:16.492851: Pseudo dice [np.float32(0.812), np.float32(0.6583), np.float32(0.8877)] 
2025-02-26 03:55:16.499442: Epoch time: 39.82 s 
2025-02-26 03:55:17.033892:  
2025-02-26 03:55:17.039420: Epoch 81 
2025-02-26 03:55:17.042987: Current learning rate: 0.00224 
2025-02-26 03:55:56.939000: train_loss -0.7475 
2025-02-26 03:55:56.946532: val_loss -0.6268 
2025-02-26 03:55:56.952592: Pseudo dice [np.float32(0.8313), np.float32(0.7401), np.float32(0.8543)] 
2025-02-26 03:55:56.958677: Epoch time: 39.91 s 
2025-02-26 03:55:57.491857:  
2025-02-26 03:55:57.497380: Epoch 82 
2025-02-26 03:55:57.500708: Current learning rate: 0.00214 
2025-02-26 03:56:37.338458: train_loss -0.7588 
2025-02-26 03:56:37.345598: val_loss -0.6671 
2025-02-26 03:56:37.349843: Pseudo dice [np.float32(0.8444), np.float32(0.7047), np.float32(0.863)] 
2025-02-26 03:56:37.355416: Epoch time: 39.85 s 
2025-02-26 03:56:37.862761:  
2025-02-26 03:56:37.868318: Epoch 83 
2025-02-26 03:56:37.870861: Current learning rate: 0.00203 
2025-02-26 03:57:17.689893: train_loss -0.7544 
2025-02-26 03:57:17.697412: val_loss -0.6742 
2025-02-26 03:57:17.701423: Pseudo dice [np.float32(0.8504), np.float32(0.7057), np.float32(0.8778)] 
2025-02-26 03:57:17.704937: Epoch time: 39.83 s 
2025-02-26 03:57:17.710955: Yayy! New best EMA pseudo Dice: 0.8021000027656555 
2025-02-26 03:57:18.505444:  
2025-02-26 03:57:18.510474: Epoch 84 
2025-02-26 03:57:18.514604: Current learning rate: 0.00192 
2025-02-26 03:57:58.292176: train_loss -0.7456 
2025-02-26 03:57:58.299881: val_loss -0.6717 
2025-02-26 03:57:58.305426: Pseudo dice [np.float32(0.8457), np.float32(0.7432), np.float32(0.8695)] 
2025-02-26 03:57:58.311444: Epoch time: 39.79 s 
2025-02-26 03:57:58.316962: Yayy! New best EMA pseudo Dice: 0.8037999868392944 
2025-02-26 03:57:58.986477:  
2025-02-26 03:57:58.992013: Epoch 85 
2025-02-26 03:57:58.996118: Current learning rate: 0.00181 
2025-02-26 03:58:38.849985: train_loss -0.7442 
2025-02-26 03:58:38.857503: val_loss -0.6419 
2025-02-26 03:58:38.861513: Pseudo dice [np.float32(0.8261), np.float32(0.7074), np.float32(0.8556)] 
2025-02-26 03:58:38.865023: Epoch time: 39.86 s 
2025-02-26 03:58:39.364862:  
2025-02-26 03:58:39.370378: Epoch 86 
2025-02-26 03:58:39.373891: Current learning rate: 0.0017 
2025-02-26 03:59:19.194206: train_loss -0.7598 
2025-02-26 03:59:19.202734: val_loss -0.6383 
2025-02-26 03:59:19.206741: Pseudo dice [np.float32(0.8306), np.float32(0.698), np.float32(0.865)] 
2025-02-26 03:59:19.211755: Epoch time: 39.83 s 
2025-02-26 03:59:19.719646:  
2025-02-26 03:59:19.724659: Epoch 87 
2025-02-26 03:59:19.728172: Current learning rate: 0.00159 
2025-02-26 03:59:59.857648: train_loss -0.7537 
2025-02-26 03:59:59.863662: val_loss -0.6375 
2025-02-26 03:59:59.869673: Pseudo dice [np.float32(0.8185), np.float32(0.7187), np.float32(0.8581)] 
2025-02-26 03:59:59.875187: Epoch time: 40.14 s 
2025-02-26 04:00:00.390807:  
2025-02-26 04:00:00.397367: Epoch 88 
2025-02-26 04:00:00.399951: Current learning rate: 0.00148 
2025-02-26 04:00:40.268396: train_loss -0.7551 
2025-02-26 04:00:40.275920: val_loss -0.6478 
2025-02-26 04:00:40.279932: Pseudo dice [np.float32(0.8204), np.float32(0.7235), np.float32(0.8602)] 
2025-02-26 04:00:40.284444: Epoch time: 39.88 s 
2025-02-26 04:00:40.788556:  
2025-02-26 04:00:40.794632: Epoch 89 
2025-02-26 04:00:40.797689: Current learning rate: 0.00137 
2025-02-26 04:01:20.545253: train_loss -0.7527 
2025-02-26 04:01:20.552274: val_loss -0.6421 
2025-02-26 04:01:20.556332: Pseudo dice [np.float32(0.8322), np.float32(0.6951), np.float32(0.8598)] 
2025-02-26 04:01:20.561349: Epoch time: 39.76 s 
2025-02-26 04:01:21.063412:  
2025-02-26 04:01:21.068938: Epoch 90 
2025-02-26 04:01:21.072472: Current learning rate: 0.00126 
2025-02-26 04:02:00.833221: train_loss -0.7542 
2025-02-26 04:02:00.839742: val_loss -0.6452 
2025-02-26 04:02:00.845759: Pseudo dice [np.float32(0.8397), np.float32(0.7349), np.float32(0.8656)] 
2025-02-26 04:02:00.851774: Epoch time: 39.77 s 
2025-02-26 04:02:01.362949:  
2025-02-26 04:02:01.368747: Epoch 91 
2025-02-26 04:02:01.372311: Current learning rate: 0.00115 
2025-02-26 04:02:41.223020: train_loss -0.7558 
2025-02-26 04:02:41.230843: val_loss -0.6354 
2025-02-26 04:02:41.235928: Pseudo dice [np.float32(0.8162), np.float32(0.7277), np.float32(0.8711)] 
2025-02-26 04:02:41.241019: Epoch time: 39.86 s 
2025-02-26 04:02:41.735586:  
2025-02-26 04:02:41.741143: Epoch 92 
2025-02-26 04:02:41.745173: Current learning rate: 0.00103 
2025-02-26 04:03:21.617045: train_loss -0.7651 
2025-02-26 04:03:21.625076: val_loss -0.6391 
2025-02-26 04:03:21.631591: Pseudo dice [np.float32(0.8341), np.float32(0.6932), np.float32(0.8596)] 
2025-02-26 04:03:21.637606: Epoch time: 39.88 s 
2025-02-26 04:03:22.311497:  
2025-02-26 04:03:22.317515: Epoch 93 
2025-02-26 04:03:22.321527: Current learning rate: 0.00091 
2025-02-26 04:04:02.145799: train_loss -0.7661 
2025-02-26 04:04:02.151985: val_loss -0.6449 
2025-02-26 04:04:02.156015: Pseudo dice [np.float32(0.827), np.float32(0.6979), np.float32(0.8628)] 
2025-02-26 04:04:02.159548: Epoch time: 39.83 s 
2025-02-26 04:04:02.649795:  
2025-02-26 04:04:02.656368: Epoch 94 
2025-02-26 04:04:02.659425: Current learning rate: 0.00079 
2025-02-26 04:04:42.460562: train_loss -0.7619 
2025-02-26 04:04:42.468083: val_loss -0.6084 
2025-02-26 04:04:42.473099: Pseudo dice [np.float32(0.8111), np.float32(0.6872), np.float32(0.8562)] 
2025-02-26 04:04:42.478118: Epoch time: 39.81 s 
2025-02-26 04:04:42.984395:  
2025-02-26 04:04:42.990514: Epoch 95 
2025-02-26 04:04:42.994030: Current learning rate: 0.00067 
2025-02-26 04:05:22.817785: train_loss -0.7641 
2025-02-26 04:05:22.825306: val_loss -0.6464 
2025-02-26 04:05:22.830824: Pseudo dice [np.float32(0.8244), np.float32(0.7454), np.float32(0.8552)] 
2025-02-26 04:05:22.836842: Epoch time: 39.83 s 
2025-02-26 04:05:23.335877:  
2025-02-26 04:05:23.341395: Epoch 96 
2025-02-26 04:05:23.344907: Current learning rate: 0.00055 
2025-02-26 04:06:03.131155: train_loss -0.7608 
2025-02-26 04:06:03.138680: val_loss -0.6615 
2025-02-26 04:06:03.144693: Pseudo dice [np.float32(0.8378), np.float32(0.708), np.float32(0.8802)] 
2025-02-26 04:06:03.151213: Epoch time: 39.8 s 
2025-02-26 04:06:03.656517:  
2025-02-26 04:06:03.662576: Epoch 97 
2025-02-26 04:06:03.666177: Current learning rate: 0.00043 
2025-02-26 04:06:43.467020: train_loss -0.769 
2025-02-26 04:06:43.474120: val_loss -0.6421 
2025-02-26 04:06:43.477679: Pseudo dice [np.float32(0.8165), np.float32(0.7127), np.float32(0.8506)] 
2025-02-26 04:06:43.481723: Epoch time: 39.81 s 
2025-02-26 04:06:43.990574:  
2025-02-26 04:06:43.995600: Epoch 98 
2025-02-26 04:06:43.999116: Current learning rate: 0.0003 
2025-02-26 04:07:23.820794: train_loss -0.7616 
2025-02-26 04:07:23.830817: val_loss -0.6454 
2025-02-26 04:07:23.837330: Pseudo dice [np.float32(0.8247), np.float32(0.7045), np.float32(0.8648)] 
2025-02-26 04:07:23.842341: Epoch time: 39.83 s 
2025-02-26 04:07:24.352382:  
2025-02-26 04:07:24.358983: Epoch 99 
2025-02-26 04:07:24.362554: Current learning rate: 0.00016 
2025-02-26 04:08:04.123042: train_loss -0.7673 
2025-02-26 04:08:04.130064: val_loss -0.6519 
2025-02-26 04:08:04.133605: Pseudo dice [np.float32(0.838), np.float32(0.6873), np.float32(0.8693)] 
2025-02-26 04:08:04.137735: Epoch time: 39.77 s 
2025-02-26 04:08:04.816930: Training done. 
2025-02-26 04:08:04.853371: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-02-26 04:08:04.864373: The split file contains 5 splits. 
2025-02-26 04:08:04.870372: Desired fold for training: 0 
2025-02-26 04:08:04.876370: This split has 387 training and 97 validation cases. 
2025-02-26 04:08:04.882370: predicting BRATS_010 
2025-02-26 04:08:04.888370: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2025-02-26 04:08:06.902245: predicting BRATS_011 
2025-02-26 04:08:06.916244: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2025-02-26 04:08:08.270905: predicting BRATS_012 
2025-02-26 04:08:08.280905: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-02-26 04:08:09.627306: predicting BRATS_018 
2025-02-26 04:08:09.639814: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2025-02-26 04:08:10.998522: predicting BRATS_020 
2025-02-26 04:08:11.011520: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2025-02-26 04:08:12.381018: predicting BRATS_028 
2025-02-26 04:08:12.393018: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-02-26 04:08:13.740701: predicting BRATS_029 
2025-02-26 04:08:13.753701: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-02-26 04:08:15.115091: predicting BRATS_032 
2025-02-26 04:08:15.126093: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2025-02-26 04:08:16.483273: predicting BRATS_034 
2025-02-26 04:08:16.494273: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2025-02-26 04:08:17.853407: predicting BRATS_041 
2025-02-26 04:08:17.867407: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2025-02-26 04:08:19.225152: predicting BRATS_042 
2025-02-26 04:08:19.238657: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2025-02-26 04:08:20.614399: predicting BRATS_047 
2025-02-26 04:08:20.626405: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-02-26 04:08:21.975426: predicting BRATS_049 
2025-02-26 04:08:21.987427: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-02-26 04:08:23.342325: predicting BRATS_053 
2025-02-26 04:08:23.355325: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-02-26 04:08:24.700189: predicting BRATS_056 
2025-02-26 04:08:24.712189: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-02-26 04:08:26.065338: predicting BRATS_057 
2025-02-26 04:08:26.076339: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-02-26 04:08:27.435194: predicting BRATS_067 
2025-02-26 04:08:27.448304: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-02-26 04:08:28.824379: predicting BRATS_069 
2025-02-26 04:08:28.838383: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-02-26 04:08:30.190751: predicting BRATS_085 
2025-02-26 04:08:30.202745: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2025-02-26 04:08:30.907312: predicting BRATS_086 
2025-02-26 04:08:30.918314: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2025-02-26 04:08:32.285627: predicting BRATS_088 
2025-02-26 04:08:32.297626: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2025-02-26 04:08:33.655042: predicting BRATS_091 
2025-02-26 04:08:33.668044: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-02-26 04:08:35.028863: predicting BRATS_098 
2025-02-26 04:08:35.041869: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2025-02-26 04:08:36.428475: predicting BRATS_100 
2025-02-26 04:08:36.451812: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-02-26 04:08:37.168442: predicting BRATS_101 
2025-02-26 04:08:37.195446: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-02-26 04:08:37.917189: predicting BRATS_102 
2025-02-26 04:08:37.941195: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2025-02-26 04:08:39.300385: predicting BRATS_104 
2025-02-26 04:08:39.326386: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2025-02-26 04:08:40.696136: predicting BRATS_111 
2025-02-26 04:08:40.722138: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2025-02-26 04:08:42.071375: predicting BRATS_116 
2025-02-26 04:08:42.100377: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2025-02-26 04:08:43.509337: predicting BRATS_135 
2025-02-26 04:08:43.530336: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-02-26 04:08:44.877862: predicting BRATS_136 
2025-02-26 04:08:44.901863: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-02-26 04:08:46.250862: predicting BRATS_138 
2025-02-26 04:08:46.279365: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2025-02-26 04:08:47.645345: predicting BRATS_145 
2025-02-26 04:08:47.672854: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2025-02-26 04:08:49.045992: predicting BRATS_149 
2025-02-26 04:08:49.067504: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2025-02-26 04:08:50.462239: predicting BRATS_155 
2025-02-26 04:08:50.488241: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-02-26 04:08:51.872715: predicting BRATS_157 
2025-02-26 04:08:51.899714: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-02-26 04:08:53.252498: predicting BRATS_158 
2025-02-26 04:08:53.279005: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-02-26 04:08:54.656900: predicting BRATS_159 
2025-02-26 04:08:54.678959: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-02-26 04:08:56.043102: predicting BRATS_163 
2025-02-26 04:08:56.072163: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-02-26 04:08:57.431252: predicting BRATS_164 
2025-02-26 04:08:57.457258: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2025-02-26 04:08:58.803664: predicting BRATS_169 
2025-02-26 04:08:58.824661: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2025-02-26 04:09:00.181592: predicting BRATS_176 
2025-02-26 04:09:00.207592: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-02-26 04:09:01.570727: predicting BRATS_181 
2025-02-26 04:09:01.592728: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2025-02-26 04:09:02.941048: predicting BRATS_183 
2025-02-26 04:09:02.963056: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-02-26 04:09:04.331983: predicting BRATS_184 
2025-02-26 04:09:04.356990: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-02-26 04:09:05.706565: predicting BRATS_187 
2025-02-26 04:09:05.729563: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-02-26 04:09:07.101070: predicting BRATS_192 
2025-02-26 04:09:07.126070: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2025-02-26 04:09:08.476070: predicting BRATS_198 
2025-02-26 04:09:08.500072: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-02-26 04:09:09.876300: predicting BRATS_207 
2025-02-26 04:09:09.905300: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-02-26 04:09:11.274023: predicting BRATS_208 
2025-02-26 04:09:11.296022: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-02-26 04:09:12.651362: predicting BRATS_218 
2025-02-26 04:09:12.680873: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-02-26 04:09:14.042842: predicting BRATS_220 
2025-02-26 04:09:14.066845: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2025-02-26 04:09:15.433753: predicting BRATS_224 
2025-02-26 04:09:15.463760: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2025-02-26 04:09:16.827790: predicting BRATS_230 
2025-02-26 04:09:16.849790: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2025-02-26 04:09:18.219347: predicting BRATS_271 
2025-02-26 04:09:18.247348: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2025-02-26 04:09:19.620703: predicting BRATS_282 
2025-02-26 04:09:19.647703: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2025-02-26 04:09:20.996214: predicting BRATS_284 
2025-02-26 04:09:21.019217: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2025-02-26 04:09:22.378488: predicting BRATS_287 
2025-02-26 04:09:22.401491: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-02-26 04:09:23.750536: predicting BRATS_290 
2025-02-26 04:09:23.774543: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2025-02-26 04:09:25.139865: predicting BRATS_291 
2025-02-26 04:09:25.165868: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-02-26 04:09:26.513532: predicting BRATS_292 
2025-02-26 04:09:26.540534: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2025-02-26 04:09:27.889830: predicting BRATS_293 
2025-02-26 04:09:27.915835: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2025-02-26 04:09:29.330521: predicting BRATS_300 
2025-02-26 04:09:29.357520: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2025-02-26 04:09:30.728898: predicting BRATS_305 
2025-02-26 04:09:30.757899: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2025-02-26 04:09:32.107787: predicting BRATS_311 
2025-02-26 04:09:32.132787: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2025-02-26 04:09:33.489888: predicting BRATS_314 
2025-02-26 04:09:33.513885: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2025-02-26 04:09:34.896176: predicting BRATS_321 
2025-02-26 04:09:34.919176: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-02-26 04:09:36.266533: predicting BRATS_328 
2025-02-26 04:09:36.295048: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2025-02-26 04:09:37.008548: predicting BRATS_329 
2025-02-26 04:09:37.032550: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2025-02-26 04:09:38.423846: predicting BRATS_335 
2025-02-26 04:09:38.449847: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2025-02-26 04:09:39.832032: predicting BRATS_343 
2025-02-26 04:09:39.863032: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2025-02-26 04:09:41.226237: predicting BRATS_350 
2025-02-26 04:09:41.258236: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2025-02-26 04:09:41.970168: predicting BRATS_351 
2025-02-26 04:09:41.994679: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2025-02-26 04:09:42.706540: predicting BRATS_356 
2025-02-26 04:09:42.734540: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2025-02-26 04:09:43.459855: predicting BRATS_366 
2025-02-26 04:09:43.485857: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2025-02-26 04:09:44.834228: predicting BRATS_367 
2025-02-26 04:09:44.861227: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2025-02-26 04:09:46.242835: predicting BRATS_374 
2025-02-26 04:09:46.268835: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2025-02-26 04:09:47.641000: predicting BRATS_376 
2025-02-26 04:09:47.670000: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2025-02-26 04:09:49.026600: predicting BRATS_377 
2025-02-26 04:09:49.052600: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2025-02-26 04:09:50.416329: predicting BRATS_378 
2025-02-26 04:09:50.438329: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2025-02-26 04:09:51.801474: predicting BRATS_379 
2025-02-26 04:09:51.827474: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2025-02-26 04:09:53.215518: predicting BRATS_384 
2025-02-26 04:09:53.244516: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2025-02-26 04:09:54.612269: predicting BRATS_386 
2025-02-26 04:09:54.635272: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-02-26 04:09:56.001308: predicting BRATS_394 
2025-02-26 04:09:56.026310: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-02-26 04:09:57.379098: predicting BRATS_398 
2025-02-26 04:09:57.402610: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2025-02-26 04:09:58.803547: predicting BRATS_400 
2025-02-26 04:09:58.830549: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2025-02-26 04:10:00.217562: predicting BRATS_432 
2025-02-26 04:10:00.248564: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2025-02-26 04:10:01.615390: predicting BRATS_437 
2025-02-26 04:10:01.640390: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-02-26 04:10:03.004464: predicting BRATS_445 
2025-02-26 04:10:03.028463: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2025-02-26 04:10:04.398956: predicting BRATS_446 
2025-02-26 04:10:04.424087: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-02-26 04:10:05.797658: predicting BRATS_450 
2025-02-26 04:10:05.822170: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2025-02-26 04:10:07.200295: predicting BRATS_452 
2025-02-26 04:10:07.225319: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2025-02-26 04:10:08.578985: predicting BRATS_460 
2025-02-26 04:10:08.607498: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2025-02-26 04:10:09.980846: predicting BRATS_470 
2025-02-26 04:10:10.011354: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-02-26 04:10:11.394325: predicting BRATS_472 
2025-02-26 04:10:11.421619: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2025-02-26 04:10:12.799564: predicting BRATS_473 
2025-02-26 04:10:12.829072: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2025-02-26 04:10:13.542203: predicting BRATS_482 
2025-02-26 04:10:13.564207: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2025-02-26 04:10:22.041027: Validation complete 
2025-02-26 04:10:22.048027: Mean Validation Dice:  0.7237998563890669 
