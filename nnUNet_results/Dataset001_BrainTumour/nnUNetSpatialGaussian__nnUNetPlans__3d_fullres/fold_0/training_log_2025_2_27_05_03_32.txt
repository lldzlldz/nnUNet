
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-27 05:03:32.522159: do_dummy_2d_data_aug: False 
2025-02-27 05:03:32.535852: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-02-27 05:03:32.542860: The split file contains 5 splits. 
2025-02-27 05:03:32.545859: Desired fold for training: 0 
2025-02-27 05:03:32.548860: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2025-02-27 05:04:05.879692: unpacking dataset... 
2025-02-27 05:04:24.985540: unpacking done... 
2025-02-27 05:04:29.939212:  
2025-02-27 05:04:29.943294: Epoch 0 
2025-02-27 05:04:29.947351: Current learning rate: 0.01 
2025-02-27 05:05:54.533075: train_loss -0.2811 
2025-02-27 05:05:54.540759: val_loss -0.4467 
2025-02-27 05:05:54.545338: Pseudo dice [np.float32(0.7095), np.float32(0.5271), np.float32(0.7572)] 
2025-02-27 05:05:54.548409: Epoch time: 84.59 s 
2025-02-27 05:05:54.551920: Yayy! New best EMA pseudo Dice: 0.6646000146865845 
2025-02-27 05:05:55.254949:  
2025-02-27 05:05:55.260964: Epoch 1 
2025-02-27 05:05:55.264470: Current learning rate: 0.00991 
2025-02-27 05:07:12.841150: train_loss -0.5342 
2025-02-27 05:07:12.848670: val_loss -0.527 
2025-02-27 05:07:12.853181: Pseudo dice [np.float32(0.7519), np.float32(0.6005), np.float32(0.8076)] 
2025-02-27 05:07:12.856190: Epoch time: 77.59 s 
2025-02-27 05:07:12.859701: Yayy! New best EMA pseudo Dice: 0.6700999736785889 
2025-02-27 05:07:13.624575:  
2025-02-27 05:07:13.630109: Epoch 2 
2025-02-27 05:07:13.634206: Current learning rate: 0.00982 
2025-02-27 05:08:31.073848: train_loss -0.5821 
2025-02-27 05:08:31.081588: val_loss -0.5484 
2025-02-27 05:08:31.085124: Pseudo dice [np.float32(0.7851), np.float32(0.6072), np.float32(0.8133)] 
2025-02-27 05:08:31.089200: Epoch time: 77.45 s 
2025-02-27 05:08:31.091736: Yayy! New best EMA pseudo Dice: 0.6765999794006348 
2025-02-27 05:08:31.867543:  
2025-02-27 05:08:31.873635: Epoch 3 
2025-02-27 05:08:31.877680: Current learning rate: 0.00973 
2025-02-27 05:09:49.287214: train_loss -0.6007 
2025-02-27 05:09:49.293769: val_loss -0.5899 
2025-02-27 05:09:49.298821: Pseudo dice [np.float32(0.7807), np.float32(0.6232), np.float32(0.8231)] 
2025-02-27 05:09:49.302862: Epoch time: 77.42 s 
2025-02-27 05:09:49.306489: Yayy! New best EMA pseudo Dice: 0.6832000017166138 
2025-02-27 05:09:50.081845:  
2025-02-27 05:09:50.086857: Epoch 4 
2025-02-27 05:09:50.090865: Current learning rate: 0.00964 
2025-02-27 05:11:07.637001: train_loss -0.6078 
2025-02-27 05:11:07.644620: val_loss -0.5577 
2025-02-27 05:11:07.648246: Pseudo dice [np.float32(0.7778), np.float32(0.6256), np.float32(0.7902)] 
2025-02-27 05:11:07.652362: Epoch time: 77.56 s 
2025-02-27 05:11:07.655957: Yayy! New best EMA pseudo Dice: 0.6880000233650208 
2025-02-27 05:11:08.539782:  
2025-02-27 05:11:08.545890: Epoch 5 
2025-02-27 05:11:08.548955: Current learning rate: 0.00955 
2025-02-27 05:12:25.985666: train_loss -0.6338 
2025-02-27 05:12:25.992772: val_loss -0.5765 
2025-02-27 05:12:25.996535: Pseudo dice [np.float32(0.7905), np.float32(0.6295), np.float32(0.8268)] 
2025-02-27 05:12:26.000082: Epoch time: 77.45 s 
2025-02-27 05:12:26.003669: Yayy! New best EMA pseudo Dice: 0.694100022315979 
2025-02-27 05:12:26.765224:  
2025-02-27 05:12:26.771808: Epoch 6 
2025-02-27 05:12:26.774346: Current learning rate: 0.00946 
2025-02-27 05:13:44.506665: train_loss -0.6475 
2025-02-27 05:13:44.514185: val_loss -0.6003 
2025-02-27 05:13:44.517699: Pseudo dice [np.float32(0.8049), np.float32(0.6625), np.float32(0.8401)] 
2025-02-27 05:13:44.521714: Epoch time: 77.74 s 
2025-02-27 05:13:44.525228: Yayy! New best EMA pseudo Dice: 0.7016000151634216 
2025-02-27 05:13:45.267320:  
2025-02-27 05:13:45.272398: Epoch 7 
2025-02-27 05:13:45.275924: Current learning rate: 0.00937 
2025-02-27 05:15:02.495472: train_loss -0.643 
2025-02-27 05:15:02.502999: val_loss -0.6176 
2025-02-27 05:15:02.507009: Pseudo dice [np.float32(0.8099), np.float32(0.7074), np.float32(0.8295)] 
2025-02-27 05:15:02.510520: Epoch time: 77.23 s 
2025-02-27 05:15:02.514532: Yayy! New best EMA pseudo Dice: 0.7096999883651733 
2025-02-27 05:15:03.292493:  
2025-02-27 05:15:03.299073: Epoch 8 
2025-02-27 05:15:03.301716: Current learning rate: 0.00928 
2025-02-27 05:16:20.691740: train_loss -0.6672 
2025-02-27 05:16:20.699007: val_loss -0.6149 
2025-02-27 05:16:20.702777: Pseudo dice [np.float32(0.8007), np.float32(0.6968), np.float32(0.842)] 
2025-02-27 05:16:20.706537: Epoch time: 77.4 s 
2025-02-27 05:16:20.710160: Yayy! New best EMA pseudo Dice: 0.71670001745224 
2025-02-27 05:16:21.470832:  
2025-02-27 05:16:21.476347: Epoch 9 
2025-02-27 05:16:21.479857: Current learning rate: 0.00919 
2025-02-27 05:17:38.987195: train_loss -0.6622 
2025-02-27 05:17:38.993912: val_loss -0.6239 
2025-02-27 05:17:38.997422: Pseudo dice [np.float32(0.8136), np.float32(0.6993), np.float32(0.8251)] 
2025-02-27 05:17:39.001431: Epoch time: 77.52 s 
2025-02-27 05:17:39.004946: Yayy! New best EMA pseudo Dice: 0.7229999899864197 
2025-02-27 05:17:39.752528:  
2025-02-27 05:17:39.758197: Epoch 10 
2025-02-27 05:17:39.761230: Current learning rate: 0.0091 
2025-02-27 05:18:56.893089: train_loss -0.6748 
2025-02-27 05:18:56.903124: val_loss -0.6138 
2025-02-27 05:18:56.909139: Pseudo dice [np.float32(0.7977), np.float32(0.7018), np.float32(0.8466)] 
2025-02-27 05:18:56.913161: Epoch time: 77.14 s 
2025-02-27 05:18:56.915671: Yayy! New best EMA pseudo Dice: 0.7289000153541565 
2025-02-27 05:18:57.679235:  
2025-02-27 05:18:57.684803: Epoch 11 
2025-02-27 05:18:57.688859: Current learning rate: 0.009 
2025-02-27 05:20:15.432851: train_loss -0.6775 
2025-02-27 05:20:15.441099: val_loss -0.6171 
2025-02-27 05:20:15.444670: Pseudo dice [np.float32(0.8071), np.float32(0.6682), np.float32(0.846)] 
2025-02-27 05:20:15.447756: Epoch time: 77.75 s 
2025-02-27 05:20:15.450786: Yayy! New best EMA pseudo Dice: 0.7333999872207642 
2025-02-27 05:20:16.218205:  
2025-02-27 05:20:16.223216: Epoch 12 
2025-02-27 05:20:16.226724: Current learning rate: 0.00891 
2025-02-27 05:21:33.833110: train_loss -0.6777 
2025-02-27 05:21:33.841265: val_loss -0.6204 
2025-02-27 05:21:33.845381: Pseudo dice [np.float32(0.8191), np.float32(0.6786), np.float32(0.8448)] 
2025-02-27 05:21:33.848638: Epoch time: 77.62 s 
2025-02-27 05:21:33.853187: Yayy! New best EMA pseudo Dice: 0.738099992275238 
2025-02-27 05:21:34.827684:  
2025-02-27 05:21:34.833267: Epoch 13 
2025-02-27 05:21:34.835869: Current learning rate: 0.00882 
2025-02-27 05:22:52.556759: train_loss -0.6755 
2025-02-27 05:22:52.564280: val_loss -0.6308 
2025-02-27 05:22:52.568290: Pseudo dice [np.float32(0.8153), np.float32(0.6973), np.float32(0.8497)] 
2025-02-27 05:22:52.571801: Epoch time: 77.73 s 
2025-02-27 05:22:52.575446: Yayy! New best EMA pseudo Dice: 0.7429999709129333 
2025-02-27 05:22:53.320841:  
2025-02-27 05:22:53.325362: Epoch 14 
2025-02-27 05:22:53.328928: Current learning rate: 0.00873 
2025-02-27 05:24:10.895607: train_loss -0.6866 
2025-02-27 05:24:10.903130: val_loss -0.621 
2025-02-27 05:24:10.907140: Pseudo dice [np.float32(0.8252), np.float32(0.6889), np.float32(0.8483)] 
2025-02-27 05:24:10.910308: Epoch time: 77.57 s 
2025-02-27 05:24:10.914853: Yayy! New best EMA pseudo Dice: 0.7475000023841858 
2025-02-27 05:24:11.681179:  
2025-02-27 05:24:11.687338: Epoch 15 
2025-02-27 05:24:11.691420: Current learning rate: 0.00864 
2025-02-27 05:25:29.277725: train_loss -0.6863 
2025-02-27 05:25:29.285248: val_loss -0.641 
2025-02-27 05:25:29.289761: Pseudo dice [np.float32(0.8077), np.float32(0.7015), np.float32(0.85)] 
2025-02-27 05:25:29.293775: Epoch time: 77.6 s 
2025-02-27 05:25:29.297787: Yayy! New best EMA pseudo Dice: 0.7513999938964844 
2025-02-27 05:25:30.082777:  
2025-02-27 05:25:30.089291: Epoch 16 
2025-02-27 05:25:30.092806: Current learning rate: 0.00855 
2025-02-27 05:26:47.600902: train_loss -0.6954 
2025-02-27 05:26:47.607920: val_loss -0.6076 
2025-02-27 05:26:47.611935: Pseudo dice [np.float32(0.8102), np.float32(0.6851), np.float32(0.8594)] 
2025-02-27 05:26:47.614440: Epoch time: 77.52 s 
2025-02-27 05:26:47.618452: Yayy! New best EMA pseudo Dice: 0.7547000050544739 
2025-02-27 05:26:48.380166:  
2025-02-27 05:26:48.385729: Epoch 17 
2025-02-27 05:26:48.389274: Current learning rate: 0.00846 
2025-02-27 05:28:06.334118: train_loss -0.7012 
2025-02-27 05:28:06.341643: val_loss -0.6493 
2025-02-27 05:28:06.345654: Pseudo dice [np.float32(0.8268), np.float32(0.7203), np.float32(0.8539)] 
2025-02-27 05:28:06.349166: Epoch time: 77.95 s 
2025-02-27 05:28:06.353177: Yayy! New best EMA pseudo Dice: 0.7592999935150146 
2025-02-27 05:28:07.116558:  
2025-02-27 05:28:07.122132: Epoch 18 
2025-02-27 05:28:07.125671: Current learning rate: 0.00836 
2025-02-27 05:29:24.890721: train_loss -0.7025 
2025-02-27 05:29:24.899183: val_loss -0.6355 
2025-02-27 05:29:24.903703: Pseudo dice [np.float32(0.8217), np.float32(0.6858), np.float32(0.8389)] 
2025-02-27 05:29:24.907721: Epoch time: 77.78 s 
2025-02-27 05:29:24.912743: Yayy! New best EMA pseudo Dice: 0.7616000175476074 
2025-02-27 05:29:25.695619:  
2025-02-27 05:29:25.701653: Epoch 19 
2025-02-27 05:29:25.705160: Current learning rate: 0.00827 
2025-02-27 05:30:43.101062: train_loss -0.7066 
2025-02-27 05:30:43.108723: val_loss -0.6452 
2025-02-27 05:30:43.112305: Pseudo dice [np.float32(0.8264), np.float32(0.704), np.float32(0.8481)] 
2025-02-27 05:30:43.115472: Epoch time: 77.41 s 
2025-02-27 05:30:43.119710: Yayy! New best EMA pseudo Dice: 0.7646999955177307 
2025-02-27 05:30:44.083012:  
2025-02-27 05:30:44.088522: Epoch 20 
2025-02-27 05:30:44.092035: Current learning rate: 0.00818 
2025-02-27 05:32:01.725531: train_loss -0.7113 
2025-02-27 05:32:01.733054: val_loss -0.6196 
2025-02-27 05:32:01.736568: Pseudo dice [np.float32(0.815), np.float32(0.6834), np.float32(0.8523)] 
2025-02-27 05:32:01.740581: Epoch time: 77.64 s 
2025-02-27 05:32:01.744093: Yayy! New best EMA pseudo Dice: 0.7666000127792358 
2025-02-27 05:32:02.519283:  
2025-02-27 05:32:02.528305: Epoch 21 
2025-02-27 05:32:02.533318: Current learning rate: 0.00809 
2025-02-27 05:33:19.821535: train_loss -0.7032 
2025-02-27 05:33:19.829056: val_loss -0.6316 
2025-02-27 05:33:19.832570: Pseudo dice [np.float32(0.8172), np.float32(0.7102), np.float32(0.8555)] 
2025-02-27 05:33:19.836581: Epoch time: 77.3 s 
2025-02-27 05:33:19.841096: Yayy! New best EMA pseudo Dice: 0.7694000005722046 
2025-02-27 05:33:20.554667:  
2025-02-27 05:33:20.561235: Epoch 22 
2025-02-27 05:33:20.564811: Current learning rate: 0.008 
2025-02-27 05:34:38.258344: train_loss -0.7092 
2025-02-27 05:34:38.265859: val_loss -0.6371 
2025-02-27 05:34:38.269869: Pseudo dice [np.float32(0.8283), np.float32(0.7111), np.float32(0.8308)] 
2025-02-27 05:34:38.273382: Epoch time: 77.7 s 
2025-02-27 05:34:38.277394: Yayy! New best EMA pseudo Dice: 0.771399974822998 
2025-02-27 05:34:39.017702:  
2025-02-27 05:34:39.024300: Epoch 23 
2025-02-27 05:34:39.026854: Current learning rate: 0.0079 
2025-02-27 05:35:56.726538: train_loss -0.7172 
2025-02-27 05:35:56.734065: val_loss -0.6596 
2025-02-27 05:35:56.738578: Pseudo dice [np.float32(0.8303), np.float32(0.742), np.float32(0.869)] 
2025-02-27 05:35:56.741588: Epoch time: 77.71 s 
2025-02-27 05:35:56.746099: Yayy! New best EMA pseudo Dice: 0.7756999731063843 
2025-02-27 05:35:57.472386:  
2025-02-27 05:35:57.477926: Epoch 24 
2025-02-27 05:35:57.481487: Current learning rate: 0.00781 
2025-02-27 05:37:15.010806: train_loss -0.7171 
2025-02-27 05:37:15.018333: val_loss -0.6426 
2025-02-27 05:37:15.021849: Pseudo dice [np.float32(0.828), np.float32(0.7184), np.float32(0.8604)] 
2025-02-27 05:37:15.025857: Epoch time: 77.54 s 
2025-02-27 05:37:15.029370: Yayy! New best EMA pseudo Dice: 0.7782999873161316 
2025-02-27 05:37:15.777558:  
2025-02-27 05:37:15.783100: Epoch 25 
2025-02-27 05:37:15.786673: Current learning rate: 0.00772 
2025-02-27 05:38:33.294918: train_loss -0.715 
2025-02-27 05:38:33.302439: val_loss -0.6322 
2025-02-27 05:38:33.305952: Pseudo dice [np.float32(0.8205), np.float32(0.7049), np.float32(0.8638)] 
2025-02-27 05:38:33.309964: Epoch time: 77.52 s 
2025-02-27 05:38:33.313477: Yayy! New best EMA pseudo Dice: 0.7800999879837036 
2025-02-27 05:38:34.109592:  
2025-02-27 05:38:34.116179: Epoch 26 
2025-02-27 05:38:34.120794: Current learning rate: 0.00763 
2025-02-27 05:39:51.676558: train_loss -0.7266 
2025-02-27 05:39:51.683100: val_loss -0.6569 
2025-02-27 05:39:51.687112: Pseudo dice [np.float32(0.8357), np.float32(0.7094), np.float32(0.8721)] 
2025-02-27 05:39:51.690624: Epoch time: 77.57 s 
2025-02-27 05:39:51.694131: Yayy! New best EMA pseudo Dice: 0.7827000021934509 
2025-02-27 05:39:52.447688:  
2025-02-27 05:39:52.453782: Epoch 27 
2025-02-27 05:39:52.457332: Current learning rate: 0.00753 
2025-02-27 05:41:10.161314: train_loss -0.718 
2025-02-27 05:41:10.168375: val_loss -0.6422 
2025-02-27 05:41:10.172384: Pseudo dice [np.float32(0.8347), np.float32(0.6808), np.float32(0.8723)] 
2025-02-27 05:41:10.175900: Epoch time: 77.71 s 
2025-02-27 05:41:10.180114: Yayy! New best EMA pseudo Dice: 0.7839999794960022 
2025-02-27 05:41:11.124602:  
2025-02-27 05:41:11.131164: Epoch 28 
2025-02-27 05:41:11.135204: Current learning rate: 0.00744 
2025-02-27 05:42:28.381894: train_loss -0.729 
2025-02-27 05:42:28.388914: val_loss -0.6526 
2025-02-27 05:42:28.392951: Pseudo dice [np.float32(0.8329), np.float32(0.7309), np.float32(0.8621)] 
2025-02-27 05:42:28.396458: Epoch time: 77.26 s 
2025-02-27 05:42:28.400475: Yayy! New best EMA pseudo Dice: 0.7864999771118164 
2025-02-27 05:42:29.147352:  
2025-02-27 05:42:29.153486: Epoch 29 
2025-02-27 05:42:29.156556: Current learning rate: 0.00735 
2025-02-27 05:43:46.164074: train_loss -0.7283 
2025-02-27 05:43:46.171597: val_loss -0.6384 
2025-02-27 05:43:46.175109: Pseudo dice [np.float32(0.8132), np.float32(0.7268), np.float32(0.8566)] 
2025-02-27 05:43:46.178618: Epoch time: 77.02 s 
2025-02-27 05:43:46.182636: Yayy! New best EMA pseudo Dice: 0.7876999974250793 
2025-02-27 05:43:46.926959:  
2025-02-27 05:43:46.931977: Epoch 30 
2025-02-27 05:43:46.934989: Current learning rate: 0.00725 
2025-02-27 05:45:04.496610: train_loss -0.7321 
2025-02-27 05:45:04.504133: val_loss -0.6402 
2025-02-27 05:45:04.508143: Pseudo dice [np.float32(0.8349), np.float32(0.7086), np.float32(0.8426)] 
2025-02-27 05:45:04.511655: Epoch time: 77.57 s 
2025-02-27 05:45:04.515667: Yayy! New best EMA pseudo Dice: 0.7885000109672546 
2025-02-27 05:45:05.280089:  
2025-02-27 05:45:05.286164: Epoch 31 
2025-02-27 05:45:05.289224: Current learning rate: 0.00716 
2025-02-27 05:46:22.908119: train_loss -0.7308 
2025-02-27 05:46:22.915218: val_loss -0.661 
2025-02-27 05:46:22.918784: Pseudo dice [np.float32(0.8424), np.float32(0.7116), np.float32(0.8768)] 
2025-02-27 05:46:22.922917: Epoch time: 77.63 s 
2025-02-27 05:46:22.926506: Yayy! New best EMA pseudo Dice: 0.7907000184059143 
2025-02-27 05:46:23.688205:  
2025-02-27 05:46:23.696382: Epoch 32 
2025-02-27 05:46:23.699951: Current learning rate: 0.00707 
2025-02-27 05:47:41.212127: train_loss -0.7299 
2025-02-27 05:47:41.218716: val_loss -0.6293 
2025-02-27 05:47:41.223270: Pseudo dice [np.float32(0.8094), np.float32(0.7101), np.float32(0.8599)] 
2025-02-27 05:47:41.226319: Epoch time: 77.52 s 
2025-02-27 05:47:41.233421: Yayy! New best EMA pseudo Dice: 0.7908999919891357 
2025-02-27 05:47:41.996099:  
2025-02-27 05:47:42.000152: Epoch 33 
2025-02-27 05:47:42.004793: Current learning rate: 0.00697 
2025-02-27 05:48:59.360245: train_loss -0.73 
2025-02-27 05:48:59.368291: val_loss -0.6306 
2025-02-27 05:48:59.373304: Pseudo dice [np.float32(0.8168), np.float32(0.7187), np.float32(0.8514)] 
2025-02-27 05:48:59.376814: Epoch time: 77.36 s 
2025-02-27 05:48:59.380836: Yayy! New best EMA pseudo Dice: 0.7914000153541565 
2025-02-27 05:49:00.158392:  
2025-02-27 05:49:00.164518: Epoch 34 
2025-02-27 05:49:00.167589: Current learning rate: 0.00688 
2025-02-27 05:50:17.958806: train_loss -0.7356 
2025-02-27 05:50:17.967464: val_loss -0.6202 
2025-02-27 05:50:17.971003: Pseudo dice [np.float32(0.8256), np.float32(0.6785), np.float32(0.8583)] 
2025-02-27 05:50:17.973528: Epoch time: 77.8 s 
2025-02-27 05:50:18.617967:  
2025-02-27 05:50:18.624549: Epoch 35 
2025-02-27 05:50:18.627155: Current learning rate: 0.00679 
2025-02-27 05:51:36.220344: train_loss -0.7396 
2025-02-27 05:51:36.226866: val_loss -0.6243 
2025-02-27 05:51:36.230373: Pseudo dice [np.float32(0.8244), np.float32(0.7027), np.float32(0.8561)] 
2025-02-27 05:51:36.233383: Epoch time: 77.6 s 
2025-02-27 05:51:37.062526:  
2025-02-27 05:51:37.068143: Epoch 36 
2025-02-27 05:51:37.071192: Current learning rate: 0.00669 
2025-02-27 05:52:54.578478: train_loss -0.7407 
2025-02-27 05:52:54.584996: val_loss -0.6449 
2025-02-27 05:52:54.589509: Pseudo dice [np.float32(0.8292), np.float32(0.7164), np.float32(0.8657)] 
2025-02-27 05:52:54.593524: Epoch time: 77.52 s 
2025-02-27 05:52:54.597535: Yayy! New best EMA pseudo Dice: 0.7925999760627747 
2025-02-27 05:52:55.369073:  
2025-02-27 05:52:55.374672: Epoch 37 
2025-02-27 05:52:55.377721: Current learning rate: 0.0066 
2025-02-27 05:54:12.946167: train_loss -0.7463 
2025-02-27 05:54:12.953831: val_loss -0.6458 
2025-02-27 05:54:12.956847: Pseudo dice [np.float32(0.8307), np.float32(0.7402), np.float32(0.8697)] 
2025-02-27 05:54:12.960891: Epoch time: 77.58 s 
2025-02-27 05:54:12.963946: Yayy! New best EMA pseudo Dice: 0.794700026512146 
2025-02-27 05:54:13.717723:  
2025-02-27 05:54:13.724394: Epoch 38 
2025-02-27 05:54:13.727934: Current learning rate: 0.0065 
2025-02-27 05:55:31.150081: train_loss -0.7388 
2025-02-27 05:55:31.157678: val_loss -0.6547 
2025-02-27 05:55:31.162227: Pseudo dice [np.float32(0.8218), np.float32(0.742), np.float32(0.8559)] 
2025-02-27 05:55:31.166277: Epoch time: 77.43 s 
2025-02-27 05:55:31.169825: Yayy! New best EMA pseudo Dice: 0.7958999872207642 
2025-02-27 05:55:31.965574:  
2025-02-27 05:55:31.971093: Epoch 39 
2025-02-27 05:55:31.974607: Current learning rate: 0.00641 
2025-02-27 05:56:49.688715: train_loss -0.7434 
2025-02-27 05:56:49.696239: val_loss -0.6489 
2025-02-27 05:56:49.699804: Pseudo dice [np.float32(0.8229), np.float32(0.7167), np.float32(0.8537)] 
2025-02-27 05:56:49.703819: Epoch time: 77.72 s 
2025-02-27 05:56:49.707334: Yayy! New best EMA pseudo Dice: 0.7960000038146973 
2025-02-27 05:56:50.487644:  
2025-02-27 05:56:50.494194: Epoch 40 
2025-02-27 05:56:50.497758: Current learning rate: 0.00631 
2025-02-27 05:58:08.261174: train_loss -0.7458 
2025-02-27 05:58:08.268343: val_loss -0.6273 
2025-02-27 05:58:08.271353: Pseudo dice [np.float32(0.822), np.float32(0.6817), np.float32(0.8585)] 
2025-02-27 05:58:08.274871: Epoch time: 77.77 s 
2025-02-27 05:58:08.939590:  
2025-02-27 05:58:08.944638: Epoch 41 
2025-02-27 05:58:08.948170: Current learning rate: 0.00622 
2025-02-27 05:59:26.272203: train_loss -0.7477 
2025-02-27 05:59:26.279223: val_loss -0.6255 
2025-02-27 05:59:26.283242: Pseudo dice [np.float32(0.8277), np.float32(0.6911), np.float32(0.8722)] 
2025-02-27 05:59:26.286749: Epoch time: 77.33 s 
2025-02-27 05:59:26.906868:  
2025-02-27 05:59:26.911917: Epoch 42 
2025-02-27 05:59:26.914044: Current learning rate: 0.00612 
2025-02-27 06:00:44.603688: train_loss -0.7527 
2025-02-27 06:00:44.610207: val_loss -0.6471 
2025-02-27 06:00:44.613719: Pseudo dice [np.float32(0.831), np.float32(0.7335), np.float32(0.8829)] 
2025-02-27 06:00:44.617738: Epoch time: 77.7 s 
2025-02-27 06:00:44.620245: Yayy! New best EMA pseudo Dice: 0.7973999977111816 
2025-02-27 06:00:45.540412:  
2025-02-27 06:00:45.545330: Epoch 43 
2025-02-27 06:00:45.548841: Current learning rate: 0.00603 
2025-02-27 06:02:03.277265: train_loss -0.7498 
2025-02-27 06:02:03.284785: val_loss -0.6214 
2025-02-27 06:02:03.288827: Pseudo dice [np.float32(0.8178), np.float32(0.7077), np.float32(0.856)] 
2025-02-27 06:02:03.293841: Epoch time: 77.74 s 
2025-02-27 06:02:03.927517:  
2025-02-27 06:02:03.935612: Epoch 44 
2025-02-27 06:02:03.939265: Current learning rate: 0.00593 
2025-02-27 06:03:20.993913: train_loss -0.7565 
2025-02-27 06:03:21.001485: val_loss -0.6323 
2025-02-27 06:03:21.005607: Pseudo dice [np.float32(0.8324), np.float32(0.7158), np.float32(0.8529)] 
2025-02-27 06:03:21.009165: Epoch time: 77.07 s 
2025-02-27 06:03:21.601171:  
2025-02-27 06:03:21.606821: Epoch 45 
2025-02-27 06:03:21.610422: Current learning rate: 0.00584 
2025-02-27 06:04:39.311720: train_loss -0.7505 
2025-02-27 06:04:39.319243: val_loss -0.648 
2025-02-27 06:04:39.323256: Pseudo dice [np.float32(0.8234), np.float32(0.7124), np.float32(0.8704)] 
2025-02-27 06:04:39.326272: Epoch time: 77.71 s 
2025-02-27 06:04:39.330315: Yayy! New best EMA pseudo Dice: 0.7978000044822693 
2025-02-27 06:04:40.049245:  
2025-02-27 06:04:40.054258: Epoch 46 
2025-02-27 06:04:40.057769: Current learning rate: 0.00574 
2025-02-27 06:05:57.648820: train_loss -0.7485 
2025-02-27 06:05:57.655889: val_loss -0.6578 
2025-02-27 06:05:57.660057: Pseudo dice [np.float32(0.8416), np.float32(0.7053), np.float32(0.8624)] 
2025-02-27 06:05:57.664132: Epoch time: 77.6 s 
2025-02-27 06:05:57.667202: Yayy! New best EMA pseudo Dice: 0.7983999848365784 
2025-02-27 06:05:58.420529:  
2025-02-27 06:05:58.426105: Epoch 47 
2025-02-27 06:05:58.430172: Current learning rate: 0.00565 
2025-02-27 06:07:15.916354: train_loss -0.7493 
2025-02-27 06:07:15.923876: val_loss -0.6725 
2025-02-27 06:07:15.927385: Pseudo dice [np.float32(0.8508), np.float32(0.7428), np.float32(0.873)] 
2025-02-27 06:07:15.930892: Epoch time: 77.5 s 
2025-02-27 06:07:15.934906: Yayy! New best EMA pseudo Dice: 0.8008000254631042 
2025-02-27 06:07:16.671544:  
2025-02-27 06:07:16.677602: Epoch 48 
2025-02-27 06:07:16.680761: Current learning rate: 0.00555 
2025-02-27 06:08:34.030523: train_loss -0.7485 
2025-02-27 06:08:34.038767: val_loss -0.6271 
2025-02-27 06:08:34.042277: Pseudo dice [np.float32(0.8193), np.float32(0.7294), np.float32(0.8587)] 
2025-02-27 06:08:34.046289: Epoch time: 77.36 s 
2025-02-27 06:08:34.051305: Yayy! New best EMA pseudo Dice: 0.8008999824523926 
2025-02-27 06:08:34.805178:  
2025-02-27 06:08:34.810693: Epoch 49 
2025-02-27 06:08:34.814204: Current learning rate: 0.00546 
2025-02-27 06:09:52.135168: train_loss -0.7514 
2025-02-27 06:09:52.142692: val_loss -0.6286 
2025-02-27 06:09:52.147201: Pseudo dice [np.float32(0.8238), np.float32(0.7119), np.float32(0.8595)] 
2025-02-27 06:09:52.150211: Epoch time: 77.33 s 
2025-02-27 06:09:52.907895:  
2025-02-27 06:09:52.913462: Epoch 50 
2025-02-27 06:09:52.917032: Current learning rate: 0.00536 
2025-02-27 06:11:10.439910: train_loss -0.7554 
2025-02-27 06:11:10.446424: val_loss -0.6325 
2025-02-27 06:11:10.449933: Pseudo dice [np.float32(0.8252), np.float32(0.6725), np.float32(0.8579)] 
2025-02-27 06:11:10.453942: Epoch time: 77.53 s 
2025-02-27 06:11:11.244977:  
2025-02-27 06:11:11.251495: Epoch 51 
2025-02-27 06:11:11.255004: Current learning rate: 0.00526 
2025-02-27 06:12:28.694916: train_loss -0.7498 
2025-02-27 06:12:28.702495: val_loss -0.6438 
2025-02-27 06:12:28.706061: Pseudo dice [np.float32(0.8367), np.float32(0.7108), np.float32(0.8583)] 
2025-02-27 06:12:28.710095: Epoch time: 77.45 s 
2025-02-27 06:12:29.441493:  
2025-02-27 06:12:29.447031: Epoch 52 
2025-02-27 06:12:29.450581: Current learning rate: 0.00517 
2025-02-27 06:13:46.869472: train_loss -0.7615 
2025-02-27 06:13:46.876008: val_loss -0.6523 
2025-02-27 06:13:46.880015: Pseudo dice [np.float32(0.8334), np.float32(0.7338), np.float32(0.8626)] 
2025-02-27 06:13:46.883523: Epoch time: 77.43 s 
2025-02-27 06:13:47.504416:  
2025-02-27 06:13:47.513080: Epoch 53 
2025-02-27 06:13:47.517720: Current learning rate: 0.00507 
2025-02-27 06:15:05.157866: train_loss -0.7548 
2025-02-27 06:15:05.164453: val_loss -0.6169 
2025-02-27 06:15:05.169065: Pseudo dice [np.float32(0.8192), np.float32(0.7062), np.float32(0.8596)] 
2025-02-27 06:15:05.173115: Epoch time: 77.65 s 
2025-02-27 06:15:05.796473:  
2025-02-27 06:15:05.803142: Epoch 54 
2025-02-27 06:15:05.808052: Current learning rate: 0.00497 
2025-02-27 06:16:23.220960: train_loss -0.7561 
2025-02-27 06:16:23.228484: val_loss -0.662 
2025-02-27 06:16:23.233502: Pseudo dice [np.float32(0.8418), np.float32(0.7073), np.float32(0.8518)] 
2025-02-27 06:16:23.237013: Epoch time: 77.43 s 
2025-02-27 06:16:23.851324:  
2025-02-27 06:16:23.857932: Epoch 55 
2025-02-27 06:16:23.862037: Current learning rate: 0.00487 
2025-02-27 06:17:41.246721: train_loss -0.7561 
2025-02-27 06:17:41.254274: val_loss -0.6546 
2025-02-27 06:17:41.258284: Pseudo dice [np.float32(0.8329), np.float32(0.7318), np.float32(0.8771)] 
2025-02-27 06:17:41.262899: Epoch time: 77.4 s 
2025-02-27 06:17:41.266416: Yayy! New best EMA pseudo Dice: 0.8014000058174133 
2025-02-27 06:17:42.034473:  
2025-02-27 06:17:42.041029: Epoch 56 
2025-02-27 06:17:42.044554: Current learning rate: 0.00478 
2025-02-27 06:18:59.406378: train_loss -0.7695 
2025-02-27 06:18:59.414780: val_loss -0.6443 
2025-02-27 06:18:59.418346: Pseudo dice [np.float32(0.8325), np.float32(0.7123), np.float32(0.8595)] 
2025-02-27 06:18:59.423358: Epoch time: 77.37 s 
2025-02-27 06:18:59.426869: Yayy! New best EMA pseudo Dice: 0.8014000058174133 
2025-02-27 06:19:00.230804:  
2025-02-27 06:19:00.236819: Epoch 57 
2025-02-27 06:19:00.241837: Current learning rate: 0.00468 
2025-02-27 06:20:17.705078: train_loss -0.7598 
2025-02-27 06:20:17.713190: val_loss -0.648 
2025-02-27 06:20:17.717225: Pseudo dice [np.float32(0.8233), np.float32(0.7159), np.float32(0.8607)] 
2025-02-27 06:20:17.721824: Epoch time: 77.48 s 
2025-02-27 06:20:18.323325:  
2025-02-27 06:20:18.328886: Epoch 58 
2025-02-27 06:20:18.333457: Current learning rate: 0.00458 
2025-02-27 06:21:36.009635: train_loss -0.7635 
2025-02-27 06:21:36.017159: val_loss -0.6412 
2025-02-27 06:21:36.022170: Pseudo dice [np.float32(0.8284), np.float32(0.732), np.float32(0.8564)] 
2025-02-27 06:21:36.025680: Epoch time: 77.69 s 
2025-02-27 06:21:36.029687: Yayy! New best EMA pseudo Dice: 0.8016999959945679 
2025-02-27 06:21:36.773279:  
2025-02-27 06:21:36.778792: Epoch 59 
2025-02-27 06:21:36.782302: Current learning rate: 0.00448 
2025-02-27 06:22:54.274126: train_loss -0.7611 
2025-02-27 06:22:54.280638: val_loss -0.6653 
2025-02-27 06:22:54.284147: Pseudo dice [np.float32(0.8304), np.float32(0.735), np.float32(0.8716)] 
2025-02-27 06:22:54.288159: Epoch time: 77.5 s 
2025-02-27 06:22:54.291669: Yayy! New best EMA pseudo Dice: 0.8026999831199646 
2025-02-27 06:22:55.253197:  
2025-02-27 06:22:55.258904: Epoch 60 
2025-02-27 06:22:55.261917: Current learning rate: 0.00438 
2025-02-27 06:24:12.392990: train_loss -0.7656 
2025-02-27 06:24:12.400582: val_loss -0.6445 
2025-02-27 06:24:12.404647: Pseudo dice [np.float32(0.8371), np.float32(0.7103), np.float32(0.8716)] 
2025-02-27 06:24:12.408180: Epoch time: 77.14 s 
2025-02-27 06:24:12.411743: Yayy! New best EMA pseudo Dice: 0.8030999898910522 
2025-02-27 06:24:13.166686:  
2025-02-27 06:24:13.172763: Epoch 61 
2025-02-27 06:24:13.175300: Current learning rate: 0.00429 
2025-02-27 06:25:30.297746: train_loss -0.7623 
2025-02-27 06:25:30.304930: val_loss -0.6642 
2025-02-27 06:25:30.308511: Pseudo dice [np.float32(0.8464), np.float32(0.7571), np.float32(0.8641)] 
2025-02-27 06:25:30.312045: Epoch time: 77.13 s 
2025-02-27 06:25:30.315592: Yayy! New best EMA pseudo Dice: 0.8050000071525574 
2025-02-27 06:25:31.078697:  
2025-02-27 06:25:31.084275: Epoch 62 
2025-02-27 06:25:31.086812: Current learning rate: 0.00419 
2025-02-27 06:26:48.611058: train_loss -0.7641 
2025-02-27 06:26:48.619585: val_loss -0.6385 
2025-02-27 06:26:48.623594: Pseudo dice [np.float32(0.8232), np.float32(0.7188), np.float32(0.8598)] 
2025-02-27 06:26:48.627106: Epoch time: 77.53 s 
2025-02-27 06:26:49.249366:  
2025-02-27 06:26:49.254900: Epoch 63 
2025-02-27 06:26:49.257926: Current learning rate: 0.00409 
2025-02-27 06:28:07.001788: train_loss -0.7709 
2025-02-27 06:28:07.008364: val_loss -0.6639 
2025-02-27 06:28:07.012904: Pseudo dice [np.float32(0.8199), np.float32(0.7457), np.float32(0.8655)] 
2025-02-27 06:28:07.017471: Epoch time: 77.75 s 
2025-02-27 06:28:07.022525: Yayy! New best EMA pseudo Dice: 0.8051999807357788 
2025-02-27 06:28:07.808317:  
2025-02-27 06:28:07.813272: Epoch 64 
2025-02-27 06:28:07.816829: Current learning rate: 0.00399 
2025-02-27 06:29:25.373527: train_loss -0.7647 
2025-02-27 06:29:25.381087: val_loss -0.6243 
2025-02-27 06:29:25.384607: Pseudo dice [np.float32(0.8234), np.float32(0.7253), np.float32(0.8546)] 
2025-02-27 06:29:25.388168: Epoch time: 77.57 s 
2025-02-27 06:29:26.015275:  
2025-02-27 06:29:26.024401: Epoch 65 
2025-02-27 06:29:26.029536: Current learning rate: 0.00389 
2025-02-27 06:30:43.405903: train_loss -0.7632 
2025-02-27 06:30:43.413421: val_loss -0.617 
2025-02-27 06:30:43.416931: Pseudo dice [np.float32(0.825), np.float32(0.685), np.float32(0.8554)] 
2025-02-27 06:30:43.420938: Epoch time: 77.39 s 
2025-02-27 06:30:44.036044:  
2025-02-27 06:30:44.042123: Epoch 66 
2025-02-27 06:30:44.045666: Current learning rate: 0.00379 
2025-02-27 06:32:01.526547: train_loss -0.7703 
2025-02-27 06:32:01.533062: val_loss -0.6439 
2025-02-27 06:32:01.536570: Pseudo dice [np.float32(0.8366), np.float32(0.7105), np.float32(0.8655)] 
2025-02-27 06:32:01.540076: Epoch time: 77.49 s 
2025-02-27 06:32:02.379418:  
2025-02-27 06:32:02.386020: Epoch 67 
2025-02-27 06:32:02.388558: Current learning rate: 0.00369 
2025-02-27 06:33:19.852313: train_loss -0.7689 
2025-02-27 06:33:19.859888: val_loss -0.6289 
2025-02-27 06:33:19.863453: Pseudo dice [np.float32(0.8048), np.float32(0.7262), np.float32(0.8641)] 
2025-02-27 06:33:19.867484: Epoch time: 77.47 s 
2025-02-27 06:33:20.500429:  
2025-02-27 06:33:20.505946: Epoch 68 
2025-02-27 06:33:20.509459: Current learning rate: 0.00359 
2025-02-27 06:34:38.146170: train_loss -0.77 
2025-02-27 06:34:38.153785: val_loss -0.6539 
2025-02-27 06:34:38.156368: Pseudo dice [np.float32(0.8429), np.float32(0.7227), np.float32(0.8748)] 
2025-02-27 06:34:38.160514: Epoch time: 77.65 s 
2025-02-27 06:34:38.805547:  
2025-02-27 06:34:38.811162: Epoch 69 
2025-02-27 06:34:38.814574: Current learning rate: 0.00349 
2025-02-27 06:35:56.314337: train_loss -0.7701 
2025-02-27 06:35:56.321977: val_loss -0.6541 
2025-02-27 06:35:56.325541: Pseudo dice [np.float32(0.8166), np.float32(0.6972), np.float32(0.8755)] 
2025-02-27 06:35:56.329067: Epoch time: 77.51 s 
2025-02-27 06:35:56.973638:  
2025-02-27 06:35:56.979152: Epoch 70 
2025-02-27 06:35:56.982663: Current learning rate: 0.00338 
2025-02-27 06:37:14.587097: train_loss -0.7715 
2025-02-27 06:37:14.594721: val_loss -0.663 
2025-02-27 06:37:14.597919: Pseudo dice [np.float32(0.8417), np.float32(0.7405), np.float32(0.8812)] 
2025-02-27 06:37:14.601027: Epoch time: 77.61 s 
2025-02-27 06:37:15.238244:  
2025-02-27 06:37:15.244282: Epoch 71 
2025-02-27 06:37:15.247334: Current learning rate: 0.00328 
2025-02-27 06:38:32.828252: train_loss -0.7686 
2025-02-27 06:38:32.835837: val_loss -0.6448 
2025-02-27 06:38:32.839380: Pseudo dice [np.float32(0.8244), np.float32(0.7437), np.float32(0.8702)] 
2025-02-27 06:38:32.843521: Epoch time: 77.59 s 
2025-02-27 06:38:32.846026: Yayy! New best EMA pseudo Dice: 0.8057000041007996 
2025-02-27 06:38:33.617900:  
2025-02-27 06:38:33.621945: Epoch 72 
2025-02-27 06:38:33.626006: Current learning rate: 0.00318 
2025-02-27 06:39:51.306604: train_loss -0.7686 
2025-02-27 06:39:51.313664: val_loss -0.6565 
2025-02-27 06:39:51.317206: Pseudo dice [np.float32(0.828), np.float32(0.7365), np.float32(0.87)] 
2025-02-27 06:39:51.320730: Epoch time: 77.69 s 
2025-02-27 06:39:51.324265: Yayy! New best EMA pseudo Dice: 0.8062999844551086 
2025-02-27 06:39:52.130722:  
2025-02-27 06:39:52.137331: Epoch 73 
2025-02-27 06:39:52.139879: Current learning rate: 0.00308 
2025-02-27 06:41:09.667605: train_loss -0.77 
2025-02-27 06:41:09.675175: val_loss -0.6482 
2025-02-27 06:41:09.678721: Pseudo dice [np.float32(0.8398), np.float32(0.7176), np.float32(0.869)] 
2025-02-27 06:41:09.685788: Epoch time: 77.54 s 
2025-02-27 06:41:09.689825: Yayy! New best EMA pseudo Dice: 0.8065000176429749 
2025-02-27 06:41:10.463649:  
2025-02-27 06:41:10.469186: Epoch 74 
2025-02-27 06:41:10.472696: Current learning rate: 0.00297 
2025-02-27 06:42:27.792583: train_loss -0.7703 
2025-02-27 06:42:27.800103: val_loss -0.6461 
2025-02-27 06:42:27.805114: Pseudo dice [np.float32(0.8132), np.float32(0.7346), np.float32(0.8629)] 
2025-02-27 06:42:27.810126: Epoch time: 77.33 s 
2025-02-27 06:42:28.633718:  
2025-02-27 06:42:28.638767: Epoch 75 
2025-02-27 06:42:28.641826: Current learning rate: 0.00287 
2025-02-27 06:43:45.853753: train_loss -0.7799 
2025-02-27 06:43:45.861271: val_loss -0.6426 
2025-02-27 06:43:45.865283: Pseudo dice [np.float32(0.8344), np.float32(0.6912), np.float32(0.8655)] 
2025-02-27 06:43:45.868793: Epoch time: 77.22 s 
2025-02-27 06:43:46.650455:  
2025-02-27 06:43:46.656493: Epoch 76 
2025-02-27 06:43:46.660025: Current learning rate: 0.00277 
2025-02-27 06:45:04.076389: train_loss -0.7776 
2025-02-27 06:45:04.082902: val_loss -0.618 
2025-02-27 06:45:04.087410: Pseudo dice [np.float32(0.8262), np.float32(0.6978), np.float32(0.8723)] 
2025-02-27 06:45:04.090417: Epoch time: 77.43 s 
2025-02-27 06:45:04.733260:  
2025-02-27 06:45:04.740960: Epoch 77 
2025-02-27 06:45:04.744002: Current learning rate: 0.00266 
2025-02-27 06:46:22.290569: train_loss -0.7776 
2025-02-27 06:46:22.297084: val_loss -0.629 
2025-02-27 06:46:22.300592: Pseudo dice [np.float32(0.8292), np.float32(0.6983), np.float32(0.8625)] 
2025-02-27 06:46:22.304603: Epoch time: 77.56 s 
2025-02-27 06:46:22.965237:  
2025-02-27 06:46:22.970780: Epoch 78 
2025-02-27 06:46:22.974337: Current learning rate: 0.00256 
2025-02-27 06:47:40.596780: train_loss -0.7726 
2025-02-27 06:47:40.604300: val_loss -0.6396 
2025-02-27 06:47:40.607809: Pseudo dice [np.float32(0.8424), np.float32(0.7215), np.float32(0.8626)] 
2025-02-27 06:47:40.610824: Epoch time: 77.63 s 
2025-02-27 06:47:41.244649:  
2025-02-27 06:47:41.248663: Epoch 79 
2025-02-27 06:47:41.252672: Current learning rate: 0.00245 
2025-02-27 06:48:58.802851: train_loss -0.7795 
2025-02-27 06:48:58.811424: val_loss -0.6278 
2025-02-27 06:48:58.815951: Pseudo dice [np.float32(0.8273), np.float32(0.7126), np.float32(0.8524)] 
2025-02-27 06:48:58.819543: Epoch time: 77.56 s 
2025-02-27 06:48:59.444437:  
2025-02-27 06:48:59.449271: Epoch 80 
2025-02-27 06:48:59.452780: Current learning rate: 0.00235 
2025-02-27 06:50:17.252924: train_loss -0.7752 
2025-02-27 06:50:17.260031: val_loss -0.6114 
2025-02-27 06:50:17.263572: Pseudo dice [np.float32(0.8261), np.float32(0.708), np.float32(0.8697)] 
2025-02-27 06:50:17.266618: Epoch time: 77.81 s 
2025-02-27 06:50:17.892874:  
2025-02-27 06:50:17.898407: Epoch 81 
2025-02-27 06:50:17.901428: Current learning rate: 0.00224 
2025-02-27 06:51:35.567100: train_loss -0.7804 
2025-02-27 06:51:35.576118: val_loss -0.6431 
2025-02-27 06:51:35.581133: Pseudo dice [np.float32(0.8323), np.float32(0.7367), np.float32(0.8542)] 
2025-02-27 06:51:35.585641: Epoch time: 77.68 s 
2025-02-27 06:51:36.418256:  
2025-02-27 06:51:36.424324: Epoch 82 
2025-02-27 06:51:36.427383: Current learning rate: 0.00214 
2025-02-27 06:52:53.993283: train_loss -0.7827 
2025-02-27 06:52:54.001810: val_loss -0.6286 
2025-02-27 06:52:54.006379: Pseudo dice [np.float32(0.8228), np.float32(0.6738), np.float32(0.8633)] 
2025-02-27 06:52:54.010977: Epoch time: 77.58 s 
2025-02-27 06:52:54.624221:  
2025-02-27 06:52:54.629234: Epoch 83 
2025-02-27 06:52:54.632242: Current learning rate: 0.00203 
2025-02-27 06:54:11.970664: train_loss -0.7826 
2025-02-27 06:54:11.977894: val_loss -0.6196 
2025-02-27 06:54:11.981913: Pseudo dice [np.float32(0.8312), np.float32(0.6975), np.float32(0.8578)] 
2025-02-27 06:54:11.985577: Epoch time: 77.35 s 
2025-02-27 06:54:12.596946:  
2025-02-27 06:54:12.602993: Epoch 84 
2025-02-27 06:54:12.606516: Current learning rate: 0.00192 
2025-02-27 06:55:30.117932: train_loss -0.7801 
2025-02-27 06:55:30.125515: val_loss -0.6553 
2025-02-27 06:55:30.129575: Pseudo dice [np.float32(0.8329), np.float32(0.7258), np.float32(0.8688)] 
2025-02-27 06:55:30.133125: Epoch time: 77.52 s 
2025-02-27 06:55:30.730604:  
2025-02-27 06:55:30.736119: Epoch 85 
2025-02-27 06:55:30.739632: Current learning rate: 0.00181 
2025-02-27 06:56:48.045692: train_loss -0.7807 
2025-02-27 06:56:48.053210: val_loss -0.6411 
2025-02-27 06:56:48.057720: Pseudo dice [np.float32(0.8329), np.float32(0.7172), np.float32(0.8579)] 
2025-02-27 06:56:48.060729: Epoch time: 77.32 s 
2025-02-27 06:56:48.704390:  
2025-02-27 06:56:48.711013: Epoch 86 
2025-02-27 06:56:48.714564: Current learning rate: 0.0017 
2025-02-27 06:58:06.459139: train_loss -0.782 
2025-02-27 06:58:06.466657: val_loss -0.6338 
2025-02-27 06:58:06.470665: Pseudo dice [np.float32(0.8202), np.float32(0.6846), np.float32(0.8706)] 
2025-02-27 06:58:06.473198: Epoch time: 77.75 s 
2025-02-27 06:58:07.095793:  
2025-02-27 06:58:07.102307: Epoch 87 
2025-02-27 06:58:07.105816: Current learning rate: 0.00159 
2025-02-27 06:59:24.713804: train_loss -0.7825 
2025-02-27 06:59:24.721942: val_loss -0.6276 
2025-02-27 06:59:24.725985: Pseudo dice [np.float32(0.8334), np.float32(0.7139), np.float32(0.873)] 
2025-02-27 06:59:24.729551: Epoch time: 77.62 s 
2025-02-27 06:59:25.326468:  
2025-02-27 06:59:25.332000: Epoch 88 
2025-02-27 06:59:25.335537: Current learning rate: 0.00148 
2025-02-27 07:00:43.037209: train_loss -0.7775 
2025-02-27 07:00:43.044305: val_loss -0.6482 
2025-02-27 07:00:43.050860: Pseudo dice [np.float32(0.8373), np.float32(0.713), np.float32(0.8645)] 
2025-02-27 07:00:43.055907: Epoch time: 77.71 s 
2025-02-27 07:00:43.667843:  
2025-02-27 07:00:43.674381: Epoch 89 
2025-02-27 07:00:43.679946: Current learning rate: 0.00137 
2025-02-27 07:02:01.270959: train_loss -0.7786 
2025-02-27 07:02:01.279577: val_loss -0.6488 
2025-02-27 07:02:01.283136: Pseudo dice [np.float32(0.8258), np.float32(0.7161), np.float32(0.8701)] 
2025-02-27 07:02:01.286183: Epoch time: 77.6 s 
2025-02-27 07:02:01.894333:  
2025-02-27 07:02:01.899870: Epoch 90 
2025-02-27 07:02:01.903901: Current learning rate: 0.00126 
2025-02-27 07:03:19.479684: train_loss -0.7894 
2025-02-27 07:03:19.487263: val_loss -0.6365 
2025-02-27 07:03:19.490296: Pseudo dice [np.float32(0.8322), np.float32(0.7122), np.float32(0.8605)] 
2025-02-27 07:03:19.495345: Epoch time: 77.59 s 
2025-02-27 07:03:20.280339:  
2025-02-27 07:03:20.286446: Epoch 91 
2025-02-27 07:03:20.289490: Current learning rate: 0.00115 
2025-02-27 07:04:37.829690: train_loss -0.7862 
2025-02-27 07:04:37.838373: val_loss -0.6436 
2025-02-27 07:04:37.842437: Pseudo dice [np.float32(0.8344), np.float32(0.7194), np.float32(0.858)] 
2025-02-27 07:04:37.845474: Epoch time: 77.55 s 
2025-02-27 07:04:38.495460:  
2025-02-27 07:04:38.501017: Epoch 92 
2025-02-27 07:04:38.504701: Current learning rate: 0.00103 
2025-02-27 07:05:56.396188: train_loss -0.7833 
2025-02-27 07:05:56.402286: val_loss -0.652 
2025-02-27 07:05:56.409513: Pseudo dice [np.float32(0.8378), np.float32(0.7019), np.float32(0.871)] 
2025-02-27 07:05:56.412560: Epoch time: 77.9 s 
2025-02-27 07:05:57.006520:  
2025-02-27 07:05:57.014108: Epoch 93 
2025-02-27 07:05:57.017682: Current learning rate: 0.00091 
2025-02-27 07:07:14.752546: train_loss -0.7836 
2025-02-27 07:07:14.760065: val_loss -0.6424 
2025-02-27 07:07:14.763573: Pseudo dice [np.float32(0.8438), np.float32(0.7211), np.float32(0.8819)] 
2025-02-27 07:07:14.767583: Epoch time: 77.75 s 
2025-02-27 07:07:15.379843:  
2025-02-27 07:07:15.385409: Epoch 94 
2025-02-27 07:07:15.387966: Current learning rate: 0.00079 
2025-02-27 07:08:33.062713: train_loss -0.7801 
2025-02-27 07:08:33.070228: val_loss -0.6711 
2025-02-27 07:08:33.074235: Pseudo dice [np.float32(0.8361), np.float32(0.7333), np.float32(0.8761)] 
2025-02-27 07:08:33.077750: Epoch time: 77.68 s 
2025-02-27 07:08:33.678938:  
2025-02-27 07:08:33.685014: Epoch 95 
2025-02-27 07:08:33.688060: Current learning rate: 0.00067 
2025-02-27 07:09:51.377769: train_loss -0.7807 
2025-02-27 07:09:51.385288: val_loss -0.6389 
2025-02-27 07:09:51.389300: Pseudo dice [np.float32(0.8406), np.float32(0.6705), np.float32(0.8706)] 
2025-02-27 07:09:51.391807: Epoch time: 77.7 s 
2025-02-27 07:09:51.986284:  
2025-02-27 07:09:51.990810: Epoch 96 
2025-02-27 07:09:51.994379: Current learning rate: 0.00055 
2025-02-27 07:11:09.560655: train_loss -0.7884 
2025-02-27 07:11:09.567175: val_loss -0.6238 
2025-02-27 07:11:09.571182: Pseudo dice [np.float32(0.8256), np.float32(0.6992), np.float32(0.8677)] 
2025-02-27 07:11:09.574694: Epoch time: 77.57 s 
2025-02-27 07:11:10.184447:  
2025-02-27 07:11:10.189459: Epoch 97 
2025-02-27 07:11:10.192968: Current learning rate: 0.00043 
2025-02-27 07:12:27.866479: train_loss -0.7881 
2025-02-27 07:12:27.873636: val_loss -0.6434 
2025-02-27 07:12:27.877678: Pseudo dice [np.float32(0.8286), np.float32(0.736), np.float32(0.87)] 
2025-02-27 07:12:27.881226: Epoch time: 77.68 s 
2025-02-27 07:12:28.507480:  
2025-02-27 07:12:28.512491: Epoch 98 
2025-02-27 07:12:28.516001: Current learning rate: 0.0003 
2025-02-27 07:13:46.177263: train_loss -0.7846 
2025-02-27 07:13:46.184827: val_loss -0.6391 
2025-02-27 07:13:46.188873: Pseudo dice [np.float32(0.8289), np.float32(0.715), np.float32(0.8711)] 
2025-02-27 07:13:46.192411: Epoch time: 77.67 s 
2025-02-27 07:13:46.977147:  
2025-02-27 07:13:46.982176: Epoch 99 
2025-02-27 07:13:46.985790: Current learning rate: 0.00016 
2025-02-27 07:15:04.772073: train_loss -0.785 
2025-02-27 07:15:04.780165: val_loss -0.6438 
2025-02-27 07:15:04.784212: Pseudo dice [np.float32(0.8272), np.float32(0.7177), np.float32(0.8714)] 
2025-02-27 07:15:04.788263: Epoch time: 77.8 s 
2025-02-27 07:15:05.646011: Training done. 
2025-02-27 07:15:05.676523: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-02-27 07:15:05.690525: The split file contains 5 splits. 
2025-02-27 07:15:05.697524: Desired fold for training: 0 
2025-02-27 07:15:05.703524: This split has 387 training and 97 validation cases. 
2025-02-27 07:15:05.710524: predicting BRATS_010 
2025-02-27 07:15:05.718526: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2025-02-27 07:15:07.799298: predicting BRATS_011 
2025-02-27 07:15:07.812299: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2025-02-27 07:15:09.190741: predicting BRATS_012 
2025-02-27 07:15:09.201741: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-02-27 07:15:10.605381: predicting BRATS_018 
2025-02-27 07:15:10.618382: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2025-02-27 07:15:11.992266: predicting BRATS_020 
2025-02-27 07:15:12.007265: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2025-02-27 07:15:13.382515: predicting BRATS_028 
2025-02-27 07:15:13.394516: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-02-27 07:15:14.778467: predicting BRATS_029 
2025-02-27 07:15:14.792467: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-02-27 07:15:16.187447: predicting BRATS_032 
2025-02-27 07:15:16.204447: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2025-02-27 07:15:17.575123: predicting BRATS_034 
2025-02-27 07:15:17.588124: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2025-02-27 07:15:18.995788: predicting BRATS_041 
2025-02-27 07:15:19.008792: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2025-02-27 07:15:20.373972: predicting BRATS_042 
2025-02-27 07:15:20.387975: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2025-02-27 07:15:21.750649: predicting BRATS_047 
2025-02-27 07:15:21.764157: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-02-27 07:15:23.159891: predicting BRATS_049 
2025-02-27 07:15:23.176399: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-02-27 07:15:24.542118: predicting BRATS_053 
2025-02-27 07:15:24.554121: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-02-27 07:15:25.938802: predicting BRATS_056 
2025-02-27 07:15:25.953809: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-02-27 07:15:27.319616: predicting BRATS_057 
2025-02-27 07:15:27.331616: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-02-27 07:15:28.712440: predicting BRATS_067 
2025-02-27 07:15:28.725441: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-02-27 07:15:30.130301: predicting BRATS_069 
2025-02-27 07:15:30.144302: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-02-27 07:15:31.497466: predicting BRATS_085 
2025-02-27 07:15:31.511468: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2025-02-27 07:15:32.211201: predicting BRATS_086 
2025-02-27 07:15:32.224201: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2025-02-27 07:15:33.622565: predicting BRATS_088 
2025-02-27 07:15:33.636565: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2025-02-27 07:15:35.033572: predicting BRATS_091 
2025-02-27 07:15:35.048573: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-02-27 07:15:36.458681: predicting BRATS_098 
2025-02-27 07:15:36.471194: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2025-02-27 07:15:37.834639: predicting BRATS_100 
2025-02-27 07:15:37.847639: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-02-27 07:15:38.573081: predicting BRATS_101 
2025-02-27 07:15:38.587079: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-02-27 07:15:39.308468: predicting BRATS_102 
2025-02-27 07:15:39.321470: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2025-02-27 07:15:40.701292: predicting BRATS_104 
2025-02-27 07:15:40.714293: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2025-02-27 07:15:42.082213: predicting BRATS_111 
2025-02-27 07:15:42.096215: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2025-02-27 07:15:43.469840: predicting BRATS_116 
2025-02-27 07:15:43.483348: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2025-02-27 07:15:44.864943: predicting BRATS_135 
2025-02-27 07:15:44.879449: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-02-27 07:15:46.269104: predicting BRATS_136 
2025-02-27 07:15:46.284607: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-02-27 07:15:47.663409: predicting BRATS_138 
2025-02-27 07:15:47.675914: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2025-02-27 07:15:49.080436: predicting BRATS_145 
2025-02-27 07:15:49.094439: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2025-02-27 07:15:50.475726: predicting BRATS_149 
2025-02-27 07:15:50.489232: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2025-02-27 07:15:51.893105: predicting BRATS_155 
2025-02-27 07:15:51.907104: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-02-27 07:15:53.310119: predicting BRATS_157 
2025-02-27 07:15:53.323123: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-02-27 07:15:54.720494: predicting BRATS_158 
2025-02-27 07:15:54.733495: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-02-27 07:15:56.145761: predicting BRATS_159 
2025-02-27 07:15:56.158761: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-02-27 07:15:57.538584: predicting BRATS_163 
2025-02-27 07:15:57.552585: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-02-27 07:15:58.936140: predicting BRATS_164 
2025-02-27 07:15:58.949142: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2025-02-27 07:16:00.311678: predicting BRATS_169 
2025-02-27 07:16:00.328677: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2025-02-27 07:16:01.703409: predicting BRATS_176 
2025-02-27 07:16:01.715410: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-02-27 07:16:03.101177: predicting BRATS_181 
2025-02-27 07:16:03.113178: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2025-02-27 07:16:04.507611: predicting BRATS_183 
2025-02-27 07:16:04.525612: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-02-27 07:16:05.898603: predicting BRATS_184 
2025-02-27 07:16:05.912603: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-02-27 07:16:07.286391: predicting BRATS_187 
2025-02-27 07:16:07.297901: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-02-27 07:16:08.661427: predicting BRATS_192 
2025-02-27 07:16:08.675431: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2025-02-27 07:16:10.030025: predicting BRATS_198 
2025-02-27 07:16:10.043026: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-02-27 07:16:11.407373: predicting BRATS_207 
2025-02-27 07:16:11.422374: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-02-27 07:16:12.808478: predicting BRATS_208 
2025-02-27 07:16:12.826478: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-02-27 07:16:14.196150: predicting BRATS_218 
2025-02-27 07:16:14.211149: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-02-27 07:16:15.595110: predicting BRATS_220 
2025-02-27 07:16:15.609113: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2025-02-27 07:16:16.972523: predicting BRATS_224 
2025-02-27 07:16:16.986531: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2025-02-27 07:16:18.379555: predicting BRATS_230 
2025-02-27 07:16:18.393559: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2025-02-27 07:16:19.751037: predicting BRATS_271 
2025-02-27 07:16:19.764037: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2025-02-27 07:16:21.140951: predicting BRATS_282 
2025-02-27 07:16:21.155952: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2025-02-27 07:16:22.518480: predicting BRATS_284 
2025-02-27 07:16:22.535480: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2025-02-27 07:16:23.900707: predicting BRATS_287 
2025-02-27 07:16:23.912709: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-02-27 07:16:25.323802: predicting BRATS_290 
2025-02-27 07:16:25.337804: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2025-02-27 07:16:26.697924: predicting BRATS_291 
2025-02-27 07:16:26.710433: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-02-27 07:16:28.095877: predicting BRATS_292 
2025-02-27 07:16:28.109384: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2025-02-27 07:16:29.477104: predicting BRATS_293 
2025-02-27 07:16:29.490111: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2025-02-27 07:16:30.901015: predicting BRATS_300 
2025-02-27 07:16:30.915525: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2025-02-27 07:16:32.316604: predicting BRATS_305 
2025-02-27 07:16:32.330604: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2025-02-27 07:16:33.745284: predicting BRATS_311 
2025-02-27 07:16:33.760284: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2025-02-27 07:16:35.167207: predicting BRATS_314 
2025-02-27 07:16:35.183210: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2025-02-27 07:16:36.554498: predicting BRATS_321 
2025-02-27 07:16:36.568500: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-02-27 07:16:37.941547: predicting BRATS_328 
2025-02-27 07:16:37.953546: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2025-02-27 07:16:38.677010: predicting BRATS_329 
2025-02-27 07:16:38.693009: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2025-02-27 07:16:40.083590: predicting BRATS_335 
2025-02-27 07:16:40.096594: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2025-02-27 07:16:41.490172: predicting BRATS_343 
2025-02-27 07:16:41.504177: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2025-02-27 07:16:42.881884: predicting BRATS_350 
2025-02-27 07:16:42.896886: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2025-02-27 07:16:43.622380: predicting BRATS_351 
2025-02-27 07:16:43.635383: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2025-02-27 07:16:44.359358: predicting BRATS_356 
2025-02-27 07:16:44.371359: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2025-02-27 07:16:45.106928: predicting BRATS_366 
2025-02-27 07:16:45.119439: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2025-02-27 07:16:46.508603: predicting BRATS_367 
2025-02-27 07:16:46.523110: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2025-02-27 07:16:47.917857: predicting BRATS_374 
2025-02-27 07:16:47.930858: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2025-02-27 07:16:49.324809: predicting BRATS_376 
2025-02-27 07:16:49.337810: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2025-02-27 07:16:50.723875: predicting BRATS_377 
2025-02-27 07:16:50.737877: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2025-02-27 07:16:52.121586: predicting BRATS_378 
2025-02-27 07:16:52.135588: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2025-02-27 07:16:53.500302: predicting BRATS_379 
2025-02-27 07:16:53.517305: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2025-02-27 07:16:54.890581: predicting BRATS_384 
2025-02-27 07:16:54.904584: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2025-02-27 07:16:56.286417: predicting BRATS_386 
2025-02-27 07:16:56.301419: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-02-27 07:16:57.675128: predicting BRATS_394 
2025-02-27 07:16:57.688128: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-02-27 07:16:59.048253: predicting BRATS_398 
2025-02-27 07:16:59.062255: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2025-02-27 07:17:00.448492: predicting BRATS_400 
2025-02-27 07:17:00.463491: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2025-02-27 07:17:01.848524: predicting BRATS_432 
2025-02-27 07:17:01.864525: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2025-02-27 07:17:03.256962: predicting BRATS_437 
2025-02-27 07:17:03.271971: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-02-27 07:17:04.640643: predicting BRATS_445 
2025-02-27 07:17:04.652642: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2025-02-27 07:17:06.015381: predicting BRATS_446 
2025-02-27 07:17:06.028892: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-02-27 07:17:07.440059: predicting BRATS_450 
2025-02-27 07:17:07.453058: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2025-02-27 07:17:08.848325: predicting BRATS_452 
2025-02-27 07:17:08.861325: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2025-02-27 07:17:10.252368: predicting BRATS_460 
2025-02-27 07:17:10.266368: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2025-02-27 07:17:11.659873: predicting BRATS_470 
2025-02-27 07:17:11.673876: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-02-27 07:17:13.039096: predicting BRATS_472 
2025-02-27 07:17:13.053097: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2025-02-27 07:17:14.439404: predicting BRATS_473 
2025-02-27 07:17:14.454405: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2025-02-27 07:17:15.175938: predicting BRATS_482 
2025-02-27 07:17:15.187938: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2025-02-27 07:17:23.776322: Validation complete 
2025-02-27 07:17:23.782323: Mean Validation Dice:  0.7268423186581413 
