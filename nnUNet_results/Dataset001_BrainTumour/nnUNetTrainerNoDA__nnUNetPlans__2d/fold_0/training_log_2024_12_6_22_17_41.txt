
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-06 22:17:41.126760: do_dummy_2d_data_aug: False 
2024-12-06 22:17:41.132760: Creating new 5-fold cross-validation split... 
2024-12-06 22:17:41.138760: Desired fold for training: 0 
2024-12-06 22:17:41.141113: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 105, 'patch_size': [192, 160], 'median_image_size_in_voxels': [169.0, 138.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2024-12-06 22:18:12.140544: unpacking dataset... 
2024-12-06 22:18:12.357972: unpacking done... 
2024-12-06 22:18:13.900744:  
2024-12-06 22:18:13.904752: Epoch 0 
2024-12-06 22:18:13.908260: Current learning rate: 0.01 
2024-12-06 22:18:50.667049: train_loss -0.3257 
2024-12-06 22:18:50.673073: val_loss -0.6176 
2024-12-06 22:18:50.677089: Pseudo dice [np.float32(0.7525), np.float32(0.5818), np.float32(0.8111)] 
2024-12-06 22:18:50.679596: Epoch time: 36.77 s 
2024-12-06 22:18:50.683112: Yayy! New best EMA pseudo Dice: 0.7150999903678894 
2024-12-06 22:18:51.439185:  
2024-12-06 22:18:51.446227: Epoch 1 
2024-12-06 22:18:51.450237: Current learning rate: 0.00991 
2024-12-06 22:19:24.173108: train_loss -0.706 
2024-12-06 22:19:24.180211: val_loss -0.6913 
2024-12-06 22:19:24.183284: Pseudo dice [np.float32(0.7945), np.float32(0.6602), np.float32(0.8464)] 
2024-12-06 22:19:24.186852: Epoch time: 32.73 s 
2024-12-06 22:19:24.190773: Yayy! New best EMA pseudo Dice: 0.720300018787384 
2024-12-06 22:19:24.915540:  
2024-12-06 22:19:24.920551: Epoch 2 
2024-12-06 22:19:24.923056: Current learning rate: 0.00982 
2024-12-06 22:19:57.523012: train_loss -0.7528 
2024-12-06 22:19:57.528527: val_loss -0.7144 
2024-12-06 22:19:57.532037: Pseudo dice [np.float32(0.8044), np.float32(0.6937), np.float32(0.8518)] 
2024-12-06 22:19:57.535543: Epoch time: 32.61 s 
2024-12-06 22:19:57.538555: Yayy! New best EMA pseudo Dice: 0.7265999913215637 
2024-12-06 22:19:58.249933:  
2024-12-06 22:19:58.255951: Epoch 3 
2024-12-06 22:19:58.258456: Current learning rate: 0.00973 
2024-12-06 22:20:30.750169: train_loss -0.772 
2024-12-06 22:20:30.756179: val_loss -0.727 
2024-12-06 22:20:30.759190: Pseudo dice [np.float32(0.8133), np.float32(0.7084), np.float32(0.8565)] 
2024-12-06 22:20:30.761699: Epoch time: 32.5 s 
2024-12-06 22:20:30.765212: Yayy! New best EMA pseudo Dice: 0.7332000136375427 
2024-12-06 22:20:31.463312:  
2024-12-06 22:20:31.468343: Epoch 4 
2024-12-06 22:20:31.471877: Current learning rate: 0.00964 
2024-12-06 22:21:03.944510: train_loss -0.7873 
2024-12-06 22:21:03.951040: val_loss -0.7214 
2024-12-06 22:21:03.953551: Pseudo dice [np.float32(0.8088), np.float32(0.6929), np.float32(0.8605)] 
2024-12-06 22:21:03.957058: Epoch time: 32.48 s 
2024-12-06 22:21:03.960069: Yayy! New best EMA pseudo Dice: 0.7386000156402588 
2024-12-06 22:21:04.671545:  
2024-12-06 22:21:04.675619: Epoch 5 
2024-12-06 22:21:04.679720: Current learning rate: 0.00955 
2024-12-06 22:21:37.408359: train_loss -0.7947 
2024-12-06 22:21:37.416474: val_loss -0.7204 
2024-12-06 22:21:37.421023: Pseudo dice [np.float32(0.81), np.float32(0.6947), np.float32(0.8572)] 
2024-12-06 22:21:37.424102: Epoch time: 32.74 s 
2024-12-06 22:21:37.426640: Yayy! New best EMA pseudo Dice: 0.7434999942779541 
2024-12-06 22:21:38.268803:  
2024-12-06 22:21:38.274356: Epoch 6 
2024-12-06 22:21:38.277952: Current learning rate: 0.00946 
2024-12-06 22:22:10.549164: train_loss -0.8034 
2024-12-06 22:22:10.554691: val_loss -0.7252 
2024-12-06 22:22:10.559716: Pseudo dice [np.float32(0.8119), np.float32(0.6963), np.float32(0.8601)] 
2024-12-06 22:22:10.564732: Epoch time: 32.28 s 
2024-12-06 22:22:10.569245: Yayy! New best EMA pseudo Dice: 0.7480999827384949 
2024-12-06 22:22:11.219714:  
2024-12-06 22:22:11.224736: Epoch 7 
2024-12-06 22:22:11.227544: Current learning rate: 0.00937 
2024-12-06 22:22:43.354874: train_loss -0.8109 
2024-12-06 22:22:43.361010: val_loss -0.7244 
2024-12-06 22:22:43.366111: Pseudo dice [np.float32(0.8159), np.float32(0.692), np.float32(0.862)] 
2024-12-06 22:22:43.371225: Epoch time: 32.14 s 
2024-12-06 22:22:43.376802: Yayy! New best EMA pseudo Dice: 0.7523000240325928 
2024-12-06 22:22:44.061757:  
2024-12-06 22:22:44.067295: Epoch 8 
2024-12-06 22:22:44.069834: Current learning rate: 0.00928 
2024-12-06 22:23:16.178576: train_loss -0.8134 
2024-12-06 22:23:16.186241: val_loss -0.7295 
2024-12-06 22:23:16.191849: Pseudo dice [np.float32(0.8135), np.float32(0.705), np.float32(0.8661)] 
2024-12-06 22:23:16.196954: Epoch time: 32.12 s 
2024-12-06 22:23:16.202544: Yayy! New best EMA pseudo Dice: 0.756600022315979 
2024-12-06 22:23:16.871943:  
2024-12-06 22:23:16.877508: Epoch 9 
2024-12-06 22:23:16.880570: Current learning rate: 0.00919 
2024-12-06 22:23:49.126845: train_loss -0.8188 
2024-12-06 22:23:49.132930: val_loss -0.7345 
2024-12-06 22:23:49.138526: Pseudo dice [np.float32(0.8188), np.float32(0.7055), np.float32(0.868)] 
2024-12-06 22:23:49.142771: Epoch time: 32.25 s 
2024-12-06 22:23:49.145843: Yayy! New best EMA pseudo Dice: 0.7605999708175659 
2024-12-06 22:23:49.825033:  
2024-12-06 22:23:49.831048: Epoch 10 
2024-12-06 22:23:49.834557: Current learning rate: 0.0091 
2024-12-06 22:24:22.158453: train_loss -0.8217 
2024-12-06 22:24:22.164986: val_loss -0.7367 
2024-12-06 22:24:22.171511: Pseudo dice [np.float32(0.8194), np.float32(0.7131), np.float32(0.8683)] 
2024-12-06 22:24:22.176598: Epoch time: 32.33 s 
2024-12-06 22:24:22.181191: Yayy! New best EMA pseudo Dice: 0.7645999789237976 
2024-12-06 22:24:22.884055:  
2024-12-06 22:24:22.889568: Epoch 11 
2024-12-06 22:24:22.892073: Current learning rate: 0.009 
2024-12-06 22:24:55.175700: train_loss -0.8248 
2024-12-06 22:24:55.182715: val_loss -0.725 
2024-12-06 22:24:55.185723: Pseudo dice [np.float32(0.815), np.float32(0.6897), np.float32(0.8687)] 
2024-12-06 22:24:55.190734: Epoch time: 32.29 s 
2024-12-06 22:24:55.195247: Yayy! New best EMA pseudo Dice: 0.767300009727478 
2024-12-06 22:24:55.925556:  
2024-12-06 22:24:55.931612: Epoch 12 
2024-12-06 22:24:55.934687: Current learning rate: 0.00891 
2024-12-06 22:25:28.237423: train_loss -0.829 
2024-12-06 22:25:28.243677: val_loss -0.7325 
2024-12-06 22:25:28.248693: Pseudo dice [np.float32(0.8208), np.float32(0.7009), np.float32(0.8645)] 
2024-12-06 22:25:28.252202: Epoch time: 32.31 s 
2024-12-06 22:25:28.255210: Yayy! New best EMA pseudo Dice: 0.7700999975204468 
2024-12-06 22:25:29.053029:  
2024-12-06 22:25:29.058532: Epoch 13 
2024-12-06 22:25:29.062043: Current learning rate: 0.00882 
2024-12-06 22:26:01.348848: train_loss -0.832 
2024-12-06 22:26:01.356228: val_loss -0.7321 
2024-12-06 22:26:01.361223: Pseudo dice [np.float32(0.8184), np.float32(0.7036), np.float32(0.8672)] 
2024-12-06 22:26:01.364788: Epoch time: 32.3 s 
2024-12-06 22:26:01.368799: Yayy! New best EMA pseudo Dice: 0.7727000117301941 
2024-12-06 22:26:02.018322:  
2024-12-06 22:26:02.023859: Epoch 14 
2024-12-06 22:26:02.026893: Current learning rate: 0.00873 
2024-12-06 22:26:34.337337: train_loss -0.8343 
2024-12-06 22:26:34.342923: val_loss -0.7326 
2024-12-06 22:26:34.348944: Pseudo dice [np.float32(0.8212), np.float32(0.7008), np.float32(0.8652)] 
2024-12-06 22:26:34.352963: Epoch time: 32.32 s 
2024-12-06 22:26:34.356482: Yayy! New best EMA pseudo Dice: 0.7749999761581421 
2024-12-06 22:26:35.014443:  
2024-12-06 22:26:35.019463: Epoch 15 
2024-12-06 22:26:35.022979: Current learning rate: 0.00864 
2024-12-06 22:27:07.314683: train_loss -0.8367 
2024-12-06 22:27:07.321308: val_loss -0.735 
2024-12-06 22:27:07.325897: Pseudo dice [np.float32(0.8177), np.float32(0.708), np.float32(0.8669)] 
2024-12-06 22:27:07.328982: Epoch time: 32.3 s 
2024-12-06 22:27:07.333030: Yayy! New best EMA pseudo Dice: 0.7773000001907349 
2024-12-06 22:27:08.008822:  
2024-12-06 22:27:08.013842: Epoch 16 
2024-12-06 22:27:08.017357: Current learning rate: 0.00855 
2024-12-06 22:27:40.301212: train_loss -0.8385 
2024-12-06 22:27:40.309692: val_loss -0.7408 
2024-12-06 22:27:40.314555: Pseudo dice [np.float32(0.8208), np.float32(0.7209), np.float32(0.8701)] 
2024-12-06 22:27:40.319065: Epoch time: 32.29 s 
2024-12-06 22:27:40.323087: Yayy! New best EMA pseudo Dice: 0.7799000144004822 
2024-12-06 22:27:40.993125:  
2024-12-06 22:27:40.998680: Epoch 17 
2024-12-06 22:27:41.002723: Current learning rate: 0.00846 
2024-12-06 22:28:13.287645: train_loss -0.84 
2024-12-06 22:28:13.294404: val_loss -0.7333 
2024-12-06 22:28:13.299445: Pseudo dice [np.float32(0.8178), np.float32(0.7134), np.float32(0.8613)] 
2024-12-06 22:28:13.302486: Epoch time: 32.29 s 
2024-12-06 22:28:13.307088: Yayy! New best EMA pseudo Dice: 0.7817000150680542 
2024-12-06 22:28:14.044179:  
2024-12-06 22:28:14.050210: Epoch 18 
2024-12-06 22:28:14.052855: Current learning rate: 0.00836 
2024-12-06 22:28:46.331583: train_loss -0.8412 
2024-12-06 22:28:46.339186: val_loss -0.7259 
2024-12-06 22:28:46.344298: Pseudo dice [np.float32(0.8181), np.float32(0.6927), np.float32(0.8674)] 
2024-12-06 22:28:46.348874: Epoch time: 32.29 s 
2024-12-06 22:28:46.351916: Yayy! New best EMA pseudo Dice: 0.782800018787384 
2024-12-06 22:28:47.023281:  
2024-12-06 22:28:47.029386: Epoch 19 
2024-12-06 22:28:47.032892: Current learning rate: 0.00827 
2024-12-06 22:29:19.325548: train_loss -0.8425 
2024-12-06 22:29:19.332062: val_loss -0.7351 
2024-12-06 22:29:19.338079: Pseudo dice [np.float32(0.8204), np.float32(0.7103), np.float32(0.8648)] 
2024-12-06 22:29:19.342091: Epoch time: 32.3 s 
2024-12-06 22:29:19.346954: Yayy! New best EMA pseudo Dice: 0.7843999862670898 
2024-12-06 22:29:20.003669:  
2024-12-06 22:29:20.008683: Epoch 20 
2024-12-06 22:29:20.012132: Current learning rate: 0.00818 
2024-12-06 22:29:52.349927: train_loss -0.8454 
2024-12-06 22:29:52.355936: val_loss -0.7313 
2024-12-06 22:29:52.360958: Pseudo dice [np.float32(0.818), np.float32(0.7062), np.float32(0.8636)] 
2024-12-06 22:29:52.364971: Epoch time: 32.35 s 
2024-12-06 22:29:52.369995: Yayy! New best EMA pseudo Dice: 0.7854999899864197 
2024-12-06 22:29:53.182523:  
2024-12-06 22:29:53.188555: Epoch 21 
2024-12-06 22:29:53.192603: Current learning rate: 0.00809 
2024-12-06 22:30:25.483386: train_loss -0.8459 
2024-12-06 22:30:25.489901: val_loss -0.7339 
2024-12-06 22:30:25.494922: Pseudo dice [np.float32(0.823), np.float32(0.7013), np.float32(0.8673)] 
2024-12-06 22:30:25.497428: Epoch time: 32.3 s 
2024-12-06 22:30:25.500788: Yayy! New best EMA pseudo Dice: 0.7867000102996826 
2024-12-06 22:30:26.139480:  
2024-12-06 22:30:26.144512: Epoch 22 
2024-12-06 22:30:26.148042: Current learning rate: 0.008 
2024-12-06 22:30:58.552574: train_loss -0.8471 
2024-12-06 22:30:58.559694: val_loss -0.7308 
2024-12-06 22:30:58.565841: Pseudo dice [np.float32(0.8188), np.float32(0.7055), np.float32(0.8647)] 
2024-12-06 22:30:58.571488: Epoch time: 32.41 s 
2024-12-06 22:30:58.577673: Yayy! New best EMA pseudo Dice: 0.7875999808311462 
2024-12-06 22:30:59.212538:  
2024-12-06 22:30:59.218596: Epoch 23 
2024-12-06 22:30:59.221650: Current learning rate: 0.0079 
2024-12-06 22:31:31.373313: train_loss -0.8466 
2024-12-06 22:31:31.378843: val_loss -0.7349 
2024-12-06 22:31:31.384529: Pseudo dice [np.float32(0.8221), np.float32(0.6987), np.float32(0.8707)] 
2024-12-06 22:31:31.389081: Epoch time: 32.16 s 
2024-12-06 22:31:31.393600: Yayy! New best EMA pseudo Dice: 0.7886000275611877 
2024-12-06 22:31:32.028415:  
2024-12-06 22:31:32.034569: Epoch 24 
2024-12-06 22:31:32.038080: Current learning rate: 0.00781 
2024-12-06 22:32:04.181004: train_loss -0.8485 
2024-12-06 22:32:04.187601: val_loss -0.7287 
2024-12-06 22:32:04.192199: Pseudo dice [np.float32(0.8217), np.float32(0.6968), np.float32(0.8622)] 
2024-12-06 22:32:04.197375: Epoch time: 32.15 s 
2024-12-06 22:32:04.200963: Yayy! New best EMA pseudo Dice: 0.7890999913215637 
2024-12-06 22:32:04.846172:  
2024-12-06 22:32:04.852243: Epoch 25 
2024-12-06 22:32:04.855807: Current learning rate: 0.00772 
2024-12-06 22:32:36.980145: train_loss -0.8488 
2024-12-06 22:32:36.985738: val_loss -0.7327 
2024-12-06 22:32:36.990304: Pseudo dice [np.float32(0.8205), np.float32(0.7057), np.float32(0.8638)] 
2024-12-06 22:32:36.995404: Epoch time: 32.13 s 
2024-12-06 22:32:36.999971: Yayy! New best EMA pseudo Dice: 0.789900004863739 
2024-12-06 22:32:37.644729:  
2024-12-06 22:32:37.649778: Epoch 26 
2024-12-06 22:32:37.653472: Current learning rate: 0.00763 
2024-12-06 22:33:09.812615: train_loss -0.8519 
2024-12-06 22:33:09.821079: val_loss -0.7336 
2024-12-06 22:33:09.826095: Pseudo dice [np.float32(0.8223), np.float32(0.7065), np.float32(0.8665)] 
2024-12-06 22:33:09.829607: Epoch time: 32.17 s 
2024-12-06 22:33:09.833620: Yayy! New best EMA pseudo Dice: 0.7907000184059143 
2024-12-06 22:33:10.478199:  
2024-12-06 22:33:10.482219: Epoch 27 
2024-12-06 22:33:10.486233: Current learning rate: 0.00753 
2024-12-06 22:33:42.652685: train_loss -0.8518 
2024-12-06 22:33:42.660223: val_loss -0.7269 
2024-12-06 22:33:42.664244: Pseudo dice [np.float32(0.8162), np.float32(0.7004), np.float32(0.8654)] 
2024-12-06 22:33:42.668262: Epoch time: 32.18 s 
2024-12-06 22:33:42.672779: Yayy! New best EMA pseudo Dice: 0.7910000085830688 
2024-12-06 22:33:43.310948:  
2024-12-06 22:33:43.316463: Epoch 28 
2024-12-06 22:33:43.318970: Current learning rate: 0.00744 
2024-12-06 22:34:15.474329: train_loss -0.8531 
2024-12-06 22:34:15.480858: val_loss -0.7309 
2024-12-06 22:34:15.485872: Pseudo dice [np.float32(0.8231), np.float32(0.6979), np.float32(0.8689)] 
2024-12-06 22:34:15.490888: Epoch time: 32.16 s 
2024-12-06 22:34:15.495903: Yayy! New best EMA pseudo Dice: 0.7915999889373779 
2024-12-06 22:34:16.279980:  
2024-12-06 22:34:16.285541: Epoch 29 
2024-12-06 22:34:16.289124: Current learning rate: 0.00735 
2024-12-06 22:34:48.441529: train_loss -0.8537 
2024-12-06 22:34:48.449163: val_loss -0.7296 
2024-12-06 22:34:48.453217: Pseudo dice [np.float32(0.8199), np.float32(0.7015), np.float32(0.8646)] 
2024-12-06 22:34:48.456774: Epoch time: 32.16 s 
2024-12-06 22:34:48.460310: Yayy! New best EMA pseudo Dice: 0.7919999957084656 
2024-12-06 22:34:49.117870:  
2024-12-06 22:34:49.123420: Epoch 30 
2024-12-06 22:34:49.126477: Current learning rate: 0.00725 
2024-12-06 22:35:21.269611: train_loss -0.8535 
2024-12-06 22:35:21.275178: val_loss -0.7319 
2024-12-06 22:35:21.280193: Pseudo dice [np.float32(0.8177), np.float32(0.706), np.float32(0.8682)] 
2024-12-06 22:35:21.285216: Epoch time: 32.15 s 
2024-12-06 22:35:21.288734: Yayy! New best EMA pseudo Dice: 0.7925000190734863 
2024-12-06 22:35:21.943740:  
2024-12-06 22:35:21.948802: Epoch 31 
2024-12-06 22:35:21.951852: Current learning rate: 0.00716 
2024-12-06 22:35:54.105595: train_loss -0.856 
2024-12-06 22:35:54.114628: val_loss -0.7351 
2024-12-06 22:35:54.119652: Pseudo dice [np.float32(0.8161), np.float32(0.7222), np.float32(0.8646)] 
2024-12-06 22:35:54.124168: Epoch time: 32.16 s 
2024-12-06 22:35:54.129203: Yayy! New best EMA pseudo Dice: 0.79339998960495 
2024-12-06 22:35:54.780599:  
2024-12-06 22:35:54.786611: Epoch 32 
2024-12-06 22:35:54.789623: Current learning rate: 0.00707 
2024-12-06 22:36:26.945945: train_loss -0.8547 
2024-12-06 22:36:26.952475: val_loss -0.7242 
2024-12-06 22:36:26.956528: Pseudo dice [np.float32(0.8124), np.float32(0.6999), np.float32(0.8626)] 
2024-12-06 22:36:26.961546: Epoch time: 32.17 s 
2024-12-06 22:36:27.515710:  
2024-12-06 22:36:27.521277: Epoch 33 
2024-12-06 22:36:27.525322: Current learning rate: 0.00697 
2024-12-06 22:36:59.664788: train_loss -0.8549 
2024-12-06 22:36:59.672456: val_loss -0.7305 
2024-12-06 22:36:59.677575: Pseudo dice [np.float32(0.8171), np.float32(0.7089), np.float32(0.8654)] 
2024-12-06 22:36:59.682154: Epoch time: 32.15 s 
2024-12-06 22:36:59.687277: Yayy! New best EMA pseudo Dice: 0.7936000227928162 
2024-12-06 22:37:00.336533:  
2024-12-06 22:37:00.342085: Epoch 34 
2024-12-06 22:37:00.345642: Current learning rate: 0.00688 
2024-12-06 22:37:32.505210: train_loss -0.8548 
2024-12-06 22:37:32.511734: val_loss -0.7325 
2024-12-06 22:37:32.517760: Pseudo dice [np.float32(0.8215), np.float32(0.7079), np.float32(0.8669)] 
2024-12-06 22:37:32.522782: Epoch time: 32.17 s 
2024-12-06 22:37:32.527804: Yayy! New best EMA pseudo Dice: 0.7940999865531921 
2024-12-06 22:37:33.177405:  
2024-12-06 22:37:33.182423: Epoch 35 
2024-12-06 22:37:33.185942: Current learning rate: 0.00679 
2024-12-06 22:38:05.338401: train_loss -0.8575 
2024-12-06 22:38:05.346615: val_loss -0.7356 
2024-12-06 22:38:05.351202: Pseudo dice [np.float32(0.8215), np.float32(0.7142), np.float32(0.8684)] 
2024-12-06 22:38:05.356002: Epoch time: 32.16 s 
2024-12-06 22:38:05.360062: Yayy! New best EMA pseudo Dice: 0.7947999835014343 
2024-12-06 22:38:06.164789:  
2024-12-06 22:38:06.169815: Epoch 36 
2024-12-06 22:38:06.172129: Current learning rate: 0.00669 
2024-12-06 22:38:38.326420: train_loss -0.858 
2024-12-06 22:38:38.332452: val_loss -0.7298 
2024-12-06 22:38:38.337473: Pseudo dice [np.float32(0.8154), np.float32(0.7089), np.float32(0.8645)] 
2024-12-06 22:38:38.343997: Epoch time: 32.16 s 
2024-12-06 22:38:38.350030: Yayy! New best EMA pseudo Dice: 0.7950000166893005 
2024-12-06 22:38:39.007401:  
2024-12-06 22:38:39.012415: Epoch 37 
2024-12-06 22:38:39.014921: Current learning rate: 0.0066 
2024-12-06 22:39:11.138632: train_loss -0.8578 
2024-12-06 22:39:11.144719: val_loss -0.7253 
2024-12-06 22:39:11.151289: Pseudo dice [np.float32(0.8179), np.float32(0.6908), np.float32(0.8665)] 
2024-12-06 22:39:11.157362: Epoch time: 32.13 s 
2024-12-06 22:39:11.729968:  
2024-12-06 22:39:11.735001: Epoch 38 
2024-12-06 22:39:11.738555: Current learning rate: 0.0065 
2024-12-06 22:39:43.883904: train_loss -0.8598 
2024-12-06 22:39:43.892996: val_loss -0.7263 
2024-12-06 22:39:43.898051: Pseudo dice [np.float32(0.817), np.float32(0.6999), np.float32(0.8623)] 
2024-12-06 22:39:43.901591: Epoch time: 32.15 s 
2024-12-06 22:39:44.463927:  
2024-12-06 22:39:44.468944: Epoch 39 
2024-12-06 22:39:44.471952: Current learning rate: 0.00641 
2024-12-06 22:40:16.644331: train_loss -0.8599 
2024-12-06 22:40:16.649464: val_loss -0.7338 
2024-12-06 22:40:16.655079: Pseudo dice [np.float32(0.8197), np.float32(0.7062), np.float32(0.8714)] 
2024-12-06 22:40:16.659096: Epoch time: 32.18 s 
2024-12-06 22:40:17.233652:  
2024-12-06 22:40:17.238667: Epoch 40 
2024-12-06 22:40:17.241675: Current learning rate: 0.00631 
2024-12-06 22:40:49.398923: train_loss -0.8596 
2024-12-06 22:40:49.405496: val_loss -0.7284 
2024-12-06 22:40:49.411559: Pseudo dice [np.float32(0.82), np.float32(0.6996), np.float32(0.8641)] 
2024-12-06 22:40:49.417123: Epoch time: 32.17 s 
2024-12-06 22:40:49.992028:  
2024-12-06 22:40:49.997600: Epoch 41 
2024-12-06 22:40:50.000143: Current learning rate: 0.00622 
2024-12-06 22:41:22.141921: train_loss -0.8615 
2024-12-06 22:41:22.148232: val_loss -0.7352 
2024-12-06 22:41:22.153843: Pseudo dice [np.float32(0.8242), np.float32(0.7099), np.float32(0.8679)] 
2024-12-06 22:41:22.157879: Epoch time: 32.15 s 
2024-12-06 22:41:22.162904: Yayy! New best EMA pseudo Dice: 0.7954999804496765 
2024-12-06 22:41:22.886440:  
2024-12-06 22:41:22.891956: Epoch 42 
2024-12-06 22:41:22.894461: Current learning rate: 0.00612 
2024-12-06 22:41:55.046488: train_loss -0.8608 
2024-12-06 22:41:55.054635: val_loss -0.7367 
2024-12-06 22:41:55.060220: Pseudo dice [np.float32(0.8215), np.float32(0.7126), np.float32(0.8693)] 
2024-12-06 22:41:55.064789: Epoch time: 32.16 s 
2024-12-06 22:41:55.070362: Yayy! New best EMA pseudo Dice: 0.7960000038146973 
2024-12-06 22:41:55.700078:  
2024-12-06 22:41:55.705657: Epoch 43 
2024-12-06 22:41:55.708207: Current learning rate: 0.00603 
2024-12-06 22:42:27.847058: train_loss -0.8635 
2024-12-06 22:42:27.853118: val_loss -0.7359 
2024-12-06 22:42:27.857163: Pseudo dice [np.float32(0.8195), np.float32(0.7147), np.float32(0.8691)] 
2024-12-06 22:42:27.861701: Epoch time: 32.15 s 
2024-12-06 22:42:27.866760: Yayy! New best EMA pseudo Dice: 0.7965999841690063 
2024-12-06 22:42:28.646706:  
2024-12-06 22:42:28.652286: Epoch 44 
2024-12-06 22:42:28.655342: Current learning rate: 0.00593 
2024-12-06 22:43:00.807212: train_loss -0.8622 
2024-12-06 22:43:00.814375: val_loss -0.7275 
2024-12-06 22:43:00.818937: Pseudo dice [np.float32(0.8124), np.float32(0.7077), np.float32(0.868)] 
2024-12-06 22:43:00.823019: Epoch time: 32.16 s 
2024-12-06 22:43:01.367196:  
2024-12-06 22:43:01.372206: Epoch 45 
2024-12-06 22:43:01.375715: Current learning rate: 0.00584 
2024-12-06 22:43:33.555725: train_loss -0.8627 
2024-12-06 22:43:33.561760: val_loss -0.7333 
2024-12-06 22:43:33.566298: Pseudo dice [np.float32(0.8194), np.float32(0.7097), np.float32(0.8672)] 
2024-12-06 22:43:33.570351: Epoch time: 32.19 s 
2024-12-06 22:43:33.575380: Yayy! New best EMA pseudo Dice: 0.7967000007629395 
2024-12-06 22:43:34.218358:  
2024-12-06 22:43:34.223891: Epoch 46 
2024-12-06 22:43:34.226396: Current learning rate: 0.00574 
2024-12-06 22:44:06.666931: train_loss -0.8651 
2024-12-06 22:44:06.674982: val_loss -0.7204 
2024-12-06 22:44:06.680003: Pseudo dice [np.float32(0.8166), np.float32(0.6834), np.float32(0.8649)] 
2024-12-06 22:44:06.685023: Epoch time: 32.45 s 
2024-12-06 22:44:07.210046:  
2024-12-06 22:44:07.215101: Epoch 47 
2024-12-06 22:44:07.217992: Current learning rate: 0.00565 
2024-12-06 22:44:39.460061: train_loss -0.8639 
2024-12-06 22:44:39.466081: val_loss -0.7261 
2024-12-06 22:44:39.468591: Pseudo dice [np.float32(0.8191), np.float32(0.6949), np.float32(0.8643)] 
2024-12-06 22:44:39.472603: Epoch time: 32.25 s 
2024-12-06 22:44:40.035131:  
2024-12-06 22:44:40.040707: Epoch 48 
2024-12-06 22:44:40.043252: Current learning rate: 0.00555 
2024-12-06 22:45:12.529060: train_loss -0.865 
2024-12-06 22:45:12.534904: val_loss -0.7309 
2024-12-06 22:45:12.538662: Pseudo dice [np.float32(0.8202), np.float32(0.7018), np.float32(0.8691)] 
2024-12-06 22:45:12.542178: Epoch time: 32.49 s 
2024-12-06 22:45:13.103138:  
2024-12-06 22:45:13.108188: Epoch 49 
2024-12-06 22:45:13.110697: Current learning rate: 0.00546 
2024-12-06 22:45:45.623384: train_loss -0.8642 
2024-12-06 22:45:45.630526: val_loss -0.7285 
2024-12-06 22:45:45.634063: Pseudo dice [np.float32(0.8188), np.float32(0.6969), np.float32(0.8692)] 
2024-12-06 22:45:45.637128: Epoch time: 32.52 s 
2024-12-06 22:45:46.328414:  
2024-12-06 22:45:46.332466: Epoch 50 
2024-12-06 22:45:46.337041: Current learning rate: 0.00536 
2024-12-06 22:46:19.150302: train_loss -0.8653 
2024-12-06 22:46:19.156338: val_loss -0.7272 
2024-12-06 22:46:19.159855: Pseudo dice [np.float32(0.8178), np.float32(0.6928), np.float32(0.868)] 
2024-12-06 22:46:19.162880: Epoch time: 32.82 s 
2024-12-06 22:46:19.729604:  
2024-12-06 22:46:19.735144: Epoch 51 
2024-12-06 22:46:19.738393: Current learning rate: 0.00526 
2024-12-06 22:46:51.803621: train_loss -0.8654 
2024-12-06 22:46:51.810841: val_loss -0.7295 
2024-12-06 22:46:51.814397: Pseudo dice [np.float32(0.8198), np.float32(0.7005), np.float32(0.8649)] 
2024-12-06 22:46:51.817453: Epoch time: 32.07 s 
2024-12-06 22:46:52.523075:  
2024-12-06 22:46:52.527110: Epoch 52 
2024-12-06 22:46:52.530944: Current learning rate: 0.00517 
2024-12-06 22:47:24.604848: train_loss -0.866 
2024-12-06 22:47:24.611364: val_loss -0.7322 
2024-12-06 22:47:24.613876: Pseudo dice [np.float32(0.8202), np.float32(0.7076), np.float32(0.865)] 
2024-12-06 22:47:24.617388: Epoch time: 32.08 s 
2024-12-06 22:47:25.186441:  
2024-12-06 22:47:25.190509: Epoch 53 
2024-12-06 22:47:25.194572: Current learning rate: 0.00507 
2024-12-06 22:47:57.489057: train_loss -0.8672 
2024-12-06 22:47:57.495173: val_loss -0.7279 
2024-12-06 22:47:57.500777: Pseudo dice [np.float32(0.8191), np.float32(0.7021), np.float32(0.8648)] 
2024-12-06 22:47:57.504785: Epoch time: 32.3 s 
2024-12-06 22:47:58.090600:  
2024-12-06 22:47:58.096124: Epoch 54 
2024-12-06 22:47:58.101137: Current learning rate: 0.00497 
2024-12-06 22:48:31.211475: train_loss -0.8667 
2024-12-06 22:48:31.217504: val_loss -0.7262 
2024-12-06 22:48:31.221511: Pseudo dice [np.float32(0.8186), np.float32(0.6965), np.float32(0.8671)] 
2024-12-06 22:48:31.225063: Epoch time: 33.12 s 
2024-12-06 22:48:31.824986:  
2024-12-06 22:48:31.831015: Epoch 55 
2024-12-06 22:48:31.833905: Current learning rate: 0.00487 
2024-12-06 22:49:04.314806: train_loss -0.8675 
2024-12-06 22:49:04.322326: val_loss -0.7334 
2024-12-06 22:49:04.326838: Pseudo dice [np.float32(0.82), np.float32(0.7139), np.float32(0.8653)] 
2024-12-06 22:49:04.330854: Epoch time: 32.49 s 
2024-12-06 22:49:04.937591:  
2024-12-06 22:49:04.943115: Epoch 56 
2024-12-06 22:49:04.946633: Current learning rate: 0.00478 
2024-12-06 22:49:37.323274: train_loss -0.8672 
2024-12-06 22:49:37.329840: val_loss -0.7323 
2024-12-06 22:49:37.333389: Pseudo dice [np.float32(0.8182), np.float32(0.7127), np.float32(0.8667)] 
2024-12-06 22:49:37.335923: Epoch time: 32.39 s 
2024-12-06 22:49:37.928316:  
2024-12-06 22:49:37.933887: Epoch 57 
2024-12-06 22:49:37.936938: Current learning rate: 0.00468 
2024-12-06 22:50:10.057218: train_loss -0.8674 
2024-12-06 22:50:10.064738: val_loss -0.73 
2024-12-06 22:50:10.068248: Pseudo dice [np.float32(0.8188), np.float32(0.7045), np.float32(0.8652)] 
2024-12-06 22:50:10.071758: Epoch time: 32.13 s 
2024-12-06 22:50:10.676239:  
2024-12-06 22:50:10.681276: Epoch 58 
2024-12-06 22:50:10.684911: Current learning rate: 0.00458 
2024-12-06 22:50:42.822769: train_loss -0.8683 
2024-12-06 22:50:42.829283: val_loss -0.73 
2024-12-06 22:50:42.832798: Pseudo dice [np.float32(0.82), np.float32(0.7058), np.float32(0.8677)] 
2024-12-06 22:50:42.836807: Epoch time: 32.15 s 
2024-12-06 22:50:43.423972:  
2024-12-06 22:50:43.428999: Epoch 59 
2024-12-06 22:50:43.433029: Current learning rate: 0.00448 
2024-12-06 22:51:15.575365: train_loss -0.8681 
2024-12-06 22:51:15.581418: val_loss -0.7301 
2024-12-06 22:51:15.584443: Pseudo dice [np.float32(0.8206), np.float32(0.7032), np.float32(0.8648)] 
2024-12-06 22:51:15.588483: Epoch time: 32.15 s 
2024-12-06 22:51:16.358847:  
2024-12-06 22:51:16.364363: Epoch 60 
2024-12-06 22:51:16.367876: Current learning rate: 0.00438 
2024-12-06 22:51:48.489311: train_loss -0.8696 
2024-12-06 22:51:48.496874: val_loss -0.7247 
2024-12-06 22:51:48.500409: Pseudo dice [np.float32(0.8199), np.float32(0.6946), np.float32(0.8631)] 
2024-12-06 22:51:48.502932: Epoch time: 32.13 s 
2024-12-06 22:51:49.102970:  
2024-12-06 22:51:49.109034: Epoch 61 
2024-12-06 22:51:49.113592: Current learning rate: 0.00429 
2024-12-06 22:52:21.250018: train_loss -0.8684 
2024-12-06 22:52:21.258114: val_loss -0.7298 
2024-12-06 22:52:21.262126: Pseudo dice [np.float32(0.8169), np.float32(0.7097), np.float32(0.8631)] 
2024-12-06 22:52:21.266639: Epoch time: 32.15 s 
2024-12-06 22:52:21.870599:  
2024-12-06 22:52:21.876168: Epoch 62 
2024-12-06 22:52:21.880753: Current learning rate: 0.00419 
2024-12-06 22:52:54.000350: train_loss -0.869 
2024-12-06 22:52:54.008572: val_loss -0.7312 
2024-12-06 22:52:54.012629: Pseudo dice [np.float32(0.8199), np.float32(0.7114), np.float32(0.8653)] 
2024-12-06 22:52:54.016676: Epoch time: 32.13 s 
2024-12-06 22:52:54.632890:  
2024-12-06 22:52:54.638429: Epoch 63 
2024-12-06 22:52:54.641982: Current learning rate: 0.00409 
2024-12-06 22:53:26.881857: train_loss -0.8704 
2024-12-06 22:53:26.887875: val_loss -0.7213 
2024-12-06 22:53:26.891890: Pseudo dice [np.float32(0.8141), np.float32(0.6989), np.float32(0.8603)] 
2024-12-06 22:53:26.894397: Epoch time: 32.25 s 
2024-12-06 22:53:27.517739:  
2024-12-06 22:53:27.522773: Epoch 64 
2024-12-06 22:53:27.525000: Current learning rate: 0.00399 
2024-12-06 22:53:59.710734: train_loss -0.8702 
2024-12-06 22:53:59.718259: val_loss -0.7259 
2024-12-06 22:53:59.722273: Pseudo dice [np.float32(0.8174), np.float32(0.6964), np.float32(0.8683)] 
2024-12-06 22:53:59.725784: Epoch time: 32.19 s 
2024-12-06 22:54:00.356544:  
2024-12-06 22:54:00.360592: Epoch 65 
2024-12-06 22:54:00.365170: Current learning rate: 0.00389 
2024-12-06 22:54:32.519323: train_loss -0.8701 
2024-12-06 22:54:32.525845: val_loss -0.7249 
2024-12-06 22:54:32.529357: Pseudo dice [np.float32(0.8218), np.float32(0.6916), np.float32(0.8672)] 
2024-12-06 22:54:32.531867: Epoch time: 32.16 s 
2024-12-06 22:54:33.154722:  
2024-12-06 22:54:33.159760: Epoch 66 
2024-12-06 22:54:33.163301: Current learning rate: 0.00379 
2024-12-06 22:55:05.200747: train_loss -0.8725 
2024-12-06 22:55:05.208389: val_loss -0.7249 
2024-12-06 22:55:05.210940: Pseudo dice [np.float32(0.8199), np.float32(0.7008), np.float32(0.8617)] 
2024-12-06 22:55:05.214992: Epoch time: 32.05 s 
2024-12-06 22:55:05.847686:  
2024-12-06 22:55:05.852702: Epoch 67 
2024-12-06 22:55:05.855712: Current learning rate: 0.00369 
2024-12-06 22:55:37.877471: train_loss -0.8709 
2024-12-06 22:55:37.883015: val_loss -0.7328 
2024-12-06 22:55:37.886733: Pseudo dice [np.float32(0.8235), np.float32(0.7067), np.float32(0.8682)] 
2024-12-06 22:55:37.890758: Epoch time: 32.03 s 
2024-12-06 22:55:38.681768:  
2024-12-06 22:55:38.686839: Epoch 68 
2024-12-06 22:55:38.689346: Current learning rate: 0.00359 
2024-12-06 22:56:10.706758: train_loss -0.8724 
2024-12-06 22:56:10.712275: val_loss -0.7264 
2024-12-06 22:56:10.715789: Pseudo dice [np.float32(0.8169), np.float32(0.7038), np.float32(0.8635)] 
2024-12-06 22:56:10.719804: Epoch time: 32.03 s 
2024-12-06 22:56:11.355998:  
2024-12-06 22:56:11.360045: Epoch 69 
2024-12-06 22:56:11.365176: Current learning rate: 0.00349 
2024-12-06 22:56:43.383259: train_loss -0.8718 
2024-12-06 22:56:43.390403: val_loss -0.7304 
2024-12-06 22:56:43.393966: Pseudo dice [np.float32(0.8226), np.float32(0.7045), np.float32(0.868)] 
2024-12-06 22:56:43.397536: Epoch time: 32.03 s 
2024-12-06 22:56:44.033983:  
2024-12-06 22:56:44.039535: Epoch 70 
2024-12-06 22:56:44.042216: Current learning rate: 0.00338 
2024-12-06 22:57:16.065242: train_loss -0.8717 
2024-12-06 22:57:16.070814: val_loss -0.7346 
2024-12-06 22:57:16.074366: Pseudo dice [np.float32(0.8206), np.float32(0.7118), np.float32(0.8696)] 
2024-12-06 22:57:16.077951: Epoch time: 32.03 s 
2024-12-06 22:57:16.728036:  
2024-12-06 22:57:16.733052: Epoch 71 
2024-12-06 22:57:16.736066: Current learning rate: 0.00328 
2024-12-06 22:57:48.743045: train_loss -0.8724 
2024-12-06 22:57:48.750574: val_loss -0.7316 
2024-12-06 22:57:48.755084: Pseudo dice [np.float32(0.8182), np.float32(0.7141), np.float32(0.8659)] 
2024-12-06 22:57:48.758100: Epoch time: 32.02 s 
2024-12-06 22:57:49.414527:  
2024-12-06 22:57:49.419562: Epoch 72 
2024-12-06 22:57:49.423117: Current learning rate: 0.00318 
2024-12-06 22:58:21.443984: train_loss -0.8727 
2024-12-06 22:58:21.450498: val_loss -0.7261 
2024-12-06 22:58:21.453005: Pseudo dice [np.float32(0.8159), np.float32(0.7005), np.float32(0.8668)] 
2024-12-06 22:58:21.456514: Epoch time: 32.03 s 
2024-12-06 22:58:22.090644:  
2024-12-06 22:58:22.095174: Epoch 73 
2024-12-06 22:58:22.099466: Current learning rate: 0.00308 
2024-12-06 22:58:54.121967: train_loss -0.8726 
2024-12-06 22:58:54.129632: val_loss -0.7275 
2024-12-06 22:58:54.132688: Pseudo dice [np.float32(0.8186), np.float32(0.7099), np.float32(0.865)] 
2024-12-06 22:58:54.135224: Epoch time: 32.03 s 
2024-12-06 22:58:54.769761:  
2024-12-06 22:58:54.774276: Epoch 74 
2024-12-06 22:58:54.777291: Current learning rate: 0.00297 
2024-12-06 22:59:26.806787: train_loss -0.8732 
2024-12-06 22:59:26.812813: val_loss -0.7264 
2024-12-06 22:59:26.816318: Pseudo dice [np.float32(0.8184), np.float32(0.6995), np.float32(0.8668)] 
2024-12-06 22:59:26.819326: Epoch time: 32.04 s 
2024-12-06 22:59:27.458070:  
2024-12-06 22:59:27.462579: Epoch 75 
2024-12-06 22:59:27.465591: Current learning rate: 0.00287 
2024-12-06 23:00:02.114839: train_loss -0.873 
2024-12-06 23:00:02.120415: val_loss -0.7328 
2024-12-06 23:00:02.125027: Pseudo dice [np.float32(0.8178), np.float32(0.7134), np.float32(0.865)] 
2024-12-06 23:00:02.129114: Epoch time: 34.66 s 
2024-12-06 23:00:02.896240:  
2024-12-06 23:00:02.900872: Epoch 76 
2024-12-06 23:00:02.904391: Current learning rate: 0.00277 
2024-12-06 23:00:36.796892: train_loss -0.8738 
2024-12-06 23:00:36.804247: val_loss -0.7204 
2024-12-06 23:00:36.806754: Pseudo dice [np.float32(0.8156), np.float32(0.6932), np.float32(0.8626)] 
2024-12-06 23:00:36.810267: Epoch time: 33.9 s 
2024-12-06 23:00:37.429959:  
2024-12-06 23:00:37.434971: Epoch 77 
2024-12-06 23:00:37.438991: Current learning rate: 0.00266 
2024-12-06 23:01:09.561925: train_loss -0.8742 
2024-12-06 23:01:09.569445: val_loss -0.7285 
2024-12-06 23:01:09.573455: Pseudo dice [np.float32(0.8181), np.float32(0.7048), np.float32(0.8688)] 
2024-12-06 23:01:09.575962: Epoch time: 32.13 s 
2024-12-06 23:01:10.188749:  
2024-12-06 23:01:10.194345: Epoch 78 
2024-12-06 23:01:10.197921: Current learning rate: 0.00256 
2024-12-06 23:01:42.331408: train_loss -0.8753 
2024-12-06 23:01:42.338604: val_loss -0.7253 
2024-12-06 23:01:42.341633: Pseudo dice [np.float32(0.8185), np.float32(0.6972), np.float32(0.864)] 
2024-12-06 23:01:42.344668: Epoch time: 32.14 s 
2024-12-06 23:01:42.952284:  
2024-12-06 23:01:42.957083: Epoch 79 
2024-12-06 23:01:42.960500: Current learning rate: 0.00245 
2024-12-06 23:02:15.080028: train_loss -0.8758 
2024-12-06 23:02:15.086589: val_loss -0.7234 
2024-12-06 23:02:15.090196: Pseudo dice [np.float32(0.8157), np.float32(0.7017), np.float32(0.8652)] 
2024-12-06 23:02:15.093252: Epoch time: 32.13 s 
2024-12-06 23:02:15.694848:  
2024-12-06 23:02:15.700443: Epoch 80 
2024-12-06 23:02:15.702987: Current learning rate: 0.00235 
2024-12-06 23:02:47.883093: train_loss -0.875 
2024-12-06 23:02:47.890621: val_loss -0.7237 
2024-12-06 23:02:47.893128: Pseudo dice [np.float32(0.817), np.float32(0.7), np.float32(0.8642)] 
2024-12-06 23:02:47.896637: Epoch time: 32.19 s 
2024-12-06 23:02:48.505228:  
2024-12-06 23:02:48.511328: Epoch 81 
2024-12-06 23:02:48.514887: Current learning rate: 0.00224 
2024-12-06 23:03:21.082130: train_loss -0.8752 
2024-12-06 23:03:21.089708: val_loss -0.7291 
2024-12-06 23:03:21.093744: Pseudo dice [np.float32(0.8216), np.float32(0.7002), np.float32(0.8654)] 
2024-12-06 23:03:21.097757: Epoch time: 32.58 s 
2024-12-06 23:03:21.748146:  
2024-12-06 23:03:21.753665: Epoch 82 
2024-12-06 23:03:21.757178: Current learning rate: 0.00214 
2024-12-06 23:03:53.898963: train_loss -0.8761 
2024-12-06 23:03:53.906569: val_loss -0.7289 
2024-12-06 23:03:53.910147: Pseudo dice [np.float32(0.8221), np.float32(0.7016), np.float32(0.8628)] 
2024-12-06 23:03:53.914214: Epoch time: 32.15 s 
2024-12-06 23:03:54.615848:  
2024-12-06 23:03:54.621376: Epoch 83 
2024-12-06 23:03:54.624904: Current learning rate: 0.00203 
2024-12-06 23:04:26.894903: train_loss -0.8754 
2024-12-06 23:04:26.902031: val_loss -0.7287 
2024-12-06 23:04:26.905081: Pseudo dice [np.float32(0.8199), np.float32(0.7025), np.float32(0.8671)] 
2024-12-06 23:04:26.910150: Epoch time: 32.28 s 
2024-12-06 23:04:27.460858:  
2024-12-06 23:04:27.466379: Epoch 84 
2024-12-06 23:04:27.469389: Current learning rate: 0.00192 
2024-12-06 23:04:59.596153: train_loss -0.8762 
2024-12-06 23:04:59.604271: val_loss -0.7301 
2024-12-06 23:04:59.607327: Pseudo dice [np.float32(0.8214), np.float32(0.711), np.float32(0.8661)] 
2024-12-06 23:04:59.611926: Epoch time: 32.14 s 
2024-12-06 23:05:00.179896:  
2024-12-06 23:05:00.184924: Epoch 85 
2024-12-06 23:05:00.188449: Current learning rate: 0.00181 
2024-12-06 23:05:32.339025: train_loss -0.8771 
2024-12-06 23:05:32.345537: val_loss -0.7273 
2024-12-06 23:05:32.349049: Pseudo dice [np.float32(0.8152), np.float32(0.7004), np.float32(0.8698)] 
2024-12-06 23:05:32.353062: Epoch time: 32.16 s 
2024-12-06 23:05:32.895668:  
2024-12-06 23:05:32.901748: Epoch 86 
2024-12-06 23:05:32.904812: Current learning rate: 0.0017 
2024-12-06 23:06:05.077797: train_loss -0.8775 
2024-12-06 23:06:05.084315: val_loss -0.7255 
2024-12-06 23:06:05.089328: Pseudo dice [np.float32(0.8181), np.float32(0.7035), np.float32(0.8644)] 
2024-12-06 23:06:05.094344: Epoch time: 32.18 s 
2024-12-06 23:06:05.650073:  
2024-12-06 23:06:05.655106: Epoch 87 
2024-12-06 23:06:05.659643: Current learning rate: 0.00159 
2024-12-06 23:06:38.094938: train_loss -0.8777 
2024-12-06 23:06:38.102034: val_loss -0.7297 
2024-12-06 23:06:38.105611: Pseudo dice [np.float32(0.8216), np.float32(0.7083), np.float32(0.8658)] 
2024-12-06 23:06:38.109648: Epoch time: 32.45 s 
2024-12-06 23:06:38.665455:  
2024-12-06 23:06:38.671028: Epoch 88 
2024-12-06 23:06:38.676129: Current learning rate: 0.00148 
2024-12-06 23:07:11.106186: train_loss -0.8774 
2024-12-06 23:07:11.113368: val_loss -0.7336 
2024-12-06 23:07:11.117944: Pseudo dice [np.float32(0.821), np.float32(0.7173), np.float32(0.8683)] 
2024-12-06 23:07:11.121483: Epoch time: 32.44 s 
2024-12-06 23:07:11.125403: Yayy! New best EMA pseudo Dice: 0.7967000007629395 
2024-12-06 23:07:11.812757:  
2024-12-06 23:07:11.819319: Epoch 89 
2024-12-06 23:07:11.823905: Current learning rate: 0.00137 
2024-12-06 23:07:44.027612: train_loss -0.8759 
2024-12-06 23:07:44.037374: val_loss -0.7277 
2024-12-06 23:07:44.040405: Pseudo dice [np.float32(0.8186), np.float32(0.7092), np.float32(0.8626)] 
2024-12-06 23:07:44.043919: Epoch time: 32.21 s 
2024-12-06 23:07:44.047931: Yayy! New best EMA pseudo Dice: 0.7967000007629395 
2024-12-06 23:07:44.711815:  
2024-12-06 23:07:44.717402: Epoch 90 
2024-12-06 23:07:44.721985: Current learning rate: 0.00126 
2024-12-06 23:08:16.883329: train_loss -0.8774 
2024-12-06 23:08:16.889937: val_loss -0.7238 
2024-12-06 23:08:16.893978: Pseudo dice [np.float32(0.8177), np.float32(0.6994), np.float32(0.8668)] 
2024-12-06 23:08:16.897539: Epoch time: 32.17 s 
2024-12-06 23:08:17.600028:  
2024-12-06 23:08:17.605563: Epoch 91 
2024-12-06 23:08:17.609122: Current learning rate: 0.00115 
2024-12-06 23:08:49.720858: train_loss -0.8773 
2024-12-06 23:08:49.728445: val_loss -0.7288 
2024-12-06 23:08:49.733356: Pseudo dice [np.float32(0.8165), np.float32(0.709), np.float32(0.8671)] 
2024-12-06 23:08:49.737374: Epoch time: 32.12 s 
2024-12-06 23:08:50.285436:  
2024-12-06 23:08:50.291035: Epoch 92 
2024-12-06 23:08:50.295594: Current learning rate: 0.00103 
2024-12-06 23:09:22.485300: train_loss -0.8781 
2024-12-06 23:09:22.491845: val_loss -0.7275 
2024-12-06 23:09:22.496862: Pseudo dice [np.float32(0.8153), np.float32(0.708), np.float32(0.8689)] 
2024-12-06 23:09:22.500875: Epoch time: 32.2 s 
2024-12-06 23:09:23.060834:  
2024-12-06 23:09:23.067410: Epoch 93 
2024-12-06 23:09:23.070493: Current learning rate: 0.00091 
2024-12-06 23:09:55.025107: train_loss -0.8788 
2024-12-06 23:09:55.034171: val_loss -0.7314 
2024-12-06 23:09:55.038739: Pseudo dice [np.float32(0.8239), np.float32(0.7096), np.float32(0.8666)] 
2024-12-06 23:09:55.042790: Epoch time: 31.97 s 
2024-12-06 23:09:55.046367: Yayy! New best EMA pseudo Dice: 0.796999990940094 
2024-12-06 23:09:55.709124:  
2024-12-06 23:09:55.714702: Epoch 94 
2024-12-06 23:09:55.719807: Current learning rate: 0.00079 
2024-12-06 23:10:27.668377: train_loss -0.8778 
2024-12-06 23:10:27.675461: val_loss -0.7258 
2024-12-06 23:10:27.679515: Pseudo dice [np.float32(0.8192), np.float32(0.7073), np.float32(0.8622)] 
2024-12-06 23:10:27.683103: Epoch time: 31.96 s 
2024-12-06 23:10:28.235831:  
2024-12-06 23:10:28.241420: Epoch 95 
2024-12-06 23:10:28.247016: Current learning rate: 0.00067 
2024-12-06 23:11:00.181091: train_loss -0.8803 
2024-12-06 23:11:00.189615: val_loss -0.7217 
2024-12-06 23:11:00.193619: Pseudo dice [np.float32(0.8202), np.float32(0.6944), np.float32(0.8609)] 
2024-12-06 23:11:00.198128: Epoch time: 31.95 s 
2024-12-06 23:11:00.750427:  
2024-12-06 23:11:00.756531: Epoch 96 
2024-12-06 23:11:00.760546: Current learning rate: 0.00055 
2024-12-06 23:11:32.700860: train_loss -0.8793 
2024-12-06 23:11:32.707434: val_loss -0.7283 
2024-12-06 23:11:32.712451: Pseudo dice [np.float32(0.8206), np.float32(0.7073), np.float32(0.8659)] 
2024-12-06 23:11:32.715963: Epoch time: 31.95 s 
2024-12-06 23:11:33.285069:  
2024-12-06 23:11:33.291594: Epoch 97 
2024-12-06 23:11:33.295608: Current learning rate: 0.00043 
2024-12-06 23:12:05.254572: train_loss -0.8792 
2024-12-06 23:12:05.263173: val_loss -0.7269 
2024-12-06 23:12:05.268234: Pseudo dice [np.float32(0.8168), np.float32(0.7061), np.float32(0.8692)] 
2024-12-06 23:12:05.272264: Epoch time: 31.97 s 
2024-12-06 23:12:05.832928:  
2024-12-06 23:12:05.838445: Epoch 98 
2024-12-06 23:12:05.843461: Current learning rate: 0.0003 
2024-12-06 23:12:37.803343: train_loss -0.8799 
2024-12-06 23:12:37.810861: val_loss -0.7268 
2024-12-06 23:12:37.814876: Pseudo dice [np.float32(0.8189), np.float32(0.7044), np.float32(0.8632)] 
2024-12-06 23:12:37.819890: Epoch time: 31.97 s 
2024-12-06 23:12:38.387708:  
2024-12-06 23:12:38.393224: Epoch 99 
2024-12-06 23:12:38.396735: Current learning rate: 0.00016 
2024-12-06 23:13:10.360648: train_loss -0.8795 
2024-12-06 23:13:10.369171: val_loss -0.7276 
2024-12-06 23:13:10.373179: Pseudo dice [np.float32(0.8185), np.float32(0.7045), np.float32(0.8659)] 
2024-12-06 23:13:10.376692: Epoch time: 31.97 s 
2024-12-06 23:13:11.250078: Training done. 
2024-12-06 23:13:11.289080: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-06 23:13:11.300079: The split file contains 5 splits. 
2024-12-06 23:13:11.305078: Desired fold for training: 0 
2024-12-06 23:13:11.310078: This split has 387 training and 97 validation cases. 
2024-12-06 23:13:11.315080: predicting BRATS_010 
2024-12-06 23:13:11.321079: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2024-12-06 23:13:12.004078: predicting BRATS_011 
2024-12-06 23:13:12.025079: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2024-12-06 23:13:12.428079: predicting BRATS_012 
2024-12-06 23:13:12.440078: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-06 23:13:12.838079: predicting BRATS_018 
2024-12-06 23:13:12.851077: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2024-12-06 23:13:13.268079: predicting BRATS_020 
2024-12-06 23:13:13.280079: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2024-12-06 23:13:13.698077: predicting BRATS_028 
2024-12-06 23:13:13.711077: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2024-12-06 23:13:14.129080: predicting BRATS_029 
2024-12-06 23:13:14.141078: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2024-12-06 23:13:14.536080: predicting BRATS_032 
2024-12-06 23:13:14.549078: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2024-12-06 23:13:14.974129: predicting BRATS_034 
2024-12-06 23:13:14.986125: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2024-12-06 23:13:15.408642: predicting BRATS_041 
2024-12-06 23:13:15.430638: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2024-12-06 23:13:16.150185: predicting BRATS_042 
2024-12-06 23:13:16.165201: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2024-12-06 23:13:16.625200: predicting BRATS_047 
2024-12-06 23:13:16.639202: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-06 23:13:17.088714: predicting BRATS_049 
2024-12-06 23:13:17.102714: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-06 23:13:17.554742: predicting BRATS_053 
2024-12-06 23:13:17.568742: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-06 23:13:17.994741: predicting BRATS_056 
2024-12-06 23:13:18.007741: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-06 23:13:18.426741: predicting BRATS_057 
2024-12-06 23:13:18.439742: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-06 23:13:18.893741: predicting BRATS_067 
2024-12-06 23:13:18.909741: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-06 23:13:19.311434: predicting BRATS_069 
2024-12-06 23:13:19.324435: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-06 23:13:19.707124: predicting BRATS_085 
2024-12-06 23:13:19.722125: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2024-12-06 23:13:20.123177: predicting BRATS_086 
2024-12-06 23:13:20.137177: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2024-12-06 23:13:20.496177: predicting BRATS_088 
2024-12-06 23:13:20.509176: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2024-12-06 23:13:20.910014: predicting BRATS_091 
2024-12-06 23:13:20.925015: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2024-12-06 23:13:21.378392: predicting BRATS_098 
2024-12-06 23:13:21.393395: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2024-12-06 23:13:21.847399: predicting BRATS_100 
2024-12-06 23:13:21.861401: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-06 23:13:22.256399: predicting BRATS_101 
2024-12-06 23:13:22.270399: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-06 23:13:22.667480: predicting BRATS_102 
2024-12-06 23:13:22.681480: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2024-12-06 23:13:23.142045: predicting BRATS_104 
2024-12-06 23:13:23.163045: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2024-12-06 23:13:23.628955: predicting BRATS_111 
2024-12-06 23:13:23.651957: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2024-12-06 23:13:24.069956: predicting BRATS_116 
2024-12-06 23:13:24.091956: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2024-12-06 23:13:24.506627: predicting BRATS_135 
2024-12-06 23:13:24.529628: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2024-12-06 23:13:24.999945: predicting BRATS_136 
2024-12-06 23:13:25.019947: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2024-12-06 23:13:25.422945: predicting BRATS_138 
2024-12-06 23:13:25.442945: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2024-12-06 23:13:25.868128: predicting BRATS_145 
2024-12-06 23:13:25.882132: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2024-12-06 23:13:26.300774: predicting BRATS_149 
2024-12-06 23:13:26.321773: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2024-12-06 23:13:26.741953: predicting BRATS_155 
2024-12-06 23:13:26.757953: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-06 23:13:27.163952: predicting BRATS_157 
2024-12-06 23:13:27.178952: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-06 23:13:27.573028: predicting BRATS_158 
2024-12-06 23:13:27.588029: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-06 23:13:28.006029: predicting BRATS_159 
2024-12-06 23:13:28.019029: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-06 23:13:28.415428: predicting BRATS_163 
2024-12-06 23:13:28.429430: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2024-12-06 23:13:28.858061: predicting BRATS_164 
2024-12-06 23:13:28.873061: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2024-12-06 23:13:29.284061: predicting BRATS_169 
2024-12-06 23:13:29.298061: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2024-12-06 23:13:29.750716: predicting BRATS_176 
2024-12-06 23:13:29.764718: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2024-12-06 23:13:30.152679: predicting BRATS_181 
2024-12-06 23:13:30.166680: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2024-12-06 23:13:30.556825: predicting BRATS_183 
2024-12-06 23:13:30.571826: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-06 23:13:30.992825: predicting BRATS_184 
2024-12-06 23:13:31.007826: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-06 23:13:31.480825: predicting BRATS_187 
2024-12-06 23:13:31.494825: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-06 23:13:31.927699: predicting BRATS_192 
2024-12-06 23:13:31.941700: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2024-12-06 23:13:32.319698: predicting BRATS_198 
2024-12-06 23:13:32.332699: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2024-12-06 23:13:32.783028: predicting BRATS_207 
2024-12-06 23:13:32.798028: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-06 23:13:33.246968: predicting BRATS_208 
2024-12-06 23:13:33.259969: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-06 23:13:33.687968: predicting BRATS_218 
2024-12-06 23:13:33.700970: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2024-12-06 23:13:34.114968: predicting BRATS_220 
2024-12-06 23:13:34.129968: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2024-12-06 23:13:34.548543: predicting BRATS_224 
2024-12-06 23:13:34.562544: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2024-12-06 23:13:35.004544: predicting BRATS_230 
2024-12-06 23:13:35.018548: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2024-12-06 23:13:35.441543: predicting BRATS_271 
2024-12-06 23:13:35.454544: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2024-12-06 23:13:35.934543: predicting BRATS_282 
2024-12-06 23:13:35.949544: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2024-12-06 23:13:36.391831: predicting BRATS_284 
2024-12-06 23:13:36.405832: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2024-12-06 23:13:36.769831: predicting BRATS_287 
2024-12-06 23:13:36.781832: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-06 23:13:37.210831: predicting BRATS_290 
2024-12-06 23:13:37.224837: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2024-12-06 23:13:37.624959: predicting BRATS_291 
2024-12-06 23:13:37.638959: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2024-12-06 23:13:38.097737: predicting BRATS_292 
2024-12-06 23:13:38.110737: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2024-12-06 23:13:38.526689: predicting BRATS_293 
2024-12-06 23:13:38.539691: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2024-12-06 23:13:38.995688: predicting BRATS_300 
2024-12-06 23:13:39.010689: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2024-12-06 23:13:39.448947: predicting BRATS_305 
2024-12-06 23:13:39.462947: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2024-12-06 23:13:39.895103: predicting BRATS_311 
2024-12-06 23:13:39.910104: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2024-12-06 23:13:40.368104: predicting BRATS_314 
2024-12-06 23:13:40.382104: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2024-12-06 23:13:40.771104: predicting BRATS_321 
2024-12-06 23:13:40.784107: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2024-12-06 23:13:41.247368: predicting BRATS_328 
2024-12-06 23:13:41.264370: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2024-12-06 23:13:41.721035: predicting BRATS_329 
2024-12-06 23:13:41.735036: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2024-12-06 23:13:42.175035: predicting BRATS_335 
2024-12-06 23:13:42.190035: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2024-12-06 23:13:42.664035: predicting BRATS_343 
2024-12-06 23:13:42.678037: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2024-12-06 23:13:43.098035: predicting BRATS_350 
2024-12-06 23:13:43.114035: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2024-12-06 23:13:43.573851: predicting BRATS_351 
2024-12-06 23:13:43.587851: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2024-12-06 23:13:43.943778: predicting BRATS_356 
2024-12-06 23:13:43.957780: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2024-12-06 23:13:44.425232: predicting BRATS_366 
2024-12-06 23:13:44.439234: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2024-12-06 23:13:44.886240: predicting BRATS_367 
2024-12-06 23:13:44.901240: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2024-12-06 23:13:45.303551: predicting BRATS_374 
2024-12-06 23:13:45.317555: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2024-12-06 23:13:45.780660: predicting BRATS_376 
2024-12-06 23:13:45.793661: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2024-12-06 23:13:46.209007: predicting BRATS_377 
2024-12-06 23:13:46.224007: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2024-12-06 23:13:46.638575: predicting BRATS_378 
2024-12-06 23:13:46.654576: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2024-12-06 23:13:47.142577: predicting BRATS_379 
2024-12-06 23:13:47.157579: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2024-12-06 23:13:47.587554: predicting BRATS_384 
2024-12-06 23:13:47.602556: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2024-12-06 23:13:48.057554: predicting BRATS_386 
2024-12-06 23:13:48.071556: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2024-12-06 23:13:48.473556: predicting BRATS_394 
2024-12-06 23:13:48.488554: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-06 23:13:48.948061: predicting BRATS_398 
2024-12-06 23:13:48.962064: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2024-12-06 23:13:49.376323: predicting BRATS_400 
2024-12-06 23:13:49.390323: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2024-12-06 23:13:49.855602: predicting BRATS_432 
2024-12-06 23:13:49.871602: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2024-12-06 23:13:50.356602: predicting BRATS_437 
2024-12-06 23:13:50.370601: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-06 23:13:50.768801: predicting BRATS_445 
2024-12-06 23:13:50.782801: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2024-12-06 23:13:51.226801: predicting BRATS_446 
2024-12-06 23:13:51.239802: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2024-12-06 23:13:51.674502: predicting BRATS_450 
2024-12-06 23:13:51.688502: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2024-12-06 23:13:52.132598: predicting BRATS_452 
2024-12-06 23:13:52.147597: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2024-12-06 23:13:52.609373: predicting BRATS_460 
2024-12-06 23:13:52.623376: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2024-12-06 23:13:53.060242: predicting BRATS_470 
2024-12-06 23:13:53.075245: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2024-12-06 23:13:53.523751: predicting BRATS_472 
2024-12-06 23:13:53.536753: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2024-12-06 23:13:53.926751: predicting BRATS_473 
2024-12-06 23:13:53.939752: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2024-12-06 23:13:54.350093: predicting BRATS_482 
2024-12-06 23:13:54.363092: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2024-12-06 23:14:01.732513: Validation complete 
2024-12-06 23:14:01.739513: Mean Validation Dice:  0.7007016075992247 
