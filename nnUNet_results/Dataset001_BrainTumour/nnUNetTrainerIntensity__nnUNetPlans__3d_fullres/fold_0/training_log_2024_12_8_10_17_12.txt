
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-08 10:17:12.938969: do_dummy_2d_data_aug: False 
2024-12-08 10:17:12.938969: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-08 10:17:12.949076: The split file contains 5 splits. 
2024-12-08 10:17:12.949076: Desired fold for training: 0 
2024-12-08 10:17:12.955356: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2024-12-08 10:17:43.405653: unpacking dataset... 
2024-12-08 10:17:44.028298: unpacking done... 
2024-12-08 10:17:46.646435:  
2024-12-08 10:17:46.651453: Epoch 0 
2024-12-08 10:17:46.654065: Current learning rate: 0.01 
2024-12-08 10:18:28.486652: train_loss -0.2965 
2024-12-08 10:18:28.494296: val_loss -0.4203 
2024-12-08 10:18:28.496890: Pseudo dice [np.float32(0.6961), np.float32(0.446), np.float32(0.7617)] 
2024-12-08 10:18:28.499454: Epoch time: 41.84 s 
2024-12-08 10:18:28.502048: Yayy! New best EMA pseudo Dice: 0.6345999836921692 
2024-12-08 10:18:29.170972:  
2024-12-08 10:18:29.176105: Epoch 1 
2024-12-08 10:18:29.178639: Current learning rate: 0.00991 
2024-12-08 10:19:06.802451: train_loss -0.499 
2024-12-08 10:19:06.807554: val_loss -0.4818 
2024-12-08 10:19:06.809774: Pseudo dice [np.float32(0.7615), np.float32(0.4571), np.float32(0.76)] 
2024-12-08 10:19:06.813286: Epoch time: 37.63 s 
2024-12-08 10:19:06.815792: Yayy! New best EMA pseudo Dice: 0.6370999813079834 
2024-12-08 10:19:07.553281:  
2024-12-08 10:19:07.559369: Epoch 2 
2024-12-08 10:19:07.562459: Current learning rate: 0.00982 
2024-12-08 10:19:45.129345: train_loss -0.5385 
2024-12-08 10:19:45.135935: val_loss -0.4998 
2024-12-08 10:19:45.139474: Pseudo dice [np.float32(0.7589), np.float32(0.5895), np.float32(0.7759)] 
2024-12-08 10:19:45.142029: Epoch time: 37.58 s 
2024-12-08 10:19:45.144566: Yayy! New best EMA pseudo Dice: 0.6442000269889832 
2024-12-08 10:19:45.887729:  
2024-12-08 10:19:45.893312: Epoch 3 
2024-12-08 10:19:45.896359: Current learning rate: 0.00973 
2024-12-08 10:20:23.417872: train_loss -0.5666 
2024-12-08 10:20:23.425482: val_loss -0.5414 
2024-12-08 10:20:23.429545: Pseudo dice [np.float32(0.7658), np.float32(0.5852), np.float32(0.7922)] 
2024-12-08 10:20:23.433098: Epoch time: 37.53 s 
2024-12-08 10:20:23.435639: Yayy! New best EMA pseudo Dice: 0.651199996471405 
2024-12-08 10:20:24.195581:  
2024-12-08 10:20:24.202165: Epoch 4 
2024-12-08 10:20:24.205261: Current learning rate: 0.00964 
2024-12-08 10:21:01.709661: train_loss -0.5995 
2024-12-08 10:21:01.715863: val_loss -0.5632 
2024-12-08 10:21:01.719951: Pseudo dice [np.float32(0.7749), np.float32(0.6394), np.float32(0.8121)] 
2024-12-08 10:21:01.722565: Epoch time: 37.51 s 
2024-12-08 10:21:01.725624: Yayy! New best EMA pseudo Dice: 0.6603000164031982 
2024-12-08 10:21:02.479928:  
2024-12-08 10:21:02.486012: Epoch 5 
2024-12-08 10:21:02.489055: Current learning rate: 0.00955 
2024-12-08 10:21:39.984690: train_loss -0.5892 
2024-12-08 10:21:39.992387: val_loss -0.5422 
2024-12-08 10:21:39.995008: Pseudo dice [np.float32(0.7765), np.float32(0.603), np.float32(0.8148)] 
2024-12-08 10:21:39.999152: Epoch time: 37.5 s 
2024-12-08 10:21:40.001687: Yayy! New best EMA pseudo Dice: 0.6674000024795532 
2024-12-08 10:21:40.830368:  
2024-12-08 10:21:40.835983: Epoch 6 
2024-12-08 10:21:40.839040: Current learning rate: 0.00946 
2024-12-08 10:22:18.305990: train_loss -0.6117 
2024-12-08 10:22:18.311053: val_loss -0.577 
2024-12-08 10:22:18.315187: Pseudo dice [np.float32(0.795), np.float32(0.6369), np.float32(0.8401)] 
2024-12-08 10:22:18.317738: Epoch time: 37.48 s 
2024-12-08 10:22:18.320279: Yayy! New best EMA pseudo Dice: 0.6764000058174133 
2024-12-08 10:22:19.049854:  
2024-12-08 10:22:19.057008: Epoch 7 
2024-12-08 10:22:19.060064: Current learning rate: 0.00937 
2024-12-08 10:22:56.538371: train_loss -0.6414 
2024-12-08 10:22:56.543961: val_loss -0.5443 
2024-12-08 10:22:56.547003: Pseudo dice [np.float32(0.7667), np.float32(0.5812), np.float32(0.8206)] 
2024-12-08 10:22:56.551631: Epoch time: 37.49 s 
2024-12-08 10:22:56.554170: Yayy! New best EMA pseudo Dice: 0.6811000108718872 
2024-12-08 10:22:57.280492:  
2024-12-08 10:22:57.285564: Epoch 8 
2024-12-08 10:22:57.288116: Current learning rate: 0.00928 
2024-12-08 10:23:34.757035: train_loss -0.6215 
2024-12-08 10:23:34.764154: val_loss -0.5509 
2024-12-08 10:23:34.768017: Pseudo dice [np.float32(0.7881), np.float32(0.5861), np.float32(0.789)] 
2024-12-08 10:23:34.771093: Epoch time: 37.48 s 
2024-12-08 10:23:34.774174: Yayy! New best EMA pseudo Dice: 0.6851000189781189 
2024-12-08 10:23:35.553857:  
2024-12-08 10:23:35.559459: Epoch 9 
2024-12-08 10:23:35.561995: Current learning rate: 0.00919 
2024-12-08 10:24:13.046479: train_loss -0.6449 
2024-12-08 10:24:13.052094: val_loss -0.5869 
2024-12-08 10:24:13.054635: Pseudo dice [np.float32(0.8063), np.float32(0.6039), np.float32(0.8257)] 
2024-12-08 10:24:13.057171: Epoch time: 37.49 s 
2024-12-08 10:24:13.059704: Yayy! New best EMA pseudo Dice: 0.691100001335144 
2024-12-08 10:24:13.770542:  
2024-12-08 10:24:13.776164: Epoch 10 
2024-12-08 10:24:13.778702: Current learning rate: 0.0091 
2024-12-08 10:24:51.257048: train_loss -0.6425 
2024-12-08 10:24:51.263653: val_loss -0.6091 
2024-12-08 10:24:51.267728: Pseudo dice [np.float32(0.8072), np.float32(0.6324), np.float32(0.8681)] 
2024-12-08 10:24:51.270301: Epoch time: 37.49 s 
2024-12-08 10:24:51.272838: Yayy! New best EMA pseudo Dice: 0.6988999843597412 
2024-12-08 10:24:52.042007:  
2024-12-08 10:24:52.047113: Epoch 11 
2024-12-08 10:24:52.049651: Current learning rate: 0.009 
2024-12-08 10:25:29.525797: train_loss -0.6393 
2024-12-08 10:25:29.533426: val_loss -0.5513 
2024-12-08 10:25:29.536477: Pseudo dice [np.float32(0.7878), np.float32(0.5295), np.float32(0.8239)] 
2024-12-08 10:25:29.539027: Epoch time: 37.49 s 
2024-12-08 10:25:29.541569: Yayy! New best EMA pseudo Dice: 0.7003999948501587 
2024-12-08 10:25:30.262417:  
2024-12-08 10:25:30.269054: Epoch 12 
2024-12-08 10:25:30.274125: Current learning rate: 0.00891 
2024-12-08 10:26:07.756862: train_loss -0.6511 
2024-12-08 10:26:07.763971: val_loss -0.5834 
2024-12-08 10:26:07.767586: Pseudo dice [np.float32(0.7837), np.float32(0.6733), np.float32(0.8456)] 
2024-12-08 10:26:07.769609: Epoch time: 37.49 s 
2024-12-08 10:26:07.772141: Yayy! New best EMA pseudo Dice: 0.707099974155426 
2024-12-08 10:26:08.653473:  
2024-12-08 10:26:08.659059: Epoch 13 
2024-12-08 10:26:08.661619: Current learning rate: 0.00882 
2024-12-08 10:26:46.116439: train_loss -0.6482 
2024-12-08 10:26:46.123039: val_loss -0.6286 
2024-12-08 10:26:46.126636: Pseudo dice [np.float32(0.8056), np.float32(0.7325), np.float32(0.8362)] 
2024-12-08 10:26:46.129692: Epoch time: 37.46 s 
2024-12-08 10:26:46.132277: Yayy! New best EMA pseudo Dice: 0.715499997138977 
2024-12-08 10:26:46.861979:  
2024-12-08 10:26:46.867579: Epoch 14 
2024-12-08 10:26:46.870116: Current learning rate: 0.00873 
2024-12-08 10:27:24.384073: train_loss -0.666 
2024-12-08 10:27:24.391682: val_loss -0.621 
2024-12-08 10:27:24.394232: Pseudo dice [np.float32(0.7942), np.float32(0.699), np.float32(0.83)] 
2024-12-08 10:27:24.396774: Epoch time: 37.52 s 
2024-12-08 10:27:24.401398: Yayy! New best EMA pseudo Dice: 0.7214000225067139 
2024-12-08 10:27:25.149024:  
2024-12-08 10:27:25.154118: Epoch 15 
2024-12-08 10:27:25.156671: Current learning rate: 0.00864 
2024-12-08 10:28:02.625729: train_loss -0.6674 
2024-12-08 10:28:02.632867: val_loss -0.6111 
2024-12-08 10:28:02.635402: Pseudo dice [np.float32(0.7994), np.float32(0.659), np.float32(0.844)] 
2024-12-08 10:28:02.639443: Epoch time: 37.48 s 
2024-12-08 10:28:02.641972: Yayy! New best EMA pseudo Dice: 0.7260000109672546 
2024-12-08 10:28:03.380197:  
2024-12-08 10:28:03.385280: Epoch 16 
2024-12-08 10:28:03.388339: Current learning rate: 0.00855 
2024-12-08 10:28:40.861672: train_loss -0.6774 
2024-12-08 10:28:40.868811: val_loss -0.5915 
2024-12-08 10:28:40.871874: Pseudo dice [np.float32(0.8032), np.float32(0.6838), np.float32(0.8116)] 
2024-12-08 10:28:40.873903: Epoch time: 37.48 s 
2024-12-08 10:28:40.876435: Yayy! New best EMA pseudo Dice: 0.7300000190734863 
2024-12-08 10:28:41.635443:  
2024-12-08 10:28:41.641025: Epoch 17 
2024-12-08 10:28:41.644614: Current learning rate: 0.00846 
2024-12-08 10:29:19.137785: train_loss -0.6791 
2024-12-08 10:29:19.143946: val_loss -0.6225 
2024-12-08 10:29:19.145975: Pseudo dice [np.float32(0.8247), np.float32(0.6622), np.float32(0.8436)] 
2024-12-08 10:29:19.150519: Epoch time: 37.5 s 
2024-12-08 10:29:19.153608: Yayy! New best EMA pseudo Dice: 0.7347000241279602 
2024-12-08 10:29:19.887921:  
2024-12-08 10:29:19.893137: Epoch 18 
2024-12-08 10:29:19.895777: Current learning rate: 0.00836 
2024-12-08 10:29:57.386531: train_loss -0.6905 
2024-12-08 10:29:57.393672: val_loss -0.6119 
2024-12-08 10:29:57.395706: Pseudo dice [np.float32(0.8009), np.float32(0.6995), np.float32(0.8363)] 
2024-12-08 10:29:57.400302: Epoch time: 37.5 s 
2024-12-08 10:29:57.403393: Yayy! New best EMA pseudo Dice: 0.7390999794006348 
2024-12-08 10:29:58.139720:  
2024-12-08 10:29:58.147333: Epoch 19 
2024-12-08 10:29:58.150946: Current learning rate: 0.00827 
2024-12-08 10:30:35.626237: train_loss -0.683 
2024-12-08 10:30:35.633828: val_loss -0.6214 
2024-12-08 10:30:35.636392: Pseudo dice [np.float32(0.817), np.float32(0.6916), np.float32(0.8383)] 
2024-12-08 10:30:35.638935: Epoch time: 37.49 s 
2024-12-08 10:30:35.644028: Yayy! New best EMA pseudo Dice: 0.7434999942779541 
2024-12-08 10:30:36.384394:  
2024-12-08 10:30:36.390485: Epoch 20 
2024-12-08 10:30:36.394544: Current learning rate: 0.00818 
2024-12-08 10:31:13.928048: train_loss -0.683 
2024-12-08 10:31:13.934640: val_loss -0.6494 
2024-12-08 10:31:13.938246: Pseudo dice [np.float32(0.8112), np.float32(0.7077), np.float32(0.8624)] 
2024-12-08 10:31:13.942286: Epoch time: 37.54 s 
2024-12-08 10:31:13.944819: Yayy! New best EMA pseudo Dice: 0.7484999895095825 
2024-12-08 10:31:14.683611:  
2024-12-08 10:31:14.688731: Epoch 21 
2024-12-08 10:31:14.693800: Current learning rate: 0.00809 
2024-12-08 10:31:52.163520: train_loss -0.6933 
2024-12-08 10:31:52.170625: val_loss -0.6276 
2024-12-08 10:31:52.174202: Pseudo dice [np.float32(0.8269), np.float32(0.6968), np.float32(0.8349)] 
2024-12-08 10:31:52.176780: Epoch time: 37.48 s 
2024-12-08 10:31:52.179319: Yayy! New best EMA pseudo Dice: 0.7523000240325928 
2024-12-08 10:31:52.893582:  
2024-12-08 10:31:52.899718: Epoch 22 
2024-12-08 10:31:52.902815: Current learning rate: 0.008 
2024-12-08 10:32:30.394623: train_loss -0.6866 
2024-12-08 10:32:30.402230: val_loss -0.6271 
2024-12-08 10:32:30.404825: Pseudo dice [np.float32(0.8191), np.float32(0.7196), np.float32(0.8229)] 
2024-12-08 10:32:30.407362: Epoch time: 37.5 s 
2024-12-08 10:32:30.411404: Yayy! New best EMA pseudo Dice: 0.7558000087738037 
2024-12-08 10:32:31.130267:  
2024-12-08 10:32:31.135336: Epoch 23 
2024-12-08 10:32:31.137882: Current learning rate: 0.0079 
2024-12-08 10:33:08.612900: train_loss -0.6949 
2024-12-08 10:33:08.620023: val_loss -0.6214 
2024-12-08 10:33:08.623099: Pseudo dice [np.float32(0.8115), np.float32(0.7055), np.float32(0.8537)] 
2024-12-08 10:33:08.627155: Epoch time: 37.48 s 
2024-12-08 10:33:08.629730: Yayy! New best EMA pseudo Dice: 0.7591999769210815 
2024-12-08 10:33:09.333700:  
2024-12-08 10:33:09.338765: Epoch 24 
2024-12-08 10:33:09.341299: Current learning rate: 0.00781 
2024-12-08 10:33:46.825821: train_loss -0.7007 
2024-12-08 10:33:46.833452: val_loss -0.6051 
2024-12-08 10:33:46.837005: Pseudo dice [np.float32(0.806), np.float32(0.6694), np.float32(0.8314)] 
2024-12-08 10:33:46.839541: Epoch time: 37.49 s 
2024-12-08 10:33:46.842109: Yayy! New best EMA pseudo Dice: 0.760200023651123 
2024-12-08 10:33:47.556589:  
2024-12-08 10:33:47.561674: Epoch 25 
2024-12-08 10:33:47.564212: Current learning rate: 0.00772 
2024-12-08 10:34:25.031919: train_loss -0.7 
2024-12-08 10:34:25.039532: val_loss -0.6275 
2024-12-08 10:34:25.042632: Pseudo dice [np.float32(0.8118), np.float32(0.6998), np.float32(0.8574)] 
2024-12-08 10:34:25.045172: Epoch time: 37.48 s 
2024-12-08 10:34:25.048219: Yayy! New best EMA pseudo Dice: 0.7631000280380249 
2024-12-08 10:34:25.763337:  
2024-12-08 10:34:25.769422: Epoch 26 
2024-12-08 10:34:25.772973: Current learning rate: 0.00763 
2024-12-08 10:35:03.252969: train_loss -0.6973 
2024-12-08 10:35:03.259127: val_loss -0.6118 
2024-12-08 10:35:03.262700: Pseudo dice [np.float32(0.8054), np.float32(0.6947), np.float32(0.8406)] 
2024-12-08 10:35:03.265744: Epoch time: 37.49 s 
2024-12-08 10:35:03.269296: Yayy! New best EMA pseudo Dice: 0.7648000121116638 
2024-12-08 10:35:03.987097:  
2024-12-08 10:35:03.992178: Epoch 27 
2024-12-08 10:35:03.995733: Current learning rate: 0.00753 
2024-12-08 10:35:41.489260: train_loss -0.6969 
2024-12-08 10:35:41.496908: val_loss -0.6218 
2024-12-08 10:35:41.499979: Pseudo dice [np.float32(0.7908), np.float32(0.7039), np.float32(0.8608)] 
2024-12-08 10:35:41.502019: Epoch time: 37.5 s 
2024-12-08 10:35:41.506070: Yayy! New best EMA pseudo Dice: 0.7669000029563904 
2024-12-08 10:35:42.380905:  
2024-12-08 10:35:42.387497: Epoch 28 
2024-12-08 10:35:42.390038: Current learning rate: 0.00744 
2024-12-08 10:36:19.860601: train_loss -0.7104 
2024-12-08 10:36:19.866674: val_loss -0.6297 
2024-12-08 10:36:19.869229: Pseudo dice [np.float32(0.8232), np.float32(0.7022), np.float32(0.8552)] 
2024-12-08 10:36:19.871761: Epoch time: 37.48 s 
2024-12-08 10:36:19.875807: Yayy! New best EMA pseudo Dice: 0.7695000171661377 
2024-12-08 10:36:20.585324:  
2024-12-08 10:36:20.592005: Epoch 29 
2024-12-08 10:36:20.594553: Current learning rate: 0.00735 
2024-12-08 10:36:58.058113: train_loss -0.7111 
2024-12-08 10:36:58.064214: val_loss -0.6133 
2024-12-08 10:36:58.067265: Pseudo dice [np.float32(0.8217), np.float32(0.6524), np.float32(0.8447)] 
2024-12-08 10:36:58.069854: Epoch time: 37.47 s 
2024-12-08 10:36:58.072917: Yayy! New best EMA pseudo Dice: 0.7699000239372253 
2024-12-08 10:36:58.792870:  
2024-12-08 10:36:58.799474: Epoch 30 
2024-12-08 10:36:58.803071: Current learning rate: 0.00725 
2024-12-08 10:37:36.273817: train_loss -0.7001 
2024-12-08 10:37:36.281406: val_loss -0.6143 
2024-12-08 10:37:36.283950: Pseudo dice [np.float32(0.8193), np.float32(0.7095), np.float32(0.855)] 
2024-12-08 10:37:36.286481: Epoch time: 37.48 s 
2024-12-08 10:37:36.289037: Yayy! New best EMA pseudo Dice: 0.7723000049591064 
2024-12-08 10:37:37.022276:  
2024-12-08 10:37:37.028357: Epoch 31 
2024-12-08 10:37:37.031466: Current learning rate: 0.00716 
2024-12-08 10:38:14.494386: train_loss -0.7238 
2024-12-08 10:38:14.500515: val_loss -0.6276 
2024-12-08 10:38:14.502570: Pseudo dice [np.float32(0.8131), np.float32(0.6906), np.float32(0.8511)] 
2024-12-08 10:38:14.505104: Epoch time: 37.47 s 
2024-12-08 10:38:14.507643: Yayy! New best EMA pseudo Dice: 0.7735999822616577 
2024-12-08 10:38:15.228699:  
2024-12-08 10:38:15.234283: Epoch 32 
2024-12-08 10:38:15.237389: Current learning rate: 0.00707 
2024-12-08 10:38:52.707242: train_loss -0.7071 
2024-12-08 10:38:52.714892: val_loss -0.6332 
2024-12-08 10:38:52.717435: Pseudo dice [np.float32(0.8228), np.float32(0.7213), np.float32(0.854)] 
2024-12-08 10:38:52.719979: Epoch time: 37.48 s 
2024-12-08 10:38:52.722509: Yayy! New best EMA pseudo Dice: 0.776199996471405 
2024-12-08 10:38:53.446928:  
2024-12-08 10:38:53.453007: Epoch 33 
2024-12-08 10:38:53.456059: Current learning rate: 0.00697 
2024-12-08 10:39:30.932001: train_loss -0.7154 
2024-12-08 10:39:30.939612: val_loss -0.6049 
2024-12-08 10:39:30.942699: Pseudo dice [np.float32(0.8277), np.float32(0.6503), np.float32(0.8484)] 
2024-12-08 10:39:30.945229: Epoch time: 37.49 s 
2024-12-08 10:39:31.501784:  
2024-12-08 10:39:31.507402: Epoch 34 
2024-12-08 10:39:31.510464: Current learning rate: 0.00688 
2024-12-08 10:40:08.995363: train_loss -0.7228 
2024-12-08 10:40:09.000434: val_loss -0.6186 
2024-12-08 10:40:09.005074: Pseudo dice [np.float32(0.8069), np.float32(0.6946), np.float32(0.8545)] 
2024-12-08 10:40:09.008127: Epoch time: 37.49 s 
2024-12-08 10:40:09.010668: Yayy! New best EMA pseudo Dice: 0.7770000100135803 
2024-12-08 10:40:09.735773:  
2024-12-08 10:40:09.742884: Epoch 35 
2024-12-08 10:40:09.745954: Current learning rate: 0.00679 
2024-12-08 10:40:47.239650: train_loss -0.7222 
2024-12-08 10:40:47.245296: val_loss -0.6363 
2024-12-08 10:40:47.248882: Pseudo dice [np.float32(0.8046), np.float32(0.7131), np.float32(0.8547)] 
2024-12-08 10:40:47.251931: Epoch time: 37.5 s 
2024-12-08 10:40:47.254984: Yayy! New best EMA pseudo Dice: 0.7784000039100647 
2024-12-08 10:40:48.123809:  
2024-12-08 10:40:48.130405: Epoch 36 
2024-12-08 10:40:48.133446: Current learning rate: 0.00669 
2024-12-08 10:41:25.589050: train_loss -0.7124 
2024-12-08 10:41:25.596682: val_loss -0.6317 
2024-12-08 10:41:25.599215: Pseudo dice [np.float32(0.8091), np.float32(0.7057), np.float32(0.8391)] 
2024-12-08 10:41:25.603267: Epoch time: 37.47 s 
2024-12-08 10:41:25.605800: Yayy! New best EMA pseudo Dice: 0.7789999842643738 
2024-12-08 10:41:26.336551:  
2024-12-08 10:41:26.343145: Epoch 37 
2024-12-08 10:41:26.346198: Current learning rate: 0.0066 
2024-12-08 10:42:03.789591: train_loss -0.7207 
2024-12-08 10:42:03.796170: val_loss -0.6428 
2024-12-08 10:42:03.799750: Pseudo dice [np.float32(0.8204), np.float32(0.7141), np.float32(0.8331)] 
2024-12-08 10:42:03.802283: Epoch time: 37.45 s 
2024-12-08 10:42:03.804816: Yayy! New best EMA pseudo Dice: 0.7799999713897705 
2024-12-08 10:42:04.539542:  
2024-12-08 10:42:04.544648: Epoch 38 
2024-12-08 10:42:04.547718: Current learning rate: 0.0065 
2024-12-08 10:42:42.001906: train_loss -0.7224 
2024-12-08 10:42:42.008522: val_loss -0.6522 
2024-12-08 10:42:42.012092: Pseudo dice [np.float32(0.8079), np.float32(0.7096), np.float32(0.8564)] 
2024-12-08 10:42:42.015654: Epoch time: 37.46 s 
2024-12-08 10:42:42.018234: Yayy! New best EMA pseudo Dice: 0.7811999917030334 
2024-12-08 10:42:42.747361:  
2024-12-08 10:42:42.752937: Epoch 39 
2024-12-08 10:42:42.755472: Current learning rate: 0.00641 
2024-12-08 10:43:20.218469: train_loss -0.7356 
2024-12-08 10:43:20.225052: val_loss -0.5949 
2024-12-08 10:43:20.227590: Pseudo dice [np.float32(0.801), np.float32(0.7206), np.float32(0.8346)] 
2024-12-08 10:43:20.231131: Epoch time: 37.47 s 
2024-12-08 10:43:20.233715: Yayy! New best EMA pseudo Dice: 0.7815999984741211 
2024-12-08 10:43:20.971092:  
2024-12-08 10:43:20.977702: Epoch 40 
2024-12-08 10:43:20.980231: Current learning rate: 0.00631 
2024-12-08 10:43:58.442030: train_loss -0.7206 
2024-12-08 10:43:58.447096: val_loss -0.6765 
2024-12-08 10:43:58.452254: Pseudo dice [np.float32(0.8315), np.float32(0.7001), np.float32(0.8799)] 
2024-12-08 10:43:58.457327: Epoch time: 37.47 s 
2024-12-08 10:43:58.462404: Yayy! New best EMA pseudo Dice: 0.7838000059127808 
2024-12-08 10:43:59.195584:  
2024-12-08 10:43:59.200709: Epoch 41 
2024-12-08 10:43:59.205285: Current learning rate: 0.00622 
2024-12-08 10:44:36.663802: train_loss -0.7253 
2024-12-08 10:44:36.671501: val_loss -0.6377 
2024-12-08 10:44:36.675594: Pseudo dice [np.float32(0.8142), np.float32(0.6926), np.float32(0.8659)] 
2024-12-08 10:44:36.680187: Epoch time: 37.47 s 
2024-12-08 10:44:36.682726: Yayy! New best EMA pseudo Dice: 0.784500002861023 
2024-12-08 10:44:37.395930:  
2024-12-08 10:44:37.401530: Epoch 42 
2024-12-08 10:44:37.404067: Current learning rate: 0.00612 
2024-12-08 10:45:14.916198: train_loss -0.7352 
2024-12-08 10:45:14.922338: val_loss -0.6563 
2024-12-08 10:45:14.924372: Pseudo dice [np.float32(0.8301), np.float32(0.6984), np.float32(0.8675)] 
2024-12-08 10:45:14.929460: Epoch time: 37.52 s 
2024-12-08 10:45:14.932011: Yayy! New best EMA pseudo Dice: 0.7858999967575073 
2024-12-08 10:45:15.651840:  
2024-12-08 10:45:15.656930: Epoch 43 
2024-12-08 10:45:15.660004: Current learning rate: 0.00603 
2024-12-08 10:45:53.146302: train_loss -0.7282 
2024-12-08 10:45:53.153965: val_loss -0.6261 
2024-12-08 10:45:53.159040: Pseudo dice [np.float32(0.8055), np.float32(0.717), np.float32(0.8318)] 
2024-12-08 10:45:53.161578: Epoch time: 37.49 s 
2024-12-08 10:45:53.851184:  
2024-12-08 10:45:53.858339: Epoch 44 
2024-12-08 10:45:53.861400: Current learning rate: 0.00593 
2024-12-08 10:46:31.329755: train_loss -0.7412 
2024-12-08 10:46:31.337388: val_loss -0.6477 
2024-12-08 10:46:31.342469: Pseudo dice [np.float32(0.8286), np.float32(0.6708), np.float32(0.8592)] 
2024-12-08 10:46:31.345032: Epoch time: 37.48 s 
2024-12-08 10:46:31.887597:  
2024-12-08 10:46:31.892757: Epoch 45 
2024-12-08 10:46:31.895808: Current learning rate: 0.00584 
2024-12-08 10:47:09.366563: train_loss -0.7299 
2024-12-08 10:47:09.371644: val_loss -0.6479 
2024-12-08 10:47:09.375239: Pseudo dice [np.float32(0.8287), np.float32(0.6991), np.float32(0.8617)] 
2024-12-08 10:47:09.377804: Epoch time: 37.48 s 
2024-12-08 10:47:09.381847: Yayy! New best EMA pseudo Dice: 0.786899983882904 
2024-12-08 10:47:10.085418:  
2024-12-08 10:47:10.092015: Epoch 46 
2024-12-08 10:47:10.095581: Current learning rate: 0.00574 
2024-12-08 10:47:47.534767: train_loss -0.7422 
2024-12-08 10:47:47.542370: val_loss -0.6352 
2024-12-08 10:47:47.544905: Pseudo dice [np.float32(0.8185), np.float32(0.704), np.float32(0.8491)] 
2024-12-08 10:47:47.550020: Epoch time: 37.45 s 
2024-12-08 10:47:47.552566: Yayy! New best EMA pseudo Dice: 0.7872999906539917 
2024-12-08 10:47:48.264240:  
2024-12-08 10:47:48.269868: Epoch 47 
2024-12-08 10:47:48.272910: Current learning rate: 0.00565 
2024-12-08 10:48:25.739498: train_loss -0.7383 
2024-12-08 10:48:25.747658: val_loss -0.6171 
2024-12-08 10:48:25.750196: Pseudo dice [np.float32(0.8106), np.float32(0.7185), np.float32(0.8476)] 
2024-12-08 10:48:25.755279: Epoch time: 37.48 s 
2024-12-08 10:48:25.757849: Yayy! New best EMA pseudo Dice: 0.7878000140190125 
2024-12-08 10:48:26.477397:  
2024-12-08 10:48:26.483996: Epoch 48 
2024-12-08 10:48:26.487549: Current learning rate: 0.00555 
2024-12-08 10:49:03.959546: train_loss -0.7406 
2024-12-08 10:49:03.965136: val_loss -0.6353 
2024-12-08 10:49:03.967163: Pseudo dice [np.float32(0.8226), np.float32(0.6929), np.float32(0.8655)] 
2024-12-08 10:49:03.971756: Epoch time: 37.48 s 
2024-12-08 10:49:03.974822: Yayy! New best EMA pseudo Dice: 0.7883999943733215 
2024-12-08 10:49:04.683441:  
2024-12-08 10:49:04.689023: Epoch 49 
2024-12-08 10:49:04.693069: Current learning rate: 0.00546 
2024-12-08 10:49:42.176324: train_loss -0.7407 
2024-12-08 10:49:42.183469: val_loss -0.6107 
2024-12-08 10:49:42.187600: Pseudo dice [np.float32(0.8152), np.float32(0.7057), np.float32(0.8379)] 
2024-12-08 10:49:42.189638: Epoch time: 37.49 s 
2024-12-08 10:49:42.891877:  
2024-12-08 10:49:42.896940: Epoch 50 
2024-12-08 10:49:42.900521: Current learning rate: 0.00536 
2024-12-08 10:50:20.377314: train_loss -0.7374 
2024-12-08 10:50:20.383393: val_loss -0.6244 
2024-12-08 10:50:20.387019: Pseudo dice [np.float32(0.8144), np.float32(0.6636), np.float32(0.8716)] 
2024-12-08 10:50:20.391089: Epoch time: 37.49 s 
2024-12-08 10:50:20.948767:  
2024-12-08 10:50:20.954354: Epoch 51 
2024-12-08 10:50:20.958919: Current learning rate: 0.00526 
2024-12-08 10:50:58.431734: train_loss -0.7428 
2024-12-08 10:50:58.438334: val_loss -0.621 
2024-12-08 10:50:58.441963: Pseudo dice [np.float32(0.8203), np.float32(0.7127), np.float32(0.839)] 
2024-12-08 10:50:58.445030: Epoch time: 37.48 s 
2024-12-08 10:50:59.143195:  
2024-12-08 10:50:59.148267: Epoch 52 
2024-12-08 10:50:59.150801: Current learning rate: 0.00517 
2024-12-08 10:51:36.622507: train_loss -0.7371 
2024-12-08 10:51:36.631159: val_loss -0.6561 
2024-12-08 10:51:36.634744: Pseudo dice [np.float32(0.8279), np.float32(0.7093), np.float32(0.8639)] 
2024-12-08 10:51:36.637797: Epoch time: 37.48 s 
2024-12-08 10:51:36.641352: Yayy! New best EMA pseudo Dice: 0.7892000079154968 
2024-12-08 10:51:37.355815:  
2024-12-08 10:51:37.360883: Epoch 53 
2024-12-08 10:51:37.364474: Current learning rate: 0.00507 
2024-12-08 10:52:14.833332: train_loss -0.7412 
2024-12-08 10:52:14.839959: val_loss -0.6441 
2024-12-08 10:52:14.843536: Pseudo dice [np.float32(0.8154), np.float32(0.7213), np.float32(0.8627)] 
2024-12-08 10:52:14.846587: Epoch time: 37.48 s 
2024-12-08 10:52:14.850137: Yayy! New best EMA pseudo Dice: 0.7903000116348267 
2024-12-08 10:52:15.562272:  
2024-12-08 10:52:15.567334: Epoch 54 
2024-12-08 10:52:15.571414: Current learning rate: 0.00497 
2024-12-08 10:52:53.046257: train_loss -0.7395 
2024-12-08 10:52:53.053393: val_loss -0.6298 
2024-12-08 10:52:53.055926: Pseudo dice [np.float32(0.8091), np.float32(0.6612), np.float32(0.8669)] 
2024-12-08 10:52:53.059984: Epoch time: 37.48 s 
2024-12-08 10:52:53.605360:  
2024-12-08 10:52:53.610945: Epoch 55 
2024-12-08 10:52:53.614002: Current learning rate: 0.00487 
2024-12-08 10:53:31.085237: train_loss -0.7476 
2024-12-08 10:53:31.092867: val_loss -0.651 
2024-12-08 10:53:31.095400: Pseudo dice [np.float32(0.8238), np.float32(0.7096), np.float32(0.8713)] 
2024-12-08 10:53:31.099493: Epoch time: 37.48 s 
2024-12-08 10:53:31.103076: Yayy! New best EMA pseudo Dice: 0.7904000282287598 
2024-12-08 10:53:31.812150:  
2024-12-08 10:53:31.817768: Epoch 56 
2024-12-08 10:53:31.820308: Current learning rate: 0.00478 
2024-12-08 10:54:09.324422: train_loss -0.7474 
2024-12-08 10:54:09.331557: val_loss -0.6341 
2024-12-08 10:54:09.334095: Pseudo dice [np.float32(0.8215), np.float32(0.7055), np.float32(0.8605)] 
2024-12-08 10:54:09.339189: Epoch time: 37.51 s 
2024-12-08 10:54:09.343252: Yayy! New best EMA pseudo Dice: 0.7908999919891357 
2024-12-08 10:54:10.058511:  
2024-12-08 10:54:10.063586: Epoch 57 
2024-12-08 10:54:10.066122: Current learning rate: 0.00468 
2024-12-08 10:54:47.554294: train_loss -0.7507 
2024-12-08 10:54:47.561945: val_loss -0.6397 
2024-12-08 10:54:47.564558: Pseudo dice [np.float32(0.8165), np.float32(0.7087), np.float32(0.8546)] 
2024-12-08 10:54:47.567106: Epoch time: 37.5 s 
2024-12-08 10:54:47.572272: Yayy! New best EMA pseudo Dice: 0.7911999821662903 
2024-12-08 10:54:48.313373:  
2024-12-08 10:54:48.318972: Epoch 58 
2024-12-08 10:54:48.322526: Current learning rate: 0.00458 
2024-12-08 10:55:25.854353: train_loss -0.757 
2024-12-08 10:55:25.861990: val_loss -0.6307 
2024-12-08 10:55:25.864553: Pseudo dice [np.float32(0.8216), np.float32(0.7029), np.float32(0.8385)] 
2024-12-08 10:55:25.869647: Epoch time: 37.54 s 
2024-12-08 10:55:26.584642:  
2024-12-08 10:55:26.590247: Epoch 59 
2024-12-08 10:55:26.592789: Current learning rate: 0.00448 
2024-12-08 10:56:04.064505: train_loss -0.7558 
2024-12-08 10:56:04.071228: val_loss -0.6646 
2024-12-08 10:56:04.075311: Pseudo dice [np.float32(0.8376), np.float32(0.7266), np.float32(0.8603)] 
2024-12-08 10:56:04.078852: Epoch time: 37.48 s 
2024-12-08 10:56:04.082417: Yayy! New best EMA pseudo Dice: 0.7925000190734863 
2024-12-08 10:56:04.806502:  
2024-12-08 10:56:04.811561: Epoch 60 
2024-12-08 10:56:04.816640: Current learning rate: 0.00438 
2024-12-08 10:56:42.293523: train_loss -0.7523 
2024-12-08 10:56:42.301208: val_loss -0.6499 
2024-12-08 10:56:42.305263: Pseudo dice [np.float32(0.8443), np.float32(0.7307), np.float32(0.8527)] 
2024-12-08 10:56:42.308825: Epoch time: 37.49 s 
2024-12-08 10:56:42.312866: Yayy! New best EMA pseudo Dice: 0.7942000031471252 
2024-12-08 10:56:43.036953:  
2024-12-08 10:56:43.042542: Epoch 61 
2024-12-08 10:56:43.046588: Current learning rate: 0.00429 
2024-12-08 10:57:20.531171: train_loss -0.7535 
2024-12-08 10:57:20.537352: val_loss -0.6424 
2024-12-08 10:57:20.541467: Pseudo dice [np.float32(0.8038), np.float32(0.7052), np.float32(0.8724)] 
2024-12-08 10:57:20.545046: Epoch time: 37.49 s 
2024-12-08 10:57:21.108804:  
2024-12-08 10:57:21.117461: Epoch 62 
2024-12-08 10:57:21.120000: Current learning rate: 0.00419 
2024-12-08 10:57:58.600190: train_loss -0.7587 
2024-12-08 10:57:58.606789: val_loss -0.651 
2024-12-08 10:57:58.610338: Pseudo dice [np.float32(0.8322), np.float32(0.7158), np.float32(0.8534)] 
2024-12-08 10:57:58.613916: Epoch time: 37.49 s 
2024-12-08 10:57:58.616462: Yayy! New best EMA pseudo Dice: 0.7947999835014343 
2024-12-08 10:57:59.341039:  
2024-12-08 10:57:59.347152: Epoch 63 
2024-12-08 10:57:59.351202: Current learning rate: 0.00409 
2024-12-08 10:58:36.814141: train_loss -0.7577 
2024-12-08 10:58:36.822355: val_loss -0.6232 
2024-12-08 10:58:36.826472: Pseudo dice [np.float32(0.8185), np.float32(0.6852), np.float32(0.8579)] 
2024-12-08 10:58:36.828508: Epoch time: 37.47 s 
2024-12-08 10:58:37.385269:  
2024-12-08 10:58:37.390921: Epoch 64 
2024-12-08 10:58:37.393466: Current learning rate: 0.00399 
2024-12-08 10:59:14.868115: train_loss -0.7566 
2024-12-08 10:59:14.873197: val_loss -0.6344 
2024-12-08 10:59:14.878313: Pseudo dice [np.float32(0.821), np.float32(0.7051), np.float32(0.8566)] 
2024-12-08 10:59:14.880855: Epoch time: 37.48 s 
2024-12-08 10:59:15.435429:  
2024-12-08 10:59:15.441107: Epoch 65 
2024-12-08 10:59:15.443660: Current learning rate: 0.00389 
2024-12-08 10:59:52.912400: train_loss -0.7546 
2024-12-08 10:59:52.920082: val_loss -0.6301 
2024-12-08 10:59:52.922621: Pseudo dice [np.float32(0.8257), np.float32(0.707), np.float32(0.8591)] 
2024-12-08 10:59:52.925152: Epoch time: 37.48 s 
2024-12-08 10:59:53.484465:  
2024-12-08 10:59:53.491089: Epoch 66 
2024-12-08 10:59:53.493629: Current learning rate: 0.00379 
2024-12-08 11:00:30.990310: train_loss -0.7613 
2024-12-08 11:00:30.998421: val_loss -0.631 
2024-12-08 11:00:31.002478: Pseudo dice [np.float32(0.816), np.float32(0.7093), np.float32(0.8579)] 
2024-12-08 11:00:31.005596: Epoch time: 37.51 s 
2024-12-08 11:00:31.704958:  
2024-12-08 11:00:31.712076: Epoch 67 
2024-12-08 11:00:31.716152: Current learning rate: 0.00369 
2024-12-08 11:01:09.186198: train_loss -0.762 
2024-12-08 11:01:09.191794: val_loss -0.6406 
2024-12-08 11:01:09.196915: Pseudo dice [np.float32(0.8308), np.float32(0.7097), np.float32(0.8601)] 
2024-12-08 11:01:09.199455: Epoch time: 37.48 s 
2024-12-08 11:01:09.204532: Yayy! New best EMA pseudo Dice: 0.7950000166893005 
2024-12-08 11:01:09.928393:  
2024-12-08 11:01:09.934518: Epoch 68 
2024-12-08 11:01:09.937052: Current learning rate: 0.00359 
2024-12-08 11:01:47.400383: train_loss -0.7677 
2024-12-08 11:01:47.407987: val_loss -0.6436 
2024-12-08 11:01:47.412104: Pseudo dice [np.float32(0.8205), np.float32(0.7261), np.float32(0.8544)] 
2024-12-08 11:01:47.415659: Epoch time: 37.47 s 
2024-12-08 11:01:47.419707: Yayy! New best EMA pseudo Dice: 0.7954999804496765 
2024-12-08 11:01:48.154934:  
2024-12-08 11:01:48.160015: Epoch 69 
2024-12-08 11:01:48.162548: Current learning rate: 0.00349 
2024-12-08 11:02:25.679950: train_loss -0.7695 
2024-12-08 11:02:25.687617: val_loss -0.6319 
2024-12-08 11:02:25.692738: Pseudo dice [np.float32(0.8291), np.float32(0.7033), np.float32(0.8571)] 
2024-12-08 11:02:25.695289: Epoch time: 37.53 s 
2024-12-08 11:02:25.700418: Yayy! New best EMA pseudo Dice: 0.7955999970436096 
2024-12-08 11:02:26.460754:  
2024-12-08 11:02:26.465851: Epoch 70 
2024-12-08 11:02:26.470926: Current learning rate: 0.00338 
2024-12-08 11:03:03.945708: train_loss -0.7666 
2024-12-08 11:03:03.951792: val_loss -0.6503 
2024-12-08 11:03:03.955870: Pseudo dice [np.float32(0.8278), np.float32(0.7077), np.float32(0.8712)] 
2024-12-08 11:03:03.959454: Epoch time: 37.49 s 
2024-12-08 11:03:03.961993: Yayy! New best EMA pseudo Dice: 0.7962999939918518 
2024-12-08 11:03:04.693394:  
2024-12-08 11:03:04.698479: Epoch 71 
2024-12-08 11:03:04.702021: Current learning rate: 0.00328 
2024-12-08 11:03:42.182182: train_loss -0.7593 
2024-12-08 11:03:42.191330: val_loss -0.6216 
2024-12-08 11:03:42.194880: Pseudo dice [np.float32(0.8251), np.float32(0.7121), np.float32(0.8527)] 
2024-12-08 11:03:42.197419: Epoch time: 37.49 s 
2024-12-08 11:03:42.201472: Yayy! New best EMA pseudo Dice: 0.7962999939918518 
2024-12-08 11:03:42.941967:  
2024-12-08 11:03:42.947085: Epoch 72 
2024-12-08 11:03:42.949629: Current learning rate: 0.00318 
2024-12-08 11:04:20.428297: train_loss -0.7705 
2024-12-08 11:04:20.433874: val_loss -0.6195 
2024-12-08 11:04:20.438958: Pseudo dice [np.float32(0.7963), np.float32(0.679), np.float32(0.8548)] 
2024-12-08 11:04:20.441494: Epoch time: 37.49 s 
2024-12-08 11:04:21.013952:  
2024-12-08 11:04:21.021609: Epoch 73 
2024-12-08 11:04:21.025175: Current learning rate: 0.00308 
2024-12-08 11:04:58.493712: train_loss -0.7685 
2024-12-08 11:04:58.499840: val_loss -0.6384 
2024-12-08 11:04:58.502378: Pseudo dice [np.float32(0.8192), np.float32(0.7099), np.float32(0.8493)] 
2024-12-08 11:04:58.504912: Epoch time: 37.48 s 
2024-12-08 11:04:59.073844:  
2024-12-08 11:04:59.079959: Epoch 74 
2024-12-08 11:04:59.083024: Current learning rate: 0.00297 
2024-12-08 11:05:36.551118: train_loss -0.762 
2024-12-08 11:05:36.557722: val_loss -0.6436 
2024-12-08 11:05:36.561282: Pseudo dice [np.float32(0.827), np.float32(0.6898), np.float32(0.8765)] 
2024-12-08 11:05:36.564336: Epoch time: 37.48 s 
2024-12-08 11:05:37.284913:  
2024-12-08 11:05:37.289471: Epoch 75 
2024-12-08 11:05:37.292550: Current learning rate: 0.00287 
2024-12-08 11:06:14.741986: train_loss -0.7729 
2024-12-08 11:06:14.748096: val_loss -0.6514 
2024-12-08 11:06:14.752168: Pseudo dice [np.float32(0.819), np.float32(0.7232), np.float32(0.8718)] 
2024-12-08 11:06:14.754708: Epoch time: 37.46 s 
2024-12-08 11:06:15.326804:  
2024-12-08 11:06:15.329857: Epoch 76 
2024-12-08 11:06:15.334960: Current learning rate: 0.00277 
2024-12-08 11:06:52.792238: train_loss -0.7632 
2024-12-08 11:06:52.799851: val_loss -0.6523 
2024-12-08 11:06:52.802393: Pseudo dice [np.float32(0.8365), np.float32(0.6974), np.float32(0.8821)] 
2024-12-08 11:06:52.804964: Epoch time: 37.47 s 
2024-12-08 11:06:52.809519: Yayy! New best EMA pseudo Dice: 0.796500027179718 
2024-12-08 11:06:53.545399:  
2024-12-08 11:06:53.550995: Epoch 77 
2024-12-08 11:06:53.555613: Current learning rate: 0.00266 
2024-12-08 11:07:31.013058: train_loss -0.7676 
2024-12-08 11:07:31.020743: val_loss -0.6496 
2024-12-08 11:07:31.023799: Pseudo dice [np.float32(0.8257), np.float32(0.6841), np.float32(0.8797)] 
2024-12-08 11:07:31.027352: Epoch time: 37.47 s 
2024-12-08 11:07:31.604894:  
2024-12-08 11:07:31.610480: Epoch 78 
2024-12-08 11:07:31.613045: Current learning rate: 0.00256 
2024-12-08 11:08:09.072494: train_loss -0.769 
2024-12-08 11:08:09.078582: val_loss -0.6549 
2024-12-08 11:08:09.081110: Pseudo dice [np.float32(0.8434), np.float32(0.6835), np.float32(0.8543)] 
2024-12-08 11:08:09.085185: Epoch time: 37.47 s 
2024-12-08 11:08:09.655000:  
2024-12-08 11:08:09.660584: Epoch 79 
2024-12-08 11:08:09.663677: Current learning rate: 0.00245 
2024-12-08 11:08:47.126977: train_loss -0.7739 
2024-12-08 11:08:47.134610: val_loss -0.6216 
2024-12-08 11:08:47.139160: Pseudo dice [np.float32(0.8335), np.float32(0.6647), np.float32(0.8607)] 
2024-12-08 11:08:47.142274: Epoch time: 37.47 s 
2024-12-08 11:08:47.712885:  
2024-12-08 11:08:47.717984: Epoch 80 
2024-12-08 11:08:47.721039: Current learning rate: 0.00235 
2024-12-08 11:09:25.182196: train_loss -0.7668 
2024-12-08 11:09:25.187799: val_loss -0.6344 
2024-12-08 11:09:25.190343: Pseudo dice [np.float32(0.8054), np.float32(0.7097), np.float32(0.8604)] 
2024-12-08 11:09:25.192931: Epoch time: 37.47 s 
2024-12-08 11:09:25.762777:  
2024-12-08 11:09:25.768406: Epoch 81 
2024-12-08 11:09:25.771463: Current learning rate: 0.00224 
2024-12-08 11:10:03.242130: train_loss -0.7744 
2024-12-08 11:10:03.249273: val_loss -0.6205 
2024-12-08 11:10:03.252332: Pseudo dice [np.float32(0.8126), np.float32(0.6582), np.float32(0.8499)] 
2024-12-08 11:10:03.254876: Epoch time: 37.48 s 
2024-12-08 11:10:03.979402:  
2024-12-08 11:10:03.985541: Epoch 82 
2024-12-08 11:10:03.988114: Current learning rate: 0.00214 
2024-12-08 11:10:41.449189: train_loss -0.7772 
2024-12-08 11:10:41.455265: val_loss -0.636 
2024-12-08 11:10:41.457797: Pseudo dice [np.float32(0.8173), np.float32(0.7064), np.float32(0.8663)] 
2024-12-08 11:10:41.461850: Epoch time: 37.47 s 
2024-12-08 11:10:42.005767:  
2024-12-08 11:10:42.011898: Epoch 83 
2024-12-08 11:10:42.015970: Current learning rate: 0.00203 
2024-12-08 11:11:19.473195: train_loss -0.7728 
2024-12-08 11:11:19.480876: val_loss -0.6453 
2024-12-08 11:11:19.483412: Pseudo dice [np.float32(0.8329), np.float32(0.7007), np.float32(0.8792)] 
2024-12-08 11:11:19.488512: Epoch time: 37.47 s 
2024-12-08 11:11:20.032805:  
2024-12-08 11:11:20.038401: Epoch 84 
2024-12-08 11:11:20.041961: Current learning rate: 0.00192 
2024-12-08 11:11:57.533246: train_loss -0.7795 
2024-12-08 11:11:57.540940: val_loss -0.618 
2024-12-08 11:11:57.546081: Pseudo dice [np.float32(0.8188), np.float32(0.6916), np.float32(0.864)] 
2024-12-08 11:11:57.548618: Epoch time: 37.5 s 
2024-12-08 11:11:58.093681:  
2024-12-08 11:11:58.099308: Epoch 85 
2024-12-08 11:11:58.101844: Current learning rate: 0.00181 
2024-12-08 11:12:35.571603: train_loss -0.7848 
2024-12-08 11:12:35.576676: val_loss -0.6223 
2024-12-08 11:12:35.579213: Pseudo dice [np.float32(0.8278), np.float32(0.7344), np.float32(0.8523)] 
2024-12-08 11:12:35.581773: Epoch time: 37.48 s 
2024-12-08 11:12:36.123501:  
2024-12-08 11:12:36.130603: Epoch 86 
2024-12-08 11:12:36.134349: Current learning rate: 0.0017 
2024-12-08 11:13:13.582556: train_loss -0.7815 
2024-12-08 11:13:13.590235: val_loss -0.6317 
2024-12-08 11:13:13.594797: Pseudo dice [np.float32(0.8139), np.float32(0.696), np.float32(0.8819)] 
2024-12-08 11:13:13.597945: Epoch time: 37.46 s 
2024-12-08 11:13:14.138980:  
2024-12-08 11:13:14.144061: Epoch 87 
2024-12-08 11:13:14.147115: Current learning rate: 0.00159 
2024-12-08 11:13:51.606536: train_loss -0.7791 
2024-12-08 11:13:51.612165: val_loss -0.6445 
2024-12-08 11:13:51.614700: Pseudo dice [np.float32(0.8195), np.float32(0.7054), np.float32(0.8604)] 
2024-12-08 11:13:51.619242: Epoch time: 37.47 s 
2024-12-08 11:13:52.159355:  
2024-12-08 11:13:52.165512: Epoch 88 
2024-12-08 11:13:52.169599: Current learning rate: 0.00148 
2024-12-08 11:14:29.654741: train_loss -0.7806 
2024-12-08 11:14:29.662349: val_loss -0.6516 
2024-12-08 11:14:29.664945: Pseudo dice [np.float32(0.8389), np.float32(0.7233), np.float32(0.8476)] 
2024-12-08 11:14:29.669506: Epoch time: 37.5 s 
2024-12-08 11:14:30.214738:  
2024-12-08 11:14:30.220336: Epoch 89 
2024-12-08 11:14:30.222873: Current learning rate: 0.00137 
2024-12-08 11:15:07.705173: train_loss -0.7802 
2024-12-08 11:15:07.710250: val_loss -0.6334 
2024-12-08 11:15:07.715321: Pseudo dice [np.float32(0.8217), np.float32(0.6775), np.float32(0.8568)] 
2024-12-08 11:15:07.717858: Epoch time: 37.49 s 
2024-12-08 11:15:08.409252:  
2024-12-08 11:15:08.415337: Epoch 90 
2024-12-08 11:15:08.419465: Current learning rate: 0.00126 
2024-12-08 11:15:45.881406: train_loss -0.7794 
2024-12-08 11:15:45.888583: val_loss -0.6815 
2024-12-08 11:15:45.893650: Pseudo dice [np.float32(0.8525), np.float32(0.747), np.float32(0.8587)] 
2024-12-08 11:15:45.897690: Epoch time: 37.47 s 
2024-12-08 11:15:45.901316: Yayy! New best EMA pseudo Dice: 0.7973999977111816 
2024-12-08 11:15:46.616763:  
2024-12-08 11:15:46.623356: Epoch 91 
2024-12-08 11:15:46.626909: Current learning rate: 0.00115 
2024-12-08 11:16:24.082496: train_loss -0.7804 
2024-12-08 11:16:24.090685: val_loss -0.6567 
2024-12-08 11:16:24.094788: Pseudo dice [np.float32(0.8426), np.float32(0.7131), np.float32(0.8503)] 
2024-12-08 11:16:24.097333: Epoch time: 37.47 s 
2024-12-08 11:16:24.100881: Yayy! New best EMA pseudo Dice: 0.7979000210762024 
2024-12-08 11:16:24.819213:  
2024-12-08 11:16:24.824283: Epoch 92 
2024-12-08 11:16:24.826852: Current learning rate: 0.00103 
2024-12-08 11:17:02.303217: train_loss -0.7854 
2024-12-08 11:17:02.308807: val_loss -0.6288 
2024-12-08 11:17:02.311894: Pseudo dice [np.float32(0.8134), np.float32(0.7166), np.float32(0.8754)] 
2024-12-08 11:17:02.315947: Epoch time: 37.49 s 
2024-12-08 11:17:02.318999: Yayy! New best EMA pseudo Dice: 0.79830002784729 
2024-12-08 11:17:03.033141:  
2024-12-08 11:17:03.038739: Epoch 93 
2024-12-08 11:17:03.041274: Current learning rate: 0.00091 
2024-12-08 11:17:40.513380: train_loss -0.7795 
2024-12-08 11:17:40.521120: val_loss -0.6007 
2024-12-08 11:17:40.523785: Pseudo dice [np.float32(0.7856), np.float32(0.6878), np.float32(0.8542)] 
2024-12-08 11:17:40.526341: Epoch time: 37.48 s 
2024-12-08 11:17:41.069171:  
2024-12-08 11:17:41.074233: Epoch 94 
2024-12-08 11:17:41.077280: Current learning rate: 0.00079 
2024-12-08 11:18:18.557781: train_loss -0.7851 
2024-12-08 11:18:18.562873: val_loss -0.6648 
2024-12-08 11:18:18.567452: Pseudo dice [np.float32(0.8395), np.float32(0.7265), np.float32(0.8479)] 
2024-12-08 11:18:18.569991: Epoch time: 37.49 s 
2024-12-08 11:18:19.115934:  
2024-12-08 11:18:19.121517: Epoch 95 
2024-12-08 11:18:19.125113: Current learning rate: 0.00067 
2024-12-08 11:18:56.603355: train_loss -0.7899 
2024-12-08 11:18:56.613035: val_loss -0.6684 
2024-12-08 11:18:56.616103: Pseudo dice [np.float32(0.8354), np.float32(0.7618), np.float32(0.8747)] 
2024-12-08 11:18:56.621181: Epoch time: 37.49 s 
2024-12-08 11:18:56.623716: Yayy! New best EMA pseudo Dice: 0.7996000051498413 
2024-12-08 11:18:57.342092:  
2024-12-08 11:18:57.347762: Epoch 96 
2024-12-08 11:18:57.350299: Current learning rate: 0.00055 
2024-12-08 11:19:34.826484: train_loss -0.7824 
2024-12-08 11:19:34.834630: val_loss -0.6493 
2024-12-08 11:19:34.837218: Pseudo dice [np.float32(0.8351), np.float32(0.7048), np.float32(0.8664)] 
2024-12-08 11:19:34.839750: Epoch time: 37.49 s 
2024-12-08 11:19:34.844324: Yayy! New best EMA pseudo Dice: 0.7998999953269958 
2024-12-08 11:19:35.559683:  
2024-12-08 11:19:35.565779: Epoch 97 
2024-12-08 11:19:35.568320: Current learning rate: 0.00043 
2024-12-08 11:20:13.073561: train_loss -0.7893 
2024-12-08 11:20:13.079661: val_loss -0.6308 
2024-12-08 11:20:13.082207: Pseudo dice [np.float32(0.8303), np.float32(0.7002), np.float32(0.8663)] 
2024-12-08 11:20:13.086257: Epoch time: 37.52 s 
2024-12-08 11:20:13.650652:  
2024-12-08 11:20:13.657753: Epoch 98 
2024-12-08 11:20:13.661340: Current learning rate: 0.0003 
2024-12-08 11:20:51.128725: train_loss -0.7872 
2024-12-08 11:20:51.136431: val_loss -0.6153 
2024-12-08 11:20:51.140012: Pseudo dice [np.float32(0.8189), np.float32(0.6925), np.float32(0.8719)] 
2024-12-08 11:20:51.142546: Epoch time: 37.48 s 
2024-12-08 11:20:51.852810:  
2024-12-08 11:20:51.859468: Epoch 99 
2024-12-08 11:20:51.862525: Current learning rate: 0.00016 
2024-12-08 11:21:29.349633: train_loss -0.7886 
2024-12-08 11:21:29.357250: val_loss -0.624 
2024-12-08 11:21:29.360824: Pseudo dice [np.float32(0.8239), np.float32(0.7188), np.float32(0.8683)] 
2024-12-08 11:21:29.363396: Epoch time: 37.5 s 
2024-12-08 11:21:30.124003: Training done. 
2024-12-08 11:21:30.164086: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-08 11:21:30.170100: The split file contains 5 splits. 
2024-12-08 11:21:30.176114: Desired fold for training: 0 
2024-12-08 11:21:30.182122: This split has 387 training and 97 validation cases. 
2024-12-08 11:21:30.186130: predicting BRATS_010 
2024-12-08 11:21:30.190135: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2024-12-08 11:21:31.009706: predicting BRATS_011 
2024-12-08 11:21:31.024816: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2024-12-08 11:21:31.205033: predicting BRATS_012 
2024-12-08 11:21:31.221107: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-08 11:21:31.408386: predicting BRATS_018 
2024-12-08 11:21:31.416788: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2024-12-08 11:21:31.611811: predicting BRATS_020 
2024-12-08 11:21:31.622224: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2024-12-08 11:21:31.815729: predicting BRATS_028 
2024-12-08 11:21:31.823961: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2024-12-08 11:21:32.019331: predicting BRATS_029 
2024-12-08 11:21:32.031359: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2024-12-08 11:21:32.222405: predicting BRATS_032 
2024-12-08 11:21:32.230635: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2024-12-08 11:21:32.425507: predicting BRATS_034 
2024-12-08 11:21:32.433693: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2024-12-08 11:21:32.630072: predicting BRATS_041 
2024-12-08 11:21:32.638224: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2024-12-08 11:21:34.738756: predicting BRATS_042 
2024-12-08 11:21:34.752290: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2024-12-08 11:21:35.113886: predicting BRATS_047 
2024-12-08 11:21:35.130299: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-08 11:21:35.339685: predicting BRATS_049 
2024-12-08 11:21:35.353719: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-08 11:21:35.569551: predicting BRATS_053 
2024-12-08 11:21:35.587268: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 11:21:35.780148: predicting BRATS_056 
2024-12-08 11:21:35.794273: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 11:21:35.989204: predicting BRATS_057 
2024-12-08 11:21:36.003229: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 11:21:36.195902: predicting BRATS_067 
2024-12-08 11:21:36.211510: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-08 11:21:36.408397: predicting BRATS_069 
2024-12-08 11:21:36.420390: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-08 11:21:36.613112: predicting BRATS_085 
2024-12-08 11:21:36.627135: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2024-12-08 11:21:36.741081: predicting BRATS_086 
2024-12-08 11:21:36.753416: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2024-12-08 11:21:36.948977: predicting BRATS_088 
2024-12-08 11:21:36.960992: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2024-12-08 11:21:37.154696: predicting BRATS_091 
2024-12-08 11:21:37.164710: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2024-12-08 11:21:37.358665: predicting BRATS_098 
2024-12-08 11:21:37.376825: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2024-12-08 11:21:37.565547: predicting BRATS_100 
2024-12-08 11:21:37.578312: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-08 11:21:37.687919: predicting BRATS_101 
2024-12-08 11:21:37.701941: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-08 11:21:37.809406: predicting BRATS_102 
2024-12-08 11:21:37.829529: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2024-12-08 11:21:38.029933: predicting BRATS_104 
2024-12-08 11:21:38.039943: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2024-12-08 11:21:38.237852: predicting BRATS_111 
2024-12-08 11:21:38.251866: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2024-12-08 11:21:38.443756: predicting BRATS_116 
2024-12-08 11:21:38.460512: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2024-12-08 11:21:38.652791: predicting BRATS_135 
2024-12-08 11:21:38.664804: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2024-12-08 11:21:38.858489: predicting BRATS_136 
2024-12-08 11:21:38.872502: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2024-12-08 11:21:39.062016: predicting BRATS_138 
2024-12-08 11:21:39.074088: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2024-12-08 11:21:39.263770: predicting BRATS_145 
2024-12-08 11:21:39.282184: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2024-12-08 11:21:39.473804: predicting BRATS_149 
2024-12-08 11:21:39.487440: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2024-12-08 11:21:39.682648: predicting BRATS_155 
2024-12-08 11:21:39.696403: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-08 11:21:39.891142: predicting BRATS_157 
2024-12-08 11:21:39.904104: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-08 11:21:40.099889: predicting BRATS_158 
2024-12-08 11:21:40.110449: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-08 11:21:40.306634: predicting BRATS_159 
2024-12-08 11:21:40.318214: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-08 11:21:40.512614: predicting BRATS_163 
2024-12-08 11:21:40.524626: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2024-12-08 11:21:40.718183: predicting BRATS_164 
2024-12-08 11:21:40.730432: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2024-12-08 11:21:40.920347: predicting BRATS_169 
2024-12-08 11:21:40.933875: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2024-12-08 11:21:41.127858: predicting BRATS_176 
2024-12-08 11:21:41.140083: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2024-12-08 11:21:41.335821: predicting BRATS_181 
2024-12-08 11:21:41.347833: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2024-12-08 11:21:41.544105: predicting BRATS_183 
2024-12-08 11:21:41.556116: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 11:21:41.745788: predicting BRATS_184 
2024-12-08 11:21:41.764155: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 11:21:41.958649: predicting BRATS_187 
2024-12-08 11:21:41.973029: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 11:21:42.164747: predicting BRATS_192 
2024-12-08 11:21:42.178762: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2024-12-08 11:21:42.363965: predicting BRATS_198 
2024-12-08 11:21:42.380662: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2024-12-08 11:21:42.578599: predicting BRATS_207 
2024-12-08 11:21:42.591007: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-08 11:21:42.775940: predicting BRATS_208 
2024-12-08 11:21:42.794271: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-08 11:21:42.989746: predicting BRATS_218 
2024-12-08 11:21:43.003760: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2024-12-08 11:21:43.198962: predicting BRATS_220 
2024-12-08 11:21:43.212493: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2024-12-08 11:21:43.406636: predicting BRATS_224 
2024-12-08 11:21:43.420659: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2024-12-08 11:21:43.616419: predicting BRATS_230 
2024-12-08 11:21:43.628437: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2024-12-08 11:21:43.821047: predicting BRATS_271 
2024-12-08 11:21:43.833061: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2024-12-08 11:21:44.024964: predicting BRATS_282 
2024-12-08 11:21:44.043056: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2024-12-08 11:21:44.234404: predicting BRATS_284 
2024-12-08 11:21:44.251072: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2024-12-08 11:21:44.436361: predicting BRATS_287 
2024-12-08 11:21:44.451429: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-08 11:21:44.646536: predicting BRATS_290 
2024-12-08 11:21:44.660551: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2024-12-08 11:21:44.854692: predicting BRATS_291 
2024-12-08 11:21:44.864703: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2024-12-08 11:21:45.051658: predicting BRATS_292 
2024-12-08 11:21:45.062443: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2024-12-08 11:21:45.258267: predicting BRATS_293 
2024-12-08 11:21:45.270279: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2024-12-08 11:21:45.471033: predicting BRATS_300 
2024-12-08 11:21:45.484786: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2024-12-08 11:21:45.677407: predicting BRATS_305 
2024-12-08 11:21:45.695494: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2024-12-08 11:21:45.892153: predicting BRATS_311 
2024-12-08 11:21:45.906173: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2024-12-08 11:21:46.095003: predicting BRATS_314 
2024-12-08 11:21:46.114316: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2024-12-08 11:21:46.311650: predicting BRATS_321 
2024-12-08 11:21:46.325664: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2024-12-08 11:21:46.519872: predicting BRATS_328 
2024-12-08 11:21:46.531890: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2024-12-08 11:21:46.643203: predicting BRATS_329 
2024-12-08 11:21:46.657436: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2024-12-08 11:21:46.850940: predicting BRATS_335 
2024-12-08 11:21:46.865079: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2024-12-08 11:21:47.061314: predicting BRATS_343 
2024-12-08 11:21:47.073326: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2024-12-08 11:21:47.264039: predicting BRATS_350 
2024-12-08 11:21:47.281827: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2024-12-08 11:21:47.402288: predicting BRATS_351 
2024-12-08 11:21:47.412303: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2024-12-08 11:21:47.526620: predicting BRATS_356 
2024-12-08 11:21:47.539497: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2024-12-08 11:21:47.661640: predicting BRATS_366 
2024-12-08 11:21:47.673654: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2024-12-08 11:21:47.874701: predicting BRATS_367 
2024-12-08 11:21:47.886714: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2024-12-08 11:21:48.081646: predicting BRATS_374 
2024-12-08 11:21:48.094784: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2024-12-08 11:21:48.289876: predicting BRATS_376 
2024-12-08 11:21:48.301891: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2024-12-08 11:21:48.498577: predicting BRATS_377 
2024-12-08 11:21:48.512591: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2024-12-08 11:21:48.708079: predicting BRATS_378 
2024-12-08 11:21:48.720424: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2024-12-08 11:21:48.915529: predicting BRATS_379 
2024-12-08 11:21:48.927084: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2024-12-08 11:21:49.124345: predicting BRATS_384 
2024-12-08 11:21:49.138448: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2024-12-08 11:21:49.328999: predicting BRATS_386 
2024-12-08 11:21:49.345023: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2024-12-08 11:21:49.539681: predicting BRATS_394 
2024-12-08 11:21:49.551434: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-08 11:21:49.745632: predicting BRATS_398 
2024-12-08 11:21:49.759698: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2024-12-08 11:21:49.949710: predicting BRATS_400 
2024-12-08 11:21:49.963237: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2024-12-08 11:21:50.159477: predicting BRATS_432 
2024-12-08 11:21:50.171490: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2024-12-08 11:21:50.368049: predicting BRATS_437 
2024-12-08 11:21:50.379450: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-08 11:21:50.566674: predicting BRATS_445 
2024-12-08 11:21:50.583275: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2024-12-08 11:21:50.775976: predicting BRATS_446 
2024-12-08 11:21:50.788037: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2024-12-08 11:21:50.983856: predicting BRATS_450 
2024-12-08 11:21:50.995869: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2024-12-08 11:21:51.188057: predicting BRATS_452 
2024-12-08 11:21:51.200069: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2024-12-08 11:21:51.392554: predicting BRATS_460 
2024-12-08 11:21:51.406151: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2024-12-08 11:21:51.601158: predicting BRATS_470 
2024-12-08 11:21:51.615220: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2024-12-08 11:21:51.810123: predicting BRATS_472 
2024-12-08 11:21:51.823255: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2024-12-08 11:21:52.012547: predicting BRATS_473 
2024-12-08 11:21:52.027066: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2024-12-08 11:21:52.133396: predicting BRATS_482 
2024-12-08 11:21:52.149727: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2024-12-08 11:21:59.299987: Validation complete 
2024-12-08 11:21:59.308097: Mean Validation Dice:  0.7180338707698715 
