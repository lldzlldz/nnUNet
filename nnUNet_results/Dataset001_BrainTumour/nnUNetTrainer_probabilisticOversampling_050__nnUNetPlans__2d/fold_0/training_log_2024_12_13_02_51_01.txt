2024-12-13 02:51:01.353728: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.33 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-13 02:51:01.358730: self.oversample_foreground_percent 0.3333333333333333 
2024-12-13 02:51:01.363237: do_dummy_2d_data_aug: False 
2024-12-13 02:51:01.371737: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-13 02:51:01.376745: The split file contains 5 splits. 
2024-12-13 02:51:01.380749: Desired fold for training: 0 
2024-12-13 02:51:01.383255: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 105, 'patch_size': [192, 160], 'median_image_size_in_voxels': [169.0, 138.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2024-12-13 02:51:36.199722: unpacking dataset... 
2024-12-13 02:51:36.455912: unpacking done... 
2024-12-13 02:51:38.025667:  
2024-12-13 02:51:38.032181: Epoch 0 
2024-12-13 02:51:38.035691: Current learning rate: 0.01 
2024-12-13 02:52:23.435411: train_loss -0.2985 
2024-12-13 02:52:23.443144: val_loss -0.5957 
2024-12-13 02:52:23.450270: Pseudo dice [np.float32(0.7324), np.float32(0.5811), np.float32(0.8005)] 
2024-12-13 02:52:23.456040: Epoch time: 45.41 s 
2024-12-13 02:52:23.461131: Yayy! New best EMA pseudo Dice: 0.7046999931335449 
2024-12-13 02:52:24.086796:  
2024-12-13 02:52:24.092860: Epoch 1 
2024-12-13 02:52:24.095974: Current learning rate: 0.00991 
2024-12-13 02:53:04.918539: train_loss -0.6748 
2024-12-13 02:53:04.926226: val_loss -0.6902 
2024-12-13 02:53:04.932342: Pseudo dice [np.float32(0.792), np.float32(0.683), np.float32(0.8407)] 
2024-12-13 02:53:04.938738: Epoch time: 40.83 s 
2024-12-13 02:53:04.946460: Yayy! New best EMA pseudo Dice: 0.7113999724388123 
2024-12-13 02:53:05.671937:  
2024-12-13 02:53:05.678001: Epoch 2 
2024-12-13 02:53:05.684699: Current learning rate: 0.00982 
2024-12-13 02:53:46.225362: train_loss -0.7195 
2024-12-13 02:53:46.233085: val_loss -0.7078 
2024-12-13 02:53:46.239707: Pseudo dice [np.float32(0.7994), np.float32(0.7), np.float32(0.8487)] 
2024-12-13 02:53:46.247366: Epoch time: 40.55 s 
2024-12-13 02:53:46.252213: Yayy! New best EMA pseudo Dice: 0.718500018119812 
2024-12-13 02:53:46.970579:  
2024-12-13 02:53:46.976124: Epoch 3 
2024-12-13 02:53:46.982719: Current learning rate: 0.00973 
2024-12-13 02:54:28.458467: train_loss -0.7372 
2024-12-13 02:54:28.467068: val_loss -0.725 
2024-12-13 02:54:28.474596: Pseudo dice [np.float32(0.811), np.float32(0.7141), np.float32(0.8572)] 
2024-12-13 02:54:28.481637: Epoch time: 41.49 s 
2024-12-13 02:54:28.486655: Yayy! New best EMA pseudo Dice: 0.7261000275611877 
2024-12-13 02:54:29.213210:  
2024-12-13 02:54:29.219733: Epoch 4 
2024-12-13 02:54:29.226254: Current learning rate: 0.00964 
2024-12-13 02:55:09.032209: train_loss -0.7459 
2024-12-13 02:55:09.040252: val_loss -0.7215 
2024-12-13 02:55:09.045356: Pseudo dice [np.float32(0.8131), np.float32(0.7016), np.float32(0.8574)] 
2024-12-13 02:55:09.050375: Epoch time: 39.82 s 
2024-12-13 02:55:09.058006: Yayy! New best EMA pseudo Dice: 0.7325999736785889 
2024-12-13 02:55:09.921100:  
2024-12-13 02:55:09.926618: Epoch 5 
2024-12-13 02:55:09.930130: Current learning rate: 0.00955 
2024-12-13 02:55:49.436018: train_loss -0.753 
2024-12-13 02:55:49.442036: val_loss -0.7271 
2024-12-13 02:55:49.448590: Pseudo dice [np.float32(0.814), np.float32(0.7107), np.float32(0.8585)] 
2024-12-13 02:55:49.455638: Epoch time: 39.52 s 
2024-12-13 02:55:49.461173: Yayy! New best EMA pseudo Dice: 0.7386999726295471 
2024-12-13 02:55:50.126008:  
2024-12-13 02:55:50.132523: Epoch 6 
2024-12-13 02:55:50.137031: Current learning rate: 0.00946 
2024-12-13 02:56:30.404455: train_loss -0.7573 
2024-12-13 02:56:30.412105: val_loss -0.7272 
2024-12-13 02:56:30.418766: Pseudo dice [np.float32(0.8188), np.float32(0.703), np.float32(0.8609)] 
2024-12-13 02:56:30.425425: Epoch time: 40.28 s 
2024-12-13 02:56:30.432030: Yayy! New best EMA pseudo Dice: 0.7443000078201294 
2024-12-13 02:56:31.116392:  
2024-12-13 02:56:31.121927: Epoch 7 
2024-12-13 02:56:31.125442: Current learning rate: 0.00937 
2024-12-13 02:57:11.009637: train_loss -0.761 
2024-12-13 02:57:11.016248: val_loss -0.7304 
2024-12-13 02:57:11.021376: Pseudo dice [np.float32(0.8153), np.float32(0.719), np.float32(0.8597)] 
2024-12-13 02:57:11.027077: Epoch time: 39.89 s 
2024-12-13 02:57:11.032676: Yayy! New best EMA pseudo Dice: 0.7497000098228455 
2024-12-13 02:57:11.731305:  
2024-12-13 02:57:11.736939: Epoch 8 
2024-12-13 02:57:11.741971: Current learning rate: 0.00928 
2024-12-13 02:57:51.941524: train_loss -0.7685 
2024-12-13 02:57:51.950224: val_loss -0.7328 
2024-12-13 02:57:51.955714: Pseudo dice [np.float32(0.8205), np.float32(0.7058), np.float32(0.8652)] 
2024-12-13 02:57:51.961871: Epoch time: 40.21 s 
2024-12-13 02:57:51.966954: Yayy! New best EMA pseudo Dice: 0.7544000148773193 
2024-12-13 02:57:52.681882:  
2024-12-13 02:57:52.687458: Epoch 9 
2024-12-13 02:57:52.691475: Current learning rate: 0.00919 
2024-12-13 02:58:32.275709: train_loss -0.7708 
2024-12-13 02:58:32.285339: val_loss -0.7368 
2024-12-13 02:58:32.292023: Pseudo dice [np.float32(0.8189), np.float32(0.7174), np.float32(0.8648)] 
2024-12-13 02:58:32.297105: Epoch time: 39.59 s 
2024-12-13 02:58:32.300670: Yayy! New best EMA pseudo Dice: 0.7590000033378601 
2024-12-13 02:58:33.016208:  
2024-12-13 02:58:33.022752: Epoch 10 
2024-12-13 02:58:33.027853: Current learning rate: 0.0091 
2024-12-13 02:59:14.159403: train_loss -0.7722 
2024-12-13 02:59:14.167095: val_loss -0.738 
2024-12-13 02:59:14.173029: Pseudo dice [np.float32(0.8179), np.float32(0.7244), np.float32(0.8643)] 
2024-12-13 02:59:14.178617: Epoch time: 41.14 s 
2024-12-13 02:59:14.184638: Yayy! New best EMA pseudo Dice: 0.7633000016212463 
2024-12-13 02:59:14.875349:  
2024-12-13 02:59:14.880883: Epoch 11 
2024-12-13 02:59:14.886462: Current learning rate: 0.009 
2024-12-13 02:59:54.638380: train_loss -0.7767 
2024-12-13 02:59:54.646785: val_loss -0.7339 
2024-12-13 02:59:54.654311: Pseudo dice [np.float32(0.8189), np.float32(0.7166), np.float32(0.8608)] 
2024-12-13 02:59:54.658958: Epoch time: 39.76 s 
2024-12-13 02:59:54.664497: Yayy! New best EMA pseudo Dice: 0.7669000029563904 
2024-12-13 02:59:55.392068:  
2024-12-13 02:59:55.397106: Epoch 12 
2024-12-13 02:59:55.402849: Current learning rate: 0.00891 
2024-12-13 03:00:37.329063: train_loss -0.7774 
2024-12-13 03:00:37.335131: val_loss -0.7359 
2024-12-13 03:00:37.342047: Pseudo dice [np.float32(0.8195), np.float32(0.7212), np.float32(0.8661)] 
2024-12-13 03:00:37.348073: Epoch time: 41.94 s 
2024-12-13 03:00:37.354671: Yayy! New best EMA pseudo Dice: 0.7703999876976013 
2024-12-13 03:00:38.230620:  
2024-12-13 03:00:38.235633: Epoch 13 
2024-12-13 03:00:38.239666: Current learning rate: 0.00882 
2024-12-13 03:01:18.523169: train_loss -0.7795 
2024-12-13 03:01:18.530220: val_loss -0.7402 
2024-12-13 03:01:18.535743: Pseudo dice [np.float32(0.8247), np.float32(0.7198), np.float32(0.8645)] 
2024-12-13 03:01:18.540517: Epoch time: 40.29 s 
2024-12-13 03:01:18.546198: Yayy! New best EMA pseudo Dice: 0.7736999988555908 
2024-12-13 03:01:19.225771:  
2024-12-13 03:01:19.231833: Epoch 14 
2024-12-13 03:01:19.234878: Current learning rate: 0.00873 
2024-12-13 03:01:58.976963: train_loss -0.7811 
2024-12-13 03:01:58.983598: val_loss -0.7431 
2024-12-13 03:01:58.990112: Pseudo dice [np.float32(0.8268), np.float32(0.7203), np.float32(0.8673)] 
2024-12-13 03:01:58.995124: Epoch time: 39.75 s 
2024-12-13 03:01:59.001147: Yayy! New best EMA pseudo Dice: 0.7767999768257141 
2024-12-13 03:01:59.702359:  
2024-12-13 03:01:59.709448: Epoch 15 
2024-12-13 03:01:59.713074: Current learning rate: 0.00864 
2024-12-13 03:02:40.169572: train_loss -0.7832 
2024-12-13 03:02:40.177243: val_loss -0.7489 
2024-12-13 03:02:40.182890: Pseudo dice [np.float32(0.8265), np.float32(0.7333), np.float32(0.8724)] 
2024-12-13 03:02:40.189513: Epoch time: 40.47 s 
2024-12-13 03:02:40.197136: Yayy! New best EMA pseudo Dice: 0.7802000045776367 
2024-12-13 03:02:40.947714:  
2024-12-13 03:02:40.953272: Epoch 16 
2024-12-13 03:02:40.957858: Current learning rate: 0.00855 
2024-12-13 03:03:21.182421: train_loss -0.7851 
2024-12-13 03:03:21.188454: val_loss -0.7447 
2024-12-13 03:03:21.194601: Pseudo dice [np.float32(0.8264), np.float32(0.7235), np.float32(0.8704)] 
2024-12-13 03:03:21.201766: Epoch time: 40.23 s 
2024-12-13 03:03:21.208949: Yayy! New best EMA pseudo Dice: 0.782800018787384 
2024-12-13 03:03:21.909294:  
2024-12-13 03:03:21.915846: Epoch 17 
2024-12-13 03:03:21.920928: Current learning rate: 0.00846 
2024-12-13 03:04:01.398926: train_loss -0.7884 
2024-12-13 03:04:01.406800: val_loss -0.7412 
2024-12-13 03:04:01.412509: Pseudo dice [np.float32(0.8275), np.float32(0.7155), np.float32(0.8682)] 
2024-12-13 03:04:01.419079: Epoch time: 39.49 s 
2024-12-13 03:04:01.426608: Yayy! New best EMA pseudo Dice: 0.7849000096321106 
2024-12-13 03:04:02.145850:  
2024-12-13 03:04:02.152416: Epoch 18 
2024-12-13 03:04:02.156020: Current learning rate: 0.00836 
2024-12-13 03:04:42.694947: train_loss -0.7863 
2024-12-13 03:04:42.700964: val_loss -0.7391 
2024-12-13 03:04:42.706056: Pseudo dice [np.float32(0.8238), np.float32(0.7256), np.float32(0.8615)] 
2024-12-13 03:04:42.712497: Epoch time: 40.55 s 
2024-12-13 03:04:42.718522: Yayy! New best EMA pseudo Dice: 0.7868000268936157 
2024-12-13 03:04:43.420054:  
2024-12-13 03:04:43.428871: Epoch 19 
2024-12-13 03:04:43.432915: Current learning rate: 0.00827 
2024-12-13 03:05:23.514129: train_loss -0.791 
2024-12-13 03:05:23.522269: val_loss -0.7384 
2024-12-13 03:05:23.527983: Pseudo dice [np.float32(0.8222), np.float32(0.7228), np.float32(0.8624)] 
2024-12-13 03:05:23.533040: Epoch time: 40.09 s 
2024-12-13 03:05:23.539176: Yayy! New best EMA pseudo Dice: 0.7883999943733215 
2024-12-13 03:05:24.252732:  
2024-12-13 03:05:24.258292: Epoch 20 
2024-12-13 03:05:24.262397: Current learning rate: 0.00818 
2024-12-13 03:06:04.747733: train_loss -0.7924 
2024-12-13 03:06:04.756495: val_loss -0.7482 
2024-12-13 03:06:04.763106: Pseudo dice [np.float32(0.8261), np.float32(0.7352), np.float32(0.8738)] 
2024-12-13 03:06:04.768769: Epoch time: 40.5 s 
2024-12-13 03:06:04.774405: Yayy! New best EMA pseudo Dice: 0.7907000184059143 
2024-12-13 03:06:05.674951:  
2024-12-13 03:06:05.679788: Epoch 21 
2024-12-13 03:06:05.685810: Current learning rate: 0.00809 
2024-12-13 03:06:45.428971: train_loss -0.7928 
2024-12-13 03:06:45.436646: val_loss -0.7416 
2024-12-13 03:06:45.444268: Pseudo dice [np.float32(0.8255), np.float32(0.7118), np.float32(0.8708)] 
2024-12-13 03:06:45.449888: Epoch time: 39.76 s 
2024-12-13 03:06:45.456511: Yayy! New best EMA pseudo Dice: 0.7918999791145325 
2024-12-13 03:06:46.148360:  
2024-12-13 03:06:46.154925: Epoch 22 
2024-12-13 03:06:46.159159: Current learning rate: 0.008 
2024-12-13 03:07:26.392574: train_loss -0.7959 
2024-12-13 03:07:26.399220: val_loss -0.7431 
2024-12-13 03:07:26.405894: Pseudo dice [np.float32(0.8232), np.float32(0.7254), np.float32(0.8681)] 
2024-12-13 03:07:26.412486: Epoch time: 40.25 s 
2024-12-13 03:07:26.418081: Yayy! New best EMA pseudo Dice: 0.7932999730110168 
2024-12-13 03:07:27.116570:  
2024-12-13 03:07:27.121517: Epoch 23 
2024-12-13 03:07:27.125539: Current learning rate: 0.0079 
2024-12-13 03:08:06.853076: train_loss -0.7959 
2024-12-13 03:08:06.861749: val_loss -0.7465 
2024-12-13 03:08:06.869450: Pseudo dice [np.float32(0.8274), np.float32(0.7225), np.float32(0.8722)] 
2024-12-13 03:08:06.876843: Epoch time: 39.74 s 
2024-12-13 03:08:06.882534: Yayy! New best EMA pseudo Dice: 0.794700026512146 
2024-12-13 03:08:07.563408:  
2024-12-13 03:08:07.569712: Epoch 24 
2024-12-13 03:08:07.574904: Current learning rate: 0.00781 
2024-12-13 03:08:48.369965: train_loss -0.7972 
2024-12-13 03:08:48.379785: val_loss -0.7426 
2024-12-13 03:08:48.386951: Pseudo dice [np.float32(0.8246), np.float32(0.726), np.float32(0.8683)] 
2024-12-13 03:08:48.390988: Epoch time: 40.81 s 
2024-12-13 03:08:48.396071: Yayy! New best EMA pseudo Dice: 0.795799970626831 
2024-12-13 03:08:49.065436:  
2024-12-13 03:08:49.071054: Epoch 25 
2024-12-13 03:08:49.076135: Current learning rate: 0.00772 
2024-12-13 03:09:27.184270: train_loss -0.7989 
2024-12-13 03:09:27.190310: val_loss -0.7457 
2024-12-13 03:09:27.194328: Pseudo dice [np.float32(0.8243), np.float32(0.7268), np.float32(0.8702)] 
2024-12-13 03:09:27.197848: Epoch time: 38.12 s 
2024-12-13 03:09:27.201866: Yayy! New best EMA pseudo Dice: 0.796999990940094 
2024-12-13 03:09:27.854809:  
2024-12-13 03:09:27.860842: Epoch 26 
2024-12-13 03:09:27.865860: Current learning rate: 0.00763 
2024-12-13 03:10:06.906270: train_loss -0.7997 
2024-12-13 03:10:06.914509: val_loss -0.7476 
2024-12-13 03:10:06.922177: Pseudo dice [np.float32(0.8239), np.float32(0.7327), np.float32(0.871)] 
2024-12-13 03:10:06.929198: Epoch time: 39.05 s 
2024-12-13 03:10:06.934763: Yayy! New best EMA pseudo Dice: 0.7982000112533569 
2024-12-13 03:10:07.639931:  
2024-12-13 03:10:07.645451: Epoch 27 
2024-12-13 03:10:07.651476: Current learning rate: 0.00753 
2024-12-13 03:10:47.893362: train_loss -0.7994 
2024-12-13 03:10:47.900901: val_loss -0.7412 
2024-12-13 03:10:47.906001: Pseudo dice [np.float32(0.8253), np.float32(0.7225), np.float32(0.8671)] 
2024-12-13 03:10:47.911107: Epoch time: 40.25 s 
2024-12-13 03:10:47.916253: Yayy! New best EMA pseudo Dice: 0.7989000082015991 
2024-12-13 03:10:48.603745:  
2024-12-13 03:10:48.610963: Epoch 28 
2024-12-13 03:10:48.614499: Current learning rate: 0.00744 
2024-12-13 03:11:29.510407: train_loss -0.8024 
2024-12-13 03:11:29.518032: val_loss -0.747 
2024-12-13 03:11:29.524058: Pseudo dice [np.float32(0.8263), np.float32(0.7275), np.float32(0.8705)] 
2024-12-13 03:11:29.530169: Epoch time: 40.91 s 
2024-12-13 03:11:29.535695: Yayy! New best EMA pseudo Dice: 0.7997999787330627 
2024-12-13 03:11:30.428396:  
2024-12-13 03:11:30.435107: Epoch 29 
2024-12-13 03:11:30.438200: Current learning rate: 0.00735 
2024-12-13 03:12:11.362960: train_loss -0.8042 
2024-12-13 03:12:11.369548: val_loss -0.7458 
2024-12-13 03:12:11.375772: Pseudo dice [np.float32(0.8282), np.float32(0.726), np.float32(0.8673)] 
2024-12-13 03:12:11.382542: Epoch time: 40.93 s 
2024-12-13 03:12:11.387552: Yayy! New best EMA pseudo Dice: 0.8004999756813049 
2024-12-13 03:12:12.097868:  
2024-12-13 03:12:12.102881: Epoch 30 
2024-12-13 03:12:12.108401: Current learning rate: 0.00725 
2024-12-13 03:12:51.269245: train_loss -0.8038 
2024-12-13 03:12:51.278418: val_loss -0.7445 
2024-12-13 03:12:51.284621: Pseudo dice [np.float32(0.8226), np.float32(0.7285), np.float32(0.8683)] 
2024-12-13 03:12:51.289723: Epoch time: 39.17 s 
2024-12-13 03:12:51.294822: Yayy! New best EMA pseudo Dice: 0.8011000156402588 
2024-12-13 03:12:51.979551:  
2024-12-13 03:12:51.986137: Epoch 31 
2024-12-13 03:12:51.991150: Current learning rate: 0.00716 
2024-12-13 03:13:30.993724: train_loss -0.8045 
2024-12-13 03:13:31.000241: val_loss -0.7459 
2024-12-13 03:13:31.005255: Pseudo dice [np.float32(0.8278), np.float32(0.7273), np.float32(0.8693)] 
2024-12-13 03:13:31.012284: Epoch time: 39.01 s 
2024-12-13 03:13:31.016308: Yayy! New best EMA pseudo Dice: 0.801800012588501 
2024-12-13 03:13:31.710943:  
2024-12-13 03:13:31.715981: Epoch 32 
2024-12-13 03:13:31.722001: Current learning rate: 0.00707 
2024-12-13 03:14:11.505873: train_loss -0.8052 
2024-12-13 03:14:11.514166: val_loss -0.749 
2024-12-13 03:14:11.519763: Pseudo dice [np.float32(0.8237), np.float32(0.7339), np.float32(0.8706)] 
2024-12-13 03:14:11.525403: Epoch time: 39.8 s 
2024-12-13 03:14:11.530463: Yayy! New best EMA pseudo Dice: 0.8026000261306763 
2024-12-13 03:14:12.244886:  
2024-12-13 03:14:12.251480: Epoch 33 
2024-12-13 03:14:12.256069: Current learning rate: 0.00697 
2024-12-13 03:14:53.276681: train_loss -0.8058 
2024-12-13 03:14:53.287415: val_loss -0.7487 
2024-12-13 03:14:53.292932: Pseudo dice [np.float32(0.8257), np.float32(0.7384), np.float32(0.8672)] 
2024-12-13 03:14:53.300897: Epoch time: 41.03 s 
2024-12-13 03:14:53.305471: Yayy! New best EMA pseudo Dice: 0.8033999800682068 
2024-12-13 03:14:54.035097:  
2024-12-13 03:14:54.040662: Epoch 34 
2024-12-13 03:14:54.045767: Current learning rate: 0.00688 
2024-12-13 03:15:35.314331: train_loss -0.8074 
2024-12-13 03:15:35.320894: val_loss -0.7505 
2024-12-13 03:15:35.327605: Pseudo dice [np.float32(0.826), np.float32(0.7395), np.float32(0.8709)] 
2024-12-13 03:15:35.334236: Epoch time: 41.28 s 
2024-12-13 03:15:35.339831: Yayy! New best EMA pseudo Dice: 0.8041999936103821 
2024-12-13 03:15:36.055176:  
2024-12-13 03:15:36.061696: Epoch 35 
2024-12-13 03:15:36.065211: Current learning rate: 0.00679 
2024-12-13 03:16:16.516759: train_loss -0.8076 
2024-12-13 03:16:16.525363: val_loss -0.7475 
2024-12-13 03:16:16.530884: Pseudo dice [np.float32(0.8292), np.float32(0.7222), np.float32(0.8735)] 
2024-12-13 03:16:16.538459: Epoch time: 40.46 s 
2024-12-13 03:16:16.545522: Yayy! New best EMA pseudo Dice: 0.8046000003814697 
2024-12-13 03:16:17.284319:  
2024-12-13 03:16:17.289839: Epoch 36 
2024-12-13 03:16:17.293353: Current learning rate: 0.00669 
2024-12-13 03:16:52.467620: train_loss -0.8085 
2024-12-13 03:16:52.473796: val_loss -0.7378 
2024-12-13 03:16:52.478343: Pseudo dice [np.float32(0.824), np.float32(0.7189), np.float32(0.8627)] 
2024-12-13 03:16:52.483090: Epoch time: 35.18 s 
2024-12-13 03:16:53.047443:  
2024-12-13 03:16:53.055109: Epoch 37 
2024-12-13 03:16:53.059660: Current learning rate: 0.0066 
2024-12-13 03:17:26.189798: train_loss -0.8091 
2024-12-13 03:17:26.195492: val_loss -0.7479 
2024-12-13 03:17:26.199512: Pseudo dice [np.float32(0.8294), np.float32(0.7294), np.float32(0.8719)] 
2024-12-13 03:17:26.202668: Epoch time: 33.14 s 
2024-12-13 03:17:26.205173: Yayy! New best EMA pseudo Dice: 0.8050000071525574 
2024-12-13 03:17:27.072695:  
2024-12-13 03:17:27.078766: Epoch 38 
2024-12-13 03:17:27.081403: Current learning rate: 0.0065 
2024-12-13 03:17:59.999496: train_loss -0.811 
2024-12-13 03:18:00.005828: val_loss -0.7484 
2024-12-13 03:18:00.010536: Pseudo dice [np.float32(0.8265), np.float32(0.726), np.float32(0.8757)] 
2024-12-13 03:18:00.014567: Epoch time: 32.93 s 
2024-12-13 03:18:00.017651: Yayy! New best EMA pseudo Dice: 0.805400013923645 
2024-12-13 03:18:00.728890:  
2024-12-13 03:18:00.733991: Epoch 39 
2024-12-13 03:18:00.736497: Current learning rate: 0.00641 
2024-12-13 03:18:33.294184: train_loss -0.8097 
2024-12-13 03:18:33.299707: val_loss -0.7504 
2024-12-13 03:18:33.303373: Pseudo dice [np.float32(0.8264), np.float32(0.7317), np.float32(0.8739)] 
2024-12-13 03:18:33.305917: Epoch time: 32.57 s 
2024-12-13 03:18:33.308499: Yayy! New best EMA pseudo Dice: 0.805899977684021 
2024-12-13 03:18:34.017557:  
2024-12-13 03:18:34.023099: Epoch 40 
2024-12-13 03:18:34.025655: Current learning rate: 0.00631 
2024-12-13 03:19:07.835849: train_loss -0.8098 
2024-12-13 03:19:07.840865: val_loss -0.7471 
2024-12-13 03:19:07.845514: Pseudo dice [np.float32(0.8289), np.float32(0.7231), np.float32(0.876)] 
2024-12-13 03:19:07.849056: Epoch time: 33.82 s 
2024-12-13 03:19:07.851607: Yayy! New best EMA pseudo Dice: 0.8062999844551086 
2024-12-13 03:19:08.585266:  
2024-12-13 03:19:08.590281: Epoch 41 
2024-12-13 03:19:08.593294: Current learning rate: 0.00622 
2024-12-13 03:19:42.722201: train_loss -0.8124 
2024-12-13 03:19:42.727917: val_loss -0.7431 
2024-12-13 03:19:42.732088: Pseudo dice [np.float32(0.8238), np.float32(0.7227), np.float32(0.871)] 
2024-12-13 03:19:42.735621: Epoch time: 34.14 s 
2024-12-13 03:19:43.309443:  
2024-12-13 03:19:43.314607: Epoch 42 
2024-12-13 03:19:43.319630: Current learning rate: 0.00612 
2024-12-13 03:20:15.911613: train_loss -0.813 
2024-12-13 03:20:15.918752: val_loss -0.7449 
2024-12-13 03:20:15.921509: Pseudo dice [np.float32(0.8265), np.float32(0.7269), np.float32(0.8719)] 
2024-12-13 03:20:15.926082: Epoch time: 32.6 s 
2024-12-13 03:20:15.929174: Yayy! New best EMA pseudo Dice: 0.8064000010490417 
2024-12-13 03:20:16.622535:  
2024-12-13 03:20:16.628117: Epoch 43 
2024-12-13 03:20:16.631237: Current learning rate: 0.00603 
2024-12-13 03:20:49.029602: train_loss -0.8122 
2024-12-13 03:20:49.035810: val_loss -0.7476 
2024-12-13 03:20:49.039406: Pseudo dice [np.float32(0.8246), np.float32(0.7336), np.float32(0.8713)] 
2024-12-13 03:20:49.042600: Epoch time: 32.41 s 
2024-12-13 03:20:49.045639: Yayy! New best EMA pseudo Dice: 0.8068000078201294 
2024-12-13 03:20:49.736206:  
2024-12-13 03:20:49.741356: Epoch 44 
2024-12-13 03:20:49.744399: Current learning rate: 0.00593 
2024-12-13 03:21:22.586776: train_loss -0.8139 
2024-12-13 03:21:22.592435: val_loss -0.739 
2024-12-13 03:21:22.596448: Pseudo dice [np.float32(0.8235), np.float32(0.7179), np.float32(0.8679)] 
2024-12-13 03:21:22.599964: Epoch time: 32.85 s 
2024-12-13 03:21:23.479041:  
2024-12-13 03:21:23.484667: Epoch 45 
2024-12-13 03:21:23.488208: Current learning rate: 0.00584 
2024-12-13 03:21:55.905073: train_loss -0.8141 
2024-12-13 03:21:55.910740: val_loss -0.7463 
2024-12-13 03:21:55.913928: Pseudo dice [np.float32(0.8243), np.float32(0.7364), np.float32(0.8654)] 
2024-12-13 03:21:55.917453: Epoch time: 32.43 s 
2024-12-13 03:21:56.472197:  
2024-12-13 03:21:56.477234: Epoch 46 
2024-12-13 03:21:56.480622: Current learning rate: 0.00574 
2024-12-13 03:22:28.895520: train_loss -0.8145 
2024-12-13 03:22:28.900661: val_loss -0.7464 
2024-12-13 03:22:28.904789: Pseudo dice [np.float32(0.829), np.float32(0.7269), np.float32(0.871)] 
2024-12-13 03:22:28.907354: Epoch time: 32.42 s 
2024-12-13 03:22:28.910883: Yayy! New best EMA pseudo Dice: 0.8069000244140625 
2024-12-13 03:22:29.585971:  
2024-12-13 03:22:29.591127: Epoch 47 
2024-12-13 03:22:29.594719: Current learning rate: 0.00565 
2024-12-13 03:23:01.989389: train_loss -0.8169 
2024-12-13 03:23:01.996977: val_loss -0.7502 
2024-12-13 03:23:02.000770: Pseudo dice [np.float32(0.825), np.float32(0.7351), np.float32(0.8749)] 
2024-12-13 03:23:02.004437: Epoch time: 32.4 s 
2024-12-13 03:23:02.007480: Yayy! New best EMA pseudo Dice: 0.8073999881744385 
2024-12-13 03:23:02.674960:  
2024-12-13 03:23:02.680524: Epoch 48 
2024-12-13 03:23:02.683694: Current learning rate: 0.00555 
2024-12-13 03:23:35.085428: train_loss -0.8162 
2024-12-13 03:23:35.090488: val_loss -0.7424 
2024-12-13 03:23:35.094208: Pseudo dice [np.float32(0.8234), np.float32(0.7248), np.float32(0.872)] 
2024-12-13 03:23:35.097731: Epoch time: 32.41 s 
2024-12-13 03:23:35.664271:  
2024-12-13 03:23:35.670342: Epoch 49 
2024-12-13 03:23:35.674001: Current learning rate: 0.00546 
2024-12-13 03:24:08.053500: train_loss -0.8174 
2024-12-13 03:24:08.060894: val_loss -0.747 
2024-12-13 03:24:08.063917: Pseudo dice [np.float32(0.8244), np.float32(0.7288), np.float32(0.8747)] 
2024-12-13 03:24:08.067446: Epoch time: 32.39 s 
2024-12-13 03:24:08.181764: Yayy! New best EMA pseudo Dice: 0.8075000047683716 
2024-12-13 03:24:08.856728:  
2024-12-13 03:24:08.861860: Epoch 50 
2024-12-13 03:24:08.865384: Current learning rate: 0.00536 
2024-12-13 03:24:41.286220: train_loss -0.8179 
2024-12-13 03:24:41.294081: val_loss -0.7518 
2024-12-13 03:24:41.297642: Pseudo dice [np.float32(0.8274), np.float32(0.7386), np.float32(0.8725)] 
2024-12-13 03:24:41.301838: Epoch time: 32.43 s 
2024-12-13 03:24:41.305351: Yayy! New best EMA pseudo Dice: 0.8080000281333923 
2024-12-13 03:24:42.000511:  
2024-12-13 03:24:42.006148: Epoch 51 
2024-12-13 03:24:42.010188: Current learning rate: 0.00526 
2024-12-13 03:25:14.441823: train_loss -0.8173 
2024-12-13 03:25:14.448339: val_loss -0.7412 
2024-12-13 03:25:14.452991: Pseudo dice [np.float32(0.8236), np.float32(0.714), np.float32(0.8731)] 
2024-12-13 03:25:14.457005: Epoch time: 32.44 s 
2024-12-13 03:25:15.179437:  
2024-12-13 03:25:15.183048: Epoch 52 
2024-12-13 03:25:15.187058: Current learning rate: 0.00517 
2024-12-13 03:25:47.440253: train_loss -0.8178 
2024-12-13 03:25:47.446382: val_loss -0.7471 
2024-12-13 03:25:47.449912: Pseudo dice [np.float32(0.8276), np.float32(0.7249), np.float32(0.8722)] 
2024-12-13 03:25:47.453621: Epoch time: 32.26 s 
2024-12-13 03:25:48.036990:  
2024-12-13 03:25:48.043149: Epoch 53 
2024-12-13 03:25:48.046195: Current learning rate: 0.00507 
2024-12-13 03:26:20.294321: train_loss -0.8169 
2024-12-13 03:26:20.609201: val_loss -0.7384 
2024-12-13 03:26:20.614324: Pseudo dice [np.float32(0.8233), np.float32(0.714), np.float32(0.8679)] 
2024-12-13 03:26:20.617406: Epoch time: 32.26 s 
2024-12-13 03:26:21.349515:  
2024-12-13 03:26:21.356209: Epoch 54 
2024-12-13 03:26:21.360302: Current learning rate: 0.00497 
2024-12-13 03:26:53.568947: train_loss -0.8193 
2024-12-13 03:26:53.575347: val_loss -0.7448 
2024-12-13 03:26:53.579988: Pseudo dice [np.float32(0.8288), np.float32(0.7248), np.float32(0.8693)] 
2024-12-13 03:26:53.583709: Epoch time: 32.22 s 
2024-12-13 03:26:54.168818:  
2024-12-13 03:26:54.174035: Epoch 55 
2024-12-13 03:26:54.176543: Current learning rate: 0.00487 
2024-12-13 03:27:26.412871: train_loss -0.8208 
2024-12-13 03:27:26.419703: val_loss -0.749 
2024-12-13 03:27:26.422873: Pseudo dice [np.float32(0.8289), np.float32(0.7319), np.float32(0.8737)] 
2024-12-13 03:27:26.426440: Epoch time: 32.25 s 
2024-12-13 03:27:26.991834:  
2024-12-13 03:27:26.996846: Epoch 56 
2024-12-13 03:27:27.000931: Current learning rate: 0.00478 
2024-12-13 03:27:59.213079: train_loss -0.8197 
2024-12-13 03:27:59.219154: val_loss -0.747 
2024-12-13 03:27:59.222883: Pseudo dice [np.float32(0.8254), np.float32(0.7304), np.float32(0.8723)] 
2024-12-13 03:27:59.226407: Epoch time: 32.22 s 
2024-12-13 03:27:59.805748:  
2024-12-13 03:27:59.810885: Epoch 57 
2024-12-13 03:27:59.814439: Current learning rate: 0.00468 
2024-12-13 03:28:32.036868: train_loss -0.8191 
2024-12-13 03:28:32.051778: val_loss -0.7423 
2024-12-13 03:28:32.056504: Pseudo dice [np.float32(0.8266), np.float32(0.7235), np.float32(0.8667)] 
2024-12-13 03:28:32.059613: Epoch time: 32.23 s 
2024-12-13 03:28:32.645216:  
2024-12-13 03:28:32.650268: Epoch 58 
2024-12-13 03:28:32.653373: Current learning rate: 0.00458 
2024-12-13 03:29:04.861474: train_loss -0.8213 
2024-12-13 03:29:04.868780: val_loss -0.7476 
2024-12-13 03:29:04.873011: Pseudo dice [np.float32(0.8265), np.float32(0.7326), np.float32(0.8733)] 
2024-12-13 03:29:04.876629: Epoch time: 32.22 s 
2024-12-13 03:29:05.450469:  
2024-12-13 03:29:05.456135: Epoch 59 
2024-12-13 03:29:05.459181: Current learning rate: 0.00448 
2024-12-13 03:29:37.679674: train_loss -0.8215 
2024-12-13 03:29:37.686917: val_loss -0.746 
2024-12-13 03:29:37.690634: Pseudo dice [np.float32(0.8279), np.float32(0.723), np.float32(0.8724)] 
2024-12-13 03:29:37.694194: Epoch time: 32.23 s 
2024-12-13 03:29:38.267430:  
2024-12-13 03:29:38.274069: Epoch 60 
2024-12-13 03:29:38.276609: Current learning rate: 0.00438 
2024-12-13 03:30:10.493797: train_loss -0.8226 
2024-12-13 03:30:10.501981: val_loss -0.7499 
2024-12-13 03:30:10.506002: Pseudo dice [np.float32(0.8275), np.float32(0.7317), np.float32(0.8744)] 
2024-12-13 03:30:10.510050: Epoch time: 32.23 s 
2024-12-13 03:30:10.512705: Yayy! New best EMA pseudo Dice: 0.8082000017166138 
2024-12-13 03:30:11.223193:  
2024-12-13 03:30:11.228800: Epoch 61 
2024-12-13 03:30:11.231448: Current learning rate: 0.00429 
2024-12-13 03:30:43.443865: train_loss -0.8226 
2024-12-13 03:30:43.450798: val_loss -0.7433 
2024-12-13 03:30:43.454850: Pseudo dice [np.float32(0.8225), np.float32(0.7261), np.float32(0.8742)] 
2024-12-13 03:30:43.458404: Epoch time: 32.22 s 
2024-12-13 03:30:44.211307:  
2024-12-13 03:30:44.216840: Epoch 62 
2024-12-13 03:30:44.220428: Current learning rate: 0.00419 
2024-12-13 03:31:16.434267: train_loss -0.8223 
2024-12-13 03:31:16.439981: val_loss -0.7431 
2024-12-13 03:31:16.443605: Pseudo dice [np.float32(0.8267), np.float32(0.7239), np.float32(0.8705)] 
2024-12-13 03:31:16.446656: Epoch time: 32.22 s 
2024-12-13 03:31:17.024060:  
2024-12-13 03:31:17.029598: Epoch 63 
2024-12-13 03:31:17.032106: Current learning rate: 0.00409 
2024-12-13 03:31:49.233390: train_loss -0.8244 
2024-12-13 03:31:49.240434: val_loss -0.7511 
2024-12-13 03:31:49.245123: Pseudo dice [np.float32(0.8312), np.float32(0.7295), np.float32(0.8737)] 
2024-12-13 03:31:49.248648: Epoch time: 32.21 s 
2024-12-13 03:31:49.252320: Yayy! New best EMA pseudo Dice: 0.8083999752998352 
2024-12-13 03:31:49.943083:  
2024-12-13 03:31:49.948131: Epoch 64 
2024-12-13 03:31:49.951256: Current learning rate: 0.00399 
2024-12-13 03:32:27.276526: train_loss -0.8235 
2024-12-13 03:32:27.282671: val_loss -0.7445 
2024-12-13 03:32:27.286682: Pseudo dice [np.float32(0.8247), np.float32(0.7217), np.float32(0.8749)] 
2024-12-13 03:32:27.289188: Epoch time: 37.33 s 
2024-12-13 03:32:27.858077:  
2024-12-13 03:32:27.864043: Epoch 65 
2024-12-13 03:32:27.867587: Current learning rate: 0.00389 
2024-12-13 03:33:00.225151: train_loss -0.8242 
2024-12-13 03:33:00.232405: val_loss -0.7463 
2024-12-13 03:33:00.234955: Pseudo dice [np.float32(0.8249), np.float32(0.7312), np.float32(0.8714)] 
2024-12-13 03:33:00.239527: Epoch time: 32.37 s 
2024-12-13 03:33:00.818652:  
2024-12-13 03:33:00.824275: Epoch 66 
2024-12-13 03:33:00.828311: Current learning rate: 0.00379 
2024-12-13 03:33:33.177982: train_loss -0.8232 
2024-12-13 03:33:33.184155: val_loss -0.7475 
2024-12-13 03:33:33.188176: Pseudo dice [np.float32(0.8284), np.float32(0.7313), np.float32(0.8708)] 
2024-12-13 03:33:33.191854: Epoch time: 32.36 s 
2024-12-13 03:33:33.195396: Yayy! New best EMA pseudo Dice: 0.8084999918937683 
2024-12-13 03:33:33.879984:  
2024-12-13 03:33:33.884125: Epoch 67 
2024-12-13 03:33:33.886706: Current learning rate: 0.00369 
2024-12-13 03:34:06.232234: train_loss -0.8249 
2024-12-13 03:34:06.237245: val_loss -0.7447 
2024-12-13 03:34:06.240755: Pseudo dice [np.float32(0.8272), np.float32(0.7184), np.float32(0.8756)] 
2024-12-13 03:34:06.244426: Epoch time: 32.35 s 
2024-12-13 03:34:06.826789:  
2024-12-13 03:34:06.832423: Epoch 68 
2024-12-13 03:34:06.834959: Current learning rate: 0.00359 
2024-12-13 03:34:39.172560: train_loss -0.8246 
2024-12-13 03:34:39.179101: val_loss -0.7501 
2024-12-13 03:34:39.182758: Pseudo dice [np.float32(0.829), np.float32(0.7328), np.float32(0.8732)] 
2024-12-13 03:34:39.185830: Epoch time: 32.35 s 
2024-12-13 03:34:39.189359: Yayy! New best EMA pseudo Dice: 0.8087000250816345 
2024-12-13 03:34:39.879937:  
2024-12-13 03:34:39.885109: Epoch 69 
2024-12-13 03:34:39.888682: Current learning rate: 0.00349 
2024-12-13 03:35:12.348648: train_loss -0.8255 
2024-12-13 03:35:12.353855: val_loss -0.7448 
2024-12-13 03:35:12.357922: Pseudo dice [np.float32(0.8267), np.float32(0.7258), np.float32(0.871)] 
2024-12-13 03:35:12.361040: Epoch time: 32.47 s 
2024-12-13 03:35:13.098522:  
2024-12-13 03:35:13.104646: Epoch 70 
2024-12-13 03:35:13.107686: Current learning rate: 0.00338 
2024-12-13 03:35:45.451726: train_loss -0.8259 
2024-12-13 03:35:45.456280: val_loss -0.7459 
2024-12-13 03:35:45.459830: Pseudo dice [np.float32(0.8245), np.float32(0.7283), np.float32(0.8744)] 
2024-12-13 03:35:45.464456: Epoch time: 32.35 s 
2024-12-13 03:35:46.037006:  
2024-12-13 03:35:46.042137: Epoch 71 
2024-12-13 03:35:46.045195: Current learning rate: 0.00328 
2024-12-13 03:36:18.374192: train_loss -0.8258 
2024-12-13 03:36:18.379800: val_loss -0.7457 
2024-12-13 03:36:18.383512: Pseudo dice [np.float32(0.8223), np.float32(0.7321), np.float32(0.873)] 
2024-12-13 03:36:18.387527: Epoch time: 32.34 s 
2024-12-13 03:36:18.391169: Yayy! New best EMA pseudo Dice: 0.8087000250816345 
2024-12-13 03:36:19.074065:  
2024-12-13 03:36:19.079624: Epoch 72 
2024-12-13 03:36:19.082765: Current learning rate: 0.00318 
2024-12-13 03:36:51.412196: train_loss -0.8267 
2024-12-13 03:36:51.418271: val_loss -0.7448 
2024-12-13 03:36:51.421434: Pseudo dice [np.float32(0.8269), np.float32(0.7242), np.float32(0.8726)] 
2024-12-13 03:36:51.425468: Epoch time: 32.34 s 
2024-12-13 03:36:52.012951:  
2024-12-13 03:36:52.017999: Epoch 73 
2024-12-13 03:36:52.021617: Current learning rate: 0.00308 
2024-12-13 03:37:24.363213: train_loss -0.8276 
2024-12-13 03:37:24.369225: val_loss -0.751 
2024-12-13 03:37:24.372863: Pseudo dice [np.float32(0.8301), np.float32(0.7368), np.float32(0.8727)] 
2024-12-13 03:37:24.376875: Epoch time: 32.35 s 
2024-12-13 03:37:24.380390: Yayy! New best EMA pseudo Dice: 0.8090999722480774 
2024-12-13 03:37:25.072642:  
2024-12-13 03:37:25.076698: Epoch 74 
2024-12-13 03:37:25.079736: Current learning rate: 0.00297 
2024-12-13 03:37:57.397089: train_loss -0.8273 
2024-12-13 03:37:57.403300: val_loss -0.742 
2024-12-13 03:37:57.406870: Pseudo dice [np.float32(0.8233), np.float32(0.7236), np.float32(0.8715)] 
2024-12-13 03:37:57.410403: Epoch time: 32.33 s 
2024-12-13 03:37:57.983807:  
2024-12-13 03:37:57.988818: Epoch 75 
2024-12-13 03:37:57.992328: Current learning rate: 0.00287 
2024-12-13 03:38:30.331740: train_loss -0.8287 
2024-12-13 03:38:30.336781: val_loss -0.7403 
2024-12-13 03:38:30.340462: Pseudo dice [np.float32(0.8232), np.float32(0.7201), np.float32(0.8699)] 
2024-12-13 03:38:30.343536: Epoch time: 32.35 s 
2024-12-13 03:38:30.912898:  
2024-12-13 03:38:30.917954: Epoch 76 
2024-12-13 03:38:30.921574: Current learning rate: 0.00277 
2024-12-13 03:39:03.284843: train_loss -0.8295 
2024-12-13 03:39:03.291529: val_loss -0.7462 
2024-12-13 03:39:03.294047: Pseudo dice [np.float32(0.8267), np.float32(0.7302), np.float32(0.8725)] 
2024-12-13 03:39:03.297569: Epoch time: 32.37 s 
2024-12-13 03:39:03.877078:  
2024-12-13 03:39:03.881675: Epoch 77 
2024-12-13 03:39:03.884179: Current learning rate: 0.00266 
2024-12-13 03:39:36.227881: train_loss -0.8289 
2024-12-13 03:39:36.234585: val_loss -0.7448 
2024-12-13 03:39:36.237608: Pseudo dice [np.float32(0.8263), np.float32(0.729), np.float32(0.8725)] 
2024-12-13 03:39:36.240737: Epoch time: 32.35 s 
2024-12-13 03:39:36.990101:  
2024-12-13 03:39:36.995787: Epoch 78 
2024-12-13 03:39:36.998839: Current learning rate: 0.00256 
2024-12-13 03:40:09.347426: train_loss -0.8281 
2024-12-13 03:40:09.352632: val_loss -0.7491 
2024-12-13 03:40:09.355667: Pseudo dice [np.float32(0.8285), np.float32(0.7297), np.float32(0.8734)] 
2024-12-13 03:40:09.358696: Epoch time: 32.36 s 
2024-12-13 03:40:09.941980:  
2024-12-13 03:40:09.946992: Epoch 79 
2024-12-13 03:40:09.950501: Current learning rate: 0.00245 
2024-12-13 03:40:42.316219: train_loss -0.8294 
2024-12-13 03:40:42.323965: val_loss -0.7476 
2024-12-13 03:40:42.327493: Pseudo dice [np.float32(0.8273), np.float32(0.7299), np.float32(0.875)] 
2024-12-13 03:40:42.330647: Epoch time: 32.38 s 
2024-12-13 03:40:42.927588:  
2024-12-13 03:40:42.933244: Epoch 80 
2024-12-13 03:40:42.936287: Current learning rate: 0.00235 
2024-12-13 03:41:15.367594: train_loss -0.8292 
2024-12-13 03:41:15.372251: val_loss -0.7393 
2024-12-13 03:41:15.375856: Pseudo dice [np.float32(0.8232), np.float32(0.7157), np.float32(0.8737)] 
2024-12-13 03:41:15.379398: Epoch time: 32.44 s 
2024-12-13 03:41:15.967877:  
2024-12-13 03:41:15.972903: Epoch 81 
2024-12-13 03:41:15.976575: Current learning rate: 0.00224 
2024-12-13 03:41:48.177469: train_loss -0.8307 
2024-12-13 03:41:48.183689: val_loss -0.745 
2024-12-13 03:41:48.187254: Pseudo dice [np.float32(0.8265), np.float32(0.7281), np.float32(0.8729)] 
2024-12-13 03:41:48.190291: Epoch time: 32.21 s 
2024-12-13 03:41:48.777779:  
2024-12-13 03:41:48.782865: Epoch 82 
2024-12-13 03:41:48.785156: Current learning rate: 0.00214 
2024-12-13 03:42:20.972140: train_loss -0.8303 
2024-12-13 03:42:20.979236: val_loss -0.7433 
2024-12-13 03:42:20.982440: Pseudo dice [np.float32(0.825), np.float32(0.7214), np.float32(0.872)] 
2024-12-13 03:42:20.984464: Epoch time: 32.19 s 
2024-12-13 03:42:21.538555:  
2024-12-13 03:42:21.543685: Epoch 83 
2024-12-13 03:42:21.546208: Current learning rate: 0.00203 
2024-12-13 03:42:53.765637: train_loss -0.8305 
2024-12-13 03:42:53.771794: val_loss -0.7437 
2024-12-13 03:42:53.774328: Pseudo dice [np.float32(0.8249), np.float32(0.7254), np.float32(0.8719)] 
2024-12-13 03:42:53.778430: Epoch time: 32.23 s 
2024-12-13 03:42:54.332689:  
2024-12-13 03:42:54.337707: Epoch 84 
2024-12-13 03:42:54.341284: Current learning rate: 0.00192 
2024-12-13 03:43:26.527204: train_loss -0.8307 
2024-12-13 03:43:26.533403: val_loss -0.7455 
2024-12-13 03:43:26.536944: Pseudo dice [np.float32(0.8247), np.float32(0.7306), np.float32(0.8728)] 
2024-12-13 03:43:26.539978: Epoch time: 32.2 s 
2024-12-13 03:43:27.099193:  
2024-12-13 03:43:27.104280: Epoch 85 
2024-12-13 03:43:27.107788: Current learning rate: 0.00181 
2024-12-13 03:43:59.287964: train_loss -0.8322 
2024-12-13 03:43:59.293706: val_loss -0.7415 
2024-12-13 03:43:59.296773: Pseudo dice [np.float32(0.8241), np.float32(0.7243), np.float32(0.871)] 
2024-12-13 03:43:59.300825: Epoch time: 32.19 s 
2024-12-13 03:44:00.006793:  
2024-12-13 03:44:00.012470: Epoch 86 
2024-12-13 03:44:00.015013: Current learning rate: 0.0017 
2024-12-13 03:44:32.206317: train_loss -0.8318 
2024-12-13 03:44:32.211500: val_loss -0.744 
2024-12-13 03:44:32.214539: Pseudo dice [np.float32(0.8268), np.float32(0.7264), np.float32(0.8705)] 
2024-12-13 03:44:32.218112: Epoch time: 32.2 s 
2024-12-13 03:44:32.766574:  
2024-12-13 03:44:32.771722: Epoch 87 
2024-12-13 03:44:32.774242: Current learning rate: 0.00159 
2024-12-13 03:45:04.963117: train_loss -0.8315 
2024-12-13 03:45:04.969734: val_loss -0.742 
2024-12-13 03:45:04.971869: Pseudo dice [np.float32(0.8283), np.float32(0.7242), np.float32(0.8691)] 
2024-12-13 03:45:04.976436: Epoch time: 32.2 s 
2024-12-13 03:45:05.536448:  
2024-12-13 03:45:05.542047: Epoch 88 
2024-12-13 03:45:05.545080: Current learning rate: 0.00148 
2024-12-13 03:45:37.709942: train_loss -0.8312 
2024-12-13 03:45:37.716231: val_loss -0.7484 
2024-12-13 03:45:37.718814: Pseudo dice [np.float32(0.831), np.float32(0.7272), np.float32(0.872)] 
2024-12-13 03:45:37.722455: Epoch time: 32.17 s 
2024-12-13 03:45:38.288628:  
2024-12-13 03:45:38.294303: Epoch 89 
2024-12-13 03:45:38.296844: Current learning rate: 0.00137 
2024-12-13 03:46:10.454218: train_loss -0.8326 
2024-12-13 03:46:10.460244: val_loss -0.7434 
2024-12-13 03:46:10.463874: Pseudo dice [np.float32(0.8264), np.float32(0.7258), np.float32(0.8704)] 
2024-12-13 03:46:10.466385: Epoch time: 32.17 s 
2024-12-13 03:46:11.032168:  
2024-12-13 03:46:11.036191: Epoch 90 
2024-12-13 03:46:11.039807: Current learning rate: 0.00126 
2024-12-13 03:46:43.197286: train_loss -0.8345 
2024-12-13 03:46:43.202426: val_loss -0.7457 
2024-12-13 03:46:43.206479: Pseudo dice [np.float32(0.8279), np.float32(0.7304), np.float32(0.8714)] 
2024-12-13 03:46:43.208497: Epoch time: 32.17 s 
2024-12-13 03:46:43.759676:  
2024-12-13 03:46:43.764788: Epoch 91 
2024-12-13 03:46:43.767876: Current learning rate: 0.00115 
2024-12-13 03:47:15.938970: train_loss -0.8332 
2024-12-13 03:47:15.944711: val_loss -0.7512 
2024-12-13 03:47:15.948225: Pseudo dice [np.float32(0.8273), np.float32(0.7421), np.float32(0.8712)] 
2024-12-13 03:47:15.951360: Epoch time: 32.18 s 
2024-12-13 03:47:16.496874:  
2024-12-13 03:47:16.502063: Epoch 92 
2024-12-13 03:47:16.505118: Current learning rate: 0.00103 
2024-12-13 03:47:48.679909: train_loss -0.8329 
2024-12-13 03:47:48.685739: val_loss -0.7402 
2024-12-13 03:47:48.689331: Pseudo dice [np.float32(0.8239), np.float32(0.7186), np.float32(0.8717)] 
2024-12-13 03:47:48.693030: Epoch time: 32.18 s 
2024-12-13 03:47:49.259393:  
2024-12-13 03:47:49.263930: Epoch 93 
2024-12-13 03:47:49.266505: Current learning rate: 0.00091 
2024-12-13 03:48:21.435722: train_loss -0.8328 
2024-12-13 03:48:21.442551: val_loss -0.744 
2024-12-13 03:48:21.445097: Pseudo dice [np.float32(0.8217), np.float32(0.7313), np.float32(0.873)] 
2024-12-13 03:48:21.448240: Epoch time: 32.18 s 
2024-12-13 03:48:22.007447:  
2024-12-13 03:48:22.012034: Epoch 94 
2024-12-13 03:48:22.015077: Current learning rate: 0.00079 
2024-12-13 03:48:54.177360: train_loss -0.8339 
2024-12-13 03:48:54.184152: val_loss -0.7463 
2024-12-13 03:48:54.187696: Pseudo dice [np.float32(0.8265), np.float32(0.7291), np.float32(0.8737)] 
2024-12-13 03:48:54.190242: Epoch time: 32.17 s 
2024-12-13 03:48:54.904088:  
2024-12-13 03:48:54.909689: Epoch 95 
2024-12-13 03:48:54.912769: Current learning rate: 0.00067 
2024-12-13 03:49:27.137877: train_loss -0.8343 
2024-12-13 03:49:27.143569: val_loss -0.7481 
2024-12-13 03:49:27.147161: Pseudo dice [np.float32(0.8263), np.float32(0.7349), np.float32(0.873)] 
2024-12-13 03:49:27.149672: Epoch time: 32.23 s 
2024-12-13 03:49:27.703089:  
2024-12-13 03:49:27.708205: Epoch 96 
2024-12-13 03:49:27.711333: Current learning rate: 0.00055 
2024-12-13 03:49:59.919277: train_loss -0.8339 
2024-12-13 03:49:59.925121: val_loss -0.7489 
2024-12-13 03:49:59.928789: Pseudo dice [np.float32(0.8286), np.float32(0.7334), np.float32(0.8742)] 
2024-12-13 03:49:59.932021: Epoch time: 32.22 s 
2024-12-13 03:49:59.934626: Yayy! New best EMA pseudo Dice: 0.8091999888420105 
2024-12-13 03:50:00.613943:  
2024-12-13 03:50:00.621617: Epoch 97 
2024-12-13 03:50:00.626166: Current learning rate: 0.00043 
2024-12-13 03:50:32.837886: train_loss -0.8356 
2024-12-13 03:50:32.843628: val_loss -0.7392 
2024-12-13 03:50:32.846717: Pseudo dice [np.float32(0.8257), np.float32(0.7145), np.float32(0.87)] 
2024-12-13 03:50:32.849253: Epoch time: 32.22 s 
2024-12-13 03:50:33.472203:  
2024-12-13 03:50:33.477752: Epoch 98 
2024-12-13 03:50:33.480852: Current learning rate: 0.0003 
2024-12-13 03:51:05.682435: train_loss -0.835 
2024-12-13 03:51:05.689120: val_loss -0.7439 
2024-12-13 03:51:05.692778: Pseudo dice [np.float32(0.8256), np.float32(0.7256), np.float32(0.8722)] 
2024-12-13 03:51:05.695286: Epoch time: 32.21 s 
2024-12-13 03:51:06.263798:  
2024-12-13 03:51:06.268881: Epoch 99 
2024-12-13 03:51:06.271998: Current learning rate: 0.00016 
2024-12-13 03:51:38.502879: train_loss -0.8347 
2024-12-13 03:51:38.508457: val_loss -0.746 
2024-12-13 03:51:38.511635: Pseudo dice [np.float32(0.8252), np.float32(0.7316), np.float32(0.8722)] 
2024-12-13 03:51:38.515243: Epoch time: 32.24 s 
2024-12-13 03:51:39.280716: Training done. 
2024-12-13 03:51:39.325095: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-13 03:51:39.331218: The split file contains 5 splits. 
2024-12-13 03:51:39.337219: Desired fold for training: 0 
2024-12-13 03:51:39.343320: This split has 387 training and 97 validation cases. 
2024-12-13 03:51:39.347319: predicting BRATS_010 
2024-12-13 03:51:39.353476: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2024-12-13 03:51:41.098969: predicting BRATS_011 
2024-12-13 03:51:41.111272: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2024-12-13 03:51:42.632587: predicting BRATS_012 
2024-12-13 03:51:42.643717: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-13 03:51:44.189198: predicting BRATS_018 
2024-12-13 03:51:44.206347: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2024-12-13 03:51:45.820441: predicting BRATS_020 
2024-12-13 03:51:46.050374: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2024-12-13 03:51:47.611979: predicting BRATS_028 
2024-12-13 03:51:47.626088: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2024-12-13 03:51:49.342470: predicting BRATS_029 
2024-12-13 03:51:49.361657: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2024-12-13 03:51:50.917808: predicting BRATS_032 
2024-12-13 03:51:50.931172: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2024-12-13 03:51:52.555331: predicting BRATS_034 
2024-12-13 03:51:52.568417: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2024-12-13 03:51:54.161199: predicting BRATS_041 
2024-12-13 03:51:54.175337: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2024-12-13 03:51:55.749226: predicting BRATS_042 
2024-12-13 03:51:55.762669: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2024-12-13 03:51:57.278427: predicting BRATS_047 
2024-12-13 03:51:57.292169: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-13 03:51:58.877267: predicting BRATS_049 
2024-12-13 03:51:58.889744: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-13 03:52:00.458927: predicting BRATS_053 
2024-12-13 03:52:00.473135: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-13 03:52:01.992924: predicting BRATS_056 
2024-12-13 03:52:02.006056: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-13 03:52:03.528172: predicting BRATS_057 
2024-12-13 03:52:03.540274: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-13 03:52:05.025826: predicting BRATS_067 
2024-12-13 03:52:05.037942: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-13 03:52:06.548725: predicting BRATS_069 
2024-12-13 03:52:06.562970: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-13 03:52:08.012771: predicting BRATS_085 
2024-12-13 03:52:08.025976: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2024-12-13 03:52:09.457671: predicting BRATS_086 
2024-12-13 03:52:09.469782: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2024-12-13 03:52:10.964055: predicting BRATS_088 
2024-12-13 03:52:10.978204: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2024-12-13 03:52:12.484719: predicting BRATS_091 
2024-12-13 03:52:12.499352: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2024-12-13 03:52:13.991898: predicting BRATS_098 
2024-12-13 03:52:14.006285: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2024-12-13 03:52:15.577019: predicting BRATS_100 
2024-12-13 03:52:15.590129: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-13 03:52:17.014422: predicting BRATS_101 
2024-12-13 03:52:17.028563: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-13 03:52:18.430734: predicting BRATS_102 
2024-12-13 03:52:18.444888: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2024-12-13 03:52:20.057339: predicting BRATS_104 
2024-12-13 03:52:20.070629: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2024-12-13 03:52:21.598236: predicting BRATS_111 
2024-12-13 03:52:21.612022: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2024-12-13 03:52:23.126185: predicting BRATS_116 
2024-12-13 03:52:23.139304: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2024-12-13 03:52:24.659678: predicting BRATS_135 
2024-12-13 03:52:24.672890: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2024-12-13 03:52:26.173778: predicting BRATS_136 
2024-12-13 03:52:26.187905: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2024-12-13 03:52:27.670286: predicting BRATS_138 
2024-12-13 03:52:27.683610: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2024-12-13 03:52:29.179471: predicting BRATS_145 
2024-12-13 03:52:29.193721: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2024-12-13 03:52:30.723505: predicting BRATS_149 
2024-12-13 03:52:30.737658: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2024-12-13 03:52:32.349855: predicting BRATS_155 
2024-12-13 03:52:32.364182: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-13 03:52:33.927470: predicting BRATS_157 
2024-12-13 03:52:33.941743: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-13 03:52:35.484645: predicting BRATS_158 
2024-12-13 03:52:35.498776: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-13 03:52:37.045310: predicting BRATS_159 
2024-12-13 03:52:37.056455: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-13 03:52:38.532331: predicting BRATS_163 
2024-12-13 03:52:38.545510: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2024-12-13 03:52:40.088351: predicting BRATS_164 
2024-12-13 03:52:40.103628: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2024-12-13 03:52:41.546311: predicting BRATS_169 
2024-12-13 03:52:41.560670: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2024-12-13 03:52:43.137144: predicting BRATS_176 
2024-12-13 03:52:43.150257: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2024-12-13 03:52:44.647358: predicting BRATS_181 
2024-12-13 03:52:44.661610: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2024-12-13 03:52:46.228227: predicting BRATS_183 
2024-12-13 03:52:46.242478: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-13 03:52:47.776358: predicting BRATS_184 
2024-12-13 03:52:47.790597: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-13 03:52:49.317430: predicting BRATS_187 
2024-12-13 03:52:49.331591: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-13 03:52:50.947243: predicting BRATS_192 
2024-12-13 03:52:50.960688: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2024-12-13 03:52:52.436019: predicting BRATS_198 
2024-12-13 03:52:52.449163: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2024-12-13 03:52:54.031048: predicting BRATS_207 
2024-12-13 03:52:54.045185: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-13 03:52:55.532816: predicting BRATS_208 
2024-12-13 03:52:55.546981: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-13 03:52:57.029124: predicting BRATS_218 
2024-12-13 03:52:57.042842: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2024-12-13 03:52:58.652809: predicting BRATS_220 
2024-12-13 03:52:58.666961: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2024-12-13 03:53:00.306117: predicting BRATS_224 
2024-12-13 03:53:00.320233: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2024-12-13 03:53:01.875950: predicting BRATS_230 
2024-12-13 03:53:01.893223: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2024-12-13 03:53:03.422737: predicting BRATS_271 
2024-12-13 03:53:03.437403: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2024-12-13 03:53:05.027899: predicting BRATS_282 
2024-12-13 03:53:05.042701: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2024-12-13 03:53:06.575583: predicting BRATS_284 
2024-12-13 03:53:06.589698: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2024-12-13 03:53:08.023360: predicting BRATS_287 
2024-12-13 03:53:08.036494: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-13 03:53:09.535379: predicting BRATS_290 
2024-12-13 03:53:09.549005: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2024-12-13 03:53:10.975422: predicting BRATS_291 
2024-12-13 03:53:10.989556: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2024-12-13 03:53:12.470702: predicting BRATS_292 
2024-12-13 03:53:12.482863: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2024-12-13 03:53:14.027987: predicting BRATS_293 
2024-12-13 03:53:14.043253: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2024-12-13 03:53:15.686891: predicting BRATS_300 
2024-12-13 03:53:15.701230: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2024-12-13 03:53:17.289682: predicting BRATS_305 
2024-12-13 03:53:17.303941: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2024-12-13 03:53:18.894830: predicting BRATS_311 
2024-12-13 03:53:18.908968: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2024-12-13 03:53:20.489285: predicting BRATS_314 
2024-12-13 03:53:20.503512: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2024-12-13 03:53:22.040158: predicting BRATS_321 
2024-12-13 03:53:22.054901: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2024-12-13 03:53:23.638482: predicting BRATS_328 
2024-12-13 03:53:23.652823: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2024-12-13 03:53:25.222443: predicting BRATS_329 
2024-12-13 03:53:25.235573: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2024-12-13 03:53:26.682168: predicting BRATS_335 
2024-12-13 03:53:26.696337: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2024-12-13 03:53:28.257650: predicting BRATS_343 
2024-12-13 03:53:28.272231: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2024-12-13 03:53:29.856592: predicting BRATS_350 
2024-12-13 03:53:29.870871: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2024-12-13 03:53:31.369125: predicting BRATS_351 
2024-12-13 03:53:31.382367: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2024-12-13 03:53:32.856086: predicting BRATS_356 
2024-12-13 03:53:32.868734: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2024-12-13 03:53:34.475992: predicting BRATS_366 
2024-12-13 03:53:34.490102: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2024-12-13 03:53:35.990068: predicting BRATS_367 
2024-12-13 03:53:36.005302: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2024-12-13 03:53:37.572250: predicting BRATS_374 
2024-12-13 03:53:37.585379: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2024-12-13 03:53:39.149540: predicting BRATS_376 
2024-12-13 03:53:39.163296: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2024-12-13 03:53:40.731126: predicting BRATS_377 
2024-12-13 03:53:40.744747: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2024-12-13 03:53:42.296968: predicting BRATS_378 
2024-12-13 03:53:42.311277: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2024-12-13 03:53:43.909284: predicting BRATS_379 
2024-12-13 03:53:43.923511: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2024-12-13 03:53:45.526987: predicting BRATS_384 
2024-12-13 03:53:45.541294: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2024-12-13 03:53:47.009355: predicting BRATS_386 
2024-12-13 03:53:47.022617: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2024-12-13 03:53:48.578031: predicting BRATS_394 
2024-12-13 03:53:48.590125: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-13 03:53:50.178541: predicting BRATS_398 
2024-12-13 03:53:50.191820: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2024-12-13 03:53:51.795423: predicting BRATS_400 
2024-12-13 03:53:51.809552: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2024-12-13 03:53:53.442942: predicting BRATS_432 
2024-12-13 03:53:53.459091: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2024-12-13 03:53:54.974344: predicting BRATS_437 
2024-12-13 03:53:54.988814: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-13 03:53:56.440470: predicting BRATS_445 
2024-12-13 03:53:56.453683: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2024-12-13 03:53:58.033504: predicting BRATS_446 
2024-12-13 03:53:58.048635: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2024-12-13 03:53:59.570499: predicting BRATS_450 
2024-12-13 03:53:59.584191: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2024-12-13 03:54:01.074618: predicting BRATS_452 
2024-12-13 03:54:01.094413: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2024-12-13 03:54:02.580187: predicting BRATS_460 
2024-12-13 03:54:02.599923: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2024-12-13 03:54:04.161401: predicting BRATS_470 
2024-12-13 03:54:04.184181: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2024-12-13 03:54:05.772825: predicting BRATS_472 
2024-12-13 03:54:05.795606: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2024-12-13 03:54:07.333661: predicting BRATS_473 
2024-12-13 03:54:07.354977: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2024-12-13 03:54:08.676619: predicting BRATS_482 
2024-12-13 03:54:08.698386: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2024-12-13 03:54:17.387721: Validation complete 
2024-12-13 03:54:17.392812: Mean Validation Dice:  0.7119424573398342 
