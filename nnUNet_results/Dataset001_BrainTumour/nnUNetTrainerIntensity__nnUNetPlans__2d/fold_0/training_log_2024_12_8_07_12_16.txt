
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-08 07:12:16.781842: do_dummy_2d_data_aug: False 
2024-12-08 07:12:16.790240: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-08 07:12:16.802383: The split file contains 5 splits. 
2024-12-08 07:12:16.804385: Desired fold for training: 0 
2024-12-08 07:12:16.806392: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 105, 'patch_size': [192, 160], 'median_image_size_in_voxels': [169.0, 138.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2024-12-08 07:12:47.112139: unpacking dataset... 
2024-12-08 07:12:47.324074: unpacking done... 
2024-12-08 07:12:48.784149:  
2024-12-08 07:12:48.789270: Epoch 0 
2024-12-08 07:12:48.791811: Current learning rate: 0.01 
2024-12-08 07:13:23.583273: train_loss -0.3496 
2024-12-08 07:13:23.589874: val_loss -0.5963 
2024-12-08 07:13:23.593414: Pseudo dice [np.float32(0.7303), np.float32(0.5682), np.float32(0.7936)] 
2024-12-08 07:13:23.596500: Epoch time: 34.8 s 
2024-12-08 07:13:23.599547: Yayy! New best EMA pseudo Dice: 0.6973999738693237 
2024-12-08 07:13:24.223418:  
2024-12-08 07:13:24.229514: Epoch 1 
2024-12-08 07:13:24.232099: Current learning rate: 0.00991 
2024-12-08 07:13:56.176718: train_loss -0.6896 
2024-12-08 07:13:56.184413: val_loss -0.693 
2024-12-08 07:13:56.189486: Pseudo dice [np.float32(0.7957), np.float32(0.6669), np.float32(0.8453)] 
2024-12-08 07:13:56.194036: Epoch time: 31.95 s 
2024-12-08 07:13:56.197169: Yayy! New best EMA pseudo Dice: 0.7045999765396118 
2024-12-08 07:13:56.883731:  
2024-12-08 07:13:56.889380: Epoch 2 
2024-12-08 07:13:56.891920: Current learning rate: 0.00982 
2024-12-08 07:14:28.850102: train_loss -0.7478 
2024-12-08 07:14:28.855172: val_loss -0.7101 
2024-12-08 07:14:28.859218: Pseudo dice [np.float32(0.8041), np.float32(0.683), np.float32(0.8521)] 
2024-12-08 07:14:28.862260: Epoch time: 31.97 s 
2024-12-08 07:14:28.864837: Yayy! New best EMA pseudo Dice: 0.7121000289916992 
2024-12-08 07:14:29.585862:  
2024-12-08 07:14:29.590938: Epoch 3 
2024-12-08 07:14:29.593472: Current learning rate: 0.00973 
2024-12-08 07:15:01.529747: train_loss -0.7693 
2024-12-08 07:15:01.538920: val_loss -0.7144 
2024-12-08 07:15:01.543988: Pseudo dice [np.float32(0.8083), np.float32(0.6896), np.float32(0.8537)] 
2024-12-08 07:15:01.547027: Epoch time: 31.94 s 
2024-12-08 07:15:01.550097: Yayy! New best EMA pseudo Dice: 0.7192999720573425 
2024-12-08 07:15:02.249937:  
2024-12-08 07:15:02.255066: Epoch 4 
2024-12-08 07:15:02.257609: Current learning rate: 0.00964 
2024-12-08 07:15:34.189297: train_loss -0.7843 
2024-12-08 07:15:34.194413: val_loss -0.7155 
2024-12-08 07:15:34.198467: Pseudo dice [np.float32(0.8112), np.float32(0.6899), np.float32(0.845)] 
2024-12-08 07:15:34.201524: Epoch time: 31.94 s 
2024-12-08 07:15:34.204575: Yayy! New best EMA pseudo Dice: 0.7254999876022339 
2024-12-08 07:15:34.918982:  
2024-12-08 07:15:34.924587: Epoch 5 
2024-12-08 07:15:34.927124: Current learning rate: 0.00955 
2024-12-08 07:16:06.857686: train_loss -0.7935 
2024-12-08 07:16:06.865357: val_loss -0.7267 
2024-12-08 07:16:06.867887: Pseudo dice [np.float32(0.8111), np.float32(0.6968), np.float32(0.8679)] 
2024-12-08 07:16:06.872449: Epoch time: 31.94 s 
2024-12-08 07:16:06.875498: Yayy! New best EMA pseudo Dice: 0.732200026512146 
2024-12-08 07:16:07.695125:  
2024-12-08 07:16:07.701281: Epoch 6 
2024-12-08 07:16:07.703817: Current learning rate: 0.00946 
2024-12-08 07:16:39.609277: train_loss -0.8034 
2024-12-08 07:16:39.614861: val_loss -0.7263 
2024-12-08 07:16:39.618450: Pseudo dice [np.float32(0.8147), np.float32(0.7001), np.float32(0.8604)] 
2024-12-08 07:16:39.621504: Epoch time: 31.91 s 
2024-12-08 07:16:39.624566: Yayy! New best EMA pseudo Dice: 0.738099992275238 
2024-12-08 07:16:40.284668:  
2024-12-08 07:16:40.290257: Epoch 7 
2024-12-08 07:16:40.292794: Current learning rate: 0.00937 
2024-12-08 07:17:12.208198: train_loss -0.8085 
2024-12-08 07:17:12.215805: val_loss -0.7319 
2024-12-08 07:17:12.217935: Pseudo dice [np.float32(0.8169), np.float32(0.7007), np.float32(0.8669)] 
2024-12-08 07:17:12.222511: Epoch time: 31.92 s 
2024-12-08 07:17:12.225134: Yayy! New best EMA pseudo Dice: 0.7437999844551086 
2024-12-08 07:17:12.909694:  
2024-12-08 07:17:12.915386: Epoch 8 
2024-12-08 07:17:12.918513: Current learning rate: 0.00928 
2024-12-08 07:17:44.816280: train_loss -0.8125 
2024-12-08 07:17:44.821911: val_loss -0.7368 
2024-12-08 07:17:44.825533: Pseudo dice [np.float32(0.8164), np.float32(0.7205), np.float32(0.8632)] 
2024-12-08 07:17:44.829103: Epoch time: 31.91 s 
2024-12-08 07:17:44.831647: Yayy! New best EMA pseudo Dice: 0.7494000196456909 
2024-12-08 07:17:45.528159:  
2024-12-08 07:17:45.533233: Epoch 9 
2024-12-08 07:17:45.535800: Current learning rate: 0.00919 
2024-12-08 07:18:17.449286: train_loss -0.8181 
2024-12-08 07:18:17.454884: val_loss -0.7342 
2024-12-08 07:18:17.459963: Pseudo dice [np.float32(0.8186), np.float32(0.7109), np.float32(0.863)] 
2024-12-08 07:18:17.462552: Epoch time: 31.92 s 
2024-12-08 07:18:17.465104: Yayy! New best EMA pseudo Dice: 0.7541999816894531 
2024-12-08 07:18:18.127734:  
2024-12-08 07:18:18.133299: Epoch 10 
2024-12-08 07:18:18.135882: Current learning rate: 0.0091 
2024-12-08 07:18:50.032750: train_loss -0.8225 
2024-12-08 07:18:50.040390: val_loss -0.7379 
2024-12-08 07:18:50.043448: Pseudo dice [np.float32(0.8208), np.float32(0.7105), np.float32(0.8681)] 
2024-12-08 07:18:50.045986: Epoch time: 31.91 s 
2024-12-08 07:18:50.050027: Yayy! New best EMA pseudo Dice: 0.7588000297546387 
2024-12-08 07:18:50.714615:  
2024-12-08 07:18:50.720698: Epoch 11 
2024-12-08 07:18:50.723237: Current learning rate: 0.009 
2024-12-08 07:19:22.616356: train_loss -0.8263 
2024-12-08 07:19:22.623458: val_loss -0.7312 
2024-12-08 07:19:22.626513: Pseudo dice [np.float32(0.817), np.float32(0.7041), np.float32(0.8617)] 
2024-12-08 07:19:22.629055: Epoch time: 31.9 s 
2024-12-08 07:19:22.632115: Yayy! New best EMA pseudo Dice: 0.7623000144958496 
2024-12-08 07:19:23.310353:  
2024-12-08 07:19:23.316453: Epoch 12 
2024-12-08 07:19:23.319501: Current learning rate: 0.00891 
2024-12-08 07:19:55.207893: train_loss -0.8279 
2024-12-08 07:19:55.213021: val_loss -0.7228 
2024-12-08 07:19:55.218104: Pseudo dice [np.float32(0.8143), np.float32(0.6858), np.float32(0.8644)] 
2024-12-08 07:19:55.220641: Epoch time: 31.9 s 
2024-12-08 07:19:55.223174: Yayy! New best EMA pseudo Dice: 0.7649000287055969 
2024-12-08 07:19:56.041327:  
2024-12-08 07:19:56.046954: Epoch 13 
2024-12-08 07:19:56.049497: Current learning rate: 0.00882 
2024-12-08 07:20:27.906944: train_loss -0.8291 
2024-12-08 07:20:27.914095: val_loss -0.7274 
2024-12-08 07:20:27.917142: Pseudo dice [np.float32(0.8123), np.float32(0.7023), np.float32(0.8608)] 
2024-12-08 07:20:27.920691: Epoch time: 31.87 s 
2024-12-08 07:20:27.922729: Yayy! New best EMA pseudo Dice: 0.7675999999046326 
2024-12-08 07:20:28.603492:  
2024-12-08 07:20:28.609146: Epoch 14 
2024-12-08 07:20:28.611710: Current learning rate: 0.00873 
2024-12-08 07:21:00.496336: train_loss -0.8313 
2024-12-08 07:21:00.503449: val_loss -0.7277 
2024-12-08 07:21:00.506500: Pseudo dice [np.float32(0.8155), np.float32(0.6993), np.float32(0.8617)] 
2024-12-08 07:21:00.509034: Epoch time: 31.89 s 
2024-12-08 07:21:00.511083: Yayy! New best EMA pseudo Dice: 0.7700999975204468 
2024-12-08 07:21:01.193988:  
2024-12-08 07:21:01.198537: Epoch 15 
2024-12-08 07:21:01.201602: Current learning rate: 0.00864 
2024-12-08 07:21:33.106208: train_loss -0.835 
2024-12-08 07:21:33.113820: val_loss -0.7367 
2024-12-08 07:21:33.118404: Pseudo dice [np.float32(0.8207), np.float32(0.7091), np.float32(0.8698)] 
2024-12-08 07:21:33.121456: Epoch time: 31.91 s 
2024-12-08 07:21:33.124000: Yayy! New best EMA pseudo Dice: 0.7730000019073486 
2024-12-08 07:21:33.798857:  
2024-12-08 07:21:33.804979: Epoch 16 
2024-12-08 07:21:33.808033: Current learning rate: 0.00855 
2024-12-08 07:22:05.677404: train_loss -0.8363 
2024-12-08 07:22:05.682483: val_loss -0.7359 
2024-12-08 07:22:05.687551: Pseudo dice [np.float32(0.8204), np.float32(0.7054), np.float32(0.8651)] 
2024-12-08 07:22:05.690174: Epoch time: 31.88 s 
2024-12-08 07:22:05.692726: Yayy! New best EMA pseudo Dice: 0.7753999829292297 
2024-12-08 07:22:06.380999:  
2024-12-08 07:22:06.386091: Epoch 17 
2024-12-08 07:22:06.389148: Current learning rate: 0.00846 
2024-12-08 07:22:38.258941: train_loss -0.8388 
2024-12-08 07:22:38.264526: val_loss -0.7345 
2024-12-08 07:22:38.269601: Pseudo dice [np.float32(0.8177), np.float32(0.7087), np.float32(0.8647)] 
2024-12-08 07:22:38.272692: Epoch time: 31.88 s 
2024-12-08 07:22:38.275735: Yayy! New best EMA pseudo Dice: 0.7775999903678894 
2024-12-08 07:22:38.963963:  
2024-12-08 07:22:38.969559: Epoch 18 
2024-12-08 07:22:38.972099: Current learning rate: 0.00836 
2024-12-08 07:23:10.850327: train_loss -0.8406 
2024-12-08 07:23:10.857425: val_loss -0.7281 
2024-12-08 07:23:10.860470: Pseudo dice [np.float32(0.8136), np.float32(0.7024), np.float32(0.8647)] 
2024-12-08 07:23:10.863547: Epoch time: 31.89 s 
2024-12-08 07:23:10.867615: Yayy! New best EMA pseudo Dice: 0.77920001745224 
2024-12-08 07:23:11.551868:  
2024-12-08 07:23:11.558957: Epoch 19 
2024-12-08 07:23:11.562065: Current learning rate: 0.00827 
2024-12-08 07:23:43.434169: train_loss -0.842 
2024-12-08 07:23:43.442330: val_loss -0.7296 
2024-12-08 07:23:43.444876: Pseudo dice [np.float32(0.8163), np.float32(0.699), np.float32(0.8672)] 
2024-12-08 07:23:43.449436: Epoch time: 31.88 s 
2024-12-08 07:23:43.452486: Yayy! New best EMA pseudo Dice: 0.7807000279426575 
2024-12-08 07:23:44.130363:  
2024-12-08 07:23:44.136073: Epoch 20 
2024-12-08 07:23:44.138632: Current learning rate: 0.00818 
2024-12-08 07:24:16.006088: train_loss -0.8447 
2024-12-08 07:24:16.013249: val_loss -0.7308 
2024-12-08 07:24:16.016309: Pseudo dice [np.float32(0.8205), np.float32(0.7002), np.float32(0.8646)] 
2024-12-08 07:24:16.020860: Epoch time: 31.88 s 
2024-12-08 07:24:16.023966: Yayy! New best EMA pseudo Dice: 0.7821000218391418 
2024-12-08 07:24:16.872379:  
2024-12-08 07:24:16.878464: Epoch 21 
2024-12-08 07:24:16.882062: Current learning rate: 0.00809 
2024-12-08 07:24:48.743246: train_loss -0.8454 
2024-12-08 07:24:48.751410: val_loss -0.7323 
2024-12-08 07:24:48.753952: Pseudo dice [np.float32(0.8163), np.float32(0.7075), np.float32(0.8682)] 
2024-12-08 07:24:48.758502: Epoch time: 31.87 s 
2024-12-08 07:24:48.761603: Yayy! New best EMA pseudo Dice: 0.7836999893188477 
2024-12-08 07:24:49.424937:  
2024-12-08 07:24:49.430526: Epoch 22 
2024-12-08 07:24:49.434650: Current learning rate: 0.008 
2024-12-08 07:25:21.298953: train_loss -0.846 
2024-12-08 07:25:21.307101: val_loss -0.7258 
2024-12-08 07:25:21.312183: Pseudo dice [np.float32(0.8102), np.float32(0.6996), np.float32(0.8652)] 
2024-12-08 07:25:21.315237: Epoch time: 31.87 s 
2024-12-08 07:25:21.317285: Yayy! New best EMA pseudo Dice: 0.784500002861023 
2024-12-08 07:25:21.982075:  
2024-12-08 07:25:21.988158: Epoch 23 
2024-12-08 07:25:21.991743: Current learning rate: 0.0079 
2024-12-08 07:25:53.860864: train_loss -0.8455 
2024-12-08 07:25:53.865986: val_loss -0.7276 
2024-12-08 07:25:53.871076: Pseudo dice [np.float32(0.8171), np.float32(0.6917), np.float32(0.8666)] 
2024-12-08 07:25:53.875642: Epoch time: 31.88 s 
2024-12-08 07:25:53.878676: Yayy! New best EMA pseudo Dice: 0.7851999998092651 
2024-12-08 07:25:54.534597:  
2024-12-08 07:25:54.540273: Epoch 24 
2024-12-08 07:25:54.544321: Current learning rate: 0.00781 
2024-12-08 07:26:26.424426: train_loss -0.8476 
2024-12-08 07:26:26.432037: val_loss -0.7295 
2024-12-08 07:26:26.434572: Pseudo dice [np.float32(0.817), np.float32(0.6982), np.float32(0.8634)] 
2024-12-08 07:26:26.437153: Epoch time: 31.89 s 
2024-12-08 07:26:26.441708: Yayy! New best EMA pseudo Dice: 0.7860000133514404 
2024-12-08 07:26:27.092947:  
2024-12-08 07:26:27.098181: Epoch 25 
2024-12-08 07:26:27.103259: Current learning rate: 0.00772 
2024-12-08 07:26:58.975203: train_loss -0.8494 
2024-12-08 07:26:58.981858: val_loss -0.7322 
2024-12-08 07:26:58.984900: Pseudo dice [np.float32(0.8146), np.float32(0.7143), np.float32(0.8667)] 
2024-12-08 07:26:58.988467: Epoch time: 31.88 s 
2024-12-08 07:26:58.991503: Yayy! New best EMA pseudo Dice: 0.7871999740600586 
2024-12-08 07:26:59.651479:  
2024-12-08 07:26:59.657570: Epoch 26 
2024-12-08 07:26:59.660614: Current learning rate: 0.00763 
2024-12-08 07:27:31.520561: train_loss -0.8481 
2024-12-08 07:27:31.528193: val_loss -0.7284 
2024-12-08 07:27:31.530729: Pseudo dice [np.float32(0.815), np.float32(0.7045), np.float32(0.8624)] 
2024-12-08 07:27:31.533261: Epoch time: 31.87 s 
2024-12-08 07:27:31.537820: Yayy! New best EMA pseudo Dice: 0.7878999710083008 
2024-12-08 07:27:32.202776:  
2024-12-08 07:27:32.207845: Epoch 27 
2024-12-08 07:27:32.211448: Current learning rate: 0.00753 
2024-12-08 07:28:04.082613: train_loss -0.8503 
2024-12-08 07:28:04.089747: val_loss -0.729 
2024-12-08 07:28:04.092804: Pseudo dice [np.float32(0.8143), np.float32(0.6975), np.float32(0.868)] 
2024-12-08 07:28:04.096355: Epoch time: 31.88 s 
2024-12-08 07:28:04.098386: Yayy! New best EMA pseudo Dice: 0.7883999943733215 
2024-12-08 07:28:04.766366:  
2024-12-08 07:28:04.771495: Epoch 28 
2024-12-08 07:28:04.774548: Current learning rate: 0.00744 
2024-12-08 07:28:36.630127: train_loss -0.8517 
2024-12-08 07:28:36.637745: val_loss -0.7362 
2024-12-08 07:28:36.642301: Pseudo dice [np.float32(0.8182), np.float32(0.7102), np.float32(0.8663)] 
2024-12-08 07:28:36.645392: Epoch time: 31.86 s 
2024-12-08 07:28:36.647933: Yayy! New best EMA pseudo Dice: 0.7893999814987183 
2024-12-08 07:28:37.463257:  
2024-12-08 07:28:37.468337: Epoch 29 
2024-12-08 07:28:37.470881: Current learning rate: 0.00735 
2024-12-08 07:29:09.348409: train_loss -0.8524 
2024-12-08 07:29:09.354008: val_loss -0.7343 
2024-12-08 07:29:09.357567: Pseudo dice [np.float32(0.8183), np.float32(0.7028), np.float32(0.8704)] 
2024-12-08 07:29:09.361166: Epoch time: 31.89 s 
2024-12-08 07:29:09.364736: Yayy! New best EMA pseudo Dice: 0.7901999950408936 
2024-12-08 07:29:10.041119:  
2024-12-08 07:29:10.047722: Epoch 30 
2024-12-08 07:29:10.051295: Current learning rate: 0.00725 
2024-12-08 07:29:41.920722: train_loss -0.8524 
2024-12-08 07:29:41.928325: val_loss -0.7292 
2024-12-08 07:29:41.932406: Pseudo dice [np.float32(0.8132), np.float32(0.708), np.float32(0.861)] 
2024-12-08 07:29:41.935967: Epoch time: 31.88 s 
2024-12-08 07:29:41.939017: Yayy! New best EMA pseudo Dice: 0.7906000018119812 
2024-12-08 07:29:42.607057:  
2024-12-08 07:29:42.613667: Epoch 31 
2024-12-08 07:29:42.616714: Current learning rate: 0.00716 
2024-12-08 07:30:14.483636: train_loss -0.8543 
2024-12-08 07:30:14.489215: val_loss -0.7324 
2024-12-08 07:30:14.492765: Pseudo dice [np.float32(0.8182), np.float32(0.7081), np.float32(0.8665)] 
2024-12-08 07:30:14.496354: Epoch time: 31.88 s 
2024-12-08 07:30:14.499918: Yayy! New best EMA pseudo Dice: 0.7912999987602234 
2024-12-08 07:30:15.170250:  
2024-12-08 07:30:15.176329: Epoch 32 
2024-12-08 07:30:15.179370: Current learning rate: 0.00707 
2024-12-08 07:30:47.061477: train_loss -0.8542 
2024-12-08 07:30:47.069642: val_loss -0.7437 
2024-12-08 07:30:47.072696: Pseudo dice [np.float32(0.825), np.float32(0.7221), np.float32(0.8675)] 
2024-12-08 07:30:47.075235: Epoch time: 31.89 s 
2024-12-08 07:30:47.079808: Yayy! New best EMA pseudo Dice: 0.7925999760627747 
2024-12-08 07:30:47.756644:  
2024-12-08 07:30:47.762221: Epoch 33 
2024-12-08 07:30:47.766343: Current learning rate: 0.00697 
2024-12-08 07:31:19.635068: train_loss -0.8534 
2024-12-08 07:31:19.641199: val_loss -0.733 
2024-12-08 07:31:19.644739: Pseudo dice [np.float32(0.8179), np.float32(0.7104), np.float32(0.8644)] 
2024-12-08 07:31:19.648316: Epoch time: 31.88 s 
2024-12-08 07:31:19.651356: Yayy! New best EMA pseudo Dice: 0.7930999994277954 
2024-12-08 07:31:20.328167:  
2024-12-08 07:31:20.333229: Epoch 34 
2024-12-08 07:31:20.336785: Current learning rate: 0.00688 
2024-12-08 07:31:52.214317: train_loss -0.8567 
2024-12-08 07:31:52.221937: val_loss -0.7325 
2024-12-08 07:31:52.227024: Pseudo dice [np.float32(0.8239), np.float32(0.7035), np.float32(0.8641)] 
2024-12-08 07:31:52.229608: Epoch time: 31.89 s 
2024-12-08 07:31:52.234163: Yayy! New best EMA pseudo Dice: 0.7935000061988831 
2024-12-08 07:31:52.905805:  
2024-12-08 07:31:52.911468: Epoch 35 
2024-12-08 07:31:52.915009: Current learning rate: 0.00679 
2024-12-08 07:32:24.804175: train_loss -0.8558 
2024-12-08 07:32:24.809813: val_loss -0.7348 
2024-12-08 07:32:24.814380: Pseudo dice [np.float32(0.819), np.float32(0.7133), np.float32(0.8659)] 
2024-12-08 07:32:24.817434: Epoch time: 31.9 s 
2024-12-08 07:32:24.819972: Yayy! New best EMA pseudo Dice: 0.7940999865531921 
2024-12-08 07:32:25.496741:  
2024-12-08 07:32:25.503849: Epoch 36 
2024-12-08 07:32:25.507418: Current learning rate: 0.00669 
2024-12-08 07:32:57.402158: train_loss -0.8572 
2024-12-08 07:32:57.409787: val_loss -0.7294 
2024-12-08 07:32:57.413339: Pseudo dice [np.float32(0.8201), np.float32(0.6983), np.float32(0.8634)] 
2024-12-08 07:32:57.417961: Epoch time: 31.91 s 
2024-12-08 07:32:58.133906:  
2024-12-08 07:32:58.139473: Epoch 37 
2024-12-08 07:32:58.143013: Current learning rate: 0.0066 
2024-12-08 07:33:30.013214: train_loss -0.8586 
2024-12-08 07:33:30.020368: val_loss -0.7314 
2024-12-08 07:33:30.023941: Pseudo dice [np.float32(0.8174), np.float32(0.7081), np.float32(0.8616)] 
2024-12-08 07:33:30.026482: Epoch time: 31.88 s 
2024-12-08 07:33:30.030532: Yayy! New best EMA pseudo Dice: 0.7943000197410583 
2024-12-08 07:33:30.708814:  
2024-12-08 07:33:30.713926: Epoch 38 
2024-12-08 07:33:30.716471: Current learning rate: 0.0065 
2024-12-08 07:34:02.576818: train_loss -0.8561 
2024-12-08 07:34:02.584472: val_loss -0.7275 
2024-12-08 07:34:02.590069: Pseudo dice [np.float32(0.8199), np.float32(0.6954), np.float32(0.8652)] 
2024-12-08 07:34:02.594120: Epoch time: 31.87 s 
2024-12-08 07:34:03.167233:  
2024-12-08 07:34:03.174340: Epoch 39 
2024-12-08 07:34:03.177419: Current learning rate: 0.00641 
2024-12-08 07:34:35.056719: train_loss -0.8592 
2024-12-08 07:34:35.062857: val_loss -0.7274 
2024-12-08 07:34:35.066903: Pseudo dice [np.float32(0.8192), np.float32(0.6992), np.float32(0.8619)] 
2024-12-08 07:34:35.070484: Epoch time: 31.89 s 
2024-12-08 07:34:35.661260:  
2024-12-08 07:34:35.667875: Epoch 40 
2024-12-08 07:34:35.671433: Current learning rate: 0.00631 
2024-12-08 07:35:07.546739: train_loss -0.8583 
2024-12-08 07:35:07.555352: val_loss -0.7282 
2024-12-08 07:35:07.560441: Pseudo dice [np.float32(0.8187), np.float32(0.7008), np.float32(0.8649)] 
2024-12-08 07:35:07.564517: Epoch time: 31.89 s 
2024-12-08 07:35:08.143341:  
2024-12-08 07:35:08.148415: Epoch 41 
2024-12-08 07:35:08.151589: Current learning rate: 0.00622 
2024-12-08 07:35:40.011658: train_loss -0.8605 
2024-12-08 07:35:40.017815: val_loss -0.7338 
2024-12-08 07:35:40.020886: Pseudo dice [np.float32(0.8174), np.float32(0.7125), np.float32(0.868)] 
2024-12-08 07:35:40.025439: Epoch time: 31.87 s 
2024-12-08 07:35:40.028492: Yayy! New best EMA pseudo Dice: 0.794700026512146 
2024-12-08 07:35:40.685026:  
2024-12-08 07:35:40.692168: Epoch 42 
2024-12-08 07:35:40.695745: Current learning rate: 0.00612 
2024-12-08 07:36:12.575471: train_loss -0.8598 
2024-12-08 07:36:12.584648: val_loss -0.7315 
2024-12-08 07:36:12.588197: Pseudo dice [np.float32(0.8196), np.float32(0.7044), np.float32(0.8665)] 
2024-12-08 07:36:12.592775: Epoch time: 31.89 s 
2024-12-08 07:36:12.595855: Yayy! New best EMA pseudo Dice: 0.7949000000953674 
2024-12-08 07:36:13.258571:  
2024-12-08 07:36:13.263645: Epoch 43 
2024-12-08 07:36:13.266237: Current learning rate: 0.00603 
2024-12-08 07:36:45.122390: train_loss -0.8598 
2024-12-08 07:36:45.129572: val_loss -0.7303 
2024-12-08 07:36:45.132637: Pseudo dice [np.float32(0.8196), np.float32(0.7072), np.float32(0.8609)] 
2024-12-08 07:36:45.137194: Epoch time: 31.86 s 
2024-12-08 07:36:45.140249: Yayy! New best EMA pseudo Dice: 0.7950000166893005 
2024-12-08 07:36:45.805630:  
2024-12-08 07:36:45.811241: Epoch 44 
2024-12-08 07:36:45.815803: Current learning rate: 0.00593 
2024-12-08 07:37:17.692145: train_loss -0.862 
2024-12-08 07:37:17.699790: val_loss -0.7309 
2024-12-08 07:37:17.702847: Pseudo dice [np.float32(0.819), np.float32(0.7044), np.float32(0.8668)] 
2024-12-08 07:37:17.707920: Epoch time: 31.89 s 
2024-12-08 07:37:17.709944: Yayy! New best EMA pseudo Dice: 0.795199990272522 
2024-12-08 07:37:18.527282:  
2024-12-08 07:37:18.532364: Epoch 45 
2024-12-08 07:37:18.536417: Current learning rate: 0.00584 
2024-12-08 07:37:50.392059: train_loss -0.8621 
2024-12-08 07:37:50.399672: val_loss -0.7291 
2024-12-08 07:37:50.402241: Pseudo dice [np.float32(0.8159), np.float32(0.7059), np.float32(0.8647)] 
2024-12-08 07:37:50.407334: Epoch time: 31.87 s 
2024-12-08 07:37:50.409872: Yayy! New best EMA pseudo Dice: 0.795199990272522 
2024-12-08 07:37:51.071089:  
2024-12-08 07:37:51.077202: Epoch 46 
2024-12-08 07:37:51.080257: Current learning rate: 0.00574 
2024-12-08 07:38:22.931447: train_loss -0.8627 
2024-12-08 07:38:22.940571: val_loss -0.7337 
2024-12-08 07:38:22.944671: Pseudo dice [np.float32(0.822), np.float32(0.7027), np.float32(0.8699)] 
2024-12-08 07:38:22.947721: Epoch time: 31.86 s 
2024-12-08 07:38:22.951765: Yayy! New best EMA pseudo Dice: 0.7954999804496765 
2024-12-08 07:38:23.607328:  
2024-12-08 07:38:23.614955: Epoch 47 
2024-12-08 07:38:23.618504: Current learning rate: 0.00565 
2024-12-08 07:38:55.477198: train_loss -0.8639 
2024-12-08 07:38:55.482794: val_loss -0.7312 
2024-12-08 07:38:55.487873: Pseudo dice [np.float32(0.8206), np.float32(0.7066), np.float32(0.8637)] 
2024-12-08 07:38:55.490406: Epoch time: 31.87 s 
2024-12-08 07:38:55.494963: Yayy! New best EMA pseudo Dice: 0.7957000136375427 
2024-12-08 07:38:56.145226:  
2024-12-08 07:38:56.151372: Epoch 48 
2024-12-08 07:38:56.154916: Current learning rate: 0.00555 
2024-12-08 07:39:28.010036: train_loss -0.8637 
2024-12-08 07:39:28.018703: val_loss -0.7327 
2024-12-08 07:39:28.021757: Pseudo dice [np.float32(0.82), np.float32(0.7063), np.float32(0.8678)] 
2024-12-08 07:39:28.026823: Epoch time: 31.86 s 
2024-12-08 07:39:28.029921: Yayy! New best EMA pseudo Dice: 0.7958999872207642 
2024-12-08 07:39:28.690925:  
2024-12-08 07:39:28.698103: Epoch 49 
2024-12-08 07:39:28.702210: Current learning rate: 0.00546 
2024-12-08 07:40:00.569263: train_loss -0.8644 
2024-12-08 07:40:00.576874: val_loss -0.7262 
2024-12-08 07:40:00.581954: Pseudo dice [np.float32(0.8139), np.float32(0.6984), np.float32(0.8671)] 
2024-12-08 07:40:00.584548: Epoch time: 31.88 s 
2024-12-08 07:40:01.241575:  
2024-12-08 07:40:01.247167: Epoch 50 
2024-12-08 07:40:01.249705: Current learning rate: 0.00536 
2024-12-08 07:40:33.107621: train_loss -0.8639 
2024-12-08 07:40:33.115829: val_loss -0.7344 
2024-12-08 07:40:33.118371: Pseudo dice [np.float32(0.823), np.float32(0.7054), np.float32(0.8687)] 
2024-12-08 07:40:33.123480: Epoch time: 31.87 s 
2024-12-08 07:40:33.126020: Yayy! New best EMA pseudo Dice: 0.7960000038146973 
2024-12-08 07:40:33.860480:  
2024-12-08 07:40:33.865556: Epoch 51 
2024-12-08 07:40:33.868091: Current learning rate: 0.00526 
2024-12-08 07:41:05.725935: train_loss -0.8657 
2024-12-08 07:41:05.732108: val_loss -0.7255 
2024-12-08 07:41:05.735645: Pseudo dice [np.float32(0.8168), np.float32(0.6959), np.float32(0.8673)] 
2024-12-08 07:41:05.739234: Epoch time: 31.87 s 
2024-12-08 07:41:06.291702:  
2024-12-08 07:41:06.296791: Epoch 52 
2024-12-08 07:41:06.299333: Current learning rate: 0.00517 
2024-12-08 07:41:38.164635: train_loss -0.8662 
2024-12-08 07:41:38.171217: val_loss -0.7319 
2024-12-08 07:41:38.174273: Pseudo dice [np.float32(0.8198), np.float32(0.7085), np.float32(0.863)] 
2024-12-08 07:41:38.178834: Epoch time: 31.87 s 
2024-12-08 07:41:38.885718:  
2024-12-08 07:41:38.891307: Epoch 53 
2024-12-08 07:41:38.893371: Current learning rate: 0.00507 
2024-12-08 07:42:10.747247: train_loss -0.8642 
2024-12-08 07:42:10.753865: val_loss -0.7306 
2024-12-08 07:42:10.757436: Pseudo dice [np.float32(0.8149), np.float32(0.7078), np.float32(0.8678)] 
2024-12-08 07:42:10.759972: Epoch time: 31.86 s 
2024-12-08 07:42:11.310491:  
2024-12-08 07:42:11.315580: Epoch 54 
2024-12-08 07:42:11.318124: Current learning rate: 0.00497 
2024-12-08 07:42:43.161049: train_loss -0.8656 
2024-12-08 07:42:43.166645: val_loss -0.7289 
2024-12-08 07:42:43.169183: Pseudo dice [np.float32(0.8198), np.float32(0.6999), np.float32(0.8657)] 
2024-12-08 07:42:43.173792: Epoch time: 31.85 s 
2024-12-08 07:42:43.735395:  
2024-12-08 07:42:43.741510: Epoch 55 
2024-12-08 07:42:43.745053: Current learning rate: 0.00487 
2024-12-08 07:43:15.602641: train_loss -0.866 
2024-12-08 07:43:15.609740: val_loss -0.7267 
2024-12-08 07:43:15.612839: Pseudo dice [np.float32(0.8161), np.float32(0.6971), np.float32(0.863)] 
2024-12-08 07:43:15.616410: Epoch time: 31.87 s 
2024-12-08 07:43:16.186754:  
2024-12-08 07:43:16.190325: Epoch 56 
2024-12-08 07:43:16.192349: Current learning rate: 0.00478 
2024-12-08 07:43:48.057962: train_loss -0.8669 
2024-12-08 07:43:48.064562: val_loss -0.7262 
2024-12-08 07:43:48.067091: Pseudo dice [np.float32(0.8159), np.float32(0.6962), np.float32(0.8662)] 
2024-12-08 07:43:48.070640: Epoch time: 31.87 s 
2024-12-08 07:43:48.615571:  
2024-12-08 07:43:48.620641: Epoch 57 
2024-12-08 07:43:48.623178: Current learning rate: 0.00468 
2024-12-08 07:44:20.491026: train_loss -0.8675 
2024-12-08 07:44:20.498729: val_loss -0.7368 
2024-12-08 07:44:20.501783: Pseudo dice [np.float32(0.8232), np.float32(0.7132), np.float32(0.8635)] 
2024-12-08 07:44:20.505327: Epoch time: 31.88 s 
2024-12-08 07:44:21.054639:  
2024-12-08 07:44:21.060804: Epoch 58 
2024-12-08 07:44:21.063853: Current learning rate: 0.00458 
2024-12-08 07:44:52.920857: train_loss -0.8667 
2024-12-08 07:44:52.926448: val_loss -0.7301 
2024-12-08 07:44:52.930488: Pseudo dice [np.float32(0.8205), np.float32(0.7029), np.float32(0.8652)] 
2024-12-08 07:44:52.933573: Epoch time: 31.87 s 
2024-12-08 07:44:53.487786:  
2024-12-08 07:44:53.492865: Epoch 59 
2024-12-08 07:44:53.495940: Current learning rate: 0.00448 
2024-12-08 07:45:25.345707: train_loss -0.8679 
2024-12-08 07:45:25.353354: val_loss -0.7304 
2024-12-08 07:45:25.358448: Pseudo dice [np.float32(0.8178), np.float32(0.7071), np.float32(0.8649)] 
2024-12-08 07:45:25.360985: Epoch time: 31.86 s 
2024-12-08 07:45:25.923368:  
2024-12-08 07:45:25.929522: Epoch 60 
2024-12-08 07:45:25.932057: Current learning rate: 0.00438 
2024-12-08 07:45:57.779558: train_loss -0.8684 
2024-12-08 07:45:57.786187: val_loss -0.7346 
2024-12-08 07:45:57.789232: Pseudo dice [np.float32(0.8216), np.float32(0.7103), np.float32(0.8659)] 
2024-12-08 07:45:57.792803: Epoch time: 31.86 s 
2024-12-08 07:45:57.797405: Yayy! New best EMA pseudo Dice: 0.7961999773979187 
2024-12-08 07:45:58.616407:  
2024-12-08 07:45:58.622488: Epoch 61 
2024-12-08 07:45:58.625020: Current learning rate: 0.00429 
2024-12-08 07:46:30.477041: train_loss -0.8674 
2024-12-08 07:46:30.484658: val_loss -0.7295 
2024-12-08 07:46:30.489814: Pseudo dice [np.float32(0.8193), np.float32(0.7078), np.float32(0.8607)] 
2024-12-08 07:46:30.492350: Epoch time: 31.86 s 
2024-12-08 07:46:31.065756:  
2024-12-08 07:46:31.070833: Epoch 62 
2024-12-08 07:46:31.074882: Current learning rate: 0.00419 
2024-12-08 07:47:02.934735: train_loss -0.8682 
2024-12-08 07:47:02.940881: val_loss -0.7334 
2024-12-08 07:47:02.943415: Pseudo dice [np.float32(0.8196), np.float32(0.7082), np.float32(0.8668)] 
2024-12-08 07:47:02.945958: Epoch time: 31.87 s 
2024-12-08 07:47:02.948490: Yayy! New best EMA pseudo Dice: 0.7962999939918518 
2024-12-08 07:47:03.621204:  
2024-12-08 07:47:03.626850: Epoch 63 
2024-12-08 07:47:03.629383: Current learning rate: 0.00409 
2024-12-08 07:47:35.496161: train_loss -0.8688 
2024-12-08 07:47:35.503771: val_loss -0.7267 
2024-12-08 07:47:35.506819: Pseudo dice [np.float32(0.8153), np.float32(0.701), np.float32(0.8655)] 
2024-12-08 07:47:35.510896: Epoch time: 31.87 s 
2024-12-08 07:47:36.087971:  
2024-12-08 07:47:36.093552: Epoch 64 
2024-12-08 07:47:36.096091: Current learning rate: 0.00399 
2024-12-08 07:48:07.946666: train_loss -0.8678 
2024-12-08 07:48:07.952742: val_loss -0.725 
2024-12-08 07:48:07.955832: Pseudo dice [np.float32(0.8175), np.float32(0.6944), np.float32(0.8651)] 
2024-12-08 07:48:07.958880: Epoch time: 31.86 s 
2024-12-08 07:48:08.514331:  
2024-12-08 07:48:08.519444: Epoch 65 
2024-12-08 07:48:08.522493: Current learning rate: 0.00389 
2024-12-08 07:48:40.379761: train_loss -0.8685 
2024-12-08 07:48:40.386896: val_loss -0.7303 
2024-12-08 07:48:40.389958: Pseudo dice [np.float32(0.8152), np.float32(0.7111), np.float32(0.8647)] 
2024-12-08 07:48:40.393003: Epoch time: 31.87 s 
2024-12-08 07:48:40.960305:  
2024-12-08 07:48:40.965424: Epoch 66 
2024-12-08 07:48:40.968484: Current learning rate: 0.00379 
2024-12-08 07:49:12.827422: train_loss -0.8704 
2024-12-08 07:49:12.832042: val_loss -0.728 
2024-12-08 07:49:12.837129: Pseudo dice [np.float32(0.8179), np.float32(0.7016), np.float32(0.8645)] 
2024-12-08 07:49:12.839718: Epoch time: 31.87 s 
2024-12-08 07:49:13.397487:  
2024-12-08 07:49:13.402586: Epoch 67 
2024-12-08 07:49:13.407191: Current learning rate: 0.00369 
2024-12-08 07:49:45.248760: train_loss -0.8705 
2024-12-08 07:49:45.255869: val_loss -0.7242 
2024-12-08 07:49:45.259475: Pseudo dice [np.float32(0.8172), np.float32(0.692), np.float32(0.8643)] 
2024-12-08 07:49:45.262013: Epoch time: 31.85 s 
2024-12-08 07:49:45.834557:  
2024-12-08 07:49:45.840669: Epoch 68 
2024-12-08 07:49:45.843210: Current learning rate: 0.00359 
2024-12-08 07:50:17.698438: train_loss -0.8705 
2024-12-08 07:50:17.704543: val_loss -0.7271 
2024-12-08 07:50:17.707081: Pseudo dice [np.float32(0.8172), np.float32(0.7026), np.float32(0.8665)] 
2024-12-08 07:50:17.710142: Epoch time: 31.86 s 
2024-12-08 07:50:18.435641:  
2024-12-08 07:50:18.441744: Epoch 69 
2024-12-08 07:50:18.444281: Current learning rate: 0.00349 
2024-12-08 07:50:50.293756: train_loss -0.8712 
2024-12-08 07:50:50.299346: val_loss -0.7235 
2024-12-08 07:50:50.301889: Pseudo dice [np.float32(0.8188), np.float32(0.688), np.float32(0.865)] 
2024-12-08 07:50:50.306446: Epoch time: 31.86 s 
2024-12-08 07:50:50.876130:  
2024-12-08 07:50:50.881307: Epoch 70 
2024-12-08 07:50:50.883859: Current learning rate: 0.00338 
2024-12-08 07:51:22.732445: train_loss -0.8695 
2024-12-08 07:51:22.740117: val_loss -0.7267 
2024-12-08 07:51:22.743690: Pseudo dice [np.float32(0.8154), np.float32(0.7016), np.float32(0.8622)] 
2024-12-08 07:51:22.747237: Epoch time: 31.86 s 
2024-12-08 07:51:23.321701:  
2024-12-08 07:51:23.327303: Epoch 71 
2024-12-08 07:51:23.329844: Current learning rate: 0.00328 
2024-12-08 07:51:55.177586: train_loss -0.8724 
2024-12-08 07:51:55.182665: val_loss -0.7251 
2024-12-08 07:51:55.186206: Pseudo dice [np.float32(0.8168), np.float32(0.6951), np.float32(0.8631)] 
2024-12-08 07:51:55.189284: Epoch time: 31.86 s 
2024-12-08 07:51:55.757201:  
2024-12-08 07:51:55.762276: Epoch 72 
2024-12-08 07:51:55.764807: Current learning rate: 0.00318 
2024-12-08 07:52:27.617958: train_loss -0.8724 
2024-12-08 07:52:27.625574: val_loss -0.7279 
2024-12-08 07:52:27.630152: Pseudo dice [np.float32(0.8203), np.float32(0.6941), np.float32(0.8674)] 
2024-12-08 07:52:27.633210: Epoch time: 31.86 s 
2024-12-08 07:52:28.211201:  
2024-12-08 07:52:28.216272: Epoch 73 
2024-12-08 07:52:28.219326: Current learning rate: 0.00308 
2024-12-08 07:53:00.070904: train_loss -0.8725 
2024-12-08 07:53:00.078555: val_loss -0.7266 
2024-12-08 07:53:00.081087: Pseudo dice [np.float32(0.819), np.float32(0.7015), np.float32(0.8636)] 
2024-12-08 07:53:00.083626: Epoch time: 31.86 s 
2024-12-08 07:53:00.643993:  
2024-12-08 07:53:00.650072: Epoch 74 
2024-12-08 07:53:00.652608: Current learning rate: 0.00297 
2024-12-08 07:53:32.499830: train_loss -0.8727 
2024-12-08 07:53:32.507493: val_loss -0.7316 
2024-12-08 07:53:32.511041: Pseudo dice [np.float32(0.8162), np.float32(0.7124), np.float32(0.8682)] 
2024-12-08 07:53:32.513576: Epoch time: 31.86 s 
2024-12-08 07:53:33.084395:  
2024-12-08 07:53:33.089530: Epoch 75 
2024-12-08 07:53:33.092587: Current learning rate: 0.00287 
2024-12-08 07:54:04.932411: train_loss -0.8744 
2024-12-08 07:54:04.940122: val_loss -0.7302 
2024-12-08 07:54:04.942160: Pseudo dice [np.float32(0.8199), np.float32(0.7134), np.float32(0.8615)] 
2024-12-08 07:54:04.960050: Epoch time: 31.85 s 
2024-12-08 07:54:05.535870:  
2024-12-08 07:54:05.540948: Epoch 76 
2024-12-08 07:54:05.543491: Current learning rate: 0.00277 
2024-12-08 07:54:37.397253: train_loss -0.8736 
2024-12-08 07:54:37.403866: val_loss -0.7296 
2024-12-08 07:54:37.407929: Pseudo dice [np.float32(0.8212), np.float32(0.7039), np.float32(0.8664)] 
2024-12-08 07:54:37.410484: Epoch time: 31.86 s 
2024-12-08 07:54:38.129167:  
2024-12-08 07:54:38.134326: Epoch 77 
2024-12-08 07:54:38.139561: Current learning rate: 0.00266 
2024-12-08 07:55:09.981291: train_loss -0.8727 
2024-12-08 07:55:09.986871: val_loss -0.731 
2024-12-08 07:55:09.989404: Pseudo dice [np.float32(0.821), np.float32(0.712), np.float32(0.8651)] 
2024-12-08 07:55:09.991477: Epoch time: 31.85 s 
2024-12-08 07:55:10.562802:  
2024-12-08 07:55:10.569421: Epoch 78 
2024-12-08 07:55:10.572506: Current learning rate: 0.00256 
2024-12-08 07:55:42.415874: train_loss -0.8747 
2024-12-08 07:55:42.422504: val_loss -0.7317 
2024-12-08 07:55:42.425037: Pseudo dice [np.float32(0.8203), np.float32(0.7095), np.float32(0.8655)] 
2024-12-08 07:55:42.429088: Epoch time: 31.85 s 
2024-12-08 07:55:43.008147:  
2024-12-08 07:55:43.013271: Epoch 79 
2024-12-08 07:55:43.015815: Current learning rate: 0.00245 
2024-12-08 07:56:14.882955: train_loss -0.8745 
2024-12-08 07:56:14.888025: val_loss -0.7312 
2024-12-08 07:56:14.892085: Pseudo dice [np.float32(0.8194), np.float32(0.7092), np.float32(0.8626)] 
2024-12-08 07:56:14.895181: Epoch time: 31.87 s 
2024-12-08 07:56:15.476338:  
2024-12-08 07:56:15.481398: Epoch 80 
2024-12-08 07:56:15.484509: Current learning rate: 0.00235 
2024-12-08 07:56:47.335878: train_loss -0.8751 
2024-12-08 07:56:47.342490: val_loss -0.7298 
2024-12-08 07:56:47.346063: Pseudo dice [np.float32(0.8195), np.float32(0.7089), np.float32(0.8621)] 
2024-12-08 07:56:47.348600: Epoch time: 31.86 s 
2024-12-08 07:56:47.934568:  
2024-12-08 07:56:47.941764: Epoch 81 
2024-12-08 07:56:47.944841: Current learning rate: 0.00224 
2024-12-08 07:57:19.785800: train_loss -0.8756 
2024-12-08 07:57:19.790884: val_loss -0.7254 
2024-12-08 07:57:19.795444: Pseudo dice [np.float32(0.8171), np.float32(0.7064), np.float32(0.8624)] 
2024-12-08 07:57:19.798493: Epoch time: 31.85 s 
2024-12-08 07:57:20.492339:  
2024-12-08 07:57:20.497979: Epoch 82 
2024-12-08 07:57:20.500520: Current learning rate: 0.00214 
2024-12-08 07:57:52.349727: train_loss -0.8737 
2024-12-08 07:57:52.355824: val_loss -0.7199 
2024-12-08 07:57:52.358942: Pseudo dice [np.float32(0.8126), np.float32(0.6962), np.float32(0.8646)] 
2024-12-08 07:57:52.361985: Epoch time: 31.86 s 
2024-12-08 07:57:52.924984:  
2024-12-08 07:57:52.930572: Epoch 83 
2024-12-08 07:57:52.933110: Current learning rate: 0.00203 
2024-12-08 07:58:24.776148: train_loss -0.8751 
2024-12-08 07:58:24.783741: val_loss -0.7224 
2024-12-08 07:58:24.787840: Pseudo dice [np.float32(0.8125), np.float32(0.7019), np.float32(0.8648)] 
2024-12-08 07:58:24.790370: Epoch time: 31.85 s 
2024-12-08 07:58:25.334973:  
2024-12-08 07:58:25.340079: Epoch 84 
2024-12-08 07:58:25.344138: Current learning rate: 0.00192 
2024-12-08 07:58:57.192086: train_loss -0.8754 
2024-12-08 07:58:57.198177: val_loss -0.7293 
2024-12-08 07:58:57.201739: Pseudo dice [np.float32(0.8199), np.float32(0.7089), np.float32(0.8659)] 
2024-12-08 07:58:57.203799: Epoch time: 31.86 s 
2024-12-08 07:58:57.900376:  
2024-12-08 07:58:57.905443: Epoch 85 
2024-12-08 07:58:57.907996: Current learning rate: 0.00181 
2024-12-08 07:59:29.759086: train_loss -0.8749 
2024-12-08 07:59:29.766701: val_loss -0.7265 
2024-12-08 07:59:29.769289: Pseudo dice [np.float32(0.8184), np.float32(0.6965), np.float32(0.8663)] 
2024-12-08 07:59:29.773860: Epoch time: 31.86 s 
2024-12-08 07:59:30.321081:  
2024-12-08 07:59:30.325142: Epoch 86 
2024-12-08 07:59:30.328688: Current learning rate: 0.0017 
2024-12-08 08:00:02.178464: train_loss -0.8752 
2024-12-08 08:00:02.183571: val_loss -0.7236 
2024-12-08 08:00:02.188662: Pseudo dice [np.float32(0.8176), np.float32(0.6967), np.float32(0.8612)] 
2024-12-08 08:00:02.191198: Epoch time: 31.86 s 
2024-12-08 08:00:02.725827:  
2024-12-08 08:00:02.731000: Epoch 87 
2024-12-08 08:00:02.735637: Current learning rate: 0.00159 
2024-12-08 08:00:34.577919: train_loss -0.8764 
2024-12-08 08:00:34.585025: val_loss -0.7301 
2024-12-08 08:00:34.588098: Pseudo dice [np.float32(0.8184), np.float32(0.7033), np.float32(0.8666)] 
2024-12-08 08:00:34.590636: Epoch time: 31.85 s 
2024-12-08 08:00:35.132688:  
2024-12-08 08:00:35.138340: Epoch 88 
2024-12-08 08:00:35.141882: Current learning rate: 0.00148 
2024-12-08 08:01:07.003482: train_loss -0.8774 
2024-12-08 08:01:07.009627: val_loss -0.7303 
2024-12-08 08:01:07.013179: Pseudo dice [np.float32(0.8215), np.float32(0.7061), np.float32(0.8652)] 
2024-12-08 08:01:07.016219: Epoch time: 31.87 s 
2024-12-08 08:01:07.584929:  
2024-12-08 08:01:07.590113: Epoch 89 
2024-12-08 08:01:07.594715: Current learning rate: 0.00137 
2024-12-08 08:01:39.446188: train_loss -0.8763 
2024-12-08 08:01:39.453845: val_loss -0.7337 
2024-12-08 08:01:39.456383: Pseudo dice [np.float32(0.8196), np.float32(0.7164), np.float32(0.8666)] 
2024-12-08 08:01:39.460432: Epoch time: 31.86 s 
2024-12-08 08:01:39.998046:  
2024-12-08 08:01:40.003125: Epoch 90 
2024-12-08 08:01:40.006173: Current learning rate: 0.00126 
2024-12-08 08:02:11.872837: train_loss -0.8769 
2024-12-08 08:02:11.878912: val_loss -0.7288 
2024-12-08 08:02:11.882519: Pseudo dice [np.float32(0.8181), np.float32(0.7085), np.float32(0.8648)] 
2024-12-08 08:02:11.885056: Epoch time: 31.88 s 
2024-12-08 08:02:12.430791:  
2024-12-08 08:02:12.436373: Epoch 91 
2024-12-08 08:02:12.439424: Current learning rate: 0.00115 
2024-12-08 08:02:44.297917: train_loss -0.8764 
2024-12-08 08:02:44.305064: val_loss -0.7268 
2024-12-08 08:02:44.308114: Pseudo dice [np.float32(0.8183), np.float32(0.7074), np.float32(0.8638)] 
2024-12-08 08:02:44.311686: Epoch time: 31.87 s 
2024-12-08 08:02:44.860827:  
2024-12-08 08:02:44.865904: Epoch 92 
2024-12-08 08:02:44.868471: Current learning rate: 0.00103 
2024-12-08 08:03:16.720471: train_loss -0.8775 
2024-12-08 08:03:16.726603: val_loss -0.7285 
2024-12-08 08:03:16.729648: Pseudo dice [np.float32(0.8229), np.float32(0.7019), np.float32(0.8669)] 
2024-12-08 08:03:16.733199: Epoch time: 31.86 s 
2024-12-08 08:03:17.277742:  
2024-12-08 08:03:17.282813: Epoch 93 
2024-12-08 08:03:17.285357: Current learning rate: 0.00091 
2024-12-08 08:03:49.218948: train_loss -0.8779 
2024-12-08 08:03:49.226064: val_loss -0.7236 
2024-12-08 08:03:49.229642: Pseudo dice [np.float32(0.8179), np.float32(0.6975), np.float32(0.8661)] 
2024-12-08 08:03:49.232186: Epoch time: 31.94 s 
2024-12-08 08:03:49.783496:  
2024-12-08 08:03:49.788627: Epoch 94 
2024-12-08 08:03:49.792167: Current learning rate: 0.00079 
2024-12-08 08:04:21.656521: train_loss -0.8772 
2024-12-08 08:04:21.664233: val_loss -0.7272 
2024-12-08 08:04:21.666790: Pseudo dice [np.float32(0.8206), np.float32(0.7003), np.float32(0.8664)] 
2024-12-08 08:04:21.669348: Epoch time: 31.87 s 
2024-12-08 08:04:22.217360:  
2024-12-08 08:04:22.223436: Epoch 95 
2024-12-08 08:04:22.227000: Current learning rate: 0.00067 
2024-12-08 08:04:54.077742: train_loss -0.8772 
2024-12-08 08:04:54.083373: val_loss -0.7275 
2024-12-08 08:04:54.086431: Pseudo dice [np.float32(0.8187), np.float32(0.7052), np.float32(0.8652)] 
2024-12-08 08:04:54.088970: Epoch time: 31.86 s 
2024-12-08 08:04:54.629776:  
2024-12-08 08:04:54.634363: Epoch 96 
2024-12-08 08:04:54.637417: Current learning rate: 0.00055 
2024-12-08 08:05:26.488955: train_loss -0.8786 
2024-12-08 08:05:26.495577: val_loss -0.723 
2024-12-08 08:05:26.499617: Pseudo dice [np.float32(0.8175), np.float32(0.6942), np.float32(0.8615)] 
2024-12-08 08:05:26.502656: Epoch time: 31.86 s 
2024-12-08 08:05:27.061548:  
2024-12-08 08:05:27.066625: Epoch 97 
2024-12-08 08:05:27.069679: Current learning rate: 0.00043 
2024-12-08 08:05:58.930915: train_loss -0.8778 
2024-12-08 08:05:58.936502: val_loss -0.7232 
2024-12-08 08:05:58.939561: Pseudo dice [np.float32(0.8167), np.float32(0.6995), np.float32(0.8629)] 
2024-12-08 08:05:58.942611: Epoch time: 31.87 s 
2024-12-08 08:05:59.502369:  
2024-12-08 08:05:59.507450: Epoch 98 
2024-12-08 08:05:59.510994: Current learning rate: 0.0003 
2024-12-08 08:06:31.370073: train_loss -0.8781 
2024-12-08 08:06:31.377673: val_loss -0.7205 
2024-12-08 08:06:31.381719: Pseudo dice [np.float32(0.8192), np.float32(0.6964), np.float32(0.8605)] 
2024-12-08 08:06:31.385330: Epoch time: 31.87 s 
2024-12-08 08:06:31.948432:  
2024-12-08 08:06:31.954034: Epoch 99 
2024-12-08 08:06:31.956573: Current learning rate: 0.00016 
2024-12-08 08:07:03.815097: train_loss -0.8798 
2024-12-08 08:07:03.822185: val_loss -0.7298 
2024-12-08 08:07:03.825324: Pseudo dice [np.float32(0.8226), np.float32(0.7068), np.float32(0.8614)] 
2024-12-08 08:07:03.827867: Epoch time: 31.87 s 
2024-12-08 08:07:04.522454: Training done. 
2024-12-08 08:07:04.557217: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-08 08:07:04.566417: The split file contains 5 splits. 
2024-12-08 08:07:04.566417: Desired fold for training: 0 
2024-12-08 08:07:04.570925: This split has 387 training and 97 validation cases. 
2024-12-08 08:07:04.570925: predicting BRATS_010 
2024-12-08 08:07:04.578992: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2024-12-08 08:07:05.140975: predicting BRATS_011 
2024-12-08 08:07:05.157540: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2024-12-08 08:07:05.580080: predicting BRATS_012 
2024-12-08 08:07:05.596670: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-08 08:07:05.989328: predicting BRATS_018 
2024-12-08 08:07:05.997379: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2024-12-08 08:07:06.417831: predicting BRATS_020 
2024-12-08 08:07:06.425923: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2024-12-08 08:07:06.867348: predicting BRATS_028 
2024-12-08 08:07:06.875625: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2024-12-08 08:07:07.292293: predicting BRATS_029 
2024-12-08 08:07:07.308811: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2024-12-08 08:07:07.716339: predicting BRATS_032 
2024-12-08 08:07:07.729962: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2024-12-08 08:07:08.157086: predicting BRATS_034 
2024-12-08 08:07:08.170329: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2024-12-08 08:07:08.596049: predicting BRATS_041 
2024-12-08 08:07:08.612535: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2024-12-08 08:07:09.255440: predicting BRATS_042 
2024-12-08 08:07:09.262692: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2024-12-08 08:07:09.804103: predicting BRATS_047 
2024-12-08 08:07:09.818177: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-08 08:07:10.258104: predicting BRATS_049 
2024-12-08 08:07:10.276567: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-08 08:07:10.734613: predicting BRATS_053 
2024-12-08 08:07:10.749255: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 08:07:11.199067: predicting BRATS_056 
2024-12-08 08:07:11.211088: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 08:07:11.650490: predicting BRATS_057 
2024-12-08 08:07:11.662490: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 08:07:12.077363: predicting BRATS_067 
2024-12-08 08:07:12.089380: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-08 08:07:12.505525: predicting BRATS_069 
2024-12-08 08:07:12.513575: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-08 08:07:12.908813: predicting BRATS_085 
2024-12-08 08:07:12.916893: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2024-12-08 08:07:13.298228: predicting BRATS_086 
2024-12-08 08:07:13.310331: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2024-12-08 08:07:13.724675: predicting BRATS_088 
2024-12-08 08:07:13.732721: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2024-12-08 08:07:14.121326: predicting BRATS_091 
2024-12-08 08:07:14.139414: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2024-12-08 08:07:14.563477: predicting BRATS_098 
2024-12-08 08:07:14.582378: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2024-12-08 08:07:14.991205: predicting BRATS_100 
2024-12-08 08:07:15.007427: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-08 08:07:15.417934: predicting BRATS_101 
2024-12-08 08:07:15.431100: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-08 08:07:15.824697: predicting BRATS_102 
2024-12-08 08:07:15.843961: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2024-12-08 08:07:16.266761: predicting BRATS_104 
2024-12-08 08:07:16.280179: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2024-12-08 08:07:16.722932: predicting BRATS_111 
2024-12-08 08:07:16.739048: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2024-12-08 08:07:17.210772: predicting BRATS_116 
2024-12-08 08:07:17.226871: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2024-12-08 08:07:17.653057: predicting BRATS_135 
2024-12-08 08:07:17.669173: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2024-12-08 08:07:18.103931: predicting BRATS_136 
2024-12-08 08:07:18.120394: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2024-12-08 08:07:18.586630: predicting BRATS_138 
2024-12-08 08:07:18.594745: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2024-12-08 08:07:19.077296: predicting BRATS_145 
2024-12-08 08:07:19.085379: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2024-12-08 08:07:19.543545: predicting BRATS_149 
2024-12-08 08:07:19.559962: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2024-12-08 08:07:19.961410: predicting BRATS_155 
2024-12-08 08:07:19.977755: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-08 08:07:20.404095: predicting BRATS_157 
2024-12-08 08:07:20.417906: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-08 08:07:20.909926: predicting BRATS_158 
2024-12-08 08:07:20.926331: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-08 08:07:21.320333: predicting BRATS_159 
2024-12-08 08:07:21.336542: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-08 08:07:21.738649: predicting BRATS_163 
2024-12-08 08:07:21.755185: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2024-12-08 08:07:22.141590: predicting BRATS_164 
2024-12-08 08:07:22.157700: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2024-12-08 08:07:22.567094: predicting BRATS_169 
2024-12-08 08:07:22.575365: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2024-12-08 08:07:23.073825: predicting BRATS_176 
2024-12-08 08:07:23.082079: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2024-12-08 08:07:23.580289: predicting BRATS_181 
2024-12-08 08:07:23.588693: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2024-12-08 08:07:24.023824: predicting BRATS_183 
2024-12-08 08:07:24.040066: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 08:07:24.522877: predicting BRATS_184 
2024-12-08 08:07:24.531289: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 08:07:24.957953: predicting BRATS_187 
2024-12-08 08:07:24.974068: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 08:07:25.392714: predicting BRATS_192 
2024-12-08 08:07:25.401044: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2024-12-08 08:07:25.867204: predicting BRATS_198 
2024-12-08 08:07:25.875417: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2024-12-08 08:07:26.333819: predicting BRATS_207 
2024-12-08 08:07:26.342126: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-08 08:07:26.800048: predicting BRATS_208 
2024-12-08 08:07:26.808366: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-08 08:07:27.210745: predicting BRATS_218 
2024-12-08 08:07:27.227528: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2024-12-08 08:07:27.710060: predicting BRATS_220 
2024-12-08 08:07:27.726822: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2024-12-08 08:07:28.209174: predicting BRATS_224 
2024-12-08 08:07:28.225645: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2024-12-08 08:07:28.691977: predicting BRATS_230 
2024-12-08 08:07:28.708476: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2024-12-08 08:07:29.110688: predicting BRATS_271 
2024-12-08 08:07:29.119127: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2024-12-08 08:07:29.585200: predicting BRATS_282 
2024-12-08 08:07:29.601262: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2024-12-08 08:07:30.003117: predicting BRATS_284 
2024-12-08 08:07:30.019620: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2024-12-08 08:07:30.452583: predicting BRATS_287 
2024-12-08 08:07:30.462684: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-08 08:07:30.864455: predicting BRATS_290 
2024-12-08 08:07:30.880779: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2024-12-08 08:07:31.307186: predicting BRATS_291 
2024-12-08 08:07:31.315235: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2024-12-08 08:07:31.733422: predicting BRATS_292 
2024-12-08 08:07:31.749704: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2024-12-08 08:07:32.200101: predicting BRATS_293 
2024-12-08 08:07:32.216490: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2024-12-08 08:07:32.731176: predicting BRATS_300 
2024-12-08 08:07:32.739650: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2024-12-08 08:07:33.190061: predicting BRATS_305 
2024-12-08 08:07:33.206802: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2024-12-08 08:07:33.616960: predicting BRATS_311 
2024-12-08 08:07:33.633372: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2024-12-08 08:07:34.044176: predicting BRATS_314 
2024-12-08 08:07:34.060726: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2024-12-08 08:07:34.510691: predicting BRATS_321 
2024-12-08 08:07:34.526846: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2024-12-08 08:07:34.993544: predicting BRATS_328 
2024-12-08 08:07:35.001990: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2024-12-08 08:07:35.468297: predicting BRATS_329 
2024-12-08 08:07:35.484443: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2024-12-08 08:07:35.885592: predicting BRATS_335 
2024-12-08 08:07:35.901990: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2024-12-08 08:07:36.344288: predicting BRATS_343 
2024-12-08 08:07:36.361053: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2024-12-08 08:07:36.816090: predicting BRATS_350 
2024-12-08 08:07:36.827749: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2024-12-08 08:07:37.309429: predicting BRATS_351 
2024-12-08 08:07:37.317802: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2024-12-08 08:07:37.744178: predicting BRATS_356 
2024-12-08 08:07:37.752613: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2024-12-08 08:07:38.242660: predicting BRATS_366 
2024-12-08 08:07:38.259286: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2024-12-08 08:07:38.660909: predicting BRATS_367 
2024-12-08 08:07:38.677099: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2024-12-08 08:07:39.159090: predicting BRATS_374 
2024-12-08 08:07:39.175723: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2024-12-08 08:07:39.651392: predicting BRATS_376 
2024-12-08 08:07:39.659782: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2024-12-08 08:07:40.077957: predicting BRATS_377 
2024-12-08 08:07:40.094122: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2024-12-08 08:07:40.511878: predicting BRATS_378 
2024-12-08 08:07:40.520185: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2024-12-08 08:07:41.018851: predicting BRATS_379 
2024-12-08 08:07:41.027156: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2024-12-08 08:07:41.485843: predicting BRATS_384 
2024-12-08 08:07:41.502397: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2024-12-08 08:07:41.879531: predicting BRATS_386 
2024-12-08 08:07:41.895664: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2024-12-08 08:07:42.305763: predicting BRATS_394 
2024-12-08 08:07:42.314003: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-08 08:07:42.804137: predicting BRATS_398 
2024-12-08 08:07:42.820405: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2024-12-08 08:07:43.270083: predicting BRATS_400 
2024-12-08 08:07:43.286603: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2024-12-08 08:07:43.713075: predicting BRATS_432 
2024-12-08 08:07:43.721435: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2024-12-08 08:07:44.219488: predicting BRATS_437 
2024-12-08 08:07:44.235593: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-08 08:07:44.645398: predicting BRATS_445 
2024-12-08 08:07:44.653469: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2024-12-08 08:07:45.119737: predicting BRATS_446 
2024-12-08 08:07:45.127982: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2024-12-08 08:07:45.618522: predicting BRATS_450 
2024-12-08 08:07:45.626702: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2024-12-08 08:07:46.021057: predicting BRATS_452 
2024-12-08 08:07:46.029155: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2024-12-08 08:07:46.471204: predicting BRATS_460 
2024-12-08 08:07:46.479441: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2024-12-08 08:07:46.961323: predicting BRATS_470 
2024-12-08 08:07:46.969367: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2024-12-08 08:07:47.428207: predicting BRATS_472 
2024-12-08 08:07:47.436672: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2024-12-08 08:07:47.862607: predicting BRATS_473 
2024-12-08 08:07:47.879099: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2024-12-08 08:07:48.285237: predicting BRATS_482 
2024-12-08 08:07:48.297482: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2024-12-08 08:07:55.681637: Validation complete 
2024-12-08 08:07:55.690056: Mean Validation Dice:  0.6982939380966933 
