
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-08 14:25:53.108071: do_dummy_2d_data_aug: False 
2024-12-08 14:25:53.116206: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-08 14:25:53.116206: The split file contains 5 splits. 
2024-12-08 14:25:53.124554: Desired fold for training: 0 
2024-12-08 14:25:53.124554: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 105, 'patch_size': [192, 160], 'median_image_size_in_voxels': [169.0, 138.0], 'spacing': [1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2024-12-08 14:26:23.939219: unpacking dataset... 
2024-12-08 14:26:24.148180: unpacking done... 
2024-12-08 14:26:25.607647:  
2024-12-08 14:26:25.612223: Epoch 0 
2024-12-08 14:26:25.614284: Current learning rate: 0.01 
2024-12-08 14:27:01.026980: train_loss -0.3142 
2024-12-08 14:27:01.035990: val_loss -0.5966 
2024-12-08 14:27:01.039510: Pseudo dice [np.float32(0.73), np.float32(0.563), np.float32(0.8102)] 
2024-12-08 14:27:01.042434: Epoch time: 35.42 s 
2024-12-08 14:27:01.045474: Yayy! New best EMA pseudo Dice: 0.7010999917984009 
2024-12-08 14:27:01.817236:  
2024-12-08 14:27:01.822105: Epoch 1 
2024-12-08 14:27:01.825673: Current learning rate: 0.00991 
2024-12-08 14:27:34.167414: train_loss -0.6909 
2024-12-08 14:27:34.173483: val_loss -0.6872 
2024-12-08 14:27:34.177043: Pseudo dice [np.float32(0.7861), np.float32(0.6726), np.float32(0.8358)] 
2024-12-08 14:27:34.180112: Epoch time: 32.35 s 
2024-12-08 14:27:34.182700: Yayy! New best EMA pseudo Dice: 0.7074000239372253 
2024-12-08 14:27:34.943459:  
2024-12-08 14:27:34.949140: Epoch 2 
2024-12-08 14:27:34.951723: Current learning rate: 0.00982 
2024-12-08 14:28:07.356513: train_loss -0.7508 
2024-12-08 14:28:07.364133: val_loss -0.7069 
2024-12-08 14:28:07.367757: Pseudo dice [np.float32(0.8039), np.float32(0.6785), np.float32(0.8499)] 
2024-12-08 14:28:07.370832: Epoch time: 32.41 s 
2024-12-08 14:28:07.374414: Yayy! New best EMA pseudo Dice: 0.7143999934196472 
2024-12-08 14:28:08.110722:  
2024-12-08 14:28:08.116399: Epoch 3 
2024-12-08 14:28:08.119972: Current learning rate: 0.00973 
2024-12-08 14:28:40.559083: train_loss -0.7697 
2024-12-08 14:28:40.565413: val_loss -0.7253 
2024-12-08 14:28:40.569497: Pseudo dice [np.float32(0.8069), np.float32(0.7082), np.float32(0.8561)] 
2024-12-08 14:28:40.572564: Epoch time: 32.45 s 
2024-12-08 14:28:40.574857: Yayy! New best EMA pseudo Dice: 0.722000002861023 
2024-12-08 14:28:41.271195:  
2024-12-08 14:28:41.276082: Epoch 4 
2024-12-08 14:28:41.279113: Current learning rate: 0.00964 
2024-12-08 14:29:13.770951: train_loss -0.7849 
2024-12-08 14:29:13.778096: val_loss -0.7243 
2024-12-08 14:29:13.780655: Pseudo dice [np.float32(0.8183), np.float32(0.6829), np.float32(0.8592)] 
2024-12-08 14:29:13.784264: Epoch time: 32.5 s 
2024-12-08 14:29:13.786324: Yayy! New best EMA pseudo Dice: 0.7285000085830688 
2024-12-08 14:29:14.515536:  
2024-12-08 14:29:14.520990: Epoch 5 
2024-12-08 14:29:14.524073: Current learning rate: 0.00955 
2024-12-08 14:29:46.806015: train_loss -0.7957 
2024-12-08 14:29:46.811953: val_loss -0.7245 
2024-12-08 14:29:46.815322: Pseudo dice [np.float32(0.8156), np.float32(0.6895), np.float32(0.8584)] 
2024-12-08 14:29:46.818364: Epoch time: 32.29 s 
2024-12-08 14:29:46.821268: Yayy! New best EMA pseudo Dice: 0.734499990940094 
2024-12-08 14:29:47.661414:  
2024-12-08 14:29:47.668038: Epoch 6 
2024-12-08 14:29:47.670950: Current learning rate: 0.00946 
2024-12-08 14:30:20.200204: train_loss -0.8042 
2024-12-08 14:30:20.206796: val_loss -0.7323 
2024-12-08 14:30:20.210072: Pseudo dice [np.float32(0.819), np.float32(0.7057), np.float32(0.8586)] 
2024-12-08 14:30:20.213790: Epoch time: 32.54 s 
2024-12-08 14:30:20.217154: Yayy! New best EMA pseudo Dice: 0.7404000163078308 
2024-12-08 14:30:20.908181:  
2024-12-08 14:30:20.913787: Epoch 7 
2024-12-08 14:30:20.916336: Current learning rate: 0.00937 
2024-12-08 14:30:53.158993: train_loss -0.81 
2024-12-08 14:30:53.164632: val_loss -0.7245 
2024-12-08 14:30:53.167182: Pseudo dice [np.float32(0.8139), np.float32(0.688), np.float32(0.8646)] 
2024-12-08 14:30:53.169734: Epoch time: 32.25 s 
2024-12-08 14:30:53.172282: Yayy! New best EMA pseudo Dice: 0.7452999949455261 
2024-12-08 14:30:53.890208:  
2024-12-08 14:30:53.895315: Epoch 8 
2024-12-08 14:30:53.898409: Current learning rate: 0.00928 
2024-12-08 14:31:26.011224: train_loss -0.8147 
2024-12-08 14:31:26.018862: val_loss -0.7336 
2024-12-08 14:31:26.021438: Pseudo dice [np.float32(0.8144), np.float32(0.7031), np.float32(0.8692)] 
2024-12-08 14:31:26.023979: Epoch time: 32.12 s 
2024-12-08 14:31:26.026522: Yayy! New best EMA pseudo Dice: 0.7502999901771545 
2024-12-08 14:31:26.777356:  
2024-12-08 14:31:26.782477: Epoch 9 
2024-12-08 14:31:26.787058: Current learning rate: 0.00919 
2024-12-08 14:31:58.886789: train_loss -0.82 
2024-12-08 14:31:58.894981: val_loss -0.7175 
2024-12-08 14:31:58.899639: Pseudo dice [np.float32(0.8096), np.float32(0.6806), np.float32(0.8614)] 
2024-12-08 14:31:58.902185: Epoch time: 32.11 s 
2024-12-08 14:31:58.904739: Yayy! New best EMA pseudo Dice: 0.7537000179290771 
2024-12-08 14:31:59.583196:  
2024-12-08 14:31:59.587794: Epoch 10 
2024-12-08 14:31:59.590875: Current learning rate: 0.0091 
2024-12-08 14:32:31.769632: train_loss -0.8236 
2024-12-08 14:32:31.775688: val_loss -0.733 
2024-12-08 14:32:31.778644: Pseudo dice [np.float32(0.8173), np.float32(0.7067), np.float32(0.8639)] 
2024-12-08 14:32:31.781727: Epoch time: 32.19 s 
2024-12-08 14:32:31.784306: Yayy! New best EMA pseudo Dice: 0.7578999996185303 
2024-12-08 14:32:32.476938:  
2024-12-08 14:32:32.481572: Epoch 11 
2024-12-08 14:32:32.484672: Current learning rate: 0.009 
2024-12-08 14:33:04.857876: train_loss -0.8284 
2024-12-08 14:33:04.865548: val_loss -0.7273 
2024-12-08 14:33:04.870646: Pseudo dice [np.float32(0.8168), np.float32(0.6901), np.float32(0.867)] 
2024-12-08 14:33:04.873195: Epoch time: 32.38 s 
2024-12-08 14:33:04.875744: Yayy! New best EMA pseudo Dice: 0.7612000107765198 
2024-12-08 14:33:05.567771:  
2024-12-08 14:33:05.572502: Epoch 12 
2024-12-08 14:33:05.576262: Current learning rate: 0.00891 
2024-12-08 14:33:37.778764: train_loss -0.8302 
2024-12-08 14:33:37.783851: val_loss -0.7219 
2024-12-08 14:33:37.788472: Pseudo dice [np.float32(0.8073), np.float32(0.6883), np.float32(0.8642)] 
2024-12-08 14:33:37.791533: Epoch time: 32.21 s 
2024-12-08 14:33:37.794086: Yayy! New best EMA pseudo Dice: 0.7638000249862671 
2024-12-08 14:33:38.625069:  
2024-12-08 14:33:38.630692: Epoch 13 
2024-12-08 14:33:38.635293: Current learning rate: 0.00882 
2024-12-08 14:34:10.977854: train_loss -0.8327 
2024-12-08 14:34:10.985463: val_loss -0.7345 
2024-12-08 14:34:10.988602: Pseudo dice [np.float32(0.8204), np.float32(0.7024), np.float32(0.8703)] 
2024-12-08 14:34:10.992648: Epoch time: 32.35 s 
2024-12-08 14:34:10.995710: Yayy! New best EMA pseudo Dice: 0.7671999931335449 
2024-12-08 14:34:11.682261:  
2024-12-08 14:34:11.687324: Epoch 14 
2024-12-08 14:34:11.691385: Current learning rate: 0.00873 
2024-12-08 14:34:43.792372: train_loss -0.8334 
2024-12-08 14:34:43.799472: val_loss -0.724 
2024-12-08 14:34:43.803104: Pseudo dice [np.float32(0.8164), np.float32(0.692), np.float32(0.8582)] 
2024-12-08 14:34:43.806152: Epoch time: 32.11 s 
2024-12-08 14:34:43.808186: Yayy! New best EMA pseudo Dice: 0.7692999839782715 
2024-12-08 14:34:44.496771:  
2024-12-08 14:34:44.502918: Epoch 15 
2024-12-08 14:34:44.505986: Current learning rate: 0.00864 
2024-12-08 14:35:16.625073: train_loss -0.836 
2024-12-08 14:35:16.632707: val_loss -0.7325 
2024-12-08 14:35:16.638304: Pseudo dice [np.float32(0.819), np.float32(0.7032), np.float32(0.864)] 
2024-12-08 14:35:16.640332: Epoch time: 32.13 s 
2024-12-08 14:35:16.644913: Yayy! New best EMA pseudo Dice: 0.7718999981880188 
2024-12-08 14:35:17.348801:  
2024-12-08 14:35:17.356443: Epoch 16 
2024-12-08 14:35:17.359504: Current learning rate: 0.00855 
2024-12-08 14:35:49.476833: train_loss -0.8386 
2024-12-08 14:35:49.482979: val_loss -0.722 
2024-12-08 14:35:49.486044: Pseudo dice [np.float32(0.812), np.float32(0.686), np.float32(0.8668)] 
2024-12-08 14:35:49.489095: Epoch time: 32.13 s 
2024-12-08 14:35:49.491639: Yayy! New best EMA pseudo Dice: 0.7735999822616577 
2024-12-08 14:35:50.203236:  
2024-12-08 14:35:50.208309: Epoch 17 
2024-12-08 14:35:50.210847: Current learning rate: 0.00846 
2024-12-08 14:36:22.312011: train_loss -0.839 
2024-12-08 14:36:22.319622: val_loss -0.7313 
2024-12-08 14:36:22.323177: Pseudo dice [np.float32(0.8179), np.float32(0.7038), np.float32(0.8637)] 
2024-12-08 14:36:22.326810: Epoch time: 32.11 s 
2024-12-08 14:36:22.330379: Yayy! New best EMA pseudo Dice: 0.7756999731063843 
2024-12-08 14:36:23.025464:  
2024-12-08 14:36:23.031566: Epoch 18 
2024-12-08 14:36:23.034104: Current learning rate: 0.00836 
2024-12-08 14:36:55.145153: train_loss -0.8403 
2024-12-08 14:36:55.150773: val_loss -0.7238 
2024-12-08 14:36:55.155331: Pseudo dice [np.float32(0.8143), np.float32(0.6865), np.float32(0.8663)] 
2024-12-08 14:36:55.160408: Epoch time: 32.12 s 
2024-12-08 14:36:55.163558: Yayy! New best EMA pseudo Dice: 0.7771000266075134 
2024-12-08 14:36:55.867303:  
2024-12-08 14:36:55.872364: Epoch 19 
2024-12-08 14:36:55.876443: Current learning rate: 0.00827 
2024-12-08 14:37:28.051067: train_loss -0.8412 
2024-12-08 14:37:28.058668: val_loss -0.7248 
2024-12-08 14:37:28.061764: Pseudo dice [np.float32(0.8191), np.float32(0.688), np.float32(0.8591)] 
2024-12-08 14:37:28.066338: Epoch time: 32.18 s 
2024-12-08 14:37:28.069403: Yayy! New best EMA pseudo Dice: 0.7781999707221985 
2024-12-08 14:37:28.778051:  
2024-12-08 14:37:28.783189: Epoch 20 
2024-12-08 14:37:28.786752: Current learning rate: 0.00818 
2024-12-08 14:38:00.911508: train_loss -0.8453 
2024-12-08 14:38:00.917670: val_loss -0.7282 
2024-12-08 14:38:00.921734: Pseudo dice [np.float32(0.8163), np.float32(0.7006), np.float32(0.8661)] 
2024-12-08 14:38:00.925349: Epoch time: 32.13 s 
2024-12-08 14:38:00.929491: Yayy! New best EMA pseudo Dice: 0.7797999978065491 
2024-12-08 14:38:01.801855:  
2024-12-08 14:38:01.808535: Epoch 21 
2024-12-08 14:38:01.812143: Current learning rate: 0.00809 
2024-12-08 14:38:33.952878: train_loss -0.8457 
2024-12-08 14:38:33.960523: val_loss -0.7286 
2024-12-08 14:38:33.965651: Pseudo dice [np.float32(0.8184), np.float32(0.6908), np.float32(0.8661)] 
2024-12-08 14:38:33.968727: Epoch time: 32.15 s 
2024-12-08 14:38:33.971265: Yayy! New best EMA pseudo Dice: 0.781000018119812 
2024-12-08 14:38:34.641203:  
2024-12-08 14:38:34.647310: Epoch 22 
2024-12-08 14:38:34.650881: Current learning rate: 0.008 
2024-12-08 14:39:06.769986: train_loss -0.8461 
2024-12-08 14:39:06.777670: val_loss -0.7337 
2024-12-08 14:39:06.780207: Pseudo dice [np.float32(0.8158), np.float32(0.7072), np.float32(0.8682)] 
2024-12-08 14:39:06.784751: Epoch time: 32.13 s 
2024-12-08 14:39:06.787839: Yayy! New best EMA pseudo Dice: 0.7825999855995178 
2024-12-08 14:39:07.465955:  
2024-12-08 14:39:07.471048: Epoch 23 
2024-12-08 14:39:07.475621: Current learning rate: 0.0079 
2024-12-08 14:39:39.419014: train_loss -0.8492 
2024-12-08 14:39:39.426634: val_loss -0.7305 
2024-12-08 14:39:39.431203: Pseudo dice [np.float32(0.8162), np.float32(0.7043), np.float32(0.8652)] 
2024-12-08 14:39:39.434316: Epoch time: 31.95 s 
2024-12-08 14:39:39.436862: Yayy! New best EMA pseudo Dice: 0.7839000225067139 
2024-12-08 14:39:40.104714:  
2024-12-08 14:39:40.110837: Epoch 24 
2024-12-08 14:39:40.115494: Current learning rate: 0.00781 
2024-12-08 14:40:12.058391: train_loss -0.8489 
2024-12-08 14:40:12.064474: val_loss -0.727 
2024-12-08 14:40:12.068069: Pseudo dice [np.float32(0.8154), np.float32(0.6979), np.float32(0.8672)] 
2024-12-08 14:40:12.072120: Epoch time: 31.95 s 
2024-12-08 14:40:12.075176: Yayy! New best EMA pseudo Dice: 0.7849000096321106 
2024-12-08 14:40:12.754127:  
2024-12-08 14:40:12.759721: Epoch 25 
2024-12-08 14:40:12.762266: Current learning rate: 0.00772 
2024-12-08 14:40:44.715170: train_loss -0.8504 
2024-12-08 14:40:44.722327: val_loss -0.7331 
2024-12-08 14:40:44.724872: Pseudo dice [np.float32(0.815), np.float32(0.7077), np.float32(0.8718)] 
2024-12-08 14:40:44.729943: Epoch time: 31.96 s 
2024-12-08 14:40:44.733002: Yayy! New best EMA pseudo Dice: 0.7861999869346619 
2024-12-08 14:40:45.410840:  
2024-12-08 14:40:45.417502: Epoch 26 
2024-12-08 14:40:45.421058: Current learning rate: 0.00763 
2024-12-08 14:41:17.367496: train_loss -0.8502 
2024-12-08 14:41:17.373080: val_loss -0.7325 
2024-12-08 14:41:17.377669: Pseudo dice [np.float32(0.8147), np.float32(0.7081), np.float32(0.8679)] 
2024-12-08 14:41:17.380740: Epoch time: 31.96 s 
2024-12-08 14:41:17.384288: Yayy! New best EMA pseudo Dice: 0.7872999906539917 
2024-12-08 14:41:18.059233:  
2024-12-08 14:41:18.064345: Epoch 27 
2024-12-08 14:41:18.068429: Current learning rate: 0.00753 
2024-12-08 14:41:50.000791: train_loss -0.8516 
2024-12-08 14:41:50.005889: val_loss -0.7285 
2024-12-08 14:41:50.010991: Pseudo dice [np.float32(0.8196), np.float32(0.6944), np.float32(0.8668)] 
2024-12-08 14:41:50.013581: Epoch time: 31.94 s 
2024-12-08 14:41:50.017653: Yayy! New best EMA pseudo Dice: 0.7878999710083008 
2024-12-08 14:41:50.704548:  
2024-12-08 14:41:50.709645: Epoch 28 
2024-12-08 14:41:50.713760: Current learning rate: 0.00744 
2024-12-08 14:42:22.667216: train_loss -0.8535 
2024-12-08 14:42:22.675394: val_loss -0.7351 
2024-12-08 14:42:22.678958: Pseudo dice [np.float32(0.8159), np.float32(0.7163), np.float32(0.8648)] 
2024-12-08 14:42:22.683052: Epoch time: 31.96 s 
2024-12-08 14:42:22.685595: Yayy! New best EMA pseudo Dice: 0.7889999747276306 
2024-12-08 14:42:23.523305:  
2024-12-08 14:42:23.528409: Epoch 29 
2024-12-08 14:42:23.532012: Current learning rate: 0.00735 
2024-12-08 14:42:55.486905: train_loss -0.8532 
2024-12-08 14:42:55.494102: val_loss -0.7302 
2024-12-08 14:42:55.497161: Pseudo dice [np.float32(0.8177), np.float32(0.7047), np.float32(0.8621)] 
2024-12-08 14:42:55.501264: Epoch time: 31.97 s 
2024-12-08 14:42:55.503816: Yayy! New best EMA pseudo Dice: 0.7896000146865845 
2024-12-08 14:42:56.202453:  
2024-12-08 14:42:56.207588: Epoch 30 
2024-12-08 14:42:56.212233: Current learning rate: 0.00725 
2024-12-08 14:43:28.136916: train_loss -0.8536 
2024-12-08 14:43:28.145656: val_loss -0.7306 
2024-12-08 14:43:28.148224: Pseudo dice [np.float32(0.8171), np.float32(0.7043), np.float32(0.8662)] 
2024-12-08 14:43:28.153352: Epoch time: 31.93 s 
2024-12-08 14:43:28.157000: Yayy! New best EMA pseudo Dice: 0.7901999950408936 
2024-12-08 14:43:28.849770:  
2024-12-08 14:43:28.855919: Epoch 31 
2024-12-08 14:43:28.860018: Current learning rate: 0.00716 
2024-12-08 14:44:00.790053: train_loss -0.8555 
2024-12-08 14:44:00.797197: val_loss -0.7317 
2024-12-08 14:44:00.799747: Pseudo dice [np.float32(0.8186), np.float32(0.7072), np.float32(0.8647)] 
2024-12-08 14:44:00.805206: Epoch time: 31.94 s 
2024-12-08 14:44:00.808246: Yayy! New best EMA pseudo Dice: 0.7908999919891357 
2024-12-08 14:44:01.497867:  
2024-12-08 14:44:01.503501: Epoch 32 
2024-12-08 14:44:01.507576: Current learning rate: 0.00707 
2024-12-08 14:44:33.446709: train_loss -0.8562 
2024-12-08 14:44:33.454319: val_loss -0.7321 
2024-12-08 14:44:33.458393: Pseudo dice [np.float32(0.8196), np.float32(0.7013), np.float32(0.8662)] 
2024-12-08 14:44:33.461998: Epoch time: 31.95 s 
2024-12-08 14:44:33.464555: Yayy! New best EMA pseudo Dice: 0.7914000153541565 
2024-12-08 14:44:34.152767:  
2024-12-08 14:44:34.157856: Epoch 33 
2024-12-08 14:44:34.160401: Current learning rate: 0.00697 
2024-12-08 14:45:06.111574: train_loss -0.8575 
2024-12-08 14:45:06.116695: val_loss -0.723 
2024-12-08 14:45:06.121276: Pseudo dice [np.float32(0.8178), np.float32(0.6859), np.float32(0.8626)] 
2024-12-08 14:45:06.124919: Epoch time: 31.96 s 
2024-12-08 14:45:06.697938:  
2024-12-08 14:45:06.703051: Epoch 34 
2024-12-08 14:45:06.706122: Current learning rate: 0.00688 
2024-12-08 14:45:38.631052: train_loss -0.8589 
2024-12-08 14:45:38.639197: val_loss -0.7338 
2024-12-08 14:45:38.641776: Pseudo dice [np.float32(0.8211), np.float32(0.707), np.float32(0.8665)] 
2024-12-08 14:45:38.646882: Epoch time: 31.93 s 
2024-12-08 14:45:38.649426: Yayy! New best EMA pseudo Dice: 0.7918000221252441 
2024-12-08 14:45:39.357157:  
2024-12-08 14:45:39.363307: Epoch 35 
2024-12-08 14:45:39.366879: Current learning rate: 0.00679 
2024-12-08 14:46:11.321159: train_loss -0.8573 
2024-12-08 14:46:11.327803: val_loss -0.7295 
2024-12-08 14:46:11.330864: Pseudo dice [np.float32(0.8186), np.float32(0.6978), np.float32(0.8667)] 
2024-12-08 14:46:11.334437: Epoch time: 31.96 s 
2024-12-08 14:46:11.338548: Yayy! New best EMA pseudo Dice: 0.7921000123023987 
2024-12-08 14:46:12.169052:  
2024-12-08 14:46:12.175198: Epoch 36 
2024-12-08 14:46:12.177749: Current learning rate: 0.00669 
2024-12-08 14:46:44.115758: train_loss -0.8589 
2024-12-08 14:46:44.123910: val_loss -0.7221 
2024-12-08 14:46:44.126978: Pseudo dice [np.float32(0.8169), np.float32(0.6901), np.float32(0.8626)] 
2024-12-08 14:46:44.131582: Epoch time: 31.95 s 
2024-12-08 14:46:44.713487:  
2024-12-08 14:46:44.719072: Epoch 37 
2024-12-08 14:46:44.723122: Current learning rate: 0.0066 
2024-12-08 14:47:16.656952: train_loss -0.8585 
2024-12-08 14:47:16.663049: val_loss -0.7322 
2024-12-08 14:47:16.666109: Pseudo dice [np.float32(0.8177), np.float32(0.7086), np.float32(0.8648)] 
2024-12-08 14:47:16.670171: Epoch time: 31.94 s 
2024-12-08 14:47:16.673277: Yayy! New best EMA pseudo Dice: 0.7924000024795532 
2024-12-08 14:47:17.380608:  
2024-12-08 14:47:17.386705: Epoch 38 
2024-12-08 14:47:17.390277: Current learning rate: 0.0065 
2024-12-08 14:47:49.319594: train_loss -0.8604 
2024-12-08 14:47:49.327209: val_loss -0.7363 
2024-12-08 14:47:49.331274: Pseudo dice [np.float32(0.8199), np.float32(0.7103), np.float32(0.87)] 
2024-12-08 14:47:49.334435: Epoch time: 31.94 s 
2024-12-08 14:47:49.336987: Yayy! New best EMA pseudo Dice: 0.7930999994277954 
2024-12-08 14:47:50.035869:  
2024-12-08 14:47:50.041971: Epoch 39 
2024-12-08 14:47:50.044050: Current learning rate: 0.00641 
2024-12-08 14:48:22.002989: train_loss -0.8611 
2024-12-08 14:48:22.010665: val_loss -0.7302 
2024-12-08 14:48:22.013218: Pseudo dice [np.float32(0.8145), np.float32(0.7016), np.float32(0.8696)] 
2024-12-08 14:48:22.018314: Epoch time: 31.97 s 
2024-12-08 14:48:22.020910: Yayy! New best EMA pseudo Dice: 0.7932999730110168 
2024-12-08 14:48:22.736403:  
2024-12-08 14:48:22.743112: Epoch 40 
2024-12-08 14:48:22.746691: Current learning rate: 0.00631 
2024-12-08 14:48:54.688455: train_loss -0.8608 
2024-12-08 14:48:54.694056: val_loss -0.7264 
2024-12-08 14:48:54.698627: Pseudo dice [np.float32(0.817), np.float32(0.6926), np.float32(0.8654)] 
2024-12-08 14:48:54.701713: Epoch time: 31.95 s 
2024-12-08 14:48:55.297654:  
2024-12-08 14:48:55.303269: Epoch 41 
2024-12-08 14:48:55.306835: Current learning rate: 0.00622 
2024-12-08 14:49:27.260059: train_loss -0.861 
2024-12-08 14:49:27.267189: val_loss -0.7284 
2024-12-08 14:49:27.270273: Pseudo dice [np.float32(0.8162), np.float32(0.704), np.float32(0.8659)] 
2024-12-08 14:49:27.274329: Epoch time: 31.96 s 
2024-12-08 14:49:27.277904: Yayy! New best EMA pseudo Dice: 0.79339998960495 
2024-12-08 14:49:27.971546:  
2024-12-08 14:49:27.976618: Epoch 42 
2024-12-08 14:49:27.979688: Current learning rate: 0.00612 
2024-12-08 14:49:59.922707: train_loss -0.8613 
2024-12-08 14:49:59.929823: val_loss -0.7365 
2024-12-08 14:49:59.932909: Pseudo dice [np.float32(0.8202), np.float32(0.7105), np.float32(0.8683)] 
2024-12-08 14:49:59.935459: Epoch time: 31.95 s 
2024-12-08 14:49:59.940556: Yayy! New best EMA pseudo Dice: 0.7940000295639038 
2024-12-08 14:50:00.618727:  
2024-12-08 14:50:00.624408: Epoch 43 
2024-12-08 14:50:00.626967: Current learning rate: 0.00603 
2024-12-08 14:50:32.659062: train_loss -0.8624 
2024-12-08 14:50:32.664167: val_loss -0.7295 
2024-12-08 14:50:32.668234: Pseudo dice [np.float32(0.817), np.float32(0.7011), np.float32(0.8645)] 
2024-12-08 14:50:32.671818: Epoch time: 32.04 s 
2024-12-08 14:50:32.674876: Yayy! New best EMA pseudo Dice: 0.7940000295639038 
2024-12-08 14:50:33.349550:  
2024-12-08 14:50:33.355640: Epoch 44 
2024-12-08 14:50:33.359725: Current learning rate: 0.00593 
2024-12-08 14:51:05.277417: train_loss -0.8631 
2024-12-08 14:51:05.284568: val_loss -0.7313 
2024-12-08 14:51:05.286609: Pseudo dice [np.float32(0.8229), np.float32(0.7054), np.float32(0.8614)] 
2024-12-08 14:51:05.291692: Epoch time: 31.93 s 
2024-12-08 14:51:05.294232: Yayy! New best EMA pseudo Dice: 0.7943000197410583 
2024-12-08 14:51:05.980274:  
2024-12-08 14:51:05.985356: Epoch 45 
2024-12-08 14:51:05.987904: Current learning rate: 0.00584 
2024-12-08 14:51:37.933781: train_loss -0.8636 
2024-12-08 14:51:37.940929: val_loss -0.722 
2024-12-08 14:51:37.943996: Pseudo dice [np.float32(0.8152), np.float32(0.6887), np.float32(0.8673)] 
2024-12-08 14:51:37.949098: Epoch time: 31.95 s 
2024-12-08 14:51:38.494309:  
2024-12-08 14:51:38.501455: Epoch 46 
2024-12-08 14:51:38.504574: Current learning rate: 0.00574 
2024-12-08 14:52:10.459337: train_loss -0.863 
2024-12-08 14:52:10.466021: val_loss -0.7175 
2024-12-08 14:52:10.468058: Pseudo dice [np.float32(0.8129), np.float32(0.6827), np.float32(0.863)] 
2024-12-08 14:52:10.473189: Epoch time: 31.97 s 
2024-12-08 14:52:11.044429:  
2024-12-08 14:52:11.051615: Epoch 47 
2024-12-08 14:52:11.054674: Current learning rate: 0.00565 
2024-12-08 14:52:48.346272: train_loss -0.865 
2024-12-08 14:52:48.352404: val_loss -0.7271 
2024-12-08 14:52:48.356489: Pseudo dice [np.float32(0.8176), np.float32(0.696), np.float32(0.8678)] 
2024-12-08 14:52:48.360074: Epoch time: 37.3 s 
2024-12-08 14:52:48.926705:  
2024-12-08 14:52:48.931852: Epoch 48 
2024-12-08 14:52:48.935462: Current learning rate: 0.00555 
2024-12-08 14:53:21.130773: train_loss -0.8643 
2024-12-08 14:53:21.138419: val_loss -0.7302 
2024-12-08 14:53:21.140957: Pseudo dice [np.float32(0.8195), np.float32(0.696), np.float32(0.8683)] 
2024-12-08 14:53:21.146043: Epoch time: 32.21 s 
2024-12-08 14:53:21.739231:  
2024-12-08 14:53:21.744857: Epoch 49 
2024-12-08 14:53:21.749964: Current learning rate: 0.00546 
2024-12-08 14:53:53.963286: train_loss -0.8657 
2024-12-08 14:53:53.968863: val_loss -0.7301 
2024-12-08 14:53:53.972955: Pseudo dice [np.float32(0.8213), np.float32(0.7), np.float32(0.8665)] 
2024-12-08 14:53:53.976602: Epoch time: 32.23 s 
2024-12-08 14:53:54.640813:  
2024-12-08 14:53:54.646416: Epoch 50 
2024-12-08 14:53:54.649996: Current learning rate: 0.00536 
2024-12-08 14:54:26.940474: train_loss -0.8665 
2024-12-08 14:54:26.946074: val_loss -0.7328 
2024-12-08 14:54:26.948611: Pseudo dice [np.float32(0.8213), np.float32(0.702), np.float32(0.8688)] 
2024-12-08 14:54:26.953741: Epoch time: 32.3 s 
2024-12-08 14:54:27.524248:  
2024-12-08 14:54:27.530340: Epoch 51 
2024-12-08 14:54:27.532940: Current learning rate: 0.00526 
2024-12-08 14:54:59.832155: train_loss -0.8659 
2024-12-08 14:54:59.839279: val_loss -0.7292 
2024-12-08 14:54:59.841820: Pseudo dice [np.float32(0.8178), np.float32(0.6984), np.float32(0.8679)] 
2024-12-08 14:54:59.845372: Epoch time: 32.31 s 
2024-12-08 14:55:00.408211:  
2024-12-08 14:55:00.414308: Epoch 52 
2024-12-08 14:55:00.417447: Current learning rate: 0.00517 
2024-12-08 14:55:32.640944: train_loss -0.8663 
2024-12-08 14:55:32.648564: val_loss -0.727 
2024-12-08 14:55:32.651616: Pseudo dice [np.float32(0.8159), np.float32(0.7001), np.float32(0.8639)] 
2024-12-08 14:55:32.654149: Epoch time: 32.23 s 
2024-12-08 14:55:33.297059:  
2024-12-08 14:55:33.303741: Epoch 53 
2024-12-08 14:55:33.307296: Current learning rate: 0.00507 
2024-12-08 14:56:05.533248: train_loss -0.8658 
2024-12-08 14:56:05.538383: val_loss -0.7391 
2024-12-08 14:56:05.542438: Pseudo dice [np.float32(0.8236), np.float32(0.7092), np.float32(0.8723)] 
2024-12-08 14:56:05.545999: Epoch time: 32.24 s 
2024-12-08 14:56:05.548542: Yayy! New best EMA pseudo Dice: 0.794700026512146 
2024-12-08 14:56:06.241596:  
2024-12-08 14:56:06.246662: Epoch 54 
2024-12-08 14:56:06.249268: Current learning rate: 0.00497 
2024-12-08 14:56:38.471391: train_loss -0.8674 
2024-12-08 14:56:38.477019: val_loss -0.7253 
2024-12-08 14:56:38.481604: Pseudo dice [np.float32(0.8167), np.float32(0.6999), np.float32(0.8651)] 
2024-12-08 14:56:38.484138: Epoch time: 32.23 s 
2024-12-08 14:56:39.046695:  
2024-12-08 14:56:39.051775: Epoch 55 
2024-12-08 14:56:39.054314: Current learning rate: 0.00487 
2024-12-08 14:57:11.255134: train_loss -0.8677 
2024-12-08 14:57:11.262232: val_loss -0.7239 
2024-12-08 14:57:11.265295: Pseudo dice [np.float32(0.8154), np.float32(0.6977), np.float32(0.8682)] 
2024-12-08 14:57:11.267842: Epoch time: 32.21 s 
2024-12-08 14:57:11.836097:  
2024-12-08 14:57:11.841171: Epoch 56 
2024-12-08 14:57:11.845736: Current learning rate: 0.00478 
2024-12-08 14:57:47.334166: train_loss -0.8677 
2024-12-08 14:57:47.340059: val_loss -0.7286 
2024-12-08 14:57:47.344125: Pseudo dice [np.float32(0.8195), np.float32(0.6973), np.float32(0.8654)] 
2024-12-08 14:57:47.349232: Epoch time: 35.5 s 
2024-12-08 14:57:48.026098:  
2024-12-08 14:57:48.032269: Epoch 57 
2024-12-08 14:57:48.035813: Current learning rate: 0.00468 
2024-12-08 14:58:20.632273: train_loss -0.8683 
2024-12-08 14:58:20.637885: val_loss -0.7269 
2024-12-08 14:58:20.641930: Pseudo dice [np.float32(0.818), np.float32(0.6915), np.float32(0.8711)] 
2024-12-08 14:58:20.645498: Epoch time: 32.61 s 
2024-12-08 14:58:21.211491:  
2024-12-08 14:58:21.219160: Epoch 58 
2024-12-08 14:58:21.222750: Current learning rate: 0.00458 
2024-12-08 14:58:53.347159: train_loss -0.8682 
2024-12-08 14:58:53.354347: val_loss -0.723 
2024-12-08 14:58:53.357399: Pseudo dice [np.float32(0.8126), np.float32(0.6944), np.float32(0.8649)] 
2024-12-08 14:58:53.360554: Epoch time: 32.14 s 
2024-12-08 14:58:54.099005:  
2024-12-08 14:58:54.103081: Epoch 59 
2024-12-08 14:58:54.106663: Current learning rate: 0.00448 
2024-12-08 14:59:26.251295: train_loss -0.8698 
2024-12-08 14:59:26.258482: val_loss -0.7263 
2024-12-08 14:59:26.263090: Pseudo dice [np.float32(0.8159), np.float32(0.7004), np.float32(0.8656)] 
2024-12-08 14:59:26.265642: Epoch time: 32.15 s 
2024-12-08 14:59:26.856125:  
2024-12-08 14:59:26.861296: Epoch 60 
2024-12-08 14:59:26.864393: Current learning rate: 0.00438 
2024-12-08 14:59:58.984637: train_loss -0.8699 
2024-12-08 14:59:58.991292: val_loss -0.7325 
2024-12-08 14:59:58.994866: Pseudo dice [np.float32(0.8203), np.float32(0.7087), np.float32(0.8666)] 
2024-12-08 14:59:58.996900: Epoch time: 32.13 s 
2024-12-08 14:59:59.588847:  
2024-12-08 14:59:59.595436: Epoch 61 
2024-12-08 14:59:59.599011: Current learning rate: 0.00429 
2024-12-08 15:00:31.706394: train_loss -0.8677 
2024-12-08 15:00:31.714021: val_loss -0.723 
2024-12-08 15:00:31.717599: Pseudo dice [np.float32(0.817), np.float32(0.6871), np.float32(0.8665)] 
2024-12-08 15:00:31.720182: Epoch time: 32.12 s 
2024-12-08 15:00:32.300302:  
2024-12-08 15:00:32.305970: Epoch 62 
2024-12-08 15:00:32.309018: Current learning rate: 0.00419 
2024-12-08 15:01:04.438907: train_loss -0.8701 
2024-12-08 15:01:04.446523: val_loss -0.7221 
2024-12-08 15:01:04.449056: Pseudo dice [np.float32(0.8119), np.float32(0.7011), np.float32(0.8609)] 
2024-12-08 15:01:04.451606: Epoch time: 32.14 s 
2024-12-08 15:01:05.032582:  
2024-12-08 15:01:05.038166: Epoch 63 
2024-12-08 15:01:05.040731: Current learning rate: 0.00409 
2024-12-08 15:01:37.166466: train_loss -0.8715 
2024-12-08 15:01:37.174086: val_loss -0.7336 
2024-12-08 15:01:37.177204: Pseudo dice [np.float32(0.8218), np.float32(0.7103), np.float32(0.8662)] 
2024-12-08 15:01:37.180792: Epoch time: 32.13 s 
2024-12-08 15:01:37.757810:  
2024-12-08 15:01:37.762908: Epoch 64 
2024-12-08 15:01:37.765481: Current learning rate: 0.00399 
2024-12-08 15:02:09.883451: train_loss -0.8713 
2024-12-08 15:02:09.890628: val_loss -0.7286 
2024-12-08 15:02:09.893191: Pseudo dice [np.float32(0.8208), np.float32(0.6977), np.float32(0.8666)] 
2024-12-08 15:02:09.897770: Epoch time: 32.13 s 
2024-12-08 15:02:10.511147:  
2024-12-08 15:02:10.516257: Epoch 65 
2024-12-08 15:02:10.519845: Current learning rate: 0.00389 
2024-12-08 15:02:42.642369: train_loss -0.87 
2024-12-08 15:02:42.649516: val_loss -0.7256 
2024-12-08 15:02:42.653157: Pseudo dice [np.float32(0.8144), np.float32(0.6985), np.float32(0.8683)] 
2024-12-08 15:02:42.656240: Epoch time: 32.13 s 
2024-12-08 15:02:43.242696:  
2024-12-08 15:02:43.247832: Epoch 66 
2024-12-08 15:02:43.250969: Current learning rate: 0.00379 
2024-12-08 15:03:15.370542: train_loss -0.871 
2024-12-08 15:03:15.378212: val_loss -0.7241 
2024-12-08 15:03:15.380759: Pseudo dice [np.float32(0.8159), np.float32(0.6992), np.float32(0.8625)] 
2024-12-08 15:03:15.383307: Epoch time: 32.13 s 
2024-12-08 15:03:16.131712:  
2024-12-08 15:03:16.136795: Epoch 67 
2024-12-08 15:03:16.139891: Current learning rate: 0.00369 
2024-12-08 15:03:48.242866: train_loss -0.8719 
2024-12-08 15:03:48.249521: val_loss -0.7325 
2024-12-08 15:03:48.253128: Pseudo dice [np.float32(0.8189), np.float32(0.7081), np.float32(0.8677)] 
2024-12-08 15:03:48.256216: Epoch time: 32.11 s 
2024-12-08 15:03:48.839582:  
2024-12-08 15:03:48.846248: Epoch 68 
2024-12-08 15:03:48.849331: Current learning rate: 0.00359 
2024-12-08 15:04:20.964651: train_loss -0.8727 
2024-12-08 15:04:20.971287: val_loss -0.7255 
2024-12-08 15:04:20.974404: Pseudo dice [np.float32(0.8157), np.float32(0.7), np.float32(0.8651)] 
2024-12-08 15:04:20.977490: Epoch time: 32.13 s 
2024-12-08 15:04:21.572656:  
2024-12-08 15:04:21.577753: Epoch 69 
2024-12-08 15:04:21.580853: Current learning rate: 0.00349 
2024-12-08 15:04:53.707124: train_loss -0.8714 
2024-12-08 15:04:53.714791: val_loss -0.7355 
2024-12-08 15:04:53.717339: Pseudo dice [np.float32(0.825), np.float32(0.7087), np.float32(0.8705)] 
2024-12-08 15:04:53.719897: Epoch time: 32.14 s 
2024-12-08 15:04:53.724478: Yayy! New best EMA pseudo Dice: 0.795199990272522 
2024-12-08 15:04:54.439205:  
2024-12-08 15:04:54.443372: Epoch 70 
2024-12-08 15:04:54.446969: Current learning rate: 0.00338 
2024-12-08 15:05:26.461407: train_loss -0.8736 
2024-12-08 15:05:26.469088: val_loss -0.725 
2024-12-08 15:05:26.472207: Pseudo dice [np.float32(0.8169), np.float32(0.6947), np.float32(0.8631)] 
2024-12-08 15:05:26.475784: Epoch time: 32.02 s 
2024-12-08 15:05:27.064424:  
2024-12-08 15:05:27.070064: Epoch 71 
2024-12-08 15:05:27.072624: Current learning rate: 0.00328 
2024-12-08 15:05:59.000809: train_loss -0.8725 
2024-12-08 15:05:59.006455: val_loss -0.7315 
2024-12-08 15:05:59.008998: Pseudo dice [np.float32(0.8197), np.float32(0.7035), np.float32(0.8701)] 
2024-12-08 15:05:59.013574: Epoch time: 31.94 s 
2024-12-08 15:05:59.601274:  
2024-12-08 15:05:59.606375: Epoch 72 
2024-12-08 15:05:59.608927: Current learning rate: 0.00318 
2024-12-08 15:06:31.565477: train_loss -0.8735 
2024-12-08 15:06:31.573062: val_loss -0.7286 
2024-12-08 15:06:31.575611: Pseudo dice [np.float32(0.8196), np.float32(0.7034), np.float32(0.8669)] 
2024-12-08 15:06:31.579738: Epoch time: 31.96 s 
2024-12-08 15:06:31.582829: Yayy! New best EMA pseudo Dice: 0.7953000068664551 
2024-12-08 15:06:32.298228:  
2024-12-08 15:06:32.303843: Epoch 73 
2024-12-08 15:06:32.306937: Current learning rate: 0.00308 
2024-12-08 15:07:04.243275: train_loss -0.8735 
2024-12-08 15:07:04.249893: val_loss -0.733 
2024-12-08 15:07:04.252441: Pseudo dice [np.float32(0.8165), np.float32(0.7109), np.float32(0.8722)] 
2024-12-08 15:07:04.256110: Epoch time: 31.95 s 
2024-12-08 15:07:04.258662: Yayy! New best EMA pseudo Dice: 0.7957000136375427 
2024-12-08 15:07:05.156018:  
2024-12-08 15:07:05.161709: Epoch 74 
2024-12-08 15:07:05.164278: Current learning rate: 0.00297 
2024-12-08 15:07:37.093568: train_loss -0.8737 
2024-12-08 15:07:37.101806: val_loss -0.7266 
2024-12-08 15:07:37.104879: Pseudo dice [np.float32(0.8167), np.float32(0.7018), np.float32(0.8669)] 
2024-12-08 15:07:37.107420: Epoch time: 31.94 s 
2024-12-08 15:07:37.711845:  
2024-12-08 15:07:37.717005: Epoch 75 
2024-12-08 15:07:37.720081: Current learning rate: 0.00287 
2024-12-08 15:08:09.644382: train_loss -0.8748 
2024-12-08 15:08:09.649496: val_loss -0.7254 
2024-12-08 15:08:09.652602: Pseudo dice [np.float32(0.8203), np.float32(0.6962), np.float32(0.866)] 
2024-12-08 15:08:09.657169: Epoch time: 31.93 s 
2024-12-08 15:08:10.245501:  
2024-12-08 15:08:10.251698: Epoch 76 
2024-12-08 15:08:10.255279: Current learning rate: 0.00277 
2024-12-08 15:08:42.180094: train_loss -0.8753 
2024-12-08 15:08:42.187278: val_loss -0.7259 
2024-12-08 15:08:42.190335: Pseudo dice [np.float32(0.8143), np.float32(0.6988), np.float32(0.869)] 
2024-12-08 15:08:42.192880: Epoch time: 31.93 s 
2024-12-08 15:08:42.782644:  
2024-12-08 15:08:42.787722: Epoch 77 
2024-12-08 15:08:42.790814: Current learning rate: 0.00266 
2024-12-08 15:09:14.703271: train_loss -0.8748 
2024-12-08 15:09:14.710356: val_loss -0.7238 
2024-12-08 15:09:14.724173: Pseudo dice [np.float32(0.8171), np.float32(0.699), np.float32(0.8647)] 
2024-12-08 15:09:14.728737: Epoch time: 31.92 s 
2024-12-08 15:09:15.330222:  
2024-12-08 15:09:15.335368: Epoch 78 
2024-12-08 15:09:15.338430: Current learning rate: 0.00256 
2024-12-08 15:09:47.259051: train_loss -0.8751 
2024-12-08 15:09:47.266634: val_loss -0.7305 
2024-12-08 15:09:47.271197: Pseudo dice [np.float32(0.8227), np.float32(0.7018), np.float32(0.8676)] 
2024-12-08 15:09:47.274316: Epoch time: 31.93 s 
2024-12-08 15:09:47.884157:  
2024-12-08 15:09:47.889743: Epoch 79 
2024-12-08 15:09:47.892296: Current learning rate: 0.00245 
2024-12-08 15:10:19.811792: train_loss -0.8757 
2024-12-08 15:10:19.817867: val_loss -0.7324 
2024-12-08 15:10:19.821439: Pseudo dice [np.float32(0.8214), np.float32(0.7066), np.float32(0.8655)] 
2024-12-08 15:10:19.824996: Epoch time: 31.93 s 
2024-12-08 15:10:20.425049:  
2024-12-08 15:10:20.430113: Epoch 80 
2024-12-08 15:10:20.433661: Current learning rate: 0.00235 
2024-12-08 15:10:52.359903: train_loss -0.8768 
2024-12-08 15:10:52.367546: val_loss -0.7275 
2024-12-08 15:10:52.372095: Pseudo dice [np.float32(0.8227), np.float32(0.699), np.float32(0.8664)] 
2024-12-08 15:10:52.375142: Epoch time: 31.94 s 
2024-12-08 15:10:52.987520:  
2024-12-08 15:10:52.993106: Epoch 81 
2024-12-08 15:10:52.996678: Current learning rate: 0.00224 
2024-12-08 15:11:24.913189: train_loss -0.875 
2024-12-08 15:11:24.918314: val_loss -0.7334 
2024-12-08 15:11:24.922871: Pseudo dice [np.float32(0.8221), np.float32(0.7085), np.float32(0.8701)] 
2024-12-08 15:11:24.925961: Epoch time: 31.93 s 
2024-12-08 15:11:24.928500: Yayy! New best EMA pseudo Dice: 0.7961000204086304 
2024-12-08 15:11:25.788709:  
2024-12-08 15:11:25.795310: Epoch 82 
2024-12-08 15:11:25.797843: Current learning rate: 0.00214 
2024-12-08 15:11:57.716773: train_loss -0.8766 
2024-12-08 15:11:57.723900: val_loss -0.7328 
2024-12-08 15:11:57.727463: Pseudo dice [np.float32(0.8215), np.float32(0.7034), np.float32(0.87)] 
2024-12-08 15:11:57.730539: Epoch time: 31.93 s 
2024-12-08 15:11:57.733608: Yayy! New best EMA pseudo Dice: 0.7964000105857849 
2024-12-08 15:11:58.425564:  
2024-12-08 15:11:58.431663: Epoch 83 
2024-12-08 15:11:58.434730: Current learning rate: 0.00203 
2024-12-08 15:12:30.343910: train_loss -0.8759 
2024-12-08 15:12:30.348967: val_loss -0.73 
2024-12-08 15:12:30.354055: Pseudo dice [np.float32(0.8209), np.float32(0.696), np.float32(0.8695)] 
2024-12-08 15:12:30.356590: Epoch time: 31.92 s 
2024-12-08 15:12:30.946876:  
2024-12-08 15:12:30.951938: Epoch 84 
2024-12-08 15:12:30.954478: Current learning rate: 0.00192 
2024-12-08 15:13:02.877331: train_loss -0.8785 
2024-12-08 15:13:02.884443: val_loss -0.7271 
2024-12-08 15:13:02.886979: Pseudo dice [np.float32(0.8205), np.float32(0.6984), np.float32(0.8643)] 
2024-12-08 15:13:02.891074: Epoch time: 31.93 s 
2024-12-08 15:13:03.458240:  
2024-12-08 15:13:03.463312: Epoch 85 
2024-12-08 15:13:03.466874: Current learning rate: 0.00181 
2024-12-08 15:13:35.377477: train_loss -0.8778 
2024-12-08 15:13:35.382592: val_loss -0.725 
2024-12-08 15:13:35.387162: Pseudo dice [np.float32(0.8137), np.float32(0.696), np.float32(0.8705)] 
2024-12-08 15:13:35.390231: Epoch time: 31.92 s 
2024-12-08 15:13:35.947547:  
2024-12-08 15:13:35.952180: Epoch 86 
2024-12-08 15:13:35.955273: Current learning rate: 0.0017 
2024-12-08 15:14:07.887272: train_loss -0.8767 
2024-12-08 15:14:07.894475: val_loss -0.7276 
2024-12-08 15:14:07.898075: Pseudo dice [np.float32(0.8157), np.float32(0.707), np.float32(0.866)] 
2024-12-08 15:14:07.900634: Epoch time: 31.94 s 
2024-12-08 15:14:08.456215:  
2024-12-08 15:14:08.459809: Epoch 87 
2024-12-08 15:14:08.463862: Current learning rate: 0.00159 
2024-12-08 15:14:40.390267: train_loss -0.8777 
2024-12-08 15:14:40.408183: val_loss -0.7265 
2024-12-08 15:14:40.412252: Pseudo dice [np.float32(0.8206), np.float32(0.7028), np.float32(0.8629)] 
2024-12-08 15:14:40.415815: Epoch time: 31.93 s 
2024-12-08 15:14:40.977370:  
2024-12-08 15:14:40.983003: Epoch 88 
2024-12-08 15:14:40.985576: Current learning rate: 0.00148 
2024-12-08 15:15:12.906792: train_loss -0.8775 
2024-12-08 15:15:12.914501: val_loss -0.726 
2024-12-08 15:15:12.919060: Pseudo dice [np.float32(0.8231), np.float32(0.6967), np.float32(0.863)] 
2024-12-08 15:15:12.922122: Epoch time: 31.93 s 
2024-12-08 15:15:13.540111:  
2024-12-08 15:15:13.545746: Epoch 89 
2024-12-08 15:15:13.548342: Current learning rate: 0.00137 
2024-12-08 15:15:45.437811: train_loss -0.8792 
2024-12-08 15:15:45.444927: val_loss -0.7203 
2024-12-08 15:15:45.448021: Pseudo dice [np.float32(0.8181), np.float32(0.6871), np.float32(0.864)] 
2024-12-08 15:15:45.450562: Epoch time: 31.9 s 
2024-12-08 15:15:46.163003:  
2024-12-08 15:15:46.169146: Epoch 90 
2024-12-08 15:15:46.171208: Current learning rate: 0.00126 
2024-12-08 15:16:18.102985: train_loss -0.8779 
2024-12-08 15:16:18.111635: val_loss -0.7254 
2024-12-08 15:16:18.115266: Pseudo dice [np.float32(0.8159), np.float32(0.6985), np.float32(0.8694)] 
2024-12-08 15:16:18.118338: Epoch time: 31.94 s 
2024-12-08 15:16:18.681932:  
2024-12-08 15:16:18.688064: Epoch 91 
2024-12-08 15:16:18.691147: Current learning rate: 0.00115 
2024-12-08 15:16:50.599125: train_loss -0.8788 
2024-12-08 15:16:50.605780: val_loss -0.7347 
2024-12-08 15:16:50.608348: Pseudo dice [np.float32(0.8208), np.float32(0.7117), np.float32(0.8682)] 
2024-12-08 15:16:50.612420: Epoch time: 31.92 s 
2024-12-08 15:16:51.191326:  
2024-12-08 15:16:51.196454: Epoch 92 
2024-12-08 15:16:51.199008: Current learning rate: 0.00103 
2024-12-08 15:17:23.135388: train_loss -0.8791 
2024-12-08 15:17:23.142592: val_loss -0.7306 
2024-12-08 15:17:23.146173: Pseudo dice [np.float32(0.8233), np.float32(0.6997), np.float32(0.8697)] 
2024-12-08 15:17:23.149261: Epoch time: 31.95 s 
2024-12-08 15:17:23.720515:  
2024-12-08 15:17:23.727154: Epoch 93 
2024-12-08 15:17:23.730733: Current learning rate: 0.00091 
2024-12-08 15:17:55.645386: train_loss -0.8802 
2024-12-08 15:17:55.650470: val_loss -0.7233 
2024-12-08 15:17:55.655640: Pseudo dice [np.float32(0.8195), np.float32(0.6992), np.float32(0.8615)] 
2024-12-08 15:17:55.658190: Epoch time: 31.92 s 
2024-12-08 15:17:56.224275:  
2024-12-08 15:17:56.229416: Epoch 94 
2024-12-08 15:17:56.231974: Current learning rate: 0.00079 
2024-12-08 15:18:28.149220: train_loss -0.8783 
2024-12-08 15:18:28.157396: val_loss -0.718 
2024-12-08 15:18:28.159431: Pseudo dice [np.float32(0.8159), np.float32(0.692), np.float32(0.8614)] 
2024-12-08 15:18:28.164512: Epoch time: 31.93 s 
2024-12-08 15:18:28.718216:  
2024-12-08 15:18:28.723814: Epoch 95 
2024-12-08 15:18:28.726888: Current learning rate: 0.00067 
2024-12-08 15:19:00.628955: train_loss -0.8796 
2024-12-08 15:19:00.638576: val_loss -0.7305 
2024-12-08 15:19:00.641661: Pseudo dice [np.float32(0.8208), np.float32(0.7101), np.float32(0.867)] 
2024-12-08 15:19:00.646747: Epoch time: 31.91 s 
2024-12-08 15:19:01.204540:  
2024-12-08 15:19:01.210149: Epoch 96 
2024-12-08 15:19:01.212688: Current learning rate: 0.00055 
2024-12-08 15:19:33.129737: train_loss -0.8788 
2024-12-08 15:19:33.135346: val_loss -0.721 
2024-12-08 15:19:33.139927: Pseudo dice [np.float32(0.8182), np.float32(0.6929), np.float32(0.8631)] 
2024-12-08 15:19:33.144477: Epoch time: 31.93 s 
2024-12-08 15:19:33.706972:  
2024-12-08 15:19:33.713086: Epoch 97 
2024-12-08 15:19:33.717177: Current learning rate: 0.00043 
2024-12-08 15:20:05.619015: train_loss -0.879 
2024-12-08 15:20:05.626703: val_loss -0.7307 
2024-12-08 15:20:05.631334: Pseudo dice [np.float32(0.8221), np.float32(0.7028), np.float32(0.8691)] 
2024-12-08 15:20:05.633881: Epoch time: 31.91 s 
2024-12-08 15:20:06.220029:  
2024-12-08 15:20:06.225094: Epoch 98 
2024-12-08 15:20:06.230230: Current learning rate: 0.0003 
2024-12-08 15:20:38.143085: train_loss -0.8798 
2024-12-08 15:20:38.148773: val_loss -0.7286 
2024-12-08 15:20:38.153875: Pseudo dice [np.float32(0.8216), np.float32(0.7039), np.float32(0.8675)] 
2024-12-08 15:20:38.158438: Epoch time: 31.92 s 
2024-12-08 15:20:38.911342:  
2024-12-08 15:20:38.917015: Epoch 99 
2024-12-08 15:20:38.921115: Current learning rate: 0.00016 
2024-12-08 15:21:10.845477: train_loss -0.8784 
2024-12-08 15:21:10.855167: val_loss -0.7208 
2024-12-08 15:21:10.858270: Pseudo dice [np.float32(0.8216), np.float32(0.6903), np.float32(0.8636)] 
2024-12-08 15:21:10.863410: Epoch time: 31.93 s 
2024-12-08 15:21:11.585031: Training done. 
2024-12-08 15:21:11.645900: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-08 15:21:11.653919: The split file contains 5 splits. 
2024-12-08 15:21:11.662215: Desired fold for training: 0 
2024-12-08 15:21:11.670241: This split has 387 training and 97 validation cases. 
2024-12-08 15:21:11.678547: predicting BRATS_010 
2024-12-08 15:21:11.678547: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2024-12-08 15:21:12.247831: predicting BRATS_011 
2024-12-08 15:21:12.272101: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2024-12-08 15:21:12.669285: predicting BRATS_012 
2024-12-08 15:21:12.677466: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-08 15:21:13.089893: predicting BRATS_018 
2024-12-08 15:21:13.106366: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2024-12-08 15:21:13.525898: predicting BRATS_020 
2024-12-08 15:21:13.541537: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2024-12-08 15:21:13.970007: predicting BRATS_028 
2024-12-08 15:21:13.986149: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2024-12-08 15:21:14.406952: predicting BRATS_029 
2024-12-08 15:21:14.417978: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2024-12-08 15:21:14.819000: predicting BRATS_032 
2024-12-08 15:21:14.834604: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2024-12-08 15:21:15.247281: predicting BRATS_034 
2024-12-08 15:21:15.263694: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2024-12-08 15:21:15.702969: predicting BRATS_041 
2024-12-08 15:21:15.711132: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2024-12-08 15:21:16.554408: predicting BRATS_042 
2024-12-08 15:21:16.562614: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2024-12-08 15:21:17.053920: predicting BRATS_047 
2024-12-08 15:21:17.068192: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-08 15:21:17.522916: predicting BRATS_049 
2024-12-08 15:21:17.539725: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-08 15:21:18.000372: predicting BRATS_053 
2024-12-08 15:21:18.014068: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 15:21:18.465337: predicting BRATS_056 
2024-12-08 15:21:18.481795: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 15:21:18.923856: predicting BRATS_057 
2024-12-08 15:21:18.940342: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 15:21:19.346592: predicting BRATS_067 
2024-12-08 15:21:19.358603: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-08 15:21:19.803143: predicting BRATS_069 
2024-12-08 15:21:19.815837: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-08 15:21:20.217867: predicting BRATS_085 
2024-12-08 15:21:20.233882: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2024-12-08 15:21:20.663687: predicting BRATS_086 
2024-12-08 15:21:20.671815: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2024-12-08 15:21:21.113518: predicting BRATS_088 
2024-12-08 15:21:21.129876: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2024-12-08 15:21:21.571521: predicting BRATS_091 
2024-12-08 15:21:21.579707: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2024-12-08 15:21:22.046465: predicting BRATS_098 
2024-12-08 15:21:22.054525: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2024-12-08 15:21:22.480362: predicting BRATS_100 
2024-12-08 15:21:22.496728: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-08 15:21:22.890661: predicting BRATS_101 
2024-12-08 15:21:22.906836: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-08 15:21:23.332747: predicting BRATS_102 
2024-12-08 15:21:23.349291: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2024-12-08 15:21:23.775746: predicting BRATS_104 
2024-12-08 15:21:23.792107: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2024-12-08 15:21:24.242727: predicting BRATS_111 
2024-12-08 15:21:24.259136: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2024-12-08 15:21:24.716983: predicting BRATS_116 
2024-12-08 15:21:24.733188: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2024-12-08 15:21:25.159458: predicting BRATS_135 
2024-12-08 15:21:25.176414: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2024-12-08 15:21:25.610439: predicting BRATS_136 
2024-12-08 15:21:25.618549: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2024-12-08 15:21:26.059985: predicting BRATS_138 
2024-12-08 15:21:26.068154: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2024-12-08 15:21:26.461625: predicting BRATS_145 
2024-12-08 15:21:26.478022: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2024-12-08 15:21:26.879738: predicting BRATS_149 
2024-12-08 15:21:26.888222: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2024-12-08 15:21:27.314651: predicting BRATS_155 
2024-12-08 15:21:27.322976: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-08 15:21:27.797928: predicting BRATS_157 
2024-12-08 15:21:27.814513: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-08 15:21:28.256474: predicting BRATS_158 
2024-12-08 15:21:28.272570: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-08 15:21:28.714686: predicting BRATS_159 
2024-12-08 15:21:28.723101: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-08 15:21:29.172778: predicting BRATS_163 
2024-12-08 15:21:29.189143: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2024-12-08 15:21:29.622651: predicting BRATS_164 
2024-12-08 15:21:29.630893: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2024-12-08 15:21:30.089042: predicting BRATS_169 
2024-12-08 15:21:30.097282: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2024-12-08 15:21:30.523503: predicting BRATS_176 
2024-12-08 15:21:30.539562: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2024-12-08 15:21:30.997400: predicting BRATS_181 
2024-12-08 15:21:31.013741: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2024-12-08 15:21:31.463589: predicting BRATS_183 
2024-12-08 15:21:31.479927: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 15:21:31.921746: predicting BRATS_184 
2024-12-08 15:21:31.929911: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 15:21:32.363776: predicting BRATS_187 
2024-12-08 15:21:32.380322: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 15:21:32.830545: predicting BRATS_192 
2024-12-08 15:21:32.846726: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2024-12-08 15:21:33.273396: predicting BRATS_198 
2024-12-08 15:21:33.289799: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2024-12-08 15:21:33.731932: predicting BRATS_207 
2024-12-08 15:21:33.748489: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-08 15:21:34.142489: predicting BRATS_208 
2024-12-08 15:21:34.150691: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-08 15:21:34.608584: predicting BRATS_218 
2024-12-08 15:21:34.624709: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2024-12-08 15:21:35.083642: predicting BRATS_220 
2024-12-08 15:21:35.099923: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2024-12-08 15:21:35.550663: predicting BRATS_224 
2024-12-08 15:21:35.567287: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2024-12-08 15:21:36.025202: predicting BRATS_230 
2024-12-08 15:21:36.041327: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2024-12-08 15:21:36.507782: predicting BRATS_271 
2024-12-08 15:21:36.524158: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2024-12-08 15:21:36.925920: predicting BRATS_282 
2024-12-08 15:21:36.941989: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2024-12-08 15:21:37.400646: predicting BRATS_284 
2024-12-08 15:21:37.417158: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2024-12-08 15:21:37.851686: predicting BRATS_287 
2024-12-08 15:21:37.859751: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-08 15:21:38.294125: predicting BRATS_290 
2024-12-08 15:21:38.302322: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2024-12-08 15:21:38.728970: predicting BRATS_291 
2024-12-08 15:21:38.745591: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2024-12-08 15:21:39.179219: predicting BRATS_292 
2024-12-08 15:21:39.195717: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2024-12-08 15:21:39.645779: predicting BRATS_293 
2024-12-08 15:21:39.653963: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2024-12-08 15:21:40.097475: predicting BRATS_300 
2024-12-08 15:21:40.113916: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2024-12-08 15:21:40.571871: predicting BRATS_305 
2024-12-08 15:21:40.588184: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2024-12-08 15:21:41.030861: predicting BRATS_311 
2024-12-08 15:21:41.047386: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2024-12-08 15:21:41.521461: predicting BRATS_314 
2024-12-08 15:21:41.529489: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2024-12-08 15:21:41.995855: predicting BRATS_321 
2024-12-08 15:21:42.003941: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2024-12-08 15:21:42.454392: predicting BRATS_328 
2024-12-08 15:21:42.462844: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2024-12-08 15:21:42.953332: predicting BRATS_329 
2024-12-08 15:21:42.961725: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2024-12-08 15:21:43.356526: predicting BRATS_335 
2024-12-08 15:21:43.364566: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2024-12-08 15:21:43.806924: predicting BRATS_343 
2024-12-08 15:21:43.823560: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2024-12-08 15:21:44.273570: predicting BRATS_350 
2024-12-08 15:21:44.281793: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2024-12-08 15:21:44.740089: predicting BRATS_351 
2024-12-08 15:21:44.748307: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2024-12-08 15:21:45.167150: predicting BRATS_356 
2024-12-08 15:21:45.175440: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2024-12-08 15:21:45.610260: predicting BRATS_366 
2024-12-08 15:21:45.626644: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2024-12-08 15:21:46.084970: predicting BRATS_367 
2024-12-08 15:21:46.101369: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2024-12-08 15:21:46.575348: predicting BRATS_374 
2024-12-08 15:21:46.583623: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2024-12-08 15:21:47.050221: predicting BRATS_376 
2024-12-08 15:21:47.058579: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2024-12-08 15:21:47.533301: predicting BRATS_377 
2024-12-08 15:21:47.549675: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2024-12-08 15:21:48.000510: predicting BRATS_378 
2024-12-08 15:21:48.016773: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2024-12-08 15:21:48.491633: predicting BRATS_379 
2024-12-08 15:21:48.499814: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2024-12-08 15:21:48.917827: predicting BRATS_384 
2024-12-08 15:21:48.934021: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2024-12-08 15:21:49.367746: predicting BRATS_386 
2024-12-08 15:21:49.384490: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2024-12-08 15:21:49.826602: predicting BRATS_394 
2024-12-08 15:21:49.843193: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-08 15:21:50.325049: predicting BRATS_398 
2024-12-08 15:21:50.333173: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2024-12-08 15:21:50.767548: predicting BRATS_400 
2024-12-08 15:21:50.784143: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2024-12-08 15:21:51.242517: predicting BRATS_432 
2024-12-08 15:21:51.250730: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2024-12-08 15:21:51.700884: predicting BRATS_437 
2024-12-08 15:21:51.717170: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-08 15:21:52.159453: predicting BRATS_445 
2024-12-08 15:21:52.167912: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2024-12-08 15:21:52.626080: predicting BRATS_446 
2024-12-08 15:21:52.634441: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2024-12-08 15:21:53.068664: predicting BRATS_450 
2024-12-08 15:21:53.085016: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2024-12-08 15:21:53.502768: predicting BRATS_452 
2024-12-08 15:21:53.510829: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2024-12-08 15:21:53.937111: predicting BRATS_460 
2024-12-08 15:21:53.945373: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2024-12-08 15:21:54.419574: predicting BRATS_470 
2024-12-08 15:21:54.427604: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2024-12-08 15:21:54.942607: predicting BRATS_472 
2024-12-08 15:21:54.959398: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2024-12-08 15:21:55.417117: predicting BRATS_473 
2024-12-08 15:21:55.433492: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2024-12-08 15:21:55.804097: predicting BRATS_482 
2024-12-08 15:21:55.812187: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2024-12-08 15:22:03.200695: Validation complete 
2024-12-08 15:22:03.209157: Mean Validation Dice:  0.6945393307502576 
