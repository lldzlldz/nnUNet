
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-16 01:19:27.396090: do_dummy_2d_data_aug: False 
2025-03-16 01:19:27.400088: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-16 01:19:27.405211: The split file contains 5 splits. 
2025-03-16 01:19:27.408216: Desired fold for training: 0 
2025-03-16 01:19:27.410214: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2025-03-16 01:19:58.436919: unpacking dataset... 
2025-03-16 01:19:58.624953: unpacking done... 
2025-03-16 01:20:01.334568:  
2025-03-16 01:20:01.339578: Epoch 0 
2025-03-16 01:20:01.342588: Current learning rate: 0.01 
2025-03-16 01:20:44.067504: train_loss -0.2729 
2025-03-16 01:20:44.074021: val_loss -0.3831 
2025-03-16 01:20:44.078031: Pseudo dice [np.float32(0.7076), np.float32(0.4378), np.float32(0.6839)] 
2025-03-16 01:20:44.081541: Epoch time: 42.73 s 
2025-03-16 01:20:44.085551: Yayy! New best EMA pseudo Dice: 0.6097999811172485 
2025-03-16 01:20:44.696487:  
2025-03-16 01:20:44.700520: Epoch 1 
2025-03-16 01:20:44.704057: Current learning rate: 0.00991 
2025-03-16 01:21:23.358447: train_loss -0.486 
2025-03-16 01:21:23.365140: val_loss -0.4984 
2025-03-16 01:21:23.369262: Pseudo dice [np.float32(0.7264), np.float32(0.5861), np.float32(0.7888)] 
2025-03-16 01:21:23.372983: Epoch time: 38.66 s 
2025-03-16 01:21:23.376543: Yayy! New best EMA pseudo Dice: 0.6189000010490417 
2025-03-16 01:21:24.070992:  
2025-03-16 01:21:24.077006: Epoch 2 
2025-03-16 01:21:24.081024: Current learning rate: 0.00982 
2025-03-16 01:22:02.778438: train_loss -0.5347 
2025-03-16 01:22:02.784451: val_loss -0.4967 
2025-03-16 01:22:02.788461: Pseudo dice [np.float32(0.7437), np.float32(0.5633), np.float32(0.7702)] 
2025-03-16 01:22:02.790970: Epoch time: 38.71 s 
2025-03-16 01:22:02.795479: Yayy! New best EMA pseudo Dice: 0.6262000203132629 
2025-03-16 01:22:03.504708:  
2025-03-16 01:22:03.509342: Epoch 3 
2025-03-16 01:22:03.512448: Current learning rate: 0.00973 
2025-03-16 01:22:42.171870: train_loss -0.5624 
2025-03-16 01:22:42.178411: val_loss -0.5253 
2025-03-16 01:22:42.181422: Pseudo dice [np.float32(0.7636), np.float32(0.576), np.float32(0.784)] 
2025-03-16 01:22:42.186436: Epoch time: 38.67 s 
2025-03-16 01:22:42.189943: Yayy! New best EMA pseudo Dice: 0.6344000101089478 
2025-03-16 01:22:42.885624:  
2025-03-16 01:22:42.891561: Epoch 4 
2025-03-16 01:22:42.895569: Current learning rate: 0.00964 
2025-03-16 01:23:21.570483: train_loss -0.5826 
2025-03-16 01:23:21.578505: val_loss -0.5702 
2025-03-16 01:23:21.583519: Pseudo dice [np.float32(0.779), np.float32(0.616), np.float32(0.8273)] 
2025-03-16 01:23:21.588531: Epoch time: 38.69 s 
2025-03-16 01:23:21.593543: Yayy! New best EMA pseudo Dice: 0.6449999809265137 
2025-03-16 01:23:22.420613:  
2025-03-16 01:23:22.426159: Epoch 5 
2025-03-16 01:23:22.429727: Current learning rate: 0.00955 
2025-03-16 01:24:00.967400: train_loss -0.5978 
2025-03-16 01:24:00.973436: val_loss -0.5773 
2025-03-16 01:24:00.977459: Pseudo dice [np.float32(0.7933), np.float32(0.6379), np.float32(0.8383)] 
2025-03-16 01:24:00.980999: Epoch time: 38.55 s 
2025-03-16 01:24:00.985582: Yayy! New best EMA pseudo Dice: 0.6561999917030334 
2025-03-16 01:24:01.677937:  
2025-03-16 01:24:01.682270: Epoch 6 
2025-03-16 01:24:01.686837: Current learning rate: 0.00946 
2025-03-16 01:24:40.429404: train_loss -0.6021 
2025-03-16 01:24:40.435925: val_loss -0.5716 
2025-03-16 01:24:40.440941: Pseudo dice [np.float32(0.7973), np.float32(0.6382), np.float32(0.8201)] 
2025-03-16 01:24:40.445459: Epoch time: 38.75 s 
2025-03-16 01:24:40.450980: Yayy! New best EMA pseudo Dice: 0.6657000184059143 
2025-03-16 01:24:41.151166:  
2025-03-16 01:24:41.157230: Epoch 7 
2025-03-16 01:24:41.161739: Current learning rate: 0.00937 
2025-03-16 01:25:19.808801: train_loss -0.6027 
2025-03-16 01:25:19.814822: val_loss -0.5126 
2025-03-16 01:25:19.819838: Pseudo dice [np.float32(0.7432), np.float32(0.5504), np.float32(0.7859)] 
2025-03-16 01:25:19.824853: Epoch time: 38.66 s 
2025-03-16 01:25:19.828863: Yayy! New best EMA pseudo Dice: 0.6685000061988831 
2025-03-16 01:25:20.551620:  
2025-03-16 01:25:20.556669: Epoch 8 
2025-03-16 01:25:20.560712: Current learning rate: 0.00928 
2025-03-16 01:25:59.203886: train_loss -0.6006 
2025-03-16 01:25:59.208928: val_loss -0.5701 
2025-03-16 01:25:59.214306: Pseudo dice [np.float32(0.7922), np.float32(0.6508), np.float32(0.822)] 
2025-03-16 01:25:59.219322: Epoch time: 38.65 s 
2025-03-16 01:25:59.223852: Yayy! New best EMA pseudo Dice: 0.6771000027656555 
2025-03-16 01:25:59.961028:  
2025-03-16 01:25:59.967061: Epoch 9 
2025-03-16 01:25:59.971689: Current learning rate: 0.00919 
2025-03-16 01:26:38.718555: train_loss -0.6165 
2025-03-16 01:26:38.724695: val_loss -0.5967 
2025-03-16 01:26:38.728247: Pseudo dice [np.float32(0.7995), np.float32(0.6707), np.float32(0.8149)] 
2025-03-16 01:26:38.731384: Epoch time: 38.76 s 
2025-03-16 01:26:38.734954: Yayy! New best EMA pseudo Dice: 0.6855999827384949 
2025-03-16 01:26:39.421998:  
2025-03-16 01:26:39.426566: Epoch 10 
2025-03-16 01:26:39.430107: Current learning rate: 0.0091 
2025-03-16 01:27:18.163984: train_loss -0.6077 
2025-03-16 01:27:18.170500: val_loss -0.574 
2025-03-16 01:27:18.174509: Pseudo dice [np.float32(0.7866), np.float32(0.6475), np.float32(0.8203)] 
2025-03-16 01:27:18.179019: Epoch time: 38.74 s 
2025-03-16 01:27:18.183030: Yayy! New best EMA pseudo Dice: 0.6922000050544739 
2025-03-16 01:27:18.875215:  
2025-03-16 01:27:18.880270: Epoch 11 
2025-03-16 01:27:18.883780: Current learning rate: 0.009 
2025-03-16 01:27:57.570698: train_loss -0.6342 
2025-03-16 01:27:57.578393: val_loss -0.5911 
2025-03-16 01:27:57.581402: Pseudo dice [np.float32(0.7887), np.float32(0.631), np.float32(0.8376)] 
2025-03-16 01:27:57.584914: Epoch time: 38.7 s 
2025-03-16 01:27:57.589926: Yayy! New best EMA pseudo Dice: 0.698199987411499 
2025-03-16 01:27:58.283146:  
2025-03-16 01:27:58.288662: Epoch 12 
2025-03-16 01:27:58.291169: Current learning rate: 0.00891 
2025-03-16 01:28:37.045248: train_loss -0.6265 
2025-03-16 01:28:37.052771: val_loss -0.5933 
2025-03-16 01:28:37.057788: Pseudo dice [np.float32(0.8148), np.float32(0.674), np.float32(0.8254)] 
2025-03-16 01:28:37.063808: Epoch time: 38.76 s 
2025-03-16 01:28:37.067822: Yayy! New best EMA pseudo Dice: 0.7055000066757202 
2025-03-16 01:28:37.915783:  
2025-03-16 01:28:37.921342: Epoch 13 
2025-03-16 01:28:37.923878: Current learning rate: 0.00882 
2025-03-16 01:29:16.564627: train_loss -0.6438 
2025-03-16 01:29:16.570641: val_loss -0.6065 
2025-03-16 01:29:16.576162: Pseudo dice [np.float32(0.7988), np.float32(0.6634), np.float32(0.8336)] 
2025-03-16 01:29:16.581174: Epoch time: 38.65 s 
2025-03-16 01:29:16.586188: Yayy! New best EMA pseudo Dice: 0.7114999890327454 
2025-03-16 01:29:17.291205:  
2025-03-16 01:29:17.297557: Epoch 14 
2025-03-16 01:29:17.301059: Current learning rate: 0.00873 
2025-03-16 01:29:55.956501: train_loss -0.6442 
2025-03-16 01:29:55.962024: val_loss -0.6003 
2025-03-16 01:29:55.965535: Pseudo dice [np.float32(0.7875), np.float32(0.6838), np.float32(0.8196)] 
2025-03-16 01:29:55.969556: Epoch time: 38.67 s 
2025-03-16 01:29:55.974572: Yayy! New best EMA pseudo Dice: 0.71670001745224 
2025-03-16 01:29:56.687153:  
2025-03-16 01:29:56.693218: Epoch 15 
2025-03-16 01:29:56.696789: Current learning rate: 0.00864 
2025-03-16 01:30:35.222844: train_loss -0.6556 
2025-03-16 01:30:35.229380: val_loss -0.6139 
2025-03-16 01:30:35.232389: Pseudo dice [np.float32(0.7735), np.float32(0.6591), np.float32(0.8568)] 
2025-03-16 01:30:35.237401: Epoch time: 38.54 s 
2025-03-16 01:30:35.241911: Yayy! New best EMA pseudo Dice: 0.7214000225067139 
2025-03-16 01:30:35.974524:  
2025-03-16 01:30:35.980350: Epoch 16 
2025-03-16 01:30:35.983854: Current learning rate: 0.00855 
2025-03-16 01:31:14.571499: train_loss -0.6543 
2025-03-16 01:31:14.578527: val_loss -0.6021 
2025-03-16 01:31:14.583498: Pseudo dice [np.float32(0.7985), np.float32(0.6729), np.float32(0.8371)] 
2025-03-16 01:31:14.588507: Epoch time: 38.6 s 
2025-03-16 01:31:14.592013: Yayy! New best EMA pseudo Dice: 0.7261999845504761 
2025-03-16 01:31:15.302211:  
2025-03-16 01:31:15.308318: Epoch 17 
2025-03-16 01:31:15.313331: Current learning rate: 0.00846 
2025-03-16 01:31:53.705639: train_loss -0.6515 
2025-03-16 01:31:53.712660: val_loss -0.6438 
2025-03-16 01:31:53.716675: Pseudo dice [np.float32(0.8214), np.float32(0.6534), np.float32(0.8575)] 
2025-03-16 01:31:53.720688: Epoch time: 38.4 s 
2025-03-16 01:31:53.725200: Yayy! New best EMA pseudo Dice: 0.7312999963760376 
2025-03-16 01:31:54.470327:  
2025-03-16 01:31:54.475353: Epoch 18 
2025-03-16 01:31:54.479305: Current learning rate: 0.00836 
2025-03-16 01:32:33.071758: train_loss -0.6498 
2025-03-16 01:32:33.077842: val_loss -0.6121 
2025-03-16 01:32:33.080890: Pseudo dice [np.float32(0.8065), np.float32(0.6719), np.float32(0.8459)] 
2025-03-16 01:32:33.084425: Epoch time: 38.6 s 
2025-03-16 01:32:33.088054: Yayy! New best EMA pseudo Dice: 0.7355999946594238 
2025-03-16 01:32:33.799891:  
2025-03-16 01:32:33.805941: Epoch 19 
2025-03-16 01:32:33.808999: Current learning rate: 0.00827 
2025-03-16 01:33:12.340616: train_loss -0.6533 
2025-03-16 01:33:12.348134: val_loss -0.6051 
2025-03-16 01:33:12.351646: Pseudo dice [np.float32(0.8053), np.float32(0.7057), np.float32(0.8296)] 
2025-03-16 01:33:12.355158: Epoch time: 38.54 s 
2025-03-16 01:33:12.359176: Yayy! New best EMA pseudo Dice: 0.7401000261306763 
2025-03-16 01:33:13.205086:  
2025-03-16 01:33:13.211637: Epoch 20 
2025-03-16 01:33:13.215153: Current learning rate: 0.00818 
2025-03-16 01:33:51.674435: train_loss -0.65 
2025-03-16 01:33:51.679986: val_loss -0.618 
2025-03-16 01:33:51.684034: Pseudo dice [np.float32(0.8051), np.float32(0.6742), np.float32(0.8595)] 
2025-03-16 01:33:51.688104: Epoch time: 38.47 s 
2025-03-16 01:33:51.692246: Yayy! New best EMA pseudo Dice: 0.7440000176429749 
2025-03-16 01:33:52.407366:  
2025-03-16 01:33:52.412878: Epoch 21 
2025-03-16 01:33:52.416387: Current learning rate: 0.00809 
2025-03-16 01:34:30.867853: train_loss -0.6561 
2025-03-16 01:34:30.872919: val_loss -0.5909 
2025-03-16 01:34:30.876996: Pseudo dice [np.float32(0.7985), np.float32(0.6063), np.float32(0.8224)] 
2025-03-16 01:34:30.882053: Epoch time: 38.46 s 
2025-03-16 01:34:31.407645:  
2025-03-16 01:34:31.413692: Epoch 22 
2025-03-16 01:34:31.417738: Current learning rate: 0.008 
2025-03-16 01:35:09.825776: train_loss -0.6609 
2025-03-16 01:35:09.831337: val_loss -0.5937 
2025-03-16 01:35:09.836396: Pseudo dice [np.float32(0.8045), np.float32(0.6201), np.float32(0.8174)] 
2025-03-16 01:35:09.841004: Epoch time: 38.42 s 
2025-03-16 01:35:09.845562: Yayy! New best EMA pseudo Dice: 0.7441999912261963 
2025-03-16 01:35:10.529395:  
2025-03-16 01:35:10.534417: Epoch 23 
2025-03-16 01:35:10.538930: Current learning rate: 0.0079 
2025-03-16 01:35:49.120642: train_loss -0.6675 
2025-03-16 01:35:49.125657: val_loss -0.6464 
2025-03-16 01:35:49.130680: Pseudo dice [np.float32(0.8398), np.float32(0.6737), np.float32(0.8592)] 
2025-03-16 01:35:49.135201: Epoch time: 38.59 s 
2025-03-16 01:35:49.138406: Yayy! New best EMA pseudo Dice: 0.7488999962806702 
2025-03-16 01:35:49.815935:  
2025-03-16 01:35:49.820603: Epoch 24 
2025-03-16 01:35:49.824656: Current learning rate: 0.00781 
2025-03-16 01:36:28.346175: train_loss -0.6765 
2025-03-16 01:36:28.352321: val_loss -0.6016 
2025-03-16 01:36:28.356873: Pseudo dice [np.float32(0.8082), np.float32(0.7072), np.float32(0.8295)] 
2025-03-16 01:36:28.360426: Epoch time: 38.53 s 
2025-03-16 01:36:28.365474: Yayy! New best EMA pseudo Dice: 0.7522000074386597 
2025-03-16 01:36:29.059239:  
2025-03-16 01:36:29.064182: Epoch 25 
2025-03-16 01:36:29.067698: Current learning rate: 0.00772 
2025-03-16 01:37:07.545806: train_loss -0.6871 
2025-03-16 01:37:07.551837: val_loss -0.6081 
2025-03-16 01:37:07.555931: Pseudo dice [np.float32(0.8138), np.float32(0.6656), np.float32(0.8224)] 
2025-03-16 01:37:07.560521: Epoch time: 38.49 s 
2025-03-16 01:37:07.565112: Yayy! New best EMA pseudo Dice: 0.7537000179290771 
2025-03-16 01:37:08.240975:  
2025-03-16 01:37:08.246529: Epoch 26 
2025-03-16 01:37:08.250069: Current learning rate: 0.00763 
2025-03-16 01:37:46.664737: train_loss -0.6749 
2025-03-16 01:37:46.671412: val_loss -0.6395 
2025-03-16 01:37:46.675001: Pseudo dice [np.float32(0.8154), np.float32(0.6792), np.float32(0.8482)] 
2025-03-16 01:37:46.678527: Epoch time: 38.42 s 
2025-03-16 01:37:46.682484: Yayy! New best EMA pseudo Dice: 0.7563999891281128 
2025-03-16 01:37:47.510725:  
2025-03-16 01:37:47.514266: Epoch 27 
2025-03-16 01:37:47.518337: Current learning rate: 0.00753 
2025-03-16 01:38:26.007789: train_loss -0.6606 
2025-03-16 01:38:26.013839: val_loss -0.6217 
2025-03-16 01:38:26.017955: Pseudo dice [np.float32(0.8078), np.float32(0.7249), np.float32(0.8562)] 
2025-03-16 01:38:26.022514: Epoch time: 38.5 s 
2025-03-16 01:38:26.027071: Yayy! New best EMA pseudo Dice: 0.7603999972343445 
2025-03-16 01:38:26.716971:  
2025-03-16 01:38:26.722533: Epoch 28 
2025-03-16 01:38:26.726541: Current learning rate: 0.00744 
2025-03-16 01:39:05.225284: train_loss -0.6796 
2025-03-16 01:39:05.231809: val_loss -0.6133 
2025-03-16 01:39:05.237826: Pseudo dice [np.float32(0.8049), np.float32(0.6518), np.float32(0.8487)] 
2025-03-16 01:39:05.241845: Epoch time: 38.51 s 
2025-03-16 01:39:05.245858: Yayy! New best EMA pseudo Dice: 0.7612000107765198 
2025-03-16 01:39:05.952153:  
2025-03-16 01:39:05.957164: Epoch 29 
2025-03-16 01:39:05.961174: Current learning rate: 0.00735 
2025-03-16 01:39:44.502201: train_loss -0.688 
2025-03-16 01:39:44.508796: val_loss -0.6086 
2025-03-16 01:39:44.512882: Pseudo dice [np.float32(0.8076), np.float32(0.6691), np.float32(0.8315)] 
2025-03-16 01:39:44.517437: Epoch time: 38.55 s 
2025-03-16 01:39:44.522507: Yayy! New best EMA pseudo Dice: 0.7620000243186951 
2025-03-16 01:39:45.228691:  
2025-03-16 01:39:45.234391: Epoch 30 
2025-03-16 01:39:45.237956: Current learning rate: 0.00725 
2025-03-16 01:40:23.723095: train_loss -0.6947 
2025-03-16 01:40:23.728735: val_loss -0.5958 
2025-03-16 01:40:23.733337: Pseudo dice [np.float32(0.8001), np.float32(0.6753), np.float32(0.8664)] 
2025-03-16 01:40:23.736920: Epoch time: 38.49 s 
2025-03-16 01:40:23.741564: Yayy! New best EMA pseudo Dice: 0.7638999819755554 
2025-03-16 01:40:24.437550:  
2025-03-16 01:40:24.443100: Epoch 31 
2025-03-16 01:40:24.447644: Current learning rate: 0.00716 
2025-03-16 01:41:02.889030: train_loss -0.6748 
2025-03-16 01:41:02.895760: val_loss -0.6105 
2025-03-16 01:41:02.899359: Pseudo dice [np.float32(0.81), np.float32(0.6826), np.float32(0.8243)] 
2025-03-16 01:41:02.903463: Epoch time: 38.45 s 
2025-03-16 01:41:02.907543: Yayy! New best EMA pseudo Dice: 0.7646999955177307 
2025-03-16 01:41:03.611049:  
2025-03-16 01:41:03.617095: Epoch 32 
2025-03-16 01:41:03.620233: Current learning rate: 0.00707 
2025-03-16 01:41:42.065333: train_loss -0.6747 
2025-03-16 01:41:42.072936: val_loss -0.6359 
2025-03-16 01:41:42.076496: Pseudo dice [np.float32(0.8323), np.float32(0.6951), np.float32(0.8425)] 
2025-03-16 01:41:42.079551: Epoch time: 38.45 s 
2025-03-16 01:41:42.084204: Yayy! New best EMA pseudo Dice: 0.7671999931335449 
2025-03-16 01:41:42.783493:  
2025-03-16 01:41:42.789017: Epoch 33 
2025-03-16 01:41:42.792618: Current learning rate: 0.00697 
2025-03-16 01:42:21.313456: train_loss -0.6801 
2025-03-16 01:42:21.321482: val_loss -0.6406 
2025-03-16 01:42:21.325994: Pseudo dice [np.float32(0.8282), np.float32(0.6489), np.float32(0.8663)] 
2025-03-16 01:42:21.331009: Epoch time: 38.53 s 
2025-03-16 01:42:21.335025: Yayy! New best EMA pseudo Dice: 0.7685999870300293 
2025-03-16 01:42:22.044199:  
2025-03-16 01:42:22.049076: Epoch 34 
2025-03-16 01:42:22.052591: Current learning rate: 0.00688 
2025-03-16 01:43:00.679949: train_loss -0.6907 
2025-03-16 01:43:00.686467: val_loss -0.5983 
2025-03-16 01:43:00.689986: Pseudo dice [np.float32(0.8025), np.float32(0.7115), np.float32(0.818)] 
2025-03-16 01:43:00.693995: Epoch time: 38.64 s 
2025-03-16 01:43:00.697515: Yayy! New best EMA pseudo Dice: 0.7695000171661377 
2025-03-16 01:43:01.547422:  
2025-03-16 01:43:01.552990: Epoch 35 
2025-03-16 01:43:01.556126: Current learning rate: 0.00679 
2025-03-16 01:43:40.021232: train_loss -0.691 
2025-03-16 01:43:40.027292: val_loss -0.6399 
2025-03-16 01:43:40.029827: Pseudo dice [np.float32(0.8126), np.float32(0.7056), np.float32(0.8433)] 
2025-03-16 01:43:40.033874: Epoch time: 38.47 s 
2025-03-16 01:43:40.037964: Yayy! New best EMA pseudo Dice: 0.7713000178337097 
2025-03-16 01:43:40.757296:  
2025-03-16 01:43:40.762831: Epoch 36 
2025-03-16 01:43:40.766380: Current learning rate: 0.00669 
2025-03-16 01:44:19.157575: train_loss -0.6932 
2025-03-16 01:44:19.164644: val_loss -0.6264 
2025-03-16 01:44:19.171406: Pseudo dice [np.float32(0.8172), np.float32(0.6799), np.float32(0.8859)] 
2025-03-16 01:44:19.177521: Epoch time: 38.4 s 
2025-03-16 01:44:19.182705: Yayy! New best EMA pseudo Dice: 0.7735999822616577 
2025-03-16 01:44:19.892987:  
2025-03-16 01:44:19.898530: Epoch 37 
2025-03-16 01:44:19.903112: Current learning rate: 0.0066 
2025-03-16 01:44:58.315584: train_loss -0.6879 
2025-03-16 01:44:58.322199: val_loss -0.6327 
2025-03-16 01:44:58.327803: Pseudo dice [np.float32(0.8151), np.float32(0.7167), np.float32(0.8597)] 
2025-03-16 01:44:58.333899: Epoch time: 38.42 s 
2025-03-16 01:44:58.337480: Yayy! New best EMA pseudo Dice: 0.7759000062942505 
2025-03-16 01:44:59.044462:  
2025-03-16 01:44:59.049974: Epoch 38 
2025-03-16 01:44:59.053485: Current learning rate: 0.0065 
2025-03-16 01:45:37.546885: train_loss -0.6939 
2025-03-16 01:45:37.553440: val_loss -0.634 
2025-03-16 01:45:37.558482: Pseudo dice [np.float32(0.8285), np.float32(0.6426), np.float32(0.839)] 
2025-03-16 01:45:37.564580: Epoch time: 38.5 s 
2025-03-16 01:45:38.110068:  
2025-03-16 01:45:38.115612: Epoch 39 
2025-03-16 01:45:38.120738: Current learning rate: 0.00641 
2025-03-16 01:46:16.666487: train_loss -0.7135 
2025-03-16 01:46:16.673089: val_loss -0.66 
2025-03-16 01:46:16.677120: Pseudo dice [np.float32(0.8284), np.float32(0.6946), np.float32(0.8615)] 
2025-03-16 01:46:16.680631: Epoch time: 38.56 s 
2025-03-16 01:46:16.684644: Yayy! New best EMA pseudo Dice: 0.7773000001907349 
2025-03-16 01:46:17.411617:  
2025-03-16 01:46:17.416648: Epoch 40 
2025-03-16 01:46:17.419717: Current learning rate: 0.00631 
2025-03-16 01:46:56.069179: train_loss -0.6993 
2025-03-16 01:46:56.076233: val_loss -0.652 
2025-03-16 01:46:56.080269: Pseudo dice [np.float32(0.8353), np.float32(0.714), np.float32(0.8618)] 
2025-03-16 01:46:56.084857: Epoch time: 38.66 s 
2025-03-16 01:46:56.089396: Yayy! New best EMA pseudo Dice: 0.7799000144004822 
2025-03-16 01:46:56.806268:  
2025-03-16 01:46:56.811435: Epoch 41 
2025-03-16 01:46:56.814976: Current learning rate: 0.00622 
2025-03-16 01:47:35.348032: train_loss -0.7014 
2025-03-16 01:47:35.353600: val_loss -0.6337 
2025-03-16 01:47:35.358702: Pseudo dice [np.float32(0.8232), np.float32(0.7221), np.float32(0.8523)] 
2025-03-16 01:47:35.364338: Epoch time: 38.54 s 
2025-03-16 01:47:35.368346: Yayy! New best EMA pseudo Dice: 0.7818999886512756 
2025-03-16 01:47:36.052834:  
2025-03-16 01:47:36.056876: Epoch 42 
2025-03-16 01:47:36.060427: Current learning rate: 0.00612 
2025-03-16 01:48:14.621997: train_loss -0.7015 
2025-03-16 01:48:14.628110: val_loss -0.6415 
2025-03-16 01:48:14.632207: Pseudo dice [np.float32(0.8067), np.float32(0.7239), np.float32(0.8591)] 
2025-03-16 01:48:14.636845: Epoch time: 38.57 s 
2025-03-16 01:48:14.641415: Yayy! New best EMA pseudo Dice: 0.78329998254776 
2025-03-16 01:48:15.470575:  
2025-03-16 01:48:15.475585: Epoch 43 
2025-03-16 01:48:15.478592: Current learning rate: 0.00603 
2025-03-16 01:48:53.937236: train_loss -0.6995 
2025-03-16 01:48:53.943787: val_loss -0.6112 
2025-03-16 01:48:53.947325: Pseudo dice [np.float32(0.8102), np.float32(0.6778), np.float32(0.8355)] 
2025-03-16 01:48:53.950853: Epoch time: 38.47 s 
2025-03-16 01:48:54.477474:  
2025-03-16 01:48:54.483054: Epoch 44 
2025-03-16 01:48:54.486073: Current learning rate: 0.00593 
2025-03-16 01:49:33.107792: train_loss -0.7065 
2025-03-16 01:49:33.114331: val_loss -0.6256 
2025-03-16 01:49:33.117364: Pseudo dice [np.float32(0.8242), np.float32(0.7061), np.float32(0.8256)] 
2025-03-16 01:49:33.121390: Epoch time: 38.63 s 
2025-03-16 01:49:33.644720:  
2025-03-16 01:49:33.650305: Epoch 45 
2025-03-16 01:49:33.654341: Current learning rate: 0.00584 
2025-03-16 01:50:12.213424: train_loss -0.7059 
2025-03-16 01:50:12.220454: val_loss -0.6532 
2025-03-16 01:50:12.224656: Pseudo dice [np.float32(0.8363), np.float32(0.7425), np.float32(0.8439)] 
2025-03-16 01:50:12.230233: Epoch time: 38.57 s 
2025-03-16 01:50:12.234780: Yayy! New best EMA pseudo Dice: 0.7851999998092651 
2025-03-16 01:50:12.922901:  
2025-03-16 01:50:12.928460: Epoch 46 
2025-03-16 01:50:12.931008: Current learning rate: 0.00574 
2025-03-16 01:50:51.449341: train_loss -0.7019 
2025-03-16 01:50:51.455355: val_loss -0.632 
2025-03-16 01:50:51.460369: Pseudo dice [np.float32(0.8133), np.float32(0.7198), np.float32(0.8637)] 
2025-03-16 01:50:51.465391: Epoch time: 38.53 s 
2025-03-16 01:50:51.470415: Yayy! New best EMA pseudo Dice: 0.7865999937057495 
2025-03-16 01:50:52.146478:  
2025-03-16 01:50:52.152032: Epoch 47 
2025-03-16 01:50:52.155667: Current learning rate: 0.00565 
2025-03-16 01:51:30.800940: train_loss -0.7058 
2025-03-16 01:51:30.807455: val_loss -0.6479 
2025-03-16 01:51:30.809961: Pseudo dice [np.float32(0.8335), np.float32(0.6724), np.float32(0.8714)] 
2025-03-16 01:51:30.813473: Epoch time: 38.65 s 
2025-03-16 01:51:30.816981: Yayy! New best EMA pseudo Dice: 0.7871999740600586 
2025-03-16 01:51:31.502394:  
2025-03-16 01:51:31.507907: Epoch 48 
2025-03-16 01:51:31.511416: Current learning rate: 0.00555 
2025-03-16 01:52:09.990602: train_loss -0.7071 
2025-03-16 01:52:09.995470: val_loss -0.6358 
2025-03-16 01:52:10.000317: Pseudo dice [np.float32(0.819), np.float32(0.6998), np.float32(0.8506)] 
2025-03-16 01:52:10.005338: Epoch time: 38.49 s 
2025-03-16 01:52:10.009852: Yayy! New best EMA pseudo Dice: 0.7874000072479248 
2025-03-16 01:52:10.716921:  
2025-03-16 01:52:10.722950: Epoch 49 
2025-03-16 01:52:10.726554: Current learning rate: 0.00546 
2025-03-16 01:52:49.250970: train_loss -0.7081 
2025-03-16 01:52:49.257568: val_loss -0.6191 
2025-03-16 01:52:49.261091: Pseudo dice [np.float32(0.7998), np.float32(0.7313), np.float32(0.8286)] 
2025-03-16 01:52:49.264114: Epoch time: 38.54 s 
2025-03-16 01:52:50.089198:  
2025-03-16 01:52:50.094243: Epoch 50 
2025-03-16 01:52:50.099269: Current learning rate: 0.00536 
2025-03-16 01:53:28.594922: train_loss -0.7122 
2025-03-16 01:53:28.600479: val_loss -0.6478 
2025-03-16 01:53:28.605083: Pseudo dice [np.float32(0.8138), np.float32(0.7257), np.float32(0.8544)] 
2025-03-16 01:53:28.610102: Epoch time: 38.51 s 
2025-03-16 01:53:28.614120: Yayy! New best EMA pseudo Dice: 0.7883999943733215 
2025-03-16 01:53:29.303871:  
2025-03-16 01:53:29.309722: Epoch 51 
2025-03-16 01:53:29.313231: Current learning rate: 0.00526 
2025-03-16 01:54:07.908814: train_loss -0.7082 
2025-03-16 01:54:07.914329: val_loss -0.626 
2025-03-16 01:54:07.918844: Pseudo dice [np.float32(0.8055), np.float32(0.6825), np.float32(0.8518)] 
2025-03-16 01:54:07.922890: Epoch time: 38.61 s 
2025-03-16 01:54:08.451158:  
2025-03-16 01:54:08.456672: Epoch 52 
2025-03-16 01:54:08.460185: Current learning rate: 0.00517 
2025-03-16 01:54:47.107636: train_loss -0.7047 
2025-03-16 01:54:47.113715: val_loss -0.6253 
2025-03-16 01:54:47.116255: Pseudo dice [np.float32(0.8181), np.float32(0.6842), np.float32(0.8583)] 
2025-03-16 01:54:47.121389: Epoch time: 38.66 s 
2025-03-16 01:54:47.651912:  
2025-03-16 01:54:47.657973: Epoch 53 
2025-03-16 01:54:47.661005: Current learning rate: 0.00507 
2025-03-16 01:55:26.167161: train_loss -0.7075 
2025-03-16 01:55:26.174193: val_loss -0.5797 
2025-03-16 01:55:26.177701: Pseudo dice [np.float32(0.7956), np.float32(0.6432), np.float32(0.8435)] 
2025-03-16 01:55:26.181208: Epoch time: 38.52 s 
2025-03-16 01:55:26.721743:  
2025-03-16 01:55:26.725778: Epoch 54 
2025-03-16 01:55:26.728310: Current learning rate: 0.00497 
2025-03-16 01:56:05.171685: train_loss -0.7053 
2025-03-16 01:56:05.178256: val_loss -0.653 
2025-03-16 01:56:05.181832: Pseudo dice [np.float32(0.8121), np.float32(0.706), np.float32(0.872)] 
2025-03-16 01:56:05.185348: Epoch time: 38.45 s 
2025-03-16 01:56:05.719830:  
2025-03-16 01:56:05.726929: Epoch 55 
2025-03-16 01:56:05.729982: Current learning rate: 0.00487 
2025-03-16 01:56:44.280983: train_loss -0.718 
2025-03-16 01:56:44.288050: val_loss -0.6207 
2025-03-16 01:56:44.290942: Pseudo dice [np.float32(0.8151), np.float32(0.7212), np.float32(0.8374)] 
2025-03-16 01:56:44.294969: Epoch time: 38.56 s 
2025-03-16 01:56:44.851510:  
2025-03-16 01:56:44.857531: Epoch 56 
2025-03-16 01:56:44.860040: Current learning rate: 0.00478 
2025-03-16 01:57:23.453009: train_loss -0.7232 
2025-03-16 01:57:23.461313: val_loss -0.6499 
2025-03-16 01:57:23.465849: Pseudo dice [np.float32(0.8461), np.float32(0.7087), np.float32(0.8704)] 
2025-03-16 01:57:23.471032: Epoch time: 38.6 s 
2025-03-16 01:57:23.474950: Yayy! New best EMA pseudo Dice: 0.7886999845504761 
2025-03-16 01:57:24.171690:  
2025-03-16 01:57:24.176702: Epoch 57 
2025-03-16 01:57:24.180212: Current learning rate: 0.00468 
2025-03-16 01:58:02.707152: train_loss -0.7213 
2025-03-16 01:58:02.713682: val_loss -0.6195 
2025-03-16 01:58:02.717031: Pseudo dice [np.float32(0.8162), np.float32(0.7198), np.float32(0.861)] 
2025-03-16 01:58:02.720538: Epoch time: 38.54 s 
2025-03-16 01:58:02.724042: Yayy! New best EMA pseudo Dice: 0.7896999716758728 
2025-03-16 01:58:03.411244:  
2025-03-16 01:58:03.416798: Epoch 58 
2025-03-16 01:58:03.420376: Current learning rate: 0.00458 
2025-03-16 01:58:42.032912: train_loss -0.722 
2025-03-16 01:58:42.039927: val_loss -0.6201 
2025-03-16 01:58:42.042937: Pseudo dice [np.float32(0.8124), np.float32(0.7055), np.float32(0.8474)] 
2025-03-16 01:58:42.047448: Epoch time: 38.62 s 
2025-03-16 01:58:42.739010:  
2025-03-16 01:58:42.744553: Epoch 59 
2025-03-16 01:58:42.748597: Current learning rate: 0.00448 
2025-03-16 01:59:21.307014: train_loss -0.7132 
2025-03-16 01:59:21.315103: val_loss -0.6678 
2025-03-16 01:59:21.320703: Pseudo dice [np.float32(0.8239), np.float32(0.6939), np.float32(0.8733)] 
2025-03-16 01:59:21.325251: Epoch time: 38.57 s 
2025-03-16 01:59:21.329793: Yayy! New best EMA pseudo Dice: 0.7904000282287598 
2025-03-16 01:59:22.032436:  
2025-03-16 01:59:22.037972: Epoch 60 
2025-03-16 01:59:22.041483: Current learning rate: 0.00438 
2025-03-16 02:00:00.495750: train_loss -0.7208 
2025-03-16 02:00:00.501764: val_loss -0.6539 
2025-03-16 02:00:00.505775: Pseudo dice [np.float32(0.8356), np.float32(0.7328), np.float32(0.874)] 
2025-03-16 02:00:00.508281: Epoch time: 38.46 s 
2025-03-16 02:00:00.511799: Yayy! New best EMA pseudo Dice: 0.7926999926567078 
2025-03-16 02:00:01.219392:  
2025-03-16 02:00:01.224330: Epoch 61 
2025-03-16 02:00:01.227843: Current learning rate: 0.00429 
2025-03-16 02:00:39.689599: train_loss -0.7199 
2025-03-16 02:00:39.696120: val_loss -0.6435 
2025-03-16 02:00:39.699626: Pseudo dice [np.float32(0.8417), np.float32(0.7002), np.float32(0.8769)] 
2025-03-16 02:00:39.703639: Epoch time: 38.47 s 
2025-03-16 02:00:39.708654: Yayy! New best EMA pseudo Dice: 0.7940999865531921 
2025-03-16 02:00:40.425962:  
2025-03-16 02:00:40.432478: Epoch 62 
2025-03-16 02:00:40.435987: Current learning rate: 0.00419 
2025-03-16 02:01:18.843971: train_loss -0.7138 
2025-03-16 02:01:18.850034: val_loss -0.6437 
2025-03-16 02:01:18.853560: Pseudo dice [np.float32(0.8406), np.float32(0.679), np.float32(0.8633)] 
2025-03-16 02:01:18.857894: Epoch time: 38.42 s 
2025-03-16 02:01:18.861408: Yayy! New best EMA pseudo Dice: 0.7940999865531921 
2025-03-16 02:01:19.569229:  
2025-03-16 02:01:19.573249: Epoch 63 
2025-03-16 02:01:19.576796: Current learning rate: 0.00409 
2025-03-16 02:01:58.072087: train_loss -0.7227 
2025-03-16 02:01:58.079631: val_loss -0.6137 
2025-03-16 02:01:58.083171: Pseudo dice [np.float32(0.8129), np.float32(0.6847), np.float32(0.8449)] 
2025-03-16 02:01:58.085678: Epoch time: 38.5 s 
2025-03-16 02:01:58.633050:  
2025-03-16 02:01:58.638060: Epoch 64 
2025-03-16 02:01:58.641071: Current learning rate: 0.00399 
2025-03-16 02:02:37.068761: train_loss -0.7261 
2025-03-16 02:02:37.075340: val_loss -0.652 
2025-03-16 02:02:37.078917: Pseudo dice [np.float32(0.8432), np.float32(0.7273), np.float32(0.8541)] 
2025-03-16 02:02:37.083466: Epoch time: 38.44 s 
2025-03-16 02:02:37.088060: Yayy! New best EMA pseudo Dice: 0.7943000197410583 
2025-03-16 02:02:37.790188:  
2025-03-16 02:02:37.795759: Epoch 65 
2025-03-16 02:02:37.799794: Current learning rate: 0.00389 
2025-03-16 02:03:16.301582: train_loss -0.728 
2025-03-16 02:03:16.307617: val_loss -0.649 
2025-03-16 02:03:16.311685: Pseudo dice [np.float32(0.8378), np.float32(0.6913), np.float32(0.8771)] 
2025-03-16 02:03:16.314832: Epoch time: 38.51 s 
2025-03-16 02:03:16.318422: Yayy! New best EMA pseudo Dice: 0.7950999736785889 
2025-03-16 02:03:17.157535:  
2025-03-16 02:03:17.164071: Epoch 66 
2025-03-16 02:03:17.169086: Current learning rate: 0.00379 
2025-03-16 02:03:55.581068: train_loss -0.7301 
2025-03-16 02:03:55.587089: val_loss -0.6339 
2025-03-16 02:03:55.591100: Pseudo dice [np.float32(0.8214), np.float32(0.6863), np.float32(0.8705)] 
2025-03-16 02:03:55.594645: Epoch time: 38.42 s 
2025-03-16 02:03:56.136400:  
2025-03-16 02:03:56.142450: Epoch 67 
2025-03-16 02:03:56.146024: Current learning rate: 0.00369 
2025-03-16 02:04:34.687633: train_loss -0.7231 
2025-03-16 02:04:34.694731: val_loss -0.6315 
2025-03-16 02:04:34.700843: Pseudo dice [np.float32(0.8187), np.float32(0.68), np.float32(0.8605)] 
2025-03-16 02:04:34.705903: Epoch time: 38.55 s 
2025-03-16 02:04:35.258783:  
2025-03-16 02:04:35.264860: Epoch 68 
2025-03-16 02:04:35.268895: Current learning rate: 0.00359 
2025-03-16 02:05:13.803674: train_loss -0.7256 
2025-03-16 02:05:13.810688: val_loss -0.6798 
2025-03-16 02:05:13.814708: Pseudo dice [np.float32(0.831), np.float32(0.7018), np.float32(0.8649)] 
2025-03-16 02:05:13.818212: Epoch time: 38.55 s 
2025-03-16 02:05:14.368750:  
2025-03-16 02:05:14.372270: Epoch 69 
2025-03-16 02:05:14.374844: Current learning rate: 0.00349 
2025-03-16 02:05:52.938307: train_loss -0.7337 
2025-03-16 02:05:52.944395: val_loss -0.6319 
2025-03-16 02:05:52.949412: Pseudo dice [np.float32(0.8161), np.float32(0.7152), np.float32(0.8566)] 
2025-03-16 02:05:52.954427: Epoch time: 38.57 s 
2025-03-16 02:05:53.504219:  
2025-03-16 02:05:53.509774: Epoch 70 
2025-03-16 02:05:53.513854: Current learning rate: 0.00338 
2025-03-16 02:06:31.960680: train_loss -0.727 
2025-03-16 02:06:31.966740: val_loss -0.6361 
2025-03-16 02:06:31.971791: Pseudo dice [np.float32(0.8147), np.float32(0.7097), np.float32(0.8509)] 
2025-03-16 02:06:31.976334: Epoch time: 38.46 s 
2025-03-16 02:06:32.525012:  
2025-03-16 02:06:32.530561: Epoch 71 
2025-03-16 02:06:32.534113: Current learning rate: 0.00328 
2025-03-16 02:07:11.039740: train_loss -0.7332 
2025-03-16 02:07:11.046276: val_loss -0.6857 
2025-03-16 02:07:11.050291: Pseudo dice [np.float32(0.8454), np.float32(0.7451), np.float32(0.8581)] 
2025-03-16 02:07:11.053808: Epoch time: 38.51 s 
2025-03-16 02:07:11.057827: Yayy! New best EMA pseudo Dice: 0.7965999841690063 
2025-03-16 02:07:11.776541:  
2025-03-16 02:07:11.781548: Epoch 72 
2025-03-16 02:07:11.785567: Current learning rate: 0.00318 
2025-03-16 02:07:50.244472: train_loss -0.7262 
2025-03-16 02:07:50.250567: val_loss -0.6551 
2025-03-16 02:07:50.253618: Pseudo dice [np.float32(0.834), np.float32(0.7186), np.float32(0.8752)] 
2025-03-16 02:07:50.258161: Epoch time: 38.47 s 
2025-03-16 02:07:50.261674: Yayy! New best EMA pseudo Dice: 0.7978000044822693 
2025-03-16 02:07:50.980430:  
2025-03-16 02:07:50.985942: Epoch 73 
2025-03-16 02:07:50.989453: Current learning rate: 0.00308 
2025-03-16 02:08:29.529568: train_loss -0.7338 
2025-03-16 02:08:29.535697: val_loss -0.6216 
2025-03-16 02:08:29.540758: Pseudo dice [np.float32(0.8103), np.float32(0.6723), np.float32(0.8546)] 
2025-03-16 02:08:29.545334: Epoch time: 38.55 s 
2025-03-16 02:08:30.236136:  
2025-03-16 02:08:30.241668: Epoch 74 
2025-03-16 02:08:30.245217: Current learning rate: 0.00297 
2025-03-16 02:09:12.997621: train_loss -0.7399 
2025-03-16 02:09:13.003802: val_loss -0.6298 
2025-03-16 02:09:13.008372: Pseudo dice [np.float32(0.8224), np.float32(0.7256), np.float32(0.8331)] 
2025-03-16 02:09:13.013932: Epoch time: 42.76 s 
2025-03-16 02:09:13.566710:  
2025-03-16 02:09:13.571730: Epoch 75 
2025-03-16 02:09:13.575251: Current learning rate: 0.00287 
2025-03-16 02:09:52.325378: train_loss -0.7417 
2025-03-16 02:09:52.331390: val_loss -0.6564 
2025-03-16 02:09:52.335403: Pseudo dice [np.float32(0.8252), np.float32(0.6899), np.float32(0.8612)] 
2025-03-16 02:09:52.340416: Epoch time: 38.76 s 
2025-03-16 02:09:52.886445:  
2025-03-16 02:09:52.892013: Epoch 76 
2025-03-16 02:09:52.895584: Current learning rate: 0.00277 
2025-03-16 02:10:31.434339: train_loss -0.743 
2025-03-16 02:10:31.441867: val_loss -0.672 
2025-03-16 02:10:31.446376: Pseudo dice [np.float32(0.829), np.float32(0.7388), np.float32(0.8765)] 
2025-03-16 02:10:31.450387: Epoch time: 38.55 s 
2025-03-16 02:10:32.001447:  
2025-03-16 02:10:32.006979: Epoch 77 
2025-03-16 02:10:32.008985: Current learning rate: 0.00266 
2025-03-16 02:11:10.628708: train_loss -0.7374 
2025-03-16 02:11:10.634357: val_loss -0.6446 
2025-03-16 02:11:10.638443: Pseudo dice [np.float32(0.8398), np.float32(0.6668), np.float32(0.8554)] 
2025-03-16 02:11:10.643583: Epoch time: 38.63 s 
2025-03-16 02:11:11.194915:  
2025-03-16 02:11:11.200438: Epoch 78 
2025-03-16 02:11:11.203948: Current learning rate: 0.00256 
2025-03-16 02:11:49.933718: train_loss -0.7353 
2025-03-16 02:11:49.939882: val_loss -0.6362 
2025-03-16 02:11:49.943395: Pseudo dice [np.float32(0.831), np.float32(0.6976), np.float32(0.8686)] 
2025-03-16 02:11:49.948405: Epoch time: 38.74 s 
2025-03-16 02:11:50.498116:  
2025-03-16 02:11:50.504169: Epoch 79 
2025-03-16 02:11:50.507691: Current learning rate: 0.00245 
2025-03-16 02:12:29.287027: train_loss -0.7323 
2025-03-16 02:12:29.294554: val_loss -0.6706 
2025-03-16 02:12:29.299570: Pseudo dice [np.float32(0.8526), np.float32(0.7274), np.float32(0.8575)] 
2025-03-16 02:12:29.304588: Epoch time: 38.79 s 
2025-03-16 02:12:29.309108: Yayy! New best EMA pseudo Dice: 0.7982000112533569 
2025-03-16 02:12:30.019222:  
2025-03-16 02:12:30.024240: Epoch 80 
2025-03-16 02:12:30.027750: Current learning rate: 0.00235 
2025-03-16 02:13:08.853430: train_loss -0.7371 
2025-03-16 02:13:08.859989: val_loss -0.6581 
2025-03-16 02:13:08.864002: Pseudo dice [np.float32(0.8388), np.float32(0.715), np.float32(0.8624)] 
2025-03-16 02:13:08.868011: Epoch time: 38.83 s 
2025-03-16 02:13:08.873024: Yayy! New best EMA pseudo Dice: 0.7989000082015991 
2025-03-16 02:13:09.739252:  
2025-03-16 02:13:09.746330: Epoch 81 
2025-03-16 02:13:09.749628: Current learning rate: 0.00224 
2025-03-16 02:13:48.456717: train_loss -0.7409 
2025-03-16 02:13:48.463295: val_loss -0.6573 
2025-03-16 02:13:48.466899: Pseudo dice [np.float32(0.8458), np.float32(0.6927), np.float32(0.8671)] 
2025-03-16 02:13:48.471912: Epoch time: 38.72 s 
2025-03-16 02:13:48.475921: Yayy! New best EMA pseudo Dice: 0.7991999983787537 
2025-03-16 02:13:49.193439:  
2025-03-16 02:13:49.197964: Epoch 82 
2025-03-16 02:13:49.200472: Current learning rate: 0.00214 
2025-03-16 02:14:28.012488: train_loss -0.7397 
2025-03-16 02:14:28.018498: val_loss -0.6382 
2025-03-16 02:14:28.024015: Pseudo dice [np.float32(0.8217), np.float32(0.7162), np.float32(0.859)] 
2025-03-16 02:14:28.029027: Epoch time: 38.82 s 
2025-03-16 02:14:28.549990:  
2025-03-16 02:14:28.555556: Epoch 83 
2025-03-16 02:14:28.559128: Current learning rate: 0.00203 
2025-03-16 02:15:07.239734: train_loss -0.7414 
2025-03-16 02:15:07.245316: val_loss -0.6614 
2025-03-16 02:15:07.250356: Pseudo dice [np.float32(0.8338), np.float32(0.7432), np.float32(0.8633)] 
2025-03-16 02:15:07.254882: Epoch time: 38.69 s 
2025-03-16 02:15:07.259962: Yayy! New best EMA pseudo Dice: 0.800599992275238 
2025-03-16 02:15:07.951654:  
2025-03-16 02:15:07.956686: Epoch 84 
2025-03-16 02:15:07.960502: Current learning rate: 0.00192 
2025-03-16 02:15:46.690566: train_loss -0.7455 
2025-03-16 02:15:46.697091: val_loss -0.6615 
2025-03-16 02:15:46.701103: Pseudo dice [np.float32(0.836), np.float32(0.7104), np.float32(0.8775)] 
2025-03-16 02:15:46.705615: Epoch time: 38.74 s 
2025-03-16 02:15:46.711133: Yayy! New best EMA pseudo Dice: 0.8012999892234802 
2025-03-16 02:15:47.406906:  
2025-03-16 02:15:47.412932: Epoch 85 
2025-03-16 02:15:47.415964: Current learning rate: 0.00181 
2025-03-16 02:16:26.153532: train_loss -0.7419 
2025-03-16 02:16:26.160054: val_loss -0.6513 
2025-03-16 02:16:26.164067: Pseudo dice [np.float32(0.818), np.float32(0.6862), np.float32(0.8588)] 
2025-03-16 02:16:26.168580: Epoch time: 38.75 s 
2025-03-16 02:16:26.685650:  
2025-03-16 02:16:26.691768: Epoch 86 
2025-03-16 02:16:26.694827: Current learning rate: 0.0017 
2025-03-16 02:17:05.256613: train_loss -0.74 
2025-03-16 02:17:05.262124: val_loss -0.6569 
2025-03-16 02:17:05.267135: Pseudo dice [np.float32(0.8274), np.float32(0.735), np.float32(0.8533)] 
2025-03-16 02:17:05.272148: Epoch time: 38.57 s 
2025-03-16 02:17:05.789585:  
2025-03-16 02:17:05.794171: Epoch 87 
2025-03-16 02:17:05.798298: Current learning rate: 0.00159 
2025-03-16 02:17:44.556508: train_loss -0.743 
2025-03-16 02:17:44.562061: val_loss -0.6651 
2025-03-16 02:17:44.567190: Pseudo dice [np.float32(0.8309), np.float32(0.7048), np.float32(0.8686)] 
2025-03-16 02:17:44.573236: Epoch time: 38.77 s 
2025-03-16 02:17:45.086405:  
2025-03-16 02:17:45.091941: Epoch 88 
2025-03-16 02:17:45.095452: Current learning rate: 0.00148 
2025-03-16 02:18:23.841268: train_loss -0.7475 
2025-03-16 02:18:23.848339: val_loss -0.6237 
2025-03-16 02:18:23.851375: Pseudo dice [np.float32(0.8298), np.float32(0.6998), np.float32(0.8576)] 
2025-03-16 02:18:23.856429: Epoch time: 38.76 s 
2025-03-16 02:18:24.517718:  
2025-03-16 02:18:24.523694: Epoch 89 
2025-03-16 02:18:24.527706: Current learning rate: 0.00137 
2025-03-16 02:19:03.172750: train_loss -0.7554 
2025-03-16 02:19:03.178768: val_loss -0.6516 
2025-03-16 02:19:03.183785: Pseudo dice [np.float32(0.8217), np.float32(0.7126), np.float32(0.8474)] 
2025-03-16 02:19:03.188803: Epoch time: 38.66 s 
2025-03-16 02:19:03.702836:  
2025-03-16 02:19:03.707847: Epoch 90 
2025-03-16 02:19:03.711357: Current learning rate: 0.00126 
2025-03-16 02:19:42.285258: train_loss -0.7447 
2025-03-16 02:19:42.290781: val_loss -0.658 
2025-03-16 02:19:42.295544: Pseudo dice [np.float32(0.8174), np.float32(0.7035), np.float32(0.8735)] 
2025-03-16 02:19:42.299055: Epoch time: 38.58 s 
2025-03-16 02:19:42.818744:  
2025-03-16 02:19:42.823793: Epoch 91 
2025-03-16 02:19:42.827340: Current learning rate: 0.00115 
2025-03-16 02:20:21.326191: train_loss -0.7467 
2025-03-16 02:20:21.333721: val_loss -0.6835 
2025-03-16 02:20:21.338732: Pseudo dice [np.float32(0.8481), np.float32(0.7441), np.float32(0.8676)] 
2025-03-16 02:20:21.343744: Epoch time: 38.51 s 
2025-03-16 02:20:21.348254: Yayy! New best EMA pseudo Dice: 0.8014000058174133 
2025-03-16 02:20:22.037941:  
2025-03-16 02:20:22.041975: Epoch 92 
2025-03-16 02:20:22.044028: Current learning rate: 0.00103 
2025-03-16 02:21:00.504112: train_loss -0.7469 
2025-03-16 02:21:00.509746: val_loss -0.6282 
2025-03-16 02:21:00.514292: Pseudo dice [np.float32(0.8155), np.float32(0.6644), np.float32(0.8707)] 
2025-03-16 02:21:00.518800: Epoch time: 38.47 s 
2025-03-16 02:21:01.036008:  
2025-03-16 02:21:01.041523: Epoch 93 
2025-03-16 02:21:01.045036: Current learning rate: 0.00091 
2025-03-16 02:21:39.685112: train_loss -0.7528 
2025-03-16 02:21:39.691768: val_loss -0.6513 
2025-03-16 02:21:39.695405: Pseudo dice [np.float32(0.8207), np.float32(0.7194), np.float32(0.8709)] 
2025-03-16 02:21:39.699961: Epoch time: 38.65 s 
2025-03-16 02:21:40.217633:  
2025-03-16 02:21:40.223180: Epoch 94 
2025-03-16 02:21:40.226755: Current learning rate: 0.00079 
2025-03-16 02:22:18.726672: train_loss -0.7562 
2025-03-16 02:22:18.732824: val_loss -0.6178 
2025-03-16 02:22:18.736353: Pseudo dice [np.float32(0.8325), np.float32(0.735), np.float32(0.8424)] 
2025-03-16 02:22:18.740426: Epoch time: 38.51 s 
2025-03-16 02:22:19.268220:  
2025-03-16 02:22:19.274812: Epoch 95 
2025-03-16 02:22:19.278823: Current learning rate: 0.00067 
2025-03-16 02:22:57.796438: train_loss -0.7475 
2025-03-16 02:22:57.802469: val_loss -0.6177 
2025-03-16 02:22:57.806116: Pseudo dice [np.float32(0.8133), np.float32(0.735), np.float32(0.8653)] 
2025-03-16 02:22:57.810143: Epoch time: 38.53 s 
2025-03-16 02:22:58.328342:  
2025-03-16 02:22:58.332364: Epoch 96 
2025-03-16 02:22:58.336376: Current learning rate: 0.00055 
2025-03-16 02:23:36.995620: train_loss -0.7572 
2025-03-16 02:23:37.002212: val_loss -0.6605 
2025-03-16 02:23:37.006765: Pseudo dice [np.float32(0.8382), np.float32(0.7326), np.float32(0.8698)] 
2025-03-16 02:23:37.009808: Epoch time: 38.67 s 
2025-03-16 02:23:37.014838: Yayy! New best EMA pseudo Dice: 0.8019999861717224 
2025-03-16 02:23:37.700470:  
2025-03-16 02:23:37.706541: Epoch 97 
2025-03-16 02:23:37.709662: Current learning rate: 0.00043 
2025-03-16 02:24:16.155907: train_loss -0.759 
2025-03-16 02:24:16.161931: val_loss -0.6603 
2025-03-16 02:24:16.166446: Pseudo dice [np.float32(0.8446), np.float32(0.7515), np.float32(0.8661)] 
2025-03-16 02:24:16.171455: Epoch time: 38.46 s 
2025-03-16 02:24:16.177464: Yayy! New best EMA pseudo Dice: 0.8039000034332275 
2025-03-16 02:24:17.022660:  
2025-03-16 02:24:17.028231: Epoch 98 
2025-03-16 02:24:17.031296: Current learning rate: 0.0003 
2025-03-16 02:24:55.535901: train_loss -0.7576 
2025-03-16 02:24:55.542920: val_loss -0.6479 
2025-03-16 02:24:55.546937: Pseudo dice [np.float32(0.8264), np.float32(0.7268), np.float32(0.8707)] 
2025-03-16 02:24:55.550951: Epoch time: 38.51 s 
2025-03-16 02:24:55.555965: Yayy! New best EMA pseudo Dice: 0.8043000102043152 
2025-03-16 02:24:56.242453:  
2025-03-16 02:24:56.247971: Epoch 99 
2025-03-16 02:24:56.251523: Current learning rate: 0.00016 
2025-03-16 02:25:34.723298: train_loss -0.7524 
2025-03-16 02:25:34.729940: val_loss -0.658 
2025-03-16 02:25:34.735070: Pseudo dice [np.float32(0.8297), np.float32(0.7272), np.float32(0.8645)] 
2025-03-16 02:25:34.738633: Epoch time: 38.48 s 
2025-03-16 02:25:34.743730: Yayy! New best EMA pseudo Dice: 0.8046000003814697 
2025-03-16 02:25:35.626389: Training done. 
2025-03-16 02:25:35.660391: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-16 02:25:35.668394: The split file contains 5 splits. 
2025-03-16 02:25:35.673394: Desired fold for training: 0 
2025-03-16 02:25:35.677395: This split has 387 training and 97 validation cases. 
2025-03-16 02:25:35.683905: predicting BRATS_010 
2025-03-16 02:25:35.689908: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2025-03-16 02:25:37.603457: predicting BRATS_011 
2025-03-16 02:25:37.616459: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2025-03-16 02:25:38.905021: predicting BRATS_012 
2025-03-16 02:25:38.916020: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-16 02:25:40.207922: predicting BRATS_018 
2025-03-16 02:25:40.219921: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2025-03-16 02:25:41.512085: predicting BRATS_020 
2025-03-16 02:25:41.524087: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2025-03-16 02:25:42.816236: predicting BRATS_028 
2025-03-16 02:25:42.828236: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-03-16 02:25:44.120255: predicting BRATS_029 
2025-03-16 02:25:44.132255: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-03-16 02:25:45.430329: predicting BRATS_032 
2025-03-16 02:25:45.443330: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2025-03-16 02:25:46.742054: predicting BRATS_034 
2025-03-16 02:25:46.755053: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2025-03-16 02:25:48.050961: predicting BRATS_041 
2025-03-16 02:25:48.063962: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2025-03-16 02:25:49.376900: predicting BRATS_042 
2025-03-16 02:25:49.390409: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2025-03-16 02:25:50.685565: predicting BRATS_047 
2025-03-16 02:25:50.698074: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-16 02:25:51.989488: predicting BRATS_049 
2025-03-16 02:25:52.002488: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-16 02:25:53.297068: predicting BRATS_053 
2025-03-16 02:25:53.310067: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-16 02:25:54.600440: predicting BRATS_056 
2025-03-16 02:25:54.613441: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-16 02:25:55.905649: predicting BRATS_057 
2025-03-16 02:25:55.917652: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-16 02:25:57.208725: predicting BRATS_067 
2025-03-16 02:25:57.220725: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-16 02:25:58.514331: predicting BRATS_069 
2025-03-16 02:25:58.527331: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-16 02:25:59.823006: predicting BRATS_085 
2025-03-16 02:25:59.837004: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2025-03-16 02:26:00.506423: predicting BRATS_086 
2025-03-16 02:26:00.519422: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2025-03-16 02:26:01.828548: predicting BRATS_088 
2025-03-16 02:26:01.842549: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2025-03-16 02:26:03.167340: predicting BRATS_091 
2025-03-16 02:26:03.180345: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-03-16 02:26:04.489678: predicting BRATS_098 
2025-03-16 02:26:04.503183: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2025-03-16 02:26:05.825974: predicting BRATS_100 
2025-03-16 02:26:05.838973: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-16 02:26:06.518619: predicting BRATS_101 
2025-03-16 02:26:06.531619: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-16 02:26:07.216765: predicting BRATS_102 
2025-03-16 02:26:07.229763: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2025-03-16 02:26:08.522137: predicting BRATS_104 
2025-03-16 02:26:08.536136: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2025-03-16 02:26:09.831589: predicting BRATS_111 
2025-03-16 02:26:09.845589: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2025-03-16 02:26:11.142120: predicting BRATS_116 
2025-03-16 02:26:11.155121: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2025-03-16 02:26:12.451235: predicting BRATS_135 
2025-03-16 02:26:12.464235: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-03-16 02:26:13.757026: predicting BRATS_136 
2025-03-16 02:26:13.771028: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-03-16 02:26:15.062476: predicting BRATS_138 
2025-03-16 02:26:15.076476: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2025-03-16 02:26:16.369058: predicting BRATS_145 
2025-03-16 02:26:16.383058: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2025-03-16 02:26:17.676624: predicting BRATS_149 
2025-03-16 02:26:17.688626: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2025-03-16 02:26:18.982929: predicting BRATS_155 
2025-03-16 02:26:18.995934: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-16 02:26:20.293754: predicting BRATS_157 
2025-03-16 02:26:20.308259: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-16 02:26:21.603436: predicting BRATS_158 
2025-03-16 02:26:21.618942: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-16 02:26:22.911582: predicting BRATS_159 
2025-03-16 02:26:22.924581: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-16 02:26:24.218477: predicting BRATS_163 
2025-03-16 02:26:24.232477: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-03-16 02:26:25.524382: predicting BRATS_164 
2025-03-16 02:26:25.538382: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2025-03-16 02:26:26.829630: predicting BRATS_169 
2025-03-16 02:26:26.841631: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2025-03-16 02:26:28.138930: predicting BRATS_176 
2025-03-16 02:26:28.151929: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-03-16 02:26:29.445022: predicting BRATS_181 
2025-03-16 02:26:29.458023: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2025-03-16 02:26:30.751142: predicting BRATS_183 
2025-03-16 02:26:30.764143: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-16 02:26:32.059115: predicting BRATS_184 
2025-03-16 02:26:32.073116: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-16 02:26:33.402942: predicting BRATS_187 
2025-03-16 02:26:33.415450: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-16 02:26:34.709096: predicting BRATS_192 
2025-03-16 02:26:34.722605: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2025-03-16 02:26:36.013971: predicting BRATS_198 
2025-03-16 02:26:36.026971: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-03-16 02:26:37.323506: predicting BRATS_207 
2025-03-16 02:26:37.337506: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-16 02:26:38.633052: predicting BRATS_208 
2025-03-16 02:26:38.645055: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-16 02:26:39.938329: predicting BRATS_218 
2025-03-16 02:26:39.950328: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-03-16 02:26:41.248825: predicting BRATS_220 
2025-03-16 02:26:41.262825: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2025-03-16 02:26:42.555819: predicting BRATS_224 
2025-03-16 02:26:42.569819: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2025-03-16 02:26:43.863907: predicting BRATS_230 
2025-03-16 02:26:43.877906: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2025-03-16 02:26:45.172829: predicting BRATS_271 
2025-03-16 02:26:45.185830: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2025-03-16 02:26:46.480788: predicting BRATS_282 
2025-03-16 02:26:46.495790: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2025-03-16 02:26:47.790096: predicting BRATS_284 
2025-03-16 02:26:47.803095: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2025-03-16 02:26:49.095679: predicting BRATS_287 
2025-03-16 02:26:49.107681: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-16 02:26:50.404241: predicting BRATS_290 
2025-03-16 02:26:50.418242: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2025-03-16 02:26:51.711185: predicting BRATS_291 
2025-03-16 02:26:51.723688: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-03-16 02:26:53.018313: predicting BRATS_292 
2025-03-16 02:26:53.030818: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2025-03-16 02:26:54.325412: predicting BRATS_293 
2025-03-16 02:26:54.338415: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2025-03-16 02:26:55.634827: predicting BRATS_300 
2025-03-16 02:26:55.648828: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2025-03-16 02:26:56.945328: predicting BRATS_305 
2025-03-16 02:26:56.958328: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2025-03-16 02:26:58.253208: predicting BRATS_311 
2025-03-16 02:26:58.267208: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2025-03-16 02:26:59.565935: predicting BRATS_314 
2025-03-16 02:26:59.579935: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2025-03-16 02:27:00.876257: predicting BRATS_321 
2025-03-16 02:27:00.890257: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-03-16 02:27:02.186061: predicting BRATS_328 
2025-03-16 02:27:02.200060: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2025-03-16 02:27:02.861656: predicting BRATS_329 
2025-03-16 02:27:02.874657: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2025-03-16 02:27:04.168388: predicting BRATS_335 
2025-03-16 02:27:04.182388: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2025-03-16 02:27:05.511723: predicting BRATS_343 
2025-03-16 02:27:05.525725: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2025-03-16 02:27:06.823034: predicting BRATS_350 
2025-03-16 02:27:06.838541: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2025-03-16 02:27:07.509557: predicting BRATS_351 
2025-03-16 02:27:07.521562: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2025-03-16 02:27:08.188307: predicting BRATS_356 
2025-03-16 02:27:08.200307: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2025-03-16 02:27:08.871723: predicting BRATS_366 
2025-03-16 02:27:08.883723: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2025-03-16 02:27:10.179661: predicting BRATS_367 
2025-03-16 02:27:10.193661: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2025-03-16 02:27:11.489269: predicting BRATS_374 
2025-03-16 02:27:11.504269: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2025-03-16 02:27:12.798620: predicting BRATS_376 
2025-03-16 02:27:12.811622: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2025-03-16 02:27:14.106600: predicting BRATS_377 
2025-03-16 02:27:14.120603: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2025-03-16 02:27:15.417635: predicting BRATS_378 
2025-03-16 02:27:15.431639: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2025-03-16 02:27:16.728646: predicting BRATS_379 
2025-03-16 02:27:16.742150: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2025-03-16 02:27:18.039315: predicting BRATS_384 
2025-03-16 02:27:18.053316: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2025-03-16 02:27:19.348591: predicting BRATS_386 
2025-03-16 02:27:19.363590: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-03-16 02:27:20.657054: predicting BRATS_394 
2025-03-16 02:27:20.671053: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-16 02:27:21.966900: predicting BRATS_398 
2025-03-16 02:27:21.981900: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2025-03-16 02:27:23.277550: predicting BRATS_400 
2025-03-16 02:27:23.291552: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2025-03-16 02:27:24.590037: predicting BRATS_432 
2025-03-16 02:27:24.605036: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2025-03-16 02:27:25.900140: predicting BRATS_437 
2025-03-16 02:27:25.914140: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-16 02:27:27.206120: predicting BRATS_445 
2025-03-16 02:27:27.220119: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2025-03-16 02:27:28.514877: predicting BRATS_446 
2025-03-16 02:27:28.527881: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-03-16 02:27:29.822316: predicting BRATS_450 
2025-03-16 02:27:29.837320: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2025-03-16 02:27:31.130086: predicting BRATS_452 
2025-03-16 02:27:31.143088: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2025-03-16 02:27:32.439089: predicting BRATS_460 
2025-03-16 02:27:32.453597: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2025-03-16 02:27:33.748040: predicting BRATS_470 
2025-03-16 02:27:33.761549: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-03-16 02:27:35.057443: predicting BRATS_472 
2025-03-16 02:27:35.069444: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2025-03-16 02:27:36.362442: predicting BRATS_473 
2025-03-16 02:27:36.375442: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2025-03-16 02:27:37.044732: predicting BRATS_482 
2025-03-16 02:27:37.055796: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2025-03-16 02:27:45.261681: Validation complete 
2025-03-16 02:27:45.266678: Mean Validation Dice:  0.7244539929683582 
