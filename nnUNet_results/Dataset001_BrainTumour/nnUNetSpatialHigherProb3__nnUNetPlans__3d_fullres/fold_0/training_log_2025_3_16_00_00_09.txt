
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-16 00:00:09.630782: do_dummy_2d_data_aug: False 
2025-03-16 00:00:09.638782: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-16 00:00:09.645572: The split file contains 5 splits. 
2025-03-16 00:00:09.647572: Desired fold for training: 0 
2025-03-16 00:00:09.650574: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2025-03-16 00:00:41.719305: unpacking dataset... 
2025-03-16 00:00:42.385530: unpacking done... 
2025-03-16 00:00:46.124005:  
2025-03-16 00:00:46.130534: Epoch 0 
2025-03-16 00:00:46.134050: Current learning rate: 0.01 
2025-03-16 00:01:28.395738: train_loss -0.2569 
2025-03-16 00:01:28.403255: val_loss -0.4359 
2025-03-16 00:01:28.406760: Pseudo dice [np.float32(0.6942), np.float32(0.5139), np.float32(0.7666)] 
2025-03-16 00:01:28.409786: Epoch time: 42.27 s 
2025-03-16 00:01:28.413297: Yayy! New best EMA pseudo Dice: 0.6582000255584717 
2025-03-16 00:01:29.130195:  
2025-03-16 00:01:29.135206: Epoch 1 
2025-03-16 00:01:29.138716: Current learning rate: 0.00991 
2025-03-16 00:02:07.679010: train_loss -0.4864 
2025-03-16 00:02:07.685542: val_loss -0.4768 
2025-03-16 00:02:07.689530: Pseudo dice [np.float32(0.7109), np.float32(0.5729), np.float32(0.7754)] 
2025-03-16 00:02:07.692559: Epoch time: 38.55 s 
2025-03-16 00:02:07.696068: Yayy! New best EMA pseudo Dice: 0.6610999703407288 
2025-03-16 00:02:08.429882:  
2025-03-16 00:02:08.434959: Epoch 2 
2025-03-16 00:02:08.437849: Current learning rate: 0.00982 
2025-03-16 00:02:46.742908: train_loss -0.5407 
2025-03-16 00:02:46.748951: val_loss -0.5179 
2025-03-16 00:02:46.752959: Pseudo dice [np.float32(0.7612), np.float32(0.6214), np.float32(0.7683)] 
2025-03-16 00:02:46.756469: Epoch time: 38.31 s 
2025-03-16 00:02:46.758984: Yayy! New best EMA pseudo Dice: 0.6665999889373779 
2025-03-16 00:02:47.533920:  
2025-03-16 00:02:47.540187: Epoch 3 
2025-03-16 00:02:47.545205: Current learning rate: 0.00973 
2025-03-16 00:03:25.805911: train_loss -0.5624 
2025-03-16 00:03:25.813025: val_loss -0.5024 
2025-03-16 00:03:25.815570: Pseudo dice [np.float32(0.7632), np.float32(0.5748), np.float32(0.788)] 
2025-03-16 00:03:25.820141: Epoch time: 38.27 s 
2025-03-16 00:03:25.823212: Yayy! New best EMA pseudo Dice: 0.670799970626831 
2025-03-16 00:03:26.565503:  
2025-03-16 00:03:26.571085: Epoch 4 
2025-03-16 00:03:26.573626: Current learning rate: 0.00964 
2025-03-16 00:04:04.904458: train_loss -0.5932 
2025-03-16 00:04:04.911077: val_loss -0.541 
2025-03-16 00:04:04.914116: Pseudo dice [np.float32(0.7578), np.float32(0.641), np.float32(0.8268)] 
2025-03-16 00:04:04.917161: Epoch time: 38.34 s 
2025-03-16 00:04:04.919711: Yayy! New best EMA pseudo Dice: 0.6779999732971191 
2025-03-16 00:04:05.807724:  
2025-03-16 00:04:05.813273: Epoch 5 
2025-03-16 00:04:05.816303: Current learning rate: 0.00955 
2025-03-16 00:04:44.081926: train_loss -0.5902 
2025-03-16 00:04:44.087981: val_loss -0.5716 
2025-03-16 00:04:44.091556: Pseudo dice [np.float32(0.7815), np.float32(0.6678), np.float32(0.8242)] 
2025-03-16 00:04:44.094588: Epoch time: 38.28 s 
2025-03-16 00:04:44.097110: Yayy! New best EMA pseudo Dice: 0.6858999729156494 
2025-03-16 00:04:44.845834:  
2025-03-16 00:04:44.851851: Epoch 6 
2025-03-16 00:04:44.854565: Current learning rate: 0.00946 
2025-03-16 00:05:23.115207: train_loss -0.5993 
2025-03-16 00:05:23.122726: val_loss -0.5897 
2025-03-16 00:05:23.126230: Pseudo dice [np.float32(0.8042), np.float32(0.6163), np.float32(0.8389)] 
2025-03-16 00:05:23.129239: Epoch time: 38.27 s 
2025-03-16 00:05:23.132747: Yayy! New best EMA pseudo Dice: 0.6927000284194946 
2025-03-16 00:05:23.891077:  
2025-03-16 00:05:23.896650: Epoch 7 
2025-03-16 00:05:23.900231: Current learning rate: 0.00937 
2025-03-16 00:06:02.304985: train_loss -0.601 
2025-03-16 00:06:02.311616: val_loss -0.5904 
2025-03-16 00:06:02.315155: Pseudo dice [np.float32(0.8003), np.float32(0.6413), np.float32(0.8213)] 
2025-03-16 00:06:02.318694: Epoch time: 38.41 s 
2025-03-16 00:06:02.321725: Yayy! New best EMA pseudo Dice: 0.6988000273704529 
2025-03-16 00:06:03.072995:  
2025-03-16 00:06:03.077030: Epoch 8 
2025-03-16 00:06:03.080564: Current learning rate: 0.00928 
2025-03-16 00:06:41.407973: train_loss -0.6176 
2025-03-16 00:06:41.413985: val_loss -0.5706 
2025-03-16 00:06:41.418000: Pseudo dice [np.float32(0.789), np.float32(0.6391), np.float32(0.8408)] 
2025-03-16 00:06:41.421506: Epoch time: 38.33 s 
2025-03-16 00:06:41.424514: Yayy! New best EMA pseudo Dice: 0.7045999765396118 
2025-03-16 00:06:42.192742:  
2025-03-16 00:06:42.197268: Epoch 9 
2025-03-16 00:06:42.200833: Current learning rate: 0.00919 
2025-03-16 00:07:20.462622: train_loss -0.617 
2025-03-16 00:07:20.468652: val_loss -0.5703 
2025-03-16 00:07:20.472995: Pseudo dice [np.float32(0.7951), np.float32(0.656), np.float32(0.8042)] 
2025-03-16 00:07:20.475503: Epoch time: 38.27 s 
2025-03-16 00:07:20.479025: Yayy! New best EMA pseudo Dice: 0.7092999815940857 
2025-03-16 00:07:21.205607:  
2025-03-16 00:07:21.210647: Epoch 10 
2025-03-16 00:07:21.214286: Current learning rate: 0.0091 
2025-03-16 00:07:59.418005: train_loss -0.6318 
2025-03-16 00:07:59.425063: val_loss -0.5924 
2025-03-16 00:07:59.428153: Pseudo dice [np.float32(0.7806), np.float32(0.6857), np.float32(0.8136)] 
2025-03-16 00:07:59.431687: Epoch time: 38.21 s 
2025-03-16 00:07:59.434737: Yayy! New best EMA pseudo Dice: 0.7142999768257141 
2025-03-16 00:08:00.193391:  
2025-03-16 00:08:00.199433: Epoch 11 
2025-03-16 00:08:00.203104: Current learning rate: 0.009 
2025-03-16 00:08:38.601793: train_loss -0.6357 
2025-03-16 00:08:38.607383: val_loss -0.5964 
2025-03-16 00:08:38.611549: Pseudo dice [np.float32(0.7912), np.float32(0.6574), np.float32(0.8237)] 
2025-03-16 00:08:38.614594: Epoch time: 38.41 s 
2025-03-16 00:08:38.617628: Yayy! New best EMA pseudo Dice: 0.7186999917030334 
2025-03-16 00:08:39.356606:  
2025-03-16 00:08:39.361150: Epoch 12 
2025-03-16 00:08:39.364190: Current learning rate: 0.00891 
2025-03-16 00:09:17.637537: train_loss -0.6224 
2025-03-16 00:09:17.644172: val_loss -0.5749 
2025-03-16 00:09:17.647209: Pseudo dice [np.float32(0.7814), np.float32(0.6707), np.float32(0.8071)] 
2025-03-16 00:09:17.650280: Epoch time: 38.28 s 
2025-03-16 00:09:17.653368: Yayy! New best EMA pseudo Dice: 0.722100019454956 
2025-03-16 00:09:18.582640:  
2025-03-16 00:09:18.588162: Epoch 13 
2025-03-16 00:09:18.591171: Current learning rate: 0.00882 
2025-03-16 00:09:56.875041: train_loss -0.6458 
2025-03-16 00:09:56.881698: val_loss -0.6343 
2025-03-16 00:09:56.885249: Pseudo dice [np.float32(0.8254), np.float32(0.6709), np.float32(0.8543)] 
2025-03-16 00:09:56.888819: Epoch time: 38.29 s 
2025-03-16 00:09:56.891865: Yayy! New best EMA pseudo Dice: 0.7282000184059143 
2025-03-16 00:09:57.640932:  
2025-03-16 00:09:57.645971: Epoch 14 
2025-03-16 00:09:57.648504: Current learning rate: 0.00873 
2025-03-16 00:10:36.023848: train_loss -0.6521 
2025-03-16 00:10:36.030794: val_loss -0.5806 
2025-03-16 00:10:36.034331: Pseudo dice [np.float32(0.7813), np.float32(0.6674), np.float32(0.8193)] 
2025-03-16 00:10:36.037855: Epoch time: 38.38 s 
2025-03-16 00:10:36.040880: Yayy! New best EMA pseudo Dice: 0.7310000061988831 
2025-03-16 00:10:36.806267:  
2025-03-16 00:10:36.812304: Epoch 15 
2025-03-16 00:10:36.815371: Current learning rate: 0.00864 
2025-03-16 00:11:20.290748: train_loss -0.6566 
2025-03-16 00:11:20.297327: val_loss -0.6129 
2025-03-16 00:11:20.299863: Pseudo dice [np.float32(0.8172), np.float32(0.6692), np.float32(0.8198)] 
2025-03-16 00:11:20.303396: Epoch time: 43.49 s 
2025-03-16 00:11:20.306429: Yayy! New best EMA pseudo Dice: 0.7347999811172485 
2025-03-16 00:11:21.076897:  
2025-03-16 00:11:21.083443: Epoch 16 
2025-03-16 00:11:21.085952: Current learning rate: 0.00855 
2025-03-16 00:12:03.484034: train_loss -0.6533 
2025-03-16 00:12:03.490163: val_loss -0.6172 
2025-03-16 00:12:03.493197: Pseudo dice [np.float32(0.8095), np.float32(0.6718), np.float32(0.8339)] 
2025-03-16 00:12:03.496726: Epoch time: 42.41 s 
2025-03-16 00:12:03.499753: Yayy! New best EMA pseudo Dice: 0.7384999990463257 
2025-03-16 00:12:04.283762:  
2025-03-16 00:12:04.289834: Epoch 17 
2025-03-16 00:12:04.292968: Current learning rate: 0.00846 
2025-03-16 00:12:46.813453: train_loss -0.6523 
2025-03-16 00:12:46.819516: val_loss -0.6002 
2025-03-16 00:12:46.823040: Pseudo dice [np.float32(0.812), np.float32(0.6582), np.float32(0.8531)] 
2025-03-16 00:12:46.826568: Epoch time: 42.53 s 
2025-03-16 00:12:46.829599: Yayy! New best EMA pseudo Dice: 0.7421000003814697 
2025-03-16 00:12:47.600871:  
2025-03-16 00:12:47.606912: Epoch 18 
2025-03-16 00:12:47.610988: Current learning rate: 0.00836 
2025-03-16 00:13:28.753770: train_loss -0.6647 
2025-03-16 00:13:28.760820: val_loss -0.6226 
2025-03-16 00:13:28.765365: Pseudo dice [np.float32(0.8133), np.float32(0.7003), np.float32(0.845)] 
2025-03-16 00:13:28.768895: Epoch time: 41.15 s 
2025-03-16 00:13:28.772439: Yayy! New best EMA pseudo Dice: 0.7465000152587891 
2025-03-16 00:13:29.552997:  
2025-03-16 00:13:29.557009: Epoch 19 
2025-03-16 00:13:29.561019: Current learning rate: 0.00827 
2025-03-16 00:14:10.196453: train_loss -0.6719 
2025-03-16 00:14:10.203494: val_loss -0.5779 
2025-03-16 00:14:10.206517: Pseudo dice [np.float32(0.7954), np.float32(0.6543), np.float32(0.8217)] 
2025-03-16 00:14:10.210538: Epoch time: 40.64 s 
2025-03-16 00:14:10.213556: Yayy! New best EMA pseudo Dice: 0.7476000189781189 
2025-03-16 00:14:11.110389:  
2025-03-16 00:14:11.115400: Epoch 20 
2025-03-16 00:14:11.119908: Current learning rate: 0.00818 
2025-03-16 00:14:49.756187: train_loss -0.6703 
2025-03-16 00:14:49.763271: val_loss -0.6399 
2025-03-16 00:14:49.766312: Pseudo dice [np.float32(0.8177), np.float32(0.6975), np.float32(0.8454)] 
2025-03-16 00:14:49.772931: Epoch time: 38.65 s 
2025-03-16 00:14:49.775978: Yayy! New best EMA pseudo Dice: 0.7515000104904175 
2025-03-16 00:14:50.537967:  
2025-03-16 00:14:50.545022: Epoch 21 
2025-03-16 00:14:50.550071: Current learning rate: 0.00809 
2025-03-16 00:15:29.119652: train_loss -0.6636 
2025-03-16 00:15:29.125730: val_loss -0.6055 
2025-03-16 00:15:29.129257: Pseudo dice [np.float32(0.8136), np.float32(0.6118), np.float32(0.8494)] 
2025-03-16 00:15:29.132795: Epoch time: 38.58 s 
2025-03-16 00:15:29.135839: Yayy! New best EMA pseudo Dice: 0.7522000074386597 
2025-03-16 00:15:29.920405:  
2025-03-16 00:15:29.925931: Epoch 22 
2025-03-16 00:15:29.928950: Current learning rate: 0.008 
2025-03-16 00:16:08.651132: train_loss -0.6729 
2025-03-16 00:16:08.657661: val_loss -0.6296 
2025-03-16 00:16:08.661701: Pseudo dice [np.float32(0.8238), np.float32(0.7055), np.float32(0.8632)] 
2025-03-16 00:16:08.665225: Epoch time: 38.73 s 
2025-03-16 00:16:08.668247: Yayy! New best EMA pseudo Dice: 0.7566999793052673 
2025-03-16 00:16:09.371905:  
2025-03-16 00:16:09.375925: Epoch 23 
2025-03-16 00:16:09.379446: Current learning rate: 0.0079 
2025-03-16 00:16:48.025989: train_loss -0.6748 
2025-03-16 00:16:48.032557: val_loss -0.6223 
2025-03-16 00:16:48.035133: Pseudo dice [np.float32(0.8166), np.float32(0.6834), np.float32(0.8474)] 
2025-03-16 00:16:48.039692: Epoch time: 38.66 s 
2025-03-16 00:16:48.042736: Yayy! New best EMA pseudo Dice: 0.7592999935150146 
2025-03-16 00:16:48.734588:  
2025-03-16 00:16:48.740116: Epoch 24 
2025-03-16 00:16:48.743635: Current learning rate: 0.00781 
2025-03-16 00:17:27.336993: train_loss -0.6765 
2025-03-16 00:17:27.343007: val_loss -0.6368 
2025-03-16 00:17:27.347017: Pseudo dice [np.float32(0.8281), np.float32(0.7234), np.float32(0.8593)] 
2025-03-16 00:17:27.349522: Epoch time: 38.6 s 
2025-03-16 00:17:27.354030: Yayy! New best EMA pseudo Dice: 0.763700008392334 
2025-03-16 00:17:28.089788:  
2025-03-16 00:17:28.096300: Epoch 25 
2025-03-16 00:17:28.099809: Current learning rate: 0.00772 
2025-03-16 00:18:06.695208: train_loss -0.6747 
2025-03-16 00:18:06.701832: val_loss -0.581 
2025-03-16 00:18:06.705918: Pseudo dice [np.float32(0.8079), np.float32(0.5862), np.float32(0.8173)] 
2025-03-16 00:18:06.711461: Epoch time: 38.61 s 
2025-03-16 00:18:07.250873:  
2025-03-16 00:18:07.255882: Epoch 26 
2025-03-16 00:18:07.259395: Current learning rate: 0.00763 
2025-03-16 00:18:45.862523: train_loss -0.6728 
2025-03-16 00:18:45.869036: val_loss -0.6089 
2025-03-16 00:18:45.872547: Pseudo dice [np.float32(0.8021), np.float32(0.6668), np.float32(0.8506)] 
2025-03-16 00:18:45.876555: Epoch time: 38.61 s 
2025-03-16 00:18:46.417820:  
2025-03-16 00:18:46.424329: Epoch 27 
2025-03-16 00:18:46.427838: Current learning rate: 0.00753 
2025-03-16 00:19:25.095876: train_loss -0.6769 
2025-03-16 00:19:25.102506: val_loss -0.6177 
2025-03-16 00:19:25.106553: Pseudo dice [np.float32(0.7841), np.float32(0.6931), np.float32(0.8441)] 
2025-03-16 00:19:25.110619: Epoch time: 38.68 s 
2025-03-16 00:19:25.804961:  
2025-03-16 00:19:25.811474: Epoch 28 
2025-03-16 00:19:25.814985: Current learning rate: 0.00744 
2025-03-16 00:20:04.377635: train_loss -0.6728 
2025-03-16 00:20:04.385363: val_loss -0.6093 
2025-03-16 00:20:04.389424: Pseudo dice [np.float32(0.8229), np.float32(0.69), np.float32(0.8343)] 
2025-03-16 00:20:04.394530: Epoch time: 38.57 s 
2025-03-16 00:20:04.397556: Yayy! New best EMA pseudo Dice: 0.7652999758720398 
2025-03-16 00:20:05.125521:  
2025-03-16 00:20:05.130631: Epoch 29 
2025-03-16 00:20:05.134688: Current learning rate: 0.00735 
2025-03-16 00:20:43.887816: train_loss -0.6802 
2025-03-16 00:20:43.895021: val_loss -0.6373 
2025-03-16 00:20:43.899039: Pseudo dice [np.float32(0.8222), np.float32(0.6824), np.float32(0.8475)] 
2025-03-16 00:20:43.902550: Epoch time: 38.76 s 
2025-03-16 00:20:43.906063: Yayy! New best EMA pseudo Dice: 0.7671999931335449 
2025-03-16 00:20:44.656349:  
2025-03-16 00:20:44.661862: Epoch 30 
2025-03-16 00:20:44.665373: Current learning rate: 0.00725 
2025-03-16 00:21:23.214458: train_loss -0.6835 
2025-03-16 00:21:23.220501: val_loss -0.6305 
2025-03-16 00:21:23.225076: Pseudo dice [np.float32(0.8271), np.float32(0.6757), np.float32(0.8382)] 
2025-03-16 00:21:23.229592: Epoch time: 38.56 s 
2025-03-16 00:21:23.233628: Yayy! New best EMA pseudo Dice: 0.7684999704360962 
2025-03-16 00:21:23.954630:  
2025-03-16 00:21:23.961142: Epoch 31 
2025-03-16 00:21:23.964655: Current learning rate: 0.00716 
2025-03-16 00:22:02.671870: train_loss -0.6851 
2025-03-16 00:22:02.679448: val_loss -0.6248 
2025-03-16 00:22:02.682466: Pseudo dice [np.float32(0.8211), np.float32(0.6917), np.float32(0.8369)] 
2025-03-16 00:22:02.685493: Epoch time: 38.72 s 
2025-03-16 00:22:02.690020: Yayy! New best EMA pseudo Dice: 0.7699999809265137 
2025-03-16 00:22:03.394671:  
2025-03-16 00:22:03.400208: Epoch 32 
2025-03-16 00:22:03.403717: Current learning rate: 0.00707 
2025-03-16 00:22:42.003826: train_loss -0.6892 
2025-03-16 00:22:42.010432: val_loss -0.6423 
2025-03-16 00:22:42.014463: Pseudo dice [np.float32(0.8242), np.float32(0.6939), np.float32(0.8761)] 
2025-03-16 00:22:42.018021: Epoch time: 38.61 s 
2025-03-16 00:22:42.021598: Yayy! New best EMA pseudo Dice: 0.7728000283241272 
2025-03-16 00:22:42.904753:  
2025-03-16 00:22:42.910784: Epoch 33 
2025-03-16 00:22:42.912983: Current learning rate: 0.00697 
2025-03-16 00:23:21.634366: train_loss -0.6962 
2025-03-16 00:23:21.639924: val_loss -0.6238 
2025-03-16 00:23:21.644449: Pseudo dice [np.float32(0.804), np.float32(0.7031), np.float32(0.8542)] 
2025-03-16 00:23:21.647481: Epoch time: 38.73 s 
2025-03-16 00:23:21.652010: Yayy! New best EMA pseudo Dice: 0.7742000222206116 
2025-03-16 00:23:22.370213:  
2025-03-16 00:23:22.376780: Epoch 34 
2025-03-16 00:23:22.380846: Current learning rate: 0.00688 
2025-03-16 00:24:00.839643: train_loss -0.7068 
2025-03-16 00:24:00.844873: val_loss -0.6227 
2025-03-16 00:24:00.849948: Pseudo dice [np.float32(0.8275), np.float32(0.6855), np.float32(0.8404)] 
2025-03-16 00:24:00.854668: Epoch time: 38.47 s 
2025-03-16 00:24:00.858728: Yayy! New best EMA pseudo Dice: 0.7752000093460083 
2025-03-16 00:24:01.592593:  
2025-03-16 00:24:01.597663: Epoch 35 
2025-03-16 00:24:01.601226: Current learning rate: 0.00679 
2025-03-16 00:24:40.254282: train_loss -0.6927 
2025-03-16 00:24:40.260878: val_loss -0.6379 
2025-03-16 00:24:40.264940: Pseudo dice [np.float32(0.8148), np.float32(0.7083), np.float32(0.8535)] 
2025-03-16 00:24:40.268766: Epoch time: 38.66 s 
2025-03-16 00:24:40.272797: Yayy! New best EMA pseudo Dice: 0.7768999934196472 
2025-03-16 00:24:41.141031:  
2025-03-16 00:24:41.145894: Epoch 36 
2025-03-16 00:24:41.150477: Current learning rate: 0.00669 
2025-03-16 00:25:19.664010: train_loss -0.7001 
2025-03-16 00:25:19.670144: val_loss -0.6082 
2025-03-16 00:25:19.675166: Pseudo dice [np.float32(0.7975), np.float32(0.7319), np.float32(0.8619)] 
2025-03-16 00:25:19.679188: Epoch time: 38.52 s 
2025-03-16 00:25:19.682704: Yayy! New best EMA pseudo Dice: 0.7789000272750854 
2025-03-16 00:25:20.398695:  
2025-03-16 00:25:20.404249: Epoch 37 
2025-03-16 00:25:20.406792: Current learning rate: 0.0066 
2025-03-16 00:25:58.954547: train_loss -0.6992 
2025-03-16 00:25:58.960524: val_loss -0.6156 
2025-03-16 00:25:58.964029: Pseudo dice [np.float32(0.8122), np.float32(0.6969), np.float32(0.8331)] 
2025-03-16 00:25:58.967042: Epoch time: 38.56 s 
2025-03-16 00:25:58.970552: Yayy! New best EMA pseudo Dice: 0.7791000008583069 
2025-03-16 00:25:59.690499:  
2025-03-16 00:25:59.695511: Epoch 38 
2025-03-16 00:25:59.699023: Current learning rate: 0.0065 
2025-03-16 00:26:38.060874: train_loss -0.7012 
2025-03-16 00:26:38.066919: val_loss -0.6011 
2025-03-16 00:26:38.070967: Pseudo dice [np.float32(0.8047), np.float32(0.6586), np.float32(0.8579)] 
2025-03-16 00:26:38.073486: Epoch time: 38.37 s 
2025-03-16 00:26:38.639987:  
2025-03-16 00:26:38.645100: Epoch 39 
2025-03-16 00:26:38.648612: Current learning rate: 0.00641 
2025-03-16 00:27:17.117565: train_loss -0.7059 
2025-03-16 00:27:17.124128: val_loss -0.6251 
2025-03-16 00:27:17.127738: Pseudo dice [np.float32(0.803), np.float32(0.6738), np.float32(0.8422)] 
2025-03-16 00:27:17.130276: Epoch time: 38.48 s 
2025-03-16 00:27:17.692413:  
2025-03-16 00:27:17.698439: Epoch 40 
2025-03-16 00:27:17.701482: Current learning rate: 0.00631 
2025-03-16 00:27:56.143152: train_loss -0.6914 
2025-03-16 00:27:56.152356: val_loss -0.6433 
2025-03-16 00:27:56.156424: Pseudo dice [np.float32(0.8271), np.float32(0.697), np.float32(0.8638)] 
2025-03-16 00:27:56.161457: Epoch time: 38.45 s 
2025-03-16 00:27:56.166001: Yayy! New best EMA pseudo Dice: 0.7797999978065491 
2025-03-16 00:27:56.904603:  
2025-03-16 00:27:56.910706: Epoch 41 
2025-03-16 00:27:56.914225: Current learning rate: 0.00622 
2025-03-16 00:28:35.345378: train_loss -0.7054 
2025-03-16 00:28:35.351898: val_loss -0.6241 
2025-03-16 00:28:35.355911: Pseudo dice [np.float32(0.8225), np.float32(0.7244), np.float32(0.8392)] 
2025-03-16 00:28:35.359422: Epoch time: 38.44 s 
2025-03-16 00:28:35.363442: Yayy! New best EMA pseudo Dice: 0.7814000248908997 
2025-03-16 00:28:36.058443:  
2025-03-16 00:28:36.062485: Epoch 42 
2025-03-16 00:28:36.067589: Current learning rate: 0.00612 
2025-03-16 00:29:14.465185: train_loss -0.7145 
2025-03-16 00:29:14.470737: val_loss -0.6079 
2025-03-16 00:29:14.475377: Pseudo dice [np.float32(0.8106), np.float32(0.6489), np.float32(0.8485)] 
2025-03-16 00:29:14.478943: Epoch time: 38.41 s 
2025-03-16 00:29:15.019148:  
2025-03-16 00:29:15.024733: Epoch 43 
2025-03-16 00:29:15.027260: Current learning rate: 0.00603 
2025-03-16 00:29:53.428462: train_loss -0.7096 
2025-03-16 00:29:53.434994: val_loss -0.6189 
2025-03-16 00:29:53.439065: Pseudo dice [np.float32(0.8139), np.float32(0.6943), np.float32(0.8617)] 
2025-03-16 00:29:53.443578: Epoch time: 38.41 s 
2025-03-16 00:29:54.116688:  
2025-03-16 00:29:54.122698: Epoch 44 
2025-03-16 00:29:54.126712: Current learning rate: 0.00593 
2025-03-16 00:30:32.583320: train_loss -0.7112 
2025-03-16 00:30:32.590931: val_loss -0.6302 
2025-03-16 00:30:32.595465: Pseudo dice [np.float32(0.8325), np.float32(0.6829), np.float32(0.8601)] 
2025-03-16 00:30:32.599510: Epoch time: 38.47 s 
2025-03-16 00:30:32.604035: Yayy! New best EMA pseudo Dice: 0.7821999788284302 
2025-03-16 00:30:33.351055:  
2025-03-16 00:30:33.356645: Epoch 45 
2025-03-16 00:30:33.360154: Current learning rate: 0.00584 
2025-03-16 00:31:11.703802: train_loss -0.7038 
2025-03-16 00:31:11.710318: val_loss -0.6077 
2025-03-16 00:31:11.713829: Pseudo dice [np.float32(0.8095), np.float32(0.6565), np.float32(0.8419)] 
2025-03-16 00:31:11.717840: Epoch time: 38.35 s 
2025-03-16 00:31:12.246637:  
2025-03-16 00:31:12.250673: Epoch 46 
2025-03-16 00:31:12.254682: Current learning rate: 0.00574 
2025-03-16 00:31:50.659499: train_loss -0.7141 
2025-03-16 00:31:50.665512: val_loss -0.6455 
2025-03-16 00:31:50.669019: Pseudo dice [np.float32(0.8265), np.float32(0.7085), np.float32(0.8548)] 
2025-03-16 00:31:50.672026: Epoch time: 38.41 s 
2025-03-16 00:31:50.675533: Yayy! New best EMA pseudo Dice: 0.7825000286102295 
2025-03-16 00:31:51.375502:  
2025-03-16 00:31:51.381047: Epoch 47 
2025-03-16 00:31:51.384598: Current learning rate: 0.00565 
2025-03-16 00:32:29.896953: train_loss -0.7185 
2025-03-16 00:32:29.901977: val_loss -0.6397 
2025-03-16 00:32:29.904750: Pseudo dice [np.float32(0.8345), np.float32(0.6522), np.float32(0.8675)] 
2025-03-16 00:32:29.909294: Epoch time: 38.52 s 
2025-03-16 00:32:29.912887: Yayy! New best EMA pseudo Dice: 0.7827000021934509 
2025-03-16 00:32:30.603805:  
2025-03-16 00:32:30.609028: Epoch 48 
2025-03-16 00:32:30.612579: Current learning rate: 0.00555 
2025-03-16 00:33:09.033013: train_loss -0.7199 
2025-03-16 00:33:09.040058: val_loss -0.6316 
2025-03-16 00:33:09.045578: Pseudo dice [np.float32(0.8343), np.float32(0.6752), np.float32(0.8632)] 
2025-03-16 00:33:09.050596: Epoch time: 38.43 s 
2025-03-16 00:33:09.055108: Yayy! New best EMA pseudo Dice: 0.7835000157356262 
2025-03-16 00:33:09.766770:  
2025-03-16 00:33:09.772872: Epoch 49 
2025-03-16 00:33:09.776383: Current learning rate: 0.00546 
2025-03-16 00:33:48.180425: train_loss -0.728 
2025-03-16 00:33:48.187504: val_loss -0.655 
2025-03-16 00:33:48.191132: Pseudo dice [np.float32(0.8249), np.float32(0.704), np.float32(0.8788)] 
2025-03-16 00:33:48.195174: Epoch time: 38.41 s 
2025-03-16 00:33:48.349478: Yayy! New best EMA pseudo Dice: 0.7853999733924866 
2025-03-16 00:33:49.042003:  
2025-03-16 00:33:49.047583: Epoch 50 
2025-03-16 00:33:49.050622: Current learning rate: 0.00536 
2025-03-16 00:34:27.534731: train_loss -0.7092 
2025-03-16 00:34:27.543931: val_loss -0.6399 
2025-03-16 00:34:27.550143: Pseudo dice [np.float32(0.8082), np.float32(0.6517), np.float32(0.8659)] 
2025-03-16 00:34:27.570237: Epoch time: 38.49 s 
2025-03-16 00:34:28.111168:  
2025-03-16 00:34:28.116228: Epoch 51 
2025-03-16 00:34:28.120342: Current learning rate: 0.00526 
2025-03-16 00:35:06.691137: train_loss -0.7114 
2025-03-16 00:35:06.698241: val_loss -0.6349 
2025-03-16 00:35:06.701806: Pseudo dice [np.float32(0.8105), np.float32(0.7153), np.float32(0.8614)] 
2025-03-16 00:35:06.705322: Epoch time: 38.58 s 
2025-03-16 00:35:06.709409: Yayy! New best EMA pseudo Dice: 0.7856000065803528 
2025-03-16 00:35:07.551092:  
2025-03-16 00:35:07.557146: Epoch 52 
2025-03-16 00:35:07.560655: Current learning rate: 0.00517 
2025-03-16 00:35:45.991506: train_loss -0.7239 
2025-03-16 00:35:45.998176: val_loss -0.6283 
2025-03-16 00:35:46.003189: Pseudo dice [np.float32(0.8214), np.float32(0.6857), np.float32(0.8505)] 
2025-03-16 00:35:46.008207: Epoch time: 38.44 s 
2025-03-16 00:35:46.013221: Yayy! New best EMA pseudo Dice: 0.7856000065803528 
2025-03-16 00:35:46.726815:  
2025-03-16 00:35:46.732357: Epoch 53 
2025-03-16 00:35:46.736922: Current learning rate: 0.00507 
2025-03-16 00:36:25.175380: train_loss -0.7212 
2025-03-16 00:36:25.182463: val_loss -0.619 
2025-03-16 00:36:25.186590: Pseudo dice [np.float32(0.8217), np.float32(0.7019), np.float32(0.8472)] 
2025-03-16 00:36:25.189644: Epoch time: 38.45 s 
2025-03-16 00:36:25.192680: Yayy! New best EMA pseudo Dice: 0.7860999703407288 
2025-03-16 00:36:25.900336:  
2025-03-16 00:36:25.905347: Epoch 54 
2025-03-16 00:36:25.909859: Current learning rate: 0.00497 
2025-03-16 00:37:04.345099: train_loss -0.7155 
2025-03-16 00:37:04.351623: val_loss -0.6322 
2025-03-16 00:37:04.356635: Pseudo dice [np.float32(0.8201), np.float32(0.6756), np.float32(0.8747)] 
2025-03-16 00:37:04.360149: Epoch time: 38.45 s 
2025-03-16 00:37:04.365166: Yayy! New best EMA pseudo Dice: 0.7864999771118164 
2025-03-16 00:37:05.084339:  
2025-03-16 00:37:05.090377: Epoch 55 
2025-03-16 00:37:05.093902: Current learning rate: 0.00487 
2025-03-16 00:37:43.537383: train_loss -0.7046 
2025-03-16 00:37:43.542900: val_loss -0.6567 
2025-03-16 00:37:43.547911: Pseudo dice [np.float32(0.8235), np.float32(0.7357), np.float32(0.8605)] 
2025-03-16 00:37:43.552928: Epoch time: 38.45 s 
2025-03-16 00:37:43.557457: Yayy! New best EMA pseudo Dice: 0.7885000109672546 
2025-03-16 00:37:44.263288:  
2025-03-16 00:37:44.268799: Epoch 56 
2025-03-16 00:37:44.273309: Current learning rate: 0.00478 
2025-03-16 00:38:22.800924: train_loss -0.724 
2025-03-16 00:38:22.807381: val_loss -0.6366 
2025-03-16 00:38:22.812155: Pseudo dice [np.float32(0.8304), np.float32(0.6975), np.float32(0.8524)] 
2025-03-16 00:38:22.816171: Epoch time: 38.54 s 
2025-03-16 00:38:22.820687: Yayy! New best EMA pseudo Dice: 0.7889999747276306 
2025-03-16 00:38:23.547836:  
2025-03-16 00:38:23.552420: Epoch 57 
2025-03-16 00:38:23.556998: Current learning rate: 0.00468 
2025-03-16 00:39:01.980786: train_loss -0.7323 
2025-03-16 00:39:01.987333: val_loss -0.6596 
2025-03-16 00:39:01.992352: Pseudo dice [np.float32(0.8347), np.float32(0.6912), np.float32(0.8683)] 
2025-03-16 00:39:01.997364: Epoch time: 38.43 s 
2025-03-16 00:39:02.001376: Yayy! New best EMA pseudo Dice: 0.789900004863739 
2025-03-16 00:39:02.725507:  
2025-03-16 00:39:02.731627: Epoch 58 
2025-03-16 00:39:02.735260: Current learning rate: 0.00458 
2025-03-16 00:39:41.107973: train_loss -0.7289 
2025-03-16 00:39:41.113528: val_loss -0.665 
2025-03-16 00:39:41.117038: Pseudo dice [np.float32(0.8255), np.float32(0.7092), np.float32(0.8863)] 
2025-03-16 00:39:41.121054: Epoch time: 38.38 s 
2025-03-16 00:39:41.123560: Yayy! New best EMA pseudo Dice: 0.7915999889373779 
2025-03-16 00:39:41.834369:  
2025-03-16 00:39:41.840410: Epoch 59 
2025-03-16 00:39:41.843223: Current learning rate: 0.00448 
2025-03-16 00:40:20.248966: train_loss -0.7259 
2025-03-16 00:40:20.255067: val_loss -0.657 
2025-03-16 00:40:20.260185: Pseudo dice [np.float32(0.847), np.float32(0.6963), np.float32(0.8573)] 
2025-03-16 00:40:20.263288: Epoch time: 38.41 s 
2025-03-16 00:40:20.266829: Yayy! New best EMA pseudo Dice: 0.7925000190734863 
2025-03-16 00:40:21.124403:  
2025-03-16 00:40:21.129439: Epoch 60 
2025-03-16 00:40:21.133584: Current learning rate: 0.00438 
2025-03-16 00:40:59.517522: train_loss -0.7231 
2025-03-16 00:40:59.524057: val_loss -0.6079 
2025-03-16 00:40:59.528069: Pseudo dice [np.float32(0.8055), np.float32(0.7147), np.float32(0.8382)] 
2025-03-16 00:40:59.531577: Epoch time: 38.39 s 
2025-03-16 00:41:00.077830:  
2025-03-16 00:41:00.083386: Epoch 61 
2025-03-16 00:41:00.087965: Current learning rate: 0.00429 
2025-03-16 00:41:38.554121: train_loss -0.7296 
2025-03-16 00:41:38.560710: val_loss -0.6378 
2025-03-16 00:41:38.563556: Pseudo dice [np.float32(0.8146), np.float32(0.73), np.float32(0.8433)] 
2025-03-16 00:41:38.568584: Epoch time: 38.48 s 
2025-03-16 00:41:39.119286:  
2025-03-16 00:41:39.125344: Epoch 62 
2025-03-16 00:41:39.128854: Current learning rate: 0.00419 
2025-03-16 00:42:17.566201: train_loss -0.734 
2025-03-16 00:42:17.572779: val_loss -0.6423 
2025-03-16 00:42:17.577322: Pseudo dice [np.float32(0.8086), np.float32(0.7043), np.float32(0.8461)] 
2025-03-16 00:42:17.581468: Epoch time: 38.45 s 
2025-03-16 00:42:18.130505:  
2025-03-16 00:42:18.136142: Epoch 63 
2025-03-16 00:42:18.140155: Current learning rate: 0.00409 
2025-03-16 00:42:56.510632: train_loss -0.7337 
2025-03-16 00:42:56.515648: val_loss -0.6412 
2025-03-16 00:42:56.520665: Pseudo dice [np.float32(0.8352), np.float32(0.7085), np.float32(0.8491)] 
2025-03-16 00:42:56.525682: Epoch time: 38.38 s 
2025-03-16 00:42:57.083835:  
2025-03-16 00:42:57.089386: Epoch 64 
2025-03-16 00:42:57.092949: Current learning rate: 0.00399 
2025-03-16 00:43:35.600224: train_loss -0.7445 
2025-03-16 00:43:35.606836: val_loss -0.6714 
2025-03-16 00:43:35.609870: Pseudo dice [np.float32(0.8289), np.float32(0.7153), np.float32(0.8768)] 
2025-03-16 00:43:35.614930: Epoch time: 38.52 s 
2025-03-16 00:43:35.618493: Yayy! New best EMA pseudo Dice: 0.7936999797821045 
2025-03-16 00:43:36.349773:  
2025-03-16 00:43:36.355799: Epoch 65 
2025-03-16 00:43:36.359806: Current learning rate: 0.00389 
2025-03-16 00:44:14.782046: train_loss -0.7263 
2025-03-16 00:44:14.788063: val_loss -0.6291 
2025-03-16 00:44:14.792078: Pseudo dice [np.float32(0.8071), np.float32(0.6988), np.float32(0.8557)] 
2025-03-16 00:44:14.796086: Epoch time: 38.43 s 
2025-03-16 00:44:15.340651:  
2025-03-16 00:44:15.345731: Epoch 66 
2025-03-16 00:44:15.348781: Current learning rate: 0.00379 
2025-03-16 00:44:53.708545: train_loss -0.7201 
2025-03-16 00:44:53.715144: val_loss -0.6609 
2025-03-16 00:44:53.720207: Pseudo dice [np.float32(0.8275), np.float32(0.7401), np.float32(0.8637)] 
2025-03-16 00:44:53.724751: Epoch time: 38.37 s 
2025-03-16 00:44:53.729816: Yayy! New best EMA pseudo Dice: 0.7947999835014343 
2025-03-16 00:44:54.430252:  
2025-03-16 00:44:54.434794: Epoch 67 
2025-03-16 00:44:54.438443: Current learning rate: 0.00369 
2025-03-16 00:45:32.723867: train_loss -0.7418 
2025-03-16 00:45:32.729885: val_loss -0.6337 
2025-03-16 00:45:32.733395: Pseudo dice [np.float32(0.8353), np.float32(0.7046), np.float32(0.8561)] 
2025-03-16 00:45:32.737410: Epoch time: 38.29 s 
2025-03-16 00:45:32.742426: Yayy! New best EMA pseudo Dice: 0.795199990272522 
2025-03-16 00:45:33.602718:  
2025-03-16 00:45:33.608230: Epoch 68 
2025-03-16 00:45:33.611741: Current learning rate: 0.00359 
2025-03-16 00:46:11.970581: train_loss -0.7282 
2025-03-16 00:46:11.976156: val_loss -0.6491 
2025-03-16 00:46:11.980803: Pseudo dice [np.float32(0.8271), np.float32(0.6868), np.float32(0.8686)] 
2025-03-16 00:46:11.986009: Epoch time: 38.37 s 
2025-03-16 00:46:12.537288:  
2025-03-16 00:46:12.542860: Epoch 69 
2025-03-16 00:46:12.545407: Current learning rate: 0.00349 
2025-03-16 00:46:50.829533: train_loss -0.7344 
2025-03-16 00:46:50.836099: val_loss -0.6532 
2025-03-16 00:46:50.839617: Pseudo dice [np.float32(0.8214), np.float32(0.6492), np.float32(0.8579)] 
2025-03-16 00:46:50.844779: Epoch time: 38.29 s 
2025-03-16 00:46:51.436311:  
2025-03-16 00:46:51.441846: Epoch 70 
2025-03-16 00:46:51.444857: Current learning rate: 0.00338 
2025-03-16 00:47:29.775386: train_loss -0.7436 
2025-03-16 00:47:29.781017: val_loss -0.6436 
2025-03-16 00:47:29.784595: Pseudo dice [np.float32(0.8184), np.float32(0.7176), np.float32(0.8475)] 
2025-03-16 00:47:29.790193: Epoch time: 38.34 s 
2025-03-16 00:47:30.342711:  
2025-03-16 00:47:30.347761: Epoch 71 
2025-03-16 00:47:30.350740: Current learning rate: 0.00328 
2025-03-16 00:48:08.712157: train_loss -0.7433 
2025-03-16 00:48:08.718262: val_loss -0.6506 
2025-03-16 00:48:08.723380: Pseudo dice [np.float32(0.8318), np.float32(0.7394), np.float32(0.865)] 
2025-03-16 00:48:08.727515: Epoch time: 38.37 s 
2025-03-16 00:48:08.731552: Yayy! New best EMA pseudo Dice: 0.795199990272522 
2025-03-16 00:48:09.447220:  
2025-03-16 00:48:09.452780: Epoch 72 
2025-03-16 00:48:09.455864: Current learning rate: 0.00318 
2025-03-16 00:48:47.750071: train_loss -0.744 
2025-03-16 00:48:47.755586: val_loss -0.6592 
2025-03-16 00:48:47.760604: Pseudo dice [np.float32(0.8127), np.float32(0.7372), np.float32(0.8673)] 
2025-03-16 00:48:47.765114: Epoch time: 38.3 s 
2025-03-16 00:48:47.769165: Yayy! New best EMA pseudo Dice: 0.7962999939918518 
2025-03-16 00:48:48.480321:  
2025-03-16 00:48:48.485874: Epoch 73 
2025-03-16 00:48:48.488422: Current learning rate: 0.00308 
2025-03-16 00:49:26.807142: train_loss -0.747 
2025-03-16 00:49:26.813765: val_loss -0.6445 
2025-03-16 00:49:26.817492: Pseudo dice [np.float32(0.833), np.float32(0.7147), np.float32(0.8508)] 
2025-03-16 00:49:26.821509: Epoch time: 38.33 s 
2025-03-16 00:49:26.826530: Yayy! New best EMA pseudo Dice: 0.7965999841690063 
2025-03-16 00:49:27.537931:  
2025-03-16 00:49:27.543508: Epoch 74 
2025-03-16 00:49:27.547030: Current learning rate: 0.00297 
2025-03-16 00:50:05.892004: train_loss -0.7477 
2025-03-16 00:50:05.899612: val_loss -0.6587 
2025-03-16 00:50:05.904689: Pseudo dice [np.float32(0.8323), np.float32(0.7447), np.float32(0.8728)] 
2025-03-16 00:50:05.909883: Epoch time: 38.35 s 
2025-03-16 00:50:05.913965: Yayy! New best EMA pseudo Dice: 0.7986000180244446 
2025-03-16 00:50:06.625733:  
2025-03-16 00:50:06.631268: Epoch 75 
2025-03-16 00:50:06.634778: Current learning rate: 0.00287 
2025-03-16 00:50:45.021939: train_loss -0.7479 
2025-03-16 00:50:45.027468: val_loss -0.6544 
2025-03-16 00:50:45.032486: Pseudo dice [np.float32(0.8406), np.float32(0.7039), np.float32(0.8554)] 
2025-03-16 00:50:45.037505: Epoch time: 38.4 s 
2025-03-16 00:50:45.042024: Yayy! New best EMA pseudo Dice: 0.7986999750137329 
2025-03-16 00:50:45.926296:  
2025-03-16 00:50:45.932323: Epoch 76 
2025-03-16 00:50:45.935889: Current learning rate: 0.00277 
2025-03-16 00:51:24.277141: train_loss -0.7405 
2025-03-16 00:51:24.283224: val_loss -0.6558 
2025-03-16 00:51:24.286803: Pseudo dice [np.float32(0.8187), np.float32(0.7106), np.float32(0.8682)] 
2025-03-16 00:51:24.290333: Epoch time: 38.35 s 
2025-03-16 00:51:24.294375: Yayy! New best EMA pseudo Dice: 0.798799991607666 
2025-03-16 00:51:24.998172:  
2025-03-16 00:51:25.003783: Epoch 77 
2025-03-16 00:51:25.006330: Current learning rate: 0.00266 
2025-03-16 00:52:03.316090: train_loss -0.7475 
2025-03-16 00:52:03.323159: val_loss -0.6437 
2025-03-16 00:52:03.326192: Pseudo dice [np.float32(0.8366), np.float32(0.7143), np.float32(0.882)] 
2025-03-16 00:52:03.331205: Epoch time: 38.32 s 
2025-03-16 00:52:03.335218: Yayy! New best EMA pseudo Dice: 0.800000011920929 
2025-03-16 00:52:04.063685:  
2025-03-16 00:52:04.069227: Epoch 78 
2025-03-16 00:52:04.072339: Current learning rate: 0.00256 
2025-03-16 00:52:42.494832: train_loss -0.7417 
2025-03-16 00:52:42.501417: val_loss -0.6292 
2025-03-16 00:52:42.506473: Pseudo dice [np.float32(0.8236), np.float32(0.7042), np.float32(0.8498)] 
2025-03-16 00:52:42.511520: Epoch time: 38.43 s 
2025-03-16 00:52:43.068250:  
2025-03-16 00:52:43.073319: Epoch 79 
2025-03-16 00:52:43.077901: Current learning rate: 0.00245 
2025-03-16 00:53:21.343520: train_loss -0.7508 
2025-03-16 00:53:21.351068: val_loss -0.691 
2025-03-16 00:53:21.354590: Pseudo dice [np.float32(0.8424), np.float32(0.7707), np.float32(0.864)] 
2025-03-16 00:53:21.358619: Epoch time: 38.28 s 
2025-03-16 00:53:21.362640: Yayy! New best EMA pseudo Dice: 0.8019000291824341 
2025-03-16 00:53:22.088021:  
2025-03-16 00:53:22.094080: Epoch 80 
2025-03-16 00:53:22.098134: Current learning rate: 0.00235 
2025-03-16 00:54:00.444729: train_loss -0.7528 
2025-03-16 00:54:00.450263: val_loss -0.6331 
2025-03-16 00:54:00.454274: Pseudo dice [np.float32(0.8357), np.float32(0.6913), np.float32(0.8623)] 
2025-03-16 00:54:00.457786: Epoch time: 38.36 s 
2025-03-16 00:54:01.029458:  
2025-03-16 00:54:01.034581: Epoch 81 
2025-03-16 00:54:01.038136: Current learning rate: 0.00224 
2025-03-16 00:54:39.320191: train_loss -0.7538 
2025-03-16 00:54:39.326441: val_loss -0.6484 
2025-03-16 00:54:39.329852: Pseudo dice [np.float32(0.8274), np.float32(0.7204), np.float32(0.8783)] 
2025-03-16 00:54:39.333863: Epoch time: 38.29 s 
2025-03-16 00:54:39.338374: Yayy! New best EMA pseudo Dice: 0.8021000027656555 
2025-03-16 00:54:40.078957:  
2025-03-16 00:54:40.087025: Epoch 82 
2025-03-16 00:54:40.090060: Current learning rate: 0.00214 
2025-03-16 00:55:18.339305: train_loss -0.7498 
2025-03-16 00:55:18.345320: val_loss -0.6486 
2025-03-16 00:55:18.350332: Pseudo dice [np.float32(0.8361), np.float32(0.6886), np.float32(0.864)] 
2025-03-16 00:55:18.354337: Epoch time: 38.26 s 
2025-03-16 00:55:19.022111:  
2025-03-16 00:55:19.027725: Epoch 83 
2025-03-16 00:55:19.031794: Current learning rate: 0.00203 
2025-03-16 00:55:57.206703: train_loss -0.7488 
2025-03-16 00:55:57.213787: val_loss -0.6214 
2025-03-16 00:55:57.217812: Pseudo dice [np.float32(0.8179), np.float32(0.7017), np.float32(0.8653)] 
2025-03-16 00:55:57.221829: Epoch time: 38.18 s 
2025-03-16 00:55:57.751623:  
2025-03-16 00:55:57.757136: Epoch 84 
2025-03-16 00:55:57.760643: Current learning rate: 0.00192 
2025-03-16 00:56:36.083653: train_loss -0.745 
2025-03-16 00:56:36.088748: val_loss -0.645 
2025-03-16 00:56:36.093822: Pseudo dice [np.float32(0.8132), np.float32(0.7341), np.float32(0.8762)] 
2025-03-16 00:56:36.098467: Epoch time: 38.33 s 
2025-03-16 00:56:36.623955:  
2025-03-16 00:56:36.630063: Epoch 85 
2025-03-16 00:56:36.633131: Current learning rate: 0.00181 
2025-03-16 00:57:14.906497: train_loss -0.7558 
2025-03-16 00:57:14.912214: val_loss -0.6166 
2025-03-16 00:57:14.917261: Pseudo dice [np.float32(0.8224), np.float32(0.6919), np.float32(0.8484)] 
2025-03-16 00:57:14.923306: Epoch time: 38.28 s 
2025-03-16 00:57:15.446545:  
2025-03-16 00:57:15.451608: Epoch 86 
2025-03-16 00:57:15.454118: Current learning rate: 0.0017 
2025-03-16 00:57:53.810178: train_loss -0.7562 
2025-03-16 00:57:53.817242: val_loss -0.6334 
2025-03-16 00:57:53.821279: Pseudo dice [np.float32(0.8305), np.float32(0.7289), np.float32(0.8616)] 
2025-03-16 00:57:53.824802: Epoch time: 38.36 s 
2025-03-16 00:57:54.354538:  
2025-03-16 00:57:54.360585: Epoch 87 
2025-03-16 00:57:54.364097: Current learning rate: 0.00159 
2025-03-16 00:58:32.633264: train_loss -0.7551 
2025-03-16 00:58:32.639953: val_loss -0.6755 
2025-03-16 00:58:32.643011: Pseudo dice [np.float32(0.8363), np.float32(0.7454), np.float32(0.8768)] 
2025-03-16 00:58:32.648070: Epoch time: 38.28 s 
2025-03-16 00:58:32.653193: Yayy! New best EMA pseudo Dice: 0.8026999831199646 
2025-03-16 00:58:33.333081:  
2025-03-16 00:58:33.339100: Epoch 88 
2025-03-16 00:58:33.342616: Current learning rate: 0.00148 
2025-03-16 00:59:11.644233: train_loss -0.7398 
2025-03-16 00:59:11.650257: val_loss -0.65 
2025-03-16 00:59:11.655273: Pseudo dice [np.float32(0.8265), np.float32(0.7126), np.float32(0.8532)] 
2025-03-16 00:59:11.659295: Epoch time: 38.31 s 
2025-03-16 00:59:12.185897:  
2025-03-16 00:59:12.191974: Epoch 89 
2025-03-16 00:59:12.195065: Current learning rate: 0.00137 
2025-03-16 00:59:50.456045: train_loss -0.7567 
2025-03-16 00:59:50.462167: val_loss -0.6718 
2025-03-16 00:59:50.464188: Pseudo dice [np.float32(0.8416), np.float32(0.7634), np.float32(0.876)] 
2025-03-16 00:59:50.469251: Epoch time: 38.27 s 
2025-03-16 00:59:50.473847: Yayy! New best EMA pseudo Dice: 0.8047000169754028 
2025-03-16 00:59:51.160404:  
2025-03-16 00:59:51.166021: Epoch 90 
2025-03-16 00:59:51.170124: Current learning rate: 0.00126 
2025-03-16 01:00:29.462368: train_loss -0.7559 
2025-03-16 01:00:29.469889: val_loss -0.6414 
2025-03-16 01:00:29.473931: Pseudo dice [np.float32(0.8401), np.float32(0.6645), np.float32(0.8728)] 
2025-03-16 01:00:29.477542: Epoch time: 38.3 s 
2025-03-16 01:00:29.996771:  
2025-03-16 01:00:30.002812: Epoch 91 
2025-03-16 01:00:30.006336: Current learning rate: 0.00115 
2025-03-16 01:01:08.330859: train_loss -0.7396 
2025-03-16 01:01:08.340044: val_loss -0.6434 
2025-03-16 01:01:08.346643: Pseudo dice [np.float32(0.8077), np.float32(0.7622), np.float32(0.8694)] 
2025-03-16 01:01:08.350687: Epoch time: 38.33 s 
2025-03-16 01:01:09.026220:  
2025-03-16 01:01:09.032261: Epoch 92 
2025-03-16 01:01:09.035777: Current learning rate: 0.00103 
2025-03-16 01:01:47.209468: train_loss -0.7606 
2025-03-16 01:01:47.214119: val_loss -0.664 
2025-03-16 01:01:47.218554: Pseudo dice [np.float32(0.8202), np.float32(0.746), np.float32(0.8904)] 
2025-03-16 01:01:47.222597: Epoch time: 38.18 s 
2025-03-16 01:01:47.227613: Yayy! New best EMA pseudo Dice: 0.8058000206947327 
2025-03-16 01:01:47.914647:  
2025-03-16 01:01:47.920166: Epoch 93 
2025-03-16 01:01:47.923681: Current learning rate: 0.00091 
2025-03-16 01:02:26.269789: train_loss -0.7547 
2025-03-16 01:02:26.276305: val_loss -0.6359 
2025-03-16 01:02:26.280316: Pseudo dice [np.float32(0.819), np.float32(0.7361), np.float32(0.861)] 
2025-03-16 01:02:26.285328: Epoch time: 38.36 s 
2025-03-16 01:02:26.817369:  
2025-03-16 01:02:26.822449: Epoch 94 
2025-03-16 01:02:26.825474: Current learning rate: 0.00079 
2025-03-16 01:03:05.127869: train_loss -0.7652 
2025-03-16 01:03:05.134503: val_loss -0.6638 
2025-03-16 01:03:05.139052: Pseudo dice [np.float32(0.8361), np.float32(0.7257), np.float32(0.8732)] 
2025-03-16 01:03:05.142597: Epoch time: 38.31 s 
2025-03-16 01:03:05.149153: Yayy! New best EMA pseudo Dice: 0.8064000010490417 
2025-03-16 01:03:05.832572:  
2025-03-16 01:03:05.837582: Epoch 95 
2025-03-16 01:03:05.841095: Current learning rate: 0.00067 
2025-03-16 01:03:44.152500: train_loss -0.7608 
2025-03-16 01:03:44.159709: val_loss -0.6259 
2025-03-16 01:03:44.162762: Pseudo dice [np.float32(0.831), np.float32(0.6735), np.float32(0.8532)] 
2025-03-16 01:03:44.166344: Epoch time: 38.32 s 
2025-03-16 01:03:44.699286:  
2025-03-16 01:03:44.705381: Epoch 96 
2025-03-16 01:03:44.707933: Current learning rate: 0.00055 
2025-03-16 01:04:22.992298: train_loss -0.7604 
2025-03-16 01:04:22.998400: val_loss -0.6678 
2025-03-16 01:04:23.002573: Pseudo dice [np.float32(0.8192), np.float32(0.7294), np.float32(0.8627)] 
2025-03-16 01:04:23.006142: Epoch time: 38.29 s 
2025-03-16 01:04:23.536652:  
2025-03-16 01:04:23.542677: Epoch 97 
2025-03-16 01:04:23.545187: Current learning rate: 0.00043 
2025-03-16 01:05:01.847829: train_loss -0.7659 
2025-03-16 01:05:01.854940: val_loss -0.6337 
2025-03-16 01:05:01.858451: Pseudo dice [np.float32(0.8357), np.float32(0.6943), np.float32(0.8781)] 
2025-03-16 01:05:01.861959: Epoch time: 38.31 s 
2025-03-16 01:05:02.407161:  
2025-03-16 01:05:02.412674: Epoch 98 
2025-03-16 01:05:02.415180: Current learning rate: 0.0003 
2025-03-16 01:05:40.670618: train_loss -0.7623 
2025-03-16 01:05:40.677280: val_loss -0.6346 
2025-03-16 01:05:40.681359: Pseudo dice [np.float32(0.8238), np.float32(0.7009), np.float32(0.8626)] 
2025-03-16 01:05:40.684397: Epoch time: 38.26 s 
2025-03-16 01:05:41.248564:  
2025-03-16 01:05:41.252111: Epoch 99 
2025-03-16 01:05:41.256273: Current learning rate: 0.00016 
2025-03-16 01:06:19.546682: train_loss -0.7615 
2025-03-16 01:06:19.553716: val_loss -0.6663 
2025-03-16 01:06:19.558292: Pseudo dice [np.float32(0.837), np.float32(0.7162), np.float32(0.8726)] 
2025-03-16 01:06:19.563307: Epoch time: 38.3 s 
2025-03-16 01:06:20.443385: Training done. 
2025-03-16 01:06:20.482894: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-16 01:06:20.494893: The split file contains 5 splits. 
2025-03-16 01:06:20.501894: Desired fold for training: 0 
2025-03-16 01:06:20.508893: This split has 387 training and 97 validation cases. 
2025-03-16 01:06:20.514893: predicting BRATS_010 
2025-03-16 01:06:20.521894: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2025-03-16 01:06:22.492901: predicting BRATS_011 
2025-03-16 01:06:22.504902: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2025-03-16 01:06:23.794770: predicting BRATS_012 
2025-03-16 01:06:23.804768: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-16 01:06:25.096632: predicting BRATS_018 
2025-03-16 01:06:25.107632: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2025-03-16 01:06:26.403797: predicting BRATS_020 
2025-03-16 01:06:26.414798: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2025-03-16 01:06:27.709184: predicting BRATS_028 
2025-03-16 01:06:27.721184: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-03-16 01:06:29.014071: predicting BRATS_029 
2025-03-16 01:06:29.027071: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-03-16 01:06:30.326111: predicting BRATS_032 
2025-03-16 01:06:30.340111: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2025-03-16 01:06:31.639005: predicting BRATS_034 
2025-03-16 01:06:31.652007: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2025-03-16 01:06:32.950831: predicting BRATS_041 
2025-03-16 01:06:32.963339: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2025-03-16 01:06:34.263334: predicting BRATS_042 
2025-03-16 01:06:34.276335: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2025-03-16 01:06:35.570956: predicting BRATS_047 
2025-03-16 01:06:35.582955: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-16 01:06:36.876210: predicting BRATS_049 
2025-03-16 01:06:36.890211: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-16 01:06:38.188247: predicting BRATS_053 
2025-03-16 01:06:38.201247: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-16 01:06:39.493761: predicting BRATS_056 
2025-03-16 01:06:39.505760: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-16 01:06:40.797265: predicting BRATS_057 
2025-03-16 01:06:40.810266: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-16 01:06:42.102613: predicting BRATS_067 
2025-03-16 01:06:42.114613: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-16 01:06:43.408833: predicting BRATS_069 
2025-03-16 01:06:43.420834: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-16 01:06:44.718721: predicting BRATS_085 
2025-03-16 01:06:44.730721: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2025-03-16 01:06:45.402554: predicting BRATS_086 
2025-03-16 01:06:45.414553: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2025-03-16 01:06:46.714357: predicting BRATS_088 
2025-03-16 01:06:46.728357: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2025-03-16 01:06:48.022879: predicting BRATS_091 
2025-03-16 01:06:48.035879: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-03-16 01:06:49.329948: predicting BRATS_098 
2025-03-16 01:06:49.342942: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2025-03-16 01:06:50.637873: predicting BRATS_100 
2025-03-16 01:06:50.650873: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-16 01:06:51.316058: predicting BRATS_101 
2025-03-16 01:06:51.329057: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-16 01:06:51.994854: predicting BRATS_102 
2025-03-16 01:06:52.006854: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2025-03-16 01:06:53.301811: predicting BRATS_104 
2025-03-16 01:06:53.315811: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2025-03-16 01:06:54.612155: predicting BRATS_111 
2025-03-16 01:06:54.625156: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2025-03-16 01:06:55.919541: predicting BRATS_116 
2025-03-16 01:06:55.932541: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2025-03-16 01:06:57.228002: predicting BRATS_135 
2025-03-16 01:06:57.241003: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-03-16 01:06:58.536720: predicting BRATS_136 
2025-03-16 01:06:58.550720: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-03-16 01:06:59.846057: predicting BRATS_138 
2025-03-16 01:06:59.859059: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2025-03-16 01:07:01.155893: predicting BRATS_145 
2025-03-16 01:07:01.168895: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2025-03-16 01:07:02.464586: predicting BRATS_149 
2025-03-16 01:07:02.477092: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2025-03-16 01:07:03.773557: predicting BRATS_155 
2025-03-16 01:07:03.787063: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-16 01:07:05.081548: predicting BRATS_157 
2025-03-16 01:07:05.095548: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-16 01:07:06.396916: predicting BRATS_158 
2025-03-16 01:07:06.410915: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-16 01:07:07.705391: predicting BRATS_159 
2025-03-16 01:07:07.718392: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-16 01:07:09.012619: predicting BRATS_163 
2025-03-16 01:07:09.025618: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-03-16 01:07:10.319775: predicting BRATS_164 
2025-03-16 01:07:10.332777: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2025-03-16 01:07:11.623654: predicting BRATS_169 
2025-03-16 01:07:11.639654: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2025-03-16 01:07:12.935540: predicting BRATS_176 
2025-03-16 01:07:12.949539: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-03-16 01:07:14.243824: predicting BRATS_181 
2025-03-16 01:07:14.256824: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2025-03-16 01:07:15.553985: predicting BRATS_183 
2025-03-16 01:07:15.567991: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-16 01:07:16.863043: predicting BRATS_184 
2025-03-16 01:07:16.877045: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-16 01:07:18.175544: predicting BRATS_187 
2025-03-16 01:07:18.187778: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-16 01:07:19.486425: predicting BRATS_192 
2025-03-16 01:07:19.500424: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2025-03-16 01:07:20.793414: predicting BRATS_198 
2025-03-16 01:07:20.806415: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-03-16 01:07:22.106752: predicting BRATS_207 
2025-03-16 01:07:22.122753: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-16 01:07:23.418473: predicting BRATS_208 
2025-03-16 01:07:23.431474: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-16 01:07:24.725749: predicting BRATS_218 
2025-03-16 01:07:24.737748: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-03-16 01:07:26.036327: predicting BRATS_220 
2025-03-16 01:07:26.050326: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2025-03-16 01:07:27.348378: predicting BRATS_224 
2025-03-16 01:07:27.361377: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2025-03-16 01:07:28.657253: predicting BRATS_230 
2025-03-16 01:07:28.670254: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2025-03-16 01:07:29.985073: predicting BRATS_271 
2025-03-16 01:07:29.998190: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2025-03-16 01:07:31.293201: predicting BRATS_282 
2025-03-16 01:07:31.307202: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2025-03-16 01:07:32.606412: predicting BRATS_284 
2025-03-16 01:07:32.619411: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2025-03-16 01:07:33.912416: predicting BRATS_287 
2025-03-16 01:07:33.924416: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-16 01:07:35.218878: predicting BRATS_290 
2025-03-16 01:07:35.231879: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2025-03-16 01:07:36.528758: predicting BRATS_291 
2025-03-16 01:07:36.541754: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-03-16 01:07:37.838736: predicting BRATS_292 
2025-03-16 01:07:37.851737: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2025-03-16 01:07:39.147779: predicting BRATS_293 
2025-03-16 01:07:39.159779: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2025-03-16 01:07:40.484253: predicting BRATS_300 
2025-03-16 01:07:40.499759: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2025-03-16 01:07:41.797951: predicting BRATS_305 
2025-03-16 01:07:41.811005: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2025-03-16 01:07:43.111809: predicting BRATS_311 
2025-03-16 01:07:43.125809: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2025-03-16 01:07:44.427090: predicting BRATS_314 
2025-03-16 01:07:44.441091: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2025-03-16 01:07:45.739012: predicting BRATS_321 
2025-03-16 01:07:45.754012: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-03-16 01:07:47.061774: predicting BRATS_328 
2025-03-16 01:07:47.074774: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2025-03-16 01:07:47.767699: predicting BRATS_329 
2025-03-16 01:07:47.779700: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2025-03-16 01:07:49.103385: predicting BRATS_335 
2025-03-16 01:07:49.116385: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2025-03-16 01:07:50.422484: predicting BRATS_343 
2025-03-16 01:07:50.436483: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2025-03-16 01:07:51.758869: predicting BRATS_350 
2025-03-16 01:07:51.773871: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2025-03-16 01:07:52.451952: predicting BRATS_351 
2025-03-16 01:07:52.463953: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2025-03-16 01:07:53.144558: predicting BRATS_356 
2025-03-16 01:07:53.156558: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2025-03-16 01:07:53.826452: predicting BRATS_366 
2025-03-16 01:07:53.839454: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2025-03-16 01:07:55.135153: predicting BRATS_367 
2025-03-16 01:07:55.148155: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2025-03-16 01:07:56.448157: predicting BRATS_374 
2025-03-16 01:07:56.461157: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2025-03-16 01:07:57.759567: predicting BRATS_376 
2025-03-16 01:07:57.772566: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2025-03-16 01:07:59.066853: predicting BRATS_377 
2025-03-16 01:07:59.079853: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2025-03-16 01:08:00.376228: predicting BRATS_378 
2025-03-16 01:08:00.390228: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2025-03-16 01:08:01.688918: predicting BRATS_379 
2025-03-16 01:08:01.701922: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2025-03-16 01:08:03.003049: predicting BRATS_384 
2025-03-16 01:08:03.016562: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2025-03-16 01:08:04.311001: predicting BRATS_386 
2025-03-16 01:08:04.324511: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-03-16 01:08:05.621618: predicting BRATS_394 
2025-03-16 01:08:05.634617: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-16 01:08:06.929524: predicting BRATS_398 
2025-03-16 01:08:06.942525: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2025-03-16 01:08:08.241160: predicting BRATS_400 
2025-03-16 01:08:08.254161: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2025-03-16 01:08:09.554075: predicting BRATS_432 
2025-03-16 01:08:09.568075: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2025-03-16 01:08:10.865077: predicting BRATS_437 
2025-03-16 01:08:10.878077: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-16 01:08:12.173904: predicting BRATS_445 
2025-03-16 01:08:12.188904: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2025-03-16 01:08:13.485249: predicting BRATS_446 
2025-03-16 01:08:13.498249: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-03-16 01:08:14.794000: predicting BRATS_450 
2025-03-16 01:08:14.807004: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2025-03-16 01:08:16.102375: predicting BRATS_452 
2025-03-16 01:08:16.114377: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2025-03-16 01:08:17.410077: predicting BRATS_460 
2025-03-16 01:08:17.423588: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2025-03-16 01:08:18.718998: predicting BRATS_470 
2025-03-16 01:08:18.734001: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-03-16 01:08:20.029407: predicting BRATS_472 
2025-03-16 01:08:20.041406: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2025-03-16 01:08:21.352652: predicting BRATS_473 
2025-03-16 01:08:21.364654: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2025-03-16 01:08:22.036610: predicting BRATS_482 
2025-03-16 01:08:22.048613: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2025-03-16 01:08:30.308042: Validation complete 
2025-03-16 01:08:30.314046: Mean Validation Dice:  0.7252197075460827 
