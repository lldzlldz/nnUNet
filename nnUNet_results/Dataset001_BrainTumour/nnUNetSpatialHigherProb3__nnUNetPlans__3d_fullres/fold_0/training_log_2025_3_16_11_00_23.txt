
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-16 11:00:23.885789: do_dummy_2d_data_aug: False 
2025-03-16 11:00:23.912181: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-16 11:00:23.920182: The split file contains 5 splits. 
2025-03-16 11:00:23.923181: Desired fold for training: 0 
2025-03-16 11:00:23.925182: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2025-03-16 11:00:55.133022: unpacking dataset... 
2025-03-16 11:00:55.777701: unpacking done... 
2025-03-16 11:00:59.406773:  
2025-03-16 11:00:59.411786: Epoch 0 
2025-03-16 11:00:59.415290: Current learning rate: 0.01 
2025-03-16 11:01:41.743893: train_loss -0.26 
2025-03-16 11:01:41.751501: val_loss -0.403 
2025-03-16 11:01:41.757132: Pseudo dice [np.float32(0.605), np.float32(0.5051), np.float32(0.7524)] 
2025-03-16 11:01:41.761743: Epoch time: 42.34 s 
2025-03-16 11:01:41.766134: Yayy! New best EMA pseudo Dice: 0.6208000183105469 
2025-03-16 11:01:42.396064:  
2025-03-16 11:01:42.401586: Epoch 1 
2025-03-16 11:01:42.405602: Current learning rate: 0.00991 
2025-03-16 11:02:20.996588: train_loss -0.4762 
2025-03-16 11:02:21.003103: val_loss -0.4565 
2025-03-16 11:02:21.009125: Pseudo dice [np.float32(0.6913), np.float32(0.5533), np.float32(0.7698)] 
2025-03-16 11:02:21.014138: Epoch time: 38.6 s 
2025-03-16 11:02:21.018146: Yayy! New best EMA pseudo Dice: 0.6258999705314636 
2025-03-16 11:02:21.707340:  
2025-03-16 11:02:21.712471: Epoch 2 
2025-03-16 11:02:21.717189: Current learning rate: 0.00982 
2025-03-16 11:03:00.364511: train_loss -0.5433 
2025-03-16 11:03:00.371085: val_loss -0.4999 
2025-03-16 11:03:00.376632: Pseudo dice [np.float32(0.7531), np.float32(0.5422), np.float32(0.7873)] 
2025-03-16 11:03:00.381291: Epoch time: 38.66 s 
2025-03-16 11:03:00.385807: Yayy! New best EMA pseudo Dice: 0.6327000260353088 
2025-03-16 11:03:01.116802:  
2025-03-16 11:03:01.121845: Epoch 3 
2025-03-16 11:03:01.125437: Current learning rate: 0.00973 
2025-03-16 11:03:39.678967: train_loss -0.5608 
2025-03-16 11:03:39.686087: val_loss -0.5298 
2025-03-16 11:03:39.689644: Pseudo dice [np.float32(0.7377), np.float32(0.6082), np.float32(0.7635)] 
2025-03-16 11:03:39.691812: Epoch time: 38.56 s 
2025-03-16 11:03:39.696401: Yayy! New best EMA pseudo Dice: 0.6398000121116638 
2025-03-16 11:03:40.397998:  
2025-03-16 11:03:40.401062: Epoch 4 
2025-03-16 11:03:40.405614: Current learning rate: 0.00964 
2025-03-16 11:04:18.985336: train_loss -0.5798 
2025-03-16 11:04:18.992351: val_loss -0.5224 
2025-03-16 11:04:18.996368: Pseudo dice [np.float32(0.7609), np.float32(0.6261), np.float32(0.7788)] 
2025-03-16 11:04:18.998875: Epoch time: 38.59 s 
2025-03-16 11:04:19.002887: Yayy! New best EMA pseudo Dice: 0.6480000019073486 
2025-03-16 11:04:19.837514:  
2025-03-16 11:04:19.842525: Epoch 5 
2025-03-16 11:04:19.845537: Current learning rate: 0.00955 
2025-03-16 11:04:58.297992: train_loss -0.5731 
2025-03-16 11:04:58.305044: val_loss -0.5455 
2025-03-16 11:04:58.311062: Pseudo dice [np.float32(0.7602), np.float32(0.5911), np.float32(0.8086)] 
2025-03-16 11:04:58.317076: Epoch time: 38.46 s 
2025-03-16 11:04:58.322091: Yayy! New best EMA pseudo Dice: 0.6552000045776367 
2025-03-16 11:04:59.013611:  
2025-03-16 11:04:59.018622: Epoch 6 
2025-03-16 11:04:59.021634: Current learning rate: 0.00946 
2025-03-16 11:05:37.662126: train_loss -0.6032 
2025-03-16 11:05:37.669145: val_loss -0.572 
2025-03-16 11:05:37.672156: Pseudo dice [np.float32(0.7822), np.float32(0.6268), np.float32(0.8408)] 
2025-03-16 11:05:37.676666: Epoch time: 38.65 s 
2025-03-16 11:05:37.680678: Yayy! New best EMA pseudo Dice: 0.6646999716758728 
2025-03-16 11:05:38.386677:  
2025-03-16 11:05:38.390711: Epoch 7 
2025-03-16 11:05:38.395278: Current learning rate: 0.00937 
2025-03-16 11:06:17.175890: train_loss -0.6071 
2025-03-16 11:06:17.183405: val_loss -0.5692 
2025-03-16 11:06:17.186917: Pseudo dice [np.float32(0.7824), np.float32(0.6466), np.float32(0.8318)] 
2025-03-16 11:06:17.189929: Epoch time: 38.79 s 
2025-03-16 11:06:17.194944: Yayy! New best EMA pseudo Dice: 0.6736000180244446 
2025-03-16 11:06:17.897992:  
2025-03-16 11:06:17.904007: Epoch 8 
2025-03-16 11:06:17.907515: Current learning rate: 0.00928 
2025-03-16 11:06:56.375343: train_loss -0.6166 
2025-03-16 11:06:56.382387: val_loss -0.5777 
2025-03-16 11:06:56.386417: Pseudo dice [np.float32(0.7787), np.float32(0.6284), np.float32(0.8289)] 
2025-03-16 11:06:56.390430: Epoch time: 38.48 s 
2025-03-16 11:06:56.392937: Yayy! New best EMA pseudo Dice: 0.6807000041007996 
2025-03-16 11:06:57.122205:  
2025-03-16 11:06:57.126765: Epoch 9 
2025-03-16 11:06:57.131337: Current learning rate: 0.00919 
2025-03-16 11:07:35.630025: train_loss -0.6215 
2025-03-16 11:07:35.637630: val_loss -0.5762 
2025-03-16 11:07:35.642694: Pseudo dice [np.float32(0.8011), np.float32(0.6243), np.float32(0.8329)] 
2025-03-16 11:07:35.646253: Epoch time: 38.51 s 
2025-03-16 11:07:35.649836: Yayy! New best EMA pseudo Dice: 0.6879000067710876 
2025-03-16 11:07:36.335737:  
2025-03-16 11:07:36.341262: Epoch 10 
2025-03-16 11:07:36.344827: Current learning rate: 0.0091 
2025-03-16 11:08:14.844067: train_loss -0.6113 
2025-03-16 11:08:14.850831: val_loss -0.5604 
2025-03-16 11:08:14.857353: Pseudo dice [np.float32(0.7847), np.float32(0.6312), np.float32(0.7811)] 
2025-03-16 11:08:14.860866: Epoch time: 38.51 s 
2025-03-16 11:08:14.865564: Yayy! New best EMA pseudo Dice: 0.6923999786376953 
2025-03-16 11:08:15.559265:  
2025-03-16 11:08:15.565286: Epoch 11 
2025-03-16 11:08:15.569313: Current learning rate: 0.009 
2025-03-16 11:08:54.095413: train_loss -0.6358 
2025-03-16 11:08:54.101474: val_loss -0.578 
2025-03-16 11:08:54.104418: Pseudo dice [np.float32(0.7816), np.float32(0.6289), np.float32(0.8042)] 
2025-03-16 11:08:54.107934: Epoch time: 38.54 s 
2025-03-16 11:08:54.111953: Yayy! New best EMA pseudo Dice: 0.6970000267028809 
2025-03-16 11:08:54.810657:  
2025-03-16 11:08:54.816686: Epoch 12 
2025-03-16 11:08:54.820202: Current learning rate: 0.00891 
2025-03-16 11:09:33.444695: train_loss -0.6424 
2025-03-16 11:09:33.452262: val_loss -0.59 
2025-03-16 11:09:33.455302: Pseudo dice [np.float32(0.8012), np.float32(0.6292), np.float32(0.8411)] 
2025-03-16 11:09:33.459844: Epoch time: 38.63 s 
2025-03-16 11:09:33.464863: Yayy! New best EMA pseudo Dice: 0.703000009059906 
2025-03-16 11:09:34.182235:  
2025-03-16 11:09:34.187342: Epoch 13 
2025-03-16 11:09:34.190897: Current learning rate: 0.00882 
2025-03-16 11:10:12.616467: train_loss -0.6217 
2025-03-16 11:10:12.623113: val_loss -0.5633 
2025-03-16 11:10:12.626664: Pseudo dice [np.float32(0.7641), np.float32(0.6332), np.float32(0.8338)] 
2025-03-16 11:10:12.631242: Epoch time: 38.43 s 
2025-03-16 11:10:12.635790: Yayy! New best EMA pseudo Dice: 0.7070000171661377 
2025-03-16 11:10:13.332667:  
2025-03-16 11:10:13.338181: Epoch 14 
2025-03-16 11:10:13.341691: Current learning rate: 0.00873 
2025-03-16 11:10:51.782995: train_loss -0.6416 
2025-03-16 11:10:51.790048: val_loss -0.5882 
2025-03-16 11:10:51.793666: Pseudo dice [np.float32(0.7831), np.float32(0.6569), np.float32(0.8334)] 
2025-03-16 11:10:51.798212: Epoch time: 38.45 s 
2025-03-16 11:10:51.802788: Yayy! New best EMA pseudo Dice: 0.7121000289916992 
2025-03-16 11:10:52.526167:  
2025-03-16 11:10:52.531180: Epoch 15 
2025-03-16 11:10:52.535194: Current learning rate: 0.00864 
2025-03-16 11:11:30.899483: train_loss -0.653 
2025-03-16 11:11:30.906564: val_loss -0.6272 
2025-03-16 11:11:30.911073: Pseudo dice [np.float32(0.8042), np.float32(0.6779), np.float32(0.855)] 
2025-03-16 11:11:30.914079: Epoch time: 38.37 s 
2025-03-16 11:11:30.917588: Yayy! New best EMA pseudo Dice: 0.7188000082969666 
2025-03-16 11:11:31.627151:  
2025-03-16 11:11:31.632770: Epoch 16 
2025-03-16 11:11:31.637336: Current learning rate: 0.00855 
2025-03-16 11:12:09.939493: train_loss -0.6461 
2025-03-16 11:12:09.945536: val_loss -0.5997 
2025-03-16 11:12:09.950549: Pseudo dice [np.float32(0.795), np.float32(0.6494), np.float32(0.8112)] 
2025-03-16 11:12:09.955562: Epoch time: 38.31 s 
2025-03-16 11:12:09.959573: Yayy! New best EMA pseudo Dice: 0.722100019454956 
2025-03-16 11:12:10.686164:  
2025-03-16 11:12:10.691868: Epoch 17 
2025-03-16 11:12:10.695398: Current learning rate: 0.00846 
2025-03-16 11:12:49.027866: train_loss -0.6489 
2025-03-16 11:12:49.035382: val_loss -0.6111 
2025-03-16 11:12:49.038896: Pseudo dice [np.float32(0.7946), np.float32(0.6545), np.float32(0.855)] 
2025-03-16 11:12:49.042904: Epoch time: 38.34 s 
2025-03-16 11:12:49.047418: Yayy! New best EMA pseudo Dice: 0.7267000079154968 
2025-03-16 11:12:49.792772:  
2025-03-16 11:12:49.798782: Epoch 18 
2025-03-16 11:12:49.801798: Current learning rate: 0.00836 
2025-03-16 11:13:32.547759: train_loss -0.6616 
2025-03-16 11:13:32.553774: val_loss -0.5936 
2025-03-16 11:13:32.557786: Pseudo dice [np.float32(0.7831), np.float32(0.673), np.float32(0.847)] 
2025-03-16 11:13:32.562798: Epoch time: 42.75 s 
2025-03-16 11:13:32.567809: Yayy! New best EMA pseudo Dice: 0.7307999730110168 
2025-03-16 11:13:33.309055:  
2025-03-16 11:13:33.314065: Epoch 19 
2025-03-16 11:13:33.317576: Current learning rate: 0.00827 
2025-03-16 11:14:12.754504: train_loss -0.6563 
2025-03-16 11:14:12.760854: val_loss -0.6251 
2025-03-16 11:14:12.765474: Pseudo dice [np.float32(0.7983), np.float32(0.7149), np.float32(0.8419)] 
2025-03-16 11:14:12.768991: Epoch time: 39.45 s 
2025-03-16 11:14:12.772214: Yayy! New best EMA pseudo Dice: 0.7361999750137329 
2025-03-16 11:14:13.684754:  
2025-03-16 11:14:13.690879: Epoch 20 
2025-03-16 11:14:13.695016: Current learning rate: 0.00818 
2025-03-16 11:14:54.081076: train_loss -0.6522 
2025-03-16 11:14:54.087590: val_loss -0.6305 
2025-03-16 11:14:54.091100: Pseudo dice [np.float32(0.8158), np.float32(0.6977), np.float32(0.8417)] 
2025-03-16 11:14:54.095110: Epoch time: 40.4 s 
2025-03-16 11:14:54.098619: Yayy! New best EMA pseudo Dice: 0.741100013256073 
2025-03-16 11:14:54.869723:  
2025-03-16 11:14:54.875737: Epoch 21 
2025-03-16 11:14:54.879248: Current learning rate: 0.00809 
2025-03-16 11:15:33.785850: train_loss -0.6593 
2025-03-16 11:15:33.793019: val_loss -0.5865 
2025-03-16 11:15:33.796050: Pseudo dice [np.float32(0.7721), np.float32(0.634), np.float32(0.8235)] 
2025-03-16 11:15:33.799574: Epoch time: 38.92 s 
2025-03-16 11:15:33.802356: Yayy! New best EMA pseudo Dice: 0.7412999868392944 
2025-03-16 11:15:34.535027:  
2025-03-16 11:15:34.540593: Epoch 22 
2025-03-16 11:15:34.544640: Current learning rate: 0.008 
2025-03-16 11:16:13.220323: train_loss -0.6672 
2025-03-16 11:16:13.225924: val_loss -0.633 
2025-03-16 11:16:13.231006: Pseudo dice [np.float32(0.8232), np.float32(0.6728), np.float32(0.8532)] 
2025-03-16 11:16:13.233568: Epoch time: 38.69 s 
2025-03-16 11:16:13.237625: Yayy! New best EMA pseudo Dice: 0.7455000281333923 
2025-03-16 11:16:13.994976:  
2025-03-16 11:16:14.001516: Epoch 23 
2025-03-16 11:16:14.004024: Current learning rate: 0.0079 
2025-03-16 11:16:52.533677: train_loss -0.6818 
2025-03-16 11:16:52.541193: val_loss -0.565 
2025-03-16 11:16:52.544703: Pseudo dice [np.float32(0.7875), np.float32(0.6405), np.float32(0.7988)] 
2025-03-16 11:16:52.547210: Epoch time: 38.54 s 
2025-03-16 11:16:53.117201:  
2025-03-16 11:16:53.122772: Epoch 24 
2025-03-16 11:16:53.126824: Current learning rate: 0.00781 
2025-03-16 11:17:31.585712: train_loss -0.6636 
2025-03-16 11:17:31.592299: val_loss -0.6176 
2025-03-16 11:17:31.595811: Pseudo dice [np.float32(0.8168), np.float32(0.6992), np.float32(0.8419)] 
2025-03-16 11:17:31.599317: Epoch time: 38.47 s 
2025-03-16 11:17:31.602345: Yayy! New best EMA pseudo Dice: 0.7493000030517578 
2025-03-16 11:17:32.344168:  
2025-03-16 11:17:32.350207: Epoch 25 
2025-03-16 11:17:32.353223: Current learning rate: 0.00772 
2025-03-16 11:18:10.809588: train_loss -0.6758 
2025-03-16 11:18:10.816237: val_loss -0.6044 
2025-03-16 11:18:10.819788: Pseudo dice [np.float32(0.8159), np.float32(0.7167), np.float32(0.8166)] 
2025-03-16 11:18:10.823825: Epoch time: 38.47 s 
2025-03-16 11:18:10.827371: Yayy! New best EMA pseudo Dice: 0.7526000142097473 
2025-03-16 11:18:11.573456:  
2025-03-16 11:18:11.579542: Epoch 26 
2025-03-16 11:18:11.582660: Current learning rate: 0.00763 
2025-03-16 11:18:50.561661: train_loss -0.6786 
2025-03-16 11:18:50.567774: val_loss -0.63 
2025-03-16 11:18:50.571366: Pseudo dice [np.float32(0.7994), np.float32(0.7099), np.float32(0.8423)] 
2025-03-16 11:18:50.575414: Epoch time: 38.99 s 
2025-03-16 11:18:50.578446: Yayy! New best EMA pseudo Dice: 0.7558000087738037 
2025-03-16 11:18:51.322182:  
2025-03-16 11:18:51.327191: Epoch 27 
2025-03-16 11:18:51.331199: Current learning rate: 0.00753 
2025-03-16 11:19:30.255818: train_loss -0.6907 
2025-03-16 11:19:30.262336: val_loss -0.6455 
2025-03-16 11:19:30.265846: Pseudo dice [np.float32(0.813), np.float32(0.6905), np.float32(0.8553)] 
2025-03-16 11:19:30.269351: Epoch time: 38.93 s 
2025-03-16 11:19:30.272359: Yayy! New best EMA pseudo Dice: 0.7588000297546387 
2025-03-16 11:19:31.207339:  
2025-03-16 11:19:31.213419: Epoch 28 
2025-03-16 11:19:31.215950: Current learning rate: 0.00744 
2025-03-16 11:20:09.614940: train_loss -0.6885 
2025-03-16 11:20:09.621503: val_loss -0.6395 
2025-03-16 11:20:09.624534: Pseudo dice [np.float32(0.8376), np.float32(0.7009), np.float32(0.8539)] 
2025-03-16 11:20:09.628056: Epoch time: 38.41 s 
2025-03-16 11:20:09.631581: Yayy! New best EMA pseudo Dice: 0.7627000212669373 
2025-03-16 11:20:10.377447:  
2025-03-16 11:20:10.382486: Epoch 29 
2025-03-16 11:20:10.386005: Current learning rate: 0.00735 
2025-03-16 11:20:48.783511: train_loss -0.6823 
2025-03-16 11:20:48.791576: val_loss -0.6334 
2025-03-16 11:20:48.794609: Pseudo dice [np.float32(0.8124), np.float32(0.6839), np.float32(0.8504)] 
2025-03-16 11:20:48.798131: Epoch time: 38.41 s 
2025-03-16 11:20:48.801658: Yayy! New best EMA pseudo Dice: 0.7645999789237976 
2025-03-16 11:20:49.560464:  
2025-03-16 11:20:49.567066: Epoch 30 
2025-03-16 11:20:49.569592: Current learning rate: 0.00725 
2025-03-16 11:21:28.416703: train_loss -0.6947 
2025-03-16 11:21:28.423737: val_loss -0.6406 
2025-03-16 11:21:28.426758: Pseudo dice [np.float32(0.8209), np.float32(0.7224), np.float32(0.8283)] 
2025-03-16 11:21:28.430267: Epoch time: 38.86 s 
2025-03-16 11:21:28.433773: Yayy! New best EMA pseudo Dice: 0.7671999931335449 
2025-03-16 11:21:29.189561:  
2025-03-16 11:21:29.195121: Epoch 31 
2025-03-16 11:21:29.198696: Current learning rate: 0.00716 
2025-03-16 11:22:09.262224: train_loss -0.6826 
2025-03-16 11:22:09.269824: val_loss -0.625 
2025-03-16 11:22:09.272904: Pseudo dice [np.float32(0.816), np.float32(0.7163), np.float32(0.8505)] 
2025-03-16 11:22:09.276455: Epoch time: 40.07 s 
2025-03-16 11:22:09.279004: Yayy! New best EMA pseudo Dice: 0.7699000239372253 
2025-03-16 11:22:10.031556:  
2025-03-16 11:22:10.036681: Epoch 32 
2025-03-16 11:22:10.040194: Current learning rate: 0.00707 
2025-03-16 11:22:48.631103: train_loss -0.687 
2025-03-16 11:22:48.639228: val_loss -0.6279 
2025-03-16 11:22:48.644303: Pseudo dice [np.float32(0.8168), np.float32(0.7198), np.float32(0.8318)] 
2025-03-16 11:22:48.646813: Epoch time: 38.6 s 
2025-03-16 11:22:48.650326: Yayy! New best EMA pseudo Dice: 0.7718999981880188 
2025-03-16 11:22:49.416006:  
2025-03-16 11:22:49.422179: Epoch 33 
2025-03-16 11:22:49.425242: Current learning rate: 0.00697 
2025-03-16 11:23:28.455919: train_loss -0.6944 
2025-03-16 11:23:28.462852: val_loss -0.6415 
2025-03-16 11:23:28.466421: Pseudo dice [np.float32(0.8146), np.float32(0.6789), np.float32(0.8511)] 
2025-03-16 11:23:28.469460: Epoch time: 39.04 s 
2025-03-16 11:23:28.472485: Yayy! New best EMA pseudo Dice: 0.7728999853134155 
2025-03-16 11:23:29.222276:  
2025-03-16 11:23:29.227827: Epoch 34 
2025-03-16 11:23:29.230868: Current learning rate: 0.00688 
2025-03-16 11:24:09.153081: train_loss -0.6894 
2025-03-16 11:24:09.159627: val_loss -0.6174 
2025-03-16 11:24:09.162146: Pseudo dice [np.float32(0.8213), np.float32(0.596), np.float32(0.8589)] 
2025-03-16 11:24:09.166169: Epoch time: 39.93 s 
2025-03-16 11:24:09.931323:  
2025-03-16 11:24:09.936840: Epoch 35 
2025-03-16 11:24:09.939345: Current learning rate: 0.00679 
2025-03-16 11:24:50.025009: train_loss -0.6913 
2025-03-16 11:24:50.033057: val_loss -0.6491 
2025-03-16 11:24:50.037086: Pseudo dice [np.float32(0.8121), np.float32(0.7156), np.float32(0.8619)] 
2025-03-16 11:24:50.041095: Epoch time: 40.09 s 
2025-03-16 11:24:50.045604: Yayy! New best EMA pseudo Dice: 0.7738999724388123 
2025-03-16 11:24:50.822343:  
2025-03-16 11:24:50.827857: Epoch 36 
2025-03-16 11:24:50.831366: Current learning rate: 0.00669 
2025-03-16 11:25:29.883024: train_loss -0.7008 
2025-03-16 11:25:29.890540: val_loss -0.6204 
2025-03-16 11:25:29.894049: Pseudo dice [np.float32(0.7988), np.float32(0.737), np.float32(0.8465)] 
2025-03-16 11:25:29.898060: Epoch time: 39.06 s 
2025-03-16 11:25:29.901570: Yayy! New best EMA pseudo Dice: 0.7760000228881836 
2025-03-16 11:25:30.664427:  
2025-03-16 11:25:30.670499: Epoch 37 
2025-03-16 11:25:30.675122: Current learning rate: 0.0066 
2025-03-16 11:26:09.908038: train_loss -0.6949 
2025-03-16 11:26:09.914185: val_loss -0.6525 
2025-03-16 11:26:09.917712: Pseudo dice [np.float32(0.8362), np.float32(0.6875), np.float32(0.8446)] 
2025-03-16 11:26:09.921232: Epoch time: 39.24 s 
2025-03-16 11:26:09.924755: Yayy! New best EMA pseudo Dice: 0.7773000001907349 
2025-03-16 11:26:10.694129:  
2025-03-16 11:26:10.699139: Epoch 38 
2025-03-16 11:26:10.703647: Current learning rate: 0.0065 
2025-03-16 11:26:50.073456: train_loss -0.6981 
2025-03-16 11:26:50.082027: val_loss -0.6311 
2025-03-16 11:26:50.087071: Pseudo dice [np.float32(0.8351), np.float32(0.7075), np.float32(0.8581)] 
2025-03-16 11:26:50.091117: Epoch time: 39.38 s 
2025-03-16 11:26:50.095648: Yayy! New best EMA pseudo Dice: 0.7796000242233276 
2025-03-16 11:26:50.852360:  
2025-03-16 11:26:50.856373: Epoch 39 
2025-03-16 11:26:50.861385: Current learning rate: 0.00641 
2025-03-16 11:27:29.768372: train_loss -0.7062 
2025-03-16 11:27:29.774969: val_loss -0.6431 
2025-03-16 11:27:29.778478: Pseudo dice [np.float32(0.8231), np.float32(0.7114), np.float32(0.8542)] 
2025-03-16 11:27:29.782486: Epoch time: 38.92 s 
2025-03-16 11:27:29.785996: Yayy! New best EMA pseudo Dice: 0.7813000082969666 
2025-03-16 11:27:30.578827:  
2025-03-16 11:27:30.584903: Epoch 40 
2025-03-16 11:27:30.588967: Current learning rate: 0.00631 
2025-03-16 11:28:10.035865: train_loss -0.6923 
2025-03-16 11:28:10.042019: val_loss -0.6358 
2025-03-16 11:28:10.046683: Pseudo dice [np.float32(0.8194), np.float32(0.6892), np.float32(0.843)] 
2025-03-16 11:28:10.050250: Epoch time: 39.46 s 
2025-03-16 11:28:10.052800: Yayy! New best EMA pseudo Dice: 0.781499981880188 
2025-03-16 11:28:10.862161:  
2025-03-16 11:28:10.868234: Epoch 41 
2025-03-16 11:28:10.872743: Current learning rate: 0.00622 
2025-03-16 11:28:50.916995: train_loss -0.7012 
2025-03-16 11:28:50.927022: val_loss -0.6357 
2025-03-16 11:28:50.932040: Pseudo dice [np.float32(0.8243), np.float32(0.6826), np.float32(0.8337)] 
2025-03-16 11:28:50.935553: Epoch time: 40.05 s 
2025-03-16 11:28:51.490726:  
2025-03-16 11:28:51.495746: Epoch 42 
2025-03-16 11:28:51.500264: Current learning rate: 0.00612 
2025-03-16 11:29:30.243574: train_loss -0.7056 
2025-03-16 11:29:30.249250: val_loss -0.6492 
2025-03-16 11:29:30.252667: Pseudo dice [np.float32(0.8355), np.float32(0.7159), np.float32(0.8755)] 
2025-03-16 11:29:30.255332: Epoch time: 38.75 s 
2025-03-16 11:29:30.260388: Yayy! New best EMA pseudo Dice: 0.7842000126838684 
2025-03-16 11:29:31.170424:  
2025-03-16 11:29:31.175984: Epoch 43 
2025-03-16 11:29:31.180028: Current learning rate: 0.00603 
2025-03-16 11:30:10.053262: train_loss -0.6868 
2025-03-16 11:30:10.060463: val_loss -0.6163 
2025-03-16 11:30:10.065010: Pseudo dice [np.float32(0.8099), np.float32(0.6554), np.float32(0.8502)] 
2025-03-16 11:30:10.069064: Epoch time: 38.88 s 
2025-03-16 11:30:10.644830:  
2025-03-16 11:30:10.649632: Epoch 44 
2025-03-16 11:30:10.655696: Current learning rate: 0.00593 
2025-03-16 11:30:49.139165: train_loss -0.6893 
2025-03-16 11:30:49.146212: val_loss -0.613 
2025-03-16 11:30:49.150303: Pseudo dice [np.float32(0.8075), np.float32(0.6583), np.float32(0.8534)] 
2025-03-16 11:30:49.154141: Epoch time: 38.5 s 
2025-03-16 11:30:49.719623:  
2025-03-16 11:30:49.725183: Epoch 45 
2025-03-16 11:30:49.728712: Current learning rate: 0.00584 
2025-03-16 11:31:28.130866: train_loss -0.7102 
2025-03-16 11:31:28.137390: val_loss -0.6313 
2025-03-16 11:31:28.141402: Pseudo dice [np.float32(0.8047), np.float32(0.6689), np.float32(0.8495)] 
2025-03-16 11:31:28.144914: Epoch time: 38.41 s 
2025-03-16 11:31:28.705399:  
2025-03-16 11:31:28.711972: Epoch 46 
2025-03-16 11:31:28.715534: Current learning rate: 0.00574 
2025-03-16 11:32:07.059680: train_loss -0.7083 
2025-03-16 11:32:07.066775: val_loss -0.6645 
2025-03-16 11:32:07.069833: Pseudo dice [np.float32(0.8328), np.float32(0.7462), np.float32(0.8474)] 
2025-03-16 11:32:07.074401: Epoch time: 38.35 s 
2025-03-16 11:32:07.662112:  
2025-03-16 11:32:07.667668: Epoch 47 
2025-03-16 11:32:07.672760: Current learning rate: 0.00565 
2025-03-16 11:32:46.077130: train_loss -0.7083 
2025-03-16 11:32:46.084177: val_loss -0.6243 
2025-03-16 11:32:46.088726: Pseudo dice [np.float32(0.8144), np.float32(0.7296), np.float32(0.8435)] 
2025-03-16 11:32:46.092240: Epoch time: 38.42 s 
2025-03-16 11:32:46.096248: Yayy! New best EMA pseudo Dice: 0.785099983215332 
2025-03-16 11:32:46.846918:  
2025-03-16 11:32:46.852433: Epoch 48 
2025-03-16 11:32:46.855941: Current learning rate: 0.00555 
2025-03-16 11:33:25.315190: train_loss -0.7041 
2025-03-16 11:33:25.321439: val_loss -0.6534 
2025-03-16 11:33:25.326019: Pseudo dice [np.float32(0.8228), np.float32(0.6961), np.float32(0.8635)] 
2025-03-16 11:33:25.330076: Epoch time: 38.47 s 
2025-03-16 11:33:25.333710: Yayy! New best EMA pseudo Dice: 0.7860000133514404 
2025-03-16 11:33:26.071254:  
2025-03-16 11:33:26.077306: Epoch 49 
2025-03-16 11:33:26.080906: Current learning rate: 0.00546 
2025-03-16 11:34:04.482890: train_loss -0.7073 
2025-03-16 11:34:04.489003: val_loss -0.6442 
2025-03-16 11:34:04.493547: Pseudo dice [np.float32(0.8319), np.float32(0.7038), np.float32(0.8602)] 
2025-03-16 11:34:04.497663: Epoch time: 38.41 s 
2025-03-16 11:34:04.656449: Yayy! New best EMA pseudo Dice: 0.7872999906539917 
2025-03-16 11:34:05.386349:  
2025-03-16 11:34:05.392864: Epoch 50 
2025-03-16 11:34:05.396373: Current learning rate: 0.00536 
2025-03-16 11:34:43.855124: train_loss -0.7022 
2025-03-16 11:34:43.862703: val_loss -0.638 
2025-03-16 11:34:43.866225: Pseudo dice [np.float32(0.8206), np.float32(0.6888), np.float32(0.8663)] 
2025-03-16 11:34:43.869810: Epoch time: 38.47 s 
2025-03-16 11:34:43.873852: Yayy! New best EMA pseudo Dice: 0.7878000140190125 
2025-03-16 11:34:44.779823:  
2025-03-16 11:34:44.785863: Epoch 51 
2025-03-16 11:34:44.790396: Current learning rate: 0.00526 
2025-03-16 11:35:23.295585: train_loss -0.7137 
2025-03-16 11:35:23.302112: val_loss -0.6437 
2025-03-16 11:35:23.307129: Pseudo dice [np.float32(0.8038), np.float32(0.7217), np.float32(0.8631)] 
2025-03-16 11:35:23.311249: Epoch time: 38.52 s 
2025-03-16 11:35:23.314785: Yayy! New best EMA pseudo Dice: 0.7886000275611877 
2025-03-16 11:35:24.062222:  
2025-03-16 11:35:24.068277: Epoch 52 
2025-03-16 11:35:24.072319: Current learning rate: 0.00517 
2025-03-16 11:36:02.519883: train_loss -0.7056 
2025-03-16 11:36:02.526397: val_loss -0.6539 
2025-03-16 11:36:02.530905: Pseudo dice [np.float32(0.836), np.float32(0.6837), np.float32(0.8615)] 
2025-03-16 11:36:02.533915: Epoch time: 38.46 s 
2025-03-16 11:36:02.537425: Yayy! New best EMA pseudo Dice: 0.7890999913215637 
2025-03-16 11:36:03.294481:  
2025-03-16 11:36:03.300494: Epoch 53 
2025-03-16 11:36:03.304002: Current learning rate: 0.00507 
2025-03-16 11:36:41.639250: train_loss -0.7126 
2025-03-16 11:36:41.645301: val_loss -0.6525 
2025-03-16 11:36:41.649341: Pseudo dice [np.float32(0.8157), np.float32(0.6897), np.float32(0.8642)] 
2025-03-16 11:36:41.652865: Epoch time: 38.35 s 
2025-03-16 11:36:41.656394: Yayy! New best EMA pseudo Dice: 0.7892000079154968 
2025-03-16 11:36:42.403692:  
2025-03-16 11:36:42.409262: Epoch 54 
2025-03-16 11:36:42.412804: Current learning rate: 0.00497 
2025-03-16 11:37:20.902253: train_loss -0.7236 
2025-03-16 11:37:20.909349: val_loss -0.67 
2025-03-16 11:37:20.913891: Pseudo dice [np.float32(0.845), np.float32(0.6693), np.float32(0.8744)] 
2025-03-16 11:37:20.917439: Epoch time: 38.5 s 
2025-03-16 11:37:20.920969: Yayy! New best EMA pseudo Dice: 0.789900004863739 
2025-03-16 11:37:21.660195:  
2025-03-16 11:37:21.664842: Epoch 55 
2025-03-16 11:37:21.668379: Current learning rate: 0.00487 
2025-03-16 11:38:00.143600: train_loss -0.7176 
2025-03-16 11:38:00.151218: val_loss -0.6282 
2025-03-16 11:38:00.155227: Pseudo dice [np.float32(0.8161), np.float32(0.7134), np.float32(0.8142)] 
2025-03-16 11:38:00.158736: Epoch time: 38.48 s 
2025-03-16 11:38:00.725371:  
2025-03-16 11:38:00.730899: Epoch 56 
2025-03-16 11:38:00.734443: Current learning rate: 0.00478 
2025-03-16 11:38:39.132013: train_loss -0.7181 
2025-03-16 11:38:39.138120: val_loss -0.6323 
2025-03-16 11:38:39.142181: Pseudo dice [np.float32(0.8221), np.float32(0.7093), np.float32(0.8745)] 
2025-03-16 11:38:39.145722: Epoch time: 38.41 s 
2025-03-16 11:38:39.148764: Yayy! New best EMA pseudo Dice: 0.7903000116348267 
2025-03-16 11:38:39.894274:  
2025-03-16 11:38:39.900298: Epoch 57 
2025-03-16 11:38:39.904809: Current learning rate: 0.00468 
2025-03-16 11:39:18.318601: train_loss -0.7237 
2025-03-16 11:39:18.325189: val_loss -0.6407 
2025-03-16 11:39:18.329224: Pseudo dice [np.float32(0.8408), np.float32(0.7111), np.float32(0.8481)] 
2025-03-16 11:39:18.332783: Epoch time: 38.42 s 
2025-03-16 11:39:18.335816: Yayy! New best EMA pseudo Dice: 0.7912999987602234 
2025-03-16 11:39:19.066654:  
2025-03-16 11:39:19.072763: Epoch 58 
2025-03-16 11:39:19.077337: Current learning rate: 0.00458 
2025-03-16 11:39:57.669028: train_loss -0.7068 
2025-03-16 11:39:57.675571: val_loss -0.6451 
2025-03-16 11:39:57.679092: Pseudo dice [np.float32(0.8381), np.float32(0.7), np.float32(0.8472)] 
2025-03-16 11:39:57.682113: Epoch time: 38.6 s 
2025-03-16 11:39:57.686178: Yayy! New best EMA pseudo Dice: 0.791700005531311 
2025-03-16 11:39:58.620351:  
2025-03-16 11:39:58.625865: Epoch 59 
2025-03-16 11:39:58.629374: Current learning rate: 0.00448 
2025-03-16 11:40:36.980876: train_loss -0.7206 
2025-03-16 11:40:36.987449: val_loss -0.6919 
2025-03-16 11:40:36.990979: Pseudo dice [np.float32(0.85), np.float32(0.7448), np.float32(0.8801)] 
2025-03-16 11:40:36.994007: Epoch time: 38.36 s 
2025-03-16 11:40:36.998034: Yayy! New best EMA pseudo Dice: 0.7950000166893005 
2025-03-16 11:40:37.751329:  
2025-03-16 11:40:37.757020: Epoch 60 
2025-03-16 11:40:37.761614: Current learning rate: 0.00438 
2025-03-16 11:41:16.093152: train_loss -0.7287 
2025-03-16 11:41:16.100171: val_loss -0.6552 
2025-03-16 11:41:16.104208: Pseudo dice [np.float32(0.8302), np.float32(0.7179), np.float32(0.8693)] 
2025-03-16 11:41:16.107714: Epoch time: 38.34 s 
2025-03-16 11:41:16.110721: Yayy! New best EMA pseudo Dice: 0.7961000204086304 
2025-03-16 11:41:16.861351:  
2025-03-16 11:41:16.868542: Epoch 61 
2025-03-16 11:41:16.872061: Current learning rate: 0.00429 
2025-03-16 11:41:55.240256: train_loss -0.7328 
2025-03-16 11:41:55.246853: val_loss -0.6194 
2025-03-16 11:41:55.250462: Pseudo dice [np.float32(0.8124), np.float32(0.6968), np.float32(0.865)] 
2025-03-16 11:41:55.254483: Epoch time: 38.38 s 
2025-03-16 11:41:55.834696:  
2025-03-16 11:41:55.840250: Epoch 62 
2025-03-16 11:41:55.844299: Current learning rate: 0.00419 
2025-03-16 11:42:34.197210: train_loss -0.7225 
2025-03-16 11:42:34.204731: val_loss -0.6437 
2025-03-16 11:42:34.208744: Pseudo dice [np.float32(0.8207), np.float32(0.7251), np.float32(0.8712)] 
2025-03-16 11:42:34.213252: Epoch time: 38.36 s 
2025-03-16 11:42:34.216258: Yayy! New best EMA pseudo Dice: 0.7965999841690063 
2025-03-16 11:42:34.970984:  
2025-03-16 11:42:34.977556: Epoch 63 
2025-03-16 11:42:34.981605: Current learning rate: 0.00409 
2025-03-16 11:43:13.345272: train_loss -0.7246 
2025-03-16 11:43:13.352484: val_loss -0.6356 
2025-03-16 11:43:13.357019: Pseudo dice [np.float32(0.8158), np.float32(0.6921), np.float32(0.8609)] 
2025-03-16 11:43:13.360560: Epoch time: 38.38 s 
2025-03-16 11:43:13.960765:  
2025-03-16 11:43:13.967865: Epoch 64 
2025-03-16 11:43:13.971957: Current learning rate: 0.00399 
2025-03-16 11:43:55.626594: train_loss -0.7268 
2025-03-16 11:43:55.633748: val_loss -0.6161 
2025-03-16 11:43:55.638317: Pseudo dice [np.float32(0.8071), np.float32(0.6548), np.float32(0.8546)] 
2025-03-16 11:43:55.642374: Epoch time: 41.67 s 
2025-03-16 11:43:56.271992:  
2025-03-16 11:43:56.278006: Epoch 65 
2025-03-16 11:43:56.283017: Current learning rate: 0.00389 
2025-03-16 11:44:36.282189: train_loss -0.7257 
2025-03-16 11:44:36.290269: val_loss -0.654 
2025-03-16 11:44:36.294306: Pseudo dice [np.float32(0.8252), np.float32(0.7231), np.float32(0.869)] 
2025-03-16 11:44:36.297866: Epoch time: 40.01 s 
2025-03-16 11:44:36.940129:  
2025-03-16 11:44:36.946649: Epoch 66 
2025-03-16 11:44:36.951659: Current learning rate: 0.00379 
2025-03-16 11:45:17.082038: train_loss -0.7339 
2025-03-16 11:45:17.090168: val_loss -0.6355 
2025-03-16 11:45:17.094711: Pseudo dice [np.float32(0.8194), np.float32(0.7071), np.float32(0.848)] 
2025-03-16 11:45:17.098257: Epoch time: 40.14 s 
2025-03-16 11:45:17.865740:  
2025-03-16 11:45:17.872788: Epoch 67 
2025-03-16 11:45:17.876320: Current learning rate: 0.00369 
2025-03-16 11:45:57.964582: train_loss -0.7279 
2025-03-16 11:45:57.974651: val_loss -0.6282 
2025-03-16 11:45:57.979693: Pseudo dice [np.float32(0.8283), np.float32(0.6647), np.float32(0.84)] 
2025-03-16 11:45:57.984202: Epoch time: 40.1 s 
2025-03-16 11:45:58.619045:  
2025-03-16 11:45:58.626564: Epoch 68 
2025-03-16 11:45:58.630571: Current learning rate: 0.00359 
2025-03-16 11:46:38.662421: train_loss -0.7323 
2025-03-16 11:46:38.669964: val_loss -0.6263 
2025-03-16 11:46:38.674975: Pseudo dice [np.float32(0.8202), np.float32(0.6866), np.float32(0.856)] 
2025-03-16 11:46:38.679986: Epoch time: 40.04 s 
2025-03-16 11:46:39.315808:  
2025-03-16 11:46:39.323349: Epoch 69 
2025-03-16 11:46:39.327872: Current learning rate: 0.00349 
2025-03-16 11:47:19.484847: train_loss -0.7402 
2025-03-16 11:47:19.491899: val_loss -0.6247 
2025-03-16 11:47:19.496932: Pseudo dice [np.float32(0.8147), np.float32(0.6679), np.float32(0.8639)] 
2025-03-16 11:47:19.501469: Epoch time: 40.17 s 
2025-03-16 11:47:20.161839:  
2025-03-16 11:47:20.168390: Epoch 70 
2025-03-16 11:47:20.173435: Current learning rate: 0.00338 
2025-03-16 11:47:58.899835: train_loss -0.7469 
2025-03-16 11:47:58.907392: val_loss -0.6401 
2025-03-16 11:47:58.911926: Pseudo dice [np.float32(0.8364), np.float32(0.7127), np.float32(0.8798)] 
2025-03-16 11:47:58.915519: Epoch time: 38.74 s 
2025-03-16 11:47:59.510712:  
2025-03-16 11:47:59.517228: Epoch 71 
2025-03-16 11:47:59.521240: Current learning rate: 0.00328 
2025-03-16 11:48:37.900419: train_loss -0.7385 
2025-03-16 11:48:37.908449: val_loss -0.6658 
2025-03-16 11:48:37.912961: Pseudo dice [np.float32(0.8242), np.float32(0.7129), np.float32(0.8667)] 
2025-03-16 11:48:37.916972: Epoch time: 38.39 s 
2025-03-16 11:48:38.502637:  
2025-03-16 11:48:38.508675: Epoch 72 
2025-03-16 11:48:38.513227: Current learning rate: 0.00318 
2025-03-16 11:49:16.866629: train_loss -0.7386 
2025-03-16 11:49:16.873213: val_loss -0.6504 
2025-03-16 11:49:16.877768: Pseudo dice [np.float32(0.829), np.float32(0.7295), np.float32(0.8555)] 
2025-03-16 11:49:16.881828: Epoch time: 38.36 s 
2025-03-16 11:49:17.471726:  
2025-03-16 11:49:17.477803: Epoch 73 
2025-03-16 11:49:17.481923: Current learning rate: 0.00308 
2025-03-16 11:49:55.782851: train_loss -0.727 
2025-03-16 11:49:55.790368: val_loss -0.6244 
2025-03-16 11:49:55.794877: Pseudo dice [np.float32(0.8213), np.float32(0.7065), np.float32(0.857)] 
2025-03-16 11:49:55.798892: Epoch time: 38.31 s 
2025-03-16 11:49:56.395950:  
2025-03-16 11:49:56.401463: Epoch 74 
2025-03-16 11:49:56.405971: Current learning rate: 0.00297 
2025-03-16 11:50:34.792403: train_loss -0.7381 
2025-03-16 11:50:34.799478: val_loss -0.6134 
2025-03-16 11:50:34.804023: Pseudo dice [np.float32(0.8049), np.float32(0.7061), np.float32(0.863)] 
2025-03-16 11:50:34.808590: Epoch time: 38.4 s 
2025-03-16 11:50:35.547099:  
2025-03-16 11:50:35.553739: Epoch 75 
2025-03-16 11:50:35.558290: Current learning rate: 0.00287 
2025-03-16 11:51:13.909807: train_loss -0.7401 
2025-03-16 11:51:13.918945: val_loss -0.651 
2025-03-16 11:51:13.923006: Pseudo dice [np.float32(0.8461), np.float32(0.7136), np.float32(0.8711)] 
2025-03-16 11:51:13.928017: Epoch time: 38.36 s 
2025-03-16 11:51:14.517119:  
2025-03-16 11:51:14.523191: Epoch 76 
2025-03-16 11:51:14.527700: Current learning rate: 0.00277 
2025-03-16 11:51:52.901742: train_loss -0.7379 
2025-03-16 11:51:52.909316: val_loss -0.6347 
2025-03-16 11:51:52.913851: Pseudo dice [np.float32(0.8051), np.float32(0.7227), np.float32(0.8505)] 
2025-03-16 11:51:52.917887: Epoch time: 38.38 s 
2025-03-16 11:51:53.514187:  
2025-03-16 11:51:53.518235: Epoch 77 
2025-03-16 11:51:53.523323: Current learning rate: 0.00266 
2025-03-16 11:52:31.903293: train_loss -0.7471 
2025-03-16 11:52:31.909848: val_loss -0.6391 
2025-03-16 11:52:31.914859: Pseudo dice [np.float32(0.8344), np.float32(0.6908), np.float32(0.8694)] 
2025-03-16 11:52:31.919870: Epoch time: 38.39 s 
2025-03-16 11:52:32.516018:  
2025-03-16 11:52:32.523145: Epoch 78 
2025-03-16 11:52:32.526727: Current learning rate: 0.00256 
2025-03-16 11:53:10.822408: train_loss -0.7482 
2025-03-16 11:53:10.829987: val_loss -0.651 
2025-03-16 11:53:10.834548: Pseudo dice [np.float32(0.8376), np.float32(0.6963), np.float32(0.8798)] 
2025-03-16 11:53:10.839086: Epoch time: 38.31 s 
2025-03-16 11:53:10.842640: Yayy! New best EMA pseudo Dice: 0.7968999743461609 
2025-03-16 11:53:11.609735:  
2025-03-16 11:53:11.615787: Epoch 79 
2025-03-16 11:53:11.620334: Current learning rate: 0.00245 
2025-03-16 11:53:49.996573: train_loss -0.7438 
2025-03-16 11:53:50.003164: val_loss -0.6501 
2025-03-16 11:53:50.006730: Pseudo dice [np.float32(0.8212), np.float32(0.7016), np.float32(0.8632)] 
2025-03-16 11:53:50.011288: Epoch time: 38.39 s 
2025-03-16 11:53:50.611932:  
2025-03-16 11:53:50.617942: Epoch 80 
2025-03-16 11:53:50.621953: Current learning rate: 0.00235 
2025-03-16 11:54:29.078897: train_loss -0.7373 
2025-03-16 11:54:29.086998: val_loss -0.6674 
2025-03-16 11:54:29.090508: Pseudo dice [np.float32(0.8323), np.float32(0.7266), np.float32(0.8735)] 
2025-03-16 11:54:29.094516: Epoch time: 38.47 s 
2025-03-16 11:54:29.099028: Yayy! New best EMA pseudo Dice: 0.7982000112533569 
2025-03-16 11:54:29.899933:  
2025-03-16 11:54:29.906031: Epoch 81 
2025-03-16 11:54:29.910603: Current learning rate: 0.00224 
2025-03-16 11:55:08.252929: train_loss -0.7474 
2025-03-16 11:55:08.260447: val_loss -0.6246 
2025-03-16 11:55:08.265458: Pseudo dice [np.float32(0.8143), np.float32(0.7088), np.float32(0.8716)] 
2025-03-16 11:55:08.270473: Epoch time: 38.35 s 
2025-03-16 11:55:08.273982: Yayy! New best EMA pseudo Dice: 0.7982000112533569 
2025-03-16 11:55:09.198585:  
2025-03-16 11:55:09.203694: Epoch 82 
2025-03-16 11:55:09.208206: Current learning rate: 0.00214 
2025-03-16 11:55:47.563216: train_loss -0.7408 
2025-03-16 11:55:47.571745: val_loss -0.6444 
2025-03-16 11:55:47.576759: Pseudo dice [np.float32(0.822), np.float32(0.7041), np.float32(0.8716)] 
2025-03-16 11:55:47.580772: Epoch time: 38.37 s 
2025-03-16 11:55:47.584286: Yayy! New best EMA pseudo Dice: 0.79830002784729 
2025-03-16 11:55:48.338655:  
2025-03-16 11:55:48.342674: Epoch 83 
2025-03-16 11:55:48.346688: Current learning rate: 0.00203 
2025-03-16 11:56:26.627087: train_loss -0.7522 
2025-03-16 11:56:26.633557: val_loss -0.6672 
2025-03-16 11:56:26.637588: Pseudo dice [np.float32(0.8474), np.float32(0.7041), np.float32(0.8687)] 
2025-03-16 11:56:26.641101: Epoch time: 38.29 s 
2025-03-16 11:56:26.645120: Yayy! New best EMA pseudo Dice: 0.7990999817848206 
2025-03-16 11:56:27.402934:  
2025-03-16 11:56:27.409456: Epoch 84 
2025-03-16 11:56:27.413464: Current learning rate: 0.00192 
2025-03-16 11:57:05.745910: train_loss -0.7461 
2025-03-16 11:57:05.753512: val_loss -0.6483 
2025-03-16 11:57:05.758631: Pseudo dice [np.float32(0.8327), np.float32(0.7045), np.float32(0.8663)] 
2025-03-16 11:57:05.762660: Epoch time: 38.34 s 
2025-03-16 11:57:05.766213: Yayy! New best EMA pseudo Dice: 0.7993000149726868 
2025-03-16 11:57:06.500730:  
2025-03-16 11:57:06.507306: Epoch 85 
2025-03-16 11:57:06.510853: Current learning rate: 0.00181 
2025-03-16 11:57:44.886161: train_loss -0.7503 
2025-03-16 11:57:44.893911: val_loss -0.6417 
2025-03-16 11:57:44.897937: Pseudo dice [np.float32(0.839), np.float32(0.6745), np.float32(0.8689)] 
2025-03-16 11:57:44.901966: Epoch time: 38.39 s 
2025-03-16 11:57:45.467318:  
2025-03-16 11:57:45.472856: Epoch 86 
2025-03-16 11:57:45.477364: Current learning rate: 0.0017 
2025-03-16 11:58:25.106100: train_loss -0.7465 
2025-03-16 11:58:25.113634: val_loss -0.6353 
2025-03-16 11:58:25.119161: Pseudo dice [np.float32(0.8271), np.float32(0.6948), np.float32(0.8549)] 
2025-03-16 11:58:25.125195: Epoch time: 39.64 s 
2025-03-16 11:58:25.829861:  
2025-03-16 11:58:25.836382: Epoch 87 
2025-03-16 11:58:25.840895: Current learning rate: 0.00159 
2025-03-16 11:59:06.285465: train_loss -0.7454 
2025-03-16 11:59:06.292985: val_loss -0.6551 
2025-03-16 11:59:06.299007: Pseudo dice [np.float32(0.8312), np.float32(0.736), np.float32(0.85)] 
2025-03-16 11:59:06.303024: Epoch time: 40.46 s 
2025-03-16 11:59:06.884208:  
2025-03-16 11:59:06.891263: Epoch 88 
2025-03-16 11:59:06.895379: Current learning rate: 0.00148 
2025-03-16 11:59:45.208708: train_loss -0.7516 
2025-03-16 11:59:45.216232: val_loss -0.6524 
2025-03-16 11:59:45.220797: Pseudo dice [np.float32(0.8398), np.float32(0.7211), np.float32(0.8609)] 
2025-03-16 11:59:45.224837: Epoch time: 38.32 s 
2025-03-16 11:59:45.228850: Yayy! New best EMA pseudo Dice: 0.7997999787330627 
2025-03-16 11:59:45.979091:  
2025-03-16 11:59:45.985154: Epoch 89 
2025-03-16 11:59:45.989686: Current learning rate: 0.00137 
2025-03-16 12:00:24.711874: train_loss -0.7492 
2025-03-16 12:00:24.718908: val_loss -0.6501 
2025-03-16 12:00:24.722470: Pseudo dice [np.float32(0.8373), np.float32(0.7184), np.float32(0.8565)] 
2025-03-16 12:00:24.727000: Epoch time: 38.73 s 
2025-03-16 12:00:24.731028: Yayy! New best EMA pseudo Dice: 0.8001999855041504 
2025-03-16 12:00:25.692366:  
2025-03-16 12:00:25.699409: Epoch 90 
2025-03-16 12:00:25.703963: Current learning rate: 0.00126 
2025-03-16 12:01:04.715635: train_loss -0.7523 
2025-03-16 12:01:04.722696: val_loss -0.6709 
2025-03-16 12:01:04.726729: Pseudo dice [np.float32(0.833), np.float32(0.7344), np.float32(0.846)] 
2025-03-16 12:01:04.730756: Epoch time: 39.02 s 
2025-03-16 12:01:04.734287: Yayy! New best EMA pseudo Dice: 0.800599992275238 
2025-03-16 12:01:05.482131:  
2025-03-16 12:01:05.487646: Epoch 91 
2025-03-16 12:01:05.493670: Current learning rate: 0.00115 
2025-03-16 12:01:44.755805: train_loss -0.7524 
2025-03-16 12:01:44.762902: val_loss -0.6446 
2025-03-16 12:01:44.766937: Pseudo dice [np.float32(0.8438), np.float32(0.7488), np.float32(0.8649)] 
2025-03-16 12:01:44.770949: Epoch time: 39.27 s 
2025-03-16 12:01:44.774957: Yayy! New best EMA pseudo Dice: 0.8025000095367432 
2025-03-16 12:01:45.520279:  
2025-03-16 12:01:45.526874: Epoch 92 
2025-03-16 12:01:45.530934: Current learning rate: 0.00103 
2025-03-16 12:02:23.928002: train_loss -0.7606 
2025-03-16 12:02:23.934526: val_loss -0.6687 
2025-03-16 12:02:23.938541: Pseudo dice [np.float32(0.8254), np.float32(0.7341), np.float32(0.8593)] 
2025-03-16 12:02:23.943055: Epoch time: 38.41 s 
2025-03-16 12:02:23.946068: Yayy! New best EMA pseudo Dice: 0.8029000163078308 
2025-03-16 12:02:24.696271:  
2025-03-16 12:02:24.702826: Epoch 93 
2025-03-16 12:02:24.706880: Current learning rate: 0.00091 
2025-03-16 12:03:03.113793: train_loss -0.7555 
2025-03-16 12:03:03.120997: val_loss -0.6395 
2025-03-16 12:03:03.126025: Pseudo dice [np.float32(0.8224), np.float32(0.6966), np.float32(0.8756)] 
2025-03-16 12:03:03.130173: Epoch time: 38.42 s 
2025-03-16 12:03:03.690295:  
2025-03-16 12:03:03.695841: Epoch 94 
2025-03-16 12:03:03.698381: Current learning rate: 0.00079 
2025-03-16 12:03:42.166345: train_loss -0.7604 
2025-03-16 12:03:42.173390: val_loss -0.6177 
2025-03-16 12:03:42.177940: Pseudo dice [np.float32(0.8069), np.float32(0.7258), np.float32(0.8466)] 
2025-03-16 12:03:42.181959: Epoch time: 38.48 s 
2025-03-16 12:03:42.745010:  
2025-03-16 12:03:42.751498: Epoch 95 
2025-03-16 12:03:42.756517: Current learning rate: 0.00067 
2025-03-16 12:04:21.156075: train_loss -0.7542 
2025-03-16 12:04:21.163596: val_loss -0.6577 
2025-03-16 12:04:21.167108: Pseudo dice [np.float32(0.832), np.float32(0.7416), np.float32(0.8698)] 
2025-03-16 12:04:21.171119: Epoch time: 38.41 s 
2025-03-16 12:04:21.733584:  
2025-03-16 12:04:21.739206: Epoch 96 
2025-03-16 12:04:21.744811: Current learning rate: 0.00055 
2025-03-16 12:05:00.224850: train_loss -0.7575 
2025-03-16 12:05:00.232511: val_loss -0.6423 
2025-03-16 12:05:00.236611: Pseudo dice [np.float32(0.8267), np.float32(0.7116), np.float32(0.8657)] 
2025-03-16 12:05:00.240631: Epoch time: 38.49 s 
2025-03-16 12:05:00.815472:  
2025-03-16 12:05:00.822001: Epoch 97 
2025-03-16 12:05:00.826019: Current learning rate: 0.00043 
2025-03-16 12:05:39.219514: train_loss -0.746 
2025-03-16 12:05:39.226719: val_loss -0.6513 
2025-03-16 12:05:39.230787: Pseudo dice [np.float32(0.8318), np.float32(0.7391), np.float32(0.8715)] 
2025-03-16 12:05:39.234343: Epoch time: 38.41 s 
2025-03-16 12:05:39.238364: Yayy! New best EMA pseudo Dice: 0.8037999868392944 
2025-03-16 12:05:40.153570:  
2025-03-16 12:05:40.160624: Epoch 98 
2025-03-16 12:05:40.164635: Current learning rate: 0.0003 
2025-03-16 12:06:18.605512: train_loss -0.7543 
2025-03-16 12:06:18.613038: val_loss -0.6638 
2025-03-16 12:06:18.617553: Pseudo dice [np.float32(0.8358), np.float32(0.7408), np.float32(0.8758)] 
2025-03-16 12:06:18.621667: Epoch time: 38.45 s 
2025-03-16 12:06:18.625677: Yayy! New best EMA pseudo Dice: 0.8051000237464905 
2025-03-16 12:06:19.380467:  
2025-03-16 12:06:19.386526: Epoch 99 
2025-03-16 12:06:19.391105: Current learning rate: 0.00016 
2025-03-16 12:06:57.775250: train_loss -0.7542 
2025-03-16 12:06:57.782769: val_loss -0.6509 
2025-03-16 12:06:57.787280: Pseudo dice [np.float32(0.831), np.float32(0.6902), np.float32(0.8737)] 
2025-03-16 12:06:57.791295: Epoch time: 38.39 s 
2025-03-16 12:06:58.614687: Training done. 
2025-03-16 12:06:58.675754: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-16 12:06:58.690755: The split file contains 5 splits. 
2025-03-16 12:06:58.696755: Desired fold for training: 0 
2025-03-16 12:06:58.704755: This split has 387 training and 97 validation cases. 
2025-03-16 12:06:58.712756: predicting BRATS_010 
2025-03-16 12:06:58.736753: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2025-03-16 12:07:00.730569: predicting BRATS_011 
2025-03-16 12:07:00.750576: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2025-03-16 12:07:02.049116: predicting BRATS_012 
2025-03-16 12:07:02.068626: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-16 12:07:03.364748: predicting BRATS_018 
2025-03-16 12:07:03.384748: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2025-03-16 12:07:04.683519: predicting BRATS_020 
2025-03-16 12:07:04.702519: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2025-03-16 12:07:06.003687: predicting BRATS_028 
2025-03-16 12:07:06.025687: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-03-16 12:07:07.323885: predicting BRATS_029 
2025-03-16 12:07:07.345887: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-03-16 12:07:08.650573: predicting BRATS_032 
2025-03-16 12:07:08.670078: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2025-03-16 12:07:09.974948: predicting BRATS_034 
2025-03-16 12:07:09.996949: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2025-03-16 12:07:11.337545: predicting BRATS_041 
2025-03-16 12:07:11.360055: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2025-03-16 12:07:12.657490: predicting BRATS_042 
2025-03-16 12:07:12.679491: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2025-03-16 12:07:13.979616: predicting BRATS_047 
2025-03-16 12:07:14.000616: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-16 12:07:15.298157: predicting BRATS_049 
2025-03-16 12:07:15.320157: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-16 12:07:16.620239: predicting BRATS_053 
2025-03-16 12:07:16.642239: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-16 12:07:17.937109: predicting BRATS_056 
2025-03-16 12:07:17.958112: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-16 12:07:19.255332: predicting BRATS_057 
2025-03-16 12:07:19.276840: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-16 12:07:20.574813: predicting BRATS_067 
2025-03-16 12:07:20.595814: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-16 12:07:21.893566: predicting BRATS_069 
2025-03-16 12:07:21.916567: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-16 12:07:23.215643: predicting BRATS_085 
2025-03-16 12:07:23.237645: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2025-03-16 12:07:23.912389: predicting BRATS_086 
2025-03-16 12:07:23.935390: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2025-03-16 12:07:25.236109: predicting BRATS_088 
2025-03-16 12:07:25.259112: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2025-03-16 12:07:26.558850: predicting BRATS_091 
2025-03-16 12:07:26.581357: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-03-16 12:07:27.881332: predicting BRATS_098 
2025-03-16 12:07:27.905332: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2025-03-16 12:07:29.207632: predicting BRATS_100 
2025-03-16 12:07:29.230632: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-16 12:07:29.937180: predicting BRATS_101 
2025-03-16 12:07:29.959185: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-16 12:07:30.633898: predicting BRATS_102 
2025-03-16 12:07:30.656901: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2025-03-16 12:07:31.955198: predicting BRATS_104 
2025-03-16 12:07:31.976706: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2025-03-16 12:07:33.276028: predicting BRATS_111 
2025-03-16 12:07:33.299026: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2025-03-16 12:07:34.600311: predicting BRATS_116 
2025-03-16 12:07:34.623312: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2025-03-16 12:07:35.919357: predicting BRATS_135 
2025-03-16 12:07:35.941356: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-03-16 12:07:37.240809: predicting BRATS_136 
2025-03-16 12:07:37.262812: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-03-16 12:07:38.560430: predicting BRATS_138 
2025-03-16 12:07:38.582941: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2025-03-16 12:07:39.886556: predicting BRATS_145 
2025-03-16 12:07:39.910556: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2025-03-16 12:07:41.210921: predicting BRATS_149 
2025-03-16 12:07:41.233921: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2025-03-16 12:07:42.535222: predicting BRATS_155 
2025-03-16 12:07:42.558222: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-16 12:07:43.856982: predicting BRATS_157 
2025-03-16 12:07:43.880494: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-16 12:07:45.209121: predicting BRATS_158 
2025-03-16 12:07:45.231121: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-16 12:07:46.530456: predicting BRATS_159 
2025-03-16 12:07:46.551457: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-16 12:07:47.850838: predicting BRATS_163 
2025-03-16 12:07:47.874841: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-03-16 12:07:49.174462: predicting BRATS_164 
2025-03-16 12:07:49.195837: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2025-03-16 12:07:50.496272: predicting BRATS_169 
2025-03-16 12:07:50.518268: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2025-03-16 12:07:51.844081: predicting BRATS_176 
2025-03-16 12:07:51.870081: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-03-16 12:07:53.184199: predicting BRATS_181 
2025-03-16 12:07:53.208244: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2025-03-16 12:07:54.505194: predicting BRATS_183 
2025-03-16 12:07:54.529195: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-16 12:07:55.830164: predicting BRATS_184 
2025-03-16 12:07:55.852166: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-16 12:07:57.152324: predicting BRATS_187 
2025-03-16 12:07:57.175327: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-16 12:07:58.476318: predicting BRATS_192 
2025-03-16 12:07:58.506406: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2025-03-16 12:07:59.803849: predicting BRATS_198 
2025-03-16 12:07:59.827850: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-03-16 12:08:01.165476: predicting BRATS_207 
2025-03-16 12:08:01.190481: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-16 12:08:02.492514: predicting BRATS_208 
2025-03-16 12:08:02.515514: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-16 12:08:03.816332: predicting BRATS_218 
2025-03-16 12:08:03.838332: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-03-16 12:08:05.141081: predicting BRATS_220 
2025-03-16 12:08:05.165081: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2025-03-16 12:08:06.465489: predicting BRATS_224 
2025-03-16 12:08:06.491491: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2025-03-16 12:08:07.792428: predicting BRATS_230 
2025-03-16 12:08:07.816934: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2025-03-16 12:08:09.119236: predicting BRATS_271 
2025-03-16 12:08:09.140235: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2025-03-16 12:08:10.441221: predicting BRATS_282 
2025-03-16 12:08:10.464221: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2025-03-16 12:08:11.800797: predicting BRATS_284 
2025-03-16 12:08:11.822797: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2025-03-16 12:08:13.121023: predicting BRATS_287 
2025-03-16 12:08:13.141022: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-16 12:08:14.440471: predicting BRATS_290 
2025-03-16 12:08:14.463470: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2025-03-16 12:08:15.761139: predicting BRATS_291 
2025-03-16 12:08:15.783135: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-03-16 12:08:17.079545: predicting BRATS_292 
2025-03-16 12:08:17.102058: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2025-03-16 12:08:18.397807: predicting BRATS_293 
2025-03-16 12:08:18.421313: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2025-03-16 12:08:19.724204: predicting BRATS_300 
2025-03-16 12:08:19.747204: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2025-03-16 12:08:21.046328: predicting BRATS_305 
2025-03-16 12:08:21.069328: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2025-03-16 12:08:22.368412: predicting BRATS_311 
2025-03-16 12:08:22.393417: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2025-03-16 12:08:23.697231: predicting BRATS_314 
2025-03-16 12:08:23.720738: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2025-03-16 12:08:25.022370: predicting BRATS_321 
2025-03-16 12:08:25.044370: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-03-16 12:08:26.344505: predicting BRATS_328 
2025-03-16 12:08:26.366505: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2025-03-16 12:08:27.030255: predicting BRATS_329 
2025-03-16 12:08:27.054256: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2025-03-16 12:08:28.356236: predicting BRATS_335 
2025-03-16 12:08:28.379235: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2025-03-16 12:08:29.718130: predicting BRATS_343 
2025-03-16 12:08:29.741128: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2025-03-16 12:08:31.043052: predicting BRATS_350 
2025-03-16 12:08:31.066052: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2025-03-16 12:08:31.739793: predicting BRATS_351 
2025-03-16 12:08:31.760793: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2025-03-16 12:08:32.427987: predicting BRATS_356 
2025-03-16 12:08:32.446988: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2025-03-16 12:08:33.142041: predicting BRATS_366 
2025-03-16 12:08:33.163042: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2025-03-16 12:08:34.462826: predicting BRATS_367 
2025-03-16 12:08:34.485827: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2025-03-16 12:08:35.794093: predicting BRATS_374 
2025-03-16 12:08:35.816602: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2025-03-16 12:08:37.132730: predicting BRATS_376 
2025-03-16 12:08:37.154730: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2025-03-16 12:08:38.450372: predicting BRATS_377 
2025-03-16 12:08:38.474375: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2025-03-16 12:08:39.774861: predicting BRATS_378 
2025-03-16 12:08:39.797862: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2025-03-16 12:08:41.096162: predicting BRATS_379 
2025-03-16 12:08:41.118676: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2025-03-16 12:08:42.452520: predicting BRATS_384 
2025-03-16 12:08:42.477520: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2025-03-16 12:08:43.773676: predicting BRATS_386 
2025-03-16 12:08:43.795676: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-03-16 12:08:45.093355: predicting BRATS_394 
2025-03-16 12:08:45.114357: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-16 12:08:46.438578: predicting BRATS_398 
2025-03-16 12:08:46.461579: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2025-03-16 12:08:47.785101: predicting BRATS_400 
2025-03-16 12:08:47.809104: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2025-03-16 12:08:49.124007: predicting BRATS_432 
2025-03-16 12:08:49.151005: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2025-03-16 12:08:50.455130: predicting BRATS_437 
2025-03-16 12:08:50.484131: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-16 12:08:51.869730: predicting BRATS_445 
2025-03-16 12:08:51.893730: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2025-03-16 12:08:53.248764: predicting BRATS_446 
2025-03-16 12:08:53.270764: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-03-16 12:08:54.575716: predicting BRATS_450 
2025-03-16 12:08:54.602717: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2025-03-16 12:08:55.964272: predicting BRATS_452 
2025-03-16 12:08:55.986274: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2025-03-16 12:08:57.304299: predicting BRATS_460 
2025-03-16 12:08:57.328807: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2025-03-16 12:08:58.628891: predicting BRATS_470 
2025-03-16 12:08:58.652890: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-03-16 12:08:59.961666: predicting BRATS_472 
2025-03-16 12:08:59.986666: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2025-03-16 12:09:01.281896: predicting BRATS_473 
2025-03-16 12:09:01.304895: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2025-03-16 12:09:01.975372: predicting BRATS_482 
2025-03-16 12:09:01.996372: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2025-03-16 12:09:10.398880: Validation complete 
2025-03-16 12:09:10.405879: Mean Validation Dice:  0.7225586196019407 
