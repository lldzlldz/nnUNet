
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-17 05:27:39.604319: do_dummy_2d_data_aug: False 
2025-03-17 05:27:39.631374: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-17 05:27:39.639379: The split file contains 5 splits. 
2025-03-17 05:27:39.642378: Desired fold for training: 0 
2025-03-17 05:27:39.644378: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2025-03-17 05:28:10.921564: unpacking dataset... 
2025-03-17 05:28:11.543637: unpacking done... 
2025-03-17 05:28:14.464687:  
2025-03-17 05:28:14.469700: Epoch 0 
2025-03-17 05:28:14.473210: Current learning rate: 0.01 
2025-03-17 05:28:56.804469: train_loss -0.3061 
2025-03-17 05:28:56.809016: val_loss -0.4213 
2025-03-17 05:28:56.812137: Pseudo dice [np.float32(0.685), np.float32(0.4949), np.float32(0.7386)] 
2025-03-17 05:28:56.816204: Epoch time: 42.34 s 
2025-03-17 05:28:56.819288: Yayy! New best EMA pseudo Dice: 0.6395000219345093 
2025-03-17 05:28:57.515472:  
2025-03-17 05:28:57.521018: Epoch 1 
2025-03-17 05:28:57.524589: Current learning rate: 0.00991 
2025-03-17 05:29:36.000135: train_loss -0.4871 
2025-03-17 05:29:36.006850: val_loss -0.4622 
2025-03-17 05:29:36.010363: Pseudo dice [np.float32(0.7264), np.float32(0.5305), np.float32(0.7713)] 
2025-03-17 05:29:36.013870: Epoch time: 38.49 s 
2025-03-17 05:29:36.016883: Yayy! New best EMA pseudo Dice: 0.6431000232696533 
2025-03-17 05:29:36.770246:  
2025-03-17 05:29:36.775789: Epoch 2 
2025-03-17 05:29:36.778306: Current learning rate: 0.00982 
2025-03-17 05:30:15.281719: train_loss -0.5272 
2025-03-17 05:30:15.287730: val_loss -0.5121 
2025-03-17 05:30:15.290737: Pseudo dice [np.float32(0.7523), np.float32(0.5525), np.float32(0.788)] 
2025-03-17 05:30:15.294245: Epoch time: 38.51 s 
2025-03-17 05:30:15.297751: Yayy! New best EMA pseudo Dice: 0.6485999822616577 
2025-03-17 05:30:16.071468:  
2025-03-17 05:30:16.077527: Epoch 3 
2025-03-17 05:30:16.080675: Current learning rate: 0.00973 
2025-03-17 05:30:54.397288: train_loss -0.5427 
2025-03-17 05:30:54.402304: val_loss -0.5148 
2025-03-17 05:30:54.406815: Pseudo dice [np.float32(0.7608), np.float32(0.5258), np.float32(0.8104)] 
2025-03-17 05:30:54.409828: Epoch time: 38.33 s 
2025-03-17 05:30:54.413338: Yayy! New best EMA pseudo Dice: 0.6535999774932861 
2025-03-17 05:30:55.163466:  
2025-03-17 05:30:55.169031: Epoch 4 
2025-03-17 05:30:55.172667: Current learning rate: 0.00964 
2025-03-17 05:31:33.484454: train_loss -0.586 
2025-03-17 05:31:33.490549: val_loss -0.5641 
2025-03-17 05:31:33.494600: Pseudo dice [np.float32(0.793), np.float32(0.5909), np.float32(0.8332)] 
2025-03-17 05:31:33.497653: Epoch time: 38.32 s 
2025-03-17 05:31:33.500227: Yayy! New best EMA pseudo Dice: 0.6621999740600586 
2025-03-17 05:31:34.391458:  
2025-03-17 05:31:34.396513: Epoch 5 
2025-03-17 05:31:34.399588: Current learning rate: 0.00955 
2025-03-17 05:32:12.677604: train_loss -0.5729 
2025-03-17 05:32:12.683753: val_loss -0.5777 
2025-03-17 05:32:12.687311: Pseudo dice [np.float32(0.7744), np.float32(0.6441), np.float32(0.8342)] 
2025-03-17 05:32:12.690355: Epoch time: 38.29 s 
2025-03-17 05:32:12.693376: Yayy! New best EMA pseudo Dice: 0.6711000204086304 
2025-03-17 05:32:13.437507:  
2025-03-17 05:32:13.443066: Epoch 6 
2025-03-17 05:32:13.447166: Current learning rate: 0.00946 
2025-03-17 05:32:51.690387: train_loss -0.5824 
2025-03-17 05:32:51.696957: val_loss -0.5527 
2025-03-17 05:32:51.700486: Pseudo dice [np.float32(0.7649), np.float32(0.6456), np.float32(0.7995)] 
2025-03-17 05:32:51.704118: Epoch time: 38.25 s 
2025-03-17 05:32:51.707147: Yayy! New best EMA pseudo Dice: 0.6776000261306763 
2025-03-17 05:32:52.449142:  
2025-03-17 05:32:52.454699: Epoch 7 
2025-03-17 05:32:52.460836: Current learning rate: 0.00937 
2025-03-17 05:33:30.745349: train_loss -0.6183 
2025-03-17 05:33:30.751447: val_loss -0.5686 
2025-03-17 05:33:30.756546: Pseudo dice [np.float32(0.7785), np.float32(0.6434), np.float32(0.8291)] 
2025-03-17 05:33:30.759586: Epoch time: 38.3 s 
2025-03-17 05:33:30.762621: Yayy! New best EMA pseudo Dice: 0.6848999857902527 
2025-03-17 05:33:31.546465:  
2025-03-17 05:33:31.553001: Epoch 8 
2025-03-17 05:33:31.556027: Current learning rate: 0.00928 
2025-03-17 05:34:09.910020: train_loss -0.6164 
2025-03-17 05:34:09.916538: val_loss -0.5704 
2025-03-17 05:34:09.920043: Pseudo dice [np.float32(0.7786), np.float32(0.6396), np.float32(0.822)] 
2025-03-17 05:34:09.923055: Epoch time: 38.36 s 
2025-03-17 05:34:09.925596: Yayy! New best EMA pseudo Dice: 0.691100001335144 
2025-03-17 05:34:10.703128:  
2025-03-17 05:34:10.708664: Epoch 9 
2025-03-17 05:34:10.712203: Current learning rate: 0.00919 
2025-03-17 05:34:49.014804: train_loss -0.6105 
2025-03-17 05:34:49.022190: val_loss -0.5689 
2025-03-17 05:34:49.026208: Pseudo dice [np.float32(0.7853), np.float32(0.6051), np.float32(0.8248)] 
2025-03-17 05:34:49.029725: Epoch time: 38.31 s 
2025-03-17 05:34:49.032854: Yayy! New best EMA pseudo Dice: 0.6958000063896179 
2025-03-17 05:34:49.764844:  
2025-03-17 05:34:49.770465: Epoch 10 
2025-03-17 05:34:49.775034: Current learning rate: 0.0091 
2025-03-17 05:35:27.948199: train_loss -0.6089 
2025-03-17 05:35:27.954255: val_loss -0.5605 
2025-03-17 05:35:27.957779: Pseudo dice [np.float32(0.7792), np.float32(0.655), np.float32(0.8035)] 
2025-03-17 05:35:27.960805: Epoch time: 38.18 s 
2025-03-17 05:35:27.963834: Yayy! New best EMA pseudo Dice: 0.7008000016212463 
2025-03-17 05:35:28.699341:  
2025-03-17 05:35:28.704855: Epoch 11 
2025-03-17 05:35:28.708366: Current learning rate: 0.009 
2025-03-17 05:36:06.994426: train_loss -0.627 
2025-03-17 05:36:07.001603: val_loss -0.6051 
2025-03-17 05:36:07.005135: Pseudo dice [np.float32(0.8195), np.float32(0.6554), np.float32(0.8356)] 
2025-03-17 05:36:07.007653: Epoch time: 38.3 s 
2025-03-17 05:36:07.011678: Yayy! New best EMA pseudo Dice: 0.7077000141143799 
2025-03-17 05:36:07.750543:  
2025-03-17 05:36:07.756588: Epoch 12 
2025-03-17 05:36:07.759598: Current learning rate: 0.00891 
2025-03-17 05:36:46.058622: train_loss -0.6366 
2025-03-17 05:36:46.064633: val_loss -0.5812 
2025-03-17 05:36:46.068649: Pseudo dice [np.float32(0.7996), np.float32(0.6298), np.float32(0.8245)] 
2025-03-17 05:36:46.072655: Epoch time: 38.31 s 
2025-03-17 05:36:46.075161: Yayy! New best EMA pseudo Dice: 0.7121000289916992 
2025-03-17 05:36:46.972190:  
2025-03-17 05:36:46.977723: Epoch 13 
2025-03-17 05:36:46.981328: Current learning rate: 0.00882 
2025-03-17 05:37:25.273682: train_loss -0.6524 
2025-03-17 05:37:25.279860: val_loss -0.6095 
2025-03-17 05:37:25.283883: Pseudo dice [np.float32(0.8141), np.float32(0.6868), np.float32(0.8286)] 
2025-03-17 05:37:25.286908: Epoch time: 38.3 s 
2025-03-17 05:37:25.289981: Yayy! New best EMA pseudo Dice: 0.718500018119812 
2025-03-17 05:37:26.051174:  
2025-03-17 05:37:26.056700: Epoch 14 
2025-03-17 05:37:26.060208: Current learning rate: 0.00873 
2025-03-17 05:38:04.428402: train_loss -0.6439 
2025-03-17 05:38:04.434994: val_loss -0.6126 
2025-03-17 05:38:04.438046: Pseudo dice [np.float32(0.8018), np.float32(0.6949), np.float32(0.8655)] 
2025-03-17 05:38:04.442098: Epoch time: 38.38 s 
2025-03-17 05:38:04.445206: Yayy! New best EMA pseudo Dice: 0.7253999710083008 
2025-03-17 05:38:05.204710:  
2025-03-17 05:38:05.210225: Epoch 15 
2025-03-17 05:38:05.213733: Current learning rate: 0.00864 
2025-03-17 05:38:43.529658: train_loss -0.6399 
2025-03-17 05:38:43.535445: val_loss -0.6125 
2025-03-17 05:38:43.539573: Pseudo dice [np.float32(0.8043), np.float32(0.6968), np.float32(0.8392)] 
2025-03-17 05:38:43.542581: Epoch time: 38.33 s 
2025-03-17 05:38:43.546089: Yayy! New best EMA pseudo Dice: 0.73089998960495 
2025-03-17 05:38:44.321353:  
2025-03-17 05:38:44.327920: Epoch 16 
2025-03-17 05:38:44.330462: Current learning rate: 0.00855 
2025-03-17 05:39:22.612621: train_loss -0.6491 
2025-03-17 05:39:22.618716: val_loss -0.6221 
2025-03-17 05:39:22.621753: Pseudo dice [np.float32(0.8121), np.float32(0.6992), np.float32(0.8397)] 
2025-03-17 05:39:22.624220: Epoch time: 38.29 s 
2025-03-17 05:39:22.631396: Yayy! New best EMA pseudo Dice: 0.7361999750137329 
2025-03-17 05:39:23.435327:  
2025-03-17 05:39:23.441400: Epoch 17 
2025-03-17 05:39:23.444188: Current learning rate: 0.00846 
2025-03-17 05:40:01.696748: train_loss -0.6606 
2025-03-17 05:40:01.703876: val_loss -0.6175 
2025-03-17 05:40:01.707392: Pseudo dice [np.float32(0.8019), np.float32(0.6951), np.float32(0.8401)] 
2025-03-17 05:40:01.711404: Epoch time: 38.26 s 
2025-03-17 05:40:01.713913: Yayy! New best EMA pseudo Dice: 0.7404999732971191 
2025-03-17 05:40:02.489313:  
2025-03-17 05:40:02.493839: Epoch 18 
2025-03-17 05:40:02.497436: Current learning rate: 0.00836 
2025-03-17 05:40:40.821974: train_loss -0.6538 
2025-03-17 05:40:40.828545: val_loss -0.6273 
2025-03-17 05:40:40.832080: Pseudo dice [np.float32(0.8056), np.float32(0.6704), np.float32(0.8452)] 
2025-03-17 05:40:40.835604: Epoch time: 38.33 s 
2025-03-17 05:40:40.838636: Yayy! New best EMA pseudo Dice: 0.7437999844551086 
2025-03-17 05:40:41.599939:  
2025-03-17 05:40:41.604977: Epoch 19 
2025-03-17 05:40:41.608522: Current learning rate: 0.00827 
2025-03-17 05:41:19.899437: train_loss -0.6658 
2025-03-17 05:41:19.906457: val_loss -0.6071 
2025-03-17 05:41:19.910474: Pseudo dice [np.float32(0.798), np.float32(0.6881), np.float32(0.8253)] 
2025-03-17 05:41:19.912982: Epoch time: 38.3 s 
2025-03-17 05:41:19.916489: Yayy! New best EMA pseudo Dice: 0.746399998664856 
2025-03-17 05:41:20.837951:  
2025-03-17 05:41:20.842487: Epoch 20 
2025-03-17 05:41:20.845539: Current learning rate: 0.00818 
2025-03-17 05:41:59.007262: train_loss -0.6629 
2025-03-17 05:41:59.013779: val_loss -0.5891 
2025-03-17 05:41:59.017291: Pseudo dice [np.float32(0.7993), np.float32(0.6738), np.float32(0.8304)] 
2025-03-17 05:41:59.021299: Epoch time: 38.17 s 
2025-03-17 05:41:59.023807: Yayy! New best EMA pseudo Dice: 0.7486000061035156 
2025-03-17 05:41:59.786830:  
2025-03-17 05:41:59.792889: Epoch 21 
2025-03-17 05:41:59.795945: Current learning rate: 0.00809 
2025-03-17 05:42:38.019972: train_loss -0.6749 
2025-03-17 05:42:38.026050: val_loss -0.5814 
2025-03-17 05:42:38.029566: Pseudo dice [np.float32(0.8042), np.float32(0.6396), np.float32(0.8728)] 
2025-03-17 05:42:38.033070: Epoch time: 38.23 s 
2025-03-17 05:42:38.036079: Yayy! New best EMA pseudo Dice: 0.7509999871253967 
2025-03-17 05:42:38.797980:  
2025-03-17 05:42:38.804054: Epoch 22 
2025-03-17 05:42:38.807608: Current learning rate: 0.008 
2025-03-17 05:43:17.045358: train_loss -0.678 
2025-03-17 05:43:17.052946: val_loss -0.6308 
2025-03-17 05:43:17.056528: Pseudo dice [np.float32(0.8118), np.float32(0.6761), np.float32(0.8523)] 
2025-03-17 05:43:17.059571: Epoch time: 38.25 s 
2025-03-17 05:43:17.062097: Yayy! New best EMA pseudo Dice: 0.7538999915122986 
2025-03-17 05:43:17.802242:  
2025-03-17 05:43:17.807254: Epoch 23 
2025-03-17 05:43:17.810768: Current learning rate: 0.0079 
2025-03-17 05:43:56.147406: train_loss -0.6842 
2025-03-17 05:43:56.153696: val_loss -0.6149 
2025-03-17 05:43:56.157296: Pseudo dice [np.float32(0.8117), np.float32(0.706), np.float32(0.8395)] 
2025-03-17 05:43:56.160373: Epoch time: 38.35 s 
2025-03-17 05:43:56.163937: Yayy! New best EMA pseudo Dice: 0.7570000290870667 
2025-03-17 05:43:56.910408:  
2025-03-17 05:43:56.914137: Epoch 24 
2025-03-17 05:43:56.918152: Current learning rate: 0.00781 
2025-03-17 05:44:35.165604: train_loss -0.6848 
2025-03-17 05:44:35.169115: val_loss -0.6421 
2025-03-17 05:44:35.173127: Pseudo dice [np.float32(0.8205), np.float32(0.6935), np.float32(0.8544)] 
2025-03-17 05:44:35.176155: Epoch time: 38.26 s 
2025-03-17 05:44:35.180196: Yayy! New best EMA pseudo Dice: 0.7602999806404114 
2025-03-17 05:44:35.929956:  
2025-03-17 05:44:35.935015: Epoch 25 
2025-03-17 05:44:35.939062: Current learning rate: 0.00772 
2025-03-17 05:45:14.161353: train_loss -0.6805 
2025-03-17 05:45:14.167875: val_loss -0.6545 
2025-03-17 05:45:14.170383: Pseudo dice [np.float32(0.8235), np.float32(0.6888), np.float32(0.8337)] 
2025-03-17 05:45:14.174402: Epoch time: 38.23 s 
2025-03-17 05:45:14.176909: Yayy! New best EMA pseudo Dice: 0.762499988079071 
2025-03-17 05:45:14.914753:  
2025-03-17 05:45:14.921309: Epoch 26 
2025-03-17 05:45:14.924865: Current learning rate: 0.00763 
2025-03-17 05:45:53.222503: train_loss -0.682 
2025-03-17 05:45:53.229076: val_loss -0.599 
2025-03-17 05:45:53.232606: Pseudo dice [np.float32(0.7947), np.float32(0.6469), np.float32(0.8225)] 
2025-03-17 05:45:53.236135: Epoch time: 38.31 s 
2025-03-17 05:45:53.963973:  
2025-03-17 05:45:53.969526: Epoch 27 
2025-03-17 05:45:53.973151: Current learning rate: 0.00753 
2025-03-17 05:46:32.219813: train_loss -0.6742 
2025-03-17 05:46:32.225907: val_loss -0.6264 
2025-03-17 05:46:32.229933: Pseudo dice [np.float32(0.8185), np.float32(0.6926), np.float32(0.8562)] 
2025-03-17 05:46:32.232942: Epoch time: 38.26 s 
2025-03-17 05:46:32.236452: Yayy! New best EMA pseudo Dice: 0.7644000053405762 
2025-03-17 05:46:32.996024:  
2025-03-17 05:46:33.002064: Epoch 28 
2025-03-17 05:46:33.005099: Current learning rate: 0.00744 
2025-03-17 05:47:11.268117: train_loss -0.6942 
2025-03-17 05:47:11.274252: val_loss -0.5974 
2025-03-17 05:47:11.277809: Pseudo dice [np.float32(0.8144), np.float32(0.6544), np.float32(0.8397)] 
2025-03-17 05:47:11.280870: Epoch time: 38.27 s 
2025-03-17 05:47:11.283389: Yayy! New best EMA pseudo Dice: 0.7649000287055969 
2025-03-17 05:47:12.027461:  
2025-03-17 05:47:12.032474: Epoch 29 
2025-03-17 05:47:12.036983: Current learning rate: 0.00735 
2025-03-17 05:47:50.253694: train_loss -0.6783 
2025-03-17 05:47:50.259828: val_loss -0.6214 
2025-03-17 05:47:50.263350: Pseudo dice [np.float32(0.8186), np.float32(0.6339), np.float32(0.8593)] 
2025-03-17 05:47:50.266373: Epoch time: 38.23 s 
2025-03-17 05:47:50.269910: Yayy! New best EMA pseudo Dice: 0.765500009059906 
2025-03-17 05:47:51.022056:  
2025-03-17 05:47:51.027688: Epoch 30 
2025-03-17 05:47:51.031231: Current learning rate: 0.00725 
2025-03-17 05:48:29.303600: train_loss -0.6912 
2025-03-17 05:48:29.310168: val_loss -0.5956 
2025-03-17 05:48:29.313178: Pseudo dice [np.float32(0.8029), np.float32(0.6361), np.float32(0.852)] 
2025-03-17 05:48:29.316705: Epoch time: 38.28 s 
2025-03-17 05:48:29.905331:  
2025-03-17 05:48:29.910397: Epoch 31 
2025-03-17 05:48:29.913465: Current learning rate: 0.00716 
2025-03-17 05:49:08.252810: train_loss -0.6849 
2025-03-17 05:49:08.260093: val_loss -0.638 
2025-03-17 05:49:08.264107: Pseudo dice [np.float32(0.8251), np.float32(0.7009), np.float32(0.8355)] 
2025-03-17 05:49:08.267618: Epoch time: 38.35 s 
2025-03-17 05:49:08.271633: Yayy! New best EMA pseudo Dice: 0.7674999833106995 
2025-03-17 05:49:09.020180:  
2025-03-17 05:49:09.025806: Epoch 32 
2025-03-17 05:49:09.029838: Current learning rate: 0.00707 
2025-03-17 05:49:47.269685: train_loss -0.6893 
2025-03-17 05:49:47.276764: val_loss -0.6654 
2025-03-17 05:49:47.279810: Pseudo dice [np.float32(0.8301), np.float32(0.7294), np.float32(0.8596)] 
2025-03-17 05:49:47.282335: Epoch time: 38.25 s 
2025-03-17 05:49:47.288404: Yayy! New best EMA pseudo Dice: 0.771399974822998 
2025-03-17 05:49:48.046595:  
2025-03-17 05:49:48.052674: Epoch 33 
2025-03-17 05:49:48.055747: Current learning rate: 0.00697 
2025-03-17 05:50:26.340115: train_loss -0.6871 
2025-03-17 05:50:26.347142: val_loss -0.6704 
2025-03-17 05:50:26.350153: Pseudo dice [np.float32(0.8422), np.float32(0.6742), np.float32(0.8652)] 
2025-03-17 05:50:26.353661: Epoch time: 38.29 s 
2025-03-17 05:50:26.356168: Yayy! New best EMA pseudo Dice: 0.7735999822616577 
2025-03-17 05:50:27.123310:  
2025-03-17 05:50:27.128346: Epoch 34 
2025-03-17 05:50:27.132165: Current learning rate: 0.00688 
2025-03-17 05:51:05.442662: train_loss -0.7022 
2025-03-17 05:51:05.448731: val_loss -0.6113 
2025-03-17 05:51:05.452781: Pseudo dice [np.float32(0.8021), np.float32(0.6732), np.float32(0.8526)] 
2025-03-17 05:51:05.455842: Epoch time: 38.32 s 
2025-03-17 05:51:05.459385: Yayy! New best EMA pseudo Dice: 0.7738999724388123 
2025-03-17 05:51:06.382787:  
2025-03-17 05:51:06.387806: Epoch 35 
2025-03-17 05:51:06.391316: Current learning rate: 0.00679 
2025-03-17 05:51:44.649948: train_loss -0.6813 
2025-03-17 05:51:44.656536: val_loss -0.6319 
2025-03-17 05:51:44.660172: Pseudo dice [np.float32(0.8207), np.float32(0.7101), np.float32(0.8084)] 
2025-03-17 05:51:44.663212: Epoch time: 38.27 s 
2025-03-17 05:51:44.666743: Yayy! New best EMA pseudo Dice: 0.7745000123977661 
2025-03-17 05:51:45.435230:  
2025-03-17 05:51:45.440858: Epoch 36 
2025-03-17 05:51:45.444419: Current learning rate: 0.00669 
2025-03-17 05:52:23.741395: train_loss -0.6944 
2025-03-17 05:52:23.747975: val_loss -0.64 
2025-03-17 05:52:23.751577: Pseudo dice [np.float32(0.8104), np.float32(0.7278), np.float32(0.8561)] 
2025-03-17 05:52:23.755171: Epoch time: 38.31 s 
2025-03-17 05:52:23.757695: Yayy! New best EMA pseudo Dice: 0.7767999768257141 
2025-03-17 05:52:24.524689:  
2025-03-17 05:52:24.530256: Epoch 37 
2025-03-17 05:52:24.533906: Current learning rate: 0.0066 
2025-03-17 05:53:03.033110: train_loss -0.6958 
2025-03-17 05:53:03.039734: val_loss -0.6381 
2025-03-17 05:53:03.045967: Pseudo dice [np.float32(0.8285), np.float32(0.688), np.float32(0.8617)] 
2025-03-17 05:53:03.049994: Epoch time: 38.51 s 
2025-03-17 05:53:03.054034: Yayy! New best EMA pseudo Dice: 0.7784000039100647 
2025-03-17 05:53:03.852772:  
2025-03-17 05:53:03.857849: Epoch 38 
2025-03-17 05:53:03.861400: Current learning rate: 0.0065 
2025-03-17 05:53:42.200257: train_loss -0.7088 
2025-03-17 05:53:42.206955: val_loss -0.6694 
2025-03-17 05:53:42.210510: Pseudo dice [np.float32(0.8261), np.float32(0.7131), np.float32(0.877)] 
2025-03-17 05:53:42.213084: Epoch time: 38.35 s 
2025-03-17 05:53:42.215605: Yayy! New best EMA pseudo Dice: 0.7810999751091003 
2025-03-17 05:53:42.999399:  
2025-03-17 05:53:43.004356: Epoch 39 
2025-03-17 05:53:43.008869: Current learning rate: 0.00641 
2025-03-17 05:54:21.302600: train_loss -0.7074 
2025-03-17 05:54:21.309725: val_loss -0.6046 
2025-03-17 05:54:21.312776: Pseudo dice [np.float32(0.8129), np.float32(0.641), np.float32(0.8395)] 
2025-03-17 05:54:21.316390: Epoch time: 38.3 s 
2025-03-17 05:54:21.922552:  
2025-03-17 05:54:21.928068: Epoch 40 
2025-03-17 05:54:21.931580: Current learning rate: 0.00631 
2025-03-17 05:55:00.216568: train_loss -0.7052 
2025-03-17 05:55:00.223089: val_loss -0.6333 
2025-03-17 05:55:00.226600: Pseudo dice [np.float32(0.8217), np.float32(0.6961), np.float32(0.8325)] 
2025-03-17 05:55:00.230615: Epoch time: 38.3 s 
2025-03-17 05:55:00.833699:  
2025-03-17 05:55:00.839263: Epoch 41 
2025-03-17 05:55:00.841814: Current learning rate: 0.00622 
2025-03-17 05:55:39.095008: train_loss -0.7108 
2025-03-17 05:55:39.101023: val_loss -0.6135 
2025-03-17 05:55:39.105036: Pseudo dice [np.float32(0.828), np.float32(0.7019), np.float32(0.836)] 
2025-03-17 05:55:39.108543: Epoch time: 38.26 s 
2025-03-17 05:55:39.839882:  
2025-03-17 05:55:39.846954: Epoch 42 
2025-03-17 05:55:39.850555: Current learning rate: 0.00612 
2025-03-17 05:56:18.073847: train_loss -0.7178 
2025-03-17 05:56:18.080874: val_loss -0.6077 
2025-03-17 05:56:18.084895: Pseudo dice [np.float32(0.8038), np.float32(0.6485), np.float32(0.836)] 
2025-03-17 05:56:18.088407: Epoch time: 38.23 s 
2025-03-17 05:56:18.656260:  
2025-03-17 05:56:18.662783: Epoch 43 
2025-03-17 05:56:18.666301: Current learning rate: 0.00603 
2025-03-17 05:56:56.897440: train_loss -0.7124 
2025-03-17 05:56:56.904052: val_loss -0.6252 
2025-03-17 05:56:56.907743: Pseudo dice [np.float32(0.8026), np.float32(0.6943), np.float32(0.8629)] 
2025-03-17 05:56:56.911802: Epoch time: 38.24 s 
2025-03-17 05:56:57.487079:  
2025-03-17 05:56:57.492405: Epoch 44 
2025-03-17 05:56:57.496459: Current learning rate: 0.00593 
2025-03-17 05:57:36.111430: train_loss -0.6976 
2025-03-17 05:57:36.119123: val_loss -0.6456 
2025-03-17 05:57:36.121668: Pseudo dice [np.float32(0.8282), np.float32(0.7021), np.float32(0.8602)] 
2025-03-17 05:57:36.126251: Epoch time: 38.63 s 
2025-03-17 05:57:36.129307: Yayy! New best EMA pseudo Dice: 0.7814000248908997 
2025-03-17 05:57:36.870942:  
2025-03-17 05:57:36.876958: Epoch 45 
2025-03-17 05:57:36.880966: Current learning rate: 0.00584 
2025-03-17 05:58:15.207443: train_loss -0.7071 
2025-03-17 05:58:15.212998: val_loss -0.6559 
2025-03-17 05:58:15.217648: Pseudo dice [np.float32(0.8349), np.float32(0.7025), np.float32(0.8394)] 
2025-03-17 05:58:15.220675: Epoch time: 38.34 s 
2025-03-17 05:58:15.224189: Yayy! New best EMA pseudo Dice: 0.7825000286102295 
2025-03-17 05:58:15.948052:  
2025-03-17 05:58:15.954068: Epoch 46 
2025-03-17 05:58:15.958074: Current learning rate: 0.00574 
2025-03-17 05:58:54.273893: train_loss -0.7146 
2025-03-17 05:58:54.280420: val_loss -0.6468 
2025-03-17 05:58:54.283931: Pseudo dice [np.float32(0.8057), np.float32(0.7123), np.float32(0.8401)] 
2025-03-17 05:58:54.286946: Epoch time: 38.33 s 
2025-03-17 05:58:54.290459: Yayy! New best EMA pseudo Dice: 0.7828999757766724 
2025-03-17 05:58:55.041657:  
2025-03-17 05:58:55.047725: Epoch 47 
2025-03-17 05:58:55.051291: Current learning rate: 0.00565 
2025-03-17 05:59:33.371492: train_loss -0.7064 
2025-03-17 05:59:33.377082: val_loss -0.6501 
2025-03-17 05:59:33.381144: Pseudo dice [np.float32(0.8186), np.float32(0.7387), np.float32(0.8676)] 
2025-03-17 05:59:33.384737: Epoch time: 38.33 s 
2025-03-17 05:59:33.389827: Yayy! New best EMA pseudo Dice: 0.7853999733924866 
2025-03-17 05:59:34.121205:  
2025-03-17 05:59:34.127728: Epoch 48 
2025-03-17 05:59:34.131740: Current learning rate: 0.00555 
2025-03-17 06:00:12.422984: train_loss -0.7087 
2025-03-17 06:00:12.429000: val_loss -0.6454 
2025-03-17 06:00:12.433010: Pseudo dice [np.float32(0.8279), np.float32(0.7059), np.float32(0.8652)] 
2025-03-17 06:00:12.435515: Epoch time: 38.3 s 
2025-03-17 06:00:12.439025: Yayy! New best EMA pseudo Dice: 0.7868000268936157 
2025-03-17 06:00:13.172870:  
2025-03-17 06:00:13.178445: Epoch 49 
2025-03-17 06:00:13.182495: Current learning rate: 0.00546 
2025-03-17 06:00:51.471764: train_loss -0.7161 
2025-03-17 06:00:51.477784: val_loss -0.6361 
2025-03-17 06:00:51.481829: Pseudo dice [np.float32(0.8169), np.float32(0.6676), np.float32(0.8708)] 
2025-03-17 06:00:51.485870: Epoch time: 38.3 s 
2025-03-17 06:00:52.365592:  
2025-03-17 06:00:52.370628: Epoch 50 
2025-03-17 06:00:52.374145: Current learning rate: 0.00536 
2025-03-17 06:01:30.631737: train_loss -0.7113 
2025-03-17 06:01:30.638809: val_loss -0.6484 
2025-03-17 06:01:30.642347: Pseudo dice [np.float32(0.8217), np.float32(0.7168), np.float32(0.8474)] 
2025-03-17 06:01:30.645384: Epoch time: 38.27 s 
2025-03-17 06:01:30.649414: Yayy! New best EMA pseudo Dice: 0.7875000238418579 
2025-03-17 06:01:31.392785:  
2025-03-17 06:01:31.398765: Epoch 51 
2025-03-17 06:01:31.402776: Current learning rate: 0.00526 
2025-03-17 06:02:09.620762: train_loss -0.7158 
2025-03-17 06:02:09.627785: val_loss -0.6671 
2025-03-17 06:02:09.630793: Pseudo dice [np.float32(0.8382), np.float32(0.7037), np.float32(0.8555)] 
2025-03-17 06:02:09.634305: Epoch time: 38.23 s 
2025-03-17 06:02:09.638318: Yayy! New best EMA pseudo Dice: 0.7886999845504761 
2025-03-17 06:02:10.382206:  
2025-03-17 06:02:10.387779: Epoch 52 
2025-03-17 06:02:10.392351: Current learning rate: 0.00517 
2025-03-17 06:02:48.703094: train_loss -0.7188 
2025-03-17 06:02:48.710206: val_loss -0.6404 
2025-03-17 06:02:48.713782: Pseudo dice [np.float32(0.8334), np.float32(0.6829), np.float32(0.8482)] 
2025-03-17 06:02:48.717360: Epoch time: 38.32 s 
2025-03-17 06:02:49.292971:  
2025-03-17 06:02:49.297000: Epoch 53 
2025-03-17 06:02:49.301026: Current learning rate: 0.00507 
2025-03-17 06:03:27.552177: train_loss -0.7223 
2025-03-17 06:03:27.560376: val_loss -0.6368 
2025-03-17 06:03:27.563933: Pseudo dice [np.float32(0.8274), np.float32(0.7252), np.float32(0.8485)] 
2025-03-17 06:03:27.566979: Epoch time: 38.26 s 
2025-03-17 06:03:27.570082: Yayy! New best EMA pseudo Dice: 0.7897999882698059 
2025-03-17 06:03:28.314413:  
2025-03-17 06:03:28.320927: Epoch 54 
2025-03-17 06:03:28.324446: Current learning rate: 0.00497 
2025-03-17 06:04:06.626318: train_loss -0.7223 
2025-03-17 06:04:06.632128: val_loss -0.629 
2025-03-17 06:04:06.635696: Pseudo dice [np.float32(0.8067), np.float32(0.7395), np.float32(0.8514)] 
2025-03-17 06:04:06.639714: Epoch time: 38.31 s 
2025-03-17 06:04:06.643233: Yayy! New best EMA pseudo Dice: 0.7907000184059143 
2025-03-17 06:04:07.389431:  
2025-03-17 06:04:07.395029: Epoch 55 
2025-03-17 06:04:07.397644: Current learning rate: 0.00487 
2025-03-17 06:04:45.658417: train_loss -0.712 
2025-03-17 06:04:45.664432: val_loss -0.6493 
2025-03-17 06:04:45.669499: Pseudo dice [np.float32(0.8317), np.float32(0.7439), np.float32(0.8695)] 
2025-03-17 06:04:45.673019: Epoch time: 38.27 s 
2025-03-17 06:04:45.676033: Yayy! New best EMA pseudo Dice: 0.7932000160217285 
2025-03-17 06:04:46.426705:  
2025-03-17 06:04:46.432260: Epoch 56 
2025-03-17 06:04:46.434804: Current learning rate: 0.00478 
2025-03-17 06:05:24.654559: train_loss -0.7223 
2025-03-17 06:05:24.660630: val_loss -0.6545 
2025-03-17 06:05:24.664637: Pseudo dice [np.float32(0.8133), np.float32(0.7358), np.float32(0.8581)] 
2025-03-17 06:05:24.668155: Epoch time: 38.23 s 
2025-03-17 06:05:24.671670: Yayy! New best EMA pseudo Dice: 0.7940999865531921 
2025-03-17 06:05:25.421803:  
2025-03-17 06:05:25.427388: Epoch 57 
2025-03-17 06:05:25.429959: Current learning rate: 0.00468 
2025-03-17 06:06:03.765327: train_loss -0.724 
2025-03-17 06:06:03.771856: val_loss -0.6518 
2025-03-17 06:06:03.775376: Pseudo dice [np.float32(0.8272), np.float32(0.6767), np.float32(0.8492)] 
2025-03-17 06:06:03.779392: Epoch time: 38.34 s 
2025-03-17 06:06:04.510463:  
2025-03-17 06:06:04.516546: Epoch 58 
2025-03-17 06:06:04.519568: Current learning rate: 0.00458 
2025-03-17 06:06:42.797102: train_loss -0.7246 
2025-03-17 06:06:42.804649: val_loss -0.5923 
2025-03-17 06:06:42.808680: Pseudo dice [np.float32(0.807), np.float32(0.6742), np.float32(0.8352)] 
2025-03-17 06:06:42.812236: Epoch time: 38.29 s 
2025-03-17 06:06:43.399395:  
2025-03-17 06:06:43.405909: Epoch 59 
2025-03-17 06:06:43.409418: Current learning rate: 0.00448 
2025-03-17 06:07:21.679356: train_loss -0.7234 
2025-03-17 06:07:21.685450: val_loss -0.6172 
2025-03-17 06:07:21.687548: Pseudo dice [np.float32(0.824), np.float32(0.6836), np.float32(0.8573)] 
2025-03-17 06:07:21.692078: Epoch time: 38.28 s 
2025-03-17 06:07:22.288454:  
2025-03-17 06:07:22.294480: Epoch 60 
2025-03-17 06:07:22.297992: Current learning rate: 0.00438 
2025-03-17 06:08:00.539943: train_loss -0.7219 
2025-03-17 06:08:00.547487: val_loss -0.6332 
2025-03-17 06:08:00.550497: Pseudo dice [np.float32(0.8003), np.float32(0.6748), np.float32(0.8449)] 
2025-03-17 06:08:00.554004: Epoch time: 38.25 s 
2025-03-17 06:08:01.136389:  
2025-03-17 06:08:01.141979: Epoch 61 
2025-03-17 06:08:01.145582: Current learning rate: 0.00429 
2025-03-17 06:08:39.346470: train_loss -0.7274 
2025-03-17 06:08:39.352667: val_loss -0.6235 
2025-03-17 06:08:39.356760: Pseudo dice [np.float32(0.8122), np.float32(0.6828), np.float32(0.8457)] 
2025-03-17 06:08:39.360325: Epoch time: 38.21 s 
2025-03-17 06:08:39.944875:  
2025-03-17 06:08:39.950399: Epoch 62 
2025-03-17 06:08:39.953918: Current learning rate: 0.00419 
2025-03-17 06:09:18.258589: train_loss -0.725 
2025-03-17 06:09:18.264941: val_loss -0.621 
2025-03-17 06:09:18.268976: Pseudo dice [np.float32(0.8175), np.float32(0.7054), np.float32(0.8546)] 
2025-03-17 06:09:18.270990: Epoch time: 38.31 s 
2025-03-17 06:09:18.871034:  
2025-03-17 06:09:18.876579: Epoch 63 
2025-03-17 06:09:18.880763: Current learning rate: 0.00409 
2025-03-17 06:09:57.073485: train_loss -0.724 
2025-03-17 06:09:57.080015: val_loss -0.6467 
2025-03-17 06:09:57.083535: Pseudo dice [np.float32(0.8136), np.float32(0.7021), np.float32(0.8719)] 
2025-03-17 06:09:57.087553: Epoch time: 38.2 s 
2025-03-17 06:09:57.686899:  
2025-03-17 06:09:57.691920: Epoch 64 
2025-03-17 06:09:57.695439: Current learning rate: 0.00399 
2025-03-17 06:10:36.031744: train_loss -0.7326 
2025-03-17 06:10:36.038820: val_loss -0.6482 
2025-03-17 06:10:36.042887: Pseudo dice [np.float32(0.8208), np.float32(0.7133), np.float32(0.8742)] 
2025-03-17 06:10:36.046414: Epoch time: 38.35 s 
2025-03-17 06:10:36.632463:  
2025-03-17 06:10:36.638512: Epoch 65 
2025-03-17 06:10:36.641603: Current learning rate: 0.00389 
2025-03-17 06:11:14.915912: train_loss -0.7346 
2025-03-17 06:11:14.922464: val_loss -0.6453 
2025-03-17 06:11:14.926015: Pseudo dice [np.float32(0.832), np.float32(0.718), np.float32(0.8636)] 
2025-03-17 06:11:14.929134: Epoch time: 38.28 s 
2025-03-17 06:11:15.665982:  
2025-03-17 06:11:15.670534: Epoch 66 
2025-03-17 06:11:15.673601: Current learning rate: 0.00379 
2025-03-17 06:11:53.943398: train_loss -0.7342 
2025-03-17 06:11:53.950932: val_loss -0.6335 
2025-03-17 06:11:53.954444: Pseudo dice [np.float32(0.8132), np.float32(0.7279), np.float32(0.847)] 
2025-03-17 06:11:53.957459: Epoch time: 38.28 s 
2025-03-17 06:11:54.547794:  
2025-03-17 06:11:54.553319: Epoch 67 
2025-03-17 06:11:54.556837: Current learning rate: 0.00369 
2025-03-17 06:12:32.860590: train_loss -0.7377 
2025-03-17 06:12:32.867173: val_loss -0.6254 
2025-03-17 06:12:32.870711: Pseudo dice [np.float32(0.8408), np.float32(0.6773), np.float32(0.8693)] 
2025-03-17 06:12:32.874727: Epoch time: 38.31 s 
2025-03-17 06:12:33.469183:  
2025-03-17 06:12:33.474262: Epoch 68 
2025-03-17 06:12:33.478315: Current learning rate: 0.00359 
2025-03-17 06:13:11.692988: train_loss -0.7278 
2025-03-17 06:13:11.699604: val_loss -0.6495 
2025-03-17 06:13:11.703628: Pseudo dice [np.float32(0.8211), np.float32(0.6858), np.float32(0.8608)] 
2025-03-17 06:13:11.707133: Epoch time: 38.23 s 
2025-03-17 06:13:12.298429:  
2025-03-17 06:13:12.304518: Epoch 69 
2025-03-17 06:13:12.307567: Current learning rate: 0.00349 
2025-03-17 06:13:50.578253: train_loss -0.7288 
2025-03-17 06:13:50.584900: val_loss -0.6207 
2025-03-17 06:13:50.588058: Pseudo dice [np.float32(0.8154), np.float32(0.7177), np.float32(0.8459)] 
2025-03-17 06:13:50.592102: Epoch time: 38.28 s 
2025-03-17 06:13:51.193992:  
2025-03-17 06:13:51.200061: Epoch 70 
2025-03-17 06:13:51.203139: Current learning rate: 0.00338 
2025-03-17 06:14:29.475161: train_loss -0.7285 
2025-03-17 06:14:29.481733: val_loss -0.64 
2025-03-17 06:14:29.485277: Pseudo dice [np.float32(0.8139), np.float32(0.7062), np.float32(0.866)] 
2025-03-17 06:14:29.488848: Epoch time: 38.28 s 
2025-03-17 06:14:30.099849:  
2025-03-17 06:14:30.104902: Epoch 71 
2025-03-17 06:14:30.107984: Current learning rate: 0.00328 
2025-03-17 06:15:08.473269: train_loss -0.7353 
2025-03-17 06:15:08.480407: val_loss -0.6522 
2025-03-17 06:15:08.483447: Pseudo dice [np.float32(0.8336), np.float32(0.6977), np.float32(0.8692)] 
2025-03-17 06:15:08.487495: Epoch time: 38.37 s 
2025-03-17 06:15:09.094255:  
2025-03-17 06:15:09.100775: Epoch 72 
2025-03-17 06:15:09.104794: Current learning rate: 0.00318 
2025-03-17 06:15:47.364677: train_loss -0.7418 
2025-03-17 06:15:47.371303: val_loss -0.6433 
2025-03-17 06:15:47.375619: Pseudo dice [np.float32(0.821), np.float32(0.7145), np.float32(0.8589)] 
2025-03-17 06:15:47.379126: Epoch time: 38.27 s 
2025-03-17 06:15:47.974791:  
2025-03-17 06:15:47.980369: Epoch 73 
2025-03-17 06:15:47.984933: Current learning rate: 0.00308 
2025-03-17 06:16:26.293200: train_loss -0.7359 
2025-03-17 06:16:26.299244: val_loss -0.6248 
2025-03-17 06:16:26.303253: Pseudo dice [np.float32(0.8188), np.float32(0.6865), np.float32(0.8617)] 
2025-03-17 06:16:26.306761: Epoch time: 38.32 s 
2025-03-17 06:16:27.074698:  
2025-03-17 06:16:27.080768: Epoch 74 
2025-03-17 06:16:27.083310: Current learning rate: 0.00297 
2025-03-17 06:17:05.303689: train_loss -0.732 
2025-03-17 06:17:05.309746: val_loss -0.6406 
2025-03-17 06:17:05.313783: Pseudo dice [np.float32(0.8327), np.float32(0.6676), np.float32(0.8469)] 
2025-03-17 06:17:05.316861: Epoch time: 38.23 s 
2025-03-17 06:17:05.910144:  
2025-03-17 06:17:05.916682: Epoch 75 
2025-03-17 06:17:05.920231: Current learning rate: 0.00287 
2025-03-17 06:17:44.151159: train_loss -0.7395 
2025-03-17 06:17:44.157234: val_loss -0.6287 
2025-03-17 06:17:44.161786: Pseudo dice [np.float32(0.8131), np.float32(0.7236), np.float32(0.8675)] 
2025-03-17 06:17:44.164817: Epoch time: 38.24 s 
2025-03-17 06:17:44.762708:  
2025-03-17 06:17:44.768722: Epoch 76 
2025-03-17 06:17:44.773737: Current learning rate: 0.00277 
2025-03-17 06:18:23.039160: train_loss -0.7385 
2025-03-17 06:18:23.046287: val_loss -0.6408 
2025-03-17 06:18:23.050395: Pseudo dice [np.float32(0.8412), np.float32(0.7187), np.float32(0.8638)] 
2025-03-17 06:18:23.053997: Epoch time: 38.28 s 
2025-03-17 06:18:23.057106: Yayy! New best EMA pseudo Dice: 0.794700026512146 
2025-03-17 06:18:23.842232:  
2025-03-17 06:18:23.846759: Epoch 77 
2025-03-17 06:18:23.850352: Current learning rate: 0.00266 
2025-03-17 06:19:02.144173: train_loss -0.7392 
2025-03-17 06:19:02.150263: val_loss -0.6124 
2025-03-17 06:19:02.153342: Pseudo dice [np.float32(0.8189), np.float32(0.6398), np.float32(0.8554)] 
2025-03-17 06:19:02.157505: Epoch time: 38.3 s 
2025-03-17 06:19:02.758176:  
2025-03-17 06:19:02.763691: Epoch 78 
2025-03-17 06:19:02.767201: Current learning rate: 0.00256 
2025-03-17 06:19:41.011829: train_loss -0.7319 
2025-03-17 06:19:41.018928: val_loss -0.6275 
2025-03-17 06:19:41.021944: Pseudo dice [np.float32(0.8181), np.float32(0.6944), np.float32(0.8573)] 
2025-03-17 06:19:41.025458: Epoch time: 38.25 s 
2025-03-17 06:19:41.634952:  
2025-03-17 06:19:41.640008: Epoch 79 
2025-03-17 06:19:41.644612: Current learning rate: 0.00245 
2025-03-17 06:20:19.966480: train_loss -0.7396 
2025-03-17 06:20:19.972567: val_loss -0.6503 
2025-03-17 06:20:19.976713: Pseudo dice [np.float32(0.8286), np.float32(0.7056), np.float32(0.8797)] 
2025-03-17 06:20:19.980726: Epoch time: 38.33 s 
2025-03-17 06:20:20.576608:  
2025-03-17 06:20:20.583200: Epoch 80 
2025-03-17 06:20:20.585744: Current learning rate: 0.00235 
2025-03-17 06:20:58.926780: train_loss -0.7337 
2025-03-17 06:20:58.934439: val_loss -0.6161 
2025-03-17 06:20:58.938148: Pseudo dice [np.float32(0.7967), np.float32(0.7184), np.float32(0.8595)] 
2025-03-17 06:20:58.941685: Epoch time: 38.35 s 
2025-03-17 06:20:59.710598:  
2025-03-17 06:20:59.717118: Epoch 81 
2025-03-17 06:20:59.720634: Current learning rate: 0.00224 
2025-03-17 06:21:38.009321: train_loss -0.7468 
2025-03-17 06:21:38.018761: val_loss -0.6726 
2025-03-17 06:21:38.021829: Pseudo dice [np.float32(0.8324), np.float32(0.7185), np.float32(0.8618)] 
2025-03-17 06:21:38.025869: Epoch time: 38.3 s 
2025-03-17 06:21:38.627415:  
2025-03-17 06:21:38.632970: Epoch 82 
2025-03-17 06:21:38.637530: Current learning rate: 0.00214 
2025-03-17 06:22:16.832497: train_loss -0.7484 
2025-03-17 06:22:16.839592: val_loss -0.6575 
2025-03-17 06:22:16.843706: Pseudo dice [np.float32(0.8326), np.float32(0.7419), np.float32(0.8642)] 
2025-03-17 06:22:16.847245: Epoch time: 38.21 s 
2025-03-17 06:22:16.850283: Yayy! New best EMA pseudo Dice: 0.7961999773979187 
2025-03-17 06:22:17.594935:  
2025-03-17 06:22:17.600024: Epoch 83 
2025-03-17 06:22:17.603647: Current learning rate: 0.00203 
2025-03-17 06:22:55.899566: train_loss -0.7463 
2025-03-17 06:22:55.905583: val_loss -0.6541 
2025-03-17 06:22:55.909596: Pseudo dice [np.float32(0.82), np.float32(0.7558), np.float32(0.8534)] 
2025-03-17 06:22:55.913108: Epoch time: 38.31 s 
2025-03-17 06:22:55.916617: Yayy! New best EMA pseudo Dice: 0.7975000143051147 
2025-03-17 06:22:56.668284:  
2025-03-17 06:22:56.673849: Epoch 84 
2025-03-17 06:22:56.677945: Current learning rate: 0.00192 
2025-03-17 06:23:35.020709: train_loss -0.7436 
2025-03-17 06:23:35.028225: val_loss -0.6499 
2025-03-17 06:23:35.032238: Pseudo dice [np.float32(0.8321), np.float32(0.6824), np.float32(0.864)] 
2025-03-17 06:23:35.035746: Epoch time: 38.35 s 
2025-03-17 06:23:35.607181:  
2025-03-17 06:23:35.612788: Epoch 85 
2025-03-17 06:23:35.617361: Current learning rate: 0.00181 
2025-03-17 06:24:13.837955: train_loss -0.7544 
2025-03-17 06:24:13.845080: val_loss -0.6472 
2025-03-17 06:24:13.848611: Pseudo dice [np.float32(0.821), np.float32(0.7553), np.float32(0.848)] 
2025-03-17 06:24:13.851640: Epoch time: 38.23 s 
2025-03-17 06:24:13.855668: Yayy! New best EMA pseudo Dice: 0.7982000112533569 
2025-03-17 06:24:14.591919:  
2025-03-17 06:24:14.597950: Epoch 86 
2025-03-17 06:24:14.601988: Current learning rate: 0.0017 
2025-03-17 06:24:52.915839: train_loss -0.7469 
2025-03-17 06:24:52.922401: val_loss -0.6753 
2025-03-17 06:24:52.925947: Pseudo dice [np.float32(0.8336), np.float32(0.7775), np.float32(0.8865)] 
2025-03-17 06:24:52.929508: Epoch time: 38.32 s 
2025-03-17 06:24:52.932046: Yayy! New best EMA pseudo Dice: 0.8015999794006348 
2025-03-17 06:24:53.664821:  
2025-03-17 06:24:53.670856: Epoch 87 
2025-03-17 06:24:53.674885: Current learning rate: 0.00159 
2025-03-17 06:25:31.895405: train_loss -0.7514 
2025-03-17 06:25:31.902460: val_loss -0.6402 
2025-03-17 06:25:31.905498: Pseudo dice [np.float32(0.8215), np.float32(0.7445), np.float32(0.8543)] 
2025-03-17 06:25:31.909022: Epoch time: 38.23 s 
2025-03-17 06:25:31.912014: Yayy! New best EMA pseudo Dice: 0.8021000027656555 
2025-03-17 06:25:32.646076:  
2025-03-17 06:25:32.652580: Epoch 88 
2025-03-17 06:25:32.656179: Current learning rate: 0.00148 
2025-03-17 06:26:10.940436: train_loss -0.7505 
2025-03-17 06:26:10.946995: val_loss -0.6564 
2025-03-17 06:26:10.950540: Pseudo dice [np.float32(0.8133), np.float32(0.7423), np.float32(0.8692)] 
2025-03-17 06:26:10.954566: Epoch time: 38.3 s 
2025-03-17 06:26:10.958101: Yayy! New best EMA pseudo Dice: 0.8026999831199646 
2025-03-17 06:26:11.852615:  
2025-03-17 06:26:11.858129: Epoch 89 
2025-03-17 06:26:11.862637: Current learning rate: 0.00137 
2025-03-17 06:26:50.134089: train_loss -0.7511 
2025-03-17 06:26:50.140676: val_loss -0.638 
2025-03-17 06:26:50.144203: Pseudo dice [np.float32(0.8234), np.float32(0.7287), np.float32(0.8406)] 
2025-03-17 06:26:50.147746: Epoch time: 38.28 s 
2025-03-17 06:26:50.713484:  
2025-03-17 06:26:50.719001: Epoch 90 
2025-03-17 06:26:50.722509: Current learning rate: 0.00126 
2025-03-17 06:27:28.983783: train_loss -0.7512 
2025-03-17 06:27:28.990800: val_loss -0.6198 
2025-03-17 06:27:28.993808: Pseudo dice [np.float32(0.8139), np.float32(0.7183), np.float32(0.8644)] 
2025-03-17 06:27:28.997316: Epoch time: 38.27 s 
2025-03-17 06:27:29.560787:  
2025-03-17 06:27:29.567356: Epoch 91 
2025-03-17 06:27:29.570901: Current learning rate: 0.00115 
2025-03-17 06:28:07.853205: train_loss -0.7567 
2025-03-17 06:28:07.860263: val_loss -0.637 
2025-03-17 06:28:07.863289: Pseudo dice [np.float32(0.8331), np.float32(0.7402), np.float32(0.8493)] 
2025-03-17 06:28:07.867319: Epoch time: 38.29 s 
2025-03-17 06:28:08.435484:  
2025-03-17 06:28:08.442056: Epoch 92 
2025-03-17 06:28:08.445638: Current learning rate: 0.00103 
2025-03-17 06:28:46.731164: train_loss -0.7468 
2025-03-17 06:28:46.737722: val_loss -0.6189 
2025-03-17 06:28:46.741744: Pseudo dice [np.float32(0.8335), np.float32(0.7086), np.float32(0.8696)] 
2025-03-17 06:28:46.745268: Epoch time: 38.3 s 
2025-03-17 06:28:47.317728:  
2025-03-17 06:28:47.323273: Epoch 93 
2025-03-17 06:28:47.330291: Current learning rate: 0.00091 
2025-03-17 06:29:25.636496: train_loss -0.7479 
2025-03-17 06:29:25.644114: val_loss -0.6545 
2025-03-17 06:29:25.647623: Pseudo dice [np.float32(0.8183), np.float32(0.7199), np.float32(0.8657)] 
2025-03-17 06:29:25.651129: Epoch time: 38.32 s 
2025-03-17 06:29:26.215471:  
2025-03-17 06:29:26.222028: Epoch 94 
2025-03-17 06:29:26.225593: Current learning rate: 0.00079 
2025-03-17 06:30:04.492158: train_loss -0.7574 
2025-03-17 06:30:04.499729: val_loss -0.6492 
2025-03-17 06:30:04.503832: Pseudo dice [np.float32(0.8505), np.float32(0.7208), np.float32(0.8727)] 
2025-03-17 06:30:04.507376: Epoch time: 38.28 s 
2025-03-17 06:30:04.510401: Yayy! New best EMA pseudo Dice: 0.8036999702453613 
2025-03-17 06:30:05.247477:  
2025-03-17 06:30:05.253035: Epoch 95 
2025-03-17 06:30:05.257684: Current learning rate: 0.00067 
2025-03-17 06:30:43.587317: train_loss -0.765 
2025-03-17 06:30:43.595846: val_loss -0.6367 
2025-03-17 06:30:43.599863: Pseudo dice [np.float32(0.8195), np.float32(0.6886), np.float32(0.8818)] 
2025-03-17 06:30:43.604381: Epoch time: 38.34 s 
2025-03-17 06:30:44.186160:  
2025-03-17 06:30:44.191736: Epoch 96 
2025-03-17 06:30:44.195782: Current learning rate: 0.00055 
2025-03-17 06:31:22.490703: train_loss -0.7532 
2025-03-17 06:31:22.497749: val_loss -0.6373 
2025-03-17 06:31:22.501301: Pseudo dice [np.float32(0.8178), np.float32(0.7545), np.float32(0.877)] 
2025-03-17 06:31:22.504338: Epoch time: 38.31 s 
2025-03-17 06:31:22.508893: Yayy! New best EMA pseudo Dice: 0.8043000102043152 
2025-03-17 06:31:23.250297:  
2025-03-17 06:31:23.255857: Epoch 97 
2025-03-17 06:31:23.260470: Current learning rate: 0.00043 
2025-03-17 06:32:01.603459: train_loss -0.7613 
2025-03-17 06:32:01.610569: val_loss -0.6693 
2025-03-17 06:32:01.614196: Pseudo dice [np.float32(0.8297), np.float32(0.701), np.float32(0.8683)] 
2025-03-17 06:32:01.617253: Epoch time: 38.35 s 
2025-03-17 06:32:02.355278:  
2025-03-17 06:32:02.361405: Epoch 98 
2025-03-17 06:32:02.365288: Current learning rate: 0.0003 
2025-03-17 06:32:40.545940: train_loss -0.7629 
2025-03-17 06:32:40.552545: val_loss -0.653 
2025-03-17 06:32:40.556056: Pseudo dice [np.float32(0.8497), np.float32(0.7044), np.float32(0.8656)] 
2025-03-17 06:32:40.559564: Epoch time: 38.19 s 
2025-03-17 06:32:41.129641:  
2025-03-17 06:32:41.135722: Epoch 99 
2025-03-17 06:32:41.138775: Current learning rate: 0.00016 
2025-03-17 06:33:19.350718: train_loss -0.7689 
2025-03-17 06:33:19.357317: val_loss -0.6398 
2025-03-17 06:33:19.360350: Pseudo dice [np.float32(0.8476), np.float32(0.6984), np.float32(0.8613)] 
2025-03-17 06:33:19.364862: Epoch time: 38.22 s 
2025-03-17 06:33:20.161066: Training done. 
2025-03-17 06:33:20.198575: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2025-03-17 06:33:20.206576: The split file contains 5 splits. 
2025-03-17 06:33:20.212575: Desired fold for training: 0 
2025-03-17 06:33:20.217575: This split has 387 training and 97 validation cases. 
2025-03-17 06:33:20.224575: predicting BRATS_010 
2025-03-17 06:33:20.231575: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2025-03-17 06:33:22.237513: predicting BRATS_011 
2025-03-17 06:33:22.250513: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2025-03-17 06:33:23.569395: predicting BRATS_012 
2025-03-17 06:33:23.580908: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-17 06:33:24.874164: predicting BRATS_018 
2025-03-17 06:33:24.886677: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2025-03-17 06:33:26.183009: predicting BRATS_020 
2025-03-17 06:33:26.196009: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2025-03-17 06:33:27.494661: predicting BRATS_028 
2025-03-17 06:33:27.505661: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2025-03-17 06:33:28.800854: predicting BRATS_029 
2025-03-17 06:33:28.812857: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2025-03-17 06:33:30.112050: predicting BRATS_032 
2025-03-17 06:33:30.126050: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2025-03-17 06:33:31.426088: predicting BRATS_034 
2025-03-17 06:33:31.440088: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2025-03-17 06:33:32.738396: predicting BRATS_041 
2025-03-17 06:33:32.752396: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2025-03-17 06:33:34.052559: predicting BRATS_042 
2025-03-17 06:33:34.066563: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2025-03-17 06:33:35.363352: predicting BRATS_047 
2025-03-17 06:33:35.378356: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-17 06:33:36.676343: predicting BRATS_049 
2025-03-17 06:33:36.691863: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-17 06:33:37.990856: predicting BRATS_053 
2025-03-17 06:33:38.004854: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-17 06:33:39.298450: predicting BRATS_056 
2025-03-17 06:33:39.310449: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-17 06:33:40.604995: predicting BRATS_057 
2025-03-17 06:33:40.616995: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-03-17 06:33:41.915173: predicting BRATS_067 
2025-03-17 06:33:41.928174: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-17 06:33:43.229849: predicting BRATS_069 
2025-03-17 06:33:43.244850: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2025-03-17 06:33:44.545511: predicting BRATS_085 
2025-03-17 06:33:44.560513: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2025-03-17 06:33:45.255289: predicting BRATS_086 
2025-03-17 06:33:45.268290: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2025-03-17 06:33:46.569250: predicting BRATS_088 
2025-03-17 06:33:46.584255: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2025-03-17 06:33:47.884097: predicting BRATS_091 
2025-03-17 06:33:47.901601: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2025-03-17 06:33:49.199252: predicting BRATS_098 
2025-03-17 06:33:49.213252: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2025-03-17 06:33:50.511026: predicting BRATS_100 
2025-03-17 06:33:50.524026: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-17 06:33:51.191035: predicting BRATS_101 
2025-03-17 06:33:51.206038: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2025-03-17 06:33:51.871874: predicting BRATS_102 
2025-03-17 06:33:51.884877: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2025-03-17 06:33:53.184937: predicting BRATS_104 
2025-03-17 06:33:53.197443: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2025-03-17 06:33:54.499426: predicting BRATS_111 
2025-03-17 06:33:54.513426: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2025-03-17 06:33:55.807956: predicting BRATS_116 
2025-03-17 06:33:55.821956: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2025-03-17 06:33:57.117116: predicting BRATS_135 
2025-03-17 06:33:57.131117: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2025-03-17 06:33:58.431032: predicting BRATS_136 
2025-03-17 06:33:58.445032: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2025-03-17 06:33:59.742996: predicting BRATS_138 
2025-03-17 06:33:59.756998: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2025-03-17 06:34:01.053281: predicting BRATS_145 
2025-03-17 06:34:01.067282: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2025-03-17 06:34:02.365203: predicting BRATS_149 
2025-03-17 06:34:02.379204: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2025-03-17 06:34:03.678715: predicting BRATS_155 
2025-03-17 06:34:03.692718: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-17 06:34:04.992074: predicting BRATS_157 
2025-03-17 06:34:05.006587: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2025-03-17 06:34:06.305481: predicting BRATS_158 
2025-03-17 06:34:06.320481: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2025-03-17 06:34:07.659603: predicting BRATS_159 
2025-03-17 06:34:07.672603: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-17 06:34:08.968892: predicting BRATS_163 
2025-03-17 06:34:08.982893: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2025-03-17 06:34:10.280945: predicting BRATS_164 
2025-03-17 06:34:10.293950: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2025-03-17 06:34:11.589773: predicting BRATS_169 
2025-03-17 06:34:11.603776: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2025-03-17 06:34:12.902572: predicting BRATS_176 
2025-03-17 06:34:12.916085: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2025-03-17 06:34:14.237016: predicting BRATS_181 
2025-03-17 06:34:14.250015: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2025-03-17 06:34:15.553857: predicting BRATS_183 
2025-03-17 06:34:15.567858: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-17 06:34:16.900603: predicting BRATS_184 
2025-03-17 06:34:16.915111: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-17 06:34:18.212197: predicting BRATS_187 
2025-03-17 06:34:18.226198: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2025-03-17 06:34:19.556890: predicting BRATS_192 
2025-03-17 06:34:19.571889: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2025-03-17 06:34:20.868022: predicting BRATS_198 
2025-03-17 06:34:20.881022: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2025-03-17 06:34:22.213252: predicting BRATS_207 
2025-03-17 06:34:22.226252: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-17 06:34:23.524777: predicting BRATS_208 
2025-03-17 06:34:23.538779: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2025-03-17 06:34:24.837592: predicting BRATS_218 
2025-03-17 06:34:24.851593: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-03-17 06:34:26.153013: predicting BRATS_220 
2025-03-17 06:34:26.169015: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2025-03-17 06:34:27.470153: predicting BRATS_224 
2025-03-17 06:34:27.484155: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2025-03-17 06:34:28.785734: predicting BRATS_230 
2025-03-17 06:34:28.798733: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2025-03-17 06:34:30.099858: predicting BRATS_271 
2025-03-17 06:34:30.112861: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2025-03-17 06:34:31.410894: predicting BRATS_282 
2025-03-17 06:34:31.425235: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2025-03-17 06:34:32.725622: predicting BRATS_284 
2025-03-17 06:34:32.739623: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2025-03-17 06:34:34.036747: predicting BRATS_287 
2025-03-17 06:34:34.049747: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2025-03-17 06:34:35.348720: predicting BRATS_290 
2025-03-17 06:34:35.365720: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2025-03-17 06:34:36.692915: predicting BRATS_291 
2025-03-17 06:34:36.705919: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2025-03-17 06:34:38.003223: predicting BRATS_292 
2025-03-17 06:34:38.016226: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2025-03-17 06:34:39.311630: predicting BRATS_293 
2025-03-17 06:34:39.325650: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2025-03-17 06:34:40.628872: predicting BRATS_300 
2025-03-17 06:34:40.644873: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2025-03-17 06:34:41.946471: predicting BRATS_305 
2025-03-17 06:34:41.961473: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2025-03-17 06:34:43.262546: predicting BRATS_311 
2025-03-17 06:34:43.276543: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2025-03-17 06:34:44.608961: predicting BRATS_314 
2025-03-17 06:34:44.623965: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2025-03-17 06:34:45.926206: predicting BRATS_321 
2025-03-17 06:34:45.938714: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2025-03-17 06:34:47.240817: predicting BRATS_328 
2025-03-17 06:34:47.253819: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2025-03-17 06:34:47.921586: predicting BRATS_329 
2025-03-17 06:34:47.934094: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2025-03-17 06:34:49.234630: predicting BRATS_335 
2025-03-17 06:34:49.247631: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2025-03-17 06:34:50.549161: predicting BRATS_343 
2025-03-17 06:34:50.563161: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2025-03-17 06:34:51.863532: predicting BRATS_350 
2025-03-17 06:34:51.877532: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2025-03-17 06:34:52.553070: predicting BRATS_351 
2025-03-17 06:34:52.565070: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2025-03-17 06:34:53.238863: predicting BRATS_356 
2025-03-17 06:34:53.251863: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2025-03-17 06:34:53.925997: predicting BRATS_366 
2025-03-17 06:34:53.939195: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2025-03-17 06:34:55.237417: predicting BRATS_367 
2025-03-17 06:34:55.252417: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2025-03-17 06:34:56.555064: predicting BRATS_374 
2025-03-17 06:34:56.569065: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2025-03-17 06:34:57.866754: predicting BRATS_376 
2025-03-17 06:34:57.881755: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2025-03-17 06:34:59.181425: predicting BRATS_377 
2025-03-17 06:34:59.195426: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2025-03-17 06:35:00.495134: predicting BRATS_378 
2025-03-17 06:35:00.510137: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2025-03-17 06:35:01.810165: predicting BRATS_379 
2025-03-17 06:35:01.824167: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2025-03-17 06:35:03.143433: predicting BRATS_384 
2025-03-17 06:35:03.157432: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2025-03-17 06:35:04.484926: predicting BRATS_386 
2025-03-17 06:35:04.498929: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2025-03-17 06:35:05.797800: predicting BRATS_394 
2025-03-17 06:35:05.812799: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2025-03-17 06:35:07.138041: predicting BRATS_398 
2025-03-17 06:35:07.151205: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2025-03-17 06:35:08.462648: predicting BRATS_400 
2025-03-17 06:35:08.476650: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2025-03-17 06:35:09.799092: predicting BRATS_432 
2025-03-17 06:35:09.813092: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2025-03-17 06:35:11.115650: predicting BRATS_437 
2025-03-17 06:35:11.129651: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2025-03-17 06:35:12.425510: predicting BRATS_445 
2025-03-17 06:35:12.438515: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2025-03-17 06:35:13.733104: predicting BRATS_446 
2025-03-17 06:35:13.746109: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2025-03-17 06:35:15.043225: predicting BRATS_450 
2025-03-17 06:35:15.058566: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2025-03-17 06:35:16.354335: predicting BRATS_452 
2025-03-17 06:35:16.366337: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2025-03-17 06:35:17.667848: predicting BRATS_460 
2025-03-17 06:35:17.681848: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2025-03-17 06:35:18.982472: predicting BRATS_470 
2025-03-17 06:35:18.997473: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2025-03-17 06:35:20.295494: predicting BRATS_472 
2025-03-17 06:35:20.309494: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2025-03-17 06:35:21.607328: predicting BRATS_473 
2025-03-17 06:35:21.621330: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2025-03-17 06:35:22.324467: predicting BRATS_482 
2025-03-17 06:35:22.337467: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2025-03-17 06:35:30.742259: Validation complete 
2025-03-17 06:35:30.748272: Mean Validation Dice:  0.7247827716763142 
