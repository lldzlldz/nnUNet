
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-08 17:31:32.053678: do_dummy_2d_data_aug: False 
2024-12-08 17:31:32.053678: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-08 17:31:32.061962: The split file contains 5 splits. 
2024-12-08 17:31:32.061962: Desired fold for training: 0 
2024-12-08 17:31:32.067279: This split has 387 training and 97 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [138.0, 169.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset001_BrainTumour', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [138, 169, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5721.0, 'mean': 728.8666381835938, 'median': 779.0, 'min': 0.0, 'percentile_00_5': 104.0, 'percentile_99_5': 1733.0, 'std': 354.5618896484375}, '1': {'max': 8761.0, 'mean': 621.560791015625, 'median': 644.0, 'min': 0.0, 'percentile_00_5': 56.0, 'percentile_99_5': 2421.0, 'std': 335.946044921875}, '2': {'max': 9012.0, 'mean': 662.5552368164062, 'median': 639.0, 'min': 0.0, 'percentile_00_5': 44.0, 'percentile_99_5': 2963.0, 'std': 420.2735595703125}, '3': {'max': 3346.0, 'mean': 664.2885131835938, 'median': 647.0, 'min': 0.0, 'percentile_00_5': 103.0, 'percentile_99_5': 1997.0, 'std': 318.48980712890625}}} 
 
2024-12-08 17:32:02.492544: unpacking dataset... 
2024-12-08 17:32:03.071138: unpacking done... 
2024-12-08 17:32:05.810578:  
2024-12-08 17:32:05.815145: Epoch 0 
2024-12-08 17:32:05.817682: Current learning rate: 0.01 
2024-12-08 17:32:46.996790: train_loss -0.2822 
2024-12-08 17:32:47.004400: val_loss -0.4288 
2024-12-08 17:32:47.006951: Pseudo dice [np.float32(0.6938), np.float32(0.5124), np.float32(0.766)] 
2024-12-08 17:32:47.009489: Epoch time: 41.19 s 
2024-12-08 17:32:47.014058: Yayy! New best EMA pseudo Dice: 0.6574000120162964 
2024-12-08 17:32:47.695166:  
2024-12-08 17:32:47.700296: Epoch 1 
2024-12-08 17:32:47.703386: Current learning rate: 0.00991 
2024-12-08 17:33:25.275525: train_loss -0.508 
2024-12-08 17:33:25.283138: val_loss -0.5104 
2024-12-08 17:33:25.285677: Pseudo dice [np.float32(0.7598), np.float32(0.5884), np.float32(0.8183)] 
2024-12-08 17:33:25.288263: Epoch time: 37.58 s 
2024-12-08 17:33:25.290803: Yayy! New best EMA pseudo Dice: 0.6639000177383423 
2024-12-08 17:33:26.011586:  
2024-12-08 17:33:26.017189: Epoch 2 
2024-12-08 17:33:26.019741: Current learning rate: 0.00982 
2024-12-08 17:34:03.577519: train_loss -0.5558 
2024-12-08 17:34:03.582678: val_loss -0.4893 
2024-12-08 17:34:03.587761: Pseudo dice [np.float32(0.7321), np.float32(0.5427), np.float32(0.7859)] 
2024-12-08 17:34:03.590290: Epoch time: 37.57 s 
2024-12-08 17:34:03.592820: Yayy! New best EMA pseudo Dice: 0.6661999821662903 
2024-12-08 17:34:04.385772:  
2024-12-08 17:34:04.391903: Epoch 3 
2024-12-08 17:34:04.394444: Current learning rate: 0.00973 
2024-12-08 17:34:41.901008: train_loss -0.5784 
2024-12-08 17:34:41.907116: val_loss -0.5312 
2024-12-08 17:34:41.910225: Pseudo dice [np.float32(0.7714), np.float32(0.6154), np.float32(0.8241)] 
2024-12-08 17:34:41.913772: Epoch time: 37.52 s 
2024-12-08 17:34:41.916308: Yayy! New best EMA pseudo Dice: 0.67330002784729 
2024-12-08 17:34:42.651005:  
2024-12-08 17:34:42.656595: Epoch 4 
2024-12-08 17:34:42.660206: Current learning rate: 0.00964 
2024-12-08 17:35:20.173894: train_loss -0.5793 
2024-12-08 17:35:20.178969: val_loss -0.5218 
2024-12-08 17:35:20.183554: Pseudo dice [np.float32(0.7332), np.float32(0.5473), np.float32(0.7868)] 
2024-12-08 17:35:20.186609: Epoch time: 37.52 s 
2024-12-08 17:35:20.189145: Yayy! New best EMA pseudo Dice: 0.6747999787330627 
2024-12-08 17:35:21.066345:  
2024-12-08 17:35:21.071969: Epoch 5 
2024-12-08 17:35:21.075548: Current learning rate: 0.00955 
2024-12-08 17:35:58.551285: train_loss -0.6014 
2024-12-08 17:35:58.558912: val_loss -0.5569 
2024-12-08 17:35:58.560976: Pseudo dice [np.float32(0.7695), np.float32(0.6528), np.float32(0.7798)] 
2024-12-08 17:35:58.565524: Epoch time: 37.49 s 
2024-12-08 17:35:58.568570: Yayy! New best EMA pseudo Dice: 0.6808000206947327 
2024-12-08 17:35:59.289387:  
2024-12-08 17:35:59.295025: Epoch 6 
2024-12-08 17:35:59.298090: Current learning rate: 0.00946 
2024-12-08 17:36:36.775526: train_loss -0.6452 
2024-12-08 17:36:36.781650: val_loss -0.5962 
2024-12-08 17:36:36.785258: Pseudo dice [np.float32(0.795), np.float32(0.6579), np.float32(0.8273)] 
2024-12-08 17:36:36.787799: Epoch time: 37.49 s 
2024-12-08 17:36:36.791374: Yayy! New best EMA pseudo Dice: 0.6887000203132629 
2024-12-08 17:36:37.536338:  
2024-12-08 17:36:37.541421: Epoch 7 
2024-12-08 17:36:37.545003: Current learning rate: 0.00937 
2024-12-08 17:37:15.011765: train_loss -0.6317 
2024-12-08 17:37:15.018388: val_loss -0.5865 
2024-12-08 17:37:15.021944: Pseudo dice [np.float32(0.799), np.float32(0.6227), np.float32(0.8209)] 
2024-12-08 17:37:15.025489: Epoch time: 37.48 s 
2024-12-08 17:37:15.028536: Yayy! New best EMA pseudo Dice: 0.694599986076355 
2024-12-08 17:37:15.769737:  
2024-12-08 17:37:15.774811: Epoch 8 
2024-12-08 17:37:15.777873: Current learning rate: 0.00928 
2024-12-08 17:37:53.291199: train_loss -0.6332 
2024-12-08 17:37:53.297321: val_loss -0.5631 
2024-12-08 17:37:53.299868: Pseudo dice [np.float32(0.7905), np.float32(0.6469), np.float32(0.8069)] 
2024-12-08 17:37:53.302402: Epoch time: 37.52 s 
2024-12-08 17:37:53.306457: Yayy! New best EMA pseudo Dice: 0.6998999714851379 
2024-12-08 17:37:54.090147:  
2024-12-08 17:37:54.095753: Epoch 9 
2024-12-08 17:37:54.098294: Current learning rate: 0.00919 
2024-12-08 17:38:31.579300: train_loss -0.6412 
2024-12-08 17:38:31.584914: val_loss -0.5867 
2024-12-08 17:38:31.589990: Pseudo dice [np.float32(0.7923), np.float32(0.6321), np.float32(0.8254)] 
2024-12-08 17:38:31.592576: Epoch time: 37.49 s 
2024-12-08 17:38:31.595130: Yayy! New best EMA pseudo Dice: 0.7049000263214111 
2024-12-08 17:38:32.327153:  
2024-12-08 17:38:32.333777: Epoch 10 
2024-12-08 17:38:32.336848: Current learning rate: 0.0091 
2024-12-08 17:39:09.819225: train_loss -0.6433 
2024-12-08 17:39:09.826441: val_loss -0.5895 
2024-12-08 17:39:09.828990: Pseudo dice [np.float32(0.7751), np.float32(0.67), np.float32(0.8321)] 
2024-12-08 17:39:09.831526: Epoch time: 37.49 s 
2024-12-08 17:39:09.834077: Yayy! New best EMA pseudo Dice: 0.7103000283241272 
2024-12-08 17:39:10.625234:  
2024-12-08 17:39:10.630345: Epoch 11 
2024-12-08 17:39:10.632895: Current learning rate: 0.009 
2024-12-08 17:39:48.116523: train_loss -0.6445 
2024-12-08 17:39:48.121620: val_loss -0.622 
2024-12-08 17:39:48.125715: Pseudo dice [np.float32(0.8148), np.float32(0.6463), np.float32(0.84)] 
2024-12-08 17:39:48.128778: Epoch time: 37.49 s 
2024-12-08 17:39:48.132428: Yayy! New best EMA pseudo Dice: 0.7160000205039978 
2024-12-08 17:39:48.878193:  
2024-12-08 17:39:48.884322: Epoch 12 
2024-12-08 17:39:48.887914: Current learning rate: 0.00891 
2024-12-08 17:40:26.370281: train_loss -0.6653 
2024-12-08 17:40:26.377409: val_loss -0.5699 
2024-12-08 17:40:26.380496: Pseudo dice [np.float32(0.7922), np.float32(0.6227), np.float32(0.836)] 
2024-12-08 17:40:26.383042: Epoch time: 37.49 s 
2024-12-08 17:40:26.385591: Yayy! New best EMA pseudo Dice: 0.7193999886512756 
2024-12-08 17:40:27.256182:  
2024-12-08 17:40:27.261828: Epoch 13 
2024-12-08 17:40:27.265951: Current learning rate: 0.00882 
2024-12-08 17:41:04.721151: train_loss -0.653 
2024-12-08 17:41:04.728757: val_loss -0.6185 
2024-12-08 17:41:04.731304: Pseudo dice [np.float32(0.7973), np.float32(0.6272), np.float32(0.8219)] 
2024-12-08 17:41:04.733871: Epoch time: 37.46 s 
2024-12-08 17:41:04.736413: Yayy! New best EMA pseudo Dice: 0.7224000096321106 
2024-12-08 17:41:05.470580:  
2024-12-08 17:41:05.475710: Epoch 14 
2024-12-08 17:41:05.479275: Current learning rate: 0.00873 
2024-12-08 17:41:42.929998: train_loss -0.656 
2024-12-08 17:41:42.936164: val_loss -0.6122 
2024-12-08 17:41:42.938723: Pseudo dice [np.float32(0.8135), np.float32(0.6556), np.float32(0.8216)] 
2024-12-08 17:41:42.941278: Epoch time: 37.46 s 
2024-12-08 17:41:42.945351: Yayy! New best EMA pseudo Dice: 0.7264999747276306 
2024-12-08 17:41:43.688800:  
2024-12-08 17:41:43.695429: Epoch 15 
2024-12-08 17:41:43.697992: Current learning rate: 0.00864 
2024-12-08 17:42:21.167680: train_loss -0.668 
2024-12-08 17:42:21.175305: val_loss -0.6251 
2024-12-08 17:42:21.177842: Pseudo dice [np.float32(0.8183), np.float32(0.6741), np.float32(0.8378)] 
2024-12-08 17:42:21.180439: Epoch time: 37.48 s 
2024-12-08 17:42:21.184997: Yayy! New best EMA pseudo Dice: 0.7315000295639038 
2024-12-08 17:42:21.939912:  
2024-12-08 17:42:21.945505: Epoch 16 
2024-12-08 17:42:21.948058: Current learning rate: 0.00855 
2024-12-08 17:42:59.424159: train_loss -0.6664 
2024-12-08 17:42:59.430256: val_loss -0.6252 
2024-12-08 17:42:59.433352: Pseudo dice [np.float32(0.8084), np.float32(0.6998), np.float32(0.852)] 
2024-12-08 17:42:59.436487: Epoch time: 37.49 s 
2024-12-08 17:42:59.438511: Yayy! New best EMA pseudo Dice: 0.7369999885559082 
2024-12-08 17:43:00.190094:  
2024-12-08 17:43:00.197768: Epoch 17 
2024-12-08 17:43:00.202859: Current learning rate: 0.00846 
2024-12-08 17:43:37.670251: train_loss -0.6952 
2024-12-08 17:43:37.677469: val_loss -0.588 
2024-12-08 17:43:37.680543: Pseudo dice [np.float32(0.8037), np.float32(0.6652), np.float32(0.8526)] 
2024-12-08 17:43:37.683095: Epoch time: 37.48 s 
2024-12-08 17:43:37.685649: Yayy! New best EMA pseudo Dice: 0.7407000064849854 
2024-12-08 17:43:38.425894:  
2024-12-08 17:43:38.432517: Epoch 18 
2024-12-08 17:43:38.435611: Current learning rate: 0.00836 
2024-12-08 17:44:21.025935: train_loss -0.6939 
2024-12-08 17:44:21.032685: val_loss -0.5806 
2024-12-08 17:44:21.036470: Pseudo dice [np.float32(0.789), np.float32(0.6567), np.float32(0.8297)] 
2024-12-08 17:44:21.039551: Epoch time: 42.6 s 
2024-12-08 17:44:21.043107: Yayy! New best EMA pseudo Dice: 0.7425000071525574 
2024-12-08 17:44:21.800442:  
2024-12-08 17:44:21.805343: Epoch 19 
2024-12-08 17:44:21.808417: Current learning rate: 0.00827 
2024-12-08 17:44:59.450963: train_loss -0.6821 
2024-12-08 17:44:59.456900: val_loss -0.6031 
2024-12-08 17:44:59.459258: Pseudo dice [np.float32(0.7949), np.float32(0.6628), np.float32(0.8353)] 
2024-12-08 17:44:59.462343: Epoch time: 37.65 s 
2024-12-08 17:44:59.465940: Yayy! New best EMA pseudo Dice: 0.744700014591217 
2024-12-08 17:45:00.218166:  
2024-12-08 17:45:00.223747: Epoch 20 
2024-12-08 17:45:00.227112: Current learning rate: 0.00818 
2024-12-08 17:45:37.880645: train_loss -0.6839 
2024-12-08 17:45:37.886997: val_loss -0.6366 
2024-12-08 17:45:37.891311: Pseudo dice [np.float32(0.8027), np.float32(0.6765), np.float32(0.8465)] 
2024-12-08 17:45:37.894110: Epoch time: 37.66 s 
2024-12-08 17:45:37.897290: Yayy! New best EMA pseudo Dice: 0.7476999759674072 
2024-12-08 17:45:38.803955:  
2024-12-08 17:45:38.809176: Epoch 21 
2024-12-08 17:45:38.811913: Current learning rate: 0.00809 
2024-12-08 17:46:16.504129: train_loss -0.69 
2024-12-08 17:46:16.511389: val_loss -0.6312 
2024-12-08 17:46:16.514906: Pseudo dice [np.float32(0.7972), np.float32(0.7313), np.float32(0.8409)] 
2024-12-08 17:46:16.518066: Epoch time: 37.7 s 
2024-12-08 17:46:16.520585: Yayy! New best EMA pseudo Dice: 0.7519000172615051 
2024-12-08 17:46:17.256560:  
2024-12-08 17:46:17.262473: Epoch 22 
2024-12-08 17:46:17.265832: Current learning rate: 0.008 
2024-12-08 17:46:54.897213: train_loss -0.6807 
2024-12-08 17:46:54.903889: val_loss -0.6243 
2024-12-08 17:46:54.906554: Pseudo dice [np.float32(0.8122), np.float32(0.6729), np.float32(0.8419)] 
2024-12-08 17:46:54.910494: Epoch time: 37.64 s 
2024-12-08 17:46:54.913069: Yayy! New best EMA pseudo Dice: 0.7542999982833862 
2024-12-08 17:46:55.652085:  
2024-12-08 17:46:55.657498: Epoch 23 
2024-12-08 17:46:55.660839: Current learning rate: 0.0079 
2024-12-08 17:47:33.270197: train_loss -0.697 
2024-12-08 17:47:33.278484: val_loss -0.6096 
2024-12-08 17:47:33.281037: Pseudo dice [np.float32(0.8089), np.float32(0.6602), np.float32(0.8296)] 
2024-12-08 17:47:33.284696: Epoch time: 37.62 s 
2024-12-08 17:47:33.288270: Yayy! New best EMA pseudo Dice: 0.7555000185966492 
2024-12-08 17:47:34.008926:  
2024-12-08 17:47:34.015400: Epoch 24 
2024-12-08 17:47:34.019189: Current learning rate: 0.00781 
2024-12-08 17:48:11.633967: train_loss -0.693 
2024-12-08 17:48:11.640299: val_loss -0.5913 
2024-12-08 17:48:11.642643: Pseudo dice [np.float32(0.8017), np.float32(0.6739), np.float32(0.8504)] 
2024-12-08 17:48:11.645195: Epoch time: 37.63 s 
2024-12-08 17:48:11.649120: Yayy! New best EMA pseudo Dice: 0.7574999928474426 
2024-12-08 17:48:12.383121:  
2024-12-08 17:48:12.388224: Epoch 25 
2024-12-08 17:48:12.391612: Current learning rate: 0.00772 
2024-12-08 17:48:50.002842: train_loss -0.6952 
2024-12-08 17:48:50.009866: val_loss -0.6292 
2024-12-08 17:48:50.012730: Pseudo dice [np.float32(0.8162), np.float32(0.6722), np.float32(0.8511)] 
2024-12-08 17:48:50.015768: Epoch time: 37.62 s 
2024-12-08 17:48:50.018872: Yayy! New best EMA pseudo Dice: 0.7597000002861023 
2024-12-08 17:48:50.740081:  
2024-12-08 17:48:50.745373: Epoch 26 
2024-12-08 17:48:50.748373: Current learning rate: 0.00763 
2024-12-08 17:49:28.323560: train_loss -0.7021 
2024-12-08 17:49:28.330807: val_loss -0.6429 
2024-12-08 17:49:28.333855: Pseudo dice [np.float32(0.8245), np.float32(0.7158), np.float32(0.8616)] 
2024-12-08 17:49:28.336384: Epoch time: 37.58 s 
2024-12-08 17:49:28.338914: Yayy! New best EMA pseudo Dice: 0.7638000249862671 
2024-12-08 17:49:29.056597:  
2024-12-08 17:49:29.061685: Epoch 27 
2024-12-08 17:49:29.064734: Current learning rate: 0.00753 
2024-12-08 17:50:06.511994: train_loss -0.7051 
2024-12-08 17:50:06.517795: val_loss -0.6212 
2024-12-08 17:50:06.522449: Pseudo dice [np.float32(0.8149), np.float32(0.6832), np.float32(0.8433)] 
2024-12-08 17:50:06.524991: Epoch time: 37.46 s 
2024-12-08 17:50:06.528037: Yayy! New best EMA pseudo Dice: 0.765500009059906 
2024-12-08 17:50:07.380001:  
2024-12-08 17:50:07.385048: Epoch 28 
2024-12-08 17:50:07.387615: Current learning rate: 0.00744 
2024-12-08 17:50:44.834033: train_loss -0.7161 
2024-12-08 17:50:44.841225: val_loss -0.6197 
2024-12-08 17:50:44.844393: Pseudo dice [np.float32(0.8166), np.float32(0.6813), np.float32(0.8414)] 
2024-12-08 17:50:44.846925: Epoch time: 37.46 s 
2024-12-08 17:50:44.849455: Yayy! New best EMA pseudo Dice: 0.7669000029563904 
2024-12-08 17:50:45.564844:  
2024-12-08 17:50:45.570417: Epoch 29 
2024-12-08 17:50:45.572991: Current learning rate: 0.00735 
2024-12-08 17:51:23.011926: train_loss -0.7072 
2024-12-08 17:51:23.019577: val_loss -0.6274 
2024-12-08 17:51:23.022112: Pseudo dice [np.float32(0.8141), np.float32(0.6611), np.float32(0.8577)] 
2024-12-08 17:51:23.024647: Epoch time: 37.45 s 
2024-12-08 17:51:23.029196: Yayy! New best EMA pseudo Dice: 0.7680000066757202 
2024-12-08 17:51:23.756147:  
2024-12-08 17:51:23.761714: Epoch 30 
2024-12-08 17:51:23.764248: Current learning rate: 0.00725 
2024-12-08 17:52:01.215977: train_loss -0.7106 
2024-12-08 17:52:01.224228: val_loss -0.6258 
2024-12-08 17:52:01.227298: Pseudo dice [np.float32(0.8148), np.float32(0.6647), np.float32(0.8479)] 
2024-12-08 17:52:01.231407: Epoch time: 37.46 s 
2024-12-08 17:52:01.233951: Yayy! New best EMA pseudo Dice: 0.7688000202178955 
2024-12-08 17:52:01.970886:  
2024-12-08 17:52:01.976955: Epoch 31 
2024-12-08 17:52:01.979493: Current learning rate: 0.00716 
2024-12-08 17:52:39.433114: train_loss -0.7034 
2024-12-08 17:52:39.440794: val_loss -0.606 
2024-12-08 17:52:39.444338: Pseudo dice [np.float32(0.8099), np.float32(0.6706), np.float32(0.8447)] 
2024-12-08 17:52:39.446868: Epoch time: 37.46 s 
2024-12-08 17:52:39.449399: Yayy! New best EMA pseudo Dice: 0.7694000005722046 
2024-12-08 17:52:40.180637:  
2024-12-08 17:52:40.187294: Epoch 32 
2024-12-08 17:52:40.189859: Current learning rate: 0.00707 
2024-12-08 17:53:17.645549: train_loss -0.7169 
2024-12-08 17:53:17.652702: val_loss -0.6021 
2024-12-08 17:53:17.656275: Pseudo dice [np.float32(0.8129), np.float32(0.6249), np.float32(0.8639)] 
2024-12-08 17:53:17.658307: Epoch time: 37.46 s 
2024-12-08 17:53:18.206013:  
2024-12-08 17:53:18.209563: Epoch 33 
2024-12-08 17:53:18.214145: Current learning rate: 0.00697 
2024-12-08 17:53:55.673794: train_loss -0.7174 
2024-12-08 17:53:55.679888: val_loss -0.6095 
2024-12-08 17:53:55.682424: Pseudo dice [np.float32(0.8093), np.float32(0.6889), np.float32(0.8363)] 
2024-12-08 17:53:55.684958: Epoch time: 37.47 s 
2024-12-08 17:53:55.689049: Yayy! New best EMA pseudo Dice: 0.7700999975204468 
2024-12-08 17:53:56.416684:  
2024-12-08 17:53:56.423825: Epoch 34 
2024-12-08 17:53:56.426877: Current learning rate: 0.00688 
2024-12-08 17:54:33.893627: train_loss -0.7265 
2024-12-08 17:54:33.901231: val_loss -0.6257 
2024-12-08 17:54:33.903809: Pseudo dice [np.float32(0.8104), np.float32(0.6477), np.float32(0.8544)] 
2024-12-08 17:54:33.906344: Epoch time: 37.48 s 
2024-12-08 17:54:33.908877: Yayy! New best EMA pseudo Dice: 0.7702000141143799 
2024-12-08 17:54:34.651623:  
2024-12-08 17:54:34.657690: Epoch 35 
2024-12-08 17:54:34.660737: Current learning rate: 0.00679 
2024-12-08 17:55:12.123060: train_loss -0.7225 
2024-12-08 17:55:12.128650: val_loss -0.6421 
2024-12-08 17:55:12.132203: Pseudo dice [np.float32(0.8346), np.float32(0.6907), np.float32(0.8384)] 
2024-12-08 17:55:12.135792: Epoch time: 37.47 s 
2024-12-08 17:55:12.138848: Yayy! New best EMA pseudo Dice: 0.7718999981880188 
2024-12-08 17:55:13.035254:  
2024-12-08 17:55:13.040825: Epoch 36 
2024-12-08 17:55:13.043376: Current learning rate: 0.00669 
2024-12-08 17:55:50.491386: train_loss -0.7219 
2024-12-08 17:55:50.498462: val_loss -0.6552 
2024-12-08 17:55:50.501556: Pseudo dice [np.float32(0.829), np.float32(0.7338), np.float32(0.8674)] 
2024-12-08 17:55:50.504097: Epoch time: 37.46 s 
2024-12-08 17:55:50.506645: Yayy! New best EMA pseudo Dice: 0.7756999731063843 
2024-12-08 17:55:51.259267:  
2024-12-08 17:55:51.261808: Epoch 37 
2024-12-08 17:55:51.266984: Current learning rate: 0.0066 
2024-12-08 17:56:28.721330: train_loss -0.7252 
2024-12-08 17:56:28.727028: val_loss -0.6461 
2024-12-08 17:56:28.731575: Pseudo dice [np.float32(0.8208), np.float32(0.7362), np.float32(0.8583)] 
2024-12-08 17:56:28.734627: Epoch time: 37.46 s 
2024-12-08 17:56:28.737214: Yayy! New best EMA pseudo Dice: 0.7786999940872192 
2024-12-08 17:56:29.488437:  
2024-12-08 17:56:29.493511: Epoch 38 
2024-12-08 17:56:29.496054: Current learning rate: 0.0065 
2024-12-08 17:57:06.940466: train_loss -0.7248 
2024-12-08 17:57:06.946589: val_loss -0.6492 
2024-12-08 17:57:06.949649: Pseudo dice [np.float32(0.8373), np.float32(0.7126), np.float32(0.852)] 
2024-12-08 17:57:06.952711: Epoch time: 37.45 s 
2024-12-08 17:57:06.955263: Yayy! New best EMA pseudo Dice: 0.7809000015258789 
2024-12-08 17:57:07.697786:  
2024-12-08 17:57:07.702857: Epoch 39 
2024-12-08 17:57:07.706934: Current learning rate: 0.00641 
2024-12-08 17:57:45.168537: train_loss -0.7282 
2024-12-08 17:57:45.173637: val_loss -0.6105 
2024-12-08 17:57:45.178187: Pseudo dice [np.float32(0.8201), np.float32(0.6445), np.float32(0.8523)] 
2024-12-08 17:57:45.181245: Epoch time: 37.47 s 
2024-12-08 17:57:45.750804:  
2024-12-08 17:57:45.753879: Epoch 40 
2024-12-08 17:57:45.756409: Current learning rate: 0.00631 
2024-12-08 17:58:23.204664: train_loss -0.7303 
2024-12-08 17:58:23.211857: val_loss -0.6124 
2024-12-08 17:58:23.215405: Pseudo dice [np.float32(0.8092), np.float32(0.6733), np.float32(0.8568)] 
2024-12-08 17:58:23.217946: Epoch time: 37.46 s 
2024-12-08 17:58:23.789181:  
2024-12-08 17:58:23.792257: Epoch 41 
2024-12-08 17:58:23.797329: Current learning rate: 0.00622 
2024-12-08 17:59:01.257806: train_loss -0.7317 
2024-12-08 17:59:01.264398: val_loss -0.6133 
2024-12-08 17:59:01.267980: Pseudo dice [np.float32(0.8249), np.float32(0.6732), np.float32(0.8398)] 
2024-12-08 17:59:01.270523: Epoch time: 37.47 s 
2024-12-08 17:59:01.871067:  
2024-12-08 17:59:01.876641: Epoch 42 
2024-12-08 17:59:01.880227: Current learning rate: 0.00612 
2024-12-08 17:59:39.326475: train_loss -0.7305 
2024-12-08 17:59:39.334135: val_loss -0.6225 
2024-12-08 17:59:39.337723: Pseudo dice [np.float32(0.8244), np.float32(0.6992), np.float32(0.8468)] 
2024-12-08 17:59:39.340260: Epoch time: 37.46 s 
2024-12-08 17:59:39.344312: Yayy! New best EMA pseudo Dice: 0.7809000015258789 
2024-12-08 17:59:40.054509:  
2024-12-08 17:59:40.059573: Epoch 43 
2024-12-08 17:59:40.062138: Current learning rate: 0.00603 
2024-12-08 18:00:17.494403: train_loss -0.738 
2024-12-08 18:00:17.502659: val_loss -0.6545 
2024-12-08 18:00:17.505716: Pseudo dice [np.float32(0.8303), np.float32(0.7342), np.float32(0.8753)] 
2024-12-08 18:00:17.508259: Epoch time: 37.44 s 
2024-12-08 18:00:17.512311: Yayy! New best EMA pseudo Dice: 0.7842000126838684 
2024-12-08 18:00:18.377708:  
2024-12-08 18:00:18.382771: Epoch 44 
2024-12-08 18:00:18.385850: Current learning rate: 0.00593 
2024-12-08 18:00:55.812943: train_loss -0.735 
2024-12-08 18:00:55.818535: val_loss -0.6317 
2024-12-08 18:00:55.821131: Pseudo dice [np.float32(0.8139), np.float32(0.7041), np.float32(0.852)] 
2024-12-08 18:00:55.823674: Epoch time: 37.44 s 
2024-12-08 18:00:55.828225: Yayy! New best EMA pseudo Dice: 0.7847999930381775 
2024-12-08 18:00:56.547540:  
2024-12-08 18:00:56.553115: Epoch 45 
2024-12-08 18:00:56.555700: Current learning rate: 0.00584 
2024-12-08 18:01:34.004904: train_loss -0.7381 
2024-12-08 18:01:34.011999: val_loss -0.6768 
2024-12-08 18:01:34.015055: Pseudo dice [np.float32(0.8246), np.float32(0.7033), np.float32(0.8633)] 
2024-12-08 18:01:34.017628: Epoch time: 37.46 s 
2024-12-08 18:01:34.020167: Yayy! New best EMA pseudo Dice: 0.7860000133514404 
2024-12-08 18:01:34.737226:  
2024-12-08 18:01:34.742302: Epoch 46 
2024-12-08 18:01:34.745840: Current learning rate: 0.00574 
2024-12-08 18:02:12.227495: train_loss -0.7406 
2024-12-08 18:02:12.233661: val_loss -0.6322 
2024-12-08 18:02:12.236711: Pseudo dice [np.float32(0.8235), np.float32(0.697), np.float32(0.8533)] 
2024-12-08 18:02:12.239830: Epoch time: 37.49 s 
2024-12-08 18:02:12.242886: Yayy! New best EMA pseudo Dice: 0.7864999771118164 
2024-12-08 18:02:12.961581:  
2024-12-08 18:02:12.967644: Epoch 47 
2024-12-08 18:02:12.971183: Current learning rate: 0.00565 
2024-12-08 18:02:50.421124: train_loss -0.7466 
2024-12-08 18:02:50.426727: val_loss -0.6264 
2024-12-08 18:02:50.429777: Pseudo dice [np.float32(0.8287), np.float32(0.7007), np.float32(0.8379)] 
2024-12-08 18:02:50.433323: Epoch time: 37.46 s 
2024-12-08 18:02:50.435905: Yayy! New best EMA pseudo Dice: 0.7868000268936157 
2024-12-08 18:02:51.145137:  
2024-12-08 18:02:51.150741: Epoch 48 
2024-12-08 18:02:51.153281: Current learning rate: 0.00555 
2024-12-08 18:03:28.606542: train_loss -0.7482 
2024-12-08 18:03:28.614170: val_loss -0.6525 
2024-12-08 18:03:28.616704: Pseudo dice [np.float32(0.8274), np.float32(0.7318), np.float32(0.8686)] 
2024-12-08 18:03:28.619235: Epoch time: 37.46 s 
2024-12-08 18:03:28.623838: Yayy! New best EMA pseudo Dice: 0.7889999747276306 
2024-12-08 18:03:29.352885:  
2024-12-08 18:03:29.357972: Epoch 49 
2024-12-08 18:03:29.361515: Current learning rate: 0.00546 
2024-12-08 18:04:06.810648: train_loss -0.7368 
2024-12-08 18:04:06.816233: val_loss -0.6205 
2024-12-08 18:04:06.819313: Pseudo dice [np.float32(0.8076), np.float32(0.6949), np.float32(0.8502)] 
2024-12-08 18:04:06.822856: Epoch time: 37.46 s 
2024-12-08 18:04:07.514281:  
2024-12-08 18:04:07.520862: Epoch 50 
2024-12-08 18:04:07.524421: Current learning rate: 0.00536 
2024-12-08 18:04:44.988835: train_loss -0.7421 
2024-12-08 18:04:44.993949: val_loss -0.63 
2024-12-08 18:04:44.998492: Pseudo dice [np.float32(0.8188), np.float32(0.6923), np.float32(0.8505)] 
2024-12-08 18:04:45.001559: Epoch time: 37.47 s 
2024-12-08 18:04:45.706097:  
2024-12-08 18:04:45.710640: Epoch 51 
2024-12-08 18:04:45.713685: Current learning rate: 0.00526 
2024-12-08 18:05:23.152394: train_loss -0.7426 
2024-12-08 18:05:23.159524: val_loss -0.6179 
2024-12-08 18:05:23.162051: Pseudo dice [np.float32(0.8216), np.float32(0.7119), np.float32(0.8413)] 
2024-12-08 18:05:23.164654: Epoch time: 37.45 s 
2024-12-08 18:05:23.714837:  
2024-12-08 18:05:23.718891: Epoch 52 
2024-12-08 18:05:23.722434: Current learning rate: 0.00517 
2024-12-08 18:06:01.163613: train_loss -0.7459 
2024-12-08 18:06:01.169679: val_loss -0.6666 
2024-12-08 18:06:01.173748: Pseudo dice [np.float32(0.8599), np.float32(0.7085), np.float32(0.8702)] 
2024-12-08 18:06:01.176276: Epoch time: 37.45 s 
2024-12-08 18:06:01.179856: Yayy! New best EMA pseudo Dice: 0.791100025177002 
2024-12-08 18:06:01.904687:  
2024-12-08 18:06:01.909750: Epoch 53 
2024-12-08 18:06:01.912275: Current learning rate: 0.00507 
2024-12-08 18:06:39.352026: train_loss -0.7478 
2024-12-08 18:06:39.358138: val_loss -0.6399 
2024-12-08 18:06:39.362188: Pseudo dice [np.float32(0.8079), np.float32(0.7132), np.float32(0.8495)] 
2024-12-08 18:06:39.365747: Epoch time: 37.45 s 
2024-12-08 18:06:39.915586:  
2024-12-08 18:06:39.919122: Epoch 54 
2024-12-08 18:06:39.921678: Current learning rate: 0.00497 
2024-12-08 18:07:17.354846: train_loss -0.7545 
2024-12-08 18:07:17.360996: val_loss -0.6602 
2024-12-08 18:07:17.364071: Pseudo dice [np.float32(0.8221), np.float32(0.7467), np.float32(0.866)] 
2024-12-08 18:07:17.367145: Epoch time: 37.44 s 
2024-12-08 18:07:17.370220: Yayy! New best EMA pseudo Dice: 0.7930999994277954 
2024-12-08 18:07:18.085807:  
2024-12-08 18:07:18.092942: Epoch 55 
2024-12-08 18:07:18.096494: Current learning rate: 0.00487 
2024-12-08 18:07:55.523093: train_loss -0.7512 
2024-12-08 18:07:55.528246: val_loss -0.6686 
2024-12-08 18:07:55.533332: Pseudo dice [np.float32(0.8279), np.float32(0.7144), np.float32(0.8638)] 
2024-12-08 18:07:55.535872: Epoch time: 37.44 s 
2024-12-08 18:07:55.538457: Yayy! New best EMA pseudo Dice: 0.7940000295639038 
2024-12-08 18:07:56.267609:  
2024-12-08 18:07:56.274719: Epoch 56 
2024-12-08 18:07:56.277774: Current learning rate: 0.00478 
2024-12-08 18:08:33.728735: train_loss -0.7492 
2024-12-08 18:08:33.735353: val_loss -0.622 
2024-12-08 18:08:33.738953: Pseudo dice [np.float32(0.7963), np.float32(0.695), np.float32(0.8705)] 
2024-12-08 18:08:33.741489: Epoch time: 37.46 s 
2024-12-08 18:08:34.288126:  
2024-12-08 18:08:34.291167: Epoch 57 
2024-12-08 18:08:34.293739: Current learning rate: 0.00468 
2024-12-08 18:09:11.737469: train_loss -0.7541 
2024-12-08 18:09:11.744110: val_loss -0.6131 
2024-12-08 18:09:11.747654: Pseudo dice [np.float32(0.826), np.float32(0.6511), np.float32(0.8624)] 
2024-12-08 18:09:11.750194: Epoch time: 37.45 s 
2024-12-08 18:09:12.299703:  
2024-12-08 18:09:12.304789: Epoch 58 
2024-12-08 18:09:12.308375: Current learning rate: 0.00458 
2024-12-08 18:09:49.737835: train_loss -0.7593 
2024-12-08 18:09:49.744967: val_loss -0.6228 
2024-12-08 18:09:49.748021: Pseudo dice [np.float32(0.8173), np.float32(0.6581), np.float32(0.8565)] 
2024-12-08 18:09:49.750635: Epoch time: 37.44 s 
2024-12-08 18:09:50.479071:  
2024-12-08 18:09:50.484123: Epoch 59 
2024-12-08 18:09:50.486654: Current learning rate: 0.00448 
2024-12-08 18:10:27.948694: train_loss -0.7617 
2024-12-08 18:10:27.956454: val_loss -0.6509 
2024-12-08 18:10:27.958991: Pseudo dice [np.float32(0.8025), np.float32(0.6661), np.float32(0.8718)] 
2024-12-08 18:10:27.963551: Epoch time: 37.47 s 
2024-12-08 18:10:28.517391:  
2024-12-08 18:10:28.522954: Epoch 60 
2024-12-08 18:10:28.525485: Current learning rate: 0.00438 
2024-12-08 18:11:05.969026: train_loss -0.7617 
2024-12-08 18:11:05.974605: val_loss -0.6341 
2024-12-08 18:11:05.978650: Pseudo dice [np.float32(0.8284), np.float32(0.7252), np.float32(0.8461)] 
2024-12-08 18:11:05.981182: Epoch time: 37.45 s 
2024-12-08 18:11:06.548468:  
2024-12-08 18:11:06.553537: Epoch 61 
2024-12-08 18:11:06.556584: Current learning rate: 0.00429 
2024-12-08 18:11:44.003621: train_loss -0.7629 
2024-12-08 18:11:44.011098: val_loss -0.6636 
2024-12-08 18:11:44.014208: Pseudo dice [np.float32(0.8283), np.float32(0.7268), np.float32(0.8816)] 
2024-12-08 18:11:44.017273: Epoch time: 37.46 s 
2024-12-08 18:11:44.571696:  
2024-12-08 18:11:44.575747: Epoch 62 
2024-12-08 18:11:44.578284: Current learning rate: 0.00419 
2024-12-08 18:12:22.029603: train_loss -0.7642 
2024-12-08 18:12:22.037741: val_loss -0.6188 
2024-12-08 18:12:22.040282: Pseudo dice [np.float32(0.8004), np.float32(0.7146), np.float32(0.8552)] 
2024-12-08 18:12:22.044832: Epoch time: 37.46 s 
2024-12-08 18:12:22.603909:  
2024-12-08 18:12:22.609019: Epoch 63 
2024-12-08 18:12:22.612562: Current learning rate: 0.00409 
2024-12-08 18:13:00.060376: train_loss -0.7638 
2024-12-08 18:13:00.067261: val_loss -0.6267 
2024-12-08 18:13:00.070829: Pseudo dice [np.float32(0.8188), np.float32(0.6762), np.float32(0.858)] 
2024-12-08 18:13:00.073881: Epoch time: 37.46 s 
2024-12-08 18:13:00.635689:  
2024-12-08 18:13:00.640938: Epoch 64 
2024-12-08 18:13:00.644479: Current learning rate: 0.00399 
2024-12-08 18:13:38.103662: train_loss -0.7608 
2024-12-08 18:13:38.110746: val_loss -0.6403 
2024-12-08 18:13:38.113272: Pseudo dice [np.float32(0.8181), np.float32(0.6962), np.float32(0.8751)] 
2024-12-08 18:13:38.117811: Epoch time: 37.47 s 
2024-12-08 18:13:38.674454:  
2024-12-08 18:13:38.678494: Epoch 65 
2024-12-08 18:13:38.682038: Current learning rate: 0.00389 
2024-12-08 18:14:16.127028: train_loss -0.7639 
2024-12-08 18:14:16.133351: val_loss -0.6492 
2024-12-08 18:14:16.138469: Pseudo dice [np.float32(0.8322), np.float32(0.688), np.float32(0.8776)] 
2024-12-08 18:14:16.142537: Epoch time: 37.45 s 
2024-12-08 18:14:16.706725:  
2024-12-08 18:14:16.711866: Epoch 66 
2024-12-08 18:14:16.714398: Current learning rate: 0.00379 
2024-12-08 18:14:54.161860: train_loss -0.7634 
2024-12-08 18:14:54.167177: val_loss -0.646 
2024-12-08 18:14:54.172291: Pseudo dice [np.float32(0.8379), np.float32(0.706), np.float32(0.8501)] 
2024-12-08 18:14:54.174838: Epoch time: 37.46 s 
2024-12-08 18:14:54.882477:  
2024-12-08 18:14:54.887549: Epoch 67 
2024-12-08 18:14:54.890650: Current learning rate: 0.00369 
2024-12-08 18:15:32.327430: train_loss -0.7657 
2024-12-08 18:15:32.334717: val_loss -0.6206 
2024-12-08 18:15:32.338282: Pseudo dice [np.float32(0.8226), np.float32(0.67), np.float32(0.8628)] 
2024-12-08 18:15:32.341347: Epoch time: 37.45 s 
2024-12-08 18:15:32.905921:  
2024-12-08 18:15:32.911002: Epoch 68 
2024-12-08 18:15:32.914113: Current learning rate: 0.00359 
2024-12-08 18:16:10.346770: train_loss -0.7683 
2024-12-08 18:16:10.352383: val_loss -0.6174 
2024-12-08 18:16:10.355046: Pseudo dice [np.float32(0.8072), np.float32(0.7209), np.float32(0.8685)] 
2024-12-08 18:16:10.357581: Epoch time: 37.44 s 
2024-12-08 18:16:10.934843:  
2024-12-08 18:16:10.939907: Epoch 69 
2024-12-08 18:16:10.942999: Current learning rate: 0.00349 
2024-12-08 18:16:48.388208: train_loss -0.7719 
2024-12-08 18:16:48.395304: val_loss -0.6101 
2024-12-08 18:16:48.399418: Pseudo dice [np.float32(0.8313), np.float32(0.7312), np.float32(0.8444)] 
2024-12-08 18:16:48.402477: Epoch time: 37.45 s 
2024-12-08 18:16:48.405536: Yayy! New best EMA pseudo Dice: 0.7940999865531921 
2024-12-08 18:16:49.143210:  
2024-12-08 18:16:49.149289: Epoch 70 
2024-12-08 18:16:49.152316: Current learning rate: 0.00338 
2024-12-08 18:17:26.586835: train_loss -0.7648 
2024-12-08 18:17:26.593438: val_loss -0.639 
2024-12-08 18:17:26.596982: Pseudo dice [np.float32(0.8316), np.float32(0.7124), np.float32(0.8621)] 
2024-12-08 18:17:26.600060: Epoch time: 37.44 s 
2024-12-08 18:17:26.602597: Yayy! New best EMA pseudo Dice: 0.7949000000953674 
2024-12-08 18:17:27.343298:  
2024-12-08 18:17:27.348376: Epoch 71 
2024-12-08 18:17:27.351018: Current learning rate: 0.00328 
2024-12-08 18:18:04.797957: train_loss -0.7712 
2024-12-08 18:18:04.805071: val_loss -0.639 
2024-12-08 18:18:04.808136: Pseudo dice [np.float32(0.8212), np.float32(0.7149), np.float32(0.8496)] 
2024-12-08 18:18:04.810674: Epoch time: 37.46 s 
2024-12-08 18:18:04.813207: Yayy! New best EMA pseudo Dice: 0.7949000000953674 
2024-12-08 18:18:05.545490:  
2024-12-08 18:18:05.550559: Epoch 72 
2024-12-08 18:18:05.554657: Current learning rate: 0.00318 
2024-12-08 18:18:42.998671: train_loss -0.7742 
2024-12-08 18:18:43.003799: val_loss -0.6626 
2024-12-08 18:18:43.006340: Pseudo dice [np.float32(0.8323), np.float32(0.738), np.float32(0.8685)] 
2024-12-08 18:18:43.010899: Epoch time: 37.45 s 
2024-12-08 18:18:43.013440: Yayy! New best EMA pseudo Dice: 0.7967000007629395 
2024-12-08 18:18:43.772792:  
2024-12-08 18:18:43.777873: Epoch 73 
2024-12-08 18:18:43.782460: Current learning rate: 0.00308 
2024-12-08 18:19:21.220900: train_loss -0.7647 
2024-12-08 18:19:21.228512: val_loss -0.6419 
2024-12-08 18:19:21.231051: Pseudo dice [np.float32(0.8185), np.float32(0.7165), np.float32(0.8552)] 
2024-12-08 18:19:21.233587: Epoch time: 37.45 s 
2024-12-08 18:19:21.238206: Yayy! New best EMA pseudo Dice: 0.7967000007629395 
2024-12-08 18:19:22.120816:  
2024-12-08 18:19:22.125433: Epoch 74 
2024-12-08 18:19:22.128494: Current learning rate: 0.00297 
2024-12-08 18:20:03.881145: train_loss -0.7697 
2024-12-08 18:20:03.887810: val_loss -0.6548 
2024-12-08 18:20:03.891884: Pseudo dice [np.float32(0.8074), np.float32(0.6732), np.float32(0.864)] 
2024-12-08 18:20:03.895454: Epoch time: 41.76 s 
2024-12-08 18:20:04.502465:  
2024-12-08 18:20:04.509132: Epoch 75 
2024-12-08 18:20:04.512693: Current learning rate: 0.00287 
2024-12-08 18:20:42.726367: train_loss -0.7606 
2024-12-08 18:20:42.733073: val_loss -0.629 
2024-12-08 18:20:42.737118: Pseudo dice [np.float32(0.8179), np.float32(0.7138), np.float32(0.8751)] 
2024-12-08 18:20:42.741662: Epoch time: 38.22 s 
2024-12-08 18:20:43.282174:  
2024-12-08 18:20:43.288258: Epoch 76 
2024-12-08 18:20:43.291289: Current learning rate: 0.00277 
2024-12-08 18:21:20.822127: train_loss -0.7719 
2024-12-08 18:21:20.829727: val_loss -0.6373 
2024-12-08 18:21:20.836331: Pseudo dice [np.float32(0.8248), np.float32(0.7216), np.float32(0.8559)] 
2024-12-08 18:21:20.839395: Epoch time: 37.54 s 
2024-12-08 18:21:21.375471:  
2024-12-08 18:21:21.381074: Epoch 77 
2024-12-08 18:21:21.383615: Current learning rate: 0.00266 
2024-12-08 18:21:59.006502: train_loss -0.7766 
2024-12-08 18:21:59.012082: val_loss -0.6404 
2024-12-08 18:21:59.014649: Pseudo dice [np.float32(0.8297), np.float32(0.7358), np.float32(0.8559)] 
2024-12-08 18:21:59.019212: Epoch time: 37.63 s 
2024-12-08 18:21:59.022264: Yayy! New best EMA pseudo Dice: 0.7975000143051147 
2024-12-08 18:21:59.825248:  
2024-12-08 18:21:59.830813: Epoch 78 
2024-12-08 18:21:59.833337: Current learning rate: 0.00256 
2024-12-08 18:22:37.389425: train_loss -0.7745 
2024-12-08 18:22:37.399034: val_loss -0.6752 
2024-12-08 18:22:37.404656: Pseudo dice [np.float32(0.8315), np.float32(0.7244), np.float32(0.8743)] 
2024-12-08 18:22:37.409724: Epoch time: 37.56 s 
2024-12-08 18:22:37.412256: Yayy! New best EMA pseudo Dice: 0.7986999750137329 
2024-12-08 18:22:38.127331:  
2024-12-08 18:22:38.132893: Epoch 79 
2024-12-08 18:22:38.135422: Current learning rate: 0.00245 
2024-12-08 18:23:15.701048: train_loss -0.7743 
2024-12-08 18:23:15.706108: val_loss -0.6405 
2024-12-08 18:23:15.710656: Pseudo dice [np.float32(0.8402), np.float32(0.6842), np.float32(0.8629)] 
2024-12-08 18:23:15.713761: Epoch time: 37.57 s 
2024-12-08 18:23:16.272852:  
2024-12-08 18:23:16.279940: Epoch 80 
2024-12-08 18:23:16.282988: Current learning rate: 0.00235 
2024-12-08 18:23:53.829196: train_loss -0.7735 
2024-12-08 18:23:53.835262: val_loss -0.5891 
2024-12-08 18:23:53.839353: Pseudo dice [np.float32(0.8069), np.float32(0.6499), np.float32(0.8561)] 
2024-12-08 18:23:53.842411: Epoch time: 37.56 s 
2024-12-08 18:23:54.540154:  
2024-12-08 18:23:54.545211: Epoch 81 
2024-12-08 18:23:54.547743: Current learning rate: 0.00224 
2024-12-08 18:24:32.097668: train_loss -0.776 
2024-12-08 18:24:32.103272: val_loss -0.6413 
2024-12-08 18:24:32.107865: Pseudo dice [np.float32(0.8335), np.float32(0.7041), np.float32(0.8504)] 
2024-12-08 18:24:32.112025: Epoch time: 37.56 s 
2024-12-08 18:24:32.685162:  
2024-12-08 18:24:32.690768: Epoch 82 
2024-12-08 18:24:32.693809: Current learning rate: 0.00214 
2024-12-08 18:25:10.267869: train_loss -0.7806 
2024-12-08 18:25:10.275566: val_loss -0.6486 
2024-12-08 18:25:10.280107: Pseudo dice [np.float32(0.8306), np.float32(0.7141), np.float32(0.8788)] 
2024-12-08 18:25:10.283156: Epoch time: 37.58 s 
2024-12-08 18:25:10.862896:  
2024-12-08 18:25:10.868452: Epoch 83 
2024-12-08 18:25:10.870976: Current learning rate: 0.00203 
2024-12-08 18:25:48.444832: train_loss -0.7781 
2024-12-08 18:25:48.452454: val_loss -0.6521 
2024-12-08 18:25:48.458015: Pseudo dice [np.float32(0.8293), np.float32(0.6963), np.float32(0.8617)] 
2024-12-08 18:25:48.462147: Epoch time: 37.58 s 
2024-12-08 18:25:48.980927:  
2024-12-08 18:25:48.987099: Epoch 84 
2024-12-08 18:25:48.990634: Current learning rate: 0.00192 
2024-12-08 18:26:26.401200: train_loss -0.7761 
2024-12-08 18:26:26.406252: val_loss -0.6256 
2024-12-08 18:26:26.408895: Pseudo dice [np.float32(0.8201), np.float32(0.7301), np.float32(0.85)] 
2024-12-08 18:26:26.411438: Epoch time: 37.42 s 
2024-12-08 18:26:26.928189:  
2024-12-08 18:26:26.934258: Epoch 85 
2024-12-08 18:26:26.937296: Current learning rate: 0.00181 
2024-12-08 18:27:04.337348: train_loss -0.7827 
2024-12-08 18:27:04.344937: val_loss -0.6197 
2024-12-08 18:27:04.349983: Pseudo dice [np.float32(0.8147), np.float32(0.6943), np.float32(0.8621)] 
2024-12-08 18:27:04.355103: Epoch time: 37.41 s 
2024-12-08 18:27:04.873234:  
2024-12-08 18:27:04.878800: Epoch 86 
2024-12-08 18:27:04.882352: Current learning rate: 0.0017 
2024-12-08 18:27:42.285363: train_loss -0.7782 
2024-12-08 18:27:42.291960: val_loss -0.622 
2024-12-08 18:27:42.295523: Pseudo dice [np.float32(0.8211), np.float32(0.6769), np.float32(0.8775)] 
2024-12-08 18:27:42.298051: Epoch time: 37.41 s 
2024-12-08 18:27:42.815579:  
2024-12-08 18:27:42.822702: Epoch 87 
2024-12-08 18:27:42.825739: Current learning rate: 0.00159 
2024-12-08 18:28:20.217711: train_loss -0.7787 
2024-12-08 18:28:20.224290: val_loss -0.6627 
2024-12-08 18:28:20.228881: Pseudo dice [np.float32(0.8472), np.float32(0.7133), np.float32(0.8681)] 
2024-12-08 18:28:20.231935: Epoch time: 37.4 s 
2024-12-08 18:28:20.752126:  
2024-12-08 18:28:20.757173: Epoch 88 
2024-12-08 18:28:20.759695: Current learning rate: 0.00148 
2024-12-08 18:28:58.179268: train_loss -0.7823 
2024-12-08 18:28:58.184332: val_loss -0.6787 
2024-12-08 18:28:58.188892: Pseudo dice [np.float32(0.8368), np.float32(0.7552), np.float32(0.8684)] 
2024-12-08 18:28:58.191524: Epoch time: 37.43 s 
2024-12-08 18:28:58.196603: Yayy! New best EMA pseudo Dice: 0.7996000051498413 
2024-12-08 18:28:59.016239:  
2024-12-08 18:28:59.021788: Epoch 89 
2024-12-08 18:28:59.024837: Current learning rate: 0.00137 
2024-12-08 18:29:36.419705: train_loss -0.7782 
2024-12-08 18:29:36.426776: val_loss -0.6515 
2024-12-08 18:29:36.429850: Pseudo dice [np.float32(0.827), np.float32(0.7419), np.float32(0.8599)] 
2024-12-08 18:29:36.432398: Epoch time: 37.4 s 
2024-12-08 18:29:36.436940: Yayy! New best EMA pseudo Dice: 0.800599992275238 
2024-12-08 18:29:37.119359:  
2024-12-08 18:29:37.125448: Epoch 90 
2024-12-08 18:29:37.128978: Current learning rate: 0.00126 
2024-12-08 18:30:14.516620: train_loss -0.7826 
2024-12-08 18:30:14.521680: val_loss -0.6426 
2024-12-08 18:30:14.526267: Pseudo dice [np.float32(0.8247), np.float32(0.7505), np.float32(0.8465)] 
2024-12-08 18:30:14.529330: Epoch time: 37.4 s 
2024-12-08 18:30:14.531858: Yayy! New best EMA pseudo Dice: 0.8012999892234802 
2024-12-08 18:30:15.204453:  
2024-12-08 18:30:15.210093: Epoch 91 
2024-12-08 18:30:15.212630: Current learning rate: 0.00115 
2024-12-08 18:30:52.598373: train_loss -0.7782 
2024-12-08 18:30:52.603962: val_loss -0.6277 
2024-12-08 18:30:52.609056: Pseudo dice [np.float32(0.8203), np.float32(0.7148), np.float32(0.8661)] 
2024-12-08 18:30:52.611590: Epoch time: 37.4 s 
2024-12-08 18:30:53.128881:  
2024-12-08 18:30:53.134958: Epoch 92 
2024-12-08 18:30:53.137481: Current learning rate: 0.00103 
2024-12-08 18:31:30.541791: train_loss -0.7843 
2024-12-08 18:31:30.548881: val_loss -0.6574 
2024-12-08 18:31:30.551933: Pseudo dice [np.float32(0.8372), np.float32(0.6815), np.float32(0.8525)] 
2024-12-08 18:31:30.554489: Epoch time: 37.41 s 
2024-12-08 18:31:31.071380:  
2024-12-08 18:31:31.078021: Epoch 93 
2024-12-08 18:31:31.081644: Current learning rate: 0.00091 
2024-12-08 18:32:08.471220: train_loss -0.7895 
2024-12-08 18:32:08.477334: val_loss -0.6576 
2024-12-08 18:32:08.480384: Pseudo dice [np.float32(0.8227), np.float32(0.7076), np.float32(0.8767)] 
2024-12-08 18:32:08.484427: Epoch time: 37.4 s 
2024-12-08 18:32:08.998319:  
2024-12-08 18:32:09.003371: Epoch 94 
2024-12-08 18:32:09.006400: Current learning rate: 0.00079 
2024-12-08 18:32:46.409421: train_loss -0.7861 
2024-12-08 18:32:46.415536: val_loss -0.6247 
2024-12-08 18:32:46.418077: Pseudo dice [np.float32(0.8107), np.float32(0.7352), np.float32(0.868)] 
2024-12-08 18:32:46.422132: Epoch time: 37.41 s 
2024-12-08 18:32:46.942458:  
2024-12-08 18:32:46.947545: Epoch 95 
2024-12-08 18:32:46.950589: Current learning rate: 0.00067 
2024-12-08 18:33:24.387865: train_loss -0.7817 
2024-12-08 18:33:24.397510: val_loss -0.6581 
2024-12-08 18:33:24.400552: Pseudo dice [np.float32(0.8391), np.float32(0.7548), np.float32(0.8569)] 
2024-12-08 18:33:24.403647: Epoch time: 37.45 s 
2024-12-08 18:33:24.406189: Yayy! New best EMA pseudo Dice: 0.8023999929428101 
2024-12-08 18:33:25.135540:  
2024-12-08 18:33:25.141117: Epoch 96 
2024-12-08 18:33:25.144150: Current learning rate: 0.00055 
2024-12-08 18:34:02.556046: train_loss -0.7848 
2024-12-08 18:34:02.562109: val_loss -0.6554 
2024-12-08 18:34:02.566149: Pseudo dice [np.float32(0.8122), np.float32(0.7431), np.float32(0.8537)] 
2024-12-08 18:34:02.569185: Epoch time: 37.42 s 
2024-12-08 18:34:02.573786: Yayy! New best EMA pseudo Dice: 0.8025000095367432 
2024-12-08 18:34:03.400790:  
2024-12-08 18:34:03.406854: Epoch 97 
2024-12-08 18:34:03.410422: Current learning rate: 0.00043 
2024-12-08 18:34:40.796237: train_loss -0.7823 
2024-12-08 18:34:40.802817: val_loss -0.6334 
2024-12-08 18:34:40.805342: Pseudo dice [np.float32(0.8163), np.float32(0.7248), np.float32(0.8646)] 
2024-12-08 18:34:40.809908: Epoch time: 37.4 s 
2024-12-08 18:34:41.339873:  
2024-12-08 18:34:41.344962: Epoch 98 
2024-12-08 18:34:41.348501: Current learning rate: 0.0003 
2024-12-08 18:35:18.740974: train_loss -0.7878 
2024-12-08 18:35:18.748568: val_loss -0.6662 
2024-12-08 18:35:18.751739: Pseudo dice [np.float32(0.845), np.float32(0.7137), np.float32(0.8738)] 
2024-12-08 18:35:18.756827: Epoch time: 37.4 s 
2024-12-08 18:35:18.761383: Yayy! New best EMA pseudo Dice: 0.8032000064849854 
2024-12-08 18:35:19.442616:  
2024-12-08 18:35:19.448186: Epoch 99 
2024-12-08 18:35:19.451228: Current learning rate: 0.00016 
2024-12-08 18:35:56.835557: train_loss -0.7829 
2024-12-08 18:35:56.842157: val_loss -0.6417 
2024-12-08 18:35:56.846732: Pseudo dice [np.float32(0.8316), np.float32(0.728), np.float32(0.8646)] 
2024-12-08 18:35:56.850791: Epoch time: 37.39 s 
2024-12-08 18:35:56.855382: Yayy! New best EMA pseudo Dice: 0.8036999702453613 
2024-12-08 18:35:57.745773: Training done. 
2024-12-08 18:35:57.782167: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset001_BrainTumour\splits_final.json 
2024-12-08 18:35:57.788406: The split file contains 5 splits. 
2024-12-08 18:35:57.788406: Desired fold for training: 0 
2024-12-08 18:35:57.796574: This split has 387 training and 97 validation cases. 
2024-12-08 18:35:57.804724: predicting BRATS_010 
2024-12-08 18:35:57.804724: BRATS_010, shape torch.Size([4, 140, 170, 147]), rank 0 
2024-12-08 18:35:58.654036: predicting BRATS_011 
2024-12-08 18:35:58.670129: BRATS_011, shape torch.Size([4, 132, 159, 137]), rank 0 
2024-12-08 18:35:58.848558: predicting BRATS_012 
2024-12-08 18:35:58.864802: BRATS_012, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-08 18:35:59.051649: predicting BRATS_018 
2024-12-08 18:35:59.067977: BRATS_018, shape torch.Size([4, 143, 165, 143]), rank 0 
2024-12-08 18:35:59.255535: predicting BRATS_020 
2024-12-08 18:35:59.263824: BRATS_020, shape torch.Size([4, 139, 164, 157]), rank 0 
2024-12-08 18:35:59.459646: predicting BRATS_028 
2024-12-08 18:35:59.467882: BRATS_028, shape torch.Size([4, 133, 161, 149]), rank 0 
2024-12-08 18:35:59.661315: predicting BRATS_029 
2024-12-08 18:35:59.671334: BRATS_029, shape torch.Size([4, 132, 175, 146]), rank 0 
2024-12-08 18:35:59.859195: predicting BRATS_032 
2024-12-08 18:35:59.873829: BRATS_032, shape torch.Size([4, 137, 163, 145]), rank 0 
2024-12-08 18:36:00.061775: predicting BRATS_034 
2024-12-08 18:36:00.074096: BRATS_034, shape torch.Size([4, 136, 169, 147]), rank 0 
2024-12-08 18:36:00.264680: predicting BRATS_041 
2024-12-08 18:36:00.280839: BRATS_041, shape torch.Size([4, 138, 166, 146]), rank 0 
2024-12-08 18:36:02.376266: predicting BRATS_042 
2024-12-08 18:36:02.390829: BRATS_042, shape torch.Size([4, 136, 163, 135]), rank 0 
2024-12-08 18:36:02.694844: predicting BRATS_047 
2024-12-08 18:36:02.718905: BRATS_047, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-08 18:36:02.955927: predicting BRATS_049 
2024-12-08 18:36:02.967940: BRATS_049, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-08 18:36:03.166274: predicting BRATS_053 
2024-12-08 18:36:03.180376: BRATS_053, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 18:36:03.381204: predicting BRATS_056 
2024-12-08 18:36:03.395222: BRATS_056, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 18:36:03.589833: predicting BRATS_057 
2024-12-08 18:36:03.603855: BRATS_057, shape torch.Size([4, 137, 151, 133]), rank 0 
2024-12-08 18:36:03.795995: predicting BRATS_067 
2024-12-08 18:36:03.810093: BRATS_067, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-08 18:36:04.010080: predicting BRATS_069 
2024-12-08 18:36:04.026097: BRATS_069, shape torch.Size([4, 134, 173, 143]), rank 0 
2024-12-08 18:36:04.218747: predicting BRATS_085 
2024-12-08 18:36:04.230761: BRATS_085, shape torch.Size([4, 127, 169, 133]), rank 0 
2024-12-08 18:36:04.346621: predicting BRATS_086 
2024-12-08 18:36:04.358640: BRATS_086, shape torch.Size([4, 133, 170, 160]), rank 0 
2024-12-08 18:36:04.551601: predicting BRATS_088 
2024-12-08 18:36:04.567911: BRATS_088, shape torch.Size([4, 136, 173, 140]), rank 0 
2024-12-08 18:36:04.758350: predicting BRATS_091 
2024-12-08 18:36:04.772368: BRATS_091, shape torch.Size([4, 133, 171, 144]), rank 0 
2024-12-08 18:36:04.967687: predicting BRATS_098 
2024-12-08 18:36:04.981250: BRATS_098, shape torch.Size([4, 139, 164, 136]), rank 0 
2024-12-08 18:36:05.171420: predicting BRATS_100 
2024-12-08 18:36:05.182773: BRATS_100, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-08 18:36:05.296877: predicting BRATS_101 
2024-12-08 18:36:05.310259: BRATS_101, shape torch.Size([4, 128, 166, 153]), rank 0 
2024-12-08 18:36:05.423043: predicting BRATS_102 
2024-12-08 18:36:05.437061: BRATS_102, shape torch.Size([4, 145, 149, 141]), rank 0 
2024-12-08 18:36:05.628829: predicting BRATS_104 
2024-12-08 18:36:05.640840: BRATS_104, shape torch.Size([4, 139, 175, 136]), rank 0 
2024-12-08 18:36:05.835856: predicting BRATS_111 
2024-12-08 18:36:05.849873: BRATS_111, shape torch.Size([4, 135, 171, 140]), rank 0 
2024-12-08 18:36:06.045019: predicting BRATS_116 
2024-12-08 18:36:06.058032: BRATS_116, shape torch.Size([4, 139, 165, 141]), rank 0 
2024-12-08 18:36:06.250467: predicting BRATS_135 
2024-12-08 18:36:06.262871: BRATS_135, shape torch.Size([4, 136, 174, 135]), rank 0 
2024-12-08 18:36:06.457025: predicting BRATS_136 
2024-12-08 18:36:06.469520: BRATS_136, shape torch.Size([4, 133, 162, 140]), rank 0 
2024-12-08 18:36:06.663793: predicting BRATS_138 
2024-12-08 18:36:06.677712: BRATS_138, shape torch.Size([4, 136, 168, 138]), rank 0 
2024-12-08 18:36:06.872370: predicting BRATS_145 
2024-12-08 18:36:06.886383: BRATS_145, shape torch.Size([4, 136, 167, 138]), rank 0 
2024-12-08 18:36:07.079561: predicting BRATS_149 
2024-12-08 18:36:07.094056: BRATS_149, shape torch.Size([4, 138, 173, 143]), rank 0 
2024-12-08 18:36:07.288264: predicting BRATS_155 
2024-12-08 18:36:07.302674: BRATS_155, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-08 18:36:07.495292: predicting BRATS_157 
2024-12-08 18:36:07.509517: BRATS_157, shape torch.Size([4, 139, 173, 141]), rank 0 
2024-12-08 18:36:07.704958: predicting BRATS_158 
2024-12-08 18:36:07.718711: BRATS_158, shape torch.Size([4, 139, 161, 136]), rank 0 
2024-12-08 18:36:07.909884: predicting BRATS_159 
2024-12-08 18:36:07.923378: BRATS_159, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-08 18:36:08.113342: predicting BRATS_163 
2024-12-08 18:36:08.125095: BRATS_163, shape torch.Size([4, 139, 161, 137]), rank 0 
2024-12-08 18:36:08.315546: predicting BRATS_164 
2024-12-08 18:36:08.329299: BRATS_164, shape torch.Size([4, 130, 162, 137]), rank 0 
2024-12-08 18:36:08.519937: predicting BRATS_169 
2024-12-08 18:36:08.531948: BRATS_169, shape torch.Size([4, 141, 170, 137]), rank 0 
2024-12-08 18:36:08.726141: predicting BRATS_176 
2024-12-08 18:36:08.740153: BRATS_176, shape torch.Size([4, 137, 167, 134]), rank 0 
2024-12-08 18:36:08.932486: predicting BRATS_181 
2024-12-08 18:36:08.945646: BRATS_181, shape torch.Size([4, 140, 160, 150]), rank 0 
2024-12-08 18:36:09.140772: predicting BRATS_183 
2024-12-08 18:36:09.152789: BRATS_183, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 18:36:09.344995: predicting BRATS_184 
2024-12-08 18:36:09.361010: BRATS_184, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 18:36:09.554074: predicting BRATS_187 
2024-12-08 18:36:09.566085: BRATS_187, shape torch.Size([4, 139, 172, 134]), rank 0 
2024-12-08 18:36:09.759454: predicting BRATS_192 
2024-12-08 18:36:09.773473: BRATS_192, shape torch.Size([4, 131, 157, 142]), rank 0 
2024-12-08 18:36:09.962024: predicting BRATS_198 
2024-12-08 18:36:09.978597: BRATS_198, shape torch.Size([4, 142, 173, 139]), rank 0 
2024-12-08 18:36:10.172159: predicting BRATS_207 
2024-12-08 18:36:10.186555: BRATS_207, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-08 18:36:10.374270: predicting BRATS_208 
2024-12-08 18:36:10.388483: BRATS_208, shape torch.Size([4, 134, 170, 138]), rank 0 
2024-12-08 18:36:10.579113: predicting BRATS_218 
2024-12-08 18:36:10.592867: BRATS_218, shape torch.Size([4, 145, 181, 138]), rank 0 
2024-12-08 18:36:10.788813: predicting BRATS_220 
2024-12-08 18:36:10.803781: BRATS_220, shape torch.Size([4, 141, 169, 140]), rank 0 
2024-12-08 18:36:10.997923: predicting BRATS_224 
2024-12-08 18:36:11.011946: BRATS_224, shape torch.Size([4, 140, 172, 138]), rank 0 
2024-12-08 18:36:11.207325: predicting BRATS_230 
2024-12-08 18:36:11.221078: BRATS_230, shape torch.Size([4, 137, 172, 133]), rank 0 
2024-12-08 18:36:11.414518: predicting BRATS_271 
2024-12-08 18:36:11.426269: BRATS_271, shape torch.Size([4, 142, 169, 141]), rank 0 
2024-12-08 18:36:11.615609: predicting BRATS_282 
2024-12-08 18:36:11.635694: BRATS_282, shape torch.Size([4, 138, 169, 141]), rank 0 
2024-12-08 18:36:11.830400: predicting BRATS_284 
2024-12-08 18:36:11.843915: BRATS_284, shape torch.Size([4, 130, 156, 129]), rank 0 
2024-12-08 18:36:12.032848: predicting BRATS_287 
2024-12-08 18:36:12.046862: BRATS_287, shape torch.Size([4, 136, 171, 144]), rank 0 
2024-12-08 18:36:12.236066: predicting BRATS_290 
2024-12-08 18:36:12.256282: BRATS_290, shape torch.Size([4, 129, 179, 142]), rank 0 
2024-12-08 18:36:12.447683: predicting BRATS_291 
2024-12-08 18:36:12.459434: BRATS_291, shape torch.Size([4, 137, 155, 144]), rank 0 
2024-12-08 18:36:12.647403: predicting BRATS_292 
2024-12-08 18:36:12.663636: BRATS_292, shape torch.Size([4, 135, 169, 144]), rank 0 
2024-12-08 18:36:12.848535: predicting BRATS_293 
2024-12-08 18:36:12.869058: BRATS_293, shape torch.Size([4, 146, 176, 142]), rank 0 
2024-12-08 18:36:13.063290: predicting BRATS_300 
2024-12-08 18:36:13.079048: BRATS_300, shape torch.Size([4, 141, 177, 133]), rank 0 
2024-12-08 18:36:13.266597: predicting BRATS_305 
2024-12-08 18:36:13.286909: BRATS_305, shape torch.Size([4, 142, 160, 152]), rank 0 
2024-12-08 18:36:13.484915: predicting BRATS_311 
2024-12-08 18:36:13.499926: BRATS_311, shape torch.Size([4, 141, 177, 140]), rank 0 
2024-12-08 18:36:13.697242: predicting BRATS_314 
2024-12-08 18:36:13.709252: BRATS_314, shape torch.Size([4, 139, 180, 140]), rank 0 
2024-12-08 18:36:13.907678: predicting BRATS_321 
2024-12-08 18:36:13.919430: BRATS_321, shape torch.Size([4, 142, 172, 134]), rank 0 
2024-12-08 18:36:14.113501: predicting BRATS_328 
2024-12-08 18:36:14.127515: BRATS_328, shape torch.Size([4, 144, 162, 128]), rank 0 
2024-12-08 18:36:14.239072: predicting BRATS_329 
2024-12-08 18:36:14.253087: BRATS_329, shape torch.Size([4, 130, 167, 148]), rank 0 
2024-12-08 18:36:14.446783: predicting BRATS_335 
2024-12-08 18:36:14.460796: BRATS_335, shape torch.Size([4, 141, 165, 143]), rank 0 
2024-12-08 18:36:14.648249: predicting BRATS_343 
2024-12-08 18:36:14.668792: BRATS_343, shape torch.Size([4, 141, 178, 140]), rank 0 
2024-12-08 18:36:14.864422: predicting BRATS_350 
2024-12-08 18:36:14.878436: BRATS_350, shape torch.Size([4, 136, 162, 122]), rank 0 
2024-12-08 18:36:14.992771: predicting BRATS_351 
2024-12-08 18:36:15.004784: BRATS_351, shape torch.Size([4, 134, 157, 126]), rank 0 
2024-12-08 18:36:15.122897: predicting BRATS_356 
2024-12-08 18:36:15.138922: BRATS_356, shape torch.Size([4, 146, 160, 127]), rank 0 
2024-12-08 18:36:15.256912: predicting BRATS_366 
2024-12-08 18:36:15.272932: BRATS_366, shape torch.Size([4, 136, 168, 134]), rank 0 
2024-12-08 18:36:15.463330: predicting BRATS_367 
2024-12-08 18:36:15.477352: BRATS_367, shape torch.Size([4, 141, 179, 135]), rank 0 
2024-12-08 18:36:15.674756: predicting BRATS_374 
2024-12-08 18:36:15.688777: BRATS_374, shape torch.Size([4, 141, 173, 131]), rank 0 
2024-12-08 18:36:15.882671: predicting BRATS_376 
2024-12-08 18:36:15.894683: BRATS_376, shape torch.Size([4, 140, 170, 136]), rank 0 
2024-12-08 18:36:16.088490: predicting BRATS_377 
2024-12-08 18:36:16.102718: BRATS_377, shape torch.Size([4, 141, 176, 141]), rank 0 
2024-12-08 18:36:16.296906: predicting BRATS_378 
2024-12-08 18:36:16.311401: BRATS_378, shape torch.Size([4, 144, 167, 139]), rank 0 
2024-12-08 18:36:16.507195: predicting BRATS_379 
2024-12-08 18:36:16.523211: BRATS_379, shape torch.Size([4, 144, 173, 141]), rank 0 
2024-12-08 18:36:16.716664: predicting BRATS_384 
2024-12-08 18:36:16.730418: BRATS_384, shape torch.Size([4, 130, 171, 138]), rank 0 
2024-12-08 18:36:16.917508: predicting BRATS_386 
2024-12-08 18:36:16.932726: BRATS_386, shape torch.Size([4, 139, 160, 147]), rank 0 
2024-12-08 18:36:17.123157: predicting BRATS_394 
2024-12-08 18:36:17.135542: BRATS_394, shape torch.Size([4, 143, 168, 133]), rank 0 
2024-12-08 18:36:17.331029: predicting BRATS_398 
2024-12-08 18:36:17.344837: BRATS_398, shape torch.Size([4, 143, 175, 134]), rank 0 
2024-12-08 18:36:17.538227: predicting BRATS_400 
2024-12-08 18:36:17.552240: BRATS_400, shape torch.Size([4, 146, 176, 148]), rank 0 
2024-12-08 18:36:17.752462: predicting BRATS_432 
2024-12-08 18:36:17.768216: BRATS_432, shape torch.Size([4, 140, 168, 140]), rank 0 
2024-12-08 18:36:17.962568: predicting BRATS_437 
2024-12-08 18:36:17.978323: BRATS_437, shape torch.Size([4, 131, 169, 139]), rank 0 
2024-12-08 18:36:18.171870: predicting BRATS_445 
2024-12-08 18:36:18.184985: BRATS_445, shape torch.Size([4, 141, 158, 137]), rank 0 
2024-12-08 18:36:18.377371: predicting BRATS_446 
2024-12-08 18:36:18.389122: BRATS_446, shape torch.Size([4, 137, 168, 145]), rank 0 
2024-12-08 18:36:18.582629: predicting BRATS_450 
2024-12-08 18:36:18.593668: BRATS_450, shape torch.Size([4, 132, 162, 135]), rank 0 
2024-12-08 18:36:18.788540: predicting BRATS_452 
2024-12-08 18:36:18.802292: BRATS_452, shape torch.Size([4, 136, 165, 146]), rank 0 
2024-12-08 18:36:18.995676: predicting BRATS_460 
2024-12-08 18:36:19.010001: BRATS_460, shape torch.Size([4, 142, 165, 139]), rank 0 
2024-12-08 18:36:19.202666: predicting BRATS_470 
2024-12-08 18:36:19.216678: BRATS_470, shape torch.Size([4, 144, 163, 133]), rank 0 
2024-12-08 18:36:19.409008: predicting BRATS_472 
2024-12-08 18:36:19.422765: BRATS_472, shape torch.Size([4, 138, 161, 139]), rank 0 
2024-12-08 18:36:19.614898: predicting BRATS_473 
2024-12-08 18:36:19.628653: BRATS_473, shape torch.Size([4, 119, 163, 143]), rank 0 
2024-12-08 18:36:19.742931: predicting BRATS_482 
2024-12-08 18:36:19.754943: BRATS_482, shape torch.Size([4, 143, 169, 134]), rank 0 
2024-12-08 18:36:26.810919: Validation complete 
2024-12-08 18:36:26.819345: Mean Validation Dice:  0.7202790047673377 
