
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-11 01:07:11.261703: do_dummy_2d_data_aug: False 
2024-12-11 01:07:11.262705: Creating new 5-fold cross-validation split... 
2024-12-11 01:07:11.269573: Desired fold for training: 0 
2024-12-11 01:07:11.272573: This split has 32 training and 9 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_avg_spacing_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 160, 128], 'median_image_size_in_voxels': [150.0, 203.0, 203.0], 'spacing': [1.99770056813713, 1.99770056813713, 1.99770056813713], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset009_Spleen', 'plans_name': 'nnUNetPlans_avg_spacing', 'original_median_spacing_after_transp': [5.0, 0.7929689884185791, 0.7929689884185791], 'original_median_shape_after_transp': [90, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1038.0, 'mean': 93.19259643554688, 'median': 97.0, 'min': -620.0, 'percentile_00_5': -42.0, 'percentile_99_5': 176.0, 'std': 40.78370666503906}}} 
 
2024-12-11 01:07:20.501911: unpacking dataset... 
2024-12-11 01:07:21.482763: unpacking done... 
2024-12-11 01:07:24.467085:  
2024-12-11 01:07:24.472098: Epoch 0 
2024-12-11 01:07:24.474604: Current learning rate: 0.01 
2024-12-11 01:08:11.312734: train_loss -0.0972 
2024-12-11 01:08:11.317334: val_loss -0.335 
2024-12-11 01:08:11.321397: Pseudo dice [np.float32(0.4984)] 
2024-12-11 01:08:11.324473: Epoch time: 46.85 s 
2024-12-11 01:08:11.327009: Yayy! New best EMA pseudo Dice: 0.4984000027179718 
2024-12-11 01:08:11.989876:  
2024-12-11 01:08:11.995512: Epoch 1 
2024-12-11 01:08:11.999101: Current learning rate: 0.00991 
2024-12-11 01:08:54.088507: train_loss -0.5105 
2024-12-11 01:08:54.094073: val_loss -0.5898 
2024-12-11 01:08:54.096580: Pseudo dice [np.float32(0.7452)] 
2024-12-11 01:08:54.100633: Epoch time: 42.1 s 
2024-12-11 01:08:54.103667: Yayy! New best EMA pseudo Dice: 0.5231000185012817 
2024-12-11 01:08:54.856135:  
2024-12-11 01:08:54.862252: Epoch 2 
2024-12-11 01:08:54.864758: Current learning rate: 0.00982 
2024-12-11 01:09:36.860109: train_loss -0.5561 
2024-12-11 01:09:36.865654: val_loss -0.5887 
2024-12-11 01:09:36.869170: Pseudo dice [np.float32(0.7608)] 
2024-12-11 01:09:36.872785: Epoch time: 42.0 s 
2024-12-11 01:09:36.875827: Yayy! New best EMA pseudo Dice: 0.5468999743461609 
2024-12-11 01:09:37.651602:  
2024-12-11 01:09:37.657117: Epoch 3 
2024-12-11 01:09:37.660158: Current learning rate: 0.00973 
2024-12-11 01:10:19.682042: train_loss -0.6283 
2024-12-11 01:10:19.687144: val_loss -0.7238 
2024-12-11 01:10:19.690677: Pseudo dice [np.float32(0.8751)] 
2024-12-11 01:10:19.693788: Epoch time: 42.03 s 
2024-12-11 01:10:19.696823: Yayy! New best EMA pseudo Dice: 0.5796999931335449 
2024-12-11 01:10:20.465980:  
2024-12-11 01:10:20.471509: Epoch 4 
2024-12-11 01:10:20.475020: Current learning rate: 0.00964 
2024-12-11 01:11:02.482525: train_loss -0.6329 
2024-12-11 01:11:02.487825: val_loss -0.665 
2024-12-11 01:11:02.491391: Pseudo dice [np.float32(0.837)] 
2024-12-11 01:11:02.494436: Epoch time: 42.02 s 
2024-12-11 01:11:02.496964: Yayy! New best EMA pseudo Dice: 0.605400025844574 
2024-12-11 01:11:03.409355:  
2024-12-11 01:11:03.414372: Epoch 5 
2024-12-11 01:11:03.417383: Current learning rate: 0.00955 
2024-12-11 01:11:45.387007: train_loss -0.6483 
2024-12-11 01:11:45.391016: val_loss -0.6816 
2024-12-11 01:11:45.394773: Pseudo dice [np.float32(0.8363)] 
2024-12-11 01:11:45.398784: Epoch time: 41.98 s 
2024-12-11 01:11:45.401290: Yayy! New best EMA pseudo Dice: 0.6284999847412109 
2024-12-11 01:11:46.150862:  
2024-12-11 01:11:46.156506: Epoch 6 
2024-12-11 01:11:46.159052: Current learning rate: 0.00946 
2024-12-11 01:12:28.551121: train_loss -0.6643 
2024-12-11 01:12:28.557266: val_loss -0.6398 
2024-12-11 01:12:28.559791: Pseudo dice [np.float32(0.7707)] 
2024-12-11 01:12:28.563318: Epoch time: 42.4 s 
2024-12-11 01:12:28.566383: Yayy! New best EMA pseudo Dice: 0.6427000164985657 
2024-12-11 01:12:29.319535:  
2024-12-11 01:12:29.325602: Epoch 7 
2024-12-11 01:12:29.328673: Current learning rate: 0.00937 
2024-12-11 01:13:11.218739: train_loss -0.6465 
2024-12-11 01:13:11.223797: val_loss -0.7335 
2024-12-11 01:13:11.226845: Pseudo dice [np.float32(0.8856)] 
2024-12-11 01:13:11.230896: Epoch time: 41.9 s 
2024-12-11 01:13:11.233403: Yayy! New best EMA pseudo Dice: 0.6669999957084656 
2024-12-11 01:13:12.032266:  
2024-12-11 01:13:12.037303: Epoch 8 
2024-12-11 01:13:12.040338: Current learning rate: 0.00928 
2024-12-11 01:13:54.349038: train_loss -0.6977 
2024-12-11 01:13:54.355618: val_loss -0.7135 
2024-12-11 01:13:54.359127: Pseudo dice [np.float32(0.8454)] 
2024-12-11 01:13:54.363182: Epoch time: 42.32 s 
2024-12-11 01:13:54.365688: Yayy! New best EMA pseudo Dice: 0.6848999857902527 
2024-12-11 01:13:55.147801:  
2024-12-11 01:13:55.152816: Epoch 9 
2024-12-11 01:13:55.156325: Current learning rate: 0.00919 
2024-12-11 01:14:37.053258: train_loss -0.6799 
2024-12-11 01:14:37.059322: val_loss -0.749 
2024-12-11 01:14:37.062420: Pseudo dice [np.float32(0.8881)] 
2024-12-11 01:14:37.065462: Epoch time: 41.91 s 
2024-12-11 01:14:37.068498: Yayy! New best EMA pseudo Dice: 0.7052000164985657 
2024-12-11 01:14:37.822112:  
2024-12-11 01:14:37.828189: Epoch 10 
2024-12-11 01:14:37.831252: Current learning rate: 0.0091 
2024-12-11 01:15:19.550804: train_loss -0.6745 
2024-12-11 01:15:19.556374: val_loss -0.7076 
2024-12-11 01:15:19.559421: Pseudo dice [np.float32(0.8352)] 
2024-12-11 01:15:19.562468: Epoch time: 41.73 s 
2024-12-11 01:15:19.564478: Yayy! New best EMA pseudo Dice: 0.7182000279426575 
2024-12-11 01:15:20.311928:  
2024-12-11 01:15:20.316975: Epoch 11 
2024-12-11 01:15:20.320027: Current learning rate: 0.009 
2024-12-11 01:16:01.897718: train_loss -0.707 
2024-12-11 01:16:01.903736: val_loss -0.6365 
2024-12-11 01:16:01.907242: Pseudo dice [np.float32(0.839)] 
2024-12-11 01:16:01.910249: Epoch time: 41.59 s 
2024-12-11 01:16:01.912755: Yayy! New best EMA pseudo Dice: 0.7303000092506409 
2024-12-11 01:16:02.653035:  
2024-12-11 01:16:02.658618: Epoch 12 
2024-12-11 01:16:02.661695: Current learning rate: 0.00891 
2024-12-11 01:16:44.362484: train_loss -0.7326 
2024-12-11 01:16:44.368083: val_loss -0.784 
2024-12-11 01:16:44.371643: Pseudo dice [np.float32(0.9268)] 
2024-12-11 01:16:44.373683: Epoch time: 41.71 s 
2024-12-11 01:16:44.377227: Yayy! New best EMA pseudo Dice: 0.7498999834060669 
2024-12-11 01:16:45.294902:  
2024-12-11 01:16:45.301060: Epoch 13 
2024-12-11 01:16:45.303568: Current learning rate: 0.00882 
2024-12-11 01:17:27.130629: train_loss -0.7392 
2024-12-11 01:17:27.135642: val_loss -0.7617 
2024-12-11 01:17:27.139151: Pseudo dice [np.float32(0.9171)] 
2024-12-11 01:17:27.142162: Epoch time: 41.84 s 
2024-12-11 01:17:27.144670: Yayy! New best EMA pseudo Dice: 0.7666000127792358 
2024-12-11 01:17:27.890141:  
2024-12-11 01:17:27.895183: Epoch 14 
2024-12-11 01:17:27.898708: Current learning rate: 0.00873 
2024-12-11 01:18:10.245142: train_loss -0.6972 
2024-12-11 01:18:10.250716: val_loss -0.6996 
2024-12-11 01:18:10.253766: Pseudo dice [np.float32(0.8503)] 
2024-12-11 01:18:10.256299: Epoch time: 42.36 s 
2024-12-11 01:18:10.260336: Yayy! New best EMA pseudo Dice: 0.7749999761581421 
2024-12-11 01:18:11.019943:  
2024-12-11 01:18:11.026054: Epoch 15 
2024-12-11 01:18:11.028069: Current learning rate: 0.00864 
2024-12-11 01:18:53.010380: train_loss -0.6922 
2024-12-11 01:18:53.016916: val_loss -0.7301 
2024-12-11 01:18:53.020430: Pseudo dice [np.float32(0.9204)] 
2024-12-11 01:18:53.023443: Epoch time: 41.99 s 
2024-12-11 01:18:53.025952: Yayy! New best EMA pseudo Dice: 0.7894999980926514 
2024-12-11 01:18:53.793970:  
2024-12-11 01:18:53.800625: Epoch 16 
2024-12-11 01:18:53.804187: Current learning rate: 0.00855 
2024-12-11 01:19:35.659141: train_loss -0.7228 
2024-12-11 01:19:35.664194: val_loss -0.7398 
2024-12-11 01:19:35.667728: Pseudo dice [np.float32(0.9304)] 
2024-12-11 01:19:35.671311: Epoch time: 41.87 s 
2024-12-11 01:19:35.674335: Yayy! New best EMA pseudo Dice: 0.803600013256073 
2024-12-11 01:19:36.445437:  
2024-12-11 01:19:36.451519: Epoch 17 
2024-12-11 01:19:36.454561: Current learning rate: 0.00846 
2024-12-11 01:20:18.474359: train_loss -0.7544 
2024-12-11 01:20:18.479951: val_loss -0.7126 
2024-12-11 01:20:18.484016: Pseudo dice [np.float32(0.9021)] 
2024-12-11 01:20:18.487025: Epoch time: 42.03 s 
2024-12-11 01:20:18.489533: Yayy! New best EMA pseudo Dice: 0.8134999871253967 
2024-12-11 01:20:19.257036:  
2024-12-11 01:20:19.263051: Epoch 18 
2024-12-11 01:20:19.266558: Current learning rate: 0.00836 
2024-12-11 01:21:01.579443: train_loss -0.7258 
2024-12-11 01:21:01.585182: val_loss -0.6354 
2024-12-11 01:21:01.587702: Pseudo dice [np.float32(0.8565)] 
2024-12-11 01:21:01.591447: Epoch time: 42.32 s 
2024-12-11 01:21:01.594963: Yayy! New best EMA pseudo Dice: 0.817799985408783 
2024-12-11 01:21:02.364304:  
2024-12-11 01:21:02.369316: Epoch 19 
2024-12-11 01:21:02.372830: Current learning rate: 0.00827 
2024-12-11 01:21:44.800075: train_loss -0.7438 
2024-12-11 01:21:44.806623: val_loss -0.7154 
2024-12-11 01:21:44.810152: Pseudo dice [np.float32(0.8723)] 
2024-12-11 01:21:44.813676: Epoch time: 42.44 s 
2024-12-11 01:21:44.816185: Yayy! New best EMA pseudo Dice: 0.823199987411499 
2024-12-11 01:21:45.586130:  
2024-12-11 01:21:45.592246: Epoch 20 
2024-12-11 01:21:45.596295: Current learning rate: 0.00818 
2024-12-11 01:22:27.813196: train_loss -0.7406 
2024-12-11 01:22:27.818247: val_loss -0.7364 
2024-12-11 01:22:27.820752: Pseudo dice [np.float32(0.9258)] 
2024-12-11 01:22:27.824302: Epoch time: 42.23 s 
2024-12-11 01:22:27.828310: Yayy! New best EMA pseudo Dice: 0.8335000276565552 
2024-12-11 01:22:28.781131:  
2024-12-11 01:22:28.786746: Epoch 21 
2024-12-11 01:22:28.790324: Current learning rate: 0.00809 
2024-12-11 01:23:11.352881: train_loss -0.6869 
2024-12-11 01:23:11.358927: val_loss -0.716 
2024-12-11 01:23:11.362446: Pseudo dice [np.float32(0.8823)] 
2024-12-11 01:23:11.365472: Epoch time: 42.57 s 
2024-12-11 01:23:11.369009: Yayy! New best EMA pseudo Dice: 0.8384000062942505 
2024-12-11 01:23:12.145257:  
2024-12-11 01:23:12.151364: Epoch 22 
2024-12-11 01:23:12.154444: Current learning rate: 0.008 
2024-12-11 01:23:54.100747: train_loss -0.728 
2024-12-11 01:23:54.105871: val_loss -0.6942 
2024-12-11 01:23:54.108924: Pseudo dice [np.float32(0.8533)] 
2024-12-11 01:23:54.112471: Epoch time: 41.96 s 
2024-12-11 01:23:54.116002: Yayy! New best EMA pseudo Dice: 0.839900016784668 
2024-12-11 01:23:54.868407:  
2024-12-11 01:23:54.873420: Epoch 23 
2024-12-11 01:23:54.876444: Current learning rate: 0.0079 
2024-12-11 01:24:37.122467: train_loss -0.7551 
2024-12-11 01:24:37.128538: val_loss -0.6803 
2024-12-11 01:24:37.131079: Pseudo dice [np.float32(0.8809)] 
2024-12-11 01:24:37.135116: Epoch time: 42.25 s 
2024-12-11 01:24:37.137655: Yayy! New best EMA pseudo Dice: 0.843999981880188 
2024-12-11 01:24:37.876226:  
2024-12-11 01:24:37.881236: Epoch 24 
2024-12-11 01:24:37.884747: Current learning rate: 0.00781 
2024-12-11 01:25:19.706814: train_loss -0.7291 
2024-12-11 01:25:19.711562: val_loss -0.8064 
2024-12-11 01:25:19.715624: Pseudo dice [np.float32(0.9422)] 
2024-12-11 01:25:19.718669: Epoch time: 41.83 s 
2024-12-11 01:25:19.721728: Yayy! New best EMA pseudo Dice: 0.8537999987602234 
2024-12-11 01:25:20.473987:  
2024-12-11 01:25:20.479599: Epoch 25 
2024-12-11 01:25:20.482639: Current learning rate: 0.00772 
2024-12-11 01:26:02.351348: train_loss -0.7328 
2024-12-11 01:26:02.357363: val_loss -0.7751 
2024-12-11 01:26:02.360868: Pseudo dice [np.float32(0.9188)] 
2024-12-11 01:26:02.363876: Epoch time: 41.88 s 
2024-12-11 01:26:02.367388: Yayy! New best EMA pseudo Dice: 0.8603000044822693 
2024-12-11 01:26:03.192581:  
2024-12-11 01:26:03.198630: Epoch 26 
2024-12-11 01:26:03.201645: Current learning rate: 0.00763 
2024-12-11 01:26:45.047021: train_loss -0.7236 
2024-12-11 01:26:45.053053: val_loss -0.7988 
2024-12-11 01:26:45.056080: Pseudo dice [np.float32(0.9278)] 
2024-12-11 01:26:45.059584: Epoch time: 41.85 s 
2024-12-11 01:26:45.063118: Yayy! New best EMA pseudo Dice: 0.8669999837875366 
2024-12-11 01:26:45.801692:  
2024-12-11 01:26:45.806726: Epoch 27 
2024-12-11 01:26:45.809475: Current learning rate: 0.00753 
2024-12-11 01:27:27.687765: train_loss -0.7073 
2024-12-11 01:27:27.692810: val_loss -0.7792 
2024-12-11 01:27:27.697363: Pseudo dice [np.float32(0.9067)] 
2024-12-11 01:27:27.700401: Epoch time: 41.89 s 
2024-12-11 01:27:27.704435: Yayy! New best EMA pseudo Dice: 0.8709999918937683 
2024-12-11 01:27:28.458144:  
2024-12-11 01:27:28.463664: Epoch 28 
2024-12-11 01:27:28.467234: Current learning rate: 0.00744 
2024-12-11 01:28:10.718452: train_loss -0.7007 
2024-12-11 01:28:10.724047: val_loss -0.6061 
2024-12-11 01:28:10.726577: Pseudo dice [np.float32(0.7916)] 
2024-12-11 01:28:10.731133: Epoch time: 42.26 s 
2024-12-11 01:28:11.494941:  
2024-12-11 01:28:11.500454: Epoch 29 
2024-12-11 01:28:11.502996: Current learning rate: 0.00735 
2024-12-11 01:28:53.443631: train_loss -0.762 
2024-12-11 01:28:53.450199: val_loss -0.7759 
2024-12-11 01:28:53.453727: Pseudo dice [np.float32(0.9087)] 
2024-12-11 01:28:53.456276: Epoch time: 41.95 s 
2024-12-11 01:28:54.051333:  
2024-12-11 01:28:54.057932: Epoch 30 
2024-12-11 01:28:54.060578: Current learning rate: 0.00725 
2024-12-11 01:29:35.955020: train_loss -0.7421 
2024-12-11 01:29:35.960035: val_loss -0.7225 
2024-12-11 01:29:35.963542: Pseudo dice [np.float32(0.875)] 
2024-12-11 01:29:35.966551: Epoch time: 41.9 s 
2024-12-11 01:29:36.550418:  
2024-12-11 01:29:36.555944: Epoch 31 
2024-12-11 01:29:36.558971: Current learning rate: 0.00716 
2024-12-11 01:30:18.446504: train_loss -0.7288 
2024-12-11 01:30:18.452574: val_loss -0.7417 
2024-12-11 01:30:18.455614: Pseudo dice [np.float32(0.9098)] 
2024-12-11 01:30:18.458692: Epoch time: 41.9 s 
2024-12-11 01:30:18.461757: Yayy! New best EMA pseudo Dice: 0.8725000023841858 
2024-12-11 01:30:19.227684:  
2024-12-11 01:30:19.233198: Epoch 32 
2024-12-11 01:30:19.236713: Current learning rate: 0.00707 
2024-12-11 01:31:01.222556: train_loss -0.739 
2024-12-11 01:31:01.227566: val_loss -0.771 
2024-12-11 01:31:01.231577: Pseudo dice [np.float32(0.9297)] 
2024-12-11 01:31:01.234083: Epoch time: 42.0 s 
2024-12-11 01:31:01.237592: Yayy! New best EMA pseudo Dice: 0.8781999945640564 
2024-12-11 01:31:02.019334:  
2024-12-11 01:31:02.024345: Epoch 33 
2024-12-11 01:31:02.027853: Current learning rate: 0.00697 
2024-12-11 01:31:44.151927: train_loss -0.7697 
2024-12-11 01:31:44.157478: val_loss -0.7609 
2024-12-11 01:31:44.161016: Pseudo dice [np.float32(0.906)] 
2024-12-11 01:31:44.163541: Epoch time: 42.13 s 
2024-12-11 01:31:44.167067: Yayy! New best EMA pseudo Dice: 0.8809999823570251 
2024-12-11 01:31:44.913102:  
2024-12-11 01:31:44.919240: Epoch 34 
2024-12-11 01:31:44.921786: Current learning rate: 0.00688 
2024-12-11 01:32:26.627225: train_loss -0.7556 
2024-12-11 01:32:26.633273: val_loss -0.7438 
2024-12-11 01:32:26.637285: Pseudo dice [np.float32(0.9208)] 
2024-12-11 01:32:26.639792: Epoch time: 41.71 s 
2024-12-11 01:32:26.643303: Yayy! New best EMA pseudo Dice: 0.8849999904632568 
2024-12-11 01:32:27.410717:  
2024-12-11 01:32:27.416234: Epoch 35 
2024-12-11 01:32:27.419745: Current learning rate: 0.00679 
2024-12-11 01:33:10.172168: train_loss -0.7752 
2024-12-11 01:33:10.177311: val_loss -0.712 
2024-12-11 01:33:10.180358: Pseudo dice [np.float32(0.9061)] 
2024-12-11 01:33:10.184396: Epoch time: 42.76 s 
2024-12-11 01:33:10.187408: Yayy! New best EMA pseudo Dice: 0.8870999813079834 
2024-12-11 01:33:10.943531:  
2024-12-11 01:33:10.949577: Epoch 36 
2024-12-11 01:33:10.952607: Current learning rate: 0.00669 
2024-12-11 01:33:52.671932: train_loss -0.771 
2024-12-11 01:33:52.677522: val_loss -0.7253 
2024-12-11 01:33:52.680552: Pseudo dice [np.float32(0.9327)] 
2024-12-11 01:33:52.683057: Epoch time: 41.73 s 
2024-12-11 01:33:52.686686: Yayy! New best EMA pseudo Dice: 0.891700029373169 
2024-12-11 01:33:53.609246:  
2024-12-11 01:33:53.614294: Epoch 37 
2024-12-11 01:33:53.617457: Current learning rate: 0.0066 
2024-12-11 01:34:35.888998: train_loss -0.761 
2024-12-11 01:34:35.895127: val_loss -0.8118 
2024-12-11 01:34:35.898142: Pseudo dice [np.float32(0.9447)] 
2024-12-11 01:34:35.901667: Epoch time: 42.28 s 
2024-12-11 01:34:35.904183: Yayy! New best EMA pseudo Dice: 0.8970000147819519 
2024-12-11 01:34:36.677563:  
2024-12-11 01:34:36.682574: Epoch 38 
2024-12-11 01:34:36.686090: Current learning rate: 0.0065 
2024-12-11 01:35:18.603344: train_loss -0.7788 
2024-12-11 01:35:18.608484: val_loss -0.7703 
2024-12-11 01:35:18.611551: Pseudo dice [np.float32(0.9201)] 
2024-12-11 01:35:18.614100: Epoch time: 41.93 s 
2024-12-11 01:35:18.617326: Yayy! New best EMA pseudo Dice: 0.8992999792098999 
2024-12-11 01:35:19.373618:  
2024-12-11 01:35:19.379755: Epoch 39 
2024-12-11 01:35:19.383785: Current learning rate: 0.00641 
2024-12-11 01:36:01.231266: train_loss -0.7639 
2024-12-11 01:36:01.237383: val_loss -0.8071 
2024-12-11 01:36:01.240403: Pseudo dice [np.float32(0.942)] 
2024-12-11 01:36:01.243920: Epoch time: 41.86 s 
2024-12-11 01:36:01.246536: Yayy! New best EMA pseudo Dice: 0.9035000205039978 
2024-12-11 01:36:02.011883:  
2024-12-11 01:36:02.017581: Epoch 40 
2024-12-11 01:36:02.021132: Current learning rate: 0.00631 
2024-12-11 01:36:43.705087: train_loss -0.7637 
2024-12-11 01:36:43.710157: val_loss -0.7922 
2024-12-11 01:36:43.713675: Pseudo dice [np.float32(0.9463)] 
2024-12-11 01:36:43.716191: Epoch time: 41.69 s 
2024-12-11 01:36:43.719805: Yayy! New best EMA pseudo Dice: 0.907800018787384 
2024-12-11 01:36:44.486107:  
2024-12-11 01:36:44.492214: Epoch 41 
2024-12-11 01:36:44.495271: Current learning rate: 0.00622 
2024-12-11 01:37:26.360987: train_loss -0.7517 
2024-12-11 01:37:26.366642: val_loss -0.8242 
2024-12-11 01:37:26.370151: Pseudo dice [np.float32(0.9317)] 
2024-12-11 01:37:26.373656: Epoch time: 41.87 s 
2024-12-11 01:37:26.376743: Yayy! New best EMA pseudo Dice: 0.9101999998092651 
2024-12-11 01:37:27.103431:  
2024-12-11 01:37:27.109079: Epoch 42 
2024-12-11 01:37:27.113131: Current learning rate: 0.00612 
2024-12-11 01:38:08.958924: train_loss -0.7727 
2024-12-11 01:38:08.964504: val_loss -0.7414 
2024-12-11 01:38:08.967130: Pseudo dice [np.float32(0.9156)] 
2024-12-11 01:38:08.970649: Epoch time: 41.86 s 
2024-12-11 01:38:08.973666: Yayy! New best EMA pseudo Dice: 0.9107000231742859 
2024-12-11 01:38:09.718970:  
2024-12-11 01:38:09.725458: Epoch 43 
2024-12-11 01:38:09.728493: Current learning rate: 0.00603 
2024-12-11 01:38:51.686756: train_loss -0.774 
2024-12-11 01:38:51.692772: val_loss -0.7682 
2024-12-11 01:38:51.696278: Pseudo dice [np.float32(0.9275)] 
2024-12-11 01:38:51.699287: Epoch time: 41.97 s 
2024-12-11 01:38:51.701794: Yayy! New best EMA pseudo Dice: 0.9124000072479248 
2024-12-11 01:38:52.453494:  
2024-12-11 01:38:52.459153: Epoch 44 
2024-12-11 01:38:52.462187: Current learning rate: 0.00593 
2024-12-11 01:39:34.813555: train_loss -0.77 
2024-12-11 01:39:34.818670: val_loss -0.8322 
2024-12-11 01:39:34.822683: Pseudo dice [np.float32(0.9497)] 
2024-12-11 01:39:34.826192: Epoch time: 42.36 s 
2024-12-11 01:39:34.828875: Yayy! New best EMA pseudo Dice: 0.9161999821662903 
2024-12-11 01:39:35.733855:  
2024-12-11 01:39:35.738986: Epoch 45 
2024-12-11 01:39:35.742016: Current learning rate: 0.00584 
2024-12-11 01:40:17.312969: train_loss -0.7629 
2024-12-11 01:40:17.319550: val_loss -0.7942 
2024-12-11 01:40:17.324564: Pseudo dice [np.float32(0.9362)] 
2024-12-11 01:40:17.328073: Epoch time: 41.58 s 
2024-12-11 01:40:17.331085: Yayy! New best EMA pseudo Dice: 0.9182000160217285 
2024-12-11 01:40:18.056293:  
2024-12-11 01:40:18.061946: Epoch 46 
2024-12-11 01:40:18.065469: Current learning rate: 0.00574 
2024-12-11 01:40:59.941821: train_loss -0.7735 
2024-12-11 01:40:59.946518: val_loss -0.8141 
2024-12-11 01:40:59.950546: Pseudo dice [np.float32(0.9523)] 
2024-12-11 01:40:59.956429: Epoch time: 41.89 s 
2024-12-11 01:40:59.962019: Yayy! New best EMA pseudo Dice: 0.9215999841690063 
2024-12-11 01:41:00.708311:  
2024-12-11 01:41:00.713848: Epoch 47 
2024-12-11 01:41:00.717460: Current learning rate: 0.00565 
2024-12-11 01:41:42.873670: train_loss -0.7737 
2024-12-11 01:41:42.879323: val_loss -0.7786 
2024-12-11 01:41:42.882852: Pseudo dice [np.float32(0.9314)] 
2024-12-11 01:41:42.885992: Epoch time: 42.17 s 
2024-12-11 01:41:42.889041: Yayy! New best EMA pseudo Dice: 0.9225999712944031 
2024-12-11 01:41:43.601595:  
2024-12-11 01:41:43.607229: Epoch 48 
2024-12-11 01:41:43.610845: Current learning rate: 0.00555 
2024-12-11 01:42:26.374676: train_loss -0.7389 
2024-12-11 01:42:26.378829: val_loss -0.7902 
2024-12-11 01:42:26.383436: Pseudo dice [np.float32(0.9545)] 
2024-12-11 01:42:26.386000: Epoch time: 42.77 s 
2024-12-11 01:42:26.389042: Yayy! New best EMA pseudo Dice: 0.9258000254631042 
2024-12-11 01:42:27.157072:  
2024-12-11 01:42:27.162674: Epoch 49 
2024-12-11 01:42:27.166209: Current learning rate: 0.00546 
2024-12-11 01:43:08.863567: train_loss -0.727 
2024-12-11 01:43:08.869190: val_loss -0.7903 
2024-12-11 01:43:08.873199: Pseudo dice [np.float32(0.9067)] 
2024-12-11 01:43:08.878346: Epoch time: 41.71 s 
2024-12-11 01:43:09.595005:  
2024-12-11 01:43:09.600644: Epoch 50 
2024-12-11 01:43:09.603171: Current learning rate: 0.00536 
2024-12-11 01:43:51.952618: train_loss -0.7685 
2024-12-11 01:43:51.957259: val_loss -0.7293 
2024-12-11 01:43:51.961812: Pseudo dice [np.float32(0.9079)] 
2024-12-11 01:43:51.964846: Epoch time: 42.36 s 
2024-12-11 01:43:52.580148:  
2024-12-11 01:43:52.585807: Epoch 51 
2024-12-11 01:43:52.588833: Current learning rate: 0.00526 
2024-12-11 01:44:34.842832: train_loss -0.7542 
2024-12-11 01:44:34.848976: val_loss -0.748 
2024-12-11 01:44:34.852531: Pseudo dice [np.float32(0.9133)] 
2024-12-11 01:44:34.855075: Epoch time: 42.26 s 
2024-12-11 01:44:35.435076:  
2024-12-11 01:44:35.439192: Epoch 52 
2024-12-11 01:44:35.441782: Current learning rate: 0.00517 
2024-12-11 01:45:17.767593: train_loss -0.7857 
2024-12-11 01:45:17.772613: val_loss -0.8386 
2024-12-11 01:45:17.776211: Pseudo dice [np.float32(0.948)] 
2024-12-11 01:45:17.778721: Epoch time: 42.33 s 
2024-12-11 01:45:18.505403:  
2024-12-11 01:45:18.510992: Epoch 53 
2024-12-11 01:45:18.513594: Current learning rate: 0.00507 
2024-12-11 01:46:00.887462: train_loss -0.7357 
2024-12-11 01:46:00.893011: val_loss -0.7495 
2024-12-11 01:46:00.896127: Pseudo dice [np.float32(0.8873)] 
2024-12-11 01:46:00.899640: Epoch time: 42.38 s 
2024-12-11 01:46:01.477067:  
2024-12-11 01:46:01.482633: Epoch 54 
2024-12-11 01:46:01.485730: Current learning rate: 0.00497 
2024-12-11 01:46:43.970940: train_loss -0.7958 
2024-12-11 01:46:43.976590: val_loss -0.7305 
2024-12-11 01:46:43.980142: Pseudo dice [np.float32(0.858)] 
2024-12-11 01:46:43.983173: Epoch time: 42.5 s 
2024-12-11 01:46:44.592697:  
2024-12-11 01:46:44.597762: Epoch 55 
2024-12-11 01:46:44.600862: Current learning rate: 0.00487 
2024-12-11 01:47:26.861237: train_loss -0.7806 
2024-12-11 01:47:26.866341: val_loss -0.7062 
2024-12-11 01:47:26.869850: Pseudo dice [np.float32(0.8587)] 
2024-12-11 01:47:26.872356: Epoch time: 42.27 s 
2024-12-11 01:47:27.453892:  
2024-12-11 01:47:27.458929: Epoch 56 
2024-12-11 01:47:27.461958: Current learning rate: 0.00478 
2024-12-11 01:48:09.982920: train_loss -0.7645 
2024-12-11 01:48:09.988522: val_loss -0.8012 
2024-12-11 01:48:09.992038: Pseudo dice [np.float32(0.9518)] 
2024-12-11 01:48:09.995052: Epoch time: 42.53 s 
2024-12-11 01:48:10.571451:  
2024-12-11 01:48:10.576583: Epoch 57 
2024-12-11 01:48:10.580137: Current learning rate: 0.00468 
2024-12-11 01:48:52.963481: train_loss -0.7795 
2024-12-11 01:48:52.969499: val_loss -0.7531 
2024-12-11 01:48:52.972004: Pseudo dice [np.float32(0.9176)] 
2024-12-11 01:48:52.975590: Epoch time: 42.39 s 
2024-12-11 01:48:53.561947:  
2024-12-11 01:48:53.567134: Epoch 58 
2024-12-11 01:48:53.570249: Current learning rate: 0.00458 
2024-12-11 01:49:35.994671: train_loss -0.794 
2024-12-11 01:49:36.000773: val_loss -0.7709 
2024-12-11 01:49:36.004980: Pseudo dice [np.float32(0.9112)] 
2024-12-11 01:49:36.008572: Epoch time: 42.43 s 
2024-12-11 01:49:36.593284:  
2024-12-11 01:49:36.599359: Epoch 59 
2024-12-11 01:49:36.602868: Current learning rate: 0.00448 
2024-12-11 01:50:18.887056: train_loss -0.8166 
2024-12-11 01:50:18.892134: val_loss -0.8005 
2024-12-11 01:50:18.894657: Pseudo dice [np.float32(0.951)] 
2024-12-11 01:50:18.898290: Epoch time: 42.29 s 
2024-12-11 01:50:19.484319:  
2024-12-11 01:50:19.489993: Epoch 60 
2024-12-11 01:50:19.493525: Current learning rate: 0.00438 
2024-12-11 01:51:01.663940: train_loss -0.7941 
2024-12-11 01:51:01.670112: val_loss -0.8492 
2024-12-11 01:51:01.673635: Pseudo dice [np.float32(0.9562)] 
2024-12-11 01:51:01.676744: Epoch time: 42.18 s 
2024-12-11 01:51:02.468724:  
2024-12-11 01:51:02.474377: Epoch 61 
2024-12-11 01:51:02.478003: Current learning rate: 0.00429 
2024-12-11 01:51:44.822345: train_loss -0.8027 
2024-12-11 01:51:44.828429: val_loss -0.7577 
2024-12-11 01:51:44.831440: Pseudo dice [np.float32(0.9393)] 
2024-12-11 01:51:44.834952: Epoch time: 42.35 s 
2024-12-11 01:51:45.429126:  
2024-12-11 01:51:45.434772: Epoch 62 
2024-12-11 01:51:45.437902: Current learning rate: 0.00419 
2024-12-11 01:52:27.597835: train_loss -0.7517 
2024-12-11 01:52:27.602881: val_loss -0.8148 
2024-12-11 01:52:27.605989: Pseudo dice [np.float32(0.9417)] 
2024-12-11 01:52:27.609536: Epoch time: 42.17 s 
2024-12-11 01:52:28.199084:  
2024-12-11 01:52:28.204597: Epoch 63 
2024-12-11 01:52:28.208211: Current learning rate: 0.00409 
2024-12-11 01:53:10.409667: train_loss -0.7915 
2024-12-11 01:53:10.415247: val_loss -0.8213 
2024-12-11 01:53:10.419383: Pseudo dice [np.float32(0.9371)] 
2024-12-11 01:53:10.422516: Epoch time: 42.21 s 
2024-12-11 01:53:10.425549: Yayy! New best EMA pseudo Dice: 0.9258999824523926 
2024-12-11 01:53:11.189081:  
2024-12-11 01:53:11.194671: Epoch 64 
2024-12-11 01:53:11.198319: Current learning rate: 0.00399 
2024-12-11 01:53:53.342495: train_loss -0.7906 
2024-12-11 01:53:53.348109: val_loss -0.7258 
2024-12-11 01:53:53.351639: Pseudo dice [np.float32(0.8794)] 
2024-12-11 01:53:53.354679: Epoch time: 42.15 s 
2024-12-11 01:53:53.977188:  
2024-12-11 01:53:53.982283: Epoch 65 
2024-12-11 01:53:53.984818: Current learning rate: 0.00389 
2024-12-11 01:54:36.591440: train_loss -0.807 
2024-12-11 01:54:36.597119: val_loss -0.7364 
2024-12-11 01:54:36.600176: Pseudo dice [np.float32(0.8674)] 
2024-12-11 01:54:36.604204: Epoch time: 42.61 s 
2024-12-11 01:54:37.208885:  
2024-12-11 01:54:37.214558: Epoch 66 
2024-12-11 01:54:37.217696: Current learning rate: 0.00379 
2024-12-11 01:55:20.027013: train_loss -0.7714 
2024-12-11 01:55:20.033024: val_loss -0.7386 
2024-12-11 01:55:20.036072: Pseudo dice [np.float32(0.9404)] 
2024-12-11 01:55:20.039587: Epoch time: 42.82 s 
2024-12-11 01:55:20.646178:  
2024-12-11 01:55:20.650012: Epoch 67 
2024-12-11 01:55:20.654141: Current learning rate: 0.00369 
2024-12-11 01:56:03.329133: train_loss -0.8012 
2024-12-11 01:56:03.334241: val_loss -0.7917 
2024-12-11 01:56:03.337855: Pseudo dice [np.float32(0.933)] 
2024-12-11 01:56:03.340945: Epoch time: 42.68 s 
2024-12-11 01:56:03.948678:  
2024-12-11 01:56:03.954335: Epoch 68 
2024-12-11 01:56:03.958477: Current learning rate: 0.00359 
2024-12-11 01:56:46.105008: train_loss -0.7916 
2024-12-11 01:56:46.110076: val_loss -0.7459 
2024-12-11 01:56:46.113586: Pseudo dice [np.float32(0.8945)] 
2024-12-11 01:56:46.116098: Epoch time: 42.16 s 
2024-12-11 01:56:46.884467:  
2024-12-11 01:56:46.890181: Epoch 69 
2024-12-11 01:56:46.893244: Current learning rate: 0.00349 
2024-12-11 01:57:28.928911: train_loss -0.7891 
2024-12-11 01:57:28.935435: val_loss -0.8042 
2024-12-11 01:57:28.938943: Pseudo dice [np.float32(0.9407)] 
2024-12-11 01:57:28.941954: Epoch time: 42.04 s 
2024-12-11 01:57:29.549536:  
2024-12-11 01:57:29.554690: Epoch 70 
2024-12-11 01:57:29.557833: Current learning rate: 0.00338 
2024-12-11 01:58:11.486065: train_loss -0.7961 
2024-12-11 01:58:11.491195: val_loss -0.7627 
2024-12-11 01:58:11.494758: Pseudo dice [np.float32(0.885)] 
2024-12-11 01:58:11.497465: Epoch time: 41.94 s 
2024-12-11 01:58:12.112540:  
2024-12-11 01:58:12.117763: Epoch 71 
2024-12-11 01:58:12.121338: Current learning rate: 0.00328 
2024-12-11 01:58:54.225458: train_loss -0.7905 
2024-12-11 01:58:54.230589: val_loss -0.8194 
2024-12-11 01:58:54.234151: Pseudo dice [np.float32(0.948)] 
2024-12-11 01:58:54.237303: Epoch time: 42.11 s 
2024-12-11 01:58:54.832258:  
2024-12-11 01:58:54.837500: Epoch 72 
2024-12-11 01:58:54.840539: Current learning rate: 0.00318 
2024-12-11 01:59:37.923399: train_loss -0.8029 
2024-12-11 01:59:37.929412: val_loss -0.868 
2024-12-11 01:59:37.932423: Pseudo dice [np.float32(0.9566)] 
2024-12-11 01:59:37.934928: Epoch time: 43.09 s 
2024-12-11 01:59:38.513664:  
2024-12-11 01:59:38.519289: Epoch 73 
2024-12-11 01:59:38.524358: Current learning rate: 0.00308 
2024-12-11 02:00:20.402340: train_loss -0.8079 
2024-12-11 02:00:20.407965: val_loss -0.8008 
2024-12-11 02:00:20.411554: Pseudo dice [np.float32(0.9574)] 
2024-12-11 02:00:20.414567: Epoch time: 41.89 s 
2024-12-11 02:00:20.418220: Yayy! New best EMA pseudo Dice: 0.9265000224113464 
2024-12-11 02:00:21.151944:  
2024-12-11 02:00:21.157092: Epoch 74 
2024-12-11 02:00:21.159598: Current learning rate: 0.00297 
2024-12-11 02:01:03.153892: train_loss -0.7834 
2024-12-11 02:01:03.159588: val_loss -0.7839 
2024-12-11 02:01:03.163133: Pseudo dice [np.float32(0.9322)] 
2024-12-11 02:01:03.166744: Epoch time: 42.0 s 
2024-12-11 02:01:03.169806: Yayy! New best EMA pseudo Dice: 0.9269999861717224 
2024-12-11 02:01:03.912659:  
2024-12-11 02:01:03.918354: Epoch 75 
2024-12-11 02:01:03.920890: Current learning rate: 0.00287 
2024-12-11 02:01:46.137933: train_loss -0.807 
2024-12-11 02:01:46.143537: val_loss -0.8144 
2024-12-11 02:01:46.147008: Pseudo dice [np.float32(0.9521)] 
2024-12-11 02:01:46.151018: Epoch time: 42.23 s 
2024-12-11 02:01:46.153523: Yayy! New best EMA pseudo Dice: 0.9296000003814697 
2024-12-11 02:01:46.897349:  
2024-12-11 02:01:46.902372: Epoch 76 
2024-12-11 02:01:46.905804: Current learning rate: 0.00277 
2024-12-11 02:02:28.807694: train_loss -0.7589 
2024-12-11 02:02:28.812705: val_loss -0.7974 
2024-12-11 02:02:28.816217: Pseudo dice [np.float32(0.938)] 
2024-12-11 02:02:28.819729: Epoch time: 41.91 s 
2024-12-11 02:02:28.822752: Yayy! New best EMA pseudo Dice: 0.930400013923645 
2024-12-11 02:02:29.718046:  
2024-12-11 02:02:29.722621: Epoch 77 
2024-12-11 02:02:29.726214: Current learning rate: 0.00266 
2024-12-11 02:03:11.818080: train_loss -0.774 
2024-12-11 02:03:11.823601: val_loss -0.6969 
2024-12-11 02:03:11.828616: Pseudo dice [np.float32(0.8777)] 
2024-12-11 02:03:11.832126: Epoch time: 42.1 s 
2024-12-11 02:03:12.428379:  
2024-12-11 02:03:12.434012: Epoch 78 
2024-12-11 02:03:12.437050: Current learning rate: 0.00256 
2024-12-11 02:03:54.481641: train_loss -0.7942 
2024-12-11 02:03:54.487306: val_loss -0.8157 
2024-12-11 02:03:54.490837: Pseudo dice [np.float32(0.9263)] 
2024-12-11 02:03:54.494379: Epoch time: 42.05 s 
2024-12-11 02:03:55.079962:  
2024-12-11 02:03:55.085636: Epoch 79 
2024-12-11 02:03:55.089177: Current learning rate: 0.00245 
2024-12-11 02:04:37.030834: train_loss -0.7866 
2024-12-11 02:04:37.036393: val_loss -0.7922 
2024-12-11 02:04:37.038439: Pseudo dice [np.float32(0.9413)] 
2024-12-11 02:04:37.042464: Epoch time: 41.95 s 
2024-12-11 02:04:37.626081:  
2024-12-11 02:04:37.631651: Epoch 80 
2024-12-11 02:04:37.634698: Current learning rate: 0.00235 
2024-12-11 02:05:19.393476: train_loss -0.7861 
2024-12-11 02:05:19.399113: val_loss -0.7655 
2024-12-11 02:05:19.402165: Pseudo dice [np.float32(0.9314)] 
2024-12-11 02:05:19.405679: Epoch time: 41.77 s 
2024-12-11 02:05:19.997156:  
2024-12-11 02:05:20.002193: Epoch 81 
2024-12-11 02:05:20.006217: Current learning rate: 0.00224 
2024-12-11 02:06:01.934604: train_loss -0.8056 
2024-12-11 02:06:01.940229: val_loss -0.8001 
2024-12-11 02:06:01.946433: Pseudo dice [np.float32(0.9067)] 
2024-12-11 02:06:01.950944: Epoch time: 41.94 s 
2024-12-11 02:06:02.543325:  
2024-12-11 02:06:02.548995: Epoch 82 
2024-12-11 02:06:02.552025: Current learning rate: 0.00214 
2024-12-11 02:06:44.581440: train_loss -0.7782 
2024-12-11 02:06:44.588973: val_loss -0.8251 
2024-12-11 02:06:44.592482: Pseudo dice [np.float32(0.9595)] 
2024-12-11 02:06:44.595493: Epoch time: 42.04 s 
2024-12-11 02:06:45.146789:  
2024-12-11 02:06:45.152370: Epoch 83 
2024-12-11 02:06:45.155432: Current learning rate: 0.00203 
2024-12-11 02:07:27.392130: train_loss -0.8049 
2024-12-11 02:07:27.397790: val_loss -0.824 
2024-12-11 02:07:27.401316: Pseudo dice [np.float32(0.947)] 
2024-12-11 02:07:27.404857: Epoch time: 42.25 s 
2024-12-11 02:07:27.407966: Yayy! New best EMA pseudo Dice: 0.9304999709129333 
2024-12-11 02:07:28.335148:  
2024-12-11 02:07:28.340271: Epoch 84 
2024-12-11 02:07:28.343284: Current learning rate: 0.00192 
2024-12-11 02:08:10.159648: train_loss -0.7749 
2024-12-11 02:08:10.165236: val_loss -0.7783 
2024-12-11 02:08:10.168253: Pseudo dice [np.float32(0.9112)] 
2024-12-11 02:08:10.171281: Epoch time: 41.83 s 
2024-12-11 02:08:10.747363:  
2024-12-11 02:08:10.752467: Epoch 85 
2024-12-11 02:08:10.755640: Current learning rate: 0.00181 
2024-12-11 02:08:52.637935: train_loss -0.8008 
2024-12-11 02:08:52.643053: val_loss -0.799 
2024-12-11 02:08:52.647167: Pseudo dice [np.float32(0.9437)] 
2024-12-11 02:08:52.650207: Epoch time: 41.89 s 
2024-12-11 02:08:53.260001:  
2024-12-11 02:08:53.265589: Epoch 86 
2024-12-11 02:08:53.268652: Current learning rate: 0.0017 
2024-12-11 02:09:35.390380: train_loss -0.7797 
2024-12-11 02:09:35.396584: val_loss -0.7941 
2024-12-11 02:09:35.400126: Pseudo dice [np.float32(0.9609)] 
2024-12-11 02:09:35.403646: Epoch time: 42.13 s 
2024-12-11 02:09:35.406701: Yayy! New best EMA pseudo Dice: 0.9332000017166138 
2024-12-11 02:09:36.156940:  
2024-12-11 02:09:36.162751: Epoch 87 
2024-12-11 02:09:36.165784: Current learning rate: 0.00159 
2024-12-11 02:10:18.091539: train_loss -0.7998 
2024-12-11 02:10:18.096552: val_loss -0.8382 
2024-12-11 02:10:18.101062: Pseudo dice [np.float32(0.959)] 
2024-12-11 02:10:18.104071: Epoch time: 41.94 s 
2024-12-11 02:10:18.106577: Yayy! New best EMA pseudo Dice: 0.9358000159263611 
2024-12-11 02:10:18.828439:  
2024-12-11 02:10:18.833970: Epoch 88 
2024-12-11 02:10:18.839079: Current learning rate: 0.00148 
2024-12-11 02:11:00.776288: train_loss -0.7766 
2024-12-11 02:11:00.780969: val_loss -0.8351 
2024-12-11 02:11:00.785535: Pseudo dice [np.float32(0.9448)] 
2024-12-11 02:11:00.788588: Epoch time: 41.95 s 
2024-12-11 02:11:00.791124: Yayy! New best EMA pseudo Dice: 0.9366999864578247 
2024-12-11 02:11:01.530792:  
2024-12-11 02:11:01.535817: Epoch 89 
2024-12-11 02:11:01.539407: Current learning rate: 0.00137 
2024-12-11 02:11:43.681125: train_loss -0.775 
2024-12-11 02:11:43.687141: val_loss -0.7383 
2024-12-11 02:11:43.690648: Pseudo dice [np.float32(0.9082)] 
2024-12-11 02:11:43.693657: Epoch time: 42.15 s 
2024-12-11 02:11:44.259182:  
2024-12-11 02:11:44.264208: Epoch 90 
2024-12-11 02:11:44.266890: Current learning rate: 0.00126 
2024-12-11 02:12:26.084703: train_loss -0.7989 
2024-12-11 02:12:26.090852: val_loss -0.7522 
2024-12-11 02:12:26.094376: Pseudo dice [np.float32(0.9016)] 
2024-12-11 02:12:26.096883: Epoch time: 41.83 s 
2024-12-11 02:12:26.649565:  
2024-12-11 02:12:26.654578: Epoch 91 
2024-12-11 02:12:26.657588: Current learning rate: 0.00115 
2024-12-11 02:13:09.031855: train_loss -0.7954 
2024-12-11 02:13:09.037581: val_loss -0.8072 
2024-12-11 02:13:09.040137: Pseudo dice [np.float32(0.9265)] 
2024-12-11 02:13:09.043662: Epoch time: 42.38 s 
2024-12-11 02:13:09.600156:  
2024-12-11 02:13:09.605305: Epoch 92 
2024-12-11 02:13:09.608440: Current learning rate: 0.00103 
2024-12-11 02:13:51.839638: train_loss -0.7907 
2024-12-11 02:13:51.844744: val_loss -0.8172 
2024-12-11 02:13:51.848829: Pseudo dice [np.float32(0.9464)] 
2024-12-11 02:13:51.851972: Epoch time: 42.24 s 
2024-12-11 02:13:52.559530:  
2024-12-11 02:13:52.565076: Epoch 93 
2024-12-11 02:13:52.568197: Current learning rate: 0.00091 
2024-12-11 02:14:34.803947: train_loss -0.8045 
2024-12-11 02:14:34.809524: val_loss -0.8018 
2024-12-11 02:14:34.814057: Pseudo dice [np.float32(0.9394)] 
2024-12-11 02:14:34.816598: Epoch time: 42.24 s 
2024-12-11 02:14:35.373296:  
2024-12-11 02:14:35.379817: Epoch 94 
2024-12-11 02:14:35.383323: Current learning rate: 0.00079 
2024-12-11 02:15:17.589461: train_loss -0.7927 
2024-12-11 02:15:17.596061: val_loss -0.7918 
2024-12-11 02:15:17.599576: Pseudo dice [np.float32(0.9205)] 
2024-12-11 02:15:17.602614: Epoch time: 42.22 s 
2024-12-11 02:15:18.156512:  
2024-12-11 02:15:18.162167: Epoch 95 
2024-12-11 02:15:18.165745: Current learning rate: 0.00067 
2024-12-11 02:16:00.070971: train_loss -0.8044 
2024-12-11 02:16:00.076613: val_loss -0.7722 
2024-12-11 02:16:00.079160: Pseudo dice [np.float32(0.9223)] 
2024-12-11 02:16:00.083277: Epoch time: 41.91 s 
2024-12-11 02:16:00.644481:  
2024-12-11 02:16:00.649684: Epoch 96 
2024-12-11 02:16:00.653238: Current learning rate: 0.00055 
2024-12-11 02:16:42.875097: train_loss -0.813 
2024-12-11 02:16:42.880005: val_loss -0.8434 
2024-12-11 02:16:42.883515: Pseudo dice [np.float32(0.9647)] 
2024-12-11 02:16:42.887527: Epoch time: 42.23 s 
2024-12-11 02:16:43.440482:  
2024-12-11 02:16:43.446134: Epoch 97 
2024-12-11 02:16:43.449295: Current learning rate: 0.00043 
2024-12-11 02:17:25.556723: train_loss -0.8059 
2024-12-11 02:17:25.562340: val_loss -0.78 
2024-12-11 02:17:25.565408: Pseudo dice [np.float32(0.9432)] 
2024-12-11 02:17:25.568798: Epoch time: 42.12 s 
2024-12-11 02:17:26.162142:  
2024-12-11 02:17:26.167775: Epoch 98 
2024-12-11 02:17:26.170861: Current learning rate: 0.0003 
2024-12-11 02:18:08.194144: train_loss -0.7678 
2024-12-11 02:18:08.199477: val_loss -0.783 
2024-12-11 02:18:08.202995: Pseudo dice [np.float32(0.9339)] 
2024-12-11 02:18:08.205462: Epoch time: 42.03 s 
2024-12-11 02:18:08.774959:  
2024-12-11 02:18:08.779152: Epoch 99 
2024-12-11 02:18:08.781674: Current learning rate: 0.00016 
2024-12-11 02:18:50.763857: train_loss -0.8148 
2024-12-11 02:18:50.768950: val_loss -0.8311 
2024-12-11 02:18:50.772800: Pseudo dice [np.float32(0.9542)] 
2024-12-11 02:18:50.775881: Epoch time: 41.99 s 
2024-12-11 02:18:50.778510: Yayy! New best EMA pseudo Dice: 0.9366999864578247 
2024-12-11 02:18:51.708433: Training done. 
2024-12-11 02:18:51.742192: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset009_Spleen\splits_final.json 
2024-12-11 02:18:51.753375: The split file contains 5 splits. 
2024-12-11 02:18:51.757023: Desired fold for training: 0 
2024-12-11 02:18:51.763534: This split has 32 training and 9 validation cases. 
2024-12-11 02:18:51.768185: predicting spleen_10 
2024-12-11 02:18:51.773199: spleen_10, shape torch.Size([1, 138, 250, 250]), rank 0 
2024-12-11 02:18:55.827564: predicting spleen_13 
2024-12-11 02:18:55.837145: spleen_13, shape torch.Size([1, 96, 190, 190]), rank 0 
2024-12-11 02:18:56.596438: predicting spleen_14 
2024-12-11 02:18:56.603950: spleen_14, shape torch.Size([1, 135, 218, 218]), rank 0 
2024-12-11 02:18:58.813909: predicting spleen_17 
2024-12-11 02:18:58.822986: spleen_17, shape torch.Size([1, 119, 157, 157]), rank 0 
2024-12-11 02:18:59.575511: predicting spleen_31 
2024-12-11 02:18:59.583120: spleen_31, shape torch.Size([1, 140, 190, 190]), rank 0 
2024-12-11 02:19:01.071302: predicting spleen_33 
2024-12-11 02:19:01.080379: spleen_33, shape torch.Size([1, 208, 237, 237]), rank 0 
2024-12-11 02:19:04.443825: predicting spleen_44 
2024-12-11 02:19:04.455950: spleen_44, shape torch.Size([1, 230, 223, 223]), rank 0 
2024-12-11 02:19:09.188665: predicting spleen_47 
2024-12-11 02:19:09.199787: spleen_47, shape torch.Size([1, 220, 201, 201]), rank 0 
2024-12-11 02:19:12.600378: predicting spleen_56 
2024-12-11 02:19:12.611453: spleen_56, shape torch.Size([1, 116, 179, 179]), rank 0 
2024-12-11 02:19:24.172167: Validation complete 
2024-12-11 02:19:24.177763: Mean Validation Dice:  0.9598917553337343 
