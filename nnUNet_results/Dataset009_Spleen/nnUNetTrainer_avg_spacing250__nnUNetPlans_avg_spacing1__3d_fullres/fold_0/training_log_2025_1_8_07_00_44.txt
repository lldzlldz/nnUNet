
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-08 07:00:44.679272: do_dummy_2d_data_aug: False 
2025-01-08 07:00:44.684279: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset009_Spleen\splits_final.json 
2025-01-08 07:00:44.689280: The split file contains 5 splits. 
2025-01-08 07:00:44.692280: Desired fold for training: 0 
2025-01-08 07:00:44.695279: This split has 32 training and 9 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_avg_spacing1_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 160, 128], 'median_image_size_in_voxels': [300.0, 406.0, 406.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset009_Spleen', 'plans_name': 'nnUNetPlans_avg_spacing1', 'original_median_spacing_after_transp': [5.0, 0.7929689884185791, 0.7929689884185791], 'original_median_shape_after_transp': [90, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1038.0, 'mean': 93.19259643554688, 'median': 97.0, 'min': -620.0, 'percentile_00_5': -42.0, 'percentile_99_5': 176.0, 'std': 40.78370666503906}}} 
 
2025-01-08 07:00:54.902939: unpacking dataset... 
2025-01-08 07:01:01.438397: unpacking done... 
2025-01-08 07:01:05.593193:  
2025-01-08 07:01:05.593193: Epoch 0 
2025-01-08 07:01:05.598207: Current learning rate: 0.01 
2025-01-08 07:01:49.470529: train_loss -0.1831 
2025-01-08 07:01:49.471046: val_loss -0.3933 
2025-01-08 07:01:49.477118: Pseudo dice [np.float32(0.5995)] 
2025-01-08 07:01:49.480244: Epoch time: 43.88 s 
2025-01-08 07:01:49.483308: Yayy! New best EMA pseudo Dice: 0.5995000004768372 
2025-01-08 07:01:50.161651:  
2025-01-08 07:01:50.162176: Epoch 1 
2025-01-08 07:01:50.167310: Current learning rate: 0.00996 
2025-01-08 07:02:29.785624: train_loss -0.477 
2025-01-08 07:02:29.786628: val_loss -0.4402 
2025-01-08 07:02:29.792646: Pseudo dice [np.float32(0.6594)] 
2025-01-08 07:02:29.795718: Epoch time: 39.62 s 
2025-01-08 07:02:29.798228: Yayy! New best EMA pseudo Dice: 0.6054999828338623 
2025-01-08 07:02:30.589669:  
2025-01-08 07:02:30.590673: Epoch 2 
2025-01-08 07:02:30.594716: Current learning rate: 0.00993 
2025-01-08 07:03:10.229757: train_loss -0.5742 
2025-01-08 07:03:10.230259: val_loss -0.4895 
2025-01-08 07:03:10.235821: Pseudo dice [np.float32(0.6819)] 
2025-01-08 07:03:10.238857: Epoch time: 39.64 s 
2025-01-08 07:03:10.242387: Yayy! New best EMA pseudo Dice: 0.613099992275238 
2025-01-08 07:03:11.095807:  
2025-01-08 07:03:11.096812: Epoch 3 
2025-01-08 07:03:11.101395: Current learning rate: 0.00989 
2025-01-08 07:03:50.700233: train_loss -0.5535 
2025-01-08 07:03:50.700233: val_loss -0.5284 
2025-01-08 07:03:50.707273: Pseudo dice [np.float32(0.7082)] 
2025-01-08 07:03:50.709779: Epoch time: 39.6 s 
2025-01-08 07:03:50.712284: Yayy! New best EMA pseudo Dice: 0.6226000189781189 
2025-01-08 07:03:51.502281:  
2025-01-08 07:03:51.502281: Epoch 4 
2025-01-08 07:03:51.508296: Current learning rate: 0.00986 
2025-01-08 07:04:31.087487: train_loss -0.619 
2025-01-08 07:04:31.088491: val_loss -0.5108 
2025-01-08 07:04:31.094505: Pseudo dice [np.float32(0.6844)] 
2025-01-08 07:04:31.097515: Epoch time: 39.59 s 
2025-01-08 07:04:31.100021: Yayy! New best EMA pseudo Dice: 0.6287999749183655 
2025-01-08 07:04:32.038368:  
2025-01-08 07:04:32.038368: Epoch 5 
2025-01-08 07:04:32.043483: Current learning rate: 0.00982 
2025-01-08 07:05:11.686541: train_loss -0.6353 
2025-01-08 07:05:11.687541: val_loss -0.6695 
2025-01-08 07:05:11.693058: Pseudo dice [np.float32(0.8042)] 
2025-01-08 07:05:11.696570: Epoch time: 39.65 s 
2025-01-08 07:05:11.699080: Yayy! New best EMA pseudo Dice: 0.6463000178337097 
2025-01-08 07:05:12.512289:  
2025-01-08 07:05:12.512289: Epoch 6 
2025-01-08 07:05:12.518419: Current learning rate: 0.00978 
2025-01-08 07:05:52.091518: train_loss -0.6637 
2025-01-08 07:05:52.091518: val_loss -0.6508 
2025-01-08 07:05:52.096031: Pseudo dice [np.float32(0.8005)] 
2025-01-08 07:05:52.099043: Epoch time: 39.58 s 
2025-01-08 07:05:52.101569: Yayy! New best EMA pseudo Dice: 0.6618000268936157 
2025-01-08 07:05:52.906306:  
2025-01-08 07:05:52.907311: Epoch 7 
2025-01-08 07:05:52.911833: Current learning rate: 0.00975 
2025-01-08 07:06:32.529782: train_loss -0.6971 
2025-01-08 07:06:32.530786: val_loss -0.6593 
2025-01-08 07:06:32.535804: Pseudo dice [np.float32(0.7778)] 
2025-01-08 07:06:32.539816: Epoch time: 39.62 s 
2025-01-08 07:06:32.543328: Yayy! New best EMA pseudo Dice: 0.6733999848365784 
2025-01-08 07:06:33.298447:  
2025-01-08 07:06:33.298950: Epoch 8 
2025-01-08 07:06:33.303965: Current learning rate: 0.00971 
2025-01-08 07:07:12.957840: train_loss -0.7269 
2025-01-08 07:07:12.958846: val_loss -0.3903 
2025-01-08 07:07:12.963578: Pseudo dice [np.float32(0.6153)] 
2025-01-08 07:07:12.968173: Epoch time: 39.66 s 
2025-01-08 07:07:13.543188:  
2025-01-08 07:07:13.543188: Epoch 9 
2025-01-08 07:07:13.549886: Current learning rate: 0.00968 
2025-01-08 07:07:53.169828: train_loss -0.7338 
2025-01-08 07:07:53.169828: val_loss -0.6561 
2025-01-08 07:07:53.174903: Pseudo dice [np.float32(0.8)] 
2025-01-08 07:07:53.179456: Epoch time: 39.63 s 
2025-01-08 07:07:53.182498: Yayy! New best EMA pseudo Dice: 0.6808000206947327 
2025-01-08 07:07:53.961203:  
2025-01-08 07:07:53.962207: Epoch 10 
2025-01-08 07:07:53.967264: Current learning rate: 0.00964 
2025-01-08 07:08:33.600475: train_loss -0.715 
2025-01-08 07:08:33.600977: val_loss -0.7618 
2025-01-08 07:08:33.605988: Pseudo dice [np.float32(0.8748)] 
2025-01-08 07:08:33.609498: Epoch time: 39.64 s 
2025-01-08 07:08:33.613504: Yayy! New best EMA pseudo Dice: 0.7002000212669373 
2025-01-08 07:08:34.365081:  
2025-01-08 07:08:34.365583: Epoch 11 
2025-01-08 07:08:34.370598: Current learning rate: 0.0096 
2025-01-08 07:09:14.033484: train_loss -0.7618 
2025-01-08 07:09:14.034488: val_loss -0.6396 
2025-01-08 07:09:14.038498: Pseudo dice [np.float32(0.7444)] 
2025-01-08 07:09:14.043063: Epoch time: 39.67 s 
2025-01-08 07:09:14.046073: Yayy! New best EMA pseudo Dice: 0.7045999765396118 
2025-01-08 07:09:14.847921:  
2025-01-08 07:09:14.847921: Epoch 12 
2025-01-08 07:09:14.852934: Current learning rate: 0.00957 
2025-01-08 07:09:54.518946: train_loss -0.7923 
2025-01-08 07:09:54.519448: val_loss -0.6449 
2025-01-08 07:09:54.525873: Pseudo dice [np.float32(0.7866)] 
2025-01-08 07:09:54.528922: Epoch time: 39.67 s 
2025-01-08 07:09:54.531971: Yayy! New best EMA pseudo Dice: 0.7128000259399414 
2025-01-08 07:09:55.435291:  
2025-01-08 07:09:55.436294: Epoch 13 
2025-01-08 07:09:55.441387: Current learning rate: 0.00953 
2025-01-08 07:10:35.049808: train_loss -0.7962 
2025-01-08 07:10:35.049808: val_loss -0.5655 
2025-01-08 07:10:35.056326: Pseudo dice [np.float32(0.7682)] 
2025-01-08 07:10:35.059367: Epoch time: 39.61 s 
2025-01-08 07:10:35.062398: Yayy! New best EMA pseudo Dice: 0.7184000015258789 
2025-01-08 07:10:35.817950:  
2025-01-08 07:10:35.818950: Epoch 14 
2025-01-08 07:10:35.824534: Current learning rate: 0.00949 
2025-01-08 07:11:15.421255: train_loss -0.7911 
2025-01-08 07:11:15.422305: val_loss -0.7872 
2025-01-08 07:11:15.427900: Pseudo dice [np.float32(0.8793)] 
2025-01-08 07:11:15.431434: Epoch time: 39.6 s 
2025-01-08 07:11:15.434464: Yayy! New best EMA pseudo Dice: 0.7343999743461609 
2025-01-08 07:11:16.251909:  
2025-01-08 07:11:16.251909: Epoch 15 
2025-01-08 07:11:16.257924: Current learning rate: 0.00946 
2025-01-08 07:11:55.868338: train_loss -0.7877 
2025-01-08 07:11:55.868338: val_loss -0.748 
2025-01-08 07:11:55.875854: Pseudo dice [np.float32(0.8409)] 
2025-01-08 07:11:55.880364: Epoch time: 39.62 s 
2025-01-08 07:11:55.883373: Yayy! New best EMA pseudo Dice: 0.7451000213623047 
2025-01-08 07:11:56.699442:  
2025-01-08 07:11:56.699945: Epoch 16 
2025-01-08 07:11:56.704989: Current learning rate: 0.00942 
2025-01-08 07:12:36.327641: train_loss -0.7753 
2025-01-08 07:12:36.327641: val_loss -0.6584 
2025-01-08 07:12:36.334155: Pseudo dice [np.float32(0.7782)] 
2025-01-08 07:12:36.337664: Epoch time: 39.63 s 
2025-01-08 07:12:36.340170: Yayy! New best EMA pseudo Dice: 0.7483999729156494 
2025-01-08 07:12:37.172318:  
2025-01-08 07:12:37.172318: Epoch 17 
2025-01-08 07:12:37.177877: Current learning rate: 0.00939 
2025-01-08 07:13:16.806671: train_loss -0.7961 
2025-01-08 07:13:16.807674: val_loss -0.6819 
2025-01-08 07:13:16.813690: Pseudo dice [np.float32(0.8281)] 
2025-01-08 07:13:16.816719: Epoch time: 39.63 s 
2025-01-08 07:13:16.819257: Yayy! New best EMA pseudo Dice: 0.7563999891281128 
2025-01-08 07:13:17.638730:  
2025-01-08 07:13:17.639730: Epoch 18 
2025-01-08 07:13:17.645329: Current learning rate: 0.00935 
2025-01-08 07:13:57.277965: train_loss -0.7974 
2025-01-08 07:13:57.277965: val_loss -0.7713 
2025-01-08 07:13:57.284021: Pseudo dice [np.float32(0.8695)] 
2025-01-08 07:13:57.287570: Epoch time: 39.64 s 
2025-01-08 07:13:57.290159: Yayy! New best EMA pseudo Dice: 0.7677000164985657 
2025-01-08 07:13:58.111581:  
2025-01-08 07:13:58.111581: Epoch 19 
2025-01-08 07:13:58.117154: Current learning rate: 0.00931 
2025-01-08 07:14:37.762759: train_loss -0.8108 
2025-01-08 07:14:37.763766: val_loss -0.8346 
2025-01-08 07:14:37.769814: Pseudo dice [np.float32(0.9073)] 
2025-01-08 07:14:37.772859: Epoch time: 39.65 s 
2025-01-08 07:14:37.775973: Yayy! New best EMA pseudo Dice: 0.7815999984741211 
2025-01-08 07:14:38.596917:  
2025-01-08 07:14:38.596917: Epoch 20 
2025-01-08 07:14:38.602481: Current learning rate: 0.00928 
2025-01-08 07:15:18.236000: train_loss -0.8514 
2025-01-08 07:15:18.236000: val_loss -0.7589 
2025-01-08 07:15:18.241015: Pseudo dice [np.float32(0.8554)] 
2025-01-08 07:15:18.243522: Epoch time: 39.64 s 
2025-01-08 07:15:18.247032: Yayy! New best EMA pseudo Dice: 0.7889999747276306 
2025-01-08 07:15:19.247136:  
2025-01-08 07:15:19.248141: Epoch 21 
2025-01-08 07:15:19.251663: Current learning rate: 0.00924 
2025-01-08 07:15:58.855008: train_loss -0.8264 
2025-01-08 07:15:58.855529: val_loss -0.8264 
2025-01-08 07:15:58.861616: Pseudo dice [np.float32(0.8972)] 
2025-01-08 07:15:58.865014: Epoch time: 39.61 s 
2025-01-08 07:15:58.868039: Yayy! New best EMA pseudo Dice: 0.7997999787330627 
2025-01-08 07:15:59.682035:  
2025-01-08 07:15:59.682035: Epoch 22 
2025-01-08 07:15:59.687047: Current learning rate: 0.0092 
2025-01-08 07:16:39.303920: train_loss -0.8249 
2025-01-08 07:16:39.304426: val_loss -0.5741 
2025-01-08 07:16:39.309957: Pseudo dice [np.float32(0.7845)] 
2025-01-08 07:16:39.314474: Epoch time: 39.62 s 
2025-01-08 07:16:39.869888:  
2025-01-08 07:16:39.869888: Epoch 23 
2025-01-08 07:16:39.875419: Current learning rate: 0.00917 
2025-01-08 07:17:19.528478: train_loss -0.8279 
2025-01-08 07:17:19.530024: val_loss -0.6744 
2025-01-08 07:17:19.535561: Pseudo dice [np.float32(0.8283)] 
2025-01-08 07:17:19.538603: Epoch time: 39.66 s 
2025-01-08 07:17:19.542632: Yayy! New best EMA pseudo Dice: 0.8012999892234802 
2025-01-08 07:17:20.343012:  
2025-01-08 07:17:20.343012: Epoch 24 
2025-01-08 07:17:20.348540: Current learning rate: 0.00913 
2025-01-08 07:17:59.951987: train_loss -0.8333 
2025-01-08 07:17:59.952490: val_loss -0.8397 
2025-01-08 07:17:59.958505: Pseudo dice [np.float32(0.9095)] 
2025-01-08 07:17:59.961011: Epoch time: 39.61 s 
2025-01-08 07:17:59.965019: Yayy! New best EMA pseudo Dice: 0.8120999932289124 
2025-01-08 07:18:00.772055:  
2025-01-08 07:18:00.772055: Epoch 25 
2025-01-08 07:18:00.779638: Current learning rate: 0.0091 
2025-01-08 07:18:40.383935: train_loss -0.8247 
2025-01-08 07:18:40.384438: val_loss -0.868 
2025-01-08 07:18:40.390452: Pseudo dice [np.float32(0.9281)] 
2025-01-08 07:18:40.392959: Epoch time: 39.61 s 
2025-01-08 07:18:40.396467: Yayy! New best EMA pseudo Dice: 0.8237000107765198 
2025-01-08 07:18:41.161987:  
2025-01-08 07:18:41.161987: Epoch 26 
2025-01-08 07:18:41.167118: Current learning rate: 0.00906 
2025-01-08 07:19:20.824034: train_loss -0.8338 
2025-01-08 07:19:20.824034: val_loss -0.8786 
2025-01-08 07:19:20.830051: Pseudo dice [np.float32(0.9326)] 
2025-01-08 07:19:20.834060: Epoch time: 39.66 s 
2025-01-08 07:19:20.836565: Yayy! New best EMA pseudo Dice: 0.8345999717712402 
2025-01-08 07:19:21.627433:  
2025-01-08 07:19:21.627433: Epoch 27 
2025-01-08 07:19:21.634007: Current learning rate: 0.00902 
2025-01-08 07:20:01.235480: train_loss -0.8628 
2025-01-08 07:20:01.236986: val_loss -0.828 
2025-01-08 07:20:01.243035: Pseudo dice [np.float32(0.9041)] 
2025-01-08 07:20:01.245554: Epoch time: 39.61 s 
2025-01-08 07:20:01.249072: Yayy! New best EMA pseudo Dice: 0.8416000008583069 
2025-01-08 07:20:02.188480:  
2025-01-08 07:20:02.188983: Epoch 28 
2025-01-08 07:20:02.193994: Current learning rate: 0.00899 
2025-01-08 07:20:41.821938: train_loss -0.8387 
2025-01-08 07:20:41.822937: val_loss -0.7913 
2025-01-08 07:20:41.829456: Pseudo dice [np.float32(0.8905)] 
2025-01-08 07:20:41.833465: Epoch time: 39.63 s 
2025-01-08 07:20:41.835972: Yayy! New best EMA pseudo Dice: 0.8464999794960022 
2025-01-08 07:20:42.651440:  
2025-01-08 07:20:42.651440: Epoch 29 
2025-01-08 07:20:42.656994: Current learning rate: 0.00895 
2025-01-08 07:21:22.269374: train_loss -0.8528 
2025-01-08 07:21:22.270377: val_loss -0.6437 
2025-01-08 07:21:22.275390: Pseudo dice [np.float32(0.792)] 
2025-01-08 07:21:22.279400: Epoch time: 39.62 s 
2025-01-08 07:21:22.847914:  
2025-01-08 07:21:22.848917: Epoch 30 
2025-01-08 07:21:22.853436: Current learning rate: 0.00891 
2025-01-08 07:22:02.426025: train_loss -0.8627 
2025-01-08 07:22:02.427029: val_loss -0.8328 
2025-01-08 07:22:02.432046: Pseudo dice [np.float32(0.9159)] 
2025-01-08 07:22:02.436053: Epoch time: 39.58 s 
2025-01-08 07:22:02.440085: Yayy! New best EMA pseudo Dice: 0.8485000133514404 
2025-01-08 07:22:03.262225:  
2025-01-08 07:22:03.263229: Epoch 31 
2025-01-08 07:22:03.267786: Current learning rate: 0.00888 
2025-01-08 07:22:42.871565: train_loss -0.8349 
2025-01-08 07:22:42.871565: val_loss -0.8137 
2025-01-08 07:22:42.877580: Pseudo dice [np.float32(0.9111)] 
2025-01-08 07:22:42.881669: Epoch time: 39.61 s 
2025-01-08 07:22:42.884174: Yayy! New best EMA pseudo Dice: 0.8547999858856201 
2025-01-08 07:22:43.685788:  
2025-01-08 07:22:43.686290: Epoch 32 
2025-01-08 07:22:43.691845: Current learning rate: 0.00884 
2025-01-08 07:23:23.313266: train_loss -0.8263 
2025-01-08 07:23:23.314264: val_loss -0.8672 
2025-01-08 07:23:23.320296: Pseudo dice [np.float32(0.9283)] 
2025-01-08 07:23:23.322834: Epoch time: 39.63 s 
2025-01-08 07:23:23.326953: Yayy! New best EMA pseudo Dice: 0.8621000051498413 
2025-01-08 07:23:24.099031:  
2025-01-08 07:23:24.100034: Epoch 33 
2025-01-08 07:23:24.104586: Current learning rate: 0.0088 
2025-01-08 07:24:03.712635: train_loss -0.8645 
2025-01-08 07:24:03.713638: val_loss -0.8371 
2025-01-08 07:24:03.720154: Pseudo dice [np.float32(0.9201)] 
2025-01-08 07:24:03.722660: Epoch time: 39.61 s 
2025-01-08 07:24:03.726169: Yayy! New best EMA pseudo Dice: 0.867900013923645 
2025-01-08 07:24:04.546957:  
2025-01-08 07:24:04.547459: Epoch 34 
2025-01-08 07:24:04.552470: Current learning rate: 0.00877 
2025-01-08 07:24:44.174178: train_loss -0.8949 
2025-01-08 07:24:44.174178: val_loss -0.8208 
2025-01-08 07:24:44.180193: Pseudo dice [np.float32(0.9138)] 
2025-01-08 07:24:44.184199: Epoch time: 39.63 s 
2025-01-08 07:24:44.186705: Yayy! New best EMA pseudo Dice: 0.8725000023841858 
2025-01-08 07:24:45.003999:  
2025-01-08 07:24:45.003999: Epoch 35 
2025-01-08 07:24:45.010014: Current learning rate: 0.00873 
2025-01-08 07:25:24.653180: train_loss -0.8613 
2025-01-08 07:25:24.653682: val_loss -0.8671 
2025-01-08 07:25:24.659206: Pseudo dice [np.float32(0.9299)] 
2025-01-08 07:25:24.663238: Epoch time: 39.65 s 
2025-01-08 07:25:24.666246: Yayy! New best EMA pseudo Dice: 0.8781999945640564 
2025-01-08 07:25:25.648255:  
2025-01-08 07:25:25.648795: Epoch 36 
2025-01-08 07:25:25.654364: Current learning rate: 0.00869 
2025-01-08 07:26:05.275125: train_loss -0.8857 
2025-01-08 07:26:05.276129: val_loss -0.8911 
2025-01-08 07:26:05.282139: Pseudo dice [np.float32(0.9437)] 
2025-01-08 07:26:05.285147: Epoch time: 39.63 s 
2025-01-08 07:26:05.288655: Yayy! New best EMA pseudo Dice: 0.8848000168800354 
2025-01-08 07:26:06.112536:  
2025-01-08 07:26:06.113540: Epoch 37 
2025-01-08 07:26:06.117565: Current learning rate: 0.00866 
2025-01-08 07:26:45.784138: train_loss -0.8663 
2025-01-08 07:26:45.784666: val_loss -0.8532 
2025-01-08 07:26:45.790247: Pseudo dice [np.float32(0.9154)] 
2025-01-08 07:26:45.793782: Epoch time: 39.67 s 
2025-01-08 07:26:45.796810: Yayy! New best EMA pseudo Dice: 0.8877999782562256 
2025-01-08 07:26:46.601804:  
2025-01-08 07:26:46.601804: Epoch 38 
2025-01-08 07:26:46.606849: Current learning rate: 0.00862 
2025-01-08 07:27:26.258388: train_loss -0.8837 
2025-01-08 07:27:26.258388: val_loss -0.8061 
2025-01-08 07:27:26.264403: Pseudo dice [np.float32(0.91)] 
2025-01-08 07:27:26.268413: Epoch time: 39.66 s 
2025-01-08 07:27:26.270919: Yayy! New best EMA pseudo Dice: 0.8899999856948853 
2025-01-08 07:27:27.068814:  
2025-01-08 07:27:27.068814: Epoch 39 
2025-01-08 07:27:27.073831: Current learning rate: 0.00858 
2025-01-08 07:28:06.719532: train_loss -0.8568 
2025-01-08 07:28:06.720536: val_loss -0.7694 
2025-01-08 07:28:06.726552: Pseudo dice [np.float32(0.8762)] 
2025-01-08 07:28:06.729561: Epoch time: 39.65 s 
2025-01-08 07:28:07.317220:  
2025-01-08 07:28:07.318223: Epoch 40 
2025-01-08 07:28:07.323251: Current learning rate: 0.00855 
2025-01-08 07:28:46.947824: train_loss -0.8155 
2025-01-08 07:28:46.949332: val_loss -0.7583 
2025-01-08 07:28:46.955433: Pseudo dice [np.float32(0.8672)] 
2025-01-08 07:28:46.958459: Epoch time: 39.63 s 
2025-01-08 07:28:47.550242:  
2025-01-08 07:28:47.551244: Epoch 41 
2025-01-08 07:28:47.556277: Current learning rate: 0.00851 
2025-01-08 07:29:27.145056: train_loss -0.8216 
2025-01-08 07:29:27.146057: val_loss -0.8329 
2025-01-08 07:29:27.151572: Pseudo dice [np.float32(0.9013)] 
2025-01-08 07:29:27.155081: Epoch time: 39.59 s 
2025-01-08 07:29:27.715496:  
2025-01-08 07:29:27.715496: Epoch 42 
2025-01-08 07:29:27.720048: Current learning rate: 0.00847 
2025-01-08 07:30:07.326255: train_loss -0.8603 
2025-01-08 07:30:07.327258: val_loss -0.8487 
2025-01-08 07:30:07.332272: Pseudo dice [np.float32(0.9202)] 
2025-01-08 07:30:07.336281: Epoch time: 39.61 s 
2025-01-08 07:30:07.338787: Yayy! New best EMA pseudo Dice: 0.8912000060081482 
2025-01-08 07:30:08.306757:  
2025-01-08 07:30:08.307761: Epoch 43 
2025-01-08 07:30:08.312805: Current learning rate: 0.00844 
2025-01-08 07:30:47.909552: train_loss -0.8765 
2025-01-08 07:30:47.910555: val_loss -0.8636 
2025-01-08 07:30:47.915569: Pseudo dice [np.float32(0.9246)] 
2025-01-08 07:30:47.919081: Epoch time: 39.6 s 
2025-01-08 07:30:47.922123: Yayy! New best EMA pseudo Dice: 0.894599974155426 
2025-01-08 07:30:48.718991:  
2025-01-08 07:30:48.719998: Epoch 44 
2025-01-08 07:30:48.724542: Current learning rate: 0.0084 
2025-01-08 07:31:28.316644: train_loss -0.8851 
2025-01-08 07:31:28.317147: val_loss -0.8319 
2025-01-08 07:31:28.323207: Pseudo dice [np.float32(0.9162)] 
2025-01-08 07:31:28.326308: Epoch time: 39.6 s 
2025-01-08 07:31:28.328834: Yayy! New best EMA pseudo Dice: 0.8967000246047974 
2025-01-08 07:31:29.099748:  
2025-01-08 07:31:29.100255: Epoch 45 
2025-01-08 07:31:29.105812: Current learning rate: 0.00836 
2025-01-08 07:32:08.704628: train_loss -0.868 
2025-01-08 07:32:08.705634: val_loss -0.6977 
2025-01-08 07:32:08.710644: Pseudo dice [np.float32(0.7892)] 
2025-01-08 07:32:08.714149: Epoch time: 39.61 s 
2025-01-08 07:32:09.275250:  
2025-01-08 07:32:09.276254: Epoch 46 
2025-01-08 07:32:09.281276: Current learning rate: 0.00833 
2025-01-08 07:32:48.944344: train_loss -0.8194 
2025-01-08 07:32:48.944344: val_loss -0.7996 
2025-01-08 07:32:48.949357: Pseudo dice [np.float32(0.888)] 
2025-01-08 07:32:48.951863: Epoch time: 39.67 s 
2025-01-08 07:32:49.510768:  
2025-01-08 07:32:49.510768: Epoch 47 
2025-01-08 07:32:49.516325: Current learning rate: 0.00829 
2025-01-08 07:33:29.167376: train_loss -0.8839 
2025-01-08 07:33:29.167376: val_loss -0.8166 
2025-01-08 07:33:29.172389: Pseudo dice [np.float32(0.9122)] 
2025-01-08 07:33:29.175900: Epoch time: 39.66 s 
2025-01-08 07:33:29.766130:  
2025-01-08 07:33:29.766130: Epoch 48 
2025-01-08 07:33:29.771661: Current learning rate: 0.00825 
2025-01-08 07:34:09.450159: train_loss -0.8696 
2025-01-08 07:34:09.455171: val_loss -0.786 
2025-01-08 07:34:09.458679: Pseudo dice [np.float32(0.8515)] 
2025-01-08 07:34:09.461689: Epoch time: 39.68 s 
2025-01-08 07:34:10.032997:  
2025-01-08 07:34:10.032997: Epoch 49 
2025-01-08 07:34:10.038024: Current learning rate: 0.00822 
2025-01-08 07:34:49.682226: train_loss -0.8551 
2025-01-08 07:34:49.683226: val_loss -0.7284 
2025-01-08 07:34:49.688741: Pseudo dice [np.float32(0.8561)] 
2025-01-08 07:34:49.692250: Epoch time: 39.65 s 
2025-01-08 07:34:50.471890:  
2025-01-08 07:34:50.472895: Epoch 50 
2025-01-08 07:34:50.478435: Current learning rate: 0.00818 
2025-01-08 07:35:30.147896: train_loss -0.853 
2025-01-08 07:35:30.148426: val_loss -0.8552 
2025-01-08 07:35:30.154481: Pseudo dice [np.float32(0.9178)] 
2025-01-08 07:35:30.157506: Epoch time: 39.68 s 
2025-01-08 07:35:30.876523:  
2025-01-08 07:35:30.876523: Epoch 51 
2025-01-08 07:35:30.882055: Current learning rate: 0.00814 
2025-01-08 07:36:10.514345: train_loss -0.8525 
2025-01-08 07:36:10.514345: val_loss -0.8357 
2025-01-08 07:36:10.520390: Pseudo dice [np.float32(0.9166)] 
2025-01-08 07:36:10.523414: Epoch time: 39.64 s 
2025-01-08 07:36:11.093053:  
2025-01-08 07:36:11.093053: Epoch 52 
2025-01-08 07:36:11.098086: Current learning rate: 0.00811 
2025-01-08 07:36:50.763111: train_loss -0.8992 
2025-01-08 07:36:50.763613: val_loss -0.8884 
2025-01-08 07:36:50.770658: Pseudo dice [np.float32(0.9421)] 
2025-01-08 07:36:50.773678: Epoch time: 39.67 s 
2025-01-08 07:36:51.343765:  
2025-01-08 07:36:51.343765: Epoch 53 
2025-01-08 07:36:51.349801: Current learning rate: 0.00807 
2025-01-08 07:37:31.012544: train_loss -0.8269 
2025-01-08 07:37:31.012544: val_loss -0.7835 
2025-01-08 07:37:31.018133: Pseudo dice [np.float32(0.8982)] 
2025-01-08 07:37:31.021232: Epoch time: 39.67 s 
2025-01-08 07:37:31.590781:  
2025-01-08 07:37:31.590781: Epoch 54 
2025-01-08 07:37:31.595794: Current learning rate: 0.00803 
2025-01-08 07:38:11.241974: train_loss -0.8951 
2025-01-08 07:38:11.242481: val_loss -0.8238 
2025-01-08 07:38:11.248554: Pseudo dice [np.float32(0.9157)] 
2025-01-08 07:38:11.251585: Epoch time: 39.65 s 
2025-01-08 07:38:11.893280:  
2025-01-08 07:38:11.893280: Epoch 55 
2025-01-08 07:38:11.898291: Current learning rate: 0.008 
2025-01-08 07:38:51.526364: train_loss -0.8364 
2025-01-08 07:38:51.527367: val_loss -0.8827 
2025-01-08 07:38:51.531888: Pseudo dice [np.float32(0.939)] 
2025-01-08 07:38:51.534915: Epoch time: 39.63 s 
2025-01-08 07:38:51.538437: Yayy! New best EMA pseudo Dice: 0.9009000062942505 
2025-01-08 07:38:52.353741:  
2025-01-08 07:38:52.354244: Epoch 56 
2025-01-08 07:38:52.359792: Current learning rate: 0.00796 
2025-01-08 07:39:31.972656: train_loss -0.8828 
2025-01-08 07:39:31.973714: val_loss -0.8905 
2025-01-08 07:39:31.979282: Pseudo dice [np.float32(0.9395)] 
2025-01-08 07:39:31.981809: Epoch time: 39.62 s 
2025-01-08 07:39:31.984334: Yayy! New best EMA pseudo Dice: 0.9047999978065491 
2025-01-08 07:39:32.789821:  
2025-01-08 07:39:32.790824: Epoch 57 
2025-01-08 07:39:32.794861: Current learning rate: 0.00792 
2025-01-08 07:40:12.434177: train_loss -0.8525 
2025-01-08 07:40:12.434684: val_loss -0.8515 
2025-01-08 07:40:12.439750: Pseudo dice [np.float32(0.9194)] 
2025-01-08 07:40:12.443312: Epoch time: 39.64 s 
2025-01-08 07:40:12.445863: Yayy! New best EMA pseudo Dice: 0.9061999917030334 
2025-01-08 07:40:13.216339:  
2025-01-08 07:40:13.217339: Epoch 58 
2025-01-08 07:40:13.222960: Current learning rate: 0.00789 
2025-01-08 07:40:52.832739: train_loss -0.885 
2025-01-08 07:40:52.832739: val_loss -0.8746 
2025-01-08 07:40:52.839255: Pseudo dice [np.float32(0.935)] 
2025-01-08 07:40:52.842764: Epoch time: 39.62 s 
2025-01-08 07:40:52.845271: Yayy! New best EMA pseudo Dice: 0.9090999960899353 
2025-01-08 07:40:53.832868:  
2025-01-08 07:40:53.832868: Epoch 59 
2025-01-08 07:40:53.838452: Current learning rate: 0.00785 
2025-01-08 07:41:33.461669: train_loss -0.8507 
2025-01-08 07:41:33.462676: val_loss -0.817 
2025-01-08 07:41:33.467909: Pseudo dice [np.float32(0.918)] 
2025-01-08 07:41:33.470968: Epoch time: 39.63 s 
2025-01-08 07:41:33.473495: Yayy! New best EMA pseudo Dice: 0.9100000262260437 
2025-01-08 07:41:34.300013:  
2025-01-08 07:41:34.300013: Epoch 60 
2025-01-08 07:41:34.305114: Current learning rate: 0.00781 
2025-01-08 07:42:13.976972: train_loss -0.8838 
2025-01-08 07:42:13.977476: val_loss -0.8311 
2025-01-08 07:42:13.982494: Pseudo dice [np.float32(0.8838)] 
2025-01-08 07:42:13.985515: Epoch time: 39.68 s 
2025-01-08 07:42:14.559899:  
2025-01-08 07:42:14.559899: Epoch 61 
2025-01-08 07:42:14.565979: Current learning rate: 0.00777 
2025-01-08 07:42:54.207811: train_loss -0.877 
2025-01-08 07:42:54.208817: val_loss -0.8247 
2025-01-08 07:42:54.212389: Pseudo dice [np.float32(0.8976)] 
2025-01-08 07:42:54.216480: Epoch time: 39.65 s 
2025-01-08 07:42:54.801700:  
2025-01-08 07:42:54.802704: Epoch 62 
2025-01-08 07:42:54.807735: Current learning rate: 0.00774 
2025-01-08 07:43:34.446944: train_loss -0.8534 
2025-01-08 07:43:34.448454: val_loss -0.8206 
2025-01-08 07:43:34.453475: Pseudo dice [np.float32(0.9148)] 
2025-01-08 07:43:34.456987: Epoch time: 39.65 s 
2025-01-08 07:43:35.036586:  
2025-01-08 07:43:35.037589: Epoch 63 
2025-01-08 07:43:35.042142: Current learning rate: 0.0077 
2025-01-08 07:44:14.712076: train_loss -0.8756 
2025-01-08 07:44:14.712076: val_loss -0.8309 
2025-01-08 07:44:14.718092: Pseudo dice [np.float32(0.9101)] 
2025-01-08 07:44:14.721605: Epoch time: 39.68 s 
2025-01-08 07:44:15.303567:  
2025-01-08 07:44:15.303567: Epoch 64 
2025-01-08 07:44:15.308581: Current learning rate: 0.00766 
2025-01-08 07:44:54.943806: train_loss -0.895 
2025-01-08 07:44:54.944316: val_loss -0.9052 
2025-01-08 07:44:54.951463: Pseudo dice [np.float32(0.9509)] 
2025-01-08 07:44:54.955520: Epoch time: 39.64 s 
2025-01-08 07:44:54.958576: Yayy! New best EMA pseudo Dice: 0.911899983882904 
2025-01-08 07:44:55.784284:  
2025-01-08 07:44:55.784788: Epoch 65 
2025-01-08 07:44:55.789801: Current learning rate: 0.00763 
2025-01-08 07:45:35.459270: train_loss -0.8848 
2025-01-08 07:45:35.459270: val_loss -0.7596 
2025-01-08 07:45:35.464288: Pseudo dice [np.float32(0.8603)] 
2025-01-08 07:45:35.467802: Epoch time: 39.68 s 
2025-01-08 07:45:36.053968:  
2025-01-08 07:45:36.053968: Epoch 66 
2025-01-08 07:45:36.060485: Current learning rate: 0.00759 
2025-01-08 07:46:15.671851: train_loss -0.8898 
2025-01-08 07:46:15.671851: val_loss -0.8112 
2025-01-08 07:46:15.677870: Pseudo dice [np.float32(0.9006)] 
2025-01-08 07:46:15.679886: Epoch time: 39.62 s 
2025-01-08 07:46:16.405584:  
2025-01-08 07:46:16.405584: Epoch 67 
2025-01-08 07:46:16.410638: Current learning rate: 0.00755 
2025-01-08 07:46:56.044094: train_loss -0.8935 
2025-01-08 07:46:56.045097: val_loss -0.6217 
2025-01-08 07:46:56.052127: Pseudo dice [np.float32(0.7922)] 
2025-01-08 07:46:56.056728: Epoch time: 39.64 s 
2025-01-08 07:46:56.648378:  
2025-01-08 07:46:56.649378: Epoch 68 
2025-01-08 07:46:56.654972: Current learning rate: 0.00751 
2025-01-08 07:47:36.290896: train_loss -0.8701 
2025-01-08 07:47:36.291399: val_loss -0.8789 
2025-01-08 07:47:36.296415: Pseudo dice [np.float32(0.9313)] 
2025-01-08 07:47:36.299958: Epoch time: 39.64 s 
2025-01-08 07:47:36.893651:  
2025-01-08 07:47:36.893651: Epoch 69 
2025-01-08 07:47:36.898664: Current learning rate: 0.00748 
2025-01-08 07:48:16.552893: train_loss -0.9048 
2025-01-08 07:48:16.552893: val_loss -0.8821 
2025-01-08 07:48:16.559409: Pseudo dice [np.float32(0.9439)] 
2025-01-08 07:48:16.561916: Epoch time: 39.66 s 
2025-01-08 07:48:17.146920:  
2025-01-08 07:48:17.146920: Epoch 70 
2025-01-08 07:48:17.151957: Current learning rate: 0.00744 
2025-01-08 07:48:56.775863: train_loss -0.895 
2025-01-08 07:48:56.777894: val_loss -0.8547 
2025-01-08 07:48:56.785577: Pseudo dice [np.float32(0.9314)] 
2025-01-08 07:48:56.790141: Epoch time: 39.63 s 
2025-01-08 07:48:57.388028:  
2025-01-08 07:48:57.389085: Epoch 71 
2025-01-08 07:48:57.393620: Current learning rate: 0.0074 
2025-01-08 07:49:37.046648: train_loss -0.8915 
2025-01-08 07:49:37.047152: val_loss -0.8328 
2025-01-08 07:49:37.052202: Pseudo dice [np.float32(0.9064)] 
2025-01-08 07:49:37.055717: Epoch time: 39.66 s 
2025-01-08 07:49:37.652899:  
2025-01-08 07:49:37.652899: Epoch 72 
2025-01-08 07:49:37.658452: Current learning rate: 0.00737 
2025-01-08 07:50:17.326022: train_loss -0.8805 
2025-01-08 07:50:17.326022: val_loss -0.8019 
2025-01-08 07:50:17.332042: Pseudo dice [np.float32(0.8999)] 
2025-01-08 07:50:17.335054: Epoch time: 39.67 s 
2025-01-08 07:50:17.918591:  
2025-01-08 07:50:17.918591: Epoch 73 
2025-01-08 07:50:17.923617: Current learning rate: 0.00733 
2025-01-08 07:50:57.525904: train_loss -0.9084 
2025-01-08 07:50:57.526909: val_loss -0.8808 
2025-01-08 07:50:57.531932: Pseudo dice [np.float32(0.9336)] 
2025-01-08 07:50:57.535946: Epoch time: 39.61 s 
2025-01-08 07:50:58.275250:  
2025-01-08 07:50:58.276256: Epoch 74 
2025-01-08 07:50:58.280802: Current learning rate: 0.00729 
2025-01-08 07:51:37.919285: train_loss -0.8958 
2025-01-08 07:51:37.919788: val_loss -0.8846 
2025-01-08 07:51:37.925816: Pseudo dice [np.float32(0.9422)] 
2025-01-08 07:51:37.928325: Epoch time: 39.64 s 
2025-01-08 07:51:38.517560:  
2025-01-08 07:51:38.518561: Epoch 75 
2025-01-08 07:51:38.523624: Current learning rate: 0.00725 
2025-01-08 07:52:18.155041: train_loss -0.8914 
2025-01-08 07:52:18.155551: val_loss -0.734 
2025-01-08 07:52:18.161195: Pseudo dice [np.float32(0.8589)] 
2025-01-08 07:52:18.164439: Epoch time: 39.64 s 
2025-01-08 07:52:18.748752:  
2025-01-08 07:52:18.748752: Epoch 76 
2025-01-08 07:52:18.754289: Current learning rate: 0.00722 
2025-01-08 07:52:58.376130: train_loss -0.8984 
2025-01-08 07:52:58.377133: val_loss -0.8522 
2025-01-08 07:52:58.382145: Pseudo dice [np.float32(0.9191)] 
2025-01-08 07:52:58.385699: Epoch time: 39.63 s 
2025-01-08 07:52:58.977451:  
2025-01-08 07:52:58.977451: Epoch 77 
2025-01-08 07:52:58.982534: Current learning rate: 0.00718 
2025-01-08 07:53:38.648978: train_loss -0.913 
2025-01-08 07:53:38.649982: val_loss -0.7316 
2025-01-08 07:53:38.656677: Pseudo dice [np.float32(0.8773)] 
2025-01-08 07:53:38.660185: Epoch time: 39.67 s 
2025-01-08 07:53:39.258835:  
2025-01-08 07:53:39.259338: Epoch 78 
2025-01-08 07:53:39.263849: Current learning rate: 0.00714 
2025-01-08 07:54:18.901607: train_loss -0.8775 
2025-01-08 07:54:18.902110: val_loss -0.8418 
2025-01-08 07:54:18.907754: Pseudo dice [np.float32(0.9084)] 
2025-01-08 07:54:18.910792: Epoch time: 39.64 s 
2025-01-08 07:54:19.500991:  
2025-01-08 07:54:19.500991: Epoch 79 
2025-01-08 07:54:19.506043: Current learning rate: 0.0071 
2025-01-08 07:54:59.142281: train_loss -0.9037 
2025-01-08 07:54:59.142790: val_loss -0.8743 
2025-01-08 07:54:59.147828: Pseudo dice [np.float32(0.931)] 
2025-01-08 07:54:59.150365: Epoch time: 39.64 s 
2025-01-08 07:54:59.752895:  
2025-01-08 07:54:59.754395: Epoch 80 
2025-01-08 07:54:59.757905: Current learning rate: 0.00707 
2025-01-08 07:55:39.395612: train_loss -0.9 
2025-01-08 07:55:39.396613: val_loss -0.8838 
2025-01-08 07:55:39.402141: Pseudo dice [np.float32(0.9366)] 
2025-01-08 07:55:39.404649: Epoch time: 39.64 s 
2025-01-08 07:55:40.004126:  
2025-01-08 07:55:40.004126: Epoch 81 
2025-01-08 07:55:40.009137: Current learning rate: 0.00703 
2025-01-08 07:56:19.637135: train_loss -0.901 
2025-01-08 07:56:19.637135: val_loss -0.8019 
2025-01-08 07:56:19.643659: Pseudo dice [np.float32(0.9016)] 
2025-01-08 07:56:19.646169: Epoch time: 39.63 s 
2025-01-08 07:56:20.478096:  
2025-01-08 07:56:20.478599: Epoch 82 
2025-01-08 07:56:20.483612: Current learning rate: 0.00699 
2025-01-08 07:57:00.100692: train_loss -0.8949 
2025-01-08 07:57:00.101692: val_loss -0.8524 
2025-01-08 07:57:00.106707: Pseudo dice [np.float32(0.9227)] 
2025-01-08 07:57:00.109741: Epoch time: 39.62 s 
2025-01-08 07:57:00.681424:  
2025-01-08 07:57:00.681424: Epoch 83 
2025-01-08 07:57:00.686438: Current learning rate: 0.00696 
2025-01-08 07:57:40.318567: train_loss -0.8555 
2025-01-08 07:57:40.319568: val_loss -0.8604 
2025-01-08 07:57:40.324585: Pseudo dice [np.float32(0.915)] 
2025-01-08 07:57:40.327596: Epoch time: 39.64 s 
2025-01-08 07:57:40.895312:  
2025-01-08 07:57:40.896319: Epoch 84 
2025-01-08 07:57:40.901467: Current learning rate: 0.00692 
2025-01-08 07:58:20.492047: train_loss -0.8903 
2025-01-08 07:58:20.493046: val_loss -0.7273 
2025-01-08 07:58:20.498564: Pseudo dice [np.float32(0.8809)] 
2025-01-08 07:58:20.502075: Epoch time: 39.6 s 
2025-01-08 07:58:21.058826:  
2025-01-08 07:58:21.059330: Epoch 85 
2025-01-08 07:58:21.064346: Current learning rate: 0.00688 
2025-01-08 07:59:00.658698: train_loss -0.8983 
2025-01-08 07:59:00.658698: val_loss -0.8115 
2025-01-08 07:59:00.664754: Pseudo dice [np.float32(0.9103)] 
2025-01-08 07:59:00.667781: Epoch time: 39.6 s 
2025-01-08 07:59:01.235636:  
2025-01-08 07:59:01.235636: Epoch 86 
2025-01-08 07:59:01.240684: Current learning rate: 0.00684 
2025-01-08 07:59:40.860846: train_loss -0.8863 
2025-01-08 07:59:40.861850: val_loss -0.9012 
2025-01-08 07:59:40.866868: Pseudo dice [np.float32(0.9472)] 
2025-01-08 07:59:40.870880: Epoch time: 39.63 s 
2025-01-08 07:59:40.873920: Yayy! New best EMA pseudo Dice: 0.9122999906539917 
2025-01-08 07:59:41.701791:  
2025-01-08 07:59:41.702791: Epoch 87 
2025-01-08 07:59:41.708309: Current learning rate: 0.0068 
2025-01-08 08:00:21.356157: train_loss -0.8948 
2025-01-08 08:00:21.356660: val_loss -0.857 
2025-01-08 08:00:21.362678: Pseudo dice [np.float32(0.925)] 
2025-01-08 08:00:21.365187: Epoch time: 39.65 s 
2025-01-08 08:00:21.368693: Yayy! New best EMA pseudo Dice: 0.9136000275611877 
2025-01-08 08:00:22.130429:  
2025-01-08 08:00:22.131431: Epoch 88 
2025-01-08 08:00:22.136509: Current learning rate: 0.00677 
2025-01-08 08:01:01.764232: train_loss -0.9115 
2025-01-08 08:01:01.764745: val_loss -0.9037 
2025-01-08 08:01:01.770293: Pseudo dice [np.float32(0.9514)] 
2025-01-08 08:01:01.773344: Epoch time: 39.63 s 
2025-01-08 08:01:01.775876: Yayy! New best EMA pseudo Dice: 0.9174000024795532 
2025-01-08 08:01:02.557196:  
2025-01-08 08:01:02.557196: Epoch 89 
2025-01-08 08:01:02.562745: Current learning rate: 0.00673 
2025-01-08 08:01:42.171511: train_loss -0.8982 
2025-01-08 08:01:42.172016: val_loss -0.6406 
2025-01-08 08:01:42.178038: Pseudo dice [np.float32(0.798)] 
2025-01-08 08:01:42.180547: Epoch time: 39.62 s 
2025-01-08 08:01:42.909300:  
2025-01-08 08:01:42.909300: Epoch 90 
2025-01-08 08:01:42.914327: Current learning rate: 0.00669 
2025-01-08 08:02:22.527437: train_loss -0.9031 
2025-01-08 08:02:22.527948: val_loss -0.8828 
2025-01-08 08:02:22.531997: Pseudo dice [np.float32(0.9411)] 
2025-01-08 08:02:22.535508: Epoch time: 39.62 s 
2025-01-08 08:02:23.094932:  
2025-01-08 08:02:23.094932: Epoch 91 
2025-01-08 08:02:23.099948: Current learning rate: 0.00665 
2025-01-08 08:03:02.727527: train_loss -0.9259 
2025-01-08 08:03:02.728048: val_loss -0.8956 
2025-01-08 08:03:02.733629: Pseudo dice [np.float32(0.948)] 
2025-01-08 08:03:02.736227: Epoch time: 39.63 s 
2025-01-08 08:03:03.311104:  
2025-01-08 08:03:03.312106: Epoch 92 
2025-01-08 08:03:03.317187: Current learning rate: 0.00662 
2025-01-08 08:03:42.957794: train_loss -0.8967 
2025-01-08 08:03:42.958308: val_loss -0.7898 
2025-01-08 08:03:42.963917: Pseudo dice [np.float32(0.9079)] 
2025-01-08 08:03:42.966977: Epoch time: 39.65 s 
2025-01-08 08:03:43.540275:  
2025-01-08 08:03:43.540275: Epoch 93 
2025-01-08 08:03:43.544850: Current learning rate: 0.00658 
2025-01-08 08:04:23.189751: train_loss -0.9055 
2025-01-08 08:04:23.190767: val_loss -0.7416 
2025-01-08 08:04:23.196090: Pseudo dice [np.float32(0.9113)] 
2025-01-08 08:04:23.199362: Epoch time: 39.65 s 
2025-01-08 08:04:23.763054:  
2025-01-08 08:04:23.763054: Epoch 94 
2025-01-08 08:04:23.768069: Current learning rate: 0.00654 
2025-01-08 08:05:03.424205: train_loss -0.8797 
2025-01-08 08:05:03.424205: val_loss -0.8771 
2025-01-08 08:05:03.430732: Pseudo dice [np.float32(0.9331)] 
2025-01-08 08:05:03.433240: Epoch time: 39.66 s 
2025-01-08 08:05:04.009636:  
2025-01-08 08:05:04.009636: Epoch 95 
2025-01-08 08:05:04.014650: Current learning rate: 0.0065 
2025-01-08 08:05:43.669426: train_loss -0.8916 
2025-01-08 08:05:43.670454: val_loss -0.8913 
2025-01-08 08:05:43.676137: Pseudo dice [np.float32(0.9426)] 
2025-01-08 08:05:43.679189: Epoch time: 39.66 s 
2025-01-08 08:05:44.251504:  
2025-01-08 08:05:44.251504: Epoch 96 
2025-01-08 08:05:44.257806: Current learning rate: 0.00647 
2025-01-08 08:06:23.923417: train_loss -0.9093 
2025-01-08 08:06:23.923417: val_loss -0.8704 
2025-01-08 08:06:23.930945: Pseudo dice [np.float32(0.9309)] 
2025-01-08 08:06:23.934957: Epoch time: 39.67 s 
2025-01-08 08:06:23.937463: Yayy! New best EMA pseudo Dice: 0.9186000227928162 
2025-01-08 08:06:24.762253:  
2025-01-08 08:06:24.762253: Epoch 97 
2025-01-08 08:06:24.767295: Current learning rate: 0.00643 
2025-01-08 08:07:04.427891: train_loss -0.911 
2025-01-08 08:07:04.428395: val_loss -0.7626 
2025-01-08 08:07:04.433950: Pseudo dice [np.float32(0.8898)] 
2025-01-08 08:07:04.436984: Epoch time: 39.67 s 
2025-01-08 08:07:05.167975:  
2025-01-08 08:07:05.168479: Epoch 98 
2025-01-08 08:07:05.173493: Current learning rate: 0.00639 
2025-01-08 08:07:44.774348: train_loss -0.9138 
2025-01-08 08:07:44.775352: val_loss -0.6388 
2025-01-08 08:07:44.781436: Pseudo dice [np.float32(0.8459)] 
2025-01-08 08:07:44.784538: Epoch time: 39.61 s 
2025-01-08 08:07:45.380302:  
2025-01-08 08:07:45.380820: Epoch 99 
2025-01-08 08:07:45.385945: Current learning rate: 0.00635 
2025-01-08 08:08:24.994100: train_loss -0.8944 
2025-01-08 08:08:24.994607: val_loss -0.8634 
2025-01-08 08:08:25.001622: Pseudo dice [np.float32(0.9298)] 
2025-01-08 08:08:25.004632: Epoch time: 39.61 s 
2025-01-08 08:08:25.828929:  
2025-01-08 08:08:25.828929: Epoch 100 
2025-01-08 08:08:25.834997: Current learning rate: 0.00631 
2025-01-08 08:09:05.490464: train_loss -0.8907 
2025-01-08 08:09:05.490967: val_loss -0.9013 
2025-01-08 08:09:05.496987: Pseudo dice [np.float32(0.9492)] 
2025-01-08 08:09:05.500153: Epoch time: 39.66 s 
2025-01-08 08:09:06.071757:  
2025-01-08 08:09:06.071757: Epoch 101 
2025-01-08 08:09:06.076769: Current learning rate: 0.00628 
2025-01-08 08:09:45.750721: train_loss -0.9085 
2025-01-08 08:09:45.751243: val_loss -0.8514 
2025-01-08 08:09:45.755335: Pseudo dice [np.float32(0.9233)] 
2025-01-08 08:09:45.758407: Epoch time: 39.68 s 
2025-01-08 08:09:46.341491:  
2025-01-08 08:09:46.341994: Epoch 102 
2025-01-08 08:09:46.347006: Current learning rate: 0.00624 
2025-01-08 08:10:25.999955: train_loss -0.911 
2025-01-08 08:10:26.000482: val_loss -0.908 
2025-01-08 08:10:26.007514: Pseudo dice [np.float32(0.947)] 
2025-01-08 08:10:26.011080: Epoch time: 39.66 s 
2025-01-08 08:10:26.015115: Yayy! New best EMA pseudo Dice: 0.9186999797821045 
2025-01-08 08:10:26.832283:  
2025-01-08 08:10:26.833284: Epoch 103 
2025-01-08 08:10:26.838357: Current learning rate: 0.0062 
2025-01-08 08:11:06.488504: train_loss -0.9265 
2025-01-08 08:11:06.489007: val_loss -0.9026 
2025-01-08 08:11:06.495022: Pseudo dice [np.float32(0.9435)] 
2025-01-08 08:11:06.498031: Epoch time: 39.66 s 
2025-01-08 08:11:06.501096: Yayy! New best EMA pseudo Dice: 0.9211000204086304 
2025-01-08 08:11:07.328270:  
2025-01-08 08:11:07.328270: Epoch 104 
2025-01-08 08:11:07.333828: Current learning rate: 0.00616 
2025-01-08 08:11:46.949305: train_loss -0.9222 
2025-01-08 08:11:46.949814: val_loss -0.8559 
2025-01-08 08:11:46.955928: Pseudo dice [np.float32(0.9283)] 
2025-01-08 08:11:46.959444: Epoch time: 39.62 s 
2025-01-08 08:11:46.962487: Yayy! New best EMA pseudo Dice: 0.9218999743461609 
2025-01-08 08:11:47.786100:  
2025-01-08 08:11:47.786602: Epoch 105 
2025-01-08 08:11:47.791611: Current learning rate: 0.00612 
2025-01-08 08:12:27.434038: train_loss -0.9149 
2025-01-08 08:12:27.435041: val_loss -0.8877 
2025-01-08 08:12:27.443086: Pseudo dice [np.float32(0.9354)] 
2025-01-08 08:12:27.447175: Epoch time: 39.65 s 
2025-01-08 08:12:27.450205: Yayy! New best EMA pseudo Dice: 0.9232000112533569 
2025-01-08 08:12:28.391922:  
2025-01-08 08:12:28.392424: Epoch 106 
2025-01-08 08:12:28.395940: Current learning rate: 0.00609 
2025-01-08 08:13:08.041401: train_loss -0.8881 
2025-01-08 08:13:08.042401: val_loss -0.8668 
2025-01-08 08:13:08.047923: Pseudo dice [np.float32(0.9233)] 
2025-01-08 08:13:08.051440: Epoch time: 39.65 s 
2025-01-08 08:13:08.053948: Yayy! New best EMA pseudo Dice: 0.9232000112533569 
2025-01-08 08:13:08.886755:  
2025-01-08 08:13:08.886755: Epoch 107 
2025-01-08 08:13:08.892308: Current learning rate: 0.00605 
2025-01-08 08:13:48.530880: train_loss -0.854 
2025-01-08 08:13:48.531881: val_loss -0.7448 
2025-01-08 08:13:48.537402: Pseudo dice [np.float32(0.8894)] 
2025-01-08 08:13:48.539909: Epoch time: 39.65 s 
2025-01-08 08:13:49.115444:  
2025-01-08 08:13:49.115444: Epoch 108 
2025-01-08 08:13:49.120997: Current learning rate: 0.00601 
2025-01-08 08:14:28.772263: train_loss -0.9025 
2025-01-08 08:14:28.772263: val_loss -0.81 
2025-01-08 08:14:28.778292: Pseudo dice [np.float32(0.8922)] 
2025-01-08 08:14:28.781805: Epoch time: 39.66 s 
2025-01-08 08:14:29.358455:  
2025-01-08 08:14:29.358455: Epoch 109 
2025-01-08 08:14:29.363028: Current learning rate: 0.00597 
2025-01-08 08:15:14.860246: train_loss -0.9014 
2025-01-08 08:15:14.860246: val_loss -0.8562 
2025-01-08 08:15:14.866767: Pseudo dice [np.float32(0.8994)] 
2025-01-08 08:15:14.869272: Epoch time: 45.5 s 
2025-01-08 08:15:15.441960:  
2025-01-08 08:15:15.441960: Epoch 110 
2025-01-08 08:15:15.447506: Current learning rate: 0.00593 
2025-01-08 08:15:56.420490: train_loss -0.9164 
2025-01-08 08:15:56.421493: val_loss -0.8813 
2025-01-08 08:15:56.427019: Pseudo dice [np.float32(0.9348)] 
2025-01-08 08:15:56.430046: Epoch time: 40.98 s 
2025-01-08 08:15:56.964763:  
2025-01-08 08:15:56.964763: Epoch 111 
2025-01-08 08:15:56.970343: Current learning rate: 0.0059 
2025-01-08 08:16:37.999358: train_loss -0.9144 
2025-01-08 08:16:38.000363: val_loss -0.8568 
2025-01-08 08:16:38.004382: Pseudo dice [np.float32(0.9363)] 
2025-01-08 08:16:38.007894: Epoch time: 41.04 s 
2025-01-08 08:16:38.572098:  
2025-01-08 08:16:38.573101: Epoch 112 
2025-01-08 08:16:38.577660: Current learning rate: 0.00586 
2025-01-08 08:17:19.289749: train_loss -0.9213 
2025-01-08 08:17:19.290267: val_loss -0.8968 
2025-01-08 08:17:19.295400: Pseudo dice [np.float32(0.9438)] 
2025-01-08 08:17:19.298439: Epoch time: 40.72 s 
2025-01-08 08:17:19.860836:  
2025-01-08 08:17:19.861835: Epoch 113 
2025-01-08 08:17:19.866710: Current learning rate: 0.00582 
2025-01-08 08:18:00.576419: train_loss -0.9026 
2025-01-08 08:18:00.576419: val_loss -0.8443 
2025-01-08 08:18:00.582442: Pseudo dice [np.float32(0.9258)] 
2025-01-08 08:18:00.585454: Epoch time: 40.72 s 
2025-01-08 08:18:01.317333:  
2025-01-08 08:18:01.317333: Epoch 114 
2025-01-08 08:18:01.323905: Current learning rate: 0.00578 
2025-01-08 08:18:42.046532: train_loss -0.903 
2025-01-08 08:18:42.046532: val_loss -0.8002 
2025-01-08 08:18:42.052548: Pseudo dice [np.float32(0.8879)] 
2025-01-08 08:18:42.056077: Epoch time: 40.73 s 
2025-01-08 08:18:42.632446:  
2025-01-08 08:18:42.633450: Epoch 115 
2025-01-08 08:18:42.638010: Current learning rate: 0.00574 
2025-01-08 08:19:23.346690: train_loss -0.9195 
2025-01-08 08:19:23.346690: val_loss -0.9076 
2025-01-08 08:19:23.353320: Pseudo dice [np.float32(0.9484)] 
2025-01-08 08:19:23.356382: Epoch time: 40.71 s 
2025-01-08 08:19:23.938648:  
2025-01-08 08:19:23.938648: Epoch 116 
2025-01-08 08:19:23.944698: Current learning rate: 0.0057 
2025-01-08 08:20:04.695702: train_loss -0.9255 
2025-01-08 08:20:04.696703: val_loss -0.8845 
2025-01-08 08:20:04.702221: Pseudo dice [np.float32(0.9418)] 
2025-01-08 08:20:04.705270: Epoch time: 40.76 s 
2025-01-08 08:20:04.708308: Yayy! New best EMA pseudo Dice: 0.9236000180244446 
2025-01-08 08:20:05.541814:  
2025-01-08 08:20:05.541814: Epoch 117 
2025-01-08 08:20:05.547355: Current learning rate: 0.00567 
2025-01-08 08:20:46.262110: train_loss -0.9221 
2025-01-08 08:20:46.263115: val_loss -0.815 
2025-01-08 08:20:46.269141: Pseudo dice [np.float32(0.8915)] 
2025-01-08 08:20:46.272162: Epoch time: 40.72 s 
2025-01-08 08:20:46.847183:  
2025-01-08 08:20:46.848182: Epoch 118 
2025-01-08 08:20:46.853252: Current learning rate: 0.00563 
2025-01-08 08:21:27.582822: train_loss -0.9021 
2025-01-08 08:21:27.582822: val_loss -0.7968 
2025-01-08 08:21:27.588383: Pseudo dice [np.float32(0.8705)] 
2025-01-08 08:21:27.592423: Epoch time: 40.74 s 
2025-01-08 08:21:28.163204:  
2025-01-08 08:21:28.164205: Epoch 119 
2025-01-08 08:21:28.169281: Current learning rate: 0.00559 
2025-01-08 08:22:08.862896: train_loss -0.892 
2025-01-08 08:22:08.863398: val_loss -0.8707 
2025-01-08 08:22:08.869413: Pseudo dice [np.float32(0.9394)] 
2025-01-08 08:22:08.873421: Epoch time: 40.7 s 
2025-01-08 08:22:09.448306:  
2025-01-08 08:22:09.448306: Epoch 120 
2025-01-08 08:22:09.453317: Current learning rate: 0.00555 
2025-01-08 08:22:50.166154: train_loss -0.8785 
2025-01-08 08:22:50.166154: val_loss -0.7767 
2025-01-08 08:22:50.172176: Pseudo dice [np.float32(0.8968)] 
2025-01-08 08:22:50.175749: Epoch time: 40.72 s 
2025-01-08 08:22:50.747475:  
2025-01-08 08:22:50.747978: Epoch 121 
2025-01-08 08:22:50.752533: Current learning rate: 0.00551 
2025-01-08 08:23:31.636585: train_loss -0.8996 
2025-01-08 08:23:31.637093: val_loss -0.7453 
2025-01-08 08:23:31.642136: Pseudo dice [np.float32(0.8817)] 
2025-01-08 08:23:31.645660: Epoch time: 40.89 s 
2025-01-08 08:23:32.219709:  
2025-01-08 08:23:32.219709: Epoch 122 
2025-01-08 08:23:32.225785: Current learning rate: 0.00547 
2025-01-08 08:24:12.924139: train_loss -0.9032 
2025-01-08 08:24:12.925139: val_loss -0.8614 
2025-01-08 08:24:12.930694: Pseudo dice [np.float32(0.9211)] 
2025-01-08 08:24:12.935228: Epoch time: 40.71 s 
2025-01-08 08:24:13.536640:  
2025-01-08 08:24:13.536640: Epoch 123 
2025-01-08 08:24:13.543206: Current learning rate: 0.00544 
2025-01-08 08:24:54.369294: train_loss -0.9211 
2025-01-08 08:24:54.370297: val_loss -0.8759 
2025-01-08 08:24:54.376458: Pseudo dice [np.float32(0.9317)] 
2025-01-08 08:24:54.380004: Epoch time: 40.83 s 
2025-01-08 08:24:54.949054:  
2025-01-08 08:24:54.950057: Epoch 124 
2025-01-08 08:24:54.954605: Current learning rate: 0.0054 
2025-01-08 08:25:35.696180: train_loss -0.9102 
2025-01-08 08:25:35.697699: val_loss -0.9032 
2025-01-08 08:25:35.702717: Pseudo dice [np.float32(0.9397)] 
2025-01-08 08:25:35.706230: Epoch time: 40.75 s 
2025-01-08 08:25:36.290174:  
2025-01-08 08:25:36.290174: Epoch 125 
2025-01-08 08:25:36.297191: Current learning rate: 0.00536 
2025-01-08 08:26:17.028248: train_loss -0.9188 
2025-01-08 08:26:17.029750: val_loss -0.9112 
2025-01-08 08:26:17.034762: Pseudo dice [np.float32(0.9538)] 
2025-01-08 08:26:17.038271: Epoch time: 40.74 s 
2025-01-08 08:26:17.610059:  
2025-01-08 08:26:17.610059: Epoch 126 
2025-01-08 08:26:17.616596: Current learning rate: 0.00532 
2025-01-08 08:26:58.359332: train_loss -0.921 
2025-01-08 08:26:58.359839: val_loss -0.855 
2025-01-08 08:26:58.365940: Pseudo dice [np.float32(0.9273)] 
2025-01-08 08:26:58.368965: Epoch time: 40.75 s 
2025-01-08 08:26:58.946276:  
2025-01-08 08:26:58.946778: Epoch 127 
2025-01-08 08:26:58.951287: Current learning rate: 0.00528 
2025-01-08 08:27:39.703704: train_loss -0.9214 
2025-01-08 08:27:39.704207: val_loss -0.8405 
2025-01-08 08:27:39.710225: Pseudo dice [np.float32(0.9153)] 
2025-01-08 08:27:39.713731: Epoch time: 40.76 s 
2025-01-08 08:27:40.284886:  
2025-01-08 08:27:40.285886: Epoch 128 
2025-01-08 08:27:40.290920: Current learning rate: 0.00524 
2025-01-08 08:28:21.047020: train_loss -0.9227 
2025-01-08 08:28:21.048024: val_loss -0.8993 
2025-01-08 08:28:21.053035: Pseudo dice [np.float32(0.9476)] 
2025-01-08 08:28:21.056541: Epoch time: 40.76 s 
2025-01-08 08:28:21.059580: Yayy! New best EMA pseudo Dice: 0.923799991607666 
2025-01-08 08:28:21.998039:  
2025-01-08 08:28:21.998039: Epoch 129 
2025-01-08 08:28:22.003083: Current learning rate: 0.0052 
2025-01-08 08:29:02.700727: train_loss -0.9171 
2025-01-08 08:29:02.701234: val_loss -0.9089 
2025-01-08 08:29:02.706783: Pseudo dice [np.float32(0.9529)] 
2025-01-08 08:29:02.709303: Epoch time: 40.7 s 
2025-01-08 08:29:02.712826: Yayy! New best EMA pseudo Dice: 0.9266999959945679 
2025-01-08 08:29:03.535655:  
2025-01-08 08:29:03.536658: Epoch 130 
2025-01-08 08:29:03.541198: Current learning rate: 0.00517 
2025-01-08 08:29:43.464764: train_loss -0.9179 
2025-01-08 08:29:43.465272: val_loss -0.9172 
2025-01-08 08:29:43.471354: Pseudo dice [np.float32(0.9528)] 
2025-01-08 08:29:43.474390: Epoch time: 39.93 s 
2025-01-08 08:29:43.477420: Yayy! New best EMA pseudo Dice: 0.9293000102043152 
2025-01-08 08:29:44.306554:  
2025-01-08 08:29:44.307057: Epoch 131 
2025-01-08 08:29:44.312603: Current learning rate: 0.00513 
2025-01-08 08:30:23.991816: train_loss -0.9122 
2025-01-08 08:30:23.992325: val_loss -0.8968 
2025-01-08 08:30:23.998941: Pseudo dice [np.float32(0.9408)] 
2025-01-08 08:30:24.002499: Epoch time: 39.69 s 
2025-01-08 08:30:24.005556: Yayy! New best EMA pseudo Dice: 0.930400013923645 
2025-01-08 08:30:24.815441:  
2025-01-08 08:30:24.816444: Epoch 132 
2025-01-08 08:30:24.822011: Current learning rate: 0.00509 
2025-01-08 08:31:04.502524: train_loss -0.9166 
2025-01-08 08:31:04.503527: val_loss -0.8631 
2025-01-08 08:31:04.509647: Pseudo dice [np.float32(0.9388)] 
2025-01-08 08:31:04.512695: Epoch time: 39.69 s 
2025-01-08 08:31:04.515214: Yayy! New best EMA pseudo Dice: 0.9312999844551086 
2025-01-08 08:31:05.345601:  
2025-01-08 08:31:05.346601: Epoch 133 
2025-01-08 08:31:05.351696: Current learning rate: 0.00505 
2025-01-08 08:31:45.002338: train_loss -0.9054 
2025-01-08 08:31:45.003342: val_loss -0.8107 
2025-01-08 08:31:45.007350: Pseudo dice [np.float32(0.9058)] 
2025-01-08 08:31:45.010861: Epoch time: 39.66 s 
2025-01-08 08:31:45.586187:  
2025-01-08 08:31:45.587190: Epoch 134 
2025-01-08 08:31:45.592243: Current learning rate: 0.00501 
2025-01-08 08:32:25.222559: train_loss -0.9272 
2025-01-08 08:32:25.222559: val_loss -0.9229 
2025-01-08 08:32:25.228575: Pseudo dice [np.float32(0.9622)] 
2025-01-08 08:32:25.231584: Epoch time: 39.64 s 
2025-01-08 08:32:25.235094: Yayy! New best EMA pseudo Dice: 0.9320999979972839 
2025-01-08 08:32:26.066921:  
2025-01-08 08:32:26.066921: Epoch 135 
2025-01-08 08:32:26.072470: Current learning rate: 0.00497 
2025-01-08 08:33:05.712807: train_loss -0.9243 
2025-01-08 08:33:05.714334: val_loss -0.893 
2025-01-08 08:33:05.720887: Pseudo dice [np.float32(0.9389)] 
2025-01-08 08:33:05.723919: Epoch time: 39.65 s 
2025-01-08 08:33:05.726947: Yayy! New best EMA pseudo Dice: 0.932699978351593 
2025-01-08 08:33:06.518945:  
2025-01-08 08:33:06.518945: Epoch 136 
2025-01-08 08:33:06.523957: Current learning rate: 0.00493 
2025-01-08 08:33:46.182191: train_loss -0.9247 
2025-01-08 08:33:46.182191: val_loss -0.8533 
2025-01-08 08:33:46.187746: Pseudo dice [np.float32(0.9285)] 
2025-01-08 08:33:46.191284: Epoch time: 39.66 s 
2025-01-08 08:33:46.940489:  
2025-01-08 08:33:46.940489: Epoch 137 
2025-01-08 08:33:46.946505: Current learning rate: 0.00489 
2025-01-08 08:34:26.577993: train_loss -0.9119 
2025-01-08 08:34:26.577993: val_loss -0.8782 
2025-01-08 08:34:26.584547: Pseudo dice [np.float32(0.9333)] 
2025-01-08 08:34:26.587595: Epoch time: 39.64 s 
2025-01-08 08:34:27.174052:  
2025-01-08 08:34:27.175052: Epoch 138 
2025-01-08 08:34:27.178093: Current learning rate: 0.00485 
2025-01-08 08:35:06.824668: train_loss -0.9301 
2025-01-08 08:35:06.825672: val_loss -0.91 
2025-01-08 08:35:06.830730: Pseudo dice [np.float32(0.9518)] 
2025-01-08 08:35:06.834808: Epoch time: 39.65 s 
2025-01-08 08:35:06.837352: Yayy! New best EMA pseudo Dice: 0.9344000220298767 
2025-01-08 08:35:07.677087:  
2025-01-08 08:35:07.677589: Epoch 139 
2025-01-08 08:35:07.682600: Current learning rate: 0.00482 
2025-01-08 08:35:47.330413: train_loss -0.9185 
2025-01-08 08:35:47.331413: val_loss -0.9063 
2025-01-08 08:35:47.336927: Pseudo dice [np.float32(0.9505)] 
2025-01-08 08:35:47.340436: Epoch time: 39.65 s 
2025-01-08 08:35:47.342942: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2025-01-08 08:35:48.169191:  
2025-01-08 08:35:48.169191: Epoch 140 
2025-01-08 08:35:48.174202: Current learning rate: 0.00478 
2025-01-08 08:36:27.826811: train_loss -0.8923 
2025-01-08 08:36:27.827811: val_loss -0.8541 
2025-01-08 08:36:27.833325: Pseudo dice [np.float32(0.9201)] 
2025-01-08 08:36:27.836836: Epoch time: 39.66 s 
2025-01-08 08:36:28.424973:  
2025-01-08 08:36:28.424973: Epoch 141 
2025-01-08 08:36:28.430001: Current learning rate: 0.00474 
2025-01-08 08:37:08.080105: train_loss -0.9168 
2025-01-08 08:37:08.080609: val_loss -0.893 
2025-01-08 08:37:08.086230: Pseudo dice [np.float32(0.9454)] 
2025-01-08 08:37:08.089288: Epoch time: 39.66 s 
2025-01-08 08:37:08.680532:  
2025-01-08 08:37:08.681535: Epoch 142 
2025-01-08 08:37:08.686112: Current learning rate: 0.0047 
2025-01-08 08:37:48.352998: train_loss -0.8979 
2025-01-08 08:37:48.352998: val_loss -0.8816 
2025-01-08 08:37:48.359012: Pseudo dice [np.float32(0.9424)] 
2025-01-08 08:37:48.362518: Epoch time: 39.67 s 
2025-01-08 08:37:48.365525: Yayy! New best EMA pseudo Dice: 0.9362000226974487 
2025-01-08 08:37:49.158833:  
2025-01-08 08:37:49.158833: Epoch 143 
2025-01-08 08:37:49.165462: Current learning rate: 0.00466 
2025-01-08 08:38:28.799164: train_loss -0.9198 
2025-01-08 08:38:28.800167: val_loss -0.919 
2025-01-08 08:38:28.805179: Pseudo dice [np.float32(0.9574)] 
2025-01-08 08:38:28.809187: Epoch time: 39.64 s 
2025-01-08 08:38:28.811692: Yayy! New best EMA pseudo Dice: 0.9383000135421753 
2025-01-08 08:38:29.648701:  
2025-01-08 08:38:29.648701: Epoch 144 
2025-01-08 08:38:29.654231: Current learning rate: 0.00462 
2025-01-08 08:39:09.311847: train_loss -0.9258 
2025-01-08 08:39:09.313358: val_loss -0.9138 
2025-01-08 08:39:09.318935: Pseudo dice [np.float32(0.9553)] 
2025-01-08 08:39:09.322477: Epoch time: 39.66 s 
2025-01-08 08:39:09.325089: Yayy! New best EMA pseudo Dice: 0.9399999976158142 
2025-01-08 08:39:10.338564:  
2025-01-08 08:39:10.339567: Epoch 145 
2025-01-08 08:39:10.344168: Current learning rate: 0.00458 
2025-01-08 08:39:49.991908: train_loss -0.917 
2025-01-08 08:39:49.993411: val_loss -0.8365 
2025-01-08 08:39:49.998423: Pseudo dice [np.float32(0.9149)] 
2025-01-08 08:39:50.001933: Epoch time: 39.65 s 
2025-01-08 08:39:50.587696:  
2025-01-08 08:39:50.588202: Epoch 146 
2025-01-08 08:39:50.593339: Current learning rate: 0.00454 
2025-01-08 08:40:30.244800: train_loss -0.924 
2025-01-08 08:40:30.245306: val_loss -0.9168 
2025-01-08 08:40:30.251350: Pseudo dice [np.float32(0.9553)] 
2025-01-08 08:40:30.254380: Epoch time: 39.66 s 
2025-01-08 08:40:30.839501:  
2025-01-08 08:40:30.840037: Epoch 147 
2025-01-08 08:40:30.845674: Current learning rate: 0.0045 
2025-01-08 08:41:10.528978: train_loss -0.9248 
2025-01-08 08:41:10.529980: val_loss -0.9015 
2025-01-08 08:41:10.536116: Pseudo dice [np.float32(0.947)] 
2025-01-08 08:41:10.539656: Epoch time: 39.69 s 
2025-01-08 08:41:10.542709: Yayy! New best EMA pseudo Dice: 0.9401000142097473 
2025-01-08 08:41:11.355969:  
2025-01-08 08:41:11.355969: Epoch 148 
2025-01-08 08:41:11.360981: Current learning rate: 0.00446 
2025-01-08 08:41:51.029392: train_loss -0.921 
2025-01-08 08:41:51.029895: val_loss -0.8323 
2025-01-08 08:41:51.035955: Pseudo dice [np.float32(0.9312)] 
2025-01-08 08:41:51.038476: Epoch time: 39.67 s 
2025-01-08 08:41:51.625484:  
2025-01-08 08:41:51.625484: Epoch 149 
2025-01-08 08:41:51.631017: Current learning rate: 0.00442 
2025-01-08 08:42:31.297369: train_loss -0.9137 
2025-01-08 08:42:31.298377: val_loss -0.9055 
2025-01-08 08:42:31.303926: Pseudo dice [np.float32(0.9501)] 
2025-01-08 08:42:31.307960: Epoch time: 39.67 s 
2025-01-08 08:42:31.484824: Yayy! New best EMA pseudo Dice: 0.9402999877929688 
2025-01-08 08:42:32.343496:  
2025-01-08 08:42:32.343998: Epoch 150 
2025-01-08 08:42:32.349010: Current learning rate: 0.00438 
2025-01-08 08:43:11.962988: train_loss -0.9255 
2025-01-08 08:43:11.962988: val_loss -0.8784 
2025-01-08 08:43:11.969117: Pseudo dice [np.float32(0.9276)] 
2025-01-08 08:43:11.973266: Epoch time: 39.62 s 
2025-01-08 08:43:12.616413:  
2025-01-08 08:43:12.616413: Epoch 151 
2025-01-08 08:43:12.621426: Current learning rate: 0.00434 
2025-01-08 08:43:52.254868: train_loss -0.9113 
2025-01-08 08:43:52.255374: val_loss -0.8887 
2025-01-08 08:43:52.261412: Pseudo dice [np.float32(0.9364)] 
2025-01-08 08:43:52.265443: Epoch time: 39.64 s 
2025-01-08 08:43:52.857172:  
2025-01-08 08:43:52.858175: Epoch 152 
2025-01-08 08:43:52.863235: Current learning rate: 0.0043 
2025-01-08 08:44:32.522200: train_loss -0.9189 
2025-01-08 08:44:32.522707: val_loss -0.8895 
2025-01-08 08:44:32.527751: Pseudo dice [np.float32(0.9322)] 
2025-01-08 08:44:32.531791: Epoch time: 39.67 s 
2025-01-08 08:44:33.264615:  
2025-01-08 08:44:33.264615: Epoch 153 
2025-01-08 08:44:33.270189: Current learning rate: 0.00427 
2025-01-08 08:45:12.975941: train_loss -0.907 
2025-01-08 08:45:12.977448: val_loss -0.8351 
2025-01-08 08:45:12.982983: Pseudo dice [np.float32(0.911)] 
2025-01-08 08:45:12.986573: Epoch time: 39.71 s 
2025-01-08 08:45:13.578922:  
2025-01-08 08:45:13.578922: Epoch 154 
2025-01-08 08:45:13.583933: Current learning rate: 0.00423 
2025-01-08 08:45:53.265523: train_loss -0.9179 
2025-01-08 08:45:53.265523: val_loss -0.9125 
2025-01-08 08:45:53.272054: Pseudo dice [np.float32(0.9508)] 
2025-01-08 08:45:53.274565: Epoch time: 39.69 s 
2025-01-08 08:45:53.866417:  
2025-01-08 08:45:53.866920: Epoch 155 
2025-01-08 08:45:53.871929: Current learning rate: 0.00419 
2025-01-08 08:46:39.572111: train_loss -0.916 
2025-01-08 08:46:39.573114: val_loss -0.888 
2025-01-08 08:46:39.579631: Pseudo dice [np.float32(0.9437)] 
2025-01-08 08:46:39.583140: Epoch time: 45.71 s 
2025-01-08 08:46:40.177755:  
2025-01-08 08:46:40.177755: Epoch 156 
2025-01-08 08:46:40.182907: Current learning rate: 0.00415 
2025-01-08 08:47:20.931033: train_loss -0.9363 
2025-01-08 08:47:20.931536: val_loss -0.92 
2025-01-08 08:47:20.936549: Pseudo dice [np.float32(0.9578)] 
2025-01-08 08:47:20.939567: Epoch time: 40.75 s 
2025-01-08 08:47:21.535590:  
2025-01-08 08:47:21.536594: Epoch 157 
2025-01-08 08:47:21.541151: Current learning rate: 0.00411 
2025-01-08 08:48:02.281694: train_loss -0.9223 
2025-01-08 08:48:02.282197: val_loss -0.831 
2025-01-08 08:48:02.288216: Pseudo dice [np.float32(0.9324)] 
2025-01-08 08:48:02.291722: Epoch time: 40.75 s 
2025-01-08 08:48:02.888039:  
2025-01-08 08:48:02.888039: Epoch 158 
2025-01-08 08:48:02.894231: Current learning rate: 0.00407 
2025-01-08 08:48:43.580918: train_loss -0.902 
2025-01-08 08:48:43.581421: val_loss -0.7142 
2025-01-08 08:48:43.586557: Pseudo dice [np.float32(0.882)] 
2025-01-08 08:48:43.590567: Epoch time: 40.69 s 
2025-01-08 08:48:44.192564:  
2025-01-08 08:48:44.192564: Epoch 159 
2025-01-08 08:48:44.197575: Current learning rate: 0.00403 
2025-01-08 08:49:24.935765: train_loss -0.9168 
2025-01-08 08:49:24.935765: val_loss -0.8232 
2025-01-08 08:49:24.940782: Pseudo dice [np.float32(0.9298)] 
2025-01-08 08:49:24.944293: Epoch time: 40.74 s 
2025-01-08 08:49:25.537224:  
2025-01-08 08:49:25.537224: Epoch 160 
2025-01-08 08:49:25.541260: Current learning rate: 0.00399 
2025-01-08 08:50:06.374172: train_loss -0.8971 
2025-01-08 08:50:06.374674: val_loss -0.9074 
2025-01-08 08:50:06.380702: Pseudo dice [np.float32(0.9506)] 
2025-01-08 08:50:06.383512: Epoch time: 40.84 s 
2025-01-08 08:50:06.971199:  
2025-01-08 08:50:06.972193: Epoch 161 
2025-01-08 08:50:06.977314: Current learning rate: 0.00395 
2025-01-08 08:50:47.668607: train_loss -0.9211 
2025-01-08 08:50:47.668607: val_loss -0.9119 
2025-01-08 08:50:47.675145: Pseudo dice [np.float32(0.9517)] 
2025-01-08 08:50:47.678154: Epoch time: 40.7 s 
2025-01-08 08:50:48.268251:  
2025-01-08 08:50:48.268251: Epoch 162 
2025-01-08 08:50:48.273264: Current learning rate: 0.00391 
2025-01-08 08:51:29.183635: train_loss -0.9299 
2025-01-08 08:51:29.184138: val_loss -0.8882 
2025-01-08 08:51:29.189149: Pseudo dice [np.float32(0.9357)] 
2025-01-08 08:51:29.192659: Epoch time: 40.92 s 
2025-01-08 08:51:29.925730:  
2025-01-08 08:51:29.925730: Epoch 163 
2025-01-08 08:51:29.931315: Current learning rate: 0.00387 
2025-01-08 08:52:10.750228: train_loss -0.9148 
2025-01-08 08:52:10.750730: val_loss -0.8065 
2025-01-08 08:52:10.755743: Pseudo dice [np.float32(0.9173)] 
2025-01-08 08:52:10.759760: Epoch time: 40.83 s 
2025-01-08 08:52:11.352441:  
2025-01-08 08:52:11.353442: Epoch 164 
2025-01-08 08:52:11.356510: Current learning rate: 0.00383 
2025-01-08 08:52:52.102933: train_loss -0.9199 
2025-01-08 08:52:52.102933: val_loss -0.7691 
2025-01-08 08:52:52.109452: Pseudo dice [np.float32(0.9172)] 
2025-01-08 08:52:52.112962: Epoch time: 40.75 s 
2025-01-08 08:52:52.689629:  
2025-01-08 08:52:52.690629: Epoch 165 
2025-01-08 08:52:52.696147: Current learning rate: 0.00379 
2025-01-08 08:53:33.419365: train_loss -0.9256 
2025-01-08 08:53:33.419867: val_loss -0.7687 
2025-01-08 08:53:33.424879: Pseudo dice [np.float32(0.9265)] 
2025-01-08 08:53:33.428395: Epoch time: 40.73 s 
2025-01-08 08:53:34.013555:  
2025-01-08 08:53:34.014555: Epoch 166 
2025-01-08 08:53:34.019688: Current learning rate: 0.00375 
2025-01-08 08:54:14.711650: train_loss -0.9154 
2025-01-08 08:54:14.711650: val_loss -0.8887 
2025-01-08 08:54:14.718253: Pseudo dice [np.float32(0.9437)] 
2025-01-08 08:54:14.721370: Epoch time: 40.7 s 
2025-01-08 08:54:15.301096:  
2025-01-08 08:54:15.301096: Epoch 167 
2025-01-08 08:54:15.306126: Current learning rate: 0.00371 
2025-01-08 08:54:56.012532: train_loss -0.9282 
2025-01-08 08:54:56.013532: val_loss -0.9252 
2025-01-08 08:54:56.019056: Pseudo dice [np.float32(0.9587)] 
2025-01-08 08:54:56.022566: Epoch time: 40.71 s 
2025-01-08 08:54:56.755745:  
2025-01-08 08:54:56.755745: Epoch 168 
2025-01-08 08:54:56.761279: Current learning rate: 0.00367 
2025-01-08 08:55:37.454377: train_loss -0.9252 
2025-01-08 08:55:37.454377: val_loss -0.88 
2025-01-08 08:55:37.459389: Pseudo dice [np.float32(0.9413)] 
2025-01-08 08:55:37.462899: Epoch time: 40.7 s 
2025-01-08 08:55:38.047519:  
2025-01-08 08:55:38.047519: Epoch 169 
2025-01-08 08:55:38.053609: Current learning rate: 0.00363 
2025-01-08 08:56:18.763089: train_loss -0.9232 
2025-01-08 08:56:18.763089: val_loss -0.7377 
2025-01-08 08:56:18.768101: Pseudo dice [np.float32(0.9076)] 
2025-01-08 08:56:18.771185: Epoch time: 40.72 s 
2025-01-08 08:56:19.359287:  
2025-01-08 08:56:19.359790: Epoch 170 
2025-01-08 08:56:19.364801: Current learning rate: 0.00359 
2025-01-08 08:57:00.050164: train_loss -0.9346 
2025-01-08 08:57:00.051170: val_loss -0.8841 
2025-01-08 08:57:00.055727: Pseudo dice [np.float32(0.9508)] 
2025-01-08 08:57:00.060281: Epoch time: 40.69 s 
2025-01-08 08:57:00.646538:  
2025-01-08 08:57:00.647538: Epoch 171 
2025-01-08 08:57:00.652637: Current learning rate: 0.00355 
2025-01-08 08:57:40.604371: train_loss -0.9249 
2025-01-08 08:57:40.604873: val_loss -0.8054 
2025-01-08 08:57:40.612394: Pseudo dice [np.float32(0.9255)] 
2025-01-08 08:57:40.617407: Epoch time: 39.96 s 
2025-01-08 08:57:41.208426:  
2025-01-08 08:57:41.209426: Epoch 172 
2025-01-08 08:57:41.214015: Current learning rate: 0.00351 
2025-01-08 08:58:20.849363: train_loss -0.9226 
2025-01-08 08:58:20.849363: val_loss -0.8724 
2025-01-08 08:58:20.855381: Pseudo dice [np.float32(0.9418)] 
2025-01-08 08:58:20.858887: Epoch time: 39.64 s 
2025-01-08 08:58:21.442440:  
2025-01-08 08:58:21.442440: Epoch 173 
2025-01-08 08:58:21.448029: Current learning rate: 0.00346 
2025-01-08 08:59:01.100429: train_loss -0.9282 
2025-01-08 08:59:01.100429: val_loss -0.9138 
2025-01-08 08:59:01.106491: Pseudo dice [np.float32(0.9542)] 
2025-01-08 08:59:01.108994: Epoch time: 39.66 s 
2025-01-08 08:59:01.691386:  
2025-01-08 08:59:01.691888: Epoch 174 
2025-01-08 08:59:01.696900: Current learning rate: 0.00342 
2025-01-08 08:59:41.331622: train_loss -0.9398 
2025-01-08 08:59:41.332625: val_loss -0.9284 
2025-01-08 08:59:41.339142: Pseudo dice [np.float32(0.9599)] 
2025-01-08 08:59:41.342653: Epoch time: 39.64 s 
2025-01-08 08:59:41.926752:  
2025-01-08 08:59:41.926752: Epoch 175 
2025-01-08 08:59:41.931302: Current learning rate: 0.00338 
2025-01-08 09:00:21.562201: train_loss -0.9089 
2025-01-08 09:00:21.562703: val_loss -0.8753 
2025-01-08 09:00:21.567716: Pseudo dice [np.float32(0.9306)] 
2025-01-08 09:00:21.571225: Epoch time: 39.64 s 
2025-01-08 09:00:22.310643:  
2025-01-08 09:00:22.311642: Epoch 176 
2025-01-08 09:00:22.314704: Current learning rate: 0.00334 
2025-01-08 09:01:01.935992: train_loss -0.9274 
2025-01-08 09:01:01.935992: val_loss -0.9233 
2025-01-08 09:01:01.942012: Pseudo dice [np.float32(0.9582)] 
2025-01-08 09:01:01.945521: Epoch time: 39.63 s 
2025-01-08 09:01:01.948538: Yayy! New best EMA pseudo Dice: 0.9402999877929688 
2025-01-08 09:01:02.759729:  
2025-01-08 09:01:02.759729: Epoch 177 
2025-01-08 09:01:02.765343: Current learning rate: 0.0033 
2025-01-08 09:01:42.429497: train_loss -0.9352 
2025-01-08 09:01:42.429497: val_loss -0.911 
2025-01-08 09:01:42.437018: Pseudo dice [np.float32(0.9479)] 
2025-01-08 09:01:42.439526: Epoch time: 39.67 s 
2025-01-08 09:01:42.443034: Yayy! New best EMA pseudo Dice: 0.941100001335144 
2025-01-08 09:01:43.233532:  
2025-01-08 09:01:43.234035: Epoch 178 
2025-01-08 09:01:43.239047: Current learning rate: 0.00326 
2025-01-08 09:02:22.910235: train_loss -0.9154 
2025-01-08 09:02:22.910235: val_loss -0.8931 
2025-01-08 09:02:22.916250: Pseudo dice [np.float32(0.9354)] 
2025-01-08 09:02:22.919261: Epoch time: 39.68 s 
2025-01-08 09:02:23.506156:  
2025-01-08 09:02:23.506156: Epoch 179 
2025-01-08 09:02:23.511505: Current learning rate: 0.00322 
2025-01-08 09:03:03.169556: train_loss -0.9237 
2025-01-08 09:03:03.170563: val_loss -0.8532 
2025-01-08 09:03:03.175573: Pseudo dice [np.float32(0.9075)] 
2025-01-08 09:03:03.179081: Epoch time: 39.66 s 
2025-01-08 09:03:03.767954:  
2025-01-08 09:03:03.767954: Epoch 180 
2025-01-08 09:03:03.773243: Current learning rate: 0.00318 
2025-01-08 09:03:43.439282: train_loss -0.8997 
2025-01-08 09:03:43.439282: val_loss -0.853 
2025-01-08 09:03:43.445300: Pseudo dice [np.float32(0.909)] 
2025-01-08 09:03:43.448845: Epoch time: 39.67 s 
2025-01-08 09:03:44.045412:  
2025-01-08 09:03:44.045412: Epoch 181 
2025-01-08 09:03:44.050458: Current learning rate: 0.00314 
2025-01-08 09:04:23.663622: train_loss -0.9188 
2025-01-08 09:04:23.663622: val_loss -0.8957 
2025-01-08 09:04:23.669639: Pseudo dice [np.float32(0.9431)] 
2025-01-08 09:04:23.672147: Epoch time: 39.62 s 
2025-01-08 09:04:24.259265:  
2025-01-08 09:04:24.260265: Epoch 182 
2025-01-08 09:04:24.263373: Current learning rate: 0.0031 
2025-01-08 09:05:03.892625: train_loss -0.9409 
2025-01-08 09:05:03.893128: val_loss -0.901 
2025-01-08 09:05:03.898140: Pseudo dice [np.float32(0.9479)] 
2025-01-08 09:05:03.901653: Epoch time: 39.63 s 
2025-01-08 09:05:04.487726:  
2025-01-08 09:05:04.487726: Epoch 183 
2025-01-08 09:05:04.491237: Current learning rate: 0.00306 
2025-01-08 09:05:44.171710: train_loss -0.9304 
2025-01-08 09:05:44.172713: val_loss -0.8807 
2025-01-08 09:05:44.178737: Pseudo dice [np.float32(0.93)] 
2025-01-08 09:05:44.181746: Epoch time: 39.69 s 
2025-01-08 09:05:44.918717:  
2025-01-08 09:05:44.919220: Epoch 184 
2025-01-08 09:05:44.924232: Current learning rate: 0.00302 
2025-01-08 09:06:24.555143: train_loss -0.925 
2025-01-08 09:06:24.556141: val_loss -0.8856 
2025-01-08 09:06:24.561655: Pseudo dice [np.float32(0.9451)] 
2025-01-08 09:06:24.564164: Epoch time: 39.64 s 
2025-01-08 09:06:25.157257:  
2025-01-08 09:06:25.157257: Epoch 185 
2025-01-08 09:06:25.161277: Current learning rate: 0.00297 
2025-01-08 09:07:04.796921: train_loss -0.9266 
2025-01-08 09:07:04.796921: val_loss -0.9007 
2025-01-08 09:07:04.803439: Pseudo dice [np.float32(0.9433)] 
2025-01-08 09:07:04.806950: Epoch time: 39.64 s 
2025-01-08 09:07:05.397395:  
2025-01-08 09:07:05.397395: Epoch 186 
2025-01-08 09:07:05.402407: Current learning rate: 0.00293 
2025-01-08 09:07:45.032911: train_loss -0.9012 
2025-01-08 09:07:45.033423: val_loss -0.8901 
2025-01-08 09:07:45.038980: Pseudo dice [np.float32(0.94)] 
2025-01-08 09:07:45.042512: Epoch time: 39.64 s 
2025-01-08 09:07:45.629359:  
2025-01-08 09:07:45.629359: Epoch 187 
2025-01-08 09:07:45.634372: Current learning rate: 0.00289 
2025-01-08 09:08:25.268918: train_loss -0.9142 
2025-01-08 09:08:25.269422: val_loss -0.8797 
2025-01-08 09:08:25.273932: Pseudo dice [np.float32(0.9424)] 
2025-01-08 09:08:25.276944: Epoch time: 39.64 s 
2025-01-08 09:08:25.861284:  
2025-01-08 09:08:25.861284: Epoch 188 
2025-01-08 09:08:25.866300: Current learning rate: 0.00285 
2025-01-08 09:09:05.487850: train_loss -0.9333 
2025-01-08 09:09:05.487850: val_loss -0.8531 
2025-01-08 09:09:05.493862: Pseudo dice [np.float32(0.9277)] 
2025-01-08 09:09:05.496869: Epoch time: 39.63 s 
2025-01-08 09:09:06.085109:  
2025-01-08 09:09:06.085109: Epoch 189 
2025-01-08 09:09:06.090170: Current learning rate: 0.00281 
2025-01-08 09:09:45.725798: train_loss -0.9351 
2025-01-08 09:09:45.725798: val_loss -0.9333 
2025-01-08 09:09:45.731842: Pseudo dice [np.float32(0.9651)] 
2025-01-08 09:09:45.734915: Epoch time: 39.64 s 
2025-01-08 09:09:46.328979:  
2025-01-08 09:09:46.329481: Epoch 190 
2025-01-08 09:09:46.333992: Current learning rate: 0.00277 
2025-01-08 09:10:26.020566: train_loss -0.9386 
2025-01-08 09:10:26.021068: val_loss -0.9072 
2025-01-08 09:10:26.027085: Pseudo dice [np.float32(0.9583)] 
2025-01-08 09:10:26.030626: Epoch time: 39.69 s 
2025-01-08 09:10:26.033688: Yayy! New best EMA pseudo Dice: 0.9417999982833862 
2025-01-08 09:10:26.874889:  
2025-01-08 09:10:26.875889: Epoch 191 
2025-01-08 09:10:26.881401: Current learning rate: 0.00273 
2025-01-08 09:11:06.513718: train_loss -0.9336 
2025-01-08 09:11:06.514223: val_loss -0.8213 
2025-01-08 09:11:06.519237: Pseudo dice [np.float32(0.9075)] 
2025-01-08 09:11:06.522745: Epoch time: 39.64 s 
2025-01-08 09:11:07.273455:  
2025-01-08 09:11:07.273455: Epoch 192 
2025-01-08 09:11:07.279518: Current learning rate: 0.00268 
2025-01-08 09:11:46.950540: train_loss -0.9288 
2025-01-08 09:11:46.950540: val_loss -0.9151 
2025-01-08 09:11:46.957053: Pseudo dice [np.float32(0.9538)] 
2025-01-08 09:11:46.959561: Epoch time: 39.68 s 
2025-01-08 09:11:47.557288:  
2025-01-08 09:11:47.557792: Epoch 193 
2025-01-08 09:11:47.562803: Current learning rate: 0.00264 
2025-01-08 09:12:27.252889: train_loss -0.9423 
2025-01-08 09:12:27.253893: val_loss -0.88 
2025-01-08 09:12:27.258905: Pseudo dice [np.float32(0.943)] 
2025-01-08 09:12:27.262915: Epoch time: 39.7 s 
2025-01-08 09:12:27.862232:  
2025-01-08 09:12:27.863237: Epoch 194 
2025-01-08 09:12:27.867790: Current learning rate: 0.0026 
2025-01-08 09:13:07.483665: train_loss -0.9371 
2025-01-08 09:13:07.484666: val_loss -0.8988 
2025-01-08 09:13:07.490181: Pseudo dice [np.float32(0.9468)] 
2025-01-08 09:13:07.492685: Epoch time: 39.62 s 
2025-01-08 09:13:08.083988:  
2025-01-08 09:13:08.084491: Epoch 195 
2025-01-08 09:13:08.088001: Current learning rate: 0.00256 
2025-01-08 09:13:47.742275: train_loss -0.9386 
2025-01-08 09:13:47.742275: val_loss -0.9188 
2025-01-08 09:13:47.748295: Pseudo dice [np.float32(0.9535)] 
2025-01-08 09:13:47.752308: Epoch time: 39.66 s 
2025-01-08 09:13:47.754819: Yayy! New best EMA pseudo Dice: 0.9420999884605408 
2025-01-08 09:13:48.592425:  
2025-01-08 09:13:48.592425: Epoch 196 
2025-01-08 09:13:48.597473: Current learning rate: 0.00252 
2025-01-08 09:14:28.224324: train_loss -0.9437 
2025-01-08 09:14:28.225827: val_loss -0.9163 
2025-01-08 09:14:28.230847: Pseudo dice [np.float32(0.9553)] 
2025-01-08 09:14:28.234365: Epoch time: 39.63 s 
2025-01-08 09:14:28.237395: Yayy! New best EMA pseudo Dice: 0.9434000253677368 
2025-01-08 09:14:29.038576:  
2025-01-08 09:14:29.039580: Epoch 197 
2025-01-08 09:14:29.044096: Current learning rate: 0.00248 
2025-01-08 09:15:08.674298: train_loss -0.9266 
2025-01-08 09:15:08.674298: val_loss -0.7562 
2025-01-08 09:15:08.680314: Pseudo dice [np.float32(0.899)] 
2025-01-08 09:15:08.682337: Epoch time: 39.64 s 
2025-01-08 09:15:09.281175:  
2025-01-08 09:15:09.282176: Epoch 198 
2025-01-08 09:15:09.286731: Current learning rate: 0.00243 
2025-01-08 09:15:48.927479: train_loss -0.9397 
2025-01-08 09:15:48.928483: val_loss -0.9153 
2025-01-08 09:15:48.933034: Pseudo dice [np.float32(0.9537)] 
2025-01-08 09:15:48.937081: Epoch time: 39.65 s 
2025-01-08 09:15:49.679115:  
2025-01-08 09:15:49.679115: Epoch 199 
2025-01-08 09:15:49.684683: Current learning rate: 0.00239 
2025-01-08 09:16:29.287283: train_loss -0.9299 
2025-01-08 09:16:29.287795: val_loss -0.8181 
2025-01-08 09:16:29.293423: Pseudo dice [np.float32(0.9193)] 
2025-01-08 09:16:29.296464: Epoch time: 39.61 s 
2025-01-08 09:16:30.095481:  
2025-01-08 09:16:30.095481: Epoch 200 
2025-01-08 09:16:30.100493: Current learning rate: 0.00235 
2025-01-08 09:17:09.761526: train_loss -0.9252 
2025-01-08 09:17:09.761526: val_loss -0.9136 
2025-01-08 09:17:09.766541: Pseudo dice [np.float32(0.9493)] 
2025-01-08 09:17:09.770550: Epoch time: 39.67 s 
2025-01-08 09:17:10.372959:  
2025-01-08 09:17:10.372959: Epoch 201 
2025-01-08 09:17:10.377011: Current learning rate: 0.00231 
2025-01-08 09:17:50.057181: train_loss -0.9278 
2025-01-08 09:17:50.057181: val_loss -0.9301 
2025-01-08 09:17:50.063797: Pseudo dice [np.float32(0.9643)] 
2025-01-08 09:17:50.066848: Epoch time: 39.68 s 
2025-01-08 09:17:50.669158:  
2025-01-08 09:17:50.669158: Epoch 202 
2025-01-08 09:17:50.674673: Current learning rate: 0.00226 
2025-01-08 09:18:30.330558: train_loss -0.9382 
2025-01-08 09:18:30.330558: val_loss -0.9154 
2025-01-08 09:18:30.336574: Pseudo dice [np.float32(0.9544)] 
2025-01-08 09:18:30.340090: Epoch time: 39.66 s 
2025-01-08 09:18:30.940902:  
2025-01-08 09:18:30.941901: Epoch 203 
2025-01-08 09:18:30.946968: Current learning rate: 0.00222 
2025-01-08 09:19:10.583775: train_loss -0.9403 
2025-01-08 09:19:10.584775: val_loss -0.889 
2025-01-08 09:19:10.590289: Pseudo dice [np.float32(0.9375)] 
2025-01-08 09:19:10.592802: Epoch time: 39.64 s 
2025-01-08 09:19:11.190148:  
2025-01-08 09:19:11.190650: Epoch 204 
2025-01-08 09:19:11.195661: Current learning rate: 0.00218 
2025-01-08 09:19:50.841359: train_loss -0.9348 
2025-01-08 09:19:50.842862: val_loss -0.8836 
2025-01-08 09:19:50.847875: Pseudo dice [np.float32(0.9408)] 
2025-01-08 09:19:50.851392: Epoch time: 39.65 s 
2025-01-08 09:19:51.443788:  
2025-01-08 09:19:51.443788: Epoch 205 
2025-01-08 09:19:51.448867: Current learning rate: 0.00214 
2025-01-08 09:20:31.074728: train_loss -0.9321 
2025-01-08 09:20:31.075247: val_loss -0.919 
2025-01-08 09:20:31.080289: Pseudo dice [np.float32(0.9575)] 
2025-01-08 09:20:31.083338: Epoch time: 39.63 s 
2025-01-08 09:20:31.086371: Yayy! New best EMA pseudo Dice: 0.9438999891281128 
2025-01-08 09:20:31.867357:  
2025-01-08 09:20:31.868361: Epoch 206 
2025-01-08 09:20:31.873024: Current learning rate: 0.00209 
2025-01-08 09:21:11.520572: train_loss -0.9441 
2025-01-08 09:21:11.521572: val_loss -0.9254 
2025-01-08 09:21:11.527084: Pseudo dice [np.float32(0.9581)] 
2025-01-08 09:21:11.530595: Epoch time: 39.65 s 
2025-01-08 09:21:11.533099: Yayy! New best EMA pseudo Dice: 0.9452999830245972 
2025-01-08 09:21:12.501085:  
2025-01-08 09:21:12.501085: Epoch 207 
2025-01-08 09:21:12.506677: Current learning rate: 0.00205 
2025-01-08 09:21:52.118835: train_loss -0.9382 
2025-01-08 09:21:52.119338: val_loss -0.7218 
2025-01-08 09:21:52.125358: Pseudo dice [np.float32(0.877)] 
2025-01-08 09:21:52.127863: Epoch time: 39.62 s 
2025-01-08 09:21:52.699873:  
2025-01-08 09:21:52.699873: Epoch 208 
2025-01-08 09:21:52.703902: Current learning rate: 0.00201 
2025-01-08 09:22:32.342744: train_loss -0.9238 
2025-01-08 09:22:32.342744: val_loss -0.8928 
2025-01-08 09:22:32.348850: Pseudo dice [np.float32(0.9425)] 
2025-01-08 09:22:32.350880: Epoch time: 39.64 s 
2025-01-08 09:22:32.916378:  
2025-01-08 09:22:32.916378: Epoch 209 
2025-01-08 09:22:32.921900: Current learning rate: 0.00196 
2025-01-08 09:23:12.548310: train_loss -0.9272 
2025-01-08 09:23:12.548813: val_loss -0.7929 
2025-01-08 09:23:12.553824: Pseudo dice [np.float32(0.9251)] 
2025-01-08 09:23:12.556329: Epoch time: 39.63 s 
2025-01-08 09:23:13.155044:  
2025-01-08 09:23:13.155547: Epoch 210 
2025-01-08 09:23:13.160564: Current learning rate: 0.00192 
2025-01-08 09:23:52.786973: train_loss -0.9423 
2025-01-08 09:23:52.786973: val_loss -0.886 
2025-01-08 09:23:52.792987: Pseudo dice [np.float32(0.9287)] 
2025-01-08 09:23:52.796515: Epoch time: 39.63 s 
2025-01-08 09:23:53.366420:  
2025-01-08 09:23:53.366420: Epoch 211 
2025-01-08 09:23:53.371962: Current learning rate: 0.00188 
2025-01-08 09:24:33.004832: train_loss -0.9406 
2025-01-08 09:24:33.005830: val_loss -0.9103 
2025-01-08 09:24:33.011355: Pseudo dice [np.float32(0.9538)] 
2025-01-08 09:24:33.013866: Epoch time: 39.64 s 
2025-01-08 09:24:33.575471:  
2025-01-08 09:24:33.575471: Epoch 212 
2025-01-08 09:24:33.580822: Current learning rate: 0.00184 
2025-01-08 09:25:13.212317: train_loss -0.9343 
2025-01-08 09:25:13.212835: val_loss -0.9089 
2025-01-08 09:25:13.218467: Pseudo dice [np.float32(0.9403)] 
2025-01-08 09:25:13.222048: Epoch time: 39.64 s 
2025-01-08 09:25:13.788745:  
2025-01-08 09:25:13.788745: Epoch 213 
2025-01-08 09:25:13.794822: Current learning rate: 0.00179 
2025-01-08 09:25:53.446682: train_loss -0.9372 
2025-01-08 09:25:53.447184: val_loss -0.9032 
2025-01-08 09:25:53.454244: Pseudo dice [np.float32(0.9528)] 
2025-01-08 09:25:53.457761: Epoch time: 39.66 s 
2025-01-08 09:25:54.093518:  
2025-01-08 09:25:54.093518: Epoch 214 
2025-01-08 09:25:54.097567: Current learning rate: 0.00175 
2025-01-08 09:26:33.727345: train_loss -0.9351 
2025-01-08 09:26:33.727345: val_loss -0.8293 
2025-01-08 09:26:33.733363: Pseudo dice [np.float32(0.9386)] 
2025-01-08 09:26:33.736868: Epoch time: 39.63 s 
2025-01-08 09:26:34.439030:  
2025-01-08 09:26:34.440030: Epoch 215 
2025-01-08 09:26:34.445549: Current learning rate: 0.0017 
2025-01-08 09:27:14.081308: train_loss -0.9373 
2025-01-08 09:27:14.082308: val_loss -0.9224 
2025-01-08 09:27:14.087823: Pseudo dice [np.float32(0.958)] 
2025-01-08 09:27:14.090330: Epoch time: 39.64 s 
2025-01-08 09:27:14.651804:  
2025-01-08 09:27:14.651804: Epoch 216 
2025-01-08 09:27:14.655836: Current learning rate: 0.00166 
2025-01-08 09:27:54.291351: train_loss -0.9412 
2025-01-08 09:27:54.291864: val_loss -0.8847 
2025-01-08 09:27:54.297409: Pseudo dice [np.float32(0.9409)] 
2025-01-08 09:27:54.300922: Epoch time: 39.64 s 
2025-01-08 09:27:54.860160:  
2025-01-08 09:27:54.860160: Epoch 217 
2025-01-08 09:27:54.865738: Current learning rate: 0.00162 
2025-01-08 09:28:34.534821: train_loss -0.9499 
2025-01-08 09:28:34.535324: val_loss -0.9308 
2025-01-08 09:28:34.540853: Pseudo dice [np.float32(0.9629)] 
2025-01-08 09:28:34.543955: Epoch time: 39.68 s 
2025-01-08 09:28:35.104331:  
2025-01-08 09:28:35.104331: Epoch 218 
2025-01-08 09:28:35.109401: Current learning rate: 0.00157 
2025-01-08 09:29:14.734532: train_loss -0.9384 
2025-01-08 09:29:14.735535: val_loss -0.9238 
2025-01-08 09:29:14.740552: Pseudo dice [np.float32(0.9604)] 
2025-01-08 09:29:14.744063: Epoch time: 39.63 s 
2025-01-08 09:29:14.747076: Yayy! New best EMA pseudo Dice: 0.9453999996185303 
2025-01-08 09:29:15.561468:  
2025-01-08 09:29:15.561468: Epoch 219 
2025-01-08 09:29:15.567066: Current learning rate: 0.00153 
2025-01-08 09:29:55.241496: train_loss -0.9406 
2025-01-08 09:29:55.242000: val_loss -0.9424 
2025-01-08 09:29:55.247038: Pseudo dice [np.float32(0.9683)] 
2025-01-08 09:29:55.250593: Epoch time: 39.68 s 
2025-01-08 09:29:55.253664: Yayy! New best EMA pseudo Dice: 0.947700023651123 
2025-01-08 09:29:56.022386:  
2025-01-08 09:29:56.022889: Epoch 220 
2025-01-08 09:29:56.027906: Current learning rate: 0.00148 
2025-01-08 09:30:35.718105: train_loss -0.9393 
2025-01-08 09:30:35.719108: val_loss -0.8922 
2025-01-08 09:30:35.724120: Pseudo dice [np.float32(0.9468)] 
2025-01-08 09:30:35.726631: Epoch time: 39.7 s 
2025-01-08 09:30:36.290393:  
2025-01-08 09:30:36.291392: Epoch 221 
2025-01-08 09:30:36.297009: Current learning rate: 0.00144 
2025-01-08 09:31:15.958939: train_loss -0.9369 
2025-01-08 09:31:15.959449: val_loss -0.9052 
2025-01-08 09:31:15.966030: Pseudo dice [np.float32(0.9556)] 
2025-01-08 09:31:15.969073: Epoch time: 39.67 s 
2025-01-08 09:31:15.971614: Yayy! New best EMA pseudo Dice: 0.9484000205993652 
2025-01-08 09:31:16.774780:  
2025-01-08 09:31:16.774780: Epoch 222 
2025-01-08 09:31:16.780856: Current learning rate: 0.00139 
2025-01-08 09:31:56.405337: train_loss -0.9309 
2025-01-08 09:31:56.406353: val_loss -0.921 
2025-01-08 09:31:56.411395: Pseudo dice [np.float32(0.9553)] 
2025-01-08 09:31:56.414921: Epoch time: 39.63 s 
2025-01-08 09:31:56.417990: Yayy! New best EMA pseudo Dice: 0.9491000175476074 
2025-01-08 09:31:57.186934:  
2025-01-08 09:31:57.187442: Epoch 223 
2025-01-08 09:31:57.192480: Current learning rate: 0.00135 
2025-01-08 09:32:36.839314: train_loss -0.94 
2025-01-08 09:32:36.840313: val_loss -0.912 
2025-01-08 09:32:36.845826: Pseudo dice [np.float32(0.9561)] 
2025-01-08 09:32:36.849336: Epoch time: 39.65 s 
2025-01-08 09:32:36.852347: Yayy! New best EMA pseudo Dice: 0.9498000144958496 
2025-01-08 09:32:37.777309:  
2025-01-08 09:32:37.777309: Epoch 224 
2025-01-08 09:32:37.782867: Current learning rate: 0.0013 
2025-01-08 09:33:17.433107: train_loss -0.9496 
2025-01-08 09:33:17.433610: val_loss -0.9298 
2025-01-08 09:33:17.438622: Pseudo dice [np.float32(0.9595)] 
2025-01-08 09:33:17.442132: Epoch time: 39.66 s 
2025-01-08 09:33:17.445637: Yayy! New best EMA pseudo Dice: 0.9506999850273132 
2025-01-08 09:33:18.203689:  
2025-01-08 09:33:18.203689: Epoch 225 
2025-01-08 09:33:18.209258: Current learning rate: 0.00126 
2025-01-08 09:33:57.832772: train_loss -0.9485 
2025-01-08 09:33:57.833275: val_loss -0.919 
2025-01-08 09:33:57.838839: Pseudo dice [np.float32(0.9586)] 
2025-01-08 09:33:57.841880: Epoch time: 39.63 s 
2025-01-08 09:33:57.844938: Yayy! New best EMA pseudo Dice: 0.9514999985694885 
2025-01-08 09:33:58.648801:  
2025-01-08 09:33:58.648801: Epoch 226 
2025-01-08 09:33:58.654814: Current learning rate: 0.00121 
2025-01-08 09:34:38.305535: train_loss -0.9516 
2025-01-08 09:34:38.306038: val_loss -0.9081 
2025-01-08 09:34:38.311598: Pseudo dice [np.float32(0.9534)] 
2025-01-08 09:34:38.314637: Epoch time: 39.66 s 
2025-01-08 09:34:38.318168: Yayy! New best EMA pseudo Dice: 0.95169997215271 
2025-01-08 09:34:39.081667:  
2025-01-08 09:34:39.082670: Epoch 227 
2025-01-08 09:34:39.087759: Current learning rate: 0.00117 
2025-01-08 09:35:18.740099: train_loss -0.9359 
2025-01-08 09:35:18.740099: val_loss -0.8644 
2025-01-08 09:35:18.746109: Pseudo dice [np.float32(0.947)] 
2025-01-08 09:35:18.749117: Epoch time: 39.66 s 
2025-01-08 09:35:19.310860:  
2025-01-08 09:35:19.311859: Epoch 228 
2025-01-08 09:35:19.316980: Current learning rate: 0.00112 
2025-01-08 09:35:58.991834: train_loss -0.9444 
2025-01-08 09:35:58.991834: val_loss -0.8165 
2025-01-08 09:35:58.997889: Pseudo dice [np.float32(0.9298)] 
2025-01-08 09:35:59.001420: Epoch time: 39.68 s 
2025-01-08 09:35:59.694436:  
2025-01-08 09:35:59.694436: Epoch 229 
2025-01-08 09:35:59.699420: Current learning rate: 0.00108 
2025-01-08 09:36:39.387874: train_loss -0.9423 
2025-01-08 09:36:39.388380: val_loss -0.8218 
2025-01-08 09:36:39.393933: Pseudo dice [np.float32(0.9197)] 
2025-01-08 09:36:39.397457: Epoch time: 39.69 s 
2025-01-08 09:36:39.960743:  
2025-01-08 09:36:39.960743: Epoch 230 
2025-01-08 09:36:39.965770: Current learning rate: 0.00103 
2025-01-08 09:37:19.640391: train_loss -0.9437 
2025-01-08 09:37:19.640391: val_loss -0.9244 
2025-01-08 09:37:19.646904: Pseudo dice [np.float32(0.9606)] 
2025-01-08 09:37:19.649922: Epoch time: 39.68 s 
2025-01-08 09:37:20.211505:  
2025-01-08 09:37:20.212008: Epoch 231 
2025-01-08 09:37:20.217020: Current learning rate: 0.00098 
2025-01-08 09:37:59.883331: train_loss -0.9337 
2025-01-08 09:37:59.883833: val_loss -0.8317 
2025-01-08 09:37:59.888844: Pseudo dice [np.float32(0.939)] 
2025-01-08 09:37:59.892353: Epoch time: 39.67 s 
2025-01-08 09:38:00.603109:  
2025-01-08 09:38:00.604109: Epoch 232 
2025-01-08 09:38:00.609701: Current learning rate: 0.00094 
2025-01-08 09:38:40.263055: train_loss -0.938 
2025-01-08 09:38:40.263055: val_loss -0.8355 
2025-01-08 09:38:40.269586: Pseudo dice [np.float32(0.9214)] 
2025-01-08 09:38:40.273098: Epoch time: 39.66 s 
2025-01-08 09:38:40.840467:  
2025-01-08 09:38:40.840467: Epoch 233 
2025-01-08 09:38:40.845507: Current learning rate: 0.00089 
2025-01-08 09:39:20.516015: train_loss -0.9456 
2025-01-08 09:39:20.516522: val_loss -0.8565 
2025-01-08 09:39:20.522554: Pseudo dice [np.float32(0.9432)] 
2025-01-08 09:39:20.525571: Epoch time: 39.68 s 
2025-01-08 09:39:21.088216:  
2025-01-08 09:39:21.089216: Epoch 234 
2025-01-08 09:39:21.093774: Current learning rate: 0.00084 
2025-01-08 09:40:00.733086: train_loss -0.9417 
2025-01-08 09:40:00.734090: val_loss -0.8015 
2025-01-08 09:40:00.739658: Pseudo dice [np.float32(0.9233)] 
2025-01-08 09:40:00.742684: Epoch time: 39.64 s 
2025-01-08 09:40:01.299206:  
2025-01-08 09:40:01.300209: Epoch 235 
2025-01-08 09:40:01.305244: Current learning rate: 0.00079 
2025-01-08 09:40:40.954268: train_loss -0.9516 
2025-01-08 09:40:40.955775: val_loss -0.9123 
2025-01-08 09:40:40.961330: Pseudo dice [np.float32(0.9547)] 
2025-01-08 09:40:40.964390: Epoch time: 39.66 s 
2025-01-08 09:40:41.524082:  
2025-01-08 09:40:41.525085: Epoch 236 
2025-01-08 09:40:41.529661: Current learning rate: 0.00075 
2025-01-08 09:41:21.127693: train_loss -0.9458 
2025-01-08 09:41:21.128202: val_loss -0.8799 
2025-01-08 09:41:21.134257: Pseudo dice [np.float32(0.9506)] 
2025-01-08 09:41:21.137307: Epoch time: 39.6 s 
2025-01-08 09:41:21.695558:  
2025-01-08 09:41:21.696558: Epoch 237 
2025-01-08 09:41:21.702148: Current learning rate: 0.0007 
2025-01-08 09:42:01.359573: train_loss -0.9495 
2025-01-08 09:42:01.360079: val_loss -0.8638 
2025-01-08 09:42:01.366134: Pseudo dice [np.float32(0.9284)] 
2025-01-08 09:42:01.369165: Epoch time: 39.66 s 
2025-01-08 09:42:01.925962:  
2025-01-08 09:42:01.925962: Epoch 238 
2025-01-08 09:42:01.930973: Current learning rate: 0.00065 
2025-01-08 09:42:41.567390: train_loss -0.9456 
2025-01-08 09:42:41.568393: val_loss -0.903 
2025-01-08 09:42:41.574404: Pseudo dice [np.float32(0.9562)] 
2025-01-08 09:42:41.577412: Epoch time: 39.64 s 
2025-01-08 09:42:42.138932:  
2025-01-08 09:42:42.138932: Epoch 239 
2025-01-08 09:42:42.143943: Current learning rate: 0.0006 
2025-01-08 09:43:21.752663: train_loss -0.9502 
2025-01-08 09:43:21.754167: val_loss -0.9019 
2025-01-08 09:43:21.759178: Pseudo dice [np.float32(0.9392)] 
2025-01-08 09:43:21.762686: Epoch time: 39.62 s 
2025-01-08 09:43:22.335714:  
2025-01-08 09:43:22.336216: Epoch 240 
2025-01-08 09:43:22.341226: Current learning rate: 0.00055 
2025-01-08 09:44:01.974286: train_loss -0.9518 
2025-01-08 09:44:01.975787: val_loss -0.9218 
2025-01-08 09:44:01.980798: Pseudo dice [np.float32(0.96)] 
2025-01-08 09:44:01.984306: Epoch time: 39.64 s 
2025-01-08 09:44:02.710501:  
2025-01-08 09:44:02.711504: Epoch 241 
2025-01-08 09:44:02.716576: Current learning rate: 0.0005 
2025-01-08 09:44:42.354163: train_loss -0.9495 
2025-01-08 09:44:42.354671: val_loss -0.9072 
2025-01-08 09:44:42.359703: Pseudo dice [np.float32(0.9536)] 
2025-01-08 09:44:42.363726: Epoch time: 39.64 s 
2025-01-08 09:44:42.937400:  
2025-01-08 09:44:42.937400: Epoch 242 
2025-01-08 09:44:42.942935: Current learning rate: 0.00045 
2025-01-08 09:45:22.572543: train_loss -0.9516 
2025-01-08 09:45:22.572543: val_loss -0.8771 
2025-01-08 09:45:22.578647: Pseudo dice [np.float32(0.9466)] 
2025-01-08 09:45:22.582656: Epoch time: 39.64 s 
2025-01-08 09:45:23.156765:  
2025-01-08 09:45:23.157268: Epoch 243 
2025-01-08 09:45:23.162278: Current learning rate: 0.0004 
2025-01-08 09:46:02.804938: train_loss -0.9485 
2025-01-08 09:46:02.804938: val_loss -0.8977 
2025-01-08 09:46:02.810505: Pseudo dice [np.float32(0.9539)] 
2025-01-08 09:46:02.814558: Epoch time: 39.65 s 
2025-01-08 09:46:03.393662:  
2025-01-08 09:46:03.393662: Epoch 244 
2025-01-08 09:46:03.397689: Current learning rate: 0.00035 
2025-01-08 09:46:43.025977: train_loss -0.9481 
2025-01-08 09:46:43.025977: val_loss -0.9064 
2025-01-08 09:46:43.031990: Pseudo dice [np.float32(0.9515)] 
2025-01-08 09:46:43.034998: Epoch time: 39.63 s 
2025-01-08 09:46:43.609764:  
2025-01-08 09:46:43.610768: Epoch 245 
2025-01-08 09:46:43.616296: Current learning rate: 0.0003 
2025-01-08 09:47:23.252509: train_loss -0.9465 
2025-01-08 09:47:23.253512: val_loss -0.8414 
2025-01-08 09:47:23.259526: Pseudo dice [np.float32(0.9255)] 
2025-01-08 09:47:23.262533: Epoch time: 39.64 s 
2025-01-08 09:47:23.838420:  
2025-01-08 09:47:23.839423: Epoch 246 
2025-01-08 09:47:23.844438: Current learning rate: 0.00024 
2025-01-08 09:48:03.461506: train_loss -0.9476 
2025-01-08 09:48:03.462029: val_loss -0.8634 
2025-01-08 09:48:03.467620: Pseudo dice [np.float32(0.9398)] 
2025-01-08 09:48:03.471153: Epoch time: 39.62 s 
2025-01-08 09:48:04.039515:  
2025-01-08 09:48:04.040518: Epoch 247 
2025-01-08 09:48:04.045598: Current learning rate: 0.00019 
2025-01-08 09:48:43.662819: train_loss -0.9495 
2025-01-08 09:48:43.663819: val_loss -0.8693 
2025-01-08 09:48:43.668830: Pseudo dice [np.float32(0.9419)] 
2025-01-08 09:48:43.671837: Epoch time: 39.62 s 
2025-01-08 09:48:44.247644:  
2025-01-08 09:48:44.247644: Epoch 248 
2025-01-08 09:48:44.252657: Current learning rate: 0.00013 
2025-01-08 09:49:23.883376: train_loss -0.944 
2025-01-08 09:49:23.884380: val_loss -0.9154 
2025-01-08 09:49:23.890390: Pseudo dice [np.float32(0.958)] 
2025-01-08 09:49:23.893398: Epoch time: 39.64 s 
2025-01-08 09:49:24.610108:  
2025-01-08 09:49:24.611111: Epoch 249 
2025-01-08 09:49:24.615637: Current learning rate: 7e-05 
2025-01-08 09:50:04.237359: train_loss -0.9488 
2025-01-08 09:50:04.237883: val_loss -0.8744 
2025-01-08 09:50:04.242921: Pseudo dice [np.float32(0.9423)] 
2025-01-08 09:50:04.246461: Epoch time: 39.63 s 
2025-01-08 09:50:05.027169: Training done. 
2025-01-08 09:50:05.061679: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset009_Spleen\splits_final.json 
2025-01-08 09:50:05.072680: The split file contains 5 splits. 
2025-01-08 09:50:05.077679: Desired fold for training: 0 
2025-01-08 09:50:05.084679: This split has 32 training and 9 validation cases. 
2025-01-08 09:50:05.090679: predicting spleen_10 
2025-01-08 09:50:05.096679: spleen_10, shape torch.Size([1, 275, 500, 500]), rank 0 
2025-01-08 09:50:35.249424: predicting spleen_13 
2025-01-08 09:50:35.276931: spleen_13, shape torch.Size([1, 192, 380, 380]), rank 0 
2025-01-08 09:50:45.747652: predicting spleen_14 
2025-01-08 09:50:45.759655: spleen_14, shape torch.Size([1, 270, 436, 436]), rank 0 
2025-01-08 09:51:06.732148: predicting spleen_17 
2025-01-08 09:51:06.753149: spleen_17, shape torch.Size([1, 238, 314, 314]), rank 0 
2025-01-08 09:51:15.166654: predicting spleen_31 
2025-01-08 09:51:15.176656: spleen_31, shape torch.Size([1, 280, 379, 379]), rank 0 
2025-01-08 09:51:29.169508: predicting spleen_33 
2025-01-08 09:51:29.186512: spleen_33, shape torch.Size([1, 415, 473, 473]), rank 0 
2025-01-08 09:52:11.872288: predicting spleen_44 
2025-01-08 09:52:11.909287: spleen_44, shape torch.Size([1, 460, 446, 446]), rank 0 
2025-01-08 09:52:53.749606: predicting spleen_47 
2025-01-08 09:52:53.785695: spleen_47, shape torch.Size([1, 440, 402, 402]), rank 0 
2025-01-08 09:53:30.494018: predicting spleen_56 
2025-01-08 09:53:30.522018: spleen_56, shape torch.Size([1, 231, 358, 358]), rank 0 
2025-01-08 09:53:50.861829: Validation complete 
2025-01-08 09:53:50.861829: Mean Validation Dice:  0.9329784412812879 
