
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-08 12:39:40.617680: do_dummy_2d_data_aug: False 
2025-01-08 12:39:40.624776: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset009_Spleen\splits_final.json 
2025-01-08 12:39:40.627399: The split file contains 5 splits. 
2025-01-08 12:39:40.630400: Desired fold for training: 0 
2025-01-08 12:39:40.632400: This split has 32 training and 9 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_avg_spacing1_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 160, 128], 'median_image_size_in_voxels': [300.0, 406.0, 406.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset009_Spleen', 'plans_name': 'nnUNetPlans_avg_spacing1', 'original_median_spacing_after_transp': [5.0, 0.7929689884185791, 0.7929689884185791], 'original_median_shape_after_transp': [90, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1038.0, 'mean': 93.19259643554688, 'median': 97.0, 'min': -620.0, 'percentile_00_5': -42.0, 'percentile_99_5': 176.0, 'std': 40.78370666503906}}} 
 
2025-01-08 12:39:48.973139: unpacking dataset... 
2025-01-08 12:39:49.153738: unpacking done... 
2025-01-08 12:39:52.196839:  
2025-01-08 12:39:52.196839: Epoch 0 
2025-01-08 12:39:52.201858: Current learning rate: 0.01 
2025-01-08 12:40:36.131723: train_loss -0.1965 
2025-01-08 12:40:36.132728: val_loss -0.2949 
2025-01-08 12:40:36.137776: Pseudo dice [np.float32(0.5252)] 
2025-01-08 12:40:36.141870: Epoch time: 43.94 s 
2025-01-08 12:40:36.144419: Yayy! New best EMA pseudo Dice: 0.5252000093460083 
2025-01-08 12:40:36.846842:  
2025-01-08 12:40:36.847359: Epoch 1 
2025-01-08 12:40:36.852371: Current learning rate: 0.00991 
2025-01-08 12:41:16.559859: train_loss -0.4249 
2025-01-08 12:41:16.560377: val_loss -0.4825 
2025-01-08 12:41:16.566447: Pseudo dice [np.float32(0.683)] 
2025-01-08 12:41:16.568956: Epoch time: 39.71 s 
2025-01-08 12:41:16.571467: Yayy! New best EMA pseudo Dice: 0.5410000085830688 
2025-01-08 12:41:17.359926:  
2025-01-08 12:41:17.359926: Epoch 2 
2025-01-08 12:41:17.364942: Current learning rate: 0.00982 
2025-01-08 12:41:57.046494: train_loss -0.5332 
2025-01-08 12:41:57.047498: val_loss -0.4133 
2025-01-08 12:41:57.054076: Pseudo dice [np.float32(0.6326)] 
2025-01-08 12:41:57.057120: Epoch time: 39.69 s 
2025-01-08 12:41:57.060647: Yayy! New best EMA pseudo Dice: 0.5501999855041504 
2025-01-08 12:41:57.890035:  
2025-01-08 12:41:57.890546: Epoch 3 
2025-01-08 12:41:57.896109: Current learning rate: 0.00973 
2025-01-08 12:42:37.574487: train_loss -0.5393 
2025-01-08 12:42:37.574990: val_loss -0.5487 
2025-01-08 12:42:37.580000: Pseudo dice [np.float32(0.7087)] 
2025-01-08 12:42:37.584052: Epoch time: 39.68 s 
2025-01-08 12:42:37.585584: Yayy! New best EMA pseudo Dice: 0.5659999847412109 
2025-01-08 12:42:38.397791:  
2025-01-08 12:42:38.397791: Epoch 4 
2025-01-08 12:42:38.402363: Current learning rate: 0.00964 
2025-01-08 12:43:18.038313: train_loss -0.6079 
2025-01-08 12:43:18.038313: val_loss -0.5855 
2025-01-08 12:43:18.044850: Pseudo dice [np.float32(0.7222)] 
2025-01-08 12:43:18.048589: Epoch time: 39.64 s 
2025-01-08 12:43:18.051635: Yayy! New best EMA pseudo Dice: 0.58160001039505 
2025-01-08 12:43:18.959943:  
2025-01-08 12:43:18.960941: Epoch 5 
2025-01-08 12:43:18.966529: Current learning rate: 0.00955 
2025-01-08 12:43:58.578388: train_loss -0.6836 
2025-01-08 12:43:58.578899: val_loss -0.6254 
2025-01-08 12:43:58.584993: Pseudo dice [np.float32(0.7971)] 
2025-01-08 12:43:58.588042: Epoch time: 39.62 s 
2025-01-08 12:43:58.590562: Yayy! New best EMA pseudo Dice: 0.6032000184059143 
2025-01-08 12:43:59.389041:  
2025-01-08 12:43:59.390044: Epoch 6 
2025-01-08 12:43:59.394598: Current learning rate: 0.00946 
2025-01-08 12:44:39.017277: train_loss -0.6763 
2025-01-08 12:44:39.018779: val_loss -0.4269 
2025-01-08 12:44:39.023789: Pseudo dice [np.float32(0.5648)] 
2025-01-08 12:44:39.027299: Epoch time: 39.63 s 
2025-01-08 12:44:39.589980:  
2025-01-08 12:44:39.589980: Epoch 7 
2025-01-08 12:44:39.594990: Current learning rate: 0.00937 
2025-01-08 12:45:19.215391: train_loss -0.7223 
2025-01-08 12:45:19.216394: val_loss -0.7261 
2025-01-08 12:45:19.222405: Pseudo dice [np.float32(0.8274)] 
2025-01-08 12:45:19.225414: Epoch time: 39.63 s 
2025-01-08 12:45:19.227920: Yayy! New best EMA pseudo Dice: 0.6222000122070312 
2025-01-08 12:45:20.018262:  
2025-01-08 12:45:20.018262: Epoch 8 
2025-01-08 12:45:20.023276: Current learning rate: 0.00928 
2025-01-08 12:45:59.674628: train_loss -0.6801 
2025-01-08 12:45:59.676139: val_loss -0.5313 
2025-01-08 12:45:59.681690: Pseudo dice [np.float32(0.7312)] 
2025-01-08 12:45:59.684703: Epoch time: 39.66 s 
2025-01-08 12:45:59.688212: Yayy! New best EMA pseudo Dice: 0.6330999732017517 
2025-01-08 12:46:00.519631:  
2025-01-08 12:46:00.520133: Epoch 9 
2025-01-08 12:46:00.525147: Current learning rate: 0.00919 
2025-01-08 12:46:40.115124: train_loss -0.6196 
2025-01-08 12:46:40.116129: val_loss -0.6457 
2025-01-08 12:46:40.121174: Pseudo dice [np.float32(0.7659)] 
2025-01-08 12:46:40.125186: Epoch time: 39.6 s 
2025-01-08 12:46:40.127695: Yayy! New best EMA pseudo Dice: 0.6463000178337097 
2025-01-08 12:46:40.920553:  
2025-01-08 12:46:40.920553: Epoch 10 
2025-01-08 12:46:40.927153: Current learning rate: 0.0091 
2025-01-08 12:47:20.555928: train_loss -0.7026 
2025-01-08 12:47:20.556432: val_loss -0.6891 
2025-01-08 12:47:20.562552: Pseudo dice [np.float32(0.814)] 
2025-01-08 12:47:20.566073: Epoch time: 39.64 s 
2025-01-08 12:47:20.569093: Yayy! New best EMA pseudo Dice: 0.663100004196167 
2025-01-08 12:47:21.362252:  
2025-01-08 12:47:21.362252: Epoch 11 
2025-01-08 12:47:21.367797: Current learning rate: 0.009 
2025-01-08 12:48:00.974697: train_loss -0.731 
2025-01-08 12:48:00.974697: val_loss -0.6867 
2025-01-08 12:48:00.980753: Pseudo dice [np.float32(0.8216)] 
2025-01-08 12:48:00.982790: Epoch time: 39.61 s 
2025-01-08 12:48:00.985818: Yayy! New best EMA pseudo Dice: 0.6790000200271606 
2025-01-08 12:48:01.781666:  
2025-01-08 12:48:01.782168: Epoch 12 
2025-01-08 12:48:01.787183: Current learning rate: 0.00891 
2025-01-08 12:48:41.396002: train_loss -0.765 
2025-01-08 12:48:41.397003: val_loss -0.6288 
2025-01-08 12:48:41.402522: Pseudo dice [np.float32(0.7874)] 
2025-01-08 12:48:41.406032: Epoch time: 39.62 s 
2025-01-08 12:48:41.409540: Yayy! New best EMA pseudo Dice: 0.6898000240325928 
2025-01-08 12:48:42.341004:  
2025-01-08 12:48:42.341004: Epoch 13 
2025-01-08 12:48:42.347021: Current learning rate: 0.00882 
2025-01-08 12:49:21.942154: train_loss -0.6896 
2025-01-08 12:49:21.943154: val_loss -0.7107 
2025-01-08 12:49:21.948668: Pseudo dice [np.float32(0.8455)] 
2025-01-08 12:49:21.951192: Epoch time: 39.6 s 
2025-01-08 12:49:21.954230: Yayy! New best EMA pseudo Dice: 0.7053999900817871 
2025-01-08 12:49:22.765712:  
2025-01-08 12:49:22.766715: Epoch 14 
2025-01-08 12:49:22.771271: Current learning rate: 0.00873 
2025-01-08 12:50:02.379694: train_loss -0.7599 
2025-01-08 12:50:02.380697: val_loss -0.7867 
2025-01-08 12:50:02.387211: Pseudo dice [np.float32(0.8869)] 
2025-01-08 12:50:02.390802: Epoch time: 39.61 s 
2025-01-08 12:50:02.394307: Yayy! New best EMA pseudo Dice: 0.7235000133514404 
2025-01-08 12:50:03.225701:  
2025-01-08 12:50:03.225701: Epoch 15 
2025-01-08 12:50:03.231256: Current learning rate: 0.00864 
2025-01-08 12:50:42.851276: train_loss -0.8216 
2025-01-08 12:50:42.852277: val_loss -0.7605 
2025-01-08 12:50:42.857794: Pseudo dice [np.float32(0.8699)] 
2025-01-08 12:50:42.860301: Epoch time: 39.63 s 
2025-01-08 12:50:42.863811: Yayy! New best EMA pseudo Dice: 0.7382000088691711 
2025-01-08 12:50:43.682094:  
2025-01-08 12:50:43.683098: Epoch 16 
2025-01-08 12:50:43.688201: Current learning rate: 0.00855 
2025-01-08 12:51:23.356703: train_loss -0.8064 
2025-01-08 12:51:23.357708: val_loss -0.7124 
2025-01-08 12:51:23.364269: Pseudo dice [np.float32(0.8447)] 
2025-01-08 12:51:23.366777: Epoch time: 39.67 s 
2025-01-08 12:51:23.370286: Yayy! New best EMA pseudo Dice: 0.7487999796867371 
2025-01-08 12:51:24.167207:  
2025-01-08 12:51:24.167207: Epoch 17 
2025-01-08 12:51:24.172219: Current learning rate: 0.00846 
2025-01-08 12:52:03.782821: train_loss -0.8195 
2025-01-08 12:52:03.783331: val_loss -0.7608 
2025-01-08 12:52:03.790967: Pseudo dice [np.float32(0.8509)] 
2025-01-08 12:52:03.795560: Epoch time: 39.62 s 
2025-01-08 12:52:03.798623: Yayy! New best EMA pseudo Dice: 0.7590000033378601 
2025-01-08 12:52:04.619790:  
2025-01-08 12:52:04.619790: Epoch 18 
2025-01-08 12:52:04.625373: Current learning rate: 0.00836 
2025-01-08 12:52:44.240840: train_loss -0.7852 
2025-01-08 12:52:44.240840: val_loss -0.8072 
2025-01-08 12:52:44.247356: Pseudo dice [np.float32(0.8862)] 
2025-01-08 12:52:44.249862: Epoch time: 39.62 s 
2025-01-08 12:52:44.253371: Yayy! New best EMA pseudo Dice: 0.7717000246047974 
2025-01-08 12:52:45.073045:  
2025-01-08 12:52:45.074048: Epoch 19 
2025-01-08 12:52:45.079080: Current learning rate: 0.00827 
2025-01-08 12:53:24.719303: train_loss -0.7923 
2025-01-08 12:53:24.719806: val_loss -0.2713 
2025-01-08 12:53:24.725954: Pseudo dice [np.float32(0.6199)] 
2025-01-08 12:53:24.728991: Epoch time: 39.65 s 
2025-01-08 12:53:25.453025:  
2025-01-08 12:53:25.453528: Epoch 20 
2025-01-08 12:53:25.458582: Current learning rate: 0.00818 
2025-01-08 12:54:05.018739: train_loss -0.7932 
2025-01-08 12:54:05.018739: val_loss -0.7561 
2025-01-08 12:54:05.025254: Pseudo dice [np.float32(0.8489)] 
2025-01-08 12:54:05.028762: Epoch time: 39.57 s 
2025-01-08 12:54:05.619905:  
2025-01-08 12:54:05.619905: Epoch 21 
2025-01-08 12:54:05.625943: Current learning rate: 0.00809 
2025-01-08 12:54:45.247641: train_loss -0.856 
2025-01-08 12:54:45.247641: val_loss -0.7428 
2025-01-08 12:54:45.252652: Pseudo dice [np.float32(0.8513)] 
2025-01-08 12:54:45.256161: Epoch time: 39.63 s 
2025-01-08 12:54:45.259666: Yayy! New best EMA pseudo Dice: 0.7742999792098999 
2025-01-08 12:54:46.020900:  
2025-01-08 12:54:46.021903: Epoch 22 
2025-01-08 12:54:46.026936: Current learning rate: 0.008 
2025-01-08 12:55:25.683342: train_loss -0.8274 
2025-01-08 12:55:25.683845: val_loss -0.777 
2025-01-08 12:55:25.689859: Pseudo dice [np.float32(0.889)] 
2025-01-08 12:55:25.692365: Epoch time: 39.66 s 
2025-01-08 12:55:25.695870: Yayy! New best EMA pseudo Dice: 0.7857999801635742 
2025-01-08 12:55:26.496689:  
2025-01-08 12:55:26.496689: Epoch 23 
2025-01-08 12:55:26.502711: Current learning rate: 0.0079 
2025-01-08 12:56:06.115965: train_loss -0.8117 
2025-01-08 12:56:06.116965: val_loss -0.7976 
2025-01-08 12:56:06.122480: Pseudo dice [np.float32(0.8942)] 
2025-01-08 12:56:06.125989: Epoch time: 39.62 s 
2025-01-08 12:56:06.128495: Yayy! New best EMA pseudo Dice: 0.7965999841690063 
2025-01-08 12:56:06.923623:  
2025-01-08 12:56:06.923623: Epoch 24 
2025-01-08 12:56:06.929656: Current learning rate: 0.00781 
2025-01-08 12:56:46.551958: train_loss -0.8542 
2025-01-08 12:56:46.551958: val_loss -0.663 
2025-01-08 12:56:46.558471: Pseudo dice [np.float32(0.8086)] 
2025-01-08 12:56:46.560977: Epoch time: 39.63 s 
2025-01-08 12:56:46.564016: Yayy! New best EMA pseudo Dice: 0.7978000044822693 
2025-01-08 12:56:47.330838:  
2025-01-08 12:56:47.330838: Epoch 25 
2025-01-08 12:56:47.336900: Current learning rate: 0.00772 
2025-01-08 12:57:26.973781: train_loss -0.8566 
2025-01-08 12:57:26.974289: val_loss -0.7346 
2025-01-08 12:57:26.980362: Pseudo dice [np.float32(0.8708)] 
2025-01-08 12:57:26.983917: Epoch time: 39.64 s 
2025-01-08 12:57:26.986939: Yayy! New best EMA pseudo Dice: 0.8051000237464905 
2025-01-08 12:57:27.747632:  
2025-01-08 12:57:27.747632: Epoch 26 
2025-01-08 12:57:27.753171: Current learning rate: 0.00763 
2025-01-08 12:58:07.334836: train_loss -0.8504 
2025-01-08 12:58:07.335338: val_loss -0.8038 
2025-01-08 12:58:07.341352: Pseudo dice [np.float32(0.9061)] 
2025-01-08 12:58:07.344858: Epoch time: 39.59 s 
2025-01-08 12:58:07.348376: Yayy! New best EMA pseudo Dice: 0.8151999711990356 
2025-01-08 12:58:08.148519:  
2025-01-08 12:58:08.149522: Epoch 27 
2025-01-08 12:58:08.154599: Current learning rate: 0.00753 
2025-01-08 12:58:47.791334: train_loss -0.8015 
2025-01-08 12:58:47.791836: val_loss -0.7298 
2025-01-08 12:58:47.797931: Pseudo dice [np.float32(0.8416)] 
2025-01-08 12:58:47.800968: Epoch time: 39.64 s 
2025-01-08 12:58:47.802987: Yayy! New best EMA pseudo Dice: 0.8179000020027161 
2025-01-08 12:58:48.764812:  
2025-01-08 12:58:48.764812: Epoch 28 
2025-01-08 12:58:48.770954: Current learning rate: 0.00744 
2025-01-08 12:59:28.364789: train_loss -0.8408 
2025-01-08 12:59:28.365792: val_loss -0.7661 
2025-01-08 12:59:28.372311: Pseudo dice [np.float32(0.8821)] 
2025-01-08 12:59:28.374857: Epoch time: 39.6 s 
2025-01-08 12:59:28.378366: Yayy! New best EMA pseudo Dice: 0.8242999911308289 
2025-01-08 12:59:29.173427:  
2025-01-08 12:59:29.174938: Epoch 29 
2025-01-08 12:59:29.180031: Current learning rate: 0.00735 
2025-01-08 13:00:08.801569: train_loss -0.8547 
2025-01-08 13:00:08.802075: val_loss -0.6297 
2025-01-08 13:00:08.807617: Pseudo dice [np.float32(0.7731)] 
2025-01-08 13:00:08.811123: Epoch time: 39.63 s 
2025-01-08 13:00:09.377371:  
2025-01-08 13:00:09.378371: Epoch 30 
2025-01-08 13:00:09.383418: Current learning rate: 0.00725 
2025-01-08 13:00:48.980062: train_loss -0.8474 
2025-01-08 13:00:48.980062: val_loss -0.6034 
2025-01-08 13:00:48.986076: Pseudo dice [np.float32(0.8189)] 
2025-01-08 13:00:48.989088: Epoch time: 39.6 s 
2025-01-08 13:00:49.561678:  
2025-01-08 13:00:49.561678: Epoch 31 
2025-01-08 13:00:49.566692: Current learning rate: 0.00716 
2025-01-08 13:01:29.148998: train_loss -0.8674 
2025-01-08 13:01:29.150003: val_loss -0.809 
2025-01-08 13:01:29.156517: Pseudo dice [np.float32(0.9045)] 
2025-01-08 13:01:29.159024: Epoch time: 39.59 s 
2025-01-08 13:01:29.162535: Yayy! New best EMA pseudo Dice: 0.8277000188827515 
2025-01-08 13:01:29.978800:  
2025-01-08 13:01:29.979306: Epoch 32 
2025-01-08 13:01:29.984351: Current learning rate: 0.00707 
2025-01-08 13:02:09.584607: train_loss -0.8527 
2025-01-08 13:02:09.584607: val_loss -0.8076 
2025-01-08 13:02:09.591192: Pseudo dice [np.float32(0.8787)] 
2025-01-08 13:02:09.594811: Epoch time: 39.61 s 
2025-01-08 13:02:09.597344: Yayy! New best EMA pseudo Dice: 0.8327999711036682 
2025-01-08 13:02:10.423726:  
2025-01-08 13:02:10.424731: Epoch 33 
2025-01-08 13:02:10.429325: Current learning rate: 0.00697 
2025-01-08 13:02:50.025306: train_loss -0.8619 
2025-01-08 13:02:50.026312: val_loss -0.8312 
2025-01-08 13:02:50.032324: Pseudo dice [np.float32(0.9038)] 
2025-01-08 13:02:50.035334: Epoch time: 39.6 s 
2025-01-08 13:02:50.038850: Yayy! New best EMA pseudo Dice: 0.839900016784668 
2025-01-08 13:02:50.830061:  
2025-01-08 13:02:50.830564: Epoch 34 
2025-01-08 13:02:50.835107: Current learning rate: 0.00688 
2025-01-08 13:03:30.415401: train_loss -0.8256 
2025-01-08 13:03:30.416406: val_loss -0.5831 
2025-01-08 13:03:30.421420: Pseudo dice [np.float32(0.7947)] 
2025-01-08 13:03:30.425431: Epoch time: 39.59 s 
2025-01-08 13:03:31.157321:  
2025-01-08 13:03:31.158322: Epoch 35 
2025-01-08 13:03:31.163337: Current learning rate: 0.00679 
2025-01-08 13:04:10.755798: train_loss -0.8382 
2025-01-08 13:04:10.756803: val_loss -0.7195 
2025-01-08 13:04:10.761824: Pseudo dice [np.float32(0.8824)] 
2025-01-08 13:04:10.765840: Epoch time: 39.6 s 
2025-01-08 13:04:10.768873: Yayy! New best EMA pseudo Dice: 0.8400999903678894 
2025-01-08 13:04:11.608013:  
2025-01-08 13:04:11.609019: Epoch 36 
2025-01-08 13:04:11.613576: Current learning rate: 0.00669 
2025-01-08 13:04:51.219144: train_loss -0.8891 
2025-01-08 13:04:51.220147: val_loss -0.855 
2025-01-08 13:04:51.225158: Pseudo dice [np.float32(0.9211)] 
2025-01-08 13:04:51.229166: Epoch time: 39.61 s 
2025-01-08 13:04:51.231671: Yayy! New best EMA pseudo Dice: 0.8482000231742859 
2025-01-08 13:04:52.059508:  
2025-01-08 13:04:52.059508: Epoch 37 
2025-01-08 13:04:52.065563: Current learning rate: 0.0066 
2025-01-08 13:05:31.675495: train_loss -0.8712 
2025-01-08 13:05:31.676499: val_loss -0.8186 
2025-01-08 13:05:31.682015: Pseudo dice [np.float32(0.898)] 
2025-01-08 13:05:31.685049: Epoch time: 39.62 s 
2025-01-08 13:05:31.688113: Yayy! New best EMA pseudo Dice: 0.8532000184059143 
2025-01-08 13:05:32.485611:  
2025-01-08 13:05:32.485611: Epoch 38 
2025-01-08 13:05:32.491624: Current learning rate: 0.0065 
2025-01-08 13:06:12.067878: train_loss -0.8711 
2025-01-08 13:06:12.068382: val_loss -0.8131 
2025-01-08 13:06:12.073926: Pseudo dice [np.float32(0.9078)] 
2025-01-08 13:06:12.076961: Epoch time: 39.58 s 
2025-01-08 13:06:12.079483: Yayy! New best EMA pseudo Dice: 0.8586000204086304 
2025-01-08 13:06:12.865414:  
2025-01-08 13:06:12.866917: Epoch 39 
2025-01-08 13:06:12.871518: Current learning rate: 0.00641 
2025-01-08 13:06:52.491685: train_loss -0.8805 
2025-01-08 13:06:52.492199: val_loss -0.8306 
2025-01-08 13:06:52.497246: Pseudo dice [np.float32(0.9147)] 
2025-01-08 13:06:52.501274: Epoch time: 39.63 s 
2025-01-08 13:06:52.504302: Yayy! New best EMA pseudo Dice: 0.8641999959945679 
2025-01-08 13:06:53.344224:  
2025-01-08 13:06:53.345227: Epoch 40 
2025-01-08 13:06:53.350261: Current learning rate: 0.00631 
2025-01-08 13:07:32.959697: train_loss -0.862 
2025-01-08 13:07:32.959697: val_loss -0.7905 
2025-01-08 13:07:32.966759: Pseudo dice [np.float32(0.8774)] 
2025-01-08 13:07:32.969800: Epoch time: 39.62 s 
2025-01-08 13:07:32.972858: Yayy! New best EMA pseudo Dice: 0.8654999732971191 
2025-01-08 13:07:33.783028:  
2025-01-08 13:07:33.784033: Epoch 41 
2025-01-08 13:07:33.788600: Current learning rate: 0.00622 
2025-01-08 13:08:13.372662: train_loss -0.8845 
2025-01-08 13:08:13.373662: val_loss -0.8733 
2025-01-08 13:08:13.379176: Pseudo dice [np.float32(0.9282)] 
2025-01-08 13:08:13.382684: Epoch time: 39.59 s 
2025-01-08 13:08:13.385190: Yayy! New best EMA pseudo Dice: 0.8718000054359436 
2025-01-08 13:08:14.191959:  
2025-01-08 13:08:14.191959: Epoch 42 
2025-01-08 13:08:14.196985: Current learning rate: 0.00612 
2025-01-08 13:08:53.817822: train_loss -0.8839 
2025-01-08 13:08:53.818825: val_loss -0.8192 
2025-01-08 13:08:53.824339: Pseudo dice [np.float32(0.9132)] 
2025-01-08 13:08:53.827890: Epoch time: 39.63 s 
2025-01-08 13:08:53.830413: Yayy! New best EMA pseudo Dice: 0.8758999705314636 
2025-01-08 13:08:54.804810:  
2025-01-08 13:08:54.805370: Epoch 43 
2025-01-08 13:08:54.809899: Current learning rate: 0.00603 
2025-01-08 13:09:34.438993: train_loss -0.8659 
2025-01-08 13:09:34.439496: val_loss -0.8541 
2025-01-08 13:09:34.445521: Pseudo dice [np.float32(0.929)] 
2025-01-08 13:09:34.448035: Epoch time: 39.63 s 
2025-01-08 13:09:34.451553: Yayy! New best EMA pseudo Dice: 0.8812999725341797 
2025-01-08 13:09:35.255943:  
2025-01-08 13:09:35.255943: Epoch 44 
2025-01-08 13:09:35.260976: Current learning rate: 0.00593 
2025-01-08 13:10:14.878547: train_loss -0.8781 
2025-01-08 13:10:14.878547: val_loss -0.8922 
2025-01-08 13:10:14.884561: Pseudo dice [np.float32(0.9454)] 
2025-01-08 13:10:14.888067: Epoch time: 39.62 s 
2025-01-08 13:10:14.891076: Yayy! New best EMA pseudo Dice: 0.8877000212669373 
2025-01-08 13:10:15.692201:  
2025-01-08 13:10:15.692201: Epoch 45 
2025-01-08 13:10:15.697241: Current learning rate: 0.00584 
2025-01-08 13:10:55.308272: train_loss -0.8588 
2025-01-08 13:10:55.308779: val_loss -0.8263 
2025-01-08 13:10:55.314334: Pseudo dice [np.float32(0.9103)] 
2025-01-08 13:10:55.317858: Epoch time: 39.62 s 
2025-01-08 13:10:55.320886: Yayy! New best EMA pseudo Dice: 0.8899000287055969 
2025-01-08 13:10:56.072528:  
2025-01-08 13:10:56.072528: Epoch 46 
2025-01-08 13:10:56.078081: Current learning rate: 0.00574 
2025-01-08 13:11:35.689278: train_loss -0.8582 
2025-01-08 13:11:35.690282: val_loss -0.8632 
2025-01-08 13:11:35.695344: Pseudo dice [np.float32(0.9227)] 
2025-01-08 13:11:35.698870: Epoch time: 39.62 s 
2025-01-08 13:11:35.701946: Yayy! New best EMA pseudo Dice: 0.8931999802589417 
2025-01-08 13:11:36.451442:  
2025-01-08 13:11:36.452445: Epoch 47 
2025-01-08 13:11:36.456978: Current learning rate: 0.00565 
2025-01-08 13:12:16.077962: train_loss -0.8629 
2025-01-08 13:12:16.077962: val_loss -0.8289 
2025-01-08 13:12:16.083979: Pseudo dice [np.float32(0.8995)] 
2025-01-08 13:12:16.086485: Epoch time: 39.63 s 
2025-01-08 13:12:16.089990: Yayy! New best EMA pseudo Dice: 0.8938000202178955 
2025-01-08 13:12:16.888322:  
2025-01-08 13:12:16.888322: Epoch 48 
2025-01-08 13:12:16.893913: Current learning rate: 0.00555 
2025-01-08 13:12:56.526462: train_loss -0.8794 
2025-01-08 13:12:56.527463: val_loss -0.8443 
2025-01-08 13:12:56.532983: Pseudo dice [np.float32(0.9031)] 
2025-01-08 13:12:56.535494: Epoch time: 39.64 s 
2025-01-08 13:12:56.539003: Yayy! New best EMA pseudo Dice: 0.8948000073432922 
2025-01-08 13:12:57.306788:  
2025-01-08 13:12:57.307302: Epoch 49 
2025-01-08 13:12:57.312381: Current learning rate: 0.00546 
2025-01-08 13:13:36.901351: train_loss -0.8552 
2025-01-08 13:13:36.902372: val_loss -0.7804 
2025-01-08 13:13:36.907950: Pseudo dice [np.float32(0.9208)] 
2025-01-08 13:13:36.910011: Epoch time: 39.6 s 
2025-01-08 13:13:37.070457: Yayy! New best EMA pseudo Dice: 0.8974000215530396 
2025-01-08 13:13:37.890132:  
2025-01-08 13:13:37.890635: Epoch 50 
2025-01-08 13:13:37.895648: Current learning rate: 0.00536 
2025-01-08 13:14:17.516534: train_loss -0.8784 
2025-01-08 13:14:17.516534: val_loss -0.8686 
2025-01-08 13:14:17.523061: Pseudo dice [np.float32(0.9301)] 
2025-01-08 13:14:17.525568: Epoch time: 39.63 s 
2025-01-08 13:14:17.529078: Yayy! New best EMA pseudo Dice: 0.900600016117096 
2025-01-08 13:14:18.531838:  
2025-01-08 13:14:18.532342: Epoch 51 
2025-01-08 13:14:18.537358: Current learning rate: 0.00526 
2025-01-08 13:14:58.138320: train_loss -0.8263 
2025-01-08 13:14:58.139350: val_loss -0.7821 
2025-01-08 13:14:58.144938: Pseudo dice [np.float32(0.8938)] 
2025-01-08 13:14:58.147470: Epoch time: 39.61 s 
2025-01-08 13:14:58.714373:  
2025-01-08 13:14:58.715378: Epoch 52 
2025-01-08 13:14:58.719914: Current learning rate: 0.00517 
2025-01-08 13:15:38.315507: train_loss -0.8658 
2025-01-08 13:15:38.315507: val_loss -0.877 
2025-01-08 13:15:38.321533: Pseudo dice [np.float32(0.9394)] 
2025-01-08 13:15:38.325049: Epoch time: 39.6 s 
2025-01-08 13:15:38.328062: Yayy! New best EMA pseudo Dice: 0.9039000272750854 
2025-01-08 13:15:39.093364:  
2025-01-08 13:15:39.093868: Epoch 53 
2025-01-08 13:15:39.098883: Current learning rate: 0.00507 
2025-01-08 13:16:18.728894: train_loss -0.8734 
2025-01-08 13:16:18.729897: val_loss -0.7532 
2025-01-08 13:16:18.735910: Pseudo dice [np.float32(0.8929)] 
2025-01-08 13:16:18.738920: Epoch time: 39.64 s 
2025-01-08 13:16:19.307183:  
2025-01-08 13:16:19.308187: Epoch 54 
2025-01-08 13:16:19.312732: Current learning rate: 0.00497 
2025-01-08 13:16:58.953262: train_loss -0.8955 
2025-01-08 13:16:58.953766: val_loss -0.8812 
2025-01-08 13:16:58.958865: Pseudo dice [np.float32(0.9362)] 
2025-01-08 13:16:58.961408: Epoch time: 39.65 s 
2025-01-08 13:16:58.966330: Yayy! New best EMA pseudo Dice: 0.9060999751091003 
2025-01-08 13:16:59.725899:  
2025-01-08 13:16:59.725899: Epoch 55 
2025-01-08 13:16:59.731914: Current learning rate: 0.00487 
2025-01-08 13:17:39.358629: train_loss -0.8852 
2025-01-08 13:17:39.359634: val_loss -0.8134 
2025-01-08 13:17:39.364648: Pseudo dice [np.float32(0.9135)] 
2025-01-08 13:17:39.368156: Epoch time: 39.63 s 
2025-01-08 13:17:39.371165: Yayy! New best EMA pseudo Dice: 0.9068999886512756 
2025-01-08 13:17:40.174831:  
2025-01-08 13:17:40.175835: Epoch 56 
2025-01-08 13:17:40.180387: Current learning rate: 0.00478 
2025-01-08 13:18:19.781362: train_loss -0.8914 
2025-01-08 13:18:19.782366: val_loss -0.6139 
2025-01-08 13:18:19.787380: Pseudo dice [np.float32(0.8077)] 
2025-01-08 13:18:19.791391: Epoch time: 39.61 s 
2025-01-08 13:18:20.360587:  
2025-01-08 13:18:20.360587: Epoch 57 
2025-01-08 13:18:20.365600: Current learning rate: 0.00468 
2025-01-08 13:18:59.997150: train_loss -0.8971 
2025-01-08 13:18:59.998659: val_loss -0.8024 
2025-01-08 13:19:00.003677: Pseudo dice [np.float32(0.9004)] 
2025-01-08 13:19:00.007194: Epoch time: 39.64 s 
2025-01-08 13:19:00.571222:  
2025-01-08 13:19:00.572222: Epoch 58 
2025-01-08 13:19:00.577302: Current learning rate: 0.00458 
2025-01-08 13:19:40.239575: train_loss -0.896 
2025-01-08 13:19:40.239575: val_loss -0.8809 
2025-01-08 13:19:40.245591: Pseudo dice [np.float32(0.9306)] 
2025-01-08 13:19:40.248600: Epoch time: 39.67 s 
2025-01-08 13:19:40.963840:  
2025-01-08 13:19:40.963840: Epoch 59 
2025-01-08 13:19:40.969894: Current learning rate: 0.00448 
2025-01-08 13:20:20.599039: train_loss -0.8838 
2025-01-08 13:20:20.599039: val_loss -0.8695 
2025-01-08 13:20:20.605174: Pseudo dice [np.float32(0.9256)] 
2025-01-08 13:20:20.608250: Epoch time: 39.64 s 
2025-01-08 13:20:21.189332:  
2025-01-08 13:20:21.189836: Epoch 60 
2025-01-08 13:20:21.194377: Current learning rate: 0.00438 
2025-01-08 13:21:00.803972: train_loss -0.8768 
2025-01-08 13:21:00.803972: val_loss -0.8694 
2025-01-08 13:21:00.809988: Pseudo dice [np.float32(0.9239)] 
2025-01-08 13:21:00.812497: Epoch time: 39.62 s 
2025-01-08 13:21:01.389328:  
2025-01-08 13:21:01.389328: Epoch 61 
2025-01-08 13:21:01.394440: Current learning rate: 0.00429 
2025-01-08 13:21:41.004647: train_loss -0.8941 
2025-01-08 13:21:41.004647: val_loss -0.8871 
2025-01-08 13:21:41.010180: Pseudo dice [np.float32(0.9404)] 
2025-01-08 13:21:41.013201: Epoch time: 39.62 s 
2025-01-08 13:21:41.016709: Yayy! New best EMA pseudo Dice: 0.9086999893188477 
2025-01-08 13:21:41.847838:  
2025-01-08 13:21:41.847838: Epoch 62 
2025-01-08 13:21:41.854057: Current learning rate: 0.00419 
2025-01-08 13:22:21.484486: train_loss -0.9095 
2025-01-08 13:22:21.485487: val_loss -0.8609 
2025-01-08 13:22:21.491011: Pseudo dice [np.float32(0.9278)] 
2025-01-08 13:22:21.494524: Epoch time: 39.64 s 
2025-01-08 13:22:21.497033: Yayy! New best EMA pseudo Dice: 0.9106000065803528 
2025-01-08 13:22:22.308165:  
2025-01-08 13:22:22.308165: Epoch 63 
2025-01-08 13:22:22.313775: Current learning rate: 0.00409 
2025-01-08 13:23:01.942321: train_loss -0.9045 
2025-01-08 13:23:01.943830: val_loss -0.9083 
2025-01-08 13:23:01.949970: Pseudo dice [np.float32(0.9541)] 
2025-01-08 13:23:01.952521: Epoch time: 39.63 s 
2025-01-08 13:23:01.955061: Yayy! New best EMA pseudo Dice: 0.9150000214576721 
2025-01-08 13:23:02.774465:  
2025-01-08 13:23:02.774465: Epoch 64 
2025-01-08 13:23:02.779475: Current learning rate: 0.00399 
2025-01-08 13:23:42.378660: train_loss -0.89 
2025-01-08 13:23:42.379660: val_loss -0.9033 
2025-01-08 13:23:42.385688: Pseudo dice [np.float32(0.9507)] 
2025-01-08 13:23:42.388224: Epoch time: 39.61 s 
2025-01-08 13:23:42.391251: Yayy! New best EMA pseudo Dice: 0.9185000061988831 
2025-01-08 13:23:43.198767:  
2025-01-08 13:23:43.199767: Epoch 65 
2025-01-08 13:23:43.204858: Current learning rate: 0.00389 
2025-01-08 13:24:22.798591: train_loss -0.9139 
2025-01-08 13:24:22.799595: val_loss -0.8885 
2025-01-08 13:24:22.805612: Pseudo dice [np.float32(0.9373)] 
2025-01-08 13:24:22.808620: Epoch time: 39.6 s 
2025-01-08 13:24:22.811126: Yayy! New best EMA pseudo Dice: 0.9204000234603882 
2025-01-08 13:24:23.623967:  
2025-01-08 13:24:23.623967: Epoch 66 
2025-01-08 13:24:23.629982: Current learning rate: 0.00379 
2025-01-08 13:25:03.204307: train_loss -0.9091 
2025-01-08 13:25:03.204307: val_loss -0.8138 
2025-01-08 13:25:03.209408: Pseudo dice [np.float32(0.9071)] 
2025-01-08 13:25:03.213942: Epoch time: 39.58 s 
2025-01-08 13:25:03.932284:  
2025-01-08 13:25:03.932284: Epoch 67 
2025-01-08 13:25:03.937300: Current learning rate: 0.00369 
2025-01-08 13:25:43.574850: train_loss -0.9045 
2025-01-08 13:25:43.575850: val_loss -0.8376 
2025-01-08 13:25:43.581371: Pseudo dice [np.float32(0.9134)] 
2025-01-08 13:25:43.583879: Epoch time: 39.64 s 
2025-01-08 13:25:44.163671:  
2025-01-08 13:25:44.164675: Epoch 68 
2025-01-08 13:25:44.169207: Current learning rate: 0.00359 
2025-01-08 13:26:23.772198: train_loss -0.903 
2025-01-08 13:26:23.773196: val_loss -0.8179 
2025-01-08 13:26:23.779722: Pseudo dice [np.float32(0.9075)] 
2025-01-08 13:26:23.782231: Epoch time: 39.61 s 
2025-01-08 13:26:24.361179:  
2025-01-08 13:26:24.362180: Epoch 69 
2025-01-08 13:26:24.367245: Current learning rate: 0.00349 
2025-01-08 13:27:03.967203: train_loss -0.8812 
2025-01-08 13:27:03.967203: val_loss -0.8756 
2025-01-08 13:27:03.973718: Pseudo dice [np.float32(0.9282)] 
2025-01-08 13:27:03.976226: Epoch time: 39.61 s 
2025-01-08 13:27:04.555623:  
2025-01-08 13:27:04.556623: Epoch 70 
2025-01-08 13:27:04.561192: Current learning rate: 0.00338 
2025-01-08 13:27:44.159922: train_loss -0.895 
2025-01-08 13:27:44.160425: val_loss -0.7745 
2025-01-08 13:27:44.166444: Pseudo dice [np.float32(0.9178)] 
2025-01-08 13:27:44.169455: Epoch time: 39.6 s 
2025-01-08 13:27:44.739336:  
2025-01-08 13:27:44.739336: Epoch 71 
2025-01-08 13:27:44.745146: Current learning rate: 0.00328 
2025-01-08 13:28:24.368573: train_loss -0.9 
2025-01-08 13:28:24.369077: val_loss -0.8835 
2025-01-08 13:28:24.374731: Pseudo dice [np.float32(0.9381)] 
2025-01-08 13:28:24.377476: Epoch time: 39.63 s 
2025-01-08 13:28:24.952906:  
2025-01-08 13:28:24.953907: Epoch 72 
2025-01-08 13:28:24.959005: Current learning rate: 0.00318 
2025-01-08 13:29:04.557509: train_loss -0.9113 
2025-01-08 13:29:04.557509: val_loss -0.9024 
2025-01-08 13:29:04.564024: Pseudo dice [np.float32(0.9474)] 
2025-01-08 13:29:04.569036: Epoch time: 39.6 s 
2025-01-08 13:29:04.571542: Yayy! New best EMA pseudo Dice: 0.9230999946594238 
2025-01-08 13:29:05.397578:  
2025-01-08 13:29:05.397578: Epoch 73 
2025-01-08 13:29:05.402598: Current learning rate: 0.00308 
2025-01-08 13:29:44.987790: train_loss -0.9168 
2025-01-08 13:29:44.987790: val_loss -0.857 
2025-01-08 13:29:44.994624: Pseudo dice [np.float32(0.9282)] 
2025-01-08 13:29:44.997130: Epoch time: 39.59 s 
2025-01-08 13:29:45.000639: Yayy! New best EMA pseudo Dice: 0.9236000180244446 
2025-01-08 13:29:45.994545:  
2025-01-08 13:29:45.995545: Epoch 74 
2025-01-08 13:29:46.000566: Current learning rate: 0.00297 
2025-01-08 13:30:25.558438: train_loss -0.9129 
2025-01-08 13:30:25.559442: val_loss -0.8304 
2025-01-08 13:30:25.565959: Pseudo dice [np.float32(0.9074)] 
2025-01-08 13:30:25.569467: Epoch time: 39.56 s 
2025-01-08 13:30:26.151600:  
2025-01-08 13:30:26.151600: Epoch 75 
2025-01-08 13:30:26.155686: Current learning rate: 0.00287 
2025-01-08 13:31:05.727107: train_loss -0.9015 
2025-01-08 13:31:05.728110: val_loss -0.8384 
2025-01-08 13:31:05.733746: Pseudo dice [np.float32(0.9095)] 
2025-01-08 13:31:05.736782: Epoch time: 39.58 s 
2025-01-08 13:31:06.316114:  
2025-01-08 13:31:06.316114: Epoch 76 
2025-01-08 13:31:06.321647: Current learning rate: 0.00277 
2025-01-08 13:31:45.946223: train_loss -0.9031 
2025-01-08 13:31:45.947726: val_loss -0.8906 
2025-01-08 13:31:45.952736: Pseudo dice [np.float32(0.9422)] 
2025-01-08 13:31:45.956245: Epoch time: 39.63 s 
2025-01-08 13:31:46.533258:  
2025-01-08 13:31:46.533761: Epoch 77 
2025-01-08 13:31:46.537270: Current learning rate: 0.00266 
2025-01-08 13:32:26.139812: train_loss -0.9182 
2025-01-08 13:32:26.140812: val_loss -0.8701 
2025-01-08 13:32:26.146326: Pseudo dice [np.float32(0.9287)] 
2025-01-08 13:32:26.148871: Epoch time: 39.61 s 
2025-01-08 13:32:26.739769:  
2025-01-08 13:32:26.740272: Epoch 78 
2025-01-08 13:32:26.745281: Current learning rate: 0.00256 
2025-01-08 13:33:06.347529: train_loss -0.9222 
2025-01-08 13:33:06.348037: val_loss -0.872 
2025-01-08 13:33:06.353085: Pseudo dice [np.float32(0.9409)] 
2025-01-08 13:33:06.356611: Epoch time: 39.61 s 
2025-01-08 13:33:06.359634: Yayy! New best EMA pseudo Dice: 0.9251999855041504 
2025-01-08 13:33:07.185607:  
2025-01-08 13:33:07.186607: Epoch 79 
2025-01-08 13:33:07.192124: Current learning rate: 0.00245 
2025-01-08 13:33:46.791654: train_loss -0.9239 
2025-01-08 13:33:46.792659: val_loss -0.8796 
2025-01-08 13:33:46.797673: Pseudo dice [np.float32(0.9432)] 
2025-01-08 13:33:46.801682: Epoch time: 39.61 s 
2025-01-08 13:33:46.804191: Yayy! New best EMA pseudo Dice: 0.9269999861717224 
2025-01-08 13:33:47.650163:  
2025-01-08 13:33:47.651163: Epoch 80 
2025-01-08 13:33:47.655727: Current learning rate: 0.00235 
2025-01-08 13:34:27.283087: train_loss -0.921 
2025-01-08 13:34:27.283598: val_loss -0.8377 
2025-01-08 13:34:27.290184: Pseudo dice [np.float32(0.9143)] 
2025-01-08 13:34:27.293726: Epoch time: 39.63 s 
2025-01-08 13:34:27.899659:  
2025-01-08 13:34:27.899659: Epoch 81 
2025-01-08 13:34:27.904674: Current learning rate: 0.00224 
2025-01-08 13:35:07.499327: train_loss -0.9162 
2025-01-08 13:35:07.499839: val_loss -0.8757 
2025-01-08 13:35:07.504882: Pseudo dice [np.float32(0.9379)] 
2025-01-08 13:35:07.508411: Epoch time: 39.6 s 
2025-01-08 13:35:08.244022:  
2025-01-08 13:35:08.245022: Epoch 82 
2025-01-08 13:35:08.250634: Current learning rate: 0.00214 
2025-01-08 13:35:47.855222: train_loss -0.9164 
2025-01-08 13:35:47.855222: val_loss -0.8429 
2025-01-08 13:35:47.861276: Pseudo dice [np.float32(0.9219)] 
2025-01-08 13:35:47.864810: Epoch time: 39.61 s 
2025-01-08 13:35:48.422412:  
2025-01-08 13:35:48.423413: Epoch 83 
2025-01-08 13:35:48.426458: Current learning rate: 0.00203 
2025-01-08 13:36:28.062878: train_loss -0.9076 
2025-01-08 13:36:28.063383: val_loss -0.839 
2025-01-08 13:36:28.069442: Pseudo dice [np.float32(0.9314)] 
2025-01-08 13:36:28.071476: Epoch time: 39.64 s 
2025-01-08 13:36:28.627076:  
2025-01-08 13:36:28.628080: Epoch 84 
2025-01-08 13:36:28.632642: Current learning rate: 0.00192 
2025-01-08 13:37:08.222286: train_loss -0.9176 
2025-01-08 13:37:08.222795: val_loss -0.8805 
2025-01-08 13:37:08.228378: Pseudo dice [np.float32(0.9382)] 
2025-01-08 13:37:08.231932: Epoch time: 39.6 s 
2025-01-08 13:37:08.234963: Yayy! New best EMA pseudo Dice: 0.9280999898910522 
2025-01-08 13:37:09.048178:  
2025-01-08 13:37:09.048681: Epoch 85 
2025-01-08 13:37:09.052189: Current learning rate: 0.00181 
2025-01-08 13:37:48.666759: train_loss -0.9212 
2025-01-08 13:37:48.666759: val_loss -0.8753 
2025-01-08 13:37:48.672773: Pseudo dice [np.float32(0.9351)] 
2025-01-08 13:37:48.675781: Epoch time: 39.62 s 
2025-01-08 13:37:48.678287: Yayy! New best EMA pseudo Dice: 0.9287999868392944 
2025-01-08 13:37:49.470783:  
2025-01-08 13:37:49.470783: Epoch 86 
2025-01-08 13:37:49.475819: Current learning rate: 0.0017 
2025-01-08 13:38:29.106049: train_loss -0.9197 
2025-01-08 13:38:29.106049: val_loss -0.8751 
2025-01-08 13:38:29.112068: Pseudo dice [np.float32(0.9414)] 
2025-01-08 13:38:29.116077: Epoch time: 39.64 s 
2025-01-08 13:38:29.118583: Yayy! New best EMA pseudo Dice: 0.9300000071525574 
2025-01-08 13:38:29.908772:  
2025-01-08 13:38:29.908772: Epoch 87 
2025-01-08 13:38:29.913804: Current learning rate: 0.00159 
2025-01-08 13:39:09.553968: train_loss -0.9283 
2025-01-08 13:39:09.553968: val_loss -0.7774 
2025-01-08 13:39:09.559985: Pseudo dice [np.float32(0.91)] 
2025-01-08 13:39:09.563001: Epoch time: 39.65 s 
2025-01-08 13:39:10.109707:  
2025-01-08 13:39:10.109707: Epoch 88 
2025-01-08 13:39:10.115347: Current learning rate: 0.00148 
2025-01-08 13:39:49.739173: train_loss -0.9272 
2025-01-08 13:39:49.739678: val_loss -0.7894 
2025-01-08 13:39:49.745233: Pseudo dice [np.float32(0.9114)] 
2025-01-08 13:39:49.748312: Epoch time: 39.63 s 
2025-01-08 13:39:50.296914:  
2025-01-08 13:39:50.296914: Epoch 89 
2025-01-08 13:39:50.303034: Current learning rate: 0.00137 
2025-01-08 13:40:29.919703: train_loss -0.9265 
2025-01-08 13:40:29.920205: val_loss -0.8106 
2025-01-08 13:40:29.925217: Pseudo dice [np.float32(0.906)] 
2025-01-08 13:40:29.928728: Epoch time: 39.62 s 
2025-01-08 13:40:30.632457:  
2025-01-08 13:40:30.633460: Epoch 90 
2025-01-08 13:40:30.637497: Current learning rate: 0.00126 
2025-01-08 13:41:10.215025: train_loss -0.9166 
2025-01-08 13:41:10.215527: val_loss -0.8328 
2025-01-08 13:41:10.221543: Pseudo dice [np.float32(0.9406)] 
2025-01-08 13:41:10.225051: Epoch time: 39.58 s 
2025-01-08 13:41:10.774699:  
2025-01-08 13:41:10.774699: Epoch 91 
2025-01-08 13:41:10.780257: Current learning rate: 0.00115 
2025-01-08 13:41:50.406104: train_loss -0.9156 
2025-01-08 13:41:50.407107: val_loss -0.8531 
2025-01-08 13:41:50.413624: Pseudo dice [np.float32(0.9298)] 
2025-01-08 13:41:50.416130: Epoch time: 39.63 s 
2025-01-08 13:41:50.967573:  
2025-01-08 13:41:50.968576: Epoch 92 
2025-01-08 13:41:50.973608: Current learning rate: 0.00103 
2025-01-08 13:42:30.570213: train_loss -0.9201 
2025-01-08 13:42:30.570213: val_loss -0.8292 
2025-01-08 13:42:30.575798: Pseudo dice [np.float32(0.9239)] 
2025-01-08 13:42:30.580361: Epoch time: 39.6 s 
2025-01-08 13:42:31.129865:  
2025-01-08 13:42:31.129865: Epoch 93 
2025-01-08 13:42:31.135412: Current learning rate: 0.00091 
2025-01-08 13:43:10.730180: train_loss -0.9263 
2025-01-08 13:43:10.730683: val_loss -0.8851 
2025-01-08 13:43:10.736757: Pseudo dice [np.float32(0.9351)] 
2025-01-08 13:43:10.739291: Epoch time: 39.6 s 
2025-01-08 13:43:11.288771:  
2025-01-08 13:43:11.289771: Epoch 94 
2025-01-08 13:43:11.294877: Current learning rate: 0.00079 
2025-01-08 13:43:50.906403: train_loss -0.9185 
2025-01-08 13:43:50.906917: val_loss -0.7995 
2025-01-08 13:43:50.912975: Pseudo dice [np.float32(0.9224)] 
2025-01-08 13:43:50.916001: Epoch time: 39.62 s 
2025-01-08 13:43:51.463926:  
2025-01-08 13:43:51.463926: Epoch 95 
2025-01-08 13:43:51.468955: Current learning rate: 0.00067 
2025-01-08 13:44:31.066180: train_loss -0.9209 
2025-01-08 13:44:31.066682: val_loss -0.8751 
2025-01-08 13:44:31.072701: Pseudo dice [np.float32(0.9316)] 
2025-01-08 13:44:31.076225: Epoch time: 39.6 s 
2025-01-08 13:44:31.627358:  
2025-01-08 13:44:31.627358: Epoch 96 
2025-01-08 13:44:31.632370: Current learning rate: 0.00055 
2025-01-08 13:45:11.250242: train_loss -0.925 
2025-01-08 13:45:11.250745: val_loss -0.8672 
2025-01-08 13:45:11.255757: Pseudo dice [np.float32(0.937)] 
2025-01-08 13:45:11.259267: Epoch time: 39.62 s 
2025-01-08 13:45:11.814290:  
2025-01-08 13:45:11.814799: Epoch 97 
2025-01-08 13:45:11.819852: Current learning rate: 0.00043 
2025-01-08 13:45:51.425631: train_loss -0.9245 
2025-01-08 13:45:51.425631: val_loss -0.8824 
2025-01-08 13:45:51.432184: Pseudo dice [np.float32(0.9393)] 
2025-01-08 13:45:51.435694: Epoch time: 39.61 s 
2025-01-08 13:45:51.995807:  
2025-01-08 13:45:51.995807: Epoch 98 
2025-01-08 13:45:51.999842: Current learning rate: 0.0003 
2025-01-08 13:46:31.560918: train_loss -0.9315 
2025-01-08 13:46:31.561921: val_loss -0.8947 
2025-01-08 13:46:31.567606: Pseudo dice [np.float32(0.9405)] 
2025-01-08 13:46:31.571614: Epoch time: 39.57 s 
2025-01-08 13:46:31.574155: Yayy! New best EMA pseudo Dice: 0.9302999973297119 
2025-01-08 13:46:32.554380:  
2025-01-08 13:46:32.554380: Epoch 99 
2025-01-08 13:46:32.559474: Current learning rate: 0.00016 
2025-01-08 13:47:12.150044: train_loss -0.9305 
2025-01-08 13:47:12.151044: val_loss -0.8744 
2025-01-08 13:47:12.156559: Pseudo dice [np.float32(0.9444)] 
2025-01-08 13:47:12.159067: Epoch time: 39.6 s 
2025-01-08 13:47:12.162612: Yayy! New best EMA pseudo Dice: 0.9316999912261963 
2025-01-08 13:47:13.138876: Training done. 
2025-01-08 13:47:13.166875: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset009_Spleen\splits_final.json 
2025-01-08 13:47:13.173874: The split file contains 5 splits. 
2025-01-08 13:47:13.179878: Desired fold for training: 0 
2025-01-08 13:47:13.184878: This split has 32 training and 9 validation cases. 
2025-01-08 13:47:13.190876: predicting spleen_10 
2025-01-08 13:47:13.198877: spleen_10, shape torch.Size([1, 275, 500, 500]), rank 0 
2025-01-08 13:47:43.098318: predicting spleen_13 
2025-01-08 13:47:43.125318: spleen_13, shape torch.Size([1, 192, 380, 380]), rank 0 
2025-01-08 13:47:53.629114: predicting spleen_14 
2025-01-08 13:47:53.641116: spleen_14, shape torch.Size([1, 270, 436, 436]), rank 0 
2025-01-08 13:48:14.660319: predicting spleen_17 
2025-01-08 13:48:14.681576: spleen_17, shape torch.Size([1, 238, 314, 314]), rank 0 
2025-01-08 13:48:23.072962: predicting spleen_31 
2025-01-08 13:48:23.083962: spleen_31, shape torch.Size([1, 280, 379, 379]), rank 0 
2025-01-08 13:48:37.040830: predicting spleen_33 
2025-01-08 13:48:37.057832: spleen_33, shape torch.Size([1, 415, 473, 473]), rank 0 
2025-01-08 13:49:19.704846: predicting spleen_44 
2025-01-08 13:49:19.740861: spleen_44, shape torch.Size([1, 460, 446, 446]), rank 0 
2025-01-08 13:50:01.588534: predicting spleen_47 
2025-01-08 13:50:01.627536: spleen_47, shape torch.Size([1, 440, 402, 402]), rank 0 
2025-01-08 13:50:38.229997: predicting spleen_56 
2025-01-08 13:50:38.268506: spleen_56, shape torch.Size([1, 231, 358, 358]), rank 0 
2025-01-08 13:50:58.531195: Validation complete 
2025-01-08 13:50:58.531195: Mean Validation Dice:  0.9091665626473304 
