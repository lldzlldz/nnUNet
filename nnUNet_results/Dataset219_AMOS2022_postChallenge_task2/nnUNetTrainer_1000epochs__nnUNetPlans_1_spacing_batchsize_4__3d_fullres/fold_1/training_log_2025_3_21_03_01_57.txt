
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-21 03:01:57.537564: do_dummy_2d_data_aug: False 
2025-03-21 03:01:57.549861: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset219_AMOS2022_postChallenge_task2\splits_final.json 
2025-03-21 03:01:57.557860: The split file contains 5 splits. 
2025-03-21 03:01:57.560864: Desired fold for training: 1 
2025-03-21 03:01:57.564646: This split has 288 training and 72 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_1_spacing_batchsize_3_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 3, 'patch_size': [128, 112, 112], 'median_image_size_in_voxels': [450.0, 398.5, 400.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset219_AMOS2022_postChallenge_task2', 'plans_name': 'nnUNetPlans_1_spacing_batchsize_3', 'original_median_spacing_after_transp': [5.0, 0.712890625, 0.712890625], 'original_median_shape_after_transp': [103, 512, 512], 'image_reader_writer': 'NibabelIOWithReorient', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3284530.75, 'mean': 4168.03125, 'median': 66.0, 'min': -3024.0, 'percentile_00_5': -982.0, 'percentile_99_5': 55963.9765625, 'std': 73746.4765625}}} 
 
2025-03-21 03:02:29.442091: unpacking dataset... 
2025-03-21 03:02:29.683374: unpacking done... 
2025-03-21 03:02:33.197703:  
2025-03-21 03:02:33.203217: Epoch 950 
2025-03-21 03:02:33.207726: Current learning rate: 0.00067 
2025-03-21 03:03:21.130943: train_loss -0.4932 
2025-03-21 03:03:21.138080: val_loss -0.4384 
2025-03-21 03:03:21.141587: Pseudo dice [np.float32(0.9408), np.float32(0.9296), np.float32(0.9413), np.float32(0.8791), np.float32(0.8281), np.float32(0.9616), np.float32(0.9364), np.float32(0.9486), np.float32(0.876), np.float32(0.8389), np.float32(0.7575), np.float32(0.7756), np.float32(0.7214), np.float32(0.6186), np.float32(0.7641)] 
2025-03-21 03:03:21.144596: Epoch time: 47.93 s 
2025-03-21 03:03:21.809524:  
2025-03-21 03:03:21.814603: Epoch 951 
2025-03-21 03:03:21.819115: Current learning rate: 0.00066 
2025-03-21 03:04:05.837468: train_loss -0.4786 
2025-03-21 03:04:05.843522: val_loss -0.4203 
2025-03-21 03:04:05.847045: Pseudo dice [np.float32(0.9656), np.float32(0.9317), np.float32(0.9422), np.float32(0.809), np.float32(0.7582), np.float32(0.9623), np.float32(0.9196), np.float32(0.9302), np.float32(0.8923), np.float32(0.8191), np.float32(0.7438), np.float32(0.6963), np.float32(0.7), np.float32(0.8982), np.float32(0.8399)] 
2025-03-21 03:04:05.850613: Epoch time: 44.03 s 
2025-03-21 03:04:06.526091:  
2025-03-21 03:04:06.532123: Epoch 952 
2025-03-21 03:04:06.535168: Current learning rate: 0.00065 
2025-03-21 03:04:50.853131: train_loss -0.4961 
2025-03-21 03:04:50.858142: val_loss -0.4275 
2025-03-21 03:04:50.862155: Pseudo dice [np.float32(0.9618), np.float32(0.9503), np.float32(0.9568), np.float32(0.8852), np.float32(0.7368), np.float32(0.9595), np.float32(0.9194), np.float32(0.9549), np.float32(0.9023), np.float32(0.8658), np.float32(0.7545), np.float32(0.7681), np.float32(0.7697), np.float32(0.9208), np.float32(0.8988)] 
2025-03-21 03:04:50.865669: Epoch time: 44.33 s 
2025-03-21 03:04:51.521887:  
2025-03-21 03:04:51.527486: Epoch 953 
2025-03-21 03:04:51.530026: Current learning rate: 0.00064 
2025-03-21 03:05:35.133509: train_loss -0.4934 
2025-03-21 03:05:35.140060: val_loss -0.4916 
2025-03-21 03:05:35.143591: Pseudo dice [np.float32(0.9624), np.float32(0.9431), np.float32(0.9497), np.float32(0.7767), np.float32(0.7816), np.float32(0.9635), np.float32(0.9127), np.float32(0.9507), np.float32(0.8811), np.float32(0.8718), np.float32(0.6857), np.float32(0.7724), np.float32(0.7966), np.float32(0.8811), np.float32(0.7295)] 
2025-03-21 03:05:35.147122: Epoch time: 43.61 s 
2025-03-21 03:05:35.969529:  
2025-03-21 03:05:35.975567: Epoch 954 
2025-03-21 03:05:35.979076: Current learning rate: 0.00063 
2025-03-21 03:06:19.770815: train_loss -0.495 
2025-03-21 03:06:19.777851: val_loss -0.5002 
2025-03-21 03:06:19.781902: Pseudo dice [np.float32(0.952), np.float32(0.9524), np.float32(0.9529), np.float32(0.8212), np.float32(0.7647), np.float32(0.9556), np.float32(0.9234), np.float32(0.9544), np.float32(0.8999), np.float32(0.8749), np.float32(0.7818), np.float32(0.7833), np.float32(0.7973), np.float32(0.64), np.float32(0.5741)] 
2025-03-21 03:06:19.784928: Epoch time: 43.8 s 
2025-03-21 03:06:20.464677:  
2025-03-21 03:06:20.470692: Epoch 955 
2025-03-21 03:06:20.473197: Current learning rate: 0.00061 
2025-03-21 03:07:04.182030: train_loss -0.4887 
2025-03-21 03:07:04.189116: val_loss -0.4514 
2025-03-21 03:07:04.192152: Pseudo dice [np.float32(0.9671), np.float32(0.9365), np.float32(0.9576), np.float32(0.8538), np.float32(0.8227), np.float32(0.9597), np.float32(0.9261), np.float32(0.9474), np.float32(0.8862), np.float32(0.8784), np.float32(0.7558), np.float32(0.8118), np.float32(0.7826), np.float32(0.8355), np.float32(0.762)] 
2025-03-21 03:07:04.195271: Epoch time: 43.72 s 
2025-03-21 03:07:04.871158:  
2025-03-21 03:07:04.877196: Epoch 956 
2025-03-21 03:07:04.880241: Current learning rate: 0.0006 
2025-03-21 03:07:48.787856: train_loss -0.4991 
2025-03-21 03:07:48.793916: val_loss -0.488 
2025-03-21 03:07:48.798101: Pseudo dice [np.float32(0.9331), np.float32(0.9469), np.float32(0.9453), np.float32(0.8906), np.float32(0.7851), np.float32(0.959), np.float32(0.9058), np.float32(0.9412), np.float32(0.8956), np.float32(0.8619), np.float32(0.735), np.float32(0.7885), np.float32(0.7808), np.float32(0.7372), np.float32(0.8504)] 
2025-03-21 03:07:48.801630: Epoch time: 43.92 s 
2025-03-21 03:07:49.486884:  
2025-03-21 03:07:49.492949: Epoch 957 
2025-03-21 03:07:49.497491: Current learning rate: 0.00059 
2025-03-21 03:08:33.104945: train_loss -0.4943 
2025-03-21 03:08:33.111012: val_loss -0.4538 
2025-03-21 03:08:33.114553: Pseudo dice [np.float32(0.9649), np.float32(0.9505), np.float32(0.9501), np.float32(0.825), np.float32(0.8042), np.float32(0.9659), np.float32(0.8858), np.float32(0.9466), np.float32(0.8832), np.float32(0.8601), np.float32(0.7474), np.float32(0.7766), np.float32(0.7863), np.float32(0.8229), np.float32(0.8883)] 
2025-03-21 03:08:33.118145: Epoch time: 43.62 s 
2025-03-21 03:08:33.785515:  
2025-03-21 03:08:33.791533: Epoch 958 
2025-03-21 03:08:33.795546: Current learning rate: 0.00058 
2025-03-21 03:09:17.318740: train_loss -0.5005 
2025-03-21 03:09:17.325801: val_loss -0.4828 
2025-03-21 03:09:17.329382: Pseudo dice [np.float32(0.9602), np.float32(0.9319), np.float32(0.9506), np.float32(0.8551), np.float32(0.8289), np.float32(0.9546), np.float32(0.9338), np.float32(0.9508), np.float32(0.8787), np.float32(0.8437), np.float32(0.7688), np.float32(0.7952), np.float32(0.7611), np.float32(0.947), np.float32(0.7644)] 
2025-03-21 03:09:17.333417: Epoch time: 43.53 s 
2025-03-21 03:09:18.036558:  
2025-03-21 03:09:18.042592: Epoch 959 
2025-03-21 03:09:18.046628: Current learning rate: 0.00056 
2025-03-21 03:10:01.561366: train_loss -0.4875 
2025-03-21 03:10:01.566968: val_loss -0.4754 
2025-03-21 03:10:01.571517: Pseudo dice [np.float32(0.9538), np.float32(0.891), np.float32(0.9201), np.float32(0.8636), np.float32(0.851), np.float32(0.9635), np.float32(0.9272), np.float32(0.9502), np.float32(0.8778), np.float32(0.8779), np.float32(0.7537), np.float32(0.7838), np.float32(0.7762), np.float32(0.8701), np.float32(0.8147)] 
2025-03-21 03:10:01.574560: Epoch time: 43.53 s 
2025-03-21 03:10:02.250368:  
2025-03-21 03:10:02.256882: Epoch 960 
2025-03-21 03:10:02.260389: Current learning rate: 0.00055 
2025-03-21 03:10:45.792440: train_loss -0.4694 
2025-03-21 03:10:45.798961: val_loss -0.4774 
2025-03-21 03:10:45.802973: Pseudo dice [np.float32(0.9624), np.float32(0.9594), np.float32(0.9623), np.float32(0.8584), np.float32(0.8246), np.float32(0.9736), np.float32(0.9104), np.float32(0.9505), np.float32(0.8818), np.float32(0.848), np.float32(0.8099), np.float32(0.7799), np.float32(0.7798), np.float32(0.8346), np.float32(0.9177)] 
2025-03-21 03:10:45.806483: Epoch time: 43.54 s 
2025-03-21 03:10:46.468427:  
2025-03-21 03:10:46.473467: Epoch 961 
2025-03-21 03:10:46.477011: Current learning rate: 0.00054 
2025-03-21 03:11:30.050138: train_loss -0.4801 
2025-03-21 03:11:30.056670: val_loss -0.4422 
2025-03-21 03:11:30.061180: Pseudo dice [np.float32(0.9301), np.float32(0.9317), np.float32(0.8936), np.float32(0.8928), np.float32(0.8009), np.float32(0.9593), np.float32(0.9224), np.float32(0.9485), np.float32(0.8822), np.float32(0.8626), np.float32(0.7744), np.float32(0.784), np.float32(0.8129), np.float32(0.8926), np.float32(0.7889)] 
2025-03-21 03:11:30.065192: Epoch time: 43.58 s 
2025-03-21 03:11:30.720710:  
2025-03-21 03:11:30.726723: Epoch 962 
2025-03-21 03:11:30.730231: Current learning rate: 0.00053 
2025-03-21 03:12:14.300989: train_loss -0.4953 
2025-03-21 03:12:14.308007: val_loss -0.4732 
2025-03-21 03:12:14.312021: Pseudo dice [np.float32(0.9464), np.float32(0.921), np.float32(0.9224), np.float32(0.8873), np.float32(0.7899), np.float32(0.948), np.float32(0.931), np.float32(0.9534), np.float32(0.8929), np.float32(0.8494), np.float32(0.7587), np.float32(0.7428), np.float32(0.789), np.float32(0.937), np.float32(0.8382)] 
2025-03-21 03:12:14.316540: Epoch time: 43.58 s 
2025-03-21 03:12:14.319569: Yayy! New best EMA pseudo Dice: 0.8676999807357788 
2025-03-21 03:12:15.299505:  
2025-03-21 03:12:15.305542: Epoch 963 
2025-03-21 03:12:15.309581: Current learning rate: 0.00051 
2025-03-21 03:12:59.343895: train_loss -0.5025 
2025-03-21 03:12:59.350910: val_loss -0.4748 
2025-03-21 03:12:59.354922: Pseudo dice [np.float32(0.9645), np.float32(0.9378), np.float32(0.9191), np.float32(0.8598), np.float32(0.7388), np.float32(0.9667), np.float32(0.9144), np.float32(0.9438), np.float32(0.8922), np.float32(0.8764), np.float32(0.764), np.float32(0.7438), np.float32(0.8234), np.float32(0.817), np.float32(0.8286)] 
2025-03-21 03:12:59.359933: Epoch time: 44.05 s 
2025-03-21 03:13:00.127210:  
2025-03-21 03:13:00.133860: Epoch 964 
2025-03-21 03:13:00.137930: Current learning rate: 0.0005 
2025-03-21 03:13:43.783887: train_loss -0.4868 
2025-03-21 03:13:43.791001: val_loss -0.4923 
2025-03-21 03:13:43.794250: Pseudo dice [np.float32(0.9634), np.float32(0.94), np.float32(0.9445), np.float32(0.8524), np.float32(0.7859), np.float32(0.9721), np.float32(0.9286), np.float32(0.9471), np.float32(0.8903), np.float32(0.8829), np.float32(0.7625), np.float32(0.8029), np.float32(0.8044), np.float32(0.7983), np.float32(0.8068)] 
2025-03-21 03:13:43.797761: Epoch time: 43.66 s 
2025-03-21 03:13:43.801770: Yayy! New best EMA pseudo Dice: 0.8679999709129333 
2025-03-21 03:13:44.639422:  
2025-03-21 03:13:44.644938: Epoch 965 
2025-03-21 03:13:44.649954: Current learning rate: 0.00049 
2025-03-21 03:14:28.298906: train_loss -0.4936 
2025-03-21 03:14:28.305954: val_loss -0.4571 
2025-03-21 03:14:28.309966: Pseudo dice [np.float32(0.9665), np.float32(0.9479), np.float32(0.9497), np.float32(0.8795), np.float32(0.7843), np.float32(0.9602), np.float32(0.9122), np.float32(0.9473), np.float32(0.8854), np.float32(0.8482), np.float32(0.7432), np.float32(0.7866), np.float32(0.8025), np.float32(0.8647), np.float32(0.6237)] 
2025-03-21 03:14:28.313973: Epoch time: 43.66 s 
2025-03-21 03:14:28.996937:  
2025-03-21 03:14:29.002994: Epoch 966 
2025-03-21 03:14:29.007005: Current learning rate: 0.00048 
2025-03-21 03:15:12.520487: train_loss -0.5014 
2025-03-21 03:15:12.527083: val_loss -0.4789 
2025-03-21 03:15:12.531647: Pseudo dice [np.float32(0.9378), np.float32(0.9327), np.float32(0.9408), np.float32(0.8944), np.float32(0.8253), np.float32(0.9678), np.float32(0.9161), np.float32(0.9458), np.float32(0.893), np.float32(0.831), np.float32(0.7658), np.float32(0.7767), np.float32(0.8104), np.float32(0.9478), np.float32(0.8057)] 
2025-03-21 03:15:12.534182: Epoch time: 43.52 s 
2025-03-21 03:15:12.538736: Yayy! New best EMA pseudo Dice: 0.868399977684021 
2025-03-21 03:15:13.366908:  
2025-03-21 03:15:13.372976: Epoch 967 
2025-03-21 03:15:13.376486: Current learning rate: 0.00046 
2025-03-21 03:15:56.948773: train_loss -0.5034 
2025-03-21 03:15:56.954503: val_loss -0.4868 
2025-03-21 03:15:56.958008: Pseudo dice [np.float32(0.9452), np.float32(0.9326), np.float32(0.9511), np.float32(0.8595), np.float32(0.7872), np.float32(0.968), np.float32(0.9295), np.float32(0.9427), np.float32(0.8915), np.float32(0.8706), np.float32(0.7677), np.float32(0.7889), np.float32(0.8238), np.float32(0.9432), np.float32(0.8958)] 
2025-03-21 03:15:56.962022: Epoch time: 43.58 s 
2025-03-21 03:15:56.965531: Yayy! New best EMA pseudo Dice: 0.870199978351593 
2025-03-21 03:15:57.813012:  
2025-03-21 03:15:57.818530: Epoch 968 
2025-03-21 03:15:57.822039: Current learning rate: 0.00045 
2025-03-21 03:16:41.389802: train_loss -0.4781 
2025-03-21 03:16:41.396870: val_loss -0.4547 
2025-03-21 03:16:41.400416: Pseudo dice [np.float32(0.9281), np.float32(0.9346), np.float32(0.9203), np.float32(0.774), np.float32(0.716), np.float32(0.9677), np.float32(0.9282), np.float32(0.949), np.float32(0.8849), np.float32(0.8644), np.float32(0.7386), np.float32(0.7646), np.float32(0.7769), np.float32(0.9067), np.float32(0.8039)] 
2025-03-21 03:16:41.403941: Epoch time: 43.58 s 
2025-03-21 03:16:42.048213:  
2025-03-21 03:16:42.054295: Epoch 969 
2025-03-21 03:16:42.057347: Current learning rate: 0.00044 
2025-03-21 03:17:25.596978: train_loss -0.4895 
2025-03-21 03:17:25.603590: val_loss -0.4696 
2025-03-21 03:17:25.607138: Pseudo dice [np.float32(0.9264), np.float32(0.9067), np.float32(0.9278), np.float32(0.8131), np.float32(0.8393), np.float32(0.9449), np.float32(0.8736), np.float32(0.9542), np.float32(0.9064), np.float32(0.8461), np.float32(0.7796), np.float32(0.7682), np.float32(0.775), np.float32(0.8197), np.float32(0.8726)] 
2025-03-21 03:17:25.610173: Epoch time: 43.55 s 
2025-03-21 03:17:26.486699:  
2025-03-21 03:17:26.493336: Epoch 970 
2025-03-21 03:17:26.495891: Current learning rate: 0.00043 
2025-03-21 03:18:10.004618: train_loss -0.4918 
2025-03-21 03:18:10.011662: val_loss -0.4958 
2025-03-21 03:18:10.015172: Pseudo dice [np.float32(0.9702), np.float32(0.935), np.float32(0.9239), np.float32(0.8915), np.float32(0.8085), np.float32(0.9649), np.float32(0.9366), np.float32(0.9511), np.float32(0.9066), np.float32(0.8706), np.float32(0.7831), np.float32(0.7736), np.float32(0.8079), np.float32(0.9277), np.float32(0.8457)] 
2025-03-21 03:18:10.019184: Epoch time: 43.52 s 
2025-03-21 03:18:10.689430:  
2025-03-21 03:18:10.693442: Epoch 971 
2025-03-21 03:18:10.696947: Current learning rate: 0.00041 
2025-03-21 03:18:54.190072: train_loss -0.4952 
2025-03-21 03:18:54.196087: val_loss -0.4605 
2025-03-21 03:18:54.200097: Pseudo dice [np.float32(0.9501), np.float32(0.9452), np.float32(0.9421), np.float32(0.9139), np.float32(0.7744), np.float32(0.9571), np.float32(0.9281), np.float32(0.9428), np.float32(0.8897), np.float32(0.8859), np.float32(0.7821), np.float32(0.7933), np.float32(0.8355), np.float32(0.9471), np.float32(0.8594)] 
2025-03-21 03:18:54.203606: Epoch time: 43.5 s 
2025-03-21 03:18:54.207614: Yayy! New best EMA pseudo Dice: 0.8720999956130981 
2025-03-21 03:18:55.008696:  
2025-03-21 03:18:55.014211: Epoch 972 
2025-03-21 03:18:55.017721: Current learning rate: 0.0004 
2025-03-21 03:19:38.608147: train_loss -0.5019 
2025-03-21 03:19:38.614243: val_loss -0.5038 
2025-03-21 03:19:38.616804: Pseudo dice [np.float32(0.9595), np.float32(0.9615), np.float32(0.9575), np.float32(0.8763), np.float32(0.8096), np.float32(0.9668), np.float32(0.9269), np.float32(0.9467), np.float32(0.9062), np.float32(0.8859), np.float32(0.7875), np.float32(0.7791), np.float32(0.8342), np.float32(0.8856), np.float32(0.8866)] 
2025-03-21 03:19:38.621356: Epoch time: 43.6 s 
2025-03-21 03:19:38.625916: Yayy! New best EMA pseudo Dice: 0.8741000294685364 
2025-03-21 03:19:39.461468:  
2025-03-21 03:19:39.468061: Epoch 973 
2025-03-21 03:19:39.471647: Current learning rate: 0.00039 
2025-03-21 03:20:23.064657: train_loss -0.4973 
2025-03-21 03:20:23.070734: val_loss -0.4868 
2025-03-21 03:20:23.075305: Pseudo dice [np.float32(0.939), np.float32(0.963), np.float32(0.9531), np.float32(0.8451), np.float32(0.8169), np.float32(0.9698), np.float32(0.9265), np.float32(0.9549), np.float32(0.8911), np.float32(0.8596), np.float32(0.7757), np.float32(0.8011), np.float32(0.818), np.float32(0.9222), np.float32(0.8525)] 
2025-03-21 03:20:23.078343: Epoch time: 43.6 s 
2025-03-21 03:20:23.082376: Yayy! New best EMA pseudo Dice: 0.8751999735832214 
2025-03-21 03:20:23.908036:  
2025-03-21 03:20:23.914110: Epoch 974 
2025-03-21 03:20:23.917182: Current learning rate: 0.00037 
2025-03-21 03:21:07.384809: train_loss -0.4738 
2025-03-21 03:21:07.392327: val_loss -0.4347 
2025-03-21 03:21:07.395835: Pseudo dice [np.float32(0.9537), np.float32(0.9356), np.float32(0.9366), np.float32(0.8506), np.float32(0.8125), np.float32(0.9665), np.float32(0.9205), np.float32(0.9489), np.float32(0.88), np.float32(0.8339), np.float32(0.7474), np.float32(0.7293), np.float32(0.7552), np.float32(0.9041), np.float32(0.8807)] 
2025-03-21 03:21:07.399844: Epoch time: 43.48 s 
2025-03-21 03:21:08.148173:  
2025-03-21 03:21:08.153184: Epoch 975 
2025-03-21 03:21:08.156698: Current learning rate: 0.00036 
2025-03-21 03:21:51.706360: train_loss -0.5065 
2025-03-21 03:21:51.712375: val_loss -0.5009 
2025-03-21 03:21:51.716386: Pseudo dice [np.float32(0.9444), np.float32(0.9495), np.float32(0.9541), np.float32(0.8778), np.float32(0.8186), np.float32(0.9696), np.float32(0.928), np.float32(0.9554), np.float32(0.8864), np.float32(0.8713), np.float32(0.7429), np.float32(0.7708), np.float32(0.7604), np.float32(0.8179), np.float32(0.6655)] 
2025-03-21 03:21:51.720894: Epoch time: 43.56 s 
2025-03-21 03:21:52.371834:  
2025-03-21 03:21:52.377411: Epoch 976 
2025-03-21 03:21:52.380990: Current learning rate: 0.00035 
2025-03-21 03:22:36.045859: train_loss -0.4935 
2025-03-21 03:22:36.052873: val_loss -0.4649 
2025-03-21 03:22:36.056885: Pseudo dice [np.float32(0.9689), np.float32(0.9367), np.float32(0.9465), np.float32(0.8721), np.float32(0.7928), np.float32(0.9652), np.float32(0.9187), np.float32(0.945), np.float32(0.9052), np.float32(0.85), np.float32(0.7823), np.float32(0.7882), np.float32(0.8162), np.float32(0.8149), np.float32(0.8449)] 
2025-03-21 03:22:36.060893: Epoch time: 43.68 s 
2025-03-21 03:22:36.720304:  
2025-03-21 03:22:36.726341: Epoch 977 
2025-03-21 03:22:36.729385: Current learning rate: 0.00034 
2025-03-21 03:23:20.351815: train_loss -0.4962 
2025-03-21 03:23:20.358329: val_loss -0.4788 
2025-03-21 03:23:20.361838: Pseudo dice [np.float32(0.9344), np.float32(0.9419), np.float32(0.9359), np.float32(0.7536), np.float32(0.7876), np.float32(0.9694), np.float32(0.9101), np.float32(0.9491), np.float32(0.8956), np.float32(0.8797), np.float32(0.7297), np.float32(0.7521), np.float32(0.7916), np.float32(0.8833), np.float32(0.8206)] 
2025-03-21 03:23:20.365846: Epoch time: 43.63 s 
2025-03-21 03:23:21.222157:  
2025-03-21 03:23:21.228678: Epoch 978 
2025-03-21 03:23:21.232689: Current learning rate: 0.00032 
2025-03-21 03:24:05.069741: train_loss -0.4949 
2025-03-21 03:24:05.076299: val_loss -0.4819 
2025-03-21 03:24:05.080345: Pseudo dice [np.float32(0.912), np.float32(0.9475), np.float32(0.9483), np.float32(0.8572), np.float32(0.7963), np.float32(0.9645), np.float32(0.9202), np.float32(0.9543), np.float32(0.8946), np.float32(0.8672), np.float32(0.7524), np.float32(0.7678), np.float32(0.7998), np.float32(0.7622), np.float32(0.8408)] 
2025-03-21 03:24:05.083874: Epoch time: 43.85 s 
2025-03-21 03:24:05.771914:  
2025-03-21 03:24:05.776927: Epoch 979 
2025-03-21 03:24:05.780441: Current learning rate: 0.00031 
2025-03-21 03:24:49.834436: train_loss -0.5124 
2025-03-21 03:24:49.841954: val_loss -0.4652 
2025-03-21 03:24:49.845463: Pseudo dice [np.float32(0.9438), np.float32(0.9526), np.float32(0.952), np.float32(0.8842), np.float32(0.784), np.float32(0.959), np.float32(0.9175), np.float32(0.9373), np.float32(0.8773), np.float32(0.8382), np.float32(0.7753), np.float32(0.7746), np.float32(0.7239), np.float32(0.8536), np.float32(0.8845)] 
2025-03-21 03:24:49.849471: Epoch time: 44.06 s 
2025-03-21 03:24:50.499569:  
2025-03-21 03:24:50.508666: Epoch 980 
2025-03-21 03:24:50.511695: Current learning rate: 0.0003 
2025-03-21 03:25:33.887980: train_loss -0.5045 
2025-03-21 03:25:33.894606: val_loss -0.5055 
2025-03-21 03:25:33.899171: Pseudo dice [np.float32(0.9465), np.float32(0.9446), np.float32(0.9511), np.float32(0.8888), np.float32(0.7594), np.float32(0.9623), np.float32(0.9084), np.float32(0.9501), np.float32(0.8898), np.float32(0.8663), np.float32(0.7559), np.float32(0.8), np.float32(0.8012), np.float32(0.8785), np.float32(0.8717)] 
2025-03-21 03:25:33.902738: Epoch time: 43.39 s 
2025-03-21 03:25:34.577375:  
2025-03-21 03:25:34.582935: Epoch 981 
2025-03-21 03:25:34.587464: Current learning rate: 0.00028 
2025-03-21 03:26:17.937036: train_loss -0.4919 
2025-03-21 03:26:17.943050: val_loss -0.4977 
2025-03-21 03:26:17.947060: Pseudo dice [np.float32(0.9175), np.float32(0.9359), np.float32(0.9421), np.float32(0.7916), np.float32(0.8026), np.float32(0.9611), np.float32(0.9157), np.float32(0.9527), np.float32(0.8781), np.float32(0.8579), np.float32(0.7449), np.float32(0.7924), np.float32(0.7399), np.float32(0.9112), np.float32(0.8135)] 
2025-03-21 03:26:17.950570: Epoch time: 43.36 s 
2025-03-21 03:26:18.619679:  
2025-03-21 03:26:18.625713: Epoch 982 
2025-03-21 03:26:18.629755: Current learning rate: 0.00027 
2025-03-21 03:27:01.974259: train_loss -0.5047 
2025-03-21 03:27:01.980276: val_loss -0.4604 
2025-03-21 03:27:01.984290: Pseudo dice [np.float32(0.958), np.float32(0.9364), np.float32(0.9435), np.float32(0.8894), np.float32(0.7922), np.float32(0.9723), np.float32(0.8736), np.float32(0.9425), np.float32(0.8932), np.float32(0.8492), np.float32(0.762), np.float32(0.7621), np.float32(0.7747), np.float32(0.8252), np.float32(0.7539)] 
2025-03-21 03:27:01.987802: Epoch time: 43.36 s 
2025-03-21 03:27:02.634584:  
2025-03-21 03:27:02.640652: Epoch 983 
2025-03-21 03:27:02.643712: Current learning rate: 0.00026 
2025-03-21 03:27:45.988286: train_loss -0.492 
2025-03-21 03:27:45.994800: val_loss -0.4132 
2025-03-21 03:27:45.998315: Pseudo dice [np.float32(0.9711), np.float32(0.9462), np.float32(0.9488), np.float32(0.8792), np.float32(0.6516), np.float32(0.9686), np.float32(0.8985), np.float32(0.9257), np.float32(0.8979), np.float32(0.8549), np.float32(0.7417), np.float32(0.781), np.float32(0.7093), np.float32(0.7981), np.float32(0.8256)] 
2025-03-21 03:27:46.002324: Epoch time: 43.35 s 
2025-03-21 03:27:46.685587:  
2025-03-21 03:27:46.691604: Epoch 984 
2025-03-21 03:27:46.695113: Current learning rate: 0.00024 
2025-03-21 03:28:30.096818: train_loss -0.4991 
2025-03-21 03:28:30.104335: val_loss -0.4657 
2025-03-21 03:28:30.107844: Pseudo dice [np.float32(0.9606), np.float32(0.9447), np.float32(0.9453), np.float32(0.856), np.float32(0.7489), np.float32(0.9713), np.float32(0.9212), np.float32(0.9443), np.float32(0.9003), np.float32(0.8675), np.float32(0.7493), np.float32(0.7895), np.float32(0.7678), np.float32(0.8257), np.float32(0.8389)] 
2025-03-21 03:28:30.111852: Epoch time: 43.41 s 
2025-03-21 03:28:30.772670:  
2025-03-21 03:28:30.779186: Epoch 985 
2025-03-21 03:28:30.782696: Current learning rate: 0.00023 
2025-03-21 03:29:14.216150: train_loss -0.5054 
2025-03-21 03:29:14.222251: val_loss -0.4521 
2025-03-21 03:29:14.228878: Pseudo dice [np.float32(0.9562), np.float32(0.937), np.float32(0.943), np.float32(0.8862), np.float32(0.7827), np.float32(0.965), np.float32(0.9285), np.float32(0.9494), np.float32(0.8981), np.float32(0.8473), np.float32(0.7824), np.float32(0.7638), np.float32(0.7818), np.float32(0.6278), np.float32(0.8584)] 
2025-03-21 03:29:14.231889: Epoch time: 43.44 s 
2025-03-21 03:29:14.902752:  
2025-03-21 03:29:14.908825: Epoch 986 
2025-03-21 03:29:14.911890: Current learning rate: 0.00021 
2025-03-21 03:29:58.771497: train_loss -0.51 
2025-03-21 03:29:58.779016: val_loss -0.5058 
2025-03-21 03:29:58.782526: Pseudo dice [np.float32(0.9608), np.float32(0.9527), np.float32(0.9496), np.float32(0.8562), np.float32(0.8066), np.float32(0.9634), np.float32(0.9219), np.float32(0.9551), np.float32(0.9201), np.float32(0.8888), np.float32(0.8165), np.float32(0.7836), np.float32(0.8072), np.float32(0.9295), np.float32(0.8843)] 
2025-03-21 03:29:58.786032: Epoch time: 43.87 s 
2025-03-21 03:29:59.636494:  
2025-03-21 03:29:59.641506: Epoch 987 
2025-03-21 03:29:59.646016: Current learning rate: 0.0002 
2025-03-21 03:30:42.993866: train_loss -0.4887 
2025-03-21 03:30:43.000881: val_loss -0.4786 
2025-03-21 03:30:43.003889: Pseudo dice [np.float32(0.9577), np.float32(0.9567), np.float32(0.9585), np.float32(0.7329), np.float32(0.7581), np.float32(0.953), np.float32(0.9212), np.float32(0.9444), np.float32(0.8726), np.float32(0.8168), np.float32(0.742), np.float32(0.7651), np.float32(0.7478), np.float32(0.9089), np.float32(0.8342)] 
2025-03-21 03:30:43.007400: Epoch time: 43.36 s 
2025-03-21 03:30:43.701222:  
2025-03-21 03:30:43.707340: Epoch 988 
2025-03-21 03:30:43.710423: Current learning rate: 0.00019 
2025-03-21 03:31:27.077420: train_loss -0.4935 
2025-03-21 03:31:27.083939: val_loss -0.4377 
2025-03-21 03:31:27.087446: Pseudo dice [np.float32(0.938), np.float32(0.9472), np.float32(0.9443), np.float32(0.8757), np.float32(0.8179), np.float32(0.9614), np.float32(0.9115), np.float32(0.9527), np.float32(0.8643), np.float32(0.8538), np.float32(0.7662), np.float32(0.7828), np.float32(0.7718), np.float32(0.7327), np.float32(0.8599)] 
2025-03-21 03:31:27.091457: Epoch time: 43.38 s 
2025-03-21 03:31:27.779721:  
2025-03-21 03:31:27.785843: Epoch 989 
2025-03-21 03:31:27.789437: Current learning rate: 0.00017 
2025-03-21 03:32:11.143483: train_loss -0.4989 
2025-03-21 03:32:11.150034: val_loss -0.4789 
2025-03-21 03:32:11.154042: Pseudo dice [np.float32(0.9686), np.float32(0.9427), np.float32(0.9578), np.float32(0.8811), np.float32(0.8375), np.float32(0.9701), np.float32(0.9111), np.float32(0.9476), np.float32(0.893), np.float32(0.8336), np.float32(0.7348), np.float32(0.7625), np.float32(0.7449), np.float32(0.9047), np.float32(0.8017)] 
2025-03-21 03:32:11.157552: Epoch time: 43.36 s 
2025-03-21 03:32:11.825043:  
2025-03-21 03:32:11.831591: Epoch 990 
2025-03-21 03:32:11.835162: Current learning rate: 0.00016 
2025-03-21 03:32:55.173048: train_loss -0.5069 
2025-03-21 03:32:55.179561: val_loss -0.5091 
2025-03-21 03:32:55.184070: Pseudo dice [np.float32(0.9662), np.float32(0.9588), np.float32(0.9621), np.float32(0.8707), np.float32(0.8135), np.float32(0.9666), np.float32(0.9015), np.float32(0.9614), np.float32(0.9093), np.float32(0.8604), np.float32(0.7673), np.float32(0.7774), np.float32(0.7991), np.float32(0.9297), np.float32(0.8168)] 
2025-03-21 03:32:55.188083: Epoch time: 43.35 s 
2025-03-21 03:32:55.837430:  
2025-03-21 03:32:55.843509: Epoch 991 
2025-03-21 03:32:55.846574: Current learning rate: 0.00014 
2025-03-21 03:33:39.216087: train_loss -0.4969 
2025-03-21 03:33:39.223609: val_loss -0.5048 
2025-03-21 03:33:39.227620: Pseudo dice [np.float32(0.9453), np.float32(0.9395), np.float32(0.9486), np.float32(0.8474), np.float32(0.8205), np.float32(0.9677), np.float32(0.9093), np.float32(0.9449), np.float32(0.8933), np.float32(0.8762), np.float32(0.7736), np.float32(0.7879), np.float32(0.8094), np.float32(0.9354), np.float32(0.8452)] 
2025-03-21 03:33:39.231129: Epoch time: 43.38 s 
2025-03-21 03:33:39.913491:  
2025-03-21 03:33:39.919589: Epoch 992 
2025-03-21 03:33:39.923601: Current learning rate: 0.00013 
2025-03-21 03:34:23.338386: train_loss -0.4937 
2025-03-21 03:34:23.344435: val_loss -0.4825 
2025-03-21 03:34:23.347977: Pseudo dice [np.float32(0.9636), np.float32(0.9358), np.float32(0.9269), np.float32(0.8646), np.float32(0.7817), np.float32(0.9729), np.float32(0.8896), np.float32(0.9451), np.float32(0.898), np.float32(0.8888), np.float32(0.768), np.float32(0.8098), np.float32(0.8094), np.float32(0.8484), np.float32(0.8646)] 
2025-03-21 03:34:23.351007: Epoch time: 43.43 s 
2025-03-21 03:34:24.000243:  
2025-03-21 03:34:24.005764: Epoch 993 
2025-03-21 03:34:24.009279: Current learning rate: 0.00011 
2025-03-21 03:35:07.126142: train_loss -0.487 
2025-03-21 03:35:07.133661: val_loss -0.4167 
2025-03-21 03:35:07.137671: Pseudo dice [np.float32(0.9347), np.float32(0.9094), np.float32(0.9311), np.float32(0.8549), np.float32(0.788), np.float32(0.9646), np.float32(0.9314), np.float32(0.9511), np.float32(0.8849), np.float32(0.86), np.float32(0.7907), np.float32(0.7952), np.float32(0.7087), np.float32(0.9063), np.float32(0.8559)] 
2025-03-21 03:35:07.141181: Epoch time: 43.13 s 
2025-03-21 03:35:07.809343:  
2025-03-21 03:35:07.816906: Epoch 994 
2025-03-21 03:35:07.820442: Current learning rate: 0.0001 
2025-03-21 03:35:50.968512: train_loss -0.5093 
2025-03-21 03:35:50.975027: val_loss -0.4796 
2025-03-21 03:35:50.978537: Pseudo dice [np.float32(0.94), np.float32(0.9494), np.float32(0.961), np.float32(0.8854), np.float32(0.7936), np.float32(0.9571), np.float32(0.8963), np.float32(0.9495), np.float32(0.9002), np.float32(0.8653), np.float32(0.7821), np.float32(0.7508), np.float32(0.7819), np.float32(0.9129), np.float32(0.7888)] 
2025-03-21 03:35:50.982545: Epoch time: 43.16 s 
2025-03-21 03:35:51.800926:  
2025-03-21 03:35:51.806494: Epoch 995 
2025-03-21 03:35:51.810069: Current learning rate: 8e-05 
2025-03-21 03:36:35.080011: train_loss -0.5055 
2025-03-21 03:36:35.087561: val_loss -0.4544 
2025-03-21 03:36:35.091069: Pseudo dice [np.float32(0.9583), np.float32(0.927), np.float32(0.8987), np.float32(0.8405), np.float32(0.807), np.float32(0.9625), np.float32(0.8547), np.float32(0.9523), np.float32(0.8992), np.float32(0.8669), np.float32(0.7607), np.float32(0.7671), np.float32(0.8093), np.float32(0.9338), np.float32(0.7466)] 
2025-03-21 03:36:35.095078: Epoch time: 43.28 s 
2025-03-21 03:36:35.746587:  
2025-03-21 03:36:35.752656: Epoch 996 
2025-03-21 03:36:35.756725: Current learning rate: 7e-05 
2025-03-21 03:37:18.957529: train_loss -0.4978 
2025-03-21 03:37:18.964039: val_loss -0.466 
2025-03-21 03:37:18.968548: Pseudo dice [np.float32(0.8763), np.float32(0.9481), np.float32(0.9471), np.float32(0.8927), np.float32(0.7559), np.float32(0.961), np.float32(0.918), np.float32(0.9458), np.float32(0.8993), np.float32(0.8842), np.float32(0.7497), np.float32(0.7917), np.float32(0.7945), np.float32(0.9182), np.float32(0.9132)] 
2025-03-21 03:37:18.971557: Epoch time: 43.21 s 
2025-03-21 03:37:19.614908:  
2025-03-21 03:37:19.620515: Epoch 997 
2025-03-21 03:37:19.624565: Current learning rate: 5e-05 
2025-03-21 03:38:02.763354: train_loss -0.4894 
2025-03-21 03:38:02.767863: val_loss -0.4639 
2025-03-21 03:38:02.770871: Pseudo dice [np.float32(0.9571), np.float32(0.9279), np.float32(0.9328), np.float32(0.8928), np.float32(0.8024), np.float32(0.9732), np.float32(0.9368), np.float32(0.9509), np.float32(0.8911), np.float32(0.8668), np.float32(0.7502), np.float32(0.7752), np.float32(0.7915), np.float32(0.8781), np.float32(0.8488)] 
2025-03-21 03:38:02.773377: Epoch time: 43.15 s 
2025-03-21 03:38:03.418704:  
2025-03-21 03:38:03.425313: Epoch 998 
2025-03-21 03:38:03.429374: Current learning rate: 4e-05 
2025-03-21 03:38:46.529785: train_loss -0.519 
2025-03-21 03:38:46.537302: val_loss -0.4988 
2025-03-21 03:38:46.541309: Pseudo dice [np.float32(0.9621), np.float32(0.943), np.float32(0.9559), np.float32(0.8778), np.float32(0.8416), np.float32(0.9726), np.float32(0.9171), np.float32(0.947), np.float32(0.8946), np.float32(0.8636), np.float32(0.7847), np.float32(0.8201), np.float32(0.7748), np.float32(0.8626), np.float32(0.8585)] 
2025-03-21 03:38:46.545818: Epoch time: 43.11 s 
2025-03-21 03:38:47.205309:  
2025-03-21 03:38:47.211913: Epoch 999 
2025-03-21 03:38:47.215948: Current learning rate: 2e-05 
2025-03-21 03:39:30.396711: train_loss -0.4958 
2025-03-21 03:39:30.403299: val_loss -0.4762 
2025-03-21 03:39:30.406834: Pseudo dice [np.float32(0.9571), np.float32(0.9504), np.float32(0.9506), np.float32(0.903), np.float32(0.8174), np.float32(0.9601), np.float32(0.9398), np.float32(0.9485), np.float32(0.8767), np.float32(0.8861), np.float32(0.7651), np.float32(0.7737), np.float32(0.7814), np.float32(0.5006), np.float32(0.8096)] 
2025-03-21 03:39:30.410864: Epoch time: 43.19 s 
2025-03-21 03:39:31.258200: Training done. 
2025-03-21 03:39:31.295714: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset219_AMOS2022_postChallenge_task2\splits_final.json 
2025-03-21 03:39:31.303715: The split file contains 5 splits. 
2025-03-21 03:39:31.310714: Desired fold for training: 1 
2025-03-21 03:39:31.314714: This split has 288 training and 72 validation cases. 
2025-03-21 03:39:31.322715: predicting amos_0006 
2025-03-21 03:39:31.331713: amos_0006, shape torch.Size([1, 495, 428, 428]), rank 0 
2025-03-21 03:40:14.452323: predicting amos_0011 
2025-03-21 03:40:14.490327: amos_0011, shape torch.Size([1, 460, 400, 400]), rank 0 
2025-03-21 03:40:57.318878: predicting amos_0018 
2025-03-21 03:40:57.367878: amos_0018, shape torch.Size([1, 520, 433, 433]), rank 0 
2025-03-21 03:41:46.251260: predicting amos_0021 
2025-03-21 03:41:46.314265: amos_0021, shape torch.Size([1, 620, 457, 457]), rank 0 
2025-03-21 03:42:57.912728: predicting amos_0027 
2025-03-21 03:42:57.984239: amos_0027, shape torch.Size([1, 620, 400, 400]), rank 0 
2025-03-21 03:43:52.952311: predicting amos_0040 
2025-03-21 03:43:52.999311: amos_0040, shape torch.Size([1, 500, 400, 400]), rank 0 
2025-03-21 03:44:35.678888: predicting amos_0043 
2025-03-21 03:44:35.744161: amos_0043, shape torch.Size([1, 425, 432, 432]), rank 0 
2025-03-21 03:45:12.337937: predicting amos_0054 
2025-03-21 03:45:12.384447: amos_0054, shape torch.Size([1, 450, 468, 468]), rank 0 
2025-03-21 03:46:08.127220: predicting amos_0058 
2025-03-21 03:46:08.175224: amos_0058, shape torch.Size([1, 475, 460, 460]), rank 0 
2025-03-21 03:47:03.882972: predicting amos_0059 
2025-03-21 03:47:03.924481: amos_0059, shape torch.Size([1, 390, 400, 400]), rank 0 
2025-03-21 03:47:40.446968: predicting amos_0060 
2025-03-21 03:47:40.489970: amos_0060, shape torch.Size([1, 560, 405, 405]), rank 0 
2025-03-21 03:48:30.755784: predicting amos_0069 
2025-03-21 03:48:30.784784: amos_0069, shape torch.Size([1, 490, 410, 410]), rank 0 
2025-03-21 03:49:13.471334: predicting amos_0070 
2025-03-21 03:49:13.528334: amos_0070, shape torch.Size([1, 515, 402, 402]), rank 0 
2025-03-21 03:50:02.106329: predicting amos_0073 
2025-03-21 03:50:02.163839: amos_0073, shape torch.Size([1, 455, 400, 400]), rank 0 
2025-03-21 03:50:45.084564: predicting amos_0086 
2025-03-21 03:50:45.125566: amos_0086, shape torch.Size([1, 400, 439, 439]), rank 0 
2025-03-21 03:51:21.865760: predicting amos_0090 
2025-03-21 03:51:21.931844: amos_0090, shape torch.Size([1, 480, 531, 531]), rank 0 
2025-03-21 03:52:32.480830: predicting amos_0098 
2025-03-21 03:52:32.547833: amos_0098, shape torch.Size([1, 485, 400, 400]), rank 0 
2025-03-21 03:53:15.264955: predicting amos_0117 
2025-03-21 03:53:15.301955: amos_0117, shape torch.Size([1, 515, 390, 390]), rank 0 
2025-03-21 03:53:51.156536: predicting amos_0129 
2025-03-21 03:53:51.202048: amos_0129, shape torch.Size([1, 620, 400, 400]), rank 0 
2025-03-21 03:54:45.978704: predicting amos_0147 
2025-03-21 03:54:46.025213: amos_0147, shape torch.Size([1, 475, 398, 398]), rank 0 
2025-03-21 03:55:28.513546: predicting amos_0154 
2025-03-21 03:55:28.554551: amos_0154, shape torch.Size([1, 440, 400, 400]), rank 0 
2025-03-21 03:56:05.286790: predicting amos_0167 
2025-03-21 03:56:05.325790: amos_0167, shape torch.Size([1, 445, 400, 400]), rank 0 
2025-03-21 03:56:41.856603: predicting amos_0171 
2025-03-21 03:56:41.889606: amos_0171, shape torch.Size([1, 485, 500, 500]), rank 0 
2025-03-21 03:57:37.614834: predicting amos_0181 
2025-03-21 03:57:37.680339: amos_0181, shape torch.Size([1, 590, 443, 443]), rank 0 
2025-03-21 03:58:32.524329: predicting amos_0191 
2025-03-21 03:58:32.585835: amos_0191, shape torch.Size([1, 470, 390, 390]), rank 0 
2025-03-21 03:59:04.045044: predicting amos_0192 
2025-03-21 03:59:04.092045: amos_0192, shape torch.Size([1, 615, 400, 400]), rank 0 
2025-03-21 04:00:00.209362: predicting amos_0195 
2025-03-21 04:00:00.236362: amos_0195, shape torch.Size([1, 670, 488, 488]), rank 0 
2025-03-21 04:01:20.291810: predicting amos_0197 
2025-03-21 04:01:20.396321: amos_0197, shape torch.Size([1, 690, 344, 344]), rank 0 
2025-03-21 04:02:05.183072: predicting amos_0202 
2025-03-21 04:02:05.242072: amos_0202, shape torch.Size([1, 440, 394, 394]), rank 0 
2025-03-21 04:02:41.804614: predicting amos_0206 
2025-03-21 04:02:41.857615: amos_0206, shape torch.Size([1, 604, 313, 313]), rank 0 
2025-03-21 04:03:10.016919: predicting amos_0212 
2025-03-21 04:03:10.052918: amos_0212, shape torch.Size([1, 430, 279, 279]), rank 0 
2025-03-21 04:03:22.136487: predicting amos_0214 
2025-03-21 04:03:22.164487: amos_0214, shape torch.Size([1, 666, 436, 436]), rank 0 
2025-03-21 04:04:24.136642: predicting amos_0217 
2025-03-21 04:04:24.213151: amos_0217, shape torch.Size([1, 612, 352, 352]), rank 0 
2025-03-21 04:05:04.558406: predicting amos_0225 
2025-03-21 04:05:04.611916: amos_0225, shape torch.Size([1, 428, 289, 289]), rank 0 
2025-03-21 04:05:23.391907: predicting amos_0226 
2025-03-21 04:05:23.421413: amos_0226, shape torch.Size([1, 606, 316, 316]), rank 0 
2025-03-21 04:05:51.432349: predicting amos_0228 
2025-03-21 04:05:51.470349: amos_0228, shape torch.Size([1, 594, 349, 349]), rank 0 
2025-03-21 04:06:31.736135: predicting amos_0244 
2025-03-21 04:06:31.796139: amos_0244, shape torch.Size([1, 610, 393, 393]), rank 0 
2025-03-21 04:07:26.704696: predicting amos_0268 
2025-03-21 04:07:26.752202: amos_0268, shape torch.Size([1, 382, 332, 332]), rank 0 
2025-03-21 04:07:42.593490: predicting amos_0279 
2025-03-21 04:07:42.624000: amos_0279, shape torch.Size([1, 441, 360, 360]), rank 0 
2025-03-21 04:08:09.474992: predicting amos_0299 
2025-03-21 04:08:09.504992: amos_0299, shape torch.Size([1, 408, 399, 399]), rank 0 
2025-03-21 04:08:45.982809: predicting amos_0301 
2025-03-21 04:08:46.020812: amos_0301, shape torch.Size([1, 478, 382, 382]), rank 0 
2025-03-21 04:09:17.422535: predicting amos_0304 
2025-03-21 04:09:17.469042: amos_0304, shape torch.Size([1, 350, 330, 330]), rank 0 
2025-03-21 04:09:33.198495: predicting amos_0313 
2025-03-21 04:09:33.230498: amos_0313, shape torch.Size([1, 460, 371, 371]), rank 0 
2025-03-21 04:10:04.485588: predicting amos_0317 
2025-03-21 04:10:04.527591: amos_0317, shape torch.Size([1, 436, 315, 315]), rank 0 
2025-03-21 04:10:23.405977: predicting amos_0321 
2025-03-21 04:10:23.438980: amos_0321, shape torch.Size([1, 384, 368, 368]), rank 0 
2025-03-21 04:10:45.911536: predicting amos_0330 
2025-03-21 04:10:45.950046: amos_0330, shape torch.Size([1, 460, 318, 318]), rank 0 
2025-03-21 04:11:07.763263: predicting amos_0334 
2025-03-21 04:11:07.790263: amos_0334, shape torch.Size([1, 590, 279, 279]), rank 0 
2025-03-21 04:11:25.850064: predicting amos_0339 
2025-03-21 04:11:25.884571: amos_0339, shape torch.Size([1, 436, 299, 299]), rank 0 
2025-03-21 04:11:44.576150: predicting amos_0341 
2025-03-21 04:11:44.607149: amos_0341, shape torch.Size([1, 605, 312, 312]), rank 0 
2025-03-21 04:12:12.619851: predicting amos_0342 
2025-03-21 04:12:12.654857: amos_0342, shape torch.Size([1, 610, 315, 315]), rank 0 
2025-03-21 04:12:40.654448: predicting amos_0348 
2025-03-21 04:12:40.697956: amos_0348, shape torch.Size([1, 634, 346, 346]), rank 0 
2025-03-21 04:13:21.050733: predicting amos_0349 
2025-03-21 04:13:21.111244: amos_0349, shape torch.Size([1, 500, 360, 360]), rank 0 
2025-03-21 04:13:52.588414: predicting amos_0353 
2025-03-21 04:13:52.627414: amos_0353, shape torch.Size([1, 434, 333, 333]), rank 0 
2025-03-21 04:14:11.517084: predicting amos_0367 
2025-03-21 04:14:11.551084: amos_0367, shape torch.Size([1, 455, 500, 500]), rank 0 
2025-03-21 04:15:07.238753: predicting amos_0372 
2025-03-21 04:15:07.301264: amos_0372, shape torch.Size([1, 485, 446, 446]), rank 0 
2025-03-21 04:15:50.103883: predicting amos_0377 
2025-03-21 04:15:50.141886: amos_0377, shape torch.Size([1, 460, 344, 344]), rank 0 
2025-03-21 04:16:21.363147: predicting amos_0387 
2025-03-21 04:16:21.397147: amos_0387, shape torch.Size([1, 525, 447, 447]), rank 0 
2025-03-21 04:17:10.583774: predicting amos_0390 
2025-03-21 04:17:10.880304: amos_0390, shape torch.Size([1, 495, 477, 477]), rank 0 
2025-03-21 04:18:07.236310: predicting amos_0396 
2025-03-21 04:18:07.314823: amos_0396, shape torch.Size([1, 430, 494, 494]), rank 0 
2025-03-21 04:18:56.443975: predicting amos_0400 
2025-03-21 04:18:56.498977: amos_0400, shape torch.Size([1, 395, 359, 359]), rank 0 
2025-03-21 04:19:27.316786: predicting amos_0410 
2025-03-21 04:19:27.365294: amos_0410, shape torch.Size([1, 535, 448, 448]), rank 0 
2025-03-21 04:20:16.419046: predicting amos_0552 
2025-03-21 04:20:17.155190: amos_0552, shape torch.Size([1, 216, 306, 379]), rank 0 
2025-03-21 04:20:30.212486: predicting amos_0556 
2025-03-21 04:20:30.237486: amos_0556, shape torch.Size([1, 216, 319, 399]), rank 0 
2025-03-21 04:20:43.439032: predicting amos_0558 
2025-03-21 04:20:43.466031: amos_0558, shape torch.Size([1, 387, 185, 420]), rank 0 
2025-03-21 04:20:59.304692: predicting amos_0561 
2025-03-21 04:20:59.329692: amos_0561, shape torch.Size([1, 216, 319, 399]), rank 0 
2025-03-21 04:21:12.461513: predicting amos_0562 
2025-03-21 04:21:12.485513: amos_0562, shape torch.Size([1, 379, 180, 379]), rank 0 
2025-03-21 04:21:23.766657: predicting amos_0573 
2025-03-21 04:21:23.796660: amos_0573, shape torch.Size([1, 216, 305, 378]), rank 0 
2025-03-21 04:21:35.161076: predicting amos_0581 
2025-03-21 04:21:35.183076: amos_0581, shape torch.Size([1, 216, 324, 399]), rank 0 
2025-03-21 04:21:48.419850: predicting amos_0583 
2025-03-21 04:21:48.443357: amos_0583, shape torch.Size([1, 379, 180, 379]), rank 0 
2025-03-21 04:21:59.681400: predicting amos_0588 
2025-03-21 04:21:59.708401: amos_0588, shape torch.Size([1, 407, 185, 420]), rank 0 
2025-03-21 04:22:15.469111: predicting amos_0590 
2025-03-21 04:22:15.494112: amos_0590, shape torch.Size([1, 408, 185, 418]), rank 0 
2025-03-21 04:22:31.211392: predicting amos_0600 
2025-03-21 04:22:31.232392: amos_0600, shape torch.Size([1, 216, 306, 379]), rank 0 
