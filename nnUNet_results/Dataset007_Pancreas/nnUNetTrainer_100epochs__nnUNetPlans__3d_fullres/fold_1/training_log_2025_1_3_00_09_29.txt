
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-03 00:09:29.009988: do_dummy_2d_data_aug: True 
2025-01-03 00:09:29.012988: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-03 00:09:29.016987: The split file contains 5 splits. 
2025-01-03 00:09:29.019986: Desired fold for training: 1 
2025-01-03 00:09:29.021986: This split has 225 training and 56 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-03 00:09:36.376971: unpacking dataset... 
2025-01-03 00:09:36.588433: unpacking done... 
2025-01-03 00:09:39.575523:  
2025-01-03 00:09:39.575523: Epoch 0 
2025-01-03 00:09:39.581540: Current learning rate: 0.01 
2025-01-03 00:10:25.198092: train_loss 0.1288 
2025-01-03 00:10:25.198594: val_loss 0.0607 
2025-01-03 00:10:25.204618: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-03 00:10:25.209630: Epoch time: 45.62 s 
2025-01-03 00:10:25.211730: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-03 00:10:25.907416:  
2025-01-03 00:10:25.907416: Epoch 1 
2025-01-03 00:10:25.914944: Current learning rate: 0.00991 
2025-01-03 00:11:07.470776: train_loss 0.0453 
2025-01-03 00:11:07.471293: val_loss 0.055 
2025-01-03 00:11:07.478371: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-03 00:11:07.483397: Epoch time: 41.56 s 
2025-01-03 00:11:07.994547:  
2025-01-03 00:11:07.995052: Epoch 2 
2025-01-03 00:11:08.000075: Current learning rate: 0.00982 
2025-01-03 00:11:50.045975: train_loss -0.0113 
2025-01-03 00:11:50.046975: val_loss -0.0583 
2025-01-03 00:11:50.052497: Pseudo dice [np.float32(0.3295), np.float32(0.0)] 
2025-01-03 00:11:50.056010: Epoch time: 42.05 s 
2025-01-03 00:11:50.058518: Yayy! New best EMA pseudo Dice: 0.016499999910593033 
2025-01-03 00:11:50.890923:  
2025-01-03 00:11:50.890923: Epoch 3 
2025-01-03 00:11:50.895936: Current learning rate: 0.00973 
2025-01-03 00:12:33.627897: train_loss -0.0714 
2025-01-03 00:12:33.627897: val_loss -0.0676 
2025-01-03 00:12:33.633911: Pseudo dice [np.float32(0.3189), np.float32(0.0)] 
2025-01-03 00:12:33.637921: Epoch time: 42.74 s 
2025-01-03 00:12:33.641430: Yayy! New best EMA pseudo Dice: 0.030799999833106995 
2025-01-03 00:12:34.450276:  
2025-01-03 00:12:34.450276: Epoch 4 
2025-01-03 00:12:34.455299: Current learning rate: 0.00964 
2025-01-03 00:13:15.993536: train_loss -0.1132 
2025-01-03 00:13:15.994038: val_loss -0.1292 
2025-01-03 00:13:15.999067: Pseudo dice [np.float32(0.4112), np.float32(0.0)] 
2025-01-03 00:13:16.003090: Epoch time: 41.54 s 
2025-01-03 00:13:16.006610: Yayy! New best EMA pseudo Dice: 0.04830000177025795 
2025-01-03 00:13:16.971529:  
2025-01-03 00:13:16.972032: Epoch 5 
2025-01-03 00:13:16.976583: Current learning rate: 0.00955 
2025-01-03 00:13:58.743891: train_loss -0.1448 
2025-01-03 00:13:58.744894: val_loss -0.1476 
2025-01-03 00:13:58.749905: Pseudo dice [np.float32(0.4293), np.float32(0.0)] 
2025-01-03 00:13:58.753912: Epoch time: 41.77 s 
2025-01-03 00:13:58.756418: Yayy! New best EMA pseudo Dice: 0.0649000033736229 
2025-01-03 00:13:59.570542:  
2025-01-03 00:13:59.571044: Epoch 6 
2025-01-03 00:13:59.577059: Current learning rate: 0.00946 
2025-01-03 00:14:41.708149: train_loss -0.1746 
2025-01-03 00:14:41.709152: val_loss -0.1759 
2025-01-03 00:14:41.715669: Pseudo dice [np.float32(0.46), np.float32(0.0)] 
2025-01-03 00:14:41.719180: Epoch time: 42.14 s 
2025-01-03 00:14:41.723191: Yayy! New best EMA pseudo Dice: 0.08139999955892563 
2025-01-03 00:14:42.543945:  
2025-01-03 00:14:42.543945: Epoch 7 
2025-01-03 00:14:42.549479: Current learning rate: 0.00937 
2025-01-03 00:15:24.356736: train_loss -0.2077 
2025-01-03 00:15:24.357244: val_loss -0.2222 
2025-01-03 00:15:24.362828: Pseudo dice [np.float32(0.5253), np.float32(0.0)] 
2025-01-03 00:15:24.366354: Epoch time: 41.81 s 
2025-01-03 00:15:24.369893: Yayy! New best EMA pseudo Dice: 0.09950000047683716 
2025-01-03 00:15:25.187485:  
2025-01-03 00:15:25.187485: Epoch 8 
2025-01-03 00:15:25.193579: Current learning rate: 0.00928 
2025-01-03 00:16:06.818403: train_loss -0.2053 
2025-01-03 00:16:06.819402: val_loss -0.2133 
2025-01-03 00:16:06.826922: Pseudo dice [np.float32(0.5139), np.float32(0.0)] 
2025-01-03 00:16:06.829930: Epoch time: 41.63 s 
2025-01-03 00:16:06.832435: Yayy! New best EMA pseudo Dice: 0.1152999997138977 
2025-01-03 00:16:07.674481:  
2025-01-03 00:16:07.674481: Epoch 9 
2025-01-03 00:16:07.680517: Current learning rate: 0.00919 
2025-01-03 00:16:49.134053: train_loss -0.247 
2025-01-03 00:16:49.134555: val_loss -0.2385 
2025-01-03 00:16:49.140093: Pseudo dice [np.float32(0.5434), np.float32(0.0)] 
2025-01-03 00:16:49.143134: Epoch time: 41.46 s 
2025-01-03 00:16:49.145213: Yayy! New best EMA pseudo Dice: 0.13089999556541443 
2025-01-03 00:16:49.910822:  
2025-01-03 00:16:49.910822: Epoch 10 
2025-01-03 00:16:49.916373: Current learning rate: 0.0091 
2025-01-03 00:17:31.026083: train_loss -0.2823 
2025-01-03 00:17:31.026083: val_loss -0.2349 
2025-01-03 00:17:31.032099: Pseudo dice [np.float32(0.4708), np.float32(0.2484)] 
2025-01-03 00:17:31.035611: Epoch time: 41.12 s 
2025-01-03 00:17:31.038619: Yayy! New best EMA pseudo Dice: 0.15379999577999115 
2025-01-03 00:17:31.834645:  
2025-01-03 00:17:31.835644: Epoch 11 
2025-01-03 00:17:31.841269: Current learning rate: 0.009 
2025-01-03 00:18:13.288168: train_loss -0.2751 
2025-01-03 00:18:13.289171: val_loss -0.284 
2025-01-03 00:18:13.295255: Pseudo dice [np.float32(0.4712), np.float32(0.3198)] 
2025-01-03 00:18:13.298869: Epoch time: 41.45 s 
2025-01-03 00:18:13.301908: Yayy! New best EMA pseudo Dice: 0.17800000309944153 
2025-01-03 00:18:14.073506:  
2025-01-03 00:18:14.074008: Epoch 12 
2025-01-03 00:18:14.079021: Current learning rate: 0.00891 
2025-01-03 00:18:55.197721: train_loss -0.2972 
2025-01-03 00:18:55.197721: val_loss -0.2666 
2025-01-03 00:18:55.204787: Pseudo dice [np.float32(0.4964), np.float32(0.1897)] 
2025-01-03 00:18:55.207293: Epoch time: 41.13 s 
2025-01-03 00:18:55.210802: Yayy! New best EMA pseudo Dice: 0.19449999928474426 
2025-01-03 00:18:56.183207:  
2025-01-03 00:18:56.183207: Epoch 13 
2025-01-03 00:18:56.188796: Current learning rate: 0.00882 
2025-01-03 00:19:37.302498: train_loss -0.3044 
2025-01-03 00:19:37.304000: val_loss -0.3088 
2025-01-03 00:19:37.309029: Pseudo dice [np.float32(0.5276), np.float32(0.3268)] 
2025-01-03 00:19:37.311676: Epoch time: 41.12 s 
2025-01-03 00:19:37.315725: Yayy! New best EMA pseudo Dice: 0.21770000457763672 
2025-01-03 00:19:38.121187:  
2025-01-03 00:19:38.122193: Epoch 14 
2025-01-03 00:19:38.127743: Current learning rate: 0.00873 
2025-01-03 00:20:19.280208: train_loss -0.2996 
2025-01-03 00:20:19.281300: val_loss -0.2625 
2025-01-03 00:20:19.286906: Pseudo dice [np.float32(0.3931), np.float32(0.3637)] 
2025-01-03 00:20:19.290431: Epoch time: 41.16 s 
2025-01-03 00:20:19.293456: Yayy! New best EMA pseudo Dice: 0.2337999939918518 
2025-01-03 00:20:20.102132:  
2025-01-03 00:20:20.102132: Epoch 15 
2025-01-03 00:20:20.108356: Current learning rate: 0.00864 
2025-01-03 00:21:01.233628: train_loss -0.3274 
2025-01-03 00:21:01.233628: val_loss -0.29 
2025-01-03 00:21:01.241144: Pseudo dice [np.float32(0.5615), np.float32(0.2009)] 
2025-01-03 00:21:01.244653: Epoch time: 41.13 s 
2025-01-03 00:21:01.248158: Yayy! New best EMA pseudo Dice: 0.2485000044107437 
2025-01-03 00:21:02.065663:  
2025-01-03 00:21:02.066666: Epoch 16 
2025-01-03 00:21:02.071694: Current learning rate: 0.00855 
2025-01-03 00:21:43.187075: train_loss -0.3433 
2025-01-03 00:21:43.187075: val_loss -0.3345 
2025-01-03 00:21:43.193089: Pseudo dice [np.float32(0.5784), np.float32(0.2551)] 
2025-01-03 00:21:43.197096: Epoch time: 41.12 s 
2025-01-03 00:21:43.200608: Yayy! New best EMA pseudo Dice: 0.2653999924659729 
2025-01-03 00:21:44.002805:  
2025-01-03 00:21:44.003808: Epoch 17 
2025-01-03 00:21:44.009344: Current learning rate: 0.00846 
2025-01-03 00:22:25.107420: train_loss -0.3383 
2025-01-03 00:22:25.108420: val_loss -0.3028 
2025-01-03 00:22:25.114024: Pseudo dice [np.float32(0.5191), np.float32(0.263)] 
2025-01-03 00:22:25.117533: Epoch time: 41.1 s 
2025-01-03 00:22:25.121541: Yayy! New best EMA pseudo Dice: 0.27790001034736633 
2025-01-03 00:22:25.939238:  
2025-01-03 00:22:25.939238: Epoch 18 
2025-01-03 00:22:25.944841: Current learning rate: 0.00836 
2025-01-03 00:23:07.508661: train_loss -0.3509 
2025-01-03 00:23:07.510165: val_loss -0.3509 
2025-01-03 00:23:07.517189: Pseudo dice [np.float32(0.541), np.float32(0.3155)] 
2025-01-03 00:23:07.520202: Epoch time: 41.57 s 
2025-01-03 00:23:07.523713: Yayy! New best EMA pseudo Dice: 0.2930000126361847 
2025-01-03 00:23:08.372376:  
2025-01-03 00:23:08.372879: Epoch 19 
2025-01-03 00:23:08.377892: Current learning rate: 0.00827 
2025-01-03 00:23:49.538757: train_loss -0.3719 
2025-01-03 00:23:49.539259: val_loss -0.361 
2025-01-03 00:23:49.545273: Pseudo dice [np.float32(0.5654), np.float32(0.3091)] 
2025-01-03 00:23:49.548778: Epoch time: 41.17 s 
2025-01-03 00:23:49.551786: Yayy! New best EMA pseudo Dice: 0.3073999881744385 
2025-01-03 00:23:50.343171:  
2025-01-03 00:23:50.343673: Epoch 20 
2025-01-03 00:23:50.348685: Current learning rate: 0.00818 
2025-01-03 00:24:31.438233: train_loss -0.3621 
2025-01-03 00:24:31.439742: val_loss -0.3236 
2025-01-03 00:24:31.445944: Pseudo dice [np.float32(0.5072), np.float32(0.2982)] 
2025-01-03 00:24:31.448988: Epoch time: 41.1 s 
2025-01-03 00:24:31.451003: Yayy! New best EMA pseudo Dice: 0.31690001487731934 
2025-01-03 00:24:32.420699:  
2025-01-03 00:24:32.421699: Epoch 21 
2025-01-03 00:24:32.427287: Current learning rate: 0.00809 
2025-01-03 00:25:13.497639: train_loss -0.376 
2025-01-03 00:25:13.499141: val_loss -0.3202 
2025-01-03 00:25:13.506155: Pseudo dice [np.float32(0.5743), np.float32(0.2049)] 
2025-01-03 00:25:13.509165: Epoch time: 41.08 s 
2025-01-03 00:25:13.512674: Yayy! New best EMA pseudo Dice: 0.32420000433921814 
2025-01-03 00:25:14.275902:  
2025-01-03 00:25:14.276417: Epoch 22 
2025-01-03 00:25:14.281542: Current learning rate: 0.008 
2025-01-03 00:25:55.345921: train_loss -0.3975 
2025-01-03 00:25:55.346935: val_loss -0.3739 
2025-01-03 00:25:55.351943: Pseudo dice [np.float32(0.5741), np.float32(0.2706)] 
2025-01-03 00:25:55.355450: Epoch time: 41.07 s 
2025-01-03 00:25:55.359461: Yayy! New best EMA pseudo Dice: 0.33399999141693115 
2025-01-03 00:25:56.155457:  
2025-01-03 00:25:56.155959: Epoch 23 
2025-01-03 00:25:56.160971: Current learning rate: 0.0079 
2025-01-03 00:26:37.238452: train_loss -0.4003 
2025-01-03 00:26:37.238957: val_loss -0.3983 
2025-01-03 00:26:37.245052: Pseudo dice [np.float32(0.635), np.float32(0.358)] 
2025-01-03 00:26:37.247557: Epoch time: 41.08 s 
2025-01-03 00:26:37.251066: Yayy! New best EMA pseudo Dice: 0.35030001401901245 
2025-01-03 00:26:38.036247:  
2025-01-03 00:26:38.036247: Epoch 24 
2025-01-03 00:26:38.041760: Current learning rate: 0.00781 
2025-01-03 00:27:19.101033: train_loss -0.4215 
2025-01-03 00:27:19.101535: val_loss -0.3835 
2025-01-03 00:27:19.107678: Pseudo dice [np.float32(0.5667), np.float32(0.3659)] 
2025-01-03 00:27:19.110230: Epoch time: 41.07 s 
2025-01-03 00:27:19.113750: Yayy! New best EMA pseudo Dice: 0.3619000017642975 
2025-01-03 00:27:19.913297:  
2025-01-03 00:27:19.914300: Epoch 25 
2025-01-03 00:27:19.920367: Current learning rate: 0.00772 
2025-01-03 00:28:01.005828: train_loss -0.4058 
2025-01-03 00:28:01.007728: val_loss -0.37 
2025-01-03 00:28:01.014276: Pseudo dice [np.float32(0.5896), np.float32(0.2623)] 
2025-01-03 00:28:01.018284: Epoch time: 41.09 s 
2025-01-03 00:28:01.021792: Yayy! New best EMA pseudo Dice: 0.3682999908924103 
2025-01-03 00:28:01.848122:  
2025-01-03 00:28:01.849127: Epoch 26 
2025-01-03 00:28:01.854219: Current learning rate: 0.00763 
2025-01-03 00:28:42.755504: train_loss -0.4084 
2025-01-03 00:28:42.755504: val_loss -0.3756 
2025-01-03 00:28:42.762101: Pseudo dice [np.float32(0.5688), np.float32(0.3982)] 
2025-01-03 00:28:42.765695: Epoch time: 40.91 s 
2025-01-03 00:28:42.769807: Yayy! New best EMA pseudo Dice: 0.3797999918460846 
2025-01-03 00:28:43.576106:  
2025-01-03 00:28:43.576106: Epoch 27 
2025-01-03 00:28:43.581636: Current learning rate: 0.00753 
2025-01-03 00:29:24.510174: train_loss -0.4169 
2025-01-03 00:29:24.510174: val_loss -0.3365 
2025-01-03 00:29:24.517235: Pseudo dice [np.float32(0.5893), np.float32(0.2506)] 
2025-01-03 00:29:24.520280: Epoch time: 40.94 s 
2025-01-03 00:29:24.523844: Yayy! New best EMA pseudo Dice: 0.3837999999523163 
2025-01-03 00:29:25.290154:  
2025-01-03 00:29:25.290669: Epoch 28 
2025-01-03 00:29:25.295713: Current learning rate: 0.00744 
2025-01-03 00:30:06.200377: train_loss -0.405 
2025-01-03 00:30:06.200889: val_loss -0.3256 
2025-01-03 00:30:06.208475: Pseudo dice [np.float32(0.5538), np.float32(0.2646)] 
2025-01-03 00:30:06.210648: Epoch time: 40.91 s 
2025-01-03 00:30:06.215248: Yayy! New best EMA pseudo Dice: 0.3862999975681305 
2025-01-03 00:30:07.003602:  
2025-01-03 00:30:07.003602: Epoch 29 
2025-01-03 00:30:07.009676: Current learning rate: 0.00735 
2025-01-03 00:30:47.896379: train_loss -0.419 
2025-01-03 00:30:47.896890: val_loss -0.4136 
2025-01-03 00:30:47.901961: Pseudo dice [np.float32(0.6377), np.float32(0.3936)] 
2025-01-03 00:30:47.905485: Epoch time: 40.89 s 
2025-01-03 00:30:47.909069: Yayy! New best EMA pseudo Dice: 0.3993000090122223 
2025-01-03 00:30:48.913635:  
2025-01-03 00:30:48.913635: Epoch 30 
2025-01-03 00:30:48.918664: Current learning rate: 0.00725 
2025-01-03 00:31:29.815729: train_loss -0.4544 
2025-01-03 00:31:29.817307: val_loss -0.4217 
2025-01-03 00:31:29.822862: Pseudo dice [np.float32(0.6238), np.float32(0.2905)] 
2025-01-03 00:31:29.826375: Epoch time: 40.9 s 
2025-01-03 00:31:29.830470: Yayy! New best EMA pseudo Dice: 0.4050999879837036 
2025-01-03 00:31:30.612653:  
2025-01-03 00:31:30.612653: Epoch 31 
2025-01-03 00:31:30.618784: Current learning rate: 0.00716 
2025-01-03 00:32:11.500160: train_loss -0.4433 
2025-01-03 00:32:11.501666: val_loss -0.3436 
2025-01-03 00:32:11.507735: Pseudo dice [np.float32(0.5974), np.float32(0.2773)] 
2025-01-03 00:32:11.511763: Epoch time: 40.89 s 
2025-01-03 00:32:11.515295: Yayy! New best EMA pseudo Dice: 0.4083000123500824 
2025-01-03 00:32:12.331994:  
2025-01-03 00:32:12.331994: Epoch 32 
2025-01-03 00:32:12.339545: Current learning rate: 0.00707 
2025-01-03 00:32:53.228367: train_loss -0.4454 
2025-01-03 00:32:53.228871: val_loss -0.3954 
2025-01-03 00:32:53.234895: Pseudo dice [np.float32(0.6062), np.float32(0.3543)] 
2025-01-03 00:32:53.238909: Epoch time: 40.9 s 
2025-01-03 00:32:53.242419: Yayy! New best EMA pseudo Dice: 0.4154999852180481 
2025-01-03 00:32:54.067334:  
2025-01-03 00:32:54.067334: Epoch 33 
2025-01-03 00:32:54.073368: Current learning rate: 0.00697 
2025-01-03 00:33:34.967492: train_loss -0.4627 
2025-01-03 00:33:34.969005: val_loss -0.4231 
2025-01-03 00:33:34.975116: Pseudo dice [np.float32(0.6301), np.float32(0.3806)] 
2025-01-03 00:33:34.978155: Epoch time: 40.9 s 
2025-01-03 00:33:34.980175: Yayy! New best EMA pseudo Dice: 0.4244999885559082 
2025-01-03 00:33:35.745108:  
2025-01-03 00:33:35.745625: Epoch 34 
2025-01-03 00:33:35.750710: Current learning rate: 0.00688 
2025-01-03 00:34:16.695796: train_loss -0.4652 
2025-01-03 00:34:16.696299: val_loss -0.3875 
2025-01-03 00:34:16.702312: Pseudo dice [np.float32(0.6521), np.float32(0.2004)] 
2025-01-03 00:34:16.705817: Epoch time: 40.95 s 
2025-01-03 00:34:16.708825: Yayy! New best EMA pseudo Dice: 0.424699991941452 
2025-01-03 00:34:17.499906:  
2025-01-03 00:34:17.500415: Epoch 35 
2025-01-03 00:34:17.505461: Current learning rate: 0.00679 
2025-01-03 00:34:58.389911: train_loss -0.4423 
2025-01-03 00:34:58.391414: val_loss -0.4309 
2025-01-03 00:34:58.397431: Pseudo dice [np.float32(0.6683), np.float32(0.3363)] 
2025-01-03 00:34:58.401442: Epoch time: 40.89 s 
2025-01-03 00:34:58.404952: Yayy! New best EMA pseudo Dice: 0.4323999881744385 
2025-01-03 00:34:59.174700:  
2025-01-03 00:34:59.175702: Epoch 36 
2025-01-03 00:34:59.181283: Current learning rate: 0.00669 
2025-01-03 00:35:40.070662: train_loss -0.4793 
2025-01-03 00:35:40.071167: val_loss -0.4393 
2025-01-03 00:35:40.077201: Pseudo dice [np.float32(0.6818), np.float32(0.2691)] 
2025-01-03 00:35:40.081218: Epoch time: 40.9 s 
2025-01-03 00:35:40.085736: Yayy! New best EMA pseudo Dice: 0.4366999864578247 
2025-01-03 00:35:40.904473:  
2025-01-03 00:35:40.904473: Epoch 37 
2025-01-03 00:35:40.910492: Current learning rate: 0.0066 
2025-01-03 00:36:21.795858: train_loss -0.4862 
2025-01-03 00:36:21.795858: val_loss -0.4222 
2025-01-03 00:36:21.802377: Pseudo dice [np.float32(0.6343), np.float32(0.353)] 
2025-01-03 00:36:21.805480: Epoch time: 40.89 s 
2025-01-03 00:36:21.809524: Yayy! New best EMA pseudo Dice: 0.4424000084400177 
2025-01-03 00:36:22.724459:  
2025-01-03 00:36:22.724459: Epoch 38 
2025-01-03 00:36:22.729692: Current learning rate: 0.0065 
2025-01-03 00:37:03.612116: train_loss -0.4671 
2025-01-03 00:37:03.613626: val_loss -0.3686 
2025-01-03 00:37:03.620810: Pseudo dice [np.float32(0.6478), np.float32(0.1853)] 
2025-01-03 00:37:03.624500: Epoch time: 40.89 s 
2025-01-03 00:37:04.193349:  
2025-01-03 00:37:04.193349: Epoch 39 
2025-01-03 00:37:04.198952: Current learning rate: 0.00641 
2025-01-03 00:37:45.078354: train_loss -0.4948 
2025-01-03 00:37:45.078354: val_loss -0.43 
2025-01-03 00:37:45.084368: Pseudo dice [np.float32(0.6557), np.float32(0.3766)] 
2025-01-03 00:37:45.088376: Epoch time: 40.89 s 
2025-01-03 00:37:45.090882: Yayy! New best EMA pseudo Dice: 0.44749999046325684 
2025-01-03 00:37:45.918133:  
2025-01-03 00:37:45.918133: Epoch 40 
2025-01-03 00:37:45.924690: Current learning rate: 0.00631 
2025-01-03 00:38:26.819119: train_loss -0.4916 
2025-01-03 00:38:26.819622: val_loss -0.3867 
2025-01-03 00:38:26.825675: Pseudo dice [np.float32(0.6313), np.float32(0.3108)] 
2025-01-03 00:38:26.829345: Epoch time: 40.9 s 
2025-01-03 00:38:26.833059: Yayy! New best EMA pseudo Dice: 0.4498000144958496 
2025-01-03 00:38:27.721490:  
2025-01-03 00:38:27.721490: Epoch 41 
2025-01-03 00:38:27.727509: Current learning rate: 0.00622 
2025-01-03 00:39:08.617503: train_loss -0.5008 
2025-01-03 00:39:08.617503: val_loss -0.4309 
2025-01-03 00:39:08.624019: Pseudo dice [np.float32(0.6432), np.float32(0.2918)] 
2025-01-03 00:39:08.627530: Epoch time: 40.9 s 
2025-01-03 00:39:08.631544: Yayy! New best EMA pseudo Dice: 0.45159998536109924 
2025-01-03 00:39:09.389894:  
2025-01-03 00:39:09.390892: Epoch 42 
2025-01-03 00:39:09.395453: Current learning rate: 0.00612 
2025-01-03 00:39:50.267891: train_loss -0.4698 
2025-01-03 00:39:50.268895: val_loss -0.4213 
2025-01-03 00:39:50.275418: Pseudo dice [np.float32(0.6583), np.float32(0.2814)] 
2025-01-03 00:39:50.278928: Epoch time: 40.88 s 
2025-01-03 00:39:50.282939: Yayy! New best EMA pseudo Dice: 0.45339998602867126 
2025-01-03 00:39:51.079771:  
2025-01-03 00:39:51.079771: Epoch 43 
2025-01-03 00:39:51.086324: Current learning rate: 0.00603 
2025-01-03 00:40:31.985319: train_loss -0.4972 
2025-01-03 00:40:31.985319: val_loss -0.4324 
2025-01-03 00:40:31.991335: Pseudo dice [np.float32(0.6696), np.float32(0.3056)] 
2025-01-03 00:40:31.995347: Epoch time: 40.91 s 
2025-01-03 00:40:31.998859: Yayy! New best EMA pseudo Dice: 0.45680001378059387 
2025-01-03 00:40:32.810381:  
2025-01-03 00:40:32.811381: Epoch 44 
2025-01-03 00:40:32.817038: Current learning rate: 0.00593 
2025-01-03 00:41:13.707541: train_loss -0.5087 
2025-01-03 00:41:13.707541: val_loss -0.43 
2025-01-03 00:41:13.716609: Pseudo dice [np.float32(0.6554), np.float32(0.4226)] 
2025-01-03 00:41:13.721149: Epoch time: 40.9 s 
2025-01-03 00:41:13.724173: Yayy! New best EMA pseudo Dice: 0.4650000035762787 
2025-01-03 00:41:14.685850:  
2025-01-03 00:41:14.685850: Epoch 45 
2025-01-03 00:41:14.691890: Current learning rate: 0.00584 
2025-01-03 00:41:55.591393: train_loss -0.4943 
2025-01-03 00:41:55.592394: val_loss -0.4014 
2025-01-03 00:41:55.598912: Pseudo dice [np.float32(0.6605), np.float32(0.2721)] 
2025-01-03 00:41:55.602924: Epoch time: 40.91 s 
2025-01-03 00:41:55.605965: Yayy! New best EMA pseudo Dice: 0.4652000069618225 
2025-01-03 00:41:56.399219:  
2025-01-03 00:41:56.399722: Epoch 46 
2025-01-03 00:41:56.405737: Current learning rate: 0.00574 
2025-01-03 00:42:37.294975: train_loss -0.4802 
2025-01-03 00:42:37.294975: val_loss -0.473 
2025-01-03 00:42:37.301494: Pseudo dice [np.float32(0.6605), np.float32(0.4927)] 
2025-01-03 00:42:37.305004: Epoch time: 40.9 s 
2025-01-03 00:42:37.309014: Yayy! New best EMA pseudo Dice: 0.4763000011444092 
2025-01-03 00:42:38.119264:  
2025-01-03 00:42:38.119264: Epoch 47 
2025-01-03 00:42:38.125372: Current learning rate: 0.00565 
2025-01-03 00:43:19.000015: train_loss -0.4927 
2025-01-03 00:43:19.000518: val_loss -0.4715 
2025-01-03 00:43:19.006531: Pseudo dice [np.float32(0.6695), np.float32(0.4448)] 
2025-01-03 00:43:19.010036: Epoch time: 40.88 s 
2025-01-03 00:43:19.013044: Yayy! New best EMA pseudo Dice: 0.4844000041484833 
2025-01-03 00:43:19.816069:  
2025-01-03 00:43:19.816571: Epoch 48 
2025-01-03 00:43:19.822585: Current learning rate: 0.00555 
2025-01-03 00:44:00.741968: train_loss -0.5157 
2025-01-03 00:44:00.742973: val_loss -0.4511 
2025-01-03 00:44:00.749498: Pseudo dice [np.float32(0.6998), np.float32(0.3709)] 
2025-01-03 00:44:00.753011: Epoch time: 40.93 s 
2025-01-03 00:44:00.756542: Yayy! New best EMA pseudo Dice: 0.4894999861717224 
2025-01-03 00:44:01.543501:  
2025-01-03 00:44:01.543501: Epoch 49 
2025-01-03 00:44:01.551022: Current learning rate: 0.00546 
2025-01-03 00:44:42.436430: train_loss -0.5213 
2025-01-03 00:44:42.437431: val_loss -0.4501 
2025-01-03 00:44:42.442952: Pseudo dice [np.float32(0.6601), np.float32(0.2906)] 
2025-01-03 00:44:42.447465: Epoch time: 40.89 s 
2025-01-03 00:44:43.230227:  
2025-01-03 00:44:43.231230: Epoch 50 
2025-01-03 00:44:43.235809: Current learning rate: 0.00536 
2025-01-03 00:45:24.129486: train_loss -0.5098 
2025-01-03 00:45:24.129486: val_loss -0.4297 
2025-01-03 00:45:24.135629: Pseudo dice [np.float32(0.6836), np.float32(0.3294)] 
2025-01-03 00:45:24.139642: Epoch time: 40.9 s 
2025-01-03 00:45:24.143154: Yayy! New best EMA pseudo Dice: 0.48989999294281006 
2025-01-03 00:45:24.944495:  
2025-01-03 00:45:24.944495: Epoch 51 
2025-01-03 00:45:24.950515: Current learning rate: 0.00526 
2025-01-03 00:46:05.908324: train_loss -0.5085 
2025-01-03 00:46:05.909328: val_loss -0.4494 
2025-01-03 00:46:05.916936: Pseudo dice [np.float32(0.6573), np.float32(0.3658)] 
2025-01-03 00:46:05.919947: Epoch time: 40.97 s 
2025-01-03 00:46:05.923459: Yayy! New best EMA pseudo Dice: 0.4921000003814697 
2025-01-03 00:46:06.681841:  
2025-01-03 00:46:06.682843: Epoch 52 
2025-01-03 00:46:06.687901: Current learning rate: 0.00517 
2025-01-03 00:46:47.563991: train_loss -0.5578 
2025-01-03 00:46:47.563991: val_loss -0.487 
2025-01-03 00:46:47.569788: Pseudo dice [np.float32(0.6996), np.float32(0.3719)] 
2025-01-03 00:46:47.574730: Epoch time: 40.88 s 
2025-01-03 00:46:47.578281: Yayy! New best EMA pseudo Dice: 0.49639999866485596 
2025-01-03 00:46:48.332389:  
2025-01-03 00:46:48.332892: Epoch 53 
2025-01-03 00:46:48.337904: Current learning rate: 0.00507 
2025-01-03 00:47:29.214741: train_loss -0.4958 
2025-01-03 00:47:29.215329: val_loss -0.4573 
2025-01-03 00:47:29.221982: Pseudo dice [np.float32(0.6631), np.float32(0.4206)] 
2025-01-03 00:47:29.225041: Epoch time: 40.88 s 
2025-01-03 00:47:29.229086: Yayy! New best EMA pseudo Dice: 0.5009999871253967 
2025-01-03 00:47:30.257690:  
2025-01-03 00:47:30.257690: Epoch 54 
2025-01-03 00:47:30.264250: Current learning rate: 0.00497 
2025-01-03 00:48:11.164240: train_loss -0.5271 
2025-01-03 00:48:11.165245: val_loss -0.4494 
2025-01-03 00:48:11.171260: Pseudo dice [np.float32(0.6912), np.float32(0.3421)] 
2025-01-03 00:48:11.175285: Epoch time: 40.91 s 
2025-01-03 00:48:11.178804: Yayy! New best EMA pseudo Dice: 0.5026000142097473 
2025-01-03 00:48:11.975234:  
2025-01-03 00:48:11.975234: Epoch 55 
2025-01-03 00:48:11.981249: Current learning rate: 0.00487 
2025-01-03 00:48:52.868308: train_loss -0.5446 
2025-01-03 00:48:52.868817: val_loss -0.4978 
2025-01-03 00:48:52.875504: Pseudo dice [np.float32(0.7096), np.float32(0.422)] 
2025-01-03 00:48:52.878560: Epoch time: 40.89 s 
2025-01-03 00:48:52.883106: Yayy! New best EMA pseudo Dice: 0.508899986743927 
2025-01-03 00:48:53.688338:  
2025-01-03 00:48:53.688338: Epoch 56 
2025-01-03 00:48:53.693921: Current learning rate: 0.00478 
2025-01-03 00:49:34.583444: train_loss -0.5386 
2025-01-03 00:49:34.584449: val_loss -0.4237 
2025-01-03 00:49:34.591180: Pseudo dice [np.float32(0.6654), np.float32(0.3299)] 
2025-01-03 00:49:34.594932: Epoch time: 40.9 s 
2025-01-03 00:49:35.153680:  
2025-01-03 00:49:35.153680: Epoch 57 
2025-01-03 00:49:35.158741: Current learning rate: 0.00468 
2025-01-03 00:50:16.036456: train_loss -0.519 
2025-01-03 00:50:16.037459: val_loss -0.4732 
2025-01-03 00:50:16.043531: Pseudo dice [np.float32(0.6768), np.float32(0.4511)] 
2025-01-03 00:50:16.047595: Epoch time: 40.88 s 
2025-01-03 00:50:16.051685: Yayy! New best EMA pseudo Dice: 0.5134000182151794 
2025-01-03 00:50:16.864802:  
2025-01-03 00:50:16.865305: Epoch 58 
2025-01-03 00:50:16.870316: Current learning rate: 0.00458 
2025-01-03 00:50:57.745111: train_loss -0.5111 
2025-01-03 00:50:57.745614: val_loss -0.5026 
2025-01-03 00:50:57.750624: Pseudo dice [np.float32(0.7078), np.float32(0.4508)] 
2025-01-03 00:50:57.754137: Epoch time: 40.88 s 
2025-01-03 00:50:57.756642: Yayy! New best EMA pseudo Dice: 0.5199999809265137 
2025-01-03 00:50:58.533594:  
2025-01-03 00:50:58.533594: Epoch 59 
2025-01-03 00:50:58.537606: Current learning rate: 0.00448 
2025-01-03 00:51:39.438837: train_loss -0.5232 
2025-01-03 00:51:39.439839: val_loss -0.468 
2025-01-03 00:51:39.444860: Pseudo dice [np.float32(0.6863), np.float32(0.3747)] 
2025-01-03 00:51:39.448397: Epoch time: 40.91 s 
2025-01-03 00:51:39.450673: Yayy! New best EMA pseudo Dice: 0.5210000276565552 
2025-01-03 00:51:40.224409:  
2025-01-03 00:51:40.224409: Epoch 60 
2025-01-03 00:51:40.229967: Current learning rate: 0.00438 
2025-01-03 00:52:21.134484: train_loss -0.5542 
2025-01-03 00:52:21.134484: val_loss -0.4855 
2025-01-03 00:52:21.141020: Pseudo dice [np.float32(0.6575), np.float32(0.4657)] 
2025-01-03 00:52:21.144028: Epoch time: 40.91 s 
2025-01-03 00:52:21.147538: Yayy! New best EMA pseudo Dice: 0.5250999927520752 
2025-01-03 00:52:22.082248:  
2025-01-03 00:52:22.083252: Epoch 61 
2025-01-03 00:52:22.087810: Current learning rate: 0.00429 
2025-01-03 00:53:02.982977: train_loss -0.5228 
2025-01-03 00:53:02.982977: val_loss -0.4517 
2025-01-03 00:53:02.990499: Pseudo dice [np.float32(0.6853), np.float32(0.2966)] 
2025-01-03 00:53:02.994012: Epoch time: 40.9 s 
2025-01-03 00:53:03.565238:  
2025-01-03 00:53:03.565741: Epoch 62 
2025-01-03 00:53:03.570755: Current learning rate: 0.00419 
2025-01-03 00:53:44.469198: train_loss -0.5168 
2025-01-03 00:53:44.469704: val_loss -0.4503 
2025-01-03 00:53:44.474746: Pseudo dice [np.float32(0.697), np.float32(0.3554)] 
2025-01-03 00:53:44.477300: Epoch time: 40.9 s 
2025-01-03 00:53:45.055761:  
2025-01-03 00:53:45.056762: Epoch 63 
2025-01-03 00:53:45.061821: Current learning rate: 0.00409 
2025-01-03 00:54:25.973033: train_loss -0.549 
2025-01-03 00:54:25.973033: val_loss -0.5229 
2025-01-03 00:54:25.979181: Pseudo dice [np.float32(0.7096), np.float32(0.509)] 
2025-01-03 00:54:25.982729: Epoch time: 40.92 s 
2025-01-03 00:54:25.985319: Yayy! New best EMA pseudo Dice: 0.5307999849319458 
2025-01-03 00:54:26.858588:  
2025-01-03 00:54:26.859593: Epoch 64 
2025-01-03 00:54:26.864621: Current learning rate: 0.00399 
2025-01-03 00:55:07.791282: train_loss -0.5371 
2025-01-03 00:55:07.791784: val_loss -0.4568 
2025-01-03 00:55:07.797799: Pseudo dice [np.float32(0.7132), np.float32(0.3319)] 
2025-01-03 00:55:07.800304: Epoch time: 40.93 s 
2025-01-03 00:55:08.374388:  
2025-01-03 00:55:08.374388: Epoch 65 
2025-01-03 00:55:08.378896: Current learning rate: 0.00389 
2025-01-03 00:55:49.288159: train_loss -0.518 
2025-01-03 00:55:49.288159: val_loss -0.5131 
2025-01-03 00:55:49.294497: Pseudo dice [np.float32(0.7079), np.float32(0.4774)] 
2025-01-03 00:55:49.298007: Epoch time: 40.91 s 
2025-01-03 00:55:49.300518: Yayy! New best EMA pseudo Dice: 0.536300003528595 
2025-01-03 00:55:50.099765:  
2025-01-03 00:55:50.099765: Epoch 66 
2025-01-03 00:55:50.104778: Current learning rate: 0.00379 
2025-01-03 00:56:30.993063: train_loss -0.5485 
2025-01-03 00:56:30.994091: val_loss -0.4679 
2025-01-03 00:56:30.999174: Pseudo dice [np.float32(0.669), np.float32(0.3528)] 
2025-01-03 00:56:31.002689: Epoch time: 40.89 s 
2025-01-03 00:56:31.581089:  
2025-01-03 00:56:31.581089: Epoch 67 
2025-01-03 00:56:31.586613: Current learning rate: 0.00369 
2025-01-03 00:57:12.501878: train_loss -0.5541 
2025-01-03 00:57:12.501878: val_loss -0.4571 
2025-01-03 00:57:12.507892: Pseudo dice [np.float32(0.6734), np.float32(0.3209)] 
2025-01-03 00:57:12.511397: Epoch time: 40.92 s 
2025-01-03 00:57:13.091766:  
2025-01-03 00:57:13.091766: Epoch 68 
2025-01-03 00:57:13.096804: Current learning rate: 0.00359 
2025-01-03 00:58:00.888961: train_loss -0.5404 
2025-01-03 00:58:00.889964: val_loss -0.5059 
2025-01-03 00:58:00.894977: Pseudo dice [np.float32(0.6892), np.float32(0.4418)] 
2025-01-03 00:58:00.898482: Epoch time: 47.8 s 
2025-01-03 00:58:01.481704:  
2025-01-03 00:58:01.482710: Epoch 69 
2025-01-03 00:58:01.487278: Current learning rate: 0.00349 
2025-01-03 00:58:42.431102: train_loss -0.5428 
2025-01-03 00:58:42.432106: val_loss -0.5126 
2025-01-03 00:58:42.437274: Pseudo dice [np.float32(0.7255), np.float32(0.4623)] 
2025-01-03 00:58:42.441303: Epoch time: 40.95 s 
2025-01-03 00:58:42.444338: Yayy! New best EMA pseudo Dice: 0.5396999716758728 
2025-01-03 00:58:43.394782:  
2025-01-03 00:58:43.394782: Epoch 70 
2025-01-03 00:58:43.400321: Current learning rate: 0.00338 
2025-01-03 00:59:24.278388: train_loss -0.5635 
2025-01-03 00:59:24.278388: val_loss -0.5395 
2025-01-03 00:59:24.284402: Pseudo dice [np.float32(0.7253), np.float32(0.4878)] 
2025-01-03 00:59:24.287909: Epoch time: 40.88 s 
2025-01-03 00:59:24.291924: Yayy! New best EMA pseudo Dice: 0.5462999939918518 
2025-01-03 00:59:25.107226:  
2025-01-03 00:59:25.107729: Epoch 71 
2025-01-03 00:59:25.112741: Current learning rate: 0.00328 
2025-01-03 01:00:05.993062: train_loss -0.5939 
2025-01-03 01:00:05.993062: val_loss -0.4857 
2025-01-03 01:00:05.999081: Pseudo dice [np.float32(0.7025), np.float32(0.3548)] 
2025-01-03 01:00:06.003091: Epoch time: 40.89 s 
2025-01-03 01:00:06.596273:  
2025-01-03 01:00:06.597279: Epoch 72 
2025-01-03 01:00:06.601299: Current learning rate: 0.00318 
2025-01-03 01:00:47.504266: train_loss -0.5733 
2025-01-03 01:00:47.504776: val_loss -0.5334 
2025-01-03 01:00:47.510869: Pseudo dice [np.float32(0.7387), np.float32(0.4416)] 
2025-01-03 01:00:47.513963: Epoch time: 40.91 s 
2025-01-03 01:00:47.517518: Yayy! New best EMA pseudo Dice: 0.5490999817848206 
2025-01-03 01:00:48.306976:  
2025-01-03 01:00:48.306976: Epoch 73 
2025-01-03 01:00:48.313528: Current learning rate: 0.00308 
2025-01-03 01:01:29.208675: train_loss -0.5672 
2025-01-03 01:01:29.208675: val_loss -0.4874 
2025-01-03 01:01:29.216248: Pseudo dice [np.float32(0.7197), np.float32(0.4343)] 
2025-01-03 01:01:29.219314: Epoch time: 40.9 s 
2025-01-03 01:01:29.221848: Yayy! New best EMA pseudo Dice: 0.5519000291824341 
2025-01-03 01:01:30.008730:  
2025-01-03 01:01:30.009232: Epoch 74 
2025-01-03 01:01:30.014243: Current learning rate: 0.00297 
2025-01-03 01:02:10.948620: train_loss -0.5815 
2025-01-03 01:02:10.949133: val_loss -0.5161 
2025-01-03 01:02:10.954771: Pseudo dice [np.float32(0.7109), np.float32(0.4419)] 
2025-01-03 01:02:10.958302: Epoch time: 40.94 s 
2025-01-03 01:02:10.961855: Yayy! New best EMA pseudo Dice: 0.5544000267982483 
2025-01-03 01:02:11.772566:  
2025-01-03 01:02:11.773070: Epoch 75 
2025-01-03 01:02:11.778103: Current learning rate: 0.00287 
2025-01-03 01:02:52.681861: train_loss -0.5827 
2025-01-03 01:02:52.682866: val_loss -0.4672 
2025-01-03 01:02:52.687880: Pseudo dice [np.float32(0.7204), np.float32(0.4068)] 
2025-01-03 01:02:52.691889: Epoch time: 40.91 s 
2025-01-03 01:02:52.695398: Yayy! New best EMA pseudo Dice: 0.5552999973297119 
2025-01-03 01:02:53.514522:  
2025-01-03 01:02:53.514522: Epoch 76 
2025-01-03 01:02:53.520583: Current learning rate: 0.00277 
2025-01-03 01:03:34.486680: train_loss -0.5534 
2025-01-03 01:03:34.487184: val_loss -0.4914 
2025-01-03 01:03:34.492795: Pseudo dice [np.float32(0.7143), np.float32(0.3536)] 
2025-01-03 01:03:34.495832: Epoch time: 40.97 s 
2025-01-03 01:03:35.231003:  
2025-01-03 01:03:35.231506: Epoch 77 
2025-01-03 01:03:35.236519: Current learning rate: 0.00266 
2025-01-03 01:04:16.131462: train_loss -0.5796 
2025-01-03 01:04:16.132966: val_loss -0.5182 
2025-01-03 01:04:16.138985: Pseudo dice [np.float32(0.677), np.float32(0.4606)] 
2025-01-03 01:04:16.142492: Epoch time: 40.9 s 
2025-01-03 01:04:16.743742:  
2025-01-03 01:04:16.743742: Epoch 78 
2025-01-03 01:04:16.748756: Current learning rate: 0.00256 
2025-01-03 01:04:57.672762: train_loss -0.5635 
2025-01-03 01:04:57.673768: val_loss -0.5395 
2025-01-03 01:04:57.679780: Pseudo dice [np.float32(0.7285), np.float32(0.4865)] 
2025-01-03 01:04:57.682917: Epoch time: 40.93 s 
2025-01-03 01:04:57.685447: Yayy! New best EMA pseudo Dice: 0.5600000023841858 
2025-01-03 01:04:58.475831:  
2025-01-03 01:04:58.476339: Epoch 79 
2025-01-03 01:04:58.480924: Current learning rate: 0.00245 
2025-01-03 01:05:39.373030: train_loss -0.5961 
2025-01-03 01:05:39.374034: val_loss -0.523 
2025-01-03 01:05:39.380552: Pseudo dice [np.float32(0.7129), np.float32(0.3976)] 
2025-01-03 01:05:39.383102: Epoch time: 40.9 s 
2025-01-03 01:05:39.976380:  
2025-01-03 01:05:39.976380: Epoch 80 
2025-01-03 01:05:39.981427: Current learning rate: 0.00235 
2025-01-03 01:06:20.936656: train_loss -0.5722 
2025-01-03 01:06:20.936656: val_loss -0.5474 
2025-01-03 01:06:20.943248: Pseudo dice [np.float32(0.7359), np.float32(0.4356)] 
2025-01-03 01:06:20.947347: Epoch time: 40.96 s 
2025-01-03 01:06:20.949852: Yayy! New best EMA pseudo Dice: 0.5620999932289124 
2025-01-03 01:06:21.803448:  
2025-01-03 01:06:21.804448: Epoch 81 
2025-01-03 01:06:21.810039: Current learning rate: 0.00224 
2025-01-03 01:07:02.724771: train_loss -0.6035 
2025-01-03 01:07:02.724771: val_loss -0.5317 
2025-01-03 01:07:02.729789: Pseudo dice [np.float32(0.7198), np.float32(0.4065)] 
2025-01-03 01:07:02.733804: Epoch time: 40.92 s 
2025-01-03 01:07:02.737318: Yayy! New best EMA pseudo Dice: 0.5622000098228455 
2025-01-03 01:07:03.526139:  
2025-01-03 01:07:03.527142: Epoch 82 
2025-01-03 01:07:03.531710: Current learning rate: 0.00214 
2025-01-03 01:07:44.436773: train_loss -0.6143 
2025-01-03 01:07:44.437280: val_loss -0.515 
2025-01-03 01:07:44.444337: Pseudo dice [np.float32(0.7157), np.float32(0.4097)] 
2025-01-03 01:07:44.447365: Epoch time: 40.91 s 
2025-01-03 01:07:44.450391: Yayy! New best EMA pseudo Dice: 0.5623000264167786 
2025-01-03 01:07:45.261028:  
2025-01-03 01:07:45.261531: Epoch 83 
2025-01-03 01:07:45.266542: Current learning rate: 0.00203 
2025-01-03 01:08:26.180423: train_loss -0.582 
2025-01-03 01:08:26.181428: val_loss -0.4665 
2025-01-03 01:08:26.186847: Pseudo dice [np.float32(0.6798), np.float32(0.2772)] 
2025-01-03 01:08:26.190356: Epoch time: 40.92 s 
2025-01-03 01:08:26.760742:  
2025-01-03 01:08:26.761743: Epoch 84 
2025-01-03 01:08:26.767324: Current learning rate: 0.00192 
2025-01-03 01:09:07.660650: train_loss -0.597 
2025-01-03 01:09:07.660650: val_loss -0.4903 
2025-01-03 01:09:07.669175: Pseudo dice [np.float32(0.7217), np.float32(0.3579)] 
2025-01-03 01:09:07.672186: Epoch time: 40.9 s 
2025-01-03 01:09:08.391292:  
2025-01-03 01:09:08.391292: Epoch 85 
2025-01-03 01:09:08.396850: Current learning rate: 0.00181 
2025-01-03 01:09:49.276813: train_loss -0.6232 
2025-01-03 01:09:49.277315: val_loss -0.4912 
2025-01-03 01:09:49.282328: Pseudo dice [np.float32(0.7298), np.float32(0.3677)] 
2025-01-03 01:09:49.285836: Epoch time: 40.89 s 
2025-01-03 01:09:49.843031:  
2025-01-03 01:09:49.843031: Epoch 86 
2025-01-03 01:09:49.849116: Current learning rate: 0.0017 
2025-01-03 01:10:30.745417: train_loss -0.5836 
2025-01-03 01:10:30.746423: val_loss -0.5467 
2025-01-03 01:10:30.752938: Pseudo dice [np.float32(0.7268), np.float32(0.3889)] 
2025-01-03 01:10:30.756448: Epoch time: 40.9 s 
2025-01-03 01:10:31.324006:  
2025-01-03 01:10:31.324006: Epoch 87 
2025-01-03 01:10:31.329560: Current learning rate: 0.00159 
2025-01-03 01:11:12.217097: train_loss -0.6157 
2025-01-03 01:11:12.217623: val_loss -0.5762 
2025-01-03 01:11:12.224693: Pseudo dice [np.float32(0.7429), np.float32(0.4625)] 
2025-01-03 01:11:12.228832: Epoch time: 40.89 s 
2025-01-03 01:11:12.793613:  
2025-01-03 01:11:12.793613: Epoch 88 
2025-01-03 01:11:12.799138: Current learning rate: 0.00148 
2025-01-03 01:11:53.686388: train_loss -0.6289 
2025-01-03 01:11:53.686902: val_loss -0.574 
2025-01-03 01:11:53.693485: Pseudo dice [np.float32(0.7395), np.float32(0.522)] 
2025-01-03 01:11:53.696549: Epoch time: 40.89 s 
2025-01-03 01:11:53.699585: Yayy! New best EMA pseudo Dice: 0.5649999976158142 
2025-01-03 01:11:54.488712:  
2025-01-03 01:11:54.489215: Epoch 89 
2025-01-03 01:11:54.494226: Current learning rate: 0.00137 
2025-01-03 01:12:35.365736: train_loss -0.6382 
2025-01-03 01:12:35.366257: val_loss -0.6106 
2025-01-03 01:12:35.372336: Pseudo dice [np.float32(0.7496), np.float32(0.5615)] 
2025-01-03 01:12:35.374653: Epoch time: 40.88 s 
2025-01-03 01:12:35.379256: Yayy! New best EMA pseudo Dice: 0.5741000175476074 
2025-01-03 01:12:36.172362:  
2025-01-03 01:12:36.173362: Epoch 90 
2025-01-03 01:12:36.178945: Current learning rate: 0.00126 
2025-01-03 01:13:17.066181: train_loss -0.6009 
2025-01-03 01:13:17.066693: val_loss -0.5434 
2025-01-03 01:13:17.072732: Pseudo dice [np.float32(0.7439), np.float32(0.5081)] 
2025-01-03 01:13:17.076260: Epoch time: 40.89 s 
2025-01-03 01:13:17.079833: Yayy! New best EMA pseudo Dice: 0.579200029373169 
2025-01-03 01:13:17.877116:  
2025-01-03 01:13:17.877116: Epoch 91 
2025-01-03 01:13:17.882676: Current learning rate: 0.00115 
2025-01-03 01:13:58.774503: train_loss -0.6182 
2025-01-03 01:13:58.775012: val_loss -0.5568 
2025-01-03 01:13:58.780570: Pseudo dice [np.float32(0.7388), np.float32(0.5057)] 
2025-01-03 01:13:58.784097: Epoch time: 40.9 s 
2025-01-03 01:13:58.787133: Yayy! New best EMA pseudo Dice: 0.5835000276565552 
2025-01-03 01:13:59.586272:  
2025-01-03 01:13:59.587272: Epoch 92 
2025-01-03 01:13:59.592787: Current learning rate: 0.00103 
2025-01-03 01:14:45.977925: train_loss -0.6308 
2025-01-03 01:14:45.979425: val_loss -0.5626 
2025-01-03 01:14:45.985440: Pseudo dice [np.float32(0.7269), np.float32(0.5221)] 
2025-01-03 01:14:45.987451: Epoch time: 46.39 s 
2025-01-03 01:14:45.991482: Yayy! New best EMA pseudo Dice: 0.5875999927520752 
2025-01-03 01:14:46.750171:  
2025-01-03 01:14:46.750673: Epoch 93 
2025-01-03 01:14:46.756687: Current learning rate: 0.00091 
2025-01-03 01:15:28.843108: train_loss -0.6262 
2025-01-03 01:15:28.844112: val_loss -0.5309 
2025-01-03 01:15:28.849961: Pseudo dice [np.float32(0.7411), np.float32(0.3954)] 
2025-01-03 01:15:28.853969: Epoch time: 42.09 s 
2025-01-03 01:15:29.533556:  
2025-01-03 01:15:29.533556: Epoch 94 
2025-01-03 01:15:29.539569: Current learning rate: 0.00079 
2025-01-03 01:16:10.576659: train_loss -0.6466 
2025-01-03 01:16:10.577160: val_loss -0.5606 
2025-01-03 01:16:10.582241: Pseudo dice [np.float32(0.7501), np.float32(0.4924)] 
2025-01-03 01:16:10.587354: Epoch time: 41.04 s 
2025-01-03 01:16:10.591922: Yayy! New best EMA pseudo Dice: 0.5892999768257141 
2025-01-03 01:16:11.364622:  
2025-01-03 01:16:11.365622: Epoch 95 
2025-01-03 01:16:11.371193: Current learning rate: 0.00067 
2025-01-03 01:16:52.406500: train_loss -0.6408 
2025-01-03 01:16:52.407501: val_loss -0.5699 
2025-01-03 01:16:52.413016: Pseudo dice [np.float32(0.7566), np.float32(0.5469)] 
2025-01-03 01:16:52.418039: Epoch time: 41.04 s 
2025-01-03 01:16:52.421557: Yayy! New best EMA pseudo Dice: 0.5954999923706055 
2025-01-03 01:16:53.146375:  
2025-01-03 01:16:53.147374: Epoch 96 
2025-01-03 01:16:53.152970: Current learning rate: 0.00055 
2025-01-03 01:17:34.213284: train_loss -0.6364 
2025-01-03 01:17:34.214283: val_loss -0.5296 
2025-01-03 01:17:34.220807: Pseudo dice [np.float32(0.7246), np.float32(0.3968)] 
2025-01-03 01:17:34.224816: Epoch time: 41.07 s 
2025-01-03 01:17:34.754576:  
2025-01-03 01:17:34.755579: Epoch 97 
2025-01-03 01:17:34.760621: Current learning rate: 0.00043 
2025-01-03 01:18:15.837837: train_loss -0.6516 
2025-01-03 01:18:15.838840: val_loss -0.5954 
2025-01-03 01:18:15.845402: Pseudo dice [np.float32(0.766), np.float32(0.5448)] 
2025-01-03 01:18:15.847920: Epoch time: 41.08 s 
2025-01-03 01:18:15.851940: Yayy! New best EMA pseudo Dice: 0.5983999967575073 
2025-01-03 01:18:16.628222:  
2025-01-03 01:18:16.629225: Epoch 98 
2025-01-03 01:18:16.633774: Current learning rate: 0.0003 
2025-01-03 01:18:57.704227: train_loss -0.6472 
2025-01-03 01:18:57.704227: val_loss -0.5064 
2025-01-03 01:18:57.710743: Pseudo dice [np.float32(0.7318), np.float32(0.3957)] 
2025-01-03 01:18:57.714256: Epoch time: 41.08 s 
2025-01-03 01:18:58.250391:  
2025-01-03 01:18:58.250892: Epoch 99 
2025-01-03 01:18:58.255906: Current learning rate: 0.00016 
2025-01-03 01:19:39.369867: train_loss -0.6272 
2025-01-03 01:19:39.370869: val_loss -0.5672 
2025-01-03 01:19:39.376886: Pseudo dice [np.float32(0.7546), np.float32(0.5073)] 
2025-01-03 01:19:39.379899: Epoch time: 41.12 s 
2025-01-03 01:19:39.383407: Yayy! New best EMA pseudo Dice: 0.5985000133514404 
2025-01-03 01:19:40.318759: Training done. 
2025-01-03 01:19:40.346761: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-03 01:19:40.353761: The split file contains 5 splits. 
2025-01-03 01:19:40.358760: Desired fold for training: 1 
2025-01-03 01:19:40.364760: This split has 225 training and 56 validation cases. 
2025-01-03 01:19:40.372761: predicting pancreas_004 
2025-01-03 01:19:40.379761: pancreas_004, shape torch.Size([1, 107, 473, 473]), rank 0 
2025-01-03 01:19:55.771803: predicting pancreas_019 
2025-01-03 01:19:55.780801: pancreas_019, shape torch.Size([1, 85, 561, 561]), rank 0 
2025-01-03 01:20:14.069771: predicting pancreas_029 
2025-01-03 01:20:14.084771: pancreas_029, shape torch.Size([1, 99, 498, 498]), rank 0 
2025-01-03 01:20:25.944028: predicting pancreas_032 
2025-01-03 01:20:25.956029: pancreas_032, shape torch.Size([1, 89, 589, 589]), rank 0 
2025-01-03 01:20:44.263400: predicting pancreas_037 
2025-01-03 01:20:44.278400: pancreas_037, shape torch.Size([1, 71, 411, 411]), rank 0 
2025-01-03 01:20:49.269037: predicting pancreas_041 
2025-01-03 01:20:49.276039: pancreas_041, shape torch.Size([1, 82, 510, 510]), rank 0 
2025-01-03 01:21:01.021749: predicting pancreas_050 
2025-01-03 01:21:01.032748: pancreas_050, shape torch.Size([1, 85, 461, 461]), rank 0 
2025-01-03 01:21:12.785596: predicting pancreas_051 
2025-01-03 01:21:12.795596: pancreas_051, shape torch.Size([1, 99, 523, 523]), rank 0 
2025-01-03 01:21:24.549702: predicting pancreas_058 
2025-01-03 01:21:24.563702: pancreas_058, shape torch.Size([1, 182, 607, 607]), rank 0 
2025-01-03 01:22:05.813987: predicting pancreas_064 
2025-01-03 01:22:05.843987: pancreas_064, shape torch.Size([1, 93, 571, 571]), rank 0 
2025-01-03 01:22:24.193856: predicting pancreas_074 
2025-01-03 01:22:24.211856: pancreas_074, shape torch.Size([1, 74, 498, 498]), rank 0 
2025-01-03 01:22:33.048228: predicting pancreas_078 
2025-01-03 01:22:33.056229: pancreas_078, shape torch.Size([1, 76, 452, 452]), rank 0 
2025-01-03 01:22:41.936506: predicting pancreas_081 
2025-01-03 01:22:41.945506: pancreas_081, shape torch.Size([1, 94, 411, 411]), rank 0 
2025-01-03 01:22:48.595482: predicting pancreas_087 
2025-01-03 01:22:48.603482: pancreas_087, shape torch.Size([1, 154, 411, 411]), rank 0 
2025-01-03 01:23:00.174082: predicting pancreas_088 
2025-01-03 01:23:00.187085: pancreas_088, shape torch.Size([1, 103, 487, 487]), rank 0 
2025-01-03 01:23:14.842105: predicting pancreas_096 
2025-01-03 01:23:14.856105: pancreas_096, shape torch.Size([1, 108, 590, 590]), rank 0 
2025-01-03 01:23:37.769628: predicting pancreas_107 
2025-01-03 01:23:37.786628: pancreas_107, shape torch.Size([1, 102, 498, 498]), rank 0 
2025-01-03 01:23:52.450767: predicting pancreas_158 
2025-01-03 01:23:52.463766: pancreas_158, shape torch.Size([1, 132, 605, 605]), rank 0 
2025-01-03 01:24:19.927418: predicting pancreas_160 
2025-01-03 01:24:19.950418: pancreas_160, shape torch.Size([1, 75, 523, 523]), rank 0 
2025-01-03 01:24:28.814041: predicting pancreas_186 
2025-01-03 01:24:28.825041: pancreas_186, shape torch.Size([1, 102, 452, 452]), rank 0 
2025-01-03 01:24:43.485257: predicting pancreas_198 
2025-01-03 01:24:43.496258: pancreas_198, shape torch.Size([1, 111, 573, 573]), rank 0 
2025-01-03 01:25:06.396233: predicting pancreas_201 
2025-01-03 01:25:06.414234: pancreas_201, shape torch.Size([1, 76, 411, 411]), rank 0 
2025-01-03 01:25:11.416250: predicting pancreas_204 
2025-01-03 01:25:11.423250: pancreas_204, shape torch.Size([1, 73, 411, 411]), rank 0 
2025-01-03 01:25:16.422623: predicting pancreas_229 
2025-01-03 01:25:16.429622: pancreas_229, shape torch.Size([1, 87, 561, 561]), rank 0 
2025-01-03 01:25:34.713493: predicting pancreas_230 
2025-01-03 01:25:34.726494: pancreas_230, shape torch.Size([1, 96, 497, 497]), rank 0 
2025-01-03 01:25:46.432912: predicting pancreas_255 
2025-01-03 01:25:46.447912: pancreas_255, shape torch.Size([1, 99, 523, 523]), rank 0 
2025-01-03 01:25:58.161913: predicting pancreas_262 
2025-01-03 01:25:58.174912: pancreas_262, shape torch.Size([1, 76, 480, 480]), rank 0 
2025-01-03 01:26:06.954838: predicting pancreas_270 
2025-01-03 01:26:06.964837: pancreas_270, shape torch.Size([1, 87, 511, 511]), rank 0 
2025-01-03 01:26:18.624141: predicting pancreas_274 
2025-01-03 01:26:18.636141: pancreas_274, shape torch.Size([1, 115, 448, 448]), rank 0 
2025-01-03 01:26:26.889674: predicting pancreas_290 
2025-01-03 01:26:26.901675: pancreas_290, shape torch.Size([1, 97, 584, 584]), rank 0 
2025-01-03 01:26:45.136624: predicting pancreas_299 
2025-01-03 01:26:45.152625: pancreas_299, shape torch.Size([1, 83, 436, 436]), rank 0 
2025-01-03 01:26:51.799818: predicting pancreas_303 
2025-01-03 01:26:51.810819: pancreas_303, shape torch.Size([1, 113, 623, 623]), rank 0 
2025-01-03 01:27:14.628697: predicting pancreas_304 
2025-01-03 01:27:14.643696: pancreas_304, shape torch.Size([1, 93, 461, 461]), rank 0 
2025-01-03 01:27:26.389900: predicting pancreas_308 
2025-01-03 01:27:26.400900: pancreas_308, shape torch.Size([1, 113, 614, 614]), rank 0 
2025-01-03 01:27:49.249182: predicting pancreas_312 
2025-01-03 01:27:49.269182: pancreas_312, shape torch.Size([1, 75, 592, 592]), rank 0 
2025-01-03 01:28:03.007104: predicting pancreas_316 
2025-01-03 01:28:03.022104: pancreas_316, shape torch.Size([1, 89, 462, 462]), rank 0 
2025-01-03 01:28:14.702364: predicting pancreas_318 
2025-01-03 01:28:14.712364: pancreas_318, shape torch.Size([1, 105, 503, 503]), rank 0 
2025-01-03 01:28:29.295416: predicting pancreas_320 
2025-01-03 01:28:29.309416: pancreas_320, shape torch.Size([1, 91, 473, 473]), rank 0 
2025-01-03 01:28:41.037913: predicting pancreas_326 
2025-01-03 01:28:41.047915: pancreas_326, shape torch.Size([1, 89, 607, 607]), rank 0 
2025-01-03 01:28:59.305815: predicting pancreas_328 
2025-01-03 01:28:59.321815: pancreas_328, shape torch.Size([1, 95, 623, 623]), rank 0 
2025-01-03 01:29:17.604847: predicting pancreas_333 
2025-01-03 01:29:17.622847: pancreas_333, shape torch.Size([1, 97, 623, 623]), rank 0 
2025-01-03 01:29:35.917199: predicting pancreas_343 
2025-01-03 01:29:35.937199: pancreas_343, shape torch.Size([1, 86, 497, 497]), rank 0 
2025-01-03 01:29:47.651592: predicting pancreas_348 
2025-01-03 01:29:47.662593: pancreas_348, shape torch.Size([1, 89, 473, 473]), rank 0 
2025-01-03 01:29:59.387439: predicting pancreas_350 
2025-01-03 01:29:59.397438: pancreas_350, shape torch.Size([1, 89, 463, 463]), rank 0 
2025-01-03 01:30:11.066912: predicting pancreas_362 
2025-01-03 01:30:11.075914: pancreas_362, shape torch.Size([1, 96, 448, 448]), rank 0 
2025-01-03 01:30:17.696163: predicting pancreas_366 
2025-01-03 01:30:17.707162: pancreas_366, shape torch.Size([1, 121, 563, 563]), rank 0 
2025-01-03 01:30:45.026096: predicting pancreas_369 
2025-01-03 01:30:45.045096: pancreas_369, shape torch.Size([1, 97, 623, 623]), rank 0 
2025-01-03 01:31:03.346295: predicting pancreas_378 
2025-01-03 01:31:03.363294: pancreas_378, shape torch.Size([1, 93, 472, 472]), rank 0 
2025-01-03 01:31:15.083961: predicting pancreas_388 
2025-01-03 01:31:15.094961: pancreas_388, shape torch.Size([1, 114, 567, 567]), rank 0 
2025-01-03 01:31:37.904744: predicting pancreas_400 
2025-01-03 01:31:37.921744: pancreas_400, shape torch.Size([1, 107, 617, 617]), rank 0 
2025-01-03 01:32:00.728237: predicting pancreas_401 
2025-01-03 01:32:00.749237: pancreas_401, shape torch.Size([1, 180, 461, 461]), rank 0 
2025-01-03 01:32:24.114259: predicting pancreas_406 
2025-01-03 01:32:24.133261: pancreas_406, shape torch.Size([1, 86, 569, 569]), rank 0 
2025-01-03 01:32:42.386814: predicting pancreas_409 
2025-01-03 01:32:42.401814: pancreas_409, shape torch.Size([1, 210, 502, 502]), rank 0 
2025-01-03 01:33:11.571588: predicting pancreas_413 
2025-01-03 01:33:11.595587: pancreas_413, shape torch.Size([1, 85, 498, 498]), rank 0 
2025-01-03 01:33:23.312587: predicting pancreas_416 
2025-01-03 01:33:23.326587: pancreas_416, shape torch.Size([1, 186, 588, 588]), rank 0 
2025-01-03 01:34:04.330921: predicting pancreas_421 
2025-01-03 01:34:04.365921: pancreas_421, shape torch.Size([1, 105, 620, 620]), rank 0 
2025-01-03 01:34:44.466957: Validation complete 
2025-01-03 01:34:44.466957: Mean Validation Dice:  0.6143260044333897 
