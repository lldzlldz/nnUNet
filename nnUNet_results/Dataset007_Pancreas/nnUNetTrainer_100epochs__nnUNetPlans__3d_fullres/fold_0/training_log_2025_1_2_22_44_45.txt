
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-02 22:44:45.804768: do_dummy_2d_data_aug: True 
2025-01-02 22:44:45.807768: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-02 22:44:45.813138: The split file contains 5 splits. 
2025-01-02 22:44:45.816142: Desired fold for training: 0 
2025-01-02 22:44:45.818142: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-02 22:44:53.256345: unpacking dataset... 
2025-01-02 22:44:53.472669: unpacking done... 
2025-01-02 22:44:56.461525:  
2025-01-02 22:44:56.461525: Epoch 0 
2025-01-02 22:44:56.466540: Current learning rate: 0.01 
2025-01-02 22:45:41.968810: train_loss 0.1212 
2025-01-02 22:45:41.968810: val_loss 0.0558 
2025-01-02 22:45:41.975325: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-02 22:45:41.978837: Epoch time: 45.51 s 
2025-01-02 22:45:41.981347: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-02 22:45:42.713176:  
2025-01-02 22:45:42.713176: Epoch 1 
2025-01-02 22:45:42.719236: Current learning rate: 0.00991 
2025-01-02 22:46:23.768019: train_loss 0.0363 
2025-01-02 22:46:23.769019: val_loss 0.0174 
2025-01-02 22:46:23.774534: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-02 22:46:23.778043: Epoch time: 41.06 s 
2025-01-02 22:46:24.298224:  
2025-01-02 22:46:24.299227: Epoch 2 
2025-01-02 22:46:24.304774: Current learning rate: 0.00982 
2025-01-02 22:47:05.366095: train_loss -0.0374 
2025-01-02 22:47:05.366598: val_loss -0.1064 
2025-01-02 22:47:05.372615: Pseudo dice [np.float32(0.3797), np.float32(0.0)] 
2025-01-02 22:47:05.375126: Epoch time: 41.07 s 
2025-01-02 22:47:05.379135: Yayy! New best EMA pseudo Dice: 0.01899999938905239 
2025-01-02 22:47:06.140957:  
2025-01-02 22:47:06.140957: Epoch 3 
2025-01-02 22:47:06.146978: Current learning rate: 0.00973 
2025-01-02 22:47:48.145463: train_loss -0.0827 
2025-01-02 22:47:48.146463: val_loss -0.1612 
2025-01-02 22:47:48.151996: Pseudo dice [np.float32(0.4726), np.float32(0.0)] 
2025-01-02 22:47:48.157013: Epoch time: 42.01 s 
2025-01-02 22:47:48.163035: Yayy! New best EMA pseudo Dice: 0.040699999779462814 
2025-01-02 22:47:48.980777:  
2025-01-02 22:47:48.981279: Epoch 4 
2025-01-02 22:47:48.986290: Current learning rate: 0.00964 
2025-01-02 22:48:31.746763: train_loss -0.1398 
2025-01-02 22:48:31.747276: val_loss -0.1566 
2025-01-02 22:48:31.753501: Pseudo dice [np.float32(0.4726), np.float32(0.0)] 
2025-01-02 22:48:31.757092: Epoch time: 42.77 s 
2025-01-02 22:48:31.760710: Yayy! New best EMA pseudo Dice: 0.06030000001192093 
2025-01-02 22:48:32.711221:  
2025-01-02 22:48:32.711727: Epoch 5 
2025-01-02 22:48:32.716741: Current learning rate: 0.00955 
2025-01-02 22:49:14.838544: train_loss -0.1583 
2025-01-02 22:49:14.838544: val_loss -0.1936 
2025-01-02 22:49:14.844557: Pseudo dice [np.float32(0.5162), np.float32(0.0)] 
2025-01-02 22:49:14.847569: Epoch time: 42.13 s 
2025-01-02 22:49:14.850077: Yayy! New best EMA pseudo Dice: 0.08009999990463257 
2025-01-02 22:49:15.601563:  
2025-01-02 22:49:15.602566: Epoch 6 
2025-01-02 22:49:15.607130: Current learning rate: 0.00946 
2025-01-02 22:49:58.246071: train_loss -0.1672 
2025-01-02 22:49:58.246071: val_loss -0.222 
2025-01-02 22:49:58.252723: Pseudo dice [np.float32(0.5448), np.float32(0.0)] 
2025-01-02 22:49:58.256761: Epoch time: 42.64 s 
2025-01-02 22:49:58.259287: Yayy! New best EMA pseudo Dice: 0.09929999709129333 
2025-01-02 22:49:59.042530:  
2025-01-02 22:49:59.042530: Epoch 7 
2025-01-02 22:49:59.050189: Current learning rate: 0.00937 
2025-01-02 22:50:40.373573: train_loss -0.1957 
2025-01-02 22:50:40.373573: val_loss -0.2305 
2025-01-02 22:50:40.380626: Pseudo dice [np.float32(0.5779), np.float32(0.0)] 
2025-01-02 22:50:40.384137: Epoch time: 41.33 s 
2025-01-02 22:50:40.387645: Yayy! New best EMA pseudo Dice: 0.11829999834299088 
2025-01-02 22:50:41.266093:  
2025-01-02 22:50:41.266093: Epoch 8 
2025-01-02 22:50:41.271155: Current learning rate: 0.00928 
2025-01-02 22:51:22.499861: train_loss -0.2139 
2025-01-02 22:51:22.501365: val_loss -0.1874 
2025-01-02 22:51:22.507382: Pseudo dice [np.float32(0.4828), np.float32(0.0)] 
2025-01-02 22:51:22.509887: Epoch time: 41.23 s 
2025-01-02 22:51:22.512473: Yayy! New best EMA pseudo Dice: 0.1306000053882599 
2025-01-02 22:51:23.301686:  
2025-01-02 22:51:23.302198: Epoch 9 
2025-01-02 22:51:23.307749: Current learning rate: 0.00919 
2025-01-02 22:52:05.313503: train_loss -0.2461 
2025-01-02 22:52:05.314018: val_loss -0.2968 
2025-01-02 22:52:05.319082: Pseudo dice [np.float32(0.5435), np.float32(0.2927)] 
2025-01-02 22:52:05.321607: Epoch time: 42.01 s 
2025-01-02 22:52:05.324126: Yayy! New best EMA pseudo Dice: 0.15929999947547913 
2025-01-02 22:52:06.147025:  
2025-01-02 22:52:06.148026: Epoch 10 
2025-01-02 22:52:06.153650: Current learning rate: 0.0091 
2025-01-02 22:52:48.044146: train_loss -0.1967 
2025-01-02 22:52:48.044653: val_loss -0.2258 
2025-01-02 22:52:48.049225: Pseudo dice [np.float32(0.578), np.float32(0.0026)] 
2025-01-02 22:52:48.053790: Epoch time: 41.9 s 
2025-01-02 22:52:48.056884: Yayy! New best EMA pseudo Dice: 0.17239999771118164 
2025-01-02 22:52:48.874524:  
2025-01-02 22:52:48.874524: Epoch 11 
2025-01-02 22:52:48.880060: Current learning rate: 0.009 
2025-01-02 22:53:30.677043: train_loss -0.2261 
2025-01-02 22:53:30.678042: val_loss -0.3371 
2025-01-02 22:53:30.684566: Pseudo dice [np.float32(0.6276), np.float32(0.2579)] 
2025-01-02 22:53:30.688076: Epoch time: 41.8 s 
2025-01-02 22:53:30.691085: Yayy! New best EMA pseudo Dice: 0.19949999451637268 
2025-01-02 22:53:31.436451:  
2025-01-02 22:53:31.436451: Epoch 12 
2025-01-02 22:53:31.441522: Current learning rate: 0.00891 
2025-01-02 22:54:12.536209: train_loss -0.2967 
2025-01-02 22:54:12.537213: val_loss -0.3104 
2025-01-02 22:54:12.543734: Pseudo dice [np.float32(0.5584), np.float32(0.308)] 
2025-01-02 22:54:12.546272: Epoch time: 41.1 s 
2025-01-02 22:54:12.548809: Yayy! New best EMA pseudo Dice: 0.22280000150203705 
2025-01-02 22:54:13.484910:  
2025-01-02 22:54:13.484910: Epoch 13 
2025-01-02 22:54:13.489947: Current learning rate: 0.00882 
2025-01-02 22:54:54.608795: train_loss -0.3102 
2025-01-02 22:54:54.609298: val_loss -0.3575 
2025-01-02 22:54:54.614311: Pseudo dice [np.float32(0.558), np.float32(0.3832)] 
2025-01-02 22:54:54.617829: Epoch time: 41.12 s 
2025-01-02 22:54:54.622845: Yayy! New best EMA pseudo Dice: 0.2476000040769577 
2025-01-02 22:54:55.362283:  
2025-01-02 22:54:55.362283: Epoch 14 
2025-01-02 22:54:55.367863: Current learning rate: 0.00873 
2025-01-02 22:55:36.517485: train_loss -0.3176 
2025-01-02 22:55:36.518486: val_loss -0.3307 
2025-01-02 22:55:36.524066: Pseudo dice [np.float32(0.5163), np.float32(0.3035)] 
2025-01-02 22:55:36.527626: Epoch time: 41.16 s 
2025-01-02 22:55:36.530130: Yayy! New best EMA pseudo Dice: 0.2637999951839447 
2025-01-02 22:55:37.249576:  
2025-01-02 22:55:37.250576: Epoch 15 
2025-01-02 22:55:37.255644: Current learning rate: 0.00864 
2025-01-02 22:56:18.567800: train_loss -0.326 
2025-01-02 22:56:18.567800: val_loss -0.3537 
2025-01-02 22:56:18.573813: Pseudo dice [np.float32(0.5432), np.float32(0.3288)] 
2025-01-02 22:56:18.577075: Epoch time: 41.32 s 
2025-01-02 22:56:18.580112: Yayy! New best EMA pseudo Dice: 0.28110000491142273 
2025-01-02 22:56:19.363919:  
2025-01-02 22:56:19.363919: Epoch 16 
2025-01-02 22:56:19.368933: Current learning rate: 0.00855 
2025-01-02 22:57:00.596948: train_loss -0.3312 
2025-01-02 22:57:00.597521: val_loss -0.3885 
2025-01-02 22:57:00.604618: Pseudo dice [np.float32(0.5991), np.float32(0.3168)] 
2025-01-02 22:57:00.608634: Epoch time: 41.23 s 
2025-01-02 22:57:00.611147: Yayy! New best EMA pseudo Dice: 0.298799991607666 
2025-01-02 22:57:01.405859:  
2025-01-02 22:57:01.405859: Epoch 17 
2025-01-02 22:57:01.412379: Current learning rate: 0.00846 
2025-01-02 22:57:42.561754: train_loss -0.3365 
2025-01-02 22:57:42.561754: val_loss -0.3413 
2025-01-02 22:57:42.567835: Pseudo dice [np.float32(0.5994), np.float32(0.3047)] 
2025-01-02 22:57:42.570555: Epoch time: 41.16 s 
2025-01-02 22:57:42.574066: Yayy! New best EMA pseudo Dice: 0.3140999972820282 
2025-01-02 22:57:43.321894:  
2025-01-02 22:57:43.321894: Epoch 18 
2025-01-02 22:57:43.327416: Current learning rate: 0.00836 
2025-01-02 22:58:24.458507: train_loss -0.3081 
2025-01-02 22:58:24.459031: val_loss -0.377 
2025-01-02 22:58:24.464637: Pseudo dice [np.float32(0.6312), np.float32(0.3237)] 
2025-01-02 22:58:24.466682: Epoch time: 41.14 s 
2025-01-02 22:58:24.471324: Yayy! New best EMA pseudo Dice: 0.3303999900817871 
2025-01-02 22:58:25.208819:  
2025-01-02 22:58:25.209819: Epoch 19 
2025-01-02 22:58:25.215405: Current learning rate: 0.00827 
2025-01-02 22:59:07.633696: train_loss -0.3767 
2025-01-02 22:59:07.633696: val_loss -0.3832 
2025-01-02 22:59:07.640251: Pseudo dice [np.float32(0.6299), np.float32(0.3281)] 
2025-01-02 22:59:07.643760: Epoch time: 42.42 s 
2025-01-02 22:59:07.646267: Yayy! New best EMA pseudo Dice: 0.34529998898506165 
2025-01-02 22:59:08.416726:  
2025-01-02 22:59:08.417727: Epoch 20 
2025-01-02 22:59:08.422795: Current learning rate: 0.00818 
2025-01-02 22:59:50.640667: train_loss -0.3474 
2025-01-02 22:59:50.641670: val_loss -0.4166 
2025-01-02 22:59:50.647693: Pseudo dice [np.float32(0.5973), np.float32(0.4605)] 
2025-01-02 22:59:50.651268: Epoch time: 42.22 s 
2025-01-02 22:59:50.653804: Yayy! New best EMA pseudo Dice: 0.3635999858379364 
2025-01-02 22:59:51.691267:  
2025-01-02 22:59:51.691267: Epoch 21 
2025-01-02 22:59:51.696805: Current learning rate: 0.00809 
2025-01-02 23:00:33.054132: train_loss -0.3804 
2025-01-02 23:00:33.054132: val_loss -0.4007 
2025-01-02 23:00:33.060866: Pseudo dice [np.float32(0.5906), np.float32(0.3165)] 
2025-01-02 23:00:33.064439: Epoch time: 41.36 s 
2025-01-02 23:00:33.067985: Yayy! New best EMA pseudo Dice: 0.3725999891757965 
2025-01-02 23:00:33.830381:  
2025-01-02 23:00:33.830381: Epoch 22 
2025-01-02 23:00:33.836990: Current learning rate: 0.008 
2025-01-02 23:01:15.190187: train_loss -0.3778 
2025-01-02 23:01:15.191191: val_loss -0.4472 
2025-01-02 23:01:15.197207: Pseudo dice [np.float32(0.6522), np.float32(0.3897)] 
2025-01-02 23:01:15.200215: Epoch time: 41.36 s 
2025-01-02 23:01:15.203727: Yayy! New best EMA pseudo Dice: 0.38749998807907104 
2025-01-02 23:01:15.941500:  
2025-01-02 23:01:15.942003: Epoch 23 
2025-01-02 23:01:15.947016: Current learning rate: 0.0079 
2025-01-02 23:01:57.126182: train_loss -0.3958 
2025-01-02 23:01:57.127187: val_loss -0.4143 
2025-01-02 23:01:57.134717: Pseudo dice [np.float32(0.6457), np.float32(0.3559)] 
2025-01-02 23:01:57.139230: Epoch time: 41.19 s 
2025-01-02 23:01:57.142810: Yayy! New best EMA pseudo Dice: 0.39879998564720154 
2025-01-02 23:01:57.847179:  
2025-01-02 23:01:57.847179: Epoch 24 
2025-01-02 23:01:57.853204: Current learning rate: 0.00781 
2025-01-02 23:02:38.987060: train_loss -0.3986 
2025-01-02 23:02:38.987060: val_loss -0.4575 
2025-01-02 23:02:38.993642: Pseudo dice [np.float32(0.661), np.float32(0.4389)] 
2025-01-02 23:02:38.997694: Epoch time: 41.14 s 
2025-01-02 23:02:39.002709: Yayy! New best EMA pseudo Dice: 0.4138999879360199 
2025-01-02 23:02:39.747845:  
2025-01-02 23:02:39.747845: Epoch 25 
2025-01-02 23:02:39.753450: Current learning rate: 0.00772 
2025-01-02 23:03:20.961653: train_loss -0.3935 
2025-01-02 23:03:20.961653: val_loss -0.409 
2025-01-02 23:03:20.966746: Pseudo dice [np.float32(0.6377), np.float32(0.2928)] 
2025-01-02 23:03:20.971331: Epoch time: 41.21 s 
2025-01-02 23:03:20.974380: Yayy! New best EMA pseudo Dice: 0.4189999997615814 
2025-01-02 23:03:21.726539:  
2025-01-02 23:03:21.726539: Epoch 26 
2025-01-02 23:03:21.731554: Current learning rate: 0.00763 
2025-01-02 23:04:03.721639: train_loss -0.4004 
2025-01-02 23:04:03.722153: val_loss -0.4005 
2025-01-02 23:04:03.729256: Pseudo dice [np.float32(0.6296), np.float32(0.3331)] 
2025-01-02 23:04:03.732828: Epoch time: 42.0 s 
2025-01-02 23:04:03.735918: Yayy! New best EMA pseudo Dice: 0.4253000020980835 
2025-01-02 23:04:04.507205:  
2025-01-02 23:04:04.508205: Epoch 27 
2025-01-02 23:04:04.513719: Current learning rate: 0.00753 
2025-01-02 23:04:46.374701: train_loss -0.4198 
2025-01-02 23:04:46.375705: val_loss -0.4472 
2025-01-02 23:04:46.381719: Pseudo dice [np.float32(0.6231), np.float32(0.4049)] 
2025-01-02 23:04:46.384729: Epoch time: 41.87 s 
2025-01-02 23:04:46.387235: Yayy! New best EMA pseudo Dice: 0.4341000020503998 
2025-01-02 23:04:47.197012:  
2025-01-02 23:04:47.197012: Epoch 28 
2025-01-02 23:04:47.202542: Current learning rate: 0.00744 
2025-01-02 23:05:28.536392: train_loss -0.4391 
2025-01-02 23:05:28.536911: val_loss -0.4398 
2025-01-02 23:05:28.542010: Pseudo dice [np.float32(0.6387), np.float32(0.426)] 
2025-01-02 23:05:28.545084: Epoch time: 41.34 s 
2025-01-02 23:05:28.548677: Yayy! New best EMA pseudo Dice: 0.4440000057220459 
2025-01-02 23:05:29.489393:  
2025-01-02 23:05:29.490398: Epoch 29 
2025-01-02 23:05:29.494995: Current learning rate: 0.00735 
2025-01-02 23:06:10.873317: train_loss -0.3785 
2025-01-02 23:06:10.874319: val_loss -0.4223 
2025-01-02 23:06:10.879881: Pseudo dice [np.float32(0.63), np.float32(0.3525)] 
2025-01-02 23:06:10.882977: Epoch time: 41.38 s 
2025-01-02 23:06:10.885502: Yayy! New best EMA pseudo Dice: 0.4487000107765198 
2025-01-02 23:06:11.672699:  
2025-01-02 23:06:11.673201: Epoch 30 
2025-01-02 23:06:11.678216: Current learning rate: 0.00725 
2025-01-02 23:06:54.349040: train_loss -0.4243 
2025-01-02 23:06:54.349543: val_loss -0.4079 
2025-01-02 23:06:54.355565: Pseudo dice [np.float32(0.6367), np.float32(0.3816)] 
2025-01-02 23:06:54.358073: Epoch time: 42.68 s 
2025-01-02 23:06:54.361580: Yayy! New best EMA pseudo Dice: 0.4546999931335449 
2025-01-02 23:06:55.166656:  
2025-01-02 23:06:55.167660: Epoch 31 
2025-01-02 23:06:55.173202: Current learning rate: 0.00716 
2025-01-02 23:07:37.209717: train_loss -0.4281 
2025-01-02 23:07:37.210221: val_loss -0.4548 
2025-01-02 23:07:37.216244: Pseudo dice [np.float32(0.6935), np.float32(0.3301)] 
2025-01-02 23:07:37.218754: Epoch time: 42.04 s 
2025-01-02 23:07:37.222268: Yayy! New best EMA pseudo Dice: 0.4603999853134155 
2025-01-02 23:07:38.072704:  
2025-01-02 23:07:38.072704: Epoch 32 
2025-01-02 23:07:38.078742: Current learning rate: 0.00707 
2025-01-02 23:08:19.379756: train_loss -0.4515 
2025-01-02 23:08:19.379756: val_loss -0.4377 
2025-01-02 23:08:19.385773: Pseudo dice [np.float32(0.6661), np.float32(0.3741)] 
2025-01-02 23:08:19.388785: Epoch time: 41.31 s 
2025-01-02 23:08:19.392294: Yayy! New best EMA pseudo Dice: 0.46639999747276306 
2025-01-02 23:08:20.164434:  
2025-01-02 23:08:20.164938: Epoch 33 
2025-01-02 23:08:20.169953: Current learning rate: 0.00697 
2025-01-02 23:09:01.864606: train_loss -0.4464 
2025-01-02 23:09:01.865111: val_loss -0.4486 
2025-01-02 23:09:01.871133: Pseudo dice [np.float32(0.6654), np.float32(0.3679)] 
2025-01-02 23:09:01.874643: Epoch time: 41.7 s 
2025-01-02 23:09:01.880168: Yayy! New best EMA pseudo Dice: 0.4713999927043915 
2025-01-02 23:09:02.713744:  
2025-01-02 23:09:02.713744: Epoch 34 
2025-01-02 23:09:02.719321: Current learning rate: 0.00688 
2025-01-02 23:09:45.630268: train_loss -0.4303 
2025-01-02 23:09:45.631272: val_loss -0.4263 
2025-01-02 23:09:45.636808: Pseudo dice [np.float32(0.6472), np.float32(0.3799)] 
2025-01-02 23:09:45.639833: Epoch time: 42.92 s 
2025-01-02 23:09:45.642898: Yayy! New best EMA pseudo Dice: 0.475600004196167 
2025-01-02 23:09:46.436783:  
2025-01-02 23:09:46.436783: Epoch 35 
2025-01-02 23:09:46.442835: Current learning rate: 0.00679 
2025-01-02 23:10:29.059068: train_loss -0.4371 
2025-01-02 23:10:29.059068: val_loss -0.4882 
2025-01-02 23:10:29.065584: Pseudo dice [np.float32(0.6874), np.float32(0.3889)] 
2025-01-02 23:10:29.069094: Epoch time: 42.62 s 
2025-01-02 23:10:29.072108: Yayy! New best EMA pseudo Dice: 0.48190000653266907 
2025-01-02 23:10:29.905699:  
2025-01-02 23:10:29.905699: Epoch 36 
2025-01-02 23:10:29.910712: Current learning rate: 0.00669 
2025-01-02 23:11:11.803906: train_loss -0.4627 
2025-01-02 23:11:11.804410: val_loss -0.4723 
2025-01-02 23:11:11.810427: Pseudo dice [np.float32(0.6736), np.float32(0.4411)] 
2025-01-02 23:11:11.813934: Epoch time: 41.9 s 
2025-01-02 23:11:11.816943: Yayy! New best EMA pseudo Dice: 0.4893999993801117 
2025-01-02 23:11:12.825889:  
2025-01-02 23:11:12.826392: Epoch 37 
2025-01-02 23:11:12.831406: Current learning rate: 0.0066 
2025-01-02 23:11:54.129006: train_loss -0.4406 
2025-01-02 23:11:54.129006: val_loss -0.4302 
2025-01-02 23:11:54.135026: Pseudo dice [np.float32(0.6797), np.float32(0.3034)] 
2025-01-02 23:11:54.138532: Epoch time: 41.3 s 
2025-01-02 23:11:54.141541: Yayy! New best EMA pseudo Dice: 0.48969998955726624 
2025-01-02 23:11:54.978510:  
2025-01-02 23:11:54.979013: Epoch 38 
2025-01-02 23:11:54.984039: Current learning rate: 0.0065 
2025-01-02 23:12:36.191111: train_loss -0.4812 
2025-01-02 23:12:36.191111: val_loss -0.4741 
2025-01-02 23:12:36.197165: Pseudo dice [np.float32(0.7088), np.float32(0.4002)] 
2025-01-02 23:12:36.200195: Epoch time: 41.21 s 
2025-01-02 23:12:36.203737: Yayy! New best EMA pseudo Dice: 0.4961000084877014 
2025-01-02 23:12:37.039784:  
2025-01-02 23:12:37.040788: Epoch 39 
2025-01-02 23:12:37.045349: Current learning rate: 0.00641 
2025-01-02 23:13:18.621469: train_loss -0.4534 
2025-01-02 23:13:18.622474: val_loss -0.4378 
2025-01-02 23:13:18.628493: Pseudo dice [np.float32(0.6535), np.float32(0.3512)] 
2025-01-02 23:13:18.631506: Epoch time: 41.58 s 
2025-01-02 23:13:18.635017: Yayy! New best EMA pseudo Dice: 0.4968000054359436 
2025-01-02 23:13:19.428197:  
2025-01-02 23:13:19.428197: Epoch 40 
2025-01-02 23:13:19.433744: Current learning rate: 0.00631 
2025-01-02 23:14:00.913092: train_loss -0.445 
2025-01-02 23:14:00.913599: val_loss -0.5025 
2025-01-02 23:14:00.919673: Pseudo dice [np.float32(0.7283), np.float32(0.4222)] 
2025-01-02 23:14:00.923756: Epoch time: 41.48 s 
2025-01-02 23:14:00.926804: Yayy! New best EMA pseudo Dice: 0.5045999884605408 
2025-01-02 23:14:01.720238:  
2025-01-02 23:14:01.721241: Epoch 41 
2025-01-02 23:14:01.726270: Current learning rate: 0.00622 
2025-01-02 23:14:43.007885: train_loss -0.4881 
2025-01-02 23:14:43.008393: val_loss -0.4551 
2025-01-02 23:14:43.014442: Pseudo dice [np.float32(0.6527), np.float32(0.4424)] 
2025-01-02 23:14:43.017471: Epoch time: 41.29 s 
2025-01-02 23:14:43.021013: Yayy! New best EMA pseudo Dice: 0.508899986743927 
2025-01-02 23:14:43.827227:  
2025-01-02 23:14:43.827227: Epoch 42 
2025-01-02 23:14:43.832760: Current learning rate: 0.00612 
2025-01-02 23:15:25.892346: train_loss -0.4731 
2025-01-02 23:15:25.892848: val_loss -0.4517 
2025-01-02 23:15:25.897885: Pseudo dice [np.float32(0.7069), np.float32(0.3197)] 
2025-01-02 23:15:25.900915: Epoch time: 42.07 s 
2025-01-02 23:15:25.903437: Yayy! New best EMA pseudo Dice: 0.5092999935150146 
2025-01-02 23:15:26.733627:  
2025-01-02 23:15:26.734630: Epoch 43 
2025-01-02 23:15:26.739201: Current learning rate: 0.00603 
2025-01-02 23:16:08.079264: train_loss -0.4655 
2025-01-02 23:16:08.080264: val_loss -0.4932 
2025-01-02 23:16:08.085777: Pseudo dice [np.float32(0.6929), np.float32(0.4397)] 
2025-01-02 23:16:08.089286: Epoch time: 41.35 s 
2025-01-02 23:16:08.091792: Yayy! New best EMA pseudo Dice: 0.5149999856948853 
2025-01-02 23:16:08.857449:  
2025-01-02 23:16:08.858452: Epoch 44 
2025-01-02 23:16:08.863997: Current learning rate: 0.00593 
2025-01-02 23:16:50.191373: train_loss -0.4771 
2025-01-02 23:16:50.191373: val_loss -0.451 
2025-01-02 23:16:50.197891: Pseudo dice [np.float32(0.6942), np.float32(0.2921)] 
2025-01-02 23:16:50.200398: Epoch time: 41.33 s 
2025-01-02 23:16:50.769910:  
2025-01-02 23:16:50.769910: Epoch 45 
2025-01-02 23:16:50.775444: Current learning rate: 0.00584 
2025-01-02 23:17:31.952842: train_loss -0.4812 
2025-01-02 23:17:31.953352: val_loss -0.4784 
2025-01-02 23:17:31.958404: Pseudo dice [np.float32(0.703), np.float32(0.4114)] 
2025-01-02 23:17:31.961931: Epoch time: 41.18 s 
2025-01-02 23:17:31.965475: Yayy! New best EMA pseudo Dice: 0.517300009727478 
2025-01-02 23:17:32.981486:  
2025-01-02 23:17:32.981486: Epoch 46 
2025-01-02 23:17:32.986505: Current learning rate: 0.00574 
2025-01-02 23:18:14.276066: train_loss -0.486 
2025-01-02 23:18:14.276575: val_loss -0.5254 
2025-01-02 23:18:14.281613: Pseudo dice [np.float32(0.7003), np.float32(0.4894)] 
2025-01-02 23:18:14.285133: Epoch time: 41.3 s 
2025-01-02 23:18:14.288190: Yayy! New best EMA pseudo Dice: 0.5249999761581421 
2025-01-02 23:18:15.063249:  
2025-01-02 23:18:15.063249: Epoch 47 
2025-01-02 23:18:15.068789: Current learning rate: 0.00565 
2025-01-02 23:18:56.560567: train_loss -0.521 
2025-01-02 23:18:56.561080: val_loss -0.5181 
2025-01-02 23:18:56.566655: Pseudo dice [np.float32(0.7274), np.float32(0.4056)] 
2025-01-02 23:18:56.569182: Epoch time: 41.5 s 
2025-01-02 23:18:56.572711: Yayy! New best EMA pseudo Dice: 0.52920001745224 
2025-01-02 23:18:57.375000:  
2025-01-02 23:18:57.375000: Epoch 48 
2025-01-02 23:18:57.381021: Current learning rate: 0.00555 
2025-01-02 23:19:39.400426: train_loss -0.476 
2025-01-02 23:19:39.400426: val_loss -0.5301 
2025-01-02 23:19:39.406446: Pseudo dice [np.float32(0.7206), np.float32(0.4384)] 
2025-01-02 23:19:39.408957: Epoch time: 42.03 s 
2025-01-02 23:19:39.412975: Yayy! New best EMA pseudo Dice: 0.5342000126838684 
2025-01-02 23:19:40.188028:  
2025-01-02 23:19:40.188028: Epoch 49 
2025-01-02 23:19:40.193572: Current learning rate: 0.00546 
2025-01-02 23:20:21.689191: train_loss -0.508 
2025-01-02 23:20:21.690193: val_loss -0.5186 
2025-01-02 23:20:21.695709: Pseudo dice [np.float32(0.7029), np.float32(0.4347)] 
2025-01-02 23:20:21.698215: Epoch time: 41.5 s 
2025-01-02 23:20:21.863341: Yayy! New best EMA pseudo Dice: 0.5376999974250793 
2025-01-02 23:20:22.726280:  
2025-01-02 23:20:22.726280: Epoch 50 
2025-01-02 23:20:22.731291: Current learning rate: 0.00536 
2025-01-02 23:21:04.089174: train_loss -0.498 
2025-01-02 23:21:04.089174: val_loss -0.5393 
2025-01-02 23:21:04.095294: Pseudo dice [np.float32(0.7442), np.float32(0.4695)] 
2025-01-02 23:21:04.098809: Epoch time: 41.36 s 
2025-01-02 23:21:04.102132: Yayy! New best EMA pseudo Dice: 0.5446000099182129 
2025-01-02 23:21:04.934317:  
2025-01-02 23:21:04.934317: Epoch 51 
2025-01-02 23:21:04.939332: Current learning rate: 0.00526 
2025-01-02 23:21:47.324262: train_loss -0.5028 
2025-01-02 23:21:47.324262: val_loss -0.5142 
2025-01-02 23:21:47.331903: Pseudo dice [np.float32(0.7207), np.float32(0.3733)] 
2025-01-02 23:21:47.336920: Epoch time: 42.39 s 
2025-01-02 23:21:47.340431: Yayy! New best EMA pseudo Dice: 0.5447999835014343 
2025-01-02 23:21:48.141958:  
2025-01-02 23:21:48.141958: Epoch 52 
2025-01-02 23:21:48.147016: Current learning rate: 0.00517 
2025-01-02 23:22:29.911028: train_loss -0.5 
2025-01-02 23:22:29.911542: val_loss -0.5304 
2025-01-02 23:22:29.916124: Pseudo dice [np.float32(0.7317), np.float32(0.3979)] 
2025-01-02 23:22:29.920623: Epoch time: 41.77 s 
2025-01-02 23:22:29.923631: Yayy! New best EMA pseudo Dice: 0.5468000173568726 
2025-01-02 23:22:30.741622:  
2025-01-02 23:22:30.742624: Epoch 53 
2025-01-02 23:22:30.747765: Current learning rate: 0.00507 
2025-01-02 23:23:13.163877: train_loss -0.4972 
2025-01-02 23:23:13.164382: val_loss -0.5079 
2025-01-02 23:23:13.170485: Pseudo dice [np.float32(0.7234), np.float32(0.4123)] 
2025-01-02 23:23:13.173023: Epoch time: 42.42 s 
2025-01-02 23:23:13.178105: Yayy! New best EMA pseudo Dice: 0.5489000082015991 
2025-01-02 23:23:14.244877:  
2025-01-02 23:23:14.244877: Epoch 54 
2025-01-02 23:23:14.249889: Current learning rate: 0.00497 
2025-01-02 23:23:56.712350: train_loss -0.5155 
2025-01-02 23:23:56.712853: val_loss -0.515 
2025-01-02 23:23:56.718872: Pseudo dice [np.float32(0.714), np.float32(0.4508)] 
2025-01-02 23:23:56.722885: Epoch time: 42.47 s 
2025-01-02 23:23:56.727396: Yayy! New best EMA pseudo Dice: 0.552299976348877 
2025-01-02 23:23:57.538122:  
2025-01-02 23:23:57.539125: Epoch 55 
2025-01-02 23:23:57.545706: Current learning rate: 0.00487 
2025-01-02 23:24:39.510185: train_loss -0.5329 
2025-01-02 23:24:39.511189: val_loss -0.5067 
2025-01-02 23:24:39.517201: Pseudo dice [np.float32(0.7205), np.float32(0.3523)] 
2025-01-02 23:24:39.520210: Epoch time: 41.97 s 
2025-01-02 23:24:40.133280:  
2025-01-02 23:24:40.134280: Epoch 56 
2025-01-02 23:24:40.139366: Current learning rate: 0.00478 
2025-01-02 23:25:21.925788: train_loss -0.5236 
2025-01-02 23:25:21.926300: val_loss -0.5175 
2025-01-02 23:25:21.931875: Pseudo dice [np.float32(0.7083), np.float32(0.475)] 
2025-01-02 23:25:21.935882: Epoch time: 41.79 s 
2025-01-02 23:25:21.939393: Yayy! New best EMA pseudo Dice: 0.5547999739646912 
2025-01-02 23:25:22.723832:  
2025-01-02 23:25:22.723832: Epoch 57 
2025-01-02 23:25:22.729862: Current learning rate: 0.00468 
2025-01-02 23:26:05.245921: train_loss -0.514 
2025-01-02 23:26:05.246469: val_loss -0.4882 
2025-01-02 23:26:05.253607: Pseudo dice [np.float32(0.708), np.float32(0.4203)] 
2025-01-02 23:26:05.257202: Epoch time: 42.52 s 
2025-01-02 23:26:05.261264: Yayy! New best EMA pseudo Dice: 0.5557000041007996 
2025-01-02 23:26:06.063271:  
2025-01-02 23:26:06.064270: Epoch 58 
2025-01-02 23:26:06.069868: Current learning rate: 0.00458 
2025-01-02 23:26:48.102941: train_loss -0.535 
2025-01-02 23:26:48.103443: val_loss -0.5408 
2025-01-02 23:26:48.109459: Pseudo dice [np.float32(0.7427), np.float32(0.4639)] 
2025-01-02 23:26:48.113468: Epoch time: 42.04 s 
2025-01-02 23:26:48.116981: Yayy! New best EMA pseudo Dice: 0.5605000257492065 
2025-01-02 23:26:48.892635:  
2025-01-02 23:26:48.892635: Epoch 59 
2025-01-02 23:26:48.898656: Current learning rate: 0.00448 
2025-01-02 23:27:30.845760: train_loss -0.5528 
2025-01-02 23:27:30.845760: val_loss -0.5405 
2025-01-02 23:27:30.852364: Pseudo dice [np.float32(0.7338), np.float32(0.4567)] 
2025-01-02 23:27:30.855441: Epoch time: 41.95 s 
2025-01-02 23:27:30.858999: Yayy! New best EMA pseudo Dice: 0.5640000104904175 
2025-01-02 23:27:31.689840:  
2025-01-02 23:27:31.690343: Epoch 60 
2025-01-02 23:27:31.695352: Current learning rate: 0.00438 
2025-01-02 23:28:13.743616: train_loss -0.5088 
2025-01-02 23:28:13.743616: val_loss -0.5291 
2025-01-02 23:28:13.749640: Pseudo dice [np.float32(0.7513), np.float32(0.4702)] 
2025-01-02 23:28:13.754158: Epoch time: 42.05 s 
2025-01-02 23:28:13.757259: Yayy! New best EMA pseudo Dice: 0.5685999989509583 
2025-01-02 23:28:14.577430:  
2025-01-02 23:28:14.577430: Epoch 61 
2025-01-02 23:28:14.583457: Current learning rate: 0.00429 
2025-01-02 23:28:56.160003: train_loss -0.5056 
2025-01-02 23:28:56.161004: val_loss -0.4514 
2025-01-02 23:28:56.166576: Pseudo dice [np.float32(0.7136), np.float32(0.2597)] 
2025-01-02 23:28:56.170085: Epoch time: 41.58 s 
2025-01-02 23:28:56.905024:  
2025-01-02 23:28:56.906022: Epoch 62 
2025-01-02 23:28:56.911592: Current learning rate: 0.00419 
2025-01-02 23:29:38.388300: train_loss -0.5298 
2025-01-02 23:29:38.388818: val_loss -0.5499 
2025-01-02 23:29:38.395458: Pseudo dice [np.float32(0.756), np.float32(0.4557)] 
2025-01-02 23:29:38.399016: Epoch time: 41.48 s 
2025-01-02 23:29:38.975653:  
2025-01-02 23:29:38.975653: Epoch 63 
2025-01-02 23:29:38.981763: Current learning rate: 0.00409 
2025-01-02 23:30:20.605072: train_loss -0.5292 
2025-01-02 23:30:20.605072: val_loss -0.514 
2025-01-02 23:30:20.612089: Pseudo dice [np.float32(0.7492), np.float32(0.4001)] 
2025-01-02 23:30:20.615098: Epoch time: 41.63 s 
2025-01-02 23:30:21.199268:  
2025-01-02 23:30:21.199268: Epoch 64 
2025-01-02 23:30:21.205791: Current learning rate: 0.00399 
2025-01-02 23:31:03.606441: train_loss -0.5358 
2025-01-02 23:31:03.606945: val_loss -0.5059 
2025-01-02 23:31:03.612982: Pseudo dice [np.float32(0.7193), np.float32(0.3711)] 
2025-01-02 23:31:03.616492: Epoch time: 42.41 s 
2025-01-02 23:31:04.198267:  
2025-01-02 23:31:04.198267: Epoch 65 
2025-01-02 23:31:04.205328: Current learning rate: 0.00389 
2025-01-02 23:31:45.913588: train_loss -0.5455 
2025-01-02 23:31:45.914100: val_loss -0.5205 
2025-01-02 23:31:45.919167: Pseudo dice [np.float32(0.7218), np.float32(0.4477)] 
2025-01-02 23:31:45.923212: Epoch time: 41.72 s 
2025-01-02 23:31:46.522541:  
2025-01-02 23:31:46.523542: Epoch 66 
2025-01-02 23:31:46.529057: Current learning rate: 0.00379 
2025-01-02 23:32:27.927620: train_loss -0.5578 
2025-01-02 23:32:27.928619: val_loss -0.4898 
2025-01-02 23:32:27.934133: Pseudo dice [np.float32(0.7371), np.float32(0.3559)] 
2025-01-02 23:32:27.937643: Epoch time: 41.41 s 
2025-01-02 23:32:28.516556:  
2025-01-02 23:32:28.516556: Epoch 67 
2025-01-02 23:32:28.522593: Current learning rate: 0.00369 
2025-01-02 23:33:10.945633: train_loss -0.5443 
2025-01-02 23:33:10.946636: val_loss -0.5404 
2025-01-02 23:33:10.952152: Pseudo dice [np.float32(0.7511), np.float32(0.3999)] 
2025-01-02 23:33:10.955712: Epoch time: 42.43 s 
2025-01-02 23:33:11.557285:  
2025-01-02 23:33:11.558285: Epoch 68 
2025-01-02 23:33:11.563879: Current learning rate: 0.00359 
2025-01-02 23:33:53.201743: train_loss -0.5592 
2025-01-02 23:33:53.203249: val_loss -0.5605 
2025-01-02 23:33:53.209331: Pseudo dice [np.float32(0.7364), np.float32(0.5181)] 
2025-01-02 23:33:53.212855: Epoch time: 41.65 s 
2025-01-02 23:33:53.215880: Yayy! New best EMA pseudo Dice: 0.571399986743927 
2025-01-02 23:33:54.063448:  
2025-01-02 23:33:54.063448: Epoch 69 
2025-01-02 23:33:54.069466: Current learning rate: 0.00349 
2025-01-02 23:34:35.761272: train_loss -0.5409 
2025-01-02 23:34:35.761272: val_loss -0.5518 
2025-01-02 23:34:35.768791: Pseudo dice [np.float32(0.7353), np.float32(0.5044)] 
2025-01-02 23:34:35.772304: Epoch time: 41.7 s 
2025-01-02 23:34:35.775810: Yayy! New best EMA pseudo Dice: 0.576200008392334 
2025-01-02 23:34:36.769765:  
2025-01-02 23:34:36.769765: Epoch 70 
2025-01-02 23:34:36.775883: Current learning rate: 0.00338 
2025-01-02 23:35:19.516980: train_loss -0.5628 
2025-01-02 23:35:19.517493: val_loss -0.5406 
2025-01-02 23:35:19.525116: Pseudo dice [np.float32(0.7617), np.float32(0.3922)] 
2025-01-02 23:35:19.529194: Epoch time: 42.75 s 
2025-01-02 23:35:19.532241: Yayy! New best EMA pseudo Dice: 0.5763000249862671 
2025-01-02 23:35:20.351856:  
2025-01-02 23:35:20.352359: Epoch 71 
2025-01-02 23:35:20.357370: Current learning rate: 0.00328 
2025-01-02 23:36:01.713415: train_loss -0.5718 
2025-01-02 23:36:01.713415: val_loss -0.5012 
2025-01-02 23:36:01.719961: Pseudo dice [np.float32(0.7396), np.float32(0.3777)] 
2025-01-02 23:36:01.723499: Epoch time: 41.36 s 
2025-01-02 23:36:02.316156:  
2025-01-02 23:36:02.316658: Epoch 72 
2025-01-02 23:36:02.322674: Current learning rate: 0.00318 
2025-01-02 23:36:44.442322: train_loss -0.5761 
2025-01-02 23:36:44.442831: val_loss -0.5457 
2025-01-02 23:36:44.448472: Pseudo dice [np.float32(0.7271), np.float32(0.377)] 
2025-01-02 23:36:44.452549: Epoch time: 42.13 s 
2025-01-02 23:36:45.057184:  
2025-01-02 23:36:45.058189: Epoch 73 
2025-01-02 23:36:45.062735: Current learning rate: 0.00308 
2025-01-02 23:37:27.256285: train_loss -0.553 
2025-01-02 23:37:27.256796: val_loss -0.5739 
2025-01-02 23:37:27.263360: Pseudo dice [np.float32(0.7561), np.float32(0.474)] 
2025-01-02 23:37:27.266899: Epoch time: 42.2 s 
2025-01-02 23:37:27.270927: Yayy! New best EMA pseudo Dice: 0.5766000151634216 
2025-01-02 23:37:28.112229:  
2025-01-02 23:37:28.113231: Epoch 74 
2025-01-02 23:37:28.118810: Current learning rate: 0.00297 
2025-01-02 23:38:09.742325: train_loss -0.5883 
2025-01-02 23:38:09.742827: val_loss -0.5503 
2025-01-02 23:38:09.748872: Pseudo dice [np.float32(0.7615), np.float32(0.5081)] 
2025-01-02 23:38:09.753904: Epoch time: 41.63 s 
2025-01-02 23:38:09.757930: Yayy! New best EMA pseudo Dice: 0.5824000239372253 
2025-01-02 23:38:10.557076:  
2025-01-02 23:38:10.558076: Epoch 75 
2025-01-02 23:38:10.563663: Current learning rate: 0.00287 
2025-01-02 23:38:53.593595: train_loss -0.568 
2025-01-02 23:38:53.593595: val_loss -0.5311 
2025-01-02 23:38:53.601297: Pseudo dice [np.float32(0.7534), np.float32(0.3758)] 
2025-01-02 23:38:53.605323: Epoch time: 43.04 s 
2025-01-02 23:38:54.203109:  
2025-01-02 23:38:54.203109: Epoch 76 
2025-01-02 23:38:54.209126: Current learning rate: 0.00277 
2025-01-02 23:39:36.455094: train_loss -0.5762 
2025-01-02 23:39:36.456098: val_loss -0.5654 
2025-01-02 23:39:36.462618: Pseudo dice [np.float32(0.7606), np.float32(0.4474)] 
2025-01-02 23:39:36.466130: Epoch time: 42.25 s 
2025-01-02 23:39:36.469676: Yayy! New best EMA pseudo Dice: 0.5828999876976013 
2025-01-02 23:39:37.314463:  
2025-01-02 23:39:37.314463: Epoch 77 
2025-01-02 23:39:37.321673: Current learning rate: 0.00266 
2025-01-02 23:40:19.106128: train_loss -0.5899 
2025-01-02 23:40:19.107133: val_loss -0.5202 
2025-01-02 23:40:19.112213: Pseudo dice [np.float32(0.7734), np.float32(0.3884)] 
2025-01-02 23:40:19.116758: Epoch time: 41.79 s 
2025-01-02 23:40:19.991296:  
2025-01-02 23:40:19.992297: Epoch 78 
2025-01-02 23:40:19.997370: Current learning rate: 0.00256 
2025-01-02 23:41:01.165675: train_loss -0.5908 
2025-01-02 23:41:01.167182: val_loss -0.5633 
2025-01-02 23:41:01.174737: Pseudo dice [np.float32(0.7641), np.float32(0.5571)] 
2025-01-02 23:41:01.177752: Epoch time: 41.17 s 
2025-01-02 23:41:01.181271: Yayy! New best EMA pseudo Dice: 0.590499997138977 
2025-01-02 23:41:01.985010:  
2025-01-02 23:41:01.986008: Epoch 79 
2025-01-02 23:41:01.991610: Current learning rate: 0.00245 
2025-01-02 23:41:43.189671: train_loss -0.5876 
2025-01-02 23:41:43.189671: val_loss -0.5528 
2025-01-02 23:41:43.196187: Pseudo dice [np.float32(0.7528), np.float32(0.4013)] 
2025-01-02 23:41:43.199696: Epoch time: 41.2 s 
2025-01-02 23:41:43.802724:  
2025-01-02 23:41:43.802724: Epoch 80 
2025-01-02 23:41:43.808830: Current learning rate: 0.00235 
2025-01-02 23:42:24.997475: train_loss -0.5771 
2025-01-02 23:42:24.997475: val_loss -0.5042 
2025-01-02 23:42:25.003991: Pseudo dice [np.float32(0.7281), np.float32(0.3675)] 
2025-01-02 23:42:25.007500: Epoch time: 41.2 s 
2025-01-02 23:42:25.607021:  
2025-01-02 23:42:25.607021: Epoch 81 
2025-01-02 23:42:25.614037: Current learning rate: 0.00224 
2025-01-02 23:43:07.324554: train_loss -0.5647 
2025-01-02 23:43:07.325057: val_loss -0.5444 
2025-01-02 23:43:07.330584: Pseudo dice [np.float32(0.7647), np.float32(0.4144)] 
2025-01-02 23:43:07.334614: Epoch time: 41.72 s 
2025-01-02 23:43:07.933510:  
2025-01-02 23:43:07.933510: Epoch 82 
2025-01-02 23:43:07.939031: Current learning rate: 0.00214 
2025-01-02 23:43:49.102313: train_loss -0.5804 
2025-01-02 23:43:49.103329: val_loss -0.5851 
2025-01-02 23:43:49.109378: Pseudo dice [np.float32(0.7771), np.float32(0.5364)] 
2025-01-02 23:43:49.112917: Epoch time: 41.17 s 
2025-01-02 23:43:49.115951: Yayy! New best EMA pseudo Dice: 0.5925999879837036 
2025-01-02 23:43:49.915696:  
2025-01-02 23:43:49.915696: Epoch 83 
2025-01-02 23:43:49.921711: Current learning rate: 0.00203 
2025-01-02 23:44:32.016315: train_loss -0.5823 
2025-01-02 23:44:32.017320: val_loss -0.5618 
2025-01-02 23:44:32.022471: Pseudo dice [np.float32(0.7646), np.float32(0.4285)] 
2025-01-02 23:44:32.027501: Epoch time: 42.1 s 
2025-01-02 23:44:32.031518: Yayy! New best EMA pseudo Dice: 0.5929999947547913 
2025-01-02 23:44:32.894444:  
2025-01-02 23:44:32.894947: Epoch 84 
2025-01-02 23:44:32.899959: Current learning rate: 0.00192 
2025-01-02 23:45:14.738505: train_loss -0.5988 
2025-01-02 23:45:14.739505: val_loss -0.5222 
2025-01-02 23:45:14.746025: Pseudo dice [np.float32(0.7489), np.float32(0.4121)] 
2025-01-02 23:45:14.750039: Epoch time: 41.85 s 
2025-01-02 23:45:15.324158:  
2025-01-02 23:45:15.324158: Epoch 85 
2025-01-02 23:45:15.329720: Current learning rate: 0.00181 
2025-01-02 23:45:57.229166: train_loss -0.6058 
2025-01-02 23:45:57.229669: val_loss -0.5663 
2025-01-02 23:45:57.235717: Pseudo dice [np.float32(0.7596), np.float32(0.4496)] 
2025-01-02 23:45:57.240244: Epoch time: 41.91 s 
2025-01-02 23:45:57.243269: Yayy! New best EMA pseudo Dice: 0.5929999947547913 
2025-01-02 23:45:58.248903:  
2025-01-02 23:45:58.248903: Epoch 86 
2025-01-02 23:45:58.254917: Current learning rate: 0.0017 
2025-01-02 23:46:39.732579: train_loss -0.5821 
2025-01-02 23:46:39.732579: val_loss -0.5789 
2025-01-02 23:46:39.739667: Pseudo dice [np.float32(0.7513), np.float32(0.5015)] 
2025-01-02 23:46:39.742728: Epoch time: 41.49 s 
2025-01-02 23:46:39.747237: Yayy! New best EMA pseudo Dice: 0.5964000225067139 
2025-01-02 23:46:40.514174:  
2025-01-02 23:46:40.514174: Epoch 87 
2025-01-02 23:46:40.520707: Current learning rate: 0.00159 
2025-01-02 23:47:21.900901: train_loss -0.6317 
2025-01-02 23:47:21.900901: val_loss -0.578 
2025-01-02 23:47:21.907493: Pseudo dice [np.float32(0.7676), np.float32(0.5026)] 
2025-01-02 23:47:21.911502: Epoch time: 41.39 s 
2025-01-02 23:47:21.916012: Yayy! New best EMA pseudo Dice: 0.6003000140190125 
2025-01-02 23:47:22.702909:  
2025-01-02 23:47:22.703913: Epoch 88 
2025-01-02 23:47:22.709994: Current learning rate: 0.00148 
2025-01-02 23:48:04.415100: train_loss -0.63 
2025-01-02 23:48:04.415602: val_loss -0.5752 
2025-01-02 23:48:04.423122: Pseudo dice [np.float32(0.7911), np.float32(0.5001)] 
2025-01-02 23:48:04.427632: Epoch time: 41.71 s 
2025-01-02 23:48:04.430640: Yayy! New best EMA pseudo Dice: 0.6047999858856201 
2025-01-02 23:48:05.226561:  
2025-01-02 23:48:05.226561: Epoch 89 
2025-01-02 23:48:05.233129: Current learning rate: 0.00137 
2025-01-02 23:48:46.554706: train_loss -0.5974 
2025-01-02 23:48:46.555217: val_loss -0.5831 
2025-01-02 23:48:46.561791: Pseudo dice [np.float32(0.7715), np.float32(0.5242)] 
2025-01-02 23:48:46.564827: Epoch time: 41.33 s 
2025-01-02 23:48:46.569361: Yayy! New best EMA pseudo Dice: 0.6090999841690063 
2025-01-02 23:48:47.411839:  
2025-01-02 23:48:47.412839: Epoch 90 
2025-01-02 23:48:47.419356: Current learning rate: 0.00126 
2025-01-02 23:49:28.659539: train_loss -0.6215 
2025-01-02 23:49:28.660057: val_loss -0.4946 
2025-01-02 23:49:28.666688: Pseudo dice [np.float32(0.7599), np.float32(0.3669)] 
2025-01-02 23:49:28.671756: Epoch time: 41.25 s 
2025-01-02 23:49:29.238183:  
2025-01-02 23:49:29.238183: Epoch 91 
2025-01-02 23:49:29.245754: Current learning rate: 0.00115 
2025-01-02 23:50:10.721823: train_loss -0.6193 
2025-01-02 23:50:10.721823: val_loss -0.5582 
2025-01-02 23:50:10.729505: Pseudo dice [np.float32(0.7614), np.float32(0.451)] 
2025-01-02 23:50:10.733539: Epoch time: 41.48 s 
2025-01-02 23:50:11.291930:  
2025-01-02 23:50:11.291930: Epoch 92 
2025-01-02 23:50:11.299476: Current learning rate: 0.00103 
2025-01-02 23:50:52.487765: train_loss -0.5944 
2025-01-02 23:50:52.488776: val_loss -0.5192 
2025-01-02 23:50:52.494894: Pseudo dice [np.float32(0.7409), np.float32(0.378)] 
2025-01-02 23:50:52.499450: Epoch time: 41.2 s 
2025-01-02 23:50:53.058671:  
2025-01-02 23:50:53.058671: Epoch 93 
2025-01-02 23:50:53.065248: Current learning rate: 0.00091 
2025-01-02 23:51:34.217026: train_loss -0.6302 
2025-01-02 23:51:34.218029: val_loss -0.5439 
2025-01-02 23:51:34.224100: Pseudo dice [np.float32(0.7414), np.float32(0.419)] 
2025-01-02 23:51:34.228160: Epoch time: 41.16 s 
2025-01-02 23:51:34.940641:  
2025-01-02 23:51:34.940641: Epoch 94 
2025-01-02 23:51:34.947234: Current learning rate: 0.00079 
2025-01-02 23:52:16.049664: train_loss -0.6315 
2025-01-02 23:52:16.050168: val_loss -0.5366 
2025-01-02 23:52:16.056225: Pseudo dice [np.float32(0.7779), np.float32(0.4173)] 
2025-01-02 23:52:16.060078: Epoch time: 41.11 s 
2025-01-02 23:52:16.622446:  
2025-01-02 23:52:16.623450: Epoch 95 
2025-01-02 23:52:16.629030: Current learning rate: 0.00067 
2025-01-02 23:52:57.757347: train_loss -0.6389 
2025-01-02 23:52:57.758352: val_loss -0.5339 
2025-01-02 23:52:57.766352: Pseudo dice [np.float32(0.7414), np.float32(0.4492)] 
2025-01-02 23:52:57.769924: Epoch time: 41.13 s 
2025-01-02 23:52:58.331004:  
2025-01-02 23:52:58.331004: Epoch 96 
2025-01-02 23:52:58.337580: Current learning rate: 0.00055 
2025-01-02 23:53:39.436194: train_loss -0.6419 
2025-01-02 23:53:39.436194: val_loss -0.5858 
2025-01-02 23:53:39.442227: Pseudo dice [np.float32(0.7716), np.float32(0.4793)] 
2025-01-02 23:53:39.448759: Epoch time: 41.11 s 
2025-01-02 23:53:40.074962:  
2025-01-02 23:53:40.074962: Epoch 97 
2025-01-02 23:53:40.081503: Current learning rate: 0.00043 
2025-01-02 23:54:21.194885: train_loss -0.6282 
2025-01-02 23:54:21.195888: val_loss -0.5955 
2025-01-02 23:54:21.202406: Pseudo dice [np.float32(0.7915), np.float32(0.517)] 
2025-01-02 23:54:21.206914: Epoch time: 41.12 s 
2025-01-02 23:54:21.783249:  
2025-01-02 23:54:21.784253: Epoch 98 
2025-01-02 23:54:21.790400: Current learning rate: 0.0003 
2025-01-02 23:55:02.938780: train_loss -0.6376 
2025-01-02 23:55:02.939282: val_loss -0.5804 
2025-01-02 23:55:02.945369: Pseudo dice [np.float32(0.7838), np.float32(0.4665)] 
2025-01-02 23:55:02.949436: Epoch time: 41.16 s 
2025-01-02 23:55:03.521455:  
2025-01-02 23:55:03.521455: Epoch 99 
2025-01-02 23:55:03.528475: Current learning rate: 0.00016 
2025-01-02 23:55:44.695588: train_loss -0.6322 
2025-01-02 23:55:44.696592: val_loss -0.5795 
2025-01-02 23:55:44.702656: Pseudo dice [np.float32(0.7851), np.float32(0.4626)] 
2025-01-02 23:55:44.706704: Epoch time: 41.18 s 
2025-01-02 23:55:44.710748: Yayy! New best EMA pseudo Dice: 0.609499990940094 
2025-01-02 23:55:45.736115: Training done. 
2025-01-02 23:55:45.778116: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-02 23:55:45.787116: The split file contains 5 splits. 
2025-01-02 23:55:45.796114: Desired fold for training: 0 
2025-01-02 23:55:45.807115: This split has 224 training and 57 validation cases. 
2025-01-02 23:55:45.815120: predicting pancreas_021 
2025-01-02 23:55:45.823120: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-02 23:55:58.357117: predicting pancreas_024 
2025-01-02 23:55:58.368118: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-02 23:56:13.000713: predicting pancreas_035 
2025-01-02 23:56:13.011714: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-02 23:56:17.982797: predicting pancreas_040 
2025-01-02 23:56:17.988797: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-01-02 23:56:29.712326: predicting pancreas_042 
2025-01-02 23:56:29.723327: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-01-02 23:56:44.370067: predicting pancreas_056 
2025-01-02 23:56:44.383067: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-02 23:56:56.096515: predicting pancreas_067 
2025-01-02 23:56:56.105516: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-02 23:57:10.764421: predicting pancreas_075 
2025-01-02 23:57:10.776929: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-01-02 23:57:16.684405: predicting pancreas_086 
2025-01-02 23:57:16.691406: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-02 23:57:25.834528: predicting pancreas_089 
2025-01-02 23:57:25.844528: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-02 23:57:37.547336: predicting pancreas_092 
2025-01-02 23:57:37.556337: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-01-02 23:58:03.910064: predicting pancreas_094 
2025-01-02 23:58:03.927065: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-02 23:58:15.648769: predicting pancreas_095 
2025-01-02 23:58:15.656768: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-02 23:58:27.410943: predicting pancreas_098 
2025-01-02 23:58:27.419940: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-02 23:58:59.399870: predicting pancreas_109 
2025-01-02 23:58:59.420866: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-02 23:59:11.210560: predicting pancreas_110 
2025-01-02 23:59:11.224559: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-02 23:59:29.552530: predicting pancreas_114 
2025-01-02 23:59:29.568039: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-02 23:59:41.318531: predicting pancreas_119 
2025-01-02 23:59:41.330532: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-02 23:59:59.625149: predicting pancreas_138 
2025-01-02 23:59:59.637149: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-03 00:00:17.970054: predicting pancreas_145 
2025-01-03 00:00:17.984060: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-03 00:00:36.325748: predicting pancreas_148 
2025-01-03 00:00:36.339748: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-01-03 00:00:48.107835: predicting pancreas_169 
2025-01-03 00:00:48.121342: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-03 00:00:59.913357: predicting pancreas_170 
2025-01-03 00:00:59.922358: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-03 00:01:14.469967: predicting pancreas_172 
2025-01-03 00:01:14.481967: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-03 00:01:26.159664: predicting pancreas_175 
2025-01-03 00:01:26.168665: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-03 00:01:37.828343: predicting pancreas_180 
2025-01-03 00:01:37.839344: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-03 00:01:49.560350: predicting pancreas_191 
2025-01-03 00:01:49.569350: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-03 00:01:55.419280: predicting pancreas_193 
2025-01-03 00:01:55.427281: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-03 00:02:10.000645: predicting pancreas_212 
2025-01-03 00:02:10.013646: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-03 00:02:21.707307: predicting pancreas_215 
2025-01-03 00:02:21.720308: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-03 00:02:33.427250: predicting pancreas_222 
2025-01-03 00:02:33.436250: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-03 00:02:38.394142: predicting pancreas_235 
2025-01-03 00:02:38.402143: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-03 00:02:50.065076: predicting pancreas_241 
2025-01-03 00:02:50.073077: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-03 00:03:01.760604: predicting pancreas_242 
2025-01-03 00:03:01.770605: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-03 00:03:16.370325: predicting pancreas_244 
2025-01-03 00:03:16.382326: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-03 00:03:39.103209: predicting pancreas_246 
2025-01-03 00:03:39.117210: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-03 00:04:01.869513: predicting pancreas_247 
2025-01-03 00:04:01.883512: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-03 00:04:08.482131: predicting pancreas_264 
2025-01-03 00:04:08.490131: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-03 00:04:23.100106: predicting pancreas_265 
2025-01-03 00:04:23.112106: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-03 00:04:34.786703: predicting pancreas_266 
2025-01-03 00:04:34.797698: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-03 00:04:52.987882: predicting pancreas_267 
2025-01-03 00:04:53.000883: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-03 00:04:59.609674: predicting pancreas_275 
2025-01-03 00:04:59.618675: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-03 00:05:14.193512: predicting pancreas_279 
2025-01-03 00:05:14.203513: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-03 00:05:19.191146: predicting pancreas_287 
2025-01-03 00:05:19.198146: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-03 00:05:30.893295: predicting pancreas_301 
2025-01-03 00:05:30.903296: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-03 00:05:42.597217: predicting pancreas_323 
2025-01-03 00:05:42.607218: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-03 00:06:02.408983: predicting pancreas_336 
2025-01-03 00:06:02.426982: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-03 00:06:17.738988: predicting pancreas_344 
2025-01-03 00:06:17.755987: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-03 00:06:32.722682: predicting pancreas_351 
2025-01-03 00:06:32.734682: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-03 00:06:39.651938: predicting pancreas_354 
2025-01-03 00:06:39.660939: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-01-03 00:07:03.347838: predicting pancreas_372 
2025-01-03 00:07:03.363839: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-03 00:07:21.694138: predicting pancreas_377 
2025-01-03 00:07:21.710138: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-01-03 00:07:36.401428: predicting pancreas_387 
2025-01-03 00:07:36.414427: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-01-03 00:07:48.465454: predicting pancreas_391 
2025-01-03 00:07:48.480455: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-03 00:08:07.297947: predicting pancreas_392 
2025-01-03 00:08:07.310948: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-01-03 00:08:15.610926: predicting pancreas_410 
2025-01-03 00:08:15.619925: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-03 00:08:23.909727: predicting pancreas_412 
2025-01-03 00:08:23.918727: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-01-03 00:09:23.802860: Validation complete 
2025-01-03 00:09:23.803860: Mean Validation Dice:  0.615438854758962 
