
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-16 08:19:37.561029: do_dummy_2d_data_aug: True 
2025-01-16 08:19:37.566032: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-16 08:19:37.572032: The split file contains 5 splits. 
2025-01-16 08:19:37.575032: Desired fold for training: 0 
2025-01-16 08:19:37.577035: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-16 08:19:44.100603: unpacking dataset... 
2025-01-16 08:19:44.504364: unpacking done... 
2025-01-16 08:19:48.103597:  
2025-01-16 08:19:48.104595: Epoch 0 
2025-01-16 08:19:48.108606: Current learning rate: 0.01 
2025-01-16 08:20:34.367799: train_loss 0.1001 
2025-01-16 08:20:34.368804: val_loss 0.0371 
2025-01-16 08:20:34.373815: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-16 08:20:34.377833: Epoch time: 46.26 s 
2025-01-16 08:20:34.380338: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-16 08:20:35.082460:  
2025-01-16 08:20:35.082460: Epoch 1 
2025-01-16 08:20:35.088009: Current learning rate: 0.00996 
2025-01-16 08:21:16.957843: train_loss -0.0143 
2025-01-16 08:21:16.957843: val_loss -0.1231 
2025-01-16 08:21:16.964899: Pseudo dice [np.float32(0.4362), np.float32(0.0)] 
2025-01-16 08:21:16.967913: Epoch time: 41.88 s 
2025-01-16 08:21:16.972936: Yayy! New best EMA pseudo Dice: 0.021800000220537186 
2025-01-16 08:21:17.691882:  
2025-01-16 08:21:17.691882: Epoch 2 
2025-01-16 08:21:17.697907: Current learning rate: 0.00993 
2025-01-16 08:21:59.602292: train_loss -0.1517 
2025-01-16 08:21:59.602797: val_loss -0.269 
2025-01-16 08:21:59.607809: Pseudo dice [np.float32(0.6374), np.float32(0.0)] 
2025-01-16 08:21:59.612820: Epoch time: 41.91 s 
2025-01-16 08:21:59.615842: Yayy! New best EMA pseudo Dice: 0.051500000059604645 
2025-01-16 08:22:00.374515:  
2025-01-16 08:22:00.375520: Epoch 3 
2025-01-16 08:22:00.381069: Current learning rate: 0.00989 
2025-01-16 08:22:42.279198: train_loss -0.1939 
2025-01-16 08:22:42.280198: val_loss -0.2749 
2025-01-16 08:22:42.285713: Pseudo dice [np.float32(0.6192), np.float32(0.0)] 
2025-01-16 08:22:42.289225: Epoch time: 41.9 s 
2025-01-16 08:22:42.291730: Yayy! New best EMA pseudo Dice: 0.07729999721050262 
2025-01-16 08:22:43.056879:  
2025-01-16 08:22:43.056879: Epoch 4 
2025-01-16 08:22:43.061893: Current learning rate: 0.00986 
2025-01-16 08:23:24.927075: train_loss -0.2301 
2025-01-16 08:23:24.927579: val_loss -0.2263 
2025-01-16 08:23:24.932627: Pseudo dice [np.float32(0.5555), np.float32(0.0)] 
2025-01-16 08:23:24.936176: Epoch time: 41.87 s 
2025-01-16 08:23:24.939227: Yayy! New best EMA pseudo Dice: 0.09740000218153 
2025-01-16 08:23:25.856586:  
2025-01-16 08:23:25.856586: Epoch 5 
2025-01-16 08:23:25.862112: Current learning rate: 0.00982 
2025-01-16 08:24:07.746788: train_loss -0.2677 
2025-01-16 08:24:07.747791: val_loss -0.2737 
2025-01-16 08:24:07.752890: Pseudo dice [np.float32(0.6195), np.float32(0.0)] 
2025-01-16 08:24:07.756458: Epoch time: 41.89 s 
2025-01-16 08:24:07.760560: Yayy! New best EMA pseudo Dice: 0.11860000342130661 
2025-01-16 08:24:08.544747:  
2025-01-16 08:24:08.544747: Epoch 6 
2025-01-16 08:24:08.550294: Current learning rate: 0.00978 
2025-01-16 08:24:50.263672: train_loss -0.2849 
2025-01-16 08:24:50.264673: val_loss -0.2994 
2025-01-16 08:24:50.270221: Pseudo dice [np.float32(0.6767), np.float32(0.0)] 
2025-01-16 08:24:50.275237: Epoch time: 41.72 s 
2025-01-16 08:24:50.280250: Yayy! New best EMA pseudo Dice: 0.14059999585151672 
2025-01-16 08:24:51.054236:  
2025-01-16 08:24:51.054236: Epoch 7 
2025-01-16 08:24:51.060270: Current learning rate: 0.00975 
2025-01-16 08:25:31.819278: train_loss -0.2953 
2025-01-16 08:25:31.820283: val_loss -0.3344 
2025-01-16 08:25:31.825296: Pseudo dice [np.float32(0.6359), np.float32(0.2221)] 
2025-01-16 08:25:31.830312: Epoch time: 40.77 s 
2025-01-16 08:25:31.832820: Yayy! New best EMA pseudo Dice: 0.16940000653266907 
2025-01-16 08:25:32.582869:  
2025-01-16 08:25:32.583871: Epoch 8 
2025-01-16 08:25:32.588446: Current learning rate: 0.00971 
2025-01-16 08:26:13.327464: train_loss -0.3386 
2025-01-16 08:26:13.328467: val_loss -0.4187 
2025-01-16 08:26:13.334482: Pseudo dice [np.float32(0.6548), np.float32(0.3758)] 
2025-01-16 08:26:13.337568: Epoch time: 40.74 s 
2025-01-16 08:26:13.340076: Yayy! New best EMA pseudo Dice: 0.20399999618530273 
2025-01-16 08:26:14.126886:  
2025-01-16 08:26:14.127889: Epoch 9 
2025-01-16 08:26:14.132524: Current learning rate: 0.00968 
2025-01-16 08:26:54.906535: train_loss -0.3645 
2025-01-16 08:26:54.906535: val_loss -0.4333 
2025-01-16 08:26:54.913660: Pseudo dice [np.float32(0.6777), np.float32(0.3365)] 
2025-01-16 08:26:54.918174: Epoch time: 40.78 s 
2025-01-16 08:26:54.921185: Yayy! New best EMA pseudo Dice: 0.23430000245571136 
2025-01-16 08:26:55.640053:  
2025-01-16 08:26:55.640053: Epoch 10 
2025-01-16 08:26:55.645592: Current learning rate: 0.00964 
2025-01-16 08:27:36.382589: train_loss -0.356 
2025-01-16 08:27:36.382589: val_loss -0.3885 
2025-01-16 08:27:36.389121: Pseudo dice [np.float32(0.6707), np.float32(0.266)] 
2025-01-16 08:27:36.393135: Epoch time: 40.74 s 
2025-01-16 08:27:36.397147: Yayy! New best EMA pseudo Dice: 0.25769999623298645 
2025-01-16 08:27:37.115295:  
2025-01-16 08:27:37.115295: Epoch 11 
2025-01-16 08:27:37.121398: Current learning rate: 0.0096 
2025-01-16 08:28:17.856190: train_loss -0.3725 
2025-01-16 08:28:17.856190: val_loss -0.4332 
2025-01-16 08:28:17.861736: Pseudo dice [np.float32(0.6585), np.float32(0.4019)] 
2025-01-16 08:28:17.865749: Epoch time: 40.74 s 
2025-01-16 08:28:17.868259: Yayy! New best EMA pseudo Dice: 0.2849999964237213 
2025-01-16 08:28:18.612777:  
2025-01-16 08:28:18.613280: Epoch 12 
2025-01-16 08:28:18.618293: Current learning rate: 0.00957 
2025-01-16 08:29:03.101322: train_loss -0.4043 
2025-01-16 08:29:03.101322: val_loss -0.408 
2025-01-16 08:29:03.107835: Pseudo dice [np.float32(0.7093), np.float32(0.2394)] 
2025-01-16 08:29:03.111345: Epoch time: 44.49 s 
2025-01-16 08:29:03.116384: Yayy! New best EMA pseudo Dice: 0.30390000343322754 
2025-01-16 08:29:04.007557:  
2025-01-16 08:29:04.008556: Epoch 13 
2025-01-16 08:29:04.015682: Current learning rate: 0.00953 
2025-01-16 08:29:44.759212: train_loss -0.4241 
2025-01-16 08:29:44.759718: val_loss -0.4943 
2025-01-16 08:29:44.764734: Pseudo dice [np.float32(0.6997), np.float32(0.3739)] 
2025-01-16 08:29:44.768764: Epoch time: 40.75 s 
2025-01-16 08:29:44.772273: Yayy! New best EMA pseudo Dice: 0.3271999955177307 
2025-01-16 08:29:45.497859:  
2025-01-16 08:29:45.498858: Epoch 14 
2025-01-16 08:29:45.503907: Current learning rate: 0.00949 
2025-01-16 08:30:26.230615: train_loss -0.4194 
2025-01-16 08:30:26.231618: val_loss -0.4362 
2025-01-16 08:30:26.237819: Pseudo dice [np.float32(0.7064), np.float32(0.279)] 
2025-01-16 08:30:26.243462: Epoch time: 40.73 s 
2025-01-16 08:30:26.246495: Yayy! New best EMA pseudo Dice: 0.34369999170303345 
2025-01-16 08:30:26.981951:  
2025-01-16 08:30:26.981951: Epoch 15 
2025-01-16 08:30:26.987515: Current learning rate: 0.00946 
2025-01-16 08:31:07.722755: train_loss -0.4506 
2025-01-16 08:31:07.723257: val_loss -0.4894 
2025-01-16 08:31:07.728270: Pseudo dice [np.float32(0.6946), np.float32(0.4234)] 
2025-01-16 08:31:07.731779: Epoch time: 40.74 s 
2025-01-16 08:31:07.735288: Yayy! New best EMA pseudo Dice: 0.3652999997138977 
2025-01-16 08:31:08.517725:  
2025-01-16 08:31:08.518728: Epoch 16 
2025-01-16 08:31:08.523771: Current learning rate: 0.00942 
2025-01-16 08:31:49.264043: train_loss -0.4168 
2025-01-16 08:31:49.265043: val_loss -0.5054 
2025-01-16 08:31:49.270647: Pseudo dice [np.float32(0.7148), np.float32(0.3507)] 
2025-01-16 08:31:49.273196: Epoch time: 40.75 s 
2025-01-16 08:31:49.277248: Yayy! New best EMA pseudo Dice: 0.38199999928474426 
2025-01-16 08:31:50.045899:  
2025-01-16 08:31:50.045899: Epoch 17 
2025-01-16 08:31:50.050914: Current learning rate: 0.00939 
2025-01-16 08:32:30.779055: train_loss -0.4512 
2025-01-16 08:32:30.779055: val_loss -0.4887 
2025-01-16 08:32:30.784147: Pseudo dice [np.float32(0.7209), np.float32(0.3933)] 
2025-01-16 08:32:30.788716: Epoch time: 40.73 s 
2025-01-16 08:32:30.791813: Yayy! New best EMA pseudo Dice: 0.3995000123977661 
2025-01-16 08:32:31.536034:  
2025-01-16 08:32:31.536034: Epoch 18 
2025-01-16 08:32:31.541066: Current learning rate: 0.00935 
2025-01-16 08:33:12.284546: train_loss -0.4457 
2025-01-16 08:33:12.285049: val_loss -0.4978 
2025-01-16 08:33:12.290060: Pseudo dice [np.float32(0.7344), np.float32(0.3348)] 
2025-01-16 08:33:12.293568: Epoch time: 40.75 s 
2025-01-16 08:33:12.296078: Yayy! New best EMA pseudo Dice: 0.4129999876022339 
2025-01-16 08:33:13.034271:  
2025-01-16 08:33:13.034271: Epoch 19 
2025-01-16 08:33:13.039836: Current learning rate: 0.00931 
2025-01-16 08:33:53.770788: train_loss -0.4901 
2025-01-16 08:33:53.771787: val_loss -0.4942 
2025-01-16 08:33:53.777362: Pseudo dice [np.float32(0.7152), np.float32(0.3816)] 
2025-01-16 08:33:53.780906: Epoch time: 40.74 s 
2025-01-16 08:33:53.783412: Yayy! New best EMA pseudo Dice: 0.42660000920295715 
2025-01-16 08:33:54.519135:  
2025-01-16 08:33:54.519638: Epoch 20 
2025-01-16 08:33:54.524656: Current learning rate: 0.00928 
2025-01-16 08:34:35.271435: train_loss -0.4813 
2025-01-16 08:34:35.272435: val_loss -0.49 
2025-01-16 08:34:35.277959: Pseudo dice [np.float32(0.7053), np.float32(0.3772)] 
2025-01-16 08:34:35.281476: Epoch time: 40.75 s 
2025-01-16 08:34:35.283982: Yayy! New best EMA pseudo Dice: 0.43799999356269836 
2025-01-16 08:34:36.198347:  
2025-01-16 08:34:36.198849: Epoch 21 
2025-01-16 08:34:36.203866: Current learning rate: 0.00924 
2025-01-16 08:35:16.935295: train_loss -0.5097 
2025-01-16 08:35:16.935799: val_loss -0.4823 
2025-01-16 08:35:16.940393: Pseudo dice [np.float32(0.7045), np.float32(0.3982)] 
2025-01-16 08:35:16.944010: Epoch time: 40.74 s 
2025-01-16 08:35:16.947384: Yayy! New best EMA pseudo Dice: 0.44940000772476196 
2025-01-16 08:35:17.638434:  
2025-01-16 08:35:17.638936: Epoch 22 
2025-01-16 08:35:17.643948: Current learning rate: 0.0092 
2025-01-16 08:35:58.390676: train_loss -0.4944 
2025-01-16 08:35:58.391681: val_loss -0.5241 
2025-01-16 08:35:58.397690: Pseudo dice [np.float32(0.7464), np.float32(0.3724)] 
2025-01-16 08:35:58.401706: Epoch time: 40.75 s 
2025-01-16 08:35:58.404211: Yayy! New best EMA pseudo Dice: 0.4603999853134155 
2025-01-16 08:35:59.122662:  
2025-01-16 08:35:59.123662: Epoch 23 
2025-01-16 08:35:59.129176: Current learning rate: 0.00917 
2025-01-16 08:36:39.862555: train_loss -0.5103 
2025-01-16 08:36:39.862555: val_loss -0.4452 
2025-01-16 08:36:39.869072: Pseudo dice [np.float32(0.7113), np.float32(0.336)] 
2025-01-16 08:36:39.871578: Epoch time: 40.74 s 
2025-01-16 08:36:39.875091: Yayy! New best EMA pseudo Dice: 0.4666999876499176 
2025-01-16 08:36:40.636152:  
2025-01-16 08:36:40.636654: Epoch 24 
2025-01-16 08:36:40.641669: Current learning rate: 0.00913 
2025-01-16 08:37:21.371097: train_loss -0.4961 
2025-01-16 08:37:21.372180: val_loss -0.5012 
2025-01-16 08:37:21.377220: Pseudo dice [np.float32(0.7488), np.float32(0.3707)] 
2025-01-16 08:37:21.380760: Epoch time: 40.74 s 
2025-01-16 08:37:21.383854: Yayy! New best EMA pseudo Dice: 0.47600001096725464 
2025-01-16 08:37:22.123210:  
2025-01-16 08:37:22.124214: Epoch 25 
2025-01-16 08:37:22.128760: Current learning rate: 0.0091 
2025-01-16 08:38:02.855837: train_loss -0.5143 
2025-01-16 08:38:02.856353: val_loss -0.5177 
2025-01-16 08:38:02.861408: Pseudo dice [np.float32(0.741), np.float32(0.4069)] 
2025-01-16 08:38:02.864447: Epoch time: 40.73 s 
2025-01-16 08:38:02.867483: Yayy! New best EMA pseudo Dice: 0.48579999804496765 
2025-01-16 08:38:03.605985:  
2025-01-16 08:38:03.605985: Epoch 26 
2025-01-16 08:38:03.611497: Current learning rate: 0.00906 
2025-01-16 08:38:44.341120: train_loss -0.5277 
2025-01-16 08:38:44.342124: val_loss -0.5174 
2025-01-16 08:38:44.347643: Pseudo dice [np.float32(0.7296), np.float32(0.4121)] 
2025-01-16 08:38:44.351660: Epoch time: 40.74 s 
2025-01-16 08:38:44.355233: Yayy! New best EMA pseudo Dice: 0.4943000078201294 
2025-01-16 08:38:45.105023:  
2025-01-16 08:38:45.105023: Epoch 27 
2025-01-16 08:38:45.110076: Current learning rate: 0.00902 
2025-01-16 08:39:25.827384: train_loss -0.5353 
2025-01-16 08:39:25.827384: val_loss -0.4878 
2025-01-16 08:39:25.833447: Pseudo dice [np.float32(0.7236), np.float32(0.4147)] 
2025-01-16 08:39:25.836479: Epoch time: 40.72 s 
2025-01-16 08:39:25.839053: Yayy! New best EMA pseudo Dice: 0.501800000667572 
2025-01-16 08:39:26.561590:  
2025-01-16 08:39:26.562095: Epoch 28 
2025-01-16 08:39:26.566621: Current learning rate: 0.00899 
2025-01-16 08:40:07.299370: train_loss -0.5461 
2025-01-16 08:40:07.299370: val_loss -0.5051 
2025-01-16 08:40:07.305390: Pseudo dice [np.float32(0.7474), np.float32(0.4262)] 
2025-01-16 08:40:07.308474: Epoch time: 40.74 s 
2025-01-16 08:40:07.311986: Yayy! New best EMA pseudo Dice: 0.5102999806404114 
2025-01-16 08:40:08.206546:  
2025-01-16 08:40:08.206546: Epoch 29 
2025-01-16 08:40:08.212654: Current learning rate: 0.00895 
2025-01-16 08:40:48.940272: train_loss -0.5411 
2025-01-16 08:40:48.940272: val_loss -0.534 
2025-01-16 08:40:48.945786: Pseudo dice [np.float32(0.7174), np.float32(0.4068)] 
2025-01-16 08:40:48.948292: Epoch time: 40.73 s 
2025-01-16 08:40:48.951803: Yayy! New best EMA pseudo Dice: 0.515500009059906 
2025-01-16 08:40:49.701572:  
2025-01-16 08:40:49.702575: Epoch 30 
2025-01-16 08:40:49.707143: Current learning rate: 0.00891 
2025-01-16 08:41:30.443076: train_loss -0.5274 
2025-01-16 08:41:30.443579: val_loss -0.5519 
2025-01-16 08:41:30.449594: Pseudo dice [np.float32(0.7416), np.float32(0.5254)] 
2025-01-16 08:41:30.453607: Epoch time: 40.74 s 
2025-01-16 08:41:30.456113: Yayy! New best EMA pseudo Dice: 0.5273000001907349 
2025-01-16 08:41:31.161932:  
2025-01-16 08:41:31.161932: Epoch 31 
2025-01-16 08:41:31.167989: Current learning rate: 0.00888 
2025-01-16 08:42:11.884745: train_loss -0.5352 
2025-01-16 08:42:11.885746: val_loss -0.4919 
2025-01-16 08:42:11.892291: Pseudo dice [np.float32(0.7434), np.float32(0.3385)] 
2025-01-16 08:42:11.895814: Epoch time: 40.72 s 
2025-01-16 08:42:11.898916: Yayy! New best EMA pseudo Dice: 0.5285999774932861 
2025-01-16 08:42:12.643768:  
2025-01-16 08:42:12.644771: Epoch 32 
2025-01-16 08:42:12.650351: Current learning rate: 0.00884 
2025-01-16 08:42:53.388244: train_loss -0.5605 
2025-01-16 08:42:53.388810: val_loss -0.5005 
2025-01-16 08:42:53.395002: Pseudo dice [np.float32(0.7346), np.float32(0.3631)] 
2025-01-16 08:42:53.398534: Epoch time: 40.74 s 
2025-01-16 08:42:53.401564: Yayy! New best EMA pseudo Dice: 0.5307000279426575 
2025-01-16 08:42:54.172283:  
2025-01-16 08:42:54.172283: Epoch 33 
2025-01-16 08:42:54.178370: Current learning rate: 0.0088 
2025-01-16 08:43:34.903405: train_loss -0.5602 
2025-01-16 08:43:34.904404: val_loss -0.4831 
2025-01-16 08:43:34.910922: Pseudo dice [np.float32(0.7402), np.float32(0.3845)] 
2025-01-16 08:43:34.915946: Epoch time: 40.73 s 
2025-01-16 08:43:34.919451: Yayy! New best EMA pseudo Dice: 0.5338000059127808 
2025-01-16 08:43:35.668282:  
2025-01-16 08:43:35.668282: Epoch 34 
2025-01-16 08:43:35.673294: Current learning rate: 0.00877 
2025-01-16 08:44:16.413783: train_loss -0.5413 
2025-01-16 08:44:16.415844: val_loss -0.5505 
2025-01-16 08:44:16.421399: Pseudo dice [np.float32(0.7541), np.float32(0.4604)] 
2025-01-16 08:44:16.424928: Epoch time: 40.75 s 
2025-01-16 08:44:16.427413: Yayy! New best EMA pseudo Dice: 0.5411999821662903 
2025-01-16 08:44:17.230256:  
2025-01-16 08:44:17.231260: Epoch 35 
2025-01-16 08:44:17.235806: Current learning rate: 0.00873 
2025-01-16 08:44:57.959532: train_loss -0.5571 
2025-01-16 08:44:57.960536: val_loss -0.5492 
2025-01-16 08:44:57.966809: Pseudo dice [np.float32(0.7263), np.float32(0.3662)] 
2025-01-16 08:44:57.970846: Epoch time: 40.73 s 
2025-01-16 08:44:57.974373: Yayy! New best EMA pseudo Dice: 0.541700005531311 
2025-01-16 08:44:58.757088:  
2025-01-16 08:44:58.757088: Epoch 36 
2025-01-16 08:44:58.762696: Current learning rate: 0.00869 
2025-01-16 08:45:39.506552: train_loss -0.5613 
2025-01-16 08:45:39.506552: val_loss -0.5104 
2025-01-16 08:45:39.513128: Pseudo dice [np.float32(0.7535), np.float32(0.3877)] 
2025-01-16 08:45:39.516264: Epoch time: 40.75 s 
2025-01-16 08:45:39.519773: Yayy! New best EMA pseudo Dice: 0.5446000099182129 
2025-01-16 08:45:40.374296:  
2025-01-16 08:45:40.375296: Epoch 37 
2025-01-16 08:45:40.380860: Current learning rate: 0.00866 
2025-01-16 08:46:21.117996: train_loss -0.5751 
2025-01-16 08:46:21.118996: val_loss -0.5804 
2025-01-16 08:46:21.124512: Pseudo dice [np.float32(0.7715), np.float32(0.515)] 
2025-01-16 08:46:21.128024: Epoch time: 40.74 s 
2025-01-16 08:46:21.132088: Yayy! New best EMA pseudo Dice: 0.5544000267982483 
2025-01-16 08:46:21.870480:  
2025-01-16 08:46:21.870983: Epoch 38 
2025-01-16 08:46:21.875993: Current learning rate: 0.00862 
2025-01-16 08:47:02.602743: train_loss -0.5743 
2025-01-16 08:47:02.602743: val_loss -0.5126 
2025-01-16 08:47:02.609309: Pseudo dice [np.float32(0.7343), np.float32(0.4333)] 
2025-01-16 08:47:02.612318: Epoch time: 40.73 s 
2025-01-16 08:47:02.615826: Yayy! New best EMA pseudo Dice: 0.5573999881744385 
2025-01-16 08:47:03.357778:  
2025-01-16 08:47:03.358299: Epoch 39 
2025-01-16 08:47:03.363309: Current learning rate: 0.00858 
2025-01-16 08:47:44.097519: train_loss -0.5718 
2025-01-16 08:47:44.097519: val_loss -0.518 
2025-01-16 08:47:44.104033: Pseudo dice [np.float32(0.7249), np.float32(0.4325)] 
2025-01-16 08:47:44.109050: Epoch time: 40.74 s 
2025-01-16 08:47:44.112560: Yayy! New best EMA pseudo Dice: 0.559499979019165 
2025-01-16 08:47:44.901134:  
2025-01-16 08:47:44.901134: Epoch 40 
2025-01-16 08:47:44.906743: Current learning rate: 0.00855 
2025-01-16 08:48:25.621921: train_loss -0.5694 
2025-01-16 08:48:25.621921: val_loss -0.5274 
2025-01-16 08:48:25.626977: Pseudo dice [np.float32(0.7627), np.float32(0.442)] 
2025-01-16 08:48:25.631533: Epoch time: 40.72 s 
2025-01-16 08:48:25.634653: Yayy! New best EMA pseudo Dice: 0.5637999773025513 
2025-01-16 08:48:26.411266:  
2025-01-16 08:48:26.411768: Epoch 41 
2025-01-16 08:48:26.416786: Current learning rate: 0.00851 
2025-01-16 08:49:07.152161: train_loss -0.6028 
2025-01-16 08:49:07.152161: val_loss -0.5148 
2025-01-16 08:49:07.158174: Pseudo dice [np.float32(0.7561), np.float32(0.384)] 
2025-01-16 08:49:07.162129: Epoch time: 40.74 s 
2025-01-16 08:49:07.165641: Yayy! New best EMA pseudo Dice: 0.5644000172615051 
2025-01-16 08:49:07.923667:  
2025-01-16 08:49:07.924667: Epoch 42 
2025-01-16 08:49:07.930297: Current learning rate: 0.00847 
2025-01-16 08:49:48.657069: train_loss -0.6212 
2025-01-16 08:49:48.657069: val_loss -0.5375 
2025-01-16 08:49:48.663094: Pseudo dice [np.float32(0.7673), np.float32(0.4252)] 
2025-01-16 08:49:48.667240: Epoch time: 40.73 s 
2025-01-16 08:49:48.671249: Yayy! New best EMA pseudo Dice: 0.5676000118255615 
2025-01-16 08:49:49.434510:  
2025-01-16 08:49:49.435514: Epoch 43 
2025-01-16 08:49:49.440573: Current learning rate: 0.00844 
2025-01-16 08:50:30.150619: train_loss -0.6117 
2025-01-16 08:50:30.152140: val_loss -0.4991 
2025-01-16 08:50:30.158258: Pseudo dice [np.float32(0.787), np.float32(0.2112)] 
2025-01-16 08:50:30.162922: Epoch time: 40.72 s 
2025-01-16 08:50:30.688062:  
2025-01-16 08:50:30.688062: Epoch 44 
2025-01-16 08:50:30.694074: Current learning rate: 0.0084 
2025-01-16 08:51:11.407058: train_loss -0.62 
2025-01-16 08:51:11.408063: val_loss -0.5659 
2025-01-16 08:51:11.414073: Pseudo dice [np.float32(0.7619), np.float32(0.4494)] 
2025-01-16 08:51:11.417084: Epoch time: 40.72 s 
2025-01-16 08:51:12.074788:  
2025-01-16 08:51:12.074788: Epoch 45 
2025-01-16 08:51:12.080340: Current learning rate: 0.00836 
2025-01-16 08:51:52.804929: train_loss -0.6167 
2025-01-16 08:51:52.804929: val_loss -0.5507 
2025-01-16 08:51:52.811058: Pseudo dice [np.float32(0.7655), np.float32(0.4264)] 
2025-01-16 08:51:52.815102: Epoch time: 40.73 s 
2025-01-16 08:51:52.818658: Yayy! New best EMA pseudo Dice: 0.5683000087738037 
2025-01-16 08:51:53.544773:  
2025-01-16 08:51:53.545775: Epoch 46 
2025-01-16 08:51:53.551354: Current learning rate: 0.00833 
2025-01-16 08:52:34.282767: train_loss -0.6101 
2025-01-16 08:52:34.283271: val_loss -0.5161 
2025-01-16 08:52:34.288822: Pseudo dice [np.float32(0.7483), np.float32(0.3971)] 
2025-01-16 08:52:34.292372: Epoch time: 40.74 s 
2025-01-16 08:52:34.295984: Yayy! New best EMA pseudo Dice: 0.5687000155448914 
2025-01-16 08:52:35.029690:  
2025-01-16 08:52:35.030693: Epoch 47 
2025-01-16 08:52:35.036228: Current learning rate: 0.00829 
2025-01-16 08:53:15.763231: train_loss -0.626 
2025-01-16 08:53:15.763741: val_loss -0.506 
2025-01-16 08:53:15.769289: Pseudo dice [np.float32(0.7261), np.float32(0.3802)] 
2025-01-16 08:53:15.773327: Epoch time: 40.73 s 
2025-01-16 08:53:16.290779:  
2025-01-16 08:53:16.291783: Epoch 48 
2025-01-16 08:53:16.296306: Current learning rate: 0.00825 
2025-01-16 08:53:57.039200: train_loss -0.6053 
2025-01-16 08:53:57.040203: val_loss -0.4841 
2025-01-16 08:53:57.046721: Pseudo dice [np.float32(0.7204), np.float32(0.3748)] 
2025-01-16 08:53:57.050257: Epoch time: 40.75 s 
2025-01-16 08:53:57.586332:  
2025-01-16 08:53:57.586836: Epoch 49 
2025-01-16 08:53:57.591846: Current learning rate: 0.00822 
2025-01-16 08:54:38.313936: train_loss -0.6073 
2025-01-16 08:54:38.314940: val_loss -0.5341 
2025-01-16 08:54:38.320951: Pseudo dice [np.float32(0.7452), np.float32(0.4462)] 
2025-01-16 08:54:38.323958: Epoch time: 40.73 s 
2025-01-16 08:54:39.008591:  
2025-01-16 08:54:39.009595: Epoch 50 
2025-01-16 08:54:39.014163: Current learning rate: 0.00818 
2025-01-16 08:55:19.743209: train_loss -0.596 
2025-01-16 08:55:19.743209: val_loss -0.4847 
2025-01-16 08:55:19.749220: Pseudo dice [np.float32(0.7516), np.float32(0.3168)] 
2025-01-16 08:55:19.752231: Epoch time: 40.73 s 
2025-01-16 08:55:20.281007:  
2025-01-16 08:55:20.282010: Epoch 51 
2025-01-16 08:55:20.287077: Current learning rate: 0.00814 
2025-01-16 08:56:01.029968: train_loss -0.6001 
2025-01-16 08:56:01.030470: val_loss -0.5415 
2025-01-16 08:56:01.036547: Pseudo dice [np.float32(0.7407), np.float32(0.4889)] 
2025-01-16 08:56:01.039581: Epoch time: 40.75 s 
2025-01-16 08:56:01.043607: Yayy! New best EMA pseudo Dice: 0.5698999762535095 
2025-01-16 08:56:01.768211:  
2025-01-16 08:56:01.769216: Epoch 52 
2025-01-16 08:56:01.773754: Current learning rate: 0.00811 
2025-01-16 08:56:42.507336: train_loss -0.6347 
2025-01-16 08:56:42.507847: val_loss -0.4919 
2025-01-16 08:56:42.514940: Pseudo dice [np.float32(0.6904), np.float32(0.4819)] 
2025-01-16 08:56:42.519008: Epoch time: 40.74 s 
2025-01-16 08:56:42.522043: Yayy! New best EMA pseudo Dice: 0.5715000033378601 
2025-01-16 08:56:43.444250:  
2025-01-16 08:56:43.445254: Epoch 53 
2025-01-16 08:56:43.449829: Current learning rate: 0.00807 
2025-01-16 08:57:24.177363: train_loss -0.6363 
2025-01-16 08:57:24.177866: val_loss -0.5613 
2025-01-16 08:57:24.183889: Pseudo dice [np.float32(0.7679), np.float32(0.4172)] 
2025-01-16 08:57:24.187446: Epoch time: 40.73 s 
2025-01-16 08:57:24.191471: Yayy! New best EMA pseudo Dice: 0.5735999941825867 
2025-01-16 08:57:24.917980:  
2025-01-16 08:57:24.918488: Epoch 54 
2025-01-16 08:57:24.924075: Current learning rate: 0.00803 
2025-01-16 08:58:05.638291: train_loss -0.6157 
2025-01-16 08:58:05.638291: val_loss -0.5281 
2025-01-16 08:58:05.643942: Pseudo dice [np.float32(0.7554), np.float32(0.4309)] 
2025-01-16 08:58:05.646978: Epoch time: 40.72 s 
2025-01-16 08:58:05.651506: Yayy! New best EMA pseudo Dice: 0.5756000280380249 
2025-01-16 08:58:06.381511:  
2025-01-16 08:58:06.381511: Epoch 55 
2025-01-16 08:58:06.387524: Current learning rate: 0.008 
2025-01-16 08:58:47.105147: train_loss -0.6323 
2025-01-16 08:58:47.105649: val_loss -0.5201 
2025-01-16 08:58:47.113288: Pseudo dice [np.float32(0.7358), np.float32(0.3913)] 
2025-01-16 08:58:47.116828: Epoch time: 40.72 s 
2025-01-16 08:58:47.649217:  
2025-01-16 08:58:47.649217: Epoch 56 
2025-01-16 08:58:47.655235: Current learning rate: 0.00796 
2025-01-16 08:59:28.388315: train_loss -0.6293 
2025-01-16 08:59:28.388834: val_loss -0.5332 
2025-01-16 08:59:28.395849: Pseudo dice [np.float32(0.7433), np.float32(0.3883)] 
2025-01-16 08:59:28.399862: Epoch time: 40.74 s 
2025-01-16 08:59:28.931465:  
2025-01-16 08:59:28.931465: Epoch 57 
2025-01-16 08:59:28.937479: Current learning rate: 0.00792 
2025-01-16 09:00:09.684042: train_loss -0.6219 
2025-01-16 09:00:09.684042: val_loss -0.6003 
2025-01-16 09:00:09.691076: Pseudo dice [np.float32(0.785), np.float32(0.4742)] 
2025-01-16 09:00:09.694588: Epoch time: 40.75 s 
2025-01-16 09:00:09.698597: Yayy! New best EMA pseudo Dice: 0.5791000127792358 
2025-01-16 09:00:10.417564:  
2025-01-16 09:00:10.418076: Epoch 58 
2025-01-16 09:00:10.423121: Current learning rate: 0.00789 
2025-01-16 09:00:51.163658: train_loss -0.635 
2025-01-16 09:00:51.164161: val_loss -0.4537 
2025-01-16 09:00:51.171179: Pseudo dice [np.float32(0.7423), np.float32(0.2122)] 
2025-01-16 09:00:51.174693: Epoch time: 40.75 s 
2025-01-16 09:00:51.716060:  
2025-01-16 09:00:51.717063: Epoch 59 
2025-01-16 09:00:51.721687: Current learning rate: 0.00785 
2025-01-16 09:01:32.474265: train_loss -0.6275 
2025-01-16 09:01:32.475265: val_loss -0.5878 
2025-01-16 09:01:32.481827: Pseudo dice [np.float32(0.7744), np.float32(0.5411)] 
2025-01-16 09:01:32.485338: Epoch time: 40.76 s 
2025-01-16 09:01:33.026342:  
2025-01-16 09:01:33.026342: Epoch 60 
2025-01-16 09:01:33.031911: Current learning rate: 0.00781 
2025-01-16 09:02:13.804076: train_loss -0.6313 
2025-01-16 09:02:13.805075: val_loss -0.5257 
2025-01-16 09:02:13.810598: Pseudo dice [np.float32(0.773), np.float32(0.4265)] 
2025-01-16 09:02:13.813108: Epoch time: 40.78 s 
2025-01-16 09:02:13.816617: Yayy! New best EMA pseudo Dice: 0.5799999833106995 
2025-01-16 09:02:14.769633:  
2025-01-16 09:02:14.769633: Epoch 61 
2025-01-16 09:02:14.775172: Current learning rate: 0.00777 
2025-01-16 09:02:55.542851: train_loss -0.6254 
2025-01-16 09:02:55.543355: val_loss -0.5336 
2025-01-16 09:02:55.548365: Pseudo dice [np.float32(0.7421), np.float32(0.4406)] 
2025-01-16 09:02:55.551872: Epoch time: 40.77 s 
2025-01-16 09:02:55.554388: Yayy! New best EMA pseudo Dice: 0.5810999870300293 
2025-01-16 09:02:56.291658:  
2025-01-16 09:02:56.292162: Epoch 62 
2025-01-16 09:02:56.297180: Current learning rate: 0.00774 
2025-01-16 09:03:37.044687: train_loss -0.6145 
2025-01-16 09:03:37.044687: val_loss -0.5612 
2025-01-16 09:03:37.051201: Pseudo dice [np.float32(0.7712), np.float32(0.4746)] 
2025-01-16 09:03:37.053711: Epoch time: 40.75 s 
2025-01-16 09:03:37.057220: Yayy! New best EMA pseudo Dice: 0.5853000283241272 
2025-01-16 09:03:37.779091:  
2025-01-16 09:03:37.779091: Epoch 63 
2025-01-16 09:03:37.784101: Current learning rate: 0.0077 
2025-01-16 09:04:18.553024: train_loss -0.6338 
2025-01-16 09:04:18.553528: val_loss -0.5446 
2025-01-16 09:04:18.558576: Pseudo dice [np.float32(0.7761), np.float32(0.4232)] 
2025-01-16 09:04:18.561625: Epoch time: 40.78 s 
2025-01-16 09:04:18.564717: Yayy! New best EMA pseudo Dice: 0.5867000222206116 
2025-01-16 09:04:19.351297:  
2025-01-16 09:04:19.352299: Epoch 64 
2025-01-16 09:04:19.357909: Current learning rate: 0.00766 
2025-01-16 09:05:00.124153: train_loss -0.6588 
2025-01-16 09:05:00.124671: val_loss -0.5644 
2025-01-16 09:05:00.129727: Pseudo dice [np.float32(0.7858), np.float32(0.4777)] 
2025-01-16 09:05:00.132346: Epoch time: 40.77 s 
2025-01-16 09:05:00.134883: Yayy! New best EMA pseudo Dice: 0.5911999940872192 
2025-01-16 09:05:00.877936:  
2025-01-16 09:05:00.877936: Epoch 65 
2025-01-16 09:05:00.883480: Current learning rate: 0.00763 
2025-01-16 09:05:41.681602: train_loss -0.6574 
2025-01-16 09:05:41.682606: val_loss -0.5317 
2025-01-16 09:05:41.687191: Pseudo dice [np.float32(0.7663), np.float32(0.4089)] 
2025-01-16 09:05:41.691261: Epoch time: 40.8 s 
2025-01-16 09:05:42.235334:  
2025-01-16 09:05:42.236335: Epoch 66 
2025-01-16 09:05:42.241428: Current learning rate: 0.00759 
2025-01-16 09:06:22.977165: train_loss -0.6591 
2025-01-16 09:06:22.978168: val_loss -0.5262 
2025-01-16 09:06:22.983706: Pseudo dice [np.float32(0.7494), np.float32(0.3925)] 
2025-01-16 09:06:22.987261: Epoch time: 40.74 s 
2025-01-16 09:06:23.530202:  
2025-01-16 09:06:23.530704: Epoch 67 
2025-01-16 09:06:23.535715: Current learning rate: 0.00755 
2025-01-16 09:07:04.297885: train_loss -0.6518 
2025-01-16 09:07:04.297885: val_loss -0.5501 
2025-01-16 09:07:04.303516: Pseudo dice [np.float32(0.7851), np.float32(0.3667)] 
2025-01-16 09:07:04.306565: Epoch time: 40.77 s 
2025-01-16 09:07:04.856644:  
2025-01-16 09:07:04.857647: Epoch 68 
2025-01-16 09:07:04.862744: Current learning rate: 0.00751 
2025-01-16 09:07:45.605324: train_loss -0.663 
2025-01-16 09:07:45.605324: val_loss -0.5435 
2025-01-16 09:07:45.610338: Pseudo dice [np.float32(0.7616), np.float32(0.4341)] 
2025-01-16 09:07:45.613846: Epoch time: 40.75 s 
2025-01-16 09:07:46.316908:  
2025-01-16 09:07:46.316908: Epoch 69 
2025-01-16 09:07:46.321921: Current learning rate: 0.00748 
2025-01-16 09:08:27.043429: train_loss -0.6614 
2025-01-16 09:08:27.043933: val_loss -0.5282 
2025-01-16 09:08:27.048992: Pseudo dice [np.float32(0.7509), np.float32(0.3899)] 
2025-01-16 09:08:27.051497: Epoch time: 40.73 s 
2025-01-16 09:08:27.593628:  
2025-01-16 09:08:27.594630: Epoch 70 
2025-01-16 09:08:27.600709: Current learning rate: 0.00744 
2025-01-16 09:09:08.340879: train_loss -0.6824 
2025-01-16 09:09:08.341387: val_loss -0.5361 
2025-01-16 09:09:08.346945: Pseudo dice [np.float32(0.7717), np.float32(0.3875)] 
2025-01-16 09:09:08.349987: Epoch time: 40.75 s 
2025-01-16 09:09:08.887975:  
2025-01-16 09:09:08.888977: Epoch 71 
2025-01-16 09:09:08.894011: Current learning rate: 0.0074 
2025-01-16 09:09:49.658685: train_loss -0.655 
2025-01-16 09:09:49.658685: val_loss -0.5429 
2025-01-16 09:09:49.664701: Pseudo dice [np.float32(0.7587), np.float32(0.4401)] 
2025-01-16 09:09:49.667207: Epoch time: 40.77 s 
2025-01-16 09:09:50.207889:  
2025-01-16 09:09:50.207889: Epoch 72 
2025-01-16 09:09:50.212915: Current learning rate: 0.00737 
2025-01-16 09:10:30.962601: train_loss -0.6679 
2025-01-16 09:10:30.963105: val_loss -0.5563 
2025-01-16 09:10:30.968699: Pseudo dice [np.float32(0.7922), np.float32(0.4743)] 
2025-01-16 09:10:30.971210: Epoch time: 40.76 s 
2025-01-16 09:10:30.974719: Yayy! New best EMA pseudo Dice: 0.5920000076293945 
2025-01-16 09:10:31.756927:  
2025-01-16 09:10:31.757143: Epoch 73 
2025-01-16 09:10:31.761671: Current learning rate: 0.00733 
2025-01-16 09:11:12.501761: train_loss -0.6732 
2025-01-16 09:11:12.501761: val_loss -0.5734 
2025-01-16 09:11:12.506774: Pseudo dice [np.float32(0.7872), np.float32(0.5358)] 
2025-01-16 09:11:12.509815: Epoch time: 40.75 s 
2025-01-16 09:11:12.513319: Yayy! New best EMA pseudo Dice: 0.5989000201225281 
2025-01-16 09:11:13.296788:  
2025-01-16 09:11:13.297792: Epoch 74 
2025-01-16 09:11:13.302339: Current learning rate: 0.00729 
2025-01-16 09:11:54.048874: train_loss -0.6973 
2025-01-16 09:11:54.049403: val_loss -0.5546 
2025-01-16 09:11:54.055015: Pseudo dice [np.float32(0.7611), np.float32(0.4115)] 
2025-01-16 09:11:54.057558: Epoch time: 40.75 s 
2025-01-16 09:11:54.603645:  
2025-01-16 09:11:54.603645: Epoch 75 
2025-01-16 09:11:54.608660: Current learning rate: 0.00725 
2025-01-16 09:12:35.356191: train_loss -0.6605 
2025-01-16 09:12:35.356191: val_loss -0.5836 
2025-01-16 09:12:35.362223: Pseudo dice [np.float32(0.7711), np.float32(0.5344)] 
2025-01-16 09:12:35.365241: Epoch time: 40.75 s 
2025-01-16 09:12:35.367747: Yayy! New best EMA pseudo Dice: 0.6032000184059143 
2025-01-16 09:12:36.161417:  
2025-01-16 09:12:36.161921: Epoch 76 
2025-01-16 09:12:36.166941: Current learning rate: 0.00722 
2025-01-16 09:13:16.915943: train_loss -0.6868 
2025-01-16 09:13:16.916445: val_loss -0.5399 
2025-01-16 09:13:16.921979: Pseudo dice [np.float32(0.7903), np.float32(0.4368)] 
2025-01-16 09:13:16.925008: Epoch time: 40.76 s 
2025-01-16 09:13:16.928513: Yayy! New best EMA pseudo Dice: 0.604200005531311 
2025-01-16 09:13:17.842786:  
2025-01-16 09:13:17.843790: Epoch 77 
2025-01-16 09:13:17.848334: Current learning rate: 0.00718 
2025-01-16 09:13:58.606166: train_loss -0.6899 
2025-01-16 09:13:58.607166: val_loss -0.6005 
2025-01-16 09:13:58.612681: Pseudo dice [np.float32(0.7698), np.float32(0.524)] 
2025-01-16 09:13:58.616245: Epoch time: 40.76 s 
2025-01-16 09:13:58.618749: Yayy! New best EMA pseudo Dice: 0.6085000038146973 
2025-01-16 09:13:59.358374:  
2025-01-16 09:13:59.359375: Epoch 78 
2025-01-16 09:13:59.364952: Current learning rate: 0.00714 
2025-01-16 09:14:40.113740: train_loss -0.6694 
2025-01-16 09:14:40.114251: val_loss -0.5549 
2025-01-16 09:14:40.118831: Pseudo dice [np.float32(0.7732), np.float32(0.4404)] 
2025-01-16 09:14:40.122343: Epoch time: 40.76 s 
2025-01-16 09:14:40.673725:  
2025-01-16 09:14:40.673725: Epoch 79 
2025-01-16 09:14:40.679276: Current learning rate: 0.0071 
2025-01-16 09:15:21.415517: train_loss -0.6753 
2025-01-16 09:15:21.416025: val_loss -0.5415 
2025-01-16 09:15:21.421127: Pseudo dice [np.float32(0.7658), np.float32(0.3757)] 
2025-01-16 09:15:21.423662: Epoch time: 40.74 s 
2025-01-16 09:15:22.003585:  
2025-01-16 09:15:22.003585: Epoch 80 
2025-01-16 09:15:22.009643: Current learning rate: 0.00707 
2025-01-16 09:16:02.750517: train_loss -0.6784 
2025-01-16 09:16:02.751029: val_loss -0.565 
2025-01-16 09:16:02.756135: Pseudo dice [np.float32(0.7654), np.float32(0.4653)] 
2025-01-16 09:16:02.759172: Epoch time: 40.75 s 
2025-01-16 09:16:03.318637:  
2025-01-16 09:16:03.319139: Epoch 81 
2025-01-16 09:16:03.324152: Current learning rate: 0.00703 
2025-01-16 09:16:44.087685: train_loss -0.6709 
2025-01-16 09:16:44.087685: val_loss -0.5233 
2025-01-16 09:16:44.092723: Pseudo dice [np.float32(0.7804), np.float32(0.3865)] 
2025-01-16 09:16:44.095768: Epoch time: 40.77 s 
2025-01-16 09:16:44.655867:  
2025-01-16 09:16:44.655867: Epoch 82 
2025-01-16 09:16:44.661402: Current learning rate: 0.00699 
2025-01-16 09:17:25.427714: train_loss -0.6996 
2025-01-16 09:17:25.427714: val_loss -0.5499 
2025-01-16 09:17:25.433265: Pseudo dice [np.float32(0.7653), np.float32(0.4766)] 
2025-01-16 09:17:25.436830: Epoch time: 40.77 s 
2025-01-16 09:17:25.958838:  
2025-01-16 09:17:25.958838: Epoch 83 
2025-01-16 09:17:25.964850: Current learning rate: 0.00696 
2025-01-16 09:18:06.741140: train_loss -0.6658 
2025-01-16 09:18:06.741648: val_loss -0.5872 
2025-01-16 09:18:06.747236: Pseudo dice [np.float32(0.7674), np.float32(0.5601)] 
2025-01-16 09:18:06.749777: Epoch time: 40.78 s 
2025-01-16 09:18:06.753313: Yayy! New best EMA pseudo Dice: 0.6110000014305115 
2025-01-16 09:18:07.519208:  
2025-01-16 09:18:07.519208: Epoch 84 
2025-01-16 09:18:07.524819: Current learning rate: 0.00692 
2025-01-16 09:18:48.279193: train_loss -0.6742 
2025-01-16 09:18:48.280196: val_loss -0.5919 
2025-01-16 09:18:48.285340: Pseudo dice [np.float32(0.7919), np.float32(0.5139)] 
2025-01-16 09:18:48.288410: Epoch time: 40.76 s 
2025-01-16 09:18:48.292451: Yayy! New best EMA pseudo Dice: 0.6151999831199646 
2025-01-16 09:18:49.237123:  
2025-01-16 09:18:49.238128: Epoch 85 
2025-01-16 09:18:49.242723: Current learning rate: 0.00688 
2025-01-16 09:19:30.001225: train_loss -0.6959 
2025-01-16 09:19:30.001730: val_loss -0.526 
2025-01-16 09:19:30.008368: Pseudo dice [np.float32(0.7675), np.float32(0.4057)] 
2025-01-16 09:19:30.011873: Epoch time: 40.76 s 
2025-01-16 09:19:30.526433:  
2025-01-16 09:19:30.526936: Epoch 86 
2025-01-16 09:19:30.531949: Current learning rate: 0.00684 
2025-01-16 09:20:11.302381: train_loss -0.7201 
2025-01-16 09:20:11.302381: val_loss -0.5649 
2025-01-16 09:20:11.307917: Pseudo dice [np.float32(0.7741), np.float32(0.4259)] 
2025-01-16 09:20:11.310945: Epoch time: 40.78 s 
2025-01-16 09:20:11.836208:  
2025-01-16 09:20:11.836711: Epoch 87 
2025-01-16 09:20:11.841723: Current learning rate: 0.0068 
2025-01-16 09:20:52.616045: train_loss -0.6953 
2025-01-16 09:20:52.616045: val_loss -0.5426 
2025-01-16 09:20:52.622650: Pseudo dice [np.float32(0.7808), np.float32(0.456)] 
2025-01-16 09:20:52.625189: Epoch time: 40.78 s 
2025-01-16 09:20:53.146096:  
2025-01-16 09:20:53.147097: Epoch 88 
2025-01-16 09:20:53.152132: Current learning rate: 0.00677 
2025-01-16 09:21:33.890345: train_loss -0.6988 
2025-01-16 09:21:33.891348: val_loss -0.5424 
2025-01-16 09:21:33.896361: Pseudo dice [np.float32(0.7626), np.float32(0.4301)] 
2025-01-16 09:21:33.900379: Epoch time: 40.74 s 
2025-01-16 09:21:34.507687:  
2025-01-16 09:21:34.507687: Epoch 89 
2025-01-16 09:21:34.513220: Current learning rate: 0.00673 
2025-01-16 09:22:15.287440: train_loss -0.7087 
2025-01-16 09:22:15.287945: val_loss -0.6044 
2025-01-16 09:22:15.293001: Pseudo dice [np.float32(0.792), np.float32(0.5357)] 
2025-01-16 09:22:15.295550: Epoch time: 40.78 s 
2025-01-16 09:22:15.300115: Yayy! New best EMA pseudo Dice: 0.6157000064849854 
2025-01-16 09:22:16.046319:  
2025-01-16 09:22:16.047320: Epoch 90 
2025-01-16 09:22:16.052897: Current learning rate: 0.00669 
2025-01-16 09:22:56.822565: train_loss -0.6888 
2025-01-16 09:22:56.823067: val_loss -0.5476 
2025-01-16 09:22:56.828620: Pseudo dice [np.float32(0.784), np.float32(0.4475)] 
2025-01-16 09:22:56.832138: Epoch time: 40.78 s 
2025-01-16 09:22:56.834650: Yayy! New best EMA pseudo Dice: 0.6157000064849854 
2025-01-16 09:22:57.561692:  
2025-01-16 09:22:57.562696: Epoch 91 
2025-01-16 09:22:57.567248: Current learning rate: 0.00665 
2025-01-16 09:23:38.315568: train_loss -0.7062 
2025-01-16 09:23:38.317299: val_loss -0.5934 
2025-01-16 09:23:38.323842: Pseudo dice [np.float32(0.809), np.float32(0.544)] 
2025-01-16 09:23:38.326355: Epoch time: 40.75 s 
2025-01-16 09:23:38.330369: Yayy! New best EMA pseudo Dice: 0.6216999888420105 
2025-01-16 09:23:39.094831:  
2025-01-16 09:23:39.095831: Epoch 92 
2025-01-16 09:23:39.101427: Current learning rate: 0.00662 
2025-01-16 09:24:19.862150: train_loss -0.7124 
2025-01-16 09:24:19.863668: val_loss -0.5245 
2025-01-16 09:24:19.869321: Pseudo dice [np.float32(0.7856), np.float32(0.3966)] 
2025-01-16 09:24:19.872346: Epoch time: 40.77 s 
2025-01-16 09:24:20.448264:  
2025-01-16 09:24:20.448264: Epoch 93 
2025-01-16 09:24:20.453276: Current learning rate: 0.00658 
2025-01-16 09:25:01.225420: train_loss -0.7184 
2025-01-16 09:25:01.225420: val_loss -0.557 
2025-01-16 09:25:01.232469: Pseudo dice [np.float32(0.7889), np.float32(0.4284)] 
2025-01-16 09:25:01.234979: Epoch time: 40.78 s 
2025-01-16 09:25:01.901835:  
2025-01-16 09:25:01.901835: Epoch 94 
2025-01-16 09:25:01.907848: Current learning rate: 0.00654 
2025-01-16 09:25:42.656016: train_loss -0.7183 
2025-01-16 09:25:42.656016: val_loss -0.5344 
2025-01-16 09:25:42.662157: Pseudo dice [np.float32(0.7478), np.float32(0.4414)] 
2025-01-16 09:25:42.664958: Epoch time: 40.75 s 
2025-01-16 09:25:43.178938:  
2025-01-16 09:25:43.179944: Epoch 95 
2025-01-16 09:25:43.184483: Current learning rate: 0.0065 
2025-01-16 09:26:23.936149: train_loss -0.712 
2025-01-16 09:26:23.937150: val_loss -0.5928 
2025-01-16 09:26:23.942665: Pseudo dice [np.float32(0.7883), np.float32(0.5506)] 
2025-01-16 09:26:23.946173: Epoch time: 40.76 s 
2025-01-16 09:26:24.460027:  
2025-01-16 09:26:24.460531: Epoch 96 
2025-01-16 09:26:24.465544: Current learning rate: 0.00647 
2025-01-16 09:27:05.222772: train_loss -0.717 
2025-01-16 09:27:05.222772: val_loss -0.5458 
2025-01-16 09:27:05.229285: Pseudo dice [np.float32(0.793), np.float32(0.4736)] 
2025-01-16 09:27:05.231794: Epoch time: 40.76 s 
2025-01-16 09:27:05.235303: Yayy! New best EMA pseudo Dice: 0.621999979019165 
2025-01-16 09:27:05.976052:  
2025-01-16 09:27:05.977052: Epoch 97 
2025-01-16 09:27:05.982095: Current learning rate: 0.00643 
2025-01-16 09:27:46.721285: train_loss -0.723 
2025-01-16 09:27:46.721285: val_loss -0.5885 
2025-01-16 09:27:46.727458: Pseudo dice [np.float32(0.7838), np.float32(0.5473)] 
2025-01-16 09:27:46.731025: Epoch time: 40.75 s 
2025-01-16 09:27:46.734071: Yayy! New best EMA pseudo Dice: 0.6263999938964844 
2025-01-16 09:27:47.457166:  
2025-01-16 09:27:47.458170: Epoch 98 
2025-01-16 09:27:47.463295: Current learning rate: 0.00639 
2025-01-16 09:28:28.228793: train_loss -0.7237 
2025-01-16 09:28:28.228793: val_loss -0.5732 
2025-01-16 09:28:28.233863: Pseudo dice [np.float32(0.7931), np.float32(0.5567)] 
2025-01-16 09:28:28.237484: Epoch time: 40.77 s 
2025-01-16 09:28:28.240552: Yayy! New best EMA pseudo Dice: 0.6312000155448914 
2025-01-16 09:28:28.952560:  
2025-01-16 09:28:28.952560: Epoch 99 
2025-01-16 09:28:28.958075: Current learning rate: 0.00635 
2025-01-16 09:29:09.716089: train_loss -0.7123 
2025-01-16 09:29:09.716598: val_loss -0.5333 
2025-01-16 09:29:09.721154: Pseudo dice [np.float32(0.791), np.float32(0.449)] 
2025-01-16 09:29:09.725199: Epoch time: 40.76 s 
2025-01-16 09:29:10.452086:  
2025-01-16 09:29:10.452086: Epoch 100 
2025-01-16 09:29:10.457164: Current learning rate: 0.00631 
2025-01-16 09:29:51.203791: train_loss -0.73 
2025-01-16 09:29:51.205311: val_loss -0.5866 
2025-01-16 09:29:51.210928: Pseudo dice [np.float32(0.7976), np.float32(0.5364)] 
2025-01-16 09:29:51.213984: Epoch time: 40.75 s 
2025-01-16 09:29:51.217021: Yayy! New best EMA pseudo Dice: 0.6338000297546387 
2025-01-16 09:29:51.928551:  
2025-01-16 09:29:51.928551: Epoch 101 
2025-01-16 09:29:51.934105: Current learning rate: 0.00628 
2025-01-16 09:30:32.687915: train_loss -0.6954 
2025-01-16 09:30:32.687915: val_loss -0.5523 
2025-01-16 09:30:32.694477: Pseudo dice [np.float32(0.7608), np.float32(0.4053)] 
2025-01-16 09:30:32.696987: Epoch time: 40.76 s 
2025-01-16 09:30:33.369371:  
2025-01-16 09:30:33.369371: Epoch 102 
2025-01-16 09:30:33.376473: Current learning rate: 0.00624 
2025-01-16 09:31:14.133821: train_loss -0.695 
2025-01-16 09:31:14.133821: val_loss -0.5696 
2025-01-16 09:31:14.138831: Pseudo dice [np.float32(0.774), np.float32(0.4614)] 
2025-01-16 09:31:14.142347: Epoch time: 40.76 s 
2025-01-16 09:31:14.663661:  
2025-01-16 09:31:14.663661: Epoch 103 
2025-01-16 09:31:14.669215: Current learning rate: 0.0062 
2025-01-16 09:31:55.439780: train_loss -0.7343 
2025-01-16 09:31:55.439780: val_loss -0.5467 
2025-01-16 09:31:55.445419: Pseudo dice [np.float32(0.7921), np.float32(0.4628)] 
2025-01-16 09:31:55.449465: Epoch time: 40.78 s 
2025-01-16 09:31:55.978441:  
2025-01-16 09:31:55.979442: Epoch 104 
2025-01-16 09:31:55.984490: Current learning rate: 0.00616 
2025-01-16 09:32:36.750725: train_loss -0.7452 
2025-01-16 09:32:36.751230: val_loss -0.5375 
2025-01-16 09:32:36.756276: Pseudo dice [np.float32(0.7958), np.float32(0.3884)] 
2025-01-16 09:32:36.759784: Epoch time: 40.77 s 
2025-01-16 09:32:37.280598:  
2025-01-16 09:32:37.281102: Epoch 105 
2025-01-16 09:32:37.286113: Current learning rate: 0.00612 
2025-01-16 09:33:18.047903: train_loss -0.7206 
2025-01-16 09:33:18.048903: val_loss -0.5188 
2025-01-16 09:33:18.054418: Pseudo dice [np.float32(0.7689), np.float32(0.3779)] 
2025-01-16 09:33:18.056925: Epoch time: 40.77 s 
2025-01-16 09:33:18.590264:  
2025-01-16 09:33:18.590767: Epoch 106 
2025-01-16 09:33:18.595356: Current learning rate: 0.00609 
2025-01-16 09:33:59.366042: train_loss -0.7403 
2025-01-16 09:33:59.367043: val_loss -0.5568 
2025-01-16 09:33:59.372573: Pseudo dice [np.float32(0.7759), np.float32(0.4113)] 
2025-01-16 09:33:59.375655: Epoch time: 40.78 s 
2025-01-16 09:33:59.906817:  
2025-01-16 09:33:59.907321: Epoch 107 
2025-01-16 09:33:59.912331: Current learning rate: 0.00605 
2025-01-16 09:34:40.676438: train_loss -0.7237 
2025-01-16 09:34:40.676438: val_loss -0.5481 
2025-01-16 09:34:40.681507: Pseudo dice [np.float32(0.7845), np.float32(0.491)] 
2025-01-16 09:34:40.685016: Epoch time: 40.77 s 
2025-01-16 09:34:41.211511:  
2025-01-16 09:34:41.211511: Epoch 108 
2025-01-16 09:34:41.216524: Current learning rate: 0.00601 
2025-01-16 09:35:21.970155: train_loss -0.7302 
2025-01-16 09:35:21.971711: val_loss -0.5705 
2025-01-16 09:35:21.976783: Pseudo dice [np.float32(0.79), np.float32(0.508)] 
2025-01-16 09:35:21.979839: Epoch time: 40.76 s 
2025-01-16 09:35:22.507678:  
2025-01-16 09:35:22.507678: Epoch 109 
2025-01-16 09:35:22.513704: Current learning rate: 0.00597 
2025-01-16 09:36:03.286335: train_loss -0.7295 
2025-01-16 09:36:03.286836: val_loss -0.5354 
2025-01-16 09:36:03.292377: Pseudo dice [np.float32(0.7819), np.float32(0.4283)] 
2025-01-16 09:36:03.295403: Epoch time: 40.78 s 
2025-01-16 09:36:03.962345:  
2025-01-16 09:36:03.962847: Epoch 110 
2025-01-16 09:36:03.967354: Current learning rate: 0.00593 
2025-01-16 09:36:44.716161: train_loss -0.7496 
2025-01-16 09:36:44.716161: val_loss -0.5642 
2025-01-16 09:36:44.722173: Pseudo dice [np.float32(0.8051), np.float32(0.4551)] 
2025-01-16 09:36:44.725182: Epoch time: 40.75 s 
2025-01-16 09:36:45.248308:  
2025-01-16 09:36:45.248810: Epoch 111 
2025-01-16 09:36:45.253819: Current learning rate: 0.0059 
2025-01-16 09:37:26.002250: train_loss -0.7199 
2025-01-16 09:37:26.002250: val_loss -0.5829 
2025-01-16 09:37:26.007817: Pseudo dice [np.float32(0.7789), np.float32(0.5345)] 
2025-01-16 09:37:26.010829: Epoch time: 40.75 s 
2025-01-16 09:37:26.533697:  
2025-01-16 09:37:26.534700: Epoch 112 
2025-01-16 09:37:26.538222: Current learning rate: 0.00586 
2025-01-16 09:38:07.273481: train_loss -0.7449 
2025-01-16 09:38:07.274992: val_loss -0.5356 
2025-01-16 09:38:07.281077: Pseudo dice [np.float32(0.7868), np.float32(0.5203)] 
2025-01-16 09:38:07.283666: Epoch time: 40.74 s 
2025-01-16 09:38:07.803482:  
2025-01-16 09:38:07.804485: Epoch 113 
2025-01-16 09:38:07.809021: Current learning rate: 0.00582 
2025-01-16 09:38:48.572098: train_loss -0.7288 
2025-01-16 09:38:48.573696: val_loss -0.5678 
2025-01-16 09:38:48.579225: Pseudo dice [np.float32(0.7978), np.float32(0.4772)] 
2025-01-16 09:38:48.582733: Epoch time: 40.77 s 
2025-01-16 09:38:49.106892:  
2025-01-16 09:38:49.107895: Epoch 114 
2025-01-16 09:38:49.112916: Current learning rate: 0.00578 
2025-01-16 09:39:29.861827: train_loss -0.7419 
2025-01-16 09:39:29.861827: val_loss -0.6202 
2025-01-16 09:39:29.867874: Pseudo dice [np.float32(0.8101), np.float32(0.5917)] 
2025-01-16 09:39:29.870912: Epoch time: 40.75 s 
2025-01-16 09:39:29.873945: Yayy! New best EMA pseudo Dice: 0.635699987411499 
2025-01-16 09:39:30.647083:  
2025-01-16 09:39:30.647586: Epoch 115 
2025-01-16 09:39:30.652639: Current learning rate: 0.00574 
2025-01-16 09:40:11.402220: train_loss -0.7357 
2025-01-16 09:40:11.403255: val_loss -0.5527 
2025-01-16 09:40:11.408308: Pseudo dice [np.float32(0.7712), np.float32(0.4874)] 
2025-01-16 09:40:11.411336: Epoch time: 40.76 s 
2025-01-16 09:40:11.949773:  
2025-01-16 09:40:11.949773: Epoch 116 
2025-01-16 09:40:11.955327: Current learning rate: 0.0057 
2025-01-16 09:40:52.706340: train_loss -0.7385 
2025-01-16 09:40:52.706340: val_loss -0.6099 
2025-01-16 09:40:52.712940: Pseudo dice [np.float32(0.8054), np.float32(0.5823)] 
2025-01-16 09:40:52.715627: Epoch time: 40.76 s 
2025-01-16 09:40:52.718689: Yayy! New best EMA pseudo Dice: 0.6409000158309937 
2025-01-16 09:40:53.524816:  
2025-01-16 09:40:53.524816: Epoch 117 
2025-01-16 09:40:53.529826: Current learning rate: 0.00567 
2025-01-16 09:41:34.304209: train_loss -0.7275 
2025-01-16 09:41:34.305214: val_loss -0.586 
2025-01-16 09:41:34.310230: Pseudo dice [np.float32(0.788), np.float32(0.5497)] 
2025-01-16 09:41:34.313824: Epoch time: 40.78 s 
2025-01-16 09:41:34.316846: Yayy! New best EMA pseudo Dice: 0.6437000036239624 
2025-01-16 09:41:35.264060:  
2025-01-16 09:41:35.264060: Epoch 118 
2025-01-16 09:41:35.270192: Current learning rate: 0.00563 
2025-01-16 09:42:16.028778: train_loss -0.7533 
2025-01-16 09:42:16.029783: val_loss -0.5571 
2025-01-16 09:42:16.034793: Pseudo dice [np.float32(0.783), np.float32(0.468)] 
2025-01-16 09:42:16.038801: Epoch time: 40.77 s 
2025-01-16 09:42:16.566969:  
2025-01-16 09:42:16.566969: Epoch 119 
2025-01-16 09:42:16.571999: Current learning rate: 0.00559 
2025-01-16 09:42:57.331335: train_loss -0.745 
2025-01-16 09:42:57.332341: val_loss -0.5418 
2025-01-16 09:42:57.337424: Pseudo dice [np.float32(0.7551), np.float32(0.4798)] 
2025-01-16 09:42:57.340956: Epoch time: 40.77 s 
2025-01-16 09:42:57.871595:  
2025-01-16 09:42:57.871595: Epoch 120 
2025-01-16 09:42:57.876606: Current learning rate: 0.00555 
2025-01-16 09:43:38.646972: train_loss -0.7303 
2025-01-16 09:43:38.646972: val_loss -0.5498 
2025-01-16 09:43:38.655013: Pseudo dice [np.float32(0.7694), np.float32(0.499)] 
2025-01-16 09:43:38.657519: Epoch time: 40.78 s 
2025-01-16 09:43:39.190575:  
2025-01-16 09:43:39.190575: Epoch 121 
2025-01-16 09:43:39.195632: Current learning rate: 0.00551 
2025-01-16 09:44:19.946749: train_loss -0.7351 
2025-01-16 09:44:19.946749: val_loss -0.5781 
2025-01-16 09:44:19.951793: Pseudo dice [np.float32(0.7764), np.float32(0.5657)] 
2025-01-16 09:44:19.955300: Epoch time: 40.76 s 
2025-01-16 09:44:20.490715:  
2025-01-16 09:44:20.491719: Epoch 122 
2025-01-16 09:44:20.496280: Current learning rate: 0.00547 
2025-01-16 09:45:01.262828: train_loss -0.7505 
2025-01-16 09:45:01.262828: val_loss -0.5684 
2025-01-16 09:45:01.268845: Pseudo dice [np.float32(0.7908), np.float32(0.5047)] 
2025-01-16 09:45:01.271350: Epoch time: 40.77 s 
2025-01-16 09:45:01.805996:  
2025-01-16 09:45:01.807002: Epoch 123 
2025-01-16 09:45:01.813058: Current learning rate: 0.00544 
2025-01-16 09:45:42.553157: train_loss -0.7369 
2025-01-16 09:45:42.553674: val_loss -0.5582 
2025-01-16 09:45:42.559262: Pseudo dice [np.float32(0.7678), np.float32(0.5069)] 
2025-01-16 09:45:42.562821: Epoch time: 40.75 s 
2025-01-16 09:45:43.098080:  
2025-01-16 09:45:43.098080: Epoch 124 
2025-01-16 09:45:43.103634: Current learning rate: 0.0054 
2025-01-16 09:46:23.854041: train_loss -0.7486 
2025-01-16 09:46:23.854544: val_loss -0.5221 
2025-01-16 09:46:23.860559: Pseudo dice [np.float32(0.7862), np.float32(0.4525)] 
2025-01-16 09:46:23.863065: Epoch time: 40.76 s 
2025-01-16 09:46:24.388154:  
2025-01-16 09:46:24.389158: Epoch 125 
2025-01-16 09:46:24.394268: Current learning rate: 0.00536 
2025-01-16 09:47:05.167836: train_loss -0.7399 
2025-01-16 09:47:05.167836: val_loss -0.5388 
2025-01-16 09:47:05.174392: Pseudo dice [np.float32(0.7967), np.float32(0.5317)] 
2025-01-16 09:47:05.177901: Epoch time: 40.78 s 
2025-01-16 09:47:05.715430:  
2025-01-16 09:47:05.715430: Epoch 126 
2025-01-16 09:47:05.720995: Current learning rate: 0.00532 
2025-01-16 09:47:46.521829: train_loss -0.7501 
2025-01-16 09:47:46.522836: val_loss -0.4973 
2025-01-16 09:47:46.527969: Pseudo dice [np.float32(0.7726), np.float32(0.3921)] 
2025-01-16 09:47:46.531495: Epoch time: 40.81 s 
2025-01-16 09:47:47.061779:  
2025-01-16 09:47:47.061779: Epoch 127 
2025-01-16 09:47:47.066792: Current learning rate: 0.00528 
2025-01-16 09:48:27.838176: train_loss -0.7559 
2025-01-16 09:48:27.839179: val_loss -0.5511 
2025-01-16 09:48:27.844194: Pseudo dice [np.float32(0.7754), np.float32(0.4413)] 
2025-01-16 09:48:27.847699: Epoch time: 40.78 s 
2025-01-16 09:48:28.379791:  
2025-01-16 09:48:28.379791: Epoch 128 
2025-01-16 09:48:28.384859: Current learning rate: 0.00524 
2025-01-16 09:49:09.140255: train_loss -0.7462 
2025-01-16 09:49:09.141261: val_loss -0.5343 
2025-01-16 09:49:09.146568: Pseudo dice [np.float32(0.7586), np.float32(0.5096)] 
2025-01-16 09:49:09.149077: Epoch time: 40.76 s 
2025-01-16 09:49:09.677087:  
2025-01-16 09:49:09.677087: Epoch 129 
2025-01-16 09:49:09.682112: Current learning rate: 0.0052 
2025-01-16 09:49:50.410681: train_loss -0.7578 
2025-01-16 09:49:50.410681: val_loss -0.6075 
2025-01-16 09:49:50.416205: Pseudo dice [np.float32(0.8032), np.float32(0.5503)] 
2025-01-16 09:49:50.419231: Epoch time: 40.73 s 
2025-01-16 09:49:50.951415:  
2025-01-16 09:49:50.951415: Epoch 130 
2025-01-16 09:49:50.956426: Current learning rate: 0.00517 
2025-01-16 09:50:31.712531: train_loss -0.7461 
2025-01-16 09:50:31.713535: val_loss -0.5472 
2025-01-16 09:50:31.718549: Pseudo dice [np.float32(0.754), np.float32(0.4608)] 
2025-01-16 09:50:31.722054: Epoch time: 40.76 s 
2025-01-16 09:50:32.266606:  
2025-01-16 09:50:32.266606: Epoch 131 
2025-01-16 09:50:32.272236: Current learning rate: 0.00513 
2025-01-16 09:51:13.031267: train_loss -0.744 
2025-01-16 09:51:13.031771: val_loss -0.6023 
2025-01-16 09:51:13.037347: Pseudo dice [np.float32(0.7897), np.float32(0.4713)] 
2025-01-16 09:51:13.039888: Epoch time: 40.77 s 
2025-01-16 09:51:13.578374:  
2025-01-16 09:51:13.578374: Epoch 132 
2025-01-16 09:51:13.583422: Current learning rate: 0.00509 
2025-01-16 09:51:54.320324: train_loss -0.7481 
2025-01-16 09:51:54.320837: val_loss -0.5605 
2025-01-16 09:51:54.326421: Pseudo dice [np.float32(0.7833), np.float32(0.4304)] 
2025-01-16 09:51:54.329455: Epoch time: 40.74 s 
2025-01-16 09:51:54.869744:  
2025-01-16 09:51:54.869744: Epoch 133 
2025-01-16 09:51:54.875300: Current learning rate: 0.00505 
2025-01-16 09:52:35.631452: train_loss -0.735 
2025-01-16 09:52:35.632457: val_loss -0.5777 
2025-01-16 09:52:35.637465: Pseudo dice [np.float32(0.8007), np.float32(0.5179)] 
2025-01-16 09:52:35.640970: Epoch time: 40.76 s 
2025-01-16 09:52:36.171109:  
2025-01-16 09:52:36.171109: Epoch 134 
2025-01-16 09:52:36.176698: Current learning rate: 0.00501 
2025-01-16 09:53:16.893787: train_loss -0.7576 
2025-01-16 09:53:16.893787: val_loss -0.5576 
2025-01-16 09:53:16.899855: Pseudo dice [np.float32(0.7787), np.float32(0.4193)] 
2025-01-16 09:53:16.903402: Epoch time: 40.72 s 
2025-01-16 09:53:17.589726:  
2025-01-16 09:53:17.590731: Epoch 135 
2025-01-16 09:53:17.595285: Current learning rate: 0.00497 
2025-01-16 09:53:58.321448: train_loss -0.7668 
2025-01-16 09:53:58.321448: val_loss -0.6199 
2025-01-16 09:53:58.327564: Pseudo dice [np.float32(0.8072), np.float32(0.5849)] 
2025-01-16 09:53:58.330070: Epoch time: 40.73 s 
2025-01-16 09:53:58.872837:  
2025-01-16 09:53:58.872837: Epoch 136 
2025-01-16 09:53:58.878374: Current learning rate: 0.00493 
2025-01-16 09:54:39.620047: train_loss -0.7625 
2025-01-16 09:54:39.621555: val_loss -0.5888 
2025-01-16 09:54:39.626629: Pseudo dice [np.float32(0.8057), np.float32(0.5444)] 
2025-01-16 09:54:39.629638: Epoch time: 40.75 s 
2025-01-16 09:54:40.170944:  
2025-01-16 09:54:40.171446: Epoch 137 
2025-01-16 09:54:40.176459: Current learning rate: 0.00489 
2025-01-16 09:55:20.937134: train_loss -0.7707 
2025-01-16 09:55:20.938136: val_loss -0.5964 
2025-01-16 09:55:20.943657: Pseudo dice [np.float32(0.7904), np.float32(0.5459)] 
2025-01-16 09:55:20.947164: Epoch time: 40.77 s 
2025-01-16 09:55:20.950670: Yayy! New best EMA pseudo Dice: 0.6438999772071838 
2025-01-16 09:55:22.050985:  
2025-01-16 09:55:22.050985: Epoch 138 
2025-01-16 09:55:22.056531: Current learning rate: 0.00485 
2025-01-16 09:56:02.816868: train_loss -0.7566 
2025-01-16 09:56:02.817372: val_loss -0.6104 
2025-01-16 09:56:02.822387: Pseudo dice [np.float32(0.8062), np.float32(0.574)] 
2025-01-16 09:56:02.825896: Epoch time: 40.77 s 
2025-01-16 09:56:02.828402: Yayy! New best EMA pseudo Dice: 0.6485000252723694 
2025-01-16 09:56:03.583272:  
2025-01-16 09:56:03.584271: Epoch 139 
2025-01-16 09:56:03.589842: Current learning rate: 0.00482 
2025-01-16 09:56:44.361458: train_loss -0.7527 
2025-01-16 09:56:44.361961: val_loss -0.5347 
2025-01-16 09:56:44.367033: Pseudo dice [np.float32(0.7913), np.float32(0.4085)] 
2025-01-16 09:56:44.370046: Epoch time: 40.78 s 
2025-01-16 09:56:44.911570:  
2025-01-16 09:56:44.912573: Epoch 140 
2025-01-16 09:56:44.917603: Current learning rate: 0.00478 
2025-01-16 09:57:25.698724: train_loss -0.7726 
2025-01-16 09:57:25.699726: val_loss -0.5724 
2025-01-16 09:57:25.704798: Pseudo dice [np.float32(0.7967), np.float32(0.4602)] 
2025-01-16 09:57:25.708402: Epoch time: 40.79 s 
2025-01-16 09:57:26.249595:  
2025-01-16 09:57:26.249595: Epoch 141 
2025-01-16 09:57:26.254606: Current learning rate: 0.00474 
2025-01-16 09:58:07.032647: train_loss -0.7513 
2025-01-16 09:58:07.033651: val_loss -0.5071 
2025-01-16 09:58:07.038900: Pseudo dice [np.float32(0.7582), np.float32(0.3111)] 
2025-01-16 09:58:07.041409: Epoch time: 40.78 s 
2025-01-16 09:58:07.589674:  
2025-01-16 09:58:07.589674: Epoch 142 
2025-01-16 09:58:07.594732: Current learning rate: 0.0047 
2025-01-16 09:58:48.358842: train_loss -0.7505 
2025-01-16 09:58:48.358842: val_loss -0.5823 
2025-01-16 09:58:48.366359: Pseudo dice [np.float32(0.7893), np.float32(0.5542)] 
2025-01-16 09:58:48.368866: Epoch time: 40.77 s 
2025-01-16 09:58:49.053135:  
2025-01-16 09:58:49.053135: Epoch 143 
2025-01-16 09:58:49.058676: Current learning rate: 0.00466 
2025-01-16 09:59:29.800185: train_loss -0.7741 
2025-01-16 09:59:29.800705: val_loss -0.5841 
2025-01-16 09:59:29.805756: Pseudo dice [np.float32(0.7706), np.float32(0.4861)] 
2025-01-16 09:59:29.809293: Epoch time: 40.75 s 
2025-01-16 09:59:30.345518:  
2025-01-16 09:59:30.345518: Epoch 144 
2025-01-16 09:59:30.350531: Current learning rate: 0.00462 
2025-01-16 10:00:11.105677: train_loss -0.7835 
2025-01-16 10:00:11.106677: val_loss -0.5513 
2025-01-16 10:00:11.112223: Pseudo dice [np.float32(0.7665), np.float32(0.5068)] 
2025-01-16 10:00:11.115731: Epoch time: 40.76 s 
2025-01-16 10:00:11.652515:  
2025-01-16 10:00:11.653018: Epoch 145 
2025-01-16 10:00:11.658027: Current learning rate: 0.00458 
2025-01-16 10:00:52.412183: train_loss -0.7908 
2025-01-16 10:00:52.412183: val_loss -0.5498 
2025-01-16 10:00:52.418331: Pseudo dice [np.float32(0.7951), np.float32(0.4675)] 
2025-01-16 10:00:52.421884: Epoch time: 40.76 s 
2025-01-16 10:00:52.959573:  
2025-01-16 10:00:52.959573: Epoch 146 
2025-01-16 10:00:52.964582: Current learning rate: 0.00454 
2025-01-16 10:01:33.732168: train_loss -0.7823 
2025-01-16 10:01:33.733168: val_loss -0.5719 
2025-01-16 10:01:33.738181: Pseudo dice [np.float32(0.7911), np.float32(0.5354)] 
2025-01-16 10:01:33.741189: Epoch time: 40.77 s 
2025-01-16 10:01:34.276757:  
2025-01-16 10:01:34.276757: Epoch 147 
2025-01-16 10:01:34.282307: Current learning rate: 0.0045 
2025-01-16 10:02:15.028226: train_loss -0.7739 
2025-01-16 10:02:15.029230: val_loss -0.4901 
2025-01-16 10:02:15.034239: Pseudo dice [np.float32(0.7788), np.float32(0.5254)] 
2025-01-16 10:02:15.037744: Epoch time: 40.75 s 
2025-01-16 10:02:15.574135:  
2025-01-16 10:02:15.574644: Epoch 148 
2025-01-16 10:02:15.579695: Current learning rate: 0.00446 
2025-01-16 10:02:56.332191: train_loss -0.7891 
2025-01-16 10:02:56.332191: val_loss -0.5844 
2025-01-16 10:02:56.337249: Pseudo dice [np.float32(0.8099), np.float32(0.4898)] 
2025-01-16 10:02:56.341294: Epoch time: 40.76 s 
2025-01-16 10:02:56.882126:  
2025-01-16 10:02:56.883129: Epoch 149 
2025-01-16 10:02:56.887238: Current learning rate: 0.00442 
2025-01-16 10:03:37.648927: train_loss -0.7779 
2025-01-16 10:03:37.649438: val_loss -0.5499 
2025-01-16 10:03:37.654996: Pseudo dice [np.float32(0.7835), np.float32(0.4474)] 
2025-01-16 10:03:37.657009: Epoch time: 40.77 s 
2025-01-16 10:03:38.543704:  
2025-01-16 10:03:38.544206: Epoch 150 
2025-01-16 10:03:38.549216: Current learning rate: 0.00438 
2025-01-16 10:04:19.284047: train_loss -0.7931 
2025-01-16 10:04:19.284047: val_loss -0.6022 
2025-01-16 10:04:19.290060: Pseudo dice [np.float32(0.8129), np.float32(0.5109)] 
2025-01-16 10:04:19.293067: Epoch time: 40.74 s 
2025-01-16 10:04:19.832025:  
2025-01-16 10:04:19.833538: Epoch 151 
2025-01-16 10:04:19.838706: Current learning rate: 0.00434 
2025-01-16 10:05:00.584468: train_loss -0.7521 
2025-01-16 10:05:00.584468: val_loss -0.5975 
2025-01-16 10:05:00.591005: Pseudo dice [np.float32(0.7717), np.float32(0.5153)] 
2025-01-16 10:05:00.594012: Epoch time: 40.75 s 
2025-01-16 10:05:01.132901:  
2025-01-16 10:05:01.133404: Epoch 152 
2025-01-16 10:05:01.138413: Current learning rate: 0.0043 
2025-01-16 10:05:41.873696: train_loss -0.7631 
2025-01-16 10:05:41.873696: val_loss -0.563 
2025-01-16 10:05:41.879709: Pseudo dice [np.float32(0.787), np.float32(0.4618)] 
2025-01-16 10:05:41.883216: Epoch time: 40.74 s 
2025-01-16 10:05:42.419994:  
2025-01-16 10:05:42.419994: Epoch 153 
2025-01-16 10:05:42.425004: Current learning rate: 0.00427 
2025-01-16 10:06:23.170909: train_loss -0.7875 
2025-01-16 10:06:23.170909: val_loss -0.5713 
2025-01-16 10:06:23.176967: Pseudo dice [np.float32(0.7968), np.float32(0.4941)] 
2025-01-16 10:06:23.179997: Epoch time: 40.75 s 
2025-01-16 10:06:23.723686:  
2025-01-16 10:06:23.724686: Epoch 154 
2025-01-16 10:06:23.730314: Current learning rate: 0.00423 
2025-01-16 10:07:04.475304: train_loss -0.7739 
2025-01-16 10:07:04.475812: val_loss -0.5566 
2025-01-16 10:07:04.481379: Pseudo dice [np.float32(0.7963), np.float32(0.4079)] 
2025-01-16 10:07:04.484410: Epoch time: 40.75 s 
2025-01-16 10:07:05.031593:  
2025-01-16 10:07:05.032593: Epoch 155 
2025-01-16 10:07:05.038108: Current learning rate: 0.00419 
2025-01-16 10:07:45.772831: train_loss -0.7798 
2025-01-16 10:07:45.772831: val_loss -0.5042 
2025-01-16 10:07:45.779948: Pseudo dice [np.float32(0.7787), np.float32(0.3862)] 
2025-01-16 10:07:45.782468: Epoch time: 40.74 s 
2025-01-16 10:07:46.331896:  
2025-01-16 10:07:46.332398: Epoch 156 
2025-01-16 10:07:46.337409: Current learning rate: 0.00415 
2025-01-16 10:08:27.085289: train_loss -0.7759 
2025-01-16 10:08:27.085803: val_loss -0.608 
2025-01-16 10:08:27.091384: Pseudo dice [np.float32(0.8043), np.float32(0.5261)] 
2025-01-16 10:08:27.094410: Epoch time: 40.75 s 
2025-01-16 10:08:27.642800:  
2025-01-16 10:08:27.642800: Epoch 157 
2025-01-16 10:08:27.647848: Current learning rate: 0.00411 
2025-01-16 10:09:08.399162: train_loss -0.7703 
2025-01-16 10:09:08.399162: val_loss -0.5437 
2025-01-16 10:09:08.405697: Pseudo dice [np.float32(0.7721), np.float32(0.583)] 
2025-01-16 10:09:08.408706: Epoch time: 40.76 s 
2025-01-16 10:09:09.103368:  
2025-01-16 10:09:09.103368: Epoch 158 
2025-01-16 10:09:09.108920: Current learning rate: 0.00407 
2025-01-16 10:09:49.860602: train_loss -0.7842 
2025-01-16 10:09:49.861607: val_loss -0.5401 
2025-01-16 10:09:49.867240: Pseudo dice [np.float32(0.7873), np.float32(0.5383)] 
2025-01-16 10:09:49.871282: Epoch time: 40.76 s 
2025-01-16 10:09:50.416346:  
2025-01-16 10:09:50.416346: Epoch 159 
2025-01-16 10:09:50.421452: Current learning rate: 0.00403 
2025-01-16 10:10:31.197504: train_loss -0.7933 
2025-01-16 10:10:31.197504: val_loss -0.5899 
2025-01-16 10:10:31.203138: Pseudo dice [np.float32(0.8074), np.float32(0.4868)] 
2025-01-16 10:10:31.206663: Epoch time: 40.78 s 
2025-01-16 10:10:31.754745:  
2025-01-16 10:10:31.755250: Epoch 160 
2025-01-16 10:10:31.760261: Current learning rate: 0.00399 
2025-01-16 10:11:12.522648: train_loss -0.7884 
2025-01-16 10:11:12.522648: val_loss -0.5904 
2025-01-16 10:11:12.529166: Pseudo dice [np.float32(0.8112), np.float32(0.5127)] 
2025-01-16 10:11:12.532676: Epoch time: 40.77 s 
2025-01-16 10:11:13.080761:  
2025-01-16 10:11:13.080761: Epoch 161 
2025-01-16 10:11:13.085776: Current learning rate: 0.00395 
2025-01-16 10:11:53.853438: train_loss -0.7931 
2025-01-16 10:11:53.854951: val_loss -0.568 
2025-01-16 10:11:53.860488: Pseudo dice [np.float32(0.7789), np.float32(0.5668)] 
2025-01-16 10:11:53.863996: Epoch time: 40.77 s 
2025-01-16 10:11:54.419404:  
2025-01-16 10:11:54.419404: Epoch 162 
2025-01-16 10:11:54.425457: Current learning rate: 0.00391 
2025-01-16 10:12:35.204604: train_loss -0.7561 
2025-01-16 10:12:35.205607: val_loss -0.4905 
2025-01-16 10:12:35.210739: Pseudo dice [np.float32(0.7528), np.float32(0.538)] 
2025-01-16 10:12:35.214288: Epoch time: 40.79 s 
2025-01-16 10:12:35.762853:  
2025-01-16 10:12:35.763356: Epoch 163 
2025-01-16 10:12:35.768367: Current learning rate: 0.00387 
2025-01-16 10:13:16.521961: train_loss -0.7804 
2025-01-16 10:13:16.522464: val_loss -0.5623 
2025-01-16 10:13:16.528086: Pseudo dice [np.float32(0.8129), np.float32(0.4075)] 
2025-01-16 10:13:16.531122: Epoch time: 40.76 s 
2025-01-16 10:13:17.082958:  
2025-01-16 10:13:17.082958: Epoch 164 
2025-01-16 10:13:17.088991: Current learning rate: 0.00383 
2025-01-16 10:13:57.841073: train_loss -0.7866 
2025-01-16 10:13:57.842077: val_loss -0.5785 
2025-01-16 10:13:57.847086: Pseudo dice [np.float32(0.7949), np.float32(0.5119)] 
2025-01-16 10:13:57.849592: Epoch time: 40.76 s 
2025-01-16 10:13:58.393951:  
2025-01-16 10:13:58.394455: Epoch 165 
2025-01-16 10:13:58.399477: Current learning rate: 0.00379 
2025-01-16 10:14:39.144695: train_loss -0.7903 
2025-01-16 10:14:39.145697: val_loss -0.5786 
2025-01-16 10:14:39.150737: Pseudo dice [np.float32(0.7872), np.float32(0.4888)] 
2025-01-16 10:14:39.154748: Epoch time: 40.75 s 
2025-01-16 10:14:39.837220:  
2025-01-16 10:14:39.837220: Epoch 166 
2025-01-16 10:14:39.842285: Current learning rate: 0.00375 
2025-01-16 10:15:20.587867: train_loss -0.8012 
2025-01-16 10:15:20.588867: val_loss -0.5973 
2025-01-16 10:15:20.593881: Pseudo dice [np.float32(0.7907), np.float32(0.6334)] 
2025-01-16 10:15:20.596891: Epoch time: 40.75 s 
2025-01-16 10:15:20.600398: Yayy! New best EMA pseudo Dice: 0.6499999761581421 
2025-01-16 10:15:21.333561:  
2025-01-16 10:15:21.334070: Epoch 167 
2025-01-16 10:15:21.339159: Current learning rate: 0.00371 
2025-01-16 10:16:02.085949: train_loss -0.7958 
2025-01-16 10:16:02.085949: val_loss -0.5051 
2025-01-16 10:16:02.091482: Pseudo dice [np.float32(0.7701), np.float32(0.4573)] 
2025-01-16 10:16:02.095491: Epoch time: 40.75 s 
2025-01-16 10:16:02.644006:  
2025-01-16 10:16:02.644006: Epoch 168 
2025-01-16 10:16:02.649032: Current learning rate: 0.00367 
2025-01-16 10:16:43.396224: train_loss -0.7667 
2025-01-16 10:16:43.396224: val_loss -0.5707 
2025-01-16 10:16:43.401763: Pseudo dice [np.float32(0.7928), np.float32(0.4834)] 
2025-01-16 10:16:43.404787: Epoch time: 40.75 s 
2025-01-16 10:16:43.961414:  
2025-01-16 10:16:43.961414: Epoch 169 
2025-01-16 10:16:43.968052: Current learning rate: 0.00363 
2025-01-16 10:17:24.727236: train_loss -0.7756 
2025-01-16 10:17:24.727236: val_loss -0.5693 
2025-01-16 10:17:24.732685: Pseudo dice [np.float32(0.7858), np.float32(0.6003)] 
2025-01-16 10:17:24.736197: Epoch time: 40.77 s 
2025-01-16 10:17:24.738706: Yayy! New best EMA pseudo Dice: 0.6503000259399414 
2025-01-16 10:17:25.494464:  
2025-01-16 10:17:25.494464: Epoch 170 
2025-01-16 10:17:25.500017: Current learning rate: 0.00359 
2025-01-16 10:18:06.254747: train_loss -0.7788 
2025-01-16 10:18:06.254747: val_loss -0.6035 
2025-01-16 10:18:06.260944: Pseudo dice [np.float32(0.8037), np.float32(0.5801)] 
2025-01-16 10:18:06.263453: Epoch time: 40.76 s 
2025-01-16 10:18:06.266986: Yayy! New best EMA pseudo Dice: 0.6545000076293945 
2025-01-16 10:18:07.047670:  
2025-01-16 10:18:07.048172: Epoch 171 
2025-01-16 10:18:07.053181: Current learning rate: 0.00355 
2025-01-16 10:18:47.802858: train_loss -0.7996 
2025-01-16 10:18:47.803863: val_loss -0.6163 
2025-01-16 10:18:47.809383: Pseudo dice [np.float32(0.7971), np.float32(0.5368)] 
2025-01-16 10:18:47.811891: Epoch time: 40.76 s 
2025-01-16 10:18:47.815402: Yayy! New best EMA pseudo Dice: 0.6557000279426575 
2025-01-16 10:18:48.599708:  
2025-01-16 10:18:48.599708: Epoch 172 
2025-01-16 10:18:48.605778: Current learning rate: 0.00351 
2025-01-16 10:19:29.366596: train_loss -0.8156 
2025-01-16 10:19:29.367100: val_loss -0.5497 
2025-01-16 10:19:29.372110: Pseudo dice [np.float32(0.7951), np.float32(0.4368)] 
2025-01-16 10:19:29.375618: Epoch time: 40.77 s 
2025-01-16 10:19:29.921169:  
2025-01-16 10:19:29.921169: Epoch 173 
2025-01-16 10:19:29.927259: Current learning rate: 0.00346 
2025-01-16 10:20:10.693663: train_loss -0.8101 
2025-01-16 10:20:10.694186: val_loss -0.5545 
2025-01-16 10:20:10.699196: Pseudo dice [np.float32(0.8022), np.float32(0.522)] 
2025-01-16 10:20:10.702711: Epoch time: 40.77 s 
2025-01-16 10:20:11.391557:  
2025-01-16 10:20:11.391557: Epoch 174 
2025-01-16 10:20:11.397110: Current learning rate: 0.00342 
2025-01-16 10:20:52.178681: train_loss -0.8109 
2025-01-16 10:20:52.179683: val_loss -0.6315 
2025-01-16 10:20:52.186301: Pseudo dice [np.float32(0.7916), np.float32(0.7095)] 
2025-01-16 10:20:52.189825: Epoch time: 40.79 s 
2025-01-16 10:20:52.192343: Yayy! New best EMA pseudo Dice: 0.6625999808311462 
2025-01-16 10:20:52.972052:  
2025-01-16 10:20:52.972052: Epoch 175 
2025-01-16 10:20:52.977589: Current learning rate: 0.00338 
2025-01-16 10:21:33.731300: train_loss -0.8206 
2025-01-16 10:21:33.732300: val_loss -0.6363 
2025-01-16 10:21:33.737813: Pseudo dice [np.float32(0.8066), np.float32(0.5839)] 
2025-01-16 10:21:33.740318: Epoch time: 40.76 s 
2025-01-16 10:21:33.743827: Yayy! New best EMA pseudo Dice: 0.6657999753952026 
2025-01-16 10:21:34.479108:  
2025-01-16 10:21:34.479108: Epoch 176 
2025-01-16 10:21:34.484226: Current learning rate: 0.00334 
2025-01-16 10:22:15.251012: train_loss -0.8092 
2025-01-16 10:22:15.251513: val_loss -0.5901 
2025-01-16 10:22:15.257061: Pseudo dice [np.float32(0.7958), np.float32(0.5117)] 
2025-01-16 10:22:15.259576: Epoch time: 40.77 s 
2025-01-16 10:22:15.806687:  
2025-01-16 10:22:15.807688: Epoch 177 
2025-01-16 10:22:15.812756: Current learning rate: 0.0033 
2025-01-16 10:22:56.591306: train_loss -0.8014 
2025-01-16 10:22:56.591306: val_loss -0.5619 
2025-01-16 10:22:56.598850: Pseudo dice [np.float32(0.8093), np.float32(0.4775)] 
2025-01-16 10:22:56.601356: Epoch time: 40.78 s 
2025-01-16 10:22:57.145880:  
2025-01-16 10:22:57.145880: Epoch 178 
2025-01-16 10:22:57.151430: Current learning rate: 0.00326 
2025-01-16 10:23:37.916509: train_loss -0.7928 
2025-01-16 10:23:37.916509: val_loss -0.5956 
2025-01-16 10:23:37.923087: Pseudo dice [np.float32(0.8038), np.float32(0.5147)] 
2025-01-16 10:23:37.926095: Epoch time: 40.77 s 
2025-01-16 10:23:38.474692:  
2025-01-16 10:23:38.474692: Epoch 179 
2025-01-16 10:23:38.479702: Current learning rate: 0.00322 
2025-01-16 10:24:19.227152: train_loss -0.8027 
2025-01-16 10:24:19.227654: val_loss -0.5351 
2025-01-16 10:24:19.232709: Pseudo dice [np.float32(0.7839), np.float32(0.3479)] 
2025-01-16 10:24:19.236219: Epoch time: 40.75 s 
2025-01-16 10:24:19.796989:  
2025-01-16 10:24:19.797501: Epoch 180 
2025-01-16 10:24:19.802552: Current learning rate: 0.00318 
2025-01-16 10:25:00.546162: train_loss -0.8117 
2025-01-16 10:25:00.546672: val_loss -0.5748 
2025-01-16 10:25:00.551027: Pseudo dice [np.float32(0.8052), np.float32(0.6011)] 
2025-01-16 10:25:00.555649: Epoch time: 40.75 s 
2025-01-16 10:25:01.097637:  
2025-01-16 10:25:01.097637: Epoch 181 
2025-01-16 10:25:01.102734: Current learning rate: 0.00314 
2025-01-16 10:25:41.853602: train_loss -0.8089 
2025-01-16 10:25:41.853602: val_loss -0.6114 
2025-01-16 10:25:41.859657: Pseudo dice [np.float32(0.8034), np.float32(0.5761)] 
2025-01-16 10:25:41.862667: Epoch time: 40.76 s 
2025-01-16 10:25:42.553328:  
2025-01-16 10:25:42.554328: Epoch 182 
2025-01-16 10:25:42.559398: Current learning rate: 0.0031 
2025-01-16 10:26:23.305842: train_loss -0.8058 
2025-01-16 10:26:23.306360: val_loss -0.6163 
2025-01-16 10:26:23.310903: Pseudo dice [np.float32(0.8104), np.float32(0.6384)] 
2025-01-16 10:26:23.314442: Epoch time: 40.75 s 
2025-01-16 10:26:23.316701: Yayy! New best EMA pseudo Dice: 0.6672000288963318 
2025-01-16 10:26:24.069518:  
2025-01-16 10:26:24.069518: Epoch 183 
2025-01-16 10:26:24.074569: Current learning rate: 0.00306 
2025-01-16 10:27:04.816051: train_loss -0.8066 
2025-01-16 10:27:04.816553: val_loss -0.5467 
2025-01-16 10:27:04.822130: Pseudo dice [np.float32(0.7849), np.float32(0.5281)] 
2025-01-16 10:27:04.825188: Epoch time: 40.75 s 
2025-01-16 10:27:05.368665:  
2025-01-16 10:27:05.369168: Epoch 184 
2025-01-16 10:27:05.374180: Current learning rate: 0.00302 
2025-01-16 10:27:46.129579: train_loss -0.8052 
2025-01-16 10:27:46.130579: val_loss -0.5967 
2025-01-16 10:27:46.136094: Pseudo dice [np.float32(0.7891), np.float32(0.5539)] 
2025-01-16 10:27:46.139601: Epoch time: 40.76 s 
2025-01-16 10:27:46.679626:  
2025-01-16 10:27:46.680625: Epoch 185 
2025-01-16 10:27:46.685181: Current learning rate: 0.00297 
2025-01-16 10:28:27.439532: train_loss -0.8147 
2025-01-16 10:28:27.439532: val_loss -0.5826 
2025-01-16 10:28:27.444543: Pseudo dice [np.float32(0.7952), np.float32(0.597)] 
2025-01-16 10:28:27.448552: Epoch time: 40.76 s 
2025-01-16 10:28:27.451057: Yayy! New best EMA pseudo Dice: 0.6696000099182129 
2025-01-16 10:28:28.188629:  
2025-01-16 10:28:28.190130: Epoch 186 
2025-01-16 10:28:28.193639: Current learning rate: 0.00293 
2025-01-16 10:29:08.942206: train_loss -0.7951 
2025-01-16 10:29:08.942711: val_loss -0.5986 
2025-01-16 10:29:08.948288: Pseudo dice [np.float32(0.7967), np.float32(0.6956)] 
2025-01-16 10:29:08.951321: Epoch time: 40.75 s 
2025-01-16 10:29:08.954367: Yayy! New best EMA pseudo Dice: 0.6772000193595886 
2025-01-16 10:29:09.687866:  
2025-01-16 10:29:09.687866: Epoch 187 
2025-01-16 10:29:09.691909: Current learning rate: 0.00289 
2025-01-16 10:29:50.427394: train_loss -0.8148 
2025-01-16 10:29:50.427394: val_loss -0.573 
2025-01-16 10:29:50.433135: Pseudo dice [np.float32(0.813), np.float32(0.5481)] 
2025-01-16 10:29:50.435663: Epoch time: 40.74 s 
2025-01-16 10:29:50.439702: Yayy! New best EMA pseudo Dice: 0.6776000261306763 
2025-01-16 10:29:51.229129:  
2025-01-16 10:29:51.229632: Epoch 188 
2025-01-16 10:29:51.234641: Current learning rate: 0.00285 
2025-01-16 10:30:31.979380: train_loss -0.8109 
2025-01-16 10:30:31.979899: val_loss -0.5702 
2025-01-16 10:30:31.984544: Pseudo dice [np.float32(0.7934), np.float32(0.4711)] 
2025-01-16 10:30:31.988056: Epoch time: 40.75 s 
2025-01-16 10:30:32.536228:  
2025-01-16 10:30:32.536228: Epoch 189 
2025-01-16 10:30:32.541775: Current learning rate: 0.00281 
2025-01-16 10:31:13.300041: train_loss -0.8043 
2025-01-16 10:31:13.301041: val_loss -0.565 
2025-01-16 10:31:13.306639: Pseudo dice [np.float32(0.7875), np.float32(0.3761)] 
2025-01-16 10:31:13.309170: Epoch time: 40.76 s 
2025-01-16 10:31:14.005512:  
2025-01-16 10:31:14.005512: Epoch 190 
2025-01-16 10:31:14.011077: Current learning rate: 0.00277 
2025-01-16 10:31:54.762902: train_loss -0.819 
2025-01-16 10:31:54.763416: val_loss -0.5557 
2025-01-16 10:31:54.770544: Pseudo dice [np.float32(0.806), np.float32(0.548)] 
2025-01-16 10:31:54.773599: Epoch time: 40.76 s 
2025-01-16 10:31:55.316075:  
2025-01-16 10:31:55.316075: Epoch 191 
2025-01-16 10:31:55.321181: Current learning rate: 0.00273 
2025-01-16 10:32:36.067733: train_loss -0.8291 
2025-01-16 10:32:36.067733: val_loss -0.532 
2025-01-16 10:32:36.074319: Pseudo dice [np.float32(0.7999), np.float32(0.5944)] 
2025-01-16 10:32:36.077326: Epoch time: 40.75 s 
2025-01-16 10:32:36.627838:  
2025-01-16 10:32:36.628341: Epoch 192 
2025-01-16 10:32:36.633351: Current learning rate: 0.00268 
2025-01-16 10:33:17.354506: train_loss -0.8209 
2025-01-16 10:33:17.355009: val_loss -0.5915 
2025-01-16 10:33:17.360080: Pseudo dice [np.float32(0.8086), np.float32(0.5449)] 
2025-01-16 10:33:17.363589: Epoch time: 40.73 s 
2025-01-16 10:33:17.920053:  
2025-01-16 10:33:17.920053: Epoch 193 
2025-01-16 10:33:17.925064: Current learning rate: 0.00264 
2025-01-16 10:33:58.665497: train_loss -0.8296 
2025-01-16 10:33:58.665497: val_loss -0.5903 
2025-01-16 10:33:58.671058: Pseudo dice [np.float32(0.7777), np.float32(0.555)] 
2025-01-16 10:33:58.673108: Epoch time: 40.75 s 
2025-01-16 10:33:59.224872:  
2025-01-16 10:33:59.225876: Epoch 194 
2025-01-16 10:33:59.230408: Current learning rate: 0.0026 
2025-01-16 10:34:39.991523: train_loss -0.8089 
2025-01-16 10:34:39.991523: val_loss -0.5964 
2025-01-16 10:34:39.996560: Pseudo dice [np.float32(0.8033), np.float32(0.5044)] 
2025-01-16 10:34:39.999112: Epoch time: 40.77 s 
2025-01-16 10:34:40.558210:  
2025-01-16 10:34:40.558210: Epoch 195 
2025-01-16 10:34:40.563235: Current learning rate: 0.00256 
2025-01-16 10:35:21.293863: train_loss -0.8298 
2025-01-16 10:35:21.293863: val_loss -0.5706 
2025-01-16 10:35:21.298874: Pseudo dice [np.float32(0.7997), np.float32(0.5021)] 
2025-01-16 10:35:21.302382: Epoch time: 40.74 s 
2025-01-16 10:35:21.854950:  
2025-01-16 10:35:21.854950: Epoch 196 
2025-01-16 10:35:21.860491: Current learning rate: 0.00252 
2025-01-16 10:36:02.614819: train_loss -0.8236 
2025-01-16 10:36:02.615321: val_loss -0.554 
2025-01-16 10:36:02.621037: Pseudo dice [np.float32(0.8103), np.float32(0.5489)] 
2025-01-16 10:36:02.623572: Epoch time: 40.76 s 
2025-01-16 10:36:03.183315:  
2025-01-16 10:36:03.184320: Epoch 197 
2025-01-16 10:36:03.188865: Current learning rate: 0.00248 
2025-01-16 10:36:43.941149: train_loss -0.8206 
2025-01-16 10:36:43.941663: val_loss -0.5492 
2025-01-16 10:36:43.946722: Pseudo dice [np.float32(0.7993), np.float32(0.5005)] 
2025-01-16 10:36:43.949749: Epoch time: 40.76 s 
2025-01-16 10:36:44.663908:  
2025-01-16 10:36:44.664421: Epoch 198 
2025-01-16 10:36:44.669487: Current learning rate: 0.00243 
2025-01-16 10:37:25.387607: train_loss -0.8208 
2025-01-16 10:37:25.388110: val_loss -0.5907 
2025-01-16 10:37:25.393122: Pseudo dice [np.float32(0.7988), np.float32(0.5928)] 
2025-01-16 10:37:25.395627: Epoch time: 40.72 s 
2025-01-16 10:37:25.950020:  
2025-01-16 10:37:25.950020: Epoch 199 
2025-01-16 10:37:25.955029: Current learning rate: 0.00239 
2025-01-16 10:38:06.676186: train_loss -0.8174 
2025-01-16 10:38:06.677186: val_loss -0.6052 
2025-01-16 10:38:06.682698: Pseudo dice [np.float32(0.7943), np.float32(0.5614)] 
2025-01-16 10:38:06.684945: Epoch time: 40.73 s 
2025-01-16 10:38:07.473657:  
2025-01-16 10:38:07.473657: Epoch 200 
2025-01-16 10:38:07.479308: Current learning rate: 0.00235 
2025-01-16 10:38:48.229119: train_loss -0.8279 
2025-01-16 10:38:48.230623: val_loss -0.5957 
2025-01-16 10:38:48.235661: Pseudo dice [np.float32(0.7997), np.float32(0.637)] 
2025-01-16 10:38:48.239174: Epoch time: 40.76 s 
2025-01-16 10:38:48.791988:  
2025-01-16 10:38:48.792491: Epoch 201 
2025-01-16 10:38:48.797504: Current learning rate: 0.00231 
2025-01-16 10:39:29.544163: train_loss -0.8335 
2025-01-16 10:39:29.544163: val_loss -0.5999 
2025-01-16 10:39:29.550178: Pseudo dice [np.float32(0.78), np.float32(0.5994)] 
2025-01-16 10:39:29.553685: Epoch time: 40.75 s 
2025-01-16 10:39:30.119105:  
2025-01-16 10:39:30.120108: Epoch 202 
2025-01-16 10:39:30.124655: Current learning rate: 0.00226 
2025-01-16 10:40:10.866064: train_loss -0.8307 
2025-01-16 10:40:10.866064: val_loss -0.5233 
2025-01-16 10:40:10.872684: Pseudo dice [np.float32(0.7898), np.float32(0.3944)] 
2025-01-16 10:40:10.875693: Epoch time: 40.75 s 
2025-01-16 10:40:11.434222:  
2025-01-16 10:40:11.434724: Epoch 203 
2025-01-16 10:40:11.439736: Current learning rate: 0.00222 
2025-01-16 10:40:52.176363: train_loss -0.8201 
2025-01-16 10:40:52.176363: val_loss -0.6062 
2025-01-16 10:40:52.181530: Pseudo dice [np.float32(0.7975), np.float32(0.5346)] 
2025-01-16 10:40:52.184569: Epoch time: 40.74 s 
2025-01-16 10:40:52.735449:  
2025-01-16 10:40:52.735449: Epoch 204 
2025-01-16 10:40:52.740460: Current learning rate: 0.00218 
2025-01-16 10:41:33.484421: train_loss -0.8366 
2025-01-16 10:41:33.484421: val_loss -0.5753 
2025-01-16 10:41:33.489432: Pseudo dice [np.float32(0.7842), np.float32(0.5286)] 
2025-01-16 10:41:33.493442: Epoch time: 40.75 s 
2025-01-16 10:41:34.188766:  
2025-01-16 10:41:34.188766: Epoch 205 
2025-01-16 10:41:34.194352: Current learning rate: 0.00214 
2025-01-16 10:42:14.964084: train_loss -0.8172 
2025-01-16 10:42:14.964084: val_loss -0.5811 
2025-01-16 10:42:14.969685: Pseudo dice [np.float32(0.7857), np.float32(0.52)] 
2025-01-16 10:42:14.972231: Epoch time: 40.78 s 
2025-01-16 10:42:15.498929:  
2025-01-16 10:42:15.498929: Epoch 206 
2025-01-16 10:42:15.504485: Current learning rate: 0.00209 
2025-01-16 10:42:56.273169: train_loss -0.8302 
2025-01-16 10:42:56.273169: val_loss -0.5826 
2025-01-16 10:42:56.279182: Pseudo dice [np.float32(0.799), np.float32(0.6879)] 
2025-01-16 10:42:56.282190: Epoch time: 40.77 s 
2025-01-16 10:42:56.808028:  
2025-01-16 10:42:56.808028: Epoch 207 
2025-01-16 10:42:56.813038: Current learning rate: 0.00205 
2025-01-16 10:43:37.548282: train_loss -0.8383 
2025-01-16 10:43:37.548282: val_loss -0.5771 
2025-01-16 10:43:37.553294: Pseudo dice [np.float32(0.8026), np.float32(0.4529)] 
2025-01-16 10:43:37.556803: Epoch time: 40.74 s 
2025-01-16 10:43:38.080577:  
2025-01-16 10:43:38.080577: Epoch 208 
2025-01-16 10:43:38.086129: Current learning rate: 0.00201 
2025-01-16 10:44:18.849281: train_loss -0.8287 
2025-01-16 10:44:18.849281: val_loss -0.603 
2025-01-16 10:44:18.855930: Pseudo dice [np.float32(0.7805), np.float32(0.6126)] 
2025-01-16 10:44:18.859002: Epoch time: 40.77 s 
2025-01-16 10:44:19.378221:  
2025-01-16 10:44:19.378221: Epoch 209 
2025-01-16 10:44:19.383755: Current learning rate: 0.00196 
2025-01-16 10:45:00.149386: train_loss -0.8399 
2025-01-16 10:45:00.149889: val_loss -0.5909 
2025-01-16 10:45:00.155902: Pseudo dice [np.float32(0.8114), np.float32(0.5571)] 
2025-01-16 10:45:00.159408: Epoch time: 40.77 s 
2025-01-16 10:45:00.679009:  
2025-01-16 10:45:00.679009: Epoch 210 
2025-01-16 10:45:00.684033: Current learning rate: 0.00192 
2025-01-16 10:45:41.424580: train_loss -0.8398 
2025-01-16 10:45:41.425083: val_loss -0.5654 
2025-01-16 10:45:41.429599: Pseudo dice [np.float32(0.8085), np.float32(0.4546)] 
2025-01-16 10:45:41.433818: Epoch time: 40.75 s 
2025-01-16 10:45:41.956655:  
2025-01-16 10:45:41.957658: Epoch 211 
2025-01-16 10:45:41.962669: Current learning rate: 0.00188 
2025-01-16 10:46:22.713554: train_loss -0.8406 
2025-01-16 10:46:22.714556: val_loss -0.6075 
2025-01-16 10:46:22.720101: Pseudo dice [np.float32(0.8207), np.float32(0.5095)] 
2025-01-16 10:46:22.722607: Epoch time: 40.76 s 
2025-01-16 10:46:23.239320:  
2025-01-16 10:46:23.240319: Epoch 212 
2025-01-16 10:46:23.245901: Current learning rate: 0.00184 
2025-01-16 10:47:03.989397: train_loss -0.8422 
2025-01-16 10:47:03.989912: val_loss -0.5851 
2025-01-16 10:47:03.995517: Pseudo dice [np.float32(0.7929), np.float32(0.5754)] 
2025-01-16 10:47:03.998056: Epoch time: 40.75 s 
2025-01-16 10:47:04.521783:  
2025-01-16 10:47:04.522784: Epoch 213 
2025-01-16 10:47:04.527852: Current learning rate: 0.00179 
2025-01-16 10:47:45.273582: train_loss -0.8328 
2025-01-16 10:47:45.273582: val_loss -0.5372 
2025-01-16 10:47:45.278649: Pseudo dice [np.float32(0.8046), np.float32(0.4868)] 
2025-01-16 10:47:45.283224: Epoch time: 40.75 s 
2025-01-16 10:47:45.944096:  
2025-01-16 10:47:45.945099: Epoch 214 
2025-01-16 10:47:45.949660: Current learning rate: 0.00175 
2025-01-16 10:48:26.692228: train_loss -0.8315 
2025-01-16 10:48:26.693226: val_loss -0.5573 
2025-01-16 10:48:26.698741: Pseudo dice [np.float32(0.8038), np.float32(0.5107)] 
2025-01-16 10:48:26.701248: Epoch time: 40.75 s 
2025-01-16 10:48:27.215783:  
2025-01-16 10:48:27.216286: Epoch 215 
2025-01-16 10:48:27.221304: Current learning rate: 0.0017 
2025-01-16 10:49:07.980124: train_loss -0.8397 
2025-01-16 10:49:07.980629: val_loss -0.5838 
2025-01-16 10:49:07.985639: Pseudo dice [np.float32(0.8052), np.float32(0.5663)] 
2025-01-16 10:49:07.989150: Epoch time: 40.77 s 
2025-01-16 10:49:08.504220:  
2025-01-16 10:49:08.504220: Epoch 216 
2025-01-16 10:49:08.509279: Current learning rate: 0.00166 
2025-01-16 10:49:49.257693: train_loss -0.8403 
2025-01-16 10:49:49.257693: val_loss -0.5535 
2025-01-16 10:49:49.263749: Pseudo dice [np.float32(0.8002), np.float32(0.3425)] 
2025-01-16 10:49:49.266806: Epoch time: 40.75 s 
2025-01-16 10:49:49.783214:  
2025-01-16 10:49:49.783214: Epoch 217 
2025-01-16 10:49:49.788235: Current learning rate: 0.00162 
2025-01-16 10:50:30.543160: train_loss -0.8335 
2025-01-16 10:50:30.543160: val_loss -0.5947 
2025-01-16 10:50:30.548262: Pseudo dice [np.float32(0.8208), np.float32(0.5748)] 
2025-01-16 10:50:30.551781: Epoch time: 40.76 s 
2025-01-16 10:50:31.069752:  
2025-01-16 10:50:31.070751: Epoch 218 
2025-01-16 10:50:31.075854: Current learning rate: 0.00157 
2025-01-16 10:51:11.820368: train_loss -0.8254 
2025-01-16 10:51:11.820368: val_loss -0.583 
2025-01-16 10:51:11.825516: Pseudo dice [np.float32(0.7972), np.float32(0.5587)] 
2025-01-16 10:51:11.829025: Epoch time: 40.75 s 
2025-01-16 10:51:12.352048:  
2025-01-16 10:51:12.352048: Epoch 219 
2025-01-16 10:51:12.357180: Current learning rate: 0.00153 
2025-01-16 10:51:53.100072: train_loss -0.8281 
2025-01-16 10:51:53.101581: val_loss -0.6045 
2025-01-16 10:51:53.107165: Pseudo dice [np.float32(0.7912), np.float32(0.6304)] 
2025-01-16 10:51:53.110226: Epoch time: 40.75 s 
2025-01-16 10:51:53.627085:  
2025-01-16 10:51:53.627085: Epoch 220 
2025-01-16 10:51:53.632647: Current learning rate: 0.00148 
2025-01-16 10:52:34.389193: train_loss -0.8462 
2025-01-16 10:52:34.389706: val_loss -0.5881 
2025-01-16 10:52:34.394777: Pseudo dice [np.float32(0.7819), np.float32(0.6849)] 
2025-01-16 10:52:34.397805: Epoch time: 40.76 s 
2025-01-16 10:52:34.914616:  
2025-01-16 10:52:34.914616: Epoch 221 
2025-01-16 10:52:34.918640: Current learning rate: 0.00144 
2025-01-16 10:53:15.676545: train_loss -0.8362 
2025-01-16 10:53:15.677545: val_loss -0.5532 
2025-01-16 10:53:15.683057: Pseudo dice [np.float32(0.7816), np.float32(0.4162)] 
2025-01-16 10:53:15.686565: Epoch time: 40.76 s 
2025-01-16 10:53:16.201440:  
2025-01-16 10:53:16.201440: Epoch 222 
2025-01-16 10:53:16.206580: Current learning rate: 0.00139 
2025-01-16 10:53:57.022475: train_loss -0.8467 
2025-01-16 10:53:57.022475: val_loss -0.569 
2025-01-16 10:53:57.027575: Pseudo dice [np.float32(0.7943), np.float32(0.4814)] 
2025-01-16 10:53:57.031630: Epoch time: 40.82 s 
2025-01-16 10:53:57.553039:  
2025-01-16 10:53:57.553039: Epoch 223 
2025-01-16 10:53:57.558588: Current learning rate: 0.00135 
2025-01-16 10:54:38.334199: train_loss -0.8499 
2025-01-16 10:54:38.334721: val_loss -0.5258 
2025-01-16 10:54:38.339779: Pseudo dice [np.float32(0.7849), np.float32(0.357)] 
2025-01-16 10:54:38.342818: Epoch time: 40.78 s 
2025-01-16 10:54:38.862751:  
2025-01-16 10:54:38.863264: Epoch 224 
2025-01-16 10:54:38.867847: Current learning rate: 0.0013 
2025-01-16 10:55:19.597066: train_loss -0.8511 
2025-01-16 10:55:19.597066: val_loss -0.587 
2025-01-16 10:55:19.603081: Pseudo dice [np.float32(0.806), np.float32(0.613)] 
2025-01-16 10:55:19.606587: Epoch time: 40.73 s 
2025-01-16 10:55:20.124082:  
2025-01-16 10:55:20.124082: Epoch 225 
2025-01-16 10:55:20.129633: Current learning rate: 0.00126 
2025-01-16 10:56:00.875379: train_loss -0.8462 
2025-01-16 10:56:00.875379: val_loss -0.5317 
2025-01-16 10:56:00.882897: Pseudo dice [np.float32(0.78), np.float32(0.5142)] 
2025-01-16 10:56:00.888910: Epoch time: 40.75 s 
2025-01-16 10:56:01.405268:  
2025-01-16 10:56:01.405770: Epoch 226 
2025-01-16 10:56:01.410782: Current learning rate: 0.00121 
2025-01-16 10:56:42.136859: train_loss -0.8458 
2025-01-16 10:56:42.136859: val_loss -0.6036 
2025-01-16 10:56:42.143090: Pseudo dice [np.float32(0.7958), np.float32(0.6506)] 
2025-01-16 10:56:42.145883: Epoch time: 40.73 s 
2025-01-16 10:56:42.659582:  
2025-01-16 10:56:42.660580: Epoch 227 
2025-01-16 10:56:42.666164: Current learning rate: 0.00117 
2025-01-16 10:57:23.401513: train_loss -0.8478 
2025-01-16 10:57:23.402513: val_loss -0.5888 
2025-01-16 10:57:23.408025: Pseudo dice [np.float32(0.8057), np.float32(0.4461)] 
2025-01-16 10:57:23.410530: Epoch time: 40.74 s 
2025-01-16 10:57:23.931003:  
2025-01-16 10:57:23.931505: Epoch 228 
2025-01-16 10:57:23.936516: Current learning rate: 0.00112 
2025-01-16 10:58:04.655486: train_loss -0.8583 
2025-01-16 10:58:04.656487: val_loss -0.5884 
2025-01-16 10:58:04.662556: Pseudo dice [np.float32(0.7982), np.float32(0.5625)] 
2025-01-16 10:58:04.665583: Epoch time: 40.73 s 
2025-01-16 10:58:05.181979:  
2025-01-16 10:58:05.181979: Epoch 229 
2025-01-16 10:58:05.186993: Current learning rate: 0.00108 
2025-01-16 10:58:45.937264: train_loss -0.8625 
2025-01-16 10:58:45.937264: val_loss -0.56 
2025-01-16 10:58:45.943796: Pseudo dice [np.float32(0.7958), np.float32(0.5139)] 
2025-01-16 10:58:45.946803: Epoch time: 40.76 s 
2025-01-16 10:58:46.461452:  
2025-01-16 10:58:46.462456: Epoch 230 
2025-01-16 10:58:46.467002: Current learning rate: 0.00103 
2025-01-16 10:59:27.215085: train_loss -0.8346 
2025-01-16 10:59:27.215085: val_loss -0.5429 
2025-01-16 10:59:27.221101: Pseudo dice [np.float32(0.8185), np.float32(0.4188)] 
2025-01-16 10:59:27.224109: Epoch time: 40.75 s 
2025-01-16 10:59:27.880638:  
2025-01-16 10:59:27.880638: Epoch 231 
2025-01-16 10:59:27.885663: Current learning rate: 0.00098 
2025-01-16 11:00:08.619578: train_loss -0.8517 
2025-01-16 11:00:08.620091: val_loss -0.5495 
2025-01-16 11:00:08.625153: Pseudo dice [np.float32(0.778), np.float32(0.4509)] 
2025-01-16 11:00:08.628673: Epoch time: 40.74 s 
2025-01-16 11:00:09.144409:  
2025-01-16 11:00:09.145412: Epoch 232 
2025-01-16 11:00:09.150027: Current learning rate: 0.00094 
2025-01-16 11:00:49.876312: train_loss -0.845 
2025-01-16 11:00:49.876312: val_loss -0.5649 
2025-01-16 11:00:49.882398: Pseudo dice [np.float32(0.7991), np.float32(0.6185)] 
2025-01-16 11:00:49.884945: Epoch time: 40.73 s 
2025-01-16 11:00:50.402034:  
2025-01-16 11:00:50.402034: Epoch 233 
2025-01-16 11:00:50.407101: Current learning rate: 0.00089 
2025-01-16 11:01:31.103148: train_loss -0.8482 
2025-01-16 11:01:31.103656: val_loss -0.6223 
2025-01-16 11:01:31.109195: Pseudo dice [np.float32(0.829), np.float32(0.5532)] 
2025-01-16 11:01:31.111700: Epoch time: 40.7 s 
2025-01-16 11:01:31.653024:  
2025-01-16 11:01:31.653024: Epoch 234 
2025-01-16 11:01:31.658034: Current learning rate: 0.00084 
2025-01-16 11:02:12.372368: train_loss -0.8479 
2025-01-16 11:02:12.372368: val_loss -0.559 
2025-01-16 11:02:12.378443: Pseudo dice [np.float32(0.7936), np.float32(0.5605)] 
2025-01-16 11:02:12.381952: Epoch time: 40.72 s 
2025-01-16 11:02:12.904982:  
2025-01-16 11:02:12.904982: Epoch 235 
2025-01-16 11:02:12.910031: Current learning rate: 0.00079 
2025-01-16 11:02:53.632413: train_loss -0.8578 
2025-01-16 11:02:53.632413: val_loss -0.5787 
2025-01-16 11:02:53.637427: Pseudo dice [np.float32(0.8116), np.float32(0.6407)] 
2025-01-16 11:02:53.640932: Epoch time: 40.73 s 
2025-01-16 11:02:54.161368:  
2025-01-16 11:02:54.161872: Epoch 236 
2025-01-16 11:02:54.166912: Current learning rate: 0.00075 
2025-01-16 11:03:34.897114: train_loss -0.8549 
2025-01-16 11:03:34.897635: val_loss -0.5818 
2025-01-16 11:03:34.902295: Pseudo dice [np.float32(0.8049), np.float32(0.5673)] 
2025-01-16 11:03:34.905807: Epoch time: 40.74 s 
2025-01-16 11:03:35.424688:  
2025-01-16 11:03:35.424688: Epoch 237 
2025-01-16 11:03:35.429718: Current learning rate: 0.0007 
2025-01-16 11:04:16.167855: train_loss -0.8467 
2025-01-16 11:04:16.168857: val_loss -0.57 
2025-01-16 11:04:16.174402: Pseudo dice [np.float32(0.8099), np.float32(0.4419)] 
2025-01-16 11:04:16.176909: Epoch time: 40.74 s 
2025-01-16 11:04:16.693839:  
2025-01-16 11:04:16.693839: Epoch 238 
2025-01-16 11:04:16.699396: Current learning rate: 0.00065 
2025-01-16 11:04:57.445415: train_loss -0.8579 
2025-01-16 11:04:57.445922: val_loss -0.5949 
2025-01-16 11:04:57.451517: Pseudo dice [np.float32(0.8013), np.float32(0.5534)] 
2025-01-16 11:04:57.454534: Epoch time: 40.75 s 
2025-01-16 11:04:57.983712:  
2025-01-16 11:04:57.984216: Epoch 239 
2025-01-16 11:04:57.989229: Current learning rate: 0.0006 
2025-01-16 11:05:38.739056: train_loss -0.864 
2025-01-16 11:05:38.739558: val_loss -0.571 
2025-01-16 11:05:38.744569: Pseudo dice [np.float32(0.8119), np.float32(0.4615)] 
2025-01-16 11:05:38.747075: Epoch time: 40.76 s 
2025-01-16 11:05:39.415896:  
2025-01-16 11:05:39.416896: Epoch 240 
2025-01-16 11:05:39.421453: Current learning rate: 0.00055 
2025-01-16 11:06:20.164638: train_loss -0.856 
2025-01-16 11:06:20.165150: val_loss -0.5717 
2025-01-16 11:06:20.170735: Pseudo dice [np.float32(0.8096), np.float32(0.5021)] 
2025-01-16 11:06:20.173758: Epoch time: 40.75 s 
2025-01-16 11:06:20.699656:  
2025-01-16 11:06:20.700159: Epoch 241 
2025-01-16 11:06:20.705179: Current learning rate: 0.0005 
2025-01-16 11:07:01.453880: train_loss -0.8647 
2025-01-16 11:07:01.453880: val_loss -0.5904 
2025-01-16 11:07:01.461012: Pseudo dice [np.float32(0.796), np.float32(0.6402)] 
2025-01-16 11:07:01.464066: Epoch time: 40.76 s 
2025-01-16 11:07:01.996207:  
2025-01-16 11:07:01.996207: Epoch 242 
2025-01-16 11:07:02.001774: Current learning rate: 0.00045 
2025-01-16 11:07:42.729418: train_loss -0.8643 
2025-01-16 11:07:42.730418: val_loss -0.6128 
2025-01-16 11:07:42.735930: Pseudo dice [np.float32(0.8163), np.float32(0.6445)] 
2025-01-16 11:07:42.739438: Epoch time: 40.73 s 
2025-01-16 11:07:43.267733:  
2025-01-16 11:07:43.267733: Epoch 243 
2025-01-16 11:07:43.273283: Current learning rate: 0.0004 
2025-01-16 11:08:24.012012: train_loss -0.86 
2025-01-16 11:08:24.012513: val_loss -0.5482 
2025-01-16 11:08:24.018122: Pseudo dice [np.float32(0.7965), np.float32(0.4687)] 
2025-01-16 11:08:24.020656: Epoch time: 40.74 s 
2025-01-16 11:08:24.544909:  
2025-01-16 11:08:24.544909: Epoch 244 
2025-01-16 11:08:24.550523: Current learning rate: 0.00035 
2025-01-16 11:09:05.292240: train_loss -0.8554 
2025-01-16 11:09:05.292752: val_loss -0.5221 
2025-01-16 11:09:05.297862: Pseudo dice [np.float32(0.7791), np.float32(0.4754)] 
2025-01-16 11:09:05.301406: Epoch time: 40.75 s 
2025-01-16 11:09:05.827689:  
2025-01-16 11:09:05.828192: Epoch 245 
2025-01-16 11:09:05.833206: Current learning rate: 0.0003 
2025-01-16 11:09:46.586958: train_loss -0.8606 
2025-01-16 11:09:46.587959: val_loss -0.589 
2025-01-16 11:09:46.593472: Pseudo dice [np.float32(0.8142), np.float32(0.4879)] 
2025-01-16 11:09:46.596984: Epoch time: 40.76 s 
2025-01-16 11:09:47.128618:  
2025-01-16 11:09:47.128618: Epoch 246 
2025-01-16 11:09:47.133630: Current learning rate: 0.00024 
2025-01-16 11:10:27.897674: train_loss -0.8565 
2025-01-16 11:10:27.897674: val_loss -0.5423 
2025-01-16 11:10:27.903688: Pseudo dice [np.float32(0.8002), np.float32(0.5464)] 
2025-01-16 11:10:27.906196: Epoch time: 40.77 s 
2025-01-16 11:10:28.433288:  
2025-01-16 11:10:28.434292: Epoch 247 
2025-01-16 11:10:28.438807: Current learning rate: 0.00019 
2025-01-16 11:11:09.210164: train_loss -0.8634 
2025-01-16 11:11:09.210669: val_loss -0.5742 
2025-01-16 11:11:09.215679: Pseudo dice [np.float32(0.8048), np.float32(0.5839)] 
2025-01-16 11:11:09.219188: Epoch time: 40.78 s 
2025-01-16 11:11:09.891613:  
2025-01-16 11:11:09.891613: Epoch 248 
2025-01-16 11:11:09.896641: Current learning rate: 0.00013 
2025-01-16 11:11:50.653333: train_loss -0.8582 
2025-01-16 11:11:50.653844: val_loss -0.547 
2025-01-16 11:11:50.658914: Pseudo dice [np.float32(0.8072), np.float32(0.5569)] 
2025-01-16 11:11:50.662423: Epoch time: 40.76 s 
2025-01-16 11:11:51.190678:  
2025-01-16 11:11:51.191679: Epoch 249 
2025-01-16 11:11:51.196226: Current learning rate: 7e-05 
2025-01-16 11:12:31.963343: train_loss -0.8589 
2025-01-16 11:12:31.963850: val_loss -0.5908 
2025-01-16 11:12:31.968893: Pseudo dice [np.float32(0.8059), np.float32(0.6226)] 
2025-01-16 11:12:31.972939: Epoch time: 40.77 s 
2025-01-16 11:12:32.705993: Training done. 
2025-01-16 11:12:32.725995: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-16 11:12:32.731996: The split file contains 5 splits. 
2025-01-16 11:12:32.735997: Desired fold for training: 0 
2025-01-16 11:12:32.739997: This split has 224 training and 57 validation cases. 
2025-01-16 11:12:32.744996: predicting pancreas_021 
2025-01-16 11:12:32.749995: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-16 11:12:45.095053: predicting pancreas_024 
2025-01-16 11:12:45.110560: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-16 11:12:59.660184: predicting pancreas_035 
2025-01-16 11:12:59.675184: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-16 11:13:04.606244: predicting pancreas_040 
2025-01-16 11:13:04.613245: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-01-16 11:13:16.250402: predicting pancreas_042 
2025-01-16 11:13:16.263402: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-01-16 11:13:30.826935: predicting pancreas_056 
2025-01-16 11:13:30.843441: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-16 11:13:42.477484: predicting pancreas_067 
2025-01-16 11:13:42.488485: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-16 11:13:57.038349: predicting pancreas_075 
2025-01-16 11:13:57.053854: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-01-16 11:14:02.897351: predicting pancreas_086 
2025-01-16 11:14:02.905348: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-16 11:14:11.997440: predicting pancreas_089 
2025-01-16 11:14:12.007439: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-16 11:14:23.637741: predicting pancreas_092 
2025-01-16 11:14:23.649743: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-01-16 11:14:49.808859: predicting pancreas_094 
2025-01-16 11:14:49.833859: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-16 11:15:01.473270: predicting pancreas_095 
2025-01-16 11:15:01.481269: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-16 11:15:13.134077: predicting pancreas_098 
2025-01-16 11:15:13.143077: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-16 11:15:44.865351: predicting pancreas_109 
2025-01-16 11:15:44.891352: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-16 11:15:56.588862: predicting pancreas_110 
2025-01-16 11:15:56.605862: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-16 11:16:14.782846: predicting pancreas_114 
2025-01-16 11:16:14.801846: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-16 11:16:26.454153: predicting pancreas_119 
2025-01-16 11:16:26.464657: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-16 11:16:44.629692: predicting pancreas_138 
2025-01-16 11:16:44.644692: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-16 11:17:02.815801: predicting pancreas_145 
2025-01-16 11:17:02.833800: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-16 11:17:21.026405: predicting pancreas_148 
2025-01-16 11:17:21.043405: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-01-16 11:17:32.688432: predicting pancreas_169 
2025-01-16 11:17:32.700434: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-16 11:17:44.329390: predicting pancreas_170 
2025-01-16 11:17:44.339390: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-16 11:17:58.888546: predicting pancreas_172 
2025-01-16 11:17:58.903546: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-16 11:18:10.544284: predicting pancreas_175 
2025-01-16 11:18:10.556284: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-16 11:18:22.207392: predicting pancreas_180 
2025-01-16 11:18:22.220392: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-16 11:18:33.855057: predicting pancreas_191 
2025-01-16 11:18:33.866056: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-16 11:18:39.707039: predicting pancreas_193 
2025-01-16 11:18:39.715039: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-16 11:18:54.270049: predicting pancreas_212 
2025-01-16 11:18:54.284049: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-16 11:19:05.952679: predicting pancreas_215 
2025-01-16 11:19:05.968680: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-16 11:19:17.623094: predicting pancreas_222 
2025-01-16 11:19:17.635095: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-16 11:19:22.577785: predicting pancreas_235 
2025-01-16 11:19:22.586291: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-16 11:19:34.209014: predicting pancreas_241 
2025-01-16 11:19:34.220014: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-16 11:19:45.885394: predicting pancreas_242 
2025-01-16 11:19:45.899900: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-16 11:20:00.449976: predicting pancreas_244 
2025-01-16 11:20:00.468976: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-16 11:20:23.160019: predicting pancreas_246 
2025-01-16 11:20:23.178019: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-16 11:20:45.864577: predicting pancreas_247 
2025-01-16 11:20:45.883577: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-16 11:20:52.466485: predicting pancreas_264 
2025-01-16 11:20:52.476484: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-16 11:21:07.025064: predicting pancreas_265 
2025-01-16 11:21:07.042058: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-16 11:21:18.704743: predicting pancreas_266 
2025-01-16 11:21:18.716743: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-16 11:21:36.866380: predicting pancreas_267 
2025-01-16 11:21:36.883889: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-16 11:21:43.467569: predicting pancreas_275 
2025-01-16 11:21:43.479576: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-16 11:21:58.007692: predicting pancreas_279 
2025-01-16 11:21:58.020691: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-16 11:22:02.972352: predicting pancreas_287 
2025-01-16 11:22:02.983352: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-16 11:22:14.625394: predicting pancreas_301 
2025-01-16 11:22:14.638393: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-16 11:22:26.285905: predicting pancreas_323 
2025-01-16 11:22:26.298905: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-16 11:22:44.481877: predicting pancreas_336 
2025-01-16 11:22:44.500876: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-16 11:22:56.164468: predicting pancreas_344 
2025-01-16 11:22:56.180468: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-16 11:23:10.764982: predicting pancreas_351 
2025-01-16 11:23:10.779981: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-16 11:23:17.358761: predicting pancreas_354 
2025-01-16 11:23:17.368265: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-01-16 11:23:40.632602: predicting pancreas_372 
2025-01-16 11:23:40.655602: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-16 11:23:58.881285: predicting pancreas_377 
2025-01-16 11:23:58.899786: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-01-16 11:24:13.480422: predicting pancreas_387 
2025-01-16 11:24:13.494425: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-01-16 11:24:25.176604: predicting pancreas_391 
2025-01-16 11:24:25.191604: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-16 11:24:43.371609: predicting pancreas_392 
2025-01-16 11:24:43.389609: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-01-16 11:24:51.609308: predicting pancreas_410 
2025-01-16 11:24:51.621308: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-16 11:24:59.827411: predicting pancreas_412 
2025-01-16 11:24:59.839917: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-01-16 11:25:57.586657: Validation complete 
2025-01-16 11:25:57.587659: Mean Validation Dice:  0.3259045881500496 
