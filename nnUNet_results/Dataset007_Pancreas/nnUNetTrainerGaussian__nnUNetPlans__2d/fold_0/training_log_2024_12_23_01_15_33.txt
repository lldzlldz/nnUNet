
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-23 01:15:33.546334: do_dummy_2d_data_aug: False 
2024-12-23 01:15:33.549331: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-23 01:15:33.553434: The split file contains 5 splits. 
2024-12-23 01:15:33.556503: Desired fold for training: 0 
2024-12-23 01:15:33.559102: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2024-12-23 01:15:39.664546: unpacking dataset... 
2024-12-23 01:15:39.857776: unpacking done... 
2024-12-23 01:15:44.084930:  
2024-12-23 01:15:44.084930: Epoch 0 
2024-12-23 01:15:44.089466: Current learning rate: 0.01 
2024-12-23 01:16:19.637364: train_loss 0.0797 
2024-12-23 01:16:19.637364: val_loss 0.0087 
2024-12-23 01:16:19.642906: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-23 01:16:19.646412: Epoch time: 35.55 s 
2024-12-23 01:16:19.649475: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-23 01:16:20.459060:  
2024-12-23 01:16:20.459060: Epoch 1 
2024-12-23 01:16:20.464137: Current learning rate: 0.00991 
2024-12-23 01:16:52.766961: train_loss -0.0104 
2024-12-23 01:16:52.767467: val_loss -0.0667 
2024-12-23 01:16:52.772381: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-23 01:16:52.775668: Epoch time: 32.31 s 
2024-12-23 01:16:53.288923:  
2024-12-23 01:16:53.289425: Epoch 2 
2024-12-23 01:16:53.294436: Current learning rate: 0.00982 
2024-12-23 01:17:25.287993: train_loss -0.1975 
2024-12-23 01:17:25.287993: val_loss -0.2316 
2024-12-23 01:17:25.294510: Pseudo dice [np.float32(0.4878), np.float32(0.0)] 
2024-12-23 01:17:25.298020: Epoch time: 32.0 s 
2024-12-23 01:17:25.302028: Yayy! New best EMA pseudo Dice: 0.024399999529123306 
2024-12-23 01:17:26.090368:  
2024-12-23 01:17:26.090368: Epoch 3 
2024-12-23 01:17:26.095383: Current learning rate: 0.00973 
2024-12-23 01:17:58.073563: train_loss -0.2944 
2024-12-23 01:17:58.073563: val_loss -0.289 
2024-12-23 01:17:58.079300: Pseudo dice [np.float32(0.5607), np.float32(0.0)] 
2024-12-23 01:17:58.082561: Epoch time: 31.98 s 
2024-12-23 01:17:58.085117: Yayy! New best EMA pseudo Dice: 0.05000000074505806 
2024-12-23 01:17:58.853247:  
2024-12-23 01:17:58.853247: Epoch 4 
2024-12-23 01:17:58.858788: Current learning rate: 0.00964 
2024-12-23 01:18:30.842745: train_loss -0.3417 
2024-12-23 01:18:30.843249: val_loss -0.3403 
2024-12-23 01:18:30.848267: Pseudo dice [np.float32(0.613), np.float32(0.0)] 
2024-12-23 01:18:30.852787: Epoch time: 31.99 s 
2024-12-23 01:18:30.855794: Yayy! New best EMA pseudo Dice: 0.07559999823570251 
2024-12-23 01:18:31.771699:  
2024-12-23 01:18:31.771699: Epoch 5 
2024-12-23 01:18:31.776680: Current learning rate: 0.00955 
2024-12-23 01:19:03.759082: train_loss -0.3904 
2024-12-23 01:19:03.760087: val_loss -0.3955 
2024-12-23 01:19:03.765670: Pseudo dice [np.float32(0.671), np.float32(0.0)] 
2024-12-23 01:19:03.770920: Epoch time: 31.99 s 
2024-12-23 01:19:03.774544: Yayy! New best EMA pseudo Dice: 0.10159999877214432 
2024-12-23 01:19:04.537042:  
2024-12-23 01:19:04.537042: Epoch 6 
2024-12-23 01:19:04.542192: Current learning rate: 0.00946 
2024-12-23 01:19:36.532014: train_loss -0.4318 
2024-12-23 01:19:36.532518: val_loss -0.405 
2024-12-23 01:19:36.537615: Pseudo dice [np.float32(0.6242), np.float32(0.2807)] 
2024-12-23 01:19:36.541145: Epoch time: 32.0 s 
2024-12-23 01:19:36.543660: Yayy! New best EMA pseudo Dice: 0.13670000433921814 
2024-12-23 01:19:37.320141:  
2024-12-23 01:19:37.320141: Epoch 7 
2024-12-23 01:19:37.324835: Current learning rate: 0.00937 
2024-12-23 01:20:09.319525: train_loss -0.4717 
2024-12-23 01:20:09.320029: val_loss -0.4903 
2024-12-23 01:20:09.326050: Pseudo dice [np.float32(0.6196), np.float32(0.4443)] 
2024-12-23 01:20:09.329567: Epoch time: 32.0 s 
2024-12-23 01:20:09.332283: Yayy! New best EMA pseudo Dice: 0.1762000024318695 
2024-12-23 01:20:10.116223:  
2024-12-23 01:20:10.116223: Epoch 8 
2024-12-23 01:20:10.121273: Current learning rate: 0.00928 
2024-12-23 01:20:42.200225: train_loss -0.4883 
2024-12-23 01:20:42.205289: val_loss -0.4688 
2024-12-23 01:20:42.208401: Pseudo dice [np.float32(0.6232), np.float32(0.4218)] 
2024-12-23 01:20:42.213480: Epoch time: 32.09 s 
2024-12-23 01:20:42.216514: Yayy! New best EMA pseudo Dice: 0.21089999377727509 
2024-12-23 01:20:43.010636:  
2024-12-23 01:20:43.010636: Epoch 9 
2024-12-23 01:20:43.014666: Current learning rate: 0.00919 
2024-12-23 01:21:15.046896: train_loss -0.5108 
2024-12-23 01:21:15.047406: val_loss -0.4327 
2024-12-23 01:21:15.053422: Pseudo dice [np.float32(0.6225), np.float32(0.3369)] 
2024-12-23 01:21:15.057439: Epoch time: 32.04 s 
2024-12-23 01:21:15.060954: Yayy! New best EMA pseudo Dice: 0.23770000040531158 
2024-12-23 01:21:15.826936:  
2024-12-23 01:21:15.826936: Epoch 10 
2024-12-23 01:21:15.831953: Current learning rate: 0.0091 
2024-12-23 01:21:47.832382: train_loss -0.5027 
2024-12-23 01:21:47.833958: val_loss -0.476 
2024-12-23 01:21:47.839566: Pseudo dice [np.float32(0.6387), np.float32(0.3925)] 
2024-12-23 01:21:47.842597: Epoch time: 32.01 s 
2024-12-23 01:21:47.845635: Yayy! New best EMA pseudo Dice: 0.265500009059906 
2024-12-23 01:21:48.601828:  
2024-12-23 01:21:48.601828: Epoch 11 
2024-12-23 01:21:48.606904: Current learning rate: 0.009 
2024-12-23 01:22:20.832670: train_loss -0.5419 
2024-12-23 01:22:20.833174: val_loss -0.5051 
2024-12-23 01:22:20.838202: Pseudo dice [np.float32(0.6537), np.float32(0.4469)] 
2024-12-23 01:22:20.841221: Epoch time: 32.23 s 
2024-12-23 01:22:20.845257: Yayy! New best EMA pseudo Dice: 0.2939999997615814 
2024-12-23 01:22:21.781307:  
2024-12-23 01:22:21.781307: Epoch 12 
2024-12-23 01:22:21.784822: Current learning rate: 0.00891 
2024-12-23 01:22:53.789039: train_loss -0.5578 
2024-12-23 01:22:53.789544: val_loss -0.5218 
2024-12-23 01:22:53.795078: Pseudo dice [np.float32(0.6829), np.float32(0.4033)] 
2024-12-23 01:22:53.798097: Epoch time: 32.01 s 
2024-12-23 01:22:53.801615: Yayy! New best EMA pseudo Dice: 0.3188999891281128 
2024-12-23 01:22:54.565804:  
2024-12-23 01:22:54.566803: Epoch 13 
2024-12-23 01:22:54.571867: Current learning rate: 0.00882 
2024-12-23 01:23:26.563419: train_loss -0.5781 
2024-12-23 01:23:26.564420: val_loss -0.494 
2024-12-23 01:23:26.569937: Pseudo dice [np.float32(0.6526), np.float32(0.3896)] 
2024-12-23 01:23:26.573446: Epoch time: 32.0 s 
2024-12-23 01:23:26.576999: Yayy! New best EMA pseudo Dice: 0.3391000032424927 
2024-12-23 01:23:27.355861:  
2024-12-23 01:23:27.356864: Epoch 14 
2024-12-23 01:23:27.361424: Current learning rate: 0.00873 
2024-12-23 01:23:59.356119: train_loss -0.5774 
2024-12-23 01:23:59.357118: val_loss -0.5136 
2024-12-23 01:23:59.363645: Pseudo dice [np.float32(0.651), np.float32(0.4301)] 
2024-12-23 01:23:59.366149: Epoch time: 32.0 s 
2024-12-23 01:23:59.369657: Yayy! New best EMA pseudo Dice: 0.35929998755455017 
2024-12-23 01:24:00.146551:  
2024-12-23 01:24:00.146551: Epoch 15 
2024-12-23 01:24:00.152123: Current learning rate: 0.00864 
2024-12-23 01:24:32.351328: train_loss -0.5722 
2024-12-23 01:24:32.351328: val_loss -0.4713 
2024-12-23 01:24:32.356899: Pseudo dice [np.float32(0.6482), np.float32(0.3619)] 
2024-12-23 01:24:32.359427: Epoch time: 32.21 s 
2024-12-23 01:24:32.362468: Yayy! New best EMA pseudo Dice: 0.37380000948905945 
2024-12-23 01:24:33.195773:  
2024-12-23 01:24:33.195773: Epoch 16 
2024-12-23 01:24:33.200830: Current learning rate: 0.00855 
2024-12-23 01:25:05.458409: train_loss -0.5918 
2024-12-23 01:25:05.458911: val_loss -0.5091 
2024-12-23 01:25:05.465170: Pseudo dice [np.float32(0.6739), np.float32(0.4218)] 
2024-12-23 01:25:05.468421: Epoch time: 32.26 s 
2024-12-23 01:25:05.472430: Yayy! New best EMA pseudo Dice: 0.3912999927997589 
2024-12-23 01:25:06.300013:  
2024-12-23 01:25:06.300013: Epoch 17 
2024-12-23 01:25:06.305062: Current learning rate: 0.00846 
2024-12-23 01:25:38.674778: train_loss -0.6201 
2024-12-23 01:25:38.675280: val_loss -0.4767 
2024-12-23 01:25:38.681297: Pseudo dice [np.float32(0.6264), np.float32(0.4029)] 
2024-12-23 01:25:38.685341: Epoch time: 32.38 s 
2024-12-23 01:25:38.687653: Yayy! New best EMA pseudo Dice: 0.4036000072956085 
2024-12-23 01:25:39.521466:  
2024-12-23 01:25:39.521466: Epoch 18 
2024-12-23 01:25:39.526481: Current learning rate: 0.00836 
2024-12-23 01:26:11.656196: train_loss -0.5796 
2024-12-23 01:26:11.656196: val_loss -0.4881 
2024-12-23 01:26:11.662235: Pseudo dice [np.float32(0.6744), np.float32(0.3726)] 
2024-12-23 01:26:11.664754: Epoch time: 32.14 s 
2024-12-23 01:26:11.668375: Yayy! New best EMA pseudo Dice: 0.4156000018119812 
2024-12-23 01:26:12.486344:  
2024-12-23 01:26:12.486344: Epoch 19 
2024-12-23 01:26:12.491899: Current learning rate: 0.00827 
2024-12-23 01:26:45.222450: train_loss -0.5759 
2024-12-23 01:26:45.222450: val_loss -0.5313 
2024-12-23 01:26:45.228974: Pseudo dice [np.float32(0.6786), np.float32(0.4646)] 
2024-12-23 01:26:45.232482: Epoch time: 32.74 s 
2024-12-23 01:26:45.234989: Yayy! New best EMA pseudo Dice: 0.4311999976634979 
2024-12-23 01:26:46.221214:  
2024-12-23 01:26:46.222218: Epoch 20 
2024-12-23 01:26:46.226767: Current learning rate: 0.00818 
2024-12-23 01:27:19.286460: train_loss -0.6146 
2024-12-23 01:27:19.287464: val_loss -0.5305 
2024-12-23 01:27:19.292491: Pseudo dice [np.float32(0.6857), np.float32(0.4697)] 
2024-12-23 01:27:19.294998: Epoch time: 33.07 s 
2024-12-23 01:27:19.299006: Yayy! New best EMA pseudo Dice: 0.4458000063896179 
2024-12-23 01:27:20.156395:  
2024-12-23 01:27:20.157398: Epoch 21 
2024-12-23 01:27:20.162513: Current learning rate: 0.00809 
2024-12-23 01:27:52.641965: train_loss -0.615 
2024-12-23 01:27:52.643469: val_loss -0.5172 
2024-12-23 01:27:52.649485: Pseudo dice [np.float32(0.6568), np.float32(0.4525)] 
2024-12-23 01:27:52.652991: Epoch time: 32.49 s 
2024-12-23 01:27:52.655998: Yayy! New best EMA pseudo Dice: 0.45669999718666077 
2024-12-23 01:27:53.473029:  
2024-12-23 01:27:53.473029: Epoch 22 
2024-12-23 01:27:53.478590: Current learning rate: 0.008 
2024-12-23 01:28:26.196335: train_loss -0.603 
2024-12-23 01:28:26.196335: val_loss -0.4902 
2024-12-23 01:28:26.201347: Pseudo dice [np.float32(0.6883), np.float32(0.3627)] 
2024-12-23 01:28:26.204856: Epoch time: 32.72 s 
2024-12-23 01:28:26.208864: Yayy! New best EMA pseudo Dice: 0.4636000096797943 
2024-12-23 01:28:27.024193:  
2024-12-23 01:28:27.024193: Epoch 23 
2024-12-23 01:28:27.029777: Current learning rate: 0.0079 
2024-12-23 01:28:59.972019: train_loss -0.6201 
2024-12-23 01:28:59.972529: val_loss -0.438 
2024-12-23 01:28:59.980099: Pseudo dice [np.float32(0.6869), np.float32(0.2908)] 
2024-12-23 01:28:59.984133: Epoch time: 32.95 s 
2024-12-23 01:28:59.987686: Yayy! New best EMA pseudo Dice: 0.4661000072956085 
2024-12-23 01:29:00.775615:  
2024-12-23 01:29:00.776118: Epoch 24 
2024-12-23 01:29:00.781127: Current learning rate: 0.00781 
2024-12-23 01:29:33.778903: train_loss -0.6466 
2024-12-23 01:29:33.779909: val_loss -0.4911 
2024-12-23 01:29:33.785127: Pseudo dice [np.float32(0.689), np.float32(0.371)] 
2024-12-23 01:29:33.788775: Epoch time: 33.0 s 
2024-12-23 01:29:33.792301: Yayy! New best EMA pseudo Dice: 0.4724999964237213 
2024-12-23 01:29:34.599424:  
2024-12-23 01:29:34.599424: Epoch 25 
2024-12-23 01:29:34.604960: Current learning rate: 0.00772 
2024-12-23 01:30:07.283992: train_loss -0.6714 
2024-12-23 01:30:07.284512: val_loss -0.4472 
2024-12-23 01:30:07.292033: Pseudo dice [np.float32(0.7043), np.float32(0.2895)] 
2024-12-23 01:30:07.295543: Epoch time: 32.69 s 
2024-12-23 01:30:07.299047: Yayy! New best EMA pseudo Dice: 0.4749000072479248 
2024-12-23 01:30:08.095899:  
2024-12-23 01:30:08.096903: Epoch 26 
2024-12-23 01:30:08.101456: Current learning rate: 0.00763 
2024-12-23 01:30:41.092700: train_loss -0.657 
2024-12-23 01:30:41.093205: val_loss -0.5468 
2024-12-23 01:30:41.098744: Pseudo dice [np.float32(0.6763), np.float32(0.5095)] 
2024-12-23 01:30:41.103276: Epoch time: 33.0 s 
2024-12-23 01:30:41.105829: Yayy! New best EMA pseudo Dice: 0.48669999837875366 
2024-12-23 01:30:42.040326:  
2024-12-23 01:30:42.040828: Epoch 27 
2024-12-23 01:30:42.045840: Current learning rate: 0.00753 
2024-12-23 01:31:15.047839: train_loss -0.6561 
2024-12-23 01:31:15.048840: val_loss -0.5166 
2024-12-23 01:31:15.055366: Pseudo dice [np.float32(0.6707), np.float32(0.4719)] 
2024-12-23 01:31:15.059673: Epoch time: 33.01 s 
2024-12-23 01:31:15.064686: Yayy! New best EMA pseudo Dice: 0.4952000081539154 
2024-12-23 01:31:15.882554:  
2024-12-23 01:31:15.883559: Epoch 28 
2024-12-23 01:31:15.888129: Current learning rate: 0.00744 
2024-12-23 01:31:48.734745: train_loss -0.6541 
2024-12-23 01:31:48.735260: val_loss -0.5209 
2024-12-23 01:31:48.741848: Pseudo dice [np.float32(0.6662), np.float32(0.4719)] 
2024-12-23 01:31:48.746453: Epoch time: 32.85 s 
2024-12-23 01:31:48.749485: Yayy! New best EMA pseudo Dice: 0.5026000142097473 
2024-12-23 01:31:49.560854:  
2024-12-23 01:31:49.560854: Epoch 29 
2024-12-23 01:31:49.566401: Current learning rate: 0.00735 
2024-12-23 01:32:22.401835: train_loss -0.6536 
2024-12-23 01:32:22.402348: val_loss -0.5103 
2024-12-23 01:32:22.406906: Pseudo dice [np.float32(0.7016), np.float32(0.3843)] 
2024-12-23 01:32:22.411488: Epoch time: 32.84 s 
2024-12-23 01:32:22.414511: Yayy! New best EMA pseudo Dice: 0.506600022315979 
2024-12-23 01:32:23.236222:  
2024-12-23 01:32:23.236726: Epoch 30 
2024-12-23 01:32:23.241743: Current learning rate: 0.00725 
2024-12-23 01:32:56.188666: train_loss -0.6648 
2024-12-23 01:32:56.189669: val_loss -0.529 
2024-12-23 01:32:56.195867: Pseudo dice [np.float32(0.6907), np.float32(0.422)] 
2024-12-23 01:32:56.199929: Epoch time: 32.95 s 
2024-12-23 01:32:56.203906: Yayy! New best EMA pseudo Dice: 0.5116000175476074 
2024-12-23 01:32:57.017778:  
2024-12-23 01:32:57.017778: Epoch 31 
2024-12-23 01:32:57.023377: Current learning rate: 0.00716 
2024-12-23 01:33:29.431112: train_loss -0.6925 
2024-12-23 01:33:29.432741: val_loss -0.4444 
2024-12-23 01:33:29.437760: Pseudo dice [np.float32(0.6697), np.float32(0.2767)] 
2024-12-23 01:33:29.441273: Epoch time: 32.41 s 
2024-12-23 01:33:29.964053:  
2024-12-23 01:33:29.965057: Epoch 32 
2024-12-23 01:33:29.969593: Current learning rate: 0.00707 
2024-12-23 01:34:02.688914: train_loss -0.699 
2024-12-23 01:34:02.689423: val_loss -0.5448 
2024-12-23 01:34:02.695519: Pseudo dice [np.float32(0.7164), np.float32(0.4958)] 
2024-12-23 01:34:02.698605: Epoch time: 32.73 s 
2024-12-23 01:34:02.702203: Yayy! New best EMA pseudo Dice: 0.5175999999046326 
2024-12-23 01:34:03.516014:  
2024-12-23 01:34:03.516014: Epoch 33 
2024-12-23 01:34:03.522028: Current learning rate: 0.00697 
2024-12-23 01:34:36.061845: train_loss -0.6948 
2024-12-23 01:34:36.061845: val_loss -0.518 
2024-12-23 01:34:36.067496: Pseudo dice [np.float32(0.715), np.float32(0.3684)] 
2024-12-23 01:34:36.071025: Epoch time: 32.55 s 
2024-12-23 01:34:36.074773: Yayy! New best EMA pseudo Dice: 0.5199999809265137 
2024-12-23 01:34:36.886188:  
2024-12-23 01:34:36.887188: Epoch 34 
2024-12-23 01:34:36.892262: Current learning rate: 0.00688 
2024-12-23 01:35:09.657041: train_loss -0.7 
2024-12-23 01:35:09.658625: val_loss -0.5399 
2024-12-23 01:35:09.665026: Pseudo dice [np.float32(0.7064), np.float32(0.4341)] 
2024-12-23 01:35:09.667562: Epoch time: 32.77 s 
2024-12-23 01:35:09.671623: Yayy! New best EMA pseudo Dice: 0.5249999761581421 
2024-12-23 01:35:10.624099:  
2024-12-23 01:35:10.624099: Epoch 35 
2024-12-23 01:35:10.629112: Current learning rate: 0.00679 
2024-12-23 01:35:43.147483: train_loss -0.6901 
2024-12-23 01:35:43.148489: val_loss -0.5579 
2024-12-23 01:35:43.154053: Pseudo dice [np.float32(0.7011), np.float32(0.4609)] 
2024-12-23 01:35:43.158218: Epoch time: 32.52 s 
2024-12-23 01:35:43.161726: Yayy! New best EMA pseudo Dice: 0.5306000113487244 
2024-12-23 01:35:43.992567:  
2024-12-23 01:35:43.993571: Epoch 36 
2024-12-23 01:35:43.998125: Current learning rate: 0.00669 
2024-12-23 01:36:16.922200: train_loss -0.6925 
2024-12-23 01:36:16.923202: val_loss -0.5414 
2024-12-23 01:36:16.928299: Pseudo dice [np.float32(0.6845), np.float32(0.4376)] 
2024-12-23 01:36:16.932350: Epoch time: 32.93 s 
2024-12-23 01:36:16.936888: Yayy! New best EMA pseudo Dice: 0.5336999893188477 
2024-12-23 01:36:17.762737:  
2024-12-23 01:36:17.762737: Epoch 37 
2024-12-23 01:36:17.768467: Current learning rate: 0.0066 
2024-12-23 01:36:50.609474: train_loss -0.6995 
2024-12-23 01:36:50.610473: val_loss -0.5346 
2024-12-23 01:36:50.617041: Pseudo dice [np.float32(0.7112), np.float32(0.4287)] 
2024-12-23 01:36:50.621053: Epoch time: 32.85 s 
2024-12-23 01:36:50.623558: Yayy! New best EMA pseudo Dice: 0.5372999906539917 
2024-12-23 01:36:51.443697:  
2024-12-23 01:36:51.443697: Epoch 38 
2024-12-23 01:36:51.448743: Current learning rate: 0.0065 
2024-12-23 01:37:24.319909: train_loss -0.7112 
2024-12-23 01:37:24.320412: val_loss -0.5142 
2024-12-23 01:37:24.325427: Pseudo dice [np.float32(0.7027), np.float32(0.425)] 
2024-12-23 01:37:24.330441: Epoch time: 32.88 s 
2024-12-23 01:37:24.333949: Yayy! New best EMA pseudo Dice: 0.5400000214576721 
2024-12-23 01:37:25.163556:  
2024-12-23 01:37:25.164555: Epoch 39 
2024-12-23 01:37:25.169631: Current learning rate: 0.00641 
2024-12-23 01:37:57.808621: train_loss -0.7357 
2024-12-23 01:37:57.808621: val_loss -0.4994 
2024-12-23 01:37:57.814646: Pseudo dice [np.float32(0.697), np.float32(0.3772)] 
2024-12-23 01:37:57.818690: Epoch time: 32.65 s 
2024-12-23 01:37:58.365460:  
2024-12-23 01:37:58.365460: Epoch 40 
2024-12-23 01:37:58.371018: Current learning rate: 0.00631 
2024-12-23 01:38:31.378838: train_loss -0.7352 
2024-12-23 01:38:31.378838: val_loss -0.5057 
2024-12-23 01:38:31.384990: Pseudo dice [np.float32(0.7156), np.float32(0.3562)] 
2024-12-23 01:38:31.388045: Epoch time: 33.01 s 
2024-12-23 01:38:31.938677:  
2024-12-23 01:38:31.939179: Epoch 41 
2024-12-23 01:38:31.944222: Current learning rate: 0.00622 
2024-12-23 01:39:04.780588: train_loss -0.7238 
2024-12-23 01:39:04.781090: val_loss -0.5328 
2024-12-23 01:39:04.786208: Pseudo dice [np.float32(0.675), np.float32(0.4724)] 
2024-12-23 01:39:04.788222: Epoch time: 32.84 s 
2024-12-23 01:39:04.792760: Yayy! New best EMA pseudo Dice: 0.5426999926567078 
2024-12-23 01:39:05.728284:  
2024-12-23 01:39:05.728284: Epoch 42 
2024-12-23 01:39:05.733871: Current learning rate: 0.00612 
2024-12-23 01:39:38.420462: train_loss -0.7127 
2024-12-23 01:39:38.420462: val_loss -0.5296 
2024-12-23 01:39:38.426155: Pseudo dice [np.float32(0.7112), np.float32(0.3992)] 
2024-12-23 01:39:38.429188: Epoch time: 32.69 s 
2024-12-23 01:39:38.433775: Yayy! New best EMA pseudo Dice: 0.5440000295639038 
2024-12-23 01:39:39.235096:  
2024-12-23 01:39:39.236597: Epoch 43 
2024-12-23 01:39:39.241608: Current learning rate: 0.00603 
2024-12-23 01:40:11.833871: train_loss -0.7146 
2024-12-23 01:40:11.834383: val_loss -0.5347 
2024-12-23 01:40:11.839948: Pseudo dice [np.float32(0.7142), np.float32(0.3948)] 
2024-12-23 01:40:11.844571: Epoch time: 32.6 s 
2024-12-23 01:40:11.847616: Yayy! New best EMA pseudo Dice: 0.5450000166893005 
2024-12-23 01:40:12.656082:  
2024-12-23 01:40:12.657081: Epoch 44 
2024-12-23 01:40:12.662149: Current learning rate: 0.00593 
2024-12-23 01:40:45.466128: train_loss -0.7455 
2024-12-23 01:40:45.467127: val_loss -0.4796 
2024-12-23 01:40:45.474196: Pseudo dice [np.float32(0.6911), np.float32(0.3309)] 
2024-12-23 01:40:45.477903: Epoch time: 32.81 s 
2024-12-23 01:40:45.991363:  
2024-12-23 01:40:45.992366: Epoch 45 
2024-12-23 01:40:45.997390: Current learning rate: 0.00584 
2024-12-23 01:41:18.489313: train_loss -0.7337 
2024-12-23 01:41:18.489313: val_loss -0.5308 
2024-12-23 01:41:18.494917: Pseudo dice [np.float32(0.6905), np.float32(0.4185)] 
2024-12-23 01:41:18.498453: Epoch time: 32.5 s 
2024-12-23 01:41:19.009144:  
2024-12-23 01:41:19.009144: Epoch 46 
2024-12-23 01:41:19.015194: Current learning rate: 0.00574 
2024-12-23 01:41:51.606297: train_loss -0.728 
2024-12-23 01:41:51.607800: val_loss -0.5058 
2024-12-23 01:41:51.614341: Pseudo dice [np.float32(0.6952), np.float32(0.3954)] 
2024-12-23 01:41:51.618432: Epoch time: 32.6 s 
2024-12-23 01:41:52.236545:  
2024-12-23 01:41:52.237544: Epoch 47 
2024-12-23 01:41:52.243064: Current learning rate: 0.00565 
2024-12-23 01:42:24.919468: train_loss -0.7591 
2024-12-23 01:42:24.920474: val_loss -0.4986 
2024-12-23 01:42:24.925237: Pseudo dice [np.float32(0.7041), np.float32(0.3548)] 
2024-12-23 01:42:24.930110: Epoch time: 32.68 s 
2024-12-23 01:42:25.438943:  
2024-12-23 01:42:25.438943: Epoch 48 
2024-12-23 01:42:25.444466: Current learning rate: 0.00555 
2024-12-23 01:42:57.917212: train_loss -0.7619 
2024-12-23 01:42:57.918722: val_loss -0.5236 
2024-12-23 01:42:57.924840: Pseudo dice [np.float32(0.7315), np.float32(0.3812)] 
2024-12-23 01:42:57.928914: Epoch time: 32.48 s 
2024-12-23 01:42:58.445065:  
2024-12-23 01:42:58.445065: Epoch 49 
2024-12-23 01:42:58.450585: Current learning rate: 0.00546 
2024-12-23 01:43:30.898186: train_loss -0.7506 
2024-12-23 01:43:30.898186: val_loss -0.5608 
2024-12-23 01:43:30.903290: Pseudo dice [np.float32(0.731), np.float32(0.4761)] 
2024-12-23 01:43:30.907326: Epoch time: 32.45 s 
2024-12-23 01:43:31.124262: Yayy! New best EMA pseudo Dice: 0.5493000149726868 
2024-12-23 01:43:32.144966:  
2024-12-23 01:43:32.145970: Epoch 50 
2024-12-23 01:43:32.151000: Current learning rate: 0.00536 
2024-12-23 01:44:04.520309: train_loss -0.767 
2024-12-23 01:44:04.520814: val_loss -0.5131 
2024-12-23 01:44:04.526836: Pseudo dice [np.float32(0.7144), np.float32(0.376)] 
2024-12-23 01:44:04.530844: Epoch time: 32.38 s 
2024-12-23 01:44:05.050927:  
2024-12-23 01:44:05.051432: Epoch 51 
2024-12-23 01:44:05.056443: Current learning rate: 0.00526 
2024-12-23 01:44:38.029403: train_loss -0.7825 
2024-12-23 01:44:38.030407: val_loss -0.5274 
2024-12-23 01:44:38.036036: Pseudo dice [np.float32(0.7364), np.float32(0.3872)] 
2024-12-23 01:44:38.042048: Epoch time: 32.98 s 
2024-12-23 01:44:38.045057: Yayy! New best EMA pseudo Dice: 0.5501999855041504 
2024-12-23 01:44:38.855480:  
2024-12-23 01:44:38.855480: Epoch 52 
2024-12-23 01:44:38.860530: Current learning rate: 0.00517 
2024-12-23 01:45:11.691751: train_loss -0.7913 
2024-12-23 01:45:11.691751: val_loss -0.5054 
2024-12-23 01:45:11.698839: Pseudo dice [np.float32(0.7223), np.float32(0.3879)] 
2024-12-23 01:45:11.702355: Epoch time: 32.84 s 
2024-12-23 01:45:11.706369: Yayy! New best EMA pseudo Dice: 0.5507000088691711 
2024-12-23 01:45:12.512343:  
2024-12-23 01:45:12.512343: Epoch 53 
2024-12-23 01:45:12.517362: Current learning rate: 0.00507 
2024-12-23 01:45:44.936805: train_loss -0.7825 
2024-12-23 01:45:44.937307: val_loss -0.5214 
2024-12-23 01:45:44.943940: Pseudo dice [np.float32(0.7204), np.float32(0.3907)] 
2024-12-23 01:45:44.947488: Epoch time: 32.43 s 
2024-12-23 01:45:44.950562: Yayy! New best EMA pseudo Dice: 0.5511000156402588 
2024-12-23 01:45:45.758459:  
2024-12-23 01:45:45.758459: Epoch 54 
2024-12-23 01:45:45.763481: Current learning rate: 0.00497 
2024-12-23 01:46:18.622755: train_loss -0.7801 
2024-12-23 01:46:18.622755: val_loss -0.4916 
2024-12-23 01:46:18.628905: Pseudo dice [np.float32(0.7109), np.float32(0.3442)] 
2024-12-23 01:46:18.632468: Epoch time: 32.86 s 
2024-12-23 01:46:19.153251:  
2024-12-23 01:46:19.154252: Epoch 55 
2024-12-23 01:46:19.158798: Current learning rate: 0.00487 
2024-12-23 01:46:52.009013: train_loss -0.7861 
2024-12-23 01:46:52.010016: val_loss -0.5076 
2024-12-23 01:46:52.016558: Pseudo dice [np.float32(0.7209), np.float32(0.3829)] 
2024-12-23 01:46:52.021093: Epoch time: 32.86 s 
2024-12-23 01:46:52.562360:  
2024-12-23 01:46:52.562360: Epoch 56 
2024-12-23 01:46:52.565964: Current learning rate: 0.00478 
2024-12-23 01:47:25.366031: train_loss -0.7932 
2024-12-23 01:47:25.366031: val_loss -0.5154 
2024-12-23 01:47:25.372011: Pseudo dice [np.float32(0.7169), np.float32(0.375)] 
2024-12-23 01:47:25.376023: Epoch time: 32.8 s 
2024-12-23 01:47:25.888826:  
2024-12-23 01:47:25.889833: Epoch 57 
2024-12-23 01:47:25.894906: Current learning rate: 0.00468 
2024-12-23 01:47:58.250124: train_loss -0.7794 
2024-12-23 01:47:58.250124: val_loss -0.5281 
2024-12-23 01:47:58.257210: Pseudo dice [np.float32(0.6785), np.float32(0.4243)] 
2024-12-23 01:47:58.260288: Epoch time: 32.36 s 
2024-12-23 01:47:58.781248:  
2024-12-23 01:47:58.781248: Epoch 58 
2024-12-23 01:47:58.786765: Current learning rate: 0.00458 
2024-12-23 01:48:32.214573: train_loss -0.7813 
2024-12-23 01:48:32.215075: val_loss -0.4622 
2024-12-23 01:48:32.221090: Pseudo dice [np.float32(0.699), np.float32(0.3004)] 
2024-12-23 01:48:32.225112: Epoch time: 33.43 s 
2024-12-23 01:48:32.750972:  
2024-12-23 01:48:32.750972: Epoch 59 
2024-12-23 01:48:32.756542: Current learning rate: 0.00448 
2024-12-23 01:49:04.775090: train_loss -0.7976 
2024-12-23 01:49:04.775600: val_loss -0.5033 
2024-12-23 01:49:04.782614: Pseudo dice [np.float32(0.729), np.float32(0.3576)] 
2024-12-23 01:49:04.786635: Epoch time: 32.02 s 
2024-12-23 01:49:05.315315:  
2024-12-23 01:49:05.315315: Epoch 60 
2024-12-23 01:49:05.321831: Current learning rate: 0.00438 
2024-12-23 01:49:37.312164: train_loss -0.7953 
2024-12-23 01:49:37.312666: val_loss -0.5338 
2024-12-23 01:49:37.318689: Pseudo dice [np.float32(0.7197), np.float32(0.4134)] 
2024-12-23 01:49:37.322279: Epoch time: 32.0 s 
2024-12-23 01:49:37.864830:  
2024-12-23 01:49:37.864830: Epoch 61 
2024-12-23 01:49:37.870450: Current learning rate: 0.00429 
2024-12-23 01:50:09.832383: train_loss -0.7985 
2024-12-23 01:50:09.833905: val_loss -0.5584 
2024-12-23 01:50:09.839456: Pseudo dice [np.float32(0.7207), np.float32(0.5263)] 
2024-12-23 01:50:09.843471: Epoch time: 31.97 s 
2024-12-23 01:50:09.846998: Yayy! New best EMA pseudo Dice: 0.5540000200271606 
2024-12-23 01:50:10.655644:  
2024-12-23 01:50:10.655644: Epoch 62 
2024-12-23 01:50:10.660692: Current learning rate: 0.00419 
2024-12-23 01:50:42.620898: train_loss -0.7984 
2024-12-23 01:50:42.620898: val_loss -0.4731 
2024-12-23 01:50:42.626916: Pseudo dice [np.float32(0.7115), np.float32(0.305)] 
2024-12-23 01:50:42.631940: Epoch time: 31.97 s 
2024-12-23 01:50:43.175262:  
2024-12-23 01:50:43.176262: Epoch 63 
2024-12-23 01:50:43.181396: Current learning rate: 0.00409 
2024-12-23 01:51:15.155234: train_loss -0.8163 
2024-12-23 01:51:15.155736: val_loss -0.5304 
2024-12-23 01:51:15.161767: Pseudo dice [np.float32(0.6995), np.float32(0.4481)] 
2024-12-23 01:51:15.165837: Epoch time: 31.98 s 
2024-12-23 01:51:15.707824:  
2024-12-23 01:51:15.707824: Epoch 64 
2024-12-23 01:51:15.713347: Current learning rate: 0.00399 
2024-12-23 01:51:47.673355: train_loss -0.8049 
2024-12-23 01:51:47.674360: val_loss -0.4834 
2024-12-23 01:51:47.681868: Pseudo dice [np.float32(0.7164), np.float32(0.2883)] 
2024-12-23 01:51:47.684913: Epoch time: 31.97 s 
2024-12-23 01:51:48.227006:  
2024-12-23 01:51:48.227006: Epoch 65 
2024-12-23 01:51:48.232529: Current learning rate: 0.00389 
2024-12-23 01:52:20.190756: train_loss -0.794 
2024-12-23 01:52:20.191757: val_loss -0.5429 
2024-12-23 01:52:20.197274: Pseudo dice [np.float32(0.7278), np.float32(0.4466)] 
2024-12-23 01:52:20.201784: Epoch time: 31.96 s 
2024-12-23 01:52:20.983676:  
2024-12-23 01:52:20.984676: Epoch 66 
2024-12-23 01:52:20.989738: Current learning rate: 0.00379 
2024-12-23 01:52:52.969228: train_loss -0.7935 
2024-12-23 01:52:52.969228: val_loss -0.5049 
2024-12-23 01:52:52.976822: Pseudo dice [np.float32(0.7142), np.float32(0.3564)] 
2024-12-23 01:52:52.980354: Epoch time: 31.99 s 
2024-12-23 01:52:53.519972:  
2024-12-23 01:52:53.519972: Epoch 67 
2024-12-23 01:52:53.525037: Current learning rate: 0.00369 
2024-12-23 01:53:25.494101: train_loss -0.8058 
2024-12-23 01:53:25.495104: val_loss -0.5247 
2024-12-23 01:53:25.500624: Pseudo dice [np.float32(0.7163), np.float32(0.4058)] 
2024-12-23 01:53:25.505195: Epoch time: 31.98 s 
2024-12-23 01:53:26.047890:  
2024-12-23 01:53:26.049394: Epoch 68 
2024-12-23 01:53:26.054410: Current learning rate: 0.00359 
2024-12-23 01:53:58.305027: train_loss -0.8104 
2024-12-23 01:53:58.305027: val_loss -0.4971 
2024-12-23 01:53:58.311779: Pseudo dice [np.float32(0.6935), np.float32(0.3794)] 
2024-12-23 01:53:58.315837: Epoch time: 32.26 s 
2024-12-23 01:53:58.862472:  
2024-12-23 01:53:58.862975: Epoch 69 
2024-12-23 01:53:58.867988: Current learning rate: 0.00349 
2024-12-23 01:54:30.842550: train_loss -0.8121 
2024-12-23 01:54:30.843554: val_loss -0.5563 
2024-12-23 01:54:30.848425: Pseudo dice [np.float32(0.7161), np.float32(0.4325)] 
2024-12-23 01:54:30.854107: Epoch time: 31.98 s 
2024-12-23 01:54:31.399568:  
2024-12-23 01:54:31.400073: Epoch 70 
2024-12-23 01:54:31.405119: Current learning rate: 0.00338 
2024-12-23 01:55:03.384000: train_loss -0.8185 
2024-12-23 01:55:03.384000: val_loss -0.4857 
2024-12-23 01:55:03.391596: Pseudo dice [np.float32(0.719), np.float32(0.3087)] 
2024-12-23 01:55:03.395638: Epoch time: 31.98 s 
2024-12-23 01:55:03.938592:  
2024-12-23 01:55:03.939594: Epoch 71 
2024-12-23 01:55:03.946117: Current learning rate: 0.00328 
2024-12-23 01:55:35.920434: train_loss -0.8284 
2024-12-23 01:55:35.921434: val_loss -0.5351 
2024-12-23 01:55:35.926949: Pseudo dice [np.float32(0.7391), np.float32(0.4064)] 
2024-12-23 01:55:35.930460: Epoch time: 31.98 s 
2024-12-23 01:55:36.481407:  
2024-12-23 01:55:36.481407: Epoch 72 
2024-12-23 01:55:36.486492: Current learning rate: 0.00318 
2024-12-23 01:56:08.456076: train_loss -0.8219 
2024-12-23 01:56:08.456581: val_loss -0.4969 
2024-12-23 01:56:08.462157: Pseudo dice [np.float32(0.7254), np.float32(0.3519)] 
2024-12-23 01:56:08.466708: Epoch time: 31.98 s 
2024-12-23 01:56:09.013007:  
2024-12-23 01:56:09.014007: Epoch 73 
2024-12-23 01:56:09.019067: Current learning rate: 0.00308 
2024-12-23 01:56:40.980007: train_loss -0.8272 
2024-12-23 01:56:40.981544: val_loss -0.4817 
2024-12-23 01:56:40.987655: Pseudo dice [np.float32(0.7413), np.float32(0.3141)] 
2024-12-23 01:56:40.991185: Epoch time: 31.97 s 
2024-12-23 01:56:41.689367:  
2024-12-23 01:56:41.689367: Epoch 74 
2024-12-23 01:56:41.694926: Current learning rate: 0.00297 
2024-12-23 01:57:13.670134: train_loss -0.8237 
2024-12-23 01:57:13.670637: val_loss -0.5212 
2024-12-23 01:57:13.675685: Pseudo dice [np.float32(0.7351), np.float32(0.3772)] 
2024-12-23 01:57:13.679816: Epoch time: 31.98 s 
2024-12-23 01:57:14.220259:  
2024-12-23 01:57:14.221268: Epoch 75 
2024-12-23 01:57:14.225859: Current learning rate: 0.00287 
2024-12-23 01:57:46.185726: train_loss -0.8381 
2024-12-23 01:57:46.186728: val_loss -0.5106 
2024-12-23 01:57:46.192294: Pseudo dice [np.float32(0.7086), np.float32(0.3832)] 
2024-12-23 01:57:46.195376: Epoch time: 31.97 s 
2024-12-23 01:57:46.732877:  
2024-12-23 01:57:46.733881: Epoch 76 
2024-12-23 01:57:46.738943: Current learning rate: 0.00277 
2024-12-23 01:58:18.725559: train_loss -0.8321 
2024-12-23 01:58:18.726559: val_loss -0.5051 
2024-12-23 01:58:18.734088: Pseudo dice [np.float32(0.7415), np.float32(0.357)] 
2024-12-23 01:58:18.738131: Epoch time: 31.99 s 
2024-12-23 01:58:19.284889:  
2024-12-23 01:58:19.284889: Epoch 77 
2024-12-23 01:58:19.289956: Current learning rate: 0.00266 
2024-12-23 01:58:51.357322: train_loss -0.8259 
2024-12-23 01:58:51.357322: val_loss -0.4942 
2024-12-23 01:58:51.363337: Pseudo dice [np.float32(0.7173), np.float32(0.3531)] 
2024-12-23 01:58:51.366348: Epoch time: 32.07 s 
2024-12-23 01:58:51.919752:  
2024-12-23 01:58:51.919752: Epoch 78 
2024-12-23 01:58:51.924800: Current learning rate: 0.00256 
2024-12-23 01:59:23.748900: train_loss -0.8429 
2024-12-23 01:59:23.748900: val_loss -0.4574 
2024-12-23 01:59:23.756927: Pseudo dice [np.float32(0.7215), np.float32(0.2689)] 
2024-12-23 01:59:23.760452: Epoch time: 31.83 s 
2024-12-23 01:59:24.304429:  
2024-12-23 01:59:24.304429: Epoch 79 
2024-12-23 01:59:24.309531: Current learning rate: 0.00245 
2024-12-23 01:59:56.127525: train_loss -0.8328 
2024-12-23 01:59:56.128032: val_loss -0.4638 
2024-12-23 01:59:56.133597: Pseudo dice [np.float32(0.7103), np.float32(0.2966)] 
2024-12-23 01:59:56.137173: Epoch time: 31.82 s 
2024-12-23 01:59:56.690008:  
2024-12-23 01:59:56.691007: Epoch 80 
2024-12-23 01:59:56.696084: Current learning rate: 0.00235 
2024-12-23 02:00:28.494102: train_loss -0.8424 
2024-12-23 02:00:28.494604: val_loss -0.46 
2024-12-23 02:00:28.500254: Pseudo dice [np.float32(0.7014), np.float32(0.2919)] 
2024-12-23 02:00:28.504349: Epoch time: 31.81 s 
2024-12-23 02:00:29.203211:  
2024-12-23 02:00:29.203211: Epoch 81 
2024-12-23 02:00:29.209234: Current learning rate: 0.00224 
2024-12-23 02:01:01.030011: train_loss -0.8499 
2024-12-23 02:01:01.031018: val_loss -0.4676 
2024-12-23 02:01:01.036749: Pseudo dice [np.float32(0.7146), np.float32(0.2771)] 
2024-12-23 02:01:01.041908: Epoch time: 31.83 s 
2024-12-23 02:01:01.610416:  
2024-12-23 02:01:01.610416: Epoch 82 
2024-12-23 02:01:01.615986: Current learning rate: 0.00214 
2024-12-23 02:01:33.436890: train_loss -0.8488 
2024-12-23 02:01:33.436890: val_loss -0.4869 
2024-12-23 02:01:33.444495: Pseudo dice [np.float32(0.7134), np.float32(0.2938)] 
2024-12-23 02:01:33.447001: Epoch time: 31.83 s 
2024-12-23 02:01:33.960646:  
2024-12-23 02:01:33.961651: Epoch 83 
2024-12-23 02:01:33.966751: Current learning rate: 0.00203 
2024-12-23 02:02:05.788158: train_loss -0.8463 
2024-12-23 02:02:05.788679: val_loss -0.492 
2024-12-23 02:02:05.794244: Pseudo dice [np.float32(0.7122), np.float32(0.3638)] 
2024-12-23 02:02:05.798259: Epoch time: 31.83 s 
2024-12-23 02:02:06.315137:  
2024-12-23 02:02:06.316141: Epoch 84 
2024-12-23 02:02:06.320676: Current learning rate: 0.00192 
2024-12-23 02:02:38.140984: train_loss -0.8566 
2024-12-23 02:02:38.141523: val_loss -0.5074 
2024-12-23 02:02:38.147574: Pseudo dice [np.float32(0.7264), np.float32(0.3882)] 
2024-12-23 02:02:38.153676: Epoch time: 31.83 s 
2024-12-23 02:02:38.666729:  
2024-12-23 02:02:38.666729: Epoch 85 
2024-12-23 02:02:38.672284: Current learning rate: 0.00181 
2024-12-23 02:03:10.491894: train_loss -0.8573 
2024-12-23 02:03:10.492900: val_loss -0.5293 
2024-12-23 02:03:10.499030: Pseudo dice [np.float32(0.7343), np.float32(0.4233)] 
2024-12-23 02:03:10.501600: Epoch time: 31.83 s 
2024-12-23 02:03:11.010726:  
2024-12-23 02:03:11.010726: Epoch 86 
2024-12-23 02:03:11.015742: Current learning rate: 0.0017 
2024-12-23 02:03:42.819350: train_loss -0.8473 
2024-12-23 02:03:42.819854: val_loss -0.4691 
2024-12-23 02:03:42.825871: Pseudo dice [np.float32(0.6981), np.float32(0.3221)] 
2024-12-23 02:03:42.829910: Epoch time: 31.81 s 
2024-12-23 02:03:43.337546:  
2024-12-23 02:03:43.337546: Epoch 87 
2024-12-23 02:03:43.343126: Current learning rate: 0.00159 
2024-12-23 02:04:15.153444: train_loss -0.8518 
2024-12-23 02:04:15.153444: val_loss -0.4759 
2024-12-23 02:04:15.159534: Pseudo dice [np.float32(0.7349), np.float32(0.3389)] 
2024-12-23 02:04:15.163190: Epoch time: 31.82 s 
2024-12-23 02:04:15.681804:  
2024-12-23 02:04:15.682809: Epoch 88 
2024-12-23 02:04:15.687863: Current learning rate: 0.00148 
2024-12-23 02:04:47.503860: train_loss -0.8597 
2024-12-23 02:04:47.503860: val_loss -0.4947 
2024-12-23 02:04:47.511555: Pseudo dice [np.float32(0.7331), np.float32(0.3451)] 
2024-12-23 02:04:47.514588: Epoch time: 31.82 s 
2024-12-23 02:04:48.033628:  
2024-12-23 02:04:48.033628: Epoch 89 
2024-12-23 02:04:48.038657: Current learning rate: 0.00137 
2024-12-23 02:05:19.862397: train_loss -0.8582 
2024-12-23 02:05:19.862903: val_loss -0.5138 
2024-12-23 02:05:19.866998: Pseudo dice [np.float32(0.7164), np.float32(0.4029)] 
2024-12-23 02:05:19.871586: Epoch time: 31.83 s 
2024-12-23 02:05:20.531957:  
2024-12-23 02:05:20.531957: Epoch 90 
2024-12-23 02:05:20.537551: Current learning rate: 0.00126 
2024-12-23 02:05:52.353085: train_loss -0.8616 
2024-12-23 02:05:52.354087: val_loss -0.4717 
2024-12-23 02:05:52.360106: Pseudo dice [np.float32(0.7302), np.float32(0.2746)] 
2024-12-23 02:05:52.363751: Epoch time: 31.82 s 
2024-12-23 02:05:52.878718:  
2024-12-23 02:05:52.878718: Epoch 91 
2024-12-23 02:05:52.884819: Current learning rate: 0.00115 
2024-12-23 02:06:24.687649: train_loss -0.8605 
2024-12-23 02:06:24.688155: val_loss -0.4925 
2024-12-23 02:06:24.693172: Pseudo dice [np.float32(0.7105), np.float32(0.3831)] 
2024-12-23 02:06:24.696685: Epoch time: 31.81 s 
2024-12-23 02:06:25.210187:  
2024-12-23 02:06:25.210187: Epoch 92 
2024-12-23 02:06:25.215214: Current learning rate: 0.00103 
2024-12-23 02:06:57.031124: train_loss -0.8675 
2024-12-23 02:06:57.032129: val_loss -0.4678 
2024-12-23 02:06:57.038682: Pseudo dice [np.float32(0.7212), np.float32(0.3054)] 
2024-12-23 02:06:57.041211: Epoch time: 31.82 s 
2024-12-23 02:06:57.556198:  
2024-12-23 02:06:57.556701: Epoch 93 
2024-12-23 02:06:57.561750: Current learning rate: 0.00091 
2024-12-23 02:07:29.351959: train_loss -0.8586 
2024-12-23 02:07:29.352962: val_loss -0.5209 
2024-12-23 02:07:29.357973: Pseudo dice [np.float32(0.7385), np.float32(0.4233)] 
2024-12-23 02:07:29.362008: Epoch time: 31.8 s 
2024-12-23 02:07:29.874265:  
2024-12-23 02:07:29.874265: Epoch 94 
2024-12-23 02:07:29.879276: Current learning rate: 0.00079 
2024-12-23 02:08:01.678853: train_loss -0.8657 
2024-12-23 02:08:01.678853: val_loss -0.469 
2024-12-23 02:08:01.684644: Pseudo dice [np.float32(0.7173), np.float32(0.2851)] 
2024-12-23 02:08:01.688235: Epoch time: 31.81 s 
2024-12-23 02:08:02.205384:  
2024-12-23 02:08:02.206388: Epoch 95 
2024-12-23 02:08:02.210789: Current learning rate: 0.00067 
2024-12-23 02:08:33.988312: train_loss -0.8689 
2024-12-23 02:08:33.988816: val_loss -0.4864 
2024-12-23 02:08:33.993837: Pseudo dice [np.float32(0.7296), np.float32(0.325)] 
2024-12-23 02:08:33.998944: Epoch time: 31.78 s 
2024-12-23 02:08:34.506110:  
2024-12-23 02:08:34.506615: Epoch 96 
2024-12-23 02:08:34.511636: Current learning rate: 0.00055 
2024-12-23 02:09:06.310768: train_loss -0.8708 
2024-12-23 02:09:06.311275: val_loss -0.4919 
2024-12-23 02:09:06.317976: Pseudo dice [np.float32(0.7361), np.float32(0.3112)] 
2024-12-23 02:09:06.322011: Epoch time: 31.81 s 
2024-12-23 02:09:06.842844:  
2024-12-23 02:09:06.844347: Epoch 97 
2024-12-23 02:09:06.849470: Current learning rate: 0.00043 
2024-12-23 02:09:38.649258: train_loss -0.8667 
2024-12-23 02:09:38.649761: val_loss -0.5022 
2024-12-23 02:09:38.655379: Pseudo dice [np.float32(0.7403), np.float32(0.3441)] 
2024-12-23 02:09:38.659418: Epoch time: 31.81 s 
2024-12-23 02:09:39.330939:  
2024-12-23 02:09:39.330939: Epoch 98 
2024-12-23 02:09:39.336025: Current learning rate: 0.0003 
2024-12-23 02:10:11.135256: train_loss -0.8599 
2024-12-23 02:10:11.135769: val_loss -0.4717 
2024-12-23 02:10:11.141356: Pseudo dice [np.float32(0.7352), np.float32(0.2641)] 
2024-12-23 02:10:11.145361: Epoch time: 31.81 s 
2024-12-23 02:10:11.661012:  
2024-12-23 02:10:11.661012: Epoch 99 
2024-12-23 02:10:11.666027: Current learning rate: 0.00016 
2024-12-23 02:10:43.454609: train_loss -0.8701 
2024-12-23 02:10:43.455114: val_loss -0.5025 
2024-12-23 02:10:43.460772: Pseudo dice [np.float32(0.7267), np.float32(0.3784)] 
2024-12-23 02:10:43.463809: Epoch time: 31.8 s 
2024-12-23 02:10:44.286240: Training done. 
2024-12-23 02:10:44.320754: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-23 02:10:44.332756: The split file contains 5 splits. 
2024-12-23 02:10:44.337754: Desired fold for training: 0 
2024-12-23 02:10:44.342754: This split has 224 training and 57 validation cases. 
2024-12-23 02:10:44.347755: predicting pancreas_021 
2024-12-23 02:10:44.353753: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2024-12-23 02:10:46.197464: predicting pancreas_024 
2024-12-23 02:10:46.208973: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2024-12-23 02:10:46.957612: predicting pancreas_035 
2024-12-23 02:10:46.969613: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2024-12-23 02:10:47.252161: predicting pancreas_040 
2024-12-23 02:10:47.258160: pancreas_040, shape torch.Size([1, 45, 526, 526]), rank 0 
2024-12-23 02:10:48.056813: predicting pancreas_042 
2024-12-23 02:10:48.063813: pancreas_042, shape torch.Size([1, 51, 537, 537]), rank 0 
2024-12-23 02:10:48.978729: predicting pancreas_056 
2024-12-23 02:10:48.985729: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2024-12-23 02:10:49.339753: predicting pancreas_067 
2024-12-23 02:10:49.347753: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2024-12-23 02:10:51.202740: predicting pancreas_075 
2024-12-23 02:10:51.222244: pancreas_075, shape torch.Size([1, 121, 521, 521]), rank 0 
2024-12-23 02:10:53.645182: predicting pancreas_086 
2024-12-23 02:10:53.665188: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2024-12-23 02:10:54.602259: predicting pancreas_089 
2024-12-23 02:10:54.611764: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-23 02:10:55.098815: predicting pancreas_092 
2024-12-23 02:10:55.112318: pancreas_092, shape torch.Size([1, 92, 513, 513]), rank 0 
2024-12-23 02:10:56.739865: predicting pancreas_094 
2024-12-23 02:10:56.753865: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2024-12-23 02:10:57.287005: predicting pancreas_095 
2024-12-23 02:10:57.297011: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2024-12-23 02:10:57.824543: predicting pancreas_098 
2024-12-23 02:10:57.848544: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2024-12-23 02:11:00.808659: predicting pancreas_109 
2024-12-23 02:11:00.838659: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2024-12-23 02:11:01.421900: predicting pancreas_110 
2024-12-23 02:11:01.436902: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2024-12-23 02:11:04.356065: predicting pancreas_114 
2024-12-23 02:11:04.377065: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2024-12-23 02:11:04.909617: predicting pancreas_119 
2024-12-23 02:11:04.922124: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2024-12-23 02:11:06.544099: predicting pancreas_138 
2024-12-23 02:11:06.568099: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2024-12-23 02:11:08.361324: predicting pancreas_145 
2024-12-23 02:11:08.379324: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2024-12-23 02:11:10.060330: predicting pancreas_148 
2024-12-23 02:11:10.088330: pancreas_148, shape torch.Size([1, 42, 486, 486]), rank 0 
2024-12-23 02:11:10.333546: predicting pancreas_169 
2024-12-23 02:11:10.340546: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2024-12-23 02:11:10.791703: predicting pancreas_170 
2024-12-23 02:11:10.800707: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2024-12-23 02:11:11.426210: predicting pancreas_172 
2024-12-23 02:11:11.441210: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2024-12-23 02:11:11.968759: predicting pancreas_175 
2024-12-23 02:11:11.982760: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-23 02:11:12.648940: predicting pancreas_180 
2024-12-23 02:11:12.660939: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2024-12-23 02:11:13.212486: predicting pancreas_191 
2024-12-23 02:11:13.225519: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2024-12-23 02:11:13.753171: predicting pancreas_193 
2024-12-23 02:11:13.761171: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2024-12-23 02:11:14.386998: predicting pancreas_212 
2024-12-23 02:11:14.403003: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2024-12-23 02:11:16.285396: predicting pancreas_215 
2024-12-23 02:11:16.298397: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2024-12-23 02:11:16.802953: predicting pancreas_222 
2024-12-23 02:11:16.817461: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2024-12-23 02:11:17.195991: predicting pancreas_235 
2024-12-23 02:11:17.203996: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2024-12-23 02:11:17.655542: predicting pancreas_241 
2024-12-23 02:11:17.668542: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2024-12-23 02:11:18.187088: predicting pancreas_242 
2024-12-23 02:11:18.201096: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2024-12-23 02:11:20.273412: predicting pancreas_244 
2024-12-23 02:11:20.291411: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2024-12-23 02:11:22.639333: predicting pancreas_246 
2024-12-23 02:11:22.657333: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2024-12-23 02:11:24.588324: predicting pancreas_247 
2024-12-23 02:11:24.606327: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2024-12-23 02:11:25.089671: predicting pancreas_264 
2024-12-23 02:11:25.099671: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2024-12-23 02:11:27.018078: predicting pancreas_265 
2024-12-23 02:11:27.036077: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2024-12-23 02:11:28.768009: predicting pancreas_266 
2024-12-23 02:11:28.782009: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2024-12-23 02:11:30.475854: predicting pancreas_267 
2024-12-23 02:11:30.490857: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2024-12-23 02:11:31.025259: predicting pancreas_275 
2024-12-23 02:11:31.035259: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2024-12-23 02:11:31.603813: predicting pancreas_279 
2024-12-23 02:11:31.613813: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2024-12-23 02:11:32.381785: predicting pancreas_287 
2024-12-23 02:11:32.391786: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2024-12-23 02:11:32.968071: predicting pancreas_301 
2024-12-23 02:11:32.982070: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2024-12-23 02:11:34.574224: predicting pancreas_323 
2024-12-23 02:11:34.588225: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2024-12-23 02:11:36.361945: predicting pancreas_336 
2024-12-23 02:11:36.380946: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2024-12-23 02:11:38.107152: predicting pancreas_344 
2024-12-23 02:11:38.128660: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2024-12-23 02:11:38.753900: predicting pancreas_351 
2024-12-23 02:11:38.768900: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2024-12-23 02:11:39.225402: predicting pancreas_354 
2024-12-23 02:11:39.233403: pancreas_354, shape torch.Size([1, 81, 529, 529]), rank 0 
2024-12-23 02:11:40.763607: predicting pancreas_372 
2024-12-23 02:11:40.780607: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2024-12-23 02:11:42.455893: predicting pancreas_377 
2024-12-23 02:11:42.473893: pancreas_377, shape torch.Size([1, 55, 551, 551]), rank 0 
2024-12-23 02:11:43.529543: predicting pancreas_387 
2024-12-23 02:11:43.537544: pancreas_387, shape torch.Size([1, 50, 498, 498]), rank 0 
2024-12-23 02:11:43.828769: predicting pancreas_391 
2024-12-23 02:11:43.834768: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2024-12-23 02:11:45.977265: predicting pancreas_392 
2024-12-23 02:11:45.994265: pancreas_392, shape torch.Size([1, 57, 448, 448]), rank 0 
2024-12-23 02:11:46.447323: predicting pancreas_410 
2024-12-23 02:11:46.455324: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2024-12-23 02:11:47.295872: predicting pancreas_412 
2024-12-23 02:11:47.305873: pancreas_412, shape torch.Size([1, 164, 584, 584]), rank 0 
2024-12-23 02:12:01.303377: Validation complete 
2024-12-23 02:12:01.303377: Mean Validation Dice:  0.47750314204375205 
