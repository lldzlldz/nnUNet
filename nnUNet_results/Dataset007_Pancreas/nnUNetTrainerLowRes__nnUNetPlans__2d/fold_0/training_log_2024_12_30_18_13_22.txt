
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-30 18:13:22.921359: do_dummy_2d_data_aug: False 
2024-12-30 18:13:22.957824: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-30 18:13:22.964827: The split file contains 5 splits. 
2024-12-30 18:13:22.967824: Desired fold for training: 0 
2024-12-30 18:13:22.970824: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2024-12-30 18:13:29.284196: unpacking dataset... 
2024-12-30 18:13:29.530194: unpacking done... 
2024-12-30 18:13:34.781940:  
2024-12-30 18:13:34.781940: Epoch 0 
2024-12-30 18:13:34.786957: Current learning rate: 0.01 
2024-12-30 18:14:10.344182: train_loss 0.0715 
2024-12-30 18:14:10.344738: val_loss 0.0085 
2024-12-30 18:14:10.349823: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-30 18:14:10.353862: Epoch time: 35.56 s 
2024-12-30 18:14:10.357445: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-30 18:14:11.142790:  
2024-12-30 18:14:11.142790: Epoch 1 
2024-12-30 18:14:11.147802: Current learning rate: 0.00991 
2024-12-30 18:14:43.173489: train_loss -0.0255 
2024-12-30 18:14:43.173489: val_loss -0.0974 
2024-12-30 18:14:43.179533: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-30 18:14:43.183059: Epoch time: 32.03 s 
2024-12-30 18:14:43.704828:  
2024-12-30 18:14:43.705828: Epoch 2 
2024-12-30 18:14:43.710891: Current learning rate: 0.00982 
2024-12-30 18:15:16.198276: train_loss -0.2306 
2024-12-30 18:15:16.199276: val_loss -0.2999 
2024-12-30 18:15:16.206800: Pseudo dice [np.float32(0.5819), np.float32(0.0)] 
2024-12-30 18:15:16.209816: Epoch time: 32.49 s 
2024-12-30 18:15:16.213330: Yayy! New best EMA pseudo Dice: 0.029100000858306885 
2024-12-30 18:15:17.104506:  
2024-12-30 18:15:17.104506: Epoch 3 
2024-12-30 18:15:17.109553: Current learning rate: 0.00973 
2024-12-30 18:15:49.236082: train_loss -0.3202 
2024-12-30 18:15:49.237082: val_loss -0.332 
2024-12-30 18:15:49.242600: Pseudo dice [np.float32(0.6221), np.float32(0.0)] 
2024-12-30 18:15:49.246110: Epoch time: 32.13 s 
2024-12-30 18:15:49.248617: Yayy! New best EMA pseudo Dice: 0.05730000138282776 
2024-12-30 18:15:50.107848:  
2024-12-30 18:15:50.108351: Epoch 4 
2024-12-30 18:15:50.113361: Current learning rate: 0.00964 
2024-12-30 18:16:22.141022: train_loss -0.3612 
2024-12-30 18:16:22.141022: val_loss -0.361 
2024-12-30 18:16:22.147036: Pseudo dice [np.float32(0.631), np.float32(0.0)] 
2024-12-30 18:16:22.151044: Epoch time: 32.03 s 
2024-12-30 18:16:22.154554: Yayy! New best EMA pseudo Dice: 0.08309999853372574 
2024-12-30 18:16:23.163090:  
2024-12-30 18:16:23.164089: Epoch 5 
2024-12-30 18:16:23.169675: Current learning rate: 0.00955 
2024-12-30 18:16:55.193101: train_loss -0.4057 
2024-12-30 18:16:55.194106: val_loss -0.43 
2024-12-30 18:16:55.199203: Pseudo dice [np.float32(0.6681), np.float32(0.0)] 
2024-12-30 18:16:55.204310: Epoch time: 32.03 s 
2024-12-30 18:16:55.206890: Yayy! New best EMA pseudo Dice: 0.10819999873638153 
2024-12-30 18:16:56.061589:  
2024-12-30 18:16:56.062100: Epoch 6 
2024-12-30 18:16:56.068168: Current learning rate: 0.00946 
2024-12-30 18:17:28.116060: train_loss -0.458 
2024-12-30 18:17:28.117063: val_loss -0.4636 
2024-12-30 18:17:28.123075: Pseudo dice [np.float32(0.5752), np.float32(0.4297)] 
2024-12-30 18:17:28.126083: Epoch time: 32.05 s 
2024-12-30 18:17:28.129593: Yayy! New best EMA pseudo Dice: 0.147599995136261 
2024-12-30 18:17:28.982831:  
2024-12-30 18:17:28.983334: Epoch 7 
2024-12-30 18:17:28.988353: Current learning rate: 0.00937 
2024-12-30 18:18:01.014590: train_loss -0.4817 
2024-12-30 18:18:01.015093: val_loss -0.493 
2024-12-30 18:18:01.021166: Pseudo dice [np.float32(0.6675), np.float32(0.4088)] 
2024-12-30 18:18:01.025676: Epoch time: 32.03 s 
2024-12-30 18:18:01.028685: Yayy! New best EMA pseudo Dice: 0.1867000013589859 
2024-12-30 18:18:01.900509:  
2024-12-30 18:18:01.901011: Epoch 8 
2024-12-30 18:18:01.907027: Current learning rate: 0.00928 
2024-12-30 18:18:33.949646: train_loss -0.518 
2024-12-30 18:18:33.950152: val_loss -0.4818 
2024-12-30 18:18:33.956167: Pseudo dice [np.float32(0.6605), np.float32(0.3561)] 
2024-12-30 18:18:33.959675: Epoch time: 32.05 s 
2024-12-30 18:18:33.962685: Yayy! New best EMA pseudo Dice: 0.21879999339580536 
2024-12-30 18:18:34.845689:  
2024-12-30 18:18:34.846191: Epoch 9 
2024-12-30 18:18:34.851202: Current learning rate: 0.00919 
2024-12-30 18:19:06.892832: train_loss -0.5425 
2024-12-30 18:19:06.892832: val_loss -0.4975 
2024-12-30 18:19:06.899356: Pseudo dice [np.float32(0.6322), np.float32(0.4306)] 
2024-12-30 18:19:06.901865: Epoch time: 32.05 s 
2024-12-30 18:19:06.905378: Yayy! New best EMA pseudo Dice: 0.2500999867916107 
2024-12-30 18:19:07.757015:  
2024-12-30 18:19:07.758518: Epoch 10 
2024-12-30 18:19:07.764572: Current learning rate: 0.0091 
2024-12-30 18:19:39.817795: train_loss -0.5365 
2024-12-30 18:19:39.817795: val_loss -0.5156 
2024-12-30 18:19:39.824312: Pseudo dice [np.float32(0.6604), np.float32(0.4684)] 
2024-12-30 18:19:39.827821: Epoch time: 32.06 s 
2024-12-30 18:19:39.831326: Yayy! New best EMA pseudo Dice: 0.2815000116825104 
2024-12-30 18:19:40.685154:  
2024-12-30 18:19:40.685154: Epoch 11 
2024-12-30 18:19:40.691185: Current learning rate: 0.009 
2024-12-30 18:20:12.719104: train_loss -0.5571 
2024-12-30 18:20:12.720606: val_loss -0.4976 
2024-12-30 18:20:12.726620: Pseudo dice [np.float32(0.6796), np.float32(0.3695)] 
2024-12-30 18:20:12.729127: Epoch time: 32.03 s 
2024-12-30 18:20:12.733135: Yayy! New best EMA pseudo Dice: 0.3057999908924103 
2024-12-30 18:20:13.748308:  
2024-12-30 18:20:13.748308: Epoch 12 
2024-12-30 18:20:13.753866: Current learning rate: 0.00891 
2024-12-30 18:20:46.014366: train_loss -0.5606 
2024-12-30 18:20:46.014366: val_loss -0.5362 
2024-12-30 18:20:46.021430: Pseudo dice [np.float32(0.6815), np.float32(0.4475)] 
2024-12-30 18:20:46.024942: Epoch time: 32.27 s 
2024-12-30 18:20:46.028447: Yayy! New best EMA pseudo Dice: 0.33169999718666077 
2024-12-30 18:20:46.891746:  
2024-12-30 18:20:46.891746: Epoch 13 
2024-12-30 18:20:46.897761: Current learning rate: 0.00882 
2024-12-30 18:21:18.942818: train_loss -0.5859 
2024-12-30 18:21:18.944326: val_loss -0.4777 
2024-12-30 18:21:18.950882: Pseudo dice [np.float32(0.671), np.float32(0.3459)] 
2024-12-30 18:21:18.954890: Epoch time: 32.05 s 
2024-12-30 18:21:18.958399: Yayy! New best EMA pseudo Dice: 0.34940001368522644 
2024-12-30 18:21:19.810984:  
2024-12-30 18:21:19.810984: Epoch 14 
2024-12-30 18:21:19.817018: Current learning rate: 0.00873 
2024-12-30 18:21:51.865129: train_loss -0.5388 
2024-12-30 18:21:51.865650: val_loss -0.5098 
2024-12-30 18:21:51.871675: Pseudo dice [np.float32(0.6604), np.float32(0.4509)] 
2024-12-30 18:21:51.875182: Epoch time: 32.06 s 
2024-12-30 18:21:51.878199: Yayy! New best EMA pseudo Dice: 0.3700000047683716 
2024-12-30 18:21:52.754884:  
2024-12-30 18:21:52.754884: Epoch 15 
2024-12-30 18:21:52.759978: Current learning rate: 0.00864 
2024-12-30 18:22:24.802812: train_loss -0.567 
2024-12-30 18:22:24.802812: val_loss -0.5193 
2024-12-30 18:22:24.810328: Pseudo dice [np.float32(0.7028), np.float32(0.3934)] 
2024-12-30 18:22:24.813837: Epoch time: 32.05 s 
2024-12-30 18:22:24.817342: Yayy! New best EMA pseudo Dice: 0.387800008058548 
2024-12-30 18:22:25.684984:  
2024-12-30 18:22:25.685499: Epoch 16 
2024-12-30 18:22:25.690545: Current learning rate: 0.00855 
2024-12-30 18:22:57.729884: train_loss -0.6067 
2024-12-30 18:22:57.730386: val_loss -0.5172 
2024-12-30 18:22:57.736400: Pseudo dice [np.float32(0.6909), np.float32(0.4224)] 
2024-12-30 18:22:57.740408: Epoch time: 32.05 s 
2024-12-30 18:22:57.743917: Yayy! New best EMA pseudo Dice: 0.40470001101493835 
2024-12-30 18:22:58.652391:  
2024-12-30 18:22:58.652391: Epoch 17 
2024-12-30 18:22:58.657402: Current learning rate: 0.00846 
2024-12-30 18:23:30.684672: train_loss -0.5903 
2024-12-30 18:23:30.685675: val_loss -0.4935 
2024-12-30 18:23:30.693192: Pseudo dice [np.float32(0.6543), np.float32(0.4162)] 
2024-12-30 18:23:30.696697: Epoch time: 32.03 s 
2024-12-30 18:23:30.699705: Yayy! New best EMA pseudo Dice: 0.41780000925064087 
2024-12-30 18:23:31.793115:  
2024-12-30 18:23:31.794119: Epoch 18 
2024-12-30 18:23:31.798682: Current learning rate: 0.00836 
2024-12-30 18:24:03.830507: train_loss -0.6282 
2024-12-30 18:24:03.831513: val_loss -0.5169 
2024-12-30 18:24:03.838028: Pseudo dice [np.float32(0.6896), np.float32(0.3934)] 
2024-12-30 18:24:03.841536: Epoch time: 32.04 s 
2024-12-30 18:24:03.845543: Yayy! New best EMA pseudo Dice: 0.4300999939441681 
2024-12-30 18:24:04.892672:  
2024-12-30 18:24:04.892672: Epoch 19 
2024-12-30 18:24:04.898765: Current learning rate: 0.00827 
2024-12-30 18:24:36.919419: train_loss -0.6154 
2024-12-30 18:24:36.920419: val_loss -0.5138 
2024-12-30 18:24:36.925932: Pseudo dice [np.float32(0.698), np.float32(0.4088)] 
2024-12-30 18:24:36.930441: Epoch time: 32.03 s 
2024-12-30 18:24:36.933449: Yayy! New best EMA pseudo Dice: 0.4424999952316284 
2024-12-30 18:24:37.811464:  
2024-12-30 18:24:37.811464: Epoch 20 
2024-12-30 18:24:37.817575: Current learning rate: 0.00818 
2024-12-30 18:25:09.832044: train_loss -0.6399 
2024-12-30 18:25:09.833044: val_loss -0.4678 
2024-12-30 18:25:09.838561: Pseudo dice [np.float32(0.6781), np.float32(0.3588)] 
2024-12-30 18:25:09.842070: Epoch time: 32.02 s 
2024-12-30 18:25:09.845579: Yayy! New best EMA pseudo Dice: 0.45010000467300415 
2024-12-30 18:25:10.723487:  
2024-12-30 18:25:10.724487: Epoch 21 
2024-12-30 18:25:10.730071: Current learning rate: 0.00809 
2024-12-30 18:25:43.072347: train_loss -0.6342 
2024-12-30 18:25:43.073357: val_loss -0.5321 
2024-12-30 18:25:43.079389: Pseudo dice [np.float32(0.6505), np.float32(0.5062)] 
2024-12-30 18:25:43.083415: Epoch time: 32.35 s 
2024-12-30 18:25:43.086932: Yayy! New best EMA pseudo Dice: 0.4629000127315521 
2024-12-30 18:25:43.932992:  
2024-12-30 18:25:43.933992: Epoch 22 
2024-12-30 18:25:43.939564: Current learning rate: 0.008 
2024-12-30 18:26:16.002519: train_loss -0.6446 
2024-12-30 18:26:16.003023: val_loss -0.4945 
2024-12-30 18:26:16.010541: Pseudo dice [np.float32(0.688), np.float32(0.3714)] 
2024-12-30 18:26:16.015053: Epoch time: 32.07 s 
2024-12-30 18:26:16.018065: Yayy! New best EMA pseudo Dice: 0.46959999203681946 
2024-12-30 18:26:16.877139:  
2024-12-30 18:26:16.878139: Epoch 23 
2024-12-30 18:26:16.883728: Current learning rate: 0.0079 
2024-12-30 18:26:48.896897: train_loss -0.656 
2024-12-30 18:26:48.897406: val_loss -0.5489 
2024-12-30 18:26:48.902459: Pseudo dice [np.float32(0.7335), np.float32(0.4241)] 
2024-12-30 18:26:48.907575: Epoch time: 32.02 s 
2024-12-30 18:26:48.910120: Yayy! New best EMA pseudo Dice: 0.4805000126361847 
2024-12-30 18:26:49.757622:  
2024-12-30 18:26:49.758129: Epoch 24 
2024-12-30 18:26:49.763165: Current learning rate: 0.00781 
2024-12-30 18:27:21.797216: train_loss -0.6752 
2024-12-30 18:27:21.798218: val_loss -0.5229 
2024-12-30 18:27:21.805805: Pseudo dice [np.float32(0.7105), np.float32(0.4205)] 
2024-12-30 18:27:21.809830: Epoch time: 32.04 s 
2024-12-30 18:27:21.813414: Yayy! New best EMA pseudo Dice: 0.48899999260902405 
2024-12-30 18:27:22.680622:  
2024-12-30 18:27:22.680622: Epoch 25 
2024-12-30 18:27:22.686640: Current learning rate: 0.00772 
2024-12-30 18:27:54.705539: train_loss -0.6416 
2024-12-30 18:27:54.705539: val_loss -0.557 
2024-12-30 18:27:54.711555: Pseudo dice [np.float32(0.7025), np.float32(0.4753)] 
2024-12-30 18:27:54.715562: Epoch time: 32.03 s 
2024-12-30 18:27:54.719071: Yayy! New best EMA pseudo Dice: 0.49900001287460327 
2024-12-30 18:27:55.592659:  
2024-12-30 18:27:55.592659: Epoch 26 
2024-12-30 18:27:55.599709: Current learning rate: 0.00763 
2024-12-30 18:28:27.625396: train_loss -0.6595 
2024-12-30 18:28:27.625396: val_loss -0.4853 
2024-12-30 18:28:27.633066: Pseudo dice [np.float32(0.6845), np.float32(0.3422)] 
2024-12-30 18:28:27.637114: Epoch time: 32.03 s 
2024-12-30 18:28:27.640173: Yayy! New best EMA pseudo Dice: 0.5004000067710876 
2024-12-30 18:28:28.662775:  
2024-12-30 18:28:28.663277: Epoch 27 
2024-12-30 18:28:28.668854: Current learning rate: 0.00753 
2024-12-30 18:29:01.224827: train_loss -0.6434 
2024-12-30 18:29:01.226348: val_loss -0.5477 
2024-12-30 18:29:01.230376: Pseudo dice [np.float32(0.6987), np.float32(0.481)] 
2024-12-30 18:29:01.234810: Epoch time: 32.56 s 
2024-12-30 18:29:01.238408: Yayy! New best EMA pseudo Dice: 0.5094000101089478 
2024-12-30 18:29:02.132078:  
2024-12-30 18:29:02.133082: Epoch 28 
2024-12-30 18:29:02.138642: Current learning rate: 0.00744 
2024-12-30 18:29:35.071808: train_loss -0.6841 
2024-12-30 18:29:35.072811: val_loss -0.5175 
2024-12-30 18:29:35.079340: Pseudo dice [np.float32(0.6972), np.float32(0.4342)] 
2024-12-30 18:29:35.082853: Epoch time: 32.94 s 
2024-12-30 18:29:35.086859: Yayy! New best EMA pseudo Dice: 0.5149999856948853 
2024-12-30 18:29:35.958272:  
2024-12-30 18:29:35.959275: Epoch 29 
2024-12-30 18:29:35.964852: Current learning rate: 0.00735 
2024-12-30 18:30:08.087583: train_loss -0.6931 
2024-12-30 18:30:08.087583: val_loss -0.5206 
2024-12-30 18:30:08.094138: Pseudo dice [np.float32(0.6983), np.float32(0.4592)] 
2024-12-30 18:30:08.097675: Epoch time: 32.13 s 
2024-12-30 18:30:08.101700: Yayy! New best EMA pseudo Dice: 0.521399974822998 
2024-12-30 18:30:08.958948:  
2024-12-30 18:30:08.959452: Epoch 30 
2024-12-30 18:30:08.965468: Current learning rate: 0.00725 
2024-12-30 18:30:41.374218: train_loss -0.6854 
2024-12-30 18:30:41.375221: val_loss -0.5223 
2024-12-30 18:30:41.381740: Pseudo dice [np.float32(0.6696), np.float32(0.455)] 
2024-12-30 18:30:41.386252: Epoch time: 32.42 s 
2024-12-30 18:30:41.389265: Yayy! New best EMA pseudo Dice: 0.5254999995231628 
2024-12-30 18:30:42.271467:  
2024-12-30 18:30:42.271971: Epoch 31 
2024-12-30 18:30:42.277995: Current learning rate: 0.00716 
2024-12-30 18:31:14.687639: train_loss -0.6764 
2024-12-30 18:31:14.687639: val_loss -0.4759 
2024-12-30 18:31:14.694155: Pseudo dice [np.float32(0.6923), np.float32(0.3348)] 
2024-12-30 18:31:14.697666: Epoch time: 32.42 s 
2024-12-30 18:31:15.282416:  
2024-12-30 18:31:15.283416: Epoch 32 
2024-12-30 18:31:15.289070: Current learning rate: 0.00707 
2024-12-30 18:31:47.959511: train_loss -0.6628 
2024-12-30 18:31:47.960017: val_loss -0.5116 
2024-12-30 18:31:47.965559: Pseudo dice [np.float32(0.6995), np.float32(0.3868)] 
2024-12-30 18:31:47.969154: Epoch time: 32.68 s 
2024-12-30 18:31:47.973178: Yayy! New best EMA pseudo Dice: 0.526199996471405 
2024-12-30 18:31:48.850832:  
2024-12-30 18:31:48.851334: Epoch 33 
2024-12-30 18:31:48.857348: Current learning rate: 0.00697 
2024-12-30 18:32:21.558887: train_loss -0.6895 
2024-12-30 18:32:21.558887: val_loss -0.5109 
2024-12-30 18:32:21.565405: Pseudo dice [np.float32(0.7052), np.float32(0.3981)] 
2024-12-30 18:32:21.569915: Epoch time: 32.71 s 
2024-12-30 18:32:21.572925: Yayy! New best EMA pseudo Dice: 0.5286999940872192 
2024-12-30 18:32:22.471548:  
2024-12-30 18:32:22.471548: Epoch 34 
2024-12-30 18:32:22.477683: Current learning rate: 0.00688 
2024-12-30 18:32:55.092178: train_loss -0.6992 
2024-12-30 18:32:55.092681: val_loss -0.5049 
2024-12-30 18:32:55.098696: Pseudo dice [np.float32(0.6561), np.float32(0.4242)] 
2024-12-30 18:32:55.102704: Epoch time: 32.62 s 
2024-12-30 18:32:55.105727: Yayy! New best EMA pseudo Dice: 0.5299000144004822 
2024-12-30 18:32:56.118071:  
2024-12-30 18:32:56.118582: Epoch 35 
2024-12-30 18:32:56.124665: Current learning rate: 0.00679 
2024-12-30 18:33:29.008810: train_loss -0.696 
2024-12-30 18:33:29.009319: val_loss -0.5028 
2024-12-30 18:33:29.015572: Pseudo dice [np.float32(0.6924), np.float32(0.3885)] 
2024-12-30 18:33:29.019149: Epoch time: 32.89 s 
2024-12-30 18:33:29.023221: Yayy! New best EMA pseudo Dice: 0.5309000015258789 
2024-12-30 18:33:29.907789:  
2024-12-30 18:33:29.907789: Epoch 36 
2024-12-30 18:33:29.913821: Current learning rate: 0.00669 
2024-12-30 18:34:03.315122: train_loss -0.7298 
2024-12-30 18:34:03.316122: val_loss -0.5338 
2024-12-30 18:34:03.321636: Pseudo dice [np.float32(0.7229), np.float32(0.4627)] 
2024-12-30 18:34:03.326650: Epoch time: 33.41 s 
2024-12-30 18:34:03.329666: Yayy! New best EMA pseudo Dice: 0.5371000170707703 
2024-12-30 18:34:04.286474:  
2024-12-30 18:34:04.286474: Epoch 37 
2024-12-30 18:34:04.293036: Current learning rate: 0.0066 
2024-12-30 18:34:37.435715: train_loss -0.7307 
2024-12-30 18:34:37.435715: val_loss -0.5629 
2024-12-30 18:34:37.442251: Pseudo dice [np.float32(0.7201), np.float32(0.5106)] 
2024-12-30 18:34:37.446830: Epoch time: 33.15 s 
2024-12-30 18:34:37.450356: Yayy! New best EMA pseudo Dice: 0.5449000000953674 
2024-12-30 18:34:38.328970:  
2024-12-30 18:34:38.329970: Epoch 38 
2024-12-30 18:34:38.335558: Current learning rate: 0.0065 
2024-12-30 18:35:11.412057: train_loss -0.726 
2024-12-30 18:35:11.412575: val_loss -0.5285 
2024-12-30 18:35:11.419153: Pseudo dice [np.float32(0.7061), np.float32(0.496)] 
2024-12-30 18:35:11.423164: Epoch time: 33.08 s 
2024-12-30 18:35:11.426678: Yayy! New best EMA pseudo Dice: 0.5504999756813049 
2024-12-30 18:35:12.309506:  
2024-12-30 18:35:12.310509: Epoch 39 
2024-12-30 18:35:12.316032: Current learning rate: 0.00641 
2024-12-30 18:35:45.458597: train_loss -0.7364 
2024-12-30 18:35:45.459101: val_loss -0.52 
2024-12-30 18:35:45.465289: Pseudo dice [np.float32(0.6973), np.float32(0.4194)] 
2024-12-30 18:35:45.469403: Epoch time: 33.15 s 
2024-12-30 18:35:45.472973: Yayy! New best EMA pseudo Dice: 0.5512999892234802 
2024-12-30 18:35:46.351885:  
2024-12-30 18:35:46.351885: Epoch 40 
2024-12-30 18:35:46.356899: Current learning rate: 0.00631 
2024-12-30 18:36:19.156824: train_loss -0.7365 
2024-12-30 18:36:19.156824: val_loss -0.49 
2024-12-30 18:36:19.164470: Pseudo dice [np.float32(0.7354), np.float32(0.3159)] 
2024-12-30 18:36:19.168041: Epoch time: 32.81 s 
2024-12-30 18:36:19.913361:  
2024-12-30 18:36:19.913361: Epoch 41 
2024-12-30 18:36:19.918876: Current learning rate: 0.00622 
2024-12-30 18:36:53.315942: train_loss -0.7505 
2024-12-30 18:36:53.315942: val_loss -0.5248 
2024-12-30 18:36:53.321498: Pseudo dice [np.float32(0.7168), np.float32(0.4683)] 
2024-12-30 18:36:53.324516: Epoch time: 33.4 s 
2024-12-30 18:36:53.329072: Yayy! New best EMA pseudo Dice: 0.5530999898910522 
2024-12-30 18:36:54.215400:  
2024-12-30 18:36:54.216400: Epoch 42 
2024-12-30 18:36:54.224049: Current learning rate: 0.00612 
2024-12-30 18:37:28.060447: train_loss -0.7587 
2024-12-30 18:37:28.061453: val_loss -0.4965 
2024-12-30 18:37:28.067969: Pseudo dice [np.float32(0.7313), np.float32(0.3472)] 
2024-12-30 18:37:28.071479: Epoch time: 33.85 s 
2024-12-30 18:37:28.638621:  
2024-12-30 18:37:28.639138: Epoch 43 
2024-12-30 18:37:28.645154: Current learning rate: 0.00603 
2024-12-30 18:38:02.466904: train_loss -0.7696 
2024-12-30 18:38:02.467408: val_loss -0.5292 
2024-12-30 18:38:02.475689: Pseudo dice [np.float32(0.7182), np.float32(0.4342)] 
2024-12-30 18:38:02.480737: Epoch time: 33.83 s 
2024-12-30 18:38:02.486681: Yayy! New best EMA pseudo Dice: 0.5541999936103821 
2024-12-30 18:38:03.413832:  
2024-12-30 18:38:03.414335: Epoch 44 
2024-12-30 18:38:03.419349: Current learning rate: 0.00593 
2024-12-30 18:38:36.522006: train_loss -0.7726 
2024-12-30 18:38:36.522508: val_loss -0.4743 
2024-12-30 18:38:36.528547: Pseudo dice [np.float32(0.7218), np.float32(0.283)] 
2024-12-30 18:38:36.532555: Epoch time: 33.11 s 
2024-12-30 18:38:37.103705:  
2024-12-30 18:38:37.103705: Epoch 45 
2024-12-30 18:38:37.110826: Current learning rate: 0.00584 
2024-12-30 18:39:09.772850: train_loss -0.7608 
2024-12-30 18:39:09.772850: val_loss -0.5498 
2024-12-30 18:39:09.779368: Pseudo dice [np.float32(0.7206), np.float32(0.5261)] 
2024-12-30 18:39:09.782880: Epoch time: 32.67 s 
2024-12-30 18:39:09.786892: Yayy! New best EMA pseudo Dice: 0.5564000010490417 
2024-12-30 18:39:10.633501:  
2024-12-30 18:39:10.633501: Epoch 46 
2024-12-30 18:39:10.638565: Current learning rate: 0.00574 
2024-12-30 18:39:43.623053: train_loss -0.755 
2024-12-30 18:39:43.623053: val_loss -0.4743 
2024-12-30 18:39:43.630094: Pseudo dice [np.float32(0.6986), np.float32(0.3214)] 
2024-12-30 18:39:43.634120: Epoch time: 32.99 s 
2024-12-30 18:39:44.195965:  
2024-12-30 18:39:44.197471: Epoch 47 
2024-12-30 18:39:44.202489: Current learning rate: 0.00565 
2024-12-30 18:40:17.103899: train_loss -0.7625 
2024-12-30 18:40:17.105407: val_loss -0.5089 
2024-12-30 18:40:17.112926: Pseudo dice [np.float32(0.7207), np.float32(0.3345)] 
2024-12-30 18:40:17.116431: Epoch time: 32.91 s 
2024-12-30 18:40:17.676146:  
2024-12-30 18:40:17.676146: Epoch 48 
2024-12-30 18:40:17.682406: Current learning rate: 0.00555 
2024-12-30 18:40:50.876382: train_loss -0.7635 
2024-12-30 18:40:50.876904: val_loss -0.532 
2024-12-30 18:40:50.884030: Pseudo dice [np.float32(0.6825), np.float32(0.4783)] 
2024-12-30 18:40:50.888097: Epoch time: 33.2 s 
2024-12-30 18:40:51.511096:  
2024-12-30 18:40:51.511607: Epoch 49 
2024-12-30 18:40:51.517632: Current learning rate: 0.00546 
2024-12-30 18:41:24.321825: train_loss -0.764 
2024-12-30 18:41:24.322328: val_loss -0.489 
2024-12-30 18:41:24.329871: Pseudo dice [np.float32(0.7364), np.float32(0.2723)] 
2024-12-30 18:41:24.333889: Epoch time: 32.81 s 
2024-12-30 18:41:25.436260:  
2024-12-30 18:41:25.436762: Epoch 50 
2024-12-30 18:41:25.442336: Current learning rate: 0.00536 
2024-12-30 18:41:58.014631: train_loss -0.7825 
2024-12-30 18:41:58.015135: val_loss -0.5018 
2024-12-30 18:41:58.020925: Pseudo dice [np.float32(0.7223), np.float32(0.3506)] 
2024-12-30 18:41:58.024995: Epoch time: 32.58 s 
2024-12-30 18:41:58.595218:  
2024-12-30 18:41:58.596218: Epoch 51 
2024-12-30 18:41:58.601305: Current learning rate: 0.00526 
2024-12-30 18:42:31.668765: train_loss -0.7906 
2024-12-30 18:42:31.669277: val_loss -0.5204 
2024-12-30 18:42:31.675409: Pseudo dice [np.float32(0.7216), np.float32(0.4278)] 
2024-12-30 18:42:31.678466: Epoch time: 33.07 s 
2024-12-30 18:42:32.253614:  
2024-12-30 18:42:32.253614: Epoch 52 
2024-12-30 18:42:32.258646: Current learning rate: 0.00517 
2024-12-30 18:43:04.817640: train_loss -0.7961 
2024-12-30 18:43:04.818147: val_loss -0.5043 
2024-12-30 18:43:04.823694: Pseudo dice [np.float32(0.7293), np.float32(0.3558)] 
2024-12-30 18:43:04.826200: Epoch time: 32.57 s 
2024-12-30 18:43:05.396241:  
2024-12-30 18:43:05.397241: Epoch 53 
2024-12-30 18:43:05.402821: Current learning rate: 0.00507 
2024-12-30 18:43:38.182512: train_loss -0.7929 
2024-12-30 18:43:38.183515: val_loss -0.5031 
2024-12-30 18:43:38.188527: Pseudo dice [np.float32(0.7258), np.float32(0.3139)] 
2024-12-30 18:43:38.192578: Epoch time: 32.79 s 
2024-12-30 18:43:38.785758:  
2024-12-30 18:43:38.786261: Epoch 54 
2024-12-30 18:43:38.792276: Current learning rate: 0.00497 
2024-12-30 18:44:12.376986: train_loss -0.7824 
2024-12-30 18:44:12.377488: val_loss -0.5019 
2024-12-30 18:44:12.383503: Pseudo dice [np.float32(0.719), np.float32(0.3603)] 
2024-12-30 18:44:12.386017: Epoch time: 33.59 s 
2024-12-30 18:44:12.960527:  
2024-12-30 18:44:12.961529: Epoch 55 
2024-12-30 18:44:12.965549: Current learning rate: 0.00487 
2024-12-30 18:44:45.866438: train_loss -0.8015 
2024-12-30 18:44:45.866940: val_loss -0.5066 
2024-12-30 18:44:45.872957: Pseudo dice [np.float32(0.7226), np.float32(0.3739)] 
2024-12-30 18:44:45.876462: Epoch time: 32.91 s 
2024-12-30 18:44:46.460563:  
2024-12-30 18:44:46.460563: Epoch 56 
2024-12-30 18:44:46.466120: Current learning rate: 0.00478 
2024-12-30 18:45:19.270822: train_loss -0.7796 
2024-12-30 18:45:19.271825: val_loss -0.5358 
2024-12-30 18:45:19.278338: Pseudo dice [np.float32(0.719), np.float32(0.4052)] 
2024-12-30 18:45:19.281877: Epoch time: 32.81 s 
2024-12-30 18:45:19.857106:  
2024-12-30 18:45:19.857106: Epoch 57 
2024-12-30 18:45:19.862117: Current learning rate: 0.00468 
2024-12-30 18:45:52.799988: train_loss -0.8008 
2024-12-30 18:45:52.799988: val_loss -0.5384 
2024-12-30 18:45:52.805095: Pseudo dice [np.float32(0.6952), np.float32(0.435)] 
2024-12-30 18:45:52.808105: Epoch time: 32.94 s 
2024-12-30 18:45:53.597749:  
2024-12-30 18:45:53.597749: Epoch 58 
2024-12-30 18:45:53.604356: Current learning rate: 0.00458 
2024-12-30 18:46:26.651186: train_loss -0.805 
2024-12-30 18:46:26.652190: val_loss -0.5073 
2024-12-30 18:46:26.658713: Pseudo dice [np.float32(0.7216), np.float32(0.3673)] 
2024-12-30 18:46:26.662227: Epoch time: 33.05 s 
2024-12-30 18:46:27.245258:  
2024-12-30 18:46:27.245761: Epoch 59 
2024-12-30 18:46:27.250773: Current learning rate: 0.00448 
2024-12-30 18:46:59.896453: train_loss -0.8082 
2024-12-30 18:46:59.896453: val_loss -0.5226 
2024-12-30 18:46:59.903026: Pseudo dice [np.float32(0.7268), np.float32(0.4407)] 
2024-12-30 18:46:59.906535: Epoch time: 32.65 s 
2024-12-30 18:47:00.490853:  
2024-12-30 18:47:00.491356: Epoch 60 
2024-12-30 18:47:00.496367: Current learning rate: 0.00438 
2024-12-30 18:47:33.659006: train_loss -0.7935 
2024-12-30 18:47:33.660008: val_loss -0.5143 
2024-12-30 18:47:33.666424: Pseudo dice [np.float32(0.7045), np.float32(0.4125)] 
2024-12-30 18:47:33.670445: Epoch time: 33.17 s 
2024-12-30 18:47:34.321402:  
2024-12-30 18:47:34.322406: Epoch 61 
2024-12-30 18:47:34.326985: Current learning rate: 0.00429 
2024-12-30 18:48:06.896106: train_loss -0.8133 
2024-12-30 18:48:06.896106: val_loss -0.52 
2024-12-30 18:48:06.902623: Pseudo dice [np.float32(0.7243), np.float32(0.4058)] 
2024-12-30 18:48:06.906134: Epoch time: 32.58 s 
2024-12-30 18:48:07.491960:  
2024-12-30 18:48:07.491960: Epoch 62 
2024-12-30 18:48:07.498053: Current learning rate: 0.00419 
2024-12-30 18:48:39.824178: train_loss -0.8143 
2024-12-30 18:48:39.825176: val_loss -0.5094 
2024-12-30 18:48:39.831782: Pseudo dice [np.float32(0.7115), np.float32(0.3906)] 
2024-12-30 18:48:39.835665: Epoch time: 32.33 s 
2024-12-30 18:48:40.414029:  
2024-12-30 18:48:40.414029: Epoch 63 
2024-12-30 18:48:40.419070: Current learning rate: 0.00409 
2024-12-30 18:49:12.494970: train_loss -0.8168 
2024-12-30 18:49:12.494970: val_loss -0.5083 
2024-12-30 18:49:12.501528: Pseudo dice [np.float32(0.7233), np.float32(0.332)] 
2024-12-30 18:49:12.505044: Epoch time: 32.08 s 
2024-12-30 18:49:13.085456:  
2024-12-30 18:49:13.086460: Epoch 64 
2024-12-30 18:49:13.092055: Current learning rate: 0.00399 
2024-12-30 18:49:45.636028: train_loss -0.8214 
2024-12-30 18:49:45.636028: val_loss -0.4845 
2024-12-30 18:49:45.642044: Pseudo dice [np.float32(0.7203), np.float32(0.3187)] 
2024-12-30 18:49:45.645086: Epoch time: 32.55 s 
2024-12-30 18:49:46.256220:  
2024-12-30 18:49:46.256220: Epoch 65 
2024-12-30 18:49:46.261811: Current learning rate: 0.00389 
2024-12-30 18:50:19.028362: train_loss -0.811 
2024-12-30 18:50:19.028362: val_loss -0.5003 
2024-12-30 18:50:19.034376: Pseudo dice [np.float32(0.7186), np.float32(0.3106)] 
2024-12-30 18:50:19.038385: Epoch time: 32.77 s 
2024-12-30 18:50:19.839159:  
2024-12-30 18:50:19.839159: Epoch 66 
2024-12-30 18:50:19.844176: Current learning rate: 0.00379 
2024-12-30 18:50:52.511421: train_loss -0.8176 
2024-12-30 18:50:52.512421: val_loss -0.4834 
2024-12-30 18:50:52.518938: Pseudo dice [np.float32(0.7218), np.float32(0.3506)] 
2024-12-30 18:50:52.522965: Epoch time: 32.67 s 
2024-12-30 18:50:53.109467:  
2024-12-30 18:50:53.109969: Epoch 67 
2024-12-30 18:50:53.115020: Current learning rate: 0.00369 
2024-12-30 18:51:25.887490: train_loss -0.8152 
2024-12-30 18:51:25.888493: val_loss -0.4773 
2024-12-30 18:51:25.895011: Pseudo dice [np.float32(0.734), np.float32(0.3126)] 
2024-12-30 18:51:25.898521: Epoch time: 32.78 s 
2024-12-30 18:51:26.487770:  
2024-12-30 18:51:26.487770: Epoch 68 
2024-12-30 18:51:26.493788: Current learning rate: 0.00359 
2024-12-30 18:51:59.221799: train_loss -0.8324 
2024-12-30 18:51:59.222302: val_loss -0.4692 
2024-12-30 18:51:59.228348: Pseudo dice [np.float32(0.7118), np.float32(0.3115)] 
2024-12-30 18:51:59.233387: Epoch time: 32.74 s 
2024-12-30 18:51:59.824166:  
2024-12-30 18:51:59.824166: Epoch 69 
2024-12-30 18:51:59.830722: Current learning rate: 0.00349 
2024-12-30 18:52:32.624233: train_loss -0.8326 
2024-12-30 18:52:32.624233: val_loss -0.4594 
2024-12-30 18:52:32.630748: Pseudo dice [np.float32(0.716), np.float32(0.3116)] 
2024-12-30 18:52:32.635760: Epoch time: 32.8 s 
2024-12-30 18:52:33.235034:  
2024-12-30 18:52:33.235537: Epoch 70 
2024-12-30 18:52:33.241554: Current learning rate: 0.00338 
2024-12-30 18:53:06.439798: train_loss -0.8334 
2024-12-30 18:53:06.440314: val_loss -0.4664 
2024-12-30 18:53:06.447428: Pseudo dice [np.float32(0.7188), np.float32(0.3054)] 
2024-12-30 18:53:06.451051: Epoch time: 33.21 s 
2024-12-30 18:53:07.044299:  
2024-12-30 18:53:07.044299: Epoch 71 
2024-12-30 18:53:07.050318: Current learning rate: 0.00328 
2024-12-30 18:53:40.039804: train_loss -0.8265 
2024-12-30 18:53:40.039804: val_loss -0.5115 
2024-12-30 18:53:40.045823: Pseudo dice [np.float32(0.7128), np.float32(0.3643)] 
2024-12-30 18:53:40.050863: Epoch time: 33.0 s 
2024-12-30 18:53:40.642672:  
2024-12-30 18:53:40.642672: Epoch 72 
2024-12-30 18:53:40.649772: Current learning rate: 0.00318 
2024-12-30 18:54:12.961939: train_loss -0.8307 
2024-12-30 18:54:12.961939: val_loss -0.4879 
2024-12-30 18:54:12.966951: Pseudo dice [np.float32(0.7066), np.float32(0.343)] 
2024-12-30 18:54:12.970982: Epoch time: 32.32 s 
2024-12-30 18:54:13.565063:  
2024-12-30 18:54:13.565063: Epoch 73 
2024-12-30 18:54:13.571077: Current learning rate: 0.00308 
2024-12-30 18:54:45.850088: train_loss -0.828 
2024-12-30 18:54:45.850594: val_loss -0.4634 
2024-12-30 18:54:45.857181: Pseudo dice [np.float32(0.6986), np.float32(0.2964)] 
2024-12-30 18:54:45.861211: Epoch time: 32.29 s 
2024-12-30 18:54:46.678319:  
2024-12-30 18:54:46.678319: Epoch 74 
2024-12-30 18:54:46.684904: Current learning rate: 0.00297 
2024-12-30 18:55:19.243475: train_loss -0.8439 
2024-12-30 18:55:19.243475: val_loss -0.4854 
2024-12-30 18:55:19.249499: Pseudo dice [np.float32(0.7124), np.float32(0.3242)] 
2024-12-30 18:55:19.254521: Epoch time: 32.57 s 
2024-12-30 18:55:19.863279:  
2024-12-30 18:55:19.864283: Epoch 75 
2024-12-30 18:55:19.869865: Current learning rate: 0.00287 
2024-12-30 18:55:52.893059: train_loss -0.8514 
2024-12-30 18:55:52.893059: val_loss -0.4759 
2024-12-30 18:55:52.900577: Pseudo dice [np.float32(0.7113), np.float32(0.3248)] 
2024-12-30 18:55:52.905085: Epoch time: 33.03 s 
2024-12-30 18:55:53.506418:  
2024-12-30 18:55:53.506946: Epoch 76 
2024-12-30 18:55:53.512963: Current learning rate: 0.00277 
2024-12-30 18:56:25.637561: train_loss -0.8391 
2024-12-30 18:56:25.638063: val_loss -0.4692 
2024-12-30 18:56:25.644175: Pseudo dice [np.float32(0.7045), np.float32(0.3391)] 
2024-12-30 18:56:25.648721: Epoch time: 32.13 s 
2024-12-30 18:56:26.248923:  
2024-12-30 18:56:26.250429: Epoch 77 
2024-12-30 18:56:26.256061: Current learning rate: 0.00266 
2024-12-30 18:56:58.485971: train_loss -0.849 
2024-12-30 18:56:58.486974: val_loss -0.4989 
2024-12-30 18:56:58.494064: Pseudo dice [np.float32(0.7185), np.float32(0.404)] 
2024-12-30 18:56:58.498611: Epoch time: 32.24 s 
2024-12-30 18:56:59.109071:  
2024-12-30 18:56:59.109071: Epoch 78 
2024-12-30 18:56:59.115669: Current learning rate: 0.00256 
2024-12-30 18:57:32.489299: train_loss -0.8459 
2024-12-30 18:57:32.490807: val_loss -0.4993 
2024-12-30 18:57:32.497361: Pseudo dice [np.float32(0.7069), np.float32(0.3749)] 
2024-12-30 18:57:32.502004: Epoch time: 33.38 s 
2024-12-30 18:57:33.101121:  
2024-12-30 18:57:33.101121: Epoch 79 
2024-12-30 18:57:33.108209: Current learning rate: 0.00245 
2024-12-30 18:58:06.051528: train_loss -0.8443 
2024-12-30 18:58:06.052532: val_loss -0.511 
2024-12-30 18:58:06.059077: Pseudo dice [np.float32(0.7227), np.float32(0.3961)] 
2024-12-30 18:58:06.062587: Epoch time: 32.95 s 
2024-12-30 18:58:06.660573:  
2024-12-30 18:58:06.660573: Epoch 80 
2024-12-30 18:58:06.668196: Current learning rate: 0.00235 
2024-12-30 18:58:39.177388: train_loss -0.8539 
2024-12-30 18:58:39.177891: val_loss -0.4588 
2024-12-30 18:58:39.182901: Pseudo dice [np.float32(0.713), np.float32(0.3192)] 
2024-12-30 18:58:39.187912: Epoch time: 32.52 s 
2024-12-30 18:58:40.021823:  
2024-12-30 18:58:40.022822: Epoch 81 
2024-12-30 18:58:40.028422: Current learning rate: 0.00224 
2024-12-30 18:59:12.919372: train_loss -0.8528 
2024-12-30 18:59:12.920371: val_loss -0.4744 
2024-12-30 18:59:12.926888: Pseudo dice [np.float32(0.7233), np.float32(0.3209)] 
2024-12-30 18:59:12.930935: Epoch time: 32.9 s 
2024-12-30 18:59:13.554704:  
2024-12-30 18:59:13.554704: Epoch 82 
2024-12-30 18:59:13.561265: Current learning rate: 0.00214 
2024-12-30 18:59:46.757431: train_loss -0.8588 
2024-12-30 18:59:46.757431: val_loss -0.5108 
2024-12-30 18:59:46.763988: Pseudo dice [np.float32(0.7153), np.float32(0.4133)] 
2024-12-30 18:59:46.768859: Epoch time: 33.2 s 
2024-12-30 18:59:47.331609:  
2024-12-30 18:59:47.332613: Epoch 83 
2024-12-30 18:59:47.338679: Current learning rate: 0.00203 
2024-12-30 19:00:20.098731: train_loss -0.8515 
2024-12-30 19:00:20.099234: val_loss -0.5027 
2024-12-30 19:00:20.106754: Pseudo dice [np.float32(0.735), np.float32(0.3312)] 
2024-12-30 19:00:20.110263: Epoch time: 32.77 s 
2024-12-30 19:00:20.681467:  
2024-12-30 19:00:20.681467: Epoch 84 
2024-12-30 19:00:20.688555: Current learning rate: 0.00192 
2024-12-30 19:00:53.564429: train_loss -0.8598 
2024-12-30 19:00:53.565433: val_loss -0.5396 
2024-12-30 19:00:53.572478: Pseudo dice [np.float32(0.7245), np.float32(0.4428)] 
2024-12-30 19:00:53.576500: Epoch time: 32.88 s 
2024-12-30 19:00:54.146751:  
2024-12-30 19:00:54.146751: Epoch 85 
2024-12-30 19:00:54.152825: Current learning rate: 0.00181 
2024-12-30 19:01:26.646136: train_loss -0.8564 
2024-12-30 19:01:26.647139: val_loss -0.4817 
2024-12-30 19:01:26.654020: Pseudo dice [np.float32(0.7214), np.float32(0.3162)] 
2024-12-30 19:01:26.660089: Epoch time: 32.5 s 
2024-12-30 19:01:27.221414:  
2024-12-30 19:01:27.221414: Epoch 86 
2024-12-30 19:01:27.227962: Current learning rate: 0.0017 
2024-12-30 19:01:59.709413: train_loss -0.8584 
2024-12-30 19:01:59.710925: val_loss -0.4467 
2024-12-30 19:01:59.717025: Pseudo dice [np.float32(0.7034), np.float32(0.264)] 
2024-12-30 19:01:59.721578: Epoch time: 32.49 s 
2024-12-30 19:02:00.283952:  
2024-12-30 19:02:00.283952: Epoch 87 
2024-12-30 19:02:00.289968: Current learning rate: 0.00159 
2024-12-30 19:02:32.962487: train_loss -0.8638 
2024-12-30 19:02:32.963003: val_loss -0.5193 
2024-12-30 19:02:32.969017: Pseudo dice [np.float32(0.7286), np.float32(0.4069)] 
2024-12-30 19:02:32.974046: Epoch time: 32.68 s 
2024-12-30 19:02:33.537228:  
2024-12-30 19:02:33.537228: Epoch 88 
2024-12-30 19:02:33.543823: Current learning rate: 0.00148 
2024-12-30 19:03:05.934559: train_loss -0.8703 
2024-12-30 19:03:05.935061: val_loss -0.4973 
2024-12-30 19:03:05.941596: Pseudo dice [np.float32(0.7215), np.float32(0.3284)] 
2024-12-30 19:03:05.945625: Epoch time: 32.4 s 
2024-12-30 19:03:06.749795:  
2024-12-30 19:03:06.749795: Epoch 89 
2024-12-30 19:03:06.755857: Current learning rate: 0.00137 
2024-12-30 19:03:39.246105: train_loss -0.8718 
2024-12-30 19:03:39.246607: val_loss -0.4949 
2024-12-30 19:03:39.252706: Pseudo dice [np.float32(0.6975), np.float32(0.3534)] 
2024-12-30 19:03:39.257234: Epoch time: 32.5 s 
2024-12-30 19:03:39.827849:  
2024-12-30 19:03:39.827849: Epoch 90 
2024-12-30 19:03:39.834480: Current learning rate: 0.00126 
2024-12-30 19:04:13.005079: train_loss -0.8687 
2024-12-30 19:04:13.005606: val_loss -0.4622 
2024-12-30 19:04:13.012629: Pseudo dice [np.float32(0.7234), np.float32(0.2717)] 
2024-12-30 19:04:13.018173: Epoch time: 33.18 s 
2024-12-30 19:04:13.601784:  
2024-12-30 19:04:13.602787: Epoch 91 
2024-12-30 19:04:13.608503: Current learning rate: 0.00115 
2024-12-30 19:04:47.081986: train_loss -0.8702 
2024-12-30 19:04:47.081986: val_loss -0.4988 
2024-12-30 19:04:47.089922: Pseudo dice [np.float32(0.7335), np.float32(0.355)] 
2024-12-30 19:04:47.095484: Epoch time: 33.48 s 
2024-12-30 19:04:47.694643:  
2024-12-30 19:04:47.694643: Epoch 92 
2024-12-30 19:04:47.701239: Current learning rate: 0.00103 
2024-12-30 19:05:20.573414: train_loss -0.8699 
2024-12-30 19:05:20.573414: val_loss -0.4926 
2024-12-30 19:05:20.581508: Pseudo dice [np.float32(0.7108), np.float32(0.3405)] 
2024-12-30 19:05:20.586059: Epoch time: 32.88 s 
2024-12-30 19:05:21.164350:  
2024-12-30 19:05:21.165353: Epoch 93 
2024-12-30 19:05:21.171421: Current learning rate: 0.00091 
2024-12-30 19:05:53.615718: train_loss -0.8607 
2024-12-30 19:05:53.616722: val_loss -0.473 
2024-12-30 19:05:53.623324: Pseudo dice [np.float32(0.6891), np.float32(0.325)] 
2024-12-30 19:05:53.627339: Epoch time: 32.45 s 
2024-12-30 19:05:54.191068:  
2024-12-30 19:05:54.191068: Epoch 94 
2024-12-30 19:05:54.198161: Current learning rate: 0.00079 
2024-12-30 19:06:26.900548: train_loss -0.8744 
2024-12-30 19:06:26.900548: val_loss -0.4548 
2024-12-30 19:06:26.908114: Pseudo dice [np.float32(0.7072), np.float32(0.2782)] 
2024-12-30 19:06:26.912653: Epoch time: 32.71 s 
2024-12-30 19:06:27.509505:  
2024-12-30 19:06:27.509505: Epoch 95 
2024-12-30 19:06:27.515528: Current learning rate: 0.00067 
2024-12-30 19:07:00.435154: train_loss -0.8657 
2024-12-30 19:07:00.435664: val_loss -0.4736 
2024-12-30 19:07:00.442716: Pseudo dice [np.float32(0.7057), np.float32(0.3122)] 
2024-12-30 19:07:00.446784: Epoch time: 32.93 s 
2024-12-30 19:07:01.006793:  
2024-12-30 19:07:01.008300: Epoch 96 
2024-12-30 19:07:01.014336: Current learning rate: 0.00055 
2024-12-30 19:07:33.829645: train_loss -0.8797 
2024-12-30 19:07:33.830648: val_loss -0.5068 
2024-12-30 19:07:33.838690: Pseudo dice [np.float32(0.7204), np.float32(0.366)] 
2024-12-30 19:07:33.842776: Epoch time: 32.82 s 
2024-12-30 19:07:34.416532:  
2024-12-30 19:07:34.416532: Epoch 97 
2024-12-30 19:07:34.423080: Current learning rate: 0.00043 
2024-12-30 19:08:07.036326: train_loss -0.8738 
2024-12-30 19:08:07.036326: val_loss -0.4851 
2024-12-30 19:08:07.043885: Pseudo dice [np.float32(0.7387), np.float32(0.3317)] 
2024-12-30 19:08:07.047912: Epoch time: 32.62 s 
2024-12-30 19:08:07.854410:  
2024-12-30 19:08:07.855414: Epoch 98 
2024-12-30 19:08:07.860955: Current learning rate: 0.0003 
2024-12-30 19:08:40.834889: train_loss -0.871 
2024-12-30 19:08:40.835892: val_loss -0.4869 
2024-12-30 19:08:40.842406: Pseudo dice [np.float32(0.7373), np.float32(0.2999)] 
2024-12-30 19:08:40.846957: Epoch time: 32.98 s 
2024-12-30 19:08:41.430379:  
2024-12-30 19:08:41.430889: Epoch 99 
2024-12-30 19:08:41.437001: Current learning rate: 0.00016 
2024-12-30 19:09:14.278297: train_loss -0.8747 
2024-12-30 19:09:14.278800: val_loss -0.5093 
2024-12-30 19:09:14.285907: Pseudo dice [np.float32(0.7104), np.float32(0.4011)] 
2024-12-30 19:09:14.289482: Epoch time: 32.85 s 
2024-12-30 19:09:15.135827: Training done. 
2024-12-30 19:09:15.183076: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-30 19:09:15.193589: The split file contains 5 splits. 
2024-12-30 19:09:15.202102: Desired fold for training: 0 
2024-12-30 19:09:15.210614: This split has 224 training and 57 validation cases. 
2024-12-30 19:09:15.220126: predicting pancreas_021 
2024-12-30 19:09:15.231143: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2024-12-30 19:09:17.679343: predicting pancreas_024 
2024-12-30 19:09:17.691850: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2024-12-30 19:09:18.227731: predicting pancreas_035 
2024-12-30 19:09:18.239744: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2024-12-30 19:09:18.588327: predicting pancreas_040 
2024-12-30 19:09:18.594328: pancreas_040, shape torch.Size([1, 45, 526, 526]), rank 0 
2024-12-30 19:09:19.337270: predicting pancreas_042 
2024-12-30 19:09:19.345779: pancreas_042, shape torch.Size([1, 51, 537, 537]), rank 0 
2024-12-30 19:09:20.210451: predicting pancreas_056 
2024-12-30 19:09:20.217958: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2024-12-30 19:09:20.648535: predicting pancreas_067 
2024-12-30 19:09:20.661042: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2024-12-30 19:09:22.431378: predicting pancreas_075 
2024-12-30 19:09:22.447901: pancreas_075, shape torch.Size([1, 121, 521, 521]), rank 0 
2024-12-30 19:09:25.380477: predicting pancreas_086 
2024-12-30 19:09:25.411009: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2024-12-30 19:09:26.412168: predicting pancreas_089 
2024-12-30 19:09:26.423677: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-30 19:09:26.973493: predicting pancreas_092 
2024-12-30 19:09:26.995049: pancreas_092, shape torch.Size([1, 92, 513, 513]), rank 0 
2024-12-30 19:09:28.982420: predicting pancreas_094 
2024-12-30 19:09:28.996927: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2024-12-30 19:09:29.518117: predicting pancreas_095 
2024-12-30 19:09:29.529629: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2024-12-30 19:09:30.111110: predicting pancreas_098 
2024-12-30 19:09:30.121615: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2024-12-30 19:09:33.156409: predicting pancreas_109 
2024-12-30 19:09:33.176422: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2024-12-30 19:09:33.796706: predicting pancreas_110 
2024-12-30 19:09:33.808717: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2024-12-30 19:09:35.535460: predicting pancreas_114 
2024-12-30 19:09:35.550474: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2024-12-30 19:09:36.166372: predicting pancreas_119 
2024-12-30 19:09:36.180386: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2024-12-30 19:09:37.881796: predicting pancreas_138 
2024-12-30 19:09:37.898804: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2024-12-30 19:09:39.893443: predicting pancreas_145 
2024-12-30 19:09:39.910454: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2024-12-30 19:09:41.886784: predicting pancreas_148 
2024-12-30 19:09:41.903798: pancreas_148, shape torch.Size([1, 42, 486, 486]), rank 0 
2024-12-30 19:09:42.172081: predicting pancreas_169 
2024-12-30 19:09:42.179081: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2024-12-30 19:09:42.738221: predicting pancreas_170 
2024-12-30 19:09:42.749229: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2024-12-30 19:09:43.431203: predicting pancreas_172 
2024-12-30 19:09:43.442708: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2024-12-30 19:09:44.041894: predicting pancreas_175 
2024-12-30 19:09:44.055404: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-30 19:09:44.619143: predicting pancreas_180 
2024-12-30 19:09:44.630782: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2024-12-30 19:09:45.279212: predicting pancreas_191 
2024-12-30 19:09:45.290722: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2024-12-30 19:09:45.615623: predicting pancreas_193 
2024-12-30 19:09:45.625133: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2024-12-30 19:09:46.369344: predicting pancreas_212 
2024-12-30 19:09:46.389361: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2024-12-30 19:09:48.488001: predicting pancreas_215 
2024-12-30 19:09:48.511518: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2024-12-30 19:09:49.120435: predicting pancreas_222 
2024-12-30 19:09:49.130937: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2024-12-30 19:09:49.556282: predicting pancreas_235 
2024-12-30 19:09:49.564791: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2024-12-30 19:09:50.068212: predicting pancreas_241 
2024-12-30 19:09:50.080222: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2024-12-30 19:09:50.706780: predicting pancreas_242 
2024-12-30 19:09:50.720802: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2024-12-30 19:09:52.774774: predicting pancreas_244 
2024-12-30 19:09:52.790795: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2024-12-30 19:09:54.802742: predicting pancreas_246 
2024-12-30 19:09:54.820754: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2024-12-30 19:09:56.926534: predicting pancreas_247 
2024-12-30 19:09:56.943548: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2024-12-30 19:09:57.436897: predicting pancreas_264 
2024-12-30 19:09:57.446405: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2024-12-30 19:09:59.805445: predicting pancreas_265 
2024-12-30 19:09:59.823461: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2024-12-30 19:10:01.395904: predicting pancreas_266 
2024-12-30 19:10:01.406408: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2024-12-30 19:10:03.264981: predicting pancreas_267 
2024-12-30 19:10:03.277486: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2024-12-30 19:10:03.805168: predicting pancreas_275 
2024-12-30 19:10:03.813675: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2024-12-30 19:10:04.458387: predicting pancreas_279 
2024-12-30 19:10:04.467893: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2024-12-30 19:10:04.997223: predicting pancreas_287 
2024-12-30 19:10:05.006729: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2024-12-30 19:10:05.589629: predicting pancreas_301 
2024-12-30 19:10:05.600135: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2024-12-30 19:10:07.335351: predicting pancreas_323 
2024-12-30 19:10:07.345857: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2024-12-30 19:10:09.275129: predicting pancreas_336 
2024-12-30 19:10:09.289634: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2024-12-30 19:10:11.083851: predicting pancreas_344 
2024-12-30 19:10:11.098356: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2024-12-30 19:10:11.684796: predicting pancreas_351 
2024-12-30 19:10:11.698302: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2024-12-30 19:10:12.236140: predicting pancreas_354 
2024-12-30 19:10:12.245646: pancreas_354, shape torch.Size([1, 81, 529, 529]), rank 0 
2024-12-30 19:10:14.014282: predicting pancreas_372 
2024-12-30 19:10:14.028795: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2024-12-30 19:10:15.995421: predicting pancreas_377 
2024-12-30 19:10:16.013433: pancreas_377, shape torch.Size([1, 55, 551, 551]), rank 0 
2024-12-30 19:10:17.120589: predicting pancreas_387 
2024-12-30 19:10:17.129096: pancreas_387, shape torch.Size([1, 50, 498, 498]), rank 0 
2024-12-30 19:10:17.465638: predicting pancreas_391 
2024-12-30 19:10:17.472140: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2024-12-30 19:10:19.322300: predicting pancreas_392 
2024-12-30 19:10:19.339808: pancreas_392, shape torch.Size([1, 57, 448, 448]), rank 0 
2024-12-30 19:10:19.688091: predicting pancreas_410 
2024-12-30 19:10:19.696596: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2024-12-30 19:10:20.218426: predicting pancreas_412 
2024-12-30 19:10:20.226938: pancreas_412, shape torch.Size([1, 164, 584, 584]), rank 0 
2024-12-30 19:10:35.479737: Validation complete 
2024-12-30 19:10:35.480739: Mean Validation Dice:  0.47398606787185793 
