2025-01-11 08:49:53.090633: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.75 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-11 08:49:53.094632: self.oversample_foreground_percent 0.75 
2025-01-11 08:49:53.098634: do_dummy_2d_data_aug: True 
2025-01-11 08:49:53.134383: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-11 08:49:53.140386: The split file contains 5 splits. 
2025-01-11 08:49:53.142386: Desired fold for training: 0 
2025-01-11 08:49:53.145386: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [32, 192, 160], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-11 08:50:00.806064: unpacking dataset... 
2025-01-11 08:50:01.173839: unpacking done... 
2025-01-11 08:50:04.067714:  
2025-01-11 08:50:04.067714: Epoch 0 
2025-01-11 08:50:04.072728: Current learning rate: 0.01 
2025-01-11 08:50:47.018279: train_loss 0.1478 
2025-01-11 08:50:47.018782: val_loss 0.0478 
2025-01-11 08:50:47.023794: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-11 08:50:47.027304: Epoch time: 42.95 s 
2025-01-11 08:50:47.029810: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-11 08:50:47.680009:  
2025-01-11 08:50:47.680009: Epoch 1 
2025-01-11 08:50:47.685053: Current learning rate: 0.00996 
2025-01-11 08:51:26.275919: train_loss -0.0277 
2025-01-11 08:51:26.275919: val_loss -0.0956 
2025-01-11 08:51:26.281934: Pseudo dice [np.float32(0.4276), np.float32(0.0)] 
2025-01-11 08:51:26.284440: Epoch time: 38.6 s 
2025-01-11 08:51:26.287946: Yayy! New best EMA pseudo Dice: 0.021400000900030136 
2025-01-11 08:51:27.019961:  
2025-01-11 08:51:27.020464: Epoch 2 
2025-01-11 08:51:27.025474: Current learning rate: 0.00993 
2025-01-11 08:52:05.599883: train_loss -0.1247 
2025-01-11 08:52:05.600404: val_loss -0.1658 
2025-01-11 08:52:05.605990: Pseudo dice [np.float32(0.5063), np.float32(0.0)] 
2025-01-11 08:52:05.609595: Epoch time: 38.58 s 
2025-01-11 08:52:05.612635: Yayy! New best EMA pseudo Dice: 0.044599998742341995 
2025-01-11 08:52:06.372040:  
2025-01-11 08:52:06.372040: Epoch 3 
2025-01-11 08:52:06.377607: Current learning rate: 0.00989 
2025-01-11 08:52:44.961832: train_loss -0.1909 
2025-01-11 08:52:44.962335: val_loss -0.2538 
2025-01-11 08:52:44.967346: Pseudo dice [np.float32(0.5868), np.float32(0.0)] 
2025-01-11 08:52:44.970855: Epoch time: 38.59 s 
2025-01-11 08:52:44.973361: Yayy! New best EMA pseudo Dice: 0.06939999759197235 
2025-01-11 08:52:45.717620:  
2025-01-11 08:52:45.717620: Epoch 4 
2025-01-11 08:52:45.723179: Current learning rate: 0.00986 
2025-01-11 08:53:24.323009: train_loss -0.2757 
2025-01-11 08:53:24.323009: val_loss -0.3014 
2025-01-11 08:53:24.329144: Pseudo dice [np.float32(0.57), np.float32(0.3077)] 
2025-01-11 08:53:24.332179: Epoch time: 38.61 s 
2025-01-11 08:53:24.334685: Yayy! New best EMA pseudo Dice: 0.10639999806880951 
2025-01-11 08:53:25.220354:  
2025-01-11 08:53:25.220354: Epoch 5 
2025-01-11 08:53:25.225420: Current learning rate: 0.00982 
2025-01-11 08:54:03.809235: train_loss -0.3036 
2025-01-11 08:54:03.810238: val_loss -0.3286 
2025-01-11 08:54:03.816755: Pseudo dice [np.float32(0.5595), np.float32(0.3748)] 
2025-01-11 08:54:03.819262: Epoch time: 38.59 s 
2025-01-11 08:54:03.822772: Yayy! New best EMA pseudo Dice: 0.14249999821186066 
2025-01-11 08:54:04.542100:  
2025-01-11 08:54:04.542100: Epoch 6 
2025-01-11 08:54:04.547177: Current learning rate: 0.00978 
2025-01-11 08:54:43.147212: train_loss -0.3363 
2025-01-11 08:54:43.147733: val_loss -0.3819 
2025-01-11 08:54:43.153371: Pseudo dice [np.float32(0.6015), np.float32(0.3781)] 
2025-01-11 08:54:43.156434: Epoch time: 38.61 s 
2025-01-11 08:54:43.159492: Yayy! New best EMA pseudo Dice: 0.17720000445842743 
2025-01-11 08:54:43.929238:  
2025-01-11 08:54:43.929238: Epoch 7 
2025-01-11 08:54:43.934911: Current learning rate: 0.00975 
2025-01-11 08:55:22.506053: train_loss -0.3545 
2025-01-11 08:55:22.507056: val_loss -0.3023 
2025-01-11 08:55:22.512730: Pseudo dice [np.float32(0.5717), np.float32(0.3089)] 
2025-01-11 08:55:22.515279: Epoch time: 38.58 s 
2025-01-11 08:55:22.518834: Yayy! New best EMA pseudo Dice: 0.20350000262260437 
2025-01-11 08:55:23.266727:  
2025-01-11 08:55:23.267727: Epoch 8 
2025-01-11 08:55:23.273246: Current learning rate: 0.00971 
2025-01-11 08:56:01.863133: train_loss -0.3376 
2025-01-11 08:56:01.863636: val_loss -0.3254 
2025-01-11 08:56:01.869702: Pseudo dice [np.float32(0.5606), np.float32(0.3386)] 
2025-01-11 08:56:01.872228: Epoch time: 38.6 s 
2025-01-11 08:56:01.875754: Yayy! New best EMA pseudo Dice: 0.2281000018119812 
2025-01-11 08:56:02.631722:  
2025-01-11 08:56:02.632225: Epoch 9 
2025-01-11 08:56:02.637274: Current learning rate: 0.00968 
2025-01-11 08:56:41.239094: train_loss -0.381 
2025-01-11 08:56:41.239598: val_loss -0.4128 
2025-01-11 08:56:41.244613: Pseudo dice [np.float32(0.631), np.float32(0.4247)] 
2025-01-11 08:56:41.248122: Epoch time: 38.61 s 
2025-01-11 08:56:41.250628: Yayy! New best EMA pseudo Dice: 0.2581000030040741 
2025-01-11 08:56:41.975707:  
2025-01-11 08:56:41.976707: Epoch 10 
2025-01-11 08:56:41.982283: Current learning rate: 0.00964 
2025-01-11 08:57:20.668466: train_loss -0.3813 
2025-01-11 08:57:20.669467: val_loss -0.3687 
2025-01-11 08:57:20.674672: Pseudo dice [np.float32(0.6121), np.float32(0.3642)] 
2025-01-11 08:57:20.678185: Epoch time: 38.69 s 
2025-01-11 08:57:20.681197: Yayy! New best EMA pseudo Dice: 0.28110000491142273 
2025-01-11 08:57:21.428988:  
2025-01-11 08:57:21.428988: Epoch 11 
2025-01-11 08:57:21.434551: Current learning rate: 0.0096 
2025-01-11 08:58:00.014433: train_loss -0.3922 
2025-01-11 08:58:00.015436: val_loss -0.3972 
2025-01-11 08:58:00.020984: Pseudo dice [np.float32(0.6357), np.float32(0.4036)] 
2025-01-11 08:58:00.024517: Epoch time: 38.59 s 
2025-01-11 08:58:00.028042: Yayy! New best EMA pseudo Dice: 0.3050000071525574 
2025-01-11 08:58:00.782222:  
2025-01-11 08:58:00.783225: Epoch 12 
2025-01-11 08:58:00.787250: Current learning rate: 0.00957 
2025-01-11 08:58:39.355350: train_loss -0.3839 
2025-01-11 08:58:39.356361: val_loss -0.4344 
2025-01-11 08:58:39.361395: Pseudo dice [np.float32(0.6419), np.float32(0.4439)] 
2025-01-11 08:58:39.364915: Epoch time: 38.57 s 
2025-01-11 08:58:39.367935: Yayy! New best EMA pseudo Dice: 0.3287000060081482 
2025-01-11 08:58:40.303926:  
2025-01-11 08:58:40.304929: Epoch 13 
2025-01-11 08:58:40.309498: Current learning rate: 0.00953 
2025-01-11 08:59:18.874810: train_loss -0.4221 
2025-01-11 08:59:18.875812: val_loss -0.4107 
2025-01-11 08:59:18.880831: Pseudo dice [np.float32(0.624), np.float32(0.4279)] 
2025-01-11 08:59:18.884344: Epoch time: 38.57 s 
2025-01-11 08:59:18.887405: Yayy! New best EMA pseudo Dice: 0.34850001335144043 
2025-01-11 08:59:19.633722:  
2025-01-11 08:59:19.634726: Epoch 14 
2025-01-11 08:59:19.639797: Current learning rate: 0.00949 
2025-01-11 08:59:58.192091: train_loss -0.4398 
2025-01-11 08:59:58.193095: val_loss -0.4367 
2025-01-11 08:59:58.198106: Pseudo dice [np.float32(0.6733), np.float32(0.4159)] 
2025-01-11 08:59:58.202113: Epoch time: 38.56 s 
2025-01-11 08:59:58.205622: Yayy! New best EMA pseudo Dice: 0.36809998750686646 
2025-01-11 08:59:58.954575:  
2025-01-11 08:59:58.955084: Epoch 15 
2025-01-11 08:59:58.960191: Current learning rate: 0.00946 
2025-01-11 09:00:37.563693: train_loss -0.4564 
2025-01-11 09:00:37.563693: val_loss -0.4845 
2025-01-11 09:00:37.569764: Pseudo dice [np.float32(0.6882), np.float32(0.4861)] 
2025-01-11 09:00:37.573386: Epoch time: 38.61 s 
2025-01-11 09:00:37.576427: Yayy! New best EMA pseudo Dice: 0.38999998569488525 
2025-01-11 09:00:38.312338:  
2025-01-11 09:00:38.312338: Epoch 16 
2025-01-11 09:00:38.317875: Current learning rate: 0.00942 
2025-01-11 09:01:16.886915: train_loss -0.4708 
2025-01-11 09:01:16.886915: val_loss -0.426 
2025-01-11 09:01:16.892933: Pseudo dice [np.float32(0.6766), np.float32(0.3737)] 
2025-01-11 09:01:16.896946: Epoch time: 38.58 s 
2025-01-11 09:01:16.899453: Yayy! New best EMA pseudo Dice: 0.4034999907016754 
2025-01-11 09:01:17.672734:  
2025-01-11 09:01:17.672734: Epoch 17 
2025-01-11 09:01:17.678267: Current learning rate: 0.00939 
2025-01-11 09:01:56.257772: train_loss -0.4394 
2025-01-11 09:01:56.258775: val_loss -0.4423 
2025-01-11 09:01:56.264347: Pseudo dice [np.float32(0.6949), np.float32(0.3954)] 
2025-01-11 09:01:56.267378: Epoch time: 38.59 s 
2025-01-11 09:01:56.270930: Yayy! New best EMA pseudo Dice: 0.41769999265670776 
2025-01-11 09:01:57.019262:  
2025-01-11 09:01:57.019262: Epoch 18 
2025-01-11 09:01:57.024806: Current learning rate: 0.00935 
2025-01-11 09:02:35.619254: train_loss -0.4429 
2025-01-11 09:02:35.619254: val_loss -0.4339 
2025-01-11 09:02:35.625267: Pseudo dice [np.float32(0.6649), np.float32(0.4056)] 
2025-01-11 09:02:35.628275: Epoch time: 38.6 s 
2025-01-11 09:02:35.631785: Yayy! New best EMA pseudo Dice: 0.4293999969959259 
2025-01-11 09:02:36.396908:  
2025-01-11 09:02:36.397419: Epoch 19 
2025-01-11 09:02:36.402467: Current learning rate: 0.00931 
2025-01-11 09:03:15.012415: train_loss -0.4674 
2025-01-11 09:03:15.012918: val_loss -0.4288 
2025-01-11 09:03:15.018463: Pseudo dice [np.float32(0.6541), np.float32(0.4127)] 
2025-01-11 09:03:15.022034: Epoch time: 38.62 s 
2025-01-11 09:03:15.025100: Yayy! New best EMA pseudo Dice: 0.4397999942302704 
2025-01-11 09:03:15.990934:  
2025-01-11 09:03:15.991938: Epoch 20 
2025-01-11 09:03:15.996983: Current learning rate: 0.00928 
2025-01-11 09:03:54.608052: train_loss -0.4853 
2025-01-11 09:03:54.609053: val_loss -0.4611 
2025-01-11 09:03:54.614573: Pseudo dice [np.float32(0.6909), np.float32(0.4521)] 
2025-01-11 09:03:54.617083: Epoch time: 38.62 s 
2025-01-11 09:03:54.620596: Yayy! New best EMA pseudo Dice: 0.453000009059906 
2025-01-11 09:03:55.390735:  
2025-01-11 09:03:55.390735: Epoch 21 
2025-01-11 09:03:55.396308: Current learning rate: 0.00924 
2025-01-11 09:04:34.008389: train_loss -0.4784 
2025-01-11 09:04:34.008907: val_loss -0.4537 
2025-01-11 09:04:34.014494: Pseudo dice [np.float32(0.6852), np.float32(0.4348)] 
2025-01-11 09:04:34.018053: Epoch time: 38.62 s 
2025-01-11 09:04:34.021094: Yayy! New best EMA pseudo Dice: 0.46369999647140503 
2025-01-11 09:04:34.749837:  
2025-01-11 09:04:34.750842: Epoch 22 
2025-01-11 09:04:34.755392: Current learning rate: 0.0092 
2025-01-11 09:05:13.327075: train_loss -0.4931 
2025-01-11 09:05:13.328579: val_loss -0.4669 
2025-01-11 09:05:13.334600: Pseudo dice [np.float32(0.7069), np.float32(0.4554)] 
2025-01-11 09:05:13.337109: Epoch time: 38.58 s 
2025-01-11 09:05:13.341120: Yayy! New best EMA pseudo Dice: 0.47540000081062317 
2025-01-11 09:05:14.111984:  
2025-01-11 09:05:14.112486: Epoch 23 
2025-01-11 09:05:14.117497: Current learning rate: 0.00917 
2025-01-11 09:05:52.714634: train_loss -0.5194 
2025-01-11 09:05:52.714634: val_loss -0.4908 
2025-01-11 09:05:52.722157: Pseudo dice [np.float32(0.699), np.float32(0.4588)] 
2025-01-11 09:05:52.726167: Epoch time: 38.6 s 
2025-01-11 09:05:52.729676: Yayy! New best EMA pseudo Dice: 0.48579999804496765 
2025-01-11 09:05:53.457536:  
2025-01-11 09:05:53.458038: Epoch 24 
2025-01-11 09:05:53.463050: Current learning rate: 0.00913 
2025-01-11 09:06:32.184040: train_loss -0.5097 
2025-01-11 09:06:32.184040: val_loss -0.4672 
2025-01-11 09:06:32.190062: Pseudo dice [np.float32(0.7082), np.float32(0.4579)] 
2025-01-11 09:06:32.194580: Epoch time: 38.73 s 
2025-01-11 09:06:32.197595: Yayy! New best EMA pseudo Dice: 0.49549999833106995 
2025-01-11 09:06:32.963123:  
2025-01-11 09:06:32.964127: Epoch 25 
2025-01-11 09:06:32.968688: Current learning rate: 0.0091 
2025-01-11 09:07:11.574224: train_loss -0.4942 
2025-01-11 09:07:11.575227: val_loss -0.4749 
2025-01-11 09:07:11.580239: Pseudo dice [np.float32(0.7044), np.float32(0.405)] 
2025-01-11 09:07:11.583745: Epoch time: 38.61 s 
2025-01-11 09:07:11.586752: Yayy! New best EMA pseudo Dice: 0.5013999938964844 
2025-01-11 09:07:12.313968:  
2025-01-11 09:07:12.313968: Epoch 26 
2025-01-11 09:07:12.320016: Current learning rate: 0.00906 
2025-01-11 09:07:50.924436: train_loss -0.4809 
2025-01-11 09:07:50.924436: val_loss -0.4692 
2025-01-11 09:07:50.929049: Pseudo dice [np.float32(0.6871), np.float32(0.4529)] 
2025-01-11 09:07:50.933070: Epoch time: 38.61 s 
2025-01-11 09:07:50.935584: Yayy! New best EMA pseudo Dice: 0.5083000063896179 
2025-01-11 09:07:51.677863:  
2025-01-11 09:07:51.677863: Epoch 27 
2025-01-11 09:07:51.683390: Current learning rate: 0.00902 
2025-01-11 09:08:30.282583: train_loss -0.4952 
2025-01-11 09:08:30.283586: val_loss -0.4634 
2025-01-11 09:08:30.287594: Pseudo dice [np.float32(0.7357), np.float32(0.3383)] 
2025-01-11 09:08:30.291103: Epoch time: 38.6 s 
2025-01-11 09:08:30.294608: Yayy! New best EMA pseudo Dice: 0.5112000107765198 
2025-01-11 09:08:31.242655:  
2025-01-11 09:08:31.242655: Epoch 28 
2025-01-11 09:08:31.245665: Current learning rate: 0.00899 
2025-01-11 09:09:09.848489: train_loss -0.5224 
2025-01-11 09:09:09.849492: val_loss -0.5324 
2025-01-11 09:09:09.854533: Pseudo dice [np.float32(0.7231), np.float32(0.5698)] 
2025-01-11 09:09:09.857317: Epoch time: 38.61 s 
2025-01-11 09:09:09.860862: Yayy! New best EMA pseudo Dice: 0.5246999859809875 
2025-01-11 09:09:10.589588:  
2025-01-11 09:09:10.590591: Epoch 29 
2025-01-11 09:09:10.595151: Current learning rate: 0.00895 
2025-01-11 09:09:49.200600: train_loss -0.5165 
2025-01-11 09:09:49.200600: val_loss -0.4928 
2025-01-11 09:09:49.206665: Pseudo dice [np.float32(0.7368), np.float32(0.4061)] 
2025-01-11 09:09:49.209795: Epoch time: 38.61 s 
2025-01-11 09:09:49.212859: Yayy! New best EMA pseudo Dice: 0.5293999910354614 
2025-01-11 09:09:49.957436:  
2025-01-11 09:09:49.957938: Epoch 30 
2025-01-11 09:09:49.962949: Current learning rate: 0.00891 
2025-01-11 09:10:28.584407: train_loss -0.5137 
2025-01-11 09:10:28.584407: val_loss -0.4819 
2025-01-11 09:10:28.590996: Pseudo dice [np.float32(0.7099), np.float32(0.4588)] 
2025-01-11 09:10:28.594045: Epoch time: 38.63 s 
2025-01-11 09:10:28.597132: Yayy! New best EMA pseudo Dice: 0.5349000096321106 
2025-01-11 09:10:29.344077:  
2025-01-11 09:10:29.344077: Epoch 31 
2025-01-11 09:10:29.349119: Current learning rate: 0.00888 
2025-01-11 09:11:07.947921: train_loss -0.5342 
2025-01-11 09:11:07.948924: val_loss -0.5267 
2025-01-11 09:11:07.954446: Pseudo dice [np.float32(0.7304), np.float32(0.4849)] 
2025-01-11 09:11:07.957957: Epoch time: 38.6 s 
2025-01-11 09:11:07.961519: Yayy! New best EMA pseudo Dice: 0.5421000123023987 
2025-01-11 09:11:08.697856:  
2025-01-11 09:11:08.698856: Epoch 32 
2025-01-11 09:11:08.703968: Current learning rate: 0.00884 
2025-01-11 09:11:47.265021: train_loss -0.5135 
2025-01-11 09:11:47.266024: val_loss -0.5232 
2025-01-11 09:11:47.271039: Pseudo dice [np.float32(0.7338), np.float32(0.5146)] 
2025-01-11 09:11:47.274544: Epoch time: 38.57 s 
2025-01-11 09:11:47.277552: Yayy! New best EMA pseudo Dice: 0.5504000186920166 
2025-01-11 09:11:48.035291:  
2025-01-11 09:11:48.036294: Epoch 33 
2025-01-11 09:11:48.040847: Current learning rate: 0.0088 
2025-01-11 09:12:26.660754: train_loss -0.5228 
2025-01-11 09:12:26.661760: val_loss -0.5133 
2025-01-11 09:12:26.666778: Pseudo dice [np.float32(0.7191), np.float32(0.5108)] 
2025-01-11 09:12:26.670787: Epoch time: 38.63 s 
2025-01-11 09:12:26.673296: Yayy! New best EMA pseudo Dice: 0.5568000078201294 
2025-01-11 09:12:27.478637:  
2025-01-11 09:12:27.479139: Epoch 34 
2025-01-11 09:12:27.484150: Current learning rate: 0.00877 
2025-01-11 09:13:06.105051: train_loss -0.5506 
2025-01-11 09:13:06.106052: val_loss -0.4855 
2025-01-11 09:13:06.111574: Pseudo dice [np.float32(0.7457), np.float32(0.3825)] 
2025-01-11 09:13:06.115087: Epoch time: 38.63 s 
2025-01-11 09:13:06.117597: Yayy! New best EMA pseudo Dice: 0.5575000047683716 
2025-01-11 09:13:06.895028:  
2025-01-11 09:13:06.895028: Epoch 35 
2025-01-11 09:13:06.901045: Current learning rate: 0.00873 
2025-01-11 09:13:45.493971: train_loss -0.5369 
2025-01-11 09:13:45.494976: val_loss -0.4515 
2025-01-11 09:13:45.500530: Pseudo dice [np.float32(0.721), np.float32(0.3321)] 
2025-01-11 09:13:45.503560: Epoch time: 38.6 s 
2025-01-11 09:13:46.245863:  
2025-01-11 09:13:46.246863: Epoch 36 
2025-01-11 09:13:46.251974: Current learning rate: 0.00869 
2025-01-11 09:14:24.837921: train_loss -0.5344 
2025-01-11 09:14:24.837921: val_loss -0.5342 
2025-01-11 09:14:24.843940: Pseudo dice [np.float32(0.736), np.float32(0.5073)] 
2025-01-11 09:14:24.846446: Epoch time: 38.59 s 
2025-01-11 09:14:24.849953: Yayy! New best EMA pseudo Dice: 0.5612000226974487 
2025-01-11 09:14:25.611782:  
2025-01-11 09:14:25.612786: Epoch 37 
2025-01-11 09:14:25.617340: Current learning rate: 0.00866 
2025-01-11 09:15:04.203736: train_loss -0.5601 
2025-01-11 09:15:04.204242: val_loss -0.449 
2025-01-11 09:15:04.209354: Pseudo dice [np.float32(0.7076), np.float32(0.3729)] 
2025-01-11 09:15:04.211892: Epoch time: 38.59 s 
2025-01-11 09:15:04.799215:  
2025-01-11 09:15:04.799215: Epoch 38 
2025-01-11 09:15:04.804226: Current learning rate: 0.00862 
2025-01-11 09:15:43.480930: train_loss -0.5713 
2025-01-11 09:15:43.480930: val_loss -0.4844 
2025-01-11 09:15:43.486954: Pseudo dice [np.float32(0.7244), np.float32(0.4518)] 
2025-01-11 09:15:43.489465: Epoch time: 38.68 s 
2025-01-11 09:15:43.492975: Yayy! New best EMA pseudo Dice: 0.5619999766349792 
2025-01-11 09:15:44.255649:  
2025-01-11 09:15:44.255649: Epoch 39 
2025-01-11 09:15:44.260209: Current learning rate: 0.00858 
2025-01-11 09:16:22.860198: train_loss -0.578 
2025-01-11 09:16:22.861208: val_loss -0.534 
2025-01-11 09:16:22.866229: Pseudo dice [np.float32(0.7177), np.float32(0.52)] 
2025-01-11 09:16:22.869740: Epoch time: 38.61 s 
2025-01-11 09:16:22.872756: Yayy! New best EMA pseudo Dice: 0.5677000284194946 
2025-01-11 09:16:23.640414:  
2025-01-11 09:16:23.640414: Epoch 40 
2025-01-11 09:16:23.645434: Current learning rate: 0.00855 
2025-01-11 09:17:02.243782: train_loss -0.559 
2025-01-11 09:17:02.244297: val_loss -0.472 
2025-01-11 09:17:02.249932: Pseudo dice [np.float32(0.7335), np.float32(0.388)] 
2025-01-11 09:17:02.252972: Epoch time: 38.6 s 
2025-01-11 09:17:02.931799:  
2025-01-11 09:17:02.931799: Epoch 41 
2025-01-11 09:17:02.937813: Current learning rate: 0.00851 
2025-01-11 09:17:41.521605: train_loss -0.563 
2025-01-11 09:17:41.521605: val_loss -0.5021 
2025-01-11 09:17:41.527619: Pseudo dice [np.float32(0.7251), np.float32(0.4608)] 
2025-01-11 09:17:41.530123: Epoch time: 38.59 s 
2025-01-11 09:17:41.534131: Yayy! New best EMA pseudo Dice: 0.569599986076355 
2025-01-11 09:17:42.269467:  
2025-01-11 09:17:42.270470: Epoch 42 
2025-01-11 09:17:42.275024: Current learning rate: 0.00847 
2025-01-11 09:18:20.890940: train_loss -0.5788 
2025-01-11 09:18:20.891490: val_loss -0.4831 
2025-01-11 09:18:20.897159: Pseudo dice [np.float32(0.7359), np.float32(0.3839)] 
2025-01-11 09:18:20.900207: Epoch time: 38.62 s 
2025-01-11 09:18:21.461541:  
2025-01-11 09:18:21.462545: Epoch 43 
2025-01-11 09:18:21.467096: Current learning rate: 0.00844 
2025-01-11 09:19:00.061731: train_loss -0.5703 
2025-01-11 09:19:00.063234: val_loss -0.5322 
2025-01-11 09:19:00.068252: Pseudo dice [np.float32(0.7348), np.float32(0.4796)] 
2025-01-11 09:19:00.071765: Epoch time: 38.6 s 
2025-01-11 09:19:00.075275: Yayy! New best EMA pseudo Dice: 0.5724999904632568 
2025-01-11 09:19:01.011383:  
2025-01-11 09:19:01.011383: Epoch 44 
2025-01-11 09:19:01.016948: Current learning rate: 0.0084 
2025-01-11 09:19:39.587231: train_loss -0.599 
2025-01-11 09:19:39.587231: val_loss -0.5631 
2025-01-11 09:19:39.593750: Pseudo dice [np.float32(0.752), np.float32(0.581)] 
2025-01-11 09:19:39.596256: Epoch time: 38.58 s 
2025-01-11 09:19:39.599765: Yayy! New best EMA pseudo Dice: 0.5819000005722046 
2025-01-11 09:19:40.332185:  
2025-01-11 09:19:40.332688: Epoch 45 
2025-01-11 09:19:40.337698: Current learning rate: 0.00836 
2025-01-11 09:20:18.898166: train_loss -0.5897 
2025-01-11 09:20:18.899169: val_loss -0.5361 
2025-01-11 09:20:18.904785: Pseudo dice [np.float32(0.7569), np.float32(0.5189)] 
2025-01-11 09:20:18.907817: Epoch time: 38.57 s 
2025-01-11 09:20:18.910341: Yayy! New best EMA pseudo Dice: 0.5874999761581421 
2025-01-11 09:20:19.652401:  
2025-01-11 09:20:19.652904: Epoch 46 
2025-01-11 09:20:19.657980: Current learning rate: 0.00833 
2025-01-11 09:20:58.269752: train_loss -0.5765 
2025-01-11 09:20:58.270753: val_loss -0.5011 
2025-01-11 09:20:58.276267: Pseudo dice [np.float32(0.7361), np.float32(0.4352)] 
2025-01-11 09:20:58.279776: Epoch time: 38.62 s 
2025-01-11 09:20:58.851909:  
2025-01-11 09:20:58.851909: Epoch 47 
2025-01-11 09:20:58.856920: Current learning rate: 0.00829 
2025-01-11 09:21:37.477197: train_loss -0.5987 
2025-01-11 09:21:37.478200: val_loss -0.515 
2025-01-11 09:21:37.483714: Pseudo dice [np.float32(0.7448), np.float32(0.4617)] 
2025-01-11 09:21:37.486233: Epoch time: 38.63 s 
2025-01-11 09:21:37.489746: Yayy! New best EMA pseudo Dice: 0.5889000296592712 
2025-01-11 09:21:38.220314:  
2025-01-11 09:21:38.220816: Epoch 48 
2025-01-11 09:21:38.225828: Current learning rate: 0.00825 
2025-01-11 09:22:16.824314: train_loss -0.5712 
2025-01-11 09:22:16.824314: val_loss -0.5365 
2025-01-11 09:22:16.830327: Pseudo dice [np.float32(0.7566), np.float32(0.4915)] 
2025-01-11 09:22:16.832832: Epoch time: 38.61 s 
2025-01-11 09:22:16.836338: Yayy! New best EMA pseudo Dice: 0.5924000144004822 
2025-01-11 09:22:17.577136:  
2025-01-11 09:22:17.577136: Epoch 49 
2025-01-11 09:22:17.582176: Current learning rate: 0.00822 
2025-01-11 09:22:56.176207: train_loss -0.5631 
2025-01-11 09:22:56.176711: val_loss -0.4877 
2025-01-11 09:22:56.183899: Pseudo dice [np.float32(0.7289), np.float32(0.4618)] 
2025-01-11 09:22:56.186407: Epoch time: 38.6 s 
2025-01-11 09:22:56.342781: Yayy! New best EMA pseudo Dice: 0.5927000045776367 
2025-01-11 09:22:57.104850:  
2025-01-11 09:22:57.105854: Epoch 50 
2025-01-11 09:22:57.110411: Current learning rate: 0.00818 
2025-01-11 09:23:35.779617: train_loss -0.6021 
2025-01-11 09:23:35.780620: val_loss -0.5343 
2025-01-11 09:23:35.786174: Pseudo dice [np.float32(0.7455), np.float32(0.4788)] 
2025-01-11 09:23:35.789727: Epoch time: 38.67 s 
2025-01-11 09:23:35.791745: Yayy! New best EMA pseudo Dice: 0.5946000218391418 
2025-01-11 09:23:36.543552:  
2025-01-11 09:23:36.543552: Epoch 51 
2025-01-11 09:23:36.548564: Current learning rate: 0.00814 
2025-01-11 09:24:15.159688: train_loss -0.607 
2025-01-11 09:24:15.160688: val_loss -0.5532 
2025-01-11 09:24:15.166203: Pseudo dice [np.float32(0.7315), np.float32(0.5579)] 
2025-01-11 09:24:15.168709: Epoch time: 38.62 s 
2025-01-11 09:24:15.172219: Yayy! New best EMA pseudo Dice: 0.5996000170707703 
2025-01-11 09:24:16.096319:  
2025-01-11 09:24:16.096319: Epoch 52 
2025-01-11 09:24:16.101852: Current learning rate: 0.00811 
2025-01-11 09:24:54.677238: train_loss -0.6009 
2025-01-11 09:24:54.677238: val_loss -0.5519 
2025-01-11 09:24:54.685011: Pseudo dice [np.float32(0.7373), np.float32(0.5647)] 
2025-01-11 09:24:54.689589: Epoch time: 38.58 s 
2025-01-11 09:24:54.692100: Yayy! New best EMA pseudo Dice: 0.6047999858856201 
2025-01-11 09:24:55.435234:  
2025-01-11 09:24:55.435743: Epoch 53 
2025-01-11 09:24:55.440783: Current learning rate: 0.00807 
2025-01-11 09:25:34.024880: train_loss -0.6071 
2025-01-11 09:25:34.024880: val_loss -0.55 
2025-01-11 09:25:34.030894: Pseudo dice [np.float32(0.7537), np.float32(0.5567)] 
2025-01-11 09:25:34.033399: Epoch time: 38.59 s 
2025-01-11 09:25:34.037406: Yayy! New best EMA pseudo Dice: 0.6097999811172485 
2025-01-11 09:25:34.787926:  
2025-01-11 09:25:34.788926: Epoch 54 
2025-01-11 09:25:34.793983: Current learning rate: 0.00803 
2025-01-11 09:26:13.367857: train_loss -0.6185 
2025-01-11 09:26:13.368860: val_loss -0.5783 
2025-01-11 09:26:13.374908: Pseudo dice [np.float32(0.7717), np.float32(0.5765)] 
2025-01-11 09:26:13.377933: Epoch time: 38.58 s 
2025-01-11 09:26:13.381454: Yayy! New best EMA pseudo Dice: 0.6161999702453613 
2025-01-11 09:26:14.148310:  
2025-01-11 09:26:14.148813: Epoch 55 
2025-01-11 09:26:14.153823: Current learning rate: 0.008 
2025-01-11 09:26:52.742920: train_loss -0.6162 
2025-01-11 09:26:52.742920: val_loss -0.5493 
2025-01-11 09:26:52.749259: Pseudo dice [np.float32(0.7504), np.float32(0.5642)] 
2025-01-11 09:26:52.751767: Epoch time: 38.6 s 
2025-01-11 09:26:52.755279: Yayy! New best EMA pseudo Dice: 0.6204000115394592 
2025-01-11 09:26:53.495435:  
2025-01-11 09:26:53.495435: Epoch 56 
2025-01-11 09:26:53.500962: Current learning rate: 0.00796 
2025-01-11 09:27:32.092190: train_loss -0.5985 
2025-01-11 09:27:32.092190: val_loss -0.4937 
2025-01-11 09:27:32.098207: Pseudo dice [np.float32(0.7219), np.float32(0.4765)] 
2025-01-11 09:27:32.100713: Epoch time: 38.6 s 
2025-01-11 09:27:32.676253:  
2025-01-11 09:27:32.676253: Epoch 57 
2025-01-11 09:27:32.681365: Current learning rate: 0.00792 
2025-01-11 09:28:11.283923: train_loss -0.5799 
2025-01-11 09:28:11.284432: val_loss -0.4971 
2025-01-11 09:28:11.289490: Pseudo dice [np.float32(0.7455), np.float32(0.4483)] 
2025-01-11 09:28:11.293019: Epoch time: 38.61 s 
2025-01-11 09:28:11.863375:  
2025-01-11 09:28:11.863375: Epoch 58 
2025-01-11 09:28:11.868912: Current learning rate: 0.00789 
2025-01-11 09:28:50.483312: train_loss -0.5909 
2025-01-11 09:28:50.484315: val_loss -0.5497 
2025-01-11 09:28:50.489851: Pseudo dice [np.float32(0.7481), np.float32(0.5667)] 
2025-01-11 09:28:50.492870: Epoch time: 38.62 s 
2025-01-11 09:28:51.213925:  
2025-01-11 09:28:51.214929: Epoch 59 
2025-01-11 09:28:51.219529: Current learning rate: 0.00785 
2025-01-11 09:29:29.825172: train_loss -0.6251 
2025-01-11 09:29:29.825678: val_loss -0.4989 
2025-01-11 09:29:29.831299: Pseudo dice [np.float32(0.7276), np.float32(0.493)] 
2025-01-11 09:29:29.834347: Epoch time: 38.61 s 
2025-01-11 09:29:30.421131:  
2025-01-11 09:29:30.422134: Epoch 60 
2025-01-11 09:29:30.426693: Current learning rate: 0.00781 
2025-01-11 09:30:09.012012: train_loss -0.5996 
2025-01-11 09:30:09.013013: val_loss -0.5295 
2025-01-11 09:30:09.018528: Pseudo dice [np.float32(0.7522), np.float32(0.4634)] 
2025-01-11 09:30:09.021035: Epoch time: 38.59 s 
2025-01-11 09:30:09.598173:  
2025-01-11 09:30:09.599699: Epoch 61 
2025-01-11 09:30:09.603221: Current learning rate: 0.00777 
2025-01-11 09:30:48.201104: train_loss -0.6179 
2025-01-11 09:30:48.201104: val_loss -0.5607 
2025-01-11 09:30:48.207120: Pseudo dice [np.float32(0.7808), np.float32(0.4924)] 
2025-01-11 09:30:48.210626: Epoch time: 38.6 s 
2025-01-11 09:30:48.783879:  
2025-01-11 09:30:48.783879: Epoch 62 
2025-01-11 09:30:48.788926: Current learning rate: 0.00774 
2025-01-11 09:31:27.389732: train_loss -0.6261 
2025-01-11 09:31:27.390733: val_loss -0.5478 
2025-01-11 09:31:27.396250: Pseudo dice [np.float32(0.7489), np.float32(0.5586)] 
2025-01-11 09:31:27.399759: Epoch time: 38.61 s 
2025-01-11 09:31:27.402267: Yayy! New best EMA pseudo Dice: 0.6233000159263611 
2025-01-11 09:31:28.164954:  
2025-01-11 09:31:28.165475: Epoch 63 
2025-01-11 09:31:28.170487: Current learning rate: 0.0077 
2025-01-11 09:32:06.802655: train_loss -0.6384 
2025-01-11 09:32:06.802655: val_loss -0.5557 
2025-01-11 09:32:06.809610: Pseudo dice [np.float32(0.7626), np.float32(0.5822)] 
2025-01-11 09:32:06.812621: Epoch time: 38.64 s 
2025-01-11 09:32:06.816134: Yayy! New best EMA pseudo Dice: 0.6281999945640564 
2025-01-11 09:32:07.640948:  
2025-01-11 09:32:07.640948: Epoch 64 
2025-01-11 09:32:07.645962: Current learning rate: 0.00766 
2025-01-11 09:32:46.363860: train_loss -0.635 
2025-01-11 09:32:46.363860: val_loss -0.5482 
2025-01-11 09:32:46.370379: Pseudo dice [np.float32(0.72), np.float32(0.5694)] 
2025-01-11 09:32:46.372888: Epoch time: 38.72 s 
2025-01-11 09:32:46.376399: Yayy! New best EMA pseudo Dice: 0.6298999786376953 
2025-01-11 09:32:47.145041:  
2025-01-11 09:32:47.145543: Epoch 65 
2025-01-11 09:32:47.150555: Current learning rate: 0.00763 
2025-01-11 09:33:25.724267: train_loss -0.6275 
2025-01-11 09:33:25.724267: val_loss -0.5642 
2025-01-11 09:33:25.730277: Pseudo dice [np.float32(0.7507), np.float32(0.5488)] 
2025-01-11 09:33:25.733285: Epoch time: 38.58 s 
2025-01-11 09:33:25.736794: Yayy! New best EMA pseudo Dice: 0.6319000124931335 
2025-01-11 09:33:26.504666:  
2025-01-11 09:33:26.505666: Epoch 66 
2025-01-11 09:33:26.510316: Current learning rate: 0.00759 
2025-01-11 09:34:05.131409: train_loss -0.635 
2025-01-11 09:34:05.131917: val_loss -0.489 
2025-01-11 09:34:05.138055: Pseudo dice [np.float32(0.7221), np.float32(0.5018)] 
2025-01-11 09:34:05.141097: Epoch time: 38.63 s 
2025-01-11 09:34:05.934962:  
2025-01-11 09:34:05.935965: Epoch 67 
2025-01-11 09:34:05.940514: Current learning rate: 0.00755 
2025-01-11 09:34:44.563464: train_loss -0.6106 
2025-01-11 09:34:44.563973: val_loss -0.524 
2025-01-11 09:34:44.570075: Pseudo dice [np.float32(0.7308), np.float32(0.6025)] 
2025-01-11 09:34:44.573183: Epoch time: 38.63 s 
2025-01-11 09:34:44.575760: Yayy! New best EMA pseudo Dice: 0.6335999965667725 
2025-01-11 09:34:45.325563:  
2025-01-11 09:34:45.326568: Epoch 68 
2025-01-11 09:34:45.331108: Current learning rate: 0.00751 
2025-01-11 09:35:23.946304: train_loss -0.6102 
2025-01-11 09:35:23.946833: val_loss -0.4833 
2025-01-11 09:35:23.951851: Pseudo dice [np.float32(0.7318), np.float32(0.5341)] 
2025-01-11 09:35:23.955364: Epoch time: 38.62 s 
2025-01-11 09:35:24.538059:  
2025-01-11 09:35:24.538059: Epoch 69 
2025-01-11 09:35:24.543072: Current learning rate: 0.00748 
2025-01-11 09:36:03.132952: train_loss -0.6343 
2025-01-11 09:36:03.132952: val_loss -0.615 
2025-01-11 09:36:03.138484: Pseudo dice [np.float32(0.7773), np.float32(0.7008)] 
2025-01-11 09:36:03.141989: Epoch time: 38.6 s 
2025-01-11 09:36:03.144997: Yayy! New best EMA pseudo Dice: 0.64410001039505 
2025-01-11 09:36:03.907551:  
2025-01-11 09:36:03.907551: Epoch 70 
2025-01-11 09:36:03.912562: Current learning rate: 0.00744 
2025-01-11 09:36:42.504961: train_loss -0.6213 
2025-01-11 09:36:42.505471: val_loss -0.5565 
2025-01-11 09:36:42.511068: Pseudo dice [np.float32(0.7591), np.float32(0.5668)] 
2025-01-11 09:36:42.514581: Epoch time: 38.6 s 
2025-01-11 09:36:42.517094: Yayy! New best EMA pseudo Dice: 0.6459000110626221 
2025-01-11 09:36:43.278591:  
2025-01-11 09:36:43.278591: Epoch 71 
2025-01-11 09:36:43.284127: Current learning rate: 0.0074 
2025-01-11 09:37:21.922064: train_loss -0.6414 
2025-01-11 09:37:21.923085: val_loss -0.558 
2025-01-11 09:37:21.928215: Pseudo dice [np.float32(0.7534), np.float32(0.5639)] 
2025-01-11 09:37:21.931258: Epoch time: 38.64 s 
2025-01-11 09:37:21.933817: Yayy! New best EMA pseudo Dice: 0.6471999883651733 
2025-01-11 09:37:22.687703:  
2025-01-11 09:37:22.687703: Epoch 72 
2025-01-11 09:37:22.693256: Current learning rate: 0.00737 
2025-01-11 09:38:01.298021: train_loss -0.6439 
2025-01-11 09:38:01.298021: val_loss -0.5916 
2025-01-11 09:38:01.304743: Pseudo dice [np.float32(0.7716), np.float32(0.5845)] 
2025-01-11 09:38:01.307781: Epoch time: 38.61 s 
2025-01-11 09:38:01.310308: Yayy! New best EMA pseudo Dice: 0.6503000259399414 
2025-01-11 09:38:02.077114:  
2025-01-11 09:38:02.077114: Epoch 73 
2025-01-11 09:38:02.082124: Current learning rate: 0.00733 
2025-01-11 09:38:40.682010: train_loss -0.6363 
2025-01-11 09:38:40.682010: val_loss -0.5374 
2025-01-11 09:38:40.688020: Pseudo dice [np.float32(0.7601), np.float32(0.4974)] 
2025-01-11 09:38:40.691029: Epoch time: 38.61 s 
2025-01-11 09:38:41.275570:  
2025-01-11 09:38:41.276574: Epoch 74 
2025-01-11 09:38:41.281124: Current learning rate: 0.00729 
2025-01-11 09:39:19.869871: train_loss -0.6353 
2025-01-11 09:39:19.870375: val_loss -0.5818 
2025-01-11 09:39:19.875940: Pseudo dice [np.float32(0.7809), np.float32(0.5394)] 
2025-01-11 09:39:19.878971: Epoch time: 38.59 s 
2025-01-11 09:39:20.650447:  
2025-01-11 09:39:20.650447: Epoch 75 
2025-01-11 09:39:20.655566: Current learning rate: 0.00725 
2025-01-11 09:39:59.256052: train_loss -0.6557 
2025-01-11 09:39:59.256052: val_loss -0.589 
2025-01-11 09:39:59.262068: Pseudo dice [np.float32(0.7627), np.float32(0.6242)] 
2025-01-11 09:39:59.264573: Epoch time: 38.61 s 
2025-01-11 09:39:59.268077: Yayy! New best EMA pseudo Dice: 0.6538000106811523 
2025-01-11 09:40:00.073226:  
2025-01-11 09:40:00.074232: Epoch 76 
2025-01-11 09:40:00.079533: Current learning rate: 0.00722 
2025-01-11 09:40:38.682977: train_loss -0.633 
2025-01-11 09:40:38.683498: val_loss -0.561 
2025-01-11 09:40:38.689104: Pseudo dice [np.float32(0.7629), np.float32(0.5042)] 
2025-01-11 09:40:38.692135: Epoch time: 38.61 s 
2025-01-11 09:40:39.277730:  
2025-01-11 09:40:39.278733: Epoch 77 
2025-01-11 09:40:39.282769: Current learning rate: 0.00718 
2025-01-11 09:41:17.945223: train_loss -0.6438 
2025-01-11 09:41:17.945725: val_loss -0.5332 
2025-01-11 09:41:17.951489: Pseudo dice [np.float32(0.7451), np.float32(0.5079)] 
2025-01-11 09:41:17.953928: Epoch time: 38.67 s 
2025-01-11 09:41:18.549615:  
2025-01-11 09:41:18.549615: Epoch 78 
2025-01-11 09:41:18.553679: Current learning rate: 0.00714 
2025-01-11 09:41:57.183496: train_loss -0.6196 
2025-01-11 09:41:57.183496: val_loss -0.5089 
2025-01-11 09:41:57.191021: Pseudo dice [np.float32(0.7595), np.float32(0.431)] 
2025-01-11 09:41:57.194045: Epoch time: 38.63 s 
2025-01-11 09:41:57.796891:  
2025-01-11 09:41:57.797892: Epoch 79 
2025-01-11 09:41:57.801036: Current learning rate: 0.0071 
2025-01-11 09:42:36.420549: train_loss -0.6586 
2025-01-11 09:42:36.422051: val_loss -0.5476 
2025-01-11 09:42:36.427093: Pseudo dice [np.float32(0.7405), np.float32(0.5563)] 
2025-01-11 09:42:36.430603: Epoch time: 38.62 s 
2025-01-11 09:42:37.020506:  
2025-01-11 09:42:37.020506: Epoch 80 
2025-01-11 09:42:37.026024: Current learning rate: 0.00707 
2025-01-11 09:43:15.639078: train_loss -0.662 
2025-01-11 09:43:15.640078: val_loss -0.5751 
2025-01-11 09:43:15.645594: Pseudo dice [np.float32(0.7561), np.float32(0.625)] 
2025-01-11 09:43:15.649105: Epoch time: 38.62 s 
2025-01-11 09:43:16.241886:  
2025-01-11 09:43:16.241886: Epoch 81 
2025-01-11 09:43:16.245396: Current learning rate: 0.00703 
2025-01-11 09:43:54.835669: train_loss -0.6476 
2025-01-11 09:43:54.837170: val_loss -0.5636 
2025-01-11 09:43:54.842181: Pseudo dice [np.float32(0.7853), np.float32(0.5455)] 
2025-01-11 09:43:54.844724: Epoch time: 38.6 s 
2025-01-11 09:43:55.445767:  
2025-01-11 09:43:55.446269: Epoch 82 
2025-01-11 09:43:55.451279: Current learning rate: 0.00699 
2025-01-11 09:44:34.045552: train_loss -0.6528 
2025-01-11 09:44:34.046555: val_loss -0.5751 
2025-01-11 09:44:34.052565: Pseudo dice [np.float32(0.7795), np.float32(0.5575)] 
2025-01-11 09:44:34.055573: Epoch time: 38.6 s 
2025-01-11 09:44:34.804484:  
2025-01-11 09:44:34.805487: Epoch 83 
2025-01-11 09:44:34.810054: Current learning rate: 0.00696 
2025-01-11 09:45:13.405719: train_loss -0.6712 
2025-01-11 09:45:13.405719: val_loss -0.525 
2025-01-11 09:45:13.411966: Pseudo dice [np.float32(0.7639), np.float32(0.4464)] 
2025-01-11 09:45:13.415537: Epoch time: 38.6 s 
2025-01-11 09:45:13.981376:  
2025-01-11 09:45:13.981376: Epoch 84 
2025-01-11 09:45:13.986946: Current learning rate: 0.00692 
2025-01-11 09:45:52.565804: train_loss -0.6751 
2025-01-11 09:45:52.565804: val_loss -0.5835 
2025-01-11 09:45:52.570816: Pseudo dice [np.float32(0.7891), np.float32(0.5475)] 
2025-01-11 09:45:52.574328: Epoch time: 38.59 s 
2025-01-11 09:45:53.127267:  
2025-01-11 09:45:53.127771: Epoch 85 
2025-01-11 09:45:53.132785: Current learning rate: 0.00688 
2025-01-11 09:46:31.729283: train_loss -0.6595 
2025-01-11 09:46:31.729789: val_loss -0.5439 
2025-01-11 09:46:31.734813: Pseudo dice [np.float32(0.7706), np.float32(0.4621)] 
2025-01-11 09:46:31.738326: Epoch time: 38.6 s 
2025-01-11 09:46:32.308935:  
2025-01-11 09:46:32.308935: Epoch 86 
2025-01-11 09:46:32.314559: Current learning rate: 0.00684 
2025-01-11 09:47:10.896582: train_loss -0.6423 
2025-01-11 09:47:10.896582: val_loss -0.575 
2025-01-11 09:47:10.901604: Pseudo dice [np.float32(0.7901), np.float32(0.5732)] 
2025-01-11 09:47:10.905113: Epoch time: 38.59 s 
2025-01-11 09:47:11.464153:  
2025-01-11 09:47:11.464153: Epoch 87 
2025-01-11 09:47:11.469163: Current learning rate: 0.0068 
2025-01-11 09:47:50.077623: train_loss -0.672 
2025-01-11 09:47:50.077623: val_loss -0.5566 
2025-01-11 09:47:50.082635: Pseudo dice [np.float32(0.7654), np.float32(0.5996)] 
2025-01-11 09:47:50.086645: Epoch time: 38.61 s 
2025-01-11 09:47:50.652778:  
2025-01-11 09:47:50.652778: Epoch 88 
2025-01-11 09:47:50.657946: Current learning rate: 0.00677 
2025-01-11 09:48:29.245141: train_loss -0.6727 
2025-01-11 09:48:29.246179: val_loss -0.5826 
2025-01-11 09:48:29.251789: Pseudo dice [np.float32(0.757), np.float32(0.6069)] 
2025-01-11 09:48:29.254833: Epoch time: 38.59 s 
2025-01-11 09:48:29.257857: Yayy! New best EMA pseudo Dice: 0.656000018119812 
2025-01-11 09:48:29.964023:  
2025-01-11 09:48:29.965026: Epoch 89 
2025-01-11 09:48:29.969940: Current learning rate: 0.00673 
2025-01-11 09:49:08.555148: train_loss -0.6734 
2025-01-11 09:49:08.555148: val_loss -0.5132 
2025-01-11 09:49:08.561163: Pseudo dice [np.float32(0.7359), np.float32(0.5123)] 
2025-01-11 09:49:08.564670: Epoch time: 38.59 s 
2025-01-11 09:49:09.133140:  
2025-01-11 09:49:09.134143: Epoch 90 
2025-01-11 09:49:09.138766: Current learning rate: 0.00669 
2025-01-11 09:49:47.862394: train_loss -0.6587 
2025-01-11 09:49:47.862394: val_loss -0.5864 
2025-01-11 09:49:47.868914: Pseudo dice [np.float32(0.7717), np.float32(0.6328)] 
2025-01-11 09:49:47.872424: Epoch time: 38.73 s 
2025-01-11 09:49:47.874932: Yayy! New best EMA pseudo Dice: 0.657800018787384 
2025-01-11 09:49:48.806800:  
2025-01-11 09:49:48.807302: Epoch 91 
2025-01-11 09:49:48.812346: Current learning rate: 0.00665 
2025-01-11 09:50:27.414613: train_loss -0.6646 
2025-01-11 09:50:27.415617: val_loss -0.5538 
2025-01-11 09:50:27.420628: Pseudo dice [np.float32(0.7852), np.float32(0.6007)] 
2025-01-11 09:50:27.424635: Epoch time: 38.61 s 
2025-01-11 09:50:27.427140: Yayy! New best EMA pseudo Dice: 0.661300003528595 
2025-01-11 09:50:28.167686:  
2025-01-11 09:50:28.168685: Epoch 92 
2025-01-11 09:50:28.173764: Current learning rate: 0.00662 
2025-01-11 09:51:06.762459: train_loss -0.701 
2025-01-11 09:51:06.762459: val_loss -0.5722 
2025-01-11 09:51:06.768973: Pseudo dice [np.float32(0.7743), np.float32(0.5212)] 
2025-01-11 09:51:06.772483: Epoch time: 38.6 s 
2025-01-11 09:51:07.326060:  
2025-01-11 09:51:07.326564: Epoch 93 
2025-01-11 09:51:07.331575: Current learning rate: 0.00658 
2025-01-11 09:51:45.918091: train_loss -0.6799 
2025-01-11 09:51:45.919858: val_loss -0.5758 
2025-01-11 09:51:45.923429: Pseudo dice [np.float32(0.7786), np.float32(0.5556)] 
2025-01-11 09:51:45.926980: Epoch time: 38.59 s 
2025-01-11 09:51:46.493001:  
2025-01-11 09:51:46.493001: Epoch 94 
2025-01-11 09:51:46.499016: Current learning rate: 0.00654 
2025-01-11 09:52:25.119227: train_loss -0.6689 
2025-01-11 09:52:25.119740: val_loss -0.5825 
2025-01-11 09:52:25.125351: Pseudo dice [np.float32(0.7643), np.float32(0.5721)] 
2025-01-11 09:52:25.128883: Epoch time: 38.63 s 
2025-01-11 09:52:25.131449: Yayy! New best EMA pseudo Dice: 0.6614000201225281 
2025-01-11 09:52:25.854538:  
2025-01-11 09:52:25.855042: Epoch 95 
2025-01-11 09:52:25.860054: Current learning rate: 0.0065 
2025-01-11 09:53:04.494112: train_loss -0.6827 
2025-01-11 09:53:04.494112: val_loss -0.5641 
2025-01-11 09:53:04.500633: Pseudo dice [np.float32(0.7865), np.float32(0.5227)] 
2025-01-11 09:53:04.503140: Epoch time: 38.64 s 
2025-01-11 09:53:05.065617:  
2025-01-11 09:53:05.065617: Epoch 96 
2025-01-11 09:53:05.071631: Current learning rate: 0.00647 
2025-01-11 09:53:43.684012: train_loss -0.6809 
2025-01-11 09:53:43.684012: val_loss -0.5631 
2025-01-11 09:53:43.689721: Pseudo dice [np.float32(0.7768), np.float32(0.5049)] 
2025-01-11 09:53:43.692744: Epoch time: 38.62 s 
2025-01-11 09:53:44.267983:  
2025-01-11 09:53:44.267983: Epoch 97 
2025-01-11 09:53:44.272999: Current learning rate: 0.00643 
2025-01-11 09:54:22.859452: train_loss -0.687 
2025-01-11 09:54:22.860455: val_loss -0.5825 
2025-01-11 09:54:22.866467: Pseudo dice [np.float32(0.78), np.float32(0.5923)] 
2025-01-11 09:54:22.870046: Epoch time: 38.59 s 
2025-01-11 09:54:22.872585: Yayy! New best EMA pseudo Dice: 0.6614999771118164 
2025-01-11 09:54:23.647035:  
2025-01-11 09:54:23.647545: Epoch 98 
2025-01-11 09:54:23.652073: Current learning rate: 0.00639 
2025-01-11 09:55:02.240678: train_loss -0.6935 
2025-01-11 09:55:02.241198: val_loss -0.5626 
2025-01-11 09:55:02.246269: Pseudo dice [np.float32(0.7759), np.float32(0.4882)] 
2025-01-11 09:55:02.249777: Epoch time: 38.59 s 
2025-01-11 09:55:02.988440:  
2025-01-11 09:55:02.988440: Epoch 99 
2025-01-11 09:55:02.994484: Current learning rate: 0.00635 
2025-01-11 09:55:41.581106: train_loss -0.6886 
2025-01-11 09:55:41.582107: val_loss -0.5552 
2025-01-11 09:55:41.587624: Pseudo dice [np.float32(0.7647), np.float32(0.5708)] 
2025-01-11 09:55:41.590131: Epoch time: 38.59 s 
2025-01-11 09:55:42.313516:  
2025-01-11 09:55:42.314520: Epoch 100 
2025-01-11 09:55:42.319092: Current learning rate: 0.00631 
2025-01-11 09:56:20.907918: train_loss -0.6927 
2025-01-11 09:56:20.907918: val_loss -0.5777 
2025-01-11 09:56:20.913934: Pseudo dice [np.float32(0.7814), np.float32(0.5812)] 
2025-01-11 09:56:20.916945: Epoch time: 38.59 s 
2025-01-11 09:56:20.919454: Yayy! New best EMA pseudo Dice: 0.6615999937057495 
2025-01-11 09:56:21.668276:  
2025-01-11 09:56:21.669280: Epoch 101 
2025-01-11 09:56:21.673824: Current learning rate: 0.00628 
2025-01-11 09:57:00.271620: train_loss -0.6976 
2025-01-11 09:57:00.272125: val_loss -0.5172 
2025-01-11 09:57:00.277167: Pseudo dice [np.float32(0.7799), np.float32(0.3717)] 
2025-01-11 09:57:00.281204: Epoch time: 38.6 s 
2025-01-11 09:57:00.855156:  
2025-01-11 09:57:00.855659: Epoch 102 
2025-01-11 09:57:00.860670: Current learning rate: 0.00624 
2025-01-11 09:57:39.448408: train_loss -0.6866 
2025-01-11 09:57:39.448923: val_loss -0.5722 
2025-01-11 09:57:39.454466: Pseudo dice [np.float32(0.7805), np.float32(0.5335)] 
2025-01-11 09:57:39.457536: Epoch time: 38.59 s 
2025-01-11 09:57:40.030299:  
2025-01-11 09:57:40.031304: Epoch 103 
2025-01-11 09:57:40.036834: Current learning rate: 0.0062 
2025-01-11 09:58:18.700964: train_loss -0.6725 
2025-01-11 09:58:18.701969: val_loss -0.5983 
2025-01-11 09:58:18.706986: Pseudo dice [np.float32(0.7806), np.float32(0.6511)] 
2025-01-11 09:58:18.710495: Epoch time: 38.67 s 
2025-01-11 09:58:19.286500:  
2025-01-11 09:58:19.286500: Epoch 104 
2025-01-11 09:58:19.292081: Current learning rate: 0.00616 
2025-01-11 09:58:57.883672: train_loss -0.6803 
2025-01-11 09:58:57.884679: val_loss -0.5303 
2025-01-11 09:58:57.889616: Pseudo dice [np.float32(0.7605), np.float32(0.491)] 
2025-01-11 09:58:57.893127: Epoch time: 38.6 s 
2025-01-11 09:58:58.498548:  
2025-01-11 09:58:58.499053: Epoch 105 
2025-01-11 09:58:58.504066: Current learning rate: 0.00612 
2025-01-11 09:59:37.102911: train_loss -0.6961 
2025-01-11 09:59:37.102911: val_loss -0.5417 
2025-01-11 09:59:37.108507: Pseudo dice [np.float32(0.7914), np.float32(0.4602)] 
2025-01-11 09:59:37.112016: Epoch time: 38.61 s 
2025-01-11 09:59:37.684734:  
2025-01-11 09:59:37.684734: Epoch 106 
2025-01-11 09:59:37.690827: Current learning rate: 0.00609 
2025-01-11 10:00:16.303136: train_loss -0.6862 
2025-01-11 10:00:16.303642: val_loss -0.5747 
2025-01-11 10:00:16.309698: Pseudo dice [np.float32(0.7774), np.float32(0.6147)] 
2025-01-11 10:00:16.312779: Epoch time: 38.62 s 
2025-01-11 10:00:17.080983:  
2025-01-11 10:00:17.081485: Epoch 107 
2025-01-11 10:00:17.086497: Current learning rate: 0.00605 
2025-01-11 10:00:55.671123: train_loss -0.6909 
2025-01-11 10:00:55.671123: val_loss -0.5282 
2025-01-11 10:00:55.677136: Pseudo dice [np.float32(0.7774), np.float32(0.4087)] 
2025-01-11 10:00:55.681151: Epoch time: 38.59 s 
2025-01-11 10:00:56.255357:  
2025-01-11 10:00:56.255357: Epoch 108 
2025-01-11 10:00:56.260999: Current learning rate: 0.00601 
2025-01-11 10:01:34.844646: train_loss -0.7101 
2025-01-11 10:01:34.845650: val_loss -0.5754 
2025-01-11 10:01:34.851173: Pseudo dice [np.float32(0.7871), np.float32(0.4983)] 
2025-01-11 10:01:34.854684: Epoch time: 38.59 s 
2025-01-11 10:01:35.428282:  
2025-01-11 10:01:35.428784: Epoch 109 
2025-01-11 10:01:35.433796: Current learning rate: 0.00597 
2025-01-11 10:02:14.017600: train_loss -0.7084 
2025-01-11 10:02:14.019105: val_loss -0.5528 
2025-01-11 10:02:14.024119: Pseudo dice [np.float32(0.7832), np.float32(0.4896)] 
2025-01-11 10:02:14.027629: Epoch time: 38.59 s 
2025-01-11 10:02:14.608440:  
2025-01-11 10:02:14.608440: Epoch 110 
2025-01-11 10:02:14.614488: Current learning rate: 0.00593 
2025-01-11 10:02:53.264076: train_loss -0.7182 
2025-01-11 10:02:53.264076: val_loss -0.5988 
2025-01-11 10:02:53.269639: Pseudo dice [np.float32(0.7816), np.float32(0.5712)] 
2025-01-11 10:02:53.272182: Epoch time: 38.66 s 
2025-01-11 10:02:53.844484:  
2025-01-11 10:02:53.844484: Epoch 111 
2025-01-11 10:02:53.849496: Current learning rate: 0.0059 
2025-01-11 10:03:32.435872: train_loss -0.7034 
2025-01-11 10:03:32.436876: val_loss -0.5822 
2025-01-11 10:03:32.442885: Pseudo dice [np.float32(0.796), np.float32(0.5611)] 
2025-01-11 10:03:32.445893: Epoch time: 38.59 s 
2025-01-11 10:03:33.018101:  
2025-01-11 10:03:33.019104: Epoch 112 
2025-01-11 10:03:33.024122: Current learning rate: 0.00586 
2025-01-11 10:04:11.624744: train_loss -0.7081 
2025-01-11 10:04:11.624744: val_loss -0.5725 
2025-01-11 10:04:11.631283: Pseudo dice [np.float32(0.7814), np.float32(0.545)] 
2025-01-11 10:04:11.634293: Epoch time: 38.61 s 
2025-01-11 10:04:12.198678:  
2025-01-11 10:04:12.199681: Epoch 113 
2025-01-11 10:04:12.204231: Current learning rate: 0.00582 
2025-01-11 10:04:50.814675: train_loss -0.6969 
2025-01-11 10:04:50.815680: val_loss -0.5701 
2025-01-11 10:04:50.820830: Pseudo dice [np.float32(0.7947), np.float32(0.487)] 
2025-01-11 10:04:50.824386: Epoch time: 38.62 s 
2025-01-11 10:04:51.394013:  
2025-01-11 10:04:51.394013: Epoch 114 
2025-01-11 10:04:51.400101: Current learning rate: 0.00578 
2025-01-11 10:05:29.999783: train_loss -0.7059 
2025-01-11 10:05:30.000784: val_loss -0.608 
2025-01-11 10:05:30.006301: Pseudo dice [np.float32(0.7804), np.float32(0.614)] 
2025-01-11 10:05:30.009812: Epoch time: 38.61 s 
2025-01-11 10:05:30.733267:  
2025-01-11 10:05:30.733267: Epoch 115 
2025-01-11 10:05:30.739324: Current learning rate: 0.00574 
2025-01-11 10:06:09.360970: train_loss -0.6999 
2025-01-11 10:06:09.361972: val_loss -0.5543 
2025-01-11 10:06:09.368495: Pseudo dice [np.float32(0.7749), np.float32(0.5126)] 
2025-01-11 10:06:09.371003: Epoch time: 38.63 s 
2025-01-11 10:06:09.946334:  
2025-01-11 10:06:09.947333: Epoch 116 
2025-01-11 10:06:09.952881: Current learning rate: 0.0057 
2025-01-11 10:06:48.602907: train_loss -0.7078 
2025-01-11 10:06:48.602907: val_loss -0.6199 
2025-01-11 10:06:48.608920: Pseudo dice [np.float32(0.7991), np.float32(0.5873)] 
2025-01-11 10:06:48.611928: Epoch time: 38.66 s 
2025-01-11 10:06:49.197170:  
2025-01-11 10:06:49.197170: Epoch 117 
2025-01-11 10:06:49.203281: Current learning rate: 0.00567 
2025-01-11 10:07:27.814191: train_loss -0.7151 
2025-01-11 10:07:27.814707: val_loss -0.5617 
2025-01-11 10:07:27.820288: Pseudo dice [np.float32(0.7678), np.float32(0.5768)] 
2025-01-11 10:07:27.822822: Epoch time: 38.62 s 
2025-01-11 10:07:28.391728:  
2025-01-11 10:07:28.391728: Epoch 118 
2025-01-11 10:07:28.399888: Current learning rate: 0.00563 
2025-01-11 10:08:06.997696: train_loss -0.7258 
2025-01-11 10:08:06.999286: val_loss -0.5973 
2025-01-11 10:08:07.004950: Pseudo dice [np.float32(0.7779), np.float32(0.6128)] 
2025-01-11 10:08:07.007461: Epoch time: 38.61 s 
2025-01-11 10:08:07.010972: Yayy! New best EMA pseudo Dice: 0.664900004863739 
2025-01-11 10:08:07.745343:  
2025-01-11 10:08:07.745343: Epoch 119 
2025-01-11 10:08:07.749853: Current learning rate: 0.00559 
2025-01-11 10:08:46.348648: train_loss -0.6828 
2025-01-11 10:08:46.349151: val_loss -0.5792 
2025-01-11 10:08:46.354162: Pseudo dice [np.float32(0.7834), np.float32(0.5546)] 
2025-01-11 10:08:46.357671: Epoch time: 38.6 s 
2025-01-11 10:08:46.361177: Yayy! New best EMA pseudo Dice: 0.6653000116348267 
2025-01-11 10:08:47.121974:  
2025-01-11 10:08:47.121974: Epoch 120 
2025-01-11 10:08:47.127012: Current learning rate: 0.00555 
2025-01-11 10:09:25.700519: train_loss -0.7054 
2025-01-11 10:09:25.701523: val_loss -0.5374 
2025-01-11 10:09:25.706775: Pseudo dice [np.float32(0.7781), np.float32(0.5433)] 
2025-01-11 10:09:25.710289: Epoch time: 38.58 s 
2025-01-11 10:09:26.281973:  
2025-01-11 10:09:26.281973: Epoch 121 
2025-01-11 10:09:26.286006: Current learning rate: 0.00551 
2025-01-11 10:10:04.872207: train_loss -0.6978 
2025-01-11 10:10:04.873210: val_loss -0.5672 
2025-01-11 10:10:04.878759: Pseudo dice [np.float32(0.8008), np.float32(0.5237)] 
2025-01-11 10:10:04.882269: Epoch time: 38.59 s 
2025-01-11 10:10:05.458530:  
2025-01-11 10:10:05.458530: Epoch 122 
2025-01-11 10:10:05.463552: Current learning rate: 0.00547 
2025-01-11 10:10:44.042634: train_loss -0.7157 
2025-01-11 10:10:44.042634: val_loss -0.5884 
2025-01-11 10:10:44.048650: Pseudo dice [np.float32(0.7955), np.float32(0.5878)] 
2025-01-11 10:10:44.051663: Epoch time: 38.58 s 
2025-01-11 10:10:44.055177: Yayy! New best EMA pseudo Dice: 0.6672999858856201 
2025-01-11 10:10:45.039912:  
2025-01-11 10:10:45.039912: Epoch 123 
2025-01-11 10:10:45.044923: Current learning rate: 0.00544 
2025-01-11 10:11:23.617533: train_loss -0.715 
2025-01-11 10:11:23.618536: val_loss -0.5701 
2025-01-11 10:11:23.624546: Pseudo dice [np.float32(0.7654), np.float32(0.5813)] 
2025-01-11 10:11:23.627554: Epoch time: 38.58 s 
2025-01-11 10:11:23.631063: Yayy! New best EMA pseudo Dice: 0.667900025844574 
2025-01-11 10:11:24.384097:  
2025-01-11 10:11:24.384604: Epoch 124 
2025-01-11 10:11:24.390716: Current learning rate: 0.0054 
2025-01-11 10:12:02.959424: train_loss -0.7052 
2025-01-11 10:12:02.959940: val_loss -0.5705 
2025-01-11 10:12:02.967040: Pseudo dice [np.float32(0.7776), np.float32(0.5434)] 
2025-01-11 10:12:02.970615: Epoch time: 38.58 s 
2025-01-11 10:12:03.549210:  
2025-01-11 10:12:03.549210: Epoch 125 
2025-01-11 10:12:03.554261: Current learning rate: 0.00536 
2025-01-11 10:12:42.134305: train_loss -0.7269 
2025-01-11 10:12:42.134812: val_loss -0.5996 
2025-01-11 10:12:42.139858: Pseudo dice [np.float32(0.7932), np.float32(0.5976)] 
2025-01-11 10:12:42.143889: Epoch time: 38.59 s 
2025-01-11 10:12:42.146464: Yayy! New best EMA pseudo Dice: 0.6700000166893005 
2025-01-11 10:12:42.898198:  
2025-01-11 10:12:42.898700: Epoch 126 
2025-01-11 10:12:42.903713: Current learning rate: 0.00532 
2025-01-11 10:13:21.497680: train_loss -0.7104 
2025-01-11 10:13:21.498183: val_loss -0.5444 
2025-01-11 10:13:21.504198: Pseudo dice [np.float32(0.7429), np.float32(0.5863)] 
2025-01-11 10:13:21.506704: Epoch time: 38.6 s 
2025-01-11 10:13:22.083928:  
2025-01-11 10:13:22.084929: Epoch 127 
2025-01-11 10:13:22.089976: Current learning rate: 0.00528 
2025-01-11 10:14:00.663537: train_loss -0.7333 
2025-01-11 10:14:00.664537: val_loss -0.6226 
2025-01-11 10:14:00.670051: Pseudo dice [np.float32(0.7999), np.float32(0.5885)] 
2025-01-11 10:14:00.673561: Epoch time: 38.58 s 
2025-01-11 10:14:00.676066: Yayy! New best EMA pseudo Dice: 0.6718999743461609 
2025-01-11 10:14:01.430954:  
2025-01-11 10:14:01.431957: Epoch 128 
2025-01-11 10:14:01.438524: Current learning rate: 0.00524 
2025-01-11 10:14:40.049048: train_loss -0.7076 
2025-01-11 10:14:40.049048: val_loss -0.5277 
2025-01-11 10:14:40.055067: Pseudo dice [np.float32(0.7713), np.float32(0.4428)] 
2025-01-11 10:14:40.059078: Epoch time: 38.62 s 
2025-01-11 10:14:40.639384:  
2025-01-11 10:14:40.640385: Epoch 129 
2025-01-11 10:14:40.645443: Current learning rate: 0.0052 
2025-01-11 10:15:19.340342: train_loss -0.7262 
2025-01-11 10:15:19.341866: val_loss -0.5305 
2025-01-11 10:15:19.348549: Pseudo dice [np.float32(0.7731), np.float32(0.4527)] 
2025-01-11 10:15:19.352163: Epoch time: 38.7 s 
2025-01-11 10:15:19.933923:  
2025-01-11 10:15:19.933923: Epoch 130 
2025-01-11 10:15:19.938934: Current learning rate: 0.00517 
2025-01-11 10:15:58.543267: train_loss -0.7287 
2025-01-11 10:15:58.544717: val_loss -0.5948 
2025-01-11 10:15:58.550096: Pseudo dice [np.float32(0.7994), np.float32(0.5787)] 
2025-01-11 10:15:58.553105: Epoch time: 38.61 s 
2025-01-11 10:15:59.126768:  
2025-01-11 10:15:59.127270: Epoch 131 
2025-01-11 10:15:59.130780: Current learning rate: 0.00513 
2025-01-11 10:16:37.734804: train_loss -0.7411 
2025-01-11 10:16:37.735317: val_loss -0.6072 
2025-01-11 10:16:37.740875: Pseudo dice [np.float32(0.7944), np.float32(0.5547)] 
2025-01-11 10:16:37.744436: Epoch time: 38.61 s 
2025-01-11 10:16:38.504921:  
2025-01-11 10:16:38.504921: Epoch 132 
2025-01-11 10:16:38.508945: Current learning rate: 0.00509 
2025-01-11 10:17:17.129648: train_loss -0.7385 
2025-01-11 10:17:17.131150: val_loss -0.5214 
2025-01-11 10:17:17.137165: Pseudo dice [np.float32(0.7768), np.float32(0.4048)] 
2025-01-11 10:17:17.140671: Epoch time: 38.63 s 
2025-01-11 10:17:17.842821:  
2025-01-11 10:17:17.843323: Epoch 133 
2025-01-11 10:17:17.848335: Current learning rate: 0.00505 
2025-01-11 10:17:56.484122: train_loss -0.7404 
2025-01-11 10:17:56.490283: val_loss -0.5642 
2025-01-11 10:17:56.493346: Pseudo dice [np.float32(0.7726), np.float32(0.5586)] 
2025-01-11 10:17:56.496975: Epoch time: 38.64 s 
2025-01-11 10:17:57.064468:  
2025-01-11 10:17:57.064972: Epoch 134 
2025-01-11 10:17:57.068482: Current learning rate: 0.00501 
2025-01-11 10:18:35.668108: train_loss -0.7409 
2025-01-11 10:18:35.669108: val_loss -0.5596 
2025-01-11 10:18:35.674629: Pseudo dice [np.float32(0.795), np.float32(0.5363)] 
2025-01-11 10:18:35.677138: Epoch time: 38.6 s 
2025-01-11 10:18:36.268461:  
2025-01-11 10:18:36.268461: Epoch 135 
2025-01-11 10:18:36.274011: Current learning rate: 0.00497 
2025-01-11 10:19:14.881808: train_loss -0.7256 
2025-01-11 10:19:14.883319: val_loss -0.5531 
2025-01-11 10:19:14.889431: Pseudo dice [np.float32(0.7729), np.float32(0.4929)] 
2025-01-11 10:19:14.893086: Epoch time: 38.61 s 
2025-01-11 10:19:15.490756:  
2025-01-11 10:19:15.490756: Epoch 136 
2025-01-11 10:19:15.495786: Current learning rate: 0.00493 
2025-01-11 10:19:54.117818: train_loss -0.7291 
2025-01-11 10:19:54.118322: val_loss -0.5388 
2025-01-11 10:19:54.124376: Pseudo dice [np.float32(0.7875), np.float32(0.4551)] 
2025-01-11 10:19:54.126893: Epoch time: 38.63 s 
2025-01-11 10:19:54.721041:  
2025-01-11 10:19:54.721041: Epoch 137 
2025-01-11 10:19:54.725613: Current learning rate: 0.00489 
2025-01-11 10:20:33.298920: train_loss -0.7374 
2025-01-11 10:20:33.298920: val_loss -0.5486 
2025-01-11 10:20:33.305435: Pseudo dice [np.float32(0.7927), np.float32(0.4965)] 
2025-01-11 10:20:33.307941: Epoch time: 38.58 s 
2025-01-11 10:20:33.886714:  
2025-01-11 10:20:33.886714: Epoch 138 
2025-01-11 10:20:33.892794: Current learning rate: 0.00485 
2025-01-11 10:21:12.494864: train_loss -0.741 
2025-01-11 10:21:12.495865: val_loss -0.5606 
2025-01-11 10:21:12.501383: Pseudo dice [np.float32(0.7813), np.float32(0.4119)] 
2025-01-11 10:21:12.504892: Epoch time: 38.61 s 
2025-01-11 10:21:13.085632:  
2025-01-11 10:21:13.085632: Epoch 139 
2025-01-11 10:21:13.091191: Current learning rate: 0.00482 
2025-01-11 10:21:51.696716: train_loss -0.7409 
2025-01-11 10:21:51.698220: val_loss -0.5651 
2025-01-11 10:21:51.704241: Pseudo dice [np.float32(0.779), np.float32(0.5429)] 
2025-01-11 10:21:51.706749: Epoch time: 38.61 s 
2025-01-11 10:21:52.466653:  
2025-01-11 10:21:52.466653: Epoch 140 
2025-01-11 10:21:52.472735: Current learning rate: 0.00478 
2025-01-11 10:22:31.063138: train_loss -0.7417 
2025-01-11 10:22:31.063138: val_loss -0.5845 
2025-01-11 10:22:31.069153: Pseudo dice [np.float32(0.7878), np.float32(0.5771)] 
2025-01-11 10:22:31.072659: Epoch time: 38.6 s 
2025-01-11 10:22:31.660966:  
2025-01-11 10:22:31.661469: Epoch 141 
2025-01-11 10:22:31.666480: Current learning rate: 0.00474 
2025-01-11 10:23:10.338764: train_loss -0.7359 
2025-01-11 10:23:10.338764: val_loss -0.5712 
2025-01-11 10:23:10.345278: Pseudo dice [np.float32(0.7808), np.float32(0.4465)] 
2025-01-11 10:23:10.347783: Epoch time: 38.68 s 
2025-01-11 10:23:10.927908:  
2025-01-11 10:23:10.929417: Epoch 142 
2025-01-11 10:23:10.934451: Current learning rate: 0.0047 
2025-01-11 10:23:49.524220: train_loss -0.7456 
2025-01-11 10:23:49.524723: val_loss -0.5838 
2025-01-11 10:23:49.529734: Pseudo dice [np.float32(0.7864), np.float32(0.496)] 
2025-01-11 10:23:49.533243: Epoch time: 38.6 s 
2025-01-11 10:23:50.115511:  
2025-01-11 10:23:50.116515: Epoch 143 
2025-01-11 10:23:50.121069: Current learning rate: 0.00466 
2025-01-11 10:24:28.690889: train_loss -0.7359 
2025-01-11 10:24:28.691396: val_loss -0.5858 
2025-01-11 10:24:28.696951: Pseudo dice [np.float32(0.7957), np.float32(0.4976)] 
2025-01-11 10:24:28.699995: Epoch time: 38.58 s 
2025-01-11 10:24:29.289728:  
2025-01-11 10:24:29.290241: Epoch 144 
2025-01-11 10:24:29.295294: Current learning rate: 0.00462 
2025-01-11 10:25:07.867405: train_loss -0.7616 
2025-01-11 10:25:07.868408: val_loss -0.5656 
2025-01-11 10:25:07.874539: Pseudo dice [np.float32(0.7891), np.float32(0.4142)] 
2025-01-11 10:25:07.877562: Epoch time: 38.58 s 
2025-01-11 10:25:08.474576:  
2025-01-11 10:25:08.474576: Epoch 145 
2025-01-11 10:25:08.480590: Current learning rate: 0.00458 
2025-01-11 10:25:47.059898: train_loss -0.7432 
2025-01-11 10:25:47.060902: val_loss -0.5694 
2025-01-11 10:25:47.065915: Pseudo dice [np.float32(0.7896), np.float32(0.4758)] 
2025-01-11 10:25:47.069422: Epoch time: 38.59 s 
2025-01-11 10:25:47.658558:  
2025-01-11 10:25:47.659061: Epoch 146 
2025-01-11 10:25:47.664072: Current learning rate: 0.00454 
2025-01-11 10:26:26.248538: train_loss -0.7078 
2025-01-11 10:26:26.249538: val_loss -0.5634 
2025-01-11 10:26:26.254552: Pseudo dice [np.float32(0.7939), np.float32(0.4592)] 
2025-01-11 10:26:26.258564: Epoch time: 38.59 s 
2025-01-11 10:26:27.013143:  
2025-01-11 10:26:27.013143: Epoch 147 
2025-01-11 10:26:27.019158: Current learning rate: 0.0045 
2025-01-11 10:27:05.592967: train_loss -0.7224 
2025-01-11 10:27:05.592967: val_loss -0.588 
2025-01-11 10:27:05.599568: Pseudo dice [np.float32(0.7864), np.float32(0.6506)] 
2025-01-11 10:27:05.602663: Epoch time: 38.58 s 
2025-01-11 10:27:06.191130:  
2025-01-11 10:27:06.191130: Epoch 148 
2025-01-11 10:27:06.196690: Current learning rate: 0.00446 
2025-01-11 10:27:44.796694: train_loss -0.7366 
2025-01-11 10:27:44.797202: val_loss -0.5624 
2025-01-11 10:27:44.802753: Pseudo dice [np.float32(0.7782), np.float32(0.6042)] 
2025-01-11 10:27:44.806279: Epoch time: 38.61 s 
2025-01-11 10:27:45.399409:  
2025-01-11 10:27:45.399409: Epoch 149 
2025-01-11 10:27:45.405476: Current learning rate: 0.00442 
2025-01-11 10:28:23.988762: train_loss -0.7379 
2025-01-11 10:28:23.989284: val_loss -0.5773 
2025-01-11 10:28:23.994901: Pseudo dice [np.float32(0.7592), np.float32(0.6408)] 
2025-01-11 10:28:23.997963: Epoch time: 38.59 s 
2025-01-11 10:28:24.744822:  
2025-01-11 10:28:24.744822: Epoch 150 
2025-01-11 10:28:24.749837: Current learning rate: 0.00438 
2025-01-11 10:29:03.355016: train_loss -0.7296 
2025-01-11 10:29:03.356017: val_loss -0.5585 
2025-01-11 10:29:03.361533: Pseudo dice [np.float32(0.7697), np.float32(0.501)] 
2025-01-11 10:29:03.364041: Epoch time: 38.61 s 
2025-01-11 10:29:03.943697:  
2025-01-11 10:29:03.944212: Epoch 151 
2025-01-11 10:29:03.949747: Current learning rate: 0.00434 
2025-01-11 10:29:42.552851: train_loss -0.7243 
2025-01-11 10:29:42.553851: val_loss -0.5698 
2025-01-11 10:29:42.559366: Pseudo dice [np.float32(0.7861), np.float32(0.5128)] 
2025-01-11 10:29:42.562875: Epoch time: 38.61 s 
2025-01-11 10:29:43.157774:  
2025-01-11 10:29:43.159276: Epoch 152 
2025-01-11 10:29:43.164292: Current learning rate: 0.0043 
2025-01-11 10:30:21.774275: train_loss -0.7354 
2025-01-11 10:30:21.774275: val_loss -0.6044 
2025-01-11 10:30:21.780299: Pseudo dice [np.float32(0.8008), np.float32(0.6323)] 
2025-01-11 10:30:21.783813: Epoch time: 38.62 s 
2025-01-11 10:30:22.375530:  
2025-01-11 10:30:22.376530: Epoch 153 
2025-01-11 10:30:22.381592: Current learning rate: 0.00427 
2025-01-11 10:31:01.032275: train_loss -0.7172 
2025-01-11 10:31:01.032778: val_loss -0.6154 
2025-01-11 10:31:01.037790: Pseudo dice [np.float32(0.7947), np.float32(0.6301)] 
2025-01-11 10:31:01.041300: Epoch time: 38.66 s 
2025-01-11 10:31:01.633378:  
2025-01-11 10:31:01.633880: Epoch 154 
2025-01-11 10:31:01.639898: Current learning rate: 0.00423 
2025-01-11 10:31:40.223304: train_loss -0.7294 
2025-01-11 10:31:40.224308: val_loss -0.5797 
2025-01-11 10:31:40.229901: Pseudo dice [np.float32(0.7861), np.float32(0.5263)] 
2025-01-11 10:31:40.233488: Epoch time: 38.59 s 
2025-01-11 10:31:41.039680:  
2025-01-11 10:31:41.040183: Epoch 155 
2025-01-11 10:31:41.045193: Current learning rate: 0.00419 
2025-01-11 10:32:19.612320: train_loss -0.7497 
2025-01-11 10:32:19.613324: val_loss -0.6014 
2025-01-11 10:32:19.618378: Pseudo dice [np.float32(0.8039), np.float32(0.6876)] 
2025-01-11 10:32:19.621411: Epoch time: 38.57 s 
2025-01-11 10:32:19.624443: Yayy! New best EMA pseudo Dice: 0.6728000044822693 
2025-01-11 10:32:20.381581:  
2025-01-11 10:32:20.381581: Epoch 156 
2025-01-11 10:32:20.386595: Current learning rate: 0.00415 
2025-01-11 10:32:58.960824: train_loss -0.7455 
2025-01-11 10:32:58.960824: val_loss -0.6032 
2025-01-11 10:32:58.967434: Pseudo dice [np.float32(0.7984), np.float32(0.6221)] 
2025-01-11 10:32:58.970474: Epoch time: 38.58 s 
2025-01-11 10:32:58.973530: Yayy! New best EMA pseudo Dice: 0.6765000224113464 
2025-01-11 10:32:59.752936:  
2025-01-11 10:32:59.753942: Epoch 157 
2025-01-11 10:32:59.758497: Current learning rate: 0.00411 
2025-01-11 10:33:38.350080: train_loss -0.7544 
2025-01-11 10:33:38.351079: val_loss -0.568 
2025-01-11 10:33:38.356595: Pseudo dice [np.float32(0.7945), np.float32(0.5185)] 
2025-01-11 10:33:38.359102: Epoch time: 38.6 s 
2025-01-11 10:33:38.961448:  
2025-01-11 10:33:38.962950: Epoch 158 
2025-01-11 10:33:38.967963: Current learning rate: 0.00407 
2025-01-11 10:34:17.558328: train_loss -0.7505 
2025-01-11 10:34:17.558844: val_loss -0.5566 
2025-01-11 10:34:17.563423: Pseudo dice [np.float32(0.7724), np.float32(0.495)] 
2025-01-11 10:34:17.567512: Epoch time: 38.6 s 
2025-01-11 10:34:18.153198:  
2025-01-11 10:34:18.154205: Epoch 159 
2025-01-11 10:34:18.158753: Current learning rate: 0.00403 
2025-01-11 10:34:56.770044: train_loss -0.7551 
2025-01-11 10:34:56.771049: val_loss -0.5702 
2025-01-11 10:34:56.776525: Pseudo dice [np.float32(0.802), np.float32(0.5446)] 
2025-01-11 10:34:56.780039: Epoch time: 38.62 s 
2025-01-11 10:34:57.386003:  
2025-01-11 10:34:57.386507: Epoch 160 
2025-01-11 10:34:57.391015: Current learning rate: 0.00399 
2025-01-11 10:35:36.002967: train_loss -0.7494 
2025-01-11 10:35:36.003472: val_loss -0.5887 
2025-01-11 10:35:36.009495: Pseudo dice [np.float32(0.7979), np.float32(0.5463)] 
2025-01-11 10:35:36.012005: Epoch time: 38.62 s 
2025-01-11 10:35:36.604545:  
2025-01-11 10:35:36.605550: Epoch 161 
2025-01-11 10:35:36.610103: Current learning rate: 0.00395 
2025-01-11 10:36:15.202729: train_loss -0.7653 
2025-01-11 10:36:15.202729: val_loss -0.5898 
2025-01-11 10:36:15.209750: Pseudo dice [np.float32(0.8083), np.float32(0.5281)] 
2025-01-11 10:36:15.213284: Epoch time: 38.6 s 
2025-01-11 10:36:15.880464:  
2025-01-11 10:36:15.881469: Epoch 162 
2025-01-11 10:36:15.886534: Current learning rate: 0.00391 
2025-01-11 10:36:54.478898: train_loss -0.7718 
2025-01-11 10:36:54.479405: val_loss -0.56 
2025-01-11 10:36:54.484967: Pseudo dice [np.float32(0.7956), np.float32(0.4896)] 
2025-01-11 10:36:54.488491: Epoch time: 38.6 s 
2025-01-11 10:36:55.273453:  
2025-01-11 10:36:55.273453: Epoch 163 
2025-01-11 10:36:55.280079: Current learning rate: 0.00387 
2025-01-11 10:37:33.896947: train_loss -0.7727 
2025-01-11 10:37:33.897951: val_loss -0.5818 
2025-01-11 10:37:33.903493: Pseudo dice [np.float32(0.7837), np.float32(0.5658)] 
2025-01-11 10:37:33.906011: Epoch time: 38.62 s 
2025-01-11 10:37:34.506254:  
2025-01-11 10:37:34.507260: Epoch 164 
2025-01-11 10:37:34.512807: Current learning rate: 0.00383 
2025-01-11 10:38:13.121001: train_loss -0.7713 
2025-01-11 10:38:13.121505: val_loss -0.5497 
2025-01-11 10:38:13.126519: Pseudo dice [np.float32(0.7766), np.float32(0.4608)] 
2025-01-11 10:38:13.130034: Epoch time: 38.61 s 
2025-01-11 10:38:13.718513:  
2025-01-11 10:38:13.718513: Epoch 165 
2025-01-11 10:38:13.724731: Current learning rate: 0.00379 
2025-01-11 10:38:52.339385: train_loss -0.7726 
2025-01-11 10:38:52.340383: val_loss -0.5837 
2025-01-11 10:38:52.345906: Pseudo dice [np.float32(0.7909), np.float32(0.5884)] 
2025-01-11 10:38:52.348413: Epoch time: 38.62 s 
2025-01-11 10:38:52.927899:  
2025-01-11 10:38:52.927899: Epoch 166 
2025-01-11 10:38:52.933461: Current learning rate: 0.00375 
2025-01-11 10:39:31.591119: train_loss -0.7676 
2025-01-11 10:39:31.591625: val_loss -0.5888 
2025-01-11 10:39:31.596769: Pseudo dice [np.float32(0.7991), np.float32(0.5541)] 
2025-01-11 10:39:31.599796: Epoch time: 38.66 s 
2025-01-11 10:39:32.183949:  
2025-01-11 10:39:32.184452: Epoch 167 
2025-01-11 10:39:32.189518: Current learning rate: 0.00371 
2025-01-11 10:40:10.782790: train_loss -0.7647 
2025-01-11 10:40:10.783293: val_loss -0.5452 
2025-01-11 10:40:10.788305: Pseudo dice [np.float32(0.79), np.float32(0.5062)] 
2025-01-11 10:40:10.791814: Epoch time: 38.6 s 
2025-01-11 10:40:11.394056:  
2025-01-11 10:40:11.395056: Epoch 168 
2025-01-11 10:40:11.400127: Current learning rate: 0.00367 
2025-01-11 10:40:50.002663: train_loss -0.7736 
2025-01-11 10:40:50.004166: val_loss -0.5648 
2025-01-11 10:40:50.009179: Pseudo dice [np.float32(0.7973), np.float32(0.5218)] 
2025-01-11 10:40:50.012688: Epoch time: 38.61 s 
2025-01-11 10:40:50.594486:  
2025-01-11 10:40:50.594486: Epoch 169 
2025-01-11 10:40:50.599544: Current learning rate: 0.00363 
2025-01-11 10:41:29.228447: train_loss -0.7737 
2025-01-11 10:41:29.228950: val_loss -0.6233 
2025-01-11 10:41:29.233554: Pseudo dice [np.float32(0.8023), np.float32(0.6707)] 
2025-01-11 10:41:29.237076: Epoch time: 38.63 s 
2025-01-11 10:41:29.836095:  
2025-01-11 10:41:29.837099: Epoch 170 
2025-01-11 10:41:29.841654: Current learning rate: 0.00359 
2025-01-11 10:42:08.565355: train_loss -0.7737 
2025-01-11 10:42:08.565355: val_loss -0.5788 
2025-01-11 10:42:08.571505: Pseudo dice [np.float32(0.7889), np.float32(0.5892)] 
2025-01-11 10:42:08.574568: Epoch time: 38.73 s 
2025-01-11 10:42:09.173786:  
2025-01-11 10:42:09.173786: Epoch 171 
2025-01-11 10:42:09.180301: Current learning rate: 0.00355 
2025-01-11 10:42:47.790956: train_loss -0.7766 
2025-01-11 10:42:47.791479: val_loss -0.6235 
2025-01-11 10:42:47.796022: Pseudo dice [np.float32(0.8115), np.float32(0.6511)] 
2025-01-11 10:42:47.799537: Epoch time: 38.62 s 
2025-01-11 10:42:47.802048: Yayy! New best EMA pseudo Dice: 0.6794000267982483 
2025-01-11 10:42:48.543081:  
2025-01-11 10:42:48.544081: Epoch 172 
2025-01-11 10:42:48.549178: Current learning rate: 0.00351 
2025-01-11 10:43:27.169959: train_loss -0.7717 
2025-01-11 10:43:27.170964: val_loss -0.6008 
2025-01-11 10:43:27.175892: Pseudo dice [np.float32(0.7884), np.float32(0.6373)] 
2025-01-11 10:43:27.180504: Epoch time: 38.63 s 
2025-01-11 10:43:27.183010: Yayy! New best EMA pseudo Dice: 0.682699978351593 
2025-01-11 10:43:27.950383:  
2025-01-11 10:43:27.950886: Epoch 173 
2025-01-11 10:43:27.955897: Current learning rate: 0.00346 
2025-01-11 10:44:06.563126: train_loss -0.779 
2025-01-11 10:44:06.563633: val_loss -0.6294 
2025-01-11 10:44:06.569278: Pseudo dice [np.float32(0.8215), np.float32(0.586)] 
2025-01-11 10:44:06.572834: Epoch time: 38.61 s 
2025-01-11 10:44:06.575904: Yayy! New best EMA pseudo Dice: 0.6848000288009644 
2025-01-11 10:44:07.341130:  
2025-01-11 10:44:07.341130: Epoch 174 
2025-01-11 10:44:07.346696: Current learning rate: 0.00342 
2025-01-11 10:44:45.944994: train_loss -0.7699 
2025-01-11 10:44:45.944994: val_loss -0.5944 
2025-01-11 10:44:45.950595: Pseudo dice [np.float32(0.8058), np.float32(0.5417)] 
2025-01-11 10:44:45.954239: Epoch time: 38.6 s 
2025-01-11 10:44:46.537162:  
2025-01-11 10:44:46.537162: Epoch 175 
2025-01-11 10:44:46.542712: Current learning rate: 0.00338 
2025-01-11 10:45:25.141141: train_loss -0.7757 
2025-01-11 10:45:25.141661: val_loss -0.5451 
2025-01-11 10:45:25.147274: Pseudo dice [np.float32(0.7902), np.float32(0.5183)] 
2025-01-11 10:45:25.150312: Epoch time: 38.6 s 
2025-01-11 10:45:25.740652:  
2025-01-11 10:45:25.740652: Epoch 176 
2025-01-11 10:45:25.745683: Current learning rate: 0.00334 
2025-01-11 10:46:04.361447: train_loss -0.7747 
2025-01-11 10:46:04.361951: val_loss -0.581 
2025-01-11 10:46:04.367500: Pseudo dice [np.float32(0.7972), np.float32(0.5571)] 
2025-01-11 10:46:04.370526: Epoch time: 38.62 s 
2025-01-11 10:46:04.963111:  
2025-01-11 10:46:04.963111: Epoch 177 
2025-01-11 10:46:04.968122: Current learning rate: 0.0033 
2025-01-11 10:46:43.561836: train_loss -0.7798 
2025-01-11 10:46:43.561836: val_loss -0.5915 
2025-01-11 10:46:43.567851: Pseudo dice [np.float32(0.7858), np.float32(0.5594)] 
2025-01-11 10:46:43.571357: Epoch time: 38.6 s 
2025-01-11 10:46:44.325001:  
2025-01-11 10:46:44.325503: Epoch 178 
2025-01-11 10:46:44.330515: Current learning rate: 0.00326 
2025-01-11 10:47:22.912174: train_loss -0.7781 
2025-01-11 10:47:22.912678: val_loss -0.5903 
2025-01-11 10:47:22.918692: Pseudo dice [np.float32(0.802), np.float32(0.5587)] 
2025-01-11 10:47:22.921198: Epoch time: 38.59 s 
2025-01-11 10:47:23.514244:  
2025-01-11 10:47:23.514244: Epoch 179 
2025-01-11 10:47:23.519767: Current learning rate: 0.00322 
2025-01-11 10:48:02.205589: train_loss -0.7838 
2025-01-11 10:48:02.206100: val_loss -0.5182 
2025-01-11 10:48:02.212204: Pseudo dice [np.float32(0.7941), np.float32(0.3843)] 
2025-01-11 10:48:02.215255: Epoch time: 38.69 s 
2025-01-11 10:48:02.806791:  
2025-01-11 10:48:02.807794: Epoch 180 
2025-01-11 10:48:02.812354: Current learning rate: 0.00318 
2025-01-11 10:48:41.434573: train_loss -0.7789 
2025-01-11 10:48:41.435084: val_loss -0.5902 
2025-01-11 10:48:41.440650: Pseudo dice [np.float32(0.7932), np.float32(0.5606)] 
2025-01-11 10:48:41.443174: Epoch time: 38.63 s 
2025-01-11 10:48:42.031553:  
2025-01-11 10:48:42.031553: Epoch 181 
2025-01-11 10:48:42.037087: Current learning rate: 0.00314 
2025-01-11 10:49:20.608930: train_loss -0.7838 
2025-01-11 10:49:20.608930: val_loss -0.6083 
2025-01-11 10:49:20.614972: Pseudo dice [np.float32(0.8151), np.float32(0.5804)] 
2025-01-11 10:49:20.617991: Epoch time: 38.58 s 
2025-01-11 10:49:21.210597:  
2025-01-11 10:49:21.211600: Epoch 182 
2025-01-11 10:49:21.217194: Current learning rate: 0.0031 
2025-01-11 10:49:59.811222: train_loss -0.7905 
2025-01-11 10:49:59.812225: val_loss -0.532 
2025-01-11 10:49:59.817236: Pseudo dice [np.float32(0.7879), np.float32(0.3756)] 
2025-01-11 10:49:59.821244: Epoch time: 38.6 s 
2025-01-11 10:50:00.415792:  
2025-01-11 10:50:00.415792: Epoch 183 
2025-01-11 10:50:00.420801: Current learning rate: 0.00306 
2025-01-11 10:50:38.996761: train_loss -0.7966 
2025-01-11 10:50:38.997263: val_loss -0.5962 
2025-01-11 10:50:39.002277: Pseudo dice [np.float32(0.8087), np.float32(0.5651)] 
2025-01-11 10:50:39.005790: Epoch time: 38.58 s 
2025-01-11 10:50:39.599035:  
2025-01-11 10:50:39.600036: Epoch 184 
2025-01-11 10:50:39.605057: Current learning rate: 0.00302 
2025-01-11 10:51:18.169024: train_loss -0.791 
2025-01-11 10:51:18.169024: val_loss -0.558 
2025-01-11 10:51:18.174559: Pseudo dice [np.float32(0.7872), np.float32(0.4869)] 
2025-01-11 10:51:18.178067: Epoch time: 38.57 s 
2025-01-11 10:51:18.767997:  
2025-01-11 10:51:18.767997: Epoch 185 
2025-01-11 10:51:18.773093: Current learning rate: 0.00297 
2025-01-11 10:51:57.354443: train_loss -0.7975 
2025-01-11 10:51:57.355446: val_loss -0.5721 
2025-01-11 10:51:57.361457: Pseudo dice [np.float32(0.808), np.float32(0.5654)] 
2025-01-11 10:51:57.365469: Epoch time: 38.59 s 
2025-01-11 10:51:58.141926:  
2025-01-11 10:51:58.142428: Epoch 186 
2025-01-11 10:51:58.147442: Current learning rate: 0.00293 
2025-01-11 10:52:36.722241: train_loss -0.7973 
2025-01-11 10:52:36.723245: val_loss -0.5001 
2025-01-11 10:52:36.730707: Pseudo dice [np.float32(0.7508), np.float32(0.4819)] 
2025-01-11 10:52:36.732992: Epoch time: 38.58 s 
2025-01-11 10:52:37.320268:  
2025-01-11 10:52:37.320268: Epoch 187 
2025-01-11 10:52:37.325785: Current learning rate: 0.00289 
2025-01-11 10:53:15.891359: train_loss -0.7962 
2025-01-11 10:53:15.892362: val_loss -0.612 
2025-01-11 10:53:15.897402: Pseudo dice [np.float32(0.8115), np.float32(0.5975)] 
2025-01-11 10:53:15.900424: Epoch time: 38.57 s 
2025-01-11 10:53:16.498826:  
2025-01-11 10:53:16.499334: Epoch 188 
2025-01-11 10:53:16.504894: Current learning rate: 0.00285 
2025-01-11 10:53:55.104367: train_loss -0.8026 
2025-01-11 10:53:55.104870: val_loss -0.5674 
2025-01-11 10:53:55.110478: Pseudo dice [np.float32(0.7923), np.float32(0.5036)] 
2025-01-11 10:53:55.113527: Epoch time: 38.61 s 
2025-01-11 10:53:55.702825:  
2025-01-11 10:53:55.703825: Epoch 189 
2025-01-11 10:53:55.708412: Current learning rate: 0.00281 
2025-01-11 10:54:34.281298: train_loss -0.7955 
2025-01-11 10:54:34.282298: val_loss -0.6112 
2025-01-11 10:54:34.287815: Pseudo dice [np.float32(0.8055), np.float32(0.6223)] 
2025-01-11 10:54:34.290321: Epoch time: 38.58 s 
2025-01-11 10:54:34.877744:  
2025-01-11 10:54:34.877744: Epoch 190 
2025-01-11 10:54:34.882756: Current learning rate: 0.00277 
2025-01-11 10:55:13.504649: train_loss -0.7654 
2025-01-11 10:55:13.505160: val_loss -0.5402 
2025-01-11 10:55:13.510782: Pseudo dice [np.float32(0.7895), np.float32(0.4821)] 
2025-01-11 10:55:13.514421: Epoch time: 38.63 s 
2025-01-11 10:55:14.105017:  
2025-01-11 10:55:14.106021: Epoch 191 
2025-01-11 10:55:14.110577: Current learning rate: 0.00273 
2025-01-11 10:55:52.720843: train_loss -0.7703 
2025-01-11 10:55:52.722346: val_loss -0.609 
2025-01-11 10:55:52.727358: Pseudo dice [np.float32(0.7956), np.float32(0.5788)] 
2025-01-11 10:55:52.730869: Epoch time: 38.62 s 
2025-01-11 10:55:53.328353:  
2025-01-11 10:55:53.328856: Epoch 192 
2025-01-11 10:55:53.333365: Current learning rate: 0.00268 
2025-01-11 10:56:32.053057: train_loss -0.7818 
2025-01-11 10:56:32.053560: val_loss -0.5734 
2025-01-11 10:56:32.059148: Pseudo dice [np.float32(0.7915), np.float32(0.5598)] 
2025-01-11 10:56:32.061693: Epoch time: 38.73 s 
2025-01-11 10:56:32.865992:  
2025-01-11 10:56:32.865992: Epoch 193 
2025-01-11 10:56:32.871005: Current learning rate: 0.00264 
2025-01-11 10:57:11.457955: train_loss -0.7897 
2025-01-11 10:57:11.458959: val_loss -0.5564 
2025-01-11 10:57:11.463971: Pseudo dice [np.float32(0.7959), np.float32(0.5882)] 
2025-01-11 10:57:11.467978: Epoch time: 38.59 s 
2025-01-11 10:57:12.071239:  
2025-01-11 10:57:12.071741: Epoch 194 
2025-01-11 10:57:12.076773: Current learning rate: 0.0026 
2025-01-11 10:57:50.681995: train_loss -0.8024 
2025-01-11 10:57:50.682522: val_loss -0.5995 
2025-01-11 10:57:50.687579: Pseudo dice [np.float32(0.7978), np.float32(0.6461)] 
2025-01-11 10:57:50.691102: Epoch time: 38.61 s 
2025-01-11 10:57:51.280800:  
2025-01-11 10:57:51.280800: Epoch 195 
2025-01-11 10:57:51.285388: Current learning rate: 0.00256 
2025-01-11 10:58:29.878711: train_loss -0.8083 
2025-01-11 10:58:29.879715: val_loss -0.5734 
2025-01-11 10:58:29.884728: Pseudo dice [np.float32(0.8077), np.float32(0.5294)] 
2025-01-11 10:58:29.888741: Epoch time: 38.6 s 
2025-01-11 10:58:30.496419:  
2025-01-11 10:58:30.497423: Epoch 196 
2025-01-11 10:58:30.502309: Current learning rate: 0.00252 
2025-01-11 10:59:09.087415: train_loss -0.804 
2025-01-11 10:59:09.087415: val_loss -0.5924 
2025-01-11 10:59:09.093430: Pseudo dice [np.float32(0.8112), np.float32(0.5433)] 
2025-01-11 10:59:09.096441: Epoch time: 38.59 s 
2025-01-11 10:59:09.689768:  
2025-01-11 10:59:09.690773: Epoch 197 
2025-01-11 10:59:09.694830: Current learning rate: 0.00248 
2025-01-11 10:59:48.277774: train_loss -0.8037 
2025-01-11 10:59:48.278773: val_loss -0.6223 
2025-01-11 10:59:48.285289: Pseudo dice [np.float32(0.8022), np.float32(0.6549)] 
2025-01-11 10:59:48.287796: Epoch time: 38.59 s 
2025-01-11 10:59:48.964455:  
2025-01-11 10:59:48.964455: Epoch 198 
2025-01-11 10:59:48.969485: Current learning rate: 0.00243 
2025-01-11 11:00:27.565025: train_loss -0.7992 
2025-01-11 11:00:27.565541: val_loss -0.5713 
2025-01-11 11:00:27.570666: Pseudo dice [np.float32(0.7932), np.float32(0.5241)] 
2025-01-11 11:00:27.573770: Epoch time: 38.6 s 
2025-01-11 11:00:28.170593:  
2025-01-11 11:00:28.171593: Epoch 199 
2025-01-11 11:00:28.176656: Current learning rate: 0.00239 
2025-01-11 11:01:06.777094: train_loss -0.7998 
2025-01-11 11:01:06.777596: val_loss -0.556 
2025-01-11 11:01:06.783196: Pseudo dice [np.float32(0.8051), np.float32(0.5614)] 
2025-01-11 11:01:06.786220: Epoch time: 38.61 s 
2025-01-11 11:01:07.544053:  
2025-01-11 11:01:07.544559: Epoch 200 
2025-01-11 11:01:07.548588: Current learning rate: 0.00235 
2025-01-11 11:01:46.238709: train_loss -0.7988 
2025-01-11 11:01:46.239712: val_loss -0.5966 
2025-01-11 11:01:46.244723: Pseudo dice [np.float32(0.8033), np.float32(0.6187)] 
2025-01-11 11:01:46.248227: Epoch time: 38.7 s 
2025-01-11 11:01:46.856051:  
2025-01-11 11:01:46.856553: Epoch 201 
2025-01-11 11:01:46.860106: Current learning rate: 0.00231 
2025-01-11 11:02:25.449923: train_loss -0.7972 
2025-01-11 11:02:25.449923: val_loss -0.5952 
2025-01-11 11:02:25.455938: Pseudo dice [np.float32(0.7964), np.float32(0.5617)] 
2025-01-11 11:02:25.458443: Epoch time: 38.59 s 
2025-01-11 11:02:26.064149:  
2025-01-11 11:02:26.065152: Epoch 202 
2025-01-11 11:02:26.070204: Current learning rate: 0.00226 
2025-01-11 11:03:04.697025: train_loss -0.7988 
2025-01-11 11:03:04.698027: val_loss -0.5133 
2025-01-11 11:03:04.703548: Pseudo dice [np.float32(0.7896), np.float32(0.3774)] 
2025-01-11 11:03:04.706054: Epoch time: 38.63 s 
2025-01-11 11:03:05.316430:  
2025-01-11 11:03:05.316430: Epoch 203 
2025-01-11 11:03:05.321459: Current learning rate: 0.00222 
2025-01-11 11:03:43.944875: train_loss -0.791 
2025-01-11 11:03:43.945876: val_loss -0.5874 
2025-01-11 11:03:43.951419: Pseudo dice [np.float32(0.7977), np.float32(0.6151)] 
2025-01-11 11:03:43.954931: Epoch time: 38.63 s 
2025-01-11 11:03:44.550258:  
2025-01-11 11:03:44.550258: Epoch 204 
2025-01-11 11:03:44.555681: Current learning rate: 0.00218 
2025-01-11 11:04:23.230811: train_loss -0.8052 
2025-01-11 11:04:23.230811: val_loss -0.5344 
2025-01-11 11:04:23.237395: Pseudo dice [np.float32(0.7986), np.float32(0.4366)] 
2025-01-11 11:04:23.240441: Epoch time: 38.68 s 
2025-01-11 11:04:23.842048:  
2025-01-11 11:04:23.843051: Epoch 205 
2025-01-11 11:04:23.847681: Current learning rate: 0.00214 
2025-01-11 11:05:02.440298: train_loss -0.8052 
2025-01-11 11:05:02.441301: val_loss -0.5635 
2025-01-11 11:05:02.447351: Pseudo dice [np.float32(0.7977), np.float32(0.4574)] 
2025-01-11 11:05:02.450385: Epoch time: 38.6 s 
2025-01-11 11:05:03.020574:  
2025-01-11 11:05:03.020574: Epoch 206 
2025-01-11 11:05:03.025598: Current learning rate: 0.00209 
2025-01-11 11:05:41.645264: train_loss -0.8049 
2025-01-11 11:05:41.645264: val_loss -0.5918 
2025-01-11 11:05:41.652785: Pseudo dice [np.float32(0.8091), np.float32(0.5903)] 
2025-01-11 11:05:41.655292: Epoch time: 38.63 s 
2025-01-11 11:05:42.220250:  
2025-01-11 11:05:42.220250: Epoch 207 
2025-01-11 11:05:42.225798: Current learning rate: 0.00205 
2025-01-11 11:06:20.865618: train_loss -0.8105 
2025-01-11 11:06:20.866122: val_loss -0.6029 
2025-01-11 11:06:20.871135: Pseudo dice [np.float32(0.8052), np.float32(0.5778)] 
2025-01-11 11:06:20.873682: Epoch time: 38.65 s 
2025-01-11 11:06:21.637859:  
2025-01-11 11:06:21.637859: Epoch 208 
2025-01-11 11:06:21.643914: Current learning rate: 0.00201 
2025-01-11 11:07:00.286782: train_loss -0.8176 
2025-01-11 11:07:00.286782: val_loss -0.6115 
2025-01-11 11:07:00.292796: Pseudo dice [np.float32(0.8212), np.float32(0.518)] 
2025-01-11 11:07:00.295805: Epoch time: 38.65 s 
2025-01-11 11:07:00.871905:  
2025-01-11 11:07:00.872909: Epoch 209 
2025-01-11 11:07:00.877567: Current learning rate: 0.00196 
2025-01-11 11:07:39.505644: train_loss -0.8123 
2025-01-11 11:07:39.505644: val_loss -0.5674 
2025-01-11 11:07:39.512666: Pseudo dice [np.float32(0.7761), np.float32(0.6149)] 
2025-01-11 11:07:39.515679: Epoch time: 38.63 s 
2025-01-11 11:07:40.077042:  
2025-01-11 11:07:40.078045: Epoch 210 
2025-01-11 11:07:40.083076: Current learning rate: 0.00192 
2025-01-11 11:08:18.729610: train_loss -0.807 
2025-01-11 11:08:18.730647: val_loss -0.5791 
2025-01-11 11:08:18.735734: Pseudo dice [np.float32(0.8034), np.float32(0.5781)] 
2025-01-11 11:08:18.738784: Epoch time: 38.65 s 
2025-01-11 11:08:19.312590:  
2025-01-11 11:08:19.313591: Epoch 211 
2025-01-11 11:08:19.318653: Current learning rate: 0.00188 
2025-01-11 11:08:57.961347: train_loss -0.8138 
2025-01-11 11:08:57.961863: val_loss -0.5841 
2025-01-11 11:08:57.967439: Pseudo dice [np.float32(0.7978), np.float32(0.5804)] 
2025-01-11 11:08:57.969967: Epoch time: 38.65 s 
2025-01-11 11:08:58.544147:  
2025-01-11 11:08:58.544147: Epoch 212 
2025-01-11 11:08:58.549217: Current learning rate: 0.00184 
2025-01-11 11:09:37.176309: train_loss -0.8161 
2025-01-11 11:09:37.176309: val_loss -0.564 
2025-01-11 11:09:37.182328: Pseudo dice [np.float32(0.805), np.float32(0.473)] 
2025-01-11 11:09:37.185843: Epoch time: 38.63 s 
2025-01-11 11:09:37.756453:  
2025-01-11 11:09:37.757454: Epoch 213 
2025-01-11 11:09:37.762038: Current learning rate: 0.00179 
2025-01-11 11:10:16.381612: train_loss -0.808 
2025-01-11 11:10:16.382611: val_loss -0.5576 
2025-01-11 11:10:16.386621: Pseudo dice [np.float32(0.7904), np.float32(0.4196)] 
2025-01-11 11:10:16.390633: Epoch time: 38.63 s 
2025-01-11 11:10:16.955373:  
2025-01-11 11:10:16.955875: Epoch 214 
2025-01-11 11:10:16.960885: Current learning rate: 0.00175 
2025-01-11 11:10:55.592810: train_loss -0.8059 
2025-01-11 11:10:55.593320: val_loss -0.5595 
2025-01-11 11:10:55.599448: Pseudo dice [np.float32(0.7992), np.float32(0.5038)] 
2025-01-11 11:10:55.602515: Epoch time: 38.64 s 
2025-01-11 11:10:56.169951:  
2025-01-11 11:10:56.170951: Epoch 215 
2025-01-11 11:10:56.176048: Current learning rate: 0.0017 
2025-01-11 11:11:34.796474: train_loss -0.8006 
2025-01-11 11:11:34.796977: val_loss -0.5806 
2025-01-11 11:11:34.802028: Pseudo dice [np.float32(0.8007), np.float32(0.6001)] 
2025-01-11 11:11:34.806060: Epoch time: 38.63 s 
2025-01-11 11:11:35.551781:  
2025-01-11 11:11:35.551781: Epoch 216 
2025-01-11 11:11:35.557813: Current learning rate: 0.00166 
2025-01-11 11:12:14.176219: train_loss -0.8118 
2025-01-11 11:12:14.177219: val_loss -0.6294 
2025-01-11 11:12:14.182744: Pseudo dice [np.float32(0.8076), np.float32(0.6926)] 
2025-01-11 11:12:14.186262: Epoch time: 38.62 s 
2025-01-11 11:12:14.751421:  
2025-01-11 11:12:14.751421: Epoch 217 
2025-01-11 11:12:14.756433: Current learning rate: 0.00162 
2025-01-11 11:12:53.418997: train_loss -0.8111 
2025-01-11 11:12:53.419508: val_loss -0.6143 
2025-01-11 11:12:53.425576: Pseudo dice [np.float32(0.8), np.float32(0.5544)] 
2025-01-11 11:12:53.428613: Epoch time: 38.67 s 
2025-01-11 11:12:53.993146:  
2025-01-11 11:12:53.993651: Epoch 218 
2025-01-11 11:12:53.998662: Current learning rate: 0.00157 
2025-01-11 11:13:32.621939: train_loss -0.8176 
2025-01-11 11:13:32.621939: val_loss -0.5941 
2025-01-11 11:13:32.628284: Pseudo dice [np.float32(0.8184), np.float32(0.5634)] 
2025-01-11 11:13:32.631798: Epoch time: 38.63 s 
2025-01-11 11:13:33.188919:  
2025-01-11 11:13:33.190422: Epoch 219 
2025-01-11 11:13:33.195435: Current learning rate: 0.00153 
2025-01-11 11:14:11.807919: train_loss -0.8237 
2025-01-11 11:14:11.808421: val_loss -0.5855 
2025-01-11 11:14:11.814037: Pseudo dice [np.float32(0.8089), np.float32(0.6098)] 
2025-01-11 11:14:11.817606: Epoch time: 38.62 s 
2025-01-11 11:14:12.382460:  
2025-01-11 11:14:12.382460: Epoch 220 
2025-01-11 11:14:12.388514: Current learning rate: 0.00148 
2025-01-11 11:14:51.004620: train_loss -0.8207 
2025-01-11 11:14:51.004620: val_loss -0.5978 
2025-01-11 11:14:51.011174: Pseudo dice [np.float32(0.8027), np.float32(0.6122)] 
2025-01-11 11:14:51.014712: Epoch time: 38.62 s 
2025-01-11 11:14:51.581509:  
2025-01-11 11:14:51.581509: Epoch 221 
2025-01-11 11:14:51.586518: Current learning rate: 0.00144 
2025-01-11 11:15:30.208174: train_loss -0.8195 
2025-01-11 11:15:30.209174: val_loss -0.5906 
2025-01-11 11:15:30.214695: Pseudo dice [np.float32(0.8046), np.float32(0.6151)] 
2025-01-11 11:15:30.218208: Epoch time: 38.63 s 
2025-01-11 11:15:30.220718: Yayy! New best EMA pseudo Dice: 0.6862999796867371 
2025-01-11 11:15:30.954750:  
2025-01-11 11:15:30.954750: Epoch 222 
2025-01-11 11:15:30.960296: Current learning rate: 0.00139 
2025-01-11 11:16:09.592189: train_loss -0.8171 
2025-01-11 11:16:09.592729: val_loss -0.5739 
2025-01-11 11:16:09.597832: Pseudo dice [np.float32(0.7975), np.float32(0.4789)] 
2025-01-11 11:16:09.602345: Epoch time: 38.64 s 
2025-01-11 11:16:10.194280:  
2025-01-11 11:16:10.194793: Epoch 223 
2025-01-11 11:16:10.199893: Current learning rate: 0.00135 
2025-01-11 11:16:48.828854: train_loss -0.8202 
2025-01-11 11:16:48.828854: val_loss -0.6173 
2025-01-11 11:16:48.834928: Pseudo dice [np.float32(0.8032), np.float32(0.6396)] 
2025-01-11 11:16:48.837966: Epoch time: 38.64 s 
2025-01-11 11:16:49.406347:  
2025-01-11 11:16:49.406347: Epoch 224 
2025-01-11 11:16:49.410400: Current learning rate: 0.0013 
2025-01-11 11:17:28.034234: train_loss -0.8177 
2025-01-11 11:17:28.035237: val_loss -0.5343 
2025-01-11 11:17:28.040249: Pseudo dice [np.float32(0.792), np.float32(0.5041)] 
2025-01-11 11:17:28.043754: Epoch time: 38.63 s 
2025-01-11 11:17:28.789888:  
2025-01-11 11:17:28.789888: Epoch 225 
2025-01-11 11:17:28.795426: Current learning rate: 0.00126 
2025-01-11 11:18:07.422215: train_loss -0.8197 
2025-01-11 11:18:07.423218: val_loss -0.5668 
2025-01-11 11:18:07.428236: Pseudo dice [np.float32(0.7964), np.float32(0.5514)] 
2025-01-11 11:18:07.430744: Epoch time: 38.63 s 
2025-01-11 11:18:07.998237:  
2025-01-11 11:18:07.999741: Epoch 226 
2025-01-11 11:18:08.004753: Current learning rate: 0.00121 
2025-01-11 11:18:46.626739: train_loss -0.8187 
2025-01-11 11:18:46.627744: val_loss -0.5748 
2025-01-11 11:18:46.633017: Pseudo dice [np.float32(0.8064), np.float32(0.5396)] 
2025-01-11 11:18:46.636541: Epoch time: 38.63 s 
2025-01-11 11:18:47.194895:  
2025-01-11 11:18:47.195901: Epoch 227 
2025-01-11 11:18:47.200460: Current learning rate: 0.00117 
2025-01-11 11:19:25.820141: train_loss -0.8234 
2025-01-11 11:19:25.821145: val_loss -0.571 
2025-01-11 11:19:25.826157: Pseudo dice [np.float32(0.7963), np.float32(0.4786)] 
2025-01-11 11:19:25.830164: Epoch time: 38.63 s 
2025-01-11 11:19:26.396807:  
2025-01-11 11:19:26.396807: Epoch 228 
2025-01-11 11:19:26.401320: Current learning rate: 0.00112 
2025-01-11 11:20:05.017927: train_loss -0.8245 
2025-01-11 11:20:05.018930: val_loss -0.5871 
2025-01-11 11:20:05.024521: Pseudo dice [np.float32(0.8148), np.float32(0.4989)] 
2025-01-11 11:20:05.027545: Epoch time: 38.62 s 
2025-01-11 11:20:05.594826:  
2025-01-11 11:20:05.595328: Epoch 229 
2025-01-11 11:20:05.600357: Current learning rate: 0.00108 
2025-01-11 11:20:44.195713: train_loss -0.8174 
2025-01-11 11:20:44.196215: val_loss -0.5782 
2025-01-11 11:20:44.201225: Pseudo dice [np.float32(0.8011), np.float32(0.5676)] 
2025-01-11 11:20:44.203730: Epoch time: 38.6 s 
2025-01-11 11:20:44.775970:  
2025-01-11 11:20:44.775970: Epoch 230 
2025-01-11 11:20:44.781563: Current learning rate: 0.00103 
2025-01-11 11:21:23.466697: train_loss -0.8247 
2025-01-11 11:21:23.467205: val_loss -0.5867 
2025-01-11 11:21:23.472239: Pseudo dice [np.float32(0.8105), np.float32(0.5461)] 
2025-01-11 11:21:23.475255: Epoch time: 38.69 s 
2025-01-11 11:21:24.036894:  
2025-01-11 11:21:24.037413: Epoch 231 
2025-01-11 11:21:24.042424: Current learning rate: 0.00098 
2025-01-11 11:22:02.650104: train_loss -0.8245 
2025-01-11 11:22:02.650104: val_loss -0.6012 
2025-01-11 11:22:02.656618: Pseudo dice [np.float32(0.8028), np.float32(0.5924)] 
2025-01-11 11:22:02.660127: Epoch time: 38.61 s 
2025-01-11 11:22:03.231960:  
2025-01-11 11:22:03.232959: Epoch 232 
2025-01-11 11:22:03.238472: Current learning rate: 0.00094 
2025-01-11 11:22:41.865820: train_loss -0.8311 
2025-01-11 11:22:41.865820: val_loss -0.5834 
2025-01-11 11:22:41.871921: Pseudo dice [np.float32(0.8071), np.float32(0.5457)] 
2025-01-11 11:22:41.875445: Epoch time: 38.63 s 
2025-01-11 11:22:42.641223:  
2025-01-11 11:22:42.641731: Epoch 233 
2025-01-11 11:22:42.646775: Current learning rate: 0.00089 
2025-01-11 11:23:21.260497: train_loss -0.836 
2025-01-11 11:23:21.261016: val_loss -0.5885 
2025-01-11 11:23:21.266610: Pseudo dice [np.float32(0.7994), np.float32(0.5875)] 
2025-01-11 11:23:21.268787: Epoch time: 38.62 s 
2025-01-11 11:23:21.838719:  
2025-01-11 11:23:21.838719: Epoch 234 
2025-01-11 11:23:21.844852: Current learning rate: 0.00084 
2025-01-11 11:24:00.468637: train_loss -0.8307 
2025-01-11 11:24:00.469642: val_loss -0.6 
2025-01-11 11:24:00.474672: Pseudo dice [np.float32(0.8032), np.float32(0.6151)] 
2025-01-11 11:24:00.478199: Epoch time: 38.63 s 
2025-01-11 11:24:01.042875:  
2025-01-11 11:24:01.042875: Epoch 235 
2025-01-11 11:24:01.048445: Current learning rate: 0.00079 
2025-01-11 11:24:39.642279: train_loss -0.8284 
2025-01-11 11:24:39.642781: val_loss -0.604 
2025-01-11 11:24:39.647798: Pseudo dice [np.float32(0.8073), np.float32(0.5932)] 
2025-01-11 11:24:39.651314: Epoch time: 38.6 s 
2025-01-11 11:24:40.224759:  
2025-01-11 11:24:40.224759: Epoch 236 
2025-01-11 11:24:40.231198: Current learning rate: 0.00075 
2025-01-11 11:25:18.826731: train_loss -0.8301 
2025-01-11 11:25:18.827731: val_loss -0.5919 
2025-01-11 11:25:18.833243: Pseudo dice [np.float32(0.7951), np.float32(0.5649)] 
2025-01-11 11:25:18.836752: Epoch time: 38.6 s 
2025-01-11 11:25:19.412353:  
2025-01-11 11:25:19.412353: Epoch 237 
2025-01-11 11:25:19.418445: Current learning rate: 0.0007 
2025-01-11 11:25:58.023351: train_loss -0.8267 
2025-01-11 11:25:58.023351: val_loss -0.5677 
2025-01-11 11:25:58.028384: Pseudo dice [np.float32(0.7979), np.float32(0.5684)] 
2025-01-11 11:25:58.031904: Epoch time: 38.61 s 
2025-01-11 11:25:58.600074:  
2025-01-11 11:25:58.600575: Epoch 238 
2025-01-11 11:25:58.605587: Current learning rate: 0.00065 
2025-01-11 11:26:37.218915: train_loss -0.8216 
2025-01-11 11:26:37.219419: val_loss -0.5664 
2025-01-11 11:26:37.224439: Pseudo dice [np.float32(0.8064), np.float32(0.5354)] 
2025-01-11 11:26:37.227955: Epoch time: 38.62 s 
2025-01-11 11:26:37.801876:  
2025-01-11 11:26:37.802878: Epoch 239 
2025-01-11 11:26:37.807935: Current learning rate: 0.0006 
2025-01-11 11:27:16.455305: train_loss -0.8288 
2025-01-11 11:27:16.455807: val_loss -0.6016 
2025-01-11 11:27:16.461447: Pseudo dice [np.float32(0.8016), np.float32(0.684)] 
2025-01-11 11:27:16.465054: Epoch time: 38.65 s 
2025-01-11 11:27:16.467588: Yayy! New best EMA pseudo Dice: 0.6883000135421753 
2025-01-11 11:27:17.208045:  
2025-01-11 11:27:17.208553: Epoch 240 
2025-01-11 11:27:17.213593: Current learning rate: 0.00055 
2025-01-11 11:27:55.854154: train_loss -0.828 
2025-01-11 11:27:55.855154: val_loss -0.5526 
2025-01-11 11:27:55.859167: Pseudo dice [np.float32(0.7935), np.float32(0.4608)] 
2025-01-11 11:27:55.863174: Epoch time: 38.65 s 
2025-01-11 11:27:56.448260:  
2025-01-11 11:27:56.449263: Epoch 241 
2025-01-11 11:27:56.453815: Current learning rate: 0.0005 
2025-01-11 11:28:35.084370: train_loss -0.8309 
2025-01-11 11:28:35.084874: val_loss -0.5463 
2025-01-11 11:28:35.089885: Pseudo dice [np.float32(0.7954), np.float32(0.4255)] 
2025-01-11 11:28:35.093394: Epoch time: 38.64 s 
2025-01-11 11:28:35.869527:  
2025-01-11 11:28:35.869527: Epoch 242 
2025-01-11 11:28:35.874641: Current learning rate: 0.00045 
2025-01-11 11:29:14.510543: train_loss -0.8282 
2025-01-11 11:29:14.511547: val_loss -0.5812 
2025-01-11 11:29:14.517233: Pseudo dice [np.float32(0.8129), np.float32(0.5162)] 
2025-01-11 11:29:14.520321: Epoch time: 38.64 s 
2025-01-11 11:29:15.100327:  
2025-01-11 11:29:15.100830: Epoch 243 
2025-01-11 11:29:15.105840: Current learning rate: 0.0004 
2025-01-11 11:29:53.774328: train_loss -0.8282 
2025-01-11 11:29:53.774328: val_loss -0.5791 
2025-01-11 11:29:53.780348: Pseudo dice [np.float32(0.8109), np.float32(0.5149)] 
2025-01-11 11:29:53.783402: Epoch time: 38.68 s 
2025-01-11 11:29:54.358166:  
2025-01-11 11:29:54.359172: Epoch 244 
2025-01-11 11:29:54.363790: Current learning rate: 0.00035 
2025-01-11 11:30:32.984804: train_loss -0.8318 
2025-01-11 11:30:32.985804: val_loss -0.6012 
2025-01-11 11:30:32.991317: Pseudo dice [np.float32(0.8121), np.float32(0.5412)] 
2025-01-11 11:30:32.993822: Epoch time: 38.63 s 
2025-01-11 11:30:33.580474:  
2025-01-11 11:30:33.580474: Epoch 245 
2025-01-11 11:30:33.585486: Current learning rate: 0.0003 
2025-01-11 11:31:12.203275: train_loss -0.8317 
2025-01-11 11:31:12.203778: val_loss -0.618 
2025-01-11 11:31:12.208898: Pseudo dice [np.float32(0.8175), np.float32(0.5627)] 
2025-01-11 11:31:12.212036: Epoch time: 38.62 s 
2025-01-11 11:31:12.798940:  
2025-01-11 11:31:12.798940: Epoch 246 
2025-01-11 11:31:12.804514: Current learning rate: 0.00024 
2025-01-11 11:31:51.419677: train_loss -0.8283 
2025-01-11 11:31:51.419677: val_loss -0.5905 
2025-01-11 11:31:51.425236: Pseudo dice [np.float32(0.7946), np.float32(0.5849)] 
2025-01-11 11:31:51.428774: Epoch time: 38.62 s 
2025-01-11 11:31:52.000175:  
2025-01-11 11:31:52.000175: Epoch 247 
2025-01-11 11:31:52.005691: Current learning rate: 0.00019 
2025-01-11 11:32:30.622818: train_loss -0.8364 
2025-01-11 11:32:30.623822: val_loss -0.6064 
2025-01-11 11:32:30.628995: Pseudo dice [np.float32(0.817), np.float32(0.592)] 
2025-01-11 11:32:30.632574: Epoch time: 38.62 s 
2025-01-11 11:32:31.216407:  
2025-01-11 11:32:31.217406: Epoch 248 
2025-01-11 11:32:31.222456: Current learning rate: 0.00013 
2025-01-11 11:33:09.856434: train_loss -0.8352 
2025-01-11 11:33:09.858461: val_loss -0.5477 
2025-01-11 11:33:09.864116: Pseudo dice [np.float32(0.7963), np.float32(0.4549)] 
2025-01-11 11:33:09.866141: Epoch time: 38.64 s 
2025-01-11 11:33:10.454705:  
2025-01-11 11:33:10.455207: Epoch 249 
2025-01-11 11:33:10.460219: Current learning rate: 7e-05 
2025-01-11 11:33:49.068953: train_loss -0.8399 
2025-01-11 11:33:49.069953: val_loss -0.5524 
2025-01-11 11:33:49.075466: Pseudo dice [np.float32(0.7975), np.float32(0.4437)] 
2025-01-11 11:33:49.078975: Epoch time: 38.62 s 
2025-01-11 11:33:50.021529: Training done. 
2025-01-11 11:33:50.059528: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-11 11:33:50.071529: The split file contains 5 splits. 
2025-01-11 11:33:50.078531: Desired fold for training: 0 
2025-01-11 11:33:50.084528: This split has 224 training and 57 validation cases. 
2025-01-11 11:33:50.089528: predicting pancreas_021 
2025-01-11 11:33:50.095535: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-11 11:34:02.138737: predicting pancreas_024 
2025-01-11 11:34:02.151737: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-11 11:34:16.158657: predicting pancreas_035 
2025-01-11 11:34:16.173657: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-11 11:34:21.184032: predicting pancreas_040 
2025-01-11 11:34:21.189031: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-01-11 11:34:32.862125: predicting pancreas_042 
2025-01-11 11:34:32.873125: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-01-11 11:34:46.889978: predicting pancreas_056 
2025-01-11 11:34:46.902978: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-11 11:34:58.565097: predicting pancreas_067 
2025-01-11 11:34:58.573098: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-11 11:35:12.578079: predicting pancreas_075 
2025-01-11 11:35:12.589079: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-01-11 11:35:19.620566: predicting pancreas_086 
2025-01-11 11:35:19.628567: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-11 11:35:27.810468: predicting pancreas_089 
2025-01-11 11:35:27.821468: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-11 11:35:39.518197: predicting pancreas_092 
2025-01-11 11:35:39.528197: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-01-11 11:36:05.217004: predicting pancreas_094 
2025-01-11 11:36:05.235004: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-11 11:36:13.067446: predicting pancreas_095 
2025-01-11 11:36:13.078446: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-11 11:36:20.891795: predicting pancreas_098 
2025-01-11 11:36:20.900802: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-11 11:36:50.200708: predicting pancreas_109 
2025-01-11 11:36:50.218710: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-11 11:37:04.237401: predicting pancreas_110 
2025-01-11 11:37:04.247404: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-11 11:37:23.883244: predicting pancreas_114 
2025-01-11 11:37:23.897244: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-11 11:37:33.248331: predicting pancreas_119 
2025-01-11 11:37:33.257332: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-11 11:37:46.916370: predicting pancreas_138 
2025-01-11 11:37:46.927370: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-11 11:38:03.311452: predicting pancreas_145 
2025-01-11 11:38:03.329453: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-11 11:38:19.732474: predicting pancreas_148 
2025-01-11 11:38:19.749475: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-01-11 11:38:31.406476: predicting pancreas_169 
2025-01-11 11:38:31.414477: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-11 11:38:39.268135: predicting pancreas_170 
2025-01-11 11:38:39.277135: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-11 11:38:53.251235: predicting pancreas_172 
2025-01-11 11:38:53.262236: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-11 11:39:01.090921: predicting pancreas_175 
2025-01-11 11:39:01.098922: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-11 11:39:12.776313: predicting pancreas_180 
2025-01-11 11:39:12.785313: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-11 11:39:20.611904: predicting pancreas_191 
2025-01-11 11:39:20.621904: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-11 11:39:25.315730: predicting pancreas_193 
2025-01-11 11:39:25.321729: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-11 11:39:41.668562: predicting pancreas_212 
2025-01-11 11:39:41.679562: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-11 11:39:55.706637: predicting pancreas_215 
2025-01-11 11:39:55.719634: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-11 11:40:09.724377: predicting pancreas_222 
2025-01-11 11:40:09.733376: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-11 11:40:14.733013: predicting pancreas_235 
2025-01-11 11:40:14.739013: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-11 11:40:26.393130: predicting pancreas_241 
2025-01-11 11:40:26.402414: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-11 11:40:40.395607: predicting pancreas_242 
2025-01-11 11:40:40.409114: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-11 11:40:54.431333: predicting pancreas_244 
2025-01-11 11:40:54.444333: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-11 11:41:14.078426: predicting pancreas_246 
2025-01-11 11:41:14.092427: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-11 11:41:30.470217: predicting pancreas_247 
2025-01-11 11:41:30.485217: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-11 11:41:38.285176: predicting pancreas_264 
2025-01-11 11:41:38.292176: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-11 11:41:52.300215: predicting pancreas_265 
2025-01-11 11:41:52.316215: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-11 11:42:04.043653: predicting pancreas_266 
2025-01-11 11:42:04.053655: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-11 11:42:20.416754: predicting pancreas_267 
2025-01-11 11:42:20.428753: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-11 11:42:28.231036: predicting pancreas_275 
2025-01-11 11:42:28.238037: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-11 11:42:37.635569: predicting pancreas_279 
2025-01-11 11:42:37.645569: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-11 11:42:43.900819: predicting pancreas_287 
2025-01-11 11:42:43.907819: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-11 11:42:57.910776: predicting pancreas_301 
2025-01-11 11:42:57.920777: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-11 11:43:09.639813: predicting pancreas_323 
2025-01-11 11:43:09.648814: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-11 11:43:26.046435: predicting pancreas_336 
2025-01-11 11:43:26.060435: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-11 11:43:37.781546: predicting pancreas_344 
2025-01-11 11:43:37.792546: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-11 11:43:51.800074: predicting pancreas_351 
2025-01-11 11:43:51.811074: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-11 11:43:59.590132: predicting pancreas_354 
2025-01-11 11:43:59.597133: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-01-11 11:44:22.924665: predicting pancreas_372 
2025-01-11 11:44:22.940665: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-11 11:44:39.271151: predicting pancreas_377 
2025-01-11 11:44:39.286658: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-01-11 11:44:53.369245: predicting pancreas_387 
2025-01-11 11:44:53.383249: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-01-11 11:45:07.393339: predicting pancreas_391 
2025-01-11 11:45:07.403845: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-11 11:45:23.788418: predicting pancreas_392 
2025-01-11 11:45:23.801422: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-01-11 11:45:34.716868: predicting pancreas_410 
2025-01-11 11:45:34.725377: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-11 11:45:44.075591: predicting pancreas_412 
2025-01-11 11:45:44.084593: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-01-11 11:46:41.618279: Validation complete 
2025-01-11 11:46:41.618279: Mean Validation Dice:  0.6363929751426703 
