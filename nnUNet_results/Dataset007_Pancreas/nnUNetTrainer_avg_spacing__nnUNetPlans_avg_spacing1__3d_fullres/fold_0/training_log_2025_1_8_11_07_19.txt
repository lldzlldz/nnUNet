
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-08 11:07:19.056756: do_dummy_2d_data_aug: False 
2025-01-08 11:07:19.088738: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-08 11:07:19.096739: The split file contains 5 splits. 
2025-01-08 11:07:19.099739: Desired fold for training: 0 
2025-01-08 11:07:19.102739: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_avg_spacing1_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [96, 160, 160], 'median_image_size_in_voxels': [240.0, 411.0, 411.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans_avg_spacing1', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-08 11:07:28.801824: unpacking dataset... 
2025-01-08 11:08:14.911528: unpacking done... 
2025-01-08 11:08:19.445958:  
2025-01-08 11:08:19.445958: Epoch 0 
2025-01-08 11:08:19.451022: Current learning rate: 0.01 
2025-01-08 11:09:06.895656: train_loss 0.1253 
2025-01-08 11:09:06.895656: val_loss 0.0697 
2025-01-08 11:09:06.900742: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-08 11:09:06.903331: Epoch time: 47.45 s 
2025-01-08 11:09:06.906875: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-08 11:09:07.645841:  
2025-01-08 11:09:07.646845: Epoch 1 
2025-01-08 11:09:07.651392: Current learning rate: 0.00991 
2025-01-08 11:09:50.640276: train_loss 0.0369 
2025-01-08 11:09:50.640276: val_loss -0.0234 
2025-01-08 11:09:50.646329: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-08 11:09:50.650342: Epoch time: 42.99 s 
2025-01-08 11:09:51.221375:  
2025-01-08 11:09:51.221375: Epoch 2 
2025-01-08 11:09:51.225976: Current learning rate: 0.00982 
2025-01-08 11:10:34.129324: train_loss -0.0466 
2025-01-08 11:10:34.129837: val_loss -0.0748 
2025-01-08 11:10:34.136016: Pseudo dice [np.float32(0.3604), np.float32(0.0)] 
2025-01-08 11:10:34.139078: Epoch time: 42.91 s 
2025-01-08 11:10:34.142161: Yayy! New best EMA pseudo Dice: 0.017999999225139618 
2025-01-08 11:10:34.946562:  
2025-01-08 11:10:34.946562: Epoch 3 
2025-01-08 11:10:34.951612: Current learning rate: 0.00973 
2025-01-08 11:11:18.013522: train_loss -0.0779 
2025-01-08 11:11:18.014560: val_loss -0.0994 
2025-01-08 11:11:18.019735: Pseudo dice [np.float32(0.319), np.float32(0.0)] 
2025-01-08 11:11:18.023387: Epoch time: 43.07 s 
2025-01-08 11:11:18.026452: Yayy! New best EMA pseudo Dice: 0.03220000118017197 
2025-01-08 11:11:18.831006:  
2025-01-08 11:11:18.832009: Epoch 4 
2025-01-08 11:11:18.837048: Current learning rate: 0.00964 
2025-01-08 11:12:01.727875: train_loss -0.0986 
2025-01-08 11:12:01.727875: val_loss -0.1493 
2025-01-08 11:12:01.733387: Pseudo dice [np.float32(0.411), np.float32(0.0)] 
2025-01-08 11:12:01.736899: Epoch time: 42.9 s 
2025-01-08 11:12:01.740412: Yayy! New best EMA pseudo Dice: 0.0494999997317791 
2025-01-08 11:12:02.660399:  
2025-01-08 11:12:02.660399: Epoch 5 
2025-01-08 11:12:02.667021: Current learning rate: 0.00955 
2025-01-08 11:12:45.550817: train_loss -0.1527 
2025-01-08 11:12:45.550817: val_loss -0.1656 
2025-01-08 11:12:45.555898: Pseudo dice [np.float32(0.4323), np.float32(0.0)] 
2025-01-08 11:12:45.560474: Epoch time: 42.89 s 
2025-01-08 11:12:45.564052: Yayy! New best EMA pseudo Dice: 0.06620000302791595 
2025-01-08 11:12:46.322409:  
2025-01-08 11:12:46.322409: Epoch 6 
2025-01-08 11:12:46.328429: Current learning rate: 0.00946 
2025-01-08 11:13:29.235277: train_loss -0.1644 
2025-01-08 11:13:29.236281: val_loss -0.1919 
2025-01-08 11:13:29.242296: Pseudo dice [np.float32(0.4212), np.float32(0.1614)] 
2025-01-08 11:13:29.245308: Epoch time: 42.91 s 
2025-01-08 11:13:29.247815: Yayy! New best EMA pseudo Dice: 0.08869999647140503 
2025-01-08 11:13:30.063433:  
2025-01-08 11:13:30.063433: Epoch 7 
2025-01-08 11:13:30.069453: Current learning rate: 0.00937 
2025-01-08 11:14:12.939472: train_loss -0.2124 
2025-01-08 11:14:12.939472: val_loss -0.2425 
2025-01-08 11:14:12.945993: Pseudo dice [np.float32(0.4187), np.float32(0.3247)] 
2025-01-08 11:14:12.948503: Epoch time: 42.88 s 
2025-01-08 11:14:12.952017: Yayy! New best EMA pseudo Dice: 0.11699999868869781 
2025-01-08 11:14:13.787966:  
2025-01-08 11:14:13.788971: Epoch 8 
2025-01-08 11:14:13.793529: Current learning rate: 0.00928 
2025-01-08 11:14:56.705847: train_loss -0.2068 
2025-01-08 11:14:56.706350: val_loss -0.2224 
2025-01-08 11:14:56.712372: Pseudo dice [np.float32(0.4947), np.float32(0.1855)] 
2025-01-08 11:14:56.714879: Epoch time: 42.92 s 
2025-01-08 11:14:56.721398: Yayy! New best EMA pseudo Dice: 0.13930000364780426 
2025-01-08 11:14:57.580460:  
2025-01-08 11:14:57.580963: Epoch 9 
2025-01-08 11:14:57.586010: Current learning rate: 0.00919 
2025-01-08 11:15:40.486666: train_loss -0.2251 
2025-01-08 11:15:40.486666: val_loss -0.2993 
2025-01-08 11:15:40.491657: Pseudo dice [np.float32(0.5401), np.float32(0.303)] 
2025-01-08 11:15:40.495166: Epoch time: 42.91 s 
2025-01-08 11:15:40.497675: Yayy! New best EMA pseudo Dice: 0.16750000417232513 
2025-01-08 11:15:41.309303:  
2025-01-08 11:15:41.309303: Epoch 10 
2025-01-08 11:15:41.314955: Current learning rate: 0.0091 
2025-01-08 11:16:24.199754: train_loss -0.2609 
2025-01-08 11:16:24.199754: val_loss -0.3243 
2025-01-08 11:16:24.205778: Pseudo dice [np.float32(0.5409), np.float32(0.3145)] 
2025-01-08 11:16:24.209793: Epoch time: 42.89 s 
2025-01-08 11:16:24.213368: Yayy! New best EMA pseudo Dice: 0.19349999725818634 
2025-01-08 11:16:25.082277:  
2025-01-08 11:16:25.082779: Epoch 11 
2025-01-08 11:16:25.087792: Current learning rate: 0.009 
2025-01-08 11:17:08.002989: train_loss -0.2679 
2025-01-08 11:17:08.002989: val_loss -0.2832 
2025-01-08 11:17:08.009514: Pseudo dice [np.float32(0.5148), np.float32(0.2788)] 
2025-01-08 11:17:08.013026: Epoch time: 42.92 s 
2025-01-08 11:17:08.015059: Yayy! New best EMA pseudo Dice: 0.21389999985694885 
2025-01-08 11:17:08.867631:  
2025-01-08 11:17:08.868635: Epoch 12 
2025-01-08 11:17:08.874187: Current learning rate: 0.00891 
2025-01-08 11:17:51.735504: train_loss -0.2373 
2025-01-08 11:17:51.735504: val_loss -0.2257 
2025-01-08 11:17:51.741525: Pseudo dice [np.float32(0.5017), np.float32(0.16)] 
2025-01-08 11:17:51.744035: Epoch time: 42.87 s 
2025-01-08 11:17:51.747550: Yayy! New best EMA pseudo Dice: 0.225600004196167 
2025-01-08 11:17:52.693216:  
2025-01-08 11:17:52.693719: Epoch 13 
2025-01-08 11:17:52.698731: Current learning rate: 0.00882 
2025-01-08 11:18:35.556034: train_loss -0.2771 
2025-01-08 11:18:35.556034: val_loss -0.3621 
2025-01-08 11:18:35.561050: Pseudo dice [np.float32(0.5634), np.float32(0.3838)] 
2025-01-08 11:18:35.564562: Epoch time: 42.86 s 
2025-01-08 11:18:35.567072: Yayy! New best EMA pseudo Dice: 0.25040000677108765 
2025-01-08 11:18:36.378033:  
2025-01-08 11:18:36.379033: Epoch 14 
2025-01-08 11:18:36.382077: Current learning rate: 0.00873 
2025-01-08 11:19:19.322033: train_loss -0.2979 
2025-01-08 11:19:19.323033: val_loss -0.2967 
2025-01-08 11:19:19.328554: Pseudo dice [np.float32(0.5019), np.float32(0.3316)] 
2025-01-08 11:19:19.332065: Epoch time: 42.94 s 
2025-01-08 11:19:19.334573: Yayy! New best EMA pseudo Dice: 0.2669999897480011 
2025-01-08 11:19:20.194609:  
2025-01-08 11:19:20.194609: Epoch 15 
2025-01-08 11:19:20.200626: Current learning rate: 0.00864 
2025-01-08 11:20:03.110666: train_loss -0.321 
2025-01-08 11:20:03.111170: val_loss -0.3491 
2025-01-08 11:20:03.117286: Pseudo dice [np.float32(0.5646), np.float32(0.3354)] 
2025-01-08 11:20:03.119794: Epoch time: 42.92 s 
2025-01-08 11:20:03.123299: Yayy! New best EMA pseudo Dice: 0.28529998660087585 
2025-01-08 11:20:03.949230:  
2025-01-08 11:20:03.949230: Epoch 16 
2025-01-08 11:20:03.954771: Current learning rate: 0.00855 
2025-01-08 11:20:46.887978: train_loss -0.319 
2025-01-08 11:20:46.888981: val_loss -0.3457 
2025-01-08 11:20:46.894992: Pseudo dice [np.float32(0.5698), np.float32(0.3225)] 
2025-01-08 11:20:46.898001: Epoch time: 42.94 s 
2025-01-08 11:20:46.901511: Yayy! New best EMA pseudo Dice: 0.30140000581741333 
2025-01-08 11:20:47.708369:  
2025-01-08 11:20:47.708369: Epoch 17 
2025-01-08 11:20:47.713986: Current learning rate: 0.00846 
2025-01-08 11:21:30.587578: train_loss -0.3189 
2025-01-08 11:21:30.587578: val_loss -0.352 
2025-01-08 11:21:30.592095: Pseudo dice [np.float32(0.5731), np.float32(0.2948)] 
2025-01-08 11:21:30.596123: Epoch time: 42.88 s 
2025-01-08 11:21:30.599131: Yayy! New best EMA pseudo Dice: 0.31459999084472656 
2025-01-08 11:21:31.378547:  
2025-01-08 11:21:31.379058: Epoch 18 
2025-01-08 11:21:31.384105: Current learning rate: 0.00836 
2025-01-08 11:22:14.251724: train_loss -0.3451 
2025-01-08 11:22:14.251724: val_loss -0.4032 
2025-01-08 11:22:14.258713: Pseudo dice [np.float32(0.5809), np.float32(0.3726)] 
2025-01-08 11:22:14.262222: Epoch time: 42.87 s 
2025-01-08 11:22:14.266229: Yayy! New best EMA pseudo Dice: 0.33090001344680786 
2025-01-08 11:22:15.133786:  
2025-01-08 11:22:15.133786: Epoch 19 
2025-01-08 11:22:15.139410: Current learning rate: 0.00827 
2025-01-08 11:22:58.098604: train_loss -0.3497 
2025-01-08 11:22:58.099604: val_loss -0.3951 
2025-01-08 11:22:58.103615: Pseudo dice [np.float32(0.5909), np.float32(0.3823)] 
2025-01-08 11:22:58.107621: Epoch time: 42.97 s 
2025-01-08 11:22:58.110126: Yayy! New best EMA pseudo Dice: 0.3463999927043915 
2025-01-08 11:22:59.031359:  
2025-01-08 11:22:59.031862: Epoch 20 
2025-01-08 11:22:59.036873: Current learning rate: 0.00818 
2025-01-08 11:23:41.902793: train_loss -0.3547 
2025-01-08 11:23:41.903296: val_loss -0.3982 
2025-01-08 11:23:41.909311: Pseudo dice [np.float32(0.6133), np.float32(0.395)] 
2025-01-08 11:23:41.911840: Epoch time: 42.87 s 
2025-01-08 11:23:41.915848: Yayy! New best EMA pseudo Dice: 0.362199991941452 
2025-01-08 11:23:42.763137:  
2025-01-08 11:23:42.764140: Epoch 21 
2025-01-08 11:23:42.770772: Current learning rate: 0.00809 
2025-01-08 11:24:25.642929: train_loss -0.3488 
2025-01-08 11:24:25.642929: val_loss -0.3533 
2025-01-08 11:24:25.649478: Pseudo dice [np.float32(0.5559), np.float32(0.4351)] 
2025-01-08 11:24:25.652992: Epoch time: 42.88 s 
2025-01-08 11:24:25.657004: Yayy! New best EMA pseudo Dice: 0.37549999356269836 
2025-01-08 11:24:26.417153:  
2025-01-08 11:24:26.418154: Epoch 22 
2025-01-08 11:24:26.423729: Current learning rate: 0.008 
2025-01-08 11:25:09.263002: train_loss -0.3395 
2025-01-08 11:25:09.263507: val_loss -0.3898 
2025-01-08 11:25:09.269604: Pseudo dice [np.float32(0.6188), np.float32(0.3874)] 
2025-01-08 11:25:09.273137: Epoch time: 42.85 s 
2025-01-08 11:25:09.276170: Yayy! New best EMA pseudo Dice: 0.38830000162124634 
2025-01-08 11:25:10.059863:  
2025-01-08 11:25:10.059863: Epoch 23 
2025-01-08 11:25:10.065977: Current learning rate: 0.0079 
2025-01-08 11:25:53.005766: train_loss -0.3637 
2025-01-08 11:25:53.007284: val_loss -0.396 
2025-01-08 11:25:53.012939: Pseudo dice [np.float32(0.6175), np.float32(0.2524)] 
2025-01-08 11:25:53.016001: Epoch time: 42.95 s 
2025-01-08 11:25:53.018586: Yayy! New best EMA pseudo Dice: 0.3930000066757202 
2025-01-08 11:25:53.843431:  
2025-01-08 11:25:53.843431: Epoch 24 
2025-01-08 11:25:53.850007: Current learning rate: 0.00781 
2025-01-08 11:26:36.750835: train_loss -0.3754 
2025-01-08 11:26:36.751839: val_loss -0.3739 
2025-01-08 11:26:36.758104: Pseudo dice [np.float32(0.6203), np.float32(0.3107)] 
2025-01-08 11:26:36.761769: Epoch time: 42.91 s 
2025-01-08 11:26:36.765337: Yayy! New best EMA pseudo Dice: 0.4002000093460083 
2025-01-08 11:26:37.538442:  
2025-01-08 11:26:37.538946: Epoch 25 
2025-01-08 11:26:37.544001: Current learning rate: 0.00772 
2025-01-08 11:27:20.459296: train_loss -0.3643 
2025-01-08 11:27:20.459810: val_loss -0.4087 
2025-01-08 11:27:20.466198: Pseudo dice [np.float32(0.6266), np.float32(0.4291)] 
2025-01-08 11:27:20.469600: Epoch time: 42.92 s 
2025-01-08 11:27:20.472919: Yayy! New best EMA pseudo Dice: 0.4129999876022339 
2025-01-08 11:27:21.269368:  
2025-01-08 11:27:21.269871: Epoch 26 
2025-01-08 11:27:21.274886: Current learning rate: 0.00763 
2025-01-08 11:28:04.227489: train_loss -0.3914 
2025-01-08 11:28:04.227489: val_loss -0.3877 
2025-01-08 11:28:04.233509: Pseudo dice [np.float32(0.6181), np.float32(0.3507)] 
2025-01-08 11:28:04.237017: Epoch time: 42.96 s 
2025-01-08 11:28:04.240028: Yayy! New best EMA pseudo Dice: 0.42010000348091125 
2025-01-08 11:28:05.004431:  
2025-01-08 11:28:05.005432: Epoch 27 
2025-01-08 11:28:05.011061: Current learning rate: 0.00753 
2025-01-08 11:28:47.935224: train_loss -0.3933 
2025-01-08 11:28:47.935224: val_loss -0.3709 
2025-01-08 11:28:47.942751: Pseudo dice [np.float32(0.6272), np.float32(0.2944)] 
2025-01-08 11:28:47.946761: Epoch time: 42.93 s 
2025-01-08 11:28:47.949267: Yayy! New best EMA pseudo Dice: 0.42419999837875366 
2025-01-08 11:28:48.876995:  
2025-01-08 11:28:48.876995: Epoch 28 
2025-01-08 11:28:48.881030: Current learning rate: 0.00744 
2025-01-08 11:29:31.798239: train_loss -0.3668 
2025-01-08 11:29:31.798752: val_loss -0.4162 
2025-01-08 11:29:31.803815: Pseudo dice [np.float32(0.6556), np.float32(0.3502)] 
2025-01-08 11:29:31.807360: Epoch time: 42.92 s 
2025-01-08 11:29:31.810414: Yayy! New best EMA pseudo Dice: 0.43209999799728394 
2025-01-08 11:29:32.578628:  
2025-01-08 11:29:32.580167: Epoch 29 
2025-01-08 11:29:32.585813: Current learning rate: 0.00735 
2025-01-08 11:30:15.466057: train_loss -0.4071 
2025-01-08 11:30:15.466057: val_loss -0.4736 
2025-01-08 11:30:15.472584: Pseudo dice [np.float32(0.652), np.float32(0.5141)] 
2025-01-08 11:30:15.476096: Epoch time: 42.89 s 
2025-01-08 11:30:15.479605: Yayy! New best EMA pseudo Dice: 0.4472000002861023 
2025-01-08 11:30:16.292156:  
2025-01-08 11:30:16.292156: Epoch 30 
2025-01-08 11:30:16.298177: Current learning rate: 0.00725 
2025-01-08 11:30:59.219146: train_loss -0.4116 
2025-01-08 11:30:59.220145: val_loss -0.4315 
2025-01-08 11:30:59.225658: Pseudo dice [np.float32(0.6714), np.float32(0.312)] 
2025-01-08 11:30:59.229167: Epoch time: 42.93 s 
2025-01-08 11:30:59.231672: Yayy! New best EMA pseudo Dice: 0.45159998536109924 
2025-01-08 11:31:00.054725:  
2025-01-08 11:31:00.054725: Epoch 31 
2025-01-08 11:31:00.060741: Current learning rate: 0.00716 
2025-01-08 11:31:42.958858: train_loss -0.4055 
2025-01-08 11:31:42.959373: val_loss -0.4336 
2025-01-08 11:31:42.964489: Pseudo dice [np.float32(0.6573), np.float32(0.4179)] 
2025-01-08 11:31:42.967997: Epoch time: 42.9 s 
2025-01-08 11:31:42.970502: Yayy! New best EMA pseudo Dice: 0.4602000117301941 
2025-01-08 11:31:43.733067:  
2025-01-08 11:31:43.733569: Epoch 32 
2025-01-08 11:31:43.740586: Current learning rate: 0.00707 
2025-01-08 11:32:26.646208: train_loss -0.396 
2025-01-08 11:32:26.646208: val_loss -0.4608 
2025-01-08 11:32:26.652222: Pseudo dice [np.float32(0.7027), np.float32(0.3155)] 
2025-01-08 11:32:26.654727: Epoch time: 42.91 s 
2025-01-08 11:32:26.658231: Yayy! New best EMA pseudo Dice: 0.4650999903678894 
2025-01-08 11:32:27.438850:  
2025-01-08 11:32:27.438850: Epoch 33 
2025-01-08 11:32:27.444864: Current learning rate: 0.00697 
2025-01-08 11:33:10.287566: train_loss -0.4048 
2025-01-08 11:33:10.288068: val_loss -0.428 
2025-01-08 11:33:10.293643: Pseudo dice [np.float32(0.6643), np.float32(0.3517)] 
2025-01-08 11:33:10.296178: Epoch time: 42.85 s 
2025-01-08 11:33:10.300222: Yayy! New best EMA pseudo Dice: 0.46939998865127563 
2025-01-08 11:33:11.080842:  
2025-01-08 11:33:11.080842: Epoch 34 
2025-01-08 11:33:11.086890: Current learning rate: 0.00688 
2025-01-08 11:33:54.032409: train_loss -0.4079 
2025-01-08 11:33:54.032409: val_loss -0.4306 
2025-01-08 11:33:54.037524: Pseudo dice [np.float32(0.6527), np.float32(0.3433)] 
2025-01-08 11:33:54.041564: Epoch time: 42.95 s 
2025-01-08 11:33:54.044616: Yayy! New best EMA pseudo Dice: 0.4722999930381775 
2025-01-08 11:33:54.868515:  
2025-01-08 11:33:54.868515: Epoch 35 
2025-01-08 11:33:54.873585: Current learning rate: 0.00679 
2025-01-08 11:34:37.790632: train_loss -0.4422 
2025-01-08 11:34:37.791633: val_loss -0.4361 
2025-01-08 11:34:37.797190: Pseudo dice [np.float32(0.6606), np.float32(0.3927)] 
2025-01-08 11:34:37.799699: Epoch time: 42.92 s 
2025-01-08 11:34:37.803209: Yayy! New best EMA pseudo Dice: 0.47769999504089355 
2025-01-08 11:34:38.817181:  
2025-01-08 11:34:38.817181: Epoch 36 
2025-01-08 11:34:38.823244: Current learning rate: 0.00669 
2025-01-08 11:35:21.692339: train_loss -0.4342 
2025-01-08 11:35:21.692339: val_loss -0.4478 
2025-01-08 11:35:21.698360: Pseudo dice [np.float32(0.6716), np.float32(0.46)] 
2025-01-08 11:35:21.702374: Epoch time: 42.88 s 
2025-01-08 11:35:21.705889: Yayy! New best EMA pseudo Dice: 0.48649999499320984 
2025-01-08 11:35:22.534447:  
2025-01-08 11:35:22.534447: Epoch 37 
2025-01-08 11:35:22.540001: Current learning rate: 0.0066 
2025-01-08 11:36:05.396315: train_loss -0.4414 
2025-01-08 11:36:05.396828: val_loss -0.4542 
2025-01-08 11:36:05.402397: Pseudo dice [np.float32(0.678), np.float32(0.3272)] 
2025-01-08 11:36:05.405942: Epoch time: 42.86 s 
2025-01-08 11:36:05.408977: Yayy! New best EMA pseudo Dice: 0.48809999227523804 
2025-01-08 11:36:06.242656:  
2025-01-08 11:36:06.242656: Epoch 38 
2025-01-08 11:36:06.248677: Current learning rate: 0.0065 
2025-01-08 11:36:49.125493: train_loss -0.4337 
2025-01-08 11:36:49.126009: val_loss -0.412 
2025-01-08 11:36:49.132111: Pseudo dice [np.float32(0.6782), np.float32(0.2906)] 
2025-01-08 11:36:49.135675: Epoch time: 42.88 s 
2025-01-08 11:36:49.737135:  
2025-01-08 11:36:49.737135: Epoch 39 
2025-01-08 11:36:49.742146: Current learning rate: 0.00641 
2025-01-08 11:37:32.652180: train_loss -0.4551 
2025-01-08 11:37:32.653183: val_loss -0.447 
2025-01-08 11:37:32.658195: Pseudo dice [np.float32(0.6935), np.float32(0.4363)] 
2025-01-08 11:37:32.660704: Epoch time: 42.92 s 
2025-01-08 11:37:32.664714: Yayy! New best EMA pseudo Dice: 0.49549999833106995 
2025-01-08 11:37:33.460253:  
2025-01-08 11:37:33.460253: Epoch 40 
2025-01-08 11:37:33.465815: Current learning rate: 0.00631 
2025-01-08 11:38:16.354464: train_loss -0.419 
2025-01-08 11:38:16.354967: val_loss -0.4358 
2025-01-08 11:38:16.361083: Pseudo dice [np.float32(0.6582), np.float32(0.4006)] 
2025-01-08 11:38:16.364114: Epoch time: 42.89 s 
2025-01-08 11:38:16.368141: Yayy! New best EMA pseudo Dice: 0.49889999628067017 
2025-01-08 11:38:17.169140:  
2025-01-08 11:38:17.169642: Epoch 41 
2025-01-08 11:38:17.174653: Current learning rate: 0.00622 
2025-01-08 11:39:00.041867: train_loss -0.4407 
2025-01-08 11:39:00.042370: val_loss -0.4405 
2025-01-08 11:39:00.045879: Pseudo dice [np.float32(0.673), np.float32(0.3464)] 
2025-01-08 11:39:00.048384: Epoch time: 42.87 s 
2025-01-08 11:39:00.052393: Yayy! New best EMA pseudo Dice: 0.4999000132083893 
2025-01-08 11:39:00.924490:  
2025-01-08 11:39:00.924490: Epoch 42 
2025-01-08 11:39:00.930020: Current learning rate: 0.00612 
2025-01-08 11:39:43.752029: train_loss -0.467 
2025-01-08 11:39:43.753033: val_loss -0.4391 
2025-01-08 11:39:43.758042: Pseudo dice [np.float32(0.6504), np.float32(0.3729)] 
2025-01-08 11:39:43.761548: Epoch time: 42.83 s 
2025-01-08 11:39:43.764556: Yayy! New best EMA pseudo Dice: 0.5011000037193298 
2025-01-08 11:39:44.532544:  
2025-01-08 11:39:44.533547: Epoch 43 
2025-01-08 11:39:44.538100: Current learning rate: 0.00603 
2025-01-08 11:40:27.466686: train_loss -0.4785 
2025-01-08 11:40:27.467189: val_loss -0.4732 
2025-01-08 11:40:27.472761: Pseudo dice [np.float32(0.7117), np.float32(0.3682)] 
2025-01-08 11:40:27.475800: Epoch time: 42.93 s 
2025-01-08 11:40:27.479323: Yayy! New best EMA pseudo Dice: 0.5049999952316284 
2025-01-08 11:40:28.490644:  
2025-01-08 11:40:28.491650: Epoch 44 
2025-01-08 11:40:28.496207: Current learning rate: 0.00593 
2025-01-08 11:41:11.380713: train_loss -0.4435 
2025-01-08 11:41:11.381718: val_loss -0.4609 
2025-01-08 11:41:11.387734: Pseudo dice [np.float32(0.6937), np.float32(0.3057)] 
2025-01-08 11:41:11.390745: Epoch time: 42.89 s 
2025-01-08 11:41:11.959491:  
2025-01-08 11:41:11.959491: Epoch 45 
2025-01-08 11:41:11.964552: Current learning rate: 0.00584 
2025-01-08 11:41:54.817521: train_loss -0.4748 
2025-01-08 11:41:54.818043: val_loss -0.4457 
2025-01-08 11:41:54.824124: Pseudo dice [np.float32(0.6669), np.float32(0.3746)] 
2025-01-08 11:41:54.826983: Epoch time: 42.86 s 
2025-01-08 11:41:54.830008: Yayy! New best EMA pseudo Dice: 0.5060999989509583 
2025-01-08 11:41:55.578388:  
2025-01-08 11:41:55.578891: Epoch 46 
2025-01-08 11:41:55.583903: Current learning rate: 0.00574 
2025-01-08 11:42:38.486199: train_loss -0.4929 
2025-01-08 11:42:38.486199: val_loss -0.4864 
2025-01-08 11:42:38.492216: Pseudo dice [np.float32(0.7127), np.float32(0.3406)] 
2025-01-08 11:42:38.495226: Epoch time: 42.91 s 
2025-01-08 11:42:38.497733: Yayy! New best EMA pseudo Dice: 0.5081999897956848 
2025-01-08 11:42:39.258771:  
2025-01-08 11:42:39.258771: Epoch 47 
2025-01-08 11:42:39.264398: Current learning rate: 0.00565 
2025-01-08 11:43:22.205183: train_loss -0.4781 
2025-01-08 11:43:22.205687: val_loss -0.4167 
2025-01-08 11:43:22.211248: Pseudo dice [np.float32(0.6689), np.float32(0.3021)] 
2025-01-08 11:43:22.213521: Epoch time: 42.95 s 
2025-01-08 11:43:22.791824:  
2025-01-08 11:43:22.791824: Epoch 48 
2025-01-08 11:43:22.796845: Current learning rate: 0.00555 
2025-01-08 11:44:05.700730: train_loss -0.4735 
2025-01-08 11:44:05.700730: val_loss -0.4917 
2025-01-08 11:44:05.706846: Pseudo dice [np.float32(0.6976), np.float32(0.4477)] 
2025-01-08 11:44:05.709414: Epoch time: 42.91 s 
2025-01-08 11:44:05.711972: Yayy! New best EMA pseudo Dice: 0.5126000046730042 
2025-01-08 11:44:06.473942:  
2025-01-08 11:44:06.473942: Epoch 49 
2025-01-08 11:44:06.479959: Current learning rate: 0.00546 
2025-01-08 11:44:49.476185: train_loss -0.4589 
2025-01-08 11:44:49.476185: val_loss -0.4812 
2025-01-08 11:44:49.483709: Pseudo dice [np.float32(0.7097), np.float32(0.3989)] 
2025-01-08 11:44:49.486218: Epoch time: 43.0 s 
2025-01-08 11:44:49.655672: Yayy! New best EMA pseudo Dice: 0.516700029373169 
2025-01-08 11:44:50.580307:  
2025-01-08 11:44:50.581311: Epoch 50 
2025-01-08 11:44:50.584883: Current learning rate: 0.00536 
2025-01-08 11:45:33.450160: train_loss -0.4778 
2025-01-08 11:45:33.450160: val_loss -0.4816 
2025-01-08 11:45:33.456413: Pseudo dice [np.float32(0.6973), np.float32(0.428)] 
2025-01-08 11:45:33.459486: Epoch time: 42.87 s 
2025-01-08 11:45:33.462998: Yayy! New best EMA pseudo Dice: 0.5213000178337097 
2025-01-08 11:45:34.290766:  
2025-01-08 11:45:34.291770: Epoch 51 
2025-01-08 11:45:34.296571: Current learning rate: 0.00526 
2025-01-08 11:46:17.188115: train_loss -0.4887 
2025-01-08 11:46:17.189119: val_loss -0.5235 
2025-01-08 11:46:17.194843: Pseudo dice [np.float32(0.6918), np.float32(0.5164)] 
2025-01-08 11:46:17.198355: Epoch time: 42.9 s 
2025-01-08 11:46:17.201864: Yayy! New best EMA pseudo Dice: 0.5296000242233276 
2025-01-08 11:46:17.995535:  
2025-01-08 11:46:17.995535: Epoch 52 
2025-01-08 11:46:18.001068: Current learning rate: 0.00517 
2025-01-08 11:47:00.905149: train_loss -0.4678 
2025-01-08 11:47:00.905149: val_loss -0.4293 
2025-01-08 11:47:00.911165: Pseudo dice [np.float32(0.7095), np.float32(0.2813)] 
2025-01-08 11:47:00.913189: Epoch time: 42.91 s 
2025-01-08 11:47:01.664140:  
2025-01-08 11:47:01.664140: Epoch 53 
2025-01-08 11:47:01.669153: Current learning rate: 0.00507 
2025-01-08 11:47:44.575899: train_loss -0.4795 
2025-01-08 11:47:44.576403: val_loss -0.5108 
2025-01-08 11:47:44.582423: Pseudo dice [np.float32(0.7146), np.float32(0.4867)] 
2025-01-08 11:47:44.584589: Epoch time: 42.91 s 
2025-01-08 11:47:44.588617: Yayy! New best EMA pseudo Dice: 0.5335999727249146 
2025-01-08 11:47:45.400055:  
2025-01-08 11:47:45.400055: Epoch 54 
2025-01-08 11:47:45.406117: Current learning rate: 0.00497 
2025-01-08 11:48:28.277550: train_loss -0.4824 
2025-01-08 11:48:28.278555: val_loss -0.5142 
2025-01-08 11:48:28.284572: Pseudo dice [np.float32(0.7024), np.float32(0.4546)] 
2025-01-08 11:48:28.287584: Epoch time: 42.88 s 
2025-01-08 11:48:28.291095: Yayy! New best EMA pseudo Dice: 0.538100004196167 
2025-01-08 11:48:29.056312:  
2025-01-08 11:48:29.056816: Epoch 55 
2025-01-08 11:48:29.061831: Current learning rate: 0.00487 
2025-01-08 11:49:11.918008: train_loss -0.4999 
2025-01-08 11:49:11.918008: val_loss -0.4439 
2025-01-08 11:49:11.924544: Pseudo dice [np.float32(0.6881), np.float32(0.3238)] 
2025-01-08 11:49:11.927554: Epoch time: 42.86 s 
2025-01-08 11:49:12.496893:  
2025-01-08 11:49:12.497899: Epoch 56 
2025-01-08 11:49:12.502452: Current learning rate: 0.00478 
2025-01-08 11:49:55.412662: train_loss -0.5144 
2025-01-08 11:49:55.413172: val_loss -0.4914 
2025-01-08 11:49:55.418229: Pseudo dice [np.float32(0.7388), np.float32(0.4096)] 
2025-01-08 11:49:55.422258: Epoch time: 42.92 s 
2025-01-08 11:49:55.425282: Yayy! New best EMA pseudo Dice: 0.5388000011444092 
2025-01-08 11:49:56.174566:  
2025-01-08 11:49:56.174566: Epoch 57 
2025-01-08 11:49:56.179581: Current learning rate: 0.00468 
2025-01-08 11:50:39.057335: train_loss -0.4956 
2025-01-08 11:50:39.058338: val_loss -0.4786 
2025-01-08 11:50:39.063353: Pseudo dice [np.float32(0.7044), np.float32(0.4323)] 
2025-01-08 11:50:39.067367: Epoch time: 42.88 s 
2025-01-08 11:50:39.069875: Yayy! New best EMA pseudo Dice: 0.5418000221252441 
2025-01-08 11:50:39.840130:  
2025-01-08 11:50:39.840635: Epoch 58 
2025-01-08 11:50:39.845651: Current learning rate: 0.00458 
2025-01-08 11:51:22.744014: train_loss -0.5005 
2025-01-08 11:51:22.744516: val_loss -0.4828 
2025-01-08 11:51:22.750644: Pseudo dice [np.float32(0.7003), np.float32(0.3802)] 
2025-01-08 11:51:22.754666: Epoch time: 42.9 s 
2025-01-08 11:51:23.352842:  
2025-01-08 11:51:23.352842: Epoch 59 
2025-01-08 11:51:23.358883: Current learning rate: 0.00448 
2025-01-08 11:52:06.221026: train_loss -0.5017 
2025-01-08 11:52:06.222030: val_loss -0.5096 
2025-01-08 11:52:06.227064: Pseudo dice [np.float32(0.7256), np.float32(0.4195)] 
2025-01-08 11:52:06.230083: Epoch time: 42.87 s 
2025-01-08 11:52:06.233106: Yayy! New best EMA pseudo Dice: 0.544700026512146 
2025-01-08 11:52:07.010622:  
2025-01-08 11:52:07.010622: Epoch 60 
2025-01-08 11:52:07.016654: Current learning rate: 0.00438 
2025-01-08 11:52:50.022105: train_loss -0.5157 
2025-01-08 11:52:50.022646: val_loss -0.4643 
2025-01-08 11:52:50.029213: Pseudo dice [np.float32(0.7261), np.float32(0.3403)] 
2025-01-08 11:52:50.032770: Epoch time: 43.01 s 
2025-01-08 11:52:50.777920:  
2025-01-08 11:52:50.778423: Epoch 61 
2025-01-08 11:52:50.783448: Current learning rate: 0.00429 
2025-01-08 11:53:33.667613: train_loss -0.5215 
2025-01-08 11:53:33.668617: val_loss -0.4721 
2025-01-08 11:53:33.673628: Pseudo dice [np.float32(0.7281), np.float32(0.3016)] 
2025-01-08 11:53:33.677137: Epoch time: 42.89 s 
2025-01-08 11:53:34.267637:  
2025-01-08 11:53:34.268637: Epoch 62 
2025-01-08 11:53:34.273648: Current learning rate: 0.00419 
2025-01-08 11:54:17.162681: train_loss -0.5376 
2025-01-08 11:54:17.163185: val_loss -0.5105 
2025-01-08 11:54:17.169199: Pseudo dice [np.float32(0.7275), np.float32(0.4448)] 
2025-01-08 11:54:17.172706: Epoch time: 42.9 s 
2025-01-08 11:54:17.175713: Yayy! New best EMA pseudo Dice: 0.545199990272522 
2025-01-08 11:54:17.940876:  
2025-01-08 11:54:17.940876: Epoch 63 
2025-01-08 11:54:17.945900: Current learning rate: 0.00409 
2025-01-08 11:55:00.786431: train_loss -0.5179 
2025-01-08 11:55:00.786431: val_loss -0.545 
2025-01-08 11:55:00.791622: Pseudo dice [np.float32(0.7568), np.float32(0.4404)] 
2025-01-08 11:55:00.795133: Epoch time: 42.85 s 
2025-01-08 11:55:00.798637: Yayy! New best EMA pseudo Dice: 0.550599992275238 
2025-01-08 11:55:01.578395:  
2025-01-08 11:55:01.578395: Epoch 64 
2025-01-08 11:55:01.583956: Current learning rate: 0.00399 
2025-01-08 11:55:44.522246: train_loss -0.518 
2025-01-08 11:55:44.522246: val_loss -0.5108 
2025-01-08 11:55:44.528259: Pseudo dice [np.float32(0.7346), np.float32(0.4266)] 
2025-01-08 11:55:44.530764: Epoch time: 42.94 s 
2025-01-08 11:55:44.534268: Yayy! New best EMA pseudo Dice: 0.553600013256073 
2025-01-08 11:55:45.315007:  
2025-01-08 11:55:45.316006: Epoch 65 
2025-01-08 11:55:45.321148: Current learning rate: 0.00389 
2025-01-08 11:56:28.192436: train_loss -0.5197 
2025-01-08 11:56:28.192938: val_loss -0.5174 
2025-01-08 11:56:28.198486: Pseudo dice [np.float32(0.7318), np.float32(0.4667)] 
2025-01-08 11:56:28.201748: Epoch time: 42.88 s 
2025-01-08 11:56:28.204773: Yayy! New best EMA pseudo Dice: 0.5580999851226807 
2025-01-08 11:56:29.030307:  
2025-01-08 11:56:29.030307: Epoch 66 
2025-01-08 11:56:29.035337: Current learning rate: 0.00379 
2025-01-08 11:57:11.917929: train_loss -0.5263 
2025-01-08 11:57:11.917929: val_loss -0.5032 
2025-01-08 11:57:11.924442: Pseudo dice [np.float32(0.7284), np.float32(0.4656)] 
2025-01-08 11:57:11.926969: Epoch time: 42.89 s 
2025-01-08 11:57:11.930224: Yayy! New best EMA pseudo Dice: 0.5619999766349792 
2025-01-08 11:57:12.740725:  
2025-01-08 11:57:12.741725: Epoch 67 
2025-01-08 11:57:12.746842: Current learning rate: 0.00369 
2025-01-08 11:57:55.701991: train_loss -0.5278 
2025-01-08 11:57:55.701991: val_loss -0.5029 
2025-01-08 11:57:55.708005: Pseudo dice [np.float32(0.7406), np.float32(0.4108)] 
2025-01-08 11:57:55.711510: Epoch time: 42.96 s 
2025-01-08 11:57:55.714517: Yayy! New best EMA pseudo Dice: 0.5633999705314636 
2025-01-08 11:57:56.500016:  
2025-01-08 11:57:56.500016: Epoch 68 
2025-01-08 11:57:56.504546: Current learning rate: 0.00359 
2025-01-08 11:58:39.348097: train_loss -0.5527 
2025-01-08 11:58:39.348607: val_loss -0.5172 
2025-01-08 11:58:39.354185: Pseudo dice [np.float32(0.7299), np.float32(0.3606)] 
2025-01-08 11:58:39.356745: Epoch time: 42.85 s 
2025-01-08 11:58:40.107169:  
2025-01-08 11:58:40.107671: Epoch 69 
2025-01-08 11:58:40.112745: Current learning rate: 0.00349 
2025-01-08 11:59:22.989214: train_loss -0.5491 
2025-01-08 11:59:22.989214: val_loss -0.5181 
2025-01-08 11:59:22.996388: Pseudo dice [np.float32(0.7265), np.float32(0.4974)] 
2025-01-08 11:59:22.999983: Epoch time: 42.88 s 
2025-01-08 11:59:23.003021: Yayy! New best EMA pseudo Dice: 0.5666000247001648 
2025-01-08 11:59:23.784496:  
2025-01-08 11:59:23.785496: Epoch 70 
2025-01-08 11:59:23.791101: Current learning rate: 0.00338 
2025-01-08 12:00:06.670404: train_loss -0.5446 
2025-01-08 12:00:06.671906: val_loss -0.5354 
2025-01-08 12:00:06.677924: Pseudo dice [np.float32(0.7145), np.float32(0.5192)] 
2025-01-08 12:00:06.680429: Epoch time: 42.89 s 
2025-01-08 12:00:06.683935: Yayy! New best EMA pseudo Dice: 0.5716000199317932 
2025-01-08 12:00:07.519258:  
2025-01-08 12:00:07.520261: Epoch 71 
2025-01-08 12:00:07.524821: Current learning rate: 0.00328 
2025-01-08 12:00:50.358431: train_loss -0.5479 
2025-01-08 12:00:50.358431: val_loss -0.5349 
2025-01-08 12:00:50.364441: Pseudo dice [np.float32(0.7381), np.float32(0.4523)] 
2025-01-08 12:00:50.367449: Epoch time: 42.84 s 
2025-01-08 12:00:50.369955: Yayy! New best EMA pseudo Dice: 0.5740000009536743 
2025-01-08 12:00:51.174857:  
2025-01-08 12:00:51.175360: Epoch 72 
2025-01-08 12:00:51.180373: Current learning rate: 0.00318 
2025-01-08 12:01:34.043457: train_loss -0.521 
2025-01-08 12:01:34.043967: val_loss -0.5485 
2025-01-08 12:01:34.049042: Pseudo dice [np.float32(0.725), np.float32(0.4976)] 
2025-01-08 12:01:34.051591: Epoch time: 42.87 s 
2025-01-08 12:01:34.056177: Yayy! New best EMA pseudo Dice: 0.5777000188827515 
2025-01-08 12:01:34.843959:  
2025-01-08 12:01:34.844963: Epoch 73 
2025-01-08 12:01:34.849538: Current learning rate: 0.00308 
2025-01-08 12:02:17.736677: train_loss -0.5489 
2025-01-08 12:02:17.736677: val_loss -0.5194 
2025-01-08 12:02:17.742698: Pseudo dice [np.float32(0.7272), np.float32(0.4965)] 
2025-01-08 12:02:17.746716: Epoch time: 42.89 s 
2025-01-08 12:02:17.749227: Yayy! New best EMA pseudo Dice: 0.5810999870300293 
2025-01-08 12:02:18.547115:  
2025-01-08 12:02:18.548314: Epoch 74 
2025-01-08 12:02:18.551857: Current learning rate: 0.00297 
2025-01-08 12:03:01.407415: train_loss -0.5457 
2025-01-08 12:03:01.407415: val_loss -0.5517 
2025-01-08 12:03:01.413433: Pseudo dice [np.float32(0.7319), np.float32(0.4527)] 
2025-01-08 12:03:01.416941: Epoch time: 42.86 s 
2025-01-08 12:03:01.419950: Yayy! New best EMA pseudo Dice: 0.5823000073432922 
2025-01-08 12:03:02.206622:  
2025-01-08 12:03:02.207124: Epoch 75 
2025-01-08 12:03:02.212166: Current learning rate: 0.00287 
2025-01-08 12:03:45.285339: train_loss -0.5625 
2025-01-08 12:03:45.286841: val_loss -0.5527 
2025-01-08 12:03:45.290350: Pseudo dice [np.float32(0.7446), np.float32(0.5167)] 
2025-01-08 12:03:45.292858: Epoch time: 43.08 s 
2025-01-08 12:03:45.296381: Yayy! New best EMA pseudo Dice: 0.5871000289916992 
2025-01-08 12:03:46.088696:  
2025-01-08 12:03:46.089202: Epoch 76 
2025-01-08 12:03:46.094338: Current learning rate: 0.00277 
2025-01-08 12:04:28.973320: train_loss -0.5506 
2025-01-08 12:04:28.973823: val_loss -0.5529 
2025-01-08 12:04:28.979484: Pseudo dice [np.float32(0.7544), np.float32(0.5255)] 
2025-01-08 12:04:28.982025: Epoch time: 42.89 s 
2025-01-08 12:04:28.984569: Yayy! New best EMA pseudo Dice: 0.5924000144004822 
2025-01-08 12:04:30.032935:  
2025-01-08 12:04:30.032935: Epoch 77 
2025-01-08 12:04:30.037992: Current learning rate: 0.00266 
2025-01-08 12:05:12.881086: train_loss -0.5822 
2025-01-08 12:05:12.881086: val_loss -0.5857 
2025-01-08 12:05:12.886733: Pseudo dice [np.float32(0.7609), np.float32(0.5229)] 
2025-01-08 12:05:12.890239: Epoch time: 42.85 s 
2025-01-08 12:05:12.893256: Yayy! New best EMA pseudo Dice: 0.5972999930381775 
2025-01-08 12:05:13.752751:  
2025-01-08 12:05:13.753751: Epoch 78 
2025-01-08 12:05:13.758871: Current learning rate: 0.00256 
2025-01-08 12:05:56.585871: train_loss -0.5631 
2025-01-08 12:05:56.586875: val_loss -0.5335 
2025-01-08 12:05:56.591890: Pseudo dice [np.float32(0.7502), np.float32(0.4197)] 
2025-01-08 12:05:56.595910: Epoch time: 42.83 s 
2025-01-08 12:05:57.216893:  
2025-01-08 12:05:57.216893: Epoch 79 
2025-01-08 12:05:57.222450: Current learning rate: 0.00245 
2025-01-08 12:06:40.091834: train_loss -0.5684 
2025-01-08 12:06:40.092336: val_loss -0.5183 
2025-01-08 12:06:40.097347: Pseudo dice [np.float32(0.7478), np.float32(0.4459)] 
2025-01-08 12:06:40.100856: Epoch time: 42.88 s 
2025-01-08 12:06:40.701137:  
2025-01-08 12:06:40.701137: Epoch 80 
2025-01-08 12:06:40.706701: Current learning rate: 0.00235 
2025-01-08 12:07:23.612785: train_loss -0.5825 
2025-01-08 12:07:23.613788: val_loss -0.5671 
2025-01-08 12:07:23.619808: Pseudo dice [np.float32(0.7627), np.float32(0.5045)] 
2025-01-08 12:07:23.623823: Epoch time: 42.91 s 
2025-01-08 12:07:23.626330: Yayy! New best EMA pseudo Dice: 0.5999000072479248 
2025-01-08 12:07:24.417714:  
2025-01-08 12:07:24.417714: Epoch 81 
2025-01-08 12:07:24.421731: Current learning rate: 0.00224 
2025-01-08 12:08:07.307625: train_loss -0.561 
2025-01-08 12:08:07.308624: val_loss -0.5374 
2025-01-08 12:08:07.314140: Pseudo dice [np.float32(0.7662), np.float32(0.4201)] 
2025-01-08 12:08:07.316646: Epoch time: 42.89 s 
2025-01-08 12:08:07.924901:  
2025-01-08 12:08:07.924901: Epoch 82 
2025-01-08 12:08:07.929938: Current learning rate: 0.00214 
2025-01-08 12:08:50.823398: train_loss -0.5525 
2025-01-08 12:08:50.824402: val_loss -0.5046 
2025-01-08 12:08:50.830423: Pseudo dice [np.float32(0.7172), np.float32(0.3821)] 
2025-01-08 12:08:50.833436: Epoch time: 42.9 s 
2025-01-08 12:08:51.413231:  
2025-01-08 12:08:51.413231: Epoch 83 
2025-01-08 12:08:51.418764: Current learning rate: 0.00203 
2025-01-08 12:09:34.290923: train_loss -0.584 
2025-01-08 12:09:34.290923: val_loss -0.5539 
2025-01-08 12:09:34.296943: Pseudo dice [np.float32(0.7293), np.float32(0.4668)] 
2025-01-08 12:09:34.300452: Epoch time: 42.88 s 
2025-01-08 12:09:35.032908:  
2025-01-08 12:09:35.032908: Epoch 84 
2025-01-08 12:09:35.039439: Current learning rate: 0.00192 
2025-01-08 12:10:17.981036: train_loss -0.575 
2025-01-08 12:10:17.982538: val_loss -0.5586 
2025-01-08 12:10:17.987553: Pseudo dice [np.float32(0.7355), np.float32(0.4948)] 
2025-01-08 12:10:17.991063: Epoch time: 42.95 s 
2025-01-08 12:10:18.558521:  
2025-01-08 12:10:18.559520: Epoch 85 
2025-01-08 12:10:18.564600: Current learning rate: 0.00181 
2025-01-08 12:11:01.453079: train_loss -0.5836 
2025-01-08 12:11:01.454110: val_loss -0.6012 
2025-01-08 12:11:01.460203: Pseudo dice [np.float32(0.7792), np.float32(0.6356)] 
2025-01-08 12:11:01.462730: Epoch time: 42.89 s 
2025-01-08 12:11:01.466263: Yayy! New best EMA pseudo Dice: 0.6078000068664551 
2025-01-08 12:11:02.216041:  
2025-01-08 12:11:02.217041: Epoch 86 
2025-01-08 12:11:02.222642: Current learning rate: 0.0017 
2025-01-08 12:11:45.081413: train_loss -0.6012 
2025-01-08 12:11:45.081413: val_loss -0.531 
2025-01-08 12:11:45.087433: Pseudo dice [np.float32(0.7495), np.float32(0.4349)] 
2025-01-08 12:11:45.090939: Epoch time: 42.87 s 
2025-01-08 12:11:45.673568:  
2025-01-08 12:11:45.673568: Epoch 87 
2025-01-08 12:11:45.678080: Current learning rate: 0.00159 
2025-01-08 12:12:28.617773: train_loss -0.5753 
2025-01-08 12:12:28.617773: val_loss -0.5495 
2025-01-08 12:12:28.624787: Pseudo dice [np.float32(0.7812), np.float32(0.5166)] 
2025-01-08 12:12:28.627794: Epoch time: 42.95 s 
2025-01-08 12:12:28.631303: Yayy! New best EMA pseudo Dice: 0.6104999780654907 
2025-01-08 12:12:29.394206:  
2025-01-08 12:12:29.394206: Epoch 88 
2025-01-08 12:12:29.400314: Current learning rate: 0.00148 
2025-01-08 12:13:12.319833: train_loss -0.5808 
2025-01-08 12:13:12.320354: val_loss -0.5444 
2025-01-08 12:13:12.326430: Pseudo dice [np.float32(0.7268), np.float32(0.5153)] 
2025-01-08 12:13:12.329964: Epoch time: 42.93 s 
2025-01-08 12:13:12.332995: Yayy! New best EMA pseudo Dice: 0.6115000247955322 
2025-01-08 12:13:13.118045:  
2025-01-08 12:13:13.118548: Epoch 89 
2025-01-08 12:13:13.124118: Current learning rate: 0.00137 
2025-01-08 12:13:56.016092: train_loss -0.5802 
2025-01-08 12:13:56.016595: val_loss -0.5887 
2025-01-08 12:13:56.022886: Pseudo dice [np.float32(0.7733), np.float32(0.5871)] 
2025-01-08 12:13:56.026469: Epoch time: 42.9 s 
2025-01-08 12:13:56.029015: Yayy! New best EMA pseudo Dice: 0.618399977684021 
2025-01-08 12:13:56.794834:  
2025-01-08 12:13:56.794834: Epoch 90 
2025-01-08 12:13:56.800865: Current learning rate: 0.00126 
2025-01-08 12:14:39.790743: train_loss -0.5864 
2025-01-08 12:14:39.791245: val_loss -0.5169 
2025-01-08 12:14:39.797257: Pseudo dice [np.float32(0.7489), np.float32(0.4626)] 
2025-01-08 12:14:39.799762: Epoch time: 43.0 s 
2025-01-08 12:14:40.373722:  
2025-01-08 12:14:40.373722: Epoch 91 
2025-01-08 12:14:40.380264: Current learning rate: 0.00115 
2025-01-08 12:15:23.294391: train_loss -0.5739 
2025-01-08 12:15:23.295393: val_loss -0.553 
2025-01-08 12:15:23.298953: Pseudo dice [np.float32(0.7431), np.float32(0.4602)] 
2025-01-08 12:15:23.302988: Epoch time: 42.92 s 
2025-01-08 12:15:23.875620:  
2025-01-08 12:15:23.876123: Epoch 92 
2025-01-08 12:15:23.881143: Current learning rate: 0.00103 
2025-01-08 12:16:06.715953: train_loss -0.6086 
2025-01-08 12:16:06.716954: val_loss -0.5707 
2025-01-08 12:16:06.723478: Pseudo dice [np.float32(0.754), np.float32(0.5522)] 
2025-01-08 12:16:06.727487: Epoch time: 42.84 s 
2025-01-08 12:16:06.729994: Yayy! New best EMA pseudo Dice: 0.6193000078201294 
2025-01-08 12:16:07.683535:  
2025-01-08 12:16:07.683535: Epoch 93 
2025-01-08 12:16:07.690201: Current learning rate: 0.00091 
2025-01-08 12:16:50.544016: train_loss -0.6295 
2025-01-08 12:16:50.545524: val_loss -0.5583 
2025-01-08 12:16:50.551074: Pseudo dice [np.float32(0.7518), np.float32(0.4376)] 
2025-01-08 12:16:50.554585: Epoch time: 42.86 s 
2025-01-08 12:16:51.137135:  
2025-01-08 12:16:51.137135: Epoch 94 
2025-01-08 12:16:51.142195: Current learning rate: 0.00079 
2025-01-08 12:17:34.030122: train_loss -0.5956 
2025-01-08 12:17:34.031122: val_loss -0.5606 
2025-01-08 12:17:34.036641: Pseudo dice [np.float32(0.7448), np.float32(0.4845)] 
2025-01-08 12:17:34.040151: Epoch time: 42.89 s 
2025-01-08 12:17:34.608358:  
2025-01-08 12:17:34.609358: Epoch 95 
2025-01-08 12:17:34.614879: Current learning rate: 0.00067 
2025-01-08 12:18:17.508780: train_loss -0.6172 
2025-01-08 12:18:17.508780: val_loss -0.5798 
2025-01-08 12:18:17.514798: Pseudo dice [np.float32(0.7805), np.float32(0.5181)] 
2025-01-08 12:18:17.518811: Epoch time: 42.9 s 
2025-01-08 12:18:17.522325: Yayy! New best EMA pseudo Dice: 0.6198999881744385 
2025-01-08 12:18:18.264693:  
2025-01-08 12:18:18.265196: Epoch 96 
2025-01-08 12:18:18.270208: Current learning rate: 0.00055 
2025-01-08 12:19:01.143325: train_loss -0.6083 
2025-01-08 12:19:01.143854: val_loss -0.5315 
2025-01-08 12:19:01.148868: Pseudo dice [np.float32(0.7525), np.float32(0.3611)] 
2025-01-08 12:19:01.152377: Epoch time: 42.88 s 
2025-01-08 12:19:01.732324:  
2025-01-08 12:19:01.732324: Epoch 97 
2025-01-08 12:19:01.737346: Current learning rate: 0.00043 
2025-01-08 12:19:44.599182: train_loss -0.608 
2025-01-08 12:19:44.599182: val_loss -0.5261 
2025-01-08 12:19:44.605703: Pseudo dice [np.float32(0.7609), np.float32(0.407)] 
2025-01-08 12:19:44.609212: Epoch time: 42.87 s 
2025-01-08 12:19:45.191844:  
2025-01-08 12:19:45.192346: Epoch 98 
2025-01-08 12:19:45.197358: Current learning rate: 0.0003 
2025-01-08 12:20:28.129422: train_loss -0.6144 
2025-01-08 12:20:28.130426: val_loss -0.5777 
2025-01-08 12:20:28.136942: Pseudo dice [np.float32(0.7587), np.float32(0.5836)] 
2025-01-08 12:20:28.140451: Epoch time: 42.94 s 
2025-01-08 12:20:28.721253:  
2025-01-08 12:20:28.722256: Epoch 99 
2025-01-08 12:20:28.727291: Current learning rate: 0.00016 
2025-01-08 12:21:11.614643: train_loss -0.6059 
2025-01-08 12:21:11.615146: val_loss -0.5568 
2025-01-08 12:21:11.621164: Pseudo dice [np.float32(0.75), np.float32(0.4698)] 
2025-01-08 12:21:11.624674: Epoch time: 42.89 s 
2025-01-08 12:21:12.399874: Training done. 
2025-01-08 12:21:12.436877: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-08 12:21:12.443384: The split file contains 5 splits. 
2025-01-08 12:21:12.447384: Desired fold for training: 0 
2025-01-08 12:21:12.452384: This split has 224 training and 57 validation cases. 
2025-01-08 12:21:12.458384: predicting pancreas_021 
2025-01-08 12:21:12.466384: pancreas_021, shape torch.Size([1, 232, 442, 442]), rank 0 
2025-01-08 12:21:32.081819: predicting pancreas_024 
2025-01-08 12:21:32.097821: pancreas_024, shape torch.Size([1, 262, 407, 407]), rank 0 
2025-01-08 12:21:55.616632: predicting pancreas_035 
2025-01-08 12:21:55.634631: pancreas_035, shape torch.Size([1, 182, 314, 314]), rank 0 
2025-01-08 12:22:00.807085: predicting pancreas_040 
2025-01-08 12:22:00.815086: pancreas_040, shape torch.Size([1, 225, 422, 422]), rank 0 
2025-01-08 12:22:19.677909: predicting pancreas_042 
2025-01-08 12:22:19.691912: pancreas_042, shape torch.Size([1, 255, 431, 431]), rank 0 
2025-01-08 12:22:43.302503: predicting pancreas_056 
2025-01-08 12:22:43.319012: pancreas_056, shape torch.Size([1, 210, 392, 392]), rank 0 
2025-01-08 12:22:55.442695: predicting pancreas_067 
2025-01-08 12:22:55.460695: pancreas_067, shape torch.Size([1, 258, 421, 421]), rank 0 
2025-01-08 12:23:19.010006: predicting pancreas_075 
2025-01-08 12:23:19.029512: pancreas_075, shape torch.Size([1, 151, 418, 418]), rank 0 
2025-01-08 12:23:33.165698: predicting pancreas_086 
2025-01-08 12:23:33.177697: pancreas_086, shape torch.Size([1, 128, 460, 460]), rank 0 
2025-01-08 12:23:42.719304: predicting pancreas_089 
2025-01-08 12:23:42.736812: pancreas_089, shape torch.Size([1, 228, 398, 398]), rank 0 
2025-01-08 12:23:54.868616: predicting pancreas_092 
2025-01-08 12:23:54.880617: pancreas_092, shape torch.Size([1, 460, 412, 412]), rank 0 
2025-01-08 12:24:37.152812: predicting pancreas_094 
2025-01-08 12:24:37.191322: pancreas_094, shape torch.Size([1, 210, 370, 370]), rank 0 
2025-01-08 12:24:49.331965: predicting pancreas_095 
2025-01-08 12:24:49.344965: pancreas_095, shape torch.Size([1, 232, 385, 385]), rank 0 
2025-01-08 12:25:01.514029: predicting pancreas_098 
2025-01-08 12:25:01.535029: pancreas_098, shape torch.Size([1, 368, 475, 475]), rank 0 
2025-01-08 12:25:34.470366: predicting pancreas_109 
2025-01-08 12:25:34.505369: pancreas_109, shape torch.Size([1, 248, 408, 408]), rank 0 
2025-01-08 12:25:58.050667: predicting pancreas_110 
2025-01-08 12:25:58.066667: pancreas_110, shape torch.Size([1, 245, 500, 500]), rank 0 
2025-01-08 12:26:31.895639: predicting pancreas_114 
2025-01-08 12:26:31.920639: pancreas_114, shape torch.Size([1, 245, 362, 362]), rank 0 
2025-01-08 12:26:47.035280: predicting pancreas_119 
2025-01-08 12:26:47.048280: pancreas_119, shape torch.Size([1, 212, 460, 460]), rank 0 
2025-01-08 12:27:05.935332: predicting pancreas_138 
2025-01-08 12:27:05.953331: pancreas_138, shape torch.Size([1, 238, 480, 480]), rank 0 
2025-01-08 12:27:24.864828: predicting pancreas_145 
2025-01-08 12:27:24.886827: pancreas_145, shape torch.Size([1, 232, 480, 480]), rank 0 
2025-01-08 12:27:43.851823: predicting pancreas_148 
2025-01-08 12:27:43.869823: pancreas_148, shape torch.Size([1, 210, 390, 390]), rank 0 
2025-01-08 12:27:56.021214: predicting pancreas_169 
2025-01-08 12:27:56.036723: pancreas_169, shape torch.Size([1, 218, 380, 380]), rank 0 
2025-01-08 12:28:08.162269: predicting pancreas_170 
2025-01-08 12:28:08.177269: pancreas_170, shape torch.Size([1, 258, 411, 411]), rank 0 
2025-01-08 12:28:31.737469: predicting pancreas_172 
2025-01-08 12:28:31.762980: pancreas_172, shape torch.Size([1, 238, 379, 379]), rank 0 
2025-01-08 12:28:43.883709: predicting pancreas_175 
2025-01-08 12:28:43.897709: pancreas_175, shape torch.Size([1, 228, 398, 398]), rank 0 
2025-01-08 12:28:56.068581: predicting pancreas_180 
2025-01-08 12:28:56.086089: pancreas_180, shape torch.Size([1, 238, 380, 380]), rank 0 
2025-01-08 12:29:08.212014: predicting pancreas_191 
2025-01-08 12:29:08.231014: pancreas_191, shape torch.Size([1, 142, 378, 378]), rank 0 
2025-01-08 12:29:14.309754: predicting pancreas_193 
2025-01-08 12:29:14.321756: pancreas_193, shape torch.Size([1, 282, 398, 398]), rank 0 
2025-01-08 12:29:29.461678: predicting pancreas_212 
2025-01-08 12:29:29.476678: pancreas_212, shape torch.Size([1, 242, 447, 447]), rank 0 
2025-01-08 12:29:53.045558: predicting pancreas_215 
2025-01-08 12:29:53.067558: pancreas_215, shape torch.Size([1, 248, 388, 388]), rank 0 
2025-01-08 12:30:08.211222: predicting pancreas_222 
2025-01-08 12:30:08.224729: pancreas_222, shape torch.Size([1, 192, 310, 310]), rank 0 
2025-01-08 12:30:13.424223: predicting pancreas_235 
2025-01-08 12:30:13.433733: pancreas_235, shape torch.Size([1, 210, 398, 398]), rank 0 
2025-01-08 12:30:25.546553: predicting pancreas_241 
2025-01-08 12:30:25.559552: pancreas_241, shape torch.Size([1, 248, 409, 409]), rank 0 
2025-01-08 12:30:49.116177: predicting pancreas_242 
2025-01-08 12:30:49.132177: pancreas_242, shape torch.Size([1, 252, 446, 446]), rank 0 
2025-01-08 12:31:12.690435: predicting pancreas_244 
2025-01-08 12:31:12.711435: pancreas_244, shape torch.Size([1, 258, 465, 465]), rank 0 
2025-01-08 12:31:36.281661: predicting pancreas_246 
2025-01-08 12:31:36.301167: pancreas_246, shape torch.Size([1, 268, 460, 460]), rank 0 
2025-01-08 12:31:59.902523: predicting pancreas_247 
2025-01-08 12:31:59.933029: pancreas_247, shape torch.Size([1, 222, 330, 330]), rank 0 
2025-01-08 12:32:12.050354: predicting pancreas_264 
2025-01-08 12:32:12.059353: pancreas_264, shape torch.Size([1, 272, 429, 429]), rank 0 
2025-01-08 12:32:35.579350: predicting pancreas_265 
2025-01-08 12:32:35.598348: pancreas_265, shape torch.Size([1, 202, 427, 427]), rank 0 
2025-01-08 12:32:54.507481: predicting pancreas_266 
2025-01-08 12:32:54.522481: pancreas_266, shape torch.Size([1, 242, 460, 460]), rank 0 
2025-01-08 12:33:18.089081: predicting pancreas_267 
2025-01-08 12:33:18.107081: pancreas_267, shape torch.Size([1, 222, 348, 348]), rank 0 
2025-01-08 12:33:30.223185: predicting pancreas_275 
2025-01-08 12:33:30.241184: pancreas_275, shape torch.Size([1, 262, 384, 384]), rank 0 
2025-01-08 12:33:45.348181: predicting pancreas_279 
2025-01-08 12:33:45.368181: pancreas_279, shape torch.Size([1, 200, 360, 360]), rank 0 
2025-01-08 12:33:57.455270: predicting pancreas_287 
2025-01-08 12:33:57.474270: pancreas_287, shape torch.Size([1, 245, 399, 399]), rank 0 
2025-01-08 12:34:12.578709: predicting pancreas_301 
2025-01-08 12:34:12.591712: pancreas_301, shape torch.Size([1, 208, 427, 427]), rank 0 
2025-01-08 12:34:31.487227: predicting pancreas_323 
2025-01-08 12:34:31.503228: pancreas_323, shape torch.Size([1, 238, 491, 491]), rank 0 
2025-01-08 12:34:58.656375: predicting pancreas_336 
2025-01-08 12:34:58.685374: pancreas_336, shape torch.Size([1, 230, 440, 440]), rank 0 
2025-01-08 12:35:17.583654: predicting pancreas_344 
2025-01-08 12:35:17.601654: pancreas_344, shape torch.Size([1, 280, 395, 395]), rank 0 
2025-01-08 12:35:32.747673: predicting pancreas_351 
2025-01-08 12:35:32.761678: pancreas_351, shape torch.Size([1, 220, 345, 345]), rank 0 
2025-01-08 12:35:44.836168: predicting pancreas_354 
2025-01-08 12:35:44.848168: pancreas_354, shape torch.Size([1, 405, 425, 425]), rank 0 
2025-01-08 12:36:22.494342: predicting pancreas_372 
2025-01-08 12:36:22.531849: pancreas_372, shape torch.Size([1, 232, 500, 500]), rank 0 
2025-01-08 12:36:49.638055: predicting pancreas_377 
2025-01-08 12:36:49.666055: pancreas_377, shape torch.Size([1, 275, 442, 442]), rank 0 
2025-01-08 12:37:13.205520: predicting pancreas_387 
2025-01-08 12:37:13.227522: pancreas_387, shape torch.Size([1, 250, 400, 400]), rank 0 
2025-01-08 12:37:28.380395: predicting pancreas_391 
2025-01-08 12:37:28.396395: pancreas_391, shape torch.Size([1, 222, 490, 490]), rank 0 
2025-01-08 12:37:55.557997: predicting pancreas_392 
2025-01-08 12:37:55.577505: pancreas_392, shape torch.Size([1, 285, 360, 360]), rank 0 
2025-01-08 12:38:10.735424: predicting pancreas_410 
2025-01-08 12:38:10.750424: pancreas_410, shape torch.Size([1, 252, 360, 360]), rank 0 
2025-01-08 12:38:25.929567: predicting pancreas_412 
2025-01-08 12:38:25.940568: pancreas_412, shape torch.Size([1, 492, 469, 469]), rank 0 
2025-01-08 12:39:35.393703: Validation complete 
2025-01-08 12:39:35.393703: Mean Validation Dice:  0.6160678583794008 
