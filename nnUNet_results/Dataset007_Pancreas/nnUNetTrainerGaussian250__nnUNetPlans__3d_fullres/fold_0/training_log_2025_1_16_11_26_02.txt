
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-16 11:26:02.507479: do_dummy_2d_data_aug: True 
2025-01-16 11:26:02.510481: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-16 11:26:02.515260: The split file contains 5 splits. 
2025-01-16 11:26:02.517264: Desired fold for training: 0 
2025-01-16 11:26:02.520263: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-16 11:26:08.570678: unpacking dataset... 
2025-01-16 11:26:08.757972: unpacking done... 
2025-01-16 11:26:11.667389:  
2025-01-16 11:26:11.667389: Epoch 0 
2025-01-16 11:26:11.672955: Current learning rate: 0.01 
2025-01-16 11:26:56.734920: train_loss 0.12 
2025-01-16 11:26:56.734920: val_loss 0.0509 
2025-01-16 11:26:56.740451: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-16 11:26:56.743477: Epoch time: 45.07 s 
2025-01-16 11:26:56.746503: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-16 11:26:57.423792:  
2025-01-16 11:26:57.424793: Epoch 1 
2025-01-16 11:26:57.430363: Current learning rate: 0.00996 
2025-01-16 11:27:38.105891: train_loss -0.0075 
2025-01-16 11:27:38.105891: val_loss -0.1109 
2025-01-16 11:27:38.111904: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-16 11:27:38.114409: Epoch time: 40.68 s 
2025-01-16 11:27:38.630929:  
2025-01-16 11:27:38.631933: Epoch 2 
2025-01-16 11:27:38.636473: Current learning rate: 0.00993 
2025-01-16 11:28:19.310669: train_loss -0.1953 
2025-01-16 11:28:19.311668: val_loss -0.2476 
2025-01-16 11:28:19.317203: Pseudo dice [np.float32(0.6348), np.float32(0.0)] 
2025-01-16 11:28:19.320712: Epoch time: 40.68 s 
2025-01-16 11:28:19.323226: Yayy! New best EMA pseudo Dice: 0.031700000166893005 
2025-01-16 11:28:20.075531:  
2025-01-16 11:28:20.075531: Epoch 3 
2025-01-16 11:28:20.080545: Current learning rate: 0.00989 
2025-01-16 11:29:00.737566: train_loss -0.2724 
2025-01-16 11:29:00.738077: val_loss -0.3153 
2025-01-16 11:29:00.745153: Pseudo dice [np.float32(0.6703), np.float32(0.0)] 
2025-01-16 11:29:00.747699: Epoch time: 40.66 s 
2025-01-16 11:29:00.751261: Yayy! New best EMA pseudo Dice: 0.06210000067949295 
2025-01-16 11:29:01.494258:  
2025-01-16 11:29:01.494258: Epoch 4 
2025-01-16 11:29:01.499815: Current learning rate: 0.00986 
2025-01-16 11:29:42.179869: train_loss -0.3192 
2025-01-16 11:29:42.180390: val_loss -0.3622 
2025-01-16 11:29:42.185971: Pseudo dice [np.float32(0.6692), np.float32(0.0)] 
2025-01-16 11:29:42.189013: Epoch time: 40.69 s 
2025-01-16 11:29:42.192547: Yayy! New best EMA pseudo Dice: 0.0892999991774559 
2025-01-16 11:29:43.041944:  
2025-01-16 11:29:43.041944: Epoch 5 
2025-01-16 11:29:43.046957: Current learning rate: 0.00982 
2025-01-16 11:30:23.709698: train_loss -0.3465 
2025-01-16 11:30:23.710203: val_loss -0.3332 
2025-01-16 11:30:23.715217: Pseudo dice [np.float32(0.5898), np.float32(0.2362)] 
2025-01-16 11:30:23.718725: Epoch time: 40.67 s 
2025-01-16 11:30:23.722232: Yayy! New best EMA pseudo Dice: 0.1216999962925911 
2025-01-16 11:30:24.433906:  
2025-01-16 11:30:24.434909: Epoch 6 
2025-01-16 11:30:24.439511: Current learning rate: 0.00978 
2025-01-16 11:31:05.104967: train_loss -0.3695 
2025-01-16 11:31:05.104967: val_loss -0.422 
2025-01-16 11:31:05.113130: Pseudo dice [np.float32(0.7005), np.float32(0.2698)] 
2025-01-16 11:31:05.116643: Epoch time: 40.67 s 
2025-01-16 11:31:05.119652: Yayy! New best EMA pseudo Dice: 0.15800000727176666 
2025-01-16 11:31:05.849095:  
2025-01-16 11:31:05.849597: Epoch 7 
2025-01-16 11:31:05.855136: Current learning rate: 0.00975 
2025-01-16 11:31:46.540254: train_loss -0.4215 
2025-01-16 11:31:46.540766: val_loss -0.4091 
2025-01-16 11:31:46.545343: Pseudo dice [np.float32(0.6556), np.float32(0.3127)] 
2025-01-16 11:31:46.549393: Epoch time: 40.69 s 
2025-01-16 11:31:46.552449: Yayy! New best EMA pseudo Dice: 0.1906999945640564 
2025-01-16 11:31:47.274468:  
2025-01-16 11:31:47.274468: Epoch 8 
2025-01-16 11:31:47.279481: Current learning rate: 0.00971 
2025-01-16 11:32:27.970223: train_loss -0.4541 
2025-01-16 11:32:27.970223: val_loss -0.4321 
2025-01-16 11:32:27.976307: Pseudo dice [np.float32(0.6916), np.float32(0.3363)] 
2025-01-16 11:32:27.979342: Epoch time: 40.7 s 
2025-01-16 11:32:27.982438: Yayy! New best EMA pseudo Dice: 0.22300000488758087 
2025-01-16 11:32:28.707548:  
2025-01-16 11:32:28.708548: Epoch 9 
2025-01-16 11:32:28.714065: Current learning rate: 0.00968 
2025-01-16 11:33:09.400718: train_loss -0.4577 
2025-01-16 11:33:09.401718: val_loss -0.4735 
2025-01-16 11:33:09.407237: Pseudo dice [np.float32(0.6877), np.float32(0.3879)] 
2025-01-16 11:33:09.409745: Epoch time: 40.69 s 
2025-01-16 11:33:09.413258: Yayy! New best EMA pseudo Dice: 0.25450000166893005 
2025-01-16 11:33:10.118474:  
2025-01-16 11:33:10.118474: Epoch 10 
2025-01-16 11:33:10.123498: Current learning rate: 0.00964 
2025-01-16 11:33:50.821911: train_loss -0.4686 
2025-01-16 11:33:50.821911: val_loss -0.4527 
2025-01-16 11:33:50.828068: Pseudo dice [np.float32(0.7069), np.float32(0.3566)] 
2025-01-16 11:33:50.830607: Epoch time: 40.7 s 
2025-01-16 11:33:50.833148: Yayy! New best EMA pseudo Dice: 0.28220000863075256 
2025-01-16 11:33:51.533823:  
2025-01-16 11:33:51.534828: Epoch 11 
2025-01-16 11:33:51.539373: Current learning rate: 0.0096 
2025-01-16 11:34:32.237084: train_loss -0.494 
2025-01-16 11:34:32.237084: val_loss -0.4922 
2025-01-16 11:34:32.243462: Pseudo dice [np.float32(0.7192), np.float32(0.4555)] 
2025-01-16 11:34:32.247070: Epoch time: 40.7 s 
2025-01-16 11:34:32.249603: Yayy! New best EMA pseudo Dice: 0.3127000033855438 
2025-01-16 11:34:32.962223:  
2025-01-16 11:34:32.963728: Epoch 12 
2025-01-16 11:34:32.968737: Current learning rate: 0.00957 
2025-01-16 11:35:13.646932: train_loss -0.4924 
2025-01-16 11:35:13.647450: val_loss -0.4471 
2025-01-16 11:35:13.652548: Pseudo dice [np.float32(0.6813), np.float32(0.3102)] 
2025-01-16 11:35:13.657093: Epoch time: 40.68 s 
2025-01-16 11:35:13.659649: Yayy! New best EMA pseudo Dice: 0.3310000002384186 
2025-01-16 11:35:14.504780:  
2025-01-16 11:35:14.504780: Epoch 13 
2025-01-16 11:35:14.510852: Current learning rate: 0.00953 
2025-01-16 11:35:55.181553: train_loss -0.5149 
2025-01-16 11:35:55.182056: val_loss -0.4612 
2025-01-16 11:35:55.187152: Pseudo dice [np.float32(0.7173), np.float32(0.3177)] 
2025-01-16 11:35:55.190660: Epoch time: 40.68 s 
2025-01-16 11:35:55.193174: Yayy! New best EMA pseudo Dice: 0.349700003862381 
2025-01-16 11:35:55.922900:  
2025-01-16 11:35:55.922900: Epoch 14 
2025-01-16 11:35:55.928942: Current learning rate: 0.00949 
2025-01-16 11:36:36.599191: train_loss -0.538 
2025-01-16 11:36:36.599191: val_loss -0.5052 
2025-01-16 11:36:36.604727: Pseudo dice [np.float32(0.7298), np.float32(0.4424)] 
2025-01-16 11:36:36.608232: Epoch time: 40.68 s 
2025-01-16 11:36:36.611245: Yayy! New best EMA pseudo Dice: 0.3732999861240387 
2025-01-16 11:36:37.353041:  
2025-01-16 11:36:37.353041: Epoch 15 
2025-01-16 11:36:37.358052: Current learning rate: 0.00946 
2025-01-16 11:37:18.019480: train_loss -0.5344 
2025-01-16 11:37:18.019981: val_loss -0.5187 
2025-01-16 11:37:18.024993: Pseudo dice [np.float32(0.7358), np.float32(0.3682)] 
2025-01-16 11:37:18.028504: Epoch time: 40.67 s 
2025-01-16 11:37:18.031009: Yayy! New best EMA pseudo Dice: 0.3912000060081482 
2025-01-16 11:37:18.750846:  
2025-01-16 11:37:18.750846: Epoch 16 
2025-01-16 11:37:18.756909: Current learning rate: 0.00942 
2025-01-16 11:37:59.408197: train_loss -0.5447 
2025-01-16 11:37:59.408702: val_loss -0.5099 
2025-01-16 11:37:59.414258: Pseudo dice [np.float32(0.7431), np.float32(0.4213)] 
2025-01-16 11:37:59.417282: Epoch time: 40.66 s 
2025-01-16 11:37:59.420819: Yayy! New best EMA pseudo Dice: 0.41029998660087585 
2025-01-16 11:38:00.153724:  
2025-01-16 11:38:00.153724: Epoch 17 
2025-01-16 11:38:00.158752: Current learning rate: 0.00939 
2025-01-16 11:38:40.843116: train_loss -0.5446 
2025-01-16 11:38:40.843116: val_loss -0.4797 
2025-01-16 11:38:40.850153: Pseudo dice [np.float32(0.7299), np.float32(0.3398)] 
2025-01-16 11:38:40.852658: Epoch time: 40.69 s 
2025-01-16 11:38:40.856167: Yayy! New best EMA pseudo Dice: 0.4226999878883362 
2025-01-16 11:38:41.580660:  
2025-01-16 11:38:41.581663: Epoch 18 
2025-01-16 11:38:41.586742: Current learning rate: 0.00935 
2025-01-16 11:39:22.257522: train_loss -0.5423 
2025-01-16 11:39:22.257522: val_loss -0.5015 
2025-01-16 11:39:22.263562: Pseudo dice [np.float32(0.723), np.float32(0.3621)] 
2025-01-16 11:39:22.266571: Epoch time: 40.68 s 
2025-01-16 11:39:22.270079: Yayy! New best EMA pseudo Dice: 0.43470001220703125 
2025-01-16 11:39:23.002651:  
2025-01-16 11:39:23.004155: Epoch 19 
2025-01-16 11:39:23.009165: Current learning rate: 0.00931 
2025-01-16 11:40:03.689730: train_loss -0.5852 
2025-01-16 11:40:03.690234: val_loss -0.4716 
2025-01-16 11:40:03.695301: Pseudo dice [np.float32(0.7492), np.float32(0.2869)] 
2025-01-16 11:40:03.698810: Epoch time: 40.69 s 
2025-01-16 11:40:03.701317: Yayy! New best EMA pseudo Dice: 0.4429999887943268 
2025-01-16 11:40:04.427446:  
2025-01-16 11:40:04.427446: Epoch 20 
2025-01-16 11:40:04.435013: Current learning rate: 0.00928 
2025-01-16 11:40:45.121175: train_loss -0.5741 
2025-01-16 11:40:45.122181: val_loss -0.4433 
2025-01-16 11:40:45.126886: Pseudo dice [np.float32(0.711), np.float32(0.2668)] 
2025-01-16 11:40:45.131396: Epoch time: 40.7 s 
2025-01-16 11:40:45.134405: Yayy! New best EMA pseudo Dice: 0.44760000705718994 
2025-01-16 11:40:46.010946:  
2025-01-16 11:40:46.010946: Epoch 21 
2025-01-16 11:40:46.015965: Current learning rate: 0.00924 
2025-01-16 11:41:26.692932: train_loss -0.578 
2025-01-16 11:41:26.692932: val_loss -0.5298 
2025-01-16 11:41:26.699949: Pseudo dice [np.float32(0.7451), np.float32(0.4239)] 
2025-01-16 11:41:26.702959: Epoch time: 40.68 s 
2025-01-16 11:41:26.706467: Yayy! New best EMA pseudo Dice: 0.46129998564720154 
2025-01-16 11:41:27.413602:  
2025-01-16 11:41:27.414603: Epoch 22 
2025-01-16 11:41:27.419668: Current learning rate: 0.0092 
2025-01-16 11:42:08.102141: train_loss -0.569 
2025-01-16 11:42:08.102645: val_loss -0.5014 
2025-01-16 11:42:08.109248: Pseudo dice [np.float32(0.726), np.float32(0.4219)] 
2025-01-16 11:42:08.112753: Epoch time: 40.69 s 
2025-01-16 11:42:08.115761: Yayy! New best EMA pseudo Dice: 0.4726000130176544 
2025-01-16 11:42:08.824162:  
2025-01-16 11:42:08.824665: Epoch 23 
2025-01-16 11:42:08.829675: Current learning rate: 0.00917 
2025-01-16 11:42:49.524417: train_loss -0.5775 
2025-01-16 11:42:49.524934: val_loss -0.5226 
2025-01-16 11:42:49.530589: Pseudo dice [np.float32(0.7564), np.float32(0.3948)] 
2025-01-16 11:42:49.533616: Epoch time: 40.7 s 
2025-01-16 11:42:49.536148: Yayy! New best EMA pseudo Dice: 0.4828999936580658 
2025-01-16 11:42:50.238382:  
2025-01-16 11:42:50.239386: Epoch 24 
2025-01-16 11:42:50.243984: Current learning rate: 0.00913 
2025-01-16 11:43:30.946050: train_loss -0.5938 
2025-01-16 11:43:30.946050: val_loss -0.518 
2025-01-16 11:43:30.952060: Pseudo dice [np.float32(0.7329), np.float32(0.3631)] 
2025-01-16 11:43:30.955068: Epoch time: 40.71 s 
2025-01-16 11:43:30.958576: Yayy! New best EMA pseudo Dice: 0.4893999993801117 
2025-01-16 11:43:31.688503:  
2025-01-16 11:43:31.688503: Epoch 25 
2025-01-16 11:43:31.694606: Current learning rate: 0.0091 
2025-01-16 11:44:12.389620: train_loss -0.5801 
2025-01-16 11:44:12.390621: val_loss -0.5188 
2025-01-16 11:44:12.397150: Pseudo dice [np.float32(0.7622), np.float32(0.3684)] 
2025-01-16 11:44:12.399656: Epoch time: 40.7 s 
2025-01-16 11:44:12.403665: Yayy! New best EMA pseudo Dice: 0.4970000088214874 
2025-01-16 11:44:13.118124:  
2025-01-16 11:44:13.118124: Epoch 26 
2025-01-16 11:44:13.124182: Current learning rate: 0.00906 
2025-01-16 11:44:53.817771: train_loss -0.6002 
2025-01-16 11:44:53.818282: val_loss -0.4943 
2025-01-16 11:44:53.823967: Pseudo dice [np.float32(0.7197), np.float32(0.416)] 
2025-01-16 11:44:53.827991: Epoch time: 40.7 s 
2025-01-16 11:44:53.830514: Yayy! New best EMA pseudo Dice: 0.5041000247001648 
2025-01-16 11:44:54.553211:  
2025-01-16 11:44:54.553713: Epoch 27 
2025-01-16 11:44:54.558723: Current learning rate: 0.00902 
2025-01-16 11:45:35.240677: train_loss -0.622 
2025-01-16 11:45:35.240677: val_loss -0.5301 
2025-01-16 11:45:35.246691: Pseudo dice [np.float32(0.7664), np.float32(0.4301)] 
2025-01-16 11:45:35.250197: Epoch time: 40.69 s 
2025-01-16 11:45:35.253205: Yayy! New best EMA pseudo Dice: 0.5134999752044678 
2025-01-16 11:45:35.970305:  
2025-01-16 11:45:35.970305: Epoch 28 
2025-01-16 11:45:35.975314: Current learning rate: 0.00899 
2025-01-16 11:46:16.650394: train_loss -0.6097 
2025-01-16 11:46:16.651399: val_loss -0.4939 
2025-01-16 11:46:16.657408: Pseudo dice [np.float32(0.7475), np.float32(0.2958)] 
2025-01-16 11:46:16.660418: Epoch time: 40.68 s 
2025-01-16 11:46:16.662926: Yayy! New best EMA pseudo Dice: 0.5142999887466431 
2025-01-16 11:46:17.498177:  
2025-01-16 11:46:17.499182: Epoch 29 
2025-01-16 11:46:17.503734: Current learning rate: 0.00895 
2025-01-16 11:46:58.187572: train_loss -0.607 
2025-01-16 11:46:58.189075: val_loss -0.5066 
2025-01-16 11:46:58.194133: Pseudo dice [np.float32(0.7617), np.float32(0.3499)] 
2025-01-16 11:46:58.197166: Epoch time: 40.69 s 
2025-01-16 11:46:58.200200: Yayy! New best EMA pseudo Dice: 0.5184000134468079 
2025-01-16 11:46:58.939404:  
2025-01-16 11:46:58.940408: Epoch 30 
2025-01-16 11:46:58.944955: Current learning rate: 0.00891 
2025-01-16 11:47:39.622673: train_loss -0.6204 
2025-01-16 11:47:39.623179: val_loss -0.512 
2025-01-16 11:47:39.629258: Pseudo dice [np.float32(0.7566), np.float32(0.4135)] 
2025-01-16 11:47:39.632296: Epoch time: 40.68 s 
2025-01-16 11:47:39.634832: Yayy! New best EMA pseudo Dice: 0.5250999927520752 
2025-01-16 11:47:40.351092:  
2025-01-16 11:47:40.351092: Epoch 31 
2025-01-16 11:47:40.356166: Current learning rate: 0.00888 
2025-01-16 11:48:21.011182: train_loss -0.6542 
2025-01-16 11:48:21.011182: val_loss -0.5055 
2025-01-16 11:48:21.016289: Pseudo dice [np.float32(0.7458), np.float32(0.3627)] 
2025-01-16 11:48:21.020814: Epoch time: 40.66 s 
2025-01-16 11:48:21.023324: Yayy! New best EMA pseudo Dice: 0.527999997138977 
2025-01-16 11:48:21.753935:  
2025-01-16 11:48:21.754439: Epoch 32 
2025-01-16 11:48:21.759450: Current learning rate: 0.00884 
2025-01-16 11:49:02.403345: train_loss -0.6265 
2025-01-16 11:49:02.404348: val_loss -0.5448 
2025-01-16 11:49:02.409388: Pseudo dice [np.float32(0.7444), np.float32(0.5257)] 
2025-01-16 11:49:02.412182: Epoch time: 40.65 s 
2025-01-16 11:49:02.415692: Yayy! New best EMA pseudo Dice: 0.5386999845504761 
2025-01-16 11:49:03.144313:  
2025-01-16 11:49:03.144313: Epoch 33 
2025-01-16 11:49:03.149323: Current learning rate: 0.0088 
2025-01-16 11:49:43.794273: train_loss -0.6446 
2025-01-16 11:49:43.795278: val_loss -0.4822 
2025-01-16 11:49:43.800312: Pseudo dice [np.float32(0.7653), np.float32(0.2229)] 
2025-01-16 11:49:43.804322: Epoch time: 40.65 s 
2025-01-16 11:49:44.335301:  
2025-01-16 11:49:44.335804: Epoch 34 
2025-01-16 11:49:44.340814: Current learning rate: 0.00877 
2025-01-16 11:50:24.983025: train_loss -0.6727 
2025-01-16 11:50:24.983531: val_loss -0.5046 
2025-01-16 11:50:24.988577: Pseudo dice [np.float32(0.7515), np.float32(0.4597)] 
2025-01-16 11:50:24.991605: Epoch time: 40.65 s 
2025-01-16 11:50:24.994692: Yayy! New best EMA pseudo Dice: 0.5414000153541565 
2025-01-16 11:50:25.726996:  
2025-01-16 11:50:25.726996: Epoch 35 
2025-01-16 11:50:25.733083: Current learning rate: 0.00873 
2025-01-16 11:51:06.372202: train_loss -0.6394 
2025-01-16 11:51:06.372704: val_loss -0.4283 
2025-01-16 11:51:06.378271: Pseudo dice [np.float32(0.6856), np.float32(0.315)] 
2025-01-16 11:51:06.382317: Epoch time: 40.65 s 
2025-01-16 11:51:07.060482:  
2025-01-16 11:51:07.060988: Epoch 36 
2025-01-16 11:51:07.066561: Current learning rate: 0.00869 
2025-01-16 11:51:47.738871: train_loss -0.6597 
2025-01-16 11:51:47.739378: val_loss -0.4456 
2025-01-16 11:51:47.744992: Pseudo dice [np.float32(0.7233), np.float32(0.2979)] 
2025-01-16 11:51:47.748023: Epoch time: 40.68 s 
2025-01-16 11:51:48.291219:  
2025-01-16 11:51:48.291728: Epoch 37 
2025-01-16 11:51:48.296766: Current learning rate: 0.00866 
2025-01-16 11:52:28.967492: train_loss -0.6542 
2025-01-16 11:52:28.968005: val_loss -0.4978 
2025-01-16 11:52:28.974023: Pseudo dice [np.float32(0.7499), np.float32(0.3975)] 
2025-01-16 11:52:28.977530: Epoch time: 40.68 s 
2025-01-16 11:52:29.521223:  
2025-01-16 11:52:29.521726: Epoch 38 
2025-01-16 11:52:29.526738: Current learning rate: 0.00862 
2025-01-16 11:53:10.211254: train_loss -0.6329 
2025-01-16 11:53:10.211254: val_loss -0.5003 
2025-01-16 11:53:10.218775: Pseudo dice [np.float32(0.7459), np.float32(0.3162)] 
2025-01-16 11:53:10.222281: Epoch time: 40.69 s 
2025-01-16 11:53:10.787501:  
2025-01-16 11:53:10.787501: Epoch 39 
2025-01-16 11:53:10.793533: Current learning rate: 0.00858 
2025-01-16 11:53:51.481055: train_loss -0.6746 
2025-01-16 11:53:51.482061: val_loss -0.4649 
2025-01-16 11:53:51.488133: Pseudo dice [np.float32(0.7622), np.float32(0.2822)] 
2025-01-16 11:53:51.491220: Epoch time: 40.69 s 
2025-01-16 11:53:52.043428:  
2025-01-16 11:53:52.043428: Epoch 40 
2025-01-16 11:53:52.048483: Current learning rate: 0.00855 
2025-01-16 11:54:32.737972: train_loss -0.6754 
2025-01-16 11:54:32.738476: val_loss -0.5469 
2025-01-16 11:54:32.744019: Pseudo dice [np.float32(0.7527), np.float32(0.4595)] 
2025-01-16 11:54:32.747540: Epoch time: 40.7 s 
2025-01-16 11:54:32.750560: Yayy! New best EMA pseudo Dice: 0.5432000160217285 
2025-01-16 11:54:33.480261:  
2025-01-16 11:54:33.480261: Epoch 41 
2025-01-16 11:54:33.485273: Current learning rate: 0.00851 
2025-01-16 11:55:14.175491: train_loss -0.6838 
2025-01-16 11:55:14.175491: val_loss -0.5218 
2025-01-16 11:55:14.182504: Pseudo dice [np.float32(0.7686), np.float32(0.4145)] 
2025-01-16 11:55:14.186191: Epoch time: 40.7 s 
2025-01-16 11:55:14.188697: Yayy! New best EMA pseudo Dice: 0.5479999780654907 
2025-01-16 11:55:14.919138:  
2025-01-16 11:55:14.919138: Epoch 42 
2025-01-16 11:55:14.924151: Current learning rate: 0.00847 
2025-01-16 11:55:55.607275: train_loss -0.6878 
2025-01-16 11:55:55.608279: val_loss -0.4987 
2025-01-16 11:55:55.613426: Pseudo dice [np.float32(0.7593), np.float32(0.3065)] 
2025-01-16 11:55:55.615998: Epoch time: 40.69 s 
2025-01-16 11:55:56.140081:  
2025-01-16 11:55:56.140081: Epoch 43 
2025-01-16 11:55:56.145091: Current learning rate: 0.00844 
2025-01-16 11:56:36.819576: train_loss -0.6922 
2025-01-16 11:56:36.819576: val_loss -0.4605 
2025-01-16 11:56:36.824588: Pseudo dice [np.float32(0.7686), np.float32(0.2828)] 
2025-01-16 11:56:36.828096: Epoch time: 40.68 s 
2025-01-16 11:56:37.484024:  
2025-01-16 11:56:37.484024: Epoch 44 
2025-01-16 11:56:37.489572: Current learning rate: 0.0084 
2025-01-16 11:57:18.151524: train_loss -0.6869 
2025-01-16 11:57:18.152030: val_loss -0.4943 
2025-01-16 11:57:18.159076: Pseudo dice [np.float32(0.7602), np.float32(0.3456)] 
2025-01-16 11:57:18.161617: Epoch time: 40.67 s 
2025-01-16 11:57:18.680983:  
2025-01-16 11:57:18.681484: Epoch 45 
2025-01-16 11:57:18.686499: Current learning rate: 0.00836 
2025-01-16 11:57:59.348110: train_loss -0.7035 
2025-01-16 11:57:59.348627: val_loss -0.5303 
2025-01-16 11:57:59.353726: Pseudo dice [np.float32(0.7583), np.float32(0.3826)] 
2025-01-16 11:57:59.357236: Epoch time: 40.67 s 
2025-01-16 11:57:59.878690:  
2025-01-16 11:57:59.878690: Epoch 46 
2025-01-16 11:57:59.883700: Current learning rate: 0.00833 
2025-01-16 11:58:40.559961: train_loss -0.7161 
2025-01-16 11:58:40.560966: val_loss -0.5037 
2025-01-16 11:58:40.566043: Pseudo dice [np.float32(0.7538), np.float32(0.4407)] 
2025-01-16 11:58:40.569140: Epoch time: 40.68 s 
2025-01-16 11:58:40.572174: Yayy! New best EMA pseudo Dice: 0.5527999997138977 
2025-01-16 11:58:41.284139:  
2025-01-16 11:58:41.284139: Epoch 47 
2025-01-16 11:58:41.289678: Current learning rate: 0.00829 
2025-01-16 11:59:21.959774: train_loss -0.6832 
2025-01-16 11:59:21.959774: val_loss -0.4784 
2025-01-16 11:59:21.965792: Pseudo dice [np.float32(0.7273), np.float32(0.343)] 
2025-01-16 11:59:21.969301: Epoch time: 40.68 s 
2025-01-16 11:59:22.481729:  
2025-01-16 11:59:22.481729: Epoch 48 
2025-01-16 11:59:22.487781: Current learning rate: 0.00825 
2025-01-16 12:00:03.180366: train_loss -0.7016 
2025-01-16 12:00:03.181370: val_loss -0.5032 
2025-01-16 12:00:03.186380: Pseudo dice [np.float32(0.7829), np.float32(0.3633)] 
2025-01-16 12:00:03.189885: Epoch time: 40.7 s 
2025-01-16 12:00:03.192893: Yayy! New best EMA pseudo Dice: 0.5532000064849854 
2025-01-16 12:00:03.924102:  
2025-01-16 12:00:03.924102: Epoch 49 
2025-01-16 12:00:03.929641: Current learning rate: 0.00822 
2025-01-16 12:00:44.621590: train_loss -0.7217 
2025-01-16 12:00:44.621590: val_loss -0.557 
2025-01-16 12:00:44.627279: Pseudo dice [np.float32(0.7933), np.float32(0.4409)] 
2025-01-16 12:00:44.629784: Epoch time: 40.7 s 
2025-01-16 12:00:44.782717: Yayy! New best EMA pseudo Dice: 0.5595999956130981 
2025-01-16 12:00:45.556766:  
2025-01-16 12:00:45.556766: Epoch 50 
2025-01-16 12:00:45.562310: Current learning rate: 0.00818 
2025-01-16 12:01:26.235833: train_loss -0.7062 
2025-01-16 12:01:26.236840: val_loss -0.5337 
2025-01-16 12:01:26.242394: Pseudo dice [np.float32(0.7718), np.float32(0.3803)] 
2025-01-16 12:01:26.244912: Epoch time: 40.68 s 
2025-01-16 12:01:26.248432: Yayy! New best EMA pseudo Dice: 0.5612000226974487 
2025-01-16 12:01:26.970241:  
2025-01-16 12:01:26.970743: Epoch 51 
2025-01-16 12:01:26.975756: Current learning rate: 0.00814 
2025-01-16 12:02:07.651414: train_loss -0.7098 
2025-01-16 12:02:07.652413: val_loss -0.5126 
2025-01-16 12:02:07.657960: Pseudo dice [np.float32(0.7729), np.float32(0.3476)] 
2025-01-16 12:02:07.661469: Epoch time: 40.68 s 
2025-01-16 12:02:08.320631:  
2025-01-16 12:02:08.321634: Epoch 52 
2025-01-16 12:02:08.326195: Current learning rate: 0.00811 
2025-01-16 12:02:49.002129: train_loss -0.7124 
2025-01-16 12:02:49.003126: val_loss -0.5118 
2025-01-16 12:02:49.008641: Pseudo dice [np.float32(0.7543), np.float32(0.4324)] 
2025-01-16 12:02:49.011147: Epoch time: 40.68 s 
2025-01-16 12:02:49.014657: Yayy! New best EMA pseudo Dice: 0.5644000172615051 
2025-01-16 12:02:49.736661:  
2025-01-16 12:02:49.736661: Epoch 53 
2025-01-16 12:02:49.742197: Current learning rate: 0.00807 
2025-01-16 12:03:30.420781: train_loss -0.7238 
2025-01-16 12:03:30.421785: val_loss -0.4731 
2025-01-16 12:03:30.426795: Pseudo dice [np.float32(0.7482), np.float32(0.3557)] 
2025-01-16 12:03:30.430302: Epoch time: 40.68 s 
2025-01-16 12:03:30.960793:  
2025-01-16 12:03:30.960793: Epoch 54 
2025-01-16 12:03:30.966407: Current learning rate: 0.00803 
2025-01-16 12:04:11.655324: train_loss -0.7317 
2025-01-16 12:04:11.655827: val_loss -0.4883 
2025-01-16 12:04:11.660365: Pseudo dice [np.float32(0.7655), np.float32(0.3183)] 
2025-01-16 12:04:11.664597: Epoch time: 40.7 s 
2025-01-16 12:04:12.183609:  
2025-01-16 12:04:12.184112: Epoch 55 
2025-01-16 12:04:12.190130: Current learning rate: 0.008 
2025-01-16 12:04:52.884811: train_loss -0.7342 
2025-01-16 12:04:52.885815: val_loss -0.5249 
2025-01-16 12:04:52.890826: Pseudo dice [np.float32(0.7658), np.float32(0.4008)] 
2025-01-16 12:04:52.894834: Epoch time: 40.7 s 
2025-01-16 12:04:53.415062:  
2025-01-16 12:04:53.415062: Epoch 56 
2025-01-16 12:04:53.420073: Current learning rate: 0.00796 
2025-01-16 12:05:34.116620: train_loss -0.7302 
2025-01-16 12:05:34.116620: val_loss -0.5276 
2025-01-16 12:05:34.121700: Pseudo dice [np.float32(0.7703), np.float32(0.3721)] 
2025-01-16 12:05:34.125760: Epoch time: 40.7 s 
2025-01-16 12:05:34.645874:  
2025-01-16 12:05:34.645874: Epoch 57 
2025-01-16 12:05:34.651413: Current learning rate: 0.00792 
2025-01-16 12:06:15.320837: train_loss -0.7236 
2025-01-16 12:06:15.321836: val_loss -0.4461 
2025-01-16 12:06:15.327395: Pseudo dice [np.float32(0.7464), np.float32(0.2342)] 
2025-01-16 12:06:15.329934: Epoch time: 40.68 s 
2025-01-16 12:06:15.857972:  
2025-01-16 12:06:15.857972: Epoch 58 
2025-01-16 12:06:15.863027: Current learning rate: 0.00789 
2025-01-16 12:06:56.558792: train_loss -0.6905 
2025-01-16 12:06:56.559294: val_loss -0.4986 
2025-01-16 12:06:56.564308: Pseudo dice [np.float32(0.7588), np.float32(0.3233)] 
2025-01-16 12:06:56.567817: Epoch time: 40.7 s 
2025-01-16 12:06:57.088404:  
2025-01-16 12:06:57.089403: Epoch 59 
2025-01-16 12:06:57.094923: Current learning rate: 0.00785 
2025-01-16 12:07:37.781586: train_loss -0.7363 
2025-01-16 12:07:37.782090: val_loss -0.5406 
2025-01-16 12:07:37.787177: Pseudo dice [np.float32(0.7676), np.float32(0.4404)] 
2025-01-16 12:07:37.790278: Epoch time: 40.69 s 
2025-01-16 12:07:38.313646:  
2025-01-16 12:07:38.313646: Epoch 60 
2025-01-16 12:07:38.319243: Current learning rate: 0.00781 
2025-01-16 12:08:19.006604: train_loss -0.73 
2025-01-16 12:08:19.006604: val_loss -0.5011 
2025-01-16 12:08:19.013163: Pseudo dice [np.float32(0.7503), np.float32(0.3486)] 
2025-01-16 12:08:19.016672: Epoch time: 40.69 s 
2025-01-16 12:08:19.680775:  
2025-01-16 12:08:19.681778: Epoch 61 
2025-01-16 12:08:19.686377: Current learning rate: 0.00777 
2025-01-16 12:09:00.380624: train_loss -0.7261 
2025-01-16 12:09:00.381627: val_loss -0.547 
2025-01-16 12:09:00.386378: Pseudo dice [np.float32(0.7684), np.float32(0.468)] 
2025-01-16 12:09:00.389575: Epoch time: 40.7 s 
2025-01-16 12:09:00.392608: Yayy! New best EMA pseudo Dice: 0.5648999810218811 
2025-01-16 12:09:01.110063:  
2025-01-16 12:09:01.110063: Epoch 62 
2025-01-16 12:09:01.115577: Current learning rate: 0.00774 
2025-01-16 12:09:41.802104: train_loss -0.7464 
2025-01-16 12:09:41.802611: val_loss -0.4855 
2025-01-16 12:09:41.807801: Pseudo dice [np.float32(0.76), np.float32(0.3301)] 
2025-01-16 12:09:41.810848: Epoch time: 40.69 s 
2025-01-16 12:09:42.338322:  
2025-01-16 12:09:42.338322: Epoch 63 
2025-01-16 12:09:42.344336: Current learning rate: 0.0077 
2025-01-16 12:10:23.038953: train_loss -0.7611 
2025-01-16 12:10:23.038953: val_loss -0.5274 
2025-01-16 12:10:23.046470: Pseudo dice [np.float32(0.7607), np.float32(0.4112)] 
2025-01-16 12:10:23.050479: Epoch time: 40.7 s 
2025-01-16 12:10:23.053987: Yayy! New best EMA pseudo Dice: 0.5651999711990356 
2025-01-16 12:10:23.796944:  
2025-01-16 12:10:23.796944: Epoch 64 
2025-01-16 12:10:23.802978: Current learning rate: 0.00766 
2025-01-16 12:11:04.494348: train_loss -0.7701 
2025-01-16 12:11:04.494869: val_loss -0.5508 
2025-01-16 12:11:04.501034: Pseudo dice [np.float32(0.7682), np.float32(0.4771)] 
2025-01-16 12:11:04.503593: Epoch time: 40.7 s 
2025-01-16 12:11:04.507648: Yayy! New best EMA pseudo Dice: 0.570900022983551 
2025-01-16 12:11:05.235699:  
2025-01-16 12:11:05.236202: Epoch 65 
2025-01-16 12:11:05.242216: Current learning rate: 0.00763 
2025-01-16 12:11:45.916079: train_loss -0.7479 
2025-01-16 12:11:45.916079: val_loss -0.531 
2025-01-16 12:11:45.922665: Pseudo dice [np.float32(0.7846), np.float32(0.4434)] 
2025-01-16 12:11:45.926222: Epoch time: 40.68 s 
2025-01-16 12:11:45.928809: Yayy! New best EMA pseudo Dice: 0.5752000212669373 
2025-01-16 12:11:46.646307:  
2025-01-16 12:11:46.647310: Epoch 66 
2025-01-16 12:11:46.652927: Current learning rate: 0.00759 
2025-01-16 12:12:27.319888: train_loss -0.7628 
2025-01-16 12:12:27.319888: val_loss -0.5198 
2025-01-16 12:12:27.326404: Pseudo dice [np.float32(0.7881), np.float32(0.4248)] 
2025-01-16 12:12:27.329912: Epoch time: 40.67 s 
2025-01-16 12:12:27.333919: Yayy! New best EMA pseudo Dice: 0.5784000158309937 
2025-01-16 12:12:28.081599:  
2025-01-16 12:12:28.081599: Epoch 67 
2025-01-16 12:12:28.087147: Current learning rate: 0.00755 
2025-01-16 12:13:08.774226: train_loss -0.7729 
2025-01-16 12:13:08.774226: val_loss -0.5727 
2025-01-16 12:13:08.780309: Pseudo dice [np.float32(0.7861), np.float32(0.4554)] 
2025-01-16 12:13:08.783413: Epoch time: 40.69 s 
2025-01-16 12:13:08.787422: Yayy! New best EMA pseudo Dice: 0.5825999975204468 
2025-01-16 12:13:09.691947:  
2025-01-16 12:13:09.692947: Epoch 68 
2025-01-16 12:13:09.698577: Current learning rate: 0.00751 
2025-01-16 12:13:50.378870: train_loss -0.7558 
2025-01-16 12:13:50.379374: val_loss -0.5602 
2025-01-16 12:13:50.385389: Pseudo dice [np.float32(0.7923), np.float32(0.4657)] 
2025-01-16 12:13:50.388892: Epoch time: 40.69 s 
2025-01-16 12:13:50.392905: Yayy! New best EMA pseudo Dice: 0.5871999859809875 
2025-01-16 12:13:51.124524:  
2025-01-16 12:13:51.124524: Epoch 69 
2025-01-16 12:13:51.130078: Current learning rate: 0.00748 
2025-01-16 12:14:31.835181: train_loss -0.7665 
2025-01-16 12:14:31.835181: val_loss -0.5319 
2025-01-16 12:14:31.841821: Pseudo dice [np.float32(0.7645), np.float32(0.3902)] 
2025-01-16 12:14:31.846838: Epoch time: 40.71 s 
2025-01-16 12:14:32.400858:  
2025-01-16 12:14:32.400858: Epoch 70 
2025-01-16 12:14:32.406427: Current learning rate: 0.00744 
2025-01-16 12:15:13.112533: train_loss -0.7894 
2025-01-16 12:15:13.113044: val_loss -0.5716 
2025-01-16 12:15:13.118597: Pseudo dice [np.float32(0.7884), np.float32(0.4855)] 
2025-01-16 12:15:13.122108: Epoch time: 40.71 s 
2025-01-16 12:15:13.126120: Yayy! New best EMA pseudo Dice: 0.5913000106811523 
2025-01-16 12:15:13.923888:  
2025-01-16 12:15:13.924888: Epoch 71 
2025-01-16 12:15:13.930488: Current learning rate: 0.0074 
2025-01-16 12:15:54.643909: train_loss -0.79 
2025-01-16 12:15:54.644421: val_loss -0.5102 
2025-01-16 12:15:54.650048: Pseudo dice [np.float32(0.7704), np.float32(0.4063)] 
2025-01-16 12:15:54.654109: Epoch time: 40.72 s 
2025-01-16 12:15:55.204371:  
2025-01-16 12:15:55.204371: Epoch 72 
2025-01-16 12:15:55.211015: Current learning rate: 0.00737 
2025-01-16 12:16:35.873291: train_loss -0.7685 
2025-01-16 12:16:35.873291: val_loss -0.5382 
2025-01-16 12:16:35.879804: Pseudo dice [np.float32(0.7732), np.float32(0.4677)] 
2025-01-16 12:16:35.883312: Epoch time: 40.67 s 
2025-01-16 12:16:35.886816: Yayy! New best EMA pseudo Dice: 0.593999981880188 
2025-01-16 12:16:36.631147:  
2025-01-16 12:16:36.632148: Epoch 73 
2025-01-16 12:16:36.637664: Current learning rate: 0.00733 
2025-01-16 12:17:17.280879: train_loss -0.7383 
2025-01-16 12:17:17.281879: val_loss -0.5157 
2025-01-16 12:17:17.288462: Pseudo dice [np.float32(0.7719), np.float32(0.4108)] 
2025-01-16 12:17:17.291972: Epoch time: 40.65 s 
2025-01-16 12:17:17.829028:  
2025-01-16 12:17:17.829028: Epoch 74 
2025-01-16 12:17:17.835072: Current learning rate: 0.00729 
2025-01-16 12:17:58.472854: train_loss -0.7572 
2025-01-16 12:17:58.474373: val_loss -0.5049 
2025-01-16 12:17:58.480474: Pseudo dice [np.float32(0.7749), np.float32(0.3769)] 
2025-01-16 12:17:58.483984: Epoch time: 40.64 s 
2025-01-16 12:17:59.027926:  
2025-01-16 12:17:59.027926: Epoch 75 
2025-01-16 12:17:59.033476: Current learning rate: 0.00725 
2025-01-16 12:18:39.691173: train_loss -0.7804 
2025-01-16 12:18:39.691675: val_loss -0.5494 
2025-01-16 12:18:39.697795: Pseudo dice [np.float32(0.7859), np.float32(0.4614)] 
2025-01-16 12:18:39.701803: Epoch time: 40.66 s 
2025-01-16 12:18:39.705311: Yayy! New best EMA pseudo Dice: 0.5950999855995178 
2025-01-16 12:18:40.453546:  
2025-01-16 12:18:40.453546: Epoch 76 
2025-01-16 12:18:40.459561: Current learning rate: 0.00722 
2025-01-16 12:19:21.103040: train_loss -0.7575 
2025-01-16 12:19:21.103544: val_loss -0.5386 
2025-01-16 12:19:21.109071: Pseudo dice [np.float32(0.7761), np.float32(0.4171)] 
2025-01-16 12:19:21.113339: Epoch time: 40.65 s 
2025-01-16 12:19:21.117352: Yayy! New best EMA pseudo Dice: 0.5952000021934509 
2025-01-16 12:19:22.042501:  
2025-01-16 12:19:22.042501: Epoch 77 
2025-01-16 12:19:22.048628: Current learning rate: 0.00718 
2025-01-16 12:20:02.698699: train_loss -0.7674 
2025-01-16 12:20:02.699724: val_loss -0.5718 
2025-01-16 12:20:02.706331: Pseudo dice [np.float32(0.7829), np.float32(0.4689)] 
2025-01-16 12:20:02.709894: Epoch time: 40.66 s 
2025-01-16 12:20:02.713437: Yayy! New best EMA pseudo Dice: 0.5982999801635742 
2025-01-16 12:20:03.473757:  
2025-01-16 12:20:03.473757: Epoch 78 
2025-01-16 12:20:03.479285: Current learning rate: 0.00714 
2025-01-16 12:20:44.162061: train_loss -0.7833 
2025-01-16 12:20:44.162061: val_loss -0.5419 
2025-01-16 12:20:44.167627: Pseudo dice [np.float32(0.7749), np.float32(0.46)] 
2025-01-16 12:20:44.173171: Epoch time: 40.69 s 
2025-01-16 12:20:44.176676: Yayy! New best EMA pseudo Dice: 0.6001999974250793 
2025-01-16 12:20:44.934643:  
2025-01-16 12:20:44.935643: Epoch 79 
2025-01-16 12:20:44.941256: Current learning rate: 0.0071 
2025-01-16 12:21:25.605548: train_loss -0.7749 
2025-01-16 12:21:25.605548: val_loss -0.5316 
2025-01-16 12:21:25.613093: Pseudo dice [np.float32(0.7737), np.float32(0.3438)] 
2025-01-16 12:21:25.618105: Epoch time: 40.67 s 
2025-01-16 12:21:26.161459:  
2025-01-16 12:21:26.161459: Epoch 80 
2025-01-16 12:21:26.167003: Current learning rate: 0.00707 
2025-01-16 12:22:06.821673: train_loss -0.7769 
2025-01-16 12:22:06.822188: val_loss -0.5039 
2025-01-16 12:22:06.827723: Pseudo dice [np.float32(0.7504), np.float32(0.3436)] 
2025-01-16 12:22:06.831731: Epoch time: 40.66 s 
2025-01-16 12:22:07.385285:  
2025-01-16 12:22:07.386285: Epoch 81 
2025-01-16 12:22:07.391920: Current learning rate: 0.00703 
2025-01-16 12:22:48.047058: train_loss -0.7867 
2025-01-16 12:22:48.048058: val_loss -0.543 
2025-01-16 12:22:48.054577: Pseudo dice [np.float32(0.7878), np.float32(0.3912)] 
2025-01-16 12:22:48.058584: Epoch time: 40.66 s 
2025-01-16 12:22:48.609100:  
2025-01-16 12:22:48.609603: Epoch 82 
2025-01-16 12:22:48.614614: Current learning rate: 0.00699 
2025-01-16 12:23:29.285230: train_loss -0.8001 
2025-01-16 12:23:29.285752: val_loss -0.5306 
2025-01-16 12:23:29.291608: Pseudo dice [np.float32(0.763), np.float32(0.3711)] 
2025-01-16 12:23:29.295190: Epoch time: 40.68 s 
2025-01-16 12:23:29.809673:  
2025-01-16 12:23:29.809673: Epoch 83 
2025-01-16 12:23:29.815815: Current learning rate: 0.00696 
2025-01-16 12:24:10.484916: train_loss -0.799 
2025-01-16 12:24:10.484916: val_loss -0.4955 
2025-01-16 12:24:10.491428: Pseudo dice [np.float32(0.7762), np.float32(0.2702)] 
2025-01-16 12:24:10.496438: Epoch time: 40.68 s 
2025-01-16 12:24:11.015303:  
2025-01-16 12:24:11.015303: Epoch 84 
2025-01-16 12:24:11.020868: Current learning rate: 0.00692 
2025-01-16 12:24:51.710092: train_loss -0.7894 
2025-01-16 12:24:51.710092: val_loss -0.5617 
2025-01-16 12:24:51.715669: Pseudo dice [np.float32(0.7892), np.float32(0.4403)] 
2025-01-16 12:24:51.720199: Epoch time: 40.7 s 
2025-01-16 12:24:52.232277:  
2025-01-16 12:24:52.232277: Epoch 85 
2025-01-16 12:24:52.238291: Current learning rate: 0.00688 
2025-01-16 12:25:32.891393: train_loss -0.7873 
2025-01-16 12:25:32.892398: val_loss -0.5044 
2025-01-16 12:25:32.898091: Pseudo dice [np.float32(0.746), np.float32(0.3673)] 
2025-01-16 12:25:32.901623: Epoch time: 40.66 s 
2025-01-16 12:25:33.415714:  
2025-01-16 12:25:33.415714: Epoch 86 
2025-01-16 12:25:33.421730: Current learning rate: 0.00684 
2025-01-16 12:26:14.074412: train_loss -0.7941 
2025-01-16 12:26:14.074412: val_loss -0.5135 
2025-01-16 12:26:14.081429: Pseudo dice [np.float32(0.7484), np.float32(0.4264)] 
2025-01-16 12:26:14.084438: Epoch time: 40.66 s 
2025-01-16 12:26:14.603734:  
2025-01-16 12:26:14.604237: Epoch 87 
2025-01-16 12:26:14.609247: Current learning rate: 0.0068 
2025-01-16 12:26:55.276109: train_loss -0.799 
2025-01-16 12:26:55.277112: val_loss -0.4852 
2025-01-16 12:26:55.283245: Pseudo dice [np.float32(0.7569), np.float32(0.389)] 
2025-01-16 12:26:55.287272: Epoch time: 40.67 s 
2025-01-16 12:26:55.865102:  
2025-01-16 12:26:55.866103: Epoch 88 
2025-01-16 12:26:55.871701: Current learning rate: 0.00677 
2025-01-16 12:27:36.554763: train_loss -0.8008 
2025-01-16 12:27:36.554763: val_loss -0.5239 
2025-01-16 12:27:36.561918: Pseudo dice [np.float32(0.7798), np.float32(0.3985)] 
2025-01-16 12:27:36.565488: Epoch time: 40.69 s 
2025-01-16 12:27:37.088203:  
2025-01-16 12:27:37.088203: Epoch 89 
2025-01-16 12:27:37.094215: Current learning rate: 0.00673 
2025-01-16 12:28:17.776067: train_loss -0.8074 
2025-01-16 12:28:17.776572: val_loss -0.5533 
2025-01-16 12:28:17.782794: Pseudo dice [np.float32(0.7663), np.float32(0.4421)] 
2025-01-16 12:28:17.786310: Epoch time: 40.69 s 
2025-01-16 12:28:18.303233:  
2025-01-16 12:28:18.303233: Epoch 90 
2025-01-16 12:28:18.308746: Current learning rate: 0.00669 
2025-01-16 12:28:58.996541: train_loss -0.8131 
2025-01-16 12:28:58.997545: val_loss -0.5284 
2025-01-16 12:28:59.003557: Pseudo dice [np.float32(0.7726), np.float32(0.4518)] 
2025-01-16 12:28:59.011077: Epoch time: 40.69 s 
2025-01-16 12:28:59.586049:  
2025-01-16 12:28:59.586049: Epoch 91 
2025-01-16 12:28:59.590097: Current learning rate: 0.00665 
2025-01-16 12:29:40.330567: train_loss -0.8141 
2025-01-16 12:29:40.331568: val_loss -0.5311 
2025-01-16 12:29:40.338086: Pseudo dice [np.float32(0.7785), np.float32(0.4074)] 
2025-01-16 12:29:40.342098: Epoch time: 40.75 s 
2025-01-16 12:29:40.856313:  
2025-01-16 12:29:40.856815: Epoch 92 
2025-01-16 12:29:40.861826: Current learning rate: 0.00662 
2025-01-16 12:30:21.535136: train_loss -0.8057 
2025-01-16 12:30:21.535136: val_loss -0.5641 
2025-01-16 12:30:21.542652: Pseudo dice [np.float32(0.7887), np.float32(0.4688)] 
2025-01-16 12:30:21.546661: Epoch time: 40.68 s 
2025-01-16 12:30:22.203487:  
2025-01-16 12:30:22.203487: Epoch 93 
2025-01-16 12:30:22.210068: Current learning rate: 0.00658 
2025-01-16 12:31:02.882613: train_loss -0.8152 
2025-01-16 12:31:02.882613: val_loss -0.5763 
2025-01-16 12:31:02.889751: Pseudo dice [np.float32(0.7767), np.float32(0.5253)] 
2025-01-16 12:31:02.893813: Epoch time: 40.68 s 
2025-01-16 12:31:03.414446:  
2025-01-16 12:31:03.414446: Epoch 94 
2025-01-16 12:31:03.420460: Current learning rate: 0.00654 
2025-01-16 12:31:44.089448: train_loss -0.8102 
2025-01-16 12:31:44.089952: val_loss -0.4663 
2025-01-16 12:31:44.095537: Pseudo dice [np.float32(0.7374), np.float32(0.4458)] 
2025-01-16 12:31:44.100065: Epoch time: 40.68 s 
2025-01-16 12:31:44.615943:  
2025-01-16 12:31:44.616470: Epoch 95 
2025-01-16 12:31:44.622024: Current learning rate: 0.0065 
2025-01-16 12:32:25.279154: train_loss -0.8074 
2025-01-16 12:32:25.279154: val_loss -0.4963 
2025-01-16 12:32:25.286668: Pseudo dice [np.float32(0.78), np.float32(0.3383)] 
2025-01-16 12:32:25.290677: Epoch time: 40.66 s 
2025-01-16 12:32:25.806461:  
2025-01-16 12:32:25.806461: Epoch 96 
2025-01-16 12:32:25.812562: Current learning rate: 0.00647 
2025-01-16 12:33:06.496701: train_loss -0.7885 
2025-01-16 12:33:06.496701: val_loss -0.5971 
2025-01-16 12:33:06.504220: Pseudo dice [np.float32(0.7875), np.float32(0.59)] 
2025-01-16 12:33:06.508229: Epoch time: 40.69 s 
2025-01-16 12:33:06.511742: Yayy! New best EMA pseudo Dice: 0.6031000018119812 
2025-01-16 12:33:07.242389:  
2025-01-16 12:33:07.242389: Epoch 97 
2025-01-16 12:33:07.249045: Current learning rate: 0.00643 
2025-01-16 12:33:47.936411: train_loss -0.8139 
2025-01-16 12:33:47.936411: val_loss -0.5278 
2025-01-16 12:33:47.942928: Pseudo dice [np.float32(0.7847), np.float32(0.4693)] 
2025-01-16 12:33:47.946440: Epoch time: 40.7 s 
2025-01-16 12:33:47.951452: Yayy! New best EMA pseudo Dice: 0.6054999828338623 
2025-01-16 12:33:48.714060:  
2025-01-16 12:33:48.714060: Epoch 98 
2025-01-16 12:33:48.720055: Current learning rate: 0.00639 
2025-01-16 12:34:29.388041: train_loss -0.8243 
2025-01-16 12:34:29.388545: val_loss -0.5318 
2025-01-16 12:34:29.394588: Pseudo dice [np.float32(0.7703), np.float32(0.4808)] 
2025-01-16 12:34:29.399600: Epoch time: 40.67 s 
2025-01-16 12:34:29.403610: Yayy! New best EMA pseudo Dice: 0.6075000166893005 
2025-01-16 12:34:30.142054:  
2025-01-16 12:34:30.142559: Epoch 99 
2025-01-16 12:34:30.147572: Current learning rate: 0.00635 
2025-01-16 12:35:10.799581: train_loss -0.8263 
2025-01-16 12:35:10.800083: val_loss -0.5042 
2025-01-16 12:35:10.806148: Pseudo dice [np.float32(0.7796), np.float32(0.4201)] 
2025-01-16 12:35:10.811215: Epoch time: 40.66 s 
2025-01-16 12:35:11.525275:  
2025-01-16 12:35:11.526274: Epoch 100 
2025-01-16 12:35:11.531846: Current learning rate: 0.00631 
2025-01-16 12:35:52.192586: train_loss -0.8268 
2025-01-16 12:35:52.193591: val_loss -0.5499 
2025-01-16 12:35:52.199638: Pseudo dice [np.float32(0.7785), np.float32(0.4801)] 
2025-01-16 12:35:52.203648: Epoch time: 40.67 s 
2025-01-16 12:35:52.207659: Yayy! New best EMA pseudo Dice: 0.609000027179718 
2025-01-16 12:35:53.096131:  
2025-01-16 12:35:53.096690: Epoch 101 
2025-01-16 12:35:53.101700: Current learning rate: 0.00628 
2025-01-16 12:36:33.741487: train_loss -0.8137 
2025-01-16 12:36:33.743005: val_loss -0.5312 
2025-01-16 12:36:33.749072: Pseudo dice [np.float32(0.7769), np.float32(0.4661)] 
2025-01-16 12:36:33.753635: Epoch time: 40.65 s 
2025-01-16 12:36:33.759237: Yayy! New best EMA pseudo Dice: 0.6101999878883362 
2025-01-16 12:36:34.528158:  
2025-01-16 12:36:34.528661: Epoch 102 
2025-01-16 12:36:34.534679: Current learning rate: 0.00624 
2025-01-16 12:37:15.181211: train_loss -0.8301 
2025-01-16 12:37:15.181211: val_loss -0.569 
2025-01-16 12:37:15.186803: Pseudo dice [np.float32(0.7799), np.float32(0.4151)] 
2025-01-16 12:37:15.191888: Epoch time: 40.65 s 
2025-01-16 12:37:15.715853:  
2025-01-16 12:37:15.715853: Epoch 103 
2025-01-16 12:37:15.722491: Current learning rate: 0.0062 
2025-01-16 12:37:56.379888: train_loss -0.8307 
2025-01-16 12:37:56.379888: val_loss -0.5151 
2025-01-16 12:37:56.386404: Pseudo dice [np.float32(0.781), np.float32(0.4639)] 
2025-01-16 12:37:56.390912: Epoch time: 40.67 s 
2025-01-16 12:37:56.394922: Yayy! New best EMA pseudo Dice: 0.6103000044822693 
2025-01-16 12:37:57.135989:  
2025-01-16 12:37:57.135989: Epoch 104 
2025-01-16 12:37:57.142001: Current learning rate: 0.00616 
2025-01-16 12:38:37.797652: train_loss -0.816 
2025-01-16 12:38:37.798652: val_loss -0.539 
2025-01-16 12:38:37.805169: Pseudo dice [np.float32(0.7815), np.float32(0.5002)] 
2025-01-16 12:38:37.809177: Epoch time: 40.66 s 
2025-01-16 12:38:37.813690: Yayy! New best EMA pseudo Dice: 0.6133999824523926 
2025-01-16 12:38:38.573155:  
2025-01-16 12:38:38.574160: Epoch 105 
2025-01-16 12:38:38.580779: Current learning rate: 0.00612 
2025-01-16 12:39:19.247838: train_loss -0.8219 
2025-01-16 12:39:19.248846: val_loss -0.5805 
2025-01-16 12:39:19.254416: Pseudo dice [np.float32(0.7786), np.float32(0.5966)] 
2025-01-16 12:39:19.258924: Epoch time: 40.67 s 
2025-01-16 12:39:19.262936: Yayy! New best EMA pseudo Dice: 0.6208000183105469 
2025-01-16 12:39:20.010312:  
2025-01-16 12:39:20.010312: Epoch 106 
2025-01-16 12:39:20.016889: Current learning rate: 0.00609 
2025-01-16 12:40:00.687342: train_loss -0.8105 
2025-01-16 12:40:00.688342: val_loss -0.5144 
2025-01-16 12:40:00.694405: Pseudo dice [np.float32(0.7907), np.float32(0.5352)] 
2025-01-16 12:40:00.698934: Epoch time: 40.68 s 
2025-01-16 12:40:00.702442: Yayy! New best EMA pseudo Dice: 0.625 
2025-01-16 12:40:01.461283:  
2025-01-16 12:40:01.461283: Epoch 107 
2025-01-16 12:40:01.467302: Current learning rate: 0.00605 
2025-01-16 12:40:42.119754: train_loss -0.8233 
2025-01-16 12:40:42.120270: val_loss -0.5204 
2025-01-16 12:40:42.127307: Pseudo dice [np.float32(0.772), np.float32(0.433)] 
2025-01-16 12:40:42.132321: Epoch time: 40.66 s 
2025-01-16 12:40:42.662786:  
2025-01-16 12:40:42.662786: Epoch 108 
2025-01-16 12:40:42.668806: Current learning rate: 0.00601 
2025-01-16 12:41:23.315693: train_loss -0.8265 
2025-01-16 12:41:23.316196: val_loss -0.5335 
2025-01-16 12:41:23.322216: Pseudo dice [np.float32(0.7637), np.float32(0.4351)] 
2025-01-16 12:41:23.326224: Epoch time: 40.65 s 
2025-01-16 12:41:23.889239:  
2025-01-16 12:41:23.890239: Epoch 109 
2025-01-16 12:41:23.895818: Current learning rate: 0.00597 
2025-01-16 12:42:04.545020: train_loss -0.8248 
2025-01-16 12:42:04.546020: val_loss -0.5333 
2025-01-16 12:42:04.551536: Pseudo dice [np.float32(0.7903), np.float32(0.4963)] 
2025-01-16 12:42:04.556549: Epoch time: 40.66 s 
2025-01-16 12:42:05.229450:  
2025-01-16 12:42:05.229952: Epoch 110 
2025-01-16 12:42:05.235997: Current learning rate: 0.00593 
2025-01-16 12:42:45.874500: train_loss -0.8364 
2025-01-16 12:42:45.875003: val_loss -0.561 
2025-01-16 12:42:45.881639: Pseudo dice [np.float32(0.7768), np.float32(0.552)] 
2025-01-16 12:42:45.885708: Epoch time: 40.65 s 
2025-01-16 12:42:45.889736: Yayy! New best EMA pseudo Dice: 0.6269000172615051 
2025-01-16 12:42:46.627052:  
2025-01-16 12:42:46.627562: Epoch 111 
2025-01-16 12:42:46.633111: Current learning rate: 0.0059 
2025-01-16 12:43:27.251218: train_loss -0.8346 
2025-01-16 12:43:27.251721: val_loss -0.5401 
2025-01-16 12:43:27.259328: Pseudo dice [np.float32(0.7709), np.float32(0.4853)] 
2025-01-16 12:43:27.262877: Epoch time: 40.62 s 
2025-01-16 12:43:27.267427: Yayy! New best EMA pseudo Dice: 0.6269999742507935 
2025-01-16 12:43:27.981784:  
2025-01-16 12:43:27.981784: Epoch 112 
2025-01-16 12:43:27.987905: Current learning rate: 0.00586 
2025-01-16 12:44:08.607838: train_loss -0.8365 
2025-01-16 12:44:08.607838: val_loss -0.5192 
2025-01-16 12:44:08.614353: Pseudo dice [np.float32(0.7805), np.float32(0.4815)] 
2025-01-16 12:44:08.618867: Epoch time: 40.63 s 
2025-01-16 12:44:08.622880: Yayy! New best EMA pseudo Dice: 0.6273999810218811 
2025-01-16 12:44:09.352975:  
2025-01-16 12:44:09.352975: Epoch 113 
2025-01-16 12:44:09.360074: Current learning rate: 0.00582 
2025-01-16 12:44:50.021099: train_loss -0.8246 
2025-01-16 12:44:50.021099: val_loss -0.5431 
2025-01-16 12:44:50.029140: Pseudo dice [np.float32(0.7579), np.float32(0.532)] 
2025-01-16 12:44:50.033148: Epoch time: 40.67 s 
2025-01-16 12:44:50.036659: Yayy! New best EMA pseudo Dice: 0.6291999816894531 
2025-01-16 12:44:50.766677:  
2025-01-16 12:44:50.766677: Epoch 114 
2025-01-16 12:44:50.773689: Current learning rate: 0.00578 
2025-01-16 12:45:31.433185: train_loss -0.8275 
2025-01-16 12:45:31.433693: val_loss -0.5566 
2025-01-16 12:45:31.439254: Pseudo dice [np.float32(0.8014), np.float32(0.4383)] 
2025-01-16 12:45:31.443357: Epoch time: 40.67 s 
2025-01-16 12:45:31.965204:  
2025-01-16 12:45:31.966210: Epoch 115 
2025-01-16 12:45:31.970768: Current learning rate: 0.00574 
2025-01-16 12:46:12.621608: train_loss -0.8329 
2025-01-16 12:46:12.623130: val_loss -0.5607 
2025-01-16 12:46:12.629201: Pseudo dice [np.float32(0.7738), np.float32(0.5477)] 
2025-01-16 12:46:12.632709: Epoch time: 40.66 s 
2025-01-16 12:46:12.636717: Yayy! New best EMA pseudo Dice: 0.6315000057220459 
2025-01-16 12:46:13.380790:  
2025-01-16 12:46:13.380790: Epoch 116 
2025-01-16 12:46:13.387347: Current learning rate: 0.0057 
2025-01-16 12:46:54.049225: train_loss -0.8429 
2025-01-16 12:46:54.049225: val_loss -0.5595 
2025-01-16 12:46:54.055740: Pseudo dice [np.float32(0.7782), np.float32(0.615)] 
2025-01-16 12:46:54.059250: Epoch time: 40.67 s 
2025-01-16 12:46:54.063259: Yayy! New best EMA pseudo Dice: 0.6380000114440918 
2025-01-16 12:46:54.840145:  
2025-01-16 12:46:54.840145: Epoch 117 
2025-01-16 12:46:54.846814: Current learning rate: 0.00567 
2025-01-16 12:47:35.512462: train_loss -0.8255 
2025-01-16 12:47:35.512984: val_loss -0.5452 
2025-01-16 12:47:35.519067: Pseudo dice [np.float32(0.7771), np.float32(0.5082)] 
2025-01-16 12:47:35.523669: Epoch time: 40.67 s 
2025-01-16 12:47:35.526747: Yayy! New best EMA pseudo Dice: 0.6384999752044678 
2025-01-16 12:47:36.395131:  
2025-01-16 12:47:36.396131: Epoch 118 
2025-01-16 12:47:36.401721: Current learning rate: 0.00563 
2025-01-16 12:48:17.038186: train_loss -0.823 
2025-01-16 12:48:17.038186: val_loss -0.5488 
2025-01-16 12:48:17.045703: Pseudo dice [np.float32(0.7748), np.float32(0.5373)] 
2025-01-16 12:48:17.049711: Epoch time: 40.64 s 
2025-01-16 12:48:17.054219: Yayy! New best EMA pseudo Dice: 0.6402000188827515 
2025-01-16 12:48:17.826411:  
2025-01-16 12:48:17.826411: Epoch 119 
2025-01-16 12:48:17.832515: Current learning rate: 0.00559 
2025-01-16 12:48:58.468452: train_loss -0.8401 
2025-01-16 12:48:58.468969: val_loss -0.5282 
2025-01-16 12:48:58.475071: Pseudo dice [np.float32(0.7609), np.float32(0.5018)] 
2025-01-16 12:48:58.479080: Epoch time: 40.64 s 
2025-01-16 12:48:59.005103:  
2025-01-16 12:48:59.006103: Epoch 120 
2025-01-16 12:48:59.011719: Current learning rate: 0.00555 
2025-01-16 12:49:45.418578: train_loss -0.8499 
2025-01-16 12:49:45.419092: val_loss -0.546 
2025-01-16 12:49:45.425303: Pseudo dice [np.float32(0.7689), np.float32(0.4381)] 
2025-01-16 12:49:45.428832: Epoch time: 46.41 s 
2025-01-16 12:49:45.974182:  
2025-01-16 12:49:45.974182: Epoch 121 
2025-01-16 12:49:45.980199: Current learning rate: 0.00551 
2025-01-16 12:50:27.776365: train_loss -0.8482 
2025-01-16 12:50:27.776365: val_loss -0.5474 
2025-01-16 12:50:27.782380: Pseudo dice [np.float32(0.7887), np.float32(0.5206)] 
2025-01-16 12:50:27.786391: Epoch time: 41.8 s 
2025-01-16 12:50:28.339097:  
2025-01-16 12:50:28.339097: Epoch 122 
2025-01-16 12:50:28.345117: Current learning rate: 0.00547 
2025-01-16 12:51:10.147415: train_loss -0.8324 
2025-01-16 12:51:10.147918: val_loss -0.5712 
2025-01-16 12:51:10.153968: Pseudo dice [np.float32(0.7786), np.float32(0.5469)] 
2025-01-16 12:51:10.158986: Epoch time: 41.81 s 
2025-01-16 12:51:10.707791:  
2025-01-16 12:51:10.707791: Epoch 123 
2025-01-16 12:51:10.714171: Current learning rate: 0.00544 
2025-01-16 12:51:52.552788: train_loss -0.839 
2025-01-16 12:51:52.553292: val_loss -0.4978 
2025-01-16 12:51:52.558871: Pseudo dice [np.float32(0.7804), np.float32(0.4408)] 
2025-01-16 12:51:52.563382: Epoch time: 41.85 s 
2025-01-16 12:51:53.110039:  
2025-01-16 12:51:53.110039: Epoch 124 
2025-01-16 12:51:53.116197: Current learning rate: 0.0054 
2025-01-16 12:52:34.957247: train_loss -0.857 
2025-01-16 12:52:34.958251: val_loss -0.5624 
2025-01-16 12:52:34.963398: Pseudo dice [np.float32(0.794), np.float32(0.5436)] 
2025-01-16 12:52:34.967914: Epoch time: 41.85 s 
2025-01-16 12:52:34.971308: Yayy! New best EMA pseudo Dice: 0.6402999758720398 
2025-01-16 12:52:35.719594:  
2025-01-16 12:52:35.719594: Epoch 125 
2025-01-16 12:52:35.725615: Current learning rate: 0.00536 
2025-01-16 12:53:17.541870: train_loss -0.8614 
2025-01-16 12:53:17.542373: val_loss -0.5224 
2025-01-16 12:53:17.548392: Pseudo dice [np.float32(0.7909), np.float32(0.3769)] 
2025-01-16 12:53:17.552403: Epoch time: 41.82 s 
2025-01-16 12:53:18.252037:  
2025-01-16 12:53:18.253041: Epoch 126 
2025-01-16 12:53:18.258299: Current learning rate: 0.00532 
2025-01-16 12:54:00.048261: train_loss -0.8648 
2025-01-16 12:54:00.049765: val_loss -0.5575 
2025-01-16 12:54:00.055420: Pseudo dice [np.float32(0.7954), np.float32(0.4502)] 
2025-01-16 12:54:00.058558: Epoch time: 41.8 s 
2025-01-16 12:54:00.607165:  
2025-01-16 12:54:00.607165: Epoch 127 
2025-01-16 12:54:00.612748: Current learning rate: 0.00528 
2025-01-16 12:54:41.337376: train_loss -0.8443 
2025-01-16 12:54:41.338381: val_loss -0.5431 
2025-01-16 12:54:41.344898: Pseudo dice [np.float32(0.7838), np.float32(0.4797)] 
2025-01-16 12:54:41.348411: Epoch time: 40.73 s 
2025-01-16 12:54:41.900299:  
2025-01-16 12:54:41.900299: Epoch 128 
2025-01-16 12:54:41.905816: Current learning rate: 0.00524 
2025-01-16 12:55:22.627951: train_loss -0.8528 
2025-01-16 12:55:22.627951: val_loss -0.5379 
2025-01-16 12:55:22.635082: Pseudo dice [np.float32(0.7978), np.float32(0.4081)] 
2025-01-16 12:55:22.639115: Epoch time: 40.73 s 
2025-01-16 12:55:23.176515:  
2025-01-16 12:55:23.176515: Epoch 129 
2025-01-16 12:55:23.182534: Current learning rate: 0.0052 
2025-01-16 12:56:03.926986: train_loss -0.8541 
2025-01-16 12:56:03.927490: val_loss -0.5546 
2025-01-16 12:56:03.934252: Pseudo dice [np.float32(0.7855), np.float32(0.4889)] 
2025-01-16 12:56:03.938285: Epoch time: 40.75 s 
2025-01-16 12:56:04.482840:  
2025-01-16 12:56:04.483342: Epoch 130 
2025-01-16 12:56:04.489362: Current learning rate: 0.00517 
2025-01-16 12:56:45.227169: train_loss -0.8435 
2025-01-16 12:56:45.227169: val_loss -0.4867 
2025-01-16 12:56:45.232809: Pseudo dice [np.float32(0.771), np.float32(0.4184)] 
2025-01-16 12:56:45.237359: Epoch time: 40.75 s 
2025-01-16 12:56:45.791357:  
2025-01-16 12:56:45.791357: Epoch 131 
2025-01-16 12:56:45.797024: Current learning rate: 0.00513 
2025-01-16 12:57:26.534598: train_loss -0.8429 
2025-01-16 12:57:26.535120: val_loss -0.5325 
2025-01-16 12:57:26.541134: Pseudo dice [np.float32(0.7935), np.float32(0.3895)] 
2025-01-16 12:57:26.545145: Epoch time: 40.74 s 
2025-01-16 12:57:27.099846:  
2025-01-16 12:57:27.100354: Epoch 132 
2025-01-16 12:57:27.105943: Current learning rate: 0.00509 
2025-01-16 12:58:07.832408: train_loss -0.8247 
2025-01-16 12:58:07.832922: val_loss -0.5361 
2025-01-16 12:58:07.838564: Pseudo dice [np.float32(0.7799), np.float32(0.4334)] 
2025-01-16 12:58:07.842616: Epoch time: 40.73 s 
2025-01-16 12:58:08.388526:  
2025-01-16 12:58:08.388526: Epoch 133 
2025-01-16 12:58:08.394543: Current learning rate: 0.00505 
2025-01-16 12:58:49.120005: train_loss -0.8298 
2025-01-16 12:58:49.121519: val_loss -0.5489 
2025-01-16 12:58:49.128197: Pseudo dice [np.float32(0.7758), np.float32(0.4809)] 
2025-01-16 12:58:49.131814: Epoch time: 40.73 s 
2025-01-16 12:58:49.825801:  
2025-01-16 12:58:49.825801: Epoch 134 
2025-01-16 12:58:49.831823: Current learning rate: 0.00501 
2025-01-16 12:59:30.558248: train_loss -0.8378 
2025-01-16 12:59:30.559248: val_loss -0.5344 
2025-01-16 12:59:30.565820: Pseudo dice [np.float32(0.778), np.float32(0.4167)] 
2025-01-16 12:59:30.569833: Epoch time: 40.73 s 
2025-01-16 12:59:31.124405:  
2025-01-16 12:59:31.125408: Epoch 135 
2025-01-16 12:59:31.130448: Current learning rate: 0.00497 
2025-01-16 13:00:11.868745: train_loss -0.8555 
2025-01-16 13:00:11.868745: val_loss -0.5337 
2025-01-16 13:00:11.874803: Pseudo dice [np.float32(0.7883), np.float32(0.4905)] 
2025-01-16 13:00:11.878828: Epoch time: 40.74 s 
2025-01-16 13:00:12.436711:  
2025-01-16 13:00:12.437214: Epoch 136 
2025-01-16 13:00:12.443226: Current learning rate: 0.00493 
2025-01-16 13:00:53.167040: train_loss -0.8582 
2025-01-16 13:00:53.167563: val_loss -0.5561 
2025-01-16 13:00:53.173582: Pseudo dice [np.float32(0.7936), np.float32(0.4959)] 
2025-01-16 13:00:53.178600: Epoch time: 40.73 s 
2025-01-16 13:00:53.726149:  
2025-01-16 13:00:53.726149: Epoch 137 
2025-01-16 13:00:53.732190: Current learning rate: 0.00489 
2025-01-16 13:01:34.469385: train_loss -0.8469 
2025-01-16 13:01:34.470903: val_loss -0.5362 
2025-01-16 13:01:34.478511: Pseudo dice [np.float32(0.7793), np.float32(0.4037)] 
2025-01-16 13:01:34.482531: Epoch time: 40.74 s 
2025-01-16 13:01:35.033594:  
2025-01-16 13:01:35.033594: Epoch 138 
2025-01-16 13:01:35.040171: Current learning rate: 0.00485 
2025-01-16 13:02:15.780450: train_loss -0.8457 
2025-01-16 13:02:15.780954: val_loss -0.4981 
2025-01-16 13:02:15.787528: Pseudo dice [np.float32(0.7563), np.float32(0.3906)] 
2025-01-16 13:02:15.791542: Epoch time: 40.75 s 
2025-01-16 13:02:16.344799:  
2025-01-16 13:02:16.344799: Epoch 139 
2025-01-16 13:02:16.351341: Current learning rate: 0.00482 
2025-01-16 13:02:57.094854: train_loss -0.841 
2025-01-16 13:02:57.095358: val_loss -0.5403 
2025-01-16 13:02:57.101373: Pseudo dice [np.float32(0.7878), np.float32(0.5125)] 
2025-01-16 13:02:57.105379: Epoch time: 40.75 s 
2025-01-16 13:02:57.661897:  
2025-01-16 13:02:57.661897: Epoch 140 
2025-01-16 13:02:57.666913: Current learning rate: 0.00478 
2025-01-16 13:03:38.402498: train_loss -0.8591 
2025-01-16 13:03:38.402498: val_loss -0.5304 
2025-01-16 13:03:38.409566: Pseudo dice [np.float32(0.7841), np.float32(0.4269)] 
2025-01-16 13:03:38.414078: Epoch time: 40.74 s 
2025-01-16 13:03:38.961622:  
2025-01-16 13:03:38.961622: Epoch 141 
2025-01-16 13:03:38.968223: Current learning rate: 0.00474 
2025-01-16 13:04:19.703158: train_loss -0.8633 
2025-01-16 13:04:19.703663: val_loss -0.5158 
2025-01-16 13:04:19.709734: Pseudo dice [np.float32(0.7901), np.float32(0.3691)] 
2025-01-16 13:04:19.713747: Epoch time: 40.74 s 
2025-01-16 13:04:20.266693:  
2025-01-16 13:04:20.266693: Epoch 142 
2025-01-16 13:04:20.273332: Current learning rate: 0.0047 
2025-01-16 13:05:01.049127: train_loss -0.8684 
2025-01-16 13:05:01.050133: val_loss -0.5338 
2025-01-16 13:05:01.057656: Pseudo dice [np.float32(0.7967), np.float32(0.4644)] 
2025-01-16 13:05:01.061663: Epoch time: 40.78 s 
2025-01-16 13:05:01.617413:  
2025-01-16 13:05:01.617413: Epoch 143 
2025-01-16 13:05:01.623460: Current learning rate: 0.00466 
2025-01-16 13:05:42.372238: train_loss -0.8607 
2025-01-16 13:05:42.373240: val_loss -0.5057 
2025-01-16 13:05:42.379830: Pseudo dice [np.float32(0.7753), np.float32(0.3616)] 
2025-01-16 13:05:42.384866: Epoch time: 40.76 s 
2025-01-16 13:05:42.933626:  
2025-01-16 13:05:42.933626: Epoch 144 
2025-01-16 13:05:42.940231: Current learning rate: 0.00462 
2025-01-16 13:06:23.676276: train_loss -0.8695 
2025-01-16 13:06:23.677278: val_loss -0.5588 
2025-01-16 13:06:23.683800: Pseudo dice [np.float32(0.7747), np.float32(0.5362)] 
2025-01-16 13:06:23.687812: Epoch time: 40.74 s 
2025-01-16 13:06:24.247566:  
2025-01-16 13:06:24.247566: Epoch 145 
2025-01-16 13:06:24.253144: Current learning rate: 0.00458 
2025-01-16 13:07:04.977772: train_loss -0.863 
2025-01-16 13:07:04.977772: val_loss -0.5179 
2025-01-16 13:07:04.984962: Pseudo dice [np.float32(0.7721), np.float32(0.5458)] 
2025-01-16 13:07:04.989023: Epoch time: 40.73 s 
2025-01-16 13:07:05.539433:  
2025-01-16 13:07:05.539433: Epoch 146 
2025-01-16 13:07:05.546454: Current learning rate: 0.00454 
2025-01-16 13:07:46.262684: train_loss -0.8599 
2025-01-16 13:07:46.263686: val_loss -0.5121 
2025-01-16 13:07:46.270207: Pseudo dice [np.float32(0.759), np.float32(0.5234)] 
2025-01-16 13:07:46.274219: Epoch time: 40.72 s 
2025-01-16 13:07:46.832430:  
2025-01-16 13:07:46.832933: Epoch 147 
2025-01-16 13:07:46.837562: Current learning rate: 0.0045 
2025-01-16 13:08:27.546201: train_loss -0.8575 
2025-01-16 13:08:27.547710: val_loss -0.4907 
2025-01-16 13:08:27.554242: Pseudo dice [np.float32(0.774), np.float32(0.4165)] 
2025-01-16 13:08:27.558247: Epoch time: 40.71 s 
2025-01-16 13:08:28.110839:  
2025-01-16 13:08:28.110839: Epoch 148 
2025-01-16 13:08:28.117421: Current learning rate: 0.00446 
2025-01-16 13:09:08.836567: train_loss -0.8419 
2025-01-16 13:09:08.836567: val_loss -0.4936 
2025-01-16 13:09:08.843136: Pseudo dice [np.float32(0.7712), np.float32(0.3768)] 
2025-01-16 13:09:08.846740: Epoch time: 40.73 s 
2025-01-16 13:09:09.399397:  
2025-01-16 13:09:09.399397: Epoch 149 
2025-01-16 13:09:09.406072: Current learning rate: 0.00442 
2025-01-16 13:09:50.134485: train_loss -0.8602 
2025-01-16 13:09:50.134992: val_loss -0.5529 
2025-01-16 13:09:50.140522: Pseudo dice [np.float32(0.79), np.float32(0.543)] 
2025-01-16 13:09:50.145041: Epoch time: 40.74 s 
2025-01-16 13:09:51.083757:  
2025-01-16 13:09:51.083757: Epoch 150 
2025-01-16 13:09:51.091006: Current learning rate: 0.00438 
2025-01-16 13:10:31.827067: train_loss -0.8658 
2025-01-16 13:10:31.828068: val_loss -0.5443 
2025-01-16 13:10:31.835589: Pseudo dice [np.float32(0.7918), np.float32(0.4853)] 
2025-01-16 13:10:31.839606: Epoch time: 40.74 s 
2025-01-16 13:10:32.389941:  
2025-01-16 13:10:32.389941: Epoch 151 
2025-01-16 13:10:32.395515: Current learning rate: 0.00434 
2025-01-16 13:11:13.121288: train_loss -0.8656 
2025-01-16 13:11:13.121797: val_loss -0.5236 
2025-01-16 13:11:13.128354: Pseudo dice [np.float32(0.8024), np.float32(0.4076)] 
2025-01-16 13:11:13.131363: Epoch time: 40.73 s 
2025-01-16 13:11:13.684469:  
2025-01-16 13:11:13.685472: Epoch 152 
2025-01-16 13:11:13.690033: Current learning rate: 0.0043 
2025-01-16 13:11:54.423037: train_loss -0.8551 
2025-01-16 13:11:54.423540: val_loss -0.5388 
2025-01-16 13:11:54.430063: Pseudo dice [np.float32(0.7777), np.float32(0.4155)] 
2025-01-16 13:11:54.433593: Epoch time: 40.74 s 
2025-01-16 13:11:54.993219:  
2025-01-16 13:11:54.993219: Epoch 153 
2025-01-16 13:11:54.999235: Current learning rate: 0.00427 
2025-01-16 13:12:35.714776: train_loss -0.8639 
2025-01-16 13:12:35.714776: val_loss -0.5036 
2025-01-16 13:12:35.721968: Pseudo dice [np.float32(0.7622), np.float32(0.4225)] 
2025-01-16 13:12:35.726534: Epoch time: 40.72 s 
2025-01-16 13:12:36.284756:  
2025-01-16 13:12:36.284756: Epoch 154 
2025-01-16 13:12:36.290286: Current learning rate: 0.00423 
2025-01-16 13:13:17.007638: train_loss -0.8704 
2025-01-16 13:13:17.008642: val_loss -0.5631 
2025-01-16 13:13:17.014205: Pseudo dice [np.float32(0.7981), np.float32(0.4793)] 
2025-01-16 13:13:17.018716: Epoch time: 40.72 s 
2025-01-16 13:13:17.585780:  
2025-01-16 13:13:17.586780: Epoch 155 
2025-01-16 13:13:17.592412: Current learning rate: 0.00419 
2025-01-16 13:14:04.348712: train_loss -0.8595 
2025-01-16 13:14:04.349253: val_loss -0.579 
2025-01-16 13:14:04.354840: Pseudo dice [np.float32(0.8062), np.float32(0.5579)] 
2025-01-16 13:14:04.359390: Epoch time: 46.76 s 
2025-01-16 13:14:04.958748:  
2025-01-16 13:14:04.958748: Epoch 156 
2025-01-16 13:14:04.964792: Current learning rate: 0.00415 
2025-01-16 13:14:46.896788: train_loss -0.8712 
2025-01-16 13:14:46.897808: val_loss -0.539 
2025-01-16 13:14:46.905436: Pseudo dice [np.float32(0.7793), np.float32(0.4374)] 
2025-01-16 13:14:46.909040: Epoch time: 41.94 s 
2025-01-16 13:14:47.503787:  
2025-01-16 13:14:47.503787: Epoch 157 
2025-01-16 13:14:47.509802: Current learning rate: 0.00411 
2025-01-16 13:15:29.445122: train_loss -0.8685 
2025-01-16 13:15:29.446127: val_loss -0.5612 
2025-01-16 13:15:29.453730: Pseudo dice [np.float32(0.767), np.float32(0.4993)] 
2025-01-16 13:15:29.458016: Epoch time: 41.94 s 
2025-01-16 13:15:30.221219:  
2025-01-16 13:15:30.221722: Epoch 158 
2025-01-16 13:15:30.226733: Current learning rate: 0.00407 
2025-01-16 13:16:12.138974: train_loss -0.8729 
2025-01-16 13:16:12.139513: val_loss -0.5342 
2025-01-16 13:16:12.145111: Pseudo dice [np.float32(0.7967), np.float32(0.4575)] 
2025-01-16 13:16:12.149173: Epoch time: 41.92 s 
2025-01-16 13:16:12.734556:  
2025-01-16 13:16:12.735553: Epoch 159 
2025-01-16 13:16:12.741180: Current learning rate: 0.00403 
2025-01-16 13:16:54.695758: train_loss -0.8815 
2025-01-16 13:16:54.696260: val_loss -0.5658 
2025-01-16 13:16:54.702278: Pseudo dice [np.float32(0.8038), np.float32(0.4872)] 
2025-01-16 13:16:54.705784: Epoch time: 41.96 s 
2025-01-16 13:16:55.297390:  
2025-01-16 13:16:55.297390: Epoch 160 
2025-01-16 13:16:55.303499: Current learning rate: 0.00399 
2025-01-16 13:17:37.275632: train_loss -0.883 
2025-01-16 13:17:37.276135: val_loss -0.5772 
2025-01-16 13:17:37.283787: Pseudo dice [np.float32(0.7836), np.float32(0.4483)] 
2025-01-16 13:17:37.287305: Epoch time: 41.98 s 
2025-01-16 13:17:37.882884:  
2025-01-16 13:17:37.882884: Epoch 161 
2025-01-16 13:17:37.888463: Current learning rate: 0.00395 
2025-01-16 13:18:19.835979: train_loss -0.8656 
2025-01-16 13:18:19.835979: val_loss -0.5211 
2025-01-16 13:18:19.842060: Pseudo dice [np.float32(0.7622), np.float32(0.5375)] 
2025-01-16 13:18:19.845603: Epoch time: 41.95 s 
2025-01-16 13:18:20.436736:  
2025-01-16 13:18:20.437739: Epoch 162 
2025-01-16 13:18:20.443374: Current learning rate: 0.00391 
2025-01-16 13:19:01.969511: train_loss -0.881 
2025-01-16 13:19:01.969511: val_loss -0.5344 
2025-01-16 13:19:01.976035: Pseudo dice [np.float32(0.7817), np.float32(0.4861)] 
2025-01-16 13:19:01.980548: Epoch time: 41.53 s 
2025-01-16 13:19:02.554534:  
2025-01-16 13:19:02.554534: Epoch 163 
2025-01-16 13:19:02.561213: Current learning rate: 0.00387 
2025-01-16 13:19:43.413302: train_loss -0.8696 
2025-01-16 13:19:43.413811: val_loss -0.5005 
2025-01-16 13:19:43.419995: Pseudo dice [np.float32(0.7669), np.float32(0.4059)] 
2025-01-16 13:19:43.423552: Epoch time: 40.86 s 
2025-01-16 13:19:43.997872:  
2025-01-16 13:19:43.997872: Epoch 164 
2025-01-16 13:19:44.004985: Current learning rate: 0.00383 
2025-01-16 13:20:24.838091: train_loss -0.8682 
2025-01-16 13:20:24.838604: val_loss -0.5207 
2025-01-16 13:20:24.844767: Pseudo dice [np.float32(0.7996), np.float32(0.4254)] 
2025-01-16 13:20:24.848315: Epoch time: 40.84 s 
2025-01-16 13:20:25.410463:  
2025-01-16 13:20:25.411466: Epoch 165 
2025-01-16 13:20:25.417023: Current learning rate: 0.00379 
2025-01-16 13:21:06.276708: train_loss -0.8726 
2025-01-16 13:21:06.277715: val_loss -0.5507 
2025-01-16 13:21:06.283259: Pseudo dice [np.float32(0.7986), np.float32(0.4734)] 
2025-01-16 13:21:06.287275: Epoch time: 40.87 s 
2025-01-16 13:21:07.004497:  
2025-01-16 13:21:07.004999: Epoch 166 
2025-01-16 13:21:07.010014: Current learning rate: 0.00375 
2025-01-16 13:21:47.896858: train_loss -0.8933 
2025-01-16 13:21:47.896858: val_loss -0.553 
2025-01-16 13:21:47.902881: Pseudo dice [np.float32(0.7963), np.float32(0.5014)] 
2025-01-16 13:21:47.906889: Epoch time: 40.89 s 
2025-01-16 13:21:48.472564:  
2025-01-16 13:21:48.472564: Epoch 167 
2025-01-16 13:21:48.477611: Current learning rate: 0.00371 
2025-01-16 13:22:29.318701: train_loss -0.8754 
2025-01-16 13:22:29.319705: val_loss -0.5321 
2025-01-16 13:22:29.327229: Pseudo dice [np.float32(0.7839), np.float32(0.5002)] 
2025-01-16 13:22:29.331240: Epoch time: 40.85 s 
2025-01-16 13:22:29.903994:  
2025-01-16 13:22:29.903994: Epoch 168 
2025-01-16 13:22:29.910100: Current learning rate: 0.00367 
2025-01-16 13:23:10.753739: train_loss -0.8768 
2025-01-16 13:23:10.754744: val_loss -0.5017 
2025-01-16 13:23:10.760790: Pseudo dice [np.float32(0.7784), np.float32(0.396)] 
2025-01-16 13:23:10.764847: Epoch time: 40.85 s 
2025-01-16 13:23:11.335147:  
2025-01-16 13:23:11.336150: Epoch 169 
2025-01-16 13:23:11.342246: Current learning rate: 0.00363 
2025-01-16 13:23:52.177918: train_loss -0.887 
2025-01-16 13:23:52.177918: val_loss -0.5315 
2025-01-16 13:23:52.185552: Pseudo dice [np.float32(0.7831), np.float32(0.425)] 
2025-01-16 13:23:52.190168: Epoch time: 40.84 s 
2025-01-16 13:23:52.758219:  
2025-01-16 13:23:52.758219: Epoch 170 
2025-01-16 13:23:52.763234: Current learning rate: 0.00359 
2025-01-16 13:24:33.582697: train_loss -0.876 
2025-01-16 13:24:33.583199: val_loss -0.5392 
2025-01-16 13:24:33.589242: Pseudo dice [np.float32(0.7881), np.float32(0.5193)] 
2025-01-16 13:24:33.593290: Epoch time: 40.83 s 
2025-01-16 13:24:34.164968:  
2025-01-16 13:24:34.164968: Epoch 171 
2025-01-16 13:24:34.171095: Current learning rate: 0.00355 
2025-01-16 13:25:15.017461: train_loss -0.8931 
2025-01-16 13:25:15.017963: val_loss -0.512 
2025-01-16 13:25:15.024596: Pseudo dice [np.float32(0.7835), np.float32(0.3327)] 
2025-01-16 13:25:15.027657: Epoch time: 40.85 s 
2025-01-16 13:25:15.596969:  
2025-01-16 13:25:15.596969: Epoch 172 
2025-01-16 13:25:15.601482: Current learning rate: 0.00351 
2025-01-16 13:25:56.445034: train_loss -0.8892 
2025-01-16 13:25:56.445536: val_loss -0.5167 
2025-01-16 13:25:56.451157: Pseudo dice [np.float32(0.7841), np.float32(0.3936)] 
2025-01-16 13:25:56.455185: Epoch time: 40.85 s 
2025-01-16 13:25:57.026237:  
2025-01-16 13:25:57.027235: Epoch 173 
2025-01-16 13:25:57.032844: Current learning rate: 0.00346 
2025-01-16 13:26:37.918766: train_loss -0.8878 
2025-01-16 13:26:37.919272: val_loss -0.4774 
2025-01-16 13:26:37.925447: Pseudo dice [np.float32(0.7737), np.float32(0.3243)] 
2025-01-16 13:26:37.929487: Epoch time: 40.89 s 
2025-01-16 13:26:38.646336:  
2025-01-16 13:26:38.646336: Epoch 174 
2025-01-16 13:26:38.652354: Current learning rate: 0.00342 
2025-01-16 13:27:19.511939: train_loss -0.8825 
2025-01-16 13:27:19.512453: val_loss -0.5148 
2025-01-16 13:27:19.519177: Pseudo dice [np.float32(0.776), np.float32(0.4969)] 
2025-01-16 13:27:19.521768: Epoch time: 40.87 s 
2025-01-16 13:27:20.093823:  
2025-01-16 13:27:20.094327: Epoch 175 
2025-01-16 13:27:20.099342: Current learning rate: 0.00338 
2025-01-16 13:28:00.959505: train_loss -0.8878 
2025-01-16 13:28:00.961010: val_loss -0.5271 
2025-01-16 13:28:00.966560: Pseudo dice [np.float32(0.7803), np.float32(0.3771)] 
2025-01-16 13:28:00.971581: Epoch time: 40.87 s 
2025-01-16 13:28:01.545157:  
2025-01-16 13:28:01.545157: Epoch 176 
2025-01-16 13:28:01.551177: Current learning rate: 0.00334 
2025-01-16 13:28:42.400820: train_loss -0.887 
2025-01-16 13:28:42.401824: val_loss -0.5381 
2025-01-16 13:28:42.408464: Pseudo dice [np.float32(0.7952), np.float32(0.3966)] 
2025-01-16 13:28:42.412539: Epoch time: 40.86 s 
2025-01-16 13:28:42.986361:  
2025-01-16 13:28:42.986361: Epoch 177 
2025-01-16 13:28:42.992939: Current learning rate: 0.0033 
2025-01-16 13:29:23.838316: train_loss -0.8829 
2025-01-16 13:29:23.839319: val_loss -0.5175 
2025-01-16 13:29:23.845378: Pseudo dice [np.float32(0.781), np.float32(0.4221)] 
2025-01-16 13:29:23.848413: Epoch time: 40.85 s 
2025-01-16 13:29:24.422294:  
2025-01-16 13:29:24.423299: Epoch 178 
2025-01-16 13:29:24.429347: Current learning rate: 0.00326 
2025-01-16 13:30:05.284447: train_loss -0.8738 
2025-01-16 13:30:05.285447: val_loss -0.5227 
2025-01-16 13:30:05.292033: Pseudo dice [np.float32(0.7725), np.float32(0.5227)] 
2025-01-16 13:30:05.295053: Epoch time: 40.86 s 
2025-01-16 13:30:05.868014:  
2025-01-16 13:30:05.868014: Epoch 179 
2025-01-16 13:30:05.874151: Current learning rate: 0.00322 
2025-01-16 13:30:46.745173: train_loss -0.8895 
2025-01-16 13:30:46.745687: val_loss -0.5161 
2025-01-16 13:30:46.751785: Pseudo dice [np.float32(0.7741), np.float32(0.3844)] 
2025-01-16 13:30:46.755501: Epoch time: 40.88 s 
2025-01-16 13:30:47.334890:  
2025-01-16 13:30:47.334890: Epoch 180 
2025-01-16 13:30:47.340426: Current learning rate: 0.00318 
2025-01-16 13:31:28.213516: train_loss -0.8981 
2025-01-16 13:31:28.215025: val_loss -0.5906 
2025-01-16 13:31:28.221721: Pseudo dice [np.float32(0.7927), np.float32(0.5831)] 
2025-01-16 13:31:28.225782: Epoch time: 40.88 s 
2025-01-16 13:31:28.799551:  
2025-01-16 13:31:28.799551: Epoch 181 
2025-01-16 13:31:28.805655: Current learning rate: 0.00314 
2025-01-16 13:32:09.673445: train_loss -0.9027 
2025-01-16 13:32:09.673445: val_loss -0.516 
2025-01-16 13:32:09.680228: Pseudo dice [np.float32(0.797), np.float32(0.4136)] 
2025-01-16 13:32:09.683827: Epoch time: 40.87 s 
2025-01-16 13:32:10.412905:  
2025-01-16 13:32:10.412905: Epoch 182 
2025-01-16 13:32:10.419509: Current learning rate: 0.0031 
2025-01-16 13:32:51.267618: train_loss -0.8927 
2025-01-16 13:32:51.267618: val_loss -0.5365 
2025-01-16 13:32:51.274683: Pseudo dice [np.float32(0.7729), np.float32(0.3982)] 
2025-01-16 13:32:51.278722: Epoch time: 40.86 s 
2025-01-16 13:32:51.855459:  
2025-01-16 13:32:51.855459: Epoch 183 
2025-01-16 13:32:51.861511: Current learning rate: 0.00306 
2025-01-16 13:33:32.713820: train_loss -0.8943 
2025-01-16 13:33:32.714820: val_loss -0.5419 
2025-01-16 13:33:32.722433: Pseudo dice [np.float32(0.793), np.float32(0.4106)] 
2025-01-16 13:33:32.727964: Epoch time: 40.86 s 
2025-01-16 13:33:33.300345:  
2025-01-16 13:33:33.300345: Epoch 184 
2025-01-16 13:33:33.306401: Current learning rate: 0.00302 
2025-01-16 13:34:14.161423: train_loss -0.9031 
2025-01-16 13:34:14.161423: val_loss -0.5287 
2025-01-16 13:34:14.167445: Pseudo dice [np.float32(0.7874), np.float32(0.5148)] 
2025-01-16 13:34:14.171458: Epoch time: 40.86 s 
2025-01-16 13:34:14.747226:  
2025-01-16 13:34:14.748226: Epoch 185 
2025-01-16 13:34:14.753747: Current learning rate: 0.00297 
2025-01-16 13:34:55.600774: train_loss -0.8988 
2025-01-16 13:34:55.600774: val_loss -0.5045 
2025-01-16 13:34:55.608820: Pseudo dice [np.float32(0.7614), np.float32(0.5013)] 
2025-01-16 13:34:55.612832: Epoch time: 40.85 s 
2025-01-16 13:34:56.181331:  
2025-01-16 13:34:56.181331: Epoch 186 
2025-01-16 13:34:56.187929: Current learning rate: 0.00293 
2025-01-16 13:35:37.035557: train_loss -0.897 
2025-01-16 13:35:37.036114: val_loss -0.4852 
2025-01-16 13:35:37.043241: Pseudo dice [np.float32(0.7693), np.float32(0.4473)] 
2025-01-16 13:35:37.046869: Epoch time: 40.86 s 
2025-01-16 13:35:37.619002:  
2025-01-16 13:35:37.619002: Epoch 187 
2025-01-16 13:35:37.625104: Current learning rate: 0.00289 
2025-01-16 13:36:18.468101: train_loss -0.898 
2025-01-16 13:36:18.468616: val_loss -0.5517 
2025-01-16 13:36:18.474188: Pseudo dice [np.float32(0.7973), np.float32(0.5357)] 
2025-01-16 13:36:18.478195: Epoch time: 40.85 s 
2025-01-16 13:36:19.047580:  
2025-01-16 13:36:19.047580: Epoch 188 
2025-01-16 13:36:19.053632: Current learning rate: 0.00285 
2025-01-16 13:36:59.886973: train_loss -0.8961 
2025-01-16 13:36:59.886973: val_loss -0.5448 
2025-01-16 13:36:59.893635: Pseudo dice [np.float32(0.7723), np.float32(0.4466)] 
2025-01-16 13:36:59.897210: Epoch time: 40.84 s 
2025-01-16 13:37:00.473703:  
2025-01-16 13:37:00.473703: Epoch 189 
2025-01-16 13:37:00.479851: Current learning rate: 0.00281 
2025-01-16 13:37:41.325890: train_loss -0.9024 
2025-01-16 13:37:41.326893: val_loss -0.5078 
2025-01-16 13:37:41.333415: Pseudo dice [np.float32(0.7977), np.float32(0.4046)] 
2025-01-16 13:37:41.336927: Epoch time: 40.85 s 
2025-01-16 13:37:42.062543:  
2025-01-16 13:37:42.063547: Epoch 190 
2025-01-16 13:37:42.068176: Current learning rate: 0.00277 
2025-01-16 13:38:22.896456: train_loss -0.8996 
2025-01-16 13:38:22.896456: val_loss -0.4838 
2025-01-16 13:38:22.902980: Pseudo dice [np.float32(0.7893), np.float32(0.3126)] 
2025-01-16 13:38:22.906492: Epoch time: 40.83 s 
2025-01-16 13:38:23.478641:  
2025-01-16 13:38:23.478641: Epoch 191 
2025-01-16 13:38:23.483656: Current learning rate: 0.00273 
2025-01-16 13:39:04.328566: train_loss -0.888 
2025-01-16 13:39:04.329569: val_loss -0.5311 
2025-01-16 13:39:04.335696: Pseudo dice [np.float32(0.7954), np.float32(0.4133)] 
2025-01-16 13:39:04.339836: Epoch time: 40.85 s 
2025-01-16 13:39:04.918417:  
2025-01-16 13:39:04.919420: Epoch 192 
2025-01-16 13:39:04.925466: Current learning rate: 0.00268 
2025-01-16 13:39:45.755141: train_loss -0.8965 
2025-01-16 13:39:45.755141: val_loss -0.5426 
2025-01-16 13:39:45.762805: Pseudo dice [np.float32(0.7895), np.float32(0.4732)] 
2025-01-16 13:39:45.766869: Epoch time: 40.84 s 
2025-01-16 13:39:46.341655:  
2025-01-16 13:39:46.342661: Epoch 193 
2025-01-16 13:39:46.347230: Current learning rate: 0.00264 
2025-01-16 13:40:27.190516: train_loss -0.9063 
2025-01-16 13:40:27.191031: val_loss -0.5727 
2025-01-16 13:40:27.196102: Pseudo dice [np.float32(0.797), np.float32(0.5273)] 
2025-01-16 13:40:27.201194: Epoch time: 40.85 s 
2025-01-16 13:40:27.785238:  
2025-01-16 13:40:27.785238: Epoch 194 
2025-01-16 13:40:27.792263: Current learning rate: 0.0026 
2025-01-16 13:41:08.641384: train_loss -0.9009 
2025-01-16 13:41:08.641384: val_loss -0.5235 
2025-01-16 13:41:08.646943: Pseudo dice [np.float32(0.8033), np.float32(0.3343)] 
2025-01-16 13:41:08.651475: Epoch time: 40.86 s 
2025-01-16 13:41:09.233773:  
2025-01-16 13:41:09.234286: Epoch 195 
2025-01-16 13:41:09.239385: Current learning rate: 0.00256 
2025-01-16 13:41:50.091528: train_loss -0.8902 
2025-01-16 13:41:50.091528: val_loss -0.4965 
2025-01-16 13:41:50.099906: Pseudo dice [np.float32(0.7718), np.float32(0.3963)] 
2025-01-16 13:41:50.103914: Epoch time: 40.86 s 
2025-01-16 13:41:50.686696:  
2025-01-16 13:41:50.687699: Epoch 196 
2025-01-16 13:41:50.692316: Current learning rate: 0.00252 
2025-01-16 13:42:31.537071: train_loss -0.8953 
2025-01-16 13:42:31.537071: val_loss -0.5448 
2025-01-16 13:42:31.544685: Pseudo dice [np.float32(0.7753), np.float32(0.4695)] 
2025-01-16 13:42:31.548197: Epoch time: 40.85 s 
2025-01-16 13:42:32.126266:  
2025-01-16 13:42:32.126266: Epoch 197 
2025-01-16 13:42:32.132850: Current learning rate: 0.00248 
2025-01-16 13:43:12.978991: train_loss -0.8847 
2025-01-16 13:43:12.979493: val_loss -0.5344 
2025-01-16 13:43:12.986081: Pseudo dice [np.float32(0.7765), np.float32(0.4172)] 
2025-01-16 13:43:12.989709: Epoch time: 40.85 s 
2025-01-16 13:43:13.571024:  
2025-01-16 13:43:13.571024: Epoch 198 
2025-01-16 13:43:13.577119: Current learning rate: 0.00243 
2025-01-16 13:43:54.403450: train_loss -0.8975 
2025-01-16 13:43:54.403450: val_loss -0.5003 
2025-01-16 13:43:54.410509: Pseudo dice [np.float32(0.7833), np.float32(0.3936)] 
2025-01-16 13:43:54.413522: Epoch time: 40.83 s 
2025-01-16 13:43:54.998177:  
2025-01-16 13:43:54.999177: Epoch 199 
2025-01-16 13:43:55.004813: Current learning rate: 0.00239 
2025-01-16 13:44:35.832967: train_loss -0.8994 
2025-01-16 13:44:35.833471: val_loss -0.5197 
2025-01-16 13:44:35.839556: Pseudo dice [np.float32(0.7948), np.float32(0.4636)] 
2025-01-16 13:44:35.844092: Epoch time: 40.83 s 
2025-01-16 13:44:36.676536:  
2025-01-16 13:44:36.677540: Epoch 200 
2025-01-16 13:44:36.683221: Current learning rate: 0.00235 
2025-01-16 13:45:17.507218: train_loss -0.9052 
2025-01-16 13:45:17.507218: val_loss -0.5244 
2025-01-16 13:45:17.514373: Pseudo dice [np.float32(0.7953), np.float32(0.3868)] 
2025-01-16 13:45:17.518401: Epoch time: 40.83 s 
2025-01-16 13:45:18.111344:  
2025-01-16 13:45:18.112344: Epoch 201 
2025-01-16 13:45:18.117924: Current learning rate: 0.00231 
2025-01-16 13:45:58.932849: train_loss -0.9013 
2025-01-16 13:45:58.932849: val_loss -0.5021 
2025-01-16 13:45:58.939984: Pseudo dice [np.float32(0.8084), np.float32(0.3009)] 
2025-01-16 13:45:58.943558: Epoch time: 40.82 s 
2025-01-16 13:45:59.528705:  
2025-01-16 13:45:59.529706: Epoch 202 
2025-01-16 13:45:59.534775: Current learning rate: 0.00226 
2025-01-16 13:46:40.337539: train_loss -0.9025 
2025-01-16 13:46:40.338043: val_loss -0.467 
2025-01-16 13:46:40.345118: Pseudo dice [np.float32(0.7775), np.float32(0.3894)] 
2025-01-16 13:46:40.348687: Epoch time: 40.81 s 
2025-01-16 13:46:40.940229:  
2025-01-16 13:46:40.940229: Epoch 203 
2025-01-16 13:46:40.945779: Current learning rate: 0.00222 
2025-01-16 13:47:21.793719: train_loss -0.9079 
2025-01-16 13:47:21.793719: val_loss -0.4837 
2025-01-16 13:47:21.800792: Pseudo dice [np.float32(0.779), np.float32(0.3321)] 
2025-01-16 13:47:21.805826: Epoch time: 40.85 s 
2025-01-16 13:47:22.389419:  
2025-01-16 13:47:22.389419: Epoch 204 
2025-01-16 13:47:22.395437: Current learning rate: 0.00218 
2025-01-16 13:48:03.227943: train_loss -0.9003 
2025-01-16 13:48:03.228452: val_loss -0.5302 
2025-01-16 13:48:03.234081: Pseudo dice [np.float32(0.8006), np.float32(0.4522)] 
2025-01-16 13:48:03.237147: Epoch time: 40.84 s 
2025-01-16 13:48:03.967602:  
2025-01-16 13:48:03.967602: Epoch 205 
2025-01-16 13:48:03.974197: Current learning rate: 0.00214 
2025-01-16 13:48:44.798011: train_loss -0.9107 
2025-01-16 13:48:44.798011: val_loss -0.5247 
2025-01-16 13:48:44.804096: Pseudo dice [np.float32(0.7759), np.float32(0.4759)] 
2025-01-16 13:48:44.807647: Epoch time: 40.83 s 
2025-01-16 13:48:45.369299:  
2025-01-16 13:48:45.369802: Epoch 206 
2025-01-16 13:48:45.379827: Current learning rate: 0.00209 
2025-01-16 13:49:26.208216: train_loss -0.9028 
2025-01-16 13:49:26.209216: val_loss -0.5316 
2025-01-16 13:49:26.214734: Pseudo dice [np.float32(0.7816), np.float32(0.3754)] 
2025-01-16 13:49:26.218243: Epoch time: 40.84 s 
2025-01-16 13:49:26.768843:  
2025-01-16 13:49:26.769848: Epoch 207 
2025-01-16 13:49:26.775970: Current learning rate: 0.00205 
2025-01-16 13:50:07.628109: train_loss -0.9076 
2025-01-16 13:50:07.628109: val_loss -0.5319 
2025-01-16 13:50:07.634757: Pseudo dice [np.float32(0.7974), np.float32(0.4509)] 
2025-01-16 13:50:07.638770: Epoch time: 40.86 s 
2025-01-16 13:50:08.188133:  
2025-01-16 13:50:08.189644: Epoch 208 
2025-01-16 13:50:08.195298: Current learning rate: 0.00201 
2025-01-16 13:50:49.038459: train_loss -0.9115 
2025-01-16 13:50:49.038964: val_loss -0.5432 
2025-01-16 13:50:49.045145: Pseudo dice [np.float32(0.784), np.float32(0.5598)] 
2025-01-16 13:50:49.048697: Epoch time: 40.85 s 
2025-01-16 13:50:49.607754:  
2025-01-16 13:50:49.607754: Epoch 209 
2025-01-16 13:50:49.613829: Current learning rate: 0.00196 
2025-01-16 13:51:30.449631: train_loss -0.9069 
2025-01-16 13:51:30.450143: val_loss -0.5124 
2025-01-16 13:51:30.457296: Pseudo dice [np.float32(0.7912), np.float32(0.3971)] 
2025-01-16 13:51:30.461333: Epoch time: 40.84 s 
2025-01-16 13:51:31.010720:  
2025-01-16 13:51:31.010720: Epoch 210 
2025-01-16 13:51:31.016798: Current learning rate: 0.00192 
2025-01-16 13:52:11.841075: train_loss -0.901 
2025-01-16 13:52:11.841584: val_loss -0.5531 
2025-01-16 13:52:11.847251: Pseudo dice [np.float32(0.7962), np.float32(0.512)] 
2025-01-16 13:52:11.850805: Epoch time: 40.83 s 
2025-01-16 13:52:12.414630:  
2025-01-16 13:52:12.414630: Epoch 211 
2025-01-16 13:52:12.420701: Current learning rate: 0.00188 
2025-01-16 13:52:53.255136: train_loss -0.9059 
2025-01-16 13:52:53.256141: val_loss -0.4966 
2025-01-16 13:52:53.262661: Pseudo dice [np.float32(0.7861), np.float32(0.4009)] 
2025-01-16 13:52:53.267170: Epoch time: 40.84 s 
2025-01-16 13:52:53.829731:  
2025-01-16 13:52:53.830233: Epoch 212 
2025-01-16 13:52:53.835885: Current learning rate: 0.00184 
2025-01-16 13:53:34.655379: train_loss -0.9154 
2025-01-16 13:53:34.655379: val_loss -0.5079 
2025-01-16 13:53:34.661984: Pseudo dice [np.float32(0.7854), np.float32(0.3041)] 
2025-01-16 13:53:34.667032: Epoch time: 40.83 s 
2025-01-16 13:53:35.368495:  
2025-01-16 13:53:35.369499: Epoch 213 
2025-01-16 13:53:35.374053: Current learning rate: 0.00179 
2025-01-16 13:54:16.199046: train_loss -0.9047 
2025-01-16 13:54:16.199550: val_loss -0.5241 
2025-01-16 13:54:16.205698: Pseudo dice [np.float32(0.7829), np.float32(0.3982)] 
2025-01-16 13:54:16.209204: Epoch time: 40.83 s 
2025-01-16 13:54:16.765401:  
2025-01-16 13:54:16.766400: Epoch 214 
2025-01-16 13:54:16.772037: Current learning rate: 0.00175 
2025-01-16 13:54:57.610923: train_loss -0.9006 
2025-01-16 13:54:57.611928: val_loss -0.5319 
2025-01-16 13:54:57.618546: Pseudo dice [np.float32(0.7713), np.float32(0.4414)] 
2025-01-16 13:54:57.622081: Epoch time: 40.85 s 
2025-01-16 13:54:58.166691:  
2025-01-16 13:54:58.167695: Epoch 215 
2025-01-16 13:54:58.173270: Current learning rate: 0.0017 
2025-01-16 13:55:39.024099: train_loss -0.9092 
2025-01-16 13:55:39.025103: val_loss -0.4851 
2025-01-16 13:55:39.033271: Pseudo dice [np.float32(0.7485), np.float32(0.3702)] 
2025-01-16 13:55:39.036823: Epoch time: 40.86 s 
2025-01-16 13:55:39.580773:  
2025-01-16 13:55:39.580773: Epoch 216 
2025-01-16 13:55:39.587790: Current learning rate: 0.00166 
2025-01-16 13:56:20.411254: train_loss -0.9057 
2025-01-16 13:56:20.412255: val_loss -0.5551 
2025-01-16 13:56:20.419344: Pseudo dice [np.float32(0.7921), np.float32(0.4853)] 
2025-01-16 13:56:20.422901: Epoch time: 40.83 s 
2025-01-16 13:56:20.977928:  
2025-01-16 13:56:20.977928: Epoch 217 
2025-01-16 13:56:20.982989: Current learning rate: 0.00162 
2025-01-16 13:57:01.815313: train_loss -0.911 
2025-01-16 13:57:01.815313: val_loss -0.5334 
2025-01-16 13:57:01.821334: Pseudo dice [np.float32(0.7959), np.float32(0.4677)] 
2025-01-16 13:57:01.825343: Epoch time: 40.84 s 
2025-01-16 13:57:02.368349:  
2025-01-16 13:57:02.368851: Epoch 218 
2025-01-16 13:57:02.374868: Current learning rate: 0.00157 
2025-01-16 13:57:43.215711: train_loss -0.9132 
2025-01-16 13:57:43.216715: val_loss -0.5249 
2025-01-16 13:57:43.222806: Pseudo dice [np.float32(0.8006), np.float32(0.3511)] 
2025-01-16 13:57:43.225845: Epoch time: 40.85 s 
2025-01-16 13:57:43.782014:  
2025-01-16 13:57:43.782014: Epoch 219 
2025-01-16 13:57:43.788094: Current learning rate: 0.00153 
2025-01-16 13:58:24.613123: train_loss -0.9143 
2025-01-16 13:58:24.613123: val_loss -0.5227 
2025-01-16 13:58:24.619642: Pseudo dice [np.float32(0.7833), np.float32(0.5228)] 
2025-01-16 13:58:24.624211: Epoch time: 40.83 s 
2025-01-16 13:58:25.175315:  
2025-01-16 13:58:25.175315: Epoch 220 
2025-01-16 13:58:25.181417: Current learning rate: 0.00148 
2025-01-16 13:59:06.016739: train_loss -0.9011 
2025-01-16 13:59:06.017743: val_loss -0.5033 
2025-01-16 13:59:06.024261: Pseudo dice [np.float32(0.7675), np.float32(0.3774)] 
2025-01-16 13:59:06.027770: Epoch time: 40.84 s 
2025-01-16 13:59:06.576616:  
2025-01-16 13:59:06.577621: Epoch 221 
2025-01-16 13:59:06.582167: Current learning rate: 0.00144 
2025-01-16 13:59:47.432165: train_loss -0.9193 
2025-01-16 13:59:47.433682: val_loss -0.5107 
2025-01-16 13:59:47.440286: Pseudo dice [np.float32(0.7762), np.float32(0.3679)] 
2025-01-16 13:59:47.443843: Epoch time: 40.86 s 
2025-01-16 13:59:48.151521:  
2025-01-16 13:59:48.152024: Epoch 222 
2025-01-16 13:59:48.158127: Current learning rate: 0.00139 
2025-01-16 14:00:28.984835: train_loss -0.9067 
2025-01-16 14:00:28.985839: val_loss -0.5643 
2025-01-16 14:00:28.993054: Pseudo dice [np.float32(0.7997), np.float32(0.4315)] 
2025-01-16 14:00:28.997639: Epoch time: 40.83 s 
2025-01-16 14:00:29.553476:  
2025-01-16 14:00:29.553476: Epoch 223 
2025-01-16 14:00:29.559497: Current learning rate: 0.00135 
2025-01-16 14:01:10.396993: train_loss -0.9016 
2025-01-16 14:01:10.396993: val_loss -0.5419 
2025-01-16 14:01:10.404051: Pseudo dice [np.float32(0.794), np.float32(0.4557)] 
2025-01-16 14:01:10.407117: Epoch time: 40.85 s 
2025-01-16 14:01:10.953969:  
2025-01-16 14:01:10.953969: Epoch 224 
2025-01-16 14:01:10.958982: Current learning rate: 0.0013 
2025-01-16 14:01:51.792366: train_loss -0.9174 
2025-01-16 14:01:51.793367: val_loss -0.5192 
2025-01-16 14:01:51.799937: Pseudo dice [np.float32(0.7692), np.float32(0.4706)] 
2025-01-16 14:01:51.803947: Epoch time: 40.84 s 
2025-01-16 14:01:52.358723:  
2025-01-16 14:01:52.359226: Epoch 225 
2025-01-16 14:01:52.365244: Current learning rate: 0.00126 
2025-01-16 14:02:33.188579: train_loss -0.9175 
2025-01-16 14:02:33.190086: val_loss -0.5301 
2025-01-16 14:02:33.197374: Pseudo dice [np.float32(0.7884), np.float32(0.3828)] 
2025-01-16 14:02:33.200927: Epoch time: 40.83 s 
2025-01-16 14:02:33.740861:  
2025-01-16 14:02:33.741366: Epoch 226 
2025-01-16 14:02:33.747382: Current learning rate: 0.00121 
2025-01-16 14:03:14.559708: train_loss -0.9126 
2025-01-16 14:03:14.560714: val_loss -0.5039 
2025-01-16 14:03:14.566811: Pseudo dice [np.float32(0.7793), np.float32(0.4426)] 
2025-01-16 14:03:14.570375: Epoch time: 40.82 s 
2025-01-16 14:03:15.121536:  
2025-01-16 14:03:15.121536: Epoch 227 
2025-01-16 14:03:15.127552: Current learning rate: 0.00117 
2025-01-16 14:03:55.954045: train_loss -0.9216 
2025-01-16 14:03:55.954045: val_loss -0.5719 
2025-01-16 14:03:55.961564: Pseudo dice [np.float32(0.7798), np.float32(0.5632)] 
2025-01-16 14:03:55.965074: Epoch time: 40.83 s 
2025-01-16 14:03:56.520975:  
2025-01-16 14:03:56.521485: Epoch 228 
2025-01-16 14:03:56.527560: Current learning rate: 0.00112 
2025-01-16 14:04:37.362924: train_loss -0.9146 
2025-01-16 14:04:37.363944: val_loss -0.5561 
2025-01-16 14:04:37.371055: Pseudo dice [np.float32(0.7934), np.float32(0.5529)] 
2025-01-16 14:04:37.375116: Epoch time: 40.84 s 
2025-01-16 14:04:37.921726:  
2025-01-16 14:04:37.922725: Epoch 229 
2025-01-16 14:04:37.928314: Current learning rate: 0.00108 
2025-01-16 14:05:18.734781: train_loss -0.9096 
2025-01-16 14:05:18.735285: val_loss -0.5643 
2025-01-16 14:05:18.741390: Pseudo dice [np.float32(0.8046), np.float32(0.4514)] 
2025-01-16 14:05:18.744903: Epoch time: 40.81 s 
2025-01-16 14:05:19.300365:  
2025-01-16 14:05:19.300365: Epoch 230 
2025-01-16 14:05:19.306917: Current learning rate: 0.00103 
2025-01-16 14:06:00.116881: train_loss -0.91 
2025-01-16 14:06:00.116881: val_loss -0.5194 
2025-01-16 14:06:00.123917: Pseudo dice [np.float32(0.7802), np.float32(0.5279)] 
2025-01-16 14:06:00.127956: Epoch time: 40.82 s 
2025-01-16 14:06:00.836275:  
2025-01-16 14:06:00.836275: Epoch 231 
2025-01-16 14:06:00.842290: Current learning rate: 0.00098 
2025-01-16 14:06:41.664187: train_loss -0.9185 
2025-01-16 14:06:41.664712: val_loss -0.5427 
2025-01-16 14:06:41.670794: Pseudo dice [np.float32(0.7873), np.float32(0.4036)] 
2025-01-16 14:06:41.674361: Epoch time: 40.83 s 
2025-01-16 14:06:42.214813:  
2025-01-16 14:06:42.215820: Epoch 232 
2025-01-16 14:06:42.221385: Current learning rate: 0.00094 
2025-01-16 14:07:23.024137: train_loss -0.9211 
2025-01-16 14:07:23.024650: val_loss -0.469 
2025-01-16 14:07:23.029724: Pseudo dice [np.float32(0.7723), np.float32(0.3282)] 
2025-01-16 14:07:23.034800: Epoch time: 40.81 s 
2025-01-16 14:07:23.587605:  
2025-01-16 14:07:23.588109: Epoch 233 
2025-01-16 14:07:23.593121: Current learning rate: 0.00089 
2025-01-16 14:08:04.402592: train_loss -0.92 
2025-01-16 14:08:04.402592: val_loss -0.5064 
2025-01-16 14:08:04.409235: Pseudo dice [np.float32(0.7913), np.float32(0.4823)] 
2025-01-16 14:08:04.413364: Epoch time: 40.82 s 
2025-01-16 14:08:04.962505:  
2025-01-16 14:08:04.962505: Epoch 234 
2025-01-16 14:08:04.968594: Current learning rate: 0.00084 
2025-01-16 14:08:45.787240: train_loss -0.9183 
2025-01-16 14:08:45.787770: val_loss -0.5195 
2025-01-16 14:08:45.796000: Pseudo dice [np.float32(0.7865), np.float32(0.3684)] 
2025-01-16 14:08:45.800123: Epoch time: 40.83 s 
2025-01-16 14:08:46.346798:  
2025-01-16 14:08:46.346798: Epoch 235 
2025-01-16 14:08:46.352849: Current learning rate: 0.00079 
2025-01-16 14:09:27.199368: train_loss -0.9131 
2025-01-16 14:09:27.200376: val_loss -0.4983 
2025-01-16 14:09:27.206406: Pseudo dice [np.float32(0.7796), np.float32(0.4187)] 
2025-01-16 14:09:27.210432: Epoch time: 40.85 s 
2025-01-16 14:09:27.769918:  
2025-01-16 14:09:27.769918: Epoch 236 
2025-01-16 14:09:27.776038: Current learning rate: 0.00075 
2025-01-16 14:10:08.610806: train_loss -0.9189 
2025-01-16 14:10:08.611329: val_loss -0.533 
2025-01-16 14:10:08.616408: Pseudo dice [np.float32(0.7832), np.float32(0.4458)] 
2025-01-16 14:10:08.620971: Epoch time: 40.84 s 
2025-01-16 14:10:09.164214:  
2025-01-16 14:10:09.164214: Epoch 237 
2025-01-16 14:10:09.173890: Current learning rate: 0.0007 
2025-01-16 14:10:50.002562: train_loss -0.9148 
2025-01-16 14:10:50.002562: val_loss -0.5134 
2025-01-16 14:10:50.009725: Pseudo dice [np.float32(0.7968), np.float32(0.3346)] 
2025-01-16 14:10:50.013788: Epoch time: 40.84 s 
2025-01-16 14:10:50.557622:  
2025-01-16 14:10:50.558135: Epoch 238 
2025-01-16 14:10:50.563149: Current learning rate: 0.00065 
2025-01-16 14:11:31.397459: train_loss -0.9132 
2025-01-16 14:11:31.398560: val_loss -0.5069 
2025-01-16 14:11:31.405709: Pseudo dice [np.float32(0.7655), np.float32(0.4535)] 
2025-01-16 14:11:31.409244: Epoch time: 40.84 s 
2025-01-16 14:11:31.963278:  
2025-01-16 14:11:31.964282: Epoch 239 
2025-01-16 14:11:31.970842: Current learning rate: 0.0006 
2025-01-16 14:12:12.794460: train_loss -0.9088 
2025-01-16 14:12:12.794460: val_loss -0.5381 
2025-01-16 14:12:12.801607: Pseudo dice [np.float32(0.7907), np.float32(0.4849)] 
2025-01-16 14:12:12.805621: Epoch time: 40.83 s 
2025-01-16 14:12:13.509195:  
2025-01-16 14:12:13.510201: Epoch 240 
2025-01-16 14:12:13.516289: Current learning rate: 0.00055 
2025-01-16 14:12:54.344349: train_loss -0.9095 
2025-01-16 14:12:54.344861: val_loss -0.5638 
2025-01-16 14:12:54.352089: Pseudo dice [np.float32(0.8029), np.float32(0.552)] 
2025-01-16 14:12:54.355648: Epoch time: 40.84 s 
2025-01-16 14:12:54.923485:  
2025-01-16 14:12:54.924485: Epoch 241 
2025-01-16 14:12:54.930079: Current learning rate: 0.0005 
2025-01-16 14:13:35.754400: train_loss -0.9175 
2025-01-16 14:13:35.754400: val_loss -0.5016 
2025-01-16 14:13:35.761920: Pseudo dice [np.float32(0.7748), np.float32(0.4649)] 
2025-01-16 14:13:35.765429: Epoch time: 40.83 s 
2025-01-16 14:13:36.332540:  
2025-01-16 14:13:36.333042: Epoch 242 
2025-01-16 14:13:36.338739: Current learning rate: 0.00045 
2025-01-16 14:14:17.157975: train_loss -0.9136 
2025-01-16 14:14:17.159014: val_loss -0.5502 
2025-01-16 14:14:17.164114: Pseudo dice [np.float32(0.7859), np.float32(0.4572)] 
2025-01-16 14:14:17.167215: Epoch time: 40.83 s 
2025-01-16 14:14:17.721466:  
2025-01-16 14:14:17.722467: Epoch 243 
2025-01-16 14:14:17.728059: Current learning rate: 0.0004 
2025-01-16 14:14:58.553437: train_loss -0.9242 
2025-01-16 14:14:58.554442: val_loss -0.5125 
2025-01-16 14:14:58.561002: Pseudo dice [np.float32(0.7729), np.float32(0.4707)] 
2025-01-16 14:14:58.565574: Epoch time: 40.83 s 
2025-01-16 14:14:59.142348:  
2025-01-16 14:14:59.143352: Epoch 244 
2025-01-16 14:14:59.147913: Current learning rate: 0.00035 
2025-01-16 14:15:39.969832: train_loss -0.9299 
2025-01-16 14:15:39.970840: val_loss -0.5062 
2025-01-16 14:15:39.976849: Pseudo dice [np.float32(0.7915), np.float32(0.4611)] 
2025-01-16 14:15:39.979862: Epoch time: 40.83 s 
2025-01-16 14:15:40.543839:  
2025-01-16 14:15:40.544843: Epoch 245 
2025-01-16 14:15:40.550408: Current learning rate: 0.0003 
2025-01-16 14:16:21.368031: train_loss -0.9215 
2025-01-16 14:16:21.369599: val_loss -0.5448 
2025-01-16 14:16:21.375196: Pseudo dice [np.float32(0.8027), np.float32(0.3677)] 
2025-01-16 14:16:21.378738: Epoch time: 40.82 s 
2025-01-16 14:16:21.934904:  
2025-01-16 14:16:21.934904: Epoch 246 
2025-01-16 14:16:21.941987: Current learning rate: 0.00024 
2025-01-16 14:17:02.775731: train_loss -0.9227 
2025-01-16 14:17:02.775731: val_loss -0.4784 
2025-01-16 14:17:02.782836: Pseudo dice [np.float32(0.7818), np.float32(0.3027)] 
2025-01-16 14:17:02.786394: Epoch time: 40.84 s 
2025-01-16 14:17:03.353452:  
2025-01-16 14:17:03.354452: Epoch 247 
2025-01-16 14:17:03.360042: Current learning rate: 0.00019 
2025-01-16 14:17:44.190387: train_loss -0.913 
2025-01-16 14:17:44.190902: val_loss -0.5276 
2025-01-16 14:17:44.196999: Pseudo dice [np.float32(0.7836), np.float32(0.393)] 
2025-01-16 14:17:44.201077: Epoch time: 40.84 s 
2025-01-16 14:17:44.912549:  
2025-01-16 14:17:44.912549: Epoch 248 
2025-01-16 14:17:44.918108: Current learning rate: 0.00013 
2025-01-16 14:18:25.737822: train_loss -0.9192 
2025-01-16 14:18:25.738339: val_loss -0.5593 
2025-01-16 14:18:25.743878: Pseudo dice [np.float32(0.8037), np.float32(0.5314)] 
2025-01-16 14:18:25.747887: Epoch time: 40.83 s 
2025-01-16 14:18:26.308312:  
2025-01-16 14:18:26.308312: Epoch 249 
2025-01-16 14:18:26.314955: Current learning rate: 7e-05 
2025-01-16 14:19:07.164008: train_loss -0.9241 
2025-01-16 14:19:07.164520: val_loss -0.5041 
2025-01-16 14:19:07.170566: Pseudo dice [np.float32(0.7816), np.float32(0.4484)] 
2025-01-16 14:19:07.175202: Epoch time: 40.86 s 
2025-01-16 14:19:07.957022: Training done. 
2025-01-16 14:19:07.983022: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-16 14:19:07.989023: The split file contains 5 splits. 
2025-01-16 14:19:07.995030: Desired fold for training: 0 
2025-01-16 14:19:08.002031: This split has 224 training and 57 validation cases. 
2025-01-16 14:19:08.008539: predicting pancreas_021 
2025-01-16 14:19:08.014541: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-16 14:19:10.209512: predicting pancreas_024 
2025-01-16 14:19:10.225512: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-16 14:19:12.121919: predicting pancreas_035 
2025-01-16 14:19:12.135919: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-16 14:19:12.807351: predicting pancreas_040 
2025-01-16 14:19:12.813858: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-01-16 14:19:14.330996: predicting pancreas_042 
2025-01-16 14:19:14.344996: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-01-16 14:19:16.253702: predicting pancreas_056 
2025-01-16 14:19:16.270703: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-16 14:19:17.793777: predicting pancreas_067 
2025-01-16 14:19:17.805780: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-16 14:19:19.736153: predicting pancreas_075 
2025-01-16 14:19:19.753153: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-01-16 14:19:20.558772: predicting pancreas_086 
2025-01-16 14:19:20.568773: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-16 14:19:21.780937: predicting pancreas_089 
2025-01-16 14:19:21.791937: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-16 14:19:23.310155: predicting pancreas_092 
2025-01-16 14:19:23.324158: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-01-16 14:19:26.767253: predicting pancreas_094 
2025-01-16 14:19:26.800259: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-16 14:19:28.360015: predicting pancreas_095 
2025-01-16 14:19:28.380016: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-16 14:19:29.957185: predicting pancreas_098 
2025-01-16 14:19:29.970185: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-16 14:19:34.165413: predicting pancreas_109 
2025-01-16 14:19:34.196415: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-16 14:19:35.765576: predicting pancreas_110 
2025-01-16 14:19:35.781576: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-16 14:19:38.183939: predicting pancreas_114 
2025-01-16 14:19:38.207941: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-16 14:19:39.763078: predicting pancreas_119 
2025-01-16 14:19:39.781078: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-16 14:19:42.157314: predicting pancreas_138 
2025-01-16 14:19:42.173313: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-16 14:19:44.569142: predicting pancreas_145 
2025-01-16 14:19:44.589142: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-16 14:19:46.979464: predicting pancreas_148 
2025-01-16 14:19:46.998464: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-01-16 14:19:48.544186: predicting pancreas_169 
2025-01-16 14:19:48.557189: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-16 14:19:50.093347: predicting pancreas_170 
2025-01-16 14:19:50.106349: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-16 14:19:52.021054: predicting pancreas_172 
2025-01-16 14:19:52.038054: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-16 14:19:53.594546: predicting pancreas_175 
2025-01-16 14:19:53.605551: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-16 14:19:55.142061: predicting pancreas_180 
2025-01-16 14:19:55.154062: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-16 14:19:56.722190: predicting pancreas_191 
2025-01-16 14:19:56.736190: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-16 14:19:57.523925: predicting pancreas_193 
2025-01-16 14:19:57.531930: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-16 14:19:59.447763: predicting pancreas_212 
2025-01-16 14:19:59.462763: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-16 14:20:01.028732: predicting pancreas_215 
2025-01-16 14:20:01.048733: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-16 14:20:02.589521: predicting pancreas_222 
2025-01-16 14:20:02.603525: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-16 14:20:03.287692: predicting pancreas_235 
2025-01-16 14:20:03.294691: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-16 14:20:04.821479: predicting pancreas_241 
2025-01-16 14:20:04.833479: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-16 14:20:06.388912: predicting pancreas_242 
2025-01-16 14:20:06.403915: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-16 14:20:08.333492: predicting pancreas_244 
2025-01-16 14:20:08.351492: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-16 14:20:11.310663: predicting pancreas_246 
2025-01-16 14:20:11.328170: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-16 14:20:14.315643: predicting pancreas_247 
2025-01-16 14:20:14.334152: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-16 14:20:15.233360: predicting pancreas_264 
2025-01-16 14:20:15.243359: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-16 14:20:17.153298: predicting pancreas_265 
2025-01-16 14:20:17.170298: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-16 14:20:18.731067: predicting pancreas_266 
2025-01-16 14:20:18.745068: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-16 14:20:21.124515: predicting pancreas_267 
2025-01-16 14:20:21.142515: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-16 14:20:22.051338: predicting pancreas_275 
2025-01-16 14:20:22.062338: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-16 14:20:23.956279: predicting pancreas_279 
2025-01-16 14:20:23.970279: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-16 14:20:24.662837: predicting pancreas_287 
2025-01-16 14:20:24.671837: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-16 14:20:26.215793: predicting pancreas_301 
2025-01-16 14:20:26.230298: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-16 14:20:27.796922: predicting pancreas_323 
2025-01-16 14:20:27.810925: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-16 14:20:30.215116: predicting pancreas_336 
2025-01-16 14:20:30.235620: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-16 14:20:31.811352: predicting pancreas_344 
2025-01-16 14:20:31.827858: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-16 14:20:33.746522: predicting pancreas_351 
2025-01-16 14:20:33.763522: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-16 14:20:34.662100: predicting pancreas_354 
2025-01-16 14:20:34.672100: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-01-16 14:20:37.729889: predicting pancreas_372 
2025-01-16 14:20:37.753890: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-16 14:20:40.187330: predicting pancreas_377 
2025-01-16 14:20:40.212332: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-01-16 14:20:42.188062: predicting pancreas_387 
2025-01-16 14:20:42.214066: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-01-16 14:20:43.789219: predicting pancreas_391 
2025-01-16 14:20:43.802219: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-16 14:20:46.188118: predicting pancreas_392 
2025-01-16 14:20:46.207119: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-01-16 14:20:47.338242: predicting pancreas_410 
2025-01-16 14:20:47.351242: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-16 14:20:48.456842: predicting pancreas_412 
2025-01-16 14:20:48.467842: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-01-16 14:21:10.949413: Validation complete 
2025-01-16 14:21:10.949413: Mean Validation Dice:  0.5798955558606878 
