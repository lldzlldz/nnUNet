
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-23 02:12:06.260410: do_dummy_2d_data_aug: False 
2024-12-23 02:12:06.265404: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-23 02:12:06.268403: The split file contains 5 splits. 
2024-12-23 02:12:06.270403: Desired fold for training: 0 
2024-12-23 02:12:06.273403: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2024-12-23 02:12:12.206121: unpacking dataset... 
2024-12-23 02:12:12.395385: unpacking done... 
2024-12-23 02:12:17.092188:  
2024-12-23 02:12:17.092188: Epoch 0 
2024-12-23 02:12:17.097254: Current learning rate: 0.01 
2024-12-23 02:12:52.026502: train_loss 0.0726 
2024-12-23 02:12:52.027501: val_loss 0.0088 
2024-12-23 02:12:52.034036: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-23 02:12:52.040063: Epoch time: 34.93 s 
2024-12-23 02:12:52.045087: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-23 02:12:52.761495:  
2024-12-23 02:12:52.761495: Epoch 1 
2024-12-23 02:12:52.765528: Current learning rate: 0.00991 
2024-12-23 02:13:24.530145: train_loss -0.0077 
2024-12-23 02:13:24.531146: val_loss -0.0508 
2024-12-23 02:13:24.536662: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-23 02:13:24.540687: Epoch time: 31.77 s 
2024-12-23 02:13:25.041902:  
2024-12-23 02:13:25.041902: Epoch 2 
2024-12-23 02:13:25.047415: Current learning rate: 0.00982 
2024-12-23 02:13:56.806172: train_loss -0.1785 
2024-12-23 02:13:56.807771: val_loss -0.2771 
2024-12-23 02:13:56.813795: Pseudo dice [np.float32(0.555), np.float32(0.0)] 
2024-12-23 02:13:56.816301: Epoch time: 31.77 s 
2024-12-23 02:13:56.819739: Yayy! New best EMA pseudo Dice: 0.027799999341368675 
2024-12-23 02:13:57.600949:  
2024-12-23 02:13:57.600949: Epoch 3 
2024-12-23 02:13:57.606516: Current learning rate: 0.00973 
2024-12-23 02:14:29.366714: train_loss -0.3162 
2024-12-23 02:14:29.367216: val_loss -0.3557 
2024-12-23 02:14:29.373365: Pseudo dice [np.float32(0.6074), np.float32(0.0)] 
2024-12-23 02:14:29.376462: Epoch time: 31.77 s 
2024-12-23 02:14:29.378517: Yayy! New best EMA pseudo Dice: 0.05530000105500221 
2024-12-23 02:14:30.133926:  
2024-12-23 02:14:30.134431: Epoch 4 
2024-12-23 02:14:30.138940: Current learning rate: 0.00964 
2024-12-23 02:15:01.876432: train_loss -0.4062 
2024-12-23 02:15:01.876945: val_loss -0.4181 
2024-12-23 02:15:01.882981: Pseudo dice [np.float32(0.5765), np.float32(0.3401)] 
2024-12-23 02:15:01.886877: Epoch time: 31.74 s 
2024-12-23 02:15:01.889410: Yayy! New best EMA pseudo Dice: 0.09560000151395798 
2024-12-23 02:15:02.781862:  
2024-12-23 02:15:02.781862: Epoch 5 
2024-12-23 02:15:02.786911: Current learning rate: 0.00955 
2024-12-23 02:15:34.559384: train_loss -0.4337 
2024-12-23 02:15:34.560910: val_loss -0.4231 
2024-12-23 02:15:34.566439: Pseudo dice [np.float32(0.5845), np.float32(0.3687)] 
2024-12-23 02:15:34.568985: Epoch time: 31.78 s 
2024-12-23 02:15:34.573070: Yayy! New best EMA pseudo Dice: 0.13369999825954437 
2024-12-23 02:15:35.321605:  
2024-12-23 02:15:35.322608: Epoch 6 
2024-12-23 02:15:35.327219: Current learning rate: 0.00946 
2024-12-23 02:16:07.073880: train_loss -0.4714 
2024-12-23 02:16:07.073880: val_loss -0.4682 
2024-12-23 02:16:07.079893: Pseudo dice [np.float32(0.6101), np.float32(0.426)] 
2024-12-23 02:16:07.083902: Epoch time: 31.75 s 
2024-12-23 02:16:07.087967: Yayy! New best EMA pseudo Dice: 0.17219999432563782 
2024-12-23 02:16:07.857192:  
2024-12-23 02:16:07.858196: Epoch 7 
2024-12-23 02:16:07.862735: Current learning rate: 0.00937 
2024-12-23 02:16:39.624439: train_loss -0.4851 
2024-12-23 02:16:39.624439: val_loss -0.4457 
2024-12-23 02:16:39.631035: Pseudo dice [np.float32(0.6374), np.float32(0.3297)] 
2024-12-23 02:16:39.634675: Epoch time: 31.77 s 
2024-12-23 02:16:39.637203: Yayy! New best EMA pseudo Dice: 0.20329999923706055 
2024-12-23 02:16:40.419472:  
2024-12-23 02:16:40.419981: Epoch 8 
2024-12-23 02:16:40.424550: Current learning rate: 0.00928 
2024-12-23 02:17:12.170910: train_loss -0.506 
2024-12-23 02:17:12.171429: val_loss -0.4826 
2024-12-23 02:17:12.176443: Pseudo dice [np.float32(0.6043), np.float32(0.4556)] 
2024-12-23 02:17:12.181456: Epoch time: 31.75 s 
2024-12-23 02:17:12.184969: Yayy! New best EMA pseudo Dice: 0.23600000143051147 
2024-12-23 02:17:12.966540:  
2024-12-23 02:17:12.967543: Epoch 9 
2024-12-23 02:17:12.971577: Current learning rate: 0.00919 
2024-12-23 02:17:44.734243: train_loss -0.5177 
2024-12-23 02:17:44.735246: val_loss -0.4841 
2024-12-23 02:17:44.741848: Pseudo dice [np.float32(0.6416), np.float32(0.4133)] 
2024-12-23 02:17:44.746394: Epoch time: 31.77 s 
2024-12-23 02:17:44.749465: Yayy! New best EMA pseudo Dice: 0.26510000228881836 
2024-12-23 02:17:45.499686:  
2024-12-23 02:17:45.499686: Epoch 10 
2024-12-23 02:17:45.504698: Current learning rate: 0.0091 
2024-12-23 02:18:17.251233: train_loss -0.5178 
2024-12-23 02:18:17.252233: val_loss -0.5033 
2024-12-23 02:18:17.257750: Pseudo dice [np.float32(0.6755), np.float32(0.4163)] 
2024-12-23 02:18:17.261307: Epoch time: 31.75 s 
2024-12-23 02:18:17.263818: Yayy! New best EMA pseudo Dice: 0.29319998621940613 
2024-12-23 02:18:18.035994:  
2024-12-23 02:18:18.035994: Epoch 11 
2024-12-23 02:18:18.041526: Current learning rate: 0.009 
2024-12-23 02:18:49.783563: train_loss -0.5352 
2024-12-23 02:18:49.784566: val_loss -0.4922 
2024-12-23 02:18:49.791094: Pseudo dice [np.float32(0.658), np.float32(0.3878)] 
2024-12-23 02:18:49.795109: Epoch time: 31.75 s 
2024-12-23 02:18:49.798124: Yayy! New best EMA pseudo Dice: 0.31619998812675476 
2024-12-23 02:18:50.712255:  
2024-12-23 02:18:50.713258: Epoch 12 
2024-12-23 02:18:50.717807: Current learning rate: 0.00891 
2024-12-23 02:19:22.460817: train_loss -0.5596 
2024-12-23 02:19:22.462320: val_loss -0.4864 
2024-12-23 02:19:22.467335: Pseudo dice [np.float32(0.6683), np.float32(0.3879)] 
2024-12-23 02:19:22.470863: Epoch time: 31.75 s 
2024-12-23 02:19:22.473373: Yayy! New best EMA pseudo Dice: 0.33739998936653137 
2024-12-23 02:19:23.248164:  
2024-12-23 02:19:23.248164: Epoch 13 
2024-12-23 02:19:23.253177: Current learning rate: 0.00882 
2024-12-23 02:19:54.983362: train_loss -0.5637 
2024-12-23 02:19:54.983890: val_loss -0.4913 
2024-12-23 02:19:54.990904: Pseudo dice [np.float32(0.6662), np.float32(0.4209)] 
2024-12-23 02:19:54.993960: Epoch time: 31.74 s 
2024-12-23 02:19:54.997474: Yayy! New best EMA pseudo Dice: 0.3580000102519989 
2024-12-23 02:19:55.759652:  
2024-12-23 02:19:55.759652: Epoch 14 
2024-12-23 02:19:55.764665: Current learning rate: 0.00873 
2024-12-23 02:20:27.502314: train_loss -0.5769 
2024-12-23 02:20:27.502821: val_loss -0.5012 
2024-12-23 02:20:27.508423: Pseudo dice [np.float32(0.6324), np.float32(0.4591)] 
2024-12-23 02:20:27.511985: Epoch time: 31.74 s 
2024-12-23 02:20:27.515006: Yayy! New best EMA pseudo Dice: 0.376800000667572 
2024-12-23 02:20:28.288898:  
2024-12-23 02:20:28.288898: Epoch 15 
2024-12-23 02:20:28.294007: Current learning rate: 0.00864 
2024-12-23 02:21:00.055008: train_loss -0.5745 
2024-12-23 02:21:00.055008: val_loss -0.4386 
2024-12-23 02:21:00.061022: Pseudo dice [np.float32(0.6082), np.float32(0.3579)] 
2024-12-23 02:21:00.064041: Epoch time: 31.77 s 
2024-12-23 02:21:00.068560: Yayy! New best EMA pseudo Dice: 0.3874000012874603 
2024-12-23 02:21:00.842450:  
2024-12-23 02:21:00.842450: Epoch 16 
2024-12-23 02:21:00.848582: Current learning rate: 0.00855 
2024-12-23 02:21:32.600650: train_loss -0.5709 
2024-12-23 02:21:32.601651: val_loss -0.5337 
2024-12-23 02:21:32.607174: Pseudo dice [np.float32(0.67), np.float32(0.4748)] 
2024-12-23 02:21:32.610693: Epoch time: 31.76 s 
2024-12-23 02:21:32.614703: Yayy! New best EMA pseudo Dice: 0.4059000015258789 
2024-12-23 02:21:33.407772:  
2024-12-23 02:21:33.407772: Epoch 17 
2024-12-23 02:21:33.412788: Current learning rate: 0.00846 
2024-12-23 02:22:05.174084: train_loss -0.5911 
2024-12-23 02:22:05.174596: val_loss -0.5065 
2024-12-23 02:22:05.179634: Pseudo dice [np.float32(0.6491), np.float32(0.4682)] 
2024-12-23 02:22:05.184174: Epoch time: 31.77 s 
2024-12-23 02:22:05.187235: Yayy! New best EMA pseudo Dice: 0.4212000072002411 
2024-12-23 02:22:05.964344:  
2024-12-23 02:22:05.964344: Epoch 18 
2024-12-23 02:22:05.969357: Current learning rate: 0.00836 
2024-12-23 02:22:37.724969: train_loss -0.6152 
2024-12-23 02:22:37.725475: val_loss -0.5041 
2024-12-23 02:22:37.731018: Pseudo dice [np.float32(0.6866), np.float32(0.3993)] 
2024-12-23 02:22:37.735071: Epoch time: 31.76 s 
2024-12-23 02:22:37.737579: Yayy! New best EMA pseudo Dice: 0.4332999885082245 
2024-12-23 02:22:38.519124:  
2024-12-23 02:22:38.519124: Epoch 19 
2024-12-23 02:22:38.524135: Current learning rate: 0.00827 
2024-12-23 02:23:10.282597: train_loss -0.6176 
2024-12-23 02:23:10.282597: val_loss -0.5214 
2024-12-23 02:23:10.289146: Pseudo dice [np.float32(0.6984), np.float32(0.3959)] 
2024-12-23 02:23:10.291699: Epoch time: 31.76 s 
2024-12-23 02:23:10.295308: Yayy! New best EMA pseudo Dice: 0.4447000026702881 
2024-12-23 02:23:11.194499:  
2024-12-23 02:23:11.194499: Epoch 20 
2024-12-23 02:23:11.200065: Current learning rate: 0.00818 
2024-12-23 02:23:42.935325: train_loss -0.6189 
2024-12-23 02:23:42.935325: val_loss -0.4079 
2024-12-23 02:23:42.941378: Pseudo dice [np.float32(0.6949), np.float32(0.1898)] 
2024-12-23 02:23:42.945439: Epoch time: 31.74 s 
2024-12-23 02:23:43.482070:  
2024-12-23 02:23:43.482070: Epoch 21 
2024-12-23 02:23:43.487086: Current learning rate: 0.00809 
2024-12-23 02:24:15.229378: train_loss -0.6125 
2024-12-23 02:24:15.230380: val_loss -0.4699 
2024-12-23 02:24:15.236901: Pseudo dice [np.float32(0.6797), np.float32(0.3705)] 
2024-12-23 02:24:15.240408: Epoch time: 31.75 s 
2024-12-23 02:24:15.243418: Yayy! New best EMA pseudo Dice: 0.45249998569488525 
2024-12-23 02:24:15.990767:  
2024-12-23 02:24:15.990767: Epoch 22 
2024-12-23 02:24:15.995776: Current learning rate: 0.008 
2024-12-23 02:24:47.732491: train_loss -0.6366 
2024-12-23 02:24:47.732995: val_loss -0.5366 
2024-12-23 02:24:47.740181: Pseudo dice [np.float32(0.6637), np.float32(0.4814)] 
2024-12-23 02:24:47.742708: Epoch time: 31.74 s 
2024-12-23 02:24:47.746836: Yayy! New best EMA pseudo Dice: 0.4645000100135803 
2024-12-23 02:24:48.494856:  
2024-12-23 02:24:48.494856: Epoch 23 
2024-12-23 02:24:48.500493: Current learning rate: 0.0079 
2024-12-23 02:25:20.243477: train_loss -0.6481 
2024-12-23 02:25:20.243979: val_loss -0.5115 
2024-12-23 02:25:20.249999: Pseudo dice [np.float32(0.6855), np.float32(0.3898)] 
2024-12-23 02:25:20.255022: Epoch time: 31.75 s 
2024-12-23 02:25:20.259036: Yayy! New best EMA pseudo Dice: 0.47189998626708984 
2024-12-23 02:25:21.024315:  
2024-12-23 02:25:21.024315: Epoch 24 
2024-12-23 02:25:21.029357: Current learning rate: 0.00781 
2024-12-23 02:25:52.772235: train_loss -0.6557 
2024-12-23 02:25:52.772235: val_loss -0.545 
2024-12-23 02:25:52.778764: Pseudo dice [np.float32(0.7033), np.float32(0.4487)] 
2024-12-23 02:25:52.781806: Epoch time: 31.75 s 
2024-12-23 02:25:52.784834: Yayy! New best EMA pseudo Dice: 0.4823000133037567 
2024-12-23 02:25:53.552314:  
2024-12-23 02:25:53.553317: Epoch 25 
2024-12-23 02:25:53.557887: Current learning rate: 0.00772 
2024-12-23 02:26:25.299916: train_loss -0.659 
2024-12-23 02:26:25.300916: val_loss -0.5021 
2024-12-23 02:26:25.306435: Pseudo dice [np.float32(0.6878), np.float32(0.3748)] 
2024-12-23 02:26:25.310977: Epoch time: 31.75 s 
2024-12-23 02:26:25.314013: Yayy! New best EMA pseudo Dice: 0.487199991941452 
2024-12-23 02:26:26.089627:  
2024-12-23 02:26:26.090633: Epoch 26 
2024-12-23 02:26:26.095212: Current learning rate: 0.00763 
2024-12-23 02:26:57.834997: train_loss -0.659 
2024-12-23 02:26:57.835998: val_loss -0.4946 
2024-12-23 02:26:57.843521: Pseudo dice [np.float32(0.6757), np.float32(0.4167)] 
2024-12-23 02:26:57.849043: Epoch time: 31.75 s 
2024-12-23 02:26:57.851551: Yayy! New best EMA pseudo Dice: 0.49309998750686646 
2024-12-23 02:26:58.733594:  
2024-12-23 02:26:58.735097: Epoch 27 
2024-12-23 02:26:58.740112: Current learning rate: 0.00753 
2024-12-23 02:27:30.482889: train_loss -0.6689 
2024-12-23 02:27:30.482889: val_loss -0.4847 
2024-12-23 02:27:30.489412: Pseudo dice [np.float32(0.6923), np.float32(0.4173)] 
2024-12-23 02:27:30.494428: Epoch time: 31.75 s 
2024-12-23 02:27:30.497938: Yayy! New best EMA pseudo Dice: 0.4991999864578247 
2024-12-23 02:27:31.292044:  
2024-12-23 02:27:31.292044: Epoch 28 
2024-12-23 02:27:31.297581: Current learning rate: 0.00744 
2024-12-23 02:28:03.047262: train_loss -0.6644 
2024-12-23 02:28:03.047764: val_loss -0.4571 
2024-12-23 02:28:03.053849: Pseudo dice [np.float32(0.6587), np.float32(0.3729)] 
2024-12-23 02:28:03.058860: Epoch time: 31.76 s 
2024-12-23 02:28:03.062366: Yayy! New best EMA pseudo Dice: 0.5008999705314636 
2024-12-23 02:28:03.823200:  
2024-12-23 02:28:03.823200: Epoch 29 
2024-12-23 02:28:03.828217: Current learning rate: 0.00735 
2024-12-23 02:28:35.586199: train_loss -0.663 
2024-12-23 02:28:35.586199: val_loss -0.4911 
2024-12-23 02:28:35.591736: Pseudo dice [np.float32(0.6488), np.float32(0.4437)] 
2024-12-23 02:28:35.596301: Epoch time: 31.76 s 
2024-12-23 02:28:35.599317: Yayy! New best EMA pseudo Dice: 0.5054000020027161 
2024-12-23 02:28:36.367384:  
2024-12-23 02:28:36.368383: Epoch 30 
2024-12-23 02:28:36.373491: Current learning rate: 0.00725 
2024-12-23 02:29:08.108783: train_loss -0.6322 
2024-12-23 02:29:08.108783: val_loss -0.4934 
2024-12-23 02:29:08.115891: Pseudo dice [np.float32(0.7006), np.float32(0.3265)] 
2024-12-23 02:29:08.119932: Epoch time: 31.74 s 
2024-12-23 02:29:08.122968: Yayy! New best EMA pseudo Dice: 0.5062999725341797 
2024-12-23 02:29:08.901506:  
2024-12-23 02:29:08.902509: Epoch 31 
2024-12-23 02:29:08.908048: Current learning rate: 0.00716 
2024-12-23 02:29:40.650148: train_loss -0.6453 
2024-12-23 02:29:40.650659: val_loss -0.4851 
2024-12-23 02:29:40.656698: Pseudo dice [np.float32(0.6772), np.float32(0.3809)] 
2024-12-23 02:29:40.659000: Epoch time: 31.75 s 
2024-12-23 02:29:40.663543: Yayy! New best EMA pseudo Dice: 0.5084999799728394 
2024-12-23 02:29:41.422445:  
2024-12-23 02:29:41.422445: Epoch 32 
2024-12-23 02:29:41.427461: Current learning rate: 0.00707 
2024-12-23 02:30:13.185096: train_loss -0.6707 
2024-12-23 02:30:13.185096: val_loss -0.5042 
2024-12-23 02:30:13.192630: Pseudo dice [np.float32(0.6689), np.float32(0.4495)] 
2024-12-23 02:30:13.197667: Epoch time: 31.76 s 
2024-12-23 02:30:13.200190: Yayy! New best EMA pseudo Dice: 0.5135999917984009 
2024-12-23 02:30:13.973232:  
2024-12-23 02:30:13.974232: Epoch 33 
2024-12-23 02:30:13.979348: Current learning rate: 0.00697 
2024-12-23 02:30:45.723326: train_loss -0.6598 
2024-12-23 02:30:45.725833: val_loss -0.4607 
2024-12-23 02:30:45.732418: Pseudo dice [np.float32(0.6998), np.float32(0.2892)] 
2024-12-23 02:30:45.735490: Epoch time: 31.75 s 
2024-12-23 02:30:46.395659:  
2024-12-23 02:30:46.395659: Epoch 34 
2024-12-23 02:30:46.400267: Current learning rate: 0.00688 
2024-12-23 02:31:18.169631: train_loss -0.6591 
2024-12-23 02:31:18.170631: val_loss -0.4533 
2024-12-23 02:31:18.178661: Pseudo dice [np.float32(0.6567), np.float32(0.3203)] 
2024-12-23 02:31:18.183681: Epoch time: 31.77 s 
2024-12-23 02:31:18.713242:  
2024-12-23 02:31:18.713242: Epoch 35 
2024-12-23 02:31:18.718272: Current learning rate: 0.00679 
2024-12-23 02:31:55.793401: train_loss -0.6843 
2024-12-23 02:31:55.794400: val_loss -0.4914 
2024-12-23 02:31:55.799924: Pseudo dice [np.float32(0.6815), np.float32(0.3815)] 
2024-12-23 02:31:55.803435: Epoch time: 37.08 s 
2024-12-23 02:31:56.346622:  
2024-12-23 02:31:56.346622: Epoch 36 
2024-12-23 02:31:56.352223: Current learning rate: 0.00669 
2024-12-23 02:32:29.895804: train_loss -0.6899 
2024-12-23 02:32:29.896307: val_loss -0.5282 
2024-12-23 02:32:29.903368: Pseudo dice [np.float32(0.6944), np.float32(0.4656)] 
2024-12-23 02:32:29.907428: Epoch time: 33.55 s 
2024-12-23 02:32:29.909652: Yayy! New best EMA pseudo Dice: 0.5184000134468079 
2024-12-23 02:32:30.737130:  
2024-12-23 02:32:30.737130: Epoch 37 
2024-12-23 02:32:30.743344: Current learning rate: 0.0066 
2024-12-23 02:33:03.435898: train_loss -0.7074 
2024-12-23 02:33:03.436903: val_loss -0.5512 
2024-12-23 02:33:03.441919: Pseudo dice [np.float32(0.707), np.float32(0.4865)] 
2024-12-23 02:33:03.445940: Epoch time: 32.7 s 
2024-12-23 02:33:03.449450: Yayy! New best EMA pseudo Dice: 0.5263000130653381 
2024-12-23 02:33:04.272328:  
2024-12-23 02:33:04.272328: Epoch 38 
2024-12-23 02:33:04.277344: Current learning rate: 0.0065 
2024-12-23 02:33:36.579613: train_loss -0.7192 
2024-12-23 02:33:36.580115: val_loss -0.5185 
2024-12-23 02:33:36.587146: Pseudo dice [np.float32(0.7033), np.float32(0.4333)] 
2024-12-23 02:33:36.590153: Epoch time: 32.31 s 
2024-12-23 02:33:36.593662: Yayy! New best EMA pseudo Dice: 0.5304999947547913 
2024-12-23 02:33:37.408868:  
2024-12-23 02:33:37.409371: Epoch 39 
2024-12-23 02:33:37.414390: Current learning rate: 0.00641 
2024-12-23 02:34:09.300869: train_loss -0.7078 
2024-12-23 02:34:09.300869: val_loss -0.5271 
2024-12-23 02:34:09.305880: Pseudo dice [np.float32(0.7067), np.float32(0.3814)] 
2024-12-23 02:34:09.310165: Epoch time: 31.89 s 
2024-12-23 02:34:09.313289: Yayy! New best EMA pseudo Dice: 0.5317999720573425 
2024-12-23 02:34:10.131474:  
2024-12-23 02:34:10.131474: Epoch 40 
2024-12-23 02:34:10.137579: Current learning rate: 0.00631 
2024-12-23 02:34:42.005444: train_loss -0.6897 
2024-12-23 02:34:42.005444: val_loss -0.493 
2024-12-23 02:34:42.012972: Pseudo dice [np.float32(0.6958), np.float32(0.4006)] 
2024-12-23 02:34:42.016490: Epoch time: 31.87 s 
2024-12-23 02:34:42.019996: Yayy! New best EMA pseudo Dice: 0.5335000157356262 
2024-12-23 02:34:42.845853:  
2024-12-23 02:34:42.846356: Epoch 41 
2024-12-23 02:34:42.851369: Current learning rate: 0.00622 
2024-12-23 02:35:14.733932: train_loss -0.6895 
2024-12-23 02:35:14.734439: val_loss -0.4731 
2024-12-23 02:35:14.741092: Pseudo dice [np.float32(0.6992), np.float32(0.3304)] 
2024-12-23 02:35:14.745745: Epoch time: 31.89 s 
2024-12-23 02:35:15.397674:  
2024-12-23 02:35:15.398177: Epoch 42 
2024-12-23 02:35:15.402689: Current learning rate: 0.00612 
2024-12-23 02:35:47.266623: train_loss -0.7008 
2024-12-23 02:35:47.266623: val_loss -0.4819 
2024-12-23 02:35:47.273142: Pseudo dice [np.float32(0.6769), np.float32(0.3386)] 
2024-12-23 02:35:47.276703: Epoch time: 31.87 s 
2024-12-23 02:35:47.788632:  
2024-12-23 02:35:47.788632: Epoch 43 
2024-12-23 02:35:47.794696: Current learning rate: 0.00603 
2024-12-23 02:36:19.691465: train_loss -0.7036 
2024-12-23 02:36:19.691465: val_loss -0.5005 
2024-12-23 02:36:19.698530: Pseudo dice [np.float32(0.6772), np.float32(0.4305)] 
2024-12-23 02:36:19.702565: Epoch time: 31.9 s 
2024-12-23 02:36:20.217030:  
2024-12-23 02:36:20.217030: Epoch 44 
2024-12-23 02:36:20.222552: Current learning rate: 0.00593 
2024-12-23 02:36:52.095818: train_loss -0.7265 
2024-12-23 02:36:52.095818: val_loss -0.5015 
2024-12-23 02:36:52.102357: Pseudo dice [np.float32(0.7153), np.float32(0.3174)] 
2024-12-23 02:36:52.105868: Epoch time: 31.88 s 
2024-12-23 02:36:52.619663:  
2024-12-23 02:36:52.619663: Epoch 45 
2024-12-23 02:36:52.624673: Current learning rate: 0.00584 
2024-12-23 02:37:24.499600: train_loss -0.7316 
2024-12-23 02:37:24.500604: val_loss -0.4847 
2024-12-23 02:37:24.506629: Pseudo dice [np.float32(0.7176), np.float32(0.3095)] 
2024-12-23 02:37:24.509696: Epoch time: 31.88 s 
2024-12-23 02:37:25.019332:  
2024-12-23 02:37:25.019332: Epoch 46 
2024-12-23 02:37:25.024869: Current learning rate: 0.00574 
2024-12-23 02:37:56.904217: train_loss -0.7517 
2024-12-23 02:37:56.904217: val_loss -0.5235 
2024-12-23 02:37:56.910247: Pseudo dice [np.float32(0.7314), np.float32(0.3829)] 
2024-12-23 02:37:56.913860: Epoch time: 31.89 s 
2024-12-23 02:37:57.415248:  
2024-12-23 02:37:57.416251: Epoch 47 
2024-12-23 02:37:57.421447: Current learning rate: 0.00565 
2024-12-23 02:38:29.757105: train_loss -0.7334 
2024-12-23 02:38:29.758616: val_loss -0.4882 
2024-12-23 02:38:29.763731: Pseudo dice [np.float32(0.6976), np.float32(0.3467)] 
2024-12-23 02:38:29.767247: Epoch time: 32.34 s 
2024-12-23 02:38:30.268436:  
2024-12-23 02:38:30.268938: Epoch 48 
2024-12-23 02:38:30.273954: Current learning rate: 0.00555 
2024-12-23 02:39:02.227244: train_loss -0.7473 
2024-12-23 02:39:02.227754: val_loss -0.4893 
2024-12-23 02:39:02.233860: Pseudo dice [np.float32(0.7119), np.float32(0.3279)] 
2024-12-23 02:39:02.237431: Epoch time: 31.96 s 
2024-12-23 02:39:02.747862:  
2024-12-23 02:39:02.747862: Epoch 49 
2024-12-23 02:39:02.753438: Current learning rate: 0.00546 
2024-12-23 02:39:34.622167: train_loss -0.725 
2024-12-23 02:39:34.622167: val_loss -0.5229 
2024-12-23 02:39:34.628678: Pseudo dice [np.float32(0.7151), np.float32(0.4546)] 
2024-12-23 02:39:34.632246: Epoch time: 31.88 s 
2024-12-23 02:39:34.855113: Yayy! New best EMA pseudo Dice: 0.5349000096321106 
2024-12-23 02:39:35.848271:  
2024-12-23 02:39:35.849271: Epoch 50 
2024-12-23 02:39:35.854329: Current learning rate: 0.00536 
2024-12-23 02:40:07.715385: train_loss -0.7496 
2024-12-23 02:40:07.715887: val_loss -0.498 
2024-12-23 02:40:07.723407: Pseudo dice [np.float32(0.703), np.float32(0.3355)] 
2024-12-23 02:40:07.726917: Epoch time: 31.87 s 
2024-12-23 02:40:08.237106:  
2024-12-23 02:40:08.237106: Epoch 51 
2024-12-23 02:40:08.242116: Current learning rate: 0.00526 
2024-12-23 02:40:40.120041: train_loss -0.7552 
2024-12-23 02:40:40.120041: val_loss -0.5486 
2024-12-23 02:40:40.126061: Pseudo dice [np.float32(0.7155), np.float32(0.4677)] 
2024-12-23 02:40:40.130074: Epoch time: 31.88 s 
2024-12-23 02:40:40.133587: Yayy! New best EMA pseudo Dice: 0.5392000079154968 
2024-12-23 02:40:40.906170:  
2024-12-23 02:40:40.906170: Epoch 52 
2024-12-23 02:40:40.911181: Current learning rate: 0.00517 
2024-12-23 02:41:12.758590: train_loss -0.7598 
2024-12-23 02:41:12.760093: val_loss -0.492 
2024-12-23 02:41:12.765614: Pseudo dice [np.float32(0.6997), np.float32(0.4464)] 
2024-12-23 02:41:12.770161: Epoch time: 31.85 s 
2024-12-23 02:41:12.772671: Yayy! New best EMA pseudo Dice: 0.5425999760627747 
2024-12-23 02:41:13.574031:  
2024-12-23 02:41:13.575033: Epoch 53 
2024-12-23 02:41:13.580088: Current learning rate: 0.00507 
2024-12-23 02:41:45.447038: train_loss -0.7722 
2024-12-23 02:41:45.447541: val_loss -0.5463 
2024-12-23 02:41:45.454087: Pseudo dice [np.float32(0.7395), np.float32(0.4)] 
2024-12-23 02:41:45.456678: Epoch time: 31.87 s 
2024-12-23 02:41:45.460258: Yayy! New best EMA pseudo Dice: 0.5453000068664551 
2024-12-23 02:41:46.259314:  
2024-12-23 02:41:46.260314: Epoch 54 
2024-12-23 02:41:46.265875: Current learning rate: 0.00497 
2024-12-23 02:42:18.143358: train_loss -0.7752 
2024-12-23 02:42:18.143868: val_loss -0.4971 
2024-12-23 02:42:18.149471: Pseudo dice [np.float32(0.7156), np.float32(0.3279)] 
2024-12-23 02:42:18.153581: Epoch time: 31.88 s 
2024-12-23 02:42:18.666005:  
2024-12-23 02:42:18.666514: Epoch 55 
2024-12-23 02:42:18.671556: Current learning rate: 0.00487 
2024-12-23 02:42:50.550082: train_loss -0.7665 
2024-12-23 02:42:50.551589: val_loss -0.542 
2024-12-23 02:42:50.558136: Pseudo dice [np.float32(0.7052), np.float32(0.451)] 
2024-12-23 02:42:50.561644: Epoch time: 31.89 s 
2024-12-23 02:42:50.564655: Yayy! New best EMA pseudo Dice: 0.5464000105857849 
2024-12-23 02:42:51.385061:  
2024-12-23 02:42:51.385061: Epoch 56 
2024-12-23 02:42:51.390638: Current learning rate: 0.00478 
2024-12-23 02:43:23.277633: train_loss -0.765 
2024-12-23 02:43:23.278639: val_loss -0.4908 
2024-12-23 02:43:23.284648: Pseudo dice [np.float32(0.7278), np.float32(0.3549)] 
2024-12-23 02:43:23.288220: Epoch time: 31.89 s 
2024-12-23 02:43:23.804425:  
2024-12-23 02:43:23.804425: Epoch 57 
2024-12-23 02:43:23.809986: Current learning rate: 0.00468 
2024-12-23 02:43:55.518382: train_loss -0.759 
2024-12-23 02:43:55.518887: val_loss -0.4536 
2024-12-23 02:43:55.525521: Pseudo dice [np.float32(0.6875), np.float32(0.2988)] 
2024-12-23 02:43:55.528582: Epoch time: 31.71 s 
2024-12-23 02:43:56.181264:  
2024-12-23 02:43:56.181264: Epoch 58 
2024-12-23 02:43:56.186813: Current learning rate: 0.00458 
2024-12-23 02:44:27.891740: train_loss -0.7663 
2024-12-23 02:44:27.892242: val_loss -0.4986 
2024-12-23 02:44:27.897317: Pseudo dice [np.float32(0.6972), np.float32(0.3554)] 
2024-12-23 02:44:27.901955: Epoch time: 31.71 s 
2024-12-23 02:44:28.425874:  
2024-12-23 02:44:28.425874: Epoch 59 
2024-12-23 02:44:28.431423: Current learning rate: 0.00448 
2024-12-23 02:45:00.132617: train_loss -0.7916 
2024-12-23 02:45:00.133120: val_loss -0.5008 
2024-12-23 02:45:00.139313: Pseudo dice [np.float32(0.7162), np.float32(0.3482)] 
2024-12-23 02:45:00.143346: Epoch time: 31.71 s 
2024-12-23 02:45:00.656830:  
2024-12-23 02:45:00.657829: Epoch 60 
2024-12-23 02:45:00.663421: Current learning rate: 0.00438 
2024-12-23 02:45:32.371667: train_loss -0.7794 
2024-12-23 02:45:32.371667: val_loss -0.5425 
2024-12-23 02:45:32.377687: Pseudo dice [np.float32(0.7142), np.float32(0.4582)] 
2024-12-23 02:45:32.381694: Epoch time: 31.71 s 
2024-12-23 02:45:32.907386:  
2024-12-23 02:45:32.907386: Epoch 61 
2024-12-23 02:45:32.912431: Current learning rate: 0.00429 
2024-12-23 02:46:04.617964: train_loss -0.7909 
2024-12-23 02:46:04.617964: val_loss -0.4775 
2024-12-23 02:46:04.623605: Pseudo dice [np.float32(0.716), np.float32(0.278)] 
2024-12-23 02:46:04.626685: Epoch time: 31.71 s 
2024-12-23 02:46:05.147493:  
2024-12-23 02:46:05.147493: Epoch 62 
2024-12-23 02:46:05.152514: Current learning rate: 0.00419 
2024-12-23 02:46:36.858091: train_loss -0.7938 
2024-12-23 02:46:36.859619: val_loss -0.4559 
2024-12-23 02:46:36.865653: Pseudo dice [np.float32(0.6927), np.float32(0.2924)] 
2024-12-23 02:46:36.868679: Epoch time: 31.71 s 
2024-12-23 02:46:37.387925:  
2024-12-23 02:46:37.388925: Epoch 63 
2024-12-23 02:46:37.394444: Current learning rate: 0.00409 
2024-12-23 02:47:09.102942: train_loss -0.7954 
2024-12-23 02:47:09.102942: val_loss -0.5334 
2024-12-23 02:47:09.109457: Pseudo dice [np.float32(0.7484), np.float32(0.3588)] 
2024-12-23 02:47:09.112495: Epoch time: 31.72 s 
2024-12-23 02:47:09.630912:  
2024-12-23 02:47:09.631912: Epoch 64 
2024-12-23 02:47:09.637489: Current learning rate: 0.00399 
2024-12-23 02:47:41.357636: train_loss -0.8014 
2024-12-23 02:47:41.358139: val_loss -0.4641 
2024-12-23 02:47:41.363692: Pseudo dice [np.float32(0.6934), np.float32(0.3032)] 
2024-12-23 02:47:41.366732: Epoch time: 31.73 s 
2024-12-23 02:47:41.888511:  
2024-12-23 02:47:41.888511: Epoch 65 
2024-12-23 02:47:41.894576: Current learning rate: 0.00389 
2024-12-23 02:48:13.583863: train_loss -0.7886 
2024-12-23 02:48:13.584365: val_loss -0.5164 
2024-12-23 02:48:13.589377: Pseudo dice [np.float32(0.7186), np.float32(0.3957)] 
2024-12-23 02:48:13.594502: Epoch time: 31.7 s 
2024-12-23 02:48:14.256922:  
2024-12-23 02:48:14.256922: Epoch 66 
2024-12-23 02:48:14.261934: Current learning rate: 0.00379 
2024-12-23 02:48:45.973779: train_loss -0.7881 
2024-12-23 02:48:45.973779: val_loss -0.5111 
2024-12-23 02:48:45.980880: Pseudo dice [np.float32(0.6996), np.float32(0.4056)] 
2024-12-23 02:48:45.986424: Epoch time: 31.72 s 
2024-12-23 02:48:46.505015:  
2024-12-23 02:48:46.506014: Epoch 67 
2024-12-23 02:48:46.511531: Current learning rate: 0.00369 
2024-12-23 02:49:18.214036: train_loss -0.7951 
2024-12-23 02:49:18.215039: val_loss -0.4892 
2024-12-23 02:49:18.221121: Pseudo dice [np.float32(0.7157), np.float32(0.3308)] 
2024-12-23 02:49:18.225178: Epoch time: 31.71 s 
2024-12-23 02:49:18.749196:  
2024-12-23 02:49:18.749196: Epoch 68 
2024-12-23 02:49:18.754751: Current learning rate: 0.00359 
2024-12-23 02:49:50.450699: train_loss -0.8028 
2024-12-23 02:49:50.451702: val_loss -0.4723 
2024-12-23 02:49:50.458338: Pseudo dice [np.float32(0.7183), np.float32(0.2662)] 
2024-12-23 02:49:50.461863: Epoch time: 31.7 s 
2024-12-23 02:49:50.989449:  
2024-12-23 02:49:50.989952: Epoch 69 
2024-12-23 02:49:50.994965: Current learning rate: 0.00349 
2024-12-23 02:50:22.685289: train_loss -0.8185 
2024-12-23 02:50:22.685289: val_loss -0.4796 
2024-12-23 02:50:22.691372: Pseudo dice [np.float32(0.7113), np.float32(0.2868)] 
2024-12-23 02:50:22.694917: Epoch time: 31.7 s 
2024-12-23 02:50:23.224522:  
2024-12-23 02:50:23.224522: Epoch 70 
2024-12-23 02:50:23.230581: Current learning rate: 0.00338 
2024-12-23 02:50:54.924148: train_loss -0.8138 
2024-12-23 02:50:54.924666: val_loss -0.4947 
2024-12-23 02:50:54.930767: Pseudo dice [np.float32(0.7324), np.float32(0.3378)] 
2024-12-23 02:50:54.934775: Epoch time: 31.7 s 
2024-12-23 02:50:55.466719:  
2024-12-23 02:50:55.466719: Epoch 71 
2024-12-23 02:50:55.472318: Current learning rate: 0.00328 
2024-12-23 02:51:27.167327: train_loss -0.814 
2024-12-23 02:51:27.167830: val_loss -0.4844 
2024-12-23 02:51:27.173967: Pseudo dice [np.float32(0.7317), np.float32(0.3169)] 
2024-12-23 02:51:27.178018: Epoch time: 31.7 s 
2024-12-23 02:51:27.729048:  
2024-12-23 02:51:27.729048: Epoch 72 
2024-12-23 02:51:27.735067: Current learning rate: 0.00318 
2024-12-23 02:51:59.435199: train_loss -0.827 
2024-12-23 02:51:59.435701: val_loss -0.4704 
2024-12-23 02:51:59.441718: Pseudo dice [np.float32(0.7082), np.float32(0.3158)] 
2024-12-23 02:51:59.445726: Epoch time: 31.71 s 
2024-12-23 02:51:59.977510:  
2024-12-23 02:51:59.979012: Epoch 73 
2024-12-23 02:51:59.984028: Current learning rate: 0.00308 
2024-12-23 02:52:31.674229: train_loss -0.8244 
2024-12-23 02:52:31.674229: val_loss -0.4921 
2024-12-23 02:52:31.680315: Pseudo dice [np.float32(0.7187), np.float32(0.3428)] 
2024-12-23 02:52:31.684334: Epoch time: 31.7 s 
2024-12-23 02:52:32.349579:  
2024-12-23 02:52:32.349579: Epoch 74 
2024-12-23 02:52:32.355598: Current learning rate: 0.00297 
2024-12-23 02:53:04.064676: train_loss -0.8185 
2024-12-23 02:53:04.065189: val_loss -0.4847 
2024-12-23 02:53:04.070251: Pseudo dice [np.float32(0.7041), np.float32(0.3363)] 
2024-12-23 02:53:04.074820: Epoch time: 31.72 s 
2024-12-23 02:53:04.606847:  
2024-12-23 02:53:04.607848: Epoch 75 
2024-12-23 02:53:04.613427: Current learning rate: 0.00287 
2024-12-23 02:53:36.297385: train_loss -0.8318 
2024-12-23 02:53:36.298910: val_loss -0.4536 
2024-12-23 02:53:36.304571: Pseudo dice [np.float32(0.7192), np.float32(0.2324)] 
2024-12-23 02:53:36.309112: Epoch time: 31.69 s 
2024-12-23 02:53:36.836579:  
2024-12-23 02:53:36.836579: Epoch 76 
2024-12-23 02:53:36.842137: Current learning rate: 0.00277 
2024-12-23 02:54:08.559111: train_loss -0.834 
2024-12-23 02:54:08.559614: val_loss -0.4718 
2024-12-23 02:54:08.566984: Pseudo dice [np.float32(0.7037), np.float32(0.3058)] 
2024-12-23 02:54:08.570050: Epoch time: 31.72 s 
2024-12-23 02:54:09.097408:  
2024-12-23 02:54:09.097910: Epoch 77 
2024-12-23 02:54:09.102925: Current learning rate: 0.00266 
2024-12-23 02:54:40.814367: train_loss -0.8319 
2024-12-23 02:54:40.814874: val_loss -0.5043 
2024-12-23 02:54:40.820993: Pseudo dice [np.float32(0.6826), np.float32(0.3989)] 
2024-12-23 02:54:40.825511: Epoch time: 31.72 s 
2024-12-23 02:54:41.363468:  
2024-12-23 02:54:41.363989: Epoch 78 
2024-12-23 02:54:41.370603: Current learning rate: 0.00256 
2024-12-23 02:55:13.100769: train_loss -0.819 
2024-12-23 02:55:13.100769: val_loss -0.4705 
2024-12-23 02:55:13.107787: Pseudo dice [np.float32(0.6906), np.float32(0.3526)] 
2024-12-23 02:55:13.112359: Epoch time: 31.74 s 
2024-12-23 02:55:13.653153:  
2024-12-23 02:55:13.653153: Epoch 79 
2024-12-23 02:55:13.658669: Current learning rate: 0.00245 
2024-12-23 02:55:45.362854: train_loss -0.8318 
2024-12-23 02:55:45.363361: val_loss -0.4973 
2024-12-23 02:55:45.370435: Pseudo dice [np.float32(0.7228), np.float32(0.3486)] 
2024-12-23 02:55:45.374454: Epoch time: 31.71 s 
2024-12-23 02:55:45.908123:  
2024-12-23 02:55:45.908123: Epoch 80 
2024-12-23 02:55:45.913680: Current learning rate: 0.00235 
2024-12-23 02:56:17.629366: train_loss -0.8313 
2024-12-23 02:56:17.630370: val_loss -0.4925 
2024-12-23 02:56:17.636394: Pseudo dice [np.float32(0.7276), np.float32(0.3195)] 
2024-12-23 02:56:17.640463: Epoch time: 31.72 s 
2024-12-23 02:56:18.310034:  
2024-12-23 02:56:18.311040: Epoch 81 
2024-12-23 02:56:18.316645: Current learning rate: 0.00224 
2024-12-23 02:56:54.889301: train_loss -0.8402 
2024-12-23 02:56:54.889803: val_loss -0.4803 
2024-12-23 02:56:54.894872: Pseudo dice [np.float32(0.7308), np.float32(0.2727)] 
2024-12-23 02:56:54.899938: Epoch time: 36.58 s 
2024-12-23 02:56:55.445297:  
2024-12-23 02:56:55.446302: Epoch 82 
2024-12-23 02:56:55.451334: Current learning rate: 0.00214 
2024-12-23 02:57:27.560208: train_loss -0.8416 
2024-12-23 02:57:27.560720: val_loss -0.4798 
2024-12-23 02:57:27.566848: Pseudo dice [np.float32(0.7473), np.float32(0.2634)] 
2024-12-23 02:57:27.570876: Epoch time: 32.11 s 
2024-12-23 02:57:28.086081:  
2024-12-23 02:57:28.086081: Epoch 83 
2024-12-23 02:57:28.091641: Current learning rate: 0.00203 
2024-12-23 02:58:00.032791: train_loss -0.8419 
2024-12-23 02:58:00.032791: val_loss -0.4467 
2024-12-23 02:58:00.038899: Pseudo dice [np.float32(0.7208), np.float32(0.2539)] 
2024-12-23 02:58:00.043445: Epoch time: 31.95 s 
2024-12-23 02:58:00.560291:  
2024-12-23 02:58:00.560291: Epoch 84 
2024-12-23 02:58:00.565304: Current learning rate: 0.00192 
2024-12-23 02:58:32.698558: train_loss -0.8439 
2024-12-23 02:58:32.698558: val_loss -0.4992 
2024-12-23 02:58:32.705113: Pseudo dice [np.float32(0.7078), np.float32(0.3627)] 
2024-12-23 02:58:32.709139: Epoch time: 32.14 s 
2024-12-23 02:58:33.247986:  
2024-12-23 02:58:33.247986: Epoch 85 
2024-12-23 02:58:33.253530: Current learning rate: 0.00181 
2024-12-23 02:59:05.844977: train_loss -0.8388 
2024-12-23 02:59:05.845485: val_loss -0.4833 
2024-12-23 02:59:05.854087: Pseudo dice [np.float32(0.7243), np.float32(0.2975)] 
2024-12-23 02:59:05.858538: Epoch time: 32.6 s 
2024-12-23 02:59:06.372528:  
2024-12-23 02:59:06.372528: Epoch 86 
2024-12-23 02:59:06.378057: Current learning rate: 0.0017 
2024-12-23 02:59:39.150774: train_loss -0.8421 
2024-12-23 02:59:39.150774: val_loss -0.4971 
2024-12-23 02:59:39.156343: Pseudo dice [np.float32(0.7059), np.float32(0.3401)] 
2024-12-23 02:59:39.160358: Epoch time: 32.78 s 
2024-12-23 02:59:39.686791:  
2024-12-23 02:59:39.687794: Epoch 87 
2024-12-23 02:59:39.692825: Current learning rate: 0.00159 
2024-12-23 03:00:12.101877: train_loss -0.8527 
2024-12-23 03:00:12.102386: val_loss -0.4634 
2024-12-23 03:00:12.108187: Pseudo dice [np.float32(0.7167), np.float32(0.3318)] 
2024-12-23 03:00:12.111267: Epoch time: 32.42 s 
2024-12-23 03:00:12.628095:  
2024-12-23 03:00:12.628597: Epoch 88 
2024-12-23 03:00:12.633611: Current learning rate: 0.00148 
2024-12-23 03:00:44.826758: train_loss -0.8411 
2024-12-23 03:00:44.827760: val_loss -0.4969 
2024-12-23 03:00:44.834278: Pseudo dice [np.float32(0.7183), np.float32(0.3595)] 
2024-12-23 03:00:44.840288: Epoch time: 32.2 s 
2024-12-23 03:00:45.498532:  
2024-12-23 03:00:45.499531: Epoch 89 
2024-12-23 03:00:45.504099: Current learning rate: 0.00137 
2024-12-23 03:01:18.701862: train_loss -0.8591 
2024-12-23 03:01:18.702369: val_loss -0.5048 
2024-12-23 03:01:18.707429: Pseudo dice [np.float32(0.7258), np.float32(0.3403)] 
2024-12-23 03:01:18.709968: Epoch time: 33.2 s 
2024-12-23 03:01:19.214172:  
2024-12-23 03:01:19.214675: Epoch 90 
2024-12-23 03:01:19.219687: Current learning rate: 0.00126 
2024-12-23 03:01:51.628615: train_loss -0.8585 
2024-12-23 03:01:51.629633: val_loss -0.4467 
2024-12-23 03:01:51.636173: Pseudo dice [np.float32(0.7074), np.float32(0.255)] 
2024-12-23 03:01:51.641192: Epoch time: 32.42 s 
2024-12-23 03:01:52.193954:  
2024-12-23 03:01:52.194957: Epoch 91 
2024-12-23 03:01:52.199525: Current learning rate: 0.00115 
2024-12-23 03:02:24.772629: train_loss -0.8565 
2024-12-23 03:02:24.773628: val_loss -0.4789 
2024-12-23 03:02:24.779148: Pseudo dice [np.float32(0.7141), np.float32(0.3408)] 
2024-12-23 03:02:24.782670: Epoch time: 32.58 s 
2024-12-23 03:02:25.338449:  
2024-12-23 03:02:25.338449: Epoch 92 
2024-12-23 03:02:25.343460: Current learning rate: 0.00103 
2024-12-23 03:02:58.329886: train_loss -0.8567 
2024-12-23 03:02:58.330389: val_loss -0.4551 
2024-12-23 03:02:58.337435: Pseudo dice [np.float32(0.7176), np.float32(0.2948)] 
2024-12-23 03:02:58.340999: Epoch time: 32.99 s 
2024-12-23 03:02:58.853875:  
2024-12-23 03:02:58.854877: Epoch 93 
2024-12-23 03:02:58.860468: Current learning rate: 0.00091 
2024-12-23 03:03:31.465489: train_loss -0.8541 
2024-12-23 03:03:31.466492: val_loss -0.4899 
2024-12-23 03:03:31.472505: Pseudo dice [np.float32(0.7254), np.float32(0.3245)] 
2024-12-23 03:03:31.475514: Epoch time: 32.61 s 
2024-12-23 03:03:32.018647:  
2024-12-23 03:03:32.018647: Epoch 94 
2024-12-23 03:03:32.024122: Current learning rate: 0.00079 
2024-12-23 03:04:04.627755: train_loss -0.8519 
2024-12-23 03:04:04.629558: val_loss -0.4805 
2024-12-23 03:04:04.635096: Pseudo dice [np.float32(0.7218), np.float32(0.2942)] 
2024-12-23 03:04:04.638606: Epoch time: 32.61 s 
2024-12-23 03:04:05.181912:  
2024-12-23 03:04:05.181912: Epoch 95 
2024-12-23 03:04:05.187973: Current learning rate: 0.00067 
2024-12-23 03:04:37.878194: train_loss -0.8562 
2024-12-23 03:04:37.878708: val_loss -0.4989 
2024-12-23 03:04:37.884348: Pseudo dice [np.float32(0.7195), np.float32(0.3444)] 
2024-12-23 03:04:37.887894: Epoch time: 32.7 s 
2024-12-23 03:04:38.437994:  
2024-12-23 03:04:38.437994: Epoch 96 
2024-12-23 03:04:38.443100: Current learning rate: 0.00055 
2024-12-23 03:05:11.116416: train_loss -0.8552 
2024-12-23 03:05:11.116416: val_loss -0.4628 
2024-12-23 03:05:11.122449: Pseudo dice [np.float32(0.7106), np.float32(0.317)] 
2024-12-23 03:05:11.126465: Epoch time: 32.68 s 
2024-12-23 03:05:11.698943:  
2024-12-23 03:05:11.698943: Epoch 97 
2024-12-23 03:05:11.703954: Current learning rate: 0.00043 
2024-12-23 03:05:44.448286: train_loss -0.8567 
2024-12-23 03:05:44.448286: val_loss -0.5001 
2024-12-23 03:05:44.454389: Pseudo dice [np.float32(0.7402), np.float32(0.3448)] 
2024-12-23 03:05:44.457260: Epoch time: 32.75 s 
2024-12-23 03:05:45.213232:  
2024-12-23 03:05:45.213232: Epoch 98 
2024-12-23 03:05:45.219816: Current learning rate: 0.0003 
2024-12-23 03:06:17.559070: train_loss -0.8647 
2024-12-23 03:06:17.560076: val_loss -0.4835 
2024-12-23 03:06:17.565155: Pseudo dice [np.float32(0.708), np.float32(0.3348)] 
2024-12-23 03:06:17.568661: Epoch time: 32.35 s 
2024-12-23 03:06:18.085161:  
2024-12-23 03:06:18.085161: Epoch 99 
2024-12-23 03:06:18.090212: Current learning rate: 0.00016 
2024-12-23 03:06:50.002798: train_loss -0.8624 
2024-12-23 03:06:50.003803: val_loss -0.4639 
2024-12-23 03:06:50.010318: Pseudo dice [np.float32(0.7149), np.float32(0.3126)] 
2024-12-23 03:06:50.013826: Epoch time: 31.92 s 
2024-12-23 03:06:50.814871: Training done. 
2024-12-23 03:06:50.842872: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-23 03:06:50.848872: The split file contains 5 splits. 
2024-12-23 03:06:50.853872: Desired fold for training: 0 
2024-12-23 03:06:50.857872: This split has 224 training and 57 validation cases. 
2024-12-23 03:06:50.864875: predicting pancreas_021 
2024-12-23 03:06:50.870872: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2024-12-23 03:06:52.683883: predicting pancreas_024 
2024-12-23 03:06:52.697886: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2024-12-23 03:06:53.158056: predicting pancreas_035 
2024-12-23 03:06:53.171056: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2024-12-23 03:06:53.461872: predicting pancreas_040 
2024-12-23 03:06:53.467875: pancreas_040, shape torch.Size([1, 45, 526, 526]), rank 0 
2024-12-23 03:06:54.099451: predicting pancreas_042 
2024-12-23 03:06:54.106958: pancreas_042, shape torch.Size([1, 51, 537, 537]), rank 0 
2024-12-23 03:06:55.265093: predicting pancreas_056 
2024-12-23 03:06:55.271093: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2024-12-23 03:06:55.722188: predicting pancreas_067 
2024-12-23 03:06:55.733188: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2024-12-23 03:06:57.264605: predicting pancreas_075 
2024-12-23 03:06:57.281605: pancreas_075, shape torch.Size([1, 121, 521, 521]), rank 0 
2024-12-23 03:06:59.494918: predicting pancreas_086 
2024-12-23 03:06:59.514424: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2024-12-23 03:07:00.440713: predicting pancreas_089 
2024-12-23 03:07:00.451713: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-23 03:07:00.906759: predicting pancreas_092 
2024-12-23 03:07:00.919271: pancreas_092, shape torch.Size([1, 92, 513, 513]), rank 0 
2024-12-23 03:07:02.517469: predicting pancreas_094 
2024-12-23 03:07:02.531469: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2024-12-23 03:07:03.141537: predicting pancreas_095 
2024-12-23 03:07:03.156538: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2024-12-23 03:07:03.653096: predicting pancreas_098 
2024-12-23 03:07:03.667098: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2024-12-23 03:07:06.339725: predicting pancreas_109 
2024-12-23 03:07:06.369725: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2024-12-23 03:07:06.920775: predicting pancreas_110 
2024-12-23 03:07:06.936775: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2024-12-23 03:07:08.511423: predicting pancreas_114 
2024-12-23 03:07:08.532426: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2024-12-23 03:07:09.065470: predicting pancreas_119 
2024-12-23 03:07:09.077471: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2024-12-23 03:07:10.671169: predicting pancreas_138 
2024-12-23 03:07:10.688169: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2024-12-23 03:07:12.398818: predicting pancreas_145 
2024-12-23 03:07:12.416322: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2024-12-23 03:07:14.214526: predicting pancreas_148 
2024-12-23 03:07:14.231526: pancreas_148, shape torch.Size([1, 42, 486, 486]), rank 0 
2024-12-23 03:07:14.478553: predicting pancreas_169 
2024-12-23 03:07:14.485556: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2024-12-23 03:07:14.938094: predicting pancreas_170 
2024-12-23 03:07:14.949095: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2024-12-23 03:07:15.731189: predicting pancreas_172 
2024-12-23 03:07:15.746188: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2024-12-23 03:07:16.616321: predicting pancreas_175 
2024-12-23 03:07:16.629319: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-23 03:07:17.095538: predicting pancreas_180 
2024-12-23 03:07:17.111042: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2024-12-23 03:07:17.597084: predicting pancreas_191 
2024-12-23 03:07:17.608084: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2024-12-23 03:07:18.015188: predicting pancreas_193 
2024-12-23 03:07:18.023187: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2024-12-23 03:07:18.695522: predicting pancreas_212 
2024-12-23 03:07:18.713038: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2024-12-23 03:07:20.486699: predicting pancreas_215 
2024-12-23 03:07:20.503701: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2024-12-23 03:07:21.056274: predicting pancreas_222 
2024-12-23 03:07:21.069274: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2024-12-23 03:07:21.458304: predicting pancreas_235 
2024-12-23 03:07:21.466305: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2024-12-23 03:07:21.911337: predicting pancreas_241 
2024-12-23 03:07:21.923846: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2024-12-23 03:07:22.517916: predicting pancreas_242 
2024-12-23 03:07:22.531917: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2024-12-23 03:07:24.514651: predicting pancreas_244 
2024-12-23 03:07:24.530651: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2024-12-23 03:07:26.231609: predicting pancreas_246 
2024-12-23 03:07:26.248609: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2024-12-23 03:07:27.941819: predicting pancreas_247 
2024-12-23 03:07:27.959819: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2024-12-23 03:07:28.398857: predicting pancreas_264 
2024-12-23 03:07:28.407859: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2024-12-23 03:07:31.049181: predicting pancreas_265 
2024-12-23 03:07:31.068182: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2024-12-23 03:07:32.546160: predicting pancreas_266 
2024-12-23 03:07:32.559160: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2024-12-23 03:07:34.422416: predicting pancreas_267 
2024-12-23 03:07:34.439417: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2024-12-23 03:07:34.822453: predicting pancreas_275 
2024-12-23 03:07:34.833454: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2024-12-23 03:07:35.291548: predicting pancreas_279 
2024-12-23 03:07:35.304548: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2024-12-23 03:07:35.665633: predicting pancreas_287 
2024-12-23 03:07:35.676630: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2024-12-23 03:07:36.318003: predicting pancreas_301 
2024-12-23 03:07:36.337000: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2024-12-23 03:07:37.961147: predicting pancreas_323 
2024-12-23 03:07:37.975147: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2024-12-23 03:07:39.603142: predicting pancreas_336 
2024-12-23 03:07:39.620650: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2024-12-23 03:07:41.107717: predicting pancreas_344 
2024-12-23 03:07:41.122222: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2024-12-23 03:07:41.693758: predicting pancreas_351 
2024-12-23 03:07:41.707760: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2024-12-23 03:07:42.149298: predicting pancreas_354 
2024-12-23 03:07:42.158299: pancreas_354, shape torch.Size([1, 81, 529, 529]), rank 0 
2024-12-23 03:07:43.630941: predicting pancreas_372 
2024-12-23 03:07:43.642941: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2024-12-23 03:07:45.310076: predicting pancreas_377 
2024-12-23 03:07:45.329582: pancreas_377, shape torch.Size([1, 55, 551, 551]), rank 0 
2024-12-23 03:07:46.236150: predicting pancreas_387 
2024-12-23 03:07:46.247150: pancreas_387, shape torch.Size([1, 50, 498, 498]), rank 0 
2024-12-23 03:07:46.491806: predicting pancreas_391 
2024-12-23 03:07:46.498805: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2024-12-23 03:07:48.140412: predicting pancreas_392 
2024-12-23 03:07:48.158412: pancreas_392, shape torch.Size([1, 57, 448, 448]), rank 0 
2024-12-23 03:07:48.425111: predicting pancreas_410 
2024-12-23 03:07:48.432112: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2024-12-23 03:07:48.862242: predicting pancreas_412 
2024-12-23 03:07:48.873242: pancreas_412, shape torch.Size([1, 164, 584, 584]), rank 0 
2024-12-23 03:08:02.882328: Validation complete 
2024-12-23 03:08:02.883321: Mean Validation Dice:  0.46539918335530533 
