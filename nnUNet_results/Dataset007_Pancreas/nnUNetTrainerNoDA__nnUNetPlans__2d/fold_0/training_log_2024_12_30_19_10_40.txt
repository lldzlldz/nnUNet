
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-30 19:10:40.727999: do_dummy_2d_data_aug: False 
2024-12-30 19:10:40.734501: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-30 19:10:40.737504: The split file contains 5 splits. 
2024-12-30 19:10:40.740504: Desired fold for training: 0 
2024-12-30 19:10:40.742504: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2024-12-30 19:10:46.680487: unpacking dataset... 
2024-12-30 19:10:46.880886: unpacking done... 
2024-12-30 19:10:51.160930:  
2024-12-30 19:10:51.160930: Epoch 0 
2024-12-30 19:10:51.165982: Current learning rate: 0.01 
2024-12-30 19:11:27.405720: train_loss 0.063 
2024-12-30 19:11:27.405720: val_loss 0.0076 
2024-12-30 19:11:27.413261: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-30 19:11:27.416787: Epoch time: 36.25 s 
2024-12-30 19:11:27.419835: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-30 19:11:28.199668:  
2024-12-30 19:11:28.199668: Epoch 1 
2024-12-30 19:11:28.205199: Current learning rate: 0.00991 
2024-12-30 19:12:00.558662: train_loss -0.0342 
2024-12-30 19:12:00.559165: val_loss -0.129 
2024-12-30 19:12:00.564176: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-30 19:12:00.567687: Epoch time: 32.36 s 
2024-12-30 19:12:01.147538:  
2024-12-30 19:12:01.147538: Epoch 2 
2024-12-30 19:12:01.153697: Current learning rate: 0.00982 
2024-12-30 19:12:33.287993: train_loss -0.2359 
2024-12-30 19:12:33.288498: val_loss -0.3158 
2024-12-30 19:12:33.294590: Pseudo dice [np.float32(0.6094), np.float32(0.0)] 
2024-12-30 19:12:33.298151: Epoch time: 32.14 s 
2024-12-30 19:12:33.301690: Yayy! New best EMA pseudo Dice: 0.030500000342726707 
2024-12-30 19:12:34.185232:  
2024-12-30 19:12:34.185232: Epoch 3 
2024-12-30 19:12:34.191302: Current learning rate: 0.00973 
2024-12-30 19:13:06.341624: train_loss -0.3404 
2024-12-30 19:13:06.342127: val_loss -0.3558 
2024-12-30 19:13:06.348147: Pseudo dice [np.float32(0.6287), np.float32(0.0)] 
2024-12-30 19:13:06.350653: Epoch time: 32.16 s 
2024-12-30 19:13:06.354659: Yayy! New best EMA pseudo Dice: 0.05889999866485596 
2024-12-30 19:13:07.221833:  
2024-12-30 19:13:07.221833: Epoch 4 
2024-12-30 19:13:07.227389: Current learning rate: 0.00964 
2024-12-30 19:13:39.389295: train_loss -0.4183 
2024-12-30 19:13:39.389295: val_loss -0.4162 
2024-12-30 19:13:39.395897: Pseudo dice [np.float32(0.6003), np.float32(0.3123)] 
2024-12-30 19:13:39.399431: Epoch time: 32.17 s 
2024-12-30 19:13:39.402469: Yayy! New best EMA pseudo Dice: 0.09860000014305115 
2024-12-30 19:13:40.422427:  
2024-12-30 19:13:40.422929: Epoch 5 
2024-12-30 19:13:40.428997: Current learning rate: 0.00955 
2024-12-30 19:14:12.598460: train_loss -0.4834 
2024-12-30 19:14:12.600969: val_loss -0.462 
2024-12-30 19:14:12.606991: Pseudo dice [np.float32(0.6076), np.float32(0.3937)] 
2024-12-30 19:14:12.610500: Epoch time: 32.18 s 
2024-12-30 19:14:12.613511: Yayy! New best EMA pseudo Dice: 0.1387999951839447 
2024-12-30 19:14:13.460955:  
2024-12-30 19:14:13.460955: Epoch 6 
2024-12-30 19:14:13.467127: Current learning rate: 0.00946 
2024-12-30 19:14:45.601081: train_loss -0.4856 
2024-12-30 19:14:45.601583: val_loss -0.474 
2024-12-30 19:14:45.607606: Pseudo dice [np.float32(0.6186), np.float32(0.3867)] 
2024-12-30 19:14:45.610118: Epoch time: 32.14 s 
2024-12-30 19:14:45.614191: Yayy! New best EMA pseudo Dice: 0.17520000040531158 
2024-12-30 19:14:46.455992:  
2024-12-30 19:14:46.455992: Epoch 7 
2024-12-30 19:14:46.462010: Current learning rate: 0.00937 
2024-12-30 19:15:18.623973: train_loss -0.527 
2024-12-30 19:15:18.623973: val_loss -0.5084 
2024-12-30 19:15:18.631582: Pseudo dice [np.float32(0.6665), np.float32(0.4173)] 
2024-12-30 19:15:18.635117: Epoch time: 32.17 s 
2024-12-30 19:15:18.638666: Yayy! New best EMA pseudo Dice: 0.211899995803833 
2024-12-30 19:15:19.501828:  
2024-12-30 19:15:19.502331: Epoch 8 
2024-12-30 19:15:19.508345: Current learning rate: 0.00928 
2024-12-30 19:15:51.664107: train_loss -0.5215 
2024-12-30 19:15:51.665107: val_loss -0.4905 
2024-12-30 19:15:51.670629: Pseudo dice [np.float32(0.6494), np.float32(0.4238)] 
2024-12-30 19:15:51.674140: Epoch time: 32.16 s 
2024-12-30 19:15:51.678151: Yayy! New best EMA pseudo Dice: 0.2442999929189682 
2024-12-30 19:15:52.587925:  
2024-12-30 19:15:52.587925: Epoch 9 
2024-12-30 19:15:52.594066: Current learning rate: 0.00919 
2024-12-30 19:16:24.740609: train_loss -0.5409 
2024-12-30 19:16:24.741112: val_loss -0.4962 
2024-12-30 19:16:24.747131: Pseudo dice [np.float32(0.6576), np.float32(0.4216)] 
2024-12-30 19:16:24.750638: Epoch time: 32.15 s 
2024-12-30 19:16:24.753657: Yayy! New best EMA pseudo Dice: 0.27390000224113464 
2024-12-30 19:16:25.593051:  
2024-12-30 19:16:25.594052: Epoch 10 
2024-12-30 19:16:25.599619: Current learning rate: 0.0091 
2024-12-30 19:16:57.896330: train_loss -0.5321 
2024-12-30 19:16:57.896832: val_loss -0.4539 
2024-12-30 19:16:57.901844: Pseudo dice [np.float32(0.6496), np.float32(0.3645)] 
2024-12-30 19:16:57.905353: Epoch time: 32.3 s 
2024-12-30 19:16:57.908858: Yayy! New best EMA pseudo Dice: 0.2971999943256378 
2024-12-30 19:16:58.765122:  
2024-12-30 19:16:58.765122: Epoch 11 
2024-12-30 19:16:58.770692: Current learning rate: 0.009 
2024-12-30 19:17:30.914501: train_loss -0.5579 
2024-12-30 19:17:30.915003: val_loss -0.5244 
2024-12-30 19:17:30.919566: Pseudo dice [np.float32(0.6935), np.float32(0.42)] 
2024-12-30 19:17:30.923075: Epoch time: 32.15 s 
2024-12-30 19:17:30.926086: Yayy! New best EMA pseudo Dice: 0.3231000006198883 
2024-12-30 19:17:31.982041:  
2024-12-30 19:17:31.982041: Epoch 12 
2024-12-30 19:17:31.989094: Current learning rate: 0.00891 
2024-12-30 19:18:04.164604: train_loss -0.5676 
2024-12-30 19:18:04.164604: val_loss -0.5022 
2024-12-30 19:18:04.169621: Pseudo dice [np.float32(0.6561), np.float32(0.4268)] 
2024-12-30 19:18:04.173136: Epoch time: 32.18 s 
2024-12-30 19:18:04.176645: Yayy! New best EMA pseudo Dice: 0.3449999988079071 
2024-12-30 19:18:05.044891:  
2024-12-30 19:18:05.044891: Epoch 13 
2024-12-30 19:18:05.052007: Current learning rate: 0.00882 
2024-12-30 19:18:37.210055: train_loss -0.5575 
2024-12-30 19:18:37.210559: val_loss -0.5202 
2024-12-30 19:18:37.216582: Pseudo dice [np.float32(0.6932), np.float32(0.4647)] 
2024-12-30 19:18:37.220594: Epoch time: 32.17 s 
2024-12-30 19:18:37.224109: Yayy! New best EMA pseudo Dice: 0.3684000074863434 
2024-12-30 19:18:38.078657:  
2024-12-30 19:18:38.078657: Epoch 14 
2024-12-30 19:18:38.084188: Current learning rate: 0.00873 
2024-12-30 19:19:10.224292: train_loss -0.5838 
2024-12-30 19:19:10.225294: val_loss -0.5238 
2024-12-30 19:19:10.231320: Pseudo dice [np.float32(0.6624), np.float32(0.4689)] 
2024-12-30 19:19:10.234334: Epoch time: 32.15 s 
2024-12-30 19:19:10.237848: Yayy! New best EMA pseudo Dice: 0.3880999982357025 
2024-12-30 19:19:11.109743:  
2024-12-30 19:19:11.109743: Epoch 15 
2024-12-30 19:19:11.114863: Current learning rate: 0.00864 
2024-12-30 19:19:43.250035: train_loss -0.5781 
2024-12-30 19:19:43.250548: val_loss -0.5156 
2024-12-30 19:19:43.256165: Pseudo dice [np.float32(0.6806), np.float32(0.4089)] 
2024-12-30 19:19:43.260204: Epoch time: 32.14 s 
2024-12-30 19:19:43.263212: Yayy! New best EMA pseudo Dice: 0.40380001068115234 
2024-12-30 19:19:44.133240:  
2024-12-30 19:19:44.134245: Epoch 16 
2024-12-30 19:19:44.138259: Current learning rate: 0.00855 
2024-12-30 19:20:16.289777: train_loss -0.5879 
2024-12-30 19:20:16.289777: val_loss -0.5074 
2024-12-30 19:20:16.297296: Pseudo dice [np.float32(0.6527), np.float32(0.4141)] 
2024-12-30 19:20:16.300802: Epoch time: 32.16 s 
2024-12-30 19:20:16.303811: Yayy! New best EMA pseudo Dice: 0.41670000553131104 
2024-12-30 19:20:17.176264:  
2024-12-30 19:20:17.176264: Epoch 17 
2024-12-30 19:20:17.182330: Current learning rate: 0.00846 
2024-12-30 19:20:49.300506: train_loss -0.6104 
2024-12-30 19:20:49.300506: val_loss -0.5379 
2024-12-30 19:20:49.306517: Pseudo dice [np.float32(0.6795), np.float32(0.4585)] 
2024-12-30 19:20:49.309532: Epoch time: 32.13 s 
2024-12-30 19:20:49.314042: Yayy! New best EMA pseudo Dice: 0.4320000112056732 
2024-12-30 19:20:50.209457:  
2024-12-30 19:20:50.209457: Epoch 18 
2024-12-30 19:20:50.214993: Current learning rate: 0.00836 
2024-12-30 19:21:22.332049: train_loss -0.6192 
2024-12-30 19:21:22.333050: val_loss -0.5172 
2024-12-30 19:21:22.338567: Pseudo dice [np.float32(0.6794), np.float32(0.419)] 
2024-12-30 19:21:22.342076: Epoch time: 32.12 s 
2024-12-30 19:21:22.346087: Yayy! New best EMA pseudo Dice: 0.44369998574256897 
2024-12-30 19:21:23.219355:  
2024-12-30 19:21:23.219355: Epoch 19 
2024-12-30 19:21:23.225966: Current learning rate: 0.00827 
2024-12-30 19:21:55.294035: train_loss -0.5815 
2024-12-30 19:21:55.294035: val_loss -0.5133 
2024-12-30 19:21:55.300052: Pseudo dice [np.float32(0.6757), np.float32(0.4313)] 
2024-12-30 19:21:55.304066: Epoch time: 32.08 s 
2024-12-30 19:21:55.307578: Yayy! New best EMA pseudo Dice: 0.4546999931335449 
2024-12-30 19:21:56.400970:  
2024-12-30 19:21:56.400970: Epoch 20 
2024-12-30 19:21:56.407011: Current learning rate: 0.00818 
2024-12-30 19:22:28.320605: train_loss -0.6303 
2024-12-30 19:22:28.320605: val_loss -0.5502 
2024-12-30 19:22:28.328512: Pseudo dice [np.float32(0.6945), np.float32(0.5081)] 
2024-12-30 19:22:28.331525: Epoch time: 31.92 s 
2024-12-30 19:22:28.335035: Yayy! New best EMA pseudo Dice: 0.4693000018596649 
2024-12-30 19:22:29.259001:  
2024-12-30 19:22:29.259001: Epoch 21 
2024-12-30 19:22:29.265017: Current learning rate: 0.00809 
2024-12-30 19:23:01.187782: train_loss -0.6216 
2024-12-30 19:23:01.187782: val_loss -0.4671 
2024-12-30 19:23:01.193883: Pseudo dice [np.float32(0.6305), np.float32(0.408)] 
2024-12-30 19:23:01.197896: Epoch time: 31.93 s 
2024-12-30 19:23:01.201409: Yayy! New best EMA pseudo Dice: 0.47429999709129333 
2024-12-30 19:23:02.033195:  
2024-12-30 19:23:02.034196: Epoch 22 
2024-12-30 19:23:02.039775: Current learning rate: 0.008 
2024-12-30 19:23:33.954118: train_loss -0.6313 
2024-12-30 19:23:33.954118: val_loss -0.5131 
2024-12-30 19:23:33.960636: Pseudo dice [np.float32(0.6823), np.float32(0.4105)] 
2024-12-30 19:23:33.964155: Epoch time: 31.92 s 
2024-12-30 19:23:33.968165: Yayy! New best EMA pseudo Dice: 0.4814999997615814 
2024-12-30 19:23:34.827767:  
2024-12-30 19:23:34.827767: Epoch 23 
2024-12-30 19:23:34.833781: Current learning rate: 0.0079 
2024-12-30 19:24:06.755692: train_loss -0.6514 
2024-12-30 19:24:06.756695: val_loss -0.4907 
2024-12-30 19:24:06.762706: Pseudo dice [np.float32(0.6913), np.float32(0.3584)] 
2024-12-30 19:24:06.765713: Epoch time: 31.93 s 
2024-12-30 19:24:06.769221: Yayy! New best EMA pseudo Dice: 0.48590001463890076 
2024-12-30 19:24:07.662339:  
2024-12-30 19:24:07.663343: Epoch 24 
2024-12-30 19:24:07.668416: Current learning rate: 0.00781 
2024-12-30 19:24:39.599806: train_loss -0.6387 
2024-12-30 19:24:39.600326: val_loss -0.5296 
2024-12-30 19:24:39.607842: Pseudo dice [np.float32(0.6896), np.float32(0.4297)] 
2024-12-30 19:24:39.611350: Epoch time: 31.94 s 
2024-12-30 19:24:39.614857: Yayy! New best EMA pseudo Dice: 0.49320000410079956 
2024-12-30 19:24:40.540462:  
2024-12-30 19:24:40.541465: Epoch 25 
2024-12-30 19:24:40.546023: Current learning rate: 0.00772 
2024-12-30 19:25:12.474881: train_loss -0.6297 
2024-12-30 19:25:12.474881: val_loss -0.5066 
2024-12-30 19:25:12.481396: Pseudo dice [np.float32(0.669), np.float32(0.3916)] 
2024-12-30 19:25:12.484906: Epoch time: 31.94 s 
2024-12-30 19:25:12.487411: Yayy! New best EMA pseudo Dice: 0.4968999922275543 
2024-12-30 19:25:13.354367:  
2024-12-30 19:25:13.355370: Epoch 26 
2024-12-30 19:25:13.359963: Current learning rate: 0.00763 
2024-12-30 19:25:45.291199: train_loss -0.6558 
2024-12-30 19:25:45.292202: val_loss -0.4858 
2024-12-30 19:25:45.297490: Pseudo dice [np.float32(0.6812), np.float32(0.3514)] 
2024-12-30 19:25:45.301503: Epoch time: 31.94 s 
2024-12-30 19:25:45.305015: Yayy! New best EMA pseudo Dice: 0.49889999628067017 
2024-12-30 19:25:46.147345:  
2024-12-30 19:25:46.147345: Epoch 27 
2024-12-30 19:25:46.152754: Current learning rate: 0.00753 
2024-12-30 19:26:18.091784: train_loss -0.671 
2024-12-30 19:26:18.092310: val_loss -0.5375 
2024-12-30 19:26:18.099379: Pseudo dice [np.float32(0.7197), np.float32(0.4426)] 
2024-12-30 19:26:18.102430: Epoch time: 31.95 s 
2024-12-30 19:26:18.105974: Yayy! New best EMA pseudo Dice: 0.507099986076355 
2024-12-30 19:26:19.100297:  
2024-12-30 19:26:19.100297: Epoch 28 
2024-12-30 19:26:19.106319: Current learning rate: 0.00744 
2024-12-30 19:26:51.031389: train_loss -0.6708 
2024-12-30 19:26:51.032417: val_loss -0.4838 
2024-12-30 19:26:51.037497: Pseudo dice [np.float32(0.683), np.float32(0.3228)] 
2024-12-30 19:26:51.041548: Epoch time: 31.93 s 
2024-12-30 19:26:51.602399:  
2024-12-30 19:26:51.603403: Epoch 29 
2024-12-30 19:26:51.607967: Current learning rate: 0.00735 
2024-12-30 19:27:23.527853: train_loss -0.6777 
2024-12-30 19:27:23.528355: val_loss -0.5031 
2024-12-30 19:27:23.534372: Pseudo dice [np.float32(0.6755), np.float32(0.4303)] 
2024-12-30 19:27:23.536877: Epoch time: 31.93 s 
2024-12-30 19:27:23.540891: Yayy! New best EMA pseudo Dice: 0.5113000273704529 
2024-12-30 19:27:24.404151:  
2024-12-30 19:27:24.404654: Epoch 30 
2024-12-30 19:27:24.410209: Current learning rate: 0.00725 
2024-12-30 19:27:56.322074: train_loss -0.6807 
2024-12-30 19:27:56.323077: val_loss -0.461 
2024-12-30 19:27:56.328093: Pseudo dice [np.float32(0.712), np.float32(0.2799)] 
2024-12-30 19:27:56.331601: Epoch time: 31.92 s 
2024-12-30 19:27:56.904085:  
2024-12-30 19:27:56.904588: Epoch 31 
2024-12-30 19:27:56.909631: Current learning rate: 0.00716 
2024-12-30 19:28:28.838739: train_loss -0.683 
2024-12-30 19:28:28.838739: val_loss -0.5172 
2024-12-30 19:28:28.846256: Pseudo dice [np.float32(0.7001), np.float32(0.412)] 
2024-12-30 19:28:28.850264: Epoch time: 31.94 s 
2024-12-30 19:28:28.853773: Yayy! New best EMA pseudo Dice: 0.5144000053405762 
2024-12-30 19:28:29.709982:  
2024-12-30 19:28:29.710485: Epoch 32 
2024-12-30 19:28:29.716502: Current learning rate: 0.00707 
2024-12-30 19:29:01.643084: train_loss -0.6752 
2024-12-30 19:29:01.643598: val_loss -0.4701 
2024-12-30 19:29:01.649177: Pseudo dice [np.float32(0.6298), np.float32(0.4162)] 
2024-12-30 19:29:01.652755: Epoch time: 31.93 s 
2024-12-30 19:29:01.655815: Yayy! New best EMA pseudo Dice: 0.5152999758720398 
2024-12-30 19:29:02.523793:  
2024-12-30 19:29:02.523793: Epoch 33 
2024-12-30 19:29:02.530338: Current learning rate: 0.00697 
2024-12-30 19:29:34.500988: train_loss -0.7001 
2024-12-30 19:29:34.500988: val_loss -0.482 
2024-12-30 19:29:34.508620: Pseudo dice [np.float32(0.6827), np.float32(0.3687)] 
2024-12-30 19:29:34.511226: Epoch time: 31.98 s 
2024-12-30 19:29:34.515274: Yayy! New best EMA pseudo Dice: 0.5163000226020813 
2024-12-30 19:29:35.374726:  
2024-12-30 19:29:35.374726: Epoch 34 
2024-12-30 19:29:35.380241: Current learning rate: 0.00688 
2024-12-30 19:30:07.304769: train_loss -0.7088 
2024-12-30 19:30:07.305772: val_loss -0.5388 
2024-12-30 19:30:07.311782: Pseudo dice [np.float32(0.7095), np.float32(0.4594)] 
2024-12-30 19:30:07.314790: Epoch time: 31.93 s 
2024-12-30 19:30:07.318300: Yayy! New best EMA pseudo Dice: 0.5231000185012817 
2024-12-30 19:30:08.405753:  
2024-12-30 19:30:08.405753: Epoch 35 
2024-12-30 19:30:08.411787: Current learning rate: 0.00679 
2024-12-30 19:30:40.322210: train_loss -0.7164 
2024-12-30 19:30:40.322210: val_loss -0.5159 
2024-12-30 19:30:40.328229: Pseudo dice [np.float32(0.7014), np.float32(0.4465)] 
2024-12-30 19:30:40.331737: Epoch time: 31.92 s 
2024-12-30 19:30:40.334749: Yayy! New best EMA pseudo Dice: 0.5281999707221985 
2024-12-30 19:30:41.204493:  
2024-12-30 19:30:41.204997: Epoch 36 
2024-12-30 19:30:41.210011: Current learning rate: 0.00669 
2024-12-30 19:31:13.101096: train_loss -0.7011 
2024-12-30 19:31:13.101096: val_loss -0.5537 
2024-12-30 19:31:13.107610: Pseudo dice [np.float32(0.6685), np.float32(0.559)] 
2024-12-30 19:31:13.110116: Epoch time: 31.9 s 
2024-12-30 19:31:13.113624: Yayy! New best EMA pseudo Dice: 0.5368000268936157 
2024-12-30 19:31:13.965872:  
2024-12-30 19:31:13.966875: Epoch 37 
2024-12-30 19:31:13.971969: Current learning rate: 0.0066 
2024-12-30 19:31:45.850794: train_loss -0.7057 
2024-12-30 19:31:45.851802: val_loss -0.492 
2024-12-30 19:31:45.857818: Pseudo dice [np.float32(0.692), np.float32(0.3602)] 
2024-12-30 19:31:45.860836: Epoch time: 31.89 s 
2024-12-30 19:31:46.448479:  
2024-12-30 19:31:46.448479: Epoch 38 
2024-12-30 19:31:46.452988: Current learning rate: 0.0065 
2024-12-30 19:32:18.348203: train_loss -0.7356 
2024-12-30 19:32:18.349203: val_loss -0.5245 
2024-12-30 19:32:18.355721: Pseudo dice [np.float32(0.702), np.float32(0.4491)] 
2024-12-30 19:32:18.359227: Epoch time: 31.9 s 
2024-12-30 19:32:18.362235: Yayy! New best EMA pseudo Dice: 0.5396999716758728 
2024-12-30 19:32:19.224579:  
2024-12-30 19:32:19.225579: Epoch 39 
2024-12-30 19:32:19.231189: Current learning rate: 0.00641 
2024-12-30 19:32:51.114328: train_loss -0.7393 
2024-12-30 19:32:51.114328: val_loss -0.55 
2024-12-30 19:32:51.120849: Pseudo dice [np.float32(0.7043), np.float32(0.4707)] 
2024-12-30 19:32:51.123356: Epoch time: 31.89 s 
2024-12-30 19:32:51.128371: Yayy! New best EMA pseudo Dice: 0.5444999933242798 
2024-12-30 19:32:52.050836:  
2024-12-30 19:32:52.050836: Epoch 40 
2024-12-30 19:32:52.055866: Current learning rate: 0.00631 
2024-12-30 19:33:23.957146: train_loss -0.7434 
2024-12-30 19:33:23.958650: val_loss -0.5269 
2024-12-30 19:33:23.964674: Pseudo dice [np.float32(0.7278), np.float32(0.4399)] 
2024-12-30 19:33:23.967181: Epoch time: 31.91 s 
2024-12-30 19:33:23.971200: Yayy! New best EMA pseudo Dice: 0.5483999848365784 
2024-12-30 19:33:24.876763:  
2024-12-30 19:33:24.876763: Epoch 41 
2024-12-30 19:33:24.881772: Current learning rate: 0.00622 
2024-12-30 19:33:56.772206: train_loss -0.7398 
2024-12-30 19:33:56.773708: val_loss -0.5287 
2024-12-30 19:33:56.777217: Pseudo dice [np.float32(0.701), np.float32(0.4181)] 
2024-12-30 19:33:56.780726: Epoch time: 31.9 s 
2024-12-30 19:33:56.783734: Yayy! New best EMA pseudo Dice: 0.5494999885559082 
2024-12-30 19:33:57.618197:  
2024-12-30 19:33:57.618703: Epoch 42 
2024-12-30 19:33:57.623225: Current learning rate: 0.00612 
2024-12-30 19:34:29.523318: train_loss -0.7524 
2024-12-30 19:34:29.523821: val_loss -0.503 
2024-12-30 19:34:29.528836: Pseudo dice [np.float32(0.7028), np.float32(0.3842)] 
2024-12-30 19:34:29.532348: Epoch time: 31.9 s 
2024-12-30 19:34:30.244580:  
2024-12-30 19:34:30.244580: Epoch 43 
2024-12-30 19:34:30.249645: Current learning rate: 0.00603 
2024-12-30 19:35:02.142850: train_loss -0.7444 
2024-12-30 19:35:02.142850: val_loss -0.4751 
2024-12-30 19:35:02.149372: Pseudo dice [np.float32(0.6919), np.float32(0.3339)] 
2024-12-30 19:35:02.152884: Epoch time: 31.9 s 
2024-12-30 19:35:02.719532:  
2024-12-30 19:35:02.719532: Epoch 44 
2024-12-30 19:35:02.724545: Current learning rate: 0.00593 
2024-12-30 19:35:34.612839: train_loss -0.7358 
2024-12-30 19:35:34.613352: val_loss -0.5098 
2024-12-30 19:35:34.618922: Pseudo dice [np.float32(0.6639), np.float32(0.447)] 
2024-12-30 19:35:34.621952: Epoch time: 31.89 s 
2024-12-30 19:35:35.184110:  
2024-12-30 19:35:35.184110: Epoch 45 
2024-12-30 19:35:35.188654: Current learning rate: 0.00584 
2024-12-30 19:36:07.078405: train_loss -0.7559 
2024-12-30 19:36:07.078405: val_loss -0.5451 
2024-12-30 19:36:07.084429: Pseudo dice [np.float32(0.702), np.float32(0.5199)] 
2024-12-30 19:36:07.088442: Epoch time: 31.89 s 
2024-12-30 19:36:07.091958: Yayy! New best EMA pseudo Dice: 0.5527999997138977 
2024-12-30 19:36:07.977943:  
2024-12-30 19:36:07.977943: Epoch 46 
2024-12-30 19:36:07.984069: Current learning rate: 0.00574 
2024-12-30 19:36:39.885281: train_loss -0.746 
2024-12-30 19:36:39.885281: val_loss -0.4975 
2024-12-30 19:36:39.891295: Pseudo dice [np.float32(0.6988), np.float32(0.364)] 
2024-12-30 19:36:39.894802: Epoch time: 31.91 s 
2024-12-30 19:36:40.446197:  
2024-12-30 19:36:40.446197: Epoch 47 
2024-12-30 19:36:40.451206: Current learning rate: 0.00565 
2024-12-30 19:37:12.350927: train_loss -0.7557 
2024-12-30 19:37:12.351429: val_loss -0.518 
2024-12-30 19:37:12.356512: Pseudo dice [np.float32(0.7024), np.float32(0.3782)] 
2024-12-30 19:37:12.359586: Epoch time: 31.91 s 
2024-12-30 19:37:12.907402:  
2024-12-30 19:37:12.907402: Epoch 48 
2024-12-30 19:37:12.912435: Current learning rate: 0.00555 
2024-12-30 19:37:44.806833: train_loss -0.7478 
2024-12-30 19:37:44.807837: val_loss -0.4894 
2024-12-30 19:37:44.812849: Pseudo dice [np.float32(0.6788), np.float32(0.3943)] 
2024-12-30 19:37:44.815354: Epoch time: 31.9 s 
2024-12-30 19:37:45.374040:  
2024-12-30 19:37:45.374040: Epoch 49 
2024-12-30 19:37:45.379087: Current learning rate: 0.00546 
2024-12-30 19:38:17.269246: train_loss -0.7612 
2024-12-30 19:38:17.269246: val_loss -0.5111 
2024-12-30 19:38:17.276768: Pseudo dice [np.float32(0.6782), np.float32(0.4452)] 
2024-12-30 19:38:17.279274: Epoch time: 31.9 s 
2024-12-30 19:38:18.183132:  
2024-12-30 19:38:18.183132: Epoch 50 
2024-12-30 19:38:18.188682: Current learning rate: 0.00536 
2024-12-30 19:38:50.096213: train_loss -0.7554 
2024-12-30 19:38:50.097733: val_loss -0.5076 
2024-12-30 19:38:50.101208: Pseudo dice [np.float32(0.7124), np.float32(0.3987)] 
2024-12-30 19:38:50.104727: Epoch time: 31.91 s 
2024-12-30 19:38:50.814602:  
2024-12-30 19:38:50.814602: Epoch 51 
2024-12-30 19:38:50.820174: Current learning rate: 0.00526 
2024-12-30 19:39:22.718022: train_loss -0.7762 
2024-12-30 19:39:22.718022: val_loss -0.5168 
2024-12-30 19:39:22.724051: Pseudo dice [np.float32(0.6859), np.float32(0.4631)] 
2024-12-30 19:39:22.727566: Epoch time: 31.9 s 
2024-12-30 19:39:23.296578:  
2024-12-30 19:39:23.296578: Epoch 52 
2024-12-30 19:39:23.302131: Current learning rate: 0.00517 
2024-12-30 19:39:55.191211: train_loss -0.7804 
2024-12-30 19:39:55.191714: val_loss -0.4974 
2024-12-30 19:39:55.197727: Pseudo dice [np.float32(0.7283), np.float32(0.3762)] 
2024-12-30 19:39:55.200233: Epoch time: 31.9 s 
2024-12-30 19:39:55.769644:  
2024-12-30 19:39:55.769644: Epoch 53 
2024-12-30 19:39:55.774680: Current learning rate: 0.00507 
2024-12-30 19:40:27.665460: train_loss -0.7934 
2024-12-30 19:40:27.666463: val_loss -0.5283 
2024-12-30 19:40:27.671492: Pseudo dice [np.float32(0.7124), np.float32(0.4422)] 
2024-12-30 19:40:27.675499: Epoch time: 31.9 s 
2024-12-30 19:40:27.679008: Yayy! New best EMA pseudo Dice: 0.5551000237464905 
2024-12-30 19:40:28.517076:  
2024-12-30 19:40:28.517579: Epoch 54 
2024-12-30 19:40:28.523178: Current learning rate: 0.00497 
2024-12-30 19:41:00.423691: train_loss -0.7637 
2024-12-30 19:41:00.423691: val_loss -0.5235 
2024-12-30 19:41:00.430274: Pseudo dice [np.float32(0.709), np.float32(0.439)] 
2024-12-30 19:41:00.433890: Epoch time: 31.91 s 
2024-12-30 19:41:00.436935: Yayy! New best EMA pseudo Dice: 0.5569999814033508 
2024-12-30 19:41:01.277209:  
2024-12-30 19:41:01.278213: Epoch 55 
2024-12-30 19:41:01.282923: Current learning rate: 0.00487 
2024-12-30 19:41:33.163965: train_loss -0.7866 
2024-12-30 19:41:33.164968: val_loss -0.5137 
2024-12-30 19:41:33.169980: Pseudo dice [np.float32(0.7222), np.float32(0.388)] 
2024-12-30 19:41:33.173988: Epoch time: 31.89 s 
2024-12-30 19:41:33.733578:  
2024-12-30 19:41:33.734578: Epoch 56 
2024-12-30 19:41:33.739128: Current learning rate: 0.00478 
2024-12-30 19:42:05.663505: train_loss -0.784 
2024-12-30 19:42:05.664505: val_loss -0.5167 
2024-12-30 19:42:05.669524: Pseudo dice [np.float32(0.6969), np.float32(0.4333)] 
2024-12-30 19:42:05.672531: Epoch time: 31.93 s 
2024-12-30 19:42:05.676612: Yayy! New best EMA pseudo Dice: 0.5576000213623047 
2024-12-30 19:42:06.518123:  
2024-12-30 19:42:06.519123: Epoch 57 
2024-12-30 19:42:06.524702: Current learning rate: 0.00468 
2024-12-30 19:42:38.427234: train_loss -0.7953 
2024-12-30 19:42:38.427234: val_loss -0.5038 
2024-12-30 19:42:38.434753: Pseudo dice [np.float32(0.7086), np.float32(0.4256)] 
2024-12-30 19:42:38.438760: Epoch time: 31.91 s 
2024-12-30 19:42:38.441265: Yayy! New best EMA pseudo Dice: 0.5586000084877014 
2024-12-30 19:42:39.299918:  
2024-12-30 19:42:39.300919: Epoch 58 
2024-12-30 19:42:39.305986: Current learning rate: 0.00458 
2024-12-30 19:43:11.215019: train_loss -0.8036 
2024-12-30 19:43:11.215019: val_loss -0.4887 
2024-12-30 19:43:11.221037: Pseudo dice [np.float32(0.7227), np.float32(0.3427)] 
2024-12-30 19:43:11.225051: Epoch time: 31.92 s 
2024-12-30 19:43:11.949727:  
2024-12-30 19:43:11.949727: Epoch 59 
2024-12-30 19:43:11.956390: Current learning rate: 0.00448 
2024-12-30 19:43:43.856524: train_loss -0.803 
2024-12-30 19:43:43.857026: val_loss -0.5368 
2024-12-30 19:43:43.863040: Pseudo dice [np.float32(0.7406), np.float32(0.3944)] 
2024-12-30 19:43:43.865546: Epoch time: 31.91 s 
2024-12-30 19:43:44.436721:  
2024-12-30 19:43:44.437223: Epoch 60 
2024-12-30 19:43:44.442260: Current learning rate: 0.00438 
2024-12-30 19:44:16.332859: train_loss -0.8053 
2024-12-30 19:44:16.332859: val_loss -0.5263 
2024-12-30 19:44:16.339372: Pseudo dice [np.float32(0.7231), np.float32(0.3806)] 
2024-12-30 19:44:16.342880: Epoch time: 31.9 s 
2024-12-30 19:44:16.915801:  
2024-12-30 19:44:16.916801: Epoch 61 
2024-12-30 19:44:16.921813: Current learning rate: 0.00429 
2024-12-30 19:44:48.857994: train_loss -0.8063 
2024-12-30 19:44:48.858999: val_loss -0.5311 
2024-12-30 19:44:48.864023: Pseudo dice [np.float32(0.7129), np.float32(0.4698)] 
2024-12-30 19:44:48.867533: Epoch time: 31.94 s 
2024-12-30 19:44:48.870547: Yayy! New best EMA pseudo Dice: 0.5601000189781189 
2024-12-30 19:44:49.722331:  
2024-12-30 19:44:49.722331: Epoch 62 
2024-12-30 19:44:49.728395: Current learning rate: 0.00419 
2024-12-30 19:45:21.646916: train_loss -0.8094 
2024-12-30 19:45:21.646916: val_loss -0.5321 
2024-12-30 19:45:21.652944: Pseudo dice [np.float32(0.6942), np.float32(0.4498)] 
2024-12-30 19:45:21.656958: Epoch time: 31.93 s 
2024-12-30 19:45:21.659468: Yayy! New best EMA pseudo Dice: 0.5612999796867371 
2024-12-30 19:45:22.512821:  
2024-12-30 19:45:22.512821: Epoch 63 
2024-12-30 19:45:22.517834: Current learning rate: 0.00409 
2024-12-30 19:45:54.402261: train_loss -0.803 
2024-12-30 19:45:54.402261: val_loss -0.5084 
2024-12-30 19:45:54.408285: Pseudo dice [np.float32(0.7268), np.float32(0.3964)] 
2024-12-30 19:45:54.410863: Epoch time: 31.89 s 
2024-12-30 19:45:54.413889: Yayy! New best EMA pseudo Dice: 0.5612999796867371 
2024-12-30 19:45:55.260182:  
2024-12-30 19:45:55.260182: Epoch 64 
2024-12-30 19:45:55.266265: Current learning rate: 0.00399 
2024-12-30 19:46:27.131604: train_loss -0.8131 
2024-12-30 19:46:27.131604: val_loss -0.5334 
2024-12-30 19:46:27.136617: Pseudo dice [np.float32(0.7205), np.float32(0.425)] 
2024-12-30 19:46:27.140626: Epoch time: 31.87 s 
2024-12-30 19:46:27.143133: Yayy! New best EMA pseudo Dice: 0.5623999834060669 
2024-12-30 19:46:28.078801:  
2024-12-30 19:46:28.078801: Epoch 65 
2024-12-30 19:46:28.084352: Current learning rate: 0.00389 
2024-12-30 19:46:59.966689: train_loss -0.8242 
2024-12-30 19:46:59.967689: val_loss -0.4827 
2024-12-30 19:46:59.973202: Pseudo dice [np.float32(0.7295), np.float32(0.3161)] 
2024-12-30 19:46:59.976709: Epoch time: 31.89 s 
2024-12-30 19:47:00.707344:  
2024-12-30 19:47:00.707344: Epoch 66 
2024-12-30 19:47:00.712355: Current learning rate: 0.00379 
2024-12-30 19:47:32.590101: train_loss -0.8212 
2024-12-30 19:47:32.590101: val_loss -0.5102 
2024-12-30 19:47:32.596627: Pseudo dice [np.float32(0.7268), np.float32(0.3941)] 
2024-12-30 19:47:32.600141: Epoch time: 31.88 s 
2024-12-30 19:47:33.166388:  
2024-12-30 19:47:33.167388: Epoch 67 
2024-12-30 19:47:33.172407: Current learning rate: 0.00369 
2024-12-30 19:48:05.045668: train_loss -0.8175 
2024-12-30 19:48:05.045668: val_loss -0.4928 
2024-12-30 19:48:05.051839: Pseudo dice [np.float32(0.7255), np.float32(0.3727)] 
2024-12-30 19:48:05.054349: Epoch time: 31.88 s 
2024-12-30 19:48:05.631790:  
2024-12-30 19:48:05.632793: Epoch 68 
2024-12-30 19:48:05.637835: Current learning rate: 0.00359 
2024-12-30 19:48:37.507241: train_loss -0.8326 
2024-12-30 19:48:37.507744: val_loss -0.5046 
2024-12-30 19:48:37.512794: Pseudo dice [np.float32(0.7347), np.float32(0.339)] 
2024-12-30 19:48:37.516306: Epoch time: 31.88 s 
2024-12-30 19:48:38.095319:  
2024-12-30 19:48:38.095319: Epoch 69 
2024-12-30 19:48:38.100401: Current learning rate: 0.00349 
2024-12-30 19:49:09.973499: train_loss -0.8235 
2024-12-30 19:49:09.973499: val_loss -0.5127 
2024-12-30 19:49:09.979030: Pseudo dice [np.float32(0.7011), np.float32(0.4406)] 
2024-12-30 19:49:09.982539: Epoch time: 31.88 s 
2024-12-30 19:49:10.557102:  
2024-12-30 19:49:10.557102: Epoch 70 
2024-12-30 19:49:10.562184: Current learning rate: 0.00338 
2024-12-30 19:49:42.417908: train_loss -0.8208 
2024-12-30 19:49:42.418928: val_loss -0.4925 
2024-12-30 19:49:42.424073: Pseudo dice [np.float32(0.716), np.float32(0.3554)] 
2024-12-30 19:49:42.428107: Epoch time: 31.86 s 
2024-12-30 19:49:43.006574:  
2024-12-30 19:49:43.006574: Epoch 71 
2024-12-30 19:49:43.012110: Current learning rate: 0.00328 
2024-12-30 19:50:14.873733: train_loss -0.827 
2024-12-30 19:50:14.874235: val_loss -0.4874 
2024-12-30 19:50:14.879251: Pseudo dice [np.float32(0.6979), np.float32(0.3956)] 
2024-12-30 19:50:14.882764: Epoch time: 31.87 s 
2024-12-30 19:50:15.457507:  
2024-12-30 19:50:15.457507: Epoch 72 
2024-12-30 19:50:15.463051: Current learning rate: 0.00318 
2024-12-30 19:50:47.324835: train_loss -0.8396 
2024-12-30 19:50:47.324835: val_loss -0.5183 
2024-12-30 19:50:47.330850: Pseudo dice [np.float32(0.7302), np.float32(0.398)] 
2024-12-30 19:50:47.333864: Epoch time: 31.87 s 
2024-12-30 19:50:47.918659:  
2024-12-30 19:50:47.919161: Epoch 73 
2024-12-30 19:50:47.924202: Current learning rate: 0.00308 
2024-12-30 19:51:19.814533: train_loss -0.8492 
2024-12-30 19:51:19.815537: val_loss -0.5214 
2024-12-30 19:51:19.822108: Pseudo dice [np.float32(0.7375), np.float32(0.385)] 
2024-12-30 19:51:19.825190: Epoch time: 31.9 s 
2024-12-30 19:51:20.598763:  
2024-12-30 19:51:20.599762: Epoch 74 
2024-12-30 19:51:20.602817: Current learning rate: 0.00297 
2024-12-30 19:51:52.465592: train_loss -0.8429 
2024-12-30 19:51:52.466095: val_loss -0.4843 
2024-12-30 19:51:52.472116: Pseudo dice [np.float32(0.7301), np.float32(0.3293)] 
2024-12-30 19:51:52.475650: Epoch time: 31.87 s 
2024-12-30 19:51:53.054990:  
2024-12-30 19:51:53.055993: Epoch 75 
2024-12-30 19:51:53.060019: Current learning rate: 0.00287 
2024-12-30 19:52:24.933095: train_loss -0.8417 
2024-12-30 19:52:24.933095: val_loss -0.5178 
2024-12-30 19:52:24.939113: Pseudo dice [np.float32(0.7205), np.float32(0.3951)] 
2024-12-30 19:52:24.942128: Epoch time: 31.88 s 
2024-12-30 19:52:25.526179:  
2024-12-30 19:52:25.526179: Epoch 76 
2024-12-30 19:52:25.531260: Current learning rate: 0.00277 
2024-12-30 19:52:57.400197: train_loss -0.8404 
2024-12-30 19:52:57.400197: val_loss -0.513 
2024-12-30 19:52:57.406209: Pseudo dice [np.float32(0.7055), np.float32(0.4405)] 
2024-12-30 19:52:57.409216: Epoch time: 31.88 s 
2024-12-30 19:52:57.998473:  
2024-12-30 19:52:57.998978: Epoch 77 
2024-12-30 19:52:58.003998: Current learning rate: 0.00266 
2024-12-30 19:53:29.881238: train_loss -0.8523 
2024-12-30 19:53:29.882239: val_loss -0.4969 
2024-12-30 19:53:29.887758: Pseudo dice [np.float32(0.7421), np.float32(0.3559)] 
2024-12-30 19:53:29.890264: Epoch time: 31.88 s 
2024-12-30 19:53:30.477302:  
2024-12-30 19:53:30.477302: Epoch 78 
2024-12-30 19:53:30.482315: Current learning rate: 0.00256 
2024-12-30 19:54:02.365710: train_loss -0.8545 
2024-12-30 19:54:02.366709: val_loss -0.5146 
2024-12-30 19:54:02.372222: Pseudo dice [np.float32(0.7234), np.float32(0.416)] 
2024-12-30 19:54:02.375730: Epoch time: 31.89 s 
2024-12-30 19:54:02.963317:  
2024-12-30 19:54:02.963317: Epoch 79 
2024-12-30 19:54:02.968878: Current learning rate: 0.00245 
2024-12-30 19:54:34.847749: train_loss -0.8554 
2024-12-30 19:54:34.847749: val_loss -0.4986 
2024-12-30 19:54:34.854266: Pseudo dice [np.float32(0.7348), np.float32(0.3291)] 
2024-12-30 19:54:34.857779: Epoch time: 31.89 s 
2024-12-30 19:54:35.444841:  
2024-12-30 19:54:35.445842: Epoch 80 
2024-12-30 19:54:35.450905: Current learning rate: 0.00235 
2024-12-30 19:55:07.324765: train_loss -0.8494 
2024-12-30 19:55:07.326275: val_loss -0.5055 
2024-12-30 19:55:07.331370: Pseudo dice [np.float32(0.7166), np.float32(0.382)] 
2024-12-30 19:55:07.334946: Epoch time: 31.88 s 
2024-12-30 19:55:08.114416:  
2024-12-30 19:55:08.114416: Epoch 81 
2024-12-30 19:55:08.120450: Current learning rate: 0.00224 
2024-12-30 19:55:39.990801: train_loss -0.8571 
2024-12-30 19:55:39.991804: val_loss -0.5084 
2024-12-30 19:55:39.997820: Pseudo dice [np.float32(0.7244), np.float32(0.3541)] 
2024-12-30 19:55:40.000831: Epoch time: 31.88 s 
2024-12-30 19:55:40.594331:  
2024-12-30 19:55:40.595834: Epoch 82 
2024-12-30 19:55:40.600847: Current learning rate: 0.00214 
2024-12-30 19:56:12.468885: train_loss -0.8635 
2024-12-30 19:56:12.470409: val_loss -0.5006 
2024-12-30 19:56:12.476435: Pseudo dice [np.float32(0.7143), np.float32(0.3449)] 
2024-12-30 19:56:12.479565: Epoch time: 31.87 s 
2024-12-30 19:56:13.055156:  
2024-12-30 19:56:13.055156: Epoch 83 
2024-12-30 19:56:13.060717: Current learning rate: 0.00203 
2024-12-30 19:56:44.959611: train_loss -0.8613 
2024-12-30 19:56:44.960114: val_loss -0.4855 
2024-12-30 19:56:44.965125: Pseudo dice [np.float32(0.7192), np.float32(0.3153)] 
2024-12-30 19:56:44.968634: Epoch time: 31.9 s 
2024-12-30 19:56:45.527490:  
2024-12-30 19:56:45.528490: Epoch 84 
2024-12-30 19:56:45.534003: Current learning rate: 0.00192 
2024-12-30 19:57:17.413068: train_loss -0.858 
2024-12-30 19:57:17.413068: val_loss -0.5158 
2024-12-30 19:57:17.420586: Pseudo dice [np.float32(0.6916), np.float32(0.3909)] 
2024-12-30 19:57:17.424092: Epoch time: 31.89 s 
2024-12-30 19:57:17.984576:  
2024-12-30 19:57:17.984576: Epoch 85 
2024-12-30 19:57:17.990135: Current learning rate: 0.00181 
2024-12-30 19:57:49.869087: train_loss -0.8537 
2024-12-30 19:57:49.869592: val_loss -0.4926 
2024-12-30 19:57:49.874685: Pseudo dice [np.float32(0.7343), np.float32(0.3381)] 
2024-12-30 19:57:49.878776: Epoch time: 31.89 s 
2024-12-30 19:57:50.429792:  
2024-12-30 19:57:50.430795: Epoch 86 
2024-12-30 19:57:50.435336: Current learning rate: 0.0017 
2024-12-30 19:58:22.309521: train_loss -0.8646 
2024-12-30 19:58:22.310045: val_loss -0.488 
2024-12-30 19:58:22.315150: Pseudo dice [np.float32(0.6955), np.float32(0.3587)] 
2024-12-30 19:58:22.318687: Epoch time: 31.88 s 
2024-12-30 19:58:22.864800:  
2024-12-30 19:58:22.864800: Epoch 87 
2024-12-30 19:58:22.870365: Current learning rate: 0.00159 
2024-12-30 19:58:54.759898: train_loss -0.8655 
2024-12-30 19:58:54.760413: val_loss -0.5075 
2024-12-30 19:58:54.766000: Pseudo dice [np.float32(0.7425), np.float32(0.344)] 
2024-12-30 19:58:54.769506: Epoch time: 31.9 s 
2024-12-30 19:58:55.318348:  
2024-12-30 19:58:55.318348: Epoch 88 
2024-12-30 19:58:55.322361: Current learning rate: 0.00148 
2024-12-30 19:59:27.244979: train_loss -0.8683 
2024-12-30 19:59:27.244979: val_loss -0.5093 
2024-12-30 19:59:27.256509: Pseudo dice [np.float32(0.7343), np.float32(0.3816)] 
2024-12-30 19:59:27.260019: Epoch time: 31.93 s 
2024-12-30 19:59:28.029291:  
2024-12-30 19:59:28.029794: Epoch 89 
2024-12-30 19:59:28.034806: Current learning rate: 0.00137 
2024-12-30 19:59:59.937649: train_loss -0.8705 
2024-12-30 19:59:59.938151: val_loss -0.4947 
2024-12-30 19:59:59.944221: Pseudo dice [np.float32(0.7068), np.float32(0.3918)] 
2024-12-30 19:59:59.947254: Epoch time: 31.91 s 
2024-12-30 20:00:00.496835:  
2024-12-30 20:00:00.497340: Epoch 90 
2024-12-30 20:00:00.501895: Current learning rate: 0.00126 
2024-12-30 20:00:32.406001: train_loss -0.8705 
2024-12-30 20:00:32.407503: val_loss -0.5004 
2024-12-30 20:00:32.415029: Pseudo dice [np.float32(0.7194), np.float32(0.3562)] 
2024-12-30 20:00:32.418538: Epoch time: 31.91 s 
2024-12-30 20:00:32.967397:  
2024-12-30 20:00:32.968397: Epoch 91 
2024-12-30 20:00:32.973454: Current learning rate: 0.00115 
2024-12-30 20:01:04.894346: train_loss -0.8687 
2024-12-30 20:01:04.895346: val_loss -0.4715 
2024-12-30 20:01:04.900866: Pseudo dice [np.float32(0.693), np.float32(0.3128)] 
2024-12-30 20:01:04.904376: Epoch time: 31.93 s 
2024-12-30 20:01:05.462197:  
2024-12-30 20:01:05.463197: Epoch 92 
2024-12-30 20:01:05.467756: Current learning rate: 0.00103 
2024-12-30 20:01:37.370554: train_loss -0.8763 
2024-12-30 20:01:37.371555: val_loss -0.5113 
2024-12-30 20:01:37.378080: Pseudo dice [np.float32(0.7186), np.float32(0.3746)] 
2024-12-30 20:01:37.382092: Epoch time: 31.91 s 
2024-12-30 20:01:37.944542:  
2024-12-30 20:01:37.945050: Epoch 93 
2024-12-30 20:01:37.950120: Current learning rate: 0.00091 
2024-12-30 20:02:09.861508: train_loss -0.8779 
2024-12-30 20:02:09.862012: val_loss -0.4967 
2024-12-30 20:02:09.867023: Pseudo dice [np.float32(0.7443), np.float32(0.3667)] 
2024-12-30 20:02:09.870530: Epoch time: 31.92 s 
2024-12-30 20:02:10.422633:  
2024-12-30 20:02:10.423637: Epoch 94 
2024-12-30 20:02:10.428221: Current learning rate: 0.00079 
2024-12-30 20:02:42.325907: train_loss -0.8763 
2024-12-30 20:02:42.325907: val_loss -0.4933 
2024-12-30 20:02:42.331935: Pseudo dice [np.float32(0.726), np.float32(0.3673)] 
2024-12-30 20:02:42.335461: Epoch time: 31.9 s 
2024-12-30 20:02:42.881945:  
2024-12-30 20:02:42.882448: Epoch 95 
2024-12-30 20:02:42.888466: Current learning rate: 0.00067 
2024-12-30 20:03:14.802614: train_loss -0.8737 
2024-12-30 20:03:14.802614: val_loss -0.4579 
2024-12-30 20:03:14.809006: Pseudo dice [np.float32(0.7132), np.float32(0.3184)] 
2024-12-30 20:03:14.811532: Epoch time: 31.92 s 
2024-12-30 20:03:15.370560:  
2024-12-30 20:03:15.370560: Epoch 96 
2024-12-30 20:03:15.375578: Current learning rate: 0.00055 
2024-12-30 20:03:47.294244: train_loss -0.8728 
2024-12-30 20:03:47.295244: val_loss -0.4741 
2024-12-30 20:03:47.301769: Pseudo dice [np.float32(0.7348), np.float32(0.3255)] 
2024-12-30 20:03:47.305275: Epoch time: 31.93 s 
2024-12-30 20:03:47.865428:  
2024-12-30 20:03:47.865428: Epoch 97 
2024-12-30 20:03:47.870986: Current learning rate: 0.00043 
2024-12-30 20:04:19.803553: train_loss -0.8795 
2024-12-30 20:04:19.804056: val_loss -0.487 
2024-12-30 20:04:19.811074: Pseudo dice [np.float32(0.713), np.float32(0.3585)] 
2024-12-30 20:04:19.815089: Epoch time: 31.94 s 
2024-12-30 20:04:20.608471:  
2024-12-30 20:04:20.609470: Epoch 98 
2024-12-30 20:04:20.615109: Current learning rate: 0.0003 
2024-12-30 20:04:52.520853: train_loss -0.8715 
2024-12-30 20:04:52.521853: val_loss -0.465 
2024-12-30 20:04:52.527367: Pseudo dice [np.float32(0.7165), np.float32(0.31)] 
2024-12-30 20:04:52.530876: Epoch time: 31.91 s 
2024-12-30 20:04:53.086326:  
2024-12-30 20:04:53.086326: Epoch 99 
2024-12-30 20:04:53.091873: Current learning rate: 0.00016 
2024-12-30 20:05:25.012086: train_loss -0.8685 
2024-12-30 20:05:25.012086: val_loss -0.4572 
2024-12-30 20:05:25.019766: Pseudo dice [np.float32(0.7138), np.float32(0.2741)] 
2024-12-30 20:05:25.023815: Epoch time: 31.93 s 
2024-12-30 20:05:25.862174: Training done. 
2024-12-30 20:05:25.889173: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-30 20:05:25.896174: The split file contains 5 splits. 
2024-12-30 20:05:25.903173: Desired fold for training: 0 
2024-12-30 20:05:25.908173: This split has 224 training and 57 validation cases. 
2024-12-30 20:05:25.915178: predicting pancreas_021 
2024-12-30 20:05:25.923177: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2024-12-30 20:05:28.035335: predicting pancreas_024 
2024-12-30 20:05:28.052336: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2024-12-30 20:05:28.788616: predicting pancreas_035 
2024-12-30 20:05:28.800619: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2024-12-30 20:05:29.282709: predicting pancreas_040 
2024-12-30 20:05:29.288706: pancreas_040, shape torch.Size([1, 45, 526, 526]), rank 0 
2024-12-30 20:05:30.170846: predicting pancreas_042 
2024-12-30 20:05:30.178846: pancreas_042, shape torch.Size([1, 51, 537, 537]), rank 0 
2024-12-30 20:05:31.015685: predicting pancreas_056 
2024-12-30 20:05:31.022685: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2024-12-30 20:05:31.436737: predicting pancreas_067 
2024-12-30 20:05:31.445737: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2024-12-30 20:05:33.183172: predicting pancreas_075 
2024-12-30 20:05:33.203172: pancreas_075, shape torch.Size([1, 121, 521, 521]), rank 0 
2024-12-30 20:05:35.699165: predicting pancreas_086 
2024-12-30 20:05:35.716168: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2024-12-30 20:05:36.808432: predicting pancreas_089 
2024-12-30 20:05:36.818435: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-30 20:05:37.393491: predicting pancreas_092 
2024-12-30 20:05:37.407493: pancreas_092, shape torch.Size([1, 92, 513, 513]), rank 0 
2024-12-30 20:05:39.181394: predicting pancreas_094 
2024-12-30 20:05:39.197394: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2024-12-30 20:05:39.734725: predicting pancreas_095 
2024-12-30 20:05:39.753724: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2024-12-30 20:05:40.339320: predicting pancreas_098 
2024-12-30 20:05:40.354321: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2024-12-30 20:05:43.373985: predicting pancreas_109 
2024-12-30 20:05:43.404985: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2024-12-30 20:05:43.991637: predicting pancreas_110 
2024-12-30 20:05:44.004638: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2024-12-30 20:05:46.227360: predicting pancreas_114 
2024-12-30 20:05:46.247867: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2024-12-30 20:05:46.800167: predicting pancreas_119 
2024-12-30 20:05:46.809168: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2024-12-30 20:05:48.436577: predicting pancreas_138 
2024-12-30 20:05:48.456578: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2024-12-30 20:05:50.306933: predicting pancreas_145 
2024-12-30 20:05:50.321935: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2024-12-30 20:05:52.316304: predicting pancreas_148 
2024-12-30 20:05:52.329307: pancreas_148, shape torch.Size([1, 42, 486, 486]), rank 0 
2024-12-30 20:05:52.554834: predicting pancreas_169 
2024-12-30 20:05:52.560833: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2024-12-30 20:05:53.097462: predicting pancreas_170 
2024-12-30 20:05:53.105462: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2024-12-30 20:05:53.800024: predicting pancreas_172 
2024-12-30 20:05:53.820024: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2024-12-30 20:05:54.393799: predicting pancreas_175 
2024-12-30 20:05:54.406799: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-30 20:05:54.979410: predicting pancreas_180 
2024-12-30 20:05:54.991410: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2024-12-30 20:05:55.582085: predicting pancreas_191 
2024-12-30 20:05:55.593086: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2024-12-30 20:05:55.955655: predicting pancreas_193 
2024-12-30 20:05:55.964656: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2024-12-30 20:05:56.726633: predicting pancreas_212 
2024-12-30 20:05:56.740140: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2024-12-30 20:05:58.647327: predicting pancreas_215 
2024-12-30 20:05:58.663327: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2024-12-30 20:05:59.272911: predicting pancreas_222 
2024-12-30 20:05:59.285912: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2024-12-30 20:05:59.708069: predicting pancreas_235 
2024-12-30 20:05:59.714070: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2024-12-30 20:06:00.204609: predicting pancreas_241 
2024-12-30 20:06:00.219610: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2024-12-30 20:06:00.856822: predicting pancreas_242 
2024-12-30 20:06:00.874821: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2024-12-30 20:06:02.866101: predicting pancreas_244 
2024-12-30 20:06:02.883101: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2024-12-30 20:06:04.687347: predicting pancreas_246 
2024-12-30 20:06:04.711349: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2024-12-30 20:06:06.997576: predicting pancreas_247 
2024-12-30 20:06:07.015575: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2024-12-30 20:06:07.494117: predicting pancreas_264 
2024-12-30 20:06:07.501117: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2024-12-30 20:06:09.808855: predicting pancreas_265 
2024-12-30 20:06:09.827859: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2024-12-30 20:06:11.518184: predicting pancreas_266 
2024-12-30 20:06:11.529186: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2024-12-30 20:06:13.357540: predicting pancreas_267 
2024-12-30 20:06:13.373540: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2024-12-30 20:06:13.836573: predicting pancreas_275 
2024-12-30 20:06:13.847080: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2024-12-30 20:06:14.420392: predicting pancreas_279 
2024-12-30 20:06:14.429394: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2024-12-30 20:06:14.968662: predicting pancreas_287 
2024-12-30 20:06:14.981663: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2024-12-30 20:06:15.597000: predicting pancreas_301 
2024-12-30 20:06:15.610999: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2024-12-30 20:06:17.303772: predicting pancreas_323 
2024-12-30 20:06:17.317772: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2024-12-30 20:06:19.256927: predicting pancreas_336 
2024-12-30 20:06:19.275927: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2024-12-30 20:06:21.265817: predicting pancreas_344 
2024-12-30 20:06:21.280817: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2024-12-30 20:06:21.982747: predicting pancreas_351 
2024-12-30 20:06:21.997747: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2024-12-30 20:06:22.454107: predicting pancreas_354 
2024-12-30 20:06:22.464106: pancreas_354, shape torch.Size([1, 81, 529, 529]), rank 0 
2024-12-30 20:06:23.905932: predicting pancreas_372 
2024-12-30 20:06:23.920932: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2024-12-30 20:06:25.823723: predicting pancreas_377 
2024-12-30 20:06:25.844726: pancreas_377, shape torch.Size([1, 55, 551, 551]), rank 0 
2024-12-30 20:06:26.829789: predicting pancreas_387 
2024-12-30 20:06:26.839795: pancreas_387, shape torch.Size([1, 50, 498, 498]), rank 0 
2024-12-30 20:06:27.167899: predicting pancreas_391 
2024-12-30 20:06:27.173899: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2024-12-30 20:06:29.028394: predicting pancreas_392 
2024-12-30 20:06:29.042396: pancreas_392, shape torch.Size([1, 57, 448, 448]), rank 0 
2024-12-30 20:06:29.398462: predicting pancreas_410 
2024-12-30 20:06:29.405462: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2024-12-30 20:06:30.020575: predicting pancreas_412 
2024-12-30 20:06:30.028576: pancreas_412, shape torch.Size([1, 164, 584, 584]), rank 0 
2024-12-30 20:06:45.162621: Validation complete 
2024-12-30 20:06:45.162621: Mean Validation Dice:  0.4724280839310073 
