
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-23 00:08:24.246019: do_dummy_2d_data_aug: False 
2024-12-23 00:08:24.251019: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-23 00:08:24.256880: The split file contains 5 splits. 
2024-12-23 00:08:24.259880: Desired fold for training: 0 
2024-12-23 00:08:24.262879: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2024-12-23 00:08:38.199531: unpacking dataset... 
2024-12-23 00:09:04.098543: unpacking done... 
2024-12-23 00:09:09.713712:  
2024-12-23 00:09:09.713712: Epoch 0 
2024-12-23 00:09:09.718726: Current learning rate: 0.01 
2024-12-23 00:09:46.537846: train_loss 0.0806 
2024-12-23 00:09:46.537846: val_loss 0.0095 
2024-12-23 00:09:46.542891: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-23 00:09:46.546843: Epoch time: 36.83 s 
2024-12-23 00:09:46.550368: Yayy! New best EMA pseudo Dice: 0.0 
2024-12-23 00:09:47.319503:  
2024-12-23 00:09:47.320005: Epoch 1 
2024-12-23 00:09:47.325020: Current learning rate: 0.00991 
2024-12-23 00:10:19.954244: train_loss -0.0033 
2024-12-23 00:10:19.955780: val_loss -0.0428 
2024-12-23 00:10:19.962545: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2024-12-23 00:10:19.967564: Epoch time: 32.64 s 
2024-12-23 00:10:20.491031:  
2024-12-23 00:10:20.491031: Epoch 2 
2024-12-23 00:10:20.497050: Current learning rate: 0.00982 
2024-12-23 00:10:53.390204: train_loss -0.1369 
2024-12-23 00:10:53.390204: val_loss -0.2553 
2024-12-23 00:10:53.402740: Pseudo dice [np.float32(0.5095), np.float32(0.0)] 
2024-12-23 00:10:53.407753: Epoch time: 32.9 s 
2024-12-23 00:10:53.412770: Yayy! New best EMA pseudo Dice: 0.025499999523162842 
2024-12-23 00:10:54.316138:  
2024-12-23 00:10:54.317138: Epoch 3 
2024-12-23 00:10:54.323657: Current learning rate: 0.00973 
2024-12-23 00:11:27.152785: train_loss -0.2583 
2024-12-23 00:11:27.153294: val_loss -0.2958 
2024-12-23 00:11:27.159830: Pseudo dice [np.float32(0.5557), np.float32(0.0)] 
2024-12-23 00:11:27.164391: Epoch time: 32.84 s 
2024-12-23 00:11:27.168944: Yayy! New best EMA pseudo Dice: 0.050700001418590546 
2024-12-23 00:11:28.030692:  
2024-12-23 00:11:28.032195: Epoch 4 
2024-12-23 00:11:28.038216: Current learning rate: 0.00964 
2024-12-23 00:12:00.641238: train_loss -0.3122 
2024-12-23 00:12:00.641238: val_loss -0.388 
2024-12-23 00:12:00.653944: Pseudo dice [np.float32(0.6107), np.float32(0.0804)] 
2024-12-23 00:12:00.660022: Epoch time: 32.61 s 
2024-12-23 00:12:00.665597: Yayy! New best EMA pseudo Dice: 0.08020000159740448 
2024-12-23 00:12:01.706649:  
2024-12-23 00:12:01.706649: Epoch 5 
2024-12-23 00:12:01.712670: Current learning rate: 0.00955 
2024-12-23 00:12:34.439099: train_loss -0.3755 
2024-12-23 00:12:34.439099: val_loss -0.4224 
2024-12-23 00:12:34.445673: Pseudo dice [np.float32(0.551), np.float32(0.4333)] 
2024-12-23 00:12:34.449733: Epoch time: 32.73 s 
2024-12-23 00:12:34.454306: Yayy! New best EMA pseudo Dice: 0.12139999866485596 
2024-12-23 00:12:35.281887:  
2024-12-23 00:12:35.281887: Epoch 6 
2024-12-23 00:12:35.287923: Current learning rate: 0.00946 
2024-12-23 00:13:07.990630: train_loss -0.3918 
2024-12-23 00:13:07.991135: val_loss -0.4851 
2024-12-23 00:13:07.998664: Pseudo dice [np.float32(0.6501), np.float32(0.3727)] 
2024-12-23 00:13:08.003179: Epoch time: 32.71 s 
2024-12-23 00:13:08.008200: Yayy! New best EMA pseudo Dice: 0.16040000319480896 
2024-12-23 00:13:08.818559:  
2024-12-23 00:13:08.818559: Epoch 7 
2024-12-23 00:13:08.825579: Current learning rate: 0.00937 
2024-12-23 00:13:41.481275: train_loss -0.4357 
2024-12-23 00:13:41.482778: val_loss -0.439 
2024-12-23 00:13:41.488792: Pseudo dice [np.float32(0.5829), np.float32(0.3776)] 
2024-12-23 00:13:41.493808: Epoch time: 32.66 s 
2024-12-23 00:13:41.497816: Yayy! New best EMA pseudo Dice: 0.1923999935388565 
2024-12-23 00:13:42.322385:  
2024-12-23 00:13:42.322385: Epoch 8 
2024-12-23 00:13:42.328959: Current learning rate: 0.00928 
2024-12-23 00:14:15.031396: train_loss -0.4236 
2024-12-23 00:14:15.032398: val_loss -0.4399 
2024-12-23 00:14:15.045432: Pseudo dice [np.float32(0.5877), np.float32(0.3937)] 
2024-12-23 00:14:15.050959: Epoch time: 32.71 s 
2024-12-23 00:14:15.055497: Yayy! New best EMA pseudo Dice: 0.22220000624656677 
2024-12-23 00:14:15.929889:  
2024-12-23 00:14:15.930890: Epoch 9 
2024-12-23 00:14:15.936503: Current learning rate: 0.00919 
2024-12-23 00:14:48.683465: train_loss -0.4214 
2024-12-23 00:14:48.684472: val_loss -0.4617 
2024-12-23 00:14:48.697046: Pseudo dice [np.float32(0.6132), np.float32(0.3756)] 
2024-12-23 00:14:48.702167: Epoch time: 32.75 s 
2024-12-23 00:14:48.706202: Yayy! New best EMA pseudo Dice: 0.24940000474452972 
2024-12-23 00:14:49.593055:  
2024-12-23 00:14:49.593055: Epoch 10 
2024-12-23 00:14:49.599092: Current learning rate: 0.0091 
2024-12-23 00:15:22.347256: train_loss -0.4569 
2024-12-23 00:15:22.347759: val_loss -0.4118 
2024-12-23 00:15:22.353775: Pseudo dice [np.float32(0.5808), np.float32(0.3268)] 
2024-12-23 00:15:22.358786: Epoch time: 32.76 s 
2024-12-23 00:15:22.363800: Yayy! New best EMA pseudo Dice: 0.26989999413490295 
2024-12-23 00:15:23.178816:  
2024-12-23 00:15:23.178816: Epoch 11 
2024-12-23 00:15:23.184829: Current learning rate: 0.009 
2024-12-23 00:15:56.003651: train_loss -0.4432 
2024-12-23 00:15:56.004156: val_loss -0.4504 
2024-12-23 00:15:56.011877: Pseudo dice [np.float32(0.5939), np.float32(0.4122)] 
2024-12-23 00:15:56.017323: Epoch time: 32.83 s 
2024-12-23 00:15:56.023842: Yayy! New best EMA pseudo Dice: 0.29319998621940613 
2024-12-23 00:15:57.019861:  
2024-12-23 00:15:57.020864: Epoch 12 
2024-12-23 00:15:57.026966: Current learning rate: 0.00891 
2024-12-23 00:16:30.520234: train_loss -0.4839 
2024-12-23 00:16:30.520740: val_loss -0.4798 
2024-12-23 00:16:30.526769: Pseudo dice [np.float32(0.6461), np.float32(0.3856)] 
2024-12-23 00:16:30.532304: Epoch time: 33.5 s 
2024-12-23 00:16:30.536849: Yayy! New best EMA pseudo Dice: 0.3154999911785126 
2024-12-23 00:16:31.366440:  
2024-12-23 00:16:31.366953: Epoch 13 
2024-12-23 00:16:31.373093: Current learning rate: 0.00882 
2024-12-23 00:17:05.287207: train_loss -0.4576 
2024-12-23 00:17:05.287711: val_loss -0.4991 
2024-12-23 00:17:05.295284: Pseudo dice [np.float32(0.6518), np.float32(0.4397)] 
2024-12-23 00:17:05.300842: Epoch time: 33.92 s 
2024-12-23 00:17:05.306397: Yayy! New best EMA pseudo Dice: 0.3384999930858612 
2024-12-23 00:17:06.139638:  
2024-12-23 00:17:06.139638: Epoch 14 
2024-12-23 00:17:06.146336: Current learning rate: 0.00873 
2024-12-23 00:17:40.196760: train_loss -0.4915 
2024-12-23 00:17:40.197286: val_loss -0.474 
2024-12-23 00:17:40.203428: Pseudo dice [np.float32(0.6266), np.float32(0.4324)] 
2024-12-23 00:17:40.208443: Epoch time: 34.06 s 
2024-12-23 00:17:40.213456: Yayy! New best EMA pseudo Dice: 0.35760000348091125 
2024-12-23 00:17:41.054410:  
2024-12-23 00:17:41.055915: Epoch 15 
2024-12-23 00:17:41.061933: Current learning rate: 0.00864 
2024-12-23 00:18:13.740075: train_loss -0.5152 
2024-12-23 00:18:13.740075: val_loss -0.4954 
2024-12-23 00:18:13.747596: Pseudo dice [np.float32(0.6488), np.float32(0.4093)] 
2024-12-23 00:18:13.751608: Epoch time: 32.69 s 
2024-12-23 00:18:13.756623: Yayy! New best EMA pseudo Dice: 0.37470000982284546 
2024-12-23 00:18:14.577969:  
2024-12-23 00:18:14.577969: Epoch 16 
2024-12-23 00:18:14.583988: Current learning rate: 0.00855 
2024-12-23 00:18:47.059917: train_loss -0.498 
2024-12-23 00:18:47.060421: val_loss -0.5102 
2024-12-23 00:18:47.074651: Pseudo dice [np.float32(0.6527), np.float32(0.455)] 
2024-12-23 00:18:47.079711: Epoch time: 32.48 s 
2024-12-23 00:18:47.084257: Yayy! New best EMA pseudo Dice: 0.39259999990463257 
2024-12-23 00:18:47.920111:  
2024-12-23 00:18:47.920613: Epoch 17 
2024-12-23 00:18:47.926631: Current learning rate: 0.00846 
2024-12-23 00:19:20.881744: train_loss -0.5296 
2024-12-23 00:19:20.882253: val_loss -0.5037 
2024-12-23 00:19:20.888273: Pseudo dice [np.float32(0.6809), np.float32(0.388)] 
2024-12-23 00:19:20.893283: Epoch time: 32.96 s 
2024-12-23 00:19:20.898297: Yayy! New best EMA pseudo Dice: 0.4068000018596649 
2024-12-23 00:19:21.745851:  
2024-12-23 00:19:21.746355: Epoch 18 
2024-12-23 00:19:21.751372: Current learning rate: 0.00836 
2024-12-23 00:19:54.960677: train_loss -0.5363 
2024-12-23 00:19:54.961188: val_loss -0.5184 
2024-12-23 00:19:54.973314: Pseudo dice [np.float32(0.6792), np.float32(0.4142)] 
2024-12-23 00:19:54.976827: Epoch time: 33.22 s 
2024-12-23 00:19:54.980837: Yayy! New best EMA pseudo Dice: 0.42080000042915344 
2024-12-23 00:19:55.836157:  
2024-12-23 00:19:55.836660: Epoch 19 
2024-12-23 00:19:55.841168: Current learning rate: 0.00827 
2024-12-23 00:20:28.853422: train_loss -0.5227 
2024-12-23 00:20:28.853422: val_loss -0.5379 
2024-12-23 00:20:28.859440: Pseudo dice [np.float32(0.6969), np.float32(0.4196)] 
2024-12-23 00:20:28.862452: Epoch time: 33.02 s 
2024-12-23 00:20:28.865964: Yayy! New best EMA pseudo Dice: 0.43459999561309814 
2024-12-23 00:20:29.862853:  
2024-12-23 00:20:29.862853: Epoch 20 
2024-12-23 00:20:29.867868: Current learning rate: 0.00818 
2024-12-23 00:21:03.187465: train_loss -0.5562 
2024-12-23 00:21:03.187465: val_loss -0.568 
2024-12-23 00:21:03.195634: Pseudo dice [np.float32(0.6894), np.float32(0.5285)] 
2024-12-23 00:21:03.199191: Epoch time: 33.33 s 
2024-12-23 00:21:03.203314: Yayy! New best EMA pseudo Dice: 0.4519999921321869 
2024-12-23 00:21:04.060769:  
2024-12-23 00:21:04.061774: Epoch 21 
2024-12-23 00:21:04.066323: Current learning rate: 0.00809 
2024-12-23 00:21:37.277982: train_loss -0.5344 
2024-12-23 00:21:37.278506: val_loss -0.5489 
2024-12-23 00:21:37.284067: Pseudo dice [np.float32(0.6436), np.float32(0.5449)] 
2024-12-23 00:21:37.288096: Epoch time: 33.22 s 
2024-12-23 00:21:37.291634: Yayy! New best EMA pseudo Dice: 0.46619999408721924 
2024-12-23 00:21:38.161575:  
2024-12-23 00:21:38.161575: Epoch 22 
2024-12-23 00:21:38.167128: Current learning rate: 0.008 
2024-12-23 00:22:11.233173: train_loss -0.5442 
2024-12-23 00:22:11.233690: val_loss -0.541 
2024-12-23 00:22:11.241876: Pseudo dice [np.float32(0.6757), np.float32(0.5085)] 
2024-12-23 00:22:11.246512: Epoch time: 33.07 s 
2024-12-23 00:22:11.251123: Yayy! New best EMA pseudo Dice: 0.4787999987602234 
2024-12-23 00:22:12.125260:  
2024-12-23 00:22:12.125260: Epoch 23 
2024-12-23 00:22:12.130273: Current learning rate: 0.0079 
2024-12-23 00:22:45.648525: train_loss -0.5465 
2024-12-23 00:22:45.648525: val_loss -0.5395 
2024-12-23 00:22:45.661068: Pseudo dice [np.float32(0.673), np.float32(0.503)] 
2024-12-23 00:22:45.665086: Epoch time: 33.52 s 
2024-12-23 00:22:45.670106: Yayy! New best EMA pseudo Dice: 0.48969998955726624 
2024-12-23 00:22:46.491623:  
2024-12-23 00:22:46.492626: Epoch 24 
2024-12-23 00:22:46.497685: Current learning rate: 0.00781 
2024-12-23 00:23:19.828269: train_loss -0.5574 
2024-12-23 00:23:19.828773: val_loss -0.5376 
2024-12-23 00:23:19.834790: Pseudo dice [np.float32(0.6875), np.float32(0.4997)] 
2024-12-23 00:23:19.838296: Epoch time: 33.34 s 
2024-12-23 00:23:19.841305: Yayy! New best EMA pseudo Dice: 0.5001000165939331 
2024-12-23 00:23:20.708931:  
2024-12-23 00:23:20.709935: Epoch 25 
2024-12-23 00:23:20.715014: Current learning rate: 0.00772 
2024-12-23 00:23:54.232592: train_loss -0.577 
2024-12-23 00:23:54.232592: val_loss -0.5188 
2024-12-23 00:23:54.239110: Pseudo dice [np.float32(0.6993), np.float32(0.4303)] 
2024-12-23 00:23:54.242622: Epoch time: 33.52 s 
2024-12-23 00:23:54.246633: Yayy! New best EMA pseudo Dice: 0.506600022315979 
2024-12-23 00:23:55.096123:  
2024-12-23 00:23:55.097131: Epoch 26 
2024-12-23 00:23:55.103258: Current learning rate: 0.00763 
2024-12-23 00:24:28.037632: train_loss -0.5646 
2024-12-23 00:24:28.038631: val_loss -0.5586 
2024-12-23 00:24:28.044149: Pseudo dice [np.float32(0.6768), np.float32(0.5306)] 
2024-12-23 00:24:28.047659: Epoch time: 32.94 s 
2024-12-23 00:24:28.051165: Yayy! New best EMA pseudo Dice: 0.5163000226020813 
2024-12-23 00:24:29.099576:  
2024-12-23 00:24:29.100579: Epoch 27 
2024-12-23 00:24:29.105665: Current learning rate: 0.00753 
2024-12-23 00:25:02.185449: train_loss -0.5795 
2024-12-23 00:25:02.185449: val_loss -0.5184 
2024-12-23 00:25:02.197488: Pseudo dice [np.float32(0.6934), np.float32(0.4602)] 
2024-12-23 00:25:02.201504: Epoch time: 33.09 s 
2024-12-23 00:25:02.206520: Yayy! New best EMA pseudo Dice: 0.5223000049591064 
2024-12-23 00:25:03.034240:  
2024-12-23 00:25:03.035244: Epoch 28 
2024-12-23 00:25:03.039795: Current learning rate: 0.00744 
2024-12-23 00:25:36.150146: train_loss -0.5617 
2024-12-23 00:25:36.151151: val_loss -0.5101 
2024-12-23 00:25:36.156165: Pseudo dice [np.float32(0.6834), np.float32(0.3829)] 
2024-12-23 00:25:36.160181: Epoch time: 33.12 s 
2024-12-23 00:25:36.163689: Yayy! New best EMA pseudo Dice: 0.5234000086784363 
2024-12-23 00:25:36.991301:  
2024-12-23 00:25:36.991301: Epoch 29 
2024-12-23 00:25:36.997430: Current learning rate: 0.00735 
2024-12-23 00:26:09.935646: train_loss -0.5489 
2024-12-23 00:26:09.936158: val_loss -0.5281 
2024-12-23 00:26:09.942793: Pseudo dice [np.float32(0.6863), np.float32(0.4603)] 
2024-12-23 00:26:09.946359: Epoch time: 32.95 s 
2024-12-23 00:26:09.949930: Yayy! New best EMA pseudo Dice: 0.5284000039100647 
2024-12-23 00:26:10.797538:  
2024-12-23 00:26:10.797538: Epoch 30 
2024-12-23 00:26:10.803658: Current learning rate: 0.00725 
2024-12-23 00:26:44.296847: train_loss -0.5715 
2024-12-23 00:26:44.297349: val_loss -0.542 
2024-12-23 00:26:44.304933: Pseudo dice [np.float32(0.6898), np.float32(0.4747)] 
2024-12-23 00:26:44.309950: Epoch time: 33.5 s 
2024-12-23 00:26:44.313967: Yayy! New best EMA pseudo Dice: 0.5338000059127808 
2024-12-23 00:26:45.140442:  
2024-12-23 00:26:45.141446: Epoch 31 
2024-12-23 00:26:45.146020: Current learning rate: 0.00716 
2024-12-23 00:27:18.663688: train_loss -0.5777 
2024-12-23 00:27:18.664190: val_loss -0.5493 
2024-12-23 00:27:18.669725: Pseudo dice [np.float32(0.6855), np.float32(0.5177)] 
2024-12-23 00:27:18.673236: Epoch time: 33.52 s 
2024-12-23 00:27:18.677251: Yayy! New best EMA pseudo Dice: 0.5406000018119812 
2024-12-23 00:27:19.496641:  
2024-12-23 00:27:19.496641: Epoch 32 
2024-12-23 00:27:19.502195: Current learning rate: 0.00707 
2024-12-23 00:27:52.954965: train_loss -0.58 
2024-12-23 00:27:52.955469: val_loss -0.5766 
2024-12-23 00:27:52.961489: Pseudo dice [np.float32(0.7122), np.float32(0.5079)] 
2024-12-23 00:27:52.965504: Epoch time: 33.46 s 
2024-12-23 00:27:52.969018: Yayy! New best EMA pseudo Dice: 0.5475000143051147 
2024-12-23 00:27:53.796523:  
2024-12-23 00:27:53.796523: Epoch 33 
2024-12-23 00:27:53.801922: Current learning rate: 0.00697 
2024-12-23 00:28:27.253571: train_loss -0.579 
2024-12-23 00:28:27.254573: val_loss -0.5404 
2024-12-23 00:28:27.260091: Pseudo dice [np.float32(0.7119), np.float32(0.4442)] 
2024-12-23 00:28:27.264603: Epoch time: 33.46 s 
2024-12-23 00:28:27.267614: Yayy! New best EMA pseudo Dice: 0.550599992275238 
2024-12-23 00:28:28.095769:  
2024-12-23 00:28:28.095769: Epoch 34 
2024-12-23 00:28:28.101930: Current learning rate: 0.00688 
2024-12-23 00:29:01.379881: train_loss -0.5786 
2024-12-23 00:29:01.379881: val_loss -0.5362 
2024-12-23 00:29:01.392422: Pseudo dice [np.float32(0.6636), np.float32(0.5065)] 
2024-12-23 00:29:01.396934: Epoch time: 33.29 s 
2024-12-23 00:29:01.400990: Yayy! New best EMA pseudo Dice: 0.5540000200271606 
2024-12-23 00:29:02.447568:  
2024-12-23 00:29:02.447568: Epoch 35 
2024-12-23 00:29:02.453123: Current learning rate: 0.00679 
2024-12-23 00:29:35.980223: train_loss -0.5752 
2024-12-23 00:29:35.980728: val_loss -0.4996 
2024-12-23 00:29:35.986753: Pseudo dice [np.float32(0.639), np.float32(0.4083)] 
2024-12-23 00:29:35.990759: Epoch time: 33.53 s 
2024-12-23 00:29:36.548638:  
2024-12-23 00:29:36.548638: Epoch 36 
2024-12-23 00:29:36.554014: Current learning rate: 0.00669 
2024-12-23 00:30:09.655587: train_loss -0.5866 
2024-12-23 00:30:09.655587: val_loss -0.494 
2024-12-23 00:30:09.661647: Pseudo dice [np.float32(0.7267), np.float32(0.2974)] 
2024-12-23 00:30:09.665635: Epoch time: 33.11 s 
2024-12-23 00:30:10.227933:  
2024-12-23 00:30:10.229604: Epoch 37 
2024-12-23 00:30:10.235197: Current learning rate: 0.0066 
2024-12-23 00:30:43.281973: train_loss -0.6144 
2024-12-23 00:30:43.282976: val_loss -0.5543 
2024-12-23 00:30:43.289497: Pseudo dice [np.float32(0.7139), np.float32(0.467)] 
2024-12-23 00:30:43.293010: Epoch time: 33.05 s 
2024-12-23 00:30:43.847703:  
2024-12-23 00:30:43.847703: Epoch 38 
2024-12-23 00:30:43.852731: Current learning rate: 0.0065 
2024-12-23 00:31:17.241267: train_loss -0.5962 
2024-12-23 00:31:17.241818: val_loss -0.5453 
2024-12-23 00:31:17.247368: Pseudo dice [np.float32(0.6959), np.float32(0.4621)] 
2024-12-23 00:31:17.251406: Epoch time: 33.39 s 
2024-12-23 00:31:17.254937: Yayy! New best EMA pseudo Dice: 0.5541999936103821 
2024-12-23 00:31:18.070478:  
2024-12-23 00:31:18.071002: Epoch 39 
2024-12-23 00:31:18.075945: Current learning rate: 0.00641 
2024-12-23 00:31:51.642776: train_loss -0.61 
2024-12-23 00:31:51.643301: val_loss -0.5161 
2024-12-23 00:31:51.650320: Pseudo dice [np.float32(0.7001), np.float32(0.4282)] 
2024-12-23 00:31:51.655338: Epoch time: 33.57 s 
2024-12-23 00:31:51.658354: Yayy! New best EMA pseudo Dice: 0.5551999807357788 
2024-12-23 00:31:52.506901:  
2024-12-23 00:31:52.507404: Epoch 40 
2024-12-23 00:31:52.512417: Current learning rate: 0.00631 
2024-12-23 00:32:25.963292: train_loss -0.6282 
2024-12-23 00:32:25.963795: val_loss -0.5517 
2024-12-23 00:32:25.969818: Pseudo dice [np.float32(0.7185), np.float32(0.4647)] 
2024-12-23 00:32:25.973325: Epoch time: 33.46 s 
2024-12-23 00:32:25.977344: Yayy! New best EMA pseudo Dice: 0.5587999820709229 
2024-12-23 00:32:26.818327:  
2024-12-23 00:32:26.819327: Epoch 41 
2024-12-23 00:32:26.824939: Current learning rate: 0.00622 
2024-12-23 00:33:00.122048: train_loss -0.6298 
2024-12-23 00:33:00.122551: val_loss -0.5078 
2024-12-23 00:33:00.130681: Pseudo dice [np.float32(0.7088), np.float32(0.3706)] 
2024-12-23 00:33:00.134712: Epoch time: 33.3 s 
2024-12-23 00:33:00.671956:  
2024-12-23 00:33:00.672458: Epoch 42 
2024-12-23 00:33:00.677477: Current learning rate: 0.00612 
2024-12-23 00:33:34.233547: train_loss -0.6006 
2024-12-23 00:33:34.233547: val_loss -0.5502 
2024-12-23 00:33:34.239570: Pseudo dice [np.float32(0.7199), np.float32(0.4913)] 
2024-12-23 00:33:34.244589: Epoch time: 33.56 s 
2024-12-23 00:33:34.248602: Yayy! New best EMA pseudo Dice: 0.5618000030517578 
2024-12-23 00:33:35.268705:  
2024-12-23 00:33:35.269208: Epoch 43 
2024-12-23 00:33:35.274221: Current learning rate: 0.00603 
2024-12-23 00:34:08.827720: train_loss -0.6322 
2024-12-23 00:34:08.829249: val_loss -0.5816 
2024-12-23 00:34:08.836884: Pseudo dice [np.float32(0.7191), np.float32(0.5573)] 
2024-12-23 00:34:08.840899: Epoch time: 33.56 s 
2024-12-23 00:34:08.845918: Yayy! New best EMA pseudo Dice: 0.5694000124931335 
2024-12-23 00:34:09.661189:  
2024-12-23 00:34:09.662193: Epoch 44 
2024-12-23 00:34:09.666763: Current learning rate: 0.00593 
2024-12-23 00:34:43.296323: train_loss -0.6251 
2024-12-23 00:34:43.297326: val_loss -0.5361 
2024-12-23 00:34:43.304902: Pseudo dice [np.float32(0.695), np.float32(0.488)] 
2024-12-23 00:34:43.308762: Epoch time: 33.64 s 
2024-12-23 00:34:43.313008: Yayy! New best EMA pseudo Dice: 0.5716000199317932 
2024-12-23 00:34:44.115975:  
2024-12-23 00:34:44.116975: Epoch 45 
2024-12-23 00:34:44.122056: Current learning rate: 0.00584 
2024-12-23 00:35:17.407415: train_loss -0.631 
2024-12-23 00:35:17.407415: val_loss -0.5535 
2024-12-23 00:35:17.413434: Pseudo dice [np.float32(0.7446), np.float32(0.4504)] 
2024-12-23 00:35:17.417447: Epoch time: 33.29 s 
2024-12-23 00:35:17.420963: Yayy! New best EMA pseudo Dice: 0.5741999745368958 
2024-12-23 00:35:18.240867:  
2024-12-23 00:35:18.241371: Epoch 46 
2024-12-23 00:35:18.246390: Current learning rate: 0.00574 
2024-12-23 00:35:51.584682: train_loss -0.6354 
2024-12-23 00:35:51.584682: val_loss -0.489 
2024-12-23 00:35:51.596233: Pseudo dice [np.float32(0.7107), np.float32(0.3987)] 
2024-12-23 00:35:51.599804: Epoch time: 33.34 s 
2024-12-23 00:35:52.132989:  
2024-12-23 00:35:52.132989: Epoch 47 
2024-12-23 00:35:52.138506: Current learning rate: 0.00565 
2024-12-23 00:36:25.727499: train_loss -0.6403 
2024-12-23 00:36:25.728499: val_loss -0.5175 
2024-12-23 00:36:25.734061: Pseudo dice [np.float32(0.6995), np.float32(0.5208)] 
2024-12-23 00:36:25.738576: Epoch time: 33.6 s 
2024-12-23 00:36:25.742599: Yayy! New best EMA pseudo Dice: 0.5760999917984009 
2024-12-23 00:36:26.557710:  
2024-12-23 00:36:26.557710: Epoch 48 
2024-12-23 00:36:26.562737: Current learning rate: 0.00555 
2024-12-23 00:37:00.343485: train_loss -0.6375 
2024-12-23 00:37:00.343988: val_loss -0.5468 
2024-12-23 00:37:00.352150: Pseudo dice [np.float32(0.7009), np.float32(0.4891)] 
2024-12-23 00:37:00.355662: Epoch time: 33.79 s 
2024-12-23 00:37:00.359676: Yayy! New best EMA pseudo Dice: 0.5778999924659729 
2024-12-23 00:37:01.198636:  
2024-12-23 00:37:01.199638: Epoch 49 
2024-12-23 00:37:01.204621: Current learning rate: 0.00546 
2024-12-23 00:37:34.367858: train_loss -0.6267 
2024-12-23 00:37:34.367858: val_loss -0.5915 
2024-12-23 00:37:34.373873: Pseudo dice [np.float32(0.7218), np.float32(0.5347)] 
2024-12-23 00:37:34.377892: Epoch time: 33.17 s 
2024-12-23 00:37:34.597515: Yayy! New best EMA pseudo Dice: 0.5830000042915344 
2024-12-23 00:37:35.552682:  
2024-12-23 00:37:35.552682: Epoch 50 
2024-12-23 00:37:35.558715: Current learning rate: 0.00536 
2024-12-23 00:38:09.009954: train_loss -0.6419 
2024-12-23 00:38:09.010456: val_loss -0.5677 
2024-12-23 00:38:09.021482: Pseudo dice [np.float32(0.7268), np.float32(0.5367)] 
2024-12-23 00:38:09.025998: Epoch time: 33.46 s 
2024-12-23 00:38:09.030529: Yayy! New best EMA pseudo Dice: 0.5878999829292297 
2024-12-23 00:38:09.856699:  
2024-12-23 00:38:09.856699: Epoch 51 
2024-12-23 00:38:09.862242: Current learning rate: 0.00526 
2024-12-23 00:38:42.517126: train_loss -0.6608 
2024-12-23 00:38:42.517126: val_loss -0.5513 
2024-12-23 00:38:42.523135: Pseudo dice [np.float32(0.7158), np.float32(0.4933)] 
2024-12-23 00:38:42.527152: Epoch time: 32.66 s 
2024-12-23 00:38:42.530658: Yayy! New best EMA pseudo Dice: 0.5895000100135803 
2024-12-23 00:38:43.342498:  
2024-12-23 00:38:43.343501: Epoch 52 
2024-12-23 00:38:43.349086: Current learning rate: 0.00517 
2024-12-23 00:39:16.294244: train_loss -0.6627 
2024-12-23 00:39:16.296293: val_loss -0.5772 
2024-12-23 00:39:16.301366: Pseudo dice [np.float32(0.6952), np.float32(0.5723)] 
2024-12-23 00:39:16.305919: Epoch time: 32.95 s 
2024-12-23 00:39:16.309947: Yayy! New best EMA pseudo Dice: 0.5939000248908997 
2024-12-23 00:39:17.128063:  
2024-12-23 00:39:17.129064: Epoch 53 
2024-12-23 00:39:17.134120: Current learning rate: 0.00507 
2024-12-23 00:39:49.715435: train_loss -0.6412 
2024-12-23 00:39:49.715938: val_loss -0.5876 
2024-12-23 00:39:49.726965: Pseudo dice [np.float32(0.7319), np.float32(0.534)] 
2024-12-23 00:39:49.731979: Epoch time: 32.59 s 
2024-12-23 00:39:49.735990: Yayy! New best EMA pseudo Dice: 0.5978000164031982 
2024-12-23 00:39:50.554785:  
2024-12-23 00:39:50.555785: Epoch 54 
2024-12-23 00:39:50.560872: Current learning rate: 0.00497 
2024-12-23 00:40:22.993751: train_loss -0.6691 
2024-12-23 00:40:22.994262: val_loss -0.5497 
2024-12-23 00:40:22.999417: Pseudo dice [np.float32(0.71), np.float32(0.4459)] 
2024-12-23 00:40:23.003452: Epoch time: 32.44 s 
2024-12-23 00:40:23.538733:  
2024-12-23 00:40:23.538733: Epoch 55 
2024-12-23 00:40:23.544315: Current learning rate: 0.00487 
2024-12-23 00:40:56.013676: train_loss -0.6749 
2024-12-23 00:40:56.013676: val_loss -0.597 
2024-12-23 00:40:56.021642: Pseudo dice [np.float32(0.7041), np.float32(0.627)] 
2024-12-23 00:40:56.025661: Epoch time: 32.48 s 
2024-12-23 00:40:56.029670: Yayy! New best EMA pseudo Dice: 0.6028000116348267 
2024-12-23 00:40:56.849748:  
2024-12-23 00:40:56.850748: Epoch 56 
2024-12-23 00:40:56.856335: Current learning rate: 0.00478 
2024-12-23 00:41:29.229196: train_loss -0.6754 
2024-12-23 00:41:29.229700: val_loss -0.5713 
2024-12-23 00:41:29.234717: Pseudo dice [np.float32(0.717), np.float32(0.5212)] 
2024-12-23 00:41:29.239232: Epoch time: 32.38 s 
2024-12-23 00:41:29.243247: Yayy! New best EMA pseudo Dice: 0.6043999791145325 
2024-12-23 00:41:30.057456:  
2024-12-23 00:41:30.057456: Epoch 57 
2024-12-23 00:41:30.062469: Current learning rate: 0.00468 
2024-12-23 00:42:02.413722: train_loss -0.655 
2024-12-23 00:42:02.413722: val_loss -0.54 
2024-12-23 00:42:02.418792: Pseudo dice [np.float32(0.6811), np.float32(0.52)] 
2024-12-23 00:42:02.424418: Epoch time: 32.36 s 
2024-12-23 00:42:03.139945:  
2024-12-23 00:42:03.140949: Epoch 58 
2024-12-23 00:42:03.145540: Current learning rate: 0.00458 
2024-12-23 00:42:35.514122: train_loss -0.6597 
2024-12-23 00:42:35.514122: val_loss -0.5403 
2024-12-23 00:42:35.520134: Pseudo dice [np.float32(0.738), np.float32(0.404)] 
2024-12-23 00:42:35.525151: Epoch time: 32.37 s 
2024-12-23 00:42:36.074206:  
2024-12-23 00:42:36.074206: Epoch 59 
2024-12-23 00:42:36.085874: Current learning rate: 0.00448 
2024-12-23 00:43:08.432843: train_loss -0.644 
2024-12-23 00:43:08.433844: val_loss -0.5332 
2024-12-23 00:43:08.446386: Pseudo dice [np.float32(0.7015), np.float32(0.4653)] 
2024-12-23 00:43:08.451403: Epoch time: 32.36 s 
2024-12-23 00:43:08.997607:  
2024-12-23 00:43:08.997607: Epoch 60 
2024-12-23 00:43:09.003192: Current learning rate: 0.00438 
2024-12-23 00:43:41.343578: train_loss -0.6615 
2024-12-23 00:43:41.344082: val_loss -0.5083 
2024-12-23 00:43:41.350106: Pseudo dice [np.float32(0.7204), np.float32(0.3955)] 
2024-12-23 00:43:41.354115: Epoch time: 32.35 s 
2024-12-23 00:43:41.895765:  
2024-12-23 00:43:41.895765: Epoch 61 
2024-12-23 00:43:41.901783: Current learning rate: 0.00429 
2024-12-23 00:44:14.578120: train_loss -0.6435 
2024-12-23 00:44:14.578120: val_loss -0.548 
2024-12-23 00:44:14.584133: Pseudo dice [np.float32(0.7049), np.float32(0.4952)] 
2024-12-23 00:44:14.588143: Epoch time: 32.68 s 
2024-12-23 00:44:15.132783:  
2024-12-23 00:44:15.133821: Epoch 62 
2024-12-23 00:44:15.138872: Current learning rate: 0.00419 
2024-12-23 00:44:47.686301: train_loss -0.678 
2024-12-23 00:44:47.686301: val_loss -0.5931 
2024-12-23 00:44:47.692822: Pseudo dice [np.float32(0.7284), np.float32(0.5992)] 
2024-12-23 00:44:47.697838: Epoch time: 32.55 s 
2024-12-23 00:44:48.273555:  
2024-12-23 00:44:48.273555: Epoch 63 
2024-12-23 00:44:48.279076: Current learning rate: 0.00409 
2024-12-23 00:45:20.625637: train_loss -0.6905 
2024-12-23 00:45:20.625637: val_loss -0.5587 
2024-12-23 00:45:20.632191: Pseudo dice [np.float32(0.7253), np.float32(0.5034)] 
2024-12-23 00:45:20.637207: Epoch time: 32.35 s 
2024-12-23 00:45:21.179097:  
2024-12-23 00:45:21.179097: Epoch 64 
2024-12-23 00:45:21.185144: Current learning rate: 0.00399 
2024-12-23 00:45:53.581179: train_loss -0.6969 
2024-12-23 00:45:53.581693: val_loss -0.5274 
2024-12-23 00:45:53.587287: Pseudo dice [np.float32(0.7324), np.float32(0.4339)] 
2024-12-23 00:45:53.591299: Epoch time: 32.4 s 
2024-12-23 00:45:54.138659:  
2024-12-23 00:45:54.139162: Epoch 65 
2024-12-23 00:45:54.144173: Current learning rate: 0.00389 
2024-12-23 00:46:26.539272: train_loss -0.6822 
2024-12-23 00:46:26.540271: val_loss -0.5603 
2024-12-23 00:46:26.545783: Pseudo dice [np.float32(0.7258), np.float32(0.52)] 
2024-12-23 00:46:26.550796: Epoch time: 32.4 s 
2024-12-23 00:46:27.271599:  
2024-12-23 00:46:27.271599: Epoch 66 
2024-12-23 00:46:27.278306: Current learning rate: 0.00379 
2024-12-23 00:46:59.653649: train_loss -0.6902 
2024-12-23 00:46:59.654160: val_loss -0.5801 
2024-12-23 00:46:59.661288: Pseudo dice [np.float32(0.756), np.float32(0.5619)] 
2024-12-23 00:46:59.664883: Epoch time: 32.38 s 
2024-12-23 00:46:59.668929: Yayy! New best EMA pseudo Dice: 0.6090999841690063 
2024-12-23 00:47:00.471802:  
2024-12-23 00:47:00.472802: Epoch 67 
2024-12-23 00:47:00.478260: Current learning rate: 0.00369 
2024-12-23 00:47:32.848816: train_loss -0.7077 
2024-12-23 00:47:32.848816: val_loss -0.5752 
2024-12-23 00:47:32.855363: Pseudo dice [np.float32(0.7405), np.float32(0.5061)] 
2024-12-23 00:47:32.859380: Epoch time: 32.38 s 
2024-12-23 00:47:32.863396: Yayy! New best EMA pseudo Dice: 0.6104999780654907 
2024-12-23 00:47:33.697426:  
2024-12-23 00:47:33.697426: Epoch 68 
2024-12-23 00:47:33.702633: Current learning rate: 0.00359 
2024-12-23 00:48:06.041595: train_loss -0.6889 
2024-12-23 00:48:06.041595: val_loss -0.533 
2024-12-23 00:48:06.047743: Pseudo dice [np.float32(0.7228), np.float32(0.4046)] 
2024-12-23 00:48:06.052840: Epoch time: 32.35 s 
2024-12-23 00:48:06.604293:  
2024-12-23 00:48:06.605296: Epoch 69 
2024-12-23 00:48:06.609839: Current learning rate: 0.00349 
2024-12-23 00:48:38.940036: train_loss -0.6876 
2024-12-23 00:48:38.941039: val_loss -0.5692 
2024-12-23 00:48:38.946666: Pseudo dice [np.float32(0.7105), np.float32(0.5212)] 
2024-12-23 00:48:38.950671: Epoch time: 32.34 s 
2024-12-23 00:48:39.498486:  
2024-12-23 00:48:39.498486: Epoch 70 
2024-12-23 00:48:39.504511: Current learning rate: 0.00338 
2024-12-23 00:49:11.830994: train_loss -0.6902 
2024-12-23 00:49:11.831498: val_loss -0.5343 
2024-12-23 00:49:11.836517: Pseudo dice [np.float32(0.7283), np.float32(0.4444)] 
2024-12-23 00:49:11.841535: Epoch time: 32.33 s 
2024-12-23 00:49:12.388404:  
2024-12-23 00:49:12.389405: Epoch 71 
2024-12-23 00:49:12.395924: Current learning rate: 0.00328 
2024-12-23 00:49:44.562131: train_loss -0.6903 
2024-12-23 00:49:44.562635: val_loss -0.5614 
2024-12-23 00:49:44.569792: Pseudo dice [np.float32(0.7378), np.float32(0.4234)] 
2024-12-23 00:49:44.573865: Epoch time: 32.17 s 
2024-12-23 00:49:45.133410:  
2024-12-23 00:49:45.133912: Epoch 72 
2024-12-23 00:49:45.138925: Current learning rate: 0.00318 
2024-12-23 00:50:17.381120: train_loss -0.7161 
2024-12-23 00:50:17.382120: val_loss -0.5412 
2024-12-23 00:50:17.387639: Pseudo dice [np.float32(0.7483), np.float32(0.4109)] 
2024-12-23 00:50:17.392150: Epoch time: 32.25 s 
2024-12-23 00:50:18.012293:  
2024-12-23 00:50:18.012293: Epoch 73 
2024-12-23 00:50:18.018314: Current learning rate: 0.00308 
2024-12-23 00:50:50.233937: train_loss -0.7228 
2024-12-23 00:50:50.234439: val_loss -0.5374 
2024-12-23 00:50:50.241455: Pseudo dice [np.float32(0.7353), np.float32(0.4621)] 
2024-12-23 00:50:50.245466: Epoch time: 32.22 s 
2024-12-23 00:50:50.976047:  
2024-12-23 00:50:50.976047: Epoch 74 
2024-12-23 00:50:50.982124: Current learning rate: 0.00297 
2024-12-23 00:51:23.170236: train_loss -0.7209 
2024-12-23 00:51:23.171238: val_loss -0.5644 
2024-12-23 00:51:23.176248: Pseudo dice [np.float32(0.7414), np.float32(0.4679)] 
2024-12-23 00:51:23.180260: Epoch time: 32.2 s 
2024-12-23 00:51:23.728592:  
2024-12-23 00:51:23.728592: Epoch 75 
2024-12-23 00:51:23.734066: Current learning rate: 0.00287 
2024-12-23 00:51:55.914725: train_loss -0.7187 
2024-12-23 00:51:55.915227: val_loss -0.5014 
2024-12-23 00:51:55.920236: Pseudo dice [np.float32(0.7241), np.float32(0.3909)] 
2024-12-23 00:51:55.924742: Epoch time: 32.19 s 
2024-12-23 00:51:56.477916:  
2024-12-23 00:51:56.478418: Epoch 76 
2024-12-23 00:51:56.481934: Current learning rate: 0.00277 
2024-12-23 00:52:28.650397: train_loss -0.7148 
2024-12-23 00:52:28.650900: val_loss -0.5675 
2024-12-23 00:52:28.656487: Pseudo dice [np.float32(0.7374), np.float32(0.5406)] 
2024-12-23 00:52:28.660519: Epoch time: 32.17 s 
2024-12-23 00:52:29.206603:  
2024-12-23 00:52:29.207608: Epoch 77 
2024-12-23 00:52:29.212149: Current learning rate: 0.00266 
2024-12-23 00:53:01.362894: train_loss -0.7346 
2024-12-23 00:53:01.363416: val_loss -0.5433 
2024-12-23 00:53:01.370503: Pseudo dice [np.float32(0.7453), np.float32(0.4348)] 
2024-12-23 00:53:01.374015: Epoch time: 32.16 s 
2024-12-23 00:53:01.930231:  
2024-12-23 00:53:01.931235: Epoch 78 
2024-12-23 00:53:01.936265: Current learning rate: 0.00256 
2024-12-23 00:53:34.074499: train_loss -0.7193 
2024-12-23 00:53:34.075502: val_loss -0.5515 
2024-12-23 00:53:34.081518: Pseudo dice [np.float32(0.7536), np.float32(0.5208)] 
2024-12-23 00:53:34.085532: Epoch time: 32.14 s 
2024-12-23 00:53:34.640276:  
2024-12-23 00:53:34.641279: Epoch 79 
2024-12-23 00:53:34.646115: Current learning rate: 0.00245 
2024-12-23 00:54:06.813094: train_loss -0.7272 
2024-12-23 00:54:06.813595: val_loss -0.5289 
2024-12-23 00:54:06.819613: Pseudo dice [np.float32(0.7487), np.float32(0.4205)] 
2024-12-23 00:54:06.823117: Epoch time: 32.17 s 
2024-12-23 00:54:07.378754:  
2024-12-23 00:54:07.379754: Epoch 80 
2024-12-23 00:54:07.387367: Current learning rate: 0.00235 
2024-12-23 00:54:39.758195: train_loss -0.7351 
2024-12-23 00:54:39.758195: val_loss -0.5362 
2024-12-23 00:54:39.767721: Pseudo dice [np.float32(0.7369), np.float32(0.4463)] 
2024-12-23 00:54:39.773236: Epoch time: 32.38 s 
2024-12-23 00:54:40.624844:  
2024-12-23 00:54:40.624844: Epoch 81 
2024-12-23 00:54:40.630956: Current learning rate: 0.00224 
2024-12-23 00:55:14.721704: train_loss -0.7308 
2024-12-23 00:55:14.722208: val_loss -0.5573 
2024-12-23 00:55:14.728283: Pseudo dice [np.float32(0.746), np.float32(0.4411)] 
2024-12-23 00:55:14.731812: Epoch time: 34.1 s 
2024-12-23 00:55:15.292632:  
2024-12-23 00:55:15.293137: Epoch 82 
2024-12-23 00:55:15.297643: Current learning rate: 0.00214 
2024-12-23 00:55:49.744721: train_loss -0.727 
2024-12-23 00:55:49.744721: val_loss -0.5731 
2024-12-23 00:55:49.752244: Pseudo dice [np.float32(0.7364), np.float32(0.5166)] 
2024-12-23 00:55:49.757260: Epoch time: 34.45 s 
2024-12-23 00:55:50.321437:  
2024-12-23 00:55:50.321437: Epoch 83 
2024-12-23 00:55:50.326482: Current learning rate: 0.00203 
2024-12-23 00:56:22.492495: train_loss -0.7325 
2024-12-23 00:56:22.492998: val_loss -0.5932 
2024-12-23 00:56:22.498010: Pseudo dice [np.float32(0.7441), np.float32(0.558)] 
2024-12-23 00:56:22.502520: Epoch time: 32.17 s 
2024-12-23 00:56:23.026748:  
2024-12-23 00:56:23.026748: Epoch 84 
2024-12-23 00:56:23.033364: Current learning rate: 0.00192 
2024-12-23 00:56:55.190650: train_loss -0.7367 
2024-12-23 00:56:55.190650: val_loss -0.5596 
2024-12-23 00:56:55.197775: Pseudo dice [np.float32(0.7277), np.float32(0.4787)] 
2024-12-23 00:56:55.203857: Epoch time: 32.16 s 
2024-12-23 00:56:55.726040:  
2024-12-23 00:56:55.726544: Epoch 85 
2024-12-23 00:56:55.732558: Current learning rate: 0.00181 
2024-12-23 00:57:27.926120: train_loss -0.7367 
2024-12-23 00:57:27.926120: val_loss -0.562 
2024-12-23 00:57:27.931131: Pseudo dice [np.float32(0.7511), np.float32(0.5052)] 
2024-12-23 00:57:27.935141: Epoch time: 32.2 s 
2024-12-23 00:57:28.453857:  
2024-12-23 00:57:28.453857: Epoch 86 
2024-12-23 00:57:28.459405: Current learning rate: 0.0017 
2024-12-23 00:58:00.610499: train_loss -0.7517 
2024-12-23 00:58:00.611009: val_loss -0.6008 
2024-12-23 00:58:00.616537: Pseudo dice [np.float32(0.7655), np.float32(0.5134)] 
2024-12-23 00:58:00.620041: Epoch time: 32.16 s 
2024-12-23 00:58:00.624052: Yayy! New best EMA pseudo Dice: 0.6119999885559082 
2024-12-23 00:58:01.411924:  
2024-12-23 00:58:01.411924: Epoch 87 
2024-12-23 00:58:01.417446: Current learning rate: 0.00159 
2024-12-23 00:58:33.565764: train_loss -0.7319 
2024-12-23 00:58:33.566267: val_loss -0.5464 
2024-12-23 00:58:33.571280: Pseudo dice [np.float32(0.7327), np.float32(0.4263)] 
2024-12-23 00:58:33.575790: Epoch time: 32.15 s 
2024-12-23 00:58:34.094507:  
2024-12-23 00:58:34.094507: Epoch 88 
2024-12-23 00:58:34.099752: Current learning rate: 0.00148 
2024-12-23 00:59:06.248665: train_loss -0.7312 
2024-12-23 00:59:06.249180: val_loss -0.6091 
2024-12-23 00:59:06.256284: Pseudo dice [np.float32(0.7583), np.float32(0.545)] 
2024-12-23 00:59:06.260914: Epoch time: 32.16 s 
2024-12-23 00:59:06.264477: Yayy! New best EMA pseudo Dice: 0.6129999756813049 
2024-12-23 00:59:07.254495:  
2024-12-23 00:59:07.254998: Epoch 89 
2024-12-23 00:59:07.259545: Current learning rate: 0.00137 
2024-12-23 00:59:39.411677: train_loss -0.7321 
2024-12-23 00:59:39.412683: val_loss -0.5189 
2024-12-23 00:59:39.417692: Pseudo dice [np.float32(0.7405), np.float32(0.4309)] 
2024-12-23 00:59:39.421199: Epoch time: 32.16 s 
2024-12-23 00:59:39.935353:  
2024-12-23 00:59:39.936357: Epoch 90 
2024-12-23 00:59:39.940928: Current learning rate: 0.00126 
2024-12-23 01:00:12.086591: train_loss -0.7432 
2024-12-23 01:00:12.088097: val_loss -0.5496 
2024-12-23 01:00:12.095706: Pseudo dice [np.float32(0.7528), np.float32(0.4559)] 
2024-12-23 01:00:12.100757: Epoch time: 32.15 s 
2024-12-23 01:00:12.614682:  
2024-12-23 01:00:12.615185: Epoch 91 
2024-12-23 01:00:12.621297: Current learning rate: 0.00115 
2024-12-23 01:00:44.793418: train_loss -0.7667 
2024-12-23 01:00:44.794418: val_loss -0.5743 
2024-12-23 01:00:44.799935: Pseudo dice [np.float32(0.7484), np.float32(0.4783)] 
2024-12-23 01:00:44.803451: Epoch time: 32.18 s 
2024-12-23 01:00:45.321851:  
2024-12-23 01:00:45.321851: Epoch 92 
2024-12-23 01:00:45.327085: Current learning rate: 0.00103 
2024-12-23 01:01:17.475410: train_loss -0.7555 
2024-12-23 01:01:17.475913: val_loss -0.5558 
2024-12-23 01:01:17.482935: Pseudo dice [np.float32(0.7415), np.float32(0.5087)] 
2024-12-23 01:01:17.487952: Epoch time: 32.15 s 
2024-12-23 01:01:18.001802:  
2024-12-23 01:01:18.001802: Epoch 93 
2024-12-23 01:01:18.008315: Current learning rate: 0.00091 
2024-12-23 01:01:50.182604: train_loss -0.7584 
2024-12-23 01:01:50.183106: val_loss -0.5867 
2024-12-23 01:01:50.188114: Pseudo dice [np.float32(0.7463), np.float32(0.4973)] 
2024-12-23 01:01:50.192627: Epoch time: 32.18 s 
2024-12-23 01:01:50.713502:  
2024-12-23 01:01:50.714505: Epoch 94 
2024-12-23 01:01:50.719527: Current learning rate: 0.00079 
2024-12-23 01:02:22.868386: train_loss -0.7582 
2024-12-23 01:02:22.868895: val_loss -0.5886 
2024-12-23 01:02:22.875932: Pseudo dice [np.float32(0.7559), np.float32(0.487)] 
2024-12-23 01:02:22.880439: Epoch time: 32.15 s 
2024-12-23 01:02:22.883446: Yayy! New best EMA pseudo Dice: 0.6134999990463257 
2024-12-23 01:02:23.666548:  
2024-12-23 01:02:23.667050: Epoch 95 
2024-12-23 01:02:23.672586: Current learning rate: 0.00067 
2024-12-23 01:02:55.802640: train_loss -0.758 
2024-12-23 01:02:55.802640: val_loss -0.5749 
2024-12-23 01:02:55.809743: Pseudo dice [np.float32(0.7492), np.float32(0.4943)] 
2024-12-23 01:02:55.814279: Epoch time: 32.14 s 
2024-12-23 01:02:55.818892: Yayy! New best EMA pseudo Dice: 0.614300012588501 
2024-12-23 01:02:56.656173:  
2024-12-23 01:02:56.656173: Epoch 96 
2024-12-23 01:02:56.662205: Current learning rate: 0.00055 
2024-12-23 01:03:28.808290: train_loss -0.7595 
2024-12-23 01:03:28.808290: val_loss -0.5767 
2024-12-23 01:03:28.816333: Pseudo dice [np.float32(0.751), np.float32(0.5359)] 
2024-12-23 01:03:28.822348: Epoch time: 32.15 s 
2024-12-23 01:03:28.825893: Yayy! New best EMA pseudo Dice: 0.6172000169754028 
2024-12-23 01:03:29.814446:  
2024-12-23 01:03:29.815450: Epoch 97 
2024-12-23 01:03:29.820999: Current learning rate: 0.00043 
2024-12-23 01:04:01.964530: train_loss -0.7651 
2024-12-23 01:04:01.965032: val_loss -0.5416 
2024-12-23 01:04:01.970043: Pseudo dice [np.float32(0.7375), np.float32(0.432)] 
2024-12-23 01:04:01.973552: Epoch time: 32.15 s 
2024-12-23 01:04:02.501096:  
2024-12-23 01:04:02.501598: Epoch 98 
2024-12-23 01:04:02.507612: Current learning rate: 0.0003 
2024-12-23 01:04:34.699594: train_loss -0.7791 
2024-12-23 01:04:34.700599: val_loss -0.5786 
2024-12-23 01:04:34.707155: Pseudo dice [np.float32(0.747), np.float32(0.5114)] 
2024-12-23 01:04:34.712166: Epoch time: 32.2 s 
2024-12-23 01:04:35.244749:  
2024-12-23 01:04:35.245254: Epoch 99 
2024-12-23 01:04:35.252335: Current learning rate: 0.00016 
2024-12-23 01:05:07.407556: train_loss -0.7645 
2024-12-23 01:05:07.408059: val_loss -0.5658 
2024-12-23 01:05:07.414632: Pseudo dice [np.float32(0.7509), np.float32(0.5056)] 
2024-12-23 01:05:07.418641: Epoch time: 32.16 s 
2024-12-23 01:05:08.198374: Training done. 
2024-12-23 01:05:08.245381: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-23 01:05:08.253886: The split file contains 5 splits. 
2024-12-23 01:05:08.263892: Desired fold for training: 0 
2024-12-23 01:05:08.271894: This split has 224 training and 57 validation cases. 
2024-12-23 01:05:08.278893: predicting pancreas_021 
2024-12-23 01:05:08.287890: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2024-12-23 01:05:13.957494: predicting pancreas_024 
2024-12-23 01:05:13.968499: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2024-12-23 01:05:15.432961: predicting pancreas_035 
2024-12-23 01:05:15.442962: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2024-12-23 01:05:16.875912: predicting pancreas_040 
2024-12-23 01:05:16.881912: pancreas_040, shape torch.Size([1, 45, 526, 526]), rank 0 
2024-12-23 01:05:19.855578: predicting pancreas_042 
2024-12-23 01:05:19.861083: pancreas_042, shape torch.Size([1, 51, 537, 537]), rank 0 
2024-12-23 01:05:23.288180: predicting pancreas_056 
2024-12-23 01:05:23.295181: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2024-12-23 01:05:24.654342: predicting pancreas_067 
2024-12-23 01:05:24.665424: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2024-12-23 01:05:30.723013: predicting pancreas_075 
2024-12-23 01:05:30.735013: pancreas_075, shape torch.Size([1, 121, 521, 521]), rank 0 
2024-12-23 01:05:37.134832: predicting pancreas_086 
2024-12-23 01:05:37.148837: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2024-12-23 01:05:40.281738: predicting pancreas_089 
2024-12-23 01:05:40.288739: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-23 01:05:41.998005: predicting pancreas_092 
2024-12-23 01:05:42.011003: pancreas_092, shape torch.Size([1, 92, 513, 513]), rank 0 
2024-12-23 01:05:47.556179: predicting pancreas_094 
2024-12-23 01:05:47.565682: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2024-12-23 01:05:49.172126: predicting pancreas_095 
2024-12-23 01:05:49.179126: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2024-12-23 01:05:50.843828: predicting pancreas_098 
2024-12-23 01:05:50.857830: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2024-12-23 01:05:58.972352: predicting pancreas_109 
2024-12-23 01:05:58.988352: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2024-12-23 01:06:00.793532: predicting pancreas_110 
2024-12-23 01:06:00.805532: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2024-12-23 01:06:07.466001: predicting pancreas_114 
2024-12-23 01:06:07.483506: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2024-12-23 01:06:09.467688: predicting pancreas_119 
2024-12-23 01:06:09.478195: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2024-12-23 01:06:14.443081: predicting pancreas_138 
2024-12-23 01:06:14.452082: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2024-12-23 01:06:19.878750: predicting pancreas_145 
2024-12-23 01:06:19.889260: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2024-12-23 01:06:25.418677: predicting pancreas_148 
2024-12-23 01:06:25.432678: pancreas_148, shape torch.Size([1, 42, 486, 486]), rank 0 
2024-12-23 01:06:26.517747: predicting pancreas_169 
2024-12-23 01:06:26.522748: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2024-12-23 01:06:28.538522: predicting pancreas_170 
2024-12-23 01:06:28.547521: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2024-12-23 01:06:30.380338: predicting pancreas_172 
2024-12-23 01:06:30.388843: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2024-12-23 01:06:32.012517: predicting pancreas_175 
2024-12-23 01:06:32.020519: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-23 01:06:33.577308: predicting pancreas_180 
2024-12-23 01:06:33.585310: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2024-12-23 01:06:35.864395: predicting pancreas_191 
2024-12-23 01:06:35.873397: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2024-12-23 01:06:37.020258: predicting pancreas_193 
2024-12-23 01:06:37.026260: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2024-12-23 01:06:39.460896: predicting pancreas_212 
2024-12-23 01:06:39.469896: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2024-12-23 01:06:49.352240: predicting pancreas_215 
2024-12-23 01:06:49.366240: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2024-12-23 01:06:54.171953: predicting pancreas_222 
2024-12-23 01:06:54.182959: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2024-12-23 01:06:55.607421: predicting pancreas_235 
2024-12-23 01:06:55.613421: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2024-12-23 01:06:57.588515: predicting pancreas_241 
2024-12-23 01:06:57.599020: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2024-12-23 01:06:59.435471: predicting pancreas_242 
2024-12-23 01:06:59.443470: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2024-12-23 01:07:05.444108: predicting pancreas_244 
2024-12-23 01:07:05.455107: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2024-12-23 01:07:11.434028: predicting pancreas_246 
2024-12-23 01:07:11.445029: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2024-12-23 01:07:17.654452: predicting pancreas_247 
2024-12-23 01:07:17.666451: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2024-12-23 01:07:19.272279: predicting pancreas_264 
2024-12-23 01:07:19.279279: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2024-12-23 01:07:25.410013: predicting pancreas_265 
2024-12-23 01:07:25.423012: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2024-12-23 01:07:30.548759: predicting pancreas_266 
2024-12-23 01:07:30.557760: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2024-12-23 01:07:36.148333: predicting pancreas_267 
2024-12-23 01:07:36.161334: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2024-12-23 01:07:37.780374: predicting pancreas_275 
2024-12-23 01:07:37.788375: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2024-12-23 01:07:39.703308: predicting pancreas_279 
2024-12-23 01:07:39.713308: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2024-12-23 01:07:41.174452: predicting pancreas_287 
2024-12-23 01:07:41.183453: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2024-12-23 01:07:42.898729: predicting pancreas_301 
2024-12-23 01:07:42.910732: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2024-12-23 01:07:47.830314: predicting pancreas_323 
2024-12-23 01:07:47.842314: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2024-12-23 01:07:53.351958: predicting pancreas_336 
2024-12-23 01:07:53.363958: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2024-12-23 01:07:58.766421: predicting pancreas_344 
2024-12-23 01:07:58.780421: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2024-12-23 01:08:01.217705: predicting pancreas_351 
2024-12-23 01:08:01.226776: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2024-12-23 01:08:02.469741: predicting pancreas_354 
2024-12-23 01:08:02.478741: pancreas_354, shape torch.Size([1, 81, 529, 529]), rank 0 
2024-12-23 01:08:07.182917: predicting pancreas_372 
2024-12-23 01:08:07.191916: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2024-12-23 01:08:12.595035: predicting pancreas_377 
2024-12-23 01:08:12.606035: pancreas_377, shape torch.Size([1, 55, 551, 551]), rank 0 
2024-12-23 01:08:16.168579: predicting pancreas_387 
2024-12-23 01:08:16.177579: pancreas_387, shape torch.Size([1, 50, 498, 498]), rank 0 
2024-12-23 01:08:17.081475: predicting pancreas_391 
2024-12-23 01:08:17.088477: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2024-12-23 01:08:22.006317: predicting pancreas_392 
2024-12-23 01:08:22.022318: pancreas_392, shape torch.Size([1, 57, 448, 448]), rank 0 
2024-12-23 01:08:23.045450: predicting pancreas_410 
2024-12-23 01:08:23.051450: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2024-12-23 01:08:24.815193: predicting pancreas_412 
2024-12-23 01:08:24.827199: pancreas_412, shape torch.Size([1, 164, 584, 584]), rank 0 
2024-12-23 01:08:45.029737: Validation complete 
2024-12-23 01:08:45.030737: Mean Validation Dice:  0.34559029309875244 
