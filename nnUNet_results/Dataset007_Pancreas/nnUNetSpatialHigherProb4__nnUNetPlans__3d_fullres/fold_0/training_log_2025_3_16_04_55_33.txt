
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-16 04:55:33.425477: do_dummy_2d_data_aug: True 
2025-03-16 04:55:33.427479: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-03-16 04:55:33.435477: The split file contains 5 splits. 
2025-03-16 04:55:33.438477: Desired fold for training: 0 
2025-03-16 04:55:33.441477: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-03-16 04:55:40.066001: unpacking dataset... 
2025-03-16 04:55:40.467639: unpacking done... 
2025-03-16 04:55:43.293886:  
2025-03-16 04:55:43.298916: Epoch 0 
2025-03-16 04:55:43.302035: Current learning rate: 0.01 
2025-03-16 04:56:28.678891: train_loss 0.1042 
2025-03-16 04:56:28.684904: val_loss 0.053 
2025-03-16 04:56:28.689922: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-03-16 04:56:28.693446: Epoch time: 45.39 s 
2025-03-16 04:56:28.696482: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-16 04:56:29.305275:  
2025-03-16 04:56:29.310864: Epoch 1 
2025-03-16 04:56:29.313917: Current learning rate: 0.00991 
2025-03-16 04:57:10.257646: train_loss -0.0038 
2025-03-16 04:57:10.263510: val_loss -0.1227 
2025-03-16 04:57:10.266768: Pseudo dice [np.float32(0.4447), np.float32(0.0)] 
2025-03-16 04:57:10.270278: Epoch time: 40.95 s 
2025-03-16 04:57:10.274288: Yayy! New best EMA pseudo Dice: 0.022199999541044235 
2025-03-16 04:57:10.958022:  
2025-03-16 04:57:10.962971: Epoch 2 
2025-03-16 04:57:10.967674: Current learning rate: 0.00982 
2025-03-16 04:57:51.881896: train_loss -0.11 
2025-03-16 04:57:51.887909: val_loss -0.1509 
2025-03-16 04:57:51.891927: Pseudo dice [np.float32(0.4655), np.float32(0.0)] 
2025-03-16 04:57:51.895438: Epoch time: 40.92 s 
2025-03-16 04:57:51.898046: Yayy! New best EMA pseudo Dice: 0.043299999088048935 
2025-03-16 04:57:52.636034:  
2025-03-16 04:57:52.641581: Epoch 3 
2025-03-16 04:57:52.645202: Current learning rate: 0.00973 
2025-03-16 04:58:33.568610: train_loss -0.1781 
2025-03-16 04:58:33.574666: val_loss -0.2411 
2025-03-16 04:58:33.578179: Pseudo dice [np.float32(0.5808), np.float32(0.0)] 
2025-03-16 04:58:33.583725: Epoch time: 40.93 s 
2025-03-16 04:58:33.587265: Yayy! New best EMA pseudo Dice: 0.06800000369548798 
2025-03-16 04:58:34.270874:  
2025-03-16 04:58:34.276469: Epoch 4 
2025-03-16 04:58:34.279016: Current learning rate: 0.00964 
2025-03-16 04:59:15.152321: train_loss -0.2059 
2025-03-16 04:59:15.157367: val_loss -0.2819 
2025-03-16 04:59:15.161377: Pseudo dice [np.float32(0.6141), np.float32(0.0)] 
2025-03-16 04:59:15.164893: Epoch time: 40.88 s 
2025-03-16 04:59:15.167397: Yayy! New best EMA pseudo Dice: 0.09189999848604202 
2025-03-16 04:59:16.055926:  
2025-03-16 04:59:16.061456: Epoch 5 
2025-03-16 04:59:16.065084: Current learning rate: 0.00955 
2025-03-16 04:59:56.931719: train_loss -0.2597 
2025-03-16 04:59:56.937233: val_loss -0.3058 
2025-03-16 04:59:56.940744: Pseudo dice [np.float32(0.601), np.float32(0.0)] 
2025-03-16 04:59:56.944755: Epoch time: 40.88 s 
2025-03-16 04:59:56.948266: Yayy! New best EMA pseudo Dice: 0.1128000020980835 
2025-03-16 04:59:57.657213:  
2025-03-16 04:59:57.662763: Epoch 6 
2025-03-16 04:59:57.667873: Current learning rate: 0.00946 
2025-03-16 05:00:38.610748: train_loss -0.2847 
2025-03-16 05:00:38.617263: val_loss -0.4192 
2025-03-16 05:00:38.621310: Pseudo dice [np.float32(0.6561), np.float32(0.4112)] 
2025-03-16 05:00:38.624355: Epoch time: 40.95 s 
2025-03-16 05:00:38.627403: Yayy! New best EMA pseudo Dice: 0.15479999780654907 
2025-03-16 05:00:39.319896:  
2025-03-16 05:00:39.325411: Epoch 7 
2025-03-16 05:00:39.327917: Current learning rate: 0.00937 
2025-03-16 05:01:20.200278: train_loss -0.3059 
2025-03-16 05:01:20.206839: val_loss -0.4089 
2025-03-16 05:01:20.211888: Pseudo dice [np.float32(0.6448), np.float32(0.3753)] 
2025-03-16 05:01:20.214966: Epoch time: 40.88 s 
2025-03-16 05:01:20.218526: Yayy! New best EMA pseudo Dice: 0.19040000438690186 
2025-03-16 05:01:20.957952:  
2025-03-16 05:01:20.964044: Epoch 8 
2025-03-16 05:01:20.968057: Current learning rate: 0.00928 
2025-03-16 05:02:01.845793: train_loss -0.3034 
2025-03-16 05:02:01.853439: val_loss -0.3199 
2025-03-16 05:02:01.856971: Pseudo dice [np.float32(0.6323), np.float32(0.1454)] 
2025-03-16 05:02:01.859998: Epoch time: 40.89 s 
2025-03-16 05:02:01.863981: Yayy! New best EMA pseudo Dice: 0.2101999968290329 
2025-03-16 05:02:02.566729:  
2025-03-16 05:02:02.572272: Epoch 9 
2025-03-16 05:02:02.577336: Current learning rate: 0.00919 
2025-03-16 05:02:43.445750: train_loss -0.3584 
2025-03-16 05:02:43.452278: val_loss -0.428 
2025-03-16 05:02:43.457289: Pseudo dice [np.float32(0.6554), np.float32(0.3741)] 
2025-03-16 05:02:43.460807: Epoch time: 40.88 s 
2025-03-16 05:02:43.464833: Yayy! New best EMA pseudo Dice: 0.24070000648498535 
2025-03-16 05:02:44.175359:  
2025-03-16 05:02:44.180872: Epoch 10 
2025-03-16 05:02:44.185886: Current learning rate: 0.0091 
2025-03-16 05:03:25.070548: train_loss -0.358 
2025-03-16 05:03:25.077761: val_loss -0.3864 
2025-03-16 05:03:25.081273: Pseudo dice [np.float32(0.5921), np.float32(0.3652)] 
2025-03-16 05:03:25.084777: Epoch time: 40.9 s 
2025-03-16 05:03:25.088797: Yayy! New best EMA pseudo Dice: 0.2644999921321869 
2025-03-16 05:03:25.763535:  
2025-03-16 05:03:25.769567: Epoch 11 
2025-03-16 05:03:25.773616: Current learning rate: 0.009 
2025-03-16 05:04:06.647467: train_loss -0.3684 
2025-03-16 05:04:06.655558: val_loss -0.4637 
2025-03-16 05:04:06.659154: Pseudo dice [np.float32(0.647), np.float32(0.4552)] 
2025-03-16 05:04:06.662676: Epoch time: 40.88 s 
2025-03-16 05:04:06.665240: Yayy! New best EMA pseudo Dice: 0.2930999994277954 
2025-03-16 05:04:07.437751:  
2025-03-16 05:04:07.443816: Epoch 12 
2025-03-16 05:04:07.446856: Current learning rate: 0.00891 
2025-03-16 05:04:48.330517: train_loss -0.377 
2025-03-16 05:04:48.335528: val_loss -0.4394 
2025-03-16 05:04:48.339541: Pseudo dice [np.float32(0.6835), np.float32(0.3721)] 
2025-03-16 05:04:48.343051: Epoch time: 40.89 s 
2025-03-16 05:04:48.345557: Yayy! New best EMA pseudo Dice: 0.3165999948978424 
2025-03-16 05:04:49.181588:  
2025-03-16 05:04:49.185606: Epoch 13 
2025-03-16 05:04:49.189642: Current learning rate: 0.00882 
2025-03-16 05:05:30.067692: train_loss -0.409 
2025-03-16 05:05:30.074206: val_loss -0.4432 
2025-03-16 05:05:30.079217: Pseudo dice [np.float32(0.6771), np.float32(0.3058)] 
2025-03-16 05:05:30.082724: Epoch time: 40.89 s 
2025-03-16 05:05:30.086369: Yayy! New best EMA pseudo Dice: 0.33410000801086426 
2025-03-16 05:05:30.806701:  
2025-03-16 05:05:30.813270: Epoch 14 
2025-03-16 05:05:30.816812: Current learning rate: 0.00873 
2025-03-16 05:06:11.669321: train_loss -0.4166 
2025-03-16 05:06:11.676413: val_loss -0.4252 
2025-03-16 05:06:11.681424: Pseudo dice [np.float32(0.6616), np.float32(0.3621)] 
2025-03-16 05:06:11.684971: Epoch time: 40.86 s 
2025-03-16 05:06:11.688481: Yayy! New best EMA pseudo Dice: 0.35190001130104065 
2025-03-16 05:06:12.381502:  
2025-03-16 05:06:12.387539: Epoch 15 
2025-03-16 05:06:12.391051: Current learning rate: 0.00864 
2025-03-16 05:06:53.263146: train_loss -0.4411 
2025-03-16 05:06:53.269161: val_loss -0.5062 
2025-03-16 05:06:53.272791: Pseudo dice [np.float32(0.7042), np.float32(0.455)] 
2025-03-16 05:06:53.276302: Epoch time: 40.88 s 
2025-03-16 05:06:53.279536: Yayy! New best EMA pseudo Dice: 0.37459999322891235 
2025-03-16 05:06:54.016346:  
2025-03-16 05:06:54.022412: Epoch 16 
2025-03-16 05:06:54.026470: Current learning rate: 0.00855 
2025-03-16 05:07:34.892722: train_loss -0.4341 
2025-03-16 05:07:34.898745: val_loss -0.4705 
2025-03-16 05:07:34.902763: Pseudo dice [np.float32(0.7191), np.float32(0.4038)] 
2025-03-16 05:07:34.906278: Epoch time: 40.88 s 
2025-03-16 05:07:34.910290: Yayy! New best EMA pseudo Dice: 0.39329999685287476 
2025-03-16 05:07:35.611300:  
2025-03-16 05:07:35.616870: Epoch 17 
2025-03-16 05:07:35.619906: Current learning rate: 0.00846 
2025-03-16 05:08:16.491662: train_loss -0.4364 
2025-03-16 05:08:16.497198: val_loss -0.4957 
2025-03-16 05:08:16.501741: Pseudo dice [np.float32(0.7196), np.float32(0.4274)] 
2025-03-16 05:08:16.505249: Epoch time: 40.88 s 
2025-03-16 05:08:16.510262: Yayy! New best EMA pseudo Dice: 0.41130000352859497 
2025-03-16 05:08:17.234230:  
2025-03-16 05:08:17.239745: Epoch 18 
2025-03-16 05:08:17.243253: Current learning rate: 0.00836 
2025-03-16 05:08:58.109518: train_loss -0.447 
2025-03-16 05:08:58.115592: val_loss -0.4736 
2025-03-16 05:08:58.119606: Pseudo dice [np.float32(0.6969), np.float32(0.43)] 
2025-03-16 05:08:58.122112: Epoch time: 40.88 s 
2025-03-16 05:08:58.125620: Yayy! New best EMA pseudo Dice: 0.42649999260902405 
2025-03-16 05:08:58.826602:  
2025-03-16 05:08:58.832744: Epoch 19 
2025-03-16 05:08:58.836797: Current learning rate: 0.00827 
2025-03-16 05:09:39.697864: train_loss -0.4425 
2025-03-16 05:09:39.703877: val_loss -0.5059 
2025-03-16 05:09:39.707887: Pseudo dice [np.float32(0.7208), np.float32(0.4412)] 
2025-03-16 05:09:39.711435: Epoch time: 40.87 s 
2025-03-16 05:09:39.713463: Yayy! New best EMA pseudo Dice: 0.44200000166893005 
2025-03-16 05:09:40.446466:  
2025-03-16 05:09:40.451981: Epoch 20 
2025-03-16 05:09:40.455488: Current learning rate: 0.00818 
2025-03-16 05:10:21.324869: train_loss -0.456 
2025-03-16 05:10:21.330881: val_loss -0.4107 
2025-03-16 05:10:21.334892: Pseudo dice [np.float32(0.6903), np.float32(0.2353)] 
2025-03-16 05:10:21.337399: Epoch time: 40.88 s 
2025-03-16 05:10:21.340908: Yayy! New best EMA pseudo Dice: 0.4440999925136566 
2025-03-16 05:10:22.203604:  
2025-03-16 05:10:22.208710: Epoch 21 
2025-03-16 05:10:22.212226: Current learning rate: 0.00809 
2025-03-16 05:11:03.082189: train_loss -0.4433 
2025-03-16 05:11:03.088202: val_loss -0.488 
2025-03-16 05:11:03.092212: Pseudo dice [np.float32(0.7149), np.float32(0.324)] 
2025-03-16 05:11:03.095722: Epoch time: 40.88 s 
2025-03-16 05:11:03.099233: Yayy! New best EMA pseudo Dice: 0.45159998536109924 
2025-03-16 05:11:03.803905:  
2025-03-16 05:11:03.809490: Epoch 22 
2025-03-16 05:11:03.814073: Current learning rate: 0.008 
2025-03-16 05:11:44.674197: train_loss -0.4699 
2025-03-16 05:11:44.679723: val_loss -0.4439 
2025-03-16 05:11:44.682277: Pseudo dice [np.float32(0.6846), np.float32(0.3665)] 
2025-03-16 05:11:44.686307: Epoch time: 40.87 s 
2025-03-16 05:11:44.689313: Yayy! New best EMA pseudo Dice: 0.45899999141693115 
2025-03-16 05:11:45.396578:  
2025-03-16 05:11:45.402143: Epoch 23 
2025-03-16 05:11:45.406173: Current learning rate: 0.0079 
2025-03-16 05:12:26.276719: train_loss -0.4484 
2025-03-16 05:12:26.283774: val_loss -0.3838 
2025-03-16 05:12:26.287287: Pseudo dice [np.float32(0.6996), np.float32(0.1777)] 
2025-03-16 05:12:26.290793: Epoch time: 40.88 s 
2025-03-16 05:12:26.812342:  
2025-03-16 05:12:26.817477: Epoch 24 
2025-03-16 05:12:26.821549: Current learning rate: 0.00781 
2025-03-16 05:13:07.671357: train_loss -0.4401 
2025-03-16 05:13:07.676369: val_loss -0.4961 
2025-03-16 05:13:07.680922: Pseudo dice [np.float32(0.7006), np.float32(0.4196)] 
2025-03-16 05:13:07.683985: Epoch time: 40.86 s 
2025-03-16 05:13:07.687495: Yayy! New best EMA pseudo Dice: 0.4672999978065491 
2025-03-16 05:13:08.367539:  
2025-03-16 05:13:08.371588: Epoch 25 
2025-03-16 05:13:08.374166: Current learning rate: 0.00772 
2025-03-16 05:13:49.249593: train_loss -0.4893 
2025-03-16 05:13:49.255697: val_loss -0.4879 
2025-03-16 05:13:49.260164: Pseudo dice [np.float32(0.7113), np.float32(0.3851)] 
2025-03-16 05:13:49.263179: Epoch time: 40.88 s 
2025-03-16 05:13:49.265684: Yayy! New best EMA pseudo Dice: 0.47540000081062317 
2025-03-16 05:13:49.993665:  
2025-03-16 05:13:49.998674: Epoch 26 
2025-03-16 05:13:50.003200: Current learning rate: 0.00763 
2025-03-16 05:14:30.870368: train_loss -0.4935 
2025-03-16 05:14:30.875882: val_loss -0.5051 
2025-03-16 05:14:30.879390: Pseudo dice [np.float32(0.6971), np.float32(0.4489)] 
2025-03-16 05:14:30.882896: Epoch time: 40.88 s 
2025-03-16 05:14:30.885905: Yayy! New best EMA pseudo Dice: 0.48510000109672546 
2025-03-16 05:14:31.560422:  
2025-03-16 05:14:31.566046: Epoch 27 
2025-03-16 05:14:31.569586: Current learning rate: 0.00753 
2025-03-16 05:15:12.442598: train_loss -0.5152 
2025-03-16 05:15:12.449252: val_loss -0.4867 
2025-03-16 05:15:12.453277: Pseudo dice [np.float32(0.6962), np.float32(0.4001)] 
2025-03-16 05:15:12.455812: Epoch time: 40.88 s 
2025-03-16 05:15:12.459324: Yayy! New best EMA pseudo Dice: 0.49140000343322754 
2025-03-16 05:15:13.178428:  
2025-03-16 05:15:13.183490: Epoch 28 
2025-03-16 05:15:13.187001: Current learning rate: 0.00744 
2025-03-16 05:15:54.052691: train_loss -0.5083 
2025-03-16 05:15:54.058719: val_loss -0.4984 
2025-03-16 05:15:54.062726: Pseudo dice [np.float32(0.725), np.float32(0.3813)] 
2025-03-16 05:15:54.065232: Epoch time: 40.88 s 
2025-03-16 05:15:54.068261: Yayy! New best EMA pseudo Dice: 0.4975999891757965 
2025-03-16 05:15:54.881449:  
2025-03-16 05:15:54.886472: Epoch 29 
2025-03-16 05:15:54.890564: Current learning rate: 0.00735 
2025-03-16 05:16:35.753732: train_loss -0.5186 
2025-03-16 05:16:35.759246: val_loss -0.4675 
2025-03-16 05:16:35.762756: Pseudo dice [np.float32(0.7421), np.float32(0.2436)] 
2025-03-16 05:16:35.766777: Epoch time: 40.87 s 
2025-03-16 05:16:36.300591:  
2025-03-16 05:16:36.306308: Epoch 30 
2025-03-16 05:16:36.309856: Current learning rate: 0.00725 
2025-03-16 05:17:17.197447: train_loss -0.5222 
2025-03-16 05:17:17.204616: val_loss -0.5317 
2025-03-16 05:17:17.209124: Pseudo dice [np.float32(0.7388), np.float32(0.4362)] 
2025-03-16 05:17:17.212135: Epoch time: 40.9 s 
2025-03-16 05:17:17.214640: Yayy! New best EMA pseudo Dice: 0.5062000155448914 
2025-03-16 05:17:17.934887:  
2025-03-16 05:17:17.939794: Epoch 31 
2025-03-16 05:17:17.944307: Current learning rate: 0.00716 
2025-03-16 05:17:58.804727: train_loss -0.5196 
2025-03-16 05:17:58.810741: val_loss -0.5226 
2025-03-16 05:17:58.814246: Pseudo dice [np.float32(0.7378), np.float32(0.4064)] 
2025-03-16 05:17:58.817255: Epoch time: 40.87 s 
2025-03-16 05:17:58.819761: Yayy! New best EMA pseudo Dice: 0.5127999782562256 
2025-03-16 05:17:59.508984:  
2025-03-16 05:17:59.514522: Epoch 32 
2025-03-16 05:17:59.518109: Current learning rate: 0.00707 
2025-03-16 05:18:40.378280: train_loss -0.5025 
2025-03-16 05:18:40.385322: val_loss -0.4961 
2025-03-16 05:18:40.388331: Pseudo dice [np.float32(0.7251), np.float32(0.3865)] 
2025-03-16 05:18:40.390836: Epoch time: 40.87 s 
2025-03-16 05:18:40.394348: Yayy! New best EMA pseudo Dice: 0.5170999765396118 
2025-03-16 05:18:41.126505:  
2025-03-16 05:18:41.131567: Epoch 33 
2025-03-16 05:18:41.135080: Current learning rate: 0.00697 
2025-03-16 05:19:22.022277: train_loss -0.5481 
2025-03-16 05:19:22.028861: val_loss -0.5131 
2025-03-16 05:19:22.033445: Pseudo dice [np.float32(0.7366), np.float32(0.3667)] 
2025-03-16 05:19:22.038532: Epoch time: 40.9 s 
2025-03-16 05:19:22.042652: Yayy! New best EMA pseudo Dice: 0.5205000042915344 
2025-03-16 05:19:22.728787:  
2025-03-16 05:19:22.733795: Epoch 34 
2025-03-16 05:19:22.737305: Current learning rate: 0.00688 
2025-03-16 05:20:03.592765: train_loss -0.5405 
2025-03-16 05:20:03.599278: val_loss -0.5213 
2025-03-16 05:20:03.602818: Pseudo dice [np.float32(0.7337), np.float32(0.4976)] 
2025-03-16 05:20:03.605545: Epoch time: 40.86 s 
2025-03-16 05:20:03.609056: Yayy! New best EMA pseudo Dice: 0.5299999713897705 
2025-03-16 05:20:04.360789:  
2025-03-16 05:20:04.366833: Epoch 35 
2025-03-16 05:20:04.369891: Current learning rate: 0.00679 
2025-03-16 05:20:45.237721: train_loss -0.506 
2025-03-16 05:20:45.243351: val_loss -0.5325 
2025-03-16 05:20:45.246871: Pseudo dice [np.float32(0.7683), np.float32(0.4114)] 
2025-03-16 05:20:45.250950: Epoch time: 40.88 s 
2025-03-16 05:20:45.254000: Yayy! New best EMA pseudo Dice: 0.5360000133514404 
2025-03-16 05:20:45.948245:  
2025-03-16 05:20:45.953296: Epoch 36 
2025-03-16 05:20:45.957417: Current learning rate: 0.00669 
2025-03-16 05:21:26.802537: train_loss -0.5547 
2025-03-16 05:21:26.808592: val_loss -0.5686 
2025-03-16 05:21:26.811620: Pseudo dice [np.float32(0.7799), np.float32(0.4153)] 
2025-03-16 05:21:26.814127: Epoch time: 40.86 s 
2025-03-16 05:21:26.817632: Yayy! New best EMA pseudo Dice: 0.5422000288963318 
2025-03-16 05:21:27.717561:  
2025-03-16 05:21:27.723575: Epoch 37 
2025-03-16 05:21:27.727582: Current learning rate: 0.0066 
2025-03-16 05:22:08.587418: train_loss -0.5892 
2025-03-16 05:22:08.594476: val_loss -0.5127 
2025-03-16 05:22:08.598006: Pseudo dice [np.float32(0.7448), np.float32(0.3571)] 
2025-03-16 05:22:08.601022: Epoch time: 40.87 s 
2025-03-16 05:22:08.604598: Yayy! New best EMA pseudo Dice: 0.5430999994277954 
2025-03-16 05:22:09.296504:  
2025-03-16 05:22:09.301543: Epoch 38 
2025-03-16 05:22:09.304961: Current learning rate: 0.0065 
2025-03-16 05:22:50.172966: train_loss -0.5606 
2025-03-16 05:22:50.178976: val_loss -0.5501 
2025-03-16 05:22:50.182027: Pseudo dice [np.float32(0.762), np.float32(0.4715)] 
2025-03-16 05:22:50.185070: Epoch time: 40.88 s 
2025-03-16 05:22:50.188098: Yayy! New best EMA pseudo Dice: 0.5504000186920166 
2025-03-16 05:22:50.933140:  
2025-03-16 05:22:50.939652: Epoch 39 
2025-03-16 05:22:50.944161: Current learning rate: 0.00641 
2025-03-16 05:23:31.810104: train_loss -0.5624 
2025-03-16 05:23:31.816117: val_loss -0.5201 
2025-03-16 05:23:31.820127: Pseudo dice [np.float32(0.764), np.float32(0.403)] 
2025-03-16 05:23:31.823636: Epoch time: 40.88 s 
2025-03-16 05:23:31.827645: Yayy! New best EMA pseudo Dice: 0.5536999702453613 
2025-03-16 05:23:32.545971:  
2025-03-16 05:23:32.551522: Epoch 40 
2025-03-16 05:23:32.556583: Current learning rate: 0.00631 
2025-03-16 05:24:13.413002: train_loss -0.535 
2025-03-16 05:24:13.419641: val_loss -0.5447 
2025-03-16 05:24:13.422147: Pseudo dice [np.float32(0.7686), np.float32(0.4497)] 
2025-03-16 05:24:13.426156: Epoch time: 40.87 s 
2025-03-16 05:24:13.428663: Yayy! New best EMA pseudo Dice: 0.5593000054359436 
2025-03-16 05:24:14.177554:  
2025-03-16 05:24:14.182565: Epoch 41 
2025-03-16 05:24:14.186077: Current learning rate: 0.00622 
2025-03-16 05:24:55.047920: train_loss -0.5759 
2025-03-16 05:24:55.053934: val_loss -0.5552 
2025-03-16 05:24:55.057441: Pseudo dice [np.float32(0.7464), np.float32(0.4864)] 
2025-03-16 05:24:55.060450: Epoch time: 40.87 s 
2025-03-16 05:24:55.063962: Yayy! New best EMA pseudo Dice: 0.5649999976158142 
2025-03-16 05:24:55.738432:  
2025-03-16 05:24:55.743975: Epoch 42 
2025-03-16 05:24:55.746516: Current learning rate: 0.00612 
2025-03-16 05:25:36.613913: train_loss -0.5592 
2025-03-16 05:25:36.620443: val_loss -0.5053 
2025-03-16 05:25:36.623451: Pseudo dice [np.float32(0.764), np.float32(0.3162)] 
2025-03-16 05:25:36.626970: Epoch time: 40.88 s 
2025-03-16 05:25:37.148537:  
2025-03-16 05:25:37.153485: Epoch 43 
2025-03-16 05:25:37.157996: Current learning rate: 0.00603 
2025-03-16 05:26:18.029929: train_loss -0.5622 
2025-03-16 05:26:18.035924: val_loss -0.5261 
2025-03-16 05:26:18.039938: Pseudo dice [np.float32(0.7464), np.float32(0.4143)] 
2025-03-16 05:26:18.042445: Epoch time: 40.88 s 
2025-03-16 05:26:18.563931:  
2025-03-16 05:26:18.569445: Epoch 44 
2025-03-16 05:26:18.572958: Current learning rate: 0.00593 
2025-03-16 05:26:59.435547: train_loss -0.5991 
2025-03-16 05:26:59.441103: val_loss -0.5353 
2025-03-16 05:26:59.444696: Pseudo dice [np.float32(0.7552), np.float32(0.4494)] 
2025-03-16 05:26:59.447230: Epoch time: 40.87 s 
2025-03-16 05:26:59.451309: Yayy! New best EMA pseudo Dice: 0.5680999755859375 
2025-03-16 05:27:00.323502:  
2025-03-16 05:27:00.328512: Epoch 45 
2025-03-16 05:27:00.332526: Current learning rate: 0.00584 
2025-03-16 05:27:41.183268: train_loss -0.5703 
2025-03-16 05:27:41.189280: val_loss -0.5352 
2025-03-16 05:27:41.192786: Pseudo dice [np.float32(0.7746), np.float32(0.3986)] 
2025-03-16 05:27:41.195796: Epoch time: 40.86 s 
2025-03-16 05:27:41.199306: Yayy! New best EMA pseudo Dice: 0.5698999762535095 
2025-03-16 05:27:41.860788:  
2025-03-16 05:27:41.866338: Epoch 46 
2025-03-16 05:27:41.869914: Current learning rate: 0.00574 
2025-03-16 05:28:22.718541: train_loss -0.5678 
2025-03-16 05:28:22.724113: val_loss -0.5262 
2025-03-16 05:28:22.727193: Pseudo dice [np.float32(0.7387), np.float32(0.3891)] 
2025-03-16 05:28:22.730698: Epoch time: 40.86 s 
2025-03-16 05:28:23.249453:  
2025-03-16 05:28:23.255966: Epoch 47 
2025-03-16 05:28:23.259476: Current learning rate: 0.00565 
2025-03-16 05:29:04.112075: train_loss -0.5836 
2025-03-16 05:29:04.117641: val_loss -0.5305 
2025-03-16 05:29:04.121150: Pseudo dice [np.float32(0.7259), np.float32(0.4824)] 
2025-03-16 05:29:04.124159: Epoch time: 40.86 s 
2025-03-16 05:29:04.126663: Yayy! New best EMA pseudo Dice: 0.5727999806404114 
2025-03-16 05:29:04.803553:  
2025-03-16 05:29:04.809066: Epoch 48 
2025-03-16 05:29:04.812575: Current learning rate: 0.00555 
2025-03-16 05:29:45.687787: train_loss -0.5667 
2025-03-16 05:29:45.693300: val_loss -0.5825 
2025-03-16 05:29:45.696810: Pseudo dice [np.float32(0.7645), np.float32(0.5076)] 
2025-03-16 05:29:45.700324: Epoch time: 40.89 s 
2025-03-16 05:29:45.703336: Yayy! New best EMA pseudo Dice: 0.5791000127792358 
2025-03-16 05:29:46.408020:  
2025-03-16 05:29:46.413624: Epoch 49 
2025-03-16 05:29:46.417156: Current learning rate: 0.00546 
2025-03-16 05:30:27.260351: train_loss -0.5922 
2025-03-16 05:30:27.266423: val_loss -0.5411 
2025-03-16 05:30:27.270960: Pseudo dice [np.float32(0.7501), np.float32(0.4045)] 
2025-03-16 05:30:27.273986: Epoch time: 40.85 s 
2025-03-16 05:30:27.936543:  
2025-03-16 05:30:27.942560: Epoch 50 
2025-03-16 05:30:27.946569: Current learning rate: 0.00536 
2025-03-16 05:31:08.803239: train_loss -0.6017 
2025-03-16 05:31:08.809265: val_loss -0.5848 
2025-03-16 05:31:08.813275: Pseudo dice [np.float32(0.7816), np.float32(0.537)] 
2025-03-16 05:31:08.816784: Epoch time: 40.87 s 
2025-03-16 05:31:08.820792: Yayy! New best EMA pseudo Dice: 0.5870000123977661 
2025-03-16 05:31:09.525601:  
2025-03-16 05:31:09.532760: Epoch 51 
2025-03-16 05:31:09.536426: Current learning rate: 0.00526 
2025-03-16 05:31:50.390996: train_loss -0.5977 
2025-03-16 05:31:50.397514: val_loss -0.5457 
2025-03-16 05:31:50.401521: Pseudo dice [np.float32(0.7677), np.float32(0.4598)] 
2025-03-16 05:31:50.405029: Epoch time: 40.87 s 
2025-03-16 05:31:50.409037: Yayy! New best EMA pseudo Dice: 0.5896999835968018 
2025-03-16 05:31:51.094156:  
2025-03-16 05:31:51.099676: Epoch 52 
2025-03-16 05:31:51.104196: Current learning rate: 0.00517 
2025-03-16 05:32:31.959958: train_loss -0.5945 
2025-03-16 05:32:31.965547: val_loss -0.6021 
2025-03-16 05:32:31.970613: Pseudo dice [np.float32(0.7589), np.float32(0.6015)] 
2025-03-16 05:32:31.973151: Epoch time: 40.87 s 
2025-03-16 05:32:31.977875: Yayy! New best EMA pseudo Dice: 0.5986999869346619 
2025-03-16 05:32:32.874849:  
2025-03-16 05:32:32.881483: Epoch 53 
2025-03-16 05:32:32.886059: Current learning rate: 0.00507 
2025-03-16 05:33:13.738790: train_loss -0.6024 
2025-03-16 05:33:13.744802: val_loss -0.5672 
2025-03-16 05:33:13.748816: Pseudo dice [np.float32(0.7485), np.float32(0.4823)] 
2025-03-16 05:33:13.752823: Epoch time: 40.86 s 
2025-03-16 05:33:13.756334: Yayy! New best EMA pseudo Dice: 0.6003999710083008 
2025-03-16 05:33:14.452858:  
2025-03-16 05:33:14.458440: Epoch 54 
2025-03-16 05:33:14.462479: Current learning rate: 0.00497 
2025-03-16 05:33:55.310871: train_loss -0.6022 
2025-03-16 05:33:55.317581: val_loss -0.5385 
2025-03-16 05:33:55.321200: Pseudo dice [np.float32(0.7483), np.float32(0.402)] 
2025-03-16 05:33:55.325285: Epoch time: 40.86 s 
2025-03-16 05:33:55.838686:  
2025-03-16 05:33:55.843820: Epoch 55 
2025-03-16 05:33:55.847883: Current learning rate: 0.00487 
2025-03-16 05:34:36.694195: train_loss -0.6079 
2025-03-16 05:34:36.700765: val_loss -0.5764 
2025-03-16 05:34:36.704861: Pseudo dice [np.float32(0.7906), np.float32(0.5072)] 
2025-03-16 05:34:36.708413: Epoch time: 40.86 s 
2025-03-16 05:34:36.711468: Yayy! New best EMA pseudo Dice: 0.6029999852180481 
2025-03-16 05:34:37.431519:  
2025-03-16 05:34:37.438098: Epoch 56 
2025-03-16 05:34:37.443183: Current learning rate: 0.00478 
2025-03-16 05:35:18.309346: train_loss -0.6165 
2025-03-16 05:35:18.316913: val_loss -0.5334 
2025-03-16 05:35:18.320945: Pseudo dice [np.float32(0.7861), np.float32(0.4521)] 
2025-03-16 05:35:18.324476: Epoch time: 40.88 s 
2025-03-16 05:35:18.328515: Yayy! New best EMA pseudo Dice: 0.6046000123023987 
2025-03-16 05:35:19.048503:  
2025-03-16 05:35:19.055069: Epoch 57 
2025-03-16 05:35:19.059113: Current learning rate: 0.00468 
2025-03-16 05:35:59.903354: train_loss -0.627 
2025-03-16 05:35:59.909368: val_loss -0.5662 
2025-03-16 05:35:59.915884: Pseudo dice [np.float32(0.7876), np.float32(0.4692)] 
2025-03-16 05:35:59.920392: Epoch time: 40.85 s 
2025-03-16 05:35:59.924404: Yayy! New best EMA pseudo Dice: 0.6069999933242798 
2025-03-16 05:36:00.628272:  
2025-03-16 05:36:00.633785: Epoch 58 
2025-03-16 05:36:00.637318: Current learning rate: 0.00458 
2025-03-16 05:36:41.512464: train_loss -0.6191 
2025-03-16 05:36:41.518529: val_loss -0.5657 
2025-03-16 05:36:41.523541: Pseudo dice [np.float32(0.7726), np.float32(0.4397)] 
2025-03-16 05:36:41.527560: Epoch time: 40.89 s 
2025-03-16 05:36:42.070374:  
2025-03-16 05:36:42.076933: Epoch 59 
2025-03-16 05:36:42.079473: Current learning rate: 0.00448 
2025-03-16 05:37:22.941642: train_loss -0.6234 
2025-03-16 05:37:22.947810: val_loss -0.5693 
2025-03-16 05:37:22.952351: Pseudo dice [np.float32(0.796), np.float32(0.4909)] 
2025-03-16 05:37:22.955390: Epoch time: 40.87 s 
2025-03-16 05:37:22.958902: Yayy! New best EMA pseudo Dice: 0.6104999780654907 
2025-03-16 05:37:23.664856:  
2025-03-16 05:37:23.670899: Epoch 60 
2025-03-16 05:37:23.674423: Current learning rate: 0.00438 
2025-03-16 05:38:04.552824: train_loss -0.6408 
2025-03-16 05:38:04.559388: val_loss -0.5906 
2025-03-16 05:38:04.564369: Pseudo dice [np.float32(0.7753), np.float32(0.5566)] 
2025-03-16 05:38:04.567565: Epoch time: 40.89 s 
2025-03-16 05:38:04.571579: Yayy! New best EMA pseudo Dice: 0.616100013256073 
2025-03-16 05:38:05.472551:  
2025-03-16 05:38:05.478573: Epoch 61 
2025-03-16 05:38:05.482088: Current learning rate: 0.00429 
2025-03-16 05:38:46.348042: train_loss -0.6425 
2025-03-16 05:38:46.353607: val_loss -0.5819 
2025-03-16 05:38:46.357118: Pseudo dice [np.float32(0.7743), np.float32(0.4762)] 
2025-03-16 05:38:46.359625: Epoch time: 40.88 s 
2025-03-16 05:38:46.363641: Yayy! New best EMA pseudo Dice: 0.6169999837875366 
2025-03-16 05:38:47.045247:  
2025-03-16 05:38:47.051334: Epoch 62 
2025-03-16 05:38:47.054406: Current learning rate: 0.00419 
2025-03-16 05:39:27.891399: train_loss -0.6472 
2025-03-16 05:39:27.897465: val_loss -0.5658 
2025-03-16 05:39:27.901533: Pseudo dice [np.float32(0.7933), np.float32(0.433)] 
2025-03-16 05:39:27.904605: Epoch time: 40.85 s 
2025-03-16 05:39:28.430837:  
2025-03-16 05:39:28.435850: Epoch 63 
2025-03-16 05:39:28.439419: Current learning rate: 0.00409 
2025-03-16 05:40:09.295848: train_loss -0.652 
2025-03-16 05:40:09.302361: val_loss -0.5536 
2025-03-16 05:40:09.305872: Pseudo dice [np.float32(0.773), np.float32(0.4474)] 
2025-03-16 05:40:09.309381: Epoch time: 40.87 s 
2025-03-16 05:40:09.841645:  
2025-03-16 05:40:09.847200: Epoch 64 
2025-03-16 05:40:09.850252: Current learning rate: 0.00399 
2025-03-16 05:40:50.714046: train_loss -0.6389 
2025-03-16 05:40:50.720598: val_loss -0.6286 
2025-03-16 05:40:50.724112: Pseudo dice [np.float32(0.7949), np.float32(0.5503)] 
2025-03-16 05:40:50.727616: Epoch time: 40.87 s 
2025-03-16 05:40:50.730624: Yayy! New best EMA pseudo Dice: 0.6215999722480774 
2025-03-16 05:40:51.483077:  
2025-03-16 05:40:51.488640: Epoch 65 
2025-03-16 05:40:51.491183: Current learning rate: 0.00389 
2025-03-16 05:41:32.346425: train_loss -0.6337 
2025-03-16 05:41:32.353437: val_loss -0.4876 
2025-03-16 05:41:32.356447: Pseudo dice [np.float32(0.774), np.float32(0.2937)] 
2025-03-16 05:41:32.359956: Epoch time: 40.86 s 
2025-03-16 05:41:32.905019:  
2025-03-16 05:41:32.910557: Epoch 66 
2025-03-16 05:41:32.913628: Current learning rate: 0.00379 
2025-03-16 05:42:13.778386: train_loss -0.6277 
2025-03-16 05:42:13.784505: val_loss -0.5262 
2025-03-16 05:42:13.788049: Pseudo dice [np.float32(0.7683), np.float32(0.3443)] 
2025-03-16 05:42:13.791128: Epoch time: 40.87 s 
2025-03-16 05:42:14.365129:  
2025-03-16 05:42:14.372222: Epoch 67 
2025-03-16 05:42:14.377337: Current learning rate: 0.00369 
2025-03-16 05:42:55.232634: train_loss -0.6183 
2025-03-16 05:42:55.237179: val_loss -0.5383 
2025-03-16 05:42:55.241712: Pseudo dice [np.float32(0.7652), np.float32(0.4362)] 
2025-03-16 05:42:55.244217: Epoch time: 40.87 s 
2025-03-16 05:42:55.781901:  
2025-03-16 05:42:55.787914: Epoch 68 
2025-03-16 05:42:55.791427: Current learning rate: 0.00359 
2025-03-16 05:43:36.660767: train_loss -0.6222 
2025-03-16 05:43:36.666780: val_loss -0.5849 
2025-03-16 05:43:36.670789: Pseudo dice [np.float32(0.7959), np.float32(0.5353)] 
2025-03-16 05:43:36.674296: Epoch time: 40.88 s 
2025-03-16 05:43:37.360439:  
2025-03-16 05:43:37.365997: Epoch 69 
2025-03-16 05:43:37.368067: Current learning rate: 0.00349 
2025-03-16 05:44:18.222026: train_loss -0.6432 
2025-03-16 05:44:18.227079: val_loss -0.54 
2025-03-16 05:44:18.230639: Pseudo dice [np.float32(0.7842), np.float32(0.3806)] 
2025-03-16 05:44:18.233721: Epoch time: 40.86 s 
2025-03-16 05:44:18.773049:  
2025-03-16 05:44:18.779072: Epoch 70 
2025-03-16 05:44:18.782583: Current learning rate: 0.00338 
2025-03-16 05:44:59.620278: train_loss -0.6579 
2025-03-16 05:44:59.625321: val_loss -0.5698 
2025-03-16 05:44:59.629385: Pseudo dice [np.float32(0.7762), np.float32(0.3648)] 
2025-03-16 05:44:59.631900: Epoch time: 40.85 s 
2025-03-16 05:45:00.175311:  
2025-03-16 05:45:00.180428: Epoch 71 
2025-03-16 05:45:00.184475: Current learning rate: 0.00328 
2025-03-16 05:45:41.028658: train_loss -0.6539 
2025-03-16 05:45:41.034214: val_loss -0.5515 
2025-03-16 05:45:41.037233: Pseudo dice [np.float32(0.762), np.float32(0.4779)] 
2025-03-16 05:45:41.040743: Epoch time: 40.85 s 
2025-03-16 05:45:41.584005:  
2025-03-16 05:45:41.590195: Epoch 72 
2025-03-16 05:45:41.593762: Current learning rate: 0.00318 
2025-03-16 05:46:22.436421: train_loss -0.6538 
2025-03-16 05:46:22.443944: val_loss -0.5595 
2025-03-16 05:46:22.446450: Pseudo dice [np.float32(0.7613), np.float32(0.4646)] 
2025-03-16 05:46:22.450561: Epoch time: 40.85 s 
2025-03-16 05:46:22.991180:  
2025-03-16 05:46:22.996798: Epoch 73 
2025-03-16 05:46:23.001000: Current learning rate: 0.00308 
2025-03-16 05:47:03.867653: train_loss -0.6761 
2025-03-16 05:47:03.874167: val_loss -0.5794 
2025-03-16 05:47:03.879182: Pseudo dice [np.float32(0.7964), np.float32(0.4383)] 
2025-03-16 05:47:03.882693: Epoch time: 40.88 s 
2025-03-16 05:47:04.428432:  
2025-03-16 05:47:04.433944: Epoch 74 
2025-03-16 05:47:04.437454: Current learning rate: 0.00297 
2025-03-16 05:47:45.291400: train_loss -0.6623 
2025-03-16 05:47:45.297477: val_loss -0.5188 
2025-03-16 05:47:45.301057: Pseudo dice [np.float32(0.769), np.float32(0.3971)] 
2025-03-16 05:47:45.304588: Epoch time: 40.86 s 
2025-03-16 05:47:45.861930:  
2025-03-16 05:47:45.867522: Epoch 75 
2025-03-16 05:47:45.871087: Current learning rate: 0.00287 
2025-03-16 05:48:26.722530: train_loss -0.665 
2025-03-16 05:48:26.729099: val_loss -0.5439 
2025-03-16 05:48:26.732726: Pseudo dice [np.float32(0.7642), np.float32(0.3947)] 
2025-03-16 05:48:26.735769: Epoch time: 40.86 s 
2025-03-16 05:48:27.281649:  
2025-03-16 05:48:27.286705: Epoch 76 
2025-03-16 05:48:27.289643: Current learning rate: 0.00277 
2025-03-16 05:49:08.138351: train_loss -0.6787 
2025-03-16 05:49:08.144017: val_loss -0.5667 
2025-03-16 05:49:08.149103: Pseudo dice [np.float32(0.7843), np.float32(0.4932)] 
2025-03-16 05:49:08.152610: Epoch time: 40.86 s 
2025-03-16 05:49:08.838809:  
2025-03-16 05:49:08.844337: Epoch 77 
2025-03-16 05:49:08.847914: Current learning rate: 0.00266 
2025-03-16 05:49:49.690989: train_loss -0.6709 
2025-03-16 05:49:49.695998: val_loss -0.5294 
2025-03-16 05:49:49.700010: Pseudo dice [np.float32(0.766), np.float32(0.415)] 
2025-03-16 05:49:49.703518: Epoch time: 40.85 s 
2025-03-16 05:49:50.282876:  
2025-03-16 05:49:50.288887: Epoch 78 
2025-03-16 05:49:50.292900: Current learning rate: 0.00256 
2025-03-16 05:50:31.144103: train_loss -0.6883 
2025-03-16 05:50:31.149664: val_loss -0.5642 
2025-03-16 05:50:31.153722: Pseudo dice [np.float32(0.7639), np.float32(0.4504)] 
2025-03-16 05:50:31.156252: Epoch time: 40.86 s 
2025-03-16 05:50:31.699977:  
2025-03-16 05:50:31.705015: Epoch 79 
2025-03-16 05:50:31.709081: Current learning rate: 0.00245 
2025-03-16 05:51:12.543621: train_loss -0.6875 
2025-03-16 05:51:12.549134: val_loss -0.5948 
2025-03-16 05:51:12.552647: Pseudo dice [np.float32(0.7828), np.float32(0.4895)] 
2025-03-16 05:51:12.556154: Epoch time: 40.84 s 
2025-03-16 05:51:13.111866:  
2025-03-16 05:51:13.116700: Epoch 80 
2025-03-16 05:51:13.120211: Current learning rate: 0.00235 
2025-03-16 05:51:53.947858: train_loss -0.689 
2025-03-16 05:51:53.953918: val_loss -0.5832 
2025-03-16 05:51:53.958111: Pseudo dice [np.float32(0.8073), np.float32(0.4849)] 
2025-03-16 05:51:53.961618: Epoch time: 40.84 s 
2025-03-16 05:51:54.569424:  
2025-03-16 05:51:54.575982: Epoch 81 
2025-03-16 05:51:54.578516: Current learning rate: 0.00224 
2025-03-16 05:52:35.455192: train_loss -0.6894 
2025-03-16 05:52:35.461629: val_loss -0.5436 
2025-03-16 05:52:35.465144: Pseudo dice [np.float32(0.7636), np.float32(0.4209)] 
2025-03-16 05:52:35.467699: Epoch time: 40.89 s 
2025-03-16 05:52:36.031782:  
2025-03-16 05:52:36.037376: Epoch 82 
2025-03-16 05:52:36.040916: Current learning rate: 0.00214 
2025-03-16 05:53:16.907503: train_loss -0.6736 
2025-03-16 05:53:16.914068: val_loss -0.5752 
2025-03-16 05:53:16.917575: Pseudo dice [np.float32(0.7861), np.float32(0.4866)] 
2025-03-16 05:53:16.920079: Epoch time: 40.88 s 
2025-03-16 05:53:17.446705:  
2025-03-16 05:53:17.452257: Epoch 83 
2025-03-16 05:53:17.456301: Current learning rate: 0.00203 
2025-03-16 05:53:58.312960: train_loss -0.6712 
2025-03-16 05:53:58.319589: val_loss -0.5608 
2025-03-16 05:53:58.323162: Pseudo dice [np.float32(0.7889), np.float32(0.4287)] 
2025-03-16 05:53:58.326230: Epoch time: 40.87 s 
2025-03-16 05:53:59.005613:  
2025-03-16 05:53:59.011176: Epoch 84 
2025-03-16 05:53:59.014213: Current learning rate: 0.00192 
2025-03-16 05:54:39.859046: train_loss -0.69 
2025-03-16 05:54:39.865562: val_loss -0.5353 
2025-03-16 05:54:39.869105: Pseudo dice [np.float32(0.764), np.float32(0.3412)] 
2025-03-16 05:54:39.871611: Epoch time: 40.85 s 
2025-03-16 05:54:40.397204:  
2025-03-16 05:54:40.402719: Epoch 85 
2025-03-16 05:54:40.406229: Current learning rate: 0.00181 
2025-03-16 05:55:21.248120: train_loss -0.6951 
2025-03-16 05:55:21.255810: val_loss -0.5298 
2025-03-16 05:55:21.259848: Pseudo dice [np.float32(0.7882), np.float32(0.39)] 
2025-03-16 05:55:21.262878: Epoch time: 40.85 s 
2025-03-16 05:55:21.774725:  
2025-03-16 05:55:21.779834: Epoch 86 
2025-03-16 05:55:21.783346: Current learning rate: 0.0017 
2025-03-16 05:56:02.641752: train_loss -0.6851 
2025-03-16 05:56:02.646817: val_loss -0.5826 
2025-03-16 05:56:02.651429: Pseudo dice [np.float32(0.7811), np.float32(0.4439)] 
2025-03-16 05:56:02.654987: Epoch time: 40.87 s 
2025-03-16 05:56:03.171749:  
2025-03-16 05:56:03.177313: Epoch 87 
2025-03-16 05:56:03.180359: Current learning rate: 0.00159 
2025-03-16 05:56:44.031173: train_loss -0.7086 
2025-03-16 05:56:44.036207: val_loss -0.5619 
2025-03-16 05:56:44.040218: Pseudo dice [np.float32(0.7806), np.float32(0.4514)] 
2025-03-16 05:56:44.042724: Epoch time: 40.86 s 
2025-03-16 05:56:44.596380:  
2025-03-16 05:56:44.601933: Epoch 88 
2025-03-16 05:56:44.604471: Current learning rate: 0.00148 
2025-03-16 05:57:25.469371: train_loss -0.7058 
2025-03-16 05:57:25.475908: val_loss -0.559 
2025-03-16 05:57:25.480549: Pseudo dice [np.float32(0.7917), np.float32(0.4822)] 
2025-03-16 05:57:25.483601: Epoch time: 40.87 s 
2025-03-16 05:57:26.003538:  
2025-03-16 05:57:26.008369: Epoch 89 
2025-03-16 05:57:26.011882: Current learning rate: 0.00137 
2025-03-16 05:58:06.870917: train_loss -0.7014 
2025-03-16 05:58:06.876806: val_loss -0.5635 
2025-03-16 05:58:06.878985: Pseudo dice [np.float32(0.801), np.float32(0.5023)] 
2025-03-16 05:58:06.884086: Epoch time: 40.87 s 
2025-03-16 05:58:07.404101:  
2025-03-16 05:58:07.409653: Epoch 90 
2025-03-16 05:58:07.414201: Current learning rate: 0.00126 
2025-03-16 05:58:48.281709: train_loss -0.7072 
2025-03-16 05:58:48.287762: val_loss -0.5946 
2025-03-16 05:58:48.291384: Pseudo dice [np.float32(0.7845), np.float32(0.4712)] 
2025-03-16 05:58:48.293928: Epoch time: 40.88 s 
2025-03-16 05:58:48.824196:  
2025-03-16 05:58:48.829711: Epoch 91 
2025-03-16 05:58:48.833221: Current learning rate: 0.00115 
2025-03-16 05:59:29.695440: train_loss -0.7165 
2025-03-16 05:59:29.701015: val_loss -0.5642 
2025-03-16 05:59:29.706127: Pseudo dice [np.float32(0.772), np.float32(0.48)] 
2025-03-16 05:59:29.709161: Epoch time: 40.87 s 
2025-03-16 05:59:30.224336:  
2025-03-16 05:59:30.230399: Epoch 92 
2025-03-16 05:59:30.233539: Current learning rate: 0.00103 
2025-03-16 06:00:11.087233: train_loss -0.7056 
2025-03-16 06:00:11.092802: val_loss -0.5611 
2025-03-16 06:00:11.097370: Pseudo dice [np.float32(0.8147), np.float32(0.4073)] 
2025-03-16 06:00:11.100882: Epoch time: 40.86 s 
2025-03-16 06:00:11.983237:  
2025-03-16 06:00:11.989297: Epoch 93 
2025-03-16 06:00:11.992349: Current learning rate: 0.00091 
2025-03-16 06:00:52.830975: train_loss -0.7158 
2025-03-16 06:00:52.836988: val_loss -0.5707 
2025-03-16 06:00:52.841002: Pseudo dice [np.float32(0.7695), np.float32(0.495)] 
2025-03-16 06:00:52.843510: Epoch time: 40.85 s 
2025-03-16 06:00:53.349797:  
2025-03-16 06:00:53.354822: Epoch 94 
2025-03-16 06:00:53.358645: Current learning rate: 0.00079 
2025-03-16 06:01:34.191317: train_loss -0.718 
2025-03-16 06:01:34.196829: val_loss -0.5767 
2025-03-16 06:01:34.200347: Pseudo dice [np.float32(0.785), np.float32(0.438)] 
2025-03-16 06:01:34.204359: Epoch time: 40.84 s 
2025-03-16 06:01:34.713008:  
2025-03-16 06:01:34.718521: Epoch 95 
2025-03-16 06:01:34.722029: Current learning rate: 0.00067 
2025-03-16 06:02:15.579559: train_loss -0.7063 
2025-03-16 06:02:15.586166: val_loss -0.5729 
2025-03-16 06:02:15.589740: Pseudo dice [np.float32(0.7994), np.float32(0.4205)] 
2025-03-16 06:02:15.593248: Epoch time: 40.87 s 
2025-03-16 06:02:16.099464:  
2025-03-16 06:02:16.105012: Epoch 96 
2025-03-16 06:02:16.109051: Current learning rate: 0.00055 
2025-03-16 06:02:56.947465: train_loss -0.7006 
2025-03-16 06:02:56.953479: val_loss -0.6206 
2025-03-16 06:02:56.957488: Pseudo dice [np.float32(0.8054), np.float32(0.5342)] 
2025-03-16 06:02:56.960997: Epoch time: 40.85 s 
2025-03-16 06:02:57.487083:  
2025-03-16 06:02:57.492663: Epoch 97 
2025-03-16 06:02:57.496229: Current learning rate: 0.00043 
2025-03-16 06:03:38.334814: train_loss -0.7057 
2025-03-16 06:03:38.340537: val_loss -0.5738 
2025-03-16 06:03:38.345152: Pseudo dice [np.float32(0.793), np.float32(0.5232)] 
2025-03-16 06:03:38.348184: Epoch time: 40.85 s 
2025-03-16 06:03:38.351217: Yayy! New best EMA pseudo Dice: 0.6251999735832214 
2025-03-16 06:03:39.067001:  
2025-03-16 06:03:39.072514: Epoch 98 
2025-03-16 06:03:39.076024: Current learning rate: 0.0003 
2025-03-16 06:04:19.928360: train_loss -0.7292 
2025-03-16 06:04:19.933977: val_loss -0.6107 
2025-03-16 06:04:19.939070: Pseudo dice [np.float32(0.8175), np.float32(0.5056)] 
2025-03-16 06:04:19.942604: Epoch time: 40.86 s 
2025-03-16 06:04:19.945658: Yayy! New best EMA pseudo Dice: 0.6287999749183655 
2025-03-16 06:04:20.658255:  
2025-03-16 06:04:20.663986: Epoch 99 
2025-03-16 06:04:20.667494: Current learning rate: 0.00016 
2025-03-16 06:05:01.539263: train_loss -0.7324 
2025-03-16 06:05:01.545275: val_loss -0.5518 
2025-03-16 06:05:01.549290: Pseudo dice [np.float32(0.7865), np.float32(0.481)] 
2025-03-16 06:05:01.552800: Epoch time: 40.88 s 
2025-03-16 06:05:01.555308: Yayy! New best EMA pseudo Dice: 0.6292999982833862 
2025-03-16 06:05:02.480899: Training done. 
2025-03-16 06:05:02.510905: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-03-16 06:05:02.518081: The split file contains 5 splits. 
2025-03-16 06:05:02.522079: Desired fold for training: 0 
2025-03-16 06:05:02.527079: This split has 224 training and 57 validation cases. 
2025-03-16 06:05:02.534077: predicting pancreas_021 
2025-03-16 06:05:02.541077: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-03-16 06:05:14.955323: predicting pancreas_024 
2025-03-16 06:05:14.976324: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-03-16 06:05:29.526172: predicting pancreas_035 
2025-03-16 06:05:29.546682: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-03-16 06:05:34.497930: predicting pancreas_040 
2025-03-16 06:05:34.509930: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-03-16 06:05:46.147595: predicting pancreas_042 
2025-03-16 06:05:46.167596: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-03-16 06:06:00.740147: predicting pancreas_056 
2025-03-16 06:06:00.757653: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-03-16 06:06:12.412606: predicting pancreas_067 
2025-03-16 06:06:12.429605: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-03-16 06:06:26.998162: predicting pancreas_075 
2025-03-16 06:06:27.021162: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-03-16 06:06:32.885979: predicting pancreas_086 
2025-03-16 06:06:32.900979: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-03-16 06:06:42.013403: predicting pancreas_089 
2025-03-16 06:06:42.027402: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-03-16 06:06:53.676175: predicting pancreas_092 
2025-03-16 06:06:53.693681: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-03-16 06:07:19.838035: predicting pancreas_094 
2025-03-16 06:07:19.868035: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-03-16 06:07:31.549297: predicting pancreas_095 
2025-03-16 06:07:31.568300: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-03-16 06:07:43.248335: predicting pancreas_098 
2025-03-16 06:07:43.266335: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-03-16 06:08:15.058542: predicting pancreas_109 
2025-03-16 06:08:15.088542: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-03-16 06:08:26.797982: predicting pancreas_110 
2025-03-16 06:08:26.820981: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-03-16 06:08:45.074279: predicting pancreas_114 
2025-03-16 06:08:45.098279: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-03-16 06:08:56.817410: predicting pancreas_119 
2025-03-16 06:08:56.836410: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-03-16 06:09:15.024455: predicting pancreas_138 
2025-03-16 06:09:15.044455: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-03-16 06:09:33.286489: predicting pancreas_145 
2025-03-16 06:09:33.310996: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-03-16 06:09:51.536987: predicting pancreas_148 
2025-03-16 06:09:51.559987: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-03-16 06:10:03.248598: predicting pancreas_169 
2025-03-16 06:10:03.266598: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-03-16 06:10:14.917569: predicting pancreas_170 
2025-03-16 06:10:14.934568: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-03-16 06:10:29.492336: predicting pancreas_172 
2025-03-16 06:10:29.513340: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-03-16 06:10:41.209673: predicting pancreas_175 
2025-03-16 06:10:41.226677: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-03-16 06:10:52.885790: predicting pancreas_180 
2025-03-16 06:10:52.903791: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-03-16 06:11:04.575919: predicting pancreas_191 
2025-03-16 06:11:04.592920: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-03-16 06:11:10.451011: predicting pancreas_193 
2025-03-16 06:11:10.465518: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-03-16 06:11:25.029077: predicting pancreas_212 
2025-03-16 06:11:25.051081: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-03-16 06:11:36.736781: predicting pancreas_215 
2025-03-16 06:11:36.759784: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-03-16 06:11:48.419814: predicting pancreas_222 
2025-03-16 06:11:48.434818: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-03-16 06:11:53.398938: predicting pancreas_235 
2025-03-16 06:11:53.412939: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-03-16 06:12:05.064900: predicting pancreas_241 
2025-03-16 06:12:05.081901: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-03-16 06:12:16.801696: predicting pancreas_242 
2025-03-16 06:12:16.822697: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-03-16 06:12:31.414567: predicting pancreas_244 
2025-03-16 06:12:31.437567: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-03-16 06:12:54.165217: predicting pancreas_246 
2025-03-16 06:12:54.189217: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-03-16 06:13:16.962429: predicting pancreas_247 
2025-03-16 06:13:16.985431: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-03-16 06:13:23.608492: predicting pancreas_264 
2025-03-16 06:13:23.626493: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-03-16 06:13:38.222985: predicting pancreas_265 
2025-03-16 06:13:38.243988: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-03-16 06:13:49.919636: predicting pancreas_266 
2025-03-16 06:13:49.937637: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-03-16 06:14:08.122076: predicting pancreas_267 
2025-03-16 06:14:08.144076: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-03-16 06:14:14.762258: predicting pancreas_275 
2025-03-16 06:14:14.779259: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-03-16 06:14:29.321584: predicting pancreas_279 
2025-03-16 06:14:29.341584: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-03-16 06:14:34.337269: predicting pancreas_287 
2025-03-16 06:14:34.352270: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-03-16 06:14:46.018574: predicting pancreas_301 
2025-03-16 06:14:46.036574: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-03-16 06:14:57.759319: predicting pancreas_323 
2025-03-16 06:14:57.777319: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-03-16 06:15:16.000063: predicting pancreas_336 
2025-03-16 06:15:16.023570: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-03-16 06:15:27.722063: predicting pancreas_344 
2025-03-16 06:15:27.741569: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-03-16 06:15:42.346411: predicting pancreas_351 
2025-03-16 06:15:42.366413: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-03-16 06:15:48.984768: predicting pancreas_354 
2025-03-16 06:15:48.999768: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-03-16 06:16:12.258080: predicting pancreas_372 
2025-03-16 06:16:12.285586: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-03-16 06:16:30.554772: predicting pancreas_377 
2025-03-16 06:16:30.580279: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-03-16 06:16:45.209608: predicting pancreas_387 
2025-03-16 06:16:45.232609: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-03-16 06:16:56.934771: predicting pancreas_391 
2025-03-16 06:16:56.953771: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-03-16 06:17:15.175128: predicting pancreas_392 
2025-03-16 06:17:15.197130: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-03-16 06:17:23.447757: predicting pancreas_410 
2025-03-16 06:17:23.466757: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-03-16 06:17:31.705407: predicting pancreas_412 
2025-03-16 06:17:31.722420: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-03-16 06:18:30.641060: Validation complete 
2025-03-16 06:18:30.647092: Mean Validation Dice:  0.32555506370352544 
