2024-12-16 13:14:37.904150: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.25 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2024-12-16 13:14:37.908154: self.oversample_foreground_percent 0.25 
2024-12-16 13:14:38.555757: do_dummy_2d_data_aug: True 
2024-12-16 13:14:38.580314: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-16 13:14:38.583314: The split file contains 5 splits. 
2024-12-16 13:14:38.585315: Desired fold for training: 0 
2024-12-16 13:14:38.588314: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [32, 192, 160], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2024-12-16 13:14:45.394987: unpacking dataset... 
2024-12-16 13:14:45.637864: unpacking done... 
2024-12-16 13:14:47.842297:  
2024-12-16 13:14:47.847314: Epoch 50 
2024-12-16 13:14:47.850824: Current learning rate: 0.00536 
2024-12-16 13:15:32.104311: train_loss -0.4551 
2024-12-16 13:15:32.111370: val_loss -0.4232 
2024-12-16 13:15:32.114884: Pseudo dice [np.float32(0.674), np.float32(0.2963)] 
2024-12-16 13:15:32.118069: Epoch time: 44.26 s 
2024-12-16 13:15:32.680098:  
2024-12-16 13:15:32.684610: Epoch 51 
2024-12-16 13:15:32.687638: Current learning rate: 0.00526 
2024-12-16 13:16:12.848195: train_loss -0.466 
2024-12-16 13:16:12.853268: val_loss -0.5258 
2024-12-16 13:16:12.856781: Pseudo dice [np.float32(0.6867), np.float32(0.51)] 
2024-12-16 13:16:12.860791: Epoch time: 40.17 s 
2024-12-16 13:16:12.863298: Yayy! New best EMA pseudo Dice: 0.5202999711036682 
2024-12-16 13:16:13.537431:  
2024-12-16 13:16:13.541002: Epoch 52 
2024-12-16 13:16:13.545048: Current learning rate: 0.00517 
2024-12-16 13:16:52.614638: train_loss -0.4482 
2024-12-16 13:16:52.621160: val_loss -0.4488 
2024-12-16 13:16:52.624669: Pseudo dice [np.float32(0.6419), np.float32(0.3824)] 
2024-12-16 13:16:52.627679: Epoch time: 39.08 s 
2024-12-16 13:16:53.164991:  
2024-12-16 13:16:53.170538: Epoch 53 
2024-12-16 13:16:53.173572: Current learning rate: 0.00507 
2024-12-16 13:17:32.888603: train_loss -0.4424 
2024-12-16 13:17:32.895121: val_loss -0.4703 
2024-12-16 13:17:32.898673: Pseudo dice [np.float32(0.6827), np.float32(0.3479)] 
2024-12-16 13:17:32.901183: Epoch time: 39.72 s 
2024-12-16 13:17:33.438205:  
2024-12-16 13:17:33.443218: Epoch 54 
2024-12-16 13:17:33.446230: Current learning rate: 0.00497 
2024-12-16 13:18:12.762618: train_loss -0.4742 
2024-12-16 13:18:12.768723: val_loss -0.5116 
2024-12-16 13:18:12.771279: Pseudo dice [np.float32(0.7037), np.float32(0.5336)] 
2024-12-16 13:18:12.775351: Epoch time: 39.33 s 
2024-12-16 13:18:12.778359: Yayy! New best EMA pseudo Dice: 0.5291000008583069 
2024-12-16 13:18:13.656826:  
2024-12-16 13:18:13.661337: Epoch 55 
2024-12-16 13:18:13.664347: Current learning rate: 0.00487 
2024-12-16 13:18:52.344035: train_loss -0.4812 
2024-12-16 13:18:52.350055: val_loss -0.4783 
2024-12-16 13:18:52.354077: Pseudo dice [np.float32(0.6871), np.float32(0.4413)] 
2024-12-16 13:18:52.357579: Epoch time: 38.69 s 
2024-12-16 13:18:52.360087: Yayy! New best EMA pseudo Dice: 0.5325999855995178 
2024-12-16 13:18:53.082479:  
2024-12-16 13:18:53.087018: Epoch 56 
2024-12-16 13:18:53.090524: Current learning rate: 0.00478 
2024-12-16 13:19:31.782251: train_loss -0.5063 
2024-12-16 13:19:31.788262: val_loss -0.452 
2024-12-16 13:19:31.792269: Pseudo dice [np.float32(0.6682), np.float32(0.334)] 
2024-12-16 13:19:31.794775: Epoch time: 38.7 s 
2024-12-16 13:19:32.334821:  
2024-12-16 13:19:32.338859: Epoch 57 
2024-12-16 13:19:32.342910: Current learning rate: 0.00468 
2024-12-16 13:20:11.048991: train_loss -0.4792 
2024-12-16 13:20:11.054049: val_loss -0.5155 
2024-12-16 13:20:11.058557: Pseudo dice [np.float32(0.7018), np.float32(0.455)] 
2024-12-16 13:20:11.061572: Epoch time: 38.72 s 
2024-12-16 13:20:11.064077: Yayy! New best EMA pseudo Dice: 0.5343000292778015 
2024-12-16 13:20:11.744786:  
2024-12-16 13:20:11.749836: Epoch 58 
2024-12-16 13:20:11.752905: Current learning rate: 0.00458 
2024-12-16 13:20:50.412861: train_loss -0.4982 
2024-12-16 13:20:50.419429: val_loss -0.4735 
2024-12-16 13:20:50.422458: Pseudo dice [np.float32(0.6809), np.float32(0.4218)] 
2024-12-16 13:20:50.425510: Epoch time: 38.67 s 
2024-12-16 13:20:50.428040: Yayy! New best EMA pseudo Dice: 0.5360000133514404 
2024-12-16 13:20:51.137318:  
2024-12-16 13:20:51.142346: Epoch 59 
2024-12-16 13:20:51.144862: Current learning rate: 0.00448 
2024-12-16 13:21:29.826866: train_loss -0.4871 
2024-12-16 13:21:29.834388: val_loss -0.4219 
2024-12-16 13:21:29.837898: Pseudo dice [np.float32(0.7262), np.float32(0.1972)] 
2024-12-16 13:21:29.841909: Epoch time: 38.69 s 
2024-12-16 13:21:30.389138:  
2024-12-16 13:21:30.394175: Epoch 60 
2024-12-16 13:21:30.396768: Current learning rate: 0.00438 
2024-12-16 13:22:09.068073: train_loss -0.5197 
2024-12-16 13:22:09.073087: val_loss -0.5271 
2024-12-16 13:22:09.077600: Pseudo dice [np.float32(0.7177), np.float32(0.4426)] 
2024-12-16 13:22:09.081123: Epoch time: 38.68 s 
2024-12-16 13:22:09.646248:  
2024-12-16 13:22:09.652347: Epoch 61 
2024-12-16 13:22:09.655394: Current learning rate: 0.00429 
2024-12-16 13:22:49.125578: train_loss -0.49 
2024-12-16 13:22:49.130600: val_loss -0.4457 
2024-12-16 13:22:49.134118: Pseudo dice [np.float32(0.6519), np.float32(0.3366)] 
2024-12-16 13:22:49.137635: Epoch time: 39.48 s 
2024-12-16 13:22:49.879430:  
2024-12-16 13:22:49.883481: Epoch 62 
2024-12-16 13:22:49.888086: Current learning rate: 0.00419 
2024-12-16 13:23:28.672251: train_loss -0.4846 
2024-12-16 13:23:28.677263: val_loss -0.5073 
2024-12-16 13:23:28.680774: Pseudo dice [np.float32(0.7271), np.float32(0.3809)] 
2024-12-16 13:23:28.684281: Epoch time: 38.79 s 
2024-12-16 13:23:29.265493:  
2024-12-16 13:23:29.269554: Epoch 63 
2024-12-16 13:23:29.273628: Current learning rate: 0.00409 
2024-12-16 13:24:08.631891: train_loss -0.5182 
2024-12-16 13:24:08.637969: val_loss -0.538 
2024-12-16 13:24:08.641039: Pseudo dice [np.float32(0.7129), np.float32(0.4809)] 
2024-12-16 13:24:08.644074: Epoch time: 39.37 s 
2024-12-16 13:24:08.646620: Yayy! New best EMA pseudo Dice: 0.5386999845504761 
2024-12-16 13:24:09.331711:  
2024-12-16 13:24:09.337249: Epoch 64 
2024-12-16 13:24:09.341308: Current learning rate: 0.00399 
2024-12-16 13:24:48.023210: train_loss -0.5054 
2024-12-16 13:24:48.029731: val_loss -0.4738 
2024-12-16 13:24:48.034747: Pseudo dice [np.float32(0.7036), np.float32(0.3392)] 
2024-12-16 13:24:48.037781: Epoch time: 38.69 s 
2024-12-16 13:24:48.584382:  
2024-12-16 13:24:48.589389: Epoch 65 
2024-12-16 13:24:48.591897: Current learning rate: 0.00389 
2024-12-16 13:25:27.236236: train_loss -0.5108 
2024-12-16 13:25:27.241753: val_loss -0.463 
2024-12-16 13:25:27.244767: Pseudo dice [np.float32(0.689), np.float32(0.3083)] 
2024-12-16 13:25:27.247795: Epoch time: 38.65 s 
2024-12-16 13:25:27.789213:  
2024-12-16 13:25:27.794227: Epoch 66 
2024-12-16 13:25:27.797239: Current learning rate: 0.00379 
2024-12-16 13:26:06.467737: train_loss -0.5158 
2024-12-16 13:26:06.474283: val_loss -0.5501 
2024-12-16 13:26:06.476790: Pseudo dice [np.float32(0.727), np.float32(0.4421)] 
2024-12-16 13:26:06.480298: Epoch time: 38.68 s 
2024-12-16 13:26:07.020538:  
2024-12-16 13:26:07.026062: Epoch 67 
2024-12-16 13:26:07.028571: Current learning rate: 0.00369 
2024-12-16 13:26:45.710527: train_loss -0.5254 
2024-12-16 13:26:45.717043: val_loss -0.4976 
2024-12-16 13:26:45.721553: Pseudo dice [np.float32(0.7061), np.float32(0.3966)] 
2024-12-16 13:26:45.724562: Epoch time: 38.69 s 
2024-12-16 13:26:45.729079: Yayy! New best EMA pseudo Dice: 0.5396000146865845 
2024-12-16 13:26:46.483177:  
2024-12-16 13:26:46.488212: Epoch 68 
2024-12-16 13:26:46.491293: Current learning rate: 0.00359 
2024-12-16 13:27:25.149636: train_loss -0.4994 
2024-12-16 13:27:25.154675: val_loss -0.4865 
2024-12-16 13:27:25.159686: Pseudo dice [np.float32(0.7084), np.float32(0.4103)] 
2024-12-16 13:27:25.163196: Epoch time: 38.67 s 
2024-12-16 13:27:25.165791: Yayy! New best EMA pseudo Dice: 0.5415999889373779 
2024-12-16 13:27:25.896734:  
2024-12-16 13:27:25.901810: Epoch 69 
2024-12-16 13:27:25.905106: Current learning rate: 0.00349 
2024-12-16 13:28:04.573563: train_loss -0.5301 
2024-12-16 13:28:04.579717: val_loss -0.5364 
2024-12-16 13:28:04.583249: Pseudo dice [np.float32(0.7509), np.float32(0.4224)] 
2024-12-16 13:28:04.586877: Epoch time: 38.68 s 
2024-12-16 13:28:04.589941: Yayy! New best EMA pseudo Dice: 0.5461000204086304 
2024-12-16 13:28:05.450447:  
2024-12-16 13:28:05.456040: Epoch 70 
2024-12-16 13:28:05.459049: Current learning rate: 0.00338 
2024-12-16 13:28:44.276039: train_loss -0.543 
2024-12-16 13:28:44.282137: val_loss -0.5758 
2024-12-16 13:28:44.285237: Pseudo dice [np.float32(0.7303), np.float32(0.5595)] 
2024-12-16 13:28:44.288833: Epoch time: 38.83 s 
2024-12-16 13:28:44.291372: Yayy! New best EMA pseudo Dice: 0.555899977684021 
2024-12-16 13:28:44.993493:  
2024-12-16 13:28:44.998511: Epoch 71 
2024-12-16 13:28:45.002026: Current learning rate: 0.00328 
2024-12-16 13:29:23.683579: train_loss -0.5316 
2024-12-16 13:29:23.688675: val_loss -0.4797 
2024-12-16 13:29:23.693248: Pseudo dice [np.float32(0.6779), np.float32(0.3444)] 
2024-12-16 13:29:23.696326: Epoch time: 38.69 s 
2024-12-16 13:29:24.242474:  
2024-12-16 13:29:24.247486: Epoch 72 
2024-12-16 13:29:24.250019: Current learning rate: 0.00318 
2024-12-16 13:30:02.913999: train_loss -0.5317 
2024-12-16 13:30:02.920515: val_loss -0.5029 
2024-12-16 13:30:02.925025: Pseudo dice [np.float32(0.7088), np.float32(0.4941)] 
2024-12-16 13:30:02.928036: Epoch time: 38.67 s 
2024-12-16 13:30:02.930543: Yayy! New best EMA pseudo Dice: 0.5565000176429749 
2024-12-16 13:30:03.671810:  
2024-12-16 13:30:03.677327: Epoch 73 
2024-12-16 13:30:03.679834: Current learning rate: 0.00308 
2024-12-16 13:30:42.330699: train_loss -0.5158 
2024-12-16 13:30:42.338356: val_loss -0.5392 
2024-12-16 13:30:42.341018: Pseudo dice [np.float32(0.7269), np.float32(0.4968)] 
2024-12-16 13:30:42.344573: Epoch time: 38.66 s 
2024-12-16 13:30:42.347641: Yayy! New best EMA pseudo Dice: 0.5619999766349792 
2024-12-16 13:30:43.054446:  
2024-12-16 13:30:43.059477: Epoch 74 
2024-12-16 13:30:43.062550: Current learning rate: 0.00297 
2024-12-16 13:31:21.732287: train_loss -0.5366 
2024-12-16 13:31:21.738300: val_loss -0.4792 
2024-12-16 13:31:21.742311: Pseudo dice [np.float32(0.7171), np.float32(0.4269)] 
2024-12-16 13:31:21.744816: Epoch time: 38.68 s 
2024-12-16 13:31:21.748863: Yayy! New best EMA pseudo Dice: 0.5630000233650208 
2024-12-16 13:31:22.515896:  
2024-12-16 13:31:22.521451: Epoch 75 
2024-12-16 13:31:22.524481: Current learning rate: 0.00287 
2024-12-16 13:32:01.193966: train_loss -0.516 
2024-12-16 13:32:01.200984: val_loss -0.5106 
2024-12-16 13:32:01.205000: Pseudo dice [np.float32(0.7233), np.float32(0.4578)] 
2024-12-16 13:32:01.207506: Epoch time: 38.68 s 
2024-12-16 13:32:01.211020: Yayy! New best EMA pseudo Dice: 0.5658000111579895 
2024-12-16 13:32:01.920136:  
2024-12-16 13:32:01.925207: Epoch 76 
2024-12-16 13:32:01.929372: Current learning rate: 0.00277 
2024-12-16 13:32:40.627754: train_loss -0.5589 
2024-12-16 13:32:40.633271: val_loss -0.5157 
2024-12-16 13:32:40.636784: Pseudo dice [np.float32(0.733), np.float32(0.3263)] 
2024-12-16 13:32:40.640800: Epoch time: 38.71 s 
2024-12-16 13:32:41.341082:  
2024-12-16 13:32:41.345758: Epoch 77 
2024-12-16 13:32:41.348788: Current learning rate: 0.00266 
2024-12-16 13:33:20.034051: train_loss -0.5393 
2024-12-16 13:33:20.039567: val_loss -0.5493 
2024-12-16 13:33:20.043110: Pseudo dice [np.float32(0.7532), np.float32(0.3767)] 
2024-12-16 13:33:20.045146: Epoch time: 38.69 s 
2024-12-16 13:33:20.604288:  
2024-12-16 13:33:20.609834: Epoch 78 
2024-12-16 13:33:20.612375: Current learning rate: 0.00256 
2024-12-16 13:33:59.255024: train_loss -0.5207 
2024-12-16 13:33:59.261041: val_loss -0.5113 
2024-12-16 13:33:59.264550: Pseudo dice [np.float32(0.7365), np.float32(0.4246)] 
2024-12-16 13:33:59.267560: Epoch time: 38.65 s 
2024-12-16 13:33:59.823989:  
2024-12-16 13:33:59.828032: Epoch 79 
2024-12-16 13:33:59.832617: Current learning rate: 0.00245 
2024-12-16 13:34:38.306242: train_loss -0.5384 
2024-12-16 13:34:38.312762: val_loss -0.5462 
2024-12-16 13:34:38.316271: Pseudo dice [np.float32(0.7284), np.float32(0.5026)] 
2024-12-16 13:34:38.319283: Epoch time: 38.48 s 
2024-12-16 13:34:38.321790: Yayy! New best EMA pseudo Dice: 0.5694000124931335 
2024-12-16 13:34:39.024878:  
2024-12-16 13:34:39.028933: Epoch 80 
2024-12-16 13:34:39.033495: Current learning rate: 0.00235 
2024-12-16 13:35:17.519358: train_loss -0.5291 
2024-12-16 13:35:17.524374: val_loss -0.5342 
2024-12-16 13:35:17.529388: Pseudo dice [np.float32(0.7345), np.float32(0.5711)] 
2024-12-16 13:35:17.532899: Epoch time: 38.49 s 
2024-12-16 13:35:17.535408: Yayy! New best EMA pseudo Dice: 0.5777000188827515 
2024-12-16 13:35:18.253083:  
2024-12-16 13:35:18.258112: Epoch 81 
2024-12-16 13:35:18.261156: Current learning rate: 0.00224 
2024-12-16 13:35:56.727779: train_loss -0.5474 
2024-12-16 13:35:56.733338: val_loss -0.5141 
2024-12-16 13:35:56.737426: Pseudo dice [np.float32(0.7653), np.float32(0.3881)] 
2024-12-16 13:35:56.740493: Epoch time: 38.48 s 
2024-12-16 13:35:57.299002:  
2024-12-16 13:35:57.303023: Epoch 82 
2024-12-16 13:35:57.306554: Current learning rate: 0.00214 
2024-12-16 13:36:35.778995: train_loss -0.5552 
2024-12-16 13:36:35.786012: val_loss -0.5066 
2024-12-16 13:36:35.790028: Pseudo dice [np.float32(0.7351), np.float32(0.4478)] 
2024-12-16 13:36:35.792040: Epoch time: 38.48 s 
2024-12-16 13:36:35.795073: Yayy! New best EMA pseudo Dice: 0.5789999961853027 
2024-12-16 13:36:36.480555:  
2024-12-16 13:36:36.486093: Epoch 83 
2024-12-16 13:36:36.489118: Current learning rate: 0.00203 
2024-12-16 13:37:14.985632: train_loss -0.5403 
2024-12-16 13:37:14.991153: val_loss -0.5205 
2024-12-16 13:37:14.993660: Pseudo dice [np.float32(0.7437), np.float32(0.4222)] 
2024-12-16 13:37:14.997173: Epoch time: 38.51 s 
2024-12-16 13:37:14.999681: Yayy! New best EMA pseudo Dice: 0.5794000029563904 
2024-12-16 13:37:15.730690:  
2024-12-16 13:37:15.735706: Epoch 84 
2024-12-16 13:37:15.738213: Current learning rate: 0.00192 
2024-12-16 13:37:54.217822: train_loss -0.5455 
2024-12-16 13:37:54.224337: val_loss -0.5849 
2024-12-16 13:37:54.226894: Pseudo dice [np.float32(0.7576), np.float32(0.5177)] 
2024-12-16 13:37:54.230408: Epoch time: 38.49 s 
2024-12-16 13:37:54.233912: Yayy! New best EMA pseudo Dice: 0.5852000117301941 
2024-12-16 13:37:55.121641:  
2024-12-16 13:37:55.127212: Epoch 85 
2024-12-16 13:37:55.130260: Current learning rate: 0.00181 
2024-12-16 13:38:33.605096: train_loss -0.5308 
2024-12-16 13:38:33.612120: val_loss -0.48 
2024-12-16 13:38:33.616137: Pseudo dice [np.float32(0.7289), np.float32(0.3248)] 
2024-12-16 13:38:33.618647: Epoch time: 38.48 s 
2024-12-16 13:38:34.139813:  
2024-12-16 13:38:34.144862: Epoch 86 
2024-12-16 13:38:34.147371: Current learning rate: 0.0017 
2024-12-16 13:39:12.647330: train_loss -0.5747 
2024-12-16 13:39:12.652396: val_loss -0.5488 
2024-12-16 13:39:12.656379: Pseudo dice [np.float32(0.7728), np.float32(0.518)] 
2024-12-16 13:39:12.658967: Epoch time: 38.51 s 
2024-12-16 13:39:12.662045: Yayy! New best EMA pseudo Dice: 0.5860000252723694 
2024-12-16 13:39:13.368848:  
2024-12-16 13:39:13.373863: Epoch 87 
2024-12-16 13:39:13.377415: Current learning rate: 0.00159 
2024-12-16 13:39:51.851967: train_loss -0.5611 
2024-12-16 13:39:51.857981: val_loss -0.5131 
2024-12-16 13:39:51.861489: Pseudo dice [np.float32(0.7218), np.float32(0.3937)] 
2024-12-16 13:39:51.864503: Epoch time: 38.48 s 
2024-12-16 13:39:52.387952:  
2024-12-16 13:39:52.392975: Epoch 88 
2024-12-16 13:39:52.395581: Current learning rate: 0.00148 
2024-12-16 13:40:30.858476: train_loss -0.5653 
2024-12-16 13:40:30.863997: val_loss -0.5481 
2024-12-16 13:40:30.867508: Pseudo dice [np.float32(0.7496), np.float32(0.4487)] 
2024-12-16 13:40:30.871022: Epoch time: 38.47 s 
2024-12-16 13:40:31.395628:  
2024-12-16 13:40:31.400665: Epoch 89 
2024-12-16 13:40:31.403244: Current learning rate: 0.00137 
2024-12-16 13:41:09.900912: train_loss -0.5647 
2024-12-16 13:41:09.907096: val_loss -0.5512 
2024-12-16 13:41:09.911111: Pseudo dice [np.float32(0.7692), np.float32(0.504)] 
2024-12-16 13:41:09.914131: Epoch time: 38.51 s 
2024-12-16 13:41:09.917696: Yayy! New best EMA pseudo Dice: 0.589900016784668 
2024-12-16 13:41:10.617575:  
2024-12-16 13:41:10.622607: Epoch 90 
2024-12-16 13:41:10.625664: Current learning rate: 0.00126 
2024-12-16 13:41:49.076216: train_loss -0.5678 
2024-12-16 13:41:49.082237: val_loss -0.5429 
2024-12-16 13:41:49.085266: Pseudo dice [np.float32(0.7639), np.float32(0.4828)] 
2024-12-16 13:41:49.088796: Epoch time: 38.46 s 
2024-12-16 13:41:49.091367: Yayy! New best EMA pseudo Dice: 0.5932999849319458 
2024-12-16 13:41:49.771472:  
2024-12-16 13:41:49.776489: Epoch 91 
2024-12-16 13:41:49.778994: Current learning rate: 0.00115 
2024-12-16 13:42:28.321121: train_loss -0.5517 
2024-12-16 13:42:28.326290: val_loss -0.5441 
2024-12-16 13:42:28.328840: Pseudo dice [np.float32(0.7368), np.float32(0.428)] 
2024-12-16 13:42:28.332351: Epoch time: 38.55 s 
2024-12-16 13:42:28.868076:  
2024-12-16 13:42:28.873087: Epoch 92 
2024-12-16 13:42:28.876099: Current learning rate: 0.00103 
2024-12-16 13:43:07.428960: train_loss -0.5921 
2024-12-16 13:43:07.436480: val_loss -0.5553 
2024-12-16 13:43:07.440493: Pseudo dice [np.float32(0.748), np.float32(0.5219)] 
2024-12-16 13:43:07.443002: Epoch time: 38.56 s 
2024-12-16 13:43:07.447012: Yayy! New best EMA pseudo Dice: 0.5964999794960022 
2024-12-16 13:43:08.313306:  
2024-12-16 13:43:08.318864: Epoch 93 
2024-12-16 13:43:08.321390: Current learning rate: 0.00091 
2024-12-16 13:43:46.833381: train_loss -0.5947 
2024-12-16 13:43:46.839895: val_loss -0.5096 
2024-12-16 13:43:46.844410: Pseudo dice [np.float32(0.7665), np.float32(0.3415)] 
2024-12-16 13:43:46.847421: Epoch time: 38.52 s 
2024-12-16 13:43:47.360492:  
2024-12-16 13:43:47.365506: Epoch 94 
2024-12-16 13:43:47.369518: Current learning rate: 0.00079 
2024-12-16 13:44:25.863347: train_loss -0.6139 
2024-12-16 13:44:25.869397: val_loss -0.572 
2024-12-16 13:44:25.872909: Pseudo dice [np.float32(0.7641), np.float32(0.5459)] 
2024-12-16 13:44:25.875922: Epoch time: 38.5 s 
2024-12-16 13:44:25.878474: Yayy! New best EMA pseudo Dice: 0.5985000133514404 
2024-12-16 13:44:26.588463:  
2024-12-16 13:44:26.594018: Epoch 95 
2024-12-16 13:44:26.596583: Current learning rate: 0.00067 
2024-12-16 13:45:05.073507: train_loss -0.5985 
2024-12-16 13:45:05.079659: val_loss -0.5358 
2024-12-16 13:45:05.082181: Pseudo dice [np.float32(0.7476), np.float32(0.4445)] 
2024-12-16 13:45:05.085704: Epoch time: 38.49 s 
2024-12-16 13:45:05.609118:  
2024-12-16 13:45:05.614678: Epoch 96 
2024-12-16 13:45:05.617244: Current learning rate: 0.00055 
2024-12-16 13:45:44.098555: train_loss -0.5893 
2024-12-16 13:45:44.105074: val_loss -0.588 
2024-12-16 13:45:44.108588: Pseudo dice [np.float32(0.7821), np.float32(0.4971)] 
2024-12-16 13:45:44.112093: Epoch time: 38.49 s 
2024-12-16 13:45:44.115103: Yayy! New best EMA pseudo Dice: 0.602400004863739 
2024-12-16 13:45:44.827045:  
2024-12-16 13:45:44.832059: Epoch 97 
2024-12-16 13:45:44.835069: Current learning rate: 0.00043 
2024-12-16 13:46:23.339406: train_loss -0.6056 
2024-12-16 13:46:23.344420: val_loss -0.5414 
2024-12-16 13:46:23.347932: Pseudo dice [np.float32(0.7368), np.float32(0.4037)] 
2024-12-16 13:46:23.350438: Epoch time: 38.51 s 
2024-12-16 13:46:23.883465:  
2024-12-16 13:46:23.889480: Epoch 98 
2024-12-16 13:46:23.892489: Current learning rate: 0.0003 
2024-12-16 13:47:02.387373: train_loss -0.5938 
2024-12-16 13:47:02.393970: val_loss -0.5644 
2024-12-16 13:47:02.397549: Pseudo dice [np.float32(0.7607), np.float32(0.5225)] 
2024-12-16 13:47:02.400078: Epoch time: 38.5 s 
2024-12-16 13:47:02.404115: Yayy! New best EMA pseudo Dice: 0.6033999919891357 
2024-12-16 13:47:03.096493:  
2024-12-16 13:47:03.101567: Epoch 99 
2024-12-16 13:47:03.105150: Current learning rate: 0.00016 
2024-12-16 13:47:41.599210: train_loss -0.5706 
2024-12-16 13:47:41.605255: val_loss -0.5677 
2024-12-16 13:47:41.609206: Pseudo dice [np.float32(0.7399), np.float32(0.5085)] 
2024-12-16 13:47:41.611718: Epoch time: 38.5 s 
2024-12-16 13:47:41.615233: Yayy! New best EMA pseudo Dice: 0.6054999828338623 
2024-12-16 13:47:42.645896: Training done. 
2024-12-16 13:47:42.687406: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2024-12-16 13:47:42.693407: The split file contains 5 splits. 
2024-12-16 13:47:42.697407: Desired fold for training: 0 
2024-12-16 13:47:42.703408: This split has 224 training and 57 validation cases. 
2024-12-16 13:47:42.707408: predicting pancreas_021 
2024-12-16 13:47:42.712407: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2024-12-16 13:47:54.621775: predicting pancreas_024 
2024-12-16 13:47:54.637775: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2024-12-16 13:48:08.533899: predicting pancreas_035 
2024-12-16 13:48:08.549900: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2024-12-16 13:48:13.501348: predicting pancreas_040 
2024-12-16 13:48:13.512348: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2024-12-16 13:48:25.077909: predicting pancreas_042 
2024-12-16 13:48:25.093165: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2024-12-16 13:48:38.964687: predicting pancreas_056 
2024-12-16 13:48:38.983691: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2024-12-16 13:48:50.550913: predicting pancreas_067 
2024-12-16 13:48:50.563914: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2024-12-16 13:49:04.405827: predicting pancreas_075 
2024-12-16 13:49:04.421830: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2024-12-16 13:49:11.378416: predicting pancreas_086 
2024-12-16 13:49:11.392416: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2024-12-16 13:49:19.506502: predicting pancreas_089 
2024-12-16 13:49:19.520007: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-16 13:49:31.086517: predicting pancreas_092 
2024-12-16 13:49:31.101516: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2024-12-16 13:49:56.557613: predicting pancreas_094 
2024-12-16 13:49:56.581613: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2024-12-16 13:50:04.353428: predicting pancreas_095 
2024-12-16 13:50:04.367429: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2024-12-16 13:50:12.099181: predicting pancreas_098 
2024-12-16 13:50:12.113180: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2024-12-16 13:50:41.225004: predicting pancreas_109 
2024-12-16 13:50:41.257007: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2024-12-16 13:50:55.153811: predicting pancreas_110 
2024-12-16 13:50:55.168814: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2024-12-16 13:51:14.593611: predicting pancreas_114 
2024-12-16 13:51:14.612614: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2024-12-16 13:51:23.896022: predicting pancreas_119 
2024-12-16 13:51:23.908531: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2024-12-16 13:51:37.417356: predicting pancreas_138 
2024-12-16 13:51:37.436356: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2024-12-16 13:51:53.618093: predicting pancreas_145 
2024-12-16 13:51:53.636093: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2024-12-16 13:52:09.849076: predicting pancreas_148 
2024-12-16 13:52:09.868076: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2024-12-16 13:52:21.405543: predicting pancreas_169 
2024-12-16 13:52:21.418541: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2024-12-16 13:52:29.169120: predicting pancreas_170 
2024-12-16 13:52:29.184121: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2024-12-16 13:52:43.072125: predicting pancreas_172 
2024-12-16 13:52:43.089124: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2024-12-16 13:52:50.860101: predicting pancreas_175 
2024-12-16 13:52:50.875099: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2024-12-16 13:53:02.450026: predicting pancreas_180 
2024-12-16 13:53:02.464530: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2024-12-16 13:53:10.224636: predicting pancreas_191 
2024-12-16 13:53:10.239635: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2024-12-16 13:53:14.893325: predicting pancreas_193 
2024-12-16 13:53:14.906325: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2024-12-16 13:53:31.044648: predicting pancreas_212 
2024-12-16 13:53:31.060650: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2024-12-16 13:53:44.946903: predicting pancreas_215 
2024-12-16 13:53:44.963905: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2024-12-16 13:53:58.821623: predicting pancreas_222 
2024-12-16 13:53:58.840603: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2024-12-16 13:54:03.808392: predicting pancreas_235 
2024-12-16 13:54:03.819392: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2024-12-16 13:54:15.377784: predicting pancreas_241 
2024-12-16 13:54:15.390786: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2024-12-16 13:54:29.258221: predicting pancreas_242 
2024-12-16 13:54:29.277224: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2024-12-16 13:54:43.185156: predicting pancreas_244 
2024-12-16 13:54:43.205163: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2024-12-16 13:55:02.637064: predicting pancreas_246 
2024-12-16 13:55:02.655061: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2024-12-16 13:55:18.899848: predicting pancreas_247 
2024-12-16 13:55:18.922853: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2024-12-16 13:55:26.652214: predicting pancreas_264 
2024-12-16 13:55:26.663214: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2024-12-16 13:55:40.549331: predicting pancreas_265 
2024-12-16 13:55:40.571334: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2024-12-16 13:55:52.160120: predicting pancreas_266 
2024-12-16 13:55:52.175121: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2024-12-16 13:56:08.389896: predicting pancreas_267 
2024-12-16 13:56:08.406896: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2024-12-16 13:56:16.141012: predicting pancreas_275 
2024-12-16 13:56:16.153013: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2024-12-16 13:56:25.458370: predicting pancreas_279 
2024-12-16 13:56:25.473371: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2024-12-16 13:56:31.667065: predicting pancreas_287 
2024-12-16 13:56:31.679063: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2024-12-16 13:56:45.565237: predicting pancreas_301 
2024-12-16 13:56:45.581241: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2024-12-16 13:56:57.141889: predicting pancreas_323 
2024-12-16 13:56:57.156889: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2024-12-16 13:57:13.378595: predicting pancreas_336 
2024-12-16 13:57:13.397595: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2024-12-16 13:57:24.984443: predicting pancreas_344 
2024-12-16 13:57:25.000443: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2024-12-16 13:57:38.905352: predicting pancreas_351 
2024-12-16 13:57:38.922357: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2024-12-16 13:57:46.672260: predicting pancreas_354 
2024-12-16 13:57:46.685260: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2024-12-16 13:58:09.925476: predicting pancreas_372 
2024-12-16 13:58:09.950989: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2024-12-16 13:58:26.216511: predicting pancreas_377 
2024-12-16 13:58:26.239516: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2024-12-16 13:58:40.195943: predicting pancreas_387 
2024-12-16 13:58:40.220943: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2024-12-16 13:58:54.138364: predicting pancreas_391 
2024-12-16 13:58:54.154369: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2024-12-16 13:59:10.392632: predicting pancreas_392 
2024-12-16 13:59:10.411635: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2024-12-16 13:59:21.265081: predicting pancreas_410 
2024-12-16 13:59:21.279087: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2024-12-16 13:59:30.556530: predicting pancreas_412 
2024-12-16 13:59:30.569531: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2024-12-16 14:00:26.262572: Validation complete 
2024-12-16 14:00:26.267571: Mean Validation Dice:  0.6137202681564935 
