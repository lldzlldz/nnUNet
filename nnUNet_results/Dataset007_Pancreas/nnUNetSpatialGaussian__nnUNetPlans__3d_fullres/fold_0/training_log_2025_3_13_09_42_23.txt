
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-13 09:42:23.640700: do_dummy_2d_data_aug: True 
2025-03-13 09:42:23.651696: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-03-13 09:42:23.658696: The split file contains 5 splits. 
2025-03-13 09:42:23.661696: Desired fold for training: 0 
2025-03-13 09:42:23.664697: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-03-13 09:42:32.122035: unpacking dataset... 
2025-03-13 09:42:54.748588: unpacking done... 
2025-03-13 09:42:58.937567:  
2025-03-13 09:42:58.943081: Epoch 0 
2025-03-13 09:42:58.945587: Current learning rate: 0.01 
2025-03-13 09:43:44.394043: train_loss 0.1178 
2025-03-13 09:43:44.399961: val_loss 0.0404 
2025-03-13 09:43:44.402466: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-03-13 09:43:44.406475: Epoch time: 45.46 s 
2025-03-13 09:43:44.408980: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-13 09:43:45.033421:  
2025-03-13 09:43:45.038972: Epoch 1 
2025-03-13 09:43:45.042988: Current learning rate: 0.00991 
2025-03-13 09:44:25.857324: train_loss 0.018 
2025-03-13 09:44:25.862434: val_loss -0.0358 
2025-03-13 09:44:25.866465: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-03-13 09:44:25.869507: Epoch time: 40.82 s 
2025-03-13 09:44:26.387081:  
2025-03-13 09:44:26.393210: Epoch 2 
2025-03-13 09:44:26.396235: Current learning rate: 0.00982 
2025-03-13 09:45:07.209145: train_loss -0.0432 
2025-03-13 09:45:07.215673: val_loss -0.0724 
2025-03-13 09:45:07.219180: Pseudo dice [np.float32(0.3641), np.float32(0.0)] 
2025-03-13 09:45:07.222189: Epoch time: 40.82 s 
2025-03-13 09:45:07.225697: Yayy! New best EMA pseudo Dice: 0.018200000748038292 
2025-03-13 09:45:07.930040:  
2025-03-13 09:45:07.935624: Epoch 3 
2025-03-13 09:45:07.938175: Current learning rate: 0.00973 
2025-03-13 09:45:48.742278: train_loss -0.0933 
2025-03-13 09:45:48.749797: val_loss -0.1337 
2025-03-13 09:45:48.754807: Pseudo dice [np.float32(0.3987), np.float32(0.0)] 
2025-03-13 09:45:48.758316: Epoch time: 40.81 s 
2025-03-13 09:45:48.761830: Yayy! New best EMA pseudo Dice: 0.03629999980330467 
2025-03-13 09:45:49.450080:  
2025-03-13 09:45:49.455099: Epoch 4 
2025-03-13 09:45:49.458608: Current learning rate: 0.00964 
2025-03-13 09:46:30.256168: train_loss -0.123 
2025-03-13 09:46:30.261697: val_loss -0.1887 
2025-03-13 09:46:30.264735: Pseudo dice [np.float32(0.4644), np.float32(0.0)] 
2025-03-13 09:46:30.268753: Epoch time: 40.81 s 
2025-03-13 09:46:30.271263: Yayy! New best EMA pseudo Dice: 0.05590000003576279 
2025-03-13 09:46:31.120494:  
2025-03-13 09:46:31.125505: Epoch 5 
2025-03-13 09:46:31.129019: Current learning rate: 0.00955 
2025-03-13 09:47:11.923252: train_loss -0.1449 
2025-03-13 09:47:11.929895: val_loss -0.1838 
2025-03-13 09:47:11.932981: Pseudo dice [np.float32(0.4276), np.float32(0.0)] 
2025-03-13 09:47:11.936007: Epoch time: 40.8 s 
2025-03-13 09:47:11.939525: Yayy! New best EMA pseudo Dice: 0.07169999927282333 
2025-03-13 09:47:12.651415:  
2025-03-13 09:47:12.656426: Epoch 6 
2025-03-13 09:47:12.659935: Current learning rate: 0.00946 
2025-03-13 09:47:53.445079: train_loss -0.1929 
2025-03-13 09:47:53.452600: val_loss -0.1952 
2025-03-13 09:47:53.456657: Pseudo dice [np.float32(0.4843), np.float32(0.0)] 
2025-03-13 09:47:53.459162: Epoch time: 40.79 s 
2025-03-13 09:47:53.462674: Yayy! New best EMA pseudo Dice: 0.08869999647140503 
2025-03-13 09:47:54.149935:  
2025-03-13 09:47:54.155478: Epoch 7 
2025-03-13 09:47:54.158039: Current learning rate: 0.00937 
2025-03-13 09:48:34.939607: train_loss -0.1954 
2025-03-13 09:48:34.945201: val_loss -0.2851 
2025-03-13 09:48:34.949246: Pseudo dice [np.float32(0.5246), np.float32(0.2304)] 
2025-03-13 09:48:34.952284: Epoch time: 40.79 s 
2025-03-13 09:48:34.955346: Yayy! New best EMA pseudo Dice: 0.11760000139474869 
2025-03-13 09:48:35.684941:  
2025-03-13 09:48:35.690975: Epoch 8 
2025-03-13 09:48:35.694261: Current learning rate: 0.00928 
2025-03-13 09:49:16.476396: train_loss -0.2412 
2025-03-13 09:49:16.482423: val_loss -0.2693 
2025-03-13 09:49:16.484743: Pseudo dice [np.float32(0.4613), np.float32(0.2777)] 
2025-03-13 09:49:16.489286: Epoch time: 40.79 s 
2025-03-13 09:49:16.491794: Yayy! New best EMA pseudo Dice: 0.1428000032901764 
2025-03-13 09:49:17.192538:  
2025-03-13 09:49:17.197549: Epoch 9 
2025-03-13 09:49:17.201061: Current learning rate: 0.00919 
2025-03-13 09:49:57.993362: train_loss -0.25 
2025-03-13 09:49:57.999772: val_loss -0.2801 
2025-03-13 09:49:58.002852: Pseudo dice [np.float32(0.503), np.float32(0.2673)] 
2025-03-13 09:49:58.006871: Epoch time: 40.8 s 
2025-03-13 09:49:58.009381: Yayy! New best EMA pseudo Dice: 0.16699999570846558 
2025-03-13 09:49:58.686583:  
2025-03-13 09:49:58.690621: Epoch 10 
2025-03-13 09:49:58.693156: Current learning rate: 0.0091 
2025-03-13 09:50:39.513692: train_loss -0.2643 
2025-03-13 09:50:39.519763: val_loss -0.343 
2025-03-13 09:50:39.523809: Pseudo dice [np.float32(0.5647), np.float32(0.363)] 
2025-03-13 09:50:39.526857: Epoch time: 40.83 s 
2025-03-13 09:50:39.529918: Yayy! New best EMA pseudo Dice: 0.19670000672340393 
2025-03-13 09:50:40.216207:  
2025-03-13 09:50:40.221739: Epoch 11 
2025-03-13 09:50:40.225294: Current learning rate: 0.009 
2025-03-13 09:51:21.023575: train_loss -0.2871 
2025-03-13 09:51:21.029665: val_loss -0.3325 
2025-03-13 09:51:21.034785: Pseudo dice [np.float32(0.5507), np.float32(0.2869)] 
2025-03-13 09:51:21.039354: Epoch time: 40.81 s 
2025-03-13 09:51:21.042394: Yayy! New best EMA pseudo Dice: 0.21889999508857727 
2025-03-13 09:51:21.765645:  
2025-03-13 09:51:21.772223: Epoch 12 
2025-03-13 09:51:21.774763: Current learning rate: 0.00891 
2025-03-13 09:52:02.631757: train_loss -0.2874 
2025-03-13 09:52:02.638293: val_loss -0.2865 
2025-03-13 09:52:02.641801: Pseudo dice [np.float32(0.4882), np.float32(0.2451)] 
2025-03-13 09:52:02.645306: Epoch time: 40.87 s 
2025-03-13 09:52:02.648313: Yayy! New best EMA pseudo Dice: 0.2337000072002411 
2025-03-13 09:52:03.486469:  
2025-03-13 09:52:03.491982: Epoch 13 
2025-03-13 09:52:03.495498: Current learning rate: 0.00882 
2025-03-13 09:52:44.308762: train_loss -0.2967 
2025-03-13 09:52:44.314816: val_loss -0.3759 
2025-03-13 09:52:44.318322: Pseudo dice [np.float32(0.5374), np.float32(0.3921)] 
2025-03-13 09:52:44.321336: Epoch time: 40.82 s 
2025-03-13 09:52:44.324844: Yayy! New best EMA pseudo Dice: 0.25679999589920044 
2025-03-13 09:52:45.009562:  
2025-03-13 09:52:45.015678: Epoch 14 
2025-03-13 09:52:45.018729: Current learning rate: 0.00873 
2025-03-13 09:53:25.800327: train_loss -0.3521 
2025-03-13 09:53:25.806449: val_loss -0.3309 
2025-03-13 09:53:25.808991: Pseudo dice [np.float32(0.5519), np.float32(0.3102)] 
2025-03-13 09:53:25.813532: Epoch time: 40.79 s 
2025-03-13 09:53:25.816148: Yayy! New best EMA pseudo Dice: 0.2741999924182892 
2025-03-13 09:53:26.495526:  
2025-03-13 09:53:26.502084: Epoch 15 
2025-03-13 09:53:26.504617: Current learning rate: 0.00864 
2025-03-13 09:54:07.295166: train_loss -0.3596 
2025-03-13 09:54:07.300684: val_loss -0.3711 
2025-03-13 09:54:07.305193: Pseudo dice [np.float32(0.5734), np.float32(0.361)] 
2025-03-13 09:54:07.308203: Epoch time: 40.8 s 
2025-03-13 09:54:07.311714: Yayy! New best EMA pseudo Dice: 0.29350000619888306 
2025-03-13 09:54:08.023634:  
2025-03-13 09:54:08.029145: Epoch 16 
2025-03-13 09:54:08.032654: Current learning rate: 0.00855 
2025-03-13 09:54:48.806404: train_loss -0.346 
2025-03-13 09:54:48.813919: val_loss -0.3858 
2025-03-13 09:54:48.817930: Pseudo dice [np.float32(0.6118), np.float32(0.3154)] 
2025-03-13 09:54:48.821437: Epoch time: 40.78 s 
2025-03-13 09:54:48.824943: Yayy! New best EMA pseudo Dice: 0.31049999594688416 
2025-03-13 09:54:49.562133:  
2025-03-13 09:54:49.568712: Epoch 17 
2025-03-13 09:54:49.571799: Current learning rate: 0.00846 
2025-03-13 09:55:30.385106: train_loss -0.3781 
2025-03-13 09:55:30.390623: val_loss -0.3275 
2025-03-13 09:55:30.395133: Pseudo dice [np.float32(0.6246), np.float32(0.1858)] 
2025-03-13 09:55:30.398140: Epoch time: 40.82 s 
2025-03-13 09:55:30.402647: Yayy! New best EMA pseudo Dice: 0.3199999928474426 
2025-03-13 09:55:31.124524:  
2025-03-13 09:55:31.130078: Epoch 18 
2025-03-13 09:55:31.133648: Current learning rate: 0.00836 
2025-03-13 09:56:11.942975: train_loss -0.3474 
2025-03-13 09:56:11.948994: val_loss -0.3669 
2025-03-13 09:56:11.951124: Pseudo dice [np.float32(0.5642), np.float32(0.3961)] 
2025-03-13 09:56:11.955647: Epoch time: 40.82 s 
2025-03-13 09:56:11.958157: Yayy! New best EMA pseudo Dice: 0.335999995470047 
2025-03-13 09:56:12.684005:  
2025-03-13 09:56:12.689485: Epoch 19 
2025-03-13 09:56:12.691497: Current learning rate: 0.00827 
2025-03-13 09:56:53.480799: train_loss -0.3665 
2025-03-13 09:56:53.487428: val_loss -0.3758 
2025-03-13 09:56:53.490979: Pseudo dice [np.float32(0.5862), np.float32(0.34)] 
2025-03-13 09:56:53.494012: Epoch time: 40.8 s 
2025-03-13 09:56:53.498037: Yayy! New best EMA pseudo Dice: 0.34869998693466187 
2025-03-13 09:56:54.341881:  
2025-03-13 09:56:54.347880: Epoch 20 
2025-03-13 09:56:54.351919: Current learning rate: 0.00818 
2025-03-13 09:57:35.146687: train_loss -0.3646 
2025-03-13 09:57:35.152239: val_loss -0.3611 
2025-03-13 09:57:35.155369: Pseudo dice [np.float32(0.5885), np.float32(0.297)] 
2025-03-13 09:57:35.158897: Epoch time: 40.8 s 
2025-03-13 09:57:35.161980: Yayy! New best EMA pseudo Dice: 0.3580999970436096 
2025-03-13 09:57:35.854673:  
2025-03-13 09:57:35.860185: Epoch 21 
2025-03-13 09:57:35.863694: Current learning rate: 0.00809 
2025-03-13 09:58:16.646697: train_loss -0.3799 
2025-03-13 09:58:16.652704: val_loss -0.3686 
2025-03-13 09:58:16.655714: Pseudo dice [np.float32(0.6279), np.float32(0.2726)] 
2025-03-13 09:58:16.659221: Epoch time: 40.79 s 
2025-03-13 09:58:16.661730: Yayy! New best EMA pseudo Dice: 0.36730000376701355 
2025-03-13 09:58:17.339647:  
2025-03-13 09:58:17.345188: Epoch 22 
2025-03-13 09:58:17.348226: Current learning rate: 0.008 
2025-03-13 09:58:58.132893: train_loss -0.3949 
2025-03-13 09:58:58.140413: val_loss -0.4604 
2025-03-13 09:58:58.143985: Pseudo dice [np.float32(0.6357), np.float32(0.4499)] 
2025-03-13 09:58:58.147132: Epoch time: 40.79 s 
2025-03-13 09:58:58.150643: Yayy! New best EMA pseudo Dice: 0.3849000036716461 
2025-03-13 09:58:58.843220:  
2025-03-13 09:58:58.848807: Epoch 23 
2025-03-13 09:58:58.851346: Current learning rate: 0.0079 
2025-03-13 09:59:39.621037: train_loss -0.4182 
2025-03-13 09:59:39.627047: val_loss -0.4432 
2025-03-13 09:59:39.630059: Pseudo dice [np.float32(0.6423), np.float32(0.36)] 
2025-03-13 09:59:39.633567: Epoch time: 40.78 s 
2025-03-13 09:59:39.637588: Yayy! New best EMA pseudo Dice: 0.39649999141693115 
2025-03-13 09:59:40.336351:  
2025-03-13 09:59:40.341900: Epoch 24 
2025-03-13 09:59:40.344933: Current learning rate: 0.00781 
2025-03-13 10:00:21.115478: train_loss -0.3935 
2025-03-13 10:00:21.121493: val_loss -0.381 
2025-03-13 10:00:21.125504: Pseudo dice [np.float32(0.6147), np.float32(0.3196)] 
2025-03-13 10:00:21.128009: Epoch time: 40.78 s 
2025-03-13 10:00:21.131517: Yayy! New best EMA pseudo Dice: 0.4036000072956085 
2025-03-13 10:00:21.850106:  
2025-03-13 10:00:21.855181: Epoch 25 
2025-03-13 10:00:21.858718: Current learning rate: 0.00772 
2025-03-13 10:01:02.640541: train_loss -0.4398 
2025-03-13 10:01:02.647555: val_loss -0.4415 
2025-03-13 10:01:02.650571: Pseudo dice [np.float32(0.6447), np.float32(0.3698)] 
2025-03-13 10:01:02.654086: Epoch time: 40.79 s 
2025-03-13 10:01:02.656590: Yayy! New best EMA pseudo Dice: 0.4138999879360199 
2025-03-13 10:01:03.361404:  
2025-03-13 10:01:03.367478: Epoch 26 
2025-03-13 10:01:03.370987: Current learning rate: 0.00763 
2025-03-13 10:01:44.152028: train_loss -0.4272 
2025-03-13 10:01:44.157615: val_loss -0.4507 
2025-03-13 10:01:44.162756: Pseudo dice [np.float32(0.6885), np.float32(0.3537)] 
2025-03-13 10:01:44.166298: Epoch time: 40.79 s 
2025-03-13 10:01:44.171096: Yayy! New best EMA pseudo Dice: 0.4246000051498413 
2025-03-13 10:01:44.888660:  
2025-03-13 10:01:44.895209: Epoch 27 
2025-03-13 10:01:44.897778: Current learning rate: 0.00753 
2025-03-13 10:02:25.689203: train_loss -0.436 
2025-03-13 10:02:25.694213: val_loss -0.4535 
2025-03-13 10:02:25.697721: Pseudo dice [np.float32(0.6779), np.float32(0.3717)] 
2025-03-13 10:02:25.701226: Epoch time: 40.8 s 
2025-03-13 10:02:25.704235: Yayy! New best EMA pseudo Dice: 0.43470001220703125 
2025-03-13 10:02:26.512367:  
2025-03-13 10:02:26.518101: Epoch 28 
2025-03-13 10:02:26.521141: Current learning rate: 0.00744 
2025-03-13 10:03:07.305078: train_loss -0.4551 
2025-03-13 10:03:07.311158: val_loss -0.4368 
2025-03-13 10:03:07.314192: Pseudo dice [np.float32(0.643), np.float32(0.3736)] 
2025-03-13 10:03:07.316697: Epoch time: 40.79 s 
2025-03-13 10:03:07.320713: Yayy! New best EMA pseudo Dice: 0.44200000166893005 
2025-03-13 10:03:07.995167:  
2025-03-13 10:03:08.000177: Epoch 29 
2025-03-13 10:03:08.003684: Current learning rate: 0.00735 
2025-03-13 10:03:48.789770: train_loss -0.4609 
2025-03-13 10:03:48.795865: val_loss -0.5074 
2025-03-13 10:03:48.798923: Pseudo dice [np.float32(0.6871), np.float32(0.4817)] 
2025-03-13 10:03:48.802471: Epoch time: 40.8 s 
2025-03-13 10:03:48.805517: Yayy! New best EMA pseudo Dice: 0.4562999904155731 
2025-03-13 10:03:49.533026:  
2025-03-13 10:03:49.538609: Epoch 30 
2025-03-13 10:03:49.541162: Current learning rate: 0.00725 
2025-03-13 10:04:30.329002: train_loss -0.4618 
2025-03-13 10:04:30.334034: val_loss -0.4755 
2025-03-13 10:04:30.338058: Pseudo dice [np.float32(0.6755), np.float32(0.409)] 
2025-03-13 10:04:30.341103: Epoch time: 40.8 s 
2025-03-13 10:04:30.344153: Yayy! New best EMA pseudo Dice: 0.4648999869823456 
2025-03-13 10:04:31.026779:  
2025-03-13 10:04:31.032320: Epoch 31 
2025-03-13 10:04:31.035899: Current learning rate: 0.00716 
2025-03-13 10:05:11.783564: train_loss -0.4564 
2025-03-13 10:05:11.789580: val_loss -0.4107 
2025-03-13 10:05:11.793588: Pseudo dice [np.float32(0.6109), np.float32(0.3728)] 
2025-03-13 10:05:11.797096: Epoch time: 40.76 s 
2025-03-13 10:05:11.799603: Yayy! New best EMA pseudo Dice: 0.4675999879837036 
2025-03-13 10:05:12.485812:  
2025-03-13 10:05:12.490857: Epoch 32 
2025-03-13 10:05:12.495265: Current learning rate: 0.00707 
2025-03-13 10:05:53.259587: train_loss -0.4521 
2025-03-13 10:05:53.267133: val_loss -0.4587 
2025-03-13 10:05:53.270643: Pseudo dice [np.float32(0.6726), np.float32(0.4203)] 
2025-03-13 10:05:53.273650: Epoch time: 40.77 s 
2025-03-13 10:05:53.277161: Yayy! New best EMA pseudo Dice: 0.4754999876022339 
2025-03-13 10:05:54.003660:  
2025-03-13 10:05:54.009176: Epoch 33 
2025-03-13 10:05:54.012688: Current learning rate: 0.00697 
2025-03-13 10:06:34.785522: train_loss -0.4588 
2025-03-13 10:06:34.791601: val_loss -0.4981 
2025-03-13 10:06:34.795723: Pseudo dice [np.float32(0.6988), np.float32(0.3789)] 
2025-03-13 10:06:34.798738: Epoch time: 40.78 s 
2025-03-13 10:06:34.802249: Yayy! New best EMA pseudo Dice: 0.48179998993873596 
2025-03-13 10:06:35.503937:  
2025-03-13 10:06:35.510033: Epoch 34 
2025-03-13 10:06:35.513093: Current learning rate: 0.00688 
2025-03-13 10:07:16.301016: train_loss -0.4491 
2025-03-13 10:07:16.307033: val_loss -0.4971 
2025-03-13 10:07:16.309539: Pseudo dice [np.float32(0.6793), np.float32(0.4446)] 
2025-03-13 10:07:16.313044: Epoch time: 40.8 s 
2025-03-13 10:07:16.316053: Yayy! New best EMA pseudo Dice: 0.48980000615119934 
2025-03-13 10:07:17.061529:  
2025-03-13 10:07:17.067042: Epoch 35 
2025-03-13 10:07:17.070550: Current learning rate: 0.00679 
2025-03-13 10:07:57.859184: train_loss -0.4474 
2025-03-13 10:07:57.865698: val_loss -0.4872 
2025-03-13 10:07:57.869714: Pseudo dice [np.float32(0.6695), np.float32(0.3949)] 
2025-03-13 10:07:57.873222: Epoch time: 40.8 s 
2025-03-13 10:07:57.876729: Yayy! New best EMA pseudo Dice: 0.49399998784065247 
2025-03-13 10:07:58.714114:  
2025-03-13 10:07:58.719703: Epoch 36 
2025-03-13 10:07:58.722250: Current learning rate: 0.00669 
2025-03-13 10:08:39.504216: train_loss -0.4594 
2025-03-13 10:08:39.510224: val_loss -0.4764 
2025-03-13 10:08:39.515738: Pseudo dice [np.float32(0.6859), np.float32(0.4123)] 
2025-03-13 10:08:39.519246: Epoch time: 40.79 s 
2025-03-13 10:08:39.521761: Yayy! New best EMA pseudo Dice: 0.49959999322891235 
2025-03-13 10:08:40.210548:  
2025-03-13 10:08:40.216101: Epoch 37 
2025-03-13 10:08:40.219617: Current learning rate: 0.0066 
2025-03-13 10:09:20.994169: train_loss -0.4826 
2025-03-13 10:09:21.000695: val_loss -0.4811 
2025-03-13 10:09:21.004204: Pseudo dice [np.float32(0.6426), np.float32(0.4589)] 
2025-03-13 10:09:21.007717: Epoch time: 40.78 s 
2025-03-13 10:09:21.010735: Yayy! New best EMA pseudo Dice: 0.5047000050544739 
2025-03-13 10:09:21.702243:  
2025-03-13 10:09:21.708330: Epoch 38 
2025-03-13 10:09:21.711415: Current learning rate: 0.0065 
2025-03-13 10:10:02.489336: train_loss -0.4736 
2025-03-13 10:10:02.495408: val_loss -0.4777 
2025-03-13 10:10:02.498919: Pseudo dice [np.float32(0.6571), np.float32(0.444)] 
2025-03-13 10:10:02.502933: Epoch time: 40.79 s 
2025-03-13 10:10:02.506444: Yayy! New best EMA pseudo Dice: 0.5092999935150146 
2025-03-13 10:10:03.208507:  
2025-03-13 10:10:03.214198: Epoch 39 
2025-03-13 10:10:03.217779: Current learning rate: 0.00641 
2025-03-13 10:10:43.998486: train_loss -0.4899 
2025-03-13 10:10:44.004461: val_loss -0.539 
2025-03-13 10:10:44.006965: Pseudo dice [np.float32(0.7199), np.float32(0.4943)] 
2025-03-13 10:10:44.010977: Epoch time: 40.79 s 
2025-03-13 10:10:44.014488: Yayy! New best EMA pseudo Dice: 0.5189999938011169 
2025-03-13 10:10:44.717984:  
2025-03-13 10:10:44.723575: Epoch 40 
2025-03-13 10:10:44.727129: Current learning rate: 0.00631 
2025-03-13 10:11:25.502481: train_loss -0.4967 
2025-03-13 10:11:25.508998: val_loss -0.4866 
2025-03-13 10:11:25.511524: Pseudo dice [np.float32(0.7061), np.float32(0.3392)] 
2025-03-13 10:11:25.515649: Epoch time: 40.79 s 
2025-03-13 10:11:25.519286: Yayy! New best EMA pseudo Dice: 0.5194000005722046 
2025-03-13 10:11:26.225240:  
2025-03-13 10:11:26.230249: Epoch 41 
2025-03-13 10:11:26.233757: Current learning rate: 0.00622 
2025-03-13 10:12:07.008835: train_loss -0.5002 
2025-03-13 10:12:07.014849: val_loss -0.508 
2025-03-13 10:12:07.017860: Pseudo dice [np.float32(0.6918), np.float32(0.4431)] 
2025-03-13 10:12:07.021369: Epoch time: 40.79 s 
2025-03-13 10:12:07.023877: Yayy! New best EMA pseudo Dice: 0.5242000222206116 
2025-03-13 10:12:07.749370:  
2025-03-13 10:12:07.755437: Epoch 42 
2025-03-13 10:12:07.757767: Current learning rate: 0.00612 
2025-03-13 10:12:48.539095: train_loss -0.4786 
2025-03-13 10:12:48.546134: val_loss -0.5059 
2025-03-13 10:12:48.549643: Pseudo dice [np.float32(0.6895), np.float32(0.4139)] 
2025-03-13 10:12:48.553684: Epoch time: 40.79 s 
2025-03-13 10:12:48.556202: Yayy! New best EMA pseudo Dice: 0.5270000100135803 
2025-03-13 10:12:49.259826:  
2025-03-13 10:12:49.265879: Epoch 43 
2025-03-13 10:12:49.268946: Current learning rate: 0.00603 
2025-03-13 10:13:30.056041: train_loss -0.498 
2025-03-13 10:13:30.063160: val_loss -0.5191 
2025-03-13 10:13:30.066234: Pseudo dice [np.float32(0.676), np.float32(0.3805)] 
2025-03-13 10:13:30.069743: Epoch time: 40.8 s 
2025-03-13 10:13:30.072249: Yayy! New best EMA pseudo Dice: 0.5271000266075134 
2025-03-13 10:13:30.895784:  
2025-03-13 10:13:30.901318: Epoch 44 
2025-03-13 10:13:30.904833: Current learning rate: 0.00593 
2025-03-13 10:14:11.687538: train_loss -0.5002 
2025-03-13 10:14:11.693547: val_loss -0.5491 
2025-03-13 10:14:11.696556: Pseudo dice [np.float32(0.731), np.float32(0.4551)] 
2025-03-13 10:14:11.700064: Epoch time: 40.79 s 
2025-03-13 10:14:11.703573: Yayy! New best EMA pseudo Dice: 0.5336999893188477 
2025-03-13 10:14:12.372507:  
2025-03-13 10:14:12.377263: Epoch 45 
2025-03-13 10:14:12.380775: Current learning rate: 0.00584 
2025-03-13 10:14:53.143481: train_loss -0.4894 
2025-03-13 10:14:53.149564: val_loss -0.505 
2025-03-13 10:14:53.153140: Pseudo dice [np.float32(0.6908), np.float32(0.4214)] 
2025-03-13 10:14:53.158753: Epoch time: 40.77 s 
2025-03-13 10:14:53.161272: Yayy! New best EMA pseudo Dice: 0.5358999967575073 
2025-03-13 10:14:53.822475:  
2025-03-13 10:14:53.828494: Epoch 46 
2025-03-13 10:14:53.831001: Current learning rate: 0.00574 
2025-03-13 10:15:34.612622: train_loss -0.4992 
2025-03-13 10:15:34.619141: val_loss -0.5005 
2025-03-13 10:15:34.621648: Pseudo dice [np.float32(0.7167), np.float32(0.4309)] 
2025-03-13 10:15:34.625157: Epoch time: 40.79 s 
2025-03-13 10:15:34.628663: Yayy! New best EMA pseudo Dice: 0.5396999716758728 
2025-03-13 10:15:35.290253:  
2025-03-13 10:15:35.296409: Epoch 47 
2025-03-13 10:15:35.298916: Current learning rate: 0.00565 
2025-03-13 10:16:16.081027: train_loss -0.5017 
2025-03-13 10:16:16.086575: val_loss -0.4482 
2025-03-13 10:16:16.090084: Pseudo dice [np.float32(0.6482), np.float32(0.3368)] 
2025-03-13 10:16:16.094095: Epoch time: 40.79 s 
2025-03-13 10:16:16.613861:  
2025-03-13 10:16:16.618977: Epoch 48 
2025-03-13 10:16:16.622041: Current learning rate: 0.00555 
2025-03-13 10:16:57.410740: train_loss -0.5121 
2025-03-13 10:16:57.417896: val_loss -0.5645 
2025-03-13 10:16:57.419907: Pseudo dice [np.float32(0.7256), np.float32(0.5431)] 
2025-03-13 10:16:57.424791: Epoch time: 40.8 s 
2025-03-13 10:16:57.427300: Yayy! New best EMA pseudo Dice: 0.5449000000953674 
2025-03-13 10:16:58.100983:  
2025-03-13 10:16:58.106575: Epoch 49 
2025-03-13 10:16:58.110628: Current learning rate: 0.00546 
2025-03-13 10:17:38.885017: train_loss -0.5025 
2025-03-13 10:17:38.892072: val_loss -0.4947 
2025-03-13 10:17:38.894577: Pseudo dice [np.float32(0.7307), np.float32(0.3874)] 
2025-03-13 10:17:38.898085: Epoch time: 40.78 s 
2025-03-13 10:17:39.036814: Yayy! New best EMA pseudo Dice: 0.5462999939918518 
2025-03-13 10:17:39.712786:  
2025-03-13 10:17:39.718935: Epoch 50 
2025-03-13 10:17:39.721961: Current learning rate: 0.00536 
2025-03-13 10:18:20.494335: train_loss -0.4991 
2025-03-13 10:18:20.500412: val_loss -0.456 
2025-03-13 10:18:20.503994: Pseudo dice [np.float32(0.7077), np.float32(0.3327)] 
2025-03-13 10:18:20.507017: Epoch time: 40.78 s 
2025-03-13 10:18:21.031353:  
2025-03-13 10:18:21.036367: Epoch 51 
2025-03-13 10:18:21.039881: Current learning rate: 0.00526 
2025-03-13 10:19:01.803414: train_loss -0.4884 
2025-03-13 10:19:01.809029: val_loss -0.4774 
2025-03-13 10:19:01.812098: Pseudo dice [np.float32(0.6818), np.float32(0.3566)] 
2025-03-13 10:19:01.815133: Epoch time: 40.77 s 
2025-03-13 10:19:02.345605:  
2025-03-13 10:19:02.350618: Epoch 52 
2025-03-13 10:19:02.354129: Current learning rate: 0.00517 
2025-03-13 10:19:43.130874: train_loss -0.5174 
2025-03-13 10:19:43.136890: val_loss -0.5283 
2025-03-13 10:19:43.140397: Pseudo dice [np.float32(0.727), np.float32(0.4676)] 
2025-03-13 10:19:43.143405: Epoch time: 40.79 s 
2025-03-13 10:19:43.146912: Yayy! New best EMA pseudo Dice: 0.5468999743461609 
2025-03-13 10:19:43.973310:  
2025-03-13 10:19:43.978436: Epoch 53 
2025-03-13 10:19:43.981955: Current learning rate: 0.00507 
2025-03-13 10:20:24.783690: train_loss -0.5241 
2025-03-13 10:20:24.789703: val_loss -0.5495 
2025-03-13 10:20:24.793715: Pseudo dice [np.float32(0.7325), np.float32(0.4526)] 
2025-03-13 10:20:24.796221: Epoch time: 40.81 s 
2025-03-13 10:20:24.799729: Yayy! New best EMA pseudo Dice: 0.5514000058174133 
2025-03-13 10:20:25.475320:  
2025-03-13 10:20:25.481424: Epoch 54 
2025-03-13 10:20:25.484483: Current learning rate: 0.00497 
2025-03-13 10:21:06.275450: train_loss -0.5138 
2025-03-13 10:21:06.281963: val_loss -0.4791 
2025-03-13 10:21:06.285472: Pseudo dice [np.float32(0.7063), np.float32(0.3698)] 
2025-03-13 10:21:06.289482: Epoch time: 40.8 s 
2025-03-13 10:21:06.814956:  
2025-03-13 10:21:06.819967: Epoch 55 
2025-03-13 10:21:06.823481: Current learning rate: 0.00487 
2025-03-13 10:21:47.606858: train_loss -0.5168 
2025-03-13 10:21:47.612871: val_loss -0.5181 
2025-03-13 10:21:47.616879: Pseudo dice [np.float32(0.7356), np.float32(0.4258)] 
2025-03-13 10:21:47.620390: Epoch time: 40.79 s 
2025-03-13 10:21:47.622897: Yayy! New best EMA pseudo Dice: 0.5532000064849854 
2025-03-13 10:21:48.338524:  
2025-03-13 10:21:48.345035: Epoch 56 
2025-03-13 10:21:48.347540: Current learning rate: 0.00478 
2025-03-13 10:22:29.127018: train_loss -0.5381 
2025-03-13 10:22:29.133105: val_loss -0.5185 
2025-03-13 10:22:29.137115: Pseudo dice [np.float32(0.7467), np.float32(0.4114)] 
2025-03-13 10:22:29.140622: Epoch time: 40.79 s 
2025-03-13 10:22:29.144128: Yayy! New best EMA pseudo Dice: 0.5558000206947327 
2025-03-13 10:22:29.823680:  
2025-03-13 10:22:29.829196: Epoch 57 
2025-03-13 10:22:29.832704: Current learning rate: 0.00468 
2025-03-13 10:23:10.620734: train_loss -0.5484 
2025-03-13 10:23:10.626776: val_loss -0.524 
2025-03-13 10:23:10.630383: Pseudo dice [np.float32(0.7192), np.float32(0.4401)] 
2025-03-13 10:23:10.633407: Epoch time: 40.8 s 
2025-03-13 10:23:10.636439: Yayy! New best EMA pseudo Dice: 0.5580999851226807 
2025-03-13 10:23:11.309919:  
2025-03-13 10:23:11.315496: Epoch 58 
2025-03-13 10:23:11.318516: Current learning rate: 0.00458 
2025-03-13 10:23:52.094963: train_loss -0.5276 
2025-03-13 10:23:52.100489: val_loss -0.5405 
2025-03-13 10:23:52.104499: Pseudo dice [np.float32(0.7314), np.float32(0.5047)] 
2025-03-13 10:23:52.107007: Epoch time: 40.79 s 
2025-03-13 10:23:52.110524: Yayy! New best EMA pseudo Dice: 0.5641000270843506 
2025-03-13 10:23:52.789531:  
2025-03-13 10:23:52.794605: Epoch 59 
2025-03-13 10:23:52.798639: Current learning rate: 0.00448 
2025-03-13 10:24:33.563267: train_loss -0.5443 
2025-03-13 10:24:33.568815: val_loss -0.5406 
2025-03-13 10:24:33.572343: Pseudo dice [np.float32(0.7432), np.float32(0.3753)] 
2025-03-13 10:24:33.575881: Epoch time: 40.77 s 
2025-03-13 10:24:34.102957:  
2025-03-13 10:24:34.109016: Epoch 60 
2025-03-13 10:24:34.112059: Current learning rate: 0.00438 
2025-03-13 10:25:14.887820: train_loss -0.5445 
2025-03-13 10:25:14.893881: val_loss -0.5472 
2025-03-13 10:25:14.897913: Pseudo dice [np.float32(0.7287), np.float32(0.4844)] 
2025-03-13 10:25:14.900944: Epoch time: 40.79 s 
2025-03-13 10:25:14.904461: Yayy! New best EMA pseudo Dice: 0.5679000020027161 
2025-03-13 10:25:15.720500:  
2025-03-13 10:25:15.726081: Epoch 61 
2025-03-13 10:25:15.728618: Current learning rate: 0.00429 
2025-03-13 10:25:56.489464: train_loss -0.5417 
2025-03-13 10:25:56.495014: val_loss -0.5132 
2025-03-13 10:25:56.498523: Pseudo dice [np.float32(0.7452), np.float32(0.4032)] 
2025-03-13 10:25:56.502034: Epoch time: 40.77 s 
2025-03-13 10:25:56.505042: Yayy! New best EMA pseudo Dice: 0.5685999989509583 
2025-03-13 10:25:57.193435:  
2025-03-13 10:25:57.199474: Epoch 62 
2025-03-13 10:25:57.201979: Current learning rate: 0.00419 
2025-03-13 10:26:37.957221: train_loss -0.562 
2025-03-13 10:26:37.963237: val_loss -0.4933 
2025-03-13 10:26:37.967246: Pseudo dice [np.float32(0.7431), np.float32(0.3608)] 
2025-03-13 10:26:37.969752: Epoch time: 40.76 s 
2025-03-13 10:26:38.502682:  
2025-03-13 10:26:38.508235: Epoch 63 
2025-03-13 10:26:38.510774: Current learning rate: 0.00409 
2025-03-13 10:27:19.270074: train_loss -0.5626 
2025-03-13 10:27:19.276590: val_loss -0.5759 
2025-03-13 10:27:19.280095: Pseudo dice [np.float32(0.7682), np.float32(0.5748)] 
2025-03-13 10:27:19.283101: Epoch time: 40.77 s 
2025-03-13 10:27:19.286613: Yayy! New best EMA pseudo Dice: 0.5774000287055969 
2025-03-13 10:27:19.978505:  
2025-03-13 10:27:19.984618: Epoch 64 
2025-03-13 10:27:19.987130: Current learning rate: 0.00399 
2025-03-13 10:28:00.764767: train_loss -0.565 
2025-03-13 10:28:00.772797: val_loss -0.4553 
2025-03-13 10:28:00.776305: Pseudo dice [np.float32(0.7055), np.float32(0.2888)] 
2025-03-13 10:28:00.779812: Epoch time: 40.79 s 
2025-03-13 10:28:01.305091:  
2025-03-13 10:28:01.310102: Epoch 65 
2025-03-13 10:28:01.313610: Current learning rate: 0.00389 
2025-03-13 10:28:42.098476: train_loss -0.5614 
2025-03-13 10:28:42.104560: val_loss -0.5291 
2025-03-13 10:28:42.107070: Pseudo dice [np.float32(0.7632), np.float32(0.4156)] 
2025-03-13 10:28:42.110588: Epoch time: 40.79 s 
2025-03-13 10:28:42.642502:  
2025-03-13 10:28:42.648026: Epoch 66 
2025-03-13 10:28:42.650536: Current learning rate: 0.00379 
2025-03-13 10:29:23.417386: train_loss -0.5411 
2025-03-13 10:29:23.422938: val_loss -0.5418 
2025-03-13 10:29:23.426485: Pseudo dice [np.float32(0.7276), np.float32(0.4849)] 
2025-03-13 10:29:23.429497: Epoch time: 40.78 s 
2025-03-13 10:29:23.959563:  
2025-03-13 10:29:23.965619: Epoch 67 
2025-03-13 10:29:23.968127: Current learning rate: 0.00369 
2025-03-13 10:30:04.745362: train_loss -0.5666 
2025-03-13 10:30:04.751876: val_loss -0.4656 
2025-03-13 10:30:04.755393: Pseudo dice [np.float32(0.7074), np.float32(0.3515)] 
2025-03-13 10:30:04.758903: Epoch time: 40.79 s 
2025-03-13 10:30:05.434998:  
2025-03-13 10:30:05.440058: Epoch 68 
2025-03-13 10:30:05.443618: Current learning rate: 0.00359 
2025-03-13 10:30:46.219887: train_loss -0.5882 
2025-03-13 10:30:46.226437: val_loss -0.5351 
2025-03-13 10:30:46.230104: Pseudo dice [np.float32(0.7636), np.float32(0.3322)] 
2025-03-13 10:30:46.234735: Epoch time: 40.79 s 
2025-03-13 10:30:46.769876:  
2025-03-13 10:30:46.775424: Epoch 69 
2025-03-13 10:30:46.778477: Current learning rate: 0.00349 
2025-03-13 10:31:27.559914: train_loss -0.56 
2025-03-13 10:31:27.566426: val_loss -0.5307 
2025-03-13 10:31:27.569935: Pseudo dice [np.float32(0.7487), np.float32(0.3596)] 
2025-03-13 10:31:27.573441: Epoch time: 40.79 s 
2025-03-13 10:31:28.125809:  
2025-03-13 10:31:28.131821: Epoch 70 
2025-03-13 10:31:28.134326: Current learning rate: 0.00338 
2025-03-13 10:32:08.922771: train_loss -0.5729 
2025-03-13 10:32:08.929285: val_loss -0.5185 
2025-03-13 10:32:08.932791: Pseudo dice [np.float32(0.7361), np.float32(0.3601)] 
2025-03-13 10:32:08.935799: Epoch time: 40.8 s 
2025-03-13 10:32:09.474161:  
2025-03-13 10:32:09.479720: Epoch 71 
2025-03-13 10:32:09.483282: Current learning rate: 0.00328 
2025-03-13 10:32:50.270487: train_loss -0.5765 
2025-03-13 10:32:50.276565: val_loss -0.5114 
2025-03-13 10:32:50.278721: Pseudo dice [np.float32(0.728), np.float32(0.4016)] 
2025-03-13 10:32:50.282746: Epoch time: 40.8 s 
2025-03-13 10:32:50.825309:  
2025-03-13 10:32:50.830946: Epoch 72 
2025-03-13 10:32:50.834496: Current learning rate: 0.00318 
2025-03-13 10:33:31.622682: train_loss -0.5665 
2025-03-13 10:33:31.629252: val_loss -0.5194 
2025-03-13 10:33:31.632812: Pseudo dice [np.float32(0.7892), np.float32(0.368)] 
2025-03-13 10:33:31.635839: Epoch time: 40.8 s 
2025-03-13 10:33:32.170468:  
2025-03-13 10:33:32.175480: Epoch 73 
2025-03-13 10:33:32.178989: Current learning rate: 0.00308 
2025-03-13 10:34:12.956463: train_loss -0.5712 
2025-03-13 10:34:12.962651: val_loss -0.5621 
2025-03-13 10:34:12.965672: Pseudo dice [np.float32(0.7515), np.float32(0.4733)] 
2025-03-13 10:34:12.969217: Epoch time: 40.79 s 
2025-03-13 10:34:13.506918:  
2025-03-13 10:34:13.512504: Epoch 74 
2025-03-13 10:34:13.515045: Current learning rate: 0.00297 
2025-03-13 10:34:54.301902: train_loss -0.6038 
2025-03-13 10:34:54.307919: val_loss -0.5603 
2025-03-13 10:34:54.311426: Pseudo dice [np.float32(0.727), np.float32(0.4629)] 
2025-03-13 10:34:54.314437: Epoch time: 40.8 s 
2025-03-13 10:34:54.859121:  
2025-03-13 10:34:54.864151: Epoch 75 
2025-03-13 10:34:54.867668: Current learning rate: 0.00287 
2025-03-13 10:35:35.665670: train_loss -0.5868 
2025-03-13 10:35:35.671236: val_loss -0.5535 
2025-03-13 10:35:35.673741: Pseudo dice [np.float32(0.7558), np.float32(0.4551)] 
2025-03-13 10:35:35.677254: Epoch time: 40.81 s 
2025-03-13 10:35:36.356247:  
2025-03-13 10:35:36.361773: Epoch 76 
2025-03-13 10:35:36.365296: Current learning rate: 0.00277 
2025-03-13 10:36:17.135173: train_loss -0.5808 
2025-03-13 10:36:17.142220: val_loss -0.5803 
2025-03-13 10:36:17.144842: Pseudo dice [np.float32(0.7718), np.float32(0.5385)] 
2025-03-13 10:36:17.148378: Epoch time: 40.78 s 
2025-03-13 10:36:17.151420: Yayy! New best EMA pseudo Dice: 0.5842999815940857 
2025-03-13 10:36:17.847068:  
2025-03-13 10:36:17.852579: Epoch 77 
2025-03-13 10:36:17.856086: Current learning rate: 0.00266 
2025-03-13 10:36:58.637542: train_loss -0.5986 
2025-03-13 10:36:58.643077: val_loss -0.5624 
2025-03-13 10:36:58.647228: Pseudo dice [np.float32(0.7412), np.float32(0.5428)] 
2025-03-13 10:36:58.649764: Epoch time: 40.79 s 
2025-03-13 10:36:58.652800: Yayy! New best EMA pseudo Dice: 0.5900999903678894 
2025-03-13 10:36:59.355187:  
2025-03-13 10:36:59.362774: Epoch 78 
2025-03-13 10:36:59.365842: Current learning rate: 0.00256 
2025-03-13 10:37:40.168506: train_loss -0.6047 
2025-03-13 10:37:40.175020: val_loss -0.5657 
2025-03-13 10:37:40.178530: Pseudo dice [np.float32(0.7404), np.float32(0.5221)] 
2025-03-13 10:37:40.182538: Epoch time: 40.81 s 
2025-03-13 10:37:40.186045: Yayy! New best EMA pseudo Dice: 0.5942000150680542 
2025-03-13 10:37:40.930189:  
2025-03-13 10:37:40.936233: Epoch 79 
2025-03-13 10:37:40.939342: Current learning rate: 0.00245 
2025-03-13 10:38:21.727793: train_loss -0.5781 
2025-03-13 10:38:21.734372: val_loss -0.544 
2025-03-13 10:38:21.737407: Pseudo dice [np.float32(0.7642), np.float32(0.4294)] 
2025-03-13 10:38:21.740950: Epoch time: 40.8 s 
2025-03-13 10:38:21.743995: Yayy! New best EMA pseudo Dice: 0.5945000052452087 
2025-03-13 10:38:22.442415:  
2025-03-13 10:38:22.447968: Epoch 80 
2025-03-13 10:38:22.450504: Current learning rate: 0.00235 
2025-03-13 10:39:03.230249: train_loss -0.5995 
2025-03-13 10:39:03.236774: val_loss -0.58 
2025-03-13 10:39:03.241284: Pseudo dice [np.float32(0.7494), np.float32(0.5542)] 
2025-03-13 10:39:03.244293: Epoch time: 40.79 s 
2025-03-13 10:39:03.247801: Yayy! New best EMA pseudo Dice: 0.6001999974250793 
2025-03-13 10:39:03.945978:  
2025-03-13 10:39:03.952043: Epoch 81 
2025-03-13 10:39:03.955086: Current learning rate: 0.00224 
2025-03-13 10:39:44.711270: train_loss -0.6186 
2025-03-13 10:39:44.716808: val_loss -0.5186 
2025-03-13 10:39:44.720317: Pseudo dice [np.float32(0.743), np.float32(0.4273)] 
2025-03-13 10:39:44.723830: Epoch time: 40.77 s 
2025-03-13 10:39:45.273255:  
2025-03-13 10:39:45.278775: Epoch 82 
2025-03-13 10:39:45.281285: Current learning rate: 0.00214 
2025-03-13 10:40:26.062308: train_loss -0.6088 
2025-03-13 10:40:26.069908: val_loss -0.535 
2025-03-13 10:40:26.074918: Pseudo dice [np.float32(0.7808), np.float32(0.4257)] 
2025-03-13 10:40:26.078426: Epoch time: 40.79 s 
2025-03-13 10:40:26.603658:  
2025-03-13 10:40:26.609699: Epoch 83 
2025-03-13 10:40:26.612756: Current learning rate: 0.00203 
2025-03-13 10:41:07.376003: train_loss -0.6193 
2025-03-13 10:41:07.383553: val_loss -0.5954 
2025-03-13 10:41:07.386058: Pseudo dice [np.float32(0.7651), np.float32(0.5338)] 
2025-03-13 10:41:07.389565: Epoch time: 40.77 s 
2025-03-13 10:41:07.393076: Yayy! New best EMA pseudo Dice: 0.604200005531311 
2025-03-13 10:41:08.211708:  
2025-03-13 10:41:08.219227: Epoch 84 
2025-03-13 10:41:08.222236: Current learning rate: 0.00192 
2025-03-13 10:41:48.998695: train_loss -0.6138 
2025-03-13 10:41:49.005212: val_loss -0.5515 
2025-03-13 10:41:49.009222: Pseudo dice [np.float32(0.7526), np.float32(0.4944)] 
2025-03-13 10:41:49.012262: Epoch time: 40.79 s 
2025-03-13 10:41:49.016797: Yayy! New best EMA pseudo Dice: 0.6061000227928162 
2025-03-13 10:41:49.690393:  
2025-03-13 10:41:49.695975: Epoch 85 
2025-03-13 10:41:49.700039: Current learning rate: 0.00181 
2025-03-13 10:42:30.470243: train_loss -0.6196 
2025-03-13 10:42:30.476259: val_loss -0.5237 
2025-03-13 10:42:30.479765: Pseudo dice [np.float32(0.769), np.float32(0.4205)] 
2025-03-13 10:42:30.482776: Epoch time: 40.78 s 
2025-03-13 10:42:30.994844:  
2025-03-13 10:42:31.000901: Epoch 86 
2025-03-13 10:42:31.003409: Current learning rate: 0.0017 
2025-03-13 10:43:11.772340: train_loss -0.6102 
2025-03-13 10:43:11.779926: val_loss -0.601 
2025-03-13 10:43:11.782936: Pseudo dice [np.float32(0.7728), np.float32(0.5403)] 
2025-03-13 10:43:11.786445: Epoch time: 40.78 s 
2025-03-13 10:43:11.789950: Yayy! New best EMA pseudo Dice: 0.6100999712944031 
2025-03-13 10:43:12.457525:  
2025-03-13 10:43:12.463631: Epoch 87 
2025-03-13 10:43:12.467139: Current learning rate: 0.00159 
2025-03-13 10:43:53.247333: train_loss -0.6158 
2025-03-13 10:43:53.252865: val_loss -0.5558 
2025-03-13 10:43:53.256378: Pseudo dice [np.float32(0.734), np.float32(0.4766)] 
2025-03-13 10:43:53.259926: Epoch time: 40.79 s 
2025-03-13 10:43:53.778041:  
2025-03-13 10:43:53.783613: Epoch 88 
2025-03-13 10:43:53.786687: Current learning rate: 0.00148 
2025-03-13 10:44:34.563123: train_loss -0.6066 
2025-03-13 10:44:34.569199: val_loss -0.5487 
2025-03-13 10:44:34.572731: Pseudo dice [np.float32(0.7764), np.float32(0.4829)] 
2025-03-13 10:44:34.575764: Epoch time: 40.79 s 
2025-03-13 10:44:34.578284: Yayy! New best EMA pseudo Dice: 0.6115999817848206 
2025-03-13 10:44:35.245094:  
2025-03-13 10:44:35.250662: Epoch 89 
2025-03-13 10:44:35.254192: Current learning rate: 0.00137 
2025-03-13 10:45:16.014293: train_loss -0.6382 
2025-03-13 10:45:16.020848: val_loss -0.5319 
2025-03-13 10:45:16.025002: Pseudo dice [np.float32(0.7603), np.float32(0.4053)] 
2025-03-13 10:45:16.028065: Epoch time: 40.77 s 
2025-03-13 10:45:16.571883:  
2025-03-13 10:45:16.577439: Epoch 90 
2025-03-13 10:45:16.581491: Current learning rate: 0.00126 
2025-03-13 10:45:57.353998: train_loss -0.618 
2025-03-13 10:45:57.360010: val_loss -0.5743 
2025-03-13 10:45:57.364019: Pseudo dice [np.float32(0.7838), np.float32(0.4759)] 
2025-03-13 10:45:57.367531: Epoch time: 40.78 s 
2025-03-13 10:45:57.882095:  
2025-03-13 10:45:57.887204: Epoch 91 
2025-03-13 10:45:57.890745: Current learning rate: 0.00115 
2025-03-13 10:46:38.656604: train_loss -0.6348 
2025-03-13 10:46:38.662638: val_loss -0.5944 
2025-03-13 10:46:38.665200: Pseudo dice [np.float32(0.7507), np.float32(0.5489)] 
2025-03-13 10:46:38.669243: Epoch time: 40.78 s 
2025-03-13 10:46:38.671775: Yayy! New best EMA pseudo Dice: 0.614799976348877 
2025-03-13 10:46:39.489213:  
2025-03-13 10:46:39.494236: Epoch 92 
2025-03-13 10:46:39.498169: Current learning rate: 0.00103 
2025-03-13 10:47:20.272597: train_loss -0.6375 
2025-03-13 10:47:20.279142: val_loss -0.5894 
2025-03-13 10:47:20.282684: Pseudo dice [np.float32(0.7728), np.float32(0.4564)] 
2025-03-13 10:47:20.285240: Epoch time: 40.78 s 
2025-03-13 10:47:20.794879:  
2025-03-13 10:47:20.799930: Epoch 93 
2025-03-13 10:47:20.802975: Current learning rate: 0.00091 
2025-03-13 10:48:01.564812: train_loss -0.6245 
2025-03-13 10:48:01.571885: val_loss -0.5931 
2025-03-13 10:48:01.575899: Pseudo dice [np.float32(0.7671), np.float32(0.5044)] 
2025-03-13 10:48:01.578405: Epoch time: 40.77 s 
2025-03-13 10:48:01.582415: Yayy! New best EMA pseudo Dice: 0.6168000102043152 
2025-03-13 10:48:02.266064:  
2025-03-13 10:48:02.271075: Epoch 94 
2025-03-13 10:48:02.274587: Current learning rate: 0.00079 
2025-03-13 10:48:43.031590: train_loss -0.6352 
2025-03-13 10:48:43.036602: val_loss -0.5597 
2025-03-13 10:48:43.041111: Pseudo dice [np.float32(0.776), np.float32(0.4587)] 
2025-03-13 10:48:43.044123: Epoch time: 40.77 s 
2025-03-13 10:48:43.047632: Yayy! New best EMA pseudo Dice: 0.6169000267982483 
2025-03-13 10:48:43.725653:  
2025-03-13 10:48:43.731774: Epoch 95 
2025-03-13 10:48:43.734840: Current learning rate: 0.00067 
2025-03-13 10:49:24.495594: train_loss -0.653 
2025-03-13 10:49:24.501239: val_loss -0.5489 
2025-03-13 10:49:24.504321: Pseudo dice [np.float32(0.7673), np.float32(0.4482)] 
2025-03-13 10:49:24.508361: Epoch time: 40.77 s 
2025-03-13 10:49:25.024962:  
2025-03-13 10:49:25.030986: Epoch 96 
2025-03-13 10:49:25.033501: Current learning rate: 0.00055 
2025-03-13 10:50:05.793039: train_loss -0.6458 
2025-03-13 10:50:05.799193: val_loss -0.5794 
2025-03-13 10:50:05.803765: Pseudo dice [np.float32(0.7661), np.float32(0.479)] 
2025-03-13 10:50:05.806319: Epoch time: 40.77 s 
2025-03-13 10:50:06.328504:  
2025-03-13 10:50:06.333576: Epoch 97 
2025-03-13 10:50:06.337672: Current learning rate: 0.00043 
2025-03-13 10:50:47.113675: train_loss -0.6487 
2025-03-13 10:50:47.119365: val_loss -0.5747 
2025-03-13 10:50:47.123743: Pseudo dice [np.float32(0.7861), np.float32(0.4768)] 
2025-03-13 10:50:47.126751: Epoch time: 40.79 s 
2025-03-13 10:50:47.130260: Yayy! New best EMA pseudo Dice: 0.6180999875068665 
2025-03-13 10:50:47.814201:  
2025-03-13 10:50:47.820288: Epoch 98 
2025-03-13 10:50:47.822300: Current learning rate: 0.0003 
2025-03-13 10:51:28.578284: train_loss -0.6507 
2025-03-13 10:51:28.583834: val_loss -0.5479 
2025-03-13 10:51:28.587858: Pseudo dice [np.float32(0.7702), np.float32(0.4008)] 
2025-03-13 10:51:28.590869: Epoch time: 40.76 s 
2025-03-13 10:51:29.113523:  
2025-03-13 10:51:29.119056: Epoch 99 
2025-03-13 10:51:29.122598: Current learning rate: 0.00016 
2025-03-13 10:52:09.879103: train_loss -0.6409 
2025-03-13 10:52:09.886217: val_loss -0.5399 
2025-03-13 10:52:09.889275: Pseudo dice [np.float32(0.7974), np.float32(0.4577)] 
2025-03-13 10:52:09.892804: Epoch time: 40.77 s 
2025-03-13 10:52:10.756490: Training done. 
2025-03-13 10:52:10.782495: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-03-13 10:52:10.788493: The split file contains 5 splits. 
2025-03-13 10:52:10.794493: Desired fold for training: 0 
2025-03-13 10:52:10.799493: This split has 224 training and 57 validation cases. 
2025-03-13 10:52:10.804492: predicting pancreas_021 
2025-03-13 10:52:10.810491: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-03-13 10:52:23.194723: predicting pancreas_024 
2025-03-13 10:52:23.212723: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-03-13 10:52:37.786685: predicting pancreas_035 
2025-03-13 10:52:37.807685: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-03-13 10:52:42.766489: predicting pancreas_040 
2025-03-13 10:52:42.779489: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-03-13 10:52:54.438409: predicting pancreas_042 
2025-03-13 10:52:54.458409: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-03-13 10:53:09.024777: predicting pancreas_056 
2025-03-13 10:53:09.042777: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-03-13 10:53:20.702303: predicting pancreas_067 
2025-03-13 10:53:20.719303: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-03-13 10:53:35.297414: predicting pancreas_075 
2025-03-13 10:53:35.318415: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-03-13 10:53:41.188116: predicting pancreas_086 
2025-03-13 10:53:41.202116: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-03-13 10:53:50.313347: predicting pancreas_089 
2025-03-13 10:53:50.326347: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-03-13 10:54:01.984149: predicting pancreas_092 
2025-03-13 10:54:01.999149: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-03-13 10:54:28.194796: predicting pancreas_094 
2025-03-13 10:54:28.224796: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-03-13 10:54:39.896696: predicting pancreas_095 
2025-03-13 10:54:39.912695: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-03-13 10:54:51.598864: predicting pancreas_098 
2025-03-13 10:54:51.613864: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-03-13 10:55:23.450511: predicting pancreas_109 
2025-03-13 10:55:23.482512: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-03-13 10:55:35.202766: predicting pancreas_110 
2025-03-13 10:55:35.224767: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-03-13 10:55:53.464606: predicting pancreas_114 
2025-03-13 10:55:53.485605: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-03-13 10:56:05.180141: predicting pancreas_119 
2025-03-13 10:56:05.198142: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-03-13 10:56:23.393709: predicting pancreas_138 
2025-03-13 10:56:23.414707: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-03-13 10:56:41.686918: predicting pancreas_145 
2025-03-13 10:56:41.704917: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-03-13 10:56:59.941678: predicting pancreas_148 
2025-03-13 10:56:59.961679: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-03-13 10:57:11.655586: predicting pancreas_169 
2025-03-13 10:57:11.671587: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-03-13 10:57:23.348954: predicting pancreas_170 
2025-03-13 10:57:23.365956: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-03-13 10:57:37.950103: predicting pancreas_172 
2025-03-13 10:57:37.968103: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-03-13 10:57:49.679053: predicting pancreas_175 
2025-03-13 10:57:49.693053: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-03-13 10:58:01.362389: predicting pancreas_180 
2025-03-13 10:58:01.378389: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-03-13 10:58:13.047851: predicting pancreas_191 
2025-03-13 10:58:13.064851: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-03-13 10:58:18.952267: predicting pancreas_193 
2025-03-13 10:58:18.965266: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-03-13 10:58:33.547944: predicting pancreas_212 
2025-03-13 10:58:33.567944: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-03-13 10:58:45.275064: predicting pancreas_215 
2025-03-13 10:58:45.293064: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-03-13 10:58:56.979208: predicting pancreas_222 
2025-03-13 10:58:56.994207: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-03-13 10:59:01.971109: predicting pancreas_235 
2025-03-13 10:59:01.984111: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-03-13 10:59:13.656899: predicting pancreas_241 
2025-03-13 10:59:13.673899: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-03-13 10:59:25.381532: predicting pancreas_242 
2025-03-13 10:59:25.402533: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-03-13 10:59:39.999462: predicting pancreas_244 
2025-03-13 10:59:40.017462: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-03-13 11:00:02.757663: predicting pancreas_246 
2025-03-13 11:00:02.778664: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-03-13 11:00:25.527389: predicting pancreas_247 
2025-03-13 11:00:25.551389: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-03-13 11:00:32.192340: predicting pancreas_264 
2025-03-13 11:00:32.207340: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-03-13 11:00:46.804005: predicting pancreas_265 
2025-03-13 11:00:46.822005: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-03-13 11:00:58.501913: predicting pancreas_266 
2025-03-13 11:00:58.517913: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-03-13 11:01:16.716674: predicting pancreas_267 
2025-03-13 11:01:16.739674: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-03-13 11:01:23.368842: predicting pancreas_275 
2025-03-13 11:01:23.385841: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-03-13 11:01:37.952436: predicting pancreas_279 
2025-03-13 11:01:37.967436: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-03-13 11:01:42.968436: predicting pancreas_287 
2025-03-13 11:01:42.981436: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-03-13 11:01:54.652455: predicting pancreas_301 
2025-03-13 11:01:54.668455: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-03-13 11:02:06.352988: predicting pancreas_323 
2025-03-13 11:02:06.372989: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-03-13 11:02:24.605562: predicting pancreas_336 
2025-03-13 11:02:24.628562: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-03-13 11:02:36.328399: predicting pancreas_344 
2025-03-13 11:02:36.347400: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-03-13 11:02:50.948792: predicting pancreas_351 
2025-03-13 11:02:50.965792: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-03-13 11:02:57.575171: predicting pancreas_354 
2025-03-13 11:02:57.590172: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-03-13 11:03:20.885753: predicting pancreas_372 
2025-03-13 11:03:20.915753: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-03-13 11:03:39.205283: predicting pancreas_377 
2025-03-13 11:03:39.225284: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-03-13 11:03:53.863239: predicting pancreas_387 
2025-03-13 11:03:53.882239: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-03-13 11:04:05.627070: predicting pancreas_391 
2025-03-13 11:04:05.648070: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-03-13 11:04:23.874223: predicting pancreas_392 
2025-03-13 11:04:23.896222: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-03-13 11:04:32.143284: predicting pancreas_410 
2025-03-13 11:04:32.159284: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-03-13 11:04:40.414660: predicting pancreas_412 
2025-03-13 11:04:40.430660: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-03-13 11:05:37.610680: Validation complete 
2025-03-13 11:05:37.616680: Mean Validation Dice:  0.6151783842157142 
