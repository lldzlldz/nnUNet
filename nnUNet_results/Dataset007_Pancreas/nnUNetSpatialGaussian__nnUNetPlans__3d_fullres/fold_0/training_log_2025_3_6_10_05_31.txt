
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-06 10:05:31.705405: do_dummy_2d_data_aug: True 
2025-03-06 10:05:31.747070: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-03-06 10:05:31.756073: The split file contains 5 splits. 
2025-03-06 10:05:31.758071: Desired fold for training: 0 
2025-03-06 10:05:31.761070: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-03-06 10:05:40.243929: unpacking dataset... 
2025-03-06 10:05:40.624140: unpacking done... 
2025-03-06 10:05:43.611362:  
2025-03-06 10:05:43.616383: Epoch 0 
2025-03-06 10:05:43.619889: Current learning rate: 0.01 
2025-03-06 10:07:13.400921: train_loss 0.1018 
2025-03-06 10:07:13.407467: val_loss 0.043 
2025-03-06 10:07:13.411585: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-03-06 10:07:13.414616: Epoch time: 89.79 s 
2025-03-06 10:07:13.417675: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-06 10:07:14.060428:  
2025-03-06 10:07:14.065943: Epoch 1 
2025-03-06 10:07:14.069452: Current learning rate: 0.00991 
2025-03-06 10:08:35.298857: train_loss -0.0003 
2025-03-06 10:08:35.305371: val_loss -0.1197 
2025-03-06 10:08:35.308880: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-03-06 10:08:35.311386: Epoch time: 81.24 s 
2025-03-06 10:08:35.858092:  
2025-03-06 10:08:35.863103: Epoch 2 
2025-03-06 10:08:35.866612: Current learning rate: 0.00982 
2025-03-06 10:09:57.047006: train_loss -0.1618 
2025-03-06 10:09:57.053024: val_loss -0.2517 
2025-03-06 10:09:57.056039: Pseudo dice [np.float32(0.6141), np.float32(0.0)] 
2025-03-06 10:09:57.059552: Epoch time: 81.19 s 
2025-03-06 10:09:57.063061: Yayy! New best EMA pseudo Dice: 0.030700000002980232 
2025-03-06 10:09:57.820977:  
2025-03-06 10:09:57.826541: Epoch 3 
2025-03-06 10:09:57.829636: Current learning rate: 0.00973 
2025-03-06 10:11:19.046017: train_loss -0.2245 
2025-03-06 10:11:19.051533: val_loss -0.2927 
2025-03-06 10:11:19.055043: Pseudo dice [np.float32(0.6509), np.float32(0.0)] 
2025-03-06 10:11:19.058052: Epoch time: 81.23 s 
2025-03-06 10:11:19.061617: Yayy! New best EMA pseudo Dice: 0.06019999831914902 
2025-03-06 10:11:19.783662:  
2025-03-06 10:11:19.789207: Epoch 4 
2025-03-06 10:11:19.791723: Current learning rate: 0.00964 
2025-03-06 10:12:40.912324: train_loss -0.2543 
2025-03-06 10:12:40.917339: val_loss -0.2951 
2025-03-06 10:12:40.921349: Pseudo dice [np.float32(0.6369), np.float32(0.0)] 
2025-03-06 10:12:40.924860: Epoch time: 81.13 s 
2025-03-06 10:12:40.927368: Yayy! New best EMA pseudo Dice: 0.0860000029206276 
2025-03-06 10:12:41.796862:  
2025-03-06 10:12:41.802454: Epoch 5 
2025-03-06 10:12:41.805501: Current learning rate: 0.00955 
2025-03-06 10:14:02.947061: train_loss -0.296 
2025-03-06 10:14:02.953578: val_loss -0.3586 
2025-03-06 10:14:02.957087: Pseudo dice [np.float32(0.6925), np.float32(0.0)] 
2025-03-06 10:14:02.959595: Epoch time: 81.15 s 
2025-03-06 10:14:02.963604: Yayy! New best EMA pseudo Dice: 0.1120000034570694 
2025-03-06 10:14:03.708063:  
2025-03-06 10:14:03.713645: Epoch 6 
2025-03-06 10:14:03.716190: Current learning rate: 0.00946 
2025-03-06 10:15:24.918609: train_loss -0.3476 
2025-03-06 10:15:24.924628: val_loss -0.3978 
2025-03-06 10:15:24.927135: Pseudo dice [np.float32(0.6536), np.float32(0.3212)] 
2025-03-06 10:15:24.931145: Epoch time: 81.21 s 
2025-03-06 10:15:24.933684: Yayy! New best EMA pseudo Dice: 0.14959999918937683 
2025-03-06 10:15:25.678745:  
2025-03-06 10:15:25.684813: Epoch 7 
2025-03-06 10:15:25.687901: Current learning rate: 0.00937 
2025-03-06 10:16:46.870727: train_loss -0.3465 
2025-03-06 10:16:46.877251: val_loss -0.4117 
2025-03-06 10:16:46.880765: Pseudo dice [np.float32(0.6491), np.float32(0.2932)] 
2025-03-06 10:16:46.883275: Epoch time: 81.19 s 
2025-03-06 10:16:46.886782: Yayy! New best EMA pseudo Dice: 0.18170000612735748 
2025-03-06 10:16:47.607845:  
2025-03-06 10:16:47.613414: Epoch 8 
2025-03-06 10:16:47.615965: Current learning rate: 0.00928 
2025-03-06 10:18:08.856002: train_loss -0.3527 
2025-03-06 10:18:08.863521: val_loss -0.3626 
2025-03-06 10:18:08.866026: Pseudo dice [np.float32(0.6503), np.float32(0.1998)] 
2025-03-06 10:18:08.870041: Epoch time: 81.25 s 
2025-03-06 10:18:08.872550: Yayy! New best EMA pseudo Dice: 0.2061000019311905 
2025-03-06 10:18:09.612062:  
2025-03-06 10:18:09.617074: Epoch 9 
2025-03-06 10:18:09.620584: Current learning rate: 0.00919 
2025-03-06 10:19:30.820916: train_loss -0.4057 
2025-03-06 10:19:30.826931: val_loss -0.4233 
2025-03-06 10:19:30.830438: Pseudo dice [np.float32(0.6416), np.float32(0.3564)] 
2025-03-06 10:19:30.833447: Epoch time: 81.21 s 
2025-03-06 10:19:30.835952: Yayy! New best EMA pseudo Dice: 0.2354000061750412 
2025-03-06 10:19:31.557945:  
2025-03-06 10:19:31.563464: Epoch 10 
2025-03-06 10:19:31.566978: Current learning rate: 0.0091 
2025-03-06 10:20:52.759439: train_loss -0.4056 
2025-03-06 10:20:52.765954: val_loss -0.4577 
2025-03-06 10:20:52.769463: Pseudo dice [np.float32(0.6651), np.float32(0.3727)] 
2025-03-06 10:20:52.772968: Epoch time: 81.2 s 
2025-03-06 10:20:52.776019: Yayy! New best EMA pseudo Dice: 0.263700008392334 
2025-03-06 10:20:53.475535:  
2025-03-06 10:20:53.480639: Epoch 11 
2025-03-06 10:20:53.484163: Current learning rate: 0.009 
2025-03-06 10:22:14.708985: train_loss -0.4425 
2025-03-06 10:22:14.715500: val_loss -0.4653 
2025-03-06 10:22:14.719012: Pseudo dice [np.float32(0.6609), np.float32(0.3745)] 
2025-03-06 10:22:14.723025: Epoch time: 81.23 s 
2025-03-06 10:22:14.725531: Yayy! New best EMA pseudo Dice: 0.2890999913215637 
2025-03-06 10:22:15.462079:  
2025-03-06 10:22:15.467673: Epoch 12 
2025-03-06 10:22:15.470222: Current learning rate: 0.00891 
2025-03-06 10:23:37.063263: train_loss -0.4197 
2025-03-06 10:23:37.068778: val_loss -0.4612 
2025-03-06 10:23:37.072289: Pseudo dice [np.float32(0.7065), np.float32(0.3538)] 
2025-03-06 10:23:37.074797: Epoch time: 81.6 s 
2025-03-06 10:23:37.078302: Yayy! New best EMA pseudo Dice: 0.3131999969482422 
2025-03-06 10:23:37.963661:  
2025-03-06 10:23:37.969223: Epoch 13 
2025-03-06 10:23:37.972849: Current learning rate: 0.00882 
2025-03-06 10:24:59.174030: train_loss -0.472 
2025-03-06 10:24:59.179543: val_loss -0.4671 
2025-03-06 10:24:59.183052: Pseudo dice [np.float32(0.7018), np.float32(0.3507)] 
2025-03-06 10:24:59.185561: Epoch time: 81.21 s 
2025-03-06 10:24:59.189068: Yayy! New best EMA pseudo Dice: 0.3345000147819519 
2025-03-06 10:24:59.926925:  
2025-03-06 10:24:59.931524: Epoch 14 
2025-03-06 10:24:59.935587: Current learning rate: 0.00873 
2025-03-06 10:26:21.110594: train_loss -0.4752 
2025-03-06 10:26:21.116110: val_loss -0.4805 
2025-03-06 10:26:21.119621: Pseudo dice [np.float32(0.7367), np.float32(0.3046)] 
2025-03-06 10:26:21.123636: Epoch time: 81.18 s 
2025-03-06 10:26:21.126144: Yayy! New best EMA pseudo Dice: 0.3531000018119812 
2025-03-06 10:26:21.860545:  
2025-03-06 10:26:21.866604: Epoch 15 
2025-03-06 10:26:21.869672: Current learning rate: 0.00864 
2025-03-06 10:27:43.045494: train_loss -0.4798 
2025-03-06 10:27:43.052068: val_loss -0.4872 
2025-03-06 10:27:43.055722: Pseudo dice [np.float32(0.7263), np.float32(0.3792)] 
2025-03-06 10:27:43.058812: Epoch time: 81.19 s 
2025-03-06 10:27:43.060831: Yayy! New best EMA pseudo Dice: 0.37310001254081726 
2025-03-06 10:27:43.908441:  
2025-03-06 10:27:43.913453: Epoch 16 
2025-03-06 10:27:43.916965: Current learning rate: 0.00855 
2025-03-06 10:29:05.185366: train_loss -0.5083 
2025-03-06 10:29:05.190880: val_loss -0.5265 
2025-03-06 10:29:05.194389: Pseudo dice [np.float32(0.7417), np.float32(0.3758)] 
2025-03-06 10:29:05.198401: Epoch time: 81.28 s 
2025-03-06 10:29:05.200905: Yayy! New best EMA pseudo Dice: 0.39169999957084656 
2025-03-06 10:29:05.974025:  
2025-03-06 10:29:05.979085: Epoch 17 
2025-03-06 10:29:05.982635: Current learning rate: 0.00846 
2025-03-06 10:30:27.220781: train_loss -0.5095 
2025-03-06 10:30:27.226796: val_loss -0.5179 
2025-03-06 10:30:27.230808: Pseudo dice [np.float32(0.7186), np.float32(0.4479)] 
2025-03-06 10:30:27.233313: Epoch time: 81.25 s 
2025-03-06 10:30:27.236822: Yayy! New best EMA pseudo Dice: 0.4108000099658966 
2025-03-06 10:30:28.002028:  
2025-03-06 10:30:28.006061: Epoch 18 
2025-03-06 10:30:28.009571: Current learning rate: 0.00836 
2025-03-06 10:31:49.208820: train_loss -0.538 
2025-03-06 10:31:49.215339: val_loss -0.5034 
2025-03-06 10:31:49.218856: Pseudo dice [np.float32(0.7299), np.float32(0.3602)] 
2025-03-06 10:31:49.222868: Epoch time: 81.21 s 
2025-03-06 10:31:49.226378: Yayy! New best EMA pseudo Dice: 0.42419999837875366 
2025-03-06 10:31:49.988705:  
2025-03-06 10:31:49.992721: Epoch 19 
2025-03-06 10:31:49.996739: Current learning rate: 0.00827 
2025-03-06 10:33:11.197449: train_loss -0.505 
2025-03-06 10:33:11.204076: val_loss -0.4669 
2025-03-06 10:33:11.207585: Pseudo dice [np.float32(0.7211), np.float32(0.3487)] 
2025-03-06 10:33:11.211090: Epoch time: 81.21 s 
2025-03-06 10:33:11.214099: Yayy! New best EMA pseudo Dice: 0.43529999256134033 
2025-03-06 10:33:11.954533:  
2025-03-06 10:33:11.961049: Epoch 20 
2025-03-06 10:33:11.964559: Current learning rate: 0.00818 
2025-03-06 10:34:33.175714: train_loss -0.5365 
2025-03-06 10:34:33.180727: val_loss -0.503 
2025-03-06 10:34:33.184243: Pseudo dice [np.float32(0.7366), np.float32(0.2836)] 
2025-03-06 10:34:33.187309: Epoch time: 81.22 s 
2025-03-06 10:34:33.189861: Yayy! New best EMA pseudo Dice: 0.44279998540878296 
2025-03-06 10:34:34.076325:  
2025-03-06 10:34:34.082368: Epoch 21 
2025-03-06 10:34:34.085422: Current learning rate: 0.00809 
2025-03-06 10:35:55.325378: train_loss -0.5349 
2025-03-06 10:35:55.331398: val_loss -0.5307 
2025-03-06 10:35:55.335416: Pseudo dice [np.float32(0.7246), np.float32(0.4386)] 
2025-03-06 10:35:55.337921: Epoch time: 81.25 s 
2025-03-06 10:35:55.341433: Yayy! New best EMA pseudo Dice: 0.45669999718666077 
2025-03-06 10:35:56.069688:  
2025-03-06 10:35:56.075763: Epoch 22 
2025-03-06 10:35:56.079275: Current learning rate: 0.008 
2025-03-06 10:37:17.291658: train_loss -0.5208 
2025-03-06 10:37:17.297678: val_loss -0.5244 
2025-03-06 10:37:17.301687: Pseudo dice [np.float32(0.7279), np.float32(0.4185)] 
2025-03-06 10:37:17.304195: Epoch time: 81.22 s 
2025-03-06 10:37:17.307708: Yayy! New best EMA pseudo Dice: 0.4683000147342682 
2025-03-06 10:37:18.070842:  
2025-03-06 10:37:18.076877: Epoch 23 
2025-03-06 10:37:18.080781: Current learning rate: 0.0079 
2025-03-06 10:38:39.258414: train_loss -0.5516 
2025-03-06 10:38:39.263460: val_loss -0.5308 
2025-03-06 10:38:39.267471: Pseudo dice [np.float32(0.762), np.float32(0.39)] 
2025-03-06 10:38:39.269976: Epoch time: 81.19 s 
2025-03-06 10:38:39.273486: Yayy! New best EMA pseudo Dice: 0.47909998893737793 
2025-03-06 10:38:39.972263:  
2025-03-06 10:38:39.977276: Epoch 24 
2025-03-06 10:38:39.980786: Current learning rate: 0.00781 
2025-03-06 10:40:01.198837: train_loss -0.5804 
2025-03-06 10:40:01.202848: val_loss -0.5267 
2025-03-06 10:40:01.205355: Pseudo dice [np.float32(0.7703), np.float32(0.4047)] 
2025-03-06 10:40:01.208896: Epoch time: 81.23 s 
2025-03-06 10:40:01.212499: Yayy! New best EMA pseudo Dice: 0.48989999294281006 
2025-03-06 10:40:01.980775:  
2025-03-06 10:40:01.987371: Epoch 25 
2025-03-06 10:40:01.989914: Current learning rate: 0.00772 
2025-03-06 10:41:23.209075: train_loss -0.5775 
2025-03-06 10:41:23.215090: val_loss -0.5233 
2025-03-06 10:41:23.219097: Pseudo dice [np.float32(0.7427), np.float32(0.4288)] 
2025-03-06 10:41:23.221604: Epoch time: 81.23 s 
2025-03-06 10:41:23.225113: Yayy! New best EMA pseudo Dice: 0.49950000643730164 
2025-03-06 10:41:23.955371:  
2025-03-06 10:41:23.960408: Epoch 26 
2025-03-06 10:41:23.963440: Current learning rate: 0.00763 
2025-03-06 10:42:45.234905: train_loss -0.5797 
2025-03-06 10:42:45.242426: val_loss -0.5432 
2025-03-06 10:42:45.245934: Pseudo dice [np.float32(0.7458), np.float32(0.4409)] 
2025-03-06 10:42:45.248943: Epoch time: 81.28 s 
2025-03-06 10:42:45.252455: Yayy! New best EMA pseudo Dice: 0.508899986743927 
2025-03-06 10:42:45.985937:  
2025-03-06 10:42:45.991506: Epoch 27 
2025-03-06 10:42:45.995566: Current learning rate: 0.00753 
2025-03-06 10:44:07.190331: train_loss -0.5805 
2025-03-06 10:44:07.196347: val_loss -0.5159 
2025-03-06 10:44:07.199072: Pseudo dice [np.float32(0.7485), np.float32(0.3888)] 
2025-03-06 10:44:07.202587: Epoch time: 81.2 s 
2025-03-06 10:44:07.205801: Yayy! New best EMA pseudo Dice: 0.5149000287055969 
2025-03-06 10:44:07.921525:  
2025-03-06 10:44:07.927053: Epoch 28 
2025-03-06 10:44:07.930565: Current learning rate: 0.00744 
2025-03-06 10:45:29.106868: train_loss -0.5815 
2025-03-06 10:45:29.112388: val_loss -0.5527 
2025-03-06 10:45:29.115898: Pseudo dice [np.float32(0.7563), np.float32(0.4077)] 
2025-03-06 10:45:29.117917: Epoch time: 81.19 s 
2025-03-06 10:45:29.121948: Yayy! New best EMA pseudo Dice: 0.5216000080108643 
2025-03-06 10:45:30.006366:  
2025-03-06 10:45:30.011434: Epoch 29 
2025-03-06 10:45:30.014980: Current learning rate: 0.00735 
2025-03-06 10:46:51.174666: train_loss -0.6026 
2025-03-06 10:46:51.179677: val_loss -0.5323 
2025-03-06 10:46:51.183187: Pseudo dice [np.float32(0.7536), np.float32(0.371)] 
2025-03-06 10:46:51.187196: Epoch time: 81.17 s 
2025-03-06 10:46:51.190710: Yayy! New best EMA pseudo Dice: 0.5256999731063843 
2025-03-06 10:46:51.926775:  
2025-03-06 10:46:51.932787: Epoch 30 
2025-03-06 10:46:51.936296: Current learning rate: 0.00725 
2025-03-06 10:48:13.113134: train_loss -0.6212 
2025-03-06 10:48:13.119651: val_loss -0.5685 
2025-03-06 10:48:13.123160: Pseudo dice [np.float32(0.757), np.float32(0.4631)] 
2025-03-06 10:48:13.125668: Epoch time: 81.19 s 
2025-03-06 10:48:13.129201: Yayy! New best EMA pseudo Dice: 0.5340999960899353 
2025-03-06 10:48:13.880440:  
2025-03-06 10:48:13.885481: Epoch 31 
2025-03-06 10:48:13.888591: Current learning rate: 0.00716 
2025-03-06 10:49:35.105994: train_loss -0.6007 
2025-03-06 10:49:35.111515: val_loss -0.5208 
2025-03-06 10:49:35.115033: Pseudo dice [np.float32(0.765), np.float32(0.328)] 
2025-03-06 10:49:35.118545: Epoch time: 81.23 s 
2025-03-06 10:49:35.121602: Yayy! New best EMA pseudo Dice: 0.5353000164031982 
2025-03-06 10:49:35.868413:  
2025-03-06 10:49:35.874000: Epoch 32 
2025-03-06 10:49:35.876563: Current learning rate: 0.00707 
2025-03-06 10:50:57.153512: train_loss -0.6176 
2025-03-06 10:50:57.160106: val_loss -0.5307 
2025-03-06 10:50:57.163139: Pseudo dice [np.float32(0.7539), np.float32(0.3882)] 
2025-03-06 10:50:57.166167: Epoch time: 81.29 s 
2025-03-06 10:50:57.168690: Yayy! New best EMA pseudo Dice: 0.5389000177383423 
2025-03-06 10:50:57.913682:  
2025-03-06 10:50:57.919249: Epoch 33 
2025-03-06 10:50:57.923328: Current learning rate: 0.00697 
2025-03-06 10:52:19.114660: train_loss -0.6093 
2025-03-06 10:52:19.119675: val_loss -0.5981 
2025-03-06 10:52:19.123686: Pseudo dice [np.float32(0.7783), np.float32(0.5251)] 
2025-03-06 10:52:19.126192: Epoch time: 81.2 s 
2025-03-06 10:52:19.129704: Yayy! New best EMA pseudo Dice: 0.5501999855041504 
2025-03-06 10:52:19.863134:  
2025-03-06 10:52:19.869744: Epoch 34 
2025-03-06 10:52:19.872272: Current learning rate: 0.00688 
2025-03-06 10:53:41.044009: train_loss -0.6097 
2025-03-06 10:53:41.050025: val_loss -0.5825 
2025-03-06 10:53:41.053533: Pseudo dice [np.float32(0.7685), np.float32(0.4833)] 
2025-03-06 10:53:41.056542: Epoch time: 81.18 s 
2025-03-06 10:53:41.060052: Yayy! New best EMA pseudo Dice: 0.5577999949455261 
2025-03-06 10:53:41.797501:  
2025-03-06 10:53:41.803017: Epoch 35 
2025-03-06 10:53:41.805523: Current learning rate: 0.00679 
2025-03-06 10:55:02.972711: train_loss -0.6138 
2025-03-06 10:55:02.979227: val_loss -0.5741 
2025-03-06 10:55:02.981733: Pseudo dice [np.float32(0.7633), np.float32(0.4901)] 
2025-03-06 10:55:02.985243: Epoch time: 81.18 s 
2025-03-06 10:55:02.987751: Yayy! New best EMA pseudo Dice: 0.5647000074386597 
2025-03-06 10:55:03.731101:  
2025-03-06 10:55:03.736614: Epoch 36 
2025-03-06 10:55:03.739120: Current learning rate: 0.00669 
2025-03-06 10:56:24.944972: train_loss -0.6131 
2025-03-06 10:56:24.950534: val_loss -0.5554 
2025-03-06 10:56:24.954568: Pseudo dice [np.float32(0.7587), np.float32(0.4797)] 
2025-03-06 10:56:24.957627: Epoch time: 81.21 s 
2025-03-06 10:56:24.960151: Yayy! New best EMA pseudo Dice: 0.5701000094413757 
2025-03-06 10:56:25.844136:  
2025-03-06 10:56:25.849155: Epoch 37 
2025-03-06 10:56:25.853291: Current learning rate: 0.0066 
2025-03-06 10:57:47.095635: train_loss -0.6151 
2025-03-06 10:57:47.102150: val_loss -0.6026 
2025-03-06 10:57:47.105660: Pseudo dice [np.float32(0.7808), np.float32(0.5432)] 
2025-03-06 10:57:47.109166: Epoch time: 81.25 s 
2025-03-06 10:57:47.112177: Yayy! New best EMA pseudo Dice: 0.5792999863624573 
2025-03-06 10:57:47.935121:  
2025-03-06 10:57:47.940687: Epoch 38 
2025-03-06 10:57:47.944333: Current learning rate: 0.0065 
2025-03-06 10:59:09.129029: train_loss -0.6325 
2025-03-06 10:59:09.134042: val_loss -0.5993 
2025-03-06 10:59:09.138051: Pseudo dice [np.float32(0.775), np.float32(0.4681)] 
2025-03-06 10:59:09.141562: Epoch time: 81.19 s 
2025-03-06 10:59:09.144070: Yayy! New best EMA pseudo Dice: 0.5835000276565552 
2025-03-06 10:59:09.920489:  
2025-03-06 10:59:09.926056: Epoch 39 
2025-03-06 10:59:09.929647: Current learning rate: 0.00641 
2025-03-06 11:00:31.058953: train_loss -0.6437 
2025-03-06 11:00:31.065470: val_loss -0.5555 
2025-03-06 11:00:31.068976: Pseudo dice [np.float32(0.7662), np.float32(0.4491)] 
2025-03-06 11:00:31.071987: Epoch time: 81.14 s 
2025-03-06 11:00:31.075497: Yayy! New best EMA pseudo Dice: 0.5859000086784363 
2025-03-06 11:00:31.831056:  
2025-03-06 11:00:31.836573: Epoch 40 
2025-03-06 11:00:31.839078: Current learning rate: 0.00631 
2025-03-06 11:01:53.022419: train_loss -0.6351 
2025-03-06 11:01:53.027432: val_loss -0.5513 
2025-03-06 11:01:53.031443: Pseudo dice [np.float32(0.7481), np.float32(0.4756)] 
2025-03-06 11:01:53.033948: Epoch time: 81.19 s 
2025-03-06 11:01:53.037457: Yayy! New best EMA pseudo Dice: 0.5885000228881836 
2025-03-06 11:01:53.769680:  
2025-03-06 11:01:53.774691: Epoch 41 
2025-03-06 11:01:53.777197: Current learning rate: 0.00622 
2025-03-06 11:03:14.958707: train_loss -0.6265 
2025-03-06 11:03:14.964726: val_loss -0.5644 
2025-03-06 11:03:14.968759: Pseudo dice [np.float32(0.7613), np.float32(0.4849)] 
2025-03-06 11:03:14.971265: Epoch time: 81.19 s 
2025-03-06 11:03:14.974774: Yayy! New best EMA pseudo Dice: 0.5920000076293945 
2025-03-06 11:03:15.713314:  
2025-03-06 11:03:15.719851: Epoch 42 
2025-03-06 11:03:15.722361: Current learning rate: 0.00612 
2025-03-06 11:04:36.916045: train_loss -0.6429 
2025-03-06 11:04:36.923072: val_loss -0.5547 
2025-03-06 11:04:36.926131: Pseudo dice [np.float32(0.7559), np.float32(0.4427)] 
2025-03-06 11:04:36.928641: Epoch time: 81.2 s 
2025-03-06 11:04:36.932150: Yayy! New best EMA pseudo Dice: 0.5927000045776367 
2025-03-06 11:04:37.816518:  
2025-03-06 11:04:37.821530: Epoch 43 
2025-03-06 11:04:37.825042: Current learning rate: 0.00603 
2025-03-06 11:05:59.120486: train_loss -0.6228 
2025-03-06 11:05:59.128072: val_loss -0.5487 
2025-03-06 11:05:59.131617: Pseudo dice [np.float32(0.7776), np.float32(0.4406)] 
2025-03-06 11:05:59.134679: Epoch time: 81.31 s 
2025-03-06 11:05:59.137205: Yayy! New best EMA pseudo Dice: 0.5943999886512756 
2025-03-06 11:05:59.878304:  
2025-03-06 11:05:59.883851: Epoch 44 
2025-03-06 11:05:59.886878: Current learning rate: 0.00593 
2025-03-06 11:07:21.036855: train_loss -0.6377 
2025-03-06 11:07:21.043372: val_loss -0.5381 
2025-03-06 11:07:21.046881: Pseudo dice [np.float32(0.7573), np.float32(0.3495)] 
2025-03-06 11:07:21.049389: Epoch time: 81.16 s 
2025-03-06 11:07:21.748177:  
2025-03-06 11:07:21.753693: Epoch 45 
2025-03-06 11:07:21.756199: Current learning rate: 0.00584 
2025-03-06 11:08:42.964019: train_loss -0.665 
2025-03-06 11:08:42.970536: val_loss -0.5533 
2025-03-06 11:08:42.973041: Pseudo dice [np.float32(0.7859), np.float32(0.4098)] 
2025-03-06 11:08:42.976550: Epoch time: 81.22 s 
2025-03-06 11:08:43.549690:  
2025-03-06 11:08:43.555315: Epoch 46 
2025-03-06 11:08:43.558361: Current learning rate: 0.00574 
2025-03-06 11:10:04.762192: train_loss -0.6643 
2025-03-06 11:10:04.769710: val_loss -0.531 
2025-03-06 11:10:04.772724: Pseudo dice [np.float32(0.7633), np.float32(0.3448)] 
2025-03-06 11:10:04.776239: Epoch time: 81.21 s 
2025-03-06 11:10:05.391480:  
2025-03-06 11:10:05.396497: Epoch 47 
2025-03-06 11:10:05.400006: Current learning rate: 0.00565 
2025-03-06 11:11:26.641482: train_loss -0.6661 
2025-03-06 11:11:26.645490: val_loss -0.5419 
2025-03-06 11:11:26.649000: Pseudo dice [np.float32(0.7641), np.float32(0.4469)] 
2025-03-06 11:11:26.652507: Epoch time: 81.25 s 
2025-03-06 11:11:27.199860:  
2025-03-06 11:11:27.204873: Epoch 48 
2025-03-06 11:11:27.208384: Current learning rate: 0.00555 
2025-03-06 11:12:48.484242: train_loss -0.6737 
2025-03-06 11:12:48.490838: val_loss -0.5682 
2025-03-06 11:12:48.493865: Pseudo dice [np.float32(0.7708), np.float32(0.4795)] 
2025-03-06 11:12:48.496894: Epoch time: 81.28 s 
2025-03-06 11:12:49.051702:  
2025-03-06 11:12:49.056717: Epoch 49 
2025-03-06 11:12:49.059222: Current learning rate: 0.00546 
2025-03-06 11:14:10.273845: train_loss -0.6554 
2025-03-06 11:14:10.280364: val_loss -0.5822 
2025-03-06 11:14:10.282870: Pseudo dice [np.float32(0.7805), np.float32(0.4575)] 
2025-03-06 11:14:10.286379: Epoch time: 81.22 s 
2025-03-06 11:14:10.436345: Yayy! New best EMA pseudo Dice: 0.5953999757766724 
2025-03-06 11:14:11.153318:  
2025-03-06 11:14:11.158326: Epoch 50 
2025-03-06 11:14:11.161347: Current learning rate: 0.00536 
2025-03-06 11:15:32.364049: train_loss -0.6584 
2025-03-06 11:15:32.370067: val_loss -0.538 
2025-03-06 11:15:32.373590: Pseudo dice [np.float32(0.7863), np.float32(0.3532)] 
2025-03-06 11:15:32.376621: Epoch time: 81.21 s 
2025-03-06 11:15:32.940530:  
2025-03-06 11:15:32.946651: Epoch 51 
2025-03-06 11:15:32.949707: Current learning rate: 0.00526 
2025-03-06 11:16:54.150667: train_loss -0.6507 
2025-03-06 11:16:54.156685: val_loss -0.5705 
2025-03-06 11:16:54.159696: Pseudo dice [np.float32(0.7716), np.float32(0.4406)] 
2025-03-06 11:16:54.163210: Epoch time: 81.21 s 
2025-03-06 11:16:54.722129:  
2025-03-06 11:16:54.728170: Epoch 52 
2025-03-06 11:16:54.731692: Current learning rate: 0.00517 
2025-03-06 11:18:15.966062: train_loss -0.6685 
2025-03-06 11:18:15.972609: val_loss -0.5716 
2025-03-06 11:18:15.976119: Pseudo dice [np.float32(0.77), np.float32(0.4562)] 
2025-03-06 11:18:15.978627: Epoch time: 81.24 s 
2025-03-06 11:18:15.982139: Yayy! New best EMA pseudo Dice: 0.5960000157356262 
2025-03-06 11:18:16.878921:  
2025-03-06 11:18:16.884940: Epoch 53 
2025-03-06 11:18:16.887446: Current learning rate: 0.00507 
2025-03-06 11:19:38.084004: train_loss -0.6645 
2025-03-06 11:19:38.089532: val_loss -0.5973 
2025-03-06 11:19:38.093040: Pseudo dice [np.float32(0.795), np.float32(0.4782)] 
2025-03-06 11:19:38.095552: Epoch time: 81.21 s 
2025-03-06 11:19:38.099058: Yayy! New best EMA pseudo Dice: 0.6000999808311462 
2025-03-06 11:19:38.819922:  
2025-03-06 11:19:38.825943: Epoch 54 
2025-03-06 11:19:38.828452: Current learning rate: 0.00497 
2025-03-06 11:21:00.098065: train_loss -0.6956 
2025-03-06 11:21:00.104076: val_loss -0.5875 
2025-03-06 11:21:00.107085: Pseudo dice [np.float32(0.7933), np.float32(0.5136)] 
2025-03-06 11:21:00.110594: Epoch time: 81.28 s 
2025-03-06 11:21:00.113100: Yayy! New best EMA pseudo Dice: 0.605400025844574 
2025-03-06 11:21:00.834523:  
2025-03-06 11:21:00.840537: Epoch 55 
2025-03-06 11:21:00.843043: Current learning rate: 0.00487 
2025-03-06 11:22:23.977615: train_loss -0.6962 
2025-03-06 11:22:23.984131: val_loss -0.5702 
2025-03-06 11:22:23.986637: Pseudo dice [np.float32(0.7951), np.float32(0.4841)] 
2025-03-06 11:22:23.990145: Epoch time: 83.14 s 
2025-03-06 11:22:23.992651: Yayy! New best EMA pseudo Dice: 0.6087999939918518 
2025-03-06 11:22:24.758513:  
2025-03-06 11:22:24.765118: Epoch 56 
2025-03-06 11:22:24.767678: Current learning rate: 0.00478 
2025-03-06 11:23:46.391381: train_loss -0.6854 
2025-03-06 11:23:46.397398: val_loss -0.5206 
2025-03-06 11:23:46.400408: Pseudo dice [np.float32(0.7639), np.float32(0.3965)] 
2025-03-06 11:23:46.403954: Epoch time: 81.63 s 
2025-03-06 11:23:46.967665:  
2025-03-06 11:23:46.973327: Epoch 57 
2025-03-06 11:23:46.976378: Current learning rate: 0.00468 
2025-03-06 11:25:08.179878: train_loss -0.6906 
2025-03-06 11:25:08.185896: val_loss -0.5506 
2025-03-06 11:25:08.189400: Pseudo dice [np.float32(0.7905), np.float32(0.4516)] 
2025-03-06 11:25:08.192410: Epoch time: 81.21 s 
2025-03-06 11:25:08.841879:  
2025-03-06 11:25:08.845932: Epoch 58 
2025-03-06 11:25:08.850519: Current learning rate: 0.00458 
2025-03-06 11:26:30.016141: train_loss -0.7043 
2025-03-06 11:26:30.022656: val_loss -0.5336 
2025-03-06 11:26:30.026165: Pseudo dice [np.float32(0.7726), np.float32(0.3094)] 
2025-03-06 11:26:30.028675: Epoch time: 81.18 s 
2025-03-06 11:26:30.595979:  
2025-03-06 11:26:30.602517: Epoch 59 
2025-03-06 11:26:30.605546: Current learning rate: 0.00448 
2025-03-06 11:27:51.870288: train_loss -0.7085 
2025-03-06 11:27:51.876943: val_loss -0.5488 
2025-03-06 11:27:51.880458: Pseudo dice [np.float32(0.7781), np.float32(0.4015)] 
2025-03-06 11:27:51.882968: Epoch time: 81.27 s 
2025-03-06 11:27:52.458935:  
2025-03-06 11:27:52.464962: Epoch 60 
2025-03-06 11:27:52.467469: Current learning rate: 0.00438 
2025-03-06 11:29:13.683473: train_loss -0.709 
2025-03-06 11:29:13.688989: val_loss -0.6109 
2025-03-06 11:29:13.692501: Pseudo dice [np.float32(0.791), np.float32(0.5331)] 
2025-03-06 11:29:13.695005: Epoch time: 81.22 s 
2025-03-06 11:29:14.443291:  
2025-03-06 11:29:14.448846: Epoch 61 
2025-03-06 11:29:14.451387: Current learning rate: 0.00429 
2025-03-06 11:30:35.620748: train_loss -0.7077 
2025-03-06 11:30:35.627267: val_loss -0.5764 
2025-03-06 11:30:35.629290: Pseudo dice [np.float32(0.8053), np.float32(0.4688)] 
2025-03-06 11:30:35.633327: Epoch time: 81.18 s 
2025-03-06 11:30:35.636338: Yayy! New best EMA pseudo Dice: 0.6090999841690063 
2025-03-06 11:30:36.378228:  
2025-03-06 11:30:36.384267: Epoch 62 
2025-03-06 11:30:36.387291: Current learning rate: 0.00419 
2025-03-06 11:31:57.584761: train_loss -0.717 
2025-03-06 11:31:57.590277: val_loss -0.5647 
2025-03-06 11:31:57.593793: Pseudo dice [np.float32(0.7554), np.float32(0.5129)] 
2025-03-06 11:31:57.596309: Epoch time: 81.21 s 
2025-03-06 11:31:57.600321: Yayy! New best EMA pseudo Dice: 0.6115999817848206 
2025-03-06 11:31:58.337989:  
2025-03-06 11:31:58.344020: Epoch 63 
2025-03-06 11:31:58.347555: Current learning rate: 0.00409 
2025-03-06 11:33:19.541652: train_loss -0.7051 
2025-03-06 11:33:19.547172: val_loss -0.5555 
2025-03-06 11:33:19.550683: Pseudo dice [np.float32(0.7831), np.float32(0.4436)] 
2025-03-06 11:33:19.554191: Epoch time: 81.2 s 
2025-03-06 11:33:19.557204: Yayy! New best EMA pseudo Dice: 0.6118000149726868 
2025-03-06 11:33:20.286858:  
2025-03-06 11:33:20.292375: Epoch 64 
2025-03-06 11:33:20.295887: Current learning rate: 0.00399 
2025-03-06 11:34:41.554427: train_loss -0.6963 
2025-03-06 11:34:41.559941: val_loss -0.585 
2025-03-06 11:34:41.563449: Pseudo dice [np.float32(0.7929), np.float32(0.5052)] 
2025-03-06 11:34:41.565955: Epoch time: 81.27 s 
2025-03-06 11:34:41.569460: Yayy! New best EMA pseudo Dice: 0.6154999732971191 
2025-03-06 11:34:42.313681:  
2025-03-06 11:34:42.319634: Epoch 65 
2025-03-06 11:34:42.322141: Current learning rate: 0.00389 
2025-03-06 11:36:03.519440: train_loss -0.7169 
2025-03-06 11:36:03.525450: val_loss -0.5714 
2025-03-06 11:36:03.528460: Pseudo dice [np.float32(0.8026), np.float32(0.4883)] 
2025-03-06 11:36:03.530966: Epoch time: 81.21 s 
2025-03-06 11:36:03.534476: Yayy! New best EMA pseudo Dice: 0.6184999942779541 
2025-03-06 11:36:04.267012:  
2025-03-06 11:36:04.272040: Epoch 66 
2025-03-06 11:36:04.275070: Current learning rate: 0.00379 
2025-03-06 11:37:25.443754: train_loss -0.7292 
2025-03-06 11:37:25.449772: val_loss -0.5772 
2025-03-06 11:37:25.452784: Pseudo dice [np.float32(0.7925), np.float32(0.5186)] 
2025-03-06 11:37:25.456293: Epoch time: 81.18 s 
2025-03-06 11:37:25.458802: Yayy! New best EMA pseudo Dice: 0.6222000122070312 
2025-03-06 11:37:26.205962:  
2025-03-06 11:37:26.210974: Epoch 67 
2025-03-06 11:37:26.214487: Current learning rate: 0.00369 
2025-03-06 11:38:47.389092: train_loss -0.7273 
2025-03-06 11:38:47.394647: val_loss -0.5143 
2025-03-06 11:38:47.397664: Pseudo dice [np.float32(0.7534), np.float32(0.4438)] 
2025-03-06 11:38:47.400688: Epoch time: 81.18 s 
2025-03-06 11:38:48.066821:  
2025-03-06 11:38:48.071831: Epoch 68 
2025-03-06 11:38:48.075340: Current learning rate: 0.00359 
2025-03-06 11:40:09.281906: train_loss -0.7226 
2025-03-06 11:40:09.286922: val_loss -0.5753 
2025-03-06 11:40:09.290435: Pseudo dice [np.float32(0.7901), np.float32(0.5063)] 
2025-03-06 11:40:09.293446: Epoch time: 81.22 s 
2025-03-06 11:40:09.297090: Yayy! New best EMA pseudo Dice: 0.6226999759674072 
2025-03-06 11:40:10.187474:  
2025-03-06 11:40:10.192501: Epoch 69 
2025-03-06 11:40:10.196530: Current learning rate: 0.00349 
2025-03-06 11:41:31.367310: train_loss -0.7152 
2025-03-06 11:41:31.373896: val_loss -0.5423 
2025-03-06 11:41:31.377522: Pseudo dice [np.float32(0.797), np.float32(0.4302)] 
2025-03-06 11:41:31.380559: Epoch time: 81.18 s 
2025-03-06 11:41:31.959130:  
2025-03-06 11:41:31.965161: Epoch 70 
2025-03-06 11:41:31.967698: Current learning rate: 0.00338 
2025-03-06 11:42:53.195409: train_loss -0.7208 
2025-03-06 11:42:53.201422: val_loss -0.6054 
2025-03-06 11:42:53.204430: Pseudo dice [np.float32(0.807), np.float32(0.5453)] 
2025-03-06 11:42:53.207940: Epoch time: 81.24 s 
2025-03-06 11:42:53.209972: Yayy! New best EMA pseudo Dice: 0.6272000074386597 
2025-03-06 11:42:54.064260:  
2025-03-06 11:42:54.069270: Epoch 71 
2025-03-06 11:42:54.073072: Current learning rate: 0.00328 
2025-03-06 11:44:15.281899: train_loss -0.7213 
2025-03-06 11:44:15.289539: val_loss -0.5506 
2025-03-06 11:44:15.291628: Pseudo dice [np.float32(0.7637), np.float32(0.4455)] 
2025-03-06 11:44:15.295677: Epoch time: 81.22 s 
2025-03-06 11:44:15.905684:  
2025-03-06 11:44:15.911822: Epoch 72 
2025-03-06 11:44:15.914367: Current learning rate: 0.00318 
2025-03-06 11:45:37.121360: train_loss -0.7273 
2025-03-06 11:45:37.127424: val_loss -0.5811 
2025-03-06 11:45:37.130523: Pseudo dice [np.float32(0.7939), np.float32(0.4787)] 
2025-03-06 11:45:37.134032: Epoch time: 81.22 s 
2025-03-06 11:45:37.712116:  
2025-03-06 11:45:37.717259: Epoch 73 
2025-03-06 11:45:37.720819: Current learning rate: 0.00308 
2025-03-06 11:46:58.854636: train_loss -0.7372 
2025-03-06 11:46:58.860150: val_loss -0.568 
2025-03-06 11:46:58.863658: Pseudo dice [np.float32(0.7917), np.float32(0.459)] 
2025-03-06 11:46:58.866165: Epoch time: 81.14 s 
2025-03-06 11:46:59.458344:  
2025-03-06 11:46:59.463374: Epoch 74 
2025-03-06 11:46:59.466908: Current learning rate: 0.00297 
2025-03-06 11:48:20.657015: train_loss -0.7378 
2025-03-06 11:48:20.664034: val_loss -0.5558 
2025-03-06 11:48:20.667043: Pseudo dice [np.float32(0.7833), np.float32(0.4237)] 
2025-03-06 11:48:20.669549: Epoch time: 81.2 s 
2025-03-06 11:48:21.240684:  
2025-03-06 11:48:21.246240: Epoch 75 
2025-03-06 11:48:21.249311: Current learning rate: 0.00287 
2025-03-06 11:49:42.505494: train_loss -0.7464 
2025-03-06 11:49:42.513014: val_loss -0.5572 
2025-03-06 11:49:42.516525: Pseudo dice [np.float32(0.7897), np.float32(0.4489)] 
2025-03-06 11:49:42.519032: Epoch time: 81.27 s 
2025-03-06 11:49:43.101642:  
2025-03-06 11:49:43.106674: Epoch 76 
2025-03-06 11:49:43.109706: Current learning rate: 0.00277 
2025-03-06 11:51:04.288263: train_loss -0.7378 
2025-03-06 11:51:04.293784: val_loss -0.5893 
2025-03-06 11:51:04.297296: Pseudo dice [np.float32(0.7808), np.float32(0.4622)] 
2025-03-06 11:51:04.299805: Epoch time: 81.19 s 
2025-03-06 11:51:05.049171:  
2025-03-06 11:51:05.053804: Epoch 77 
2025-03-06 11:51:05.056348: Current learning rate: 0.00266 
2025-03-06 11:52:26.261829: train_loss -0.7442 
2025-03-06 11:52:26.268006: val_loss -0.5642 
2025-03-06 11:52:26.271039: Pseudo dice [np.float32(0.782), np.float32(0.4517)] 
2025-03-06 11:52:26.274567: Epoch time: 81.21 s 
2025-03-06 11:52:26.864334:  
2025-03-06 11:52:26.869454: Epoch 78 
2025-03-06 11:52:26.873003: Current learning rate: 0.00256 
2025-03-06 11:53:48.026508: train_loss -0.7479 
2025-03-06 11:53:48.032113: val_loss -0.5758 
2025-03-06 11:53:48.035673: Pseudo dice [np.float32(0.7915), np.float32(0.4611)] 
2025-03-06 11:53:48.039292: Epoch time: 81.16 s 
2025-03-06 11:53:48.643921:  
2025-03-06 11:53:48.649440: Epoch 79 
2025-03-06 11:53:48.651447: Current learning rate: 0.00245 
2025-03-06 11:55:09.875665: train_loss -0.7475 
2025-03-06 11:55:09.881959: val_loss -0.5543 
2025-03-06 11:55:09.885017: Pseudo dice [np.float32(0.7843), np.float32(0.4248)] 
2025-03-06 11:55:09.888068: Epoch time: 81.23 s 
2025-03-06 11:55:10.492397:  
2025-03-06 11:55:10.497953: Epoch 80 
2025-03-06 11:55:10.501517: Current learning rate: 0.00235 
2025-03-06 11:56:31.735054: train_loss -0.7479 
2025-03-06 11:56:31.741568: val_loss -0.5661 
2025-03-06 11:56:31.746078: Pseudo dice [np.float32(0.7842), np.float32(0.5027)] 
2025-03-06 11:56:31.750092: Epoch time: 81.24 s 
2025-03-06 11:56:32.358052:  
2025-03-06 11:56:32.364119: Epoch 81 
2025-03-06 11:56:32.367771: Current learning rate: 0.00224 
2025-03-06 11:57:53.627706: train_loss -0.7606 
2025-03-06 11:57:53.633720: val_loss -0.6331 
2025-03-06 11:57:53.636729: Pseudo dice [np.float32(0.8004), np.float32(0.5349)] 
2025-03-06 11:57:53.640238: Epoch time: 81.27 s 
2025-03-06 11:57:53.643746: Yayy! New best EMA pseudo Dice: 0.6276999711990356 
2025-03-06 11:57:54.391303:  
2025-03-06 11:57:54.396816: Epoch 82 
2025-03-06 11:57:54.400324: Current learning rate: 0.00214 
2025-03-06 11:59:15.590348: train_loss -0.7569 
2025-03-06 11:59:15.595868: val_loss -0.5764 
2025-03-06 11:59:15.599378: Pseudo dice [np.float32(0.7793), np.float32(0.528)] 
2025-03-06 11:59:15.603392: Epoch time: 81.2 s 
2025-03-06 11:59:15.605899: Yayy! New best EMA pseudo Dice: 0.630299985408783 
2025-03-06 11:59:16.337080:  
2025-03-06 11:59:16.343211: Epoch 83 
2025-03-06 11:59:16.346316: Current learning rate: 0.00203 
2025-03-06 12:00:37.537504: train_loss -0.7683 
2025-03-06 12:00:37.543518: val_loss -0.5906 
2025-03-06 12:00:37.546529: Pseudo dice [np.float32(0.8017), np.float32(0.4718)] 
2025-03-06 12:00:37.550038: Epoch time: 81.2 s 
2025-03-06 12:00:37.554049: Yayy! New best EMA pseudo Dice: 0.6309999823570251 
2025-03-06 12:00:38.278031:  
2025-03-06 12:00:38.283606: Epoch 84 
2025-03-06 12:00:38.286703: Current learning rate: 0.00192 
2025-03-06 12:01:59.473355: train_loss -0.7714 
2025-03-06 12:01:59.479021: val_loss -0.5718 
2025-03-06 12:01:59.483071: Pseudo dice [np.float32(0.7872), np.float32(0.4925)] 
2025-03-06 12:01:59.486167: Epoch time: 81.2 s 
2025-03-06 12:01:59.488699: Yayy! New best EMA pseudo Dice: 0.6317999958992004 
2025-03-06 12:02:00.357928:  
2025-03-06 12:02:00.362952: Epoch 85 
2025-03-06 12:02:00.366615: Current learning rate: 0.00181 
2025-03-06 12:03:21.546222: train_loss -0.7659 
2025-03-06 12:03:21.553242: val_loss -0.5796 
2025-03-06 12:03:21.556796: Pseudo dice [np.float32(0.7756), np.float32(0.566)] 
2025-03-06 12:03:21.560328: Epoch time: 81.19 s 
2025-03-06 12:03:21.563890: Yayy! New best EMA pseudo Dice: 0.635699987411499 
2025-03-06 12:03:22.369948:  
2025-03-06 12:03:22.375772: Epoch 86 
2025-03-06 12:03:22.379278: Current learning rate: 0.0017 
2025-03-06 12:04:43.660668: train_loss -0.7652 
2025-03-06 12:04:43.667691: val_loss -0.5538 
2025-03-06 12:04:43.670704: Pseudo dice [np.float32(0.7901), np.float32(0.4215)] 
2025-03-06 12:04:43.674216: Epoch time: 81.29 s 
2025-03-06 12:04:44.232973:  
2025-03-06 12:04:44.237987: Epoch 87 
2025-03-06 12:04:44.241000: Current learning rate: 0.00159 
2025-03-06 12:06:05.451772: train_loss -0.7649 
2025-03-06 12:06:05.456818: val_loss -0.5753 
2025-03-06 12:06:05.459844: Pseudo dice [np.float32(0.805), np.float32(0.4726)] 
2025-03-06 12:06:05.463352: Epoch time: 81.22 s 
2025-03-06 12:06:06.009815:  
2025-03-06 12:06:06.014838: Epoch 88 
2025-03-06 12:06:06.019853: Current learning rate: 0.00148 
2025-03-06 12:07:27.242242: train_loss -0.7674 
2025-03-06 12:07:27.248257: val_loss -0.6 
2025-03-06 12:07:27.251764: Pseudo dice [np.float32(0.7774), np.float32(0.5644)] 
2025-03-06 12:07:27.254772: Epoch time: 81.23 s 
2025-03-06 12:07:27.258283: Yayy! New best EMA pseudo Dice: 0.6370999813079834 
2025-03-06 12:07:27.979596:  
2025-03-06 12:07:27.984608: Epoch 89 
2025-03-06 12:07:27.988116: Current learning rate: 0.00137 
2025-03-06 12:08:49.202157: train_loss -0.778 
2025-03-06 12:08:49.208188: val_loss -0.5705 
2025-03-06 12:08:49.211213: Pseudo dice [np.float32(0.7781), np.float32(0.5088)] 
2025-03-06 12:08:49.214725: Epoch time: 81.22 s 
2025-03-06 12:08:49.217230: Yayy! New best EMA pseudo Dice: 0.6377000212669373 
2025-03-06 12:08:49.927628:  
2025-03-06 12:08:49.932647: Epoch 90 
2025-03-06 12:08:49.936158: Current learning rate: 0.00126 
2025-03-06 12:10:11.155344: train_loss -0.7768 
2025-03-06 12:10:11.161865: val_loss -0.61 
2025-03-06 12:10:11.164371: Pseudo dice [np.float32(0.8004), np.float32(0.5177)] 
2025-03-06 12:10:11.167881: Epoch time: 81.23 s 
2025-03-06 12:10:11.171391: Yayy! New best EMA pseudo Dice: 0.6399000287055969 
2025-03-06 12:10:11.882951:  
2025-03-06 12:10:11.888465: Epoch 91 
2025-03-06 12:10:11.891973: Current learning rate: 0.00115 
2025-03-06 12:11:33.102178: train_loss -0.7668 
2025-03-06 12:11:33.108732: val_loss -0.5831 
2025-03-06 12:11:33.111778: Pseudo dice [np.float32(0.7871), np.float32(0.525)] 
2025-03-06 12:11:33.114814: Epoch time: 81.22 s 
2025-03-06 12:11:33.118845: Yayy! New best EMA pseudo Dice: 0.6414999961853027 
2025-03-06 12:11:33.848264:  
2025-03-06 12:11:33.853839: Epoch 92 
2025-03-06 12:11:33.857356: Current learning rate: 0.00103 
2025-03-06 12:12:55.130334: train_loss -0.7779 
2025-03-06 12:12:55.136851: val_loss -0.5628 
2025-03-06 12:12:55.139357: Pseudo dice [np.float32(0.8012), np.float32(0.5648)] 
2025-03-06 12:12:55.143404: Epoch time: 81.28 s 
2025-03-06 12:12:55.146947: Yayy! New best EMA pseudo Dice: 0.6456000208854675 
2025-03-06 12:12:55.852555:  
2025-03-06 12:12:55.857563: Epoch 93 
2025-03-06 12:12:55.861079: Current learning rate: 0.00091 
2025-03-06 12:14:17.124897: train_loss -0.7896 
2025-03-06 12:14:17.131426: val_loss -0.5448 
2025-03-06 12:14:17.135446: Pseudo dice [np.float32(0.8004), np.float32(0.377)] 
2025-03-06 12:14:17.139961: Epoch time: 81.27 s 
2025-03-06 12:14:17.844575:  
2025-03-06 12:14:17.850114: Epoch 94 
2025-03-06 12:14:17.853676: Current learning rate: 0.00079 
2025-03-06 12:15:39.081172: train_loss -0.7845 
2025-03-06 12:15:39.087687: val_loss -0.6201 
2025-03-06 12:15:39.091244: Pseudo dice [np.float32(0.8052), np.float32(0.5621)] 
2025-03-06 12:15:39.095338: Epoch time: 81.24 s 
2025-03-06 12:15:39.657528:  
2025-03-06 12:15:39.663458: Epoch 95 
2025-03-06 12:15:39.666546: Current learning rate: 0.00067 
2025-03-06 12:17:00.897567: train_loss -0.7652 
2025-03-06 12:17:00.903588: val_loss -0.6132 
2025-03-06 12:17:00.906605: Pseudo dice [np.float32(0.8097), np.float32(0.5714)] 
2025-03-06 12:17:00.910117: Epoch time: 81.24 s 
2025-03-06 12:17:00.913633: Yayy! New best EMA pseudo Dice: 0.6488999724388123 
2025-03-06 12:17:01.634299:  
2025-03-06 12:17:01.639909: Epoch 96 
2025-03-06 12:17:01.642929: Current learning rate: 0.00055 
2025-03-06 12:18:22.800175: train_loss -0.7854 
2025-03-06 12:18:22.806190: val_loss -0.5929 
2025-03-06 12:18:22.810198: Pseudo dice [np.float32(0.7984), np.float32(0.5802)] 
2025-03-06 12:18:22.812741: Epoch time: 81.17 s 
2025-03-06 12:18:22.816252: Yayy! New best EMA pseudo Dice: 0.652999997138977 
2025-03-06 12:18:23.538006:  
2025-03-06 12:18:23.544037: Epoch 97 
2025-03-06 12:18:23.547070: Current learning rate: 0.00043 
2025-03-06 12:19:44.879738: train_loss -0.791 
2025-03-06 12:19:44.885759: val_loss -0.5716 
2025-03-06 12:19:44.889772: Pseudo dice [np.float32(0.8062), np.float32(0.4196)] 
2025-03-06 12:19:44.894285: Epoch time: 81.34 s 
2025-03-06 12:19:45.467014:  
2025-03-06 12:19:45.473631: Epoch 98 
2025-03-06 12:19:45.476658: Current learning rate: 0.0003 
2025-03-06 12:21:06.735757: train_loss -0.7921 
2025-03-06 12:21:06.742593: val_loss -0.554 
2025-03-06 12:21:06.746658: Pseudo dice [np.float32(0.7923), np.float32(0.3898)] 
2025-03-06 12:21:06.751197: Epoch time: 81.27 s 
2025-03-06 12:21:07.457004:  
2025-03-06 12:21:07.463521: Epoch 99 
2025-03-06 12:21:07.467033: Current learning rate: 0.00016 
2025-03-06 12:22:28.686424: train_loss -0.7905 
2025-03-06 12:22:28.694450: val_loss -0.5618 
2025-03-06 12:22:28.698083: Pseudo dice [np.float32(0.7937), np.float32(0.4072)] 
2025-03-06 12:22:28.701125: Epoch time: 81.23 s 
2025-03-06 12:22:29.492001: Training done. 
2025-03-06 12:22:29.528001: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-03-06 12:22:29.541006: The split file contains 5 splits. 
2025-03-06 12:22:29.547006: Desired fold for training: 0 
2025-03-06 12:22:29.551517: This split has 224 training and 57 validation cases. 
2025-03-06 12:22:29.558517: predicting pancreas_021 
2025-03-06 12:22:29.565518: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-03-06 12:22:42.375623: predicting pancreas_024 
2025-03-06 12:22:42.398624: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-03-06 12:22:57.511380: predicting pancreas_035 
2025-03-06 12:22:57.534380: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-03-06 12:23:02.667806: predicting pancreas_040 
2025-03-06 12:23:02.681313: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-03-06 12:23:15.156555: predicting pancreas_042 
2025-03-06 12:23:15.177558: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-03-06 12:23:30.382036: predicting pancreas_056 
2025-03-06 12:23:30.406544: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-03-06 12:23:42.505776: predicting pancreas_067 
2025-03-06 12:23:42.524776: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-03-06 12:23:57.693806: predicting pancreas_075 
2025-03-06 12:23:57.715315: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-03-06 12:24:03.817315: predicting pancreas_086 
2025-03-06 12:24:03.834316: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-03-06 12:24:13.303965: predicting pancreas_089 
2025-03-06 12:24:13.321474: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-03-06 12:24:25.418373: predicting pancreas_092 
2025-03-06 12:24:25.436880: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-03-06 12:24:52.637092: predicting pancreas_094 
2025-03-06 12:24:52.669599: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-03-06 12:25:04.784713: predicting pancreas_095 
2025-03-06 12:25:04.801713: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-03-06 12:25:16.935653: predicting pancreas_098 
2025-03-06 12:25:16.954659: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-03-06 12:25:49.935848: predicting pancreas_109 
2025-03-06 12:25:49.967843: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-03-06 12:26:02.150696: predicting pancreas_110 
2025-03-06 12:26:02.173697: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-03-06 12:26:21.103017: predicting pancreas_114 
2025-03-06 12:26:21.130036: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-03-06 12:26:33.269983: predicting pancreas_119 
2025-03-06 12:26:33.290978: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-03-06 12:26:52.184400: predicting pancreas_138 
2025-03-06 12:26:52.206401: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-03-06 12:27:11.131764: predicting pancreas_145 
2025-03-06 12:27:11.158277: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-03-06 12:27:30.090952: predicting pancreas_148 
2025-03-06 12:27:30.116953: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-03-06 12:27:42.266593: predicting pancreas_169 
2025-03-06 12:27:42.285594: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-03-06 12:27:54.410181: predicting pancreas_170 
2025-03-06 12:27:54.428181: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-03-06 12:28:09.553197: predicting pancreas_172 
2025-03-06 12:28:09.573200: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-03-06 12:28:21.704366: predicting pancreas_175 
2025-03-06 12:28:21.725366: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-03-06 12:28:33.852769: predicting pancreas_180 
2025-03-06 12:28:33.874769: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-03-06 12:28:45.998033: predicting pancreas_191 
2025-03-06 12:28:46.016541: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-03-06 12:28:52.106510: predicting pancreas_193 
2025-03-06 12:28:52.119562: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-03-06 12:29:07.278582: predicting pancreas_212 
2025-03-06 12:29:07.300584: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-03-06 12:29:19.492784: predicting pancreas_215 
2025-03-06 12:29:19.516785: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-03-06 12:29:31.642234: predicting pancreas_222 
2025-03-06 12:29:31.662741: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-03-06 12:29:36.819054: predicting pancreas_235 
2025-03-06 12:29:36.834060: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-03-06 12:29:48.930444: predicting pancreas_241 
2025-03-06 12:29:48.948447: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-03-06 12:30:01.088481: predicting pancreas_242 
2025-03-06 12:30:01.111482: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-03-06 12:30:16.303038: predicting pancreas_244 
2025-03-06 12:30:16.326038: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-03-06 12:30:39.940883: predicting pancreas_246 
2025-03-06 12:30:39.967883: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-03-06 12:31:03.598800: predicting pancreas_247 
2025-03-06 12:31:03.621314: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-03-06 12:31:10.491002: predicting pancreas_264 
2025-03-06 12:31:10.509005: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-03-06 12:31:25.704697: predicting pancreas_265 
2025-03-06 12:31:25.728701: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-03-06 12:31:37.853063: predicting pancreas_266 
2025-03-06 12:31:37.875064: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-03-06 12:31:56.797927: predicting pancreas_267 
2025-03-06 12:31:56.820928: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-03-06 12:32:03.715553: predicting pancreas_275 
2025-03-06 12:32:03.732554: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-03-06 12:32:18.850435: predicting pancreas_279 
2025-03-06 12:32:18.868945: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-03-06 12:32:24.068732: predicting pancreas_287 
2025-03-06 12:32:24.085239: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-03-06 12:32:36.222259: predicting pancreas_301 
2025-03-06 12:32:36.245259: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-03-06 12:32:48.365051: predicting pancreas_323 
2025-03-06 12:32:48.385055: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-03-06 12:33:07.331954: predicting pancreas_336 
2025-03-06 12:33:07.353956: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-03-06 12:33:19.508139: predicting pancreas_344 
2025-03-06 12:33:19.528142: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-03-06 12:33:34.695593: predicting pancreas_351 
2025-03-06 12:33:34.719104: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-03-06 12:33:41.582517: predicting pancreas_354 
2025-03-06 12:33:41.600517: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-03-06 12:34:05.806324: predicting pancreas_372 
2025-03-06 12:34:05.835329: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-03-06 12:34:24.755174: predicting pancreas_377 
2025-03-06 12:34:24.782174: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-03-06 12:34:39.961075: predicting pancreas_387 
2025-03-06 12:34:39.986583: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-03-06 12:34:52.137433: predicting pancreas_391 
2025-03-06 12:34:52.159440: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-03-06 12:35:11.094425: predicting pancreas_392 
2025-03-06 12:35:11.117426: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-03-06 12:35:19.680577: predicting pancreas_410 
2025-03-06 12:35:19.700083: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-03-06 12:35:28.250962: predicting pancreas_412 
2025-03-06 12:35:28.268961: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-03-06 12:36:29.269448: Validation complete 
2025-03-06 12:36:29.276448: Mean Validation Dice:  0.29856391884184663 
