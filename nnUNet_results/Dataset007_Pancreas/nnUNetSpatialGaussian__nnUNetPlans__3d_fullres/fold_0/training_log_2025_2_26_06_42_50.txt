
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-26 06:42:50.655395: do_dummy_2d_data_aug: True 
2025-02-26 06:42:50.677434: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-02-26 06:42:50.686235: The split file contains 5 splits. 
2025-02-26 06:42:50.689229: Desired fold for training: 0 
2025-02-26 06:42:50.691229: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-02-26 06:42:57.780738: unpacking dataset... 
2025-02-26 06:42:58.225181: unpacking done... 
2025-02-26 06:43:01.110296:  
2025-02-26 06:43:01.115306: Epoch 0 
2025-02-26 06:43:01.118818: Current learning rate: 0.01 
2025-02-26 06:43:48.174158: train_loss 0.16 
2025-02-26 06:43:48.179673: val_loss 0.0668 
2025-02-26 06:43:48.183184: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-02-26 06:43:48.186690: Epoch time: 47.06 s 
2025-02-26 06:43:48.189701: Yayy! New best EMA pseudo Dice: 0.0 
2025-02-26 06:43:48.764214:  
2025-02-26 06:43:48.770278: Epoch 1 
2025-02-26 06:43:48.772812: Current learning rate: 0.00991 
2025-02-26 06:44:31.256035: train_loss 0.0539 
2025-02-26 06:44:31.262578: val_loss 0.025 
2025-02-26 06:44:31.266170: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-02-26 06:44:31.269844: Epoch time: 42.49 s 
2025-02-26 06:44:31.758679:  
2025-02-26 06:44:31.764225: Epoch 2 
2025-02-26 06:44:31.767764: Current learning rate: 0.00982 
2025-02-26 06:45:14.245693: train_loss -0.0111 
2025-02-26 06:45:14.251271: val_loss -0.1269 
2025-02-26 06:45:14.255779: Pseudo dice [np.float32(0.342), np.float32(0.0)] 
2025-02-26 06:45:14.261293: Epoch time: 42.49 s 
2025-02-26 06:45:14.267308: Yayy! New best EMA pseudo Dice: 0.017100000753998756 
2025-02-26 06:45:14.938251:  
2025-02-26 06:45:14.943827: Epoch 3 
2025-02-26 06:45:14.947428: Current learning rate: 0.00973 
2025-02-26 06:45:57.419882: train_loss -0.1319 
2025-02-26 06:45:57.426399: val_loss -0.1997 
2025-02-26 06:45:57.430911: Pseudo dice [np.float32(0.5383), np.float32(0.0)] 
2025-02-26 06:45:57.434925: Epoch time: 42.48 s 
2025-02-26 06:45:57.440941: Yayy! New best EMA pseudo Dice: 0.04230000078678131 
2025-02-26 06:45:58.090408:  
2025-02-26 06:45:58.095965: Epoch 4 
2025-02-26 06:45:58.099596: Current learning rate: 0.00964 
2025-02-26 06:46:40.560293: train_loss -0.2123 
2025-02-26 06:46:40.565814: val_loss -0.2575 
2025-02-26 06:46:40.569324: Pseudo dice [np.float32(0.6006), np.float32(0.0)] 
2025-02-26 06:46:40.572834: Epoch time: 42.47 s 
2025-02-26 06:46:40.575846: Yayy! New best EMA pseudo Dice: 0.06809999793767929 
2025-02-26 06:46:41.361652:  
2025-02-26 06:46:41.367745: Epoch 5 
2025-02-26 06:46:41.370278: Current learning rate: 0.00955 
2025-02-26 06:47:23.845838: train_loss -0.241 
2025-02-26 06:47:23.851855: val_loss -0.2779 
2025-02-26 06:47:23.854362: Pseudo dice [np.float32(0.6313), np.float32(0.0)] 
2025-02-26 06:47:23.858371: Epoch time: 42.48 s 
2025-02-26 06:47:23.860877: Yayy! New best EMA pseudo Dice: 0.09290000051259995 
2025-02-26 06:47:24.500343:  
2025-02-26 06:47:24.504902: Epoch 6 
2025-02-26 06:47:24.509458: Current learning rate: 0.00946 
2025-02-26 06:48:06.984610: train_loss -0.2585 
2025-02-26 06:48:06.992129: val_loss -0.314 
2025-02-26 06:48:06.994637: Pseudo dice [np.float32(0.6651), np.float32(0.0)] 
2025-02-26 06:48:06.998651: Epoch time: 42.49 s 
2025-02-26 06:48:07.002162: Yayy! New best EMA pseudo Dice: 0.11680000275373459 
2025-02-26 06:48:07.656807:  
2025-02-26 06:48:07.662364: Epoch 7 
2025-02-26 06:48:07.666414: Current learning rate: 0.00937 
2025-02-26 06:48:50.183671: train_loss -0.2789 
2025-02-26 06:48:50.189211: val_loss -0.324 
2025-02-26 06:48:50.192744: Pseudo dice [np.float32(0.6576), np.float32(0.0)] 
2025-02-26 06:48:50.195721: Epoch time: 42.53 s 
2025-02-26 06:48:50.197730: Yayy! New best EMA pseudo Dice: 0.1379999965429306 
2025-02-26 06:48:50.858818:  
2025-02-26 06:48:50.863293: Epoch 8 
2025-02-26 06:48:50.866802: Current learning rate: 0.00928 
2025-02-26 06:49:33.421276: train_loss -0.3115 
2025-02-26 06:49:33.427293: val_loss -0.3539 
2025-02-26 06:49:33.432308: Pseudo dice [np.float32(0.6948), np.float32(0.0)] 
2025-02-26 06:49:33.436323: Epoch time: 42.56 s 
2025-02-26 06:49:33.439835: Yayy! New best EMA pseudo Dice: 0.1589999943971634 
2025-02-26 06:49:34.107604:  
2025-02-26 06:49:34.113133: Epoch 9 
2025-02-26 06:49:34.116684: Current learning rate: 0.00919 
2025-02-26 06:50:16.596911: train_loss -0.2942 
2025-02-26 06:50:16.603935: val_loss -0.3247 
2025-02-26 06:50:16.606945: Pseudo dice [np.float32(0.6105), np.float32(0.2538)] 
2025-02-26 06:50:16.610975: Epoch time: 42.49 s 
2025-02-26 06:50:16.614014: Yayy! New best EMA pseudo Dice: 0.18629999458789825 
2025-02-26 06:50:17.252503:  
2025-02-26 06:50:17.257516: Epoch 10 
2025-02-26 06:50:17.261034: Current learning rate: 0.0091 
2025-02-26 06:50:59.725220: train_loss -0.3267 
2025-02-26 06:50:59.731747: val_loss -0.3902 
2025-02-26 06:50:59.735259: Pseudo dice [np.float32(0.6208), np.float32(0.306)] 
2025-02-26 06:50:59.737766: Epoch time: 42.47 s 
2025-02-26 06:50:59.745301: Yayy! New best EMA pseudo Dice: 0.21400000154972076 
2025-02-26 06:51:00.393144:  
2025-02-26 06:51:00.398667: Epoch 11 
2025-02-26 06:51:00.402178: Current learning rate: 0.009 
2025-02-26 06:51:42.875257: train_loss -0.3739 
2025-02-26 06:51:42.880818: val_loss -0.4283 
2025-02-26 06:51:42.884387: Pseudo dice [np.float32(0.6582), np.float32(0.3016)] 
2025-02-26 06:51:42.887956: Epoch time: 42.48 s 
2025-02-26 06:51:42.891086: Yayy! New best EMA pseudo Dice: 0.24060000479221344 
2025-02-26 06:51:43.543557:  
2025-02-26 06:51:43.548594: Epoch 12 
2025-02-26 06:51:43.552334: Current learning rate: 0.00891 
2025-02-26 06:52:26.027367: train_loss -0.3926 
2025-02-26 06:52:26.034893: val_loss -0.44 
2025-02-26 06:52:26.038909: Pseudo dice [np.float32(0.6854), np.float32(0.2954)] 
2025-02-26 06:52:26.041465: Epoch time: 42.48 s 
2025-02-26 06:52:26.044977: Yayy! New best EMA pseudo Dice: 0.2655999958515167 
2025-02-26 06:52:26.848210:  
2025-02-26 06:52:26.854249: Epoch 13 
2025-02-26 06:52:26.857307: Current learning rate: 0.00882 
2025-02-26 06:53:09.317870: train_loss -0.3999 
2025-02-26 06:53:09.324384: val_loss -0.4437 
2025-02-26 06:53:09.326894: Pseudo dice [np.float32(0.6814), np.float32(0.3763)] 
2025-02-26 06:53:09.330403: Epoch time: 42.47 s 
2025-02-26 06:53:09.334417: Yayy! New best EMA pseudo Dice: 0.29190000891685486 
2025-02-26 06:53:09.985116:  
2025-02-26 06:53:09.990128: Epoch 14 
2025-02-26 06:53:09.993637: Current learning rate: 0.00873 
2025-02-26 06:53:52.448104: train_loss -0.4274 
2025-02-26 06:53:52.454127: val_loss -0.4413 
2025-02-26 06:53:52.459140: Pseudo dice [np.float32(0.6928), np.float32(0.3843)] 
2025-02-26 06:53:52.463201: Epoch time: 42.46 s 
2025-02-26 06:53:52.466763: Yayy! New best EMA pseudo Dice: 0.3165999948978424 
2025-02-26 06:53:53.125356:  
2025-02-26 06:53:53.130912: Epoch 15 
2025-02-26 06:53:53.134962: Current learning rate: 0.00864 
2025-02-26 06:54:35.601765: train_loss -0.4347 
2025-02-26 06:54:35.606839: val_loss -0.3881 
2025-02-26 06:54:35.610359: Pseudo dice [np.float32(0.655), np.float32(0.2444)] 
2025-02-26 06:54:35.613973: Epoch time: 42.48 s 
2025-02-26 06:54:35.617052: Yayy! New best EMA pseudo Dice: 0.32989999651908875 
2025-02-26 06:54:36.282756:  
2025-02-26 06:54:36.288807: Epoch 16 
2025-02-26 06:54:36.291852: Current learning rate: 0.00855 
2025-02-26 06:55:18.763574: train_loss -0.4264 
2025-02-26 06:55:18.769657: val_loss -0.4677 
2025-02-26 06:55:18.773201: Pseudo dice [np.float32(0.6931), np.float32(0.3384)] 
2025-02-26 06:55:18.776843: Epoch time: 42.48 s 
2025-02-26 06:55:18.779892: Yayy! New best EMA pseudo Dice: 0.34850001335144043 
2025-02-26 06:55:19.445183:  
2025-02-26 06:55:19.450740: Epoch 17 
2025-02-26 06:55:19.454290: Current learning rate: 0.00846 
2025-02-26 06:56:01.923841: train_loss -0.4594 
2025-02-26 06:56:01.929975: val_loss -0.3976 
2025-02-26 06:56:01.932505: Pseudo dice [np.float32(0.6755), np.float32(0.2239)] 
2025-02-26 06:56:01.936143: Epoch time: 42.48 s 
2025-02-26 06:56:01.939796: Yayy! New best EMA pseudo Dice: 0.358599990606308 
2025-02-26 06:56:02.608646:  
2025-02-26 06:56:02.613664: Epoch 18 
2025-02-26 06:56:02.617174: Current learning rate: 0.00836 
2025-02-26 06:56:45.104921: train_loss -0.4294 
2025-02-26 06:56:45.110577: val_loss -0.4677 
2025-02-26 06:56:45.115664: Pseudo dice [np.float32(0.6896), np.float32(0.386)] 
2025-02-26 06:56:45.121751: Epoch time: 42.5 s 
2025-02-26 06:56:45.126958: Yayy! New best EMA pseudo Dice: 0.3765000104904175 
2025-02-26 06:56:45.788762:  
2025-02-26 06:56:45.794785: Epoch 19 
2025-02-26 06:56:45.798292: Current learning rate: 0.00827 
2025-02-26 06:57:28.260978: train_loss -0.4478 
2025-02-26 06:57:28.267491: val_loss -0.4938 
2025-02-26 06:57:28.271000: Pseudo dice [np.float32(0.7041), np.float32(0.3771)] 
2025-02-26 06:57:28.275011: Epoch time: 42.47 s 
2025-02-26 06:57:28.277520: Yayy! New best EMA pseudo Dice: 0.3928999900817871 
2025-02-26 06:57:28.955157:  
2025-02-26 06:57:28.961736: Epoch 20 
2025-02-26 06:57:28.964267: Current learning rate: 0.00818 
2025-02-26 06:58:11.435595: train_loss -0.4875 
2025-02-26 06:58:11.443136: val_loss -0.4819 
2025-02-26 06:58:11.446153: Pseudo dice [np.float32(0.6965), np.float32(0.4155)] 
2025-02-26 06:58:11.450702: Epoch time: 42.48 s 
2025-02-26 06:58:11.455213: Yayy! New best EMA pseudo Dice: 0.4092000126838684 
2025-02-26 06:58:12.272752:  
2025-02-26 06:58:12.277764: Epoch 21 
2025-02-26 06:58:12.282277: Current learning rate: 0.00809 
2025-02-26 06:58:54.738084: train_loss -0.5077 
2025-02-26 06:58:54.744203: val_loss -0.4951 
2025-02-26 06:58:54.747786: Pseudo dice [np.float32(0.7427), np.float32(0.3933)] 
2025-02-26 06:58:54.751304: Epoch time: 42.47 s 
2025-02-26 06:58:54.754355: Yayy! New best EMA pseudo Dice: 0.4250999987125397 
2025-02-26 06:58:55.406411:  
2025-02-26 06:58:55.412446: Epoch 22 
2025-02-26 06:58:55.415506: Current learning rate: 0.008 
2025-02-26 06:59:37.908691: train_loss -0.5137 
2025-02-26 06:59:37.915204: val_loss -0.4787 
2025-02-26 06:59:37.918714: Pseudo dice [np.float32(0.7093), np.float32(0.338)] 
2025-02-26 06:59:37.921218: Epoch time: 42.5 s 
2025-02-26 06:59:37.927737: Yayy! New best EMA pseudo Dice: 0.4350000023841858 
2025-02-26 06:59:38.570383:  
2025-02-26 06:59:38.575396: Epoch 23 
2025-02-26 06:59:38.578905: Current learning rate: 0.0079 
2025-02-26 07:00:21.414659: train_loss -0.4826 
2025-02-26 07:00:21.421831: val_loss -0.4391 
2025-02-26 07:00:21.425454: Pseudo dice [np.float32(0.7069), np.float32(0.2602)] 
2025-02-26 07:00:21.428479: Epoch time: 42.84 s 
2025-02-26 07:00:21.431998: Yayy! New best EMA pseudo Dice: 0.4397999942302704 
2025-02-26 07:00:22.066480:  
2025-02-26 07:00:22.072498: Epoch 24 
2025-02-26 07:00:22.076002: Current learning rate: 0.00781 
2025-02-26 07:01:04.553169: train_loss -0.4908 
2025-02-26 07:01:04.559188: val_loss -0.5071 
2025-02-26 07:01:04.564208: Pseudo dice [np.float32(0.746), np.float32(0.3804)] 
2025-02-26 07:01:04.568225: Epoch time: 42.49 s 
2025-02-26 07:01:04.571743: Yayy! New best EMA pseudo Dice: 0.4521999955177307 
2025-02-26 07:01:05.222823:  
2025-02-26 07:01:05.229352: Epoch 25 
2025-02-26 07:01:05.232867: Current learning rate: 0.00772 
2025-02-26 07:01:47.688971: train_loss -0.4882 
2025-02-26 07:01:47.695601: val_loss -0.5118 
2025-02-26 07:01:47.698756: Pseudo dice [np.float32(0.7225), np.float32(0.4552)] 
2025-02-26 07:01:47.702346: Epoch time: 42.47 s 
2025-02-26 07:01:47.705426: Yayy! New best EMA pseudo Dice: 0.4657999873161316 
2025-02-26 07:01:48.353929:  
2025-02-26 07:01:48.359944: Epoch 26 
2025-02-26 07:01:48.366457: Current learning rate: 0.00763 
2025-02-26 07:02:30.847657: train_loss -0.5255 
2025-02-26 07:02:30.853699: val_loss -0.497 
2025-02-26 07:02:30.857301: Pseudo dice [np.float32(0.7283), np.float32(0.3869)] 
2025-02-26 07:02:30.860332: Epoch time: 42.5 s 
2025-02-26 07:02:30.864343: Yayy! New best EMA pseudo Dice: 0.4749999940395355 
2025-02-26 07:02:31.519979:  
2025-02-26 07:02:31.525531: Epoch 27 
2025-02-26 07:02:31.529122: Current learning rate: 0.00753 
2025-02-26 07:03:14.004659: train_loss -0.5397 
2025-02-26 07:03:14.011181: val_loss -0.5411 
2025-02-26 07:03:14.014693: Pseudo dice [np.float32(0.7483), np.float32(0.4332)] 
2025-02-26 07:03:14.017198: Epoch time: 42.48 s 
2025-02-26 07:03:14.021211: Yayy! New best EMA pseudo Dice: 0.48660001158714294 
2025-02-26 07:03:14.681224:  
2025-02-26 07:03:14.686235: Epoch 28 
2025-02-26 07:03:14.689745: Current learning rate: 0.00744 
2025-02-26 07:03:57.147727: train_loss -0.5229 
2025-02-26 07:03:57.154243: val_loss -0.5218 
2025-02-26 07:03:57.159254: Pseudo dice [np.float32(0.7501), np.float32(0.4081)] 
2025-02-26 07:03:57.163765: Epoch time: 42.47 s 
2025-02-26 07:03:57.166775: Yayy! New best EMA pseudo Dice: 0.4957999885082245 
2025-02-26 07:03:57.989119:  
2025-02-26 07:03:57.994131: Epoch 29 
2025-02-26 07:03:57.997643: Current learning rate: 0.00735 
2025-02-26 07:04:40.462337: train_loss -0.5373 
2025-02-26 07:04:40.469359: val_loss -0.4897 
2025-02-26 07:04:40.472414: Pseudo dice [np.float32(0.7271), np.float32(0.3798)] 
2025-02-26 07:04:40.475958: Epoch time: 42.47 s 
2025-02-26 07:04:40.480039: Yayy! New best EMA pseudo Dice: 0.5016000270843506 
2025-02-26 07:04:41.133482:  
2025-02-26 07:04:41.140008: Epoch 30 
2025-02-26 07:04:41.143524: Current learning rate: 0.00725 
2025-02-26 07:05:23.626777: train_loss -0.5443 
2025-02-26 07:05:23.632798: val_loss -0.5322 
2025-02-26 07:05:23.635815: Pseudo dice [np.float32(0.7639), np.float32(0.4119)] 
2025-02-26 07:05:23.639330: Epoch time: 42.49 s 
2025-02-26 07:05:23.642841: Yayy! New best EMA pseudo Dice: 0.510200023651123 
2025-02-26 07:05:24.313800:  
2025-02-26 07:05:24.319030: Epoch 31 
2025-02-26 07:05:24.322556: Current learning rate: 0.00716 
2025-02-26 07:06:06.788903: train_loss -0.5626 
2025-02-26 07:06:06.794920: val_loss -0.5517 
2025-02-26 07:06:06.798934: Pseudo dice [np.float32(0.7587), np.float32(0.4109)] 
2025-02-26 07:06:06.802446: Epoch time: 42.48 s 
2025-02-26 07:06:06.806459: Yayy! New best EMA pseudo Dice: 0.5177000164985657 
2025-02-26 07:06:07.454815:  
2025-02-26 07:06:07.460876: Epoch 32 
2025-02-26 07:06:07.463951: Current learning rate: 0.00707 
2025-02-26 07:06:49.933468: train_loss -0.5494 
2025-02-26 07:06:49.938673: val_loss -0.5128 
2025-02-26 07:06:49.942770: Pseudo dice [np.float32(0.7637), np.float32(0.448)] 
2025-02-26 07:06:49.945895: Epoch time: 42.48 s 
2025-02-26 07:06:49.949056: Yayy! New best EMA pseudo Dice: 0.5264999866485596 
2025-02-26 07:06:50.600740:  
2025-02-26 07:06:50.607293: Epoch 33 
2025-02-26 07:06:50.610337: Current learning rate: 0.00697 
2025-02-26 07:07:33.142103: train_loss -0.5428 
2025-02-26 07:07:33.148252: val_loss -0.51 
2025-02-26 07:07:33.151775: Pseudo dice [np.float32(0.7058), np.float32(0.4259)] 
2025-02-26 07:07:33.154516: Epoch time: 42.54 s 
2025-02-26 07:07:33.159044: Yayy! New best EMA pseudo Dice: 0.5303999781608582 
2025-02-26 07:07:33.818148:  
2025-02-26 07:07:33.823226: Epoch 34 
2025-02-26 07:07:33.827373: Current learning rate: 0.00688 
2025-02-26 07:08:16.302620: train_loss -0.5692 
2025-02-26 07:08:16.308637: val_loss -0.5594 
2025-02-26 07:08:16.312152: Pseudo dice [np.float32(0.7717), np.float32(0.4723)] 
2025-02-26 07:08:16.315161: Epoch time: 42.48 s 
2025-02-26 07:08:16.318674: Yayy! New best EMA pseudo Dice: 0.5396000146865845 
2025-02-26 07:08:16.980964:  
2025-02-26 07:08:16.986621: Epoch 35 
2025-02-26 07:08:16.990221: Current learning rate: 0.00679 
2025-02-26 07:08:59.463033: train_loss -0.536 
2025-02-26 07:08:59.469054: val_loss -0.5175 
2025-02-26 07:08:59.472561: Pseudo dice [np.float32(0.7514), np.float32(0.3953)] 
2025-02-26 07:08:59.475572: Epoch time: 42.48 s 
2025-02-26 07:08:59.479085: Yayy! New best EMA pseudo Dice: 0.5429999828338623 
2025-02-26 07:09:00.143981:  
2025-02-26 07:09:00.149179: Epoch 36 
2025-02-26 07:09:00.152694: Current learning rate: 0.00669 
2025-02-26 07:09:42.628076: train_loss -0.5861 
2025-02-26 07:09:42.634605: val_loss -0.549 
2025-02-26 07:09:42.639615: Pseudo dice [np.float32(0.7568), np.float32(0.3997)] 
2025-02-26 07:09:42.642189: Epoch time: 42.49 s 
2025-02-26 07:09:42.646253: Yayy! New best EMA pseudo Dice: 0.546500027179718 
2025-02-26 07:09:43.466510:  
2025-02-26 07:09:43.472096: Epoch 37 
2025-02-26 07:09:43.476145: Current learning rate: 0.0066 
2025-02-26 07:10:25.937999: train_loss -0.579 
2025-02-26 07:10:25.945017: val_loss -0.5311 
2025-02-26 07:10:25.949031: Pseudo dice [np.float32(0.7771), np.float32(0.3223)] 
2025-02-26 07:10:25.952540: Epoch time: 42.47 s 
2025-02-26 07:10:25.956552: Yayy! New best EMA pseudo Dice: 0.5468000173568726 
2025-02-26 07:10:26.635979:  
2025-02-26 07:10:26.639490: Epoch 38 
2025-02-26 07:10:26.643500: Current learning rate: 0.0065 
2025-02-26 07:11:09.102891: train_loss -0.5699 
2025-02-26 07:11:09.109410: val_loss -0.5242 
2025-02-26 07:11:09.112921: Pseudo dice [np.float32(0.7285), np.float32(0.4477)] 
2025-02-26 07:11:09.116931: Epoch time: 42.47 s 
2025-02-26 07:11:09.120443: Yayy! New best EMA pseudo Dice: 0.5508999824523926 
2025-02-26 07:11:09.788539:  
2025-02-26 07:11:09.794108: Epoch 39 
2025-02-26 07:11:09.798667: Current learning rate: 0.00641 
2025-02-26 07:11:52.271042: train_loss -0.5847 
2025-02-26 07:11:52.277093: val_loss -0.523 
2025-02-26 07:11:52.280140: Pseudo dice [np.float32(0.7455), np.float32(0.3881)] 
2025-02-26 07:11:52.283205: Epoch time: 42.48 s 
2025-02-26 07:11:52.286237: Yayy! New best EMA pseudo Dice: 0.5525000095367432 
2025-02-26 07:11:52.958925:  
2025-02-26 07:11:52.964061: Epoch 40 
2025-02-26 07:11:52.967577: Current learning rate: 0.00631 
2025-02-26 07:12:35.434524: train_loss -0.5836 
2025-02-26 07:12:35.440112: val_loss -0.555 
2025-02-26 07:12:35.443668: Pseudo dice [np.float32(0.7545), np.float32(0.4393)] 
2025-02-26 07:12:35.447176: Epoch time: 42.48 s 
2025-02-26 07:12:35.450188: Yayy! New best EMA pseudo Dice: 0.5569999814033508 
2025-02-26 07:12:36.122345:  
2025-02-26 07:12:36.127870: Epoch 41 
2025-02-26 07:12:36.131381: Current learning rate: 0.00622 
2025-02-26 07:13:18.613821: train_loss -0.6083 
2025-02-26 07:13:18.619832: val_loss -0.5134 
2025-02-26 07:13:18.622841: Pseudo dice [np.float32(0.7531), np.float32(0.3935)] 
2025-02-26 07:13:18.626354: Epoch time: 42.49 s 
2025-02-26 07:13:18.628864: Yayy! New best EMA pseudo Dice: 0.5586000084877014 
2025-02-26 07:13:19.284964:  
2025-02-26 07:13:19.290112: Epoch 42 
2025-02-26 07:13:19.293659: Current learning rate: 0.00612 
2025-02-26 07:14:01.753887: train_loss -0.6157 
2025-02-26 07:14:01.758965: val_loss -0.5885 
2025-02-26 07:14:01.761560: Pseudo dice [np.float32(0.7711), np.float32(0.4812)] 
2025-02-26 07:14:01.765605: Epoch time: 42.47 s 
2025-02-26 07:14:01.769191: Yayy! New best EMA pseudo Dice: 0.5654000043869019 
2025-02-26 07:14:02.418642:  
2025-02-26 07:14:02.424155: Epoch 43 
2025-02-26 07:14:02.427665: Current learning rate: 0.00603 
2025-02-26 07:14:44.891823: train_loss -0.6122 
2025-02-26 07:14:44.896843: val_loss -0.5514 
2025-02-26 07:14:44.900859: Pseudo dice [np.float32(0.7375), np.float32(0.452)] 
2025-02-26 07:14:44.903368: Epoch time: 42.47 s 
2025-02-26 07:14:44.906885: Yayy! New best EMA pseudo Dice: 0.5683000087738037 
2025-02-26 07:14:45.571285:  
2025-02-26 07:14:45.577877: Epoch 44 
2025-02-26 07:14:45.580410: Current learning rate: 0.00593 
2025-02-26 07:15:28.049593: train_loss -0.6339 
2025-02-26 07:15:28.056106: val_loss -0.516 
2025-02-26 07:15:28.059617: Pseudo dice [np.float32(0.7679), np.float32(0.352)] 
2025-02-26 07:15:28.062121: Epoch time: 42.48 s 
2025-02-26 07:15:28.703186:  
2025-02-26 07:15:28.708804: Epoch 45 
2025-02-26 07:15:28.712381: Current learning rate: 0.00584 
2025-02-26 07:16:11.178902: train_loss -0.6048 
2025-02-26 07:16:11.185008: val_loss -0.5005 
2025-02-26 07:16:11.188062: Pseudo dice [np.float32(0.753), np.float32(0.3858)] 
2025-02-26 07:16:11.191095: Epoch time: 42.48 s 
2025-02-26 07:16:11.680888:  
2025-02-26 07:16:11.686409: Epoch 46 
2025-02-26 07:16:11.689919: Current learning rate: 0.00574 
2025-02-26 07:16:54.159955: train_loss -0.6088 
2025-02-26 07:16:54.165983: val_loss -0.5048 
2025-02-26 07:16:54.168572: Pseudo dice [np.float32(0.7336), np.float32(0.3983)] 
2025-02-26 07:16:54.172642: Epoch time: 42.48 s 
2025-02-26 07:16:54.659812:  
2025-02-26 07:16:54.665327: Epoch 47 
2025-02-26 07:16:54.667833: Current learning rate: 0.00565 
2025-02-26 07:17:37.135270: train_loss -0.6194 
2025-02-26 07:17:37.141418: val_loss -0.5248 
2025-02-26 07:17:37.144423: Pseudo dice [np.float32(0.7282), np.float32(0.4225)] 
2025-02-26 07:17:37.147944: Epoch time: 42.48 s 
2025-02-26 07:17:37.648056:  
2025-02-26 07:17:37.653626: Epoch 48 
2025-02-26 07:17:37.657709: Current learning rate: 0.00555 
2025-02-26 07:18:20.163767: train_loss -0.6087 
2025-02-26 07:18:20.170843: val_loss -0.5285 
2025-02-26 07:18:20.174353: Pseudo dice [np.float32(0.7562), np.float32(0.4128)] 
2025-02-26 07:18:20.177365: Epoch time: 42.52 s 
2025-02-26 07:18:20.180879: Yayy! New best EMA pseudo Dice: 0.5698999762535095 
2025-02-26 07:18:20.838948:  
2025-02-26 07:18:20.844478: Epoch 49 
2025-02-26 07:18:20.847998: Current learning rate: 0.00546 
2025-02-26 07:19:03.312335: train_loss -0.6476 
2025-02-26 07:19:03.318353: val_loss -0.5148 
2025-02-26 07:19:03.321862: Pseudo dice [np.float32(0.7562), np.float32(0.4162)] 
2025-02-26 07:19:03.325877: Epoch time: 42.47 s 
2025-02-26 07:19:03.467392: Yayy! New best EMA pseudo Dice: 0.5715000033378601 
2025-02-26 07:19:04.124213:  
2025-02-26 07:19:04.129227: Epoch 50 
2025-02-26 07:19:04.132236: Current learning rate: 0.00536 
2025-02-26 07:19:46.597239: train_loss -0.626 
2025-02-26 07:19:46.603761: val_loss -0.5587 
2025-02-26 07:19:46.607276: Pseudo dice [np.float32(0.7477), np.float32(0.4878)] 
2025-02-26 07:19:46.610781: Epoch time: 42.47 s 
2025-02-26 07:19:46.613799: Yayy! New best EMA pseudo Dice: 0.576200008392334 
2025-02-26 07:19:47.279412:  
2025-02-26 07:19:47.284427: Epoch 51 
2025-02-26 07:19:47.287935: Current learning rate: 0.00526 
2025-02-26 07:20:29.762318: train_loss -0.6164 
2025-02-26 07:20:29.768332: val_loss -0.5756 
2025-02-26 07:20:29.772346: Pseudo dice [np.float32(0.749), np.float32(0.489)] 
2025-02-26 07:20:29.777362: Epoch time: 42.48 s 
2025-02-26 07:20:29.782377: Yayy! New best EMA pseudo Dice: 0.5803999900817871 
2025-02-26 07:20:30.436589:  
2025-02-26 07:20:30.441684: Epoch 52 
2025-02-26 07:20:30.444715: Current learning rate: 0.00517 
2025-02-26 07:21:12.946198: train_loss -0.6352 
2025-02-26 07:21:12.951711: val_loss -0.5846 
2025-02-26 07:21:12.955228: Pseudo dice [np.float32(0.7731), np.float32(0.5152)] 
2025-02-26 07:21:12.958732: Epoch time: 42.51 s 
2025-02-26 07:21:12.961742: Yayy! New best EMA pseudo Dice: 0.5867999792098999 
2025-02-26 07:21:13.756403:  
2025-02-26 07:21:13.761417: Epoch 53 
2025-02-26 07:21:13.764925: Current learning rate: 0.00507 
2025-02-26 07:21:56.295099: train_loss -0.6298 
2025-02-26 07:21:56.301231: val_loss -0.5651 
2025-02-26 07:21:56.304792: Pseudo dice [np.float32(0.7827), np.float32(0.4475)] 
2025-02-26 07:21:56.307851: Epoch time: 42.54 s 
2025-02-26 07:21:56.311882: Yayy! New best EMA pseudo Dice: 0.5896000266075134 
2025-02-26 07:21:56.964274:  
2025-02-26 07:21:56.970470: Epoch 54 
2025-02-26 07:21:56.972991: Current learning rate: 0.00497 
2025-02-26 07:22:39.503247: train_loss -0.6534 
2025-02-26 07:22:39.509266: val_loss -0.5928 
2025-02-26 07:22:39.513275: Pseudo dice [np.float32(0.7852), np.float32(0.4751)] 
2025-02-26 07:22:39.516788: Epoch time: 42.54 s 
2025-02-26 07:22:39.519293: Yayy! New best EMA pseudo Dice: 0.5936999917030334 
2025-02-26 07:22:40.171606:  
2025-02-26 07:22:40.177733: Epoch 55 
2025-02-26 07:22:40.181241: Current learning rate: 0.00487 
2025-02-26 07:23:22.709250: train_loss -0.6467 
2025-02-26 07:23:22.715780: val_loss -0.5747 
2025-02-26 07:23:22.718290: Pseudo dice [np.float32(0.783), np.float32(0.513)] 
2025-02-26 07:23:22.721810: Epoch time: 42.54 s 
2025-02-26 07:23:22.725316: Yayy! New best EMA pseudo Dice: 0.5990999937057495 
2025-02-26 07:23:23.384689:  
2025-02-26 07:23:23.390275: Epoch 56 
2025-02-26 07:23:23.393600: Current learning rate: 0.00478 
2025-02-26 07:24:05.929986: train_loss -0.6529 
2025-02-26 07:24:05.936008: val_loss -0.5285 
2025-02-26 07:24:05.941026: Pseudo dice [np.float32(0.7519), np.float32(0.357)] 
2025-02-26 07:24:05.945035: Epoch time: 42.55 s 
2025-02-26 07:24:06.444012:  
2025-02-26 07:24:06.449627: Epoch 57 
2025-02-26 07:24:06.453147: Current learning rate: 0.00468 
2025-02-26 07:24:48.979180: train_loss -0.6633 
2025-02-26 07:24:48.984198: val_loss -0.5348 
2025-02-26 07:24:48.987707: Pseudo dice [np.float32(0.7746), np.float32(0.3672)] 
2025-02-26 07:24:48.991214: Epoch time: 42.54 s 
2025-02-26 07:24:49.487057:  
2025-02-26 07:24:49.493653: Epoch 58 
2025-02-26 07:24:49.497203: Current learning rate: 0.00458 
2025-02-26 07:25:32.024749: train_loss -0.6416 
2025-02-26 07:25:32.030823: val_loss -0.5804 
2025-02-26 07:25:32.033889: Pseudo dice [np.float32(0.7742), np.float32(0.5171)] 
2025-02-26 07:25:32.036942: Epoch time: 42.54 s 
2025-02-26 07:25:32.545128:  
2025-02-26 07:25:32.550145: Epoch 59 
2025-02-26 07:25:32.554388: Current learning rate: 0.00448 
2025-02-26 07:26:15.074046: train_loss -0.6557 
2025-02-26 07:26:15.080564: val_loss -0.5146 
2025-02-26 07:26:15.084075: Pseudo dice [np.float32(0.7524), np.float32(0.2829)] 
2025-02-26 07:26:15.087585: Epoch time: 42.53 s 
2025-02-26 07:26:15.586644:  
2025-02-26 07:26:15.592710: Epoch 60 
2025-02-26 07:26:15.596230: Current learning rate: 0.00438 
2025-02-26 07:26:58.158061: train_loss -0.6555 
2025-02-26 07:26:58.164131: val_loss -0.5682 
2025-02-26 07:26:58.167698: Pseudo dice [np.float32(0.7734), np.float32(0.4913)] 
2025-02-26 07:26:58.170733: Epoch time: 42.57 s 
2025-02-26 07:26:58.671902:  
2025-02-26 07:26:58.677432: Epoch 61 
2025-02-26 07:26:58.680971: Current learning rate: 0.00429 
2025-02-26 07:27:41.204262: train_loss -0.6777 
2025-02-26 07:27:41.210775: val_loss -0.5884 
2025-02-26 07:27:41.215788: Pseudo dice [np.float32(0.7792), np.float32(0.5427)] 
2025-02-26 07:27:41.219297: Epoch time: 42.53 s 
2025-02-26 07:27:41.223340: Yayy! New best EMA pseudo Dice: 0.600600004196167 
2025-02-26 07:27:41.868945:  
2025-02-26 07:27:41.873962: Epoch 62 
2025-02-26 07:27:41.877594: Current learning rate: 0.00419 
2025-02-26 07:28:24.406761: train_loss -0.6767 
2025-02-26 07:28:24.413778: val_loss -0.5485 
2025-02-26 07:28:24.416791: Pseudo dice [np.float32(0.7522), np.float32(0.4145)] 
2025-02-26 07:28:24.420299: Epoch time: 42.54 s 
2025-02-26 07:28:24.928938:  
2025-02-26 07:28:24.933959: Epoch 63 
2025-02-26 07:28:24.937475: Current learning rate: 0.00409 
2025-02-26 07:29:07.493810: train_loss -0.6757 
2025-02-26 07:29:07.500331: val_loss -0.5564 
2025-02-26 07:29:07.503839: Pseudo dice [np.float32(0.7845), np.float32(0.4741)] 
2025-02-26 07:29:07.506847: Epoch time: 42.57 s 
2025-02-26 07:29:07.509933: Yayy! New best EMA pseudo Dice: 0.6018999814987183 
2025-02-26 07:29:08.191146:  
2025-02-26 07:29:08.196683: Epoch 64 
2025-02-26 07:29:08.200191: Current learning rate: 0.00399 
2025-02-26 07:29:50.725776: train_loss -0.6577 
2025-02-26 07:29:50.730884: val_loss -0.5324 
2025-02-26 07:29:50.735546: Pseudo dice [np.float32(0.7552), np.float32(0.4371)] 
2025-02-26 07:29:50.738053: Epoch time: 42.54 s 
2025-02-26 07:29:51.241178:  
2025-02-26 07:29:51.246733: Epoch 65 
2025-02-26 07:29:51.250772: Current learning rate: 0.00389 
2025-02-26 07:30:33.789047: train_loss -0.6555 
2025-02-26 07:30:33.795106: val_loss -0.5826 
2025-02-26 07:30:33.797629: Pseudo dice [np.float32(0.7784), np.float32(0.5067)] 
2025-02-26 07:30:33.801234: Epoch time: 42.55 s 
2025-02-26 07:30:33.805335: Yayy! New best EMA pseudo Dice: 0.6054999828338623 
2025-02-26 07:30:34.459188:  
2025-02-26 07:30:34.465211: Epoch 66 
2025-02-26 07:30:34.468723: Current learning rate: 0.00379 
2025-02-26 07:31:16.998088: train_loss -0.6848 
2025-02-26 07:31:17.004145: val_loss -0.5317 
2025-02-26 07:31:17.007176: Pseudo dice [np.float32(0.7635), np.float32(0.4306)] 
2025-02-26 07:31:17.010687: Epoch time: 42.54 s 
2025-02-26 07:31:17.513691:  
2025-02-26 07:31:17.519266: Epoch 67 
2025-02-26 07:31:17.522801: Current learning rate: 0.00369 
2025-02-26 07:32:00.145512: train_loss -0.6744 
2025-02-26 07:32:00.151181: val_loss -0.5684 
2025-02-26 07:32:00.155224: Pseudo dice [np.float32(0.7575), np.float32(0.5382)] 
2025-02-26 07:32:00.158299: Epoch time: 42.63 s 
2025-02-26 07:32:00.160837: Yayy! New best EMA pseudo Dice: 0.6089000105857849 
2025-02-26 07:32:00.965573:  
2025-02-26 07:32:00.972092: Epoch 68 
2025-02-26 07:32:00.974600: Current learning rate: 0.00359 
2025-02-26 07:32:43.677379: train_loss -0.6882 
2025-02-26 07:32:43.682945: val_loss -0.5572 
2025-02-26 07:32:43.686972: Pseudo dice [np.float32(0.7625), np.float32(0.4997)] 
2025-02-26 07:32:43.689981: Epoch time: 42.71 s 
2025-02-26 07:32:43.693493: Yayy! New best EMA pseudo Dice: 0.6111999750137329 
2025-02-26 07:32:44.370052:  
2025-02-26 07:32:44.375065: Epoch 69 
2025-02-26 07:32:44.378575: Current learning rate: 0.00349 
2025-02-26 07:33:27.095313: train_loss -0.689 
2025-02-26 07:33:27.102863: val_loss -0.5952 
2025-02-26 07:33:27.105481: Pseudo dice [np.float32(0.7909), np.float32(0.4571)] 
2025-02-26 07:33:27.108637: Epoch time: 42.73 s 
2025-02-26 07:33:27.112790: Yayy! New best EMA pseudo Dice: 0.6123999953269958 
2025-02-26 07:33:27.773910:  
2025-02-26 07:33:27.779975: Epoch 70 
2025-02-26 07:33:27.783006: Current learning rate: 0.00338 
2025-02-26 07:34:10.497323: train_loss -0.6986 
2025-02-26 07:34:10.501333: val_loss -0.5652 
2025-02-26 07:34:10.506346: Pseudo dice [np.float32(0.768), np.float32(0.4871)] 
2025-02-26 07:34:10.510355: Epoch time: 42.72 s 
2025-02-26 07:34:10.514864: Yayy! New best EMA pseudo Dice: 0.6140000224113464 
2025-02-26 07:34:11.181250:  
2025-02-26 07:34:11.186790: Epoch 71 
2025-02-26 07:34:11.190304: Current learning rate: 0.00328 
2025-02-26 07:34:53.907541: train_loss -0.6929 
2025-02-26 07:34:53.913556: val_loss -0.5451 
2025-02-26 07:34:53.917564: Pseudo dice [np.float32(0.7738), np.float32(0.4107)] 
2025-02-26 07:34:53.922074: Epoch time: 42.73 s 
2025-02-26 07:34:54.432863:  
2025-02-26 07:34:54.438411: Epoch 72 
2025-02-26 07:34:54.441920: Current learning rate: 0.00318 
2025-02-26 07:35:37.166337: train_loss -0.7027 
2025-02-26 07:35:37.172858: val_loss -0.5135 
2025-02-26 07:35:37.176368: Pseudo dice [np.float32(0.7564), np.float32(0.3111)] 
2025-02-26 07:35:37.178878: Epoch time: 42.73 s 
2025-02-26 07:35:37.692520:  
2025-02-26 07:35:37.698276: Epoch 73 
2025-02-26 07:35:37.700783: Current learning rate: 0.00308 
2025-02-26 07:36:20.413457: train_loss -0.7059 
2025-02-26 07:36:20.422605: val_loss -0.6164 
2025-02-26 07:36:20.426678: Pseudo dice [np.float32(0.7844), np.float32(0.526)] 
2025-02-26 07:36:20.431920: Epoch time: 42.72 s 
2025-02-26 07:36:20.942936:  
2025-02-26 07:36:20.948481: Epoch 74 
2025-02-26 07:36:20.954057: Current learning rate: 0.00297 
2025-02-26 07:37:03.592003: train_loss -0.708 
2025-02-26 07:37:03.598081: val_loss -0.545 
2025-02-26 07:37:03.602626: Pseudo dice [np.float32(0.7703), np.float32(0.4526)] 
2025-02-26 07:37:03.605703: Epoch time: 42.65 s 
2025-02-26 07:37:04.119571:  
2025-02-26 07:37:04.125085: Epoch 75 
2025-02-26 07:37:04.128600: Current learning rate: 0.00287 
2025-02-26 07:37:46.657640: train_loss -0.6922 
2025-02-26 07:37:46.663155: val_loss -0.5805 
2025-02-26 07:37:46.666663: Pseudo dice [np.float32(0.785), np.float32(0.5511)] 
2025-02-26 07:37:46.669174: Epoch time: 42.54 s 
2025-02-26 07:37:46.673184: Yayy! New best EMA pseudo Dice: 0.6151999831199646 
2025-02-26 07:37:47.492365:  
2025-02-26 07:37:47.497880: Epoch 76 
2025-02-26 07:37:47.501392: Current learning rate: 0.00277 
2025-02-26 07:38:30.198099: train_loss -0.6944 
2025-02-26 07:38:30.203687: val_loss -0.5671 
2025-02-26 07:38:30.206729: Pseudo dice [np.float32(0.802), np.float32(0.4144)] 
2025-02-26 07:38:30.210243: Epoch time: 42.71 s 
2025-02-26 07:38:30.729433:  
2025-02-26 07:38:30.734951: Epoch 77 
2025-02-26 07:38:30.738462: Current learning rate: 0.00266 
2025-02-26 07:39:13.448856: train_loss -0.7009 
2025-02-26 07:39:13.455431: val_loss -0.5652 
2025-02-26 07:39:13.458494: Pseudo dice [np.float32(0.803), np.float32(0.4524)] 
2025-02-26 07:39:13.461094: Epoch time: 42.72 s 
2025-02-26 07:39:13.465301: Yayy! New best EMA pseudo Dice: 0.6158000230789185 
2025-02-26 07:39:14.143381:  
2025-02-26 07:39:14.148401: Epoch 78 
2025-02-26 07:39:14.151915: Current learning rate: 0.00256 
2025-02-26 07:39:56.915640: train_loss -0.6991 
2025-02-26 07:39:56.922671: val_loss -0.5477 
2025-02-26 07:39:56.925987: Pseudo dice [np.float32(0.7702), np.float32(0.4113)] 
2025-02-26 07:39:56.930005: Epoch time: 42.77 s 
2025-02-26 07:39:57.451279:  
2025-02-26 07:39:57.456796: Epoch 79 
2025-02-26 07:39:57.460309: Current learning rate: 0.00245 
2025-02-26 07:40:40.168927: train_loss -0.7035 
2025-02-26 07:40:40.175517: val_loss -0.5527 
2025-02-26 07:40:40.179429: Pseudo dice [np.float32(0.7851), np.float32(0.4117)] 
2025-02-26 07:40:40.182480: Epoch time: 42.72 s 
2025-02-26 07:40:40.700494:  
2025-02-26 07:40:40.705526: Epoch 80 
2025-02-26 07:40:40.709091: Current learning rate: 0.00235 
2025-02-26 07:41:23.413363: train_loss -0.7032 
2025-02-26 07:41:23.420984: val_loss -0.5463 
2025-02-26 07:41:23.424061: Pseudo dice [np.float32(0.7787), np.float32(0.4404)] 
2025-02-26 07:41:23.428614: Epoch time: 42.71 s 
2025-02-26 07:41:23.949274:  
2025-02-26 07:41:23.954296: Epoch 81 
2025-02-26 07:41:23.957812: Current learning rate: 0.00224 
2025-02-26 07:42:06.685356: train_loss -0.7185 
2025-02-26 07:42:06.692379: val_loss -0.5477 
2025-02-26 07:42:06.697402: Pseudo dice [np.float32(0.7731), np.float32(0.4502)] 
2025-02-26 07:42:06.700414: Epoch time: 42.74 s 
2025-02-26 07:42:07.224098:  
2025-02-26 07:42:07.230171: Epoch 82 
2025-02-26 07:42:07.233717: Current learning rate: 0.00214 
2025-02-26 07:42:49.947083: train_loss -0.7222 
2025-02-26 07:42:49.953595: val_loss -0.5304 
2025-02-26 07:42:49.958607: Pseudo dice [np.float32(0.7559), np.float32(0.4346)] 
2025-02-26 07:42:49.962115: Epoch time: 42.72 s 
2025-02-26 07:42:50.458439:  
2025-02-26 07:42:50.463952: Epoch 83 
2025-02-26 07:42:50.467464: Current learning rate: 0.00203 
2025-02-26 07:43:33.173334: train_loss -0.719 
2025-02-26 07:43:33.179428: val_loss -0.5576 
2025-02-26 07:43:33.182986: Pseudo dice [np.float32(0.7801), np.float32(0.467)] 
2025-02-26 07:43:33.185018: Epoch time: 42.72 s 
2025-02-26 07:43:33.831934:  
2025-02-26 07:43:33.837451: Epoch 84 
2025-02-26 07:43:33.840960: Current learning rate: 0.00192 
2025-02-26 07:44:16.540841: train_loss -0.7204 
2025-02-26 07:44:16.547358: val_loss -0.5265 
2025-02-26 07:44:16.550869: Pseudo dice [np.float32(0.7516), np.float32(0.4295)] 
2025-02-26 07:44:16.554379: Epoch time: 42.71 s 
2025-02-26 07:44:17.047524:  
2025-02-26 07:44:17.054067: Epoch 85 
2025-02-26 07:44:17.056573: Current learning rate: 0.00181 
2025-02-26 07:44:59.781705: train_loss -0.7379 
2025-02-26 07:44:59.787724: val_loss -0.5983 
2025-02-26 07:44:59.791735: Pseudo dice [np.float32(0.7953), np.float32(0.4624)] 
2025-02-26 07:44:59.794241: Epoch time: 42.73 s 
2025-02-26 07:45:00.285836:  
2025-02-26 07:45:00.291352: Epoch 86 
2025-02-26 07:45:00.294865: Current learning rate: 0.0017 
2025-02-26 07:45:43.005196: train_loss -0.7414 
2025-02-26 07:45:43.011049: val_loss -0.5688 
2025-02-26 07:45:43.014080: Pseudo dice [np.float32(0.7808), np.float32(0.4815)] 
2025-02-26 07:45:43.017593: Epoch time: 42.72 s 
2025-02-26 07:45:43.509728:  
2025-02-26 07:45:43.515297: Epoch 87 
2025-02-26 07:45:43.518347: Current learning rate: 0.00159 
2025-02-26 07:46:26.230035: train_loss -0.7204 
2025-02-26 07:46:26.236688: val_loss -0.5824 
2025-02-26 07:46:26.240780: Pseudo dice [np.float32(0.8015), np.float32(0.4861)] 
2025-02-26 07:46:26.243834: Epoch time: 42.72 s 
2025-02-26 07:46:26.246884: Yayy! New best EMA pseudo Dice: 0.6162999868392944 
2025-02-26 07:46:26.877624:  
2025-02-26 07:46:26.884138: Epoch 88 
2025-02-26 07:46:26.887651: Current learning rate: 0.00148 
2025-02-26 07:47:09.615501: train_loss -0.7229 
2025-02-26 07:47:09.622018: val_loss -0.5533 
2025-02-26 07:47:09.625528: Pseudo dice [np.float32(0.7802), np.float32(0.4768)] 
2025-02-26 07:47:09.629540: Epoch time: 42.74 s 
2025-02-26 07:47:09.634557: Yayy! New best EMA pseudo Dice: 0.6175000071525574 
2025-02-26 07:47:10.289647:  
2025-02-26 07:47:10.295274: Epoch 89 
2025-02-26 07:47:10.298335: Current learning rate: 0.00137 
2025-02-26 07:47:53.011811: train_loss -0.7498 
2025-02-26 07:47:53.017355: val_loss -0.5268 
2025-02-26 07:47:53.021936: Pseudo dice [np.float32(0.7707), np.float32(0.4123)] 
2025-02-26 07:47:53.025446: Epoch time: 42.72 s 
2025-02-26 07:47:53.518746:  
2025-02-26 07:47:53.525315: Epoch 90 
2025-02-26 07:47:53.528864: Current learning rate: 0.00126 
2025-02-26 07:48:36.251232: train_loss -0.7485 
2025-02-26 07:48:36.257163: val_loss -0.5688 
2025-02-26 07:48:36.261172: Pseudo dice [np.float32(0.7892), np.float32(0.5545)] 
2025-02-26 07:48:36.266188: Epoch time: 42.73 s 
2025-02-26 07:48:36.269699: Yayy! New best EMA pseudo Dice: 0.6205999851226807 
2025-02-26 07:48:36.915076:  
2025-02-26 07:48:36.923148: Epoch 91 
2025-02-26 07:48:36.926443: Current learning rate: 0.00115 
2025-02-26 07:49:19.648536: train_loss -0.7623 
2025-02-26 07:49:19.655174: val_loss -0.5591 
2025-02-26 07:49:19.660268: Pseudo dice [np.float32(0.7934), np.float32(0.4602)] 
2025-02-26 07:49:19.664816: Epoch time: 42.73 s 
2025-02-26 07:49:19.668329: Yayy! New best EMA pseudo Dice: 0.6212000250816345 
2025-02-26 07:49:20.462049:  
2025-02-26 07:49:20.469702: Epoch 92 
2025-02-26 07:49:20.473758: Current learning rate: 0.00103 
2025-02-26 07:50:03.187410: train_loss -0.739 
2025-02-26 07:50:03.195066: val_loss -0.5764 
2025-02-26 07:50:03.199233: Pseudo dice [np.float32(0.7803), np.float32(0.4645)] 
2025-02-26 07:50:03.202779: Epoch time: 42.73 s 
2025-02-26 07:50:03.207322: Yayy! New best EMA pseudo Dice: 0.6212999820709229 
2025-02-26 07:50:03.857927:  
2025-02-26 07:50:03.865507: Epoch 93 
2025-02-26 07:50:03.872117: Current learning rate: 0.00091 
2025-02-26 07:50:46.593166: train_loss -0.7528 
2025-02-26 07:50:46.600276: val_loss -0.5866 
2025-02-26 07:50:46.603818: Pseudo dice [np.float32(0.7976), np.float32(0.5205)] 
2025-02-26 07:50:46.608391: Epoch time: 42.74 s 
2025-02-26 07:50:46.613045: Yayy! New best EMA pseudo Dice: 0.6251000165939331 
2025-02-26 07:50:47.255498:  
2025-02-26 07:50:47.262079: Epoch 94 
2025-02-26 07:50:47.265629: Current learning rate: 0.00079 
2025-02-26 07:51:30.076178: train_loss -0.7672 
2025-02-26 07:51:30.082744: val_loss -0.5601 
2025-02-26 07:51:30.086775: Pseudo dice [np.float32(0.7853), np.float32(0.4515)] 
2025-02-26 07:51:30.089805: Epoch time: 42.82 s 
2025-02-26 07:51:30.583310:  
2025-02-26 07:51:30.590412: Epoch 95 
2025-02-26 07:51:30.593443: Current learning rate: 0.00067 
2025-02-26 07:52:13.326092: train_loss -0.7571 
2025-02-26 07:52:13.332257: val_loss -0.5218 
2025-02-26 07:52:13.335819: Pseudo dice [np.float32(0.7893), np.float32(0.3488)] 
2025-02-26 07:52:13.338896: Epoch time: 42.74 s 
2025-02-26 07:52:13.831213:  
2025-02-26 07:52:13.836767: Epoch 96 
2025-02-26 07:52:13.840343: Current learning rate: 0.00055 
2025-02-26 07:52:56.569100: train_loss -0.7547 
2025-02-26 07:52:56.575191: val_loss -0.5362 
2025-02-26 07:52:56.577736: Pseudo dice [np.float32(0.7846), np.float32(0.3563)] 
2025-02-26 07:52:56.582308: Epoch time: 42.74 s 
2025-02-26 07:52:57.080571:  
2025-02-26 07:52:57.085274: Epoch 97 
2025-02-26 07:52:57.090162: Current learning rate: 0.00043 
2025-02-26 07:53:39.821669: train_loss -0.7472 
2025-02-26 07:53:39.828186: val_loss -0.581 
2025-02-26 07:53:39.833203: Pseudo dice [np.float32(0.8058), np.float32(0.5579)] 
2025-02-26 07:53:39.837716: Epoch time: 42.74 s 
2025-02-26 07:53:40.504510:  
2025-02-26 07:53:40.511129: Epoch 98 
2025-02-26 07:53:40.514665: Current learning rate: 0.0003 
2025-02-26 07:54:23.207784: train_loss -0.7563 
2025-02-26 07:54:23.214391: val_loss -0.574 
2025-02-26 07:54:23.217901: Pseudo dice [np.float32(0.8064), np.float32(0.502)] 
2025-02-26 07:54:23.221408: Epoch time: 42.7 s 
2025-02-26 07:54:23.721727:  
2025-02-26 07:54:23.726892: Epoch 99 
2025-02-26 07:54:23.730443: Current learning rate: 0.00016 
2025-02-26 07:55:06.445121: train_loss -0.7514 
2025-02-26 07:55:06.452638: val_loss -0.5725 
2025-02-26 07:55:06.456659: Pseudo dice [np.float32(0.7814), np.float32(0.4362)] 
2025-02-26 07:55:06.460761: Epoch time: 42.72 s 
2025-02-26 07:55:07.325092: Training done. 
2025-02-26 07:55:07.355093: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-02-26 07:55:07.361093: The split file contains 5 splits. 
2025-02-26 07:55:07.367092: Desired fold for training: 0 
2025-02-26 07:55:07.372092: This split has 224 training and 57 validation cases. 
2025-02-26 07:55:07.377092: predicting pancreas_021 
2025-02-26 07:55:07.384096: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-02-26 07:55:20.389583: predicting pancreas_024 
2025-02-26 07:55:20.407583: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-02-26 07:55:35.784109: predicting pancreas_035 
2025-02-26 07:55:35.803117: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-02-26 07:55:41.028037: predicting pancreas_040 
2025-02-26 07:55:41.040036: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-02-26 07:55:53.345926: predicting pancreas_042 
2025-02-26 07:55:53.362928: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-02-26 07:56:08.769694: predicting pancreas_056 
2025-02-26 07:56:08.787694: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-02-26 07:56:21.075945: predicting pancreas_067 
2025-02-26 07:56:21.090944: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-02-26 07:56:36.470652: predicting pancreas_075 
2025-02-26 07:56:36.490651: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-02-26 07:56:42.687060: predicting pancreas_086 
2025-02-26 07:56:42.702063: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-02-26 07:56:52.317840: predicting pancreas_089 
2025-02-26 07:56:52.333840: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-02-26 07:57:04.627654: predicting pancreas_092 
2025-02-26 07:57:04.642654: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-02-26 07:57:32.238285: predicting pancreas_094 
2025-02-26 07:57:32.266287: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-02-26 07:57:44.577341: predicting pancreas_095 
2025-02-26 07:57:44.595346: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-02-26 07:57:56.915253: predicting pancreas_098 
2025-02-26 07:57:56.930255: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-02-26 07:58:30.481286: predicting pancreas_109 
2025-02-26 07:58:30.507290: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-02-26 07:58:42.882728: predicting pancreas_110 
2025-02-26 07:58:42.901727: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-02-26 07:59:02.125965: predicting pancreas_114 
2025-02-26 07:59:02.145971: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-02-26 07:59:14.484508: predicting pancreas_119 
2025-02-26 07:59:14.501508: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-02-26 07:59:33.720759: predicting pancreas_138 
2025-02-26 07:59:33.738761: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-02-26 07:59:52.959659: predicting pancreas_145 
2025-02-26 07:59:52.979662: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-02-26 08:00:12.269924: predicting pancreas_148 
2025-02-26 08:00:12.288925: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-02-26 08:00:24.950373: predicting pancreas_169 
2025-02-26 08:00:24.969373: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-02-26 08:00:37.293239: predicting pancreas_170 
2025-02-26 08:00:37.311243: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-02-26 08:00:52.674892: predicting pancreas_172 
2025-02-26 08:00:52.693892: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-02-26 08:01:05.015497: predicting pancreas_175 
2025-02-26 08:01:05.030503: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-02-26 08:01:17.336640: predicting pancreas_180 
2025-02-26 08:01:17.353149: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-02-26 08:01:29.654855: predicting pancreas_191 
2025-02-26 08:01:29.672350: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-02-26 08:01:35.865208: predicting pancreas_193 
2025-02-26 08:01:35.879212: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-02-26 08:01:51.292551: predicting pancreas_212 
2025-02-26 08:01:51.310549: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-02-26 08:02:03.664581: predicting pancreas_215 
2025-02-26 08:02:03.684087: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-02-26 08:02:16.013685: predicting pancreas_222 
2025-02-26 08:02:16.029685: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-02-26 08:02:21.267029: predicting pancreas_235 
2025-02-26 08:02:21.283036: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-02-26 08:02:33.599683: predicting pancreas_241 
2025-02-26 08:02:33.618201: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-02-26 08:02:45.991834: predicting pancreas_242 
2025-02-26 08:02:46.011838: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-02-26 08:03:01.418306: predicting pancreas_244 
2025-02-26 08:03:01.436814: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-02-26 08:03:25.396567: predicting pancreas_246 
2025-02-26 08:03:25.417568: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-02-26 08:03:49.398389: predicting pancreas_247 
2025-02-26 08:03:49.420393: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-02-26 08:03:56.400546: predicting pancreas_264 
2025-02-26 08:03:56.417546: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-02-26 08:04:11.828227: predicting pancreas_265 
2025-02-26 08:04:11.846227: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-02-26 08:04:24.176122: predicting pancreas_266 
2025-02-26 08:04:24.194121: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-02-26 08:04:43.385732: predicting pancreas_267 
2025-02-26 08:04:43.402835: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-02-26 08:04:50.392102: predicting pancreas_275 
2025-02-26 08:04:50.407109: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-02-26 08:05:05.772980: predicting pancreas_279 
2025-02-26 08:05:05.787986: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-02-26 08:05:11.044468: predicting pancreas_287 
2025-02-26 08:05:11.058472: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-02-26 08:05:23.373593: predicting pancreas_301 
2025-02-26 08:05:23.389593: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-02-26 08:05:35.728886: predicting pancreas_323 
2025-02-26 08:05:35.746886: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-02-26 08:05:54.954211: predicting pancreas_336 
2025-02-26 08:05:54.973211: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-02-26 08:06:07.349352: predicting pancreas_344 
2025-02-26 08:06:07.368352: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-02-26 08:06:22.771494: predicting pancreas_351 
2025-02-26 08:06:22.788494: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-02-26 08:06:29.777890: predicting pancreas_354 
2025-02-26 08:06:29.791891: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-02-26 08:06:54.351195: predicting pancreas_372 
2025-02-26 08:06:54.374200: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-02-26 08:07:13.659786: predicting pancreas_377 
2025-02-26 08:07:13.681786: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-02-26 08:07:29.103340: predicting pancreas_387 
2025-02-26 08:07:29.121477: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-02-26 08:07:41.453367: predicting pancreas_391 
2025-02-26 08:07:41.474370: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-02-26 08:08:00.664117: predicting pancreas_392 
2025-02-26 08:08:00.681117: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-02-26 08:08:09.385275: predicting pancreas_410 
2025-02-26 08:08:09.399274: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-02-26 08:08:18.097127: predicting pancreas_412 
2025-02-26 08:08:18.111127: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-02-26 08:09:18.699131: Validation complete 
2025-02-26 08:09:18.705128: Mean Validation Dice:  0.3480582406472868 
