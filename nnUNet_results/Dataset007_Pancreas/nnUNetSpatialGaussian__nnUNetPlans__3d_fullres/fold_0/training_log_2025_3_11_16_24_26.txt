
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-11 16:24:26.491833: do_dummy_2d_data_aug: True 
2025-03-11 16:24:26.507671: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-03-11 16:24:26.515699: The split file contains 5 splits. 
2025-03-11 16:24:26.518260: Desired fold for training: 0 
2025-03-11 16:24:26.520879: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-03-11 16:24:35.396490: unpacking dataset... 
2025-03-11 16:24:56.040744: unpacking done... 
2025-03-11 16:25:00.276034:  
2025-03-11 16:25:00.281168: Epoch 0 
2025-03-11 16:25:00.284745: Current learning rate: 0.01 
2025-03-11 16:25:47.630388: train_loss 0.0821 
2025-03-11 16:25:47.636086: val_loss -0.0038 
2025-03-11 16:25:47.639624: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-03-11 16:25:47.642654: Epoch time: 47.35 s 
2025-03-11 16:25:47.645689: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-11 16:25:48.312436:  
2025-03-11 16:25:48.318019: Epoch 1 
2025-03-11 16:25:48.321568: Current learning rate: 0.00991 
2025-03-11 16:26:30.764383: train_loss -0.0932 
2025-03-11 16:26:30.771027: val_loss -0.2024 
2025-03-11 16:26:30.774659: Pseudo dice [np.float32(0.5595), np.float32(0.0)] 
2025-03-11 16:26:30.777784: Epoch time: 42.45 s 
2025-03-11 16:26:30.780929: Yayy! New best EMA pseudo Dice: 0.02800000086426735 
2025-03-11 16:26:31.525269:  
2025-03-11 16:26:31.530937: Epoch 2 
2025-03-11 16:26:31.534571: Current learning rate: 0.00982 
2025-03-11 16:27:13.981490: train_loss -0.1993 
2025-03-11 16:27:13.988276: val_loss -0.2685 
2025-03-11 16:27:13.992138: Pseudo dice [np.float32(0.644), np.float32(0.0)] 
2025-03-11 16:27:13.995198: Epoch time: 42.46 s 
2025-03-11 16:27:13.998764: Yayy! New best EMA pseudo Dice: 0.05739999935030937 
2025-03-11 16:27:14.764950:  
2025-03-11 16:27:14.771170: Epoch 3 
2025-03-11 16:27:14.774794: Current learning rate: 0.00973 
2025-03-11 16:27:57.189555: train_loss -0.2133 
2025-03-11 16:27:57.195828: val_loss -0.2983 
2025-03-11 16:27:57.198401: Pseudo dice [np.float32(0.6355), np.float32(0.0)] 
2025-03-11 16:27:57.202392: Epoch time: 42.43 s 
2025-03-11 16:27:57.204968: Yayy! New best EMA pseudo Dice: 0.08340000361204147 
2025-03-11 16:27:57.952296:  
2025-03-11 16:27:57.958881: Epoch 4 
2025-03-11 16:27:57.961918: Current learning rate: 0.00964 
2025-03-11 16:28:40.385649: train_loss -0.2542 
2025-03-11 16:28:40.392309: val_loss -0.367 
2025-03-11 16:28:40.396082: Pseudo dice [np.float32(0.659), np.float32(0.2936)] 
2025-03-11 16:28:40.399209: Epoch time: 42.43 s 
2025-03-11 16:28:40.402322: Yayy! New best EMA pseudo Dice: 0.12269999831914902 
2025-03-11 16:28:41.289128:  
2025-03-11 16:28:41.294836: Epoch 5 
2025-03-11 16:28:41.298007: Current learning rate: 0.00955 
2025-03-11 16:29:23.709779: train_loss -0.3072 
2025-03-11 16:29:23.716336: val_loss -0.3881 
2025-03-11 16:29:23.719866: Pseudo dice [np.float32(0.684), np.float32(0.2649)] 
2025-03-11 16:29:23.723392: Epoch time: 42.42 s 
2025-03-11 16:29:23.726433: Yayy! New best EMA pseudo Dice: 0.15790000557899475 
2025-03-11 16:29:24.438301:  
2025-03-11 16:29:24.443862: Epoch 6 
2025-03-11 16:29:24.447951: Current learning rate: 0.00946 
2025-03-11 16:30:06.878575: train_loss -0.3344 
2025-03-11 16:30:06.884760: val_loss -0.3572 
2025-03-11 16:30:06.888312: Pseudo dice [np.float32(0.6125), np.float32(0.2457)] 
2025-03-11 16:30:06.891483: Epoch time: 42.44 s 
2025-03-11 16:30:06.893996: Yayy! New best EMA pseudo Dice: 0.1850000023841858 
2025-03-11 16:30:07.638392:  
2025-03-11 16:30:07.644549: Epoch 7 
2025-03-11 16:30:07.647587: Current learning rate: 0.00937 
2025-03-11 16:30:50.059894: train_loss -0.3539 
2025-03-11 16:30:50.066312: val_loss -0.4252 
2025-03-11 16:30:50.070460: Pseudo dice [np.float32(0.6738), np.float32(0.3387)] 
2025-03-11 16:30:50.073557: Epoch time: 42.42 s 
2025-03-11 16:30:50.076690: Yayy! New best EMA pseudo Dice: 0.21709999442100525 
2025-03-11 16:30:50.826394:  
2025-03-11 16:30:50.832443: Epoch 8 
2025-03-11 16:30:50.835989: Current learning rate: 0.00928 
2025-03-11 16:31:33.258244: train_loss -0.3684 
2025-03-11 16:31:33.264350: val_loss -0.4561 
2025-03-11 16:31:33.267945: Pseudo dice [np.float32(0.6938), np.float32(0.3898)] 
2025-03-11 16:31:33.271016: Epoch time: 42.43 s 
2025-03-11 16:31:33.273704: Yayy! New best EMA pseudo Dice: 0.24959999322891235 
2025-03-11 16:31:34.022301:  
2025-03-11 16:31:34.028405: Epoch 9 
2025-03-11 16:31:34.032031: Current learning rate: 0.00919 
2025-03-11 16:32:16.443063: train_loss -0.3906 
2025-03-11 16:32:16.449509: val_loss -0.3865 
2025-03-11 16:32:16.452716: Pseudo dice [np.float32(0.6703), np.float32(0.2398)] 
2025-03-11 16:32:16.456431: Epoch time: 42.42 s 
2025-03-11 16:32:16.459536: Yayy! New best EMA pseudo Dice: 0.2700999975204468 
2025-03-11 16:32:17.197567:  
2025-03-11 16:32:17.203785: Epoch 10 
2025-03-11 16:32:17.207078: Current learning rate: 0.0091 
2025-03-11 16:32:59.602270: train_loss -0.4211 
2025-03-11 16:32:59.608205: val_loss -0.4432 
2025-03-11 16:32:59.611853: Pseudo dice [np.float32(0.6973), np.float32(0.4065)] 
2025-03-11 16:32:59.614902: Epoch time: 42.41 s 
2025-03-11 16:32:59.617933: Yayy! New best EMA pseudo Dice: 0.29829999804496765 
2025-03-11 16:33:00.346426:  
2025-03-11 16:33:00.352603: Epoch 11 
2025-03-11 16:33:00.355160: Current learning rate: 0.009 
2025-03-11 16:33:42.768310: train_loss -0.4463 
2025-03-11 16:33:42.774648: val_loss -0.4664 
2025-03-11 16:33:42.778248: Pseudo dice [np.float32(0.7002), np.float32(0.3514)] 
2025-03-11 16:33:42.781438: Epoch time: 42.42 s 
2025-03-11 16:33:42.784561: Yayy! New best EMA pseudo Dice: 0.32109999656677246 
2025-03-11 16:33:43.505104:  
2025-03-11 16:33:43.510730: Epoch 12 
2025-03-11 16:33:43.514389: Current learning rate: 0.00891 
2025-03-11 16:34:25.909419: train_loss -0.4462 
2025-03-11 16:34:25.915117: val_loss -0.4397 
2025-03-11 16:34:25.918226: Pseudo dice [np.float32(0.6895), np.float32(0.3385)] 
2025-03-11 16:34:25.921855: Epoch time: 42.4 s 
2025-03-11 16:34:25.925016: Yayy! New best EMA pseudo Dice: 0.34040001034736633 
2025-03-11 16:34:26.809274:  
2025-03-11 16:34:26.814974: Epoch 13 
2025-03-11 16:34:26.818357: Current learning rate: 0.00882 
2025-03-11 16:35:09.240029: train_loss -0.4599 
2025-03-11 16:35:09.247319: val_loss -0.5004 
2025-03-11 16:35:09.250480: Pseudo dice [np.float32(0.7326), np.float32(0.4207)] 
2025-03-11 16:35:09.253518: Epoch time: 42.43 s 
2025-03-11 16:35:09.257071: Yayy! New best EMA pseudo Dice: 0.36399999260902405 
2025-03-11 16:35:09.994726:  
2025-03-11 16:35:10.000425: Epoch 14 
2025-03-11 16:35:10.003652: Current learning rate: 0.00873 
2025-03-11 16:35:52.417525: train_loss -0.4368 
2025-03-11 16:35:52.424157: val_loss -0.5033 
2025-03-11 16:35:52.427317: Pseudo dice [np.float32(0.7314), np.float32(0.4233)] 
2025-03-11 16:35:52.430923: Epoch time: 42.42 s 
2025-03-11 16:35:52.434114: Yayy! New best EMA pseudo Dice: 0.38530001044273376 
2025-03-11 16:35:53.192469:  
2025-03-11 16:35:53.198614: Epoch 15 
2025-03-11 16:35:53.202317: Current learning rate: 0.00864 
2025-03-11 16:36:35.601176: train_loss -0.4482 
2025-03-11 16:36:35.607358: val_loss -0.4756 
2025-03-11 16:36:35.610960: Pseudo dice [np.float32(0.7021), np.float32(0.4153)] 
2025-03-11 16:36:35.614605: Epoch time: 42.41 s 
2025-03-11 16:36:35.617128: Yayy! New best EMA pseudo Dice: 0.4027000069618225 
2025-03-11 16:36:36.363526:  
2025-03-11 16:36:36.368808: Epoch 16 
2025-03-11 16:36:36.372968: Current learning rate: 0.00855 
2025-03-11 16:37:18.778572: train_loss -0.4716 
2025-03-11 16:37:18.785263: val_loss -0.446 
2025-03-11 16:37:18.788844: Pseudo dice [np.float32(0.7162), np.float32(0.2436)] 
2025-03-11 16:37:18.792768: Epoch time: 42.42 s 
2025-03-11 16:37:18.795319: Yayy! New best EMA pseudo Dice: 0.41040000319480896 
2025-03-11 16:37:19.550530:  
2025-03-11 16:37:19.555567: Epoch 17 
2025-03-11 16:37:19.559587: Current learning rate: 0.00846 
2025-03-11 16:38:01.976663: train_loss -0.4876 
2025-03-11 16:38:01.982893: val_loss -0.5158 
2025-03-11 16:38:01.986574: Pseudo dice [np.float32(0.7464), np.float32(0.461)] 
2025-03-11 16:38:01.989685: Epoch time: 42.43 s 
2025-03-11 16:38:01.993324: Yayy! New best EMA pseudo Dice: 0.42969998717308044 
2025-03-11 16:38:02.740292:  
2025-03-11 16:38:02.745474: Epoch 18 
2025-03-11 16:38:02.750072: Current learning rate: 0.00836 
2025-03-11 16:38:45.135871: train_loss -0.5168 
2025-03-11 16:38:45.142098: val_loss -0.4411 
2025-03-11 16:38:45.145196: Pseudo dice [np.float32(0.7023), np.float32(0.2511)] 
2025-03-11 16:38:45.148933: Epoch time: 42.4 s 
2025-03-11 16:38:45.152019: Yayy! New best EMA pseudo Dice: 0.4343999922275543 
2025-03-11 16:38:45.899711:  
2025-03-11 16:38:45.905369: Epoch 19 
2025-03-11 16:38:45.909666: Current learning rate: 0.00827 
2025-03-11 16:39:28.295186: train_loss -0.5089 
2025-03-11 16:39:28.301464: val_loss -0.4879 
2025-03-11 16:39:28.305140: Pseudo dice [np.float32(0.7242), np.float32(0.3925)] 
2025-03-11 16:39:28.308195: Epoch time: 42.4 s 
2025-03-11 16:39:28.311424: Yayy! New best EMA pseudo Dice: 0.44679999351501465 
2025-03-11 16:39:29.067457:  
2025-03-11 16:39:29.074149: Epoch 20 
2025-03-11 16:39:29.077768: Current learning rate: 0.00818 
2025-03-11 16:40:11.459115: train_loss -0.519 
2025-03-11 16:40:11.464798: val_loss -0.5146 
2025-03-11 16:40:11.468416: Pseudo dice [np.float32(0.7441), np.float32(0.3701)] 
2025-03-11 16:40:11.470997: Epoch time: 42.39 s 
2025-03-11 16:40:11.475075: Yayy! New best EMA pseudo Dice: 0.4578000009059906 
2025-03-11 16:40:12.378437:  
2025-03-11 16:40:12.384257: Epoch 21 
2025-03-11 16:40:12.387830: Current learning rate: 0.00809 
2025-03-11 16:40:54.777705: train_loss -0.5239 
2025-03-11 16:40:54.783402: val_loss -0.5251 
2025-03-11 16:40:54.787628: Pseudo dice [np.float32(0.733), np.float32(0.4462)] 
2025-03-11 16:40:54.790667: Epoch time: 42.4 s 
2025-03-11 16:40:54.793389: Yayy! New best EMA pseudo Dice: 0.47099998593330383 
2025-03-11 16:40:55.522411:  
2025-03-11 16:40:55.528562: Epoch 22 
2025-03-11 16:40:55.530582: Current learning rate: 0.008 
2025-03-11 16:41:37.918818: train_loss -0.5146 
2025-03-11 16:41:37.924859: val_loss -0.4729 
2025-03-11 16:41:37.928403: Pseudo dice [np.float32(0.7377), np.float32(0.2975)] 
2025-03-11 16:41:37.931946: Epoch time: 42.4 s 
2025-03-11 16:41:37.935474: Yayy! New best EMA pseudo Dice: 0.4756999909877777 
2025-03-11 16:41:38.651739:  
2025-03-11 16:41:38.657971: Epoch 23 
2025-03-11 16:41:38.661633: Current learning rate: 0.0079 
2025-03-11 16:42:21.053815: train_loss -0.5124 
2025-03-11 16:42:21.060389: val_loss -0.5006 
2025-03-11 16:42:21.063986: Pseudo dice [np.float32(0.7355), np.float32(0.3723)] 
2025-03-11 16:42:21.067136: Epoch time: 42.4 s 
2025-03-11 16:42:21.069706: Yayy! New best EMA pseudo Dice: 0.48350000381469727 
2025-03-11 16:42:21.792683:  
2025-03-11 16:42:21.799038: Epoch 24 
2025-03-11 16:42:21.802113: Current learning rate: 0.00781 
2025-03-11 16:43:04.196012: train_loss -0.5463 
2025-03-11 16:43:04.202764: val_loss -0.5233 
2025-03-11 16:43:04.205864: Pseudo dice [np.float32(0.7266), np.float32(0.4457)] 
2025-03-11 16:43:04.209502: Epoch time: 42.4 s 
2025-03-11 16:43:04.212658: Yayy! New best EMA pseudo Dice: 0.49380001425743103 
2025-03-11 16:43:04.949726:  
2025-03-11 16:43:04.955609: Epoch 25 
2025-03-11 16:43:04.959294: Current learning rate: 0.00772 
2025-03-11 16:43:47.356495: train_loss -0.5411 
2025-03-11 16:43:47.363284: val_loss -0.5523 
2025-03-11 16:43:47.366513: Pseudo dice [np.float32(0.753), np.float32(0.4388)] 
2025-03-11 16:43:47.369973: Epoch time: 42.41 s 
2025-03-11 16:43:47.373121: Yayy! New best EMA pseudo Dice: 0.5040000081062317 
2025-03-11 16:43:48.099054:  
2025-03-11 16:43:48.104786: Epoch 26 
2025-03-11 16:43:48.108448: Current learning rate: 0.00763 
2025-03-11 16:44:30.513785: train_loss -0.5209 
2025-03-11 16:44:30.520430: val_loss -0.5188 
2025-03-11 16:44:30.523602: Pseudo dice [np.float32(0.7218), np.float32(0.459)] 
2025-03-11 16:44:30.527245: Epoch time: 42.42 s 
2025-03-11 16:44:30.530359: Yayy! New best EMA pseudo Dice: 0.5126000046730042 
2025-03-11 16:44:31.267296:  
2025-03-11 16:44:31.273565: Epoch 27 
2025-03-11 16:44:31.277013: Current learning rate: 0.00753 
2025-03-11 16:45:13.669145: train_loss -0.5525 
2025-03-11 16:45:13.675192: val_loss -0.4956 
2025-03-11 16:45:13.678780: Pseudo dice [np.float32(0.7381), np.float32(0.3558)] 
2025-03-11 16:45:13.681826: Epoch time: 42.4 s 
2025-03-11 16:45:13.685359: Yayy! New best EMA pseudo Dice: 0.5160999894142151 
2025-03-11 16:45:14.413501:  
2025-03-11 16:45:14.419641: Epoch 28 
2025-03-11 16:45:14.423258: Current learning rate: 0.00744 
2025-03-11 16:45:56.824543: train_loss -0.5715 
2025-03-11 16:45:56.831094: val_loss -0.5627 
2025-03-11 16:45:56.834616: Pseudo dice [np.float32(0.7516), np.float32(0.4751)] 
2025-03-11 16:45:56.837667: Epoch time: 42.41 s 
2025-03-11 16:45:56.840186: Yayy! New best EMA pseudo Dice: 0.5257999897003174 
2025-03-11 16:45:57.748587:  
2025-03-11 16:45:57.754327: Epoch 29 
2025-03-11 16:45:57.757373: Current learning rate: 0.00735 
2025-03-11 16:46:40.158237: train_loss -0.5751 
2025-03-11 16:46:40.163950: val_loss -0.5606 
2025-03-11 16:46:40.167072: Pseudo dice [np.float32(0.7694), np.float32(0.4833)] 
2025-03-11 16:46:40.170608: Epoch time: 42.41 s 
2025-03-11 16:46:40.173661: Yayy! New best EMA pseudo Dice: 0.5357999801635742 
2025-03-11 16:46:40.919438:  
2025-03-11 16:46:40.925377: Epoch 30 
2025-03-11 16:46:40.929061: Current learning rate: 0.00725 
2025-03-11 16:47:23.490675: train_loss -0.5618 
2025-03-11 16:47:23.497346: val_loss -0.5504 
2025-03-11 16:47:23.500910: Pseudo dice [np.float32(0.7786), np.float32(0.4729)] 
2025-03-11 16:47:23.503997: Epoch time: 42.57 s 
2025-03-11 16:47:23.507597: Yayy! New best EMA pseudo Dice: 0.5447999835014343 
2025-03-11 16:47:24.265583:  
2025-03-11 16:47:24.270683: Epoch 31 
2025-03-11 16:47:24.274842: Current learning rate: 0.00716 
2025-03-11 16:48:06.758527: train_loss -0.5787 
2025-03-11 16:48:06.764803: val_loss -0.4907 
2025-03-11 16:48:06.768415: Pseudo dice [np.float32(0.7565), np.float32(0.3684)] 
2025-03-11 16:48:06.771530: Epoch time: 42.49 s 
2025-03-11 16:48:06.774562: Yayy! New best EMA pseudo Dice: 0.5465999841690063 
2025-03-11 16:48:07.509124:  
2025-03-11 16:48:07.513278: Epoch 32 
2025-03-11 16:48:07.516492: Current learning rate: 0.00707 
2025-03-11 16:48:49.904976: train_loss -0.5869 
2025-03-11 16:48:49.911703: val_loss -0.5317 
2025-03-11 16:48:49.915347: Pseudo dice [np.float32(0.7527), np.float32(0.4384)] 
2025-03-11 16:48:49.919061: Epoch time: 42.4 s 
2025-03-11 16:48:49.922171: Yayy! New best EMA pseudo Dice: 0.5515000224113464 
2025-03-11 16:48:50.666695:  
2025-03-11 16:48:50.672905: Epoch 33 
2025-03-11 16:48:50.675980: Current learning rate: 0.00697 
2025-03-11 16:49:33.080810: train_loss -0.564 
2025-03-11 16:49:33.086460: val_loss -0.5091 
2025-03-11 16:49:33.090675: Pseudo dice [np.float32(0.7476), np.float32(0.3088)] 
2025-03-11 16:49:33.093797: Epoch time: 42.41 s 
2025-03-11 16:49:33.681939:  
2025-03-11 16:49:33.687648: Epoch 34 
2025-03-11 16:49:33.691327: Current learning rate: 0.00688 
2025-03-11 16:50:16.155446: train_loss -0.5332 
2025-03-11 16:50:16.160598: val_loss -0.5253 
2025-03-11 16:50:16.164332: Pseudo dice [np.float32(0.7403), np.float32(0.4625)] 
2025-03-11 16:50:16.166981: Epoch time: 42.47 s 
2025-03-11 16:50:16.170843: Yayy! New best EMA pseudo Dice: 0.5544000267982483 
2025-03-11 16:50:16.952276:  
2025-03-11 16:50:16.958561: Epoch 35 
2025-03-11 16:50:16.962177: Current learning rate: 0.00679 
2025-03-11 16:50:59.447295: train_loss -0.5661 
2025-03-11 16:50:59.452908: val_loss -0.4949 
2025-03-11 16:50:59.455485: Pseudo dice [np.float32(0.7376), np.float32(0.3418)] 
2025-03-11 16:50:59.459563: Epoch time: 42.5 s 
2025-03-11 16:51:00.049435:  
2025-03-11 16:51:00.055171: Epoch 36 
2025-03-11 16:51:00.059262: Current learning rate: 0.00669 
2025-03-11 16:51:42.558940: train_loss -0.6124 
2025-03-11 16:51:42.565062: val_loss -0.5306 
2025-03-11 16:51:42.571296: Pseudo dice [np.float32(0.7371), np.float32(0.4546)] 
2025-03-11 16:51:42.574916: Epoch time: 42.51 s 
2025-03-11 16:51:42.577991: Yayy! New best EMA pseudo Dice: 0.557200014591217 
2025-03-11 16:51:43.478873:  
2025-03-11 16:51:43.484979: Epoch 37 
2025-03-11 16:51:43.488030: Current learning rate: 0.0066 
2025-03-11 16:52:25.948023: train_loss -0.5914 
2025-03-11 16:52:25.953946: val_loss -0.5288 
2025-03-11 16:52:25.957577: Pseudo dice [np.float32(0.7665), np.float32(0.3803)] 
2025-03-11 16:52:25.960692: Epoch time: 42.47 s 
2025-03-11 16:52:25.963813: Yayy! New best EMA pseudo Dice: 0.5587999820709229 
2025-03-11 16:52:26.730269:  
2025-03-11 16:52:26.736476: Epoch 38 
2025-03-11 16:52:26.740047: Current learning rate: 0.0065 
2025-03-11 16:53:09.191782: train_loss -0.6093 
2025-03-11 16:53:09.197562: val_loss -0.5432 
2025-03-11 16:53:09.201417: Pseudo dice [np.float32(0.7379), np.float32(0.4643)] 
2025-03-11 16:53:09.205156: Epoch time: 42.46 s 
2025-03-11 16:53:09.208238: Yayy! New best EMA pseudo Dice: 0.5630999803543091 
2025-03-11 16:53:09.983336:  
2025-03-11 16:53:09.989886: Epoch 39 
2025-03-11 16:53:09.993093: Current learning rate: 0.00641 
2025-03-11 16:53:52.465964: train_loss -0.59 
2025-03-11 16:53:52.472522: val_loss -0.5172 
2025-03-11 16:53:52.476054: Pseudo dice [np.float32(0.7587), np.float32(0.4152)] 
2025-03-11 16:53:52.480108: Epoch time: 42.48 s 
2025-03-11 16:53:52.482640: Yayy! New best EMA pseudo Dice: 0.5654000043869019 
2025-03-11 16:53:53.242711:  
2025-03-11 16:53:53.248391: Epoch 40 
2025-03-11 16:53:53.251473: Current learning rate: 0.00631 
2025-03-11 16:54:35.752122: train_loss -0.6165 
2025-03-11 16:54:35.758845: val_loss -0.5171 
2025-03-11 16:54:35.762462: Pseudo dice [np.float32(0.7677), np.float32(0.4218)] 
2025-03-11 16:54:35.765582: Epoch time: 42.51 s 
2025-03-11 16:54:35.768923: Yayy! New best EMA pseudo Dice: 0.5684000253677368 
2025-03-11 16:54:36.558336:  
2025-03-11 16:54:36.564045: Epoch 41 
2025-03-11 16:54:36.566659: Current learning rate: 0.00622 
2025-03-11 16:55:19.072120: train_loss -0.6056 
2025-03-11 16:55:19.077703: val_loss -0.5071 
2025-03-11 16:55:19.082250: Pseudo dice [np.float32(0.7545), np.float32(0.3566)] 
2025-03-11 16:55:19.085285: Epoch time: 42.51 s 
2025-03-11 16:55:19.666199:  
2025-03-11 16:55:19.673962: Epoch 42 
2025-03-11 16:55:19.679191: Current learning rate: 0.00612 
2025-03-11 16:56:02.206749: train_loss -0.6146 
2025-03-11 16:56:02.213427: val_loss -0.4679 
2025-03-11 16:56:02.217021: Pseudo dice [np.float32(0.7565), np.float32(0.2622)] 
2025-03-11 16:56:02.220670: Epoch time: 42.54 s 
2025-03-11 16:56:02.793209:  
2025-03-11 16:56:02.798304: Epoch 43 
2025-03-11 16:56:02.801839: Current learning rate: 0.00603 
2025-03-11 16:56:45.325076: train_loss -0.6231 
2025-03-11 16:56:45.331283: val_loss -0.5744 
2025-03-11 16:56:45.334913: Pseudo dice [np.float32(0.7676), np.float32(0.4787)] 
2025-03-11 16:56:45.338958: Epoch time: 42.53 s 
2025-03-11 16:56:45.909296:  
2025-03-11 16:56:45.915509: Epoch 44 
2025-03-11 16:56:45.919104: Current learning rate: 0.00593 
2025-03-11 16:57:28.448850: train_loss -0.6273 
2025-03-11 16:57:28.454982: val_loss -0.5631 
2025-03-11 16:57:28.458561: Pseudo dice [np.float32(0.7829), np.float32(0.4375)] 
2025-03-11 16:57:28.462103: Epoch time: 42.54 s 
2025-03-11 16:57:28.465142: Yayy! New best EMA pseudo Dice: 0.5717999935150146 
2025-03-11 16:57:29.348434:  
2025-03-11 16:57:29.354219: Epoch 45 
2025-03-11 16:57:29.357286: Current learning rate: 0.00584 
2025-03-11 16:58:11.844494: train_loss -0.6333 
2025-03-11 16:58:11.850160: val_loss -0.5184 
2025-03-11 16:58:11.854260: Pseudo dice [np.float32(0.7645), np.float32(0.3785)] 
2025-03-11 16:58:11.857342: Epoch time: 42.5 s 
2025-03-11 16:58:12.445787:  
2025-03-11 16:58:12.451408: Epoch 46 
2025-03-11 16:58:12.455178: Current learning rate: 0.00574 
2025-03-11 16:58:54.965223: train_loss -0.6383 
2025-03-11 16:58:54.971982: val_loss -0.5569 
2025-03-11 16:58:54.975606: Pseudo dice [np.float32(0.7598), np.float32(0.4424)] 
2025-03-11 16:58:54.979236: Epoch time: 42.52 s 
2025-03-11 16:58:54.982353: Yayy! New best EMA pseudo Dice: 0.5746999979019165 
2025-03-11 16:58:55.730309:  
2025-03-11 16:58:55.736393: Epoch 47 
2025-03-11 16:58:55.739432: Current learning rate: 0.00565 
2025-03-11 16:59:38.294642: train_loss -0.6221 
2025-03-11 16:59:38.301704: val_loss -0.5249 
2025-03-11 16:59:38.305278: Pseudo dice [np.float32(0.7283), np.float32(0.4508)] 
2025-03-11 16:59:38.307799: Epoch time: 42.56 s 
2025-03-11 16:59:38.311340: Yayy! New best EMA pseudo Dice: 0.576200008392334 
2025-03-11 16:59:39.035542:  
2025-03-11 16:59:39.041661: Epoch 48 
2025-03-11 16:59:39.044703: Current learning rate: 0.00555 
2025-03-11 17:00:21.549151: train_loss -0.6123 
2025-03-11 17:00:21.555303: val_loss -0.5294 
2025-03-11 17:00:21.558920: Pseudo dice [np.float32(0.7547), np.float32(0.3772)] 
2025-03-11 17:00:21.562023: Epoch time: 42.51 s 
2025-03-11 17:00:22.127970:  
2025-03-11 17:00:22.135697: Epoch 49 
2025-03-11 17:00:22.140293: Current learning rate: 0.00546 
2025-03-11 17:01:04.626629: train_loss -0.619 
2025-03-11 17:01:04.633430: val_loss -0.5367 
2025-03-11 17:01:04.636544: Pseudo dice [np.float32(0.7682), np.float32(0.429)] 
2025-03-11 17:01:04.640157: Epoch time: 42.5 s 
2025-03-11 17:01:04.800843: Yayy! New best EMA pseudo Dice: 0.5774999856948853 
2025-03-11 17:01:05.550425:  
2025-03-11 17:01:05.556129: Epoch 50 
2025-03-11 17:01:05.559806: Current learning rate: 0.00536 
2025-03-11 17:01:48.064185: train_loss -0.6272 
2025-03-11 17:01:48.070237: val_loss -0.5833 
2025-03-11 17:01:48.074264: Pseudo dice [np.float32(0.7764), np.float32(0.5446)] 
2025-03-11 17:01:48.077296: Epoch time: 42.51 s 
2025-03-11 17:01:48.080320: Yayy! New best EMA pseudo Dice: 0.5857999920845032 
2025-03-11 17:01:48.833327:  
2025-03-11 17:01:48.837406: Epoch 51 
2025-03-11 17:01:48.840578: Current learning rate: 0.00526 
2025-03-11 17:02:31.317703: train_loss -0.6513 
2025-03-11 17:02:31.323395: val_loss -0.5482 
2025-03-11 17:02:31.327101: Pseudo dice [np.float32(0.7692), np.float32(0.43)] 
2025-03-11 17:02:31.330723: Epoch time: 42.49 s 
2025-03-11 17:02:31.333849: Yayy! New best EMA pseudo Dice: 0.5871999859809875 
2025-03-11 17:02:32.059644:  
2025-03-11 17:02:32.064246: Epoch 52 
2025-03-11 17:02:32.067396: Current learning rate: 0.00517 
2025-03-11 17:03:14.607043: train_loss -0.6269 
2025-03-11 17:03:14.612891: val_loss -0.5617 
2025-03-11 17:03:14.616473: Pseudo dice [np.float32(0.7633), np.float32(0.4944)] 
2025-03-11 17:03:14.619647: Epoch time: 42.55 s 
2025-03-11 17:03:14.623255: Yayy! New best EMA pseudo Dice: 0.5913000106811523 
2025-03-11 17:03:15.360302:  
2025-03-11 17:03:15.365692: Epoch 53 
2025-03-11 17:03:15.368837: Current learning rate: 0.00507 
2025-03-11 17:03:57.856114: train_loss -0.6281 
2025-03-11 17:03:57.862741: val_loss -0.5513 
2025-03-11 17:03:57.866015: Pseudo dice [np.float32(0.7712), np.float32(0.3354)] 
2025-03-11 17:03:57.869809: Epoch time: 42.5 s 
2025-03-11 17:03:58.435173:  
2025-03-11 17:03:58.441417: Epoch 54 
2025-03-11 17:03:58.444611: Current learning rate: 0.00497 
2025-03-11 17:04:40.970791: train_loss -0.6665 
2025-03-11 17:04:40.977455: val_loss -0.5187 
2025-03-11 17:04:40.981083: Pseudo dice [np.float32(0.785), np.float32(0.3979)] 
2025-03-11 17:04:40.984161: Epoch time: 42.54 s 
2025-03-11 17:04:41.566282:  
2025-03-11 17:04:41.571330: Epoch 55 
2025-03-11 17:04:41.574864: Current learning rate: 0.00487 
2025-03-11 17:05:24.080979: train_loss -0.6605 
2025-03-11 17:05:24.087545: val_loss -0.6136 
2025-03-11 17:05:24.090068: Pseudo dice [np.float32(0.7922), np.float32(0.523)] 
2025-03-11 17:05:24.094121: Epoch time: 42.52 s 
2025-03-11 17:05:24.096649: Yayy! New best EMA pseudo Dice: 0.5949000120162964 
2025-03-11 17:05:24.836897:  
2025-03-11 17:05:24.842474: Epoch 56 
2025-03-11 17:05:24.846008: Current learning rate: 0.00478 
2025-03-11 17:06:07.332771: train_loss -0.659 
2025-03-11 17:06:07.338474: val_loss -0.5907 
2025-03-11 17:06:07.342802: Pseudo dice [np.float32(0.7768), np.float32(0.5291)] 
2025-03-11 17:06:07.345953: Epoch time: 42.5 s 
2025-03-11 17:06:07.349557: Yayy! New best EMA pseudo Dice: 0.6007000207901001 
2025-03-11 17:06:08.109727:  
2025-03-11 17:06:08.115513: Epoch 57 
2025-03-11 17:06:08.119094: Current learning rate: 0.00468 
2025-03-11 17:06:50.580753: train_loss -0.6459 
2025-03-11 17:06:50.587786: val_loss -0.5435 
2025-03-11 17:06:50.591835: Pseudo dice [np.float32(0.742), np.float32(0.4542)] 
2025-03-11 17:06:50.595367: Epoch time: 42.47 s 
2025-03-11 17:06:51.175900:  
2025-03-11 17:06:51.181484: Epoch 58 
2025-03-11 17:06:51.185025: Current learning rate: 0.00458 
2025-03-11 17:07:33.671120: train_loss -0.6698 
2025-03-11 17:07:33.676692: val_loss -0.5797 
2025-03-11 17:07:33.681222: Pseudo dice [np.float32(0.7876), np.float32(0.5099)] 
2025-03-11 17:07:33.684258: Epoch time: 42.5 s 
2025-03-11 17:07:33.687784: Yayy! New best EMA pseudo Dice: 0.6053000092506409 
2025-03-11 17:07:34.453222:  
2025-03-11 17:07:34.458921: Epoch 59 
2025-03-11 17:07:34.461030: Current learning rate: 0.00448 
2025-03-11 17:08:16.959464: train_loss -0.6631 
2025-03-11 17:08:16.966159: val_loss -0.5442 
2025-03-11 17:08:16.969317: Pseudo dice [np.float32(0.7829), np.float32(0.3758)] 
2025-03-11 17:08:16.972802: Epoch time: 42.51 s 
2025-03-11 17:08:17.711036:  
2025-03-11 17:08:17.716082: Epoch 60 
2025-03-11 17:08:17.720020: Current learning rate: 0.00438 
2025-03-11 17:09:00.200268: train_loss -0.6492 
2025-03-11 17:09:00.204928: val_loss -0.5847 
2025-03-11 17:09:00.208011: Pseudo dice [np.float32(0.7728), np.float32(0.5112)] 
2025-03-11 17:09:00.211601: Epoch time: 42.49 s 
2025-03-11 17:09:00.214683: Yayy! New best EMA pseudo Dice: 0.6065999865531921 
2025-03-11 17:09:00.975791:  
2025-03-11 17:09:00.981447: Epoch 61 
2025-03-11 17:09:00.984580: Current learning rate: 0.00429 
2025-03-11 17:09:43.466816: train_loss -0.6712 
2025-03-11 17:09:43.473925: val_loss -0.5496 
2025-03-11 17:09:43.476974: Pseudo dice [np.float32(0.7797), np.float32(0.4353)] 
2025-03-11 17:09:43.480525: Epoch time: 42.49 s 
2025-03-11 17:09:43.484090: Yayy! New best EMA pseudo Dice: 0.6067000031471252 
2025-03-11 17:09:44.233777:  
2025-03-11 17:09:44.239623: Epoch 62 
2025-03-11 17:09:44.243345: Current learning rate: 0.00419 
2025-03-11 17:10:26.713914: train_loss -0.6766 
2025-03-11 17:10:26.722054: val_loss -0.5524 
2025-03-11 17:10:26.725898: Pseudo dice [np.float32(0.7737), np.float32(0.4224)] 
2025-03-11 17:10:26.729701: Epoch time: 42.48 s 
2025-03-11 17:10:27.309570:  
2025-03-11 17:10:27.315267: Epoch 63 
2025-03-11 17:10:27.318907: Current learning rate: 0.00409 
2025-03-11 17:11:09.862477: train_loss -0.6602 
2025-03-11 17:11:09.868673: val_loss -0.5605 
2025-03-11 17:11:09.872795: Pseudo dice [np.float32(0.7914), np.float32(0.4303)] 
2025-03-11 17:11:09.876339: Epoch time: 42.55 s 
2025-03-11 17:11:10.458087:  
2025-03-11 17:11:10.463798: Epoch 64 
2025-03-11 17:11:10.466877: Current learning rate: 0.00399 
2025-03-11 17:11:52.956346: train_loss -0.6906 
2025-03-11 17:11:52.963465: val_loss -0.5578 
2025-03-11 17:11:52.966514: Pseudo dice [np.float32(0.7822), np.float32(0.4254)] 
2025-03-11 17:11:52.970548: Epoch time: 42.5 s 
2025-03-11 17:11:53.559860:  
2025-03-11 17:11:53.565500: Epoch 65 
2025-03-11 17:11:53.569165: Current learning rate: 0.00389 
2025-03-11 17:12:36.052508: train_loss -0.706 
2025-03-11 17:12:36.059117: val_loss -0.5589 
2025-03-11 17:12:36.062645: Pseudo dice [np.float32(0.7933), np.float32(0.4333)] 
2025-03-11 17:12:36.066181: Epoch time: 42.49 s 
2025-03-11 17:12:36.069292: Yayy! New best EMA pseudo Dice: 0.6068000197410583 
2025-03-11 17:12:36.836877:  
2025-03-11 17:12:36.842494: Epoch 66 
2025-03-11 17:12:36.846637: Current learning rate: 0.00379 
2025-03-11 17:13:19.317968: train_loss -0.6982 
2025-03-11 17:13:19.324147: val_loss -0.5303 
2025-03-11 17:13:19.327252: Pseudo dice [np.float32(0.7649), np.float32(0.4439)] 
2025-03-11 17:13:19.330865: Epoch time: 42.48 s 
2025-03-11 17:13:19.917253:  
2025-03-11 17:13:19.922581: Epoch 67 
2025-03-11 17:13:19.926913: Current learning rate: 0.00369 
2025-03-11 17:14:02.428865: train_loss -0.684 
2025-03-11 17:14:02.435468: val_loss -0.5499 
2025-03-11 17:14:02.438498: Pseudo dice [np.float32(0.7768), np.float32(0.4662)] 
2025-03-11 17:14:02.442022: Epoch time: 42.51 s 
2025-03-11 17:14:02.445051: Yayy! New best EMA pseudo Dice: 0.6080999970436096 
2025-03-11 17:14:03.366386:  
2025-03-11 17:14:03.372469: Epoch 68 
2025-03-11 17:14:03.376039: Current learning rate: 0.00359 
2025-03-11 17:14:45.867104: train_loss -0.681 
2025-03-11 17:14:45.873894: val_loss -0.5673 
2025-03-11 17:14:45.877798: Pseudo dice [np.float32(0.7695), np.float32(0.468)] 
2025-03-11 17:14:45.881061: Epoch time: 42.5 s 
2025-03-11 17:14:45.884196: Yayy! New best EMA pseudo Dice: 0.6090999841690063 
2025-03-11 17:14:46.663243:  
2025-03-11 17:14:46.669030: Epoch 69 
2025-03-11 17:14:46.672645: Current learning rate: 0.00349 
2025-03-11 17:15:29.154991: train_loss -0.7049 
2025-03-11 17:15:29.163586: val_loss -0.5797 
2025-03-11 17:15:29.167662: Pseudo dice [np.float32(0.7721), np.float32(0.5251)] 
2025-03-11 17:15:29.171696: Epoch time: 42.49 s 
2025-03-11 17:15:29.174762: Yayy! New best EMA pseudo Dice: 0.613099992275238 
2025-03-11 17:15:29.988493:  
2025-03-11 17:15:29.994851: Epoch 70 
2025-03-11 17:15:29.997959: Current learning rate: 0.00338 
2025-03-11 17:16:12.471918: train_loss -0.6899 
2025-03-11 17:16:12.477560: val_loss -0.5769 
2025-03-11 17:16:12.481588: Pseudo dice [np.float32(0.7842), np.float32(0.5379)] 
2025-03-11 17:16:12.484632: Epoch time: 42.48 s 
2025-03-11 17:16:12.488191: Yayy! New best EMA pseudo Dice: 0.617900013923645 
2025-03-11 17:16:13.242087:  
2025-03-11 17:16:13.248142: Epoch 71 
2025-03-11 17:16:13.251663: Current learning rate: 0.00328 
2025-03-11 17:16:55.752063: train_loss -0.6978 
2025-03-11 17:16:55.758307: val_loss -0.6204 
2025-03-11 17:16:55.761270: Pseudo dice [np.float32(0.8193), np.float32(0.5842)] 
2025-03-11 17:16:55.765181: Epoch time: 42.51 s 
2025-03-11 17:16:55.768298: Yayy! New best EMA pseudo Dice: 0.6262999773025513 
2025-03-11 17:16:56.545460:  
2025-03-11 17:16:56.551749: Epoch 72 
2025-03-11 17:16:56.555385: Current learning rate: 0.00318 
2025-03-11 17:17:39.147562: train_loss -0.717 
2025-03-11 17:17:39.153285: val_loss -0.5175 
2025-03-11 17:17:39.157351: Pseudo dice [np.float32(0.761), np.float32(0.3943)] 
2025-03-11 17:17:39.160388: Epoch time: 42.6 s 
2025-03-11 17:17:39.782595:  
2025-03-11 17:17:39.788697: Epoch 73 
2025-03-11 17:17:39.792344: Current learning rate: 0.00308 
2025-03-11 17:18:22.372225: train_loss -0.7083 
2025-03-11 17:18:22.377781: val_loss -0.5562 
2025-03-11 17:18:22.382003: Pseudo dice [np.float32(0.7727), np.float32(0.4262)] 
2025-03-11 17:18:22.385053: Epoch time: 42.59 s 
2025-03-11 17:18:22.978047:  
2025-03-11 17:18:22.984239: Epoch 74 
2025-03-11 17:18:22.987753: Current learning rate: 0.00297 
2025-03-11 17:19:05.451225: train_loss -0.7083 
2025-03-11 17:19:05.457448: val_loss -0.575 
2025-03-11 17:19:05.461316: Pseudo dice [np.float32(0.7897), np.float32(0.5197)] 
2025-03-11 17:19:05.464997: Epoch time: 42.47 s 
2025-03-11 17:19:06.065083:  
2025-03-11 17:19:06.070688: Epoch 75 
2025-03-11 17:19:06.074380: Current learning rate: 0.00287 
2025-03-11 17:19:48.554541: train_loss -0.719 
2025-03-11 17:19:48.559210: val_loss -0.5835 
2025-03-11 17:19:48.562816: Pseudo dice [np.float32(0.8051), np.float32(0.509)] 
2025-03-11 17:19:48.566394: Epoch time: 42.49 s 
2025-03-11 17:19:49.327625:  
2025-03-11 17:19:49.333805: Epoch 76 
2025-03-11 17:19:49.336931: Current learning rate: 0.00277 
2025-03-11 17:20:31.832821: train_loss -0.7023 
2025-03-11 17:20:31.840888: val_loss -0.524 
2025-03-11 17:20:31.845417: Pseudo dice [np.float32(0.7495), np.float32(0.4687)] 
2025-03-11 17:20:31.848976: Epoch time: 42.51 s 
2025-03-11 17:20:32.477001:  
2025-03-11 17:20:32.482624: Epoch 77 
2025-03-11 17:20:32.486649: Current learning rate: 0.00266 
2025-03-11 17:21:14.966883: train_loss -0.7101 
2025-03-11 17:21:14.973171: val_loss -0.592 
2025-03-11 17:21:14.976292: Pseudo dice [np.float32(0.7857), np.float32(0.5219)] 
2025-03-11 17:21:14.979865: Epoch time: 42.49 s 
2025-03-11 17:21:14.982901: Yayy! New best EMA pseudo Dice: 0.6273999810218811 
2025-03-11 17:21:15.767367:  
2025-03-11 17:21:15.774013: Epoch 78 
2025-03-11 17:21:15.777146: Current learning rate: 0.00256 
2025-03-11 17:21:58.255795: train_loss -0.735 
2025-03-11 17:21:58.262021: val_loss -0.5407 
2025-03-11 17:21:58.265106: Pseudo dice [np.float32(0.7737), np.float32(0.4086)] 
2025-03-11 17:21:58.268705: Epoch time: 42.49 s 
2025-03-11 17:21:58.874707:  
2025-03-11 17:21:58.879847: Epoch 79 
2025-03-11 17:21:58.883484: Current learning rate: 0.00245 
2025-03-11 17:22:41.372031: train_loss -0.7253 
2025-03-11 17:22:41.376105: val_loss -0.5798 
2025-03-11 17:22:41.380129: Pseudo dice [np.float32(0.7849), np.float32(0.5483)] 
2025-03-11 17:22:41.383671: Epoch time: 42.5 s 
2025-03-11 17:22:41.386193: Yayy! New best EMA pseudo Dice: 0.6280999779701233 
2025-03-11 17:22:42.144566:  
2025-03-11 17:22:42.150641: Epoch 80 
2025-03-11 17:22:42.153667: Current learning rate: 0.00235 
2025-03-11 17:23:24.728400: train_loss -0.7231 
2025-03-11 17:23:24.735036: val_loss -0.552 
2025-03-11 17:23:24.738685: Pseudo dice [np.float32(0.7856), np.float32(0.4535)] 
2025-03-11 17:23:24.741784: Epoch time: 42.58 s 
2025-03-11 17:23:25.367599:  
2025-03-11 17:23:25.372730: Epoch 81 
2025-03-11 17:23:25.376731: Current learning rate: 0.00224 
2025-03-11 17:24:07.867782: train_loss -0.7036 
2025-03-11 17:24:07.872385: val_loss -0.5736 
2025-03-11 17:24:07.876580: Pseudo dice [np.float32(0.7759), np.float32(0.5076)] 
2025-03-11 17:24:07.879805: Epoch time: 42.5 s 
2025-03-11 17:24:07.882844: Yayy! New best EMA pseudo Dice: 0.6287000179290771 
2025-03-11 17:24:08.675925:  
2025-03-11 17:24:08.682022: Epoch 82 
2025-03-11 17:24:08.685055: Current learning rate: 0.00214 
2025-03-11 17:24:51.155558: train_loss -0.7254 
2025-03-11 17:24:51.162184: val_loss -0.5641 
2025-03-11 17:24:51.166314: Pseudo dice [np.float32(0.7754), np.float32(0.4185)] 
2025-03-11 17:24:51.169456: Epoch time: 42.48 s 
2025-03-11 17:24:51.742234:  
2025-03-11 17:24:51.748090: Epoch 83 
2025-03-11 17:24:51.752172: Current learning rate: 0.00203 
2025-03-11 17:25:34.223302: train_loss -0.7505 
2025-03-11 17:25:34.230911: val_loss -0.614 
2025-03-11 17:25:34.236123: Pseudo dice [np.float32(0.8109), np.float32(0.57)] 
2025-03-11 17:25:34.239315: Epoch time: 42.48 s 
2025-03-11 17:25:34.242376: Yayy! New best EMA pseudo Dice: 0.6320000290870667 
2025-03-11 17:25:35.131532:  
2025-03-11 17:25:35.137238: Epoch 84 
2025-03-11 17:25:35.140802: Current learning rate: 0.00192 
2025-03-11 17:26:17.615504: train_loss -0.7356 
2025-03-11 17:26:17.621161: val_loss -0.5507 
2025-03-11 17:26:17.624894: Pseudo dice [np.float32(0.7967), np.float32(0.4011)] 
2025-03-11 17:26:17.628492: Epoch time: 42.49 s 
2025-03-11 17:26:18.188656:  
2025-03-11 17:26:18.194209: Epoch 85 
2025-03-11 17:26:18.197237: Current learning rate: 0.00181 
2025-03-11 17:27:00.661975: train_loss -0.7577 
2025-03-11 17:27:00.667676: val_loss -0.5592 
2025-03-11 17:27:00.670870: Pseudo dice [np.float32(0.7872), np.float32(0.4943)] 
2025-03-11 17:27:00.674488: Epoch time: 42.47 s 
2025-03-11 17:27:01.299412:  
2025-03-11 17:27:01.305049: Epoch 86 
2025-03-11 17:27:01.309073: Current learning rate: 0.0017 
2025-03-11 17:27:43.793353: train_loss -0.7399 
2025-03-11 17:27:43.799917: val_loss -0.583 
2025-03-11 17:27:43.803941: Pseudo dice [np.float32(0.8007), np.float32(0.5402)] 
2025-03-11 17:27:43.806966: Epoch time: 42.49 s 
2025-03-11 17:27:43.809995: Yayy! New best EMA pseudo Dice: 0.633899986743927 
2025-03-11 17:27:44.544964:  
2025-03-11 17:27:44.551039: Epoch 87 
2025-03-11 17:27:44.554135: Current learning rate: 0.00159 
2025-03-11 17:28:27.047434: train_loss -0.7527 
2025-03-11 17:28:27.054197: val_loss -0.5959 
2025-03-11 17:28:27.057773: Pseudo dice [np.float32(0.7992), np.float32(0.5086)] 
2025-03-11 17:28:27.061108: Epoch time: 42.5 s 
2025-03-11 17:28:27.064594: Yayy! New best EMA pseudo Dice: 0.6359000205993652 
2025-03-11 17:28:27.779661:  
2025-03-11 17:28:27.784988: Epoch 88 
2025-03-11 17:28:27.788597: Current learning rate: 0.00148 
2025-03-11 17:29:10.290087: train_loss -0.7559 
2025-03-11 17:29:10.294143: val_loss -0.5725 
2025-03-11 17:29:10.298184: Pseudo dice [np.float32(0.7763), np.float32(0.5392)] 
2025-03-11 17:29:10.301223: Epoch time: 42.51 s 
2025-03-11 17:29:10.304838: Yayy! New best EMA pseudo Dice: 0.6381000280380249 
2025-03-11 17:29:11.030929:  
2025-03-11 17:29:11.036612: Epoch 89 
2025-03-11 17:29:11.039701: Current learning rate: 0.00137 
2025-03-11 17:29:53.547165: train_loss -0.7502 
2025-03-11 17:29:53.553296: val_loss -0.5672 
2025-03-11 17:29:53.557687: Pseudo dice [np.float32(0.809), np.float32(0.4916)] 
2025-03-11 17:29:53.561267: Epoch time: 42.52 s 
2025-03-11 17:29:53.564308: Yayy! New best EMA pseudo Dice: 0.6392999887466431 
2025-03-11 17:29:54.316033:  
2025-03-11 17:29:54.321953: Epoch 90 
2025-03-11 17:29:54.325666: Current learning rate: 0.00126 
2025-03-11 17:30:36.832736: train_loss -0.7643 
2025-03-11 17:30:36.838667: val_loss -0.5925 
2025-03-11 17:30:36.842167: Pseudo dice [np.float32(0.7896), np.float32(0.5703)] 
2025-03-11 17:30:36.845741: Epoch time: 42.52 s 
2025-03-11 17:30:36.849322: Yayy! New best EMA pseudo Dice: 0.6434000134468079 
2025-03-11 17:30:37.572194:  
2025-03-11 17:30:37.579301: Epoch 91 
2025-03-11 17:30:37.582601: Current learning rate: 0.00115 
2025-03-11 17:31:20.051409: train_loss -0.7439 
2025-03-11 17:31:20.057667: val_loss -0.5587 
2025-03-11 17:31:20.061302: Pseudo dice [np.float32(0.7696), np.float32(0.526)] 
2025-03-11 17:31:20.064390: Epoch time: 42.48 s 
2025-03-11 17:31:20.068102: Yayy! New best EMA pseudo Dice: 0.6438000202178955 
2025-03-11 17:31:20.791255:  
2025-03-11 17:31:20.797460: Epoch 92 
2025-03-11 17:31:20.800082: Current learning rate: 0.00103 
2025-03-11 17:32:03.273060: train_loss -0.7657 
2025-03-11 17:32:03.279618: val_loss -0.5248 
2025-03-11 17:32:03.282724: Pseudo dice [np.float32(0.7839), np.float32(0.3927)] 
2025-03-11 17:32:03.286258: Epoch time: 42.48 s 
2025-03-11 17:32:03.993184:  
2025-03-11 17:32:03.999888: Epoch 93 
2025-03-11 17:32:04.003517: Current learning rate: 0.00091 
2025-03-11 17:32:46.487660: train_loss -0.7465 
2025-03-11 17:32:46.493892: val_loss -0.5726 
2025-03-11 17:32:46.497476: Pseudo dice [np.float32(0.8115), np.float32(0.4871)] 
2025-03-11 17:32:46.500627: Epoch time: 42.49 s 
2025-03-11 17:32:47.074575:  
2025-03-11 17:32:47.081678: Epoch 94 
2025-03-11 17:32:47.085210: Current learning rate: 0.00079 
2025-03-11 17:33:29.543158: train_loss -0.7601 
2025-03-11 17:33:29.549704: val_loss -0.5476 
2025-03-11 17:33:29.553243: Pseudo dice [np.float32(0.7918), np.float32(0.5018)] 
2025-03-11 17:33:29.556766: Epoch time: 42.47 s 
2025-03-11 17:33:30.111770:  
2025-03-11 17:33:30.118011: Epoch 95 
2025-03-11 17:33:30.121100: Current learning rate: 0.00067 
2025-03-11 17:34:12.606712: train_loss -0.7729 
2025-03-11 17:34:12.612906: val_loss -0.581 
2025-03-11 17:34:12.616547: Pseudo dice [np.float32(0.7869), np.float32(0.4677)] 
2025-03-11 17:34:12.619629: Epoch time: 42.5 s 
2025-03-11 17:34:13.178200:  
2025-03-11 17:34:13.184819: Epoch 96 
2025-03-11 17:34:13.187929: Current learning rate: 0.00055 
2025-03-11 17:34:55.657529: train_loss -0.744 
2025-03-11 17:34:55.663739: val_loss -0.5864 
2025-03-11 17:34:55.667426: Pseudo dice [np.float32(0.8124), np.float32(0.556)] 
2025-03-11 17:34:55.671071: Epoch time: 42.48 s 
2025-03-11 17:34:56.244090:  
2025-03-11 17:34:56.249846: Epoch 97 
2025-03-11 17:34:56.252971: Current learning rate: 0.00043 
2025-03-11 17:35:38.793180: train_loss -0.7663 
2025-03-11 17:35:38.799246: val_loss -0.5814 
2025-03-11 17:35:38.803780: Pseudo dice [np.float32(0.8021), np.float32(0.4308)] 
2025-03-11 17:35:38.807374: Epoch time: 42.55 s 
2025-03-11 17:35:39.375823:  
2025-03-11 17:35:39.381235: Epoch 98 
2025-03-11 17:35:39.384812: Current learning rate: 0.0003 
2025-03-11 17:36:21.880683: train_loss -0.7715 
2025-03-11 17:36:21.886728: val_loss -0.5725 
2025-03-11 17:36:21.889756: Pseudo dice [np.float32(0.7796), np.float32(0.5427)] 
2025-03-11 17:36:21.893774: Epoch time: 42.51 s 
2025-03-11 17:36:22.470468:  
2025-03-11 17:36:22.476044: Epoch 99 
2025-03-11 17:36:22.479729: Current learning rate: 0.00016 
2025-03-11 17:37:04.995729: train_loss -0.7764 
2025-03-11 17:37:05.002404: val_loss -0.6088 
2025-03-11 17:37:05.006444: Pseudo dice [np.float32(0.808), np.float32(0.5089)] 
2025-03-11 17:37:05.009511: Epoch time: 42.53 s 
2025-03-11 17:37:05.012171: Yayy! New best EMA pseudo Dice: 0.6442999839782715 
2025-03-11 17:37:05.927090: Training done. 
2025-03-11 17:37:05.960443: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-03-11 17:37:05.967280: The split file contains 5 splits. 
2025-03-11 17:37:05.973376: Desired fold for training: 0 
2025-03-11 17:37:05.978087: This split has 224 training and 57 validation cases. 
2025-03-11 17:37:05.983389: predicting pancreas_021 
2025-03-11 17:37:05.990335: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-03-11 17:37:18.792810: predicting pancreas_024 
2025-03-11 17:37:18.815574: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-03-11 17:37:33.835669: predicting pancreas_035 
2025-03-11 17:37:33.857681: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-03-11 17:37:38.983093: predicting pancreas_040 
2025-03-11 17:37:38.996733: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-03-11 17:37:51.067611: predicting pancreas_042 
2025-03-11 17:37:51.088693: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-03-11 17:38:06.160022: predicting pancreas_056 
2025-03-11 17:38:06.183471: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-03-11 17:38:18.217160: predicting pancreas_067 
2025-03-11 17:38:18.235206: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-03-11 17:38:33.314330: predicting pancreas_075 
2025-03-11 17:38:33.337120: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-03-11 17:38:39.389343: predicting pancreas_086 
2025-03-11 17:38:39.406294: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-03-11 17:38:48.807652: predicting pancreas_089 
2025-03-11 17:38:48.825440: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-03-11 17:39:00.853253: predicting pancreas_092 
2025-03-11 17:39:00.871899: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-03-11 17:39:27.936920: predicting pancreas_094 
2025-03-11 17:39:27.967853: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-03-11 17:39:40.006223: predicting pancreas_095 
2025-03-11 17:39:40.024136: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-03-11 17:39:52.091251: predicting pancreas_098 
2025-03-11 17:39:52.110462: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-03-11 17:40:24.976615: predicting pancreas_109 
2025-03-11 17:40:25.008952: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-03-11 17:40:37.111650: predicting pancreas_110 
2025-03-11 17:40:37.134708: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-03-11 17:40:55.950147: predicting pancreas_114 
2025-03-11 17:40:55.974935: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-03-11 17:41:08.028703: predicting pancreas_119 
2025-03-11 17:41:08.048139: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-03-11 17:41:26.845839: predicting pancreas_138 
2025-03-11 17:41:26.868745: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-03-11 17:41:45.696440: predicting pancreas_145 
2025-03-11 17:41:45.723526: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-03-11 17:42:04.556473: predicting pancreas_148 
2025-03-11 17:42:04.579503: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-03-11 17:42:16.627083: predicting pancreas_169 
2025-03-11 17:42:16.646136: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-03-11 17:42:28.678776: predicting pancreas_170 
2025-03-11 17:42:28.696477: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-03-11 17:42:43.716985: predicting pancreas_172 
2025-03-11 17:42:43.739908: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-03-11 17:42:55.846602: predicting pancreas_175 
2025-03-11 17:42:55.864736: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-03-11 17:43:07.926757: predicting pancreas_180 
2025-03-11 17:43:07.945993: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-03-11 17:43:19.999845: predicting pancreas_191 
2025-03-11 17:43:20.016918: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-03-11 17:43:26.071592: predicting pancreas_193 
2025-03-11 17:43:26.086520: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-03-11 17:43:41.127602: predicting pancreas_212 
2025-03-11 17:43:41.149789: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-03-11 17:43:53.242770: predicting pancreas_215 
2025-03-11 17:43:53.266295: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-03-11 17:44:05.326823: predicting pancreas_222 
2025-03-11 17:44:05.346759: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-03-11 17:44:10.471523: predicting pancreas_235 
2025-03-11 17:44:10.488102: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-03-11 17:44:22.516959: predicting pancreas_241 
2025-03-11 17:44:22.533925: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-03-11 17:44:34.581343: predicting pancreas_242 
2025-03-11 17:44:34.601362: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-03-11 17:44:49.659217: predicting pancreas_244 
2025-03-11 17:44:49.681356: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-03-11 17:45:13.152698: predicting pancreas_246 
2025-03-11 17:45:13.177514: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-03-11 17:45:36.650025: predicting pancreas_247 
2025-03-11 17:45:36.673822: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-03-11 17:45:43.494970: predicting pancreas_264 
2025-03-11 17:45:43.510111: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-03-11 17:45:58.555256: predicting pancreas_265 
2025-03-11 17:45:58.578187: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-03-11 17:46:10.644923: predicting pancreas_266 
2025-03-11 17:46:10.665614: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-03-11 17:46:29.453660: predicting pancreas_267 
2025-03-11 17:46:29.478622: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-03-11 17:46:36.292326: predicting pancreas_275 
2025-03-11 17:46:36.309362: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-03-11 17:46:51.342573: predicting pancreas_279 
2025-03-11 17:46:51.361553: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-03-11 17:46:56.502198: predicting pancreas_287 
2025-03-11 17:46:56.517883: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-03-11 17:47:08.569265: predicting pancreas_301 
2025-03-11 17:47:08.589082: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-03-11 17:47:20.772069: predicting pancreas_323 
2025-03-11 17:47:20.791993: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-03-11 17:47:39.601245: predicting pancreas_336 
2025-03-11 17:47:39.625906: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-03-11 17:47:51.732921: predicting pancreas_344 
2025-03-11 17:47:51.754898: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-03-11 17:48:06.799603: predicting pancreas_351 
2025-03-11 17:48:06.820950: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-03-11 17:48:13.656732: predicting pancreas_354 
2025-03-11 17:48:13.671929: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-03-11 17:48:37.838470: predicting pancreas_372 
2025-03-11 17:48:37.867397: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-03-11 17:48:56.705718: predicting pancreas_377 
2025-03-11 17:48:56.735893: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-03-11 17:49:11.815110: predicting pancreas_387 
2025-03-11 17:49:11.837970: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-03-11 17:49:23.961712: predicting pancreas_391 
2025-03-11 17:49:23.983058: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-03-11 17:49:42.791702: predicting pancreas_392 
2025-03-11 17:49:42.814791: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-03-11 17:49:51.340348: predicting pancreas_410 
2025-03-11 17:49:51.358342: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-03-11 17:49:59.851633: predicting pancreas_412 
2025-03-11 17:49:59.868865: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-03-11 17:51:01.643205: Validation complete 
2025-03-11 17:51:01.649517: Mean Validation Dice:  0.3741257951149444 
