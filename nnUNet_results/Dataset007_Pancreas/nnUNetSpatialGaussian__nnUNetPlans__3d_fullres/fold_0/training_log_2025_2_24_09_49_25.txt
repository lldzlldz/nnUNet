
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-24 09:49:25.108629: do_dummy_2d_data_aug: True 
2025-02-24 09:49:25.140814: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-02-24 09:49:25.148812: The split file contains 5 splits. 
2025-02-24 09:49:25.151812: Desired fold for training: 0 
2025-02-24 09:49:25.154812: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-02-24 09:49:32.419599: unpacking dataset... 
2025-02-24 09:49:32.873775: unpacking done... 
2025-02-24 09:49:35.716045:  
2025-02-24 09:49:35.721057: Epoch 0 
2025-02-24 09:49:35.724565: Current learning rate: 0.01 
2025-02-24 09:50:22.439200: train_loss 0.1267 
2025-02-24 09:50:22.445214: val_loss 0.0545 
2025-02-24 09:50:22.448226: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-02-24 09:50:22.451738: Epoch time: 46.72 s 
2025-02-24 09:50:22.455756: Yayy! New best EMA pseudo Dice: 0.0 
2025-02-24 09:50:23.045460:  
2025-02-24 09:50:23.057113: Epoch 1 
2025-02-24 09:50:23.060202: Current learning rate: 0.00996 
2025-02-24 09:51:05.172152: train_loss 0.0297 
2025-02-24 09:51:05.178467: val_loss -0.0211 
2025-02-24 09:51:05.181984: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-02-24 09:51:05.185081: Epoch time: 42.13 s 
2025-02-24 09:51:05.679577:  
2025-02-24 09:51:05.685129: Epoch 2 
2025-02-24 09:51:05.688684: Current learning rate: 0.00993 
2025-02-24 09:51:47.794052: train_loss -0.0936 
2025-02-24 09:51:47.800125: val_loss -0.1754 
2025-02-24 09:51:47.803672: Pseudo dice [np.float32(0.5335), np.float32(0.0)] 
2025-02-24 09:51:47.807703: Epoch time: 42.11 s 
2025-02-24 09:51:47.813901: Yayy! New best EMA pseudo Dice: 0.02669999934732914 
2025-02-24 09:51:48.500364:  
2025-02-24 09:51:48.506507: Epoch 3 
2025-02-24 09:51:48.510064: Current learning rate: 0.00989 
2025-02-24 09:52:30.594930: train_loss -0.1844 
2025-02-24 09:52:30.600950: val_loss -0.2241 
2025-02-24 09:52:30.604083: Pseudo dice [np.float32(0.5522), np.float32(0.0)] 
2025-02-24 09:52:30.607626: Epoch time: 42.09 s 
2025-02-24 09:52:30.611205: Yayy! New best EMA pseudo Dice: 0.051600001752376556 
2025-02-24 09:52:31.282508:  
2025-02-24 09:52:31.288610: Epoch 4 
2025-02-24 09:52:31.291671: Current learning rate: 0.00986 
2025-02-24 09:53:13.381538: train_loss -0.2048 
2025-02-24 09:53:13.388053: val_loss -0.2695 
2025-02-24 09:53:13.393067: Pseudo dice [np.float32(0.6156), np.float32(0.0)] 
2025-02-24 09:53:13.398083: Epoch time: 42.1 s 
2025-02-24 09:53:13.400591: Yayy! New best EMA pseudo Dice: 0.07720000296831131 
2025-02-24 09:53:14.206877:  
2025-02-24 09:53:14.211889: Epoch 5 
2025-02-24 09:53:14.215401: Current learning rate: 0.00982 
2025-02-24 09:53:56.328004: train_loss -0.2315 
2025-02-24 09:53:56.333519: val_loss -0.2407 
2025-02-24 09:53:56.337036: Pseudo dice [np.float32(0.554), np.float32(0.0)] 
2025-02-24 09:53:56.340540: Epoch time: 42.12 s 
2025-02-24 09:53:56.344552: Yayy! New best EMA pseudo Dice: 0.09719999879598618 
2025-02-24 09:53:57.003895:  
2025-02-24 09:53:57.009412: Epoch 6 
2025-02-24 09:53:57.012921: Current learning rate: 0.00978 
2025-02-24 09:54:39.130541: train_loss -0.2532 
2025-02-24 09:54:39.137189: val_loss -0.3316 
2025-02-24 09:54:39.141307: Pseudo dice [np.float32(0.6735), np.float32(0.0)] 
2025-02-24 09:54:39.146362: Epoch time: 42.13 s 
2025-02-24 09:54:39.150552: Yayy! New best EMA pseudo Dice: 0.12120000272989273 
2025-02-24 09:54:39.807004:  
2025-02-24 09:54:39.810490: Epoch 7 
2025-02-24 09:54:39.817006: Current learning rate: 0.00975 
2025-02-24 09:55:21.897734: train_loss -0.3173 
2025-02-24 09:55:21.902743: val_loss -0.349 
2025-02-24 09:55:21.906764: Pseudo dice [np.float32(0.5894), np.float32(0.3227)] 
2025-02-24 09:55:21.909271: Epoch time: 42.09 s 
2025-02-24 09:55:21.912788: Yayy! New best EMA pseudo Dice: 0.15459999442100525 
2025-02-24 09:55:22.565152:  
2025-02-24 09:55:22.570164: Epoch 8 
2025-02-24 09:55:22.573673: Current learning rate: 0.00971 
2025-02-24 09:56:04.663938: train_loss -0.3347 
2025-02-24 09:56:04.670516: val_loss -0.3965 
2025-02-24 09:56:04.673575: Pseudo dice [np.float32(0.6439), np.float32(0.3809)] 
2025-02-24 09:56:04.676118: Epoch time: 42.1 s 
2025-02-24 09:56:04.679182: Yayy! New best EMA pseudo Dice: 0.19040000438690186 
2025-02-24 09:56:05.362748:  
2025-02-24 09:56:05.368320: Epoch 9 
2025-02-24 09:56:05.371854: Current learning rate: 0.00968 
2025-02-24 09:56:47.477625: train_loss -0.3333 
2025-02-24 09:56:47.484204: val_loss -0.3507 
2025-02-24 09:56:47.487750: Pseudo dice [np.float32(0.6068), np.float32(0.2916)] 
2025-02-24 09:56:47.491338: Epoch time: 42.12 s 
2025-02-24 09:56:47.495401: Yayy! New best EMA pseudo Dice: 0.21629999577999115 
2025-02-24 09:56:48.141966:  
2025-02-24 09:56:48.147512: Epoch 10 
2025-02-24 09:56:48.151048: Current learning rate: 0.00964 
2025-02-24 09:57:30.243041: train_loss -0.38 
2025-02-24 09:57:30.249185: val_loss -0.3659 
2025-02-24 09:57:30.252726: Pseudo dice [np.float32(0.6665), np.float32(0.2536)] 
2025-02-24 09:57:30.255838: Epoch time: 42.1 s 
2025-02-24 09:57:30.259406: Yayy! New best EMA pseudo Dice: 0.24070000648498535 
2025-02-24 09:57:30.914068:  
2025-02-24 09:57:30.919595: Epoch 11 
2025-02-24 09:57:30.923107: Current learning rate: 0.0096 
2025-02-24 09:58:13.010491: train_loss -0.3862 
2025-02-24 09:58:13.016654: val_loss -0.4406 
2025-02-24 09:58:13.019174: Pseudo dice [np.float32(0.6859), np.float32(0.3199)] 
2025-02-24 09:58:13.023253: Epoch time: 42.1 s 
2025-02-24 09:58:13.026818: Yayy! New best EMA pseudo Dice: 0.2669000029563904 
2025-02-24 09:58:13.721722:  
2025-02-24 09:58:13.727300: Epoch 12 
2025-02-24 09:58:13.730361: Current learning rate: 0.00957 
2025-02-24 09:58:55.854600: train_loss -0.368 
2025-02-24 09:58:55.861120: val_loss -0.4181 
2025-02-24 09:58:55.865638: Pseudo dice [np.float32(0.6778), np.float32(0.3319)] 
2025-02-24 09:58:55.868708: Epoch time: 42.13 s 
2025-02-24 09:58:55.872284: Yayy! New best EMA pseudo Dice: 0.2906999886035919 
2025-02-24 09:58:56.659686:  
2025-02-24 09:58:56.664709: Epoch 13 
2025-02-24 09:58:56.668221: Current learning rate: 0.00953 
2025-02-24 09:59:38.783767: train_loss -0.391 
2025-02-24 09:59:38.789868: val_loss -0.443 
2025-02-24 09:59:38.792882: Pseudo dice [np.float32(0.655), np.float32(0.3528)] 
2025-02-24 09:59:38.796437: Epoch time: 42.12 s 
2025-02-24 09:59:38.799953: Yayy! New best EMA pseudo Dice: 0.31200000643730164 
2025-02-24 09:59:39.457283:  
2025-02-24 09:59:39.463309: Epoch 14 
2025-02-24 09:59:39.466814: Current learning rate: 0.00949 
2025-02-24 10:00:21.575750: train_loss -0.3626 
2025-02-24 10:00:21.581346: val_loss -0.4525 
2025-02-24 10:00:21.585433: Pseudo dice [np.float32(0.6857), np.float32(0.3266)] 
2025-02-24 10:00:21.588479: Epoch time: 42.12 s 
2025-02-24 10:00:21.592595: Yayy! New best EMA pseudo Dice: 0.3314000070095062 
2025-02-24 10:00:22.264441:  
2025-02-24 10:00:22.269471: Epoch 15 
2025-02-24 10:00:22.273061: Current learning rate: 0.00946 
2025-02-24 10:01:04.493502: train_loss -0.4344 
2025-02-24 10:01:04.500528: val_loss -0.4897 
2025-02-24 10:01:04.504540: Pseudo dice [np.float32(0.7029), np.float32(0.3867)] 
2025-02-24 10:01:04.508047: Epoch time: 42.23 s 
2025-02-24 10:01:04.512063: Yayy! New best EMA pseudo Dice: 0.35280001163482666 
2025-02-24 10:01:05.201490:  
2025-02-24 10:01:05.207503: Epoch 16 
2025-02-24 10:01:05.211011: Current learning rate: 0.00942 
2025-02-24 10:01:47.315125: train_loss -0.4399 
2025-02-24 10:01:47.321260: val_loss -0.4558 
2025-02-24 10:01:47.324828: Pseudo dice [np.float32(0.6696), np.float32(0.2952)] 
2025-02-24 10:01:47.328380: Epoch time: 42.11 s 
2025-02-24 10:01:47.332035: Yayy! New best EMA pseudo Dice: 0.36570000648498535 
2025-02-24 10:01:48.006497:  
2025-02-24 10:01:48.012067: Epoch 17 
2025-02-24 10:01:48.016124: Current learning rate: 0.00939 
2025-02-24 10:02:30.142346: train_loss -0.4429 
2025-02-24 10:02:30.148530: val_loss -0.4662 
2025-02-24 10:02:30.152126: Pseudo dice [np.float32(0.7165), np.float32(0.381)] 
2025-02-24 10:02:30.155150: Epoch time: 42.14 s 
2025-02-24 10:02:30.159847: Yayy! New best EMA pseudo Dice: 0.3840000033378601 
2025-02-24 10:02:30.833518:  
2025-02-24 10:02:30.839036: Epoch 18 
2025-02-24 10:02:30.842551: Current learning rate: 0.00935 
2025-02-24 10:03:12.964195: train_loss -0.4775 
2025-02-24 10:03:12.971770: val_loss -0.4846 
2025-02-24 10:03:12.974806: Pseudo dice [np.float32(0.7133), np.float32(0.4127)] 
2025-02-24 10:03:12.978315: Epoch time: 42.13 s 
2025-02-24 10:03:12.981328: Yayy! New best EMA pseudo Dice: 0.4018999934196472 
2025-02-24 10:03:13.671571:  
2025-02-24 10:03:13.677647: Epoch 19 
2025-02-24 10:03:13.681214: Current learning rate: 0.00931 
2025-02-24 10:03:55.784711: train_loss -0.4879 
2025-02-24 10:03:55.790732: val_loss -0.4824 
2025-02-24 10:03:55.794744: Pseudo dice [np.float32(0.7082), np.float32(0.3642)] 
2025-02-24 10:03:55.797252: Epoch time: 42.11 s 
2025-02-24 10:03:55.800764: Yayy! New best EMA pseudo Dice: 0.4153999984264374 
2025-02-24 10:03:56.472161:  
2025-02-24 10:03:56.478178: Epoch 20 
2025-02-24 10:03:56.480687: Current learning rate: 0.00928 
2025-02-24 10:04:38.601337: train_loss -0.4967 
2025-02-24 10:04:38.606917: val_loss -0.4953 
2025-02-24 10:04:38.610430: Pseudo dice [np.float32(0.7251), np.float32(0.3936)] 
2025-02-24 10:04:38.613937: Epoch time: 42.13 s 
2025-02-24 10:04:38.617953: Yayy! New best EMA pseudo Dice: 0.42980000376701355 
2025-02-24 10:04:39.445373:  
2025-02-24 10:04:39.451888: Epoch 21 
2025-02-24 10:04:39.455404: Current learning rate: 0.00924 
2025-02-24 10:05:21.566442: train_loss -0.4842 
2025-02-24 10:05:21.572077: val_loss -0.4604 
2025-02-24 10:05:21.575600: Pseudo dice [np.float32(0.6919), np.float32(0.3686)] 
2025-02-24 10:05:21.578630: Epoch time: 42.12 s 
2025-02-24 10:05:21.581831: Yayy! New best EMA pseudo Dice: 0.4397999942302704 
2025-02-24 10:05:22.241353:  
2025-02-24 10:05:22.246946: Epoch 22 
2025-02-24 10:05:22.250585: Current learning rate: 0.0092 
2025-02-24 10:06:04.371433: train_loss -0.4857 
2025-02-24 10:06:04.377498: val_loss -0.5294 
2025-02-24 10:06:04.381069: Pseudo dice [np.float32(0.7338), np.float32(0.4209)] 
2025-02-24 10:06:04.384622: Epoch time: 42.13 s 
2025-02-24 10:06:04.387797: Yayy! New best EMA pseudo Dice: 0.4535999894142151 
2025-02-24 10:06:05.033521:  
2025-02-24 10:06:05.040096: Epoch 23 
2025-02-24 10:06:05.042620: Current learning rate: 0.00917 
2025-02-24 10:06:47.141138: train_loss -0.4911 
2025-02-24 10:06:47.146402: val_loss -0.4329 
2025-02-24 10:06:47.150466: Pseudo dice [np.float32(0.6646), np.float32(0.2916)] 
2025-02-24 10:06:47.154040: Epoch time: 42.11 s 
2025-02-24 10:06:47.156574: Yayy! New best EMA pseudo Dice: 0.4560000002384186 
2025-02-24 10:06:47.813190:  
2025-02-24 10:06:47.818703: Epoch 24 
2025-02-24 10:06:47.822211: Current learning rate: 0.00913 
2025-02-24 10:07:29.940051: train_loss -0.4945 
2025-02-24 10:07:29.946684: val_loss -0.5096 
2025-02-24 10:07:29.949725: Pseudo dice [np.float32(0.71), np.float32(0.4471)] 
2025-02-24 10:07:29.952755: Epoch time: 42.13 s 
2025-02-24 10:07:29.956771: Yayy! New best EMA pseudo Dice: 0.4683000147342682 
2025-02-24 10:07:30.599529:  
2025-02-24 10:07:30.603876: Epoch 25 
2025-02-24 10:07:30.609508: Current learning rate: 0.0091 
2025-02-24 10:08:12.754924: train_loss -0.5222 
2025-02-24 10:08:12.762448: val_loss -0.4978 
2025-02-24 10:08:12.767465: Pseudo dice [np.float32(0.7184), np.float32(0.3727)] 
2025-02-24 10:08:12.769978: Epoch time: 42.16 s 
2025-02-24 10:08:12.773997: Yayy! New best EMA pseudo Dice: 0.47600001096725464 
2025-02-24 10:08:13.427196:  
2025-02-24 10:08:13.433717: Epoch 26 
2025-02-24 10:08:13.436227: Current learning rate: 0.00906 
2025-02-24 10:08:55.553249: train_loss -0.5347 
2025-02-24 10:08:55.558765: val_loss -0.5186 
2025-02-24 10:08:55.562281: Pseudo dice [np.float32(0.7405), np.float32(0.4113)] 
2025-02-24 10:08:55.566287: Epoch time: 42.13 s 
2025-02-24 10:08:55.569803: Yayy! New best EMA pseudo Dice: 0.4860000014305115 
2025-02-24 10:08:56.240315:  
2025-02-24 10:08:56.245837: Epoch 27 
2025-02-24 10:08:56.249355: Current learning rate: 0.00902 
2025-02-24 10:09:38.363152: train_loss -0.5313 
2025-02-24 10:09:38.368285: val_loss -0.5345 
2025-02-24 10:09:38.373462: Pseudo dice [np.float32(0.737), np.float32(0.4061)] 
2025-02-24 10:09:38.378001: Epoch time: 42.12 s 
2025-02-24 10:09:38.381512: Yayy! New best EMA pseudo Dice: 0.4945000112056732 
2025-02-24 10:09:39.049448:  
2025-02-24 10:09:39.055017: Epoch 28 
2025-02-24 10:09:39.058564: Current learning rate: 0.00899 
2025-02-24 10:10:21.145083: train_loss -0.5407 
2025-02-24 10:10:21.152617: val_loss -0.4702 
2025-02-24 10:10:21.156127: Pseudo dice [np.float32(0.7174), np.float32(0.3825)] 
2025-02-24 10:10:21.159136: Epoch time: 42.1 s 
2025-02-24 10:10:21.162652: Yayy! New best EMA pseudo Dice: 0.5001000165939331 
2025-02-24 10:10:21.961756:  
2025-02-24 10:10:21.967274: Epoch 29 
2025-02-24 10:10:21.970786: Current learning rate: 0.00895 
2025-02-24 10:11:04.089356: train_loss -0.5396 
2025-02-24 10:11:04.096049: val_loss -0.4532 
2025-02-24 10:11:04.099632: Pseudo dice [np.float32(0.7161), np.float32(0.2535)] 
2025-02-24 10:11:04.103303: Epoch time: 42.13 s 
2025-02-24 10:11:04.614487:  
2025-02-24 10:11:04.619652: Epoch 30 
2025-02-24 10:11:04.623219: Current learning rate: 0.00891 
2025-02-24 10:11:46.713742: train_loss -0.5465 
2025-02-24 10:11:46.720339: val_loss -0.5679 
2025-02-24 10:11:46.723974: Pseudo dice [np.float32(0.7417), np.float32(0.4825)] 
2025-02-24 10:11:46.727531: Epoch time: 42.1 s 
2025-02-24 10:11:46.730095: Yayy! New best EMA pseudo Dice: 0.5098999738693237 
2025-02-24 10:11:47.401088:  
2025-02-24 10:11:47.406612: Epoch 31 
2025-02-24 10:11:47.410122: Current learning rate: 0.00888 
2025-02-24 10:12:29.489866: train_loss -0.5197 
2025-02-24 10:12:29.496384: val_loss -0.4402 
2025-02-24 10:12:29.499894: Pseudo dice [np.float32(0.7335), np.float32(0.2562)] 
2025-02-24 10:12:29.502903: Epoch time: 42.09 s 
2025-02-24 10:12:30.015953:  
2025-02-24 10:12:30.021502: Epoch 32 
2025-02-24 10:12:30.024596: Current learning rate: 0.00884 
2025-02-24 10:13:12.113378: train_loss -0.5344 
2025-02-24 10:13:12.119431: val_loss -0.4848 
2025-02-24 10:13:12.121937: Pseudo dice [np.float32(0.7127), np.float32(0.3182)] 
2025-02-24 10:13:12.125946: Epoch time: 42.1 s 
2025-02-24 10:13:12.635869:  
2025-02-24 10:13:12.641422: Epoch 33 
2025-02-24 10:13:12.643973: Current learning rate: 0.0088 
2025-02-24 10:13:54.748795: train_loss -0.5483 
2025-02-24 10:13:54.754909: val_loss -0.4681 
2025-02-24 10:13:54.759641: Pseudo dice [np.float32(0.7161), np.float32(0.2943)] 
2025-02-24 10:13:54.762866: Epoch time: 42.11 s 
2025-02-24 10:13:55.273845:  
2025-02-24 10:13:55.279418: Epoch 34 
2025-02-24 10:13:55.282452: Current learning rate: 0.00877 
2025-02-24 10:14:37.385262: train_loss -0.5561 
2025-02-24 10:14:37.391784: val_loss -0.4808 
2025-02-24 10:14:37.395792: Pseudo dice [np.float32(0.714), np.float32(0.3721)] 
2025-02-24 10:14:37.399331: Epoch time: 42.11 s 
2025-02-24 10:14:37.402358: Yayy! New best EMA pseudo Dice: 0.5121999979019165 
2025-02-24 10:14:38.066189:  
2025-02-24 10:14:38.071725: Epoch 35 
2025-02-24 10:14:38.075272: Current learning rate: 0.00873 
2025-02-24 10:15:20.155087: train_loss -0.5755 
2025-02-24 10:15:20.161100: val_loss -0.5082 
2025-02-24 10:15:20.164606: Pseudo dice [np.float32(0.7353), np.float32(0.3964)] 
2025-02-24 10:15:20.167614: Epoch time: 42.09 s 
2025-02-24 10:15:20.171131: Yayy! New best EMA pseudo Dice: 0.5174999833106995 
2025-02-24 10:15:20.835478:  
2025-02-24 10:15:20.841601: Epoch 36 
2025-02-24 10:15:20.844700: Current learning rate: 0.00869 
2025-02-24 10:16:02.946665: train_loss -0.5611 
2025-02-24 10:16:02.952751: val_loss -0.5564 
2025-02-24 10:16:02.956001: Pseudo dice [np.float32(0.7423), np.float32(0.4762)] 
2025-02-24 10:16:02.958551: Epoch time: 42.11 s 
2025-02-24 10:16:02.961609: Yayy! New best EMA pseudo Dice: 0.5267000198364258 
2025-02-24 10:16:03.811943:  
2025-02-24 10:16:03.818528: Epoch 37 
2025-02-24 10:16:03.824128: Current learning rate: 0.00866 
2025-02-24 10:16:45.918828: train_loss -0.5426 
2025-02-24 10:16:45.925350: val_loss -0.5128 
2025-02-24 10:16:45.928917: Pseudo dice [np.float32(0.745), np.float32(0.3481)] 
2025-02-24 10:16:45.931464: Epoch time: 42.11 s 
2025-02-24 10:16:45.934980: Yayy! New best EMA pseudo Dice: 0.5286999940872192 
2025-02-24 10:16:46.625452:  
2025-02-24 10:16:46.631010: Epoch 38 
2025-02-24 10:16:46.633552: Current learning rate: 0.00862 
2025-02-24 10:17:28.743586: train_loss -0.5741 
2025-02-24 10:17:28.749102: val_loss -0.5431 
2025-02-24 10:17:28.752612: Pseudo dice [np.float32(0.7372), np.float32(0.4394)] 
2025-02-24 10:17:28.756627: Epoch time: 42.12 s 
2025-02-24 10:17:28.759136: Yayy! New best EMA pseudo Dice: 0.534600019454956 
2025-02-24 10:17:29.426251:  
2025-02-24 10:17:29.430809: Epoch 39 
2025-02-24 10:17:29.434847: Current learning rate: 0.00858 
2025-02-24 10:18:11.551149: train_loss -0.5549 
2025-02-24 10:18:11.556662: val_loss -0.5202 
2025-02-24 10:18:11.560171: Pseudo dice [np.float32(0.7504), np.float32(0.4245)] 
2025-02-24 10:18:11.563677: Epoch time: 42.12 s 
2025-02-24 10:18:11.567691: Yayy! New best EMA pseudo Dice: 0.539900004863739 
2025-02-24 10:18:12.257042:  
2025-02-24 10:18:12.263613: Epoch 40 
2025-02-24 10:18:12.267144: Current learning rate: 0.00855 
2025-02-24 10:18:54.377096: train_loss -0.5819 
2025-02-24 10:18:54.383643: val_loss -0.5401 
2025-02-24 10:18:54.387671: Pseudo dice [np.float32(0.7317), np.float32(0.4474)] 
2025-02-24 10:18:54.391471: Epoch time: 42.12 s 
2025-02-24 10:18:54.394986: Yayy! New best EMA pseudo Dice: 0.5449000000953674 
2025-02-24 10:18:55.070332:  
2025-02-24 10:18:55.076851: Epoch 41 
2025-02-24 10:18:55.080357: Current learning rate: 0.00851 
2025-02-24 10:19:37.203938: train_loss -0.5784 
2025-02-24 10:19:37.210468: val_loss -0.544 
2025-02-24 10:19:37.215481: Pseudo dice [np.float32(0.7642), np.float32(0.4156)] 
2025-02-24 10:19:37.220502: Epoch time: 42.13 s 
2025-02-24 10:19:37.225015: Yayy! New best EMA pseudo Dice: 0.5493999719619751 
2025-02-24 10:19:37.887445:  
2025-02-24 10:19:37.893552: Epoch 42 
2025-02-24 10:19:37.897114: Current learning rate: 0.00847 
2025-02-24 10:20:20.007585: train_loss -0.5795 
2025-02-24 10:20:20.014253: val_loss -0.5252 
2025-02-24 10:20:20.017812: Pseudo dice [np.float32(0.7775), np.float32(0.3869)] 
2025-02-24 10:20:20.020847: Epoch time: 42.12 s 
2025-02-24 10:20:20.025607: Yayy! New best EMA pseudo Dice: 0.5526999831199646 
2025-02-24 10:20:20.682685:  
2025-02-24 10:20:20.689240: Epoch 43 
2025-02-24 10:20:20.692799: Current learning rate: 0.00844 
2025-02-24 10:21:02.844534: train_loss -0.5865 
2025-02-24 10:21:02.851048: val_loss -0.5835 
2025-02-24 10:21:02.854427: Pseudo dice [np.float32(0.768), np.float32(0.5334)] 
2025-02-24 10:21:02.858439: Epoch time: 42.16 s 
2025-02-24 10:21:02.861950: Yayy! New best EMA pseudo Dice: 0.5625 
2025-02-24 10:21:03.514895:  
2025-02-24 10:21:03.520912: Epoch 44 
2025-02-24 10:21:03.524419: Current learning rate: 0.0084 
2025-02-24 10:21:45.667617: train_loss -0.5831 
2025-02-24 10:21:45.673631: val_loss -0.5305 
2025-02-24 10:21:45.677641: Pseudo dice [np.float32(0.7634), np.float32(0.3086)] 
2025-02-24 10:21:45.681150: Epoch time: 42.15 s 
2025-02-24 10:21:46.330423:  
2025-02-24 10:21:46.335970: Epoch 45 
2025-02-24 10:21:46.340011: Current learning rate: 0.00836 
2025-02-24 10:22:28.455568: train_loss -0.5853 
2025-02-24 10:22:28.462768: val_loss -0.5957 
2025-02-24 10:22:28.466300: Pseudo dice [np.float32(0.7483), np.float32(0.5307)] 
2025-02-24 10:22:28.469854: Epoch time: 42.13 s 
2025-02-24 10:22:28.473954: Yayy! New best EMA pseudo Dice: 0.567799985408783 
2025-02-24 10:22:29.141693:  
2025-02-24 10:22:29.147277: Epoch 46 
2025-02-24 10:22:29.150333: Current learning rate: 0.00833 
2025-02-24 10:23:11.264074: train_loss -0.5729 
2025-02-24 10:23:11.269595: val_loss -0.4663 
2025-02-24 10:23:11.273112: Pseudo dice [np.float32(0.7161), np.float32(0.3175)] 
2025-02-24 10:23:11.277129: Epoch time: 42.12 s 
2025-02-24 10:23:11.789522:  
2025-02-24 10:23:11.796177: Epoch 47 
2025-02-24 10:23:11.799738: Current learning rate: 0.00829 
2025-02-24 10:23:53.907487: train_loss -0.5861 
2025-02-24 10:23:53.913683: val_loss -0.5296 
2025-02-24 10:23:53.917767: Pseudo dice [np.float32(0.7542), np.float32(0.4299)] 
2025-02-24 10:23:53.921321: Epoch time: 42.12 s 
2025-02-24 10:23:54.426911:  
2025-02-24 10:23:54.433539: Epoch 48 
2025-02-24 10:23:54.437103: Current learning rate: 0.00825 
2025-02-24 10:24:36.539651: train_loss -0.5887 
2025-02-24 10:24:36.546180: val_loss -0.5355 
2025-02-24 10:24:36.550203: Pseudo dice [np.float32(0.7448), np.float32(0.4637)] 
2025-02-24 10:24:36.553754: Epoch time: 42.11 s 
2025-02-24 10:24:36.557391: Yayy! New best EMA pseudo Dice: 0.5695000290870667 
2025-02-24 10:24:37.225787:  
2025-02-24 10:24:37.232886: Epoch 49 
2025-02-24 10:24:37.236400: Current learning rate: 0.00822 
2025-02-24 10:25:19.325110: train_loss -0.6006 
2025-02-24 10:25:19.332148: val_loss -0.594 
2025-02-24 10:25:19.336659: Pseudo dice [np.float32(0.7845), np.float32(0.5507)] 
2025-02-24 10:25:19.340674: Epoch time: 42.1 s 
2025-02-24 10:25:19.487306: Yayy! New best EMA pseudo Dice: 0.5792999863624573 
2025-02-24 10:25:20.151822:  
2025-02-24 10:25:20.158144: Epoch 50 
2025-02-24 10:25:20.161673: Current learning rate: 0.00818 
2025-02-24 10:26:02.263597: train_loss -0.5894 
2025-02-24 10:26:02.270116: val_loss -0.555 
2025-02-24 10:26:02.273627: Pseudo dice [np.float32(0.7707), np.float32(0.4491)] 
2025-02-24 10:26:02.277635: Epoch time: 42.11 s 
2025-02-24 10:26:02.281146: Yayy! New best EMA pseudo Dice: 0.5824000239372253 
2025-02-24 10:26:02.943075:  
2025-02-24 10:26:02.949670: Epoch 51 
2025-02-24 10:26:02.953739: Current learning rate: 0.00814 
2025-02-24 10:26:45.040488: train_loss -0.632 
2025-02-24 10:26:45.045584: val_loss -0.5692 
2025-02-24 10:26:45.049614: Pseudo dice [np.float32(0.7744), np.float32(0.4827)] 
2025-02-24 10:26:45.053166: Epoch time: 42.1 s 
2025-02-24 10:26:45.056964: Yayy! New best EMA pseudo Dice: 0.5870000123977661 
2025-02-24 10:26:45.734589:  
2025-02-24 10:26:45.741205: Epoch 52 
2025-02-24 10:26:45.744758: Current learning rate: 0.00811 
2025-02-24 10:27:27.861807: train_loss -0.6024 
2025-02-24 10:27:27.868319: val_loss -0.551 
2025-02-24 10:27:27.871337: Pseudo dice [np.float32(0.7845), np.float32(0.3233)] 
2025-02-24 10:27:27.875878: Epoch time: 42.13 s 
2025-02-24 10:27:28.529141:  
2025-02-24 10:27:28.534690: Epoch 53 
2025-02-24 10:27:28.539756: Current learning rate: 0.00807 
2025-02-24 10:28:10.625397: train_loss -0.6113 
2025-02-24 10:28:10.631951: val_loss -0.5449 
2025-02-24 10:28:10.635489: Pseudo dice [np.float32(0.7666), np.float32(0.4417)] 
2025-02-24 10:28:10.639499: Epoch time: 42.1 s 
2025-02-24 10:28:11.144567:  
2025-02-24 10:28:11.151191: Epoch 54 
2025-02-24 10:28:11.154739: Current learning rate: 0.00803 
2025-02-24 10:28:53.304311: train_loss -0.6042 
2025-02-24 10:28:53.310324: val_loss -0.5787 
2025-02-24 10:28:53.314332: Pseudo dice [np.float32(0.7892), np.float32(0.4662)] 
2025-02-24 10:28:53.317841: Epoch time: 42.16 s 
2025-02-24 10:28:53.321848: Yayy! New best EMA pseudo Dice: 0.589900016784668 
2025-02-24 10:28:53.995574:  
2025-02-24 10:28:54.001144: Epoch 55 
2025-02-24 10:28:54.005708: Current learning rate: 0.008 
2025-02-24 10:29:36.092895: train_loss -0.6104 
2025-02-24 10:29:36.099507: val_loss -0.5787 
2025-02-24 10:29:36.103393: Pseudo dice [np.float32(0.7757), np.float32(0.4532)] 
2025-02-24 10:29:36.106910: Epoch time: 42.1 s 
2025-02-24 10:29:36.111747: Yayy! New best EMA pseudo Dice: 0.5924000144004822 
2025-02-24 10:29:36.770784:  
2025-02-24 10:29:36.777305: Epoch 56 
2025-02-24 10:29:36.783819: Current learning rate: 0.00796 
2025-02-24 10:30:18.876941: train_loss -0.6176 
2025-02-24 10:30:18.883135: val_loss -0.5562 
2025-02-24 10:30:18.888192: Pseudo dice [np.float32(0.7865), np.float32(0.3599)] 
2025-02-24 10:30:18.894257: Epoch time: 42.11 s 
2025-02-24 10:30:19.410196:  
2025-02-24 10:30:19.417944: Epoch 57 
2025-02-24 10:30:19.422991: Current learning rate: 0.00792 
2025-02-24 10:31:01.524568: train_loss -0.6644 
2025-02-24 10:31:01.530581: val_loss -0.539 
2025-02-24 10:31:01.533588: Pseudo dice [np.float32(0.7696), np.float32(0.4097)] 
2025-02-24 10:31:01.537097: Epoch time: 42.11 s 
2025-02-24 10:31:02.042832:  
2025-02-24 10:31:02.048918: Epoch 58 
2025-02-24 10:31:02.051963: Current learning rate: 0.00789 
2025-02-24 10:31:44.150406: train_loss -0.5983 
2025-02-24 10:31:44.156928: val_loss -0.5412 
2025-02-24 10:31:44.160941: Pseudo dice [np.float32(0.7407), np.float32(0.4414)] 
2025-02-24 10:31:44.165452: Epoch time: 42.11 s 
2025-02-24 10:31:44.682073:  
2025-02-24 10:31:44.687620: Epoch 59 
2025-02-24 10:31:44.690160: Current learning rate: 0.00785 
2025-02-24 10:32:26.817941: train_loss -0.5673 
2025-02-24 10:32:26.823967: val_loss -0.5655 
2025-02-24 10:32:26.826480: Pseudo dice [np.float32(0.7656), np.float32(0.4734)] 
2025-02-24 10:32:26.830488: Epoch time: 42.14 s 
2025-02-24 10:32:26.834000: Yayy! New best EMA pseudo Dice: 0.5932999849319458 
2025-02-24 10:32:27.501181:  
2025-02-24 10:32:27.507200: Epoch 60 
2025-02-24 10:32:27.509705: Current learning rate: 0.00781 
2025-02-24 10:33:09.624906: train_loss -0.5988 
2025-02-24 10:33:09.631450: val_loss -0.5593 
2025-02-24 10:33:09.634981: Pseudo dice [np.float32(0.743), np.float32(0.4921)] 
2025-02-24 10:33:09.637575: Epoch time: 42.12 s 
2025-02-24 10:33:09.641345: Yayy! New best EMA pseudo Dice: 0.59579998254776 
2025-02-24 10:33:10.475829:  
2025-02-24 10:33:10.480840: Epoch 61 
2025-02-24 10:33:10.484359: Current learning rate: 0.00777 
2025-02-24 10:33:52.580627: train_loss -0.6402 
2025-02-24 10:33:52.586668: val_loss -0.538 
2025-02-24 10:33:52.589173: Pseudo dice [np.float32(0.7527), np.float32(0.4348)] 
2025-02-24 10:33:52.593189: Epoch time: 42.11 s 
2025-02-24 10:33:53.108757:  
2025-02-24 10:33:53.114300: Epoch 62 
2025-02-24 10:33:53.117848: Current learning rate: 0.00774 
2025-02-24 10:34:35.193913: train_loss -0.6307 
2025-02-24 10:34:35.198924: val_loss -0.5288 
2025-02-24 10:34:35.203947: Pseudo dice [np.float32(0.7489), np.float32(0.4965)] 
2025-02-24 10:34:35.208455: Epoch time: 42.09 s 
2025-02-24 10:34:35.213976: Yayy! New best EMA pseudo Dice: 0.5982999801635742 
2025-02-24 10:34:35.884468:  
2025-02-24 10:34:35.889500: Epoch 63 
2025-02-24 10:34:35.893572: Current learning rate: 0.0077 
2025-02-24 10:35:17.980218: train_loss -0.6321 
2025-02-24 10:35:17.986275: val_loss -0.6004 
2025-02-24 10:35:17.989355: Pseudo dice [np.float32(0.7838), np.float32(0.5929)] 
2025-02-24 10:35:17.992867: Epoch time: 42.1 s 
2025-02-24 10:35:17.995375: Yayy! New best EMA pseudo Dice: 0.6072999835014343 
2025-02-24 10:35:18.658661:  
2025-02-24 10:35:18.664949: Epoch 64 
2025-02-24 10:35:18.667460: Current learning rate: 0.00766 
2025-02-24 10:36:00.790692: train_loss -0.6388 
2025-02-24 10:36:00.796366: val_loss -0.5519 
2025-02-24 10:36:00.799875: Pseudo dice [np.float32(0.7711), np.float32(0.4817)] 
2025-02-24 10:36:00.803386: Epoch time: 42.13 s 
2025-02-24 10:36:00.806397: Yayy! New best EMA pseudo Dice: 0.6092000007629395 
2025-02-24 10:36:01.480931:  
2025-02-24 10:36:01.486454: Epoch 65 
2025-02-24 10:36:01.489966: Current learning rate: 0.00763 
2025-02-24 10:36:43.592994: train_loss -0.6467 
2025-02-24 10:36:43.599072: val_loss -0.5499 
2025-02-24 10:36:43.604724: Pseudo dice [np.float32(0.7674), np.float32(0.4466)] 
2025-02-24 10:36:43.609365: Epoch time: 42.11 s 
2025-02-24 10:36:44.123019:  
2025-02-24 10:36:44.128031: Epoch 66 
2025-02-24 10:36:44.131539: Current learning rate: 0.00759 
2025-02-24 10:37:26.258909: train_loss -0.6663 
2025-02-24 10:37:26.263991: val_loss -0.5356 
2025-02-24 10:37:26.267502: Pseudo dice [np.float32(0.7786), np.float32(0.3385)] 
2025-02-24 10:37:26.271515: Epoch time: 42.14 s 
2025-02-24 10:37:26.787338:  
2025-02-24 10:37:26.792855: Epoch 67 
2025-02-24 10:37:26.795363: Current learning rate: 0.00755 
2025-02-24 10:38:14.125139: train_loss -0.654 
2025-02-24 10:38:14.132893: val_loss -0.5529 
2025-02-24 10:38:14.137947: Pseudo dice [np.float32(0.7827), np.float32(0.4618)] 
2025-02-24 10:38:14.142048: Epoch time: 47.34 s 
2025-02-24 10:38:14.667673:  
2025-02-24 10:38:14.673799: Epoch 68 
2025-02-24 10:38:14.676851: Current learning rate: 0.00751 
2025-02-24 10:38:58.088575: train_loss -0.6532 
2025-02-24 10:38:58.093714: val_loss -0.58 
2025-02-24 10:38:58.099274: Pseudo dice [np.float32(0.7906), np.float32(0.4926)] 
2025-02-24 10:38:58.105296: Epoch time: 43.42 s 
2025-02-24 10:38:58.110319: Yayy! New best EMA pseudo Dice: 0.6093999743461609 
2025-02-24 10:38:58.940043:  
2025-02-24 10:38:58.945556: Epoch 69 
2025-02-24 10:38:58.950065: Current learning rate: 0.00748 
2025-02-24 10:39:42.355465: train_loss -0.6611 
2025-02-24 10:39:42.361489: val_loss -0.576 
2025-02-24 10:39:42.365505: Pseudo dice [np.float32(0.7656), np.float32(0.5242)] 
2025-02-24 10:39:42.368015: Epoch time: 43.42 s 
2025-02-24 10:39:42.371533: Yayy! New best EMA pseudo Dice: 0.6129000186920166 
2025-02-24 10:39:43.065465:  
2025-02-24 10:39:43.070482: Epoch 70 
2025-02-24 10:39:43.074001: Current learning rate: 0.00744 
2025-02-24 10:40:26.526331: train_loss -0.6687 
2025-02-24 10:40:26.532441: val_loss -0.5523 
2025-02-24 10:40:26.535948: Pseudo dice [np.float32(0.7648), np.float32(0.4829)] 
2025-02-24 10:40:26.538959: Epoch time: 43.46 s 
2025-02-24 10:40:26.543976: Yayy! New best EMA pseudo Dice: 0.6140000224113464 
2025-02-24 10:40:27.232290:  
2025-02-24 10:40:27.238337: Epoch 71 
2025-02-24 10:40:27.241464: Current learning rate: 0.0074 
2025-02-24 10:41:10.655697: train_loss -0.6454 
2025-02-24 10:41:10.661713: val_loss -0.5702 
2025-02-24 10:41:10.665720: Pseudo dice [np.float32(0.7662), np.float32(0.4287)] 
2025-02-24 10:41:10.670771: Epoch time: 43.42 s 
2025-02-24 10:41:11.201785:  
2025-02-24 10:41:11.206805: Epoch 72 
2025-02-24 10:41:11.210321: Current learning rate: 0.00737 
2025-02-24 10:41:54.689302: train_loss -0.6538 
2025-02-24 10:41:54.695325: val_loss -0.5106 
2025-02-24 10:41:54.698837: Pseudo dice [np.float32(0.7689), np.float32(0.3708)] 
2025-02-24 10:41:54.701845: Epoch time: 43.49 s 
2025-02-24 10:41:55.229387:  
2025-02-24 10:41:55.234041: Epoch 73 
2025-02-24 10:41:55.239087: Current learning rate: 0.00733 
2025-02-24 10:42:38.673358: train_loss -0.6186 
2025-02-24 10:42:38.679884: val_loss -0.5542 
2025-02-24 10:42:38.682386: Pseudo dice [np.float32(0.7888), np.float32(0.3916)] 
2025-02-24 10:42:38.686397: Epoch time: 43.44 s 
2025-02-24 10:42:39.215619:  
2025-02-24 10:42:39.220643: Epoch 74 
2025-02-24 10:42:39.224440: Current learning rate: 0.00729 
2025-02-24 10:43:22.877788: train_loss -0.6532 
2025-02-24 10:43:22.885309: val_loss -0.5642 
2025-02-24 10:43:22.889321: Pseudo dice [np.float32(0.7747), np.float32(0.4422)] 
2025-02-24 10:43:22.892831: Epoch time: 43.66 s 
2025-02-24 10:43:23.423748:  
2025-02-24 10:43:23.429809: Epoch 75 
2025-02-24 10:43:23.435392: Current learning rate: 0.00725 
2025-02-24 10:44:06.857245: train_loss -0.6329 
2025-02-24 10:44:06.863760: val_loss -0.6168 
2025-02-24 10:44:06.866271: Pseudo dice [np.float32(0.7858), np.float32(0.6132)] 
2025-02-24 10:44:06.869791: Epoch time: 43.43 s 
2025-02-24 10:44:06.873810: Yayy! New best EMA pseudo Dice: 0.6158000230789185 
2025-02-24 10:44:07.579195:  
2025-02-24 10:44:07.585722: Epoch 76 
2025-02-24 10:44:07.589732: Current learning rate: 0.00722 
2025-02-24 10:44:50.991998: train_loss -0.643 
2025-02-24 10:44:50.998552: val_loss -0.57 
2025-02-24 10:44:51.002652: Pseudo dice [np.float32(0.7519), np.float32(0.4845)] 
2025-02-24 10:44:51.005665: Epoch time: 43.41 s 
2025-02-24 10:44:51.009177: Yayy! New best EMA pseudo Dice: 0.616100013256073 
2025-02-24 10:44:51.850981:  
2025-02-24 10:44:51.855994: Epoch 77 
2025-02-24 10:44:51.860507: Current learning rate: 0.00718 
2025-02-24 10:45:35.285929: train_loss -0.6754 
2025-02-24 10:45:35.291469: val_loss -0.5586 
2025-02-24 10:45:35.295980: Pseudo dice [np.float32(0.7859), np.float32(0.4838)] 
2025-02-24 10:45:35.298990: Epoch time: 43.44 s 
2025-02-24 10:45:35.302508: Yayy! New best EMA pseudo Dice: 0.617900013923645 
2025-02-24 10:45:35.985091:  
2025-02-24 10:45:35.990139: Epoch 78 
2025-02-24 10:45:35.994017: Current learning rate: 0.00714 
2025-02-24 10:46:19.354246: train_loss -0.655 
2025-02-24 10:46:19.360400: val_loss -0.5039 
2025-02-24 10:46:19.364463: Pseudo dice [np.float32(0.7407), np.float32(0.3727)] 
2025-02-24 10:46:19.367974: Epoch time: 43.37 s 
2025-02-24 10:46:19.905452:  
2025-02-24 10:46:19.911589: Epoch 79 
2025-02-24 10:46:19.915682: Current learning rate: 0.0071 
2025-02-24 10:47:03.324555: train_loss -0.6596 
2025-02-24 10:47:03.331071: val_loss -0.5818 
2025-02-24 10:47:03.334585: Pseudo dice [np.float32(0.7844), np.float32(0.5059)] 
2025-02-24 10:47:03.338093: Epoch time: 43.42 s 
2025-02-24 10:47:03.867988:  
2025-02-24 10:47:03.874527: Epoch 80 
2025-02-24 10:47:03.877558: Current learning rate: 0.00707 
2025-02-24 10:47:47.101966: train_loss -0.6442 
2025-02-24 10:47:47.107485: val_loss -0.5693 
2025-02-24 10:47:47.112002: Pseudo dice [np.float32(0.7679), np.float32(0.4567)] 
2025-02-24 10:47:47.117016: Epoch time: 43.23 s 
2025-02-24 10:47:47.660396:  
2025-02-24 10:47:47.665429: Epoch 81 
2025-02-24 10:47:47.668324: Current learning rate: 0.00703 
2025-02-24 10:48:29.827463: train_loss -0.6763 
2025-02-24 10:48:29.833566: val_loss -0.584 
2025-02-24 10:48:29.838175: Pseudo dice [np.float32(0.7834), np.float32(0.5133)] 
2025-02-24 10:48:29.841831: Epoch time: 42.17 s 
2025-02-24 10:48:29.845391: Yayy! New best EMA pseudo Dice: 0.6182000041007996 
2025-02-24 10:48:30.550655:  
2025-02-24 10:48:30.557179: Epoch 82 
2025-02-24 10:48:30.560694: Current learning rate: 0.00699 
2025-02-24 10:49:12.712687: train_loss -0.6846 
2025-02-24 10:49:12.718271: val_loss -0.5934 
2025-02-24 10:49:12.720812: Pseudo dice [np.float32(0.7796), np.float32(0.5277)] 
2025-02-24 10:49:12.724874: Epoch time: 42.16 s 
2025-02-24 10:49:12.727944: Yayy! New best EMA pseudo Dice: 0.6218000054359436 
2025-02-24 10:49:13.383264:  
2025-02-24 10:49:13.388785: Epoch 83 
2025-02-24 10:49:13.392301: Current learning rate: 0.00696 
2025-02-24 10:49:55.558119: train_loss -0.642 
2025-02-24 10:49:55.564642: val_loss -0.5123 
2025-02-24 10:49:55.568654: Pseudo dice [np.float32(0.7522), np.float32(0.371)] 
2025-02-24 10:49:55.573670: Epoch time: 42.18 s 
2025-02-24 10:49:56.079475:  
2025-02-24 10:49:56.085104: Epoch 84 
2025-02-24 10:49:56.088640: Current learning rate: 0.00692 
2025-02-24 10:50:38.240843: train_loss -0.6667 
2025-02-24 10:50:38.246406: val_loss -0.5099 
2025-02-24 10:50:38.248957: Pseudo dice [np.float32(0.757), np.float32(0.3721)] 
2025-02-24 10:50:38.252983: Epoch time: 42.16 s 
2025-02-24 10:50:38.925049:  
2025-02-24 10:50:38.930063: Epoch 85 
2025-02-24 10:50:38.934103: Current learning rate: 0.00688 
2025-02-24 10:51:21.080595: train_loss -0.6888 
2025-02-24 10:51:21.088217: val_loss -0.5658 
2025-02-24 10:51:21.092254: Pseudo dice [np.float32(0.7803), np.float32(0.4623)] 
2025-02-24 10:51:21.095304: Epoch time: 42.16 s 
2025-02-24 10:51:21.595523:  
2025-02-24 10:51:21.601566: Epoch 86 
2025-02-24 10:51:21.604617: Current learning rate: 0.00684 
2025-02-24 10:52:03.762222: train_loss -0.7028 
2025-02-24 10:52:03.767778: val_loss -0.5691 
2025-02-24 10:52:03.771788: Pseudo dice [np.float32(0.7811), np.float32(0.4781)] 
2025-02-24 10:52:03.775044: Epoch time: 42.17 s 
2025-02-24 10:52:04.276898:  
2025-02-24 10:52:04.282453: Epoch 87 
2025-02-24 10:52:04.286493: Current learning rate: 0.0068 
2025-02-24 10:52:46.440624: train_loss -0.7047 
2025-02-24 10:52:46.447166: val_loss -0.5292 
2025-02-24 10:52:46.450736: Pseudo dice [np.float32(0.7913), np.float32(0.3789)] 
2025-02-24 10:52:46.453792: Epoch time: 42.16 s 
2025-02-24 10:52:46.957806:  
2025-02-24 10:52:46.963360: Epoch 88 
2025-02-24 10:52:46.966882: Current learning rate: 0.00677 
2025-02-24 10:53:29.119386: train_loss -0.6702 
2025-02-24 10:53:29.125903: val_loss -0.5258 
2025-02-24 10:53:29.129912: Pseudo dice [np.float32(0.768), np.float32(0.3776)] 
2025-02-24 10:53:29.132418: Epoch time: 42.16 s 
2025-02-24 10:53:29.632936:  
2025-02-24 10:53:29.638528: Epoch 89 
2025-02-24 10:53:29.642144: Current learning rate: 0.00673 
2025-02-24 10:54:11.789844: train_loss -0.687 
2025-02-24 10:54:11.795578: val_loss -0.5836 
2025-02-24 10:54:11.799655: Pseudo dice [np.float32(0.7994), np.float32(0.4756)] 
2025-02-24 10:54:11.802735: Epoch time: 42.16 s 
2025-02-24 10:54:12.302894:  
2025-02-24 10:54:12.308421: Epoch 90 
2025-02-24 10:54:12.311937: Current learning rate: 0.00669 
2025-02-24 10:54:54.466396: train_loss -0.7045 
2025-02-24 10:54:54.473480: val_loss -0.5579 
2025-02-24 10:54:54.478492: Pseudo dice [np.float32(0.7671), np.float32(0.4935)] 
2025-02-24 10:54:54.482057: Epoch time: 42.16 s 
2025-02-24 10:54:54.986934:  
2025-02-24 10:54:54.992022: Epoch 91 
2025-02-24 10:54:54.995647: Current learning rate: 0.00665 
2025-02-24 10:55:37.114942: train_loss -0.7017 
2025-02-24 10:55:37.121456: val_loss -0.539 
2025-02-24 10:55:37.124969: Pseudo dice [np.float32(0.8004), np.float32(0.4468)] 
2025-02-24 10:55:37.127476: Epoch time: 42.13 s 
2025-02-24 10:55:37.632215:  
2025-02-24 10:55:37.638774: Epoch 92 
2025-02-24 10:55:37.642325: Current learning rate: 0.00662 
2025-02-24 10:56:19.772500: train_loss -0.7 
2025-02-24 10:56:19.779158: val_loss -0.5224 
2025-02-24 10:56:19.782212: Pseudo dice [np.float32(0.7754), np.float32(0.4239)] 
2025-02-24 10:56:19.785776: Epoch time: 42.14 s 
2025-02-24 10:56:20.284678:  
2025-02-24 10:56:20.289691: Epoch 93 
2025-02-24 10:56:20.293202: Current learning rate: 0.00658 
2025-02-24 10:57:02.425081: train_loss -0.688 
2025-02-24 10:57:02.431599: val_loss -0.6054 
2025-02-24 10:57:02.435116: Pseudo dice [np.float32(0.7737), np.float32(0.5526)] 
2025-02-24 10:57:02.438621: Epoch time: 42.14 s 
2025-02-24 10:57:03.103162:  
2025-02-24 10:57:03.109220: Epoch 94 
2025-02-24 10:57:03.111727: Current learning rate: 0.00654 
2025-02-24 10:57:45.211108: train_loss -0.6607 
2025-02-24 10:57:45.217626: val_loss -0.5653 
2025-02-24 10:57:45.221136: Pseudo dice [np.float32(0.7747), np.float32(0.5018)] 
2025-02-24 10:57:45.225145: Epoch time: 42.11 s 
2025-02-24 10:57:45.725226:  
2025-02-24 10:57:45.730870: Epoch 95 
2025-02-24 10:57:45.734907: Current learning rate: 0.0065 
2025-02-24 10:58:27.826696: train_loss -0.6871 
2025-02-24 10:58:27.834270: val_loss -0.5583 
2025-02-24 10:58:27.837780: Pseudo dice [np.float32(0.7525), np.float32(0.4677)] 
2025-02-24 10:58:27.840288: Epoch time: 42.1 s 
2025-02-24 10:58:28.341114:  
2025-02-24 10:58:28.345178: Epoch 96 
2025-02-24 10:58:28.348709: Current learning rate: 0.00647 
2025-02-24 10:59:10.459810: train_loss -0.7027 
2025-02-24 10:59:10.465825: val_loss -0.5464 
2025-02-24 10:59:10.469333: Pseudo dice [np.float32(0.767), np.float32(0.5157)] 
2025-02-24 10:59:10.472343: Epoch time: 42.12 s 
2025-02-24 10:59:10.986377:  
2025-02-24 10:59:10.991891: Epoch 97 
2025-02-24 10:59:10.995403: Current learning rate: 0.00643 
2025-02-24 10:59:53.111435: train_loss -0.6872 
2025-02-24 10:59:53.117475: val_loss -0.541 
2025-02-24 10:59:53.121485: Pseudo dice [np.float32(0.7767), np.float32(0.4114)] 
2025-02-24 10:59:53.124993: Epoch time: 42.13 s 
2025-02-24 10:59:53.637053:  
2025-02-24 10:59:53.642242: Epoch 98 
2025-02-24 10:59:53.646306: Current learning rate: 0.00639 
2025-02-24 11:00:35.775586: train_loss -0.7269 
2025-02-24 11:00:35.782102: val_loss -0.5958 
2025-02-24 11:00:35.785611: Pseudo dice [np.float32(0.7665), np.float32(0.5458)] 
2025-02-24 11:00:35.789120: Epoch time: 42.14 s 
2025-02-24 11:00:36.295619:  
2025-02-24 11:00:36.300658: Epoch 99 
2025-02-24 11:00:36.304712: Current learning rate: 0.00635 
2025-02-24 11:01:18.814220: train_loss -0.7001 
2025-02-24 11:01:18.820743: val_loss -0.5447 
2025-02-24 11:01:18.824259: Pseudo dice [np.float32(0.7762), np.float32(0.4741)] 
2025-02-24 11:01:18.826765: Epoch time: 42.52 s 
2025-02-24 11:01:18.969491: Yayy! New best EMA pseudo Dice: 0.621999979019165 
2025-02-24 11:01:19.615808:  
2025-02-24 11:01:19.621834: Epoch 100 
2025-02-24 11:01:19.625349: Current learning rate: 0.00631 
2025-02-24 11:02:06.738689: train_loss -0.6894 
2025-02-24 11:02:06.744401: val_loss -0.5634 
2025-02-24 11:02:06.747962: Pseudo dice [np.float32(0.7513), np.float32(0.4665)] 
2025-02-24 11:02:06.751496: Epoch time: 47.12 s 
2025-02-24 11:02:07.264628:  
2025-02-24 11:02:07.271144: Epoch 101 
2025-02-24 11:02:07.274652: Current learning rate: 0.00628 
2025-02-24 11:02:50.613707: train_loss -0.6948 
2025-02-24 11:02:50.620232: val_loss -0.5711 
2025-02-24 11:02:50.624244: Pseudo dice [np.float32(0.7655), np.float32(0.5085)] 
2025-02-24 11:02:50.627756: Epoch time: 43.35 s 
2025-02-24 11:02:50.631771: Yayy! New best EMA pseudo Dice: 0.6223000288009644 
2025-02-24 11:02:51.490623:  
2025-02-24 11:02:51.494664: Epoch 102 
2025-02-24 11:02:51.499844: Current learning rate: 0.00624 
2025-02-24 11:03:34.803838: train_loss -0.6909 
2025-02-24 11:03:34.809879: val_loss -0.5632 
2025-02-24 11:03:34.813486: Pseudo dice [np.float32(0.7735), np.float32(0.5544)] 
2025-02-24 11:03:34.817285: Epoch time: 43.31 s 
2025-02-24 11:03:34.820452: Yayy! New best EMA pseudo Dice: 0.6265000104904175 
2025-02-24 11:03:35.502607:  
2025-02-24 11:03:35.508736: Epoch 103 
2025-02-24 11:03:35.511807: Current learning rate: 0.0062 
2025-02-24 11:04:18.881460: train_loss -0.7095 
2025-02-24 11:04:18.887610: val_loss -0.5732 
2025-02-24 11:04:18.890655: Pseudo dice [np.float32(0.7853), np.float32(0.5011)] 
2025-02-24 11:04:18.893048: Epoch time: 43.38 s 
2025-02-24 11:04:18.897702: Yayy! New best EMA pseudo Dice: 0.6281999945640564 
2025-02-24 11:04:19.565807:  
2025-02-24 11:04:19.572406: Epoch 104 
2025-02-24 11:04:19.575940: Current learning rate: 0.00616 
2025-02-24 11:05:02.915502: train_loss -0.7227 
2025-02-24 11:05:02.921535: val_loss -0.6124 
2025-02-24 11:05:02.925059: Pseudo dice [np.float32(0.7924), np.float32(0.5796)] 
2025-02-24 11:05:02.928117: Epoch time: 43.35 s 
2025-02-24 11:05:02.932137: Yayy! New best EMA pseudo Dice: 0.633899986743927 
2025-02-24 11:05:03.606045:  
2025-02-24 11:05:03.611088: Epoch 105 
2025-02-24 11:05:03.617483: Current learning rate: 0.00612 
2025-02-24 11:05:46.997698: train_loss -0.7157 
2025-02-24 11:05:47.004746: val_loss -0.5934 
2025-02-24 11:05:47.008293: Pseudo dice [np.float32(0.7804), np.float32(0.559)] 
2025-02-24 11:05:47.011809: Epoch time: 43.39 s 
2025-02-24 11:05:47.015929: Yayy! New best EMA pseudo Dice: 0.637499988079071 
2025-02-24 11:05:47.705978:  
2025-02-24 11:05:47.712494: Epoch 106 
2025-02-24 11:05:47.716006: Current learning rate: 0.00609 
2025-02-24 11:06:31.066078: train_loss -0.709 
2025-02-24 11:06:31.072657: val_loss -0.5978 
2025-02-24 11:06:31.076221: Pseudo dice [np.float32(0.7993), np.float32(0.5752)] 
2025-02-24 11:06:31.079786: Epoch time: 43.36 s 
2025-02-24 11:06:31.083825: Yayy! New best EMA pseudo Dice: 0.6424999833106995 
2025-02-24 11:06:31.743699:  
2025-02-24 11:06:31.750224: Epoch 107 
2025-02-24 11:06:31.753732: Current learning rate: 0.00605 
2025-02-24 11:07:15.246910: train_loss -0.7078 
2025-02-24 11:07:15.254527: val_loss -0.5465 
2025-02-24 11:07:15.257570: Pseudo dice [np.float32(0.7962), np.float32(0.4179)] 
2025-02-24 11:07:15.261135: Epoch time: 43.5 s 
2025-02-24 11:07:15.773838:  
2025-02-24 11:07:15.779850: Epoch 108 
2025-02-24 11:07:15.782863: Current learning rate: 0.00601 
2025-02-24 11:07:59.119071: train_loss -0.73 
2025-02-24 11:07:59.125145: val_loss -0.5815 
2025-02-24 11:07:59.129083: Pseudo dice [np.float32(0.7793), np.float32(0.5425)] 
2025-02-24 11:07:59.132345: Epoch time: 43.35 s 
2025-02-24 11:07:59.642726:  
2025-02-24 11:07:59.648259: Epoch 109 
2025-02-24 11:07:59.651769: Current learning rate: 0.00597 
2025-02-24 11:08:43.050943: train_loss -0.7355 
2025-02-24 11:08:43.056961: val_loss -0.544 
2025-02-24 11:08:43.060465: Pseudo dice [np.float32(0.7841), np.float32(0.4256)] 
2025-02-24 11:08:43.063476: Epoch time: 43.41 s 
2025-02-24 11:08:43.727736:  
2025-02-24 11:08:43.733202: Epoch 110 
2025-02-24 11:08:43.736713: Current learning rate: 0.00593 
2025-02-24 11:09:27.070541: train_loss -0.7026 
2025-02-24 11:09:27.076555: val_loss -0.5263 
2025-02-24 11:09:27.079567: Pseudo dice [np.float32(0.78), np.float32(0.3603)] 
2025-02-24 11:09:27.083079: Epoch time: 43.34 s 
2025-02-24 11:09:27.596569:  
2025-02-24 11:09:27.602598: Epoch 111 
2025-02-24 11:09:27.606117: Current learning rate: 0.0059 
2025-02-24 11:10:10.956294: train_loss -0.7156 
2025-02-24 11:10:10.962404: val_loss -0.5533 
2025-02-24 11:10:10.965915: Pseudo dice [np.float32(0.7724), np.float32(0.4224)] 
2025-02-24 11:10:10.969929: Epoch time: 43.36 s 
2025-02-24 11:10:11.475892:  
2025-02-24 11:10:11.481451: Epoch 112 
2025-02-24 11:10:11.485497: Current learning rate: 0.00586 
2025-02-24 11:10:54.856644: train_loss -0.7258 
2025-02-24 11:10:54.861659: val_loss -0.6124 
2025-02-24 11:10:54.868176: Pseudo dice [np.float32(0.7603), np.float32(0.5965)] 
2025-02-24 11:10:54.871690: Epoch time: 43.38 s 
2025-02-24 11:10:55.378441:  
2025-02-24 11:10:55.383452: Epoch 113 
2025-02-24 11:10:55.386965: Current learning rate: 0.00582 
2025-02-24 11:11:38.840277: train_loss -0.7119 
2025-02-24 11:11:38.847363: val_loss -0.5445 
2025-02-24 11:11:38.851006: Pseudo dice [np.float32(0.7761), np.float32(0.5327)] 
2025-02-24 11:11:38.854564: Epoch time: 43.46 s 
2025-02-24 11:11:39.374137:  
2025-02-24 11:11:39.379181: Epoch 114 
2025-02-24 11:11:39.382786: Current learning rate: 0.00578 
2025-02-24 11:12:21.547281: train_loss -0.7395 
2025-02-24 11:12:21.553298: val_loss -0.5359 
2025-02-24 11:12:21.555802: Pseudo dice [np.float32(0.7675), np.float32(0.4189)] 
2025-02-24 11:12:21.559815: Epoch time: 42.17 s 
2025-02-24 11:12:22.067024:  
2025-02-24 11:12:22.072582: Epoch 115 
2025-02-24 11:12:22.076195: Current learning rate: 0.00574 
2025-02-24 11:13:04.218218: train_loss -0.7303 
2025-02-24 11:13:04.223733: val_loss -0.5175 
2025-02-24 11:13:04.227245: Pseudo dice [np.float32(0.7672), np.float32(0.3882)] 
2025-02-24 11:13:04.229916: Epoch time: 42.15 s 
2025-02-24 11:13:04.750005:  
2025-02-24 11:13:04.755039: Epoch 116 
2025-02-24 11:13:04.759066: Current learning rate: 0.0057 
2025-02-24 11:13:46.901939: train_loss -0.7168 
2025-02-24 11:13:46.908465: val_loss -0.53 
2025-02-24 11:13:46.913487: Pseudo dice [np.float32(0.7716), np.float32(0.406)] 
2025-02-24 11:13:46.918510: Epoch time: 42.15 s 
2025-02-24 11:13:47.440227:  
2025-02-24 11:13:47.446918: Epoch 117 
2025-02-24 11:13:47.450486: Current learning rate: 0.00567 
2025-02-24 11:14:29.580387: train_loss -0.753 
2025-02-24 11:14:29.586158: val_loss -0.5511 
2025-02-24 11:14:29.589647: Pseudo dice [np.float32(0.7865), np.float32(0.452)] 
2025-02-24 11:14:29.593153: Epoch time: 42.14 s 
2025-02-24 11:14:30.260156:  
2025-02-24 11:14:30.265171: Epoch 118 
2025-02-24 11:14:30.268683: Current learning rate: 0.00563 
2025-02-24 11:15:12.419361: train_loss -0.7163 
2025-02-24 11:15:12.425527: val_loss -0.6078 
2025-02-24 11:15:12.428595: Pseudo dice [np.float32(0.7937), np.float32(0.5718)] 
2025-02-24 11:15:12.432153: Epoch time: 42.16 s 
2025-02-24 11:15:12.939977:  
2025-02-24 11:15:12.945585: Epoch 119 
2025-02-24 11:15:12.949127: Current learning rate: 0.00559 
2025-02-24 11:15:55.124691: train_loss -0.7109 
2025-02-24 11:15:55.131213: val_loss -0.5819 
2025-02-24 11:15:55.133718: Pseudo dice [np.float32(0.7684), np.float32(0.5317)] 
2025-02-24 11:15:55.137728: Epoch time: 42.18 s 
2025-02-24 11:15:55.658714:  
2025-02-24 11:15:55.664348: Epoch 120 
2025-02-24 11:15:55.667389: Current learning rate: 0.00555 
2025-02-24 11:16:37.793994: train_loss -0.7176 
2025-02-24 11:16:37.800017: val_loss -0.5597 
2025-02-24 11:16:37.803034: Pseudo dice [np.float32(0.7705), np.float32(0.4864)] 
2025-02-24 11:16:37.806552: Epoch time: 42.14 s 
2025-02-24 11:16:38.322409:  
2025-02-24 11:16:38.328433: Epoch 121 
2025-02-24 11:16:38.330937: Current learning rate: 0.00551 
2025-02-24 11:17:20.475242: train_loss -0.7481 
2025-02-24 11:17:20.481058: val_loss -0.5528 
2025-02-24 11:17:20.485103: Pseudo dice [np.float32(0.7719), np.float32(0.4928)] 
2025-02-24 11:17:20.488139: Epoch time: 42.15 s 
2025-02-24 11:17:20.998954:  
2025-02-24 11:17:21.004529: Epoch 122 
2025-02-24 11:17:21.007063: Current learning rate: 0.00547 
2025-02-24 11:18:03.154710: train_loss -0.7508 
2025-02-24 11:18:03.161372: val_loss -0.5498 
2025-02-24 11:18:03.164429: Pseudo dice [np.float32(0.785), np.float32(0.4829)] 
2025-02-24 11:18:03.167936: Epoch time: 42.16 s 
2025-02-24 11:18:03.682295:  
2025-02-24 11:18:03.688401: Epoch 123 
2025-02-24 11:18:03.690413: Current learning rate: 0.00544 
2025-02-24 11:18:45.847067: train_loss -0.7423 
2025-02-24 11:18:45.852581: val_loss -0.577 
2025-02-24 11:18:45.857093: Pseudo dice [np.float32(0.7922), np.float32(0.5129)] 
2025-02-24 11:18:45.860101: Epoch time: 42.17 s 
2025-02-24 11:18:46.372838:  
2025-02-24 11:18:46.378888: Epoch 124 
2025-02-24 11:18:46.381938: Current learning rate: 0.0054 
2025-02-24 11:19:28.516799: train_loss -0.7478 
2025-02-24 11:19:28.522316: val_loss -0.5484 
2025-02-24 11:19:28.525827: Pseudo dice [np.float32(0.7763), np.float32(0.4932)] 
2025-02-24 11:19:28.528330: Epoch time: 42.14 s 
2025-02-24 11:19:29.041218:  
2025-02-24 11:19:29.047794: Epoch 125 
2025-02-24 11:19:29.051336: Current learning rate: 0.00536 
2025-02-24 11:20:11.180511: train_loss -0.7462 
2025-02-24 11:20:11.186131: val_loss -0.5954 
2025-02-24 11:20:11.189662: Pseudo dice [np.float32(0.7945), np.float32(0.5129)] 
2025-02-24 11:20:11.192960: Epoch time: 42.14 s 
2025-02-24 11:20:11.855777:  
2025-02-24 11:20:11.861293: Epoch 126 
2025-02-24 11:20:11.864805: Current learning rate: 0.00532 
2025-02-24 11:20:53.972516: train_loss -0.7258 
2025-02-24 11:20:53.978308: val_loss -0.5207 
2025-02-24 11:20:53.981815: Pseudo dice [np.float32(0.7793), np.float32(0.4688)] 
2025-02-24 11:20:53.985325: Epoch time: 42.12 s 
2025-02-24 11:20:54.495497:  
2025-02-24 11:20:54.501629: Epoch 127 
2025-02-24 11:20:54.504665: Current learning rate: 0.00528 
2025-02-24 11:21:39.964031: train_loss -0.7426 
2025-02-24 11:21:39.970738: val_loss -0.5553 
2025-02-24 11:21:39.973797: Pseudo dice [np.float32(0.7271), np.float32(0.5421)] 
2025-02-24 11:21:39.977356: Epoch time: 45.47 s 
2025-02-24 11:21:40.497272:  
2025-02-24 11:21:40.502795: Epoch 128 
2025-02-24 11:21:40.506314: Current learning rate: 0.00524 
2025-02-24 11:22:22.623275: train_loss -0.7504 
2025-02-24 11:22:22.629291: val_loss -0.5484 
2025-02-24 11:22:22.632799: Pseudo dice [np.float32(0.7818), np.float32(0.456)] 
2025-02-24 11:22:22.635807: Epoch time: 42.13 s 
2025-02-24 11:22:23.146959:  
2025-02-24 11:22:23.152473: Epoch 129 
2025-02-24 11:22:23.155981: Current learning rate: 0.0052 
2025-02-24 11:23:05.261969: train_loss -0.7443 
2025-02-24 11:23:05.268040: val_loss -0.5954 
2025-02-24 11:23:05.271585: Pseudo dice [np.float32(0.794), np.float32(0.514)] 
2025-02-24 11:23:05.274629: Epoch time: 42.12 s 
2025-02-24 11:23:05.791847:  
2025-02-24 11:23:05.797912: Epoch 130 
2025-02-24 11:23:05.800535: Current learning rate: 0.00517 
2025-02-24 11:23:47.913599: train_loss -0.7555 
2025-02-24 11:23:47.919114: val_loss -0.584 
2025-02-24 11:23:47.922630: Pseudo dice [np.float32(0.7669), np.float32(0.5671)] 
2025-02-24 11:23:47.926132: Epoch time: 42.12 s 
2025-02-24 11:23:48.438212:  
2025-02-24 11:23:48.443787: Epoch 131 
2025-02-24 11:23:48.447936: Current learning rate: 0.00513 
2025-02-24 11:24:30.572038: train_loss -0.7477 
2025-02-24 11:24:30.578553: val_loss -0.5614 
2025-02-24 11:24:30.582063: Pseudo dice [np.float32(0.804), np.float32(0.4414)] 
2025-02-24 11:24:30.586072: Epoch time: 42.13 s 
2025-02-24 11:24:31.100336:  
2025-02-24 11:24:31.105361: Epoch 132 
2025-02-24 11:24:31.109344: Current learning rate: 0.00509 
2025-02-24 11:25:13.221087: train_loss -0.7648 
2025-02-24 11:25:13.227116: val_loss -0.5578 
2025-02-24 11:25:13.230629: Pseudo dice [np.float32(0.7936), np.float32(0.5312)] 
2025-02-24 11:25:13.233994: Epoch time: 42.12 s 
2025-02-24 11:25:13.747732:  
2025-02-24 11:25:13.753882: Epoch 133 
2025-02-24 11:25:13.756943: Current learning rate: 0.00505 
2025-02-24 11:25:55.917148: train_loss -0.7617 
2025-02-24 11:25:55.923163: val_loss -0.548 
2025-02-24 11:25:55.928180: Pseudo dice [np.float32(0.7703), np.float32(0.4232)] 
2025-02-24 11:25:55.933697: Epoch time: 42.17 s 
2025-02-24 11:25:56.451115:  
2025-02-24 11:25:56.456639: Epoch 134 
2025-02-24 11:25:56.459934: Current learning rate: 0.00501 
2025-02-24 11:26:38.622638: train_loss -0.7642 
2025-02-24 11:26:38.629199: val_loss -0.5515 
2025-02-24 11:26:38.634284: Pseudo dice [np.float32(0.7419), np.float32(0.497)] 
2025-02-24 11:26:38.637864: Epoch time: 42.17 s 
2025-02-24 11:26:39.330957:  
2025-02-24 11:26:39.336509: Epoch 135 
2025-02-24 11:26:39.340619: Current learning rate: 0.00497 
2025-02-24 11:27:21.490434: train_loss -0.7588 
2025-02-24 11:27:21.497021: val_loss -0.6028 
2025-02-24 11:27:21.501663: Pseudo dice [np.float32(0.8062), np.float32(0.5168)] 
2025-02-24 11:27:21.505721: Epoch time: 42.16 s 
2025-02-24 11:27:22.032415:  
2025-02-24 11:27:22.037941: Epoch 136 
2025-02-24 11:27:22.041453: Current learning rate: 0.00493 
2025-02-24 11:28:04.203750: train_loss -0.7633 
2025-02-24 11:28:04.209766: val_loss -0.614 
2025-02-24 11:28:04.213787: Pseudo dice [np.float32(0.8058), np.float32(0.5936)] 
2025-02-24 11:28:04.217298: Epoch time: 42.17 s 
2025-02-24 11:28:04.742040:  
2025-02-24 11:28:04.748102: Epoch 137 
2025-02-24 11:28:04.751173: Current learning rate: 0.00489 
2025-02-24 11:28:46.879150: train_loss -0.7604 
2025-02-24 11:28:46.884202: val_loss -0.5747 
2025-02-24 11:28:46.887835: Pseudo dice [np.float32(0.7854), np.float32(0.4538)] 
2025-02-24 11:28:46.891346: Epoch time: 42.14 s 
2025-02-24 11:28:47.413204:  
2025-02-24 11:28:47.418216: Epoch 138 
2025-02-24 11:28:47.421724: Current learning rate: 0.00485 
2025-02-24 11:29:29.549053: train_loss -0.756 
2025-02-24 11:29:29.555129: val_loss -0.5479 
2025-02-24 11:29:29.558158: Pseudo dice [np.float32(0.7668), np.float32(0.4805)] 
2025-02-24 11:29:29.561736: Epoch time: 42.14 s 
2025-02-24 11:29:30.087928:  
2025-02-24 11:29:30.094519: Epoch 139 
2025-02-24 11:29:30.097046: Current learning rate: 0.00482 
2025-02-24 11:30:12.240150: train_loss -0.7571 
2025-02-24 11:30:12.245873: val_loss -0.5702 
2025-02-24 11:30:12.248408: Pseudo dice [np.float32(0.7885), np.float32(0.5055)] 
2025-02-24 11:30:12.251924: Epoch time: 42.15 s 
2025-02-24 11:30:12.785125:  
2025-02-24 11:30:12.791230: Epoch 140 
2025-02-24 11:30:12.795241: Current learning rate: 0.00478 
2025-02-24 11:30:54.925701: train_loss -0.7695 
2025-02-24 11:30:54.931341: val_loss -0.5818 
2025-02-24 11:30:54.935880: Pseudo dice [np.float32(0.7844), np.float32(0.5468)] 
2025-02-24 11:30:54.938920: Epoch time: 42.14 s 
2025-02-24 11:30:55.467497:  
2025-02-24 11:30:55.473042: Epoch 141 
2025-02-24 11:30:55.476555: Current learning rate: 0.00474 
2025-02-24 11:31:37.641514: train_loss -0.7487 
2025-02-24 11:31:37.648193: val_loss -0.5542 
2025-02-24 11:31:37.651738: Pseudo dice [np.float32(0.7623), np.float32(0.4857)] 
2025-02-24 11:31:37.654774: Epoch time: 42.18 s 
2025-02-24 11:31:38.180520:  
2025-02-24 11:31:38.188696: Epoch 142 
2025-02-24 11:31:38.194261: Current learning rate: 0.0047 
2025-02-24 11:32:20.354589: train_loss -0.7528 
2025-02-24 11:32:20.360111: val_loss -0.552 
2025-02-24 11:32:20.363619: Pseudo dice [np.float32(0.7866), np.float32(0.4918)] 
2025-02-24 11:32:20.367635: Epoch time: 42.17 s 
2025-02-24 11:32:21.061895:  
2025-02-24 11:32:21.067463: Epoch 143 
2025-02-24 11:32:21.071035: Current learning rate: 0.00466 
2025-02-24 11:33:03.204956: train_loss -0.7569 
2025-02-24 11:33:03.210607: val_loss -0.5683 
2025-02-24 11:33:03.214179: Pseudo dice [np.float32(0.7736), np.float32(0.5835)] 
2025-02-24 11:33:03.217219: Epoch time: 42.14 s 
2025-02-24 11:33:03.220792: Yayy! New best EMA pseudo Dice: 0.6438999772071838 
2025-02-24 11:33:03.883356:  
2025-02-24 11:33:03.888422: Epoch 144 
2025-02-24 11:33:03.892005: Current learning rate: 0.00462 
2025-02-24 11:33:46.055632: train_loss -0.7655 
2025-02-24 11:33:46.061715: val_loss -0.5187 
2025-02-24 11:33:46.065274: Pseudo dice [np.float32(0.7797), np.float32(0.502)] 
2025-02-24 11:33:46.068838: Epoch time: 42.17 s 
2025-02-24 11:33:46.595119:  
2025-02-24 11:33:46.600713: Epoch 145 
2025-02-24 11:33:46.603761: Current learning rate: 0.00458 
2025-02-24 11:34:28.747539: train_loss -0.7529 
2025-02-24 11:34:28.752551: val_loss -0.6025 
2025-02-24 11:34:28.756560: Pseudo dice [np.float32(0.7969), np.float32(0.5122)] 
2025-02-24 11:34:28.759068: Epoch time: 42.15 s 
2025-02-24 11:34:28.762583: Yayy! New best EMA pseudo Dice: 0.6446999907493591 
2025-02-24 11:34:29.447598:  
2025-02-24 11:34:29.454208: Epoch 146 
2025-02-24 11:34:29.457755: Current learning rate: 0.00454 
2025-02-24 11:35:11.578019: train_loss -0.7629 
2025-02-24 11:35:11.583054: val_loss -0.5743 
2025-02-24 11:35:11.586664: Pseudo dice [np.float32(0.7962), np.float32(0.5028)] 
2025-02-24 11:35:11.590324: Epoch time: 42.13 s 
2025-02-24 11:35:11.594384: Yayy! New best EMA pseudo Dice: 0.6452000141143799 
2025-02-24 11:35:12.272882:  
2025-02-24 11:35:12.278396: Epoch 147 
2025-02-24 11:35:12.281907: Current learning rate: 0.0045 
2025-02-24 11:35:54.437084: train_loss -0.7741 
2025-02-24 11:35:54.443597: val_loss -0.5787 
2025-02-24 11:35:54.447135: Pseudo dice [np.float32(0.7675), np.float32(0.4783)] 
2025-02-24 11:35:54.450722: Epoch time: 42.17 s 
2025-02-24 11:35:54.979461:  
2025-02-24 11:35:54.985032: Epoch 148 
2025-02-24 11:35:54.988074: Current learning rate: 0.00446 
2025-02-24 11:36:37.154836: train_loss -0.7616 
2025-02-24 11:36:37.160925: val_loss -0.595 
2025-02-24 11:36:37.164465: Pseudo dice [np.float32(0.7965), np.float32(0.5807)] 
2025-02-24 11:36:37.168163: Epoch time: 42.18 s 
2025-02-24 11:36:37.172419: Yayy! New best EMA pseudo Dice: 0.6474999785423279 
2025-02-24 11:36:37.854174:  
2025-02-24 11:36:37.860203: Epoch 149 
2025-02-24 11:36:37.863714: Current learning rate: 0.00442 
2025-02-24 11:37:20.016627: train_loss -0.7623 
2025-02-24 11:37:20.022640: val_loss -0.5837 
2025-02-24 11:37:20.026411: Pseudo dice [np.float32(0.8035), np.float32(0.5239)] 
2025-02-24 11:37:20.029924: Epoch time: 42.16 s 
2025-02-24 11:37:20.173207: Yayy! New best EMA pseudo Dice: 0.6491000056266785 
2025-02-24 11:37:20.857301:  
2025-02-24 11:37:20.862900: Epoch 150 
2025-02-24 11:37:20.865959: Current learning rate: 0.00438 
2025-02-24 11:38:03.019761: train_loss -0.7447 
2025-02-24 11:38:03.025276: val_loss -0.5832 
2025-02-24 11:38:03.028787: Pseudo dice [np.float32(0.7941), np.float32(0.5611)] 
2025-02-24 11:38:03.032292: Epoch time: 42.16 s 
2025-02-24 11:38:03.035305: Yayy! New best EMA pseudo Dice: 0.6520000100135803 
2025-02-24 11:38:03.872377:  
2025-02-24 11:38:03.877394: Epoch 151 
2025-02-24 11:38:03.880905: Current learning rate: 0.00434 
2025-02-24 11:38:46.014992: train_loss -0.7697 
2025-02-24 11:38:46.021512: val_loss -0.5571 
2025-02-24 11:38:46.024025: Pseudo dice [np.float32(0.7799), np.float32(0.5238)] 
2025-02-24 11:38:46.028036: Epoch time: 42.14 s 
2025-02-24 11:38:46.552027:  
2025-02-24 11:38:46.558565: Epoch 152 
2025-02-24 11:38:46.561071: Current learning rate: 0.0043 
2025-02-24 11:39:28.684244: train_loss -0.7774 
2025-02-24 11:39:28.690850: val_loss -0.5352 
2025-02-24 11:39:28.693905: Pseudo dice [np.float32(0.7961), np.float32(0.4496)] 
2025-02-24 11:39:28.697452: Epoch time: 42.13 s 
2025-02-24 11:39:29.223633:  
2025-02-24 11:39:29.229162: Epoch 153 
2025-02-24 11:39:29.232712: Current learning rate: 0.00427 
2025-02-24 11:40:11.349657: train_loss -0.7698 
2025-02-24 11:40:11.356212: val_loss -0.6063 
2025-02-24 11:40:11.359409: Pseudo dice [np.float32(0.7864), np.float32(0.6128)] 
2025-02-24 11:40:11.362753: Epoch time: 42.13 s 
2025-02-24 11:40:11.366381: Yayy! New best EMA pseudo Dice: 0.6541000008583069 
2025-02-24 11:40:12.062613:  
2025-02-24 11:40:12.068128: Epoch 154 
2025-02-24 11:40:12.071639: Current learning rate: 0.00423 
2025-02-24 11:40:54.199939: train_loss -0.7883 
2025-02-24 11:40:54.206521: val_loss -0.5954 
2025-02-24 11:40:54.209553: Pseudo dice [np.float32(0.7871), np.float32(0.5859)] 
2025-02-24 11:40:54.214073: Epoch time: 42.14 s 
2025-02-24 11:40:54.217799: Yayy! New best EMA pseudo Dice: 0.6572999954223633 
2025-02-24 11:40:54.893586:  
2025-02-24 11:40:54.899616: Epoch 155 
2025-02-24 11:40:54.903130: Current learning rate: 0.00419 
2025-02-24 11:41:37.057432: train_loss -0.7771 
2025-02-24 11:41:37.062752: val_loss -0.6067 
2025-02-24 11:41:37.066759: Pseudo dice [np.float32(0.7792), np.float32(0.5415)] 
2025-02-24 11:41:37.070269: Epoch time: 42.16 s 
2025-02-24 11:41:37.073776: Yayy! New best EMA pseudo Dice: 0.6575999855995178 
2025-02-24 11:41:37.759511:  
2025-02-24 11:41:37.765035: Epoch 156 
2025-02-24 11:41:37.768168: Current learning rate: 0.00415 
2025-02-24 11:42:19.861093: train_loss -0.7732 
2025-02-24 11:42:19.867608: val_loss -0.5252 
2025-02-24 11:42:19.871117: Pseudo dice [np.float32(0.7916), np.float32(0.4935)] 
2025-02-24 11:42:19.875169: Epoch time: 42.1 s 
2025-02-24 11:42:20.402935:  
2025-02-24 11:42:20.408450: Epoch 157 
2025-02-24 11:42:20.411961: Current learning rate: 0.00411 
2025-02-24 11:43:02.497570: train_loss -0.7801 
2025-02-24 11:43:02.504161: val_loss -0.6027 
2025-02-24 11:43:02.508173: Pseudo dice [np.float32(0.8023), np.float32(0.5474)] 
2025-02-24 11:43:02.511688: Epoch time: 42.1 s 
2025-02-24 11:43:02.518212: Yayy! New best EMA pseudo Dice: 0.6579999923706055 
2025-02-24 11:43:03.359758:  
2025-02-24 11:43:03.365851: Epoch 158 
2025-02-24 11:43:03.369435: Current learning rate: 0.00407 
2025-02-24 11:43:45.472693: train_loss -0.7792 
2025-02-24 11:43:45.479227: val_loss -0.5795 
2025-02-24 11:43:45.482743: Pseudo dice [np.float32(0.7985), np.float32(0.4782)] 
2025-02-24 11:43:45.485770: Epoch time: 42.11 s 
2025-02-24 11:43:46.018975:  
2025-02-24 11:43:46.025565: Epoch 159 
2025-02-24 11:43:46.028600: Current learning rate: 0.00403 
2025-02-24 11:44:28.128222: train_loss -0.7668 
2025-02-24 11:44:28.133735: val_loss -0.5854 
2025-02-24 11:44:28.137246: Pseudo dice [np.float32(0.7789), np.float32(0.5519)] 
2025-02-24 11:44:28.140753: Epoch time: 42.11 s 
2025-02-24 11:44:28.668878:  
2025-02-24 11:44:28.674967: Epoch 160 
2025-02-24 11:44:28.678099: Current learning rate: 0.00399 
2025-02-24 11:45:10.815183: train_loss -0.7738 
2025-02-24 11:45:10.821283: val_loss -0.5744 
2025-02-24 11:45:10.824831: Pseudo dice [np.float32(0.7952), np.float32(0.5359)] 
2025-02-24 11:45:10.827922: Epoch time: 42.15 s 
2025-02-24 11:45:11.356566:  
2025-02-24 11:45:11.362138: Epoch 161 
2025-02-24 11:45:11.365680: Current learning rate: 0.00395 
2025-02-24 11:45:53.493464: train_loss -0.784 
2025-02-24 11:45:53.499474: val_loss -0.5906 
2025-02-24 11:45:53.502485: Pseudo dice [np.float32(0.8028), np.float32(0.6371)] 
2025-02-24 11:45:53.505995: Epoch time: 42.14 s 
2025-02-24 11:45:53.509508: Yayy! New best EMA pseudo Dice: 0.6639999747276306 
2025-02-24 11:45:54.209109:  
2025-02-24 11:45:54.214653: Epoch 162 
2025-02-24 11:45:54.218272: Current learning rate: 0.00391 
2025-02-24 11:46:36.353157: train_loss -0.7878 
2025-02-24 11:46:36.359256: val_loss -0.5639 
2025-02-24 11:46:36.363022: Pseudo dice [np.float32(0.808), np.float32(0.4714)] 
2025-02-24 11:46:36.366056: Epoch time: 42.14 s 
2025-02-24 11:46:36.906030:  
2025-02-24 11:46:36.912058: Epoch 163 
2025-02-24 11:46:36.915566: Current learning rate: 0.00387 
2025-02-24 11:47:19.039366: train_loss -0.7552 
2025-02-24 11:47:19.044956: val_loss -0.5206 
2025-02-24 11:47:19.048079: Pseudo dice [np.float32(0.7795), np.float32(0.5608)] 
2025-02-24 11:47:19.052089: Epoch time: 42.13 s 
2025-02-24 11:47:19.580398:  
2025-02-24 11:47:19.587070: Epoch 164 
2025-02-24 11:47:19.590117: Current learning rate: 0.00383 
2025-02-24 11:48:01.709388: train_loss -0.783 
2025-02-24 11:48:01.715016: val_loss -0.6116 
2025-02-24 11:48:01.719064: Pseudo dice [np.float32(0.7804), np.float32(0.6291)] 
2025-02-24 11:48:01.722624: Epoch time: 42.13 s 
2025-02-24 11:48:01.725710: Yayy! New best EMA pseudo Dice: 0.666700005531311 
2025-02-24 11:48:02.391968:  
2025-02-24 11:48:02.397480: Epoch 165 
2025-02-24 11:48:02.400990: Current learning rate: 0.00379 
2025-02-24 11:48:44.544137: train_loss -0.7937 
2025-02-24 11:48:44.551664: val_loss -0.579 
2025-02-24 11:48:44.555677: Pseudo dice [np.float32(0.7736), np.float32(0.5402)] 
2025-02-24 11:48:44.560694: Epoch time: 42.15 s 
2025-02-24 11:48:45.235413:  
2025-02-24 11:48:45.240985: Epoch 166 
2025-02-24 11:48:45.245024: Current learning rate: 0.00375 
2025-02-24 11:49:27.361819: train_loss -0.7844 
2025-02-24 11:49:27.368893: val_loss -0.5427 
2025-02-24 11:49:27.372401: Pseudo dice [np.float32(0.7951), np.float32(0.3882)] 
2025-02-24 11:49:27.375909: Epoch time: 42.13 s 
2025-02-24 11:49:27.891368:  
2025-02-24 11:49:27.896882: Epoch 167 
2025-02-24 11:49:27.900393: Current learning rate: 0.00371 
2025-02-24 11:50:15.965433: train_loss -0.7681 
2025-02-24 11:50:15.971208: val_loss -0.6074 
2025-02-24 11:50:15.974768: Pseudo dice [np.float32(0.7888), np.float32(0.5387)] 
2025-02-24 11:50:15.978316: Epoch time: 48.08 s 
2025-02-24 11:50:16.504350:  
2025-02-24 11:50:16.510463: Epoch 168 
2025-02-24 11:50:16.515501: Current learning rate: 0.00367 
2025-02-24 11:50:59.953396: train_loss -0.7789 
2025-02-24 11:50:59.960571: val_loss -0.5749 
2025-02-24 11:50:59.964124: Pseudo dice [np.float32(0.8099), np.float32(0.5903)] 
2025-02-24 11:50:59.967702: Epoch time: 43.45 s 
2025-02-24 11:51:00.497732:  
2025-02-24 11:51:00.503250: Epoch 169 
2025-02-24 11:51:00.506763: Current learning rate: 0.00363 
2025-02-24 11:51:43.949048: train_loss -0.7894 
2025-02-24 11:51:43.954140: val_loss -0.5707 
2025-02-24 11:51:43.957658: Pseudo dice [np.float32(0.7803), np.float32(0.475)] 
2025-02-24 11:51:43.961666: Epoch time: 43.45 s 
2025-02-24 11:51:44.507792:  
2025-02-24 11:51:44.512832: Epoch 170 
2025-02-24 11:51:44.516475: Current learning rate: 0.00359 
2025-02-24 11:52:27.942290: train_loss -0.7696 
2025-02-24 11:52:27.947214: val_loss -0.5699 
2025-02-24 11:52:27.951724: Pseudo dice [np.float32(0.7905), np.float32(0.421)] 
2025-02-24 11:52:27.954737: Epoch time: 43.44 s 
2025-02-24 11:52:28.476977:  
2025-02-24 11:52:28.482538: Epoch 171 
2025-02-24 11:52:28.487120: Current learning rate: 0.00355 
2025-02-24 11:53:11.934047: train_loss -0.7842 
2025-02-24 11:53:11.940219: val_loss -0.5565 
2025-02-24 11:53:11.943290: Pseudo dice [np.float32(0.796), np.float32(0.5206)] 
2025-02-24 11:53:11.946820: Epoch time: 43.46 s 
2025-02-24 11:53:12.477439:  
2025-02-24 11:53:12.482452: Epoch 172 
2025-02-24 11:53:12.485964: Current learning rate: 0.00351 
2025-02-24 11:53:55.939128: train_loss -0.775 
2025-02-24 11:53:55.945736: val_loss -0.5571 
2025-02-24 11:53:55.949270: Pseudo dice [np.float32(0.7817), np.float32(0.3919)] 
2025-02-24 11:53:55.952893: Epoch time: 43.46 s 
2025-02-24 11:53:56.480188:  
2025-02-24 11:53:56.485719: Epoch 173 
2025-02-24 11:53:56.489264: Current learning rate: 0.00346 
2025-02-24 11:54:39.984656: train_loss -0.7964 
2025-02-24 11:54:39.990271: val_loss -0.6126 
2025-02-24 11:54:39.993793: Pseudo dice [np.float32(0.8057), np.float32(0.5553)] 
2025-02-24 11:54:39.997355: Epoch time: 43.51 s 
2025-02-24 11:54:40.695664:  
2025-02-24 11:54:40.701689: Epoch 174 
2025-02-24 11:54:40.705194: Current learning rate: 0.00342 
2025-02-24 11:55:24.090244: train_loss -0.7784 
2025-02-24 11:55:24.096329: val_loss -0.5516 
2025-02-24 11:55:24.098925: Pseudo dice [np.float32(0.7889), np.float32(0.4684)] 
2025-02-24 11:55:24.102473: Epoch time: 43.4 s 
2025-02-24 11:55:24.631184:  
2025-02-24 11:55:24.636700: Epoch 175 
2025-02-24 11:55:24.640208: Current learning rate: 0.00338 
2025-02-24 11:56:08.039294: train_loss -0.7936 
2025-02-24 11:56:08.045819: val_loss -0.5237 
2025-02-24 11:56:08.049330: Pseudo dice [np.float32(0.79), np.float32(0.3689)] 
2025-02-24 11:56:08.052834: Epoch time: 43.41 s 
2025-02-24 11:56:08.586243:  
2025-02-24 11:56:08.591818: Epoch 176 
2025-02-24 11:56:08.595449: Current learning rate: 0.00334 
2025-02-24 11:56:52.029713: train_loss -0.7703 
2025-02-24 11:56:52.035781: val_loss -0.5441 
2025-02-24 11:56:52.038423: Pseudo dice [np.float32(0.7977), np.float32(0.5914)] 
2025-02-24 11:56:52.042472: Epoch time: 43.44 s 
2025-02-24 11:56:52.572948:  
2025-02-24 11:56:52.578966: Epoch 177 
2025-02-24 11:56:52.582973: Current learning rate: 0.0033 
2025-02-24 11:57:36.039986: train_loss -0.7923 
2025-02-24 11:57:36.047082: val_loss -0.5762 
2025-02-24 11:57:36.050590: Pseudo dice [np.float32(0.7972), np.float32(0.4331)] 
2025-02-24 11:57:36.053098: Epoch time: 43.47 s 
2025-02-24 11:57:36.589543:  
2025-02-24 11:57:36.594577: Epoch 178 
2025-02-24 11:57:36.598085: Current learning rate: 0.00326 
2025-02-24 11:58:20.052452: train_loss -0.7884 
2025-02-24 11:58:20.058463: val_loss -0.5622 
2025-02-24 11:58:20.062475: Pseudo dice [np.float32(0.7983), np.float32(0.4824)] 
2025-02-24 11:58:20.064985: Epoch time: 43.46 s 
2025-02-24 11:58:20.599240:  
2025-02-24 11:58:20.605343: Epoch 179 
2025-02-24 11:58:20.609129: Current learning rate: 0.00322 
2025-02-24 11:59:04.082644: train_loss -0.7979 
2025-02-24 11:59:04.088219: val_loss -0.567 
2025-02-24 11:59:04.091844: Pseudo dice [np.float32(0.7911), np.float32(0.3814)] 
2025-02-24 11:59:04.095422: Epoch time: 43.48 s 
2025-02-24 11:59:04.625491:  
2025-02-24 11:59:04.631032: Epoch 180 
2025-02-24 11:59:04.634595: Current learning rate: 0.00318 
2025-02-24 11:59:47.510144: train_loss -0.8072 
2025-02-24 11:59:47.516167: val_loss -0.5341 
2025-02-24 11:59:47.519177: Pseudo dice [np.float32(0.7786), np.float32(0.3584)] 
2025-02-24 11:59:47.522688: Epoch time: 42.89 s 
2025-02-24 11:59:48.054209:  
2025-02-24 11:59:48.060331: Epoch 181 
2025-02-24 11:59:48.064538: Current learning rate: 0.00314 
2025-02-24 12:00:30.191951: train_loss -0.8085 
2025-02-24 12:00:30.197555: val_loss -0.6024 
2025-02-24 12:00:30.201106: Pseudo dice [np.float32(0.7929), np.float32(0.6068)] 
2025-02-24 12:00:30.204709: Epoch time: 42.14 s 
2025-02-24 12:00:30.913720:  
2025-02-24 12:00:30.918741: Epoch 182 
2025-02-24 12:00:30.922259: Current learning rate: 0.0031 
2025-02-24 12:01:13.465187: train_loss -0.8188 
2025-02-24 12:01:13.471700: val_loss -0.5304 
2025-02-24 12:01:13.476208: Pseudo dice [np.float32(0.7937), np.float32(0.4701)] 
2025-02-24 12:01:13.480220: Epoch time: 42.55 s 
2025-02-24 12:01:14.015435:  
2025-02-24 12:01:14.022024: Epoch 183 
2025-02-24 12:01:14.024571: Current learning rate: 0.00306 
2025-02-24 12:01:56.174249: train_loss -0.8054 
2025-02-24 12:01:56.179782: val_loss -0.5338 
2025-02-24 12:01:56.183291: Pseudo dice [np.float32(0.7948), np.float32(0.3415)] 
2025-02-24 12:01:56.186798: Epoch time: 42.16 s 
2025-02-24 12:01:56.714134:  
2025-02-24 12:01:56.719789: Epoch 184 
2025-02-24 12:01:56.723376: Current learning rate: 0.00302 
2025-02-24 12:02:38.892891: train_loss -0.8006 
2025-02-24 12:02:38.898909: val_loss -0.6211 
2025-02-24 12:02:38.902417: Pseudo dice [np.float32(0.7952), np.float32(0.6006)] 
2025-02-24 12:02:38.905426: Epoch time: 42.18 s 
2025-02-24 12:02:39.449076:  
2025-02-24 12:02:39.454768: Epoch 185 
2025-02-24 12:02:39.458341: Current learning rate: 0.00297 
2025-02-24 12:03:21.591018: train_loss -0.789 
2025-02-24 12:03:21.596104: val_loss -0.562 
2025-02-24 12:03:21.598699: Pseudo dice [np.float32(0.7914), np.float32(0.6023)] 
2025-02-24 12:03:21.602741: Epoch time: 42.14 s 
2025-02-24 12:03:22.126775:  
2025-02-24 12:03:22.132838: Epoch 186 
2025-02-24 12:03:22.135892: Current learning rate: 0.00293 
2025-02-24 12:04:04.286131: train_loss -0.7913 
2025-02-24 12:04:04.291656: val_loss -0.5539 
2025-02-24 12:04:04.295167: Pseudo dice [np.float32(0.7942), np.float32(0.4379)] 
2025-02-24 12:04:04.300182: Epoch time: 42.16 s 
2025-02-24 12:04:04.827065:  
2025-02-24 12:04:04.832075: Epoch 187 
2025-02-24 12:04:04.835101: Current learning rate: 0.00289 
2025-02-24 12:04:46.985027: train_loss -0.8032 
2025-02-24 12:04:46.990544: val_loss -0.5644 
2025-02-24 12:04:46.995054: Pseudo dice [np.float32(0.7894), np.float32(0.5258)] 
2025-02-24 12:04:46.998066: Epoch time: 42.16 s 
2025-02-24 12:04:47.525820:  
2025-02-24 12:04:47.531839: Epoch 188 
2025-02-24 12:04:47.534343: Current learning rate: 0.00285 
2025-02-24 12:05:29.676988: train_loss -0.8093 
2025-02-24 12:05:29.684062: val_loss -0.5685 
2025-02-24 12:05:29.688128: Pseudo dice [np.float32(0.7956), np.float32(0.4117)] 
2025-02-24 12:05:29.691154: Epoch time: 42.15 s 
2025-02-24 12:05:30.217376:  
2025-02-24 12:05:30.223520: Epoch 189 
2025-02-24 12:05:30.227082: Current learning rate: 0.00281 
2025-02-24 12:06:12.384481: train_loss -0.8167 
2025-02-24 12:06:12.390542: val_loss -0.5515 
2025-02-24 12:06:12.393557: Pseudo dice [np.float32(0.788), np.float32(0.4926)] 
2025-02-24 12:06:12.397175: Epoch time: 42.17 s 
2025-02-24 12:06:13.089655:  
2025-02-24 12:06:13.096362: Epoch 190 
2025-02-24 12:06:13.099437: Current learning rate: 0.00277 
2025-02-24 12:06:55.234832: train_loss -0.7969 
2025-02-24 12:06:55.240850: val_loss -0.5803 
2025-02-24 12:06:55.244896: Pseudo dice [np.float32(0.7814), np.float32(0.5617)] 
2025-02-24 12:06:55.247913: Epoch time: 42.15 s 
2025-02-24 12:06:55.774231:  
2025-02-24 12:06:55.780276: Epoch 191 
2025-02-24 12:06:55.784123: Current learning rate: 0.00273 
2025-02-24 12:07:37.901962: train_loss -0.8123 
2025-02-24 12:07:37.906983: val_loss -0.5749 
2025-02-24 12:07:37.911637: Pseudo dice [np.float32(0.8038), np.float32(0.5511)] 
2025-02-24 12:07:37.915404: Epoch time: 42.13 s 
2025-02-24 12:07:38.448821:  
2025-02-24 12:07:38.454338: Epoch 192 
2025-02-24 12:07:38.457848: Current learning rate: 0.00268 
2025-02-24 12:08:20.554965: train_loss -0.8062 
2025-02-24 12:08:20.561019: val_loss -0.5648 
2025-02-24 12:08:20.566029: Pseudo dice [np.float32(0.7669), np.float32(0.5534)] 
2025-02-24 12:08:20.570050: Epoch time: 42.11 s 
2025-02-24 12:08:21.100510:  
2025-02-24 12:08:21.106072: Epoch 193 
2025-02-24 12:08:21.109102: Current learning rate: 0.00264 
2025-02-24 12:09:03.221283: train_loss -0.8123 
2025-02-24 12:09:03.227376: val_loss -0.5554 
2025-02-24 12:09:03.231054: Pseudo dice [np.float32(0.7876), np.float32(0.3963)] 
2025-02-24 12:09:03.234583: Epoch time: 42.12 s 
2025-02-24 12:09:03.767987:  
2025-02-24 12:09:03.773502: Epoch 194 
2025-02-24 12:09:03.777113: Current learning rate: 0.0026 
2025-02-24 12:09:45.898564: train_loss -0.8159 
2025-02-24 12:09:45.904091: val_loss -0.5608 
2025-02-24 12:09:45.907602: Pseudo dice [np.float32(0.7899), np.float32(0.4196)] 
2025-02-24 12:09:45.910108: Epoch time: 42.13 s 
2025-02-24 12:09:46.439167:  
2025-02-24 12:09:46.444772: Epoch 195 
2025-02-24 12:09:46.448309: Current learning rate: 0.00256 
2025-02-24 12:10:28.557056: train_loss -0.8177 
2025-02-24 12:10:28.562635: val_loss -0.5228 
2025-02-24 12:10:28.565185: Pseudo dice [np.float32(0.7809), np.float32(0.3553)] 
2025-02-24 12:10:28.568695: Epoch time: 42.12 s 
2025-02-24 12:10:29.111248:  
2025-02-24 12:10:29.116804: Epoch 196 
2025-02-24 12:10:29.119341: Current learning rate: 0.00252 
2025-02-24 12:11:11.241179: train_loss -0.8161 
2025-02-24 12:11:11.247777: val_loss -0.569 
2025-02-24 12:11:11.250791: Pseudo dice [np.float32(0.7985), np.float32(0.4504)] 
2025-02-24 12:11:11.254302: Epoch time: 42.13 s 
2025-02-24 12:11:11.792439:  
2025-02-24 12:11:11.798501: Epoch 197 
2025-02-24 12:11:11.802010: Current learning rate: 0.00248 
2025-02-24 12:11:53.886659: train_loss -0.8246 
2025-02-24 12:11:53.891672: val_loss -0.5411 
2025-02-24 12:11:53.895687: Pseudo dice [np.float32(0.7853), np.float32(0.541)] 
2025-02-24 12:11:53.899201: Epoch time: 42.1 s 
2025-02-24 12:11:54.603920:  
2025-02-24 12:11:54.609480: Epoch 198 
2025-02-24 12:11:54.612012: Current learning rate: 0.00243 
2025-02-24 12:12:36.742381: train_loss -0.8057 
2025-02-24 12:12:36.747496: val_loss -0.6079 
2025-02-24 12:12:36.751096: Pseudo dice [np.float32(0.8124), np.float32(0.5505)] 
2025-02-24 12:12:36.754118: Epoch time: 42.14 s 
2025-02-24 12:12:37.283330:  
2025-02-24 12:12:37.288878: Epoch 199 
2025-02-24 12:12:37.292939: Current learning rate: 0.00239 
2025-02-24 12:13:19.412170: train_loss -0.8093 
2025-02-24 12:13:19.417780: val_loss -0.598 
2025-02-24 12:13:19.421334: Pseudo dice [np.float32(0.7964), np.float32(0.5418)] 
2025-02-24 12:13:19.424387: Epoch time: 42.13 s 
2025-02-24 12:13:20.100606:  
2025-02-24 12:13:20.105626: Epoch 200 
2025-02-24 12:13:20.109137: Current learning rate: 0.00235 
2025-02-24 12:14:02.238323: train_loss -0.801 
2025-02-24 12:14:02.244856: val_loss -0.518 
2025-02-24 12:14:02.248403: Pseudo dice [np.float32(0.7979), np.float32(0.3922)] 
2025-02-24 12:14:02.250536: Epoch time: 42.14 s 
2025-02-24 12:14:02.792155:  
2025-02-24 12:14:02.797182: Epoch 201 
2025-02-24 12:14:02.801077: Current learning rate: 0.00231 
2025-02-24 12:14:44.926483: train_loss -0.815 
2025-02-24 12:14:44.932175: val_loss -0.5168 
2025-02-24 12:14:44.935768: Pseudo dice [np.float32(0.7837), np.float32(0.303)] 
2025-02-24 12:14:44.938311: Epoch time: 42.14 s 
2025-02-24 12:14:45.474759:  
2025-02-24 12:14:45.480335: Epoch 202 
2025-02-24 12:14:45.484398: Current learning rate: 0.00226 
2025-02-24 12:15:27.597343: train_loss -0.8287 
2025-02-24 12:15:27.603361: val_loss -0.6 
2025-02-24 12:15:27.607373: Pseudo dice [np.float32(0.8171), np.float32(0.5236)] 
2025-02-24 12:15:27.610883: Epoch time: 42.12 s 
2025-02-24 12:15:28.143569:  
2025-02-24 12:15:28.149095: Epoch 203 
2025-02-24 12:15:28.152654: Current learning rate: 0.00222 
2025-02-24 12:16:10.269854: train_loss -0.8292 
2025-02-24 12:16:10.276413: val_loss -0.5681 
2025-02-24 12:16:10.281508: Pseudo dice [np.float32(0.7943), np.float32(0.4672)] 
2025-02-24 12:16:10.285164: Epoch time: 42.13 s 
2025-02-24 12:16:10.820940:  
2025-02-24 12:16:10.826484: Epoch 204 
2025-02-24 12:16:10.830138: Current learning rate: 0.00218 
2025-02-24 12:16:52.938174: train_loss -0.8126 
2025-02-24 12:16:52.944270: val_loss -0.5521 
2025-02-24 12:16:52.948317: Pseudo dice [np.float32(0.7691), np.float32(0.4476)] 
2025-02-24 12:16:52.951327: Epoch time: 42.12 s 
2025-02-24 12:16:53.640858:  
2025-02-24 12:16:53.645885: Epoch 205 
2025-02-24 12:16:53.649447: Current learning rate: 0.00214 
2025-02-24 12:17:35.745862: train_loss -0.8166 
2025-02-24 12:17:35.751418: val_loss -0.6113 
2025-02-24 12:17:35.755016: Pseudo dice [np.float32(0.8038), np.float32(0.6112)] 
2025-02-24 12:17:35.758579: Epoch time: 42.11 s 
2025-02-24 12:17:36.275059:  
2025-02-24 12:17:36.281683: Epoch 206 
2025-02-24 12:17:36.284215: Current learning rate: 0.00209 
2025-02-24 12:18:18.349634: train_loss -0.813 
2025-02-24 12:18:18.356156: val_loss -0.5769 
2025-02-24 12:18:18.358661: Pseudo dice [np.float32(0.8034), np.float32(0.4643)] 
2025-02-24 12:18:18.362175: Epoch time: 42.07 s 
2025-02-24 12:18:18.872797:  
2025-02-24 12:18:18.878332: Epoch 207 
2025-02-24 12:18:18.881436: Current learning rate: 0.00205 
2025-02-24 12:19:00.978608: train_loss -0.8272 
2025-02-24 12:19:00.984727: val_loss -0.5616 
2025-02-24 12:19:00.987773: Pseudo dice [np.float32(0.7705), np.float32(0.5877)] 
2025-02-24 12:19:00.990312: Epoch time: 42.11 s 
2025-02-24 12:19:01.506254:  
2025-02-24 12:19:01.511769: Epoch 208 
2025-02-24 12:19:01.515278: Current learning rate: 0.00201 
2025-02-24 12:19:43.617676: train_loss -0.8219 
2025-02-24 12:19:43.623278: val_loss -0.5552 
2025-02-24 12:19:43.626790: Pseudo dice [np.float32(0.7861), np.float32(0.4446)] 
2025-02-24 12:19:43.630296: Epoch time: 42.11 s 
2025-02-24 12:19:44.135505:  
2025-02-24 12:19:44.141036: Epoch 209 
2025-02-24 12:19:44.144589: Current learning rate: 0.00196 
2025-02-24 12:20:26.267829: train_loss -0.8254 
2025-02-24 12:20:26.273928: val_loss -0.5431 
2025-02-24 12:20:26.276969: Pseudo dice [np.float32(0.7816), np.float32(0.4783)] 
2025-02-24 12:20:26.280539: Epoch time: 42.13 s 
2025-02-24 12:20:26.787205:  
2025-02-24 12:20:26.792227: Epoch 210 
2025-02-24 12:20:26.795142: Current learning rate: 0.00192 
2025-02-24 12:21:08.894210: train_loss -0.822 
2025-02-24 12:21:08.900229: val_loss -0.5098 
2025-02-24 12:21:08.904244: Pseudo dice [np.float32(0.7929), np.float32(0.3265)] 
2025-02-24 12:21:08.906751: Epoch time: 42.11 s 
2025-02-24 12:21:09.415759:  
2025-02-24 12:21:09.420808: Epoch 211 
2025-02-24 12:21:09.423878: Current learning rate: 0.00188 
2025-02-24 12:21:51.527326: train_loss -0.8217 
2025-02-24 12:21:51.533346: val_loss -0.5761 
2025-02-24 12:21:51.535852: Pseudo dice [np.float32(0.8181), np.float32(0.5672)] 
2025-02-24 12:21:51.539868: Epoch time: 42.11 s 
2025-02-24 12:21:52.048293:  
2025-02-24 12:21:52.053304: Epoch 212 
2025-02-24 12:21:52.056815: Current learning rate: 0.00184 
2025-02-24 12:22:34.149507: train_loss -0.8278 
2025-02-24 12:22:34.155064: val_loss -0.5772 
2025-02-24 12:22:34.158679: Pseudo dice [np.float32(0.7943), np.float32(0.4134)] 
2025-02-24 12:22:34.162277: Epoch time: 42.1 s 
2025-02-24 12:22:34.671035:  
2025-02-24 12:22:34.677106: Epoch 213 
2025-02-24 12:22:34.680167: Current learning rate: 0.00179 
2025-02-24 12:23:16.787439: train_loss -0.8356 
2025-02-24 12:23:16.793515: val_loss -0.5703 
2025-02-24 12:23:16.796554: Pseudo dice [np.float32(0.7997), np.float32(0.4766)] 
2025-02-24 12:23:16.800083: Epoch time: 42.12 s 
2025-02-24 12:23:17.465045:  
2025-02-24 12:23:17.470092: Epoch 214 
2025-02-24 12:23:17.473124: Current learning rate: 0.00175 
2025-02-24 12:23:59.561714: train_loss -0.8293 
2025-02-24 12:23:59.567783: val_loss -0.5944 
2025-02-24 12:23:59.572939: Pseudo dice [np.float32(0.8156), np.float32(0.5221)] 
2025-02-24 12:23:59.576591: Epoch time: 42.1 s 
2025-02-24 12:24:00.083710:  
2025-02-24 12:24:00.089339: Epoch 215 
2025-02-24 12:24:00.092417: Current learning rate: 0.0017 
2025-02-24 12:24:42.171806: train_loss -0.8216 
2025-02-24 12:24:42.177443: val_loss -0.584 
2025-02-24 12:24:42.180474: Pseudo dice [np.float32(0.8071), np.float32(0.5369)] 
2025-02-24 12:24:42.184053: Epoch time: 42.09 s 
2025-02-24 12:24:42.688954:  
2025-02-24 12:24:42.693984: Epoch 216 
2025-02-24 12:24:42.697659: Current learning rate: 0.00166 
2025-02-24 12:25:24.788528: train_loss -0.8137 
2025-02-24 12:25:24.793541: val_loss -0.5681 
2025-02-24 12:25:24.797053: Pseudo dice [np.float32(0.8014), np.float32(0.4087)] 
2025-02-24 12:25:24.800562: Epoch time: 42.1 s 
2025-02-24 12:25:25.310586:  
2025-02-24 12:25:25.317206: Epoch 217 
2025-02-24 12:25:25.320750: Current learning rate: 0.00162 
2025-02-24 12:26:07.480299: train_loss -0.8325 
2025-02-24 12:26:07.487409: val_loss -0.5832 
2025-02-24 12:26:07.490953: Pseudo dice [np.float32(0.8009), np.float32(0.5806)] 
2025-02-24 12:26:07.493499: Epoch time: 42.17 s 
2025-02-24 12:26:07.995291:  
2025-02-24 12:26:08.000322: Epoch 218 
2025-02-24 12:26:08.004511: Current learning rate: 0.00157 
2025-02-24 12:26:50.141964: train_loss -0.8425 
2025-02-24 12:26:50.147535: val_loss -0.5718 
2025-02-24 12:26:50.151162: Pseudo dice [np.float32(0.7856), np.float32(0.5222)] 
2025-02-24 12:26:50.153673: Epoch time: 42.15 s 
2025-02-24 12:26:50.654677:  
2025-02-24 12:26:50.659715: Epoch 219 
2025-02-24 12:26:50.663744: Current learning rate: 0.00153 
2025-02-24 12:27:32.814458: train_loss -0.8417 
2025-02-24 12:27:32.820472: val_loss -0.5724 
2025-02-24 12:27:32.824485: Pseudo dice [np.float32(0.8119), np.float32(0.5808)] 
2025-02-24 12:27:32.826992: Epoch time: 42.16 s 
2025-02-24 12:27:33.329379:  
2025-02-24 12:27:33.334391: Epoch 220 
2025-02-24 12:27:33.337903: Current learning rate: 0.00148 
2025-02-24 12:28:15.455158: train_loss -0.8329 
2025-02-24 12:28:15.460712: val_loss -0.5292 
2025-02-24 12:28:15.464224: Pseudo dice [np.float32(0.7813), np.float32(0.5573)] 
2025-02-24 12:28:15.468238: Epoch time: 42.13 s 
2025-02-24 12:28:15.969537:  
2025-02-24 12:28:15.975090: Epoch 221 
2025-02-24 12:28:15.979202: Current learning rate: 0.00144 
2025-02-24 12:28:58.136396: train_loss -0.8193 
2025-02-24 12:28:58.143484: val_loss -0.5695 
2025-02-24 12:28:58.146032: Pseudo dice [np.float32(0.7881), np.float32(0.5426)] 
2025-02-24 12:28:58.149545: Epoch time: 42.17 s 
2025-02-24 12:28:58.824372:  
2025-02-24 12:28:58.830470: Epoch 222 
2025-02-24 12:28:58.832513: Current learning rate: 0.00139 
2025-02-24 12:29:40.956479: train_loss -0.8368 
2025-02-24 12:29:40.962105: val_loss -0.5683 
2025-02-24 12:29:40.965644: Pseudo dice [np.float32(0.7954), np.float32(0.4265)] 
2025-02-24 12:29:40.968683: Epoch time: 42.13 s 
2025-02-24 12:29:41.471959:  
2025-02-24 12:29:41.478038: Epoch 223 
2025-02-24 12:29:41.481590: Current learning rate: 0.00135 
2025-02-24 12:30:23.606933: train_loss -0.8357 
2025-02-24 12:30:23.613010: val_loss -0.5798 
2025-02-24 12:30:23.616578: Pseudo dice [np.float32(0.792), np.float32(0.4663)] 
2025-02-24 12:30:23.619599: Epoch time: 42.14 s 
2025-02-24 12:30:24.121468:  
2025-02-24 12:30:24.127516: Epoch 224 
2025-02-24 12:30:24.130027: Current learning rate: 0.0013 
2025-02-24 12:31:06.256660: train_loss -0.8499 
2025-02-24 12:31:06.261756: val_loss -0.631 
2025-02-24 12:31:06.265797: Pseudo dice [np.float32(0.8074), np.float32(0.6563)] 
2025-02-24 12:31:06.269541: Epoch time: 42.14 s 
2025-02-24 12:31:06.763664:  
2025-02-24 12:31:06.768679: Epoch 225 
2025-02-24 12:31:06.772192: Current learning rate: 0.00126 
2025-02-24 12:31:48.863164: train_loss -0.8497 
2025-02-24 12:31:48.868680: val_loss -0.5594 
2025-02-24 12:31:48.872192: Pseudo dice [np.float32(0.8127), np.float32(0.473)] 
2025-02-24 12:31:48.875698: Epoch time: 42.1 s 
2025-02-24 12:31:49.396548:  
2025-02-24 12:31:49.402063: Epoch 226 
2025-02-24 12:31:49.405575: Current learning rate: 0.00121 
2025-02-24 12:32:31.519582: train_loss -0.8426 
2025-02-24 12:32:31.525103: val_loss -0.5889 
2025-02-24 12:32:31.528622: Pseudo dice [np.float32(0.7989), np.float32(0.604)] 
2025-02-24 12:32:31.532134: Epoch time: 42.12 s 
2025-02-24 12:32:32.036457:  
2025-02-24 12:32:32.042045: Epoch 227 
2025-02-24 12:32:32.045604: Current learning rate: 0.00117 
2025-02-24 12:33:14.142695: train_loss -0.8432 
2025-02-24 12:33:14.148823: val_loss -0.6007 
2025-02-24 12:33:14.151878: Pseudo dice [np.float32(0.8057), np.float32(0.5683)] 
2025-02-24 12:33:14.155432: Epoch time: 42.11 s 
2025-02-24 12:33:14.663029:  
2025-02-24 12:33:14.668544: Epoch 228 
2025-02-24 12:33:14.672055: Current learning rate: 0.00112 
2025-02-24 12:33:56.784746: train_loss -0.8393 
2025-02-24 12:33:56.790316: val_loss -0.5565 
2025-02-24 12:33:56.793878: Pseudo dice [np.float32(0.7948), np.float32(0.5339)] 
2025-02-24 12:33:56.796410: Epoch time: 42.12 s 
2025-02-24 12:33:57.302211:  
2025-02-24 12:33:57.307727: Epoch 229 
2025-02-24 12:33:57.311237: Current learning rate: 0.00108 
2025-02-24 12:34:39.410384: train_loss -0.833 
2025-02-24 12:34:39.415536: val_loss -0.5495 
2025-02-24 12:34:39.420211: Pseudo dice [np.float32(0.7894), np.float32(0.3875)] 
2025-02-24 12:34:39.423765: Epoch time: 42.11 s 
2025-02-24 12:34:39.928219:  
2025-02-24 12:34:39.934282: Epoch 230 
2025-02-24 12:34:39.937325: Current learning rate: 0.00103 
2025-02-24 12:35:22.070719: train_loss -0.851 
2025-02-24 12:35:22.076848: val_loss -0.5831 
2025-02-24 12:35:22.079926: Pseudo dice [np.float32(0.7936), np.float32(0.4964)] 
2025-02-24 12:35:22.083456: Epoch time: 42.14 s 
2025-02-24 12:35:22.762933:  
2025-02-24 12:35:22.770449: Epoch 231 
2025-02-24 12:35:22.773459: Current learning rate: 0.00098 
2025-02-24 12:36:04.899871: train_loss -0.8371 
2025-02-24 12:36:04.906394: val_loss -0.558 
2025-02-24 12:36:04.909909: Pseudo dice [np.float32(0.801), np.float32(0.4242)] 
2025-02-24 12:36:04.912423: Epoch time: 42.14 s 
2025-02-24 12:36:05.423045:  
2025-02-24 12:36:05.428564: Epoch 232 
2025-02-24 12:36:05.432080: Current learning rate: 0.00094 
2025-02-24 12:36:47.560043: train_loss -0.837 
2025-02-24 12:36:47.567056: val_loss -0.5744 
2025-02-24 12:36:47.571071: Pseudo dice [np.float32(0.8023), np.float32(0.3999)] 
2025-02-24 12:36:47.575079: Epoch time: 42.14 s 
2025-02-24 12:36:48.078974:  
2025-02-24 12:36:48.084494: Epoch 233 
2025-02-24 12:36:48.088006: Current learning rate: 0.00089 
2025-02-24 12:37:30.202169: train_loss -0.8413 
2025-02-24 12:37:30.208684: val_loss -0.5999 
2025-02-24 12:37:30.212200: Pseudo dice [np.float32(0.791), np.float32(0.5603)] 
2025-02-24 12:37:30.214713: Epoch time: 42.12 s 
2025-02-24 12:37:30.718820:  
2025-02-24 12:37:30.724445: Epoch 234 
2025-02-24 12:37:30.727958: Current learning rate: 0.00084 
2025-02-24 12:38:12.851988: train_loss -0.8349 
2025-02-24 12:38:12.857505: val_loss -0.6123 
2025-02-24 12:38:12.860012: Pseudo dice [np.float32(0.8065), np.float32(0.5827)] 
2025-02-24 12:38:12.863521: Epoch time: 42.13 s 
2025-02-24 12:38:13.365948:  
2025-02-24 12:38:13.372017: Epoch 235 
2025-02-24 12:38:13.375067: Current learning rate: 0.00079 
2025-02-24 12:38:55.496179: train_loss -0.8515 
2025-02-24 12:38:55.501787: val_loss -0.571 
2025-02-24 12:38:55.505831: Pseudo dice [np.float32(0.8205), np.float32(0.5105)] 
2025-02-24 12:38:55.508846: Epoch time: 42.13 s 
2025-02-24 12:38:56.018808:  
2025-02-24 12:38:56.024373: Epoch 236 
2025-02-24 12:38:56.027946: Current learning rate: 0.00075 
2025-02-24 12:39:38.140396: train_loss -0.838 
2025-02-24 12:39:38.146933: val_loss -0.5939 
2025-02-24 12:39:38.150458: Pseudo dice [np.float32(0.7844), np.float32(0.564)] 
2025-02-24 12:39:38.153869: Epoch time: 42.12 s 
2025-02-24 12:39:38.656355:  
2025-02-24 12:39:38.661873: Epoch 237 
2025-02-24 12:39:38.665381: Current learning rate: 0.0007 
2025-02-24 12:40:20.826610: train_loss -0.8503 
2025-02-24 12:40:20.832187: val_loss -0.5573 
2025-02-24 12:40:20.835825: Pseudo dice [np.float32(0.8181), np.float32(0.4304)] 
2025-02-24 12:40:20.838876: Epoch time: 42.17 s 
2025-02-24 12:40:21.348372:  
2025-02-24 12:40:21.353954: Epoch 238 
2025-02-24 12:40:21.357486: Current learning rate: 0.00065 
2025-02-24 12:41:03.485654: train_loss -0.8488 
2025-02-24 12:41:03.492354: val_loss -0.5779 
2025-02-24 12:41:03.496408: Pseudo dice [np.float32(0.8119), np.float32(0.4698)] 
2025-02-24 12:41:03.499947: Epoch time: 42.14 s 
2025-02-24 12:41:04.004467:  
2025-02-24 12:41:04.009501: Epoch 239 
2025-02-24 12:41:04.013086: Current learning rate: 0.0006 
2025-02-24 12:41:46.156493: train_loss -0.8534 
2025-02-24 12:41:46.162193: val_loss -0.5413 
2025-02-24 12:41:46.165757: Pseudo dice [np.float32(0.7751), np.float32(0.4256)] 
2025-02-24 12:41:46.168843: Epoch time: 42.15 s 
2025-02-24 12:41:46.853582:  
2025-02-24 12:41:46.858595: Epoch 240 
2025-02-24 12:41:46.862107: Current learning rate: 0.00055 
2025-02-24 12:42:28.992591: train_loss -0.8426 
2025-02-24 12:42:28.998608: val_loss -0.5887 
2025-02-24 12:42:29.002625: Pseudo dice [np.float32(0.8073), np.float32(0.4115)] 
2025-02-24 12:42:29.006134: Epoch time: 42.14 s 
2025-02-24 12:42:29.520003:  
2025-02-24 12:42:29.525019: Epoch 241 
2025-02-24 12:42:29.528529: Current learning rate: 0.0005 
2025-02-24 12:43:11.658988: train_loss -0.8449 
2025-02-24 12:43:11.665169: val_loss -0.5227 
2025-02-24 12:43:11.668750: Pseudo dice [np.float32(0.7841), np.float32(0.3195)] 
2025-02-24 12:43:11.671764: Epoch time: 42.14 s 
2025-02-24 12:43:12.190113:  
2025-02-24 12:43:12.195626: Epoch 242 
2025-02-24 12:43:12.199137: Current learning rate: 0.00045 
2025-02-24 12:43:54.338277: train_loss -0.8497 
2025-02-24 12:43:54.343899: val_loss -0.5757 
2025-02-24 12:43:54.346934: Pseudo dice [np.float32(0.8036), np.float32(0.457)] 
2025-02-24 12:43:54.350438: Epoch time: 42.15 s 
2025-02-24 12:43:54.866187:  
2025-02-24 12:43:54.872213: Epoch 243 
2025-02-24 12:43:54.875556: Current learning rate: 0.0004 
2025-02-24 12:44:37.014585: train_loss -0.8526 
2025-02-24 12:44:37.021732: val_loss -0.5443 
2025-02-24 12:44:37.025241: Pseudo dice [np.float32(0.8067), np.float32(0.3853)] 
2025-02-24 12:44:37.027329: Epoch time: 42.15 s 
2025-02-24 12:44:37.544508:  
2025-02-24 12:44:37.549523: Epoch 244 
2025-02-24 12:44:37.553042: Current learning rate: 0.00035 
2025-02-24 12:45:19.703568: train_loss -0.8544 
2025-02-24 12:45:19.709181: val_loss -0.5986 
2025-02-24 12:45:19.711704: Pseudo dice [np.float32(0.8101), np.float32(0.5097)] 
2025-02-24 12:45:19.716798: Epoch time: 42.16 s 
2025-02-24 12:45:20.228379:  
2025-02-24 12:45:20.233893: Epoch 245 
2025-02-24 12:45:20.237400: Current learning rate: 0.0003 
2025-02-24 12:46:02.367787: train_loss -0.8526 
2025-02-24 12:46:02.375349: val_loss -0.5791 
2025-02-24 12:46:02.378860: Pseudo dice [np.float32(0.8119), np.float32(0.4589)] 
2025-02-24 12:46:02.381367: Epoch time: 42.14 s 
2025-02-24 12:46:02.898553:  
2025-02-24 12:46:02.904171: Epoch 246 
2025-02-24 12:46:02.908211: Current learning rate: 0.00024 
2025-02-24 12:46:45.035078: train_loss -0.8514 
2025-02-24 12:46:45.040616: val_loss -0.5727 
2025-02-24 12:46:45.044125: Pseudo dice [np.float32(0.8128), np.float32(0.4747)] 
2025-02-24 12:46:45.047629: Epoch time: 42.14 s 
2025-02-24 12:46:45.558609:  
2025-02-24 12:46:45.563645: Epoch 247 
2025-02-24 12:46:45.566472: Current learning rate: 0.00019 
2025-02-24 12:47:27.706658: train_loss -0.8525 
2025-02-24 12:47:27.712673: val_loss -0.5998 
2025-02-24 12:47:27.715177: Pseudo dice [np.float32(0.8137), np.float32(0.4876)] 
2025-02-24 12:47:27.719184: Epoch time: 42.15 s 
2025-02-24 12:47:28.400616:  
2025-02-24 12:47:28.406770: Epoch 248 
2025-02-24 12:47:28.409310: Current learning rate: 0.00013 
2025-02-24 12:48:10.513754: train_loss -0.8617 
2025-02-24 12:48:10.519764: val_loss -0.5609 
2025-02-24 12:48:10.522774: Pseudo dice [np.float32(0.8092), np.float32(0.4661)] 
2025-02-24 12:48:10.526285: Epoch time: 42.11 s 
2025-02-24 12:48:11.036974:  
2025-02-24 12:48:11.042494: Epoch 249 
2025-02-24 12:48:11.046014: Current learning rate: 7e-05 
2025-02-24 12:48:53.137836: train_loss -0.8539 
2025-02-24 12:48:53.142848: val_loss -0.5731 
2025-02-24 12:48:53.146357: Pseudo dice [np.float32(0.818), np.float32(0.5751)] 
2025-02-24 12:48:53.150370: Epoch time: 42.1 s 
2025-02-24 12:48:53.844943: Training done. 
2025-02-24 12:48:53.916947: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-02-24 12:48:53.924456: The split file contains 5 splits. 
2025-02-24 12:48:53.932457: Desired fold for training: 0 
2025-02-24 12:48:53.938455: This split has 224 training and 57 validation cases. 
2025-02-24 12:48:53.945456: predicting pancreas_021 
2025-02-24 12:48:53.952455: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-02-24 12:49:06.757444: predicting pancreas_024 
2025-02-24 12:49:06.776443: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-02-24 12:49:21.874696: predicting pancreas_035 
2025-02-24 12:49:21.892695: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-02-24 12:49:27.022241: predicting pancreas_040 
2025-02-24 12:49:27.034244: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-02-24 12:49:39.139901: predicting pancreas_042 
2025-02-24 12:49:39.156409: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-02-24 12:49:54.269232: predicting pancreas_056 
2025-02-24 12:49:54.288232: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-02-24 12:50:06.446634: predicting pancreas_067 
2025-02-24 12:50:06.463629: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-02-24 12:50:21.581204: predicting pancreas_075 
2025-02-24 12:50:21.599205: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-02-24 12:50:27.698413: predicting pancreas_086 
2025-02-24 12:50:27.712414: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-02-24 12:50:37.185553: predicting pancreas_089 
2025-02-24 12:50:37.200553: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-02-24 12:50:49.280095: predicting pancreas_092 
2025-02-24 12:50:49.294601: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-02-24 12:51:16.448004: predicting pancreas_094 
2025-02-24 12:51:16.473004: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-02-24 12:51:28.559017: predicting pancreas_095 
2025-02-24 12:51:28.574017: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-02-24 12:51:40.679647: predicting pancreas_098 
2025-02-24 12:51:40.695647: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-02-24 12:52:13.670040: predicting pancreas_109 
2025-02-24 12:52:13.695040: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-02-24 12:52:25.840324: predicting pancreas_110 
2025-02-24 12:52:25.860839: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-02-24 12:52:44.751274: predicting pancreas_114 
2025-02-24 12:52:44.771781: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-02-24 12:52:56.942377: predicting pancreas_119 
2025-02-24 12:52:56.959377: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-02-24 12:53:15.838446: predicting pancreas_138 
2025-02-24 12:53:15.856447: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-02-24 12:53:34.772223: predicting pancreas_145 
2025-02-24 12:53:34.792226: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-02-24 12:53:53.689758: predicting pancreas_148 
2025-02-24 12:53:53.709762: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-02-24 12:54:05.819698: predicting pancreas_169 
2025-02-24 12:54:05.838205: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-02-24 12:54:17.922034: predicting pancreas_170 
2025-02-24 12:54:17.936542: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-02-24 12:54:33.017216: predicting pancreas_172 
2025-02-24 12:54:33.034220: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-02-24 12:54:45.146827: predicting pancreas_175 
2025-02-24 12:54:45.160336: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-02-24 12:54:57.254756: predicting pancreas_180 
2025-02-24 12:54:57.270265: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-02-24 12:55:09.366804: predicting pancreas_191 
2025-02-24 12:55:09.383802: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-02-24 12:55:15.477702: predicting pancreas_193 
2025-02-24 12:55:15.490702: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-02-24 12:55:30.663751: predicting pancreas_212 
2025-02-24 12:55:30.681261: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-02-24 12:55:42.820451: predicting pancreas_215 
2025-02-24 12:55:42.838451: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-02-24 12:55:54.934648: predicting pancreas_222 
2025-02-24 12:55:54.950649: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-02-24 12:56:00.117443: predicting pancreas_235 
2025-02-24 12:56:00.130444: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-02-24 12:56:12.236054: predicting pancreas_241 
2025-02-24 12:56:12.252057: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-02-24 12:56:24.360365: predicting pancreas_242 
2025-02-24 12:56:24.378364: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-02-24 12:56:39.532762: predicting pancreas_244 
2025-02-24 12:56:39.550761: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-02-24 12:57:03.121757: predicting pancreas_246 
2025-02-24 12:57:03.142268: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-02-24 12:57:26.728267: predicting pancreas_247 
2025-02-24 12:57:26.747271: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-02-24 12:57:33.619625: predicting pancreas_264 
2025-02-24 12:57:33.632626: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-02-24 12:57:48.789520: predicting pancreas_265 
2025-02-24 12:57:48.806520: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-02-24 12:58:00.922933: predicting pancreas_266 
2025-02-24 12:58:00.940933: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-02-24 12:58:19.834214: predicting pancreas_267 
2025-02-24 12:58:19.854214: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-02-24 12:58:26.763812: predicting pancreas_275 
2025-02-24 12:58:26.778811: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-02-24 12:58:41.870991: predicting pancreas_279 
2025-02-24 12:58:41.886991: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-02-24 12:58:47.066008: predicting pancreas_287 
2025-02-24 12:58:47.079007: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-02-24 12:58:59.181995: predicting pancreas_301 
2025-02-24 12:58:59.198995: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-02-24 12:59:11.309486: predicting pancreas_323 
2025-02-24 12:59:11.325490: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-02-24 12:59:30.226660: predicting pancreas_336 
2025-02-24 12:59:30.248166: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-02-24 12:59:42.401801: predicting pancreas_344 
2025-02-24 12:59:42.421801: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-02-24 12:59:57.536171: predicting pancreas_351 
2025-02-24 12:59:57.554177: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-02-24 13:00:04.414703: predicting pancreas_354 
2025-02-24 13:00:04.428705: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-02-24 13:00:28.550675: predicting pancreas_372 
2025-02-24 13:00:28.576666: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-02-24 13:00:47.507808: predicting pancreas_377 
2025-02-24 13:00:47.528808: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-02-24 13:01:02.785850: predicting pancreas_387 
2025-02-24 13:01:02.803854: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-02-24 13:01:15.256573: predicting pancreas_391 
2025-02-24 13:01:15.274575: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-02-24 13:01:34.152141: predicting pancreas_392 
2025-02-24 13:01:34.171140: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-02-24 13:01:42.724861: predicting pancreas_410 
2025-02-24 13:01:42.739868: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-02-24 13:01:51.276316: predicting pancreas_412 
2025-02-24 13:01:51.290315: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-02-24 13:02:51.180191: Validation complete 
2025-02-24 13:02:51.186072: Mean Validation Dice:  0.36868083868054335 
