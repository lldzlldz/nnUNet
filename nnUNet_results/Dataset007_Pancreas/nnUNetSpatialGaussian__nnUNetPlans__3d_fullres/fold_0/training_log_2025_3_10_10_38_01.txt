
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-10 10:38:01.746585: do_dummy_2d_data_aug: True 
2025-03-10 10:38:01.776835: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-03-10 10:38:01.784835: The split file contains 5 splits. 
2025-03-10 10:38:01.787835: Desired fold for training: 0 
2025-03-10 10:38:01.789965: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-03-10 10:38:10.340744: unpacking dataset... 
2025-03-10 10:38:10.752031: unpacking done... 
2025-03-10 10:38:13.771774:  
2025-03-10 10:38:13.776790: Epoch 0 
2025-03-10 10:38:13.780294: Current learning rate: 0.01 
2025-03-10 10:39:43.856076: train_loss 0.0978 
2025-03-10 10:39:43.862590: val_loss 0.0447 
2025-03-10 10:39:43.866098: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-03-10 10:39:43.869605: Epoch time: 90.09 s 
2025-03-10 10:39:43.872613: Yayy! New best EMA pseudo Dice: 0.0 
2025-03-10 10:39:44.532301:  
2025-03-10 10:39:44.538873: Epoch 1 
2025-03-10 10:39:44.542427: Current learning rate: 0.00991 
2025-03-10 10:41:06.241994: train_loss 0.0088 
2025-03-10 10:41:06.249511: val_loss -0.0672 
2025-03-10 10:41:06.253019: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-03-10 10:41:06.256030: Epoch time: 81.71 s 
2025-03-10 10:41:06.809685:  
2025-03-10 10:41:06.816360: Epoch 2 
2025-03-10 10:41:06.819380: Current learning rate: 0.00982 
2025-03-10 10:42:28.480925: train_loss -0.1512 
2025-03-10 10:42:28.488442: val_loss -0.2517 
2025-03-10 10:42:28.492950: Pseudo dice [np.float32(0.5939), np.float32(0.0)] 
2025-03-10 10:42:28.495965: Epoch time: 81.67 s 
2025-03-10 10:42:28.499476: Yayy! New best EMA pseudo Dice: 0.02969999983906746 
2025-03-10 10:42:29.258175:  
2025-03-10 10:42:29.265767: Epoch 3 
2025-03-10 10:42:29.268823: Current learning rate: 0.00973 
2025-03-10 10:43:50.886261: train_loss -0.222 
2025-03-10 10:43:50.891275: val_loss -0.2716 
2025-03-10 10:43:50.894786: Pseudo dice [np.float32(0.6257), np.float32(0.0)] 
2025-03-10 10:43:50.898795: Epoch time: 81.63 s 
2025-03-10 10:43:50.901301: Yayy! New best EMA pseudo Dice: 0.057999998331069946 
2025-03-10 10:43:51.618104:  
2025-03-10 10:43:51.624619: Epoch 4 
2025-03-10 10:43:51.630639: Current learning rate: 0.00964 
2025-03-10 10:45:13.192344: train_loss -0.2617 
2025-03-10 10:45:13.197931: val_loss -0.3176 
2025-03-10 10:45:13.201440: Pseudo dice [np.float32(0.6105), np.float32(0.182)] 
2025-03-10 10:45:13.205448: Epoch time: 81.57 s 
2025-03-10 10:45:13.208956: Yayy! New best EMA pseudo Dice: 0.09179999679327011 
2025-03-10 10:45:14.094146:  
2025-03-10 10:45:14.100177: Epoch 5 
2025-03-10 10:45:14.102854: Current learning rate: 0.00955 
2025-03-10 10:46:35.664479: train_loss -0.2939 
2025-03-10 10:46:35.671638: val_loss -0.3501 
2025-03-10 10:46:35.674700: Pseudo dice [np.float32(0.6908), np.float32(0.1581)] 
2025-03-10 10:46:35.677768: Epoch time: 81.57 s 
2025-03-10 10:46:35.680809: Yayy! New best EMA pseudo Dice: 0.1251000016927719 
2025-03-10 10:46:36.404013:  
2025-03-10 10:46:36.409027: Epoch 6 
2025-03-10 10:46:36.412540: Current learning rate: 0.00946 
2025-03-10 10:47:58.024147: train_loss -0.3191 
2025-03-10 10:47:58.031201: val_loss -0.3626 
2025-03-10 10:47:58.034729: Pseudo dice [np.float32(0.6012), np.float32(0.2526)] 
2025-03-10 10:47:58.038305: Epoch time: 81.62 s 
2025-03-10 10:47:58.041829: Yayy! New best EMA pseudo Dice: 0.15530000627040863 
2025-03-10 10:47:58.805698:  
2025-03-10 10:47:58.810709: Epoch 7 
2025-03-10 10:47:58.814218: Current learning rate: 0.00937 
2025-03-10 10:49:20.470158: train_loss -0.3706 
2025-03-10 10:49:20.477175: val_loss -0.4477 
2025-03-10 10:49:20.480184: Pseudo dice [np.float32(0.663), np.float32(0.3608)] 
2025-03-10 10:49:20.483695: Epoch time: 81.67 s 
2025-03-10 10:49:20.487201: Yayy! New best EMA pseudo Dice: 0.19089999794960022 
2025-03-10 10:49:21.255375:  
2025-03-10 10:49:21.261472: Epoch 8 
2025-03-10 10:49:21.264518: Current learning rate: 0.00928 
2025-03-10 10:50:42.980923: train_loss -0.3603 
2025-03-10 10:50:42.988442: val_loss -0.4438 
2025-03-10 10:50:42.990949: Pseudo dice [np.float32(0.6777), np.float32(0.3313)] 
2025-03-10 10:50:42.994958: Epoch time: 81.73 s 
2025-03-10 10:50:42.998468: Yayy! New best EMA pseudo Dice: 0.2222999930381775 
2025-03-10 10:50:43.728655:  
2025-03-10 10:50:43.734739: Epoch 9 
2025-03-10 10:50:43.737821: Current learning rate: 0.00919 
2025-03-10 10:52:05.306974: train_loss -0.3875 
2025-03-10 10:52:05.313546: val_loss -0.4204 
2025-03-10 10:52:05.317052: Pseudo dice [np.float32(0.6954), np.float32(0.2121)] 
2025-03-10 10:52:05.320060: Epoch time: 81.58 s 
2025-03-10 10:52:05.323569: Yayy! New best EMA pseudo Dice: 0.24539999663829803 
2025-03-10 10:52:06.057809:  
2025-03-10 10:52:06.063344: Epoch 10 
2025-03-10 10:52:06.067424: Current learning rate: 0.0091 
2025-03-10 10:53:27.610619: train_loss -0.3925 
2025-03-10 10:53:27.617136: val_loss -0.4735 
2025-03-10 10:53:27.620650: Pseudo dice [np.float32(0.6798), np.float32(0.4198)] 
2025-03-10 10:53:27.624154: Epoch time: 81.55 s 
2025-03-10 10:53:27.627169: Yayy! New best EMA pseudo Dice: 0.2759000062942505 
2025-03-10 10:53:28.361620:  
2025-03-10 10:53:28.367135: Epoch 11 
2025-03-10 10:53:28.372150: Current learning rate: 0.009 
2025-03-10 10:54:49.949620: train_loss -0.4137 
2025-03-10 10:54:49.956633: val_loss -0.4642 
2025-03-10 10:54:49.959643: Pseudo dice [np.float32(0.6753), np.float32(0.3559)] 
2025-03-10 10:54:49.962684: Epoch time: 81.59 s 
2025-03-10 10:54:49.966719: Yayy! New best EMA pseudo Dice: 0.29980000853538513 
2025-03-10 10:54:50.683079:  
2025-03-10 10:54:50.688669: Epoch 12 
2025-03-10 10:54:50.692227: Current learning rate: 0.00891 
2025-03-10 10:56:12.317425: train_loss -0.4352 
2025-03-10 10:56:12.322940: val_loss -0.4975 
2025-03-10 10:56:12.326451: Pseudo dice [np.float32(0.7255), np.float32(0.3652)] 
2025-03-10 10:56:12.330458: Epoch time: 81.63 s 
2025-03-10 10:56:12.333965: Yayy! New best EMA pseudo Dice: 0.32440000772476196 
2025-03-10 10:56:13.231124:  
2025-03-10 10:56:13.236637: Epoch 13 
2025-03-10 10:56:13.240145: Current learning rate: 0.00882 
2025-03-10 10:57:34.908034: train_loss -0.4687 
2025-03-10 10:57:34.917053: val_loss -0.4469 
2025-03-10 10:57:34.920603: Pseudo dice [np.float32(0.705), np.float32(0.3018)] 
2025-03-10 10:57:34.924609: Epoch time: 81.68 s 
2025-03-10 10:57:34.928117: Yayy! New best EMA pseudo Dice: 0.3422999978065491 
2025-03-10 10:57:35.683430:  
2025-03-10 10:57:35.689443: Epoch 14 
2025-03-10 10:57:35.692951: Current learning rate: 0.00873 
2025-03-10 10:58:57.324929: train_loss -0.4626 
2025-03-10 10:58:57.330577: val_loss -0.5142 
2025-03-10 10:58:57.334098: Pseudo dice [np.float32(0.7354), np.float32(0.4041)] 
2025-03-10 10:58:57.337620: Epoch time: 81.64 s 
2025-03-10 10:58:57.341037: Yayy! New best EMA pseudo Dice: 0.36500000953674316 
2025-03-10 10:58:58.097625:  
2025-03-10 10:58:58.103176: Epoch 15 
2025-03-10 10:58:58.106687: Current learning rate: 0.00864 
2025-03-10 11:00:19.707473: train_loss -0.4906 
2025-03-10 11:00:19.712991: val_loss -0.5344 
2025-03-10 11:00:19.719010: Pseudo dice [np.float32(0.7282), np.float32(0.5003)] 
2025-03-10 11:00:19.723020: Epoch time: 81.61 s 
2025-03-10 11:00:19.725526: Yayy! New best EMA pseudo Dice: 0.38999998569488525 
2025-03-10 11:00:20.474730:  
2025-03-10 11:00:20.480276: Epoch 16 
2025-03-10 11:00:20.484908: Current learning rate: 0.00855 
2025-03-10 11:01:42.116839: train_loss -0.4649 
2025-03-10 11:01:42.123855: val_loss -0.4688 
2025-03-10 11:01:42.127379: Pseudo dice [np.float32(0.7087), np.float32(0.2862)] 
2025-03-10 11:01:42.130407: Epoch time: 81.64 s 
2025-03-10 11:01:42.132914: Yayy! New best EMA pseudo Dice: 0.40070000290870667 
2025-03-10 11:01:42.905248:  
2025-03-10 11:01:42.910763: Epoch 17 
2025-03-10 11:01:42.915272: Current learning rate: 0.00846 
2025-03-10 11:03:04.482421: train_loss -0.5127 
2025-03-10 11:03:04.488947: val_loss -0.478 
2025-03-10 11:03:04.492590: Pseudo dice [np.float32(0.7051), np.float32(0.381)] 
2025-03-10 11:03:04.496646: Epoch time: 81.58 s 
2025-03-10 11:03:04.500262: Yayy! New best EMA pseudo Dice: 0.414900004863739 
2025-03-10 11:03:05.276891:  
2025-03-10 11:03:05.282409: Epoch 18 
2025-03-10 11:03:05.285918: Current learning rate: 0.00836 
2025-03-10 11:04:26.907683: train_loss -0.5245 
2025-03-10 11:04:26.915262: val_loss -0.514 
2025-03-10 11:04:26.918796: Pseudo dice [np.float32(0.7225), np.float32(0.4615)] 
2025-03-10 11:04:26.922331: Epoch time: 81.63 s 
2025-03-10 11:04:26.925375: Yayy! New best EMA pseudo Dice: 0.4325999915599823 
2025-03-10 11:04:27.668034:  
2025-03-10 11:04:27.674118: Epoch 19 
2025-03-10 11:04:27.677629: Current learning rate: 0.00827 
2025-03-10 11:05:49.349062: train_loss -0.5149 
2025-03-10 11:05:49.355578: val_loss -0.5192 
2025-03-10 11:05:49.359090: Pseudo dice [np.float32(0.7238), np.float32(0.4169)] 
2025-03-10 11:05:49.363104: Epoch time: 81.68 s 
2025-03-10 11:05:49.366615: Yayy! New best EMA pseudo Dice: 0.446399986743927 
2025-03-10 11:05:50.146677:  
2025-03-10 11:05:50.152750: Epoch 20 
2025-03-10 11:05:50.155309: Current learning rate: 0.00818 
2025-03-10 11:07:11.709746: train_loss -0.5337 
2025-03-10 11:07:11.716383: val_loss -0.5424 
2025-03-10 11:07:11.721401: Pseudo dice [np.float32(0.7413), np.float32(0.4397)] 
2025-03-10 11:07:11.725413: Epoch time: 81.56 s 
2025-03-10 11:07:11.728924: Yayy! New best EMA pseudo Dice: 0.4607999920845032 
2025-03-10 11:07:12.667188:  
2025-03-10 11:07:12.673258: Epoch 21 
2025-03-10 11:07:12.676836: Current learning rate: 0.00809 
2025-03-10 11:08:34.237965: train_loss -0.541 
2025-03-10 11:08:34.244481: val_loss -0.5461 
2025-03-10 11:08:34.247993: Pseudo dice [np.float32(0.7491), np.float32(0.414)] 
2025-03-10 11:08:34.251512: Epoch time: 81.57 s 
2025-03-10 11:08:34.255087: Yayy! New best EMA pseudo Dice: 0.47290000319480896 
2025-03-10 11:08:34.985760:  
2025-03-10 11:08:34.991277: Epoch 22 
2025-03-10 11:08:34.994792: Current learning rate: 0.008 
2025-03-10 11:09:56.573540: train_loss -0.5448 
2025-03-10 11:09:56.581065: val_loss -0.5341 
2025-03-10 11:09:56.584577: Pseudo dice [np.float32(0.7248), np.float32(0.4523)] 
2025-03-10 11:09:56.588244: Epoch time: 81.59 s 
2025-03-10 11:09:56.591760: Yayy! New best EMA pseudo Dice: 0.484499990940094 
2025-03-10 11:09:57.310595:  
2025-03-10 11:09:57.316153: Epoch 23 
2025-03-10 11:09:57.320201: Current learning rate: 0.0079 
2025-03-10 11:11:18.932697: train_loss -0.5596 
2025-03-10 11:11:18.940284: val_loss -0.4807 
2025-03-10 11:11:18.943825: Pseudo dice [np.float32(0.7231), np.float32(0.3737)] 
2025-03-10 11:11:18.947367: Epoch time: 81.62 s 
2025-03-10 11:11:18.950920: Yayy! New best EMA pseudo Dice: 0.4909000098705292 
2025-03-10 11:11:19.685179:  
2025-03-10 11:11:19.691202: Epoch 24 
2025-03-10 11:11:19.693713: Current learning rate: 0.00781 
2025-03-10 11:12:41.258843: train_loss -0.5336 
2025-03-10 11:12:41.264896: val_loss -0.525 
2025-03-10 11:12:41.268927: Pseudo dice [np.float32(0.7499), np.float32(0.3898)] 
2025-03-10 11:12:41.272434: Epoch time: 81.57 s 
2025-03-10 11:12:41.275443: Yayy! New best EMA pseudo Dice: 0.49880000948905945 
2025-03-10 11:12:41.996539:  
2025-03-10 11:12:42.002447: Epoch 25 
2025-03-10 11:12:42.006459: Current learning rate: 0.00772 
2025-03-10 11:14:03.722152: train_loss -0.5434 
2025-03-10 11:14:03.729669: val_loss -0.53 
2025-03-10 11:14:03.733683: Pseudo dice [np.float32(0.7409), np.float32(0.4229)] 
2025-03-10 11:14:03.737195: Epoch time: 81.73 s 
2025-03-10 11:14:03.739710: Yayy! New best EMA pseudo Dice: 0.507099986076355 
2025-03-10 11:14:04.487016:  
2025-03-10 11:14:04.492029: Epoch 26 
2025-03-10 11:14:04.495541: Current learning rate: 0.00763 
2025-03-10 11:15:26.084895: train_loss -0.546 
2025-03-10 11:15:26.091913: val_loss -0.5725 
2025-03-10 11:15:26.094924: Pseudo dice [np.float32(0.7679), np.float32(0.4372)] 
2025-03-10 11:15:26.098433: Epoch time: 81.6 s 
2025-03-10 11:15:26.100940: Yayy! New best EMA pseudo Dice: 0.5166000127792358 
2025-03-10 11:15:26.823752:  
2025-03-10 11:15:26.829558: Epoch 27 
2025-03-10 11:15:26.833069: Current learning rate: 0.00753 
2025-03-10 11:16:48.432124: train_loss -0.5508 
2025-03-10 11:16:48.438641: val_loss -0.5425 
2025-03-10 11:16:48.442150: Pseudo dice [np.float32(0.7542), np.float32(0.3994)] 
2025-03-10 11:16:48.446158: Epoch time: 81.61 s 
2025-03-10 11:16:48.449669: Yayy! New best EMA pseudo Dice: 0.522599995136261 
2025-03-10 11:16:49.201234:  
2025-03-10 11:16:49.206805: Epoch 28 
2025-03-10 11:16:49.210462: Current learning rate: 0.00744 
2025-03-10 11:18:10.809091: train_loss -0.5857 
2025-03-10 11:18:10.815606: val_loss -0.5386 
2025-03-10 11:18:10.819117: Pseudo dice [np.float32(0.7328), np.float32(0.405)] 
2025-03-10 11:18:10.823128: Epoch time: 81.61 s 
2025-03-10 11:18:10.825635: Yayy! New best EMA pseudo Dice: 0.5273000001907349 
2025-03-10 11:18:11.703605:  
2025-03-10 11:18:11.709141: Epoch 29 
2025-03-10 11:18:11.712325: Current learning rate: 0.00735 
2025-03-10 11:19:33.304702: train_loss -0.5913 
2025-03-10 11:19:33.312735: val_loss -0.5269 
2025-03-10 11:19:33.316273: Pseudo dice [np.float32(0.7554), np.float32(0.3894)] 
2025-03-10 11:19:33.320609: Epoch time: 81.6 s 
2025-03-10 11:19:33.324123: Yayy! New best EMA pseudo Dice: 0.5317999720573425 
2025-03-10 11:19:34.071928:  
2025-03-10 11:19:34.077969: Epoch 30 
2025-03-10 11:19:34.082016: Current learning rate: 0.00725 
2025-03-10 11:20:55.768814: train_loss -0.5909 
2025-03-10 11:20:55.775331: val_loss -0.5287 
2025-03-10 11:20:55.778839: Pseudo dice [np.float32(0.7511), np.float32(0.361)] 
2025-03-10 11:20:55.781850: Epoch time: 81.7 s 
2025-03-10 11:20:55.785358: Yayy! New best EMA pseudo Dice: 0.5342000126838684 
2025-03-10 11:20:56.516754:  
2025-03-10 11:20:56.522772: Epoch 31 
2025-03-10 11:20:56.526283: Current learning rate: 0.00716 
2025-03-10 11:22:18.100238: train_loss -0.5782 
2025-03-10 11:22:18.105253: val_loss -0.5499 
2025-03-10 11:22:18.108766: Pseudo dice [np.float32(0.7582), np.float32(0.4192)] 
2025-03-10 11:22:18.112302: Epoch time: 81.58 s 
2025-03-10 11:22:18.115876: Yayy! New best EMA pseudo Dice: 0.5396999716758728 
2025-03-10 11:22:18.860503:  
2025-03-10 11:22:18.866017: Epoch 32 
2025-03-10 11:22:18.869525: Current learning rate: 0.00707 
2025-03-10 11:23:40.409596: train_loss -0.5939 
2025-03-10 11:23:40.415609: val_loss -0.5549 
2025-03-10 11:23:40.419622: Pseudo dice [np.float32(0.7464), np.float32(0.4558)] 
2025-03-10 11:23:40.423131: Epoch time: 81.55 s 
2025-03-10 11:23:40.425636: Yayy! New best EMA pseudo Dice: 0.545799970626831 
2025-03-10 11:23:41.152151:  
2025-03-10 11:23:41.157667: Epoch 33 
2025-03-10 11:23:41.161175: Current learning rate: 0.00697 
2025-03-10 11:25:02.744292: train_loss -0.6041 
2025-03-10 11:25:02.750385: val_loss -0.5135 
2025-03-10 11:25:02.755462: Pseudo dice [np.float32(0.7653), np.float32(0.3474)] 
2025-03-10 11:25:02.760093: Epoch time: 81.59 s 
2025-03-10 11:25:02.762600: Yayy! New best EMA pseudo Dice: 0.5468999743461609 
2025-03-10 11:25:03.533019:  
2025-03-10 11:25:03.539592: Epoch 34 
2025-03-10 11:25:03.543126: Current learning rate: 0.00688 
2025-03-10 11:26:25.092795: train_loss -0.6169 
2025-03-10 11:26:25.098307: val_loss -0.526 
2025-03-10 11:26:25.100862: Pseudo dice [np.float32(0.7696), np.float32(0.3848)] 
2025-03-10 11:26:25.104374: Epoch time: 81.56 s 
2025-03-10 11:26:25.107881: Yayy! New best EMA pseudo Dice: 0.5498999953269958 
2025-03-10 11:26:25.865909:  
2025-03-10 11:26:25.871966: Epoch 35 
2025-03-10 11:26:25.875043: Current learning rate: 0.00679 
2025-03-10 11:27:47.529867: train_loss -0.6222 
2025-03-10 11:27:47.537388: val_loss -0.5127 
2025-03-10 11:27:47.541399: Pseudo dice [np.float32(0.7513), np.float32(0.3278)] 
2025-03-10 11:27:47.544908: Epoch time: 81.66 s 
2025-03-10 11:27:48.127879:  
2025-03-10 11:27:48.133915: Epoch 36 
2025-03-10 11:27:48.136960: Current learning rate: 0.00669 
2025-03-10 11:29:10.257873: train_loss -0.6253 
2025-03-10 11:29:10.264386: val_loss -0.5142 
2025-03-10 11:29:10.267899: Pseudo dice [np.float32(0.774), np.float32(0.3181)] 
2025-03-10 11:29:10.271910: Epoch time: 82.13 s 
2025-03-10 11:29:10.995032:  
2025-03-10 11:29:11.000626: Epoch 37 
2025-03-10 11:29:11.005219: Current learning rate: 0.0066 
2025-03-10 11:30:32.573320: train_loss -0.5928 
2025-03-10 11:30:32.579834: val_loss -0.533 
2025-03-10 11:30:32.583344: Pseudo dice [np.float32(0.7557), np.float32(0.3916)] 
2025-03-10 11:30:32.587352: Epoch time: 81.58 s 
2025-03-10 11:30:32.589859: Yayy! New best EMA pseudo Dice: 0.5511000156402588 
2025-03-10 11:30:33.342526:  
2025-03-10 11:30:33.348040: Epoch 38 
2025-03-10 11:30:33.351552: Current learning rate: 0.0065 
2025-03-10 11:31:54.893383: train_loss -0.6303 
2025-03-10 11:31:54.899896: val_loss -0.5433 
2025-03-10 11:31:54.903404: Pseudo dice [np.float32(0.7697), np.float32(0.4314)] 
2025-03-10 11:31:54.905915: Epoch time: 81.55 s 
2025-03-10 11:31:54.909921: Yayy! New best EMA pseudo Dice: 0.5559999942779541 
2025-03-10 11:31:55.653067:  
2025-03-10 11:31:55.658582: Epoch 39 
2025-03-10 11:31:55.662091: Current learning rate: 0.00641 
2025-03-10 11:33:17.348304: train_loss -0.6305 
2025-03-10 11:33:17.354820: val_loss -0.4919 
2025-03-10 11:33:17.358330: Pseudo dice [np.float32(0.7549), np.float32(0.2944)] 
2025-03-10 11:33:17.362341: Epoch time: 81.7 s 
2025-03-10 11:33:17.964883:  
2025-03-10 11:33:17.971404: Epoch 40 
2025-03-10 11:33:17.974914: Current learning rate: 0.00631 
2025-03-10 11:34:39.657104: train_loss -0.6334 
2025-03-10 11:34:39.664629: val_loss -0.5636 
2025-03-10 11:34:39.668649: Pseudo dice [np.float32(0.7534), np.float32(0.5025)] 
2025-03-10 11:34:39.672161: Epoch time: 81.69 s 
2025-03-10 11:34:39.676178: Yayy! New best EMA pseudo Dice: 0.5604000091552734 
2025-03-10 11:34:40.489629:  
2025-03-10 11:34:40.494702: Epoch 41 
2025-03-10 11:34:40.499891: Current learning rate: 0.00622 
2025-03-10 11:36:02.213650: train_loss -0.6079 
2025-03-10 11:36:02.219673: val_loss -0.5369 
2025-03-10 11:36:02.227199: Pseudo dice [np.float32(0.75), np.float32(0.3953)] 
2025-03-10 11:36:02.232219: Epoch time: 81.73 s 
2025-03-10 11:36:02.235726: Yayy! New best EMA pseudo Dice: 0.5616000294685364 
2025-03-10 11:36:02.959562:  
2025-03-10 11:36:02.967083: Epoch 42 
2025-03-10 11:36:02.971093: Current learning rate: 0.00612 
2025-03-10 11:37:24.608447: train_loss -0.6222 
2025-03-10 11:37:24.615965: val_loss -0.593 
2025-03-10 11:37:24.619474: Pseudo dice [np.float32(0.7685), np.float32(0.4972)] 
2025-03-10 11:37:24.624492: Epoch time: 81.65 s 
2025-03-10 11:37:24.628501: Yayy! New best EMA pseudo Dice: 0.5687000155448914 
2025-03-10 11:37:25.365072:  
2025-03-10 11:37:25.371128: Epoch 43 
2025-03-10 11:37:25.375664: Current learning rate: 0.00603 
2025-03-10 11:38:47.008505: train_loss -0.6318 
2025-03-10 11:38:47.015020: val_loss -0.5658 
2025-03-10 11:38:47.022541: Pseudo dice [np.float32(0.7694), np.float32(0.463)] 
2025-03-10 11:38:47.026053: Epoch time: 81.64 s 
2025-03-10 11:38:47.030070: Yayy! New best EMA pseudo Dice: 0.5734999775886536 
2025-03-10 11:38:47.780721:  
2025-03-10 11:38:47.788741: Epoch 44 
2025-03-10 11:38:47.794757: Current learning rate: 0.00593 
2025-03-10 11:40:09.377997: train_loss -0.6582 
2025-03-10 11:40:09.385590: val_loss -0.5059 
2025-03-10 11:40:09.390165: Pseudo dice [np.float32(0.7698), np.float32(0.3652)] 
2025-03-10 11:40:09.393794: Epoch time: 81.6 s 
2025-03-10 11:40:10.092510:  
2025-03-10 11:40:10.098047: Epoch 45 
2025-03-10 11:40:10.101595: Current learning rate: 0.00584 
2025-03-10 11:41:31.713376: train_loss -0.6521 
2025-03-10 11:41:31.719475: val_loss -0.5415 
2025-03-10 11:41:31.724066: Pseudo dice [np.float32(0.7754), np.float32(0.3781)] 
2025-03-10 11:41:31.727709: Epoch time: 81.62 s 
2025-03-10 11:41:32.280923:  
2025-03-10 11:41:32.287998: Epoch 46 
2025-03-10 11:41:32.291586: Current learning rate: 0.00574 
2025-03-10 11:42:53.984430: train_loss -0.6515 
2025-03-10 11:42:53.991008: val_loss -0.5363 
2025-03-10 11:42:53.995578: Pseudo dice [np.float32(0.7721), np.float32(0.3873)] 
2025-03-10 11:42:53.999586: Epoch time: 81.7 s 
2025-03-10 11:42:54.003096: Yayy! New best EMA pseudo Dice: 0.5738999843597412 
2025-03-10 11:42:54.721338:  
2025-03-10 11:42:54.727353: Epoch 47 
2025-03-10 11:42:54.731361: Current learning rate: 0.00565 
2025-03-10 11:44:16.370344: train_loss -0.6454 
2025-03-10 11:44:16.377535: val_loss -0.5941 
2025-03-10 11:44:16.380588: Pseudo dice [np.float32(0.7808), np.float32(0.4825)] 
2025-03-10 11:44:16.384656: Epoch time: 81.65 s 
2025-03-10 11:44:16.388237: Yayy! New best EMA pseudo Dice: 0.5796999931335449 
2025-03-10 11:44:17.132690:  
2025-03-10 11:44:17.139265: Epoch 48 
2025-03-10 11:44:17.143914: Current learning rate: 0.00555 
2025-03-10 11:45:38.783795: train_loss -0.6613 
2025-03-10 11:45:38.790310: val_loss -0.5312 
2025-03-10 11:45:38.794361: Pseudo dice [np.float32(0.7604), np.float32(0.3716)] 
2025-03-10 11:45:38.797973: Epoch time: 81.65 s 
2025-03-10 11:45:39.359545:  
2025-03-10 11:45:39.365616: Epoch 49 
2025-03-10 11:45:39.368664: Current learning rate: 0.00546 
2025-03-10 11:47:00.995820: train_loss -0.6562 
2025-03-10 11:47:01.002894: val_loss -0.5854 
2025-03-10 11:47:01.007512: Pseudo dice [np.float32(0.7752), np.float32(0.4783)] 
2025-03-10 11:47:01.010588: Epoch time: 81.64 s 
2025-03-10 11:47:01.165797: Yayy! New best EMA pseudo Dice: 0.5831999778747559 
2025-03-10 11:47:01.881589:  
2025-03-10 11:47:01.888218: Epoch 50 
2025-03-10 11:47:01.892292: Current learning rate: 0.00536 
2025-03-10 11:48:23.513977: train_loss -0.6602 
2025-03-10 11:48:23.521092: val_loss -0.538 
2025-03-10 11:48:23.524667: Pseudo dice [np.float32(0.7752), np.float32(0.4245)] 
2025-03-10 11:48:23.527697: Epoch time: 81.63 s 
2025-03-10 11:48:23.531245: Yayy! New best EMA pseudo Dice: 0.5848000049591064 
2025-03-10 11:48:24.252187:  
2025-03-10 11:48:24.257710: Epoch 51 
2025-03-10 11:48:24.261789: Current learning rate: 0.00526 
2025-03-10 11:49:45.899256: train_loss -0.6681 
2025-03-10 11:49:45.906776: val_loss -0.5437 
2025-03-10 11:49:45.910786: Pseudo dice [np.float32(0.7871), np.float32(0.3393)] 
2025-03-10 11:49:45.914296: Epoch time: 81.65 s 
2025-03-10 11:49:46.483327:  
2025-03-10 11:49:46.488878: Epoch 52 
2025-03-10 11:49:46.493444: Current learning rate: 0.00517 
2025-03-10 11:51:08.272810: train_loss -0.6578 
2025-03-10 11:51:08.280328: val_loss -0.5562 
2025-03-10 11:51:08.283836: Pseudo dice [np.float32(0.7787), np.float32(0.4157)] 
2025-03-10 11:51:08.286342: Epoch time: 81.79 s 
2025-03-10 11:51:09.006556:  
2025-03-10 11:51:09.012582: Epoch 53 
2025-03-10 11:51:09.016090: Current learning rate: 0.00507 
2025-03-10 11:52:30.613663: train_loss -0.674 
2025-03-10 11:52:30.620178: val_loss -0.5764 
2025-03-10 11:52:30.624738: Pseudo dice [np.float32(0.7849), np.float32(0.4893)] 
2025-03-10 11:52:30.627769: Epoch time: 81.61 s 
2025-03-10 11:52:30.632782: Yayy! New best EMA pseudo Dice: 0.5893999934196472 
2025-03-10 11:52:31.378605:  
2025-03-10 11:52:31.387636: Epoch 54 
2025-03-10 11:52:31.391659: Current learning rate: 0.00497 
2025-03-10 11:53:52.993143: train_loss -0.6717 
2025-03-10 11:53:52.998658: val_loss -0.5969 
2025-03-10 11:53:53.003741: Pseudo dice [np.float32(0.7766), np.float32(0.4649)] 
2025-03-10 11:53:53.006777: Epoch time: 81.62 s 
2025-03-10 11:53:53.011321: Yayy! New best EMA pseudo Dice: 0.5925999879837036 
2025-03-10 11:53:53.746945:  
2025-03-10 11:53:53.753963: Epoch 55 
2025-03-10 11:53:53.757976: Current learning rate: 0.00487 
2025-03-10 11:55:15.329325: train_loss -0.6725 
2025-03-10 11:55:15.335839: val_loss -0.6311 
2025-03-10 11:55:15.340430: Pseudo dice [np.float32(0.8069), np.float32(0.5409)] 
2025-03-10 11:55:15.344445: Epoch time: 81.58 s 
2025-03-10 11:55:15.348025: Yayy! New best EMA pseudo Dice: 0.6007000207901001 
2025-03-10 11:55:16.086243:  
2025-03-10 11:55:16.093854: Epoch 56 
2025-03-10 11:55:16.098016: Current learning rate: 0.00478 
2025-03-10 11:56:37.713320: train_loss -0.6738 
2025-03-10 11:56:37.720336: val_loss -0.6055 
2025-03-10 11:56:37.724349: Pseudo dice [np.float32(0.7938), np.float32(0.5299)] 
2025-03-10 11:56:37.728366: Epoch time: 81.63 s 
2025-03-10 11:56:37.731879: Yayy! New best EMA pseudo Dice: 0.6068000197410583 
2025-03-10 11:56:38.493876:  
2025-03-10 11:56:38.500397: Epoch 57 
2025-03-10 11:56:38.504906: Current learning rate: 0.00468 
2025-03-10 11:58:00.208878: train_loss -0.6917 
2025-03-10 11:58:00.215935: val_loss -0.566 
2025-03-10 11:58:00.219463: Pseudo dice [np.float32(0.7857), np.float32(0.4247)] 
2025-03-10 11:58:00.223492: Epoch time: 81.72 s 
2025-03-10 11:58:00.781683:  
2025-03-10 11:58:00.786743: Epoch 58 
2025-03-10 11:58:00.790260: Current learning rate: 0.00458 
2025-03-10 11:59:22.412018: train_loss -0.6888 
2025-03-10 11:59:22.419598: val_loss -0.5665 
2025-03-10 11:59:22.423650: Pseudo dice [np.float32(0.7767), np.float32(0.465)] 
2025-03-10 11:59:22.426700: Epoch time: 81.63 s 
2025-03-10 11:59:22.431271: Yayy! New best EMA pseudo Dice: 0.6080999970436096 
2025-03-10 11:59:23.185664:  
2025-03-10 11:59:23.192189: Epoch 59 
2025-03-10 11:59:23.194194: Current learning rate: 0.00448 
2025-03-10 12:00:44.860621: train_loss -0.6845 
2025-03-10 12:00:44.865632: val_loss -0.5974 
2025-03-10 12:00:44.870144: Pseudo dice [np.float32(0.7881), np.float32(0.524)] 
2025-03-10 12:00:44.873153: Epoch time: 81.68 s 
2025-03-10 12:00:44.875659: Yayy! New best EMA pseudo Dice: 0.6129000186920166 
2025-03-10 12:00:45.627681:  
2025-03-10 12:00:45.633219: Epoch 60 
2025-03-10 12:00:45.636771: Current learning rate: 0.00438 
2025-03-10 12:02:07.235638: train_loss -0.6977 
2025-03-10 12:02:07.242164: val_loss -0.5395 
2025-03-10 12:02:07.245678: Pseudo dice [np.float32(0.7862), np.float32(0.3854)] 
2025-03-10 12:02:07.248691: Epoch time: 81.61 s 
2025-03-10 12:02:07.965563:  
2025-03-10 12:02:07.971105: Epoch 61 
2025-03-10 12:02:07.973617: Current learning rate: 0.00429 
2025-03-10 12:03:29.542389: train_loss -0.699 
2025-03-10 12:03:29.548918: val_loss -0.5559 
2025-03-10 12:03:29.552932: Pseudo dice [np.float32(0.7886), np.float32(0.4368)] 
2025-03-10 12:03:29.555441: Epoch time: 81.58 s 
2025-03-10 12:03:30.136568:  
2025-03-10 12:03:30.142106: Epoch 62 
2025-03-10 12:03:30.145616: Current learning rate: 0.00419 
2025-03-10 12:04:51.783952: train_loss -0.7062 
2025-03-10 12:04:51.791144: val_loss -0.5426 
2025-03-10 12:04:51.795184: Pseudo dice [np.float32(0.7806), np.float32(0.4521)] 
2025-03-10 12:04:51.798753: Epoch time: 81.65 s 
2025-03-10 12:04:52.375897:  
2025-03-10 12:04:52.382514: Epoch 63 
2025-03-10 12:04:52.385558: Current learning rate: 0.00409 
2025-03-10 12:06:14.101179: train_loss -0.7051 
2025-03-10 12:06:14.108785: val_loss -0.5681 
2025-03-10 12:06:14.111832: Pseudo dice [np.float32(0.7953), np.float32(0.4525)] 
2025-03-10 12:06:14.114861: Epoch time: 81.73 s 
2025-03-10 12:06:14.698510:  
2025-03-10 12:06:14.704076: Epoch 64 
2025-03-10 12:06:14.707622: Current learning rate: 0.00399 
2025-03-10 12:07:36.274508: train_loss -0.7201 
2025-03-10 12:07:36.280523: val_loss -0.5553 
2025-03-10 12:07:36.284532: Pseudo dice [np.float32(0.7952), np.float32(0.3674)] 
2025-03-10 12:07:36.288040: Epoch time: 81.58 s 
2025-03-10 12:07:36.864769:  
2025-03-10 12:07:36.870286: Epoch 65 
2025-03-10 12:07:36.874799: Current learning rate: 0.00389 
2025-03-10 12:08:58.528776: train_loss -0.7156 
2025-03-10 12:08:58.534785: val_loss -0.5506 
2025-03-10 12:08:58.537822: Pseudo dice [np.float32(0.7711), np.float32(0.4603)] 
2025-03-10 12:08:58.541363: Epoch time: 81.67 s 
2025-03-10 12:08:59.112580:  
2025-03-10 12:08:59.118607: Epoch 66 
2025-03-10 12:08:59.121638: Current learning rate: 0.00379 
2025-03-10 12:10:20.736625: train_loss -0.682 
2025-03-10 12:10:20.743270: val_loss -0.5306 
2025-03-10 12:10:20.746329: Pseudo dice [np.float32(0.7829), np.float32(0.3282)] 
2025-03-10 12:10:20.750449: Epoch time: 81.63 s 
2025-03-10 12:10:21.338514:  
2025-03-10 12:10:21.344103: Epoch 67 
2025-03-10 12:10:21.347658: Current learning rate: 0.00369 
2025-03-10 12:11:42.957379: train_loss -0.695 
2025-03-10 12:11:42.963400: val_loss -0.5649 
2025-03-10 12:11:42.966913: Pseudo dice [np.float32(0.7755), np.float32(0.4672)] 
2025-03-10 12:11:42.969926: Epoch time: 81.62 s 
2025-03-10 12:11:43.555204:  
2025-03-10 12:11:43.561223: Epoch 68 
2025-03-10 12:11:43.563729: Current learning rate: 0.00359 
2025-03-10 12:13:05.266758: train_loss -0.7069 
2025-03-10 12:13:05.273373: val_loss -0.5723 
2025-03-10 12:13:05.276884: Pseudo dice [np.float32(0.8018), np.float32(0.4659)] 
2025-03-10 12:13:05.280892: Epoch time: 81.71 s 
2025-03-10 12:13:06.057374:  
2025-03-10 12:13:06.062946: Epoch 69 
2025-03-10 12:13:06.067511: Current learning rate: 0.00349 
2025-03-10 12:14:27.725636: train_loss -0.7162 
2025-03-10 12:14:27.731662: val_loss -0.544 
2025-03-10 12:14:27.735694: Pseudo dice [np.float32(0.7896), np.float32(0.3549)] 
2025-03-10 12:14:27.738200: Epoch time: 81.67 s 
2025-03-10 12:14:28.333595:  
2025-03-10 12:14:28.339127: Epoch 70 
2025-03-10 12:14:28.345211: Current learning rate: 0.00338 
2025-03-10 12:15:49.921553: train_loss -0.7213 
2025-03-10 12:15:49.927212: val_loss -0.5696 
2025-03-10 12:15:49.931752: Pseudo dice [np.float32(0.7889), np.float32(0.4285)] 
2025-03-10 12:15:49.935261: Epoch time: 81.59 s 
2025-03-10 12:15:50.517124:  
2025-03-10 12:15:50.522637: Epoch 71 
2025-03-10 12:15:50.526151: Current learning rate: 0.00328 
2025-03-10 12:17:12.109186: train_loss -0.7025 
2025-03-10 12:17:12.116704: val_loss -0.5575 
2025-03-10 12:17:12.120712: Pseudo dice [np.float32(0.7913), np.float32(0.4644)] 
2025-03-10 12:17:12.124221: Epoch time: 81.59 s 
2025-03-10 12:17:12.699710:  
2025-03-10 12:17:12.705268: Epoch 72 
2025-03-10 12:17:12.709325: Current learning rate: 0.00318 
2025-03-10 12:18:34.372106: train_loss -0.7242 
2025-03-10 12:18:34.378125: val_loss -0.6018 
2025-03-10 12:18:34.381634: Pseudo dice [np.float32(0.7978), np.float32(0.4906)] 
2025-03-10 12:18:34.384645: Epoch time: 81.67 s 
2025-03-10 12:18:34.970166:  
2025-03-10 12:18:34.975753: Epoch 73 
2025-03-10 12:18:34.980934: Current learning rate: 0.00308 
2025-03-10 12:19:56.624902: train_loss -0.7306 
2025-03-10 12:19:56.631925: val_loss -0.5604 
2025-03-10 12:19:56.635940: Pseudo dice [np.float32(0.7936), np.float32(0.4646)] 
2025-03-10 12:19:56.639454: Epoch time: 81.66 s 
2025-03-10 12:19:56.642465: Yayy! New best EMA pseudo Dice: 0.6132000088691711 
2025-03-10 12:19:57.381844:  
2025-03-10 12:19:57.386856: Epoch 74 
2025-03-10 12:19:57.390367: Current learning rate: 0.00297 
2025-03-10 12:21:19.065694: train_loss -0.7363 
2025-03-10 12:21:19.072287: val_loss -0.5755 
2025-03-10 12:21:19.075834: Pseudo dice [np.float32(0.7954), np.float32(0.5227)] 
2025-03-10 12:21:19.079384: Epoch time: 81.68 s 
2025-03-10 12:21:19.082458: Yayy! New best EMA pseudo Dice: 0.6177999973297119 
2025-03-10 12:21:19.855086:  
2025-03-10 12:21:19.861665: Epoch 75 
2025-03-10 12:21:19.864758: Current learning rate: 0.00287 
2025-03-10 12:22:41.448412: train_loss -0.7196 
2025-03-10 12:22:41.453928: val_loss -0.6111 
2025-03-10 12:22:41.457437: Pseudo dice [np.float32(0.8077), np.float32(0.5056)] 
2025-03-10 12:22:41.460942: Epoch time: 81.59 s 
2025-03-10 12:22:41.463950: Yayy! New best EMA pseudo Dice: 0.6216999888420105 
2025-03-10 12:22:42.363156:  
2025-03-10 12:22:42.369222: Epoch 76 
2025-03-10 12:22:42.373275: Current learning rate: 0.00277 
2025-03-10 12:24:04.023552: train_loss -0.7153 
2025-03-10 12:24:04.031072: val_loss -0.6188 
2025-03-10 12:24:04.034583: Pseudo dice [np.float32(0.7978), np.float32(0.5304)] 
2025-03-10 12:24:04.037089: Epoch time: 81.66 s 
2025-03-10 12:24:04.041099: Yayy! New best EMA pseudo Dice: 0.6258999705314636 
2025-03-10 12:24:04.817479:  
2025-03-10 12:24:04.825529: Epoch 77 
2025-03-10 12:24:04.830686: Current learning rate: 0.00266 
2025-03-10 12:25:26.414349: train_loss -0.7302 
2025-03-10 12:25:26.421428: val_loss -0.6036 
2025-03-10 12:25:26.424459: Pseudo dice [np.float32(0.7822), np.float32(0.5483)] 
2025-03-10 12:25:26.427969: Epoch time: 81.6 s 
2025-03-10 12:25:26.431478: Yayy! New best EMA pseudo Dice: 0.6298999786376953 
2025-03-10 12:25:27.197526:  
2025-03-10 12:25:27.203151: Epoch 78 
2025-03-10 12:25:27.206698: Current learning rate: 0.00256 
2025-03-10 12:26:48.858153: train_loss -0.7473 
2025-03-10 12:26:48.864830: val_loss -0.6036 
2025-03-10 12:26:48.868953: Pseudo dice [np.float32(0.796), np.float32(0.5094)] 
2025-03-10 12:26:48.872531: Epoch time: 81.66 s 
2025-03-10 12:26:48.876064: Yayy! New best EMA pseudo Dice: 0.632099986076355 
2025-03-10 12:26:49.619823:  
2025-03-10 12:26:49.625839: Epoch 79 
2025-03-10 12:26:49.628345: Current learning rate: 0.00245 
2025-03-10 12:28:11.244942: train_loss -0.7475 
2025-03-10 12:28:11.251459: val_loss -0.5986 
2025-03-10 12:28:11.254968: Pseudo dice [np.float32(0.8007), np.float32(0.5114)] 
2025-03-10 12:28:11.258976: Epoch time: 81.63 s 
2025-03-10 12:28:11.261482: Yayy! New best EMA pseudo Dice: 0.6345000267028809 
2025-03-10 12:28:12.037216:  
2025-03-10 12:28:12.043262: Epoch 80 
2025-03-10 12:28:12.046787: Current learning rate: 0.00235 
2025-03-10 12:29:34.166709: train_loss -0.7573 
2025-03-10 12:29:34.172800: val_loss -0.5643 
2025-03-10 12:29:34.176312: Pseudo dice [np.float32(0.786), np.float32(0.4727)] 
2025-03-10 12:29:34.180329: Epoch time: 82.13 s 
2025-03-10 12:29:34.767337:  
2025-03-10 12:29:34.773852: Epoch 81 
2025-03-10 12:29:34.778362: Current learning rate: 0.00224 
2025-03-10 12:30:56.368552: train_loss -0.7484 
2025-03-10 12:30:56.374565: val_loss -0.6033 
2025-03-10 12:30:56.378089: Pseudo dice [np.float32(0.779), np.float32(0.5202)] 
2025-03-10 12:30:56.381124: Epoch time: 81.6 s 
2025-03-10 12:30:56.385135: Yayy! New best EMA pseudo Dice: 0.6355999708175659 
2025-03-10 12:30:57.148062:  
2025-03-10 12:30:57.153600: Epoch 82 
2025-03-10 12:30:57.157229: Current learning rate: 0.00214 
2025-03-10 12:32:18.724347: train_loss -0.7595 
2025-03-10 12:32:18.730365: val_loss -0.5462 
2025-03-10 12:32:18.734424: Pseudo dice [np.float32(0.7838), np.float32(0.4735)] 
2025-03-10 12:32:18.736871: Epoch time: 81.58 s 
2025-03-10 12:32:19.291633:  
2025-03-10 12:32:19.297645: Epoch 83 
2025-03-10 12:32:19.303163: Current learning rate: 0.00203 
2025-03-10 12:33:40.944513: train_loss -0.7533 
2025-03-10 12:33:40.951035: val_loss -0.5736 
2025-03-10 12:33:40.954544: Pseudo dice [np.float32(0.7986), np.float32(0.5135)] 
2025-03-10 12:33:40.958054: Epoch time: 81.65 s 
2025-03-10 12:33:40.961063: Yayy! New best EMA pseudo Dice: 0.6370000243186951 
2025-03-10 12:33:41.861110:  
2025-03-10 12:33:41.866673: Epoch 84 
2025-03-10 12:33:41.870693: Current learning rate: 0.00192 
2025-03-10 12:35:03.603957: train_loss -0.743 
2025-03-10 12:35:03.610978: val_loss -0.5714 
2025-03-10 12:35:03.613990: Pseudo dice [np.float32(0.7831), np.float32(0.4625)] 
2025-03-10 12:35:03.617505: Epoch time: 81.74 s 
2025-03-10 12:35:04.196418:  
2025-03-10 12:35:04.202510: Epoch 85 
2025-03-10 12:35:04.205588: Current learning rate: 0.00181 
2025-03-10 12:36:25.822727: train_loss -0.7703 
2025-03-10 12:36:25.828368: val_loss -0.5807 
2025-03-10 12:36:25.832940: Pseudo dice [np.float32(0.7997), np.float32(0.4644)] 
2025-03-10 12:36:25.836482: Epoch time: 81.63 s 
2025-03-10 12:36:26.393143:  
2025-03-10 12:36:26.398774: Epoch 86 
2025-03-10 12:36:26.402313: Current learning rate: 0.0017 
2025-03-10 12:37:48.120093: train_loss -0.7652 
2025-03-10 12:37:48.127110: val_loss -0.581 
2025-03-10 12:37:48.130121: Pseudo dice [np.float32(0.7871), np.float32(0.4857)] 
2025-03-10 12:37:48.134231: Epoch time: 81.73 s 
2025-03-10 12:37:48.679675:  
2025-03-10 12:37:48.685695: Epoch 87 
2025-03-10 12:37:48.688201: Current learning rate: 0.00159 
2025-03-10 12:39:10.290485: train_loss -0.766 
2025-03-10 12:39:10.299052: val_loss -0.6253 
2025-03-10 12:39:10.304086: Pseudo dice [np.float32(0.8055), np.float32(0.578)] 
2025-03-10 12:39:10.307607: Epoch time: 81.61 s 
2025-03-10 12:39:10.311132: Yayy! New best EMA pseudo Dice: 0.640999972820282 
2025-03-10 12:39:11.035366:  
2025-03-10 12:39:11.041423: Epoch 88 
2025-03-10 12:39:11.043961: Current learning rate: 0.00148 
2025-03-10 12:40:32.692811: train_loss -0.7514 
2025-03-10 12:40:32.699324: val_loss -0.6185 
2025-03-10 12:40:32.702833: Pseudo dice [np.float32(0.816), np.float32(0.5461)] 
2025-03-10 12:40:32.705338: Epoch time: 81.66 s 
2025-03-10 12:40:32.709348: Yayy! New best EMA pseudo Dice: 0.6449999809265137 
2025-03-10 12:40:33.442136:  
2025-03-10 12:40:33.447695: Epoch 89 
2025-03-10 12:40:33.452237: Current learning rate: 0.00137 
2025-03-10 12:41:55.143593: train_loss -0.7632 
2025-03-10 12:41:55.150607: val_loss -0.5925 
2025-03-10 12:41:55.156123: Pseudo dice [np.float32(0.7827), np.float32(0.5317)] 
2025-03-10 12:41:55.161137: Epoch time: 81.7 s 
2025-03-10 12:41:55.164646: Yayy! New best EMA pseudo Dice: 0.6462000012397766 
2025-03-10 12:41:55.912308:  
2025-03-10 12:41:55.918923: Epoch 90 
2025-03-10 12:41:55.921947: Current learning rate: 0.00126 
2025-03-10 12:43:17.639938: train_loss -0.7528 
2025-03-10 12:43:17.645955: val_loss -0.6174 
2025-03-10 12:43:17.649967: Pseudo dice [np.float32(0.8024), np.float32(0.5287)] 
2025-03-10 12:43:17.653477: Epoch time: 81.73 s 
2025-03-10 12:43:17.656984: Yayy! New best EMA pseudo Dice: 0.6481000185012817 
2025-03-10 12:43:18.380418:  
2025-03-10 12:43:18.384952: Epoch 91 
2025-03-10 12:43:18.388516: Current learning rate: 0.00115 
2025-03-10 12:44:40.006673: train_loss -0.7689 
2025-03-10 12:44:40.013188: val_loss -0.6057 
2025-03-10 12:44:40.016698: Pseudo dice [np.float32(0.7975), np.float32(0.5045)] 
2025-03-10 12:44:40.020707: Epoch time: 81.63 s 
2025-03-10 12:44:40.023213: Yayy! New best EMA pseudo Dice: 0.6484000086784363 
2025-03-10 12:44:40.745336:  
2025-03-10 12:44:40.750890: Epoch 92 
2025-03-10 12:44:40.755510: Current learning rate: 0.00103 
2025-03-10 12:46:02.349519: train_loss -0.772 
2025-03-10 12:46:02.355613: val_loss -0.5673 
2025-03-10 12:46:02.359140: Pseudo dice [np.float32(0.7906), np.float32(0.415)] 
2025-03-10 12:46:02.363166: Epoch time: 81.6 s 
2025-03-10 12:46:03.075567:  
2025-03-10 12:46:03.081082: Epoch 93 
2025-03-10 12:46:03.084592: Current learning rate: 0.00091 
2025-03-10 12:47:24.733560: train_loss -0.7889 
2025-03-10 12:47:24.739579: val_loss -0.5797 
2025-03-10 12:47:24.743591: Pseudo dice [np.float32(0.7958), np.float32(0.4642)] 
2025-03-10 12:47:24.748103: Epoch time: 81.66 s 
2025-03-10 12:47:25.295754:  
2025-03-10 12:47:25.301770: Epoch 94 
2025-03-10 12:47:25.305280: Current learning rate: 0.00079 
2025-03-10 12:48:46.942546: train_loss -0.7782 
2025-03-10 12:48:46.949069: val_loss -0.5571 
2025-03-10 12:48:46.952573: Pseudo dice [np.float32(0.7923), np.float32(0.4559)] 
2025-03-10 12:48:46.955580: Epoch time: 81.65 s 
2025-03-10 12:48:47.510786:  
2025-03-10 12:48:47.517374: Epoch 95 
2025-03-10 12:48:47.519912: Current learning rate: 0.00067 
2025-03-10 12:50:09.250554: train_loss -0.7713 
2025-03-10 12:50:09.257083: val_loss -0.5985 
2025-03-10 12:50:09.260737: Pseudo dice [np.float32(0.7892), np.float32(0.4559)] 
2025-03-10 12:50:09.264816: Epoch time: 81.74 s 
2025-03-10 12:50:09.821811:  
2025-03-10 12:50:09.827381: Epoch 96 
2025-03-10 12:50:09.831954: Current learning rate: 0.00055 
2025-03-10 12:51:31.454700: train_loss -0.7857 
2025-03-10 12:51:31.461282: val_loss -0.5862 
2025-03-10 12:51:31.464839: Pseudo dice [np.float32(0.7882), np.float32(0.4429)] 
2025-03-10 12:51:31.467391: Epoch time: 81.63 s 
2025-03-10 12:51:32.035717:  
2025-03-10 12:51:32.040659: Epoch 97 
2025-03-10 12:51:32.044168: Current learning rate: 0.00043 
2025-03-10 12:52:53.655843: train_loss -0.7842 
2025-03-10 12:52:53.663370: val_loss -0.6164 
2025-03-10 12:52:53.667384: Pseudo dice [np.float32(0.8142), np.float32(0.5431)] 
2025-03-10 12:52:53.670899: Epoch time: 81.62 s 
2025-03-10 12:52:54.226461:  
2025-03-10 12:52:54.232525: Epoch 98 
2025-03-10 12:52:54.236040: Current learning rate: 0.0003 
2025-03-10 12:54:15.831400: train_loss -0.7828 
2025-03-10 12:54:15.837916: val_loss -0.5814 
2025-03-10 12:54:15.841428: Pseudo dice [np.float32(0.806), np.float32(0.4442)] 
2025-03-10 12:54:15.844460: Epoch time: 81.6 s 
2025-03-10 12:54:16.415705:  
2025-03-10 12:54:16.420731: Epoch 99 
2025-03-10 12:54:16.424263: Current learning rate: 0.00016 
2025-03-10 12:55:38.008908: train_loss -0.778 
2025-03-10 12:55:38.015427: val_loss -0.6286 
2025-03-10 12:55:38.019439: Pseudo dice [np.float32(0.8098), np.float32(0.5581)] 
2025-03-10 12:55:38.022950: Epoch time: 81.59 s 
2025-03-10 12:55:38.790020: Training done. 
2025-03-10 12:55:38.816532: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-03-10 12:55:38.822531: The split file contains 5 splits. 
2025-03-10 12:55:38.828533: Desired fold for training: 0 
2025-03-10 12:55:38.832534: This split has 224 training and 57 validation cases. 
2025-03-10 12:55:38.837533: predicting pancreas_021 
2025-03-10 12:55:38.843534: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-03-10 12:55:51.570709: predicting pancreas_024 
2025-03-10 12:55:51.588709: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-03-10 12:56:06.611475: predicting pancreas_035 
2025-03-10 12:56:06.630985: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-03-10 12:56:11.751997: predicting pancreas_040 
2025-03-10 12:56:11.765998: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-03-10 12:56:23.775591: predicting pancreas_042 
2025-03-10 12:56:23.792592: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-03-10 12:56:38.808337: predicting pancreas_056 
2025-03-10 12:56:38.827339: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-03-10 12:56:50.882479: predicting pancreas_067 
2025-03-10 12:56:50.897479: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-03-10 12:57:05.937086: predicting pancreas_075 
2025-03-10 12:57:05.959592: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-03-10 12:57:12.009993: predicting pancreas_086 
2025-03-10 12:57:12.024992: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-03-10 12:57:21.406265: predicting pancreas_089 
2025-03-10 12:57:21.421268: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-03-10 12:57:33.474809: predicting pancreas_092 
2025-03-10 12:57:33.493808: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-03-10 12:58:00.497578: predicting pancreas_094 
2025-03-10 12:58:00.524578: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-03-10 12:58:12.552159: predicting pancreas_095 
2025-03-10 12:58:12.566158: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-03-10 12:58:24.630495: predicting pancreas_098 
2025-03-10 12:58:24.647497: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-03-10 12:58:57.427457: predicting pancreas_109 
2025-03-10 12:58:57.454458: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-03-10 12:59:09.519242: predicting pancreas_110 
2025-03-10 12:59:09.539749: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-03-10 12:59:28.335946: predicting pancreas_114 
2025-03-10 12:59:28.356989: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-03-10 12:59:40.431165: predicting pancreas_119 
2025-03-10 12:59:40.448168: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-03-10 12:59:59.190557: predicting pancreas_138 
2025-03-10 12:59:59.211556: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-03-10 13:00:17.986546: predicting pancreas_145 
2025-03-10 13:00:18.011549: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-03-10 13:00:36.832126: predicting pancreas_148 
2025-03-10 13:00:36.851126: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-03-10 13:00:48.913756: predicting pancreas_169 
2025-03-10 13:00:48.929757: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-03-10 13:01:01.015332: predicting pancreas_170 
2025-03-10 13:01:01.030332: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-03-10 13:01:16.044468: predicting pancreas_172 
2025-03-10 13:01:16.067468: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-03-10 13:01:28.122932: predicting pancreas_175 
2025-03-10 13:01:28.138439: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-03-10 13:01:40.199419: predicting pancreas_180 
2025-03-10 13:01:40.216421: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-03-10 13:01:52.288857: predicting pancreas_191 
2025-03-10 13:01:52.303857: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-03-10 13:01:58.380905: predicting pancreas_193 
2025-03-10 13:01:58.394905: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-03-10 13:02:13.411778: predicting pancreas_212 
2025-03-10 13:02:13.429778: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-03-10 13:02:25.544720: predicting pancreas_215 
2025-03-10 13:02:25.565726: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-03-10 13:02:37.608251: predicting pancreas_222 
2025-03-10 13:02:37.625250: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-03-10 13:02:42.747100: predicting pancreas_235 
2025-03-10 13:02:42.761100: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-03-10 13:02:54.791053: predicting pancreas_241 
2025-03-10 13:02:54.807053: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-03-10 13:03:06.835611: predicting pancreas_242 
2025-03-10 13:03:06.855611: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-03-10 13:03:21.915976: predicting pancreas_244 
2025-03-10 13:03:21.935975: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-03-10 13:03:45.381378: predicting pancreas_246 
2025-03-10 13:03:45.406377: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-03-10 13:04:08.872493: predicting pancreas_247 
2025-03-10 13:04:08.892493: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-03-10 13:04:15.716290: predicting pancreas_264 
2025-03-10 13:04:15.733291: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-03-10 13:04:30.780058: predicting pancreas_265 
2025-03-10 13:04:30.801058: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-03-10 13:04:42.856097: predicting pancreas_266 
2025-03-10 13:04:42.872608: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-03-10 13:05:01.618648: predicting pancreas_267 
2025-03-10 13:05:01.642648: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-03-10 13:05:08.497055: predicting pancreas_275 
2025-03-10 13:05:08.514055: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-03-10 13:05:23.514995: predicting pancreas_279 
2025-03-10 13:05:23.535995: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-03-10 13:05:28.671530: predicting pancreas_287 
2025-03-10 13:05:28.689534: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-03-10 13:05:40.745469: predicting pancreas_301 
2025-03-10 13:05:40.762469: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-03-10 13:05:52.825084: predicting pancreas_323 
2025-03-10 13:05:52.842085: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-03-10 13:06:11.654823: predicting pancreas_336 
2025-03-10 13:06:11.675822: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-03-10 13:06:23.745217: predicting pancreas_344 
2025-03-10 13:06:23.767217: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-03-10 13:06:38.818422: predicting pancreas_351 
2025-03-10 13:06:38.837424: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-03-10 13:06:45.669173: predicting pancreas_354 
2025-03-10 13:06:45.685173: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-03-10 13:07:09.725176: predicting pancreas_372 
2025-03-10 13:07:09.750176: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-03-10 13:07:28.589544: predicting pancreas_377 
2025-03-10 13:07:28.614543: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-03-10 13:07:43.684917: predicting pancreas_387 
2025-03-10 13:07:43.705985: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-03-10 13:07:55.738508: predicting pancreas_391 
2025-03-10 13:07:55.757508: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-03-10 13:08:14.557933: predicting pancreas_392 
2025-03-10 13:08:14.580933: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-03-10 13:08:23.098103: predicting pancreas_410 
2025-03-10 13:08:23.114106: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-03-10 13:08:31.613415: predicting pancreas_412 
2025-03-10 13:08:31.629419: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-03-10 13:09:32.282047: Validation complete 
2025-03-10 13:09:32.291046: Mean Validation Dice:  0.29509653685980763 
