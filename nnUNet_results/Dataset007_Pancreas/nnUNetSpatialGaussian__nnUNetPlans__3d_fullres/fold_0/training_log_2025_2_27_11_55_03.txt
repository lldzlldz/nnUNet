
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-02-27 11:55:03.312723: do_dummy_2d_data_aug: True 
2025-02-27 11:55:03.333079: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-02-27 11:55:03.340886: The split file contains 5 splits. 
2025-02-27 11:55:03.343886: Desired fold for training: 0 
2025-02-27 11:55:03.346884: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-02-27 11:55:13.643979: unpacking dataset... 
2025-02-27 11:55:34.245126: unpacking done... 
2025-02-27 11:55:38.483845:  
2025-02-27 11:55:38.488356: Epoch 0 
2025-02-27 11:55:38.491365: Current learning rate: 0.01 
2025-02-27 11:57:09.887114: train_loss 0.0934 
2025-02-27 11:57:09.892675: val_loss 0.032 
2025-02-27 11:57:09.897216: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-02-27 11:57:09.900727: Epoch time: 91.4 s 
2025-02-27 11:57:09.904233: Yayy! New best EMA pseudo Dice: 0.0 
2025-02-27 11:57:10.585218:  
2025-02-27 11:57:10.590736: Epoch 1 
2025-02-27 11:57:10.593243: Current learning rate: 0.00991 
2025-02-27 11:58:33.154900: train_loss -0.0127 
2025-02-27 11:58:33.161421: val_loss -0.123 
2025-02-27 11:58:33.164927: Pseudo dice [np.float32(0.2396), np.float32(0.0)] 
2025-02-27 11:58:33.167936: Epoch time: 82.57 s 
2025-02-27 11:58:33.171446: Yayy! New best EMA pseudo Dice: 0.012000000104308128 
2025-02-27 11:58:33.896621:  
2025-02-27 11:58:33.902178: Epoch 2 
2025-02-27 11:58:33.905691: Current learning rate: 0.00982 
2025-02-27 11:59:56.529274: train_loss -0.1502 
2025-02-27 11:59:56.535834: val_loss -0.2414 
2025-02-27 11:59:56.539371: Pseudo dice [np.float32(0.5884), np.float32(0.0)] 
2025-02-27 11:59:56.543402: Epoch time: 82.63 s 
2025-02-27 11:59:56.546427: Yayy! New best EMA pseudo Dice: 0.04019999876618385 
2025-02-27 11:59:57.311099:  
2025-02-27 11:59:57.316644: Epoch 3 
2025-02-27 11:59:57.320194: Current learning rate: 0.00973 
2025-02-27 12:01:19.941207: train_loss -0.2145 
2025-02-27 12:01:19.947726: val_loss -0.3054 
2025-02-27 12:01:19.951237: Pseudo dice [np.float32(0.6596), np.float32(0.0)] 
2025-02-27 12:01:19.954744: Epoch time: 82.63 s 
2025-02-27 12:01:19.957867: Yayy! New best EMA pseudo Dice: 0.06920000165700912 
2025-02-27 12:01:20.709802:  
2025-02-27 12:01:20.714814: Epoch 4 
2025-02-27 12:01:20.718323: Current learning rate: 0.00964 
2025-02-27 12:02:43.308211: train_loss -0.2586 
2025-02-27 12:02:43.314229: val_loss -0.315 
2025-02-27 12:02:43.317735: Pseudo dice [np.float32(0.6627), np.float32(0.0)] 
2025-02-27 12:02:43.320743: Epoch time: 82.6 s 
2025-02-27 12:02:43.324257: Yayy! New best EMA pseudo Dice: 0.09539999812841415 
2025-02-27 12:02:44.217120:  
2025-02-27 12:02:44.222152: Epoch 5 
2025-02-27 12:02:44.225795: Current learning rate: 0.00955 
2025-02-27 12:04:06.771038: train_loss -0.3126 
2025-02-27 12:04:06.777070: val_loss -0.3954 
2025-02-27 12:04:06.780573: Pseudo dice [np.float32(0.6456), np.float32(0.2716)] 
2025-02-27 12:04:06.783592: Epoch time: 82.55 s 
2025-02-27 12:04:06.786102: Yayy! New best EMA pseudo Dice: 0.13169999420642853 
2025-02-27 12:04:07.498812:  
2025-02-27 12:04:07.504845: Epoch 6 
2025-02-27 12:04:07.507356: Current learning rate: 0.00946 
2025-02-27 12:05:30.083245: train_loss -0.3329 
2025-02-27 12:05:30.090396: val_loss -0.3652 
2025-02-27 12:05:30.092934: Pseudo dice [np.float32(0.6113), np.float32(0.2949)] 
2025-02-27 12:05:30.095971: Epoch time: 82.58 s 
2025-02-27 12:05:30.099506: Yayy! New best EMA pseudo Dice: 0.16380000114440918 
2025-02-27 12:05:30.840283:  
2025-02-27 12:05:30.846406: Epoch 7 
2025-02-27 12:05:30.849920: Current learning rate: 0.00937 
2025-02-27 12:06:53.409929: train_loss -0.349 
2025-02-27 12:06:53.418985: val_loss -0.3968 
2025-02-27 12:06:53.422500: Pseudo dice [np.float32(0.6212), np.float32(0.3035)] 
2025-02-27 12:06:53.426003: Epoch time: 82.57 s 
2025-02-27 12:06:53.429013: Yayy! New best EMA pseudo Dice: 0.19370000064373016 
2025-02-27 12:06:54.161328:  
2025-02-27 12:06:54.165378: Epoch 8 
2025-02-27 12:06:54.167930: Current learning rate: 0.00928 
2025-02-27 12:08:16.759248: train_loss -0.4015 
2025-02-27 12:08:16.765773: val_loss -0.4316 
2025-02-27 12:08:16.769292: Pseudo dice [np.float32(0.687), np.float32(0.258)] 
2025-02-27 12:08:16.771800: Epoch time: 82.6 s 
2025-02-27 12:08:16.775811: Yayy! New best EMA pseudo Dice: 0.2215999960899353 
2025-02-27 12:08:17.545676:  
2025-02-27 12:08:17.550780: Epoch 9 
2025-02-27 12:08:17.554450: Current learning rate: 0.00919 
2025-02-27 12:09:40.148932: train_loss -0.401 
2025-02-27 12:09:40.157456: val_loss -0.4532 
2025-02-27 12:09:40.161466: Pseudo dice [np.float32(0.6967), np.float32(0.3723)] 
2025-02-27 12:09:40.164975: Epoch time: 82.6 s 
2025-02-27 12:09:40.167483: Yayy! New best EMA pseudo Dice: 0.25290000438690186 
2025-02-27 12:09:40.894382:  
2025-02-27 12:09:40.899942: Epoch 10 
2025-02-27 12:09:40.903485: Current learning rate: 0.0091 
2025-02-27 12:11:03.466116: train_loss -0.4234 
2025-02-27 12:11:03.472641: val_loss -0.4413 
2025-02-27 12:11:03.476661: Pseudo dice [np.float32(0.6775), np.float32(0.3017)] 
2025-02-27 12:11:03.479167: Epoch time: 82.57 s 
2025-02-27 12:11:03.482676: Yayy! New best EMA pseudo Dice: 0.27649998664855957 
2025-02-27 12:11:04.229528:  
2025-02-27 12:11:04.235650: Epoch 11 
2025-02-27 12:11:04.237674: Current learning rate: 0.009 
2025-02-27 12:12:26.847087: train_loss -0.4261 
2025-02-27 12:12:26.855608: val_loss -0.4899 
2025-02-27 12:12:26.859618: Pseudo dice [np.float32(0.7128), np.float32(0.3962)] 
2025-02-27 12:12:26.863130: Epoch time: 82.62 s 
2025-02-27 12:12:26.866639: Yayy! New best EMA pseudo Dice: 0.3043000102043152 
2025-02-27 12:12:27.586555:  
2025-02-27 12:12:27.592661: Epoch 12 
2025-02-27 12:12:27.595703: Current learning rate: 0.00891 
2025-02-27 12:13:50.196480: train_loss -0.4135 
2025-02-27 12:13:50.201639: val_loss -0.4438 
2025-02-27 12:13:50.205721: Pseudo dice [np.float32(0.6761), np.float32(0.3349)] 
2025-02-27 12:13:50.209282: Epoch time: 82.61 s 
2025-02-27 12:13:50.211802: Yayy! New best EMA pseudo Dice: 0.3244999945163727 
2025-02-27 12:13:51.123672:  
2025-02-27 12:13:51.129247: Epoch 13 
2025-02-27 12:13:51.132847: Current learning rate: 0.00882 
2025-02-27 12:15:13.748492: train_loss -0.4811 
2025-02-27 12:15:13.755005: val_loss -0.4846 
2025-02-27 12:15:13.758515: Pseudo dice [np.float32(0.7216), np.float32(0.3808)] 
2025-02-27 12:15:13.762525: Epoch time: 82.63 s 
2025-02-27 12:15:13.765032: Yayy! New best EMA pseudo Dice: 0.34709998965263367 
2025-02-27 12:15:14.514251:  
2025-02-27 12:15:14.520430: Epoch 14 
2025-02-27 12:15:14.523968: Current learning rate: 0.00873 
2025-02-27 12:16:37.086042: train_loss -0.465 
2025-02-27 12:16:37.092562: val_loss -0.5014 
2025-02-27 12:16:37.096069: Pseudo dice [np.float32(0.7054), np.float32(0.422)] 
2025-02-27 12:16:37.099082: Epoch time: 82.57 s 
2025-02-27 12:16:37.102591: Yayy! New best EMA pseudo Dice: 0.36880001425743103 
2025-02-27 12:16:37.838430:  
2025-02-27 12:16:37.843997: Epoch 15 
2025-02-27 12:16:37.846548: Current learning rate: 0.00864 
2025-02-27 12:18:00.428023: train_loss -0.4871 
2025-02-27 12:18:00.435582: val_loss -0.4881 
2025-02-27 12:18:00.438092: Pseudo dice [np.float32(0.7332), np.float32(0.3756)] 
2025-02-27 12:18:00.442103: Epoch time: 82.59 s 
2025-02-27 12:18:00.445616: Yayy! New best EMA pseudo Dice: 0.3873000144958496 
2025-02-27 12:18:01.208815:  
2025-02-27 12:18:01.214331: Epoch 16 
2025-02-27 12:18:01.217841: Current learning rate: 0.00855 
2025-02-27 12:19:23.787082: train_loss -0.4942 
2025-02-27 12:19:23.793604: val_loss -0.4743 
2025-02-27 12:19:23.797114: Pseudo dice [np.float32(0.7334), np.float32(0.3172)] 
2025-02-27 12:19:23.801123: Epoch time: 82.58 s 
2025-02-27 12:19:23.803629: Yayy! New best EMA pseudo Dice: 0.4011000096797943 
2025-02-27 12:19:24.559043:  
2025-02-27 12:19:24.565083: Epoch 17 
2025-02-27 12:19:24.568126: Current learning rate: 0.00846 
2025-02-27 12:20:47.118501: train_loss -0.5189 
2025-02-27 12:20:47.124159: val_loss -0.5109 
2025-02-27 12:20:47.127216: Pseudo dice [np.float32(0.7284), np.float32(0.4199)] 
2025-02-27 12:20:47.130271: Epoch time: 82.56 s 
2025-02-27 12:20:47.132895: Yayy! New best EMA pseudo Dice: 0.41839998960494995 
2025-02-27 12:20:47.923175:  
2025-02-27 12:20:47.929312: Epoch 18 
2025-02-27 12:20:47.931833: Current learning rate: 0.00836 
2025-02-27 12:22:10.536494: train_loss -0.5306 
2025-02-27 12:22:10.543541: val_loss -0.4806 
2025-02-27 12:22:10.546570: Pseudo dice [np.float32(0.7208), np.float32(0.3638)] 
2025-02-27 12:22:10.550083: Epoch time: 82.61 s 
2025-02-27 12:22:10.553589: Yayy! New best EMA pseudo Dice: 0.4307999908924103 
2025-02-27 12:22:11.305869:  
2025-02-27 12:22:11.311430: Epoch 19 
2025-02-27 12:22:11.314964: Current learning rate: 0.00827 
2025-02-27 12:23:33.912680: train_loss -0.4886 
2025-02-27 12:23:33.919195: val_loss -0.4895 
2025-02-27 12:23:33.922706: Pseudo dice [np.float32(0.7092), np.float32(0.3823)] 
2025-02-27 12:23:33.926216: Epoch time: 82.61 s 
2025-02-27 12:23:33.929228: Yayy! New best EMA pseudo Dice: 0.4422999918460846 
2025-02-27 12:23:34.825765:  
2025-02-27 12:23:34.831282: Epoch 20 
2025-02-27 12:23:34.835791: Current learning rate: 0.00818 
2025-02-27 12:24:57.379987: train_loss -0.5131 
2025-02-27 12:24:57.386505: val_loss -0.5205 
2025-02-27 12:24:57.390514: Pseudo dice [np.float32(0.7523), np.float32(0.4051)] 
2025-02-27 12:24:57.393632: Epoch time: 82.56 s 
2025-02-27 12:24:57.397163: Yayy! New best EMA pseudo Dice: 0.4560000002384186 
2025-02-27 12:24:58.161049:  
2025-02-27 12:24:58.167111: Epoch 21 
2025-02-27 12:24:58.170639: Current learning rate: 0.00809 
2025-02-27 12:26:20.798573: train_loss -0.5811 
2025-02-27 12:26:20.804193: val_loss -0.516 
2025-02-27 12:26:20.808818: Pseudo dice [np.float32(0.7514), np.float32(0.3816)] 
2025-02-27 12:26:20.812392: Epoch time: 82.64 s 
2025-02-27 12:26:20.815954: Yayy! New best EMA pseudo Dice: 0.46700000762939453 
2025-02-27 12:26:21.534599:  
2025-02-27 12:26:21.541200: Epoch 22 
2025-02-27 12:26:21.544753: Current learning rate: 0.008 
2025-02-27 12:27:44.153175: train_loss -0.5461 
2025-02-27 12:27:44.160694: val_loss -0.5134 
2025-02-27 12:27:44.164206: Pseudo dice [np.float32(0.7377), np.float32(0.3658)] 
2025-02-27 12:27:44.167713: Epoch time: 82.62 s 
2025-02-27 12:27:44.170722: Yayy! New best EMA pseudo Dice: 0.4754999876022339 
2025-02-27 12:27:44.917382:  
2025-02-27 12:27:44.922437: Epoch 23 
2025-02-27 12:27:44.927013: Current learning rate: 0.0079 
2025-02-27 12:29:07.879020: train_loss -0.5718 
2025-02-27 12:29:07.884551: val_loss -0.5286 
2025-02-27 12:29:07.888583: Pseudo dice [np.float32(0.759), np.float32(0.3679)] 
2025-02-27 12:29:07.891594: Epoch time: 82.96 s 
2025-02-27 12:29:07.895104: Yayy! New best EMA pseudo Dice: 0.48429998755455017 
2025-02-27 12:29:08.627129:  
2025-02-27 12:29:08.633418: Epoch 24 
2025-02-27 12:29:08.636479: Current learning rate: 0.00781 
2025-02-27 12:30:31.350284: train_loss -0.5784 
2025-02-27 12:30:31.357810: val_loss -0.5526 
2025-02-27 12:30:31.361820: Pseudo dice [np.float32(0.7549), np.float32(0.4581)] 
2025-02-27 12:30:31.365329: Epoch time: 82.72 s 
2025-02-27 12:30:31.368834: Yayy! New best EMA pseudo Dice: 0.4964999854564667 
2025-02-27 12:30:32.110053:  
2025-02-27 12:30:32.115626: Epoch 25 
2025-02-27 12:30:32.119679: Current learning rate: 0.00772 
2025-02-27 12:31:54.744485: train_loss -0.5695 
2025-02-27 12:31:54.751007: val_loss -0.5659 
2025-02-27 12:31:54.755021: Pseudo dice [np.float32(0.748), np.float32(0.4971)] 
2025-02-27 12:31:54.758534: Epoch time: 82.63 s 
2025-02-27 12:31:54.763550: Yayy! New best EMA pseudo Dice: 0.5091000199317932 
2025-02-27 12:31:55.488523:  
2025-02-27 12:31:55.493536: Epoch 26 
2025-02-27 12:31:55.497046: Current learning rate: 0.00763 
2025-02-27 12:33:18.086279: train_loss -0.5813 
2025-02-27 12:33:18.092798: val_loss -0.5396 
2025-02-27 12:33:18.096810: Pseudo dice [np.float32(0.7545), np.float32(0.3898)] 
2025-02-27 12:33:18.100320: Epoch time: 82.6 s 
2025-02-27 12:33:18.103851: Yayy! New best EMA pseudo Dice: 0.5153999924659729 
2025-02-27 12:33:18.874235:  
2025-02-27 12:33:18.880371: Epoch 27 
2025-02-27 12:33:18.883464: Current learning rate: 0.00753 
2025-02-27 12:34:41.440694: train_loss -0.5906 
2025-02-27 12:34:41.448225: val_loss -0.5565 
2025-02-27 12:34:41.451737: Pseudo dice [np.float32(0.7657), np.float32(0.441)] 
2025-02-27 12:34:41.455747: Epoch time: 82.57 s 
2025-02-27 12:34:41.459258: Yayy! New best EMA pseudo Dice: 0.5242000222206116 
2025-02-27 12:34:42.348838:  
2025-02-27 12:34:42.354354: Epoch 28 
2025-02-27 12:34:42.357863: Current learning rate: 0.00744 
2025-02-27 12:36:04.928790: train_loss -0.5838 
2025-02-27 12:36:04.936312: val_loss -0.5142 
2025-02-27 12:36:04.940320: Pseudo dice [np.float32(0.739), np.float32(0.3489)] 
2025-02-27 12:36:04.943830: Epoch time: 82.58 s 
2025-02-27 12:36:04.947842: Yayy! New best EMA pseudo Dice: 0.526199996471405 
2025-02-27 12:36:05.705957:  
2025-02-27 12:36:05.711977: Epoch 29 
2025-02-27 12:36:05.715480: Current learning rate: 0.00735 
2025-02-27 12:37:28.281175: train_loss -0.6049 
2025-02-27 12:37:28.288696: val_loss -0.5437 
2025-02-27 12:37:28.292708: Pseudo dice [np.float32(0.7578), np.float32(0.4456)] 
2025-02-27 12:37:28.295748: Epoch time: 82.58 s 
2025-02-27 12:37:28.299889: Yayy! New best EMA pseudo Dice: 0.5336999893188477 
2025-02-27 12:37:29.032560:  
2025-02-27 12:37:29.038577: Epoch 30 
2025-02-27 12:37:29.042082: Current learning rate: 0.00725 
2025-02-27 12:38:51.671159: train_loss -0.5984 
2025-02-27 12:38:51.677187: val_loss -0.5152 
2025-02-27 12:38:51.681195: Pseudo dice [np.float32(0.7483), np.float32(0.36)] 
2025-02-27 12:38:51.684704: Epoch time: 82.64 s 
2025-02-27 12:38:51.688715: Yayy! New best EMA pseudo Dice: 0.5357999801635742 
2025-02-27 12:38:52.492891:  
2025-02-27 12:38:52.498915: Epoch 31 
2025-02-27 12:38:52.502421: Current learning rate: 0.00716 
2025-02-27 12:40:15.256148: train_loss -0.5939 
2025-02-27 12:40:15.262667: val_loss -0.539 
2025-02-27 12:40:15.266676: Pseudo dice [np.float32(0.7628), np.float32(0.4032)] 
2025-02-27 12:40:15.270185: Epoch time: 82.76 s 
2025-02-27 12:40:15.274196: Yayy! New best EMA pseudo Dice: 0.5404999852180481 
2025-02-27 12:40:16.027439:  
2025-02-27 12:40:16.033534: Epoch 32 
2025-02-27 12:40:16.036595: Current learning rate: 0.00707 
2025-02-27 12:41:38.681478: train_loss -0.6193 
2025-02-27 12:41:38.687993: val_loss -0.5292 
2025-02-27 12:41:38.692509: Pseudo dice [np.float32(0.7708), np.float32(0.3964)] 
2025-02-27 12:41:38.695520: Epoch time: 82.66 s 
2025-02-27 12:41:38.699029: Yayy! New best EMA pseudo Dice: 0.5447999835014343 
2025-02-27 12:41:39.450221:  
2025-02-27 12:41:39.455287: Epoch 33 
2025-02-27 12:41:39.460378: Current learning rate: 0.00697 
2025-02-27 12:43:02.058147: train_loss -0.5836 
2025-02-27 12:43:02.064663: val_loss -0.5515 
2025-02-27 12:43:02.068174: Pseudo dice [np.float32(0.7565), np.float32(0.443)] 
2025-02-27 12:43:02.072182: Epoch time: 82.61 s 
2025-02-27 12:43:02.075693: Yayy! New best EMA pseudo Dice: 0.5503000020980835 
2025-02-27 12:43:02.836093:  
2025-02-27 12:43:02.842744: Epoch 34 
2025-02-27 12:43:02.846268: Current learning rate: 0.00688 
2025-02-27 12:44:25.478577: train_loss -0.6096 
2025-02-27 12:44:25.485101: val_loss -0.5367 
2025-02-27 12:44:25.489704: Pseudo dice [np.float32(0.7604), np.float32(0.3357)] 
2025-02-27 12:44:25.493236: Epoch time: 82.64 s 
2025-02-27 12:44:26.243420:  
2025-02-27 12:44:26.249305: Epoch 35 
2025-02-27 12:44:26.253318: Current learning rate: 0.00679 
2025-02-27 12:45:48.856423: train_loss -0.6318 
2025-02-27 12:45:48.863943: val_loss -0.5555 
2025-02-27 12:45:48.867452: Pseudo dice [np.float32(0.7752), np.float32(0.3972)] 
2025-02-27 12:45:48.870981: Epoch time: 82.61 s 
2025-02-27 12:45:48.874015: Yayy! New best EMA pseudo Dice: 0.5536999702453613 
2025-02-27 12:45:49.607393:  
2025-02-27 12:45:49.612957: Epoch 36 
2025-02-27 12:45:49.617531: Current learning rate: 0.00669 
2025-02-27 12:47:12.185409: train_loss -0.5879 
2025-02-27 12:47:12.191436: val_loss -0.502 
2025-02-27 12:47:12.195444: Pseudo dice [np.float32(0.7509), np.float32(0.3571)] 
2025-02-27 12:47:12.198953: Epoch time: 82.58 s 
2025-02-27 12:47:12.202963: Yayy! New best EMA pseudo Dice: 0.5536999702453613 
2025-02-27 12:47:12.968147:  
2025-02-27 12:47:12.973741: Epoch 37 
2025-02-27 12:47:12.978845: Current learning rate: 0.0066 
2025-02-27 12:48:35.565537: train_loss -0.6308 
2025-02-27 12:48:35.574059: val_loss -0.5639 
2025-02-27 12:48:35.579072: Pseudo dice [np.float32(0.7736), np.float32(0.4196)] 
2025-02-27 12:48:35.582578: Epoch time: 82.6 s 
2025-02-27 12:48:35.585586: Yayy! New best EMA pseudo Dice: 0.5580000281333923 
2025-02-27 12:48:36.336213:  
2025-02-27 12:48:36.341765: Epoch 38 
2025-02-27 12:48:36.345784: Current learning rate: 0.0065 
2025-02-27 12:49:58.975497: train_loss -0.619 
2025-02-27 12:49:58.983017: val_loss -0.5312 
2025-02-27 12:49:58.986526: Pseudo dice [np.float32(0.7747), np.float32(0.3877)] 
2025-02-27 12:49:58.990537: Epoch time: 82.64 s 
2025-02-27 12:49:58.995149: Yayy! New best EMA pseudo Dice: 0.5602999925613403 
2025-02-27 12:49:59.757881:  
2025-02-27 12:49:59.764469: Epoch 39 
2025-02-27 12:49:59.768071: Current learning rate: 0.00641 
2025-02-27 12:51:22.340799: train_loss -0.6371 
2025-02-27 12:51:22.347885: val_loss -0.561 
2025-02-27 12:51:22.351448: Pseudo dice [np.float32(0.7782), np.float32(0.4743)] 
2025-02-27 12:51:22.355482: Epoch time: 82.58 s 
2025-02-27 12:51:22.359052: Yayy! New best EMA pseudo Dice: 0.5669000148773193 
2025-02-27 12:51:23.126036:  
2025-02-27 12:51:23.132056: Epoch 40 
2025-02-27 12:51:23.135565: Current learning rate: 0.00631 
2025-02-27 12:52:45.757733: train_loss -0.6324 
2025-02-27 12:52:45.765251: val_loss -0.5776 
2025-02-27 12:52:45.768761: Pseudo dice [np.float32(0.7698), np.float32(0.4576)] 
2025-02-27 12:52:45.772772: Epoch time: 82.63 s 
2025-02-27 12:52:45.776322: Yayy! New best EMA pseudo Dice: 0.5716000199317932 
2025-02-27 12:52:46.533469:  
2025-02-27 12:52:46.538491: Epoch 41 
2025-02-27 12:52:46.542351: Current learning rate: 0.00622 
2025-02-27 12:54:09.141680: train_loss -0.6527 
2025-02-27 12:54:09.148721: val_loss -0.5671 
2025-02-27 12:54:09.152231: Pseudo dice [np.float32(0.7755), np.float32(0.4736)] 
2025-02-27 12:54:09.156241: Epoch time: 82.61 s 
2025-02-27 12:54:09.159751: Yayy! New best EMA pseudo Dice: 0.5769000053405762 
2025-02-27 12:54:09.895686:  
2025-02-27 12:54:09.901241: Epoch 42 
2025-02-27 12:54:09.904763: Current learning rate: 0.00612 
2025-02-27 12:55:32.486628: train_loss -0.6377 
2025-02-27 12:55:32.494161: val_loss -0.5479 
2025-02-27 12:55:32.497674: Pseudo dice [np.float32(0.7682), np.float32(0.4066)] 
2025-02-27 12:55:32.501186: Epoch time: 82.59 s 
2025-02-27 12:55:32.504200: Yayy! New best EMA pseudo Dice: 0.5778999924659729 
2025-02-27 12:55:33.381071:  
2025-02-27 12:55:33.387139: Epoch 43 
2025-02-27 12:55:33.390868: Current learning rate: 0.00603 
2025-02-27 12:56:55.971924: train_loss -0.6387 
2025-02-27 12:56:55.977645: val_loss -0.5875 
2025-02-27 12:56:55.982754: Pseudo dice [np.float32(0.782), np.float32(0.4781)] 
2025-02-27 12:56:55.985287: Epoch time: 82.59 s 
2025-02-27 12:56:55.989398: Yayy! New best EMA pseudo Dice: 0.5831000208854675 
2025-02-27 12:56:56.727983:  
2025-02-27 12:56:56.734165: Epoch 44 
2025-02-27 12:56:56.737674: Current learning rate: 0.00593 
2025-02-27 12:58:19.345226: train_loss -0.6478 
2025-02-27 12:58:19.351748: val_loss -0.5742 
2025-02-27 12:58:19.355756: Pseudo dice [np.float32(0.7827), np.float32(0.4089)] 
2025-02-27 12:58:19.359266: Epoch time: 82.62 s 
2025-02-27 12:58:19.362772: Yayy! New best EMA pseudo Dice: 0.5843999981880188 
2025-02-27 12:58:20.126909:  
2025-02-27 12:58:20.133027: Epoch 45 
2025-02-27 12:58:20.136089: Current learning rate: 0.00584 
2025-02-27 12:59:42.762930: train_loss -0.645 
2025-02-27 12:59:42.771963: val_loss -0.5539 
2025-02-27 12:59:42.775479: Pseudo dice [np.float32(0.7754), np.float32(0.441)] 
2025-02-27 12:59:42.779490: Epoch time: 82.64 s 
2025-02-27 12:59:42.781996: Yayy! New best EMA pseudo Dice: 0.5867999792098999 
2025-02-27 12:59:43.505843:  
2025-02-27 12:59:43.511355: Epoch 46 
2025-02-27 12:59:43.514867: Current learning rate: 0.00574 
2025-02-27 13:01:06.121644: train_loss -0.6382 
2025-02-27 13:01:06.129168: val_loss -0.5823 
2025-02-27 13:01:06.133181: Pseudo dice [np.float32(0.7761), np.float32(0.5068)] 
2025-02-27 13:01:06.136691: Epoch time: 82.62 s 
2025-02-27 13:01:06.140200: Yayy! New best EMA pseudo Dice: 0.5922999978065491 
2025-02-27 13:01:06.891081:  
2025-02-27 13:01:06.896702: Epoch 47 
2025-02-27 13:01:06.900747: Current learning rate: 0.00565 
2025-02-27 13:02:29.575218: train_loss -0.6535 
2025-02-27 13:02:29.581742: val_loss -0.5315 
2025-02-27 13:02:29.586256: Pseudo dice [np.float32(0.7516), np.float32(0.3971)] 
2025-02-27 13:02:29.590273: Epoch time: 82.68 s 
2025-02-27 13:02:30.146817:  
2025-02-27 13:02:30.152883: Epoch 48 
2025-02-27 13:02:30.155944: Current learning rate: 0.00555 
2025-02-27 13:03:52.759199: train_loss -0.6782 
2025-02-27 13:03:52.765715: val_loss -0.5745 
2025-02-27 13:03:52.769224: Pseudo dice [np.float32(0.7829), np.float32(0.4939)] 
2025-02-27 13:03:52.773234: Epoch time: 82.61 s 
2025-02-27 13:03:52.776745: Yayy! New best EMA pseudo Dice: 0.595300018787384 
2025-02-27 13:03:53.487055:  
2025-02-27 13:03:53.492620: Epoch 49 
2025-02-27 13:03:53.496721: Current learning rate: 0.00546 
2025-02-27 13:05:16.093139: train_loss -0.6625 
2025-02-27 13:05:16.100196: val_loss -0.5735 
2025-02-27 13:05:16.104238: Pseudo dice [np.float32(0.7734), np.float32(0.4242)] 
2025-02-27 13:05:16.107763: Epoch time: 82.61 s 
2025-02-27 13:05:16.265409: Yayy! New best EMA pseudo Dice: 0.5956000089645386 
2025-02-27 13:05:16.990626:  
2025-02-27 13:05:16.995636: Epoch 50 
2025-02-27 13:05:16.999666: Current learning rate: 0.00536 
2025-02-27 13:06:39.654512: train_loss -0.6627 
2025-02-27 13:06:39.662136: val_loss -0.5124 
2025-02-27 13:06:39.665351: Pseudo dice [np.float32(0.772), np.float32(0.3109)] 
2025-02-27 13:06:39.668858: Epoch time: 82.66 s 
2025-02-27 13:06:40.398131:  
2025-02-27 13:06:40.403769: Epoch 51 
2025-02-27 13:06:40.408336: Current learning rate: 0.00526 
2025-02-27 13:08:02.996246: train_loss -0.656 
2025-02-27 13:08:03.003259: val_loss -0.573 
2025-02-27 13:08:03.007270: Pseudo dice [np.float32(0.776), np.float32(0.4486)] 
2025-02-27 13:08:03.011276: Epoch time: 82.6 s 
2025-02-27 13:08:03.581266:  
2025-02-27 13:08:03.587284: Epoch 52 
2025-02-27 13:08:03.591292: Current learning rate: 0.00517 
2025-02-27 13:09:26.221944: train_loss -0.6661 
2025-02-27 13:09:26.229462: val_loss -0.5488 
2025-02-27 13:09:26.233972: Pseudo dice [np.float32(0.7767), np.float32(0.4132)] 
2025-02-27 13:09:26.237987: Epoch time: 82.64 s 
2025-02-27 13:09:26.816644:  
2025-02-27 13:09:26.823205: Epoch 53 
2025-02-27 13:09:26.826891: Current learning rate: 0.00507 
2025-02-27 13:10:49.380202: train_loss -0.6748 
2025-02-27 13:10:49.387730: val_loss -0.5565 
2025-02-27 13:10:49.391745: Pseudo dice [np.float32(0.7786), np.float32(0.3778)] 
2025-02-27 13:10:49.396257: Epoch time: 82.56 s 
2025-02-27 13:10:49.970531:  
2025-02-27 13:10:49.977152: Epoch 54 
2025-02-27 13:10:49.980711: Current learning rate: 0.00497 
2025-02-27 13:12:12.608552: train_loss -0.6941 
2025-02-27 13:12:12.615644: val_loss -0.584 
2025-02-27 13:12:12.619305: Pseudo dice [np.float32(0.7783), np.float32(0.4652)] 
2025-02-27 13:12:12.623373: Epoch time: 82.64 s 
2025-02-27 13:12:13.228807:  
2025-02-27 13:12:13.234359: Epoch 55 
2025-02-27 13:12:13.238415: Current learning rate: 0.00487 
2025-02-27 13:13:35.843566: train_loss -0.6756 
2025-02-27 13:13:35.851084: val_loss -0.5842 
2025-02-27 13:13:35.854595: Pseudo dice [np.float32(0.7909), np.float32(0.4756)] 
2025-02-27 13:13:35.858604: Epoch time: 82.61 s 
2025-02-27 13:13:35.862117: Yayy! New best EMA pseudo Dice: 0.5982000231742859 
2025-02-27 13:13:36.595529:  
2025-02-27 13:13:36.601604: Epoch 56 
2025-02-27 13:13:36.605659: Current learning rate: 0.00478 
2025-02-27 13:14:59.211607: train_loss -0.6914 
2025-02-27 13:14:59.219126: val_loss -0.5766 
2025-02-27 13:14:59.223138: Pseudo dice [np.float32(0.7618), np.float32(0.4851)] 
2025-02-27 13:14:59.227650: Epoch time: 82.62 s 
2025-02-27 13:14:59.230659: Yayy! New best EMA pseudo Dice: 0.6007000207901001 
2025-02-27 13:14:59.977713:  
2025-02-27 13:14:59.983397: Epoch 57 
2025-02-27 13:14:59.987269: Current learning rate: 0.00468 
2025-02-27 13:16:22.567413: train_loss -0.6904 
2025-02-27 13:16:22.574937: val_loss -0.5935 
2025-02-27 13:16:22.578954: Pseudo dice [np.float32(0.7957), np.float32(0.5106)] 
2025-02-27 13:16:22.582465: Epoch time: 82.59 s 
2025-02-27 13:16:22.586478: Yayy! New best EMA pseudo Dice: 0.60589998960495 
2025-02-27 13:16:23.334867:  
2025-02-27 13:16:23.341461: Epoch 58 
2025-02-27 13:16:23.344005: Current learning rate: 0.00458 
2025-02-27 13:17:45.939031: train_loss -0.7043 
2025-02-27 13:17:45.946551: val_loss -0.5835 
2025-02-27 13:17:45.950059: Pseudo dice [np.float32(0.7825), np.float32(0.4803)] 
2025-02-27 13:17:45.954072: Epoch time: 82.6 s 
2025-02-27 13:17:45.957578: Yayy! New best EMA pseudo Dice: 0.6085000038146973 
2025-02-27 13:17:46.909795:  
2025-02-27 13:17:46.917419: Epoch 59 
2025-02-27 13:17:46.922474: Current learning rate: 0.00448 
2025-02-27 13:19:09.495797: train_loss -0.6843 
2025-02-27 13:19:09.502372: val_loss -0.5513 
2025-02-27 13:19:09.507426: Pseudo dice [np.float32(0.7893), np.float32(0.4542)] 
2025-02-27 13:19:09.511040: Epoch time: 82.59 s 
2025-02-27 13:19:09.515082: Yayy! New best EMA pseudo Dice: 0.6097999811172485 
2025-02-27 13:19:10.265633:  
2025-02-27 13:19:10.272235: Epoch 60 
2025-02-27 13:19:10.275775: Current learning rate: 0.00438 
2025-02-27 13:20:32.838944: train_loss -0.6853 
2025-02-27 13:20:32.846463: val_loss -0.5444 
2025-02-27 13:20:32.849473: Pseudo dice [np.float32(0.7794), np.float32(0.435)] 
2025-02-27 13:20:32.853983: Epoch time: 82.57 s 
2025-02-27 13:20:33.457922:  
2025-02-27 13:20:33.463493: Epoch 61 
2025-02-27 13:20:33.466037: Current learning rate: 0.00429 
2025-02-27 13:21:56.076262: train_loss -0.7158 
2025-02-27 13:21:56.083277: val_loss -0.5391 
2025-02-27 13:21:56.086289: Pseudo dice [np.float32(0.7763), np.float32(0.3525)] 
2025-02-27 13:21:56.089801: Epoch time: 82.62 s 
2025-02-27 13:21:56.669766:  
2025-02-27 13:21:56.674811: Epoch 62 
2025-02-27 13:21:56.677880: Current learning rate: 0.00419 
2025-02-27 13:23:19.261705: train_loss -0.6969 
2025-02-27 13:23:19.268220: val_loss -0.5692 
2025-02-27 13:23:19.271730: Pseudo dice [np.float32(0.7855), np.float32(0.4362)] 
2025-02-27 13:23:19.274235: Epoch time: 82.59 s 
2025-02-27 13:23:19.850782:  
2025-02-27 13:23:19.856848: Epoch 63 
2025-02-27 13:23:19.859971: Current learning rate: 0.00409 
2025-02-27 13:24:42.443023: train_loss -0.7215 
2025-02-27 13:24:42.452048: val_loss -0.5938 
2025-02-27 13:24:42.455596: Pseudo dice [np.float32(0.7951), np.float32(0.4863)] 
2025-02-27 13:24:42.459103: Epoch time: 82.59 s 
2025-02-27 13:24:43.028566:  
2025-02-27 13:24:43.035152: Epoch 64 
2025-02-27 13:24:43.038699: Current learning rate: 0.00399 
2025-02-27 13:26:05.620128: train_loss -0.7136 
2025-02-27 13:26:05.627261: val_loss -0.5809 
2025-02-27 13:26:05.631341: Pseudo dice [np.float32(0.7751), np.float32(0.4853)] 
2025-02-27 13:26:05.635416: Epoch time: 82.59 s 
2025-02-27 13:26:05.638980: Yayy! New best EMA pseudo Dice: 0.6111999750137329 
2025-02-27 13:26:06.378160:  
2025-02-27 13:26:06.385238: Epoch 65 
2025-02-27 13:26:06.389310: Current learning rate: 0.00389 
2025-02-27 13:27:29.025694: train_loss -0.714 
2025-02-27 13:27:29.032223: val_loss -0.5784 
2025-02-27 13:27:29.036236: Pseudo dice [np.float32(0.783), np.float32(0.4774)] 
2025-02-27 13:27:29.039749: Epoch time: 82.65 s 
2025-02-27 13:27:29.043762: Yayy! New best EMA pseudo Dice: 0.613099992275238 
2025-02-27 13:27:29.822980:  
2025-02-27 13:27:29.829043: Epoch 66 
2025-02-27 13:27:29.832115: Current learning rate: 0.00379 
2025-02-27 13:28:52.445735: train_loss -0.7277 
2025-02-27 13:28:52.453761: val_loss -0.5902 
2025-02-27 13:28:52.458774: Pseudo dice [np.float32(0.7876), np.float32(0.4724)] 
2025-02-27 13:28:52.462285: Epoch time: 82.62 s 
2025-02-27 13:28:52.466304: Yayy! New best EMA pseudo Dice: 0.614799976348877 
2025-02-27 13:28:53.365993:  
2025-02-27 13:28:53.371507: Epoch 67 
2025-02-27 13:28:53.376016: Current learning rate: 0.00369 
2025-02-27 13:30:16.336161: train_loss -0.7244 
2025-02-27 13:30:16.343696: val_loss -0.5866 
2025-02-27 13:30:16.348212: Pseudo dice [np.float32(0.7878), np.float32(0.4527)] 
2025-02-27 13:30:16.352230: Epoch time: 82.97 s 
2025-02-27 13:30:16.355742: Yayy! New best EMA pseudo Dice: 0.6154000163078308 
2025-02-27 13:30:17.106012:  
2025-02-27 13:30:17.112605: Epoch 68 
2025-02-27 13:30:17.115146: Current learning rate: 0.00359 
2025-02-27 13:31:39.728828: train_loss -0.7155 
2025-02-27 13:31:39.735349: val_loss -0.5752 
2025-02-27 13:31:39.739363: Pseudo dice [np.float32(0.8036), np.float32(0.4685)] 
2025-02-27 13:31:39.743876: Epoch time: 82.62 s 
2025-02-27 13:31:39.747895: Yayy! New best EMA pseudo Dice: 0.6173999905586243 
2025-02-27 13:31:40.501524:  
2025-02-27 13:31:40.508044: Epoch 69 
2025-02-27 13:31:40.512553: Current learning rate: 0.00349 
2025-02-27 13:33:03.090357: train_loss -0.7173 
2025-02-27 13:33:03.097874: val_loss -0.5596 
2025-02-27 13:33:03.101384: Pseudo dice [np.float32(0.7752), np.float32(0.4346)] 
2025-02-27 13:33:03.105394: Epoch time: 82.59 s 
2025-02-27 13:33:03.685646:  
2025-02-27 13:33:03.691213: Epoch 70 
2025-02-27 13:33:03.695837: Current learning rate: 0.00338 
2025-02-27 13:34:26.250749: train_loss -0.7165 
2025-02-27 13:34:26.257914: val_loss -0.5804 
2025-02-27 13:34:26.262008: Pseudo dice [np.float32(0.7937), np.float32(0.5132)] 
2025-02-27 13:34:26.265563: Epoch time: 82.57 s 
2025-02-27 13:34:26.270208: Yayy! New best EMA pseudo Dice: 0.6198999881744385 
2025-02-27 13:34:27.018892:  
2025-02-27 13:34:27.024451: Epoch 71 
2025-02-27 13:34:27.028527: Current learning rate: 0.00328 
2025-02-27 13:35:49.630025: train_loss -0.7273 
2025-02-27 13:35:49.637544: val_loss -0.5881 
2025-02-27 13:35:49.641550: Pseudo dice [np.float32(0.7882), np.float32(0.4806)] 
2025-02-27 13:35:49.646087: Epoch time: 82.61 s 
2025-02-27 13:35:49.650166: Yayy! New best EMA pseudo Dice: 0.621399998664856 
2025-02-27 13:35:50.403349:  
2025-02-27 13:35:50.408864: Epoch 72 
2025-02-27 13:35:50.413373: Current learning rate: 0.00318 
2025-02-27 13:37:13.015156: train_loss -0.7298 
2025-02-27 13:37:13.022677: val_loss -0.5648 
2025-02-27 13:37:13.026688: Pseudo dice [np.float32(0.7945), np.float32(0.4352)] 
2025-02-27 13:37:13.031198: Epoch time: 82.61 s 
2025-02-27 13:37:13.613122:  
2025-02-27 13:37:13.619731: Epoch 73 
2025-02-27 13:37:13.622283: Current learning rate: 0.00308 
2025-02-27 13:38:36.183301: train_loss -0.7221 
2025-02-27 13:38:36.190322: val_loss -0.5649 
2025-02-27 13:38:36.194335: Pseudo dice [np.float32(0.7961), np.float32(0.4268)] 
2025-02-27 13:38:36.198346: Epoch time: 82.57 s 
2025-02-27 13:38:36.798816:  
2025-02-27 13:38:36.803674: Epoch 74 
2025-02-27 13:38:36.807183: Current learning rate: 0.00297 
2025-02-27 13:39:59.378146: train_loss -0.7378 
2025-02-27 13:39:59.385247: val_loss -0.5543 
2025-02-27 13:39:59.389317: Pseudo dice [np.float32(0.7743), np.float32(0.4815)] 
2025-02-27 13:39:59.392857: Epoch time: 82.58 s 
2025-02-27 13:40:00.142421:  
2025-02-27 13:40:00.149071: Epoch 75 
2025-02-27 13:40:00.153121: Current learning rate: 0.00287 
2025-02-27 13:41:22.731203: train_loss -0.7347 
2025-02-27 13:41:22.737717: val_loss -0.5939 
2025-02-27 13:41:22.742226: Pseudo dice [np.float32(0.7966), np.float32(0.5155)] 
2025-02-27 13:41:22.746238: Epoch time: 82.59 s 
2025-02-27 13:41:22.749743: Yayy! New best EMA pseudo Dice: 0.6241000294685364 
2025-02-27 13:41:23.494796:  
2025-02-27 13:41:23.500818: Epoch 76 
2025-02-27 13:41:23.504825: Current learning rate: 0.00277 
2025-02-27 13:42:46.164999: train_loss -0.7446 
2025-02-27 13:42:46.171662: val_loss -0.6045 
2025-02-27 13:42:46.176236: Pseudo dice [np.float32(0.7938), np.float32(0.5747)] 
2025-02-27 13:42:46.180271: Epoch time: 82.67 s 
2025-02-27 13:42:46.183333: Yayy! New best EMA pseudo Dice: 0.6301000118255615 
2025-02-27 13:42:46.956467:  
2025-02-27 13:42:46.963044: Epoch 77 
2025-02-27 13:42:46.967594: Current learning rate: 0.00266 
2025-02-27 13:44:09.565283: train_loss -0.7523 
2025-02-27 13:44:09.572298: val_loss -0.5955 
2025-02-27 13:44:09.576315: Pseudo dice [np.float32(0.7995), np.float32(0.5049)] 
2025-02-27 13:44:09.580326: Epoch time: 82.61 s 
2025-02-27 13:44:09.584836: Yayy! New best EMA pseudo Dice: 0.6323000192642212 
2025-02-27 13:44:10.339724:  
2025-02-27 13:44:10.345738: Epoch 78 
2025-02-27 13:44:10.349749: Current learning rate: 0.00256 
2025-02-27 13:45:32.989854: train_loss -0.7511 
2025-02-27 13:45:32.996391: val_loss -0.6104 
2025-02-27 13:45:33.000966: Pseudo dice [np.float32(0.7912), np.float32(0.5178)] 
2025-02-27 13:45:33.005012: Epoch time: 82.65 s 
2025-02-27 13:45:33.008075: Yayy! New best EMA pseudo Dice: 0.6345999836921692 
2025-02-27 13:45:33.777382:  
2025-02-27 13:45:33.783976: Epoch 79 
2025-02-27 13:45:33.788106: Current learning rate: 0.00245 
2025-02-27 13:46:56.459613: train_loss -0.757 
2025-02-27 13:46:56.466689: val_loss -0.6115 
2025-02-27 13:46:56.470734: Pseudo dice [np.float32(0.818), np.float32(0.5048)] 
2025-02-27 13:46:56.474797: Epoch time: 82.68 s 
2025-02-27 13:46:56.479343: Yayy! New best EMA pseudo Dice: 0.6371999979019165 
2025-02-27 13:46:57.234271:  
2025-02-27 13:46:57.241433: Epoch 80 
2025-02-27 13:46:57.245477: Current learning rate: 0.00235 
2025-02-27 13:48:19.878018: train_loss -0.7585 
2025-02-27 13:48:19.885540: val_loss -0.6225 
2025-02-27 13:48:19.889554: Pseudo dice [np.float32(0.7998), np.float32(0.562)] 
2025-02-27 13:48:19.893122: Epoch time: 82.64 s 
2025-02-27 13:48:19.897133: Yayy! New best EMA pseudo Dice: 0.6416000127792358 
2025-02-27 13:48:20.653496:  
2025-02-27 13:48:20.660014: Epoch 81 
2025-02-27 13:48:20.665029: Current learning rate: 0.00224 
2025-02-27 13:49:43.245108: train_loss -0.7509 
2025-02-27 13:49:43.252792: val_loss -0.607 
2025-02-27 13:49:43.256338: Pseudo dice [np.float32(0.798), np.float32(0.5976)] 
2025-02-27 13:49:43.259933: Epoch time: 82.59 s 
2025-02-27 13:49:43.264986: Yayy! New best EMA pseudo Dice: 0.6471999883651733 
2025-02-27 13:49:44.067495:  
2025-02-27 13:49:44.074181: Epoch 82 
2025-02-27 13:49:44.077715: Current learning rate: 0.00214 
2025-02-27 13:51:06.689414: train_loss -0.7391 
2025-02-27 13:51:06.696970: val_loss -0.5842 
2025-02-27 13:51:06.700982: Pseudo dice [np.float32(0.7937), np.float32(0.478)] 
2025-02-27 13:51:06.704491: Epoch time: 82.62 s 
2025-02-27 13:51:07.439650:  
2025-02-27 13:51:07.446170: Epoch 83 
2025-02-27 13:51:07.450179: Current learning rate: 0.00203 
2025-02-27 13:52:30.089583: train_loss -0.7453 
2025-02-27 13:52:30.097101: val_loss -0.5797 
2025-02-27 13:52:30.100611: Pseudo dice [np.float32(0.7916), np.float32(0.4645)] 
2025-02-27 13:52:30.104622: Epoch time: 82.65 s 
2025-02-27 13:52:30.673511:  
2025-02-27 13:52:30.679536: Epoch 84 
2025-02-27 13:52:30.683542: Current learning rate: 0.00192 
2025-02-27 13:53:53.279970: train_loss -0.7536 
2025-02-27 13:53:53.287491: val_loss -0.5925 
2025-02-27 13:53:53.292000: Pseudo dice [np.float32(0.7914), np.float32(0.5417)] 
2025-02-27 13:53:53.296011: Epoch time: 82.61 s 
2025-02-27 13:53:53.858373:  
2025-02-27 13:53:53.864981: Epoch 85 
2025-02-27 13:53:53.869555: Current learning rate: 0.00181 
2025-02-27 13:55:16.473143: train_loss -0.7569 
2025-02-27 13:55:16.480660: val_loss -0.5883 
2025-02-27 13:55:16.484169: Pseudo dice [np.float32(0.7918), np.float32(0.4848)] 
2025-02-27 13:55:16.489182: Epoch time: 82.61 s 
2025-02-27 13:55:17.057505:  
2025-02-27 13:55:17.064161: Epoch 86 
2025-02-27 13:55:17.068225: Current learning rate: 0.0017 
2025-02-27 13:56:39.678157: train_loss -0.769 
2025-02-27 13:56:39.685674: val_loss -0.6095 
2025-02-27 13:56:39.689684: Pseudo dice [np.float32(0.8011), np.float32(0.5572)] 
2025-02-27 13:56:39.693193: Epoch time: 82.62 s 
2025-02-27 13:56:39.696730: Yayy! New best EMA pseudo Dice: 0.6489999890327454 
2025-02-27 13:56:40.405835:  
2025-02-27 13:56:40.411353: Epoch 87 
2025-02-27 13:56:40.416364: Current learning rate: 0.00159 
2025-02-27 13:58:03.022792: train_loss -0.7569 
2025-02-27 13:58:03.030311: val_loss -0.5936 
2025-02-27 13:58:03.033821: Pseudo dice [np.float32(0.8075), np.float32(0.5311)] 
2025-02-27 13:58:03.038837: Epoch time: 82.62 s 
2025-02-27 13:58:03.042341: Yayy! New best EMA pseudo Dice: 0.6510999798774719 
2025-02-27 13:58:03.778188:  
2025-02-27 13:58:03.784227: Epoch 88 
2025-02-27 13:58:03.788579: Current learning rate: 0.00148 
2025-02-27 13:59:26.375399: train_loss -0.7781 
2025-02-27 13:59:26.382609: val_loss -0.598 
2025-02-27 13:59:26.387159: Pseudo dice [np.float32(0.8033), np.float32(0.4519)] 
2025-02-27 13:59:26.390709: Epoch time: 82.6 s 
2025-02-27 13:59:26.963300:  
2025-02-27 13:59:26.969419: Epoch 89 
2025-02-27 13:59:26.973511: Current learning rate: 0.00137 
2025-02-27 14:00:49.555410: train_loss -0.7745 
2025-02-27 14:00:49.562928: val_loss -0.6181 
2025-02-27 14:00:49.567669: Pseudo dice [np.float32(0.8035), np.float32(0.6075)] 
2025-02-27 14:00:49.571680: Epoch time: 82.59 s 
2025-02-27 14:00:49.575190: Yayy! New best EMA pseudo Dice: 0.6543999910354614 
2025-02-27 14:00:50.292567:  
2025-02-27 14:00:50.299583: Epoch 90 
2025-02-27 14:00:50.303594: Current learning rate: 0.00126 
2025-02-27 14:02:12.906906: train_loss -0.7742 
2025-02-27 14:02:12.915429: val_loss -0.5981 
2025-02-27 14:02:12.919451: Pseudo dice [np.float32(0.783), np.float32(0.5147)] 
2025-02-27 14:02:12.923459: Epoch time: 82.61 s 
2025-02-27 14:02:13.479824:  
2025-02-27 14:02:13.485842: Epoch 91 
2025-02-27 14:02:13.490861: Current learning rate: 0.00115 
2025-02-27 14:03:36.110045: train_loss -0.7792 
2025-02-27 14:03:36.117715: val_loss -0.5923 
2025-02-27 14:03:36.121747: Pseudo dice [np.float32(0.802), np.float32(0.5107)] 
2025-02-27 14:03:36.126394: Epoch time: 82.63 s 
2025-02-27 14:03:36.872761:  
2025-02-27 14:03:36.877785: Epoch 92 
2025-02-27 14:03:36.881919: Current learning rate: 0.00103 
2025-02-27 14:04:59.510510: train_loss -0.7768 
2025-02-27 14:04:59.518028: val_loss -0.6021 
2025-02-27 14:04:59.522038: Pseudo dice [np.float32(0.7998), np.float32(0.526)] 
2025-02-27 14:04:59.525548: Epoch time: 82.64 s 
2025-02-27 14:04:59.529558: Yayy! New best EMA pseudo Dice: 0.6549999713897705 
2025-02-27 14:05:00.247081:  
2025-02-27 14:05:00.253680: Epoch 93 
2025-02-27 14:05:00.257750: Current learning rate: 0.00091 
2025-02-27 14:06:22.831623: train_loss -0.7762 
2025-02-27 14:06:22.839146: val_loss -0.6348 
2025-02-27 14:06:22.842154: Pseudo dice [np.float32(0.8228), np.float32(0.5824)] 
2025-02-27 14:06:22.846710: Epoch time: 82.58 s 
2025-02-27 14:06:22.850778: Yayy! New best EMA pseudo Dice: 0.6596999764442444 
2025-02-27 14:06:23.574415:  
2025-02-27 14:06:23.580969: Epoch 94 
2025-02-27 14:06:23.585063: Current learning rate: 0.00079 
2025-02-27 14:07:46.185014: train_loss -0.7833 
2025-02-27 14:07:46.192546: val_loss -0.6282 
2025-02-27 14:07:46.197564: Pseudo dice [np.float32(0.7993), np.float32(0.6553)] 
2025-02-27 14:07:46.202582: Epoch time: 82.61 s 
2025-02-27 14:07:46.206595: Yayy! New best EMA pseudo Dice: 0.6664999723434448 
2025-02-27 14:07:46.931808:  
2025-02-27 14:07:46.938361: Epoch 95 
2025-02-27 14:07:46.940882: Current learning rate: 0.00067 
2025-02-27 14:09:09.556787: train_loss -0.7938 
2025-02-27 14:09:09.564319: val_loss -0.613 
2025-02-27 14:09:09.567834: Pseudo dice [np.float32(0.7975), np.float32(0.563)] 
2025-02-27 14:09:09.571347: Epoch time: 82.63 s 
2025-02-27 14:09:09.574361: Yayy! New best EMA pseudo Dice: 0.667900025844574 
2025-02-27 14:09:10.293678:  
2025-02-27 14:09:10.299715: Epoch 96 
2025-02-27 14:09:10.302754: Current learning rate: 0.00055 
2025-02-27 14:10:32.901975: train_loss -0.7837 
2025-02-27 14:10:32.908496: val_loss -0.6021 
2025-02-27 14:10:32.912004: Pseudo dice [np.float32(0.8058), np.float32(0.4536)] 
2025-02-27 14:10:32.916027: Epoch time: 82.61 s 
2025-02-27 14:10:33.484397:  
2025-02-27 14:10:33.490911: Epoch 97 
2025-02-27 14:10:33.494422: Current learning rate: 0.00043 
2025-02-27 14:11:56.118743: train_loss -0.7801 
2025-02-27 14:11:56.125262: val_loss -0.5791 
2025-02-27 14:11:56.129307: Pseudo dice [np.float32(0.7882), np.float32(0.5035)] 
2025-02-27 14:11:56.132817: Epoch time: 82.63 s 
2025-02-27 14:11:56.703604:  
2025-02-27 14:11:56.709377: Epoch 98 
2025-02-27 14:11:56.712886: Current learning rate: 0.0003 
2025-02-27 14:13:19.372716: train_loss -0.7763 
2025-02-27 14:13:19.380239: val_loss -0.577 
2025-02-27 14:13:19.383249: Pseudo dice [np.float32(0.7985), np.float32(0.5066)] 
2025-02-27 14:13:19.388261: Epoch time: 82.67 s 
2025-02-27 14:13:19.956714:  
2025-02-27 14:13:19.962724: Epoch 99 
2025-02-27 14:13:19.965235: Current learning rate: 0.00016 
2025-02-27 14:14:42.561739: train_loss -0.802 
2025-02-27 14:14:42.568257: val_loss -0.5746 
2025-02-27 14:14:42.571765: Pseudo dice [np.float32(0.8013), np.float32(0.4698)] 
2025-02-27 14:14:42.574775: Epoch time: 82.61 s 
2025-02-27 14:14:43.374148: Training done. 
2025-02-27 14:14:43.406148: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-02-27 14:14:43.413149: The split file contains 5 splits. 
2025-02-27 14:14:43.418149: Desired fold for training: 0 
2025-02-27 14:14:43.423152: This split has 224 training and 57 validation cases. 
2025-02-27 14:14:43.428152: predicting pancreas_021 
2025-02-27 14:14:43.434152: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-02-27 14:14:56.535566: predicting pancreas_024 
2025-02-27 14:14:56.556075: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-02-27 14:15:11.800648: predicting pancreas_035 
2025-02-27 14:15:11.822648: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-02-27 14:15:17.004328: predicting pancreas_040 
2025-02-27 14:15:17.017328: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-02-27 14:15:29.221583: predicting pancreas_042 
2025-02-27 14:15:29.241584: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-02-27 14:15:44.501786: predicting pancreas_056 
2025-02-27 14:15:44.523781: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-02-27 14:15:56.745900: predicting pancreas_067 
2025-02-27 14:15:56.762901: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-02-27 14:16:12.039276: predicting pancreas_075 
2025-02-27 14:16:12.062277: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-02-27 14:16:18.207659: predicting pancreas_086 
2025-02-27 14:16:18.223660: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-02-27 14:16:27.759217: predicting pancreas_089 
2025-02-27 14:16:27.776217: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-02-27 14:16:39.995445: predicting pancreas_092 
2025-02-27 14:16:40.013955: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-02-27 14:17:07.401158: predicting pancreas_094 
2025-02-27 14:17:07.432665: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-02-27 14:17:19.639147: predicting pancreas_095 
2025-02-27 14:17:19.656147: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-02-27 14:17:31.887481: predicting pancreas_098 
2025-02-27 14:17:31.905479: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-02-27 14:18:05.169056: predicting pancreas_109 
2025-02-27 14:18:05.200057: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-02-27 14:18:17.453946: predicting pancreas_110 
2025-02-27 14:18:17.477084: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-02-27 14:18:36.538578: predicting pancreas_114 
2025-02-27 14:18:36.563581: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-02-27 14:18:48.803812: predicting pancreas_119 
2025-02-27 14:18:48.820812: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-02-27 14:19:07.876687: predicting pancreas_138 
2025-02-27 14:19:07.898198: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-02-27 14:19:26.971127: predicting pancreas_145 
2025-02-27 14:19:26.994130: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-02-27 14:19:46.083623: predicting pancreas_148 
2025-02-27 14:19:46.104623: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-02-27 14:19:58.335379: predicting pancreas_169 
2025-02-27 14:19:58.351379: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-02-27 14:20:10.571332: predicting pancreas_170 
2025-02-27 14:20:10.589321: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-02-27 14:20:25.835807: predicting pancreas_172 
2025-02-27 14:20:25.855314: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-02-27 14:20:38.077428: predicting pancreas_175 
2025-02-27 14:20:38.094428: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-02-27 14:20:50.327026: predicting pancreas_180 
2025-02-27 14:20:50.346026: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-02-27 14:21:02.575234: predicting pancreas_191 
2025-02-27 14:21:02.592234: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-02-27 14:21:08.743977: predicting pancreas_193 
2025-02-27 14:21:08.758977: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-02-27 14:21:23.993989: predicting pancreas_212 
2025-02-27 14:21:24.012989: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-02-27 14:21:36.250294: predicting pancreas_215 
2025-02-27 14:21:36.271294: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-02-27 14:21:48.512922: predicting pancreas_222 
2025-02-27 14:21:48.530922: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-02-27 14:21:53.717349: predicting pancreas_235 
2025-02-27 14:21:53.730350: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-02-27 14:22:05.937746: predicting pancreas_241 
2025-02-27 14:22:05.954746: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-02-27 14:22:18.177566: predicting pancreas_242 
2025-02-27 14:22:18.200567: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-02-27 14:22:33.465594: predicting pancreas_244 
2025-02-27 14:22:33.488595: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-02-27 14:22:57.231021: predicting pancreas_246 
2025-02-27 14:22:57.255129: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-02-27 14:23:21.027457: predicting pancreas_247 
2025-02-27 14:23:21.051456: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-02-27 14:23:27.970678: predicting pancreas_264 
2025-02-27 14:23:27.988771: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-02-27 14:23:43.232433: predicting pancreas_265 
2025-02-27 14:23:43.255429: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-02-27 14:23:55.500574: predicting pancreas_266 
2025-02-27 14:23:55.520573: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-02-27 14:24:14.579900: predicting pancreas_267 
2025-02-27 14:24:14.605408: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-02-27 14:24:21.527352: predicting pancreas_275 
2025-02-27 14:24:21.544353: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-02-27 14:24:36.797170: predicting pancreas_279 
2025-02-27 14:24:36.817174: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-02-27 14:24:42.038895: predicting pancreas_287 
2025-02-27 14:24:42.054895: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-02-27 14:24:54.264980: predicting pancreas_301 
2025-02-27 14:24:54.283979: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-02-27 14:25:06.533276: predicting pancreas_323 
2025-02-27 14:25:06.552785: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-02-27 14:25:25.608814: predicting pancreas_336 
2025-02-27 14:25:25.633814: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-02-27 14:25:37.910831: predicting pancreas_344 
2025-02-27 14:25:37.931829: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-02-27 14:25:53.165920: predicting pancreas_351 
2025-02-27 14:25:53.183431: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-02-27 14:26:00.093126: predicting pancreas_354 
2025-02-27 14:26:00.108127: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-02-27 14:26:24.446265: predicting pancreas_372 
2025-02-27 14:26:24.478270: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-02-27 14:26:43.570801: predicting pancreas_377 
2025-02-27 14:26:43.594805: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-02-27 14:26:58.875341: predicting pancreas_387 
2025-02-27 14:26:58.898342: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-02-27 14:27:11.148479: predicting pancreas_391 
2025-02-27 14:27:11.169475: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-02-27 14:27:30.230826: predicting pancreas_392 
2025-02-27 14:27:30.253852: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-02-27 14:27:38.893243: predicting pancreas_410 
2025-02-27 14:27:38.910244: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-02-27 14:27:47.553989: predicting pancreas_412 
2025-02-27 14:27:47.570989: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-02-27 14:28:48.688243: Validation complete 
2025-02-27 14:28:48.694242: Mean Validation Dice:  0.3467772013996653 
