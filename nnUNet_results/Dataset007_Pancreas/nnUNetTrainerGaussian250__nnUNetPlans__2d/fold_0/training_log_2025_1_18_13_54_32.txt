
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-18 13:54:32.884595: do_dummy_2d_data_aug: False 
2025-01-18 13:54:32.890595: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-18 13:54:32.892596: The split file contains 5 splits. 
2025-01-18 13:54:32.895595: Desired fold for training: 0 
2025-01-18 13:54:32.898596: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-18 13:54:38.806787: unpacking dataset... 
2025-01-18 13:54:38.990073: unpacking done... 
2025-01-18 13:54:43.083049:  
2025-01-18 13:54:43.083049: Epoch 0 
2025-01-18 13:54:43.088060: Current learning rate: 0.01 
2025-01-18 13:55:18.096138: train_loss 0.0661 
2025-01-18 13:55:18.097137: val_loss 0.0073 
2025-01-18 13:55:18.102654: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-18 13:55:18.106164: Epoch time: 35.01 s 
2025-01-18 13:55:18.108672: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-18 13:55:18.811834:  
2025-01-18 13:55:18.812835: Epoch 1 
2025-01-18 13:55:18.817956: Current learning rate: 0.00996 
2025-01-18 13:55:50.646815: train_loss -0.039 
2025-01-18 13:55:50.648320: val_loss -0.1526 
2025-01-18 13:55:50.650826: Pseudo dice [np.float32(0.0002), np.float32(0.0)] 
2025-01-18 13:55:50.654336: Epoch time: 31.83 s 
2025-01-18 13:55:50.657859: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-18 13:55:51.446516:  
2025-01-18 13:55:51.446516: Epoch 2 
2025-01-18 13:55:51.451527: Current learning rate: 0.00993 
2025-01-18 13:56:23.259940: train_loss -0.2529 
2025-01-18 13:56:23.259940: val_loss -0.302 
2025-01-18 13:56:23.266454: Pseudo dice [np.float32(0.5819), np.float32(0.0)] 
2025-01-18 13:56:23.269480: Epoch time: 31.81 s 
2025-01-18 13:56:23.271503: Yayy! New best EMA pseudo Dice: 0.029100000858306885 
2025-01-18 13:56:24.082725:  
2025-01-18 13:56:24.083228: Epoch 3 
2025-01-18 13:56:24.088247: Current learning rate: 0.00989 
2025-01-18 13:56:55.897413: train_loss -0.326 
2025-01-18 13:56:55.898418: val_loss -0.3711 
2025-01-18 13:56:55.903937: Pseudo dice [np.float32(0.6217), np.float32(0.0)] 
2025-01-18 13:56:55.906954: Epoch time: 31.82 s 
2025-01-18 13:56:55.909978: Yayy! New best EMA pseudo Dice: 0.05730000138282776 
2025-01-18 13:56:56.686943:  
2025-01-18 13:56:56.688454: Epoch 4 
2025-01-18 13:56:56.694019: Current learning rate: 0.00986 
2025-01-18 13:57:28.518927: train_loss -0.4328 
2025-01-18 13:57:28.519441: val_loss -0.4149 
2025-01-18 13:57:28.525061: Pseudo dice [np.float32(0.6032), np.float32(0.3346)] 
2025-01-18 13:57:28.528123: Epoch time: 31.83 s 
2025-01-18 13:57:28.531289: Yayy! New best EMA pseudo Dice: 0.09839999675750732 
2025-01-18 13:57:29.435468:  
2025-01-18 13:57:29.435468: Epoch 5 
2025-01-18 13:57:29.441025: Current learning rate: 0.00982 
2025-01-18 13:58:01.271543: train_loss -0.4299 
2025-01-18 13:58:01.273050: val_loss -0.4414 
2025-01-18 13:58:01.279150: Pseudo dice [np.float32(0.5629), np.float32(0.4063)] 
2025-01-18 13:58:01.282216: Epoch time: 31.84 s 
2025-01-18 13:58:01.285246: Yayy! New best EMA pseudo Dice: 0.1370999962091446 
2025-01-18 13:58:02.071696:  
2025-01-18 13:58:02.072696: Epoch 6 
2025-01-18 13:58:02.077821: Current learning rate: 0.00978 
2025-01-18 13:58:33.919812: train_loss -0.4708 
2025-01-18 13:58:33.919812: val_loss -0.3925 
2025-01-18 13:58:33.926331: Pseudo dice [np.float32(0.5198), np.float32(0.3416)] 
2025-01-18 13:58:33.928837: Epoch time: 31.85 s 
2025-01-18 13:58:33.931871: Yayy! New best EMA pseudo Dice: 0.1664000004529953 
2025-01-18 13:58:34.727891:  
2025-01-18 13:58:34.727891: Epoch 7 
2025-01-18 13:58:34.732966: Current learning rate: 0.00975 
2025-01-18 13:59:06.571351: train_loss -0.4824 
2025-01-18 13:59:06.572876: val_loss -0.4352 
2025-01-18 13:59:06.579404: Pseudo dice [np.float32(0.6459), np.float32(0.2875)] 
2025-01-18 13:59:06.582916: Epoch time: 31.84 s 
2025-01-18 13:59:06.585425: Yayy! New best EMA pseudo Dice: 0.1964000016450882 
2025-01-18 13:59:07.379077:  
2025-01-18 13:59:07.380077: Epoch 8 
2025-01-18 13:59:07.385153: Current learning rate: 0.00971 
2025-01-18 13:59:39.220186: train_loss -0.5143 
2025-01-18 13:59:39.220186: val_loss -0.4568 
2025-01-18 13:59:39.226206: Pseudo dice [np.float32(0.585), np.float32(0.4059)] 
2025-01-18 13:59:39.229217: Epoch time: 31.84 s 
2025-01-18 13:59:39.231763: Yayy! New best EMA pseudo Dice: 0.22630000114440918 
2025-01-18 13:59:40.055772:  
2025-01-18 13:59:40.055772: Epoch 9 
2025-01-18 13:59:40.060794: Current learning rate: 0.00968 
2025-01-18 14:00:11.871736: train_loss -0.5526 
2025-01-18 14:00:11.871736: val_loss -0.5307 
2025-01-18 14:00:11.877758: Pseudo dice [np.float32(0.6795), np.float32(0.4571)] 
2025-01-18 14:00:11.880265: Epoch time: 31.82 s 
2025-01-18 14:00:11.883771: Yayy! New best EMA pseudo Dice: 0.2605000138282776 
2025-01-18 14:00:12.665622:  
2025-01-18 14:00:12.665622: Epoch 10 
2025-01-18 14:00:12.672188: Current learning rate: 0.00964 
2025-01-18 14:00:44.493047: train_loss -0.5598 
2025-01-18 14:00:44.493047: val_loss -0.4937 
2025-01-18 14:00:44.499071: Pseudo dice [np.float32(0.6767), np.float32(0.3713)] 
2025-01-18 14:00:44.502594: Epoch time: 31.83 s 
2025-01-18 14:00:44.505639: Yayy! New best EMA pseudo Dice: 0.28690001368522644 
2025-01-18 14:00:45.292252:  
2025-01-18 14:00:45.292252: Epoch 11 
2025-01-18 14:00:45.297795: Current learning rate: 0.0096 
2025-01-18 14:01:17.135756: train_loss -0.5731 
2025-01-18 14:01:17.136260: val_loss -0.4637 
2025-01-18 14:01:17.142312: Pseudo dice [np.float32(0.6804), np.float32(0.3193)] 
2025-01-18 14:01:17.145365: Epoch time: 31.84 s 
2025-01-18 14:01:17.148874: Yayy! New best EMA pseudo Dice: 0.30820000171661377 
2025-01-18 14:01:18.073172:  
2025-01-18 14:01:18.073172: Epoch 12 
2025-01-18 14:01:18.078210: Current learning rate: 0.00957 
2025-01-18 14:01:49.888467: train_loss -0.5931 
2025-01-18 14:01:49.888969: val_loss -0.444 
2025-01-18 14:01:49.893991: Pseudo dice [np.float32(0.6848), np.float32(0.2847)] 
2025-01-18 14:01:49.897590: Epoch time: 31.82 s 
2025-01-18 14:01:49.900134: Yayy! New best EMA pseudo Dice: 0.32580000162124634 
2025-01-18 14:01:50.698681:  
2025-01-18 14:01:50.698681: Epoch 13 
2025-01-18 14:01:50.702124: Current learning rate: 0.00953 
2025-01-18 14:02:22.518917: train_loss -0.5667 
2025-01-18 14:02:22.519436: val_loss -0.4878 
2025-01-18 14:02:22.524448: Pseudo dice [np.float32(0.6425), np.float32(0.4285)] 
2025-01-18 14:02:22.526954: Epoch time: 31.82 s 
2025-01-18 14:02:22.530468: Yayy! New best EMA pseudo Dice: 0.3467999994754791 
2025-01-18 14:02:23.327587:  
2025-01-18 14:02:23.328591: Epoch 14 
2025-01-18 14:02:23.333141: Current learning rate: 0.00949 
2025-01-18 14:02:55.154754: train_loss -0.583 
2025-01-18 14:02:55.154754: val_loss -0.5345 
2025-01-18 14:02:55.160774: Pseudo dice [np.float32(0.7073), np.float32(0.4802)] 
2025-01-18 14:02:55.163280: Epoch time: 31.83 s 
2025-01-18 14:02:55.165786: Yayy! New best EMA pseudo Dice: 0.3714999854564667 
2025-01-18 14:02:55.990894:  
2025-01-18 14:02:55.990894: Epoch 15 
2025-01-18 14:02:55.997000: Current learning rate: 0.00946 
2025-01-18 14:03:27.813354: train_loss -0.592 
2025-01-18 14:03:27.814355: val_loss -0.4931 
2025-01-18 14:03:27.819873: Pseudo dice [np.float32(0.6824), np.float32(0.3928)] 
2025-01-18 14:03:27.823383: Epoch time: 31.82 s 
2025-01-18 14:03:27.825890: Yayy! New best EMA pseudo Dice: 0.3880999982357025 
2025-01-18 14:03:28.640086:  
2025-01-18 14:03:28.640086: Epoch 16 
2025-01-18 14:03:28.646137: Current learning rate: 0.00942 
2025-01-18 14:04:00.475718: train_loss -0.5887 
2025-01-18 14:04:00.477228: val_loss -0.498 
2025-01-18 14:04:00.482258: Pseudo dice [np.float32(0.6497), np.float32(0.4422)] 
2025-01-18 14:04:00.485779: Epoch time: 31.84 s 
2025-01-18 14:04:00.488801: Yayy! New best EMA pseudo Dice: 0.40389999747276306 
2025-01-18 14:04:01.294352:  
2025-01-18 14:04:01.294352: Epoch 17 
2025-01-18 14:04:01.299481: Current learning rate: 0.00939 
2025-01-18 14:04:33.111572: train_loss -0.6218 
2025-01-18 14:04:33.112077: val_loss -0.5249 
2025-01-18 14:04:33.117091: Pseudo dice [np.float32(0.6696), np.float32(0.4569)] 
2025-01-18 14:04:33.120600: Epoch time: 31.82 s 
2025-01-18 14:04:33.124675: Yayy! New best EMA pseudo Dice: 0.4198000133037567 
2025-01-18 14:04:33.925717:  
2025-01-18 14:04:33.926219: Epoch 18 
2025-01-18 14:04:33.932301: Current learning rate: 0.00935 
2025-01-18 14:05:05.753504: train_loss -0.6363 
2025-01-18 14:05:05.754510: val_loss -0.4939 
2025-01-18 14:05:05.761030: Pseudo dice [np.float32(0.686), np.float32(0.3958)] 
2025-01-18 14:05:05.764069: Epoch time: 31.83 s 
2025-01-18 14:05:05.768598: Yayy! New best EMA pseudo Dice: 0.4318999946117401 
2025-01-18 14:05:06.579017:  
2025-01-18 14:05:06.579017: Epoch 19 
2025-01-18 14:05:06.585030: Current learning rate: 0.00931 
2025-01-18 14:05:38.397061: train_loss -0.6348 
2025-01-18 14:05:38.397564: val_loss -0.4984 
2025-01-18 14:05:38.403643: Pseudo dice [np.float32(0.6989), np.float32(0.3585)] 
2025-01-18 14:05:38.407206: Epoch time: 31.82 s 
2025-01-18 14:05:38.410812: Yayy! New best EMA pseudo Dice: 0.4415999948978424 
2025-01-18 14:05:39.362767:  
2025-01-18 14:05:39.363271: Epoch 20 
2025-01-18 14:05:39.368284: Current learning rate: 0.00928 
2025-01-18 14:06:11.179977: train_loss -0.6348 
2025-01-18 14:06:11.179977: val_loss -0.5295 
2025-01-18 14:06:11.186494: Pseudo dice [np.float32(0.69), np.float32(0.4752)] 
2025-01-18 14:06:11.189035: Epoch time: 31.82 s 
2025-01-18 14:06:11.192544: Yayy! New best EMA pseudo Dice: 0.45570001006126404 
2025-01-18 14:06:12.018739:  
2025-01-18 14:06:12.018739: Epoch 21 
2025-01-18 14:06:12.024292: Current learning rate: 0.00924 
2025-01-18 14:06:43.934558: train_loss -0.6415 
2025-01-18 14:06:43.935069: val_loss -0.4819 
2025-01-18 14:06:43.940599: Pseudo dice [np.float32(0.6901), np.float32(0.3533)] 
2025-01-18 14:06:43.945139: Epoch time: 31.92 s 
2025-01-18 14:06:43.947649: Yayy! New best EMA pseudo Dice: 0.46230000257492065 
2025-01-18 14:06:44.765668:  
2025-01-18 14:06:44.766668: Epoch 22 
2025-01-18 14:06:44.771679: Current learning rate: 0.0092 
2025-01-18 14:07:16.593129: train_loss -0.6307 
2025-01-18 14:07:16.593129: val_loss -0.5154 
2025-01-18 14:07:16.600707: Pseudo dice [np.float32(0.702), np.float32(0.3935)] 
2025-01-18 14:07:16.603829: Epoch time: 31.83 s 
2025-01-18 14:07:16.606375: Yayy! New best EMA pseudo Dice: 0.4708999991416931 
2025-01-18 14:07:17.394925:  
2025-01-18 14:07:17.395427: Epoch 23 
2025-01-18 14:07:17.401442: Current learning rate: 0.00917 
2025-01-18 14:07:49.229951: train_loss -0.6557 
2025-01-18 14:07:49.230952: val_loss -0.486 
2025-01-18 14:07:49.237481: Pseudo dice [np.float32(0.6632), np.float32(0.3844)] 
2025-01-18 14:07:49.241005: Epoch time: 31.84 s 
2025-01-18 14:07:49.244031: Yayy! New best EMA pseudo Dice: 0.47620001435279846 
2025-01-18 14:07:50.049581:  
2025-01-18 14:07:50.050084: Epoch 24 
2025-01-18 14:07:50.055096: Current learning rate: 0.00913 
2025-01-18 14:08:21.889532: train_loss -0.6565 
2025-01-18 14:08:21.890053: val_loss -0.5344 
2025-01-18 14:08:21.895193: Pseudo dice [np.float32(0.6811), np.float32(0.4888)] 
2025-01-18 14:08:21.899247: Epoch time: 31.84 s 
2025-01-18 14:08:21.902255: Yayy! New best EMA pseudo Dice: 0.4869999885559082 
2025-01-18 14:08:22.706023:  
2025-01-18 14:08:22.706023: Epoch 25 
2025-01-18 14:08:22.711069: Current learning rate: 0.0091 
2025-01-18 14:08:54.536451: train_loss -0.6381 
2025-01-18 14:08:54.536955: val_loss -0.525 
2025-01-18 14:08:54.542551: Pseudo dice [np.float32(0.683), np.float32(0.4454)] 
2025-01-18 14:08:54.547634: Epoch time: 31.83 s 
2025-01-18 14:08:54.550244: Yayy! New best EMA pseudo Dice: 0.49470001459121704 
2025-01-18 14:08:55.349312:  
2025-01-18 14:08:55.350316: Epoch 26 
2025-01-18 14:08:55.355873: Current learning rate: 0.00906 
2025-01-18 14:09:27.178220: train_loss -0.6714 
2025-01-18 14:09:27.178722: val_loss -0.5234 
2025-01-18 14:09:27.184742: Pseudo dice [np.float32(0.7253), np.float32(0.4095)] 
2025-01-18 14:09:27.187250: Epoch time: 31.83 s 
2025-01-18 14:09:27.191258: Yayy! New best EMA pseudo Dice: 0.5019999742507935 
2025-01-18 14:09:28.120382:  
2025-01-18 14:09:28.120884: Epoch 27 
2025-01-18 14:09:28.125896: Current learning rate: 0.00902 
2025-01-18 14:09:59.958820: train_loss -0.6752 
2025-01-18 14:09:59.958820: val_loss -0.5193 
2025-01-18 14:09:59.966343: Pseudo dice [np.float32(0.7018), np.float32(0.451)] 
2025-01-18 14:09:59.969861: Epoch time: 31.84 s 
2025-01-18 14:09:59.972884: Yayy! New best EMA pseudo Dice: 0.5095000267028809 
2025-01-18 14:10:00.774568:  
2025-01-18 14:10:00.774568: Epoch 28 
2025-01-18 14:10:00.779607: Current learning rate: 0.00899 
2025-01-18 14:10:32.600014: train_loss -0.6843 
2025-01-18 14:10:32.600519: val_loss -0.5066 
2025-01-18 14:10:32.606585: Pseudo dice [np.float32(0.6631), np.float32(0.4462)] 
2025-01-18 14:10:32.610108: Epoch time: 31.83 s 
2025-01-18 14:10:32.612645: Yayy! New best EMA pseudo Dice: 0.5139999985694885 
2025-01-18 14:10:33.409079:  
2025-01-18 14:10:33.409589: Epoch 29 
2025-01-18 14:10:33.414675: Current learning rate: 0.00895 
2025-01-18 14:11:05.225496: train_loss -0.6619 
2025-01-18 14:11:05.226017: val_loss -0.5133 
2025-01-18 14:11:05.233038: Pseudo dice [np.float32(0.6829), np.float32(0.4555)] 
2025-01-18 14:11:05.235810: Epoch time: 31.82 s 
2025-01-18 14:11:05.239826: Yayy! New best EMA pseudo Dice: 0.5195000171661377 
2025-01-18 14:11:06.033703:  
2025-01-18 14:11:06.033703: Epoch 30 
2025-01-18 14:11:06.039276: Current learning rate: 0.00891 
2025-01-18 14:11:37.857104: train_loss -0.6595 
2025-01-18 14:11:37.858109: val_loss -0.5124 
2025-01-18 14:11:37.863128: Pseudo dice [np.float32(0.6911), np.float32(0.4335)] 
2025-01-18 14:11:37.867139: Epoch time: 31.82 s 
2025-01-18 14:11:37.870667: Yayy! New best EMA pseudo Dice: 0.5238000154495239 
2025-01-18 14:11:38.697216:  
2025-01-18 14:11:38.698216: Epoch 31 
2025-01-18 14:11:38.703336: Current learning rate: 0.00888 
2025-01-18 14:12:10.512049: train_loss -0.6882 
2025-01-18 14:12:10.513564: val_loss -0.5438 
2025-01-18 14:12:10.519744: Pseudo dice [np.float32(0.6848), np.float32(0.4936)] 
2025-01-18 14:12:10.522290: Epoch time: 31.81 s 
2025-01-18 14:12:10.526860: Yayy! New best EMA pseudo Dice: 0.5303000211715698 
2025-01-18 14:12:11.330224:  
2025-01-18 14:12:11.331227: Epoch 32 
2025-01-18 14:12:11.335269: Current learning rate: 0.00884 
2025-01-18 14:12:43.170200: train_loss -0.6761 
2025-01-18 14:12:43.170703: val_loss -0.5349 
2025-01-18 14:12:43.175723: Pseudo dice [np.float32(0.6939), np.float32(0.4707)] 
2025-01-18 14:12:43.179748: Epoch time: 31.84 s 
2025-01-18 14:12:43.182786: Yayy! New best EMA pseudo Dice: 0.5354999899864197 
2025-01-18 14:12:43.982811:  
2025-01-18 14:12:43.982811: Epoch 33 
2025-01-18 14:12:43.988847: Current learning rate: 0.0088 
2025-01-18 14:13:15.825278: train_loss -0.6873 
2025-01-18 14:13:15.825278: val_loss -0.4638 
2025-01-18 14:13:15.831294: Pseudo dice [np.float32(0.7049), np.float32(0.3182)] 
2025-01-18 14:13:15.834339: Epoch time: 31.84 s 
2025-01-18 14:13:16.389655:  
2025-01-18 14:13:16.389655: Epoch 34 
2025-01-18 14:13:16.395216: Current learning rate: 0.00877 
2025-01-18 14:13:48.215127: train_loss -0.7245 
2025-01-18 14:13:48.215127: val_loss -0.5123 
2025-01-18 14:13:48.221645: Pseudo dice [np.float32(0.7111), np.float32(0.3991)] 
2025-01-18 14:13:48.224674: Epoch time: 31.83 s 
2025-01-18 14:13:48.929401:  
2025-01-18 14:13:48.929401: Epoch 35 
2025-01-18 14:13:48.935440: Current learning rate: 0.00873 
2025-01-18 14:14:20.760535: train_loss -0.7178 
2025-01-18 14:14:20.760535: val_loss -0.4952 
2025-01-18 14:14:20.767050: Pseudo dice [np.float32(0.6955), np.float32(0.4216)] 
2025-01-18 14:14:20.770078: Epoch time: 31.83 s 
2025-01-18 14:14:20.773626: Yayy! New best EMA pseudo Dice: 0.5375999808311462 
2025-01-18 14:14:21.594617:  
2025-01-18 14:14:21.594617: Epoch 36 
2025-01-18 14:14:21.597642: Current learning rate: 0.00869 
2025-01-18 14:14:53.420407: train_loss -0.7218 
2025-01-18 14:14:53.420407: val_loss -0.487 
2025-01-18 14:14:53.425420: Pseudo dice [np.float32(0.6938), np.float32(0.3325)] 
2025-01-18 14:14:53.429431: Epoch time: 31.83 s 
2025-01-18 14:14:54.003457:  
2025-01-18 14:14:54.003457: Epoch 37 
2025-01-18 14:14:54.009524: Current learning rate: 0.00866 
2025-01-18 14:15:25.835156: train_loss -0.6982 
2025-01-18 14:15:25.836157: val_loss -0.4586 
2025-01-18 14:15:25.841673: Pseudo dice [np.float32(0.6852), np.float32(0.2913)] 
2025-01-18 14:15:25.845184: Epoch time: 31.83 s 
2025-01-18 14:15:26.406013:  
2025-01-18 14:15:26.406013: Epoch 38 
2025-01-18 14:15:26.411558: Current learning rate: 0.00862 
2025-01-18 14:15:58.238526: train_loss -0.7044 
2025-01-18 14:15:58.239526: val_loss -0.4913 
2025-01-18 14:15:58.246053: Pseudo dice [np.float32(0.677), np.float32(0.3573)] 
2025-01-18 14:15:58.248556: Epoch time: 31.83 s 
2025-01-18 14:15:58.814959:  
2025-01-18 14:15:58.814959: Epoch 39 
2025-01-18 14:15:58.819971: Current learning rate: 0.00858 
2025-01-18 14:16:30.651627: train_loss -0.6956 
2025-01-18 14:16:30.652626: val_loss -0.5251 
2025-01-18 14:16:30.658142: Pseudo dice [np.float32(0.6929), np.float32(0.4138)] 
2025-01-18 14:16:30.662663: Epoch time: 31.84 s 
2025-01-18 14:16:31.234673:  
2025-01-18 14:16:31.234673: Epoch 40 
2025-01-18 14:16:31.240196: Current learning rate: 0.00855 
2025-01-18 14:17:03.075722: train_loss -0.7326 
2025-01-18 14:17:03.077236: val_loss -0.4824 
2025-01-18 14:17:03.084773: Pseudo dice [np.float32(0.7029), np.float32(0.3968)] 
2025-01-18 14:17:03.088292: Epoch time: 31.84 s 
2025-01-18 14:17:03.664126:  
2025-01-18 14:17:03.665129: Epoch 41 
2025-01-18 14:17:03.669698: Current learning rate: 0.00851 
2025-01-18 14:17:35.504294: train_loss -0.7171 
2025-01-18 14:17:35.504294: val_loss -0.5106 
2025-01-18 14:17:35.509365: Pseudo dice [np.float32(0.7024), np.float32(0.411)] 
2025-01-18 14:17:35.513919: Epoch time: 31.84 s 
2025-01-18 14:17:36.202885:  
2025-01-18 14:17:36.203889: Epoch 42 
2025-01-18 14:17:36.208486: Current learning rate: 0.00847 
2025-01-18 14:18:08.038040: train_loss -0.7268 
2025-01-18 14:18:08.038544: val_loss -0.4852 
2025-01-18 14:18:08.045568: Pseudo dice [np.float32(0.6962), np.float32(0.3912)] 
2025-01-18 14:18:08.048602: Epoch time: 31.84 s 
2025-01-18 14:18:08.588101:  
2025-01-18 14:18:08.588101: Epoch 43 
2025-01-18 14:18:08.594199: Current learning rate: 0.00844 
2025-01-18 14:18:40.428936: train_loss -0.7285 
2025-01-18 14:18:40.429939: val_loss -0.5116 
2025-01-18 14:18:40.434631: Pseudo dice [np.float32(0.6846), np.float32(0.4445)] 
2025-01-18 14:18:40.438647: Epoch time: 31.84 s 
2025-01-18 14:18:40.441713: Yayy! New best EMA pseudo Dice: 0.5393000245094299 
2025-01-18 14:18:41.247004:  
2025-01-18 14:18:41.247004: Epoch 44 
2025-01-18 14:18:41.252187: Current learning rate: 0.0084 
2025-01-18 14:19:13.070382: train_loss -0.7069 
2025-01-18 14:19:13.070896: val_loss -0.5102 
2025-01-18 14:19:13.076911: Pseudo dice [np.float32(0.7083), np.float32(0.376)] 
2025-01-18 14:19:13.080456: Epoch time: 31.82 s 
2025-01-18 14:19:13.083515: Yayy! New best EMA pseudo Dice: 0.5396000146865845 
2025-01-18 14:19:13.902843:  
2025-01-18 14:19:13.902843: Epoch 45 
2025-01-18 14:19:13.907972: Current learning rate: 0.00836 
2025-01-18 14:19:45.740882: train_loss -0.7308 
2025-01-18 14:19:45.741394: val_loss -0.5395 
2025-01-18 14:19:45.747409: Pseudo dice [np.float32(0.7338), np.float32(0.4955)] 
2025-01-18 14:19:45.750925: Epoch time: 31.84 s 
2025-01-18 14:19:45.753974: Yayy! New best EMA pseudo Dice: 0.5471000075340271 
2025-01-18 14:19:46.550850:  
2025-01-18 14:19:46.550850: Epoch 46 
2025-01-18 14:19:46.555862: Current learning rate: 0.00833 
2025-01-18 14:20:18.375153: train_loss -0.7292 
2025-01-18 14:20:18.376655: val_loss -0.531 
2025-01-18 14:20:18.384179: Pseudo dice [np.float32(0.6747), np.float32(0.5133)] 
2025-01-18 14:20:18.387692: Epoch time: 31.82 s 
2025-01-18 14:20:18.390706: Yayy! New best EMA pseudo Dice: 0.551800012588501 
2025-01-18 14:20:19.171323:  
2025-01-18 14:20:19.172324: Epoch 47 
2025-01-18 14:20:19.177890: Current learning rate: 0.00829 
2025-01-18 14:20:51.013158: train_loss -0.7347 
2025-01-18 14:20:51.013660: val_loss -0.5248 
2025-01-18 14:20:51.019677: Pseudo dice [np.float32(0.7213), np.float32(0.4256)] 
2025-01-18 14:20:51.023183: Epoch time: 31.84 s 
2025-01-18 14:20:51.026192: Yayy! New best EMA pseudo Dice: 0.5540000200271606 
2025-01-18 14:20:51.818784:  
2025-01-18 14:20:51.819287: Epoch 48 
2025-01-18 14:20:51.825301: Current learning rate: 0.00825 
2025-01-18 14:21:23.646374: train_loss -0.7594 
2025-01-18 14:21:23.647379: val_loss -0.4778 
2025-01-18 14:21:23.653372: Pseudo dice [np.float32(0.7123), np.float32(0.3528)] 
2025-01-18 14:21:23.655879: Epoch time: 31.83 s 
2025-01-18 14:21:24.206999:  
2025-01-18 14:21:24.207999: Epoch 49 
2025-01-18 14:21:24.212540: Current learning rate: 0.00822 
2025-01-18 14:21:56.065597: train_loss -0.7456 
2025-01-18 14:21:56.067109: val_loss -0.4768 
2025-01-18 14:21:56.072870: Pseudo dice [np.float32(0.7023), np.float32(0.3247)] 
2025-01-18 14:21:56.077384: Epoch time: 31.86 s 
2025-01-18 14:21:56.991369:  
2025-01-18 14:21:56.991369: Epoch 50 
2025-01-18 14:21:56.997889: Current learning rate: 0.00818 
2025-01-18 14:22:28.827206: train_loss -0.7357 
2025-01-18 14:22:28.828211: val_loss -0.511 
2025-01-18 14:22:28.834629: Pseudo dice [np.float32(0.7071), np.float32(0.4003)] 
2025-01-18 14:22:28.838197: Epoch time: 31.84 s 
2025-01-18 14:22:29.379879:  
2025-01-18 14:22:29.379879: Epoch 51 
2025-01-18 14:22:29.384917: Current learning rate: 0.00814 
2025-01-18 14:23:01.216995: train_loss -0.7525 
2025-01-18 14:23:01.217510: val_loss -0.5231 
2025-01-18 14:23:01.222548: Pseudo dice [np.float32(0.7202), np.float32(0.3892)] 
2025-01-18 14:23:01.226092: Epoch time: 31.84 s 
2025-01-18 14:23:01.763078:  
2025-01-18 14:23:01.763078: Epoch 52 
2025-01-18 14:23:01.768629: Current learning rate: 0.00811 
2025-01-18 14:23:33.597045: train_loss -0.7655 
2025-01-18 14:23:33.598048: val_loss -0.5071 
2025-01-18 14:23:33.603419: Pseudo dice [np.float32(0.6682), np.float32(0.4115)] 
2025-01-18 14:23:33.605929: Epoch time: 31.83 s 
2025-01-18 14:23:34.148397:  
2025-01-18 14:23:34.149400: Epoch 53 
2025-01-18 14:23:34.154433: Current learning rate: 0.00807 
2025-01-18 14:24:05.983960: train_loss -0.7771 
2025-01-18 14:24:05.984462: val_loss -0.5101 
2025-01-18 14:24:05.991074: Pseudo dice [np.float32(0.7121), np.float32(0.3727)] 
2025-01-18 14:24:05.994103: Epoch time: 31.84 s 
2025-01-18 14:24:06.539399:  
2025-01-18 14:24:06.539399: Epoch 54 
2025-01-18 14:24:06.544957: Current learning rate: 0.00803 
2025-01-18 14:24:38.374814: train_loss -0.7716 
2025-01-18 14:24:38.375814: val_loss -0.5162 
2025-01-18 14:24:38.381332: Pseudo dice [np.float32(0.718), np.float32(0.3884)] 
2025-01-18 14:24:38.384844: Epoch time: 31.84 s 
2025-01-18 14:24:38.937402:  
2025-01-18 14:24:38.937402: Epoch 55 
2025-01-18 14:24:38.942414: Current learning rate: 0.008 
2025-01-18 14:25:10.804358: train_loss -0.7881 
2025-01-18 14:25:10.804862: val_loss -0.5139 
2025-01-18 14:25:10.810882: Pseudo dice [np.float32(0.7156), np.float32(0.4903)] 
2025-01-18 14:25:10.813386: Epoch time: 31.87 s 
2025-01-18 14:25:11.366555:  
2025-01-18 14:25:11.366555: Epoch 56 
2025-01-18 14:25:11.371581: Current learning rate: 0.00796 
2025-01-18 14:25:43.211753: train_loss -0.7648 
2025-01-18 14:25:43.211753: val_loss -0.4864 
2025-01-18 14:25:43.217775: Pseudo dice [np.float32(0.7099), np.float32(0.3488)] 
2025-01-18 14:25:43.221305: Epoch time: 31.85 s 
2025-01-18 14:25:43.783703:  
2025-01-18 14:25:43.783703: Epoch 57 
2025-01-18 14:25:43.788714: Current learning rate: 0.00792 
2025-01-18 14:26:15.616995: train_loss -0.7859 
2025-01-18 14:26:15.617998: val_loss -0.5314 
2025-01-18 14:26:15.624015: Pseudo dice [np.float32(0.7068), np.float32(0.4647)] 
2025-01-18 14:26:15.627024: Epoch time: 31.83 s 
2025-01-18 14:26:15.629587: Yayy! New best EMA pseudo Dice: 0.5547000169754028 
2025-01-18 14:26:16.555379:  
2025-01-18 14:26:16.555379: Epoch 58 
2025-01-18 14:26:16.560894: Current learning rate: 0.00789 
2025-01-18 14:26:48.356219: train_loss -0.7847 
2025-01-18 14:26:48.356219: val_loss -0.5439 
2025-01-18 14:26:48.362741: Pseudo dice [np.float32(0.7419), np.float32(0.432)] 
2025-01-18 14:26:48.366771: Epoch time: 31.8 s 
2025-01-18 14:26:48.370318: Yayy! New best EMA pseudo Dice: 0.5579000115394592 
2025-01-18 14:26:49.159300:  
2025-01-18 14:26:49.160300: Epoch 59 
2025-01-18 14:26:49.165816: Current learning rate: 0.00785 
2025-01-18 14:27:20.976884: train_loss -0.7919 
2025-01-18 14:27:20.977883: val_loss -0.4816 
2025-01-18 14:27:20.983399: Pseudo dice [np.float32(0.716), np.float32(0.3119)] 
2025-01-18 14:27:20.986908: Epoch time: 31.82 s 
2025-01-18 14:27:21.534878:  
2025-01-18 14:27:21.534878: Epoch 60 
2025-01-18 14:27:21.540529: Current learning rate: 0.00781 
2025-01-18 14:27:53.332348: train_loss -0.7829 
2025-01-18 14:27:53.332852: val_loss -0.5389 
2025-01-18 14:27:53.339056: Pseudo dice [np.float32(0.7143), np.float32(0.4954)] 
2025-01-18 14:27:53.342603: Epoch time: 31.8 s 
2025-01-18 14:27:53.346653: Yayy! New best EMA pseudo Dice: 0.5587000250816345 
2025-01-18 14:27:54.146774:  
2025-01-18 14:27:54.147780: Epoch 61 
2025-01-18 14:27:54.153451: Current learning rate: 0.00777 
2025-01-18 14:28:25.957953: train_loss -0.7917 
2025-01-18 14:28:25.958456: val_loss -0.47 
2025-01-18 14:28:25.964476: Pseudo dice [np.float32(0.7298), np.float32(0.2787)] 
2025-01-18 14:28:25.967486: Epoch time: 31.81 s 
2025-01-18 14:28:26.512458:  
2025-01-18 14:28:26.513459: Epoch 62 
2025-01-18 14:28:26.518520: Current learning rate: 0.00774 
2025-01-18 14:28:58.327241: train_loss -0.8007 
2025-01-18 14:28:58.327241: val_loss -0.4776 
2025-01-18 14:28:58.333756: Pseudo dice [np.float32(0.7357), np.float32(0.3601)] 
2025-01-18 14:28:58.337770: Epoch time: 31.81 s 
2025-01-18 14:28:58.883834:  
2025-01-18 14:28:58.883834: Epoch 63 
2025-01-18 14:28:58.888364: Current learning rate: 0.0077 
2025-01-18 14:29:30.704623: train_loss -0.7906 
2025-01-18 14:29:30.705125: val_loss -0.5263 
2025-01-18 14:29:30.711722: Pseudo dice [np.float32(0.7215), np.float32(0.4187)] 
2025-01-18 14:29:30.715752: Epoch time: 31.82 s 
2025-01-18 14:29:31.261657:  
2025-01-18 14:29:31.261657: Epoch 64 
2025-01-18 14:29:31.267269: Current learning rate: 0.00766 
2025-01-18 14:30:03.085166: train_loss -0.7876 
2025-01-18 14:30:03.085166: val_loss -0.4731 
2025-01-18 14:30:03.091182: Pseudo dice [np.float32(0.6955), np.float32(0.366)] 
2025-01-18 14:30:03.095195: Epoch time: 31.82 s 
2025-01-18 14:30:03.787050:  
2025-01-18 14:30:03.788049: Epoch 65 
2025-01-18 14:30:03.793662: Current learning rate: 0.00763 
2025-01-18 14:30:35.611198: train_loss -0.7851 
2025-01-18 14:30:35.611198: val_loss -0.5104 
2025-01-18 14:30:35.618721: Pseudo dice [np.float32(0.7095), np.float32(0.4082)] 
2025-01-18 14:30:35.622728: Epoch time: 31.83 s 
2025-01-18 14:30:36.176853:  
2025-01-18 14:30:36.177356: Epoch 66 
2025-01-18 14:30:36.182430: Current learning rate: 0.00759 
2025-01-18 14:31:07.987955: train_loss -0.7946 
2025-01-18 14:31:07.987955: val_loss -0.4757 
2025-01-18 14:31:07.994470: Pseudo dice [np.float32(0.7042), np.float32(0.3994)] 
2025-01-18 14:31:07.998484: Epoch time: 31.81 s 
2025-01-18 14:31:08.544539:  
2025-01-18 14:31:08.545542: Epoch 67 
2025-01-18 14:31:08.550572: Current learning rate: 0.00755 
2025-01-18 14:31:40.352543: train_loss -0.7819 
2025-01-18 14:31:40.352543: val_loss -0.484 
2025-01-18 14:31:40.358030: Pseudo dice [np.float32(0.6874), np.float32(0.3949)] 
2025-01-18 14:31:40.362133: Epoch time: 31.81 s 
2025-01-18 14:31:40.918272:  
2025-01-18 14:31:40.919274: Epoch 68 
2025-01-18 14:31:40.924864: Current learning rate: 0.00751 
2025-01-18 14:32:12.730934: train_loss -0.7987 
2025-01-18 14:32:12.731935: val_loss -0.4903 
2025-01-18 14:32:12.737481: Pseudo dice [np.float32(0.7168), np.float32(0.4099)] 
2025-01-18 14:32:12.740500: Epoch time: 31.81 s 
2025-01-18 14:32:13.308714:  
2025-01-18 14:32:13.308714: Epoch 69 
2025-01-18 14:32:13.314323: Current learning rate: 0.00748 
2025-01-18 14:32:45.134406: train_loss -0.8024 
2025-01-18 14:32:45.134406: val_loss -0.5072 
2025-01-18 14:32:45.140925: Pseudo dice [np.float32(0.695), np.float32(0.414)] 
2025-01-18 14:32:45.143456: Epoch time: 31.83 s 
2025-01-18 14:32:45.708557:  
2025-01-18 14:32:45.708557: Epoch 70 
2025-01-18 14:32:45.714633: Current learning rate: 0.00744 
2025-01-18 14:33:17.501706: train_loss -0.8075 
2025-01-18 14:33:17.502219: val_loss -0.4483 
2025-01-18 14:33:17.509742: Pseudo dice [np.float32(0.6954), np.float32(0.2289)] 
2025-01-18 14:33:17.513268: Epoch time: 31.79 s 
2025-01-18 14:33:18.070204:  
2025-01-18 14:33:18.070204: Epoch 71 
2025-01-18 14:33:18.076218: Current learning rate: 0.0074 
2025-01-18 14:33:49.894100: train_loss -0.8092 
2025-01-18 14:33:49.894604: val_loss -0.4869 
2025-01-18 14:33:49.899629: Pseudo dice [np.float32(0.7175), np.float32(0.3817)] 
2025-01-18 14:33:49.903143: Epoch time: 31.83 s 
2025-01-18 14:33:50.462295:  
2025-01-18 14:33:50.462295: Epoch 72 
2025-01-18 14:33:50.467307: Current learning rate: 0.00737 
2025-01-18 14:34:22.266988: train_loss -0.8134 
2025-01-18 14:34:22.266988: val_loss -0.4779 
2025-01-18 14:34:22.273511: Pseudo dice [np.float32(0.6975), np.float32(0.31)] 
2025-01-18 14:34:22.276016: Epoch time: 31.81 s 
2025-01-18 14:34:22.979461:  
2025-01-18 14:34:22.979461: Epoch 73 
2025-01-18 14:34:22.985567: Current learning rate: 0.00733 
2025-01-18 14:34:54.783355: train_loss -0.8111 
2025-01-18 14:34:54.783355: val_loss -0.4868 
2025-01-18 14:34:54.790404: Pseudo dice [np.float32(0.7064), np.float32(0.3352)] 
2025-01-18 14:34:54.793913: Epoch time: 31.8 s 
2025-01-18 14:34:55.347927:  
2025-01-18 14:34:55.347927: Epoch 74 
2025-01-18 14:34:55.354028: Current learning rate: 0.00729 
2025-01-18 14:35:27.146163: train_loss -0.8115 
2025-01-18 14:35:27.147164: val_loss -0.4631 
2025-01-18 14:35:27.152681: Pseudo dice [np.float32(0.7279), np.float32(0.2719)] 
2025-01-18 14:35:27.156191: Epoch time: 31.8 s 
2025-01-18 14:35:27.710131:  
2025-01-18 14:35:27.710131: Epoch 75 
2025-01-18 14:35:27.714164: Current learning rate: 0.00725 
2025-01-18 14:35:59.512175: train_loss -0.812 
2025-01-18 14:35:59.512175: val_loss -0.4982 
2025-01-18 14:35:59.519693: Pseudo dice [np.float32(0.7128), np.float32(0.3426)] 
2025-01-18 14:35:59.524204: Epoch time: 31.8 s 
2025-01-18 14:36:00.085712:  
2025-01-18 14:36:00.085712: Epoch 76 
2025-01-18 14:36:00.092295: Current learning rate: 0.00722 
2025-01-18 14:36:31.881806: train_loss -0.8047 
2025-01-18 14:36:31.882810: val_loss -0.5207 
2025-01-18 14:36:31.888823: Pseudo dice [np.float32(0.7171), np.float32(0.4123)] 
2025-01-18 14:36:31.892836: Epoch time: 31.8 s 
2025-01-18 14:36:32.455093:  
2025-01-18 14:36:32.455093: Epoch 77 
2025-01-18 14:36:32.461107: Current learning rate: 0.00718 
2025-01-18 14:37:04.259525: train_loss -0.7957 
2025-01-18 14:37:04.260045: val_loss -0.5273 
2025-01-18 14:37:04.266060: Pseudo dice [np.float32(0.7295), np.float32(0.4245)] 
2025-01-18 14:37:04.270132: Epoch time: 31.81 s 
2025-01-18 14:37:04.836390:  
2025-01-18 14:37:04.836893: Epoch 78 
2025-01-18 14:37:04.843907: Current learning rate: 0.00714 
2025-01-18 14:37:36.650136: train_loss -0.8029 
2025-01-18 14:37:36.650136: val_loss -0.4874 
2025-01-18 14:37:36.657661: Pseudo dice [np.float32(0.743), np.float32(0.2723)] 
2025-01-18 14:37:36.661172: Epoch time: 31.81 s 
2025-01-18 14:37:37.228569:  
2025-01-18 14:37:37.228569: Epoch 79 
2025-01-18 14:37:37.234587: Current learning rate: 0.0071 
2025-01-18 14:38:09.024542: train_loss -0.8189 
2025-01-18 14:38:09.025046: val_loss -0.489 
2025-01-18 14:38:09.031063: Pseudo dice [np.float32(0.7183), np.float32(0.3179)] 
2025-01-18 14:38:09.036076: Epoch time: 31.8 s 
2025-01-18 14:38:09.617993:  
2025-01-18 14:38:09.617993: Epoch 80 
2025-01-18 14:38:09.624010: Current learning rate: 0.00707 
2025-01-18 14:38:41.428436: train_loss -0.8031 
2025-01-18 14:38:41.429444: val_loss -0.4323 
2025-01-18 14:38:41.434451: Pseudo dice [np.float32(0.7159), np.float32(0.2131)] 
2025-01-18 14:38:41.437964: Epoch time: 31.81 s 
2025-01-18 14:38:42.150239:  
2025-01-18 14:38:42.151239: Epoch 81 
2025-01-18 14:38:42.156834: Current learning rate: 0.00703 
2025-01-18 14:39:13.978036: train_loss -0.8107 
2025-01-18 14:39:13.978036: val_loss -0.4435 
2025-01-18 14:39:13.985562: Pseudo dice [np.float32(0.7174), np.float32(0.2666)] 
2025-01-18 14:39:13.990103: Epoch time: 31.83 s 
2025-01-18 14:39:14.553298:  
2025-01-18 14:39:14.553802: Epoch 82 
2025-01-18 14:39:14.559818: Current learning rate: 0.00699 
2025-01-18 14:39:46.364742: train_loss -0.8196 
2025-01-18 14:39:46.365748: val_loss -0.4914 
2025-01-18 14:39:46.373268: Pseudo dice [np.float32(0.7227), np.float32(0.3898)] 
2025-01-18 14:39:46.378280: Epoch time: 31.81 s 
2025-01-18 14:39:46.908698:  
2025-01-18 14:39:46.909702: Epoch 83 
2025-01-18 14:39:46.915750: Current learning rate: 0.00696 
2025-01-18 14:40:18.721470: train_loss -0.8142 
2025-01-18 14:40:18.723023: val_loss -0.4909 
2025-01-18 14:40:18.729269: Pseudo dice [np.float32(0.7216), np.float32(0.3706)] 
2025-01-18 14:40:18.734832: Epoch time: 31.81 s 
2025-01-18 14:40:19.270096:  
2025-01-18 14:40:19.271099: Epoch 84 
2025-01-18 14:40:19.278239: Current learning rate: 0.00692 
2025-01-18 14:40:51.078452: train_loss -0.8092 
2025-01-18 14:40:51.078452: val_loss -0.4575 
2025-01-18 14:40:51.084471: Pseudo dice [np.float32(0.6995), np.float32(0.2997)] 
2025-01-18 14:40:51.089022: Epoch time: 31.81 s 
2025-01-18 14:40:51.628628:  
2025-01-18 14:40:51.628628: Epoch 85 
2025-01-18 14:40:51.632648: Current learning rate: 0.00688 
2025-01-18 14:41:23.446892: train_loss -0.8328 
2025-01-18 14:41:23.446892: val_loss -0.5202 
2025-01-18 14:41:23.454421: Pseudo dice [np.float32(0.6964), np.float32(0.4639)] 
2025-01-18 14:41:23.460433: Epoch time: 31.82 s 
2025-01-18 14:41:23.989879:  
2025-01-18 14:41:23.990384: Epoch 86 
2025-01-18 14:41:23.997904: Current learning rate: 0.00684 
2025-01-18 14:41:55.800876: train_loss -0.808 
2025-01-18 14:41:55.800876: val_loss -0.5015 
2025-01-18 14:41:55.808488: Pseudo dice [np.float32(0.7165), np.float32(0.359)] 
2025-01-18 14:41:55.813637: Epoch time: 31.81 s 
2025-01-18 14:41:56.353382:  
2025-01-18 14:41:56.354382: Epoch 87 
2025-01-18 14:41:56.358923: Current learning rate: 0.0068 
2025-01-18 14:42:28.178085: train_loss -0.8278 
2025-01-18 14:42:28.178085: val_loss -0.4762 
2025-01-18 14:42:28.184634: Pseudo dice [np.float32(0.701), np.float32(0.3488)] 
2025-01-18 14:42:28.188173: Epoch time: 31.82 s 
2025-01-18 14:42:28.719334:  
2025-01-18 14:42:28.720340: Epoch 88 
2025-01-18 14:42:28.727465: Current learning rate: 0.00677 
2025-01-18 14:43:00.532400: train_loss -0.8314 
2025-01-18 14:43:00.533401: val_loss -0.4786 
2025-01-18 14:43:00.540920: Pseudo dice [np.float32(0.7211), np.float32(0.3816)] 
2025-01-18 14:43:00.543928: Epoch time: 31.81 s 
2025-01-18 14:43:01.226379:  
2025-01-18 14:43:01.226379: Epoch 89 
2025-01-18 14:43:01.231914: Current learning rate: 0.00673 
2025-01-18 14:43:33.028519: train_loss -0.8321 
2025-01-18 14:43:33.029523: val_loss -0.4845 
2025-01-18 14:43:33.035537: Pseudo dice [np.float32(0.7103), np.float32(0.3983)] 
2025-01-18 14:43:33.038608: Epoch time: 31.8 s 
2025-01-18 14:43:33.567491:  
2025-01-18 14:43:33.567491: Epoch 90 
2025-01-18 14:43:33.573081: Current learning rate: 0.00669 
2025-01-18 14:44:05.366393: train_loss -0.8348 
2025-01-18 14:44:05.366909: val_loss -0.4713 
2025-01-18 14:44:05.374551: Pseudo dice [np.float32(0.7241), np.float32(0.2968)] 
2025-01-18 14:44:05.378638: Epoch time: 31.8 s 
2025-01-18 14:44:05.908432:  
2025-01-18 14:44:05.908936: Epoch 91 
2025-01-18 14:44:05.912445: Current learning rate: 0.00665 
2025-01-18 14:44:37.703909: train_loss -0.8421 
2025-01-18 14:44:37.703909: val_loss -0.4851 
2025-01-18 14:44:37.710431: Pseudo dice [np.float32(0.6994), np.float32(0.3157)] 
2025-01-18 14:44:37.712939: Epoch time: 31.8 s 
2025-01-18 14:44:38.241495:  
2025-01-18 14:44:38.242495: Epoch 92 
2025-01-18 14:44:38.247569: Current learning rate: 0.00662 
2025-01-18 14:45:10.047172: train_loss -0.8389 
2025-01-18 14:45:10.047686: val_loss -0.466 
2025-01-18 14:45:10.054375: Pseudo dice [np.float32(0.7159), np.float32(0.3474)] 
2025-01-18 14:45:10.058426: Epoch time: 31.81 s 
2025-01-18 14:45:10.601993:  
2025-01-18 14:45:10.602542: Epoch 93 
2025-01-18 14:45:10.608155: Current learning rate: 0.00658 
2025-01-18 14:45:42.407154: train_loss -0.8282 
2025-01-18 14:45:42.407154: val_loss -0.4886 
2025-01-18 14:45:42.413676: Pseudo dice [np.float32(0.7225), np.float32(0.3525)] 
2025-01-18 14:45:42.417184: Epoch time: 31.81 s 
2025-01-18 14:45:42.999596:  
2025-01-18 14:45:43.000100: Epoch 94 
2025-01-18 14:45:43.005110: Current learning rate: 0.00654 
2025-01-18 14:46:14.806901: train_loss -0.8456 
2025-01-18 14:46:14.807418: val_loss -0.4925 
2025-01-18 14:46:14.813468: Pseudo dice [np.float32(0.7053), np.float32(0.3751)] 
2025-01-18 14:46:14.815712: Epoch time: 31.81 s 
2025-01-18 14:46:15.359587:  
2025-01-18 14:46:15.359587: Epoch 95 
2025-01-18 14:46:15.365641: Current learning rate: 0.0065 
2025-01-18 14:46:47.166270: train_loss -0.8369 
2025-01-18 14:46:47.167276: val_loss -0.4999 
2025-01-18 14:46:47.173800: Pseudo dice [np.float32(0.7218), np.float32(0.336)] 
2025-01-18 14:46:47.177343: Epoch time: 31.81 s 
2025-01-18 14:46:47.717158:  
2025-01-18 14:46:47.717158: Epoch 96 
2025-01-18 14:46:47.723198: Current learning rate: 0.00647 
2025-01-18 14:47:19.538687: train_loss -0.8452 
2025-01-18 14:47:19.538687: val_loss -0.5063 
2025-01-18 14:47:19.545212: Pseudo dice [np.float32(0.7321), np.float32(0.4008)] 
2025-01-18 14:47:19.548754: Epoch time: 31.82 s 
2025-01-18 14:47:20.248148:  
2025-01-18 14:47:20.249146: Epoch 97 
2025-01-18 14:47:20.254202: Current learning rate: 0.00643 
2025-01-18 14:47:52.051186: train_loss -0.8462 
2025-01-18 14:47:52.052696: val_loss -0.4561 
2025-01-18 14:47:52.058235: Pseudo dice [np.float32(0.691), np.float32(0.3309)] 
2025-01-18 14:47:52.062755: Epoch time: 31.8 s 
2025-01-18 14:47:52.613680:  
2025-01-18 14:47:52.613680: Epoch 98 
2025-01-18 14:47:52.620256: Current learning rate: 0.00639 
2025-01-18 14:48:24.418759: train_loss -0.8347 
2025-01-18 14:48:24.419262: val_loss -0.4649 
2025-01-18 14:48:24.425277: Pseudo dice [np.float32(0.7008), np.float32(0.3228)] 
2025-01-18 14:48:24.428782: Epoch time: 31.81 s 
2025-01-18 14:48:24.974949:  
2025-01-18 14:48:24.974949: Epoch 99 
2025-01-18 14:48:24.980465: Current learning rate: 0.00635 
2025-01-18 14:48:56.777460: train_loss -0.8421 
2025-01-18 14:48:56.777962: val_loss -0.4465 
2025-01-18 14:48:56.782471: Pseudo dice [np.float32(0.7164), np.float32(0.2763)] 
2025-01-18 14:48:56.785482: Epoch time: 31.8 s 
2025-01-18 14:48:57.579592:  
2025-01-18 14:48:57.579592: Epoch 100 
2025-01-18 14:48:57.585149: Current learning rate: 0.00631 
2025-01-18 14:49:29.379288: train_loss -0.8309 
2025-01-18 14:49:29.379798: val_loss -0.4948 
2025-01-18 14:49:29.385846: Pseudo dice [np.float32(0.7155), np.float32(0.3024)] 
2025-01-18 14:49:29.388935: Epoch time: 31.8 s 
2025-01-18 14:49:29.939767:  
2025-01-18 14:49:29.940770: Epoch 101 
2025-01-18 14:49:29.945339: Current learning rate: 0.00628 
2025-01-18 14:50:01.753139: train_loss -0.8412 
2025-01-18 14:50:01.753643: val_loss -0.476 
2025-01-18 14:50:01.758656: Pseudo dice [np.float32(0.6959), np.float32(0.3312)] 
2025-01-18 14:50:01.763182: Epoch time: 31.81 s 
2025-01-18 14:50:02.304248:  
2025-01-18 14:50:02.304248: Epoch 102 
2025-01-18 14:50:02.310850: Current learning rate: 0.00624 
2025-01-18 14:50:34.109741: train_loss -0.8424 
2025-01-18 14:50:34.110243: val_loss -0.4877 
2025-01-18 14:50:34.116258: Pseudo dice [np.float32(0.6817), np.float32(0.3742)] 
2025-01-18 14:50:34.120310: Epoch time: 31.81 s 
2025-01-18 14:50:34.659321:  
2025-01-18 14:50:34.659321: Epoch 103 
2025-01-18 14:50:34.665442: Current learning rate: 0.0062 
2025-01-18 14:51:06.478099: train_loss -0.8486 
2025-01-18 14:51:06.478607: val_loss -0.5215 
2025-01-18 14:51:06.484243: Pseudo dice [np.float32(0.7311), np.float32(0.4002)] 
2025-01-18 14:51:06.488295: Epoch time: 31.82 s 
2025-01-18 14:51:07.027321:  
2025-01-18 14:51:07.027832: Epoch 104 
2025-01-18 14:51:07.032878: Current learning rate: 0.00616 
2025-01-18 14:51:38.835583: train_loss -0.8509 
2025-01-18 14:51:38.835583: val_loss -0.5252 
2025-01-18 14:51:38.842105: Pseudo dice [np.float32(0.7202), np.float32(0.3997)] 
2025-01-18 14:51:38.846627: Epoch time: 31.81 s 
2025-01-18 14:51:39.545451:  
2025-01-18 14:51:39.546450: Epoch 105 
2025-01-18 14:51:39.552025: Current learning rate: 0.00612 
2025-01-18 14:52:11.349980: train_loss -0.8594 
2025-01-18 14:52:11.350983: val_loss -0.4809 
2025-01-18 14:52:11.358206: Pseudo dice [np.float32(0.7282), np.float32(0.318)] 
2025-01-18 14:52:11.362396: Epoch time: 31.8 s 
2025-01-18 14:52:11.924004:  
2025-01-18 14:52:11.924004: Epoch 106 
2025-01-18 14:52:11.930035: Current learning rate: 0.00609 
2025-01-18 14:52:43.722358: train_loss -0.8452 
2025-01-18 14:52:43.722864: val_loss -0.4528 
2025-01-18 14:52:43.728409: Pseudo dice [np.float32(0.7106), np.float32(0.2615)] 
2025-01-18 14:52:43.732207: Epoch time: 31.8 s 
2025-01-18 14:52:44.278519:  
2025-01-18 14:52:44.278519: Epoch 107 
2025-01-18 14:52:44.284560: Current learning rate: 0.00605 
2025-01-18 14:53:16.074843: train_loss -0.8519 
2025-01-18 14:53:16.075346: val_loss -0.5096 
2025-01-18 14:53:16.081362: Pseudo dice [np.float32(0.7186), np.float32(0.3994)] 
2025-01-18 14:53:16.084873: Epoch time: 31.8 s 
2025-01-18 14:53:16.629552:  
2025-01-18 14:53:16.630055: Epoch 108 
2025-01-18 14:53:16.635066: Current learning rate: 0.00601 
2025-01-18 14:53:48.435506: train_loss -0.85 
2025-01-18 14:53:48.436064: val_loss -0.4988 
2025-01-18 14:53:48.441604: Pseudo dice [np.float32(0.704), np.float32(0.4046)] 
2025-01-18 14:53:48.445688: Epoch time: 31.81 s 
2025-01-18 14:53:48.996436:  
2025-01-18 14:53:48.996436: Epoch 109 
2025-01-18 14:53:49.002546: Current learning rate: 0.00597 
2025-01-18 14:54:20.804573: train_loss -0.8543 
2025-01-18 14:54:20.805075: val_loss -0.4706 
2025-01-18 14:54:20.810610: Pseudo dice [np.float32(0.7361), np.float32(0.2589)] 
2025-01-18 14:54:20.814797: Epoch time: 31.81 s 
2025-01-18 14:54:21.355450:  
2025-01-18 14:54:21.356454: Epoch 110 
2025-01-18 14:54:21.362491: Current learning rate: 0.00593 
2025-01-18 14:54:53.174680: train_loss -0.8572 
2025-01-18 14:54:53.174680: val_loss -0.4734 
2025-01-18 14:54:53.180220: Pseudo dice [np.float32(0.7324), np.float32(0.2728)] 
2025-01-18 14:54:53.184740: Epoch time: 31.82 s 
2025-01-18 14:54:53.737665:  
2025-01-18 14:54:53.737665: Epoch 111 
2025-01-18 14:54:53.742691: Current learning rate: 0.0059 
2025-01-18 14:55:25.541915: train_loss -0.8591 
2025-01-18 14:55:25.542919: val_loss -0.4834 
2025-01-18 14:55:25.548933: Pseudo dice [np.float32(0.7074), np.float32(0.3463)] 
2025-01-18 14:55:25.551942: Epoch time: 31.81 s 
2025-01-18 14:55:26.084733:  
2025-01-18 14:55:26.085734: Epoch 112 
2025-01-18 14:55:26.090836: Current learning rate: 0.00586 
2025-01-18 14:55:57.888658: train_loss -0.8325 
2025-01-18 14:55:57.889175: val_loss -0.4827 
2025-01-18 14:55:57.894838: Pseudo dice [np.float32(0.7127), np.float32(0.361)] 
2025-01-18 14:55:57.898396: Epoch time: 31.8 s 
2025-01-18 14:55:58.598248:  
2025-01-18 14:55:58.598248: Epoch 113 
2025-01-18 14:55:58.603856: Current learning rate: 0.00582 
2025-01-18 14:56:30.392955: train_loss -0.8428 
2025-01-18 14:56:30.392955: val_loss -0.4646 
2025-01-18 14:56:30.399476: Pseudo dice [np.float32(0.7089), np.float32(0.2914)] 
2025-01-18 14:56:30.403984: Epoch time: 31.8 s 
2025-01-18 14:56:30.950536:  
2025-01-18 14:56:30.951541: Epoch 114 
2025-01-18 14:56:30.956591: Current learning rate: 0.00578 
2025-01-18 14:57:02.741889: train_loss -0.831 
2025-01-18 14:57:02.742391: val_loss -0.4646 
2025-01-18 14:57:02.750251: Pseudo dice [np.float32(0.7101), np.float32(0.2773)] 
2025-01-18 14:57:02.753264: Epoch time: 31.79 s 
2025-01-18 14:57:03.289727:  
2025-01-18 14:57:03.290726: Epoch 115 
2025-01-18 14:57:03.296390: Current learning rate: 0.00574 
2025-01-18 14:57:35.071861: train_loss -0.8419 
2025-01-18 14:57:35.071861: val_loss -0.4941 
2025-01-18 14:57:35.078409: Pseudo dice [np.float32(0.7212), np.float32(0.3419)] 
2025-01-18 14:57:35.081918: Epoch time: 31.78 s 
2025-01-18 14:57:35.623349:  
2025-01-18 14:57:35.623349: Epoch 116 
2025-01-18 14:57:35.629364: Current learning rate: 0.0057 
2025-01-18 14:58:07.427025: train_loss -0.8509 
2025-01-18 14:58:07.427530: val_loss -0.4969 
2025-01-18 14:58:07.433549: Pseudo dice [np.float32(0.7252), np.float32(0.3666)] 
2025-01-18 14:58:07.437059: Epoch time: 31.8 s 
2025-01-18 14:58:07.985059:  
2025-01-18 14:58:07.985059: Epoch 117 
2025-01-18 14:58:07.990577: Current learning rate: 0.00567 
2025-01-18 14:58:39.781319: train_loss -0.8668 
2025-01-18 14:58:39.782324: val_loss -0.4823 
2025-01-18 14:58:39.787467: Pseudo dice [np.float32(0.7385), np.float32(0.2933)] 
2025-01-18 14:58:39.791170: Epoch time: 31.8 s 
2025-01-18 14:58:40.359392:  
2025-01-18 14:58:40.359392: Epoch 118 
2025-01-18 14:58:40.364417: Current learning rate: 0.00563 
2025-01-18 14:59:12.133502: train_loss -0.8626 
2025-01-18 14:59:12.135018: val_loss -0.4493 
2025-01-18 14:59:12.141043: Pseudo dice [np.float32(0.7104), np.float32(0.2603)] 
2025-01-18 14:59:12.145680: Epoch time: 31.78 s 
2025-01-18 14:59:12.695627:  
2025-01-18 14:59:12.696634: Epoch 119 
2025-01-18 14:59:12.701191: Current learning rate: 0.00559 
2025-01-18 14:59:44.492197: train_loss -0.8579 
2025-01-18 14:59:44.492197: val_loss -0.508 
2025-01-18 14:59:44.498725: Pseudo dice [np.float32(0.7199), np.float32(0.359)] 
2025-01-18 14:59:44.502236: Epoch time: 31.8 s 
2025-01-18 14:59:45.063012:  
2025-01-18 14:59:45.063012: Epoch 120 
2025-01-18 14:59:45.069077: Current learning rate: 0.00555 
2025-01-18 15:00:16.870122: train_loss -0.8652 
2025-01-18 15:00:16.870122: val_loss -0.447 
2025-01-18 15:00:16.877148: Pseudo dice [np.float32(0.6918), np.float32(0.258)] 
2025-01-18 15:00:16.880184: Epoch time: 31.81 s 
2025-01-18 15:00:17.586955:  
2025-01-18 15:00:17.587461: Epoch 121 
2025-01-18 15:00:17.592042: Current learning rate: 0.00551 
2025-01-18 15:00:49.375293: train_loss -0.8642 
2025-01-18 15:00:49.376298: val_loss -0.4786 
2025-01-18 15:00:49.381311: Pseudo dice [np.float32(0.6899), np.float32(0.3485)] 
2025-01-18 15:00:49.385393: Epoch time: 31.79 s 
2025-01-18 15:00:49.945120:  
2025-01-18 15:00:49.946124: Epoch 122 
2025-01-18 15:00:49.950711: Current learning rate: 0.00547 
2025-01-18 15:01:21.725829: train_loss -0.8707 
2025-01-18 15:01:21.727332: val_loss -0.4884 
2025-01-18 15:01:21.733278: Pseudo dice [np.float32(0.7177), np.float32(0.319)] 
2025-01-18 15:01:21.736786: Epoch time: 31.78 s 
2025-01-18 15:01:22.280267:  
2025-01-18 15:01:22.281271: Epoch 123 
2025-01-18 15:01:22.286308: Current learning rate: 0.00544 
2025-01-18 15:01:54.083280: train_loss -0.8677 
2025-01-18 15:01:54.083801: val_loss -0.5089 
2025-01-18 15:01:54.089973: Pseudo dice [np.float32(0.6975), np.float32(0.3749)] 
2025-01-18 15:01:54.093508: Epoch time: 31.8 s 
2025-01-18 15:01:54.645634:  
2025-01-18 15:01:54.645634: Epoch 124 
2025-01-18 15:01:54.651754: Current learning rate: 0.0054 
2025-01-18 15:02:26.457718: train_loss -0.8697 
2025-01-18 15:02:26.458236: val_loss -0.479 
2025-01-18 15:02:26.463879: Pseudo dice [np.float32(0.7271), np.float32(0.3167)] 
2025-01-18 15:02:26.466939: Epoch time: 31.81 s 
2025-01-18 15:02:27.025658:  
2025-01-18 15:02:27.026386: Epoch 125 
2025-01-18 15:02:27.031397: Current learning rate: 0.00536 
2025-01-18 15:02:58.825060: train_loss -0.8737 
2025-01-18 15:02:58.826563: val_loss -0.4787 
2025-01-18 15:02:58.832584: Pseudo dice [np.float32(0.7158), np.float32(0.2812)] 
2025-01-18 15:02:58.836600: Epoch time: 31.8 s 
2025-01-18 15:02:59.380255:  
2025-01-18 15:02:59.380255: Epoch 126 
2025-01-18 15:02:59.385857: Current learning rate: 0.00532 
2025-01-18 15:03:31.187807: train_loss -0.8623 
2025-01-18 15:03:31.188309: val_loss -0.4677 
2025-01-18 15:03:31.193947: Pseudo dice [np.float32(0.7164), np.float32(0.2841)] 
2025-01-18 15:03:31.197974: Epoch time: 31.81 s 
2025-01-18 15:03:31.746519:  
2025-01-18 15:03:31.747035: Epoch 127 
2025-01-18 15:03:31.752625: Current learning rate: 0.00528 
2025-01-18 15:04:03.555383: train_loss -0.8656 
2025-01-18 15:04:03.555383: val_loss -0.4729 
2025-01-18 15:04:03.563926: Pseudo dice [np.float32(0.711), np.float32(0.3287)] 
2025-01-18 15:04:03.567983: Epoch time: 31.81 s 
2025-01-18 15:04:04.116558:  
2025-01-18 15:04:04.117557: Epoch 128 
2025-01-18 15:04:04.122664: Current learning rate: 0.00524 
2025-01-18 15:04:35.917984: train_loss -0.8643 
2025-01-18 15:04:35.918487: val_loss -0.426 
2025-01-18 15:04:35.923003: Pseudo dice [np.float32(0.7135), np.float32(0.1961)] 
2025-01-18 15:04:35.925513: Epoch time: 31.8 s 
2025-01-18 15:04:36.637269:  
2025-01-18 15:04:36.637269: Epoch 129 
2025-01-18 15:04:36.643836: Current learning rate: 0.0052 
2025-01-18 15:05:08.420609: train_loss -0.862 
2025-01-18 15:05:08.421127: val_loss -0.4313 
2025-01-18 15:05:08.427160: Pseudo dice [np.float32(0.6918), np.float32(0.2342)] 
2025-01-18 15:05:08.430666: Epoch time: 31.78 s 
2025-01-18 15:05:08.989501:  
2025-01-18 15:05:08.990505: Epoch 130 
2025-01-18 15:05:08.995076: Current learning rate: 0.00517 
2025-01-18 15:05:40.788832: train_loss -0.8785 
2025-01-18 15:05:40.789335: val_loss -0.4542 
2025-01-18 15:05:40.795354: Pseudo dice [np.float32(0.7071), np.float32(0.267)] 
2025-01-18 15:05:40.798860: Epoch time: 31.8 s 
2025-01-18 15:05:41.347336:  
2025-01-18 15:05:41.348339: Epoch 131 
2025-01-18 15:05:41.352891: Current learning rate: 0.00513 
2025-01-18 15:06:13.158191: train_loss -0.8749 
2025-01-18 15:06:13.159193: val_loss -0.4815 
2025-01-18 15:06:13.164709: Pseudo dice [np.float32(0.7404), np.float32(0.3113)] 
2025-01-18 15:06:13.168728: Epoch time: 31.81 s 
2025-01-18 15:06:13.720411:  
2025-01-18 15:06:13.720914: Epoch 132 
2025-01-18 15:06:13.725927: Current learning rate: 0.00509 
2025-01-18 15:06:45.540205: train_loss -0.875 
2025-01-18 15:06:45.540205: val_loss -0.491 
2025-01-18 15:06:45.546225: Pseudo dice [np.float32(0.6959), np.float32(0.3724)] 
2025-01-18 15:06:45.550234: Epoch time: 31.82 s 
2025-01-18 15:06:46.105793:  
2025-01-18 15:06:46.105793: Epoch 133 
2025-01-18 15:06:46.120002: Current learning rate: 0.00505 
2025-01-18 15:07:17.918951: train_loss -0.886 
2025-01-18 15:07:17.918951: val_loss -0.4482 
2025-01-18 15:07:17.924968: Pseudo dice [np.float32(0.7101), np.float32(0.2404)] 
2025-01-18 15:07:17.929015: Epoch time: 31.81 s 
2025-01-18 15:07:18.489044:  
2025-01-18 15:07:18.489547: Epoch 134 
2025-01-18 15:07:18.492612: Current learning rate: 0.00501 
2025-01-18 15:07:50.311745: train_loss -0.8796 
2025-01-18 15:07:50.311745: val_loss -0.5098 
2025-01-18 15:07:50.318788: Pseudo dice [np.float32(0.7199), np.float32(0.4352)] 
2025-01-18 15:07:50.322087: Epoch time: 31.82 s 
2025-01-18 15:07:50.885061:  
2025-01-18 15:07:50.886065: Epoch 135 
2025-01-18 15:07:50.891195: Current learning rate: 0.00497 
2025-01-18 15:08:22.691796: train_loss -0.8848 
2025-01-18 15:08:22.691796: val_loss -0.4514 
2025-01-18 15:08:22.698898: Pseudo dice [np.float32(0.7235), np.float32(0.2714)] 
2025-01-18 15:08:22.702408: Epoch time: 31.81 s 
2025-01-18 15:08:23.264369:  
2025-01-18 15:08:23.264369: Epoch 136 
2025-01-18 15:08:23.269919: Current learning rate: 0.00493 
2025-01-18 15:08:55.074048: train_loss -0.8788 
2025-01-18 15:08:55.075052: val_loss -0.501 
2025-01-18 15:08:55.081139: Pseudo dice [np.float32(0.724), np.float32(0.3259)] 
2025-01-18 15:08:55.084201: Epoch time: 31.81 s 
2025-01-18 15:08:55.795045:  
2025-01-18 15:08:55.795045: Epoch 137 
2025-01-18 15:08:55.801090: Current learning rate: 0.00489 
2025-01-18 15:09:27.606188: train_loss -0.8802 
2025-01-18 15:09:27.607194: val_loss -0.4658 
2025-01-18 15:09:27.613214: Pseudo dice [np.float32(0.7113), np.float32(0.3162)] 
2025-01-18 15:09:27.616751: Epoch time: 31.81 s 
2025-01-18 15:09:28.167402:  
2025-01-18 15:09:28.167402: Epoch 138 
2025-01-18 15:09:28.172413: Current learning rate: 0.00485 
2025-01-18 15:09:59.978014: train_loss -0.8821 
2025-01-18 15:09:59.979537: val_loss -0.4363 
2025-01-18 15:09:59.985070: Pseudo dice [np.float32(0.7098), np.float32(0.2381)] 
2025-01-18 15:09:59.988629: Epoch time: 31.81 s 
2025-01-18 15:10:00.542120:  
2025-01-18 15:10:00.542622: Epoch 139 
2025-01-18 15:10:00.547636: Current learning rate: 0.00482 
2025-01-18 15:10:32.344763: train_loss -0.8709 
2025-01-18 15:10:32.344763: val_loss -0.4813 
2025-01-18 15:10:32.351779: Pseudo dice [np.float32(0.7022), np.float32(0.3102)] 
2025-01-18 15:10:32.354855: Epoch time: 31.8 s 
2025-01-18 15:10:32.920118:  
2025-01-18 15:10:32.921121: Epoch 140 
2025-01-18 15:10:32.925681: Current learning rate: 0.00478 
2025-01-18 15:11:04.725633: train_loss -0.8725 
2025-01-18 15:11:04.726634: val_loss -0.4489 
2025-01-18 15:11:04.733158: Pseudo dice [np.float32(0.7041), np.float32(0.2659)] 
2025-01-18 15:11:04.736667: Epoch time: 31.81 s 
2025-01-18 15:11:05.312348:  
2025-01-18 15:11:05.312348: Epoch 141 
2025-01-18 15:11:05.317359: Current learning rate: 0.00474 
2025-01-18 15:11:37.117648: train_loss -0.8833 
2025-01-18 15:11:37.117648: val_loss -0.5088 
2025-01-18 15:11:37.124200: Pseudo dice [np.float32(0.7397), np.float32(0.329)] 
2025-01-18 15:11:37.127284: Epoch time: 31.81 s 
2025-01-18 15:11:37.680021:  
2025-01-18 15:11:37.680021: Epoch 142 
2025-01-18 15:11:37.685598: Current learning rate: 0.0047 
2025-01-18 15:12:09.492316: train_loss -0.8828 
2025-01-18 15:12:09.492820: val_loss -0.4675 
2025-01-18 15:12:09.500176: Pseudo dice [np.float32(0.7223), np.float32(0.2929)] 
2025-01-18 15:12:09.503687: Epoch time: 31.81 s 
2025-01-18 15:12:10.066263:  
2025-01-18 15:12:10.067266: Epoch 143 
2025-01-18 15:12:10.072396: Current learning rate: 0.00466 
2025-01-18 15:12:41.879697: train_loss -0.8875 
2025-01-18 15:12:41.881200: val_loss -0.4734 
2025-01-18 15:12:41.887743: Pseudo dice [np.float32(0.7193), np.float32(0.3032)] 
2025-01-18 15:12:41.891755: Epoch time: 31.81 s 
2025-01-18 15:12:42.448334:  
2025-01-18 15:12:42.448334: Epoch 144 
2025-01-18 15:12:42.452360: Current learning rate: 0.00462 
2025-01-18 15:13:14.237525: train_loss -0.8983 
2025-01-18 15:13:14.238525: val_loss -0.4698 
2025-01-18 15:13:14.246046: Pseudo dice [np.float32(0.6934), np.float32(0.33)] 
2025-01-18 15:13:14.249128: Epoch time: 31.79 s 
2025-01-18 15:13:14.960231:  
2025-01-18 15:13:14.961230: Epoch 145 
2025-01-18 15:13:14.966319: Current learning rate: 0.00458 
2025-01-18 15:13:46.758393: train_loss -0.8946 
2025-01-18 15:13:46.758897: val_loss -0.4608 
2025-01-18 15:13:46.765528: Pseudo dice [np.float32(0.7068), np.float32(0.3032)] 
2025-01-18 15:13:46.769073: Epoch time: 31.8 s 
2025-01-18 15:13:47.333239:  
2025-01-18 15:13:47.333239: Epoch 146 
2025-01-18 15:13:47.338830: Current learning rate: 0.00454 
2025-01-18 15:14:19.136338: train_loss -0.899 
2025-01-18 15:14:19.137339: val_loss -0.4807 
2025-01-18 15:14:19.143859: Pseudo dice [np.float32(0.7159), np.float32(0.3391)] 
2025-01-18 15:14:19.147397: Epoch time: 31.8 s 
2025-01-18 15:14:19.720182:  
2025-01-18 15:14:19.720182: Epoch 147 
2025-01-18 15:14:19.725799: Current learning rate: 0.0045 
2025-01-18 15:14:51.520239: train_loss -0.883 
2025-01-18 15:14:51.520761: val_loss -0.4544 
2025-01-18 15:14:51.527418: Pseudo dice [np.float32(0.712), np.float32(0.2914)] 
2025-01-18 15:14:51.530964: Epoch time: 31.8 s 
2025-01-18 15:14:52.085025:  
2025-01-18 15:14:52.085025: Epoch 148 
2025-01-18 15:14:52.091042: Current learning rate: 0.00446 
2025-01-18 15:15:23.870813: train_loss -0.8701 
2025-01-18 15:15:23.870813: val_loss -0.4878 
2025-01-18 15:15:23.881940: Pseudo dice [np.float32(0.7117), np.float32(0.4161)] 
2025-01-18 15:15:23.890976: Epoch time: 31.79 s 
2025-01-18 15:15:24.440979:  
2025-01-18 15:15:24.441978: Epoch 149 
2025-01-18 15:15:24.447042: Current learning rate: 0.00442 
2025-01-18 15:15:56.234697: train_loss -0.8786 
2025-01-18 15:15:56.235211: val_loss -0.4944 
2025-01-18 15:15:56.245942: Pseudo dice [np.float32(0.7196), np.float32(0.3704)] 
2025-01-18 15:15:56.249498: Epoch time: 31.79 s 
2025-01-18 15:15:57.050567:  
2025-01-18 15:15:57.051073: Epoch 150 
2025-01-18 15:15:57.056123: Current learning rate: 0.00438 
2025-01-18 15:16:28.872853: train_loss -0.8846 
2025-01-18 15:16:28.872853: val_loss -0.4636 
2025-01-18 15:16:28.879875: Pseudo dice [np.float32(0.7145), np.float32(0.3085)] 
2025-01-18 15:16:28.887973: Epoch time: 31.82 s 
2025-01-18 15:16:29.450963:  
2025-01-18 15:16:29.451466: Epoch 151 
2025-01-18 15:16:29.455976: Current learning rate: 0.00434 
2025-01-18 15:17:01.269659: train_loss -0.8853 
2025-01-18 15:17:01.269659: val_loss -0.5243 
2025-01-18 15:17:01.276175: Pseudo dice [np.float32(0.7181), np.float32(0.4314)] 
2025-01-18 15:17:01.279191: Epoch time: 31.82 s 
2025-01-18 15:17:01.832191:  
2025-01-18 15:17:01.832696: Epoch 152 
2025-01-18 15:17:01.837206: Current learning rate: 0.0043 
2025-01-18 15:17:33.631891: train_loss -0.8821 
2025-01-18 15:17:33.633394: val_loss -0.4611 
2025-01-18 15:17:33.638406: Pseudo dice [np.float32(0.7031), np.float32(0.3242)] 
2025-01-18 15:17:33.642423: Epoch time: 31.8 s 
2025-01-18 15:17:34.345190:  
2025-01-18 15:17:34.345190: Epoch 153 
2025-01-18 15:17:34.350201: Current learning rate: 0.00427 
2025-01-18 15:18:06.148428: train_loss -0.8886 
2025-01-18 15:18:06.149428: val_loss -0.4766 
2025-01-18 15:18:06.154944: Pseudo dice [np.float32(0.7145), np.float32(0.3337)] 
2025-01-18 15:18:06.157987: Epoch time: 31.8 s 
2025-01-18 15:18:06.730923:  
2025-01-18 15:18:06.730923: Epoch 154 
2025-01-18 15:18:06.736486: Current learning rate: 0.00423 
2025-01-18 15:18:38.533036: train_loss -0.8885 
2025-01-18 15:18:38.534042: val_loss -0.46 
2025-01-18 15:18:38.538051: Pseudo dice [np.float32(0.7173), np.float32(0.3277)] 
2025-01-18 15:18:38.541073: Epoch time: 31.8 s 
2025-01-18 15:18:39.109269:  
2025-01-18 15:18:39.109269: Epoch 155 
2025-01-18 15:18:39.114280: Current learning rate: 0.00419 
2025-01-18 15:19:10.917293: train_loss -0.8981 
2025-01-18 15:19:10.917796: val_loss -0.4482 
2025-01-18 15:19:10.924822: Pseudo dice [np.float32(0.7039), np.float32(0.2835)] 
2025-01-18 15:19:10.927942: Epoch time: 31.81 s 
2025-01-18 15:19:11.491207:  
2025-01-18 15:19:11.492213: Epoch 156 
2025-01-18 15:19:11.496755: Current learning rate: 0.00415 
2025-01-18 15:19:43.270327: train_loss -0.8903 
2025-01-18 15:19:43.270327: val_loss -0.4418 
2025-01-18 15:19:43.276853: Pseudo dice [np.float32(0.7023), np.float32(0.2556)] 
2025-01-18 15:19:43.280369: Epoch time: 31.78 s 
2025-01-18 15:19:43.850893:  
2025-01-18 15:19:43.850893: Epoch 157 
2025-01-18 15:19:43.856418: Current learning rate: 0.00411 
2025-01-18 15:20:15.659934: train_loss -0.8911 
2025-01-18 15:20:15.659934: val_loss -0.4556 
2025-01-18 15:20:15.666535: Pseudo dice [np.float32(0.7399), np.float32(0.2646)] 
2025-01-18 15:20:15.670064: Epoch time: 31.81 s 
2025-01-18 15:20:16.239635:  
2025-01-18 15:20:16.239635: Epoch 158 
2025-01-18 15:20:16.245178: Current learning rate: 0.00407 
2025-01-18 15:20:48.024592: train_loss -0.8931 
2025-01-18 15:20:48.025097: val_loss -0.4321 
2025-01-18 15:20:48.031116: Pseudo dice [np.float32(0.6953), np.float32(0.2279)] 
2025-01-18 15:20:48.033622: Epoch time: 31.79 s 
2025-01-18 15:20:48.596392:  
2025-01-18 15:20:48.596392: Epoch 159 
2025-01-18 15:20:48.602406: Current learning rate: 0.00403 
2025-01-18 15:21:20.384984: train_loss -0.8995 
2025-01-18 15:21:20.385990: val_loss -0.4949 
2025-01-18 15:21:20.392507: Pseudo dice [np.float32(0.7266), np.float32(0.3789)] 
2025-01-18 15:21:20.397564: Epoch time: 31.79 s 
2025-01-18 15:21:20.975676:  
2025-01-18 15:21:20.976179: Epoch 160 
2025-01-18 15:21:20.979708: Current learning rate: 0.00399 
2025-01-18 15:21:52.760759: train_loss -0.8971 
2025-01-18 15:21:52.761764: val_loss -0.448 
2025-01-18 15:21:52.768423: Pseudo dice [np.float32(0.702), np.float32(0.3248)] 
2025-01-18 15:21:52.772975: Epoch time: 31.79 s 
2025-01-18 15:21:53.493996:  
2025-01-18 15:21:53.493996: Epoch 161 
2025-01-18 15:21:53.499667: Current learning rate: 0.00395 
2025-01-18 15:22:25.293046: train_loss -0.8983 
2025-01-18 15:22:25.294045: val_loss -0.4456 
2025-01-18 15:22:25.300568: Pseudo dice [np.float32(0.7054), np.float32(0.2872)] 
2025-01-18 15:22:25.304577: Epoch time: 31.8 s 
2025-01-18 15:22:25.879475:  
2025-01-18 15:22:25.880477: Epoch 162 
2025-01-18 15:22:25.886065: Current learning rate: 0.00391 
2025-01-18 15:22:57.675403: train_loss -0.8977 
2025-01-18 15:22:57.675923: val_loss -0.4785 
2025-01-18 15:22:57.681941: Pseudo dice [np.float32(0.7108), np.float32(0.2935)] 
2025-01-18 15:22:57.685954: Epoch time: 31.8 s 
2025-01-18 15:22:58.264350:  
2025-01-18 15:22:58.264853: Epoch 163 
2025-01-18 15:22:58.270376: Current learning rate: 0.00387 
2025-01-18 15:23:30.052293: train_loss -0.9051 
2025-01-18 15:23:30.053297: val_loss -0.4641 
2025-01-18 15:23:30.059809: Pseudo dice [np.float32(0.7253), np.float32(0.2776)] 
2025-01-18 15:23:30.064362: Epoch time: 31.79 s 
2025-01-18 15:23:30.639013:  
2025-01-18 15:23:30.639013: Epoch 164 
2025-01-18 15:23:30.645650: Current learning rate: 0.00383 
2025-01-18 15:24:02.436844: train_loss -0.9018 
2025-01-18 15:24:02.436844: val_loss -0.4279 
2025-01-18 15:24:02.443483: Pseudo dice [np.float32(0.6892), np.float32(0.2164)] 
2025-01-18 15:24:02.447059: Epoch time: 31.8 s 
2025-01-18 15:24:02.998337:  
2025-01-18 15:24:02.998337: Epoch 165 
2025-01-18 15:24:03.004931: Current learning rate: 0.00379 
2025-01-18 15:24:34.804859: train_loss -0.9092 
2025-01-18 15:24:34.805859: val_loss -0.4312 
2025-01-18 15:24:34.811373: Pseudo dice [np.float32(0.706), np.float32(0.2521)] 
2025-01-18 15:24:34.814883: Epoch time: 31.81 s 
2025-01-18 15:24:35.371903:  
2025-01-18 15:24:35.371903: Epoch 166 
2025-01-18 15:24:35.377917: Current learning rate: 0.00375 
2025-01-18 15:25:07.176277: train_loss -0.9116 
2025-01-18 15:25:07.177276: val_loss -0.4186 
2025-01-18 15:25:07.183798: Pseudo dice [np.float32(0.6977), np.float32(0.2433)] 
2025-01-18 15:25:07.187825: Epoch time: 31.81 s 
2025-01-18 15:25:07.737216:  
2025-01-18 15:25:07.737718: Epoch 167 
2025-01-18 15:25:07.742765: Current learning rate: 0.00371 
2025-01-18 15:25:39.532511: train_loss -0.9065 
2025-01-18 15:25:39.532511: val_loss -0.4915 
2025-01-18 15:25:39.539025: Pseudo dice [np.float32(0.7326), np.float32(0.2937)] 
2025-01-18 15:25:39.541566: Epoch time: 31.8 s 
2025-01-18 15:25:40.112114:  
2025-01-18 15:25:40.112114: Epoch 168 
2025-01-18 15:25:40.118197: Current learning rate: 0.00367 
2025-01-18 15:26:11.917508: train_loss -0.9058 
2025-01-18 15:26:11.918513: val_loss -0.4818 
2025-01-18 15:26:11.925541: Pseudo dice [np.float32(0.7211), np.float32(0.2781)] 
2025-01-18 15:26:11.930066: Epoch time: 31.81 s 
2025-01-18 15:26:12.631189:  
2025-01-18 15:26:12.632186: Epoch 169 
2025-01-18 15:26:12.635241: Current learning rate: 0.00363 
2025-01-18 15:26:44.426541: train_loss -0.9111 
2025-01-18 15:26:44.427044: val_loss -0.493 
2025-01-18 15:26:44.433067: Pseudo dice [np.float32(0.7258), np.float32(0.3462)] 
2025-01-18 15:26:44.437077: Epoch time: 31.8 s 
2025-01-18 15:26:45.010884:  
2025-01-18 15:26:45.011885: Epoch 170 
2025-01-18 15:26:45.018407: Current learning rate: 0.00359 
2025-01-18 15:27:16.810035: train_loss -0.9066 
2025-01-18 15:27:16.811039: val_loss -0.484 
2025-01-18 15:27:16.818559: Pseudo dice [np.float32(0.7083), np.float32(0.291)] 
2025-01-18 15:27:16.822569: Epoch time: 31.8 s 
2025-01-18 15:27:17.384624:  
2025-01-18 15:27:17.385628: Epoch 171 
2025-01-18 15:27:17.390195: Current learning rate: 0.00355 
2025-01-18 15:27:49.175000: train_loss -0.9066 
2025-01-18 15:27:49.175000: val_loss -0.4678 
2025-01-18 15:27:49.182525: Pseudo dice [np.float32(0.7137), np.float32(0.2812)] 
2025-01-18 15:27:49.185532: Epoch time: 31.79 s 
2025-01-18 15:27:49.775622:  
2025-01-18 15:27:49.775622: Epoch 172 
2025-01-18 15:27:49.781639: Current learning rate: 0.00351 
2025-01-18 15:28:21.575825: train_loss -0.911 
2025-01-18 15:28:21.576828: val_loss -0.4154 
2025-01-18 15:28:21.584128: Pseudo dice [np.float32(0.7053), np.float32(0.2033)] 
2025-01-18 15:28:21.588139: Epoch time: 31.8 s 
2025-01-18 15:28:22.147921:  
2025-01-18 15:28:22.148925: Epoch 173 
2025-01-18 15:28:22.155498: Current learning rate: 0.00346 
2025-01-18 15:28:53.944931: train_loss -0.9109 
2025-01-18 15:28:53.945435: val_loss -0.4216 
2025-01-18 15:28:53.951453: Pseudo dice [np.float32(0.7068), np.float32(0.2097)] 
2025-01-18 15:28:53.955537: Epoch time: 31.8 s 
2025-01-18 15:28:54.514277:  
2025-01-18 15:28:54.514277: Epoch 174 
2025-01-18 15:28:54.520339: Current learning rate: 0.00342 
2025-01-18 15:29:26.320124: train_loss -0.9098 
2025-01-18 15:29:26.321627: val_loss -0.432 
2025-01-18 15:29:26.328168: Pseudo dice [np.float32(0.6742), np.float32(0.2493)] 
2025-01-18 15:29:26.333213: Epoch time: 31.81 s 
2025-01-18 15:29:26.893983:  
2025-01-18 15:29:26.894984: Epoch 175 
2025-01-18 15:29:26.900608: Current learning rate: 0.00338 
2025-01-18 15:29:58.699584: train_loss -0.9139 
2025-01-18 15:29:58.699584: val_loss -0.4591 
2025-01-18 15:29:58.707110: Pseudo dice [np.float32(0.7305), np.float32(0.2682)] 
2025-01-18 15:29:58.712123: Epoch time: 31.81 s 
2025-01-18 15:29:59.421660:  
2025-01-18 15:29:59.421660: Epoch 176 
2025-01-18 15:29:59.426675: Current learning rate: 0.00334 
2025-01-18 15:30:31.214566: train_loss -0.91 
2025-01-18 15:30:31.215571: val_loss -0.4691 
2025-01-18 15:30:31.222095: Pseudo dice [np.float32(0.7304), np.float32(0.2553)] 
2025-01-18 15:30:31.225629: Epoch time: 31.79 s 
2025-01-18 15:30:31.793004:  
2025-01-18 15:30:31.793004: Epoch 177 
2025-01-18 15:30:31.799016: Current learning rate: 0.0033 
2025-01-18 15:31:03.573992: train_loss -0.9033 
2025-01-18 15:31:03.573992: val_loss -0.4199 
2025-01-18 15:31:03.581095: Pseudo dice [np.float32(0.7064), np.float32(0.1987)] 
2025-01-18 15:31:03.586192: Epoch time: 31.78 s 
2025-01-18 15:31:04.145904:  
2025-01-18 15:31:04.145904: Epoch 178 
2025-01-18 15:31:04.150916: Current learning rate: 0.00326 
2025-01-18 15:31:35.939332: train_loss -0.9059 
2025-01-18 15:31:35.939332: val_loss -0.4638 
2025-01-18 15:31:35.946359: Pseudo dice [np.float32(0.7235), np.float32(0.2742)] 
2025-01-18 15:31:35.950450: Epoch time: 31.79 s 
2025-01-18 15:31:36.516003:  
2025-01-18 15:31:36.516003: Epoch 179 
2025-01-18 15:31:36.521550: Current learning rate: 0.00322 
2025-01-18 15:32:08.295532: train_loss -0.9001 
2025-01-18 15:32:08.296532: val_loss -0.4584 
2025-01-18 15:32:08.303060: Pseudo dice [np.float32(0.7254), np.float32(0.2536)] 
2025-01-18 15:32:08.308159: Epoch time: 31.78 s 
2025-01-18 15:32:08.868531:  
2025-01-18 15:32:08.869034: Epoch 180 
2025-01-18 15:32:08.875048: Current learning rate: 0.00318 
2025-01-18 15:32:40.686713: train_loss -0.9016 
2025-01-18 15:32:40.686713: val_loss -0.4755 
2025-01-18 15:32:40.694899: Pseudo dice [np.float32(0.7065), np.float32(0.2853)] 
2025-01-18 15:32:40.698973: Epoch time: 31.82 s 
2025-01-18 15:32:41.267186:  
2025-01-18 15:32:41.267186: Epoch 181 
2025-01-18 15:32:41.273216: Current learning rate: 0.00314 
2025-01-18 15:33:13.079196: train_loss -0.9055 
2025-01-18 15:33:13.079699: val_loss -0.4782 
2025-01-18 15:33:13.087736: Pseudo dice [np.float32(0.741), np.float32(0.2665)] 
2025-01-18 15:33:13.093265: Epoch time: 31.81 s 
2025-01-18 15:33:13.660203:  
2025-01-18 15:33:13.661206: Epoch 182 
2025-01-18 15:33:13.667778: Current learning rate: 0.0031 
2025-01-18 15:33:45.467747: train_loss -0.9112 
2025-01-18 15:33:45.468751: val_loss -0.4433 
2025-01-18 15:33:45.475271: Pseudo dice [np.float32(0.713), np.float32(0.2599)] 
2025-01-18 15:33:45.478787: Epoch time: 31.81 s 
2025-01-18 15:33:46.040519:  
2025-01-18 15:33:46.041023: Epoch 183 
2025-01-18 15:33:46.046034: Current learning rate: 0.00306 
2025-01-18 15:34:17.843708: train_loss -0.9168 
2025-01-18 15:34:17.844210: val_loss -0.482 
2025-01-18 15:34:17.851728: Pseudo dice [np.float32(0.7113), np.float32(0.3293)] 
2025-01-18 15:34:17.855803: Epoch time: 31.8 s 
2025-01-18 15:34:18.561222:  
2025-01-18 15:34:18.561222: Epoch 184 
2025-01-18 15:34:18.567271: Current learning rate: 0.00302 
2025-01-18 15:34:50.350869: train_loss -0.9097 
2025-01-18 15:34:50.351868: val_loss -0.4485 
2025-01-18 15:34:50.358388: Pseudo dice [np.float32(0.7124), np.float32(0.2533)] 
2025-01-18 15:34:50.362466: Epoch time: 31.79 s 
2025-01-18 15:34:50.928600:  
2025-01-18 15:34:50.928600: Epoch 185 
2025-01-18 15:34:50.934616: Current learning rate: 0.00297 
2025-01-18 15:35:22.727460: train_loss -0.9145 
2025-01-18 15:35:22.727460: val_loss -0.4612 
2025-01-18 15:35:22.733548: Pseudo dice [np.float32(0.6949), np.float32(0.2934)] 
2025-01-18 15:35:22.738233: Epoch time: 31.8 s 
2025-01-18 15:35:23.296862:  
2025-01-18 15:35:23.296862: Epoch 186 
2025-01-18 15:35:23.300892: Current learning rate: 0.00293 
2025-01-18 15:35:55.107025: train_loss -0.9229 
2025-01-18 15:35:55.107529: val_loss -0.4497 
2025-01-18 15:35:55.114550: Pseudo dice [np.float32(0.7154), np.float32(0.2568)] 
2025-01-18 15:35:55.118563: Epoch time: 31.81 s 
2025-01-18 15:35:55.691145:  
2025-01-18 15:35:55.691145: Epoch 187 
2025-01-18 15:35:55.695703: Current learning rate: 0.00289 
2025-01-18 15:36:27.501901: train_loss -0.9143 
2025-01-18 15:36:27.501901: val_loss -0.5083 
2025-01-18 15:36:27.509423: Pseudo dice [np.float32(0.7218), np.float32(0.3175)] 
2025-01-18 15:36:27.513431: Epoch time: 31.81 s 
2025-01-18 15:36:28.081830:  
2025-01-18 15:36:28.081830: Epoch 188 
2025-01-18 15:36:28.088414: Current learning rate: 0.00285 
2025-01-18 15:36:59.887012: train_loss -0.9132 
2025-01-18 15:36:59.887521: val_loss -0.437 
2025-01-18 15:36:59.894105: Pseudo dice [np.float32(0.7163), np.float32(0.2268)] 
2025-01-18 15:36:59.899153: Epoch time: 31.81 s 
2025-01-18 15:37:00.461079:  
2025-01-18 15:37:00.461079: Epoch 189 
2025-01-18 15:37:00.466660: Current learning rate: 0.00281 
2025-01-18 15:37:32.264248: train_loss -0.9194 
2025-01-18 15:37:32.264751: val_loss -0.4665 
2025-01-18 15:37:32.270773: Pseudo dice [np.float32(0.7307), np.float32(0.256)] 
2025-01-18 15:37:32.275629: Epoch time: 31.8 s 
2025-01-18 15:37:32.843247:  
2025-01-18 15:37:32.843754: Epoch 190 
2025-01-18 15:37:32.849362: Current learning rate: 0.00277 
2025-01-18 15:38:04.656071: train_loss -0.9124 
2025-01-18 15:38:04.657111: val_loss -0.4671 
2025-01-18 15:38:04.661167: Pseudo dice [np.float32(0.7292), np.float32(0.2682)] 
2025-01-18 15:38:04.665848: Epoch time: 31.81 s 
2025-01-18 15:38:05.242879:  
2025-01-18 15:38:05.242879: Epoch 191 
2025-01-18 15:38:05.248437: Current learning rate: 0.00273 
2025-01-18 15:38:37.053726: train_loss -0.9167 
2025-01-18 15:38:37.053726: val_loss -0.4748 
2025-01-18 15:38:37.060810: Pseudo dice [np.float32(0.7352), np.float32(0.2274)] 
2025-01-18 15:38:37.063842: Epoch time: 31.81 s 
2025-01-18 15:38:37.780746:  
2025-01-18 15:38:37.781753: Epoch 192 
2025-01-18 15:38:37.786295: Current learning rate: 0.00268 
2025-01-18 15:39:09.581814: train_loss -0.9164 
2025-01-18 15:39:09.582814: val_loss -0.4761 
2025-01-18 15:39:09.589333: Pseudo dice [np.float32(0.7154), np.float32(0.2606)] 
2025-01-18 15:39:09.593876: Epoch time: 31.8 s 
2025-01-18 15:39:10.166225:  
2025-01-18 15:39:10.167226: Epoch 193 
2025-01-18 15:39:10.173327: Current learning rate: 0.00264 
2025-01-18 15:39:41.989415: train_loss -0.9166 
2025-01-18 15:39:41.989929: val_loss -0.482 
2025-01-18 15:39:41.995971: Pseudo dice [np.float32(0.7306), np.float32(0.2995)] 
2025-01-18 15:39:41.999543: Epoch time: 31.82 s 
2025-01-18 15:39:42.576368:  
2025-01-18 15:39:42.576876: Epoch 194 
2025-01-18 15:39:42.581450: Current learning rate: 0.0026 
2025-01-18 15:40:14.371867: train_loss -0.9081 
2025-01-18 15:40:14.371867: val_loss -0.4388 
2025-01-18 15:40:14.378885: Pseudo dice [np.float32(0.7231), np.float32(0.2125)] 
2025-01-18 15:40:14.382900: Epoch time: 31.8 s 
2025-01-18 15:40:14.964825:  
2025-01-18 15:40:14.964825: Epoch 195 
2025-01-18 15:40:14.971372: Current learning rate: 0.00256 
2025-01-18 15:40:46.776336: train_loss -0.9215 
2025-01-18 15:40:46.776336: val_loss -0.4159 
2025-01-18 15:40:46.782352: Pseudo dice [np.float32(0.6965), np.float32(0.1876)] 
2025-01-18 15:40:46.786387: Epoch time: 31.81 s 
2025-01-18 15:40:47.366161:  
2025-01-18 15:40:47.367167: Epoch 196 
2025-01-18 15:40:47.371739: Current learning rate: 0.00252 
2025-01-18 15:41:19.171040: train_loss -0.9192 
2025-01-18 15:41:19.171544: val_loss -0.4446 
2025-01-18 15:41:19.178644: Pseudo dice [np.float32(0.7064), np.float32(0.2462)] 
2025-01-18 15:41:19.182701: Epoch time: 31.81 s 
2025-01-18 15:41:19.756083:  
2025-01-18 15:41:19.756585: Epoch 197 
2025-01-18 15:41:19.762601: Current learning rate: 0.00248 
2025-01-18 15:41:51.558404: train_loss -0.9235 
2025-01-18 15:41:51.559410: val_loss -0.4734 
2025-01-18 15:41:51.565926: Pseudo dice [np.float32(0.7328), np.float32(0.3123)] 
2025-01-18 15:41:51.569026: Epoch time: 31.8 s 
2025-01-18 15:41:52.138269:  
2025-01-18 15:41:52.139272: Epoch 198 
2025-01-18 15:41:52.145302: Current learning rate: 0.00243 
2025-01-18 15:42:23.937589: train_loss -0.9196 
2025-01-18 15:42:23.939102: val_loss -0.4266 
2025-01-18 15:42:23.944122: Pseudo dice [np.float32(0.7164), np.float32(0.2073)] 
2025-01-18 15:42:23.948658: Epoch time: 31.8 s 
2025-01-18 15:42:24.668423:  
2025-01-18 15:42:24.668423: Epoch 199 
2025-01-18 15:42:24.675015: Current learning rate: 0.00239 
2025-01-18 15:42:56.457205: train_loss -0.9248 
2025-01-18 15:42:56.457709: val_loss -0.3991 
2025-01-18 15:42:56.464727: Pseudo dice [np.float32(0.6989), np.float32(0.2034)] 
2025-01-18 15:42:56.468276: Epoch time: 31.79 s 
2025-01-18 15:42:57.277934:  
2025-01-18 15:42:57.278437: Epoch 200 
2025-01-18 15:42:57.284451: Current learning rate: 0.00235 
2025-01-18 15:43:29.072479: train_loss -0.9157 
2025-01-18 15:43:29.072479: val_loss -0.4859 
2025-01-18 15:43:29.080185: Pseudo dice [np.float32(0.7132), np.float32(0.3265)] 
2025-01-18 15:43:29.083745: Epoch time: 31.8 s 
2025-01-18 15:43:29.654090:  
2025-01-18 15:43:29.654090: Epoch 201 
2025-01-18 15:43:29.660930: Current learning rate: 0.00231 
2025-01-18 15:44:01.450933: train_loss -0.9265 
2025-01-18 15:44:01.451940: val_loss -0.4883 
2025-01-18 15:44:01.457530: Pseudo dice [np.float32(0.7182), np.float32(0.3428)] 
2025-01-18 15:44:01.463126: Epoch time: 31.8 s 
2025-01-18 15:44:02.043090:  
2025-01-18 15:44:02.043090: Epoch 202 
2025-01-18 15:44:02.050663: Current learning rate: 0.00226 
2025-01-18 15:44:33.857119: train_loss -0.9194 
2025-01-18 15:44:33.857119: val_loss -0.4424 
2025-01-18 15:44:33.864647: Pseudo dice [np.float32(0.7051), np.float32(0.2449)] 
2025-01-18 15:44:33.868156: Epoch time: 31.82 s 
2025-01-18 15:44:34.432013:  
2025-01-18 15:44:34.432013: Epoch 203 
2025-01-18 15:44:34.437558: Current learning rate: 0.00222 
2025-01-18 15:45:06.236619: train_loss -0.9211 
2025-01-18 15:45:06.237139: val_loss -0.4514 
2025-01-18 15:45:06.243156: Pseudo dice [np.float32(0.7077), np.float32(0.2986)] 
2025-01-18 15:45:06.246660: Epoch time: 31.81 s 
2025-01-18 15:45:06.817959:  
2025-01-18 15:45:06.817959: Epoch 204 
2025-01-18 15:45:06.824546: Current learning rate: 0.00218 
2025-01-18 15:45:38.627930: train_loss -0.9216 
2025-01-18 15:45:38.628435: val_loss -0.4386 
2025-01-18 15:45:38.635453: Pseudo dice [np.float32(0.7317), np.float32(0.1718)] 
2025-01-18 15:45:38.639524: Epoch time: 31.81 s 
2025-01-18 15:45:39.214648:  
2025-01-18 15:45:39.214648: Epoch 205 
2025-01-18 15:45:39.221195: Current learning rate: 0.00214 
2025-01-18 15:46:11.035821: train_loss -0.9239 
2025-01-18 15:46:11.036330: val_loss -0.4585 
2025-01-18 15:46:11.042375: Pseudo dice [np.float32(0.6965), np.float32(0.3118)] 
2025-01-18 15:46:11.044611: Epoch time: 31.82 s 
2025-01-18 15:46:11.617523:  
2025-01-18 15:46:11.618527: Epoch 206 
2025-01-18 15:46:11.624626: Current learning rate: 0.00209 
2025-01-18 15:46:43.417675: train_loss -0.923 
2025-01-18 15:46:43.418179: val_loss -0.4304 
2025-01-18 15:46:43.424335: Pseudo dice [np.float32(0.7124), np.float32(0.2363)] 
2025-01-18 15:46:43.428394: Epoch time: 31.8 s 
2025-01-18 15:46:44.133963:  
2025-01-18 15:46:44.134465: Epoch 207 
2025-01-18 15:46:44.139481: Current learning rate: 0.00205 
2025-01-18 15:47:15.941445: train_loss -0.9284 
2025-01-18 15:47:15.941445: val_loss -0.4378 
2025-01-18 15:47:15.947541: Pseudo dice [np.float32(0.7044), np.float32(0.261)] 
2025-01-18 15:47:15.952199: Epoch time: 31.81 s 
2025-01-18 15:47:16.494197:  
2025-01-18 15:47:16.494197: Epoch 208 
2025-01-18 15:47:16.500768: Current learning rate: 0.00201 
2025-01-18 15:47:48.301278: train_loss -0.927 
2025-01-18 15:47:48.302850: val_loss -0.4651 
2025-01-18 15:47:48.309629: Pseudo dice [np.float32(0.7159), np.float32(0.2705)] 
2025-01-18 15:47:48.313637: Epoch time: 31.81 s 
2025-01-18 15:47:48.849595:  
2025-01-18 15:47:48.850594: Epoch 209 
2025-01-18 15:47:48.856242: Current learning rate: 0.00196 
2025-01-18 15:48:20.639328: train_loss -0.9264 
2025-01-18 15:48:20.639328: val_loss -0.4714 
2025-01-18 15:48:20.646848: Pseudo dice [np.float32(0.7484), np.float32(0.261)] 
2025-01-18 15:48:20.649860: Epoch time: 31.79 s 
2025-01-18 15:48:21.187500:  
2025-01-18 15:48:21.187500: Epoch 210 
2025-01-18 15:48:21.194092: Current learning rate: 0.00192 
2025-01-18 15:48:52.994016: train_loss -0.928 
2025-01-18 15:48:52.994016: val_loss -0.3972 
2025-01-18 15:48:53.000032: Pseudo dice [np.float32(0.6935), np.float32(0.1918)] 
2025-01-18 15:48:53.005045: Epoch time: 31.81 s 
2025-01-18 15:48:53.542872:  
2025-01-18 15:48:53.542872: Epoch 211 
2025-01-18 15:48:53.548967: Current learning rate: 0.00188 
2025-01-18 15:49:25.351385: train_loss -0.9335 
2025-01-18 15:49:25.352385: val_loss -0.4259 
2025-01-18 15:49:25.358916: Pseudo dice [np.float32(0.709), np.float32(0.2166)] 
2025-01-18 15:49:25.363489: Epoch time: 31.81 s 
2025-01-18 15:49:25.908238:  
2025-01-18 15:49:25.908238: Epoch 212 
2025-01-18 15:49:25.914256: Current learning rate: 0.00184 
2025-01-18 15:49:57.716701: train_loss -0.9307 
2025-01-18 15:49:57.718214: val_loss -0.4492 
2025-01-18 15:49:57.724753: Pseudo dice [np.float32(0.7179), np.float32(0.2661)] 
2025-01-18 15:49:57.728260: Epoch time: 31.81 s 
2025-01-18 15:49:58.262303:  
2025-01-18 15:49:58.263303: Epoch 213 
2025-01-18 15:49:58.268818: Current learning rate: 0.00179 
2025-01-18 15:50:30.070281: train_loss -0.9237 
2025-01-18 15:50:30.071281: val_loss -0.475 
2025-01-18 15:50:30.077810: Pseudo dice [np.float32(0.7168), np.float32(0.3244)] 
2025-01-18 15:50:30.082331: Epoch time: 31.81 s 
2025-01-18 15:50:30.625689:  
2025-01-18 15:50:30.625689: Epoch 214 
2025-01-18 15:50:30.631737: Current learning rate: 0.00175 
2025-01-18 15:51:02.427430: train_loss -0.928 
2025-01-18 15:51:02.428936: val_loss -0.4727 
2025-01-18 15:51:02.433953: Pseudo dice [np.float32(0.7158), np.float32(0.3438)] 
2025-01-18 15:51:02.438968: Epoch time: 31.8 s 
2025-01-18 15:51:03.125104:  
2025-01-18 15:51:03.126103: Epoch 215 
2025-01-18 15:51:03.131682: Current learning rate: 0.0017 
2025-01-18 15:51:34.908810: train_loss -0.9264 
2025-01-18 15:51:34.909814: val_loss -0.4365 
2025-01-18 15:51:34.917294: Pseudo dice [np.float32(0.7102), np.float32(0.2637)] 
2025-01-18 15:51:34.920843: Epoch time: 31.78 s 
2025-01-18 15:51:35.457525:  
2025-01-18 15:51:35.458030: Epoch 216 
2025-01-18 15:51:35.463041: Current learning rate: 0.00166 
2025-01-18 15:52:07.247997: train_loss -0.9271 
2025-01-18 15:52:07.247997: val_loss -0.441 
2025-01-18 15:52:07.254515: Pseudo dice [np.float32(0.7122), np.float32(0.2399)] 
2025-01-18 15:52:07.259027: Epoch time: 31.79 s 
2025-01-18 15:52:07.788799:  
2025-01-18 15:52:07.788799: Epoch 217 
2025-01-18 15:52:07.794350: Current learning rate: 0.00162 
2025-01-18 15:52:39.593444: train_loss -0.9309 
2025-01-18 15:52:39.593444: val_loss -0.4584 
2025-01-18 15:52:39.599963: Pseudo dice [np.float32(0.7079), np.float32(0.2637)] 
2025-01-18 15:52:39.602980: Epoch time: 31.81 s 
2025-01-18 15:52:40.154179:  
2025-01-18 15:52:40.154179: Epoch 218 
2025-01-18 15:52:40.159693: Current learning rate: 0.00157 
2025-01-18 15:53:11.965872: train_loss -0.9281 
2025-01-18 15:53:11.965872: val_loss -0.4445 
2025-01-18 15:53:11.972893: Pseudo dice [np.float32(0.7012), np.float32(0.253)] 
2025-01-18 15:53:11.976935: Epoch time: 31.81 s 
2025-01-18 15:53:12.521577:  
2025-01-18 15:53:12.521577: Epoch 219 
2025-01-18 15:53:12.527121: Current learning rate: 0.00153 
2025-01-18 15:53:44.314237: train_loss -0.9325 
2025-01-18 15:53:44.314237: val_loss -0.4451 
2025-01-18 15:53:44.320776: Pseudo dice [np.float32(0.7236), np.float32(0.2728)] 
2025-01-18 15:53:44.324307: Epoch time: 31.79 s 
2025-01-18 15:53:44.867007:  
2025-01-18 15:53:44.868011: Epoch 220 
2025-01-18 15:53:44.874603: Current learning rate: 0.00148 
2025-01-18 15:54:16.660816: train_loss -0.9228 
2025-01-18 15:54:16.661331: val_loss -0.484 
2025-01-18 15:54:16.667348: Pseudo dice [np.float32(0.6842), np.float32(0.3587)] 
2025-01-18 15:54:16.672362: Epoch time: 31.79 s 
2025-01-18 15:54:17.208242:  
2025-01-18 15:54:17.208242: Epoch 221 
2025-01-18 15:54:17.214796: Current learning rate: 0.00144 
2025-01-18 15:54:49.006816: train_loss -0.9289 
2025-01-18 15:54:49.007320: val_loss -0.4629 
2025-01-18 15:54:49.012859: Pseudo dice [np.float32(0.7216), np.float32(0.2587)] 
2025-01-18 15:54:49.018430: Epoch time: 31.8 s 
2025-01-18 15:54:49.556833:  
2025-01-18 15:54:49.557838: Epoch 222 
2025-01-18 15:54:49.562891: Current learning rate: 0.00139 
2025-01-18 15:55:21.374361: train_loss -0.9271 
2025-01-18 15:55:21.375365: val_loss -0.4375 
2025-01-18 15:55:21.381885: Pseudo dice [np.float32(0.7117), np.float32(0.2568)] 
2025-01-18 15:55:21.386958: Epoch time: 31.82 s 
2025-01-18 15:55:22.072132:  
2025-01-18 15:55:22.072132: Epoch 223 
2025-01-18 15:55:22.078148: Current learning rate: 0.00135 
2025-01-18 15:55:53.870392: train_loss -0.9313 
2025-01-18 15:55:53.870895: val_loss -0.4534 
2025-01-18 15:55:53.876984: Pseudo dice [np.float32(0.7133), np.float32(0.2577)] 
2025-01-18 15:55:53.881065: Epoch time: 31.8 s 
2025-01-18 15:55:54.419389:  
2025-01-18 15:55:54.419389: Epoch 224 
2025-01-18 15:55:54.424414: Current learning rate: 0.0013 
2025-01-18 15:56:26.225314: train_loss -0.9308 
2025-01-18 15:56:26.225314: val_loss -0.4116 
2025-01-18 15:56:26.234342: Pseudo dice [np.float32(0.6967), np.float32(0.2189)] 
2025-01-18 15:56:26.237850: Epoch time: 31.81 s 
2025-01-18 15:56:26.775476:  
2025-01-18 15:56:26.776475: Epoch 225 
2025-01-18 15:56:26.781586: Current learning rate: 0.00126 
2025-01-18 15:56:58.588569: train_loss -0.9301 
2025-01-18 15:56:58.589085: val_loss -0.4386 
2025-01-18 15:56:58.595717: Pseudo dice [np.float32(0.6985), np.float32(0.2492)] 
2025-01-18 15:56:58.598757: Epoch time: 31.81 s 
2025-01-18 15:56:59.148263:  
2025-01-18 15:56:59.149264: Epoch 226 
2025-01-18 15:56:59.154400: Current learning rate: 0.00121 
2025-01-18 15:57:30.953821: train_loss -0.9269 
2025-01-18 15:57:30.954323: val_loss -0.4773 
2025-01-18 15:57:30.960344: Pseudo dice [np.float32(0.7232), np.float32(0.2572)] 
2025-01-18 15:57:30.965359: Epoch time: 31.81 s 
2025-01-18 15:57:31.497056:  
2025-01-18 15:57:31.497056: Epoch 227 
2025-01-18 15:57:31.503103: Current learning rate: 0.00117 
2025-01-18 15:58:03.313319: train_loss -0.9284 
2025-01-18 15:58:03.314329: val_loss -0.4145 
2025-01-18 15:58:03.321012: Pseudo dice [np.float32(0.6937), np.float32(0.1872)] 
2025-01-18 15:58:03.326062: Epoch time: 31.82 s 
2025-01-18 15:58:03.867942:  
2025-01-18 15:58:03.867942: Epoch 228 
2025-01-18 15:58:03.874571: Current learning rate: 0.00112 
2025-01-18 15:58:35.668812: train_loss -0.9313 
2025-01-18 15:58:35.669817: val_loss -0.466 
2025-01-18 15:58:35.676858: Pseudo dice [np.float32(0.7173), np.float32(0.315)] 
2025-01-18 15:58:35.680890: Epoch time: 31.8 s 
2025-01-18 15:58:36.218695:  
2025-01-18 15:58:36.218695: Epoch 229 
2025-01-18 15:58:36.224809: Current learning rate: 0.00108 
2025-01-18 15:59:08.020515: train_loss -0.9285 
2025-01-18 15:59:08.020515: val_loss -0.4399 
2025-01-18 15:59:08.044144: Pseudo dice [np.float32(0.7216), np.float32(0.2253)] 
2025-01-18 15:59:08.048153: Epoch time: 31.8 s 
2025-01-18 15:59:08.589296:  
2025-01-18 15:59:08.589296: Epoch 230 
2025-01-18 15:59:08.595864: Current learning rate: 0.00103 
2025-01-18 15:59:40.386787: train_loss -0.9303 
2025-01-18 15:59:40.386787: val_loss -0.4771 
2025-01-18 15:59:40.393901: Pseudo dice [np.float32(0.7117), np.float32(0.3076)] 
2025-01-18 15:59:40.397410: Epoch time: 31.8 s 
2025-01-18 15:59:40.930633:  
2025-01-18 15:59:40.931638: Epoch 231 
2025-01-18 15:59:40.937688: Current learning rate: 0.00098 
2025-01-18 16:00:12.747188: train_loss -0.9351 
2025-01-18 16:00:12.747691: val_loss -0.4565 
2025-01-18 16:00:12.754710: Pseudo dice [np.float32(0.705), np.float32(0.2562)] 
2025-01-18 16:00:12.758725: Epoch time: 31.82 s 
2025-01-18 16:00:13.440766:  
2025-01-18 16:00:13.441769: Epoch 232 
2025-01-18 16:00:13.447839: Current learning rate: 0.00094 
2025-01-18 16:00:45.246462: train_loss -0.9296 
2025-01-18 16:00:45.246462: val_loss -0.4763 
2025-01-18 16:00:45.254488: Pseudo dice [np.float32(0.7032), np.float32(0.3147)] 
2025-01-18 16:00:45.258062: Epoch time: 31.81 s 
2025-01-18 16:00:45.808509:  
2025-01-18 16:00:45.809509: Epoch 233 
2025-01-18 16:00:45.815099: Current learning rate: 0.00089 
2025-01-18 16:01:17.604188: train_loss -0.9376 
2025-01-18 16:01:17.604692: val_loss -0.4651 
2025-01-18 16:01:17.611707: Pseudo dice [np.float32(0.7274), np.float32(0.2415)] 
2025-01-18 16:01:17.615302: Epoch time: 31.8 s 
2025-01-18 16:01:18.144247:  
2025-01-18 16:01:18.144247: Epoch 234 
2025-01-18 16:01:18.150920: Current learning rate: 0.00084 
2025-01-18 16:01:49.960497: train_loss -0.9345 
2025-01-18 16:01:49.961497: val_loss -0.4422 
2025-01-18 16:01:49.967013: Pseudo dice [np.float32(0.7091), np.float32(0.2484)] 
2025-01-18 16:01:49.970030: Epoch time: 31.82 s 
2025-01-18 16:01:50.500131:  
2025-01-18 16:01:50.500131: Epoch 235 
2025-01-18 16:01:50.506648: Current learning rate: 0.00079 
2025-01-18 16:02:22.293087: train_loss -0.9289 
2025-01-18 16:02:22.293589: val_loss -0.4188 
2025-01-18 16:02:22.300170: Pseudo dice [np.float32(0.679), np.float32(0.2339)] 
2025-01-18 16:02:22.304769: Epoch time: 31.79 s 
2025-01-18 16:02:22.838011:  
2025-01-18 16:02:22.838011: Epoch 236 
2025-01-18 16:02:22.844602: Current learning rate: 0.00075 
2025-01-18 16:02:54.637568: train_loss -0.9358 
2025-01-18 16:02:54.638071: val_loss -0.4587 
2025-01-18 16:02:54.644097: Pseudo dice [np.float32(0.6998), np.float32(0.2639)] 
2025-01-18 16:02:54.648105: Epoch time: 31.8 s 
2025-01-18 16:02:55.185437:  
2025-01-18 16:02:55.185437: Epoch 237 
2025-01-18 16:02:55.190979: Current learning rate: 0.0007 
2025-01-18 16:03:26.997807: train_loss -0.9315 
2025-01-18 16:03:26.998309: val_loss -0.4434 
2025-01-18 16:03:27.006425: Pseudo dice [np.float32(0.6979), np.float32(0.2479)] 
2025-01-18 16:03:27.009972: Epoch time: 31.81 s 
2025-01-18 16:03:27.539814:  
2025-01-18 16:03:27.540818: Epoch 238 
2025-01-18 16:03:27.545389: Current learning rate: 0.00065 
2025-01-18 16:03:59.347809: train_loss -0.9424 
2025-01-18 16:03:59.348314: val_loss -0.4639 
2025-01-18 16:03:59.354331: Pseudo dice [np.float32(0.7059), np.float32(0.3066)] 
2025-01-18 16:03:59.358870: Epoch time: 31.81 s 
2025-01-18 16:03:59.914847:  
2025-01-18 16:03:59.914847: Epoch 239 
2025-01-18 16:03:59.920907: Current learning rate: 0.0006 
2025-01-18 16:04:31.721730: train_loss -0.9281 
2025-01-18 16:04:31.721730: val_loss -0.457 
2025-01-18 16:04:31.729250: Pseudo dice [np.float32(0.7242), np.float32(0.2595)] 
2025-01-18 16:04:31.734265: Epoch time: 31.81 s 
2025-01-18 16:04:32.416901:  
2025-01-18 16:04:32.416901: Epoch 240 
2025-01-18 16:04:32.422998: Current learning rate: 0.00055 
2025-01-18 16:05:04.220708: train_loss -0.9305 
2025-01-18 16:05:04.220708: val_loss -0.423 
2025-01-18 16:05:04.228228: Pseudo dice [np.float32(0.6924), np.float32(0.1943)] 
2025-01-18 16:05:04.232738: Epoch time: 31.8 s 
2025-01-18 16:05:04.783874:  
2025-01-18 16:05:04.784392: Epoch 241 
2025-01-18 16:05:04.789042: Current learning rate: 0.0005 
2025-01-18 16:05:36.586349: train_loss -0.9365 
2025-01-18 16:05:36.586853: val_loss -0.452 
2025-01-18 16:05:36.593868: Pseudo dice [np.float32(0.7107), np.float32(0.2498)] 
2025-01-18 16:05:36.597907: Epoch time: 31.8 s 
2025-01-18 16:05:37.145843:  
2025-01-18 16:05:37.145843: Epoch 242 
2025-01-18 16:05:37.152420: Current learning rate: 0.00045 
2025-01-18 16:06:08.956741: train_loss -0.9365 
2025-01-18 16:06:08.958254: val_loss -0.4825 
2025-01-18 16:06:08.965022: Pseudo dice [np.float32(0.7054), np.float32(0.3507)] 
2025-01-18 16:06:08.969062: Epoch time: 31.81 s 
2025-01-18 16:06:09.517436:  
2025-01-18 16:06:09.517436: Epoch 243 
2025-01-18 16:06:09.522991: Current learning rate: 0.0004 
2025-01-18 16:06:41.316062: train_loss -0.9376 
2025-01-18 16:06:41.316565: val_loss -0.4482 
2025-01-18 16:06:41.323579: Pseudo dice [np.float32(0.7101), np.float32(0.2534)] 
2025-01-18 16:06:41.328149: Epoch time: 31.8 s 
2025-01-18 16:06:41.874637:  
2025-01-18 16:06:41.874637: Epoch 244 
2025-01-18 16:06:41.880208: Current learning rate: 0.00035 
2025-01-18 16:07:13.682193: train_loss -0.9384 
2025-01-18 16:07:13.682697: val_loss -0.4616 
2025-01-18 16:07:13.689720: Pseudo dice [np.float32(0.7186), np.float32(0.2546)] 
2025-01-18 16:07:13.694332: Epoch time: 31.81 s 
2025-01-18 16:07:14.247843:  
2025-01-18 16:07:14.248847: Epoch 245 
2025-01-18 16:07:14.255013: Current learning rate: 0.0003 
2025-01-18 16:07:46.061284: train_loss -0.9418 
2025-01-18 16:07:46.061800: val_loss -0.4285 
2025-01-18 16:07:46.067817: Pseudo dice [np.float32(0.6994), np.float32(0.2262)] 
2025-01-18 16:07:46.070844: Epoch time: 31.81 s 
2025-01-18 16:07:46.614138:  
2025-01-18 16:07:46.615138: Epoch 246 
2025-01-18 16:07:46.621655: Current learning rate: 0.00024 
2025-01-18 16:08:18.437925: train_loss -0.9366 
2025-01-18 16:08:18.438925: val_loss -0.4362 
2025-01-18 16:08:18.445449: Pseudo dice [np.float32(0.6983), np.float32(0.2421)] 
2025-01-18 16:08:18.449465: Epoch time: 31.82 s 
2025-01-18 16:08:18.996751:  
2025-01-18 16:08:18.996751: Epoch 247 
2025-01-18 16:08:19.002776: Current learning rate: 0.00019 
2025-01-18 16:08:50.816184: train_loss -0.9418 
2025-01-18 16:08:50.817183: val_loss -0.4668 
2025-01-18 16:08:50.822704: Pseudo dice [np.float32(0.7167), np.float32(0.2988)] 
2025-01-18 16:08:50.827721: Epoch time: 31.82 s 
2025-01-18 16:08:51.371843:  
2025-01-18 16:08:51.371843: Epoch 248 
2025-01-18 16:08:51.377939: Current learning rate: 0.00013 
2025-01-18 16:09:23.169631: train_loss -0.9405 
2025-01-18 16:09:23.171137: val_loss -0.4274 
2025-01-18 16:09:23.178152: Pseudo dice [np.float32(0.7108), np.float32(0.2231)] 
2025-01-18 16:09:23.181692: Epoch time: 31.8 s 
2025-01-18 16:09:23.880459:  
2025-01-18 16:09:23.881461: Epoch 249 
2025-01-18 16:09:23.887039: Current learning rate: 7e-05 
2025-01-18 16:09:55.677640: train_loss -0.9337 
2025-01-18 16:09:55.678640: val_loss -0.4439 
2025-01-18 16:09:55.685159: Pseudo dice [np.float32(0.7071), np.float32(0.2651)] 
2025-01-18 16:09:55.691673: Epoch time: 31.8 s 
2025-01-18 16:09:56.538992: Training done. 
2025-01-18 16:09:56.559024: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-18 16:09:56.566021: The split file contains 5 splits. 
2025-01-18 16:09:56.571023: Desired fold for training: 0 
2025-01-18 16:09:56.578022: This split has 224 training and 57 validation cases. 
2025-01-18 16:09:56.583022: predicting pancreas_021 
2025-01-18 16:09:56.590022: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-18 16:09:58.537966: predicting pancreas_024 
2025-01-18 16:09:58.553473: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-18 16:09:59.042135: predicting pancreas_035 
2025-01-18 16:09:59.057642: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-18 16:09:59.391171: predicting pancreas_040 
2025-01-18 16:09:59.399173: pancreas_040, shape torch.Size([1, 45, 526, 526]), rank 0 
2025-01-18 16:10:00.132171: predicting pancreas_042 
2025-01-18 16:10:00.139175: pancreas_042, shape torch.Size([1, 51, 537, 537]), rank 0 
2025-01-18 16:10:00.953096: predicting pancreas_056 
2025-01-18 16:10:00.962096: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-18 16:10:01.354299: predicting pancreas_067 
2025-01-18 16:10:01.366299: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-18 16:10:03.019798: predicting pancreas_075 
2025-01-18 16:10:03.039803: pancreas_075, shape torch.Size([1, 121, 521, 521]), rank 0 
2025-01-18 16:10:05.807216: predicting pancreas_086 
2025-01-18 16:10:05.826217: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-18 16:10:06.767912: predicting pancreas_089 
2025-01-18 16:10:06.777913: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-18 16:10:07.318977: predicting pancreas_092 
2025-01-18 16:10:07.332977: pancreas_092, shape torch.Size([1, 92, 513, 513]), rank 0 
2025-01-18 16:10:09.090507: predicting pancreas_094 
2025-01-18 16:10:09.104507: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-18 16:10:09.557191: predicting pancreas_095 
2025-01-18 16:10:09.570190: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-18 16:10:10.134875: predicting pancreas_098 
2025-01-18 16:10:10.145879: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-18 16:10:13.101311: predicting pancreas_109 
2025-01-18 16:10:13.130311: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-18 16:10:13.714011: predicting pancreas_110 
2025-01-18 16:10:13.730012: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-18 16:10:15.829953: predicting pancreas_114 
2025-01-18 16:10:15.856460: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-18 16:10:16.389999: predicting pancreas_119 
2025-01-18 16:10:16.401999: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-18 16:10:18.044136: predicting pancreas_138 
2025-01-18 16:10:18.062641: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-18 16:10:19.807523: predicting pancreas_145 
2025-01-18 16:10:19.826524: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-18 16:10:21.606101: predicting pancreas_148 
2025-01-18 16:10:21.626101: pancreas_148, shape torch.Size([1, 42, 486, 486]), rank 0 
2025-01-18 16:10:21.879128: predicting pancreas_169 
2025-01-18 16:10:21.886130: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-18 16:10:22.384315: predicting pancreas_170 
2025-01-18 16:10:22.396317: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-18 16:10:22.994570: predicting pancreas_172 
2025-01-18 16:10:23.011573: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-18 16:10:23.581617: predicting pancreas_175 
2025-01-18 16:10:23.594617: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-18 16:10:24.124001: predicting pancreas_180 
2025-01-18 16:10:24.138001: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-18 16:10:24.674567: predicting pancreas_191 
2025-01-18 16:10:24.689567: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-18 16:10:25.013638: predicting pancreas_193 
2025-01-18 16:10:25.022638: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-18 16:10:25.715828: predicting pancreas_212 
2025-01-18 16:10:25.733829: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-18 16:10:27.600135: predicting pancreas_215 
2025-01-18 16:10:27.614135: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-18 16:10:28.139554: predicting pancreas_222 
2025-01-18 16:10:28.154557: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-18 16:10:28.577114: predicting pancreas_235 
2025-01-18 16:10:28.585114: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-18 16:10:29.053150: predicting pancreas_241 
2025-01-18 16:10:29.064657: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-18 16:10:29.622823: predicting pancreas_242 
2025-01-18 16:10:29.638824: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-18 16:10:31.599447: predicting pancreas_244 
2025-01-18 16:10:31.618448: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-18 16:10:33.567097: predicting pancreas_246 
2025-01-18 16:10:33.585097: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-18 16:10:35.501906: predicting pancreas_247 
2025-01-18 16:10:35.518906: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-18 16:10:36.004117: predicting pancreas_264 
2025-01-18 16:10:36.012117: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-18 16:10:38.066564: predicting pancreas_265 
2025-01-18 16:10:38.084564: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-18 16:10:39.611002: predicting pancreas_266 
2025-01-18 16:10:39.625004: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-18 16:10:41.455449: predicting pancreas_267 
2025-01-18 16:10:41.473958: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-18 16:10:41.971091: predicting pancreas_275 
2025-01-18 16:10:41.982091: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-18 16:10:42.587747: predicting pancreas_279 
2025-01-18 16:10:42.600748: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-18 16:10:43.036967: predicting pancreas_287 
2025-01-18 16:10:43.045968: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-18 16:10:43.662111: predicting pancreas_301 
2025-01-18 16:10:43.679112: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-18 16:10:45.278385: predicting pancreas_323 
2025-01-18 16:10:45.293386: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-18 16:10:47.131966: predicting pancreas_336 
2025-01-18 16:10:47.150969: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-18 16:10:48.919956: predicting pancreas_344 
2025-01-18 16:10:48.934956: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-18 16:10:49.537570: predicting pancreas_351 
2025-01-18 16:10:49.551579: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-18 16:10:50.047653: predicting pancreas_354 
2025-01-18 16:10:50.056657: pancreas_354, shape torch.Size([1, 81, 529, 529]), rank 0 
2025-01-18 16:10:51.498826: predicting pancreas_372 
2025-01-18 16:10:51.513827: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-18 16:10:53.220931: predicting pancreas_377 
2025-01-18 16:10:53.236931: pancreas_377, shape torch.Size([1, 55, 551, 551]), rank 0 
2025-01-18 16:10:54.284074: predicting pancreas_387 
2025-01-18 16:10:54.295074: pancreas_387, shape torch.Size([1, 50, 498, 498]), rank 0 
2025-01-18 16:10:54.563599: predicting pancreas_391 
2025-01-18 16:10:54.572106: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-18 16:10:56.199122: predicting pancreas_392 
2025-01-18 16:10:56.215122: pancreas_392, shape torch.Size([1, 57, 448, 448]), rank 0 
2025-01-18 16:10:56.519251: predicting pancreas_410 
2025-01-18 16:10:56.526251: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-18 16:10:57.028381: predicting pancreas_412 
2025-01-18 16:10:57.039382: pancreas_412, shape torch.Size([1, 164, 584, 584]), rank 0 
2025-01-18 16:11:11.569107: Validation complete 
2025-01-18 16:11:11.569107: Mean Validation Dice:  0.45692909654241876 
