
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-02 05:40:04.029140: do_dummy_2d_data_aug: True 
2025-01-02 05:40:04.045137: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-02 05:40:04.054140: The split file contains 5 splits. 
2025-01-02 05:40:04.056137: Desired fold for training: 0 
2025-01-02 05:40:04.059139: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-02 05:40:12.120954: unpacking dataset... 
2025-01-02 05:40:36.470145: unpacking done... 
2025-01-02 05:40:41.681829:  
2025-01-02 05:40:41.682332: Epoch 0 
2025-01-02 05:40:41.687345: Current learning rate: 0.01 
2025-01-02 05:41:27.275301: train_loss 0.0965 
2025-01-02 05:41:27.275301: val_loss 0.0305 
2025-01-02 05:41:27.281819: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-02 05:41:27.284326: Epoch time: 45.59 s 
2025-01-02 05:41:27.287344: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-02 05:41:27.955861:  
2025-01-02 05:41:27.955861: Epoch 1 
2025-01-02 05:41:27.960907: Current learning rate: 0.00996 
2025-01-02 05:42:08.791489: train_loss 0.003 
2025-01-02 05:42:08.791489: val_loss -0.0718 
2025-01-02 05:42:08.798004: Pseudo dice [np.float32(0.3518), np.float32(0.0)] 
2025-01-02 05:42:08.801020: Epoch time: 40.84 s 
2025-01-02 05:42:08.804069: Yayy! New best EMA pseudo Dice: 0.01759999990463257 
2025-01-02 05:42:09.544196:  
2025-01-02 05:42:09.545199: Epoch 2 
2025-01-02 05:42:09.550251: Current learning rate: 0.00993 
2025-01-02 05:42:50.360965: train_loss -0.0651 
2025-01-02 05:42:50.361477: val_loss -0.113 
2025-01-02 05:42:50.367607: Pseudo dice [np.float32(0.394), np.float32(0.0)] 
2025-01-02 05:42:50.370433: Epoch time: 40.82 s 
2025-01-02 05:42:50.373610: Yayy! New best EMA pseudo Dice: 0.03550000116229057 
2025-01-02 05:42:51.126988:  
2025-01-02 05:42:51.127994: Epoch 3 
2025-01-02 05:42:51.132534: Current learning rate: 0.00989 
2025-01-02 05:43:31.945946: train_loss -0.1149 
2025-01-02 05:43:31.946450: val_loss -0.163 
2025-01-02 05:43:31.952466: Pseudo dice [np.float32(0.4348), np.float32(0.0)] 
2025-01-02 05:43:31.954974: Epoch time: 40.82 s 
2025-01-02 05:43:31.958482: Yayy! New best EMA pseudo Dice: 0.053700000047683716 
2025-01-02 05:43:32.708691:  
2025-01-02 05:43:32.708691: Epoch 4 
2025-01-02 05:43:32.713704: Current learning rate: 0.00986 
2025-01-02 05:44:13.522377: train_loss -0.14 
2025-01-02 05:44:13.522377: val_loss -0.207 
2025-01-02 05:44:13.528401: Pseudo dice [np.float32(0.5007), np.float32(0.0)] 
2025-01-02 05:44:13.531913: Epoch time: 40.82 s 
2025-01-02 05:44:13.534924: Yayy! New best EMA pseudo Dice: 0.07339999824762344 
2025-01-02 05:44:14.424392:  
2025-01-02 05:44:14.425397: Epoch 5 
2025-01-02 05:44:14.429991: Current learning rate: 0.00982 
2025-01-02 05:44:55.281017: train_loss -0.1645 
2025-01-02 05:44:55.281017: val_loss -0.2095 
2025-01-02 05:44:55.287037: Pseudo dice [np.float32(0.4701), np.float32(0.0)] 
2025-01-02 05:44:55.290545: Epoch time: 40.86 s 
2025-01-02 05:44:55.293555: Yayy! New best EMA pseudo Dice: 0.08959999680519104 
2025-01-02 05:44:56.040705:  
2025-01-02 05:44:56.041709: Epoch 6 
2025-01-02 05:44:56.045234: Current learning rate: 0.00978 
2025-01-02 05:45:36.863957: train_loss -0.2101 
2025-01-02 05:45:36.865468: val_loss -0.1956 
2025-01-02 05:45:36.871502: Pseudo dice [np.float32(0.4704), np.float32(0.0)] 
2025-01-02 05:45:36.875013: Epoch time: 40.82 s 
2025-01-02 05:45:36.877519: Yayy! New best EMA pseudo Dice: 0.10409999638795853 
2025-01-02 05:45:37.608432:  
2025-01-02 05:45:37.609968: Epoch 7 
2025-01-02 05:45:37.615132: Current learning rate: 0.00975 
2025-01-02 05:46:18.410130: train_loss -0.2176 
2025-01-02 05:46:18.410130: val_loss -0.2746 
2025-01-02 05:46:18.418225: Pseudo dice [np.float32(0.4767), np.float32(0.213)] 
2025-01-02 05:46:18.420731: Epoch time: 40.8 s 
2025-01-02 05:46:18.424236: Yayy! New best EMA pseudo Dice: 0.1281999945640564 
2025-01-02 05:46:19.159963:  
2025-01-02 05:46:19.159963: Epoch 8 
2025-01-02 05:46:19.165497: Current learning rate: 0.00971 
2025-01-02 05:46:59.997049: train_loss -0.25 
2025-01-02 05:46:59.997561: val_loss -0.2755 
2025-01-02 05:47:00.004630: Pseudo dice [np.float32(0.49), np.float32(0.2212)] 
2025-01-02 05:47:00.010247: Epoch time: 40.84 s 
2025-01-02 05:47:00.013356: Yayy! New best EMA pseudo Dice: 0.1509000062942505 
2025-01-02 05:47:00.786655:  
2025-01-02 05:47:00.787656: Epoch 9 
2025-01-02 05:47:00.792228: Current learning rate: 0.00968 
2025-01-02 05:47:41.611569: train_loss -0.2468 
2025-01-02 05:47:41.612080: val_loss -0.3572 
2025-01-02 05:47:41.617637: Pseudo dice [np.float32(0.5602), np.float32(0.371)] 
2025-01-02 05:47:41.620670: Epoch time: 40.82 s 
2025-01-02 05:47:41.623718: Yayy! New best EMA pseudo Dice: 0.18240000307559967 
2025-01-02 05:47:42.328616:  
2025-01-02 05:47:42.329124: Epoch 10 
2025-01-02 05:47:42.334161: Current learning rate: 0.00964 
2025-01-02 05:48:23.167604: train_loss -0.2933 
2025-01-02 05:48:23.168607: val_loss -0.271 
2025-01-02 05:48:23.175137: Pseudo dice [np.float32(0.4965), np.float32(0.2993)] 
2025-01-02 05:48:23.179647: Epoch time: 40.84 s 
2025-01-02 05:48:23.183661: Yayy! New best EMA pseudo Dice: 0.20389999449253082 
2025-01-02 05:48:23.914857:  
2025-01-02 05:48:23.916362: Epoch 11 
2025-01-02 05:48:23.921451: Current learning rate: 0.0096 
2025-01-02 05:49:04.746445: train_loss -0.2622 
2025-01-02 05:49:04.746445: val_loss -0.2972 
2025-01-02 05:49:04.752465: Pseudo dice [np.float32(0.5328), np.float32(0.2436)] 
2025-01-02 05:49:04.754973: Epoch time: 40.83 s 
2025-01-02 05:49:04.758484: Yayy! New best EMA pseudo Dice: 0.2223999947309494 
2025-01-02 05:49:05.498568:  
2025-01-02 05:49:05.498568: Epoch 12 
2025-01-02 05:49:05.504154: Current learning rate: 0.00957 
2025-01-02 05:49:46.379059: train_loss -0.3104 
2025-01-02 05:49:46.379587: val_loss -0.3494 
2025-01-02 05:49:46.385609: Pseudo dice [np.float32(0.6007), np.float32(0.2642)] 
2025-01-02 05:49:46.389623: Epoch time: 40.88 s 
2025-01-02 05:49:46.392131: Yayy! New best EMA pseudo Dice: 0.2433999925851822 
2025-01-02 05:49:47.321504:  
2025-01-02 05:49:47.321504: Epoch 13 
2025-01-02 05:49:47.327521: Current learning rate: 0.00953 
2025-01-02 05:50:28.119946: train_loss -0.295 
2025-01-02 05:50:28.119946: val_loss -0.3432 
2025-01-02 05:50:28.126987: Pseudo dice [np.float32(0.556), np.float32(0.3274)] 
2025-01-02 05:50:28.129492: Epoch time: 40.8 s 
2025-01-02 05:50:28.133000: Yayy! New best EMA pseudo Dice: 0.2632000148296356 
2025-01-02 05:50:28.854769:  
2025-01-02 05:50:28.854769: Epoch 14 
2025-01-02 05:50:28.860783: Current learning rate: 0.00949 
2025-01-02 05:51:09.644783: train_loss -0.3247 
2025-01-02 05:51:09.645286: val_loss -0.3456 
2025-01-02 05:51:09.650296: Pseudo dice [np.float32(0.5567), np.float32(0.3019)] 
2025-01-02 05:51:09.653805: Epoch time: 40.79 s 
2025-01-02 05:51:09.657309: Yayy! New best EMA pseudo Dice: 0.2797999978065491 
2025-01-02 05:51:10.418190:  
2025-01-02 05:51:10.418190: Epoch 15 
2025-01-02 05:51:10.423749: Current learning rate: 0.00946 
2025-01-02 05:51:51.235000: train_loss -0.3313 
2025-01-02 05:51:51.235512: val_loss -0.3696 
2025-01-02 05:51:51.241106: Pseudo dice [np.float32(0.6078), np.float32(0.255)] 
2025-01-02 05:51:51.244819: Epoch time: 40.82 s 
2025-01-02 05:51:51.247519: Yayy! New best EMA pseudo Dice: 0.29499998688697815 
2025-01-02 05:51:51.983969:  
2025-01-02 05:51:51.985472: Epoch 16 
2025-01-02 05:51:51.990486: Current learning rate: 0.00942 
2025-01-02 05:52:32.781599: train_loss -0.359 
2025-01-02 05:52:32.781599: val_loss -0.35 
2025-01-02 05:52:32.787668: Pseudo dice [np.float32(0.5664), np.float32(0.3354)] 
2025-01-02 05:52:32.790751: Epoch time: 40.8 s 
2025-01-02 05:52:32.793144: Yayy! New best EMA pseudo Dice: 0.31060001254081726 
2025-01-02 05:52:33.578358:  
2025-01-02 05:52:33.578860: Epoch 17 
2025-01-02 05:52:33.583873: Current learning rate: 0.00939 
2025-01-02 05:53:14.408252: train_loss -0.3329 
2025-01-02 05:53:14.408756: val_loss -0.3828 
2025-01-02 05:53:14.414771: Pseudo dice [np.float32(0.6197), np.float32(0.3625)] 
2025-01-02 05:53:14.417792: Epoch time: 40.83 s 
2025-01-02 05:53:14.420831: Yayy! New best EMA pseudo Dice: 0.3285999894142151 
2025-01-02 05:53:15.157717:  
2025-01-02 05:53:15.158717: Epoch 18 
2025-01-02 05:53:15.164233: Current learning rate: 0.00935 
2025-01-02 05:53:55.979647: train_loss -0.3524 
2025-01-02 05:53:55.979647: val_loss -0.4013 
2025-01-02 05:53:55.985671: Pseudo dice [np.float32(0.6178), np.float32(0.343)] 
2025-01-02 05:53:55.989184: Epoch time: 40.82 s 
2025-01-02 05:53:55.991695: Yayy! New best EMA pseudo Dice: 0.34380000829696655 
2025-01-02 05:53:56.748305:  
2025-01-02 05:53:56.748305: Epoch 19 
2025-01-02 05:53:56.753376: Current learning rate: 0.00931 
2025-01-02 05:54:37.544909: train_loss -0.3496 
2025-01-02 05:54:37.545412: val_loss -0.3753 
2025-01-02 05:54:37.551533: Pseudo dice [np.float32(0.6119), np.float32(0.317)] 
2025-01-02 05:54:37.554556: Epoch time: 40.8 s 
2025-01-02 05:54:37.558074: Yayy! New best EMA pseudo Dice: 0.35589998960494995 
2025-01-02 05:54:38.498683:  
2025-01-02 05:54:38.499686: Epoch 20 
2025-01-02 05:54:38.504255: Current learning rate: 0.00928 
2025-01-02 05:55:19.314834: train_loss -0.3724 
2025-01-02 05:55:19.314834: val_loss -0.3073 
2025-01-02 05:55:19.322350: Pseudo dice [np.float32(0.5235), np.float32(0.1932)] 
2025-01-02 05:55:19.325856: Epoch time: 40.82 s 
2025-01-02 05:55:19.328865: Yayy! New best EMA pseudo Dice: 0.3560999929904938 
2025-01-02 05:55:20.071538:  
2025-01-02 05:55:20.072539: Epoch 21 
2025-01-02 05:55:20.078122: Current learning rate: 0.00924 
2025-01-02 05:56:00.893073: train_loss -0.3437 
2025-01-02 05:56:00.893575: val_loss -0.3537 
2025-01-02 05:56:00.898597: Pseudo dice [np.float32(0.6465), np.float32(0.208)] 
2025-01-02 05:56:00.902109: Epoch time: 40.82 s 
2025-01-02 05:56:00.904616: Yayy! New best EMA pseudo Dice: 0.36320000886917114 
2025-01-02 05:56:01.641261:  
2025-01-02 05:56:01.641261: Epoch 22 
2025-01-02 05:56:01.646292: Current learning rate: 0.0092 
2025-01-02 05:56:42.440641: train_loss -0.3766 
2025-01-02 05:56:42.441158: val_loss -0.4438 
2025-01-02 05:56:42.447738: Pseudo dice [np.float32(0.6568), np.float32(0.3957)] 
2025-01-02 05:56:42.450863: Epoch time: 40.8 s 
2025-01-02 05:56:42.453932: Yayy! New best EMA pseudo Dice: 0.37950000166893005 
2025-01-02 05:56:43.179869:  
2025-01-02 05:56:43.180372: Epoch 23 
2025-01-02 05:56:43.185527: Current learning rate: 0.00917 
2025-01-02 05:57:24.021136: train_loss -0.4015 
2025-01-02 05:57:24.021650: val_loss -0.341 
2025-01-02 05:57:24.028041: Pseudo dice [np.float32(0.5679), np.float32(0.2764)] 
2025-01-02 05:57:24.031230: Epoch time: 40.84 s 
2025-01-02 05:57:24.034272: Yayy! New best EMA pseudo Dice: 0.3837999999523163 
2025-01-02 05:57:24.764229:  
2025-01-02 05:57:24.764229: Epoch 24 
2025-01-02 05:57:24.768739: Current learning rate: 0.00913 
2025-01-02 05:58:05.560717: train_loss -0.397 
2025-01-02 05:58:05.561721: val_loss -0.4033 
2025-01-02 05:58:05.566737: Pseudo dice [np.float32(0.6502), np.float32(0.3921)] 
2025-01-02 05:58:05.570745: Epoch time: 40.8 s 
2025-01-02 05:58:05.573251: Yayy! New best EMA pseudo Dice: 0.39750000834465027 
2025-01-02 05:58:06.300353:  
2025-01-02 05:58:06.300856: Epoch 25 
2025-01-02 05:58:06.305943: Current learning rate: 0.0091 
2025-01-02 05:58:47.110951: train_loss -0.3984 
2025-01-02 05:58:47.110951: val_loss -0.4305 
2025-01-02 05:58:47.116961: Pseudo dice [np.float32(0.6596), np.float32(0.3384)] 
2025-01-02 05:58:47.119972: Epoch time: 40.81 s 
2025-01-02 05:58:47.122478: Yayy! New best EMA pseudo Dice: 0.4077000021934509 
2025-01-02 05:58:47.856412:  
2025-01-02 05:58:47.856412: Epoch 26 
2025-01-02 05:58:47.861938: Current learning rate: 0.00906 
2025-01-02 05:59:28.683233: train_loss -0.4112 
2025-01-02 05:59:28.683233: val_loss -0.428 
2025-01-02 05:59:28.689268: Pseudo dice [np.float32(0.6716), np.float32(0.3787)] 
2025-01-02 05:59:28.692852: Epoch time: 40.83 s 
2025-01-02 05:59:28.695901: Yayy! New best EMA pseudo Dice: 0.41940000653266907 
2025-01-02 05:59:29.441533:  
2025-01-02 05:59:29.441533: Epoch 27 
2025-01-02 05:59:29.447071: Current learning rate: 0.00902 
2025-01-02 06:00:10.265121: train_loss -0.3986 
2025-01-02 06:00:10.265638: val_loss -0.4091 
2025-01-02 06:00:10.271230: Pseudo dice [np.float32(0.6698), np.float32(0.2959)] 
2025-01-02 06:00:10.274283: Epoch time: 40.82 s 
2025-01-02 06:00:10.276292: Yayy! New best EMA pseudo Dice: 0.42579999566078186 
2025-01-02 06:00:11.165370:  
2025-01-02 06:00:11.166376: Epoch 28 
2025-01-02 06:00:11.171431: Current learning rate: 0.00899 
2025-01-02 06:00:51.971244: train_loss -0.3962 
2025-01-02 06:00:51.971244: val_loss -0.4364 
2025-01-02 06:00:51.977257: Pseudo dice [np.float32(0.6073), np.float32(0.403)] 
2025-01-02 06:00:51.979763: Epoch time: 40.81 s 
2025-01-02 06:00:51.983268: Yayy! New best EMA pseudo Dice: 0.43369999527931213 
2025-01-02 06:00:52.703847:  
2025-01-02 06:00:52.703847: Epoch 29 
2025-01-02 06:00:52.708878: Current learning rate: 0.00895 
2025-01-02 06:01:33.571906: train_loss -0.4014 
2025-01-02 06:01:33.572907: val_loss -0.4349 
2025-01-02 06:01:33.578424: Pseudo dice [np.float32(0.6666), np.float32(0.3968)] 
2025-01-02 06:01:33.581936: Epoch time: 40.87 s 
2025-01-02 06:01:33.584444: Yayy! New best EMA pseudo Dice: 0.44350001215934753 
2025-01-02 06:01:34.324724:  
2025-01-02 06:01:34.325727: Epoch 30 
2025-01-02 06:01:34.330772: Current learning rate: 0.00891 
2025-01-02 06:02:15.130513: train_loss -0.4262 
2025-01-02 06:02:15.131513: val_loss -0.4207 
2025-01-02 06:02:15.137035: Pseudo dice [np.float32(0.6146), np.float32(0.3583)] 
2025-01-02 06:02:15.140548: Epoch time: 40.81 s 
2025-01-02 06:02:15.143057: Yayy! New best EMA pseudo Dice: 0.44780001044273376 
2025-01-02 06:02:15.871080:  
2025-01-02 06:02:15.871080: Epoch 31 
2025-01-02 06:02:15.876624: Current learning rate: 0.00888 
2025-01-02 06:02:56.668492: train_loss -0.4692 
2025-01-02 06:02:56.668492: val_loss -0.4771 
2025-01-02 06:02:56.674680: Pseudo dice [np.float32(0.6683), np.float32(0.4436)] 
2025-01-02 06:02:56.678190: Epoch time: 40.8 s 
2025-01-02 06:02:56.680697: Yayy! New best EMA pseudo Dice: 0.4586000144481659 
2025-01-02 06:02:57.432332:  
2025-01-02 06:02:57.432332: Epoch 32 
2025-01-02 06:02:57.437345: Current learning rate: 0.00884 
2025-01-02 06:03:38.224885: train_loss -0.4546 
2025-01-02 06:03:38.225391: val_loss -0.4459 
2025-01-02 06:03:38.230405: Pseudo dice [np.float32(0.6878), np.float32(0.3111)] 
2025-01-02 06:03:38.233917: Epoch time: 40.79 s 
2025-01-02 06:03:38.237424: Yayy! New best EMA pseudo Dice: 0.4627000093460083 
2025-01-02 06:03:38.975493:  
2025-01-02 06:03:38.976496: Epoch 33 
2025-01-02 06:03:38.981053: Current learning rate: 0.0088 
2025-01-02 06:04:19.800922: train_loss -0.4315 
2025-01-02 06:04:19.801424: val_loss -0.4988 
2025-01-02 06:04:19.808466: Pseudo dice [np.float32(0.6847), np.float32(0.4391)] 
2025-01-02 06:04:19.811482: Epoch time: 40.83 s 
2025-01-02 06:04:19.814502: Yayy! New best EMA pseudo Dice: 0.4726000130176544 
2025-01-02 06:04:20.552913:  
2025-01-02 06:04:20.553916: Epoch 34 
2025-01-02 06:04:20.558461: Current learning rate: 0.00877 
2025-01-02 06:05:01.367622: train_loss -0.4636 
2025-01-02 06:05:01.367622: val_loss -0.5005 
2025-01-02 06:05:01.374137: Pseudo dice [np.float32(0.6843), np.float32(0.4292)] 
2025-01-02 06:05:01.377651: Epoch time: 40.81 s 
2025-01-02 06:05:01.380161: Yayy! New best EMA pseudo Dice: 0.48100000619888306 
2025-01-02 06:05:02.131330:  
2025-01-02 06:05:02.131833: Epoch 35 
2025-01-02 06:05:02.136846: Current learning rate: 0.00873 
2025-01-02 06:05:42.960944: train_loss -0.4476 
2025-01-02 06:05:42.960944: val_loss -0.3815 
2025-01-02 06:05:42.967472: Pseudo dice [np.float32(0.6348), np.float32(0.2094)] 
2025-01-02 06:05:42.970981: Epoch time: 40.83 s 
2025-01-02 06:05:43.547361:  
2025-01-02 06:05:43.548363: Epoch 36 
2025-01-02 06:05:43.553878: Current learning rate: 0.00869 
2025-01-02 06:06:24.370562: train_loss -0.4587 
2025-01-02 06:06:24.371065: val_loss -0.4388 
2025-01-02 06:06:24.377094: Pseudo dice [np.float32(0.6068), np.float32(0.3298)] 
2025-01-02 06:06:24.381106: Epoch time: 40.82 s 
2025-01-02 06:06:25.116554:  
2025-01-02 06:06:25.117555: Epoch 37 
2025-01-02 06:06:25.122607: Current learning rate: 0.00866 
2025-01-02 06:07:05.929744: train_loss -0.4281 
2025-01-02 06:07:05.929744: val_loss -0.4828 
2025-01-02 06:07:05.936263: Pseudo dice [np.float32(0.6456), np.float32(0.5077)] 
2025-01-02 06:07:05.938770: Epoch time: 40.81 s 
2025-01-02 06:07:05.942281: Yayy! New best EMA pseudo Dice: 0.4846999943256378 
2025-01-02 06:07:06.703651:  
2025-01-02 06:07:06.703651: Epoch 38 
2025-01-02 06:07:06.708682: Current learning rate: 0.00862 
2025-01-02 06:07:47.515317: train_loss -0.4187 
2025-01-02 06:07:47.516321: val_loss -0.4805 
2025-01-02 06:07:47.521840: Pseudo dice [np.float32(0.6645), np.float32(0.4466)] 
2025-01-02 06:07:47.523846: Epoch time: 40.81 s 
2025-01-02 06:07:47.527903: Yayy! New best EMA pseudo Dice: 0.4918000102043152 
2025-01-02 06:07:48.271359:  
2025-01-02 06:07:48.271862: Epoch 39 
2025-01-02 06:07:48.276873: Current learning rate: 0.00858 
2025-01-02 06:08:29.076337: train_loss -0.457 
2025-01-02 06:08:29.076840: val_loss -0.4616 
2025-01-02 06:08:29.082854: Pseudo dice [np.float32(0.6986), np.float32(0.3799)] 
2025-01-02 06:08:29.086377: Epoch time: 40.81 s 
2025-01-02 06:08:29.089399: Yayy! New best EMA pseudo Dice: 0.4964999854564667 
2025-01-02 06:08:29.847726:  
2025-01-02 06:08:29.848730: Epoch 40 
2025-01-02 06:08:29.853760: Current learning rate: 0.00855 
2025-01-02 06:09:10.667806: train_loss -0.4679 
2025-01-02 06:09:10.668809: val_loss -0.4819 
2025-01-02 06:09:10.674826: Pseudo dice [np.float32(0.7036), np.float32(0.3713)] 
2025-01-02 06:09:10.677835: Epoch time: 40.82 s 
2025-01-02 06:09:10.680341: Yayy! New best EMA pseudo Dice: 0.5005999803543091 
2025-01-02 06:09:11.451869:  
2025-01-02 06:09:11.451869: Epoch 41 
2025-01-02 06:09:11.457412: Current learning rate: 0.00851 
2025-01-02 06:09:52.292261: train_loss -0.455 
2025-01-02 06:09:52.292781: val_loss -0.5017 
2025-01-02 06:09:52.297868: Pseudo dice [np.float32(0.7053), np.float32(0.4118)] 
2025-01-02 06:09:52.301377: Epoch time: 40.84 s 
2025-01-02 06:09:52.303883: Yayy! New best EMA pseudo Dice: 0.5063999891281128 
2025-01-02 06:09:53.075452:  
2025-01-02 06:09:53.075452: Epoch 42 
2025-01-02 06:09:53.080995: Current learning rate: 0.00847 
2025-01-02 06:10:33.913174: train_loss -0.4611 
2025-01-02 06:10:33.913700: val_loss -0.4703 
2025-01-02 06:10:33.920771: Pseudo dice [np.float32(0.6597), np.float32(0.4097)] 
2025-01-02 06:10:33.923784: Epoch time: 40.84 s 
2025-01-02 06:10:33.926289: Yayy! New best EMA pseudo Dice: 0.5091999769210815 
2025-01-02 06:10:34.668487:  
2025-01-02 06:10:34.668487: Epoch 43 
2025-01-02 06:10:34.673541: Current learning rate: 0.00844 
2025-01-02 06:11:15.470213: train_loss -0.4751 
2025-01-02 06:11:15.470213: val_loss -0.5105 
2025-01-02 06:11:15.476223: Pseudo dice [np.float32(0.7116), np.float32(0.4174)] 
2025-01-02 06:11:15.480237: Epoch time: 40.8 s 
2025-01-02 06:11:15.482743: Yayy! New best EMA pseudo Dice: 0.5148000121116638 
2025-01-02 06:11:16.376966:  
2025-01-02 06:11:16.376966: Epoch 44 
2025-01-02 06:11:16.382500: Current learning rate: 0.0084 
2025-01-02 06:11:57.213083: train_loss -0.4901 
2025-01-02 06:11:57.214589: val_loss -0.4578 
2025-01-02 06:11:57.220119: Pseudo dice [np.float32(0.6985), np.float32(0.3587)] 
2025-01-02 06:11:57.223144: Epoch time: 40.84 s 
2025-01-02 06:11:57.225661: Yayy! New best EMA pseudo Dice: 0.5160999894142151 
2025-01-02 06:11:57.980814:  
2025-01-02 06:11:57.981316: Epoch 45 
2025-01-02 06:11:57.986328: Current learning rate: 0.00836 
2025-01-02 06:12:38.883126: train_loss -0.473 
2025-01-02 06:12:38.884129: val_loss -0.4708 
2025-01-02 06:12:38.890239: Pseudo dice [np.float32(0.6846), np.float32(0.3501)] 
2025-01-02 06:12:38.893250: Epoch time: 40.9 s 
2025-01-02 06:12:38.895759: Yayy! New best EMA pseudo Dice: 0.5163000226020813 
2025-01-02 06:12:39.617981:  
2025-01-02 06:12:39.617981: Epoch 46 
2025-01-02 06:12:39.622992: Current learning rate: 0.00833 
2025-01-02 06:13:20.429051: train_loss -0.4848 
2025-01-02 06:13:20.430054: val_loss -0.4189 
2025-01-02 06:13:20.436573: Pseudo dice [np.float32(0.6488), np.float32(0.3028)] 
2025-01-02 06:13:20.440081: Epoch time: 40.81 s 
2025-01-02 06:13:21.003367:  
2025-01-02 06:13:21.003876: Epoch 47 
2025-01-02 06:13:21.008427: Current learning rate: 0.00829 
2025-01-02 06:14:01.825571: train_loss -0.5093 
2025-01-02 06:14:01.825571: val_loss -0.4786 
2025-01-02 06:14:01.831598: Pseudo dice [np.float32(0.6954), np.float32(0.3702)] 
2025-01-02 06:14:01.834618: Epoch time: 40.82 s 
2025-01-02 06:14:02.390869:  
2025-01-02 06:14:02.391869: Epoch 48 
2025-01-02 06:14:02.396948: Current learning rate: 0.00825 
2025-01-02 06:14:43.208502: train_loss -0.4955 
2025-01-02 06:14:43.209012: val_loss -0.4733 
2025-01-02 06:14:43.214070: Pseudo dice [np.float32(0.71), np.float32(0.3235)] 
2025-01-02 06:14:43.217599: Epoch time: 40.82 s 
2025-01-02 06:14:43.781144:  
2025-01-02 06:14:43.781144: Epoch 49 
2025-01-02 06:14:43.786190: Current learning rate: 0.00822 
2025-01-02 06:15:24.591690: train_loss -0.4843 
2025-01-02 06:15:24.591690: val_loss -0.5079 
2025-01-02 06:15:24.595700: Pseudo dice [np.float32(0.7103), np.float32(0.3916)] 
2025-01-02 06:15:24.599247: Epoch time: 40.81 s 
2025-01-02 06:15:24.753883: Yayy! New best EMA pseudo Dice: 0.5181999802589417 
2025-01-02 06:15:25.554947:  
2025-01-02 06:15:25.555952: Epoch 50 
2025-01-02 06:15:25.561551: Current learning rate: 0.00818 
2025-01-02 06:16:06.406477: train_loss -0.5129 
2025-01-02 06:16:06.406979: val_loss -0.5711 
2025-01-02 06:16:06.411991: Pseudo dice [np.float32(0.7469), np.float32(0.5757)] 
2025-01-02 06:16:06.415499: Epoch time: 40.85 s 
2025-01-02 06:16:06.418015: Yayy! New best EMA pseudo Dice: 0.5325000286102295 
2025-01-02 06:16:07.163984:  
2025-01-02 06:16:07.164487: Epoch 51 
2025-01-02 06:16:07.169499: Current learning rate: 0.00814 
2025-01-02 06:16:47.985347: train_loss -0.5327 
2025-01-02 06:16:47.985851: val_loss -0.5355 
2025-01-02 06:16:47.991919: Pseudo dice [np.float32(0.7453), np.float32(0.4437)] 
2025-01-02 06:16:47.995441: Epoch time: 40.82 s 
2025-01-02 06:16:47.997961: Yayy! New best EMA pseudo Dice: 0.5386999845504761 
2025-01-02 06:16:48.916696:  
2025-01-02 06:16:48.916696: Epoch 52 
2025-01-02 06:16:48.922232: Current learning rate: 0.00811 
2025-01-02 06:17:29.722913: train_loss -0.492 
2025-01-02 06:17:29.723415: val_loss -0.4737 
2025-01-02 06:17:29.730428: Pseudo dice [np.float32(0.693), np.float32(0.3781)] 
2025-01-02 06:17:29.733436: Epoch time: 40.81 s 
2025-01-02 06:17:30.300085:  
2025-01-02 06:17:30.301088: Epoch 53 
2025-01-02 06:17:30.305647: Current learning rate: 0.00807 
2025-01-02 06:18:11.090819: train_loss -0.4997 
2025-01-02 06:18:11.091322: val_loss -0.438 
2025-01-02 06:18:11.096333: Pseudo dice [np.float32(0.6818), np.float32(0.2562)] 
2025-01-02 06:18:11.099842: Epoch time: 40.79 s 
2025-01-02 06:18:11.672197:  
2025-01-02 06:18:11.673197: Epoch 54 
2025-01-02 06:18:11.678267: Current learning rate: 0.00803 
2025-01-02 06:18:52.510243: train_loss -0.4937 
2025-01-02 06:18:52.511247: val_loss -0.4883 
2025-01-02 06:18:52.517760: Pseudo dice [np.float32(0.6904), np.float32(0.4153)] 
2025-01-02 06:18:52.520778: Epoch time: 40.84 s 
2025-01-02 06:18:53.104981:  
2025-01-02 06:18:53.104981: Epoch 55 
2025-01-02 06:18:53.110521: Current learning rate: 0.008 
2025-01-02 06:19:33.909346: train_loss -0.4948 
2025-01-02 06:19:33.910351: val_loss -0.5167 
2025-01-02 06:19:33.916370: Pseudo dice [np.float32(0.7078), np.float32(0.3934)] 
2025-01-02 06:19:33.919382: Epoch time: 40.8 s 
2025-01-02 06:19:34.486781:  
2025-01-02 06:19:34.486781: Epoch 56 
2025-01-02 06:19:34.492417: Current learning rate: 0.00796 
2025-01-02 06:20:15.304733: train_loss -0.5159 
2025-01-02 06:20:15.305738: val_loss -0.5583 
2025-01-02 06:20:15.311441: Pseudo dice [np.float32(0.7479), np.float32(0.5005)] 
2025-01-02 06:20:15.314518: Epoch time: 40.82 s 
2025-01-02 06:20:15.317604: Yayy! New best EMA pseudo Dice: 0.5442000031471252 
2025-01-02 06:20:16.052619:  
2025-01-02 06:20:16.052619: Epoch 57 
2025-01-02 06:20:16.058155: Current learning rate: 0.00792 
2025-01-02 06:20:56.874908: train_loss -0.5302 
2025-01-02 06:20:56.875911: val_loss -0.4669 
2025-01-02 06:20:56.881929: Pseudo dice [np.float32(0.7309), np.float32(0.3757)] 
2025-01-02 06:20:56.885951: Epoch time: 40.82 s 
2025-01-02 06:20:56.889959: Yayy! New best EMA pseudo Dice: 0.5450999736785889 
2025-01-02 06:20:57.641672:  
2025-01-02 06:20:57.641672: Epoch 58 
2025-01-02 06:20:57.647696: Current learning rate: 0.00789 
2025-01-02 06:21:38.449065: train_loss -0.4916 
2025-01-02 06:21:38.449575: val_loss -0.5026 
2025-01-02 06:21:38.454654: Pseudo dice [np.float32(0.7155), np.float32(0.3575)] 
2025-01-02 06:21:38.459187: Epoch time: 40.81 s 
2025-01-02 06:21:39.032068:  
2025-01-02 06:21:39.033067: Epoch 59 
2025-01-02 06:21:39.038157: Current learning rate: 0.00785 
2025-01-02 06:22:19.858753: train_loss -0.5129 
2025-01-02 06:22:19.858753: val_loss -0.4924 
2025-01-02 06:22:19.864773: Pseudo dice [np.float32(0.7184), np.float32(0.3827)] 
2025-01-02 06:22:19.867785: Epoch time: 40.83 s 
2025-01-02 06:22:20.625869:  
2025-01-02 06:22:20.625869: Epoch 60 
2025-01-02 06:22:20.630883: Current learning rate: 0.00781 
2025-01-02 06:23:01.411317: train_loss -0.5022 
2025-01-02 06:23:01.411821: val_loss -0.4737 
2025-01-02 06:23:01.417840: Pseudo dice [np.float32(0.7256), np.float32(0.3402)] 
2025-01-02 06:23:01.420346: Epoch time: 40.79 s 
2025-01-02 06:23:01.984997:  
2025-01-02 06:23:01.984997: Epoch 61 
2025-01-02 06:23:01.990541: Current learning rate: 0.00777 
2025-01-02 06:23:42.859196: train_loss -0.5153 
2025-01-02 06:23:42.859700: val_loss -0.494 
2025-01-02 06:23:42.865725: Pseudo dice [np.float32(0.7213), np.float32(0.3912)] 
2025-01-02 06:23:42.868236: Epoch time: 40.88 s 
2025-01-02 06:23:43.439228:  
2025-01-02 06:23:43.439733: Epoch 62 
2025-01-02 06:23:43.445762: Current learning rate: 0.00774 
2025-01-02 06:24:24.248230: train_loss -0.5139 
2025-01-02 06:24:24.248230: val_loss -0.5253 
2025-01-02 06:24:24.254252: Pseudo dice [np.float32(0.7205), np.float32(0.4416)] 
2025-01-02 06:24:24.257761: Epoch time: 40.81 s 
2025-01-02 06:24:24.260771: Yayy! New best EMA pseudo Dice: 0.5485000014305115 
2025-01-02 06:24:25.014234:  
2025-01-02 06:24:25.014736: Epoch 63 
2025-01-02 06:24:25.019757: Current learning rate: 0.0077 
2025-01-02 06:25:05.823848: train_loss -0.5081 
2025-01-02 06:25:05.824851: val_loss -0.5134 
2025-01-02 06:25:05.830389: Pseudo dice [np.float32(0.7034), np.float32(0.4507)] 
2025-01-02 06:25:05.833420: Epoch time: 40.81 s 
2025-01-02 06:25:05.836447: Yayy! New best EMA pseudo Dice: 0.5514000058174133 
2025-01-02 06:25:06.574348:  
2025-01-02 06:25:06.575352: Epoch 64 
2025-01-02 06:25:06.579922: Current learning rate: 0.00766 
2025-01-02 06:25:47.401227: train_loss -0.5355 
2025-01-02 06:25:47.402230: val_loss -0.4809 
2025-01-02 06:25:47.407240: Pseudo dice [np.float32(0.7087), np.float32(0.3627)] 
2025-01-02 06:25:47.410745: Epoch time: 40.83 s 
2025-01-02 06:25:47.985912:  
2025-01-02 06:25:47.986912: Epoch 65 
2025-01-02 06:25:47.991481: Current learning rate: 0.00763 
2025-01-02 06:26:28.794098: train_loss -0.5559 
2025-01-02 06:26:28.794098: val_loss -0.5339 
2025-01-02 06:26:28.800304: Pseudo dice [np.float32(0.7221), np.float32(0.451)] 
2025-01-02 06:26:28.803352: Epoch time: 40.81 s 
2025-01-02 06:26:28.806380: Yayy! New best EMA pseudo Dice: 0.5534999966621399 
2025-01-02 06:26:29.569530:  
2025-01-02 06:26:29.569530: Epoch 66 
2025-01-02 06:26:29.574666: Current learning rate: 0.00759 
2025-01-02 06:27:10.390063: train_loss -0.5448 
2025-01-02 06:27:10.390565: val_loss -0.5363 
2025-01-02 06:27:10.395579: Pseudo dice [np.float32(0.7451), np.float32(0.4019)] 
2025-01-02 06:27:10.398084: Epoch time: 40.82 s 
2025-01-02 06:27:10.401593: Yayy! New best EMA pseudo Dice: 0.5554999709129333 
2025-01-02 06:27:11.150341:  
2025-01-02 06:27:11.150341: Epoch 67 
2025-01-02 06:27:11.155354: Current learning rate: 0.00755 
2025-01-02 06:27:51.953057: train_loss -0.5158 
2025-01-02 06:27:51.954060: val_loss -0.5071 
2025-01-02 06:27:51.960098: Pseudo dice [np.float32(0.7223), np.float32(0.4678)] 
2025-01-02 06:27:51.963123: Epoch time: 40.8 s 
2025-01-02 06:27:51.965192: Yayy! New best EMA pseudo Dice: 0.5594000220298767 
2025-01-02 06:27:52.954767:  
2025-01-02 06:27:52.954767: Epoch 68 
2025-01-02 06:27:52.959853: Current learning rate: 0.00751 
2025-01-02 06:28:33.776451: train_loss -0.5275 
2025-01-02 06:28:33.777455: val_loss -0.4896 
2025-01-02 06:28:33.782468: Pseudo dice [np.float32(0.7338), np.float32(0.3632)] 
2025-01-02 06:28:33.786007: Epoch time: 40.82 s 
2025-01-02 06:28:34.382531:  
2025-01-02 06:28:34.383534: Epoch 69 
2025-01-02 06:28:34.388127: Current learning rate: 0.00748 
2025-01-02 06:29:15.208693: train_loss -0.532 
2025-01-02 06:29:15.208693: val_loss -0.5172 
2025-01-02 06:29:15.214736: Pseudo dice [np.float32(0.7061), np.float32(0.4373)] 
2025-01-02 06:29:15.217755: Epoch time: 40.83 s 
2025-01-02 06:29:15.220810: Yayy! New best EMA pseudo Dice: 0.5597000122070312 
2025-01-02 06:29:15.976437:  
2025-01-02 06:29:15.977440: Epoch 70 
2025-01-02 06:29:15.981998: Current learning rate: 0.00744 
2025-01-02 06:29:56.793577: train_loss -0.5518 
2025-01-02 06:29:56.793577: val_loss -0.5639 
2025-01-02 06:29:56.800101: Pseudo dice [np.float32(0.7374), np.float32(0.5058)] 
2025-01-02 06:29:56.802609: Epoch time: 40.82 s 
2025-01-02 06:29:56.806123: Yayy! New best EMA pseudo Dice: 0.5659000277519226 
2025-01-02 06:29:57.545135:  
2025-01-02 06:29:57.546140: Epoch 71 
2025-01-02 06:29:57.550674: Current learning rate: 0.0074 
2025-01-02 06:30:38.378652: train_loss -0.5206 
2025-01-02 06:30:38.379658: val_loss -0.516 
2025-01-02 06:30:38.385179: Pseudo dice [np.float32(0.7371), np.float32(0.3934)] 
2025-01-02 06:30:38.387687: Epoch time: 40.83 s 
2025-01-02 06:30:38.968687:  
2025-01-02 06:30:38.968687: Epoch 72 
2025-01-02 06:30:38.974237: Current learning rate: 0.00737 
2025-01-02 06:31:19.780893: train_loss -0.5846 
2025-01-02 06:31:19.781399: val_loss -0.5255 
2025-01-02 06:31:19.787493: Pseudo dice [np.float32(0.7452), np.float32(0.4151)] 
2025-01-02 06:31:19.790529: Epoch time: 40.81 s 
2025-01-02 06:31:19.794051: Yayy! New best EMA pseudo Dice: 0.567300021648407 
2025-01-02 06:31:20.549217:  
2025-01-02 06:31:20.549724: Epoch 73 
2025-01-02 06:31:20.554763: Current learning rate: 0.00733 
2025-01-02 06:32:01.384546: train_loss -0.5381 
2025-01-02 06:32:01.385049: val_loss -0.5332 
2025-01-02 06:32:01.390060: Pseudo dice [np.float32(0.7537), np.float32(0.4178)] 
2025-01-02 06:32:01.393571: Epoch time: 40.84 s 
2025-01-02 06:32:01.396076: Yayy! New best EMA pseudo Dice: 0.569100022315979 
2025-01-02 06:32:02.143369:  
2025-01-02 06:32:02.143369: Epoch 74 
2025-01-02 06:32:02.148931: Current learning rate: 0.00729 
2025-01-02 06:32:43.034872: train_loss -0.5386 
2025-01-02 06:32:43.035875: val_loss -0.4571 
2025-01-02 06:32:43.040885: Pseudo dice [np.float32(0.7096), np.float32(0.3684)] 
2025-01-02 06:32:43.043391: Epoch time: 40.89 s 
2025-01-02 06:32:43.630225:  
2025-01-02 06:32:43.631225: Epoch 75 
2025-01-02 06:32:43.635741: Current learning rate: 0.00725 
2025-01-02 06:33:24.468502: train_loss -0.5366 
2025-01-02 06:33:24.469012: val_loss -0.501 
2025-01-02 06:33:24.475668: Pseudo dice [np.float32(0.7303), np.float32(0.3569)] 
2025-01-02 06:33:24.479251: Epoch time: 40.84 s 
2025-01-02 06:33:25.271235:  
2025-01-02 06:33:25.271738: Epoch 76 
2025-01-02 06:33:25.276751: Current learning rate: 0.00722 
2025-01-02 06:34:06.081101: train_loss -0.5287 
2025-01-02 06:34:06.081101: val_loss -0.4952 
2025-01-02 06:34:06.087119: Pseudo dice [np.float32(0.7042), np.float32(0.4138)] 
2025-01-02 06:34:06.090129: Epoch time: 40.81 s 
2025-01-02 06:34:06.664901:  
2025-01-02 06:34:06.664901: Epoch 77 
2025-01-02 06:34:06.670788: Current learning rate: 0.00718 
2025-01-02 06:34:47.480040: train_loss -0.5608 
2025-01-02 06:34:47.480555: val_loss -0.5389 
2025-01-02 06:34:47.486703: Pseudo dice [np.float32(0.7419), np.float32(0.3852)] 
2025-01-02 06:34:47.489745: Epoch time: 40.82 s 
2025-01-02 06:34:48.305324:  
2025-01-02 06:34:48.305324: Epoch 78 
2025-01-02 06:34:48.310338: Current learning rate: 0.00714 
2025-01-02 06:35:29.146976: train_loss -0.5528 
2025-01-02 06:35:29.147983: val_loss -0.5421 
2025-01-02 06:35:29.153070: Pseudo dice [np.float32(0.7351), np.float32(0.5087)] 
2025-01-02 06:35:29.157088: Epoch time: 40.84 s 
2025-01-02 06:35:29.159600: Yayy! New best EMA pseudo Dice: 0.5691999793052673 
2025-01-02 06:35:29.920275:  
2025-01-02 06:35:29.921276: Epoch 79 
2025-01-02 06:35:29.926333: Current learning rate: 0.0071 
2025-01-02 06:36:10.728571: train_loss -0.5322 
2025-01-02 06:36:10.729075: val_loss -0.5358 
2025-01-02 06:36:10.734087: Pseudo dice [np.float32(0.71), np.float32(0.4204)] 
2025-01-02 06:36:10.737598: Epoch time: 40.81 s 
2025-01-02 06:36:11.332012:  
2025-01-02 06:36:11.332515: Epoch 80 
2025-01-02 06:36:11.337526: Current learning rate: 0.00707 
2025-01-02 06:36:52.148571: train_loss -0.5637 
2025-01-02 06:36:52.148571: val_loss -0.4896 
2025-01-02 06:36:52.156099: Pseudo dice [np.float32(0.7325), np.float32(0.3904)] 
2025-01-02 06:36:52.158605: Epoch time: 40.82 s 
2025-01-02 06:36:52.764142:  
2025-01-02 06:36:52.764142: Epoch 81 
2025-01-02 06:36:52.769710: Current learning rate: 0.00703 
2025-01-02 06:37:33.594561: train_loss -0.5495 
2025-01-02 06:37:33.594561: val_loss -0.5048 
2025-01-02 06:37:33.600664: Pseudo dice [np.float32(0.7532), np.float32(0.3735)] 
2025-01-02 06:37:33.602749: Epoch time: 40.83 s 
2025-01-02 06:37:34.196218:  
2025-01-02 06:37:34.196218: Epoch 82 
2025-01-02 06:37:34.201280: Current learning rate: 0.00699 
2025-01-02 06:38:15.021364: train_loss -0.5112 
2025-01-02 06:38:15.021873: val_loss -0.5075 
2025-01-02 06:38:15.027908: Pseudo dice [np.float32(0.7425), np.float32(0.415)] 
2025-01-02 06:38:15.030469: Epoch time: 40.83 s 
2025-01-02 06:38:15.593346:  
2025-01-02 06:38:15.594349: Epoch 83 
2025-01-02 06:38:15.598871: Current learning rate: 0.00696 
2025-01-02 06:38:56.424175: train_loss -0.5448 
2025-01-02 06:38:56.424175: val_loss -0.5569 
2025-01-02 06:38:56.430189: Pseudo dice [np.float32(0.7505), np.float32(0.5187)] 
2025-01-02 06:38:56.432694: Epoch time: 40.83 s 
2025-01-02 06:38:56.436702: Yayy! New best EMA pseudo Dice: 0.5752999782562256 
2025-01-02 06:38:57.392051:  
2025-01-02 06:38:57.392051: Epoch 84 
2025-01-02 06:38:57.398064: Current learning rate: 0.00692 
2025-01-02 06:39:38.199463: train_loss -0.5567 
2025-01-02 06:39:38.199966: val_loss -0.5328 
2025-01-02 06:39:38.204977: Pseudo dice [np.float32(0.7322), np.float32(0.5102)] 
2025-01-02 06:39:38.208486: Epoch time: 40.81 s 
2025-01-02 06:39:38.212494: Yayy! New best EMA pseudo Dice: 0.5799000263214111 
2025-01-02 06:39:38.954221:  
2025-01-02 06:39:38.954733: Epoch 85 
2025-01-02 06:39:38.959784: Current learning rate: 0.00688 
2025-01-02 06:40:19.759322: train_loss -0.5382 
2025-01-02 06:40:19.760322: val_loss -0.4881 
2025-01-02 06:40:19.765845: Pseudo dice [np.float32(0.7276), np.float32(0.3573)] 
2025-01-02 06:40:19.769357: Epoch time: 40.81 s 
2025-01-02 06:40:20.344134:  
2025-01-02 06:40:20.345135: Epoch 86 
2025-01-02 06:40:20.350203: Current learning rate: 0.00684 
2025-01-02 06:41:01.170530: train_loss -0.5271 
2025-01-02 06:41:01.170530: val_loss -0.5138 
2025-01-02 06:41:01.176608: Pseudo dice [np.float32(0.7322), np.float32(0.4012)] 
2025-01-02 06:41:01.179667: Epoch time: 40.83 s 
2025-01-02 06:41:01.735258:  
2025-01-02 06:41:01.736258: Epoch 87 
2025-01-02 06:41:01.741335: Current learning rate: 0.0068 
2025-01-02 06:41:42.556808: train_loss -0.5653 
2025-01-02 06:41:42.557311: val_loss -0.4938 
2025-01-02 06:41:42.562323: Pseudo dice [np.float32(0.737), np.float32(0.3994)] 
2025-01-02 06:41:42.565881: Epoch time: 40.82 s 
2025-01-02 06:41:43.119268:  
2025-01-02 06:41:43.119268: Epoch 88 
2025-01-02 06:41:43.125306: Current learning rate: 0.00677 
2025-01-02 06:42:23.957390: train_loss -0.5632 
2025-01-02 06:42:23.957955: val_loss -0.494 
2025-01-02 06:42:23.962491: Pseudo dice [np.float32(0.7113), np.float32(0.361)] 
2025-01-02 06:42:23.965522: Epoch time: 40.84 s 
2025-01-02 06:42:24.522316:  
2025-01-02 06:42:24.522316: Epoch 89 
2025-01-02 06:42:24.527367: Current learning rate: 0.00673 
2025-01-02 06:43:05.347621: train_loss -0.5523 
2025-01-02 06:43:05.348123: val_loss -0.5212 
2025-01-02 06:43:05.354139: Pseudo dice [np.float32(0.7441), np.float32(0.3369)] 
2025-01-02 06:43:05.357645: Epoch time: 40.83 s 
2025-01-02 06:43:05.938427:  
2025-01-02 06:43:05.938427: Epoch 90 
2025-01-02 06:43:05.944022: Current learning rate: 0.00669 
2025-01-02 06:43:46.894464: train_loss -0.5923 
2025-01-02 06:43:46.894464: val_loss -0.5212 
2025-01-02 06:43:46.900478: Pseudo dice [np.float32(0.7404), np.float32(0.3276)] 
2025-01-02 06:43:46.903983: Epoch time: 40.96 s 
2025-01-02 06:43:47.462204:  
2025-01-02 06:43:47.462204: Epoch 91 
2025-01-02 06:43:47.467744: Current learning rate: 0.00665 
2025-01-02 06:44:28.296009: train_loss -0.5617 
2025-01-02 06:44:28.297011: val_loss -0.5179 
2025-01-02 06:44:28.302055: Pseudo dice [np.float32(0.716), np.float32(0.4832)] 
2025-01-02 06:44:28.305585: Epoch time: 40.83 s 
2025-01-02 06:44:29.027017:  
2025-01-02 06:44:29.027017: Epoch 92 
2025-01-02 06:44:29.032606: Current learning rate: 0.00662 
2025-01-02 06:45:09.860372: train_loss -0.5173 
2025-01-02 06:45:09.861372: val_loss -0.5037 
2025-01-02 06:45:09.866896: Pseudo dice [np.float32(0.7366), np.float32(0.4035)] 
2025-01-02 06:45:09.870407: Epoch time: 40.83 s 
2025-01-02 06:45:10.439823:  
2025-01-02 06:45:10.439823: Epoch 93 
2025-01-02 06:45:10.445403: Current learning rate: 0.00658 
2025-01-02 06:45:51.280210: train_loss -0.5373 
2025-01-02 06:45:51.281213: val_loss -0.5184 
2025-01-02 06:45:51.287248: Pseudo dice [np.float32(0.7449), np.float32(0.428)] 
2025-01-02 06:45:51.290281: Epoch time: 40.84 s 
2025-01-02 06:45:51.851830:  
2025-01-02 06:45:51.851830: Epoch 94 
2025-01-02 06:45:51.856842: Current learning rate: 0.00654 
2025-01-02 06:46:32.675022: train_loss -0.5667 
2025-01-02 06:46:32.675022: val_loss -0.5362 
2025-01-02 06:46:32.682037: Pseudo dice [np.float32(0.728), np.float32(0.4767)] 
2025-01-02 06:46:32.685053: Epoch time: 40.82 s 
2025-01-02 06:46:33.247827:  
2025-01-02 06:46:33.247827: Epoch 95 
2025-01-02 06:46:33.253407: Current learning rate: 0.0065 
2025-01-02 06:47:14.061596: train_loss -0.5486 
2025-01-02 06:47:14.062600: val_loss -0.5645 
2025-01-02 06:47:14.067703: Pseudo dice [np.float32(0.7491), np.float32(0.5009)] 
2025-01-02 06:47:14.071223: Epoch time: 40.81 s 
2025-01-02 06:47:14.628900:  
2025-01-02 06:47:14.629402: Epoch 96 
2025-01-02 06:47:14.634413: Current learning rate: 0.00647 
2025-01-02 06:47:55.458561: train_loss -0.5823 
2025-01-02 06:47:55.459561: val_loss -0.5587 
2025-01-02 06:47:55.465075: Pseudo dice [np.float32(0.7663), np.float32(0.5598)] 
2025-01-02 06:47:55.468582: Epoch time: 40.83 s 
2025-01-02 06:47:55.471094: Yayy! New best EMA pseudo Dice: 0.5867999792098999 
2025-01-02 06:47:56.191916:  
2025-01-02 06:47:56.191916: Epoch 97 
2025-01-02 06:47:56.197435: Current learning rate: 0.00643 
2025-01-02 06:48:37.020106: train_loss -0.5936 
2025-01-02 06:48:37.020106: val_loss -0.5554 
2025-01-02 06:48:37.027156: Pseudo dice [np.float32(0.7528), np.float32(0.4864)] 
2025-01-02 06:48:37.030668: Epoch time: 40.83 s 
2025-01-02 06:48:37.033649: Yayy! New best EMA pseudo Dice: 0.5900999903678894 
2025-01-02 06:48:37.777025:  
2025-01-02 06:48:37.777025: Epoch 98 
2025-01-02 06:48:37.782040: Current learning rate: 0.00639 
2025-01-02 06:49:18.602480: train_loss -0.5674 
2025-01-02 06:49:18.602992: val_loss -0.5526 
2025-01-02 06:49:18.608619: Pseudo dice [np.float32(0.7556), np.float32(0.4842)] 
2025-01-02 06:49:18.612143: Epoch time: 40.83 s 
2025-01-02 06:49:18.615233: Yayy! New best EMA pseudo Dice: 0.5931000113487244 
2025-01-02 06:49:19.353865:  
2025-01-02 06:49:19.353865: Epoch 99 
2025-01-02 06:49:19.358877: Current learning rate: 0.00635 
2025-01-02 06:50:00.208360: train_loss -0.5949 
2025-01-02 06:50:00.208863: val_loss -0.5278 
2025-01-02 06:50:00.213966: Pseudo dice [np.float32(0.7246), np.float32(0.3791)] 
2025-01-02 06:50:00.217483: Epoch time: 40.86 s 
2025-01-02 06:50:00.967068:  
2025-01-02 06:50:00.968071: Epoch 100 
2025-01-02 06:50:00.973176: Current learning rate: 0.00631 
2025-01-02 06:50:41.790296: train_loss -0.56 
2025-01-02 06:50:41.791302: val_loss -0.504 
2025-01-02 06:50:41.795842: Pseudo dice [np.float32(0.7463), np.float32(0.3588)] 
2025-01-02 06:50:41.799866: Epoch time: 40.82 s 
2025-01-02 06:50:42.540572:  
2025-01-02 06:50:42.541577: Epoch 101 
2025-01-02 06:50:42.546605: Current learning rate: 0.00628 
2025-01-02 06:51:23.370476: train_loss -0.5467 
2025-01-02 06:51:23.371479: val_loss -0.509 
2025-01-02 06:51:23.377000: Pseudo dice [np.float32(0.7299), np.float32(0.4064)] 
2025-01-02 06:51:23.380510: Epoch time: 40.83 s 
2025-01-02 06:51:24.211498:  
2025-01-02 06:51:24.212001: Epoch 102 
2025-01-02 06:51:24.217551: Current learning rate: 0.00624 
2025-01-02 06:52:05.034764: train_loss -0.6143 
2025-01-02 06:52:05.036269: val_loss -0.5359 
2025-01-02 06:52:05.041816: Pseudo dice [np.float32(0.7423), np.float32(0.4369)] 
2025-01-02 06:52:05.044322: Epoch time: 40.82 s 
2025-01-02 06:52:05.607648:  
2025-01-02 06:52:05.607648: Epoch 103 
2025-01-02 06:52:05.612734: Current learning rate: 0.0062 
2025-01-02 06:52:46.414037: train_loss -0.5939 
2025-01-02 06:52:46.414037: val_loss -0.5298 
2025-01-02 06:52:46.418559: Pseudo dice [np.float32(0.743), np.float32(0.4776)] 
2025-01-02 06:52:46.421596: Epoch time: 40.81 s 
2025-01-02 06:52:46.994178:  
2025-01-02 06:52:46.994178: Epoch 104 
2025-01-02 06:52:46.999189: Current learning rate: 0.00616 
2025-01-02 06:53:27.807384: train_loss -0.6033 
2025-01-02 06:53:27.807887: val_loss -0.5551 
2025-01-02 06:53:27.814917: Pseudo dice [np.float32(0.7618), np.float32(0.4567)] 
2025-01-02 06:53:27.817931: Epoch time: 40.81 s 
2025-01-02 06:53:28.397136:  
2025-01-02 06:53:28.397136: Epoch 105 
2025-01-02 06:53:28.403155: Current learning rate: 0.00612 
2025-01-02 06:54:09.200259: train_loss -0.5864 
2025-01-02 06:54:09.201264: val_loss -0.5884 
2025-01-02 06:54:09.207314: Pseudo dice [np.float32(0.7686), np.float32(0.5554)] 
2025-01-02 06:54:09.210821: Epoch time: 40.8 s 
2025-01-02 06:54:09.213860: Yayy! New best EMA pseudo Dice: 0.5963000059127808 
2025-01-02 06:54:09.961462:  
2025-01-02 06:54:09.961462: Epoch 106 
2025-01-02 06:54:09.967003: Current learning rate: 0.00609 
2025-01-02 06:54:50.878447: train_loss -0.5928 
2025-01-02 06:54:50.878447: val_loss -0.5688 
2025-01-02 06:54:50.884971: Pseudo dice [np.float32(0.7682), np.float32(0.5005)] 
2025-01-02 06:54:50.888485: Epoch time: 40.92 s 
2025-01-02 06:54:50.890990: Yayy! New best EMA pseudo Dice: 0.6000999808311462 
2025-01-02 06:54:51.661043:  
2025-01-02 06:54:51.661043: Epoch 107 
2025-01-02 06:54:51.666562: Current learning rate: 0.00605 
2025-01-02 06:55:32.494457: train_loss -0.6109 
2025-01-02 06:55:32.494457: val_loss -0.5308 
2025-01-02 06:55:32.500972: Pseudo dice [np.float32(0.7595), np.float32(0.3741)] 
2025-01-02 06:55:32.504480: Epoch time: 40.83 s 
2025-01-02 06:55:33.077734:  
2025-01-02 06:55:33.077734: Epoch 108 
2025-01-02 06:55:33.083271: Current learning rate: 0.00601 
2025-01-02 06:56:13.918882: train_loss -0.57 
2025-01-02 06:56:13.919886: val_loss -0.5612 
2025-01-02 06:56:13.923902: Pseudo dice [np.float32(0.7241), np.float32(0.4728)] 
2025-01-02 06:56:13.927417: Epoch time: 40.84 s 
2025-01-02 06:56:14.727745:  
2025-01-02 06:56:14.728746: Epoch 109 
2025-01-02 06:56:14.733825: Current learning rate: 0.00597 
2025-01-02 06:56:55.547787: train_loss -0.5716 
2025-01-02 06:56:55.548791: val_loss -0.5185 
2025-01-02 06:56:55.554434: Pseudo dice [np.float32(0.6944), np.float32(0.4476)] 
2025-01-02 06:56:55.557499: Epoch time: 40.82 s 
2025-01-02 06:56:56.156733:  
2025-01-02 06:56:56.156733: Epoch 110 
2025-01-02 06:56:56.162265: Current learning rate: 0.00593 
2025-01-02 06:57:36.979964: train_loss -0.5884 
2025-01-02 06:57:36.980969: val_loss -0.5328 
2025-01-02 06:57:36.987071: Pseudo dice [np.float32(0.7743), np.float32(0.4264)] 
2025-01-02 06:57:36.990589: Epoch time: 40.82 s 
2025-01-02 06:57:37.563709:  
2025-01-02 06:57:37.563709: Epoch 111 
2025-01-02 06:57:37.568722: Current learning rate: 0.0059 
2025-01-02 06:58:18.379634: train_loss -0.5562 
2025-01-02 06:58:18.380151: val_loss -0.5088 
2025-01-02 06:58:18.386226: Pseudo dice [np.float32(0.7325), np.float32(0.362)] 
2025-01-02 06:58:18.389754: Epoch time: 40.82 s 
2025-01-02 06:58:18.957580:  
2025-01-02 06:58:18.957580: Epoch 112 
2025-01-02 06:58:18.962595: Current learning rate: 0.00586 
2025-01-02 06:58:59.744323: train_loss -0.5719 
2025-01-02 06:58:59.745323: val_loss -0.5223 
2025-01-02 06:58:59.750836: Pseudo dice [np.float32(0.7343), np.float32(0.4467)] 
2025-01-02 06:58:59.754344: Epoch time: 40.79 s 
2025-01-02 06:59:00.321282:  
2025-01-02 06:59:00.322286: Epoch 113 
2025-01-02 06:59:00.327388: Current learning rate: 0.00582 
2025-01-02 06:59:41.141235: train_loss -0.6195 
2025-01-02 06:59:41.141235: val_loss -0.5942 
2025-01-02 06:59:41.148263: Pseudo dice [np.float32(0.7421), np.float32(0.5367)] 
2025-01-02 06:59:41.151274: Epoch time: 40.82 s 
2025-01-02 06:59:41.739564:  
2025-01-02 06:59:41.739564: Epoch 114 
2025-01-02 06:59:41.746083: Current learning rate: 0.00578 
2025-01-02 07:00:22.560301: train_loss -0.6074 
2025-01-02 07:00:22.560804: val_loss -0.5251 
2025-01-02 07:00:22.566825: Pseudo dice [np.float32(0.7498), np.float32(0.3912)] 
2025-01-02 07:00:22.570334: Epoch time: 40.82 s 
2025-01-02 07:00:23.136885:  
2025-01-02 07:00:23.137888: Epoch 115 
2025-01-02 07:00:23.142459: Current learning rate: 0.00574 
2025-01-02 07:01:03.972196: train_loss -0.6041 
2025-01-02 07:01:03.972196: val_loss -0.5592 
2025-01-02 07:01:03.978712: Pseudo dice [np.float32(0.7415), np.float32(0.4903)] 
2025-01-02 07:01:03.982224: Epoch time: 40.84 s 
2025-01-02 07:01:04.565966:  
2025-01-02 07:01:04.566468: Epoch 116 
2025-01-02 07:01:04.571480: Current learning rate: 0.0057 
2025-01-02 07:01:45.362072: train_loss -0.5767 
2025-01-02 07:01:45.362577: val_loss -0.5273 
2025-01-02 07:01:45.368595: Pseudo dice [np.float32(0.7321), np.float32(0.4672)] 
2025-01-02 07:01:45.372104: Epoch time: 40.8 s 
2025-01-02 07:01:46.256513:  
2025-01-02 07:01:46.257516: Epoch 117 
2025-01-02 07:01:46.262544: Current learning rate: 0.00567 
2025-01-02 07:02:27.081470: train_loss -0.5999 
2025-01-02 07:02:27.081470: val_loss -0.5548 
2025-01-02 07:02:27.088998: Pseudo dice [np.float32(0.7677), np.float32(0.4364)] 
2025-01-02 07:02:27.092510: Epoch time: 40.82 s 
2025-01-02 07:02:27.669542:  
2025-01-02 07:02:27.669542: Epoch 118 
2025-01-02 07:02:27.675556: Current learning rate: 0.00563 
2025-01-02 07:03:08.481935: train_loss -0.6106 
2025-01-02 07:03:08.482934: val_loss -0.5188 
2025-01-02 07:03:08.488447: Pseudo dice [np.float32(0.7684), np.float32(0.4184)] 
2025-01-02 07:03:08.491956: Epoch time: 40.81 s 
2025-01-02 07:03:09.072640:  
2025-01-02 07:03:09.072640: Epoch 119 
2025-01-02 07:03:09.077149: Current learning rate: 0.00559 
2025-01-02 07:03:49.903065: train_loss -0.6187 
2025-01-02 07:03:49.904069: val_loss -0.5694 
2025-01-02 07:03:49.909079: Pseudo dice [np.float32(0.7594), np.float32(0.5604)] 
2025-01-02 07:03:49.913088: Epoch time: 40.83 s 
2025-01-02 07:03:49.915592: Yayy! New best EMA pseudo Dice: 0.6022999882698059 
2025-01-02 07:03:50.642140:  
2025-01-02 07:03:50.642644: Epoch 120 
2025-01-02 07:03:50.647654: Current learning rate: 0.00555 
2025-01-02 07:04:31.473636: train_loss -0.604 
2025-01-02 07:04:31.473636: val_loss -0.5452 
2025-01-02 07:04:31.481156: Pseudo dice [np.float32(0.7577), np.float32(0.4486)] 
2025-01-02 07:04:31.483663: Epoch time: 40.83 s 
2025-01-02 07:04:31.487171: Yayy! New best EMA pseudo Dice: 0.6022999882698059 
2025-01-02 07:04:32.242419:  
2025-01-02 07:04:32.243423: Epoch 121 
2025-01-02 07:04:32.247960: Current learning rate: 0.00551 
2025-01-02 07:05:13.094774: train_loss -0.5907 
2025-01-02 07:05:13.095777: val_loss -0.5467 
2025-01-02 07:05:13.101066: Pseudo dice [np.float32(0.7479), np.float32(0.4731)] 
2025-01-02 07:05:13.104589: Epoch time: 40.85 s 
2025-01-02 07:05:13.107875: Yayy! New best EMA pseudo Dice: 0.6032000184059143 
2025-01-02 07:05:13.856201:  
2025-01-02 07:05:13.856201: Epoch 122 
2025-01-02 07:05:13.861735: Current learning rate: 0.00547 
2025-01-02 07:05:54.673574: train_loss -0.5938 
2025-01-02 07:05:54.674577: val_loss -0.5265 
2025-01-02 07:05:54.680587: Pseudo dice [np.float32(0.6914), np.float32(0.5544)] 
2025-01-02 07:05:54.683595: Epoch time: 40.82 s 
2025-01-02 07:05:54.686100: Yayy! New best EMA pseudo Dice: 0.6050999760627747 
2025-01-02 07:05:55.419451:  
2025-01-02 07:05:55.419954: Epoch 123 
2025-01-02 07:05:55.424965: Current learning rate: 0.00544 
2025-01-02 07:06:36.200400: train_loss -0.5936 
2025-01-02 07:06:36.201400: val_loss -0.6016 
2025-01-02 07:06:36.206923: Pseudo dice [np.float32(0.7718), np.float32(0.6208)] 
2025-01-02 07:06:36.210443: Epoch time: 40.78 s 
2025-01-02 07:06:36.212953: Yayy! New best EMA pseudo Dice: 0.614300012588501 
2025-01-02 07:06:36.956323:  
2025-01-02 07:06:36.956323: Epoch 124 
2025-01-02 07:06:36.961406: Current learning rate: 0.0054 
2025-01-02 07:07:17.764977: train_loss -0.6199 
2025-01-02 07:07:17.765482: val_loss -0.5597 
2025-01-02 07:07:17.771024: Pseudo dice [np.float32(0.7735), np.float32(0.4895)] 
2025-01-02 07:07:17.774543: Epoch time: 40.81 s 
2025-01-02 07:07:17.777565: Yayy! New best EMA pseudo Dice: 0.6159999966621399 
2025-01-02 07:07:18.706015:  
2025-01-02 07:07:18.706015: Epoch 125 
2025-01-02 07:07:18.711025: Current learning rate: 0.00536 
2025-01-02 07:07:59.523101: train_loss -0.58 
2025-01-02 07:07:59.523101: val_loss -0.5079 
2025-01-02 07:07:59.529114: Pseudo dice [np.float32(0.705), np.float32(0.4399)] 
2025-01-02 07:07:59.532620: Epoch time: 40.82 s 
2025-01-02 07:08:00.126598:  
2025-01-02 07:08:00.126598: Epoch 126 
2025-01-02 07:08:00.131181: Current learning rate: 0.00532 
2025-01-02 07:08:40.940648: train_loss -0.6096 
2025-01-02 07:08:40.942168: val_loss -0.5249 
2025-01-02 07:08:40.947750: Pseudo dice [np.float32(0.7455), np.float32(0.3857)] 
2025-01-02 07:08:40.950795: Epoch time: 40.82 s 
2025-01-02 07:08:41.534376:  
2025-01-02 07:08:41.534376: Epoch 127 
2025-01-02 07:08:41.539418: Current learning rate: 0.00528 
2025-01-02 07:09:22.356390: train_loss -0.623 
2025-01-02 07:09:22.356893: val_loss -0.5698 
2025-01-02 07:09:22.363061: Pseudo dice [np.float32(0.7692), np.float32(0.4505)] 
2025-01-02 07:09:22.366638: Epoch time: 40.82 s 
2025-01-02 07:09:22.939745:  
2025-01-02 07:09:22.940251: Epoch 128 
2025-01-02 07:09:22.944803: Current learning rate: 0.00524 
2025-01-02 07:10:03.766032: train_loss -0.624 
2025-01-02 07:10:03.767033: val_loss -0.5112 
2025-01-02 07:10:03.772554: Pseudo dice [np.float32(0.7272), np.float32(0.4467)] 
2025-01-02 07:10:03.776066: Epoch time: 40.83 s 
2025-01-02 07:10:04.357111:  
2025-01-02 07:10:04.357619: Epoch 129 
2025-01-02 07:10:04.362696: Current learning rate: 0.0052 
2025-01-02 07:10:45.184986: train_loss -0.6136 
2025-01-02 07:10:45.185489: val_loss -0.5662 
2025-01-02 07:10:45.191506: Pseudo dice [np.float32(0.7747), np.float32(0.4753)] 
2025-01-02 07:10:45.194012: Epoch time: 40.83 s 
2025-01-02 07:10:45.787978:  
2025-01-02 07:10:45.788981: Epoch 130 
2025-01-02 07:10:45.793541: Current learning rate: 0.00517 
2025-01-02 07:11:26.621986: train_loss -0.6244 
2025-01-02 07:11:26.622501: val_loss -0.5596 
2025-01-02 07:11:26.628072: Pseudo dice [np.float32(0.7544), np.float32(0.5533)] 
2025-01-02 07:11:26.632625: Epoch time: 40.83 s 
2025-01-02 07:11:27.226019:  
2025-01-02 07:11:27.226019: Epoch 131 
2025-01-02 07:11:27.233157: Current learning rate: 0.00513 
2025-01-02 07:12:08.051011: train_loss -0.6014 
2025-01-02 07:12:08.051514: val_loss -0.5617 
2025-01-02 07:12:08.057076: Pseudo dice [np.float32(0.7596), np.float32(0.4463)] 
2025-01-02 07:12:08.060114: Epoch time: 40.83 s 
2025-01-02 07:12:08.636024:  
2025-01-02 07:12:08.636024: Epoch 132 
2025-01-02 07:12:08.641035: Current learning rate: 0.00509 
2025-01-02 07:12:49.460541: train_loss -0.6325 
2025-01-02 07:12:49.460541: val_loss -0.5631 
2025-01-02 07:12:49.465838: Pseudo dice [np.float32(0.7877), np.float32(0.4731)] 
2025-01-02 07:12:49.469911: Epoch time: 40.83 s 
2025-01-02 07:12:50.221646:  
2025-01-02 07:12:50.221646: Epoch 133 
2025-01-02 07:12:50.226677: Current learning rate: 0.00505 
2025-01-02 07:13:31.050503: train_loss -0.5983 
2025-01-02 07:13:31.051508: val_loss -0.501 
2025-01-02 07:13:31.058022: Pseudo dice [np.float32(0.7379), np.float32(0.3572)] 
2025-01-02 07:13:31.061533: Epoch time: 40.83 s 
2025-01-02 07:13:31.636627:  
2025-01-02 07:13:31.637631: Epoch 134 
2025-01-02 07:13:31.642181: Current learning rate: 0.00501 
2025-01-02 07:14:12.467062: train_loss -0.6246 
2025-01-02 07:14:12.467566: val_loss -0.5642 
2025-01-02 07:14:12.473164: Pseudo dice [np.float32(0.7829), np.float32(0.3631)] 
2025-01-02 07:14:12.476699: Epoch time: 40.83 s 
2025-01-02 07:14:13.063999:  
2025-01-02 07:14:13.065003: Epoch 135 
2025-01-02 07:14:13.070040: Current learning rate: 0.00497 
2025-01-02 07:14:53.896370: train_loss -0.6417 
2025-01-02 07:14:53.896370: val_loss -0.5765 
2025-01-02 07:14:53.902901: Pseudo dice [np.float32(0.7554), np.float32(0.5191)] 
2025-01-02 07:14:53.905412: Epoch time: 40.83 s 
2025-01-02 07:14:54.553471:  
2025-01-02 07:14:54.553471: Epoch 136 
2025-01-02 07:14:54.558483: Current learning rate: 0.00493 
2025-01-02 07:15:35.390341: train_loss -0.624 
2025-01-02 07:15:35.390858: val_loss -0.5469 
2025-01-02 07:15:35.397435: Pseudo dice [np.float32(0.7812), np.float32(0.4105)] 
2025-01-02 07:15:35.400993: Epoch time: 40.84 s 
2025-01-02 07:15:35.986290:  
2025-01-02 07:15:35.986290: Epoch 137 
2025-01-02 07:15:35.992398: Current learning rate: 0.00489 
2025-01-02 07:16:16.867360: train_loss -0.6131 
2025-01-02 07:16:16.868366: val_loss -0.5546 
2025-01-02 07:16:16.873925: Pseudo dice [np.float32(0.7632), np.float32(0.5006)] 
2025-01-02 07:16:16.876977: Epoch time: 40.88 s 
2025-01-02 07:16:17.472643:  
2025-01-02 07:16:17.472643: Epoch 138 
2025-01-02 07:16:17.477718: Current learning rate: 0.00485 
2025-01-02 07:16:58.340480: train_loss -0.6213 
2025-01-02 07:16:58.340480: val_loss -0.5326 
2025-01-02 07:16:58.346996: Pseudo dice [np.float32(0.7723), np.float32(0.4087)] 
2025-01-02 07:16:58.350510: Epoch time: 40.87 s 
2025-01-02 07:16:58.928567:  
2025-01-02 07:16:58.928567: Epoch 139 
2025-01-02 07:16:58.934138: Current learning rate: 0.00482 
2025-01-02 07:17:39.758482: train_loss -0.6333 
2025-01-02 07:17:39.758990: val_loss -0.5675 
2025-01-02 07:17:39.764572: Pseudo dice [np.float32(0.761), np.float32(0.512)] 
2025-01-02 07:17:39.767595: Epoch time: 40.83 s 
2025-01-02 07:17:40.349783:  
2025-01-02 07:17:40.350286: Epoch 140 
2025-01-02 07:17:40.355297: Current learning rate: 0.00478 
2025-01-02 07:18:21.196414: train_loss -0.6379 
2025-01-02 07:18:21.197413: val_loss -0.6015 
2025-01-02 07:18:21.202928: Pseudo dice [np.float32(0.7833), np.float32(0.5212)] 
2025-01-02 07:18:21.206440: Epoch time: 40.85 s 
2025-01-02 07:18:21.969804:  
2025-01-02 07:18:21.970809: Epoch 141 
2025-01-02 07:18:21.975352: Current learning rate: 0.00474 
2025-01-02 07:19:02.823329: train_loss -0.6355 
2025-01-02 07:19:02.823834: val_loss -0.5896 
2025-01-02 07:19:02.828847: Pseudo dice [np.float32(0.7842), np.float32(0.4721)] 
2025-01-02 07:19:02.832359: Epoch time: 40.85 s 
2025-01-02 07:19:03.424084:  
2025-01-02 07:19:03.424084: Epoch 142 
2025-01-02 07:19:03.429098: Current learning rate: 0.0047 
2025-01-02 07:19:44.229779: train_loss -0.6316 
2025-01-02 07:19:44.229779: val_loss -0.5843 
2025-01-02 07:19:44.235806: Pseudo dice [np.float32(0.7757), np.float32(0.5195)] 
2025-01-02 07:19:44.239329: Epoch time: 40.81 s 
2025-01-02 07:19:44.241941: Yayy! New best EMA pseudo Dice: 0.6183000206947327 
2025-01-02 07:19:44.986935:  
2025-01-02 07:19:44.987938: Epoch 143 
2025-01-02 07:19:44.992824: Current learning rate: 0.00466 
2025-01-02 07:20:25.818180: train_loss -0.6567 
2025-01-02 07:20:25.819183: val_loss -0.5514 
2025-01-02 07:20:25.824236: Pseudo dice [np.float32(0.772), np.float32(0.4644)] 
2025-01-02 07:20:25.827775: Epoch time: 40.83 s 
2025-01-02 07:20:26.408890:  
2025-01-02 07:20:26.408890: Epoch 144 
2025-01-02 07:20:26.414456: Current learning rate: 0.00462 
2025-01-02 07:21:07.232143: train_loss -0.6321 
2025-01-02 07:21:07.232143: val_loss -0.5644 
2025-01-02 07:21:07.237201: Pseudo dice [np.float32(0.766), np.float32(0.4086)] 
2025-01-02 07:21:07.241774: Epoch time: 40.82 s 
2025-01-02 07:21:07.855896:  
2025-01-02 07:21:07.855896: Epoch 145 
2025-01-02 07:21:07.860929: Current learning rate: 0.00458 
2025-01-02 07:21:48.690763: train_loss -0.6316 
2025-01-02 07:21:48.690763: val_loss -0.558 
2025-01-02 07:21:48.697285: Pseudo dice [np.float32(0.7693), np.float32(0.4888)] 
2025-01-02 07:21:48.699792: Epoch time: 40.84 s 
2025-01-02 07:21:49.291211:  
2025-01-02 07:21:49.292211: Epoch 146 
2025-01-02 07:21:49.295271: Current learning rate: 0.00454 
2025-01-02 07:22:30.111631: train_loss -0.6434 
2025-01-02 07:22:30.111631: val_loss -0.5885 
2025-01-02 07:22:30.117647: Pseudo dice [np.float32(0.7722), np.float32(0.5251)] 
2025-01-02 07:22:30.121162: Epoch time: 40.82 s 
2025-01-02 07:22:30.124172: Yayy! New best EMA pseudo Dice: 0.6197999715805054 
2025-01-02 07:22:30.895016:  
2025-01-02 07:22:30.895519: Epoch 147 
2025-01-02 07:22:30.900563: Current learning rate: 0.0045 
2025-01-02 07:23:11.704954: train_loss -0.6362 
2025-01-02 07:23:11.704954: val_loss -0.5515 
2025-01-02 07:23:11.710977: Pseudo dice [np.float32(0.7693), np.float32(0.4759)] 
2025-01-02 07:23:11.714484: Epoch time: 40.81 s 
2025-01-02 07:23:11.717498: Yayy! New best EMA pseudo Dice: 0.6201000213623047 
2025-01-02 07:23:12.474581:  
2025-01-02 07:23:12.475582: Epoch 148 
2025-01-02 07:23:12.480659: Current learning rate: 0.00446 
2025-01-02 07:23:53.297658: train_loss -0.6395 
2025-01-02 07:23:53.297658: val_loss -0.5338 
2025-01-02 07:23:53.303678: Pseudo dice [np.float32(0.7563), np.float32(0.4009)] 
2025-01-02 07:23:53.307188: Epoch time: 40.82 s 
2025-01-02 07:23:54.059485:  
2025-01-02 07:23:54.060485: Epoch 149 
2025-01-02 07:23:54.065586: Current learning rate: 0.00442 
2025-01-02 07:24:34.883674: train_loss -0.6452 
2025-01-02 07:24:34.884678: val_loss -0.5555 
2025-01-02 07:24:34.889697: Pseudo dice [np.float32(0.7602), np.float32(0.4652)] 
2025-01-02 07:24:34.893301: Epoch time: 40.82 s 
2025-01-02 07:24:35.627731:  
2025-01-02 07:24:35.627731: Epoch 150 
2025-01-02 07:24:35.632782: Current learning rate: 0.00438 
2025-01-02 07:25:16.448910: train_loss -0.644 
2025-01-02 07:25:16.449910: val_loss -0.5387 
2025-01-02 07:25:16.455427: Pseudo dice [np.float32(0.7731), np.float32(0.3847)] 
2025-01-02 07:25:16.457934: Epoch time: 40.82 s 
2025-01-02 07:25:17.041295:  
2025-01-02 07:25:17.042299: Epoch 151 
2025-01-02 07:25:17.047370: Current learning rate: 0.00434 
2025-01-02 07:25:57.831649: train_loss -0.6454 
2025-01-02 07:25:57.832160: val_loss -0.5742 
2025-01-02 07:25:57.837791: Pseudo dice [np.float32(0.7567), np.float32(0.4754)] 
2025-01-02 07:25:57.840869: Epoch time: 40.79 s 
2025-01-02 07:25:58.438022:  
2025-01-02 07:25:58.438022: Epoch 152 
2025-01-02 07:25:58.444108: Current learning rate: 0.0043 
2025-01-02 07:26:39.230353: train_loss -0.6532 
2025-01-02 07:26:39.231357: val_loss -0.6103 
2025-01-02 07:26:39.237871: Pseudo dice [np.float32(0.7764), np.float32(0.5641)] 
2025-01-02 07:26:39.241383: Epoch time: 40.79 s 
2025-01-02 07:26:39.838189:  
2025-01-02 07:26:39.838189: Epoch 153 
2025-01-02 07:26:39.843220: Current learning rate: 0.00427 
2025-01-02 07:27:20.728104: train_loss -0.6409 
2025-01-02 07:27:20.728620: val_loss -0.6227 
2025-01-02 07:27:20.733674: Pseudo dice [np.float32(0.8009), np.float32(0.513)] 
2025-01-02 07:27:20.736708: Epoch time: 40.89 s 
2025-01-02 07:27:20.740213: Yayy! New best EMA pseudo Dice: 0.621999979019165 
2025-01-02 07:27:21.488268:  
2025-01-02 07:27:21.489270: Epoch 154 
2025-01-02 07:27:21.493822: Current learning rate: 0.00423 
2025-01-02 07:28:02.290867: train_loss -0.6538 
2025-01-02 07:28:02.291370: val_loss -0.5942 
2025-01-02 07:28:02.296383: Pseudo dice [np.float32(0.7785), np.float32(0.5115)] 
2025-01-02 07:28:02.299935: Epoch time: 40.8 s 
2025-01-02 07:28:02.303443: Yayy! New best EMA pseudo Dice: 0.6243000030517578 
2025-01-02 07:28:03.084834:  
2025-01-02 07:28:03.086342: Epoch 155 
2025-01-02 07:28:03.090949: Current learning rate: 0.00419 
2025-01-02 07:28:43.890215: train_loss -0.6533 
2025-01-02 07:28:43.890215: val_loss -0.6374 
2025-01-02 07:28:43.895848: Pseudo dice [np.float32(0.8214), np.float32(0.6223)] 
2025-01-02 07:28:43.899910: Epoch time: 40.81 s 
2025-01-02 07:28:43.903036: Yayy! New best EMA pseudo Dice: 0.6341000199317932 
2025-01-02 07:28:44.682387:  
2025-01-02 07:28:44.682387: Epoch 156 
2025-01-02 07:28:44.687472: Current learning rate: 0.00415 
2025-01-02 07:29:25.480415: train_loss -0.663 
2025-01-02 07:29:25.480415: val_loss -0.5533 
2025-01-02 07:29:25.486453: Pseudo dice [np.float32(0.771), np.float32(0.4614)] 
2025-01-02 07:29:25.489462: Epoch time: 40.8 s 
2025-01-02 07:29:26.254112:  
2025-01-02 07:29:26.255111: Epoch 157 
2025-01-02 07:29:26.260706: Current learning rate: 0.00411 
2025-01-02 07:30:07.073722: train_loss -0.6553 
2025-01-02 07:30:07.073722: val_loss -0.6191 
2025-01-02 07:30:07.079747: Pseudo dice [np.float32(0.7775), np.float32(0.6016)] 
2025-01-02 07:30:07.083266: Epoch time: 40.82 s 
2025-01-02 07:30:07.085851: Yayy! New best EMA pseudo Dice: 0.6380000114440918 
2025-01-02 07:30:07.845098:  
2025-01-02 07:30:07.845098: Epoch 158 
2025-01-02 07:30:07.851215: Current learning rate: 0.00407 
2025-01-02 07:30:48.647898: train_loss -0.6595 
2025-01-02 07:30:48.648898: val_loss -0.5396 
2025-01-02 07:30:48.654415: Pseudo dice [np.float32(0.7796), np.float32(0.4269)] 
2025-01-02 07:30:48.657924: Epoch time: 40.8 s 
2025-01-02 07:30:49.257727:  
2025-01-02 07:30:49.258230: Epoch 159 
2025-01-02 07:30:49.263266: Current learning rate: 0.00403 
2025-01-02 07:31:30.062933: train_loss -0.6525 
2025-01-02 07:31:30.063934: val_loss -0.5876 
2025-01-02 07:31:30.070461: Pseudo dice [np.float32(0.7815), np.float32(0.4203)] 
2025-01-02 07:31:30.073971: Epoch time: 40.81 s 
2025-01-02 07:31:30.664960:  
2025-01-02 07:31:30.664960: Epoch 160 
2025-01-02 07:31:30.670006: Current learning rate: 0.00399 
2025-01-02 07:32:11.477506: train_loss -0.6627 
2025-01-02 07:32:11.477506: val_loss -0.5334 
2025-01-02 07:32:11.483519: Pseudo dice [np.float32(0.7722), np.float32(0.4584)] 
2025-01-02 07:32:11.486024: Epoch time: 40.81 s 
2025-01-02 07:32:12.077810:  
2025-01-02 07:32:12.078810: Epoch 161 
2025-01-02 07:32:12.084323: Current learning rate: 0.00395 
2025-01-02 07:32:52.894433: train_loss -0.6323 
2025-01-02 07:32:52.895437: val_loss -0.5819 
2025-01-02 07:32:52.901478: Pseudo dice [np.float32(0.768), np.float32(0.3805)] 
2025-01-02 07:32:52.904510: Epoch time: 40.82 s 
2025-01-02 07:32:53.497017:  
2025-01-02 07:32:53.498020: Epoch 162 
2025-01-02 07:32:53.503053: Current learning rate: 0.00391 
2025-01-02 07:33:34.313755: train_loss -0.6337 
2025-01-02 07:33:34.314268: val_loss -0.5562 
2025-01-02 07:33:34.321346: Pseudo dice [np.float32(0.7477), np.float32(0.4469)] 
2025-01-02 07:33:34.324378: Epoch time: 40.82 s 
2025-01-02 07:33:34.928722:  
2025-01-02 07:33:34.929724: Epoch 163 
2025-01-02 07:33:34.934910: Current learning rate: 0.00387 
2025-01-02 07:34:15.771081: train_loss -0.6569 
2025-01-02 07:34:15.772593: val_loss -0.5983 
2025-01-02 07:34:15.778147: Pseudo dice [np.float32(0.7982), np.float32(0.5366)] 
2025-01-02 07:34:15.781178: Epoch time: 40.84 s 
2025-01-02 07:34:16.383840:  
2025-01-02 07:34:16.383840: Epoch 164 
2025-01-02 07:34:16.389911: Current learning rate: 0.00383 
2025-01-02 07:34:57.261522: train_loss -0.6664 
2025-01-02 07:34:57.262034: val_loss -0.5684 
2025-01-02 07:34:57.267125: Pseudo dice [np.float32(0.7706), np.float32(0.4412)] 
2025-01-02 07:34:57.270674: Epoch time: 40.88 s 
2025-01-02 07:34:58.018904:  
2025-01-02 07:34:58.019406: Epoch 165 
2025-01-02 07:34:58.022915: Current learning rate: 0.00379 
2025-01-02 07:35:38.839979: train_loss -0.6467 
2025-01-02 07:35:38.840985: val_loss -0.5175 
2025-01-02 07:35:38.847000: Pseudo dice [np.float32(0.7654), np.float32(0.4202)] 
2025-01-02 07:35:38.850015: Epoch time: 40.82 s 
2025-01-02 07:35:39.428194:  
2025-01-02 07:35:39.429149: Epoch 166 
2025-01-02 07:35:39.434162: Current learning rate: 0.00375 
2025-01-02 07:36:20.255254: train_loss -0.6501 
2025-01-02 07:36:20.256258: val_loss -0.5677 
2025-01-02 07:36:20.261784: Pseudo dice [np.float32(0.7877), np.float32(0.4154)] 
2025-01-02 07:36:20.265800: Epoch time: 40.83 s 
2025-01-02 07:36:21.057483:  
2025-01-02 07:36:21.057483: Epoch 167 
2025-01-02 07:36:21.062559: Current learning rate: 0.00371 
2025-01-02 07:37:01.865272: train_loss -0.6568 
2025-01-02 07:37:01.866275: val_loss -0.5744 
2025-01-02 07:37:01.872795: Pseudo dice [np.float32(0.7636), np.float32(0.5078)] 
2025-01-02 07:37:01.875301: Epoch time: 40.81 s 
2025-01-02 07:37:02.487652:  
2025-01-02 07:37:02.488162: Epoch 168 
2025-01-02 07:37:02.493744: Current learning rate: 0.00367 
2025-01-02 07:37:43.298976: train_loss -0.662 
2025-01-02 07:37:43.299984: val_loss -0.5403 
2025-01-02 07:37:43.306505: Pseudo dice [np.float32(0.7713), np.float32(0.3846)] 
2025-01-02 07:37:43.310017: Epoch time: 40.81 s 
2025-01-02 07:37:43.914416:  
2025-01-02 07:37:43.914416: Epoch 169 
2025-01-02 07:37:43.919449: Current learning rate: 0.00363 
2025-01-02 07:38:24.735913: train_loss -0.6521 
2025-01-02 07:38:24.736415: val_loss -0.6155 
2025-01-02 07:38:24.741426: Pseudo dice [np.float32(0.7988), np.float32(0.596)] 
2025-01-02 07:38:24.744934: Epoch time: 40.82 s 
2025-01-02 07:38:25.333962:  
2025-01-02 07:38:25.334963: Epoch 170 
2025-01-02 07:38:25.340062: Current learning rate: 0.00359 
2025-01-02 07:39:06.156102: train_loss -0.6701 
2025-01-02 07:39:06.156610: val_loss -0.5849 
2025-01-02 07:39:06.161667: Pseudo dice [np.float32(0.7819), np.float32(0.5071)] 
2025-01-02 07:39:06.165710: Epoch time: 40.82 s 
2025-01-02 07:39:06.803505:  
2025-01-02 07:39:06.803505: Epoch 171 
2025-01-02 07:39:06.809519: Current learning rate: 0.00355 
2025-01-02 07:39:47.626322: train_loss -0.6588 
2025-01-02 07:39:47.626322: val_loss -0.5507 
2025-01-02 07:39:47.632341: Pseudo dice [np.float32(0.7852), np.float32(0.4832)] 
2025-01-02 07:39:47.635849: Epoch time: 40.82 s 
2025-01-02 07:39:48.223312:  
2025-01-02 07:39:48.223312: Epoch 172 
2025-01-02 07:39:48.228324: Current learning rate: 0.00351 
2025-01-02 07:40:29.055062: train_loss -0.6722 
2025-01-02 07:40:29.055062: val_loss -0.5692 
2025-01-02 07:40:29.060126: Pseudo dice [np.float32(0.7897), np.float32(0.4287)] 
2025-01-02 07:40:29.063659: Epoch time: 40.83 s 
2025-01-02 07:40:29.833412:  
2025-01-02 07:40:29.833412: Epoch 173 
2025-01-02 07:40:29.838429: Current learning rate: 0.00346 
2025-01-02 07:41:10.663446: train_loss -0.66 
2025-01-02 07:41:10.663446: val_loss -0.6129 
2025-01-02 07:41:10.666958: Pseudo dice [np.float32(0.7778), np.float32(0.5768)] 
2025-01-02 07:41:10.671035: Epoch time: 40.83 s 
2025-01-02 07:41:11.257714:  
2025-01-02 07:41:11.258717: Epoch 174 
2025-01-02 07:41:11.263451: Current learning rate: 0.00342 
2025-01-02 07:41:52.081600: train_loss -0.6858 
2025-01-02 07:41:52.082103: val_loss -0.5735 
2025-01-02 07:41:52.087116: Pseudo dice [np.float32(0.7551), np.float32(0.5058)] 
2025-01-02 07:41:52.090137: Epoch time: 40.82 s 
2025-01-02 07:41:52.682093:  
2025-01-02 07:41:52.682093: Epoch 175 
2025-01-02 07:41:52.687129: Current learning rate: 0.00338 
2025-01-02 07:42:33.511467: train_loss -0.6681 
2025-01-02 07:42:33.512470: val_loss -0.5857 
2025-01-02 07:42:33.518988: Pseudo dice [np.float32(0.7743), np.float32(0.4722)] 
2025-01-02 07:42:33.522497: Epoch time: 40.83 s 
2025-01-02 07:42:34.116187:  
2025-01-02 07:42:34.116187: Epoch 176 
2025-01-02 07:42:34.121199: Current learning rate: 0.00334 
2025-01-02 07:43:14.939277: train_loss -0.6649 
2025-01-02 07:43:14.939277: val_loss -0.5768 
2025-01-02 07:43:14.945389: Pseudo dice [np.float32(0.77), np.float32(0.5216)] 
2025-01-02 07:43:14.947923: Epoch time: 40.82 s 
2025-01-02 07:43:15.533793:  
2025-01-02 07:43:15.534796: Epoch 177 
2025-01-02 07:43:15.539383: Current learning rate: 0.0033 
2025-01-02 07:43:56.355372: train_loss -0.6847 
2025-01-02 07:43:56.356375: val_loss -0.5626 
2025-01-02 07:43:56.361845: Pseudo dice [np.float32(0.7628), np.float32(0.4957)] 
2025-01-02 07:43:56.365359: Epoch time: 40.82 s 
2025-01-02 07:43:56.957715:  
2025-01-02 07:43:56.957715: Epoch 178 
2025-01-02 07:43:56.962753: Current learning rate: 0.00326 
2025-01-02 07:44:37.793141: train_loss -0.6763 
2025-01-02 07:44:37.794146: val_loss -0.6259 
2025-01-02 07:44:37.805676: Pseudo dice [np.float32(0.7902), np.float32(0.5565)] 
2025-01-02 07:44:37.809186: Epoch time: 40.84 s 
2025-01-02 07:44:38.396996:  
2025-01-02 07:44:38.397499: Epoch 179 
2025-01-02 07:44:38.402509: Current learning rate: 0.00322 
2025-01-02 07:45:19.289516: train_loss -0.6743 
2025-01-02 07:45:19.290520: val_loss -0.5799 
2025-01-02 07:45:19.295561: Pseudo dice [np.float32(0.7612), np.float32(0.5254)] 
2025-01-02 07:45:19.299066: Epoch time: 40.89 s 
2025-01-02 07:45:20.069642:  
2025-01-02 07:45:20.070642: Epoch 180 
2025-01-02 07:45:20.075712: Current learning rate: 0.00318 
2025-01-02 07:46:00.930075: train_loss -0.6915 
2025-01-02 07:46:00.930618: val_loss -0.5534 
2025-01-02 07:46:00.936203: Pseudo dice [np.float32(0.7732), np.float32(0.4309)] 
2025-01-02 07:46:00.939242: Epoch time: 40.86 s 
2025-01-02 07:46:01.533674:  
2025-01-02 07:46:01.533674: Epoch 181 
2025-01-02 07:46:01.538687: Current learning rate: 0.00314 
2025-01-02 07:46:42.357332: train_loss -0.6938 
2025-01-02 07:46:42.357844: val_loss -0.5858 
2025-01-02 07:46:42.363429: Pseudo dice [np.float32(0.798), np.float32(0.5066)] 
2025-01-02 07:46:42.365943: Epoch time: 40.82 s 
2025-01-02 07:46:42.966362:  
2025-01-02 07:46:42.966362: Epoch 182 
2025-01-02 07:46:42.971399: Current learning rate: 0.0031 
2025-01-02 07:47:23.784872: train_loss -0.6782 
2025-01-02 07:47:23.785374: val_loss -0.6055 
2025-01-02 07:47:23.790386: Pseudo dice [np.float32(0.7994), np.float32(0.5354)] 
2025-01-02 07:47:23.793898: Epoch time: 40.82 s 
2025-01-02 07:47:23.796401: Yayy! New best EMA pseudo Dice: 0.6380000114440918 
2025-01-02 07:47:24.540773:  
2025-01-02 07:47:24.540773: Epoch 183 
2025-01-02 07:47:24.546333: Current learning rate: 0.00306 
2025-01-02 07:48:05.369477: train_loss -0.6872 
2025-01-02 07:48:05.369477: val_loss -0.5731 
2025-01-02 07:48:05.375494: Pseudo dice [np.float32(0.7896), np.float32(0.4675)] 
2025-01-02 07:48:05.379504: Epoch time: 40.83 s 
2025-01-02 07:48:05.973732:  
2025-01-02 07:48:05.973732: Epoch 184 
2025-01-02 07:48:05.978779: Current learning rate: 0.00302 
2025-01-02 07:48:46.793922: train_loss -0.6778 
2025-01-02 07:48:46.793922: val_loss -0.5754 
2025-01-02 07:48:46.800461: Pseudo dice [np.float32(0.7862), np.float32(0.3858)] 
2025-01-02 07:48:46.803480: Epoch time: 40.82 s 
2025-01-02 07:48:47.401095:  
2025-01-02 07:48:47.401095: Epoch 185 
2025-01-02 07:48:47.406106: Current learning rate: 0.00297 
2025-01-02 07:49:28.232122: train_loss -0.6936 
2025-01-02 07:49:28.232634: val_loss -0.5621 
2025-01-02 07:49:28.238220: Pseudo dice [np.float32(0.7734), np.float32(0.4915)] 
2025-01-02 07:49:28.241789: Epoch time: 40.83 s 
2025-01-02 07:49:28.837420:  
2025-01-02 07:49:28.837930: Epoch 186 
2025-01-02 07:49:28.843036: Current learning rate: 0.00293 
2025-01-02 07:50:09.656461: train_loss -0.6812 
2025-01-02 07:50:09.656461: val_loss -0.5753 
2025-01-02 07:50:09.662472: Pseudo dice [np.float32(0.7972), np.float32(0.4663)] 
2025-01-02 07:50:09.665481: Epoch time: 40.82 s 
2025-01-02 07:50:10.262667:  
2025-01-02 07:50:10.263170: Epoch 187 
2025-01-02 07:50:10.268261: Current learning rate: 0.00289 
2025-01-02 07:50:51.096948: train_loss -0.6748 
2025-01-02 07:50:51.097953: val_loss -0.5718 
2025-01-02 07:50:51.102971: Pseudo dice [np.float32(0.7841), np.float32(0.5013)] 
2025-01-02 07:50:51.106478: Epoch time: 40.84 s 
2025-01-02 07:50:51.885293:  
2025-01-02 07:50:51.885797: Epoch 188 
2025-01-02 07:50:51.890872: Current learning rate: 0.00285 
2025-01-02 07:51:32.721869: train_loss -0.6794 
2025-01-02 07:51:32.721869: val_loss -0.5832 
2025-01-02 07:51:32.729389: Pseudo dice [np.float32(0.7608), np.float32(0.5156)] 
2025-01-02 07:51:32.732947: Epoch time: 40.84 s 
2025-01-02 07:51:33.327469:  
2025-01-02 07:51:33.327469: Epoch 189 
2025-01-02 07:51:33.333052: Current learning rate: 0.00281 
2025-01-02 07:52:14.146579: train_loss -0.6671 
2025-01-02 07:52:14.146579: val_loss -0.5995 
2025-01-02 07:52:14.152592: Pseudo dice [np.float32(0.7741), np.float32(0.4804)] 
2025-01-02 07:52:14.155602: Epoch time: 40.82 s 
2025-01-02 07:52:14.743468:  
2025-01-02 07:52:14.743468: Epoch 190 
2025-01-02 07:52:14.748479: Current learning rate: 0.00277 
2025-01-02 07:52:55.552826: train_loss -0.6848 
2025-01-02 07:52:55.554333: val_loss -0.5543 
2025-01-02 07:52:55.558893: Pseudo dice [np.float32(0.7648), np.float32(0.4201)] 
2025-01-02 07:52:55.562927: Epoch time: 40.81 s 
2025-01-02 07:52:56.148342:  
2025-01-02 07:52:56.149345: Epoch 191 
2025-01-02 07:52:56.154011: Current learning rate: 0.00273 
2025-01-02 07:53:36.969802: train_loss -0.6593 
2025-01-02 07:53:36.970801: val_loss -0.6048 
2025-01-02 07:53:36.977321: Pseudo dice [np.float32(0.7697), np.float32(0.5079)] 
2025-01-02 07:53:36.980829: Epoch time: 40.82 s 
2025-01-02 07:53:37.577550:  
2025-01-02 07:53:37.577550: Epoch 192 
2025-01-02 07:53:37.583136: Current learning rate: 0.00268 
2025-01-02 07:54:18.441053: train_loss -0.6773 
2025-01-02 07:54:18.442057: val_loss -0.6066 
2025-01-02 07:54:18.447067: Pseudo dice [np.float32(0.7789), np.float32(0.5573)] 
2025-01-02 07:54:18.451074: Epoch time: 40.86 s 
2025-01-02 07:54:19.047601:  
2025-01-02 07:54:19.047601: Epoch 193 
2025-01-02 07:54:19.053177: Current learning rate: 0.00264 
2025-01-02 07:54:59.928436: train_loss -0.6817 
2025-01-02 07:54:59.928436: val_loss -0.6144 
2025-01-02 07:54:59.934950: Pseudo dice [np.float32(0.7994), np.float32(0.5385)] 
2025-01-02 07:54:59.937456: Epoch time: 40.88 s 
2025-01-02 07:55:00.536834:  
2025-01-02 07:55:00.538352: Epoch 194 
2025-01-02 07:55:00.543402: Current learning rate: 0.0026 
2025-01-02 07:55:41.391183: train_loss -0.69 
2025-01-02 07:55:41.391183: val_loss -0.6217 
2025-01-02 07:55:41.398266: Pseudo dice [np.float32(0.7689), np.float32(0.5792)] 
2025-01-02 07:55:41.401376: Epoch time: 40.85 s 
2025-01-02 07:55:41.403910: Yayy! New best EMA pseudo Dice: 0.6409000158309937 
2025-01-02 07:55:42.200947:  
2025-01-02 07:55:42.200947: Epoch 195 
2025-01-02 07:55:42.206498: Current learning rate: 0.00256 
2025-01-02 07:56:23.043369: train_loss -0.7167 
2025-01-02 07:56:23.044369: val_loss -0.6111 
2025-01-02 07:56:23.049881: Pseudo dice [np.float32(0.7974), np.float32(0.526)] 
2025-01-02 07:56:23.053390: Epoch time: 40.84 s 
2025-01-02 07:56:23.055895: Yayy! New best EMA pseudo Dice: 0.6430000066757202 
2025-01-02 07:56:24.018774:  
2025-01-02 07:56:24.019773: Epoch 196 
2025-01-02 07:56:24.025317: Current learning rate: 0.00252 
2025-01-02 07:57:04.833543: train_loss -0.6893 
2025-01-02 07:57:04.833543: val_loss -0.5719 
2025-01-02 07:57:04.840080: Pseudo dice [np.float32(0.7505), np.float32(0.5837)] 
2025-01-02 07:57:04.843087: Epoch time: 40.81 s 
2025-01-02 07:57:04.845595: Yayy! New best EMA pseudo Dice: 0.6453999876976013 
2025-01-02 07:57:05.626986:  
2025-01-02 07:57:05.626986: Epoch 197 
2025-01-02 07:57:05.631550: Current learning rate: 0.00248 
2025-01-02 07:57:46.456678: train_loss -0.6947 
2025-01-02 07:57:46.457191: val_loss -0.5941 
2025-01-02 07:57:46.462779: Pseudo dice [np.float32(0.7752), np.float32(0.5159)] 
2025-01-02 07:57:46.465828: Epoch time: 40.83 s 
2025-01-02 07:57:46.467847: Yayy! New best EMA pseudo Dice: 0.6453999876976013 
2025-01-02 07:57:47.239562:  
2025-01-02 07:57:47.239562: Epoch 198 
2025-01-02 07:57:47.245124: Current learning rate: 0.00243 
2025-01-02 07:58:28.050537: train_loss -0.698 
2025-01-02 07:58:28.051540: val_loss -0.5961 
2025-01-02 07:58:28.056594: Pseudo dice [np.float32(0.781), np.float32(0.4703)] 
2025-01-02 07:58:28.059103: Epoch time: 40.81 s 
2025-01-02 07:58:28.667699:  
2025-01-02 07:58:28.667699: Epoch 199 
2025-01-02 07:58:28.673238: Current learning rate: 0.00239 
2025-01-02 07:59:09.476567: train_loss -0.684 
2025-01-02 07:59:09.477073: val_loss -0.596 
2025-01-02 07:59:09.482113: Pseudo dice [np.float32(0.7945), np.float32(0.491)] 
2025-01-02 07:59:09.486139: Epoch time: 40.81 s 
2025-01-02 07:59:10.236856:  
2025-01-02 07:59:10.237358: Epoch 200 
2025-01-02 07:59:10.242369: Current learning rate: 0.00235 
2025-01-02 07:59:51.071222: train_loss -0.6852 
2025-01-02 07:59:51.072224: val_loss -0.5996 
2025-01-02 07:59:51.078245: Pseudo dice [np.float32(0.778), np.float32(0.5394)] 
2025-01-02 07:59:51.081763: Epoch time: 40.84 s 
2025-01-02 07:59:51.686153:  
2025-01-02 07:59:51.686153: Epoch 201 
2025-01-02 07:59:51.691690: Current learning rate: 0.00231 
2025-01-02 08:00:32.525280: train_loss -0.7076 
2025-01-02 08:00:32.525785: val_loss -0.5957 
2025-01-02 08:00:32.531835: Pseudo dice [np.float32(0.7792), np.float32(0.5245)] 
2025-01-02 08:00:32.534864: Epoch time: 40.84 s 
2025-01-02 08:00:32.537895: Yayy! New best EMA pseudo Dice: 0.6456000208854675 
2025-01-02 08:00:33.328083:  
2025-01-02 08:00:33.329086: Epoch 202 
2025-01-02 08:00:33.333633: Current learning rate: 0.00226 
2025-01-02 08:01:14.164313: train_loss -0.703 
2025-01-02 08:01:14.165312: val_loss -0.5897 
2025-01-02 08:01:14.170829: Pseudo dice [np.float32(0.7822), np.float32(0.5147)] 
2025-01-02 08:01:14.173336: Epoch time: 40.84 s 
2025-01-02 08:01:14.176846: Yayy! New best EMA pseudo Dice: 0.6459000110626221 
2025-01-02 08:01:15.106550:  
2025-01-02 08:01:15.106550: Epoch 203 
2025-01-02 08:01:15.111596: Current learning rate: 0.00222 
2025-01-02 08:01:55.934047: train_loss -0.7055 
2025-01-02 08:01:55.934047: val_loss -0.5852 
2025-01-02 08:01:55.940063: Pseudo dice [np.float32(0.7808), np.float32(0.5513)] 
2025-01-02 08:01:55.943077: Epoch time: 40.83 s 
2025-01-02 08:01:55.945586: Yayy! New best EMA pseudo Dice: 0.6478999853134155 
2025-01-02 08:01:56.794777:  
2025-01-02 08:01:56.795280: Epoch 204 
2025-01-02 08:01:56.800294: Current learning rate: 0.00218 
2025-01-02 08:02:37.590880: train_loss -0.7002 
2025-01-02 08:02:37.592384: val_loss -0.5501 
2025-01-02 08:02:37.599408: Pseudo dice [np.float32(0.7934), np.float32(0.4249)] 
2025-01-02 08:02:37.602420: Epoch time: 40.8 s 
2025-01-02 08:02:38.212622:  
2025-01-02 08:02:38.213133: Epoch 205 
2025-01-02 08:02:38.218229: Current learning rate: 0.00214 
2025-01-02 08:03:19.031471: train_loss -0.7064 
2025-01-02 08:03:19.032470: val_loss -0.5894 
2025-01-02 08:03:19.037983: Pseudo dice [np.float32(0.7821), np.float32(0.4643)] 
2025-01-02 08:03:19.041492: Epoch time: 40.82 s 
2025-01-02 08:03:19.633230:  
2025-01-02 08:03:19.634233: Epoch 206 
2025-01-02 08:03:19.638822: Current learning rate: 0.00209 
2025-01-02 08:04:00.447865: train_loss -0.6986 
2025-01-02 08:04:00.448868: val_loss -0.5871 
2025-01-02 08:04:00.453953: Pseudo dice [np.float32(0.7978), np.float32(0.4391)] 
2025-01-02 08:04:00.457552: Epoch time: 40.81 s 
2025-01-02 08:04:01.027725:  
2025-01-02 08:04:01.028727: Epoch 207 
2025-01-02 08:04:01.033388: Current learning rate: 0.00205 
2025-01-02 08:04:41.863960: train_loss -0.7205 
2025-01-02 08:04:41.864964: val_loss -0.603 
2025-01-02 08:04:41.869975: Pseudo dice [np.float32(0.7645), np.float32(0.6168)] 
2025-01-02 08:04:41.873983: Epoch time: 40.84 s 
2025-01-02 08:04:42.471064:  
2025-01-02 08:04:42.471792: Epoch 208 
2025-01-02 08:04:42.477074: Current learning rate: 0.00201 
2025-01-02 08:05:23.340221: train_loss -0.708 
2025-01-02 08:05:23.340731: val_loss -0.6376 
2025-01-02 08:05:23.346275: Pseudo dice [np.float32(0.7965), np.float32(0.6046)] 
2025-01-02 08:05:23.348793: Epoch time: 40.87 s 
2025-01-02 08:05:23.352818: Yayy! New best EMA pseudo Dice: 0.6503000259399414 
2025-01-02 08:05:24.086579:  
2025-01-02 08:05:24.087579: Epoch 209 
2025-01-02 08:05:24.092659: Current learning rate: 0.00196 
2025-01-02 08:06:04.908221: train_loss -0.7126 
2025-01-02 08:06:04.908732: val_loss -0.6107 
2025-01-02 08:06:04.914336: Pseudo dice [np.float32(0.8048), np.float32(0.5564)] 
2025-01-02 08:06:04.917412: Epoch time: 40.82 s 
2025-01-02 08:06:04.920452: Yayy! New best EMA pseudo Dice: 0.6532999873161316 
2025-01-02 08:06:05.659197:  
2025-01-02 08:06:05.659197: Epoch 210 
2025-01-02 08:06:05.664749: Current learning rate: 0.00192 
2025-01-02 08:06:46.482478: train_loss -0.7143 
2025-01-02 08:06:46.483481: val_loss -0.613 
2025-01-02 08:06:46.490128: Pseudo dice [np.float32(0.7969), np.float32(0.528)] 
2025-01-02 08:06:46.492639: Epoch time: 40.82 s 
2025-01-02 08:06:46.496649: Yayy! New best EMA pseudo Dice: 0.65420001745224 
2025-01-02 08:06:47.422976:  
2025-01-02 08:06:47.422976: Epoch 211 
2025-01-02 08:06:47.428550: Current learning rate: 0.00188 
2025-01-02 08:07:28.222527: train_loss -0.7255 
2025-01-02 08:07:28.223530: val_loss -0.6314 
2025-01-02 08:07:28.229645: Pseudo dice [np.float32(0.8015), np.float32(0.579)] 
2025-01-02 08:07:28.232687: Epoch time: 40.8 s 
2025-01-02 08:07:28.235717: Yayy! New best EMA pseudo Dice: 0.657800018787384 
2025-01-02 08:07:28.970566:  
2025-01-02 08:07:28.971069: Epoch 212 
2025-01-02 08:07:28.976082: Current learning rate: 0.00184 
2025-01-02 08:08:09.797207: train_loss -0.7244 
2025-01-02 08:08:09.798239: val_loss -0.6261 
2025-01-02 08:08:09.803849: Pseudo dice [np.float32(0.8021), np.float32(0.6223)] 
2025-01-02 08:08:09.807372: Epoch time: 40.83 s 
2025-01-02 08:08:09.810395: Yayy! New best EMA pseudo Dice: 0.6632999777793884 
2025-01-02 08:08:10.572527:  
2025-01-02 08:08:10.573030: Epoch 213 
2025-01-02 08:08:10.578046: Current learning rate: 0.00179 
2025-01-02 08:08:51.408437: train_loss -0.7223 
2025-01-02 08:08:51.408437: val_loss -0.5816 
2025-01-02 08:08:51.414479: Pseudo dice [np.float32(0.8014), np.float32(0.4694)] 
2025-01-02 08:08:51.416986: Epoch time: 40.84 s 
2025-01-02 08:08:51.968279:  
2025-01-02 08:08:51.968279: Epoch 214 
2025-01-02 08:08:51.973297: Current learning rate: 0.00175 
2025-01-02 08:09:32.778913: train_loss -0.7203 
2025-01-02 08:09:32.779414: val_loss -0.6287 
2025-01-02 08:09:32.784964: Pseudo dice [np.float32(0.7944), np.float32(0.5252)] 
2025-01-02 08:09:32.787481: Epoch time: 40.81 s 
2025-01-02 08:09:33.349073:  
2025-01-02 08:09:33.349073: Epoch 215 
2025-01-02 08:09:33.354604: Current learning rate: 0.0017 
2025-01-02 08:10:14.188814: train_loss -0.7272 
2025-01-02 08:10:14.189329: val_loss -0.6117 
2025-01-02 08:10:14.193898: Pseudo dice [np.float32(0.8101), np.float32(0.5472)] 
2025-01-02 08:10:14.197975: Epoch time: 40.84 s 
2025-01-02 08:10:14.747208:  
2025-01-02 08:10:14.747208: Epoch 216 
2025-01-02 08:10:14.752817: Current learning rate: 0.00166 
2025-01-02 08:10:55.579064: train_loss -0.7196 
2025-01-02 08:10:55.580067: val_loss -0.6459 
2025-01-02 08:10:55.585081: Pseudo dice [np.float32(0.8144), np.float32(0.5046)] 
2025-01-02 08:10:55.589092: Epoch time: 40.83 s 
2025-01-02 08:10:56.151415:  
2025-01-02 08:10:56.151415: Epoch 217 
2025-01-02 08:10:56.157486: Current learning rate: 0.00162 
2025-01-02 08:11:36.969493: train_loss -0.7207 
2025-01-02 08:11:36.969493: val_loss -0.6265 
2025-01-02 08:11:36.976517: Pseudo dice [np.float32(0.8), np.float32(0.6712)] 
2025-01-02 08:11:36.979526: Epoch time: 40.82 s 
2025-01-02 08:11:36.982032: Yayy! New best EMA pseudo Dice: 0.6693000197410583 
2025-01-02 08:11:37.709293:  
2025-01-02 08:11:37.710293: Epoch 218 
2025-01-02 08:11:37.715351: Current learning rate: 0.00157 
2025-01-02 08:12:18.536971: train_loss -0.739 
2025-01-02 08:12:18.537473: val_loss -0.556 
2025-01-02 08:12:18.543064: Pseudo dice [np.float32(0.7907), np.float32(0.5349)] 
2025-01-02 08:12:18.546105: Epoch time: 40.83 s 
2025-01-02 08:12:19.304804:  
2025-01-02 08:12:19.304804: Epoch 219 
2025-01-02 08:12:19.310350: Current learning rate: 0.00153 
2025-01-02 08:13:00.140948: train_loss -0.7433 
2025-01-02 08:13:00.140948: val_loss -0.6113 
2025-01-02 08:13:00.145958: Pseudo dice [np.float32(0.7976), np.float32(0.5892)] 
2025-01-02 08:13:00.149965: Epoch time: 40.84 s 
2025-01-02 08:13:00.152471: Yayy! New best EMA pseudo Dice: 0.6711999773979187 
2025-01-02 08:13:00.895310:  
2025-01-02 08:13:00.895310: Epoch 220 
2025-01-02 08:13:00.900862: Current learning rate: 0.00148 
2025-01-02 08:13:41.738784: train_loss -0.7276 
2025-01-02 08:13:41.739291: val_loss -0.5748 
2025-01-02 08:13:41.745891: Pseudo dice [np.float32(0.7682), np.float32(0.4762)] 
2025-01-02 08:13:41.748423: Epoch time: 40.84 s 
2025-01-02 08:13:42.299177:  
2025-01-02 08:13:42.299177: Epoch 221 
2025-01-02 08:13:42.304747: Current learning rate: 0.00144 
2025-01-02 08:14:23.129764: train_loss -0.723 
2025-01-02 08:14:23.130769: val_loss -0.562 
2025-01-02 08:14:23.135782: Pseudo dice [np.float32(0.8075), np.float32(0.4328)] 
2025-01-02 08:14:23.139289: Epoch time: 40.83 s 
2025-01-02 08:14:23.694675:  
2025-01-02 08:14:23.694675: Epoch 222 
2025-01-02 08:14:23.700229: Current learning rate: 0.00139 
2025-01-02 08:15:04.531253: train_loss -0.7149 
2025-01-02 08:15:04.531765: val_loss -0.5863 
2025-01-02 08:15:04.537321: Pseudo dice [np.float32(0.806), np.float32(0.5354)] 
2025-01-02 08:15:04.539843: Epoch time: 40.84 s 
2025-01-02 08:15:05.104175:  
2025-01-02 08:15:05.105178: Epoch 223 
2025-01-02 08:15:05.110220: Current learning rate: 0.00135 
2025-01-02 08:15:45.936208: train_loss -0.7285 
2025-01-02 08:15:45.936208: val_loss -0.6389 
2025-01-02 08:15:45.943419: Pseudo dice [np.float32(0.7865), np.float32(0.5854)] 
2025-01-02 08:15:45.946959: Epoch time: 40.83 s 
2025-01-02 08:15:46.500315:  
2025-01-02 08:15:46.501317: Epoch 224 
2025-01-02 08:15:46.506343: Current learning rate: 0.0013 
2025-01-02 08:16:27.377691: train_loss -0.7285 
2025-01-02 08:16:27.377691: val_loss -0.5829 
2025-01-02 08:16:27.383734: Pseudo dice [np.float32(0.7959), np.float32(0.5299)] 
2025-01-02 08:16:27.387265: Epoch time: 40.88 s 
2025-01-02 08:16:27.942303:  
2025-01-02 08:16:27.942303: Epoch 225 
2025-01-02 08:16:27.947328: Current learning rate: 0.00126 
2025-01-02 08:17:08.769172: train_loss -0.7286 
2025-01-02 08:17:08.769681: val_loss -0.5813 
2025-01-02 08:17:08.775782: Pseudo dice [np.float32(0.8048), np.float32(0.4091)] 
2025-01-02 08:17:08.778809: Epoch time: 40.83 s 
2025-01-02 08:17:09.333925:  
2025-01-02 08:17:09.333925: Epoch 226 
2025-01-02 08:17:09.338956: Current learning rate: 0.00121 
2025-01-02 08:17:50.184468: train_loss -0.7163 
2025-01-02 08:17:50.184468: val_loss -0.6043 
2025-01-02 08:17:50.190486: Pseudo dice [np.float32(0.7852), np.float32(0.4715)] 
2025-01-02 08:17:50.192992: Epoch time: 40.85 s 
2025-01-02 08:17:50.738900:  
2025-01-02 08:17:50.738900: Epoch 227 
2025-01-02 08:17:50.744967: Current learning rate: 0.00117 
2025-01-02 08:18:31.585804: train_loss -0.7328 
2025-01-02 08:18:31.586307: val_loss -0.6054 
2025-01-02 08:18:31.591857: Pseudo dice [np.float32(0.8054), np.float32(0.5227)] 
2025-01-02 08:18:31.594884: Epoch time: 40.85 s 
2025-01-02 08:18:32.364223:  
2025-01-02 08:18:32.365226: Epoch 228 
2025-01-02 08:18:32.370257: Current learning rate: 0.00112 
2025-01-02 08:19:13.202241: train_loss -0.7428 
2025-01-02 08:19:13.202241: val_loss -0.5667 
2025-01-02 08:19:13.207287: Pseudo dice [np.float32(0.7879), np.float32(0.4083)] 
2025-01-02 08:19:13.210822: Epoch time: 40.84 s 
2025-01-02 08:19:13.761568:  
2025-01-02 08:19:13.762072: Epoch 229 
2025-01-02 08:19:13.767086: Current learning rate: 0.00108 
2025-01-02 08:19:54.556054: train_loss -0.7334 
2025-01-02 08:19:54.557068: val_loss -0.6125 
2025-01-02 08:19:54.563637: Pseudo dice [np.float32(0.8112), np.float32(0.4539)] 
2025-01-02 08:19:54.566159: Epoch time: 40.8 s 
2025-01-02 08:19:55.118943:  
2025-01-02 08:19:55.119947: Epoch 230 
2025-01-02 08:19:55.124494: Current learning rate: 0.00103 
2025-01-02 08:20:35.957821: train_loss -0.727 
2025-01-02 08:20:35.958826: val_loss -0.6207 
2025-01-02 08:20:35.965342: Pseudo dice [np.float32(0.8069), np.float32(0.5727)] 
2025-01-02 08:20:35.967850: Epoch time: 40.84 s 
2025-01-02 08:20:36.523763:  
2025-01-02 08:20:36.524790: Epoch 231 
2025-01-02 08:20:36.529390: Current learning rate: 0.00098 
2025-01-02 08:21:17.361039: train_loss -0.7463 
2025-01-02 08:21:17.361039: val_loss -0.6436 
2025-01-02 08:21:17.367057: Pseudo dice [np.float32(0.7992), np.float32(0.5787)] 
2025-01-02 08:21:17.370073: Epoch time: 40.84 s 
2025-01-02 08:21:17.920894:  
2025-01-02 08:21:17.920894: Epoch 232 
2025-01-02 08:21:17.925943: Current learning rate: 0.00094 
2025-01-02 08:21:58.733098: train_loss -0.7335 
2025-01-02 08:21:58.733098: val_loss -0.549 
2025-01-02 08:21:58.739119: Pseudo dice [np.float32(0.7804), np.float32(0.344)] 
2025-01-02 08:21:58.742629: Epoch time: 40.81 s 
2025-01-02 08:21:59.297178:  
2025-01-02 08:21:59.297178: Epoch 233 
2025-01-02 08:21:59.303732: Current learning rate: 0.00089 
2025-01-02 08:22:40.129017: train_loss -0.7336 
2025-01-02 08:22:40.129017: val_loss -0.5823 
2025-01-02 08:22:40.135140: Pseudo dice [np.float32(0.804), np.float32(0.5782)] 
2025-01-02 08:22:40.138703: Epoch time: 40.83 s 
2025-01-02 08:22:40.696773:  
2025-01-02 08:22:40.696773: Epoch 234 
2025-01-02 08:22:40.701805: Current learning rate: 0.00084 
2025-01-02 08:23:21.497889: train_loss -0.7353 
2025-01-02 08:23:21.498892: val_loss -0.6268 
2025-01-02 08:23:21.504437: Pseudo dice [np.float32(0.797), np.float32(0.5672)] 
2025-01-02 08:23:21.507972: Epoch time: 40.8 s 
2025-01-02 08:23:22.059833:  
2025-01-02 08:23:22.059833: Epoch 235 
2025-01-02 08:23:22.064844: Current learning rate: 0.00079 
2025-01-02 08:24:02.891484: train_loss -0.7442 
2025-01-02 08:24:02.892576: val_loss -0.5623 
2025-01-02 08:24:02.898121: Pseudo dice [np.float32(0.7801), np.float32(0.5312)] 
2025-01-02 08:24:02.901166: Epoch time: 40.83 s 
2025-01-02 08:24:03.631124:  
2025-01-02 08:24:03.631124: Epoch 236 
2025-01-02 08:24:03.636139: Current learning rate: 0.00075 
2025-01-02 08:24:44.440918: train_loss -0.7365 
2025-01-02 08:24:44.441924: val_loss -0.5866 
2025-01-02 08:24:44.447464: Pseudo dice [np.float32(0.8034), np.float32(0.4819)] 
2025-01-02 08:24:44.450983: Epoch time: 40.81 s 
2025-01-02 08:24:45.003645:  
2025-01-02 08:24:45.003645: Epoch 237 
2025-01-02 08:24:45.009177: Current learning rate: 0.0007 
2025-01-02 08:25:25.827180: train_loss -0.7413 
2025-01-02 08:25:25.828689: val_loss -0.6057 
2025-01-02 08:25:25.834763: Pseudo dice [np.float32(0.7842), np.float32(0.6144)] 
2025-01-02 08:25:25.837298: Epoch time: 40.82 s 
2025-01-02 08:25:26.393215:  
2025-01-02 08:25:26.393215: Epoch 238 
2025-01-02 08:25:26.398728: Current learning rate: 0.00065 
2025-01-02 08:26:07.214991: train_loss -0.7423 
2025-01-02 08:26:07.215501: val_loss -0.5915 
2025-01-02 08:26:07.221118: Pseudo dice [np.float32(0.7978), np.float32(0.5903)] 
2025-01-02 08:26:07.224158: Epoch time: 40.82 s 
2025-01-02 08:26:07.787221:  
2025-01-02 08:26:07.787727: Epoch 239 
2025-01-02 08:26:07.792739: Current learning rate: 0.0006 
2025-01-02 08:26:51.290713: train_loss -0.7518 
2025-01-02 08:26:51.291241: val_loss -0.6534 
2025-01-02 08:26:51.297260: Pseudo dice [np.float32(0.8307), np.float32(0.6009)] 
2025-01-02 08:26:51.300771: Epoch time: 43.5 s 
2025-01-02 08:26:51.859601:  
2025-01-02 08:26:51.859601: Epoch 240 
2025-01-02 08:26:51.865141: Current learning rate: 0.00055 
2025-01-02 08:27:32.678403: train_loss -0.7513 
2025-01-02 08:27:32.678907: val_loss -0.5933 
2025-01-02 08:27:32.684509: Pseudo dice [np.float32(0.816), np.float32(0.5155)] 
2025-01-02 08:27:32.687054: Epoch time: 40.82 s 
2025-01-02 08:27:33.249484:  
2025-01-02 08:27:33.249484: Epoch 241 
2025-01-02 08:27:33.254533: Current learning rate: 0.0005 
2025-01-02 08:28:14.046758: train_loss -0.7501 
2025-01-02 08:28:14.046758: val_loss -0.5729 
2025-01-02 08:28:14.053271: Pseudo dice [np.float32(0.7829), np.float32(0.4709)] 
2025-01-02 08:28:14.055777: Epoch time: 40.8 s 
2025-01-02 08:28:14.619895:  
2025-01-02 08:28:14.619895: Epoch 242 
2025-01-02 08:28:14.624916: Current learning rate: 0.00045 
2025-01-02 08:28:55.434967: train_loss -0.76 
2025-01-02 08:28:55.435474: val_loss -0.5789 
2025-01-02 08:28:55.442535: Pseudo dice [np.float32(0.7936), np.float32(0.5662)] 
2025-01-02 08:28:55.445056: Epoch time: 40.82 s 
2025-01-02 08:28:56.014055:  
2025-01-02 08:28:56.014055: Epoch 243 
2025-01-02 08:28:56.019640: Current learning rate: 0.0004 
2025-01-02 08:29:36.824376: train_loss -0.7536 
2025-01-02 08:29:36.824376: val_loss -0.5986 
2025-01-02 08:29:36.831521: Pseudo dice [np.float32(0.8024), np.float32(0.5322)] 
2025-01-02 08:29:36.834582: Epoch time: 40.81 s 
2025-01-02 08:29:37.408424:  
2025-01-02 08:29:37.408424: Epoch 244 
2025-01-02 08:29:37.413450: Current learning rate: 0.00035 
2025-01-02 08:30:18.245272: train_loss -0.7512 
2025-01-02 08:30:18.245783: val_loss -0.5952 
2025-01-02 08:30:18.251339: Pseudo dice [np.float32(0.8198), np.float32(0.5317)] 
2025-01-02 08:30:18.253861: Epoch time: 40.84 s 
2025-01-02 08:30:18.984669:  
2025-01-02 08:30:18.985173: Epoch 245 
2025-01-02 08:30:18.990184: Current learning rate: 0.0003 
2025-01-02 08:30:59.805463: train_loss -0.7411 
2025-01-02 08:30:59.805967: val_loss -0.6092 
2025-01-02 08:30:59.811576: Pseudo dice [np.float32(0.8086), np.float32(0.5525)] 
2025-01-02 08:30:59.814617: Epoch time: 40.82 s 
2025-01-02 08:31:00.398374:  
2025-01-02 08:31:00.398876: Epoch 246 
2025-01-02 08:31:00.404014: Current learning rate: 0.00024 
2025-01-02 08:31:41.199500: train_loss -0.7565 
2025-01-02 08:31:41.200500: val_loss -0.5725 
2025-01-02 08:31:41.207016: Pseudo dice [np.float32(0.8129), np.float32(0.4406)] 
2025-01-02 08:31:41.211024: Epoch time: 40.8 s 
2025-01-02 08:31:41.785023:  
2025-01-02 08:31:41.785524: Epoch 247 
2025-01-02 08:31:41.790536: Current learning rate: 0.00019 
2025-01-02 08:32:22.582666: train_loss -0.7481 
2025-01-02 08:32:22.584172: val_loss -0.6271 
2025-01-02 08:32:22.589224: Pseudo dice [np.float32(0.8114), np.float32(0.6082)] 
2025-01-02 08:32:22.592289: Epoch time: 40.8 s 
2025-01-02 08:32:23.181284:  
2025-01-02 08:32:23.181284: Epoch 248 
2025-01-02 08:32:23.187320: Current learning rate: 0.00013 
2025-01-02 08:33:03.998636: train_loss -0.741 
2025-01-02 08:33:03.999139: val_loss -0.6147 
2025-01-02 08:33:04.004741: Pseudo dice [np.float32(0.812), np.float32(0.5506)] 
2025-01-02 08:33:04.009309: Epoch time: 40.82 s 
2025-01-02 08:33:04.572946:  
2025-01-02 08:33:04.573948: Epoch 249 
2025-01-02 08:33:04.578965: Current learning rate: 7e-05 
2025-01-02 08:33:45.382947: train_loss -0.7567 
2025-01-02 08:33:45.383453: val_loss -0.5984 
2025-01-02 08:33:45.390044: Pseudo dice [np.float32(0.7955), np.float32(0.506)] 
2025-01-02 08:33:45.393077: Epoch time: 40.81 s 
2025-01-02 08:33:46.163251: Training done. 
2025-01-02 08:33:46.187252: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-02 08:33:46.193252: The split file contains 5 splits. 
2025-01-02 08:33:46.199255: Desired fold for training: 0 
2025-01-02 08:33:46.203254: This split has 224 training and 57 validation cases. 
2025-01-02 08:33:46.209255: predicting pancreas_021 
2025-01-02 08:33:46.216252: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-02 08:33:58.558096: predicting pancreas_024 
2025-01-02 08:33:58.570096: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-02 08:34:13.120454: predicting pancreas_035 
2025-01-02 08:34:13.132454: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-02 08:34:18.077989: predicting pancreas_040 
2025-01-02 08:34:18.083986: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-01-02 08:34:29.708695: predicting pancreas_042 
2025-01-02 08:34:29.720695: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-01-02 08:34:44.265028: predicting pancreas_056 
2025-01-02 08:34:44.277535: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-02 08:34:55.922517: predicting pancreas_067 
2025-01-02 08:34:55.931517: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-02 08:35:10.514679: predicting pancreas_075 
2025-01-02 08:35:10.526679: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-01-02 08:35:16.376640: predicting pancreas_086 
2025-01-02 08:35:16.387145: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-02 08:35:25.523257: predicting pancreas_089 
2025-01-02 08:35:25.534257: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-02 08:35:37.154398: predicting pancreas_092 
2025-01-02 08:35:37.164397: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-01-02 08:36:03.342648: predicting pancreas_094 
2025-01-02 08:36:03.359648: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-02 08:36:14.982806: predicting pancreas_095 
2025-01-02 08:36:14.991807: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-02 08:36:26.649803: predicting pancreas_098 
2025-01-02 08:36:26.659803: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-02 08:36:58.502951: predicting pancreas_109 
2025-01-02 08:36:58.520952: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-02 08:37:10.217141: predicting pancreas_110 
2025-01-02 08:37:10.234141: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-02 08:37:28.458483: predicting pancreas_114 
2025-01-02 08:37:28.473990: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-02 08:37:40.137674: predicting pancreas_119 
2025-01-02 08:37:40.150675: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-02 08:37:58.340164: predicting pancreas_138 
2025-01-02 08:37:58.352164: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-02 08:38:16.582016: predicting pancreas_145 
2025-01-02 08:38:16.597019: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-02 08:38:34.811933: predicting pancreas_148 
2025-01-02 08:38:34.831933: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-01-02 08:38:46.489306: predicting pancreas_169 
2025-01-02 08:38:46.498306: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-02 08:38:58.141592: predicting pancreas_170 
2025-01-02 08:38:58.149595: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-02 08:39:12.677580: predicting pancreas_172 
2025-01-02 08:39:12.689580: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-02 08:39:24.339945: predicting pancreas_175 
2025-01-02 08:39:24.352035: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-02 08:39:35.993363: predicting pancreas_180 
2025-01-02 08:39:36.004363: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-02 08:39:47.677995: predicting pancreas_191 
2025-01-02 08:39:47.687996: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-02 08:39:53.536483: predicting pancreas_193 
2025-01-02 08:39:53.542483: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-02 08:40:08.079741: predicting pancreas_212 
2025-01-02 08:40:08.091741: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-02 08:40:19.784891: predicting pancreas_215 
2025-01-02 08:40:19.797892: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-02 08:40:31.447484: predicting pancreas_222 
2025-01-02 08:40:31.457484: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-02 08:40:36.440486: predicting pancreas_235 
2025-01-02 08:40:36.448490: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-02 08:40:48.081728: predicting pancreas_241 
2025-01-02 08:40:48.089728: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-02 08:40:59.751888: predicting pancreas_242 
2025-01-02 08:40:59.765887: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-02 08:41:14.335439: predicting pancreas_244 
2025-01-02 08:41:14.353439: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-02 08:41:37.119603: predicting pancreas_246 
2025-01-02 08:41:37.133110: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-02 08:41:59.889959: predicting pancreas_247 
2025-01-02 08:41:59.903959: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-02 08:42:06.497493: predicting pancreas_264 
2025-01-02 08:42:06.507494: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-02 08:42:21.062688: predicting pancreas_265 
2025-01-02 08:42:21.075688: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-02 08:42:32.745173: predicting pancreas_266 
2025-01-02 08:42:32.755176: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-02 08:42:50.940144: predicting pancreas_267 
2025-01-02 08:42:50.957143: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-02 08:42:57.551105: predicting pancreas_275 
2025-01-02 08:42:57.563108: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-02 08:43:12.086265: predicting pancreas_279 
2025-01-02 08:43:12.099265: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-02 08:43:17.072678: predicting pancreas_287 
2025-01-02 08:43:17.080678: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-02 08:43:28.737484: predicting pancreas_301 
2025-01-02 08:43:28.748483: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-02 08:43:40.441515: predicting pancreas_323 
2025-01-02 08:43:40.453516: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-02 08:43:58.692914: predicting pancreas_336 
2025-01-02 08:43:58.707917: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-02 08:44:10.390690: predicting pancreas_344 
2025-01-02 08:44:10.405691: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-02 08:44:24.968488: predicting pancreas_351 
2025-01-02 08:44:24.980489: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-02 08:44:31.567909: predicting pancreas_354 
2025-01-02 08:44:31.577909: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-01-02 08:44:54.879178: predicting pancreas_372 
2025-01-02 08:44:54.896178: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-02 08:45:13.160053: predicting pancreas_377 
2025-01-02 08:45:13.179562: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-01-02 08:45:27.812396: predicting pancreas_387 
2025-01-02 08:45:27.826395: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-01-02 08:45:39.498822: predicting pancreas_391 
2025-01-02 08:45:39.514822: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-02 08:45:57.709488: predicting pancreas_392 
2025-01-02 08:45:57.721488: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-01-02 08:46:05.936660: predicting pancreas_410 
2025-01-02 08:46:05.946660: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-02 08:46:14.160384: predicting pancreas_412 
2025-01-02 08:46:14.169385: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-01-02 08:47:13.074866: Validation complete 
2025-01-02 08:47:13.074866: Mean Validation Dice:  0.640963697175142 
