
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-16 17:16:19.638680: do_dummy_2d_data_aug: True 
2025-01-16 17:16:19.643685: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-16 17:16:19.646685: The split file contains 5 splits. 
2025-01-16 17:16:19.649685: Desired fold for training: 0 
2025-01-16 17:16:19.652681: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-16 17:16:25.348000: unpacking dataset... 
2025-01-16 17:16:25.538709: unpacking done... 
2025-01-16 17:16:29.278288:  
2025-01-16 17:16:29.278288: Epoch 0 
2025-01-16 17:16:29.283302: Current learning rate: 0.01 
2025-01-16 17:17:14.444927: train_loss 0.1031 
2025-01-16 17:17:14.445931: val_loss 0.0331 
2025-01-16 17:17:14.450941: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-16 17:17:14.454456: Epoch time: 45.17 s 
2025-01-16 17:17:14.457469: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-16 17:17:15.142213:  
2025-01-16 17:17:15.143216: Epoch 1 
2025-01-16 17:17:15.148277: Current learning rate: 0.00996 
2025-01-16 17:17:55.963677: train_loss -0.0626 
2025-01-16 17:17:55.964209: val_loss -0.1284 
2025-01-16 17:17:55.968271: Pseudo dice [np.float32(0.462), np.float32(0.0)] 
2025-01-16 17:17:55.971324: Epoch time: 40.82 s 
2025-01-16 17:17:55.974375: Yayy! New best EMA pseudo Dice: 0.023099999874830246 
2025-01-16 17:17:56.738862:  
2025-01-16 17:17:56.739369: Epoch 2 
2025-01-16 17:17:56.743897: Current learning rate: 0.00993 
2025-01-16 17:18:37.556126: train_loss -0.203 
2025-01-16 17:18:37.556642: val_loss -0.2151 
2025-01-16 17:18:37.561654: Pseudo dice [np.float32(0.5789), np.float32(0.0)] 
2025-01-16 17:18:37.565165: Epoch time: 40.82 s 
2025-01-16 17:18:37.567672: Yayy! New best EMA pseudo Dice: 0.04969999939203262 
2025-01-16 17:18:38.345936:  
2025-01-16 17:18:38.346940: Epoch 3 
2025-01-16 17:18:38.350995: Current learning rate: 0.00989 
2025-01-16 17:19:19.321661: train_loss -0.2781 
2025-01-16 17:19:19.321661: val_loss -0.287 
2025-01-16 17:19:19.327679: Pseudo dice [np.float32(0.6585), np.float32(0.0473)] 
2025-01-16 17:19:19.331192: Epoch time: 40.98 s 
2025-01-16 17:19:19.334203: Yayy! New best EMA pseudo Dice: 0.08009999990463257 
2025-01-16 17:19:20.226142:  
2025-01-16 17:19:20.226646: Epoch 4 
2025-01-16 17:19:20.231662: Current learning rate: 0.00986 
2025-01-16 17:20:01.173042: train_loss -0.3231 
2025-01-16 17:20:01.174050: val_loss -0.3492 
2025-01-16 17:20:01.180108: Pseudo dice [np.float32(0.7004), np.float32(0.121)] 
2025-01-16 17:20:01.183173: Epoch time: 40.95 s 
2025-01-16 17:20:01.186258: Yayy! New best EMA pseudo Dice: 0.11309999972581863 
2025-01-16 17:20:02.229445:  
2025-01-16 17:20:02.230446: Epoch 5 
2025-01-16 17:20:02.235535: Current learning rate: 0.00982 
2025-01-16 17:20:43.171740: train_loss -0.3453 
2025-01-16 17:20:43.171740: val_loss -0.3946 
2025-01-16 17:20:43.177807: Pseudo dice [np.float32(0.6607), np.float32(0.3825)] 
2025-01-16 17:20:43.180891: Epoch time: 40.94 s 
2025-01-16 17:20:43.183492: Yayy! New best EMA pseudo Dice: 0.15399999916553497 
2025-01-16 17:20:44.040034:  
2025-01-16 17:20:44.040552: Epoch 6 
2025-01-16 17:20:44.045574: Current learning rate: 0.00978 
2025-01-16 17:21:24.971380: train_loss -0.421 
2025-01-16 17:21:24.971887: val_loss -0.3919 
2025-01-16 17:21:24.976462: Pseudo dice [np.float32(0.6667), np.float32(0.2846)] 
2025-01-16 17:21:24.979981: Epoch time: 40.93 s 
2025-01-16 17:21:24.982485: Yayy! New best EMA pseudo Dice: 0.18610000610351562 
2025-01-16 17:21:25.734903:  
2025-01-16 17:21:25.735421: Epoch 7 
2025-01-16 17:21:25.738959: Current learning rate: 0.00975 
2025-01-16 17:22:06.560310: train_loss -0.4067 
2025-01-16 17:22:06.560310: val_loss -0.4387 
2025-01-16 17:22:06.566325: Pseudo dice [np.float32(0.6851), np.float32(0.3406)] 
2025-01-16 17:22:06.568831: Epoch time: 40.83 s 
2025-01-16 17:22:06.571337: Yayy! New best EMA pseudo Dice: 0.21879999339580536 
2025-01-16 17:22:07.317824:  
2025-01-16 17:22:07.318828: Epoch 8 
2025-01-16 17:22:07.323858: Current learning rate: 0.00971 
2025-01-16 17:22:48.116191: train_loss -0.4267 
2025-01-16 17:22:48.117190: val_loss -0.4071 
2025-01-16 17:22:48.122704: Pseudo dice [np.float32(0.697), np.float32(0.3135)] 
2025-01-16 17:22:48.126214: Epoch time: 40.8 s 
2025-01-16 17:22:48.128721: Yayy! New best EMA pseudo Dice: 0.2475000023841858 
2025-01-16 17:22:48.901003:  
2025-01-16 17:22:48.901506: Epoch 9 
2025-01-16 17:22:48.906519: Current learning rate: 0.00968 
2025-01-16 17:23:29.707075: train_loss -0.4299 
2025-01-16 17:23:29.707577: val_loss -0.4278 
2025-01-16 17:23:29.712590: Pseudo dice [np.float32(0.6441), np.float32(0.413)] 
2025-01-16 17:23:29.716100: Epoch time: 40.81 s 
2025-01-16 17:23:29.718608: Yayy! New best EMA pseudo Dice: 0.27559998631477356 
2025-01-16 17:23:30.441790:  
2025-01-16 17:23:30.441790: Epoch 10 
2025-01-16 17:23:30.446804: Current learning rate: 0.00964 
2025-01-16 17:24:11.241150: train_loss -0.4644 
2025-01-16 17:24:11.241150: val_loss -0.4859 
2025-01-16 17:24:11.246164: Pseudo dice [np.float32(0.6827), np.float32(0.4039)] 
2025-01-16 17:24:11.250173: Epoch time: 40.8 s 
2025-01-16 17:24:11.252679: Yayy! New best EMA pseudo Dice: 0.30230000615119934 
2025-01-16 17:24:12.026803:  
2025-01-16 17:24:12.027308: Epoch 11 
2025-01-16 17:24:12.032321: Current learning rate: 0.0096 
2025-01-16 17:24:52.816268: train_loss -0.4479 
2025-01-16 17:24:52.816780: val_loss -0.4521 
2025-01-16 17:24:52.821706: Pseudo dice [np.float32(0.6619), np.float32(0.4356)] 
2025-01-16 17:24:52.825232: Epoch time: 40.79 s 
2025-01-16 17:24:52.828470: Yayy! New best EMA pseudo Dice: 0.3269999921321869 
2025-01-16 17:24:53.611764:  
2025-01-16 17:24:53.612269: Epoch 12 
2025-01-16 17:24:53.617321: Current learning rate: 0.00957 
2025-01-16 17:25:34.413936: train_loss -0.4638 
2025-01-16 17:25:34.414459: val_loss -0.4622 
2025-01-16 17:25:34.419032: Pseudo dice [np.float32(0.7013), np.float32(0.3534)] 
2025-01-16 17:25:34.423160: Epoch time: 40.8 s 
2025-01-16 17:25:34.425695: Yayy! New best EMA pseudo Dice: 0.34700000286102295 
2025-01-16 17:25:35.334816:  
2025-01-16 17:25:35.335819: Epoch 13 
2025-01-16 17:25:35.340405: Current learning rate: 0.00953 
2025-01-16 17:26:16.132785: train_loss -0.4563 
2025-01-16 17:26:16.133787: val_loss -0.4801 
2025-01-16 17:26:16.138869: Pseudo dice [np.float32(0.6896), np.float32(0.4002)] 
2025-01-16 17:26:16.142348: Epoch time: 40.8 s 
2025-01-16 17:26:16.145859: Yayy! New best EMA pseudo Dice: 0.3668000102043152 
2025-01-16 17:26:16.916011:  
2025-01-16 17:26:16.916011: Epoch 14 
2025-01-16 17:26:16.921026: Current learning rate: 0.00949 
2025-01-16 17:26:57.727418: train_loss -0.5057 
2025-01-16 17:26:57.728454: val_loss -0.4846 
2025-01-16 17:26:57.734039: Pseudo dice [np.float32(0.7224), np.float32(0.3808)] 
2025-01-16 17:26:57.737567: Epoch time: 40.81 s 
2025-01-16 17:26:57.740595: Yayy! New best EMA pseudo Dice: 0.38530001044273376 
2025-01-16 17:26:58.530424:  
2025-01-16 17:26:58.531427: Epoch 15 
2025-01-16 17:26:58.535982: Current learning rate: 0.00946 
2025-01-16 17:27:39.329954: train_loss -0.5275 
2025-01-16 17:27:39.330458: val_loss -0.4893 
2025-01-16 17:27:39.336540: Pseudo dice [np.float32(0.7287), np.float32(0.3983)] 
2025-01-16 17:27:39.339079: Epoch time: 40.8 s 
2025-01-16 17:27:39.344119: Yayy! New best EMA pseudo Dice: 0.40310001373291016 
2025-01-16 17:27:40.138041:  
2025-01-16 17:27:40.138551: Epoch 16 
2025-01-16 17:27:40.143617: Current learning rate: 0.00942 
2025-01-16 17:28:20.942047: train_loss -0.4997 
2025-01-16 17:28:20.942552: val_loss -0.4886 
2025-01-16 17:28:20.948569: Pseudo dice [np.float32(0.6828), np.float32(0.4327)] 
2025-01-16 17:28:20.952579: Epoch time: 40.8 s 
2025-01-16 17:28:20.956090: Yayy! New best EMA pseudo Dice: 0.4185999929904938 
2025-01-16 17:28:21.751976:  
2025-01-16 17:28:21.751976: Epoch 17 
2025-01-16 17:28:21.756990: Current learning rate: 0.00939 
2025-01-16 17:29:02.549592: train_loss -0.523 
2025-01-16 17:29:02.550596: val_loss -0.4968 
2025-01-16 17:29:02.555119: Pseudo dice [np.float32(0.7248), np.float32(0.4699)] 
2025-01-16 17:29:02.559663: Epoch time: 40.8 s 
2025-01-16 17:29:02.562171: Yayy! New best EMA pseudo Dice: 0.43650001287460327 
2025-01-16 17:29:03.350103:  
2025-01-16 17:29:03.350606: Epoch 18 
2025-01-16 17:29:03.356136: Current learning rate: 0.00935 
2025-01-16 17:29:44.138786: train_loss -0.5461 
2025-01-16 17:29:44.139290: val_loss -0.4942 
2025-01-16 17:29:44.143808: Pseudo dice [np.float32(0.7471), np.float32(0.3777)] 
2025-01-16 17:29:44.148516: Epoch time: 40.79 s 
2025-01-16 17:29:44.153024: Yayy! New best EMA pseudo Dice: 0.4490000009536743 
2025-01-16 17:29:44.956886:  
2025-01-16 17:29:44.957890: Epoch 19 
2025-01-16 17:29:44.961925: Current learning rate: 0.00931 
2025-01-16 17:30:25.764319: train_loss -0.5875 
2025-01-16 17:30:25.764319: val_loss -0.5607 
2025-01-16 17:30:25.770435: Pseudo dice [np.float32(0.7591), np.float32(0.5201)] 
2025-01-16 17:30:25.772941: Epoch time: 40.81 s 
2025-01-16 17:30:25.776451: Yayy! New best EMA pseudo Dice: 0.46810001134872437 
2025-01-16 17:30:26.587964:  
2025-01-16 17:30:26.587964: Epoch 20 
2025-01-16 17:30:26.593030: Current learning rate: 0.00928 
2025-01-16 17:31:07.395422: train_loss -0.5946 
2025-01-16 17:31:07.395931: val_loss -0.5303 
2025-01-16 17:31:07.401490: Pseudo dice [np.float32(0.712), np.float32(0.483)] 
2025-01-16 17:31:07.404533: Epoch time: 40.81 s 
2025-01-16 17:31:07.408576: Yayy! New best EMA pseudo Dice: 0.48100000619888306 
2025-01-16 17:31:08.327950:  
2025-01-16 17:31:08.327950: Epoch 21 
2025-01-16 17:31:08.333522: Current learning rate: 0.00924 
2025-01-16 17:31:49.136312: train_loss -0.5785 
2025-01-16 17:31:49.137857: val_loss -0.4428 
2025-01-16 17:31:49.143394: Pseudo dice [np.float32(0.7395), np.float32(0.3124)] 
2025-01-16 17:31:49.146903: Epoch time: 40.81 s 
2025-01-16 17:31:49.150409: Yayy! New best EMA pseudo Dice: 0.4855000078678131 
2025-01-16 17:31:49.928330:  
2025-01-16 17:31:49.928330: Epoch 22 
2025-01-16 17:31:49.933419: Current learning rate: 0.0092 
2025-01-16 17:32:30.737816: train_loss -0.5837 
2025-01-16 17:32:30.739336: val_loss -0.4803 
2025-01-16 17:32:30.745434: Pseudo dice [np.float32(0.691), np.float32(0.4612)] 
2025-01-16 17:32:30.748498: Epoch time: 40.81 s 
2025-01-16 17:32:30.751522: Yayy! New best EMA pseudo Dice: 0.49459999799728394 
2025-01-16 17:32:31.499177:  
2025-01-16 17:32:31.499177: Epoch 23 
2025-01-16 17:32:31.504189: Current learning rate: 0.00917 
2025-01-16 17:33:12.318472: train_loss -0.5728 
2025-01-16 17:33:12.318472: val_loss -0.5245 
2025-01-16 17:33:12.323484: Pseudo dice [np.float32(0.7546), np.float32(0.4062)] 
2025-01-16 17:33:12.325991: Epoch time: 40.82 s 
2025-01-16 17:33:12.329499: Yayy! New best EMA pseudo Dice: 0.5031999945640564 
2025-01-16 17:33:13.073001:  
2025-01-16 17:33:13.074006: Epoch 24 
2025-01-16 17:33:13.079543: Current learning rate: 0.00913 
2025-01-16 17:33:53.895062: train_loss -0.571 
2025-01-16 17:33:53.895062: val_loss -0.5229 
2025-01-16 17:33:53.900211: Pseudo dice [np.float32(0.7734), np.float32(0.3779)] 
2025-01-16 17:33:53.904256: Epoch time: 40.82 s 
2025-01-16 17:33:53.909316: Yayy! New best EMA pseudo Dice: 0.5103999972343445 
2025-01-16 17:33:54.690113:  
2025-01-16 17:33:54.690113: Epoch 25 
2025-01-16 17:33:54.696757: Current learning rate: 0.0091 
2025-01-16 17:34:35.520641: train_loss -0.5908 
2025-01-16 17:34:35.521146: val_loss -0.5002 
2025-01-16 17:34:35.527162: Pseudo dice [np.float32(0.7297), np.float32(0.3939)] 
2025-01-16 17:34:35.530668: Epoch time: 40.83 s 
2025-01-16 17:34:35.533681: Yayy! New best EMA pseudo Dice: 0.5156000256538391 
2025-01-16 17:34:36.328031:  
2025-01-16 17:34:36.328031: Epoch 26 
2025-01-16 17:34:36.334096: Current learning rate: 0.00906 
2025-01-16 17:35:17.148645: train_loss -0.6127 
2025-01-16 17:35:17.148645: val_loss -0.4921 
2025-01-16 17:35:17.155739: Pseudo dice [np.float32(0.7384), np.float32(0.3635)] 
2025-01-16 17:35:17.159251: Epoch time: 40.82 s 
2025-01-16 17:35:17.161758: Yayy! New best EMA pseudo Dice: 0.51910001039505 
2025-01-16 17:35:17.906448:  
2025-01-16 17:35:17.906448: Epoch 27 
2025-01-16 17:35:17.911480: Current learning rate: 0.00902 
2025-01-16 17:35:58.720281: train_loss -0.5978 
2025-01-16 17:35:58.720785: val_loss -0.4727 
2025-01-16 17:35:58.726878: Pseudo dice [np.float32(0.7394), np.float32(0.4045)] 
2025-01-16 17:35:58.730384: Epoch time: 40.81 s 
2025-01-16 17:35:58.733394: Yayy! New best EMA pseudo Dice: 0.524399995803833 
2025-01-16 17:35:59.515758:  
2025-01-16 17:35:59.515758: Epoch 28 
2025-01-16 17:35:59.521777: Current learning rate: 0.00899 
2025-01-16 17:36:40.331559: train_loss -0.6183 
2025-01-16 17:36:40.331559: val_loss -0.5404 
2025-01-16 17:36:40.338153: Pseudo dice [np.float32(0.7487), np.float32(0.4307)] 
2025-01-16 17:36:40.341177: Epoch time: 40.82 s 
2025-01-16 17:36:40.344226: Yayy! New best EMA pseudo Dice: 0.5309000015258789 
2025-01-16 17:36:41.271485:  
2025-01-16 17:36:41.272485: Epoch 29 
2025-01-16 17:36:41.278077: Current learning rate: 0.00895 
2025-01-16 17:37:22.079782: train_loss -0.6031 
2025-01-16 17:37:22.080786: val_loss -0.5206 
2025-01-16 17:37:22.086352: Pseudo dice [np.float32(0.7544), np.float32(0.4124)] 
2025-01-16 17:37:22.089875: Epoch time: 40.81 s 
2025-01-16 17:37:22.092895: Yayy! New best EMA pseudo Dice: 0.5361999869346619 
2025-01-16 17:37:22.865611:  
2025-01-16 17:37:22.865611: Epoch 30 
2025-01-16 17:37:22.872162: Current learning rate: 0.00891 
2025-01-16 17:38:03.679777: train_loss -0.6242 
2025-01-16 17:38:03.680310: val_loss -0.5294 
2025-01-16 17:38:03.685945: Pseudo dice [np.float32(0.7315), np.float32(0.4415)] 
2025-01-16 17:38:03.689022: Epoch time: 40.82 s 
2025-01-16 17:38:03.692107: Yayy! New best EMA pseudo Dice: 0.5411999821662903 
2025-01-16 17:38:04.477775:  
2025-01-16 17:38:04.478774: Epoch 31 
2025-01-16 17:38:04.484360: Current learning rate: 0.00888 
2025-01-16 17:38:45.299301: train_loss -0.6062 
2025-01-16 17:38:45.299811: val_loss -0.5038 
2025-01-16 17:38:45.304907: Pseudo dice [np.float32(0.7483), np.float32(0.3592)] 
2025-01-16 17:38:45.309011: Epoch time: 40.82 s 
2025-01-16 17:38:45.312041: Yayy! New best EMA pseudo Dice: 0.5424000024795532 
2025-01-16 17:38:46.106786:  
2025-01-16 17:38:46.106786: Epoch 32 
2025-01-16 17:38:46.111801: Current learning rate: 0.00884 
2025-01-16 17:39:26.907362: train_loss -0.607 
2025-01-16 17:39:26.907875: val_loss -0.4835 
2025-01-16 17:39:26.913048: Pseudo dice [np.float32(0.7363), np.float32(0.3486)] 
2025-01-16 17:39:26.917081: Epoch time: 40.8 s 
2025-01-16 17:39:26.920636: Yayy! New best EMA pseudo Dice: 0.5424000024795532 
2025-01-16 17:39:27.710692:  
2025-01-16 17:39:27.711692: Epoch 33 
2025-01-16 17:39:27.717322: Current learning rate: 0.0088 
2025-01-16 17:40:08.516340: train_loss -0.6359 
2025-01-16 17:40:08.517344: val_loss -0.4921 
2025-01-16 17:40:08.523037: Pseudo dice [np.float32(0.753), np.float32(0.3284)] 
2025-01-16 17:40:08.526074: Epoch time: 40.81 s 
2025-01-16 17:40:09.087915:  
2025-01-16 17:40:09.087915: Epoch 34 
2025-01-16 17:40:09.093514: Current learning rate: 0.00877 
2025-01-16 17:40:49.876622: train_loss -0.6229 
2025-01-16 17:40:49.877135: val_loss -0.5163 
2025-01-16 17:40:49.883285: Pseudo dice [np.float32(0.7721), np.float32(0.3627)] 
2025-01-16 17:40:49.886328: Epoch time: 40.79 s 
2025-01-16 17:40:49.889363: Yayy! New best EMA pseudo Dice: 0.5447999835014343 
2025-01-16 17:40:50.688628:  
2025-01-16 17:40:50.689631: Epoch 35 
2025-01-16 17:40:50.694679: Current learning rate: 0.00873 
2025-01-16 17:41:31.503892: train_loss -0.6502 
2025-01-16 17:41:31.504911: val_loss -0.5029 
2025-01-16 17:41:31.509960: Pseudo dice [np.float32(0.7557), np.float32(0.3459)] 
2025-01-16 17:41:31.513993: Epoch time: 40.82 s 
2025-01-16 17:41:31.517537: Yayy! New best EMA pseudo Dice: 0.5454000234603882 
2025-01-16 17:41:32.313196:  
2025-01-16 17:41:32.314199: Epoch 36 
2025-01-16 17:41:32.319736: Current learning rate: 0.00869 
2025-01-16 17:42:13.098738: train_loss -0.6506 
2025-01-16 17:42:13.099245: val_loss -0.4956 
2025-01-16 17:42:13.104293: Pseudo dice [np.float32(0.7702), np.float32(0.3678)] 
2025-01-16 17:42:13.107819: Epoch time: 40.79 s 
2025-01-16 17:42:13.111358: Yayy! New best EMA pseudo Dice: 0.5476999878883362 
2025-01-16 17:42:14.077512:  
2025-01-16 17:42:14.078516: Epoch 37 
2025-01-16 17:42:14.084046: Current learning rate: 0.00866 
2025-01-16 17:42:54.863652: train_loss -0.661 
2025-01-16 17:42:54.864168: val_loss -0.5652 
2025-01-16 17:42:54.869729: Pseudo dice [np.float32(0.7903), np.float32(0.4762)] 
2025-01-16 17:42:54.872759: Epoch time: 40.79 s 
2025-01-16 17:42:54.876767: Yayy! New best EMA pseudo Dice: 0.5562999844551086 
2025-01-16 17:42:55.682479:  
2025-01-16 17:42:55.682981: Epoch 38 
2025-01-16 17:42:55.686490: Current learning rate: 0.00862 
2025-01-16 17:43:36.493448: train_loss -0.653 
2025-01-16 17:43:36.494962: val_loss -0.546 
2025-01-16 17:43:36.500541: Pseudo dice [np.float32(0.7634), np.float32(0.4424)] 
2025-01-16 17:43:36.504563: Epoch time: 40.81 s 
2025-01-16 17:43:36.508571: Yayy! New best EMA pseudo Dice: 0.5609999895095825 
2025-01-16 17:43:37.307531:  
2025-01-16 17:43:37.308033: Epoch 39 
2025-01-16 17:43:37.314048: Current learning rate: 0.00858 
2025-01-16 17:44:18.098686: train_loss -0.655 
2025-01-16 17:44:18.099197: val_loss -0.5333 
2025-01-16 17:44:18.104253: Pseudo dice [np.float32(0.7632), np.float32(0.466)] 
2025-01-16 17:44:18.106791: Epoch time: 40.79 s 
2025-01-16 17:44:18.110848: Yayy! New best EMA pseudo Dice: 0.5662999749183655 
2025-01-16 17:44:18.910318:  
2025-01-16 17:44:18.910318: Epoch 40 
2025-01-16 17:44:18.915847: Current learning rate: 0.00855 
2025-01-16 17:44:59.712148: train_loss -0.6585 
2025-01-16 17:44:59.712656: val_loss -0.5538 
2025-01-16 17:44:59.718716: Pseudo dice [np.float32(0.7602), np.float32(0.4591)] 
2025-01-16 17:44:59.721781: Epoch time: 40.8 s 
2025-01-16 17:44:59.725293: Yayy! New best EMA pseudo Dice: 0.5705999732017517 
2025-01-16 17:45:00.541229:  
2025-01-16 17:45:00.541229: Epoch 41 
2025-01-16 17:45:00.547248: Current learning rate: 0.00851 
2025-01-16 17:45:41.340032: train_loss -0.6714 
2025-01-16 17:45:41.340032: val_loss -0.537 
2025-01-16 17:45:41.346143: Pseudo dice [np.float32(0.7811), np.float32(0.4051)] 
2025-01-16 17:45:41.348704: Epoch time: 40.8 s 
2025-01-16 17:45:41.352339: Yayy! New best EMA pseudo Dice: 0.5728999972343445 
2025-01-16 17:45:42.133118:  
2025-01-16 17:45:42.134123: Epoch 42 
2025-01-16 17:45:42.138674: Current learning rate: 0.00847 
2025-01-16 17:46:22.947381: train_loss -0.6804 
2025-01-16 17:46:22.947381: val_loss -0.5251 
2025-01-16 17:46:22.952924: Pseudo dice [np.float32(0.7884), np.float32(0.4112)] 
2025-01-16 17:46:22.956566: Epoch time: 40.81 s 
2025-01-16 17:46:22.960094: Yayy! New best EMA pseudo Dice: 0.5756000280380249 
2025-01-16 17:46:23.747117:  
2025-01-16 17:46:23.748123: Epoch 43 
2025-01-16 17:46:23.752677: Current learning rate: 0.00844 
2025-01-16 17:47:04.566648: train_loss -0.6966 
2025-01-16 17:47:04.567213: val_loss -0.5798 
2025-01-16 17:47:04.571778: Pseudo dice [np.float32(0.7588), np.float32(0.5124)] 
2025-01-16 17:47:04.576334: Epoch time: 40.82 s 
2025-01-16 17:47:04.579397: Yayy! New best EMA pseudo Dice: 0.58160001039505 
2025-01-16 17:47:05.356862:  
2025-01-16 17:47:05.357862: Epoch 44 
2025-01-16 17:47:05.363447: Current learning rate: 0.0084 
2025-01-16 17:47:46.156885: train_loss -0.6772 
2025-01-16 17:47:46.157397: val_loss -0.5048 
2025-01-16 17:47:46.163975: Pseudo dice [np.float32(0.7631), np.float32(0.3482)] 
2025-01-16 17:47:46.169061: Epoch time: 40.8 s 
2025-01-16 17:47:46.874068:  
2025-01-16 17:47:46.874068: Epoch 45 
2025-01-16 17:47:46.880111: Current learning rate: 0.00836 
2025-01-16 17:48:27.676293: train_loss -0.6905 
2025-01-16 17:48:27.677297: val_loss -0.5509 
2025-01-16 17:48:27.683864: Pseudo dice [np.float32(0.7696), np.float32(0.494)] 
2025-01-16 17:48:27.687892: Epoch time: 40.8 s 
2025-01-16 17:48:27.691432: Yayy! New best EMA pseudo Dice: 0.5842999815940857 
2025-01-16 17:48:28.446012:  
2025-01-16 17:48:28.446012: Epoch 46 
2025-01-16 17:48:28.452538: Current learning rate: 0.00833 
2025-01-16 17:49:09.235643: train_loss -0.7072 
2025-01-16 17:49:09.236146: val_loss -0.53 
2025-01-16 17:49:09.241699: Pseudo dice [np.float32(0.7744), np.float32(0.4683)] 
2025-01-16 17:49:09.245733: Epoch time: 40.79 s 
2025-01-16 17:49:09.249266: Yayy! New best EMA pseudo Dice: 0.5879999995231628 
2025-01-16 17:49:10.028170:  
2025-01-16 17:49:10.029173: Epoch 47 
2025-01-16 17:49:10.035234: Current learning rate: 0.00829 
2025-01-16 17:49:50.828955: train_loss -0.6685 
2025-01-16 17:49:50.829473: val_loss -0.4429 
2025-01-16 17:49:50.835541: Pseudo dice [np.float32(0.7563), np.float32(0.1905)] 
2025-01-16 17:49:50.839070: Epoch time: 40.8 s 
2025-01-16 17:49:51.388871:  
2025-01-16 17:49:51.388871: Epoch 48 
2025-01-16 17:49:51.394912: Current learning rate: 0.00825 
2025-01-16 17:50:32.185291: train_loss -0.6788 
2025-01-16 17:50:32.186294: val_loss -0.5229 
2025-01-16 17:50:32.192406: Pseudo dice [np.float32(0.7596), np.float32(0.4284)] 
2025-01-16 17:50:32.195468: Epoch time: 40.8 s 
2025-01-16 17:50:32.755473:  
2025-01-16 17:50:32.755473: Epoch 49 
2025-01-16 17:50:32.761025: Current learning rate: 0.00822 
2025-01-16 17:51:13.545260: train_loss -0.704 
2025-01-16 17:51:13.545766: val_loss -0.5301 
2025-01-16 17:51:13.550325: Pseudo dice [np.float32(0.7837), np.float32(0.3732)] 
2025-01-16 17:51:13.553918: Epoch time: 40.79 s 
2025-01-16 17:51:14.289037:  
2025-01-16 17:51:14.289037: Epoch 50 
2025-01-16 17:51:14.294052: Current learning rate: 0.00818 
2025-01-16 17:51:55.089473: train_loss -0.683 
2025-01-16 17:51:55.089473: val_loss -0.5644 
2025-01-16 17:51:55.095491: Pseudo dice [np.float32(0.7677), np.float32(0.4882)] 
2025-01-16 17:51:55.099500: Epoch time: 40.8 s 
2025-01-16 17:51:55.659388:  
2025-01-16 17:51:55.659388: Epoch 51 
2025-01-16 17:51:55.662923: Current learning rate: 0.00814 
2025-01-16 17:52:36.441116: train_loss -0.7205 
2025-01-16 17:52:36.441622: val_loss -0.5253 
2025-01-16 17:52:36.448323: Pseudo dice [np.float32(0.7792), np.float32(0.3653)] 
2025-01-16 17:52:36.452402: Epoch time: 40.78 s 
2025-01-16 17:52:37.005919:  
2025-01-16 17:52:37.005919: Epoch 52 
2025-01-16 17:52:37.011462: Current learning rate: 0.00811 
2025-01-16 17:53:17.801264: train_loss -0.7051 
2025-01-16 17:53:17.801264: val_loss -0.483 
2025-01-16 17:53:17.808395: Pseudo dice [np.float32(0.7691), np.float32(0.3268)] 
2025-01-16 17:53:17.811443: Epoch time: 40.8 s 
2025-01-16 17:53:18.517031:  
2025-01-16 17:53:18.518035: Epoch 53 
2025-01-16 17:53:18.522584: Current learning rate: 0.00807 
2025-01-16 17:53:59.319587: train_loss -0.7028 
2025-01-16 17:53:59.320090: val_loss -0.5239 
2025-01-16 17:53:59.326107: Pseudo dice [np.float32(0.764), np.float32(0.4003)] 
2025-01-16 17:53:59.330118: Epoch time: 40.8 s 
2025-01-16 17:53:59.881286:  
2025-01-16 17:53:59.881286: Epoch 54 
2025-01-16 17:53:59.886361: Current learning rate: 0.00803 
2025-01-16 17:54:40.669387: train_loss -0.7023 
2025-01-16 17:54:40.670891: val_loss -0.5136 
2025-01-16 17:54:40.676916: Pseudo dice [np.float32(0.7558), np.float32(0.2847)] 
2025-01-16 17:54:40.680189: Epoch time: 40.79 s 
2025-01-16 17:54:41.233688:  
2025-01-16 17:54:41.234688: Epoch 55 
2025-01-16 17:54:41.240260: Current learning rate: 0.008 
2025-01-16 17:55:22.021168: train_loss -0.7078 
2025-01-16 17:55:22.021687: val_loss -0.5009 
2025-01-16 17:55:22.027784: Pseudo dice [np.float32(0.7835), np.float32(0.3354)] 
2025-01-16 17:55:22.030291: Epoch time: 40.79 s 
2025-01-16 17:55:22.583976:  
2025-01-16 17:55:22.584478: Epoch 56 
2025-01-16 17:55:22.590103: Current learning rate: 0.00796 
2025-01-16 17:56:03.400928: train_loss -0.7043 
2025-01-16 17:56:03.400928: val_loss -0.5033 
2025-01-16 17:56:03.407489: Pseudo dice [np.float32(0.7359), np.float32(0.34)] 
2025-01-16 17:56:03.411027: Epoch time: 40.82 s 
2025-01-16 17:56:03.967201:  
2025-01-16 17:56:03.967201: Epoch 57 
2025-01-16 17:56:03.973820: Current learning rate: 0.00792 
2025-01-16 17:56:44.766162: train_loss -0.737 
2025-01-16 17:56:44.766664: val_loss -0.4883 
2025-01-16 17:56:44.771793: Pseudo dice [np.float32(0.7745), np.float32(0.3103)] 
2025-01-16 17:56:44.775559: Epoch time: 40.8 s 
2025-01-16 17:56:45.325437:  
2025-01-16 17:56:45.326436: Epoch 58 
2025-01-16 17:56:45.332041: Current learning rate: 0.00789 
2025-01-16 17:57:26.123993: train_loss -0.7201 
2025-01-16 17:57:26.124512: val_loss -0.5305 
2025-01-16 17:57:26.130082: Pseudo dice [np.float32(0.7887), np.float32(0.4226)] 
2025-01-16 17:57:26.133599: Epoch time: 40.8 s 
2025-01-16 17:57:26.682747:  
2025-01-16 17:57:26.683748: Epoch 59 
2025-01-16 17:57:26.688762: Current learning rate: 0.00785 
2025-01-16 17:58:07.496411: train_loss -0.7241 
2025-01-16 17:58:07.496913: val_loss -0.5128 
2025-01-16 17:58:07.501930: Pseudo dice [np.float32(0.755), np.float32(0.366)] 
2025-01-16 17:58:07.505448: Epoch time: 40.81 s 
2025-01-16 17:58:08.065495:  
2025-01-16 17:58:08.066499: Epoch 60 
2025-01-16 17:58:08.071549: Current learning rate: 0.00781 
2025-01-16 17:58:48.859815: train_loss -0.7442 
2025-01-16 17:58:48.860317: val_loss -0.5171 
2025-01-16 17:58:48.865331: Pseudo dice [np.float32(0.7647), np.float32(0.394)] 
2025-01-16 17:58:48.867838: Epoch time: 40.79 s 
2025-01-16 17:58:49.582123:  
2025-01-16 17:58:49.582123: Epoch 61 
2025-01-16 17:58:49.588243: Current learning rate: 0.00777 
2025-01-16 17:59:30.386994: train_loss -0.7019 
2025-01-16 17:59:30.387998: val_loss -0.5256 
2025-01-16 17:59:30.393634: Pseudo dice [np.float32(0.7589), np.float32(0.4172)] 
2025-01-16 17:59:30.397647: Epoch time: 40.8 s 
2025-01-16 17:59:30.951328:  
2025-01-16 17:59:30.951833: Epoch 62 
2025-01-16 17:59:30.956848: Current learning rate: 0.00774 
2025-01-16 18:00:11.757732: train_loss -0.682 
2025-01-16 18:00:11.759238: val_loss -0.5311 
2025-01-16 18:00:11.764306: Pseudo dice [np.float32(0.7634), np.float32(0.4277)] 
2025-01-16 18:00:11.766813: Epoch time: 40.81 s 
2025-01-16 18:00:12.336623:  
2025-01-16 18:00:12.336623: Epoch 63 
2025-01-16 18:00:12.342693: Current learning rate: 0.0077 
2025-01-16 18:00:53.151408: train_loss -0.7157 
2025-01-16 18:00:53.151408: val_loss -0.535 
2025-01-16 18:00:53.156476: Pseudo dice [np.float32(0.7682), np.float32(0.475)] 
2025-01-16 18:00:53.160019: Epoch time: 40.81 s 
2025-01-16 18:00:53.715624:  
2025-01-16 18:00:53.716129: Epoch 64 
2025-01-16 18:00:53.721144: Current learning rate: 0.00766 
2025-01-16 18:01:34.520614: train_loss -0.7296 
2025-01-16 18:01:34.521126: val_loss -0.4946 
2025-01-16 18:01:34.527204: Pseudo dice [np.float32(0.7768), np.float32(0.3467)] 
2025-01-16 18:01:34.530233: Epoch time: 40.81 s 
2025-01-16 18:01:35.090218:  
2025-01-16 18:01:35.090722: Epoch 65 
2025-01-16 18:01:35.095736: Current learning rate: 0.00763 
2025-01-16 18:02:15.901749: train_loss -0.7232 
2025-01-16 18:02:15.901749: val_loss -0.5323 
2025-01-16 18:02:15.907904: Pseudo dice [np.float32(0.7707), np.float32(0.4501)] 
2025-01-16 18:02:15.910431: Epoch time: 40.81 s 
2025-01-16 18:02:16.469439:  
2025-01-16 18:02:16.470440: Epoch 66 
2025-01-16 18:02:16.475998: Current learning rate: 0.00759 
2025-01-16 18:02:57.289426: train_loss -0.715 
2025-01-16 18:02:57.289943: val_loss -0.5482 
2025-01-16 18:02:57.296046: Pseudo dice [np.float32(0.781), np.float32(0.4999)] 
2025-01-16 18:02:57.300091: Epoch time: 40.82 s 
2025-01-16 18:02:57.865496:  
2025-01-16 18:02:57.866500: Epoch 67 
2025-01-16 18:02:57.871055: Current learning rate: 0.00755 
2025-01-16 18:03:38.676711: train_loss -0.7361 
2025-01-16 18:03:38.676711: val_loss -0.5541 
2025-01-16 18:03:38.682728: Pseudo dice [np.float32(0.7741), np.float32(0.4572)] 
2025-01-16 18:03:38.685233: Epoch time: 40.81 s 
2025-01-16 18:03:38.687740: Yayy! New best EMA pseudo Dice: 0.5893999934196472 
2025-01-16 18:03:39.499961:  
2025-01-16 18:03:39.500958: Epoch 68 
2025-01-16 18:03:39.506474: Current learning rate: 0.00751 
2025-01-16 18:04:20.310092: train_loss -0.7453 
2025-01-16 18:04:20.310092: val_loss -0.5295 
2025-01-16 18:04:20.315110: Pseudo dice [np.float32(0.7955), np.float32(0.4274)] 
2025-01-16 18:04:20.318617: Epoch time: 40.81 s 
2025-01-16 18:04:20.321626: Yayy! New best EMA pseudo Dice: 0.5916000008583069 
2025-01-16 18:04:21.257705:  
2025-01-16 18:04:21.258708: Epoch 69 
2025-01-16 18:04:21.262736: Current learning rate: 0.00748 
2025-01-16 18:05:02.056613: train_loss -0.7411 
2025-01-16 18:05:02.057127: val_loss -0.5219 
2025-01-16 18:05:02.062739: Pseudo dice [np.float32(0.7452), np.float32(0.4819)] 
2025-01-16 18:05:02.065280: Epoch time: 40.8 s 
2025-01-16 18:05:02.067817: Yayy! New best EMA pseudo Dice: 0.5938000082969666 
2025-01-16 18:05:02.837484:  
2025-01-16 18:05:02.837987: Epoch 70 
2025-01-16 18:05:02.843023: Current learning rate: 0.00744 
2025-01-16 18:05:43.617702: train_loss -0.7483 
2025-01-16 18:05:43.619208: val_loss -0.5088 
2025-01-16 18:05:43.623750: Pseudo dice [np.float32(0.7485), np.float32(0.4599)] 
2025-01-16 18:05:43.627264: Epoch time: 40.78 s 
2025-01-16 18:05:43.631361: Yayy! New best EMA pseudo Dice: 0.5947999954223633 
2025-01-16 18:05:44.437985:  
2025-01-16 18:05:44.438988: Epoch 71 
2025-01-16 18:05:44.444026: Current learning rate: 0.0074 
2025-01-16 18:06:25.243910: train_loss -0.7719 
2025-01-16 18:06:25.244413: val_loss -0.5513 
2025-01-16 18:06:25.249999: Pseudo dice [np.float32(0.7804), np.float32(0.486)] 
2025-01-16 18:06:25.253023: Epoch time: 40.81 s 
2025-01-16 18:06:25.255041: Yayy! New best EMA pseudo Dice: 0.5986999869346619 
2025-01-16 18:06:26.025218:  
2025-01-16 18:06:26.025218: Epoch 72 
2025-01-16 18:06:26.030262: Current learning rate: 0.00737 
2025-01-16 18:07:06.806466: train_loss -0.7692 
2025-01-16 18:07:06.806969: val_loss -0.5603 
2025-01-16 18:07:06.812990: Pseudo dice [np.float32(0.7977), np.float32(0.457)] 
2025-01-16 18:07:06.816504: Epoch time: 40.78 s 
2025-01-16 18:07:06.819516: Yayy! New best EMA pseudo Dice: 0.6014999747276306 
2025-01-16 18:07:07.578694:  
2025-01-16 18:07:07.579697: Epoch 73 
2025-01-16 18:07:07.585273: Current learning rate: 0.00733 
2025-01-16 18:07:48.388917: train_loss -0.7714 
2025-01-16 18:07:48.389431: val_loss -0.5358 
2025-01-16 18:07:48.395059: Pseudo dice [np.float32(0.7851), np.float32(0.4369)] 
2025-01-16 18:07:48.398118: Epoch time: 40.81 s 
2025-01-16 18:07:48.401171: Yayy! New best EMA pseudo Dice: 0.6025000214576721 
2025-01-16 18:07:49.210736:  
2025-01-16 18:07:49.210736: Epoch 74 
2025-01-16 18:07:49.215323: Current learning rate: 0.00729 
2025-01-16 18:08:30.011008: train_loss -0.7646 
2025-01-16 18:08:30.011008: val_loss -0.5308 
2025-01-16 18:08:30.017589: Pseudo dice [np.float32(0.7789), np.float32(0.4181)] 
2025-01-16 18:08:30.020599: Epoch time: 40.8 s 
2025-01-16 18:08:30.583955:  
2025-01-16 18:08:30.583955: Epoch 75 
2025-01-16 18:08:30.588001: Current learning rate: 0.00725 
2025-01-16 18:09:11.380084: train_loss -0.7585 
2025-01-16 18:09:11.380084: val_loss -0.5337 
2025-01-16 18:09:11.386099: Pseudo dice [np.float32(0.7596), np.float32(0.4115)] 
2025-01-16 18:09:11.389606: Epoch time: 40.8 s 
2025-01-16 18:09:11.972257:  
2025-01-16 18:09:11.972257: Epoch 76 
2025-01-16 18:09:11.977819: Current learning rate: 0.00722 
2025-01-16 18:09:52.773848: train_loss -0.7462 
2025-01-16 18:09:52.774850: val_loss -0.5744 
2025-01-16 18:09:52.780469: Pseudo dice [np.float32(0.788), np.float32(0.4742)] 
2025-01-16 18:09:52.783003: Epoch time: 40.8 s 
2025-01-16 18:09:52.786513: Yayy! New best EMA pseudo Dice: 0.6035000085830688 
2025-01-16 18:09:53.734585:  
2025-01-16 18:09:53.735586: Epoch 77 
2025-01-16 18:09:53.741235: Current learning rate: 0.00718 
2025-01-16 18:10:34.534248: train_loss -0.7482 
2025-01-16 18:10:34.535761: val_loss -0.5764 
2025-01-16 18:10:34.541300: Pseudo dice [np.float32(0.7866), np.float32(0.5401)] 
2025-01-16 18:10:34.543806: Epoch time: 40.8 s 
2025-01-16 18:10:34.547315: Yayy! New best EMA pseudo Dice: 0.609499990940094 
2025-01-16 18:10:35.346567:  
2025-01-16 18:10:35.346567: Epoch 78 
2025-01-16 18:10:35.352124: Current learning rate: 0.00714 
2025-01-16 18:11:16.131382: train_loss -0.7767 
2025-01-16 18:11:16.132407: val_loss -0.4804 
2025-01-16 18:11:16.137985: Pseudo dice [np.float32(0.7687), np.float32(0.4462)] 
2025-01-16 18:11:16.140527: Epoch time: 40.79 s 
2025-01-16 18:11:16.716427:  
2025-01-16 18:11:16.716944: Epoch 79 
2025-01-16 18:11:16.721957: Current learning rate: 0.0071 
2025-01-16 18:11:57.481353: train_loss -0.7839 
2025-01-16 18:11:57.482358: val_loss -0.521 
2025-01-16 18:11:57.487566: Pseudo dice [np.float32(0.7763), np.float32(0.4264)] 
2025-01-16 18:11:57.491619: Epoch time: 40.77 s 
2025-01-16 18:11:58.085012:  
2025-01-16 18:11:58.085012: Epoch 80 
2025-01-16 18:11:58.090024: Current learning rate: 0.00707 
2025-01-16 18:12:38.858369: train_loss -0.77 
2025-01-16 18:12:38.858369: val_loss -0.5705 
2025-01-16 18:12:38.866277: Pseudo dice [np.float32(0.7834), np.float32(0.455)] 
2025-01-16 18:12:38.868784: Epoch time: 40.77 s 
2025-01-16 18:12:38.872289: Yayy! New best EMA pseudo Dice: 0.6096000075340271 
2025-01-16 18:12:39.677509:  
2025-01-16 18:12:39.678515: Epoch 81 
2025-01-16 18:12:39.683543: Current learning rate: 0.00703 
2025-01-16 18:13:20.488810: train_loss -0.787 
2025-01-16 18:13:20.488810: val_loss -0.5293 
2025-01-16 18:13:20.495325: Pseudo dice [np.float32(0.7855), np.float32(0.4881)] 
2025-01-16 18:13:20.497830: Epoch time: 40.81 s 
2025-01-16 18:13:20.501341: Yayy! New best EMA pseudo Dice: 0.6122999787330627 
2025-01-16 18:13:21.286849:  
2025-01-16 18:13:21.287848: Epoch 82 
2025-01-16 18:13:21.292912: Current learning rate: 0.00699 
2025-01-16 18:14:02.081442: train_loss -0.7783 
2025-01-16 18:14:02.081442: val_loss -0.5519 
2025-01-16 18:14:02.087458: Pseudo dice [np.float32(0.7824), np.float32(0.4439)] 
2025-01-16 18:14:02.089969: Epoch time: 40.79 s 
2025-01-16 18:14:02.093978: Yayy! New best EMA pseudo Dice: 0.6123999953269958 
2025-01-16 18:14:02.858382:  
2025-01-16 18:14:02.858382: Epoch 83 
2025-01-16 18:14:02.864521: Current learning rate: 0.00696 
2025-01-16 18:14:43.669114: train_loss -0.7759 
2025-01-16 18:14:43.669625: val_loss -0.4769 
2025-01-16 18:14:43.675184: Pseudo dice [np.float32(0.7599), np.float32(0.3262)] 
2025-01-16 18:14:43.677706: Epoch time: 40.81 s 
2025-01-16 18:14:44.218090:  
2025-01-16 18:14:44.218090: Epoch 84 
2025-01-16 18:14:44.223103: Current learning rate: 0.00692 
2025-01-16 18:15:25.014008: train_loss -0.7735 
2025-01-16 18:15:25.014008: val_loss -0.5281 
2025-01-16 18:15:25.020028: Pseudo dice [np.float32(0.7725), np.float32(0.4686)] 
2025-01-16 18:15:25.022535: Epoch time: 40.8 s 
2025-01-16 18:15:25.575943:  
2025-01-16 18:15:25.575943: Epoch 85 
2025-01-16 18:15:25.581499: Current learning rate: 0.00688 
2025-01-16 18:16:06.379782: train_loss -0.7849 
2025-01-16 18:16:06.380789: val_loss -0.5504 
2025-01-16 18:16:06.385800: Pseudo dice [np.float32(0.7763), np.float32(0.4577)] 
2025-01-16 18:16:06.388310: Epoch time: 40.8 s 
2025-01-16 18:16:07.085595:  
2025-01-16 18:16:07.086602: Epoch 86 
2025-01-16 18:16:07.091153: Current learning rate: 0.00684 
2025-01-16 18:16:47.881495: train_loss -0.7884 
2025-01-16 18:16:47.881999: val_loss -0.5669 
2025-01-16 18:16:47.887104: Pseudo dice [np.float32(0.7734), np.float32(0.5475)] 
2025-01-16 18:16:47.890672: Epoch time: 40.8 s 
2025-01-16 18:16:47.894287: Yayy! New best EMA pseudo Dice: 0.6132000088691711 
2025-01-16 18:16:48.665152:  
2025-01-16 18:16:48.665152: Epoch 87 
2025-01-16 18:16:48.670714: Current learning rate: 0.0068 
2025-01-16 18:17:29.471457: train_loss -0.7972 
2025-01-16 18:17:29.471970: val_loss -0.5137 
2025-01-16 18:17:29.476561: Pseudo dice [np.float32(0.7688), np.float32(0.506)] 
2025-01-16 18:17:29.480086: Epoch time: 40.81 s 
2025-01-16 18:17:29.482634: Yayy! New best EMA pseudo Dice: 0.6155999898910522 
2025-01-16 18:17:30.266028:  
2025-01-16 18:17:30.267029: Epoch 88 
2025-01-16 18:17:30.272104: Current learning rate: 0.00677 
2025-01-16 18:18:11.087361: train_loss -0.8023 
2025-01-16 18:18:11.087873: val_loss -0.5397 
2025-01-16 18:18:11.092940: Pseudo dice [np.float32(0.7827), np.float32(0.4772)] 
2025-01-16 18:18:11.095967: Epoch time: 40.82 s 
2025-01-16 18:18:11.098999: Yayy! New best EMA pseudo Dice: 0.6171000003814697 
2025-01-16 18:18:11.871371:  
2025-01-16 18:18:11.871371: Epoch 89 
2025-01-16 18:18:11.876474: Current learning rate: 0.00673 
2025-01-16 18:18:52.693029: train_loss -0.801 
2025-01-16 18:18:52.693029: val_loss -0.5771 
2025-01-16 18:18:52.700155: Pseudo dice [np.float32(0.781), np.float32(0.5084)] 
2025-01-16 18:18:52.704712: Epoch time: 40.82 s 
2025-01-16 18:18:52.707291: Yayy! New best EMA pseudo Dice: 0.6197999715805054 
2025-01-16 18:18:53.485672:  
2025-01-16 18:18:53.486180: Epoch 90 
2025-01-16 18:18:53.491350: Current learning rate: 0.00669 
2025-01-16 18:19:34.309633: train_loss -0.8103 
2025-01-16 18:19:34.309633: val_loss -0.5645 
2025-01-16 18:19:34.315653: Pseudo dice [np.float32(0.7783), np.float32(0.5208)] 
2025-01-16 18:19:34.318159: Epoch time: 40.82 s 
2025-01-16 18:19:34.321666: Yayy! New best EMA pseudo Dice: 0.6227999925613403 
2025-01-16 18:19:35.097154:  
2025-01-16 18:19:35.098157: Epoch 91 
2025-01-16 18:19:35.104790: Current learning rate: 0.00665 
2025-01-16 18:20:15.887823: train_loss -0.8125 
2025-01-16 18:20:15.888326: val_loss -0.5691 
2025-01-16 18:20:15.892906: Pseudo dice [np.float32(0.7783), np.float32(0.4876)] 
2025-01-16 18:20:15.896512: Epoch time: 40.79 s 
2025-01-16 18:20:15.899580: Yayy! New best EMA pseudo Dice: 0.6237999796867371 
2025-01-16 18:20:16.679583:  
2025-01-16 18:20:16.680583: Epoch 92 
2025-01-16 18:20:16.685654: Current learning rate: 0.00662 
2025-01-16 18:20:57.471017: train_loss -0.798 
2025-01-16 18:20:57.472021: val_loss -0.4966 
2025-01-16 18:20:57.477032: Pseudo dice [np.float32(0.7597), np.float32(0.352)] 
2025-01-16 18:20:57.481041: Epoch time: 40.79 s 
2025-01-16 18:20:58.027465:  
2025-01-16 18:20:58.027465: Epoch 93 
2025-01-16 18:20:58.032476: Current learning rate: 0.00658 
2025-01-16 18:21:38.826026: train_loss -0.7727 
2025-01-16 18:21:38.827029: val_loss -0.5129 
2025-01-16 18:21:38.831606: Pseudo dice [np.float32(0.7681), np.float32(0.4203)] 
2025-01-16 18:21:38.836252: Epoch time: 40.8 s 
2025-01-16 18:21:39.530105:  
2025-01-16 18:21:39.530105: Epoch 94 
2025-01-16 18:21:39.535637: Current learning rate: 0.00654 
2025-01-16 18:22:20.321874: train_loss -0.8052 
2025-01-16 18:22:20.322875: val_loss -0.52 
2025-01-16 18:22:20.328388: Pseudo dice [np.float32(0.7819), np.float32(0.3849)] 
2025-01-16 18:22:20.331897: Epoch time: 40.79 s 
2025-01-16 18:22:20.880045:  
2025-01-16 18:22:20.880045: Epoch 95 
2025-01-16 18:22:20.886114: Current learning rate: 0.0065 
2025-01-16 18:23:01.672415: train_loss -0.784 
2025-01-16 18:23:01.672934: val_loss -0.5449 
2025-01-16 18:23:01.678003: Pseudo dice [np.float32(0.7815), np.float32(0.476)] 
2025-01-16 18:23:01.681537: Epoch time: 40.79 s 
2025-01-16 18:23:02.228293:  
2025-01-16 18:23:02.228293: Epoch 96 
2025-01-16 18:23:02.233348: Current learning rate: 0.00647 
2025-01-16 18:23:43.018447: train_loss -0.8043 
2025-01-16 18:23:43.018961: val_loss -0.5353 
2025-01-16 18:23:43.025547: Pseudo dice [np.float32(0.7498), np.float32(0.4372)] 
2025-01-16 18:23:43.028590: Epoch time: 40.79 s 
2025-01-16 18:23:43.590737:  
2025-01-16 18:23:43.590737: Epoch 97 
2025-01-16 18:23:43.596298: Current learning rate: 0.00643 
2025-01-16 18:24:24.380399: train_loss -0.7996 
2025-01-16 18:24:24.381399: val_loss -0.5677 
2025-01-16 18:24:24.386416: Pseudo dice [np.float32(0.7821), np.float32(0.5698)] 
2025-01-16 18:24:24.390433: Epoch time: 40.79 s 
2025-01-16 18:24:24.946298:  
2025-01-16 18:24:24.946298: Epoch 98 
2025-01-16 18:24:24.951313: Current learning rate: 0.00639 
2025-01-16 18:25:05.754784: train_loss -0.791 
2025-01-16 18:25:05.755289: val_loss -0.5273 
2025-01-16 18:25:05.760882: Pseudo dice [np.float32(0.7967), np.float32(0.3909)] 
2025-01-16 18:25:05.763916: Epoch time: 40.81 s 
2025-01-16 18:25:06.325893:  
2025-01-16 18:25:06.325893: Epoch 99 
2025-01-16 18:25:06.331940: Current learning rate: 0.00635 
2025-01-16 18:25:47.139821: train_loss -0.7939 
2025-01-16 18:25:47.139821: val_loss -0.5317 
2025-01-16 18:25:47.146336: Pseudo dice [np.float32(0.7651), np.float32(0.5573)] 
2025-01-16 18:25:47.148841: Epoch time: 40.81 s 
2025-01-16 18:25:47.911979:  
2025-01-16 18:25:47.911979: Epoch 100 
2025-01-16 18:25:47.919108: Current learning rate: 0.00631 
2025-01-16 18:26:28.724870: train_loss -0.8131 
2025-01-16 18:26:28.725443: val_loss -0.4885 
2025-01-16 18:26:28.731524: Pseudo dice [np.float32(0.7817), np.float32(0.3727)] 
2025-01-16 18:26:28.734048: Epoch time: 40.81 s 
2025-01-16 18:26:29.300967:  
2025-01-16 18:26:29.300967: Epoch 101 
2025-01-16 18:26:29.306026: Current learning rate: 0.00628 
2025-01-16 18:27:10.138347: train_loss -0.7903 
2025-01-16 18:27:10.138861: val_loss -0.4998 
2025-01-16 18:27:10.143413: Pseudo dice [np.float32(0.783), np.float32(0.4961)] 
2025-01-16 18:27:10.145948: Epoch time: 40.84 s 
2025-01-16 18:27:10.852413:  
2025-01-16 18:27:10.852413: Epoch 102 
2025-01-16 18:27:10.857971: Current learning rate: 0.00624 
2025-01-16 18:27:51.666848: train_loss -0.8072 
2025-01-16 18:27:51.667853: val_loss -0.535 
2025-01-16 18:27:51.672874: Pseudo dice [np.float32(0.7761), np.float32(0.4915)] 
2025-01-16 18:27:51.675927: Epoch time: 40.81 s 
2025-01-16 18:27:52.241854:  
2025-01-16 18:27:52.241854: Epoch 103 
2025-01-16 18:27:52.246908: Current learning rate: 0.0062 
2025-01-16 18:28:33.044376: train_loss -0.8138 
2025-01-16 18:28:33.045402: val_loss -0.565 
2025-01-16 18:28:33.050010: Pseudo dice [np.float32(0.7633), np.float32(0.5172)] 
2025-01-16 18:28:33.053674: Epoch time: 40.8 s 
2025-01-16 18:28:33.619652:  
2025-01-16 18:28:33.620652: Epoch 104 
2025-01-16 18:28:33.623692: Current learning rate: 0.00616 
2025-01-16 18:29:14.432356: train_loss -0.8134 
2025-01-16 18:29:14.433356: val_loss -0.5603 
2025-01-16 18:29:14.438873: Pseudo dice [np.float32(0.7924), np.float32(0.4971)] 
2025-01-16 18:29:14.441379: Epoch time: 40.81 s 
2025-01-16 18:29:14.444888: Yayy! New best EMA pseudo Dice: 0.6240000128746033 
2025-01-16 18:29:15.225538:  
2025-01-16 18:29:15.226042: Epoch 105 
2025-01-16 18:29:15.231054: Current learning rate: 0.00612 
2025-01-16 18:29:56.053472: train_loss -0.8198 
2025-01-16 18:29:56.053976: val_loss -0.5227 
2025-01-16 18:29:56.059993: Pseudo dice [np.float32(0.7874), np.float32(0.3955)] 
2025-01-16 18:29:56.064001: Epoch time: 40.83 s 
2025-01-16 18:29:56.616129:  
2025-01-16 18:29:56.616129: Epoch 106 
2025-01-16 18:29:56.621142: Current learning rate: 0.00609 
2025-01-16 18:30:37.405578: train_loss -0.8151 
2025-01-16 18:30:37.405578: val_loss -0.6062 
2025-01-16 18:30:37.411229: Pseudo dice [np.float32(0.7892), np.float32(0.5382)] 
2025-01-16 18:30:37.413739: Epoch time: 40.79 s 
2025-01-16 18:30:37.417291: Yayy! New best EMA pseudo Dice: 0.6251000165939331 
2025-01-16 18:30:38.210299:  
2025-01-16 18:30:38.210299: Epoch 107 
2025-01-16 18:30:38.215337: Current learning rate: 0.00605 
2025-01-16 18:31:19.019796: train_loss -0.8244 
2025-01-16 18:31:19.020314: val_loss -0.5672 
2025-01-16 18:31:19.025876: Pseudo dice [np.float32(0.7648), np.float32(0.525)] 
2025-01-16 18:31:19.028903: Epoch time: 40.81 s 
2025-01-16 18:31:19.031411: Yayy! New best EMA pseudo Dice: 0.6269999742507935 
2025-01-16 18:31:19.788715:  
2025-01-16 18:31:19.789219: Epoch 108 
2025-01-16 18:31:19.794800: Current learning rate: 0.00601 
2025-01-16 18:32:00.565321: train_loss -0.833 
2025-01-16 18:32:00.565827: val_loss -0.5421 
2025-01-16 18:32:00.571491: Pseudo dice [np.float32(0.8027), np.float32(0.4526)] 
2025-01-16 18:32:00.574539: Epoch time: 40.78 s 
2025-01-16 18:32:00.577074: Yayy! New best EMA pseudo Dice: 0.6270999908447266 
2025-01-16 18:32:01.360734:  
2025-01-16 18:32:01.361737: Epoch 109 
2025-01-16 18:32:01.367272: Current learning rate: 0.00597 
2025-01-16 18:32:42.142412: train_loss -0.8139 
2025-01-16 18:32:42.142412: val_loss -0.5566 
2025-01-16 18:32:42.148926: Pseudo dice [np.float32(0.7846), np.float32(0.5129)] 
2025-01-16 18:32:42.152436: Epoch time: 40.78 s 
2025-01-16 18:32:42.155943: Yayy! New best EMA pseudo Dice: 0.6292999982833862 
2025-01-16 18:32:43.097980:  
2025-01-16 18:32:43.097980: Epoch 110 
2025-01-16 18:32:43.104689: Current learning rate: 0.00593 
2025-01-16 18:33:23.872922: train_loss -0.8179 
2025-01-16 18:33:23.874438: val_loss -0.4945 
2025-01-16 18:33:23.879509: Pseudo dice [np.float32(0.7868), np.float32(0.4707)] 
2025-01-16 18:33:23.883024: Epoch time: 40.78 s 
2025-01-16 18:33:24.443004:  
2025-01-16 18:33:24.444008: Epoch 111 
2025-01-16 18:33:24.448597: Current learning rate: 0.0059 
2025-01-16 18:34:05.228167: train_loss -0.8237 
2025-01-16 18:34:05.228671: val_loss -0.5309 
2025-01-16 18:34:05.233716: Pseudo dice [np.float32(0.7694), np.float32(0.4397)] 
2025-01-16 18:34:05.237245: Epoch time: 40.79 s 
2025-01-16 18:34:05.786492:  
2025-01-16 18:34:05.786994: Epoch 112 
2025-01-16 18:34:05.792008: Current learning rate: 0.00586 
2025-01-16 18:34:46.591389: train_loss -0.8308 
2025-01-16 18:34:46.591389: val_loss -0.5844 
2025-01-16 18:34:46.597388: Pseudo dice [np.float32(0.7946), np.float32(0.5028)] 
2025-01-16 18:34:46.601394: Epoch time: 40.8 s 
2025-01-16 18:34:47.152786:  
2025-01-16 18:34:47.153786: Epoch 113 
2025-01-16 18:34:47.159406: Current learning rate: 0.00582 
2025-01-16 18:35:27.934587: train_loss -0.7925 
2025-01-16 18:35:27.935099: val_loss -0.5254 
2025-01-16 18:35:27.939671: Pseudo dice [np.float32(0.7645), np.float32(0.5388)] 
2025-01-16 18:35:27.944235: Epoch time: 40.78 s 
2025-01-16 18:35:27.947276: Yayy! New best EMA pseudo Dice: 0.6312000155448914 
2025-01-16 18:35:28.735181:  
2025-01-16 18:35:28.735181: Epoch 114 
2025-01-16 18:35:28.741245: Current learning rate: 0.00578 
2025-01-16 18:36:09.536402: train_loss -0.8207 
2025-01-16 18:36:09.536905: val_loss -0.5462 
2025-01-16 18:36:09.542992: Pseudo dice [np.float32(0.759), np.float32(0.5473)] 
2025-01-16 18:36:09.546523: Epoch time: 40.8 s 
2025-01-16 18:36:09.550040: Yayy! New best EMA pseudo Dice: 0.633400022983551 
2025-01-16 18:36:10.343539:  
2025-01-16 18:36:10.343539: Epoch 115 
2025-01-16 18:36:10.349053: Current learning rate: 0.00574 
2025-01-16 18:36:51.147047: train_loss -0.8275 
2025-01-16 18:36:51.147551: val_loss -0.5414 
2025-01-16 18:36:51.153595: Pseudo dice [np.float32(0.7697), np.float32(0.5463)] 
2025-01-16 18:36:51.157115: Epoch time: 40.8 s 
2025-01-16 18:36:51.161185: Yayy! New best EMA pseudo Dice: 0.6359000205993652 
2025-01-16 18:36:51.917603:  
2025-01-16 18:36:51.918603: Epoch 116 
2025-01-16 18:36:51.923752: Current learning rate: 0.0057 
2025-01-16 18:37:32.696136: train_loss -0.8071 
2025-01-16 18:37:32.696642: val_loss -0.5425 
2025-01-16 18:37:32.702712: Pseudo dice [np.float32(0.78), np.float32(0.5285)] 
2025-01-16 18:37:32.706750: Epoch time: 40.78 s 
2025-01-16 18:37:32.710801: Yayy! New best EMA pseudo Dice: 0.6377000212669373 
2025-01-16 18:37:33.504777:  
2025-01-16 18:37:33.505780: Epoch 117 
2025-01-16 18:37:33.510842: Current learning rate: 0.00567 
2025-01-16 18:38:14.315455: train_loss -0.8254 
2025-01-16 18:38:14.315960: val_loss -0.6137 
2025-01-16 18:38:14.320972: Pseudo dice [np.float32(0.8018), np.float32(0.5527)] 
2025-01-16 18:38:14.325480: Epoch time: 40.81 s 
2025-01-16 18:38:14.328488: Yayy! New best EMA pseudo Dice: 0.641700029373169 
2025-01-16 18:38:15.123498:  
2025-01-16 18:38:15.123498: Epoch 118 
2025-01-16 18:38:15.129533: Current learning rate: 0.00563 
2025-01-16 18:38:55.921409: train_loss -0.8343 
2025-01-16 18:38:55.922412: val_loss -0.5375 
2025-01-16 18:38:55.926428: Pseudo dice [np.float32(0.7609), np.float32(0.5895)] 
2025-01-16 18:38:55.929943: Epoch time: 40.8 s 
2025-01-16 18:38:55.933455: Yayy! New best EMA pseudo Dice: 0.6449999809265137 
2025-01-16 18:38:56.849775:  
2025-01-16 18:38:56.850278: Epoch 119 
2025-01-16 18:38:56.855289: Current learning rate: 0.00559 
2025-01-16 18:39:37.648142: train_loss -0.8264 
2025-01-16 18:39:37.648142: val_loss -0.562 
2025-01-16 18:39:37.654157: Pseudo dice [np.float32(0.7711), np.float32(0.5003)] 
2025-01-16 18:39:37.658165: Epoch time: 40.8 s 
2025-01-16 18:39:38.218307:  
2025-01-16 18:39:38.219310: Epoch 120 
2025-01-16 18:39:38.224417: Current learning rate: 0.00555 
2025-01-16 18:40:19.006255: train_loss -0.8184 
2025-01-16 18:40:19.006758: val_loss -0.5691 
2025-01-16 18:40:19.012296: Pseudo dice [np.float32(0.7956), np.float32(0.5526)] 
2025-01-16 18:40:19.016317: Epoch time: 40.79 s 
2025-01-16 18:40:19.019844: Yayy! New best EMA pseudo Dice: 0.6470999717712402 
2025-01-16 18:40:19.778609:  
2025-01-16 18:40:19.779120: Epoch 121 
2025-01-16 18:40:19.784656: Current learning rate: 0.00551 
2025-01-16 18:41:00.568395: train_loss -0.834 
2025-01-16 18:41:00.569397: val_loss -0.5405 
2025-01-16 18:41:00.575418: Pseudo dice [np.float32(0.8005), np.float32(0.4079)] 
2025-01-16 18:41:00.578429: Epoch time: 40.79 s 
2025-01-16 18:41:01.144163:  
2025-01-16 18:41:01.144665: Epoch 122 
2025-01-16 18:41:01.149747: Current learning rate: 0.00547 
2025-01-16 18:41:41.922609: train_loss -0.8298 
2025-01-16 18:41:41.923612: val_loss -0.5249 
2025-01-16 18:41:41.929679: Pseudo dice [np.float32(0.7767), np.float32(0.4106)] 
2025-01-16 18:41:41.932714: Epoch time: 40.78 s 
2025-01-16 18:41:42.501342:  
2025-01-16 18:41:42.501342: Epoch 123 
2025-01-16 18:41:42.509488: Current learning rate: 0.00544 
2025-01-16 18:42:23.284067: train_loss -0.838 
2025-01-16 18:42:23.284579: val_loss -0.5198 
2025-01-16 18:42:23.290655: Pseudo dice [np.float32(0.7847), np.float32(0.333)] 
2025-01-16 18:42:23.294732: Epoch time: 40.78 s 
2025-01-16 18:42:23.855644:  
2025-01-16 18:42:23.856643: Epoch 124 
2025-01-16 18:42:23.862704: Current learning rate: 0.0054 
2025-01-16 18:43:04.632571: train_loss -0.824 
2025-01-16 18:43:04.632571: val_loss -0.5567 
2025-01-16 18:43:04.639607: Pseudo dice [np.float32(0.7887), np.float32(0.5409)] 
2025-01-16 18:43:04.643119: Epoch time: 40.78 s 
2025-01-16 18:43:05.204177:  
2025-01-16 18:43:05.204177: Epoch 125 
2025-01-16 18:43:05.209733: Current learning rate: 0.00536 
2025-01-16 18:43:45.977238: train_loss -0.8324 
2025-01-16 18:43:45.978238: val_loss -0.517 
2025-01-16 18:43:45.985788: Pseudo dice [np.float32(0.7608), np.float32(0.3967)] 
2025-01-16 18:43:45.989799: Epoch time: 40.77 s 
2025-01-16 18:43:46.551910:  
2025-01-16 18:43:46.552910: Epoch 126 
2025-01-16 18:43:46.558530: Current learning rate: 0.00532 
2025-01-16 18:44:27.340421: train_loss -0.8419 
2025-01-16 18:44:27.341927: val_loss -0.4992 
2025-01-16 18:44:27.347562: Pseudo dice [np.float32(0.78), np.float32(0.4042)] 
2025-01-16 18:44:27.352143: Epoch time: 40.79 s 
2025-01-16 18:44:28.065633:  
2025-01-16 18:44:28.065633: Epoch 127 
2025-01-16 18:44:28.072211: Current learning rate: 0.00528 
2025-01-16 18:45:08.875661: train_loss -0.8443 
2025-01-16 18:45:08.876163: val_loss -0.5088 
2025-01-16 18:45:08.883213: Pseudo dice [np.float32(0.7727), np.float32(0.4766)] 
2025-01-16 18:45:08.887243: Epoch time: 40.81 s 
2025-01-16 18:45:09.448797:  
2025-01-16 18:45:09.449300: Epoch 128 
2025-01-16 18:45:09.454312: Current learning rate: 0.00524 
2025-01-16 18:45:50.242647: train_loss -0.852 
2025-01-16 18:45:50.243650: val_loss -0.5335 
2025-01-16 18:45:50.251193: Pseudo dice [np.float32(0.7913), np.float32(0.372)] 
2025-01-16 18:45:50.255228: Epoch time: 40.79 s 
2025-01-16 18:45:50.820527:  
2025-01-16 18:45:50.821527: Epoch 129 
2025-01-16 18:45:50.827110: Current learning rate: 0.0052 
2025-01-16 18:46:31.611494: train_loss -0.8547 
2025-01-16 18:46:31.613001: val_loss -0.4968 
2025-01-16 18:46:31.619534: Pseudo dice [np.float32(0.7811), np.float32(0.3722)] 
2025-01-16 18:46:31.623546: Epoch time: 40.79 s 
2025-01-16 18:46:32.190421:  
2025-01-16 18:46:32.190421: Epoch 130 
2025-01-16 18:46:32.197480: Current learning rate: 0.00517 
2025-01-16 18:47:13.008610: train_loss -0.8547 
2025-01-16 18:47:13.009119: val_loss -0.5496 
2025-01-16 18:47:13.015759: Pseudo dice [np.float32(0.7712), np.float32(0.4656)] 
2025-01-16 18:47:13.020314: Epoch time: 40.82 s 
2025-01-16 18:47:13.591496:  
2025-01-16 18:47:13.591496: Epoch 131 
2025-01-16 18:47:13.598510: Current learning rate: 0.00513 
2025-01-16 18:47:54.389982: train_loss -0.8459 
2025-01-16 18:47:54.389982: val_loss -0.5241 
2025-01-16 18:47:54.397013: Pseudo dice [np.float32(0.7756), np.float32(0.4145)] 
2025-01-16 18:47:54.401539: Epoch time: 40.8 s 
2025-01-16 18:47:54.968886:  
2025-01-16 18:47:54.968886: Epoch 132 
2025-01-16 18:47:54.974900: Current learning rate: 0.00509 
2025-01-16 18:48:35.762023: train_loss -0.8467 
2025-01-16 18:48:35.762526: val_loss -0.511 
2025-01-16 18:48:35.768117: Pseudo dice [np.float32(0.7771), np.float32(0.4494)] 
2025-01-16 18:48:35.773700: Epoch time: 40.79 s 
2025-01-16 18:48:36.343422:  
2025-01-16 18:48:36.344425: Epoch 133 
2025-01-16 18:48:36.350985: Current learning rate: 0.00505 
2025-01-16 18:49:17.147203: train_loss -0.8511 
2025-01-16 18:49:17.147705: val_loss -0.5508 
2025-01-16 18:49:17.153846: Pseudo dice [np.float32(0.7924), np.float32(0.4849)] 
2025-01-16 18:49:17.158413: Epoch time: 40.8 s 
2025-01-16 18:49:17.728443:  
2025-01-16 18:49:17.728443: Epoch 134 
2025-01-16 18:49:17.734477: Current learning rate: 0.00501 
2025-01-16 18:49:58.523781: train_loss -0.8625 
2025-01-16 18:49:58.524784: val_loss -0.5755 
2025-01-16 18:49:58.531332: Pseudo dice [np.float32(0.7852), np.float32(0.5806)] 
2025-01-16 18:49:58.534951: Epoch time: 40.8 s 
2025-01-16 18:49:59.259333:  
2025-01-16 18:49:59.260336: Epoch 135 
2025-01-16 18:49:59.266922: Current learning rate: 0.00497 
2025-01-16 18:50:40.061919: train_loss -0.8605 
2025-01-16 18:50:40.061919: val_loss -0.5711 
2025-01-16 18:50:40.068963: Pseudo dice [np.float32(0.7835), np.float32(0.5148)] 
2025-01-16 18:50:40.073492: Epoch time: 40.8 s 
2025-01-16 18:50:40.643615:  
2025-01-16 18:50:40.644618: Epoch 136 
2025-01-16 18:50:40.651206: Current learning rate: 0.00493 
2025-01-16 18:51:21.440509: train_loss -0.8412 
2025-01-16 18:51:21.441508: val_loss -0.5865 
2025-01-16 18:51:21.448024: Pseudo dice [np.float32(0.7878), np.float32(0.5998)] 
2025-01-16 18:51:21.453034: Epoch time: 40.8 s 
2025-01-16 18:51:22.029439:  
2025-01-16 18:51:22.029439: Epoch 137 
2025-01-16 18:51:22.036477: Current learning rate: 0.00489 
2025-01-16 18:52:02.835333: train_loss -0.8574 
2025-01-16 18:52:02.836333: val_loss -0.5075 
2025-01-16 18:52:02.842849: Pseudo dice [np.float32(0.7664), np.float32(0.3745)] 
2025-01-16 18:52:02.847861: Epoch time: 40.81 s 
2025-01-16 18:52:03.422895:  
2025-01-16 18:52:03.422895: Epoch 138 
2025-01-16 18:52:03.429962: Current learning rate: 0.00485 
2025-01-16 18:52:44.224512: train_loss -0.8555 
2025-01-16 18:52:44.224512: val_loss -0.5597 
2025-01-16 18:52:44.232031: Pseudo dice [np.float32(0.8076), np.float32(0.463)] 
2025-01-16 18:52:44.236038: Epoch time: 40.8 s 
2025-01-16 18:52:44.809445:  
2025-01-16 18:52:44.809947: Epoch 139 
2025-01-16 18:52:44.815961: Current learning rate: 0.00482 
2025-01-16 18:53:25.603442: train_loss -0.8471 
2025-01-16 18:53:25.603442: val_loss -0.514 
2025-01-16 18:53:25.610993: Pseudo dice [np.float32(0.7804), np.float32(0.6168)] 
2025-01-16 18:53:25.615517: Epoch time: 40.79 s 
2025-01-16 18:53:26.194735:  
2025-01-16 18:53:26.195238: Epoch 140 
2025-01-16 18:53:26.201252: Current learning rate: 0.00478 
2025-01-16 18:54:06.988730: train_loss -0.8455 
2025-01-16 18:54:06.989733: val_loss -0.5551 
2025-01-16 18:54:06.996246: Pseudo dice [np.float32(0.7778), np.float32(0.488)] 
2025-01-16 18:54:06.999754: Epoch time: 40.79 s 
2025-01-16 18:54:07.569213:  
2025-01-16 18:54:07.570217: Epoch 141 
2025-01-16 18:54:07.576839: Current learning rate: 0.00474 
2025-01-16 18:54:48.366005: train_loss -0.8436 
2025-01-16 18:54:48.366005: val_loss -0.5197 
2025-01-16 18:54:48.373042: Pseudo dice [np.float32(0.7879), np.float32(0.378)] 
2025-01-16 18:54:48.377551: Epoch time: 40.8 s 
2025-01-16 18:54:48.951126:  
2025-01-16 18:54:48.951126: Epoch 142 
2025-01-16 18:54:48.957142: Current learning rate: 0.0047 
2025-01-16 18:55:29.745159: train_loss -0.8403 
2025-01-16 18:55:29.745666: val_loss -0.5741 
2025-01-16 18:55:29.750198: Pseudo dice [np.float32(0.7774), np.float32(0.5349)] 
2025-01-16 18:55:29.754730: Epoch time: 40.8 s 
2025-01-16 18:55:30.482666:  
2025-01-16 18:55:30.482666: Epoch 143 
2025-01-16 18:55:30.489746: Current learning rate: 0.00466 
2025-01-16 18:56:11.268725: train_loss -0.8404 
2025-01-16 18:56:11.268725: val_loss -0.5468 
2025-01-16 18:56:11.276240: Pseudo dice [np.float32(0.7935), np.float32(0.3817)] 
2025-01-16 18:56:11.279749: Epoch time: 40.79 s 
2025-01-16 18:56:11.851783:  
2025-01-16 18:56:11.852783: Epoch 144 
2025-01-16 18:56:11.858370: Current learning rate: 0.00462 
2025-01-16 18:56:52.628621: train_loss -0.8464 
2025-01-16 18:56:52.629625: val_loss -0.4678 
2025-01-16 18:56:52.636196: Pseudo dice [np.float32(0.7574), np.float32(0.5046)] 
2025-01-16 18:56:52.641208: Epoch time: 40.78 s 
2025-01-16 18:56:53.213685:  
2025-01-16 18:56:53.213685: Epoch 145 
2025-01-16 18:56:53.219727: Current learning rate: 0.00458 
2025-01-16 18:57:33.992851: train_loss -0.8398 
2025-01-16 18:57:33.993354: val_loss -0.562 
2025-01-16 18:57:33.998442: Pseudo dice [np.float32(0.7802), np.float32(0.5218)] 
2025-01-16 18:57:34.002950: Epoch time: 40.78 s 
2025-01-16 18:57:34.581155:  
2025-01-16 18:57:34.582158: Epoch 146 
2025-01-16 18:57:34.587227: Current learning rate: 0.00454 
2025-01-16 18:58:15.357709: train_loss -0.8641 
2025-01-16 18:58:15.358223: val_loss -0.5274 
2025-01-16 18:58:15.364300: Pseudo dice [np.float32(0.7855), np.float32(0.5731)] 
2025-01-16 18:58:15.368878: Epoch time: 40.78 s 
2025-01-16 18:58:15.949316:  
2025-01-16 18:58:15.949316: Epoch 147 
2025-01-16 18:58:15.955866: Current learning rate: 0.0045 
2025-01-16 18:58:56.734176: train_loss -0.8575 
2025-01-16 18:58:56.734176: val_loss -0.5589 
2025-01-16 18:58:56.741235: Pseudo dice [np.float32(0.7969), np.float32(0.5383)] 
2025-01-16 18:58:56.745326: Epoch time: 40.79 s 
2025-01-16 18:58:57.323832:  
2025-01-16 18:58:57.323832: Epoch 148 
2025-01-16 18:58:57.330949: Current learning rate: 0.00446 
2025-01-16 18:59:38.096215: train_loss -0.8565 
2025-01-16 18:59:38.096215: val_loss -0.5381 
2025-01-16 18:59:38.102229: Pseudo dice [np.float32(0.7783), np.float32(0.4884)] 
2025-01-16 18:59:38.106236: Epoch time: 40.77 s 
2025-01-16 18:59:38.680328:  
2025-01-16 18:59:38.681331: Epoch 149 
2025-01-16 18:59:38.687928: Current learning rate: 0.00442 
2025-01-16 19:00:19.457769: train_loss -0.8702 
2025-01-16 19:00:19.457769: val_loss -0.5424 
2025-01-16 19:00:19.464782: Pseudo dice [np.float32(0.7818), np.float32(0.571)] 
2025-01-16 19:00:19.468794: Epoch time: 40.78 s 
2025-01-16 19:00:20.272038:  
2025-01-16 19:00:20.273042: Epoch 150 
2025-01-16 19:00:20.279600: Current learning rate: 0.00438 
2025-01-16 19:01:01.054581: train_loss -0.8263 
2025-01-16 19:01:01.055094: val_loss -0.5255 
2025-01-16 19:01:01.061686: Pseudo dice [np.float32(0.7975), np.float32(0.3652)] 
2025-01-16 19:01:01.066287: Epoch time: 40.78 s 
2025-01-16 19:01:01.799798:  
2025-01-16 19:01:01.800301: Epoch 151 
2025-01-16 19:01:01.807344: Current learning rate: 0.00434 
2025-01-16 19:01:42.593067: train_loss -0.8586 
2025-01-16 19:01:42.593570: val_loss -0.5346 
2025-01-16 19:01:42.599589: Pseudo dice [np.float32(0.7681), np.float32(0.546)] 
2025-01-16 19:01:42.604604: Epoch time: 40.79 s 
2025-01-16 19:01:43.180717:  
2025-01-16 19:01:43.180717: Epoch 152 
2025-01-16 19:01:43.187316: Current learning rate: 0.0043 
2025-01-16 19:02:23.963055: train_loss -0.8569 
2025-01-16 19:02:23.963055: val_loss -0.5317 
2025-01-16 19:02:23.969572: Pseudo dice [np.float32(0.7845), np.float32(0.543)] 
2025-01-16 19:02:23.973100: Epoch time: 40.78 s 
2025-01-16 19:02:24.543206:  
2025-01-16 19:02:24.543709: Epoch 153 
2025-01-16 19:02:24.548723: Current learning rate: 0.00427 
2025-01-16 19:03:05.337026: train_loss -0.8621 
2025-01-16 19:03:05.337026: val_loss -0.5525 
2025-01-16 19:03:05.344128: Pseudo dice [np.float32(0.796), np.float32(0.4127)] 
2025-01-16 19:03:05.347636: Epoch time: 40.79 s 
2025-01-16 19:03:05.930852:  
2025-01-16 19:03:05.930852: Epoch 154 
2025-01-16 19:03:05.936408: Current learning rate: 0.00423 
2025-01-16 19:03:46.709872: train_loss -0.8613 
2025-01-16 19:03:46.709872: val_loss -0.4832 
2025-01-16 19:03:46.715958: Pseudo dice [np.float32(0.7745), np.float32(0.4528)] 
2025-01-16 19:03:46.720009: Epoch time: 40.78 s 
2025-01-16 19:03:47.306098:  
2025-01-16 19:03:47.306600: Epoch 155 
2025-01-16 19:03:47.312155: Current learning rate: 0.00419 
2025-01-16 19:04:28.080062: train_loss -0.8628 
2025-01-16 19:04:28.081066: val_loss -0.5664 
2025-01-16 19:04:28.087128: Pseudo dice [np.float32(0.7929), np.float32(0.499)] 
2025-01-16 19:04:28.091150: Epoch time: 40.77 s 
2025-01-16 19:04:28.679765:  
2025-01-16 19:04:28.679765: Epoch 156 
2025-01-16 19:04:28.685332: Current learning rate: 0.00415 
2025-01-16 19:05:09.464054: train_loss -0.8533 
2025-01-16 19:05:09.465058: val_loss -0.5568 
2025-01-16 19:05:09.470070: Pseudo dice [np.float32(0.7929), np.float32(0.5556)] 
2025-01-16 19:05:09.474077: Epoch time: 40.78 s 
2025-01-16 19:05:10.058894:  
2025-01-16 19:05:10.059397: Epoch 157 
2025-01-16 19:05:10.063960: Current learning rate: 0.00411 
2025-01-16 19:05:50.847102: train_loss -0.8531 
2025-01-16 19:05:50.848105: val_loss -0.5196 
2025-01-16 19:05:50.854669: Pseudo dice [np.float32(0.7869), np.float32(0.4801)] 
2025-01-16 19:05:50.858265: Epoch time: 40.79 s 
2025-01-16 19:05:51.441543:  
2025-01-16 19:05:51.442546: Epoch 158 
2025-01-16 19:05:51.447595: Current learning rate: 0.00407 
2025-01-16 19:06:32.220093: train_loss -0.8765 
2025-01-16 19:06:32.220093: val_loss -0.5116 
2025-01-16 19:06:32.226628: Pseudo dice [np.float32(0.8018), np.float32(0.4427)] 
2025-01-16 19:06:32.230149: Epoch time: 40.78 s 
2025-01-16 19:06:32.969345:  
2025-01-16 19:06:32.970348: Epoch 159 
2025-01-16 19:06:32.975398: Current learning rate: 0.00403 
2025-01-16 19:07:13.773772: train_loss -0.8696 
2025-01-16 19:07:13.774776: val_loss -0.5159 
2025-01-16 19:07:13.780338: Pseudo dice [np.float32(0.788), np.float32(0.478)] 
2025-01-16 19:07:13.783845: Epoch time: 40.8 s 
2025-01-16 19:07:14.366266:  
2025-01-16 19:07:14.367269: Epoch 160 
2025-01-16 19:07:14.372325: Current learning rate: 0.00399 
2025-01-16 19:07:55.168270: train_loss -0.8618 
2025-01-16 19:07:55.169273: val_loss -0.5288 
2025-01-16 19:07:55.174338: Pseudo dice [np.float32(0.7964), np.float32(0.5123)] 
2025-01-16 19:07:55.177863: Epoch time: 40.8 s 
2025-01-16 19:07:55.764082:  
2025-01-16 19:07:55.764590: Epoch 161 
2025-01-16 19:07:55.770189: Current learning rate: 0.00395 
2025-01-16 19:08:36.572026: train_loss -0.8708 
2025-01-16 19:08:36.572026: val_loss -0.5057 
2025-01-16 19:08:36.579167: Pseudo dice [np.float32(0.7889), np.float32(0.4671)] 
2025-01-16 19:08:36.582209: Epoch time: 40.81 s 
2025-01-16 19:08:37.164014:  
2025-01-16 19:08:37.164014: Epoch 162 
2025-01-16 19:08:37.169602: Current learning rate: 0.00391 
2025-01-16 19:09:17.959626: train_loss -0.8717 
2025-01-16 19:09:17.960629: val_loss -0.5146 
2025-01-16 19:09:17.965695: Pseudo dice [np.float32(0.7654), np.float32(0.4117)] 
2025-01-16 19:09:17.969735: Epoch time: 40.8 s 
2025-01-16 19:09:18.551418:  
2025-01-16 19:09:18.551920: Epoch 163 
2025-01-16 19:09:18.556962: Current learning rate: 0.00387 
2025-01-16 19:09:59.347946: train_loss -0.8725 
2025-01-16 19:09:59.347946: val_loss -0.5559 
2025-01-16 19:09:59.353496: Pseudo dice [np.float32(0.7959), np.float32(0.5018)] 
2025-01-16 19:09:59.357037: Epoch time: 40.8 s 
2025-01-16 19:09:59.942915:  
2025-01-16 19:09:59.942915: Epoch 164 
2025-01-16 19:09:59.949034: Current learning rate: 0.00383 
2025-01-16 19:10:40.747921: train_loss -0.8679 
2025-01-16 19:10:40.747921: val_loss -0.5411 
2025-01-16 19:10:40.754035: Pseudo dice [np.float32(0.8155), np.float32(0.4314)] 
2025-01-16 19:10:40.757083: Epoch time: 40.81 s 
2025-01-16 19:10:41.326392:  
2025-01-16 19:10:41.326392: Epoch 165 
2025-01-16 19:10:41.332053: Current learning rate: 0.00379 
2025-01-16 19:11:22.122784: train_loss -0.8818 
2025-01-16 19:11:22.123787: val_loss -0.5395 
2025-01-16 19:11:22.129335: Pseudo dice [np.float32(0.7846), np.float32(0.4678)] 
2025-01-16 19:11:22.132416: Epoch time: 40.8 s 
2025-01-16 19:11:22.701302:  
2025-01-16 19:11:22.701302: Epoch 166 
2025-01-16 19:11:22.707377: Current learning rate: 0.00375 
2025-01-16 19:12:03.489330: train_loss -0.8823 
2025-01-16 19:12:03.489330: val_loss -0.5304 
2025-01-16 19:12:03.495384: Pseudo dice [np.float32(0.7772), np.float32(0.4975)] 
2025-01-16 19:12:03.498935: Epoch time: 40.79 s 
2025-01-16 19:12:04.214093:  
2025-01-16 19:12:04.214093: Epoch 167 
2025-01-16 19:12:04.219135: Current learning rate: 0.00371 
2025-01-16 19:12:44.990443: train_loss -0.8729 
2025-01-16 19:12:44.990952: val_loss -0.5316 
2025-01-16 19:12:44.996055: Pseudo dice [np.float32(0.7765), np.float32(0.4334)] 
2025-01-16 19:12:45.000102: Epoch time: 40.78 s 
2025-01-16 19:12:45.582057:  
2025-01-16 19:12:45.582057: Epoch 168 
2025-01-16 19:12:45.588091: Current learning rate: 0.00367 
2025-01-16 19:13:26.350857: train_loss -0.8725 
2025-01-16 19:13:26.351362: val_loss -0.5026 
2025-01-16 19:13:26.357420: Pseudo dice [np.float32(0.7877), np.float32(0.4512)] 
2025-01-16 19:13:26.360935: Epoch time: 40.77 s 
2025-01-16 19:13:26.937262:  
2025-01-16 19:13:26.937262: Epoch 169 
2025-01-16 19:13:26.942819: Current learning rate: 0.00363 
2025-01-16 19:14:07.717137: train_loss -0.884 
2025-01-16 19:14:07.717640: val_loss -0.4983 
2025-01-16 19:14:07.723214: Pseudo dice [np.float32(0.7576), np.float32(0.4077)] 
2025-01-16 19:14:07.726243: Epoch time: 40.78 s 
2025-01-16 19:14:08.302051:  
2025-01-16 19:14:08.302051: Epoch 170 
2025-01-16 19:14:08.308068: Current learning rate: 0.00359 
2025-01-16 19:14:49.096958: train_loss -0.8734 
2025-01-16 19:14:49.097961: val_loss -0.5533 
2025-01-16 19:14:49.103514: Pseudo dice [np.float32(0.78), np.float32(0.5313)] 
2025-01-16 19:14:49.107054: Epoch time: 40.8 s 
2025-01-16 19:14:49.681712:  
2025-01-16 19:14:49.682715: Epoch 171 
2025-01-16 19:14:49.687309: Current learning rate: 0.00355 
2025-01-16 19:15:30.496223: train_loss -0.8777 
2025-01-16 19:15:30.496223: val_loss -0.5394 
2025-01-16 19:15:30.501280: Pseudo dice [np.float32(0.7871), np.float32(0.4664)] 
2025-01-16 19:15:30.503801: Epoch time: 40.81 s 
2025-01-16 19:15:31.075881:  
2025-01-16 19:15:31.075881: Epoch 172 
2025-01-16 19:15:31.082429: Current learning rate: 0.00351 
2025-01-16 19:16:11.890134: train_loss -0.8801 
2025-01-16 19:16:11.891133: val_loss -0.5269 
2025-01-16 19:16:11.896649: Pseudo dice [np.float32(0.7892), np.float32(0.5402)] 
2025-01-16 19:16:11.901163: Epoch time: 40.81 s 
2025-01-16 19:16:12.478288:  
2025-01-16 19:16:12.478797: Epoch 173 
2025-01-16 19:16:12.483830: Current learning rate: 0.00346 
2025-01-16 19:16:53.290128: train_loss -0.8892 
2025-01-16 19:16:53.291127: val_loss -0.5071 
2025-01-16 19:16:53.296690: Pseudo dice [np.float32(0.7829), np.float32(0.4974)] 
2025-01-16 19:16:53.300276: Epoch time: 40.81 s 
2025-01-16 19:16:53.874810:  
2025-01-16 19:16:53.874810: Epoch 174 
2025-01-16 19:16:53.880429: Current learning rate: 0.00342 
2025-01-16 19:17:34.670750: train_loss -0.8815 
2025-01-16 19:17:34.670750: val_loss -0.5156 
2025-01-16 19:17:34.676799: Pseudo dice [np.float32(0.7919), np.float32(0.5225)] 
2025-01-16 19:17:34.679825: Epoch time: 40.8 s 
2025-01-16 19:17:35.413075:  
2025-01-16 19:17:35.414078: Epoch 175 
2025-01-16 19:17:35.418105: Current learning rate: 0.00338 
2025-01-16 19:18:16.184270: train_loss -0.8763 
2025-01-16 19:18:16.185269: val_loss -0.5616 
2025-01-16 19:18:16.190787: Pseudo dice [np.float32(0.7999), np.float32(0.4569)] 
2025-01-16 19:18:16.194297: Epoch time: 40.77 s 
2025-01-16 19:18:16.763855:  
2025-01-16 19:18:16.765364: Epoch 176 
2025-01-16 19:18:16.771446: Current learning rate: 0.00334 
2025-01-16 19:18:57.557941: train_loss -0.8748 
2025-01-16 19:18:57.558444: val_loss -0.5621 
2025-01-16 19:18:57.563995: Pseudo dice [np.float32(0.7967), np.float32(0.5078)] 
2025-01-16 19:18:57.566533: Epoch time: 40.79 s 
2025-01-16 19:18:58.158434:  
2025-01-16 19:18:58.158940: Epoch 177 
2025-01-16 19:18:58.164013: Current learning rate: 0.0033 
2025-01-16 19:19:38.967844: train_loss -0.8925 
2025-01-16 19:19:38.968351: val_loss -0.5204 
2025-01-16 19:19:38.973979: Pseudo dice [np.float32(0.7829), np.float32(0.4424)] 
2025-01-16 19:19:38.977021: Epoch time: 40.81 s 
2025-01-16 19:19:39.553811:  
2025-01-16 19:19:39.554814: Epoch 178 
2025-01-16 19:19:39.559361: Current learning rate: 0.00326 
2025-01-16 19:20:20.375761: train_loss -0.8868 
2025-01-16 19:20:20.376265: val_loss -0.5273 
2025-01-16 19:20:20.382432: Pseudo dice [np.float32(0.7948), np.float32(0.3837)] 
2025-01-16 19:20:20.385996: Epoch time: 40.82 s 
2025-01-16 19:20:20.959674:  
2025-01-16 19:20:20.959674: Epoch 179 
2025-01-16 19:20:20.964688: Current learning rate: 0.00322 
2025-01-16 19:21:01.761128: train_loss -0.8931 
2025-01-16 19:21:01.761646: val_loss -0.5689 
2025-01-16 19:21:01.767210: Pseudo dice [np.float32(0.7937), np.float32(0.5322)] 
2025-01-16 19:21:01.770239: Epoch time: 40.8 s 
2025-01-16 19:21:02.348436:  
2025-01-16 19:21:02.348436: Epoch 180 
2025-01-16 19:21:02.353998: Current learning rate: 0.00318 
2025-01-16 19:21:43.150278: train_loss -0.8904 
2025-01-16 19:21:43.150783: val_loss -0.5691 
2025-01-16 19:21:43.156321: Pseudo dice [np.float32(0.7975), np.float32(0.509)] 
2025-01-16 19:21:43.159919: Epoch time: 40.8 s 
2025-01-16 19:21:43.737457:  
2025-01-16 19:21:43.738459: Epoch 181 
2025-01-16 19:21:43.743993: Current learning rate: 0.00314 
2025-01-16 19:22:24.536741: train_loss -0.8902 
2025-01-16 19:22:24.536741: val_loss -0.5606 
2025-01-16 19:22:24.540752: Pseudo dice [np.float32(0.7955), np.float32(0.5292)] 
2025-01-16 19:22:24.544264: Epoch time: 40.8 s 
2025-01-16 19:22:25.270506:  
2025-01-16 19:22:25.271506: Epoch 182 
2025-01-16 19:22:25.277020: Current learning rate: 0.0031 
2025-01-16 19:23:06.060503: train_loss -0.8785 
2025-01-16 19:23:06.060503: val_loss -0.4956 
2025-01-16 19:23:06.067023: Pseudo dice [np.float32(0.7778), np.float32(0.5166)] 
2025-01-16 19:23:06.070533: Epoch time: 40.79 s 
2025-01-16 19:23:06.645806:  
2025-01-16 19:23:06.646313: Epoch 183 
2025-01-16 19:23:06.651890: Current learning rate: 0.00306 
2025-01-16 19:23:47.415565: train_loss -0.8809 
2025-01-16 19:23:47.416077: val_loss -0.5733 
2025-01-16 19:23:47.421143: Pseudo dice [np.float32(0.8009), np.float32(0.6277)] 
2025-01-16 19:23:47.425190: Epoch time: 40.77 s 
2025-01-16 19:23:48.003779:  
2025-01-16 19:23:48.004783: Epoch 184 
2025-01-16 19:23:48.009330: Current learning rate: 0.00302 
2025-01-16 19:24:28.785392: train_loss -0.8849 
2025-01-16 19:24:28.785392: val_loss -0.5286 
2025-01-16 19:24:28.791405: Pseudo dice [np.float32(0.7842), np.float32(0.4763)] 
2025-01-16 19:24:28.794414: Epoch time: 40.78 s 
2025-01-16 19:24:29.372221:  
2025-01-16 19:24:29.372723: Epoch 185 
2025-01-16 19:24:29.378387: Current learning rate: 0.00297 
2025-01-16 19:25:10.143257: train_loss -0.8956 
2025-01-16 19:25:10.143257: val_loss -0.5273 
2025-01-16 19:25:10.149775: Pseudo dice [np.float32(0.7813), np.float32(0.4059)] 
2025-01-16 19:25:10.153285: Epoch time: 40.77 s 
2025-01-16 19:25:10.726508:  
2025-01-16 19:25:10.726508: Epoch 186 
2025-01-16 19:25:10.731522: Current learning rate: 0.00293 
2025-01-16 19:25:51.490346: train_loss -0.8942 
2025-01-16 19:25:51.490849: val_loss -0.543 
2025-01-16 19:25:51.497917: Pseudo dice [np.float32(0.8037), np.float32(0.5872)] 
2025-01-16 19:25:51.500982: Epoch time: 40.77 s 
2025-01-16 19:25:52.079191:  
2025-01-16 19:25:52.079191: Epoch 187 
2025-01-16 19:25:52.084205: Current learning rate: 0.00289 
2025-01-16 19:26:32.851870: train_loss -0.889 
2025-01-16 19:26:32.851870: val_loss -0.5644 
2025-01-16 19:26:32.857888: Pseudo dice [np.float32(0.7883), np.float32(0.5126)] 
2025-01-16 19:26:32.861898: Epoch time: 40.77 s 
2025-01-16 19:26:33.431620:  
2025-01-16 19:26:33.432126: Epoch 188 
2025-01-16 19:26:33.437138: Current learning rate: 0.00285 
2025-01-16 19:27:14.229929: train_loss -0.8811 
2025-01-16 19:27:14.230933: val_loss -0.5167 
2025-01-16 19:27:14.235490: Pseudo dice [np.float32(0.789), np.float32(0.518)] 
2025-01-16 19:27:14.240019: Epoch time: 40.8 s 
2025-01-16 19:27:14.819752:  
2025-01-16 19:27:14.820755: Epoch 189 
2025-01-16 19:27:14.826393: Current learning rate: 0.00281 
2025-01-16 19:27:55.620590: train_loss -0.8908 
2025-01-16 19:27:55.621096: val_loss -0.5495 
2025-01-16 19:27:55.626650: Pseudo dice [np.float32(0.8166), np.float32(0.4875)] 
2025-01-16 19:27:55.630203: Epoch time: 40.8 s 
2025-01-16 19:27:56.363847:  
2025-01-16 19:27:56.364349: Epoch 190 
2025-01-16 19:27:56.369361: Current learning rate: 0.00277 
2025-01-16 19:28:37.172645: train_loss -0.887 
2025-01-16 19:28:37.173645: val_loss -0.4961 
2025-01-16 19:28:37.179160: Pseudo dice [np.float32(0.7754), np.float32(0.3954)] 
2025-01-16 19:28:37.182673: Epoch time: 40.81 s 
2025-01-16 19:28:37.759467:  
2025-01-16 19:28:37.759467: Epoch 191 
2025-01-16 19:28:37.764999: Current learning rate: 0.00273 
2025-01-16 19:29:18.536139: train_loss -0.8965 
2025-01-16 19:29:18.536640: val_loss -0.5395 
2025-01-16 19:29:18.541710: Pseudo dice [np.float32(0.7935), np.float32(0.4067)] 
2025-01-16 19:29:18.545741: Epoch time: 40.78 s 
2025-01-16 19:29:19.133705:  
2025-01-16 19:29:19.134704: Epoch 192 
2025-01-16 19:29:19.140273: Current learning rate: 0.00268 
2025-01-16 19:29:59.917176: train_loss -0.8991 
2025-01-16 19:29:59.917680: val_loss -0.4755 
2025-01-16 19:29:59.921209: Pseudo dice [np.float32(0.7986), np.float32(0.3467)] 
2025-01-16 19:29:59.925234: Epoch time: 40.78 s 
2025-01-16 19:30:00.507600:  
2025-01-16 19:30:00.508600: Epoch 193 
2025-01-16 19:30:00.513661: Current learning rate: 0.00264 
2025-01-16 19:30:41.290277: train_loss -0.8946 
2025-01-16 19:30:41.291280: val_loss -0.5682 
2025-01-16 19:30:41.296343: Pseudo dice [np.float32(0.8031), np.float32(0.5223)] 
2025-01-16 19:30:41.300353: Epoch time: 40.78 s 
2025-01-16 19:30:41.878683:  
2025-01-16 19:30:41.878683: Epoch 194 
2025-01-16 19:30:41.883696: Current learning rate: 0.0026 
2025-01-16 19:31:22.658973: train_loss -0.8984 
2025-01-16 19:31:22.659977: val_loss -0.5494 
2025-01-16 19:31:22.666014: Pseudo dice [np.float32(0.7944), np.float32(0.4627)] 
2025-01-16 19:31:22.669024: Epoch time: 40.78 s 
2025-01-16 19:31:23.261933:  
2025-01-16 19:31:23.262936: Epoch 195 
2025-01-16 19:31:23.267492: Current learning rate: 0.00256 
2025-01-16 19:32:04.061138: train_loss -0.8982 
2025-01-16 19:32:04.061646: val_loss -0.5062 
2025-01-16 19:32:04.067199: Pseudo dice [np.float32(0.7977), np.float32(0.4056)] 
2025-01-16 19:32:04.070251: Epoch time: 40.8 s 
2025-01-16 19:32:04.657563:  
2025-01-16 19:32:04.658566: Epoch 196 
2025-01-16 19:32:04.663130: Current learning rate: 0.00252 
2025-01-16 19:32:45.451825: train_loss -0.8996 
2025-01-16 19:32:45.452829: val_loss -0.5872 
2025-01-16 19:32:45.458374: Pseudo dice [np.float32(0.805), np.float32(0.6368)] 
2025-01-16 19:32:45.461394: Epoch time: 40.79 s 
2025-01-16 19:32:46.044253:  
2025-01-16 19:32:46.045252: Epoch 197 
2025-01-16 19:32:46.050304: Current learning rate: 0.00248 
2025-01-16 19:33:26.842935: train_loss -0.8972 
2025-01-16 19:33:26.843937: val_loss -0.537 
2025-01-16 19:33:26.848950: Pseudo dice [np.float32(0.7845), np.float32(0.4385)] 
2025-01-16 19:33:26.852964: Epoch time: 40.8 s 
2025-01-16 19:33:27.594257:  
2025-01-16 19:33:27.594760: Epoch 198 
2025-01-16 19:33:27.599269: Current learning rate: 0.00243 
2025-01-16 19:34:08.379734: train_loss -0.9025 
2025-01-16 19:34:08.380247: val_loss -0.52 
2025-01-16 19:34:08.385351: Pseudo dice [np.float32(0.7825), np.float32(0.5116)] 
2025-01-16 19:34:08.388397: Epoch time: 40.79 s 
2025-01-16 19:34:08.979698:  
2025-01-16 19:34:08.979698: Epoch 199 
2025-01-16 19:34:08.985740: Current learning rate: 0.00239 
2025-01-16 19:34:49.766786: train_loss -0.9067 
2025-01-16 19:34:49.766786: val_loss -0.5069 
2025-01-16 19:34:49.773304: Pseudo dice [np.float32(0.7911), np.float32(0.5155)] 
2025-01-16 19:34:49.776814: Epoch time: 40.79 s 
2025-01-16 19:34:50.560789:  
2025-01-16 19:34:50.560789: Epoch 200 
2025-01-16 19:34:50.566830: Current learning rate: 0.00235 
2025-01-16 19:35:31.365924: train_loss -0.8965 
2025-01-16 19:35:31.366927: val_loss -0.5621 
2025-01-16 19:35:31.372047: Pseudo dice [np.float32(0.7945), np.float32(0.4929)] 
2025-01-16 19:35:31.375572: Epoch time: 40.81 s 
2025-01-16 19:35:31.958134:  
2025-01-16 19:35:31.958134: Epoch 201 
2025-01-16 19:35:31.963681: Current learning rate: 0.00231 
2025-01-16 19:36:12.760767: train_loss -0.8977 
2025-01-16 19:36:12.760767: val_loss -0.5712 
2025-01-16 19:36:12.766838: Pseudo dice [np.float32(0.7864), np.float32(0.5627)] 
2025-01-16 19:36:12.770376: Epoch time: 40.8 s 
2025-01-16 19:36:13.359428:  
2025-01-16 19:36:13.359428: Epoch 202 
2025-01-16 19:36:13.365500: Current learning rate: 0.00226 
2025-01-16 19:36:54.152831: train_loss -0.9079 
2025-01-16 19:36:54.153833: val_loss -0.5731 
2025-01-16 19:36:54.158849: Pseudo dice [np.float32(0.7951), np.float32(0.5323)] 
2025-01-16 19:36:54.162857: Epoch time: 40.79 s 
2025-01-16 19:36:54.749296:  
2025-01-16 19:36:54.749296: Epoch 203 
2025-01-16 19:36:54.754336: Current learning rate: 0.00222 
2025-01-16 19:37:35.551120: train_loss -0.8982 
2025-01-16 19:37:35.551623: val_loss -0.5375 
2025-01-16 19:37:35.557184: Pseudo dice [np.float32(0.7887), np.float32(0.5343)] 
2025-01-16 19:37:35.560218: Epoch time: 40.8 s 
2025-01-16 19:37:36.145523:  
2025-01-16 19:37:36.145523: Epoch 204 
2025-01-16 19:37:36.151084: Current learning rate: 0.00218 
2025-01-16 19:38:16.941582: train_loss -0.9087 
2025-01-16 19:38:16.941582: val_loss -0.5279 
2025-01-16 19:38:16.948168: Pseudo dice [np.float32(0.7908), np.float32(0.4121)] 
2025-01-16 19:38:16.951716: Epoch time: 40.8 s 
2025-01-16 19:38:17.542540:  
2025-01-16 19:38:17.542540: Epoch 205 
2025-01-16 19:38:17.548055: Current learning rate: 0.00214 
2025-01-16 19:38:58.345744: train_loss -0.9057 
2025-01-16 19:38:58.346747: val_loss -0.5062 
2025-01-16 19:38:58.352296: Pseudo dice [np.float32(0.7962), np.float32(0.3697)] 
2025-01-16 19:38:58.355827: Epoch time: 40.8 s 
2025-01-16 19:38:59.068501:  
2025-01-16 19:38:59.068501: Epoch 206 
2025-01-16 19:38:59.073118: Current learning rate: 0.00209 
2025-01-16 19:39:39.866710: train_loss -0.9123 
2025-01-16 19:39:39.867725: val_loss -0.5187 
2025-01-16 19:39:39.873774: Pseudo dice [np.float32(0.7847), np.float32(0.5175)] 
2025-01-16 19:39:39.877322: Epoch time: 40.8 s 
2025-01-16 19:39:40.437793:  
2025-01-16 19:39:40.437793: Epoch 207 
2025-01-16 19:39:40.443325: Current learning rate: 0.00205 
2025-01-16 19:40:21.239536: train_loss -0.9071 
2025-01-16 19:40:21.241562: val_loss -0.5498 
2025-01-16 19:40:21.247129: Pseudo dice [np.float32(0.7873), np.float32(0.6049)] 
2025-01-16 19:40:21.249731: Epoch time: 40.8 s 
2025-01-16 19:40:21.806848:  
2025-01-16 19:40:21.806848: Epoch 208 
2025-01-16 19:40:21.811861: Current learning rate: 0.00201 
2025-01-16 19:41:02.597832: train_loss -0.8965 
2025-01-16 19:41:02.598346: val_loss -0.5898 
2025-01-16 19:41:02.605004: Pseudo dice [np.float32(0.797), np.float32(0.5563)] 
2025-01-16 19:41:02.608039: Epoch time: 40.79 s 
2025-01-16 19:41:03.158263:  
2025-01-16 19:41:03.159268: Epoch 209 
2025-01-16 19:41:03.165323: Current learning rate: 0.00196 
2025-01-16 19:41:43.954602: train_loss -0.9076 
2025-01-16 19:41:43.955605: val_loss -0.5214 
2025-01-16 19:41:43.961618: Pseudo dice [np.float32(0.7865), np.float32(0.3702)] 
2025-01-16 19:41:43.964627: Epoch time: 40.8 s 
2025-01-16 19:41:44.522253:  
2025-01-16 19:41:44.522253: Epoch 210 
2025-01-16 19:41:44.527336: Current learning rate: 0.00192 
2025-01-16 19:42:25.332309: train_loss -0.8957 
2025-01-16 19:42:25.332812: val_loss -0.5907 
2025-01-16 19:42:25.338375: Pseudo dice [np.float32(0.7943), np.float32(0.6346)] 
2025-01-16 19:42:25.341402: Epoch time: 40.81 s 
2025-01-16 19:42:25.344926: Yayy! New best EMA pseudo Dice: 0.6474000215530396 
2025-01-16 19:42:26.117185:  
2025-01-16 19:42:26.118696: Epoch 211 
2025-01-16 19:42:26.124740: Current learning rate: 0.00188 
2025-01-16 19:43:06.919277: train_loss -0.9007 
2025-01-16 19:43:06.919277: val_loss -0.5291 
2025-01-16 19:43:06.924841: Pseudo dice [np.float32(0.7789), np.float32(0.559)] 
2025-01-16 19:43:06.928879: Epoch time: 40.8 s 
2025-01-16 19:43:06.931887: Yayy! New best EMA pseudo Dice: 0.6496000289916992 
2025-01-16 19:43:07.712950:  
2025-01-16 19:43:07.712950: Epoch 212 
2025-01-16 19:43:07.718986: Current learning rate: 0.00184 
2025-01-16 19:43:48.496645: train_loss -0.8981 
2025-01-16 19:43:48.497153: val_loss -0.5753 
2025-01-16 19:43:48.502198: Pseudo dice [np.float32(0.7999), np.float32(0.6277)] 
2025-01-16 19:43:48.506833: Epoch time: 40.78 s 
2025-01-16 19:43:48.510194: Yayy! New best EMA pseudo Dice: 0.656000018119812 
2025-01-16 19:43:49.300519:  
2025-01-16 19:43:49.301519: Epoch 213 
2025-01-16 19:43:49.307111: Current learning rate: 0.00179 
2025-01-16 19:44:30.091466: train_loss -0.892 
2025-01-16 19:44:30.091972: val_loss -0.5089 
2025-01-16 19:44:30.097037: Pseudo dice [np.float32(0.7697), np.float32(0.4109)] 
2025-01-16 19:44:30.100061: Epoch time: 40.79 s 
2025-01-16 19:44:30.805110:  
2025-01-16 19:44:30.806109: Epoch 214 
2025-01-16 19:44:30.811695: Current learning rate: 0.00175 
2025-01-16 19:45:11.609440: train_loss -0.9 
2025-01-16 19:45:11.610444: val_loss -0.5623 
2025-01-16 19:45:11.615006: Pseudo dice [np.float32(0.8083), np.float32(0.5486)] 
2025-01-16 19:45:11.619089: Epoch time: 40.8 s 
2025-01-16 19:45:12.168350:  
2025-01-16 19:45:12.168350: Epoch 215 
2025-01-16 19:45:12.173397: Current learning rate: 0.0017 
2025-01-16 19:45:52.973454: train_loss -0.907 
2025-01-16 19:45:52.973957: val_loss -0.5663 
2025-01-16 19:45:52.980015: Pseudo dice [np.float32(0.7953), np.float32(0.5248)] 
2025-01-16 19:45:52.982534: Epoch time: 40.81 s 
2025-01-16 19:45:53.532428:  
2025-01-16 19:45:53.532934: Epoch 216 
2025-01-16 19:45:53.537988: Current learning rate: 0.00166 
2025-01-16 19:46:34.337544: train_loss -0.9028 
2025-01-16 19:46:34.339055: val_loss -0.5578 
2025-01-16 19:46:34.345155: Pseudo dice [np.float32(0.8088), np.float32(0.5286)] 
2025-01-16 19:46:34.347691: Epoch time: 40.81 s 
2025-01-16 19:46:34.900013:  
2025-01-16 19:46:34.900013: Epoch 217 
2025-01-16 19:46:34.906092: Current learning rate: 0.00162 
2025-01-16 19:47:15.702743: train_loss -0.8994 
2025-01-16 19:47:15.703747: val_loss -0.5378 
2025-01-16 19:47:15.709820: Pseudo dice [np.float32(0.7877), np.float32(0.4873)] 
2025-01-16 19:47:15.712855: Epoch time: 40.8 s 
2025-01-16 19:47:16.268994:  
2025-01-16 19:47:16.270505: Epoch 218 
2025-01-16 19:47:16.275607: Current learning rate: 0.00157 
2025-01-16 19:47:57.062809: train_loss -0.9083 
2025-01-16 19:47:57.064324: val_loss -0.5029 
2025-01-16 19:47:57.069909: Pseudo dice [np.float32(0.7845), np.float32(0.5277)] 
2025-01-16 19:47:57.072953: Epoch time: 40.79 s 
2025-01-16 19:47:57.625144:  
2025-01-16 19:47:57.626144: Epoch 219 
2025-01-16 19:47:57.631200: Current learning rate: 0.00153 
2025-01-16 19:48:38.419477: train_loss -0.9107 
2025-01-16 19:48:38.419477: val_loss -0.6066 
2025-01-16 19:48:38.425486: Pseudo dice [np.float32(0.8217), np.float32(0.5961)] 
2025-01-16 19:48:38.428494: Epoch time: 40.79 s 
2025-01-16 19:48:38.432005: Yayy! New best EMA pseudo Dice: 0.6588000059127808 
2025-01-16 19:48:39.242773:  
2025-01-16 19:48:39.242773: Epoch 220 
2025-01-16 19:48:39.248343: Current learning rate: 0.00148 
2025-01-16 19:49:20.047995: train_loss -0.9052 
2025-01-16 19:49:20.047995: val_loss -0.5307 
2025-01-16 19:49:20.054009: Pseudo dice [np.float32(0.7705), np.float32(0.6249)] 
2025-01-16 19:49:20.057515: Epoch time: 40.81 s 
2025-01-16 19:49:20.060524: Yayy! New best EMA pseudo Dice: 0.6626999974250793 
2025-01-16 19:49:20.807689:  
2025-01-16 19:49:20.808192: Epoch 221 
2025-01-16 19:49:20.813771: Current learning rate: 0.00144 
2025-01-16 19:50:01.595417: train_loss -0.9035 
2025-01-16 19:50:01.595417: val_loss -0.5183 
2025-01-16 19:50:01.602008: Pseudo dice [np.float32(0.7972), np.float32(0.5011)] 
2025-01-16 19:50:01.605561: Epoch time: 40.79 s 
2025-01-16 19:50:02.157032:  
2025-01-16 19:50:02.158035: Epoch 222 
2025-01-16 19:50:02.163069: Current learning rate: 0.00139 
2025-01-16 19:50:42.959566: train_loss -0.9009 
2025-01-16 19:50:42.960068: val_loss -0.5352 
2025-01-16 19:50:42.965672: Pseudo dice [np.float32(0.8029), np.float32(0.5858)] 
2025-01-16 19:50:42.969246: Epoch time: 40.8 s 
2025-01-16 19:50:42.971788: Yayy! New best EMA pseudo Dice: 0.6646999716758728 
2025-01-16 19:50:43.902424:  
2025-01-16 19:50:43.903428: Epoch 223 
2025-01-16 19:50:43.909041: Current learning rate: 0.00135 
2025-01-16 19:51:24.710634: train_loss -0.9139 
2025-01-16 19:51:24.711633: val_loss -0.5571 
2025-01-16 19:51:24.717152: Pseudo dice [np.float32(0.7952), np.float32(0.5284)] 
2025-01-16 19:51:24.720664: Epoch time: 40.81 s 
2025-01-16 19:51:25.270787:  
2025-01-16 19:51:25.271296: Epoch 224 
2025-01-16 19:51:25.275837: Current learning rate: 0.0013 
2025-01-16 19:52:06.038322: train_loss -0.9131 
2025-01-16 19:52:06.038322: val_loss -0.5382 
2025-01-16 19:52:06.044839: Pseudo dice [np.float32(0.8006), np.float32(0.4273)] 
2025-01-16 19:52:06.050861: Epoch time: 40.77 s 
2025-01-16 19:52:06.597782:  
2025-01-16 19:52:06.598786: Epoch 225 
2025-01-16 19:52:06.603329: Current learning rate: 0.00126 
2025-01-16 19:52:47.378136: train_loss -0.9119 
2025-01-16 19:52:47.379140: val_loss -0.5014 
2025-01-16 19:52:47.384161: Pseudo dice [np.float32(0.7883), np.float32(0.357)] 
2025-01-16 19:52:47.387678: Epoch time: 40.78 s 
2025-01-16 19:52:47.942179:  
2025-01-16 19:52:47.943186: Epoch 226 
2025-01-16 19:52:47.947730: Current learning rate: 0.00121 
2025-01-16 19:53:28.741727: train_loss -0.9178 
2025-01-16 19:53:28.741727: val_loss -0.5317 
2025-01-16 19:53:28.748771: Pseudo dice [np.float32(0.792), np.float32(0.4875)] 
2025-01-16 19:53:28.752282: Epoch time: 40.8 s 
2025-01-16 19:53:29.303106:  
2025-01-16 19:53:29.303608: Epoch 227 
2025-01-16 19:53:29.308619: Current learning rate: 0.00117 
2025-01-16 19:54:10.099502: train_loss -0.9028 
2025-01-16 19:54:10.100505: val_loss -0.5548 
2025-01-16 19:54:10.107052: Pseudo dice [np.float32(0.7846), np.float32(0.4742)] 
2025-01-16 19:54:10.111094: Epoch time: 40.8 s 
2025-01-16 19:54:10.653281:  
2025-01-16 19:54:10.653281: Epoch 228 
2025-01-16 19:54:10.659344: Current learning rate: 0.00112 
2025-01-16 19:54:51.461267: train_loss -0.9102 
2025-01-16 19:54:51.461773: val_loss -0.5662 
2025-01-16 19:54:51.467308: Pseudo dice [np.float32(0.797), np.float32(0.5504)] 
2025-01-16 19:54:51.470821: Epoch time: 40.81 s 
2025-01-16 19:54:52.015771:  
2025-01-16 19:54:52.016775: Epoch 229 
2025-01-16 19:54:52.021330: Current learning rate: 0.00108 
2025-01-16 19:55:32.819255: train_loss -0.9173 
2025-01-16 19:55:32.819255: val_loss -0.5517 
2025-01-16 19:55:32.825294: Pseudo dice [np.float32(0.7934), np.float32(0.527)] 
2025-01-16 19:55:32.828830: Epoch time: 40.8 s 
2025-01-16 19:55:33.380220:  
2025-01-16 19:55:33.380220: Epoch 230 
2025-01-16 19:55:33.385257: Current learning rate: 0.00103 
2025-01-16 19:56:14.183128: train_loss -0.9054 
2025-01-16 19:56:14.183128: val_loss -0.519 
2025-01-16 19:56:14.189715: Pseudo dice [np.float32(0.8115), np.float32(0.3411)] 
2025-01-16 19:56:14.192232: Epoch time: 40.8 s 
2025-01-16 19:56:14.892246:  
2025-01-16 19:56:14.892246: Epoch 231 
2025-01-16 19:56:14.897258: Current learning rate: 0.00098 
2025-01-16 19:56:55.686245: train_loss -0.9133 
2025-01-16 19:56:55.687248: val_loss -0.5662 
2025-01-16 19:56:55.693261: Pseudo dice [np.float32(0.7855), np.float32(0.5428)] 
2025-01-16 19:56:55.696270: Epoch time: 40.8 s 
2025-01-16 19:56:56.241508:  
2025-01-16 19:56:56.241508: Epoch 232 
2025-01-16 19:56:56.246544: Current learning rate: 0.00094 
2025-01-16 19:57:37.040460: train_loss -0.9049 
2025-01-16 19:57:37.041968: val_loss -0.5423 
2025-01-16 19:57:37.047500: Pseudo dice [np.float32(0.8044), np.float32(0.4879)] 
2025-01-16 19:57:37.051010: Epoch time: 40.8 s 
2025-01-16 19:57:37.603688:  
2025-01-16 19:57:37.604194: Epoch 233 
2025-01-16 19:57:37.609252: Current learning rate: 0.00089 
2025-01-16 19:58:18.411801: train_loss -0.9173 
2025-01-16 19:58:18.412315: val_loss -0.5513 
2025-01-16 19:58:18.417369: Pseudo dice [np.float32(0.8061), np.float32(0.5677)] 
2025-01-16 19:58:18.421420: Epoch time: 40.81 s 
2025-01-16 19:58:18.965250:  
2025-01-16 19:58:18.966250: Epoch 234 
2025-01-16 19:58:18.971324: Current learning rate: 0.00084 
2025-01-16 19:58:59.760579: train_loss -0.9043 
2025-01-16 19:58:59.760579: val_loss -0.5299 
2025-01-16 19:58:59.767119: Pseudo dice [np.float32(0.7846), np.float32(0.4155)] 
2025-01-16 19:58:59.770668: Epoch time: 40.8 s 
2025-01-16 19:59:00.323102:  
2025-01-16 19:59:00.324105: Epoch 235 
2025-01-16 19:59:00.330119: Current learning rate: 0.00079 
2025-01-16 19:59:41.122997: train_loss -0.9131 
2025-01-16 19:59:41.123500: val_loss -0.5341 
2025-01-16 19:59:41.129034: Pseudo dice [np.float32(0.8022), np.float32(0.5368)] 
2025-01-16 19:59:41.132555: Epoch time: 40.8 s 
2025-01-16 19:59:41.680275:  
2025-01-16 19:59:41.680778: Epoch 236 
2025-01-16 19:59:41.685790: Current learning rate: 0.00075 
2025-01-16 20:00:22.477219: train_loss -0.9134 
2025-01-16 20:00:22.477722: val_loss -0.5689 
2025-01-16 20:00:22.484777: Pseudo dice [np.float32(0.8033), np.float32(0.5766)] 
2025-01-16 20:00:22.487798: Epoch time: 40.8 s 
2025-01-16 20:00:23.035147:  
2025-01-16 20:00:23.035147: Epoch 237 
2025-01-16 20:00:23.040715: Current learning rate: 0.0007 
2025-01-16 20:01:03.822887: train_loss -0.9145 
2025-01-16 20:01:03.824396: val_loss -0.543 
2025-01-16 20:01:03.829930: Pseudo dice [np.float32(0.7864), np.float32(0.5028)] 
2025-01-16 20:01:03.833440: Epoch time: 40.79 s 
2025-01-16 20:01:04.382990:  
2025-01-16 20:01:04.383493: Epoch 238 
2025-01-16 20:01:04.388414: Current learning rate: 0.00065 
2025-01-16 20:01:45.196996: train_loss -0.9159 
2025-01-16 20:01:45.197502: val_loss -0.5613 
2025-01-16 20:01:45.202543: Pseudo dice [np.float32(0.7938), np.float32(0.5098)] 
2025-01-16 20:01:45.206581: Epoch time: 40.82 s 
2025-01-16 20:01:45.756732:  
2025-01-16 20:01:45.756732: Epoch 239 
2025-01-16 20:01:45.762768: Current learning rate: 0.0006 
2025-01-16 20:02:26.567168: train_loss -0.917 
2025-01-16 20:02:26.567168: val_loss -0.5545 
2025-01-16 20:02:26.571712: Pseudo dice [np.float32(0.8095), np.float32(0.4561)] 
2025-01-16 20:02:26.575322: Epoch time: 40.81 s 
2025-01-16 20:02:27.291719:  
2025-01-16 20:02:27.292226: Epoch 240 
2025-01-16 20:02:27.297819: Current learning rate: 0.00055 
2025-01-16 20:03:08.095556: train_loss -0.9193 
2025-01-16 20:03:08.096062: val_loss -0.5689 
2025-01-16 20:03:08.101628: Pseudo dice [np.float32(0.7978), np.float32(0.526)] 
2025-01-16 20:03:08.105164: Epoch time: 40.81 s 
2025-01-16 20:03:08.660701:  
2025-01-16 20:03:08.660701: Epoch 241 
2025-01-16 20:03:08.667788: Current learning rate: 0.0005 
2025-01-16 20:03:49.455627: train_loss -0.9178 
2025-01-16 20:03:49.456625: val_loss -0.5224 
2025-01-16 20:03:49.462141: Pseudo dice [np.float32(0.7742), np.float32(0.4696)] 
2025-01-16 20:03:49.465650: Epoch time: 40.79 s 
2025-01-16 20:03:50.022998:  
2025-01-16 20:03:50.022998: Epoch 242 
2025-01-16 20:03:50.029099: Current learning rate: 0.00045 
2025-01-16 20:04:30.822578: train_loss -0.9129 
2025-01-16 20:04:30.823081: val_loss -0.527 
2025-01-16 20:04:30.828606: Pseudo dice [np.float32(0.784), np.float32(0.4048)] 
2025-01-16 20:04:30.832632: Epoch time: 40.8 s 
2025-01-16 20:04:31.388235:  
2025-01-16 20:04:31.388235: Epoch 243 
2025-01-16 20:04:31.393857: Current learning rate: 0.0004 
2025-01-16 20:05:12.194689: train_loss -0.9234 
2025-01-16 20:05:12.194689: val_loss -0.5629 
2025-01-16 20:05:12.200749: Pseudo dice [np.float32(0.7968), np.float32(0.5452)] 
2025-01-16 20:05:12.204300: Epoch time: 40.81 s 
2025-01-16 20:05:12.763688:  
2025-01-16 20:05:12.763688: Epoch 244 
2025-01-16 20:05:12.769727: Current learning rate: 0.00035 
2025-01-16 20:05:53.564230: train_loss -0.9168 
2025-01-16 20:05:53.564743: val_loss -0.5251 
2025-01-16 20:05:53.570307: Pseudo dice [np.float32(0.7948), np.float32(0.4093)] 
2025-01-16 20:05:53.572902: Epoch time: 40.8 s 
2025-01-16 20:05:54.130295:  
2025-01-16 20:05:54.130295: Epoch 245 
2025-01-16 20:05:54.135810: Current learning rate: 0.0003 
2025-01-16 20:06:34.926305: train_loss -0.9133 
2025-01-16 20:06:34.926807: val_loss -0.5309 
2025-01-16 20:06:34.932917: Pseudo dice [np.float32(0.7909), np.float32(0.5332)] 
2025-01-16 20:06:34.935446: Epoch time: 40.8 s 
2025-01-16 20:06:35.497299:  
2025-01-16 20:06:35.497299: Epoch 246 
2025-01-16 20:06:35.502914: Current learning rate: 0.00024 
2025-01-16 20:07:16.295954: train_loss -0.9214 
2025-01-16 20:07:16.297465: val_loss -0.5221 
2025-01-16 20:07:16.303104: Pseudo dice [np.float32(0.7912), np.float32(0.4014)] 
2025-01-16 20:07:16.306140: Epoch time: 40.8 s 
2025-01-16 20:07:16.862837:  
2025-01-16 20:07:16.863840: Epoch 247 
2025-01-16 20:07:16.869410: Current learning rate: 0.00019 
2025-01-16 20:07:57.660554: train_loss -0.9199 
2025-01-16 20:07:57.662063: val_loss -0.5589 
2025-01-16 20:07:57.667709: Pseudo dice [np.float32(0.7858), np.float32(0.5378)] 
2025-01-16 20:07:57.670747: Epoch time: 40.8 s 
2025-01-16 20:07:58.385710:  
2025-01-16 20:07:58.385710: Epoch 248 
2025-01-16 20:07:58.390723: Current learning rate: 0.00013 
2025-01-16 20:08:39.170287: train_loss -0.9174 
2025-01-16 20:08:39.170795: val_loss -0.5386 
2025-01-16 20:08:39.175846: Pseudo dice [np.float32(0.7877), np.float32(0.5345)] 
2025-01-16 20:08:39.179878: Epoch time: 40.79 s 
2025-01-16 20:08:39.734666:  
2025-01-16 20:08:39.734666: Epoch 249 
2025-01-16 20:08:39.740223: Current learning rate: 7e-05 
2025-01-16 20:09:20.523153: train_loss -0.9131 
2025-01-16 20:09:20.523660: val_loss -0.4751 
2025-01-16 20:09:20.529238: Pseudo dice [np.float32(0.7779), np.float32(0.3274)] 
2025-01-16 20:09:20.532271: Epoch time: 40.79 s 
2025-01-16 20:09:21.303807: Training done. 
2025-01-16 20:09:21.326808: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-16 20:09:21.333811: The split file contains 5 splits. 
2025-01-16 20:09:21.337809: Desired fold for training: 0 
2025-01-16 20:09:21.340809: This split has 224 training and 57 validation cases. 
2025-01-16 20:09:21.345807: predicting pancreas_021 
2025-01-16 20:09:21.350810: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-16 20:09:23.554571: predicting pancreas_024 
2025-01-16 20:09:23.571575: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-16 20:09:25.468613: predicting pancreas_035 
2025-01-16 20:09:25.484117: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-16 20:09:26.157176: predicting pancreas_040 
2025-01-16 20:09:26.165179: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-01-16 20:09:27.683339: predicting pancreas_042 
2025-01-16 20:09:27.698343: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-01-16 20:09:29.607642: predicting pancreas_056 
2025-01-16 20:09:29.626642: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-16 20:09:31.151264: predicting pancreas_067 
2025-01-16 20:09:31.162267: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-16 20:09:33.080052: predicting pancreas_075 
2025-01-16 20:09:33.102053: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-01-16 20:09:33.899908: predicting pancreas_086 
2025-01-16 20:09:33.908911: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-16 20:09:35.125214: predicting pancreas_089 
2025-01-16 20:09:35.135215: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-16 20:09:36.653325: predicting pancreas_092 
2025-01-16 20:09:36.668326: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-01-16 20:09:40.122210: predicting pancreas_094 
2025-01-16 20:09:40.154211: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-16 20:09:41.720149: predicting pancreas_095 
2025-01-16 20:09:41.732150: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-16 20:09:43.308641: predicting pancreas_098 
2025-01-16 20:09:43.324641: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-16 20:09:47.494564: predicting pancreas_109 
2025-01-16 20:09:47.522565: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-16 20:09:49.128519: predicting pancreas_110 
2025-01-16 20:09:49.139519: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-16 20:09:51.547094: predicting pancreas_114 
2025-01-16 20:09:51.567095: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-16 20:09:53.125351: predicting pancreas_119 
2025-01-16 20:09:53.137352: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-16 20:09:55.497758: predicting pancreas_138 
2025-01-16 20:09:55.513759: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-16 20:09:57.937048: predicting pancreas_145 
2025-01-16 20:09:57.955049: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-16 20:10:00.351460: predicting pancreas_148 
2025-01-16 20:10:00.369462: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-01-16 20:10:01.907480: predicting pancreas_169 
2025-01-16 20:10:01.920480: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-16 20:10:03.460372: predicting pancreas_170 
2025-01-16 20:10:03.473371: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-16 20:10:05.406057: predicting pancreas_172 
2025-01-16 20:10:05.418057: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-16 20:10:06.963735: predicting pancreas_175 
2025-01-16 20:10:06.976736: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-16 20:10:08.521076: predicting pancreas_180 
2025-01-16 20:10:08.531077: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-16 20:10:10.073967: predicting pancreas_191 
2025-01-16 20:10:10.085971: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-16 20:10:10.878580: predicting pancreas_193 
2025-01-16 20:10:10.885580: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-16 20:10:12.795869: predicting pancreas_212 
2025-01-16 20:10:12.809376: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-16 20:10:14.382020: predicting pancreas_215 
2025-01-16 20:10:14.399023: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-16 20:10:15.962007: predicting pancreas_222 
2025-01-16 20:10:15.975006: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-16 20:10:16.659841: predicting pancreas_235 
2025-01-16 20:10:16.666841: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-16 20:10:18.201105: predicting pancreas_241 
2025-01-16 20:10:18.212613: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-16 20:10:19.774992: predicting pancreas_242 
2025-01-16 20:10:19.787993: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-16 20:10:21.720565: predicting pancreas_244 
2025-01-16 20:10:21.737567: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-16 20:10:24.707701: predicting pancreas_246 
2025-01-16 20:10:24.728713: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-16 20:10:27.704005: predicting pancreas_247 
2025-01-16 20:10:27.718512: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-16 20:10:28.621878: predicting pancreas_264 
2025-01-16 20:10:28.629881: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-16 20:10:30.547760: predicting pancreas_265 
2025-01-16 20:10:30.565760: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-16 20:10:32.126731: predicting pancreas_266 
2025-01-16 20:10:32.136731: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-16 20:10:34.522803: predicting pancreas_267 
2025-01-16 20:10:34.540803: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-16 20:10:35.447945: predicting pancreas_275 
2025-01-16 20:10:35.456945: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-16 20:10:37.370996: predicting pancreas_279 
2025-01-16 20:10:37.383996: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-16 20:10:38.076669: predicting pancreas_287 
2025-01-16 20:10:38.084669: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-16 20:10:39.620289: predicting pancreas_301 
2025-01-16 20:10:39.633392: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-16 20:10:41.190762: predicting pancreas_323 
2025-01-16 20:10:41.206764: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-16 20:10:43.616664: predicting pancreas_336 
2025-01-16 20:10:43.637679: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-16 20:10:45.206244: predicting pancreas_344 
2025-01-16 20:10:45.223247: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-16 20:10:47.140552: predicting pancreas_351 
2025-01-16 20:10:47.154552: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-16 20:10:48.052901: predicting pancreas_354 
2025-01-16 20:10:48.063901: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-01-16 20:10:51.119663: predicting pancreas_372 
2025-01-16 20:10:51.145170: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-16 20:10:53.585640: predicting pancreas_377 
2025-01-16 20:10:53.605644: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-01-16 20:10:55.571928: predicting pancreas_387 
2025-01-16 20:10:55.592928: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-01-16 20:10:57.160304: predicting pancreas_391 
2025-01-16 20:10:57.175304: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-16 20:10:59.559259: predicting pancreas_392 
2025-01-16 20:10:59.577259: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-01-16 20:11:00.719621: predicting pancreas_410 
2025-01-16 20:11:00.730624: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-16 20:11:01.829503: predicting pancreas_412 
2025-01-16 20:11:01.843009: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-01-16 20:11:23.907772: Validation complete 
2025-01-16 20:11:23.907772: Mean Validation Dice:  0.5988394793417213 
