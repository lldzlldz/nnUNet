2025-01-08 22:12:28.520336: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.25 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-08 22:12:28.523338: self.oversample_foreground_percent 0.0 
2025-01-08 22:12:28.526338: do_dummy_2d_data_aug: True 
2025-01-08 22:12:28.560463: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-08 22:12:28.566969: The split file contains 5 splits. 
2025-01-08 22:12:28.569390: Desired fold for training: 0 
2025-01-08 22:12:28.571389: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-08 22:12:35.347751: unpacking dataset... 
2025-01-08 22:12:35.746479: unpacking done... 
2025-01-08 22:12:39.413336:  
2025-01-08 22:12:39.414339: Epoch 0 
2025-01-08 22:12:39.418888: Current learning rate: 0.01 
2025-01-08 22:13:24.818701: train_loss 0.1059 
2025-01-08 22:13:24.819704: val_loss 0.0387 
2025-01-08 22:13:24.824716: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-08 22:13:24.828733: Epoch time: 45.41 s 
2025-01-08 22:13:24.831240: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-08 22:13:25.567506:  
2025-01-08 22:13:25.567506: Epoch 1 
2025-01-08 22:13:25.572534: Current learning rate: 0.00996 
2025-01-08 22:14:06.424208: train_loss 0.0404 
2025-01-08 22:14:06.424711: val_loss 0.0314 
2025-01-08 22:14:06.429993: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-08 22:14:06.433585: Epoch time: 40.86 s 
2025-01-08 22:14:06.979469:  
2025-01-08 22:14:06.979469: Epoch 2 
2025-01-08 22:14:06.984488: Current learning rate: 0.00993 
2025-01-08 22:14:47.823288: train_loss 0.0218 
2025-01-08 22:14:47.823805: val_loss -0.0038 
2025-01-08 22:14:47.827863: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-08 22:14:47.830902: Epoch time: 40.84 s 
2025-01-08 22:14:48.401944:  
2025-01-08 22:14:48.402947: Epoch 3 
2025-01-08 22:14:48.407479: Current learning rate: 0.00989 
2025-01-08 22:15:29.246861: train_loss -0.0008 
2025-01-08 22:15:29.247373: val_loss 0.036 
2025-01-08 22:15:29.252509: Pseudo dice [np.float32(0.1068), np.float32(0.0)] 
2025-01-08 22:15:29.256055: Epoch time: 40.85 s 
2025-01-08 22:15:29.259088: Yayy! New best EMA pseudo Dice: 0.0052999998442828655 
2025-01-08 22:15:30.031568:  
2025-01-08 22:15:30.031568: Epoch 4 
2025-01-08 22:15:30.037199: Current learning rate: 0.00986 
2025-01-08 22:16:10.839272: train_loss 0.0113 
2025-01-08 22:16:10.840273: val_loss -0.0208 
2025-01-08 22:16:10.845788: Pseudo dice [np.float32(0.1136), np.float32(0.0)] 
2025-01-08 22:16:10.849297: Epoch time: 40.81 s 
2025-01-08 22:16:10.851805: Yayy! New best EMA pseudo Dice: 0.010499999858438969 
2025-01-08 22:16:11.725835:  
2025-01-08 22:16:11.725835: Epoch 5 
2025-01-08 22:16:11.730888: Current learning rate: 0.00982 
2025-01-08 22:16:52.526060: train_loss -0.0298 
2025-01-08 22:16:52.526569: val_loss -0.012 
2025-01-08 22:16:52.531610: Pseudo dice [np.float32(0.21), np.float32(0.0)] 
2025-01-08 22:16:52.535133: Epoch time: 40.8 s 
2025-01-08 22:16:52.538154: Yayy! New best EMA pseudo Dice: 0.019899999722838402 
2025-01-08 22:16:53.319862:  
2025-01-08 22:16:53.322879: Epoch 6 
2025-01-08 22:16:53.327455: Current learning rate: 0.00978 
2025-01-08 22:17:34.138384: train_loss -0.0382 
2025-01-08 22:17:34.138891: val_loss -0.0571 
2025-01-08 22:17:34.143924: Pseudo dice [np.float32(0.2769), np.float32(0.0)] 
2025-01-08 22:17:34.147456: Epoch time: 40.82 s 
2025-01-08 22:17:34.150578: Yayy! New best EMA pseudo Dice: 0.03180000185966492 
2025-01-08 22:17:34.895965:  
2025-01-08 22:17:34.895965: Epoch 7 
2025-01-08 22:17:34.900977: Current learning rate: 0.00975 
2025-01-08 22:18:15.702107: train_loss -0.0214 
2025-01-08 22:18:15.702107: val_loss -0.0847 
2025-01-08 22:18:15.707664: Pseudo dice [np.float32(0.3431), np.float32(0.0)] 
2025-01-08 22:18:15.710692: Epoch time: 40.81 s 
2025-01-08 22:18:15.713198: Yayy! New best EMA pseudo Dice: 0.04580000042915344 
2025-01-08 22:18:16.517184:  
2025-01-08 22:18:16.517184: Epoch 8 
2025-01-08 22:18:16.522732: Current learning rate: 0.00971 
2025-01-08 22:18:57.362132: train_loss -0.0623 
2025-01-08 22:18:57.363136: val_loss -0.1201 
2025-01-08 22:18:57.368734: Pseudo dice [np.float32(0.3965), np.float32(0.0)] 
2025-01-08 22:18:57.371791: Epoch time: 40.85 s 
2025-01-08 22:18:57.374327: Yayy! New best EMA pseudo Dice: 0.061000000685453415 
2025-01-08 22:18:58.196783:  
2025-01-08 22:18:58.197786: Epoch 9 
2025-01-08 22:18:58.202390: Current learning rate: 0.00968 
2025-01-08 22:19:39.026539: train_loss -0.0712 
2025-01-08 22:19:39.027041: val_loss -0.0715 
2025-01-08 22:19:39.032053: Pseudo dice [np.float32(0.3082), np.float32(0.0)] 
2025-01-08 22:19:39.035562: Epoch time: 40.83 s 
2025-01-08 22:19:39.038068: Yayy! New best EMA pseudo Dice: 0.07029999792575836 
2025-01-08 22:19:39.771273:  
2025-01-08 22:19:39.772277: Epoch 10 
2025-01-08 22:19:39.776967: Current learning rate: 0.00964 
2025-01-08 22:20:20.605466: train_loss -0.0767 
2025-01-08 22:20:20.606471: val_loss -0.0822 
2025-01-08 22:20:20.611483: Pseudo dice [np.float32(0.293), np.float32(0.0)] 
2025-01-08 22:20:20.615492: Epoch time: 40.83 s 
2025-01-08 22:20:20.617998: Yayy! New best EMA pseudo Dice: 0.0778999999165535 
2025-01-08 22:20:21.406899:  
2025-01-08 22:20:21.407904: Epoch 11 
2025-01-08 22:20:21.412478: Current learning rate: 0.0096 
2025-01-08 22:21:02.247853: train_loss -0.0874 
2025-01-08 22:21:02.248434: val_loss -0.1008 
2025-01-08 22:21:02.254449: Pseudo dice [np.float32(0.3908), np.float32(0.0)] 
2025-01-08 22:21:02.256955: Epoch time: 40.84 s 
2025-01-08 22:21:02.260463: Yayy! New best EMA pseudo Dice: 0.08969999849796295 
2025-01-08 22:21:03.067841:  
2025-01-08 22:21:03.069344: Epoch 12 
2025-01-08 22:21:03.074394: Current learning rate: 0.00957 
2025-01-08 22:21:43.909638: train_loss -0.0887 
2025-01-08 22:21:43.909638: val_loss -0.1293 
2025-01-08 22:21:43.915186: Pseudo dice [np.float32(0.4077), np.float32(0.0)] 
2025-01-08 22:21:43.917696: Epoch time: 40.84 s 
2025-01-08 22:21:43.921210: Yayy! New best EMA pseudo Dice: 0.10109999775886536 
2025-01-08 22:21:44.866802:  
2025-01-08 22:21:44.867307: Epoch 13 
2025-01-08 22:21:44.874827: Current learning rate: 0.00953 
2025-01-08 22:22:25.715289: train_loss -0.104 
2025-01-08 22:22:25.715289: val_loss -0.1498 
2025-01-08 22:22:25.721306: Pseudo dice [np.float32(0.4752), np.float32(0.0)] 
2025-01-08 22:22:25.725317: Epoch time: 40.85 s 
2025-01-08 22:22:25.728829: Yayy! New best EMA pseudo Dice: 0.11479999870061874 
2025-01-08 22:22:26.518486:  
2025-01-08 22:22:26.518486: Epoch 14 
2025-01-08 22:22:26.524527: Current learning rate: 0.00949 
2025-01-08 22:23:07.385341: train_loss -0.106 
2025-01-08 22:23:07.386850: val_loss -0.1507 
2025-01-08 22:23:07.392513: Pseudo dice [np.float32(0.4427), np.float32(0.0)] 
2025-01-08 22:23:07.395036: Epoch time: 40.87 s 
2025-01-08 22:23:07.398072: Yayy! New best EMA pseudo Dice: 0.12540000677108765 
2025-01-08 22:23:08.197167:  
2025-01-08 22:23:08.198167: Epoch 15 
2025-01-08 22:23:08.203681: Current learning rate: 0.00946 
2025-01-08 22:23:49.008444: train_loss -0.1093 
2025-01-08 22:23:49.009443: val_loss -0.1491 
2025-01-08 22:23:49.014956: Pseudo dice [np.float32(0.4476), np.float32(0.0)] 
2025-01-08 22:23:49.018468: Epoch time: 40.81 s 
2025-01-08 22:23:49.022475: Yayy! New best EMA pseudo Dice: 0.13519999384880066 
2025-01-08 22:23:49.770519:  
2025-01-08 22:23:49.770519: Epoch 16 
2025-01-08 22:23:49.776534: Current learning rate: 0.00942 
2025-01-08 22:24:30.583955: train_loss -0.1117 
2025-01-08 22:24:30.585460: val_loss -0.1785 
2025-01-08 22:24:30.590499: Pseudo dice [np.float32(0.5223), np.float32(0.0)] 
2025-01-08 22:24:30.594053: Epoch time: 40.81 s 
2025-01-08 22:24:30.596559: Yayy! New best EMA pseudo Dice: 0.1477999985218048 
2025-01-08 22:24:31.372884:  
2025-01-08 22:24:31.372884: Epoch 17 
2025-01-08 22:24:31.378899: Current learning rate: 0.00939 
2025-01-08 22:25:12.193852: train_loss -0.1225 
2025-01-08 22:25:12.194851: val_loss -0.1737 
2025-01-08 22:25:12.200365: Pseudo dice [np.float32(0.4525), np.float32(0.014)] 
2025-01-08 22:25:12.203874: Epoch time: 40.82 s 
2025-01-08 22:25:12.207379: Yayy! New best EMA pseudo Dice: 0.15639999508857727 
2025-01-08 22:25:12.955075:  
2025-01-08 22:25:12.955075: Epoch 18 
2025-01-08 22:25:12.960597: Current learning rate: 0.00935 
2025-01-08 22:25:53.759273: train_loss -0.1146 
2025-01-08 22:25:53.759273: val_loss -0.2001 
2025-01-08 22:25:53.765291: Pseudo dice [np.float32(0.5056), np.float32(0.1587)] 
2025-01-08 22:25:53.769303: Epoch time: 40.81 s 
2025-01-08 22:25:53.772812: Yayy! New best EMA pseudo Dice: 0.17399999499320984 
2025-01-08 22:25:54.576605:  
2025-01-08 22:25:54.577107: Epoch 19 
2025-01-08 22:25:54.582117: Current learning rate: 0.00931 
2025-01-08 22:26:35.387215: train_loss -0.1488 
2025-01-08 22:26:35.387215: val_loss -0.2129 
2025-01-08 22:26:35.393234: Pseudo dice [np.float32(0.4984), np.float32(0.0484)] 
2025-01-08 22:26:35.396739: Epoch time: 40.81 s 
2025-01-08 22:26:35.399750: Yayy! New best EMA pseudo Dice: 0.18389999866485596 
2025-01-08 22:26:36.161343:  
2025-01-08 22:26:36.161343: Epoch 20 
2025-01-08 22:26:36.165370: Current learning rate: 0.00928 
2025-01-08 22:27:16.971867: train_loss -0.1389 
2025-01-08 22:27:16.971867: val_loss -0.1544 
2025-01-08 22:27:16.977944: Pseudo dice [np.float32(0.3626), np.float32(0.2566)] 
2025-01-08 22:27:16.980638: Epoch time: 40.81 s 
2025-01-08 22:27:16.983652: Yayy! New best EMA pseudo Dice: 0.1965000033378601 
2025-01-08 22:27:17.914027:  
2025-01-08 22:27:17.915027: Epoch 21 
2025-01-08 22:27:17.920651: Current learning rate: 0.00924 
2025-01-08 22:27:58.720191: train_loss -0.1453 
2025-01-08 22:27:58.720694: val_loss -0.2209 
2025-01-08 22:27:58.726228: Pseudo dice [np.float32(0.4847), np.float32(0.2359)] 
2025-01-08 22:27:58.728733: Epoch time: 40.81 s 
2025-01-08 22:27:58.732247: Yayy! New best EMA pseudo Dice: 0.21279999613761902 
2025-01-08 22:27:59.461475:  
2025-01-08 22:27:59.461977: Epoch 22 
2025-01-08 22:27:59.466989: Current learning rate: 0.0092 
2025-01-08 22:28:40.271653: train_loss -0.1645 
2025-01-08 22:28:40.271653: val_loss -0.1672 
2025-01-08 22:28:40.278168: Pseudo dice [np.float32(0.4057), np.float32(0.1822)] 
2025-01-08 22:28:40.280676: Epoch time: 40.81 s 
2025-01-08 22:28:40.284186: Yayy! New best EMA pseudo Dice: 0.22100000083446503 
2025-01-08 22:28:41.072736:  
2025-01-08 22:28:41.072736: Epoch 23 
2025-01-08 22:28:41.077746: Current learning rate: 0.00917 
2025-01-08 22:29:21.892307: train_loss -0.1611 
2025-01-08 22:29:21.893307: val_loss -0.2428 
2025-01-08 22:29:21.898821: Pseudo dice [np.float32(0.5135), np.float32(0.2012)] 
2025-01-08 22:29:21.902332: Epoch time: 40.82 s 
2025-01-08 22:29:21.904841: Yayy! New best EMA pseudo Dice: 0.2345999926328659 
2025-01-08 22:29:22.717585:  
2025-01-08 22:29:22.719090: Epoch 24 
2025-01-08 22:29:22.724102: Current learning rate: 0.00913 
2025-01-08 22:30:03.528239: train_loss -0.1445 
2025-01-08 22:30:03.528239: val_loss -0.2055 
2025-01-08 22:30:03.534371: Pseudo dice [np.float32(0.4946), np.float32(0.1567)] 
2025-01-08 22:30:03.536890: Epoch time: 40.81 s 
2025-01-08 22:30:03.540409: Yayy! New best EMA pseudo Dice: 0.24369999766349792 
2025-01-08 22:30:04.326117:  
2025-01-08 22:30:04.326117: Epoch 25 
2025-01-08 22:30:04.331161: Current learning rate: 0.0091 
2025-01-08 22:30:45.156778: train_loss -0.1595 
2025-01-08 22:30:45.157778: val_loss -0.1837 
2025-01-08 22:30:45.163292: Pseudo dice [np.float32(0.3788), np.float32(0.2168)] 
2025-01-08 22:30:45.165799: Epoch time: 40.83 s 
2025-01-08 22:30:45.169309: Yayy! New best EMA pseudo Dice: 0.249099999666214 
2025-01-08 22:30:45.946153:  
2025-01-08 22:30:45.946655: Epoch 26 
2025-01-08 22:30:45.952669: Current learning rate: 0.00906 
2025-01-08 22:31:26.754964: train_loss -0.1561 
2025-01-08 22:31:26.755969: val_loss -0.1995 
2025-01-08 22:31:26.761025: Pseudo dice [np.float32(0.4616), np.float32(0.1865)] 
2025-01-08 22:31:26.764082: Epoch time: 40.81 s 
2025-01-08 22:31:26.767202: Yayy! New best EMA pseudo Dice: 0.2565999925136566 
2025-01-08 22:31:27.499812:  
2025-01-08 22:31:27.499812: Epoch 27 
2025-01-08 22:31:27.503828: Current learning rate: 0.00902 
2025-01-08 22:32:08.297492: train_loss -0.1708 
2025-01-08 22:32:08.297492: val_loss -0.2195 
2025-01-08 22:32:08.303507: Pseudo dice [np.float32(0.501), np.float32(0.2268)] 
2025-01-08 22:32:08.306013: Epoch time: 40.8 s 
2025-01-08 22:32:08.309518: Yayy! New best EMA pseudo Dice: 0.267300009727478 
2025-01-08 22:32:09.073701:  
2025-01-08 22:32:09.073701: Epoch 28 
2025-01-08 22:32:09.079186: Current learning rate: 0.00899 
2025-01-08 22:32:49.932134: train_loss -0.2047 
2025-01-08 22:32:49.932134: val_loss -0.2083 
2025-01-08 22:32:49.938148: Pseudo dice [np.float32(0.4948), np.float32(0.1688)] 
2025-01-08 22:32:49.941655: Epoch time: 40.86 s 
2025-01-08 22:32:49.944173: Yayy! New best EMA pseudo Dice: 0.27379998564720154 
2025-01-08 22:32:50.945839:  
2025-01-08 22:32:50.946839: Epoch 29 
2025-01-08 22:32:50.951853: Current learning rate: 0.00895 
2025-01-08 22:33:31.807955: train_loss -0.2015 
2025-01-08 22:33:31.808955: val_loss -0.2478 
2025-01-08 22:33:31.814472: Pseudo dice [np.float32(0.4686), np.float32(0.2949)] 
2025-01-08 22:33:31.816979: Epoch time: 40.86 s 
2025-01-08 22:33:31.820489: Yayy! New best EMA pseudo Dice: 0.28459998965263367 
2025-01-08 22:33:32.628742:  
2025-01-08 22:33:32.629244: Epoch 30 
2025-01-08 22:33:32.634253: Current learning rate: 0.00891 
2025-01-08 22:34:13.424072: train_loss -0.1892 
2025-01-08 22:34:13.425075: val_loss -0.257 
2025-01-08 22:34:13.430087: Pseudo dice [np.float32(0.571), np.float32(0.2579)] 
2025-01-08 22:34:13.433594: Epoch time: 40.8 s 
2025-01-08 22:34:13.436602: Yayy! New best EMA pseudo Dice: 0.29760000109672546 
2025-01-08 22:34:14.225603:  
2025-01-08 22:34:14.226604: Epoch 31 
2025-01-08 22:34:14.232718: Current learning rate: 0.00888 
2025-01-08 22:34:55.025531: train_loss -0.1985 
2025-01-08 22:34:55.025531: val_loss -0.1982 
2025-01-08 22:34:55.031545: Pseudo dice [np.float32(0.4994), np.float32(0.1881)] 
2025-01-08 22:34:55.034054: Epoch time: 40.8 s 
2025-01-08 22:34:55.037573: Yayy! New best EMA pseudo Dice: 0.30219998955726624 
2025-01-08 22:34:55.821911:  
2025-01-08 22:34:55.821911: Epoch 32 
2025-01-08 22:34:55.826943: Current learning rate: 0.00884 
2025-01-08 22:35:36.643064: train_loss -0.1759 
2025-01-08 22:35:36.643583: val_loss -0.2355 
2025-01-08 22:35:36.649189: Pseudo dice [np.float32(0.5028), np.float32(0.2096)] 
2025-01-08 22:35:36.652713: Epoch time: 40.82 s 
2025-01-08 22:35:36.655741: Yayy! New best EMA pseudo Dice: 0.3075999915599823 
2025-01-08 22:35:37.422878:  
2025-01-08 22:35:37.422878: Epoch 33 
2025-01-08 22:35:37.427979: Current learning rate: 0.0088 
2025-01-08 22:36:18.214787: train_loss -0.2446 
2025-01-08 22:36:18.214787: val_loss -0.1863 
2025-01-08 22:36:18.220803: Pseudo dice [np.float32(0.5159), np.float32(0.1397)] 
2025-01-08 22:36:18.224309: Epoch time: 40.79 s 
2025-01-08 22:36:18.227319: Yayy! New best EMA pseudo Dice: 0.30959999561309814 
2025-01-08 22:36:19.030128:  
2025-01-08 22:36:19.031130: Epoch 34 
2025-01-08 22:36:19.035693: Current learning rate: 0.00877 
2025-01-08 22:36:59.827535: train_loss -0.1942 
2025-01-08 22:36:59.828538: val_loss -0.2258 
2025-01-08 22:36:59.834712: Pseudo dice [np.float32(0.4995), np.float32(0.1735)] 
2025-01-08 22:36:59.837764: Epoch time: 40.8 s 
2025-01-08 22:36:59.840542: Yayy! New best EMA pseudo Dice: 0.3122999966144562 
2025-01-08 22:37:00.651930:  
2025-01-08 22:37:00.651930: Epoch 35 
2025-01-08 22:37:00.656950: Current learning rate: 0.00873 
2025-01-08 22:37:41.485271: train_loss -0.1945 
2025-01-08 22:37:41.486271: val_loss -0.26 
2025-01-08 22:37:41.491787: Pseudo dice [np.float32(0.4998), np.float32(0.2417)] 
2025-01-08 22:37:41.494294: Epoch time: 40.83 s 
2025-01-08 22:37:41.497808: Yayy! New best EMA pseudo Dice: 0.3181000053882599 
2025-01-08 22:37:42.274180:  
2025-01-08 22:37:42.274180: Epoch 36 
2025-01-08 22:37:42.279711: Current learning rate: 0.00869 
2025-01-08 22:38:23.101026: train_loss -0.2061 
2025-01-08 22:38:23.101538: val_loss -0.2684 
2025-01-08 22:38:23.107109: Pseudo dice [np.float32(0.5415), np.float32(0.3036)] 
2025-01-08 22:38:23.110614: Epoch time: 40.83 s 
2025-01-08 22:38:23.113622: Yayy! New best EMA pseudo Dice: 0.3285999894142151 
2025-01-08 22:38:24.060743:  
2025-01-08 22:38:24.060743: Epoch 37 
2025-01-08 22:38:24.064771: Current learning rate: 0.00866 
2025-01-08 22:39:04.855488: train_loss -0.2123 
2025-01-08 22:39:04.856492: val_loss -0.2811 
2025-01-08 22:39:04.862503: Pseudo dice [np.float32(0.5268), np.float32(0.3402)] 
2025-01-08 22:39:04.865514: Epoch time: 40.8 s 
2025-01-08 22:39:04.869024: Yayy! New best EMA pseudo Dice: 0.3391000032424927 
2025-01-08 22:39:05.673712:  
2025-01-08 22:39:05.673712: Epoch 38 
2025-01-08 22:39:05.679729: Current learning rate: 0.00862 
2025-01-08 22:39:46.478681: train_loss -0.2081 
2025-01-08 22:39:46.478681: val_loss -0.2679 
2025-01-08 22:39:46.483694: Pseudo dice [np.float32(0.5676), np.float32(0.3084)] 
2025-01-08 22:39:46.486200: Epoch time: 40.81 s 
2025-01-08 22:39:46.490209: Yayy! New best EMA pseudo Dice: 0.3490000069141388 
2025-01-08 22:39:47.326580:  
2025-01-08 22:39:47.326580: Epoch 39 
2025-01-08 22:39:47.332656: Current learning rate: 0.00858 
2025-01-08 22:40:28.141262: train_loss -0.212 
2025-01-08 22:40:28.141766: val_loss -0.283 
2025-01-08 22:40:28.147327: Pseudo dice [np.float32(0.5396), np.float32(0.2908)] 
2025-01-08 22:40:28.151352: Epoch time: 40.82 s 
2025-01-08 22:40:28.154572: Yayy! New best EMA pseudo Dice: 0.3555999994277954 
2025-01-08 22:40:28.956049:  
2025-01-08 22:40:28.957049: Epoch 40 
2025-01-08 22:40:28.962561: Current learning rate: 0.00855 
2025-01-08 22:41:09.758166: train_loss -0.2107 
2025-01-08 22:41:09.759674: val_loss -0.3072 
2025-01-08 22:41:09.765729: Pseudo dice [np.float32(0.5602), np.float32(0.3298)] 
2025-01-08 22:41:09.769237: Epoch time: 40.8 s 
2025-01-08 22:41:09.772247: Yayy! New best EMA pseudo Dice: 0.3644999861717224 
2025-01-08 22:41:10.524772:  
2025-01-08 22:41:10.524772: Epoch 41 
2025-01-08 22:41:10.530792: Current learning rate: 0.00851 
2025-01-08 22:41:51.316623: train_loss -0.2255 
2025-01-08 22:41:51.316623: val_loss -0.3234 
2025-01-08 22:41:51.324143: Pseudo dice [np.float32(0.5387), np.float32(0.3505)] 
2025-01-08 22:41:51.328151: Epoch time: 40.79 s 
2025-01-08 22:41:51.330657: Yayy! New best EMA pseudo Dice: 0.3725000023841858 
2025-01-08 22:41:52.107933:  
2025-01-08 22:41:52.107933: Epoch 42 
2025-01-08 22:41:52.112962: Current learning rate: 0.00847 
2025-01-08 22:42:32.925875: train_loss -0.2287 
2025-01-08 22:42:32.926378: val_loss -0.2922 
2025-01-08 22:42:32.931425: Pseudo dice [np.float32(0.5714), np.float32(0.3301)] 
2025-01-08 22:42:32.934455: Epoch time: 40.82 s 
2025-01-08 22:42:32.937487: Yayy! New best EMA pseudo Dice: 0.38040000200271606 
2025-01-08 22:42:33.676533:  
2025-01-08 22:42:33.676533: Epoch 43 
2025-01-08 22:42:33.682629: Current learning rate: 0.00844 
2025-01-08 22:43:14.509546: train_loss -0.2307 
2025-01-08 22:43:14.510050: val_loss -0.2545 
2025-01-08 22:43:14.515065: Pseudo dice [np.float32(0.53), np.float32(0.2392)] 
2025-01-08 22:43:14.518106: Epoch time: 40.83 s 
2025-01-08 22:43:14.521135: Yayy! New best EMA pseudo Dice: 0.3808000087738037 
2025-01-08 22:43:15.250272:  
2025-01-08 22:43:15.250272: Epoch 44 
2025-01-08 22:43:15.255824: Current learning rate: 0.0084 
2025-01-08 22:43:56.034215: train_loss -0.218 
2025-01-08 22:43:56.035216: val_loss -0.2946 
2025-01-08 22:43:56.040745: Pseudo dice [np.float32(0.5645), np.float32(0.1943)] 
2025-01-08 22:43:56.044254: Epoch time: 40.78 s 
2025-01-08 22:43:56.724641:  
2025-01-08 22:43:56.724641: Epoch 45 
2025-01-08 22:43:56.729686: Current learning rate: 0.00836 
2025-01-08 22:44:37.530316: train_loss -0.2447 
2025-01-08 22:44:37.530818: val_loss -0.3025 
2025-01-08 22:44:37.535829: Pseudo dice [np.float32(0.6201), np.float32(0.2516)] 
2025-01-08 22:44:37.539341: Epoch time: 40.81 s 
2025-01-08 22:44:37.541845: Yayy! New best EMA pseudo Dice: 0.3862000107765198 
2025-01-08 22:44:38.273472:  
2025-01-08 22:44:38.274475: Epoch 46 
2025-01-08 22:44:38.279039: Current learning rate: 0.00833 
2025-01-08 22:45:19.071683: train_loss -0.2457 
2025-01-08 22:45:19.071683: val_loss -0.2565 
2025-01-08 22:45:19.077694: Pseudo dice [np.float32(0.5278), np.float32(0.3123)] 
2025-01-08 22:45:19.080702: Epoch time: 40.8 s 
2025-01-08 22:45:19.083208: Yayy! New best EMA pseudo Dice: 0.3894999921321869 
2025-01-08 22:45:19.824600:  
2025-01-08 22:45:19.824600: Epoch 47 
2025-01-08 22:45:19.830202: Current learning rate: 0.00829 
2025-01-08 22:46:00.660577: train_loss -0.2272 
2025-01-08 22:46:00.660577: val_loss -0.2782 
2025-01-08 22:46:00.665589: Pseudo dice [np.float32(0.5497), np.float32(0.1877)] 
2025-01-08 22:46:00.669603: Epoch time: 40.84 s 
2025-01-08 22:46:01.208628:  
2025-01-08 22:46:01.208628: Epoch 48 
2025-01-08 22:46:01.213697: Current learning rate: 0.00825 
2025-01-08 22:46:42.027261: train_loss -0.2343 
2025-01-08 22:46:42.027772: val_loss -0.3027 
2025-01-08 22:46:42.032324: Pseudo dice [np.float32(0.5138), np.float32(0.3502)] 
2025-01-08 22:46:42.035914: Epoch time: 40.82 s 
2025-01-08 22:46:42.037964: Yayy! New best EMA pseudo Dice: 0.3919000029563904 
2025-01-08 22:46:42.814235:  
2025-01-08 22:46:42.814235: Epoch 49 
2025-01-08 22:46:42.819792: Current learning rate: 0.00822 
2025-01-08 22:47:23.648604: train_loss -0.2557 
2025-01-08 22:47:23.649608: val_loss -0.25 
2025-01-08 22:47:23.654623: Pseudo dice [np.float32(0.506), np.float32(0.2372)] 
2025-01-08 22:47:23.658128: Epoch time: 40.83 s 
2025-01-08 22:47:24.439078:  
2025-01-08 22:47:24.439078: Epoch 50 
2025-01-08 22:47:24.444114: Current learning rate: 0.00818 
2025-01-08 22:48:05.243309: train_loss -0.2581 
2025-01-08 22:48:05.243811: val_loss -0.2934 
2025-01-08 22:48:05.248822: Pseudo dice [np.float32(0.5745), np.float32(0.2965)] 
2025-01-08 22:48:05.251328: Epoch time: 40.81 s 
2025-01-08 22:48:05.254837: Yayy! New best EMA pseudo Dice: 0.3944999873638153 
2025-01-08 22:48:06.080816:  
2025-01-08 22:48:06.080816: Epoch 51 
2025-01-08 22:48:06.085826: Current learning rate: 0.00814 
2025-01-08 22:48:46.889898: train_loss -0.2459 
2025-01-08 22:48:46.889898: val_loss -0.2565 
2025-01-08 22:48:46.894972: Pseudo dice [np.float32(0.5406), np.float32(0.2377)] 
2025-01-08 22:48:46.898575: Epoch time: 40.81 s 
2025-01-08 22:48:47.448072:  
2025-01-08 22:48:47.449118: Epoch 52 
2025-01-08 22:48:47.453666: Current learning rate: 0.00811 
2025-01-08 22:49:28.255154: train_loss -0.2602 
2025-01-08 22:49:28.256155: val_loss -0.3092 
2025-01-08 22:49:28.261669: Pseudo dice [np.float32(0.5877), np.float32(0.2376)] 
2025-01-08 22:49:28.265181: Epoch time: 40.81 s 
2025-01-08 22:49:28.270192: Yayy! New best EMA pseudo Dice: 0.39579999446868896 
2025-01-08 22:49:29.065271:  
2025-01-08 22:49:29.065773: Epoch 53 
2025-01-08 22:49:29.069282: Current learning rate: 0.00807 
2025-01-08 22:50:09.892672: train_loss -0.245 
2025-01-08 22:50:09.894189: val_loss -0.281 
2025-01-08 22:50:09.899817: Pseudo dice [np.float32(0.5478), np.float32(0.2507)] 
2025-01-08 22:50:09.902875: Epoch time: 40.83 s 
2025-01-08 22:50:09.906930: Yayy! New best EMA pseudo Dice: 0.3961000144481659 
2025-01-08 22:50:10.839933:  
2025-01-08 22:50:10.840436: Epoch 54 
2025-01-08 22:50:10.845446: Current learning rate: 0.00803 
2025-01-08 22:50:51.662778: train_loss -0.2318 
2025-01-08 22:50:51.662778: val_loss -0.2379 
2025-01-08 22:50:51.669294: Pseudo dice [np.float32(0.5632), np.float32(0.2066)] 
2025-01-08 22:50:51.672804: Epoch time: 40.82 s 
2025-01-08 22:50:52.218450:  
2025-01-08 22:50:52.218450: Epoch 55 
2025-01-08 22:50:52.223498: Current learning rate: 0.008 
2025-01-08 22:51:33.022017: train_loss -0.2846 
2025-01-08 22:51:33.023519: val_loss -0.3289 
2025-01-08 22:51:33.028531: Pseudo dice [np.float32(0.6012), np.float32(0.3265)] 
2025-01-08 22:51:33.033040: Epoch time: 40.8 s 
2025-01-08 22:51:33.036048: Yayy! New best EMA pseudo Dice: 0.4018999934196472 
2025-01-08 22:51:33.821528:  
2025-01-08 22:51:33.821528: Epoch 56 
2025-01-08 22:51:33.827566: Current learning rate: 0.00796 
2025-01-08 22:52:14.595437: train_loss -0.2573 
2025-01-08 22:52:14.595942: val_loss -0.3424 
2025-01-08 22:52:14.600954: Pseudo dice [np.float32(0.5761), np.float32(0.263)] 
2025-01-08 22:52:14.604464: Epoch time: 40.77 s 
2025-01-08 22:52:14.607969: Yayy! New best EMA pseudo Dice: 0.40369999408721924 
2025-01-08 22:52:15.426371:  
2025-01-08 22:52:15.426874: Epoch 57 
2025-01-08 22:52:15.431885: Current learning rate: 0.00792 
2025-01-08 22:52:56.220340: train_loss -0.2612 
2025-01-08 22:52:56.220340: val_loss -0.3234 
2025-01-08 22:52:56.226353: Pseudo dice [np.float32(0.6031), np.float32(0.2716)] 
2025-01-08 22:52:56.230361: Epoch time: 40.79 s 
2025-01-08 22:52:56.233870: Yayy! New best EMA pseudo Dice: 0.40700000524520874 
2025-01-08 22:52:56.981300:  
2025-01-08 22:52:56.981300: Epoch 58 
2025-01-08 22:52:56.986333: Current learning rate: 0.00789 
2025-01-08 22:53:37.814481: train_loss -0.2724 
2025-01-08 22:53:37.814996: val_loss -0.297 
2025-01-08 22:53:37.820574: Pseudo dice [np.float32(0.5897), np.float32(0.3055)] 
2025-01-08 22:53:37.823628: Epoch time: 40.83 s 
2025-01-08 22:53:37.827299: Yayy! New best EMA pseudo Dice: 0.41110000014305115 
2025-01-08 22:53:38.586021:  
2025-01-08 22:53:38.587022: Epoch 59 
2025-01-08 22:53:38.592601: Current learning rate: 0.00785 
2025-01-08 22:54:19.404548: train_loss -0.2711 
2025-01-08 22:54:19.404548: val_loss -0.3002 
2025-01-08 22:54:19.411062: Pseudo dice [np.float32(0.5637), np.float32(0.2972)] 
2025-01-08 22:54:19.414572: Epoch time: 40.82 s 
2025-01-08 22:54:19.417644: Yayy! New best EMA pseudo Dice: 0.4129999876022339 
2025-01-08 22:54:20.244568:  
2025-01-08 22:54:20.244568: Epoch 60 
2025-01-08 22:54:20.250630: Current learning rate: 0.00781 
2025-01-08 22:55:01.065014: train_loss -0.2743 
2025-01-08 22:55:01.065527: val_loss -0.2956 
2025-01-08 22:55:01.070589: Pseudo dice [np.float32(0.5169), np.float32(0.3009)] 
2025-01-08 22:55:01.074645: Epoch time: 40.82 s 
2025-01-08 22:55:01.621282:  
2025-01-08 22:55:01.621282: Epoch 61 
2025-01-08 22:55:01.626295: Current learning rate: 0.00777 
2025-01-08 22:55:42.427838: train_loss -0.2738 
2025-01-08 22:55:42.428843: val_loss -0.2845 
2025-01-08 22:55:42.433855: Pseudo dice [np.float32(0.5631), np.float32(0.2489)] 
2025-01-08 22:55:42.437866: Epoch time: 40.81 s 
2025-01-08 22:55:43.145123:  
2025-01-08 22:55:43.145123: Epoch 62 
2025-01-08 22:55:43.151222: Current learning rate: 0.00774 
2025-01-08 22:56:23.929824: train_loss -0.2666 
2025-01-08 22:56:23.929824: val_loss -0.2948 
2025-01-08 22:56:23.936460: Pseudo dice [np.float32(0.5715), np.float32(0.2609)] 
2025-01-08 22:56:23.940563: Epoch time: 40.79 s 
2025-01-08 22:56:24.532741:  
2025-01-08 22:56:24.533243: Epoch 63 
2025-01-08 22:56:24.538263: Current learning rate: 0.0077 
2025-01-08 22:57:05.344305: train_loss -0.2591 
2025-01-08 22:57:05.345309: val_loss -0.2865 
2025-01-08 22:57:05.351872: Pseudo dice [np.float32(0.5564), np.float32(0.2611)] 
2025-01-08 22:57:05.355899: Epoch time: 40.81 s 
2025-01-08 22:57:05.904767:  
2025-01-08 22:57:05.904767: Epoch 64 
2025-01-08 22:57:05.910338: Current learning rate: 0.00766 
2025-01-08 22:57:46.708341: train_loss -0.2754 
2025-01-08 22:57:46.708341: val_loss -0.3584 
2025-01-08 22:57:46.714856: Pseudo dice [np.float32(0.629), np.float32(0.3405)] 
2025-01-08 22:57:46.718366: Epoch time: 40.8 s 
2025-01-08 22:57:46.722290: Yayy! New best EMA pseudo Dice: 0.41929998993873596 
2025-01-08 22:57:47.467238:  
2025-01-08 22:57:47.467238: Epoch 65 
2025-01-08 22:57:47.473935: Current learning rate: 0.00763 
2025-01-08 22:58:28.324161: train_loss -0.2838 
2025-01-08 22:58:28.324161: val_loss -0.326 
2025-01-08 22:58:28.331213: Pseudo dice [np.float32(0.6301), np.float32(0.1814)] 
2025-01-08 22:58:28.334239: Epoch time: 40.86 s 
2025-01-08 22:58:28.885554:  
2025-01-08 22:58:28.885554: Epoch 66 
2025-01-08 22:58:28.891082: Current learning rate: 0.00759 
2025-01-08 22:59:09.689499: train_loss -0.2665 
2025-01-08 22:59:09.691000: val_loss -0.3448 
2025-01-08 22:59:09.697015: Pseudo dice [np.float32(0.6195), np.float32(0.3085)] 
2025-01-08 22:59:09.699521: Epoch time: 40.8 s 
2025-01-08 22:59:09.703031: Yayy! New best EMA pseudo Dice: 0.42250001430511475 
2025-01-08 22:59:10.510292:  
2025-01-08 22:59:10.510292: Epoch 67 
2025-01-08 22:59:10.515303: Current learning rate: 0.00755 
2025-01-08 22:59:51.314390: train_loss -0.2926 
2025-01-08 22:59:51.314390: val_loss -0.3261 
2025-01-08 22:59:51.320979: Pseudo dice [np.float32(0.6512), np.float32(0.4123)] 
2025-01-08 22:59:51.324589: Epoch time: 40.8 s 
2025-01-08 22:59:51.329154: Yayy! New best EMA pseudo Dice: 0.4334999918937683 
2025-01-08 22:59:52.106636:  
2025-01-08 22:59:52.107140: Epoch 68 
2025-01-08 22:59:52.112692: Current learning rate: 0.00751 
2025-01-08 23:00:32.921447: train_loss -0.2801 
2025-01-08 23:00:32.921962: val_loss -0.3331 
2025-01-08 23:00:32.927553: Pseudo dice [np.float32(0.6869), np.float32(0.3626)] 
2025-01-08 23:00:32.931591: Epoch time: 40.82 s 
2025-01-08 23:00:32.935202: Yayy! New best EMA pseudo Dice: 0.4426000118255615 
2025-01-08 23:00:33.708402:  
2025-01-08 23:00:33.709402: Epoch 69 
2025-01-08 23:00:33.714974: Current learning rate: 0.00748 
2025-01-08 23:01:14.508054: train_loss -0.2922 
2025-01-08 23:01:14.509556: val_loss -0.3178 
2025-01-08 23:01:14.515605: Pseudo dice [np.float32(0.6332), np.float32(0.251)] 
2025-01-08 23:01:14.518638: Epoch time: 40.8 s 
2025-01-08 23:01:15.079333:  
2025-01-08 23:01:15.079835: Epoch 70 
2025-01-08 23:01:15.084847: Current learning rate: 0.00744 
2025-01-08 23:01:55.896775: train_loss -0.2816 
2025-01-08 23:01:55.897779: val_loss -0.3568 
2025-01-08 23:01:55.903188: Pseudo dice [np.float32(0.6332), np.float32(0.2896)] 
2025-01-08 23:01:55.906700: Epoch time: 40.82 s 
2025-01-08 23:01:55.910235: Yayy! New best EMA pseudo Dice: 0.44440001249313354 
2025-01-08 23:01:56.831517:  
2025-01-08 23:01:56.831517: Epoch 71 
2025-01-08 23:01:56.838573: Current learning rate: 0.0074 
2025-01-08 23:02:37.667798: train_loss -0.3017 
2025-01-08 23:02:37.668303: val_loss -0.3359 
2025-01-08 23:02:37.673341: Pseudo dice [np.float32(0.6677), np.float32(0.227)] 
2025-01-08 23:02:37.676850: Epoch time: 40.84 s 
2025-01-08 23:02:37.680857: Yayy! New best EMA pseudo Dice: 0.4447000026702881 
2025-01-08 23:02:38.456876:  
2025-01-08 23:02:38.456876: Epoch 72 
2025-01-08 23:02:38.460915: Current learning rate: 0.00737 
2025-01-08 23:03:19.257383: train_loss -0.2802 
2025-01-08 23:03:19.257383: val_loss -0.3234 
2025-01-08 23:03:19.263398: Pseudo dice [np.float32(0.579), np.float32(0.2474)] 
2025-01-08 23:03:19.267406: Epoch time: 40.8 s 
2025-01-08 23:03:19.831551:  
2025-01-08 23:03:19.831551: Epoch 73 
2025-01-08 23:03:19.836067: Current learning rate: 0.00733 
2025-01-08 23:04:00.649884: train_loss -0.2903 
2025-01-08 23:04:00.650887: val_loss -0.3228 
2025-01-08 23:04:00.657408: Pseudo dice [np.float32(0.6177), np.float32(0.3725)] 
2025-01-08 23:04:00.660917: Epoch time: 40.82 s 
2025-01-08 23:04:00.664926: Yayy! New best EMA pseudo Dice: 0.44690001010894775 
2025-01-08 23:04:01.485787:  
2025-01-08 23:04:01.485787: Epoch 74 
2025-01-08 23:04:01.492473: Current learning rate: 0.00729 
2025-01-08 23:04:42.285995: train_loss -0.3199 
2025-01-08 23:04:42.287000: val_loss -0.3605 
2025-01-08 23:04:42.293540: Pseudo dice [np.float32(0.6365), np.float32(0.3131)] 
2025-01-08 23:04:42.297048: Epoch time: 40.8 s 
2025-01-08 23:04:42.300554: Yayy! New best EMA pseudo Dice: 0.4496999979019165 
2025-01-08 23:04:43.090873:  
2025-01-08 23:04:43.090873: Epoch 75 
2025-01-08 23:04:43.097335: Current learning rate: 0.00725 
2025-01-08 23:05:23.897043: train_loss -0.2865 
2025-01-08 23:05:23.898047: val_loss -0.3565 
2025-01-08 23:05:23.904064: Pseudo dice [np.float32(0.6635), np.float32(0.2611)] 
2025-01-08 23:05:23.907076: Epoch time: 40.81 s 
2025-01-08 23:05:23.911603: Yayy! New best EMA pseudo Dice: 0.45100000500679016 
2025-01-08 23:05:24.736497:  
2025-01-08 23:05:24.736497: Epoch 76 
2025-01-08 23:05:24.742549: Current learning rate: 0.00722 
2025-01-08 23:06:05.547220: train_loss -0.2931 
2025-01-08 23:06:05.548220: val_loss -0.3351 
2025-01-08 23:06:05.553734: Pseudo dice [np.float32(0.6315), np.float32(0.2004)] 
2025-01-08 23:06:05.557243: Epoch time: 40.81 s 
2025-01-08 23:06:06.127328:  
2025-01-08 23:06:06.127830: Epoch 77 
2025-01-08 23:06:06.132903: Current learning rate: 0.00718 
2025-01-08 23:06:46.943788: train_loss -0.2737 
2025-01-08 23:06:46.944788: val_loss -0.3469 
2025-01-08 23:06:46.950305: Pseudo dice [np.float32(0.6277), np.float32(0.3612)] 
2025-01-08 23:06:46.953351: Epoch time: 40.82 s 
2025-01-08 23:06:46.957386: Yayy! New best EMA pseudo Dice: 0.4521999955177307 
2025-01-08 23:06:47.772388:  
2025-01-08 23:06:47.772891: Epoch 78 
2025-01-08 23:06:47.777902: Current learning rate: 0.00714 
2025-01-08 23:07:28.565789: train_loss -0.3169 
2025-01-08 23:07:28.567292: val_loss -0.3896 
2025-01-08 23:07:28.570802: Pseudo dice [np.float32(0.6309), np.float32(0.4444)] 
2025-01-08 23:07:28.574812: Epoch time: 40.79 s 
2025-01-08 23:07:28.577919: Yayy! New best EMA pseudo Dice: 0.46070000529289246 
2025-01-08 23:07:29.486170:  
2025-01-08 23:07:29.486673: Epoch 79 
2025-01-08 23:07:29.490186: Current learning rate: 0.0071 
2025-01-08 23:08:10.267725: train_loss -0.2977 
2025-01-08 23:08:10.267725: val_loss -0.4193 
2025-01-08 23:08:10.273739: Pseudo dice [np.float32(0.6825), np.float32(0.3538)] 
2025-01-08 23:08:10.276245: Epoch time: 40.78 s 
2025-01-08 23:08:10.280252: Yayy! New best EMA pseudo Dice: 0.46639999747276306 
2025-01-08 23:08:11.081689:  
2025-01-08 23:08:11.082693: Epoch 80 
2025-01-08 23:08:11.087259: Current learning rate: 0.00707 
2025-01-08 23:08:51.874905: train_loss -0.3053 
2025-01-08 23:08:51.875407: val_loss -0.3208 
2025-01-08 23:08:51.880417: Pseudo dice [np.float32(0.6271), np.float32(0.2794)] 
2025-01-08 23:08:51.884927: Epoch time: 40.79 s 
2025-01-08 23:08:52.455654:  
2025-01-08 23:08:52.455654: Epoch 81 
2025-01-08 23:08:52.462773: Current learning rate: 0.00703 
2025-01-08 23:09:33.259351: train_loss -0.315 
2025-01-08 23:09:33.259351: val_loss -0.3857 
2025-01-08 23:09:33.265866: Pseudo dice [np.float32(0.6799), np.float32(0.4661)] 
2025-01-08 23:09:33.269375: Epoch time: 40.8 s 
2025-01-08 23:09:33.273388: Yayy! New best EMA pseudo Dice: 0.47589999437332153 
2025-01-08 23:09:34.093078:  
2025-01-08 23:09:34.093078: Epoch 82 
2025-01-08 23:09:34.099137: Current learning rate: 0.00699 
2025-01-08 23:10:14.878592: train_loss -0.2975 
2025-01-08 23:10:14.878592: val_loss -0.3518 
2025-01-08 23:10:14.884606: Pseudo dice [np.float32(0.6391), np.float32(0.3109)] 
2025-01-08 23:10:14.888614: Epoch time: 40.79 s 
2025-01-08 23:10:15.426416:  
2025-01-08 23:10:15.426931: Epoch 83 
2025-01-08 23:10:15.431979: Current learning rate: 0.00696 
2025-01-08 23:10:56.290939: train_loss -0.2922 
2025-01-08 23:10:56.290939: val_loss -0.3886 
2025-01-08 23:10:56.297453: Pseudo dice [np.float32(0.6339), np.float32(0.3496)] 
2025-01-08 23:10:56.300962: Epoch time: 40.87 s 
2025-01-08 23:10:56.304982: Yayy! New best EMA pseudo Dice: 0.477400004863739 
2025-01-08 23:10:57.045930:  
2025-01-08 23:10:57.046433: Epoch 84 
2025-01-08 23:10:57.053955: Current learning rate: 0.00692 
2025-01-08 23:11:37.865870: train_loss -0.321 
2025-01-08 23:11:37.866373: val_loss -0.3613 
2025-01-08 23:11:37.871384: Pseudo dice [np.float32(0.6699), np.float32(0.2696)] 
2025-01-08 23:11:37.874893: Epoch time: 40.82 s 
2025-01-08 23:11:38.416101:  
2025-01-08 23:11:38.416101: Epoch 85 
2025-01-08 23:11:38.421111: Current learning rate: 0.00688 
2025-01-08 23:12:19.240695: train_loss -0.3273 
2025-01-08 23:12:19.241197: val_loss -0.329 
2025-01-08 23:12:19.247254: Pseudo dice [np.float32(0.641), np.float32(0.2297)] 
2025-01-08 23:12:19.251277: Epoch time: 40.83 s 
2025-01-08 23:12:19.796799:  
2025-01-08 23:12:19.796799: Epoch 86 
2025-01-08 23:12:19.801810: Current learning rate: 0.00684 
2025-01-08 23:13:00.600748: train_loss -0.3077 
2025-01-08 23:13:00.600748: val_loss -0.4375 
2025-01-08 23:13:00.607271: Pseudo dice [np.float32(0.705), np.float32(0.4615)] 
2025-01-08 23:13:00.611347: Epoch time: 40.81 s 
2025-01-08 23:13:00.614412: Yayy! New best EMA pseudo Dice: 0.483599990606308 
2025-01-08 23:13:01.508276:  
2025-01-08 23:13:01.509279: Epoch 87 
2025-01-08 23:13:01.514888: Current learning rate: 0.0068 
2025-01-08 23:13:42.314030: train_loss -0.3257 
2025-01-08 23:13:42.314030: val_loss -0.3416 
2025-01-08 23:13:42.320545: Pseudo dice [np.float32(0.646), np.float32(0.2159)] 
2025-01-08 23:13:42.324055: Epoch time: 40.81 s 
2025-01-08 23:13:42.870103:  
2025-01-08 23:13:42.870103: Epoch 88 
2025-01-08 23:13:42.875162: Current learning rate: 0.00677 
2025-01-08 23:14:23.679980: train_loss -0.3151 
2025-01-08 23:14:23.680483: val_loss -0.4126 
2025-01-08 23:14:23.686533: Pseudo dice [np.float32(0.6862), np.float32(0.2596)] 
2025-01-08 23:14:23.691058: Epoch time: 40.81 s 
2025-01-08 23:14:24.255418:  
2025-01-08 23:14:24.256418: Epoch 89 
2025-01-08 23:14:24.262020: Current learning rate: 0.00673 
2025-01-08 23:15:05.051758: train_loss -0.3138 
2025-01-08 23:15:05.052758: val_loss -0.3561 
2025-01-08 23:15:05.059275: Pseudo dice [np.float32(0.6522), np.float32(0.2725)] 
2025-01-08 23:15:05.063283: Epoch time: 40.8 s 
2025-01-08 23:15:05.600345:  
2025-01-08 23:15:05.600345: Epoch 90 
2025-01-08 23:15:05.605355: Current learning rate: 0.00669 
2025-01-08 23:15:46.393898: train_loss -0.3408 
2025-01-08 23:15:46.393898: val_loss -0.3095 
2025-01-08 23:15:46.401415: Pseudo dice [np.float32(0.6192), np.float32(0.2138)] 
2025-01-08 23:15:46.404924: Epoch time: 40.79 s 
2025-01-08 23:15:46.952289:  
2025-01-08 23:15:46.953293: Epoch 91 
2025-01-08 23:15:46.958341: Current learning rate: 0.00665 
2025-01-08 23:16:27.756092: train_loss -0.3269 
2025-01-08 23:16:27.756606: val_loss -0.3541 
2025-01-08 23:16:27.762145: Pseudo dice [np.float32(0.6361), np.float32(0.3288)] 
2025-01-08 23:16:27.766155: Epoch time: 40.8 s 
2025-01-08 23:16:28.324315:  
2025-01-08 23:16:28.324315: Epoch 92 
2025-01-08 23:16:28.329904: Current learning rate: 0.00662 
2025-01-08 23:17:09.129653: train_loss -0.3031 
2025-01-08 23:17:09.130156: val_loss -0.3859 
2025-01-08 23:17:09.137176: Pseudo dice [np.float32(0.6831), np.float32(0.3937)] 
2025-01-08 23:17:09.141196: Epoch time: 40.81 s 
2025-01-08 23:17:09.683116:  
2025-01-08 23:17:09.684621: Epoch 93 
2025-01-08 23:17:09.690642: Current learning rate: 0.00658 
2025-01-08 23:17:50.466857: train_loss -0.3115 
2025-01-08 23:17:50.467857: val_loss -0.355 
2025-01-08 23:17:50.474375: Pseudo dice [np.float32(0.6918), np.float32(0.2466)] 
2025-01-08 23:17:50.479388: Epoch time: 40.78 s 
2025-01-08 23:17:51.022252:  
2025-01-08 23:17:51.022252: Epoch 94 
2025-01-08 23:17:51.028271: Current learning rate: 0.00654 
2025-01-08 23:18:31.834614: train_loss -0.3009 
2025-01-08 23:18:31.835118: val_loss -0.3579 
2025-01-08 23:18:31.841716: Pseudo dice [np.float32(0.6512), np.float32(0.3355)] 
2025-01-08 23:18:31.844800: Epoch time: 40.81 s 
2025-01-08 23:18:32.587145:  
2025-01-08 23:18:32.588145: Epoch 95 
2025-01-08 23:18:32.593763: Current learning rate: 0.0065 
2025-01-08 23:19:13.373724: train_loss -0.3352 
2025-01-08 23:19:13.373724: val_loss -0.3396 
2025-01-08 23:19:13.380240: Pseudo dice [np.float32(0.6424), np.float32(0.2898)] 
2025-01-08 23:19:13.385253: Epoch time: 40.79 s 
2025-01-08 23:19:13.926029:  
2025-01-08 23:19:13.926029: Epoch 96 
2025-01-08 23:19:13.932604: Current learning rate: 0.00647 
2025-01-08 23:19:54.742548: train_loss -0.3364 
2025-01-08 23:19:54.743062: val_loss -0.3877 
2025-01-08 23:19:54.748647: Pseudo dice [np.float32(0.6471), np.float32(0.3358)] 
2025-01-08 23:19:54.751705: Epoch time: 40.82 s 
2025-01-08 23:19:55.310272:  
2025-01-08 23:19:55.310272: Epoch 97 
2025-01-08 23:19:55.315311: Current learning rate: 0.00643 
2025-01-08 23:20:36.104971: train_loss -0.3292 
2025-01-08 23:20:36.104971: val_loss -0.3852 
2025-01-08 23:20:36.112056: Pseudo dice [np.float32(0.709), np.float32(0.4316)] 
2025-01-08 23:20:36.115568: Epoch time: 40.8 s 
2025-01-08 23:20:36.119603: Yayy! New best EMA pseudo Dice: 0.48809999227523804 
2025-01-08 23:20:36.881453:  
2025-01-08 23:20:36.881453: Epoch 98 
2025-01-08 23:20:36.887015: Current learning rate: 0.00639 
2025-01-08 23:21:17.678822: train_loss -0.3289 
2025-01-08 23:21:17.679325: val_loss -0.4385 
2025-01-08 23:21:17.684904: Pseudo dice [np.float32(0.6823), np.float32(0.3788)] 
2025-01-08 23:21:17.689441: Epoch time: 40.8 s 
2025-01-08 23:21:17.692950: Yayy! New best EMA pseudo Dice: 0.49239999055862427 
2025-01-08 23:21:18.432640:  
2025-01-08 23:21:18.433644: Epoch 99 
2025-01-08 23:21:18.440181: Current learning rate: 0.00635 
2025-01-08 23:21:59.241803: train_loss -0.3369 
2025-01-08 23:21:59.242808: val_loss -0.3567 
2025-01-08 23:21:59.250324: Pseudo dice [np.float32(0.6629), np.float32(0.3837)] 
2025-01-08 23:21:59.254335: Epoch time: 40.81 s 
2025-01-08 23:21:59.413217: Yayy! New best EMA pseudo Dice: 0.49549999833106995 
2025-01-08 23:22:00.251215:  
2025-01-08 23:22:00.251718: Epoch 100 
2025-01-08 23:22:00.257731: Current learning rate: 0.00631 
2025-01-08 23:22:41.052407: train_loss -0.3248 
2025-01-08 23:22:41.053410: val_loss -0.3611 
2025-01-08 23:22:41.059432: Pseudo dice [np.float32(0.6869), np.float32(0.2889)] 
2025-01-08 23:22:41.063448: Epoch time: 40.8 s 
2025-01-08 23:22:41.609965:  
2025-01-08 23:22:41.609965: Epoch 101 
2025-01-08 23:22:41.615017: Current learning rate: 0.00628 
2025-01-08 23:23:22.485644: train_loss -0.3411 
2025-01-08 23:23:22.486649: val_loss -0.395 
2025-01-08 23:23:22.493731: Pseudo dice [np.float32(0.63), np.float32(0.3793)] 
2025-01-08 23:23:22.497758: Epoch time: 40.88 s 
2025-01-08 23:23:22.501297: Yayy! New best EMA pseudo Dice: 0.49570000171661377 
2025-01-08 23:23:23.375871:  
2025-01-08 23:23:23.376374: Epoch 102 
2025-01-08 23:23:23.382387: Current learning rate: 0.00624 
2025-01-08 23:24:04.165845: train_loss -0.3486 
2025-01-08 23:24:04.166350: val_loss -0.405 
2025-01-08 23:24:04.172365: Pseudo dice [np.float32(0.6824), np.float32(0.3401)] 
2025-01-08 23:24:04.174871: Epoch time: 40.79 s 
2025-01-08 23:24:04.178880: Yayy! New best EMA pseudo Dice: 0.49720001220703125 
2025-01-08 23:24:05.142955:  
2025-01-08 23:24:05.142955: Epoch 103 
2025-01-08 23:24:05.148975: Current learning rate: 0.0062 
2025-01-08 23:24:45.920890: train_loss -0.3693 
2025-01-08 23:24:45.921896: val_loss -0.4044 
2025-01-08 23:24:45.927907: Pseudo dice [np.float32(0.7218), np.float32(0.3541)] 
2025-01-08 23:24:45.931919: Epoch time: 40.78 s 
2025-01-08 23:24:45.934424: Yayy! New best EMA pseudo Dice: 0.5012999773025513 
2025-01-08 23:24:46.671444:  
2025-01-08 23:24:46.672443: Epoch 104 
2025-01-08 23:24:46.676990: Current learning rate: 0.00616 
2025-01-08 23:25:27.461416: train_loss -0.3465 
2025-01-08 23:25:27.462420: val_loss -0.3731 
2025-01-08 23:25:27.468933: Pseudo dice [np.float32(0.6746), np.float32(0.2877)] 
2025-01-08 23:25:27.472443: Epoch time: 40.79 s 
2025-01-08 23:25:28.022256:  
2025-01-08 23:25:28.023260: Epoch 105 
2025-01-08 23:25:28.029676: Current learning rate: 0.00612 
2025-01-08 23:26:08.809965: train_loss -0.3387 
2025-01-08 23:26:08.811467: val_loss -0.3379 
2025-01-08 23:26:08.818483: Pseudo dice [np.float32(0.6893), np.float32(0.2263)] 
2025-01-08 23:26:08.821492: Epoch time: 40.79 s 
2025-01-08 23:26:09.377647:  
2025-01-08 23:26:09.377647: Epoch 106 
2025-01-08 23:26:09.382657: Current learning rate: 0.00609 
2025-01-08 23:26:50.199446: train_loss -0.3177 
2025-01-08 23:26:50.200446: val_loss -0.3992 
2025-01-08 23:26:50.205968: Pseudo dice [np.float32(0.6234), np.float32(0.3518)] 
2025-01-08 23:26:50.211019: Epoch time: 40.82 s 
2025-01-08 23:26:50.782891:  
2025-01-08 23:26:50.783393: Epoch 107 
2025-01-08 23:26:50.789408: Current learning rate: 0.00605 
2025-01-08 23:27:31.598212: train_loss -0.3279 
2025-01-08 23:27:31.599217: val_loss -0.3492 
2025-01-08 23:27:31.605861: Pseudo dice [np.float32(0.6782), np.float32(0.2271)] 
2025-01-08 23:27:31.610876: Epoch time: 40.82 s 
2025-01-08 23:27:32.192253:  
2025-01-08 23:27:32.193253: Epoch 108 
2025-01-08 23:27:32.199774: Current learning rate: 0.00601 
2025-01-08 23:28:12.990101: train_loss -0.3534 
2025-01-08 23:28:12.990605: val_loss -0.3713 
2025-01-08 23:28:12.996626: Pseudo dice [np.float32(0.6829), np.float32(0.2522)] 
2025-01-08 23:28:13.001642: Epoch time: 40.8 s 
2025-01-08 23:28:13.561323:  
2025-01-08 23:28:13.562826: Epoch 109 
2025-01-08 23:28:13.567838: Current learning rate: 0.00597 
2025-01-08 23:28:54.363071: train_loss -0.3679 
2025-01-08 23:28:54.364074: val_loss -0.4237 
2025-01-08 23:28:54.370589: Pseudo dice [np.float32(0.6955), np.float32(0.4611)] 
2025-01-08 23:28:54.374099: Epoch time: 40.8 s 
2025-01-08 23:28:54.928236:  
2025-01-08 23:28:54.928236: Epoch 110 
2025-01-08 23:28:54.934275: Current learning rate: 0.00593 
2025-01-08 23:29:35.713661: train_loss -0.3321 
2025-01-08 23:29:35.715168: val_loss -0.4254 
2025-01-08 23:29:35.721707: Pseudo dice [np.float32(0.6927), np.float32(0.3657)] 
2025-01-08 23:29:35.725715: Epoch time: 40.79 s 
2025-01-08 23:29:36.277657:  
2025-01-08 23:29:36.278656: Epoch 111 
2025-01-08 23:29:36.284250: Current learning rate: 0.0059 
2025-01-08 23:30:17.086043: train_loss -0.362 
2025-01-08 23:30:17.087046: val_loss -0.3857 
2025-01-08 23:30:17.093560: Pseudo dice [np.float32(0.708), np.float32(0.3134)] 
2025-01-08 23:30:17.097070: Epoch time: 40.81 s 
2025-01-08 23:30:17.829305:  
2025-01-08 23:30:17.830307: Epoch 112 
2025-01-08 23:30:17.835318: Current learning rate: 0.00586 
2025-01-08 23:30:58.639219: train_loss -0.3419 
2025-01-08 23:30:58.639219: val_loss -0.3613 
2025-01-08 23:30:58.647288: Pseudo dice [np.float32(0.6784), np.float32(0.3829)] 
2025-01-08 23:30:58.651299: Epoch time: 40.81 s 
2025-01-08 23:30:58.655809: Yayy! New best EMA pseudo Dice: 0.5041999816894531 
2025-01-08 23:30:59.382900:  
2025-01-08 23:30:59.383903: Epoch 113 
2025-01-08 23:30:59.389922: Current learning rate: 0.00582 
2025-01-08 23:31:46.194245: train_loss -0.3325 
2025-01-08 23:31:46.194245: val_loss -0.3215 
2025-01-08 23:31:46.200259: Pseudo dice [np.float32(0.5999), np.float32(0.3312)] 
2025-01-08 23:31:46.205277: Epoch time: 46.81 s 
2025-01-08 23:31:46.736334:  
2025-01-08 23:31:46.736334: Epoch 114 
2025-01-08 23:31:46.742855: Current learning rate: 0.00578 
2025-01-08 23:32:27.688285: train_loss -0.3386 
2025-01-08 23:32:27.688285: val_loss -0.3689 
2025-01-08 23:32:27.695175: Pseudo dice [np.float32(0.6613), np.float32(0.3658)] 
2025-01-08 23:32:27.700192: Epoch time: 40.95 s 
2025-01-08 23:32:28.241964:  
2025-01-08 23:32:28.242968: Epoch 115 
2025-01-08 23:32:28.249091: Current learning rate: 0.00574 
2025-01-08 23:33:09.258116: train_loss -0.3581 
2025-01-08 23:33:09.258116: val_loss -0.3443 
2025-01-08 23:33:09.265130: Pseudo dice [np.float32(0.6662), np.float32(0.2388)] 
2025-01-08 23:33:09.269645: Epoch time: 41.02 s 
2025-01-08 23:33:09.799016:  
2025-01-08 23:33:09.799016: Epoch 116 
2025-01-08 23:33:09.805559: Current learning rate: 0.0057 
2025-01-08 23:33:50.791853: train_loss -0.3927 
2025-01-08 23:33:50.792857: val_loss -0.4083 
2025-01-08 23:33:50.799098: Pseudo dice [np.float32(0.6862), np.float32(0.4196)] 
2025-01-08 23:33:50.805656: Epoch time: 40.99 s 
2025-01-08 23:33:51.340326:  
2025-01-08 23:33:51.340828: Epoch 117 
2025-01-08 23:33:51.346854: Current learning rate: 0.00567 
2025-01-08 23:34:32.331419: train_loss -0.3776 
2025-01-08 23:34:32.331419: val_loss -0.4399 
2025-01-08 23:34:32.338933: Pseudo dice [np.float32(0.6714), np.float32(0.4541)] 
2025-01-08 23:34:32.344956: Epoch time: 40.99 s 
2025-01-08 23:34:32.348720: Yayy! New best EMA pseudo Dice: 0.508400022983551 
2025-01-08 23:34:33.056363:  
2025-01-08 23:34:33.057362: Epoch 118 
2025-01-08 23:34:33.063879: Current learning rate: 0.00563 
2025-01-08 23:35:14.012295: train_loss -0.339 
2025-01-08 23:35:14.013300: val_loss -0.3819 
2025-01-08 23:35:14.019812: Pseudo dice [np.float32(0.6648), np.float32(0.3471)] 
2025-01-08 23:35:14.024923: Epoch time: 40.96 s 
2025-01-08 23:35:14.564731:  
2025-01-08 23:35:14.564731: Epoch 119 
2025-01-08 23:35:14.570283: Current learning rate: 0.00559 
2025-01-08 23:35:55.529314: train_loss -0.3838 
2025-01-08 23:35:55.530317: val_loss -0.4528 
2025-01-08 23:35:55.536466: Pseudo dice [np.float32(0.7126), np.float32(0.4169)] 
2025-01-08 23:35:55.539577: Epoch time: 40.96 s 
2025-01-08 23:35:55.544186: Yayy! New best EMA pseudo Dice: 0.5138000249862671 
2025-01-08 23:35:56.524315:  
2025-01-08 23:35:56.525315: Epoch 120 
2025-01-08 23:35:56.530912: Current learning rate: 0.00555 
2025-01-08 23:36:37.611576: train_loss -0.3574 
2025-01-08 23:36:37.612579: val_loss -0.4099 
2025-01-08 23:36:37.620098: Pseudo dice [np.float32(0.6728), np.float32(0.4642)] 
2025-01-08 23:36:37.625619: Epoch time: 41.09 s 
2025-01-08 23:36:37.630632: Yayy! New best EMA pseudo Dice: 0.5192999839782715 
2025-01-08 23:36:38.432838:  
2025-01-08 23:36:38.433841: Epoch 121 
2025-01-08 23:36:38.439897: Current learning rate: 0.00551 
2025-01-08 23:37:19.373741: train_loss -0.3476 
2025-01-08 23:37:19.373741: val_loss -0.3987 
2025-01-08 23:37:19.381256: Pseudo dice [np.float32(0.6838), np.float32(0.2829)] 
2025-01-08 23:37:19.387278: Epoch time: 40.94 s 
2025-01-08 23:37:19.925426:  
2025-01-08 23:37:19.925426: Epoch 122 
2025-01-08 23:37:19.931987: Current learning rate: 0.00547 
2025-01-08 23:38:00.873378: train_loss -0.3534 
2025-01-08 23:38:00.873881: val_loss -0.4303 
2025-01-08 23:38:00.880895: Pseudo dice [np.float32(0.7209), np.float32(0.4007)] 
2025-01-08 23:38:00.885910: Epoch time: 40.95 s 
2025-01-08 23:38:00.888918: Yayy! New best EMA pseudo Dice: 0.5202000141143799 
2025-01-08 23:38:01.609202:  
2025-01-08 23:38:01.609202: Epoch 123 
2025-01-08 23:38:01.615724: Current learning rate: 0.00544 
2025-01-08 23:38:42.567536: train_loss -0.3408 
2025-01-08 23:38:42.567536: val_loss -0.4175 
2025-01-08 23:38:42.575050: Pseudo dice [np.float32(0.7022), np.float32(0.3996)] 
2025-01-08 23:38:42.580070: Epoch time: 40.96 s 
2025-01-08 23:38:42.586099: Yayy! New best EMA pseudo Dice: 0.5232999920845032 
2025-01-08 23:38:43.323168:  
2025-01-08 23:38:43.324168: Epoch 124 
2025-01-08 23:38:43.329748: Current learning rate: 0.0054 
2025-01-08 23:39:24.271748: train_loss -0.3851 
2025-01-08 23:39:24.271748: val_loss -0.391 
2025-01-08 23:39:24.279278: Pseudo dice [np.float32(0.6879), np.float32(0.3755)] 
2025-01-08 23:39:24.283288: Epoch time: 40.95 s 
2025-01-08 23:39:24.286796: Yayy! New best EMA pseudo Dice: 0.5241000056266785 
2025-01-08 23:39:25.077662:  
2025-01-08 23:39:25.077662: Epoch 125 
2025-01-08 23:39:25.084230: Current learning rate: 0.00536 
2025-01-08 23:40:06.047186: train_loss -0.3676 
2025-01-08 23:40:06.048190: val_loss -0.4111 
2025-01-08 23:40:06.054712: Pseudo dice [np.float32(0.6807), np.float32(0.3324)] 
2025-01-08 23:40:06.059740: Epoch time: 40.97 s 
2025-01-08 23:40:06.590604:  
2025-01-08 23:40:06.591106: Epoch 126 
2025-01-08 23:40:06.597130: Current learning rate: 0.00532 
2025-01-08 23:40:47.566507: train_loss -0.364 
2025-01-08 23:40:47.567010: val_loss -0.4583 
2025-01-08 23:40:47.573608: Pseudo dice [np.float32(0.7194), np.float32(0.356)] 
2025-01-08 23:40:47.577168: Epoch time: 40.98 s 
2025-01-08 23:40:48.109539:  
2025-01-08 23:40:48.109539: Epoch 127 
2025-01-08 23:40:48.115577: Current learning rate: 0.00528 
2025-01-08 23:41:29.043867: train_loss -0.3846 
2025-01-08 23:41:29.044872: val_loss -0.4382 
2025-01-08 23:41:29.051385: Pseudo dice [np.float32(0.7221), np.float32(0.4067)] 
2025-01-08 23:41:29.057400: Epoch time: 40.94 s 
2025-01-08 23:41:29.060904: Yayy! New best EMA pseudo Dice: 0.527899980545044 
2025-01-08 23:41:30.057290:  
2025-01-08 23:41:30.057290: Epoch 128 
2025-01-08 23:41:30.063813: Current learning rate: 0.00524 
2025-01-08 23:42:10.862705: train_loss -0.388 
2025-01-08 23:42:10.862705: val_loss -0.366 
2025-01-08 23:42:10.870301: Pseudo dice [np.float32(0.6759), np.float32(0.3082)] 
2025-01-08 23:42:10.875412: Epoch time: 40.81 s 
2025-01-08 23:42:11.430932:  
2025-01-08 23:42:11.430932: Epoch 129 
2025-01-08 23:42:11.437081: Current learning rate: 0.0052 
2025-01-08 23:42:52.261133: train_loss -0.3562 
2025-01-08 23:42:52.261645: val_loss -0.3664 
2025-01-08 23:42:52.267728: Pseudo dice [np.float32(0.6965), np.float32(0.3926)] 
2025-01-08 23:42:52.270234: Epoch time: 40.83 s 
2025-01-08 23:42:52.819836:  
2025-01-08 23:42:52.819836: Epoch 130 
2025-01-08 23:42:52.825850: Current learning rate: 0.00517 
2025-01-08 23:43:33.572588: train_loss -0.3767 
2025-01-08 23:43:33.572588: val_loss -0.4115 
2025-01-08 23:43:33.578673: Pseudo dice [np.float32(0.7031), np.float32(0.3753)] 
2025-01-08 23:43:33.582185: Epoch time: 40.75 s 
2025-01-08 23:43:34.118890:  
2025-01-08 23:43:34.119392: Epoch 131 
2025-01-08 23:43:34.125415: Current learning rate: 0.00513 
2025-01-08 23:44:14.879212: train_loss -0.3593 
2025-01-08 23:44:14.879715: val_loss -0.4317 
2025-01-08 23:44:14.888235: Pseudo dice [np.float32(0.6914), np.float32(0.5182)] 
2025-01-08 23:44:14.895752: Epoch time: 40.76 s 
2025-01-08 23:44:14.899257: Yayy! New best EMA pseudo Dice: 0.5353999733924866 
2025-01-08 23:44:15.661536:  
2025-01-08 23:44:15.661536: Epoch 132 
2025-01-08 23:44:15.667097: Current learning rate: 0.00509 
2025-01-08 23:44:56.431878: train_loss -0.3558 
2025-01-08 23:44:56.432381: val_loss -0.3834 
2025-01-08 23:44:56.438620: Pseudo dice [np.float32(0.6775), np.float32(0.3643)] 
2025-01-08 23:44:56.441130: Epoch time: 40.77 s 
2025-01-08 23:44:56.972774:  
2025-01-08 23:44:56.972774: Epoch 133 
2025-01-08 23:44:56.978432: Current learning rate: 0.00505 
2025-01-08 23:45:37.734669: train_loss -0.3635 
2025-01-08 23:45:37.734669: val_loss -0.3728 
2025-01-08 23:45:37.741822: Pseudo dice [np.float32(0.661), np.float32(0.3011)] 
2025-01-08 23:45:37.745335: Epoch time: 40.76 s 
2025-01-08 23:45:38.296017:  
2025-01-08 23:45:38.296017: Epoch 134 
2025-01-08 23:45:38.301028: Current learning rate: 0.00501 
2025-01-08 23:46:19.062991: train_loss -0.3902 
2025-01-08 23:46:19.063495: val_loss -0.3736 
2025-01-08 23:46:19.068534: Pseudo dice [np.float32(0.7029), np.float32(0.3702)] 
2025-01-08 23:46:19.072044: Epoch time: 40.77 s 
2025-01-08 23:46:19.605743:  
2025-01-08 23:46:19.605743: Epoch 135 
2025-01-08 23:46:19.611302: Current learning rate: 0.00497 
2025-01-08 23:47:00.396619: train_loss -0.3809 
2025-01-08 23:47:00.396619: val_loss -0.4084 
2025-01-08 23:47:00.403134: Pseudo dice [np.float32(0.7084), np.float32(0.3594)] 
2025-01-08 23:47:00.408145: Epoch time: 40.79 s 
2025-01-08 23:47:01.175035:  
2025-01-08 23:47:01.175035: Epoch 136 
2025-01-08 23:47:01.181694: Current learning rate: 0.00493 
2025-01-08 23:47:41.984410: train_loss -0.3951 
2025-01-08 23:47:41.985413: val_loss -0.4086 
2025-01-08 23:47:41.990493: Pseudo dice [np.float32(0.7016), np.float32(0.296)] 
2025-01-08 23:47:41.994627: Epoch time: 40.81 s 
2025-01-08 23:47:42.544158:  
2025-01-08 23:47:42.545163: Epoch 137 
2025-01-08 23:47:42.549707: Current learning rate: 0.00489 
2025-01-08 23:48:23.402649: train_loss -0.3931 
2025-01-08 23:48:23.403151: val_loss -0.4288 
2025-01-08 23:48:23.409212: Pseudo dice [np.float32(0.7338), np.float32(0.3238)] 
2025-01-08 23:48:23.412734: Epoch time: 40.86 s 
2025-01-08 23:48:23.965251:  
2025-01-08 23:48:23.965755: Epoch 138 
2025-01-08 23:48:23.970764: Current learning rate: 0.00485 
2025-01-08 23:49:04.825749: train_loss -0.3951 
2025-01-08 23:49:04.826254: val_loss -0.42 
2025-01-08 23:49:04.831271: Pseudo dice [np.float32(0.7458), np.float32(0.3328)] 
2025-01-08 23:49:04.835783: Epoch time: 40.86 s 
2025-01-08 23:49:05.388267:  
2025-01-08 23:49:05.388267: Epoch 139 
2025-01-08 23:49:05.393322: Current learning rate: 0.00482 
2025-01-08 23:49:46.228536: train_loss -0.3843 
2025-01-08 23:49:46.229537: val_loss -0.4649 
2025-01-08 23:49:46.235054: Pseudo dice [np.float32(0.7507), np.float32(0.5554)] 
2025-01-08 23:49:46.238563: Epoch time: 40.84 s 
2025-01-08 23:49:46.242572: Yayy! New best EMA pseudo Dice: 0.5407000184059143 
2025-01-08 23:49:46.999087:  
2025-01-08 23:49:47.000091: Epoch 140 
2025-01-08 23:49:47.004622: Current learning rate: 0.00478 
2025-01-08 23:50:27.858268: train_loss -0.3952 
2025-01-08 23:50:27.858268: val_loss -0.4004 
2025-01-08 23:50:27.864782: Pseudo dice [np.float32(0.6859), np.float32(0.4037)] 
2025-01-08 23:50:27.869291: Epoch time: 40.86 s 
2025-01-08 23:50:27.873302: Yayy! New best EMA pseudo Dice: 0.541100025177002 
2025-01-08 23:50:28.678401:  
2025-01-08 23:50:28.678401: Epoch 141 
2025-01-08 23:50:28.684491: Current learning rate: 0.00474 
2025-01-08 23:51:09.534725: train_loss -0.3577 
2025-01-08 23:51:09.535240: val_loss -0.374 
2025-01-08 23:51:09.541418: Pseudo dice [np.float32(0.6841), np.float32(0.3485)] 
2025-01-08 23:51:09.544445: Epoch time: 40.86 s 
2025-01-08 23:51:10.103718:  
2025-01-08 23:51:10.103718: Epoch 142 
2025-01-08 23:51:10.110735: Current learning rate: 0.0047 
2025-01-08 23:51:50.950034: train_loss -0.4004 
2025-01-08 23:51:50.950034: val_loss -0.4336 
2025-01-08 23:51:50.956071: Pseudo dice [np.float32(0.7114), np.float32(0.4276)] 
2025-01-08 23:51:50.960594: Epoch time: 40.85 s 
2025-01-08 23:51:50.964169: Yayy! New best EMA pseudo Dice: 0.541700005531311 
2025-01-08 23:51:51.710383:  
2025-01-08 23:51:51.710383: Epoch 143 
2025-01-08 23:51:51.715941: Current learning rate: 0.00466 
2025-01-08 23:52:32.552057: train_loss -0.4093 
2025-01-08 23:52:32.553063: val_loss -0.4404 
2025-01-08 23:52:32.559578: Pseudo dice [np.float32(0.7217), np.float32(0.427)] 
2025-01-08 23:52:32.563087: Epoch time: 40.84 s 
2025-01-08 23:52:32.566604: Yayy! New best EMA pseudo Dice: 0.5450000166893005 
2025-01-08 23:52:33.350532:  
2025-01-08 23:52:33.351035: Epoch 144 
2025-01-08 23:52:33.358088: Current learning rate: 0.00462 
2025-01-08 23:53:14.171020: train_loss -0.3829 
2025-01-08 23:53:14.171020: val_loss -0.3933 
2025-01-08 23:53:14.177536: Pseudo dice [np.float32(0.7079), np.float32(0.324)] 
2025-01-08 23:53:14.181047: Epoch time: 40.82 s 
2025-01-08 23:53:14.896431:  
2025-01-08 23:53:14.896431: Epoch 145 
2025-01-08 23:53:14.901994: Current learning rate: 0.00458 
2025-01-08 23:53:55.747137: train_loss -0.4223 
2025-01-08 23:53:55.747137: val_loss -0.4483 
2025-01-08 23:53:55.754655: Pseudo dice [np.float32(0.7548), np.float32(0.3319)] 
2025-01-08 23:53:55.761173: Epoch time: 40.85 s 
2025-01-08 23:53:56.306415:  
2025-01-08 23:53:56.307414: Epoch 146 
2025-01-08 23:53:56.312426: Current learning rate: 0.00454 
2025-01-08 23:54:37.161234: train_loss -0.4003 
2025-01-08 23:54:37.162237: val_loss -0.4475 
2025-01-08 23:54:37.168901: Pseudo dice [np.float32(0.7302), np.float32(0.5071)] 
2025-01-08 23:54:37.172911: Epoch time: 40.85 s 
2025-01-08 23:54:37.177421: Yayy! New best EMA pseudo Dice: 0.5497999787330627 
2025-01-08 23:54:37.983536:  
2025-01-08 23:54:37.984536: Epoch 147 
2025-01-08 23:54:37.990131: Current learning rate: 0.0045 
2025-01-08 23:55:18.813402: train_loss -0.4014 
2025-01-08 23:55:18.814405: val_loss -0.4243 
2025-01-08 23:55:18.820421: Pseudo dice [np.float32(0.7098), np.float32(0.4413)] 
2025-01-08 23:55:18.825437: Epoch time: 40.83 s 
2025-01-08 23:55:18.829449: Yayy! New best EMA pseudo Dice: 0.5523999929428101 
2025-01-08 23:55:19.617640:  
2025-01-08 23:55:19.618640: Epoch 148 
2025-01-08 23:55:19.623653: Current learning rate: 0.00446 
2025-01-08 23:56:00.445554: train_loss -0.4085 
2025-01-08 23:56:00.446553: val_loss -0.4075 
2025-01-08 23:56:00.453070: Pseudo dice [np.float32(0.7794), np.float32(0.3817)] 
2025-01-08 23:56:00.458085: Epoch time: 40.83 s 
2025-01-08 23:56:00.462094: Yayy! New best EMA pseudo Dice: 0.5551999807357788 
2025-01-08 23:56:01.271270:  
2025-01-08 23:56:01.272276: Epoch 149 
2025-01-08 23:56:01.276834: Current learning rate: 0.00442 
2025-01-08 23:56:42.109695: train_loss -0.3687 
2025-01-08 23:56:42.110199: val_loss -0.4199 
2025-01-08 23:56:42.116220: Pseudo dice [np.float32(0.692), np.float32(0.4153)] 
2025-01-08 23:56:42.120232: Epoch time: 40.84 s 
2025-01-08 23:56:42.854476:  
2025-01-08 23:56:42.855476: Epoch 150 
2025-01-08 23:56:42.861064: Current learning rate: 0.00438 
2025-01-08 23:57:23.708443: train_loss -0.4115 
2025-01-08 23:57:23.708950: val_loss -0.4179 
2025-01-08 23:57:23.717210: Pseudo dice [np.float32(0.7235), np.float32(0.3537)] 
2025-01-08 23:57:23.722247: Epoch time: 40.85 s 
2025-01-08 23:57:24.270219:  
2025-01-08 23:57:24.270219: Epoch 151 
2025-01-08 23:57:24.275230: Current learning rate: 0.00434 
2025-01-08 23:58:05.094004: train_loss -0.3978 
2025-01-08 23:58:05.094004: val_loss -0.4394 
2025-01-08 23:58:05.101025: Pseudo dice [np.float32(0.7244), np.float32(0.3936)] 
2025-01-08 23:58:05.106039: Epoch time: 40.83 s 
2025-01-08 23:58:05.660466:  
2025-01-08 23:58:05.660466: Epoch 152 
2025-01-08 23:58:05.667142: Current learning rate: 0.0043 
2025-01-08 23:58:46.519956: train_loss -0.4143 
2025-01-08 23:58:46.519956: val_loss -0.4509 
2025-01-08 23:58:46.526476: Pseudo dice [np.float32(0.7149), np.float32(0.437)] 
2025-01-08 23:58:46.529989: Epoch time: 40.86 s 
2025-01-08 23:58:46.536003: Yayy! New best EMA pseudo Dice: 0.5562000274658203 
2025-01-08 23:58:47.555545:  
2025-01-08 23:58:47.555545: Epoch 153 
2025-01-08 23:58:47.562126: Current learning rate: 0.00427 
2025-01-08 23:59:28.399313: train_loss -0.4126 
2025-01-08 23:59:28.400825: val_loss -0.4397 
2025-01-08 23:59:28.406987: Pseudo dice [np.float32(0.7029), np.float32(0.3935)] 
2025-01-08 23:59:28.411539: Epoch time: 40.84 s 
2025-01-08 23:59:29.003897:  
2025-01-08 23:59:29.004902: Epoch 154 
2025-01-08 23:59:29.010421: Current learning rate: 0.00423 
2025-01-09 00:00:09.840225: train_loss -0.4042 
2025-01-09 00:00:09.840225: val_loss -0.422 
2025-01-09 00:00:09.846235: Pseudo dice [np.float32(0.7444), np.float32(0.4888)] 
2025-01-09 00:00:09.850256: Epoch time: 40.84 s 
2025-01-09 00:00:09.854260: Yayy! New best EMA pseudo Dice: 0.5615000128746033 
2025-01-09 00:00:10.664014:  
2025-01-09 00:00:10.664014: Epoch 155 
2025-01-09 00:00:10.670028: Current learning rate: 0.00419 
2025-01-09 00:00:51.521646: train_loss -0.421 
2025-01-09 00:00:51.522651: val_loss -0.4291 
2025-01-09 00:00:51.527966: Pseudo dice [np.float32(0.7307), np.float32(0.2561)] 
2025-01-09 00:00:51.531509: Epoch time: 40.86 s 
2025-01-09 00:00:52.085128:  
2025-01-09 00:00:52.085128: Epoch 156 
2025-01-09 00:00:52.090160: Current learning rate: 0.00415 
2025-01-09 00:01:32.913125: train_loss -0.421 
2025-01-09 00:01:32.914125: val_loss -0.4161 
2025-01-09 00:01:32.920642: Pseudo dice [np.float32(0.7319), np.float32(0.4228)] 
2025-01-09 00:01:32.925659: Epoch time: 40.83 s 
2025-01-09 00:01:33.494911:  
2025-01-09 00:01:33.495413: Epoch 157 
2025-01-09 00:01:33.500424: Current learning rate: 0.00411 
2025-01-09 00:02:14.335900: train_loss -0.3933 
2025-01-09 00:02:14.335900: val_loss -0.4074 
2025-01-09 00:02:14.341972: Pseudo dice [np.float32(0.7021), np.float32(0.3233)] 
2025-01-09 00:02:14.345580: Epoch time: 40.84 s 
2025-01-09 00:02:14.914241:  
2025-01-09 00:02:14.914752: Epoch 158 
2025-01-09 00:02:14.920332: Current learning rate: 0.00407 
2025-01-09 00:02:55.800207: train_loss -0.4059 
2025-01-09 00:02:55.800732: val_loss -0.4001 
2025-01-09 00:02:55.806780: Pseudo dice [np.float32(0.6618), np.float32(0.2533)] 
2025-01-09 00:02:55.809289: Epoch time: 40.89 s 
2025-01-09 00:02:56.376865:  
2025-01-09 00:02:56.376865: Epoch 159 
2025-01-09 00:02:56.383391: Current learning rate: 0.00403 
2025-01-09 00:03:37.245914: train_loss -0.396 
2025-01-09 00:03:37.245914: val_loss -0.5039 
2025-01-09 00:03:37.251930: Pseudo dice [np.float32(0.74), np.float32(0.5172)] 
2025-01-09 00:03:37.255939: Epoch time: 40.87 s 
2025-01-09 00:03:37.968995:  
2025-01-09 00:03:37.968995: Epoch 160 
2025-01-09 00:03:37.973554: Current learning rate: 0.00399 
2025-01-09 00:04:18.807466: train_loss -0.4026 
2025-01-09 00:04:18.808471: val_loss -0.3878 
2025-01-09 00:04:18.814062: Pseudo dice [np.float32(0.7173), np.float32(0.3466)] 
2025-01-09 00:04:18.817166: Epoch time: 40.84 s 
2025-01-09 00:04:19.376726:  
2025-01-09 00:04:19.377731: Epoch 161 
2025-01-09 00:04:19.383791: Current learning rate: 0.00395 
2025-01-09 00:05:00.226222: train_loss -0.4134 
2025-01-09 00:05:00.226724: val_loss -0.414 
2025-01-09 00:05:00.232744: Pseudo dice [np.float32(0.7029), np.float32(0.3566)] 
2025-01-09 00:05:00.236753: Epoch time: 40.85 s 
2025-01-09 00:05:00.807523:  
2025-01-09 00:05:00.808026: Epoch 162 
2025-01-09 00:05:00.813128: Current learning rate: 0.00391 
2025-01-09 00:05:41.655983: train_loss -0.4101 
2025-01-09 00:05:41.656984: val_loss -0.4256 
2025-01-09 00:05:41.663506: Pseudo dice [np.float32(0.7302), np.float32(0.3165)] 
2025-01-09 00:05:41.668524: Epoch time: 40.85 s 
2025-01-09 00:05:42.236295:  
2025-01-09 00:05:42.236798: Epoch 163 
2025-01-09 00:05:42.241813: Current learning rate: 0.00387 
2025-01-09 00:06:23.060728: train_loss -0.4223 
2025-01-09 00:06:23.061231: val_loss -0.3877 
2025-01-09 00:06:23.067244: Pseudo dice [np.float32(0.6765), np.float32(0.2461)] 
2025-01-09 00:06:23.072254: Epoch time: 40.83 s 
2025-01-09 00:06:23.677357:  
2025-01-09 00:06:23.677357: Epoch 164 
2025-01-09 00:06:23.682384: Current learning rate: 0.00383 
2025-01-09 00:07:04.508246: train_loss -0.4159 
2025-01-09 00:07:04.509247: val_loss -0.4914 
2025-01-09 00:07:04.515765: Pseudo dice [np.float32(0.7309), np.float32(0.5191)] 
2025-01-09 00:07:04.519773: Epoch time: 40.83 s 
2025-01-09 00:07:05.063878:  
2025-01-09 00:07:05.063878: Epoch 165 
2025-01-09 00:07:05.068429: Current learning rate: 0.00379 
2025-01-09 00:07:45.905869: train_loss -0.4065 
2025-01-09 00:07:45.906869: val_loss -0.4015 
2025-01-09 00:07:45.912384: Pseudo dice [np.float32(0.754), np.float32(0.4019)] 
2025-01-09 00:07:45.916896: Epoch time: 40.84 s 
2025-01-09 00:07:46.464885:  
2025-01-09 00:07:46.465396: Epoch 166 
2025-01-09 00:07:46.470454: Current learning rate: 0.00375 
2025-01-09 00:08:27.277327: train_loss -0.4158 
2025-01-09 00:08:27.277837: val_loss -0.44 
2025-01-09 00:08:27.282400: Pseudo dice [np.float32(0.7741), np.float32(0.433)] 
2025-01-09 00:08:27.286432: Epoch time: 40.81 s 
2025-01-09 00:08:27.842012:  
2025-01-09 00:08:27.842520: Epoch 167 
2025-01-09 00:08:27.847610: Current learning rate: 0.00371 
2025-01-09 00:09:08.688433: train_loss -0.4154 
2025-01-09 00:09:08.688936: val_loss -0.4114 
2025-01-09 00:09:08.694495: Pseudo dice [np.float32(0.7335), np.float32(0.4052)] 
2025-01-09 00:09:08.697522: Epoch time: 40.85 s 
2025-01-09 00:09:09.459158:  
2025-01-09 00:09:09.459158: Epoch 168 
2025-01-09 00:09:09.465253: Current learning rate: 0.00367 
2025-01-09 00:09:50.323652: train_loss -0.4011 
2025-01-09 00:09:50.323652: val_loss -0.3939 
2025-01-09 00:09:50.330170: Pseudo dice [np.float32(0.7124), np.float32(0.3833)] 
2025-01-09 00:09:50.334682: Epoch time: 40.87 s 
2025-01-09 00:09:50.906448:  
2025-01-09 00:09:50.906951: Epoch 169 
2025-01-09 00:09:50.911964: Current learning rate: 0.00363 
2025-01-09 00:10:31.764689: train_loss -0.3938 
2025-01-09 00:10:31.764689: val_loss -0.4465 
2025-01-09 00:10:31.771318: Pseudo dice [np.float32(0.7528), np.float32(0.5036)] 
2025-01-09 00:10:31.774830: Epoch time: 40.86 s 
2025-01-09 00:10:31.778372: Yayy! New best EMA pseudo Dice: 0.5623999834060669 
2025-01-09 00:10:32.524467:  
2025-01-09 00:10:32.524467: Epoch 170 
2025-01-09 00:10:32.530423: Current learning rate: 0.00359 
2025-01-09 00:11:13.376918: train_loss -0.4056 
2025-01-09 00:11:13.377921: val_loss -0.4658 
2025-01-09 00:11:13.383469: Pseudo dice [np.float32(0.7262), np.float32(0.4755)] 
2025-01-09 00:11:13.387597: Epoch time: 40.85 s 
2025-01-09 00:11:13.391641: Yayy! New best EMA pseudo Dice: 0.5662000179290771 
2025-01-09 00:11:14.159789:  
2025-01-09 00:11:14.159789: Epoch 171 
2025-01-09 00:11:14.165929: Current learning rate: 0.00355 
2025-01-09 00:11:55.005899: train_loss -0.4006 
2025-01-09 00:11:55.006420: val_loss -0.4413 
2025-01-09 00:11:55.011440: Pseudo dice [np.float32(0.746), np.float32(0.3373)] 
2025-01-09 00:11:55.014948: Epoch time: 40.85 s 
2025-01-09 00:11:55.616544:  
2025-01-09 00:11:55.616544: Epoch 172 
2025-01-09 00:11:55.622105: Current learning rate: 0.00351 
2025-01-09 00:12:36.467496: train_loss -0.4271 
2025-01-09 00:12:36.468499: val_loss -0.4285 
2025-01-09 00:12:36.474040: Pseudo dice [np.float32(0.73), np.float32(0.2079)] 
2025-01-09 00:12:36.476552: Epoch time: 40.85 s 
2025-01-09 00:12:37.025490:  
2025-01-09 00:12:37.025490: Epoch 173 
2025-01-09 00:12:37.031558: Current learning rate: 0.00346 
2025-01-09 00:13:17.856663: train_loss -0.4235 
2025-01-09 00:13:17.857668: val_loss -0.482 
2025-01-09 00:13:17.863184: Pseudo dice [np.float32(0.7436), np.float32(0.4216)] 
2025-01-09 00:13:17.867718: Epoch time: 40.83 s 
2025-01-09 00:13:18.414357:  
2025-01-09 00:13:18.414357: Epoch 174 
2025-01-09 00:13:18.419960: Current learning rate: 0.00342 
2025-01-09 00:13:59.264867: train_loss -0.3931 
2025-01-09 00:13:59.265869: val_loss -0.4037 
2025-01-09 00:13:59.271384: Pseudo dice [np.float32(0.6927), np.float32(0.3705)] 
2025-01-09 00:13:59.277398: Epoch time: 40.85 s 
2025-01-09 00:13:59.835565:  
2025-01-09 00:13:59.835565: Epoch 175 
2025-01-09 00:13:59.841612: Current learning rate: 0.00338 
2025-01-09 00:14:40.665326: train_loss -0.4087 
2025-01-09 00:14:40.665326: val_loss -0.4073 
2025-01-09 00:14:40.671683: Pseudo dice [np.float32(0.7628), np.float32(0.3217)] 
2025-01-09 00:14:40.675227: Epoch time: 40.83 s 
2025-01-09 00:14:41.400763:  
2025-01-09 00:14:41.401268: Epoch 176 
2025-01-09 00:14:41.406340: Current learning rate: 0.00334 
2025-01-09 00:15:22.310936: train_loss -0.407 
2025-01-09 00:15:22.311936: val_loss -0.4801 
2025-01-09 00:15:22.317449: Pseudo dice [np.float32(0.7694), np.float32(0.3803)] 
2025-01-09 00:15:22.323468: Epoch time: 40.91 s 
2025-01-09 00:15:22.869640:  
2025-01-09 00:15:22.870643: Epoch 177 
2025-01-09 00:15:22.875220: Current learning rate: 0.0033 
2025-01-09 00:16:03.710360: train_loss -0.418 
2025-01-09 00:16:03.710862: val_loss -0.484 
2025-01-09 00:16:03.717906: Pseudo dice [np.float32(0.741), np.float32(0.3856)] 
2025-01-09 00:16:03.723419: Epoch time: 40.84 s 
2025-01-09 00:16:04.275503:  
2025-01-09 00:16:04.275503: Epoch 178 
2025-01-09 00:16:04.282527: Current learning rate: 0.00326 
2025-01-09 00:16:45.113584: train_loss -0.4524 
2025-01-09 00:16:45.113584: val_loss -0.4369 
2025-01-09 00:16:45.121101: Pseudo dice [np.float32(0.6879), np.float32(0.4105)] 
2025-01-09 00:16:45.124605: Epoch time: 40.84 s 
2025-01-09 00:16:45.679344:  
2025-01-09 00:16:45.679846: Epoch 179 
2025-01-09 00:16:45.684857: Current learning rate: 0.00322 
2025-01-09 00:17:26.497414: train_loss -0.4143 
2025-01-09 00:17:26.498413: val_loss -0.4541 
2025-01-09 00:17:26.503931: Pseudo dice [np.float32(0.7361), np.float32(0.4135)] 
2025-01-09 00:17:26.507443: Epoch time: 40.82 s 
2025-01-09 00:17:27.072559:  
2025-01-09 00:17:27.072559: Epoch 180 
2025-01-09 00:17:27.078621: Current learning rate: 0.00318 
2025-01-09 00:18:07.890185: train_loss -0.4393 
2025-01-09 00:18:07.890185: val_loss -0.4857 
2025-01-09 00:18:07.896198: Pseudo dice [np.float32(0.7385), np.float32(0.4072)] 
2025-01-09 00:18:07.901714: Epoch time: 40.82 s 
2025-01-09 00:18:08.472872:  
2025-01-09 00:18:08.472872: Epoch 181 
2025-01-09 00:18:08.479445: Current learning rate: 0.00314 
2025-01-09 00:18:49.312459: train_loss -0.4284 
2025-01-09 00:18:49.313463: val_loss -0.4509 
2025-01-09 00:18:49.319149: Pseudo dice [np.float32(0.7361), np.float32(0.4535)] 
2025-01-09 00:18:49.322172: Epoch time: 40.84 s 
2025-01-09 00:18:49.883192:  
2025-01-09 00:18:49.884198: Epoch 182 
2025-01-09 00:18:49.889218: Current learning rate: 0.0031 
2025-01-09 00:19:30.712158: train_loss -0.4491 
2025-01-09 00:19:30.712672: val_loss -0.4609 
2025-01-09 00:19:30.718272: Pseudo dice [np.float32(0.7798), np.float32(0.3928)] 
2025-01-09 00:19:30.722281: Epoch time: 40.83 s 
2025-01-09 00:19:31.277374:  
2025-01-09 00:19:31.277374: Epoch 183 
2025-01-09 00:19:31.283889: Current learning rate: 0.00306 
2025-01-09 00:20:12.107546: train_loss -0.4472 
2025-01-09 00:20:12.108550: val_loss -0.4934 
2025-01-09 00:20:12.113566: Pseudo dice [np.float32(0.7437), np.float32(0.4376)] 
2025-01-09 00:20:12.117579: Epoch time: 40.83 s 
2025-01-09 00:20:12.122593: Yayy! New best EMA pseudo Dice: 0.5674999952316284 
2025-01-09 00:20:13.057226:  
2025-01-09 00:20:13.058231: Epoch 184 
2025-01-09 00:20:13.064276: Current learning rate: 0.00302 
2025-01-09 00:20:53.874469: train_loss -0.4362 
2025-01-09 00:20:53.875468: val_loss -0.4588 
2025-01-09 00:20:53.880988: Pseudo dice [np.float32(0.7427), np.float32(0.4204)] 
2025-01-09 00:20:53.886003: Epoch time: 40.82 s 
2025-01-09 00:20:53.890516: Yayy! New best EMA pseudo Dice: 0.5688999891281128 
2025-01-09 00:20:54.647280:  
2025-01-09 00:20:54.647280: Epoch 185 
2025-01-09 00:20:54.653381: Current learning rate: 0.00297 
2025-01-09 00:21:35.498688: train_loss -0.4279 
2025-01-09 00:21:35.500192: val_loss -0.4987 
2025-01-09 00:21:35.506207: Pseudo dice [np.float32(0.7597), np.float32(0.4821)] 
2025-01-09 00:21:35.510214: Epoch time: 40.85 s 
2025-01-09 00:21:35.513229: Yayy! New best EMA pseudo Dice: 0.5741000175476074 
2025-01-09 00:21:36.259383:  
2025-01-09 00:21:36.259887: Epoch 186 
2025-01-09 00:21:36.264727: Current learning rate: 0.00293 
2025-01-09 00:22:17.089575: train_loss -0.4346 
2025-01-09 00:22:17.089575: val_loss -0.4067 
2025-01-09 00:22:17.094585: Pseudo dice [np.float32(0.7523), np.float32(0.283)] 
2025-01-09 00:22:17.099596: Epoch time: 40.83 s 
2025-01-09 00:22:17.685398:  
2025-01-09 00:22:17.686398: Epoch 187 
2025-01-09 00:22:17.691457: Current learning rate: 0.00289 
2025-01-09 00:22:58.512474: train_loss -0.4137 
2025-01-09 00:22:58.512985: val_loss -0.499 
2025-01-09 00:22:58.519053: Pseudo dice [np.float32(0.7733), np.float32(0.4256)] 
2025-01-09 00:22:58.522595: Epoch time: 40.83 s 
2025-01-09 00:22:59.082385:  
2025-01-09 00:22:59.082385: Epoch 188 
2025-01-09 00:22:59.087977: Current learning rate: 0.00285 
2025-01-09 00:23:39.946408: train_loss -0.4512 
2025-01-09 00:23:39.947408: val_loss -0.409 
2025-01-09 00:23:39.952922: Pseudo dice [np.float32(0.7179), np.float32(0.4138)] 
2025-01-09 00:23:39.956431: Epoch time: 40.86 s 
2025-01-09 00:23:40.524468:  
2025-01-09 00:23:40.525467: Epoch 189 
2025-01-09 00:23:40.531066: Current learning rate: 0.00281 
2025-01-09 00:24:21.339287: train_loss -0.4441 
2025-01-09 00:24:21.340304: val_loss -0.479 
2025-01-09 00:24:21.345866: Pseudo dice [np.float32(0.7582), np.float32(0.4671)] 
2025-01-09 00:24:21.350912: Epoch time: 40.81 s 
2025-01-09 00:24:21.355445: Yayy! New best EMA pseudo Dice: 0.5752000212669373 
2025-01-09 00:24:22.122074:  
2025-01-09 00:24:22.123074: Epoch 190 
2025-01-09 00:24:22.128127: Current learning rate: 0.00277 
2025-01-09 00:25:02.987579: train_loss -0.4614 
2025-01-09 00:25:02.987579: val_loss -0.4507 
2025-01-09 00:25:02.994094: Pseudo dice [np.float32(0.7504), np.float32(0.4704)] 
2025-01-09 00:25:02.999104: Epoch time: 40.87 s 
2025-01-09 00:25:03.002613: Yayy! New best EMA pseudo Dice: 0.5787000060081482 
2025-01-09 00:25:03.840746:  
2025-01-09 00:25:03.840746: Epoch 191 
2025-01-09 00:25:03.847270: Current learning rate: 0.00273 
2025-01-09 00:25:44.687839: train_loss -0.434 
2025-01-09 00:25:44.688838: val_loss -0.4439 
2025-01-09 00:25:44.694352: Pseudo dice [np.float32(0.7328), np.float32(0.4571)] 
2025-01-09 00:25:44.696862: Epoch time: 40.85 s 
2025-01-09 00:25:44.701371: Yayy! New best EMA pseudo Dice: 0.580299973487854 
2025-01-09 00:25:45.703261:  
2025-01-09 00:25:45.703261: Epoch 192 
2025-01-09 00:25:45.709876: Current learning rate: 0.00268 
2025-01-09 00:26:26.519488: train_loss -0.4323 
2025-01-09 00:26:26.520492: val_loss -0.4408 
2025-01-09 00:26:26.526514: Pseudo dice [np.float32(0.7568), np.float32(0.4025)] 
2025-01-09 00:26:26.530531: Epoch time: 40.82 s 
2025-01-09 00:26:27.108803:  
2025-01-09 00:26:27.108803: Epoch 193 
2025-01-09 00:26:27.114824: Current learning rate: 0.00264 
2025-01-09 00:27:07.950258: train_loss -0.4823 
2025-01-09 00:27:07.951769: val_loss -0.4906 
2025-01-09 00:27:07.957922: Pseudo dice [np.float32(0.7752), np.float32(0.5214)] 
2025-01-09 00:27:07.961970: Epoch time: 40.84 s 
2025-01-09 00:27:07.965539: Yayy! New best EMA pseudo Dice: 0.5871000289916992 
2025-01-09 00:27:08.738215:  
2025-01-09 00:27:08.738215: Epoch 194 
2025-01-09 00:27:08.743290: Current learning rate: 0.0026 
2025-01-09 00:27:49.652634: train_loss -0.47 
2025-01-09 00:27:49.652634: val_loss -0.4415 
2025-01-09 00:27:49.659183: Pseudo dice [np.float32(0.7505), np.float32(0.4547)] 
2025-01-09 00:27:49.662691: Epoch time: 40.92 s 
2025-01-09 00:27:49.665197: Yayy! New best EMA pseudo Dice: 0.5885999798774719 
2025-01-09 00:27:50.481850:  
2025-01-09 00:27:50.482854: Epoch 195 
2025-01-09 00:27:50.489031: Current learning rate: 0.00256 
2025-01-09 00:28:31.342236: train_loss -0.4241 
2025-01-09 00:28:31.343747: val_loss -0.4273 
2025-01-09 00:28:31.351931: Pseudo dice [np.float32(0.7361), np.float32(0.3208)] 
2025-01-09 00:28:31.356009: Epoch time: 40.86 s 
2025-01-09 00:28:31.926591:  
2025-01-09 00:28:31.927094: Epoch 196 
2025-01-09 00:28:31.932107: Current learning rate: 0.00252 
2025-01-09 00:29:12.761970: train_loss -0.4358 
2025-01-09 00:29:12.762497: val_loss -0.4269 
2025-01-09 00:29:12.768511: Pseudo dice [np.float32(0.7349), np.float32(0.4874)] 
2025-01-09 00:29:12.772524: Epoch time: 40.84 s 
2025-01-09 00:29:13.333847:  
2025-01-09 00:29:13.334350: Epoch 197 
2025-01-09 00:29:13.339360: Current learning rate: 0.00248 
2025-01-09 00:29:54.202264: train_loss -0.4534 
2025-01-09 00:29:54.202264: val_loss -0.4736 
2025-01-09 00:29:54.208852: Pseudo dice [np.float32(0.7651), np.float32(0.5018)] 
2025-01-09 00:29:54.213399: Epoch time: 40.87 s 
2025-01-09 00:29:54.216422: Yayy! New best EMA pseudo Dice: 0.5903000235557556 
2025-01-09 00:29:55.041803:  
2025-01-09 00:29:55.042801: Epoch 198 
2025-01-09 00:29:55.048373: Current learning rate: 0.00243 
2025-01-09 00:30:35.902134: train_loss -0.4511 
2025-01-09 00:30:35.902636: val_loss -0.3917 
2025-01-09 00:30:35.908649: Pseudo dice [np.float32(0.7558), np.float32(0.2674)] 
2025-01-09 00:30:35.912656: Epoch time: 40.86 s 
2025-01-09 00:30:36.475849:  
2025-01-09 00:30:36.476852: Epoch 199 
2025-01-09 00:30:36.482382: Current learning rate: 0.00239 
2025-01-09 00:31:17.331020: train_loss -0.4252 
2025-01-09 00:31:17.331020: val_loss -0.4115 
2025-01-09 00:31:17.338036: Pseudo dice [np.float32(0.7596), np.float32(0.4754)] 
2025-01-09 00:31:17.342047: Epoch time: 40.86 s 
2025-01-09 00:31:18.271538:  
2025-01-09 00:31:18.271538: Epoch 200 
2025-01-09 00:31:18.278749: Current learning rate: 0.00235 
2025-01-09 00:31:59.118937: train_loss -0.4452 
2025-01-09 00:31:59.118937: val_loss -0.4842 
2025-01-09 00:31:59.124949: Pseudo dice [np.float32(0.7426), np.float32(0.495)] 
2025-01-09 00:31:59.127961: Epoch time: 40.85 s 
2025-01-09 00:31:59.702342:  
2025-01-09 00:31:59.702844: Epoch 201 
2025-01-09 00:31:59.707384: Current learning rate: 0.00231 
2025-01-09 00:32:40.549423: train_loss -0.4487 
2025-01-09 00:32:40.549423: val_loss -0.4733 
2025-01-09 00:32:40.555438: Pseudo dice [np.float32(0.7594), np.float32(0.5481)] 
2025-01-09 00:32:40.560452: Epoch time: 40.85 s 
2025-01-09 00:32:40.564462: Yayy! New best EMA pseudo Dice: 0.5956000089645386 
2025-01-09 00:32:41.373382:  
2025-01-09 00:32:41.373382: Epoch 202 
2025-01-09 00:32:41.378455: Current learning rate: 0.00226 
2025-01-09 00:33:22.219577: train_loss -0.4431 
2025-01-09 00:33:22.220575: val_loss -0.4937 
2025-01-09 00:33:22.227094: Pseudo dice [np.float32(0.7746), np.float32(0.4145)] 
2025-01-09 00:33:22.231103: Epoch time: 40.85 s 
2025-01-09 00:33:22.808245:  
2025-01-09 00:33:22.808245: Epoch 203 
2025-01-09 00:33:22.814381: Current learning rate: 0.00222 
2025-01-09 00:34:03.684722: train_loss -0.4337 
2025-01-09 00:34:03.685725: val_loss -0.4637 
2025-01-09 00:34:03.691423: Pseudo dice [np.float32(0.7728), np.float32(0.4809)] 
2025-01-09 00:34:03.694977: Epoch time: 40.88 s 
2025-01-09 00:34:03.696991: Yayy! New best EMA pseudo Dice: 0.5986999869346619 
2025-01-09 00:34:04.479702:  
2025-01-09 00:34:04.479702: Epoch 204 
2025-01-09 00:34:04.485716: Current learning rate: 0.00218 
2025-01-09 00:34:45.324811: train_loss -0.4516 
2025-01-09 00:34:45.325314: val_loss -0.4815 
2025-01-09 00:34:45.330852: Pseudo dice [np.float32(0.7558), np.float32(0.4827)] 
2025-01-09 00:34:45.334424: Epoch time: 40.85 s 
2025-01-09 00:34:45.338443: Yayy! New best EMA pseudo Dice: 0.6007000207901001 
2025-01-09 00:34:46.158337:  
2025-01-09 00:34:46.158337: Epoch 205 
2025-01-09 00:34:46.164369: Current learning rate: 0.00214 
2025-01-09 00:35:27.019084: train_loss -0.4626 
2025-01-09 00:35:27.019084: val_loss -0.4495 
2025-01-09 00:35:27.025102: Pseudo dice [np.float32(0.7521), np.float32(0.4184)] 
2025-01-09 00:35:27.029112: Epoch time: 40.86 s 
2025-01-09 00:35:27.571365:  
2025-01-09 00:35:27.571365: Epoch 206 
2025-01-09 00:35:27.576879: Current learning rate: 0.00209 
2025-01-09 00:36:08.422365: train_loss -0.4581 
2025-01-09 00:36:08.422870: val_loss -0.461 
2025-01-09 00:36:08.430388: Pseudo dice [np.float32(0.7389), np.float32(0.4033)] 
2025-01-09 00:36:08.435398: Epoch time: 40.85 s 
2025-01-09 00:36:09.128388:  
2025-01-09 00:36:09.128388: Epoch 207 
2025-01-09 00:36:09.134484: Current learning rate: 0.00205 
2025-01-09 00:36:49.951205: train_loss -0.4401 
2025-01-09 00:36:49.951205: val_loss -0.4895 
2025-01-09 00:36:49.958225: Pseudo dice [np.float32(0.779), np.float32(0.4123)] 
2025-01-09 00:36:49.962242: Epoch time: 40.82 s 
2025-01-09 00:36:50.506034:  
2025-01-09 00:36:50.506034: Epoch 208 
2025-01-09 00:36:50.511740: Current learning rate: 0.00201 
2025-01-09 00:37:31.396305: train_loss -0.4637 
2025-01-09 00:37:31.397305: val_loss -0.4978 
2025-01-09 00:37:31.402824: Pseudo dice [np.float32(0.7736), np.float32(0.3544)] 
2025-01-09 00:37:31.407335: Epoch time: 40.89 s 
2025-01-09 00:37:31.968690:  
2025-01-09 00:37:31.968690: Epoch 209 
2025-01-09 00:37:31.973750: Current learning rate: 0.00196 
2025-01-09 00:38:12.842128: train_loss -0.4737 
2025-01-09 00:38:12.842632: val_loss -0.4982 
2025-01-09 00:38:12.848656: Pseudo dice [np.float32(0.758), np.float32(0.4763)] 
2025-01-09 00:38:12.852664: Epoch time: 40.87 s 
2025-01-09 00:38:13.397014:  
2025-01-09 00:38:13.397014: Epoch 210 
2025-01-09 00:38:13.403592: Current learning rate: 0.00192 
2025-01-09 00:38:54.254969: train_loss -0.4783 
2025-01-09 00:38:54.254969: val_loss -0.4435 
2025-01-09 00:38:54.262489: Pseudo dice [np.float32(0.7798), np.float32(0.346)] 
2025-01-09 00:38:54.266530: Epoch time: 40.86 s 
2025-01-09 00:38:54.800940:  
2025-01-09 00:38:54.800940: Epoch 211 
2025-01-09 00:38:54.806969: Current learning rate: 0.00188 
2025-01-09 00:39:35.648427: train_loss -0.4647 
2025-01-09 00:39:35.648427: val_loss -0.4546 
2025-01-09 00:39:35.656946: Pseudo dice [np.float32(0.7641), np.float32(0.4021)] 
2025-01-09 00:39:35.660955: Epoch time: 40.85 s 
2025-01-09 00:39:36.199831:  
2025-01-09 00:39:36.200830: Epoch 212 
2025-01-09 00:39:36.205878: Current learning rate: 0.00184 
2025-01-09 00:40:17.060929: train_loss -0.4993 
2025-01-09 00:40:17.060929: val_loss -0.546 
2025-01-09 00:40:17.067449: Pseudo dice [np.float32(0.7678), np.float32(0.4751)] 
2025-01-09 00:40:17.070961: Epoch time: 40.86 s 
2025-01-09 00:40:17.614435:  
2025-01-09 00:40:17.614435: Epoch 213 
2025-01-09 00:40:17.620533: Current learning rate: 0.00179 
2025-01-09 00:40:58.467691: train_loss -0.457 
2025-01-09 00:40:58.468194: val_loss -0.3937 
2025-01-09 00:40:58.475210: Pseudo dice [np.float32(0.7668), np.float32(0.4653)] 
2025-01-09 00:40:58.478219: Epoch time: 40.85 s 
2025-01-09 00:40:59.006003:  
2025-01-09 00:40:59.006003: Epoch 214 
2025-01-09 00:40:59.012015: Current learning rate: 0.00175 
2025-01-09 00:41:39.875755: train_loss -0.453 
2025-01-09 00:41:39.876757: val_loss -0.4529 
2025-01-09 00:41:39.882284: Pseudo dice [np.float32(0.7514), np.float32(0.3573)] 
2025-01-09 00:41:39.886802: Epoch time: 40.87 s 
2025-01-09 00:41:40.634641:  
2025-01-09 00:41:40.636143: Epoch 215 
2025-01-09 00:41:40.642168: Current learning rate: 0.0017 
2025-01-09 00:42:21.471052: train_loss -0.4588 
2025-01-09 00:42:21.472061: val_loss -0.4959 
2025-01-09 00:42:21.478073: Pseudo dice [np.float32(0.7465), np.float32(0.4483)] 
2025-01-09 00:42:21.481081: Epoch time: 40.84 s 
2025-01-09 00:42:22.048293:  
2025-01-09 00:42:22.049293: Epoch 216 
2025-01-09 00:42:22.054872: Current learning rate: 0.00166 
2025-01-09 00:43:02.894647: train_loss -0.4765 
2025-01-09 00:43:02.895150: val_loss -0.4879 
2025-01-09 00:43:02.900800: Pseudo dice [np.float32(0.7695), np.float32(0.4906)] 
2025-01-09 00:43:02.904338: Epoch time: 40.85 s 
2025-01-09 00:43:03.430079:  
2025-01-09 00:43:03.430079: Epoch 217 
2025-01-09 00:43:03.436175: Current learning rate: 0.00162 
2025-01-09 00:43:44.266870: train_loss -0.4664 
2025-01-09 00:43:44.267871: val_loss -0.4638 
2025-01-09 00:43:44.273422: Pseudo dice [np.float32(0.739), np.float32(0.3883)] 
2025-01-09 00:43:44.276455: Epoch time: 40.84 s 
2025-01-09 00:43:44.808073:  
2025-01-09 00:43:44.808073: Epoch 218 
2025-01-09 00:43:44.813141: Current learning rate: 0.00157 
2025-01-09 00:44:25.651897: train_loss -0.4639 
2025-01-09 00:44:25.652401: val_loss -0.4524 
2025-01-09 00:44:25.657420: Pseudo dice [np.float32(0.7693), np.float32(0.321)] 
2025-01-09 00:44:25.660928: Epoch time: 40.84 s 
2025-01-09 00:44:26.241446:  
2025-01-09 00:44:26.242452: Epoch 219 
2025-01-09 00:44:26.247983: Current learning rate: 0.00153 
2025-01-09 00:45:07.094763: train_loss -0.4514 
2025-01-09 00:45:07.095283: val_loss -0.4789 
2025-01-09 00:45:07.101377: Pseudo dice [np.float32(0.7713), np.float32(0.4396)] 
2025-01-09 00:45:07.106894: Epoch time: 40.85 s 
2025-01-09 00:45:07.634455:  
2025-01-09 00:45:07.634455: Epoch 220 
2025-01-09 00:45:07.639493: Current learning rate: 0.00148 
2025-01-09 00:45:48.509794: train_loss -0.4665 
2025-01-09 00:45:48.509794: val_loss -0.4439 
2025-01-09 00:45:48.516316: Pseudo dice [np.float32(0.7697), np.float32(0.4455)] 
2025-01-09 00:45:48.521332: Epoch time: 40.88 s 
2025-01-09 00:45:49.055556:  
2025-01-09 00:45:49.055556: Epoch 221 
2025-01-09 00:45:49.060677: Current learning rate: 0.00144 
2025-01-09 00:46:29.921667: train_loss -0.4721 
2025-01-09 00:46:29.921667: val_loss -0.509 
2025-01-09 00:46:29.928179: Pseudo dice [np.float32(0.7316), np.float32(0.4715)] 
2025-01-09 00:46:29.931687: Epoch time: 40.87 s 
2025-01-09 00:46:30.463947:  
2025-01-09 00:46:30.464449: Epoch 222 
2025-01-09 00:46:30.471966: Current learning rate: 0.00139 
2025-01-09 00:47:11.297491: train_loss -0.4639 
2025-01-09 00:47:11.297491: val_loss -0.4667 
2025-01-09 00:47:11.304509: Pseudo dice [np.float32(0.7752), np.float32(0.4964)] 
2025-01-09 00:47:11.310024: Epoch time: 40.83 s 
2025-01-09 00:47:11.837174:  
2025-01-09 00:47:11.837174: Epoch 223 
2025-01-09 00:47:11.842185: Current learning rate: 0.00135 
2025-01-09 00:47:52.668115: train_loss -0.4983 
2025-01-09 00:47:52.669118: val_loss -0.4836 
2025-01-09 00:47:52.674691: Pseudo dice [np.float32(0.7813), np.float32(0.4175)] 
2025-01-09 00:47:52.678237: Epoch time: 40.83 s 
2025-01-09 00:47:53.374329:  
2025-01-09 00:47:53.375334: Epoch 224 
2025-01-09 00:47:53.380433: Current learning rate: 0.0013 
2025-01-09 00:48:34.220046: train_loss -0.4553 
2025-01-09 00:48:34.221047: val_loss -0.469 
2025-01-09 00:48:34.226562: Pseudo dice [np.float32(0.7903), np.float32(0.4838)] 
2025-01-09 00:48:34.231573: Epoch time: 40.85 s 
2025-01-09 00:48:34.235084: Yayy! New best EMA pseudo Dice: 0.6013000011444092 
2025-01-09 00:48:35.010610:  
2025-01-09 00:48:35.011113: Epoch 225 
2025-01-09 00:48:35.016132: Current learning rate: 0.00126 
2025-01-09 00:49:15.912034: train_loss -0.4617 
2025-01-09 00:49:15.913034: val_loss -0.4763 
2025-01-09 00:49:15.918555: Pseudo dice [np.float32(0.7742), np.float32(0.4322)] 
2025-01-09 00:49:15.923572: Epoch time: 40.9 s 
2025-01-09 00:49:15.928082: Yayy! New best EMA pseudo Dice: 0.6014999747276306 
2025-01-09 00:49:16.666796:  
2025-01-09 00:49:16.666796: Epoch 226 
2025-01-09 00:49:16.672809: Current learning rate: 0.00121 
2025-01-09 00:49:57.519577: train_loss -0.4749 
2025-01-09 00:49:57.519577: val_loss -0.4665 
2025-01-09 00:49:57.526592: Pseudo dice [np.float32(0.7925), np.float32(0.5256)] 
2025-01-09 00:49:57.530605: Epoch time: 40.85 s 
2025-01-09 00:49:57.535616: Yayy! New best EMA pseudo Dice: 0.6072999835014343 
2025-01-09 00:49:58.287672:  
2025-01-09 00:49:58.288676: Epoch 227 
2025-01-09 00:49:58.293222: Current learning rate: 0.00117 
2025-01-09 00:50:39.141502: train_loss -0.4635 
2025-01-09 00:50:39.143003: val_loss -0.4686 
2025-01-09 00:50:39.150020: Pseudo dice [np.float32(0.7783), np.float32(0.4852)] 
2025-01-09 00:50:39.155036: Epoch time: 40.85 s 
2025-01-09 00:50:39.159047: Yayy! New best EMA pseudo Dice: 0.6097000241279602 
2025-01-09 00:50:39.944576:  
2025-01-09 00:50:39.944576: Epoch 228 
2025-01-09 00:50:39.950786: Current learning rate: 0.00112 
2025-01-09 00:51:20.796635: train_loss -0.481 
2025-01-09 00:51:20.797635: val_loss -0.4618 
2025-01-09 00:51:20.804152: Pseudo dice [np.float32(0.7706), np.float32(0.3904)] 
2025-01-09 00:51:20.809164: Epoch time: 40.85 s 
2025-01-09 00:51:21.337193:  
2025-01-09 00:51:21.337193: Epoch 229 
2025-01-09 00:51:21.344259: Current learning rate: 0.00108 
2025-01-09 00:52:02.182785: train_loss -0.4824 
2025-01-09 00:52:02.183789: val_loss -0.4527 
2025-01-09 00:52:02.190961: Pseudo dice [np.float32(0.7395), np.float32(0.4184)] 
2025-01-09 00:52:02.195044: Epoch time: 40.85 s 
2025-01-09 00:52:02.719584:  
2025-01-09 00:52:02.720583: Epoch 230 
2025-01-09 00:52:02.725597: Current learning rate: 0.00103 
2025-01-09 00:52:43.549612: train_loss -0.507 
2025-01-09 00:52:43.550617: val_loss -0.4837 
2025-01-09 00:52:43.557132: Pseudo dice [np.float32(0.7433), np.float32(0.4293)] 
2025-01-09 00:52:43.561642: Epoch time: 40.83 s 
2025-01-09 00:52:44.092792:  
2025-01-09 00:52:44.093797: Epoch 231 
2025-01-09 00:52:44.098381: Current learning rate: 0.00098 
2025-01-09 00:53:24.960529: train_loss -0.4623 
2025-01-09 00:53:24.961051: val_loss -0.5323 
2025-01-09 00:53:24.966625: Pseudo dice [np.float32(0.7852), np.float32(0.6169)] 
2025-01-09 00:53:24.970718: Epoch time: 40.87 s 
2025-01-09 00:53:24.974779: Yayy! New best EMA pseudo Dice: 0.6121000051498413 
2025-01-09 00:53:25.718666:  
2025-01-09 00:53:25.718666: Epoch 232 
2025-01-09 00:53:25.725680: Current learning rate: 0.00094 
2025-01-09 00:54:06.562008: train_loss -0.4937 
2025-01-09 00:54:06.562008: val_loss -0.4312 
2025-01-09 00:54:06.567935: Pseudo dice [np.float32(0.7652), np.float32(0.4135)] 
2025-01-09 00:54:06.571943: Epoch time: 40.84 s 
2025-01-09 00:54:07.245175:  
2025-01-09 00:54:07.245175: Epoch 233 
2025-01-09 00:54:07.251233: Current learning rate: 0.00089 
2025-01-09 00:54:48.099925: train_loss -0.5067 
2025-01-09 00:54:48.100428: val_loss -0.4788 
2025-01-09 00:54:48.106441: Pseudo dice [np.float32(0.7704), np.float32(0.4037)] 
2025-01-09 00:54:48.109949: Epoch time: 40.86 s 
2025-01-09 00:54:48.645206:  
2025-01-09 00:54:48.645206: Epoch 234 
2025-01-09 00:54:48.651219: Current learning rate: 0.00084 
2025-01-09 00:55:29.483497: train_loss -0.4915 
2025-01-09 00:55:29.484498: val_loss -0.4547 
2025-01-09 00:55:29.490242: Pseudo dice [np.float32(0.7493), np.float32(0.4531)] 
2025-01-09 00:55:29.493750: Epoch time: 40.84 s 
2025-01-09 00:55:30.033522:  
2025-01-09 00:55:30.034525: Epoch 235 
2025-01-09 00:55:30.039598: Current learning rate: 0.00079 
2025-01-09 00:56:10.860444: train_loss -0.4739 
2025-01-09 00:56:10.860444: val_loss -0.5025 
2025-01-09 00:56:10.867961: Pseudo dice [np.float32(0.7858), np.float32(0.539)] 
2025-01-09 00:56:10.870974: Epoch time: 40.83 s 
2025-01-09 00:56:10.875507: Yayy! New best EMA pseudo Dice: 0.612500011920929 
2025-01-09 00:56:11.671014:  
2025-01-09 00:56:11.671014: Epoch 236 
2025-01-09 00:56:11.675575: Current learning rate: 0.00075 
2025-01-09 00:56:52.519274: train_loss -0.4702 
2025-01-09 00:56:52.520273: val_loss -0.5132 
2025-01-09 00:56:52.526793: Pseudo dice [np.float32(0.7477), np.float32(0.4513)] 
2025-01-09 00:56:52.530801: Epoch time: 40.85 s 
2025-01-09 00:56:53.065061:  
2025-01-09 00:56:53.065563: Epoch 237 
2025-01-09 00:56:53.070652: Current learning rate: 0.0007 
2025-01-09 00:57:33.895102: train_loss -0.4903 
2025-01-09 00:57:33.895606: val_loss -0.4988 
2025-01-09 00:57:33.903125: Pseudo dice [np.float32(0.8016), np.float32(0.5654)] 
2025-01-09 00:57:33.906632: Epoch time: 40.83 s 
2025-01-09 00:57:33.910640: Yayy! New best EMA pseudo Dice: 0.618399977684021 
2025-01-09 00:57:34.714945:  
2025-01-09 00:57:34.715448: Epoch 238 
2025-01-09 00:57:34.720458: Current learning rate: 0.00065 
2025-01-09 00:58:18.578039: train_loss -0.4886 
2025-01-09 00:58:18.579042: val_loss -0.5018 
2025-01-09 00:58:18.585561: Pseudo dice [np.float32(0.7888), np.float32(0.4767)] 
2025-01-09 00:58:18.590070: Epoch time: 43.86 s 
2025-01-09 00:58:18.594080: Yayy! New best EMA pseudo Dice: 0.6197999715805054 
2025-01-09 00:58:19.399617:  
2025-01-09 00:58:19.400120: Epoch 239 
2025-01-09 00:58:19.405132: Current learning rate: 0.0006 
2025-01-09 00:59:03.410865: train_loss -0.5032 
2025-01-09 00:59:03.410865: val_loss -0.4979 
2025-01-09 00:59:03.418105: Pseudo dice [np.float32(0.7708), np.float32(0.4157)] 
2025-01-09 00:59:03.423748: Epoch time: 44.01 s 
2025-01-09 00:59:04.084272:  
2025-01-09 00:59:04.085276: Epoch 240 
2025-01-09 00:59:04.089827: Current learning rate: 0.00055 
2025-01-09 00:59:45.360890: train_loss -0.5071 
2025-01-09 00:59:45.360890: val_loss -0.4907 
2025-01-09 00:59:45.368445: Pseudo dice [np.float32(0.7695), np.float32(0.4522)] 
2025-01-09 00:59:45.373487: Epoch time: 41.28 s 
2025-01-09 00:59:46.082975:  
2025-01-09 00:59:46.082975: Epoch 241 
2025-01-09 00:59:46.088989: Current learning rate: 0.0005 
2025-01-09 01:00:26.934359: train_loss -0.5158 
2025-01-09 01:00:26.935359: val_loss -0.5157 
2025-01-09 01:00:26.940875: Pseudo dice [np.float32(0.77), np.float32(0.5223)] 
2025-01-09 01:00:26.945886: Epoch time: 40.85 s 
2025-01-09 01:00:27.491751:  
2025-01-09 01:00:27.492754: Epoch 242 
2025-01-09 01:00:27.497316: Current learning rate: 0.00045 
2025-01-09 01:01:08.619023: train_loss -0.4983 
2025-01-09 01:01:08.619023: val_loss -0.4435 
2025-01-09 01:01:08.625041: Pseudo dice [np.float32(0.7823), np.float32(0.5444)] 
2025-01-09 01:01:08.627548: Epoch time: 41.13 s 
2025-01-09 01:01:08.631557: Yayy! New best EMA pseudo Dice: 0.6238999962806702 
2025-01-09 01:01:09.430124:  
2025-01-09 01:01:09.431128: Epoch 243 
2025-01-09 01:01:09.437153: Current learning rate: 0.0004 
2025-01-09 01:01:53.144944: train_loss -0.4957 
2025-01-09 01:01:53.144944: val_loss -0.4685 
2025-01-09 01:01:53.151962: Pseudo dice [np.float32(0.7682), np.float32(0.4827)] 
2025-01-09 01:01:53.154974: Epoch time: 43.71 s 
2025-01-09 01:01:53.158484: Yayy! New best EMA pseudo Dice: 0.6241000294685364 
2025-01-09 01:01:53.951903:  
2025-01-09 01:01:53.952905: Epoch 244 
2025-01-09 01:01:53.958941: Current learning rate: 0.00035 
2025-01-09 01:02:34.763526: train_loss -0.4812 
2025-01-09 01:02:34.763526: val_loss -0.492 
2025-01-09 01:02:34.771042: Pseudo dice [np.float32(0.7973), np.float32(0.5601)] 
2025-01-09 01:02:34.776052: Epoch time: 40.81 s 
2025-01-09 01:02:34.780561: Yayy! New best EMA pseudo Dice: 0.6294999718666077 
2025-01-09 01:02:35.574086:  
2025-01-09 01:02:35.574086: Epoch 245 
2025-01-09 01:02:35.583259: Current learning rate: 0.0003 
2025-01-09 01:03:16.406823: train_loss -0.5275 
2025-01-09 01:03:16.406823: val_loss -0.5768 
2025-01-09 01:03:16.412837: Pseudo dice [np.float32(0.7909), np.float32(0.5327)] 
2025-01-09 01:03:16.417850: Epoch time: 40.83 s 
2025-01-09 01:03:16.421864: Yayy! New best EMA pseudo Dice: 0.6327000260353088 
2025-01-09 01:03:17.190710:  
2025-01-09 01:03:17.190710: Epoch 246 
2025-01-09 01:03:17.196741: Current learning rate: 0.00024 
2025-01-09 01:03:58.020653: train_loss -0.4924 
2025-01-09 01:03:58.020653: val_loss -0.5238 
2025-01-09 01:03:58.029171: Pseudo dice [np.float32(0.7882), np.float32(0.5468)] 
2025-01-09 01:03:58.033181: Epoch time: 40.83 s 
2025-01-09 01:03:58.037189: Yayy! New best EMA pseudo Dice: 0.6362000107765198 
2025-01-09 01:03:58.891701:  
2025-01-09 01:03:58.892706: Epoch 247 
2025-01-09 01:03:58.899287: Current learning rate: 0.00019 
2025-01-09 01:04:39.733790: train_loss -0.4903 
2025-01-09 01:04:39.733790: val_loss -0.4953 
2025-01-09 01:04:39.739805: Pseudo dice [np.float32(0.7706), np.float32(0.3943)] 
2025-01-09 01:04:39.744815: Epoch time: 40.84 s 
2025-01-09 01:04:40.291259:  
2025-01-09 01:04:40.292263: Epoch 248 
2025-01-09 01:04:40.296827: Current learning rate: 0.00013 
2025-01-09 01:05:25.233521: train_loss -0.4919 
2025-01-09 01:05:25.234525: val_loss -0.4765 
2025-01-09 01:05:25.241050: Pseudo dice [np.float32(0.7703), np.float32(0.4461)] 
2025-01-09 01:05:25.246066: Epoch time: 44.94 s 
2025-01-09 01:05:25.965027:  
2025-01-09 01:05:25.965027: Epoch 249 
2025-01-09 01:05:25.970036: Current learning rate: 7e-05 
2025-01-09 01:06:06.827836: train_loss -0.4916 
2025-01-09 01:06:06.827836: val_loss -0.5047 
2025-01-09 01:06:06.833906: Pseudo dice [np.float32(0.7731), np.float32(0.403)] 
2025-01-09 01:06:06.836441: Epoch time: 40.86 s 
2025-01-09 01:06:07.579715: Training done. 
2025-01-09 01:06:07.611225: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-09 01:06:07.621225: The split file contains 5 splits. 
2025-01-09 01:06:07.629226: Desired fold for training: 0 
2025-01-09 01:06:07.634225: This split has 224 training and 57 validation cases. 
2025-01-09 01:06:07.639225: predicting pancreas_021 
2025-01-09 01:06:07.646225: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-09 01:06:19.993530: predicting pancreas_024 
2025-01-09 01:06:20.008036: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-09 01:06:34.561110: predicting pancreas_035 
2025-01-09 01:06:34.576110: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-09 01:06:39.507807: predicting pancreas_040 
2025-01-09 01:06:39.514807: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-01-09 01:06:51.192962: predicting pancreas_042 
2025-01-09 01:06:51.204962: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-01-09 01:07:05.779244: predicting pancreas_056 
2025-01-09 01:07:05.793244: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-09 01:07:17.446382: predicting pancreas_067 
2025-01-09 01:07:17.455382: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-09 01:07:32.018183: predicting pancreas_075 
2025-01-09 01:07:32.033186: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-01-09 01:07:37.884700: predicting pancreas_086 
2025-01-09 01:07:37.896700: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-09 01:07:46.970373: predicting pancreas_089 
2025-01-09 01:07:46.980374: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-09 01:07:58.610727: predicting pancreas_092 
2025-01-09 01:07:58.621726: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-01-09 01:08:24.755144: predicting pancreas_094 
2025-01-09 01:08:24.777653: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-09 01:08:36.423369: predicting pancreas_095 
2025-01-09 01:08:36.433368: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-09 01:08:48.098820: predicting pancreas_098 
2025-01-09 01:08:48.108821: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-09 01:09:19.952492: predicting pancreas_109 
2025-01-09 01:09:19.975492: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-09 01:09:31.698900: predicting pancreas_110 
2025-01-09 01:09:31.711901: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-09 01:09:49.938343: predicting pancreas_114 
2025-01-09 01:09:49.956854: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-09 01:10:01.621791: predicting pancreas_119 
2025-01-09 01:10:01.634797: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-09 01:10:19.794921: predicting pancreas_138 
2025-01-09 01:10:19.808921: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-09 01:10:38.032951: predicting pancreas_145 
2025-01-09 01:10:38.049951: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-09 01:10:56.271503: predicting pancreas_148 
2025-01-09 01:10:56.286009: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-01-09 01:11:07.943407: predicting pancreas_169 
2025-01-09 01:11:07.953408: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-09 01:11:19.607681: predicting pancreas_170 
2025-01-09 01:11:19.618681: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-09 01:11:34.170049: predicting pancreas_172 
2025-01-09 01:11:34.183049: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-09 01:11:45.834053: predicting pancreas_175 
2025-01-09 01:11:45.845053: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-09 01:11:57.486690: predicting pancreas_180 
2025-01-09 01:11:57.499690: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-09 01:12:09.126111: predicting pancreas_191 
2025-01-09 01:12:09.137616: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-09 01:12:14.997653: predicting pancreas_193 
2025-01-09 01:12:15.005653: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-09 01:12:29.550654: predicting pancreas_212 
2025-01-09 01:12:29.564654: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-09 01:12:41.260244: predicting pancreas_215 
2025-01-09 01:12:41.274244: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-09 01:12:52.929497: predicting pancreas_222 
2025-01-09 01:12:52.940498: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-09 01:12:57.897008: predicting pancreas_235 
2025-01-09 01:12:57.904007: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-09 01:13:09.680403: predicting pancreas_241 
2025-01-09 01:13:09.690403: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-09 01:13:24.342404: predicting pancreas_242 
2025-01-09 01:13:24.356405: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-09 01:13:38.954994: predicting pancreas_244 
2025-01-09 01:13:38.969994: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-09 01:14:01.687312: predicting pancreas_246 
2025-01-09 01:14:01.704315: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-09 01:14:24.425774: predicting pancreas_247 
2025-01-09 01:14:24.442774: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-09 01:14:31.044399: predicting pancreas_264 
2025-01-09 01:14:31.053399: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-09 01:14:45.621770: predicting pancreas_265 
2025-01-09 01:14:45.637275: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-09 01:14:57.310686: predicting pancreas_266 
2025-01-09 01:14:57.324686: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-09 01:15:15.477508: predicting pancreas_267 
2025-01-09 01:15:15.492508: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-09 01:15:22.105866: predicting pancreas_275 
2025-01-09 01:15:22.115866: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-09 01:15:36.651335: predicting pancreas_279 
2025-01-09 01:15:36.662340: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-09 01:15:41.641703: predicting pancreas_287 
2025-01-09 01:15:41.651703: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-09 01:15:53.297273: predicting pancreas_301 
2025-01-09 01:15:53.309272: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-09 01:16:04.974847: predicting pancreas_323 
2025-01-09 01:16:04.987849: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-09 01:16:23.219386: predicting pancreas_336 
2025-01-09 01:16:23.236382: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-09 01:16:34.934045: predicting pancreas_344 
2025-01-09 01:16:34.948045: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-09 01:16:49.514973: predicting pancreas_351 
2025-01-09 01:16:49.529477: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-09 01:16:56.129822: predicting pancreas_354 
2025-01-09 01:16:56.139822: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-01-09 01:17:19.399154: predicting pancreas_372 
2025-01-09 01:17:19.420155: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-09 01:17:37.680815: predicting pancreas_377 
2025-01-09 01:17:37.699815: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-01-09 01:17:52.321189: predicting pancreas_387 
2025-01-09 01:17:52.337189: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-01-09 01:18:04.026061: predicting pancreas_391 
2025-01-09 01:18:04.039061: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-09 01:18:22.246309: predicting pancreas_392 
2025-01-09 01:18:22.261309: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-01-09 01:18:30.502472: predicting pancreas_410 
2025-01-09 01:18:30.513472: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-09 01:18:38.730581: predicting pancreas_412 
2025-01-09 01:18:38.743581: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-01-09 01:19:37.299802: Validation complete 
2025-01-09 01:19:37.299802: Mean Validation Dice:  0.6395736456915553 
