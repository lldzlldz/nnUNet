
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-18 16:11:16.378226: do_dummy_2d_data_aug: False 
2025-01-18 16:11:16.380228: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-18 16:11:16.385189: The split file contains 5 splits. 
2025-01-18 16:11:16.387192: Desired fold for training: 0 
2025-01-18 16:11:16.390193: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-18 16:11:22.163513: unpacking dataset... 
2025-01-18 16:11:22.350161: unpacking done... 
2025-01-18 16:11:26.351393:  
2025-01-18 16:11:26.351393: Epoch 0 
2025-01-18 16:11:26.356403: Current learning rate: 0.01 
2025-01-18 16:12:01.308455: train_loss 0.079 
2025-01-18 16:12:01.309970: val_loss 0.0121 
2025-01-18 16:12:01.315569: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-18 16:12:01.319078: Epoch time: 34.96 s 
2025-01-18 16:12:01.321120: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-18 16:12:02.026128:  
2025-01-18 16:12:02.026128: Epoch 1 
2025-01-18 16:12:02.031668: Current learning rate: 0.00996 
2025-01-18 16:12:33.819565: train_loss 0.0006 
2025-01-18 16:12:33.821073: val_loss -0.0211 
2025-01-18 16:12:33.826094: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-18 16:12:33.829630: Epoch time: 31.79 s 
2025-01-18 16:12:34.357108:  
2025-01-18 16:12:34.357108: Epoch 2 
2025-01-18 16:12:34.362168: Current learning rate: 0.00993 
2025-01-18 16:13:06.166137: train_loss -0.132 
2025-01-18 16:13:06.167141: val_loss -0.2802 
2025-01-18 16:13:06.172158: Pseudo dice [np.float32(0.5878), np.float32(0.0)] 
2025-01-18 16:13:06.175245: Epoch time: 31.81 s 
2025-01-18 16:13:06.178290: Yayy! New best EMA pseudo Dice: 0.029400000348687172 
2025-01-18 16:13:06.994334:  
2025-01-18 16:13:06.994334: Epoch 3 
2025-01-18 16:13:06.999865: Current learning rate: 0.00989 
2025-01-18 16:13:38.795938: train_loss -0.2947 
2025-01-18 16:13:38.796445: val_loss -0.3543 
2025-01-18 16:13:38.801462: Pseudo dice [np.float32(0.6455), np.float32(0.0)] 
2025-01-18 16:13:38.803968: Epoch time: 31.8 s 
2025-01-18 16:13:38.808012: Yayy! New best EMA pseudo Dice: 0.05869999900460243 
2025-01-18 16:13:39.586047:  
2025-01-18 16:13:39.586047: Epoch 4 
2025-01-18 16:13:39.591058: Current learning rate: 0.00986 
2025-01-18 16:14:11.387062: train_loss -0.3748 
2025-01-18 16:14:11.387062: val_loss -0.3819 
2025-01-18 16:14:11.393085: Pseudo dice [np.float32(0.6101), np.float32(0.0)] 
2025-01-18 16:14:11.396135: Epoch time: 31.8 s 
2025-01-18 16:14:11.398159: Yayy! New best EMA pseudo Dice: 0.08340000361204147 
2025-01-18 16:14:12.320411:  
2025-01-18 16:14:12.320411: Epoch 5 
2025-01-18 16:14:12.325781: Current learning rate: 0.00982 
2025-01-18 16:14:44.106613: train_loss -0.4256 
2025-01-18 16:14:44.106613: val_loss -0.4634 
2025-01-18 16:14:44.112870: Pseudo dice [np.float32(0.6484), np.float32(0.3711)] 
2025-01-18 16:14:44.115462: Epoch time: 31.79 s 
2025-01-18 16:14:44.118005: Yayy! New best EMA pseudo Dice: 0.12600000202655792 
2025-01-18 16:14:44.920330:  
2025-01-18 16:14:44.920330: Epoch 6 
2025-01-18 16:14:44.925901: Current learning rate: 0.00978 
2025-01-18 16:15:16.722205: train_loss -0.4472 
2025-01-18 16:15:16.722713: val_loss -0.4277 
2025-01-18 16:15:16.727735: Pseudo dice [np.float32(0.5612), np.float32(0.3585)] 
2025-01-18 16:15:16.731251: Epoch time: 31.8 s 
2025-01-18 16:15:16.733269: Yayy! New best EMA pseudo Dice: 0.15940000116825104 
2025-01-18 16:15:17.528391:  
2025-01-18 16:15:17.529397: Epoch 7 
2025-01-18 16:15:17.534439: Current learning rate: 0.00975 
2025-01-18 16:15:49.332132: train_loss -0.4732 
2025-01-18 16:15:49.332664: val_loss -0.4391 
2025-01-18 16:15:49.338681: Pseudo dice [np.float32(0.66), np.float32(0.3221)] 
2025-01-18 16:15:49.341693: Epoch time: 31.8 s 
2025-01-18 16:15:49.344710: Yayy! New best EMA pseudo Dice: 0.19249999523162842 
2025-01-18 16:15:50.143439:  
2025-01-18 16:15:50.143439: Epoch 8 
2025-01-18 16:15:50.149014: Current learning rate: 0.00971 
2025-01-18 16:16:21.924074: train_loss -0.4966 
2025-01-18 16:16:21.924576: val_loss -0.4876 
2025-01-18 16:16:21.929594: Pseudo dice [np.float32(0.6209), np.float32(0.4164)] 
2025-01-18 16:16:21.933104: Epoch time: 31.78 s 
2025-01-18 16:16:21.935621: Yayy! New best EMA pseudo Dice: 0.22519999742507935 
2025-01-18 16:16:22.734161:  
2025-01-18 16:16:22.734667: Epoch 9 
2025-01-18 16:16:22.739679: Current learning rate: 0.00968 
2025-01-18 16:16:54.510273: train_loss -0.5226 
2025-01-18 16:16:54.510776: val_loss -0.5041 
2025-01-18 16:16:54.516795: Pseudo dice [np.float32(0.6725), np.float32(0.4027)] 
2025-01-18 16:16:54.519824: Epoch time: 31.78 s 
2025-01-18 16:16:54.523410: Yayy! New best EMA pseudo Dice: 0.2563999891281128 
2025-01-18 16:16:55.298493:  
2025-01-18 16:16:55.298493: Epoch 10 
2025-01-18 16:16:55.304029: Current learning rate: 0.00964 
2025-01-18 16:17:27.088692: train_loss -0.5278 
2025-01-18 16:17:27.088692: val_loss -0.4629 
2025-01-18 16:17:27.095207: Pseudo dice [np.float32(0.6446), np.float32(0.331)] 
2025-01-18 16:17:27.098717: Epoch time: 31.79 s 
2025-01-18 16:17:27.101223: Yayy! New best EMA pseudo Dice: 0.27950000762939453 
2025-01-18 16:17:27.887746:  
2025-01-18 16:17:27.888750: Epoch 11 
2025-01-18 16:17:27.893290: Current learning rate: 0.0096 
2025-01-18 16:17:59.665775: train_loss -0.5308 
2025-01-18 16:17:59.665775: val_loss -0.4937 
2025-01-18 16:17:59.672924: Pseudo dice [np.float32(0.6442), np.float32(0.4177)] 
2025-01-18 16:17:59.675470: Epoch time: 31.78 s 
2025-01-18 16:17:59.678577: Yayy! New best EMA pseudo Dice: 0.30469998717308044 
2025-01-18 16:18:00.595292:  
2025-01-18 16:18:00.595795: Epoch 12 
2025-01-18 16:18:00.600805: Current learning rate: 0.00957 
2025-01-18 16:18:32.372383: train_loss -0.5276 
2025-01-18 16:18:32.373388: val_loss -0.4882 
2025-01-18 16:18:32.379907: Pseudo dice [np.float32(0.6223), np.float32(0.424)] 
2025-01-18 16:18:32.383443: Epoch time: 31.78 s 
2025-01-18 16:18:32.385496: Yayy! New best EMA pseudo Dice: 0.3264999985694885 
2025-01-18 16:18:33.185883:  
2025-01-18 16:18:33.185883: Epoch 13 
2025-01-18 16:18:33.190923: Current learning rate: 0.00953 
2025-01-18 16:19:05.009723: train_loss -0.551 
2025-01-18 16:19:05.010226: val_loss -0.4104 
2025-01-18 16:19:05.015243: Pseudo dice [np.float32(0.5664), np.float32(0.3294)] 
2025-01-18 16:19:05.019284: Epoch time: 31.82 s 
2025-01-18 16:19:05.022342: Yayy! New best EMA pseudo Dice: 0.33869999647140503 
2025-01-18 16:19:05.855873:  
2025-01-18 16:19:05.856376: Epoch 14 
2025-01-18 16:19:05.860938: Current learning rate: 0.00949 
2025-01-18 16:19:37.694204: train_loss -0.5287 
2025-01-18 16:19:37.694204: val_loss -0.4779 
2025-01-18 16:19:37.700219: Pseudo dice [np.float32(0.6744), np.float32(0.3569)] 
2025-01-18 16:19:37.702726: Epoch time: 31.84 s 
2025-01-18 16:19:37.705734: Yayy! New best EMA pseudo Dice: 0.3564000129699707 
2025-01-18 16:19:38.518460:  
2025-01-18 16:19:38.518962: Epoch 15 
2025-01-18 16:19:38.524013: Current learning rate: 0.00946 
2025-01-18 16:20:10.351574: train_loss -0.5468 
2025-01-18 16:20:10.352573: val_loss -0.497 
2025-01-18 16:20:10.358118: Pseudo dice [np.float32(0.6887), np.float32(0.4166)] 
2025-01-18 16:20:10.361657: Epoch time: 31.83 s 
2025-01-18 16:20:10.364671: Yayy! New best EMA pseudo Dice: 0.37599998712539673 
2025-01-18 16:20:11.186829:  
2025-01-18 16:20:11.186829: Epoch 16 
2025-01-18 16:20:11.191882: Current learning rate: 0.00942 
2025-01-18 16:20:43.016156: train_loss -0.5574 
2025-01-18 16:20:43.016660: val_loss -0.5031 
2025-01-18 16:20:43.021680: Pseudo dice [np.float32(0.658), np.float32(0.4585)] 
2025-01-18 16:20:43.024186: Epoch time: 31.83 s 
2025-01-18 16:20:43.027725: Yayy! New best EMA pseudo Dice: 0.39419999718666077 
2025-01-18 16:20:43.866862:  
2025-01-18 16:20:43.866862: Epoch 17 
2025-01-18 16:20:43.873056: Current learning rate: 0.00939 
2025-01-18 16:21:15.723722: train_loss -0.5757 
2025-01-18 16:21:15.724722: val_loss -0.4524 
2025-01-18 16:21:15.729735: Pseudo dice [np.float32(0.6608), np.float32(0.3416)] 
2025-01-18 16:21:15.733325: Epoch time: 31.86 s 
2025-01-18 16:21:15.736361: Yayy! New best EMA pseudo Dice: 0.4049000144004822 
2025-01-18 16:21:16.560649:  
2025-01-18 16:21:16.561648: Epoch 18 
2025-01-18 16:21:16.566719: Current learning rate: 0.00935 
2025-01-18 16:21:48.422397: train_loss -0.6014 
2025-01-18 16:21:48.422900: val_loss -0.4973 
2025-01-18 16:21:48.428494: Pseudo dice [np.float32(0.7078), np.float32(0.3658)] 
2025-01-18 16:21:48.431030: Epoch time: 31.86 s 
2025-01-18 16:21:48.433596: Yayy! New best EMA pseudo Dice: 0.4180999994277954 
2025-01-18 16:21:49.266803:  
2025-01-18 16:21:49.267305: Epoch 19 
2025-01-18 16:21:49.272326: Current learning rate: 0.00931 
2025-01-18 16:22:21.133216: train_loss -0.6191 
2025-01-18 16:22:21.134218: val_loss -0.4824 
2025-01-18 16:22:21.139765: Pseudo dice [np.float32(0.6808), np.float32(0.3344)] 
2025-01-18 16:22:21.143275: Epoch time: 31.87 s 
2025-01-18 16:22:21.145780: Yayy! New best EMA pseudo Dice: 0.4271000027656555 
2025-01-18 16:22:22.115296:  
2025-01-18 16:22:22.116299: Epoch 20 
2025-01-18 16:22:22.122373: Current learning rate: 0.00928 
2025-01-18 16:22:53.964248: train_loss -0.6153 
2025-01-18 16:22:53.964248: val_loss -0.5377 
2025-01-18 16:22:53.970269: Pseudo dice [np.float32(0.6875), np.float32(0.4679)] 
2025-01-18 16:22:53.973793: Epoch time: 31.85 s 
2025-01-18 16:22:53.976815: Yayy! New best EMA pseudo Dice: 0.44209998846054077 
2025-01-18 16:22:54.817103:  
2025-01-18 16:22:54.817605: Epoch 21 
2025-01-18 16:22:54.823186: Current learning rate: 0.00924 
2025-01-18 16:23:26.756400: train_loss -0.6453 
2025-01-18 16:23:26.756903: val_loss -0.5197 
2025-01-18 16:23:26.761922: Pseudo dice [np.float32(0.666), np.float32(0.4751)] 
2025-01-18 16:23:26.764943: Epoch time: 31.94 s 
2025-01-18 16:23:26.767967: Yayy! New best EMA pseudo Dice: 0.45500001311302185 
2025-01-18 16:23:27.593806:  
2025-01-18 16:23:27.593806: Epoch 22 
2025-01-18 16:23:27.598844: Current learning rate: 0.0092 
2025-01-18 16:23:59.509901: train_loss -0.6635 
2025-01-18 16:23:59.515914: val_loss -0.5234 
2025-01-18 16:23:59.519929: Pseudo dice [np.float32(0.705), np.float32(0.4174)] 
2025-01-18 16:23:59.522435: Epoch time: 31.92 s 
2025-01-18 16:23:59.524942: Yayy! New best EMA pseudo Dice: 0.46560001373291016 
2025-01-18 16:24:00.344029:  
2025-01-18 16:24:00.345034: Epoch 23 
2025-01-18 16:24:00.349587: Current learning rate: 0.00917 
2025-01-18 16:24:32.223272: train_loss -0.6453 
2025-01-18 16:24:32.223272: val_loss -0.478 
2025-01-18 16:24:32.229292: Pseudo dice [np.float32(0.6367), np.float32(0.4086)] 
2025-01-18 16:24:32.232304: Epoch time: 31.88 s 
2025-01-18 16:24:32.234809: Yayy! New best EMA pseudo Dice: 0.47130000591278076 
2025-01-18 16:24:33.035140:  
2025-01-18 16:24:33.036140: Epoch 24 
2025-01-18 16:24:33.041723: Current learning rate: 0.00913 
2025-01-18 16:25:04.929465: train_loss -0.6083 
2025-01-18 16:25:04.929465: val_loss -0.4981 
2025-01-18 16:25:04.936113: Pseudo dice [np.float32(0.6654), np.float32(0.4192)] 
2025-01-18 16:25:04.939160: Epoch time: 31.89 s 
2025-01-18 16:25:04.942254: Yayy! New best EMA pseudo Dice: 0.47839999198913574 
2025-01-18 16:25:05.754552:  
2025-01-18 16:25:05.755054: Epoch 25 
2025-01-18 16:25:05.760066: Current learning rate: 0.0091 
2025-01-18 16:25:37.630820: train_loss -0.6058 
2025-01-18 16:25:37.631339: val_loss -0.5015 
2025-01-18 16:25:37.636350: Pseudo dice [np.float32(0.6598), np.float32(0.4151)] 
2025-01-18 16:25:37.639860: Epoch time: 31.88 s 
2025-01-18 16:25:37.641981: Yayy! New best EMA pseudo Dice: 0.48429998755455017 
2025-01-18 16:25:38.453027:  
2025-01-18 16:25:38.454027: Epoch 26 
2025-01-18 16:25:38.459085: Current learning rate: 0.00906 
2025-01-18 16:26:10.344231: train_loss -0.6486 
2025-01-18 16:26:10.345236: val_loss -0.5024 
2025-01-18 16:26:10.350251: Pseudo dice [np.float32(0.7038), np.float32(0.4152)] 
2025-01-18 16:26:10.353759: Epoch time: 31.89 s 
2025-01-18 16:26:10.356767: Yayy! New best EMA pseudo Dice: 0.4918000102043152 
2025-01-18 16:26:11.313544:  
2025-01-18 16:26:11.313544: Epoch 27 
2025-01-18 16:26:11.319658: Current learning rate: 0.00902 
2025-01-18 16:26:43.163462: train_loss -0.6536 
2025-01-18 16:26:43.163462: val_loss -0.5165 
2025-01-18 16:26:43.169492: Pseudo dice [np.float32(0.6953), np.float32(0.4521)] 
2025-01-18 16:26:43.170995: Epoch time: 31.85 s 
2025-01-18 16:26:43.175047: Yayy! New best EMA pseudo Dice: 0.5 
2025-01-18 16:26:43.990538:  
2025-01-18 16:26:43.991542: Epoch 28 
2025-01-18 16:26:43.996090: Current learning rate: 0.00899 
2025-01-18 16:27:15.855218: train_loss -0.6208 
2025-01-18 16:27:15.855218: val_loss -0.5453 
2025-01-18 16:27:15.861230: Pseudo dice [np.float32(0.6902), np.float32(0.4818)] 
2025-01-18 16:27:15.864240: Epoch time: 31.87 s 
2025-01-18 16:27:15.866745: Yayy! New best EMA pseudo Dice: 0.5085999965667725 
2025-01-18 16:27:16.696883:  
2025-01-18 16:27:16.696883: Epoch 29 
2025-01-18 16:27:16.702900: Current learning rate: 0.00895 
2025-01-18 16:27:48.552967: train_loss -0.6529 
2025-01-18 16:27:48.552967: val_loss -0.505 
2025-01-18 16:27:48.559014: Pseudo dice [np.float32(0.6666), np.float32(0.4594)] 
2025-01-18 16:27:48.561519: Epoch time: 31.86 s 
2025-01-18 16:27:48.564025: Yayy! New best EMA pseudo Dice: 0.5139999985694885 
2025-01-18 16:27:49.388073:  
2025-01-18 16:27:49.388073: Epoch 30 
2025-01-18 16:27:49.394170: Current learning rate: 0.00891 
2025-01-18 16:28:21.268726: train_loss -0.6776 
2025-01-18 16:28:21.268726: val_loss -0.4939 
2025-01-18 16:28:21.274736: Pseudo dice [np.float32(0.6732), np.float32(0.4262)] 
2025-01-18 16:28:21.277745: Epoch time: 31.88 s 
2025-01-18 16:28:21.280251: Yayy! New best EMA pseudo Dice: 0.5175999999046326 
2025-01-18 16:28:22.100340:  
2025-01-18 16:28:22.100340: Epoch 31 
2025-01-18 16:28:22.105352: Current learning rate: 0.00888 
2025-01-18 16:28:53.973507: train_loss -0.6716 
2025-01-18 16:28:53.974016: val_loss -0.4674 
2025-01-18 16:28:53.979619: Pseudo dice [np.float32(0.691), np.float32(0.3291)] 
2025-01-18 16:28:53.982654: Epoch time: 31.87 s 
2025-01-18 16:28:54.551361:  
2025-01-18 16:28:54.552366: Epoch 32 
2025-01-18 16:28:54.557021: Current learning rate: 0.00884 
2025-01-18 16:29:26.393467: train_loss -0.6472 
2025-01-18 16:29:26.393467: val_loss -0.5132 
2025-01-18 16:29:26.399487: Pseudo dice [np.float32(0.6915), np.float32(0.434)] 
2025-01-18 16:29:26.403496: Epoch time: 31.84 s 
2025-01-18 16:29:26.406542: Yayy! New best EMA pseudo Dice: 0.521399974822998 
2025-01-18 16:29:27.220243:  
2025-01-18 16:29:27.220243: Epoch 33 
2025-01-18 16:29:27.225781: Current learning rate: 0.0088 
2025-01-18 16:29:59.058097: train_loss -0.6683 
2025-01-18 16:29:59.058097: val_loss -0.5453 
2025-01-18 16:29:59.063172: Pseudo dice [np.float32(0.6894), np.float32(0.4926)] 
2025-01-18 16:29:59.067191: Epoch time: 31.84 s 
2025-01-18 16:29:59.069700: Yayy! New best EMA pseudo Dice: 0.5284000039100647 
2025-01-18 16:29:59.892591:  
2025-01-18 16:29:59.893094: Epoch 34 
2025-01-18 16:29:59.898105: Current learning rate: 0.00877 
2025-01-18 16:30:31.723535: train_loss -0.6661 
2025-01-18 16:30:31.724538: val_loss -0.4964 
2025-01-18 16:30:31.730126: Pseudo dice [np.float32(0.6476), np.float32(0.4168)] 
2025-01-18 16:30:31.732677: Epoch time: 31.83 s 
2025-01-18 16:30:31.735760: Yayy! New best EMA pseudo Dice: 0.5288000106811523 
2025-01-18 16:30:32.712265:  
2025-01-18 16:30:32.713269: Epoch 35 
2025-01-18 16:30:32.719878: Current learning rate: 0.00873 
2025-01-18 16:31:04.547189: train_loss -0.6686 
2025-01-18 16:31:04.548189: val_loss -0.4955 
2025-01-18 16:31:04.553735: Pseudo dice [np.float32(0.6685), np.float32(0.3932)] 
2025-01-18 16:31:04.556275: Epoch time: 31.83 s 
2025-01-18 16:31:04.558867: Yayy! New best EMA pseudo Dice: 0.5289999842643738 
2025-01-18 16:31:05.397718:  
2025-01-18 16:31:05.397718: Epoch 36 
2025-01-18 16:31:05.402731: Current learning rate: 0.00869 
2025-01-18 16:31:37.244080: train_loss -0.6884 
2025-01-18 16:31:37.244583: val_loss -0.4709 
2025-01-18 16:31:37.251652: Pseudo dice [np.float32(0.7042), np.float32(0.3599)] 
2025-01-18 16:31:37.254758: Epoch time: 31.85 s 
2025-01-18 16:31:37.257773: Yayy! New best EMA pseudo Dice: 0.5292999744415283 
2025-01-18 16:31:38.078063:  
2025-01-18 16:31:38.078063: Epoch 37 
2025-01-18 16:31:38.083073: Current learning rate: 0.00866 
2025-01-18 16:32:09.914021: train_loss -0.7052 
2025-01-18 16:32:09.914524: val_loss -0.4778 
2025-01-18 16:32:09.919534: Pseudo dice [np.float32(0.6843), np.float32(0.373)] 
2025-01-18 16:32:09.923563: Epoch time: 31.84 s 
2025-01-18 16:32:10.497969:  
2025-01-18 16:32:10.498973: Epoch 38 
2025-01-18 16:32:10.503995: Current learning rate: 0.00862 
2025-01-18 16:32:42.336015: train_loss -0.6837 
2025-01-18 16:32:42.336015: val_loss -0.438 
2025-01-18 16:32:42.342115: Pseudo dice [np.float32(0.6613), np.float32(0.3285)] 
2025-01-18 16:32:42.345147: Epoch time: 31.84 s 
2025-01-18 16:32:42.929044:  
2025-01-18 16:32:42.929044: Epoch 39 
2025-01-18 16:32:42.934119: Current learning rate: 0.00858 
2025-01-18 16:33:14.765725: train_loss -0.6754 
2025-01-18 16:33:14.766731: val_loss -0.4756 
2025-01-18 16:33:14.771744: Pseudo dice [np.float32(0.6938), np.float32(0.3013)] 
2025-01-18 16:33:14.775249: Epoch time: 31.84 s 
2025-01-18 16:33:15.360088:  
2025-01-18 16:33:15.361092: Epoch 40 
2025-01-18 16:33:15.365616: Current learning rate: 0.00855 
2025-01-18 16:33:47.195950: train_loss -0.7153 
2025-01-18 16:33:47.196953: val_loss -0.5432 
2025-01-18 16:33:47.202776: Pseudo dice [np.float32(0.7204), np.float32(0.3986)] 
2025-01-18 16:33:47.205848: Epoch time: 31.84 s 
2025-01-18 16:33:47.789171:  
2025-01-18 16:33:47.789171: Epoch 41 
2025-01-18 16:33:47.795230: Current learning rate: 0.00851 
2025-01-18 16:34:19.633821: train_loss -0.709 
2025-01-18 16:34:19.634325: val_loss -0.5099 
2025-01-18 16:34:19.639441: Pseudo dice [np.float32(0.6661), np.float32(0.4995)] 
2025-01-18 16:34:19.642534: Epoch time: 31.85 s 
2025-01-18 16:34:19.645078: Yayy! New best EMA pseudo Dice: 0.5321999788284302 
2025-01-18 16:34:20.613837:  
2025-01-18 16:34:20.613837: Epoch 42 
2025-01-18 16:34:20.619366: Current learning rate: 0.00847 
2025-01-18 16:34:52.471505: train_loss -0.7128 
2025-01-18 16:34:52.472512: val_loss -0.5143 
2025-01-18 16:34:52.477523: Pseudo dice [np.float32(0.73), np.float32(0.3585)] 
2025-01-18 16:34:52.480030: Epoch time: 31.86 s 
2025-01-18 16:34:52.484038: Yayy! New best EMA pseudo Dice: 0.5333999991416931 
2025-01-18 16:34:53.301082:  
2025-01-18 16:34:53.302085: Epoch 43 
2025-01-18 16:34:53.306789: Current learning rate: 0.00844 
2025-01-18 16:35:25.170120: train_loss -0.7215 
2025-01-18 16:35:25.170120: val_loss -0.4903 
2025-01-18 16:35:25.176143: Pseudo dice [np.float32(0.7281), np.float32(0.3778)] 
2025-01-18 16:35:25.178655: Epoch time: 31.87 s 
2025-01-18 16:35:25.182207: Yayy! New best EMA pseudo Dice: 0.5353999733924866 
2025-01-18 16:35:25.992435:  
2025-01-18 16:35:25.992435: Epoch 44 
2025-01-18 16:35:25.996460: Current learning rate: 0.0084 
2025-01-18 16:35:57.833619: train_loss -0.7328 
2025-01-18 16:35:57.834122: val_loss -0.5312 
2025-01-18 16:35:57.839295: Pseudo dice [np.float32(0.7071), np.float32(0.488)] 
2025-01-18 16:35:57.841853: Epoch time: 31.84 s 
2025-01-18 16:35:57.845405: Yayy! New best EMA pseudo Dice: 0.5415999889373779 
2025-01-18 16:35:58.656142:  
2025-01-18 16:35:58.656142: Epoch 45 
2025-01-18 16:35:58.661174: Current learning rate: 0.00836 
2025-01-18 16:36:30.504843: train_loss -0.6821 
2025-01-18 16:36:30.506352: val_loss -0.5218 
2025-01-18 16:36:30.511945: Pseudo dice [np.float32(0.6961), np.float32(0.4302)] 
2025-01-18 16:36:30.515064: Epoch time: 31.85 s 
2025-01-18 16:36:30.518129: Yayy! New best EMA pseudo Dice: 0.5437999963760376 
2025-01-18 16:36:31.327870:  
2025-01-18 16:36:31.327870: Epoch 46 
2025-01-18 16:36:31.333383: Current learning rate: 0.00833 
2025-01-18 16:37:03.162386: train_loss -0.7049 
2025-01-18 16:37:03.163385: val_loss -0.5288 
2025-01-18 16:37:03.169701: Pseudo dice [np.float32(0.7095), np.float32(0.4278)] 
2025-01-18 16:37:03.171714: Epoch time: 31.84 s 
2025-01-18 16:37:03.174743: Yayy! New best EMA pseudo Dice: 0.5461999773979187 
2025-01-18 16:37:03.993911:  
2025-01-18 16:37:03.994414: Epoch 47 
2025-01-18 16:37:03.999427: Current learning rate: 0.00829 
2025-01-18 16:37:35.864714: train_loss -0.6949 
2025-01-18 16:37:35.865717: val_loss -0.4858 
2025-01-18 16:37:35.870732: Pseudo dice [np.float32(0.7095), np.float32(0.3141)] 
2025-01-18 16:37:35.874742: Epoch time: 31.87 s 
2025-01-18 16:37:36.433411:  
2025-01-18 16:37:36.433411: Epoch 48 
2025-01-18 16:37:36.438955: Current learning rate: 0.00825 
2025-01-18 16:38:08.282211: train_loss -0.7257 
2025-01-18 16:38:08.282211: val_loss -0.4884 
2025-01-18 16:38:08.288222: Pseudo dice [np.float32(0.7104), np.float32(0.3641)] 
2025-01-18 16:38:08.291234: Epoch time: 31.85 s 
2025-01-18 16:38:08.855752:  
2025-01-18 16:38:08.856756: Epoch 49 
2025-01-18 16:38:08.861297: Current learning rate: 0.00822 
2025-01-18 16:38:40.712800: train_loss -0.7373 
2025-01-18 16:38:40.714820: val_loss -0.5222 
2025-01-18 16:38:40.719866: Pseudo dice [np.float32(0.6844), np.float32(0.4791)] 
2025-01-18 16:38:40.723392: Epoch time: 31.86 s 
2025-01-18 16:38:41.652021:  
2025-01-18 16:38:41.652021: Epoch 50 
2025-01-18 16:38:41.657032: Current learning rate: 0.00818 
2025-01-18 16:39:13.460272: train_loss -0.7238 
2025-01-18 16:39:13.460272: val_loss -0.532 
2025-01-18 16:39:13.466794: Pseudo dice [np.float32(0.7141), np.float32(0.4273)] 
2025-01-18 16:39:13.469300: Epoch time: 31.81 s 
2025-01-18 16:39:13.471805: Yayy! New best EMA pseudo Dice: 0.5486000180244446 
2025-01-18 16:39:14.326853:  
2025-01-18 16:39:14.327856: Epoch 51 
2025-01-18 16:39:14.332419: Current learning rate: 0.00814 
2025-01-18 16:39:46.180331: train_loss -0.7385 
2025-01-18 16:39:46.180331: val_loss -0.5328 
2025-01-18 16:39:46.187885: Pseudo dice [np.float32(0.717), np.float32(0.4613)] 
2025-01-18 16:39:46.191425: Epoch time: 31.85 s 
2025-01-18 16:39:46.195450: Yayy! New best EMA pseudo Dice: 0.5526999831199646 
2025-01-18 16:39:47.022063:  
2025-01-18 16:39:47.022063: Epoch 52 
2025-01-18 16:39:47.028077: Current learning rate: 0.00811 
2025-01-18 16:40:18.857334: train_loss -0.7167 
2025-01-18 16:40:18.858341: val_loss -0.5081 
2025-01-18 16:40:18.864481: Pseudo dice [np.float32(0.7035), np.float32(0.4255)] 
2025-01-18 16:40:18.867533: Epoch time: 31.84 s 
2025-01-18 16:40:18.870586: Yayy! New best EMA pseudo Dice: 0.5539000034332275 
2025-01-18 16:40:19.694387:  
2025-01-18 16:40:19.694890: Epoch 53 
2025-01-18 16:40:19.700932: Current learning rate: 0.00807 
2025-01-18 16:40:51.517802: train_loss -0.7451 
2025-01-18 16:40:51.518305: val_loss -0.4926 
2025-01-18 16:40:51.524396: Pseudo dice [np.float32(0.6637), np.float32(0.4458)] 
2025-01-18 16:40:51.527947: Epoch time: 31.82 s 
2025-01-18 16:40:51.531053: Yayy! New best EMA pseudo Dice: 0.5540000200271606 
2025-01-18 16:40:52.347630:  
2025-01-18 16:40:52.348634: Epoch 54 
2025-01-18 16:40:52.354198: Current learning rate: 0.00803 
2025-01-18 16:41:24.188622: train_loss -0.7483 
2025-01-18 16:41:24.188622: val_loss -0.4768 
2025-01-18 16:41:24.194664: Pseudo dice [np.float32(0.7042), np.float32(0.3789)] 
2025-01-18 16:41:24.198673: Epoch time: 31.84 s 
2025-01-18 16:41:24.759013:  
2025-01-18 16:41:24.759013: Epoch 55 
2025-01-18 16:41:24.765029: Current learning rate: 0.008 
2025-01-18 16:41:56.574501: train_loss -0.7195 
2025-01-18 16:41:56.575067: val_loss -0.5254 
2025-01-18 16:41:56.581083: Pseudo dice [np.float32(0.6828), np.float32(0.4943)] 
2025-01-18 16:41:56.584589: Epoch time: 31.82 s 
2025-01-18 16:41:56.587598: Yayy! New best EMA pseudo Dice: 0.5562999844551086 
2025-01-18 16:41:57.413890:  
2025-01-18 16:41:57.414398: Epoch 56 
2025-01-18 16:41:57.418937: Current learning rate: 0.00796 
2025-01-18 16:42:29.251776: train_loss -0.7322 
2025-01-18 16:42:29.252780: val_loss -0.4534 
2025-01-18 16:42:29.259299: Pseudo dice [np.float32(0.6944), np.float32(0.2961)] 
2025-01-18 16:42:29.263308: Epoch time: 31.84 s 
2025-01-18 16:42:29.973249:  
2025-01-18 16:42:29.974253: Epoch 57 
2025-01-18 16:42:29.978809: Current learning rate: 0.00792 
2025-01-18 16:43:01.814009: train_loss -0.7452 
2025-01-18 16:43:01.814009: val_loss -0.4882 
2025-01-18 16:43:01.820560: Pseudo dice [np.float32(0.7229), np.float32(0.3598)] 
2025-01-18 16:43:01.824112: Epoch time: 31.84 s 
2025-01-18 16:43:02.368604:  
2025-01-18 16:43:02.369114: Epoch 58 
2025-01-18 16:43:02.374266: Current learning rate: 0.00789 
2025-01-18 16:43:34.207732: train_loss -0.7682 
2025-01-18 16:43:34.208236: val_loss -0.5267 
2025-01-18 16:43:34.214252: Pseudo dice [np.float32(0.7159), np.float32(0.4375)] 
2025-01-18 16:43:34.217758: Epoch time: 31.84 s 
2025-01-18 16:43:34.783949:  
2025-01-18 16:43:34.784955: Epoch 59 
2025-01-18 16:43:34.790504: Current learning rate: 0.00785 
2025-01-18 16:44:06.643223: train_loss -0.7713 
2025-01-18 16:44:06.644726: val_loss -0.4755 
2025-01-18 16:44:06.649740: Pseudo dice [np.float32(0.7237), np.float32(0.3416)] 
2025-01-18 16:44:06.653253: Epoch time: 31.86 s 
2025-01-18 16:44:07.209656:  
2025-01-18 16:44:07.210660: Epoch 60 
2025-01-18 16:44:07.216197: Current learning rate: 0.00781 
2025-01-18 16:44:39.042388: train_loss -0.773 
2025-01-18 16:44:39.042388: val_loss -0.5443 
2025-01-18 16:44:39.049431: Pseudo dice [np.float32(0.7186), np.float32(0.4308)] 
2025-01-18 16:44:39.053956: Epoch time: 31.83 s 
2025-01-18 16:44:39.613888:  
2025-01-18 16:44:39.614887: Epoch 61 
2025-01-18 16:44:39.620460: Current learning rate: 0.00777 
2025-01-18 16:45:11.447803: train_loss -0.7636 
2025-01-18 16:45:11.447803: val_loss -0.5328 
2025-01-18 16:45:11.455870: Pseudo dice [np.float32(0.7027), np.float32(0.4602)] 
2025-01-18 16:45:11.460398: Epoch time: 31.83 s 
2025-01-18 16:45:12.057640:  
2025-01-18 16:45:12.057640: Epoch 62 
2025-01-18 16:45:12.064206: Current learning rate: 0.00774 
2025-01-18 16:45:43.884647: train_loss -0.7673 
2025-01-18 16:45:43.886150: val_loss -0.4921 
2025-01-18 16:45:43.892169: Pseudo dice [np.float32(0.7059), np.float32(0.4033)] 
2025-01-18 16:45:43.896183: Epoch time: 31.83 s 
2025-01-18 16:45:44.456120:  
2025-01-18 16:45:44.457123: Epoch 63 
2025-01-18 16:45:44.461691: Current learning rate: 0.0077 
2025-01-18 16:46:16.298040: train_loss -0.7745 
2025-01-18 16:46:16.298040: val_loss -0.5123 
2025-01-18 16:46:16.304073: Pseudo dice [np.float32(0.722), np.float32(0.4465)] 
2025-01-18 16:46:16.307653: Epoch time: 31.84 s 
2025-01-18 16:46:16.311693: Yayy! New best EMA pseudo Dice: 0.5583000183105469 
2025-01-18 16:46:17.132416:  
2025-01-18 16:46:17.132416: Epoch 64 
2025-01-18 16:46:17.138518: Current learning rate: 0.00766 
2025-01-18 16:46:48.978257: train_loss -0.7486 
2025-01-18 16:46:48.979761: val_loss -0.4378 
2025-01-18 16:46:48.986285: Pseudo dice [np.float32(0.6836), np.float32(0.3263)] 
2025-01-18 16:46:48.990801: Epoch time: 31.85 s 
2025-01-18 16:46:49.701963:  
2025-01-18 16:46:49.702966: Epoch 65 
2025-01-18 16:46:49.707520: Current learning rate: 0.00763 
2025-01-18 16:47:21.541880: train_loss -0.7675 
2025-01-18 16:47:21.542382: val_loss -0.4882 
2025-01-18 16:47:21.547975: Pseudo dice [np.float32(0.7239), np.float32(0.3246)] 
2025-01-18 16:47:21.551534: Epoch time: 31.84 s 
2025-01-18 16:47:22.111938:  
2025-01-18 16:47:22.111938: Epoch 66 
2025-01-18 16:47:22.118057: Current learning rate: 0.00759 
2025-01-18 16:47:53.959663: train_loss -0.7945 
2025-01-18 16:47:53.959663: val_loss -0.5202 
2025-01-18 16:47:53.966758: Pseudo dice [np.float32(0.7074), np.float32(0.452)] 
2025-01-18 16:47:53.970298: Epoch time: 31.85 s 
2025-01-18 16:47:54.531262:  
2025-01-18 16:47:54.531262: Epoch 67 
2025-01-18 16:47:54.536811: Current learning rate: 0.00755 
2025-01-18 16:48:26.384434: train_loss -0.7696 
2025-01-18 16:48:26.384434: val_loss -0.5012 
2025-01-18 16:48:26.390450: Pseudo dice [np.float32(0.7065), np.float32(0.3738)] 
2025-01-18 16:48:26.394487: Epoch time: 31.85 s 
2025-01-18 16:48:26.966603:  
2025-01-18 16:48:26.967606: Epoch 68 
2025-01-18 16:48:26.972699: Current learning rate: 0.00751 
2025-01-18 16:48:58.811613: train_loss -0.7753 
2025-01-18 16:48:58.811613: val_loss -0.4995 
2025-01-18 16:48:58.818663: Pseudo dice [np.float32(0.6822), np.float32(0.3755)] 
2025-01-18 16:48:58.821736: Epoch time: 31.85 s 
2025-01-18 16:48:59.394622:  
2025-01-18 16:48:59.394622: Epoch 69 
2025-01-18 16:48:59.399805: Current learning rate: 0.00748 
2025-01-18 16:49:31.248029: train_loss -0.7576 
2025-01-18 16:49:31.248029: val_loss -0.4729 
2025-01-18 16:49:31.254550: Pseudo dice [np.float32(0.6926), np.float32(0.3749)] 
2025-01-18 16:49:31.258060: Epoch time: 31.85 s 
2025-01-18 16:49:31.835274:  
2025-01-18 16:49:31.836278: Epoch 70 
2025-01-18 16:49:31.840831: Current learning rate: 0.00744 
2025-01-18 16:50:03.689981: train_loss -0.7742 
2025-01-18 16:50:03.690982: val_loss -0.4986 
2025-01-18 16:50:03.696504: Pseudo dice [np.float32(0.7166), np.float32(0.4015)] 
2025-01-18 16:50:03.702077: Epoch time: 31.85 s 
2025-01-18 16:50:04.268577:  
2025-01-18 16:50:04.268577: Epoch 71 
2025-01-18 16:50:04.274102: Current learning rate: 0.0074 
2025-01-18 16:50:36.123849: train_loss -0.7899 
2025-01-18 16:50:36.123849: val_loss -0.4866 
2025-01-18 16:50:36.129867: Pseudo dice [np.float32(0.686), np.float32(0.4047)] 
2025-01-18 16:50:36.133373: Epoch time: 31.86 s 
2025-01-18 16:50:36.700124:  
2025-01-18 16:50:36.701128: Epoch 72 
2025-01-18 16:50:36.705670: Current learning rate: 0.00737 
2025-01-18 16:51:08.576426: train_loss -0.791 
2025-01-18 16:51:08.576426: val_loss -0.4887 
2025-01-18 16:51:08.582941: Pseudo dice [np.float32(0.6922), np.float32(0.4247)] 
2025-01-18 16:51:08.586014: Epoch time: 31.88 s 
2025-01-18 16:51:09.302386:  
2025-01-18 16:51:09.302892: Epoch 73 
2025-01-18 16:51:09.307442: Current learning rate: 0.00733 
2025-01-18 16:51:41.152412: train_loss -0.7849 
2025-01-18 16:51:41.152921: val_loss -0.4972 
2025-01-18 16:51:41.159512: Pseudo dice [np.float32(0.6955), np.float32(0.3626)] 
2025-01-18 16:51:41.164089: Epoch time: 31.85 s 
2025-01-18 16:51:41.733829:  
2025-01-18 16:51:41.733829: Epoch 74 
2025-01-18 16:51:41.740392: Current learning rate: 0.00729 
2025-01-18 16:52:13.594573: train_loss -0.793 
2025-01-18 16:52:13.595075: val_loss -0.502 
2025-01-18 16:52:13.601179: Pseudo dice [np.float32(0.7145), np.float32(0.3882)] 
2025-01-18 16:52:13.603722: Epoch time: 31.86 s 
2025-01-18 16:52:14.177355:  
2025-01-18 16:52:14.177355: Epoch 75 
2025-01-18 16:52:14.182884: Current learning rate: 0.00725 
2025-01-18 16:52:46.035258: train_loss -0.8032 
2025-01-18 16:52:46.036760: val_loss -0.4809 
2025-01-18 16:52:46.042781: Pseudo dice [np.float32(0.707), np.float32(0.3284)] 
2025-01-18 16:52:46.045290: Epoch time: 31.86 s 
2025-01-18 16:52:46.644507:  
2025-01-18 16:52:46.645508: Epoch 76 
2025-01-18 16:52:46.651109: Current learning rate: 0.00722 
2025-01-18 16:53:18.487308: train_loss -0.7966 
2025-01-18 16:53:18.487811: val_loss -0.4518 
2025-01-18 16:53:18.493360: Pseudo dice [np.float32(0.6995), np.float32(0.2518)] 
2025-01-18 16:53:18.496407: Epoch time: 31.84 s 
2025-01-18 16:53:19.066386:  
2025-01-18 16:53:19.066386: Epoch 77 
2025-01-18 16:53:19.071934: Current learning rate: 0.00718 
2025-01-18 16:53:50.938478: train_loss -0.8018 
2025-01-18 16:53:50.938980: val_loss -0.5185 
2025-01-18 16:53:50.944994: Pseudo dice [np.float32(0.697), np.float32(0.4274)] 
2025-01-18 16:53:50.949005: Epoch time: 31.87 s 
2025-01-18 16:53:51.517292:  
2025-01-18 16:53:51.518298: Epoch 78 
2025-01-18 16:53:51.523354: Current learning rate: 0.00714 
2025-01-18 16:54:23.359307: train_loss -0.7902 
2025-01-18 16:54:23.359813: val_loss -0.5125 
2025-01-18 16:54:23.366394: Pseudo dice [np.float32(0.7411), np.float32(0.3633)] 
2025-01-18 16:54:23.369929: Epoch time: 31.84 s 
2025-01-18 16:54:23.939854:  
2025-01-18 16:54:23.940857: Epoch 79 
2025-01-18 16:54:23.945400: Current learning rate: 0.0071 
2025-01-18 16:54:55.785376: train_loss -0.7753 
2025-01-18 16:54:55.786377: val_loss -0.5452 
2025-01-18 16:54:55.792920: Pseudo dice [np.float32(0.6974), np.float32(0.5098)] 
2025-01-18 16:54:55.796424: Epoch time: 31.85 s 
2025-01-18 16:54:56.378605:  
2025-01-18 16:54:56.379606: Epoch 80 
2025-01-18 16:54:56.385187: Current learning rate: 0.00707 
2025-01-18 16:55:28.311744: train_loss -0.7724 
2025-01-18 16:55:28.313250: val_loss -0.4797 
2025-01-18 16:55:28.318269: Pseudo dice [np.float32(0.7059), np.float32(0.3711)] 
2025-01-18 16:55:28.322784: Epoch time: 31.93 s 
2025-01-18 16:55:28.906112:  
2025-01-18 16:55:28.907115: Epoch 81 
2025-01-18 16:55:28.912216: Current learning rate: 0.00703 
2025-01-18 16:56:00.749347: train_loss -0.7536 
2025-01-18 16:56:00.750850: val_loss -0.4751 
2025-01-18 16:56:00.756866: Pseudo dice [np.float32(0.6974), np.float32(0.3396)] 
2025-01-18 16:56:00.761878: Epoch time: 31.84 s 
2025-01-18 16:56:01.338537:  
2025-01-18 16:56:01.338537: Epoch 82 
2025-01-18 16:56:01.343548: Current learning rate: 0.00699 
2025-01-18 16:56:33.197153: train_loss -0.804 
2025-01-18 16:56:33.197657: val_loss -0.509 
2025-01-18 16:56:33.202667: Pseudo dice [np.float32(0.7148), np.float32(0.4564)] 
2025-01-18 16:56:33.206176: Epoch time: 31.86 s 
2025-01-18 16:56:33.757988:  
2025-01-18 16:56:33.758989: Epoch 83 
2025-01-18 16:56:33.764056: Current learning rate: 0.00696 
2025-01-18 16:57:05.630440: train_loss -0.8103 
2025-01-18 16:57:05.630952: val_loss -0.4686 
2025-01-18 16:57:05.638682: Pseudo dice [np.float32(0.7444), np.float32(0.2932)] 
2025-01-18 16:57:05.642251: Epoch time: 31.87 s 
2025-01-18 16:57:06.190578:  
2025-01-18 16:57:06.190578: Epoch 84 
2025-01-18 16:57:06.195624: Current learning rate: 0.00692 
2025-01-18 16:57:38.057513: train_loss -0.8157 
2025-01-18 16:57:38.058015: val_loss -0.481 
2025-01-18 16:57:38.063066: Pseudo dice [np.float32(0.7012), np.float32(0.357)] 
2025-01-18 16:57:38.067098: Epoch time: 31.87 s 
2025-01-18 16:57:38.610482:  
2025-01-18 16:57:38.610482: Epoch 85 
2025-01-18 16:57:38.619080: Current learning rate: 0.00688 
2025-01-18 16:58:10.479013: train_loss -0.803 
2025-01-18 16:58:10.480014: val_loss -0.5144 
2025-01-18 16:58:10.486540: Pseudo dice [np.float32(0.7048), np.float32(0.3811)] 
2025-01-18 16:58:10.490048: Epoch time: 31.87 s 
2025-01-18 16:58:11.033211:  
2025-01-18 16:58:11.033211: Epoch 86 
2025-01-18 16:58:11.040795: Current learning rate: 0.00684 
2025-01-18 16:58:42.893909: train_loss -0.8127 
2025-01-18 16:58:42.894412: val_loss -0.5333 
2025-01-18 16:58:42.901428: Pseudo dice [np.float32(0.7008), np.float32(0.4281)] 
2025-01-18 16:58:42.905441: Epoch time: 31.86 s 
2025-01-18 16:58:43.454770:  
2025-01-18 16:58:43.455272: Epoch 87 
2025-01-18 16:58:43.461287: Current learning rate: 0.0068 
2025-01-18 16:59:15.331681: train_loss -0.7976 
2025-01-18 16:59:15.332186: val_loss -0.5182 
2025-01-18 16:59:15.338212: Pseudo dice [np.float32(0.7139), np.float32(0.4224)] 
2025-01-18 16:59:15.342222: Epoch time: 31.88 s 
2025-01-18 16:59:15.890838:  
2025-01-18 16:59:15.890838: Epoch 88 
2025-01-18 16:59:15.896890: Current learning rate: 0.00677 
2025-01-18 16:59:47.761457: train_loss -0.7801 
2025-01-18 16:59:47.762459: val_loss -0.4709 
2025-01-18 16:59:47.770527: Pseudo dice [np.float32(0.7246), np.float32(0.3073)] 
2025-01-18 16:59:47.775538: Epoch time: 31.87 s 
2025-01-18 16:59:48.475158:  
2025-01-18 16:59:48.475158: Epoch 89 
2025-01-18 16:59:48.481292: Current learning rate: 0.00673 
2025-01-18 17:00:20.329149: train_loss -0.7999 
2025-01-18 17:00:20.330151: val_loss -0.4403 
2025-01-18 17:00:20.335721: Pseudo dice [np.float32(0.7077), np.float32(0.223)] 
2025-01-18 17:00:20.338773: Epoch time: 31.85 s 
2025-01-18 17:00:20.890855:  
2025-01-18 17:00:20.890855: Epoch 90 
2025-01-18 17:00:20.896393: Current learning rate: 0.00669 
2025-01-18 17:00:52.731906: train_loss -0.7643 
2025-01-18 17:00:52.732908: val_loss -0.5155 
2025-01-18 17:00:52.738986: Pseudo dice [np.float32(0.7302), np.float32(0.4494)] 
2025-01-18 17:00:52.742037: Epoch time: 31.84 s 
2025-01-18 17:00:53.293308:  
2025-01-18 17:00:53.293308: Epoch 91 
2025-01-18 17:00:53.298367: Current learning rate: 0.00665 
2025-01-18 17:01:25.143170: train_loss -0.8052 
2025-01-18 17:01:25.143170: val_loss -0.487 
2025-01-18 17:01:25.149207: Pseudo dice [np.float32(0.7157), np.float32(0.3045)] 
2025-01-18 17:01:25.152247: Epoch time: 31.85 s 
2025-01-18 17:01:25.703007:  
2025-01-18 17:01:25.704010: Epoch 92 
2025-01-18 17:01:25.708579: Current learning rate: 0.00662 
2025-01-18 17:01:57.563185: train_loss -0.8166 
2025-01-18 17:01:57.563701: val_loss -0.4984 
2025-01-18 17:01:57.569278: Pseudo dice [np.float32(0.7167), np.float32(0.4354)] 
2025-01-18 17:01:57.572366: Epoch time: 31.86 s 
2025-01-18 17:01:58.118300:  
2025-01-18 17:01:58.118300: Epoch 93 
2025-01-18 17:01:58.123311: Current learning rate: 0.00658 
2025-01-18 17:02:29.964219: train_loss -0.8294 
2025-01-18 17:02:29.964219: val_loss -0.4872 
2025-01-18 17:02:29.969232: Pseudo dice [np.float32(0.7535), np.float32(0.3843)] 
2025-01-18 17:02:29.973778: Epoch time: 31.85 s 
2025-01-18 17:02:30.526465:  
2025-01-18 17:02:30.526465: Epoch 94 
2025-01-18 17:02:30.532028: Current learning rate: 0.00654 
2025-01-18 17:03:02.377523: train_loss -0.8194 
2025-01-18 17:03:02.378039: val_loss -0.4906 
2025-01-18 17:03:02.383060: Pseudo dice [np.float32(0.729), np.float32(0.389)] 
2025-01-18 17:03:02.386570: Epoch time: 31.85 s 
2025-01-18 17:03:02.935019:  
2025-01-18 17:03:02.935019: Epoch 95 
2025-01-18 17:03:02.940031: Current learning rate: 0.0065 
2025-01-18 17:03:34.769111: train_loss -0.8274 
2025-01-18 17:03:34.769613: val_loss -0.4967 
2025-01-18 17:03:34.775148: Pseudo dice [np.float32(0.7213), np.float32(0.4115)] 
2025-01-18 17:03:34.778191: Epoch time: 31.83 s 
2025-01-18 17:03:35.335487:  
2025-01-18 17:03:35.335487: Epoch 96 
2025-01-18 17:03:35.341038: Current learning rate: 0.00647 
2025-01-18 17:04:07.185403: train_loss -0.8331 
2025-01-18 17:04:07.186402: val_loss -0.506 
2025-01-18 17:04:07.191432: Pseudo dice [np.float32(0.7028), np.float32(0.386)] 
2025-01-18 17:04:07.195090: Epoch time: 31.85 s 
2025-01-18 17:04:07.895428:  
2025-01-18 17:04:07.896431: Epoch 97 
2025-01-18 17:04:07.901011: Current learning rate: 0.00643 
2025-01-18 17:04:39.724901: train_loss -0.8406 
2025-01-18 17:04:39.724901: val_loss -0.4856 
2025-01-18 17:04:39.730920: Pseudo dice [np.float32(0.7008), np.float32(0.3657)] 
2025-01-18 17:04:39.734427: Epoch time: 31.83 s 
2025-01-18 17:04:40.295488:  
2025-01-18 17:04:40.295488: Epoch 98 
2025-01-18 17:04:40.301046: Current learning rate: 0.00639 
2025-01-18 17:05:12.130429: train_loss -0.8371 
2025-01-18 17:05:12.130429: val_loss -0.4848 
2025-01-18 17:05:12.136447: Pseudo dice [np.float32(0.6964), np.float32(0.3641)] 
2025-01-18 17:05:12.138956: Epoch time: 31.84 s 
2025-01-18 17:05:12.704054:  
2025-01-18 17:05:12.704054: Epoch 99 
2025-01-18 17:05:12.709066: Current learning rate: 0.00635 
2025-01-18 17:05:44.552960: train_loss -0.8311 
2025-01-18 17:05:44.553961: val_loss -0.5014 
2025-01-18 17:05:44.560484: Pseudo dice [np.float32(0.7135), np.float32(0.3901)] 
2025-01-18 17:05:44.563989: Epoch time: 31.85 s 
2025-01-18 17:05:45.406232:  
2025-01-18 17:05:45.407233: Epoch 100 
2025-01-18 17:05:45.412298: Current learning rate: 0.00631 
2025-01-18 17:06:17.251044: train_loss -0.82 
2025-01-18 17:06:17.252043: val_loss -0.4665 
2025-01-18 17:06:17.257576: Pseudo dice [np.float32(0.727), np.float32(0.3657)] 
2025-01-18 17:06:17.260163: Epoch time: 31.85 s 
2025-01-18 17:06:17.826749:  
2025-01-18 17:06:17.826749: Epoch 101 
2025-01-18 17:06:17.832901: Current learning rate: 0.00628 
2025-01-18 17:06:49.673321: train_loss -0.8172 
2025-01-18 17:06:49.673321: val_loss -0.5077 
2025-01-18 17:06:49.679350: Pseudo dice [np.float32(0.711), np.float32(0.3896)] 
2025-01-18 17:06:49.682874: Epoch time: 31.85 s 
2025-01-18 17:06:50.242354:  
2025-01-18 17:06:50.243360: Epoch 102 
2025-01-18 17:06:50.247901: Current learning rate: 0.00624 
2025-01-18 17:07:22.092103: train_loss -0.8205 
2025-01-18 17:07:22.092103: val_loss -0.4888 
2025-01-18 17:07:22.097208: Pseudo dice [np.float32(0.7013), np.float32(0.3656)] 
2025-01-18 17:07:22.100735: Epoch time: 31.85 s 
2025-01-18 17:07:22.659255:  
2025-01-18 17:07:22.659255: Epoch 103 
2025-01-18 17:07:22.663950: Current learning rate: 0.0062 
2025-01-18 17:07:54.512710: train_loss -0.8185 
2025-01-18 17:07:54.513713: val_loss -0.4768 
2025-01-18 17:07:54.518731: Pseudo dice [np.float32(0.713), np.float32(0.3752)] 
2025-01-18 17:07:54.522238: Epoch time: 31.85 s 
2025-01-18 17:07:55.098080:  
2025-01-18 17:07:55.099083: Epoch 104 
2025-01-18 17:07:55.103824: Current learning rate: 0.00616 
2025-01-18 17:08:26.954276: train_loss -0.8262 
2025-01-18 17:08:26.954276: val_loss -0.5224 
2025-01-18 17:08:26.960364: Pseudo dice [np.float32(0.7255), np.float32(0.4128)] 
2025-01-18 17:08:26.962406: Epoch time: 31.86 s 
2025-01-18 17:08:27.687112:  
2025-01-18 17:08:27.687615: Epoch 105 
2025-01-18 17:08:27.692627: Current learning rate: 0.00612 
2025-01-18 17:08:59.546808: train_loss -0.8355 
2025-01-18 17:08:59.547808: val_loss -0.5269 
2025-01-18 17:08:59.553355: Pseudo dice [np.float32(0.7271), np.float32(0.4393)] 
2025-01-18 17:08:59.555861: Epoch time: 31.86 s 
2025-01-18 17:09:00.118576:  
2025-01-18 17:09:00.119582: Epoch 106 
2025-01-18 17:09:00.124124: Current learning rate: 0.00609 
2025-01-18 17:09:31.962810: train_loss -0.8461 
2025-01-18 17:09:31.963312: val_loss -0.494 
2025-01-18 17:09:31.968325: Pseudo dice [np.float32(0.7194), np.float32(0.3404)] 
2025-01-18 17:09:31.971834: Epoch time: 31.84 s 
2025-01-18 17:09:32.537920:  
2025-01-18 17:09:32.538424: Epoch 107 
2025-01-18 17:09:32.543437: Current learning rate: 0.00605 
2025-01-18 17:10:04.386172: train_loss -0.8399 
2025-01-18 17:10:04.386172: val_loss -0.5014 
2025-01-18 17:10:04.392041: Pseudo dice [np.float32(0.7247), np.float32(0.346)] 
2025-01-18 17:10:04.395161: Epoch time: 31.85 s 
2025-01-18 17:10:04.963905:  
2025-01-18 17:10:04.964907: Epoch 108 
2025-01-18 17:10:04.969474: Current learning rate: 0.00601 
2025-01-18 17:10:36.803617: train_loss -0.8455 
2025-01-18 17:10:36.804623: val_loss -0.4896 
2025-01-18 17:10:36.810146: Pseudo dice [np.float32(0.7261), np.float32(0.3824)] 
2025-01-18 17:10:36.813704: Epoch time: 31.84 s 
2025-01-18 17:10:37.381786:  
2025-01-18 17:10:37.381786: Epoch 109 
2025-01-18 17:10:37.387313: Current learning rate: 0.00597 
2025-01-18 17:11:09.237719: train_loss -0.8385 
2025-01-18 17:11:09.238723: val_loss -0.4888 
2025-01-18 17:11:09.244739: Pseudo dice [np.float32(0.7182), np.float32(0.3607)] 
2025-01-18 17:11:09.247748: Epoch time: 31.86 s 
2025-01-18 17:11:09.806336:  
2025-01-18 17:11:09.806840: Epoch 110 
2025-01-18 17:11:09.811857: Current learning rate: 0.00593 
2025-01-18 17:11:41.663397: train_loss -0.8387 
2025-01-18 17:11:41.664402: val_loss -0.4476 
2025-01-18 17:11:41.669472: Pseudo dice [np.float32(0.6986), np.float32(0.254)] 
2025-01-18 17:11:41.672500: Epoch time: 31.86 s 
2025-01-18 17:11:42.230682:  
2025-01-18 17:11:42.231688: Epoch 111 
2025-01-18 17:11:42.235212: Current learning rate: 0.0059 
2025-01-18 17:12:14.069381: train_loss -0.8439 
2025-01-18 17:12:14.069896: val_loss -0.4963 
2025-01-18 17:12:14.074973: Pseudo dice [np.float32(0.7301), np.float32(0.3542)] 
2025-01-18 17:12:14.078531: Epoch time: 31.84 s 
2025-01-18 17:12:14.646381:  
2025-01-18 17:12:14.647384: Epoch 112 
2025-01-18 17:12:14.651927: Current learning rate: 0.00586 
2025-01-18 17:12:46.488078: train_loss -0.846 
2025-01-18 17:12:46.488582: val_loss -0.4992 
2025-01-18 17:12:46.495602: Pseudo dice [np.float32(0.71), np.float32(0.3539)] 
2025-01-18 17:12:46.498612: Epoch time: 31.84 s 
2025-01-18 17:12:47.208423:  
2025-01-18 17:12:47.208423: Epoch 113 
2025-01-18 17:12:47.213977: Current learning rate: 0.00582 
2025-01-18 17:13:19.052972: train_loss -0.8591 
2025-01-18 17:13:19.052972: val_loss -0.4676 
2025-01-18 17:13:19.058989: Pseudo dice [np.float32(0.729), np.float32(0.2857)] 
2025-01-18 17:13:19.061496: Epoch time: 31.85 s 
2025-01-18 17:13:19.615474:  
2025-01-18 17:13:19.615977: Epoch 114 
2025-01-18 17:13:19.620988: Current learning rate: 0.00578 
2025-01-18 17:13:51.458640: train_loss -0.8585 
2025-01-18 17:13:51.459644: val_loss -0.5315 
2025-01-18 17:13:51.465760: Pseudo dice [np.float32(0.7382), np.float32(0.4488)] 
2025-01-18 17:13:51.469307: Epoch time: 31.84 s 
2025-01-18 17:13:52.019763:  
2025-01-18 17:13:52.020766: Epoch 115 
2025-01-18 17:13:52.024803: Current learning rate: 0.00574 
2025-01-18 17:14:23.847877: train_loss -0.8521 
2025-01-18 17:14:23.848381: val_loss -0.496 
2025-01-18 17:14:23.854441: Pseudo dice [np.float32(0.7081), np.float32(0.3884)] 
2025-01-18 17:14:23.856968: Epoch time: 31.83 s 
2025-01-18 17:14:24.438587:  
2025-01-18 17:14:24.439095: Epoch 116 
2025-01-18 17:14:24.444141: Current learning rate: 0.0057 
2025-01-18 17:14:56.274695: train_loss -0.8663 
2025-01-18 17:14:56.276197: val_loss -0.5045 
2025-01-18 17:14:56.281209: Pseudo dice [np.float32(0.7221), np.float32(0.4154)] 
2025-01-18 17:14:56.284719: Epoch time: 31.84 s 
2025-01-18 17:14:56.847345:  
2025-01-18 17:14:56.847345: Epoch 117 
2025-01-18 17:14:56.853363: Current learning rate: 0.00567 
2025-01-18 17:15:28.696784: train_loss -0.8654 
2025-01-18 17:15:28.697784: val_loss -0.4955 
2025-01-18 17:15:28.703329: Pseudo dice [np.float32(0.7058), np.float32(0.4336)] 
2025-01-18 17:15:28.705834: Epoch time: 31.85 s 
2025-01-18 17:15:29.277904:  
2025-01-18 17:15:29.278907: Epoch 118 
2025-01-18 17:15:29.283508: Current learning rate: 0.00563 
2025-01-18 17:16:01.152059: train_loss -0.8561 
2025-01-18 17:16:01.152059: val_loss -0.4705 
2025-01-18 17:16:01.158015: Pseudo dice [np.float32(0.6914), np.float32(0.3573)] 
2025-01-18 17:16:01.161535: Epoch time: 31.87 s 
2025-01-18 17:16:01.722955:  
2025-01-18 17:16:01.723959: Epoch 119 
2025-01-18 17:16:01.728068: Current learning rate: 0.00559 
2025-01-18 17:16:33.580059: train_loss -0.8575 
2025-01-18 17:16:33.580562: val_loss -0.4736 
2025-01-18 17:16:33.585574: Pseudo dice [np.float32(0.7128), np.float32(0.3482)] 
2025-01-18 17:16:33.589084: Epoch time: 31.86 s 
2025-01-18 17:16:34.155121:  
2025-01-18 17:16:34.155121: Epoch 120 
2025-01-18 17:16:34.160660: Current learning rate: 0.00555 
2025-01-18 17:17:06.001239: train_loss -0.8528 
2025-01-18 17:17:06.002245: val_loss -0.4855 
2025-01-18 17:17:06.007255: Pseudo dice [np.float32(0.7296), np.float32(0.332)] 
2025-01-18 17:17:06.010762: Epoch time: 31.85 s 
2025-01-18 17:17:06.719398:  
2025-01-18 17:17:06.719902: Epoch 121 
2025-01-18 17:17:06.723410: Current learning rate: 0.00551 
2025-01-18 17:17:38.577256: train_loss -0.863 
2025-01-18 17:17:38.577777: val_loss -0.4683 
2025-01-18 17:17:38.582330: Pseudo dice [np.float32(0.7322), np.float32(0.3053)] 
2025-01-18 17:17:38.586377: Epoch time: 31.86 s 
2025-01-18 17:17:39.144253:  
2025-01-18 17:17:39.144253: Epoch 122 
2025-01-18 17:17:39.150833: Current learning rate: 0.00547 
2025-01-18 17:18:10.995684: train_loss -0.8558 
2025-01-18 17:18:10.996198: val_loss -0.4733 
2025-01-18 17:18:11.003257: Pseudo dice [np.float32(0.7068), np.float32(0.3213)] 
2025-01-18 17:18:11.006367: Epoch time: 31.85 s 
2025-01-18 17:18:11.568543:  
2025-01-18 17:18:11.569543: Epoch 123 
2025-01-18 17:18:11.575149: Current learning rate: 0.00544 
2025-01-18 17:18:43.423577: train_loss -0.8612 
2025-01-18 17:18:43.424577: val_loss -0.4584 
2025-01-18 17:18:43.431125: Pseudo dice [np.float32(0.7158), np.float32(0.3112)] 
2025-01-18 17:18:43.435072: Epoch time: 31.86 s 
2025-01-18 17:18:44.004799:  
2025-01-18 17:18:44.004799: Epoch 124 
2025-01-18 17:18:44.011362: Current learning rate: 0.0054 
2025-01-18 17:19:15.861472: train_loss -0.8648 
2025-01-18 17:19:15.861472: val_loss -0.4333 
2025-01-18 17:19:15.867996: Pseudo dice [np.float32(0.7001), np.float32(0.2744)] 
2025-01-18 17:19:15.872509: Epoch time: 31.86 s 
2025-01-18 17:19:16.453092:  
2025-01-18 17:19:16.454095: Epoch 125 
2025-01-18 17:19:16.458725: Current learning rate: 0.00536 
2025-01-18 17:19:48.302899: train_loss -0.8708 
2025-01-18 17:19:48.302899: val_loss -0.4056 
2025-01-18 17:19:48.310508: Pseudo dice [np.float32(0.7123), np.float32(0.2005)] 
2025-01-18 17:19:48.313052: Epoch time: 31.85 s 
2025-01-18 17:19:48.890475:  
2025-01-18 17:19:48.890977: Epoch 126 
2025-01-18 17:19:48.898494: Current learning rate: 0.00532 
2025-01-18 17:20:20.763675: train_loss -0.8566 
2025-01-18 17:20:20.764180: val_loss -0.468 
2025-01-18 17:20:20.769761: Pseudo dice [np.float32(0.7152), np.float32(0.3199)] 
2025-01-18 17:20:20.774823: Epoch time: 31.87 s 
2025-01-18 17:20:21.343788:  
2025-01-18 17:20:21.344795: Epoch 127 
2025-01-18 17:20:21.349334: Current learning rate: 0.00528 
2025-01-18 17:20:53.207254: train_loss -0.8611 
2025-01-18 17:20:53.207254: val_loss -0.5001 
2025-01-18 17:20:53.214782: Pseudo dice [np.float32(0.7063), np.float32(0.3792)] 
2025-01-18 17:20:53.218791: Epoch time: 31.86 s 
2025-01-18 17:20:53.786531:  
2025-01-18 17:20:53.786531: Epoch 128 
2025-01-18 17:20:53.792061: Current learning rate: 0.00524 
2025-01-18 17:21:25.653995: train_loss -0.8601 
2025-01-18 17:21:25.654499: val_loss -0.4699 
2025-01-18 17:21:25.660517: Pseudo dice [np.float32(0.7234), np.float32(0.2749)] 
2025-01-18 17:21:25.664024: Epoch time: 31.87 s 
2025-01-18 17:21:26.375789:  
2025-01-18 17:21:26.376294: Epoch 129 
2025-01-18 17:21:26.382309: Current learning rate: 0.0052 
2025-01-18 17:21:58.221171: train_loss -0.8602 
2025-01-18 17:21:58.221676: val_loss -0.4633 
2025-01-18 17:21:58.228697: Pseudo dice [np.float32(0.7193), np.float32(0.3166)] 
2025-01-18 17:21:58.232709: Epoch time: 31.85 s 
2025-01-18 17:21:58.796259:  
2025-01-18 17:21:58.796259: Epoch 130 
2025-01-18 17:21:58.802808: Current learning rate: 0.00517 
2025-01-18 17:22:30.636122: train_loss -0.8625 
2025-01-18 17:22:30.637122: val_loss -0.4485 
2025-01-18 17:22:30.642639: Pseudo dice [np.float32(0.7094), np.float32(0.2577)] 
2025-01-18 17:22:30.646151: Epoch time: 31.84 s 
2025-01-18 17:22:31.213745:  
2025-01-18 17:22:31.214749: Epoch 131 
2025-01-18 17:22:31.220945: Current learning rate: 0.00513 
2025-01-18 17:23:03.057191: train_loss -0.8589 
2025-01-18 17:23:03.057707: val_loss -0.453 
2025-01-18 17:23:03.064297: Pseudo dice [np.float32(0.7113), np.float32(0.2824)] 
2025-01-18 17:23:03.067849: Epoch time: 31.84 s 
2025-01-18 17:23:03.627247:  
2025-01-18 17:23:03.628246: Epoch 132 
2025-01-18 17:23:03.633869: Current learning rate: 0.00509 
2025-01-18 17:23:35.476690: train_loss -0.868 
2025-01-18 17:23:35.478786: val_loss -0.4582 
2025-01-18 17:23:35.485369: Pseudo dice [np.float32(0.7271), np.float32(0.2551)] 
2025-01-18 17:23:35.489987: Epoch time: 31.85 s 
2025-01-18 17:23:36.061635:  
2025-01-18 17:23:36.061635: Epoch 133 
2025-01-18 17:23:36.067681: Current learning rate: 0.00505 
2025-01-18 17:24:07.901711: train_loss -0.8648 
2025-01-18 17:24:07.902223: val_loss -0.5133 
2025-01-18 17:24:07.908240: Pseudo dice [np.float32(0.7014), np.float32(0.4321)] 
2025-01-18 17:24:07.913255: Epoch time: 31.84 s 
2025-01-18 17:24:08.483040:  
2025-01-18 17:24:08.484040: Epoch 134 
2025-01-18 17:24:08.489607: Current learning rate: 0.00501 
2025-01-18 17:24:40.320240: train_loss -0.8612 
2025-01-18 17:24:40.320240: val_loss -0.4384 
2025-01-18 17:24:40.326256: Pseudo dice [np.float32(0.703), np.float32(0.2875)] 
2025-01-18 17:24:40.329765: Epoch time: 31.84 s 
2025-01-18 17:24:40.897590:  
2025-01-18 17:24:40.897590: Epoch 135 
2025-01-18 17:24:40.902601: Current learning rate: 0.00497 
2025-01-18 17:25:12.739668: train_loss -0.8441 
2025-01-18 17:25:12.739668: val_loss -0.4721 
2025-01-18 17:25:12.748242: Pseudo dice [np.float32(0.697), np.float32(0.3747)] 
2025-01-18 17:25:12.751290: Epoch time: 31.84 s 
2025-01-18 17:25:13.322457:  
2025-01-18 17:25:13.322457: Epoch 136 
2025-01-18 17:25:13.330034: Current learning rate: 0.00493 
2025-01-18 17:25:45.178213: train_loss -0.8591 
2025-01-18 17:25:45.178735: val_loss -0.4972 
2025-01-18 17:25:45.185353: Pseudo dice [np.float32(0.7002), np.float32(0.3865)] 
2025-01-18 17:25:45.189411: Epoch time: 31.86 s 
2025-01-18 17:25:45.941281:  
2025-01-18 17:25:45.942279: Epoch 137 
2025-01-18 17:25:45.947855: Current learning rate: 0.00489 
2025-01-18 17:26:17.789773: train_loss -0.8609 
2025-01-18 17:26:17.790772: val_loss -0.4329 
2025-01-18 17:26:17.797303: Pseudo dice [np.float32(0.7014), np.float32(0.2657)] 
2025-01-18 17:26:17.801311: Epoch time: 31.85 s 
2025-01-18 17:26:18.379530:  
2025-01-18 17:26:18.380534: Epoch 138 
2025-01-18 17:26:18.385090: Current learning rate: 0.00485 
2025-01-18 17:26:50.225546: train_loss -0.8659 
2025-01-18 17:26:50.225546: val_loss -0.4511 
2025-01-18 17:26:50.232069: Pseudo dice [np.float32(0.7028), np.float32(0.274)] 
2025-01-18 17:26:50.236617: Epoch time: 31.85 s 
2025-01-18 17:26:50.815849:  
2025-01-18 17:26:50.815849: Epoch 139 
2025-01-18 17:26:50.821483: Current learning rate: 0.00482 
2025-01-18 17:27:22.665524: train_loss -0.8563 
2025-01-18 17:27:22.666528: val_loss -0.4617 
2025-01-18 17:27:22.672286: Pseudo dice [np.float32(0.7075), np.float32(0.3008)] 
2025-01-18 17:27:22.676298: Epoch time: 31.85 s 
2025-01-18 17:27:23.241704:  
2025-01-18 17:27:23.241704: Epoch 140 
2025-01-18 17:27:23.247219: Current learning rate: 0.00478 
2025-01-18 17:27:55.088483: train_loss -0.863 
2025-01-18 17:27:55.090015: val_loss -0.4855 
2025-01-18 17:27:55.096075: Pseudo dice [np.float32(0.7058), np.float32(0.3495)] 
2025-01-18 17:27:55.100085: Epoch time: 31.85 s 
2025-01-18 17:27:55.672658:  
2025-01-18 17:27:55.673167: Epoch 141 
2025-01-18 17:27:55.677789: Current learning rate: 0.00474 
2025-01-18 17:28:27.522288: train_loss -0.8658 
2025-01-18 17:28:27.523290: val_loss -0.4651 
2025-01-18 17:28:27.529831: Pseudo dice [np.float32(0.7195), np.float32(0.28)] 
2025-01-18 17:28:27.533430: Epoch time: 31.85 s 
2025-01-18 17:28:28.113364:  
2025-01-18 17:28:28.113364: Epoch 142 
2025-01-18 17:28:28.118919: Current learning rate: 0.0047 
2025-01-18 17:28:59.970744: train_loss -0.8765 
2025-01-18 17:28:59.971263: val_loss -0.476 
2025-01-18 17:28:59.977897: Pseudo dice [np.float32(0.7143), np.float32(0.3375)] 
2025-01-18 17:28:59.982465: Epoch time: 31.86 s 
2025-01-18 17:29:00.556400:  
2025-01-18 17:29:00.556902: Epoch 143 
2025-01-18 17:29:00.562916: Current learning rate: 0.00466 
2025-01-18 17:29:32.411698: train_loss -0.8784 
2025-01-18 17:29:32.411698: val_loss -0.4589 
2025-01-18 17:29:32.418216: Pseudo dice [np.float32(0.6993), np.float32(0.3113)] 
2025-01-18 17:29:32.421257: Epoch time: 31.86 s 
2025-01-18 17:29:32.994634:  
2025-01-18 17:29:32.994634: Epoch 144 
2025-01-18 17:29:33.001241: Current learning rate: 0.00462 
2025-01-18 17:30:04.840280: train_loss -0.8818 
2025-01-18 17:30:04.840280: val_loss -0.4542 
2025-01-18 17:30:04.846794: Pseudo dice [np.float32(0.7206), np.float32(0.3148)] 
2025-01-18 17:30:04.850303: Epoch time: 31.85 s 
2025-01-18 17:30:05.575569:  
2025-01-18 17:30:05.575569: Epoch 145 
2025-01-18 17:30:05.581662: Current learning rate: 0.00458 
2025-01-18 17:30:37.400727: train_loss -0.8631 
2025-01-18 17:30:37.401229: val_loss -0.4922 
2025-01-18 17:30:37.407248: Pseudo dice [np.float32(0.7201), np.float32(0.3346)] 
2025-01-18 17:30:37.411339: Epoch time: 31.83 s 
2025-01-18 17:30:37.986181:  
2025-01-18 17:30:37.986181: Epoch 146 
2025-01-18 17:30:37.993276: Current learning rate: 0.00454 
2025-01-18 17:31:09.834233: train_loss -0.8701 
2025-01-18 17:31:09.834233: val_loss -0.4942 
2025-01-18 17:31:09.845859: Pseudo dice [np.float32(0.721), np.float32(0.3834)] 
2025-01-18 17:31:09.851874: Epoch time: 31.85 s 
2025-01-18 17:31:10.428473:  
2025-01-18 17:31:10.428473: Epoch 147 
2025-01-18 17:31:10.434573: Current learning rate: 0.0045 
2025-01-18 17:31:42.251158: train_loss -0.8726 
2025-01-18 17:31:42.251662: val_loss -0.4486 
2025-01-18 17:31:42.257685: Pseudo dice [np.float32(0.725), np.float32(0.3227)] 
2025-01-18 17:31:42.261216: Epoch time: 31.82 s 
2025-01-18 17:31:42.853456:  
2025-01-18 17:31:42.853456: Epoch 148 
2025-01-18 17:31:42.860509: Current learning rate: 0.00446 
2025-01-18 17:32:14.690914: train_loss -0.8709 
2025-01-18 17:32:14.691418: val_loss -0.4854 
2025-01-18 17:32:14.698441: Pseudo dice [np.float32(0.7183), np.float32(0.3523)] 
2025-01-18 17:32:14.702483: Epoch time: 31.84 s 
2025-01-18 17:32:15.280708:  
2025-01-18 17:32:15.281713: Epoch 149 
2025-01-18 17:32:15.286255: Current learning rate: 0.00442 
2025-01-18 17:32:47.112232: train_loss -0.877 
2025-01-18 17:32:47.112736: val_loss -0.4661 
2025-01-18 17:32:47.118776: Pseudo dice [np.float32(0.7098), np.float32(0.2964)] 
2025-01-18 17:32:47.122728: Epoch time: 31.83 s 
2025-01-18 17:32:47.986254:  
2025-01-18 17:32:47.986254: Epoch 150 
2025-01-18 17:32:47.992378: Current learning rate: 0.00438 
2025-01-18 17:33:19.841501: train_loss -0.8747 
2025-01-18 17:33:19.841501: val_loss -0.4646 
2025-01-18 17:33:19.848100: Pseudo dice [np.float32(0.732), np.float32(0.2926)] 
2025-01-18 17:33:19.852176: Epoch time: 31.86 s 
2025-01-18 17:33:20.423458:  
2025-01-18 17:33:20.423963: Epoch 151 
2025-01-18 17:33:20.428975: Current learning rate: 0.00434 
2025-01-18 17:33:52.244064: train_loss -0.8755 
2025-01-18 17:33:52.244568: val_loss -0.4568 
2025-01-18 17:33:52.251617: Pseudo dice [np.float32(0.7125), np.float32(0.3004)] 
2025-01-18 17:33:52.254627: Epoch time: 31.82 s 
2025-01-18 17:33:52.979408:  
2025-01-18 17:33:52.979911: Epoch 152 
2025-01-18 17:33:52.984962: Current learning rate: 0.0043 
2025-01-18 17:34:24.811641: train_loss -0.8762 
2025-01-18 17:34:24.811641: val_loss -0.485 
2025-01-18 17:34:24.819164: Pseudo dice [np.float32(0.7045), np.float32(0.3186)] 
2025-01-18 17:34:24.821867: Epoch time: 31.83 s 
2025-01-18 17:34:25.398947:  
2025-01-18 17:34:25.398947: Epoch 153 
2025-01-18 17:34:25.404963: Current learning rate: 0.00427 
2025-01-18 17:34:57.246291: train_loss -0.8764 
2025-01-18 17:34:57.246291: val_loss -0.4752 
2025-01-18 17:34:57.252806: Pseudo dice [np.float32(0.7072), np.float32(0.3004)] 
2025-01-18 17:34:57.256845: Epoch time: 31.85 s 
2025-01-18 17:34:57.845844:  
2025-01-18 17:34:57.845844: Epoch 154 
2025-01-18 17:34:57.851402: Current learning rate: 0.00423 
2025-01-18 17:35:29.686877: train_loss -0.8855 
2025-01-18 17:35:29.687381: val_loss -0.4548 
2025-01-18 17:35:29.694046: Pseudo dice [np.float32(0.7287), np.float32(0.2721)] 
2025-01-18 17:35:29.697580: Epoch time: 31.84 s 
2025-01-18 17:35:30.293076:  
2025-01-18 17:35:30.293076: Epoch 155 
2025-01-18 17:35:30.298607: Current learning rate: 0.00419 
2025-01-18 17:36:02.143052: train_loss -0.8849 
2025-01-18 17:36:02.144557: val_loss -0.4675 
2025-01-18 17:36:02.150573: Pseudo dice [np.float32(0.7317), np.float32(0.302)] 
2025-01-18 17:36:02.154607: Epoch time: 31.85 s 
2025-01-18 17:36:02.734915:  
2025-01-18 17:36:02.734915: Epoch 156 
2025-01-18 17:36:02.741997: Current learning rate: 0.00415 
2025-01-18 17:36:34.592230: train_loss -0.8879 
2025-01-18 17:36:34.593230: val_loss -0.4916 
2025-01-18 17:36:34.598749: Pseudo dice [np.float32(0.7141), np.float32(0.3985)] 
2025-01-18 17:36:34.603270: Epoch time: 31.86 s 
2025-01-18 17:36:35.192761:  
2025-01-18 17:36:35.193762: Epoch 157 
2025-01-18 17:36:35.199336: Current learning rate: 0.00411 
2025-01-18 17:37:07.030136: train_loss -0.8789 
2025-01-18 17:37:07.030136: val_loss -0.4545 
2025-01-18 17:37:07.037663: Pseudo dice [np.float32(0.6938), np.float32(0.3133)] 
2025-01-18 17:37:07.041670: Epoch time: 31.84 s 
2025-01-18 17:37:07.633611:  
2025-01-18 17:37:07.633611: Epoch 158 
2025-01-18 17:37:07.639136: Current learning rate: 0.00407 
2025-01-18 17:37:39.494122: train_loss -0.8855 
2025-01-18 17:37:39.494625: val_loss -0.4971 
2025-01-18 17:37:39.500640: Pseudo dice [np.float32(0.7123), np.float32(0.4089)] 
2025-01-18 17:37:39.504648: Epoch time: 31.86 s 
2025-01-18 17:37:40.098158:  
2025-01-18 17:37:40.098158: Epoch 159 
2025-01-18 17:37:40.104192: Current learning rate: 0.00403 
2025-01-18 17:38:11.947487: train_loss -0.8875 
2025-01-18 17:38:11.948990: val_loss -0.4788 
2025-01-18 17:38:11.955542: Pseudo dice [np.float32(0.7121), np.float32(0.3226)] 
2025-01-18 17:38:11.959562: Epoch time: 31.85 s 
2025-01-18 17:38:12.692227:  
2025-01-18 17:38:12.693226: Epoch 160 
2025-01-18 17:38:12.698743: Current learning rate: 0.00399 
2025-01-18 17:38:44.539466: train_loss -0.8862 
2025-01-18 17:38:44.540468: val_loss -0.4772 
2025-01-18 17:38:44.545998: Pseudo dice [np.float32(0.7131), np.float32(0.3705)] 
2025-01-18 17:38:44.550521: Epoch time: 31.85 s 
2025-01-18 17:38:45.143017:  
2025-01-18 17:38:45.144020: Epoch 161 
2025-01-18 17:38:45.149554: Current learning rate: 0.00395 
2025-01-18 17:39:16.985313: train_loss -0.8843 
2025-01-18 17:39:16.985815: val_loss -0.5022 
2025-01-18 17:39:16.993345: Pseudo dice [np.float32(0.7165), np.float32(0.3691)] 
2025-01-18 17:39:16.996854: Epoch time: 31.84 s 
2025-01-18 17:39:17.584467:  
2025-01-18 17:39:17.584467: Epoch 162 
2025-01-18 17:39:17.590011: Current learning rate: 0.00391 
2025-01-18 17:39:49.428064: train_loss -0.8952 
2025-01-18 17:39:49.428064: val_loss -0.4196 
2025-01-18 17:39:49.435112: Pseudo dice [np.float32(0.6847), np.float32(0.2547)] 
2025-01-18 17:39:49.438136: Epoch time: 31.85 s 
2025-01-18 17:39:50.030689:  
2025-01-18 17:39:50.030689: Epoch 163 
2025-01-18 17:39:50.035808: Current learning rate: 0.00387 
2025-01-18 17:40:21.896043: train_loss -0.8876 
2025-01-18 17:40:21.896043: val_loss -0.4815 
2025-01-18 17:40:21.901655: Pseudo dice [np.float32(0.7203), np.float32(0.321)] 
2025-01-18 17:40:21.906186: Epoch time: 31.87 s 
2025-01-18 17:40:22.488689:  
2025-01-18 17:40:22.488689: Epoch 164 
2025-01-18 17:40:22.493702: Current learning rate: 0.00383 
2025-01-18 17:40:54.333464: train_loss -0.887 
2025-01-18 17:40:54.333987: val_loss -0.4598 
2025-01-18 17:40:54.340004: Pseudo dice [np.float32(0.7052), np.float32(0.3326)] 
2025-01-18 17:40:54.347245: Epoch time: 31.85 s 
2025-01-18 17:40:54.926608:  
2025-01-18 17:40:54.926608: Epoch 165 
2025-01-18 17:40:54.933213: Current learning rate: 0.00379 
2025-01-18 17:41:26.761821: train_loss -0.8966 
2025-01-18 17:41:26.761821: val_loss -0.467 
2025-01-18 17:41:26.769343: Pseudo dice [np.float32(0.6912), np.float32(0.3237)] 
2025-01-18 17:41:26.773353: Epoch time: 31.84 s 
2025-01-18 17:41:27.351850:  
2025-01-18 17:41:27.352358: Epoch 166 
2025-01-18 17:41:27.358488: Current learning rate: 0.00375 
2025-01-18 17:41:59.203307: train_loss -0.8883 
2025-01-18 17:41:59.203810: val_loss -0.4185 
2025-01-18 17:41:59.209826: Pseudo dice [np.float32(0.6836), np.float32(0.2131)] 
2025-01-18 17:41:59.213834: Epoch time: 31.85 s 
2025-01-18 17:41:59.785140:  
2025-01-18 17:41:59.785140: Epoch 167 
2025-01-18 17:41:59.790154: Current learning rate: 0.00371 
2025-01-18 17:42:31.633219: train_loss -0.9013 
2025-01-18 17:42:31.633734: val_loss -0.483 
2025-01-18 17:42:31.640763: Pseudo dice [np.float32(0.7017), np.float32(0.3236)] 
2025-01-18 17:42:31.645888: Epoch time: 31.85 s 
2025-01-18 17:42:32.371240:  
2025-01-18 17:42:32.371240: Epoch 168 
2025-01-18 17:42:32.378319: Current learning rate: 0.00367 
2025-01-18 17:43:04.207631: train_loss -0.8992 
2025-01-18 17:43:04.208133: val_loss -0.4437 
2025-01-18 17:43:04.214244: Pseudo dice [np.float32(0.7093), np.float32(0.2764)] 
2025-01-18 17:43:04.218273: Epoch time: 31.84 s 
2025-01-18 17:43:04.791979:  
2025-01-18 17:43:04.791979: Epoch 169 
2025-01-18 17:43:04.797546: Current learning rate: 0.00363 
2025-01-18 17:43:36.644913: train_loss -0.8979 
2025-01-18 17:43:36.645916: val_loss -0.4259 
2025-01-18 17:43:36.652433: Pseudo dice [np.float32(0.6873), np.float32(0.2869)] 
2025-01-18 17:43:36.655988: Epoch time: 31.85 s 
2025-01-18 17:43:37.224933:  
2025-01-18 17:43:37.224933: Epoch 170 
2025-01-18 17:43:37.230529: Current learning rate: 0.00359 
2025-01-18 17:44:09.054437: train_loss -0.8976 
2025-01-18 17:44:09.054942: val_loss -0.4343 
2025-01-18 17:44:09.062474: Pseudo dice [np.float32(0.6678), np.float32(0.2656)] 
2025-01-18 17:44:09.065995: Epoch time: 31.83 s 
2025-01-18 17:44:09.649489:  
2025-01-18 17:44:09.650493: Epoch 171 
2025-01-18 17:44:09.656026: Current learning rate: 0.00355 
2025-01-18 17:44:41.486233: train_loss -0.8957 
2025-01-18 17:44:41.487239: val_loss -0.4888 
2025-01-18 17:44:41.493325: Pseudo dice [np.float32(0.7129), np.float32(0.3252)] 
2025-01-18 17:44:41.496385: Epoch time: 31.84 s 
2025-01-18 17:44:42.070105:  
2025-01-18 17:44:42.070105: Epoch 172 
2025-01-18 17:44:42.080290: Current learning rate: 0.00351 
2025-01-18 17:45:13.929515: train_loss -0.9016 
2025-01-18 17:45:13.929515: val_loss -0.437 
2025-01-18 17:45:13.936040: Pseudo dice [np.float32(0.6963), np.float32(0.2678)] 
2025-01-18 17:45:13.941082: Epoch time: 31.86 s 
2025-01-18 17:45:14.510852:  
2025-01-18 17:45:14.510852: Epoch 173 
2025-01-18 17:45:14.517444: Current learning rate: 0.00346 
2025-01-18 17:45:46.379078: train_loss -0.8959 
2025-01-18 17:45:46.379583: val_loss -0.432 
2025-01-18 17:45:46.385607: Pseudo dice [np.float32(0.7011), np.float32(0.2429)] 
2025-01-18 17:45:46.389631: Epoch time: 31.87 s 
2025-01-18 17:45:46.958801:  
2025-01-18 17:45:46.959804: Epoch 174 
2025-01-18 17:45:46.964417: Current learning rate: 0.00342 
2025-01-18 17:46:18.832521: train_loss -0.8977 
2025-01-18 17:46:18.832521: val_loss -0.4681 
2025-01-18 17:46:18.839108: Pseudo dice [np.float32(0.7177), np.float32(0.3)] 
2025-01-18 17:46:18.843180: Epoch time: 31.87 s 
2025-01-18 17:46:19.420774:  
2025-01-18 17:46:19.420774: Epoch 175 
2025-01-18 17:46:19.426875: Current learning rate: 0.00338 
2025-01-18 17:46:51.291183: train_loss -0.9055 
2025-01-18 17:46:51.292182: val_loss -0.4424 
2025-01-18 17:46:51.297701: Pseudo dice [np.float32(0.7189), np.float32(0.2713)] 
2025-01-18 17:46:51.301209: Epoch time: 31.87 s 
2025-01-18 17:46:52.035607:  
2025-01-18 17:46:52.035607: Epoch 176 
2025-01-18 17:46:52.041160: Current learning rate: 0.00334 
2025-01-18 17:47:23.889352: train_loss -0.9002 
2025-01-18 17:47:23.889352: val_loss -0.4443 
2025-01-18 17:47:23.895432: Pseudo dice [np.float32(0.7141), np.float32(0.2384)] 
2025-01-18 17:47:23.897914: Epoch time: 31.85 s 
2025-01-18 17:47:24.471208:  
2025-01-18 17:47:24.471713: Epoch 177 
2025-01-18 17:47:24.477731: Current learning rate: 0.0033 
2025-01-18 17:47:56.328717: train_loss -0.9028 
2025-01-18 17:47:56.329219: val_loss -0.4932 
2025-01-18 17:47:56.334750: Pseudo dice [np.float32(0.7026), np.float32(0.3915)] 
2025-01-18 17:47:56.339290: Epoch time: 31.86 s 
2025-01-18 17:47:56.922419:  
2025-01-18 17:47:56.922921: Epoch 178 
2025-01-18 17:47:56.928467: Current learning rate: 0.00326 
2025-01-18 17:48:28.784562: train_loss -0.9023 
2025-01-18 17:48:28.785561: val_loss -0.4533 
2025-01-18 17:48:28.791750: Pseudo dice [np.float32(0.7209), np.float32(0.2886)] 
2025-01-18 17:48:28.795781: Epoch time: 31.86 s 
2025-01-18 17:48:29.364737:  
2025-01-18 17:48:29.365743: Epoch 179 
2025-01-18 17:48:29.370284: Current learning rate: 0.00322 
2025-01-18 17:49:01.224437: train_loss -0.9044 
2025-01-18 17:49:01.225438: val_loss -0.4599 
2025-01-18 17:49:01.230978: Pseudo dice [np.float32(0.7336), np.float32(0.3427)] 
2025-01-18 17:49:01.235991: Epoch time: 31.86 s 
2025-01-18 17:49:01.818486:  
2025-01-18 17:49:01.818486: Epoch 180 
2025-01-18 17:49:01.824524: Current learning rate: 0.00318 
2025-01-18 17:49:33.662217: train_loss -0.9052 
2025-01-18 17:49:33.662217: val_loss -0.4697 
2025-01-18 17:49:33.668763: Pseudo dice [np.float32(0.7212), np.float32(0.3118)] 
2025-01-18 17:49:33.673778: Epoch time: 31.84 s 
2025-01-18 17:49:34.248207:  
2025-01-18 17:49:34.248207: Epoch 181 
2025-01-18 17:49:34.253764: Current learning rate: 0.00314 
2025-01-18 17:50:06.110712: train_loss -0.9059 
2025-01-18 17:50:06.111221: val_loss -0.4823 
2025-01-18 17:50:06.116810: Pseudo dice [np.float32(0.721), np.float32(0.3151)] 
2025-01-18 17:50:06.121438: Epoch time: 31.86 s 
2025-01-18 17:50:06.692858:  
2025-01-18 17:50:06.694373: Epoch 182 
2025-01-18 17:50:06.699959: Current learning rate: 0.0031 
2025-01-18 17:50:38.557536: train_loss -0.9051 
2025-01-18 17:50:38.558054: val_loss -0.4224 
2025-01-18 17:50:38.563116: Pseudo dice [np.float32(0.6872), np.float32(0.2498)] 
2025-01-18 17:50:38.567720: Epoch time: 31.86 s 
2025-01-18 17:50:39.297155:  
2025-01-18 17:50:39.297658: Epoch 183 
2025-01-18 17:50:39.303217: Current learning rate: 0.00306 
2025-01-18 17:51:11.167696: train_loss -0.905 
2025-01-18 17:51:11.168695: val_loss -0.4618 
2025-01-18 17:51:11.176736: Pseudo dice [np.float32(0.7115), np.float32(0.2695)] 
2025-01-18 17:51:11.180859: Epoch time: 31.87 s 
2025-01-18 17:51:11.767734:  
2025-01-18 17:51:11.767734: Epoch 184 
2025-01-18 17:51:11.774302: Current learning rate: 0.00302 
2025-01-18 17:51:43.617571: train_loss -0.9115 
2025-01-18 17:51:43.617571: val_loss -0.4352 
2025-01-18 17:51:43.624092: Pseudo dice [np.float32(0.7093), np.float32(0.2663)] 
2025-01-18 17:51:43.628216: Epoch time: 31.85 s 
2025-01-18 17:51:44.207961:  
2025-01-18 17:51:44.207961: Epoch 185 
2025-01-18 17:51:44.215013: Current learning rate: 0.00297 
2025-01-18 17:52:16.059221: train_loss -0.9044 
2025-01-18 17:52:16.060774: val_loss -0.4726 
2025-01-18 17:52:16.066798: Pseudo dice [np.float32(0.7311), np.float32(0.3126)] 
2025-01-18 17:52:16.070158: Epoch time: 31.85 s 
2025-01-18 17:52:16.649762:  
2025-01-18 17:52:16.650277: Epoch 186 
2025-01-18 17:52:16.655860: Current learning rate: 0.00293 
2025-01-18 17:52:48.518595: train_loss -0.9103 
2025-01-18 17:52:48.520116: val_loss -0.4477 
2025-01-18 17:52:48.526281: Pseudo dice [np.float32(0.6898), np.float32(0.2629)] 
2025-01-18 17:52:48.530000: Epoch time: 31.87 s 
2025-01-18 17:52:49.103015:  
2025-01-18 17:52:49.104019: Epoch 187 
2025-01-18 17:52:49.108589: Current learning rate: 0.00289 
2025-01-18 17:53:20.972875: train_loss -0.9036 
2025-01-18 17:53:20.972875: val_loss -0.422 
2025-01-18 17:53:20.979934: Pseudo dice [np.float32(0.7027), np.float32(0.2336)] 
2025-01-18 17:53:20.984041: Epoch time: 31.87 s 
2025-01-18 17:53:21.560944:  
2025-01-18 17:53:21.561947: Epoch 188 
2025-01-18 17:53:21.566517: Current learning rate: 0.00285 
2025-01-18 17:53:53.416824: train_loss -0.9055 
2025-01-18 17:53:53.417845: val_loss -0.4302 
2025-01-18 17:53:53.424010: Pseudo dice [np.float32(0.7251), np.float32(0.2153)] 
2025-01-18 17:53:53.427539: Epoch time: 31.86 s 
2025-01-18 17:53:54.008909:  
2025-01-18 17:53:54.009913: Epoch 189 
2025-01-18 17:53:54.014472: Current learning rate: 0.00281 
2025-01-18 17:54:25.863105: train_loss -0.9133 
2025-01-18 17:54:25.863105: val_loss -0.454 
2025-01-18 17:54:25.870675: Pseudo dice [np.float32(0.7233), np.float32(0.3802)] 
2025-01-18 17:54:25.873382: Epoch time: 31.85 s 
2025-01-18 17:54:26.448101:  
2025-01-18 17:54:26.449101: Epoch 190 
2025-01-18 17:54:26.454735: Current learning rate: 0.00277 
2025-01-18 17:54:58.307219: train_loss -0.9122 
2025-01-18 17:54:58.308217: val_loss -0.4897 
2025-01-18 17:54:58.316244: Pseudo dice [np.float32(0.7208), np.float32(0.3338)] 
2025-01-18 17:54:58.319753: Epoch time: 31.86 s 
2025-01-18 17:54:59.064494:  
2025-01-18 17:54:59.065498: Epoch 191 
2025-01-18 17:54:59.072375: Current learning rate: 0.00273 
2025-01-18 17:55:30.909225: train_loss -0.9102 
2025-01-18 17:55:30.909225: val_loss -0.4449 
2025-01-18 17:55:30.915794: Pseudo dice [np.float32(0.7023), np.float32(0.3561)] 
2025-01-18 17:55:30.919306: Epoch time: 31.84 s 
2025-01-18 17:55:31.504268:  
2025-01-18 17:55:31.504268: Epoch 192 
2025-01-18 17:55:31.510335: Current learning rate: 0.00268 
2025-01-18 17:56:03.344283: train_loss -0.9084 
2025-01-18 17:56:03.344796: val_loss -0.4801 
2025-01-18 17:56:03.350814: Pseudo dice [np.float32(0.7229), np.float32(0.3288)] 
2025-01-18 17:56:03.354320: Epoch time: 31.84 s 
2025-01-18 17:56:03.935509:  
2025-01-18 17:56:03.936012: Epoch 193 
2025-01-18 17:56:03.941023: Current learning rate: 0.00264 
2025-01-18 17:56:35.781319: train_loss -0.907 
2025-01-18 17:56:35.782864: val_loss -0.4834 
2025-01-18 17:56:35.788481: Pseudo dice [np.float32(0.7226), np.float32(0.3686)] 
2025-01-18 17:56:35.791989: Epoch time: 31.85 s 
2025-01-18 17:56:36.387473:  
2025-01-18 17:56:36.387473: Epoch 194 
2025-01-18 17:56:36.393490: Current learning rate: 0.0026 
2025-01-18 17:57:08.235436: train_loss -0.9158 
2025-01-18 17:57:08.235436: val_loss -0.4634 
2025-01-18 17:57:08.241954: Pseudo dice [np.float32(0.6923), np.float32(0.3291)] 
2025-01-18 17:57:08.246464: Epoch time: 31.85 s 
2025-01-18 17:57:08.835006:  
2025-01-18 17:57:08.836006: Epoch 195 
2025-01-18 17:57:08.841082: Current learning rate: 0.00256 
2025-01-18 17:57:40.694999: train_loss -0.9082 
2025-01-18 17:57:40.694999: val_loss -0.4532 
2025-01-18 17:57:40.701800: Pseudo dice [np.float32(0.6976), np.float32(0.2666)] 
2025-01-18 17:57:40.705809: Epoch time: 31.86 s 
2025-01-18 17:57:41.286417:  
2025-01-18 17:57:41.287417: Epoch 196 
2025-01-18 17:57:41.293040: Current learning rate: 0.00252 
2025-01-18 17:58:13.149955: train_loss -0.9087 
2025-01-18 17:58:13.149955: val_loss -0.4443 
2025-01-18 17:58:13.156474: Pseudo dice [np.float32(0.699), np.float32(0.2884)] 
2025-01-18 17:58:13.160488: Epoch time: 31.86 s 
2025-01-18 17:58:13.746172:  
2025-01-18 17:58:13.746172: Epoch 197 
2025-01-18 17:58:13.752325: Current learning rate: 0.00248 
2025-01-18 17:58:45.590870: train_loss -0.9175 
2025-01-18 17:58:45.591870: val_loss -0.4645 
2025-01-18 17:58:45.597383: Pseudo dice [np.float32(0.7124), np.float32(0.3027)] 
2025-01-18 17:58:45.600893: Epoch time: 31.85 s 
2025-01-18 17:58:46.203268:  
2025-01-18 17:58:46.203268: Epoch 198 
2025-01-18 17:58:46.209291: Current learning rate: 0.00243 
2025-01-18 17:59:18.129440: train_loss -0.9162 
2025-01-18 17:59:18.129440: val_loss -0.4717 
2025-01-18 17:59:18.135963: Pseudo dice [np.float32(0.7184), np.float32(0.2786)] 
2025-01-18 17:59:18.140473: Epoch time: 31.93 s 
2025-01-18 17:59:18.736564:  
2025-01-18 17:59:18.736564: Epoch 199 
2025-01-18 17:59:18.742121: Current learning rate: 0.00239 
2025-01-18 17:59:50.581530: train_loss -0.9177 
2025-01-18 17:59:50.582039: val_loss -0.4555 
2025-01-18 17:59:50.588751: Pseudo dice [np.float32(0.6927), np.float32(0.2669)] 
2025-01-18 17:59:50.592280: Epoch time: 31.85 s 
2025-01-18 17:59:51.439888:  
2025-01-18 17:59:51.439888: Epoch 200 
2025-01-18 17:59:51.445426: Current learning rate: 0.00235 
2025-01-18 18:00:23.267545: train_loss -0.9129 
2025-01-18 18:00:23.268550: val_loss -0.4189 
2025-01-18 18:00:23.274606: Pseudo dice [np.float32(0.682), np.float32(0.2401)] 
2025-01-18 18:00:23.277628: Epoch time: 31.83 s 
2025-01-18 18:00:23.867202:  
2025-01-18 18:00:23.867202: Epoch 201 
2025-01-18 18:00:23.872746: Current learning rate: 0.00231 
2025-01-18 18:00:55.713581: train_loss -0.9124 
2025-01-18 18:00:55.713581: val_loss -0.4665 
2025-01-18 18:00:55.719695: Pseudo dice [np.float32(0.7079), np.float32(0.3162)] 
2025-01-18 18:00:55.724244: Epoch time: 31.85 s 
2025-01-18 18:00:56.323029:  
2025-01-18 18:00:56.323532: Epoch 202 
2025-01-18 18:00:56.329544: Current learning rate: 0.00226 
2025-01-18 18:01:28.147102: train_loss -0.9177 
2025-01-18 18:01:28.147607: val_loss -0.4394 
2025-01-18 18:01:28.153228: Pseudo dice [np.float32(0.7127), np.float32(0.2773)] 
2025-01-18 18:01:28.156755: Epoch time: 31.83 s 
2025-01-18 18:01:28.739298:  
2025-01-18 18:01:28.740299: Epoch 203 
2025-01-18 18:01:28.745361: Current learning rate: 0.00222 
2025-01-18 18:02:00.562398: train_loss -0.919 
2025-01-18 18:02:00.563402: val_loss -0.4626 
2025-01-18 18:02:00.569919: Pseudo dice [np.float32(0.7214), np.float32(0.3045)] 
2025-01-18 18:02:00.573457: Epoch time: 31.82 s 
2025-01-18 18:02:01.165449:  
2025-01-18 18:02:01.166453: Epoch 204 
2025-01-18 18:02:01.171986: Current learning rate: 0.00218 
2025-01-18 18:02:32.994985: train_loss -0.9052 
2025-01-18 18:02:32.995491: val_loss -0.416 
2025-01-18 18:02:33.001077: Pseudo dice [np.float32(0.7024), np.float32(0.2399)] 
2025-01-18 18:02:33.005128: Epoch time: 31.83 s 
2025-01-18 18:02:33.596380:  
2025-01-18 18:02:33.596380: Epoch 205 
2025-01-18 18:02:33.602464: Current learning rate: 0.00214 
2025-01-18 18:03:05.418190: train_loss -0.9078 
2025-01-18 18:03:05.418692: val_loss -0.4594 
2025-01-18 18:03:05.424790: Pseudo dice [np.float32(0.7223), np.float32(0.3075)] 
2025-01-18 18:03:05.427804: Epoch time: 31.82 s 
2025-01-18 18:03:06.133161:  
2025-01-18 18:03:06.133663: Epoch 206 
2025-01-18 18:03:06.139682: Current learning rate: 0.00209 
2025-01-18 18:03:37.941346: train_loss -0.915 
2025-01-18 18:03:37.941850: val_loss -0.4449 
2025-01-18 18:03:37.948015: Pseudo dice [np.float32(0.709), np.float32(0.2332)] 
2025-01-18 18:03:37.951079: Epoch time: 31.81 s 
2025-01-18 18:03:38.508092:  
2025-01-18 18:03:38.509096: Epoch 207 
2025-01-18 18:03:38.514678: Current learning rate: 0.00205 
2025-01-18 18:04:10.356412: train_loss -0.916 
2025-01-18 18:04:10.357915: val_loss -0.4524 
2025-01-18 18:04:10.362969: Pseudo dice [np.float32(0.7049), np.float32(0.2755)] 
2025-01-18 18:04:10.367478: Epoch time: 31.85 s 
2025-01-18 18:04:10.921040:  
2025-01-18 18:04:10.921040: Epoch 208 
2025-01-18 18:04:10.926633: Current learning rate: 0.00201 
2025-01-18 18:04:42.752531: train_loss -0.9219 
2025-01-18 18:04:42.753536: val_loss -0.4424 
2025-01-18 18:04:42.760613: Pseudo dice [np.float32(0.708), np.float32(0.2797)] 
2025-01-18 18:04:42.765153: Epoch time: 31.83 s 
2025-01-18 18:04:43.322549:  
2025-01-18 18:04:43.322549: Epoch 209 
2025-01-18 18:04:43.327627: Current learning rate: 0.00196 
2025-01-18 18:05:15.169030: train_loss -0.9211 
2025-01-18 18:05:15.169535: val_loss -0.4626 
2025-01-18 18:05:15.175558: Pseudo dice [np.float32(0.7242), np.float32(0.2907)] 
2025-01-18 18:05:15.179602: Epoch time: 31.85 s 
2025-01-18 18:05:15.742565:  
2025-01-18 18:05:15.743068: Epoch 210 
2025-01-18 18:05:15.750083: Current learning rate: 0.00192 
2025-01-18 18:05:47.585819: train_loss -0.9223 
2025-01-18 18:05:47.586321: val_loss -0.4472 
2025-01-18 18:05:47.593838: Pseudo dice [np.float32(0.7111), np.float32(0.2554)] 
2025-01-18 18:05:47.596880: Epoch time: 31.84 s 
2025-01-18 18:05:48.152107:  
2025-01-18 18:05:48.152107: Epoch 211 
2025-01-18 18:05:48.157637: Current learning rate: 0.00188 
2025-01-18 18:06:19.999612: train_loss -0.9195 
2025-01-18 18:06:20.000115: val_loss -0.4371 
2025-01-18 18:06:20.007694: Pseudo dice [np.float32(0.6854), np.float32(0.2526)] 
2025-01-18 18:06:20.011235: Epoch time: 31.85 s 
2025-01-18 18:06:20.570457:  
2025-01-18 18:06:20.571462: Epoch 212 
2025-01-18 18:06:20.577047: Current learning rate: 0.00184 
2025-01-18 18:06:52.429314: train_loss -0.9221 
2025-01-18 18:06:52.429822: val_loss -0.4084 
2025-01-18 18:06:52.434411: Pseudo dice [np.float32(0.7029), np.float32(0.1943)] 
2025-01-18 18:06:52.439469: Epoch time: 31.86 s 
2025-01-18 18:06:52.994039:  
2025-01-18 18:06:52.995043: Epoch 213 
2025-01-18 18:06:52.999598: Current learning rate: 0.00179 
2025-01-18 18:07:24.860383: train_loss -0.9247 
2025-01-18 18:07:24.861386: val_loss -0.4482 
2025-01-18 18:07:24.867404: Pseudo dice [np.float32(0.7032), np.float32(0.3263)] 
2025-01-18 18:07:24.870413: Epoch time: 31.87 s 
2025-01-18 18:07:25.576697:  
2025-01-18 18:07:25.576697: Epoch 214 
2025-01-18 18:07:25.582733: Current learning rate: 0.00175 
2025-01-18 18:07:57.419451: train_loss -0.9193 
2025-01-18 18:07:57.420954: val_loss -0.4462 
2025-01-18 18:07:57.428477: Pseudo dice [np.float32(0.6934), np.float32(0.3016)] 
2025-01-18 18:07:57.431989: Epoch time: 31.84 s 
2025-01-18 18:07:57.978672:  
2025-01-18 18:07:57.979675: Epoch 215 
2025-01-18 18:07:57.984241: Current learning rate: 0.0017 
2025-01-18 18:08:29.831265: train_loss -0.9233 
2025-01-18 18:08:29.832687: val_loss -0.4596 
2025-01-18 18:08:29.838707: Pseudo dice [np.float32(0.71), np.float32(0.283)] 
2025-01-18 18:08:29.841737: Epoch time: 31.85 s 
2025-01-18 18:08:30.399655:  
2025-01-18 18:08:30.399655: Epoch 216 
2025-01-18 18:08:30.407173: Current learning rate: 0.00166 
2025-01-18 18:09:02.243516: train_loss -0.9207 
2025-01-18 18:09:02.244028: val_loss -0.4626 
2025-01-18 18:09:02.251109: Pseudo dice [np.float32(0.6999), np.float32(0.2903)] 
2025-01-18 18:09:02.254158: Epoch time: 31.85 s 
2025-01-18 18:09:02.808656:  
2025-01-18 18:09:02.809660: Epoch 217 
2025-01-18 18:09:02.814697: Current learning rate: 0.00162 
2025-01-18 18:09:34.658604: train_loss -0.9221 
2025-01-18 18:09:34.659114: val_loss -0.4461 
2025-01-18 18:09:34.665184: Pseudo dice [np.float32(0.7082), np.float32(0.2576)] 
2025-01-18 18:09:34.668764: Epoch time: 31.85 s 
2025-01-18 18:09:35.222181:  
2025-01-18 18:09:35.222181: Epoch 218 
2025-01-18 18:09:35.227223: Current learning rate: 0.00157 
2025-01-18 18:10:07.053888: train_loss -0.9227 
2025-01-18 18:10:07.054391: val_loss -0.4669 
2025-01-18 18:10:07.060444: Pseudo dice [np.float32(0.6921), np.float32(0.3492)] 
2025-01-18 18:10:07.064452: Epoch time: 31.83 s 
2025-01-18 18:10:07.615322:  
2025-01-18 18:10:07.615322: Epoch 219 
2025-01-18 18:10:07.621866: Current learning rate: 0.00153 
2025-01-18 18:10:39.476892: train_loss -0.9258 
2025-01-18 18:10:39.478403: val_loss -0.4547 
2025-01-18 18:10:39.484480: Pseudo dice [np.float32(0.708), np.float32(0.3278)] 
2025-01-18 18:10:39.487506: Epoch time: 31.86 s 
2025-01-18 18:10:40.045858:  
2025-01-18 18:10:40.046361: Epoch 220 
2025-01-18 18:10:40.051371: Current learning rate: 0.00148 
2025-01-18 18:11:11.904515: train_loss -0.9242 
2025-01-18 18:11:11.905529: val_loss -0.4279 
2025-01-18 18:11:11.911294: Pseudo dice [np.float32(0.6988), np.float32(0.2581)] 
2025-01-18 18:11:11.915333: Epoch time: 31.86 s 
2025-01-18 18:11:12.474717:  
2025-01-18 18:11:12.474717: Epoch 221 
2025-01-18 18:11:12.481891: Current learning rate: 0.00144 
2025-01-18 18:11:44.322765: train_loss -0.923 
2025-01-18 18:11:44.322765: val_loss -0.4433 
2025-01-18 18:11:44.328447: Pseudo dice [np.float32(0.7148), np.float32(0.2509)] 
2025-01-18 18:11:44.331498: Epoch time: 31.85 s 
2025-01-18 18:11:44.891629:  
2025-01-18 18:11:44.891629: Epoch 222 
2025-01-18 18:11:44.897168: Current learning rate: 0.00139 
2025-01-18 18:12:16.757753: train_loss -0.9205 
2025-01-18 18:12:16.758756: val_loss -0.4974 
2025-01-18 18:12:16.764336: Pseudo dice [np.float32(0.713), np.float32(0.3592)] 
2025-01-18 18:12:16.767902: Epoch time: 31.87 s 
2025-01-18 18:12:17.475646:  
2025-01-18 18:12:17.476651: Epoch 223 
2025-01-18 18:12:17.481185: Current learning rate: 0.00135 
2025-01-18 18:12:49.320860: train_loss -0.9242 
2025-01-18 18:12:49.321362: val_loss -0.4146 
2025-01-18 18:12:49.327894: Pseudo dice [np.float32(0.6961), np.float32(0.2774)] 
2025-01-18 18:12:49.338995: Epoch time: 31.85 s 
2025-01-18 18:12:49.890913:  
2025-01-18 18:12:49.890913: Epoch 224 
2025-01-18 18:12:49.896462: Current learning rate: 0.0013 
2025-01-18 18:13:21.716124: train_loss -0.9279 
2025-01-18 18:13:21.716641: val_loss -0.4487 
2025-01-18 18:13:21.722660: Pseudo dice [np.float32(0.7006), np.float32(0.3089)] 
2025-01-18 18:13:21.726683: Epoch time: 31.83 s 
2025-01-18 18:13:22.273434:  
2025-01-18 18:13:22.273434: Epoch 225 
2025-01-18 18:13:22.279473: Current learning rate: 0.00126 
2025-01-18 18:13:54.123114: train_loss -0.9272 
2025-01-18 18:13:54.125138: val_loss -0.4439 
2025-01-18 18:13:54.130152: Pseudo dice [np.float32(0.7156), np.float32(0.3234)] 
2025-01-18 18:13:54.134665: Epoch time: 31.85 s 
2025-01-18 18:13:54.684862:  
2025-01-18 18:13:54.684862: Epoch 226 
2025-01-18 18:13:54.690428: Current learning rate: 0.00121 
2025-01-18 18:14:26.543158: train_loss -0.9214 
2025-01-18 18:14:26.543158: val_loss -0.4471 
2025-01-18 18:14:26.549687: Pseudo dice [np.float32(0.6965), np.float32(0.2913)] 
2025-01-18 18:14:26.553703: Epoch time: 31.86 s 
2025-01-18 18:14:27.103047:  
2025-01-18 18:14:27.103549: Epoch 227 
2025-01-18 18:14:27.109710: Current learning rate: 0.00117 
2025-01-18 18:14:58.952043: train_loss -0.9295 
2025-01-18 18:14:58.952043: val_loss -0.4701 
2025-01-18 18:14:58.961072: Pseudo dice [np.float32(0.701), np.float32(0.3701)] 
2025-01-18 18:14:58.966084: Epoch time: 31.85 s 
2025-01-18 18:14:59.520722:  
2025-01-18 18:14:59.522224: Epoch 228 
2025-01-18 18:14:59.527235: Current learning rate: 0.00112 
2025-01-18 18:15:31.380870: train_loss -0.9267 
2025-01-18 18:15:31.381871: val_loss -0.4422 
2025-01-18 18:15:31.388402: Pseudo dice [np.float32(0.6945), np.float32(0.2797)] 
2025-01-18 18:15:31.392412: Epoch time: 31.86 s 
2025-01-18 18:15:31.955792:  
2025-01-18 18:15:31.956797: Epoch 229 
2025-01-18 18:15:31.961923: Current learning rate: 0.00108 
2025-01-18 18:16:03.823376: train_loss -0.9257 
2025-01-18 18:16:03.824376: val_loss -0.4435 
2025-01-18 18:16:03.829895: Pseudo dice [np.float32(0.7132), np.float32(0.2781)] 
2025-01-18 18:16:03.833405: Epoch time: 31.87 s 
2025-01-18 18:16:04.385736:  
2025-01-18 18:16:04.385736: Epoch 230 
2025-01-18 18:16:04.392252: Current learning rate: 0.00103 
2025-01-18 18:16:36.223148: train_loss -0.9249 
2025-01-18 18:16:36.224664: val_loss -0.4727 
2025-01-18 18:16:36.231198: Pseudo dice [np.float32(0.7131), np.float32(0.388)] 
2025-01-18 18:16:36.234727: Epoch time: 31.84 s 
2025-01-18 18:16:36.975986:  
2025-01-18 18:16:36.975986: Epoch 231 
2025-01-18 18:16:36.982018: Current learning rate: 0.00098 
2025-01-18 18:17:08.838995: train_loss -0.9242 
2025-01-18 18:17:08.840002: val_loss -0.4521 
2025-01-18 18:17:08.844011: Pseudo dice [np.float32(0.7095), np.float32(0.3231)] 
2025-01-18 18:17:08.847519: Epoch time: 31.86 s 
2025-01-18 18:17:09.392295:  
2025-01-18 18:17:09.392295: Epoch 232 
2025-01-18 18:17:09.397842: Current learning rate: 0.00094 
2025-01-18 18:17:41.266457: train_loss -0.9278 
2025-01-18 18:17:41.266457: val_loss -0.4503 
2025-01-18 18:17:41.272978: Pseudo dice [np.float32(0.6911), np.float32(0.2709)] 
2025-01-18 18:17:41.278086: Epoch time: 31.88 s 
2025-01-18 18:17:41.828694:  
2025-01-18 18:17:41.828694: Epoch 233 
2025-01-18 18:17:41.835240: Current learning rate: 0.00089 
2025-01-18 18:18:13.695309: train_loss -0.9227 
2025-01-18 18:18:13.695309: val_loss -0.475 
2025-01-18 18:18:13.701863: Pseudo dice [np.float32(0.7114), np.float32(0.3132)] 
2025-01-18 18:18:13.705911: Epoch time: 31.87 s 
2025-01-18 18:18:14.253052:  
2025-01-18 18:18:14.254058: Epoch 234 
2025-01-18 18:18:14.258613: Current learning rate: 0.00084 
2025-01-18 18:18:46.124826: train_loss -0.9283 
2025-01-18 18:18:46.124826: val_loss -0.4354 
2025-01-18 18:18:46.131404: Pseudo dice [np.float32(0.7154), np.float32(0.2503)] 
2025-01-18 18:18:46.134954: Epoch time: 31.87 s 
2025-01-18 18:18:46.708575:  
2025-01-18 18:18:46.708575: Epoch 235 
2025-01-18 18:18:46.714171: Current learning rate: 0.00079 
2025-01-18 18:19:18.581148: train_loss -0.9211 
2025-01-18 18:19:18.581660: val_loss -0.4713 
2025-01-18 18:19:18.587925: Pseudo dice [np.float32(0.7097), np.float32(0.3292)] 
2025-01-18 18:19:18.592139: Epoch time: 31.87 s 
2025-01-18 18:19:19.157709:  
2025-01-18 18:19:19.158211: Epoch 236 
2025-01-18 18:19:19.163224: Current learning rate: 0.00075 
2025-01-18 18:19:51.023913: train_loss -0.9275 
2025-01-18 18:19:51.025425: val_loss -0.429 
2025-01-18 18:19:51.032063: Pseudo dice [np.float32(0.7062), np.float32(0.2309)] 
2025-01-18 18:19:51.035619: Epoch time: 31.87 s 
2025-01-18 18:19:51.586035:  
2025-01-18 18:19:51.586035: Epoch 237 
2025-01-18 18:19:51.592049: Current learning rate: 0.0007 
2025-01-18 18:20:23.447469: train_loss -0.9307 
2025-01-18 18:20:23.447972: val_loss -0.4677 
2025-01-18 18:20:23.458560: Pseudo dice [np.float32(0.7157), np.float32(0.3126)] 
2025-01-18 18:20:23.462073: Epoch time: 31.86 s 
2025-01-18 18:20:24.011483:  
2025-01-18 18:20:24.011985: Epoch 238 
2025-01-18 18:20:24.017999: Current learning rate: 0.00065 
2025-01-18 18:20:55.880586: train_loss -0.9295 
2025-01-18 18:20:55.880586: val_loss -0.4841 
2025-01-18 18:20:55.887125: Pseudo dice [np.float32(0.7162), np.float32(0.3758)] 
2025-01-18 18:20:55.891170: Epoch time: 31.87 s 
2025-01-18 18:20:56.441765:  
2025-01-18 18:20:56.442768: Epoch 239 
2025-01-18 18:20:56.449874: Current learning rate: 0.0006 
2025-01-18 18:21:28.287308: train_loss -0.9277 
2025-01-18 18:21:28.287811: val_loss -0.4625 
2025-01-18 18:21:28.293827: Pseudo dice [np.float32(0.7311), np.float32(0.343)] 
2025-01-18 18:21:28.297835: Epoch time: 31.85 s 
2025-01-18 18:21:29.006322:  
2025-01-18 18:21:29.007322: Epoch 240 
2025-01-18 18:21:29.013973: Current learning rate: 0.00055 
2025-01-18 18:22:00.850806: train_loss -0.9225 
2025-01-18 18:22:00.851811: val_loss -0.428 
2025-01-18 18:22:00.858334: Pseudo dice [np.float32(0.688), np.float32(0.2633)] 
2025-01-18 18:22:00.863345: Epoch time: 31.84 s 
2025-01-18 18:22:01.420735:  
2025-01-18 18:22:01.421738: Epoch 241 
2025-01-18 18:22:01.426764: Current learning rate: 0.0005 
2025-01-18 18:22:33.272372: train_loss -0.93 
2025-01-18 18:22:33.273373: val_loss -0.4587 
2025-01-18 18:22:33.279892: Pseudo dice [np.float32(0.7288), np.float32(0.2929)] 
2025-01-18 18:22:33.282398: Epoch time: 31.85 s 
2025-01-18 18:22:33.837137:  
2025-01-18 18:22:33.837137: Epoch 242 
2025-01-18 18:22:33.843152: Current learning rate: 0.00045 
2025-01-18 18:23:05.706620: train_loss -0.9322 
2025-01-18 18:23:05.706620: val_loss -0.4407 
2025-01-18 18:23:05.714306: Pseudo dice [np.float32(0.709), np.float32(0.2935)] 
2025-01-18 18:23:05.716840: Epoch time: 31.87 s 
2025-01-18 18:23:06.286961:  
2025-01-18 18:23:06.286961: Epoch 243 
2025-01-18 18:23:06.291989: Current learning rate: 0.0004 
2025-01-18 18:23:38.157095: train_loss -0.937 
2025-01-18 18:23:38.158096: val_loss -0.4069 
2025-01-18 18:23:38.164142: Pseudo dice [np.float32(0.6776), np.float32(0.2315)] 
2025-01-18 18:23:38.168674: Epoch time: 31.87 s 
2025-01-18 18:23:38.724393:  
2025-01-18 18:23:38.724393: Epoch 244 
2025-01-18 18:23:38.730408: Current learning rate: 0.00035 
2025-01-18 18:24:10.587046: train_loss -0.9316 
2025-01-18 18:24:10.587046: val_loss -0.449 
2025-01-18 18:24:10.593060: Pseudo dice [np.float32(0.7021), np.float32(0.2988)] 
2025-01-18 18:24:10.597160: Epoch time: 31.86 s 
2025-01-18 18:24:11.156218:  
2025-01-18 18:24:11.156218: Epoch 245 
2025-01-18 18:24:11.161229: Current learning rate: 0.0003 
2025-01-18 18:24:42.985693: train_loss -0.9309 
2025-01-18 18:24:42.986202: val_loss -0.4377 
2025-01-18 18:24:42.992287: Pseudo dice [np.float32(0.7068), np.float32(0.2875)] 
2025-01-18 18:24:42.996826: Epoch time: 31.83 s 
2025-01-18 18:24:43.562303:  
2025-01-18 18:24:43.563303: Epoch 246 
2025-01-18 18:24:43.568863: Current learning rate: 0.00024 
2025-01-18 18:25:15.397573: train_loss -0.93 
2025-01-18 18:25:15.397573: val_loss -0.4563 
2025-01-18 18:25:15.403591: Pseudo dice [np.float32(0.6943), np.float32(0.3208)] 
2025-01-18 18:25:15.407601: Epoch time: 31.84 s 
2025-01-18 18:25:15.976665:  
2025-01-18 18:25:15.976665: Epoch 247 
2025-01-18 18:25:15.982738: Current learning rate: 0.00019 
2025-01-18 18:25:47.807641: train_loss -0.9354 
2025-01-18 18:25:47.808144: val_loss -0.4804 
2025-01-18 18:25:47.813166: Pseudo dice [np.float32(0.7163), np.float32(0.3184)] 
2025-01-18 18:25:47.817675: Epoch time: 31.83 s 
2025-01-18 18:25:48.524829:  
2025-01-18 18:25:48.525356: Epoch 248 
2025-01-18 18:25:48.531373: Current learning rate: 0.00013 
2025-01-18 18:26:20.373837: train_loss -0.9373 
2025-01-18 18:26:20.373837: val_loss -0.4863 
2025-01-18 18:26:20.380073: Pseudo dice [np.float32(0.7166), np.float32(0.3761)] 
2025-01-18 18:26:20.384606: Epoch time: 31.85 s 
2025-01-18 18:26:20.943907:  
2025-01-18 18:26:20.943907: Epoch 249 
2025-01-18 18:26:20.951019: Current learning rate: 7e-05 
2025-01-18 18:26:52.797729: train_loss -0.9339 
2025-01-18 18:26:52.798731: val_loss -0.4142 
2025-01-18 18:26:52.805259: Pseudo dice [np.float32(0.6856), np.float32(0.2233)] 
2025-01-18 18:26:52.816852: Epoch time: 31.85 s 
2025-01-18 18:26:53.672878: Training done. 
2025-01-18 18:26:53.721992: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-18 18:26:53.733992: The split file contains 5 splits. 
2025-01-18 18:26:53.740994: Desired fold for training: 0 
2025-01-18 18:26:53.746990: This split has 224 training and 57 validation cases. 
2025-01-18 18:26:53.751991: predicting pancreas_021 
2025-01-18 18:26:53.758992: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-18 18:26:55.736169: predicting pancreas_024 
2025-01-18 18:26:55.749170: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-18 18:26:56.235411: predicting pancreas_035 
2025-01-18 18:26:56.248410: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-18 18:26:56.579881: predicting pancreas_040 
2025-01-18 18:26:56.585881: pancreas_040, shape torch.Size([1, 45, 526, 526]), rank 0 
2025-01-18 18:26:57.304926: predicting pancreas_042 
2025-01-18 18:26:57.311925: pancreas_042, shape torch.Size([1, 51, 537, 537]), rank 0 
2025-01-18 18:26:58.144622: predicting pancreas_056 
2025-01-18 18:26:58.152128: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-18 18:26:58.545881: predicting pancreas_067 
2025-01-18 18:26:58.554881: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-18 18:27:00.239749: predicting pancreas_075 
2025-01-18 18:27:00.253750: pancreas_075, shape torch.Size([1, 121, 521, 521]), rank 0 
2025-01-18 18:27:02.742280: predicting pancreas_086 
2025-01-18 18:27:02.762280: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-18 18:27:03.708859: predicting pancreas_089 
2025-01-18 18:27:03.718858: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-18 18:27:04.225404: predicting pancreas_092 
2025-01-18 18:27:04.238401: pancreas_092, shape torch.Size([1, 92, 513, 513]), rank 0 
2025-01-18 18:27:06.040717: predicting pancreas_094 
2025-01-18 18:27:06.054717: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-18 18:27:06.522245: predicting pancreas_095 
2025-01-18 18:27:06.533244: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-18 18:27:07.056458: predicting pancreas_098 
2025-01-18 18:27:07.069460: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-18 18:27:09.965971: predicting pancreas_109 
2025-01-18 18:27:09.992478: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-18 18:27:10.583296: predicting pancreas_110 
2025-01-18 18:27:10.601297: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-18 18:27:12.632929: predicting pancreas_114 
2025-01-18 18:27:12.655930: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-18 18:27:13.182189: predicting pancreas_119 
2025-01-18 18:27:13.192189: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-18 18:27:14.918023: predicting pancreas_138 
2025-01-18 18:27:14.935022: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-18 18:27:16.718701: predicting pancreas_145 
2025-01-18 18:27:16.734700: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-18 18:27:18.418294: predicting pancreas_148 
2025-01-18 18:27:18.435294: pancreas_148, shape torch.Size([1, 42, 486, 486]), rank 0 
2025-01-18 18:27:18.681361: predicting pancreas_169 
2025-01-18 18:27:18.687868: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-18 18:27:19.143494: predicting pancreas_170 
2025-01-18 18:27:19.153494: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-18 18:27:19.739730: predicting pancreas_172 
2025-01-18 18:27:19.756731: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-18 18:27:20.303779: predicting pancreas_175 
2025-01-18 18:27:20.318779: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-18 18:27:20.808854: predicting pancreas_180 
2025-01-18 18:27:20.822854: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-18 18:27:21.358397: predicting pancreas_191 
2025-01-18 18:27:21.371400: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-18 18:27:21.703432: predicting pancreas_193 
2025-01-18 18:27:21.710430: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-18 18:27:22.399040: predicting pancreas_212 
2025-01-18 18:27:22.416040: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-18 18:27:24.450033: predicting pancreas_215 
2025-01-18 18:27:24.466033: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-18 18:27:25.055181: predicting pancreas_222 
2025-01-18 18:27:25.070182: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-18 18:27:25.460508: predicting pancreas_235 
2025-01-18 18:27:25.468508: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-18 18:27:25.967651: predicting pancreas_241 
2025-01-18 18:27:25.983654: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-18 18:27:26.607915: predicting pancreas_242 
2025-01-18 18:27:26.625917: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-18 18:27:28.590011: predicting pancreas_244 
2025-01-18 18:27:28.610011: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-18 18:27:30.662019: predicting pancreas_246 
2025-01-18 18:27:30.681023: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-18 18:27:32.725427: predicting pancreas_247 
2025-01-18 18:27:32.747428: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-18 18:27:33.225173: predicting pancreas_264 
2025-01-18 18:27:33.236174: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-18 18:27:35.302065: predicting pancreas_265 
2025-01-18 18:27:35.317065: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-18 18:27:36.767973: predicting pancreas_266 
2025-01-18 18:27:36.778976: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-18 18:27:38.657845: predicting pancreas_267 
2025-01-18 18:27:38.674845: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-18 18:27:39.163970: predicting pancreas_275 
2025-01-18 18:27:39.175971: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-18 18:27:39.695355: predicting pancreas_279 
2025-01-18 18:27:39.707356: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-18 18:27:40.179445: predicting pancreas_287 
2025-01-18 18:27:40.187444: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-18 18:27:40.762607: predicting pancreas_301 
2025-01-18 18:27:40.777607: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-18 18:27:42.484834: predicting pancreas_323 
2025-01-18 18:27:42.495338: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-18 18:27:44.362095: predicting pancreas_336 
2025-01-18 18:27:44.383099: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-18 18:27:46.228346: predicting pancreas_344 
2025-01-18 18:27:46.243349: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-18 18:27:46.871964: predicting pancreas_351 
2025-01-18 18:27:46.887968: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-18 18:27:47.370105: predicting pancreas_354 
2025-01-18 18:27:47.380106: pancreas_354, shape torch.Size([1, 81, 529, 529]), rank 0 
2025-01-18 18:27:49.028125: predicting pancreas_372 
2025-01-18 18:27:49.041124: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-18 18:27:50.828120: predicting pancreas_377 
2025-01-18 18:27:50.850121: pancreas_377, shape torch.Size([1, 55, 551, 551]), rank 0 
2025-01-18 18:27:51.810008: predicting pancreas_387 
2025-01-18 18:27:51.819008: pancreas_387, shape torch.Size([1, 50, 498, 498]), rank 0 
2025-01-18 18:27:52.052640: predicting pancreas_391 
2025-01-18 18:27:52.059641: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-18 18:27:53.861491: predicting pancreas_392 
2025-01-18 18:27:53.880491: pancreas_392, shape torch.Size([1, 57, 448, 448]), rank 0 
2025-01-18 18:27:54.208055: predicting pancreas_410 
2025-01-18 18:27:54.214055: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-18 18:27:54.676863: predicting pancreas_412 
2025-01-18 18:27:54.687868: pancreas_412, shape torch.Size([1, 164, 584, 584]), rank 0 
2025-01-18 18:28:09.313293: Validation complete 
2025-01-18 18:28:09.313293: Mean Validation Dice:  0.4629383997239585 
