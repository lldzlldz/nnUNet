
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-16 14:21:15.872530: do_dummy_2d_data_aug: True 
2025-01-16 14:21:15.877527: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-16 14:21:15.880527: The split file contains 5 splits. 
2025-01-16 14:21:15.883529: Desired fold for training: 0 
2025-01-16 14:21:15.885527: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-16 14:21:21.612304: unpacking dataset... 
2025-01-16 14:21:21.804027: unpacking done... 
2025-01-16 14:21:24.696080:  
2025-01-16 14:21:24.696080: Epoch 0 
2025-01-16 14:21:24.701094: Current learning rate: 0.01 
2025-01-16 14:22:09.881153: train_loss 0.1394 
2025-01-16 14:22:09.882158: val_loss 0.0573 
2025-01-16 14:22:09.888172: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-16 14:22:09.891181: Epoch time: 45.19 s 
2025-01-16 14:22:09.893688: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-16 14:22:10.562093:  
2025-01-16 14:22:10.562598: Epoch 1 
2025-01-16 14:22:10.567111: Current learning rate: 0.00996 
2025-01-16 14:22:51.392871: train_loss 0.0325 
2025-01-16 14:22:51.393382: val_loss -0.0301 
2025-01-16 14:22:51.400030: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-16 14:22:51.403071: Epoch time: 40.83 s 
2025-01-16 14:22:51.963824:  
2025-01-16 14:22:51.963824: Epoch 2 
2025-01-16 14:22:51.969450: Current learning rate: 0.00993 
2025-01-16 14:23:32.814276: train_loss -0.1243 
2025-01-16 14:23:32.814779: val_loss -0.257 
2025-01-16 14:23:32.821913: Pseudo dice [np.float32(0.6494), np.float32(0.0)] 
2025-01-16 14:23:32.824963: Epoch time: 40.85 s 
2025-01-16 14:23:32.828055: Yayy! New best EMA pseudo Dice: 0.032499998807907104 
2025-01-16 14:23:33.618402:  
2025-01-16 14:23:33.619408: Epoch 3 
2025-01-16 14:23:33.624474: Current learning rate: 0.00989 
2025-01-16 14:24:14.462476: train_loss -0.2505 
2025-01-16 14:24:14.462476: val_loss -0.2792 
2025-01-16 14:24:14.469168: Pseudo dice [np.float32(0.6511), np.float32(0.0)] 
2025-01-16 14:24:14.472720: Epoch time: 40.84 s 
2025-01-16 14:24:14.475754: Yayy! New best EMA pseudo Dice: 0.061799999326467514 
2025-01-16 14:24:15.228144:  
2025-01-16 14:24:15.229144: Epoch 4 
2025-01-16 14:24:15.234659: Current learning rate: 0.00986 
2025-01-16 14:24:56.064074: train_loss -0.282 
2025-01-16 14:24:56.065078: val_loss -0.3226 
2025-01-16 14:24:56.071091: Pseudo dice [np.float32(0.6674), np.float32(0.0)] 
2025-01-16 14:24:56.074103: Epoch time: 40.84 s 
2025-01-16 14:24:56.076610: Yayy! New best EMA pseudo Dice: 0.08900000154972076 
2025-01-16 14:24:56.966113:  
2025-01-16 14:24:56.967118: Epoch 5 
2025-01-16 14:24:56.971682: Current learning rate: 0.00982 
2025-01-16 14:25:37.817027: train_loss -0.3187 
2025-01-16 14:25:37.817531: val_loss -0.3432 
2025-01-16 14:25:37.824630: Pseudo dice [np.float32(0.6763), np.float32(0.0)] 
2025-01-16 14:25:37.828751: Epoch time: 40.85 s 
2025-01-16 14:25:37.831287: Yayy! New best EMA pseudo Dice: 0.11389999836683273 
2025-01-16 14:25:38.567697:  
2025-01-16 14:25:38.567697: Epoch 6 
2025-01-16 14:25:38.572710: Current learning rate: 0.00978 
2025-01-16 14:26:19.405393: train_loss -0.3512 
2025-01-16 14:26:19.405897: val_loss -0.3574 
2025-01-16 14:26:19.410938: Pseudo dice [np.float32(0.6941), np.float32(0.0)] 
2025-01-16 14:26:19.414464: Epoch time: 40.84 s 
2025-01-16 14:26:19.416610: Yayy! New best EMA pseudo Dice: 0.1371999979019165 
2025-01-16 14:26:20.183757:  
2025-01-16 14:26:20.184761: Epoch 7 
2025-01-16 14:26:20.189923: Current learning rate: 0.00975 
2025-01-16 14:27:01.015924: train_loss -0.3583 
2025-01-16 14:27:01.015924: val_loss -0.3697 
2025-01-16 14:27:01.022458: Pseudo dice [np.float32(0.7194), np.float32(0.0)] 
2025-01-16 14:27:01.025467: Epoch time: 40.83 s 
2025-01-16 14:27:01.028979: Yayy! New best EMA pseudo Dice: 0.15950000286102295 
2025-01-16 14:27:01.821219:  
2025-01-16 14:27:01.821725: Epoch 8 
2025-01-16 14:27:01.826769: Current learning rate: 0.00971 
2025-01-16 14:27:42.660889: train_loss -0.3837 
2025-01-16 14:27:42.661893: val_loss -0.3909 
2025-01-16 14:27:42.668010: Pseudo dice [np.float32(0.7225), np.float32(0.0)] 
2025-01-16 14:27:42.671055: Epoch time: 40.84 s 
2025-01-16 14:27:42.673562: Yayy! New best EMA pseudo Dice: 0.17960000038146973 
2025-01-16 14:27:43.446197:  
2025-01-16 14:27:43.447200: Epoch 9 
2025-01-16 14:27:43.455903: Current learning rate: 0.00968 
2025-01-16 14:28:24.317402: train_loss -0.4038 
2025-01-16 14:28:24.317905: val_loss -0.4022 
2025-01-16 14:28:24.324068: Pseudo dice [np.float32(0.7333), np.float32(0.0)] 
2025-01-16 14:28:24.327110: Epoch time: 40.87 s 
2025-01-16 14:28:24.329132: Yayy! New best EMA pseudo Dice: 0.19830000400543213 
2025-01-16 14:28:25.061328:  
2025-01-16 14:28:25.062328: Epoch 10 
2025-01-16 14:28:25.067368: Current learning rate: 0.00964 
2025-01-16 14:29:05.919238: train_loss -0.406 
2025-01-16 14:29:05.919742: val_loss -0.3619 
2025-01-16 14:29:05.924837: Pseudo dice [np.float32(0.728), np.float32(0.0)] 
2025-01-16 14:29:05.928469: Epoch time: 40.86 s 
2025-01-16 14:29:05.930976: Yayy! New best EMA pseudo Dice: 0.21490000188350677 
2025-01-16 14:29:06.878690:  
2025-01-16 14:29:06.878690: Epoch 11 
2025-01-16 14:29:06.885260: Current learning rate: 0.0096 
2025-01-16 14:29:47.739206: train_loss -0.4251 
2025-01-16 14:29:47.740211: val_loss -0.4117 
2025-01-16 14:29:47.746737: Pseudo dice [np.float32(0.7232), np.float32(0.0)] 
2025-01-16 14:29:47.749246: Epoch time: 40.86 s 
2025-01-16 14:29:47.752764: Yayy! New best EMA pseudo Dice: 0.2295999974012375 
2025-01-16 14:29:48.554950:  
2025-01-16 14:29:48.555489: Epoch 12 
2025-01-16 14:29:48.561051: Current learning rate: 0.00957 
2025-01-16 14:30:29.393268: train_loss -0.4147 
2025-01-16 14:30:29.393770: val_loss -0.4399 
2025-01-16 14:30:29.400789: Pseudo dice [np.float32(0.7363), np.float32(0.3119)] 
2025-01-16 14:30:29.403797: Epoch time: 40.84 s 
2025-01-16 14:30:29.408309: Yayy! New best EMA pseudo Dice: 0.2590000033378601 
2025-01-16 14:30:30.317225:  
2025-01-16 14:30:30.317728: Epoch 13 
2025-01-16 14:30:30.323741: Current learning rate: 0.00953 
2025-01-16 14:31:11.164221: train_loss -0.476 
2025-01-16 14:31:11.164221: val_loss -0.4515 
2025-01-16 14:31:11.170324: Pseudo dice [np.float32(0.7244), np.float32(0.3754)] 
2025-01-16 14:31:11.173852: Epoch time: 40.85 s 
2025-01-16 14:31:11.176890: Yayy! New best EMA pseudo Dice: 0.288100004196167 
2025-01-16 14:31:11.958896:  
2025-01-16 14:31:11.958896: Epoch 14 
2025-01-16 14:31:11.964425: Current learning rate: 0.00949 
2025-01-16 14:31:52.811563: train_loss -0.4703 
2025-01-16 14:31:52.812066: val_loss -0.4481 
2025-01-16 14:31:52.817611: Pseudo dice [np.float32(0.7133), np.float32(0.3391)] 
2025-01-16 14:31:52.820639: Epoch time: 40.85 s 
2025-01-16 14:31:52.823985: Yayy! New best EMA pseudo Dice: 0.31189998984336853 
2025-01-16 14:31:53.627824:  
2025-01-16 14:31:53.627824: Epoch 15 
2025-01-16 14:31:53.633367: Current learning rate: 0.00946 
2025-01-16 14:32:34.475704: train_loss -0.5208 
2025-01-16 14:32:34.477775: val_loss -0.4425 
2025-01-16 14:32:34.485341: Pseudo dice [np.float32(0.7268), np.float32(0.2526)] 
2025-01-16 14:32:34.487845: Epoch time: 40.85 s 
2025-01-16 14:32:34.491354: Yayy! New best EMA pseudo Dice: 0.3296999931335449 
2025-01-16 14:32:35.270201:  
2025-01-16 14:32:35.270201: Epoch 16 
2025-01-16 14:32:35.275215: Current learning rate: 0.00942 
2025-01-16 14:33:16.138908: train_loss -0.5332 
2025-01-16 14:33:16.139410: val_loss -0.5083 
2025-01-16 14:33:16.144430: Pseudo dice [np.float32(0.7416), np.float32(0.4222)] 
2025-01-16 14:33:16.147948: Epoch time: 40.87 s 
2025-01-16 14:33:16.151963: Yayy! New best EMA pseudo Dice: 0.3549000024795532 
2025-01-16 14:33:16.927500:  
2025-01-16 14:33:16.927500: Epoch 17 
2025-01-16 14:33:16.932515: Current learning rate: 0.00939 
2025-01-16 14:33:57.778138: train_loss -0.5438 
2025-01-16 14:33:57.778138: val_loss -0.4965 
2025-01-16 14:33:57.785737: Pseudo dice [np.float32(0.7328), np.float32(0.4013)] 
2025-01-16 14:33:57.789247: Epoch time: 40.85 s 
2025-01-16 14:33:57.791754: Yayy! New best EMA pseudo Dice: 0.37610000371932983 
2025-01-16 14:33:58.543663:  
2025-01-16 14:33:58.543663: Epoch 18 
2025-01-16 14:33:58.549209: Current learning rate: 0.00935 
2025-01-16 14:34:39.405014: train_loss -0.5321 
2025-01-16 14:34:39.405014: val_loss -0.5318 
2025-01-16 14:34:39.411553: Pseudo dice [np.float32(0.7471), np.float32(0.4791)] 
2025-01-16 14:34:39.414562: Epoch time: 40.86 s 
2025-01-16 14:34:39.418070: Yayy! New best EMA pseudo Dice: 0.39980000257492065 
2025-01-16 14:34:40.208277:  
2025-01-16 14:34:40.209281: Epoch 19 
2025-01-16 14:34:40.213836: Current learning rate: 0.00931 
2025-01-16 14:35:21.047508: train_loss -0.554 
2025-01-16 14:35:21.048011: val_loss -0.422 
2025-01-16 14:35:21.053791: Pseudo dice [np.float32(0.7343), np.float32(0.2318)] 
2025-01-16 14:35:21.056833: Epoch time: 40.84 s 
2025-01-16 14:35:21.060371: Yayy! New best EMA pseudo Dice: 0.4081999957561493 
2025-01-16 14:35:21.846613:  
2025-01-16 14:35:21.847116: Epoch 20 
2025-01-16 14:35:21.852209: Current learning rate: 0.00928 
2025-01-16 14:36:02.708227: train_loss -0.5863 
2025-01-16 14:36:02.709232: val_loss -0.5112 
2025-01-16 14:36:02.715245: Pseudo dice [np.float32(0.7418), np.float32(0.4576)] 
2025-01-16 14:36:02.718254: Epoch time: 40.86 s 
2025-01-16 14:36:02.721765: Yayy! New best EMA pseudo Dice: 0.42730000615119934 
2025-01-16 14:36:03.668181:  
2025-01-16 14:36:03.669188: Epoch 21 
2025-01-16 14:36:03.674215: Current learning rate: 0.00924 
2025-01-16 14:36:44.512948: train_loss -0.5634 
2025-01-16 14:36:44.513451: val_loss -0.4748 
2025-01-16 14:36:44.520073: Pseudo dice [np.float32(0.7236), np.float32(0.2758)] 
2025-01-16 14:36:44.523595: Epoch time: 40.84 s 
2025-01-16 14:36:44.526444: Yayy! New best EMA pseudo Dice: 0.4345000088214874 
2025-01-16 14:36:45.301093:  
2025-01-16 14:36:45.301596: Epoch 22 
2025-01-16 14:36:45.306610: Current learning rate: 0.0092 
2025-01-16 14:37:26.136405: train_loss -0.5803 
2025-01-16 14:37:26.136405: val_loss -0.4481 
2025-01-16 14:37:26.142979: Pseudo dice [np.float32(0.7014), np.float32(0.3366)] 
2025-01-16 14:37:26.146490: Epoch time: 40.84 s 
2025-01-16 14:37:26.148996: Yayy! New best EMA pseudo Dice: 0.4429999887943268 
2025-01-16 14:37:26.897857:  
2025-01-16 14:37:26.897857: Epoch 23 
2025-01-16 14:37:26.903872: Current learning rate: 0.00917 
2025-01-16 14:38:07.735567: train_loss -0.5649 
2025-01-16 14:38:07.736073: val_loss -0.502 
2025-01-16 14:38:07.742625: Pseudo dice [np.float32(0.7822), np.float32(0.4335)] 
2025-01-16 14:38:07.746168: Epoch time: 40.84 s 
2025-01-16 14:38:07.749692: Yayy! New best EMA pseudo Dice: 0.4595000147819519 
2025-01-16 14:38:08.489045:  
2025-01-16 14:38:08.489045: Epoch 24 
2025-01-16 14:38:08.495106: Current learning rate: 0.00913 
2025-01-16 14:38:49.356236: train_loss -0.6265 
2025-01-16 14:38:49.360786: val_loss -0.5128 
2025-01-16 14:38:49.364319: Pseudo dice [np.float32(0.7534), np.float32(0.3693)] 
2025-01-16 14:38:49.367921: Epoch time: 40.87 s 
2025-01-16 14:38:49.370983: Yayy! New best EMA pseudo Dice: 0.46970000863075256 
2025-01-16 14:38:50.117450:  
2025-01-16 14:38:50.117450: Epoch 25 
2025-01-16 14:38:50.123557: Current learning rate: 0.0091 
2025-01-16 14:39:30.969485: train_loss -0.6042 
2025-01-16 14:39:30.969999: val_loss -0.5026 
2025-01-16 14:39:30.975653: Pseudo dice [np.float32(0.7479), np.float32(0.3997)] 
2025-01-16 14:39:30.978719: Epoch time: 40.85 s 
2025-01-16 14:39:30.980747: Yayy! New best EMA pseudo Dice: 0.48010000586509705 
2025-01-16 14:39:31.726403:  
2025-01-16 14:39:31.726906: Epoch 26 
2025-01-16 14:39:31.732992: Current learning rate: 0.00906 
2025-01-16 14:40:12.571032: train_loss -0.6382 
2025-01-16 14:40:12.571564: val_loss -0.49 
2025-01-16 14:40:12.576646: Pseudo dice [np.float32(0.7674), np.float32(0.2937)] 
2025-01-16 14:40:12.580184: Epoch time: 40.85 s 
2025-01-16 14:40:12.582700: Yayy! New best EMA pseudo Dice: 0.48510000109672546 
2025-01-16 14:40:13.316260:  
2025-01-16 14:40:13.316260: Epoch 27 
2025-01-16 14:40:13.321273: Current learning rate: 0.00902 
2025-01-16 14:40:54.186263: train_loss -0.6317 
2025-01-16 14:40:54.186263: val_loss -0.5442 
2025-01-16 14:40:54.192803: Pseudo dice [np.float32(0.7608), np.float32(0.4766)] 
2025-01-16 14:40:54.195813: Epoch time: 40.87 s 
2025-01-16 14:40:54.198319: Yayy! New best EMA pseudo Dice: 0.4984999895095825 
2025-01-16 14:40:54.939313:  
2025-01-16 14:40:54.939313: Epoch 28 
2025-01-16 14:40:54.944385: Current learning rate: 0.00899 
2025-01-16 14:41:35.796417: train_loss -0.6323 
2025-01-16 14:41:35.796963: val_loss -0.499 
2025-01-16 14:41:35.804146: Pseudo dice [np.float32(0.7707), np.float32(0.3298)] 
2025-01-16 14:41:35.806681: Epoch time: 40.86 s 
2025-01-16 14:41:35.810270: Yayy! New best EMA pseudo Dice: 0.5037000179290771 
2025-01-16 14:41:36.727765:  
2025-01-16 14:41:36.728270: Epoch 29 
2025-01-16 14:41:36.733320: Current learning rate: 0.00895 
2025-01-16 14:42:17.567852: train_loss -0.6338 
2025-01-16 14:42:17.568856: val_loss -0.5266 
2025-01-16 14:42:17.573871: Pseudo dice [np.float32(0.7689), np.float32(0.3791)] 
2025-01-16 14:42:17.577379: Epoch time: 40.84 s 
2025-01-16 14:42:17.580390: Yayy! New best EMA pseudo Dice: 0.510699987411499 
2025-01-16 14:42:18.331557:  
2025-01-16 14:42:18.331557: Epoch 30 
2025-01-16 14:42:18.336591: Current learning rate: 0.00891 
2025-01-16 14:42:59.165341: train_loss -0.6145 
2025-01-16 14:42:59.166347: val_loss -0.4739 
2025-01-16 14:42:59.171950: Pseudo dice [np.float32(0.7394), np.float32(0.3415)] 
2025-01-16 14:42:59.175014: Epoch time: 40.83 s 
2025-01-16 14:42:59.178073: Yayy! New best EMA pseudo Dice: 0.513700008392334 
2025-01-16 14:42:59.948449:  
2025-01-16 14:42:59.948951: Epoch 31 
2025-01-16 14:42:59.953964: Current learning rate: 0.00888 
2025-01-16 14:43:40.795082: train_loss -0.632 
2025-01-16 14:43:40.796082: val_loss -0.5229 
2025-01-16 14:43:40.801598: Pseudo dice [np.float32(0.7777), np.float32(0.4173)] 
2025-01-16 14:43:40.804103: Epoch time: 40.85 s 
2025-01-16 14:43:40.807612: Yayy! New best EMA pseudo Dice: 0.5220999717712402 
2025-01-16 14:43:41.566836:  
2025-01-16 14:43:41.566836: Epoch 32 
2025-01-16 14:43:41.571846: Current learning rate: 0.00884 
2025-01-16 14:44:22.409069: train_loss -0.6333 
2025-01-16 14:44:22.409069: val_loss -0.5116 
2025-01-16 14:44:22.414672: Pseudo dice [np.float32(0.7506), np.float32(0.3954)] 
2025-01-16 14:44:22.418199: Epoch time: 40.84 s 
2025-01-16 14:44:22.421232: Yayy! New best EMA pseudo Dice: 0.5271000266075134 
2025-01-16 14:44:23.213324:  
2025-01-16 14:44:23.213324: Epoch 33 
2025-01-16 14:44:23.218878: Current learning rate: 0.0088 
2025-01-16 14:45:04.048621: train_loss -0.6314 
2025-01-16 14:45:04.048621: val_loss -0.4894 
2025-01-16 14:45:04.053631: Pseudo dice [np.float32(0.7324), np.float32(0.4109)] 
2025-01-16 14:45:04.057137: Epoch time: 40.84 s 
2025-01-16 14:45:04.060144: Yayy! New best EMA pseudo Dice: 0.5315999984741211 
2025-01-16 14:45:04.845489:  
2025-01-16 14:45:04.845992: Epoch 34 
2025-01-16 14:45:04.851022: Current learning rate: 0.00877 
2025-01-16 14:45:45.679628: train_loss -0.64 
2025-01-16 14:45:45.679628: val_loss -0.4802 
2025-01-16 14:45:45.686161: Pseudo dice [np.float32(0.7525), np.float32(0.3688)] 
2025-01-16 14:45:45.689168: Epoch time: 40.84 s 
2025-01-16 14:45:45.691676: Yayy! New best EMA pseudo Dice: 0.534500002861023 
2025-01-16 14:45:46.459077:  
2025-01-16 14:45:46.460079: Epoch 35 
2025-01-16 14:45:46.464676: Current learning rate: 0.00873 
2025-01-16 14:46:27.301068: train_loss -0.66 
2025-01-16 14:46:27.302071: val_loss -0.4839 
2025-01-16 14:46:27.307667: Pseudo dice [np.float32(0.7535), np.float32(0.3469)] 
2025-01-16 14:46:27.310777: Epoch time: 40.84 s 
2025-01-16 14:46:27.313814: Yayy! New best EMA pseudo Dice: 0.5360999703407288 
2025-01-16 14:46:28.074628:  
2025-01-16 14:46:28.075131: Epoch 36 
2025-01-16 14:46:28.082144: Current learning rate: 0.00869 
2025-01-16 14:47:08.909035: train_loss -0.6488 
2025-01-16 14:47:08.910039: val_loss -0.4297 
2025-01-16 14:47:08.915119: Pseudo dice [np.float32(0.7393), np.float32(0.2873)] 
2025-01-16 14:47:08.918631: Epoch time: 40.84 s 
2025-01-16 14:47:09.640202:  
2025-01-16 14:47:09.640202: Epoch 37 
2025-01-16 14:47:09.645746: Current learning rate: 0.00866 
2025-01-16 14:47:50.447526: train_loss -0.6127 
2025-01-16 14:47:50.448529: val_loss -0.4813 
2025-01-16 14:47:50.458251: Pseudo dice [np.float32(0.7097), np.float32(0.4068)] 
2025-01-16 14:47:50.462309: Epoch time: 40.81 s 
2025-01-16 14:47:50.465364: Yayy! New best EMA pseudo Dice: 0.5361999869346619 
2025-01-16 14:47:51.245937:  
2025-01-16 14:47:51.245937: Epoch 38 
2025-01-16 14:47:51.251513: Current learning rate: 0.00862 
2025-01-16 14:48:32.076831: train_loss -0.6411 
2025-01-16 14:48:32.077835: val_loss -0.528 
2025-01-16 14:48:32.083945: Pseudo dice [np.float32(0.7749), np.float32(0.4821)] 
2025-01-16 14:48:32.087467: Epoch time: 40.83 s 
2025-01-16 14:48:32.090487: Yayy! New best EMA pseudo Dice: 0.5454999804496765 
2025-01-16 14:48:32.886569:  
2025-01-16 14:48:32.887072: Epoch 39 
2025-01-16 14:48:32.892082: Current learning rate: 0.00858 
2025-01-16 14:49:13.712877: train_loss -0.6403 
2025-01-16 14:49:13.713880: val_loss -0.4898 
2025-01-16 14:49:13.717889: Pseudo dice [np.float32(0.7538), np.float32(0.3146)] 
2025-01-16 14:49:13.722437: Epoch time: 40.83 s 
2025-01-16 14:49:14.308174:  
2025-01-16 14:49:14.309177: Epoch 40 
2025-01-16 14:49:14.313753: Current learning rate: 0.00855 
2025-01-16 14:49:55.145728: train_loss -0.6458 
2025-01-16 14:49:55.146731: val_loss -0.5033 
2025-01-16 14:49:55.153275: Pseudo dice [np.float32(0.7454), np.float32(0.3474)] 
2025-01-16 14:49:55.156783: Epoch time: 40.84 s 
2025-01-16 14:49:55.833965:  
2025-01-16 14:49:55.834472: Epoch 41 
2025-01-16 14:49:55.839528: Current learning rate: 0.00851 
2025-01-16 14:50:36.675432: train_loss -0.6785 
2025-01-16 14:50:36.676431: val_loss -0.5077 
2025-01-16 14:50:36.681944: Pseudo dice [np.float32(0.7524), np.float32(0.3661)] 
2025-01-16 14:50:36.685452: Epoch time: 40.84 s 
2025-01-16 14:50:36.687959: Yayy! New best EMA pseudo Dice: 0.5460000038146973 
2025-01-16 14:50:37.432588:  
2025-01-16 14:50:37.432588: Epoch 42 
2025-01-16 14:50:37.438117: Current learning rate: 0.00847 
2025-01-16 14:51:18.276554: train_loss -0.6834 
2025-01-16 14:51:18.277057: val_loss -0.5678 
2025-01-16 14:51:18.282921: Pseudo dice [np.float32(0.7944), np.float32(0.4381)] 
2025-01-16 14:51:18.285429: Epoch time: 40.84 s 
2025-01-16 14:51:18.287938: Yayy! New best EMA pseudo Dice: 0.5529999732971191 
2025-01-16 14:51:19.053406:  
2025-01-16 14:51:19.053914: Epoch 43 
2025-01-16 14:51:19.058442: Current learning rate: 0.00844 
2025-01-16 14:51:59.894472: train_loss -0.7057 
2025-01-16 14:51:59.894472: val_loss -0.5321 
2025-01-16 14:51:59.900264: Pseudo dice [np.float32(0.7657), np.float32(0.4758)] 
2025-01-16 14:51:59.903849: Epoch time: 40.84 s 
2025-01-16 14:51:59.906872: Yayy! New best EMA pseudo Dice: 0.5598000288009644 
2025-01-16 14:52:00.650395:  
2025-01-16 14:52:00.651399: Epoch 44 
2025-01-16 14:52:00.655969: Current learning rate: 0.0084 
2025-01-16 14:52:41.510330: train_loss -0.6957 
2025-01-16 14:52:41.511330: val_loss -0.4222 
2025-01-16 14:52:41.516848: Pseudo dice [np.float32(0.7161), np.float32(0.2289)] 
2025-01-16 14:52:41.520357: Epoch time: 40.86 s 
2025-01-16 14:52:42.214301:  
2025-01-16 14:52:42.214301: Epoch 45 
2025-01-16 14:52:42.219907: Current learning rate: 0.00836 
2025-01-16 14:53:23.090837: train_loss -0.6553 
2025-01-16 14:53:23.091343: val_loss -0.5284 
2025-01-16 14:53:23.096422: Pseudo dice [np.float32(0.7696), np.float32(0.3787)] 
2025-01-16 14:53:23.099493: Epoch time: 40.88 s 
2025-01-16 14:53:23.638963:  
2025-01-16 14:53:23.638963: Epoch 46 
2025-01-16 14:53:23.644537: Current learning rate: 0.00833 
2025-01-16 14:54:04.474659: train_loss -0.6881 
2025-01-16 14:54:04.474659: val_loss -0.5037 
2025-01-16 14:54:04.481780: Pseudo dice [np.float32(0.7667), np.float32(0.3532)] 
2025-01-16 14:54:04.484288: Epoch time: 40.84 s 
2025-01-16 14:54:05.026038:  
2025-01-16 14:54:05.026541: Epoch 47 
2025-01-16 14:54:05.031557: Current learning rate: 0.00829 
2025-01-16 14:54:45.883146: train_loss -0.6902 
2025-01-16 14:54:45.884146: val_loss -0.5026 
2025-01-16 14:54:45.889663: Pseudo dice [np.float32(0.7711), np.float32(0.3933)] 
2025-01-16 14:54:45.893174: Epoch time: 40.86 s 
2025-01-16 14:54:46.429496:  
2025-01-16 14:54:46.430496: Epoch 48 
2025-01-16 14:54:46.435570: Current learning rate: 0.00825 
2025-01-16 14:55:27.291388: train_loss -0.7139 
2025-01-16 14:55:27.291388: val_loss -0.5417 
2025-01-16 14:55:27.297478: Pseudo dice [np.float32(0.7701), np.float32(0.5264)] 
2025-01-16 14:55:27.300580: Epoch time: 40.86 s 
2025-01-16 14:55:27.303712: Yayy! New best EMA pseudo Dice: 0.5659999847412109 
2025-01-16 14:55:28.048518:  
2025-01-16 14:55:28.048518: Epoch 49 
2025-01-16 14:55:28.054082: Current learning rate: 0.00822 
2025-01-16 14:56:08.907424: train_loss -0.7342 
2025-01-16 14:56:08.907424: val_loss -0.5058 
2025-01-16 14:56:08.912544: Pseudo dice [np.float32(0.7742), np.float32(0.3624)] 
2025-01-16 14:56:08.916638: Epoch time: 40.86 s 
2025-01-16 14:56:09.076364: Yayy! New best EMA pseudo Dice: 0.5662000179290771 
2025-01-16 14:56:09.869038:  
2025-01-16 14:56:09.870041: Epoch 50 
2025-01-16 14:56:09.874604: Current learning rate: 0.00818 
2025-01-16 14:56:50.708563: train_loss -0.6988 
2025-01-16 14:56:50.709066: val_loss -0.5377 
2025-01-16 14:56:50.714114: Pseudo dice [np.float32(0.7683), np.float32(0.4258)] 
2025-01-16 14:56:50.717147: Epoch time: 40.84 s 
2025-01-16 14:56:50.720254: Yayy! New best EMA pseudo Dice: 0.5692999958992004 
2025-01-16 14:56:51.467489:  
2025-01-16 14:56:51.467489: Epoch 51 
2025-01-16 14:56:51.472558: Current learning rate: 0.00814 
2025-01-16 14:57:32.308028: train_loss -0.7154 
2025-01-16 14:57:32.309031: val_loss -0.4629 
2025-01-16 14:57:32.314046: Pseudo dice [np.float32(0.7699), np.float32(0.2936)] 
2025-01-16 14:57:32.317553: Epoch time: 40.84 s 
2025-01-16 14:57:32.865300:  
2025-01-16 14:57:32.865300: Epoch 52 
2025-01-16 14:57:32.872944: Current learning rate: 0.00811 
2025-01-16 14:58:13.705073: train_loss -0.7138 
2025-01-16 14:58:13.705575: val_loss -0.5372 
2025-01-16 14:58:13.710635: Pseudo dice [np.float32(0.777), np.float32(0.4604)] 
2025-01-16 14:58:13.713684: Epoch time: 40.84 s 
2025-01-16 14:58:13.716736: Yayy! New best EMA pseudo Dice: 0.570900022983551 
2025-01-16 14:58:14.456645:  
2025-01-16 14:58:14.457648: Epoch 53 
2025-01-16 14:58:14.462712: Current learning rate: 0.00807 
2025-01-16 14:58:55.266072: train_loss -0.7422 
2025-01-16 14:58:55.266587: val_loss -0.5424 
2025-01-16 14:58:55.272162: Pseudo dice [np.float32(0.7869), np.float32(0.4584)] 
2025-01-16 14:58:55.275190: Epoch time: 40.81 s 
2025-01-16 14:58:55.277695: Yayy! New best EMA pseudo Dice: 0.5759999752044678 
2025-01-16 14:58:56.205541:  
2025-01-16 14:58:56.205541: Epoch 54 
2025-01-16 14:58:56.210551: Current learning rate: 0.00803 
2025-01-16 14:59:37.041225: train_loss -0.7426 
2025-01-16 14:59:37.042226: val_loss -0.4647 
2025-01-16 14:59:37.048817: Pseudo dice [np.float32(0.7419), np.float32(0.3724)] 
2025-01-16 14:59:37.052323: Epoch time: 40.84 s 
2025-01-16 14:59:37.607258:  
2025-01-16 14:59:37.607761: Epoch 55 
2025-01-16 14:59:37.613315: Current learning rate: 0.008 
2025-01-16 15:00:18.434928: train_loss -0.7334 
2025-01-16 15:00:18.435430: val_loss -0.5413 
2025-01-16 15:00:18.441100: Pseudo dice [np.float32(0.7905), np.float32(0.4456)] 
2025-01-16 15:00:18.443626: Epoch time: 40.83 s 
2025-01-16 15:00:18.446156: Yayy! New best EMA pseudo Dice: 0.578499972820282 
2025-01-16 15:00:19.190555:  
2025-01-16 15:00:19.191065: Epoch 56 
2025-01-16 15:00:19.196132: Current learning rate: 0.00796 
2025-01-16 15:01:00.014266: train_loss -0.7512 
2025-01-16 15:01:00.014772: val_loss -0.5112 
2025-01-16 15:01:00.019839: Pseudo dice [np.float32(0.778), np.float32(0.3392)] 
2025-01-16 15:01:00.023870: Epoch time: 40.83 s 
2025-01-16 15:01:00.578286:  
2025-01-16 15:01:00.578286: Epoch 57 
2025-01-16 15:01:00.583305: Current learning rate: 0.00792 
2025-01-16 15:01:41.421579: train_loss -0.7353 
2025-01-16 15:01:41.421579: val_loss -0.5673 
2025-01-16 15:01:41.426630: Pseudo dice [np.float32(0.7922), np.float32(0.4425)] 
2025-01-16 15:01:41.430663: Epoch time: 40.84 s 
2025-01-16 15:01:41.433183: Yayy! New best EMA pseudo Dice: 0.5806000232696533 
2025-01-16 15:01:42.182699:  
2025-01-16 15:01:42.182699: Epoch 58 
2025-01-16 15:01:42.187724: Current learning rate: 0.00789 
2025-01-16 15:02:23.042045: train_loss -0.7349 
2025-01-16 15:02:23.042555: val_loss -0.4924 
2025-01-16 15:02:23.048145: Pseudo dice [np.float32(0.7461), np.float32(0.3477)] 
2025-01-16 15:02:23.050681: Epoch time: 40.86 s 
2025-01-16 15:02:23.601147:  
2025-01-16 15:02:23.602153: Epoch 59 
2025-01-16 15:02:23.606711: Current learning rate: 0.00785 
2025-01-16 15:03:04.430021: train_loss -0.7202 
2025-01-16 15:03:04.430530: val_loss -0.5478 
2025-01-16 15:03:04.436182: Pseudo dice [np.float32(0.7868), np.float32(0.393)] 
2025-01-16 15:03:04.439291: Epoch time: 40.83 s 
2025-01-16 15:03:04.993833:  
2025-01-16 15:03:04.993833: Epoch 60 
2025-01-16 15:03:04.998847: Current learning rate: 0.00781 
2025-01-16 15:03:45.820587: train_loss -0.7432 
2025-01-16 15:03:45.821588: val_loss -0.5278 
2025-01-16 15:03:45.828112: Pseudo dice [np.float32(0.7462), np.float32(0.4138)] 
2025-01-16 15:03:45.831620: Epoch time: 40.83 s 
2025-01-16 15:03:46.380206:  
2025-01-16 15:03:46.380206: Epoch 61 
2025-01-16 15:03:46.385224: Current learning rate: 0.00777 
2025-01-16 15:04:27.200082: train_loss -0.7529 
2025-01-16 15:04:27.200601: val_loss -0.5314 
2025-01-16 15:04:27.206158: Pseudo dice [np.float32(0.7615), np.float32(0.3988)] 
2025-01-16 15:04:27.209190: Epoch time: 40.82 s 
2025-01-16 15:04:27.916430:  
2025-01-16 15:04:27.916933: Epoch 62 
2025-01-16 15:04:27.920444: Current learning rate: 0.00774 
2025-01-16 15:05:08.799007: train_loss -0.7509 
2025-01-16 15:05:08.799514: val_loss -0.49 
2025-01-16 15:05:08.804647: Pseudo dice [np.float32(0.7901), np.float32(0.3661)] 
2025-01-16 15:05:08.807194: Epoch time: 40.88 s 
2025-01-16 15:05:09.355336:  
2025-01-16 15:05:09.356340: Epoch 63 
2025-01-16 15:05:09.360896: Current learning rate: 0.0077 
2025-01-16 15:05:50.209619: train_loss -0.7278 
2025-01-16 15:05:50.209619: val_loss -0.5589 
2025-01-16 15:05:50.214720: Pseudo dice [np.float32(0.7971), np.float32(0.4194)] 
2025-01-16 15:05:50.218802: Epoch time: 40.85 s 
2025-01-16 15:05:50.221880: Yayy! New best EMA pseudo Dice: 0.5817000269889832 
2025-01-16 15:05:50.995882:  
2025-01-16 15:05:50.995882: Epoch 64 
2025-01-16 15:05:51.001452: Current learning rate: 0.00766 
2025-01-16 15:06:31.842432: train_loss -0.7392 
2025-01-16 15:06:31.843439: val_loss -0.4627 
2025-01-16 15:06:31.848513: Pseudo dice [np.float32(0.7428), np.float32(0.354)] 
2025-01-16 15:06:31.851059: Epoch time: 40.85 s 
2025-01-16 15:06:32.411980:  
2025-01-16 15:06:32.412486: Epoch 65 
2025-01-16 15:06:32.416997: Current learning rate: 0.00763 
2025-01-16 15:07:13.237473: train_loss -0.7361 
2025-01-16 15:07:13.238479: val_loss -0.5309 
2025-01-16 15:07:13.244490: Pseudo dice [np.float32(0.7658), np.float32(0.4454)] 
2025-01-16 15:07:13.247500: Epoch time: 40.83 s 
2025-01-16 15:07:13.810884:  
2025-01-16 15:07:13.810884: Epoch 66 
2025-01-16 15:07:13.815961: Current learning rate: 0.00759 
2025-01-16 15:07:54.623860: train_loss -0.7362 
2025-01-16 15:07:54.623860: val_loss -0.5332 
2025-01-16 15:07:54.629879: Pseudo dice [np.float32(0.7836), np.float32(0.346)] 
2025-01-16 15:07:54.633554: Epoch time: 40.81 s 
2025-01-16 15:07:55.193621:  
2025-01-16 15:07:55.193621: Epoch 67 
2025-01-16 15:07:55.198634: Current learning rate: 0.00755 
2025-01-16 15:08:36.004903: train_loss -0.7448 
2025-01-16 15:08:36.005416: val_loss -0.5268 
2025-01-16 15:08:36.011061: Pseudo dice [np.float32(0.7684), np.float32(0.4197)] 
2025-01-16 15:08:36.013619: Epoch time: 40.81 s 
2025-01-16 15:08:36.578875:  
2025-01-16 15:08:36.579378: Epoch 68 
2025-01-16 15:08:36.585395: Current learning rate: 0.00751 
2025-01-16 15:09:17.402929: train_loss -0.7557 
2025-01-16 15:09:17.402929: val_loss -0.5799 
2025-01-16 15:09:17.407944: Pseudo dice [np.float32(0.7679), np.float32(0.5549)] 
2025-01-16 15:09:17.411450: Epoch time: 40.83 s 
2025-01-16 15:09:17.414461: Yayy! New best EMA pseudo Dice: 0.5889999866485596 
2025-01-16 15:09:18.219819:  
2025-01-16 15:09:18.220322: Epoch 69 
2025-01-16 15:09:18.225340: Current learning rate: 0.00748 
2025-01-16 15:09:59.029062: train_loss -0.7516 
2025-01-16 15:09:59.030065: val_loss -0.5108 
2025-01-16 15:09:59.035104: Pseudo dice [np.float32(0.761), np.float32(0.3638)] 
2025-01-16 15:09:59.038609: Epoch time: 40.81 s 
2025-01-16 15:09:59.759694:  
2025-01-16 15:09:59.759694: Epoch 70 
2025-01-16 15:09:59.764704: Current learning rate: 0.00744 
2025-01-16 15:10:40.555985: train_loss -0.7417 
2025-01-16 15:10:40.556988: val_loss -0.505 
2025-01-16 15:10:40.563056: Pseudo dice [np.float32(0.781), np.float32(0.3625)] 
2025-01-16 15:10:40.566080: Epoch time: 40.8 s 
2025-01-16 15:10:41.133010:  
2025-01-16 15:10:41.134013: Epoch 71 
2025-01-16 15:10:41.138570: Current learning rate: 0.0074 
2025-01-16 15:11:21.943522: train_loss -0.7758 
2025-01-16 15:11:21.944025: val_loss -0.5737 
2025-01-16 15:11:21.949125: Pseudo dice [np.float32(0.7914), np.float32(0.4168)] 
2025-01-16 15:11:21.953150: Epoch time: 40.81 s 
2025-01-16 15:11:22.524471:  
2025-01-16 15:11:22.524471: Epoch 72 
2025-01-16 15:11:22.530024: Current learning rate: 0.00737 
2025-01-16 15:12:03.324143: train_loss -0.7647 
2025-01-16 15:12:03.324143: val_loss -0.5098 
2025-01-16 15:12:03.329175: Pseudo dice [np.float32(0.7796), np.float32(0.4)] 
2025-01-16 15:12:03.333195: Epoch time: 40.8 s 
2025-01-16 15:12:03.896370:  
2025-01-16 15:12:03.897371: Epoch 73 
2025-01-16 15:12:03.902500: Current learning rate: 0.00733 
2025-01-16 15:12:44.700309: train_loss -0.7559 
2025-01-16 15:12:44.700309: val_loss -0.5321 
2025-01-16 15:12:44.706875: Pseudo dice [np.float32(0.7572), np.float32(0.4189)] 
2025-01-16 15:12:44.709924: Epoch time: 40.8 s 
2025-01-16 15:12:45.274917:  
2025-01-16 15:12:45.275917: Epoch 74 
2025-01-16 15:12:45.281430: Current learning rate: 0.00729 
2025-01-16 15:13:26.092172: train_loss -0.7421 
2025-01-16 15:13:26.092172: val_loss -0.5202 
2025-01-16 15:13:26.097245: Pseudo dice [np.float32(0.7612), np.float32(0.3819)] 
2025-01-16 15:13:26.100770: Epoch time: 40.82 s 
2025-01-16 15:13:26.669469:  
2025-01-16 15:13:26.670468: Epoch 75 
2025-01-16 15:13:26.676065: Current learning rate: 0.00725 
2025-01-16 15:14:07.485691: train_loss -0.7406 
2025-01-16 15:14:07.486202: val_loss -0.4874 
2025-01-16 15:14:07.491784: Pseudo dice [np.float32(0.7431), np.float32(0.4249)] 
2025-01-16 15:14:07.495308: Epoch time: 40.82 s 
2025-01-16 15:14:08.059177:  
2025-01-16 15:14:08.059177: Epoch 76 
2025-01-16 15:14:08.065193: Current learning rate: 0.00722 
2025-01-16 15:14:48.887889: train_loss -0.749 
2025-01-16 15:14:48.887889: val_loss -0.5002 
2025-01-16 15:14:48.894426: Pseudo dice [np.float32(0.7546), np.float32(0.3608)] 
2025-01-16 15:14:48.897437: Epoch time: 40.83 s 
2025-01-16 15:14:49.457070:  
2025-01-16 15:14:49.457070: Epoch 77 
2025-01-16 15:14:49.462627: Current learning rate: 0.00718 
2025-01-16 15:15:30.271283: train_loss -0.7579 
2025-01-16 15:15:30.271794: val_loss -0.5038 
2025-01-16 15:15:30.276871: Pseudo dice [np.float32(0.7754), np.float32(0.3481)] 
2025-01-16 15:15:30.280403: Epoch time: 40.82 s 
2025-01-16 15:15:31.005852:  
2025-01-16 15:15:31.005852: Epoch 78 
2025-01-16 15:15:31.011453: Current learning rate: 0.00714 
2025-01-16 15:16:11.804736: train_loss -0.764 
2025-01-16 15:16:11.805238: val_loss -0.5388 
2025-01-16 15:16:11.810842: Pseudo dice [np.float32(0.7735), np.float32(0.4588)] 
2025-01-16 15:16:11.813881: Epoch time: 40.8 s 
2025-01-16 15:16:12.385865:  
2025-01-16 15:16:12.386370: Epoch 79 
2025-01-16 15:16:12.391380: Current learning rate: 0.0071 
2025-01-16 15:16:53.202413: train_loss -0.7703 
2025-01-16 15:16:53.202413: val_loss -0.4965 
2025-01-16 15:16:53.209484: Pseudo dice [np.float32(0.7933), np.float32(0.3458)] 
2025-01-16 15:16:53.212521: Epoch time: 40.82 s 
2025-01-16 15:16:53.790807:  
2025-01-16 15:16:53.790807: Epoch 80 
2025-01-16 15:16:53.795905: Current learning rate: 0.00707 
2025-01-16 15:17:34.599966: train_loss -0.7595 
2025-01-16 15:17:34.600478: val_loss -0.5874 
2025-01-16 15:17:34.606053: Pseudo dice [np.float32(0.7912), np.float32(0.5091)] 
2025-01-16 15:17:34.609094: Epoch time: 40.81 s 
2025-01-16 15:17:34.612127: Yayy! New best EMA pseudo Dice: 0.5893999934196472 
2025-01-16 15:17:35.392268:  
2025-01-16 15:17:35.392770: Epoch 81 
2025-01-16 15:17:35.397851: Current learning rate: 0.00703 
2025-01-16 15:18:16.215391: train_loss -0.7843 
2025-01-16 15:18:16.216390: val_loss -0.51 
2025-01-16 15:18:16.221946: Pseudo dice [np.float32(0.7977), np.float32(0.3974)] 
2025-01-16 15:18:16.225532: Epoch time: 40.82 s 
2025-01-16 15:18:16.228084: Yayy! New best EMA pseudo Dice: 0.5902000069618225 
2025-01-16 15:18:17.010582:  
2025-01-16 15:18:17.010582: Epoch 82 
2025-01-16 15:18:17.015594: Current learning rate: 0.00699 
2025-01-16 15:18:57.834114: train_loss -0.7691 
2025-01-16 15:18:57.834114: val_loss -0.5311 
2025-01-16 15:18:57.838757: Pseudo dice [np.float32(0.7717), np.float32(0.4068)] 
2025-01-16 15:18:57.842778: Epoch time: 40.83 s 
2025-01-16 15:18:58.382984:  
2025-01-16 15:18:58.382984: Epoch 83 
2025-01-16 15:18:58.388050: Current learning rate: 0.00696 
2025-01-16 15:19:39.202736: train_loss -0.764 
2025-01-16 15:19:39.203252: val_loss -0.5269 
2025-01-16 15:19:39.209415: Pseudo dice [np.float32(0.7639), np.float32(0.4617)] 
2025-01-16 15:19:39.212466: Epoch time: 40.82 s 
2025-01-16 15:19:39.215522: Yayy! New best EMA pseudo Dice: 0.5924000144004822 
2025-01-16 15:19:39.995189:  
2025-01-16 15:19:39.996192: Epoch 84 
2025-01-16 15:19:40.000738: Current learning rate: 0.00692 
2025-01-16 15:20:20.786874: train_loss -0.7969 
2025-01-16 15:20:20.786874: val_loss -0.5401 
2025-01-16 15:20:20.791464: Pseudo dice [np.float32(0.8088), np.float32(0.4321)] 
2025-01-16 15:20:20.796039: Epoch time: 40.79 s 
2025-01-16 15:20:20.798546: Yayy! New best EMA pseudo Dice: 0.5952000021934509 
2025-01-16 15:20:21.567936:  
2025-01-16 15:20:21.568438: Epoch 85 
2025-01-16 15:20:21.573448: Current learning rate: 0.00688 
2025-01-16 15:21:02.373362: train_loss -0.8045 
2025-01-16 15:21:02.373883: val_loss -0.4794 
2025-01-16 15:21:02.378951: Pseudo dice [np.float32(0.7736), np.float32(0.3294)] 
2025-01-16 15:21:02.382478: Epoch time: 40.81 s 
2025-01-16 15:21:03.076795:  
2025-01-16 15:21:03.077795: Epoch 86 
2025-01-16 15:21:03.082909: Current learning rate: 0.00684 
2025-01-16 15:21:43.892845: train_loss -0.7932 
2025-01-16 15:21:43.892845: val_loss -0.6011 
2025-01-16 15:21:43.900428: Pseudo dice [np.float32(0.7947), np.float32(0.5544)] 
2025-01-16 15:21:43.903482: Epoch time: 40.82 s 
2025-01-16 15:21:43.906019: Yayy! New best EMA pseudo Dice: 0.5992000102996826 
2025-01-16 15:21:44.690193:  
2025-01-16 15:21:44.690704: Epoch 87 
2025-01-16 15:21:44.695751: Current learning rate: 0.0068 
2025-01-16 15:22:25.507136: train_loss -0.8007 
2025-01-16 15:22:25.507639: val_loss -0.5237 
2025-01-16 15:22:25.513348: Pseudo dice [np.float32(0.7756), np.float32(0.4396)] 
2025-01-16 15:22:25.516394: Epoch time: 40.82 s 
2025-01-16 15:22:25.518903: Yayy! New best EMA pseudo Dice: 0.6000000238418579 
2025-01-16 15:22:26.264801:  
2025-01-16 15:22:26.265804: Epoch 88 
2025-01-16 15:22:26.270359: Current learning rate: 0.00677 
2025-01-16 15:23:07.097253: train_loss -0.7572 
2025-01-16 15:23:07.097253: val_loss -0.5369 
2025-01-16 15:23:07.102383: Pseudo dice [np.float32(0.7491), np.float32(0.4395)] 
2025-01-16 15:23:07.105914: Epoch time: 40.83 s 
2025-01-16 15:23:07.652553:  
2025-01-16 15:23:07.653556: Epoch 89 
2025-01-16 15:23:07.658184: Current learning rate: 0.00673 
2025-01-16 15:23:48.474751: train_loss -0.8001 
2025-01-16 15:23:48.474751: val_loss -0.5492 
2025-01-16 15:23:48.480331: Pseudo dice [np.float32(0.7853), np.float32(0.4063)] 
2025-01-16 15:23:48.483887: Epoch time: 40.82 s 
2025-01-16 15:23:49.030331:  
2025-01-16 15:23:49.031334: Epoch 90 
2025-01-16 15:23:49.035878: Current learning rate: 0.00669 
2025-01-16 15:24:29.861893: train_loss -0.8145 
2025-01-16 15:24:29.862893: val_loss -0.466 
2025-01-16 15:24:29.867904: Pseudo dice [np.float32(0.7636), np.float32(0.4059)] 
2025-01-16 15:24:29.870912: Epoch time: 40.83 s 
2025-01-16 15:24:30.416611:  
2025-01-16 15:24:30.417614: Epoch 91 
2025-01-16 15:24:30.422199: Current learning rate: 0.00665 
2025-01-16 15:25:11.223329: train_loss -0.8001 
2025-01-16 15:25:11.223329: val_loss -0.5515 
2025-01-16 15:25:11.228420: Pseudo dice [np.float32(0.7972), np.float32(0.4947)] 
2025-01-16 15:25:11.231945: Epoch time: 40.81 s 
2025-01-16 15:25:11.234967: Yayy! New best EMA pseudo Dice: 0.6025000214576721 
2025-01-16 15:25:12.014465:  
2025-01-16 15:25:12.014982: Epoch 92 
2025-01-16 15:25:12.018524: Current learning rate: 0.00662 
2025-01-16 15:25:52.841035: train_loss -0.7965 
2025-01-16 15:25:52.841540: val_loss -0.5283 
2025-01-16 15:25:52.847614: Pseudo dice [np.float32(0.7681), np.float32(0.4832)] 
2025-01-16 15:25:52.851649: Epoch time: 40.83 s 
2025-01-16 15:25:52.854691: Yayy! New best EMA pseudo Dice: 0.6047999858856201 
2025-01-16 15:25:53.621624:  
2025-01-16 15:25:53.621624: Epoch 93 
2025-01-16 15:25:53.627711: Current learning rate: 0.00658 
2025-01-16 15:26:34.444196: train_loss -0.7833 
2025-01-16 15:26:34.444196: val_loss -0.5338 
2025-01-16 15:26:34.451324: Pseudo dice [np.float32(0.7826), np.float32(0.4943)] 
2025-01-16 15:26:34.454367: Epoch time: 40.82 s 
2025-01-16 15:26:34.456890: Yayy! New best EMA pseudo Dice: 0.6082000136375427 
2025-01-16 15:26:35.197472:  
2025-01-16 15:26:35.197472: Epoch 94 
2025-01-16 15:26:35.203086: Current learning rate: 0.00654 
2025-01-16 15:27:16.048314: train_loss -0.811 
2025-01-16 15:27:16.048826: val_loss -0.5295 
2025-01-16 15:27:16.054397: Pseudo dice [np.float32(0.7665), np.float32(0.4793)] 
2025-01-16 15:27:16.056933: Epoch time: 40.85 s 
2025-01-16 15:27:16.060464: Yayy! New best EMA pseudo Dice: 0.6096000075340271 
2025-01-16 15:27:16.988430:  
2025-01-16 15:27:16.988430: Epoch 95 
2025-01-16 15:27:16.993988: Current learning rate: 0.0065 
2025-01-16 15:27:57.818666: train_loss -0.82 
2025-01-16 15:27:57.819170: val_loss -0.5335 
2025-01-16 15:27:57.825234: Pseudo dice [np.float32(0.7886), np.float32(0.3914)] 
2025-01-16 15:27:57.827373: Epoch time: 40.83 s 
2025-01-16 15:27:58.380176:  
2025-01-16 15:27:58.380176: Epoch 96 
2025-01-16 15:27:58.385234: Current learning rate: 0.00647 
2025-01-16 15:28:39.212255: train_loss -0.8197 
2025-01-16 15:28:39.212255: val_loss -0.5509 
2025-01-16 15:28:39.218355: Pseudo dice [np.float32(0.7997), np.float32(0.5576)] 
2025-01-16 15:28:39.221861: Epoch time: 40.83 s 
2025-01-16 15:28:39.224871: Yayy! New best EMA pseudo Dice: 0.614799976348877 
2025-01-16 15:28:40.008456:  
2025-01-16 15:28:40.009456: Epoch 97 
2025-01-16 15:28:40.014511: Current learning rate: 0.00643 
2025-01-16 15:29:20.844515: train_loss -0.7922 
2025-01-16 15:29:20.845515: val_loss -0.5569 
2025-01-16 15:29:20.851027: Pseudo dice [np.float32(0.791), np.float32(0.5348)] 
2025-01-16 15:29:20.854534: Epoch time: 40.84 s 
2025-01-16 15:29:20.857039: Yayy! New best EMA pseudo Dice: 0.6195999979972839 
2025-01-16 15:29:21.616203:  
2025-01-16 15:29:21.616203: Epoch 98 
2025-01-16 15:29:21.621751: Current learning rate: 0.00639 
2025-01-16 15:30:02.445747: train_loss -0.8218 
2025-01-16 15:30:02.446258: val_loss -0.5026 
2025-01-16 15:30:02.451305: Pseudo dice [np.float32(0.7533), np.float32(0.3708)] 
2025-01-16 15:30:02.454834: Epoch time: 40.83 s 
2025-01-16 15:30:03.006183:  
2025-01-16 15:30:03.006685: Epoch 99 
2025-01-16 15:30:03.011733: Current learning rate: 0.00635 
2025-01-16 15:30:43.825828: train_loss -0.8177 
2025-01-16 15:30:43.826832: val_loss -0.5615 
2025-01-16 15:30:43.831842: Pseudo dice [np.float32(0.8008), np.float32(0.4675)] 
2025-01-16 15:30:43.835855: Epoch time: 40.82 s 
2025-01-16 15:30:44.588242:  
2025-01-16 15:30:44.588242: Epoch 100 
2025-01-16 15:30:44.594766: Current learning rate: 0.00631 
2025-01-16 15:31:25.403802: train_loss -0.817 
2025-01-16 15:31:25.403802: val_loss -0.5425 
2025-01-16 15:31:25.409873: Pseudo dice [np.float32(0.7841), np.float32(0.4533)] 
2025-01-16 15:31:25.412905: Epoch time: 40.82 s 
2025-01-16 15:31:25.965923:  
2025-01-16 15:31:25.965923: Epoch 101 
2025-01-16 15:31:25.971006: Current learning rate: 0.00628 
2025-01-16 15:32:06.766224: train_loss -0.8098 
2025-01-16 15:32:06.766224: val_loss -0.553 
2025-01-16 15:32:06.772365: Pseudo dice [np.float32(0.7695), np.float32(0.4575)] 
2025-01-16 15:32:06.775909: Epoch time: 40.8 s 
2025-01-16 15:32:07.329901:  
2025-01-16 15:32:07.329901: Epoch 102 
2025-01-16 15:32:07.335116: Current learning rate: 0.00624 
2025-01-16 15:32:48.131955: train_loss -0.8 
2025-01-16 15:32:48.132457: val_loss -0.5198 
2025-01-16 15:32:48.139488: Pseudo dice [np.float32(0.7571), np.float32(0.4229)] 
2025-01-16 15:32:48.142521: Epoch time: 40.8 s 
2025-01-16 15:32:48.846537:  
2025-01-16 15:32:48.847540: Epoch 103 
2025-01-16 15:32:48.853177: Current learning rate: 0.0062 
2025-01-16 15:33:29.664748: train_loss -0.8039 
2025-01-16 15:33:29.665255: val_loss -0.5691 
2025-01-16 15:33:29.671414: Pseudo dice [np.float32(0.7793), np.float32(0.593)] 
2025-01-16 15:33:29.674940: Epoch time: 40.82 s 
2025-01-16 15:33:29.677454: Yayy! New best EMA pseudo Dice: 0.6205999851226807 
2025-01-16 15:33:30.450013:  
2025-01-16 15:33:30.451011: Epoch 104 
2025-01-16 15:33:30.456074: Current learning rate: 0.00616 
2025-01-16 15:34:11.281934: train_loss -0.7916 
2025-01-16 15:34:11.282452: val_loss -0.5071 
2025-01-16 15:34:11.287492: Pseudo dice [np.float32(0.7751), np.float32(0.3524)] 
2025-01-16 15:34:11.290590: Epoch time: 40.83 s 
2025-01-16 15:34:11.853028:  
2025-01-16 15:34:11.853028: Epoch 105 
2025-01-16 15:34:11.858572: Current learning rate: 0.00612 
2025-01-16 15:34:52.688020: train_loss -0.7857 
2025-01-16 15:34:52.688523: val_loss -0.549 
2025-01-16 15:34:52.694068: Pseudo dice [np.float32(0.7962), np.float32(0.4692)] 
2025-01-16 15:34:52.697094: Epoch time: 40.83 s 
2025-01-16 15:34:53.255025:  
2025-01-16 15:34:53.255025: Epoch 106 
2025-01-16 15:34:53.261080: Current learning rate: 0.00609 
2025-01-16 15:35:34.089698: train_loss -0.8072 
2025-01-16 15:35:34.090200: val_loss -0.5315 
2025-01-16 15:35:34.095744: Pseudo dice [np.float32(0.7705), np.float32(0.4591)] 
2025-01-16 15:35:34.098757: Epoch time: 40.84 s 
2025-01-16 15:35:34.659860:  
2025-01-16 15:35:34.659860: Epoch 107 
2025-01-16 15:35:34.665922: Current learning rate: 0.00605 
2025-01-16 15:36:15.491098: train_loss -0.8031 
2025-01-16 15:36:15.492101: val_loss -0.584 
2025-01-16 15:36:15.497654: Pseudo dice [np.float32(0.7896), np.float32(0.6196)] 
2025-01-16 15:36:15.500176: Epoch time: 40.83 s 
2025-01-16 15:36:15.502697: Yayy! New best EMA pseudo Dice: 0.6252999901771545 
2025-01-16 15:36:16.271025:  
2025-01-16 15:36:16.271527: Epoch 108 
2025-01-16 15:36:16.276537: Current learning rate: 0.00601 
2025-01-16 15:36:57.081071: train_loss -0.8273 
2025-01-16 15:36:57.081071: val_loss -0.5835 
2025-01-16 15:36:57.087059: Pseudo dice [np.float32(0.7981), np.float32(0.6174)] 
2025-01-16 15:36:57.089571: Epoch time: 40.81 s 
2025-01-16 15:36:57.093629: Yayy! New best EMA pseudo Dice: 0.6334999799728394 
2025-01-16 15:36:57.880783:  
2025-01-16 15:36:57.881787: Epoch 109 
2025-01-16 15:36:57.886340: Current learning rate: 0.00597 
2025-01-16 15:37:38.723842: train_loss -0.8158 
2025-01-16 15:37:38.724843: val_loss -0.55 
2025-01-16 15:37:38.730359: Pseudo dice [np.float32(0.7829), np.float32(0.4589)] 
2025-01-16 15:37:38.732865: Epoch time: 40.84 s 
2025-01-16 15:37:39.303471:  
2025-01-16 15:37:39.303471: Epoch 110 
2025-01-16 15:37:39.308485: Current learning rate: 0.00593 
2025-01-16 15:38:20.143026: train_loss -0.8375 
2025-01-16 15:38:20.143026: val_loss -0.5351 
2025-01-16 15:38:20.148042: Pseudo dice [np.float32(0.806), np.float32(0.427)] 
2025-01-16 15:38:20.151551: Epoch time: 40.84 s 
2025-01-16 15:38:20.857514:  
2025-01-16 15:38:20.858523: Epoch 111 
2025-01-16 15:38:20.863076: Current learning rate: 0.0059 
2025-01-16 15:39:01.703216: train_loss -0.8145 
2025-01-16 15:39:01.703760: val_loss -0.57 
2025-01-16 15:39:01.709474: Pseudo dice [np.float32(0.7933), np.float32(0.543)] 
2025-01-16 15:39:01.713063: Epoch time: 40.85 s 
2025-01-16 15:39:01.716132: Yayy! New best EMA pseudo Dice: 0.6344000101089478 
2025-01-16 15:39:02.490941:  
2025-01-16 15:39:02.490941: Epoch 112 
2025-01-16 15:39:02.495967: Current learning rate: 0.00586 
2025-01-16 15:39:43.328936: train_loss -0.8318 
2025-01-16 15:39:43.330455: val_loss -0.4852 
2025-01-16 15:39:43.335530: Pseudo dice [np.float32(0.7938), np.float32(0.3234)] 
2025-01-16 15:39:43.339093: Epoch time: 40.84 s 
2025-01-16 15:39:43.888975:  
2025-01-16 15:39:43.889478: Epoch 113 
2025-01-16 15:39:43.894491: Current learning rate: 0.00582 
2025-01-16 15:40:24.718900: train_loss -0.8132 
2025-01-16 15:40:24.719414: val_loss -0.5517 
2025-01-16 15:40:24.724980: Pseudo dice [np.float32(0.8016), np.float32(0.516)] 
2025-01-16 15:40:24.728517: Epoch time: 40.83 s 
2025-01-16 15:40:25.281128:  
2025-01-16 15:40:25.282132: Epoch 114 
2025-01-16 15:40:25.287191: Current learning rate: 0.00578 
2025-01-16 15:41:06.135432: train_loss -0.8509 
2025-01-16 15:41:06.135950: val_loss -0.5424 
2025-01-16 15:41:06.141612: Pseudo dice [np.float32(0.7951), np.float32(0.422)] 
2025-01-16 15:41:06.144192: Epoch time: 40.85 s 
2025-01-16 15:41:06.695032:  
2025-01-16 15:41:06.696537: Epoch 115 
2025-01-16 15:41:06.701047: Current learning rate: 0.00574 
2025-01-16 15:41:47.536160: train_loss -0.8417 
2025-01-16 15:41:47.536678: val_loss -0.5442 
2025-01-16 15:41:47.541938: Pseudo dice [np.float32(0.7824), np.float32(0.5182)] 
2025-01-16 15:41:47.545464: Epoch time: 40.84 s 
2025-01-16 15:41:48.108800:  
2025-01-16 15:41:48.108800: Epoch 116 
2025-01-16 15:41:48.115357: Current learning rate: 0.0057 
2025-01-16 15:42:28.948534: train_loss -0.8468 
2025-01-16 15:42:28.948534: val_loss -0.6214 
2025-01-16 15:42:28.954648: Pseudo dice [np.float32(0.7924), np.float32(0.639)] 
2025-01-16 15:42:28.957155: Epoch time: 40.84 s 
2025-01-16 15:42:28.960662: Yayy! New best EMA pseudo Dice: 0.638700008392334 
2025-01-16 15:42:29.740525:  
2025-01-16 15:42:29.740525: Epoch 117 
2025-01-16 15:42:29.745538: Current learning rate: 0.00567 
2025-01-16 15:43:10.583912: train_loss -0.8364 
2025-01-16 15:43:10.583912: val_loss -0.5286 
2025-01-16 15:43:10.589993: Pseudo dice [np.float32(0.7752), np.float32(0.4129)] 
2025-01-16 15:43:10.593513: Epoch time: 40.84 s 
2025-01-16 15:43:11.163660:  
2025-01-16 15:43:11.163660: Epoch 118 
2025-01-16 15:43:11.169239: Current learning rate: 0.00563 
2025-01-16 15:43:52.013114: train_loss -0.8408 
2025-01-16 15:43:52.013626: val_loss -0.5295 
2025-01-16 15:43:52.019168: Pseudo dice [np.float32(0.7923), np.float32(0.499)] 
2025-01-16 15:43:52.021675: Epoch time: 40.85 s 
2025-01-16 15:43:52.589758:  
2025-01-16 15:43:52.589758: Epoch 119 
2025-01-16 15:43:52.594778: Current learning rate: 0.00559 
2025-01-16 15:44:33.431808: train_loss -0.8356 
2025-01-16 15:44:33.431808: val_loss -0.5326 
2025-01-16 15:44:33.436370: Pseudo dice [np.float32(0.7955), np.float32(0.4422)] 
2025-01-16 15:44:33.440918: Epoch time: 40.84 s 
2025-01-16 15:44:34.164994:  
2025-01-16 15:44:34.165998: Epoch 120 
2025-01-16 15:44:34.170556: Current learning rate: 0.00555 
2025-01-16 15:45:14.996707: train_loss -0.8494 
2025-01-16 15:45:14.997214: val_loss -0.591 
2025-01-16 15:45:15.003276: Pseudo dice [np.float32(0.7924), np.float32(0.5612)] 
2025-01-16 15:45:15.005782: Epoch time: 40.83 s 
2025-01-16 15:45:15.566041:  
2025-01-16 15:45:15.566544: Epoch 121 
2025-01-16 15:45:15.571557: Current learning rate: 0.00551 
2025-01-16 15:45:56.405833: train_loss -0.8388 
2025-01-16 15:45:56.405833: val_loss -0.4953 
2025-01-16 15:45:56.412449: Pseudo dice [np.float32(0.7777), np.float32(0.4321)] 
2025-01-16 15:45:56.415491: Epoch time: 40.84 s 
2025-01-16 15:45:56.989579:  
2025-01-16 15:45:56.990580: Epoch 122 
2025-01-16 15:45:56.996153: Current learning rate: 0.00547 
2025-01-16 15:46:37.830750: train_loss -0.8404 
2025-01-16 15:46:37.830750: val_loss -0.5595 
2025-01-16 15:46:37.836767: Pseudo dice [np.float32(0.7823), np.float32(0.5238)] 
2025-01-16 15:46:37.839277: Epoch time: 40.84 s 
2025-01-16 15:46:38.402451:  
2025-01-16 15:46:38.403456: Epoch 123 
2025-01-16 15:46:38.408008: Current learning rate: 0.00544 
2025-01-16 15:47:19.224689: train_loss -0.8352 
2025-01-16 15:47:19.224689: val_loss -0.523 
2025-01-16 15:47:19.230779: Pseudo dice [np.float32(0.7622), np.float32(0.4048)] 
2025-01-16 15:47:19.233318: Epoch time: 40.82 s 
2025-01-16 15:47:19.791058:  
2025-01-16 15:47:19.791058: Epoch 124 
2025-01-16 15:47:19.796072: Current learning rate: 0.0054 
2025-01-16 15:48:00.613181: train_loss -0.8472 
2025-01-16 15:48:00.614186: val_loss -0.4932 
2025-01-16 15:48:00.620238: Pseudo dice [np.float32(0.7577), np.float32(0.4461)] 
2025-01-16 15:48:00.623248: Epoch time: 40.82 s 
2025-01-16 15:48:01.194645:  
2025-01-16 15:48:01.194645: Epoch 125 
2025-01-16 15:48:01.199767: Current learning rate: 0.00536 
2025-01-16 15:48:42.021952: train_loss -0.8282 
2025-01-16 15:48:42.022455: val_loss -0.5627 
2025-01-16 15:48:42.028001: Pseudo dice [np.float32(0.8071), np.float32(0.4531)] 
2025-01-16 15:48:42.031543: Epoch time: 40.83 s 
2025-01-16 15:48:42.590421:  
2025-01-16 15:48:42.590421: Epoch 126 
2025-01-16 15:48:42.595960: Current learning rate: 0.00532 
2025-01-16 15:49:23.418225: train_loss -0.8466 
2025-01-16 15:49:23.418225: val_loss -0.5234 
2025-01-16 15:49:23.424775: Pseudo dice [np.float32(0.78), np.float32(0.4909)] 
2025-01-16 15:49:23.427871: Epoch time: 40.83 s 
2025-01-16 15:49:23.985572:  
2025-01-16 15:49:23.985572: Epoch 127 
2025-01-16 15:49:23.990653: Current learning rate: 0.00528 
2025-01-16 15:50:04.815917: train_loss -0.847 
2025-01-16 15:50:04.816922: val_loss -0.513 
2025-01-16 15:50:04.822064: Pseudo dice [np.float32(0.7911), np.float32(0.3876)] 
2025-01-16 15:50:04.825571: Epoch time: 40.83 s 
2025-01-16 15:50:05.549093:  
2025-01-16 15:50:05.549093: Epoch 128 
2025-01-16 15:50:05.554610: Current learning rate: 0.00524 
2025-01-16 15:50:46.344270: train_loss -0.8309 
2025-01-16 15:50:46.344270: val_loss -0.5149 
2025-01-16 15:50:46.350840: Pseudo dice [np.float32(0.7735), np.float32(0.4328)] 
2025-01-16 15:50:46.353879: Epoch time: 40.8 s 
2025-01-16 15:50:46.912667:  
2025-01-16 15:50:46.912667: Epoch 129 
2025-01-16 15:50:46.917685: Current learning rate: 0.0052 
2025-01-16 15:51:27.723144: train_loss -0.8304 
2025-01-16 15:51:27.724144: val_loss -0.585 
2025-01-16 15:51:27.729660: Pseudo dice [np.float32(0.7966), np.float32(0.5047)] 
2025-01-16 15:51:27.733168: Epoch time: 40.81 s 
2025-01-16 15:51:28.293636:  
2025-01-16 15:51:28.293636: Epoch 130 
2025-01-16 15:51:28.299741: Current learning rate: 0.00517 
2025-01-16 15:52:09.104033: train_loss -0.8343 
2025-01-16 15:52:09.105538: val_loss -0.516 
2025-01-16 15:52:09.110550: Pseudo dice [np.float32(0.76), np.float32(0.4682)] 
2025-01-16 15:52:09.114061: Epoch time: 40.81 s 
2025-01-16 15:52:09.688473:  
2025-01-16 15:52:09.689478: Epoch 131 
2025-01-16 15:52:09.694035: Current learning rate: 0.00513 
2025-01-16 15:52:50.533083: train_loss -0.849 
2025-01-16 15:52:50.533083: val_loss -0.5752 
2025-01-16 15:52:50.539222: Pseudo dice [np.float32(0.7997), np.float32(0.4833)] 
2025-01-16 15:52:50.542308: Epoch time: 40.84 s 
2025-01-16 15:52:51.101738:  
2025-01-16 15:52:51.102744: Epoch 132 
2025-01-16 15:52:51.107782: Current learning rate: 0.00509 
2025-01-16 15:53:31.925015: train_loss -0.8548 
2025-01-16 15:53:31.926021: val_loss -0.5227 
2025-01-16 15:53:31.932207: Pseudo dice [np.float32(0.7808), np.float32(0.4615)] 
2025-01-16 15:53:31.935255: Epoch time: 40.82 s 
2025-01-16 15:53:32.502717:  
2025-01-16 15:53:32.502717: Epoch 133 
2025-01-16 15:53:32.507965: Current learning rate: 0.00505 
2025-01-16 15:54:13.334616: train_loss -0.8392 
2025-01-16 15:54:13.334616: val_loss -0.508 
2025-01-16 15:54:13.341134: Pseudo dice [np.float32(0.7729), np.float32(0.5077)] 
2025-01-16 15:54:13.343641: Epoch time: 40.83 s 
2025-01-16 15:54:13.911774:  
2025-01-16 15:54:13.911774: Epoch 134 
2025-01-16 15:54:13.917307: Current learning rate: 0.00501 
2025-01-16 15:54:54.751929: train_loss -0.8485 
2025-01-16 15:54:54.752936: val_loss -0.5836 
2025-01-16 15:54:54.757981: Pseudo dice [np.float32(0.787), np.float32(0.6687)] 
2025-01-16 15:54:54.761487: Epoch time: 40.84 s 
2025-01-16 15:54:55.327405:  
2025-01-16 15:54:55.328413: Epoch 135 
2025-01-16 15:54:55.333447: Current learning rate: 0.00497 
2025-01-16 15:55:36.161755: train_loss -0.8494 
2025-01-16 15:55:36.161755: val_loss -0.5646 
2025-01-16 15:55:36.167386: Pseudo dice [np.float32(0.7794), np.float32(0.6428)] 
2025-01-16 15:55:36.170447: Epoch time: 40.83 s 
2025-01-16 15:55:36.173492: Yayy! New best EMA pseudo Dice: 0.6446999907493591 
2025-01-16 15:55:36.971804:  
2025-01-16 15:55:36.971804: Epoch 136 
2025-01-16 15:55:36.977932: Current learning rate: 0.00493 
2025-01-16 15:56:17.790627: train_loss -0.8566 
2025-01-16 15:56:17.790627: val_loss -0.5237 
2025-01-16 15:56:17.796685: Pseudo dice [np.float32(0.7801), np.float32(0.4359)] 
2025-01-16 15:56:17.800210: Epoch time: 40.82 s 
2025-01-16 15:56:18.538648:  
2025-01-16 15:56:18.538648: Epoch 137 
2025-01-16 15:56:18.543729: Current learning rate: 0.00489 
2025-01-16 15:56:59.343784: train_loss -0.8657 
2025-01-16 15:56:59.344789: val_loss -0.5397 
2025-01-16 15:56:59.349802: Pseudo dice [np.float32(0.7855), np.float32(0.5197)] 
2025-01-16 15:56:59.353309: Epoch time: 40.81 s 
2025-01-16 15:56:59.917742:  
2025-01-16 15:56:59.917742: Epoch 138 
2025-01-16 15:56:59.923305: Current learning rate: 0.00485 
2025-01-16 15:57:40.735591: train_loss -0.8428 
2025-01-16 15:57:40.736095: val_loss -0.5035 
2025-01-16 15:57:40.741626: Pseudo dice [np.float32(0.7755), np.float32(0.3617)] 
2025-01-16 15:57:40.744650: Epoch time: 40.82 s 
2025-01-16 15:57:41.320706:  
2025-01-16 15:57:41.320706: Epoch 139 
2025-01-16 15:57:41.325807: Current learning rate: 0.00482 
2025-01-16 15:58:22.143873: train_loss -0.8339 
2025-01-16 15:58:22.144382: val_loss -0.577 
2025-01-16 15:58:22.150580: Pseudo dice [np.float32(0.799), np.float32(0.5115)] 
2025-01-16 15:58:22.153642: Epoch time: 40.82 s 
2025-01-16 15:58:22.728788:  
2025-01-16 15:58:22.728788: Epoch 140 
2025-01-16 15:58:22.734344: Current learning rate: 0.00478 
2025-01-16 15:59:03.536201: train_loss -0.8577 
2025-01-16 15:59:03.537705: val_loss -0.5069 
2025-01-16 15:59:03.542720: Pseudo dice [np.float32(0.7959), np.float32(0.361)] 
2025-01-16 15:59:03.546229: Epoch time: 40.81 s 
2025-01-16 15:59:04.112349:  
2025-01-16 15:59:04.112349: Epoch 141 
2025-01-16 15:59:04.117419: Current learning rate: 0.00474 
2025-01-16 15:59:44.950425: train_loss -0.875 
2025-01-16 15:59:44.950425: val_loss -0.5825 
2025-01-16 15:59:44.955437: Pseudo dice [np.float32(0.7906), np.float32(0.5682)] 
2025-01-16 15:59:44.958945: Epoch time: 40.84 s 
2025-01-16 15:59:45.544236:  
2025-01-16 15:59:45.544739: Epoch 142 
2025-01-16 15:59:45.549752: Current learning rate: 0.0047 
2025-01-16 16:00:26.357409: train_loss -0.8686 
2025-01-16 16:00:26.358408: val_loss -0.5129 
2025-01-16 16:00:26.363954: Pseudo dice [np.float32(0.7794), np.float32(0.4063)] 
2025-01-16 16:00:26.366491: Epoch time: 40.81 s 
2025-01-16 16:00:26.954843:  
2025-01-16 16:00:26.955347: Epoch 143 
2025-01-16 16:00:26.960359: Current learning rate: 0.00466 
2025-01-16 16:01:07.779852: train_loss -0.8575 
2025-01-16 16:01:07.780373: val_loss -0.5026 
2025-01-16 16:01:07.786021: Pseudo dice [np.float32(0.7714), np.float32(0.4833)] 
2025-01-16 16:01:07.788041: Epoch time: 40.83 s 
2025-01-16 16:01:08.359925:  
2025-01-16 16:01:08.360929: Epoch 144 
2025-01-16 16:01:08.365480: Current learning rate: 0.00462 
2025-01-16 16:01:49.187485: train_loss -0.8613 
2025-01-16 16:01:49.187485: val_loss -0.5485 
2025-01-16 16:01:49.194031: Pseudo dice [np.float32(0.8064), np.float32(0.5775)] 
2025-01-16 16:01:49.197041: Epoch time: 40.83 s 
2025-01-16 16:01:49.929177:  
2025-01-16 16:01:49.930181: Epoch 145 
2025-01-16 16:01:49.934733: Current learning rate: 0.00458 
2025-01-16 16:02:30.755325: train_loss -0.8675 
2025-01-16 16:02:30.755836: val_loss -0.4965 
2025-01-16 16:02:30.760889: Pseudo dice [np.float32(0.7849), np.float32(0.4494)] 
2025-01-16 16:02:30.764419: Epoch time: 40.83 s 
2025-01-16 16:02:31.342898:  
2025-01-16 16:02:31.342898: Epoch 146 
2025-01-16 16:02:31.346944: Current learning rate: 0.00454 
2025-01-16 16:03:12.193951: train_loss -0.8724 
2025-01-16 16:03:12.194454: val_loss -0.5265 
2025-01-16 16:03:12.200545: Pseudo dice [np.float32(0.7889), np.float32(0.5208)] 
2025-01-16 16:03:12.203050: Epoch time: 40.85 s 
2025-01-16 16:03:12.773376:  
2025-01-16 16:03:12.773376: Epoch 147 
2025-01-16 16:03:12.779393: Current learning rate: 0.0045 
2025-01-16 16:03:53.611356: train_loss -0.8596 
2025-01-16 16:03:53.611860: val_loss -0.5576 
2025-01-16 16:03:53.616873: Pseudo dice [np.float32(0.8026), np.float32(0.486)] 
2025-01-16 16:03:53.619379: Epoch time: 40.84 s 
2025-01-16 16:03:54.197691:  
2025-01-16 16:03:54.197691: Epoch 148 
2025-01-16 16:03:54.203279: Current learning rate: 0.00446 
2025-01-16 16:04:35.033872: train_loss -0.8584 
2025-01-16 16:04:35.034942: val_loss -0.5275 
2025-01-16 16:04:35.040109: Pseudo dice [np.float32(0.779), np.float32(0.438)] 
2025-01-16 16:04:35.043642: Epoch time: 40.84 s 
2025-01-16 16:04:35.611406:  
2025-01-16 16:04:35.611406: Epoch 149 
2025-01-16 16:04:35.616446: Current learning rate: 0.00442 
2025-01-16 16:05:16.437530: train_loss -0.853 
2025-01-16 16:05:16.438035: val_loss -0.5386 
2025-01-16 16:05:16.443676: Pseudo dice [np.float32(0.7829), np.float32(0.4069)] 
2025-01-16 16:05:16.446701: Epoch time: 40.83 s 
2025-01-16 16:05:17.235830:  
2025-01-16 16:05:17.235830: Epoch 150 
2025-01-16 16:05:17.242425: Current learning rate: 0.00438 
2025-01-16 16:05:58.038998: train_loss -0.8505 
2025-01-16 16:05:58.038998: val_loss -0.5206 
2025-01-16 16:05:58.044014: Pseudo dice [np.float32(0.7584), np.float32(0.4495)] 
2025-01-16 16:05:58.047524: Epoch time: 40.8 s 
2025-01-16 16:05:58.620689:  
2025-01-16 16:05:58.620689: Epoch 151 
2025-01-16 16:05:58.625769: Current learning rate: 0.00434 
2025-01-16 16:06:39.417461: train_loss -0.8597 
2025-01-16 16:06:39.418460: val_loss -0.5581 
2025-01-16 16:06:39.423978: Pseudo dice [np.float32(0.7982), np.float32(0.4621)] 
2025-01-16 16:06:39.427487: Epoch time: 40.8 s 
2025-01-16 16:06:39.996525:  
2025-01-16 16:06:39.997027: Epoch 152 
2025-01-16 16:06:40.002042: Current learning rate: 0.0043 
2025-01-16 16:07:20.811349: train_loss -0.8548 
2025-01-16 16:07:20.812350: val_loss -0.4689 
2025-01-16 16:07:20.818401: Pseudo dice [np.float32(0.765), np.float32(0.3189)] 
2025-01-16 16:07:20.821452: Epoch time: 40.82 s 
2025-01-16 16:07:21.558410:  
2025-01-16 16:07:21.558410: Epoch 153 
2025-01-16 16:07:21.564509: Current learning rate: 0.00427 
2025-01-16 16:08:02.384326: train_loss -0.8536 
2025-01-16 16:08:02.386359: val_loss -0.5388 
2025-01-16 16:08:02.391374: Pseudo dice [np.float32(0.8068), np.float32(0.4713)] 
2025-01-16 16:08:02.394883: Epoch time: 40.83 s 
2025-01-16 16:08:02.972616:  
2025-01-16 16:08:02.972616: Epoch 154 
2025-01-16 16:08:02.977630: Current learning rate: 0.00423 
2025-01-16 16:08:43.802625: train_loss -0.8638 
2025-01-16 16:08:43.802625: val_loss -0.5674 
2025-01-16 16:08:43.807778: Pseudo dice [np.float32(0.7884), np.float32(0.5148)] 
2025-01-16 16:08:43.810826: Epoch time: 40.83 s 
2025-01-16 16:08:44.398903:  
2025-01-16 16:08:44.398903: Epoch 155 
2025-01-16 16:08:44.403977: Current learning rate: 0.00419 
2025-01-16 16:09:25.229761: train_loss -0.865 
2025-01-16 16:09:25.230273: val_loss -0.5417 
2025-01-16 16:09:25.235424: Pseudo dice [np.float32(0.8023), np.float32(0.4336)] 
2025-01-16 16:09:25.239467: Epoch time: 40.83 s 
2025-01-16 16:09:25.834054:  
2025-01-16 16:09:25.835058: Epoch 156 
2025-01-16 16:09:25.839661: Current learning rate: 0.00415 
2025-01-16 16:10:06.669746: train_loss -0.8782 
2025-01-16 16:10:06.670808: val_loss -0.5485 
2025-01-16 16:10:06.676420: Pseudo dice [np.float32(0.7967), np.float32(0.4938)] 
2025-01-16 16:10:06.679548: Epoch time: 40.84 s 
2025-01-16 16:10:07.255358:  
2025-01-16 16:10:07.256359: Epoch 157 
2025-01-16 16:10:07.261875: Current learning rate: 0.00411 
2025-01-16 16:10:48.097769: train_loss -0.8608 
2025-01-16 16:10:48.098274: val_loss -0.5596 
2025-01-16 16:10:48.104329: Pseudo dice [np.float32(0.7881), np.float32(0.4641)] 
2025-01-16 16:10:48.106455: Epoch time: 40.84 s 
2025-01-16 16:10:48.697886:  
2025-01-16 16:10:48.697886: Epoch 158 
2025-01-16 16:10:48.702899: Current learning rate: 0.00407 
2025-01-16 16:11:29.511744: train_loss -0.8748 
2025-01-16 16:11:29.512248: val_loss -0.5155 
2025-01-16 16:11:29.517778: Pseudo dice [np.float32(0.7847), np.float32(0.4222)] 
2025-01-16 16:11:29.520324: Epoch time: 40.82 s 
2025-01-16 16:11:30.113332:  
2025-01-16 16:11:30.113332: Epoch 159 
2025-01-16 16:11:30.118364: Current learning rate: 0.00403 
2025-01-16 16:12:10.937228: train_loss -0.8717 
2025-01-16 16:12:10.937731: val_loss -0.5472 
2025-01-16 16:12:10.943862: Pseudo dice [np.float32(0.7835), np.float32(0.4599)] 
2025-01-16 16:12:10.947872: Epoch time: 40.82 s 
2025-01-16 16:12:11.678850:  
2025-01-16 16:12:11.679847: Epoch 160 
2025-01-16 16:12:11.684964: Current learning rate: 0.00399 
2025-01-16 16:12:52.518664: train_loss -0.8908 
2025-01-16 16:12:52.519669: val_loss -0.5767 
2025-01-16 16:12:52.524210: Pseudo dice [np.float32(0.7861), np.float32(0.5383)] 
2025-01-16 16:12:52.528269: Epoch time: 40.84 s 
2025-01-16 16:12:53.123436:  
2025-01-16 16:12:53.123436: Epoch 161 
2025-01-16 16:12:53.128992: Current learning rate: 0.00395 
2025-01-16 16:13:33.929292: train_loss -0.8721 
2025-01-16 16:13:33.929292: val_loss -0.5018 
2025-01-16 16:13:33.935447: Pseudo dice [np.float32(0.8011), np.float32(0.5733)] 
2025-01-16 16:13:33.938316: Epoch time: 40.81 s 
2025-01-16 16:13:34.527419:  
2025-01-16 16:13:34.528418: Epoch 162 
2025-01-16 16:13:34.533258: Current learning rate: 0.00391 
2025-01-16 16:14:15.394212: train_loss -0.8622 
2025-01-16 16:14:15.394212: val_loss -0.5508 
2025-01-16 16:14:15.399267: Pseudo dice [np.float32(0.7872), np.float32(0.6174)] 
2025-01-16 16:14:15.403278: Epoch time: 40.87 s 
2025-01-16 16:14:15.982719:  
2025-01-16 16:14:15.983717: Epoch 163 
2025-01-16 16:14:15.988295: Current learning rate: 0.00387 
2025-01-16 16:14:56.728319: train_loss -0.884 
2025-01-16 16:14:56.728822: val_loss -0.5346 
2025-01-16 16:14:56.733834: Pseudo dice [np.float32(0.7763), np.float32(0.6776)] 
2025-01-16 16:14:56.736340: Epoch time: 40.75 s 
2025-01-16 16:14:56.739849: Yayy! New best EMA pseudo Dice: 0.6489999890327454 
2025-01-16 16:14:57.534213:  
2025-01-16 16:14:57.534213: Epoch 164 
2025-01-16 16:14:57.539382: Current learning rate: 0.00383 
2025-01-16 16:15:38.266725: train_loss -0.8851 
2025-01-16 16:15:38.267731: val_loss -0.5201 
2025-01-16 16:15:38.272776: Pseudo dice [np.float32(0.7915), np.float32(0.3444)] 
2025-01-16 16:15:38.275829: Epoch time: 40.73 s 
2025-01-16 16:15:38.842216:  
2025-01-16 16:15:38.842216: Epoch 165 
2025-01-16 16:15:38.848281: Current learning rate: 0.00379 
2025-01-16 16:16:19.577579: train_loss -0.8616 
2025-01-16 16:16:19.578579: val_loss -0.5141 
2025-01-16 16:16:19.584098: Pseudo dice [np.float32(0.7948), np.float32(0.3953)] 
2025-01-16 16:16:19.586603: Epoch time: 40.74 s 
2025-01-16 16:16:20.164414:  
2025-01-16 16:16:20.164414: Epoch 166 
2025-01-16 16:16:20.169454: Current learning rate: 0.00375 
2025-01-16 16:17:00.893446: train_loss -0.8662 
2025-01-16 16:17:00.894949: val_loss -0.5309 
2025-01-16 16:17:00.900966: Pseudo dice [np.float32(0.7845), np.float32(0.5072)] 
2025-01-16 16:17:00.904472: Epoch time: 40.73 s 
2025-01-16 16:17:01.481385:  
2025-01-16 16:17:01.481887: Epoch 167 
2025-01-16 16:17:01.486900: Current learning rate: 0.00371 
2025-01-16 16:17:42.228918: train_loss -0.8895 
2025-01-16 16:17:42.229922: val_loss -0.599 
2025-01-16 16:17:42.234979: Pseudo dice [np.float32(0.8012), np.float32(0.649)] 
2025-01-16 16:17:42.238077: Epoch time: 40.75 s 
2025-01-16 16:17:42.808238:  
2025-01-16 16:17:42.809243: Epoch 168 
2025-01-16 16:17:42.813838: Current learning rate: 0.00367 
2025-01-16 16:18:23.535319: train_loss -0.8813 
2025-01-16 16:18:23.535319: val_loss -0.4937 
2025-01-16 16:18:23.541339: Pseudo dice [np.float32(0.7785), np.float32(0.395)] 
2025-01-16 16:18:23.543846: Epoch time: 40.73 s 
2025-01-16 16:18:24.286293:  
2025-01-16 16:18:24.286293: Epoch 169 
2025-01-16 16:18:24.291307: Current learning rate: 0.00363 
2025-01-16 16:19:05.030214: train_loss -0.8781 
2025-01-16 16:19:05.031783: val_loss -0.5152 
2025-01-16 16:19:05.036829: Pseudo dice [np.float32(0.7928), np.float32(0.4326)] 
2025-01-16 16:19:05.039855: Epoch time: 40.75 s 
2025-01-16 16:19:05.611443:  
2025-01-16 16:19:05.611443: Epoch 170 
2025-01-16 16:19:05.616457: Current learning rate: 0.00359 
2025-01-16 16:19:46.357862: train_loss -0.8857 
2025-01-16 16:19:46.358366: val_loss -0.5515 
2025-01-16 16:19:46.363945: Pseudo dice [np.float32(0.7691), np.float32(0.4289)] 
2025-01-16 16:19:46.366491: Epoch time: 40.75 s 
2025-01-16 16:19:46.941521:  
2025-01-16 16:19:46.942527: Epoch 171 
2025-01-16 16:19:46.947070: Current learning rate: 0.00355 
2025-01-16 16:20:27.671976: train_loss -0.8704 
2025-01-16 16:20:27.672979: val_loss -0.5231 
2025-01-16 16:20:27.678019: Pseudo dice [np.float32(0.8034), np.float32(0.3929)] 
2025-01-16 16:20:27.682028: Epoch time: 40.73 s 
2025-01-16 16:20:28.254398:  
2025-01-16 16:20:28.254903: Epoch 172 
2025-01-16 16:20:28.258413: Current learning rate: 0.00351 
2025-01-16 16:21:08.991426: train_loss -0.8721 
2025-01-16 16:21:08.991426: val_loss -0.5404 
2025-01-16 16:21:08.997943: Pseudo dice [np.float32(0.7943), np.float32(0.4419)] 
2025-01-16 16:21:09.001453: Epoch time: 40.74 s 
2025-01-16 16:21:09.582105:  
2025-01-16 16:21:09.582609: Epoch 173 
2025-01-16 16:21:09.587621: Current learning rate: 0.00346 
2025-01-16 16:21:50.325857: train_loss -0.8745 
2025-01-16 16:21:50.326369: val_loss -0.545 
2025-01-16 16:21:50.331437: Pseudo dice [np.float32(0.8035), np.float32(0.4769)] 
2025-01-16 16:21:50.333965: Epoch time: 40.74 s 
2025-01-16 16:21:50.906651:  
2025-01-16 16:21:50.907651: Epoch 174 
2025-01-16 16:21:50.912198: Current learning rate: 0.00342 
2025-01-16 16:22:31.636569: train_loss -0.8855 
2025-01-16 16:22:31.637071: val_loss -0.55 
2025-01-16 16:22:31.642150: Pseudo dice [np.float32(0.7914), np.float32(0.4436)] 
2025-01-16 16:22:31.645262: Epoch time: 40.73 s 
2025-01-16 16:22:32.222172:  
2025-01-16 16:22:32.223176: Epoch 175 
2025-01-16 16:22:32.227728: Current learning rate: 0.00338 
2025-01-16 16:23:12.951879: train_loss -0.894 
2025-01-16 16:23:12.952882: val_loss -0.5546 
2025-01-16 16:23:12.959015: Pseudo dice [np.float32(0.7902), np.float32(0.6246)] 
2025-01-16 16:23:12.962054: Epoch time: 40.73 s 
2025-01-16 16:23:13.535315:  
2025-01-16 16:23:13.535817: Epoch 176 
2025-01-16 16:23:13.540830: Current learning rate: 0.00334 
2025-01-16 16:23:54.240954: train_loss -0.8794 
2025-01-16 16:23:54.241460: val_loss -0.5368 
2025-01-16 16:23:54.247025: Pseudo dice [np.float32(0.7911), np.float32(0.5734)] 
2025-01-16 16:23:54.249561: Epoch time: 40.71 s 
2025-01-16 16:23:54.973431:  
2025-01-16 16:23:54.973939: Epoch 177 
2025-01-16 16:23:54.979030: Current learning rate: 0.0033 
2025-01-16 16:24:35.679094: train_loss -0.8856 
2025-01-16 16:24:35.679094: val_loss -0.5703 
2025-01-16 16:24:35.684780: Pseudo dice [np.float32(0.7982), np.float32(0.5471)] 
2025-01-16 16:24:35.688319: Epoch time: 40.71 s 
2025-01-16 16:24:36.261729:  
2025-01-16 16:24:36.262236: Epoch 178 
2025-01-16 16:24:36.266271: Current learning rate: 0.00326 
2025-01-16 16:25:16.998662: train_loss -0.8785 
2025-01-16 16:25:16.998662: val_loss -0.5424 
2025-01-16 16:25:17.005231: Pseudo dice [np.float32(0.7848), np.float32(0.4217)] 
2025-01-16 16:25:17.007744: Epoch time: 40.74 s 
2025-01-16 16:25:17.581409:  
2025-01-16 16:25:17.581409: Epoch 179 
2025-01-16 16:25:17.585919: Current learning rate: 0.00322 
2025-01-16 16:25:58.308705: train_loss -0.8655 
2025-01-16 16:25:58.309214: val_loss -0.5541 
2025-01-16 16:25:58.314801: Pseudo dice [np.float32(0.79), np.float32(0.5776)] 
2025-01-16 16:25:58.317334: Epoch time: 40.73 s 
2025-01-16 16:25:58.899269:  
2025-01-16 16:25:58.900269: Epoch 180 
2025-01-16 16:25:58.905882: Current learning rate: 0.00318 
2025-01-16 16:26:39.629824: train_loss -0.8888 
2025-01-16 16:26:39.630327: val_loss -0.5293 
2025-01-16 16:26:39.635421: Pseudo dice [np.float32(0.7884), np.float32(0.4204)] 
2025-01-16 16:26:39.638482: Epoch time: 40.73 s 
2025-01-16 16:26:40.215735:  
2025-01-16 16:26:40.216735: Epoch 181 
2025-01-16 16:26:40.221753: Current learning rate: 0.00314 
2025-01-16 16:27:20.942231: train_loss -0.882 
2025-01-16 16:27:20.943235: val_loss -0.5185 
2025-01-16 16:27:20.948252: Pseudo dice [np.float32(0.787), np.float32(0.404)] 
2025-01-16 16:27:20.950761: Epoch time: 40.73 s 
2025-01-16 16:27:21.527135:  
2025-01-16 16:27:21.528138: Epoch 182 
2025-01-16 16:27:21.533169: Current learning rate: 0.0031 
2025-01-16 16:28:02.252778: train_loss -0.882 
2025-01-16 16:28:02.252778: val_loss -0.6115 
2025-01-16 16:28:02.259395: Pseudo dice [np.float32(0.7919), np.float32(0.5754)] 
2025-01-16 16:28:02.262445: Epoch time: 40.73 s 
2025-01-16 16:28:02.842502:  
2025-01-16 16:28:02.843507: Epoch 183 
2025-01-16 16:28:02.848072: Current learning rate: 0.00306 
2025-01-16 16:28:43.571702: train_loss -0.8813 
2025-01-16 16:28:43.572205: val_loss -0.5532 
2025-01-16 16:28:43.577249: Pseudo dice [np.float32(0.8157), np.float32(0.5762)] 
2025-01-16 16:28:43.579755: Epoch time: 40.73 s 
2025-01-16 16:28:44.156178:  
2025-01-16 16:28:44.157177: Epoch 184 
2025-01-16 16:28:44.162236: Current learning rate: 0.00302 
2025-01-16 16:29:24.922373: train_loss -0.8903 
2025-01-16 16:29:24.922373: val_loss -0.5107 
2025-01-16 16:29:24.927950: Pseudo dice [np.float32(0.7879), np.float32(0.3175)] 
2025-01-16 16:29:24.931503: Epoch time: 40.77 s 
2025-01-16 16:29:25.508535:  
2025-01-16 16:29:25.509037: Epoch 185 
2025-01-16 16:29:25.514136: Current learning rate: 0.00297 
2025-01-16 16:30:06.223638: train_loss -0.8815 
2025-01-16 16:30:06.223638: val_loss -0.5276 
2025-01-16 16:30:06.228679: Pseudo dice [np.float32(0.7802), np.float32(0.423)] 
2025-01-16 16:30:06.231290: Epoch time: 40.72 s 
2025-01-16 16:30:06.816230:  
2025-01-16 16:30:06.816230: Epoch 186 
2025-01-16 16:30:06.822336: Current learning rate: 0.00293 
2025-01-16 16:30:47.529185: train_loss -0.8867 
2025-01-16 16:30:47.529691: val_loss -0.5334 
2025-01-16 16:30:47.534746: Pseudo dice [np.float32(0.794), np.float32(0.5157)] 
2025-01-16 16:30:47.537293: Epoch time: 40.71 s 
2025-01-16 16:30:48.115291:  
2025-01-16 16:30:48.115291: Epoch 187 
2025-01-16 16:30:48.120840: Current learning rate: 0.00289 
2025-01-16 16:31:28.817919: train_loss -0.8851 
2025-01-16 16:31:28.818429: val_loss -0.5396 
2025-01-16 16:31:28.823484: Pseudo dice [np.float32(0.7899), np.float32(0.4605)] 
2025-01-16 16:31:28.827009: Epoch time: 40.7 s 
2025-01-16 16:31:29.404348:  
2025-01-16 16:31:29.405352: Epoch 188 
2025-01-16 16:31:29.409997: Current learning rate: 0.00285 
2025-01-16 16:32:10.124484: train_loss -0.8894 
2025-01-16 16:32:10.124987: val_loss -0.5683 
2025-01-16 16:32:10.132065: Pseudo dice [np.float32(0.7979), np.float32(0.5603)] 
2025-01-16 16:32:10.135083: Epoch time: 40.72 s 
2025-01-16 16:32:10.709554:  
2025-01-16 16:32:10.710557: Epoch 189 
2025-01-16 16:32:10.715155: Current learning rate: 0.00281 
2025-01-16 16:32:51.410836: train_loss -0.88 
2025-01-16 16:32:51.411341: val_loss -0.5225 
2025-01-16 16:32:51.416387: Pseudo dice [np.float32(0.7746), np.float32(0.4861)] 
2025-01-16 16:32:51.418919: Epoch time: 40.7 s 
2025-01-16 16:32:52.001779:  
2025-01-16 16:32:52.002782: Epoch 190 
2025-01-16 16:32:52.007349: Current learning rate: 0.00277 
2025-01-16 16:33:32.721269: train_loss -0.8971 
2025-01-16 16:33:32.722269: val_loss -0.5403 
2025-01-16 16:33:32.726282: Pseudo dice [np.float32(0.7796), np.float32(0.5453)] 
2025-01-16 16:33:32.730294: Epoch time: 40.72 s 
2025-01-16 16:33:33.312417:  
2025-01-16 16:33:33.312925: Epoch 191 
2025-01-16 16:33:33.317503: Current learning rate: 0.00273 
2025-01-16 16:34:14.030555: train_loss -0.889 
2025-01-16 16:34:14.031555: val_loss -0.5036 
2025-01-16 16:34:14.038073: Pseudo dice [np.float32(0.7755), np.float32(0.5087)] 
2025-01-16 16:34:14.040580: Epoch time: 40.72 s 
2025-01-16 16:34:14.774109:  
2025-01-16 16:34:14.774109: Epoch 192 
2025-01-16 16:34:14.779648: Current learning rate: 0.00268 
2025-01-16 16:34:55.491809: train_loss -0.8887 
2025-01-16 16:34:55.492807: val_loss -0.5392 
2025-01-16 16:34:55.498324: Pseudo dice [np.float32(0.7798), np.float32(0.4428)] 
2025-01-16 16:34:55.500831: Epoch time: 40.72 s 
2025-01-16 16:34:56.082094:  
2025-01-16 16:34:56.082094: Epoch 193 
2025-01-16 16:34:56.087160: Current learning rate: 0.00264 
2025-01-16 16:35:36.788926: train_loss -0.8948 
2025-01-16 16:35:36.788926: val_loss -0.5724 
2025-01-16 16:35:36.793942: Pseudo dice [np.float32(0.7935), np.float32(0.5923)] 
2025-01-16 16:35:36.797954: Epoch time: 40.71 s 
2025-01-16 16:35:37.385083:  
2025-01-16 16:35:37.385083: Epoch 194 
2025-01-16 16:35:37.390906: Current learning rate: 0.0026 
2025-01-16 16:36:18.114158: train_loss -0.8977 
2025-01-16 16:36:18.114158: val_loss -0.5431 
2025-01-16 16:36:18.119775: Pseudo dice [np.float32(0.7961), np.float32(0.3836)] 
2025-01-16 16:36:18.122805: Epoch time: 40.73 s 
2025-01-16 16:36:18.709177:  
2025-01-16 16:36:18.709177: Epoch 195 
2025-01-16 16:36:18.714210: Current learning rate: 0.00256 
2025-01-16 16:36:59.413574: train_loss -0.8927 
2025-01-16 16:36:59.414083: val_loss -0.5684 
2025-01-16 16:36:59.417610: Pseudo dice [np.float32(0.8142), np.float32(0.4696)] 
2025-01-16 16:36:59.420634: Epoch time: 40.71 s 
2025-01-16 16:37:00.008429:  
2025-01-16 16:37:00.008429: Epoch 196 
2025-01-16 16:37:00.013504: Current learning rate: 0.00252 
2025-01-16 16:37:40.737146: train_loss -0.8881 
2025-01-16 16:37:40.737648: val_loss -0.5407 
2025-01-16 16:37:40.742661: Pseudo dice [np.float32(0.8076), np.float32(0.4993)] 
2025-01-16 16:37:40.745167: Epoch time: 40.73 s 
2025-01-16 16:37:41.332942:  
2025-01-16 16:37:41.332942: Epoch 197 
2025-01-16 16:37:41.338477: Current learning rate: 0.00248 
2025-01-16 16:38:22.061741: train_loss -0.9036 
2025-01-16 16:38:22.061741: val_loss -0.553 
2025-01-16 16:38:22.066867: Pseudo dice [np.float32(0.7894), np.float32(0.4704)] 
2025-01-16 16:38:22.069404: Epoch time: 40.73 s 
2025-01-16 16:38:22.652639:  
2025-01-16 16:38:22.652639: Epoch 198 
2025-01-16 16:38:22.656715: Current learning rate: 0.00243 
2025-01-16 16:39:03.356512: train_loss -0.8946 
2025-01-16 16:39:03.357015: val_loss -0.5254 
2025-01-16 16:39:03.363034: Pseudo dice [np.float32(0.785), np.float32(0.4724)] 
2025-01-16 16:39:03.366539: Epoch time: 40.7 s 
2025-01-16 16:39:03.953811:  
2025-01-16 16:39:03.953811: Epoch 199 
2025-01-16 16:39:03.958841: Current learning rate: 0.00239 
2025-01-16 16:39:44.671908: train_loss -0.8916 
2025-01-16 16:39:44.672413: val_loss -0.5586 
2025-01-16 16:39:44.677447: Pseudo dice [np.float32(0.7793), np.float32(0.4744)] 
2025-01-16 16:39:44.679454: Epoch time: 40.72 s 
2025-01-16 16:39:45.684675:  
2025-01-16 16:39:45.685186: Epoch 200 
2025-01-16 16:39:45.690233: Current learning rate: 0.00235 
2025-01-16 16:40:26.426505: train_loss -0.8928 
2025-01-16 16:40:26.427027: val_loss -0.5049 
2025-01-16 16:40:26.432128: Pseudo dice [np.float32(0.7885), np.float32(0.3552)] 
2025-01-16 16:40:26.434144: Epoch time: 40.74 s 
2025-01-16 16:40:27.015952:  
2025-01-16 16:40:27.015952: Epoch 201 
2025-01-16 16:40:27.021499: Current learning rate: 0.00231 
2025-01-16 16:41:07.749920: train_loss -0.8865 
2025-01-16 16:41:07.749920: val_loss -0.5669 
2025-01-16 16:41:07.756995: Pseudo dice [np.float32(0.7855), np.float32(0.6874)] 
2025-01-16 16:41:07.759591: Epoch time: 40.73 s 
2025-01-16 16:41:08.344882:  
2025-01-16 16:41:08.344882: Epoch 202 
2025-01-16 16:41:08.349945: Current learning rate: 0.00226 
2025-01-16 16:41:49.087729: train_loss -0.893 
2025-01-16 16:41:49.088734: val_loss -0.586 
2025-01-16 16:41:49.094348: Pseudo dice [np.float32(0.8146), np.float32(0.5171)] 
2025-01-16 16:41:49.096895: Epoch time: 40.74 s 
2025-01-16 16:41:49.687663:  
2025-01-16 16:41:49.688662: Epoch 203 
2025-01-16 16:41:49.693234: Current learning rate: 0.00222 
2025-01-16 16:42:30.414872: train_loss -0.8937 
2025-01-16 16:42:30.416376: val_loss -0.5133 
2025-01-16 16:42:30.421925: Pseudo dice [np.float32(0.7758), np.float32(0.4019)] 
2025-01-16 16:42:30.424954: Epoch time: 40.73 s 
2025-01-16 16:42:31.012226:  
2025-01-16 16:42:31.013231: Epoch 204 
2025-01-16 16:42:31.017789: Current learning rate: 0.00218 
2025-01-16 16:43:11.727551: train_loss -0.8983 
2025-01-16 16:43:11.728555: val_loss -0.5435 
2025-01-16 16:43:11.733729: Pseudo dice [np.float32(0.7882), np.float32(0.6037)] 
2025-01-16 16:43:11.737319: Epoch time: 40.72 s 
2025-01-16 16:43:12.333907:  
2025-01-16 16:43:12.333907: Epoch 205 
2025-01-16 16:43:12.338975: Current learning rate: 0.00214 
2025-01-16 16:43:53.048772: train_loss -0.9037 
2025-01-16 16:43:53.050373: val_loss -0.5759 
2025-01-16 16:43:53.055480: Pseudo dice [np.float32(0.8034), np.float32(0.645)] 
2025-01-16 16:43:53.058494: Epoch time: 40.72 s 
2025-01-16 16:43:53.061000: Yayy! New best EMA pseudo Dice: 0.6517999768257141 
2025-01-16 16:43:53.858387:  
2025-01-16 16:43:53.858387: Epoch 206 
2025-01-16 16:43:53.863935: Current learning rate: 0.00209 
2025-01-16 16:44:34.617807: train_loss -0.9092 
2025-01-16 16:44:34.618317: val_loss -0.5597 
2025-01-16 16:44:34.622880: Pseudo dice [np.float32(0.8026), np.float32(0.4231)] 
2025-01-16 16:44:34.626407: Epoch time: 40.76 s 
2025-01-16 16:44:35.178272:  
2025-01-16 16:44:35.178272: Epoch 207 
2025-01-16 16:44:35.183822: Current learning rate: 0.00205 
2025-01-16 16:45:15.909647: train_loss -0.9028 
2025-01-16 16:45:15.910650: val_loss -0.5127 
2025-01-16 16:45:15.914658: Pseudo dice [np.float32(0.7491), np.float32(0.5128)] 
2025-01-16 16:45:15.917164: Epoch time: 40.73 s 
2025-01-16 16:45:16.473168:  
2025-01-16 16:45:16.473168: Epoch 208 
2025-01-16 16:45:16.478246: Current learning rate: 0.00201 
2025-01-16 16:45:57.188291: train_loss -0.9039 
2025-01-16 16:45:57.188794: val_loss -0.5778 
2025-01-16 16:45:57.193843: Pseudo dice [np.float32(0.8003), np.float32(0.5601)] 
2025-01-16 16:45:57.196889: Epoch time: 40.72 s 
2025-01-16 16:45:57.909639:  
2025-01-16 16:45:57.910640: Epoch 209 
2025-01-16 16:45:57.915200: Current learning rate: 0.00196 
2025-01-16 16:46:38.627433: train_loss -0.8984 
2025-01-16 16:46:38.627946: val_loss -0.5248 
2025-01-16 16:46:38.633076: Pseudo dice [np.float32(0.7789), np.float32(0.4367)] 
2025-01-16 16:46:38.635582: Epoch time: 40.72 s 
2025-01-16 16:46:39.193502:  
2025-01-16 16:46:39.194005: Epoch 210 
2025-01-16 16:46:39.198537: Current learning rate: 0.00192 
2025-01-16 16:47:19.923272: train_loss -0.9082 
2025-01-16 16:47:19.923782: val_loss -0.5676 
2025-01-16 16:47:19.928928: Pseudo dice [np.float32(0.7965), np.float32(0.6223)] 
2025-01-16 16:47:19.931453: Epoch time: 40.73 s 
2025-01-16 16:47:19.934484: Yayy! New best EMA pseudo Dice: 0.6517999768257141 
2025-01-16 16:47:20.726463:  
2025-01-16 16:47:20.726463: Epoch 211 
2025-01-16 16:47:20.729482: Current learning rate: 0.00188 
2025-01-16 16:47:59.680547: train_loss -0.9017 
2025-01-16 16:47:59.681053: val_loss -0.5297 
2025-01-16 16:47:59.686128: Pseudo dice [np.float32(0.781), np.float32(0.5624)] 
2025-01-16 16:47:59.688670: Epoch time: 38.95 s 
2025-01-16 16:47:59.692214: Yayy! New best EMA pseudo Dice: 0.6538000106811523 
2025-01-16 16:48:00.485777:  
2025-01-16 16:48:00.485777: Epoch 212 
2025-01-16 16:48:00.491328: Current learning rate: 0.00184 
2025-01-16 16:48:41.218835: train_loss -0.9055 
2025-01-16 16:48:41.218835: val_loss -0.51 
2025-01-16 16:48:41.224367: Pseudo dice [np.float32(0.7805), np.float32(0.5807)] 
2025-01-16 16:48:41.226873: Epoch time: 40.73 s 
2025-01-16 16:48:41.230391: Yayy! New best EMA pseudo Dice: 0.656499981880188 
2025-01-16 16:48:42.011759:  
2025-01-16 16:48:42.011759: Epoch 213 
2025-01-16 16:48:42.016774: Current learning rate: 0.00179 
2025-01-16 16:49:22.726559: train_loss -0.9041 
2025-01-16 16:49:22.726559: val_loss -0.5572 
2025-01-16 16:49:22.733099: Pseudo dice [np.float32(0.8103), np.float32(0.4636)] 
2025-01-16 16:49:22.736107: Epoch time: 40.72 s 
2025-01-16 16:49:23.289994:  
2025-01-16 16:49:23.289994: Epoch 214 
2025-01-16 16:49:23.295007: Current learning rate: 0.00175 
2025-01-16 16:50:04.015494: train_loss -0.9159 
2025-01-16 16:50:04.016502: val_loss -0.5556 
2025-01-16 16:50:04.021604: Pseudo dice [np.float32(0.8054), np.float32(0.4818)] 
2025-01-16 16:50:04.024634: Epoch time: 40.73 s 
2025-01-16 16:50:04.577324:  
2025-01-16 16:50:04.577324: Epoch 215 
2025-01-16 16:50:04.582884: Current learning rate: 0.0017 
2025-01-16 16:50:45.305396: train_loss -0.9138 
2025-01-16 16:50:45.305898: val_loss -0.5616 
2025-01-16 16:50:45.310931: Pseudo dice [np.float32(0.7806), np.float32(0.5537)] 
2025-01-16 16:50:45.313955: Epoch time: 40.73 s 
2025-01-16 16:50:45.865390:  
2025-01-16 16:50:45.866393: Epoch 216 
2025-01-16 16:50:45.871451: Current learning rate: 0.00166 
2025-01-16 16:51:26.603397: train_loss -0.9164 
2025-01-16 16:51:26.603905: val_loss -0.559 
2025-01-16 16:51:26.608944: Pseudo dice [np.float32(0.7938), np.float32(0.5751)] 
2025-01-16 16:51:26.612467: Epoch time: 40.74 s 
2025-01-16 16:51:26.614987: Yayy! New best EMA pseudo Dice: 0.657800018787384 
2025-01-16 16:51:27.509935:  
2025-01-16 16:51:27.509935: Epoch 217 
2025-01-16 16:51:27.515951: Current learning rate: 0.00162 
2025-01-16 16:52:08.239306: train_loss -0.9032 
2025-01-16 16:52:08.239809: val_loss -0.5629 
2025-01-16 16:52:08.246373: Pseudo dice [np.float32(0.8067), np.float32(0.597)] 
2025-01-16 16:52:08.248893: Epoch time: 40.73 s 
2025-01-16 16:52:08.251919: Yayy! New best EMA pseudo Dice: 0.6621999740600586 
2025-01-16 16:52:09.029348:  
2025-01-16 16:52:09.030351: Epoch 218 
2025-01-16 16:52:09.034426: Current learning rate: 0.00157 
2025-01-16 16:52:49.757898: train_loss -0.9063 
2025-01-16 16:52:49.757898: val_loss -0.5377 
2025-01-16 16:52:49.762910: Pseudo dice [np.float32(0.7879), np.float32(0.4294)] 
2025-01-16 16:52:49.766420: Epoch time: 40.73 s 
2025-01-16 16:52:50.317394:  
2025-01-16 16:52:50.318395: Epoch 219 
2025-01-16 16:52:50.322949: Current learning rate: 0.00153 
2025-01-16 16:53:31.056431: train_loss -0.917 
2025-01-16 16:53:31.056947: val_loss -0.5515 
2025-01-16 16:53:31.062529: Pseudo dice [np.float32(0.7909), np.float32(0.621)] 
2025-01-16 16:53:31.065060: Epoch time: 40.74 s 
2025-01-16 16:53:31.619749:  
2025-01-16 16:53:31.619749: Epoch 220 
2025-01-16 16:53:31.624762: Current learning rate: 0.00148 
2025-01-16 16:54:12.355639: train_loss -0.9057 
2025-01-16 16:54:12.355639: val_loss -0.5281 
2025-01-16 16:54:12.361684: Pseudo dice [np.float32(0.8071), np.float32(0.584)] 
2025-01-16 16:54:12.364706: Epoch time: 40.74 s 
2025-01-16 16:54:12.368348: Yayy! New best EMA pseudo Dice: 0.6650999784469604 
2025-01-16 16:54:13.153425:  
2025-01-16 16:54:13.154425: Epoch 221 
2025-01-16 16:54:13.159940: Current learning rate: 0.00144 
2025-01-16 16:54:53.888972: train_loss -0.9216 
2025-01-16 16:54:53.889488: val_loss -0.5205 
2025-01-16 16:54:53.894626: Pseudo dice [np.float32(0.7852), np.float32(0.435)] 
2025-01-16 16:54:53.897657: Epoch time: 40.74 s 
2025-01-16 16:54:54.457261:  
2025-01-16 16:54:54.457261: Epoch 222 
2025-01-16 16:54:54.461287: Current learning rate: 0.00139 
2025-01-16 16:55:35.200443: train_loss -0.9112 
2025-01-16 16:55:35.200955: val_loss -0.5856 
2025-01-16 16:55:35.206510: Pseudo dice [np.float32(0.8008), np.float32(0.7513)] 
2025-01-16 16:55:35.209098: Epoch time: 40.74 s 
2025-01-16 16:55:35.211628: Yayy! New best EMA pseudo Dice: 0.6712999939918518 
2025-01-16 16:55:35.963469:  
2025-01-16 16:55:35.964468: Epoch 223 
2025-01-16 16:55:35.969985: Current learning rate: 0.00135 
2025-01-16 16:56:16.699480: train_loss -0.9131 
2025-01-16 16:56:16.699480: val_loss -0.5371 
2025-01-16 16:56:16.704608: Pseudo dice [np.float32(0.7972), np.float32(0.3888)] 
2025-01-16 16:56:16.708135: Epoch time: 40.74 s 
2025-01-16 16:56:17.260351:  
2025-01-16 16:56:17.260351: Epoch 224 
2025-01-16 16:56:17.265885: Current learning rate: 0.0013 
2025-01-16 16:56:58.004268: train_loss -0.9086 
2025-01-16 16:56:58.004268: val_loss -0.5586 
2025-01-16 16:56:58.010286: Pseudo dice [np.float32(0.8043), np.float32(0.5258)] 
2025-01-16 16:56:58.013793: Epoch time: 40.74 s 
2025-01-16 16:56:58.717632:  
2025-01-16 16:56:58.717632: Epoch 225 
2025-01-16 16:56:58.723261: Current learning rate: 0.00126 
2025-01-16 16:57:39.441236: train_loss -0.8981 
2025-01-16 16:57:39.441752: val_loss -0.521 
2025-01-16 16:57:39.447305: Pseudo dice [np.float32(0.7797), np.float32(0.4627)] 
2025-01-16 16:57:39.449812: Epoch time: 40.72 s 
2025-01-16 16:57:40.006525:  
2025-01-16 16:57:40.006525: Epoch 226 
2025-01-16 16:57:40.011560: Current learning rate: 0.00121 
2025-01-16 16:58:20.744051: train_loss -0.9085 
2025-01-16 16:58:20.744051: val_loss -0.5398 
2025-01-16 16:58:20.749602: Pseudo dice [np.float32(0.7835), np.float32(0.521)] 
2025-01-16 16:58:20.752652: Epoch time: 40.74 s 
2025-01-16 16:58:21.305068:  
2025-01-16 16:58:21.305068: Epoch 227 
2025-01-16 16:58:21.310110: Current learning rate: 0.00117 
2025-01-16 16:59:02.041571: train_loss -0.9124 
2025-01-16 16:59:02.041571: val_loss -0.5405 
2025-01-16 16:59:02.047707: Pseudo dice [np.float32(0.7898), np.float32(0.5998)] 
2025-01-16 16:59:02.050747: Epoch time: 40.74 s 
2025-01-16 16:59:02.603951:  
2025-01-16 16:59:02.603951: Epoch 228 
2025-01-16 16:59:02.608980: Current learning rate: 0.00112 
2025-01-16 16:59:43.340236: train_loss -0.9078 
2025-01-16 16:59:43.340745: val_loss -0.5137 
2025-01-16 16:59:43.345788: Pseudo dice [np.float32(0.7789), np.float32(0.5084)] 
2025-01-16 16:59:43.348328: Epoch time: 40.74 s 
2025-01-16 16:59:43.904365:  
2025-01-16 16:59:43.904365: Epoch 229 
2025-01-16 16:59:43.909381: Current learning rate: 0.00108 
2025-01-16 17:00:24.632642: train_loss -0.9192 
2025-01-16 17:00:24.633648: val_loss -0.5225 
2025-01-16 17:00:24.638660: Pseudo dice [np.float32(0.7632), np.float32(0.5587)] 
2025-01-16 17:00:24.641166: Epoch time: 40.73 s 
2025-01-16 17:00:25.195527:  
2025-01-16 17:00:25.196530: Epoch 230 
2025-01-16 17:00:25.201076: Current learning rate: 0.00103 
2025-01-16 17:01:05.935383: train_loss -0.9074 
2025-01-16 17:01:05.936387: val_loss -0.5492 
2025-01-16 17:01:05.941461: Pseudo dice [np.float32(0.8028), np.float32(0.6426)] 
2025-01-16 17:01:05.945001: Epoch time: 40.74 s 
2025-01-16 17:01:06.494462:  
2025-01-16 17:01:06.494968: Epoch 231 
2025-01-16 17:01:06.500016: Current learning rate: 0.00098 
2025-01-16 17:01:47.245860: train_loss -0.9118 
2025-01-16 17:01:47.246367: val_loss -0.5384 
2025-01-16 17:01:47.251401: Pseudo dice [np.float32(0.774), np.float32(0.5562)] 
2025-01-16 17:01:47.254922: Epoch time: 40.75 s 
2025-01-16 17:01:47.810026:  
2025-01-16 17:01:47.810529: Epoch 232 
2025-01-16 17:01:47.815047: Current learning rate: 0.00094 
2025-01-16 17:02:28.550062: train_loss -0.9128 
2025-01-16 17:02:28.551066: val_loss -0.5615 
2025-01-16 17:02:28.556132: Pseudo dice [np.float32(0.7943), np.float32(0.4632)] 
2025-01-16 17:02:28.559720: Epoch time: 40.74 s 
2025-01-16 17:02:29.109801:  
2025-01-16 17:02:29.109801: Epoch 233 
2025-01-16 17:02:29.114869: Current learning rate: 0.00089 
2025-01-16 17:03:09.855191: train_loss -0.9148 
2025-01-16 17:03:09.855696: val_loss -0.5489 
2025-01-16 17:03:09.861251: Pseudo dice [np.float32(0.7976), np.float32(0.5311)] 
2025-01-16 17:03:09.863828: Epoch time: 40.75 s 
2025-01-16 17:03:10.565193:  
2025-01-16 17:03:10.566198: Epoch 234 
2025-01-16 17:03:10.570225: Current learning rate: 0.00084 
2025-01-16 17:03:51.282680: train_loss -0.9143 
2025-01-16 17:03:51.283182: val_loss -0.549 
2025-01-16 17:03:51.288235: Pseudo dice [np.float32(0.7846), np.float32(0.5398)] 
2025-01-16 17:03:51.291257: Epoch time: 40.72 s 
2025-01-16 17:03:51.845010:  
2025-01-16 17:03:51.845010: Epoch 235 
2025-01-16 17:03:51.849519: Current learning rate: 0.00079 
2025-01-16 17:04:32.586688: train_loss -0.922 
2025-01-16 17:04:32.587688: val_loss -0.5585 
2025-01-16 17:04:32.593205: Pseudo dice [np.float32(0.8002), np.float32(0.5813)] 
2025-01-16 17:04:32.595711: Epoch time: 40.74 s 
2025-01-16 17:04:33.152413:  
2025-01-16 17:04:33.153412: Epoch 236 
2025-01-16 17:04:33.157971: Current learning rate: 0.00075 
2025-01-16 17:05:13.877599: train_loss -0.9187 
2025-01-16 17:05:13.877599: val_loss -0.5639 
2025-01-16 17:05:13.885135: Pseudo dice [np.float32(0.8006), np.float32(0.5979)] 
2025-01-16 17:05:13.888149: Epoch time: 40.73 s 
2025-01-16 17:05:14.445249:  
2025-01-16 17:05:14.446249: Epoch 237 
2025-01-16 17:05:14.451398: Current learning rate: 0.0007 
2025-01-16 17:05:55.190256: train_loss -0.9177 
2025-01-16 17:05:55.190762: val_loss -0.557 
2025-01-16 17:05:55.196318: Pseudo dice [np.float32(0.7964), np.float32(0.4728)] 
2025-01-16 17:05:55.199351: Epoch time: 40.75 s 
2025-01-16 17:05:55.752132:  
2025-01-16 17:05:55.752132: Epoch 238 
2025-01-16 17:05:55.756674: Current learning rate: 0.00065 
2025-01-16 17:06:36.493255: train_loss -0.9033 
2025-01-16 17:06:36.493758: val_loss -0.5655 
2025-01-16 17:06:36.499351: Pseudo dice [np.float32(0.7896), np.float32(0.5116)] 
2025-01-16 17:06:36.501881: Epoch time: 40.74 s 
2025-01-16 17:06:37.060005:  
2025-01-16 17:06:37.060516: Epoch 239 
2025-01-16 17:06:37.065556: Current learning rate: 0.0006 
2025-01-16 17:07:17.807998: train_loss -0.921 
2025-01-16 17:07:17.807998: val_loss -0.5482 
2025-01-16 17:07:17.814043: Pseudo dice [np.float32(0.8074), np.float32(0.6056)] 
2025-01-16 17:07:17.816549: Epoch time: 40.75 s 
2025-01-16 17:07:18.381099:  
2025-01-16 17:07:18.381602: Epoch 240 
2025-01-16 17:07:18.387165: Current learning rate: 0.00055 
2025-01-16 17:07:59.121307: train_loss -0.9163 
2025-01-16 17:07:59.121815: val_loss -0.5477 
2025-01-16 17:07:59.126858: Pseudo dice [np.float32(0.793), np.float32(0.579)] 
2025-01-16 17:07:59.130393: Epoch time: 40.74 s 
2025-01-16 17:07:59.692004:  
2025-01-16 17:07:59.692507: Epoch 241 
2025-01-16 17:07:59.697519: Current learning rate: 0.0005 
2025-01-16 17:08:40.426484: train_loss -0.915 
2025-01-16 17:08:40.426989: val_loss -0.5656 
2025-01-16 17:08:40.432026: Pseudo dice [np.float32(0.8016), np.float32(0.4619)] 
2025-01-16 17:08:40.435547: Epoch time: 40.74 s 
2025-01-16 17:08:41.150228:  
2025-01-16 17:08:41.150741: Epoch 242 
2025-01-16 17:08:41.155782: Current learning rate: 0.00045 
2025-01-16 17:09:21.883668: train_loss -0.9176 
2025-01-16 17:09:21.884171: val_loss -0.5253 
2025-01-16 17:09:21.889716: Pseudo dice [np.float32(0.7942), np.float32(0.4326)] 
2025-01-16 17:09:21.892757: Epoch time: 40.73 s 
2025-01-16 17:09:22.459836:  
2025-01-16 17:09:22.459836: Epoch 243 
2025-01-16 17:09:22.464391: Current learning rate: 0.0004 
2025-01-16 17:10:03.198954: train_loss -0.9181 
2025-01-16 17:10:03.200973: val_loss -0.5519 
2025-01-16 17:10:03.205985: Pseudo dice [np.float32(0.7952), np.float32(0.5337)] 
2025-01-16 17:10:03.209495: Epoch time: 40.74 s 
2025-01-16 17:10:03.771270:  
2025-01-16 17:10:03.771270: Epoch 244 
2025-01-16 17:10:03.776289: Current learning rate: 0.00035 
2025-01-16 17:10:44.505106: train_loss -0.9223 
2025-01-16 17:10:44.505612: val_loss -0.5542 
2025-01-16 17:10:44.510699: Pseudo dice [np.float32(0.7706), np.float32(0.6057)] 
2025-01-16 17:10:44.513748: Epoch time: 40.73 s 
2025-01-16 17:10:45.076939:  
2025-01-16 17:10:45.077943: Epoch 245 
2025-01-16 17:10:45.082485: Current learning rate: 0.0003 
2025-01-16 17:11:25.805040: train_loss -0.9206 
2025-01-16 17:11:25.805557: val_loss -0.5415 
2025-01-16 17:11:25.810626: Pseudo dice [np.float32(0.7833), np.float32(0.4631)] 
2025-01-16 17:11:25.813168: Epoch time: 40.73 s 
2025-01-16 17:11:26.382514:  
2025-01-16 17:11:26.382514: Epoch 246 
2025-01-16 17:11:26.387544: Current learning rate: 0.00024 
2025-01-16 17:12:07.126976: train_loss -0.9223 
2025-01-16 17:12:07.127479: val_loss -0.5012 
2025-01-16 17:12:07.132538: Pseudo dice [np.float32(0.7792), np.float32(0.5257)] 
2025-01-16 17:12:07.135563: Epoch time: 40.75 s 
2025-01-16 17:12:07.698049:  
2025-01-16 17:12:07.698049: Epoch 247 
2025-01-16 17:12:07.703077: Current learning rate: 0.00019 
2025-01-16 17:12:48.431170: train_loss -0.9183 
2025-01-16 17:12:48.431170: val_loss -0.5284 
2025-01-16 17:12:48.437222: Pseudo dice [np.float32(0.7784), np.float32(0.4919)] 
2025-01-16 17:12:48.439753: Epoch time: 40.73 s 
2025-01-16 17:12:49.005328:  
2025-01-16 17:12:49.005328: Epoch 248 
2025-01-16 17:12:49.010343: Current learning rate: 0.00013 
2025-01-16 17:13:29.752390: train_loss -0.9082 
2025-01-16 17:13:29.752893: val_loss -0.5276 
2025-01-16 17:13:29.757962: Pseudo dice [np.float32(0.7889), np.float32(0.3891)] 
2025-01-16 17:13:29.761005: Epoch time: 40.75 s 
2025-01-16 17:13:30.328457:  
2025-01-16 17:13:30.328457: Epoch 249 
2025-01-16 17:13:30.333989: Current learning rate: 7e-05 
2025-01-16 17:14:11.064959: train_loss -0.9186 
2025-01-16 17:14:11.065464: val_loss -0.5095 
2025-01-16 17:14:11.070516: Pseudo dice [np.float32(0.7842), np.float32(0.5209)] 
2025-01-16 17:14:11.073043: Epoch time: 40.74 s 
2025-01-16 17:14:12.003594: Training done. 
2025-01-16 17:14:12.032595: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-16 17:14:12.044596: The split file contains 5 splits. 
2025-01-16 17:14:12.050596: Desired fold for training: 0 
2025-01-16 17:14:12.054596: This split has 224 training and 57 validation cases. 
2025-01-16 17:14:12.058594: predicting pancreas_021 
2025-01-16 17:14:12.063599: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-16 17:14:14.266782: predicting pancreas_024 
2025-01-16 17:14:14.285015: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-16 17:14:16.180442: predicting pancreas_035 
2025-01-16 17:14:16.196442: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-16 17:14:16.867024: predicting pancreas_040 
2025-01-16 17:14:16.874024: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-01-16 17:14:18.391714: predicting pancreas_042 
2025-01-16 17:14:18.406718: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-01-16 17:14:20.327633: predicting pancreas_056 
2025-01-16 17:14:20.346632: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-16 17:14:21.870804: predicting pancreas_067 
2025-01-16 17:14:21.883311: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-16 17:14:23.806855: predicting pancreas_075 
2025-01-16 17:14:23.824855: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-01-16 17:14:24.624124: predicting pancreas_086 
2025-01-16 17:14:24.634124: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-16 17:14:25.847516: predicting pancreas_089 
2025-01-16 17:14:25.858516: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-16 17:14:27.377204: predicting pancreas_092 
2025-01-16 17:14:27.392712: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-01-16 17:14:30.814530: predicting pancreas_094 
2025-01-16 17:14:30.835530: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-16 17:14:32.365183: predicting pancreas_095 
2025-01-16 17:14:32.378186: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-16 17:14:33.950356: predicting pancreas_098 
2025-01-16 17:14:33.963356: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-16 17:14:38.119067: predicting pancreas_109 
2025-01-16 17:14:38.143066: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-16 17:14:39.716081: predicting pancreas_110 
2025-01-16 17:14:39.732081: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-16 17:14:42.134722: predicting pancreas_114 
2025-01-16 17:14:42.155722: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-16 17:14:43.700600: predicting pancreas_119 
2025-01-16 17:14:43.713599: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-16 17:14:46.089842: predicting pancreas_138 
2025-01-16 17:14:46.104842: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-16 17:14:48.509881: predicting pancreas_145 
2025-01-16 17:14:48.529881: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-16 17:14:50.929567: predicting pancreas_148 
2025-01-16 17:14:50.946567: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-01-16 17:14:52.486120: predicting pancreas_169 
2025-01-16 17:14:52.496375: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-16 17:14:54.021635: predicting pancreas_170 
2025-01-16 17:14:54.034634: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-16 17:14:55.944735: predicting pancreas_172 
2025-01-16 17:14:55.960736: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-16 17:14:57.517114: predicting pancreas_175 
2025-01-16 17:14:57.527114: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-16 17:14:59.061621: predicting pancreas_180 
2025-01-16 17:14:59.074622: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-16 17:15:00.608888: predicting pancreas_191 
2025-01-16 17:15:00.621889: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-16 17:15:01.410587: predicting pancreas_193 
2025-01-16 17:15:01.419587: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-16 17:15:03.332868: predicting pancreas_212 
2025-01-16 17:15:03.347868: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-16 17:15:04.910482: predicting pancreas_215 
2025-01-16 17:15:04.928482: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-16 17:15:06.483880: predicting pancreas_222 
2025-01-16 17:15:06.493880: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-16 17:15:07.170094: predicting pancreas_235 
2025-01-16 17:15:07.178091: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-16 17:15:08.701009: predicting pancreas_241 
2025-01-16 17:15:08.711010: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-16 17:15:10.261070: predicting pancreas_242 
2025-01-16 17:15:10.277071: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-16 17:15:12.203664: predicting pancreas_244 
2025-01-16 17:15:12.221663: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-16 17:15:15.196808: predicting pancreas_246 
2025-01-16 17:15:15.212315: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-16 17:15:18.187689: predicting pancreas_247 
2025-01-16 17:15:18.207201: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-16 17:15:19.100980: predicting pancreas_264 
2025-01-16 17:15:19.110990: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-16 17:15:21.032313: predicting pancreas_265 
2025-01-16 17:15:21.050313: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-16 17:15:22.610115: predicting pancreas_266 
2025-01-16 17:15:22.633116: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-16 17:15:25.012164: predicting pancreas_267 
2025-01-16 17:15:25.030164: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-16 17:15:25.940175: predicting pancreas_275 
2025-01-16 17:15:25.949178: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-16 17:15:27.846890: predicting pancreas_279 
2025-01-16 17:15:27.860889: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-16 17:15:28.552556: predicting pancreas_287 
2025-01-16 17:15:28.561554: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-16 17:15:30.093417: predicting pancreas_301 
2025-01-16 17:15:30.103419: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-16 17:15:31.657058: predicting pancreas_323 
2025-01-16 17:15:31.672058: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-16 17:15:34.065630: predicting pancreas_336 
2025-01-16 17:15:34.085630: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-16 17:15:35.647061: predicting pancreas_344 
2025-01-16 17:15:35.663060: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-16 17:15:37.576035: predicting pancreas_351 
2025-01-16 17:15:37.591035: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-16 17:15:38.489639: predicting pancreas_354 
2025-01-16 17:15:38.501639: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-01-16 17:15:41.561734: predicting pancreas_372 
2025-01-16 17:15:41.586735: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-16 17:15:44.021000: predicting pancreas_377 
2025-01-16 17:15:44.047001: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-01-16 17:15:46.019089: predicting pancreas_387 
2025-01-16 17:15:46.041595: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-01-16 17:15:47.621808: predicting pancreas_391 
2025-01-16 17:15:47.638041: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-16 17:15:50.025933: predicting pancreas_392 
2025-01-16 17:15:50.044933: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-01-16 17:15:51.176050: predicting pancreas_410 
2025-01-16 17:15:51.192051: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-16 17:15:52.288041: predicting pancreas_412 
2025-01-16 17:15:52.299042: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-01-16 17:16:14.668812: Validation complete 
2025-01-16 17:16:14.668812: Mean Validation Dice:  0.5960957135029515 
