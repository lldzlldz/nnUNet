
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-18 18:28:14.277196: do_dummy_2d_data_aug: False 
2025-01-18 18:28:14.282197: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-18 18:28:14.285894: The split file contains 5 splits. 
2025-01-18 18:28:14.287897: Desired fold for training: 0 
2025-01-18 18:28:14.290897: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 12, 'patch_size': [512, 512], 'median_image_size_in_voxels': [512.0, 512.0], 'spacing': [0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 8, 'features_per_stage': [32, 64, 128, 256, 512, 512, 512, 512], 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'strides': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-18 18:28:20.142157: unpacking dataset... 
2025-01-18 18:28:20.334327: unpacking done... 
2025-01-18 18:28:25.219515:  
2025-01-18 18:28:25.220520: Epoch 0 
2025-01-18 18:28:25.224529: Current learning rate: 0.01 
2025-01-18 18:29:00.297691: train_loss 0.0694 
2025-01-18 18:29:00.298691: val_loss 0.0089 
2025-01-18 18:29:00.304232: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-18 18:29:00.306783: Epoch time: 35.08 s 
2025-01-18 18:29:00.310293: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-18 18:29:01.043644:  
2025-01-18 18:29:01.043644: Epoch 1 
2025-01-18 18:29:01.049666: Current learning rate: 0.00996 
2025-01-18 18:29:32.928625: train_loss -0.0257 
2025-01-18 18:29:32.928625: val_loss -0.1139 
2025-01-18 18:29:32.935764: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-18 18:29:32.939824: Epoch time: 31.89 s 
2025-01-18 18:29:33.488025:  
2025-01-18 18:29:33.488025: Epoch 2 
2025-01-18 18:29:33.493037: Current learning rate: 0.00993 
2025-01-18 18:30:05.366125: train_loss -0.2287 
2025-01-18 18:30:05.366125: val_loss -0.2997 
2025-01-18 18:30:05.372699: Pseudo dice [np.float32(0.5766), np.float32(0.0)] 
2025-01-18 18:30:05.376244: Epoch time: 31.88 s 
2025-01-18 18:30:05.379751: Yayy! New best EMA pseudo Dice: 0.02879999950528145 
2025-01-18 18:30:06.209018:  
2025-01-18 18:30:06.209018: Epoch 3 
2025-01-18 18:30:06.214068: Current learning rate: 0.00989 
2025-01-18 18:30:38.076885: train_loss -0.3225 
2025-01-18 18:30:38.077890: val_loss -0.3478 
2025-01-18 18:30:38.083450: Pseudo dice [np.float32(0.6195), np.float32(0.0)] 
2025-01-18 18:30:38.087005: Epoch time: 31.87 s 
2025-01-18 18:30:38.089541: Yayy! New best EMA pseudo Dice: 0.05689999833703041 
2025-01-18 18:30:38.896221:  
2025-01-18 18:30:38.896221: Epoch 4 
2025-01-18 18:30:38.901232: Current learning rate: 0.00986 
2025-01-18 18:31:10.807230: train_loss -0.3867 
2025-01-18 18:31:10.807230: val_loss -0.3913 
2025-01-18 18:31:10.813750: Pseudo dice [np.float32(0.5993), np.float32(0.296)] 
2025-01-18 18:31:10.817262: Epoch time: 31.91 s 
2025-01-18 18:31:10.819772: Yayy! New best EMA pseudo Dice: 0.09600000083446503 
2025-01-18 18:31:11.765971:  
2025-01-18 18:31:11.765971: Epoch 5 
2025-01-18 18:31:11.771610: Current learning rate: 0.00982 
2025-01-18 18:31:43.649655: train_loss -0.4435 
2025-01-18 18:31:43.650157: val_loss -0.4674 
2025-01-18 18:31:43.655796: Pseudo dice [np.float32(0.6155), np.float32(0.4281)] 
2025-01-18 18:31:43.658833: Epoch time: 31.88 s 
2025-01-18 18:31:43.661860: Yayy! New best EMA pseudo Dice: 0.13860000669956207 
2025-01-18 18:31:44.460871:  
2025-01-18 18:31:44.460871: Epoch 6 
2025-01-18 18:31:44.465894: Current learning rate: 0.00978 
2025-01-18 18:32:16.354605: train_loss -0.4567 
2025-01-18 18:32:16.355609: val_loss -0.4603 
2025-01-18 18:32:16.361663: Pseudo dice [np.float32(0.6147), np.float32(0.3933)] 
2025-01-18 18:32:16.364701: Epoch time: 31.9 s 
2025-01-18 18:32:16.367208: Yayy! New best EMA pseudo Dice: 0.17509999871253967 
2025-01-18 18:32:17.183220:  
2025-01-18 18:32:17.183220: Epoch 7 
2025-01-18 18:32:17.188274: Current learning rate: 0.00975 
2025-01-18 18:32:49.062466: train_loss -0.4714 
2025-01-18 18:32:49.063471: val_loss -0.4589 
2025-01-18 18:32:49.068488: Pseudo dice [np.float32(0.6276), np.float32(0.3726)] 
2025-01-18 18:32:49.071864: Epoch time: 31.88 s 
2025-01-18 18:32:49.074370: Yayy! New best EMA pseudo Dice: 0.20759999752044678 
2025-01-18 18:32:49.900112:  
2025-01-18 18:32:49.901115: Epoch 8 
2025-01-18 18:32:49.905635: Current learning rate: 0.00971 
2025-01-18 18:33:21.775588: train_loss -0.4915 
2025-01-18 18:33:21.776594: val_loss -0.4682 
2025-01-18 18:33:21.781606: Pseudo dice [np.float32(0.6235), np.float32(0.3876)] 
2025-01-18 18:33:21.785113: Epoch time: 31.88 s 
2025-01-18 18:33:21.787627: Yayy! New best EMA pseudo Dice: 0.23739999532699585 
2025-01-18 18:33:22.599744:  
2025-01-18 18:33:22.599744: Epoch 9 
2025-01-18 18:33:22.605306: Current learning rate: 0.00968 
2025-01-18 18:33:54.492470: train_loss -0.5224 
2025-01-18 18:33:54.492973: val_loss -0.4543 
2025-01-18 18:33:54.498497: Pseudo dice [np.float32(0.6362), np.float32(0.3349)] 
2025-01-18 18:33:54.501525: Epoch time: 31.89 s 
2025-01-18 18:33:54.504033: Yayy! New best EMA pseudo Dice: 0.2621999979019165 
2025-01-18 18:33:55.299017:  
2025-01-18 18:33:55.299017: Epoch 10 
2025-01-18 18:33:55.304047: Current learning rate: 0.00964 
2025-01-18 18:34:27.179900: train_loss -0.5299 
2025-01-18 18:34:27.180428: val_loss -0.4791 
2025-01-18 18:34:27.185057: Pseudo dice [np.float32(0.6599), np.float32(0.356)] 
2025-01-18 18:34:27.188106: Epoch time: 31.88 s 
2025-01-18 18:34:27.191141: Yayy! New best EMA pseudo Dice: 0.28679999709129333 
2025-01-18 18:34:27.997623:  
2025-01-18 18:34:27.997623: Epoch 11 
2025-01-18 18:34:28.001153: Current learning rate: 0.0096 
2025-01-18 18:34:59.870212: train_loss -0.4948 
2025-01-18 18:34:59.870719: val_loss -0.4927 
2025-01-18 18:34:59.876815: Pseudo dice [np.float32(0.6505), np.float32(0.4086)] 
2025-01-18 18:34:59.880851: Epoch time: 31.87 s 
2025-01-18 18:34:59.883860: Yayy! New best EMA pseudo Dice: 0.3111000061035156 
2025-01-18 18:35:00.843640:  
2025-01-18 18:35:00.844646: Epoch 12 
2025-01-18 18:35:00.849189: Current learning rate: 0.00957 
2025-01-18 18:35:32.724120: train_loss -0.546 
2025-01-18 18:35:32.724639: val_loss -0.5189 
2025-01-18 18:35:32.729650: Pseudo dice [np.float32(0.6695), np.float32(0.4277)] 
2025-01-18 18:35:32.733161: Epoch time: 31.88 s 
2025-01-18 18:35:32.735667: Yayy! New best EMA pseudo Dice: 0.33480000495910645 
2025-01-18 18:35:33.569757:  
2025-01-18 18:35:33.569757: Epoch 13 
2025-01-18 18:35:33.575330: Current learning rate: 0.00953 
2025-01-18 18:36:05.438734: train_loss -0.5639 
2025-01-18 18:36:05.439740: val_loss -0.4485 
2025-01-18 18:36:05.445759: Pseudo dice [np.float32(0.665), np.float32(0.3119)] 
2025-01-18 18:36:05.448769: Epoch time: 31.87 s 
2025-01-18 18:36:05.451303: Yayy! New best EMA pseudo Dice: 0.35019999742507935 
2025-01-18 18:36:06.253408:  
2025-01-18 18:36:06.253408: Epoch 14 
2025-01-18 18:36:06.258958: Current learning rate: 0.00949 
2025-01-18 18:36:38.131572: train_loss -0.5595 
2025-01-18 18:36:38.132575: val_loss -0.4913 
2025-01-18 18:36:38.137591: Pseudo dice [np.float32(0.626), np.float32(0.4302)] 
2025-01-18 18:36:38.140097: Epoch time: 31.88 s 
2025-01-18 18:36:38.143189: Yayy! New best EMA pseudo Dice: 0.36800000071525574 
2025-01-18 18:36:38.956034:  
2025-01-18 18:36:38.957037: Epoch 15 
2025-01-18 18:36:38.962328: Current learning rate: 0.00946 
2025-01-18 18:37:10.837715: train_loss -0.5764 
2025-01-18 18:37:10.838720: val_loss -0.5036 
2025-01-18 18:37:10.843749: Pseudo dice [np.float32(0.6832), np.float32(0.4444)] 
2025-01-18 18:37:10.847251: Epoch time: 31.88 s 
2025-01-18 18:37:10.850260: Yayy! New best EMA pseudo Dice: 0.38760000467300415 
2025-01-18 18:37:11.723698:  
2025-01-18 18:37:11.724702: Epoch 16 
2025-01-18 18:37:11.729293: Current learning rate: 0.00942 
2025-01-18 18:37:43.624202: train_loss -0.5815 
2025-01-18 18:37:43.624202: val_loss -0.4838 
2025-01-18 18:37:43.629759: Pseudo dice [np.float32(0.6591), np.float32(0.3538)] 
2025-01-18 18:37:43.632343: Epoch time: 31.9 s 
2025-01-18 18:37:43.636436: Yayy! New best EMA pseudo Dice: 0.3995000123977661 
2025-01-18 18:37:44.469987:  
2025-01-18 18:37:44.470492: Epoch 17 
2025-01-18 18:37:44.475507: Current learning rate: 0.00939 
2025-01-18 18:38:16.369434: train_loss -0.5983 
2025-01-18 18:38:16.370011: val_loss -0.5063 
2025-01-18 18:38:16.375550: Pseudo dice [np.float32(0.7015), np.float32(0.4093)] 
2025-01-18 18:38:16.378072: Epoch time: 31.9 s 
2025-01-18 18:38:16.382113: Yayy! New best EMA pseudo Dice: 0.41499999165534973 
2025-01-18 18:38:17.225142:  
2025-01-18 18:38:17.225142: Epoch 18 
2025-01-18 18:38:17.229707: Current learning rate: 0.00935 
2025-01-18 18:38:49.130430: train_loss -0.5897 
2025-01-18 18:38:49.131434: val_loss -0.4857 
2025-01-18 18:38:49.137455: Pseudo dice [np.float32(0.6784), np.float32(0.3799)] 
2025-01-18 18:38:49.140513: Epoch time: 31.91 s 
2025-01-18 18:38:49.144025: Yayy! New best EMA pseudo Dice: 0.42649999260902405 
2025-01-18 18:38:49.983474:  
2025-01-18 18:38:49.983474: Epoch 19 
2025-01-18 18:38:49.989507: Current learning rate: 0.00931 
2025-01-18 18:39:21.883891: train_loss -0.602 
2025-01-18 18:39:21.884401: val_loss -0.5361 
2025-01-18 18:39:21.889969: Pseudo dice [np.float32(0.6621), np.float32(0.4847)] 
2025-01-18 18:39:21.892989: Epoch time: 31.9 s 
2025-01-18 18:39:21.896005: Yayy! New best EMA pseudo Dice: 0.44119998812675476 
2025-01-18 18:39:22.881265:  
2025-01-18 18:39:22.881265: Epoch 20 
2025-01-18 18:39:22.886824: Current learning rate: 0.00928 
2025-01-18 18:39:54.771261: train_loss -0.6055 
2025-01-18 18:39:54.771261: val_loss -0.5485 
2025-01-18 18:39:54.777279: Pseudo dice [np.float32(0.7034), np.float32(0.4241)] 
2025-01-18 18:39:54.781324: Epoch time: 31.89 s 
2025-01-18 18:39:54.784381: Yayy! New best EMA pseudo Dice: 0.45339998602867126 
2025-01-18 18:39:55.626612:  
2025-01-18 18:39:55.627116: Epoch 21 
2025-01-18 18:39:55.631683: Current learning rate: 0.00924 
2025-01-18 18:40:27.518601: train_loss -0.629 
2025-01-18 18:40:27.520104: val_loss -0.4751 
2025-01-18 18:40:27.525155: Pseudo dice [np.float32(0.7024), np.float32(0.3186)] 
2025-01-18 18:40:27.528184: Epoch time: 31.89 s 
2025-01-18 18:40:27.531692: Yayy! New best EMA pseudo Dice: 0.45910000801086426 
2025-01-18 18:40:28.323718:  
2025-01-18 18:40:28.323718: Epoch 22 
2025-01-18 18:40:28.329290: Current learning rate: 0.0092 
2025-01-18 18:41:00.218954: train_loss -0.6331 
2025-01-18 18:41:00.219458: val_loss -0.545 
2025-01-18 18:41:00.227039: Pseudo dice [np.float32(0.6859), np.float32(0.494)] 
2025-01-18 18:41:00.232086: Epoch time: 31.9 s 
2025-01-18 18:41:00.235121: Yayy! New best EMA pseudo Dice: 0.4722000062465668 
2025-01-18 18:41:01.031228:  
2025-01-18 18:41:01.031228: Epoch 23 
2025-01-18 18:41:01.036863: Current learning rate: 0.00917 
2025-01-18 18:41:32.942826: train_loss -0.6328 
2025-01-18 18:41:32.943348: val_loss -0.5068 
2025-01-18 18:41:32.948439: Pseudo dice [np.float32(0.6901), np.float32(0.3877)] 
2025-01-18 18:41:32.951493: Epoch time: 31.91 s 
2025-01-18 18:41:32.954030: Yayy! New best EMA pseudo Dice: 0.4788999855518341 
2025-01-18 18:41:33.761958:  
2025-01-18 18:41:33.762961: Epoch 24 
2025-01-18 18:41:33.766510: Current learning rate: 0.00913 
2025-01-18 18:42:05.663931: train_loss -0.6411 
2025-01-18 18:42:05.664932: val_loss -0.5558 
2025-01-18 18:42:05.671452: Pseudo dice [np.float32(0.6993), np.float32(0.5019)] 
2025-01-18 18:42:05.674965: Epoch time: 31.9 s 
2025-01-18 18:42:05.678007: Yayy! New best EMA pseudo Dice: 0.4909999966621399 
2025-01-18 18:42:06.482943:  
2025-01-18 18:42:06.482943: Epoch 25 
2025-01-18 18:42:06.488957: Current learning rate: 0.0091 
2025-01-18 18:42:38.378252: train_loss -0.6473 
2025-01-18 18:42:38.379253: val_loss -0.4858 
2025-01-18 18:42:38.384286: Pseudo dice [np.float32(0.6892), np.float32(0.3537)] 
2025-01-18 18:42:38.387309: Epoch time: 31.9 s 
2025-01-18 18:42:38.390818: Yayy! New best EMA pseudo Dice: 0.49410000443458557 
2025-01-18 18:42:39.191783:  
2025-01-18 18:42:39.191783: Epoch 26 
2025-01-18 18:42:39.197344: Current learning rate: 0.00906 
2025-01-18 18:43:11.096144: train_loss -0.6503 
2025-01-18 18:43:11.097147: val_loss -0.5086 
2025-01-18 18:43:11.103740: Pseudo dice [np.float32(0.7035), np.float32(0.4299)] 
2025-01-18 18:43:11.106267: Epoch time: 31.91 s 
2025-01-18 18:43:11.110296: Yayy! New best EMA pseudo Dice: 0.5012999773025513 
2025-01-18 18:43:12.065790:  
2025-01-18 18:43:12.065790: Epoch 27 
2025-01-18 18:43:12.071320: Current learning rate: 0.00902 
2025-01-18 18:43:43.953258: train_loss -0.6305 
2025-01-18 18:43:43.953258: val_loss -0.5498 
2025-01-18 18:43:43.958277: Pseudo dice [np.float32(0.7071), np.float32(0.4816)] 
2025-01-18 18:43:43.961788: Epoch time: 31.89 s 
2025-01-18 18:43:43.965295: Yayy! New best EMA pseudo Dice: 0.5105999708175659 
2025-01-18 18:43:44.781055:  
2025-01-18 18:43:44.781055: Epoch 28 
2025-01-18 18:43:44.787068: Current learning rate: 0.00899 
2025-01-18 18:44:16.683273: train_loss -0.6534 
2025-01-18 18:44:16.683273: val_loss -0.5165 
2025-01-18 18:44:16.689293: Pseudo dice [np.float32(0.6829), np.float32(0.4368)] 
2025-01-18 18:44:16.693334: Epoch time: 31.9 s 
2025-01-18 18:44:16.696846: Yayy! New best EMA pseudo Dice: 0.5156000256538391 
2025-01-18 18:44:17.513379:  
2025-01-18 18:44:17.514382: Epoch 29 
2025-01-18 18:44:17.519336: Current learning rate: 0.00895 
2025-01-18 18:44:49.431011: train_loss -0.6596 
2025-01-18 18:44:49.431517: val_loss -0.4937 
2025-01-18 18:44:49.437538: Pseudo dice [np.float32(0.6632), np.float32(0.4403)] 
2025-01-18 18:44:49.439553: Epoch time: 31.92 s 
2025-01-18 18:44:49.444091: Yayy! New best EMA pseudo Dice: 0.5192000269889832 
2025-01-18 18:44:50.272137:  
2025-01-18 18:44:50.272137: Epoch 30 
2025-01-18 18:44:50.278228: Current learning rate: 0.00891 
2025-01-18 18:45:22.159065: train_loss -0.6376 
2025-01-18 18:45:22.159575: val_loss -0.4957 
2025-01-18 18:45:22.165244: Pseudo dice [np.float32(0.7028), np.float32(0.3419)] 
2025-01-18 18:45:22.168815: Epoch time: 31.89 s 
2025-01-18 18:45:22.171863: Yayy! New best EMA pseudo Dice: 0.5195000171661377 
2025-01-18 18:45:22.974140:  
2025-01-18 18:45:22.974140: Epoch 31 
2025-01-18 18:45:22.980171: Current learning rate: 0.00888 
2025-01-18 18:45:54.878057: train_loss -0.6689 
2025-01-18 18:45:54.878564: val_loss -0.5286 
2025-01-18 18:45:54.883567: Pseudo dice [np.float32(0.6983), np.float32(0.4623)] 
2025-01-18 18:45:54.887196: Epoch time: 31.9 s 
2025-01-18 18:45:54.891217: Yayy! New best EMA pseudo Dice: 0.525600016117096 
2025-01-18 18:45:55.713226:  
2025-01-18 18:45:55.713226: Epoch 32 
2025-01-18 18:45:55.718762: Current learning rate: 0.00884 
2025-01-18 18:46:27.605633: train_loss -0.6323 
2025-01-18 18:46:27.606633: val_loss -0.4821 
2025-01-18 18:46:27.612160: Pseudo dice [np.float32(0.6927), np.float32(0.3482)] 
2025-01-18 18:46:27.615670: Epoch time: 31.89 s 
2025-01-18 18:46:28.187820:  
2025-01-18 18:46:28.188334: Epoch 33 
2025-01-18 18:46:28.193879: Current learning rate: 0.0088 
2025-01-18 18:47:00.090732: train_loss -0.6853 
2025-01-18 18:47:00.090732: val_loss -0.5165 
2025-01-18 18:47:00.096720: Pseudo dice [np.float32(0.7062), np.float32(0.4506)] 
2025-01-18 18:47:00.100235: Epoch time: 31.9 s 
2025-01-18 18:47:00.103350: Yayy! New best EMA pseudo Dice: 0.5303999781608582 
2025-01-18 18:47:00.916876:  
2025-01-18 18:47:00.916876: Epoch 34 
2025-01-18 18:47:00.921917: Current learning rate: 0.00877 
2025-01-18 18:47:32.804641: train_loss -0.6776 
2025-01-18 18:47:32.806149: val_loss -0.5228 
2025-01-18 18:47:32.812171: Pseudo dice [np.float32(0.6863), np.float32(0.4458)] 
2025-01-18 18:47:32.815054: Epoch time: 31.89 s 
2025-01-18 18:47:32.820592: Yayy! New best EMA pseudo Dice: 0.5339999794960022 
2025-01-18 18:47:33.802090:  
2025-01-18 18:47:33.803092: Epoch 35 
2025-01-18 18:47:33.808123: Current learning rate: 0.00873 
2025-01-18 18:48:05.709718: train_loss -0.6635 
2025-01-18 18:48:05.710719: val_loss -0.5161 
2025-01-18 18:48:05.716855: Pseudo dice [np.float32(0.707), np.float32(0.4086)] 
2025-01-18 18:48:05.720897: Epoch time: 31.91 s 
2025-01-18 18:48:05.723934: Yayy! New best EMA pseudo Dice: 0.5364000201225281 
2025-01-18 18:48:06.564403:  
2025-01-18 18:48:06.565407: Epoch 36 
2025-01-18 18:48:06.568924: Current learning rate: 0.00869 
2025-01-18 18:48:38.461462: train_loss -0.6973 
2025-01-18 18:48:38.462465: val_loss -0.5328 
2025-01-18 18:48:38.468121: Pseudo dice [np.float32(0.7277), np.float32(0.4744)] 
2025-01-18 18:48:38.471711: Epoch time: 31.9 s 
2025-01-18 18:48:38.474801: Yayy! New best EMA pseudo Dice: 0.5428000092506409 
2025-01-18 18:48:39.308478:  
2025-01-18 18:48:39.308478: Epoch 37 
2025-01-18 18:48:39.315492: Current learning rate: 0.00866 
2025-01-18 18:49:11.216453: train_loss -0.6946 
2025-01-18 18:49:11.216955: val_loss -0.5326 
2025-01-18 18:49:11.222980: Pseudo dice [np.float32(0.7007), np.float32(0.4404)] 
2025-01-18 18:49:11.226517: Epoch time: 31.91 s 
2025-01-18 18:49:11.229541: Yayy! New best EMA pseudo Dice: 0.5455999970436096 
2025-01-18 18:49:12.065366:  
2025-01-18 18:49:12.065366: Epoch 38 
2025-01-18 18:49:12.070932: Current learning rate: 0.00862 
2025-01-18 18:49:43.966868: train_loss -0.6981 
2025-01-18 18:49:43.966868: val_loss -0.5123 
2025-01-18 18:49:43.973384: Pseudo dice [np.float32(0.6897), np.float32(0.4589)] 
2025-01-18 18:49:43.976895: Epoch time: 31.9 s 
2025-01-18 18:49:43.979400: Yayy! New best EMA pseudo Dice: 0.5485000014305115 
2025-01-18 18:49:44.812673:  
2025-01-18 18:49:44.813676: Epoch 39 
2025-01-18 18:49:44.819730: Current learning rate: 0.00858 
2025-01-18 18:50:16.721245: train_loss -0.6996 
2025-01-18 18:50:16.722253: val_loss -0.4598 
2025-01-18 18:50:16.727778: Pseudo dice [np.float32(0.6971), np.float32(0.361)] 
2025-01-18 18:50:16.731798: Epoch time: 31.91 s 
2025-01-18 18:50:17.326926:  
2025-01-18 18:50:17.326926: Epoch 40 
2025-01-18 18:50:17.332527: Current learning rate: 0.00855 
2025-01-18 18:50:49.231402: train_loss -0.7222 
2025-01-18 18:50:49.232401: val_loss -0.4931 
2025-01-18 18:50:49.237956: Pseudo dice [np.float32(0.7095), np.float32(0.3683)] 
2025-01-18 18:50:49.241466: Epoch time: 31.91 s 
2025-01-18 18:50:49.833989:  
2025-01-18 18:50:49.833989: Epoch 41 
2025-01-18 18:50:49.842126: Current learning rate: 0.00851 
2025-01-18 18:51:21.728155: train_loss -0.655 
2025-01-18 18:51:21.728155: val_loss -0.4793 
2025-01-18 18:51:21.734205: Pseudo dice [np.float32(0.6573), np.float32(0.4176)] 
2025-01-18 18:51:21.737771: Epoch time: 31.89 s 
2025-01-18 18:51:22.436655:  
2025-01-18 18:51:22.437661: Epoch 42 
2025-01-18 18:51:22.443197: Current learning rate: 0.00847 
2025-01-18 18:51:54.315476: train_loss -0.6635 
2025-01-18 18:51:54.315983: val_loss -0.4996 
2025-01-18 18:51:54.321609: Pseudo dice [np.float32(0.6506), np.float32(0.4536)] 
2025-01-18 18:51:54.325175: Epoch time: 31.88 s 
2025-01-18 18:51:54.891617:  
2025-01-18 18:51:54.891617: Epoch 43 
2025-01-18 18:51:54.897631: Current learning rate: 0.00844 
2025-01-18 18:52:26.758985: train_loss -0.6937 
2025-01-18 18:52:26.759496: val_loss -0.5288 
2025-01-18 18:52:26.769050: Pseudo dice [np.float32(0.7197), np.float32(0.4631)] 
2025-01-18 18:52:26.772098: Epoch time: 31.87 s 
2025-01-18 18:52:26.775607: Yayy! New best EMA pseudo Dice: 0.5501999855041504 
2025-01-18 18:52:27.584648:  
2025-01-18 18:52:27.585150: Epoch 44 
2025-01-18 18:52:27.590162: Current learning rate: 0.0084 
2025-01-18 18:52:59.450740: train_loss -0.7086 
2025-01-18 18:52:59.451261: val_loss -0.4998 
2025-01-18 18:52:59.456273: Pseudo dice [np.float32(0.707), np.float32(0.4098)] 
2025-01-18 18:52:59.460285: Epoch time: 31.87 s 
2025-01-18 18:52:59.463860: Yayy! New best EMA pseudo Dice: 0.5509999990463257 
2025-01-18 18:53:00.266744:  
2025-01-18 18:53:00.266744: Epoch 45 
2025-01-18 18:53:00.271758: Current learning rate: 0.00836 
2025-01-18 18:53:32.127618: train_loss -0.7235 
2025-01-18 18:53:32.127618: val_loss -0.5558 
2025-01-18 18:53:32.134162: Pseudo dice [np.float32(0.7012), np.float32(0.5095)] 
2025-01-18 18:53:32.137176: Epoch time: 31.86 s 
2025-01-18 18:53:32.140740: Yayy! New best EMA pseudo Dice: 0.5565000176429749 
2025-01-18 18:53:32.961119:  
2025-01-18 18:53:32.961119: Epoch 46 
2025-01-18 18:53:32.967212: Current learning rate: 0.00833 
2025-01-18 18:54:04.837209: train_loss -0.7362 
2025-01-18 18:54:04.837712: val_loss -0.5127 
2025-01-18 18:54:04.844730: Pseudo dice [np.float32(0.6958), np.float32(0.4419)] 
2025-01-18 18:54:04.847740: Epoch time: 31.88 s 
2025-01-18 18:54:04.851251: Yayy! New best EMA pseudo Dice: 0.557699978351593 
2025-01-18 18:54:05.660430:  
2025-01-18 18:54:05.660430: Epoch 47 
2025-01-18 18:54:05.666477: Current learning rate: 0.00829 
2025-01-18 18:54:37.549235: train_loss -0.7423 
2025-01-18 18:54:37.550235: val_loss -0.5151 
2025-01-18 18:54:37.556353: Pseudo dice [np.float32(0.7026), np.float32(0.4957)] 
2025-01-18 18:54:37.559859: Epoch time: 31.89 s 
2025-01-18 18:54:37.562869: Yayy! New best EMA pseudo Dice: 0.5618000030517578 
2025-01-18 18:54:38.365834:  
2025-01-18 18:54:38.366337: Epoch 48 
2025-01-18 18:54:38.371932: Current learning rate: 0.00825 
2025-01-18 18:55:10.247698: train_loss -0.7151 
2025-01-18 18:55:10.248698: val_loss -0.5365 
2025-01-18 18:55:10.252710: Pseudo dice [np.float32(0.6951), np.float32(0.5246)] 
2025-01-18 18:55:10.256719: Epoch time: 31.88 s 
2025-01-18 18:55:10.260228: Yayy! New best EMA pseudo Dice: 0.5666000247001648 
2025-01-18 18:55:11.073973:  
2025-01-18 18:55:11.073973: Epoch 49 
2025-01-18 18:55:11.079989: Current learning rate: 0.00822 
2025-01-18 18:55:42.959793: train_loss -0.7102 
2025-01-18 18:55:42.960798: val_loss -0.5356 
2025-01-18 18:55:42.965810: Pseudo dice [np.float32(0.6672), np.float32(0.4915)] 
2025-01-18 18:55:42.969819: Epoch time: 31.89 s 
2025-01-18 18:55:43.194519: Yayy! New best EMA pseudo Dice: 0.5679000020027161 
2025-01-18 18:55:44.153963:  
2025-01-18 18:55:44.154969: Epoch 50 
2025-01-18 18:55:44.159992: Current learning rate: 0.00818 
2025-01-18 18:56:16.023464: train_loss -0.7329 
2025-01-18 18:56:16.023973: val_loss -0.5075 
2025-01-18 18:56:16.029642: Pseudo dice [np.float32(0.7142), np.float32(0.4088)] 
2025-01-18 18:56:16.033170: Epoch time: 31.87 s 
2025-01-18 18:56:16.598680:  
2025-01-18 18:56:16.598680: Epoch 51 
2025-01-18 18:56:16.604283: Current learning rate: 0.00814 
2025-01-18 18:56:48.475747: train_loss -0.7238 
2025-01-18 18:56:48.475747: val_loss -0.557 
2025-01-18 18:56:48.482264: Pseudo dice [np.float32(0.7094), np.float32(0.5335)] 
2025-01-18 18:56:48.485772: Epoch time: 31.88 s 
2025-01-18 18:56:48.489280: Yayy! New best EMA pseudo Dice: 0.572700023651123 
2025-01-18 18:56:49.306938:  
2025-01-18 18:56:49.306938: Epoch 52 
2025-01-18 18:56:49.317110: Current learning rate: 0.00811 
2025-01-18 18:57:21.203078: train_loss -0.7442 
2025-01-18 18:57:21.203580: val_loss -0.5428 
2025-01-18 18:57:21.209182: Pseudo dice [np.float32(0.7118), np.float32(0.4741)] 
2025-01-18 18:57:21.212200: Epoch time: 31.9 s 
2025-01-18 18:57:21.216296: Yayy! New best EMA pseudo Dice: 0.5746999979019165 
2025-01-18 18:57:22.021429:  
2025-01-18 18:57:22.021429: Epoch 53 
2025-01-18 18:57:22.026965: Current learning rate: 0.00807 
2025-01-18 18:57:53.908978: train_loss -0.7503 
2025-01-18 18:57:53.909979: val_loss -0.5285 
2025-01-18 18:57:53.915502: Pseudo dice [np.float32(0.7302), np.float32(0.4237)] 
2025-01-18 18:57:53.919654: Epoch time: 31.89 s 
2025-01-18 18:57:53.923200: Yayy! New best EMA pseudo Dice: 0.5748999714851379 
2025-01-18 18:57:54.744632:  
2025-01-18 18:57:54.745136: Epoch 54 
2025-01-18 18:57:54.750148: Current learning rate: 0.00803 
2025-01-18 18:58:26.642272: train_loss -0.7514 
2025-01-18 18:58:26.643275: val_loss -0.5115 
2025-01-18 18:58:26.649310: Pseudo dice [np.float32(0.7072), np.float32(0.4065)] 
2025-01-18 18:58:26.652854: Epoch time: 31.9 s 
2025-01-18 18:58:27.210576:  
2025-01-18 18:58:27.210576: Epoch 55 
2025-01-18 18:58:27.216095: Current learning rate: 0.008 
2025-01-18 18:58:59.100420: train_loss -0.7164 
2025-01-18 18:58:59.100922: val_loss -0.4917 
2025-01-18 18:58:59.107008: Pseudo dice [np.float32(0.6748), np.float32(0.4121)] 
2025-01-18 18:58:59.109533: Epoch time: 31.89 s 
2025-01-18 18:58:59.661237:  
2025-01-18 18:58:59.661237: Epoch 56 
2025-01-18 18:58:59.667273: Current learning rate: 0.00796 
2025-01-18 18:59:31.573569: train_loss -0.7306 
2025-01-18 18:59:31.574569: val_loss -0.5065 
2025-01-18 18:59:31.580885: Pseudo dice [np.float32(0.7073), np.float32(0.4089)] 
2025-01-18 18:59:31.583393: Epoch time: 31.91 s 
2025-01-18 18:59:32.135109:  
2025-01-18 18:59:32.135109: Epoch 57 
2025-01-18 18:59:32.140640: Current learning rate: 0.00792 
2025-01-18 19:00:04.031505: train_loss -0.728 
2025-01-18 19:00:04.032014: val_loss -0.4606 
2025-01-18 19:00:04.037134: Pseudo dice [np.float32(0.7044), np.float32(0.3323)] 
2025-01-18 19:00:04.039690: Epoch time: 31.9 s 
2025-01-18 19:00:04.739729:  
2025-01-18 19:00:04.739729: Epoch 58 
2025-01-18 19:00:04.745300: Current learning rate: 0.00789 
2025-01-18 19:00:36.629620: train_loss -0.7505 
2025-01-18 19:00:36.629620: val_loss -0.537 
2025-01-18 19:00:36.636138: Pseudo dice [np.float32(0.7147), np.float32(0.4452)] 
2025-01-18 19:00:36.638646: Epoch time: 31.89 s 
2025-01-18 19:00:37.193104:  
2025-01-18 19:00:37.193104: Epoch 59 
2025-01-18 19:00:37.199125: Current learning rate: 0.00785 
2025-01-18 19:01:09.069468: train_loss -0.7645 
2025-01-18 19:01:09.070474: val_loss -0.5343 
2025-01-18 19:01:09.076993: Pseudo dice [np.float32(0.7281), np.float32(0.4325)] 
2025-01-18 19:01:09.079499: Epoch time: 31.88 s 
2025-01-18 19:01:09.641642:  
2025-01-18 19:01:09.641642: Epoch 60 
2025-01-18 19:01:09.647756: Current learning rate: 0.00781 
2025-01-18 19:01:41.540824: train_loss -0.7811 
2025-01-18 19:01:41.541329: val_loss -0.4849 
2025-01-18 19:01:41.547352: Pseudo dice [np.float32(0.7105), np.float32(0.3475)] 
2025-01-18 19:01:41.551363: Epoch time: 31.9 s 
2025-01-18 19:01:42.106441:  
2025-01-18 19:01:42.106441: Epoch 61 
2025-01-18 19:01:42.112460: Current learning rate: 0.00777 
2025-01-18 19:02:14.010228: train_loss -0.7656 
2025-01-18 19:02:14.010228: val_loss -0.4954 
2025-01-18 19:02:14.015961: Pseudo dice [np.float32(0.6786), np.float32(0.4243)] 
2025-01-18 19:02:14.019471: Epoch time: 31.9 s 
2025-01-18 19:02:14.577035:  
2025-01-18 19:02:14.577538: Epoch 62 
2025-01-18 19:02:14.582551: Current learning rate: 0.00774 
2025-01-18 19:02:46.465211: train_loss -0.7677 
2025-01-18 19:02:46.465211: val_loss -0.5361 
2025-01-18 19:02:46.478750: Pseudo dice [np.float32(0.7091), np.float32(0.4414)] 
2025-01-18 19:02:46.481758: Epoch time: 31.89 s 
2025-01-18 19:02:47.048297:  
2025-01-18 19:02:47.048800: Epoch 63 
2025-01-18 19:02:47.053812: Current learning rate: 0.0077 
2025-01-18 19:03:18.930977: train_loss -0.7739 
2025-01-18 19:03:18.931479: val_loss -0.5349 
2025-01-18 19:03:18.937091: Pseudo dice [np.float32(0.714), np.float32(0.4625)] 
2025-01-18 19:03:18.941656: Epoch time: 31.88 s 
2025-01-18 19:03:19.503606:  
2025-01-18 19:03:19.503606: Epoch 64 
2025-01-18 19:03:19.509135: Current learning rate: 0.00766 
2025-01-18 19:03:51.376875: train_loss -0.7407 
2025-01-18 19:03:51.377381: val_loss -0.4743 
2025-01-18 19:03:51.383421: Pseudo dice [np.float32(0.7076), np.float32(0.3832)] 
2025-01-18 19:03:51.386968: Epoch time: 31.87 s 
2025-01-18 19:03:51.951662:  
2025-01-18 19:03:51.951662: Epoch 65 
2025-01-18 19:03:51.956673: Current learning rate: 0.00763 
2025-01-18 19:04:23.840318: train_loss -0.7708 
2025-01-18 19:04:23.841323: val_loss -0.538 
2025-01-18 19:04:23.847838: Pseudo dice [np.float32(0.7343), np.float32(0.4726)] 
2025-01-18 19:04:23.851352: Epoch time: 31.89 s 
2025-01-18 19:04:24.565730:  
2025-01-18 19:04:24.566734: Epoch 66 
2025-01-18 19:04:24.571274: Current learning rate: 0.00759 
2025-01-18 19:04:56.466370: train_loss -0.7885 
2025-01-18 19:04:56.466370: val_loss -0.4888 
2025-01-18 19:04:56.472890: Pseudo dice [np.float32(0.7116), np.float32(0.3691)] 
2025-01-18 19:04:56.476399: Epoch time: 31.9 s 
2025-01-18 19:04:57.035112:  
2025-01-18 19:04:57.036110: Epoch 67 
2025-01-18 19:04:57.041625: Current learning rate: 0.00755 
2025-01-18 19:05:28.927613: train_loss -0.7877 
2025-01-18 19:05:28.928121: val_loss -0.5124 
2025-01-18 19:05:28.934720: Pseudo dice [np.float32(0.7081), np.float32(0.3669)] 
2025-01-18 19:05:28.937323: Epoch time: 31.89 s 
2025-01-18 19:05:29.509714:  
2025-01-18 19:05:29.509714: Epoch 68 
2025-01-18 19:05:29.517233: Current learning rate: 0.00751 
2025-01-18 19:06:01.405640: train_loss -0.7725 
2025-01-18 19:06:01.405640: val_loss -0.5179 
2025-01-18 19:06:01.411734: Pseudo dice [np.float32(0.708), np.float32(0.4267)] 
2025-01-18 19:06:01.415801: Epoch time: 31.9 s 
2025-01-18 19:06:01.984394:  
2025-01-18 19:06:01.985394: Epoch 69 
2025-01-18 19:06:01.991003: Current learning rate: 0.00748 
2025-01-18 19:06:33.881945: train_loss -0.7848 
2025-01-18 19:06:33.882462: val_loss -0.5075 
2025-01-18 19:06:33.889095: Pseudo dice [np.float32(0.7229), np.float32(0.4561)] 
2025-01-18 19:06:33.892135: Epoch time: 31.9 s 
2025-01-18 19:06:34.474272:  
2025-01-18 19:06:34.475271: Epoch 70 
2025-01-18 19:06:34.480847: Current learning rate: 0.00744 
2025-01-18 19:07:06.368363: train_loss -0.7987 
2025-01-18 19:07:06.369363: val_loss -0.5184 
2025-01-18 19:07:06.376392: Pseudo dice [np.float32(0.7048), np.float32(0.3887)] 
2025-01-18 19:07:06.380455: Epoch time: 31.89 s 
2025-01-18 19:07:06.957234:  
2025-01-18 19:07:06.957234: Epoch 71 
2025-01-18 19:07:06.962296: Current learning rate: 0.0074 
2025-01-18 19:07:38.850649: train_loss -0.772 
2025-01-18 19:07:38.851652: val_loss -0.5135 
2025-01-18 19:07:38.858169: Pseudo dice [np.float32(0.6943), np.float32(0.4246)] 
2025-01-18 19:07:38.864184: Epoch time: 31.89 s 
2025-01-18 19:07:39.439152:  
2025-01-18 19:07:39.440153: Epoch 72 
2025-01-18 19:07:39.445724: Current learning rate: 0.00737 
2025-01-18 19:08:11.338969: train_loss -0.7792 
2025-01-18 19:08:11.340474: val_loss -0.5085 
2025-01-18 19:08:11.346489: Pseudo dice [np.float32(0.7073), np.float32(0.3942)] 
2025-01-18 19:08:11.351505: Epoch time: 31.9 s 
2025-01-18 19:08:12.078275:  
2025-01-18 19:08:12.079279: Epoch 73 
2025-01-18 19:08:12.083829: Current learning rate: 0.00733 
2025-01-18 19:08:43.980108: train_loss -0.7875 
2025-01-18 19:08:43.981111: val_loss -0.4851 
2025-01-18 19:08:43.987630: Pseudo dice [np.float32(0.7135), np.float32(0.3041)] 
2025-01-18 19:08:43.991163: Epoch time: 31.9 s 
2025-01-18 19:08:44.571569:  
2025-01-18 19:08:44.572573: Epoch 74 
2025-01-18 19:08:44.577185: Current learning rate: 0.00729 
2025-01-18 19:09:16.473424: train_loss -0.7986 
2025-01-18 19:09:16.473424: val_loss -0.5014 
2025-01-18 19:09:16.480943: Pseudo dice [np.float32(0.7268), np.float32(0.3776)] 
2025-01-18 19:09:16.487957: Epoch time: 31.9 s 
2025-01-18 19:09:17.055954:  
2025-01-18 19:09:17.055954: Epoch 75 
2025-01-18 19:09:17.061969: Current learning rate: 0.00725 
2025-01-18 19:09:48.960430: train_loss -0.7796 
2025-01-18 19:09:48.960938: val_loss -0.5211 
2025-01-18 19:09:48.967619: Pseudo dice [np.float32(0.6757), np.float32(0.4419)] 
2025-01-18 19:09:48.971152: Epoch time: 31.91 s 
2025-01-18 19:09:49.542588:  
2025-01-18 19:09:49.542588: Epoch 76 
2025-01-18 19:09:49.548603: Current learning rate: 0.00722 
2025-01-18 19:10:21.440431: train_loss -0.7965 
2025-01-18 19:10:21.442011: val_loss -0.4799 
2025-01-18 19:10:21.448639: Pseudo dice [np.float32(0.7055), np.float32(0.2634)] 
2025-01-18 19:10:21.451149: Epoch time: 31.9 s 
2025-01-18 19:10:22.022306:  
2025-01-18 19:10:22.022306: Epoch 77 
2025-01-18 19:10:22.028370: Current learning rate: 0.00718 
2025-01-18 19:10:53.912172: train_loss -0.8077 
2025-01-18 19:10:53.913681: val_loss -0.5183 
2025-01-18 19:10:53.919580: Pseudo dice [np.float32(0.7289), np.float32(0.358)] 
2025-01-18 19:10:53.924132: Epoch time: 31.89 s 
2025-01-18 19:10:54.499060:  
2025-01-18 19:10:54.499060: Epoch 78 
2025-01-18 19:10:54.505143: Current learning rate: 0.00714 
2025-01-18 19:11:26.385522: train_loss -0.8043 
2025-01-18 19:11:26.386526: val_loss -0.5382 
2025-01-18 19:11:26.392128: Pseudo dice [np.float32(0.7264), np.float32(0.4286)] 
2025-01-18 19:11:26.396702: Epoch time: 31.89 s 
2025-01-18 19:11:26.979480:  
2025-01-18 19:11:26.979480: Epoch 79 
2025-01-18 19:11:26.984493: Current learning rate: 0.0071 
2025-01-18 19:11:58.869940: train_loss -0.8075 
2025-01-18 19:11:58.870443: val_loss -0.4822 
2025-01-18 19:11:58.876016: Pseudo dice [np.float32(0.7067), np.float32(0.3666)] 
2025-01-18 19:11:58.880113: Epoch time: 31.89 s 
2025-01-18 19:11:59.450996:  
2025-01-18 19:11:59.450996: Epoch 80 
2025-01-18 19:11:59.457015: Current learning rate: 0.00707 
2025-01-18 19:12:31.346355: train_loss -0.8242 
2025-01-18 19:12:31.347875: val_loss -0.5218 
2025-01-18 19:12:31.353932: Pseudo dice [np.float32(0.7413), np.float32(0.4278)] 
2025-01-18 19:12:31.357181: Epoch time: 31.9 s 
2025-01-18 19:12:32.086564:  
2025-01-18 19:12:32.086564: Epoch 81 
2025-01-18 19:12:32.093127: Current learning rate: 0.00703 
2025-01-18 19:13:03.990804: train_loss -0.8039 
2025-01-18 19:13:03.991805: val_loss -0.5027 
2025-01-18 19:13:03.997327: Pseudo dice [np.float32(0.7233), np.float32(0.3397)] 
2025-01-18 19:13:04.001345: Epoch time: 31.91 s 
2025-01-18 19:13:04.577191:  
2025-01-18 19:13:04.577191: Epoch 82 
2025-01-18 19:13:04.582323: Current learning rate: 0.00699 
2025-01-18 19:13:36.466110: train_loss -0.8187 
2025-01-18 19:13:36.466110: val_loss -0.5043 
2025-01-18 19:13:36.473213: Pseudo dice [np.float32(0.7094), np.float32(0.357)] 
2025-01-18 19:13:36.476249: Epoch time: 31.89 s 
2025-01-18 19:13:37.037384:  
2025-01-18 19:13:37.038388: Epoch 83 
2025-01-18 19:13:37.044509: Current learning rate: 0.00696 
2025-01-18 19:14:08.934370: train_loss -0.7956 
2025-01-18 19:14:08.934370: val_loss -0.5098 
2025-01-18 19:14:08.941890: Pseudo dice [np.float32(0.7269), np.float32(0.4163)] 
2025-01-18 19:14:08.945400: Epoch time: 31.9 s 
2025-01-18 19:14:09.491215:  
2025-01-18 19:14:09.491215: Epoch 84 
2025-01-18 19:14:09.496767: Current learning rate: 0.00692 
2025-01-18 19:14:41.393767: train_loss -0.8122 
2025-01-18 19:14:41.394767: val_loss -0.4524 
2025-01-18 19:14:41.400325: Pseudo dice [np.float32(0.7171), np.float32(0.2924)] 
2025-01-18 19:14:41.403834: Epoch time: 31.9 s 
2025-01-18 19:14:41.949724:  
2025-01-18 19:14:41.949724: Epoch 85 
2025-01-18 19:14:41.956328: Current learning rate: 0.00688 
2025-01-18 19:15:13.844980: train_loss -0.8193 
2025-01-18 19:15:13.845482: val_loss -0.4879 
2025-01-18 19:15:13.852586: Pseudo dice [np.float32(0.7234), np.float32(0.3176)] 
2025-01-18 19:15:13.856127: Epoch time: 31.9 s 
2025-01-18 19:15:14.403085:  
2025-01-18 19:15:14.403588: Epoch 86 
2025-01-18 19:15:14.408599: Current learning rate: 0.00684 
2025-01-18 19:15:46.300148: train_loss -0.8235 
2025-01-18 19:15:46.301155: val_loss -0.5091 
2025-01-18 19:15:46.307166: Pseudo dice [np.float32(0.7156), np.float32(0.3825)] 
2025-01-18 19:15:46.311180: Epoch time: 31.9 s 
2025-01-18 19:15:46.855233:  
2025-01-18 19:15:46.855233: Epoch 87 
2025-01-18 19:15:46.860792: Current learning rate: 0.0068 
2025-01-18 19:16:18.736971: train_loss -0.8225 
2025-01-18 19:16:18.737476: val_loss -0.4949 
2025-01-18 19:16:18.743001: Pseudo dice [np.float32(0.7139), np.float32(0.3622)] 
2025-01-18 19:16:18.747029: Epoch time: 31.88 s 
2025-01-18 19:16:19.288326:  
2025-01-18 19:16:19.289330: Epoch 88 
2025-01-18 19:16:19.293878: Current learning rate: 0.00677 
2025-01-18 19:16:51.169628: train_loss -0.8284 
2025-01-18 19:16:51.169628: val_loss -0.4694 
2025-01-18 19:16:51.175646: Pseudo dice [np.float32(0.7289), np.float32(0.3034)] 
2025-01-18 19:16:51.179656: Epoch time: 31.88 s 
2025-01-18 19:16:51.879564:  
2025-01-18 19:16:51.879564: Epoch 89 
2025-01-18 19:16:51.885108: Current learning rate: 0.00673 
2025-01-18 19:17:23.767022: train_loss -0.8388 
2025-01-18 19:17:23.767022: val_loss -0.4803 
2025-01-18 19:17:23.773059: Pseudo dice [np.float32(0.7287), np.float32(0.3107)] 
2025-01-18 19:17:23.776266: Epoch time: 31.89 s 
2025-01-18 19:17:24.324896:  
2025-01-18 19:17:24.324896: Epoch 90 
2025-01-18 19:17:24.330479: Current learning rate: 0.00669 
2025-01-18 19:17:56.210701: train_loss -0.8341 
2025-01-18 19:17:56.210701: val_loss -0.5143 
2025-01-18 19:17:56.217214: Pseudo dice [np.float32(0.7207), np.float32(0.4365)] 
2025-01-18 19:17:56.219720: Epoch time: 31.89 s 
2025-01-18 19:17:56.763652:  
2025-01-18 19:17:56.763652: Epoch 91 
2025-01-18 19:17:56.769196: Current learning rate: 0.00665 
2025-01-18 19:18:28.642204: train_loss -0.825 
2025-01-18 19:18:28.643284: val_loss -0.5238 
2025-01-18 19:18:28.648854: Pseudo dice [np.float32(0.7301), np.float32(0.4122)] 
2025-01-18 19:18:28.652398: Epoch time: 31.88 s 
2025-01-18 19:18:29.200394:  
2025-01-18 19:18:29.200394: Epoch 92 
2025-01-18 19:18:29.206411: Current learning rate: 0.00662 
2025-01-18 19:19:01.091275: train_loss -0.8339 
2025-01-18 19:19:01.092282: val_loss -0.4829 
2025-01-18 19:19:01.098293: Pseudo dice [np.float32(0.7153), np.float32(0.3221)] 
2025-01-18 19:19:01.101301: Epoch time: 31.89 s 
2025-01-18 19:19:01.651212:  
2025-01-18 19:19:01.651721: Epoch 93 
2025-01-18 19:19:01.656774: Current learning rate: 0.00658 
2025-01-18 19:19:33.552432: train_loss -0.8368 
2025-01-18 19:19:33.552432: val_loss -0.5152 
2025-01-18 19:19:33.558475: Pseudo dice [np.float32(0.7315), np.float32(0.3525)] 
2025-01-18 19:19:33.562581: Epoch time: 31.9 s 
2025-01-18 19:19:34.110615:  
2025-01-18 19:19:34.110615: Epoch 94 
2025-01-18 19:19:34.116180: Current learning rate: 0.00654 
2025-01-18 19:20:06.001569: train_loss -0.8487 
2025-01-18 19:20:06.002077: val_loss -0.4795 
2025-01-18 19:20:06.008658: Pseudo dice [np.float32(0.7108), np.float32(0.3586)] 
2025-01-18 19:20:06.011716: Epoch time: 31.89 s 
2025-01-18 19:20:06.554186:  
2025-01-18 19:20:06.554689: Epoch 95 
2025-01-18 19:20:06.559701: Current learning rate: 0.0065 
2025-01-18 19:20:38.445813: train_loss -0.8304 
2025-01-18 19:20:38.446813: val_loss -0.4441 
2025-01-18 19:20:38.452330: Pseudo dice [np.float32(0.7025), np.float32(0.2837)] 
2025-01-18 19:20:38.455841: Epoch time: 31.89 s 
2025-01-18 19:20:39.008574:  
2025-01-18 19:20:39.009077: Epoch 96 
2025-01-18 19:20:39.015094: Current learning rate: 0.00647 
2025-01-18 19:21:10.908525: train_loss -0.8416 
2025-01-18 19:21:10.908525: val_loss -0.486 
2025-01-18 19:21:10.914549: Pseudo dice [np.float32(0.7277), np.float32(0.3712)] 
2025-01-18 19:21:10.918071: Epoch time: 31.9 s 
2025-01-18 19:21:11.634600:  
2025-01-18 19:21:11.635109: Epoch 97 
2025-01-18 19:21:11.640675: Current learning rate: 0.00643 
2025-01-18 19:21:43.531631: train_loss -0.8427 
2025-01-18 19:21:43.532133: val_loss -0.4765 
2025-01-18 19:21:43.538163: Pseudo dice [np.float32(0.728), np.float32(0.3249)] 
2025-01-18 19:21:43.541710: Epoch time: 31.9 s 
2025-01-18 19:21:44.092257:  
2025-01-18 19:21:44.092760: Epoch 98 
2025-01-18 19:21:44.097779: Current learning rate: 0.00639 
2025-01-18 19:22:15.987991: train_loss -0.845 
2025-01-18 19:22:15.988497: val_loss -0.483 
2025-01-18 19:22:15.994593: Pseudo dice [np.float32(0.7245), np.float32(0.3274)] 
2025-01-18 19:22:15.997134: Epoch time: 31.9 s 
2025-01-18 19:22:16.550426:  
2025-01-18 19:22:16.550426: Epoch 99 
2025-01-18 19:22:16.555438: Current learning rate: 0.00635 
2025-01-18 19:22:48.429684: train_loss -0.84 
2025-01-18 19:22:48.430685: val_loss -0.4941 
2025-01-18 19:22:48.436199: Pseudo dice [np.float32(0.7206), np.float32(0.3857)] 
2025-01-18 19:22:48.439712: Epoch time: 31.88 s 
2025-01-18 19:22:49.257285:  
2025-01-18 19:22:49.257285: Epoch 100 
2025-01-18 19:22:49.261795: Current learning rate: 0.00631 
2025-01-18 19:23:21.144071: train_loss -0.836 
2025-01-18 19:23:21.144621: val_loss -0.5315 
2025-01-18 19:23:21.149664: Pseudo dice [np.float32(0.715), np.float32(0.4381)] 
2025-01-18 19:23:21.153172: Epoch time: 31.89 s 
2025-01-18 19:23:21.705320:  
2025-01-18 19:23:21.706324: Epoch 101 
2025-01-18 19:23:21.712890: Current learning rate: 0.00628 
2025-01-18 19:23:53.596847: train_loss -0.8283 
2025-01-18 19:23:53.596847: val_loss -0.5064 
2025-01-18 19:23:53.603364: Pseudo dice [np.float32(0.6873), np.float32(0.4114)] 
2025-01-18 19:23:53.607889: Epoch time: 31.89 s 
2025-01-18 19:23:54.165109:  
2025-01-18 19:23:54.165667: Epoch 102 
2025-01-18 19:23:54.170830: Current learning rate: 0.00624 
2025-01-18 19:24:26.054981: train_loss -0.7861 
2025-01-18 19:24:26.056484: val_loss -0.4661 
2025-01-18 19:24:26.060502: Pseudo dice [np.float32(0.7243), np.float32(0.2993)] 
2025-01-18 19:24:26.064015: Epoch time: 31.89 s 
2025-01-18 19:24:26.619702:  
2025-01-18 19:24:26.620703: Epoch 103 
2025-01-18 19:24:26.625805: Current learning rate: 0.0062 
2025-01-18 19:24:58.488153: train_loss -0.8052 
2025-01-18 19:24:58.488658: val_loss -0.4784 
2025-01-18 19:24:58.494678: Pseudo dice [np.float32(0.7063), np.float32(0.3271)] 
2025-01-18 19:24:58.496756: Epoch time: 31.87 s 
2025-01-18 19:24:59.059204:  
2025-01-18 19:24:59.059707: Epoch 104 
2025-01-18 19:24:59.065371: Current learning rate: 0.00616 
2025-01-18 19:25:30.941790: train_loss -0.8087 
2025-01-18 19:25:30.942794: val_loss -0.451 
2025-01-18 19:25:30.948310: Pseudo dice [np.float32(0.7225), np.float32(0.2575)] 
2025-01-18 19:25:30.951822: Epoch time: 31.88 s 
2025-01-18 19:25:31.512846:  
2025-01-18 19:25:31.512846: Epoch 105 
2025-01-18 19:25:31.518388: Current learning rate: 0.00612 
2025-01-18 19:26:03.398862: train_loss -0.8293 
2025-01-18 19:26:03.399867: val_loss -0.489 
2025-01-18 19:26:03.405486: Pseudo dice [np.float32(0.7261), np.float32(0.2959)] 
2025-01-18 19:26:03.409513: Epoch time: 31.89 s 
2025-01-18 19:26:04.126215:  
2025-01-18 19:26:04.126215: Epoch 106 
2025-01-18 19:26:04.132314: Current learning rate: 0.00609 
2025-01-18 19:26:36.001014: train_loss -0.8288 
2025-01-18 19:26:36.002014: val_loss -0.4519 
2025-01-18 19:26:36.007601: Pseudo dice [np.float32(0.74), np.float32(0.2204)] 
2025-01-18 19:26:36.011110: Epoch time: 31.88 s 
2025-01-18 19:26:36.566786:  
2025-01-18 19:26:36.567288: Epoch 107 
2025-01-18 19:26:36.573302: Current learning rate: 0.00605 
2025-01-18 19:27:08.444063: train_loss -0.8194 
2025-01-18 19:27:08.445063: val_loss -0.484 
2025-01-18 19:27:08.452581: Pseudo dice [np.float32(0.7266), np.float32(0.3082)] 
2025-01-18 19:27:08.456593: Epoch time: 31.88 s 
2025-01-18 19:27:09.014841:  
2025-01-18 19:27:09.014841: Epoch 108 
2025-01-18 19:27:09.020168: Current learning rate: 0.00601 
2025-01-18 19:27:40.906204: train_loss -0.8442 
2025-01-18 19:27:40.906717: val_loss -0.4866 
2025-01-18 19:27:40.912740: Pseudo dice [np.float32(0.7134), np.float32(0.3174)] 
2025-01-18 19:27:40.916745: Epoch time: 31.89 s 
2025-01-18 19:27:41.480142:  
2025-01-18 19:27:41.480142: Epoch 109 
2025-01-18 19:27:41.486175: Current learning rate: 0.00597 
2025-01-18 19:28:13.368492: train_loss -0.8454 
2025-01-18 19:28:13.368994: val_loss -0.4703 
2025-01-18 19:28:13.374583: Pseudo dice [np.float32(0.7338), np.float32(0.2699)] 
2025-01-18 19:28:13.378093: Epoch time: 31.89 s 
2025-01-18 19:28:13.934310:  
2025-01-18 19:28:13.934310: Epoch 110 
2025-01-18 19:28:13.939344: Current learning rate: 0.00593 
2025-01-18 19:28:45.838561: train_loss -0.8448 
2025-01-18 19:28:45.839078: val_loss -0.4692 
2025-01-18 19:28:45.845141: Pseudo dice [np.float32(0.7032), np.float32(0.3062)] 
2025-01-18 19:28:45.848684: Epoch time: 31.91 s 
2025-01-18 19:28:46.405007:  
2025-01-18 19:28:46.406006: Epoch 111 
2025-01-18 19:28:46.411519: Current learning rate: 0.0059 
2025-01-18 19:29:18.293535: train_loss -0.85 
2025-01-18 19:29:18.294538: val_loss -0.5105 
2025-01-18 19:29:18.301116: Pseudo dice [np.float32(0.7215), np.float32(0.3849)] 
2025-01-18 19:29:18.304643: Epoch time: 31.89 s 
2025-01-18 19:29:18.859155:  
2025-01-18 19:29:18.859155: Epoch 112 
2025-01-18 19:29:18.865230: Current learning rate: 0.00586 
2025-01-18 19:29:50.758938: train_loss -0.8474 
2025-01-18 19:29:50.760440: val_loss -0.533 
2025-01-18 19:29:50.766488: Pseudo dice [np.float32(0.7156), np.float32(0.4148)] 
2025-01-18 19:29:50.769526: Epoch time: 31.9 s 
2025-01-18 19:29:51.320311:  
2025-01-18 19:29:51.320311: Epoch 113 
2025-01-18 19:29:51.326331: Current learning rate: 0.00582 
2025-01-18 19:30:23.214358: train_loss -0.8318 
2025-01-18 19:30:23.214915: val_loss -0.5282 
2025-01-18 19:30:23.221025: Pseudo dice [np.float32(0.7322), np.float32(0.3876)] 
2025-01-18 19:30:23.225584: Epoch time: 31.89 s 
2025-01-18 19:30:23.935546:  
2025-01-18 19:30:23.935546: Epoch 114 
2025-01-18 19:30:23.941110: Current learning rate: 0.00578 
2025-01-18 19:30:55.817921: train_loss -0.8373 
2025-01-18 19:30:55.818926: val_loss -0.5231 
2025-01-18 19:30:55.825443: Pseudo dice [np.float32(0.7274), np.float32(0.3967)] 
2025-01-18 19:30:55.828955: Epoch time: 31.88 s 
2025-01-18 19:30:56.376790:  
2025-01-18 19:30:56.376790: Epoch 115 
2025-01-18 19:30:56.382332: Current learning rate: 0.00574 
2025-01-18 19:31:28.256776: train_loss -0.8445 
2025-01-18 19:31:28.257781: val_loss -0.4873 
2025-01-18 19:31:28.262827: Pseudo dice [np.float32(0.7246), np.float32(0.3693)] 
2025-01-18 19:31:28.266836: Epoch time: 31.88 s 
2025-01-18 19:31:28.827095:  
2025-01-18 19:31:28.827095: Epoch 116 
2025-01-18 19:31:28.833682: Current learning rate: 0.0057 
2025-01-18 19:32:00.723167: train_loss -0.847 
2025-01-18 19:32:00.723167: val_loss -0.5002 
2025-01-18 19:32:00.729706: Pseudo dice [np.float32(0.7229), np.float32(0.4012)] 
2025-01-18 19:32:00.733214: Epoch time: 31.9 s 
2025-01-18 19:32:01.287203:  
2025-01-18 19:32:01.288202: Epoch 117 
2025-01-18 19:32:01.293303: Current learning rate: 0.00567 
2025-01-18 19:32:33.162962: train_loss -0.8541 
2025-01-18 19:32:33.162962: val_loss -0.4747 
2025-01-18 19:32:33.169632: Pseudo dice [np.float32(0.7196), np.float32(0.2758)] 
2025-01-18 19:32:33.173141: Epoch time: 31.88 s 
2025-01-18 19:32:33.734691:  
2025-01-18 19:32:33.734691: Epoch 118 
2025-01-18 19:32:33.740707: Current learning rate: 0.00563 
2025-01-18 19:33:05.634209: train_loss -0.8498 
2025-01-18 19:33:05.634209: val_loss -0.5098 
2025-01-18 19:33:05.640228: Pseudo dice [np.float32(0.7182), np.float32(0.3661)] 
2025-01-18 19:33:05.644238: Epoch time: 31.9 s 
2025-01-18 19:33:06.210713:  
2025-01-18 19:33:06.211221: Epoch 119 
2025-01-18 19:33:06.216270: Current learning rate: 0.00559 
2025-01-18 19:33:38.111054: train_loss -0.8537 
2025-01-18 19:33:38.111054: val_loss -0.5118 
2025-01-18 19:33:38.117624: Pseudo dice [np.float32(0.7328), np.float32(0.3288)] 
2025-01-18 19:33:38.121179: Epoch time: 31.9 s 
2025-01-18 19:33:38.673288:  
2025-01-18 19:33:38.673288: Epoch 120 
2025-01-18 19:33:38.678803: Current learning rate: 0.00555 
2025-01-18 19:34:10.592951: train_loss -0.8654 
2025-01-18 19:34:10.593953: val_loss -0.4523 
2025-01-18 19:34:10.600471: Pseudo dice [np.float32(0.7324), np.float32(0.1983)] 
2025-01-18 19:34:10.604445: Epoch time: 31.92 s 
2025-01-18 19:34:11.164181:  
2025-01-18 19:34:11.164684: Epoch 121 
2025-01-18 19:34:11.169694: Current learning rate: 0.00551 
2025-01-18 19:34:43.077884: train_loss -0.8691 
2025-01-18 19:34:43.078398: val_loss -0.4956 
2025-01-18 19:34:43.084462: Pseudo dice [np.float32(0.7288), np.float32(0.3025)] 
2025-01-18 19:34:43.087283: Epoch time: 31.91 s 
2025-01-18 19:34:43.801035:  
2025-01-18 19:34:43.801035: Epoch 122 
2025-01-18 19:34:43.807127: Current learning rate: 0.00547 
2025-01-18 19:35:15.711030: train_loss -0.8618 
2025-01-18 19:35:15.711030: val_loss -0.4292 
2025-01-18 19:35:15.717040: Pseudo dice [np.float32(0.7099), np.float32(0.1928)] 
2025-01-18 19:35:15.720051: Epoch time: 31.91 s 
2025-01-18 19:35:16.284447:  
2025-01-18 19:35:16.284447: Epoch 123 
2025-01-18 19:35:16.289460: Current learning rate: 0.00544 
2025-01-18 19:35:48.178718: train_loss -0.8686 
2025-01-18 19:35:48.179721: val_loss -0.5138 
2025-01-18 19:35:48.185261: Pseudo dice [np.float32(0.7453), np.float32(0.3455)] 
2025-01-18 19:35:48.189270: Epoch time: 31.9 s 
2025-01-18 19:35:48.762570:  
2025-01-18 19:35:48.763569: Epoch 124 
2025-01-18 19:35:48.769643: Current learning rate: 0.0054 
2025-01-18 19:36:20.666970: train_loss -0.876 
2025-01-18 19:36:20.666970: val_loss -0.5056 
2025-01-18 19:36:20.673490: Pseudo dice [np.float32(0.7227), np.float32(0.312)] 
2025-01-18 19:36:20.677001: Epoch time: 31.9 s 
2025-01-18 19:36:21.230746:  
2025-01-18 19:36:21.230746: Epoch 125 
2025-01-18 19:36:21.236297: Current learning rate: 0.00536 
2025-01-18 19:36:53.123926: train_loss -0.8684 
2025-01-18 19:36:53.123926: val_loss -0.483 
2025-01-18 19:36:53.129942: Pseudo dice [np.float32(0.7027), np.float32(0.3151)] 
2025-01-18 19:36:53.133450: Epoch time: 31.89 s 
2025-01-18 19:36:53.688489:  
2025-01-18 19:36:53.688489: Epoch 126 
2025-01-18 19:36:53.694506: Current learning rate: 0.00532 
2025-01-18 19:37:25.582977: train_loss -0.8696 
2025-01-18 19:37:25.583487: val_loss -0.5008 
2025-01-18 19:37:25.589502: Pseudo dice [np.float32(0.7355), np.float32(0.2938)] 
2025-01-18 19:37:25.593009: Epoch time: 31.9 s 
2025-01-18 19:37:26.151320:  
2025-01-18 19:37:26.152324: Epoch 127 
2025-01-18 19:37:26.156886: Current learning rate: 0.00528 
2025-01-18 19:37:58.052748: train_loss -0.8733 
2025-01-18 19:37:58.054327: val_loss -0.4766 
2025-01-18 19:37:58.059902: Pseudo dice [np.float32(0.7325), np.float32(0.2671)] 
2025-01-18 19:37:58.063412: Epoch time: 31.9 s 
2025-01-18 19:37:58.624208:  
2025-01-18 19:37:58.624208: Epoch 128 
2025-01-18 19:37:58.629736: Current learning rate: 0.00524 
2025-01-18 19:38:30.528508: train_loss -0.8752 
2025-01-18 19:38:30.529507: val_loss -0.518 
2025-01-18 19:38:30.535074: Pseudo dice [np.float32(0.7361), np.float32(0.3581)] 
2025-01-18 19:38:30.538613: Epoch time: 31.91 s 
2025-01-18 19:38:31.097714:  
2025-01-18 19:38:31.097714: Epoch 129 
2025-01-18 19:38:31.103742: Current learning rate: 0.0052 
2025-01-18 19:39:02.992460: train_loss -0.8739 
2025-01-18 19:39:02.992460: val_loss -0.5108 
2025-01-18 19:39:02.998519: Pseudo dice [np.float32(0.7255), np.float32(0.3843)] 
2025-01-18 19:39:03.001562: Epoch time: 31.9 s 
2025-01-18 19:39:03.714278:  
2025-01-18 19:39:03.714278: Epoch 130 
2025-01-18 19:39:03.719310: Current learning rate: 0.00517 
2025-01-18 19:39:35.616784: train_loss -0.8757 
2025-01-18 19:39:35.617288: val_loss -0.5055 
2025-01-18 19:39:35.623302: Pseudo dice [np.float32(0.7219), np.float32(0.344)] 
2025-01-18 19:39:35.626811: Epoch time: 31.9 s 
2025-01-18 19:39:36.191142:  
2025-01-18 19:39:36.191142: Epoch 131 
2025-01-18 19:39:36.196193: Current learning rate: 0.00513 
2025-01-18 19:40:08.095250: train_loss -0.8758 
2025-01-18 19:40:08.095250: val_loss -0.4435 
2025-01-18 19:40:08.101832: Pseudo dice [np.float32(0.7069), np.float32(0.2302)] 
2025-01-18 19:40:08.105878: Epoch time: 31.91 s 
2025-01-18 19:40:08.660839:  
2025-01-18 19:40:08.660839: Epoch 132 
2025-01-18 19:40:08.667437: Current learning rate: 0.00509 
2025-01-18 19:40:40.564617: train_loss -0.8701 
2025-01-18 19:40:40.565120: val_loss -0.4672 
2025-01-18 19:40:40.571660: Pseudo dice [np.float32(0.7113), np.float32(0.2809)] 
2025-01-18 19:40:40.574198: Epoch time: 31.9 s 
2025-01-18 19:40:41.134088:  
2025-01-18 19:40:41.134590: Epoch 133 
2025-01-18 19:40:41.139600: Current learning rate: 0.00505 
2025-01-18 19:41:13.030002: train_loss -0.8774 
2025-01-18 19:41:13.030515: val_loss -0.4389 
2025-01-18 19:41:13.036117: Pseudo dice [np.float32(0.7082), np.float32(0.2302)] 
2025-01-18 19:41:13.039682: Epoch time: 31.9 s 
2025-01-18 19:41:13.607546:  
2025-01-18 19:41:13.608049: Epoch 134 
2025-01-18 19:41:13.613593: Current learning rate: 0.00501 
2025-01-18 19:41:45.511460: train_loss -0.8497 
2025-01-18 19:41:45.512462: val_loss -0.4787 
2025-01-18 19:41:45.518990: Pseudo dice [np.float32(0.6977), np.float32(0.3861)] 
2025-01-18 19:41:45.520996: Epoch time: 31.9 s 
2025-01-18 19:41:46.090049:  
2025-01-18 19:41:46.090049: Epoch 135 
2025-01-18 19:41:46.095060: Current learning rate: 0.00497 
2025-01-18 19:42:17.991490: train_loss -0.8588 
2025-01-18 19:42:17.992490: val_loss -0.5474 
2025-01-18 19:42:17.997916: Pseudo dice [np.float32(0.7369), np.float32(0.4466)] 
2025-01-18 19:42:18.002436: Epoch time: 31.9 s 
2025-01-18 19:42:18.574635:  
2025-01-18 19:42:18.575636: Epoch 136 
2025-01-18 19:42:18.580715: Current learning rate: 0.00493 
2025-01-18 19:42:50.498306: train_loss -0.8636 
2025-01-18 19:42:50.499809: val_loss -0.4817 
2025-01-18 19:42:50.505378: Pseudo dice [np.float32(0.713), np.float32(0.3034)] 
2025-01-18 19:42:50.508641: Epoch time: 31.92 s 
2025-01-18 19:42:51.074996:  
2025-01-18 19:42:51.074996: Epoch 137 
2025-01-18 19:42:51.081583: Current learning rate: 0.00489 
2025-01-18 19:43:22.991259: train_loss -0.8652 
2025-01-18 19:43:22.992265: val_loss -0.5127 
2025-01-18 19:43:22.998779: Pseudo dice [np.float32(0.7172), np.float32(0.3579)] 
2025-01-18 19:43:23.002291: Epoch time: 31.92 s 
2025-01-18 19:43:23.727100:  
2025-01-18 19:43:23.727100: Epoch 138 
2025-01-18 19:43:23.732111: Current learning rate: 0.00485 
2025-01-18 19:43:55.625365: train_loss -0.866 
2025-01-18 19:43:55.625365: val_loss -0.492 
2025-01-18 19:43:55.632002: Pseudo dice [np.float32(0.7182), np.float32(0.3335)] 
2025-01-18 19:43:55.635114: Epoch time: 31.9 s 
2025-01-18 19:43:56.210134:  
2025-01-18 19:43:56.210134: Epoch 139 
2025-01-18 19:43:56.216244: Current learning rate: 0.00482 
2025-01-18 19:44:28.081033: train_loss -0.8639 
2025-01-18 19:44:28.082552: val_loss -0.4931 
2025-01-18 19:44:28.089081: Pseudo dice [np.float32(0.7244), np.float32(0.3598)] 
2025-01-18 19:44:28.092119: Epoch time: 31.87 s 
2025-01-18 19:44:28.666775:  
2025-01-18 19:44:28.667779: Epoch 140 
2025-01-18 19:44:28.672807: Current learning rate: 0.00478 
2025-01-18 19:45:00.559290: train_loss -0.8721 
2025-01-18 19:45:00.559798: val_loss -0.4987 
2025-01-18 19:45:00.565452: Pseudo dice [np.float32(0.7201), np.float32(0.3064)] 
2025-01-18 19:45:00.569963: Epoch time: 31.89 s 
2025-01-18 19:45:01.139976:  
2025-01-18 19:45:01.139976: Epoch 141 
2025-01-18 19:45:01.146044: Current learning rate: 0.00474 
2025-01-18 19:45:33.032751: train_loss -0.8582 
2025-01-18 19:45:33.033753: val_loss -0.5194 
2025-01-18 19:45:33.040278: Pseudo dice [np.float32(0.7285), np.float32(0.343)] 
2025-01-18 19:45:33.043785: Epoch time: 31.89 s 
2025-01-18 19:45:33.615216:  
2025-01-18 19:45:33.616219: Epoch 142 
2025-01-18 19:45:33.621122: Current learning rate: 0.0047 
2025-01-18 19:46:05.508837: train_loss -0.8683 
2025-01-18 19:46:05.509350: val_loss -0.472 
2025-01-18 19:46:05.514490: Pseudo dice [np.float32(0.7082), np.float32(0.3058)] 
2025-01-18 19:46:05.517123: Epoch time: 31.89 s 
2025-01-18 19:46:06.094501:  
2025-01-18 19:46:06.094501: Epoch 143 
2025-01-18 19:46:06.100618: Current learning rate: 0.00466 
2025-01-18 19:46:37.980846: train_loss -0.8768 
2025-01-18 19:46:37.981349: val_loss -0.5159 
2025-01-18 19:46:37.987984: Pseudo dice [np.float32(0.7322), np.float32(0.3244)] 
2025-01-18 19:46:37.991102: Epoch time: 31.89 s 
2025-01-18 19:46:38.562023:  
2025-01-18 19:46:38.562526: Epoch 144 
2025-01-18 19:46:38.567538: Current learning rate: 0.00462 
2025-01-18 19:47:10.471315: train_loss -0.8874 
2025-01-18 19:47:10.471837: val_loss -0.4772 
2025-01-18 19:47:10.479359: Pseudo dice [np.float32(0.7317), np.float32(0.2692)] 
2025-01-18 19:47:10.482399: Epoch time: 31.91 s 
2025-01-18 19:47:11.049283:  
2025-01-18 19:47:11.050287: Epoch 145 
2025-01-18 19:47:11.054853: Current learning rate: 0.00458 
2025-01-18 19:47:42.948155: train_loss -0.8831 
2025-01-18 19:47:42.948155: val_loss -0.4673 
2025-01-18 19:47:42.955202: Pseudo dice [np.float32(0.6949), np.float32(0.2725)] 
2025-01-18 19:47:42.958812: Epoch time: 31.9 s 
2025-01-18 19:47:43.677618:  
2025-01-18 19:47:43.677618: Epoch 146 
2025-01-18 19:47:43.681644: Current learning rate: 0.00454 
2025-01-18 19:48:15.569735: train_loss -0.8881 
2025-01-18 19:48:15.570740: val_loss -0.4238 
2025-01-18 19:48:15.577298: Pseudo dice [np.float32(0.6845), np.float32(0.2353)] 
2025-01-18 19:48:15.580809: Epoch time: 31.89 s 
2025-01-18 19:48:16.145805:  
2025-01-18 19:48:16.145805: Epoch 147 
2025-01-18 19:48:16.151823: Current learning rate: 0.0045 
2025-01-18 19:48:48.034292: train_loss -0.8868 
2025-01-18 19:48:48.034812: val_loss -0.4769 
2025-01-18 19:48:48.040902: Pseudo dice [np.float32(0.726), np.float32(0.2712)] 
2025-01-18 19:48:48.044428: Epoch time: 31.89 s 
2025-01-18 19:48:48.617438:  
2025-01-18 19:48:48.617438: Epoch 148 
2025-01-18 19:48:48.623047: Current learning rate: 0.00446 
2025-01-18 19:49:20.508666: train_loss -0.8861 
2025-01-18 19:49:20.509669: val_loss -0.4689 
2025-01-18 19:49:20.516189: Pseudo dice [np.float32(0.7268), np.float32(0.2741)] 
2025-01-18 19:49:20.518744: Epoch time: 31.89 s 
2025-01-18 19:49:21.096283:  
2025-01-18 19:49:21.097286: Epoch 149 
2025-01-18 19:49:21.101851: Current learning rate: 0.00442 
2025-01-18 19:49:52.981162: train_loss -0.8835 
2025-01-18 19:49:52.981162: val_loss -0.4792 
2025-01-18 19:49:52.987388: Pseudo dice [np.float32(0.7025), np.float32(0.3324)] 
2025-01-18 19:49:52.990923: Epoch time: 31.88 s 
2025-01-18 19:49:53.807192:  
2025-01-18 19:49:53.808195: Epoch 150 
2025-01-18 19:49:53.812751: Current learning rate: 0.00438 
2025-01-18 19:50:25.700309: train_loss -0.8728 
2025-01-18 19:50:25.700309: val_loss -0.4524 
2025-01-18 19:50:25.706867: Pseudo dice [np.float32(0.724), np.float32(0.2391)] 
2025-01-18 19:50:25.710891: Epoch time: 31.89 s 
2025-01-18 19:50:26.275841:  
2025-01-18 19:50:26.275841: Epoch 151 
2025-01-18 19:50:26.282363: Current learning rate: 0.00434 
2025-01-18 19:50:58.179826: train_loss -0.877 
2025-01-18 19:50:58.180341: val_loss -0.4818 
2025-01-18 19:50:58.186878: Pseudo dice [np.float32(0.7176), np.float32(0.2603)] 
2025-01-18 19:50:58.190428: Epoch time: 31.9 s 
2025-01-18 19:50:58.763094:  
2025-01-18 19:50:58.763094: Epoch 152 
2025-01-18 19:50:58.768626: Current learning rate: 0.0043 
2025-01-18 19:51:30.654779: train_loss -0.882 
2025-01-18 19:51:30.654779: val_loss -0.507 
2025-01-18 19:51:30.660886: Pseudo dice [np.float32(0.7391), np.float32(0.3193)] 
2025-01-18 19:51:30.665423: Epoch time: 31.89 s 
2025-01-18 19:51:31.237763:  
2025-01-18 19:51:31.238761: Epoch 153 
2025-01-18 19:51:31.244398: Current learning rate: 0.00427 
2025-01-18 19:52:03.122110: train_loss -0.8727 
2025-01-18 19:52:03.123631: val_loss -0.4738 
2025-01-18 19:52:03.129666: Pseudo dice [np.float32(0.732), np.float32(0.3179)] 
2025-01-18 19:52:03.133480: Epoch time: 31.88 s 
2025-01-18 19:52:03.864132:  
2025-01-18 19:52:03.865131: Epoch 154 
2025-01-18 19:52:03.870646: Current learning rate: 0.00423 
2025-01-18 19:52:35.750457: train_loss -0.8723 
2025-01-18 19:52:35.750457: val_loss -0.52 
2025-01-18 19:52:35.757603: Pseudo dice [np.float32(0.7266), np.float32(0.3834)] 
2025-01-18 19:52:35.760650: Epoch time: 31.89 s 
2025-01-18 19:52:36.336255:  
2025-01-18 19:52:36.336255: Epoch 155 
2025-01-18 19:52:36.342827: Current learning rate: 0.00419 
2025-01-18 19:53:08.217515: train_loss -0.8901 
2025-01-18 19:53:08.219017: val_loss -0.4925 
2025-01-18 19:53:08.225034: Pseudo dice [np.float32(0.731), np.float32(0.3047)] 
2025-01-18 19:53:08.227541: Epoch time: 31.88 s 
2025-01-18 19:53:08.810688:  
2025-01-18 19:53:08.810688: Epoch 156 
2025-01-18 19:53:08.816202: Current learning rate: 0.00415 
2025-01-18 19:53:40.696265: train_loss -0.8838 
2025-01-18 19:53:40.696265: val_loss -0.4768 
2025-01-18 19:53:40.703299: Pseudo dice [np.float32(0.7197), np.float32(0.2964)] 
2025-01-18 19:53:40.706331: Epoch time: 31.89 s 
2025-01-18 19:53:41.289776:  
2025-01-18 19:53:41.290780: Epoch 157 
2025-01-18 19:53:41.296888: Current learning rate: 0.00411 
2025-01-18 19:54:13.162514: train_loss -0.8813 
2025-01-18 19:54:13.163018: val_loss -0.4646 
2025-01-18 19:54:13.170535: Pseudo dice [np.float32(0.6976), np.float32(0.3144)] 
2025-01-18 19:54:13.174617: Epoch time: 31.87 s 
2025-01-18 19:54:13.754807:  
2025-01-18 19:54:13.755810: Epoch 158 
2025-01-18 19:54:13.761905: Current learning rate: 0.00407 
2025-01-18 19:54:45.651273: train_loss -0.8854 
2025-01-18 19:54:45.652273: val_loss -0.4798 
2025-01-18 19:54:45.657830: Pseudo dice [np.float32(0.7268), np.float32(0.3068)] 
2025-01-18 19:54:45.662359: Epoch time: 31.9 s 
2025-01-18 19:54:46.234984:  
2025-01-18 19:54:46.235988: Epoch 159 
2025-01-18 19:54:46.240529: Current learning rate: 0.00403 
2025-01-18 19:55:18.121310: train_loss -0.8934 
2025-01-18 19:55:18.121814: val_loss -0.5174 
2025-01-18 19:55:18.129005: Pseudo dice [np.float32(0.7352), np.float32(0.4125)] 
2025-01-18 19:55:18.132514: Epoch time: 31.89 s 
2025-01-18 19:55:18.715650:  
2025-01-18 19:55:18.716650: Epoch 160 
2025-01-18 19:55:18.722166: Current learning rate: 0.00399 
2025-01-18 19:55:50.602686: train_loss -0.8903 
2025-01-18 19:55:50.602686: val_loss -0.4376 
2025-01-18 19:55:50.609205: Pseudo dice [np.float32(0.6919), np.float32(0.2973)] 
2025-01-18 19:55:50.612236: Epoch time: 31.89 s 
2025-01-18 19:55:51.345273:  
2025-01-18 19:55:51.345778: Epoch 161 
2025-01-18 19:55:51.350788: Current learning rate: 0.00395 
2025-01-18 19:56:23.221647: train_loss -0.9017 
2025-01-18 19:56:23.221647: val_loss -0.4783 
2025-01-18 19:56:23.228176: Pseudo dice [np.float32(0.6989), np.float32(0.3127)] 
2025-01-18 19:56:23.231727: Epoch time: 31.88 s 
2025-01-18 19:56:23.813513:  
2025-01-18 19:56:23.813513: Epoch 162 
2025-01-18 19:56:23.819562: Current learning rate: 0.00391 
2025-01-18 19:56:55.704082: train_loss -0.8999 
2025-01-18 19:56:55.705082: val_loss -0.4564 
2025-01-18 19:56:55.711224: Pseudo dice [np.float32(0.7315), np.float32(0.2456)] 
2025-01-18 19:56:55.713308: Epoch time: 31.89 s 
2025-01-18 19:56:56.289392:  
2025-01-18 19:56:56.289392: Epoch 163 
2025-01-18 19:56:56.295407: Current learning rate: 0.00387 
2025-01-18 19:57:28.179047: train_loss -0.8966 
2025-01-18 19:57:28.181074: val_loss -0.4992 
2025-01-18 19:57:28.187124: Pseudo dice [np.float32(0.7131), np.float32(0.3418)] 
2025-01-18 19:57:28.190667: Epoch time: 31.89 s 
2025-01-18 19:57:28.767092:  
2025-01-18 19:57:28.767594: Epoch 164 
2025-01-18 19:57:28.772606: Current learning rate: 0.00383 
2025-01-18 19:58:00.659732: train_loss -0.9004 
2025-01-18 19:58:00.660250: val_loss -0.4816 
2025-01-18 19:58:00.666781: Pseudo dice [np.float32(0.7211), np.float32(0.3203)] 
2025-01-18 19:58:00.670405: Epoch time: 31.89 s 
2025-01-18 19:58:01.234446:  
2025-01-18 19:58:01.235449: Epoch 165 
2025-01-18 19:58:01.240002: Current learning rate: 0.00379 
2025-01-18 19:58:33.114126: train_loss -0.9031 
2025-01-18 19:58:33.114634: val_loss -0.4993 
2025-01-18 19:58:33.120721: Pseudo dice [np.float32(0.7162), np.float32(0.3465)] 
2025-01-18 19:58:33.124823: Epoch time: 31.88 s 
2025-01-18 19:58:33.689075:  
2025-01-18 19:58:33.689075: Epoch 166 
2025-01-18 19:58:33.694121: Current learning rate: 0.00375 
2025-01-18 19:59:05.568674: train_loss -0.8985 
2025-01-18 19:59:05.570205: val_loss -0.4969 
2025-01-18 19:59:05.576891: Pseudo dice [np.float32(0.714), np.float32(0.3506)] 
2025-01-18 19:59:05.580410: Epoch time: 31.88 s 
2025-01-18 19:59:06.144452:  
2025-01-18 19:59:06.144955: Epoch 167 
2025-01-18 19:59:06.149965: Current learning rate: 0.00371 
2025-01-18 19:59:38.025988: train_loss -0.9003 
2025-01-18 19:59:38.025988: val_loss -0.4522 
2025-01-18 19:59:38.032506: Pseudo dice [np.float32(0.7047), np.float32(0.2699)] 
2025-01-18 19:59:38.035593: Epoch time: 31.88 s 
2025-01-18 19:59:38.608306:  
2025-01-18 19:59:38.608306: Epoch 168 
2025-01-18 19:59:38.613402: Current learning rate: 0.00367 
2025-01-18 20:00:10.517682: train_loss -0.898 
2025-01-18 20:00:10.518185: val_loss -0.4729 
2025-01-18 20:00:10.524200: Pseudo dice [np.float32(0.7169), np.float32(0.2983)] 
2025-01-18 20:00:10.528209: Epoch time: 31.91 s 
2025-01-18 20:00:11.258790:  
2025-01-18 20:00:11.259296: Epoch 169 
2025-01-18 20:00:11.264343: Current learning rate: 0.00363 
2025-01-18 20:00:43.157133: train_loss -0.9003 
2025-01-18 20:00:43.157133: val_loss -0.4588 
2025-01-18 20:00:43.163662: Pseudo dice [np.float32(0.7293), np.float32(0.2628)] 
2025-01-18 20:00:43.167201: Epoch time: 31.9 s 
2025-01-18 20:00:43.736356:  
2025-01-18 20:00:43.736859: Epoch 170 
2025-01-18 20:00:43.741369: Current learning rate: 0.00359 
2025-01-18 20:01:15.643487: train_loss -0.8982 
2025-01-18 20:01:15.643487: val_loss -0.47 
2025-01-18 20:01:15.651558: Pseudo dice [np.float32(0.7124), np.float32(0.3041)] 
2025-01-18 20:01:15.655102: Epoch time: 31.91 s 
2025-01-18 20:01:16.229031:  
2025-01-18 20:01:16.229535: Epoch 171 
2025-01-18 20:01:16.234547: Current learning rate: 0.00355 
2025-01-18 20:01:48.114201: train_loss -0.8899 
2025-01-18 20:01:48.114704: val_loss -0.4746 
2025-01-18 20:01:48.119716: Pseudo dice [np.float32(0.7088), np.float32(0.2808)] 
2025-01-18 20:01:48.124224: Epoch time: 31.89 s 
2025-01-18 20:01:48.698145:  
2025-01-18 20:01:48.699148: Epoch 172 
2025-01-18 20:01:48.705252: Current learning rate: 0.00351 
2025-01-18 20:02:20.607116: train_loss -0.8925 
2025-01-18 20:02:20.607116: val_loss -0.4965 
2025-01-18 20:02:20.614248: Pseudo dice [np.float32(0.7194), np.float32(0.3393)] 
2025-01-18 20:02:20.617286: Epoch time: 31.91 s 
2025-01-18 20:02:21.193252:  
2025-01-18 20:02:21.193252: Epoch 173 
2025-01-18 20:02:21.198835: Current learning rate: 0.00346 
2025-01-18 20:02:53.089274: train_loss -0.8952 
2025-01-18 20:02:53.090792: val_loss -0.4604 
2025-01-18 20:02:53.096597: Pseudo dice [np.float32(0.6857), np.float32(0.2816)] 
2025-01-18 20:02:53.100106: Epoch time: 31.9 s 
2025-01-18 20:02:53.670315:  
2025-01-18 20:02:53.670817: Epoch 174 
2025-01-18 20:02:53.676834: Current learning rate: 0.00342 
2025-01-18 20:03:25.623118: train_loss -0.9023 
2025-01-18 20:03:25.624121: val_loss -0.5057 
2025-01-18 20:03:25.630650: Pseudo dice [np.float32(0.7276), np.float32(0.3221)] 
2025-01-18 20:03:25.634168: Epoch time: 31.95 s 
2025-01-18 20:03:26.213927:  
2025-01-18 20:03:26.214932: Epoch 175 
2025-01-18 20:03:26.219476: Current learning rate: 0.00338 
2025-01-18 20:03:58.161921: train_loss -0.9076 
2025-01-18 20:03:58.162427: val_loss -0.4373 
2025-01-18 20:03:58.168444: Pseudo dice [np.float32(0.7138), np.float32(0.2493)] 
2025-01-18 20:03:58.171957: Epoch time: 31.95 s 
2025-01-18 20:03:58.752213:  
2025-01-18 20:03:58.752213: Epoch 176 
2025-01-18 20:03:58.757751: Current learning rate: 0.00334 
2025-01-18 20:04:30.790006: train_loss -0.9116 
2025-01-18 20:04:30.791012: val_loss -0.4941 
2025-01-18 20:04:30.796103: Pseudo dice [np.float32(0.7238), np.float32(0.3301)] 
2025-01-18 20:04:30.799181: Epoch time: 32.04 s 
2025-01-18 20:04:31.533227:  
2025-01-18 20:04:31.534230: Epoch 177 
2025-01-18 20:04:31.538830: Current learning rate: 0.0033 
2025-01-18 20:05:03.551060: train_loss -0.9025 
2025-01-18 20:05:03.551060: val_loss -0.4571 
2025-01-18 20:05:03.557085: Pseudo dice [np.float32(0.7272), np.float32(0.2876)] 
2025-01-18 20:05:03.560637: Epoch time: 32.02 s 
2025-01-18 20:05:04.139771:  
2025-01-18 20:05:04.140273: Epoch 178 
2025-01-18 20:05:04.145319: Current learning rate: 0.00326 
2025-01-18 20:05:37.727924: train_loss -0.9061 
2025-01-18 20:05:37.727924: val_loss -0.4647 
2025-01-18 20:05:37.733940: Pseudo dice [np.float32(0.6915), np.float32(0.2906)] 
2025-01-18 20:05:37.737446: Epoch time: 33.59 s 
2025-01-18 20:05:38.333160:  
2025-01-18 20:05:38.333160: Epoch 179 
2025-01-18 20:05:38.338766: Current learning rate: 0.00322 
2025-01-18 20:06:10.446357: train_loss -0.8999 
2025-01-18 20:06:10.446860: val_loss -0.4697 
2025-01-18 20:06:10.452875: Pseudo dice [np.float32(0.6993), np.float32(0.3278)] 
2025-01-18 20:06:10.456382: Epoch time: 32.11 s 
2025-01-18 20:06:11.044536:  
2025-01-18 20:06:11.044536: Epoch 180 
2025-01-18 20:06:11.050551: Current learning rate: 0.00318 
2025-01-18 20:06:43.145531: train_loss -0.9057 
2025-01-18 20:06:43.146034: val_loss -0.4676 
2025-01-18 20:06:43.151095: Pseudo dice [np.float32(0.7046), np.float32(0.2952)] 
2025-01-18 20:06:43.154134: Epoch time: 32.1 s 
2025-01-18 20:06:43.736490:  
2025-01-18 20:06:43.737495: Epoch 181 
2025-01-18 20:06:43.742034: Current learning rate: 0.00314 
2025-01-18 20:07:15.857271: train_loss -0.9123 
2025-01-18 20:07:15.857776: val_loss -0.4636 
2025-01-18 20:07:15.863803: Pseudo dice [np.float32(0.716), np.float32(0.3194)] 
2025-01-18 20:07:15.867321: Epoch time: 32.12 s 
2025-01-18 20:07:16.457456:  
2025-01-18 20:07:16.457965: Epoch 182 
2025-01-18 20:07:16.463565: Current learning rate: 0.0031 
2025-01-18 20:07:48.564737: train_loss -0.9135 
2025-01-18 20:07:48.565241: val_loss -0.4192 
2025-01-18 20:07:48.571265: Pseudo dice [np.float32(0.6914), np.float32(0.2385)] 
2025-01-18 20:07:48.574773: Epoch time: 32.11 s 
2025-01-18 20:07:49.157339:  
2025-01-18 20:07:49.157842: Epoch 183 
2025-01-18 20:07:49.162859: Current learning rate: 0.00306 
2025-01-18 20:08:22.047108: train_loss -0.905 
2025-01-18 20:08:22.047108: val_loss -0.4988 
2025-01-18 20:08:22.053773: Pseudo dice [np.float32(0.736), np.float32(0.285)] 
2025-01-18 20:08:22.057353: Epoch time: 32.89 s 
2025-01-18 20:08:22.775612:  
2025-01-18 20:08:22.775612: Epoch 184 
2025-01-18 20:08:22.780707: Current learning rate: 0.00302 
2025-01-18 20:08:55.460020: train_loss -0.9064 
2025-01-18 20:08:55.460020: val_loss -0.4662 
2025-01-18 20:08:55.466549: Pseudo dice [np.float32(0.732), np.float32(0.2505)] 
2025-01-18 20:08:55.470093: Epoch time: 32.69 s 
2025-01-18 20:08:56.027911:  
2025-01-18 20:08:56.027911: Epoch 185 
2025-01-18 20:08:56.032927: Current learning rate: 0.00297 
2025-01-18 20:09:28.553702: train_loss -0.9118 
2025-01-18 20:09:28.555209: val_loss -0.4536 
2025-01-18 20:09:28.561744: Pseudo dice [np.float32(0.6887), np.float32(0.2644)] 
2025-01-18 20:09:28.565356: Epoch time: 32.53 s 
2025-01-18 20:09:29.129069:  
2025-01-18 20:09:29.129069: Epoch 186 
2025-01-18 20:09:29.134611: Current learning rate: 0.00293 
2025-01-18 20:10:01.947705: train_loss -0.9108 
2025-01-18 20:10:01.947705: val_loss -0.4441 
2025-01-18 20:10:01.954228: Pseudo dice [np.float32(0.7183), np.float32(0.2394)] 
2025-01-18 20:10:01.957742: Epoch time: 32.82 s 
2025-01-18 20:10:02.522509:  
2025-01-18 20:10:02.523512: Epoch 187 
2025-01-18 20:10:02.528034: Current learning rate: 0.00289 
2025-01-18 20:10:36.031243: train_loss -0.9152 
2025-01-18 20:10:36.031745: val_loss -0.461 
2025-01-18 20:10:36.037837: Pseudo dice [np.float32(0.6987), np.float32(0.2663)] 
2025-01-18 20:10:36.041844: Epoch time: 33.51 s 
2025-01-18 20:10:36.598362:  
2025-01-18 20:10:36.598864: Epoch 188 
2025-01-18 20:10:36.603877: Current learning rate: 0.00285 
2025-01-18 20:11:09.076469: train_loss -0.9123 
2025-01-18 20:11:09.076974: val_loss -0.4866 
2025-01-18 20:11:09.084018: Pseudo dice [np.float32(0.7206), np.float32(0.3165)] 
2025-01-18 20:11:09.087570: Epoch time: 32.48 s 
2025-01-18 20:11:09.661470:  
2025-01-18 20:11:09.661974: Epoch 189 
2025-01-18 20:11:09.666986: Current learning rate: 0.00281 
2025-01-18 20:11:41.749676: train_loss -0.9138 
2025-01-18 20:11:41.750177: val_loss -0.4619 
2025-01-18 20:11:41.755739: Pseudo dice [np.float32(0.7065), np.float32(0.2763)] 
2025-01-18 20:11:41.762260: Epoch time: 32.09 s 
2025-01-18 20:11:42.316144:  
2025-01-18 20:11:42.316144: Epoch 190 
2025-01-18 20:11:42.322209: Current learning rate: 0.00277 
2025-01-18 20:12:15.577940: train_loss -0.9056 
2025-01-18 20:12:15.578942: val_loss -0.4942 
2025-01-18 20:12:15.587001: Pseudo dice [np.float32(0.7304), np.float32(0.3484)] 
2025-01-18 20:12:15.590512: Epoch time: 33.26 s 
2025-01-18 20:12:16.157403:  
2025-01-18 20:12:16.157905: Epoch 191 
2025-01-18 20:12:16.162921: Current learning rate: 0.00273 
2025-01-18 20:12:49.284961: train_loss -0.9143 
2025-01-18 20:12:49.285468: val_loss -0.4494 
2025-01-18 20:12:49.291481: Pseudo dice [np.float32(0.709), np.float32(0.242)] 
2025-01-18 20:12:49.296038: Epoch time: 33.13 s 
2025-01-18 20:12:50.053576:  
2025-01-18 20:12:50.054576: Epoch 192 
2025-01-18 20:12:50.060179: Current learning rate: 0.00268 
2025-01-18 20:13:22.453444: train_loss -0.9104 
2025-01-18 20:13:22.454984: val_loss -0.4529 
2025-01-18 20:13:22.461036: Pseudo dice [np.float32(0.7229), np.float32(0.3048)] 
2025-01-18 20:13:22.464590: Epoch time: 32.4 s 
2025-01-18 20:13:23.026725:  
2025-01-18 20:13:23.027244: Epoch 193 
2025-01-18 20:13:23.032254: Current learning rate: 0.00264 
2025-01-18 20:13:55.143846: train_loss -0.9196 
2025-01-18 20:13:55.145354: val_loss -0.489 
2025-01-18 20:13:55.150422: Pseudo dice [np.float32(0.7402), np.float32(0.3068)] 
2025-01-18 20:13:55.154574: Epoch time: 32.12 s 
2025-01-18 20:13:55.716535:  
2025-01-18 20:13:55.716535: Epoch 194 
2025-01-18 20:13:55.722551: Current learning rate: 0.0026 
2025-01-18 20:14:29.311021: train_loss -0.9139 
2025-01-18 20:14:29.311021: val_loss -0.455 
2025-01-18 20:14:29.317577: Pseudo dice [np.float32(0.7214), np.float32(0.2423)] 
2025-01-18 20:14:29.322238: Epoch time: 33.6 s 
2025-01-18 20:14:29.920923:  
2025-01-18 20:14:29.920923: Epoch 195 
2025-01-18 20:14:29.926959: Current learning rate: 0.00256 
2025-01-18 20:15:04.388967: train_loss -0.9118 
2025-01-18 20:15:04.388967: val_loss -0.4376 
2025-01-18 20:15:04.395568: Pseudo dice [np.float32(0.7069), np.float32(0.1964)] 
2025-01-18 20:15:04.399854: Epoch time: 34.47 s 
2025-01-18 20:15:04.976598:  
2025-01-18 20:15:04.976598: Epoch 196 
2025-01-18 20:15:04.981658: Current learning rate: 0.00252 
2025-01-18 20:15:38.208778: train_loss -0.9157 
2025-01-18 20:15:38.208778: val_loss -0.4751 
2025-01-18 20:15:38.215293: Pseudo dice [np.float32(0.734), np.float32(0.2679)] 
2025-01-18 20:15:38.218801: Epoch time: 33.23 s 
2025-01-18 20:15:38.789021:  
2025-01-18 20:15:38.789021: Epoch 197 
2025-01-18 20:15:38.794052: Current learning rate: 0.00248 
2025-01-18 20:16:11.847978: train_loss -0.9194 
2025-01-18 20:16:11.848492: val_loss -0.4761 
2025-01-18 20:16:11.854146: Pseudo dice [np.float32(0.7315), np.float32(0.3005)] 
2025-01-18 20:16:11.858190: Epoch time: 33.06 s 
2025-01-18 20:16:12.421639:  
2025-01-18 20:16:12.422143: Epoch 198 
2025-01-18 20:16:12.427181: Current learning rate: 0.00243 
2025-01-18 20:16:46.520044: train_loss -0.9169 
2025-01-18 20:16:46.520562: val_loss -0.4613 
2025-01-18 20:16:46.525630: Pseudo dice [np.float32(0.7292), np.float32(0.2572)] 
2025-01-18 20:16:46.529694: Epoch time: 34.1 s 
2025-01-18 20:16:47.089325:  
2025-01-18 20:16:47.090331: Epoch 199 
2025-01-18 20:16:47.096361: Current learning rate: 0.00239 
2025-01-18 20:17:20.106519: train_loss -0.9153 
2025-01-18 20:17:20.107023: val_loss -0.4848 
2025-01-18 20:17:20.113650: Pseudo dice [np.float32(0.7255), np.float32(0.2917)] 
2025-01-18 20:17:20.117224: Epoch time: 33.02 s 
2025-01-18 20:17:21.094842:  
2025-01-18 20:17:21.095846: Epoch 200 
2025-01-18 20:17:21.100883: Current learning rate: 0.00235 
2025-01-18 20:17:54.102502: train_loss -0.915 
2025-01-18 20:17:54.103024: val_loss -0.4591 
2025-01-18 20:17:54.109078: Pseudo dice [np.float32(0.724), np.float32(0.2211)] 
2025-01-18 20:17:54.113129: Epoch time: 33.01 s 
2025-01-18 20:17:54.685946:  
2025-01-18 20:17:54.685946: Epoch 201 
2025-01-18 20:17:54.692102: Current learning rate: 0.00231 
2025-01-18 20:18:27.705414: train_loss -0.9151 
2025-01-18 20:18:27.706419: val_loss -0.4154 
2025-01-18 20:18:27.711992: Pseudo dice [np.float32(0.7208), np.float32(0.1701)] 
2025-01-18 20:18:27.715535: Epoch time: 33.02 s 
2025-01-18 20:18:28.279973:  
2025-01-18 20:18:28.280976: Epoch 202 
2025-01-18 20:18:28.286564: Current learning rate: 0.00226 
2025-01-18 20:19:01.365417: train_loss -0.9153 
2025-01-18 20:19:01.365928: val_loss -0.4659 
2025-01-18 20:19:01.371558: Pseudo dice [np.float32(0.7498), np.float32(0.2563)] 
2025-01-18 20:19:01.375148: Epoch time: 33.09 s 
2025-01-18 20:19:01.940398:  
2025-01-18 20:19:01.940398: Epoch 203 
2025-01-18 20:19:01.945960: Current learning rate: 0.00222 
2025-01-18 20:19:36.585151: train_loss -0.9168 
2025-01-18 20:19:36.586155: val_loss -0.4899 
2025-01-18 20:19:36.592460: Pseudo dice [np.float32(0.7254), np.float32(0.3135)] 
2025-01-18 20:19:36.596473: Epoch time: 34.65 s 
2025-01-18 20:19:37.190929:  
2025-01-18 20:19:37.191934: Epoch 204 
2025-01-18 20:19:37.197489: Current learning rate: 0.00218 
2025-01-18 20:20:13.114553: train_loss -0.9226 
2025-01-18 20:20:13.116060: val_loss -0.4694 
2025-01-18 20:20:13.122090: Pseudo dice [np.float32(0.7285), np.float32(0.2877)] 
2025-01-18 20:20:13.124629: Epoch time: 35.92 s 
2025-01-18 20:20:13.707067:  
2025-01-18 20:20:13.707572: Epoch 205 
2025-01-18 20:20:13.713590: Current learning rate: 0.00214 
2025-01-18 20:20:50.268473: train_loss -0.9199 
2025-01-18 20:20:50.268473: val_loss -0.4584 
2025-01-18 20:20:50.276386: Pseudo dice [np.float32(0.7087), np.float32(0.2757)] 
2025-01-18 20:20:50.279900: Epoch time: 36.56 s 
2025-01-18 20:20:50.828020:  
2025-01-18 20:20:50.828020: Epoch 206 
2025-01-18 20:20:50.834071: Current learning rate: 0.00209 
2025-01-18 20:21:27.183213: train_loss -0.9226 
2025-01-18 20:21:27.184219: val_loss -0.4842 
2025-01-18 20:21:27.191741: Pseudo dice [np.float32(0.7326), np.float32(0.3152)] 
2025-01-18 20:21:27.195761: Epoch time: 36.36 s 
2025-01-18 20:21:27.901945:  
2025-01-18 20:21:27.902950: Epoch 207 
2025-01-18 20:21:27.907999: Current learning rate: 0.00205 
2025-01-18 20:22:01.501038: train_loss -0.9191 
2025-01-18 20:22:01.501543: val_loss -0.4771 
2025-01-18 20:22:01.507560: Pseudo dice [np.float32(0.7097), np.float32(0.321)] 
2025-01-18 20:22:01.511573: Epoch time: 33.6 s 
2025-01-18 20:22:02.068891:  
2025-01-18 20:22:02.068891: Epoch 208 
2025-01-18 20:22:02.075914: Current learning rate: 0.00201 
2025-01-18 20:22:37.869435: train_loss -0.9268 
2025-01-18 20:22:37.869435: val_loss -0.4525 
2025-01-18 20:22:37.875996: Pseudo dice [np.float32(0.7163), np.float32(0.24)] 
2025-01-18 20:22:37.881619: Epoch time: 35.8 s 
2025-01-18 20:22:38.453477:  
2025-01-18 20:22:38.453477: Epoch 209 
2025-01-18 20:22:38.459495: Current learning rate: 0.00196 
2025-01-18 20:23:14.494141: train_loss -0.9198 
2025-01-18 20:23:14.494660: val_loss -0.4739 
2025-01-18 20:23:14.502179: Pseudo dice [np.float32(0.715), np.float32(0.3199)] 
2025-01-18 20:23:14.505314: Epoch time: 36.04 s 
2025-01-18 20:23:15.076988:  
2025-01-18 20:23:15.076988: Epoch 210 
2025-01-18 20:23:15.083781: Current learning rate: 0.00192 
2025-01-18 20:23:51.065939: train_loss -0.9224 
2025-01-18 20:23:51.065939: val_loss -0.458 
2025-01-18 20:23:51.071960: Pseudo dice [np.float32(0.7238), np.float32(0.2328)] 
2025-01-18 20:23:51.075979: Epoch time: 35.99 s 
2025-01-18 20:23:51.618429:  
2025-01-18 20:23:51.618429: Epoch 211 
2025-01-18 20:23:51.625081: Current learning rate: 0.00188 
2025-01-18 20:24:27.683367: train_loss -0.9245 
2025-01-18 20:24:27.683367: val_loss -0.4707 
2025-01-18 20:24:27.690560: Pseudo dice [np.float32(0.704), np.float32(0.3049)] 
2025-01-18 20:24:27.695167: Epoch time: 36.07 s 
2025-01-18 20:24:28.261405:  
2025-01-18 20:24:28.261405: Epoch 212 
2025-01-18 20:24:28.267479: Current learning rate: 0.00184 
2025-01-18 20:25:04.033306: train_loss -0.9235 
2025-01-18 20:25:04.034305: val_loss -0.4474 
2025-01-18 20:25:04.040831: Pseudo dice [np.float32(0.7078), np.float32(0.2542)] 
2025-01-18 20:25:04.044838: Epoch time: 35.77 s 
2025-01-18 20:25:04.599163:  
2025-01-18 20:25:04.599670: Epoch 213 
2025-01-18 20:25:04.605226: Current learning rate: 0.00179 
2025-01-18 20:25:38.455970: train_loss -0.9226 
2025-01-18 20:25:38.456968: val_loss -0.4695 
2025-01-18 20:25:38.463497: Pseudo dice [np.float32(0.7086), np.float32(0.2763)] 
2025-01-18 20:25:38.467509: Epoch time: 33.86 s 
2025-01-18 20:25:39.017289:  
2025-01-18 20:25:39.018292: Epoch 214 
2025-01-18 20:25:39.024163: Current learning rate: 0.00175 
2025-01-18 20:26:12.516648: train_loss -0.9249 
2025-01-18 20:26:12.518150: val_loss -0.4832 
2025-01-18 20:26:12.524171: Pseudo dice [np.float32(0.7131), np.float32(0.3263)] 
2025-01-18 20:26:12.528264: Epoch time: 33.5 s 
2025-01-18 20:26:13.218076:  
2025-01-18 20:26:13.218076: Epoch 215 
2025-01-18 20:26:13.224103: Current learning rate: 0.0017 
2025-01-18 20:26:45.669514: train_loss -0.9254 
2025-01-18 20:26:45.669514: val_loss -0.4563 
2025-01-18 20:26:45.676208: Pseudo dice [np.float32(0.7045), np.float32(0.3129)] 
2025-01-18 20:26:45.680220: Epoch time: 32.45 s 
2025-01-18 20:26:46.218849:  
2025-01-18 20:26:46.218849: Epoch 216 
2025-01-18 20:26:46.224874: Current learning rate: 0.00166 
2025-01-18 20:27:18.598558: train_loss -0.9253 
2025-01-18 20:27:18.598558: val_loss -0.4677 
2025-01-18 20:27:18.604625: Pseudo dice [np.float32(0.7156), np.float32(0.2802)] 
2025-01-18 20:27:18.609388: Epoch time: 32.38 s 
2025-01-18 20:27:19.153904:  
2025-01-18 20:27:19.154910: Epoch 217 
2025-01-18 20:27:19.161041: Current learning rate: 0.00162 
2025-01-18 20:27:51.553218: train_loss -0.9291 
2025-01-18 20:27:51.553722: val_loss -0.4532 
2025-01-18 20:27:51.559752: Pseudo dice [np.float32(0.718), np.float32(0.2513)] 
2025-01-18 20:27:51.564766: Epoch time: 32.4 s 
2025-01-18 20:27:52.101440:  
2025-01-18 20:27:52.101945: Epoch 218 
2025-01-18 20:27:52.106960: Current learning rate: 0.00157 
2025-01-18 20:28:24.485836: train_loss -0.9219 
2025-01-18 20:28:24.486835: val_loss -0.4691 
2025-01-18 20:28:24.491851: Pseudo dice [np.float32(0.7172), np.float32(0.2528)] 
2025-01-18 20:28:24.495863: Epoch time: 32.39 s 
2025-01-18 20:28:25.049575:  
2025-01-18 20:28:25.050077: Epoch 219 
2025-01-18 20:28:25.055096: Current learning rate: 0.00153 
2025-01-18 20:28:57.264066: train_loss -0.9234 
2025-01-18 20:28:57.264066: val_loss -0.4694 
2025-01-18 20:28:57.270692: Pseudo dice [np.float32(0.7207), np.float32(0.278)] 
2025-01-18 20:28:57.274743: Epoch time: 32.22 s 
2025-01-18 20:28:57.816050:  
2025-01-18 20:28:57.816050: Epoch 220 
2025-01-18 20:28:57.822086: Current learning rate: 0.00148 
2025-01-18 20:29:30.206103: train_loss -0.9248 
2025-01-18 20:29:30.207605: val_loss -0.4406 
2025-01-18 20:29:30.214126: Pseudo dice [np.float32(0.7072), np.float32(0.2267)] 
2025-01-18 20:29:30.217688: Epoch time: 32.39 s 
2025-01-18 20:29:30.791580:  
2025-01-18 20:29:30.791580: Epoch 221 
2025-01-18 20:29:30.796618: Current learning rate: 0.00144 
2025-01-18 20:30:03.225492: train_loss -0.9254 
2025-01-18 20:30:03.226489: val_loss -0.4547 
2025-01-18 20:30:03.232003: Pseudo dice [np.float32(0.6902), np.float32(0.2685)] 
2025-01-18 20:30:03.235516: Epoch time: 32.43 s 
2025-01-18 20:30:03.764937:  
2025-01-18 20:30:03.764937: Epoch 222 
2025-01-18 20:30:03.771009: Current learning rate: 0.00139 
2025-01-18 20:30:36.214881: train_loss -0.9185 
2025-01-18 20:30:36.215884: val_loss -0.5073 
2025-01-18 20:30:36.222478: Pseudo dice [np.float32(0.7361), np.float32(0.3284)] 
2025-01-18 20:30:36.226067: Epoch time: 32.45 s 
2025-01-18 20:30:36.766418:  
2025-01-18 20:30:36.766418: Epoch 223 
2025-01-18 20:30:36.771973: Current learning rate: 0.00135 
2025-01-18 20:31:09.155178: train_loss -0.9239 
2025-01-18 20:31:09.155680: val_loss -0.4841 
2025-01-18 20:31:09.161706: Pseudo dice [np.float32(0.7092), np.float32(0.291)] 
2025-01-18 20:31:09.166274: Epoch time: 32.39 s 
2025-01-18 20:31:09.903225:  
2025-01-18 20:31:09.903225: Epoch 224 
2025-01-18 20:31:09.908790: Current learning rate: 0.0013 
2025-01-18 20:31:42.159496: train_loss -0.92 
2025-01-18 20:31:42.159998: val_loss -0.4739 
2025-01-18 20:31:42.166763: Pseudo dice [np.float32(0.7253), np.float32(0.3118)] 
2025-01-18 20:31:42.169818: Epoch time: 32.26 s 
2025-01-18 20:31:42.699361:  
2025-01-18 20:31:42.700366: Epoch 225 
2025-01-18 20:31:42.705898: Current learning rate: 0.00126 
2025-01-18 20:32:15.598859: train_loss -0.9257 
2025-01-18 20:32:15.598859: val_loss -0.4648 
2025-01-18 20:32:15.607929: Pseudo dice [np.float32(0.7303), np.float32(0.2693)] 
2025-01-18 20:32:15.612947: Epoch time: 32.9 s 
2025-01-18 20:32:16.148115:  
2025-01-18 20:32:16.149118: Epoch 226 
2025-01-18 20:32:16.153667: Current learning rate: 0.00121 
2025-01-18 20:32:49.513351: train_loss -0.9248 
2025-01-18 20:32:49.513351: val_loss -0.4537 
2025-01-18 20:32:49.520459: Pseudo dice [np.float32(0.7075), np.float32(0.2798)] 
2025-01-18 20:32:49.525604: Epoch time: 33.37 s 
2025-01-18 20:32:50.126305:  
2025-01-18 20:32:50.126305: Epoch 227 
2025-01-18 20:32:50.150905: Current learning rate: 0.00117 
2025-01-18 20:33:22.907667: train_loss -0.9266 
2025-01-18 20:33:22.908669: val_loss -0.4391 
2025-01-18 20:33:22.915200: Pseudo dice [np.float32(0.7156), np.float32(0.2525)] 
2025-01-18 20:33:22.918713: Epoch time: 32.78 s 
2025-01-18 20:33:23.452001:  
2025-01-18 20:33:23.452001: Epoch 228 
2025-01-18 20:33:23.458276: Current learning rate: 0.00112 
2025-01-18 20:33:55.645885: train_loss -0.9305 
2025-01-18 20:33:55.645885: val_loss -0.448 
2025-01-18 20:33:55.652910: Pseudo dice [np.float32(0.7099), np.float32(0.2469)] 
2025-01-18 20:33:55.656944: Epoch time: 32.19 s 
2025-01-18 20:33:56.186182:  
2025-01-18 20:33:56.186182: Epoch 229 
2025-01-18 20:33:56.192320: Current learning rate: 0.00108 
2025-01-18 20:34:28.338698: train_loss -0.9369 
2025-01-18 20:34:28.340201: val_loss -0.4692 
2025-01-18 20:34:28.346224: Pseudo dice [np.float32(0.7182), np.float32(0.3064)] 
2025-01-18 20:34:28.350785: Epoch time: 32.15 s 
2025-01-18 20:34:28.883691:  
2025-01-18 20:34:28.884696: Epoch 230 
2025-01-18 20:34:28.889248: Current learning rate: 0.00103 
2025-01-18 20:35:01.079633: train_loss -0.9224 
2025-01-18 20:35:01.079633: val_loss -0.4932 
2025-01-18 20:35:01.086172: Pseudo dice [np.float32(0.727), np.float32(0.3582)] 
2025-01-18 20:35:01.090774: Epoch time: 32.2 s 
2025-01-18 20:35:01.620759:  
2025-01-18 20:35:01.620759: Epoch 231 
2025-01-18 20:35:01.625945: Current learning rate: 0.00098 
2025-01-18 20:35:33.760713: train_loss -0.9244 
2025-01-18 20:35:33.761215: val_loss -0.4736 
2025-01-18 20:35:33.767739: Pseudo dice [np.float32(0.7127), np.float32(0.2798)] 
2025-01-18 20:35:33.771334: Epoch time: 32.14 s 
2025-01-18 20:35:34.462677:  
2025-01-18 20:35:34.463682: Epoch 232 
2025-01-18 20:35:34.469801: Current learning rate: 0.00094 
2025-01-18 20:36:06.611598: train_loss -0.9284 
2025-01-18 20:36:06.611598: val_loss -0.4719 
2025-01-18 20:36:06.617618: Pseudo dice [np.float32(0.72), np.float32(0.3238)] 
2025-01-18 20:36:06.621628: Epoch time: 32.15 s 
2025-01-18 20:36:07.151918:  
2025-01-18 20:36:07.151918: Epoch 233 
2025-01-18 20:36:07.156931: Current learning rate: 0.00089 
2025-01-18 20:36:39.295150: train_loss -0.9278 
2025-01-18 20:36:39.296151: val_loss -0.466 
2025-01-18 20:36:39.303184: Pseudo dice [np.float32(0.7045), np.float32(0.2889)] 
2025-01-18 20:36:39.307268: Epoch time: 32.14 s 
2025-01-18 20:36:39.846813:  
2025-01-18 20:36:39.846813: Epoch 234 
2025-01-18 20:36:39.852873: Current learning rate: 0.00084 
2025-01-18 20:37:11.987100: train_loss -0.926 
2025-01-18 20:37:11.988680: val_loss -0.4814 
2025-01-18 20:37:11.994906: Pseudo dice [np.float32(0.7223), np.float32(0.2799)] 
2025-01-18 20:37:11.998961: Epoch time: 32.14 s 
2025-01-18 20:37:12.532269:  
2025-01-18 20:37:12.532269: Epoch 235 
2025-01-18 20:37:12.538452: Current learning rate: 0.00079 
2025-01-18 20:37:44.714177: train_loss -0.9327 
2025-01-18 20:37:44.714681: val_loss -0.4679 
2025-01-18 20:37:44.721288: Pseudo dice [np.float32(0.7218), np.float32(0.2621)] 
2025-01-18 20:37:44.725051: Epoch time: 32.18 s 
2025-01-18 20:37:45.261873:  
2025-01-18 20:37:45.261873: Epoch 236 
2025-01-18 20:37:45.267888: Current learning rate: 0.00075 
2025-01-18 20:38:17.460013: train_loss -0.9298 
2025-01-18 20:38:17.460517: val_loss -0.4986 
2025-01-18 20:38:17.465534: Pseudo dice [np.float32(0.7287), np.float32(0.3028)] 
2025-01-18 20:38:17.470552: Epoch time: 32.2 s 
2025-01-18 20:38:17.990908:  
2025-01-18 20:38:17.991914: Epoch 237 
2025-01-18 20:38:17.996486: Current learning rate: 0.0007 
2025-01-18 20:38:49.867690: train_loss -0.9304 
2025-01-18 20:38:49.867690: val_loss -0.4886 
2025-01-18 20:38:49.874711: Pseudo dice [np.float32(0.7282), np.float32(0.3134)] 
2025-01-18 20:38:49.878736: Epoch time: 31.88 s 
2025-01-18 20:38:50.407608:  
2025-01-18 20:38:50.408613: Epoch 238 
2025-01-18 20:38:50.413197: Current learning rate: 0.00065 
2025-01-18 20:39:22.280660: train_loss -0.9252 
2025-01-18 20:39:22.281171: val_loss -0.4464 
2025-01-18 20:39:22.286792: Pseudo dice [np.float32(0.6995), np.float32(0.2591)] 
2025-01-18 20:39:22.290301: Epoch time: 31.87 s 
2025-01-18 20:39:22.811252:  
2025-01-18 20:39:22.811252: Epoch 239 
2025-01-18 20:39:22.816778: Current learning rate: 0.0006 
2025-01-18 20:39:54.670012: train_loss -0.9392 
2025-01-18 20:39:54.671516: val_loss -0.4411 
2025-01-18 20:39:54.677536: Pseudo dice [np.float32(0.7119), np.float32(0.2442)] 
2025-01-18 20:39:54.682067: Epoch time: 31.86 s 
2025-01-18 20:39:55.216191:  
2025-01-18 20:39:55.217194: Epoch 240 
2025-01-18 20:39:55.223286: Current learning rate: 0.00055 
2025-01-18 20:40:27.078899: train_loss -0.929 
2025-01-18 20:40:27.078899: val_loss -0.4506 
2025-01-18 20:40:27.085486: Pseudo dice [np.float32(0.7243), np.float32(0.2377)] 
2025-01-18 20:40:27.088997: Epoch time: 31.86 s 
2025-01-18 20:40:27.776383:  
2025-01-18 20:40:27.776383: Epoch 241 
2025-01-18 20:40:27.781936: Current learning rate: 0.0005 
2025-01-18 20:40:59.629268: train_loss -0.9277 
2025-01-18 20:40:59.629771: val_loss -0.4277 
2025-01-18 20:40:59.635789: Pseudo dice [np.float32(0.7209), np.float32(0.1894)] 
2025-01-18 20:40:59.639798: Epoch time: 31.85 s 
2025-01-18 20:41:00.175796:  
2025-01-18 20:41:00.176797: Epoch 242 
2025-01-18 20:41:00.182395: Current learning rate: 0.00045 
2025-01-18 20:41:32.032956: train_loss -0.9315 
2025-01-18 20:41:32.033459: val_loss -0.4762 
2025-01-18 20:41:32.039999: Pseudo dice [np.float32(0.7237), np.float32(0.3019)] 
2025-01-18 20:41:32.043513: Epoch time: 31.86 s 
2025-01-18 20:41:32.572237:  
2025-01-18 20:41:32.572740: Epoch 243 
2025-01-18 20:41:32.577751: Current learning rate: 0.0004 
2025-01-18 20:42:04.419849: train_loss -0.9299 
2025-01-18 20:42:04.420850: val_loss -0.4446 
2025-01-18 20:42:04.427368: Pseudo dice [np.float32(0.7237), np.float32(0.2199)] 
2025-01-18 20:42:04.431380: Epoch time: 31.85 s 
2025-01-18 20:42:04.974630:  
2025-01-18 20:42:04.975133: Epoch 244 
2025-01-18 20:42:04.980146: Current learning rate: 0.00035 
2025-01-18 20:42:36.832521: train_loss -0.9304 
2025-01-18 20:42:36.833023: val_loss -0.4307 
2025-01-18 20:42:36.839041: Pseudo dice [np.float32(0.7047), np.float32(0.2399)] 
2025-01-18 20:42:36.842552: Epoch time: 31.86 s 
2025-01-18 20:42:37.366339:  
2025-01-18 20:42:37.366339: Epoch 245 
2025-01-18 20:42:37.371877: Current learning rate: 0.0003 
2025-01-18 20:43:09.226035: train_loss -0.9344 
2025-01-18 20:43:09.226035: val_loss -0.4822 
2025-01-18 20:43:09.233065: Pseudo dice [np.float32(0.7239), np.float32(0.264)] 
2025-01-18 20:43:09.236115: Epoch time: 31.86 s 
2025-01-18 20:43:09.764639:  
2025-01-18 20:43:09.764639: Epoch 246 
2025-01-18 20:43:09.770153: Current learning rate: 0.00024 
2025-01-18 20:43:41.623830: train_loss -0.927 
2025-01-18 20:43:41.623830: val_loss -0.4646 
2025-01-18 20:43:41.630466: Pseudo dice [np.float32(0.7301), np.float32(0.2436)] 
2025-01-18 20:43:41.634546: Epoch time: 31.86 s 
2025-01-18 20:43:42.157338:  
2025-01-18 20:43:42.158344: Epoch 247 
2025-01-18 20:43:42.162886: Current learning rate: 0.00019 
2025-01-18 20:44:13.998788: train_loss -0.9395 
2025-01-18 20:44:13.999292: val_loss -0.4602 
2025-01-18 20:44:14.005395: Pseudo dice [np.float32(0.7089), np.float32(0.2678)] 
2025-01-18 20:44:14.009482: Epoch time: 31.84 s 
2025-01-18 20:44:14.537159:  
2025-01-18 20:44:14.537159: Epoch 248 
2025-01-18 20:44:14.543015: Current learning rate: 0.00013 
2025-01-18 20:44:46.382288: train_loss -0.9318 
2025-01-18 20:44:46.382792: val_loss -0.4583 
2025-01-18 20:44:46.388810: Pseudo dice [np.float32(0.7044), np.float32(0.273)] 
2025-01-18 20:44:46.392417: Epoch time: 31.85 s 
2025-01-18 20:44:47.070447:  
2025-01-18 20:44:47.070447: Epoch 249 
2025-01-18 20:44:47.075971: Current learning rate: 7e-05 
2025-01-18 20:45:18.896042: train_loss -0.9354 
2025-01-18 20:45:18.896042: val_loss -0.4544 
2025-01-18 20:45:18.902605: Pseudo dice [np.float32(0.7327), np.float32(0.2216)] 
2025-01-18 20:45:18.906160: Epoch time: 31.83 s 
2025-01-18 20:45:19.725287: Training done. 
2025-01-18 20:45:19.749289: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-18 20:45:19.757291: The split file contains 5 splits. 
2025-01-18 20:45:19.764289: Desired fold for training: 0 
2025-01-18 20:45:19.769289: This split has 224 training and 57 validation cases. 
2025-01-18 20:45:19.776295: predicting pancreas_021 
2025-01-18 20:45:19.784294: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-18 20:45:21.679682: predicting pancreas_024 
2025-01-18 20:45:21.692683: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-18 20:45:22.138802: predicting pancreas_035 
2025-01-18 20:45:22.150805: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-18 20:45:22.455965: predicting pancreas_040 
2025-01-18 20:45:22.461967: pancreas_040, shape torch.Size([1, 45, 526, 526]), rank 0 
2025-01-18 20:45:23.107833: predicting pancreas_042 
2025-01-18 20:45:23.113835: pancreas_042, shape torch.Size([1, 51, 537, 537]), rank 0 
2025-01-18 20:45:23.863127: predicting pancreas_056 
2025-01-18 20:45:23.870128: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-18 20:45:24.238164: predicting pancreas_067 
2025-01-18 20:45:24.250165: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-18 20:45:25.819653: predicting pancreas_075 
2025-01-18 20:45:25.832650: pancreas_075, shape torch.Size([1, 121, 521, 521]), rank 0 
2025-01-18 20:45:28.037382: predicting pancreas_086 
2025-01-18 20:45:28.064382: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-18 20:45:29.151501: predicting pancreas_089 
2025-01-18 20:45:29.162502: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-18 20:45:29.662865: predicting pancreas_092 
2025-01-18 20:45:29.675868: pancreas_092, shape torch.Size([1, 92, 513, 513]), rank 0 
2025-01-18 20:45:31.399550: predicting pancreas_094 
2025-01-18 20:45:31.414550: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-18 20:45:31.842582: predicting pancreas_095 
2025-01-18 20:45:31.853581: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-18 20:45:32.340123: predicting pancreas_098 
2025-01-18 20:45:32.361123: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-18 20:45:35.271444: predicting pancreas_109 
2025-01-18 20:45:35.299955: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-18 20:45:35.861494: predicting pancreas_110 
2025-01-18 20:45:35.876504: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-18 20:45:37.849692: predicting pancreas_114 
2025-01-18 20:45:37.871692: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-18 20:45:38.435256: predicting pancreas_119 
2025-01-18 20:45:38.447256: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-18 20:45:40.059939: predicting pancreas_138 
2025-01-18 20:45:40.073940: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-18 20:45:41.826100: predicting pancreas_145 
2025-01-18 20:45:41.844100: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-18 20:45:43.551820: predicting pancreas_148 
2025-01-18 20:45:43.580821: pancreas_148, shape torch.Size([1, 42, 486, 486]), rank 0 
2025-01-18 20:45:43.813348: predicting pancreas_169 
2025-01-18 20:45:43.820348: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-18 20:45:44.305898: predicting pancreas_170 
2025-01-18 20:45:44.316898: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-18 20:45:44.856449: predicting pancreas_172 
2025-01-18 20:45:44.871449: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-18 20:45:45.422503: predicting pancreas_175 
2025-01-18 20:45:45.436503: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-18 20:45:45.943043: predicting pancreas_180 
2025-01-18 20:45:45.960042: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-18 20:45:46.501089: predicting pancreas_191 
2025-01-18 20:45:46.514089: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-18 20:45:46.840617: predicting pancreas_193 
2025-01-18 20:45:46.848618: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-18 20:45:47.512702: predicting pancreas_212 
2025-01-18 20:45:47.528703: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-18 20:45:49.522879: predicting pancreas_215 
2025-01-18 20:45:49.540879: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-18 20:45:50.089418: predicting pancreas_222 
2025-01-18 20:45:50.102923: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-18 20:45:50.523952: predicting pancreas_235 
2025-01-18 20:45:50.529953: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-18 20:45:50.971989: predicting pancreas_241 
2025-01-18 20:45:50.982992: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-18 20:45:51.603561: predicting pancreas_242 
2025-01-18 20:45:51.619562: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-18 20:45:53.633728: predicting pancreas_244 
2025-01-18 20:45:53.650727: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-18 20:45:55.599409: predicting pancreas_246 
2025-01-18 20:45:55.616409: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-18 20:45:57.601081: predicting pancreas_247 
2025-01-18 20:45:57.620081: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-18 20:45:58.094121: predicting pancreas_264 
2025-01-18 20:45:58.103625: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-18 20:46:00.015408: predicting pancreas_265 
2025-01-18 20:46:00.034407: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-18 20:46:01.528554: predicting pancreas_266 
2025-01-18 20:46:01.541554: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-18 20:46:03.229751: predicting pancreas_267 
2025-01-18 20:46:03.246751: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-18 20:46:03.723289: predicting pancreas_275 
2025-01-18 20:46:03.733289: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-18 20:46:04.269828: predicting pancreas_279 
2025-01-18 20:46:04.283831: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-18 20:46:04.748409: predicting pancreas_287 
2025-01-18 20:46:04.758413: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-18 20:46:05.273476: predicting pancreas_301 
2025-01-18 20:46:05.291480: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-18 20:46:06.951663: predicting pancreas_323 
2025-01-18 20:46:06.965662: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-18 20:46:08.799308: predicting pancreas_336 
2025-01-18 20:46:08.817311: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-18 20:46:10.516485: predicting pancreas_344 
2025-01-18 20:46:10.534487: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-18 20:46:11.124531: predicting pancreas_351 
2025-01-18 20:46:11.136531: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-18 20:46:11.613071: predicting pancreas_354 
2025-01-18 20:46:11.621071: pancreas_354, shape torch.Size([1, 81, 529, 529]), rank 0 
2025-01-18 20:46:13.161714: predicting pancreas_372 
2025-01-18 20:46:13.177716: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-18 20:46:14.963879: predicting pancreas_377 
2025-01-18 20:46:14.980879: pancreas_377, shape torch.Size([1, 55, 551, 551]), rank 0 
2025-01-18 20:46:15.983969: predicting pancreas_387 
2025-01-18 20:46:15.993972: pancreas_387, shape torch.Size([1, 50, 498, 498]), rank 0 
2025-01-18 20:46:16.214522: predicting pancreas_391 
2025-01-18 20:46:16.221521: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-18 20:46:17.874667: predicting pancreas_392 
2025-01-18 20:46:17.893670: pancreas_392, shape torch.Size([1, 57, 448, 448]), rank 0 
2025-01-18 20:46:18.200698: predicting pancreas_410 
2025-01-18 20:46:18.207697: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-18 20:46:18.776249: predicting pancreas_412 
2025-01-18 20:46:18.785253: pancreas_412, shape torch.Size([1, 164, 584, 584]), rank 0 
2025-01-18 20:46:32.789339: Validation complete 
2025-01-18 20:46:32.789339: Mean Validation Dice:  0.46733149733446244 
