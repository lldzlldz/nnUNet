
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-16 20:11:28.819023: do_dummy_2d_data_aug: True 
2025-01-16 20:11:28.822024: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-16 20:11:28.827024: The split file contains 5 splits. 
2025-01-16 20:11:28.830023: Desired fold for training: 0 
2025-01-16 20:11:28.832027: This split has 224 training and 57 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [40, 224, 224], 'median_image_size_in_voxels': [96.0, 512.0, 512.0], 'spacing': [2.5, 0.8027340173721313, 0.8027340173721313], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[1, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [1, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_Pancreas', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [2.5, 0.8027340173721313, 0.8027340173721313], 'original_median_shape_after_transp': [93, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 80.36482238769531, 'median': 86.0, 'min': -998.0, 'percentile_00_5': -92.0, 'percentile_99_5': 217.0, 'std': 72.70781707763672}}} 
 
2025-01-16 20:11:34.554187: unpacking dataset... 
2025-01-16 20:11:34.745078: unpacking done... 
2025-01-16 20:11:37.691115:  
2025-01-16 20:11:37.691115: Epoch 0 
2025-01-16 20:11:37.696126: Current learning rate: 0.01 
2025-01-16 20:12:22.783875: train_loss 0.1096 
2025-01-16 20:12:22.784879: val_loss 0.045 
2025-01-16 20:12:22.789894: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-16 20:12:22.794907: Epoch time: 45.09 s 
2025-01-16 20:12:22.797414: Yayy! New best EMA pseudo Dice: 0.0 
2025-01-16 20:12:23.485011:  
2025-01-16 20:12:23.485011: Epoch 1 
2025-01-16 20:12:23.490026: Current learning rate: 0.00996 
2025-01-16 20:13:04.233481: train_loss 0.009 
2025-01-16 20:13:04.233481: val_loss -0.1143 
2025-01-16 20:13:04.239016: Pseudo dice [np.float32(0.0), np.float32(0.0)] 
2025-01-16 20:13:04.242037: Epoch time: 40.75 s 
2025-01-16 20:13:04.789178:  
2025-01-16 20:13:04.789178: Epoch 2 
2025-01-16 20:13:04.794212: Current learning rate: 0.00993 
2025-01-16 20:13:45.530123: train_loss -0.1689 
2025-01-16 20:13:45.530625: val_loss -0.2095 
2025-01-16 20:13:45.536187: Pseudo dice [np.float32(0.5723), np.float32(0.0)] 
2025-01-16 20:13:45.538710: Epoch time: 40.74 s 
2025-01-16 20:13:45.542236: Yayy! New best EMA pseudo Dice: 0.028599999845027924 
2025-01-16 20:13:46.313095:  
2025-01-16 20:13:46.314095: Epoch 3 
2025-01-16 20:13:46.319685: Current learning rate: 0.00989 
2025-01-16 20:14:27.070169: train_loss -0.2479 
2025-01-16 20:14:27.070169: val_loss -0.2888 
2025-01-16 20:14:27.076242: Pseudo dice [np.float32(0.6879), np.float32(0.0)] 
2025-01-16 20:14:27.079261: Epoch time: 40.76 s 
2025-01-16 20:14:27.082279: Yayy! New best EMA pseudo Dice: 0.060100000351667404 
2025-01-16 20:14:27.874664:  
2025-01-16 20:14:27.874664: Epoch 4 
2025-01-16 20:14:27.879678: Current learning rate: 0.00986 
2025-01-16 20:15:08.620673: train_loss -0.2925 
2025-01-16 20:15:08.621176: val_loss -0.3334 
2025-01-16 20:15:08.626195: Pseudo dice [np.float32(0.7016), np.float32(0.0)] 
2025-01-16 20:15:08.629735: Epoch time: 40.75 s 
2025-01-16 20:15:08.632822: Yayy! New best EMA pseudo Dice: 0.08919999748468399 
2025-01-16 20:15:09.515895:  
2025-01-16 20:15:09.515895: Epoch 5 
2025-01-16 20:15:09.521950: Current learning rate: 0.00982 
2025-01-16 20:15:50.254836: train_loss -0.3066 
2025-01-16 20:15:50.255348: val_loss -0.3312 
2025-01-16 20:15:50.260413: Pseudo dice [np.float32(0.6909), np.float32(0.0)] 
2025-01-16 20:15:50.262944: Epoch time: 40.74 s 
2025-01-16 20:15:50.267003: Yayy! New best EMA pseudo Dice: 0.11479999870061874 
2025-01-16 20:15:51.025501:  
2025-01-16 20:15:51.025501: Epoch 6 
2025-01-16 20:15:51.030520: Current learning rate: 0.00978 
2025-01-16 20:16:31.757879: train_loss -0.336 
2025-01-16 20:16:31.758381: val_loss -0.3718 
2025-01-16 20:16:31.763436: Pseudo dice [np.float32(0.6954), np.float32(0.2695)] 
2025-01-16 20:16:31.765972: Epoch time: 40.73 s 
2025-01-16 20:16:31.769481: Yayy! New best EMA pseudo Dice: 0.15160000324249268 
2025-01-16 20:16:32.541325:  
2025-01-16 20:16:32.542834: Epoch 7 
2025-01-16 20:16:32.547889: Current learning rate: 0.00975 
2025-01-16 20:17:13.303067: train_loss -0.3939 
2025-01-16 20:17:13.303067: val_loss -0.4337 
2025-01-16 20:17:13.309215: Pseudo dice [np.float32(0.6925), np.float32(0.3996)] 
2025-01-16 20:17:13.311748: Epoch time: 40.76 s 
2025-01-16 20:17:13.315315: Yayy! New best EMA pseudo Dice: 0.19099999964237213 
2025-01-16 20:17:14.118052:  
2025-01-16 20:17:14.119059: Epoch 8 
2025-01-16 20:17:14.123614: Current learning rate: 0.00971 
2025-01-16 20:17:54.889186: train_loss -0.4137 
2025-01-16 20:17:54.889186: val_loss -0.388 
2025-01-16 20:17:54.895727: Pseudo dice [np.float32(0.6557), np.float32(0.2761)] 
2025-01-16 20:17:54.898738: Epoch time: 40.77 s 
2025-01-16 20:17:54.901245: Yayy! New best EMA pseudo Dice: 0.21850000321865082 
2025-01-16 20:17:55.668480:  
2025-01-16 20:17:55.669485: Epoch 9 
2025-01-16 20:17:55.674039: Current learning rate: 0.00968 
2025-01-16 20:18:36.417703: train_loss -0.4308 
2025-01-16 20:18:36.418214: val_loss -0.423 
2025-01-16 20:18:36.423808: Pseudo dice [np.float32(0.6901), np.float32(0.3191)] 
2025-01-16 20:18:36.426330: Epoch time: 40.75 s 
2025-01-16 20:18:36.428853: Yayy! New best EMA pseudo Dice: 0.24709999561309814 
2025-01-16 20:18:37.159546:  
2025-01-16 20:18:37.161049: Epoch 10 
2025-01-16 20:18:37.165558: Current learning rate: 0.00964 
2025-01-16 20:19:17.917779: train_loss -0.4654 
2025-01-16 20:19:17.918291: val_loss -0.4475 
2025-01-16 20:19:17.923862: Pseudo dice [np.float32(0.6904), np.float32(0.3656)] 
2025-01-16 20:19:17.927393: Epoch time: 40.76 s 
2025-01-16 20:19:17.930064: Yayy! New best EMA pseudo Dice: 0.2752000093460083 
2025-01-16 20:19:18.674389:  
2025-01-16 20:19:18.674389: Epoch 11 
2025-01-16 20:19:18.679401: Current learning rate: 0.0096 
2025-01-16 20:19:59.428756: train_loss -0.4852 
2025-01-16 20:19:59.429259: val_loss -0.4791 
2025-01-16 20:19:59.434279: Pseudo dice [np.float32(0.7051), np.float32(0.4569)] 
2025-01-16 20:19:59.437886: Epoch time: 40.75 s 
2025-01-16 20:19:59.440932: Yayy! New best EMA pseudo Dice: 0.3057999908924103 
2025-01-16 20:20:00.189645:  
2025-01-16 20:20:00.189645: Epoch 12 
2025-01-16 20:20:00.194659: Current learning rate: 0.00957 
2025-01-16 20:20:40.946761: train_loss -0.5049 
2025-01-16 20:20:40.946761: val_loss -0.4625 
2025-01-16 20:20:40.951857: Pseudo dice [np.float32(0.7367), np.float32(0.3881)] 
2025-01-16 20:20:40.955906: Epoch time: 40.76 s 
2025-01-16 20:20:40.958955: Yayy! New best EMA pseudo Dice: 0.33149999380111694 
2025-01-16 20:20:41.894124:  
2025-01-16 20:20:41.894124: Epoch 13 
2025-01-16 20:20:41.899762: Current learning rate: 0.00953 
2025-01-16 20:21:22.619437: train_loss -0.4924 
2025-01-16 20:21:22.620438: val_loss -0.5067 
2025-01-16 20:21:22.626512: Pseudo dice [np.float32(0.7307), np.float32(0.3946)] 
2025-01-16 20:21:22.629555: Epoch time: 40.73 s 
2025-01-16 20:21:22.632061: Yayy! New best EMA pseudo Dice: 0.3546000123023987 
2025-01-16 20:21:23.417283:  
2025-01-16 20:21:23.417786: Epoch 14 
2025-01-16 20:21:23.422928: Current learning rate: 0.00949 
2025-01-16 20:22:04.132214: train_loss -0.5287 
2025-01-16 20:22:04.133220: val_loss -0.4635 
2025-01-16 20:22:04.138235: Pseudo dice [np.float32(0.7188), np.float32(0.337)] 
2025-01-16 20:22:04.142245: Epoch time: 40.72 s 
2025-01-16 20:22:04.144753: Yayy! New best EMA pseudo Dice: 0.3718999922275543 
2025-01-16 20:22:04.932348:  
2025-01-16 20:22:04.932348: Epoch 15 
2025-01-16 20:22:04.937860: Current learning rate: 0.00946 
2025-01-16 20:22:45.665887: train_loss -0.5163 
2025-01-16 20:22:45.666930: val_loss -0.4735 
2025-01-16 20:22:45.673985: Pseudo dice [np.float32(0.6853), np.float32(0.3933)] 
2025-01-16 20:22:45.677498: Epoch time: 40.73 s 
2025-01-16 20:22:45.681004: Yayy! New best EMA pseudo Dice: 0.388700008392334 
2025-01-16 20:22:46.442919:  
2025-01-16 20:22:46.442919: Epoch 16 
2025-01-16 20:22:46.448036: Current learning rate: 0.00942 
2025-01-16 20:23:27.189509: train_loss -0.5286 
2025-01-16 20:23:27.189509: val_loss -0.4389 
2025-01-16 20:23:27.194522: Pseudo dice [np.float32(0.6775), np.float32(0.3002)] 
2025-01-16 20:23:27.199574: Epoch time: 40.75 s 
2025-01-16 20:23:27.202081: Yayy! New best EMA pseudo Dice: 0.3986999988555908 
2025-01-16 20:23:27.964518:  
2025-01-16 20:23:27.966021: Epoch 17 
2025-01-16 20:23:27.969536: Current learning rate: 0.00939 
2025-01-16 20:24:08.711647: train_loss -0.5324 
2025-01-16 20:24:08.712154: val_loss -0.4453 
2025-01-16 20:24:08.718245: Pseudo dice [np.float32(0.7022), np.float32(0.3828)] 
2025-01-16 20:24:08.721855: Epoch time: 40.75 s 
2025-01-16 20:24:08.725441: Yayy! New best EMA pseudo Dice: 0.413100004196167 
2025-01-16 20:24:09.506080:  
2025-01-16 20:24:09.507083: Epoch 18 
2025-01-16 20:24:09.512177: Current learning rate: 0.00935 
2025-01-16 20:24:50.227154: train_loss -0.5213 
2025-01-16 20:24:50.228155: val_loss -0.4374 
2025-01-16 20:24:50.233215: Pseudo dice [np.float32(0.7285), np.float32(0.2775)] 
2025-01-16 20:24:50.236261: Epoch time: 40.72 s 
2025-01-16 20:24:50.239771: Yayy! New best EMA pseudo Dice: 0.4221000075340271 
2025-01-16 20:24:50.990702:  
2025-01-16 20:24:50.990702: Epoch 19 
2025-01-16 20:24:50.996774: Current learning rate: 0.00931 
2025-01-16 20:25:31.740985: train_loss -0.5533 
2025-01-16 20:25:31.741985: val_loss -0.4983 
2025-01-16 20:25:31.747499: Pseudo dice [np.float32(0.712), np.float32(0.3505)] 
2025-01-16 20:25:31.751008: Epoch time: 40.75 s 
2025-01-16 20:25:31.753513: Yayy! New best EMA pseudo Dice: 0.43299999833106995 
2025-01-16 20:25:32.517895:  
2025-01-16 20:25:32.518399: Epoch 20 
2025-01-16 20:25:32.523528: Current learning rate: 0.00928 
2025-01-16 20:26:13.274984: train_loss -0.5459 
2025-01-16 20:26:13.276013: val_loss -0.4694 
2025-01-16 20:26:13.280665: Pseudo dice [np.float32(0.7251), np.float32(0.2963)] 
2025-01-16 20:26:13.284774: Epoch time: 40.76 s 
2025-01-16 20:26:13.287282: Yayy! New best EMA pseudo Dice: 0.4406999945640564 
2025-01-16 20:26:14.203138:  
2025-01-16 20:26:14.203643: Epoch 21 
2025-01-16 20:26:14.208656: Current learning rate: 0.00924 
2025-01-16 20:26:54.951973: train_loss -0.5696 
2025-01-16 20:26:54.951973: val_loss -0.5089 
2025-01-16 20:26:54.957586: Pseudo dice [np.float32(0.7449), np.float32(0.4166)] 
2025-01-16 20:26:54.961607: Epoch time: 40.75 s 
2025-01-16 20:26:54.965127: Yayy! New best EMA pseudo Dice: 0.4546999931335449 
2025-01-16 20:26:55.697753:  
2025-01-16 20:26:55.697753: Epoch 22 
2025-01-16 20:26:55.703298: Current learning rate: 0.0092 
2025-01-16 20:27:36.461037: train_loss -0.5967 
2025-01-16 20:27:36.461539: val_loss -0.5239 
2025-01-16 20:27:36.467083: Pseudo dice [np.float32(0.7305), np.float32(0.4406)] 
2025-01-16 20:27:36.470603: Epoch time: 40.76 s 
2025-01-16 20:27:36.473623: Yayy! New best EMA pseudo Dice: 0.46779999136924744 
2025-01-16 20:27:37.240118:  
2025-01-16 20:27:37.241121: Epoch 23 
2025-01-16 20:27:37.245201: Current learning rate: 0.00917 
2025-01-16 20:28:17.986452: train_loss -0.5906 
2025-01-16 20:28:17.986452: val_loss -0.5085 
2025-01-16 20:28:17.994011: Pseudo dice [np.float32(0.7416), np.float32(0.3991)] 
2025-01-16 20:28:17.998539: Epoch time: 40.75 s 
2025-01-16 20:28:18.001566: Yayy! New best EMA pseudo Dice: 0.4781000018119812 
2025-01-16 20:28:18.771247:  
2025-01-16 20:28:18.771750: Epoch 24 
2025-01-16 20:28:18.776794: Current learning rate: 0.00913 
2025-01-16 20:28:59.498815: train_loss -0.6073 
2025-01-16 20:28:59.499321: val_loss -0.5007 
2025-01-16 20:28:59.504413: Pseudo dice [np.float32(0.7197), np.float32(0.4419)] 
2025-01-16 20:28:59.507468: Epoch time: 40.73 s 
2025-01-16 20:28:59.510505: Yayy! New best EMA pseudo Dice: 0.48840001225471497 
2025-01-16 20:29:00.282355:  
2025-01-16 20:29:00.284381: Epoch 25 
2025-01-16 20:29:00.289462: Current learning rate: 0.0091 
2025-01-16 20:29:41.039992: train_loss -0.572 
2025-01-16 20:29:41.040996: val_loss -0.5051 
2025-01-16 20:29:41.046199: Pseudo dice [np.float32(0.7289), np.float32(0.4267)] 
2025-01-16 20:29:41.050236: Epoch time: 40.76 s 
2025-01-16 20:29:41.053784: Yayy! New best EMA pseudo Dice: 0.49729999899864197 
2025-01-16 20:29:41.824745:  
2025-01-16 20:29:41.825264: Epoch 26 
2025-01-16 20:29:41.830279: Current learning rate: 0.00906 
2025-01-16 20:30:22.574558: train_loss -0.5947 
2025-01-16 20:30:22.575562: val_loss -0.5276 
2025-01-16 20:30:22.582119: Pseudo dice [np.float32(0.763), np.float32(0.4439)] 
2025-01-16 20:30:22.585630: Epoch time: 40.75 s 
2025-01-16 20:30:22.588136: Yayy! New best EMA pseudo Dice: 0.5078999996185303 
2025-01-16 20:30:23.354686:  
2025-01-16 20:30:23.354686: Epoch 27 
2025-01-16 20:30:23.360312: Current learning rate: 0.00902 
2025-01-16 20:31:04.106652: train_loss -0.5927 
2025-01-16 20:31:04.107155: val_loss -0.5494 
2025-01-16 20:31:04.112207: Pseudo dice [np.float32(0.7683), np.float32(0.4151)] 
2025-01-16 20:31:04.115244: Epoch time: 40.75 s 
2025-01-16 20:31:04.119270: Yayy! New best EMA pseudo Dice: 0.5163000226020813 
2025-01-16 20:31:04.894250:  
2025-01-16 20:31:04.895250: Epoch 28 
2025-01-16 20:31:04.899813: Current learning rate: 0.00899 
2025-01-16 20:31:45.645565: train_loss -0.6071 
2025-01-16 20:31:45.646592: val_loss -0.5148 
2025-01-16 20:31:45.652124: Pseudo dice [np.float32(0.7494), np.float32(0.4058)] 
2025-01-16 20:31:45.655630: Epoch time: 40.75 s 
2025-01-16 20:31:45.658639: Yayy! New best EMA pseudo Dice: 0.5224000215530396 
2025-01-16 20:31:46.546715:  
2025-01-16 20:31:46.546715: Epoch 29 
2025-01-16 20:31:46.552260: Current learning rate: 0.00895 
2025-01-16 20:32:27.306548: train_loss -0.6112 
2025-01-16 20:32:27.306548: val_loss -0.4497 
2025-01-16 20:32:27.311562: Pseudo dice [np.float32(0.7173), np.float32(0.3385)] 
2025-01-16 20:32:27.315073: Epoch time: 40.76 s 
2025-01-16 20:32:27.317580: Yayy! New best EMA pseudo Dice: 0.5230000019073486 
2025-01-16 20:32:28.073266:  
2025-01-16 20:32:28.073266: Epoch 30 
2025-01-16 20:32:28.080930: Current learning rate: 0.00891 
2025-01-16 20:33:08.840319: train_loss -0.6158 
2025-01-16 20:33:08.840319: val_loss -0.5399 
2025-01-16 20:33:08.846332: Pseudo dice [np.float32(0.7119), np.float32(0.446)] 
2025-01-16 20:33:08.848840: Epoch time: 40.77 s 
2025-01-16 20:33:08.855359: Yayy! New best EMA pseudo Dice: 0.5285999774932861 
2025-01-16 20:33:09.603713:  
2025-01-16 20:33:09.603713: Epoch 31 
2025-01-16 20:33:09.608773: Current learning rate: 0.00888 
2025-01-16 20:33:50.355895: train_loss -0.6289 
2025-01-16 20:33:50.355895: val_loss -0.5324 
2025-01-16 20:33:50.361930: Pseudo dice [np.float32(0.7646), np.float32(0.4079)] 
2025-01-16 20:33:50.364949: Epoch time: 40.75 s 
2025-01-16 20:33:50.367455: Yayy! New best EMA pseudo Dice: 0.5343000292778015 
2025-01-16 20:33:51.116153:  
2025-01-16 20:33:51.116153: Epoch 32 
2025-01-16 20:33:51.121165: Current learning rate: 0.00884 
2025-01-16 20:34:31.857258: train_loss -0.6371 
2025-01-16 20:34:31.858346: val_loss -0.5137 
2025-01-16 20:34:31.863388: Pseudo dice [np.float32(0.7471), np.float32(0.4056)] 
2025-01-16 20:34:31.866419: Epoch time: 40.74 s 
2025-01-16 20:34:31.869433: Yayy! New best EMA pseudo Dice: 0.5385000109672546 
2025-01-16 20:34:32.643727:  
2025-01-16 20:34:32.644229: Epoch 33 
2025-01-16 20:34:32.649241: Current learning rate: 0.0088 
2025-01-16 20:35:13.379715: train_loss -0.6239 
2025-01-16 20:35:13.380228: val_loss -0.5213 
2025-01-16 20:35:13.385273: Pseudo dice [np.float32(0.7373), np.float32(0.3832)] 
2025-01-16 20:35:13.387795: Epoch time: 40.74 s 
2025-01-16 20:35:13.391321: Yayy! New best EMA pseudo Dice: 0.5407000184059143 
2025-01-16 20:35:14.162561:  
2025-01-16 20:35:14.162561: Epoch 34 
2025-01-16 20:35:14.168621: Current learning rate: 0.00877 
2025-01-16 20:35:54.904702: train_loss -0.6592 
2025-01-16 20:35:54.905704: val_loss -0.5447 
2025-01-16 20:35:54.910719: Pseudo dice [np.float32(0.7832), np.float32(0.4126)] 
2025-01-16 20:35:54.913732: Epoch time: 40.74 s 
2025-01-16 20:35:54.916238: Yayy! New best EMA pseudo Dice: 0.5464000105857849 
2025-01-16 20:35:55.667920:  
2025-01-16 20:35:55.667920: Epoch 35 
2025-01-16 20:35:55.674035: Current learning rate: 0.00873 
2025-01-16 20:36:36.405308: train_loss -0.6458 
2025-01-16 20:36:36.406313: val_loss -0.5033 
2025-01-16 20:36:36.411325: Pseudo dice [np.float32(0.7263), np.float32(0.4255)] 
2025-01-16 20:36:36.414831: Epoch time: 40.74 s 
2025-01-16 20:36:36.417840: Yayy! New best EMA pseudo Dice: 0.5493999719619751 
2025-01-16 20:36:37.237029:  
2025-01-16 20:36:37.237029: Epoch 36 
2025-01-16 20:36:37.242561: Current learning rate: 0.00869 
2025-01-16 20:37:17.971329: train_loss -0.6776 
2025-01-16 20:37:17.971833: val_loss -0.5526 
2025-01-16 20:37:17.976881: Pseudo dice [np.float32(0.7877), np.float32(0.4785)] 
2025-01-16 20:37:17.980427: Epoch time: 40.74 s 
2025-01-16 20:37:17.982951: Yayy! New best EMA pseudo Dice: 0.557699978351593 
2025-01-16 20:37:18.884389:  
2025-01-16 20:37:18.885392: Epoch 37 
2025-01-16 20:37:18.890483: Current learning rate: 0.00866 
2025-01-16 20:37:59.608796: train_loss -0.688 
2025-01-16 20:37:59.608796: val_loss -0.5584 
2025-01-16 20:37:59.613806: Pseudo dice [np.float32(0.7881), np.float32(0.4767)] 
2025-01-16 20:37:59.617815: Epoch time: 40.72 s 
2025-01-16 20:37:59.620321: Yayy! New best EMA pseudo Dice: 0.5651999711990356 
2025-01-16 20:38:00.385015:  
2025-01-16 20:38:00.386015: Epoch 38 
2025-01-16 20:38:00.391113: Current learning rate: 0.00862 
2025-01-16 20:38:41.113496: train_loss -0.6909 
2025-01-16 20:38:41.114500: val_loss -0.5046 
2025-01-16 20:38:41.119513: Pseudo dice [np.float32(0.7253), np.float32(0.4114)] 
2025-01-16 20:38:41.123019: Epoch time: 40.73 s 
2025-01-16 20:38:41.126026: Yayy! New best EMA pseudo Dice: 0.565500020980835 
2025-01-16 20:38:41.905051:  
2025-01-16 20:38:41.905051: Epoch 39 
2025-01-16 20:38:41.911119: Current learning rate: 0.00858 
2025-01-16 20:39:22.623546: train_loss -0.6641 
2025-01-16 20:39:22.623546: val_loss -0.5356 
2025-01-16 20:39:22.630655: Pseudo dice [np.float32(0.7721), np.float32(0.4433)] 
2025-01-16 20:39:22.633787: Epoch time: 40.72 s 
2025-01-16 20:39:22.637322: Yayy! New best EMA pseudo Dice: 0.5697000026702881 
2025-01-16 20:39:23.452739:  
2025-01-16 20:39:23.453742: Epoch 40 
2025-01-16 20:39:23.458291: Current learning rate: 0.00855 
2025-01-16 20:40:04.174022: train_loss -0.6452 
2025-01-16 20:40:04.174531: val_loss -0.5503 
2025-01-16 20:40:04.180111: Pseudo dice [np.float32(0.7811), np.float32(0.4464)] 
2025-01-16 20:40:04.183171: Epoch time: 40.72 s 
2025-01-16 20:40:04.185708: Yayy! New best EMA pseudo Dice: 0.5741000175476074 
2025-01-16 20:40:04.964984:  
2025-01-16 20:40:04.964984: Epoch 41 
2025-01-16 20:40:04.970523: Current learning rate: 0.00851 
2025-01-16 20:40:45.693735: train_loss -0.6843 
2025-01-16 20:40:45.693735: val_loss -0.5578 
2025-01-16 20:40:45.699271: Pseudo dice [np.float32(0.7857), np.float32(0.3985)] 
2025-01-16 20:40:45.702778: Epoch time: 40.73 s 
2025-01-16 20:40:45.705788: Yayy! New best EMA pseudo Dice: 0.5759000182151794 
2025-01-16 20:40:46.440272:  
2025-01-16 20:40:46.441271: Epoch 42 
2025-01-16 20:40:46.446350: Current learning rate: 0.00847 
2025-01-16 20:41:27.205579: train_loss -0.6718 
2025-01-16 20:41:27.206583: val_loss -0.4921 
2025-01-16 20:41:27.211608: Pseudo dice [np.float32(0.7721), np.float32(0.3236)] 
2025-01-16 20:41:27.215088: Epoch time: 40.77 s 
2025-01-16 20:41:27.779406:  
2025-01-16 20:41:27.779406: Epoch 43 
2025-01-16 20:41:27.785990: Current learning rate: 0.00844 
2025-01-16 20:42:08.529587: train_loss -0.712 
2025-01-16 20:42:08.530106: val_loss -0.4793 
2025-01-16 20:42:08.534676: Pseudo dice [np.float32(0.7753), np.float32(0.3645)] 
2025-01-16 20:42:08.538724: Epoch time: 40.75 s 
2025-01-16 20:42:09.097813:  
2025-01-16 20:42:09.097813: Epoch 44 
2025-01-16 20:42:09.104375: Current learning rate: 0.0084 
2025-01-16 20:42:49.842111: train_loss -0.7064 
2025-01-16 20:42:49.843111: val_loss -0.5462 
2025-01-16 20:42:49.849627: Pseudo dice [np.float32(0.7746), np.float32(0.4648)] 
2025-01-16 20:42:49.853641: Epoch time: 40.75 s 
2025-01-16 20:42:49.858660: Yayy! New best EMA pseudo Dice: 0.5774999856948853 
2025-01-16 20:42:50.764251:  
2025-01-16 20:42:50.764251: Epoch 45 
2025-01-16 20:42:50.770796: Current learning rate: 0.00836 
2025-01-16 20:43:31.504213: train_loss -0.714 
2025-01-16 20:43:31.504715: val_loss -0.5204 
2025-01-16 20:43:31.509784: Pseudo dice [np.float32(0.784), np.float32(0.3498)] 
2025-01-16 20:43:31.514822: Epoch time: 40.74 s 
2025-01-16 20:43:32.065065:  
2025-01-16 20:43:32.065065: Epoch 46 
2025-01-16 20:43:32.071080: Current learning rate: 0.00833 
2025-01-16 20:44:12.807271: train_loss -0.6843 
2025-01-16 20:44:12.807786: val_loss -0.5112 
2025-01-16 20:44:12.813377: Pseudo dice [np.float32(0.7687), np.float32(0.3223)] 
2025-01-16 20:44:12.816431: Epoch time: 40.74 s 
2025-01-16 20:44:13.370546:  
2025-01-16 20:44:13.371049: Epoch 47 
2025-01-16 20:44:13.376085: Current learning rate: 0.00829 
2025-01-16 20:44:54.103416: train_loss -0.6767 
2025-01-16 20:44:54.103918: val_loss -0.5264 
2025-01-16 20:44:54.110000: Pseudo dice [np.float32(0.7838), np.float32(0.4053)] 
2025-01-16 20:44:54.113023: Epoch time: 40.73 s 
2025-01-16 20:44:54.659456:  
2025-01-16 20:44:54.660456: Epoch 48 
2025-01-16 20:44:54.666059: Current learning rate: 0.00825 
2025-01-16 20:45:35.404407: train_loss -0.7046 
2025-01-16 20:45:35.405914: val_loss -0.5117 
2025-01-16 20:45:35.411475: Pseudo dice [np.float32(0.7767), np.float32(0.4118)] 
2025-01-16 20:45:35.414987: Epoch time: 40.75 s 
2025-01-16 20:45:35.969324:  
2025-01-16 20:45:35.969841: Epoch 49 
2025-01-16 20:45:35.975854: Current learning rate: 0.00822 
2025-01-16 20:46:16.727209: train_loss -0.7229 
2025-01-16 20:46:16.727209: val_loss -0.5278 
2025-01-16 20:46:16.733232: Pseudo dice [np.float32(0.7576), np.float32(0.4382)] 
2025-01-16 20:46:16.736745: Epoch time: 40.76 s 
2025-01-16 20:46:16.894732: Yayy! New best EMA pseudo Dice: 0.5794000029563904 
2025-01-16 20:46:17.684080:  
2025-01-16 20:46:17.684583: Epoch 50 
2025-01-16 20:46:17.689594: Current learning rate: 0.00818 
2025-01-16 20:46:58.423765: train_loss -0.7144 
2025-01-16 20:46:58.424769: val_loss -0.5371 
2025-01-16 20:46:58.430784: Pseudo dice [np.float32(0.7605), np.float32(0.4585)] 
2025-01-16 20:46:58.433793: Epoch time: 40.74 s 
2025-01-16 20:46:58.437303: Yayy! New best EMA pseudo Dice: 0.5824000239372253 
2025-01-16 20:46:59.213166:  
2025-01-16 20:46:59.214170: Epoch 51 
2025-01-16 20:46:59.219206: Current learning rate: 0.00814 
2025-01-16 20:47:39.936970: train_loss -0.7214 
2025-01-16 20:47:39.937480: val_loss -0.5305 
2025-01-16 20:47:39.941509: Pseudo dice [np.float32(0.7847), np.float32(0.4314)] 
2025-01-16 20:47:39.945048: Epoch time: 40.72 s 
2025-01-16 20:47:39.948575: Yayy! New best EMA pseudo Dice: 0.5849999785423279 
2025-01-16 20:47:40.695433:  
2025-01-16 20:47:40.695433: Epoch 52 
2025-01-16 20:47:40.701463: Current learning rate: 0.00811 
2025-01-16 20:48:21.433561: train_loss -0.746 
2025-01-16 20:48:21.434064: val_loss -0.4715 
2025-01-16 20:48:21.439608: Pseudo dice [np.float32(0.761), np.float32(0.4217)] 
2025-01-16 20:48:21.443144: Epoch time: 40.74 s 
2025-01-16 20:48:21.446690: Yayy! New best EMA pseudo Dice: 0.5856000185012817 
2025-01-16 20:48:22.333126:  
2025-01-16 20:48:22.334130: Epoch 53 
2025-01-16 20:48:22.338684: Current learning rate: 0.00807 
2025-01-16 20:49:03.063936: train_loss -0.7457 
2025-01-16 20:49:03.063936: val_loss -0.4905 
2025-01-16 20:49:03.070471: Pseudo dice [np.float32(0.7348), np.float32(0.3915)] 
2025-01-16 20:49:03.074054: Epoch time: 40.73 s 
2025-01-16 20:49:03.631826:  
2025-01-16 20:49:03.631826: Epoch 54 
2025-01-16 20:49:03.636842: Current learning rate: 0.00803 
2025-01-16 20:49:44.372116: train_loss -0.7215 
2025-01-16 20:49:44.373116: val_loss -0.508 
2025-01-16 20:49:44.379633: Pseudo dice [np.float32(0.7637), np.float32(0.4725)] 
2025-01-16 20:49:44.383644: Epoch time: 40.74 s 
2025-01-16 20:49:44.387153: Yayy! New best EMA pseudo Dice: 0.5867999792098999 
2025-01-16 20:49:45.132108:  
2025-01-16 20:49:45.132611: Epoch 55 
2025-01-16 20:49:45.137624: Current learning rate: 0.008 
2025-01-16 20:50:25.868441: train_loss -0.7027 
2025-01-16 20:50:25.869444: val_loss -0.4889 
2025-01-16 20:50:25.877021: Pseudo dice [np.float32(0.7689), np.float32(0.332)] 
2025-01-16 20:50:25.881070: Epoch time: 40.74 s 
2025-01-16 20:50:26.435714:  
2025-01-16 20:50:26.435714: Epoch 56 
2025-01-16 20:50:26.441728: Current learning rate: 0.00796 
2025-01-16 20:51:07.184188: train_loss -0.7386 
2025-01-16 20:51:07.185703: val_loss -0.5239 
2025-01-16 20:51:07.192822: Pseudo dice [np.float32(0.7553), np.float32(0.4289)] 
2025-01-16 20:51:07.197833: Epoch time: 40.75 s 
2025-01-16 20:51:07.751228:  
2025-01-16 20:51:07.752228: Epoch 57 
2025-01-16 20:51:07.757803: Current learning rate: 0.00792 
2025-01-16 20:51:48.467294: train_loss -0.7046 
2025-01-16 20:51:48.468298: val_loss -0.5517 
2025-01-16 20:51:48.474844: Pseudo dice [np.float32(0.7829), np.float32(0.5197)] 
2025-01-16 20:51:48.479854: Epoch time: 40.72 s 
2025-01-16 20:51:48.484865: Yayy! New best EMA pseudo Dice: 0.5907999873161316 
2025-01-16 20:51:49.255650:  
2025-01-16 20:51:49.255650: Epoch 58 
2025-01-16 20:51:49.262198: Current learning rate: 0.00789 
2025-01-16 20:52:29.965983: train_loss -0.7228 
2025-01-16 20:52:29.965983: val_loss -0.4788 
2025-01-16 20:52:29.973567: Pseudo dice [np.float32(0.7333), np.float32(0.5089)] 
2025-01-16 20:52:29.978107: Epoch time: 40.71 s 
2025-01-16 20:52:29.983152: Yayy! New best EMA pseudo Dice: 0.5938000082969666 
2025-01-16 20:52:30.782030:  
2025-01-16 20:52:30.782532: Epoch 59 
2025-01-16 20:52:30.787543: Current learning rate: 0.00785 
2025-01-16 20:53:11.507572: train_loss -0.7267 
2025-01-16 20:53:11.508081: val_loss -0.5386 
2025-01-16 20:53:11.511119: Pseudo dice [np.float32(0.7873), np.float32(0.4718)] 
2025-01-16 20:53:11.514205: Epoch time: 40.73 s 
2025-01-16 20:53:11.517241: Yayy! New best EMA pseudo Dice: 0.5974000096321106 
2025-01-16 20:53:12.263144:  
2025-01-16 20:53:12.263646: Epoch 60 
2025-01-16 20:53:12.268657: Current learning rate: 0.00781 
2025-01-16 20:53:52.973324: train_loss -0.7362 
2025-01-16 20:53:52.974323: val_loss -0.5058 
2025-01-16 20:53:52.979935: Pseudo dice [np.float32(0.7659), np.float32(0.3919)] 
2025-01-16 20:53:52.982442: Epoch time: 40.71 s 
2025-01-16 20:53:53.681314:  
2025-01-16 20:53:53.681314: Epoch 61 
2025-01-16 20:53:53.686326: Current learning rate: 0.00777 
2025-01-16 20:54:34.413306: train_loss -0.7482 
2025-01-16 20:54:34.414812: val_loss -0.5285 
2025-01-16 20:54:34.419824: Pseudo dice [np.float32(0.7821), np.float32(0.4248)] 
2025-01-16 20:54:34.422330: Epoch time: 40.73 s 
2025-01-16 20:54:34.988673:  
2025-01-16 20:54:34.988673: Epoch 62 
2025-01-16 20:54:34.993716: Current learning rate: 0.00774 
2025-01-16 20:55:15.752961: train_loss -0.7534 
2025-01-16 20:55:15.753464: val_loss -0.4825 
2025-01-16 20:55:15.758537: Pseudo dice [np.float32(0.7643), np.float32(0.3275)] 
2025-01-16 20:55:15.762047: Epoch time: 40.76 s 
2025-01-16 20:55:16.323445:  
2025-01-16 20:55:16.323957: Epoch 63 
2025-01-16 20:55:16.329036: Current learning rate: 0.0077 
2025-01-16 20:55:57.055580: train_loss -0.7427 
2025-01-16 20:55:57.056583: val_loss -0.5638 
2025-01-16 20:55:57.062132: Pseudo dice [np.float32(0.7612), np.float32(0.5621)] 
2025-01-16 20:55:57.065162: Epoch time: 40.73 s 
2025-01-16 20:55:57.068730: Yayy! New best EMA pseudo Dice: 0.5982999801635742 
2025-01-16 20:55:57.809110:  
2025-01-16 20:55:57.810114: Epoch 64 
2025-01-16 20:55:57.814710: Current learning rate: 0.00766 
2025-01-16 20:56:38.554140: train_loss -0.7489 
2025-01-16 20:56:38.554643: val_loss -0.557 
2025-01-16 20:56:38.559659: Pseudo dice [np.float32(0.7823), np.float32(0.4181)] 
2025-01-16 20:56:38.563180: Epoch time: 40.75 s 
2025-01-16 20:56:38.565689: Yayy! New best EMA pseudo Dice: 0.5985000133514404 
2025-01-16 20:56:39.309094:  
2025-01-16 20:56:39.310093: Epoch 65 
2025-01-16 20:56:39.315195: Current learning rate: 0.00763 
2025-01-16 20:57:20.081240: train_loss -0.7688 
2025-01-16 20:57:20.081240: val_loss -0.5028 
2025-01-16 20:57:20.086831: Pseudo dice [np.float32(0.7591), np.float32(0.3466)] 
2025-01-16 20:57:20.089873: Epoch time: 40.77 s 
2025-01-16 20:57:20.656224:  
2025-01-16 20:57:20.656224: Epoch 66 
2025-01-16 20:57:20.659737: Current learning rate: 0.00759 
2025-01-16 20:58:01.405746: train_loss -0.7818 
2025-01-16 20:58:01.405746: val_loss -0.545 
2025-01-16 20:58:01.411345: Pseudo dice [np.float32(0.7619), np.float32(0.4788)] 
2025-01-16 20:58:01.414397: Epoch time: 40.75 s 
2025-01-16 20:58:01.981515:  
2025-01-16 20:58:01.981515: Epoch 67 
2025-01-16 20:58:01.986527: Current learning rate: 0.00755 
2025-01-16 20:58:42.720245: train_loss -0.7777 
2025-01-16 20:58:42.720748: val_loss -0.527 
2025-01-16 20:58:42.725765: Pseudo dice [np.float32(0.7569), np.float32(0.4035)] 
2025-01-16 20:58:42.729276: Epoch time: 40.74 s 
2025-01-16 20:58:43.302744:  
2025-01-16 20:58:43.302744: Epoch 68 
2025-01-16 20:58:43.308324: Current learning rate: 0.00751 
2025-01-16 20:59:24.061072: train_loss -0.7738 
2025-01-16 20:59:24.062075: val_loss -0.5428 
2025-01-16 20:59:24.067090: Pseudo dice [np.float32(0.7832), np.float32(0.5559)] 
2025-01-16 20:59:24.070099: Epoch time: 40.76 s 
2025-01-16 20:59:24.072606: Yayy! New best EMA pseudo Dice: 0.602400004863739 
2025-01-16 20:59:25.052849:  
2025-01-16 20:59:25.053848: Epoch 69 
2025-01-16 20:59:25.058927: Current learning rate: 0.00748 
2025-01-16 21:00:05.792383: train_loss -0.7819 
2025-01-16 21:00:05.792887: val_loss -0.4758 
2025-01-16 21:00:05.797960: Pseudo dice [np.float32(0.7793), np.float32(0.231)] 
2025-01-16 21:00:05.801022: Epoch time: 40.74 s 
2025-01-16 21:00:06.375472:  
2025-01-16 21:00:06.376476: Epoch 70 
2025-01-16 21:00:06.381036: Current learning rate: 0.00744 
2025-01-16 21:00:47.106152: train_loss -0.7812 
2025-01-16 21:00:47.106656: val_loss -0.5273 
2025-01-16 21:00:47.111670: Pseudo dice [np.float32(0.7974), np.float32(0.3769)] 
2025-01-16 21:00:47.114178: Epoch time: 40.73 s 
2025-01-16 21:00:47.681304:  
2025-01-16 21:00:47.681809: Epoch 71 
2025-01-16 21:00:47.686827: Current learning rate: 0.0074 
2025-01-16 21:01:28.443748: train_loss -0.7672 
2025-01-16 21:01:28.444258: val_loss -0.5114 
2025-01-16 21:01:28.449305: Pseudo dice [np.float32(0.7701), np.float32(0.3806)] 
2025-01-16 21:01:28.452830: Epoch time: 40.76 s 
2025-01-16 21:01:29.029999:  
2025-01-16 21:01:29.030508: Epoch 72 
2025-01-16 21:01:29.038170: Current learning rate: 0.00737 
2025-01-16 21:02:09.780797: train_loss -0.7813 
2025-01-16 21:02:09.781306: val_loss -0.4859 
2025-01-16 21:02:09.786877: Pseudo dice [np.float32(0.7739), np.float32(0.3855)] 
2025-01-16 21:02:09.789899: Epoch time: 40.75 s 
2025-01-16 21:02:10.357410:  
2025-01-16 21:02:10.357410: Epoch 73 
2025-01-16 21:02:10.362956: Current learning rate: 0.00733 
2025-01-16 21:02:51.101220: train_loss -0.7859 
2025-01-16 21:02:51.102221: val_loss -0.5512 
2025-01-16 21:02:51.107740: Pseudo dice [np.float32(0.7682), np.float32(0.538)] 
2025-01-16 21:02:51.111252: Epoch time: 40.74 s 
2025-01-16 21:02:51.687370:  
2025-01-16 21:02:51.688373: Epoch 74 
2025-01-16 21:02:51.692920: Current learning rate: 0.00729 
2025-01-16 21:03:32.419709: train_loss -0.7993 
2025-01-16 21:03:32.420224: val_loss -0.551 
2025-01-16 21:03:32.426852: Pseudo dice [np.float32(0.7806), np.float32(0.4476)] 
2025-01-16 21:03:32.429404: Epoch time: 40.73 s 
2025-01-16 21:03:32.998844:  
2025-01-16 21:03:32.998844: Epoch 75 
2025-01-16 21:03:33.003462: Current learning rate: 0.00725 
2025-01-16 21:04:13.733121: train_loss -0.7988 
2025-01-16 21:04:13.734126: val_loss -0.4982 
2025-01-16 21:04:13.738667: Pseudo dice [np.float32(0.7603), np.float32(0.3774)] 
2025-01-16 21:04:13.741694: Epoch time: 40.74 s 
2025-01-16 21:04:14.314191:  
2025-01-16 21:04:14.314191: Epoch 76 
2025-01-16 21:04:14.319242: Current learning rate: 0.00722 
2025-01-16 21:04:55.053881: train_loss -0.7859 
2025-01-16 21:04:55.054887: val_loss -0.5272 
2025-01-16 21:04:55.058895: Pseudo dice [np.float32(0.7381), np.float32(0.3647)] 
2025-01-16 21:04:55.061401: Epoch time: 40.74 s 
2025-01-16 21:04:55.796083:  
2025-01-16 21:04:55.796083: Epoch 77 
2025-01-16 21:04:55.801677: Current learning rate: 0.00718 
2025-01-16 21:05:36.543847: train_loss -0.7601 
2025-01-16 21:05:36.544359: val_loss -0.5322 
2025-01-16 21:05:36.548911: Pseudo dice [np.float32(0.78), np.float32(0.3918)] 
2025-01-16 21:05:36.552491: Epoch time: 40.75 s 
2025-01-16 21:05:37.129903:  
2025-01-16 21:05:37.130405: Epoch 78 
2025-01-16 21:05:37.135418: Current learning rate: 0.00714 
2025-01-16 21:06:17.861204: train_loss -0.7836 
2025-01-16 21:06:17.861204: val_loss -0.4772 
2025-01-16 21:06:17.867219: Pseudo dice [np.float32(0.777), np.float32(0.3128)] 
2025-01-16 21:06:17.870229: Epoch time: 40.73 s 
2025-01-16 21:06:18.448496:  
2025-01-16 21:06:18.448496: Epoch 79 
2025-01-16 21:06:18.453512: Current learning rate: 0.0071 
2025-01-16 21:06:59.173819: train_loss -0.7669 
2025-01-16 21:06:59.174819: val_loss -0.5309 
2025-01-16 21:06:59.179833: Pseudo dice [np.float32(0.7818), np.float32(0.4418)] 
2025-01-16 21:06:59.182843: Epoch time: 40.73 s 
2025-01-16 21:06:59.775826:  
2025-01-16 21:06:59.776329: Epoch 80 
2025-01-16 21:06:59.781343: Current learning rate: 0.00707 
2025-01-16 21:07:40.511137: train_loss -0.7727 
2025-01-16 21:07:40.512141: val_loss -0.5001 
2025-01-16 21:07:40.517154: Pseudo dice [np.float32(0.7735), np.float32(0.4234)] 
2025-01-16 21:07:40.520663: Epoch time: 40.74 s 
2025-01-16 21:07:41.093469:  
2025-01-16 21:07:41.094975: Epoch 81 
2025-01-16 21:07:41.099987: Current learning rate: 0.00703 
2025-01-16 21:08:21.816900: train_loss -0.7705 
2025-01-16 21:08:21.818416: val_loss -0.5287 
2025-01-16 21:08:21.822484: Pseudo dice [np.float32(0.7917), np.float32(0.4114)] 
2025-01-16 21:08:21.826510: Epoch time: 40.72 s 
2025-01-16 21:08:22.411954:  
2025-01-16 21:08:22.412954: Epoch 82 
2025-01-16 21:08:22.417522: Current learning rate: 0.00699 
2025-01-16 21:09:03.132892: train_loss -0.7775 
2025-01-16 21:09:03.133414: val_loss -0.4991 
2025-01-16 21:09:03.138494: Pseudo dice [np.float32(0.776), np.float32(0.4396)] 
2025-01-16 21:09:03.142008: Epoch time: 40.72 s 
2025-01-16 21:09:03.692318:  
2025-01-16 21:09:03.693323: Epoch 83 
2025-01-16 21:09:03.697355: Current learning rate: 0.00696 
2025-01-16 21:09:44.390972: train_loss -0.7877 
2025-01-16 21:09:44.390972: val_loss -0.5324 
2025-01-16 21:09:44.396539: Pseudo dice [np.float32(0.7673), np.float32(0.437)] 
2025-01-16 21:09:44.399593: Epoch time: 40.7 s 
2025-01-16 21:09:44.941902:  
2025-01-16 21:09:44.941902: Epoch 84 
2025-01-16 21:09:44.946940: Current learning rate: 0.00692 
2025-01-16 21:10:25.649933: train_loss -0.7888 
2025-01-16 21:10:25.650441: val_loss -0.5464 
2025-01-16 21:10:25.656006: Pseudo dice [np.float32(0.7788), np.float32(0.4459)] 
2025-01-16 21:10:25.658053: Epoch time: 40.71 s 
2025-01-16 21:10:26.361082:  
2025-01-16 21:10:26.362085: Epoch 85 
2025-01-16 21:10:26.366641: Current learning rate: 0.00688 
2025-01-16 21:11:07.074813: train_loss -0.7873 
2025-01-16 21:11:07.075320: val_loss -0.5429 
2025-01-16 21:11:07.080912: Pseudo dice [np.float32(0.7621), np.float32(0.6046)] 
2025-01-16 21:11:07.083454: Epoch time: 40.71 s 
2025-01-16 21:11:07.085959: Yayy! New best EMA pseudo Dice: 0.6039000153541565 
2025-01-16 21:11:07.855437:  
2025-01-16 21:11:07.855437: Epoch 86 
2025-01-16 21:11:07.860485: Current learning rate: 0.00684 
2025-01-16 21:11:48.570886: train_loss -0.8023 
2025-01-16 21:11:48.571889: val_loss -0.5529 
2025-01-16 21:11:48.577346: Pseudo dice [np.float32(0.7738), np.float32(0.7017)] 
2025-01-16 21:11:48.580863: Epoch time: 40.72 s 
2025-01-16 21:11:48.584023: Yayy! New best EMA pseudo Dice: 0.6172999739646912 
2025-01-16 21:11:49.377380:  
2025-01-16 21:11:49.377380: Epoch 87 
2025-01-16 21:11:49.382441: Current learning rate: 0.0068 
2025-01-16 21:12:30.098685: train_loss -0.792 
2025-01-16 21:12:30.099690: val_loss -0.5093 
2025-01-16 21:12:30.105348: Pseudo dice [np.float32(0.7892), np.float32(0.3788)] 
2025-01-16 21:12:30.107882: Epoch time: 40.72 s 
2025-01-16 21:12:30.662182:  
2025-01-16 21:12:30.662182: Epoch 88 
2025-01-16 21:12:30.667194: Current learning rate: 0.00677 
2025-01-16 21:13:11.375858: train_loss -0.7975 
2025-01-16 21:13:11.376856: val_loss -0.5228 
2025-01-16 21:13:11.381919: Pseudo dice [np.float32(0.7443), np.float32(0.4325)] 
2025-01-16 21:13:11.384948: Epoch time: 40.72 s 
2025-01-16 21:13:11.926281:  
2025-01-16 21:13:11.927278: Epoch 89 
2025-01-16 21:13:11.932383: Current learning rate: 0.00673 
2025-01-16 21:13:52.654062: train_loss -0.7973 
2025-01-16 21:13:52.654583: val_loss -0.4709 
2025-01-16 21:13:52.659224: Pseudo dice [np.float32(0.7674), np.float32(0.2823)] 
2025-01-16 21:13:52.661756: Epoch time: 40.73 s 
2025-01-16 21:13:53.223125:  
2025-01-16 21:13:53.223629: Epoch 90 
2025-01-16 21:13:53.228142: Current learning rate: 0.00669 
2025-01-16 21:14:33.957981: train_loss -0.8094 
2025-01-16 21:14:33.959004: val_loss -0.5058 
2025-01-16 21:14:33.965088: Pseudo dice [np.float32(0.7797), np.float32(0.4485)] 
2025-01-16 21:14:33.969208: Epoch time: 40.74 s 
2025-01-16 21:14:34.509578:  
2025-01-16 21:14:34.510577: Epoch 91 
2025-01-16 21:14:34.516170: Current learning rate: 0.00665 
2025-01-16 21:15:15.234946: train_loss -0.7921 
2025-01-16 21:15:15.234946: val_loss -0.5528 
2025-01-16 21:15:15.239961: Pseudo dice [np.float32(0.7926), np.float32(0.4091)] 
2025-01-16 21:15:15.243472: Epoch time: 40.73 s 
2025-01-16 21:15:15.801544:  
2025-01-16 21:15:15.801544: Epoch 92 
2025-01-16 21:15:15.806556: Current learning rate: 0.00662 
2025-01-16 21:15:56.537372: train_loss -0.806 
2025-01-16 21:15:56.537882: val_loss -0.5117 
2025-01-16 21:15:56.543485: Pseudo dice [np.float32(0.7721), np.float32(0.5508)] 
2025-01-16 21:15:56.546533: Epoch time: 40.74 s 
2025-01-16 21:15:57.250473:  
2025-01-16 21:15:57.251476: Epoch 93 
2025-01-16 21:15:57.256572: Current learning rate: 0.00658 
2025-01-16 21:16:37.996980: train_loss -0.8017 
2025-01-16 21:16:37.996980: val_loss -0.5518 
2025-01-16 21:16:38.004142: Pseudo dice [np.float32(0.7831), np.float32(0.4481)] 
2025-01-16 21:16:38.007652: Epoch time: 40.75 s 
2025-01-16 21:16:38.553227:  
2025-01-16 21:16:38.554227: Epoch 94 
2025-01-16 21:16:38.559822: Current learning rate: 0.00654 
2025-01-16 21:17:19.301600: train_loss -0.8013 
2025-01-16 21:17:19.301600: val_loss -0.5554 
2025-01-16 21:17:19.307180: Pseudo dice [np.float32(0.7996), np.float32(0.5888)] 
2025-01-16 21:17:19.310753: Epoch time: 40.75 s 
2025-01-16 21:17:19.313785: Yayy! New best EMA pseudo Dice: 0.618399977684021 
2025-01-16 21:17:20.060920:  
2025-01-16 21:17:20.060920: Epoch 95 
2025-01-16 21:17:20.066143: Current learning rate: 0.0065 
2025-01-16 21:18:00.813153: train_loss -0.8079 
2025-01-16 21:18:00.813660: val_loss -0.5199 
2025-01-16 21:18:00.819220: Pseudo dice [np.float32(0.7707), np.float32(0.3618)] 
2025-01-16 21:18:00.822248: Epoch time: 40.75 s 
2025-01-16 21:18:01.374851:  
2025-01-16 21:18:01.375854: Epoch 96 
2025-01-16 21:18:01.380428: Current learning rate: 0.00647 
2025-01-16 21:18:42.102609: train_loss -0.8141 
2025-01-16 21:18:42.103124: val_loss -0.4799 
2025-01-16 21:18:42.108690: Pseudo dice [np.float32(0.7523), np.float32(0.4411)] 
2025-01-16 21:18:42.111720: Epoch time: 40.73 s 
2025-01-16 21:18:42.665609:  
2025-01-16 21:18:42.665609: Epoch 97 
2025-01-16 21:18:42.671149: Current learning rate: 0.00643 
2025-01-16 21:19:23.396992: train_loss -0.8172 
2025-01-16 21:19:23.397995: val_loss -0.5528 
2025-01-16 21:19:23.403008: Pseudo dice [np.float32(0.803), np.float32(0.5584)] 
2025-01-16 21:19:23.407016: Epoch time: 40.73 s 
2025-01-16 21:19:23.409521: Yayy! New best EMA pseudo Dice: 0.6184999942779541 
2025-01-16 21:19:24.188648:  
2025-01-16 21:19:24.189151: Epoch 98 
2025-01-16 21:19:24.194161: Current learning rate: 0.00639 
2025-01-16 21:20:04.933797: train_loss -0.8122 
2025-01-16 21:20:04.934301: val_loss -0.5332 
2025-01-16 21:20:04.939862: Pseudo dice [np.float32(0.7909), np.float32(0.4548)] 
2025-01-16 21:20:04.942902: Epoch time: 40.75 s 
2025-01-16 21:20:04.945408: Yayy! New best EMA pseudo Dice: 0.6189000010490417 
2025-01-16 21:20:05.743234:  
2025-01-16 21:20:05.743234: Epoch 99 
2025-01-16 21:20:05.748834: Current learning rate: 0.00635 
2025-01-16 21:20:46.479217: train_loss -0.8028 
2025-01-16 21:20:46.479733: val_loss -0.5434 
2025-01-16 21:20:46.485315: Pseudo dice [np.float32(0.7992), np.float32(0.4644)] 
2025-01-16 21:20:46.487855: Epoch time: 40.74 s 
2025-01-16 21:20:46.665469: Yayy! New best EMA pseudo Dice: 0.620199978351593 
2025-01-16 21:20:47.466434:  
2025-01-16 21:20:47.467438: Epoch 100 
2025-01-16 21:20:47.472474: Current learning rate: 0.00631 
2025-01-16 21:21:28.204942: train_loss -0.8113 
2025-01-16 21:21:28.205445: val_loss -0.548 
2025-01-16 21:21:28.210495: Pseudo dice [np.float32(0.7829), np.float32(0.4583)] 
2025-01-16 21:21:28.214064: Epoch time: 40.74 s 
2025-01-16 21:21:28.217097: Yayy! New best EMA pseudo Dice: 0.620199978351593 
2025-01-16 21:21:29.001689:  
2025-01-16 21:21:29.002203: Epoch 101 
2025-01-16 21:21:29.007258: Current learning rate: 0.00628 
2025-01-16 21:22:09.721899: train_loss -0.8179 
2025-01-16 21:22:09.722899: val_loss -0.5492 
2025-01-16 21:22:09.728498: Pseudo dice [np.float32(0.7791), np.float32(0.5186)] 
2025-01-16 21:22:09.731004: Epoch time: 40.72 s 
2025-01-16 21:22:09.734514: Yayy! New best EMA pseudo Dice: 0.6230999827384949 
2025-01-16 21:22:10.703266:  
2025-01-16 21:22:10.703768: Epoch 102 
2025-01-16 21:22:10.708782: Current learning rate: 0.00624 
2025-01-16 21:22:51.432038: train_loss -0.8299 
2025-01-16 21:22:51.433060: val_loss -0.5023 
2025-01-16 21:22:51.438686: Pseudo dice [np.float32(0.7911), np.float32(0.5477)] 
2025-01-16 21:22:51.441191: Epoch time: 40.73 s 
2025-01-16 21:22:51.444697: Yayy! New best EMA pseudo Dice: 0.6276999711990356 
2025-01-16 21:22:52.234896:  
2025-01-16 21:22:52.235896: Epoch 103 
2025-01-16 21:22:52.240971: Current learning rate: 0.0062 
2025-01-16 21:23:32.942390: train_loss -0.8394 
2025-01-16 21:23:32.943388: val_loss -0.5276 
2025-01-16 21:23:32.948905: Pseudo dice [np.float32(0.7724), np.float32(0.5351)] 
2025-01-16 21:23:32.951410: Epoch time: 40.71 s 
2025-01-16 21:23:32.953916: Yayy! New best EMA pseudo Dice: 0.630299985408783 
2025-01-16 21:23:33.752539:  
2025-01-16 21:23:33.753042: Epoch 104 
2025-01-16 21:23:33.758053: Current learning rate: 0.00616 
2025-01-16 21:24:14.486070: train_loss -0.8379 
2025-01-16 21:24:14.487073: val_loss -0.5158 
2025-01-16 21:24:14.492740: Pseudo dice [np.float32(0.7862), np.float32(0.5561)] 
2025-01-16 21:24:14.495245: Epoch time: 40.73 s 
2025-01-16 21:24:14.498755: Yayy! New best EMA pseudo Dice: 0.6344000101089478 
2025-01-16 21:24:15.277570:  
2025-01-16 21:24:15.278573: Epoch 105 
2025-01-16 21:24:15.284113: Current learning rate: 0.00612 
2025-01-16 21:24:55.987489: train_loss -0.8373 
2025-01-16 21:24:55.987991: val_loss -0.5202 
2025-01-16 21:24:55.993610: Pseudo dice [np.float32(0.7997), np.float32(0.4249)] 
2025-01-16 21:24:55.996645: Epoch time: 40.71 s 
2025-01-16 21:24:56.559619:  
2025-01-16 21:24:56.560619: Epoch 106 
2025-01-16 21:24:56.566196: Current learning rate: 0.00609 
2025-01-16 21:25:37.274614: train_loss -0.8285 
2025-01-16 21:25:37.275121: val_loss -0.5174 
2025-01-16 21:25:37.280745: Pseudo dice [np.float32(0.7908), np.float32(0.4304)] 
2025-01-16 21:25:37.284294: Epoch time: 40.72 s 
2025-01-16 21:25:37.853679:  
2025-01-16 21:25:37.853679: Epoch 107 
2025-01-16 21:25:37.859210: Current learning rate: 0.00605 
2025-01-16 21:26:18.572479: train_loss -0.8517 
2025-01-16 21:26:18.573482: val_loss -0.5296 
2025-01-16 21:26:18.577519: Pseudo dice [np.float32(0.7918), np.float32(0.551)] 
2025-01-16 21:26:18.580029: Epoch time: 40.72 s 
2025-01-16 21:26:19.138763:  
2025-01-16 21:26:19.138763: Epoch 108 
2025-01-16 21:26:19.143809: Current learning rate: 0.00601 
2025-01-16 21:26:59.849570: train_loss -0.8423 
2025-01-16 21:26:59.850573: val_loss -0.5556 
2025-01-16 21:26:59.856163: Pseudo dice [np.float32(0.783), np.float32(0.5598)] 
2025-01-16 21:26:59.859194: Epoch time: 40.71 s 
2025-01-16 21:26:59.862226: Yayy! New best EMA pseudo Dice: 0.6378999948501587 
2025-01-16 21:27:00.643476:  
2025-01-16 21:27:00.643476: Epoch 109 
2025-01-16 21:27:00.649038: Current learning rate: 0.00597 
2025-01-16 21:27:41.401977: train_loss -0.8378 
2025-01-16 21:27:41.402480: val_loss -0.5412 
2025-01-16 21:27:41.407544: Pseudo dice [np.float32(0.7844), np.float32(0.5441)] 
2025-01-16 21:27:41.411053: Epoch time: 40.76 s 
2025-01-16 21:27:41.414560: Yayy! New best EMA pseudo Dice: 0.640500009059906 
2025-01-16 21:27:42.207755:  
2025-01-16 21:27:42.207755: Epoch 110 
2025-01-16 21:27:42.211797: Current learning rate: 0.00593 
2025-01-16 21:28:22.927276: train_loss -0.8336 
2025-01-16 21:28:22.927783: val_loss -0.5234 
2025-01-16 21:28:22.933353: Pseudo dice [np.float32(0.7778), np.float32(0.4422)] 
2025-01-16 21:28:22.936406: Epoch time: 40.72 s 
2025-01-16 21:28:23.500703:  
2025-01-16 21:28:23.500703: Epoch 111 
2025-01-16 21:28:23.506723: Current learning rate: 0.0059 
2025-01-16 21:29:04.204447: train_loss -0.8116 
2025-01-16 21:29:04.205475: val_loss -0.5174 
2025-01-16 21:29:04.210524: Pseudo dice [np.float32(0.7817), np.float32(0.3961)] 
2025-01-16 21:29:04.213048: Epoch time: 40.7 s 
2025-01-16 21:29:04.766924:  
2025-01-16 21:29:04.767433: Epoch 112 
2025-01-16 21:29:04.771960: Current learning rate: 0.00586 
2025-01-16 21:29:45.477474: train_loss -0.8371 
2025-01-16 21:29:45.478991: val_loss -0.4729 
2025-01-16 21:29:45.484064: Pseudo dice [np.float32(0.7673), np.float32(0.396)] 
2025-01-16 21:29:45.487103: Epoch time: 40.71 s 
2025-01-16 21:29:46.042161:  
2025-01-16 21:29:46.042161: Epoch 113 
2025-01-16 21:29:46.047789: Current learning rate: 0.00582 
2025-01-16 21:30:26.739385: train_loss -0.835 
2025-01-16 21:30:26.739385: val_loss -0.5372 
2025-01-16 21:30:26.744452: Pseudo dice [np.float32(0.7773), np.float32(0.387)] 
2025-01-16 21:30:26.747977: Epoch time: 40.7 s 
2025-01-16 21:30:27.301575:  
2025-01-16 21:30:27.302579: Epoch 114 
2025-01-16 21:30:27.308124: Current learning rate: 0.00578 
2025-01-16 21:31:08.003272: train_loss -0.8451 
2025-01-16 21:31:08.003777: val_loss -0.4859 
2025-01-16 21:31:08.009342: Pseudo dice [np.float32(0.7667), np.float32(0.5019)] 
2025-01-16 21:31:08.012898: Epoch time: 40.7 s 
2025-01-16 21:31:08.565001:  
2025-01-16 21:31:08.566005: Epoch 115 
2025-01-16 21:31:08.570554: Current learning rate: 0.00574 
2025-01-16 21:31:49.259638: train_loss -0.8199 
2025-01-16 21:31:49.260641: val_loss -0.5111 
2025-01-16 21:31:49.266206: Pseudo dice [np.float32(0.7587), np.float32(0.5511)] 
2025-01-16 21:31:49.269294: Epoch time: 40.69 s 
2025-01-16 21:31:49.833381:  
2025-01-16 21:31:49.834384: Epoch 116 
2025-01-16 21:31:49.838971: Current learning rate: 0.0057 
2025-01-16 21:32:30.525274: train_loss -0.8221 
2025-01-16 21:32:30.525780: val_loss -0.5262 
2025-01-16 21:32:30.530398: Pseudo dice [np.float32(0.7739), np.float32(0.4656)] 
2025-01-16 21:32:30.533943: Epoch time: 40.69 s 
2025-01-16 21:32:31.093007:  
2025-01-16 21:32:31.093007: Epoch 117 
2025-01-16 21:32:31.099037: Current learning rate: 0.00567 
2025-01-16 21:33:11.813831: train_loss -0.8311 
2025-01-16 21:33:11.814343: val_loss -0.4697 
2025-01-16 21:33:11.819936: Pseudo dice [np.float32(0.7588), np.float32(0.3646)] 
2025-01-16 21:33:11.822964: Epoch time: 40.72 s 
2025-01-16 21:33:12.536531:  
2025-01-16 21:33:12.537531: Epoch 118 
2025-01-16 21:33:12.543107: Current learning rate: 0.00563 
2025-01-16 21:33:53.259341: train_loss -0.8326 
2025-01-16 21:33:53.260407: val_loss -0.5501 
2025-01-16 21:33:53.265477: Pseudo dice [np.float32(0.7897), np.float32(0.4578)] 
2025-01-16 21:33:53.268511: Epoch time: 40.72 s 
2025-01-16 21:33:53.832704:  
2025-01-16 21:33:53.833211: Epoch 119 
2025-01-16 21:33:53.837249: Current learning rate: 0.00559 
2025-01-16 21:34:34.532346: train_loss -0.836 
2025-01-16 21:34:34.532848: val_loss -0.5362 
2025-01-16 21:34:34.538944: Pseudo dice [np.float32(0.7906), np.float32(0.6075)] 
2025-01-16 21:34:34.542986: Epoch time: 40.7 s 
2025-01-16 21:34:35.107436:  
2025-01-16 21:34:35.108437: Epoch 120 
2025-01-16 21:34:35.114020: Current learning rate: 0.00555 
2025-01-16 21:35:15.827074: train_loss -0.8528 
2025-01-16 21:35:15.828078: val_loss -0.5343 
2025-01-16 21:35:15.833623: Pseudo dice [np.float32(0.7713), np.float32(0.4324)] 
2025-01-16 21:35:15.836653: Epoch time: 40.72 s 
2025-01-16 21:35:16.400130:  
2025-01-16 21:35:16.400631: Epoch 121 
2025-01-16 21:35:16.407722: Current learning rate: 0.00551 
2025-01-16 21:35:57.122771: train_loss -0.8523 
2025-01-16 21:35:57.122771: val_loss -0.5521 
2025-01-16 21:35:57.129411: Pseudo dice [np.float32(0.806), np.float32(0.4521)] 
2025-01-16 21:35:57.132957: Epoch time: 40.72 s 
2025-01-16 21:35:57.695683:  
2025-01-16 21:35:57.696682: Epoch 122 
2025-01-16 21:35:57.704786: Current learning rate: 0.00547 
2025-01-16 21:36:38.414943: train_loss -0.8511 
2025-01-16 21:36:38.415943: val_loss -0.5728 
2025-01-16 21:36:38.422465: Pseudo dice [np.float32(0.783), np.float32(0.4741)] 
2025-01-16 21:36:38.426473: Epoch time: 40.72 s 
2025-01-16 21:36:38.989100:  
2025-01-16 21:36:38.989100: Epoch 123 
2025-01-16 21:36:38.996177: Current learning rate: 0.00544 
2025-01-16 21:37:19.686574: train_loss -0.83 
2025-01-16 21:37:19.686574: val_loss -0.5435 
2025-01-16 21:37:19.693709: Pseudo dice [np.float32(0.7871), np.float32(0.4481)] 
2025-01-16 21:37:19.697765: Epoch time: 40.7 s 
2025-01-16 21:37:20.262672:  
2025-01-16 21:37:20.263669: Epoch 124 
2025-01-16 21:37:20.269261: Current learning rate: 0.0054 
2025-01-16 21:38:00.981053: train_loss -0.8453 
2025-01-16 21:38:00.982056: val_loss -0.5248 
2025-01-16 21:38:00.988632: Pseudo dice [np.float32(0.7791), np.float32(0.437)] 
2025-01-16 21:38:00.992169: Epoch time: 40.72 s 
2025-01-16 21:38:01.561163:  
2025-01-16 21:38:01.562164: Epoch 125 
2025-01-16 21:38:01.567749: Current learning rate: 0.00536 
2025-01-16 21:38:42.285262: train_loss -0.8354 
2025-01-16 21:38:42.286281: val_loss -0.5153 
2025-01-16 21:38:42.293892: Pseudo dice [np.float32(0.7736), np.float32(0.3441)] 
2025-01-16 21:38:42.297930: Epoch time: 40.72 s 
2025-01-16 21:38:43.015826:  
2025-01-16 21:38:43.015826: Epoch 126 
2025-01-16 21:38:43.021859: Current learning rate: 0.00532 
2025-01-16 21:39:23.750244: train_loss -0.8556 
2025-01-16 21:39:23.750746: val_loss -0.5479 
2025-01-16 21:39:23.756788: Pseudo dice [np.float32(0.784), np.float32(0.4562)] 
2025-01-16 21:39:23.760311: Epoch time: 40.74 s 
2025-01-16 21:39:24.326462:  
2025-01-16 21:39:24.326462: Epoch 127 
2025-01-16 21:39:24.333600: Current learning rate: 0.00528 
2025-01-16 21:40:05.039844: train_loss -0.854 
2025-01-16 21:40:05.040349: val_loss -0.4916 
2025-01-16 21:40:05.046912: Pseudo dice [np.float32(0.7744), np.float32(0.4199)] 
2025-01-16 21:40:05.051465: Epoch time: 40.71 s 
2025-01-16 21:40:05.631118:  
2025-01-16 21:40:05.632118: Epoch 128 
2025-01-16 21:40:05.637172: Current learning rate: 0.00524 
2025-01-16 21:40:46.340930: train_loss -0.8714 
2025-01-16 21:40:46.341435: val_loss -0.5099 
2025-01-16 21:40:46.348565: Pseudo dice [np.float32(0.7954), np.float32(0.5002)] 
2025-01-16 21:40:46.353712: Epoch time: 40.71 s 
2025-01-16 21:40:46.916682:  
2025-01-16 21:40:46.916682: Epoch 129 
2025-01-16 21:40:46.922745: Current learning rate: 0.0052 
2025-01-16 21:41:27.632107: train_loss -0.8399 
2025-01-16 21:41:27.632610: val_loss -0.5796 
2025-01-16 21:41:27.638650: Pseudo dice [np.float32(0.7804), np.float32(0.5649)] 
2025-01-16 21:41:27.642665: Epoch time: 40.72 s 
2025-01-16 21:41:28.217382:  
2025-01-16 21:41:28.217885: Epoch 130 
2025-01-16 21:41:28.223434: Current learning rate: 0.00517 
2025-01-16 21:42:08.931453: train_loss -0.8487 
2025-01-16 21:42:08.932961: val_loss -0.5083 
2025-01-16 21:42:08.939071: Pseudo dice [np.float32(0.774), np.float32(0.5325)] 
2025-01-16 21:42:08.943616: Epoch time: 40.72 s 
2025-01-16 21:42:09.509574:  
2025-01-16 21:42:09.509574: Epoch 131 
2025-01-16 21:42:09.515640: Current learning rate: 0.00513 
2025-01-16 21:42:50.235297: train_loss -0.856 
2025-01-16 21:42:50.235297: val_loss -0.5548 
2025-01-16 21:42:50.241872: Pseudo dice [np.float32(0.8004), np.float32(0.4285)] 
2025-01-16 21:42:50.244911: Epoch time: 40.73 s 
2025-01-16 21:42:50.812948:  
2025-01-16 21:42:50.813462: Epoch 132 
2025-01-16 21:42:50.821104: Current learning rate: 0.00509 
2025-01-16 21:43:31.517017: train_loss -0.8589 
2025-01-16 21:43:31.517017: val_loss -0.4944 
2025-01-16 21:43:31.524073: Pseudo dice [np.float32(0.7886), np.float32(0.4674)] 
2025-01-16 21:43:31.528096: Epoch time: 40.71 s 
2025-01-16 21:43:32.095001:  
2025-01-16 21:43:32.095001: Epoch 133 
2025-01-16 21:43:32.101066: Current learning rate: 0.00505 
2025-01-16 21:44:12.811785: train_loss -0.8636 
2025-01-16 21:44:12.812290: val_loss -0.5363 
2025-01-16 21:44:12.818832: Pseudo dice [np.float32(0.7613), np.float32(0.4308)] 
2025-01-16 21:44:12.822369: Epoch time: 40.72 s 
2025-01-16 21:44:13.549276:  
2025-01-16 21:44:13.549276: Epoch 134 
2025-01-16 21:44:13.555292: Current learning rate: 0.00501 
2025-01-16 21:44:54.284196: train_loss -0.84 
2025-01-16 21:44:54.284701: val_loss -0.4863 
2025-01-16 21:44:54.290273: Pseudo dice [np.float32(0.7612), np.float32(0.3039)] 
2025-01-16 21:44:54.295318: Epoch time: 40.74 s 
2025-01-16 21:44:54.870207:  
2025-01-16 21:44:54.870207: Epoch 135 
2025-01-16 21:44:54.877265: Current learning rate: 0.00497 
2025-01-16 21:45:35.597482: train_loss -0.8353 
2025-01-16 21:45:35.598482: val_loss -0.5678 
2025-01-16 21:45:35.603999: Pseudo dice [np.float32(0.7975), np.float32(0.453)] 
2025-01-16 21:45:35.609039: Epoch time: 40.73 s 
2025-01-16 21:45:36.177084:  
2025-01-16 21:45:36.177084: Epoch 136 
2025-01-16 21:45:36.183135: Current learning rate: 0.00493 
2025-01-16 21:46:16.900238: train_loss -0.8609 
2025-01-16 21:46:16.900238: val_loss -0.513 
2025-01-16 21:46:16.907847: Pseudo dice [np.float32(0.7945), np.float32(0.4494)] 
2025-01-16 21:46:16.912358: Epoch time: 40.72 s 
2025-01-16 21:46:17.483918:  
2025-01-16 21:46:17.483918: Epoch 137 
2025-01-16 21:46:17.489933: Current learning rate: 0.00489 
2025-01-16 21:46:58.214931: train_loss -0.8495 
2025-01-16 21:46:58.215434: val_loss -0.5498 
2025-01-16 21:46:58.222062: Pseudo dice [np.float32(0.7824), np.float32(0.5347)] 
2025-01-16 21:46:58.226622: Epoch time: 40.73 s 
2025-01-16 21:46:58.799856:  
2025-01-16 21:46:58.799856: Epoch 138 
2025-01-16 21:46:58.806911: Current learning rate: 0.00485 
2025-01-16 21:47:39.527130: train_loss -0.8578 
2025-01-16 21:47:39.527130: val_loss -0.5309 
2025-01-16 21:47:39.534214: Pseudo dice [np.float32(0.7901), np.float32(0.3918)] 
2025-01-16 21:47:39.538285: Epoch time: 40.73 s 
2025-01-16 21:47:40.116761:  
2025-01-16 21:47:40.117764: Epoch 139 
2025-01-16 21:47:40.122825: Current learning rate: 0.00482 
2025-01-16 21:48:20.829868: train_loss -0.8479 
2025-01-16 21:48:20.831371: val_loss -0.5604 
2025-01-16 21:48:20.837423: Pseudo dice [np.float32(0.7928), np.float32(0.5637)] 
2025-01-16 21:48:20.841433: Epoch time: 40.71 s 
2025-01-16 21:48:21.424037:  
2025-01-16 21:48:21.425040: Epoch 140 
2025-01-16 21:48:21.431082: Current learning rate: 0.00478 
2025-01-16 21:49:02.152155: train_loss -0.8559 
2025-01-16 21:49:02.152155: val_loss -0.5388 
2025-01-16 21:49:02.159233: Pseudo dice [np.float32(0.794), np.float32(0.3749)] 
2025-01-16 21:49:02.163819: Epoch time: 40.73 s 
2025-01-16 21:49:02.742985:  
2025-01-16 21:49:02.742985: Epoch 141 
2025-01-16 21:49:02.749044: Current learning rate: 0.00474 
2025-01-16 21:49:43.470841: train_loss -0.8539 
2025-01-16 21:49:43.471845: val_loss -0.5266 
2025-01-16 21:49:43.476892: Pseudo dice [np.float32(0.7877), np.float32(0.5269)] 
2025-01-16 21:49:43.481959: Epoch time: 40.73 s 
2025-01-16 21:49:44.215134:  
2025-01-16 21:49:44.215637: Epoch 142 
2025-01-16 21:49:44.221652: Current learning rate: 0.0047 
2025-01-16 21:50:24.933340: train_loss -0.8512 
2025-01-16 21:50:24.933848: val_loss -0.5023 
2025-01-16 21:50:24.939926: Pseudo dice [np.float32(0.7706), np.float32(0.5409)] 
2025-01-16 21:50:24.943474: Epoch time: 40.72 s 
2025-01-16 21:50:25.525097:  
2025-01-16 21:50:25.525097: Epoch 143 
2025-01-16 21:50:25.532116: Current learning rate: 0.00466 
2025-01-16 21:51:06.265030: train_loss -0.853 
2025-01-16 21:51:06.266033: val_loss -0.5225 
2025-01-16 21:51:06.272141: Pseudo dice [np.float32(0.7731), np.float32(0.5268)] 
2025-01-16 21:51:06.276688: Epoch time: 40.74 s 
2025-01-16 21:51:06.850592:  
2025-01-16 21:51:06.850592: Epoch 144 
2025-01-16 21:51:06.856137: Current learning rate: 0.00462 
2025-01-16 21:51:47.580315: train_loss -0.8582 
2025-01-16 21:51:47.580315: val_loss -0.511 
2025-01-16 21:51:47.587425: Pseudo dice [np.float32(0.771), np.float32(0.4857)] 
2025-01-16 21:51:47.591474: Epoch time: 40.73 s 
2025-01-16 21:51:48.164992:  
2025-01-16 21:51:48.164992: Epoch 145 
2025-01-16 21:51:48.171009: Current learning rate: 0.00458 
2025-01-16 21:52:28.895200: train_loss -0.8642 
2025-01-16 21:52:28.896203: val_loss -0.555 
2025-01-16 21:52:28.902220: Pseudo dice [np.float32(0.7935), np.float32(0.6297)] 
2025-01-16 21:52:28.906234: Epoch time: 40.73 s 
2025-01-16 21:52:29.482590:  
2025-01-16 21:52:29.482590: Epoch 146 
2025-01-16 21:52:29.489138: Current learning rate: 0.00454 
2025-01-16 21:53:10.201743: train_loss -0.8625 
2025-01-16 21:53:10.201743: val_loss -0.5359 
2025-01-16 21:53:10.209399: Pseudo dice [np.float32(0.7696), np.float32(0.5011)] 
2025-01-16 21:53:10.212432: Epoch time: 40.72 s 
2025-01-16 21:53:10.788484:  
2025-01-16 21:53:10.789488: Epoch 147 
2025-01-16 21:53:10.795045: Current learning rate: 0.0045 
2025-01-16 21:53:51.505410: train_loss -0.8766 
2025-01-16 21:53:51.505912: val_loss -0.5588 
2025-01-16 21:53:51.511565: Pseudo dice [np.float32(0.7838), np.float32(0.4474)] 
2025-01-16 21:53:51.516643: Epoch time: 40.72 s 
2025-01-16 21:53:52.090503:  
2025-01-16 21:53:52.090503: Epoch 148 
2025-01-16 21:53:52.097107: Current learning rate: 0.00446 
2025-01-16 21:54:32.807224: train_loss -0.8586 
2025-01-16 21:54:32.807726: val_loss -0.5398 
2025-01-16 21:54:32.813370: Pseudo dice [np.float32(0.7921), np.float32(0.5434)] 
2025-01-16 21:54:32.818403: Epoch time: 40.72 s 
2025-01-16 21:54:33.391021:  
2025-01-16 21:54:33.392021: Epoch 149 
2025-01-16 21:54:33.397629: Current learning rate: 0.00442 
2025-01-16 21:55:14.116884: train_loss -0.8691 
2025-01-16 21:55:14.116884: val_loss -0.5138 
2025-01-16 21:55:14.123419: Pseudo dice [np.float32(0.7997), np.float32(0.6016)] 
2025-01-16 21:55:14.127468: Epoch time: 40.73 s 
2025-01-16 21:55:14.308046: Yayy! New best EMA pseudo Dice: 0.6442999839782715 
2025-01-16 21:55:15.282377:  
2025-01-16 21:55:15.282377: Epoch 150 
2025-01-16 21:55:15.288394: Current learning rate: 0.00438 
2025-01-16 21:55:56.010335: train_loss -0.869 
2025-01-16 21:55:56.010842: val_loss -0.5113 
2025-01-16 21:55:56.014876: Pseudo dice [np.float32(0.7874), np.float32(0.5185)] 
2025-01-16 21:55:56.019975: Epoch time: 40.73 s 
2025-01-16 21:55:56.022492: Yayy! New best EMA pseudo Dice: 0.6452000141143799 
2025-01-16 21:55:56.820720:  
2025-01-16 21:55:56.820720: Epoch 151 
2025-01-16 21:55:56.826780: Current learning rate: 0.00434 
2025-01-16 21:56:37.544463: train_loss -0.868 
2025-01-16 21:56:37.544463: val_loss -0.5055 
2025-01-16 21:56:37.550511: Pseudo dice [np.float32(0.7661), np.float32(0.3791)] 
2025-01-16 21:56:37.554109: Epoch time: 40.72 s 
2025-01-16 21:56:38.132782:  
2025-01-16 21:56:38.133980: Epoch 152 
2025-01-16 21:56:38.143039: Current learning rate: 0.0043 
2025-01-16 21:57:18.855057: train_loss -0.8691 
2025-01-16 21:57:18.855057: val_loss -0.5206 
2025-01-16 21:57:18.862188: Pseudo dice [np.float32(0.7666), np.float32(0.544)] 
2025-01-16 21:57:18.865733: Epoch time: 40.72 s 
2025-01-16 21:57:19.445154:  
2025-01-16 21:57:19.446154: Epoch 153 
2025-01-16 21:57:19.451214: Current learning rate: 0.00427 
2025-01-16 21:58:00.164451: train_loss -0.8829 
2025-01-16 21:58:00.164451: val_loss -0.5373 
2025-01-16 21:58:00.171505: Pseudo dice [np.float32(0.7794), np.float32(0.4577)] 
2025-01-16 21:58:00.175541: Epoch time: 40.72 s 
2025-01-16 21:58:00.764998:  
2025-01-16 21:58:00.764998: Epoch 154 
2025-01-16 21:58:00.771033: Current learning rate: 0.00423 
2025-01-16 21:58:41.484194: train_loss -0.8704 
2025-01-16 21:58:41.484194: val_loss -0.5109 
2025-01-16 21:58:41.491851: Pseudo dice [np.float32(0.797), np.float32(0.3775)] 
2025-01-16 21:58:41.495893: Epoch time: 40.72 s 
2025-01-16 21:58:42.099140:  
2025-01-16 21:58:42.099140: Epoch 155 
2025-01-16 21:58:42.105695: Current learning rate: 0.00419 
2025-01-16 21:59:22.800445: train_loss -0.8716 
2025-01-16 21:59:22.800445: val_loss -0.5036 
2025-01-16 21:59:22.820719: Pseudo dice [np.float32(0.7685), np.float32(0.5799)] 
2025-01-16 21:59:22.843890: Epoch time: 40.7 s 
2025-01-16 21:59:23.434439:  
2025-01-16 21:59:23.435443: Epoch 156 
2025-01-16 21:59:23.441493: Current learning rate: 0.00415 
2025-01-16 22:00:04.138554: train_loss -0.866 
2025-01-16 22:00:04.138554: val_loss -0.5109 
2025-01-16 22:00:04.145585: Pseudo dice [np.float32(0.7819), np.float32(0.3792)] 
2025-01-16 22:00:04.150095: Epoch time: 40.7 s 
2025-01-16 22:00:04.737560:  
2025-01-16 22:00:04.738564: Epoch 157 
2025-01-16 22:00:04.763802: Current learning rate: 0.00411 
2025-01-16 22:00:45.479458: train_loss -0.8664 
2025-01-16 22:00:45.479458: val_loss -0.5847 
2025-01-16 22:00:45.485976: Pseudo dice [np.float32(0.7865), np.float32(0.4979)] 
2025-01-16 22:00:45.490486: Epoch time: 40.74 s 
2025-01-16 22:00:46.221319:  
2025-01-16 22:00:46.221319: Epoch 158 
2025-01-16 22:00:46.226834: Current learning rate: 0.00407 
2025-01-16 22:01:26.919739: train_loss -0.8797 
2025-01-16 22:01:26.920244: val_loss -0.5384 
2025-01-16 22:01:26.926782: Pseudo dice [np.float32(0.795), np.float32(0.4353)] 
2025-01-16 22:01:26.930909: Epoch time: 40.7 s 
2025-01-16 22:01:27.514032:  
2025-01-16 22:01:27.515037: Epoch 159 
2025-01-16 22:01:27.520065: Current learning rate: 0.00403 
2025-01-16 22:02:08.233028: train_loss -0.8827 
2025-01-16 22:02:08.234061: val_loss -0.5282 
2025-01-16 22:02:08.239115: Pseudo dice [np.float32(0.7869), np.float32(0.4047)] 
2025-01-16 22:02:08.243641: Epoch time: 40.72 s 
2025-01-16 22:02:08.839544:  
2025-01-16 22:02:08.840541: Epoch 160 
2025-01-16 22:02:08.846116: Current learning rate: 0.00399 
2025-01-16 22:02:49.577293: train_loss -0.8796 
2025-01-16 22:02:49.577795: val_loss -0.489 
2025-01-16 22:02:49.603871: Pseudo dice [np.float32(0.7719), np.float32(0.3921)] 
2025-01-16 22:02:49.623921: Epoch time: 40.74 s 
2025-01-16 22:02:50.230385:  
2025-01-16 22:02:50.231388: Epoch 161 
2025-01-16 22:02:50.237491: Current learning rate: 0.00395 
2025-01-16 22:03:30.938839: train_loss -0.8643 
2025-01-16 22:03:30.939345: val_loss -0.5446 
2025-01-16 22:03:30.945497: Pseudo dice [np.float32(0.7897), np.float32(0.5559)] 
2025-01-16 22:03:30.949561: Epoch time: 40.71 s 
2025-01-16 22:03:31.533925:  
2025-01-16 22:03:31.533925: Epoch 162 
2025-01-16 22:03:31.539496: Current learning rate: 0.00391 
2025-01-16 22:04:12.258611: train_loss -0.8809 
2025-01-16 22:04:12.259615: val_loss -0.5074 
2025-01-16 22:04:12.266129: Pseudo dice [np.float32(0.7768), np.float32(0.425)] 
2025-01-16 22:04:12.269639: Epoch time: 40.73 s 
2025-01-16 22:04:12.852434:  
2025-01-16 22:04:12.852937: Epoch 163 
2025-01-16 22:04:12.858562: Current learning rate: 0.00387 
2025-01-16 22:04:53.564411: train_loss -0.8739 
2025-01-16 22:04:53.564914: val_loss -0.5164 
2025-01-16 22:04:53.570457: Pseudo dice [np.float32(0.7818), np.float32(0.5908)] 
2025-01-16 22:04:53.575511: Epoch time: 40.71 s 
2025-01-16 22:04:54.165943:  
2025-01-16 22:04:54.166454: Epoch 164 
2025-01-16 22:04:54.171000: Current learning rate: 0.00383 
2025-01-16 22:05:34.889047: train_loss -0.8755 
2025-01-16 22:05:34.889551: val_loss -0.529 
2025-01-16 22:05:34.895609: Pseudo dice [np.float32(0.7763), np.float32(0.4161)] 
2025-01-16 22:05:34.899624: Epoch time: 40.72 s 
2025-01-16 22:05:35.467558:  
2025-01-16 22:05:35.467558: Epoch 165 
2025-01-16 22:05:35.474115: Current learning rate: 0.00379 
2025-01-16 22:06:16.189529: train_loss -0.876 
2025-01-16 22:06:16.189529: val_loss -0.5217 
2025-01-16 22:06:16.194606: Pseudo dice [np.float32(0.7885), np.float32(0.382)] 
2025-01-16 22:06:16.200169: Epoch time: 40.72 s 
2025-01-16 22:06:16.920113:  
2025-01-16 22:06:16.921120: Epoch 166 
2025-01-16 22:06:16.926199: Current learning rate: 0.00375 
2025-01-16 22:06:57.635208: train_loss -0.89 
2025-01-16 22:06:57.636213: val_loss -0.5039 
2025-01-16 22:06:57.642226: Pseudo dice [np.float32(0.7784), np.float32(0.4158)] 
2025-01-16 22:06:57.657764: Epoch time: 40.72 s 
2025-01-16 22:06:58.225426:  
2025-01-16 22:06:58.225426: Epoch 167 
2025-01-16 22:06:58.247125: Current learning rate: 0.00371 
2025-01-16 22:07:38.979607: train_loss -0.8854 
2025-01-16 22:07:38.981119: val_loss -0.5477 
2025-01-16 22:07:38.987194: Pseudo dice [np.float32(0.7845), np.float32(0.4608)] 
2025-01-16 22:07:38.990738: Epoch time: 40.76 s 
2025-01-16 22:07:39.570109:  
2025-01-16 22:07:39.571109: Epoch 168 
2025-01-16 22:07:39.578627: Current learning rate: 0.00367 
2025-01-16 22:08:20.277596: train_loss -0.8802 
2025-01-16 22:08:20.278600: val_loss -0.5748 
2025-01-16 22:08:20.284661: Pseudo dice [np.float32(0.7927), np.float32(0.5365)] 
2025-01-16 22:08:20.287686: Epoch time: 40.71 s 
2025-01-16 22:08:20.867968:  
2025-01-16 22:08:20.867968: Epoch 169 
2025-01-16 22:08:20.875537: Current learning rate: 0.00363 
2025-01-16 22:09:01.586189: train_loss -0.8881 
2025-01-16 22:09:01.586693: val_loss -0.5721 
2025-01-16 22:09:01.591769: Pseudo dice [np.float32(0.7977), np.float32(0.5622)] 
2025-01-16 22:09:01.596278: Epoch time: 40.72 s 
2025-01-16 22:09:02.167878:  
2025-01-16 22:09:02.167878: Epoch 170 
2025-01-16 22:09:02.173413: Current learning rate: 0.00359 
2025-01-16 22:09:42.917102: train_loss -0.8787 
2025-01-16 22:09:42.918124: val_loss -0.5718 
2025-01-16 22:09:42.924782: Pseudo dice [np.float32(0.8004), np.float32(0.5574)] 
2025-01-16 22:09:42.928827: Epoch time: 40.75 s 
2025-01-16 22:09:43.508571:  
2025-01-16 22:09:43.508571: Epoch 171 
2025-01-16 22:09:43.515145: Current learning rate: 0.00355 
2025-01-16 22:10:24.217415: train_loss -0.889 
2025-01-16 22:10:24.217936: val_loss -0.5107 
2025-01-16 22:10:24.222446: Pseudo dice [np.float32(0.7884), np.float32(0.51)] 
2025-01-16 22:10:24.225455: Epoch time: 40.71 s 
2025-01-16 22:10:24.852632:  
2025-01-16 22:10:24.852632: Epoch 172 
2025-01-16 22:10:24.858196: Current learning rate: 0.00351 
2025-01-16 22:11:05.597843: train_loss -0.8897 
2025-01-16 22:11:05.598846: val_loss -0.5386 
2025-01-16 22:11:05.603394: Pseudo dice [np.float32(0.7841), np.float32(0.4488)] 
2025-01-16 22:11:05.607920: Epoch time: 40.75 s 
2025-01-16 22:11:06.188675:  
2025-01-16 22:11:06.189178: Epoch 173 
2025-01-16 22:11:06.195196: Current learning rate: 0.00346 
2025-01-16 22:11:46.975775: train_loss -0.8974 
2025-01-16 22:11:46.975775: val_loss -0.5324 
2025-01-16 22:11:46.982797: Pseudo dice [np.float32(0.7674), np.float32(0.4978)] 
2025-01-16 22:11:46.985808: Epoch time: 40.79 s 
2025-01-16 22:11:47.717955:  
2025-01-16 22:11:47.717955: Epoch 174 
2025-01-16 22:11:47.723970: Current learning rate: 0.00342 
2025-01-16 22:12:28.481544: train_loss -0.8838 
2025-01-16 22:12:28.481544: val_loss -0.5588 
2025-01-16 22:12:28.489078: Pseudo dice [np.float32(0.796), np.float32(0.4429)] 
2025-01-16 22:12:28.492588: Epoch time: 40.76 s 
2025-01-16 22:12:29.076353:  
2025-01-16 22:12:29.076353: Epoch 175 
2025-01-16 22:12:29.082396: Current learning rate: 0.00338 
2025-01-16 22:13:09.846268: train_loss -0.8967 
2025-01-16 22:13:09.846268: val_loss -0.5588 
2025-01-16 22:13:09.852808: Pseudo dice [np.float32(0.7846), np.float32(0.5735)] 
2025-01-16 22:13:09.857361: Epoch time: 40.77 s 
2025-01-16 22:13:10.461559:  
2025-01-16 22:13:10.461559: Epoch 176 
2025-01-16 22:13:10.467113: Current learning rate: 0.00334 
2025-01-16 22:13:51.216482: train_loss -0.892 
2025-01-16 22:13:51.217486: val_loss -0.4837 
2025-01-16 22:13:51.222005: Pseudo dice [np.float32(0.7687), np.float32(0.5363)] 
2025-01-16 22:13:51.226644: Epoch time: 40.76 s 
2025-01-16 22:13:51.811868:  
2025-01-16 22:13:51.812373: Epoch 177 
2025-01-16 22:13:51.816387: Current learning rate: 0.0033 
2025-01-16 22:14:32.550382: train_loss -0.8849 
2025-01-16 22:14:32.550382: val_loss -0.535 
2025-01-16 22:14:32.556397: Pseudo dice [np.float32(0.784), np.float32(0.4879)] 
2025-01-16 22:14:32.560410: Epoch time: 40.74 s 
2025-01-16 22:14:33.224580:  
2025-01-16 22:14:33.225083: Epoch 178 
2025-01-16 22:14:33.230100: Current learning rate: 0.00326 
2025-01-16 22:15:13.970919: train_loss -0.8903 
2025-01-16 22:15:13.970919: val_loss -0.5129 
2025-01-16 22:15:13.975458: Pseudo dice [np.float32(0.7883), np.float32(0.5642)] 
2025-01-16 22:15:13.979470: Epoch time: 40.75 s 
2025-01-16 22:15:14.557634:  
2025-01-16 22:15:14.557634: Epoch 179 
2025-01-16 22:15:14.578421: Current learning rate: 0.00322 
2025-01-16 22:15:58.878741: train_loss -0.8987 
2025-01-16 22:15:58.878741: val_loss -0.5626 
2025-01-16 22:15:58.885282: Pseudo dice [np.float32(0.7888), np.float32(0.5854)] 
2025-01-16 22:15:58.888812: Epoch time: 44.32 s 
2025-01-16 22:15:58.892838: Yayy! New best EMA pseudo Dice: 0.6470999717712402 
2025-01-16 22:15:59.702534:  
2025-01-16 22:15:59.703534: Epoch 180 
2025-01-16 22:15:59.709053: Current learning rate: 0.00318 
2025-01-16 22:16:40.461145: train_loss -0.879 
2025-01-16 22:16:40.462145: val_loss -0.5165 
2025-01-16 22:16:40.468693: Pseudo dice [np.float32(0.7876), np.float32(0.4123)] 
2025-01-16 22:16:40.472704: Epoch time: 40.76 s 
2025-01-16 22:16:41.200270:  
2025-01-16 22:16:41.200270: Epoch 181 
2025-01-16 22:16:41.206896: Current learning rate: 0.00314 
2025-01-16 22:17:21.919890: train_loss -0.8918 
2025-01-16 22:17:21.919890: val_loss -0.5343 
2025-01-16 22:17:21.926504: Pseudo dice [np.float32(0.7962), np.float32(0.6717)] 
2025-01-16 22:17:21.931065: Epoch time: 40.72 s 
2025-01-16 22:17:21.934110: Yayy! New best EMA pseudo Dice: 0.6514999866485596 
2025-01-16 22:17:22.742419:  
2025-01-16 22:17:22.742419: Epoch 182 
2025-01-16 22:17:22.749520: Current learning rate: 0.0031 
2025-01-16 22:18:03.479350: train_loss -0.8924 
2025-01-16 22:18:03.480350: val_loss -0.5407 
2025-01-16 22:18:03.485869: Pseudo dice [np.float32(0.7892), np.float32(0.5596)] 
2025-01-16 22:18:03.503407: Epoch time: 40.74 s 
2025-01-16 22:18:03.521971: Yayy! New best EMA pseudo Dice: 0.6538000106811523 
2025-01-16 22:18:04.332514:  
2025-01-16 22:18:04.332514: Epoch 183 
2025-01-16 22:18:04.338062: Current learning rate: 0.00306 
2025-01-16 22:18:45.069890: train_loss -0.8984 
2025-01-16 22:18:45.070392: val_loss -0.5659 
2025-01-16 22:18:45.093640: Pseudo dice [np.float32(0.8107), np.float32(0.4782)] 
2025-01-16 22:18:45.096149: Epoch time: 40.74 s 
2025-01-16 22:18:45.674016:  
2025-01-16 22:18:45.674016: Epoch 184 
2025-01-16 22:18:45.680663: Current learning rate: 0.00302 
2025-01-16 22:19:26.419583: train_loss -0.9028 
2025-01-16 22:19:26.420582: val_loss -0.516 
2025-01-16 22:19:26.426646: Pseudo dice [np.float32(0.8039), np.float32(0.5279)] 
2025-01-16 22:19:26.429674: Epoch time: 40.75 s 
2025-01-16 22:19:26.433708: Yayy! New best EMA pseudo Dice: 0.65420001745224 
2025-01-16 22:19:27.240562:  
2025-01-16 22:19:27.241065: Epoch 185 
2025-01-16 22:19:27.246076: Current learning rate: 0.00297 
2025-01-16 22:20:07.962073: train_loss -0.9069 
2025-01-16 22:20:07.962073: val_loss -0.5248 
2025-01-16 22:20:07.969643: Pseudo dice [np.float32(0.7863), np.float32(0.6314)] 
2025-01-16 22:20:07.974193: Epoch time: 40.72 s 
2025-01-16 22:20:07.977231: Yayy! New best EMA pseudo Dice: 0.659600019454956 
2025-01-16 22:20:08.769084:  
2025-01-16 22:20:08.770088: Epoch 186 
2025-01-16 22:20:08.776181: Current learning rate: 0.00293 
2025-01-16 22:20:49.514945: train_loss -0.8931 
2025-01-16 22:20:49.515450: val_loss -0.496 
2025-01-16 22:20:49.521544: Pseudo dice [np.float32(0.7739), np.float32(0.3975)] 
2025-01-16 22:20:49.525589: Epoch time: 40.75 s 
2025-01-16 22:20:50.110805:  
2025-01-16 22:20:50.110805: Epoch 187 
2025-01-16 22:20:50.114866: Current learning rate: 0.00289 
2025-01-16 22:21:30.849927: train_loss -0.8951 
2025-01-16 22:21:30.850930: val_loss -0.547 
2025-01-16 22:21:30.857442: Pseudo dice [np.float32(0.7926), np.float32(0.5718)] 
2025-01-16 22:21:30.860957: Epoch time: 40.74 s 
2025-01-16 22:21:31.439648:  
2025-01-16 22:21:31.440153: Epoch 188 
2025-01-16 22:21:31.446841: Current learning rate: 0.00285 
2025-01-16 22:22:12.181989: train_loss -0.8891 
2025-01-16 22:22:12.182993: val_loss -0.5646 
2025-01-16 22:22:12.189007: Pseudo dice [np.float32(0.7938), np.float32(0.4928)] 
2025-01-16 22:22:12.192016: Epoch time: 40.74 s 
2025-01-16 22:22:12.926033:  
2025-01-16 22:22:12.926033: Epoch 189 
2025-01-16 22:22:12.932047: Current learning rate: 0.00281 
2025-01-16 22:22:53.649051: train_loss -0.8961 
2025-01-16 22:22:53.649051: val_loss -0.5337 
2025-01-16 22:22:53.655200: Pseudo dice [np.float32(0.7792), np.float32(0.6301)] 
2025-01-16 22:22:53.660257: Epoch time: 40.72 s 
2025-01-16 22:22:54.246325:  
2025-01-16 22:22:54.247324: Epoch 190 
2025-01-16 22:22:54.252946: Current learning rate: 0.00277 
2025-01-16 22:23:34.963573: train_loss -0.8999 
2025-01-16 22:23:34.964578: val_loss -0.5371 
2025-01-16 22:23:35.003726: Pseudo dice [np.float32(0.7768), np.float32(0.5737)] 
2025-01-16 22:23:35.007741: Epoch time: 40.72 s 
2025-01-16 22:23:35.011256: Yayy! New best EMA pseudo Dice: 0.6607000231742859 
2025-01-16 22:23:35.806823:  
2025-01-16 22:23:35.807827: Epoch 191 
2025-01-16 22:23:35.812397: Current learning rate: 0.00273 
2025-01-16 22:24:16.545526: train_loss -0.9102 
2025-01-16 22:24:16.546034: val_loss -0.5592 
2025-01-16 22:24:16.552612: Pseudo dice [np.float32(0.7804), np.float32(0.5451)] 
2025-01-16 22:24:16.556664: Epoch time: 40.74 s 
2025-01-16 22:24:16.559191: Yayy! New best EMA pseudo Dice: 0.6608999967575073 
2025-01-16 22:24:17.377600:  
2025-01-16 22:24:17.377600: Epoch 192 
2025-01-16 22:24:17.384226: Current learning rate: 0.00268 
2025-01-16 22:24:58.161242: train_loss -0.9055 
2025-01-16 22:24:58.166788: val_loss -0.5328 
2025-01-16 22:24:58.170815: Pseudo dice [np.float32(0.8), np.float32(0.4867)] 
2025-01-16 22:24:58.192083: Epoch time: 40.78 s 
2025-01-16 22:24:58.782118:  
2025-01-16 22:24:58.782118: Epoch 193 
2025-01-16 22:24:58.788667: Current learning rate: 0.00264 
2025-01-16 22:25:39.537011: train_loss -0.9082 
2025-01-16 22:25:39.537011: val_loss -0.5493 
2025-01-16 22:25:39.542022: Pseudo dice [np.float32(0.7937), np.float32(0.5686)] 
2025-01-16 22:25:39.545533: Epoch time: 40.75 s 
2025-01-16 22:25:39.549037: Yayy! New best EMA pseudo Dice: 0.6614000201225281 
2025-01-16 22:25:40.331052:  
2025-01-16 22:25:40.331554: Epoch 194 
2025-01-16 22:25:40.336575: Current learning rate: 0.0026 
2025-01-16 22:26:21.069065: train_loss -0.9026 
2025-01-16 22:26:21.070065: val_loss -0.5273 
2025-01-16 22:26:21.075581: Pseudo dice [np.float32(0.7811), np.float32(0.4044)] 
2025-01-16 22:26:21.079090: Epoch time: 40.74 s 
2025-01-16 22:26:21.671253:  
2025-01-16 22:26:21.671253: Epoch 195 
2025-01-16 22:26:21.677291: Current learning rate: 0.00256 
2025-01-16 22:27:02.414433: train_loss -0.9024 
2025-01-16 22:27:02.414433: val_loss -0.5509 
2025-01-16 22:27:02.421546: Pseudo dice [np.float32(0.7982), np.float32(0.5102)] 
2025-01-16 22:27:02.424585: Epoch time: 40.74 s 
2025-01-16 22:27:03.015932:  
2025-01-16 22:27:03.016935: Epoch 196 
2025-01-16 22:27:03.038841: Current learning rate: 0.00252 
2025-01-16 22:27:43.777648: train_loss -0.9094 
2025-01-16 22:27:43.777648: val_loss -0.5274 
2025-01-16 22:27:43.784745: Pseudo dice [np.float32(0.798), np.float32(0.3989)] 
2025-01-16 22:27:43.788314: Epoch time: 40.76 s 
2025-01-16 22:27:44.529288:  
2025-01-16 22:27:44.530292: Epoch 197 
2025-01-16 22:27:44.534861: Current learning rate: 0.00248 
2025-01-16 22:28:25.249953: train_loss -0.9078 
2025-01-16 22:28:25.249953: val_loss -0.5399 
2025-01-16 22:28:25.271044: Pseudo dice [np.float32(0.8024), np.float32(0.3787)] 
2025-01-16 22:28:25.274550: Epoch time: 40.72 s 
2025-01-16 22:28:25.863302:  
2025-01-16 22:28:25.863302: Epoch 198 
2025-01-16 22:28:25.871417: Current learning rate: 0.00243 
2025-01-16 22:29:06.629387: train_loss -0.9083 
2025-01-16 22:29:06.629387: val_loss -0.5095 
2025-01-16 22:29:06.634928: Pseudo dice [np.float32(0.7798), np.float32(0.378)] 
2025-01-16 22:29:06.638437: Epoch time: 40.77 s 
2025-01-16 22:29:07.224767:  
2025-01-16 22:29:07.224767: Epoch 199 
2025-01-16 22:29:07.230784: Current learning rate: 0.00239 
2025-01-16 22:29:47.973935: train_loss -0.901 
2025-01-16 22:29:47.974437: val_loss -0.5231 
2025-01-16 22:29:47.980521: Pseudo dice [np.float32(0.7929), np.float32(0.4079)] 
2025-01-16 22:29:47.984070: Epoch time: 40.75 s 
2025-01-16 22:29:48.800306:  
2025-01-16 22:29:48.800306: Epoch 200 
2025-01-16 22:29:48.806855: Current learning rate: 0.00235 
2025-01-16 22:30:29.535529: train_loss -0.8938 
2025-01-16 22:30:29.535529: val_loss -0.5419 
2025-01-16 22:30:29.542103: Pseudo dice [np.float32(0.7955), np.float32(0.5487)] 
2025-01-16 22:30:29.551126: Epoch time: 40.74 s 
2025-01-16 22:30:30.137299:  
2025-01-16 22:30:30.137299: Epoch 201 
2025-01-16 22:30:30.143864: Current learning rate: 0.00231 
2025-01-16 22:31:10.870615: train_loss -0.8992 
2025-01-16 22:31:10.871122: val_loss -0.5285 
2025-01-16 22:31:10.876180: Pseudo dice [np.float32(0.7936), np.float32(0.4826)] 
2025-01-16 22:31:10.882762: Epoch time: 40.73 s 
2025-01-16 22:31:11.479708:  
2025-01-16 22:31:11.479708: Epoch 202 
2025-01-16 22:31:11.485835: Current learning rate: 0.00226 
2025-01-16 22:31:52.223923: train_loss -0.9051 
2025-01-16 22:31:52.223923: val_loss -0.5466 
2025-01-16 22:31:52.231004: Pseudo dice [np.float32(0.7956), np.float32(0.562)] 
2025-01-16 22:31:52.235557: Epoch time: 40.75 s 
2025-01-16 22:31:52.824627:  
2025-01-16 22:31:52.825628: Epoch 203 
2025-01-16 22:31:52.832216: Current learning rate: 0.00222 
2025-01-16 22:32:33.566415: train_loss -0.8999 
2025-01-16 22:32:33.566926: val_loss -0.5153 
2025-01-16 22:32:33.573560: Pseudo dice [np.float32(0.7927), np.float32(0.3918)] 
2025-01-16 22:32:33.577614: Epoch time: 40.74 s 
2025-01-16 22:32:34.187355:  
2025-01-16 22:32:34.187858: Epoch 204 
2025-01-16 22:32:34.192896: Current learning rate: 0.00218 
2025-01-16 22:33:14.924395: train_loss -0.901 
2025-01-16 22:33:14.924395: val_loss -0.5218 
2025-01-16 22:33:14.964566: Pseudo dice [np.float32(0.7859), np.float32(0.5015)] 
2025-01-16 22:33:14.984108: Epoch time: 40.74 s 
2025-01-16 22:33:15.738822:  
2025-01-16 22:33:15.738822: Epoch 205 
2025-01-16 22:33:15.744837: Current learning rate: 0.00214 
2025-01-16 22:33:56.498623: train_loss -0.9015 
2025-01-16 22:33:56.498623: val_loss -0.5147 
2025-01-16 22:33:56.506787: Pseudo dice [np.float32(0.8041), np.float32(0.4028)] 
2025-01-16 22:33:56.511342: Epoch time: 40.76 s 
2025-01-16 22:33:57.067937:  
2025-01-16 22:33:57.068937: Epoch 206 
2025-01-16 22:33:57.074596: Current learning rate: 0.00209 
2025-01-16 22:34:37.810921: train_loss -0.9078 
2025-01-16 22:34:37.810921: val_loss -0.5393 
2025-01-16 22:34:37.817959: Pseudo dice [np.float32(0.7836), np.float32(0.3522)] 
2025-01-16 22:34:37.821468: Epoch time: 40.74 s 
2025-01-16 22:34:38.383390:  
2025-01-16 22:34:38.383390: Epoch 207 
2025-01-16 22:34:38.389405: Current learning rate: 0.00205 
2025-01-16 22:35:19.132798: train_loss -0.9036 
2025-01-16 22:35:19.133303: val_loss -0.5318 
2025-01-16 22:35:19.138872: Pseudo dice [np.float32(0.7876), np.float32(0.4593)] 
2025-01-16 22:35:19.141935: Epoch time: 40.75 s 
2025-01-16 22:35:19.701261:  
2025-01-16 22:35:19.702265: Epoch 208 
2025-01-16 22:35:19.706821: Current learning rate: 0.00201 
2025-01-16 22:36:00.457756: train_loss -0.9017 
2025-01-16 22:36:00.457756: val_loss -0.5194 
2025-01-16 22:36:00.463801: Pseudo dice [np.float32(0.7879), np.float32(0.4592)] 
2025-01-16 22:36:00.467870: Epoch time: 40.76 s 
2025-01-16 22:36:01.023637:  
2025-01-16 22:36:01.023637: Epoch 209 
2025-01-16 22:36:01.028648: Current learning rate: 0.00196 
2025-01-16 22:36:41.770674: train_loss -0.9029 
2025-01-16 22:36:41.771177: val_loss -0.4906 
2025-01-16 22:36:41.778285: Pseudo dice [np.float32(0.802), np.float32(0.3258)] 
2025-01-16 22:36:41.782328: Epoch time: 40.75 s 
2025-01-16 22:36:42.341356:  
2025-01-16 22:36:42.341356: Epoch 210 
2025-01-16 22:36:42.347371: Current learning rate: 0.00192 
2025-01-16 22:37:23.103331: train_loss -0.9105 
2025-01-16 22:37:23.103331: val_loss -0.5368 
2025-01-16 22:37:23.109882: Pseudo dice [np.float32(0.7923), np.float32(0.5177)] 
2025-01-16 22:37:23.113391: Epoch time: 40.76 s 
2025-01-16 22:37:23.671335:  
2025-01-16 22:37:23.672340: Epoch 211 
2025-01-16 22:37:23.676901: Current learning rate: 0.00188 
2025-01-16 22:38:04.424369: train_loss -0.9039 
2025-01-16 22:38:04.424369: val_loss -0.4649 
2025-01-16 22:38:04.431537: Pseudo dice [np.float32(0.7788), np.float32(0.4746)] 
2025-01-16 22:38:04.435582: Epoch time: 40.75 s 
2025-01-16 22:38:04.992492:  
2025-01-16 22:38:04.992492: Epoch 212 
2025-01-16 22:38:04.997504: Current learning rate: 0.00184 
2025-01-16 22:38:45.757503: train_loss -0.8982 
2025-01-16 22:38:45.757503: val_loss -0.5316 
2025-01-16 22:38:45.764542: Pseudo dice [np.float32(0.7896), np.float32(0.4897)] 
2025-01-16 22:38:45.768050: Epoch time: 40.77 s 
2025-01-16 22:38:46.475893:  
2025-01-16 22:38:46.476898: Epoch 213 
2025-01-16 22:38:46.481453: Current learning rate: 0.00179 
2025-01-16 22:39:27.226896: train_loss -0.9055 
2025-01-16 22:39:27.226896: val_loss -0.5581 
2025-01-16 22:39:27.233913: Pseudo dice [np.float32(0.8005), np.float32(0.4514)] 
2025-01-16 22:39:27.237926: Epoch time: 40.75 s 
2025-01-16 22:39:27.793455:  
2025-01-16 22:39:27.794459: Epoch 214 
2025-01-16 22:39:27.817182: Current learning rate: 0.00175 
2025-01-16 22:40:08.566821: train_loss -0.8996 
2025-01-16 22:40:08.566821: val_loss -0.5209 
2025-01-16 22:40:08.573382: Pseudo dice [np.float32(0.7776), np.float32(0.6315)] 
2025-01-16 22:40:08.576938: Epoch time: 40.77 s 
2025-01-16 22:40:09.133495:  
2025-01-16 22:40:09.134499: Epoch 215 
2025-01-16 22:40:09.139084: Current learning rate: 0.0017 
2025-01-16 22:40:49.858347: train_loss -0.9002 
2025-01-16 22:40:49.858347: val_loss -0.5048 
2025-01-16 22:40:49.864361: Pseudo dice [np.float32(0.7807), np.float32(0.4899)] 
2025-01-16 22:40:49.868370: Epoch time: 40.72 s 
2025-01-16 22:40:50.424294:  
2025-01-16 22:40:50.424294: Epoch 216 
2025-01-16 22:40:50.430838: Current learning rate: 0.00166 
2025-01-16 22:41:31.183333: train_loss -0.9082 
2025-01-16 22:41:31.183333: val_loss -0.4905 
2025-01-16 22:41:31.190365: Pseudo dice [np.float32(0.7762), np.float32(0.5378)] 
2025-01-16 22:41:31.212916: Epoch time: 40.76 s 
2025-01-16 22:41:31.764035:  
2025-01-16 22:41:31.765038: Epoch 217 
2025-01-16 22:41:31.770105: Current learning rate: 0.00162 
2025-01-16 22:42:12.519977: train_loss -0.9056 
2025-01-16 22:42:12.520480: val_loss -0.535 
2025-01-16 22:42:12.527072: Pseudo dice [np.float32(0.7943), np.float32(0.5613)] 
2025-01-16 22:42:12.531086: Epoch time: 40.76 s 
2025-01-16 22:42:13.088852:  
2025-01-16 22:42:13.088852: Epoch 218 
2025-01-16 22:42:13.093865: Current learning rate: 0.00157 
2025-01-16 22:42:53.850353: train_loss -0.8969 
2025-01-16 22:42:53.851355: val_loss -0.5245 
2025-01-16 22:42:53.857349: Pseudo dice [np.float32(0.7953), np.float32(0.3831)] 
2025-01-16 22:42:53.866869: Epoch time: 40.76 s 
2025-01-16 22:42:54.416178:  
2025-01-16 22:42:54.417179: Epoch 219 
2025-01-16 22:42:54.422781: Current learning rate: 0.00153 
2025-01-16 22:43:35.170815: train_loss -0.9068 
2025-01-16 22:43:35.171318: val_loss -0.4834 
2025-01-16 22:43:35.176331: Pseudo dice [np.float32(0.7719), np.float32(0.5028)] 
2025-01-16 22:43:35.181344: Epoch time: 40.75 s 
2025-01-16 22:43:35.732917:  
2025-01-16 22:43:35.733420: Epoch 220 
2025-01-16 22:43:35.739434: Current learning rate: 0.00148 
2025-01-16 22:44:16.500076: train_loss -0.9128 
2025-01-16 22:44:16.501583: val_loss -0.4984 
2025-01-16 22:44:16.506594: Pseudo dice [np.float32(0.7941), np.float32(0.4546)] 
2025-01-16 22:44:16.510103: Epoch time: 40.77 s 
2025-01-16 22:44:17.064128:  
2025-01-16 22:44:17.064128: Epoch 221 
2025-01-16 22:44:17.070718: Current learning rate: 0.00144 
2025-01-16 22:44:57.822196: train_loss -0.9128 
2025-01-16 22:44:57.823196: val_loss -0.4868 
2025-01-16 22:44:57.828710: Pseudo dice [np.float32(0.7976), np.float32(0.4314)] 
2025-01-16 22:44:57.832219: Epoch time: 40.76 s 
2025-01-16 22:44:58.537672:  
2025-01-16 22:44:58.537672: Epoch 222 
2025-01-16 22:44:58.544212: Current learning rate: 0.00139 
2025-01-16 22:45:39.286700: train_loss -0.9132 
2025-01-16 22:45:39.287203: val_loss -0.5035 
2025-01-16 22:45:39.294724: Pseudo dice [np.float32(0.7856), np.float32(0.5162)] 
2025-01-16 22:45:39.298233: Epoch time: 40.75 s 
2025-01-16 22:45:39.845782:  
2025-01-16 22:45:39.846785: Epoch 223 
2025-01-16 22:45:39.851387: Current learning rate: 0.00135 
2025-01-16 22:46:20.593685: train_loss -0.9071 
2025-01-16 22:46:20.594187: val_loss -0.5447 
2025-01-16 22:46:20.600204: Pseudo dice [np.float32(0.7791), np.float32(0.5388)] 
2025-01-16 22:46:20.604210: Epoch time: 40.75 s 
2025-01-16 22:46:21.155893:  
2025-01-16 22:46:21.156407: Epoch 224 
2025-01-16 22:46:21.179507: Current learning rate: 0.0013 
2025-01-16 22:47:01.922191: train_loss -0.9063 
2025-01-16 22:47:01.923194: val_loss -0.5393 
2025-01-16 22:47:01.929777: Pseudo dice [np.float32(0.7894), np.float32(0.489)] 
2025-01-16 22:47:01.931797: Epoch time: 40.77 s 
2025-01-16 22:47:02.492670:  
2025-01-16 22:47:02.493672: Epoch 225 
2025-01-16 22:47:02.498263: Current learning rate: 0.00126 
2025-01-16 22:47:43.245487: train_loss -0.9155 
2025-01-16 22:47:43.245487: val_loss -0.5472 
2025-01-16 22:47:43.252551: Pseudo dice [np.float32(0.7886), np.float32(0.453)] 
2025-01-16 22:47:43.256573: Epoch time: 40.75 s 
2025-01-16 22:47:43.809950:  
2025-01-16 22:47:43.809950: Epoch 226 
2025-01-16 22:47:43.821006: Current learning rate: 0.00121 
2025-01-16 22:48:24.563755: train_loss -0.9073 
2025-01-16 22:48:24.564259: val_loss -0.56 
2025-01-16 22:48:24.569350: Pseudo dice [np.float32(0.8078), np.float32(0.4797)] 
2025-01-16 22:48:24.572925: Epoch time: 40.75 s 
2025-01-16 22:48:25.133522:  
2025-01-16 22:48:25.133522: Epoch 227 
2025-01-16 22:48:25.140077: Current learning rate: 0.00117 
2025-01-16 22:49:05.932930: train_loss -0.9079 
2025-01-16 22:49:05.933954: val_loss -0.5257 
2025-01-16 22:49:05.939027: Pseudo dice [np.float32(0.7953), np.float32(0.5144)] 
2025-01-16 22:49:05.943536: Epoch time: 40.8 s 
2025-01-16 22:49:06.493563:  
2025-01-16 22:49:06.494066: Epoch 228 
2025-01-16 22:49:06.500136: Current learning rate: 0.00112 
2025-01-16 22:49:47.235053: train_loss -0.909 
2025-01-16 22:49:47.235555: val_loss -0.5523 
2025-01-16 22:49:47.240871: Pseudo dice [np.float32(0.7937), np.float32(0.5435)] 
2025-01-16 22:49:47.244890: Epoch time: 40.74 s 
2025-01-16 22:49:47.794966:  
2025-01-16 22:49:47.794966: Epoch 229 
2025-01-16 22:49:47.799976: Current learning rate: 0.00108 
2025-01-16 22:50:28.533937: train_loss -0.9158 
2025-01-16 22:50:28.533937: val_loss -0.5301 
2025-01-16 22:50:28.556679: Pseudo dice [np.float32(0.7916), np.float32(0.4875)] 
2025-01-16 22:50:28.561191: Epoch time: 40.74 s 
2025-01-16 22:50:29.108255:  
2025-01-16 22:50:29.109256: Epoch 230 
2025-01-16 22:50:29.114906: Current learning rate: 0.00103 
2025-01-16 22:51:15.696754: train_loss -0.9099 
2025-01-16 22:51:15.697257: val_loss -0.5304 
2025-01-16 22:51:15.703275: Pseudo dice [np.float32(0.7793), np.float32(0.5874)] 
2025-01-16 22:51:15.707285: Epoch time: 46.59 s 
2025-01-16 22:51:16.452376:  
2025-01-16 22:51:16.452376: Epoch 231 
2025-01-16 22:51:16.458994: Current learning rate: 0.00098 
2025-01-16 22:51:58.357953: train_loss -0.9188 
2025-01-16 22:51:58.357953: val_loss -0.4701 
2025-01-16 22:51:58.364476: Pseudo dice [np.float32(0.7773), np.float32(0.3181)] 
2025-01-16 22:51:58.367984: Epoch time: 41.91 s 
2025-01-16 22:51:58.898288:  
2025-01-16 22:51:58.899290: Epoch 232 
2025-01-16 22:51:58.904488: Current learning rate: 0.00094 
2025-01-16 22:52:39.824057: train_loss -0.9115 
2025-01-16 22:52:39.825057: val_loss -0.5043 
2025-01-16 22:52:39.834080: Pseudo dice [np.float32(0.7976), np.float32(0.3383)] 
2025-01-16 22:52:39.840593: Epoch time: 40.93 s 
2025-01-16 22:52:40.367295:  
2025-01-16 22:52:40.367798: Epoch 233 
2025-01-16 22:52:40.372809: Current learning rate: 0.00089 
2025-01-16 22:53:21.302517: train_loss -0.9121 
2025-01-16 22:53:21.303522: val_loss -0.5124 
2025-01-16 22:53:21.309075: Pseudo dice [np.float32(0.7841), np.float32(0.3232)] 
2025-01-16 22:53:21.311580: Epoch time: 40.94 s 
2025-01-16 22:53:21.834172:  
2025-01-16 22:53:21.835175: Epoch 234 
2025-01-16 22:53:21.841248: Current learning rate: 0.00084 
2025-01-16 22:54:02.763057: train_loss -0.9175 
2025-01-16 22:54:02.764056: val_loss -0.567 
2025-01-16 22:54:02.770571: Pseudo dice [np.float32(0.7947), np.float32(0.5768)] 
2025-01-16 22:54:02.773079: Epoch time: 40.93 s 
2025-01-16 22:54:03.303548:  
2025-01-16 22:54:03.304549: Epoch 235 
2025-01-16 22:54:03.310130: Current learning rate: 0.00079 
2025-01-16 22:54:44.240921: train_loss -0.9095 
2025-01-16 22:54:44.240921: val_loss -0.5763 
2025-01-16 22:54:44.249440: Pseudo dice [np.float32(0.7995), np.float32(0.6093)] 
2025-01-16 22:54:44.255956: Epoch time: 40.94 s 
2025-01-16 22:54:44.783277:  
2025-01-16 22:54:44.783277: Epoch 236 
2025-01-16 22:54:44.790322: Current learning rate: 0.00075 
2025-01-16 22:55:25.710593: train_loss -0.9116 
2025-01-16 22:55:25.711596: val_loss -0.5413 
2025-01-16 22:55:25.718112: Pseudo dice [np.float32(0.7976), np.float32(0.5436)] 
2025-01-16 22:55:25.724125: Epoch time: 40.93 s 
2025-01-16 22:55:26.244737:  
2025-01-16 22:55:26.244737: Epoch 237 
2025-01-16 22:55:26.250753: Current learning rate: 0.0007 
2025-01-16 22:56:07.210505: train_loss -0.9242 
2025-01-16 22:56:07.211019: val_loss -0.5015 
2025-01-16 22:56:07.217064: Pseudo dice [np.float32(0.7918), np.float32(0.5613)] 
2025-01-16 22:56:07.221074: Epoch time: 40.97 s 
2025-01-16 22:56:07.775927:  
2025-01-16 22:56:07.775927: Epoch 238 
2025-01-16 22:56:07.781943: Current learning rate: 0.00065 
2025-01-16 22:56:48.714869: train_loss -0.921 
2025-01-16 22:56:48.714869: val_loss -0.5477 
2025-01-16 22:56:48.721413: Pseudo dice [np.float32(0.7999), np.float32(0.4586)] 
2025-01-16 22:56:48.725423: Epoch time: 40.94 s 
2025-01-16 22:56:49.406468:  
2025-01-16 22:56:49.407471: Epoch 239 
2025-01-16 22:56:49.413009: Current learning rate: 0.0006 
2025-01-16 22:57:30.521850: train_loss -0.9138 
2025-01-16 22:57:30.521850: val_loss -0.5128 
2025-01-16 22:57:30.528383: Pseudo dice [np.float32(0.7849), np.float32(0.4794)] 
2025-01-16 22:57:30.531390: Epoch time: 41.12 s 
2025-01-16 22:57:31.060475:  
2025-01-16 22:57:31.060475: Epoch 240 
2025-01-16 22:57:31.067028: Current learning rate: 0.00055 
2025-01-16 22:58:11.986933: train_loss -0.9133 
2025-01-16 22:58:11.987451: val_loss -0.5761 
2025-01-16 22:58:11.992446: Pseudo dice [np.float32(0.8136), np.float32(0.5264)] 
2025-01-16 22:58:12.016072: Epoch time: 40.93 s 
2025-01-16 22:58:12.546855:  
2025-01-16 22:58:12.548859: Epoch 241 
2025-01-16 22:58:12.554377: Current learning rate: 0.0005 
2025-01-16 22:58:53.465882: train_loss -0.9189 
2025-01-16 22:58:53.466386: val_loss -0.5305 
2025-01-16 22:58:53.474909: Pseudo dice [np.float32(0.767), np.float32(0.6142)] 
2025-01-16 22:58:53.478416: Epoch time: 40.92 s 
2025-01-16 22:58:54.008116:  
2025-01-16 22:58:54.008116: Epoch 242 
2025-01-16 22:58:54.014724: Current learning rate: 0.00045 
2025-01-16 22:59:34.928560: train_loss -0.9233 
2025-01-16 22:59:34.928560: val_loss -0.5695 
2025-01-16 22:59:34.934785: Pseudo dice [np.float32(0.8035), np.float32(0.6141)] 
2025-01-16 22:59:34.937655: Epoch time: 40.92 s 
2025-01-16 22:59:35.472288:  
2025-01-16 22:59:35.472288: Epoch 243 
2025-01-16 22:59:35.478844: Current learning rate: 0.0004 
2025-01-16 23:00:16.379673: train_loss -0.9096 
2025-01-16 23:00:16.380192: val_loss -0.5117 
2025-01-16 23:00:16.386348: Pseudo dice [np.float32(0.7933), np.float32(0.3964)] 
2025-01-16 23:00:16.391386: Epoch time: 40.91 s 
2025-01-16 23:00:16.928623:  
2025-01-16 23:00:16.928623: Epoch 244 
2025-01-16 23:00:16.933669: Current learning rate: 0.00035 
2025-01-16 23:00:57.832243: train_loss -0.9265 
2025-01-16 23:00:57.832243: val_loss -0.5397 
2025-01-16 23:00:57.855806: Pseudo dice [np.float32(0.7788), np.float32(0.4935)] 
2025-01-16 23:00:57.859815: Epoch time: 40.9 s 
2025-01-16 23:00:58.393016:  
2025-01-16 23:00:58.394021: Epoch 245 
2025-01-16 23:00:58.401594: Current learning rate: 0.0003 
2025-01-16 23:01:39.339605: train_loss -0.9221 
2025-01-16 23:01:39.339605: val_loss -0.5455 
2025-01-16 23:01:39.346658: Pseudo dice [np.float32(0.7914), np.float32(0.4611)] 
2025-01-16 23:01:39.350168: Epoch time: 40.95 s 
2025-01-16 23:01:39.887441:  
2025-01-16 23:01:39.887441: Epoch 246 
2025-01-16 23:01:39.893461: Current learning rate: 0.00024 
2025-01-16 23:02:20.786680: train_loss -0.9221 
2025-01-16 23:02:20.787183: val_loss -0.5165 
2025-01-16 23:02:20.793263: Pseudo dice [np.float32(0.7989), np.float32(0.35)] 
2025-01-16 23:02:20.797272: Epoch time: 40.9 s 
2025-01-16 23:02:21.332182:  
2025-01-16 23:02:21.332684: Epoch 247 
2025-01-16 23:02:21.338708: Current learning rate: 0.00019 
2025-01-16 23:03:01.988411: train_loss -0.9178 
2025-01-16 23:03:01.988411: val_loss -0.5355 
2025-01-16 23:03:01.995465: Pseudo dice [np.float32(0.8029), np.float32(0.4097)] 
2025-01-16 23:03:01.998975: Epoch time: 40.66 s 
2025-01-16 23:03:02.686973:  
2025-01-16 23:03:02.686973: Epoch 248 
2025-01-16 23:03:02.693618: Current learning rate: 0.00013 
2025-01-16 23:03:43.312324: train_loss -0.9234 
2025-01-16 23:03:43.313324: val_loss -0.4932 
2025-01-16 23:03:43.318843: Pseudo dice [np.float32(0.7853), np.float32(0.4529)] 
2025-01-16 23:03:43.341443: Epoch time: 40.63 s 
2025-01-16 23:03:43.865515:  
2025-01-16 23:03:43.865515: Epoch 249 
2025-01-16 23:03:43.890756: Current learning rate: 7e-05 
2025-01-16 23:04:24.524912: train_loss -0.9251 
2025-01-16 23:04:24.525415: val_loss -0.4929 
2025-01-16 23:04:24.530428: Pseudo dice [np.float32(0.7752), np.float32(0.4875)] 
2025-01-16 23:04:24.533938: Epoch time: 40.66 s 
2025-01-16 23:04:25.258918: Training done. 
2025-01-16 23:04:25.289433: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset007_Pancreas\splits_final.json 
2025-01-16 23:04:25.300436: The split file contains 5 splits. 
2025-01-16 23:04:25.306435: Desired fold for training: 0 
2025-01-16 23:04:25.313436: This split has 224 training and 57 validation cases. 
2025-01-16 23:04:25.319434: predicting pancreas_021 
2025-01-16 23:04:25.327436: pancreas_021, shape torch.Size([1, 93, 551, 551]), rank 0 
2025-01-16 23:04:27.561722: predicting pancreas_024 
2025-01-16 23:04:27.576724: pancreas_024, shape torch.Size([1, 105, 507, 507]), rank 0 
2025-01-16 23:04:29.469850: predicting pancreas_035 
2025-01-16 23:04:29.483852: pancreas_035, shape torch.Size([1, 73, 391, 391]), rank 0 
2025-01-16 23:04:30.153499: predicting pancreas_040 
2025-01-16 23:04:30.160499: pancreas_040, shape torch.Size([1, 90, 526, 526]), rank 0 
2025-01-16 23:04:31.673435: predicting pancreas_042 
2025-01-16 23:04:31.687939: pancreas_042, shape torch.Size([1, 102, 537, 537]), rank 0 
2025-01-16 23:04:33.601802: predicting pancreas_056 
2025-01-16 23:04:33.618801: pancreas_056, shape torch.Size([1, 84, 488, 488]), rank 0 
2025-01-16 23:04:35.149480: predicting pancreas_067 
2025-01-16 23:04:35.162479: pancreas_067, shape torch.Size([1, 103, 524, 524]), rank 0 
2025-01-16 23:04:37.071895: predicting pancreas_075 
2025-01-16 23:04:37.089401: pancreas_075, shape torch.Size([1, 60, 521, 521]), rank 0 
2025-01-16 23:04:37.897615: predicting pancreas_086 
2025-01-16 23:04:37.908617: pancreas_086, shape torch.Size([1, 51, 573, 573]), rank 0 
2025-01-16 23:04:39.116774: predicting pancreas_089 
2025-01-16 23:04:39.126774: pancreas_089, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-16 23:04:40.682048: predicting pancreas_092 
2025-01-16 23:04:40.696554: pancreas_092, shape torch.Size([1, 184, 513, 513]), rank 0 
2025-01-16 23:04:44.185472: predicting pancreas_094 
2025-01-16 23:04:44.211980: pancreas_094, shape torch.Size([1, 84, 461, 461]), rank 0 
2025-01-16 23:04:45.757676: predicting pancreas_095 
2025-01-16 23:04:45.765675: pancreas_095, shape torch.Size([1, 93, 480, 480]), rank 0 
2025-01-16 23:04:47.334444: predicting pancreas_098 
2025-01-16 23:04:47.348444: pancreas_098, shape torch.Size([1, 147, 592, 592]), rank 0 
2025-01-16 23:04:51.535745: predicting pancreas_109 
2025-01-16 23:04:51.559745: pancreas_109, shape torch.Size([1, 99, 508, 508]), rank 0 
2025-01-16 23:04:53.135555: predicting pancreas_110 
2025-01-16 23:04:53.149555: pancreas_110, shape torch.Size([1, 98, 623, 623]), rank 0 
2025-01-16 23:04:55.575361: predicting pancreas_114 
2025-01-16 23:04:55.593871: pancreas_114, shape torch.Size([1, 98, 451, 451]), rank 0 
2025-01-16 23:04:57.161542: predicting pancreas_119 
2025-01-16 23:04:57.171542: pancreas_119, shape torch.Size([1, 85, 573, 573]), rank 0 
2025-01-16 23:04:59.544056: predicting pancreas_138 
2025-01-16 23:04:59.556053: pancreas_138, shape torch.Size([1, 95, 598, 598]), rank 0 
2025-01-16 23:05:01.973349: predicting pancreas_145 
2025-01-16 23:05:01.990855: pancreas_145, shape torch.Size([1, 93, 598, 598]), rank 0 
2025-01-16 23:05:04.406122: predicting pancreas_148 
2025-01-16 23:05:04.422122: pancreas_148, shape torch.Size([1, 84, 486, 486]), rank 0 
2025-01-16 23:05:05.983649: predicting pancreas_169 
2025-01-16 23:05:05.994156: pancreas_169, shape torch.Size([1, 87, 473, 473]), rank 0 
2025-01-16 23:05:07.543561: predicting pancreas_170 
2025-01-16 23:05:07.554561: pancreas_170, shape torch.Size([1, 103, 512, 512]), rank 0 
2025-01-16 23:05:09.479236: predicting pancreas_172 
2025-01-16 23:05:09.492236: pancreas_172, shape torch.Size([1, 95, 472, 472]), rank 0 
2025-01-16 23:05:11.046226: predicting pancreas_175 
2025-01-16 23:05:11.058226: pancreas_175, shape torch.Size([1, 91, 496, 496]), rank 0 
2025-01-16 23:05:12.615371: predicting pancreas_180 
2025-01-16 23:05:12.627371: pancreas_180, shape torch.Size([1, 95, 473, 473]), rank 0 
2025-01-16 23:05:14.170785: predicting pancreas_191 
2025-01-16 23:05:14.181789: pancreas_191, shape torch.Size([1, 57, 471, 471]), rank 0 
2025-01-16 23:05:14.973032: predicting pancreas_193 
2025-01-16 23:05:14.981031: pancreas_193, shape torch.Size([1, 113, 496, 496]), rank 0 
2025-01-16 23:05:16.908545: predicting pancreas_212 
2025-01-16 23:05:16.922545: pancreas_212, shape torch.Size([1, 97, 557, 557]), rank 0 
2025-01-16 23:05:18.541000: predicting pancreas_215 
2025-01-16 23:05:18.556000: pancreas_215, shape torch.Size([1, 99, 483, 483]), rank 0 
2025-01-16 23:05:20.128124: predicting pancreas_222 
2025-01-16 23:05:20.140122: pancreas_222, shape torch.Size([1, 77, 386, 386]), rank 0 
2025-01-16 23:05:20.822691: predicting pancreas_235 
2025-01-16 23:05:20.830691: pancreas_235, shape torch.Size([1, 84, 496, 496]), rank 0 
2025-01-16 23:05:22.380122: predicting pancreas_241 
2025-01-16 23:05:22.393125: pancreas_241, shape torch.Size([1, 99, 510, 510]), rank 0 
2025-01-16 23:05:23.968422: predicting pancreas_242 
2025-01-16 23:05:23.981421: pancreas_242, shape torch.Size([1, 101, 556, 556]), rank 0 
2025-01-16 23:05:25.920455: predicting pancreas_244 
2025-01-16 23:05:25.936455: pancreas_244, shape torch.Size([1, 103, 579, 579]), rank 0 
2025-01-16 23:05:28.922649: predicting pancreas_246 
2025-01-16 23:05:28.941650: pancreas_246, shape torch.Size([1, 107, 573, 573]), rank 0 
2025-01-16 23:05:31.929444: predicting pancreas_247 
2025-01-16 23:05:31.947444: pancreas_247, shape torch.Size([1, 89, 411, 411]), rank 0 
2025-01-16 23:05:32.850837: predicting pancreas_264 
2025-01-16 23:05:32.859837: pancreas_264, shape torch.Size([1, 109, 534, 534]), rank 0 
2025-01-16 23:05:34.802380: predicting pancreas_265 
2025-01-16 23:05:34.818885: pancreas_265, shape torch.Size([1, 81, 532, 532]), rank 0 
2025-01-16 23:05:36.405786: predicting pancreas_266 
2025-01-16 23:05:36.417297: pancreas_266, shape torch.Size([1, 97, 573, 573]), rank 0 
2025-01-16 23:05:38.814080: predicting pancreas_267 
2025-01-16 23:05:38.830080: pancreas_267, shape torch.Size([1, 89, 434, 434]), rank 0 
2025-01-16 23:05:39.732979: predicting pancreas_275 
2025-01-16 23:05:39.741979: pancreas_275, shape torch.Size([1, 105, 478, 478]), rank 0 
2025-01-16 23:05:41.663866: predicting pancreas_279 
2025-01-16 23:05:41.675866: pancreas_279, shape torch.Size([1, 80, 448, 448]), rank 0 
2025-01-16 23:05:42.379537: predicting pancreas_287 
2025-01-16 23:05:42.388538: pancreas_287, shape torch.Size([1, 98, 497, 497]), rank 0 
2025-01-16 23:05:43.945701: predicting pancreas_301 
2025-01-16 23:05:43.958701: pancreas_301, shape torch.Size([1, 83, 532, 532]), rank 0 
2025-01-16 23:05:45.517177: predicting pancreas_323 
2025-01-16 23:05:45.529178: pancreas_323, shape torch.Size([1, 95, 612, 612]), rank 0 
2025-01-16 23:05:47.945676: predicting pancreas_336 
2025-01-16 23:05:47.963676: pancreas_336, shape torch.Size([1, 92, 548, 548]), rank 0 
2025-01-16 23:05:49.528886: predicting pancreas_344 
2025-01-16 23:05:49.542885: pancreas_344, shape torch.Size([1, 112, 492, 492]), rank 0 
2025-01-16 23:05:51.504035: predicting pancreas_351 
2025-01-16 23:05:51.518541: pancreas_351, shape torch.Size([1, 88, 430, 430]), rank 0 
2025-01-16 23:05:52.420688: predicting pancreas_354 
2025-01-16 23:05:52.429687: pancreas_354, shape torch.Size([1, 162, 529, 529]), rank 0 
2025-01-16 23:05:55.526765: predicting pancreas_372 
2025-01-16 23:05:55.547765: pancreas_372, shape torch.Size([1, 93, 623, 623]), rank 0 
2025-01-16 23:05:57.994437: predicting pancreas_377 
2025-01-16 23:05:58.017956: pancreas_377, shape torch.Size([1, 110, 551, 551]), rank 0 
2025-01-16 23:06:00.016564: predicting pancreas_387 
2025-01-16 23:06:00.039073: pancreas_387, shape torch.Size([1, 100, 498, 498]), rank 0 
2025-01-16 23:06:01.615033: predicting pancreas_391 
2025-01-16 23:06:01.628543: pancreas_391, shape torch.Size([1, 89, 610, 610]), rank 0 
2025-01-16 23:06:04.051490: predicting pancreas_392 
2025-01-16 23:06:04.071490: pancreas_392, shape torch.Size([1, 114, 448, 448]), rank 0 
2025-01-16 23:06:05.229989: predicting pancreas_410 
2025-01-16 23:06:05.242989: pancreas_410, shape torch.Size([1, 101, 448, 448]), rank 0 
2025-01-16 23:06:06.365574: predicting pancreas_412 
2025-01-16 23:06:06.376574: pancreas_412, shape torch.Size([1, 197, 584, 584]), rank 0 
2025-01-16 23:06:27.822567: Validation complete 
2025-01-16 23:06:27.822567: Mean Validation Dice:  0.5833510738530993 
