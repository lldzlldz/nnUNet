2025-01-08 19:11:52.472486: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.25 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-08 19:11:52.475486: self.oversample_foreground_percent 0.0 
2025-01-08 19:11:52.477990: do_dummy_2d_data_aug: False 
2025-01-08 19:11:52.495354: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset003_Liver\splits_final.json 
2025-01-08 19:11:52.502354: The split file contains 5 splits. 
2025-01-08 19:11:52.504355: Desired fold for training: 0 
2025-01-08 19:11:52.507356: This split has 104 training and 27 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [482.0, 512.0, 512.0], 'spacing': [1.0, 0.767578125, 0.767578125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset003_Liver', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 0.767578125, 0.767578125], 'original_median_shape_after_transp': [432, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5420.0, 'mean': 99.48007202148438, 'median': 101.0, 'min': -983.0, 'percentile_00_5': -15.0, 'percentile_99_5': 197.0, 'std': 37.13840103149414}}} 
 
2025-01-08 19:12:00.690094: unpacking dataset... 
2025-01-08 19:12:00.998982: unpacking done... 
2025-01-08 19:12:04.781739:  
2025-01-08 19:12:04.781739: Epoch 0 
2025-01-08 19:12:04.786273: Current learning rate: 0.01 
2025-01-08 19:12:46.178164: train_loss 0.1959 
2025-01-08 19:12:46.178164: val_loss 0.1108 
2025-01-08 19:12:46.185686: Pseudo dice [np.float32(0.0275), np.float32(0.0)] 
2025-01-08 19:12:46.190244: Epoch time: 41.4 s 
2025-01-08 19:12:46.195328: Yayy! New best EMA pseudo Dice: 0.013700000010430813 
2025-01-08 19:12:46.810018:  
2025-01-08 19:12:46.810018: Epoch 1 
2025-01-08 19:12:46.817039: Current learning rate: 0.00996 
2025-01-08 19:13:24.286569: train_loss 0.0673 
2025-01-08 19:13:24.287081: val_loss 0.0441 
2025-01-08 19:13:24.292142: Pseudo dice [np.float32(0.5244), np.float32(0.0)] 
2025-01-08 19:13:24.296159: Epoch time: 37.48 s 
2025-01-08 19:13:24.299675: Yayy! New best EMA pseudo Dice: 0.038600001484155655 
2025-01-08 19:13:24.974204:  
2025-01-08 19:13:24.975204: Epoch 2 
2025-01-08 19:13:24.980817: Current learning rate: 0.00993 
2025-01-08 19:14:02.456745: train_loss 0.0585 
2025-01-08 19:14:02.456745: val_loss 0.0032 
2025-01-08 19:14:02.462767: Pseudo dice [np.float32(0.6096), np.float32(0.0)] 
2025-01-08 19:14:02.466779: Epoch time: 37.48 s 
2025-01-08 19:14:02.470289: Yayy! New best EMA pseudo Dice: 0.06520000100135803 
2025-01-08 19:14:03.167520:  
2025-01-08 19:14:03.167520: Epoch 3 
2025-01-08 19:14:03.173586: Current learning rate: 0.00989 
2025-01-08 19:14:40.655653: train_loss 0.0311 
2025-01-08 19:14:40.655653: val_loss 0.014 
2025-01-08 19:14:40.662171: Pseudo dice [np.float32(0.4763), np.float32(0.0)] 
2025-01-08 19:14:40.665680: Epoch time: 37.49 s 
2025-01-08 19:14:40.669189: Yayy! New best EMA pseudo Dice: 0.08250000327825546 
2025-01-08 19:14:41.345377:  
2025-01-08 19:14:41.345377: Epoch 4 
2025-01-08 19:14:41.350413: Current learning rate: 0.00986 
2025-01-08 19:15:18.820109: train_loss 0.0314 
2025-01-08 19:15:18.820109: val_loss -0.011 
2025-01-08 19:15:18.827256: Pseudo dice [np.float32(0.6474), np.float32(0.0)] 
2025-01-08 19:15:18.832390: Epoch time: 37.48 s 
2025-01-08 19:15:18.836946: Yayy! New best EMA pseudo Dice: 0.10660000145435333 
2025-01-08 19:15:19.653404:  
2025-01-08 19:15:19.653404: Epoch 5 
2025-01-08 19:15:19.659423: Current learning rate: 0.00982 
2025-01-08 19:15:57.146224: train_loss 0.0284 
2025-01-08 19:15:57.146729: val_loss 0.0037 
2025-01-08 19:15:57.151740: Pseudo dice [np.float32(0.5927), np.float32(0.0)] 
2025-01-08 19:15:57.155251: Epoch time: 37.49 s 
2025-01-08 19:15:57.159260: Yayy! New best EMA pseudo Dice: 0.12559999525547028 
2025-01-08 19:15:57.821988:  
2025-01-08 19:15:57.822990: Epoch 6 
2025-01-08 19:15:57.828038: Current learning rate: 0.00978 
2025-01-08 19:16:35.302053: train_loss 0.0114 
2025-01-08 19:16:35.303052: val_loss 0.0246 
2025-01-08 19:16:35.308571: Pseudo dice [np.float32(0.5986), np.float32(0.0)] 
2025-01-08 19:16:35.312080: Epoch time: 37.48 s 
2025-01-08 19:16:35.316093: Yayy! New best EMA pseudo Dice: 0.14300000667572021 
2025-01-08 19:16:35.977618:  
2025-01-08 19:16:35.978618: Epoch 7 
2025-01-08 19:16:35.984204: Current learning rate: 0.00975 
2025-01-08 19:17:13.463197: train_loss 0.0502 
2025-01-08 19:17:13.464197: val_loss 0.0143 
2025-01-08 19:17:13.470720: Pseudo dice [np.float32(0.581), np.float32(0.0)] 
2025-01-08 19:17:13.477262: Epoch time: 37.49 s 
2025-01-08 19:17:13.482369: Yayy! New best EMA pseudo Dice: 0.15770000219345093 
2025-01-08 19:17:14.153936:  
2025-01-08 19:17:14.153936: Epoch 8 
2025-01-08 19:17:14.160453: Current learning rate: 0.00971 
2025-01-08 19:17:51.797384: train_loss 0.0303 
2025-01-08 19:17:51.798391: val_loss 0.0059 
2025-01-08 19:17:51.803402: Pseudo dice [np.float32(0.5035), np.float32(0.0)] 
2025-01-08 19:17:51.808415: Epoch time: 37.64 s 
2025-01-08 19:17:51.814426: Yayy! New best EMA pseudo Dice: 0.1670999974012375 
2025-01-08 19:17:52.499487:  
2025-01-08 19:17:52.499487: Epoch 9 
2025-01-08 19:17:52.505596: Current learning rate: 0.00968 
2025-01-08 19:18:30.034544: train_loss 0.0042 
2025-01-08 19:18:30.034544: val_loss -0.0315 
2025-01-08 19:18:30.040563: Pseudo dice [np.float32(0.6724), np.float32(0.0)] 
2025-01-08 19:18:30.044071: Epoch time: 37.54 s 
2025-01-08 19:18:30.047080: Yayy! New best EMA pseudo Dice: 0.18400000035762787 
2025-01-08 19:18:30.705325:  
2025-01-08 19:18:30.705325: Epoch 10 
2025-01-08 19:18:30.711843: Current learning rate: 0.00964 
2025-01-08 19:19:08.235766: train_loss -0.0116 
2025-01-08 19:19:08.236268: val_loss -0.0105 
2025-01-08 19:19:08.241822: Pseudo dice [np.float32(0.6539), np.float32(0.0)] 
2025-01-08 19:19:08.245340: Epoch time: 37.53 s 
2025-01-08 19:19:08.248371: Yayy! New best EMA pseudo Dice: 0.19830000400543213 
2025-01-08 19:19:08.928604:  
2025-01-08 19:19:08.929607: Epoch 11 
2025-01-08 19:19:08.934180: Current learning rate: 0.0096 
2025-01-08 19:19:46.462720: train_loss -0.0045 
2025-01-08 19:19:46.463725: val_loss -0.0139 
2025-01-08 19:19:46.468735: Pseudo dice [np.float32(0.6787), np.float32(0.0)] 
2025-01-08 19:19:46.472747: Epoch time: 37.53 s 
2025-01-08 19:19:46.476259: Yayy! New best EMA pseudo Dice: 0.21240000426769257 
2025-01-08 19:19:47.150788:  
2025-01-08 19:19:47.150788: Epoch 12 
2025-01-08 19:19:47.157812: Current learning rate: 0.00957 
2025-01-08 19:20:24.687958: train_loss 0.0009 
2025-01-08 19:20:24.689464: val_loss -0.0794 
2025-01-08 19:20:24.695489: Pseudo dice [np.float32(0.7456), np.float32(0.0)] 
2025-01-08 19:20:24.700507: Epoch time: 37.54 s 
2025-01-08 19:20:24.704521: Yayy! New best EMA pseudo Dice: 0.22849999368190765 
2025-01-08 19:20:25.528677:  
2025-01-08 19:20:25.529187: Epoch 13 
2025-01-08 19:20:25.534248: Current learning rate: 0.00953 
2025-01-08 19:21:03.055967: train_loss -0.0278 
2025-01-08 19:21:03.055967: val_loss -0.0158 
2025-01-08 19:21:03.062990: Pseudo dice [np.float32(0.6599), np.float32(0.0)] 
2025-01-08 19:21:03.068508: Epoch time: 37.53 s 
2025-01-08 19:21:03.073522: Yayy! New best EMA pseudo Dice: 0.2386000007390976 
2025-01-08 19:21:03.731250:  
2025-01-08 19:21:03.731250: Epoch 14 
2025-01-08 19:21:03.736638: Current learning rate: 0.00949 
2025-01-08 19:21:41.243479: train_loss -0.0053 
2025-01-08 19:21:41.243479: val_loss -0.0199 
2025-01-08 19:21:41.249496: Pseudo dice [np.float32(0.6787), np.float32(0.0)] 
2025-01-08 19:21:41.253508: Epoch time: 37.51 s 
2025-01-08 19:21:41.257021: Yayy! New best EMA pseudo Dice: 0.24869999289512634 
2025-01-08 19:21:41.932658:  
2025-01-08 19:21:41.932658: Epoch 15 
2025-01-08 19:21:41.938702: Current learning rate: 0.00946 
2025-01-08 19:22:19.545639: train_loss -0.0234 
2025-01-08 19:22:19.546643: val_loss -0.0376 
2025-01-08 19:22:19.553283: Pseudo dice [np.float32(0.6705), np.float32(0.0)] 
2025-01-08 19:22:19.556814: Epoch time: 37.61 s 
2025-01-08 19:22:19.560839: Yayy! New best EMA pseudo Dice: 0.2572999894618988 
2025-01-08 19:22:20.264926:  
2025-01-08 19:22:20.265428: Epoch 16 
2025-01-08 19:22:20.271442: Current learning rate: 0.00942 
2025-01-08 19:22:57.300119: train_loss -0.0187 
2025-01-08 19:22:57.300631: val_loss -0.0891 
2025-01-08 19:22:57.306191: Pseudo dice [np.float32(0.8237), np.float32(0.0)] 
2025-01-08 19:22:57.309227: Epoch time: 37.04 s 
2025-01-08 19:22:57.312791: Yayy! New best EMA pseudo Dice: 0.2727999985218048 
2025-01-08 19:22:58.004448:  
2025-01-08 19:22:58.004448: Epoch 17 
2025-01-08 19:22:58.010540: Current learning rate: 0.00939 
2025-01-08 19:23:34.432319: train_loss -0.0554 
2025-01-08 19:23:34.433323: val_loss -0.0401 
2025-01-08 19:23:34.438948: Pseudo dice [np.float32(0.7455), np.float32(0.0)] 
2025-01-08 19:23:34.442020: Epoch time: 36.43 s 
2025-01-08 19:23:34.445054: Yayy! New best EMA pseudo Dice: 0.28279998898506165 
2025-01-08 19:23:35.122961:  
2025-01-08 19:23:35.122961: Epoch 18 
2025-01-08 19:23:35.128975: Current learning rate: 0.00935 
2025-01-08 19:24:11.526630: train_loss -0.0405 
2025-01-08 19:24:11.526630: val_loss -0.1468 
2025-01-08 19:24:11.533164: Pseudo dice [np.float32(0.7608), np.float32(0.0)] 
2025-01-08 19:24:11.538173: Epoch time: 36.4 s 
2025-01-08 19:24:11.542183: Yayy! New best EMA pseudo Dice: 0.29260000586509705 
2025-01-08 19:24:12.227061:  
2025-01-08 19:24:12.228064: Epoch 19 
2025-01-08 19:24:12.233092: Current learning rate: 0.00931 
2025-01-08 19:24:48.628450: train_loss -0.0323 
2025-01-08 19:24:48.629475: val_loss -0.1005 
2025-01-08 19:24:48.635047: Pseudo dice [np.float32(0.8065), np.float32(0.0)] 
2025-01-08 19:24:48.638601: Epoch time: 36.4 s 
2025-01-08 19:24:48.642159: Yayy! New best EMA pseudo Dice: 0.303600013256073 
2025-01-08 19:24:49.471483:  
2025-01-08 19:24:49.471483: Epoch 20 
2025-01-08 19:24:49.478135: Current learning rate: 0.00928 
2025-01-08 19:25:25.925563: train_loss -0.0531 
2025-01-08 19:25:25.925563: val_loss -0.0892 
2025-01-08 19:25:25.931589: Pseudo dice [np.float32(0.7443), np.float32(0.0)] 
2025-01-08 19:25:25.935092: Epoch time: 36.45 s 
2025-01-08 19:25:25.939104: Yayy! New best EMA pseudo Dice: 0.31049999594688416 
2025-01-08 19:25:26.626408:  
2025-01-08 19:25:26.627411: Epoch 21 
2025-01-08 19:25:26.633485: Current learning rate: 0.00924 
2025-01-08 19:26:03.028861: train_loss -0.0381 
2025-01-08 19:26:03.029365: val_loss -0.0504 
2025-01-08 19:26:03.034377: Pseudo dice [np.float32(0.7066), np.float32(0.0)] 
2025-01-08 19:26:03.037887: Epoch time: 36.4 s 
2025-01-08 19:26:03.041897: Yayy! New best EMA pseudo Dice: 0.3147999942302704 
2025-01-08 19:26:03.711784:  
2025-01-08 19:26:03.711784: Epoch 22 
2025-01-08 19:26:03.717330: Current learning rate: 0.0092 
2025-01-08 19:26:40.122830: train_loss -0.0657 
2025-01-08 19:26:40.122830: val_loss -0.0599 
2025-01-08 19:26:40.130471: Pseudo dice [np.float32(0.8064), np.float32(0.0)] 
2025-01-08 19:26:40.135085: Epoch time: 36.41 s 
2025-01-08 19:26:40.139123: Yayy! New best EMA pseudo Dice: 0.32359999418258667 
2025-01-08 19:26:40.810145:  
2025-01-08 19:26:40.811148: Epoch 23 
2025-01-08 19:26:40.816694: Current learning rate: 0.00917 
2025-01-08 19:27:17.254832: train_loss -0.0474 
2025-01-08 19:27:17.255336: val_loss -0.054 
2025-01-08 19:27:17.261351: Pseudo dice [np.float32(0.6926), np.float32(0.0)] 
2025-01-08 19:27:17.267364: Epoch time: 36.44 s 
2025-01-08 19:27:17.270372: Yayy! New best EMA pseudo Dice: 0.32589998841285706 
2025-01-08 19:27:17.944396:  
2025-01-08 19:27:17.944396: Epoch 24 
2025-01-08 19:27:17.950409: Current learning rate: 0.00913 
2025-01-08 19:27:54.372545: train_loss -0.0574 
2025-01-08 19:27:54.373057: val_loss -0.1259 
2025-01-08 19:27:54.379142: Pseudo dice [np.float32(0.825), np.float32(0.0)] 
2025-01-08 19:27:54.384193: Epoch time: 36.43 s 
2025-01-08 19:27:54.388886: Yayy! New best EMA pseudo Dice: 0.3345000147819519 
2025-01-08 19:27:55.057396:  
2025-01-08 19:27:55.058396: Epoch 25 
2025-01-08 19:27:55.063958: Current learning rate: 0.0091 
2025-01-08 19:28:31.457969: train_loss -0.0961 
2025-01-08 19:28:31.457969: val_loss -0.0686 
2025-01-08 19:28:31.465064: Pseudo dice [np.float32(0.6846), np.float32(0.0)] 
2025-01-08 19:28:31.468119: Epoch time: 36.4 s 
2025-01-08 19:28:31.472231: Yayy! New best EMA pseudo Dice: 0.3352999985218048 
2025-01-08 19:28:32.138166:  
2025-01-08 19:28:32.138166: Epoch 26 
2025-01-08 19:28:32.143719: Current learning rate: 0.00906 
2025-01-08 19:29:08.560385: train_loss -0.0911 
2025-01-08 19:29:08.560888: val_loss -0.0502 
2025-01-08 19:29:08.566456: Pseudo dice [np.float32(0.6528), np.float32(0.0387)] 
2025-01-08 19:29:08.569998: Epoch time: 36.42 s 
2025-01-08 19:29:08.573025: Yayy! New best EMA pseudo Dice: 0.33640000224113464 
2025-01-08 19:29:09.258303:  
2025-01-08 19:29:09.258303: Epoch 27 
2025-01-08 19:29:09.263829: Current learning rate: 0.00902 
2025-01-08 19:29:45.681103: train_loss -0.0437 
2025-01-08 19:29:45.681103: val_loss -0.0954 
2025-01-08 19:29:45.687711: Pseudo dice [np.float32(0.7539), np.float32(0.235)] 
2025-01-08 19:29:45.690243: Epoch time: 36.42 s 
2025-01-08 19:29:45.694432: Yayy! New best EMA pseudo Dice: 0.3522000014781952 
2025-01-08 19:29:46.521200:  
2025-01-08 19:29:46.522206: Epoch 28 
2025-01-08 19:29:46.526755: Current learning rate: 0.00899 
2025-01-08 19:30:22.961741: train_loss -0.0641 
2025-01-08 19:30:22.961741: val_loss -0.0729 
2025-01-08 19:30:22.966809: Pseudo dice [np.float32(0.8129), np.float32(0.1331)] 
2025-01-08 19:30:22.971408: Epoch time: 36.44 s 
2025-01-08 19:30:22.974949: Yayy! New best EMA pseudo Dice: 0.36419999599456787 
2025-01-08 19:30:23.647984:  
2025-01-08 19:30:23.647984: Epoch 29 
2025-01-08 19:30:23.652996: Current learning rate: 0.00895 
2025-01-08 19:31:00.088161: train_loss -0.068 
2025-01-08 19:31:00.089162: val_loss -0.0876 
2025-01-08 19:31:00.095688: Pseudo dice [np.float32(0.842), np.float32(0.1615)] 
2025-01-08 19:31:00.099706: Epoch time: 36.44 s 
2025-01-08 19:31:00.102727: Yayy! New best EMA pseudo Dice: 0.3779999911785126 
2025-01-08 19:31:00.783196:  
2025-01-08 19:31:00.784196: Epoch 30 
2025-01-08 19:31:00.789283: Current learning rate: 0.00891 
2025-01-08 19:31:37.173001: train_loss -0.0719 
2025-01-08 19:31:37.173001: val_loss -0.1278 
2025-01-08 19:31:37.179069: Pseudo dice [np.float32(0.7653), np.float32(0.3726)] 
2025-01-08 19:31:37.182112: Epoch time: 36.39 s 
2025-01-08 19:31:37.185709: Yayy! New best EMA pseudo Dice: 0.3971000015735626 
2025-01-08 19:31:37.868750:  
2025-01-08 19:31:37.868750: Epoch 31 
2025-01-08 19:31:37.874804: Current learning rate: 0.00888 
2025-01-08 19:32:14.271918: train_loss -0.0863 
2025-01-08 19:32:14.272919: val_loss -0.0892 
2025-01-08 19:32:14.278441: Pseudo dice [np.float32(0.7858), np.float32(0.1339)] 
2025-01-08 19:32:14.283455: Epoch time: 36.4 s 
2025-01-08 19:32:14.285961: Yayy! New best EMA pseudo Dice: 0.4034000039100647 
2025-01-08 19:32:14.970796:  
2025-01-08 19:32:14.970796: Epoch 32 
2025-01-08 19:32:14.976835: Current learning rate: 0.00884 
2025-01-08 19:32:51.379391: train_loss -0.0973 
2025-01-08 19:32:51.379391: val_loss -0.0785 
2025-01-08 19:32:51.387025: Pseudo dice [np.float32(0.7177), np.float32(0.0371)] 
2025-01-08 19:32:51.391075: Epoch time: 36.41 s 
2025-01-08 19:32:51.913927:  
2025-01-08 19:32:51.913927: Epoch 33 
2025-01-08 19:32:51.919440: Current learning rate: 0.0088 
2025-01-08 19:33:28.310713: train_loss -0.1115 
2025-01-08 19:33:28.311217: val_loss -0.1165 
2025-01-08 19:33:28.316770: Pseudo dice [np.float32(0.8531), np.float32(0.0694)] 
2025-01-08 19:33:28.319793: Epoch time: 36.4 s 
2025-01-08 19:33:28.323369: Yayy! New best EMA pseudo Dice: 0.4068000018596649 
2025-01-08 19:33:28.996785:  
2025-01-08 19:33:28.997793: Epoch 34 
2025-01-08 19:33:29.002390: Current learning rate: 0.00877 
2025-01-08 19:34:05.417266: train_loss -0.0999 
2025-01-08 19:34:05.417266: val_loss -0.1435 
2025-01-08 19:34:05.423302: Pseudo dice [np.float32(0.8153), np.float32(0.2384)] 
2025-01-08 19:34:05.428912: Epoch time: 36.42 s 
2025-01-08 19:34:05.432426: Yayy! New best EMA pseudo Dice: 0.4187999963760376 
2025-01-08 19:34:06.117127:  
2025-01-08 19:34:06.117127: Epoch 35 
2025-01-08 19:34:06.122690: Current learning rate: 0.00873 
2025-01-08 19:34:42.564519: train_loss -0.0977 
2025-01-08 19:34:42.565520: val_loss -0.1269 
2025-01-08 19:34:42.572053: Pseudo dice [np.float32(0.8256), np.float32(0.1765)] 
2025-01-08 19:34:42.578071: Epoch time: 36.45 s 
2025-01-08 19:34:42.581079: Yayy! New best EMA pseudo Dice: 0.4271000027656555 
2025-01-08 19:34:43.417740:  
2025-01-08 19:34:43.417740: Epoch 36 
2025-01-08 19:34:43.422750: Current learning rate: 0.00869 
2025-01-08 19:35:19.902751: train_loss -0.0698 
2025-01-08 19:35:19.902751: val_loss -0.1384 
2025-01-08 19:35:19.909267: Pseudo dice [np.float32(0.8228), np.float32(0.2093)] 
2025-01-08 19:35:19.912778: Epoch time: 36.49 s 
2025-01-08 19:35:19.916286: Yayy! New best EMA pseudo Dice: 0.4359999895095825 
2025-01-08 19:35:20.603622:  
2025-01-08 19:35:20.604124: Epoch 37 
2025-01-08 19:35:20.610145: Current learning rate: 0.00866 
2025-01-08 19:35:57.015737: train_loss -0.0928 
2025-01-08 19:35:57.015737: val_loss -0.1609 
2025-01-08 19:35:57.023253: Pseudo dice [np.float32(0.8297), np.float32(0.4675)] 
2025-01-08 19:35:57.028264: Epoch time: 36.41 s 
2025-01-08 19:35:57.032271: Yayy! New best EMA pseudo Dice: 0.45719999074935913 
2025-01-08 19:35:57.718375:  
2025-01-08 19:35:57.718375: Epoch 38 
2025-01-08 19:35:57.723407: Current learning rate: 0.00862 
2025-01-08 19:36:34.207419: train_loss -0.0739 
2025-01-08 19:36:34.207419: val_loss -0.1107 
2025-01-08 19:36:34.213933: Pseudo dice [np.float32(0.8242), np.float32(0.2162)] 
2025-01-08 19:36:34.217443: Epoch time: 36.49 s 
2025-01-08 19:36:34.222457: Yayy! New best EMA pseudo Dice: 0.4634999930858612 
2025-01-08 19:36:34.904221:  
2025-01-08 19:36:34.905224: Epoch 39 
2025-01-08 19:36:34.909772: Current learning rate: 0.00858 
2025-01-08 19:37:11.329713: train_loss -0.0933 
2025-01-08 19:37:11.330215: val_loss -0.1257 
2025-01-08 19:37:11.336323: Pseudo dice [np.float32(0.7926), np.float32(0.341)] 
2025-01-08 19:37:11.341377: Epoch time: 36.43 s 
2025-01-08 19:37:11.346032: Yayy! New best EMA pseudo Dice: 0.47380000352859497 
2025-01-08 19:37:12.043311:  
2025-01-08 19:37:12.044311: Epoch 40 
2025-01-08 19:37:12.049356: Current learning rate: 0.00855 
2025-01-08 19:37:48.493359: train_loss -0.1011 
2025-01-08 19:37:48.494359: val_loss -0.1145 
2025-01-08 19:37:48.499876: Pseudo dice [np.float32(0.8042), np.float32(0.2069)] 
2025-01-08 19:37:48.502383: Epoch time: 36.45 s 
2025-01-08 19:37:48.505896: Yayy! New best EMA pseudo Dice: 0.47699999809265137 
2025-01-08 19:37:49.197561:  
2025-01-08 19:37:49.198564: Epoch 41 
2025-01-08 19:37:49.203145: Current learning rate: 0.00851 
2025-01-08 19:38:25.596177: train_loss -0.0783 
2025-01-08 19:38:25.596177: val_loss -0.0915 
2025-01-08 19:38:25.603242: Pseudo dice [np.float32(0.8152), np.float32(0.1856)] 
2025-01-08 19:38:25.606776: Epoch time: 36.4 s 
2025-01-08 19:38:25.610322: Yayy! New best EMA pseudo Dice: 0.47940000891685486 
2025-01-08 19:38:26.267850:  
2025-01-08 19:38:26.267850: Epoch 42 
2025-01-08 19:38:26.272860: Current learning rate: 0.00847 
2025-01-08 19:39:02.670021: train_loss -0.1042 
2025-01-08 19:39:02.670021: val_loss -0.166 
2025-01-08 19:39:02.676603: Pseudo dice [np.float32(0.8105), np.float32(0.2378)] 
2025-01-08 19:39:02.680155: Epoch time: 36.4 s 
2025-01-08 19:39:02.683187: Yayy! New best EMA pseudo Dice: 0.4837999939918518 
2025-01-08 19:39:03.491777:  
2025-01-08 19:39:03.492780: Epoch 43 
2025-01-08 19:39:03.498348: Current learning rate: 0.00844 
2025-01-08 19:39:39.869505: train_loss -0.0889 
2025-01-08 19:39:39.869505: val_loss -0.1214 
2025-01-08 19:39:39.875520: Pseudo dice [np.float32(0.8043), np.float32(0.1638)] 
2025-01-08 19:39:39.879540: Epoch time: 36.38 s 
2025-01-08 19:39:39.882047: Yayy! New best EMA pseudo Dice: 0.4839000105857849 
2025-01-08 19:39:40.554389:  
2025-01-08 19:39:40.554389: Epoch 44 
2025-01-08 19:39:40.560030: Current learning rate: 0.0084 
2025-01-08 19:40:16.960233: train_loss -0.0984 
2025-01-08 19:40:16.960233: val_loss -0.1304 
2025-01-08 19:40:16.966268: Pseudo dice [np.float32(0.7994), np.float32(0.5275)] 
2025-01-08 19:40:16.970293: Epoch time: 36.41 s 
2025-01-08 19:40:16.972804: Yayy! New best EMA pseudo Dice: 0.501800000667572 
2025-01-08 19:40:17.639723:  
2025-01-08 19:40:17.640226: Epoch 45 
2025-01-08 19:40:17.645243: Current learning rate: 0.00836 
2025-01-08 19:40:54.097856: train_loss -0.0994 
2025-01-08 19:40:54.098357: val_loss -0.1309 
2025-01-08 19:40:54.103367: Pseudo dice [np.float32(0.8279), np.float32(0.1942)] 
2025-01-08 19:40:54.106875: Epoch time: 36.46 s 
2025-01-08 19:40:54.109384: Yayy! New best EMA pseudo Dice: 0.5026999711990356 
2025-01-08 19:40:54.775737:  
2025-01-08 19:40:54.775737: Epoch 46 
2025-01-08 19:40:54.781772: Current learning rate: 0.00833 
2025-01-08 19:41:31.197921: train_loss -0.1217 
2025-01-08 19:41:31.199431: val_loss -0.0785 
2025-01-08 19:41:31.205477: Pseudo dice [np.float32(0.698), np.float32(0.393)] 
2025-01-08 19:41:31.211493: Epoch time: 36.42 s 
2025-01-08 19:41:31.216503: Yayy! New best EMA pseudo Dice: 0.5070000290870667 
2025-01-08 19:41:31.886641:  
2025-01-08 19:41:31.887143: Epoch 47 
2025-01-08 19:41:31.892157: Current learning rate: 0.00829 
2025-01-08 19:42:08.303632: train_loss -0.125 
2025-01-08 19:42:08.304635: val_loss -0.0621 
2025-01-08 19:42:08.311148: Pseudo dice [np.float32(0.7096), np.float32(0.0514)] 
2025-01-08 19:42:08.315655: Epoch time: 36.42 s 
2025-01-08 19:42:08.840071:  
2025-01-08 19:42:08.841074: Epoch 48 
2025-01-08 19:42:08.845648: Current learning rate: 0.00825 
2025-01-08 19:42:45.229342: train_loss -0.1104 
2025-01-08 19:42:45.230853: val_loss -0.1508 
2025-01-08 19:42:45.236947: Pseudo dice [np.float32(0.8393), np.float32(0.5864)] 
2025-01-08 19:42:45.239458: Epoch time: 36.39 s 
2025-01-08 19:42:45.242968: Yayy! New best EMA pseudo Dice: 0.5162000060081482 
2025-01-08 19:42:45.908445:  
2025-01-08 19:42:45.908445: Epoch 49 
2025-01-08 19:42:45.913457: Current learning rate: 0.00822 
2025-01-08 19:43:22.381250: train_loss -0.0891 
2025-01-08 19:43:22.382265: val_loss -0.1147 
2025-01-08 19:43:22.388007: Pseudo dice [np.float32(0.7563), np.float32(0.2589)] 
2025-01-08 19:43:22.390525: Epoch time: 36.47 s 
2025-01-08 19:43:23.058412:  
2025-01-08 19:43:23.059412: Epoch 50 
2025-01-08 19:43:23.064485: Current learning rate: 0.00818 
2025-01-08 19:43:59.492411: train_loss -0.1214 
2025-01-08 19:43:59.492411: val_loss -0.0961 
2025-01-08 19:43:59.498426: Pseudo dice [np.float32(0.7297), np.float32(0.0324)] 
2025-01-08 19:43:59.501434: Epoch time: 36.43 s 
2025-01-08 19:44:00.181243:  
2025-01-08 19:44:00.182248: Epoch 51 
2025-01-08 19:44:00.186799: Current learning rate: 0.00814 
2025-01-08 19:44:36.577353: train_loss -0.0883 
2025-01-08 19:44:36.577859: val_loss -0.1003 
2025-01-08 19:44:36.582869: Pseudo dice [np.float32(0.7928), np.float32(0.0474)] 
2025-01-08 19:44:36.586378: Epoch time: 36.4 s 
2025-01-08 19:44:37.117840:  
2025-01-08 19:44:37.117840: Epoch 52 
2025-01-08 19:44:37.123890: Current learning rate: 0.00811 
2025-01-08 19:45:13.533969: train_loss -0.1247 
2025-01-08 19:45:13.534472: val_loss -0.1299 
2025-01-08 19:45:13.540495: Pseudo dice [np.float32(0.8033), np.float32(0.5129)] 
2025-01-08 19:45:13.545511: Epoch time: 36.42 s 
2025-01-08 19:45:14.076830:  
2025-01-08 19:45:14.076830: Epoch 53 
2025-01-08 19:45:14.082886: Current learning rate: 0.00807 
2025-01-08 19:45:50.521563: train_loss -0.1039 
2025-01-08 19:45:50.522566: val_loss -0.1272 
2025-01-08 19:45:50.529079: Pseudo dice [np.float32(0.7346), np.float32(0.1359)] 
2025-01-08 19:45:50.534092: Epoch time: 36.45 s 
2025-01-08 19:45:51.061797:  
2025-01-08 19:45:51.061797: Epoch 54 
2025-01-08 19:45:51.069415: Current learning rate: 0.00803 
2025-01-08 19:46:27.461673: train_loss -0.0922 
2025-01-08 19:46:27.461673: val_loss -0.1298 
2025-01-08 19:46:27.468098: Pseudo dice [np.float32(0.7577), np.float32(0.4567)] 
2025-01-08 19:46:27.472623: Epoch time: 36.4 s 
2025-01-08 19:46:28.009609:  
2025-01-08 19:46:28.009609: Epoch 55 
2025-01-08 19:46:28.015671: Current learning rate: 0.008 
2025-01-08 19:47:04.405125: train_loss -0.0997 
2025-01-08 19:47:04.405637: val_loss -0.0998 
2025-01-08 19:47:04.412705: Pseudo dice [np.float32(0.7884), np.float32(0.2485)] 
2025-01-08 19:47:04.416843: Epoch time: 36.4 s 
2025-01-08 19:47:04.944614:  
2025-01-08 19:47:04.945115: Epoch 56 
2025-01-08 19:47:04.951128: Current learning rate: 0.00796 
2025-01-08 19:47:41.336589: train_loss -0.1513 
2025-01-08 19:47:41.336589: val_loss -0.1654 
2025-01-08 19:47:41.343153: Pseudo dice [np.float32(0.8687), np.float32(0.4714)] 
2025-01-08 19:47:41.347231: Epoch time: 36.39 s 
2025-01-08 19:47:41.350845: Yayy! New best EMA pseudo Dice: 0.5292999744415283 
2025-01-08 19:47:42.094596:  
2025-01-08 19:47:42.094596: Epoch 57 
2025-01-08 19:47:42.101164: Current learning rate: 0.00792 
2025-01-08 19:48:18.500135: train_loss -0.0867 
2025-01-08 19:48:18.501137: val_loss -0.1387 
2025-01-08 19:48:18.507657: Pseudo dice [np.float32(0.8572), np.float32(0.3451)] 
2025-01-08 19:48:18.512672: Epoch time: 36.41 s 
2025-01-08 19:48:18.516684: Yayy! New best EMA pseudo Dice: 0.5364999771118164 
2025-01-08 19:48:19.203912:  
2025-01-08 19:48:19.203912: Epoch 58 
2025-01-08 19:48:19.209968: Current learning rate: 0.00789 
2025-01-08 19:48:55.602770: train_loss -0.1189 
2025-01-08 19:48:55.602770: val_loss -0.1342 
2025-01-08 19:48:55.610296: Pseudo dice [np.float32(0.8918), np.float32(0.5395)] 
2025-01-08 19:48:55.614306: Epoch time: 36.4 s 
2025-01-08 19:48:55.617817: Yayy! New best EMA pseudo Dice: 0.5544000267982483 
2025-01-08 19:48:56.477140:  
2025-01-08 19:48:56.478143: Epoch 59 
2025-01-08 19:48:56.482681: Current learning rate: 0.00785 
2025-01-08 19:49:32.900574: train_loss -0.1106 
2025-01-08 19:49:32.901578: val_loss -0.1724 
2025-01-08 19:49:32.908095: Pseudo dice [np.float32(0.8234), np.float32(0.3319)] 
2025-01-08 19:49:32.911608: Epoch time: 36.42 s 
2025-01-08 19:49:32.915620: Yayy! New best EMA pseudo Dice: 0.5566999912261963 
2025-01-08 19:49:33.604261:  
2025-01-08 19:49:33.605261: Epoch 60 
2025-01-08 19:49:33.610869: Current learning rate: 0.00781 
2025-01-08 19:50:10.042924: train_loss -0.1267 
2025-01-08 19:50:10.042924: val_loss -0.1714 
2025-01-08 19:50:10.048471: Pseudo dice [np.float32(0.8417), np.float32(0.4848)] 
2025-01-08 19:50:10.052479: Epoch time: 36.44 s 
2025-01-08 19:50:10.054986: Yayy! New best EMA pseudo Dice: 0.5673999786376953 
2025-01-08 19:50:10.736458:  
2025-01-08 19:50:10.736458: Epoch 61 
2025-01-08 19:50:10.741473: Current learning rate: 0.00777 
2025-01-08 19:50:47.309636: train_loss -0.1586 
2025-01-08 19:50:47.310636: val_loss -0.1665 
2025-01-08 19:50:47.317152: Pseudo dice [np.float32(0.768), np.float32(0.3271)] 
2025-01-08 19:50:47.319657: Epoch time: 36.57 s 
2025-01-08 19:50:47.854221:  
2025-01-08 19:50:47.854221: Epoch 62 
2025-01-08 19:50:47.861065: Current learning rate: 0.00774 
2025-01-08 19:51:24.259859: train_loss -0.1073 
2025-01-08 19:51:24.260365: val_loss -0.1457 
2025-01-08 19:51:24.265964: Pseudo dice [np.float32(0.837), np.float32(0.3513)] 
2025-01-08 19:51:24.270061: Epoch time: 36.41 s 
2025-01-08 19:51:24.273102: Yayy! New best EMA pseudo Dice: 0.5683000087738037 
2025-01-08 19:51:24.946328:  
2025-01-08 19:51:24.946328: Epoch 63 
2025-01-08 19:51:24.952352: Current learning rate: 0.0077 
2025-01-08 19:52:01.348042: train_loss -0.1313 
2025-01-08 19:52:01.349044: val_loss -0.1792 
2025-01-08 19:52:01.354570: Pseudo dice [np.float32(0.8143), np.float32(0.3088)] 
2025-01-08 19:52:01.359585: Epoch time: 36.4 s 
2025-01-08 19:52:01.891382:  
2025-01-08 19:52:01.891382: Epoch 64 
2025-01-08 19:52:01.896420: Current learning rate: 0.00766 
2025-01-08 19:52:38.302835: train_loss -0.0979 
2025-01-08 19:52:38.303840: val_loss -0.0753 
2025-01-08 19:52:38.310355: Pseudo dice [np.float32(0.7621), np.float32(0.2023)] 
2025-01-08 19:52:38.314869: Epoch time: 36.41 s 
2025-01-08 19:52:38.851948:  
2025-01-08 19:52:38.852954: Epoch 65 
2025-01-08 19:52:38.858053: Current learning rate: 0.00763 
2025-01-08 19:53:15.255826: train_loss -0.1372 
2025-01-08 19:53:15.256329: val_loss -0.1263 
2025-01-08 19:53:15.263851: Pseudo dice [np.float32(0.8188), np.float32(0.3986)] 
2025-01-08 19:53:15.270866: Epoch time: 36.4 s 
2025-01-08 19:53:15.800504:  
2025-01-08 19:53:15.800504: Epoch 66 
2025-01-08 19:53:15.806081: Current learning rate: 0.00759 
2025-01-08 19:53:52.232719: train_loss -0.127 
2025-01-08 19:53:52.233723: val_loss -0.2078 
2025-01-08 19:53:52.240239: Pseudo dice [np.float32(0.8749), np.float32(0.5741)] 
2025-01-08 19:53:52.246264: Epoch time: 36.43 s 
2025-01-08 19:53:52.253794: Yayy! New best EMA pseudo Dice: 0.5800999999046326 
2025-01-08 19:53:53.086039:  
2025-01-08 19:53:53.086039: Epoch 67 
2025-01-08 19:53:53.091596: Current learning rate: 0.00755 
2025-01-08 19:54:29.525506: train_loss -0.1267 
2025-01-08 19:54:29.525506: val_loss -0.1417 
2025-01-08 19:54:29.531524: Pseudo dice [np.float32(0.8316), np.float32(0.1161)] 
2025-01-08 19:54:29.535537: Epoch time: 36.44 s 
2025-01-08 19:54:30.083146:  
2025-01-08 19:54:30.083146: Epoch 68 
2025-01-08 19:54:30.088711: Current learning rate: 0.00751 
2025-01-08 19:55:06.489041: train_loss -0.1326 
2025-01-08 19:55:06.490046: val_loss -0.1229 
2025-01-08 19:55:06.496459: Pseudo dice [np.float32(0.7966), np.float32(0.2956)] 
2025-01-08 19:55:06.500476: Epoch time: 36.41 s 
2025-01-08 19:55:07.042221:  
2025-01-08 19:55:07.042221: Epoch 69 
2025-01-08 19:55:07.048243: Current learning rate: 0.00748 
2025-01-08 19:55:43.453877: train_loss -0.1226 
2025-01-08 19:55:43.453877: val_loss -0.1686 
2025-01-08 19:55:43.460035: Pseudo dice [np.float32(0.8726), np.float32(0.5098)] 
2025-01-08 19:55:43.464128: Epoch time: 36.41 s 
2025-01-08 19:55:44.005452:  
2025-01-08 19:55:44.006455: Epoch 70 
2025-01-08 19:55:44.010478: Current learning rate: 0.00744 
2025-01-08 19:56:20.680982: train_loss -0.1262 
2025-01-08 19:56:20.681983: val_loss -0.1754 
2025-01-08 19:56:20.687496: Pseudo dice [np.float32(0.8999), np.float32(0.4341)] 
2025-01-08 19:56:20.692009: Epoch time: 36.68 s 
2025-01-08 19:56:20.696025: Yayy! New best EMA pseudo Dice: 0.5882999897003174 
2025-01-08 19:56:21.399278:  
2025-01-08 19:56:21.400282: Epoch 71 
2025-01-08 19:56:21.405313: Current learning rate: 0.0074 
2025-01-08 19:56:57.787621: train_loss -0.1053 
2025-01-08 19:56:57.788136: val_loss -0.1257 
2025-01-08 19:56:57.793717: Pseudo dice [np.float32(0.7713), np.float32(0.2117)] 
2025-01-08 19:56:57.796771: Epoch time: 36.39 s 
2025-01-08 19:56:58.339321:  
2025-01-08 19:56:58.340322: Epoch 72 
2025-01-08 19:56:58.345404: Current learning rate: 0.00737 
2025-01-08 19:57:34.726771: train_loss -0.1447 
2025-01-08 19:57:34.727281: val_loss -0.2112 
2025-01-08 19:57:34.733334: Pseudo dice [np.float32(0.8295), np.float32(0.3076)] 
2025-01-08 19:57:34.738391: Epoch time: 36.39 s 
2025-01-08 19:57:35.280178:  
2025-01-08 19:57:35.281176: Epoch 73 
2025-01-08 19:57:35.286231: Current learning rate: 0.00733 
2025-01-08 19:58:11.682389: train_loss -0.1336 
2025-01-08 19:58:11.683393: val_loss -0.1966 
2025-01-08 19:58:11.688960: Pseudo dice [np.float32(0.8335), np.float32(0.203)] 
2025-01-08 19:58:11.692468: Epoch time: 36.4 s 
2025-01-08 19:58:12.234993:  
2025-01-08 19:58:12.236007: Epoch 74 
2025-01-08 19:58:12.241058: Current learning rate: 0.00729 
2025-01-08 19:58:48.649393: train_loss -0.0925 
2025-01-08 19:58:48.650395: val_loss -0.1186 
2025-01-08 19:58:48.655917: Pseudo dice [np.float32(0.7535), np.float32(0.6418)] 
2025-01-08 19:58:48.660431: Epoch time: 36.41 s 
2025-01-08 19:58:49.375215:  
2025-01-08 19:58:49.375717: Epoch 75 
2025-01-08 19:58:49.380231: Current learning rate: 0.00725 
2025-01-08 19:59:25.786105: train_loss -0.1073 
2025-01-08 19:59:25.786607: val_loss -0.1981 
2025-01-08 19:59:25.792624: Pseudo dice [np.float32(0.8985), np.float32(0.4365)] 
2025-01-08 19:59:25.796130: Epoch time: 36.41 s 
2025-01-08 19:59:25.799138: Yayy! New best EMA pseudo Dice: 0.5925999879837036 
2025-01-08 19:59:26.477067:  
2025-01-08 19:59:26.477067: Epoch 76 
2025-01-08 19:59:26.483089: Current learning rate: 0.00722 
2025-01-08 20:00:02.894489: train_loss -0.148 
2025-01-08 20:00:02.894489: val_loss -0.1833 
2025-01-08 20:00:02.900502: Pseudo dice [np.float32(0.8587), np.float32(0.2992)] 
2025-01-08 20:00:02.903510: Epoch time: 36.42 s 
2025-01-08 20:00:03.442247:  
2025-01-08 20:00:03.442247: Epoch 77 
2025-01-08 20:00:03.447804: Current learning rate: 0.00718 
2025-01-08 20:00:39.894835: train_loss -0.1552 
2025-01-08 20:00:39.895836: val_loss -0.1723 
2025-01-08 20:00:39.901350: Pseudo dice [np.float32(0.8282), np.float32(0.523)] 
2025-01-08 20:00:39.904858: Epoch time: 36.45 s 
2025-01-08 20:00:39.909868: Yayy! New best EMA pseudo Dice: 0.5996999740600586 
2025-01-08 20:00:40.680044:  
2025-01-08 20:00:40.680044: Epoch 78 
2025-01-08 20:00:40.686110: Current learning rate: 0.00714 
2025-01-08 20:01:17.065770: train_loss -0.1544 
2025-01-08 20:01:17.065770: val_loss -0.2102 
2025-01-08 20:01:17.073296: Pseudo dice [np.float32(0.8406), np.float32(0.2385)] 
2025-01-08 20:01:17.077806: Epoch time: 36.39 s 
2025-01-08 20:01:17.634487:  
2025-01-08 20:01:17.634487: Epoch 79 
2025-01-08 20:01:17.640504: Current learning rate: 0.0071 
2025-01-08 20:01:54.040823: train_loss -0.1639 
2025-01-08 20:01:54.041823: val_loss -0.1948 
2025-01-08 20:01:54.048161: Pseudo dice [np.float32(0.8293), np.float32(0.4321)] 
2025-01-08 20:01:54.052166: Epoch time: 36.41 s 
2025-01-08 20:01:54.598245:  
2025-01-08 20:01:54.598746: Epoch 80 
2025-01-08 20:01:54.603757: Current learning rate: 0.00707 
2025-01-08 20:02:30.986329: train_loss -0.1238 
2025-01-08 20:02:30.987331: val_loss -0.1648 
2025-01-08 20:02:30.992845: Pseudo dice [np.float32(0.8568), np.float32(0.5312)] 
2025-01-08 20:02:30.996384: Epoch time: 36.39 s 
2025-01-08 20:02:30.999889: Yayy! New best EMA pseudo Dice: 0.6069999933242798 
2025-01-08 20:02:31.692314:  
2025-01-08 20:02:31.692314: Epoch 81 
2025-01-08 20:02:31.697881: Current learning rate: 0.00703 
2025-01-08 20:03:08.093447: train_loss -0.1637 
2025-01-08 20:03:08.093447: val_loss -0.2039 
2025-01-08 20:03:08.099964: Pseudo dice [np.float32(0.8305), np.float32(0.3126)] 
2025-01-08 20:03:08.103475: Epoch time: 36.4 s 
2025-01-08 20:03:08.797643:  
2025-01-08 20:03:08.798646: Epoch 82 
2025-01-08 20:03:08.803671: Current learning rate: 0.00699 
2025-01-08 20:03:45.180674: train_loss -0.1019 
2025-01-08 20:03:45.181178: val_loss -0.0583 
2025-01-08 20:03:45.186701: Pseudo dice [np.float32(0.7306), np.float32(0.0255)] 
2025-01-08 20:03:45.192238: Epoch time: 36.38 s 
2025-01-08 20:03:45.710000:  
2025-01-08 20:03:45.710000: Epoch 83 
2025-01-08 20:03:45.715542: Current learning rate: 0.00696 
2025-01-08 20:04:22.229323: train_loss -0.1383 
2025-01-08 20:04:22.230826: val_loss -0.1265 
2025-01-08 20:04:22.236846: Pseudo dice [np.float32(0.7805), np.float32(0.2196)] 
2025-01-08 20:04:22.240855: Epoch time: 36.52 s 
2025-01-08 20:04:22.825161:  
2025-01-08 20:04:22.825667: Epoch 84 
2025-01-08 20:04:22.830729: Current learning rate: 0.00692 
2025-01-08 20:04:59.251853: train_loss -0.127 
2025-01-08 20:04:59.253355: val_loss -0.1678 
2025-01-08 20:04:59.260878: Pseudo dice [np.float32(0.8528), np.float32(0.6677)] 
2025-01-08 20:04:59.264392: Epoch time: 36.43 s 
2025-01-08 20:04:59.786680:  
2025-01-08 20:04:59.787681: Epoch 85 
2025-01-08 20:04:59.792717: Current learning rate: 0.00688 
2025-01-08 20:05:36.188803: train_loss -0.1373 
2025-01-08 20:05:36.188803: val_loss -0.1207 
2025-01-08 20:05:36.194822: Pseudo dice [np.float32(0.7431), np.float32(0.144)] 
2025-01-08 20:05:36.197833: Epoch time: 36.4 s 
2025-01-08 20:05:36.717839:  
2025-01-08 20:05:36.718839: Epoch 86 
2025-01-08 20:05:36.724350: Current learning rate: 0.00684 
2025-01-08 20:06:13.118269: train_loss -0.1575 
2025-01-08 20:06:13.119272: val_loss -0.2111 
2025-01-08 20:06:13.125784: Pseudo dice [np.float32(0.876), np.float32(0.2687)] 
2025-01-08 20:06:13.130795: Epoch time: 36.4 s 
2025-01-08 20:06:13.663200:  
2025-01-08 20:06:13.663200: Epoch 87 
2025-01-08 20:06:13.668218: Current learning rate: 0.0068 
2025-01-08 20:06:50.065275: train_loss -0.1349 
2025-01-08 20:06:50.065275: val_loss -0.1889 
2025-01-08 20:06:50.072795: Pseudo dice [np.float32(0.8703), np.float32(0.5711)] 
2025-01-08 20:06:50.077808: Epoch time: 36.4 s 
2025-01-08 20:06:50.603612:  
2025-01-08 20:06:50.603612: Epoch 88 
2025-01-08 20:06:50.609376: Current learning rate: 0.00677 
2025-01-08 20:07:27.040642: train_loss -0.1245 
2025-01-08 20:07:27.042145: val_loss -0.1384 
2025-01-08 20:07:27.047730: Pseudo dice [np.float32(0.8532), np.float32(0.2905)] 
2025-01-08 20:07:27.052742: Epoch time: 36.44 s 
2025-01-08 20:07:27.575805:  
2025-01-08 20:07:27.576809: Epoch 89 
2025-01-08 20:07:27.580982: Current learning rate: 0.00673 
2025-01-08 20:08:03.990036: train_loss -0.1649 
2025-01-08 20:08:03.990036: val_loss -0.1692 
2025-01-08 20:08:03.997278: Pseudo dice [np.float32(0.8138), np.float32(0.4535)] 
2025-01-08 20:08:04.000803: Epoch time: 36.41 s 
2025-01-08 20:08:04.533461:  
2025-01-08 20:08:04.533461: Epoch 90 
2025-01-08 20:08:04.538518: Current learning rate: 0.00669 
2025-01-08 20:08:40.933326: train_loss -0.1599 
2025-01-08 20:08:40.933840: val_loss -0.115 
2025-01-08 20:08:40.939981: Pseudo dice [np.float32(0.8725), np.float32(0.0247)] 
2025-01-08 20:08:40.943544: Epoch time: 36.4 s 
2025-01-08 20:08:41.643618:  
2025-01-08 20:08:41.644695: Epoch 91 
2025-01-08 20:08:41.649288: Current learning rate: 0.00665 
2025-01-08 20:09:18.061993: train_loss -0.1437 
2025-01-08 20:09:18.062994: val_loss -0.1653 
2025-01-08 20:09:18.069509: Pseudo dice [np.float32(0.8941), np.float32(0.5287)] 
2025-01-08 20:09:18.074520: Epoch time: 36.42 s 
2025-01-08 20:09:18.609360:  
2025-01-08 20:09:18.610366: Epoch 92 
2025-01-08 20:09:18.614413: Current learning rate: 0.00662 
2025-01-08 20:09:55.030073: train_loss -0.1673 
2025-01-08 20:09:55.030073: val_loss -0.1743 
2025-01-08 20:09:55.038708: Pseudo dice [np.float32(0.869), np.float32(0.3218)] 
2025-01-08 20:09:55.042255: Epoch time: 36.42 s 
2025-01-08 20:09:55.597196:  
2025-01-08 20:09:55.597196: Epoch 93 
2025-01-08 20:09:55.602712: Current learning rate: 0.00658 
2025-01-08 20:10:32.014373: train_loss -0.1359 
2025-01-08 20:10:32.014373: val_loss -0.185 
2025-01-08 20:10:32.021418: Pseudo dice [np.float32(0.8605), np.float32(0.5513)] 
2025-01-08 20:10:32.025428: Epoch time: 36.42 s 
2025-01-08 20:10:32.552458:  
2025-01-08 20:10:32.553457: Epoch 94 
2025-01-08 20:10:32.559043: Current learning rate: 0.00654 
2025-01-08 20:11:09.024836: train_loss -0.1367 
2025-01-08 20:11:09.025857: val_loss -0.1645 
2025-01-08 20:11:09.031903: Pseudo dice [np.float32(0.7697), np.float32(0.445)] 
2025-01-08 20:11:09.036531: Epoch time: 36.47 s 
2025-01-08 20:11:09.561555:  
2025-01-08 20:11:09.561555: Epoch 95 
2025-01-08 20:11:09.567105: Current learning rate: 0.0065 
2025-01-08 20:11:45.968814: train_loss -0.1147 
2025-01-08 20:11:45.969318: val_loss -0.167 
2025-01-08 20:11:45.975337: Pseudo dice [np.float32(0.8437), np.float32(0.5081)] 
2025-01-08 20:11:45.980350: Epoch time: 36.41 s 
2025-01-08 20:11:45.984286: Yayy! New best EMA pseudo Dice: 0.611299991607666 
2025-01-08 20:11:46.672764:  
2025-01-08 20:11:46.672764: Epoch 96 
2025-01-08 20:11:46.678777: Current learning rate: 0.00647 
2025-01-08 20:12:23.053041: train_loss -0.1444 
2025-01-08 20:12:23.054040: val_loss -0.1621 
2025-01-08 20:12:23.059239: Pseudo dice [np.float32(0.8737), np.float32(0.1874)] 
2025-01-08 20:12:23.063263: Epoch time: 36.38 s 
2025-01-08 20:12:23.597858:  
2025-01-08 20:12:23.598862: Epoch 97 
2025-01-08 20:12:23.603411: Current learning rate: 0.00643 
2025-01-08 20:13:00.011299: train_loss -0.1517 
2025-01-08 20:13:00.011802: val_loss -0.0766 
2025-01-08 20:13:00.020328: Pseudo dice [np.float32(0.778), np.float32(0.3144)] 
2025-01-08 20:13:00.027850: Epoch time: 36.41 s 
2025-01-08 20:13:00.562252:  
2025-01-08 20:13:00.562754: Epoch 98 
2025-01-08 20:13:00.567764: Current learning rate: 0.00639 
2025-01-08 20:13:37.063857: train_loss -0.1189 
2025-01-08 20:13:37.063857: val_loss -0.2298 
2025-01-08 20:13:37.071380: Pseudo dice [np.float32(0.9058), np.float32(0.5662)] 
2025-01-08 20:13:37.075390: Epoch time: 36.5 s 
2025-01-08 20:13:37.077896: Yayy! New best EMA pseudo Dice: 0.6114000082015991 
2025-01-08 20:13:37.749764:  
2025-01-08 20:13:37.749764: Epoch 99 
2025-01-08 20:13:37.755341: Current learning rate: 0.00635 
2025-01-08 20:14:14.164241: train_loss -0.1883 
2025-01-08 20:14:14.164241: val_loss -0.2346 
2025-01-08 20:14:14.170863: Pseudo dice [np.float32(0.8581), np.float32(0.5664)] 
2025-01-08 20:14:14.174407: Epoch time: 36.41 s 
2025-01-08 20:14:14.320626: Yayy! New best EMA pseudo Dice: 0.6215000152587891 
2025-01-08 20:14:15.008657:  
2025-01-08 20:14:15.008657: Epoch 100 
2025-01-08 20:14:15.014171: Current learning rate: 0.00631 
2025-01-08 20:14:51.383231: train_loss -0.1522 
2025-01-08 20:14:51.383733: val_loss -0.1113 
2025-01-08 20:14:51.389609: Pseudo dice [np.float32(0.7458), np.float32(0.273)] 
2025-01-08 20:14:51.393124: Epoch time: 36.38 s 
2025-01-08 20:14:51.921804:  
2025-01-08 20:14:51.921804: Epoch 101 
2025-01-08 20:14:51.927362: Current learning rate: 0.00628 
2025-01-08 20:15:28.340102: train_loss -0.1082 
2025-01-08 20:15:28.340102: val_loss -0.1725 
2025-01-08 20:15:28.346259: Pseudo dice [np.float32(0.8333), np.float32(0.4)] 
2025-01-08 20:15:28.350343: Epoch time: 36.42 s 
2025-01-08 20:15:28.881287:  
2025-01-08 20:15:28.882289: Epoch 102 
2025-01-08 20:15:28.887365: Current learning rate: 0.00624 
2025-01-08 20:16:05.290525: train_loss -0.1242 
2025-01-08 20:16:05.291090: val_loss -0.2139 
2025-01-08 20:16:05.298126: Pseudo dice [np.float32(0.8654), np.float32(0.6493)] 
2025-01-08 20:16:05.302635: Epoch time: 36.41 s 
2025-01-08 20:16:05.307647: Yayy! New best EMA pseudo Dice: 0.6255999803543091 
2025-01-08 20:16:05.980123:  
2025-01-08 20:16:05.980123: Epoch 103 
2025-01-08 20:16:05.985794: Current learning rate: 0.0062 
2025-01-08 20:16:42.394035: train_loss -0.1159 
2025-01-08 20:16:42.394538: val_loss -0.1703 
2025-01-08 20:16:42.400139: Pseudo dice [np.float32(0.8763), np.float32(0.2556)] 
2025-01-08 20:16:42.403227: Epoch time: 36.41 s 
2025-01-08 20:16:42.933402:  
2025-01-08 20:16:42.934405: Epoch 104 
2025-01-08 20:16:42.939454: Current learning rate: 0.00616 
2025-01-08 20:17:19.435441: train_loss -0.1629 
2025-01-08 20:17:19.436447: val_loss -0.1521 
2025-01-08 20:17:19.442460: Pseudo dice [np.float32(0.8014), np.float32(0.2694)] 
2025-01-08 20:17:19.445468: Epoch time: 36.5 s 
2025-01-08 20:17:19.985696:  
2025-01-08 20:17:19.986199: Epoch 105 
2025-01-08 20:17:19.992217: Current learning rate: 0.00612 
2025-01-08 20:17:56.395935: train_loss -0.1705 
2025-01-08 20:17:56.396437: val_loss -0.1863 
2025-01-08 20:17:56.403455: Pseudo dice [np.float32(0.8474), np.float32(0.4805)] 
2025-01-08 20:17:56.407569: Epoch time: 36.41 s 
2025-01-08 20:17:57.102525:  
2025-01-08 20:17:57.135048: Epoch 106 
2025-01-08 20:17:57.138561: Current learning rate: 0.00609 
2025-01-08 20:18:33.551547: train_loss -0.1358 
2025-01-08 20:18:33.551547: val_loss -0.1626 
2025-01-08 20:18:33.558069: Pseudo dice [np.float32(0.8819), np.float32(0.3242)] 
2025-01-08 20:18:33.561577: Epoch time: 36.45 s 
2025-01-08 20:18:34.090369:  
2025-01-08 20:18:34.090369: Epoch 107 
2025-01-08 20:18:34.095981: Current learning rate: 0.00605 
2025-01-08 20:19:10.484288: train_loss -0.1327 
2025-01-08 20:19:10.484288: val_loss -0.1594 
2025-01-08 20:19:10.491309: Pseudo dice [np.float32(0.8787), np.float32(0.4007)] 
2025-01-08 20:19:10.495329: Epoch time: 36.39 s 
2025-01-08 20:19:11.022199:  
2025-01-08 20:19:11.023226: Epoch 108 
2025-01-08 20:19:11.028292: Current learning rate: 0.00601 
2025-01-08 20:19:47.434749: train_loss -0.1519 
2025-01-08 20:19:47.434749: val_loss -0.1135 
2025-01-08 20:19:47.442351: Pseudo dice [np.float32(0.8037), np.float32(0.2436)] 
2025-01-08 20:19:47.447486: Epoch time: 36.41 s 
2025-01-08 20:19:47.976805:  
2025-01-08 20:19:47.976805: Epoch 109 
2025-01-08 20:19:47.982348: Current learning rate: 0.00597 
2025-01-08 20:20:24.386101: train_loss -0.1831 
2025-01-08 20:20:24.387125: val_loss -0.2567 
2025-01-08 20:20:24.394198: Pseudo dice [np.float32(0.8649), np.float32(0.483)] 
2025-01-08 20:20:24.400812: Epoch time: 36.41 s 
2025-01-08 20:20:24.928702:  
2025-01-08 20:20:24.928702: Epoch 110 
2025-01-08 20:20:24.934772: Current learning rate: 0.00593 
2025-01-08 20:21:01.348276: train_loss -0.1284 
2025-01-08 20:21:01.348276: val_loss -0.2083 
2025-01-08 20:21:01.356013: Pseudo dice [np.float32(0.8263), np.float32(0.5019)] 
2025-01-08 20:21:01.361131: Epoch time: 36.42 s 
2025-01-08 20:21:01.888994:  
2025-01-08 20:21:01.890000: Epoch 111 
2025-01-08 20:21:01.895127: Current learning rate: 0.0059 
2025-01-08 20:21:38.336696: train_loss -0.158 
2025-01-08 20:21:38.337219: val_loss -0.194 
2025-01-08 20:21:38.343354: Pseudo dice [np.float32(0.8612), np.float32(0.4933)] 
2025-01-08 20:21:38.346877: Epoch time: 36.45 s 
2025-01-08 20:21:38.863421:  
2025-01-08 20:21:38.863421: Epoch 112 
2025-01-08 20:21:38.869436: Current learning rate: 0.00586 
2025-01-08 20:22:15.269624: train_loss -0.1629 
2025-01-08 20:22:15.270641: val_loss -0.1848 
2025-01-08 20:22:15.277258: Pseudo dice [np.float32(0.862), np.float32(0.3257)] 
2025-01-08 20:22:15.280318: Epoch time: 36.41 s 
2025-01-08 20:22:15.802885:  
2025-01-08 20:22:15.802885: Epoch 113 
2025-01-08 20:22:15.808437: Current learning rate: 0.00582 
2025-01-08 20:22:52.197081: train_loss -0.1788 
2025-01-08 20:22:52.198084: val_loss -0.2164 
2025-01-08 20:22:52.204157: Pseudo dice [np.float32(0.8777), np.float32(0.4074)] 
2025-01-08 20:22:52.207170: Epoch time: 36.4 s 
2025-01-08 20:22:52.899933:  
2025-01-08 20:22:52.899933: Epoch 114 
2025-01-08 20:22:52.905454: Current learning rate: 0.00578 
2025-01-08 20:23:29.299512: train_loss -0.1169 
2025-01-08 20:23:29.300016: val_loss -0.1134 
2025-01-08 20:23:29.307547: Pseudo dice [np.float32(0.8196), np.float32(0.3754)] 
2025-01-08 20:23:29.313569: Epoch time: 36.4 s 
2025-01-08 20:23:29.847667:  
2025-01-08 20:23:29.847667: Epoch 115 
2025-01-08 20:23:29.853230: Current learning rate: 0.00574 
2025-01-08 20:24:06.267324: train_loss -0.1526 
2025-01-08 20:24:06.268326: val_loss -0.1732 
2025-01-08 20:24:06.274337: Pseudo dice [np.float32(0.8824), np.float32(0.3198)] 
2025-01-08 20:24:06.277345: Epoch time: 36.42 s 
2025-01-08 20:24:06.807769:  
2025-01-08 20:24:06.807769: Epoch 116 
2025-01-08 20:24:06.814817: Current learning rate: 0.0057 
2025-01-08 20:24:43.189130: train_loss -0.1369 
2025-01-08 20:24:43.189767: val_loss -0.1914 
2025-01-08 20:24:43.196295: Pseudo dice [np.float32(0.8763), np.float32(0.5246)] 
2025-01-08 20:24:43.200317: Epoch time: 36.38 s 
2025-01-08 20:24:43.202822: Yayy! New best EMA pseudo Dice: 0.6276999711990356 
2025-01-08 20:24:43.868187:  
2025-01-08 20:24:43.868187: Epoch 117 
2025-01-08 20:24:43.874234: Current learning rate: 0.00567 
2025-01-08 20:25:20.246913: train_loss -0.1617 
2025-01-08 20:25:20.247415: val_loss -0.2192 
2025-01-08 20:25:20.253431: Pseudo dice [np.float32(0.8954), np.float32(0.4315)] 
2025-01-08 20:25:20.256936: Epoch time: 36.38 s 
2025-01-08 20:25:20.260480: Yayy! New best EMA pseudo Dice: 0.6312000155448914 
2025-01-08 20:25:20.941455:  
2025-01-08 20:25:20.942455: Epoch 118 
2025-01-08 20:25:20.948047: Current learning rate: 0.00563 
2025-01-08 20:25:57.477805: train_loss -0.1969 
2025-01-08 20:25:57.478309: val_loss -0.1231 
2025-01-08 20:25:57.488622: Pseudo dice [np.float32(0.802), np.float32(0.2525)] 
2025-01-08 20:25:57.493687: Epoch time: 36.54 s 
2025-01-08 20:25:58.029814:  
2025-01-08 20:25:58.029814: Epoch 119 
2025-01-08 20:25:58.035973: Current learning rate: 0.00559 
2025-01-08 20:26:34.430325: train_loss -0.1955 
2025-01-08 20:26:34.431330: val_loss -0.1954 
2025-01-08 20:26:34.437844: Pseudo dice [np.float32(0.8378), np.float32(0.3905)] 
2025-01-08 20:26:34.442357: Epoch time: 36.4 s 
2025-01-08 20:26:34.981442:  
2025-01-08 20:26:34.981946: Epoch 120 
2025-01-08 20:26:34.986959: Current learning rate: 0.00555 
2025-01-08 20:27:11.390035: train_loss -0.1684 
2025-01-08 20:27:11.390035: val_loss -0.1816 
2025-01-08 20:27:11.398554: Pseudo dice [np.float32(0.8566), np.float32(0.3917)] 
2025-01-08 20:27:11.402562: Epoch time: 36.41 s 
2025-01-08 20:27:11.930904:  
2025-01-08 20:27:11.932408: Epoch 121 
2025-01-08 20:27:11.937496: Current learning rate: 0.00551 
2025-01-08 20:27:48.343441: train_loss -0.177 
2025-01-08 20:27:48.344445: val_loss -0.1887 
2025-01-08 20:27:48.350960: Pseudo dice [np.float32(0.8835), np.float32(0.4591)] 
2025-01-08 20:27:48.354476: Epoch time: 36.41 s 
2025-01-08 20:27:49.052675:  
2025-01-08 20:27:49.053177: Epoch 122 
2025-01-08 20:27:49.058244: Current learning rate: 0.00547 
2025-01-08 20:28:25.493921: train_loss -0.1753 
2025-01-08 20:28:25.495429: val_loss -0.1656 
2025-01-08 20:28:25.500462: Pseudo dice [np.float32(0.7948), np.float32(0.2666)] 
2025-01-08 20:28:25.505080: Epoch time: 36.44 s 
2025-01-08 20:28:26.039136:  
2025-01-08 20:28:26.039136: Epoch 123 
2025-01-08 20:28:26.045147: Current learning rate: 0.00544 
2025-01-08 20:29:02.499150: train_loss -0.1959 
2025-01-08 20:29:02.499150: val_loss -0.2142 
2025-01-08 20:29:02.505670: Pseudo dice [np.float32(0.8573), np.float32(0.5778)] 
2025-01-08 20:29:02.509179: Epoch time: 36.46 s 
2025-01-08 20:29:03.044192:  
2025-01-08 20:29:03.044192: Epoch 124 
2025-01-08 20:29:03.050213: Current learning rate: 0.0054 
2025-01-08 20:29:39.487161: train_loss -0.1655 
2025-01-08 20:29:39.488165: val_loss -0.2238 
2025-01-08 20:29:39.494681: Pseudo dice [np.float32(0.8751), np.float32(0.5542)] 
2025-01-08 20:29:39.500698: Epoch time: 36.44 s 
2025-01-08 20:29:39.505712: Yayy! New best EMA pseudo Dice: 0.6351000070571899 
2025-01-08 20:29:40.208369:  
2025-01-08 20:29:40.208875: Epoch 125 
2025-01-08 20:29:40.213887: Current learning rate: 0.00536 
2025-01-08 20:30:16.593957: train_loss -0.1761 
2025-01-08 20:30:16.594956: val_loss -0.1467 
2025-01-08 20:30:16.601474: Pseudo dice [np.float32(0.7965), np.float32(0.313)] 
2025-01-08 20:30:16.605506: Epoch time: 36.39 s 
2025-01-08 20:30:17.132816:  
2025-01-08 20:30:17.133318: Epoch 126 
2025-01-08 20:30:17.138329: Current learning rate: 0.00532 
2025-01-08 20:30:53.617177: train_loss -0.1494 
2025-01-08 20:30:53.617177: val_loss -0.0989 
2025-01-08 20:30:53.625700: Pseudo dice [np.float32(0.6894), np.float32(0.207)] 
2025-01-08 20:30:53.632224: Epoch time: 36.49 s 
2025-01-08 20:30:54.163021:  
2025-01-08 20:30:54.163021: Epoch 127 
2025-01-08 20:30:54.169114: Current learning rate: 0.00528 
2025-01-08 20:31:30.547176: train_loss -0.1829 
2025-01-08 20:31:30.548681: val_loss -0.2144 
2025-01-08 20:31:30.555700: Pseudo dice [np.float32(0.903), np.float32(0.4318)] 
2025-01-08 20:31:30.559221: Epoch time: 36.39 s 
2025-01-08 20:31:31.093968:  
2025-01-08 20:31:31.093968: Epoch 128 
2025-01-08 20:31:31.099991: Current learning rate: 0.00524 
2025-01-08 20:32:07.496732: train_loss -0.1453 
2025-01-08 20:32:07.498236: val_loss -0.1366 
2025-01-08 20:32:07.504255: Pseudo dice [np.float32(0.8504), np.float32(0.2303)] 
2025-01-08 20:32:07.510270: Epoch time: 36.4 s 
2025-01-08 20:32:08.045669:  
2025-01-08 20:32:08.045669: Epoch 129 
2025-01-08 20:32:08.051683: Current learning rate: 0.0052 
2025-01-08 20:32:44.459778: train_loss -0.1728 
2025-01-08 20:32:44.460781: val_loss -0.1803 
2025-01-08 20:32:44.466350: Pseudo dice [np.float32(0.8883), np.float32(0.4233)] 
2025-01-08 20:32:44.470438: Epoch time: 36.41 s 
2025-01-08 20:32:45.159752:  
2025-01-08 20:32:45.160755: Epoch 130 
2025-01-08 20:32:45.166341: Current learning rate: 0.00517 
2025-01-08 20:33:21.557496: train_loss -0.1709 
2025-01-08 20:33:21.557999: val_loss -0.2055 
2025-01-08 20:33:21.565514: Pseudo dice [np.float32(0.8599), np.float32(0.3984)] 
2025-01-08 20:33:21.571551: Epoch time: 36.4 s 
2025-01-08 20:33:22.116376:  
2025-01-08 20:33:22.116376: Epoch 131 
2025-01-08 20:33:22.121963: Current learning rate: 0.00513 
2025-01-08 20:33:58.497510: train_loss -0.1712 
2025-01-08 20:33:58.498018: val_loss -0.2079 
2025-01-08 20:33:58.504068: Pseudo dice [np.float32(0.882), np.float32(0.3807)] 
2025-01-08 20:33:58.507199: Epoch time: 36.38 s 
2025-01-08 20:33:59.042810:  
2025-01-08 20:33:59.043810: Epoch 132 
2025-01-08 20:33:59.048875: Current learning rate: 0.00509 
2025-01-08 20:34:35.417202: train_loss -0.1506 
2025-01-08 20:34:35.418203: val_loss -0.1798 
2025-01-08 20:34:35.424754: Pseudo dice [np.float32(0.8989), np.float32(0.5503)] 
2025-01-08 20:34:35.428766: Epoch time: 36.37 s 
2025-01-08 20:34:35.966954:  
2025-01-08 20:34:35.967957: Epoch 133 
2025-01-08 20:34:35.972493: Current learning rate: 0.00505 
2025-01-08 20:35:12.383878: train_loss -0.1799 
2025-01-08 20:35:12.384883: val_loss -0.1151 
2025-01-08 20:35:12.390477: Pseudo dice [np.float32(0.8688), np.float32(0.3725)] 
2025-01-08 20:35:12.394598: Epoch time: 36.42 s 
2025-01-08 20:35:12.930307:  
2025-01-08 20:35:12.930307: Epoch 134 
2025-01-08 20:35:12.935819: Current learning rate: 0.00501 
2025-01-08 20:35:49.345062: train_loss -0.1956 
2025-01-08 20:35:49.346067: val_loss -0.2137 
2025-01-08 20:35:49.353217: Pseudo dice [np.float32(0.9209), np.float32(0.475)] 
2025-01-08 20:35:49.358094: Epoch time: 36.42 s 
2025-01-08 20:35:49.896930:  
2025-01-08 20:35:49.897440: Epoch 135 
2025-01-08 20:35:49.903066: Current learning rate: 0.00497 
2025-01-08 20:36:26.332519: train_loss -0.1757 
2025-01-08 20:36:26.332519: val_loss -0.1685 
2025-01-08 20:36:26.340035: Pseudo dice [np.float32(0.8512), np.float32(0.5059)] 
2025-01-08 20:36:26.343544: Epoch time: 36.44 s 
2025-01-08 20:36:26.347557: Yayy! New best EMA pseudo Dice: 0.6377999782562256 
2025-01-08 20:36:27.030449:  
2025-01-08 20:36:27.030449: Epoch 136 
2025-01-08 20:36:27.036033: Current learning rate: 0.00493 
2025-01-08 20:37:03.464195: train_loss -0.1799 
2025-01-08 20:37:03.464195: val_loss -0.2228 
2025-01-08 20:37:03.470222: Pseudo dice [np.float32(0.9149), np.float32(0.544)] 
2025-01-08 20:37:03.474231: Epoch time: 36.43 s 
2025-01-08 20:37:03.476738: Yayy! New best EMA pseudo Dice: 0.6468999981880188 
2025-01-08 20:37:04.180335:  
2025-01-08 20:37:04.181335: Epoch 137 
2025-01-08 20:37:04.186910: Current learning rate: 0.00489 
2025-01-08 20:37:40.613117: train_loss -0.1842 
2025-01-08 20:37:40.614116: val_loss -0.1957 
2025-01-08 20:37:40.620631: Pseudo dice [np.float32(0.9093), np.float32(0.5284)] 
2025-01-08 20:37:40.625646: Epoch time: 36.43 s 
2025-01-08 20:37:40.629655: Yayy! New best EMA pseudo Dice: 0.6541000008583069 
2025-01-08 20:37:41.491045:  
2025-01-08 20:37:41.491546: Epoch 138 
2025-01-08 20:37:41.497559: Current learning rate: 0.00485 
2025-01-08 20:38:17.989407: train_loss -0.1787 
2025-01-08 20:38:17.990911: val_loss -0.2087 
2025-01-08 20:38:17.998430: Pseudo dice [np.float32(0.8448), np.float32(0.581)] 
2025-01-08 20:38:18.003441: Epoch time: 36.5 s 
2025-01-08 20:38:18.007951: Yayy! New best EMA pseudo Dice: 0.6600000262260437 
2025-01-08 20:38:18.697606:  
2025-01-08 20:38:18.697606: Epoch 139 
2025-01-08 20:38:18.703147: Current learning rate: 0.00482 
2025-01-08 20:38:55.105143: train_loss -0.1713 
2025-01-08 20:38:55.106146: val_loss -0.163 
2025-01-08 20:38:55.112661: Pseudo dice [np.float32(0.8587), np.float32(0.4108)] 
2025-01-08 20:38:55.117181: Epoch time: 36.41 s 
2025-01-08 20:38:55.663294:  
2025-01-08 20:38:55.663294: Epoch 140 
2025-01-08 20:38:55.670326: Current learning rate: 0.00478 
2025-01-08 20:39:32.084391: train_loss -0.1795 
2025-01-08 20:39:32.084893: val_loss -0.1281 
2025-01-08 20:39:32.091946: Pseudo dice [np.float32(0.869), np.float32(0.5479)] 
2025-01-08 20:39:32.098461: Epoch time: 36.42 s 
2025-01-08 20:39:32.102471: Yayy! New best EMA pseudo Dice: 0.6625999808311462 
2025-01-08 20:39:32.786471:  
2025-01-08 20:39:32.787471: Epoch 141 
2025-01-08 20:39:32.793025: Current learning rate: 0.00474 
2025-01-08 20:40:09.213222: train_loss -0.1476 
2025-01-08 20:40:09.213222: val_loss -0.1705 
2025-01-08 20:40:09.221794: Pseudo dice [np.float32(0.9208), np.float32(0.3243)] 
2025-01-08 20:40:09.228495: Epoch time: 36.43 s 
2025-01-08 20:40:09.771154:  
2025-01-08 20:40:09.771657: Epoch 142 
2025-01-08 20:40:09.777674: Current learning rate: 0.0047 
2025-01-08 20:40:46.207636: train_loss -0.1892 
2025-01-08 20:40:46.207636: val_loss -0.1359 
2025-01-08 20:40:46.215151: Pseudo dice [np.float32(0.7675), np.float32(0.4726)] 
2025-01-08 20:40:46.221163: Epoch time: 36.44 s 
2025-01-08 20:40:46.766899:  
2025-01-08 20:40:46.767410: Epoch 143 
2025-01-08 20:40:46.772977: Current learning rate: 0.00466 
2025-01-08 20:41:23.167129: train_loss -0.1396 
2025-01-08 20:41:23.168133: val_loss -0.1538 
2025-01-08 20:41:23.175658: Pseudo dice [np.float32(0.8528), np.float32(0.2629)] 
2025-01-08 20:41:23.180964: Epoch time: 36.4 s 
2025-01-08 20:41:23.721572:  
2025-01-08 20:41:23.722572: Epoch 144 
2025-01-08 20:41:23.728599: Current learning rate: 0.00462 
2025-01-08 20:42:00.130160: train_loss -0.2079 
2025-01-08 20:42:00.132309: val_loss -0.17 
2025-01-08 20:42:00.140354: Pseudo dice [np.float32(0.8041), np.float32(0.4516)] 
2025-01-08 20:42:00.147881: Epoch time: 36.41 s 
2025-01-08 20:42:00.847342:  
2025-01-08 20:42:00.847342: Epoch 145 
2025-01-08 20:42:00.853354: Current learning rate: 0.00458 
2025-01-08 20:42:37.337528: train_loss -0.1735 
2025-01-08 20:42:37.338042: val_loss -0.2015 
2025-01-08 20:42:37.344085: Pseudo dice [np.float32(0.8892), np.float32(0.4562)] 
2025-01-08 20:42:37.347589: Epoch time: 36.49 s 
2025-01-08 20:42:37.891148:  
2025-01-08 20:42:37.892149: Epoch 146 
2025-01-08 20:42:37.897727: Current learning rate: 0.00454 
2025-01-08 20:43:14.290602: train_loss -0.1392 
2025-01-08 20:43:14.290602: val_loss -0.2483 
2025-01-08 20:43:14.299135: Pseudo dice [np.float32(0.8841), np.float32(0.5651)] 
2025-01-08 20:43:14.304802: Epoch time: 36.4 s 
2025-01-08 20:43:14.853213:  
2025-01-08 20:43:14.853213: Epoch 147 
2025-01-08 20:43:14.860230: Current learning rate: 0.0045 
2025-01-08 20:43:51.270858: train_loss -0.1817 
2025-01-08 20:43:51.272362: val_loss -0.1872 
2025-01-08 20:43:51.279880: Pseudo dice [np.float32(0.8545), np.float32(0.4503)] 
2025-01-08 20:43:51.285911: Epoch time: 36.42 s 
2025-01-08 20:43:51.830665:  
2025-01-08 20:43:51.830665: Epoch 148 
2025-01-08 20:43:51.837217: Current learning rate: 0.00446 
2025-01-08 20:44:28.252967: train_loss -0.187 
2025-01-08 20:44:28.253967: val_loss -0.2392 
2025-01-08 20:44:28.260480: Pseudo dice [np.float32(0.8999), np.float32(0.3706)] 
2025-01-08 20:44:28.266494: Epoch time: 36.42 s 
2025-01-08 20:44:28.808671:  
2025-01-08 20:44:28.808671: Epoch 149 
2025-01-08 20:44:28.815732: Current learning rate: 0.00442 
2025-01-08 20:45:05.219193: train_loss -0.185 
2025-01-08 20:45:05.219695: val_loss -0.2188 
2025-01-08 20:45:05.226715: Pseudo dice [np.float32(0.9158), np.float32(0.3215)] 
2025-01-08 20:45:05.231731: Epoch time: 36.41 s 
2025-01-08 20:45:05.924367:  
2025-01-08 20:45:05.924367: Epoch 150 
2025-01-08 20:45:05.930966: Current learning rate: 0.00438 
2025-01-08 20:45:48.161958: train_loss -0.2125 
2025-01-08 20:45:48.161958: val_loss -0.2333 
2025-01-08 20:45:48.169128: Pseudo dice [np.float32(0.8925), np.float32(0.5704)] 
2025-01-08 20:45:48.174209: Epoch time: 42.24 s 
2025-01-08 20:45:48.718198:  
2025-01-08 20:45:48.718198: Epoch 151 
2025-01-08 20:45:48.724215: Current learning rate: 0.00434 
2025-01-08 20:46:26.148048: train_loss -0.1651 
2025-01-08 20:46:26.148048: val_loss -0.1729 
2025-01-08 20:46:26.156575: Pseudo dice [np.float32(0.845), np.float32(0.255)] 
2025-01-08 20:46:26.166104: Epoch time: 37.43 s 
2025-01-08 20:46:26.728224:  
2025-01-08 20:46:26.728224: Epoch 152 
2025-01-08 20:46:26.734777: Current learning rate: 0.0043 
2025-01-08 20:47:04.193571: train_loss -0.1601 
2025-01-08 20:47:04.194073: val_loss -0.2018 
2025-01-08 20:47:04.201593: Pseudo dice [np.float32(0.8805), np.float32(0.3696)] 
2025-01-08 20:47:04.206611: Epoch time: 37.47 s 
2025-01-08 20:47:04.909609:  
2025-01-08 20:47:04.909609: Epoch 153 
2025-01-08 20:47:04.916180: Current learning rate: 0.00427 
2025-01-08 20:47:42.390054: train_loss -0.1963 
2025-01-08 20:47:42.390567: val_loss -0.2438 
2025-01-08 20:47:42.397661: Pseudo dice [np.float32(0.8826), np.float32(0.3073)] 
2025-01-08 20:47:42.402838: Epoch time: 37.48 s 
2025-01-08 20:47:42.957705:  
2025-01-08 20:47:42.958709: Epoch 154 
2025-01-08 20:47:42.965259: Current learning rate: 0.00423 
2025-01-08 20:48:20.530861: train_loss -0.1718 
2025-01-08 20:48:20.531371: val_loss -0.2667 
2025-01-08 20:48:20.538511: Pseudo dice [np.float32(0.9358), np.float32(0.4173)] 
2025-01-08 20:48:20.543070: Epoch time: 37.57 s 
2025-01-08 20:48:21.103562:  
2025-01-08 20:48:21.104073: Epoch 155 
2025-01-08 20:48:21.110198: Current learning rate: 0.00419 
2025-01-08 20:48:58.544599: train_loss -0.185 
2025-01-08 20:48:58.545102: val_loss -0.2636 
2025-01-08 20:48:58.552361: Pseudo dice [np.float32(0.8982), np.float32(0.2545)] 
2025-01-08 20:48:58.557406: Epoch time: 37.44 s 
2025-01-08 20:48:59.116918:  
2025-01-08 20:48:59.116918: Epoch 156 
2025-01-08 20:48:59.122934: Current learning rate: 0.00415 
2025-01-08 20:49:36.555014: train_loss -0.2029 
2025-01-08 20:49:36.555014: val_loss -0.1819 
2025-01-08 20:49:36.562836: Pseudo dice [np.float32(0.8852), np.float32(0.3275)] 
2025-01-08 20:49:36.568850: Epoch time: 37.44 s 
2025-01-08 20:49:37.120166:  
2025-01-08 20:49:37.120166: Epoch 157 
2025-01-08 20:49:37.126729: Current learning rate: 0.00411 
2025-01-08 20:50:14.563021: train_loss -0.1902 
2025-01-08 20:50:14.563524: val_loss -0.2274 
2025-01-08 20:50:14.569543: Pseudo dice [np.float32(0.9112), np.float32(0.4809)] 
2025-01-08 20:50:14.574559: Epoch time: 37.44 s 
2025-01-08 20:50:15.125115:  
2025-01-08 20:50:15.126119: Epoch 158 
2025-01-08 20:50:15.131732: Current learning rate: 0.00407 
2025-01-08 20:50:52.568106: train_loss -0.1746 
2025-01-08 20:50:52.569110: val_loss -0.2439 
2025-01-08 20:50:52.575632: Pseudo dice [np.float32(0.8611), np.float32(0.4863)] 
2025-01-08 20:50:52.580149: Epoch time: 37.44 s 
2025-01-08 20:50:53.140296:  
2025-01-08 20:50:53.141296: Epoch 159 
2025-01-08 20:50:53.146819: Current learning rate: 0.00403 
2025-01-08 20:51:30.581520: train_loss -0.1641 
2025-01-08 20:51:30.581520: val_loss -0.1761 
2025-01-08 20:51:30.589034: Pseudo dice [np.float32(0.8802), np.float32(0.5707)] 
2025-01-08 20:51:30.593652: Epoch time: 37.44 s 
2025-01-08 20:51:31.308014:  
2025-01-08 20:51:31.308014: Epoch 160 
2025-01-08 20:51:31.314032: Current learning rate: 0.00399 
2025-01-08 20:52:08.735640: train_loss -0.1679 
2025-01-08 20:52:08.736147: val_loss -0.1836 
2025-01-08 20:52:08.743840: Pseudo dice [np.float32(0.8954), np.float32(0.1263)] 
2025-01-08 20:52:08.747379: Epoch time: 37.43 s 
2025-01-08 20:52:09.300206:  
2025-01-08 20:52:09.300709: Epoch 161 
2025-01-08 20:52:09.305728: Current learning rate: 0.00395 
2025-01-08 20:52:46.805151: train_loss -0.2072 
2025-01-08 20:52:46.806669: val_loss -0.2395 
2025-01-08 20:52:46.813277: Pseudo dice [np.float32(0.8709), np.float32(0.2363)] 
2025-01-08 20:52:46.817345: Epoch time: 37.51 s 
2025-01-08 20:52:47.364585:  
2025-01-08 20:52:47.365092: Epoch 162 
2025-01-08 20:52:47.370687: Current learning rate: 0.00391 
2025-01-08 20:53:24.771221: train_loss -0.1974 
2025-01-08 20:53:24.772224: val_loss -0.2131 
2025-01-08 20:53:24.778791: Pseudo dice [np.float32(0.833), np.float32(0.4909)] 
2025-01-08 20:53:24.783330: Epoch time: 37.41 s 
2025-01-08 20:53:25.337626:  
2025-01-08 20:53:25.337626: Epoch 163 
2025-01-08 20:53:25.343641: Current learning rate: 0.00387 
2025-01-08 20:54:02.779112: train_loss -0.1892 
2025-01-08 20:54:02.779112: val_loss -0.209 
2025-01-08 20:54:02.786638: Pseudo dice [np.float32(0.9185), np.float32(0.7166)] 
2025-01-08 20:54:02.791656: Epoch time: 37.44 s 
2025-01-08 20:54:03.343130:  
2025-01-08 20:54:03.343130: Epoch 164 
2025-01-08 20:54:03.349199: Current learning rate: 0.00383 
2025-01-08 20:54:40.764116: train_loss -0.2051 
2025-01-08 20:54:40.765121: val_loss -0.197 
2025-01-08 20:54:40.773173: Pseudo dice [np.float32(0.8976), np.float32(0.4643)] 
2025-01-08 20:54:40.779293: Epoch time: 37.42 s 
2025-01-08 20:54:41.315153:  
2025-01-08 20:54:41.316157: Epoch 165 
2025-01-08 20:54:41.320727: Current learning rate: 0.00379 
2025-01-08 20:55:18.458411: train_loss -0.2096 
2025-01-08 20:55:18.459414: val_loss -0.2112 
2025-01-08 20:55:18.466469: Pseudo dice [np.float32(0.8673), np.float32(0.619)] 
2025-01-08 20:55:18.472005: Epoch time: 37.14 s 
2025-01-08 20:55:18.476012: Yayy! New best EMA pseudo Dice: 0.6626999974250793 
2025-01-08 20:55:19.174692:  
2025-01-08 20:55:19.175697: Epoch 166 
2025-01-08 20:55:19.181397: Current learning rate: 0.00375 
2025-01-08 20:55:55.587961: train_loss -0.1916 
2025-01-08 20:55:55.588463: val_loss -0.2604 
2025-01-08 20:55:55.594478: Pseudo dice [np.float32(0.9147), np.float32(0.4376)] 
2025-01-08 20:55:55.598487: Epoch time: 36.41 s 
2025-01-08 20:55:55.601995: Yayy! New best EMA pseudo Dice: 0.6639999747276306 
2025-01-08 20:55:56.293699:  
2025-01-08 20:55:56.293699: Epoch 167 
2025-01-08 20:55:56.300271: Current learning rate: 0.00371 
2025-01-08 20:56:32.725375: train_loss -0.1638 
2025-01-08 20:56:32.725375: val_loss -0.1711 
2025-01-08 20:56:32.735450: Pseudo dice [np.float32(0.8593), np.float32(0.5333)] 
2025-01-08 20:56:32.739139: Epoch time: 36.43 s 
2025-01-08 20:56:32.742662: Yayy! New best EMA pseudo Dice: 0.6672000288963318 
2025-01-08 20:56:33.662333:  
2025-01-08 20:56:33.662333: Epoch 168 
2025-01-08 20:56:33.667861: Current learning rate: 0.00367 
2025-01-08 20:57:10.067172: train_loss -0.2174 
2025-01-08 20:57:10.067678: val_loss -0.208 
2025-01-08 20:57:10.073692: Pseudo dice [np.float32(0.8956), np.float32(0.4781)] 
2025-01-08 20:57:10.077700: Epoch time: 36.41 s 
2025-01-08 20:57:10.083726: Yayy! New best EMA pseudo Dice: 0.6692000031471252 
2025-01-08 20:57:10.773215:  
2025-01-08 20:57:10.773215: Epoch 169 
2025-01-08 20:57:10.778226: Current learning rate: 0.00363 
2025-01-08 20:57:47.235489: train_loss -0.1949 
2025-01-08 20:57:47.236489: val_loss -0.1831 
2025-01-08 20:57:47.242007: Pseudo dice [np.float32(0.8843), np.float32(0.4539)] 
2025-01-08 20:57:47.246549: Epoch time: 36.46 s 
2025-01-08 20:57:47.791635:  
2025-01-08 20:57:47.791635: Epoch 170 
2025-01-08 20:57:47.797205: Current learning rate: 0.00359 
2025-01-08 20:58:24.212443: train_loss -0.1852 
2025-01-08 20:58:24.212950: val_loss -0.2248 
2025-01-08 20:58:24.220014: Pseudo dice [np.float32(0.869), np.float32(0.6176)] 
2025-01-08 20:58:24.224574: Epoch time: 36.42 s 
2025-01-08 20:58:24.228118: Yayy! New best EMA pseudo Dice: 0.6765999794006348 
2025-01-08 20:58:24.922630:  
2025-01-08 20:58:24.922630: Epoch 171 
2025-01-08 20:58:24.928146: Current learning rate: 0.00355 
2025-01-08 20:59:01.326686: train_loss -0.2097 
2025-01-08 20:59:01.326686: val_loss -0.1522 
2025-01-08 20:59:01.333771: Pseudo dice [np.float32(0.9178), np.float32(0.5661)] 
2025-01-08 20:59:01.337816: Epoch time: 36.41 s 
2025-01-08 20:59:01.340492: Yayy! New best EMA pseudo Dice: 0.6830999851226807 
2025-01-08 20:59:02.043984:  
2025-01-08 20:59:02.044496: Epoch 172 
2025-01-08 20:59:02.049506: Current learning rate: 0.00351 
2025-01-08 20:59:38.433756: train_loss -0.2081 
2025-01-08 20:59:38.434760: val_loss -0.2467 
2025-01-08 20:59:38.442615: Pseudo dice [np.float32(0.9071), np.float32(0.3396)] 
2025-01-08 20:59:38.446629: Epoch time: 36.39 s 
2025-01-08 20:59:38.993569:  
2025-01-08 20:59:38.993914: Epoch 173 
2025-01-08 20:59:38.999097: Current learning rate: 0.00346 
2025-01-08 21:00:15.390859: train_loss -0.1856 
2025-01-08 21:00:15.390859: val_loss -0.2371 
2025-01-08 21:00:15.396448: Pseudo dice [np.float32(0.9052), np.float32(0.6825)] 
2025-01-08 21:00:15.401029: Epoch time: 36.4 s 
2025-01-08 21:00:15.404073: Yayy! New best EMA pseudo Dice: 0.6887999773025513 
2025-01-08 21:00:16.103422:  
2025-01-08 21:00:16.103925: Epoch 174 
2025-01-08 21:00:16.108437: Current learning rate: 0.00342 
2025-01-08 21:00:52.503999: train_loss -0.2043 
2025-01-08 21:00:52.503999: val_loss -0.1736 
2025-01-08 21:00:52.510017: Pseudo dice [np.float32(0.8927), np.float32(0.4165)] 
2025-01-08 21:00:52.514030: Epoch time: 36.4 s 
2025-01-08 21:00:53.057169:  
2025-01-08 21:00:53.057169: Epoch 175 
2025-01-08 21:00:53.062755: Current learning rate: 0.00338 
2025-01-08 21:01:29.465067: train_loss -0.1895 
2025-01-08 21:01:29.466068: val_loss -0.1611 
2025-01-08 21:01:29.472109: Pseudo dice [np.float32(0.9097), np.float32(0.4611)] 
2025-01-08 21:01:29.476680: Epoch time: 36.41 s 
2025-01-08 21:01:30.189363:  
2025-01-08 21:01:30.189363: Epoch 176 
2025-01-08 21:01:30.194992: Current learning rate: 0.00334 
2025-01-08 21:02:06.589421: train_loss -0.1694 
2025-01-08 21:02:06.589936: val_loss -0.1758 
2025-01-08 21:02:06.597214: Pseudo dice [np.float32(0.8697), np.float32(0.4435)] 
2025-01-08 21:02:06.602756: Epoch time: 36.4 s 
2025-01-08 21:02:07.149626:  
2025-01-08 21:02:07.149626: Epoch 177 
2025-01-08 21:02:07.155183: Current learning rate: 0.0033 
2025-01-08 21:02:43.528349: train_loss -0.1759 
2025-01-08 21:02:43.529859: val_loss -0.2477 
2025-01-08 21:02:43.535962: Pseudo dice [np.float32(0.8937), np.float32(0.682)] 
2025-01-08 21:02:43.540073: Epoch time: 36.38 s 
2025-01-08 21:02:43.543116: Yayy! New best EMA pseudo Dice: 0.6930999755859375 
2025-01-08 21:02:44.246388:  
2025-01-08 21:02:44.246388: Epoch 178 
2025-01-08 21:02:44.251412: Current learning rate: 0.00326 
2025-01-08 21:03:20.667689: train_loss -0.2216 
2025-01-08 21:03:20.668200: val_loss -0.2158 
2025-01-08 21:03:20.673817: Pseudo dice [np.float32(0.9069), np.float32(0.4849)] 
2025-01-08 21:03:20.677851: Epoch time: 36.42 s 
2025-01-08 21:03:20.681409: Yayy! New best EMA pseudo Dice: 0.6933000087738037 
2025-01-08 21:03:21.398100:  
2025-01-08 21:03:21.399100: Epoch 179 
2025-01-08 21:03:21.403163: Current learning rate: 0.00322 
2025-01-08 21:03:57.790084: train_loss -0.1802 
2025-01-08 21:03:57.791083: val_loss -0.1915 
2025-01-08 21:03:57.797601: Pseudo dice [np.float32(0.8829), np.float32(0.4822)] 
2025-01-08 21:03:57.804115: Epoch time: 36.39 s 
2025-01-08 21:03:58.350420:  
2025-01-08 21:03:58.350420: Epoch 180 
2025-01-08 21:03:58.356448: Current learning rate: 0.00318 
2025-01-08 21:04:34.742055: train_loss -0.1959 
2025-01-08 21:04:34.742560: val_loss -0.2754 
2025-01-08 21:04:34.749174: Pseudo dice [np.float32(0.9099), np.float32(0.5836)] 
2025-01-08 21:04:34.753188: Epoch time: 36.39 s 
2025-01-08 21:04:34.757699: Yayy! New best EMA pseudo Dice: 0.697700023651123 
2025-01-08 21:04:35.448783:  
2025-01-08 21:04:35.448783: Epoch 181 
2025-01-08 21:04:35.454298: Current learning rate: 0.00314 
2025-01-08 21:05:11.799819: train_loss -0.1873 
2025-01-08 21:05:11.800822: val_loss -0.1701 
2025-01-08 21:05:11.807340: Pseudo dice [np.float32(0.8239), np.float32(0.6659)] 
2025-01-08 21:05:11.812353: Epoch time: 36.35 s 
2025-01-08 21:05:11.815870: Yayy! New best EMA pseudo Dice: 0.7024000287055969 
2025-01-08 21:05:12.529240:  
2025-01-08 21:05:12.529240: Epoch 182 
2025-01-08 21:05:12.535268: Current learning rate: 0.0031 
2025-01-08 21:05:49.024005: train_loss -0.197 
2025-01-08 21:05:49.024516: val_loss -0.2101 
2025-01-08 21:05:49.031842: Pseudo dice [np.float32(0.8917), np.float32(0.6463)] 
2025-01-08 21:05:49.035352: Epoch time: 36.5 s 
2025-01-08 21:05:49.038858: Yayy! New best EMA pseudo Dice: 0.7091000080108643 
2025-01-08 21:05:49.905276:  
2025-01-08 21:05:49.905778: Epoch 183 
2025-01-08 21:05:49.910790: Current learning rate: 0.00306 
2025-01-08 21:06:26.296854: train_loss -0.2239 
2025-01-08 21:06:26.297855: val_loss -0.2066 
2025-01-08 21:06:26.303371: Pseudo dice [np.float32(0.8604), np.float32(0.5806)] 
2025-01-08 21:06:26.306884: Epoch time: 36.39 s 
2025-01-08 21:06:26.313396: Yayy! New best EMA pseudo Dice: 0.7102000117301941 
2025-01-08 21:06:27.018325:  
2025-01-08 21:06:27.018826: Epoch 184 
2025-01-08 21:06:27.023840: Current learning rate: 0.00302 
2025-01-08 21:07:03.390295: train_loss -0.2086 
2025-01-08 21:07:03.391298: val_loss -0.236 
2025-01-08 21:07:03.397394: Pseudo dice [np.float32(0.8911), np.float32(0.7351)] 
2025-01-08 21:07:03.400428: Epoch time: 36.37 s 
2025-01-08 21:07:03.403938: Yayy! New best EMA pseudo Dice: 0.7204999923706055 
2025-01-08 21:07:04.112813:  
2025-01-08 21:07:04.112813: Epoch 185 
2025-01-08 21:07:04.118214: Current learning rate: 0.00297 
2025-01-08 21:07:40.543597: train_loss -0.2033 
2025-01-08 21:07:40.544599: val_loss -0.2046 
2025-01-08 21:07:40.551120: Pseudo dice [np.float32(0.8708), np.float32(0.5216)] 
2025-01-08 21:07:40.555127: Epoch time: 36.43 s 
2025-01-08 21:07:41.100585:  
2025-01-08 21:07:41.101589: Epoch 186 
2025-01-08 21:07:41.106155: Current learning rate: 0.00293 
2025-01-08 21:08:17.478517: train_loss -0.1977 
2025-01-08 21:08:17.479521: val_loss -0.2119 
2025-01-08 21:08:17.487177: Pseudo dice [np.float32(0.9012), np.float32(0.6156)] 
2025-01-08 21:08:17.491211: Epoch time: 36.38 s 
2025-01-08 21:08:17.495260: Yayy! New best EMA pseudo Dice: 0.722100019454956 
2025-01-08 21:08:18.197127:  
2025-01-08 21:08:18.197127: Epoch 187 
2025-01-08 21:08:18.203181: Current learning rate: 0.00289 
2025-01-08 21:08:54.606713: train_loss -0.198 
2025-01-08 21:08:54.607218: val_loss -0.2383 
2025-01-08 21:08:54.613241: Pseudo dice [np.float32(0.8638), np.float32(0.5927)] 
2025-01-08 21:08:54.617252: Epoch time: 36.41 s 
2025-01-08 21:08:54.620763: Yayy! New best EMA pseudo Dice: 0.7226999998092651 
2025-01-08 21:08:55.315818:  
2025-01-08 21:08:55.316818: Epoch 188 
2025-01-08 21:08:55.321872: Current learning rate: 0.00285 
2025-01-08 21:09:31.707443: train_loss -0.2314 
2025-01-08 21:09:31.708459: val_loss -0.2322 
2025-01-08 21:09:31.715086: Pseudo dice [np.float32(0.8836), np.float32(0.4116)] 
2025-01-08 21:09:31.718729: Epoch time: 36.39 s 
2025-01-08 21:09:32.259535:  
2025-01-08 21:09:32.260038: Epoch 189 
2025-01-08 21:09:32.265052: Current learning rate: 0.00281 
2025-01-08 21:10:08.656281: train_loss -0.2204 
2025-01-08 21:10:08.656784: val_loss -0.2216 
2025-01-08 21:10:08.662359: Pseudo dice [np.float32(0.8676), np.float32(0.6053)] 
2025-01-08 21:10:08.665466: Epoch time: 36.4 s 
2025-01-08 21:10:09.210463:  
2025-01-08 21:10:09.211466: Epoch 190 
2025-01-08 21:10:09.216507: Current learning rate: 0.00277 
2025-01-08 21:10:45.710017: train_loss -0.2004 
2025-01-08 21:10:45.711520: val_loss -0.2124 
2025-01-08 21:10:45.717538: Pseudo dice [np.float32(0.9121), np.float32(0.7276)] 
2025-01-08 21:10:45.722549: Epoch time: 36.5 s 
2025-01-08 21:10:45.726563: Yayy! New best EMA pseudo Dice: 0.7275999784469604 
2025-01-08 21:10:46.418986:  
2025-01-08 21:10:46.419987: Epoch 191 
2025-01-08 21:10:46.425620: Current learning rate: 0.00273 
2025-01-08 21:11:22.802013: train_loss -0.1526 
2025-01-08 21:11:22.802013: val_loss -0.1851 
2025-01-08 21:11:22.808028: Pseudo dice [np.float32(0.8524), np.float32(0.5175)] 
2025-01-08 21:11:22.812040: Epoch time: 36.38 s 
2025-01-08 21:11:23.365944:  
2025-01-08 21:11:23.365944: Epoch 192 
2025-01-08 21:11:23.371496: Current learning rate: 0.00268 
2025-01-08 21:11:59.777039: train_loss -0.2054 
2025-01-08 21:11:59.777039: val_loss -0.2152 
2025-01-08 21:11:59.783058: Pseudo dice [np.float32(0.8201), np.float32(0.6502)] 
2025-01-08 21:11:59.788069: Epoch time: 36.41 s 
2025-01-08 21:12:00.347538:  
2025-01-08 21:12:00.347538: Epoch 193 
2025-01-08 21:12:00.353097: Current learning rate: 0.00264 
2025-01-08 21:12:36.731225: train_loss -0.1774 
2025-01-08 21:12:36.732230: val_loss -0.2487 
2025-01-08 21:12:36.740364: Pseudo dice [np.float32(0.892), np.float32(0.535)] 
2025-01-08 21:12:36.744982: Epoch time: 36.38 s 
2025-01-08 21:12:37.301814:  
2025-01-08 21:12:37.301814: Epoch 194 
2025-01-08 21:12:37.307364: Current learning rate: 0.0026 
2025-01-08 21:13:13.690082: train_loss -0.2162 
2025-01-08 21:13:13.690082: val_loss -0.2587 
2025-01-08 21:13:13.697154: Pseudo dice [np.float32(0.9203), np.float32(0.4908)] 
2025-01-08 21:13:13.701694: Epoch time: 36.39 s 
2025-01-08 21:13:14.253768:  
2025-01-08 21:13:14.253768: Epoch 195 
2025-01-08 21:13:14.259809: Current learning rate: 0.00256 
2025-01-08 21:13:50.668274: train_loss -0.2379 
2025-01-08 21:13:50.668274: val_loss -0.2357 
2025-01-08 21:13:50.675794: Pseudo dice [np.float32(0.8954), np.float32(0.5974)] 
2025-01-08 21:13:50.679307: Epoch time: 36.42 s 
2025-01-08 21:13:51.227386:  
2025-01-08 21:13:51.227386: Epoch 196 
2025-01-08 21:13:51.232926: Current learning rate: 0.00252 
2025-01-08 21:14:27.604844: train_loss -0.2267 
2025-01-08 21:14:27.605848: val_loss -0.2357 
2025-01-08 21:14:27.613367: Pseudo dice [np.float32(0.8602), np.float32(0.6755)] 
2025-01-08 21:14:27.619886: Epoch time: 36.38 s 
2025-01-08 21:14:27.624904: Yayy! New best EMA pseudo Dice: 0.7285000085830688 
2025-01-08 21:14:28.336460:  
2025-01-08 21:14:28.336460: Epoch 197 
2025-01-08 21:14:28.342003: Current learning rate: 0.00248 
2025-01-08 21:15:04.742141: train_loss -0.1774 
2025-01-08 21:15:04.742141: val_loss -0.1548 
2025-01-08 21:15:04.747797: Pseudo dice [np.float32(0.8452), np.float32(0.6481)] 
2025-01-08 21:15:04.753338: Epoch time: 36.41 s 
2025-01-08 21:15:04.757357: Yayy! New best EMA pseudo Dice: 0.7303000092506409 
2025-01-08 21:15:05.630084:  
2025-01-08 21:15:05.630084: Epoch 198 
2025-01-08 21:15:05.636097: Current learning rate: 0.00243 
2025-01-08 21:15:42.032331: train_loss -0.1909 
2025-01-08 21:15:42.033330: val_loss -0.1999 
2025-01-08 21:15:42.039850: Pseudo dice [np.float32(0.9095), np.float32(0.5705)] 
2025-01-08 21:15:42.043862: Epoch time: 36.4 s 
2025-01-08 21:15:42.048877: Yayy! New best EMA pseudo Dice: 0.7312999963760376 
2025-01-08 21:15:42.750503:  
2025-01-08 21:15:42.751508: Epoch 199 
2025-01-08 21:15:42.754535: Current learning rate: 0.00239 
2025-01-08 21:16:19.153667: train_loss -0.1969 
2025-01-08 21:16:19.153667: val_loss -0.1904 
2025-01-08 21:16:19.160729: Pseudo dice [np.float32(0.8716), np.float32(0.6619)] 
2025-01-08 21:16:19.164776: Epoch time: 36.4 s 
2025-01-08 21:16:19.325317: Yayy! New best EMA pseudo Dice: 0.7347999811172485 
2025-01-08 21:16:20.017344:  
2025-01-08 21:16:20.017344: Epoch 200 
2025-01-08 21:16:20.022389: Current learning rate: 0.00235 
2025-01-08 21:16:56.414366: train_loss -0.1882 
2025-01-08 21:16:56.415365: val_loss -0.2423 
2025-01-08 21:16:56.420916: Pseudo dice [np.float32(0.8933), np.float32(0.3929)] 
2025-01-08 21:16:56.424426: Epoch time: 36.4 s 
2025-01-08 21:16:56.978732:  
2025-01-08 21:16:56.979739: Epoch 201 
2025-01-08 21:16:56.985320: Current learning rate: 0.00231 
2025-01-08 21:17:33.379446: train_loss -0.2109 
2025-01-08 21:17:33.379446: val_loss -0.2124 
2025-01-08 21:17:33.389473: Pseudo dice [np.float32(0.9323), np.float32(0.6953)] 
2025-01-08 21:17:33.394488: Epoch time: 36.4 s 
2025-01-08 21:17:33.972983:  
2025-01-08 21:17:33.972983: Epoch 202 
2025-01-08 21:17:33.979049: Current learning rate: 0.00226 
2025-01-08 21:18:10.325172: train_loss -0.2148 
2025-01-08 21:18:10.325172: val_loss -0.2314 
2025-01-08 21:18:10.332513: Pseudo dice [np.float32(0.9131), np.float32(0.6644)] 
2025-01-08 21:18:10.337522: Epoch time: 36.35 s 
2025-01-08 21:18:10.342544: Yayy! New best EMA pseudo Dice: 0.7398999929428101 
2025-01-08 21:18:11.040025:  
2025-01-08 21:18:11.041024: Epoch 203 
2025-01-08 21:18:11.047174: Current learning rate: 0.00222 
2025-01-08 21:18:47.452451: train_loss -0.192 
2025-01-08 21:18:47.453458: val_loss -0.166 
2025-01-08 21:18:47.459973: Pseudo dice [np.float32(0.9189), np.float32(0.1695)] 
2025-01-08 21:18:47.463481: Epoch time: 36.41 s 
2025-01-08 21:18:48.017054:  
2025-01-08 21:18:48.017054: Epoch 204 
2025-01-08 21:18:48.021578: Current learning rate: 0.00218 
2025-01-08 21:19:24.451256: train_loss -0.242 
2025-01-08 21:19:24.452257: val_loss -0.2599 
2025-01-08 21:19:24.460280: Pseudo dice [np.float32(0.9271), np.float32(0.4992)] 
2025-01-08 21:19:24.465290: Epoch time: 36.43 s 
2025-01-08 21:19:25.172309:  
2025-01-08 21:19:25.172309: Epoch 205 
2025-01-08 21:19:25.176327: Current learning rate: 0.00214 
2025-01-08 21:20:01.542537: train_loss -0.2226 
2025-01-08 21:20:01.543048: val_loss -0.2487 
2025-01-08 21:20:01.549622: Pseudo dice [np.float32(0.9183), np.float32(0.6982)] 
2025-01-08 21:20:01.553155: Epoch time: 36.37 s 
2025-01-08 21:20:02.079333:  
2025-01-08 21:20:02.080334: Epoch 206 
2025-01-08 21:20:02.085936: Current learning rate: 0.00209 
2025-01-08 21:20:38.481317: train_loss -0.2335 
2025-01-08 21:20:38.481827: val_loss -0.1526 
2025-01-08 21:20:38.490006: Pseudo dice [np.float32(0.81), np.float32(0.5436)] 
2025-01-08 21:20:38.495576: Epoch time: 36.4 s 
2025-01-08 21:20:39.020322:  
2025-01-08 21:20:39.020322: Epoch 207 
2025-01-08 21:20:39.025845: Current learning rate: 0.00205 
2025-01-08 21:21:15.420336: train_loss -0.2022 
2025-01-08 21:21:15.421340: val_loss -0.272 
2025-01-08 21:21:15.427863: Pseudo dice [np.float32(0.9025), np.float32(0.3943)] 
2025-01-08 21:21:15.433887: Epoch time: 36.4 s 
2025-01-08 21:21:15.959116:  
2025-01-08 21:21:15.959116: Epoch 208 
2025-01-08 21:21:15.964635: Current learning rate: 0.00201 
2025-01-08 21:21:52.347597: train_loss -0.2225 
2025-01-08 21:21:52.348599: val_loss -0.2004 
2025-01-08 21:21:52.356288: Pseudo dice [np.float32(0.9301), np.float32(0.1556)] 
2025-01-08 21:21:52.360608: Epoch time: 36.39 s 
2025-01-08 21:21:52.887276:  
2025-01-08 21:21:52.887276: Epoch 209 
2025-01-08 21:21:52.892300: Current learning rate: 0.00196 
2025-01-08 21:22:29.272027: train_loss -0.2261 
2025-01-08 21:22:29.272027: val_loss -0.2773 
2025-01-08 21:22:29.279160: Pseudo dice [np.float32(0.8929), np.float32(0.7005)] 
2025-01-08 21:22:29.284222: Epoch time: 36.39 s 
2025-01-08 21:22:29.805134:  
2025-01-08 21:22:29.805637: Epoch 210 
2025-01-08 21:22:29.810651: Current learning rate: 0.00192 
2025-01-08 21:23:06.193812: train_loss -0.2152 
2025-01-08 21:23:06.194812: val_loss -0.2288 
2025-01-08 21:23:06.202829: Pseudo dice [np.float32(0.9434), np.float32(0.7372)] 
2025-01-08 21:23:06.210352: Epoch time: 36.39 s 
2025-01-08 21:23:06.734488:  
2025-01-08 21:23:06.735992: Epoch 211 
2025-01-08 21:23:06.740507: Current learning rate: 0.00188 
2025-01-08 21:23:43.115793: train_loss -0.2532 
2025-01-08 21:23:43.115793: val_loss -0.1897 
2025-01-08 21:23:43.123312: Pseudo dice [np.float32(0.8299), np.float32(0.5385)] 
2025-01-08 21:23:43.127324: Epoch time: 36.38 s 
2025-01-08 21:23:43.646387:  
2025-01-08 21:23:43.646387: Epoch 212 
2025-01-08 21:23:43.651987: Current learning rate: 0.00184 
2025-01-08 21:24:19.993655: train_loss -0.2194 
2025-01-08 21:24:19.994160: val_loss -0.2512 
2025-01-08 21:24:20.001679: Pseudo dice [np.float32(0.9238), np.float32(0.47)] 
2025-01-08 21:24:20.006693: Epoch time: 36.35 s 
2025-01-08 21:24:20.539225:  
2025-01-08 21:24:20.539225: Epoch 213 
2025-01-08 21:24:20.544758: Current learning rate: 0.00179 
2025-01-08 21:24:56.908826: train_loss -0.2415 
2025-01-08 21:24:56.909328: val_loss -0.2843 
2025-01-08 21:24:56.916494: Pseudo dice [np.float32(0.8997), np.float32(0.6233)] 
2025-01-08 21:24:56.920001: Epoch time: 36.37 s 
2025-01-08 21:24:57.604970:  
2025-01-08 21:24:57.605472: Epoch 214 
2025-01-08 21:24:57.610484: Current learning rate: 0.00175 
2025-01-08 21:25:34.019767: train_loss -0.237 
2025-01-08 21:25:34.020773: val_loss -0.2595 
2025-01-08 21:25:34.026951: Pseudo dice [np.float32(0.9199), np.float32(0.7622)] 
2025-01-08 21:25:34.032596: Epoch time: 36.42 s 
2025-01-08 21:25:34.546281:  
2025-01-08 21:25:34.547280: Epoch 215 
2025-01-08 21:25:34.552878: Current learning rate: 0.0017 
2025-01-08 21:26:10.911379: train_loss -0.2093 
2025-01-08 21:26:10.911883: val_loss -0.2745 
2025-01-08 21:26:10.919408: Pseudo dice [np.float32(0.9025), np.float32(0.625)] 
2025-01-08 21:26:10.924473: Epoch time: 36.37 s 
2025-01-08 21:26:11.446584:  
2025-01-08 21:26:11.446584: Epoch 216 
2025-01-08 21:26:11.451603: Current learning rate: 0.00166 
2025-01-08 21:26:53.535429: train_loss -0.1881 
2025-01-08 21:26:53.535934: val_loss -0.1637 
2025-01-08 21:26:53.543552: Pseudo dice [np.float32(0.8542), np.float32(0.4894)] 
2025-01-08 21:26:53.547670: Epoch time: 42.09 s 
2025-01-08 21:26:54.059891:  
2025-01-08 21:26:54.059891: Epoch 217 
2025-01-08 21:26:54.065915: Current learning rate: 0.00162 
2025-01-08 21:27:31.459817: train_loss -0.2003 
2025-01-08 21:27:31.460817: val_loss -0.2825 
2025-01-08 21:27:31.467343: Pseudo dice [np.float32(0.9196), np.float32(0.7553)] 
2025-01-08 21:27:31.473862: Epoch time: 37.4 s 
2025-01-08 21:27:31.478878: Yayy! New best EMA pseudo Dice: 0.7400000095367432 
2025-01-08 21:27:32.145162:  
2025-01-08 21:27:32.145162: Epoch 218 
2025-01-08 21:27:32.150173: Current learning rate: 0.00157 
2025-01-08 21:28:09.591529: train_loss -0.2044 
2025-01-08 21:28:09.591529: val_loss -0.2519 
2025-01-08 21:28:09.598551: Pseudo dice [np.float32(0.9264), np.float32(0.73)] 
2025-01-08 21:28:09.604071: Epoch time: 37.45 s 
2025-01-08 21:28:09.608584: Yayy! New best EMA pseudo Dice: 0.7487999796867371 
2025-01-08 21:28:10.290377:  
2025-01-08 21:28:10.290880: Epoch 219 
2025-01-08 21:28:10.295892: Current learning rate: 0.00153 
2025-01-08 21:28:47.646122: train_loss -0.2335 
2025-01-08 21:28:47.646122: val_loss -0.2465 
2025-01-08 21:28:47.652649: Pseudo dice [np.float32(0.8935), np.float32(0.5227)] 
2025-01-08 21:28:47.657241: Epoch time: 37.36 s 
2025-01-08 21:28:48.172426:  
2025-01-08 21:28:48.172426: Epoch 220 
2025-01-08 21:28:48.178543: Current learning rate: 0.00148 
2025-01-08 21:29:25.597579: train_loss -0.2311 
2025-01-08 21:29:25.597579: val_loss -0.2103 
2025-01-08 21:29:25.604095: Pseudo dice [np.float32(0.937), np.float32(0.7205)] 
2025-01-08 21:29:25.607605: Epoch time: 37.43 s 
2025-01-08 21:29:25.611111: Yayy! New best EMA pseudo Dice: 0.7530999779701233 
2025-01-08 21:29:26.274564:  
2025-01-08 21:29:26.274564: Epoch 221 
2025-01-08 21:29:26.280094: Current learning rate: 0.00144 
2025-01-08 21:30:03.638629: train_loss -0.2234 
2025-01-08 21:30:03.638629: val_loss -0.2851 
2025-01-08 21:30:03.645198: Pseudo dice [np.float32(0.9292), np.float32(0.7188)] 
2025-01-08 21:30:03.648739: Epoch time: 37.37 s 
2025-01-08 21:30:03.652784: Yayy! New best EMA pseudo Dice: 0.760200023651123 
2025-01-08 21:30:04.495115:  
2025-01-08 21:30:04.495115: Epoch 222 
2025-01-08 21:30:04.501737: Current learning rate: 0.00139 
2025-01-08 21:30:41.956382: train_loss -0.2244 
2025-01-08 21:30:41.957389: val_loss -0.2684 
2025-01-08 21:30:41.964911: Pseudo dice [np.float32(0.9161), np.float32(0.6748)] 
2025-01-08 21:30:41.971430: Epoch time: 37.46 s 
2025-01-08 21:30:41.974958: Yayy! New best EMA pseudo Dice: 0.763700008392334 
2025-01-08 21:30:42.647815:  
2025-01-08 21:30:42.647815: Epoch 223 
2025-01-08 21:30:42.653328: Current learning rate: 0.00135 
2025-01-08 21:31:20.036229: train_loss -0.2444 
2025-01-08 21:31:20.036229: val_loss -0.2433 
2025-01-08 21:31:20.045254: Pseudo dice [np.float32(0.9317), np.float32(0.6582)] 
2025-01-08 21:31:20.050271: Epoch time: 37.39 s 
2025-01-08 21:31:20.055286: Yayy! New best EMA pseudo Dice: 0.7669000029563904 
2025-01-08 21:31:20.756256:  
2025-01-08 21:31:20.756256: Epoch 224 
2025-01-08 21:31:20.761778: Current learning rate: 0.0013 
2025-01-08 21:31:58.145218: train_loss -0.2093 
2025-01-08 21:31:58.146747: val_loss -0.2163 
2025-01-08 21:31:58.152394: Pseudo dice [np.float32(0.8579), np.float32(0.6152)] 
2025-01-08 21:31:58.155907: Epoch time: 37.39 s 
2025-01-08 21:31:58.676582:  
2025-01-08 21:31:58.676582: Epoch 225 
2025-01-08 21:31:58.681107: Current learning rate: 0.00126 
2025-01-08 21:32:36.063556: train_loss -0.2556 
2025-01-08 21:32:36.063556: val_loss -0.2593 
2025-01-08 21:32:36.069834: Pseudo dice [np.float32(0.9527), np.float32(0.7153)] 
2025-01-08 21:32:36.073910: Epoch time: 37.39 s 
2025-01-08 21:32:36.077494: Yayy! New best EMA pseudo Dice: 0.770799994468689 
2025-01-08 21:32:36.754720:  
2025-01-08 21:32:36.755223: Epoch 226 
2025-01-08 21:32:36.761242: Current learning rate: 0.00121 
2025-01-08 21:33:14.088199: train_loss -0.2071 
2025-01-08 21:33:14.089201: val_loss -0.2414 
2025-01-08 21:33:14.095716: Pseudo dice [np.float32(0.9195), np.float32(0.3025)] 
2025-01-08 21:33:14.099224: Epoch time: 37.33 s 
2025-01-08 21:33:14.619766:  
2025-01-08 21:33:14.620765: Epoch 227 
2025-01-08 21:33:14.626283: Current learning rate: 0.00117 
2025-01-08 21:33:52.016555: train_loss -0.227 
2025-01-08 21:33:52.017057: val_loss -0.3084 
2025-01-08 21:33:52.025576: Pseudo dice [np.float32(0.9063), np.float32(0.8074)] 
2025-01-08 21:33:52.029584: Epoch time: 37.4 s 
2025-01-08 21:33:52.548112:  
2025-01-08 21:33:52.548112: Epoch 228 
2025-01-08 21:33:52.554127: Current learning rate: 0.00112 
2025-01-08 21:34:29.937024: train_loss -0.2007 
2025-01-08 21:34:29.937530: val_loss -0.2405 
2025-01-08 21:34:29.944133: Pseudo dice [np.float32(0.9244), np.float32(0.5429)] 
2025-01-08 21:34:29.950264: Epoch time: 37.39 s 
2025-01-08 21:34:30.634712:  
2025-01-08 21:34:30.634712: Epoch 229 
2025-01-08 21:34:30.640726: Current learning rate: 0.00108 
2025-01-08 21:35:08.028553: train_loss -0.2508 
2025-01-08 21:35:08.028553: val_loss -0.1564 
2025-01-08 21:35:08.035783: Pseudo dice [np.float32(0.9143), np.float32(0.2331)] 
2025-01-08 21:35:08.039333: Epoch time: 37.39 s 
2025-01-08 21:35:08.557423:  
2025-01-08 21:35:08.557926: Epoch 230 
2025-01-08 21:35:08.562937: Current learning rate: 0.00103 
2025-01-08 21:35:45.937485: train_loss -0.2228 
2025-01-08 21:35:45.938488: val_loss -0.2333 
2025-01-08 21:35:45.945320: Pseudo dice [np.float32(0.9122), np.float32(0.7326)] 
2025-01-08 21:35:45.951347: Epoch time: 37.38 s 
2025-01-08 21:35:46.478528:  
2025-01-08 21:35:46.479031: Epoch 231 
2025-01-08 21:35:46.484043: Current learning rate: 0.00098 
2025-01-08 21:36:23.693776: train_loss -0.245 
2025-01-08 21:36:23.694789: val_loss -0.2272 
2025-01-08 21:36:23.701357: Pseudo dice [np.float32(0.8767), np.float32(0.5024)] 
2025-01-08 21:36:23.704973: Epoch time: 37.22 s 
2025-01-08 21:36:24.227186:  
2025-01-08 21:36:24.227186: Epoch 232 
2025-01-08 21:36:24.232296: Current learning rate: 0.00094 
2025-01-08 21:37:00.572694: train_loss -0.2104 
2025-01-08 21:37:00.572694: val_loss -0.2111 
2025-01-08 21:37:00.579872: Pseudo dice [np.float32(0.8877), np.float32(0.3412)] 
2025-01-08 21:37:00.584884: Epoch time: 36.35 s 
2025-01-08 21:37:01.106045:  
2025-01-08 21:37:01.107049: Epoch 233 
2025-01-08 21:37:01.111605: Current learning rate: 0.00089 
2025-01-08 21:37:37.497090: train_loss -0.2469 
2025-01-08 21:37:37.498593: val_loss -0.2709 
2025-01-08 21:37:37.504613: Pseudo dice [np.float32(0.9054), np.float32(0.7899)] 
2025-01-08 21:37:37.509628: Epoch time: 36.39 s 
2025-01-08 21:37:38.026531:  
2025-01-08 21:37:38.026531: Epoch 234 
2025-01-08 21:37:38.032556: Current learning rate: 0.00084 
2025-01-08 21:38:14.416665: train_loss -0.2315 
2025-01-08 21:38:14.417170: val_loss -0.2678 
2025-01-08 21:38:14.424697: Pseudo dice [np.float32(0.9323), np.float32(0.6019)] 
2025-01-08 21:38:14.430722: Epoch time: 36.39 s 
2025-01-08 21:38:14.945848:  
2025-01-08 21:38:14.945848: Epoch 235 
2025-01-08 21:38:14.951399: Current learning rate: 0.00079 
2025-01-08 21:38:51.309114: train_loss -0.2296 
2025-01-08 21:38:51.310116: val_loss -0.2872 
2025-01-08 21:38:51.316676: Pseudo dice [np.float32(0.9465), np.float32(0.6403)] 
2025-01-08 21:38:51.321728: Epoch time: 36.36 s 
2025-01-08 21:38:51.840438:  
2025-01-08 21:38:51.840438: Epoch 236 
2025-01-08 21:38:51.844976: Current learning rate: 0.00075 
2025-01-08 21:39:28.295359: train_loss -0.2255 
2025-01-08 21:39:28.297389: val_loss -0.2888 
2025-01-08 21:39:28.302918: Pseudo dice [np.float32(0.9303), np.float32(0.6369)] 
2025-01-08 21:39:28.307455: Epoch time: 36.45 s 
2025-01-08 21:39:28.824984:  
2025-01-08 21:39:28.824984: Epoch 237 
2025-01-08 21:39:28.831555: Current learning rate: 0.0007 
2025-01-08 21:40:05.214352: train_loss -0.2491 
2025-01-08 21:40:05.214352: val_loss -0.3146 
2025-01-08 21:40:05.221900: Pseudo dice [np.float32(0.9324), np.float32(0.5978)] 
2025-01-08 21:40:05.225557: Epoch time: 36.39 s 
2025-01-08 21:40:05.915091:  
2025-01-08 21:40:05.915594: Epoch 238 
2025-01-08 21:40:05.920609: Current learning rate: 0.00065 
2025-01-08 21:40:42.292933: train_loss -0.208 
2025-01-08 21:40:42.294437: val_loss -0.3134 
2025-01-08 21:40:42.302957: Pseudo dice [np.float32(0.9435), np.float32(0.6305)] 
2025-01-08 21:40:42.306964: Epoch time: 36.38 s 
2025-01-08 21:40:42.854440:  
2025-01-08 21:40:42.854440: Epoch 239 
2025-01-08 21:40:42.860478: Current learning rate: 0.0006 
2025-01-08 21:41:25.736300: train_loss -0.2493 
2025-01-08 21:41:25.736802: val_loss -0.2678 
2025-01-08 21:41:25.743344: Pseudo dice [np.float32(0.8899), np.float32(0.7849)] 
2025-01-08 21:41:25.746909: Epoch time: 42.88 s 
2025-01-08 21:41:26.274254:  
2025-01-08 21:41:26.274254: Epoch 240 
2025-01-08 21:41:26.279848: Current learning rate: 0.00055 
2025-01-08 21:42:03.640143: train_loss -0.2471 
2025-01-08 21:42:03.640143: val_loss -0.3018 
2025-01-08 21:42:03.646661: Pseudo dice [np.float32(0.9319), np.float32(0.6807)] 
2025-01-08 21:42:03.651220: Epoch time: 37.37 s 
2025-01-08 21:42:04.183279:  
2025-01-08 21:42:04.184281: Epoch 241 
2025-01-08 21:42:04.190326: Current learning rate: 0.0005 
2025-01-08 21:42:41.562206: train_loss -0.2616 
2025-01-08 21:42:41.562206: val_loss -0.2593 
2025-01-08 21:42:41.569729: Pseudo dice [np.float32(0.9172), np.float32(0.6003)] 
2025-01-08 21:42:41.574240: Epoch time: 37.38 s 
2025-01-08 21:42:42.101440:  
2025-01-08 21:42:42.101440: Epoch 242 
2025-01-08 21:42:42.108001: Current learning rate: 0.00045 
2025-01-08 21:43:19.493101: train_loss -0.2401 
2025-01-08 21:43:19.494102: val_loss -0.2313 
2025-01-08 21:43:19.500618: Pseudo dice [np.float32(0.8952), np.float32(0.5058)] 
2025-01-08 21:43:19.507131: Epoch time: 37.39 s 
2025-01-08 21:43:20.033454:  
2025-01-08 21:43:20.033454: Epoch 243 
2025-01-08 21:43:20.039509: Current learning rate: 0.0004 
2025-01-08 21:43:57.450400: train_loss -0.2138 
2025-01-08 21:43:57.450914: val_loss -0.219 
2025-01-08 21:43:57.459446: Pseudo dice [np.float32(0.8825), np.float32(0.328)] 
2025-01-08 21:43:57.466971: Epoch time: 37.42 s 
2025-01-08 21:43:57.996424:  
2025-01-08 21:43:57.996424: Epoch 244 
2025-01-08 21:43:58.002955: Current learning rate: 0.00035 
2025-01-08 21:44:35.399978: train_loss -0.2707 
2025-01-08 21:44:35.400979: val_loss -0.225 
2025-01-08 21:44:35.407504: Pseudo dice [np.float32(0.8872), np.float32(0.6325)] 
2025-01-08 21:44:35.411510: Epoch time: 37.4 s 
2025-01-08 21:44:35.939726:  
2025-01-08 21:44:35.939726: Epoch 245 
2025-01-08 21:44:35.944773: Current learning rate: 0.0003 
2025-01-08 21:45:13.284880: train_loss -0.2617 
2025-01-08 21:45:13.284880: val_loss -0.27 
2025-01-08 21:45:13.292290: Pseudo dice [np.float32(0.9273), np.float32(0.6977)] 
2025-01-08 21:45:13.295799: Epoch time: 37.35 s 
2025-01-08 21:45:13.984712:  
2025-01-08 21:45:13.984712: Epoch 246 
2025-01-08 21:45:13.990724: Current learning rate: 0.00024 
2025-01-08 21:45:51.378616: train_loss -0.2545 
2025-01-08 21:45:51.379135: val_loss -0.2219 
2025-01-08 21:45:51.385682: Pseudo dice [np.float32(0.9075), np.float32(0.5041)] 
2025-01-08 21:45:51.389245: Epoch time: 37.39 s 
2025-01-08 21:45:51.915900:  
2025-01-08 21:45:51.916904: Epoch 247 
2025-01-08 21:45:51.921960: Current learning rate: 0.00019 
2025-01-08 21:46:29.331835: train_loss -0.2745 
2025-01-08 21:46:29.331835: val_loss -0.2512 
2025-01-08 21:46:29.340365: Pseudo dice [np.float32(0.8903), np.float32(0.634)] 
2025-01-08 21:46:29.346383: Epoch time: 37.42 s 
2025-01-08 21:46:29.873069:  
2025-01-08 21:46:29.873069: Epoch 248 
2025-01-08 21:46:29.878603: Current learning rate: 0.00013 
2025-01-08 21:47:07.282357: train_loss -0.2058 
2025-01-08 21:47:07.283864: val_loss -0.2483 
2025-01-08 21:47:07.291564: Pseudo dice [np.float32(0.9161), np.float32(0.4149)] 
2025-01-08 21:47:07.295624: Epoch time: 37.41 s 
2025-01-08 21:47:07.824405:  
2025-01-08 21:47:07.824405: Epoch 249 
2025-01-08 21:47:07.829924: Current learning rate: 7e-05 
2025-01-08 21:47:45.187589: train_loss -0.24 
2025-01-08 21:47:45.189094: val_loss -0.2343 
2025-01-08 21:47:45.197156: Pseudo dice [np.float32(0.9267), np.float32(0.663)] 
2025-01-08 21:47:45.202220: Epoch time: 37.36 s 
2025-01-08 21:47:45.907799: Training done. 
2025-01-08 21:47:45.947307: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset003_Liver\splits_final.json 
2025-01-08 21:47:45.960309: The split file contains 5 splits. 
2025-01-08 21:47:45.967308: Desired fold for training: 0 
2025-01-08 21:47:45.973307: This split has 104 training and 27 validation cases. 
2025-01-08 21:47:45.981308: predicting liver_101 
2025-01-08 21:47:45.991307: liver_101, shape torch.Size([1, 478, 470, 470]), rank 0 
2025-01-08 21:48:41.900674: predicting liver_11 
2025-01-08 21:48:41.939674: liver_11, shape torch.Size([1, 466, 448, 448]), rank 0 
2025-01-08 21:49:22.684891: predicting liver_112 
2025-01-08 21:49:22.718892: liver_112, shape torch.Size([1, 601, 427, 427]), rank 0 
2025-01-08 21:50:15.033555: predicting liver_115 
2025-01-08 21:50:15.078555: liver_115, shape torch.Size([1, 677, 504, 504]), rank 0 
2025-01-08 21:51:33.074938: predicting liver_12 
2025-01-08 21:51:33.137942: liver_12, shape torch.Size([1, 455, 436, 436]), rank 0 
2025-01-08 21:52:12.808285: predicting liver_120 
2025-01-08 21:52:12.840286: liver_120, shape torch.Size([1, 636, 496, 496]), rank 0 
2025-01-08 21:53:22.188726: predicting liver_128 
2025-01-08 21:53:22.236230: liver_128, shape torch.Size([1, 458, 521, 521]), rank 0 
2025-01-08 21:54:32.726301: predicting liver_17 
2025-01-08 21:54:32.779812: liver_17, shape torch.Size([1, 661, 496, 496]), rank 0 
2025-01-08 21:55:49.895437: predicting liver_19 
2025-01-08 21:55:49.952437: liver_19, shape torch.Size([1, 438, 502, 502]), rank 0 
2025-01-08 21:56:36.273355: predicting liver_24 
2025-01-08 21:56:36.314862: liver_24, shape torch.Size([1, 414, 447, 447]), rank 0 
2025-01-08 21:57:10.415628: predicting liver_25 
2025-01-08 21:57:10.444135: liver_25, shape torch.Size([1, 421, 512, 512]), rank 0 
2025-01-08 21:57:56.621852: predicting liver_27 
2025-01-08 21:57:56.656361: liver_27, shape torch.Size([1, 603, 492, 492]), rank 0 
2025-01-08 21:59:05.909295: predicting liver_3 
2025-01-08 21:59:05.950295: liver_3, shape torch.Size([1, 534, 462, 462]), rank 0 
2025-01-08 22:00:07.500652: predicting liver_38 
2025-01-08 22:00:07.536653: liver_38, shape torch.Size([1, 132, 667, 667]), rank 0 
2025-01-08 22:00:39.011994: predicting liver_40 
2025-01-08 22:00:39.034994: liver_40, shape torch.Size([1, 122, 667, 667]), rank 0 
2025-01-08 22:00:54.947725: predicting liver_41 
2025-01-08 22:00:54.965230: liver_41, shape torch.Size([1, 113, 667, 667]), rank 0 
2025-01-08 22:01:10.877289: predicting liver_42 
2025-01-08 22:01:10.894289: liver_42, shape torch.Size([1, 125, 667, 667]), rank 0 
2025-01-08 22:01:26.787382: predicting liver_44 
2025-01-08 22:01:26.807382: liver_44, shape torch.Size([1, 119, 667, 667]), rank 0 
2025-01-08 22:01:42.709253: predicting liver_5 
2025-01-08 22:01:42.727254: liver_5, shape torch.Size([1, 430, 646, 646]), rank 0 
2025-01-08 22:03:16.841907: predicting liver_51 
2025-01-08 22:03:16.899422: liver_51, shape torch.Size([1, 681, 602, 602]), rank 0 
2025-01-08 22:05:24.163125: predicting liver_52 
2025-01-08 22:05:24.256634: liver_52, shape torch.Size([1, 592, 558, 558]), rank 0 
2025-01-08 22:06:54.798730: predicting liver_58 
2025-01-08 22:06:54.867238: liver_58, shape torch.Size([1, 424, 456, 456]), rank 0 
2025-01-08 22:07:41.085663: predicting liver_64 
2025-01-08 22:07:41.114663: liver_64, shape torch.Size([1, 460, 519, 519]), rank 0 
2025-01-08 22:08:51.579704: predicting liver_70 
2025-01-08 22:08:51.617707: liver_70, shape torch.Size([1, 416, 399, 399]), rank 0 
2025-01-08 22:09:25.573699: predicting liver_75 
2025-01-08 22:09:25.594706: liver_75, shape torch.Size([1, 445, 505, 505]), rank 0 
2025-01-08 22:10:11.813301: predicting liver_77 
2025-01-08 22:10:11.850301: liver_77, shape torch.Size([1, 470, 521, 521]), rank 0 
2025-01-08 22:11:22.232632: predicting liver_82 
2025-01-08 22:11:22.279632: liver_82, shape torch.Size([1, 416, 417, 417]), rank 0 
2025-01-08 22:12:23.404459: Validation complete 
2025-01-08 22:12:23.404459: Mean Validation Dice:  0.7390881393417268 
