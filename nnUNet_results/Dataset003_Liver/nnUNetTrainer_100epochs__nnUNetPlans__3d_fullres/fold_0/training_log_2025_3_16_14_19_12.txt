
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-03-16 14:19:12.657406: do_dummy_2d_data_aug: False 
2025-03-16 14:19:12.670915: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset003_Liver\splits_final.json 
2025-03-16 14:19:12.679428: The split file contains 5 splits. 
2025-03-16 14:19:12.681424: Desired fold for training: 0 
2025-03-16 14:19:12.684933: This split has 104 training and 27 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [482.0, 512.0, 512.0], 'spacing': [1.0, 0.767578125, 0.767578125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset003_Liver', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 0.767578125, 0.767578125], 'original_median_shape_after_transp': [432, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5420.0, 'mean': 99.48007202148438, 'median': 101.0, 'min': -983.0, 'percentile_00_5': -15.0, 'percentile_99_5': 197.0, 'std': 37.13840103149414}}} 
 
2025-03-16 14:19:20.931892: unpacking dataset... 
2025-03-16 14:19:21.228259: unpacking done... 
2025-03-16 14:19:24.162632:  
2025-03-16 14:19:24.168653: Epoch 0 
2025-03-16 14:19:24.172674: Current learning rate: 0.01 
2025-03-16 14:20:05.711306: train_loss 0.1181 
2025-03-16 14:20:05.717923: val_loss -0.0231 
2025-03-16 14:20:05.722940: Pseudo dice [np.float32(0.7838), np.float32(0.0)] 
2025-03-16 14:20:05.727992: Epoch time: 41.55 s 
2025-03-16 14:20:05.732502: Yayy! New best EMA pseudo Dice: 0.3919000029563904 
2025-03-16 14:20:06.385579:  
2025-03-16 14:20:06.391090: Epoch 1 
2025-03-16 14:20:06.394600: Current learning rate: 0.00991 
2025-03-16 14:20:43.823644: train_loss -0.0646 
2025-03-16 14:20:43.830276: val_loss -0.0657 
2025-03-16 14:20:43.834300: Pseudo dice [np.float32(0.7851), np.float32(0.0)] 
2025-03-16 14:20:43.836306: Epoch time: 37.44 s 
2025-03-16 14:20:43.840460: Yayy! New best EMA pseudo Dice: 0.3919999897480011 
2025-03-16 14:20:44.549900:  
2025-03-16 14:20:44.555995: Epoch 2 
2025-03-16 14:20:44.559101: Current learning rate: 0.00982 
2025-03-16 14:21:21.635175: train_loss -0.0996 
2025-03-16 14:21:21.641307: val_loss -0.1863 
2025-03-16 14:21:21.645859: Pseudo dice [np.float32(0.8421), np.float32(0.0)] 
2025-03-16 14:21:21.648948: Epoch time: 37.09 s 
2025-03-16 14:21:21.652491: Yayy! New best EMA pseudo Dice: 0.39489999413490295 
2025-03-16 14:21:22.411911:  
2025-03-16 14:21:22.417957: Epoch 3 
2025-03-16 14:21:22.421607: Current learning rate: 0.00973 
2025-03-16 14:21:59.805820: train_loss -0.1325 
2025-03-16 14:21:59.812842: val_loss -0.277 
2025-03-16 14:21:59.815854: Pseudo dice [np.float32(0.8819), np.float32(0.3044)] 
2025-03-16 14:21:59.819889: Epoch time: 37.39 s 
2025-03-16 14:21:59.823418: Yayy! New best EMA pseudo Dice: 0.4147000014781952 
2025-03-16 14:22:00.616728:  
2025-03-16 14:22:00.622744: Epoch 4 
2025-03-16 14:22:00.626996: Current learning rate: 0.00964 
2025-03-16 14:22:37.870052: train_loss -0.1546 
2025-03-16 14:22:37.876119: val_loss -0.1765 
2025-03-16 14:22:37.879626: Pseudo dice [np.float32(0.8329), np.float32(0.1409)] 
2025-03-16 14:22:37.882637: Epoch time: 37.25 s 
2025-03-16 14:22:37.886146: Yayy! New best EMA pseudo Dice: 0.4219000041484833 
2025-03-16 14:22:38.816535:  
2025-03-16 14:22:38.822081: Epoch 5 
2025-03-16 14:22:38.825402: Current learning rate: 0.00955 
2025-03-16 14:23:16.216000: train_loss -0.2334 
2025-03-16 14:23:16.223133: val_loss -0.3191 
2025-03-16 14:23:16.227339: Pseudo dice [np.float32(0.8759), np.float32(0.4169)] 
2025-03-16 14:23:16.231404: Epoch time: 37.4 s 
2025-03-16 14:23:16.234464: Yayy! New best EMA pseudo Dice: 0.44440001249313354 
2025-03-16 14:23:17.035683:  
2025-03-16 14:23:17.041517: Epoch 6 
2025-03-16 14:23:17.044024: Current learning rate: 0.00946 
2025-03-16 14:23:54.479299: train_loss -0.2421 
2025-03-16 14:23:54.485419: val_loss -0.3684 
2025-03-16 14:23:54.489477: Pseudo dice [np.float32(0.9189), np.float32(0.5152)] 
2025-03-16 14:23:54.493580: Epoch time: 37.45 s 
2025-03-16 14:23:54.497144: Yayy! New best EMA pseudo Dice: 0.4715999960899353 
2025-03-16 14:23:55.317576:  
2025-03-16 14:23:55.323620: Epoch 7 
2025-03-16 14:23:55.326682: Current learning rate: 0.00937 
2025-03-16 14:24:32.688611: train_loss -0.345 
2025-03-16 14:24:32.695181: val_loss -0.3097 
2025-03-16 14:24:32.699306: Pseudo dice [np.float32(0.8669), np.float32(0.3841)] 
2025-03-16 14:24:32.702355: Epoch time: 37.37 s 
2025-03-16 14:24:32.705442: Yayy! New best EMA pseudo Dice: 0.4869999885559082 
2025-03-16 14:24:33.484287:  
2025-03-16 14:24:33.489824: Epoch 8 
2025-03-16 14:24:33.493384: Current learning rate: 0.00928 
2025-03-16 14:25:10.830349: train_loss -0.3239 
2025-03-16 14:25:10.835998: val_loss -0.3773 
2025-03-16 14:25:10.839511: Pseudo dice [np.float32(0.9029), np.float32(0.509)] 
2025-03-16 14:25:10.843019: Epoch time: 37.35 s 
2025-03-16 14:25:10.846052: Yayy! New best EMA pseudo Dice: 0.508899986743927 
2025-03-16 14:25:11.658750:  
2025-03-16 14:25:11.664794: Epoch 9 
2025-03-16 14:25:11.667843: Current learning rate: 0.00919 
2025-03-16 14:25:48.831782: train_loss -0.3247 
2025-03-16 14:25:48.838363: val_loss -0.3994 
2025-03-16 14:25:48.841874: Pseudo dice [np.float32(0.9084), np.float32(0.4952)] 
2025-03-16 14:25:48.845379: Epoch time: 37.17 s 
2025-03-16 14:25:48.849418: Yayy! New best EMA pseudo Dice: 0.5281999707221985 
2025-03-16 14:25:49.621236:  
2025-03-16 14:25:49.627279: Epoch 10 
2025-03-16 14:25:49.630328: Current learning rate: 0.0091 
2025-03-16 14:26:26.957368: train_loss -0.3664 
2025-03-16 14:26:26.963014: val_loss -0.3959 
2025-03-16 14:26:26.967594: Pseudo dice [np.float32(0.8978), np.float32(0.5278)] 
2025-03-16 14:26:26.970642: Epoch time: 37.34 s 
2025-03-16 14:26:26.973756: Yayy! New best EMA pseudo Dice: 0.5467000007629395 
2025-03-16 14:26:27.758143:  
2025-03-16 14:26:27.764662: Epoch 11 
2025-03-16 14:26:27.768176: Current learning rate: 0.009 
2025-03-16 14:27:05.355543: train_loss -0.3492 
2025-03-16 14:27:05.361612: val_loss -0.4655 
2025-03-16 14:27:05.365644: Pseudo dice [np.float32(0.9332), np.float32(0.4984)] 
2025-03-16 14:27:05.369315: Epoch time: 37.6 s 
2025-03-16 14:27:05.372826: Yayy! New best EMA pseudo Dice: 0.5636000037193298 
2025-03-16 14:27:06.313033:  
2025-03-16 14:27:06.321183: Epoch 12 
2025-03-16 14:27:06.325197: Current learning rate: 0.00891 
2025-03-16 14:27:44.385214: train_loss -0.3686 
2025-03-16 14:27:44.390895: val_loss -0.4282 
2025-03-16 14:27:44.395480: Pseudo dice [np.float32(0.9207), np.float32(0.5779)] 
2025-03-16 14:27:44.399033: Epoch time: 38.07 s 
2025-03-16 14:27:44.403063: Yayy! New best EMA pseudo Dice: 0.582099974155426 
2025-03-16 14:27:45.194211:  
2025-03-16 14:27:45.199727: Epoch 13 
2025-03-16 14:27:45.203240: Current learning rate: 0.00882 
2025-03-16 14:28:23.380356: train_loss -0.3355 
2025-03-16 14:28:23.386940: val_loss -0.3796 
2025-03-16 14:28:23.390511: Pseudo dice [np.float32(0.8928), np.float32(0.523)] 
2025-03-16 14:28:23.394045: Epoch time: 38.19 s 
2025-03-16 14:28:23.397597: Yayy! New best EMA pseudo Dice: 0.5946999788284302 
2025-03-16 14:28:24.201298:  
2025-03-16 14:28:24.207639: Epoch 14 
2025-03-16 14:28:24.211151: Current learning rate: 0.00873 
2025-03-16 14:29:02.124795: train_loss -0.3939 
2025-03-16 14:29:02.131325: val_loss -0.4003 
2025-03-16 14:29:02.134837: Pseudo dice [np.float32(0.8965), np.float32(0.5234)] 
2025-03-16 14:29:02.138847: Epoch time: 37.92 s 
2025-03-16 14:29:02.142365: Yayy! New best EMA pseudo Dice: 0.6061999797821045 
2025-03-16 14:29:02.940897:  
2025-03-16 14:29:02.945940: Epoch 15 
2025-03-16 14:29:02.949888: Current learning rate: 0.00864 
2025-03-16 14:29:40.956453: train_loss -0.3834 
2025-03-16 14:29:40.962971: val_loss -0.3927 
2025-03-16 14:29:40.966484: Pseudo dice [np.float32(0.8973), np.float32(0.5917)] 
2025-03-16 14:29:40.970496: Epoch time: 38.02 s 
2025-03-16 14:29:40.974008: Yayy! New best EMA pseudo Dice: 0.6201000213623047 
2025-03-16 14:29:41.796543:  
2025-03-16 14:29:41.802810: Epoch 16 
2025-03-16 14:29:41.806362: Current learning rate: 0.00855 
2025-03-16 14:30:20.162267: train_loss -0.3644 
2025-03-16 14:30:20.168781: val_loss -0.408 
2025-03-16 14:30:20.172294: Pseudo dice [np.float32(0.9199), np.float32(0.5355)] 
2025-03-16 14:30:20.176314: Epoch time: 38.37 s 
2025-03-16 14:30:20.179345: Yayy! New best EMA pseudo Dice: 0.6308000087738037 
2025-03-16 14:30:21.013214:  
2025-03-16 14:30:21.018878: Epoch 17 
2025-03-16 14:30:21.023432: Current learning rate: 0.00846 
2025-03-16 14:30:58.702215: train_loss -0.3836 
2025-03-16 14:30:58.708732: val_loss -0.4259 
2025-03-16 14:30:58.713252: Pseudo dice [np.float32(0.9209), np.float32(0.552)] 
2025-03-16 14:30:58.716785: Epoch time: 37.69 s 
2025-03-16 14:30:58.719826: Yayy! New best EMA pseudo Dice: 0.6413999795913696 
2025-03-16 14:30:59.508559:  
2025-03-16 14:30:59.515139: Epoch 18 
2025-03-16 14:30:59.518708: Current learning rate: 0.00836 
2025-03-16 14:31:37.082648: train_loss -0.3649 
2025-03-16 14:31:37.089688: val_loss -0.406 
2025-03-16 14:31:37.093699: Pseudo dice [np.float32(0.9031), np.float32(0.5092)] 
2025-03-16 14:31:37.097211: Epoch time: 37.57 s 
2025-03-16 14:31:37.101223: Yayy! New best EMA pseudo Dice: 0.6478999853134155 
2025-03-16 14:31:37.911957:  
2025-03-16 14:31:37.918565: Epoch 19 
2025-03-16 14:31:37.921118: Current learning rate: 0.00827 
2025-03-16 14:32:15.654796: train_loss -0.3872 
2025-03-16 14:32:15.661326: val_loss -0.49 
2025-03-16 14:32:15.664841: Pseudo dice [np.float32(0.9342), np.float32(0.6249)] 
2025-03-16 14:32:15.668864: Epoch time: 37.74 s 
2025-03-16 14:32:15.672382: Yayy! New best EMA pseudo Dice: 0.6610000133514404 
2025-03-16 14:32:16.617984:  
2025-03-16 14:32:16.623514: Epoch 20 
2025-03-16 14:32:16.627027: Current learning rate: 0.00818 
2025-03-16 14:32:54.853262: train_loss -0.398 
2025-03-16 14:32:54.857315: val_loss -0.4416 
2025-03-16 14:32:54.860835: Pseudo dice [np.float32(0.9275), np.float32(0.6122)] 
2025-03-16 14:32:54.864339: Epoch time: 38.24 s 
2025-03-16 14:32:54.867351: Yayy! New best EMA pseudo Dice: 0.6718999743461609 
2025-03-16 14:32:55.671368:  
2025-03-16 14:32:55.677479: Epoch 21 
2025-03-16 14:32:55.681071: Current learning rate: 0.00809 
2025-03-16 14:33:35.673170: train_loss -0.4024 
2025-03-16 14:33:35.678735: val_loss -0.4772 
2025-03-16 14:33:35.682750: Pseudo dice [np.float32(0.9341), np.float32(0.5702)] 
2025-03-16 14:33:35.686267: Epoch time: 40.0 s 
2025-03-16 14:33:35.689780: Yayy! New best EMA pseudo Dice: 0.6798999905586243 
2025-03-16 14:33:36.470397:  
2025-03-16 14:33:36.477026: Epoch 22 
2025-03-16 14:33:36.480582: Current learning rate: 0.008 
2025-03-16 14:34:14.377806: train_loss -0.4208 
2025-03-16 14:34:14.384335: val_loss -0.4831 
2025-03-16 14:34:14.388846: Pseudo dice [np.float32(0.9204), np.float32(0.6177)] 
2025-03-16 14:34:14.391862: Epoch time: 37.91 s 
2025-03-16 14:34:14.396381: Yayy! New best EMA pseudo Dice: 0.6887999773025513 
2025-03-16 14:34:15.164907:  
2025-03-16 14:34:15.170969: Epoch 23 
2025-03-16 14:34:15.174662: Current learning rate: 0.0079 
2025-03-16 14:34:53.582982: train_loss -0.4673 
2025-03-16 14:34:53.589002: val_loss -0.4854 
2025-03-16 14:34:53.593014: Pseudo dice [np.float32(0.9332), np.float32(0.6057)] 
2025-03-16 14:34:53.596525: Epoch time: 38.42 s 
2025-03-16 14:34:53.600540: Yayy! New best EMA pseudo Dice: 0.6969000101089478 
2025-03-16 14:34:54.432611:  
2025-03-16 14:34:54.438135: Epoch 24 
2025-03-16 14:34:54.441651: Current learning rate: 0.00781 
2025-03-16 14:35:32.227720: train_loss -0.4673 
2025-03-16 14:35:32.232734: val_loss -0.4009 
2025-03-16 14:35:32.235744: Pseudo dice [np.float32(0.8976), np.float32(0.5263)] 
2025-03-16 14:35:32.240254: Epoch time: 37.8 s 
2025-03-16 14:35:32.243273: Yayy! New best EMA pseudo Dice: 0.6984000205993652 
2025-03-16 14:35:33.048786:  
2025-03-16 14:35:33.055370: Epoch 25 
2025-03-16 14:35:33.058960: Current learning rate: 0.00772 
2025-03-16 14:36:10.578052: train_loss -0.4042 
2025-03-16 14:36:10.584569: val_loss -0.5155 
2025-03-16 14:36:10.588081: Pseudo dice [np.float32(0.9304), np.float32(0.6133)] 
2025-03-16 14:36:10.592098: Epoch time: 37.53 s 
2025-03-16 14:36:10.596615: Yayy! New best EMA pseudo Dice: 0.7057999968528748 
2025-03-16 14:36:11.399314:  
2025-03-16 14:36:11.405425: Epoch 26 
2025-03-16 14:36:11.409009: Current learning rate: 0.00763 
2025-03-16 14:36:48.556222: train_loss -0.4572 
2025-03-16 14:36:48.562238: val_loss -0.5111 
2025-03-16 14:36:48.566248: Pseudo dice [np.float32(0.9315), np.float32(0.642)] 
2025-03-16 14:36:48.569758: Epoch time: 37.16 s 
2025-03-16 14:36:48.573767: Yayy! New best EMA pseudo Dice: 0.7138000130653381 
2025-03-16 14:36:49.520901:  
2025-03-16 14:36:49.526968: Epoch 27 
2025-03-16 14:36:49.531038: Current learning rate: 0.00753 
2025-03-16 14:37:26.787728: train_loss -0.4342 
2025-03-16 14:37:26.794252: val_loss -0.496 
2025-03-16 14:37:26.797756: Pseudo dice [np.float32(0.9312), np.float32(0.6303)] 
2025-03-16 14:37:26.800764: Epoch time: 37.27 s 
2025-03-16 14:37:26.804275: Yayy! New best EMA pseudo Dice: 0.7204999923706055 
2025-03-16 14:37:27.609794:  
2025-03-16 14:37:27.614856: Epoch 28 
2025-03-16 14:37:27.618890: Current learning rate: 0.00744 
2025-03-16 14:38:04.783263: train_loss -0.4778 
2025-03-16 14:38:04.788279: val_loss -0.5068 
2025-03-16 14:38:04.792292: Pseudo dice [np.float32(0.9262), np.float32(0.6984)] 
2025-03-16 14:38:04.794800: Epoch time: 37.17 s 
2025-03-16 14:38:04.798315: Yayy! New best EMA pseudo Dice: 0.7297000288963318 
2025-03-16 14:38:05.587205:  
2025-03-16 14:38:05.593750: Epoch 29 
2025-03-16 14:38:05.597307: Current learning rate: 0.00735 
2025-03-16 14:38:42.754221: train_loss -0.4557 
2025-03-16 14:38:42.761239: val_loss -0.5 
2025-03-16 14:38:42.765254: Pseudo dice [np.float32(0.9375), np.float32(0.5578)] 
2025-03-16 14:38:42.769266: Epoch time: 37.17 s 
2025-03-16 14:38:42.772776: Yayy! New best EMA pseudo Dice: 0.7315000295639038 
2025-03-16 14:38:43.582346:  
2025-03-16 14:38:43.588870: Epoch 30 
2025-03-16 14:38:43.592376: Current learning rate: 0.00725 
2025-03-16 14:39:20.754916: train_loss -0.4548 
2025-03-16 14:39:20.760938: val_loss -0.5242 
2025-03-16 14:39:20.764948: Pseudo dice [np.float32(0.9426), np.float32(0.7221)] 
2025-03-16 14:39:20.768460: Epoch time: 37.17 s 
2025-03-16 14:39:20.771967: Yayy! New best EMA pseudo Dice: 0.741599977016449 
2025-03-16 14:39:21.562605:  
2025-03-16 14:39:21.567115: Epoch 31 
2025-03-16 14:39:21.570123: Current learning rate: 0.00716 
2025-03-16 14:39:58.743240: train_loss -0.4745 
2025-03-16 14:39:58.749259: val_loss -0.5355 
2025-03-16 14:39:58.753271: Pseudo dice [np.float32(0.9415), np.float32(0.5866)] 
2025-03-16 14:39:58.756790: Epoch time: 37.18 s 
2025-03-16 14:39:58.760797: Yayy! New best EMA pseudo Dice: 0.7437999844551086 
2025-03-16 14:39:59.558688:  
2025-03-16 14:39:59.564238: Epoch 32 
2025-03-16 14:39:59.568979: Current learning rate: 0.00707 
2025-03-16 14:40:36.698348: train_loss -0.5058 
2025-03-16 14:40:36.704865: val_loss -0.5293 
2025-03-16 14:40:36.708375: Pseudo dice [np.float32(0.9367), np.float32(0.6527)] 
2025-03-16 14:40:36.712388: Epoch time: 37.14 s 
2025-03-16 14:40:36.716902: Yayy! New best EMA pseudo Dice: 0.7488999962806702 
2025-03-16 14:40:37.516078:  
2025-03-16 14:40:37.522719: Epoch 33 
2025-03-16 14:40:37.526776: Current learning rate: 0.00697 
2025-03-16 14:41:14.840160: train_loss -0.4595 
2025-03-16 14:41:14.846179: val_loss -0.5824 
2025-03-16 14:41:14.850185: Pseudo dice [np.float32(0.9607), np.float32(0.7497)] 
2025-03-16 14:41:14.852695: Epoch time: 37.32 s 
2025-03-16 14:41:14.856204: Yayy! New best EMA pseudo Dice: 0.7595999836921692 
2025-03-16 14:41:15.663872:  
2025-03-16 14:41:15.668903: Epoch 34 
2025-03-16 14:41:15.672416: Current learning rate: 0.00688 
2025-03-16 14:41:52.826758: train_loss -0.4942 
2025-03-16 14:41:52.831770: val_loss -0.558 
2025-03-16 14:41:52.834782: Pseudo dice [np.float32(0.9495), np.float32(0.6792)] 
2025-03-16 14:41:52.839291: Epoch time: 37.16 s 
2025-03-16 14:41:52.843302: Yayy! New best EMA pseudo Dice: 0.7649999856948853 
2025-03-16 14:41:53.817100:  
2025-03-16 14:41:53.822138: Epoch 35 
2025-03-16 14:41:53.825681: Current learning rate: 0.00679 
2025-03-16 14:42:30.979195: train_loss -0.5172 
2025-03-16 14:42:30.985211: val_loss -0.5697 
2025-03-16 14:42:30.989221: Pseudo dice [np.float32(0.9414), np.float32(0.7733)] 
2025-03-16 14:42:30.992737: Epoch time: 37.16 s 
2025-03-16 14:42:30.996743: Yayy! New best EMA pseudo Dice: 0.7742999792098999 
2025-03-16 14:42:31.800488:  
2025-03-16 14:42:31.807047: Epoch 36 
2025-03-16 14:42:31.810581: Current learning rate: 0.00669 
2025-03-16 14:43:08.966714: train_loss -0.4687 
2025-03-16 14:43:08.973229: val_loss -0.5452 
2025-03-16 14:43:08.977739: Pseudo dice [np.float32(0.9502), np.float32(0.7254)] 
2025-03-16 14:43:08.980750: Epoch time: 37.17 s 
2025-03-16 14:43:08.984263: Yayy! New best EMA pseudo Dice: 0.7806000113487244 
2025-03-16 14:43:09.793773:  
2025-03-16 14:43:09.799791: Epoch 37 
2025-03-16 14:43:09.803797: Current learning rate: 0.0066 
2025-03-16 14:43:46.980178: train_loss -0.4855 
2025-03-16 14:43:46.986320: val_loss -0.5504 
2025-03-16 14:43:46.990329: Pseudo dice [np.float32(0.9429), np.float32(0.6918)] 
2025-03-16 14:43:46.993841: Epoch time: 37.19 s 
2025-03-16 14:43:46.997859: Yayy! New best EMA pseudo Dice: 0.7843000292778015 
2025-03-16 14:43:47.810506:  
2025-03-16 14:43:47.817575: Epoch 38 
2025-03-16 14:43:47.820718: Current learning rate: 0.0065 
2025-03-16 14:44:24.923163: train_loss -0.4848 
2025-03-16 14:44:24.929726: val_loss -0.5109 
2025-03-16 14:44:24.933783: Pseudo dice [np.float32(0.9311), np.float32(0.5655)] 
2025-03-16 14:44:24.937821: Epoch time: 37.11 s 
2025-03-16 14:44:25.562039:  
2025-03-16 14:44:25.568130: Epoch 39 
2025-03-16 14:44:25.571753: Current learning rate: 0.00641 
2025-03-16 14:45:02.716507: train_loss -0.5137 
2025-03-16 14:45:02.722553: val_loss -0.5081 
2025-03-16 14:45:02.727087: Pseudo dice [np.float32(0.9242), np.float32(0.7056)] 
2025-03-16 14:45:02.730119: Epoch time: 37.15 s 
2025-03-16 14:45:03.366424:  
2025-03-16 14:45:03.372958: Epoch 40 
2025-03-16 14:45:03.376530: Current learning rate: 0.00631 
2025-03-16 14:45:40.528749: train_loss -0.4652 
2025-03-16 14:45:40.535851: val_loss -0.4873 
2025-03-16 14:45:40.539436: Pseudo dice [np.float32(0.9321), np.float32(0.6213)] 
2025-03-16 14:45:40.542064: Epoch time: 37.16 s 
2025-03-16 14:45:41.186607:  
2025-03-16 14:45:41.192162: Epoch 41 
2025-03-16 14:45:41.196275: Current learning rate: 0.00622 
2025-03-16 14:46:18.331855: train_loss -0.5205 
2025-03-16 14:46:18.338021: val_loss -0.5548 
2025-03-16 14:46:18.342597: Pseudo dice [np.float32(0.9527), np.float32(0.6571)] 
2025-03-16 14:46:18.348185: Epoch time: 37.15 s 
2025-03-16 14:46:18.352307: Yayy! New best EMA pseudo Dice: 0.7854999899864197 
2025-03-16 14:46:19.101005:  
2025-03-16 14:46:19.107080: Epoch 42 
2025-03-16 14:46:19.110202: Current learning rate: 0.00612 
2025-03-16 14:46:56.304518: train_loss -0.5101 
2025-03-16 14:46:56.311040: val_loss -0.5229 
2025-03-16 14:46:56.314546: Pseudo dice [np.float32(0.9353), np.float32(0.6162)] 
2025-03-16 14:46:56.318559: Epoch time: 37.2 s 
2025-03-16 14:46:57.094563:  
2025-03-16 14:46:57.100079: Epoch 43 
2025-03-16 14:46:57.103588: Current learning rate: 0.00603 
2025-03-16 14:47:34.285430: train_loss -0.5017 
2025-03-16 14:47:34.291448: val_loss -0.575 
2025-03-16 14:47:34.297463: Pseudo dice [np.float32(0.9452), np.float32(0.7521)] 
2025-03-16 14:47:34.301483: Epoch time: 37.19 s 
2025-03-16 14:47:34.305493: Yayy! New best EMA pseudo Dice: 0.7910000085830688 
2025-03-16 14:47:35.074792:  
2025-03-16 14:47:35.080810: Epoch 44 
2025-03-16 14:47:35.084831: Current learning rate: 0.00593 
2025-03-16 14:48:12.277005: train_loss -0.5132 
2025-03-16 14:48:12.284529: val_loss -0.5828 
2025-03-16 14:48:12.288042: Pseudo dice [np.float32(0.9556), np.float32(0.7331)] 
2025-03-16 14:48:12.292048: Epoch time: 37.2 s 
2025-03-16 14:48:12.296559: Yayy! New best EMA pseudo Dice: 0.7962999939918518 
2025-03-16 14:48:13.090498:  
2025-03-16 14:48:13.097601: Epoch 45 
2025-03-16 14:48:13.101669: Current learning rate: 0.00584 
2025-03-16 14:48:50.280228: train_loss -0.5187 
2025-03-16 14:48:50.287754: val_loss -0.5298 
2025-03-16 14:48:50.292772: Pseudo dice [np.float32(0.9407), np.float32(0.6152)] 
2025-03-16 14:48:50.296283: Epoch time: 37.19 s 
2025-03-16 14:48:50.905097:  
2025-03-16 14:48:50.911712: Epoch 46 
2025-03-16 14:48:50.915290: Current learning rate: 0.00574 
2025-03-16 14:49:28.068047: train_loss -0.5267 
2025-03-16 14:49:28.074583: val_loss -0.5832 
2025-03-16 14:49:28.078758: Pseudo dice [np.float32(0.9436), np.float32(0.6657)] 
2025-03-16 14:49:28.083403: Epoch time: 37.16 s 
2025-03-16 14:49:28.692085:  
2025-03-16 14:49:28.698105: Epoch 47 
2025-03-16 14:49:28.700613: Current learning rate: 0.00565 
2025-03-16 14:50:05.813674: train_loss -0.5478 
2025-03-16 14:50:05.820230: val_loss -0.4826 
2025-03-16 14:50:05.824242: Pseudo dice [np.float32(0.928), np.float32(0.5876)] 
2025-03-16 14:50:05.827756: Epoch time: 37.12 s 
2025-03-16 14:50:06.441466:  
2025-03-16 14:50:06.448990: Epoch 48 
2025-03-16 14:50:06.452492: Current learning rate: 0.00555 
2025-03-16 14:50:43.580933: train_loss -0.4811 
2025-03-16 14:50:43.587449: val_loss -0.53 
2025-03-16 14:50:43.590958: Pseudo dice [np.float32(0.9299), np.float32(0.6986)] 
2025-03-16 14:50:43.594968: Epoch time: 37.14 s 
2025-03-16 14:50:44.232445:  
2025-03-16 14:50:44.239004: Epoch 49 
2025-03-16 14:50:44.242551: Current learning rate: 0.00546 
2025-03-16 14:51:21.397255: train_loss -0.5156 
2025-03-16 14:51:21.403773: val_loss -0.5634 
2025-03-16 14:51:21.407820: Pseudo dice [np.float32(0.935), np.float32(0.6433)] 
2025-03-16 14:51:21.412038: Epoch time: 37.17 s 
2025-03-16 14:51:22.182106:  
2025-03-16 14:51:22.188736: Epoch 50 
2025-03-16 14:51:22.192802: Current learning rate: 0.00536 
2025-03-16 14:51:59.389895: train_loss -0.5311 
2025-03-16 14:51:59.397413: val_loss -0.5745 
2025-03-16 14:51:59.400922: Pseudo dice [np.float32(0.9463), np.float32(0.7386)] 
2025-03-16 14:51:59.404429: Epoch time: 37.21 s 
2025-03-16 14:51:59.408443: Yayy! New best EMA pseudo Dice: 0.7983999848365784 
2025-03-16 14:52:00.339431:  
2025-03-16 14:52:00.345467: Epoch 51 
2025-03-16 14:52:00.350245: Current learning rate: 0.00526 
2025-03-16 14:52:37.328066: train_loss -0.5266 
2025-03-16 14:52:37.335086: val_loss -0.6234 
2025-03-16 14:52:37.338096: Pseudo dice [np.float32(0.9497), np.float32(0.747)] 
2025-03-16 14:52:37.341605: Epoch time: 36.99 s 
2025-03-16 14:52:37.346618: Yayy! New best EMA pseudo Dice: 0.8033999800682068 
2025-03-16 14:52:38.118228:  
2025-03-16 14:52:38.124365: Epoch 52 
2025-03-16 14:52:38.128446: Current learning rate: 0.00517 
2025-03-16 14:53:15.180447: train_loss -0.5391 
2025-03-16 14:53:15.186965: val_loss -0.5956 
2025-03-16 14:53:15.190973: Pseudo dice [np.float32(0.9495), np.float32(0.722)] 
2025-03-16 14:53:15.194484: Epoch time: 37.06 s 
2025-03-16 14:53:15.197990: Yayy! New best EMA pseudo Dice: 0.8065999746322632 
2025-03-16 14:53:15.973929:  
2025-03-16 14:53:15.980461: Epoch 53 
2025-03-16 14:53:15.983995: Current learning rate: 0.00507 
2025-03-16 14:53:52.937966: train_loss -0.5183 
2025-03-16 14:53:52.947488: val_loss -0.5855 
2025-03-16 14:53:52.950496: Pseudo dice [np.float32(0.9517), np.float32(0.7334)] 
2025-03-16 14:53:52.954006: Epoch time: 36.96 s 
2025-03-16 14:53:52.958017: Yayy! New best EMA pseudo Dice: 0.8101999759674072 
2025-03-16 14:53:53.720640:  
2025-03-16 14:53:53.725695: Epoch 54 
2025-03-16 14:53:53.729223: Current learning rate: 0.00497 
2025-03-16 14:54:30.669187: train_loss -0.5539 
2025-03-16 14:54:30.675202: val_loss -0.611 
2025-03-16 14:54:30.679210: Pseudo dice [np.float32(0.9633), np.float32(0.7467)] 
2025-03-16 14:54:30.682230: Epoch time: 36.95 s 
2025-03-16 14:54:30.686295: Yayy! New best EMA pseudo Dice: 0.8147000074386597 
2025-03-16 14:54:31.488965:  
2025-03-16 14:54:31.495548: Epoch 55 
2025-03-16 14:54:31.499601: Current learning rate: 0.00487 
2025-03-16 14:55:08.438981: train_loss -0.5634 
2025-03-16 14:55:08.445499: val_loss -0.6372 
2025-03-16 14:55:08.449507: Pseudo dice [np.float32(0.9492), np.float32(0.7973)] 
2025-03-16 14:55:08.453018: Epoch time: 36.95 s 
2025-03-16 14:55:08.457029: Yayy! New best EMA pseudo Dice: 0.8205000162124634 
2025-03-16 14:55:09.223759:  
2025-03-16 14:55:09.229776: Epoch 56 
2025-03-16 14:55:09.233281: Current learning rate: 0.00478 
2025-03-16 14:55:46.163607: train_loss -0.5602 
2025-03-16 14:55:46.171126: val_loss -0.59 
2025-03-16 14:55:46.174635: Pseudo dice [np.float32(0.9524), np.float32(0.7593)] 
2025-03-16 14:55:46.178643: Epoch time: 36.94 s 
2025-03-16 14:55:46.183154: Yayy! New best EMA pseudo Dice: 0.8241000175476074 
2025-03-16 14:55:46.989122:  
2025-03-16 14:55:46.995686: Epoch 57 
2025-03-16 14:55:46.999214: Current learning rate: 0.00468 
2025-03-16 14:56:23.938567: train_loss -0.5918 
2025-03-16 14:56:23.943584: val_loss -0.6114 
2025-03-16 14:56:23.952605: Pseudo dice [np.float32(0.9565), np.float32(0.7272)] 
2025-03-16 14:56:23.956114: Epoch time: 36.95 s 
2025-03-16 14:56:23.960127: Yayy! New best EMA pseudo Dice: 0.8258000016212463 
2025-03-16 14:56:24.776420:  
2025-03-16 14:56:24.782995: Epoch 58 
2025-03-16 14:56:24.787056: Current learning rate: 0.00458 
2025-03-16 14:57:01.743548: train_loss -0.5763 
2025-03-16 14:57:01.750564: val_loss -0.615 
2025-03-16 14:57:01.754578: Pseudo dice [np.float32(0.9531), np.float32(0.7241)] 
2025-03-16 14:57:01.758588: Epoch time: 36.97 s 
2025-03-16 14:57:01.763097: Yayy! New best EMA pseudo Dice: 0.8270999789237976 
2025-03-16 14:57:02.715397:  
2025-03-16 14:57:02.721016: Epoch 59 
2025-03-16 14:57:02.724586: Current learning rate: 0.00448 
2025-03-16 14:57:39.690514: train_loss -0.5712 
2025-03-16 14:57:39.697032: val_loss -0.5811 
2025-03-16 14:57:39.701046: Pseudo dice [np.float32(0.9484), np.float32(0.73)] 
2025-03-16 14:57:39.704558: Epoch time: 36.98 s 
2025-03-16 14:57:39.708572: Yayy! New best EMA pseudo Dice: 0.8282999992370605 
2025-03-16 14:57:40.502597:  
2025-03-16 14:57:40.509150: Epoch 60 
2025-03-16 14:57:40.513006: Current learning rate: 0.00438 
2025-03-16 14:58:17.473658: train_loss -0.5623 
2025-03-16 14:58:17.480856: val_loss -0.6043 
2025-03-16 14:58:17.483888: Pseudo dice [np.float32(0.9586), np.float32(0.6038)] 
2025-03-16 14:58:17.488428: Epoch time: 36.97 s 
2025-03-16 14:58:18.099294:  
2025-03-16 14:58:18.104808: Epoch 61 
2025-03-16 14:58:18.109316: Current learning rate: 0.00429 
2025-03-16 14:58:55.061573: train_loss -0.5811 
2025-03-16 14:58:55.067699: val_loss -0.5826 
2025-03-16 14:58:55.071708: Pseudo dice [np.float32(0.9379), np.float32(0.7677)] 
2025-03-16 14:58:55.075217: Epoch time: 36.96 s 
2025-03-16 14:58:55.687488:  
2025-03-16 14:58:55.693573: Epoch 62 
2025-03-16 14:58:55.697580: Current learning rate: 0.00419 
2025-03-16 14:59:32.618013: train_loss -0.5563 
2025-03-16 14:59:32.624527: val_loss -0.5857 
2025-03-16 14:59:32.629541: Pseudo dice [np.float32(0.9476), np.float32(0.7049)] 
2025-03-16 14:59:32.633049: Epoch time: 36.93 s 
2025-03-16 14:59:33.247282:  
2025-03-16 14:59:33.254354: Epoch 63 
2025-03-16 14:59:33.257932: Current learning rate: 0.00409 
2025-03-16 15:00:10.218978: train_loss -0.5587 
2025-03-16 15:00:10.225496: val_loss -0.5889 
2025-03-16 15:00:10.229503: Pseudo dice [np.float32(0.9455), np.float32(0.6418)] 
2025-03-16 15:00:10.234070: Epoch time: 36.97 s 
2025-03-16 15:00:10.856266:  
2025-03-16 15:00:10.863826: Epoch 64 
2025-03-16 15:00:10.867878: Current learning rate: 0.00399 
2025-03-16 15:00:47.822446: train_loss -0.5688 
2025-03-16 15:00:47.828543: val_loss -0.6045 
2025-03-16 15:00:47.832587: Pseudo dice [np.float32(0.9566), np.float32(0.6993)] 
2025-03-16 15:00:47.836645: Epoch time: 36.97 s 
2025-03-16 15:00:48.447745:  
2025-03-16 15:00:48.453258: Epoch 65 
2025-03-16 15:00:48.458272: Current learning rate: 0.00389 
2025-03-16 15:01:25.400192: train_loss -0.5369 
2025-03-16 15:01:25.406754: val_loss -0.6305 
2025-03-16 15:01:25.411292: Pseudo dice [np.float32(0.9464), np.float32(0.8286)] 
2025-03-16 15:01:25.415832: Epoch time: 36.95 s 
2025-03-16 15:01:25.419372: Yayy! New best EMA pseudo Dice: 0.8300999999046326 
2025-03-16 15:01:26.348344:  
2025-03-16 15:01:26.354944: Epoch 66 
2025-03-16 15:01:26.358974: Current learning rate: 0.00379 
2025-03-16 15:02:03.288907: train_loss -0.5468 
2025-03-16 15:02:03.296017: val_loss -0.6107 
2025-03-16 15:02:03.302032: Pseudo dice [np.float32(0.9504), np.float32(0.7568)] 
2025-03-16 15:02:03.307056: Epoch time: 36.94 s 
2025-03-16 15:02:03.310561: Yayy! New best EMA pseudo Dice: 0.8324000239372253 
2025-03-16 15:02:04.103018:  
2025-03-16 15:02:04.110583: Epoch 67 
2025-03-16 15:02:04.114616: Current learning rate: 0.00369 
2025-03-16 15:02:41.046682: train_loss -0.5662 
2025-03-16 15:02:41.053277: val_loss -0.493 
2025-03-16 15:02:41.057312: Pseudo dice [np.float32(0.9312), np.float32(0.6153)] 
2025-03-16 15:02:41.061885: Epoch time: 36.94 s 
2025-03-16 15:02:41.681611:  
2025-03-16 15:02:41.689636: Epoch 68 
2025-03-16 15:02:41.695651: Current learning rate: 0.00359 
2025-03-16 15:03:18.581890: train_loss -0.5742 
2025-03-16 15:03:18.588448: val_loss -0.5844 
2025-03-16 15:03:18.592501: Pseudo dice [np.float32(0.9596), np.float32(0.7298)] 
2025-03-16 15:03:18.596027: Epoch time: 36.9 s 
2025-03-16 15:03:19.216294:  
2025-03-16 15:03:19.222308: Epoch 69 
2025-03-16 15:03:19.226315: Current learning rate: 0.00349 
2025-03-16 15:03:56.143119: train_loss -0.6025 
2025-03-16 15:03:56.149641: val_loss -0.6316 
2025-03-16 15:03:56.153846: Pseudo dice [np.float32(0.9584), np.float32(0.7866)] 
2025-03-16 15:03:56.158357: Epoch time: 36.93 s 
2025-03-16 15:03:56.162371: Yayy! New best EMA pseudo Dice: 0.8327000141143799 
2025-03-16 15:03:56.948405:  
2025-03-16 15:03:56.954987: Epoch 70 
2025-03-16 15:03:56.959533: Current learning rate: 0.00338 
2025-03-16 15:04:33.864680: train_loss -0.5803 
2025-03-16 15:04:33.871378: val_loss -0.5729 
2025-03-16 15:04:33.876447: Pseudo dice [np.float32(0.9504), np.float32(0.7386)] 
2025-03-16 15:04:33.880488: Epoch time: 36.92 s 
2025-03-16 15:04:33.884554: Yayy! New best EMA pseudo Dice: 0.833899974822998 
2025-03-16 15:04:34.700794:  
2025-03-16 15:04:34.707381: Epoch 71 
2025-03-16 15:04:34.711430: Current learning rate: 0.00328 
2025-03-16 15:05:11.638918: train_loss -0.5846 
2025-03-16 15:05:11.646437: val_loss -0.65 
2025-03-16 15:05:11.650946: Pseudo dice [np.float32(0.9551), np.float32(0.8438)] 
2025-03-16 15:05:11.654467: Epoch time: 36.94 s 
2025-03-16 15:05:11.659026: Yayy! New best EMA pseudo Dice: 0.840499997138977 
2025-03-16 15:05:12.460842:  
2025-03-16 15:05:12.467463: Epoch 72 
2025-03-16 15:05:12.471470: Current learning rate: 0.00318 
2025-03-16 15:05:49.390757: train_loss -0.5958 
2025-03-16 15:05:49.397841: val_loss -0.609 
2025-03-16 15:05:49.402389: Pseudo dice [np.float32(0.9498), np.float32(0.6841)] 
2025-03-16 15:05:49.406491: Epoch time: 36.93 s 
2025-03-16 15:05:50.032434:  
2025-03-16 15:05:50.038503: Epoch 73 
2025-03-16 15:05:50.041571: Current learning rate: 0.00308 
2025-03-16 15:06:26.984731: train_loss -0.5936 
2025-03-16 15:06:26.991322: val_loss -0.596 
2025-03-16 15:06:26.996384: Pseudo dice [np.float32(0.9564), np.float32(0.7017)] 
2025-03-16 15:06:27.000459: Epoch time: 36.95 s 
2025-03-16 15:06:27.817270:  
2025-03-16 15:06:27.823874: Epoch 74 
2025-03-16 15:06:27.827937: Current learning rate: 0.00297 
2025-03-16 15:07:04.739799: train_loss -0.6118 
2025-03-16 15:07:04.744822: val_loss -0.6665 
2025-03-16 15:07:04.749465: Pseudo dice [np.float32(0.9606), np.float32(0.8426)] 
2025-03-16 15:07:04.753532: Epoch time: 36.92 s 
2025-03-16 15:07:04.756072: Yayy! New best EMA pseudo Dice: 0.8436999917030334 
2025-03-16 15:07:05.538823:  
2025-03-16 15:07:05.545893: Epoch 75 
2025-03-16 15:07:05.549494: Current learning rate: 0.00287 
2025-03-16 15:07:42.459922: train_loss -0.5892 
2025-03-16 15:07:42.468010: val_loss -0.6471 
2025-03-16 15:07:42.472019: Pseudo dice [np.float32(0.9572), np.float32(0.8349)] 
2025-03-16 15:07:42.475531: Epoch time: 36.92 s 
2025-03-16 15:07:42.480547: Yayy! New best EMA pseudo Dice: 0.8489000201225281 
2025-03-16 15:07:43.273365:  
2025-03-16 15:07:43.280940: Epoch 76 
2025-03-16 15:07:43.285512: Current learning rate: 0.00277 
2025-03-16 15:08:20.234346: train_loss -0.5886 
2025-03-16 15:08:20.241376: val_loss -0.6698 
2025-03-16 15:08:20.245420: Pseudo dice [np.float32(0.9566), np.float32(0.7948)] 
2025-03-16 15:08:20.249435: Epoch time: 36.96 s 
2025-03-16 15:08:20.252951: Yayy! New best EMA pseudo Dice: 0.8515999913215637 
2025-03-16 15:08:21.047289:  
2025-03-16 15:08:21.052837: Epoch 77 
2025-03-16 15:08:21.057522: Current learning rate: 0.00266 
2025-03-16 15:08:58.044811: train_loss -0.5942 
2025-03-16 15:08:58.052335: val_loss -0.6321 
2025-03-16 15:08:58.056345: Pseudo dice [np.float32(0.9566), np.float32(0.7233)] 
2025-03-16 15:08:58.061392: Epoch time: 37.0 s 
2025-03-16 15:08:58.702163:  
2025-03-16 15:08:58.708180: Epoch 78 
2025-03-16 15:08:58.712189: Current learning rate: 0.00256 
2025-03-16 15:09:35.586818: train_loss -0.6119 
2025-03-16 15:09:35.594449: val_loss -0.6289 
2025-03-16 15:09:35.598505: Pseudo dice [np.float32(0.9587), np.float32(0.8517)] 
2025-03-16 15:09:35.603046: Epoch time: 36.89 s 
2025-03-16 15:09:35.607582: Yayy! New best EMA pseudo Dice: 0.85589998960495 
2025-03-16 15:09:36.404505:  
2025-03-16 15:09:36.411562: Epoch 79 
2025-03-16 15:09:36.416191: Current learning rate: 0.00245 
2025-03-16 15:10:13.345188: train_loss -0.6093 
2025-03-16 15:10:13.352206: val_loss -0.6483 
2025-03-16 15:10:13.356220: Pseudo dice [np.float32(0.9604), np.float32(0.7932)] 
2025-03-16 15:10:13.360229: Epoch time: 36.94 s 
2025-03-16 15:10:13.365240: Yayy! New best EMA pseudo Dice: 0.8579999804496765 
2025-03-16 15:10:14.174241:  
2025-03-16 15:10:14.180812: Epoch 80 
2025-03-16 15:10:14.185924: Current learning rate: 0.00235 
2025-03-16 15:10:51.108306: train_loss -0.6204 
2025-03-16 15:10:51.117326: val_loss -0.6382 
2025-03-16 15:10:51.122337: Pseudo dice [np.float32(0.9581), np.float32(0.8142)] 
2025-03-16 15:10:51.127861: Epoch time: 36.93 s 
2025-03-16 15:10:51.130886: Yayy! New best EMA pseudo Dice: 0.86080002784729 
2025-03-16 15:10:52.111628:  
2025-03-16 15:10:52.117141: Epoch 81 
2025-03-16 15:10:52.120651: Current learning rate: 0.00224 
2025-03-16 15:11:29.053820: train_loss -0.5551 
2025-03-16 15:11:29.059873: val_loss -0.6454 
2025-03-16 15:11:29.063887: Pseudo dice [np.float32(0.9609), np.float32(0.7738)] 
2025-03-16 15:11:29.067397: Epoch time: 36.94 s 
2025-03-16 15:11:29.071407: Yayy! New best EMA pseudo Dice: 0.8615000247955322 
2025-03-16 15:11:29.872281:  
2025-03-16 15:11:29.878845: Epoch 82 
2025-03-16 15:11:29.881454: Current learning rate: 0.00214 
2025-03-16 15:12:06.787099: train_loss -0.6086 
2025-03-16 15:12:06.793138: val_loss -0.6459 
2025-03-16 15:12:06.797173: Pseudo dice [np.float32(0.9604), np.float32(0.844)] 
2025-03-16 15:12:06.800200: Epoch time: 36.91 s 
2025-03-16 15:12:06.803710: Yayy! New best EMA pseudo Dice: 0.8654999732971191 
2025-03-16 15:12:07.571148:  
2025-03-16 15:12:07.577215: Epoch 83 
2025-03-16 15:12:07.581283: Current learning rate: 0.00203 
2025-03-16 15:12:44.528140: train_loss -0.643 
2025-03-16 15:12:44.534154: val_loss -0.6061 
2025-03-16 15:12:44.538167: Pseudo dice [np.float32(0.955), np.float32(0.7436)] 
2025-03-16 15:12:44.542178: Epoch time: 36.96 s 
2025-03-16 15:12:45.132332:  
2025-03-16 15:12:45.140459: Epoch 84 
2025-03-16 15:12:45.148049: Current learning rate: 0.00192 
2025-03-16 15:13:22.077428: train_loss -0.621 
2025-03-16 15:13:22.083940: val_loss -0.6396 
2025-03-16 15:13:22.086984: Pseudo dice [np.float32(0.9583), np.float32(0.765)] 
2025-03-16 15:13:22.091516: Epoch time: 36.95 s 
2025-03-16 15:13:22.688044:  
2025-03-16 15:13:22.693589: Epoch 85 
2025-03-16 15:13:22.697610: Current learning rate: 0.00181 
2025-03-16 15:13:59.589122: train_loss -0.6136 
2025-03-16 15:13:59.595187: val_loss -0.5904 
2025-03-16 15:13:59.598820: Pseudo dice [np.float32(0.9594), np.float32(0.6906)] 
2025-03-16 15:13:59.601860: Epoch time: 36.9 s 
2025-03-16 15:14:00.208968:  
2025-03-16 15:14:00.214980: Epoch 86 
2025-03-16 15:14:00.218489: Current learning rate: 0.0017 
2025-03-16 15:14:37.129614: train_loss -0.6048 
2025-03-16 15:14:37.136132: val_loss -0.6401 
2025-03-16 15:14:37.140644: Pseudo dice [np.float32(0.9645), np.float32(0.7892)] 
2025-03-16 15:14:37.143653: Epoch time: 36.92 s 
2025-03-16 15:14:37.736668:  
2025-03-16 15:14:37.742298: Epoch 87 
2025-03-16 15:14:37.746358: Current learning rate: 0.00159 
2025-03-16 15:15:14.646656: train_loss -0.6295 
2025-03-16 15:15:14.653168: val_loss -0.649 
2025-03-16 15:15:14.657685: Pseudo dice [np.float32(0.9615), np.float32(0.8422)] 
2025-03-16 15:15:14.660695: Epoch time: 36.91 s 
2025-03-16 15:15:14.664212: Yayy! New best EMA pseudo Dice: 0.8654999732971191 
2025-03-16 15:15:15.410259:  
2025-03-16 15:15:15.415772: Epoch 88 
2025-03-16 15:15:15.419280: Current learning rate: 0.00148 
2025-03-16 15:15:52.304659: train_loss -0.5997 
2025-03-16 15:15:52.310671: val_loss -0.6254 
2025-03-16 15:15:52.314256: Pseudo dice [np.float32(0.9474), np.float32(0.804)] 
2025-03-16 15:15:52.317811: Epoch time: 36.89 s 
2025-03-16 15:15:52.321837: Yayy! New best EMA pseudo Dice: 0.866599977016449 
2025-03-16 15:15:53.303374:  
2025-03-16 15:15:53.308248: Epoch 89 
2025-03-16 15:15:53.312761: Current learning rate: 0.00137 
2025-03-16 15:16:30.222155: train_loss -0.6069 
2025-03-16 15:16:30.228172: val_loss -0.6598 
2025-03-16 15:16:30.232184: Pseudo dice [np.float32(0.9619), np.float32(0.7931)] 
2025-03-16 15:16:30.235693: Epoch time: 36.92 s 
2025-03-16 15:16:30.240705: Yayy! New best EMA pseudo Dice: 0.8676999807357788 
2025-03-16 15:16:31.022333:  
2025-03-16 15:16:31.028878: Epoch 90 
2025-03-16 15:16:31.032974: Current learning rate: 0.00126 
2025-03-16 15:17:07.939152: train_loss -0.637 
2025-03-16 15:17:07.945862: val_loss -0.6294 
2025-03-16 15:17:07.949985: Pseudo dice [np.float32(0.9567), np.float32(0.7954)] 
2025-03-16 15:17:07.954021: Epoch time: 36.92 s 
2025-03-16 15:17:07.958099: Yayy! New best EMA pseudo Dice: 0.8684999942779541 
2025-03-16 15:17:08.731818:  
2025-03-16 15:17:08.736885: Epoch 91 
2025-03-16 15:17:08.741468: Current learning rate: 0.00115 
2025-03-16 15:17:45.634296: train_loss -0.6252 
2025-03-16 15:17:45.641817: val_loss -0.6623 
2025-03-16 15:17:45.645835: Pseudo dice [np.float32(0.9582), np.float32(0.8589)] 
2025-03-16 15:17:45.649849: Epoch time: 36.9 s 
2025-03-16 15:17:45.654359: Yayy! New best EMA pseudo Dice: 0.8725000023841858 
2025-03-16 15:17:46.441621:  
2025-03-16 15:17:46.447269: Epoch 92 
2025-03-16 15:17:46.452356: Current learning rate: 0.00103 
2025-03-16 15:18:23.398764: train_loss -0.6258 
2025-03-16 15:18:23.406469: val_loss -0.6121 
2025-03-16 15:18:23.409982: Pseudo dice [np.float32(0.9543), np.float32(0.7205)] 
2025-03-16 15:18:23.414999: Epoch time: 36.96 s 
2025-03-16 15:18:24.014439:  
2025-03-16 15:18:24.020492: Epoch 93 
2025-03-16 15:18:24.025513: Current learning rate: 0.00091 
2025-03-16 15:19:00.953177: train_loss -0.6219 
2025-03-16 15:19:00.960317: val_loss -0.6536 
2025-03-16 15:19:00.965568: Pseudo dice [np.float32(0.9555), np.float32(0.8163)] 
2025-03-16 15:19:00.969658: Epoch time: 36.94 s 
2025-03-16 15:19:01.586797:  
2025-03-16 15:19:01.592828: Epoch 94 
2025-03-16 15:19:01.597891: Current learning rate: 0.00079 
2025-03-16 15:19:38.525475: train_loss -0.6264 
2025-03-16 15:19:38.532999: val_loss -0.6226 
2025-03-16 15:19:38.537015: Pseudo dice [np.float32(0.9418), np.float32(0.8028)] 
2025-03-16 15:19:38.540523: Epoch time: 36.94 s 
2025-03-16 15:19:39.134882:  
2025-03-16 15:19:39.141447: Epoch 95 
2025-03-16 15:19:39.146000: Current learning rate: 0.00067 
2025-03-16 15:20:16.055024: train_loss -0.6191 
2025-03-16 15:20:16.060682: val_loss -0.6488 
2025-03-16 15:20:16.065751: Pseudo dice [np.float32(0.9565), np.float32(0.8093)] 
2025-03-16 15:20:16.068801: Epoch time: 36.92 s 
2025-03-16 15:20:16.678946:  
2025-03-16 15:20:16.685530: Epoch 96 
2025-03-16 15:20:16.690246: Current learning rate: 0.00055 
2025-03-16 15:20:53.633311: train_loss -0.6453 
2025-03-16 15:20:53.640927: val_loss -0.6506 
2025-03-16 15:20:53.645561: Pseudo dice [np.float32(0.9588), np.float32(0.8022)] 
2025-03-16 15:20:53.649156: Epoch time: 36.96 s 
2025-03-16 15:20:53.654173: Yayy! New best EMA pseudo Dice: 0.8729000091552734 
2025-03-16 15:20:54.405637:  
2025-03-16 15:20:54.412194: Epoch 97 
2025-03-16 15:20:54.416246: Current learning rate: 0.00043 
2025-03-16 15:21:31.496029: train_loss -0.6532 
2025-03-16 15:21:31.503787: val_loss -0.6259 
2025-03-16 15:21:31.508027: Pseudo dice [np.float32(0.9607), np.float32(0.8194)] 
2025-03-16 15:21:31.512166: Epoch time: 37.09 s 
2025-03-16 15:21:31.515799: Yayy! New best EMA pseudo Dice: 0.8745999932289124 
2025-03-16 15:21:32.292726:  
2025-03-16 15:21:32.298275: Epoch 98 
2025-03-16 15:21:32.303898: Current learning rate: 0.0003 
2025-03-16 15:22:09.214852: train_loss -0.628 
2025-03-16 15:22:09.222468: val_loss -0.6572 
2025-03-16 15:22:09.227026: Pseudo dice [np.float32(0.9692), np.float32(0.8204)] 
2025-03-16 15:22:09.231046: Epoch time: 36.92 s 
2025-03-16 15:22:09.235058: Yayy! New best EMA pseudo Dice: 0.8766000270843506 
2025-03-16 15:22:10.004693:  
2025-03-16 15:22:10.011751: Epoch 99 
2025-03-16 15:22:10.015880: Current learning rate: 0.00016 
2025-03-16 15:22:46.914593: train_loss -0.6488 
2025-03-16 15:22:46.921721: val_loss -0.6823 
2025-03-16 15:22:46.926468: Pseudo dice [np.float32(0.9625), np.float32(0.8167)] 
2025-03-16 15:22:46.930557: Epoch time: 36.91 s 
2025-03-16 15:22:46.935141: Yayy! New best EMA pseudo Dice: 0.8779000043869019 
2025-03-16 15:22:47.910006: Training done. 
2025-03-16 15:22:47.942008: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset003_Liver\splits_final.json 
2025-03-16 15:22:47.951014: The split file contains 5 splits. 
2025-03-16 15:22:47.956009: Desired fold for training: 0 
2025-03-16 15:22:47.962518: This split has 104 training and 27 validation cases. 
2025-03-16 15:22:47.967518: predicting liver_101 
2025-03-16 15:22:47.975518: liver_101, shape torch.Size([1, 478, 470, 470]), rank 0 
2025-03-16 15:23:42.959175: predicting liver_11 
2025-03-16 15:23:43.002177: liver_11, shape torch.Size([1, 466, 448, 448]), rank 0 
2025-03-16 15:24:22.984084: predicting liver_112 
2025-03-16 15:24:23.025085: liver_112, shape torch.Size([1, 601, 427, 427]), rank 0 
2025-03-16 15:25:14.421636: predicting liver_115 
2025-03-16 15:25:14.473145: liver_115, shape torch.Size([1, 677, 504, 504]), rank 0 
2025-03-16 15:26:31.985072: predicting liver_12 
2025-03-16 15:26:32.054579: liver_12, shape torch.Size([1, 455, 436, 436]), rank 0 
2025-03-16 15:27:12.060031: predicting liver_120 
2025-03-16 15:27:12.099031: liver_120, shape torch.Size([1, 636, 496, 496]), rank 0 
2025-03-16 15:28:21.819985: predicting liver_128 
2025-03-16 15:28:21.872985: liver_128, shape torch.Size([1, 458, 521, 521]), rank 0 
2025-03-16 15:29:32.693863: predicting liver_17 
2025-03-16 15:29:32.753374: liver_17, shape torch.Size([1, 661, 496, 496]), rank 0 
2025-03-16 15:30:50.162241: predicting liver_19 
2025-03-16 15:30:50.227749: liver_19, shape torch.Size([1, 438, 502, 502]), rank 0 
2025-03-16 15:31:36.911233: predicting liver_24 
2025-03-16 15:31:36.960742: liver_24, shape torch.Size([1, 414, 447, 447]), rank 0 
2025-03-16 15:32:11.321551: predicting liver_25 
2025-03-16 15:32:11.353553: liver_25, shape torch.Size([1, 421, 512, 512]), rank 0 
2025-03-16 15:32:57.885396: predicting liver_27 
2025-03-16 15:32:57.941903: liver_27, shape torch.Size([1, 603, 492, 492]), rank 0 
2025-03-16 15:34:07.787841: predicting liver_3 
2025-03-16 15:34:07.847844: liver_3, shape torch.Size([1, 534, 462, 462]), rank 0 
2025-03-16 15:35:09.880077: predicting liver_38 
2025-03-16 15:35:09.936582: liver_38, shape torch.Size([1, 132, 667, 667]), rank 0 
2025-03-16 15:35:41.666568: predicting liver_40 
2025-03-16 15:35:41.692568: liver_40, shape torch.Size([1, 122, 667, 667]), rank 0 
2025-03-16 15:35:57.746616: predicting liver_41 
2025-03-16 15:35:57.773618: liver_41, shape torch.Size([1, 113, 667, 667]), rank 0 
2025-03-16 15:36:13.783828: predicting liver_42 
2025-03-16 15:36:13.810828: liver_42, shape torch.Size([1, 125, 667, 667]), rank 0 
2025-03-16 15:36:29.814773: predicting liver_44 
2025-03-16 15:36:29.847777: liver_44, shape torch.Size([1, 119, 667, 667]), rank 0 
2025-03-16 15:36:45.849964: predicting liver_5 
2025-03-16 15:36:45.876130: liver_5, shape torch.Size([1, 430, 646, 646]), rank 0 
2025-03-16 15:38:20.735613: predicting liver_51 
2025-03-16 15:38:20.800612: liver_51, shape torch.Size([1, 681, 602, 602]), rank 0 
2025-03-16 15:40:28.878392: predicting liver_52 
2025-03-16 15:40:28.966904: liver_52, shape torch.Size([1, 592, 558, 558]), rank 0 
2025-03-16 15:42:00.313881: predicting liver_58 
2025-03-16 15:42:00.389883: liver_58, shape torch.Size([1, 424, 456, 456]), rank 0 
2025-03-16 15:42:47.034096: predicting liver_64 
2025-03-16 15:42:47.070096: liver_64, shape torch.Size([1, 460, 519, 519]), rank 0 
2025-03-16 15:43:57.837475: predicting liver_70 
2025-03-16 15:43:57.883479: liver_70, shape torch.Size([1, 416, 399, 399]), rank 0 
2025-03-16 15:44:32.159659: predicting liver_75 
2025-03-16 15:44:32.189661: liver_75, shape torch.Size([1, 445, 505, 505]), rank 0 
2025-03-16 15:45:18.813272: predicting liver_77 
2025-03-16 15:45:18.865785: liver_77, shape torch.Size([1, 470, 521, 521]), rank 0 
2025-03-16 15:46:29.687663: predicting liver_82 
2025-03-16 15:46:29.740663: liver_82, shape torch.Size([1, 416, 417, 417]), rank 0 
2025-03-16 15:47:33.417152: Validation complete 
2025-03-16 15:47:33.423149: Mean Validation Dice:  0.6772781629741612 
