
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-03 16:18:05.587056: do_dummy_2d_data_aug: False 
2025-01-03 16:18:05.595318: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset003_Liver\splits_final.json 
2025-01-03 16:18:05.602322: The split file contains 5 splits. 
2025-01-03 16:18:05.605320: Desired fold for training: 1 
2025-01-03 16:18:05.607321: This split has 105 training and 26 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [482.0, 512.0, 512.0], 'spacing': [1.0, 0.767578125, 0.767578125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset003_Liver', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 0.767578125, 0.767578125], 'original_median_shape_after_transp': [432, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5420.0, 'mean': 99.48007202148438, 'median': 101.0, 'min': -983.0, 'percentile_00_5': -15.0, 'percentile_99_5': 197.0, 'std': 37.13840103149414}}} 
 
2025-01-03 16:18:21.239981: unpacking dataset... 
2025-01-03 16:19:21.248566: unpacking done... 
2025-01-03 16:19:26.556400:  
2025-01-03 16:19:26.556400: Epoch 0 
2025-01-03 16:19:26.562434: Current learning rate: 0.01 
2025-01-03 16:20:09.437370: train_loss 0.0781 
2025-01-03 16:20:09.437370: val_loss -0.1049 
2025-01-03 16:20:09.444584: Pseudo dice [np.float32(0.8001), np.float32(0.0)] 
2025-01-03 16:20:09.447645: Epoch time: 42.88 s 
2025-01-03 16:20:09.451214: Yayy! New best EMA pseudo Dice: 0.4000999927520752 
2025-01-03 16:20:10.191826:  
2025-01-03 16:20:10.192831: Epoch 1 
2025-01-03 16:20:10.197412: Current learning rate: 0.00991 
2025-01-03 16:20:48.237326: train_loss -0.04 
2025-01-03 16:20:48.238330: val_loss 0.1023 
2025-01-03 16:20:48.243345: Pseudo dice [np.float32(0.7009), np.float32(0.0)] 
2025-01-03 16:20:48.247354: Epoch time: 38.05 s 
2025-01-03 16:20:48.881639:  
2025-01-03 16:20:48.882352: Epoch 2 
2025-01-03 16:20:48.888371: Current learning rate: 0.00982 
2025-01-03 16:21:27.239319: train_loss -0.1747 
2025-01-03 16:21:27.240324: val_loss -0.2318 
2025-01-03 16:21:27.246841: Pseudo dice [np.float32(0.8558), np.float32(0.2372)] 
2025-01-03 16:21:27.250350: Epoch time: 38.36 s 
2025-01-03 16:21:27.254393: Yayy! New best EMA pseudo Dice: 0.41019999980926514 
2025-01-03 16:21:28.077278:  
2025-01-03 16:21:28.077788: Epoch 3 
2025-01-03 16:21:28.083352: Current learning rate: 0.00973 
2025-01-03 16:22:06.423584: train_loss -0.2058 
2025-01-03 16:22:06.424589: val_loss -0.2922 
2025-01-03 16:22:06.431110: Pseudo dice [np.float32(0.8593), np.float32(0.4368)] 
2025-01-03 16:22:06.434624: Epoch time: 38.35 s 
2025-01-03 16:22:06.438131: Yayy! New best EMA pseudo Dice: 0.4339999854564667 
2025-01-03 16:22:07.250379:  
2025-01-03 16:22:07.250881: Epoch 4 
2025-01-03 16:22:07.257481: Current learning rate: 0.00964 
2025-01-03 16:22:45.505622: train_loss -0.2613 
2025-01-03 16:22:45.506135: val_loss -0.257 
2025-01-03 16:22:45.511696: Pseudo dice [np.float32(0.8545), np.float32(0.4119)] 
2025-01-03 16:22:45.516756: Epoch time: 38.26 s 
2025-01-03 16:22:45.520290: Yayy! New best EMA pseudo Dice: 0.453900009393692 
2025-01-03 16:22:46.481198:  
2025-01-03 16:22:46.482703: Epoch 5 
2025-01-03 16:22:46.488725: Current learning rate: 0.00955 
2025-01-03 16:23:24.864254: train_loss -0.2666 
2025-01-03 16:23:24.865258: val_loss -0.2367 
2025-01-03 16:23:24.871780: Pseudo dice [np.float32(0.8422), np.float32(0.3885)] 
2025-01-03 16:23:24.876294: Epoch time: 38.38 s 
2025-01-03 16:23:24.879351: Yayy! New best EMA pseudo Dice: 0.4700999855995178 
2025-01-03 16:23:25.685310:  
2025-01-03 16:23:25.685818: Epoch 6 
2025-01-03 16:23:25.692446: Current learning rate: 0.00946 
2025-01-03 16:24:03.933415: train_loss -0.3092 
2025-01-03 16:24:03.934422: val_loss -0.3521 
2025-01-03 16:24:03.939432: Pseudo dice [np.float32(0.8906), np.float32(0.4078)] 
2025-01-03 16:24:03.943444: Epoch time: 38.25 s 
2025-01-03 16:24:03.946955: Yayy! New best EMA pseudo Dice: 0.4880000054836273 
2025-01-03 16:24:04.723708:  
2025-01-03 16:24:04.723708: Epoch 7 
2025-01-03 16:24:04.728753: Current learning rate: 0.00937 
2025-01-03 16:24:42.639050: train_loss -0.3092 
2025-01-03 16:24:42.639050: val_loss -0.3433 
2025-01-03 16:24:42.645610: Pseudo dice [np.float32(0.8706), np.float32(0.5139)] 
2025-01-03 16:24:42.649121: Epoch time: 37.92 s 
2025-01-03 16:24:42.653132: Yayy! New best EMA pseudo Dice: 0.508400022983551 
2025-01-03 16:24:43.515468:  
2025-01-03 16:24:43.516474: Epoch 8 
2025-01-03 16:24:43.523192: Current learning rate: 0.00928 
2025-01-03 16:25:22.622503: train_loss -0.3618 
2025-01-03 16:25:22.623502: val_loss -0.2778 
2025-01-03 16:25:22.629024: Pseudo dice [np.float32(0.8781), np.float32(0.388)] 
2025-01-03 16:25:22.632534: Epoch time: 39.11 s 
2025-01-03 16:25:22.636547: Yayy! New best EMA pseudo Dice: 0.5209000110626221 
2025-01-03 16:25:23.497045:  
2025-01-03 16:25:23.498049: Epoch 9 
2025-01-03 16:25:23.504112: Current learning rate: 0.00919 
2025-01-03 16:26:02.835771: train_loss -0.3652 
2025-01-03 16:26:02.836774: val_loss -0.3873 
2025-01-03 16:26:02.843296: Pseudo dice [np.float32(0.8953), np.float32(0.5133)] 
2025-01-03 16:26:02.846811: Epoch time: 39.34 s 
2025-01-03 16:26:02.850822: Yayy! New best EMA pseudo Dice: 0.5392000079154968 
2025-01-03 16:26:03.668404:  
2025-01-03 16:26:03.668404: Epoch 10 
2025-01-03 16:26:03.674424: Current learning rate: 0.0091 
2025-01-03 16:26:41.473904: train_loss -0.3836 
2025-01-03 16:26:41.474908: val_loss -0.3541 
2025-01-03 16:26:41.481428: Pseudo dice [np.float32(0.9068), np.float32(0.3046)] 
2025-01-03 16:26:41.484940: Epoch time: 37.81 s 
2025-01-03 16:26:41.487446: Yayy! New best EMA pseudo Dice: 0.5458999872207642 
2025-01-03 16:26:42.310781:  
2025-01-03 16:26:42.311285: Epoch 11 
2025-01-03 16:26:42.316298: Current learning rate: 0.009 
2025-01-03 16:27:19.700219: train_loss -0.3432 
2025-01-03 16:27:19.700733: val_loss -0.3149 
2025-01-03 16:27:19.707585: Pseudo dice [np.float32(0.8779), np.float32(0.411)] 
2025-01-03 16:27:19.713948: Epoch time: 37.39 s 
2025-01-03 16:27:19.719638: Yayy! New best EMA pseudo Dice: 0.5557000041007996 
2025-01-03 16:27:20.579054:  
2025-01-03 16:27:20.579054: Epoch 12 
2025-01-03 16:27:20.585072: Current learning rate: 0.00891 
2025-01-03 16:27:57.977580: train_loss -0.3993 
2025-01-03 16:27:57.979085: val_loss -0.3902 
2025-01-03 16:27:57.985107: Pseudo dice [np.float32(0.89), np.float32(0.4065)] 
2025-01-03 16:27:57.989120: Epoch time: 37.4 s 
2025-01-03 16:27:57.992688: Yayy! New best EMA pseudo Dice: 0.5649999976158142 
2025-01-03 16:27:58.948863:  
2025-01-03 16:27:58.948863: Epoch 13 
2025-01-03 16:27:58.954887: Current learning rate: 0.00882 
2025-01-03 16:28:36.374928: train_loss -0.4049 
2025-01-03 16:28:36.375432: val_loss -0.4447 
2025-01-03 16:28:36.382056: Pseudo dice [np.float32(0.9126), np.float32(0.4306)] 
2025-01-03 16:28:36.385148: Epoch time: 37.43 s 
2025-01-03 16:28:36.388657: Yayy! New best EMA pseudo Dice: 0.5756000280380249 
2025-01-03 16:28:37.171857:  
2025-01-03 16:28:37.172359: Epoch 14 
2025-01-03 16:28:37.177372: Current learning rate: 0.00873 
2025-01-03 16:29:14.332326: train_loss -0.4147 
2025-01-03 16:29:14.332326: val_loss -0.4311 
2025-01-03 16:29:14.339482: Pseudo dice [np.float32(0.9167), np.float32(0.5094)] 
2025-01-03 16:29:14.342591: Epoch time: 37.16 s 
2025-01-03 16:29:14.346703: Yayy! New best EMA pseudo Dice: 0.5893999934196472 
2025-01-03 16:29:15.201819:  
2025-01-03 16:29:15.202820: Epoch 15 
2025-01-03 16:29:15.208347: Current learning rate: 0.00864 
2025-01-03 16:29:52.381299: train_loss -0.3916 
2025-01-03 16:29:52.381812: val_loss -0.3989 
2025-01-03 16:29:52.386855: Pseudo dice [np.float32(0.9008), np.float32(0.4174)] 
2025-01-03 16:29:52.390883: Epoch time: 37.18 s 
2025-01-03 16:29:52.393909: Yayy! New best EMA pseudo Dice: 0.5964000225067139 
2025-01-03 16:29:53.205527:  
2025-01-03 16:29:53.206525: Epoch 16 
2025-01-03 16:29:53.212179: Current learning rate: 0.00855 
2025-01-03 16:30:31.330152: train_loss -0.4077 
2025-01-03 16:30:31.330657: val_loss -0.3276 
2025-01-03 16:30:31.336677: Pseudo dice [np.float32(0.8764), np.float32(0.4214)] 
2025-01-03 16:30:31.340686: Epoch time: 38.12 s 
2025-01-03 16:30:31.343193: Yayy! New best EMA pseudo Dice: 0.6015999913215637 
2025-01-03 16:30:32.129828:  
2025-01-03 16:30:32.129828: Epoch 17 
2025-01-03 16:30:32.134886: Current learning rate: 0.00846 
2025-01-03 16:31:09.758395: train_loss -0.3888 
2025-01-03 16:31:09.758898: val_loss -0.3235 
2025-01-03 16:31:09.765490: Pseudo dice [np.float32(0.8777), np.float32(0.3756)] 
2025-01-03 16:31:09.768613: Epoch time: 37.63 s 
2025-01-03 16:31:09.772211: Yayy! New best EMA pseudo Dice: 0.6040999889373779 
2025-01-03 16:31:10.552260:  
2025-01-03 16:31:10.553266: Epoch 18 
2025-01-03 16:31:10.559293: Current learning rate: 0.00836 
2025-01-03 16:31:48.306652: train_loss -0.44 
2025-01-03 16:31:48.307657: val_loss -0.4189 
2025-01-03 16:31:48.311696: Pseudo dice [np.float32(0.9194), np.float32(0.3969)] 
2025-01-03 16:31:48.314232: Epoch time: 37.75 s 
2025-01-03 16:31:48.317873: Yayy! New best EMA pseudo Dice: 0.609499990940094 
2025-01-03 16:31:49.115488:  
2025-01-03 16:31:49.116492: Epoch 19 
2025-01-03 16:31:49.123040: Current learning rate: 0.00827 
2025-01-03 16:32:26.303010: train_loss -0.4359 
2025-01-03 16:32:26.303514: val_loss -0.4965 
2025-01-03 16:32:26.309531: Pseudo dice [np.float32(0.934), np.float32(0.6073)] 
2025-01-03 16:32:26.313039: Epoch time: 37.19 s 
2025-01-03 16:32:26.316049: Yayy! New best EMA pseudo Dice: 0.6255999803543091 
2025-01-03 16:32:27.244993:  
2025-01-03 16:32:27.245993: Epoch 20 
2025-01-03 16:32:27.251573: Current learning rate: 0.00818 
2025-01-03 16:33:04.459646: train_loss -0.4308 
2025-01-03 16:33:04.460652: val_loss -0.377 
2025-01-03 16:33:04.467166: Pseudo dice [np.float32(0.9065), np.float32(0.4999)] 
2025-01-03 16:33:04.470677: Epoch time: 37.21 s 
2025-01-03 16:33:04.474690: Yayy! New best EMA pseudo Dice: 0.633400022983551 
2025-01-03 16:33:05.256524:  
2025-01-03 16:33:05.256524: Epoch 21 
2025-01-03 16:33:05.262328: Current learning rate: 0.00809 
2025-01-03 16:33:42.530032: train_loss -0.4389 
2025-01-03 16:33:42.531032: val_loss -0.3225 
2025-01-03 16:33:42.537582: Pseudo dice [np.float32(0.8767), np.float32(0.3247)] 
2025-01-03 16:33:42.541592: Epoch time: 37.27 s 
2025-01-03 16:33:43.133566:  
2025-01-03 16:33:43.134569: Epoch 22 
2025-01-03 16:33:43.139124: Current learning rate: 0.008 
2025-01-03 16:34:20.379928: train_loss -0.4605 
2025-01-03 16:34:20.380928: val_loss -0.4255 
2025-01-03 16:34:20.386441: Pseudo dice [np.float32(0.9166), np.float32(0.4167)] 
2025-01-03 16:34:20.390951: Epoch time: 37.25 s 
2025-01-03 16:34:20.394476: Yayy! New best EMA pseudo Dice: 0.6338000297546387 
2025-01-03 16:34:21.131671:  
2025-01-03 16:34:21.131671: Epoch 23 
2025-01-03 16:34:21.137703: Current learning rate: 0.0079 
2025-01-03 16:34:58.360917: train_loss -0.4717 
2025-01-03 16:34:58.361919: val_loss -0.4761 
2025-01-03 16:34:58.368554: Pseudo dice [np.float32(0.9225), np.float32(0.5742)] 
2025-01-03 16:34:58.372593: Epoch time: 37.23 s 
2025-01-03 16:34:58.376117: Yayy! New best EMA pseudo Dice: 0.6452000141143799 
2025-01-03 16:34:59.114764:  
2025-01-03 16:34:59.115767: Epoch 24 
2025-01-03 16:34:59.121302: Current learning rate: 0.00781 
2025-01-03 16:35:36.265648: train_loss -0.4724 
2025-01-03 16:35:36.266157: val_loss -0.3756 
2025-01-03 16:35:36.273739: Pseudo dice [np.float32(0.8924), np.float32(0.5074)] 
2025-01-03 16:35:36.277967: Epoch time: 37.15 s 
2025-01-03 16:35:36.281531: Yayy! New best EMA pseudo Dice: 0.6506999731063843 
2025-01-03 16:35:37.033199:  
2025-01-03 16:35:37.034199: Epoch 25 
2025-01-03 16:35:37.039830: Current learning rate: 0.00772 
2025-01-03 16:36:14.192409: train_loss -0.4773 
2025-01-03 16:36:14.193412: val_loss -0.3182 
2025-01-03 16:36:14.200930: Pseudo dice [np.float32(0.88), np.float32(0.3544)] 
2025-01-03 16:36:14.205941: Epoch time: 37.16 s 
2025-01-03 16:36:14.850486:  
2025-01-03 16:36:14.850486: Epoch 26 
2025-01-03 16:36:14.856062: Current learning rate: 0.00763 
2025-01-03 16:36:52.139511: train_loss -0.48 
2025-01-03 16:36:52.140514: val_loss -0.362 
2025-01-03 16:36:52.147071: Pseudo dice [np.float32(0.8767), np.float32(0.5707)] 
2025-01-03 16:36:52.150660: Epoch time: 37.29 s 
2025-01-03 16:36:52.153702: Yayy! New best EMA pseudo Dice: 0.6549999713897705 
2025-01-03 16:36:52.914258:  
2025-01-03 16:36:52.914258: Epoch 27 
2025-01-03 16:36:52.923380: Current learning rate: 0.00753 
2025-01-03 16:37:30.098670: train_loss -0.4347 
2025-01-03 16:37:30.099173: val_loss -0.3978 
2025-01-03 16:37:30.106186: Pseudo dice [np.float32(0.9129), np.float32(0.4745)] 
2025-01-03 16:37:30.109193: Epoch time: 37.19 s 
2025-01-03 16:37:30.112701: Yayy! New best EMA pseudo Dice: 0.6589000225067139 
2025-01-03 16:37:31.046748:  
2025-01-03 16:37:31.047764: Epoch 28 
2025-01-03 16:37:31.054821: Current learning rate: 0.00744 
2025-01-03 16:38:08.196970: train_loss -0.4586 
2025-01-03 16:38:08.197973: val_loss -0.5251 
2025-01-03 16:38:08.205490: Pseudo dice [np.float32(0.9371), np.float32(0.7565)] 
2025-01-03 16:38:08.209499: Epoch time: 37.15 s 
2025-01-03 16:38:08.213006: Yayy! New best EMA pseudo Dice: 0.6776999831199646 
2025-01-03 16:38:08.971186:  
2025-01-03 16:38:08.972190: Epoch 29 
2025-01-03 16:38:08.977228: Current learning rate: 0.00735 
2025-01-03 16:38:46.304933: train_loss -0.4832 
2025-01-03 16:38:46.305937: val_loss -0.4559 
2025-01-03 16:38:46.312632: Pseudo dice [np.float32(0.9222), np.float32(0.5824)] 
2025-01-03 16:38:46.316650: Epoch time: 37.33 s 
2025-01-03 16:38:46.320171: Yayy! New best EMA pseudo Dice: 0.6851000189781189 
2025-01-03 16:38:47.086259:  
2025-01-03 16:38:47.087265: Epoch 30 
2025-01-03 16:38:47.093354: Current learning rate: 0.00725 
2025-01-03 16:39:24.209616: train_loss -0.4665 
2025-01-03 16:39:24.210617: val_loss -0.4601 
2025-01-03 16:39:24.218138: Pseudo dice [np.float32(0.9348), np.float32(0.6229)] 
2025-01-03 16:39:24.222154: Epoch time: 37.12 s 
2025-01-03 16:39:24.226167: Yayy! New best EMA pseudo Dice: 0.6945000290870667 
2025-01-03 16:39:24.989108:  
2025-01-03 16:39:24.989108: Epoch 31 
2025-01-03 16:39:24.995713: Current learning rate: 0.00716 
2025-01-03 16:40:02.194581: train_loss -0.5078 
2025-01-03 16:40:02.195084: val_loss -0.3813 
2025-01-03 16:40:02.201101: Pseudo dice [np.float32(0.9091), np.float32(0.3141)] 
2025-01-03 16:40:02.205110: Epoch time: 37.21 s 
2025-01-03 16:40:02.817796:  
2025-01-03 16:40:02.818305: Epoch 32 
2025-01-03 16:40:02.824386: Current learning rate: 0.00707 
2025-01-03 16:40:40.016187: train_loss -0.4792 
2025-01-03 16:40:40.017193: val_loss -0.4952 
2025-01-03 16:40:40.023711: Pseudo dice [np.float32(0.9317), np.float32(0.523)] 
2025-01-03 16:40:40.028725: Epoch time: 37.2 s 
2025-01-03 16:40:40.625429:  
2025-01-03 16:40:40.625429: Epoch 33 
2025-01-03 16:40:40.633007: Current learning rate: 0.00697 
2025-01-03 16:41:17.828693: train_loss -0.4628 
2025-01-03 16:41:17.829694: val_loss -0.4007 
2025-01-03 16:41:17.836217: Pseudo dice [np.float32(0.9053), np.float32(0.4947)] 
2025-01-03 16:41:17.840227: Epoch time: 37.2 s 
2025-01-03 16:41:18.539305:  
2025-01-03 16:41:18.540306: Epoch 34 
2025-01-03 16:41:18.546905: Current learning rate: 0.00688 
2025-01-03 16:41:55.779535: train_loss -0.5068 
2025-01-03 16:41:55.780039: val_loss -0.4465 
2025-01-03 16:41:55.788043: Pseudo dice [np.float32(0.9227), np.float32(0.458)] 
2025-01-03 16:41:55.791594: Epoch time: 37.24 s 
2025-01-03 16:41:56.405054:  
2025-01-03 16:41:56.405054: Epoch 35 
2025-01-03 16:41:56.410601: Current learning rate: 0.00679 
2025-01-03 16:42:33.580899: train_loss -0.4984 
2025-01-03 16:42:33.581901: val_loss -0.4499 
2025-01-03 16:42:33.589421: Pseudo dice [np.float32(0.917), np.float32(0.4793)] 
2025-01-03 16:42:33.593434: Epoch time: 37.18 s 
2025-01-03 16:42:34.221572:  
2025-01-03 16:42:34.222075: Epoch 36 
2025-01-03 16:42:34.227086: Current learning rate: 0.00669 
2025-01-03 16:43:11.405266: train_loss -0.4893 
2025-01-03 16:43:11.406271: val_loss -0.4486 
2025-01-03 16:43:11.413394: Pseudo dice [np.float32(0.9288), np.float32(0.5835)] 
2025-01-03 16:43:11.416900: Epoch time: 37.18 s 
2025-01-03 16:43:11.419908: Yayy! New best EMA pseudo Dice: 0.6983000040054321 
2025-01-03 16:43:12.420970:  
2025-01-03 16:43:12.421974: Epoch 37 
2025-01-03 16:43:12.426537: Current learning rate: 0.0066 
2025-01-03 16:43:49.613525: train_loss -0.5063 
2025-01-03 16:43:49.614531: val_loss -0.4675 
2025-01-03 16:43:49.620590: Pseudo dice [np.float32(0.9257), np.float32(0.4382)] 
2025-01-03 16:43:49.624222: Epoch time: 37.19 s 
2025-01-03 16:43:50.233288:  
2025-01-03 16:43:50.234293: Epoch 38 
2025-01-03 16:43:50.240352: Current learning rate: 0.0065 
2025-01-03 16:44:27.390409: train_loss -0.5017 
2025-01-03 16:44:27.390409: val_loss -0.5049 
2025-01-03 16:44:27.396986: Pseudo dice [np.float32(0.9283), np.float32(0.6283)] 
2025-01-03 16:44:27.401999: Epoch time: 37.16 s 
2025-01-03 16:44:27.406017: Yayy! New best EMA pseudo Dice: 0.7049000263214111 
2025-01-03 16:44:28.233207:  
2025-01-03 16:44:28.233207: Epoch 39 
2025-01-03 16:44:28.239430: Current learning rate: 0.00641 
2025-01-03 16:45:05.392751: train_loss -0.5164 
2025-01-03 16:45:05.393757: val_loss -0.4732 
2025-01-03 16:45:05.400276: Pseudo dice [np.float32(0.9298), np.float32(0.5177)] 
2025-01-03 16:45:05.404789: Epoch time: 37.16 s 
2025-01-03 16:45:05.407799: Yayy! New best EMA pseudo Dice: 0.7067000269889832 
2025-01-03 16:45:06.179646:  
2025-01-03 16:45:06.180149: Epoch 40 
2025-01-03 16:45:06.186166: Current learning rate: 0.00631 
2025-01-03 16:45:43.338100: train_loss -0.5027 
2025-01-03 16:45:43.338610: val_loss -0.4523 
2025-01-03 16:45:43.346372: Pseudo dice [np.float32(0.9033), np.float32(0.6341)] 
2025-01-03 16:45:43.350956: Epoch time: 37.16 s 
2025-01-03 16:45:43.354609: Yayy! New best EMA pseudo Dice: 0.7128999829292297 
2025-01-03 16:45:44.142244:  
2025-01-03 16:45:44.143247: Epoch 41 
2025-01-03 16:45:44.149867: Current learning rate: 0.00622 
2025-01-03 16:46:21.464085: train_loss -0.5129 
2025-01-03 16:46:21.464594: val_loss -0.4506 
2025-01-03 16:46:21.471215: Pseudo dice [np.float32(0.9211), np.float32(0.6639)] 
2025-01-03 16:46:21.475744: Epoch time: 37.32 s 
2025-01-03 16:46:21.478765: Yayy! New best EMA pseudo Dice: 0.7208999991416931 
2025-01-03 16:46:22.218361:  
2025-01-03 16:46:22.218361: Epoch 42 
2025-01-03 16:46:22.224956: Current learning rate: 0.00612 
2025-01-03 16:46:59.298544: train_loss -0.5448 
2025-01-03 16:46:59.299547: val_loss -0.4938 
2025-01-03 16:46:59.306066: Pseudo dice [np.float32(0.933), np.float32(0.5978)] 
2025-01-03 16:46:59.310074: Epoch time: 37.08 s 
2025-01-03 16:46:59.313622: Yayy! New best EMA pseudo Dice: 0.7253000140190125 
2025-01-03 16:47:00.064949:  
2025-01-03 16:47:00.065450: Epoch 43 
2025-01-03 16:47:00.071514: Current learning rate: 0.00603 
2025-01-03 16:47:37.119331: train_loss -0.5441 
2025-01-03 16:47:37.119843: val_loss -0.4597 
2025-01-03 16:47:37.126987: Pseudo dice [np.float32(0.9333), np.float32(0.4987)] 
2025-01-03 16:47:37.130998: Epoch time: 37.06 s 
2025-01-03 16:47:37.901078:  
2025-01-03 16:47:37.902077: Epoch 44 
2025-01-03 16:47:37.907647: Current learning rate: 0.00593 
2025-01-03 16:48:14.890891: train_loss -0.5298 
2025-01-03 16:48:14.891408: val_loss -0.4916 
2025-01-03 16:48:14.898982: Pseudo dice [np.float32(0.9212), np.float32(0.5771)] 
2025-01-03 16:48:14.903515: Epoch time: 36.99 s 
2025-01-03 16:48:14.907550: Yayy! New best EMA pseudo Dice: 0.7268999814987183 
2025-01-03 16:48:15.647809:  
2025-01-03 16:48:15.647809: Epoch 45 
2025-01-03 16:48:15.655366: Current learning rate: 0.00584 
2025-01-03 16:48:57.976146: train_loss -0.5011 
2025-01-03 16:48:57.977149: val_loss -0.517 
2025-01-03 16:48:57.985343: Pseudo dice [np.float32(0.9278), np.float32(0.517)] 
2025-01-03 16:48:57.990422: Epoch time: 42.33 s 
2025-01-03 16:48:58.621276:  
2025-01-03 16:48:58.622276: Epoch 46 
2025-01-03 16:48:58.627369: Current learning rate: 0.00574 
2025-01-03 16:49:36.664196: train_loss -0.5547 
2025-01-03 16:49:36.664699: val_loss -0.5007 
2025-01-03 16:49:36.672220: Pseudo dice [np.float32(0.9281), np.float32(0.5558)] 
2025-01-03 16:49:36.676235: Epoch time: 38.04 s 
2025-01-03 16:49:36.679794: Yayy! New best EMA pseudo Dice: 0.7279999852180481 
2025-01-03 16:49:37.446725:  
2025-01-03 16:49:37.447726: Epoch 47 
2025-01-03 16:49:37.453621: Current learning rate: 0.00565 
2025-01-03 16:50:15.074343: train_loss -0.5311 
2025-01-03 16:50:15.074845: val_loss -0.4202 
2025-01-03 16:50:15.081002: Pseudo dice [np.float32(0.9308), np.float32(0.3175)] 
2025-01-03 16:50:15.085573: Epoch time: 37.63 s 
2025-01-03 16:50:15.669183:  
2025-01-03 16:50:15.669183: Epoch 48 
2025-01-03 16:50:15.675199: Current learning rate: 0.00555 
2025-01-03 16:50:53.834173: train_loss -0.5247 
2025-01-03 16:50:53.834687: val_loss -0.4752 
2025-01-03 16:50:53.841801: Pseudo dice [np.float32(0.9096), np.float32(0.5865)] 
2025-01-03 16:50:53.845813: Epoch time: 38.17 s 
2025-01-03 16:50:54.446468:  
2025-01-03 16:50:54.447474: Epoch 49 
2025-01-03 16:50:54.454000: Current learning rate: 0.00546 
2025-01-03 16:51:32.598146: train_loss -0.5766 
2025-01-03 16:51:32.599145: val_loss -0.4536 
2025-01-03 16:51:32.605670: Pseudo dice [np.float32(0.9076), np.float32(0.5094)] 
2025-01-03 16:51:32.610683: Epoch time: 38.15 s 
2025-01-03 16:51:33.391109:  
2025-01-03 16:51:33.391109: Epoch 50 
2025-01-03 16:51:33.397233: Current learning rate: 0.00536 
2025-01-03 16:52:11.253053: train_loss -0.5857 
2025-01-03 16:52:11.254555: val_loss -0.5645 
2025-01-03 16:52:11.262167: Pseudo dice [np.float32(0.9441), np.float32(0.661)] 
2025-01-03 16:52:11.267181: Epoch time: 37.86 s 
2025-01-03 16:52:11.839575:  
2025-01-03 16:52:11.840578: Epoch 51 
2025-01-03 16:52:11.847679: Current learning rate: 0.00526 
2025-01-03 16:52:49.678190: train_loss -0.5348 
2025-01-03 16:52:49.678693: val_loss -0.4807 
2025-01-03 16:52:49.685877: Pseudo dice [np.float32(0.9247), np.float32(0.5365)] 
2025-01-03 16:52:49.690447: Epoch time: 37.84 s 
2025-01-03 16:52:49.694508: Yayy! New best EMA pseudo Dice: 0.7279999852180481 
2025-01-03 16:52:50.470867:  
2025-01-03 16:52:50.470867: Epoch 52 
2025-01-03 16:52:50.476881: Current learning rate: 0.00517 
2025-01-03 16:53:28.410507: train_loss -0.5491 
2025-01-03 16:53:28.411012: val_loss -0.5105 
2025-01-03 16:53:28.418034: Pseudo dice [np.float32(0.9375), np.float32(0.5211)] 
2025-01-03 16:53:28.422049: Epoch time: 37.94 s 
2025-01-03 16:53:28.426065: Yayy! New best EMA pseudo Dice: 0.7281000018119812 
2025-01-03 16:53:29.456650:  
2025-01-03 16:53:29.456650: Epoch 53 
2025-01-03 16:53:29.463669: Current learning rate: 0.00507 
2025-01-03 16:54:07.792414: train_loss -0.5612 
2025-01-03 16:54:07.793420: val_loss -0.433 
2025-01-03 16:54:07.800537: Pseudo dice [np.float32(0.9208), np.float32(0.4329)] 
2025-01-03 16:54:07.804554: Epoch time: 38.34 s 
2025-01-03 16:54:08.420696:  
2025-01-03 16:54:08.421199: Epoch 54 
2025-01-03 16:54:08.427249: Current learning rate: 0.00497 
2025-01-03 16:54:45.643384: train_loss -0.5343 
2025-01-03 16:54:45.643963: val_loss -0.4344 
2025-01-03 16:54:45.651401: Pseudo dice [np.float32(0.9176), np.float32(0.5845)] 
2025-01-03 16:54:45.655965: Epoch time: 37.22 s 
2025-01-03 16:54:46.255080:  
2025-01-03 16:54:46.255080: Epoch 55 
2025-01-03 16:54:46.262094: Current learning rate: 0.00487 
2025-01-03 16:55:23.462024: train_loss -0.5582 
2025-01-03 16:55:23.463527: val_loss -0.4942 
2025-01-03 16:55:23.471050: Pseudo dice [np.float32(0.9133), np.float32(0.6082)] 
2025-01-03 16:55:23.475580: Epoch time: 37.21 s 
2025-01-03 16:55:23.479092: Yayy! New best EMA pseudo Dice: 0.7293000221252441 
2025-01-03 16:55:24.238282:  
2025-01-03 16:55:24.238282: Epoch 56 
2025-01-03 16:55:24.244297: Current learning rate: 0.00478 
2025-01-03 16:56:01.761345: train_loss -0.5379 
2025-01-03 16:56:01.761345: val_loss -0.4911 
2025-01-03 16:56:01.767863: Pseudo dice [np.float32(0.9275), np.float32(0.5078)] 
2025-01-03 16:56:01.771375: Epoch time: 37.52 s 
2025-01-03 16:56:02.387167:  
2025-01-03 16:56:02.387167: Epoch 57 
2025-01-03 16:56:02.393745: Current learning rate: 0.00468 
2025-01-03 16:56:40.195323: train_loss -0.5564 
2025-01-03 16:56:40.195825: val_loss -0.4852 
2025-01-03 16:56:40.201844: Pseudo dice [np.float32(0.9222), np.float32(0.5641)] 
2025-01-03 16:56:40.206856: Epoch time: 37.81 s 
2025-01-03 16:56:40.210363: Yayy! New best EMA pseudo Dice: 0.7296000123023987 
2025-01-03 16:56:40.977562:  
2025-01-03 16:56:40.978562: Epoch 58 
2025-01-03 16:56:40.984142: Current learning rate: 0.00458 
2025-01-03 16:57:19.025285: train_loss -0.561 
2025-01-03 16:57:19.026290: val_loss -0.4871 
2025-01-03 16:57:19.033470: Pseudo dice [np.float32(0.9267), np.float32(0.5138)] 
2025-01-03 16:57:19.038036: Epoch time: 38.05 s 
2025-01-03 16:57:19.681797:  
2025-01-03 16:57:19.681797: Epoch 59 
2025-01-03 16:57:19.686810: Current learning rate: 0.00448 
2025-01-03 16:57:56.914537: train_loss -0.578 
2025-01-03 16:57:56.915542: val_loss -0.4515 
2025-01-03 16:57:56.922060: Pseudo dice [np.float32(0.9169), np.float32(0.4686)] 
2025-01-03 16:57:56.924566: Epoch time: 37.23 s 
2025-01-03 16:57:57.537026:  
2025-01-03 16:57:57.538027: Epoch 60 
2025-01-03 16:57:57.543612: Current learning rate: 0.00438 
2025-01-03 16:58:34.780826: train_loss -0.5459 
2025-01-03 16:58:34.780826: val_loss -0.5198 
2025-01-03 16:58:34.788000: Pseudo dice [np.float32(0.9216), np.float32(0.6758)] 
2025-01-03 16:58:34.792515: Epoch time: 37.24 s 
2025-01-03 16:58:34.795524: Yayy! New best EMA pseudo Dice: 0.7325000166893005 
2025-01-03 16:58:35.804417:  
2025-01-03 16:58:35.805420: Epoch 61 
2025-01-03 16:58:35.811579: Current learning rate: 0.00429 
2025-01-03 16:59:13.098477: train_loss -0.5609 
2025-01-03 16:59:13.098477: val_loss -0.4275 
2025-01-03 16:59:13.104996: Pseudo dice [np.float32(0.9286), np.float32(0.5235)] 
2025-01-03 16:59:13.108505: Epoch time: 37.29 s 
2025-01-03 16:59:13.739555:  
2025-01-03 16:59:13.740555: Epoch 62 
2025-01-03 16:59:13.746132: Current learning rate: 0.00419 
2025-01-03 16:59:51.211425: train_loss -0.5485 
2025-01-03 16:59:51.211938: val_loss -0.5736 
2025-01-03 16:59:51.218559: Pseudo dice [np.float32(0.9344), np.float32(0.5655)] 
2025-01-03 16:59:51.222160: Epoch time: 37.47 s 
2025-01-03 16:59:51.224766: Yayy! New best EMA pseudo Dice: 0.7336000204086304 
2025-01-03 16:59:52.010114:  
2025-01-03 16:59:52.010114: Epoch 63 
2025-01-03 16:59:52.016129: Current learning rate: 0.00409 
2025-01-03 17:00:29.192553: train_loss -0.5703 
2025-01-03 17:00:29.192553: val_loss -0.5298 
2025-01-03 17:00:29.200076: Pseudo dice [np.float32(0.9309), np.float32(0.5966)] 
2025-01-03 17:00:29.203587: Epoch time: 37.18 s 
2025-01-03 17:00:29.207093: Yayy! New best EMA pseudo Dice: 0.7365999817848206 
2025-01-03 17:00:30.017418:  
2025-01-03 17:00:30.017418: Epoch 64 
2025-01-03 17:00:30.022433: Current learning rate: 0.00399 
2025-01-03 17:01:07.186433: train_loss -0.5899 
2025-01-03 17:01:07.186949: val_loss -0.4411 
2025-01-03 17:01:07.193623: Pseudo dice [np.float32(0.91), np.float32(0.5194)] 
2025-01-03 17:01:07.196804: Epoch time: 37.17 s 
2025-01-03 17:01:07.808148:  
2025-01-03 17:01:07.809153: Epoch 65 
2025-01-03 17:01:07.815247: Current learning rate: 0.00389 
2025-01-03 17:01:45.082995: train_loss -0.5661 
2025-01-03 17:01:45.084001: val_loss -0.5227 
2025-01-03 17:01:45.090518: Pseudo dice [np.float32(0.925), np.float32(0.6485)] 
2025-01-03 17:01:45.094029: Epoch time: 37.27 s 
2025-01-03 17:01:45.098039: Yayy! New best EMA pseudo Dice: 0.7397000193595886 
2025-01-03 17:01:45.915073:  
2025-01-03 17:01:45.916073: Epoch 66 
2025-01-03 17:01:45.921659: Current learning rate: 0.00379 
2025-01-03 17:02:24.449479: train_loss -0.5702 
2025-01-03 17:02:24.449479: val_loss -0.493 
2025-01-03 17:02:24.456499: Pseudo dice [np.float32(0.926), np.float32(0.6091)] 
2025-01-03 17:02:24.460515: Epoch time: 38.53 s 
2025-01-03 17:02:24.464023: Yayy! New best EMA pseudo Dice: 0.7425000071525574 
2025-01-03 17:02:25.331168:  
2025-01-03 17:02:25.331690: Epoch 67 
2025-01-03 17:02:25.338280: Current learning rate: 0.00369 
2025-01-03 17:03:03.470222: train_loss -0.576 
2025-01-03 17:03:03.471723: val_loss -0.5528 
2025-01-03 17:03:03.478742: Pseudo dice [np.float32(0.927), np.float32(0.69)] 
2025-01-03 17:03:03.481753: Epoch time: 38.14 s 
2025-01-03 17:03:03.486077: Yayy! New best EMA pseudo Dice: 0.7491000294685364 
2025-01-03 17:03:04.475393:  
2025-01-03 17:03:04.475896: Epoch 68 
2025-01-03 17:03:04.480907: Current learning rate: 0.00359 
2025-01-03 17:03:42.143119: train_loss -0.6116 
2025-01-03 17:03:42.143688: val_loss -0.4791 
2025-01-03 17:03:42.149765: Pseudo dice [np.float32(0.9187), np.float32(0.5499)] 
2025-01-03 17:03:42.153773: Epoch time: 37.67 s 
2025-01-03 17:03:42.800368:  
2025-01-03 17:03:42.801368: Epoch 69 
2025-01-03 17:03:42.806949: Current learning rate: 0.00349 
2025-01-03 17:04:21.442961: train_loss -0.6201 
2025-01-03 17:04:21.444467: val_loss -0.5747 
2025-01-03 17:04:21.450093: Pseudo dice [np.float32(0.9395), np.float32(0.8269)] 
2025-01-03 17:04:21.454656: Epoch time: 38.64 s 
2025-01-03 17:04:21.457705: Yayy! New best EMA pseudo Dice: 0.7612000107765198 
2025-01-03 17:04:22.273262:  
2025-01-03 17:04:22.273262: Epoch 70 
2025-01-03 17:04:22.279845: Current learning rate: 0.00338 
2025-01-03 17:05:00.153861: train_loss -0.5873 
2025-01-03 17:05:00.153861: val_loss -0.5164 
2025-01-03 17:05:00.160874: Pseudo dice [np.float32(0.9391), np.float32(0.6093)] 
2025-01-03 17:05:00.163885: Epoch time: 37.88 s 
2025-01-03 17:05:00.167393: Yayy! New best EMA pseudo Dice: 0.762499988079071 
2025-01-03 17:05:00.982187:  
2025-01-03 17:05:00.982187: Epoch 71 
2025-01-03 17:05:00.988773: Current learning rate: 0.00328 
2025-01-03 17:05:39.031642: train_loss -0.5857 
2025-01-03 17:05:39.032656: val_loss -0.5313 
2025-01-03 17:05:39.039706: Pseudo dice [np.float32(0.9315), np.float32(0.567)] 
2025-01-03 17:05:39.042735: Epoch time: 38.05 s 
2025-01-03 17:05:39.692357:  
2025-01-03 17:05:39.692357: Epoch 72 
2025-01-03 17:05:39.698903: Current learning rate: 0.00318 
2025-01-03 17:06:17.804409: train_loss -0.6201 
2025-01-03 17:06:17.805413: val_loss -0.6057 
2025-01-03 17:06:17.811927: Pseudo dice [np.float32(0.9469), np.float32(0.7743)] 
2025-01-03 17:06:17.815437: Epoch time: 38.11 s 
2025-01-03 17:06:17.819446: Yayy! New best EMA pseudo Dice: 0.7710999846458435 
2025-01-03 17:06:18.645867:  
2025-01-03 17:06:18.645867: Epoch 73 
2025-01-03 17:06:18.650878: Current learning rate: 0.00308 
2025-01-03 17:06:56.981457: train_loss -0.5879 
2025-01-03 17:06:56.981457: val_loss -0.5019 
2025-01-03 17:06:56.988054: Pseudo dice [np.float32(0.9201), np.float32(0.5875)] 
2025-01-03 17:06:56.992673: Epoch time: 38.34 s 
2025-01-03 17:06:57.614080:  
2025-01-03 17:06:57.614583: Epoch 74 
2025-01-03 17:06:57.620599: Current learning rate: 0.00297 
2025-01-03 17:07:35.333777: train_loss -0.6107 
2025-01-03 17:07:35.334279: val_loss -0.5087 
2025-01-03 17:07:35.341293: Pseudo dice [np.float32(0.9285), np.float32(0.5921)] 
2025-01-03 17:07:35.344302: Epoch time: 37.72 s 
2025-01-03 17:07:35.984688:  
2025-01-03 17:07:35.984688: Epoch 75 
2025-01-03 17:07:35.991247: Current learning rate: 0.00287 
2025-01-03 17:08:14.901920: train_loss -0.609 
2025-01-03 17:08:14.902931: val_loss -0.4947 
2025-01-03 17:08:14.909598: Pseudo dice [np.float32(0.9379), np.float32(0.4726)] 
2025-01-03 17:08:14.913140: Epoch time: 38.92 s 
2025-01-03 17:08:15.713092:  
2025-01-03 17:08:15.714092: Epoch 76 
2025-01-03 17:08:15.719730: Current learning rate: 0.00277 
2025-01-03 17:08:53.550425: train_loss -0.5999 
2025-01-03 17:08:53.551451: val_loss -0.525 
2025-01-03 17:08:53.558608: Pseudo dice [np.float32(0.9363), np.float32(0.6025)] 
2025-01-03 17:08:53.562648: Epoch time: 37.84 s 
2025-01-03 17:08:54.200694:  
2025-01-03 17:08:54.201693: Epoch 77 
2025-01-03 17:08:54.207278: Current learning rate: 0.00266 
2025-01-03 17:09:32.047992: train_loss -0.617 
2025-01-03 17:09:32.047992: val_loss -0.5806 
2025-01-03 17:09:32.055059: Pseudo dice [np.float32(0.9448), np.float32(0.7095)] 
2025-01-03 17:09:32.058093: Epoch time: 37.85 s 
2025-01-03 17:09:32.735707:  
2025-01-03 17:09:32.735707: Epoch 78 
2025-01-03 17:09:32.742228: Current learning rate: 0.00256 
2025-01-03 17:10:10.506608: train_loss -0.605 
2025-01-03 17:10:10.507613: val_loss -0.5364 
2025-01-03 17:10:10.514127: Pseudo dice [np.float32(0.9412), np.float32(0.6073)] 
2025-01-03 17:10:10.517637: Epoch time: 37.77 s 
2025-01-03 17:10:11.182994:  
2025-01-03 17:10:11.183997: Epoch 79 
2025-01-03 17:10:11.189555: Current learning rate: 0.00245 
2025-01-03 17:10:49.169787: train_loss -0.6286 
2025-01-03 17:10:49.170294: val_loss -0.5842 
2025-01-03 17:10:49.176837: Pseudo dice [np.float32(0.9407), np.float32(0.7187)] 
2025-01-03 17:10:49.180494: Epoch time: 37.99 s 
2025-01-03 17:10:49.183514: Yayy! New best EMA pseudo Dice: 0.7757999897003174 
2025-01-03 17:10:50.003211:  
2025-01-03 17:10:50.003713: Epoch 80 
2025-01-03 17:10:50.008724: Current learning rate: 0.00235 
2025-01-03 17:11:27.759330: train_loss -0.6271 
2025-01-03 17:11:27.759330: val_loss -0.5273 
2025-01-03 17:11:27.766999: Pseudo dice [np.float32(0.9339), np.float32(0.6467)] 
2025-01-03 17:11:27.771041: Epoch time: 37.76 s 
2025-01-03 17:11:27.774608: Yayy! New best EMA pseudo Dice: 0.7771999835968018 
2025-01-03 17:11:28.650693:  
2025-01-03 17:11:28.651197: Epoch 81 
2025-01-03 17:11:28.658495: Current learning rate: 0.00224 
2025-01-03 17:12:07.037346: train_loss -0.6393 
2025-01-03 17:12:07.037855: val_loss -0.4554 
2025-01-03 17:12:07.045011: Pseudo dice [np.float32(0.9303), np.float32(0.381)] 
2025-01-03 17:12:07.048080: Epoch time: 38.39 s 
2025-01-03 17:12:07.683285:  
2025-01-03 17:12:07.683789: Epoch 82 
2025-01-03 17:12:07.689803: Current learning rate: 0.00214 
2025-01-03 17:12:45.113413: train_loss -0.6243 
2025-01-03 17:12:45.113920: val_loss -0.4994 
2025-01-03 17:12:45.120519: Pseudo dice [np.float32(0.943), np.float32(0.5222)] 
2025-01-03 17:12:45.124271: Epoch time: 37.43 s 
2025-01-03 17:12:45.927084:  
2025-01-03 17:12:45.928090: Epoch 83 
2025-01-03 17:12:45.934660: Current learning rate: 0.00203 
2025-01-03 17:13:24.072741: train_loss -0.6338 
2025-01-03 17:13:24.072741: val_loss -0.5626 
2025-01-03 17:13:24.079302: Pseudo dice [np.float32(0.9414), np.float32(0.622)] 
2025-01-03 17:13:24.082813: Epoch time: 38.15 s 
2025-01-03 17:13:24.699270:  
2025-01-03 17:13:24.700273: Epoch 84 
2025-01-03 17:13:24.705306: Current learning rate: 0.00192 
2025-01-03 17:14:03.038695: train_loss -0.6236 
2025-01-03 17:14:03.039695: val_loss -0.4913 
2025-01-03 17:14:03.046346: Pseudo dice [np.float32(0.9371), np.float32(0.546)] 
2025-01-03 17:14:03.049863: Epoch time: 38.34 s 
2025-01-03 17:14:03.668555:  
2025-01-03 17:14:03.668555: Epoch 85 
2025-01-03 17:14:03.674578: Current learning rate: 0.00181 
2025-01-03 17:14:41.345866: train_loss -0.637 
2025-01-03 17:14:41.346869: val_loss -0.5665 
2025-01-03 17:14:41.354440: Pseudo dice [np.float32(0.938), np.float32(0.5872)] 
2025-01-03 17:14:41.359453: Epoch time: 37.68 s 
2025-01-03 17:14:41.975602:  
2025-01-03 17:14:41.976605: Epoch 86 
2025-01-03 17:14:41.983188: Current learning rate: 0.0017 
2025-01-03 17:15:19.570672: train_loss -0.6438 
2025-01-03 17:15:19.571674: val_loss -0.4949 
2025-01-03 17:15:19.579261: Pseudo dice [np.float32(0.9434), np.float32(0.5437)] 
2025-01-03 17:15:19.583346: Epoch time: 37.6 s 
2025-01-03 17:15:20.198342:  
2025-01-03 17:15:20.198342: Epoch 87 
2025-01-03 17:15:20.204906: Current learning rate: 0.00159 
2025-01-03 17:15:57.714776: train_loss -0.652 
2025-01-03 17:15:57.715780: val_loss -0.5739 
2025-01-03 17:15:57.722292: Pseudo dice [np.float32(0.9388), np.float32(0.6383)] 
2025-01-03 17:15:57.725801: Epoch time: 37.52 s 
2025-01-03 17:15:58.338169:  
2025-01-03 17:15:58.338672: Epoch 88 
2025-01-03 17:15:58.343684: Current learning rate: 0.00148 
2025-01-03 17:16:36.376139: train_loss -0.6273 
2025-01-03 17:16:36.377140: val_loss -0.615 
2025-01-03 17:16:36.384656: Pseudo dice [np.float32(0.9499), np.float32(0.7546)] 
2025-01-03 17:16:36.388670: Epoch time: 38.04 s 
2025-01-03 17:16:37.008354:  
2025-01-03 17:16:37.009353: Epoch 89 
2025-01-03 17:16:37.014939: Current learning rate: 0.00137 
2025-01-03 17:17:14.529448: train_loss -0.6351 
2025-01-03 17:17:14.530960: val_loss -0.539 
2025-01-03 17:17:14.538063: Pseudo dice [np.float32(0.9309), np.float32(0.6558)] 
2025-01-03 17:17:14.542662: Epoch time: 37.52 s 
2025-01-03 17:17:15.178025:  
2025-01-03 17:17:15.178025: Epoch 90 
2025-01-03 17:17:15.184592: Current learning rate: 0.00126 
2025-01-03 17:17:52.656720: train_loss -0.6553 
2025-01-03 17:17:52.657222: val_loss -0.5508 
2025-01-03 17:17:52.663750: Pseudo dice [np.float32(0.936), np.float32(0.6648)] 
2025-01-03 17:17:52.667764: Epoch time: 37.48 s 
2025-01-03 17:17:53.469854:  
2025-01-03 17:17:53.469854: Epoch 91 
2025-01-03 17:17:53.476425: Current learning rate: 0.00115 
2025-01-03 17:18:31.098003: train_loss -0.6546 
2025-01-03 17:18:31.098003: val_loss -0.46 
2025-01-03 17:18:31.105524: Pseudo dice [np.float32(0.9185), np.float32(0.5843)] 
2025-01-03 17:18:31.109033: Epoch time: 37.63 s 
2025-01-03 17:18:31.722517:  
2025-01-03 17:18:31.723520: Epoch 92 
2025-01-03 17:18:31.729579: Current learning rate: 0.00103 
2025-01-03 17:19:09.747704: train_loss -0.6411 
2025-01-03 17:19:09.748703: val_loss -0.5505 
2025-01-03 17:19:09.755220: Pseudo dice [np.float32(0.945), np.float32(0.4625)] 
2025-01-03 17:19:09.758726: Epoch time: 38.03 s 
2025-01-03 17:19:10.355062:  
2025-01-03 17:19:10.355062: Epoch 93 
2025-01-03 17:19:10.362078: Current learning rate: 0.00091 
2025-01-03 17:19:49.254115: train_loss -0.6289 
2025-01-03 17:19:49.255116: val_loss -0.576 
2025-01-03 17:19:49.264155: Pseudo dice [np.float32(0.9496), np.float32(0.6319)] 
2025-01-03 17:19:49.269169: Epoch time: 38.9 s 
2025-01-03 17:19:49.886734:  
2025-01-03 17:19:49.886734: Epoch 94 
2025-01-03 17:19:49.892812: Current learning rate: 0.00079 
2025-01-03 17:20:28.342799: train_loss -0.661 
2025-01-03 17:20:28.343802: val_loss -0.5424 
2025-01-03 17:20:28.353619: Pseudo dice [np.float32(0.9347), np.float32(0.6369)] 
2025-01-03 17:20:28.357128: Epoch time: 38.46 s 
2025-01-03 17:20:28.970377:  
2025-01-03 17:20:28.970377: Epoch 95 
2025-01-03 17:20:28.975388: Current learning rate: 0.00067 
2025-01-03 17:21:07.393653: train_loss -0.6397 
2025-01-03 17:21:07.394654: val_loss -0.4593 
2025-01-03 17:21:07.401175: Pseudo dice [np.float32(0.927), np.float32(0.4994)] 
2025-01-03 17:21:07.404680: Epoch time: 38.42 s 
2025-01-03 17:21:08.018243:  
2025-01-03 17:21:08.018243: Epoch 96 
2025-01-03 17:21:08.024842: Current learning rate: 0.00055 
2025-01-03 17:21:46.597405: train_loss -0.6709 
2025-01-03 17:21:46.598426: val_loss -0.5566 
2025-01-03 17:21:46.607001: Pseudo dice [np.float32(0.9268), np.float32(0.6612)] 
2025-01-03 17:21:46.611130: Epoch time: 38.58 s 
2025-01-03 17:21:47.258153:  
2025-01-03 17:21:47.258153: Epoch 97 
2025-01-03 17:21:47.264212: Current learning rate: 0.00043 
2025-01-03 17:22:25.361347: train_loss -0.6414 
2025-01-03 17:22:25.361347: val_loss -0.5054 
2025-01-03 17:22:25.368873: Pseudo dice [np.float32(0.9253), np.float32(0.5803)] 
2025-01-03 17:22:25.373892: Epoch time: 38.1 s 
2025-01-03 17:22:26.025157:  
2025-01-03 17:22:26.026160: Epoch 98 
2025-01-03 17:22:26.032741: Current learning rate: 0.0003 
2025-01-03 17:23:04.381366: train_loss -0.6683 
2025-01-03 17:23:04.382370: val_loss -0.4885 
2025-01-03 17:23:04.388900: Pseudo dice [np.float32(0.9378), np.float32(0.524)] 
2025-01-03 17:23:04.393410: Epoch time: 38.36 s 
2025-01-03 17:23:05.262721:  
2025-01-03 17:23:05.263721: Epoch 99 
2025-01-03 17:23:05.268749: Current learning rate: 0.00016 
2025-01-03 17:23:43.041189: train_loss -0.6646 
2025-01-03 17:23:43.042215: val_loss -0.5365 
2025-01-03 17:23:43.048280: Pseudo dice [np.float32(0.9363), np.float32(0.6298)] 
2025-01-03 17:23:43.052306: Epoch time: 37.78 s 
2025-01-03 17:23:43.872005: Training done. 
2025-01-03 17:23:43.913521: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset003_Liver\splits_final.json 
2025-01-03 17:23:43.922521: The split file contains 5 splits. 
2025-01-03 17:23:43.930519: Desired fold for training: 1 
2025-01-03 17:23:43.936522: This split has 105 training and 26 validation cases. 
2025-01-03 17:23:43.944521: predicting liver_10 
2025-01-03 17:23:43.952521: liver_10, shape torch.Size([1, 501, 513, 513]), rank 0 
2025-01-03 17:24:55.747014: predicting liver_103 
2025-01-03 17:24:55.804523: liver_103, shape torch.Size([1, 478, 571, 571]), rank 0 
2025-01-03 17:26:07.827596: predicting liver_105 
2025-01-03 17:26:07.907603: liver_105, shape torch.Size([1, 690, 563, 563]), rank 0 
2025-01-03 17:27:49.968014: predicting liver_106 
2025-01-03 17:27:50.060529: liver_106, shape torch.Size([1, 617, 486, 486]), rank 0 
2025-01-03 17:29:00.205660: predicting liver_116 
2025-01-03 17:29:00.266718: liver_116, shape torch.Size([1, 636, 526, 526]), rank 0 
2025-01-03 17:30:31.316160: predicting liver_123 
2025-01-03 17:30:31.383671: liver_123, shape torch.Size([1, 648, 499, 499]), rank 0 
2025-01-03 17:31:49.038634: predicting liver_127 
2025-01-03 17:31:49.089634: liver_127, shape torch.Size([1, 691, 515, 515]), rank 0 
2025-01-03 17:33:30.396654: predicting liver_14 
2025-01-03 17:33:30.464660: liver_14, shape torch.Size([1, 588, 457, 457]), rank 0 
2025-01-03 17:34:42.931083: predicting liver_16 
2025-01-03 17:34:42.984083: liver_16, shape torch.Size([1, 551, 469, 469]), rank 0 
2025-01-03 17:35:46.230999: predicting liver_21 
2025-01-03 17:35:46.270513: liver_21, shape torch.Size([1, 437, 512, 512]), rank 0 
2025-01-03 17:36:32.893020: predicting liver_23 
2025-01-03 17:36:32.928020: liver_23, shape torch.Size([1, 469, 440, 440]), rank 0 
2025-01-03 17:37:13.869483: predicting liver_28 
2025-01-03 17:37:13.899487: liver_28, shape torch.Size([1, 129, 667, 667]), rank 0 
2025-01-03 17:37:45.935940: predicting liver_4 
2025-01-03 17:37:45.962450: liver_4, shape torch.Size([1, 673, 602, 602]), rank 0 
2025-01-03 17:39:54.882790: predicting liver_45 
2025-01-03 17:39:54.994265: liver_45, shape torch.Size([1, 74, 667, 667]), rank 0 
2025-01-03 17:40:10.963237: predicting liver_59 
2025-01-03 17:40:10.979237: liver_59, shape torch.Size([1, 432, 456, 456]), rank 0 
2025-01-03 17:40:57.940794: predicting liver_66 
2025-01-03 17:40:57.987307: liver_66, shape torch.Size([1, 430, 476, 476]), rank 0 
2025-01-03 17:41:45.121411: predicting liver_67 
2025-01-03 17:41:45.151917: liver_67, shape torch.Size([1, 412, 474, 474]), rank 0 
2025-01-03 17:42:32.416171: predicting liver_68 
2025-01-03 17:42:32.450175: liver_68, shape torch.Size([1, 665, 444, 444]), rank 0 
2025-01-03 17:43:30.478180: predicting liver_7 
2025-01-03 17:43:30.551689: liver_7, shape torch.Size([1, 541, 499, 499]), rank 0 
2025-01-03 17:44:33.538691: predicting liver_71 
2025-01-03 17:44:33.614198: liver_71, shape torch.Size([1, 470, 371, 371]), rank 0 
2025-01-03 17:45:01.607466: predicting liver_73 
2025-01-03 17:45:01.638466: liver_73, shape torch.Size([1, 484, 634, 634]), rank 0 
2025-01-03 17:46:33.243401: predicting liver_85 
2025-01-03 17:46:33.331740: liver_85, shape torch.Size([1, 441, 430, 430]), rank 0 
2025-01-03 17:47:09.430169: predicting liver_86 
2025-01-03 17:47:09.471168: liver_86, shape torch.Size([1, 453, 456, 456]), rank 0 
2025-01-03 17:48:04.795974: predicting liver_91 
2025-01-03 17:48:04.840482: liver_91, shape torch.Size([1, 601, 572, 572]), rank 0 
2025-01-03 17:49:38.162071: predicting liver_93 
2025-01-03 17:49:38.221584: liver_93, shape torch.Size([1, 557, 442, 442]), rank 0 
2025-01-03 17:50:24.249205: predicting liver_96 
2025-01-03 17:50:24.295205: liver_96, shape torch.Size([1, 505, 498, 498]), rank 0 
2025-01-03 17:51:52.762281: Validation complete 
2025-01-03 17:51:52.763280: Mean Validation Dice:  0.6795390924616532 
