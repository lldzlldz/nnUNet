2025-01-11 17:07:16.016129: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.25 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-11 17:07:16.021129: self.oversample_foreground_percent 0.25 
2025-01-11 17:07:16.024129: do_dummy_2d_data_aug: False 
2025-01-11 17:07:16.031408: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset003_Liver\splits_final.json 
2025-01-11 17:07:16.038412: The split file contains 5 splits. 
2025-01-11 17:07:16.040412: Desired fold for training: 0 
2025-01-11 17:07:16.043411: This split has 104 training and 27 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [96, 112, 112], 'median_image_size_in_voxels': [482.0, 512.0, 512.0], 'spacing': [1.0, 0.767578125, 0.767578125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset003_Liver', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [1.0, 0.767578125, 0.767578125], 'original_median_shape_after_transp': [432, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5420.0, 'mean': 99.48007202148438, 'median': 101.0, 'min': -983.0, 'percentile_00_5': -15.0, 'percentile_99_5': 197.0, 'std': 37.13840103149414}}} 
 
2025-01-11 17:07:24.671262: unpacking dataset... 
2025-01-11 17:07:24.946933: unpacking done... 
2025-01-11 17:07:27.218156:  
2025-01-11 17:07:27.218156: Epoch 0 
2025-01-11 17:07:27.223169: Current learning rate: 0.01 
2025-01-11 17:08:10.751673: train_loss 0.0401 
2025-01-11 17:08:10.752677: val_loss -0.1464 
2025-01-11 17:08:10.759192: Pseudo dice [np.float32(0.8107), np.float32(0.0)] 
2025-01-11 17:08:10.762700: Epoch time: 43.53 s 
2025-01-11 17:08:10.765206: Yayy! New best EMA pseudo Dice: 0.40529999136924744 
2025-01-11 17:08:11.358916:  
2025-01-11 17:08:11.359421: Epoch 1 
2025-01-11 17:08:11.364489: Current learning rate: 0.00996 
2025-01-11 17:08:50.871673: train_loss -0.0967 
2025-01-11 17:08:50.871673: val_loss -0.1908 
2025-01-11 17:08:50.878193: Pseudo dice [np.float32(0.8252), np.float32(0.0)] 
2025-01-11 17:08:50.883209: Epoch time: 39.51 s 
2025-01-11 17:08:50.886720: Yayy! New best EMA pseudo Dice: 0.40610000491142273 
2025-01-11 17:08:51.519652:  
2025-01-11 17:08:51.520154: Epoch 2 
2025-01-11 17:08:51.525165: Current learning rate: 0.00993 
2025-01-11 17:09:30.991424: train_loss -0.1465 
2025-01-11 17:09:30.992949: val_loss -0.2061 
2025-01-11 17:09:30.998991: Pseudo dice [np.float32(0.8316), np.float32(0.0305)] 
2025-01-11 17:09:31.005007: Epoch time: 39.47 s 
2025-01-11 17:09:31.010539: Yayy! New best EMA pseudo Dice: 0.40860000252723694 
2025-01-11 17:09:31.674347:  
2025-01-11 17:09:31.675347: Epoch 3 
2025-01-11 17:09:31.679911: Current learning rate: 0.00989 
2025-01-11 17:10:11.109006: train_loss -0.2049 
2025-01-11 17:10:11.109006: val_loss -0.3331 
2025-01-11 17:10:11.115533: Pseudo dice [np.float32(0.8806), np.float32(0.2705)] 
2025-01-11 17:10:11.118042: Epoch time: 39.43 s 
2025-01-11 17:10:11.121550: Yayy! New best EMA pseudo Dice: 0.4253000020980835 
2025-01-11 17:10:11.774347:  
2025-01-11 17:10:11.774347: Epoch 4 
2025-01-11 17:10:11.779382: Current learning rate: 0.00986 
2025-01-11 17:10:51.304258: train_loss -0.2582 
2025-01-11 17:10:51.305258: val_loss -0.3168 
2025-01-11 17:10:51.310772: Pseudo dice [np.float32(0.8611), np.float32(0.3762)] 
2025-01-11 17:10:51.315791: Epoch time: 39.53 s 
2025-01-11 17:10:51.319320: Yayy! New best EMA pseudo Dice: 0.444599986076355 
2025-01-11 17:10:52.098901:  
2025-01-11 17:10:52.098901: Epoch 5 
2025-01-11 17:10:52.103913: Current learning rate: 0.00982 
2025-01-11 17:11:31.503659: train_loss -0.2708 
2025-01-11 17:11:31.504161: val_loss -0.2748 
2025-01-11 17:11:31.510189: Pseudo dice [np.float32(0.8382), np.float32(0.352)] 
2025-01-11 17:11:31.515204: Epoch time: 39.41 s 
2025-01-11 17:11:31.519215: Yayy! New best EMA pseudo Dice: 0.4596000015735626 
2025-01-11 17:11:32.152846:  
2025-01-11 17:11:32.152846: Epoch 6 
2025-01-11 17:11:32.157857: Current learning rate: 0.00978 
2025-01-11 17:12:11.556098: train_loss -0.2636 
2025-01-11 17:12:11.556611: val_loss -0.3436 
2025-01-11 17:12:11.562780: Pseudo dice [np.float32(0.8701), np.float32(0.4508)] 
2025-01-11 17:12:11.566297: Epoch time: 39.4 s 
2025-01-11 17:12:11.569483: Yayy! New best EMA pseudo Dice: 0.4796999990940094 
2025-01-11 17:12:12.183091:  
2025-01-11 17:12:12.183091: Epoch 7 
2025-01-11 17:12:12.188620: Current learning rate: 0.00975 
2025-01-11 17:12:51.970896: train_loss -0.3377 
2025-01-11 17:12:51.971901: val_loss -0.3745 
2025-01-11 17:12:51.979422: Pseudo dice [np.float32(0.8758), np.float32(0.5167)] 
2025-01-11 17:12:51.984444: Epoch time: 39.79 s 
2025-01-11 17:12:51.989468: Yayy! New best EMA pseudo Dice: 0.5013999938964844 
2025-01-11 17:12:52.645464:  
2025-01-11 17:12:52.645464: Epoch 8 
2025-01-11 17:12:52.651133: Current learning rate: 0.00971 
2025-01-11 17:13:32.045465: train_loss -0.3143 
2025-01-11 17:13:32.045465: val_loss -0.3897 
2025-01-11 17:13:32.052506: Pseudo dice [np.float32(0.8965), np.float32(0.4678)] 
2025-01-11 17:13:32.056117: Epoch time: 39.4 s 
2025-01-11 17:13:32.060277: Yayy! New best EMA pseudo Dice: 0.5195000171661377 
2025-01-11 17:13:32.729098:  
2025-01-11 17:13:32.729098: Epoch 9 
2025-01-11 17:13:32.735245: Current learning rate: 0.00968 
2025-01-11 17:14:12.125673: train_loss -0.3569 
2025-01-11 17:14:12.125673: val_loss -0.3836 
2025-01-11 17:14:12.132321: Pseudo dice [np.float32(0.8834), np.float32(0.3326)] 
2025-01-11 17:14:12.135871: Epoch time: 39.4 s 
2025-01-11 17:14:12.139402: Yayy! New best EMA pseudo Dice: 0.5282999873161316 
2025-01-11 17:14:12.771909:  
2025-01-11 17:14:12.771909: Epoch 10 
2025-01-11 17:14:12.777928: Current learning rate: 0.00964 
2025-01-11 17:14:52.158445: train_loss -0.3823 
2025-01-11 17:14:52.158949: val_loss -0.4004 
2025-01-11 17:14:52.165964: Pseudo dice [np.float32(0.8906), np.float32(0.4531)] 
2025-01-11 17:14:52.170976: Epoch time: 39.39 s 
2025-01-11 17:14:52.174990: Yayy! New best EMA pseudo Dice: 0.5426999926567078 
2025-01-11 17:14:52.814269:  
2025-01-11 17:14:52.814269: Epoch 11 
2025-01-11 17:14:52.819875: Current learning rate: 0.0096 
2025-01-11 17:15:32.232572: train_loss -0.3734 
2025-01-11 17:15:32.233577: val_loss -0.3951 
2025-01-11 17:15:32.240119: Pseudo dice [np.float32(0.8747), np.float32(0.4889)] 
2025-01-11 17:15:32.244146: Epoch time: 39.42 s 
2025-01-11 17:15:32.249671: Yayy! New best EMA pseudo Dice: 0.5565999746322632 
2025-01-11 17:15:33.070600:  
2025-01-11 17:15:33.070600: Epoch 12 
2025-01-11 17:15:33.074108: Current learning rate: 0.00957 
2025-01-11 17:16:12.569789: train_loss -0.368 
2025-01-11 17:16:12.570793: val_loss -0.4261 
2025-01-11 17:16:12.577317: Pseudo dice [np.float32(0.8789), np.float32(0.5387)] 
2025-01-11 17:16:12.580829: Epoch time: 39.5 s 
2025-01-11 17:16:12.585851: Yayy! New best EMA pseudo Dice: 0.5717999935150146 
2025-01-11 17:16:13.239563:  
2025-01-11 17:16:13.239563: Epoch 13 
2025-01-11 17:16:13.244579: Current learning rate: 0.00953 
2025-01-11 17:16:52.638449: train_loss -0.3954 
2025-01-11 17:16:52.638449: val_loss -0.3995 
2025-01-11 17:16:52.645154: Pseudo dice [np.float32(0.8774), np.float32(0.5491)] 
2025-01-11 17:16:52.651174: Epoch time: 39.4 s 
2025-01-11 17:16:52.656806: Yayy! New best EMA pseudo Dice: 0.5860000252723694 
2025-01-11 17:16:53.265048:  
2025-01-11 17:16:53.265048: Epoch 14 
2025-01-11 17:16:53.270656: Current learning rate: 0.00949 
2025-01-11 17:17:32.810289: train_loss -0.3823 
2025-01-11 17:17:32.810791: val_loss -0.489 
2025-01-11 17:17:32.817812: Pseudo dice [np.float32(0.9019), np.float32(0.564)] 
2025-01-11 17:17:32.823330: Epoch time: 39.55 s 
2025-01-11 17:17:32.826844: Yayy! New best EMA pseudo Dice: 0.6007000207901001 
2025-01-11 17:17:33.488118:  
2025-01-11 17:17:33.488118: Epoch 15 
2025-01-11 17:17:33.493636: Current learning rate: 0.00946 
2025-01-11 17:18:12.247597: train_loss -0.3954 
2025-01-11 17:18:12.248105: val_loss -0.4371 
2025-01-11 17:18:12.253780: Pseudo dice [np.float32(0.8856), np.float32(0.5488)] 
2025-01-11 17:18:12.257845: Epoch time: 38.76 s 
2025-01-11 17:18:12.261409: Yayy! New best EMA pseudo Dice: 0.6122999787330627 
2025-01-11 17:18:12.912208:  
2025-01-11 17:18:12.912208: Epoch 16 
2025-01-11 17:18:12.919734: Current learning rate: 0.00942 
2025-01-11 17:18:51.589480: train_loss -0.3631 
2025-01-11 17:18:51.590484: val_loss -0.4356 
2025-01-11 17:18:51.596687: Pseudo dice [np.float32(0.8808), np.float32(0.5936)] 
2025-01-11 17:18:51.601333: Epoch time: 38.68 s 
2025-01-11 17:18:51.605183: Yayy! New best EMA pseudo Dice: 0.6248000264167786 
2025-01-11 17:18:52.256192:  
2025-01-11 17:18:52.256698: Epoch 17 
2025-01-11 17:18:52.261748: Current learning rate: 0.00939 
2025-01-11 17:19:30.921832: train_loss -0.392 
2025-01-11 17:19:30.921832: val_loss -0.4718 
2025-01-11 17:19:30.928965: Pseudo dice [np.float32(0.9129), np.float32(0.5422)] 
2025-01-11 17:19:30.933029: Epoch time: 38.67 s 
2025-01-11 17:19:30.935554: Yayy! New best EMA pseudo Dice: 0.6351000070571899 
2025-01-11 17:19:31.581112:  
2025-01-11 17:19:31.581112: Epoch 18 
2025-01-11 17:19:31.586673: Current learning rate: 0.00935 
2025-01-11 17:20:10.174266: train_loss -0.4073 
2025-01-11 17:20:10.174773: val_loss -0.4454 
2025-01-11 17:20:10.180379: Pseudo dice [np.float32(0.8762), np.float32(0.6124)] 
2025-01-11 17:20:10.184890: Epoch time: 38.59 s 
2025-01-11 17:20:10.187899: Yayy! New best EMA pseudo Dice: 0.6460000276565552 
2025-01-11 17:20:10.832671:  
2025-01-11 17:20:10.833677: Epoch 19 
2025-01-11 17:20:10.838234: Current learning rate: 0.00931 
2025-01-11 17:20:49.443164: train_loss -0.3844 
2025-01-11 17:20:49.444167: val_loss -0.393 
2025-01-11 17:20:49.450698: Pseudo dice [np.float32(0.8761), np.float32(0.4618)] 
2025-01-11 17:20:49.455217: Epoch time: 38.61 s 
2025-01-11 17:20:49.460241: Yayy! New best EMA pseudo Dice: 0.6482999920845032 
2025-01-11 17:20:50.314027:  
2025-01-11 17:20:50.314027: Epoch 20 
2025-01-11 17:20:50.317612: Current learning rate: 0.00928 
2025-01-11 17:21:28.988871: train_loss -0.3909 
2025-01-11 17:21:28.989374: val_loss -0.4417 
2025-01-11 17:21:28.995121: Pseudo dice [np.float32(0.9069), np.float32(0.4626)] 
2025-01-11 17:21:28.999815: Epoch time: 38.68 s 
2025-01-11 17:21:29.004838: Yayy! New best EMA pseudo Dice: 0.6518999934196472 
2025-01-11 17:21:29.654933:  
2025-01-11 17:21:29.654933: Epoch 21 
2025-01-11 17:21:29.660965: Current learning rate: 0.00924 
2025-01-11 17:22:08.207210: train_loss -0.4156 
2025-01-11 17:22:08.207731: val_loss -0.3981 
2025-01-11 17:22:08.215253: Pseudo dice [np.float32(0.8617), np.float32(0.6519)] 
2025-01-11 17:22:08.220272: Epoch time: 38.55 s 
2025-01-11 17:22:08.226793: Yayy! New best EMA pseudo Dice: 0.6624000072479248 
2025-01-11 17:22:08.837386:  
2025-01-11 17:22:08.837386: Epoch 22 
2025-01-11 17:22:08.842487: Current learning rate: 0.0092 
2025-01-11 17:22:47.614604: train_loss -0.4239 
2025-01-11 17:22:47.615603: val_loss -0.515 
2025-01-11 17:22:47.623638: Pseudo dice [np.float32(0.9064), np.float32(0.6176)] 
2025-01-11 17:22:47.629656: Epoch time: 38.78 s 
2025-01-11 17:22:47.635674: Yayy! New best EMA pseudo Dice: 0.6723999977111816 
2025-01-11 17:22:48.243722:  
2025-01-11 17:22:48.243722: Epoch 23 
2025-01-11 17:22:48.248744: Current learning rate: 0.00917 
2025-01-11 17:23:26.845782: train_loss -0.4562 
2025-01-11 17:23:26.845782: val_loss -0.5124 
2025-01-11 17:23:26.851808: Pseudo dice [np.float32(0.9123), np.float32(0.6157)] 
2025-01-11 17:23:26.855819: Epoch time: 38.6 s 
2025-01-11 17:23:26.860334: Yayy! New best EMA pseudo Dice: 0.6815000176429749 
2025-01-11 17:23:27.464842:  
2025-01-11 17:23:27.464842: Epoch 24 
2025-01-11 17:23:27.470969: Current learning rate: 0.00913 
2025-01-11 17:24:06.083889: train_loss -0.4505 
2025-01-11 17:24:06.084894: val_loss -0.4846 
2025-01-11 17:24:06.091421: Pseudo dice [np.float32(0.8974), np.float32(0.6028)] 
2025-01-11 17:24:06.097445: Epoch time: 38.62 s 
2025-01-11 17:24:06.101466: Yayy! New best EMA pseudo Dice: 0.6883999705314636 
2025-01-11 17:24:06.727206:  
2025-01-11 17:24:06.728210: Epoch 25 
2025-01-11 17:24:06.733231: Current learning rate: 0.0091 
2025-01-11 17:24:45.412171: train_loss -0.4445 
2025-01-11 17:24:45.413172: val_loss -0.5173 
2025-01-11 17:24:45.418700: Pseudo dice [np.float32(0.9237), np.float32(0.6156)] 
2025-01-11 17:24:45.423210: Epoch time: 38.68 s 
2025-01-11 17:24:45.426223: Yayy! New best EMA pseudo Dice: 0.6965000033378601 
2025-01-11 17:24:46.065819:  
2025-01-11 17:24:46.066322: Epoch 26 
2025-01-11 17:24:46.071337: Current learning rate: 0.00906 
2025-01-11 17:25:24.700615: train_loss -0.46 
2025-01-11 17:25:24.700615: val_loss -0.5229 
2025-01-11 17:25:24.708141: Pseudo dice [np.float32(0.9246), np.float32(0.6179)] 
2025-01-11 17:25:24.713158: Epoch time: 38.64 s 
2025-01-11 17:25:24.717164: Yayy! New best EMA pseudo Dice: 0.7039999961853027 
2025-01-11 17:25:25.345696:  
2025-01-11 17:25:25.346702: Epoch 27 
2025-01-11 17:25:25.351245: Current learning rate: 0.00902 
2025-01-11 17:26:03.993148: train_loss -0.4872 
2025-01-11 17:26:03.994153: val_loss -0.5615 
2025-01-11 17:26:04.000769: Pseudo dice [np.float32(0.9176), np.float32(0.7083)] 
2025-01-11 17:26:04.005792: Epoch time: 38.65 s 
2025-01-11 17:26:04.009820: Yayy! New best EMA pseudo Dice: 0.714900016784668 
2025-01-11 17:26:04.804851:  
2025-01-11 17:26:04.805851: Epoch 28 
2025-01-11 17:26:04.810915: Current learning rate: 0.00899 
2025-01-11 17:26:43.395530: train_loss -0.4326 
2025-01-11 17:26:43.396529: val_loss -0.5773 
2025-01-11 17:26:43.403050: Pseudo dice [np.float32(0.9183), np.float32(0.7152)] 
2025-01-11 17:26:43.409061: Epoch time: 38.59 s 
2025-01-11 17:26:43.414072: Yayy! New best EMA pseudo Dice: 0.7250999808311462 
2025-01-11 17:26:44.050873:  
2025-01-11 17:26:44.051872: Epoch 29 
2025-01-11 17:26:44.057384: Current learning rate: 0.00895 
2025-01-11 17:27:22.710254: train_loss -0.4499 
2025-01-11 17:27:22.710756: val_loss -0.453 
2025-01-11 17:27:22.716776: Pseudo dice [np.float32(0.9083), np.float32(0.4329)] 
2025-01-11 17:27:22.720286: Epoch time: 38.66 s 
2025-01-11 17:27:23.243206:  
2025-01-11 17:27:23.243708: Epoch 30 
2025-01-11 17:27:23.248719: Current learning rate: 0.00891 
2025-01-11 17:28:01.854902: train_loss -0.4569 
2025-01-11 17:28:01.855902: val_loss -0.4966 
2025-01-11 17:28:01.863422: Pseudo dice [np.float32(0.9254), np.float32(0.5853)] 
2025-01-11 17:28:01.868732: Epoch time: 38.61 s 
2025-01-11 17:28:02.400042:  
2025-01-11 17:28:02.400042: Epoch 31 
2025-01-11 17:28:02.405596: Current learning rate: 0.00888 
2025-01-11 17:28:41.000365: train_loss -0.4831 
2025-01-11 17:28:41.000866: val_loss -0.535 
2025-01-11 17:28:41.007560: Pseudo dice [np.float32(0.9154), np.float32(0.7291)] 
2025-01-11 17:28:41.012677: Epoch time: 38.6 s 
2025-01-11 17:28:41.017233: Yayy! New best EMA pseudo Dice: 0.7330999970436096 
2025-01-11 17:28:41.647947:  
2025-01-11 17:28:41.647947: Epoch 32 
2025-01-11 17:28:41.653010: Current learning rate: 0.00884 
2025-01-11 17:29:20.371378: train_loss -0.487 
2025-01-11 17:29:20.371378: val_loss -0.5113 
2025-01-11 17:29:20.377950: Pseudo dice [np.float32(0.9189), np.float32(0.543)] 
2025-01-11 17:29:20.381500: Epoch time: 38.72 s 
2025-01-11 17:29:20.915717:  
2025-01-11 17:29:20.915717: Epoch 33 
2025-01-11 17:29:20.921117: Current learning rate: 0.0088 
2025-01-11 17:29:59.592745: train_loss -0.443 
2025-01-11 17:29:59.592745: val_loss -0.4975 
2025-01-11 17:29:59.598900: Pseudo dice [np.float32(0.9064), np.float32(0.5917)] 
2025-01-11 17:29:59.602943: Epoch time: 38.68 s 
2025-01-11 17:29:59.606474: Yayy! New best EMA pseudo Dice: 0.734499990940094 
2025-01-11 17:30:00.244969:  
2025-01-11 17:30:00.244969: Epoch 34 
2025-01-11 17:30:00.250578: Current learning rate: 0.00877 
2025-01-11 17:30:39.022191: train_loss -0.4958 
2025-01-11 17:30:39.022714: val_loss -0.5298 
2025-01-11 17:30:39.029414: Pseudo dice [np.float32(0.9243), np.float32(0.7052)] 
2025-01-11 17:30:39.033519: Epoch time: 38.78 s 
2025-01-11 17:30:39.037058: Yayy! New best EMA pseudo Dice: 0.7425000071525574 
2025-01-11 17:30:39.690411:  
2025-01-11 17:30:39.690411: Epoch 35 
2025-01-11 17:30:39.695433: Current learning rate: 0.00873 
2025-01-11 17:31:18.264565: train_loss -0.496 
2025-01-11 17:31:18.264565: val_loss -0.448 
2025-01-11 17:31:18.271087: Pseudo dice [np.float32(0.8893), np.float32(0.5757)] 
2025-01-11 17:31:18.276097: Epoch time: 38.58 s 
2025-01-11 17:31:18.981920:  
2025-01-11 17:31:18.981920: Epoch 36 
2025-01-11 17:31:18.987438: Current learning rate: 0.00869 
2025-01-11 17:31:57.587131: train_loss -0.5016 
2025-01-11 17:31:57.588134: val_loss -0.5492 
2025-01-11 17:31:57.594157: Pseudo dice [np.float32(0.9278), np.float32(0.693)] 
2025-01-11 17:31:57.597172: Epoch time: 38.61 s 
2025-01-11 17:31:57.600687: Yayy! New best EMA pseudo Dice: 0.7483999729156494 
2025-01-11 17:31:58.234028:  
2025-01-11 17:31:58.235030: Epoch 37 
2025-01-11 17:31:58.239624: Current learning rate: 0.00866 
2025-01-11 17:32:36.878506: train_loss -0.4719 
2025-01-11 17:32:36.879510: val_loss -0.5059 
2025-01-11 17:32:36.884528: Pseudo dice [np.float32(0.9153), np.float32(0.6875)] 
2025-01-11 17:32:36.888538: Epoch time: 38.64 s 
2025-01-11 17:32:36.892051: Yayy! New best EMA pseudo Dice: 0.7537000179290771 
2025-01-11 17:32:37.546433:  
2025-01-11 17:32:37.546937: Epoch 38 
2025-01-11 17:32:37.551951: Current learning rate: 0.00862 
2025-01-11 17:33:16.123447: train_loss -0.4992 
2025-01-11 17:33:16.124452: val_loss -0.4886 
2025-01-11 17:33:16.131015: Pseudo dice [np.float32(0.8904), np.float32(0.6338)] 
2025-01-11 17:33:16.133572: Epoch time: 38.58 s 
2025-01-11 17:33:16.137710: Yayy! New best EMA pseudo Dice: 0.7545999884605408 
2025-01-11 17:33:16.774726:  
2025-01-11 17:33:16.774726: Epoch 39 
2025-01-11 17:33:16.780272: Current learning rate: 0.00858 
2025-01-11 17:33:55.424666: train_loss -0.4632 
2025-01-11 17:33:55.425223: val_loss -0.552 
2025-01-11 17:33:55.430947: Pseudo dice [np.float32(0.9197), np.float32(0.6806)] 
2025-01-11 17:33:55.435018: Epoch time: 38.65 s 
2025-01-11 17:33:55.439097: Yayy! New best EMA pseudo Dice: 0.7591000199317932 
2025-01-11 17:33:56.086374:  
2025-01-11 17:33:56.086374: Epoch 40 
2025-01-11 17:33:56.091909: Current learning rate: 0.00855 
2025-01-11 17:34:34.635430: train_loss -0.4689 
2025-01-11 17:34:34.636435: val_loss -0.5631 
2025-01-11 17:34:34.642520: Pseudo dice [np.float32(0.9075), np.float32(0.6933)] 
2025-01-11 17:34:34.649085: Epoch time: 38.55 s 
2025-01-11 17:34:34.655356: Yayy! New best EMA pseudo Dice: 0.7631999850273132 
2025-01-11 17:34:35.306427:  
2025-01-11 17:34:35.307430: Epoch 41 
2025-01-11 17:34:35.311981: Current learning rate: 0.00851 
2025-01-11 17:35:13.893508: train_loss -0.4663 
2025-01-11 17:35:13.894014: val_loss -0.5566 
2025-01-11 17:35:13.900034: Pseudo dice [np.float32(0.9301), np.float32(0.6967)] 
2025-01-11 17:35:13.905050: Epoch time: 38.59 s 
2025-01-11 17:35:13.909063: Yayy! New best EMA pseudo Dice: 0.7682999968528748 
2025-01-11 17:35:14.522427:  
2025-01-11 17:35:14.522427: Epoch 42 
2025-01-11 17:35:14.527441: Current learning rate: 0.00847 
2025-01-11 17:35:53.148885: train_loss -0.5221 
2025-01-11 17:35:53.150389: val_loss -0.56 
2025-01-11 17:35:53.158918: Pseudo dice [np.float32(0.9315), np.float32(0.7349)] 
2025-01-11 17:35:53.165249: Epoch time: 38.63 s 
2025-01-11 17:35:53.170366: Yayy! New best EMA pseudo Dice: 0.7746999859809875 
2025-01-11 17:35:53.812280:  
2025-01-11 17:35:53.812280: Epoch 43 
2025-01-11 17:35:53.818355: Current learning rate: 0.00844 
2025-01-11 17:36:32.388563: train_loss -0.4676 
2025-01-11 17:36:32.389567: val_loss -0.5281 
2025-01-11 17:36:32.396089: Pseudo dice [np.float32(0.9171), np.float32(0.7293)] 
2025-01-11 17:36:32.401137: Epoch time: 38.58 s 
2025-01-11 17:36:32.405783: Yayy! New best EMA pseudo Dice: 0.7796000242233276 
2025-01-11 17:36:33.197800:  
2025-01-11 17:36:33.197800: Epoch 44 
2025-01-11 17:36:33.202808: Current learning rate: 0.0084 
2025-01-11 17:37:11.841917: train_loss -0.4835 
2025-01-11 17:37:11.842917: val_loss -0.5881 
2025-01-11 17:37:11.849442: Pseudo dice [np.float32(0.9371), np.float32(0.6947)] 
2025-01-11 17:37:11.853967: Epoch time: 38.64 s 
2025-01-11 17:37:11.856517: Yayy! New best EMA pseudo Dice: 0.7832000255584717 
2025-01-11 17:37:12.460515:  
2025-01-11 17:37:12.460515: Epoch 45 
2025-01-11 17:37:12.465601: Current learning rate: 0.00836 
2025-01-11 17:37:51.068837: train_loss -0.4982 
2025-01-11 17:37:51.069842: val_loss -0.5395 
2025-01-11 17:37:51.074865: Pseudo dice [np.float32(0.9293), np.float32(0.6471)] 
2025-01-11 17:37:51.078879: Epoch time: 38.61 s 
2025-01-11 17:37:51.082390: Yayy! New best EMA pseudo Dice: 0.7836999893188477 
2025-01-11 17:37:51.696872:  
2025-01-11 17:37:51.697875: Epoch 46 
2025-01-11 17:37:51.702475: Current learning rate: 0.00833 
2025-01-11 17:38:30.345147: train_loss -0.4955 
2025-01-11 17:38:30.347170: val_loss -0.5123 
2025-01-11 17:38:30.354290: Pseudo dice [np.float32(0.9283), np.float32(0.6994)] 
2025-01-11 17:38:30.357926: Epoch time: 38.65 s 
2025-01-11 17:38:30.361976: Yayy! New best EMA pseudo Dice: 0.7867000102996826 
2025-01-11 17:38:30.998388:  
2025-01-11 17:38:30.998894: Epoch 47 
2025-01-11 17:38:31.003427: Current learning rate: 0.00829 
2025-01-11 17:39:09.571321: train_loss -0.4729 
2025-01-11 17:39:09.572326: val_loss -0.5674 
2025-01-11 17:39:09.578878: Pseudo dice [np.float32(0.9172), np.float32(0.7346)] 
2025-01-11 17:39:09.582396: Epoch time: 38.57 s 
2025-01-11 17:39:09.587412: Yayy! New best EMA pseudo Dice: 0.7907000184059143 
2025-01-11 17:39:10.209932:  
2025-01-11 17:39:10.210935: Epoch 48 
2025-01-11 17:39:10.215540: Current learning rate: 0.00825 
2025-01-11 17:39:48.808584: train_loss -0.5275 
2025-01-11 17:39:48.809134: val_loss -0.5566 
2025-01-11 17:39:48.814927: Pseudo dice [np.float32(0.9364), np.float32(0.7116)] 
2025-01-11 17:39:48.819049: Epoch time: 38.6 s 
2025-01-11 17:39:48.822090: Yayy! New best EMA pseudo Dice: 0.7940000295639038 
2025-01-11 17:39:49.457911:  
2025-01-11 17:39:49.458416: Epoch 49 
2025-01-11 17:39:49.463435: Current learning rate: 0.00822 
2025-01-11 17:40:28.034136: train_loss -0.4627 
2025-01-11 17:40:28.035638: val_loss -0.5276 
2025-01-11 17:40:28.040653: Pseudo dice [np.float32(0.9305), np.float32(0.6049)] 
2025-01-11 17:40:28.045669: Epoch time: 38.58 s 
2025-01-11 17:40:28.689962:  
2025-01-11 17:40:28.689962: Epoch 50 
2025-01-11 17:40:28.695008: Current learning rate: 0.00818 
2025-01-11 17:41:07.327724: train_loss -0.5029 
2025-01-11 17:41:07.329271: val_loss -0.4725 
2025-01-11 17:41:07.335001: Pseudo dice [np.float32(0.8973), np.float32(0.528)] 
2025-01-11 17:41:07.338060: Epoch time: 38.64 s 
2025-01-11 17:41:07.856556:  
2025-01-11 17:41:07.857555: Epoch 51 
2025-01-11 17:41:07.862634: Current learning rate: 0.00814 
2025-01-11 17:41:46.467816: train_loss -0.525 
2025-01-11 17:41:46.467816: val_loss -0.5318 
2025-01-11 17:41:46.474837: Pseudo dice [np.float32(0.9114), np.float32(0.709)] 
2025-01-11 17:41:46.478851: Epoch time: 38.61 s 
2025-01-11 17:41:47.173622:  
2025-01-11 17:41:47.173622: Epoch 52 
2025-01-11 17:41:47.179171: Current learning rate: 0.00811 
2025-01-11 17:42:25.770179: train_loss -0.5418 
2025-01-11 17:42:25.771183: val_loss -0.5614 
2025-01-11 17:42:25.777579: Pseudo dice [np.float32(0.9276), np.float32(0.6375)] 
2025-01-11 17:42:25.780591: Epoch time: 38.6 s 
2025-01-11 17:42:26.300755:  
2025-01-11 17:42:26.301266: Epoch 53 
2025-01-11 17:42:26.305875: Current learning rate: 0.00807 
2025-01-11 17:43:04.971154: train_loss -0.5479 
2025-01-11 17:43:04.972158: val_loss -0.597 
2025-01-11 17:43:04.979692: Pseudo dice [np.float32(0.9328), np.float32(0.7083)] 
2025-01-11 17:43:04.984716: Epoch time: 38.67 s 
2025-01-11 17:43:05.506332:  
2025-01-11 17:43:05.506332: Epoch 54 
2025-01-11 17:43:05.511354: Current learning rate: 0.00803 
2025-01-11 17:43:44.130382: train_loss -0.5168 
2025-01-11 17:43:44.130382: val_loss -0.5437 
2025-01-11 17:43:44.136405: Pseudo dice [np.float32(0.9319), np.float32(0.7021)] 
2025-01-11 17:43:44.142920: Epoch time: 38.62 s 
2025-01-11 17:43:44.670472:  
2025-01-11 17:43:44.671472: Epoch 55 
2025-01-11 17:43:44.676485: Current learning rate: 0.008 
2025-01-11 17:44:23.327030: train_loss -0.497 
2025-01-11 17:44:23.327030: val_loss -0.5757 
2025-01-11 17:44:23.333560: Pseudo dice [np.float32(0.9292), np.float32(0.6396)] 
2025-01-11 17:44:23.338577: Epoch time: 38.66 s 
2025-01-11 17:44:23.862335:  
2025-01-11 17:44:23.862335: Epoch 56 
2025-01-11 17:44:23.867862: Current learning rate: 0.00796 
2025-01-11 17:45:02.509829: train_loss -0.5133 
2025-01-11 17:45:02.509829: val_loss -0.5625 
2025-01-11 17:45:02.516345: Pseudo dice [np.float32(0.931), np.float32(0.7323)] 
2025-01-11 17:45:02.523360: Epoch time: 38.65 s 
2025-01-11 17:45:02.528877: Yayy! New best EMA pseudo Dice: 0.7953000068664551 
2025-01-11 17:45:03.169742:  
2025-01-11 17:45:03.169742: Epoch 57 
2025-01-11 17:45:03.175264: Current learning rate: 0.00792 
2025-01-11 17:45:41.840559: train_loss -0.5325 
2025-01-11 17:45:41.841559: val_loss -0.5988 
2025-01-11 17:45:41.847670: Pseudo dice [np.float32(0.9233), np.float32(0.6817)] 
2025-01-11 17:45:41.850705: Epoch time: 38.67 s 
2025-01-11 17:45:41.854756: Yayy! New best EMA pseudo Dice: 0.7960000038146973 
2025-01-11 17:45:42.486672:  
2025-01-11 17:45:42.486672: Epoch 58 
2025-01-11 17:45:42.492261: Current learning rate: 0.00789 
2025-01-11 17:46:21.194650: train_loss -0.5415 
2025-01-11 17:46:21.194650: val_loss -0.529 
2025-01-11 17:46:21.202173: Pseudo dice [np.float32(0.9122), np.float32(0.7248)] 
2025-01-11 17:46:21.206226: Epoch time: 38.71 s 
2025-01-11 17:46:21.209249: Yayy! New best EMA pseudo Dice: 0.79830002784729 
2025-01-11 17:46:22.016055:  
2025-01-11 17:46:22.016055: Epoch 59 
2025-01-11 17:46:22.021608: Current learning rate: 0.00785 
2025-01-11 17:47:00.583679: train_loss -0.5626 
2025-01-11 17:47:00.583679: val_loss -0.5542 
2025-01-11 17:47:00.591202: Pseudo dice [np.float32(0.9426), np.float32(0.7441)] 
2025-01-11 17:47:00.597221: Epoch time: 38.57 s 
2025-01-11 17:47:00.600734: Yayy! New best EMA pseudo Dice: 0.8027999997138977 
2025-01-11 17:47:01.242411:  
2025-01-11 17:47:01.242411: Epoch 60 
2025-01-11 17:47:01.247491: Current learning rate: 0.00781 
2025-01-11 17:47:39.798053: train_loss -0.5126 
2025-01-11 17:47:39.798555: val_loss -0.5019 
2025-01-11 17:47:39.804579: Pseudo dice [np.float32(0.9271), np.float32(0.5573)] 
2025-01-11 17:47:39.808597: Epoch time: 38.56 s 
2025-01-11 17:47:40.328694:  
2025-01-11 17:47:40.328694: Epoch 61 
2025-01-11 17:47:40.334223: Current learning rate: 0.00777 
2025-01-11 17:48:19.009202: train_loss -0.528 
2025-01-11 17:48:19.009202: val_loss -0.5649 
2025-01-11 17:48:19.015732: Pseudo dice [np.float32(0.935), np.float32(0.7109)] 
2025-01-11 17:48:19.021754: Epoch time: 38.68 s 
2025-01-11 17:48:19.547108:  
2025-01-11 17:48:19.547612: Epoch 62 
2025-01-11 17:48:19.552633: Current learning rate: 0.00774 
2025-01-11 17:48:58.164777: train_loss -0.5105 
2025-01-11 17:48:58.165781: val_loss -0.6101 
2025-01-11 17:48:58.173310: Pseudo dice [np.float32(0.9275), np.float32(0.8132)] 
2025-01-11 17:48:58.177324: Epoch time: 38.62 s 
2025-01-11 17:48:58.180835: Yayy! New best EMA pseudo Dice: 0.8065000176429749 
2025-01-11 17:48:58.810930:  
2025-01-11 17:48:58.811439: Epoch 63 
2025-01-11 17:48:58.815998: Current learning rate: 0.0077 
2025-01-11 17:49:37.493333: train_loss -0.5005 
2025-01-11 17:49:37.494334: val_loss -0.6262 
2025-01-11 17:49:37.502353: Pseudo dice [np.float32(0.949), np.float32(0.7791)] 
2025-01-11 17:49:37.507962: Epoch time: 38.68 s 
2025-01-11 17:49:37.514567: Yayy! New best EMA pseudo Dice: 0.8122000098228455 
2025-01-11 17:49:38.130435:  
2025-01-11 17:49:38.131188: Epoch 64 
2025-01-11 17:49:38.136199: Current learning rate: 0.00766 
2025-01-11 17:50:16.705629: train_loss -0.5408 
2025-01-11 17:50:16.706138: val_loss -0.5934 
2025-01-11 17:50:16.712720: Pseudo dice [np.float32(0.9324), np.float32(0.7541)] 
2025-01-11 17:50:16.717377: Epoch time: 38.58 s 
2025-01-11 17:50:16.721467: Yayy! New best EMA pseudo Dice: 0.8152999877929688 
2025-01-11 17:50:17.364262:  
2025-01-11 17:50:17.364262: Epoch 65 
2025-01-11 17:50:17.369881: Current learning rate: 0.00763 
2025-01-11 17:50:56.064072: train_loss -0.5243 
2025-01-11 17:50:56.065077: val_loss -0.5703 
2025-01-11 17:50:56.074103: Pseudo dice [np.float32(0.9191), np.float32(0.6323)] 
2025-01-11 17:50:56.077612: Epoch time: 38.7 s 
2025-01-11 17:50:56.613323:  
2025-01-11 17:50:56.613323: Epoch 66 
2025-01-11 17:50:56.618331: Current learning rate: 0.00759 
2025-01-11 17:51:35.244468: train_loss -0.5173 
2025-01-11 17:51:35.245471: val_loss -0.6062 
2025-01-11 17:51:35.251987: Pseudo dice [np.float32(0.9457), np.float32(0.7522)] 
2025-01-11 17:51:35.256009: Epoch time: 38.63 s 
2025-01-11 17:51:35.785227:  
2025-01-11 17:51:35.786267: Epoch 67 
2025-01-11 17:51:35.790883: Current learning rate: 0.00755 
2025-01-11 17:52:14.419468: train_loss -0.5486 
2025-01-11 17:52:14.420969: val_loss -0.5816 
2025-01-11 17:52:14.427987: Pseudo dice [np.float32(0.9351), np.float32(0.6917)] 
2025-01-11 17:52:14.432003: Epoch time: 38.63 s 
2025-01-11 17:52:15.151232:  
2025-01-11 17:52:15.152232: Epoch 68 
2025-01-11 17:52:15.157305: Current learning rate: 0.00751 
2025-01-11 17:52:53.757733: train_loss -0.5545 
2025-01-11 17:52:53.757733: val_loss -0.6025 
2025-01-11 17:52:53.764320: Pseudo dice [np.float32(0.9386), np.float32(0.7523)] 
2025-01-11 17:52:53.768054: Epoch time: 38.61 s 
2025-01-11 17:52:53.772130: Yayy! New best EMA pseudo Dice: 0.8180000185966492 
2025-01-11 17:52:54.407689:  
2025-01-11 17:52:54.407689: Epoch 69 
2025-01-11 17:52:54.413208: Current learning rate: 0.00748 
2025-01-11 17:53:33.015526: train_loss -0.5482 
2025-01-11 17:53:33.016030: val_loss -0.5288 
2025-01-11 17:53:33.022152: Pseudo dice [np.float32(0.9124), np.float32(0.6224)] 
2025-01-11 17:53:33.025679: Epoch time: 38.61 s 
2025-01-11 17:53:33.558213:  
2025-01-11 17:53:33.559213: Epoch 70 
2025-01-11 17:53:33.564303: Current learning rate: 0.00744 
2025-01-11 17:54:12.294084: train_loss -0.5114 
2025-01-11 17:54:12.294084: val_loss -0.5845 
2025-01-11 17:54:12.300606: Pseudo dice [np.float32(0.9345), np.float32(0.6586)] 
2025-01-11 17:54:12.304126: Epoch time: 38.74 s 
2025-01-11 17:54:12.857247:  
2025-01-11 17:54:12.857247: Epoch 71 
2025-01-11 17:54:12.862789: Current learning rate: 0.0074 
2025-01-11 17:54:51.464890: train_loss -0.5244 
2025-01-11 17:54:51.464890: val_loss -0.5423 
2025-01-11 17:54:51.470911: Pseudo dice [np.float32(0.9299), np.float32(0.6747)] 
2025-01-11 17:54:51.476833: Epoch time: 38.61 s 
2025-01-11 17:54:52.027597:  
2025-01-11 17:54:52.027597: Epoch 72 
2025-01-11 17:54:52.033163: Current learning rate: 0.00737 
2025-01-11 17:55:30.609024: train_loss -0.5488 
2025-01-11 17:55:30.610534: val_loss -0.541 
2025-01-11 17:55:30.616259: Pseudo dice [np.float32(0.9216), np.float32(0.6457)] 
2025-01-11 17:55:30.619766: Epoch time: 38.58 s 
2025-01-11 17:55:31.153559:  
2025-01-11 17:55:31.154564: Epoch 73 
2025-01-11 17:55:31.159270: Current learning rate: 0.00733 
2025-01-11 17:56:09.783584: train_loss -0.561 
2025-01-11 17:56:09.784583: val_loss -0.6413 
2025-01-11 17:56:09.790097: Pseudo dice [np.float32(0.9422), np.float32(0.7841)] 
2025-01-11 17:56:09.796113: Epoch time: 38.63 s 
2025-01-11 17:56:10.334496:  
2025-01-11 17:56:10.334496: Epoch 74 
2025-01-11 17:56:10.340013: Current learning rate: 0.00729 
2025-01-11 17:56:48.894964: train_loss -0.5147 
2025-01-11 17:56:48.894964: val_loss -0.5909 
2025-01-11 17:56:48.900983: Pseudo dice [np.float32(0.9479), np.float32(0.7296)] 
2025-01-11 17:56:48.906008: Epoch time: 38.56 s 
2025-01-11 17:56:49.611493:  
2025-01-11 17:56:49.611493: Epoch 75 
2025-01-11 17:56:49.617506: Current learning rate: 0.00725 
2025-01-11 17:57:28.241162: train_loss -0.5568 
2025-01-11 17:57:28.242166: val_loss -0.5965 
2025-01-11 17:57:28.248700: Pseudo dice [np.float32(0.9369), np.float32(0.6611)] 
2025-01-11 17:57:28.253718: Epoch time: 38.63 s 
2025-01-11 17:57:28.809516:  
2025-01-11 17:57:28.809516: Epoch 76 
2025-01-11 17:57:28.815079: Current learning rate: 0.00722 
2025-01-11 17:58:07.387041: train_loss -0.5347 
2025-01-11 17:58:07.388045: val_loss -0.5753 
2025-01-11 17:58:07.393753: Pseudo dice [np.float32(0.9238), np.float32(0.7775)] 
2025-01-11 17:58:07.396823: Epoch time: 38.58 s 
2025-01-11 17:58:07.947921:  
2025-01-11 17:58:07.948423: Epoch 77 
2025-01-11 17:58:07.953439: Current learning rate: 0.00718 
2025-01-11 17:58:46.535399: train_loss -0.526 
2025-01-11 17:58:46.540408: val_loss -0.4854 
2025-01-11 17:58:46.545422: Pseudo dice [np.float32(0.9215), np.float32(0.5611)] 
2025-01-11 17:58:46.550434: Epoch time: 38.59 s 
2025-01-11 17:58:47.105160:  
2025-01-11 17:58:47.105160: Epoch 78 
2025-01-11 17:58:47.110267: Current learning rate: 0.00714 
2025-01-11 17:59:25.702155: train_loss -0.5074 
2025-01-11 17:59:25.702664: val_loss -0.5397 
2025-01-11 17:59:25.708984: Pseudo dice [np.float32(0.9206), np.float32(0.6788)] 
2025-01-11 17:59:25.713819: Epoch time: 38.6 s 
2025-01-11 17:59:26.261501:  
2025-01-11 17:59:26.261501: Epoch 79 
2025-01-11 17:59:26.265536: Current learning rate: 0.0071 
2025-01-11 18:00:04.837536: train_loss -0.5265 
2025-01-11 18:00:04.838061: val_loss -0.5532 
2025-01-11 18:00:04.845667: Pseudo dice [np.float32(0.9338), np.float32(0.638)] 
2025-01-11 18:00:04.850284: Epoch time: 38.58 s 
2025-01-11 18:00:05.393506:  
2025-01-11 18:00:05.394012: Epoch 80 
2025-01-11 18:00:05.399040: Current learning rate: 0.00707 
2025-01-11 18:00:44.004641: train_loss -0.5656 
2025-01-11 18:00:44.005146: val_loss -0.5756 
2025-01-11 18:00:44.011165: Pseudo dice [np.float32(0.924), np.float32(0.7047)] 
2025-01-11 18:00:44.015176: Epoch time: 38.61 s 
2025-01-11 18:00:44.562729:  
2025-01-11 18:00:44.562729: Epoch 81 
2025-01-11 18:00:44.567743: Current learning rate: 0.00703 
2025-01-11 18:01:23.260628: train_loss -0.5499 
2025-01-11 18:01:23.261628: val_loss -0.5896 
2025-01-11 18:01:23.269651: Pseudo dice [np.float32(0.9292), np.float32(0.7194)] 
2025-01-11 18:01:23.275670: Epoch time: 38.7 s 
2025-01-11 18:01:23.820477:  
2025-01-11 18:01:23.820477: Epoch 82 
2025-01-11 18:01:23.826063: Current learning rate: 0.00699 
2025-01-11 18:02:02.439546: train_loss -0.5594 
2025-01-11 18:02:02.439546: val_loss -0.5804 
2025-01-11 18:02:02.448565: Pseudo dice [np.float32(0.9271), np.float32(0.6957)] 
2025-01-11 18:02:02.453587: Epoch time: 38.62 s 
2025-01-11 18:02:03.146112:  
2025-01-11 18:02:03.146615: Epoch 83 
2025-01-11 18:02:03.152249: Current learning rate: 0.00696 
2025-01-11 18:02:41.733061: train_loss -0.5755 
2025-01-11 18:02:41.733572: val_loss -0.5776 
2025-01-11 18:02:41.738647: Pseudo dice [np.float32(0.927), np.float32(0.6777)] 
2025-01-11 18:02:41.742247: Epoch time: 38.59 s 
2025-01-11 18:02:42.257123:  
2025-01-11 18:02:42.257123: Epoch 84 
2025-01-11 18:02:42.262137: Current learning rate: 0.00692 
2025-01-11 18:03:20.850218: train_loss -0.5631 
2025-01-11 18:03:20.852225: val_loss -0.6203 
2025-01-11 18:03:20.858928: Pseudo dice [np.float32(0.9417), np.float32(0.7716)] 
2025-01-11 18:03:20.862489: Epoch time: 38.59 s 
2025-01-11 18:03:21.382637:  
2025-01-11 18:03:21.383146: Epoch 85 
2025-01-11 18:03:21.387175: Current learning rate: 0.00688 
2025-01-11 18:03:59.936887: train_loss -0.5779 
2025-01-11 18:03:59.937892: val_loss -0.5833 
2025-01-11 18:03:59.944411: Pseudo dice [np.float32(0.9406), np.float32(0.6988)] 
2025-01-11 18:03:59.948424: Epoch time: 38.55 s 
2025-01-11 18:04:00.470915:  
2025-01-11 18:04:00.471417: Epoch 86 
2025-01-11 18:04:00.476518: Current learning rate: 0.00684 
2025-01-11 18:04:39.042725: train_loss -0.5508 
2025-01-11 18:04:39.043732: val_loss -0.5869 
2025-01-11 18:04:39.050248: Pseudo dice [np.float32(0.9421), np.float32(0.5633)] 
2025-01-11 18:04:39.055269: Epoch time: 38.57 s 
2025-01-11 18:04:39.577749:  
2025-01-11 18:04:39.578750: Epoch 87 
2025-01-11 18:04:39.583872: Current learning rate: 0.0068 
2025-01-11 18:05:18.179447: train_loss -0.5473 
2025-01-11 18:05:18.179447: val_loss -0.541 
2025-01-11 18:05:18.186003: Pseudo dice [np.float32(0.9228), np.float32(0.6903)] 
2025-01-11 18:05:18.190043: Epoch time: 38.6 s 
2025-01-11 18:05:18.707479:  
2025-01-11 18:05:18.707479: Epoch 88 
2025-01-11 18:05:18.713551: Current learning rate: 0.00677 
2025-01-11 18:05:57.368847: train_loss -0.5577 
2025-01-11 18:05:57.376365: val_loss -0.5723 
2025-01-11 18:05:57.379876: Pseudo dice [np.float32(0.9285), np.float32(0.6804)] 
2025-01-11 18:05:57.386409: Epoch time: 38.66 s 
2025-01-11 18:05:57.912416:  
2025-01-11 18:05:57.912416: Epoch 89 
2025-01-11 18:05:57.917434: Current learning rate: 0.00673 
2025-01-11 18:06:36.545639: train_loss -0.5586 
2025-01-11 18:06:36.546143: val_loss -0.604 
2025-01-11 18:06:36.553107: Pseudo dice [np.float32(0.9146), np.float32(0.7432)] 
2025-01-11 18:06:36.560141: Epoch time: 38.63 s 
2025-01-11 18:06:37.079611:  
2025-01-11 18:06:37.080114: Epoch 90 
2025-01-11 18:06:37.085124: Current learning rate: 0.00669 
2025-01-11 18:07:15.716091: train_loss -0.5451 
2025-01-11 18:07:15.716091: val_loss -0.5757 
2025-01-11 18:07:15.723611: Pseudo dice [np.float32(0.9317), np.float32(0.6463)] 
2025-01-11 18:07:15.728625: Epoch time: 38.64 s 
2025-01-11 18:07:16.424911:  
2025-01-11 18:07:16.425912: Epoch 91 
2025-01-11 18:07:16.430977: Current learning rate: 0.00665 
2025-01-11 18:07:55.028614: train_loss -0.5735 
2025-01-11 18:07:55.029614: val_loss -0.6258 
2025-01-11 18:07:55.036135: Pseudo dice [np.float32(0.9442), np.float32(0.7851)] 
2025-01-11 18:07:55.041660: Epoch time: 38.6 s 
2025-01-11 18:07:55.561500:  
2025-01-11 18:07:55.562003: Epoch 92 
2025-01-11 18:07:55.565554: Current learning rate: 0.00662 
2025-01-11 18:08:34.209701: train_loss -0.6267 
2025-01-11 18:08:34.210701: val_loss -0.5958 
2025-01-11 18:08:34.217224: Pseudo dice [np.float32(0.9408), np.float32(0.6937)] 
2025-01-11 18:08:34.220732: Epoch time: 38.65 s 
2025-01-11 18:08:34.736643:  
2025-01-11 18:08:34.737145: Epoch 93 
2025-01-11 18:08:34.742157: Current learning rate: 0.00658 
2025-01-11 18:09:13.341491: train_loss -0.5699 
2025-01-11 18:09:13.341491: val_loss -0.601 
2025-01-11 18:09:13.348574: Pseudo dice [np.float32(0.95), np.float32(0.706)] 
2025-01-11 18:09:13.352600: Epoch time: 38.61 s 
2025-01-11 18:09:13.872993:  
2025-01-11 18:09:13.872993: Epoch 94 
2025-01-11 18:09:13.879032: Current learning rate: 0.00654 
2025-01-11 18:09:52.474503: train_loss -0.5634 
2025-01-11 18:09:52.474503: val_loss -0.5918 
2025-01-11 18:09:52.482153: Pseudo dice [np.float32(0.9276), np.float32(0.7962)] 
2025-01-11 18:09:52.486751: Epoch time: 38.6 s 
2025-01-11 18:09:52.491342: Yayy! New best EMA pseudo Dice: 0.8198000192642212 
2025-01-11 18:09:53.120123:  
2025-01-11 18:09:53.120123: Epoch 95 
2025-01-11 18:09:53.125687: Current learning rate: 0.0065 
2025-01-11 18:10:31.742979: train_loss -0.5855 
2025-01-11 18:10:31.743979: val_loss -0.5973 
2025-01-11 18:10:31.750508: Pseudo dice [np.float32(0.9352), np.float32(0.6821)] 
2025-01-11 18:10:31.755077: Epoch time: 38.62 s 
2025-01-11 18:10:32.273928:  
2025-01-11 18:10:32.273928: Epoch 96 
2025-01-11 18:10:32.279471: Current learning rate: 0.00647 
2025-01-11 18:11:11.013188: train_loss -0.5727 
2025-01-11 18:11:11.013188: val_loss -0.5575 
2025-01-11 18:11:11.019702: Pseudo dice [np.float32(0.9392), np.float32(0.7211)] 
2025-01-11 18:11:11.023214: Epoch time: 38.74 s 
2025-01-11 18:11:11.027224: Yayy! New best EMA pseudo Dice: 0.8198000192642212 
2025-01-11 18:11:11.659618:  
2025-01-11 18:11:11.659618: Epoch 97 
2025-01-11 18:11:11.664677: Current learning rate: 0.00643 
2025-01-11 18:11:50.286129: train_loss -0.5918 
2025-01-11 18:11:50.288133: val_loss -0.5711 
2025-01-11 18:11:50.293656: Pseudo dice [np.float32(0.9279), np.float32(0.7338)] 
2025-01-11 18:11:50.297168: Epoch time: 38.63 s 
2025-01-11 18:11:50.300759: Yayy! New best EMA pseudo Dice: 0.820900022983551 
2025-01-11 18:11:50.947119:  
2025-01-11 18:11:50.947119: Epoch 98 
2025-01-11 18:11:50.952667: Current learning rate: 0.00639 
2025-01-11 18:12:29.527763: train_loss -0.5517 
2025-01-11 18:12:29.528768: val_loss -0.6103 
2025-01-11 18:12:29.535866: Pseudo dice [np.float32(0.9381), np.float32(0.7243)] 
2025-01-11 18:12:29.542418: Epoch time: 38.58 s 
2025-01-11 18:12:29.545937: Yayy! New best EMA pseudo Dice: 0.8220000267028809 
2025-01-11 18:12:30.206217:  
2025-01-11 18:12:30.206217: Epoch 99 
2025-01-11 18:12:30.211740: Current learning rate: 0.00635 
2025-01-11 18:13:09.185532: train_loss -0.5916 
2025-01-11 18:13:09.186535: val_loss -0.6153 
2025-01-11 18:13:09.193055: Pseudo dice [np.float32(0.9471), np.float32(0.7492)] 
2025-01-11 18:13:09.199075: Epoch time: 38.98 s 
2025-01-11 18:13:09.290035: Yayy! New best EMA pseudo Dice: 0.8245999813079834 
2025-01-11 18:13:10.114978:  
2025-01-11 18:13:10.115983: Epoch 100 
2025-01-11 18:13:10.120555: Current learning rate: 0.00631 
2025-01-11 18:13:48.762170: train_loss -0.5578 
2025-01-11 18:13:48.762676: val_loss -0.6018 
2025-01-11 18:13:48.768820: Pseudo dice [np.float32(0.9358), np.float32(0.6511)] 
2025-01-11 18:13:48.771856: Epoch time: 38.65 s 
2025-01-11 18:13:49.291610:  
2025-01-11 18:13:49.293117: Epoch 101 
2025-01-11 18:13:49.298748: Current learning rate: 0.00628 
2025-01-11 18:14:27.879757: train_loss -0.537 
2025-01-11 18:14:27.880259: val_loss -0.596 
2025-01-11 18:14:27.886441: Pseudo dice [np.float32(0.9355), np.float32(0.7975)] 
2025-01-11 18:14:27.890486: Epoch time: 38.59 s 
2025-01-11 18:14:27.894071: Yayy! New best EMA pseudo Dice: 0.8259999752044678 
2025-01-11 18:14:28.523944:  
2025-01-11 18:14:28.523944: Epoch 102 
2025-01-11 18:14:28.529517: Current learning rate: 0.00624 
2025-01-11 18:15:07.096669: train_loss -0.5711 
2025-01-11 18:15:07.097672: val_loss -0.5861 
2025-01-11 18:15:07.104237: Pseudo dice [np.float32(0.9324), np.float32(0.7898)] 
2025-01-11 18:15:07.108274: Epoch time: 38.57 s 
2025-01-11 18:15:07.113328: Yayy! New best EMA pseudo Dice: 0.8295000195503235 
2025-01-11 18:15:07.749351:  
2025-01-11 18:15:07.749852: Epoch 103 
2025-01-11 18:15:07.754867: Current learning rate: 0.0062 
2025-01-11 18:15:46.362626: train_loss -0.5787 
2025-01-11 18:15:46.363626: val_loss -0.5724 
2025-01-11 18:15:46.369148: Pseudo dice [np.float32(0.9308), np.float32(0.7054)] 
2025-01-11 18:15:46.374165: Epoch time: 38.61 s 
2025-01-11 18:15:46.901009:  
2025-01-11 18:15:46.901009: Epoch 104 
2025-01-11 18:15:46.907064: Current learning rate: 0.00616 
2025-01-11 18:16:25.564787: train_loss -0.5428 
2025-01-11 18:16:25.565290: val_loss -0.5903 
2025-01-11 18:16:25.572316: Pseudo dice [np.float32(0.9406), np.float32(0.6679)] 
2025-01-11 18:16:25.576332: Epoch time: 38.66 s 
2025-01-11 18:16:26.110418:  
2025-01-11 18:16:26.110921: Epoch 105 
2025-01-11 18:16:26.115939: Current learning rate: 0.00612 
2025-01-11 18:17:04.745744: train_loss -0.5658 
2025-01-11 18:17:04.746246: val_loss -0.6326 
2025-01-11 18:17:04.752262: Pseudo dice [np.float32(0.936), np.float32(0.7922)] 
2025-01-11 18:17:04.757279: Epoch time: 38.64 s 
2025-01-11 18:17:04.762302: Yayy! New best EMA pseudo Dice: 0.8296999931335449 
2025-01-11 18:17:05.407362:  
2025-01-11 18:17:05.407362: Epoch 106 
2025-01-11 18:17:05.413388: Current learning rate: 0.00609 
2025-01-11 18:17:44.091945: train_loss -0.5507 
2025-01-11 18:17:44.093450: val_loss -0.5718 
2025-01-11 18:17:44.100468: Pseudo dice [np.float32(0.9504), np.float32(0.7402)] 
2025-01-11 18:17:44.105483: Epoch time: 38.69 s 
2025-01-11 18:17:44.110496: Yayy! New best EMA pseudo Dice: 0.8313000202178955 
2025-01-11 18:17:44.942202:  
2025-01-11 18:17:44.942703: Epoch 107 
2025-01-11 18:17:44.947715: Current learning rate: 0.00605 
2025-01-11 18:18:23.535718: train_loss -0.5779 
2025-01-11 18:18:23.536222: val_loss -0.5671 
2025-01-11 18:18:23.542241: Pseudo dice [np.float32(0.9342), np.float32(0.6158)] 
2025-01-11 18:18:23.548255: Epoch time: 38.59 s 
2025-01-11 18:18:24.075775:  
2025-01-11 18:18:24.075775: Epoch 108 
2025-01-11 18:18:24.080801: Current learning rate: 0.00601 
2025-01-11 18:19:02.819108: train_loss -0.5652 
2025-01-11 18:19:02.820111: val_loss -0.6175 
2025-01-11 18:19:02.827631: Pseudo dice [np.float32(0.9429), np.float32(0.7749)] 
2025-01-11 18:19:02.834147: Epoch time: 38.74 s 
2025-01-11 18:19:03.363962:  
2025-01-11 18:19:03.364962: Epoch 109 
2025-01-11 18:19:03.370482: Current learning rate: 0.00597 
2025-01-11 18:19:42.070062: train_loss -0.5971 
2025-01-11 18:19:42.072078: val_loss -0.6186 
2025-01-11 18:19:42.078266: Pseudo dice [np.float32(0.9457), np.float32(0.7489)] 
2025-01-11 18:19:42.084924: Epoch time: 38.71 s 
2025-01-11 18:19:42.612094:  
2025-01-11 18:19:42.612604: Epoch 110 
2025-01-11 18:19:42.618193: Current learning rate: 0.00593 
2025-01-11 18:20:21.349737: train_loss -0.5934 
2025-01-11 18:20:21.350293: val_loss -0.5382 
2025-01-11 18:20:21.356315: Pseudo dice [np.float32(0.9229), np.float32(0.7254)] 
2025-01-11 18:20:21.361335: Epoch time: 38.74 s 
2025-01-11 18:20:21.888010:  
2025-01-11 18:20:21.889010: Epoch 111 
2025-01-11 18:20:21.894172: Current learning rate: 0.0059 
2025-01-11 18:21:00.548892: train_loss -0.6003 
2025-01-11 18:21:00.549397: val_loss -0.5859 
2025-01-11 18:21:00.556416: Pseudo dice [np.float32(0.9452), np.float32(0.7438)] 
2025-01-11 18:21:00.560434: Epoch time: 38.66 s 
2025-01-11 18:21:00.564449: Yayy! New best EMA pseudo Dice: 0.83160001039505 
2025-01-11 18:21:01.195360:  
2025-01-11 18:21:01.195360: Epoch 112 
2025-01-11 18:21:01.199874: Current learning rate: 0.00586 
2025-01-11 18:21:39.978994: train_loss -0.6102 
2025-01-11 18:21:39.979510: val_loss -0.6314 
2025-01-11 18:21:39.987036: Pseudo dice [np.float32(0.9443), np.float32(0.705)] 
2025-01-11 18:21:39.992574: Epoch time: 38.78 s 
2025-01-11 18:21:40.510296:  
2025-01-11 18:21:40.510296: Epoch 113 
2025-01-11 18:21:40.515813: Current learning rate: 0.00582 
2025-01-11 18:22:19.097892: train_loss -0.5809 
2025-01-11 18:22:19.098896: val_loss -0.6469 
2025-01-11 18:22:19.104436: Pseudo dice [np.float32(0.9548), np.float32(0.7232)] 
2025-01-11 18:22:19.110678: Epoch time: 38.59 s 
2025-01-11 18:22:19.115725: Yayy! New best EMA pseudo Dice: 0.8317000269889832 
2025-01-11 18:22:19.755425:  
2025-01-11 18:22:19.756430: Epoch 114 
2025-01-11 18:22:19.761521: Current learning rate: 0.00578 
2025-01-11 18:22:58.327696: train_loss -0.5629 
2025-01-11 18:22:58.327696: val_loss -0.6032 
2025-01-11 18:22:58.334787: Pseudo dice [np.float32(0.931), np.float32(0.6951)] 
2025-01-11 18:22:58.340924: Epoch time: 38.57 s 
2025-01-11 18:22:58.866068:  
2025-01-11 18:22:58.866068: Epoch 115 
2025-01-11 18:22:58.871653: Current learning rate: 0.00574 
2025-01-11 18:23:37.450333: train_loss -0.6129 
2025-01-11 18:23:37.450333: val_loss -0.6138 
2025-01-11 18:23:37.457350: Pseudo dice [np.float32(0.9468), np.float32(0.7106)] 
2025-01-11 18:23:37.461366: Epoch time: 38.58 s 
2025-01-11 18:23:38.168445:  
2025-01-11 18:23:38.168445: Epoch 116 
2025-01-11 18:23:38.173964: Current learning rate: 0.0057 
2025-01-11 18:24:16.775040: train_loss -0.611 
2025-01-11 18:24:16.776039: val_loss -0.5352 
2025-01-11 18:24:16.781555: Pseudo dice [np.float32(0.9199), np.float32(0.5955)] 
2025-01-11 18:24:16.786577: Epoch time: 38.61 s 
2025-01-11 18:24:17.318146:  
2025-01-11 18:24:17.318655: Epoch 117 
2025-01-11 18:24:17.323755: Current learning rate: 0.00567 
2025-01-11 18:24:55.887519: train_loss -0.616 
2025-01-11 18:24:55.888043: val_loss -0.6485 
2025-01-11 18:24:55.895574: Pseudo dice [np.float32(0.9403), np.float32(0.76)] 
2025-01-11 18:24:55.900089: Epoch time: 38.57 s 
2025-01-11 18:24:56.426939:  
2025-01-11 18:24:56.426939: Epoch 118 
2025-01-11 18:24:56.432456: Current learning rate: 0.00563 
2025-01-11 18:25:35.019817: train_loss -0.6066 
2025-01-11 18:25:35.020330: val_loss -0.6071 
2025-01-11 18:25:35.026921: Pseudo dice [np.float32(0.94), np.float32(0.6583)] 
2025-01-11 18:25:35.032007: Epoch time: 38.59 s 
2025-01-11 18:25:35.557540:  
2025-01-11 18:25:35.557540: Epoch 119 
2025-01-11 18:25:35.563105: Current learning rate: 0.00559 
2025-01-11 18:26:14.240159: train_loss -0.6147 
2025-01-11 18:26:14.241162: val_loss -0.597 
2025-01-11 18:26:14.247179: Pseudo dice [np.float32(0.9462), np.float32(0.683)] 
2025-01-11 18:26:14.250190: Epoch time: 38.68 s 
2025-01-11 18:26:14.781412:  
2025-01-11 18:26:14.781412: Epoch 120 
2025-01-11 18:26:14.784923: Current learning rate: 0.00555 
2025-01-11 18:26:53.392436: train_loss -0.5816 
2025-01-11 18:26:53.392943: val_loss -0.5866 
2025-01-11 18:26:53.400172: Pseudo dice [np.float32(0.9384), np.float32(0.5782)] 
2025-01-11 18:26:53.405188: Epoch time: 38.61 s 
2025-01-11 18:26:53.931955:  
2025-01-11 18:26:53.932456: Epoch 121 
2025-01-11 18:26:53.937470: Current learning rate: 0.00551 
2025-01-11 18:27:32.791344: train_loss -0.6125 
2025-01-11 18:27:32.791853: val_loss -0.6453 
2025-01-11 18:27:32.799515: Pseudo dice [np.float32(0.9475), np.float32(0.7646)] 
2025-01-11 18:27:32.804595: Epoch time: 38.86 s 
2025-01-11 18:27:33.337012:  
2025-01-11 18:27:33.337012: Epoch 122 
2025-01-11 18:27:33.342527: Current learning rate: 0.00547 
2025-01-11 18:28:12.089185: train_loss -0.6119 
2025-01-11 18:28:12.090189: val_loss -0.6195 
2025-01-11 18:28:12.097715: Pseudo dice [np.float32(0.9404), np.float32(0.7753)] 
2025-01-11 18:28:12.102732: Epoch time: 38.75 s 
2025-01-11 18:28:12.632252:  
2025-01-11 18:28:12.632252: Epoch 123 
2025-01-11 18:28:12.638325: Current learning rate: 0.00544 
2025-01-11 18:28:51.232380: train_loss -0.6014 
2025-01-11 18:28:51.233383: val_loss -0.6597 
2025-01-11 18:28:51.239542: Pseudo dice [np.float32(0.9521), np.float32(0.7936)] 
2025-01-11 18:28:51.243164: Epoch time: 38.6 s 
2025-01-11 18:28:51.951832:  
2025-01-11 18:28:51.951832: Epoch 124 
2025-01-11 18:28:51.956860: Current learning rate: 0.0054 
2025-01-11 18:29:30.557123: train_loss -0.5668 
2025-01-11 18:29:30.558125: val_loss -0.6103 
2025-01-11 18:29:30.564646: Pseudo dice [np.float32(0.9492), np.float32(0.7625)] 
2025-01-11 18:29:30.568657: Epoch time: 38.61 s 
2025-01-11 18:29:31.130519:  
2025-01-11 18:29:31.130519: Epoch 125 
2025-01-11 18:29:31.138572: Current learning rate: 0.00536 
2025-01-11 18:30:09.728100: train_loss -0.6047 
2025-01-11 18:30:09.729103: val_loss -0.6345 
2025-01-11 18:30:09.737628: Pseudo dice [np.float32(0.9479), np.float32(0.7194)] 
2025-01-11 18:30:09.742641: Epoch time: 38.6 s 
2025-01-11 18:30:10.275224:  
2025-01-11 18:30:10.275224: Epoch 126 
2025-01-11 18:30:10.280740: Current learning rate: 0.00532 
2025-01-11 18:30:48.944289: train_loss -0.5932 
2025-01-11 18:30:48.946310: val_loss -0.6006 
2025-01-11 18:30:48.951913: Pseudo dice [np.float32(0.9539), np.float32(0.7844)] 
2025-01-11 18:30:48.957488: Epoch time: 38.67 s 
2025-01-11 18:30:48.962555: Yayy! New best EMA pseudo Dice: 0.835099995136261 
2025-01-11 18:30:49.609895:  
2025-01-11 18:30:49.609895: Epoch 127 
2025-01-11 18:30:49.613958: Current learning rate: 0.00528 
2025-01-11 18:31:28.227597: train_loss -0.5786 
2025-01-11 18:31:28.228601: val_loss -0.5956 
2025-01-11 18:31:28.236133: Pseudo dice [np.float32(0.9443), np.float32(0.8093)] 
2025-01-11 18:31:28.240176: Epoch time: 38.62 s 
2025-01-11 18:31:28.244239: Yayy! New best EMA pseudo Dice: 0.8392999768257141 
2025-01-11 18:31:28.903064:  
2025-01-11 18:31:28.903567: Epoch 128 
2025-01-11 18:31:28.908586: Current learning rate: 0.00524 
2025-01-11 18:32:07.525251: train_loss -0.5927 
2025-01-11 18:32:07.526258: val_loss -0.6391 
2025-01-11 18:32:07.532781: Pseudo dice [np.float32(0.9512), np.float32(0.7388)] 
2025-01-11 18:32:07.536291: Epoch time: 38.62 s 
2025-01-11 18:32:07.541304: Yayy! New best EMA pseudo Dice: 0.839900016784668 
2025-01-11 18:32:08.193494:  
2025-01-11 18:32:08.193998: Epoch 129 
2025-01-11 18:32:08.199059: Current learning rate: 0.0052 
2025-01-11 18:32:46.872093: train_loss -0.5782 
2025-01-11 18:32:46.873098: val_loss -0.66 
2025-01-11 18:32:46.879151: Pseudo dice [np.float32(0.9303), np.float32(0.8189)] 
2025-01-11 18:32:46.884233: Epoch time: 38.68 s 
2025-01-11 18:32:46.888785: Yayy! New best EMA pseudo Dice: 0.8432999849319458 
2025-01-11 18:32:47.541387:  
2025-01-11 18:32:47.541387: Epoch 130 
2025-01-11 18:32:47.546969: Current learning rate: 0.00517 
2025-01-11 18:33:26.174376: train_loss -0.5852 
2025-01-11 18:33:26.174376: val_loss -0.6103 
2025-01-11 18:33:26.182948: Pseudo dice [np.float32(0.9339), np.float32(0.8211)] 
2025-01-11 18:33:26.186471: Epoch time: 38.63 s 
2025-01-11 18:33:26.192009: Yayy! New best EMA pseudo Dice: 0.8467000126838684 
2025-01-11 18:33:26.855431:  
2025-01-11 18:33:26.855431: Epoch 131 
2025-01-11 18:33:26.860997: Current learning rate: 0.00513 
2025-01-11 18:34:05.515869: train_loss -0.6195 
2025-01-11 18:34:05.515869: val_loss -0.6266 
2025-01-11 18:34:05.523396: Pseudo dice [np.float32(0.949), np.float32(0.7066)] 
2025-01-11 18:34:05.526913: Epoch time: 38.66 s 
2025-01-11 18:34:06.243028:  
2025-01-11 18:34:06.243028: Epoch 132 
2025-01-11 18:34:06.248553: Current learning rate: 0.00509 
2025-01-11 18:34:44.854735: train_loss -0.5869 
2025-01-11 18:34:44.854735: val_loss -0.6951 
2025-01-11 18:34:44.861752: Pseudo dice [np.float32(0.948), np.float32(0.7759)] 
2025-01-11 18:34:44.867314: Epoch time: 38.61 s 
2025-01-11 18:34:45.408672:  
2025-01-11 18:34:45.409175: Epoch 133 
2025-01-11 18:34:45.414193: Current learning rate: 0.00505 
2025-01-11 18:35:24.123814: train_loss -0.5801 
2025-01-11 18:35:24.124816: val_loss -0.5669 
2025-01-11 18:35:24.131344: Pseudo dice [np.float32(0.9367), np.float32(0.6946)] 
2025-01-11 18:35:24.135350: Epoch time: 38.72 s 
2025-01-11 18:35:24.668568:  
2025-01-11 18:35:24.669073: Epoch 134 
2025-01-11 18:35:24.674756: Current learning rate: 0.00501 
2025-01-11 18:36:03.337865: train_loss -0.5938 
2025-01-11 18:36:03.337865: val_loss -0.6285 
2025-01-11 18:36:03.344481: Pseudo dice [np.float32(0.949), np.float32(0.7071)] 
2025-01-11 18:36:03.350594: Epoch time: 38.67 s 
2025-01-11 18:36:03.892461:  
2025-01-11 18:36:03.892461: Epoch 135 
2025-01-11 18:36:03.898551: Current learning rate: 0.00497 
2025-01-11 18:36:42.513688: train_loss -0.6348 
2025-01-11 18:36:42.515194: val_loss -0.615 
2025-01-11 18:36:42.521217: Pseudo dice [np.float32(0.943), np.float32(0.7175)] 
2025-01-11 18:36:42.527287: Epoch time: 38.62 s 
2025-01-11 18:36:43.078382:  
2025-01-11 18:36:43.079381: Epoch 136 
2025-01-11 18:36:43.084458: Current learning rate: 0.00493 
2025-01-11 18:37:21.818733: train_loss -0.634 
2025-01-11 18:37:21.818733: val_loss -0.61 
2025-01-11 18:37:21.826268: Pseudo dice [np.float32(0.9408), np.float32(0.6746)] 
2025-01-11 18:37:21.829786: Epoch time: 38.74 s 
2025-01-11 18:37:22.378897:  
2025-01-11 18:37:22.378897: Epoch 137 
2025-01-11 18:37:22.384437: Current learning rate: 0.00489 
2025-01-11 18:38:01.052677: train_loss -0.6278 
2025-01-11 18:38:01.052677: val_loss -0.6578 
2025-01-11 18:38:01.059690: Pseudo dice [np.float32(0.952), np.float32(0.8331)] 
2025-01-11 18:38:01.065203: Epoch time: 38.67 s 
2025-01-11 18:38:01.622588:  
2025-01-11 18:38:01.622588: Epoch 138 
2025-01-11 18:38:01.627612: Current learning rate: 0.00485 
2025-01-11 18:38:40.267294: train_loss -0.6269 
2025-01-11 18:38:40.268294: val_loss -0.6645 
2025-01-11 18:38:40.274369: Pseudo dice [np.float32(0.9469), np.float32(0.6767)] 
2025-01-11 18:38:40.278374: Epoch time: 38.65 s 
2025-01-11 18:38:40.818927:  
2025-01-11 18:38:40.818927: Epoch 139 
2025-01-11 18:38:40.823939: Current learning rate: 0.00482 
2025-01-11 18:39:19.416093: train_loss -0.6187 
2025-01-11 18:39:19.417092: val_loss -0.6585 
2025-01-11 18:39:19.423404: Pseudo dice [np.float32(0.9534), np.float32(0.8231)] 
2025-01-11 18:39:19.430928: Epoch time: 38.6 s 
2025-01-11 18:39:20.149197:  
2025-01-11 18:39:20.149700: Epoch 140 
2025-01-11 18:39:20.154768: Current learning rate: 0.00478 
2025-01-11 18:39:58.741507: train_loss -0.6162 
2025-01-11 18:39:58.742010: val_loss -0.6223 
2025-01-11 18:39:58.749034: Pseudo dice [np.float32(0.9366), np.float32(0.6647)] 
2025-01-11 18:39:58.753049: Epoch time: 38.59 s 
2025-01-11 18:39:59.293608:  
2025-01-11 18:39:59.294614: Epoch 141 
2025-01-11 18:39:59.299156: Current learning rate: 0.00474 
2025-01-11 18:40:37.941210: train_loss -0.6372 
2025-01-11 18:40:37.941210: val_loss -0.5836 
2025-01-11 18:40:37.947733: Pseudo dice [np.float32(0.9467), np.float32(0.7438)] 
2025-01-11 18:40:37.952241: Epoch time: 38.65 s 
2025-01-11 18:40:38.496030:  
2025-01-11 18:40:38.496532: Epoch 142 
2025-01-11 18:40:38.502116: Current learning rate: 0.0047 
2025-01-11 18:41:17.146692: train_loss -0.6163 
2025-01-11 18:41:17.147692: val_loss -0.599 
2025-01-11 18:41:17.154217: Pseudo dice [np.float32(0.9435), np.float32(0.7112)] 
2025-01-11 18:41:17.158231: Epoch time: 38.65 s 
2025-01-11 18:41:17.710654:  
2025-01-11 18:41:17.710654: Epoch 143 
2025-01-11 18:41:17.716269: Current learning rate: 0.00466 
2025-01-11 18:41:56.383797: train_loss -0.6202 
2025-01-11 18:41:56.385308: val_loss -0.6635 
2025-01-11 18:41:56.391829: Pseudo dice [np.float32(0.9647), np.float32(0.7213)] 
2025-01-11 18:41:56.397849: Epoch time: 38.67 s 
2025-01-11 18:41:56.951550:  
2025-01-11 18:41:56.951550: Epoch 144 
2025-01-11 18:41:56.956564: Current learning rate: 0.00462 
2025-01-11 18:42:35.604934: train_loss -0.6251 
2025-01-11 18:42:35.605937: val_loss -0.5937 
2025-01-11 18:42:35.615964: Pseudo dice [np.float32(0.9438), np.float32(0.6708)] 
2025-01-11 18:42:35.620981: Epoch time: 38.65 s 
2025-01-11 18:42:36.160151:  
2025-01-11 18:42:36.160151: Epoch 145 
2025-01-11 18:42:36.166215: Current learning rate: 0.00458 
2025-01-11 18:43:14.915478: train_loss -0.5994 
2025-01-11 18:43:14.915478: val_loss -0.598 
2025-01-11 18:43:14.922999: Pseudo dice [np.float32(0.9532), np.float32(0.676)] 
2025-01-11 18:43:14.928015: Epoch time: 38.76 s 
2025-01-11 18:43:15.474884:  
2025-01-11 18:43:15.475885: Epoch 146 
2025-01-11 18:43:15.480957: Current learning rate: 0.00454 
2025-01-11 18:43:54.203271: train_loss -0.6368 
2025-01-11 18:43:54.204774: val_loss -0.617 
2025-01-11 18:43:54.211800: Pseudo dice [np.float32(0.9541), np.float32(0.7515)] 
2025-01-11 18:43:54.217318: Epoch time: 38.73 s 
2025-01-11 18:43:54.768066:  
2025-01-11 18:43:54.769070: Epoch 147 
2025-01-11 18:43:54.774699: Current learning rate: 0.0045 
2025-01-11 18:44:33.409383: train_loss -0.6324 
2025-01-11 18:44:33.410384: val_loss -0.6475 
2025-01-11 18:44:33.415903: Pseudo dice [np.float32(0.9508), np.float32(0.6922)] 
2025-01-11 18:44:33.421927: Epoch time: 38.64 s 
2025-01-11 18:44:34.155957:  
2025-01-11 18:44:34.156961: Epoch 148 
2025-01-11 18:44:34.163480: Current learning rate: 0.00446 
2025-01-11 18:45:12.771056: train_loss -0.6136 
2025-01-11 18:45:12.772060: val_loss -0.6391 
2025-01-11 18:45:12.779157: Pseudo dice [np.float32(0.9483), np.float32(0.7697)] 
2025-01-11 18:45:12.783221: Epoch time: 38.62 s 
2025-01-11 18:45:13.330649:  
2025-01-11 18:45:13.331153: Epoch 149 
2025-01-11 18:45:13.335740: Current learning rate: 0.00442 
2025-01-11 18:45:51.999786: train_loss -0.598 
2025-01-11 18:45:52.000289: val_loss -0.6296 
2025-01-11 18:45:52.007818: Pseudo dice [np.float32(0.9434), np.float32(0.716)] 
2025-01-11 18:45:52.013846: Epoch time: 38.67 s 
2025-01-11 18:45:52.672172:  
2025-01-11 18:45:52.672172: Epoch 150 
2025-01-11 18:45:52.677192: Current learning rate: 0.00438 
2025-01-11 18:46:31.358277: train_loss -0.6161 
2025-01-11 18:46:31.358786: val_loss -0.5923 
2025-01-11 18:46:31.365886: Pseudo dice [np.float32(0.9359), np.float32(0.7305)] 
2025-01-11 18:46:31.371480: Epoch time: 38.69 s 
2025-01-11 18:46:31.921407:  
2025-01-11 18:46:31.921407: Epoch 151 
2025-01-11 18:46:31.926427: Current learning rate: 0.00434 
2025-01-11 18:47:10.588119: train_loss -0.6154 
2025-01-11 18:47:10.589141: val_loss -0.5742 
2025-01-11 18:47:10.594266: Pseudo dice [np.float32(0.9497), np.float32(0.7235)] 
2025-01-11 18:47:10.599323: Epoch time: 38.67 s 
2025-01-11 18:47:11.147300:  
2025-01-11 18:47:11.147300: Epoch 152 
2025-01-11 18:47:11.153323: Current learning rate: 0.0043 
2025-01-11 18:47:49.810979: train_loss -0.6241 
2025-01-11 18:47:49.810979: val_loss -0.5942 
2025-01-11 18:47:49.818125: Pseudo dice [np.float32(0.9403), np.float32(0.611)] 
2025-01-11 18:47:49.822701: Epoch time: 38.67 s 
2025-01-11 18:47:50.373654:  
2025-01-11 18:47:50.373654: Epoch 153 
2025-01-11 18:47:50.378669: Current learning rate: 0.00427 
2025-01-11 18:48:29.022601: train_loss -0.6536 
2025-01-11 18:48:29.022601: val_loss -0.5741 
2025-01-11 18:48:29.027666: Pseudo dice [np.float32(0.9291), np.float32(0.6335)] 
2025-01-11 18:48:29.031748: Epoch time: 38.65 s 
2025-01-11 18:48:29.581141:  
2025-01-11 18:48:29.581141: Epoch 154 
2025-01-11 18:48:29.587241: Current learning rate: 0.00423 
2025-01-11 18:49:08.176322: train_loss -0.5798 
2025-01-11 18:49:08.176826: val_loss -0.6923 
2025-01-11 18:49:08.183845: Pseudo dice [np.float32(0.9528), np.float32(0.8199)] 
2025-01-11 18:49:08.187400: Epoch time: 38.6 s 
2025-01-11 18:49:08.917353:  
2025-01-11 18:49:08.917353: Epoch 155 
2025-01-11 18:49:08.923370: Current learning rate: 0.00419 
2025-01-11 18:49:47.536767: train_loss -0.6192 
2025-01-11 18:49:47.538281: val_loss -0.6001 
2025-01-11 18:49:47.547360: Pseudo dice [np.float32(0.9373), np.float32(0.6866)] 
2025-01-11 18:49:47.552379: Epoch time: 38.62 s 
2025-01-11 18:49:48.109349:  
2025-01-11 18:49:48.109349: Epoch 156 
2025-01-11 18:49:48.115394: Current learning rate: 0.00415 
2025-01-11 18:50:26.865125: train_loss -0.6374 
2025-01-11 18:50:26.865125: val_loss -0.6174 
2025-01-11 18:50:26.872649: Pseudo dice [np.float32(0.9454), np.float32(0.8087)] 
2025-01-11 18:50:26.876163: Epoch time: 38.76 s 
2025-01-11 18:50:27.427485:  
2025-01-11 18:50:27.427485: Epoch 157 
2025-01-11 18:50:27.433553: Current learning rate: 0.00411 
2025-01-11 18:51:06.182611: train_loss -0.6173 
2025-01-11 18:51:06.183615: val_loss -0.707 
2025-01-11 18:51:06.191131: Pseudo dice [np.float32(0.9569), np.float32(0.7719)] 
2025-01-11 18:51:06.195141: Epoch time: 38.76 s 
2025-01-11 18:51:06.748858:  
2025-01-11 18:51:06.748858: Epoch 158 
2025-01-11 18:51:06.754890: Current learning rate: 0.00407 
2025-01-11 18:51:45.394146: train_loss -0.6233 
2025-01-11 18:51:45.395149: val_loss -0.6118 
2025-01-11 18:51:45.401672: Pseudo dice [np.float32(0.9452), np.float32(0.6994)] 
2025-01-11 18:51:45.407697: Epoch time: 38.65 s 
2025-01-11 18:51:45.964421:  
2025-01-11 18:51:45.964421: Epoch 159 
2025-01-11 18:51:45.969964: Current learning rate: 0.00403 
2025-01-11 18:52:24.665574: train_loss -0.6298 
2025-01-11 18:52:24.665574: val_loss -0.5707 
2025-01-11 18:52:24.673108: Pseudo dice [np.float32(0.9274), np.float32(0.6597)] 
2025-01-11 18:52:24.678127: Epoch time: 38.7 s 
2025-01-11 18:52:25.233462:  
2025-01-11 18:52:25.233964: Epoch 160 
2025-01-11 18:52:25.238977: Current learning rate: 0.00399 
2025-01-11 18:53:10.147569: train_loss -0.6625 
2025-01-11 18:53:10.148573: val_loss -0.636 
2025-01-11 18:53:10.154587: Pseudo dice [np.float32(0.9605), np.float32(0.8392)] 
2025-01-11 18:53:10.159599: Epoch time: 44.91 s 
2025-01-11 18:53:10.823484:  
2025-01-11 18:53:10.823484: Epoch 161 
2025-01-11 18:53:10.829543: Current learning rate: 0.00395 
2025-01-11 18:53:51.893219: train_loss -0.6649 
2025-01-11 18:53:51.893219: val_loss -0.6604 
2025-01-11 18:53:51.900741: Pseudo dice [np.float32(0.9518), np.float32(0.7561)] 
2025-01-11 18:53:51.904750: Epoch time: 41.07 s 
2025-01-11 18:53:52.603147:  
2025-01-11 18:53:52.603147: Epoch 162 
2025-01-11 18:53:52.608683: Current learning rate: 0.00391 
2025-01-11 18:54:33.012109: train_loss -0.6531 
2025-01-11 18:54:33.013109: val_loss -0.632 
2025-01-11 18:54:33.019629: Pseudo dice [np.float32(0.9418), np.float32(0.7617)] 
2025-01-11 18:54:33.024643: Epoch time: 40.41 s 
2025-01-11 18:54:33.889280:  
2025-01-11 18:54:33.889280: Epoch 163 
2025-01-11 18:54:33.894868: Current learning rate: 0.00387 
2025-01-11 18:55:14.231579: train_loss -0.6167 
2025-01-11 18:55:14.232600: val_loss -0.6206 
2025-01-11 18:55:14.239215: Pseudo dice [np.float32(0.9463), np.float32(0.7513)] 
2025-01-11 18:55:14.243928: Epoch time: 40.34 s 
2025-01-11 18:55:14.978108:  
2025-01-11 18:55:14.978611: Epoch 164 
2025-01-11 18:55:14.983622: Current learning rate: 0.00383 
2025-01-11 18:55:55.467556: train_loss -0.6192 
2025-01-11 18:55:55.468560: val_loss -0.6291 
2025-01-11 18:55:55.474573: Pseudo dice [np.float32(0.955), np.float32(0.7399)] 
2025-01-11 18:55:55.479587: Epoch time: 40.49 s 
2025-01-11 18:55:56.188035:  
2025-01-11 18:55:56.188035: Epoch 165 
2025-01-11 18:55:56.193582: Current learning rate: 0.00379 
2025-01-11 18:56:36.593928: train_loss -0.6236 
2025-01-11 18:56:36.594929: val_loss -0.5979 
2025-01-11 18:56:36.602956: Pseudo dice [np.float32(0.9503), np.float32(0.735)] 
2025-01-11 18:56:36.607466: Epoch time: 40.41 s 
2025-01-11 18:56:37.299346:  
2025-01-11 18:56:37.299346: Epoch 166 
2025-01-11 18:56:37.304899: Current learning rate: 0.00375 
2025-01-11 18:57:17.854280: train_loss -0.6333 
2025-01-11 18:57:17.855280: val_loss -0.6455 
2025-01-11 18:57:17.861797: Pseudo dice [np.float32(0.9536), np.float32(0.7581)] 
2025-01-11 18:57:17.865807: Epoch time: 40.55 s 
2025-01-11 18:57:18.577293:  
2025-01-11 18:57:18.577293: Epoch 167 
2025-01-11 18:57:18.582942: Current learning rate: 0.00371 
2025-01-11 18:57:59.154177: train_loss -0.647 
2025-01-11 18:57:59.155176: val_loss -0.6704 
2025-01-11 18:57:59.161736: Pseudo dice [np.float32(0.9612), np.float32(0.7662)] 
2025-01-11 18:57:59.165750: Epoch time: 40.58 s 
2025-01-11 18:57:59.842072:  
2025-01-11 18:57:59.842072: Epoch 168 
2025-01-11 18:57:59.847084: Current learning rate: 0.00367 
2025-01-11 18:58:40.281009: train_loss -0.6164 
2025-01-11 18:58:40.281512: val_loss -0.6233 
2025-01-11 18:58:40.287558: Pseudo dice [np.float32(0.9496), np.float32(0.7793)] 
2025-01-11 18:58:40.291570: Epoch time: 40.44 s 
2025-01-11 18:58:40.295079: Yayy! New best EMA pseudo Dice: 0.847599983215332 
2025-01-11 18:58:41.115791:  
2025-01-11 18:58:41.115791: Epoch 169 
2025-01-11 18:58:41.121809: Current learning rate: 0.00363 
2025-01-11 18:59:21.637471: train_loss -0.6576 
2025-01-11 18:59:21.637983: val_loss -0.5472 
2025-01-11 18:59:21.645057: Pseudo dice [np.float32(0.9368), np.float32(0.5331)] 
2025-01-11 18:59:21.649070: Epoch time: 40.52 s 
2025-01-11 18:59:22.503117:  
2025-01-11 18:59:22.503117: Epoch 170 
2025-01-11 18:59:22.509249: Current learning rate: 0.00359 
2025-01-11 19:00:02.864481: train_loss -0.6264 
2025-01-11 19:00:02.865485: val_loss -0.6468 
2025-01-11 19:00:02.871656: Pseudo dice [np.float32(0.9588), np.float32(0.8048)] 
2025-01-11 19:00:02.877003: Epoch time: 40.36 s 
2025-01-11 19:00:03.593513:  
2025-01-11 19:00:03.593513: Epoch 171 
2025-01-11 19:00:03.598527: Current learning rate: 0.00355 
2025-01-11 19:00:44.007683: train_loss -0.6577 
2025-01-11 19:00:44.007683: val_loss -0.6668 
2025-01-11 19:00:44.015227: Pseudo dice [np.float32(0.9529), np.float32(0.8134)] 
2025-01-11 19:00:44.019238: Epoch time: 40.41 s 
2025-01-11 19:00:44.721214:  
2025-01-11 19:00:44.722213: Epoch 172 
2025-01-11 19:00:44.727281: Current learning rate: 0.00351 
2025-01-11 19:01:25.214094: train_loss -0.6253 
2025-01-11 19:01:25.214608: val_loss -0.6334 
2025-01-11 19:01:25.221706: Pseudo dice [np.float32(0.9437), np.float32(0.7723)] 
2025-01-11 19:01:25.224777: Epoch time: 40.49 s 
2025-01-11 19:01:25.945512:  
2025-01-11 19:01:25.946435: Epoch 173 
2025-01-11 19:01:25.951520: Current learning rate: 0.00346 
2025-01-11 19:02:06.319481: train_loss -0.6355 
2025-01-11 19:02:06.319985: val_loss -0.6403 
2025-01-11 19:02:06.326002: Pseudo dice [np.float32(0.9473), np.float32(0.8509)] 
2025-01-11 19:02:06.331017: Epoch time: 40.37 s 
2025-01-11 19:02:06.337032: Yayy! New best EMA pseudo Dice: 0.8517000079154968 
2025-01-11 19:02:07.140162:  
2025-01-11 19:02:07.141166: Epoch 174 
2025-01-11 19:02:07.145701: Current learning rate: 0.00342 
2025-01-11 19:02:47.807261: train_loss -0.6449 
2025-01-11 19:02:47.808763: val_loss -0.6323 
2025-01-11 19:02:47.815786: Pseudo dice [np.float32(0.9402), np.float32(0.8425)] 
2025-01-11 19:02:47.823314: Epoch time: 40.67 s 
2025-01-11 19:02:47.829840: Yayy! New best EMA pseudo Dice: 0.8557000160217285 
2025-01-11 19:02:48.652242:  
2025-01-11 19:02:48.652242: Epoch 175 
2025-01-11 19:02:48.657256: Current learning rate: 0.00338 
2025-01-11 19:03:29.262577: train_loss -0.6414 
2025-01-11 19:03:29.263580: val_loss -0.6483 
2025-01-11 19:03:29.269690: Pseudo dice [np.float32(0.9496), np.float32(0.7798)] 
2025-01-11 19:03:29.273837: Epoch time: 40.61 s 
2025-01-11 19:03:29.277400: Yayy! New best EMA pseudo Dice: 0.8565999865531921 
2025-01-11 19:03:30.024786:  
2025-01-11 19:03:30.024786: Epoch 176 
2025-01-11 19:03:30.029407: Current learning rate: 0.00334 
2025-01-11 19:04:09.647152: train_loss -0.6463 
2025-01-11 19:04:09.647691: val_loss -0.6528 
2025-01-11 19:04:09.654027: Pseudo dice [np.float32(0.9504), np.float32(0.8198)] 
2025-01-11 19:04:09.660222: Epoch time: 39.62 s 
2025-01-11 19:04:09.665306: Yayy! New best EMA pseudo Dice: 0.8593999743461609 
2025-01-11 19:04:10.449759:  
2025-01-11 19:04:10.449759: Epoch 177 
2025-01-11 19:04:10.455774: Current learning rate: 0.0033 
2025-01-11 19:04:49.616245: train_loss -0.6468 
2025-01-11 19:04:49.616749: val_loss -0.6548 
2025-01-11 19:04:49.623886: Pseudo dice [np.float32(0.9627), np.float32(0.7881)] 
2025-01-11 19:04:49.629547: Epoch time: 39.17 s 
2025-01-11 19:04:49.633110: Yayy! New best EMA pseudo Dice: 0.8610000014305115 
2025-01-11 19:04:50.644036:  
2025-01-11 19:04:50.645040: Epoch 178 
2025-01-11 19:04:50.649574: Current learning rate: 0.00326 
2025-01-11 19:05:29.692369: train_loss -0.6641 
2025-01-11 19:05:29.692369: val_loss -0.664 
2025-01-11 19:05:29.699890: Pseudo dice [np.float32(0.9572), np.float32(0.7195)] 
2025-01-11 19:05:29.703399: Epoch time: 39.05 s 
2025-01-11 19:05:30.406594:  
2025-01-11 19:05:30.406594: Epoch 179 
2025-01-11 19:05:30.412140: Current learning rate: 0.00322 
2025-01-11 19:06:09.506132: train_loss -0.6397 
2025-01-11 19:06:09.506132: val_loss -0.6101 
2025-01-11 19:06:09.512692: Pseudo dice [np.float32(0.952), np.float32(0.7346)] 
2025-01-11 19:06:09.517770: Epoch time: 39.1 s 
2025-01-11 19:06:10.183691:  
2025-01-11 19:06:10.184690: Epoch 180 
2025-01-11 19:06:10.189807: Current learning rate: 0.00318 
2025-01-11 19:06:49.254383: train_loss -0.6542 
2025-01-11 19:06:49.254383: val_loss -0.6143 
2025-01-11 19:06:49.260403: Pseudo dice [np.float32(0.9488), np.float32(0.6594)] 
2025-01-11 19:06:49.266417: Epoch time: 39.07 s 
2025-01-11 19:06:49.921403:  
2025-01-11 19:06:49.921917: Epoch 181 
2025-01-11 19:06:49.926996: Current learning rate: 0.00314 
2025-01-11 19:07:29.025898: train_loss -0.6661 
2025-01-11 19:07:29.025898: val_loss -0.6399 
2025-01-11 19:07:29.032415: Pseudo dice [np.float32(0.95), np.float32(0.5698)] 
2025-01-11 19:07:29.038434: Epoch time: 39.11 s 
2025-01-11 19:07:29.736856:  
2025-01-11 19:07:29.736856: Epoch 182 
2025-01-11 19:07:29.741899: Current learning rate: 0.0031 
2025-01-11 19:08:08.825250: train_loss -0.6497 
2025-01-11 19:08:08.826253: val_loss -0.6749 
2025-01-11 19:08:08.833404: Pseudo dice [np.float32(0.9585), np.float32(0.7696)] 
2025-01-11 19:08:08.838413: Epoch time: 39.09 s 
2025-01-11 19:08:09.551460:  
2025-01-11 19:08:09.552463: Epoch 183 
2025-01-11 19:08:09.557023: Current learning rate: 0.00306 
2025-01-11 19:08:48.569330: train_loss -0.6536 
2025-01-11 19:08:48.569330: val_loss -0.6644 
2025-01-11 19:08:48.577850: Pseudo dice [np.float32(0.9373), np.float32(0.7814)] 
2025-01-11 19:08:48.581856: Epoch time: 39.02 s 
2025-01-11 19:08:49.295238:  
2025-01-11 19:08:49.295238: Epoch 184 
2025-01-11 19:08:49.301256: Current learning rate: 0.00302 
2025-01-11 19:09:28.360000: train_loss -0.6632 
2025-01-11 19:09:28.360000: val_loss -0.6671 
2025-01-11 19:09:28.366016: Pseudo dice [np.float32(0.9416), np.float32(0.8675)] 
2025-01-11 19:09:28.369521: Epoch time: 39.07 s 
2025-01-11 19:09:29.076283:  
2025-01-11 19:09:29.077286: Epoch 185 
2025-01-11 19:09:29.082366: Current learning rate: 0.00297 
2025-01-11 19:10:08.321680: train_loss -0.6816 
2025-01-11 19:10:08.322679: val_loss -0.5854 
2025-01-11 19:10:08.329197: Pseudo dice [np.float32(0.9451), np.float32(0.6618)] 
2025-01-11 19:10:08.334208: Epoch time: 39.25 s 
2025-01-11 19:10:09.179428:  
2025-01-11 19:10:09.179428: Epoch 186 
2025-01-11 19:10:09.185445: Current learning rate: 0.00293 
2025-01-11 19:10:48.246595: train_loss -0.6686 
2025-01-11 19:10:48.246595: val_loss -0.6588 
2025-01-11 19:10:48.254118: Pseudo dice [np.float32(0.9474), np.float32(0.7124)] 
2025-01-11 19:10:48.259130: Epoch time: 39.07 s 
2025-01-11 19:10:48.919470:  
2025-01-11 19:10:48.920473: Epoch 187 
2025-01-11 19:10:48.925486: Current learning rate: 0.00289 
2025-01-11 19:11:27.955716: train_loss -0.6686 
2025-01-11 19:11:27.956717: val_loss -0.6968 
2025-01-11 19:11:27.963241: Pseudo dice [np.float32(0.9559), np.float32(0.7771)] 
2025-01-11 19:11:27.967249: Epoch time: 39.04 s 
2025-01-11 19:11:28.647431:  
2025-01-11 19:11:28.647431: Epoch 188 
2025-01-11 19:11:28.652497: Current learning rate: 0.00285 
2025-01-11 19:12:07.722668: train_loss -0.6527 
2025-01-11 19:12:07.722668: val_loss -0.6598 
2025-01-11 19:12:07.727835: Pseudo dice [np.float32(0.9393), np.float32(0.8698)] 
2025-01-11 19:12:07.731879: Epoch time: 39.08 s 
2025-01-11 19:12:08.437519:  
2025-01-11 19:12:08.438519: Epoch 189 
2025-01-11 19:12:08.444089: Current learning rate: 0.00281 
2025-01-11 19:12:47.618739: train_loss -0.6658 
2025-01-11 19:12:47.619241: val_loss -0.6353 
2025-01-11 19:12:47.627770: Pseudo dice [np.float32(0.9612), np.float32(0.7656)] 
2025-01-11 19:12:47.631782: Epoch time: 39.18 s 
2025-01-11 19:12:48.322332:  
2025-01-11 19:12:48.322332: Epoch 190 
2025-01-11 19:12:48.327894: Current learning rate: 0.00277 
2025-01-11 19:13:27.459135: train_loss -0.6374 
2025-01-11 19:13:27.460138: val_loss -0.6438 
2025-01-11 19:13:27.466658: Pseudo dice [np.float32(0.9563), np.float32(0.7388)] 
2025-01-11 19:13:27.471249: Epoch time: 39.14 s 
2025-01-11 19:13:28.189977:  
2025-01-11 19:13:28.189977: Epoch 191 
2025-01-11 19:13:28.195542: Current learning rate: 0.00273 
2025-01-11 19:14:07.430981: train_loss -0.6282 
2025-01-11 19:14:07.430981: val_loss -0.6811 
2025-01-11 19:14:07.437503: Pseudo dice [np.float32(0.9577), np.float32(0.8488)] 
2025-01-11 19:14:07.441014: Epoch time: 39.24 s 
2025-01-11 19:14:08.108483:  
2025-01-11 19:14:08.108483: Epoch 192 
2025-01-11 19:14:08.115007: Current learning rate: 0.00268 
2025-01-11 19:14:47.242953: train_loss -0.6189 
2025-01-11 19:14:47.243958: val_loss -0.6901 
2025-01-11 19:14:47.251477: Pseudo dice [np.float32(0.9537), np.float32(0.7958)] 
2025-01-11 19:14:47.255487: Epoch time: 39.13 s 
2025-01-11 19:14:47.960991:  
2025-01-11 19:14:47.961991: Epoch 193 
2025-01-11 19:14:47.967509: Current learning rate: 0.00264 
2025-01-11 19:15:27.103270: train_loss -0.6593 
2025-01-11 19:15:27.103270: val_loss -0.6324 
2025-01-11 19:15:27.111899: Pseudo dice [np.float32(0.9536), np.float32(0.7896)] 
2025-01-11 19:15:27.115909: Epoch time: 39.14 s 
2025-01-11 19:15:27.119416: Yayy! New best EMA pseudo Dice: 0.8614000082015991 
2025-01-11 19:15:28.121996:  
2025-01-11 19:15:28.121996: Epoch 194 
2025-01-11 19:15:28.128054: Current learning rate: 0.0026 
2025-01-11 19:16:07.267671: train_loss -0.66 
2025-01-11 19:16:07.268700: val_loss -0.6867 
2025-01-11 19:16:07.275290: Pseudo dice [np.float32(0.9523), np.float32(0.7661)] 
2025-01-11 19:16:07.280882: Epoch time: 39.15 s 
2025-01-11 19:16:07.981717:  
2025-01-11 19:16:07.981717: Epoch 195 
2025-01-11 19:16:07.987732: Current learning rate: 0.00256 
2025-01-11 19:16:51.535527: train_loss -0.6263 
2025-01-11 19:16:51.535527: val_loss -0.6717 
2025-01-11 19:16:51.543257: Pseudo dice [np.float32(0.9475), np.float32(0.7831)] 
2025-01-11 19:16:51.547806: Epoch time: 43.55 s 
2025-01-11 19:16:51.552362: Yayy! New best EMA pseudo Dice: 0.8615999817848206 
2025-01-11 19:16:52.350933:  
2025-01-11 19:16:52.350933: Epoch 196 
2025-01-11 19:16:52.356449: Current learning rate: 0.00252 
2025-01-11 19:17:32.381613: train_loss -0.6605 
2025-01-11 19:17:32.383643: val_loss -0.6808 
2025-01-11 19:17:32.389390: Pseudo dice [np.float32(0.9523), np.float32(0.8072)] 
2025-01-11 19:17:32.394454: Epoch time: 40.03 s 
2025-01-11 19:17:32.398999: Yayy! New best EMA pseudo Dice: 0.8633999824523926 
2025-01-11 19:17:33.179377:  
2025-01-11 19:17:33.179377: Epoch 197 
2025-01-11 19:17:33.184400: Current learning rate: 0.00248 
2025-01-11 19:18:13.677196: train_loss -0.6816 
2025-01-11 19:18:13.678196: val_loss -0.6515 
2025-01-11 19:18:13.685744: Pseudo dice [np.float32(0.9521), np.float32(0.7595)] 
2025-01-11 19:18:13.689753: Epoch time: 40.5 s 
2025-01-11 19:18:14.368703:  
2025-01-11 19:18:14.369205: Epoch 198 
2025-01-11 19:18:14.374250: Current learning rate: 0.00243 
2025-01-11 19:18:54.400176: train_loss -0.6624 
2025-01-11 19:18:54.401176: val_loss -0.661 
2025-01-11 19:18:54.407698: Pseudo dice [np.float32(0.9532), np.float32(0.8354)] 
2025-01-11 19:18:54.411707: Epoch time: 40.03 s 
2025-01-11 19:18:54.415218: Yayy! New best EMA pseudo Dice: 0.8658000230789185 
2025-01-11 19:18:55.182969:  
2025-01-11 19:18:55.182969: Epoch 199 
2025-01-11 19:18:55.187979: Current learning rate: 0.00239 
2025-01-11 19:19:35.247387: train_loss -0.6784 
2025-01-11 19:19:35.248390: val_loss -0.6714 
2025-01-11 19:19:35.254914: Pseudo dice [np.float32(0.9591), np.float32(0.764)] 
2025-01-11 19:19:35.259938: Epoch time: 40.06 s 
2025-01-11 19:19:36.026822:  
2025-01-11 19:19:36.027326: Epoch 200 
2025-01-11 19:19:36.032336: Current learning rate: 0.00235 
2025-01-11 19:20:16.080561: train_loss -0.6561 
2025-01-11 19:20:16.080561: val_loss -0.6276 
2025-01-11 19:20:16.086575: Pseudo dice [np.float32(0.9554), np.float32(0.7473)] 
2025-01-11 19:20:16.091586: Epoch time: 40.05 s 
2025-01-11 19:20:16.807889:  
2025-01-11 19:20:16.808391: Epoch 201 
2025-01-11 19:20:16.813471: Current learning rate: 0.00231 
2025-01-11 19:20:57.210697: train_loss -0.6537 
2025-01-11 19:20:57.211700: val_loss -0.6485 
2025-01-11 19:20:57.218215: Pseudo dice [np.float32(0.9568), np.float32(0.7093)] 
2025-01-11 19:20:57.221761: Epoch time: 40.4 s 
2025-01-11 19:20:58.060391:  
2025-01-11 19:20:58.060902: Epoch 202 
2025-01-11 19:20:58.065961: Current learning rate: 0.00226 
2025-01-11 19:21:38.268613: train_loss -0.6633 
2025-01-11 19:21:38.268613: val_loss -0.6718 
2025-01-11 19:21:38.275130: Pseudo dice [np.float32(0.9575), np.float32(0.8128)] 
2025-01-11 19:21:38.281145: Epoch time: 40.21 s 
2025-01-11 19:21:38.975996:  
2025-01-11 19:21:38.976998: Epoch 203 
2025-01-11 19:21:38.981556: Current learning rate: 0.00222 
2025-01-11 19:22:19.302239: train_loss -0.6553 
2025-01-11 19:22:19.303778: val_loss -0.6459 
2025-01-11 19:22:19.309919: Pseudo dice [np.float32(0.9517), np.float32(0.6256)] 
2025-01-11 19:22:19.312604: Epoch time: 40.33 s 
2025-01-11 19:22:19.992376:  
2025-01-11 19:22:19.992376: Epoch 204 
2025-01-11 19:22:19.997392: Current learning rate: 0.00218 
2025-01-11 19:23:00.394304: train_loss -0.6784 
2025-01-11 19:23:00.394304: val_loss -0.6696 
2025-01-11 19:23:00.400928: Pseudo dice [np.float32(0.9513), np.float32(0.7588)] 
2025-01-11 19:23:00.404542: Epoch time: 40.4 s 
2025-01-11 19:23:01.109455:  
2025-01-11 19:23:01.109455: Epoch 205 
2025-01-11 19:23:01.114476: Current learning rate: 0.00214 
2025-01-11 19:23:41.379615: train_loss -0.6708 
2025-01-11 19:23:41.380118: val_loss -0.6462 
2025-01-11 19:23:41.387638: Pseudo dice [np.float32(0.9532), np.float32(0.7073)] 
2025-01-11 19:23:41.392658: Epoch time: 40.27 s 
2025-01-11 19:23:42.022225:  
2025-01-11 19:23:42.023226: Epoch 206 
2025-01-11 19:23:42.028809: Current learning rate: 0.00209 
2025-01-11 19:24:22.331730: train_loss -0.6614 
2025-01-11 19:24:22.333344: val_loss -0.6629 
2025-01-11 19:24:22.338550: Pseudo dice [np.float32(0.9545), np.float32(0.8011)] 
2025-01-11 19:24:22.343671: Epoch time: 40.31 s 
2025-01-11 19:24:23.015428:  
2025-01-11 19:24:23.016067: Epoch 207 
2025-01-11 19:24:23.022088: Current learning rate: 0.00205 
2025-01-11 19:25:03.290707: train_loss -0.6789 
2025-01-11 19:25:03.291312: val_loss -0.6598 
2025-01-11 19:25:03.297905: Pseudo dice [np.float32(0.9562), np.float32(0.7977)] 
2025-01-11 19:25:03.302589: Epoch time: 40.28 s 
2025-01-11 19:25:03.970355:  
2025-01-11 19:25:03.970355: Epoch 208 
2025-01-11 19:25:03.975937: Current learning rate: 0.00201 
2025-01-11 19:25:44.512910: train_loss -0.6839 
2025-01-11 19:25:44.512910: val_loss -0.6559 
2025-01-11 19:25:44.520522: Pseudo dice [np.float32(0.9483), np.float32(0.7521)] 
2025-01-11 19:25:44.525648: Epoch time: 40.54 s 
2025-01-11 19:25:45.173968:  
2025-01-11 19:25:45.174968: Epoch 209 
2025-01-11 19:25:45.180029: Current learning rate: 0.00196 
2025-01-11 19:26:25.423985: train_loss -0.6723 
2025-01-11 19:26:25.423985: val_loss -0.6966 
2025-01-11 19:26:25.430629: Pseudo dice [np.float32(0.9575), np.float32(0.8559)] 
2025-01-11 19:26:25.434139: Epoch time: 40.25 s 
2025-01-11 19:26:26.263080:  
2025-01-11 19:26:26.263080: Epoch 210 
2025-01-11 19:26:26.268104: Current learning rate: 0.00192 
2025-01-11 19:27:06.541603: train_loss -0.662 
2025-01-11 19:27:06.542605: val_loss -0.7311 
2025-01-11 19:27:06.549128: Pseudo dice [np.float32(0.9632), np.float32(0.7601)] 
2025-01-11 19:27:06.554149: Epoch time: 40.28 s 
2025-01-11 19:27:07.177335:  
2025-01-11 19:27:07.178337: Epoch 211 
2025-01-11 19:27:07.183938: Current learning rate: 0.00188 
2025-01-11 19:27:47.523641: train_loss -0.6733 
2025-01-11 19:27:47.523641: val_loss -0.6897 
2025-01-11 19:27:47.531164: Pseudo dice [np.float32(0.9501), np.float32(0.8134)] 
2025-01-11 19:27:47.538689: Epoch time: 40.35 s 
2025-01-11 19:27:48.212696:  
2025-01-11 19:27:48.213198: Epoch 212 
2025-01-11 19:27:48.218209: Current learning rate: 0.00184 
2025-01-11 19:28:28.542000: train_loss -0.6905 
2025-01-11 19:28:28.543503: val_loss -0.6688 
2025-01-11 19:28:28.549517: Pseudo dice [np.float32(0.9593), np.float32(0.7966)] 
2025-01-11 19:28:28.555535: Epoch time: 40.33 s 
2025-01-11 19:28:29.195736:  
2025-01-11 19:28:29.195736: Epoch 213 
2025-01-11 19:28:29.201320: Current learning rate: 0.00179 
2025-01-11 19:29:09.495569: train_loss -0.6669 
2025-01-11 19:29:09.497185: val_loss -0.6483 
2025-01-11 19:29:09.502796: Pseudo dice [np.float32(0.9539), np.float32(0.8315)] 
2025-01-11 19:29:09.507863: Epoch time: 40.3 s 
2025-01-11 19:29:09.512948: Yayy! New best EMA pseudo Dice: 0.8680999875068665 
2025-01-11 19:29:10.238922:  
2025-01-11 19:29:10.238922: Epoch 214 
2025-01-11 19:29:10.244474: Current learning rate: 0.00175 
2025-01-11 19:29:50.566007: train_loss -0.6739 
2025-01-11 19:29:50.566519: val_loss -0.6522 
2025-01-11 19:29:50.572586: Pseudo dice [np.float32(0.959), np.float32(0.7907)] 
2025-01-11 19:29:50.575052: Epoch time: 40.33 s 
2025-01-11 19:29:50.580124: Yayy! New best EMA pseudo Dice: 0.8687999844551086 
2025-01-11 19:29:51.330693:  
2025-01-11 19:29:51.331694: Epoch 215 
2025-01-11 19:29:51.337277: Current learning rate: 0.0017 
2025-01-11 19:30:31.422266: train_loss -0.6487 
2025-01-11 19:30:31.424341: val_loss -0.7022 
2025-01-11 19:30:31.430912: Pseudo dice [np.float32(0.9586), np.float32(0.8461)] 
2025-01-11 19:30:31.437053: Epoch time: 40.09 s 
2025-01-11 19:30:31.442917: Yayy! New best EMA pseudo Dice: 0.8720999956130981 
2025-01-11 19:30:32.193640:  
2025-01-11 19:30:32.193640: Epoch 216 
2025-01-11 19:30:32.199185: Current learning rate: 0.00166 
2025-01-11 19:31:11.131122: train_loss -0.6588 
2025-01-11 19:31:11.132125: val_loss -0.6378 
2025-01-11 19:31:11.138353: Pseudo dice [np.float32(0.9565), np.float32(0.7303)] 
2025-01-11 19:31:11.145968: Epoch time: 38.94 s 
2025-01-11 19:31:11.802652:  
2025-01-11 19:31:11.802652: Epoch 217 
2025-01-11 19:31:11.808681: Current learning rate: 0.00162 
2025-01-11 19:31:50.661776: train_loss -0.6755 
2025-01-11 19:31:50.663282: val_loss -0.6924 
2025-01-11 19:31:50.671365: Pseudo dice [np.float32(0.9588), np.float32(0.8056)] 
2025-01-11 19:31:50.676383: Epoch time: 38.86 s 
2025-01-11 19:31:51.483157:  
2025-01-11 19:31:51.483157: Epoch 218 
2025-01-11 19:31:51.487777: Current learning rate: 0.00157 
2025-01-11 19:32:30.366745: train_loss -0.6591 
2025-01-11 19:32:30.367748: val_loss -0.6755 
2025-01-11 19:32:30.374262: Pseudo dice [np.float32(0.9494), np.float32(0.7983)] 
2025-01-11 19:32:30.378769: Epoch time: 38.88 s 
2025-01-11 19:32:31.001443:  
2025-01-11 19:32:31.001443: Epoch 219 
2025-01-11 19:32:31.006477: Current learning rate: 0.00153 
2025-01-11 19:33:09.870961: train_loss -0.7165 
2025-01-11 19:33:09.870961: val_loss -0.6931 
2025-01-11 19:33:09.878649: Pseudo dice [np.float32(0.9597), np.float32(0.7016)] 
2025-01-11 19:33:09.883740: Epoch time: 38.87 s 
2025-01-11 19:33:10.521828:  
2025-01-11 19:33:10.521828: Epoch 220 
2025-01-11 19:33:10.526841: Current learning rate: 0.00148 
2025-01-11 19:33:49.374738: train_loss -0.6567 
2025-01-11 19:33:49.375255: val_loss -0.732 
2025-01-11 19:33:49.381863: Pseudo dice [np.float32(0.9564), np.float32(0.8369)] 
2025-01-11 19:33:49.386032: Epoch time: 38.85 s 
2025-01-11 19:33:50.042635:  
2025-01-11 19:33:50.042635: Epoch 221 
2025-01-11 19:33:50.048193: Current learning rate: 0.00144 
2025-01-11 19:34:28.937771: train_loss -0.6873 
2025-01-11 19:34:28.938273: val_loss -0.6074 
2025-01-11 19:34:28.944284: Pseudo dice [np.float32(0.946), np.float32(0.7602)] 
2025-01-11 19:34:28.949293: Epoch time: 38.9 s 
2025-01-11 19:34:29.569410:  
2025-01-11 19:34:29.569410: Epoch 222 
2025-01-11 19:34:29.574424: Current learning rate: 0.00139 
2025-01-11 19:35:08.412151: train_loss -0.6788 
2025-01-11 19:35:08.412151: val_loss -0.6935 
2025-01-11 19:35:08.418718: Pseudo dice [np.float32(0.9609), np.float32(0.8475)] 
2025-01-11 19:35:08.421804: Epoch time: 38.84 s 
2025-01-11 19:35:09.061667:  
2025-01-11 19:35:09.062169: Epoch 223 
2025-01-11 19:35:09.067182: Current learning rate: 0.00135 
2025-01-11 19:35:47.943896: train_loss -0.6645 
2025-01-11 19:35:47.944403: val_loss -0.6678 
2025-01-11 19:35:47.951499: Pseudo dice [np.float32(0.9589), np.float32(0.8471)] 
2025-01-11 19:35:47.955529: Epoch time: 38.88 s 
2025-01-11 19:35:47.961575: Yayy! New best EMA pseudo Dice: 0.8748999834060669 
2025-01-11 19:35:48.725872:  
2025-01-11 19:35:48.725872: Epoch 224 
2025-01-11 19:35:48.731404: Current learning rate: 0.0013 
2025-01-11 19:36:27.673329: train_loss -0.6774 
2025-01-11 19:36:27.673329: val_loss -0.6974 
2025-01-11 19:36:27.679345: Pseudo dice [np.float32(0.9633), np.float32(0.8008)] 
2025-01-11 19:36:27.683992: Epoch time: 38.95 s 
2025-01-11 19:36:27.689085: Yayy! New best EMA pseudo Dice: 0.8755999803543091 
2025-01-11 19:36:28.423697:  
2025-01-11 19:36:28.424704: Epoch 225 
2025-01-11 19:36:28.429239: Current learning rate: 0.00126 
2025-01-11 19:37:07.292809: train_loss -0.6951 
2025-01-11 19:37:07.292809: val_loss -0.7146 
2025-01-11 19:37:07.299326: Pseudo dice [np.float32(0.9559), np.float32(0.8394)] 
2025-01-11 19:37:07.302838: Epoch time: 38.87 s 
2025-01-11 19:37:07.306347: Yayy! New best EMA pseudo Dice: 0.8777999877929688 
2025-01-11 19:37:08.068159:  
2025-01-11 19:37:08.068159: Epoch 226 
2025-01-11 19:37:08.073741: Current learning rate: 0.00121 
2025-01-11 19:37:52.213431: train_loss -0.6765 
2025-01-11 19:37:52.214435: val_loss -0.7165 
2025-01-11 19:37:52.220952: Pseudo dice [np.float32(0.9607), np.float32(0.7749)] 
2025-01-11 19:37:52.225967: Epoch time: 44.15 s 
2025-01-11 19:37:53.047880:  
2025-01-11 19:37:53.048884: Epoch 227 
2025-01-11 19:37:53.054036: Current learning rate: 0.00117 
2025-01-11 19:38:34.228218: train_loss -0.6865 
2025-01-11 19:38:34.229221: val_loss -0.6557 
2025-01-11 19:38:34.235740: Pseudo dice [np.float32(0.9503), np.float32(0.8004)] 
2025-01-11 19:38:34.239253: Epoch time: 41.18 s 
2025-01-11 19:38:34.966776:  
2025-01-11 19:38:34.966776: Epoch 228 
2025-01-11 19:38:34.972310: Current learning rate: 0.00112 
2025-01-11 19:39:14.680894: train_loss -0.6831 
2025-01-11 19:39:14.680894: val_loss -0.6755 
2025-01-11 19:39:14.686924: Pseudo dice [np.float32(0.9564), np.float32(0.8665)] 
2025-01-11 19:39:14.690433: Epoch time: 39.71 s 
2025-01-11 19:39:14.692940: Yayy! New best EMA pseudo Dice: 0.8801000118255615 
2025-01-11 19:39:15.468127:  
2025-01-11 19:39:15.468127: Epoch 229 
2025-01-11 19:39:15.474164: Current learning rate: 0.00108 
2025-01-11 19:39:55.121319: train_loss -0.664 
2025-01-11 19:39:55.121826: val_loss -0.6978 
2025-01-11 19:39:55.127402: Pseudo dice [np.float32(0.9614), np.float32(0.8671)] 
2025-01-11 19:39:55.131940: Epoch time: 39.65 s 
2025-01-11 19:39:55.135036: Yayy! New best EMA pseudo Dice: 0.8835999965667725 
2025-01-11 19:39:55.933381:  
2025-01-11 19:39:55.933381: Epoch 230 
2025-01-11 19:39:55.938911: Current learning rate: 0.00103 
2025-01-11 19:40:35.648708: train_loss -0.6939 
2025-01-11 19:40:35.649708: val_loss -0.6578 
2025-01-11 19:40:35.657727: Pseudo dice [np.float32(0.9623), np.float32(0.8193)] 
2025-01-11 19:40:35.662741: Epoch time: 39.72 s 
2025-01-11 19:40:35.667251: Yayy! New best EMA pseudo Dice: 0.8842999935150146 
2025-01-11 19:40:36.514463:  
2025-01-11 19:40:36.514463: Epoch 231 
2025-01-11 19:40:36.520031: Current learning rate: 0.00098 
2025-01-11 19:41:16.614660: train_loss -0.7022 
2025-01-11 19:41:16.615162: val_loss -0.663 
2025-01-11 19:41:16.623338: Pseudo dice [np.float32(0.9597), np.float32(0.7816)] 
2025-01-11 19:41:16.628350: Epoch time: 40.1 s 
2025-01-11 19:41:17.312296:  
2025-01-11 19:41:17.312296: Epoch 232 
2025-01-11 19:41:17.318329: Current learning rate: 0.00094 
2025-01-11 19:41:57.367626: train_loss -0.6989 
2025-01-11 19:41:57.368629: val_loss -0.7262 
2025-01-11 19:41:57.374640: Pseudo dice [np.float32(0.9638), np.float32(0.8285)] 
2025-01-11 19:41:57.377647: Epoch time: 40.06 s 
2025-01-11 19:41:58.071499:  
2025-01-11 19:41:58.072001: Epoch 233 
2025-01-11 19:41:58.077041: Current learning rate: 0.00089 
2025-01-11 19:42:38.112647: train_loss -0.6967 
2025-01-11 19:42:38.113652: val_loss -0.6488 
2025-01-11 19:42:38.120184: Pseudo dice [np.float32(0.963), np.float32(0.709)] 
2025-01-11 19:42:38.122719: Epoch time: 40.04 s 
2025-01-11 19:42:38.833536:  
2025-01-11 19:42:38.833536: Epoch 234 
2025-01-11 19:42:38.839555: Current learning rate: 0.00084 
2025-01-11 19:43:19.091218: train_loss -0.7087 
2025-01-11 19:43:19.091730: val_loss -0.7184 
2025-01-11 19:43:19.098309: Pseudo dice [np.float32(0.9688), np.float32(0.7202)] 
2025-01-11 19:43:19.101843: Epoch time: 40.26 s 
2025-01-11 19:43:19.809803:  
2025-01-11 19:43:19.810305: Epoch 235 
2025-01-11 19:43:19.815338: Current learning rate: 0.00079 
2025-01-11 19:43:59.162384: train_loss -0.7126 
2025-01-11 19:43:59.163424: val_loss -0.6482 
2025-01-11 19:43:59.169068: Pseudo dice [np.float32(0.9671), np.float32(0.8084)] 
2025-01-11 19:43:59.173082: Epoch time: 39.35 s 
2025-01-11 19:44:00.035043:  
2025-01-11 19:44:00.035043: Epoch 236 
2025-01-11 19:44:00.041110: Current learning rate: 0.00075 
2025-01-11 19:44:39.438401: train_loss -0.7029 
2025-01-11 19:44:39.439906: val_loss -0.7368 
2025-01-11 19:44:39.445926: Pseudo dice [np.float32(0.9605), np.float32(0.8615)] 
2025-01-11 19:44:39.449936: Epoch time: 39.4 s 
2025-01-11 19:44:40.133829:  
2025-01-11 19:44:40.133829: Epoch 237 
2025-01-11 19:44:40.138897: Current learning rate: 0.0007 
2025-01-11 19:45:19.512472: train_loss -0.7103 
2025-01-11 19:45:19.513974: val_loss -0.6782 
2025-01-11 19:45:19.521490: Pseudo dice [np.float32(0.9513), np.float32(0.7913)] 
2025-01-11 19:45:19.525998: Epoch time: 39.38 s 
2025-01-11 19:45:20.248218:  
2025-01-11 19:45:20.248721: Epoch 238 
2025-01-11 19:45:20.253733: Current learning rate: 0.00065 
2025-01-11 19:45:59.660119: train_loss -0.6938 
2025-01-11 19:45:59.661122: val_loss -0.7153 
2025-01-11 19:45:59.667147: Pseudo dice [np.float32(0.9622), np.float32(0.8152)] 
2025-01-11 19:45:59.671771: Epoch time: 39.41 s 
2025-01-11 19:46:00.386648:  
2025-01-11 19:46:00.387150: Epoch 239 
2025-01-11 19:46:00.392160: Current learning rate: 0.0006 
2025-01-11 19:46:39.829189: train_loss -0.7214 
2025-01-11 19:46:39.830693: val_loss -0.6747 
2025-01-11 19:46:39.836708: Pseudo dice [np.float32(0.9554), np.float32(0.7906)] 
2025-01-11 19:46:39.840716: Epoch time: 39.44 s 
2025-01-11 19:46:40.574486:  
2025-01-11 19:46:40.574990: Epoch 240 
2025-01-11 19:46:40.580026: Current learning rate: 0.00055 
2025-01-11 19:47:19.868857: train_loss -0.7147 
2025-01-11 19:47:19.868857: val_loss -0.6952 
2025-01-11 19:47:19.876489: Pseudo dice [np.float32(0.9569), np.float32(0.816)] 
2025-01-11 19:47:19.879024: Epoch time: 39.3 s 
2025-01-11 19:47:20.608037:  
2025-01-11 19:47:20.608546: Epoch 241 
2025-01-11 19:47:20.613558: Current learning rate: 0.0005 
2025-01-11 19:48:00.174896: train_loss -0.7 
2025-01-11 19:48:00.175896: val_loss -0.7125 
2025-01-11 19:48:00.182415: Pseudo dice [np.float32(0.9589), np.float32(0.7735)] 
2025-01-11 19:48:00.185921: Epoch time: 39.57 s 
2025-01-11 19:48:00.883439:  
2025-01-11 19:48:00.883942: Epoch 242 
2025-01-11 19:48:00.889958: Current learning rate: 0.00045 
2025-01-11 19:48:40.153074: train_loss -0.6963 
2025-01-11 19:48:40.154078: val_loss -0.6804 
2025-01-11 19:48:40.160091: Pseudo dice [np.float32(0.9589), np.float32(0.8541)] 
2025-01-11 19:48:40.164102: Epoch time: 39.27 s 
2025-01-11 19:48:40.905170:  
2025-01-11 19:48:40.906171: Epoch 243 
2025-01-11 19:48:40.910724: Current learning rate: 0.0004 
2025-01-11 19:49:20.193935: train_loss -0.6919 
2025-01-11 19:49:20.193935: val_loss -0.7142 
2025-01-11 19:49:20.202963: Pseudo dice [np.float32(0.9623), np.float32(0.8449)] 
2025-01-11 19:49:20.206475: Epoch time: 39.29 s 
2025-01-11 19:49:21.084356:  
2025-01-11 19:49:21.084356: Epoch 244 
2025-01-11 19:49:21.090374: Current learning rate: 0.00035 
2025-01-11 19:50:00.511404: train_loss -0.7101 
2025-01-11 19:50:00.511915: val_loss -0.6775 
2025-01-11 19:50:00.516961: Pseudo dice [np.float32(0.9622), np.float32(0.8607)] 
2025-01-11 19:50:00.520016: Epoch time: 39.43 s 
2025-01-11 19:50:00.523117: Yayy! New best EMA pseudo Dice: 0.8866999745368958 
2025-01-11 19:50:01.342235:  
2025-01-11 19:50:01.342235: Epoch 245 
2025-01-11 19:50:01.347324: Current learning rate: 0.0003 
2025-01-11 19:50:40.672803: train_loss -0.7059 
2025-01-11 19:50:40.673803: val_loss -0.6825 
2025-01-11 19:50:40.679322: Pseudo dice [np.float32(0.9603), np.float32(0.8251)] 
2025-01-11 19:50:40.681829: Epoch time: 39.33 s 
2025-01-11 19:50:40.685341: Yayy! New best EMA pseudo Dice: 0.8873000144958496 
2025-01-11 19:50:41.465175:  
2025-01-11 19:50:41.465175: Epoch 246 
2025-01-11 19:50:41.471246: Current learning rate: 0.00024 
2025-01-11 19:51:20.956701: train_loss -0.7081 
2025-01-11 19:51:20.957328: val_loss -0.73 
2025-01-11 19:51:20.962855: Pseudo dice [np.float32(0.9582), np.float32(0.8599)] 
2025-01-11 19:51:20.966863: Epoch time: 39.49 s 
2025-01-11 19:51:20.970373: Yayy! New best EMA pseudo Dice: 0.8894000053405762 
2025-01-11 19:51:21.796309:  
2025-01-11 19:51:21.796309: Epoch 247 
2025-01-11 19:51:21.802346: Current learning rate: 0.00019 
2025-01-11 19:52:01.127382: train_loss -0.7126 
2025-01-11 19:52:01.128386: val_loss -0.7017 
2025-01-11 19:52:01.134897: Pseudo dice [np.float32(0.9647), np.float32(0.7367)] 
2025-01-11 19:52:01.139405: Epoch time: 39.33 s 
2025-01-11 19:52:01.830204:  
2025-01-11 19:52:01.831208: Epoch 248 
2025-01-11 19:52:01.836744: Current learning rate: 0.00013 
2025-01-11 19:52:41.092894: train_loss -0.6997 
2025-01-11 19:52:41.093908: val_loss -0.6783 
2025-01-11 19:52:41.101472: Pseudo dice [np.float32(0.9624), np.float32(0.8364)] 
2025-01-11 19:52:41.104502: Epoch time: 39.26 s 
2025-01-11 19:52:41.828189:  
2025-01-11 19:52:41.828691: Epoch 249 
2025-01-11 19:52:41.833702: Current learning rate: 7e-05 
2025-01-11 19:53:21.204864: train_loss -0.6916 
2025-01-11 19:53:21.204864: val_loss -0.6988 
2025-01-11 19:53:21.213443: Pseudo dice [np.float32(0.9611), np.float32(0.8326)] 
2025-01-11 19:53:21.216980: Epoch time: 39.38 s 
2025-01-11 19:53:22.055958: Training done. 
2025-01-11 19:53:22.096956: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset003_Liver\splits_final.json 
2025-01-11 19:53:22.110955: The split file contains 5 splits. 
2025-01-11 19:53:22.119956: Desired fold for training: 0 
2025-01-11 19:53:22.125956: This split has 104 training and 27 validation cases. 
2025-01-11 19:53:22.131955: predicting liver_101 
2025-01-11 19:53:22.139954: liver_101, shape torch.Size([1, 478, 470, 470]), rank 0 
2025-01-11 19:54:14.879361: predicting liver_11 
2025-01-11 19:54:14.924872: liver_11, shape torch.Size([1, 466, 448, 448]), rank 0 
2025-01-11 19:54:55.052119: predicting liver_112 
2025-01-11 19:54:55.091119: liver_112, shape torch.Size([1, 601, 427, 427]), rank 0 
2025-01-11 19:55:47.622692: predicting liver_115 
2025-01-11 19:55:47.678200: liver_115, shape torch.Size([1, 677, 504, 504]), rank 0 
2025-01-11 19:57:08.122180: predicting liver_12 
2025-01-11 19:57:08.206687: liver_12, shape torch.Size([1, 455, 436, 436]), rank 0 
2025-01-11 19:57:47.509498: predicting liver_120 
2025-01-11 19:57:47.553499: liver_120, shape torch.Size([1, 636, 496, 496]), rank 0 
2025-01-11 19:59:02.013764: predicting liver_128 
2025-01-11 19:59:02.080273: liver_128, shape torch.Size([1, 458, 521, 521]), rank 0 
2025-01-11 20:00:07.416378: predicting liver_17 
2025-01-11 20:00:07.474378: liver_17, shape torch.Size([1, 661, 496, 496]), rank 0 
2025-01-11 20:01:21.772361: predicting liver_19 
2025-01-11 20:01:21.847868: liver_19, shape torch.Size([1, 438, 502, 502]), rank 0 
2025-01-11 20:02:13.417115: predicting liver_24 
2025-01-11 20:02:13.471624: liver_24, shape torch.Size([1, 414, 447, 447]), rank 0 
2025-01-11 20:02:48.638721: predicting liver_25 
2025-01-11 20:02:48.674230: liver_25, shape torch.Size([1, 421, 512, 512]), rank 0 
2025-01-11 20:03:46.475088: predicting liver_27 
2025-01-11 20:03:46.521596: liver_27, shape torch.Size([1, 603, 492, 492]), rank 0 
2025-01-11 20:04:55.007957: predicting liver_3 
2025-01-11 20:04:55.070352: liver_3, shape torch.Size([1, 534, 462, 462]), rank 0 
2025-01-11 20:05:57.737611: predicting liver_38 
2025-01-11 20:05:57.792118: liver_38, shape torch.Size([1, 132, 667, 667]), rank 0 
2025-01-11 20:06:19.509772: predicting liver_40 
2025-01-11 20:06:19.535772: liver_40, shape torch.Size([1, 122, 667, 667]), rank 0 
2025-01-11 20:06:41.166156: predicting liver_41 
2025-01-11 20:06:41.193665: liver_41, shape torch.Size([1, 113, 667, 667]), rank 0 
2025-01-11 20:07:02.850782: predicting liver_42 
2025-01-11 20:07:02.875782: liver_42, shape torch.Size([1, 125, 667, 667]), rank 0 
2025-01-11 20:07:24.521246: predicting liver_44 
2025-01-11 20:07:24.547751: liver_44, shape torch.Size([1, 119, 667, 667]), rank 0 
2025-01-11 20:07:46.138862: predicting liver_5 
2025-01-11 20:07:46.164369: liver_5, shape torch.Size([1, 430, 646, 646]), rank 0 
2025-01-11 20:09:12.507601: predicting liver_51 
2025-01-11 20:09:12.582601: liver_51, shape torch.Size([1, 681, 602, 602]), rank 0 
2025-01-11 20:11:16.628188: predicting liver_52 
2025-01-11 20:11:16.748709: liver_52, shape torch.Size([1, 592, 558, 558]), rank 0 
2025-01-11 20:12:43.531790: predicting liver_58 
2025-01-11 20:12:43.626300: liver_58, shape torch.Size([1, 424, 456, 456]), rank 0 
2025-01-11 20:13:29.194638: predicting liver_64 
2025-01-11 20:13:29.242281: liver_64, shape torch.Size([1, 460, 519, 519]), rank 0 
2025-01-11 20:14:34.042670: predicting liver_70 
2025-01-11 20:14:34.094671: liver_70, shape torch.Size([1, 416, 399, 399]), rank 0 
2025-01-11 20:15:08.807510: predicting liver_75 
2025-01-11 20:15:08.836510: liver_75, shape torch.Size([1, 445, 505, 505]), rank 0 
2025-01-11 20:16:13.873429: predicting liver_77 
2025-01-11 20:16:13.921546: liver_77, shape torch.Size([1, 470, 521, 521]), rank 0 
2025-01-11 20:17:18.728351: predicting liver_82 
2025-01-11 20:17:18.791859: liver_82, shape torch.Size([1, 416, 417, 417]), rank 0 
2025-01-11 20:18:20.149540: Validation complete 
2025-01-11 20:18:20.150538: Mean Validation Dice:  0.7938103193260058 
