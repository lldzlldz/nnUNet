2025-01-11 05:41:06.772601: Ignore previous message about oversample_foreground_percent. oversample_foreground_percent overwritten to 0.75 

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-01-11 05:41:06.777112: self.oversample_foreground_percent 0.75 
2025-01-11 05:41:06.780110: do_dummy_2d_data_aug: False 
2025-01-11 05:41:06.783109: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset003_Liver\splits_final.json 
2025-01-11 05:41:06.788261: The split file contains 5 splits. 
2025-01-11 05:41:06.791260: Desired fold for training: 0 
2025-01-11 05:41:06.793261: This split has 104 training and 27 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_batch_size_4_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 4, 'patch_size': [96, 112, 112], 'median_image_size_in_voxels': [482.0, 512.0, 512.0], 'spacing': [1.0, 0.767578125, 0.767578125], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset003_Liver', 'plans_name': 'nnUNetPlans_batch_size_4', 'original_median_spacing_after_transp': [1.0, 0.767578125, 0.767578125], 'original_median_shape_after_transp': [432, 512, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 5420.0, 'mean': 99.48007202148438, 'median': 101.0, 'min': -983.0, 'percentile_00_5': -15.0, 'percentile_99_5': 197.0, 'std': 37.13840103149414}}} 
 
2025-01-11 05:41:15.294625: unpacking dataset... 
2025-01-11 05:41:15.561401: unpacking done... 
2025-01-11 05:41:18.485273:  
2025-01-11 05:41:18.485273: Epoch 0 
2025-01-11 05:41:18.490362: Current learning rate: 0.01 
2025-01-11 05:42:01.319345: train_loss 0.0393 
2025-01-11 05:42:01.320360: val_loss -0.1566 
2025-01-11 05:42:01.325426: Pseudo dice [np.float32(0.8687), np.float32(0.0)] 
2025-01-11 05:42:01.328957: Epoch time: 42.84 s 
2025-01-11 05:42:01.331494: Yayy! New best EMA pseudo Dice: 0.4343999922275543 
2025-01-11 05:42:01.889945:  
2025-01-11 05:42:01.890948: Epoch 1 
2025-01-11 05:42:01.895526: Current learning rate: 0.00996 
2025-01-11 05:42:40.755530: train_loss -0.1811 
2025-01-11 05:42:40.756529: val_loss -0.3053 
2025-01-11 05:42:40.763049: Pseudo dice [np.float32(0.9011), np.float32(0.3803)] 
2025-01-11 05:42:40.768066: Epoch time: 38.87 s 
2025-01-11 05:42:40.773082: Yayy! New best EMA pseudo Dice: 0.45500001311302185 
2025-01-11 05:42:41.369803:  
2025-01-11 05:42:41.369803: Epoch 2 
2025-01-11 05:42:41.375818: Current learning rate: 0.00993 
2025-01-11 05:43:20.224432: train_loss -0.28 
2025-01-11 05:43:20.225934: val_loss -0.3945 
2025-01-11 05:43:20.231954: Pseudo dice [np.float32(0.9165), np.float32(0.5142)] 
2025-01-11 05:43:20.234462: Epoch time: 38.86 s 
2025-01-11 05:43:20.240473: Yayy! New best EMA pseudo Dice: 0.48100000619888306 
2025-01-11 05:43:20.854053:  
2025-01-11 05:43:20.854053: Epoch 3 
2025-01-11 05:43:20.859639: Current learning rate: 0.00989 
2025-01-11 05:43:59.739204: train_loss -0.3728 
2025-01-11 05:43:59.739204: val_loss -0.43 
2025-01-11 05:43:59.746246: Pseudo dice [np.float32(0.9214), np.float32(0.5118)] 
2025-01-11 05:43:59.748752: Epoch time: 38.89 s 
2025-01-11 05:43:59.752262: Yayy! New best EMA pseudo Dice: 0.5045999884605408 
2025-01-11 05:44:00.354077:  
2025-01-11 05:44:00.354578: Epoch 4 
2025-01-11 05:44:00.359593: Current learning rate: 0.00986 
2025-01-11 05:44:39.262972: train_loss -0.3624 
2025-01-11 05:44:39.262972: val_loss -0.4983 
2025-01-11 05:44:39.268984: Pseudo dice [np.float32(0.9424), np.float32(0.5993)] 
2025-01-11 05:44:39.272996: Epoch time: 38.91 s 
2025-01-11 05:44:39.277014: Yayy! New best EMA pseudo Dice: 0.5311999917030334 
2025-01-11 05:44:40.006622:  
2025-01-11 05:44:40.007127: Epoch 5 
2025-01-11 05:44:40.012140: Current learning rate: 0.00982 
2025-01-11 05:45:18.924369: train_loss -0.406 
2025-01-11 05:45:18.925374: val_loss -0.4176 
2025-01-11 05:45:18.930902: Pseudo dice [np.float32(0.9328), np.float32(0.5317)] 
2025-01-11 05:45:18.937417: Epoch time: 38.92 s 
2025-01-11 05:45:18.941927: Yayy! New best EMA pseudo Dice: 0.5512999892234802 
2025-01-11 05:45:19.532977:  
2025-01-11 05:45:19.533980: Epoch 6 
2025-01-11 05:45:19.538549: Current learning rate: 0.00978 
2025-01-11 05:45:58.501812: train_loss -0.4232 
2025-01-11 05:45:58.502816: val_loss -0.5023 
2025-01-11 05:45:58.508982: Pseudo dice [np.float32(0.9322), np.float32(0.6069)] 
2025-01-11 05:45:58.512533: Epoch time: 38.97 s 
2025-01-11 05:45:58.515558: Yayy! New best EMA pseudo Dice: 0.5730999708175659 
2025-01-11 05:45:59.133454:  
2025-01-11 05:45:59.134457: Epoch 7 
2025-01-11 05:45:59.140050: Current learning rate: 0.00975 
2025-01-11 05:46:38.099319: train_loss -0.437 
2025-01-11 05:46:38.099319: val_loss -0.4656 
2025-01-11 05:46:38.106844: Pseudo dice [np.float32(0.9302), np.float32(0.5338)] 
2025-01-11 05:46:38.110351: Epoch time: 38.97 s 
2025-01-11 05:46:38.113359: Yayy! New best EMA pseudo Dice: 0.5889999866485596 
2025-01-11 05:46:38.720100:  
2025-01-11 05:46:38.721103: Epoch 8 
2025-01-11 05:46:38.726149: Current learning rate: 0.00971 
2025-01-11 05:47:17.708840: train_loss -0.4686 
2025-01-11 05:47:17.708840: val_loss -0.5928 
2025-01-11 05:47:17.715859: Pseudo dice [np.float32(0.9449), np.float32(0.7009)] 
2025-01-11 05:47:17.720873: Epoch time: 38.99 s 
2025-01-11 05:47:17.724890: Yayy! New best EMA pseudo Dice: 0.6123999953269958 
2025-01-11 05:47:18.350149:  
2025-01-11 05:47:18.350149: Epoch 9 
2025-01-11 05:47:18.355188: Current learning rate: 0.00968 
2025-01-11 05:47:57.260730: train_loss -0.4524 
2025-01-11 05:47:57.261233: val_loss -0.5296 
2025-01-11 05:47:57.267258: Pseudo dice [np.float32(0.946), np.float32(0.6622)] 
2025-01-11 05:47:57.269768: Epoch time: 38.91 s 
2025-01-11 05:47:57.273778: Yayy! New best EMA pseudo Dice: 0.631600022315979 
2025-01-11 05:47:57.872477:  
2025-01-11 05:47:57.872477: Epoch 10 
2025-01-11 05:47:57.878012: Current learning rate: 0.00964 
2025-01-11 05:48:36.742382: train_loss -0.4902 
2025-01-11 05:48:36.743386: val_loss -0.5696 
2025-01-11 05:48:36.749905: Pseudo dice [np.float32(0.9481), np.float32(0.6506)] 
2025-01-11 05:48:36.753922: Epoch time: 38.87 s 
2025-01-11 05:48:36.758989: Yayy! New best EMA pseudo Dice: 0.6484000086784363 
2025-01-11 05:48:37.359469:  
2025-01-11 05:48:37.359986: Epoch 11 
2025-01-11 05:48:37.364540: Current learning rate: 0.0096 
2025-01-11 05:49:16.258885: train_loss -0.4874 
2025-01-11 05:49:16.259909: val_loss -0.5929 
2025-01-11 05:49:16.266008: Pseudo dice [np.float32(0.9507), np.float32(0.7264)] 
2025-01-11 05:49:16.270068: Epoch time: 38.9 s 
2025-01-11 05:49:16.273119: Yayy! New best EMA pseudo Dice: 0.6674000024795532 
2025-01-11 05:49:16.874562:  
2025-01-11 05:49:16.874562: Epoch 12 
2025-01-11 05:49:16.880217: Current learning rate: 0.00957 
2025-01-11 05:49:55.787435: train_loss -0.4875 
2025-01-11 05:49:55.787435: val_loss -0.5495 
2025-01-11 05:49:55.793364: Pseudo dice [np.float32(0.9427), np.float32(0.7082)] 
2025-01-11 05:49:55.796875: Epoch time: 38.91 s 
2025-01-11 05:49:55.800383: Yayy! New best EMA pseudo Dice: 0.6832000017166138 
2025-01-11 05:49:56.550791:  
2025-01-11 05:49:56.550791: Epoch 13 
2025-01-11 05:49:56.556355: Current learning rate: 0.00953 
2025-01-11 05:50:35.448336: train_loss -0.4809 
2025-01-11 05:50:35.448336: val_loss -0.576 
2025-01-11 05:50:35.455006: Pseudo dice [np.float32(0.9478), np.float32(0.6691)] 
2025-01-11 05:50:35.457615: Epoch time: 38.9 s 
2025-01-11 05:50:35.461174: Yayy! New best EMA pseudo Dice: 0.6956999897956848 
2025-01-11 05:50:36.057821:  
2025-01-11 05:50:36.058825: Epoch 14 
2025-01-11 05:50:36.063359: Current learning rate: 0.00949 
2025-01-11 05:51:14.994663: train_loss -0.5152 
2025-01-11 05:51:14.994663: val_loss -0.5612 
2025-01-11 05:51:15.002184: Pseudo dice [np.float32(0.9499), np.float32(0.6789)] 
2025-01-11 05:51:15.004692: Epoch time: 38.94 s 
2025-01-11 05:51:15.008702: Yayy! New best EMA pseudo Dice: 0.7075999975204468 
2025-01-11 05:51:15.616347:  
2025-01-11 05:51:15.617349: Epoch 15 
2025-01-11 05:51:15.622913: Current learning rate: 0.00946 
2025-01-11 05:51:54.359289: train_loss -0.5018 
2025-01-11 05:51:54.359790: val_loss -0.5677 
2025-01-11 05:51:54.365808: Pseudo dice [np.float32(0.9445), np.float32(0.7353)] 
2025-01-11 05:51:54.369316: Epoch time: 38.74 s 
2025-01-11 05:51:54.372325: Yayy! New best EMA pseudo Dice: 0.72079998254776 
2025-01-11 05:51:54.986937:  
2025-01-11 05:51:54.987439: Epoch 16 
2025-01-11 05:51:54.992452: Current learning rate: 0.00942 
2025-01-11 05:52:33.681115: train_loss -0.4999 
2025-01-11 05:52:33.681115: val_loss -0.6074 
2025-01-11 05:52:33.687696: Pseudo dice [np.float32(0.9525), np.float32(0.7606)] 
2025-01-11 05:52:33.692248: Epoch time: 38.7 s 
2025-01-11 05:52:33.696266: Yayy! New best EMA pseudo Dice: 0.7343999743461609 
2025-01-11 05:52:34.316906:  
2025-01-11 05:52:34.317909: Epoch 17 
2025-01-11 05:52:34.322465: Current learning rate: 0.00939 
2025-01-11 05:53:12.962323: train_loss -0.5501 
2025-01-11 05:53:12.962837: val_loss -0.6236 
2025-01-11 05:53:12.968913: Pseudo dice [np.float32(0.9551), np.float32(0.759)] 
2025-01-11 05:53:12.972452: Epoch time: 38.65 s 
2025-01-11 05:53:12.975483: Yayy! New best EMA pseudo Dice: 0.7466999888420105 
2025-01-11 05:53:13.581690:  
2025-01-11 05:53:13.581690: Epoch 18 
2025-01-11 05:53:13.586737: Current learning rate: 0.00935 
2025-01-11 05:53:52.232168: train_loss -0.5599 
2025-01-11 05:53:52.233172: val_loss -0.5862 
2025-01-11 05:53:52.239275: Pseudo dice [np.float32(0.9479), np.float32(0.7251)] 
2025-01-11 05:53:52.243820: Epoch time: 38.65 s 
2025-01-11 05:53:52.247337: Yayy! New best EMA pseudo Dice: 0.7555999755859375 
2025-01-11 05:53:52.861470:  
2025-01-11 05:53:52.861470: Epoch 19 
2025-01-11 05:53:52.866992: Current learning rate: 0.00931 
2025-01-11 05:54:31.511441: train_loss -0.5673 
2025-01-11 05:54:31.512444: val_loss -0.5811 
2025-01-11 05:54:31.518962: Pseudo dice [np.float32(0.948), np.float32(0.7154)] 
2025-01-11 05:54:31.522470: Epoch time: 38.65 s 
2025-01-11 05:54:31.524974: Yayy! New best EMA pseudo Dice: 0.7631999850273132 
2025-01-11 05:54:32.305108:  
2025-01-11 05:54:32.305108: Epoch 20 
2025-01-11 05:54:32.310682: Current learning rate: 0.00928 
2025-01-11 05:55:10.964406: train_loss -0.5329 
2025-01-11 05:55:10.965407: val_loss -0.6372 
2025-01-11 05:55:10.970926: Pseudo dice [np.float32(0.9585), np.float32(0.7889)] 
2025-01-11 05:55:10.974436: Epoch time: 38.66 s 
2025-01-11 05:55:10.976944: Yayy! New best EMA pseudo Dice: 0.7742999792098999 
2025-01-11 05:55:11.600204:  
2025-01-11 05:55:11.600204: Epoch 21 
2025-01-11 05:55:11.606751: Current learning rate: 0.00924 
2025-01-11 05:55:50.247082: train_loss -0.5507 
2025-01-11 05:55:50.248083: val_loss -0.5824 
2025-01-11 05:55:50.254148: Pseudo dice [np.float32(0.9321), np.float32(0.733)] 
2025-01-11 05:55:50.256167: Epoch time: 38.65 s 
2025-01-11 05:55:50.260202: Yayy! New best EMA pseudo Dice: 0.7800999879837036 
2025-01-11 05:55:50.846599:  
2025-01-11 05:55:50.846599: Epoch 22 
2025-01-11 05:55:50.852111: Current learning rate: 0.0092 
2025-01-11 05:56:29.512657: train_loss -0.5704 
2025-01-11 05:56:29.513659: val_loss -0.6384 
2025-01-11 05:56:29.519693: Pseudo dice [np.float32(0.9589), np.float32(0.7447)] 
2025-01-11 05:56:29.524228: Epoch time: 38.67 s 
2025-01-11 05:56:29.527739: Yayy! New best EMA pseudo Dice: 0.7872999906539917 
2025-01-11 05:56:30.118575:  
2025-01-11 05:56:30.119085: Epoch 23 
2025-01-11 05:56:30.124205: Current learning rate: 0.00917 
2025-01-11 05:57:08.809797: train_loss -0.5721 
2025-01-11 05:57:08.810302: val_loss -0.6364 
2025-01-11 05:57:08.816417: Pseudo dice [np.float32(0.9529), np.float32(0.749)] 
2025-01-11 05:57:08.821006: Epoch time: 38.69 s 
2025-01-11 05:57:08.823545: Yayy! New best EMA pseudo Dice: 0.7936999797821045 
2025-01-11 05:57:09.415503:  
2025-01-11 05:57:09.416007: Epoch 24 
2025-01-11 05:57:09.421017: Current learning rate: 0.00913 
2025-01-11 05:57:48.081564: train_loss -0.5371 
2025-01-11 05:57:48.082567: val_loss -0.5949 
2025-01-11 05:57:48.088581: Pseudo dice [np.float32(0.9431), np.float32(0.7512)] 
2025-01-11 05:57:48.092596: Epoch time: 38.67 s 
2025-01-11 05:57:48.095110: Yayy! New best EMA pseudo Dice: 0.7990000247955322 
2025-01-11 05:57:48.697735:  
2025-01-11 05:57:48.697735: Epoch 25 
2025-01-11 05:57:48.703753: Current learning rate: 0.0091 
2025-01-11 05:58:27.456916: train_loss -0.5421 
2025-01-11 05:58:27.457935: val_loss -0.5524 
2025-01-11 05:58:27.463971: Pseudo dice [np.float32(0.9466), np.float32(0.6669)] 
2025-01-11 05:58:27.467496: Epoch time: 38.76 s 
2025-01-11 05:58:27.470538: Yayy! New best EMA pseudo Dice: 0.7997999787330627 
2025-01-11 05:58:28.063091:  
2025-01-11 05:58:28.063091: Epoch 26 
2025-01-11 05:58:28.068199: Current learning rate: 0.00906 
2025-01-11 05:59:06.700442: train_loss -0.5675 
2025-01-11 05:59:06.701009: val_loss -0.6076 
2025-01-11 05:59:06.707136: Pseudo dice [np.float32(0.9568), np.float32(0.7431)] 
2025-01-11 05:59:06.711740: Epoch time: 38.64 s 
2025-01-11 05:59:06.715295: Yayy! New best EMA pseudo Dice: 0.8047999739646912 
2025-01-11 05:59:07.302057:  
2025-01-11 05:59:07.302057: Epoch 27 
2025-01-11 05:59:07.307068: Current learning rate: 0.00902 
2025-01-11 05:59:45.941706: train_loss -0.581 
2025-01-11 05:59:45.941706: val_loss -0.6642 
2025-01-11 05:59:45.948235: Pseudo dice [np.float32(0.9545), np.float32(0.749)] 
2025-01-11 05:59:45.951244: Epoch time: 38.64 s 
2025-01-11 05:59:45.953748: Yayy! New best EMA pseudo Dice: 0.809499979019165 
2025-01-11 05:59:46.695939:  
2025-01-11 05:59:46.696942: Epoch 28 
2025-01-11 05:59:46.701973: Current learning rate: 0.00899 
2025-01-11 06:00:25.351333: train_loss -0.5621 
2025-01-11 06:00:25.351333: val_loss -0.6176 
2025-01-11 06:00:25.358944: Pseudo dice [np.float32(0.9493), np.float32(0.7236)] 
2025-01-11 06:00:25.361033: Epoch time: 38.66 s 
2025-01-11 06:00:25.364587: Yayy! New best EMA pseudo Dice: 0.8122000098228455 
2025-01-11 06:00:25.957366:  
2025-01-11 06:00:25.957366: Epoch 29 
2025-01-11 06:00:25.963383: Current learning rate: 0.00895 
2025-01-11 06:01:04.601950: train_loss -0.5961 
2025-01-11 06:01:04.602458: val_loss -0.6526 
2025-01-11 06:01:04.607556: Pseudo dice [np.float32(0.9607), np.float32(0.7712)] 
2025-01-11 06:01:04.612136: Epoch time: 38.65 s 
2025-01-11 06:01:04.616769: Yayy! New best EMA pseudo Dice: 0.8176000118255615 
2025-01-11 06:01:05.226081:  
2025-01-11 06:01:05.227583: Epoch 30 
2025-01-11 06:01:05.233601: Current learning rate: 0.00891 
2025-01-11 06:01:43.905874: train_loss -0.605 
2025-01-11 06:01:43.906376: val_loss -0.5516 
2025-01-11 06:01:43.911389: Pseudo dice [np.float32(0.9409), np.float32(0.5832)] 
2025-01-11 06:01:43.914903: Epoch time: 38.68 s 
2025-01-11 06:01:44.423588:  
2025-01-11 06:01:44.423588: Epoch 31 
2025-01-11 06:01:44.428600: Current learning rate: 0.00888 
2025-01-11 06:02:23.080535: train_loss -0.606 
2025-01-11 06:02:23.080535: val_loss -0.6373 
2025-01-11 06:02:23.086567: Pseudo dice [np.float32(0.956), np.float32(0.7576)] 
2025-01-11 06:02:23.089586: Epoch time: 38.66 s 
2025-01-11 06:02:23.604688:  
2025-01-11 06:02:23.604688: Epoch 32 
2025-01-11 06:02:23.609702: Current learning rate: 0.00884 
2025-01-11 06:03:02.290247: train_loss -0.5747 
2025-01-11 06:03:02.291250: val_loss -0.6631 
2025-01-11 06:03:02.297281: Pseudo dice [np.float32(0.9608), np.float32(0.8083)] 
2025-01-11 06:03:02.300346: Epoch time: 38.69 s 
2025-01-11 06:03:02.303859: Yayy! New best EMA pseudo Dice: 0.8233000040054321 
2025-01-11 06:03:02.913261:  
2025-01-11 06:03:02.913767: Epoch 33 
2025-01-11 06:03:02.918811: Current learning rate: 0.0088 
2025-01-11 06:03:41.566589: train_loss -0.5959 
2025-01-11 06:03:41.567588: val_loss -0.6465 
2025-01-11 06:03:41.573109: Pseudo dice [np.float32(0.9554), np.float32(0.7765)] 
2025-01-11 06:03:41.576622: Epoch time: 38.65 s 
2025-01-11 06:03:41.579133: Yayy! New best EMA pseudo Dice: 0.8276000022888184 
2025-01-11 06:03:42.172870:  
2025-01-11 06:03:42.173873: Epoch 34 
2025-01-11 06:03:42.178491: Current learning rate: 0.00877 
2025-01-11 06:04:20.790675: train_loss -0.6001 
2025-01-11 06:04:20.791679: val_loss -0.7183 
2025-01-11 06:04:20.796697: Pseudo dice [np.float32(0.9562), np.float32(0.8498)] 
2025-01-11 06:04:20.800204: Epoch time: 38.62 s 
2025-01-11 06:04:20.803220: Yayy! New best EMA pseudo Dice: 0.835099995136261 
2025-01-11 06:04:21.408669:  
2025-01-11 06:04:21.409673: Epoch 35 
2025-01-11 06:04:21.415767: Current learning rate: 0.00873 
2025-01-11 06:05:00.043735: train_loss -0.5927 
2025-01-11 06:05:00.043735: val_loss -0.603 
2025-01-11 06:05:00.049759: Pseudo dice [np.float32(0.9407), np.float32(0.7414)] 
2025-01-11 06:05:00.055769: Epoch time: 38.64 s 
2025-01-11 06:05:00.058781: Yayy! New best EMA pseudo Dice: 0.8356999754905701 
2025-01-11 06:05:00.667778:  
2025-01-11 06:05:00.668778: Epoch 36 
2025-01-11 06:05:00.674392: Current learning rate: 0.00869 
2025-01-11 06:05:39.624767: train_loss -0.5951 
2025-01-11 06:05:39.625767: val_loss -0.6202 
2025-01-11 06:05:39.632296: Pseudo dice [np.float32(0.9516), np.float32(0.75)] 
2025-01-11 06:05:39.635805: Epoch time: 38.96 s 
2025-01-11 06:05:39.638847: Yayy! New best EMA pseudo Dice: 0.8371999859809875 
2025-01-11 06:05:40.237575:  
2025-01-11 06:05:40.237575: Epoch 37 
2025-01-11 06:05:40.242595: Current learning rate: 0.00866 
2025-01-11 06:06:18.885093: train_loss -0.6026 
2025-01-11 06:06:18.886094: val_loss -0.6743 
2025-01-11 06:06:18.891616: Pseudo dice [np.float32(0.9553), np.float32(0.7924)] 
2025-01-11 06:06:18.895128: Epoch time: 38.65 s 
2025-01-11 06:06:18.898635: Yayy! New best EMA pseudo Dice: 0.8409000039100647 
2025-01-11 06:06:19.506046:  
2025-01-11 06:06:19.506548: Epoch 38 
2025-01-11 06:06:19.511566: Current learning rate: 0.00862 
2025-01-11 06:06:58.161923: train_loss -0.6078 
2025-01-11 06:06:58.162926: val_loss -0.5977 
2025-01-11 06:06:58.169445: Pseudo dice [np.float32(0.9402), np.float32(0.6823)] 
2025-01-11 06:06:58.174455: Epoch time: 38.66 s 
2025-01-11 06:06:58.703158:  
2025-01-11 06:06:58.703158: Epoch 39 
2025-01-11 06:06:58.708184: Current learning rate: 0.00858 
2025-01-11 06:07:37.354084: train_loss -0.5948 
2025-01-11 06:07:37.354597: val_loss -0.6654 
2025-01-11 06:07:37.360748: Pseudo dice [np.float32(0.9514), np.float32(0.8143)] 
2025-01-11 06:07:37.364625: Epoch time: 38.65 s 
2025-01-11 06:07:37.368728: Yayy! New best EMA pseudo Dice: 0.8424000144004822 
2025-01-11 06:07:37.987614:  
2025-01-11 06:07:37.988617: Epoch 40 
2025-01-11 06:07:37.993664: Current learning rate: 0.00855 
2025-01-11 06:08:16.629539: train_loss -0.6083 
2025-01-11 06:08:16.630539: val_loss -0.6639 
2025-01-11 06:08:16.636057: Pseudo dice [np.float32(0.9588), np.float32(0.7869)] 
2025-01-11 06:08:16.639120: Epoch time: 38.64 s 
2025-01-11 06:08:16.642659: Yayy! New best EMA pseudo Dice: 0.8453999757766724 
2025-01-11 06:08:17.257403:  
2025-01-11 06:08:17.257403: Epoch 41 
2025-01-11 06:08:17.263499: Current learning rate: 0.00851 
2025-01-11 06:08:55.888291: train_loss -0.6181 
2025-01-11 06:08:55.888291: val_loss -0.6743 
2025-01-11 06:08:55.894831: Pseudo dice [np.float32(0.9605), np.float32(0.7747)] 
2025-01-11 06:08:55.897427: Epoch time: 38.63 s 
2025-01-11 06:08:55.900938: Yayy! New best EMA pseudo Dice: 0.8476999998092651 
2025-01-11 06:08:56.488899:  
2025-01-11 06:08:56.489901: Epoch 42 
2025-01-11 06:08:56.494990: Current learning rate: 0.00847 
2025-01-11 06:09:35.108225: train_loss -0.6063 
2025-01-11 06:09:35.109229: val_loss -0.6291 
2025-01-11 06:09:35.115859: Pseudo dice [np.float32(0.9571), np.float32(0.6803)] 
2025-01-11 06:09:35.118907: Epoch time: 38.62 s 
2025-01-11 06:09:35.621367:  
2025-01-11 06:09:35.621367: Epoch 43 
2025-01-11 06:09:35.626385: Current learning rate: 0.00844 
2025-01-11 06:10:14.244467: train_loss -0.6299 
2025-01-11 06:10:14.244467: val_loss -0.6809 
2025-01-11 06:10:14.251027: Pseudo dice [np.float32(0.9618), np.float32(0.7899)] 
2025-01-11 06:10:14.256539: Epoch time: 38.62 s 
2025-01-11 06:10:14.260049: Yayy! New best EMA pseudo Dice: 0.8478999733924866 
2025-01-11 06:10:14.989160:  
2025-01-11 06:10:14.989160: Epoch 44 
2025-01-11 06:10:14.994679: Current learning rate: 0.0084 
2025-01-11 06:10:53.631619: train_loss -0.6345 
2025-01-11 06:10:53.632312: val_loss -0.6603 
2025-01-11 06:10:53.637888: Pseudo dice [np.float32(0.96), np.float32(0.765)] 
2025-01-11 06:10:53.640057: Epoch time: 38.64 s 
2025-01-11 06:10:53.644592: Yayy! New best EMA pseudo Dice: 0.8493000268936157 
2025-01-11 06:10:54.237281:  
2025-01-11 06:10:54.237281: Epoch 45 
2025-01-11 06:10:54.242315: Current learning rate: 0.00836 
2025-01-11 06:11:32.849696: train_loss -0.6181 
2025-01-11 06:11:32.850701: val_loss -0.6119 
2025-01-11 06:11:32.857220: Pseudo dice [np.float32(0.9545), np.float32(0.6579)] 
2025-01-11 06:11:32.862241: Epoch time: 38.61 s 
2025-01-11 06:11:33.370822:  
2025-01-11 06:11:33.370822: Epoch 46 
2025-01-11 06:11:33.375895: Current learning rate: 0.00833 
2025-01-11 06:12:12.003930: train_loss -0.6076 
2025-01-11 06:12:12.003930: val_loss -0.5686 
2025-01-11 06:12:12.010443: Pseudo dice [np.float32(0.9433), np.float32(0.6461)] 
2025-01-11 06:12:12.013951: Epoch time: 38.63 s 
2025-01-11 06:12:12.517748:  
2025-01-11 06:12:12.517748: Epoch 47 
2025-01-11 06:12:12.523324: Current learning rate: 0.00829 
2025-01-11 06:12:51.254581: train_loss -0.629 
2025-01-11 06:12:51.255083: val_loss -0.6768 
2025-01-11 06:12:51.261101: Pseudo dice [np.float32(0.9557), np.float32(0.7863)] 
2025-01-11 06:12:51.264610: Epoch time: 38.74 s 
2025-01-11 06:12:51.761801:  
2025-01-11 06:12:51.762804: Epoch 48 
2025-01-11 06:12:51.767851: Current learning rate: 0.00825 
2025-01-11 06:13:30.404744: train_loss -0.6362 
2025-01-11 06:13:30.404744: val_loss -0.6993 
2025-01-11 06:13:30.410816: Pseudo dice [np.float32(0.9642), np.float32(0.8053)] 
2025-01-11 06:13:30.414177: Epoch time: 38.64 s 
2025-01-11 06:13:30.923996:  
2025-01-11 06:13:30.923996: Epoch 49 
2025-01-11 06:13:30.929629: Current learning rate: 0.00822 
2025-01-11 06:14:09.603764: train_loss -0.6402 
2025-01-11 06:14:09.604766: val_loss -0.6774 
2025-01-11 06:14:09.609781: Pseudo dice [np.float32(0.9593), np.float32(0.8182)] 
2025-01-11 06:14:09.613791: Epoch time: 38.68 s 
2025-01-11 06:14:09.696671: Yayy! New best EMA pseudo Dice: 0.8514000177383423 
2025-01-11 06:14:10.301183:  
2025-01-11 06:14:10.301183: Epoch 50 
2025-01-11 06:14:10.306711: Current learning rate: 0.00818 
2025-01-11 06:14:48.972640: train_loss -0.6578 
2025-01-11 06:14:48.973144: val_loss -0.7177 
2025-01-11 06:14:48.978157: Pseudo dice [np.float32(0.9602), np.float32(0.802)] 
2025-01-11 06:14:48.980662: Epoch time: 38.67 s 
2025-01-11 06:14:48.984172: Yayy! New best EMA pseudo Dice: 0.8543999791145325 
2025-01-11 06:14:49.583911:  
2025-01-11 06:14:49.584413: Epoch 51 
2025-01-11 06:14:49.589449: Current learning rate: 0.00814 
2025-01-11 06:15:28.238795: train_loss -0.655 
2025-01-11 06:15:28.239286: val_loss -0.6078 
2025-01-11 06:15:28.244827: Pseudo dice [np.float32(0.9519), np.float32(0.6996)] 
2025-01-11 06:15:28.248333: Epoch time: 38.65 s 
2025-01-11 06:15:28.916848:  
2025-01-11 06:15:28.916848: Epoch 52 
2025-01-11 06:15:28.922382: Current learning rate: 0.00811 
2025-01-11 06:16:07.539141: train_loss -0.6617 
2025-01-11 06:16:07.539141: val_loss -0.7363 
2025-01-11 06:16:07.545728: Pseudo dice [np.float32(0.9644), np.float32(0.8043)] 
2025-01-11 06:16:07.550743: Epoch time: 38.62 s 
2025-01-11 06:16:07.554755: Yayy! New best EMA pseudo Dice: 0.8547999858856201 
2025-01-11 06:16:08.148526:  
2025-01-11 06:16:08.148526: Epoch 53 
2025-01-11 06:16:08.154569: Current learning rate: 0.00807 
2025-01-11 06:16:46.795298: train_loss -0.6511 
2025-01-11 06:16:46.795298: val_loss -0.6369 
2025-01-11 06:16:46.801327: Pseudo dice [np.float32(0.9555), np.float32(0.751)] 
2025-01-11 06:16:46.805344: Epoch time: 38.65 s 
2025-01-11 06:16:47.316228:  
2025-01-11 06:16:47.316228: Epoch 54 
2025-01-11 06:16:47.322343: Current learning rate: 0.00803 
2025-01-11 06:17:25.956875: train_loss -0.6351 
2025-01-11 06:17:25.957880: val_loss -0.6746 
2025-01-11 06:17:25.962893: Pseudo dice [np.float32(0.9575), np.float32(0.8215)] 
2025-01-11 06:17:25.966907: Epoch time: 38.64 s 
2025-01-11 06:17:25.971419: Yayy! New best EMA pseudo Dice: 0.8580999970436096 
2025-01-11 06:17:26.577849:  
2025-01-11 06:17:26.577849: Epoch 55 
2025-01-11 06:17:26.582862: Current learning rate: 0.008 
2025-01-11 06:18:05.205479: train_loss -0.6577 
2025-01-11 06:18:05.205479: val_loss -0.6489 
2025-01-11 06:18:05.211505: Pseudo dice [np.float32(0.9553), np.float32(0.7706)] 
2025-01-11 06:18:05.214518: Epoch time: 38.63 s 
2025-01-11 06:18:05.218031: Yayy! New best EMA pseudo Dice: 0.8586000204086304 
2025-01-11 06:18:05.810734:  
2025-01-11 06:18:05.811738: Epoch 56 
2025-01-11 06:18:05.816289: Current learning rate: 0.00796 
2025-01-11 06:18:44.460033: train_loss -0.6637 
2025-01-11 06:18:44.461036: val_loss -0.6935 
2025-01-11 06:18:44.467555: Pseudo dice [np.float32(0.9601), np.float32(0.8226)] 
2025-01-11 06:18:44.471067: Epoch time: 38.65 s 
2025-01-11 06:18:44.473577: Yayy! New best EMA pseudo Dice: 0.8618999719619751 
2025-01-11 06:18:45.076850:  
2025-01-11 06:18:45.077851: Epoch 57 
2025-01-11 06:18:45.082904: Current learning rate: 0.00792 
2025-01-11 06:19:23.708038: train_loss -0.6683 
2025-01-11 06:19:23.708541: val_loss -0.6953 
2025-01-11 06:19:23.714088: Pseudo dice [np.float32(0.9608), np.float32(0.7709)] 
2025-01-11 06:19:23.717149: Epoch time: 38.63 s 
2025-01-11 06:19:23.720726: Yayy! New best EMA pseudo Dice: 0.8622999787330627 
2025-01-11 06:19:24.319518:  
2025-01-11 06:19:24.320518: Epoch 58 
2025-01-11 06:19:24.326105: Current learning rate: 0.00789 
2025-01-11 06:20:03.059356: train_loss -0.6754 
2025-01-11 06:20:03.059859: val_loss -0.6943 
2025-01-11 06:20:03.065872: Pseudo dice [np.float32(0.9584), np.float32(0.7761)] 
2025-01-11 06:20:03.068883: Epoch time: 38.74 s 
2025-01-11 06:20:03.071916: Yayy! New best EMA pseudo Dice: 0.8628000020980835 
2025-01-11 06:20:03.816653:  
2025-01-11 06:20:03.816653: Epoch 59 
2025-01-11 06:20:03.822788: Current learning rate: 0.00785 
2025-01-11 06:20:42.448674: train_loss -0.6581 
2025-01-11 06:20:42.449675: val_loss -0.6663 
2025-01-11 06:20:42.455189: Pseudo dice [np.float32(0.9543), np.float32(0.818)] 
2025-01-11 06:20:42.457695: Epoch time: 38.63 s 
2025-01-11 06:20:42.461208: Yayy! New best EMA pseudo Dice: 0.8651000261306763 
2025-01-11 06:20:43.069468:  
2025-01-11 06:20:43.069971: Epoch 60 
2025-01-11 06:20:43.074984: Current learning rate: 0.00781 
2025-01-11 06:21:21.738331: train_loss -0.644 
2025-01-11 06:21:21.739335: val_loss -0.6337 
2025-01-11 06:21:21.745847: Pseudo dice [np.float32(0.9547), np.float32(0.7507)] 
2025-01-11 06:21:21.750472: Epoch time: 38.67 s 
2025-01-11 06:21:22.266464:  
2025-01-11 06:21:22.266965: Epoch 61 
2025-01-11 06:21:22.271976: Current learning rate: 0.00777 
2025-01-11 06:22:00.900219: train_loss -0.6643 
2025-01-11 06:22:00.901218: val_loss -0.6731 
2025-01-11 06:22:00.907742: Pseudo dice [np.float32(0.9575), np.float32(0.8166)] 
2025-01-11 06:22:00.911756: Epoch time: 38.63 s 
2025-01-11 06:22:00.915270: Yayy! New best EMA pseudo Dice: 0.8661999702453613 
2025-01-11 06:22:01.510143:  
2025-01-11 06:22:01.510143: Epoch 62 
2025-01-11 06:22:01.515077: Current learning rate: 0.00774 
2025-01-11 06:22:40.181737: train_loss -0.6135 
2025-01-11 06:22:40.182240: val_loss -0.632 
2025-01-11 06:22:40.187259: Pseudo dice [np.float32(0.9514), np.float32(0.7589)] 
2025-01-11 06:22:40.190773: Epoch time: 38.67 s 
2025-01-11 06:22:40.705492:  
2025-01-11 06:22:40.706492: Epoch 63 
2025-01-11 06:22:40.712105: Current learning rate: 0.0077 
2025-01-11 06:23:19.341043: train_loss -0.6111 
2025-01-11 06:23:19.341554: val_loss -0.675 
2025-01-11 06:23:19.347679: Pseudo dice [np.float32(0.9581), np.float32(0.7597)] 
2025-01-11 06:23:19.351748: Epoch time: 38.64 s 
2025-01-11 06:23:19.862225:  
2025-01-11 06:23:19.863231: Epoch 64 
2025-01-11 06:23:19.868834: Current learning rate: 0.00766 
2025-01-11 06:23:58.523253: train_loss -0.6554 
2025-01-11 06:23:58.523756: val_loss -0.5947 
2025-01-11 06:23:58.529883: Pseudo dice [np.float32(0.9556), np.float32(0.7131)] 
2025-01-11 06:23:58.533420: Epoch time: 38.66 s 
2025-01-11 06:23:59.052486:  
2025-01-11 06:23:59.052486: Epoch 65 
2025-01-11 06:23:59.058071: Current learning rate: 0.00763 
2025-01-11 06:24:37.695622: train_loss -0.6633 
2025-01-11 06:24:37.696426: val_loss -0.6315 
2025-01-11 06:24:37.702035: Pseudo dice [np.float32(0.9432), np.float32(0.7575)] 
2025-01-11 06:24:37.705541: Epoch time: 38.64 s 
2025-01-11 06:24:38.220700:  
2025-01-11 06:24:38.221704: Epoch 66 
2025-01-11 06:24:38.226736: Current learning rate: 0.00759 
2025-01-11 06:25:16.875433: train_loss -0.6838 
2025-01-11 06:25:16.875936: val_loss -0.6743 
2025-01-11 06:25:16.882056: Pseudo dice [np.float32(0.9643), np.float32(0.7573)] 
2025-01-11 06:25:16.885242: Epoch time: 38.65 s 
2025-01-11 06:25:17.557252:  
2025-01-11 06:25:17.557754: Epoch 67 
2025-01-11 06:25:17.562766: Current learning rate: 0.00755 
2025-01-11 06:25:56.207575: train_loss -0.6683 
2025-01-11 06:25:56.208576: val_loss -0.6501 
2025-01-11 06:25:56.216097: Pseudo dice [np.float32(0.9599), np.float32(0.7346)] 
2025-01-11 06:25:56.219613: Epoch time: 38.65 s 
2025-01-11 06:25:56.743129:  
2025-01-11 06:25:56.743129: Epoch 68 
2025-01-11 06:25:56.748690: Current learning rate: 0.00751 
2025-01-11 06:26:35.387921: train_loss -0.6519 
2025-01-11 06:26:35.388926: val_loss -0.6504 
2025-01-11 06:26:35.394531: Pseudo dice [np.float32(0.9543), np.float32(0.732)] 
2025-01-11 06:26:35.397569: Epoch time: 38.65 s 
2025-01-11 06:26:35.919161:  
2025-01-11 06:26:35.919161: Epoch 69 
2025-01-11 06:26:35.924191: Current learning rate: 0.00748 
2025-01-11 06:27:14.680282: train_loss -0.6478 
2025-01-11 06:27:14.681285: val_loss -0.7192 
2025-01-11 06:27:14.687805: Pseudo dice [np.float32(0.9538), np.float32(0.8253)] 
2025-01-11 06:27:14.692825: Epoch time: 38.76 s 
2025-01-11 06:27:15.224322:  
2025-01-11 06:27:15.224824: Epoch 70 
2025-01-11 06:27:15.229884: Current learning rate: 0.00744 
2025-01-11 06:27:53.872624: train_loss -0.6927 
2025-01-11 06:27:53.873132: val_loss -0.7022 
2025-01-11 06:27:53.878701: Pseudo dice [np.float32(0.9653), np.float32(0.7528)] 
2025-01-11 06:27:53.881772: Epoch time: 38.65 s 
2025-01-11 06:27:54.400864:  
2025-01-11 06:27:54.401865: Epoch 71 
2025-01-11 06:27:54.406936: Current learning rate: 0.0074 
2025-01-11 06:28:33.068659: train_loss -0.6722 
2025-01-11 06:28:33.069171: val_loss -0.702 
2025-01-11 06:28:33.075815: Pseudo dice [np.float32(0.957), np.float32(0.7799)] 
2025-01-11 06:28:33.079406: Epoch time: 38.67 s 
2025-01-11 06:28:33.597474:  
2025-01-11 06:28:33.597474: Epoch 72 
2025-01-11 06:28:33.603028: Current learning rate: 0.00737 
2025-01-11 06:29:12.264465: train_loss -0.6496 
2025-01-11 06:29:12.265188: val_loss -0.6997 
2025-01-11 06:29:12.270731: Pseudo dice [np.float32(0.961), np.float32(0.793)] 
2025-01-11 06:29:12.274244: Epoch time: 38.67 s 
2025-01-11 06:29:12.792623:  
2025-01-11 06:29:12.793124: Epoch 73 
2025-01-11 06:29:12.796634: Current learning rate: 0.00733 
2025-01-11 06:29:51.416659: train_loss -0.6755 
2025-01-11 06:29:51.417170: val_loss -0.6516 
2025-01-11 06:29:51.423224: Pseudo dice [np.float32(0.96), np.float32(0.7378)] 
2025-01-11 06:29:51.427802: Epoch time: 38.63 s 
2025-01-11 06:29:51.946491:  
2025-01-11 06:29:51.946491: Epoch 74 
2025-01-11 06:29:51.952541: Current learning rate: 0.00729 
2025-01-11 06:30:30.591008: train_loss -0.6915 
2025-01-11 06:30:30.592010: val_loss -0.637 
2025-01-11 06:30:30.597034: Pseudo dice [np.float32(0.9633), np.float32(0.7379)] 
2025-01-11 06:30:30.601048: Epoch time: 38.64 s 
2025-01-11 06:30:31.278682:  
2025-01-11 06:30:31.278682: Epoch 75 
2025-01-11 06:30:31.283695: Current learning rate: 0.00725 
2025-01-11 06:31:09.960573: train_loss -0.6786 
2025-01-11 06:31:09.961577: val_loss -0.6628 
2025-01-11 06:31:09.967221: Pseudo dice [np.float32(0.9573), np.float32(0.7249)] 
2025-01-11 06:31:09.972829: Epoch time: 38.68 s 
2025-01-11 06:31:10.498971:  
2025-01-11 06:31:10.500473: Epoch 76 
2025-01-11 06:31:10.505489: Current learning rate: 0.00722 
2025-01-11 06:31:49.181969: train_loss -0.6954 
2025-01-11 06:31:49.183472: val_loss -0.6969 
2025-01-11 06:31:49.188486: Pseudo dice [np.float32(0.9622), np.float32(0.7979)] 
2025-01-11 06:31:49.192495: Epoch time: 38.68 s 
2025-01-11 06:31:49.708218:  
2025-01-11 06:31:49.708218: Epoch 77 
2025-01-11 06:31:49.713797: Current learning rate: 0.00718 
2025-01-11 06:32:28.375050: train_loss -0.6726 
2025-01-11 06:32:28.376052: val_loss -0.6641 
2025-01-11 06:32:28.380763: Pseudo dice [np.float32(0.9554), np.float32(0.7755)] 
2025-01-11 06:32:28.384277: Epoch time: 38.67 s 
2025-01-11 06:32:28.917772:  
2025-01-11 06:32:28.918773: Epoch 78 
2025-01-11 06:32:28.925291: Current learning rate: 0.00714 
2025-01-11 06:33:07.572502: train_loss -0.7084 
2025-01-11 06:33:07.574007: val_loss -0.7286 
2025-01-11 06:33:07.579057: Pseudo dice [np.float32(0.964), np.float32(0.8004)] 
2025-01-11 06:33:07.583570: Epoch time: 38.65 s 
2025-01-11 06:33:08.118232:  
2025-01-11 06:33:08.118734: Epoch 79 
2025-01-11 06:33:08.123784: Current learning rate: 0.0071 
2025-01-11 06:33:46.753894: train_loss -0.7088 
2025-01-11 06:33:46.754398: val_loss -0.7059 
2025-01-11 06:33:46.759413: Pseudo dice [np.float32(0.9593), np.float32(0.8199)] 
2025-01-11 06:33:46.762923: Epoch time: 38.64 s 
2025-01-11 06:33:47.290207:  
2025-01-11 06:33:47.290207: Epoch 80 
2025-01-11 06:33:47.295726: Current learning rate: 0.00707 
2025-01-11 06:34:26.027732: train_loss -0.6729 
2025-01-11 06:34:26.027732: val_loss -0.6459 
2025-01-11 06:34:26.034766: Pseudo dice [np.float32(0.9544), np.float32(0.7866)] 
2025-01-11 06:34:26.039275: Epoch time: 38.74 s 
2025-01-11 06:34:26.042290: Yayy! New best EMA pseudo Dice: 0.8662999868392944 
2025-01-11 06:34:26.668244:  
2025-01-11 06:34:26.668746: Epoch 81 
2025-01-11 06:34:26.673760: Current learning rate: 0.00703 
2025-01-11 06:35:05.329856: train_loss -0.6567 
2025-01-11 06:35:05.330861: val_loss -0.7086 
2025-01-11 06:35:05.336911: Pseudo dice [np.float32(0.9505), np.float32(0.8154)] 
2025-01-11 06:35:05.342731: Epoch time: 38.66 s 
2025-01-11 06:35:05.346238: Yayy! New best EMA pseudo Dice: 0.8679999709129333 
2025-01-11 06:35:06.112511:  
2025-01-11 06:35:06.112511: Epoch 82 
2025-01-11 06:35:06.118061: Current learning rate: 0.00699 
2025-01-11 06:35:44.753466: train_loss -0.6376 
2025-01-11 06:35:44.754466: val_loss -0.7016 
2025-01-11 06:35:44.759991: Pseudo dice [np.float32(0.9575), np.float32(0.8086)] 
2025-01-11 06:35:44.763507: Epoch time: 38.64 s 
2025-01-11 06:35:44.766011: Yayy! New best EMA pseudo Dice: 0.8694999814033508 
2025-01-11 06:35:45.369623:  
2025-01-11 06:35:45.369623: Epoch 83 
2025-01-11 06:35:45.375802: Current learning rate: 0.00696 
2025-01-11 06:36:24.050840: train_loss -0.6766 
2025-01-11 06:36:24.051343: val_loss -0.7024 
2025-01-11 06:36:24.056884: Pseudo dice [np.float32(0.9543), np.float32(0.7866)] 
2025-01-11 06:36:24.060395: Epoch time: 38.68 s 
2025-01-11 06:36:24.062902: Yayy! New best EMA pseudo Dice: 0.8695999979972839 
2025-01-11 06:36:24.656068:  
2025-01-11 06:36:24.656571: Epoch 84 
2025-01-11 06:36:24.661585: Current learning rate: 0.00692 
2025-01-11 06:37:03.293237: train_loss -0.6925 
2025-01-11 06:37:03.294238: val_loss -0.7051 
2025-01-11 06:37:03.299762: Pseudo dice [np.float32(0.96), np.float32(0.8353)] 
2025-01-11 06:37:03.303280: Epoch time: 38.64 s 
2025-01-11 06:37:03.305790: Yayy! New best EMA pseudo Dice: 0.8723999857902527 
2025-01-11 06:37:03.901353:  
2025-01-11 06:37:03.901353: Epoch 85 
2025-01-11 06:37:03.906369: Current learning rate: 0.00688 
2025-01-11 06:37:42.546282: train_loss -0.6927 
2025-01-11 06:37:42.546282: val_loss -0.6647 
2025-01-11 06:37:42.552307: Pseudo dice [np.float32(0.9581), np.float32(0.7386)] 
2025-01-11 06:37:42.555816: Epoch time: 38.65 s 
2025-01-11 06:37:43.065500:  
2025-01-11 06:37:43.066002: Epoch 86 
2025-01-11 06:37:43.071076: Current learning rate: 0.00684 
2025-01-11 06:38:21.695829: train_loss -0.66 
2025-01-11 06:38:21.695829: val_loss -0.6195 
2025-01-11 06:38:21.702445: Pseudo dice [np.float32(0.9549), np.float32(0.7174)] 
2025-01-11 06:38:21.705504: Epoch time: 38.63 s 
2025-01-11 06:38:22.211065:  
2025-01-11 06:38:22.211567: Epoch 87 
2025-01-11 06:38:22.216686: Current learning rate: 0.0068 
2025-01-11 06:39:00.858498: train_loss -0.7071 
2025-01-11 06:39:00.859009: val_loss -0.6926 
2025-01-11 06:39:00.863574: Pseudo dice [np.float32(0.9666), np.float32(0.8112)] 
2025-01-11 06:39:00.866116: Epoch time: 38.65 s 
2025-01-11 06:39:01.372266:  
2025-01-11 06:39:01.372768: Epoch 88 
2025-01-11 06:39:01.377788: Current learning rate: 0.00677 
2025-01-11 06:39:40.033527: train_loss -0.6948 
2025-01-11 06:39:40.034531: val_loss -0.6998 
2025-01-11 06:39:40.040589: Pseudo dice [np.float32(0.9567), np.float32(0.8471)] 
2025-01-11 06:39:40.044612: Epoch time: 38.66 s 
2025-01-11 06:39:40.554118:  
2025-01-11 06:39:40.554118: Epoch 89 
2025-01-11 06:39:40.559127: Current learning rate: 0.00673 
2025-01-11 06:40:19.249534: train_loss -0.6892 
2025-01-11 06:40:19.249534: val_loss -0.7108 
2025-01-11 06:40:19.255481: Pseudo dice [np.float32(0.9602), np.float32(0.8309)] 
2025-01-11 06:40:19.258992: Epoch time: 38.69 s 
2025-01-11 06:40:19.261498: Yayy! New best EMA pseudo Dice: 0.8744999766349792 
2025-01-11 06:40:20.036486:  
2025-01-11 06:40:20.036989: Epoch 90 
2025-01-11 06:40:20.042000: Current learning rate: 0.00669 
2025-01-11 06:40:58.697875: train_loss -0.6939 
2025-01-11 06:40:58.697875: val_loss -0.6945 
2025-01-11 06:40:58.704993: Pseudo dice [np.float32(0.9632), np.float32(0.8242)] 
2025-01-11 06:40:58.708558: Epoch time: 38.66 s 
2025-01-11 06:40:58.712095: Yayy! New best EMA pseudo Dice: 0.8763999938964844 
2025-01-11 06:40:59.301242:  
2025-01-11 06:40:59.301745: Epoch 91 
2025-01-11 06:40:59.306758: Current learning rate: 0.00665 
2025-01-11 06:41:38.039796: train_loss -0.6862 
2025-01-11 06:41:38.039796: val_loss -0.6558 
2025-01-11 06:41:38.045956: Pseudo dice [np.float32(0.9596), np.float32(0.7634)] 
2025-01-11 06:41:38.050091: Epoch time: 38.74 s 
2025-01-11 06:41:38.554345:  
2025-01-11 06:41:38.554847: Epoch 92 
2025-01-11 06:41:38.559860: Current learning rate: 0.00662 
2025-01-11 06:42:17.215185: train_loss -0.7082 
2025-01-11 06:42:17.215698: val_loss -0.7131 
2025-01-11 06:42:17.222289: Pseudo dice [np.float32(0.9621), np.float32(0.8237)] 
2025-01-11 06:42:17.225867: Epoch time: 38.66 s 
2025-01-11 06:42:17.229391: Yayy! New best EMA pseudo Dice: 0.8766999840736389 
2025-01-11 06:42:17.824168:  
2025-01-11 06:42:17.825169: Epoch 93 
2025-01-11 06:42:17.830287: Current learning rate: 0.00658 
2025-01-11 06:42:56.460747: train_loss -0.7162 
2025-01-11 06:42:56.461254: val_loss -0.6736 
2025-01-11 06:42:56.467420: Pseudo dice [np.float32(0.9575), np.float32(0.7973)] 
2025-01-11 06:42:56.471576: Epoch time: 38.64 s 
2025-01-11 06:42:56.474674: Yayy! New best EMA pseudo Dice: 0.876800000667572 
2025-01-11 06:42:57.070711:  
2025-01-11 06:42:57.071714: Epoch 94 
2025-01-11 06:42:57.076278: Current learning rate: 0.00654 
2025-01-11 06:43:35.716598: train_loss -0.6843 
2025-01-11 06:43:35.716598: val_loss -0.7086 
2025-01-11 06:43:35.723217: Pseudo dice [np.float32(0.9587), np.float32(0.8328)] 
2025-01-11 06:43:35.726226: Epoch time: 38.65 s 
2025-01-11 06:43:35.729740: Yayy! New best EMA pseudo Dice: 0.8787000179290771 
2025-01-11 06:43:36.333632:  
2025-01-11 06:43:36.334632: Epoch 95 
2025-01-11 06:43:36.339718: Current learning rate: 0.0065 
2025-01-11 06:44:14.997685: train_loss -0.6994 
2025-01-11 06:44:14.998196: val_loss -0.7209 
2025-01-11 06:44:15.004365: Pseudo dice [np.float32(0.9607), np.float32(0.7928)] 
2025-01-11 06:44:15.007961: Epoch time: 38.66 s 
2025-01-11 06:44:15.513009:  
2025-01-11 06:44:15.513009: Epoch 96 
2025-01-11 06:44:15.518579: Current learning rate: 0.00647 
2025-01-11 06:44:54.177618: train_loss -0.68 
2025-01-11 06:44:54.178131: val_loss -0.731 
2025-01-11 06:44:54.184195: Pseudo dice [np.float32(0.9622), np.float32(0.8193)] 
2025-01-11 06:44:54.188219: Epoch time: 38.67 s 
2025-01-11 06:44:54.191756: Yayy! New best EMA pseudo Dice: 0.8797000050544739 
2025-01-11 06:44:54.791894:  
2025-01-11 06:44:54.792397: Epoch 97 
2025-01-11 06:44:54.797411: Current learning rate: 0.00643 
2025-01-11 06:45:33.432359: train_loss -0.7384 
2025-01-11 06:45:33.433363: val_loss -0.704 
2025-01-11 06:45:33.439881: Pseudo dice [np.float32(0.9629), np.float32(0.7677)] 
2025-01-11 06:45:33.443393: Epoch time: 38.64 s 
2025-01-11 06:45:34.111607:  
2025-01-11 06:45:34.111607: Epoch 98 
2025-01-11 06:45:34.117122: Current learning rate: 0.00639 
2025-01-11 06:46:12.775027: train_loss -0.701 
2025-01-11 06:46:12.775528: val_loss -0.7343 
2025-01-11 06:46:12.781548: Pseudo dice [np.float32(0.9642), np.float32(0.8186)] 
2025-01-11 06:46:12.785151: Epoch time: 38.66 s 
2025-01-11 06:46:13.297175:  
2025-01-11 06:46:13.298179: Epoch 99 
2025-01-11 06:46:13.303204: Current learning rate: 0.00635 
2025-01-11 06:46:51.936203: train_loss -0.6896 
2025-01-11 06:46:51.936203: val_loss -0.6702 
2025-01-11 06:46:51.942715: Pseudo dice [np.float32(0.9589), np.float32(0.7792)] 
2025-01-11 06:46:51.947729: Epoch time: 38.64 s 
2025-01-11 06:46:52.556676:  
2025-01-11 06:46:52.556676: Epoch 100 
2025-01-11 06:46:52.562244: Current learning rate: 0.00631 
2025-01-11 06:47:31.186656: train_loss -0.676 
2025-01-11 06:47:31.187099: val_loss -0.6858 
2025-01-11 06:47:31.194145: Pseudo dice [np.float32(0.9577), np.float32(0.8228)] 
2025-01-11 06:47:31.197659: Epoch time: 38.63 s 
2025-01-11 06:47:31.715713:  
2025-01-11 06:47:31.715713: Epoch 101 
2025-01-11 06:47:31.721731: Current learning rate: 0.00628 
2025-01-11 06:48:10.370122: train_loss -0.7087 
2025-01-11 06:48:10.371137: val_loss -0.668 
2025-01-11 06:48:10.376225: Pseudo dice [np.float32(0.9573), np.float32(0.7642)] 
2025-01-11 06:48:10.382287: Epoch time: 38.65 s 
2025-01-11 06:48:10.890468:  
2025-01-11 06:48:10.890969: Epoch 102 
2025-01-11 06:48:10.895984: Current learning rate: 0.00624 
2025-01-11 06:48:49.630925: train_loss -0.6979 
2025-01-11 06:48:49.630925: val_loss -0.6899 
2025-01-11 06:48:49.637592: Pseudo dice [np.float32(0.9536), np.float32(0.8056)] 
2025-01-11 06:48:49.640687: Epoch time: 38.74 s 
2025-01-11 06:48:50.156030:  
2025-01-11 06:48:50.156534: Epoch 103 
2025-01-11 06:48:50.161548: Current learning rate: 0.0062 
2025-01-11 06:49:28.788587: train_loss -0.7083 
2025-01-11 06:49:28.789098: val_loss -0.7074 
2025-01-11 06:49:28.795722: Pseudo dice [np.float32(0.9627), np.float32(0.8035)] 
2025-01-11 06:49:28.798861: Epoch time: 38.63 s 
2025-01-11 06:49:29.308529:  
2025-01-11 06:49:29.309039: Epoch 104 
2025-01-11 06:49:29.314109: Current learning rate: 0.00616 
2025-01-11 06:50:07.969930: train_loss -0.6893 
2025-01-11 06:50:07.969930: val_loss -0.7099 
2025-01-11 06:50:07.976904: Pseudo dice [np.float32(0.9651), np.float32(0.7785)] 
2025-01-11 06:50:07.979419: Epoch time: 38.66 s 
2025-01-11 06:50:08.490582:  
2025-01-11 06:50:08.490582: Epoch 105 
2025-01-11 06:50:08.496679: Current learning rate: 0.00612 
2025-01-11 06:50:47.130931: train_loss -0.7122 
2025-01-11 06:50:47.130931: val_loss -0.6686 
2025-01-11 06:50:47.136955: Pseudo dice [np.float32(0.959), np.float32(0.7247)] 
2025-01-11 06:50:47.141985: Epoch time: 38.64 s 
2025-01-11 06:50:47.809493:  
2025-01-11 06:50:47.809493: Epoch 106 
2025-01-11 06:50:47.815013: Current learning rate: 0.00609 
2025-01-11 06:51:26.483338: train_loss -0.7024 
2025-01-11 06:51:26.483840: val_loss -0.7484 
2025-01-11 06:51:26.489861: Pseudo dice [np.float32(0.9608), np.float32(0.8151)] 
2025-01-11 06:51:26.492371: Epoch time: 38.67 s 
2025-01-11 06:51:27.006344:  
2025-01-11 06:51:27.006344: Epoch 107 
2025-01-11 06:51:27.011876: Current learning rate: 0.00605 
2025-01-11 06:52:05.631382: train_loss -0.7189 
2025-01-11 06:52:05.631382: val_loss -0.6989 
2025-01-11 06:52:05.638167: Pseudo dice [np.float32(0.9609), np.float32(0.821)] 
2025-01-11 06:52:05.641755: Epoch time: 38.63 s 
2025-01-11 06:52:06.155454:  
2025-01-11 06:52:06.155454: Epoch 108 
2025-01-11 06:52:06.161557: Current learning rate: 0.00601 
2025-01-11 06:52:44.808085: train_loss -0.7212 
2025-01-11 06:52:44.808589: val_loss -0.7249 
2025-01-11 06:52:44.815171: Pseudo dice [np.float32(0.9642), np.float32(0.8045)] 
2025-01-11 06:52:44.818188: Epoch time: 38.65 s 
2025-01-11 06:52:45.340306:  
2025-01-11 06:52:45.340306: Epoch 109 
2025-01-11 06:52:45.345835: Current learning rate: 0.00597 
2025-01-11 06:53:23.941355: train_loss -0.7071 
2025-01-11 06:53:23.942362: val_loss -0.7354 
2025-01-11 06:53:23.947821: Pseudo dice [np.float32(0.9641), np.float32(0.8235)] 
2025-01-11 06:53:23.951338: Epoch time: 38.6 s 
2025-01-11 06:53:24.465044:  
2025-01-11 06:53:24.466044: Epoch 110 
2025-01-11 06:53:24.471560: Current learning rate: 0.00593 
2025-01-11 06:54:03.096723: train_loss -0.7157 
2025-01-11 06:54:03.096723: val_loss -0.7163 
2025-01-11 06:54:03.103744: Pseudo dice [np.float32(0.9644), np.float32(0.7761)] 
2025-01-11 06:54:03.108760: Epoch time: 38.63 s 
2025-01-11 06:54:03.624359:  
2025-01-11 06:54:03.624359: Epoch 111 
2025-01-11 06:54:03.629907: Current learning rate: 0.0059 
2025-01-11 06:54:42.260012: train_loss -0.7083 
2025-01-11 06:54:42.261016: val_loss -0.6912 
2025-01-11 06:54:42.266661: Pseudo dice [np.float32(0.9546), np.float32(0.8145)] 
2025-01-11 06:54:42.272677: Epoch time: 38.64 s 
2025-01-11 06:54:42.792274:  
2025-01-11 06:54:42.792775: Epoch 112 
2025-01-11 06:54:42.797333: Current learning rate: 0.00586 
2025-01-11 06:55:21.545827: train_loss -0.7233 
2025-01-11 06:55:21.546861: val_loss -0.7036 
2025-01-11 06:55:21.552444: Pseudo dice [np.float32(0.9581), np.float32(0.7842)] 
2025-01-11 06:55:21.555629: Epoch time: 38.75 s 
2025-01-11 06:55:22.063764:  
2025-01-11 06:55:22.064766: Epoch 113 
2025-01-11 06:55:22.069912: Current learning rate: 0.00582 
2025-01-11 06:56:00.698065: train_loss -0.7276 
2025-01-11 06:56:00.699070: val_loss -0.6781 
2025-01-11 06:56:00.705232: Pseudo dice [np.float32(0.9544), np.float32(0.8041)] 
2025-01-11 06:56:00.708757: Epoch time: 38.63 s 
2025-01-11 06:56:01.371466:  
2025-01-11 06:56:01.372471: Epoch 114 
2025-01-11 06:56:01.377046: Current learning rate: 0.00578 
2025-01-11 06:56:39.997926: train_loss -0.7109 
2025-01-11 06:56:39.997926: val_loss -0.731 
2025-01-11 06:56:40.005448: Pseudo dice [np.float32(0.9573), np.float32(0.7975)] 
2025-01-11 06:56:40.010461: Epoch time: 38.63 s 
2025-01-11 06:56:40.522243:  
2025-01-11 06:56:40.523243: Epoch 115 
2025-01-11 06:56:40.527820: Current learning rate: 0.00574 
2025-01-11 06:57:19.199660: train_loss -0.7135 
2025-01-11 06:57:19.199660: val_loss -0.7272 
2025-01-11 06:57:19.205686: Pseudo dice [np.float32(0.9632), np.float32(0.8023)] 
2025-01-11 06:57:19.210704: Epoch time: 38.68 s 
2025-01-11 06:57:19.729416:  
2025-01-11 06:57:19.729416: Epoch 116 
2025-01-11 06:57:19.734436: Current learning rate: 0.0057 
2025-01-11 06:57:58.369932: train_loss -0.6965 
2025-01-11 06:57:58.369932: val_loss -0.6907 
2025-01-11 06:57:58.376951: Pseudo dice [np.float32(0.9646), np.float32(0.8284)] 
2025-01-11 06:57:58.379959: Epoch time: 38.64 s 
2025-01-11 06:57:58.383469: Yayy! New best EMA pseudo Dice: 0.8805000185966492 
2025-01-11 06:57:58.992251:  
2025-01-11 06:57:58.992817: Epoch 117 
2025-01-11 06:57:58.999465: Current learning rate: 0.00567 
2025-01-11 06:58:37.632678: train_loss -0.7033 
2025-01-11 06:58:37.632678: val_loss -0.7229 
2025-01-11 06:58:37.639800: Pseudo dice [np.float32(0.9593), np.float32(0.8296)] 
2025-01-11 06:58:37.642439: Epoch time: 38.64 s 
2025-01-11 06:58:37.646316: Yayy! New best EMA pseudo Dice: 0.8819000124931335 
2025-01-11 06:58:38.251965:  
2025-01-11 06:58:38.251965: Epoch 118 
2025-01-11 06:58:38.257483: Current learning rate: 0.00563 
2025-01-11 06:59:16.916076: train_loss -0.7235 
2025-01-11 06:59:16.916593: val_loss -0.7164 
2025-01-11 06:59:16.922204: Pseudo dice [np.float32(0.9618), np.float32(0.8221)] 
2025-01-11 06:59:16.925806: Epoch time: 38.66 s 
2025-01-11 06:59:16.928870: Yayy! New best EMA pseudo Dice: 0.8828999996185303 
2025-01-11 06:59:17.534986:  
2025-01-11 06:59:17.534986: Epoch 119 
2025-01-11 06:59:17.541054: Current learning rate: 0.00559 
2025-01-11 06:59:56.189324: train_loss -0.7347 
2025-01-11 06:59:56.190331: val_loss -0.7164 
2025-01-11 06:59:56.196484: Pseudo dice [np.float32(0.965), np.float32(0.7896)] 
2025-01-11 06:59:56.200533: Epoch time: 38.65 s 
2025-01-11 06:59:56.712343:  
2025-01-11 06:59:56.712845: Epoch 120 
2025-01-11 06:59:56.717877: Current learning rate: 0.00555 
2025-01-11 07:00:35.333934: train_loss -0.7387 
2025-01-11 07:00:35.335438: val_loss -0.7272 
2025-01-11 07:00:35.342959: Pseudo dice [np.float32(0.9675), np.float32(0.7814)] 
2025-01-11 07:00:35.347974: Epoch time: 38.62 s 
2025-01-11 07:00:35.864313:  
2025-01-11 07:00:35.864816: Epoch 121 
2025-01-11 07:00:35.869828: Current learning rate: 0.00551 
2025-01-11 07:01:14.491210: train_loss -0.7258 
2025-01-11 07:01:14.492212: val_loss -0.6752 
2025-01-11 07:01:14.497231: Pseudo dice [np.float32(0.9599), np.float32(0.7989)] 
2025-01-11 07:01:14.503245: Epoch time: 38.63 s 
2025-01-11 07:01:15.175686:  
2025-01-11 07:01:15.176691: Epoch 122 
2025-01-11 07:01:15.181720: Current learning rate: 0.00547 
2025-01-11 07:01:53.825726: train_loss -0.7455 
2025-01-11 07:01:53.825726: val_loss -0.7224 
2025-01-11 07:01:53.831747: Pseudo dice [np.float32(0.965), np.float32(0.8194)] 
2025-01-11 07:01:53.837762: Epoch time: 38.65 s 
2025-01-11 07:01:54.350409:  
2025-01-11 07:01:54.350409: Epoch 123 
2025-01-11 07:01:54.355962: Current learning rate: 0.00544 
2025-01-11 07:02:33.157014: train_loss -0.7273 
2025-01-11 07:02:33.157534: val_loss -0.6902 
2025-01-11 07:02:33.162090: Pseudo dice [np.float32(0.963), np.float32(0.7735)] 
2025-01-11 07:02:33.165179: Epoch time: 38.81 s 
2025-01-11 07:02:33.687325:  
2025-01-11 07:02:33.687832: Epoch 124 
2025-01-11 07:02:33.693858: Current learning rate: 0.0054 
2025-01-11 07:03:12.338754: train_loss -0.7401 
2025-01-11 07:03:12.338754: val_loss -0.6428 
2025-01-11 07:03:12.345279: Pseudo dice [np.float32(0.9606), np.float32(0.7734)] 
2025-01-11 07:03:12.347793: Epoch time: 38.65 s 
2025-01-11 07:03:12.860269:  
2025-01-11 07:03:12.861269: Epoch 125 
2025-01-11 07:03:12.866871: Current learning rate: 0.00536 
2025-01-11 07:03:51.492631: train_loss -0.7114 
2025-01-11 07:03:51.493638: val_loss -0.7327 
2025-01-11 07:03:51.498653: Pseudo dice [np.float32(0.9602), np.float32(0.8301)] 
2025-01-11 07:03:51.502666: Epoch time: 38.63 s 
2025-01-11 07:03:52.018220:  
2025-01-11 07:03:52.018220: Epoch 126 
2025-01-11 07:03:52.023233: Current learning rate: 0.00532 
2025-01-11 07:04:30.650963: train_loss -0.7459 
2025-01-11 07:04:30.651467: val_loss -0.7319 
2025-01-11 07:04:30.657488: Pseudo dice [np.float32(0.9609), np.float32(0.827)] 
2025-01-11 07:04:30.661500: Epoch time: 38.63 s 
2025-01-11 07:04:31.175849:  
2025-01-11 07:04:31.175849: Epoch 127 
2025-01-11 07:04:31.180859: Current learning rate: 0.00528 
2025-01-11 07:05:09.774802: train_loss -0.722 
2025-01-11 07:05:09.774802: val_loss -0.6896 
2025-01-11 07:05:09.780812: Pseudo dice [np.float32(0.9549), np.float32(0.7612)] 
2025-01-11 07:05:09.783821: Epoch time: 38.6 s 
2025-01-11 07:05:10.296263:  
2025-01-11 07:05:10.296263: Epoch 128 
2025-01-11 07:05:10.301279: Current learning rate: 0.00524 
2025-01-11 07:05:48.941371: train_loss -0.7195 
2025-01-11 07:05:48.942116: val_loss -0.6706 
2025-01-11 07:05:48.947673: Pseudo dice [np.float32(0.9623), np.float32(0.7776)] 
2025-01-11 07:05:48.950180: Epoch time: 38.65 s 
2025-01-11 07:05:49.470098:  
2025-01-11 07:05:49.470098: Epoch 129 
2025-01-11 07:05:49.475118: Current learning rate: 0.0052 
2025-01-11 07:06:28.095653: train_loss -0.734 
2025-01-11 07:06:28.096657: val_loss -0.6982 
2025-01-11 07:06:28.102703: Pseudo dice [np.float32(0.9652), np.float32(0.7854)] 
2025-01-11 07:06:28.106297: Epoch time: 38.63 s 
2025-01-11 07:06:28.781881:  
2025-01-11 07:06:28.782882: Epoch 130 
2025-01-11 07:06:28.785925: Current learning rate: 0.00517 
2025-01-11 07:07:07.393960: train_loss -0.755 
2025-01-11 07:07:07.394963: val_loss -0.6788 
2025-01-11 07:07:07.401026: Pseudo dice [np.float32(0.966), np.float32(0.7798)] 
2025-01-11 07:07:07.404556: Epoch time: 38.61 s 
2025-01-11 07:07:07.921559:  
2025-01-11 07:07:07.921559: Epoch 131 
2025-01-11 07:07:07.927133: Current learning rate: 0.00513 
2025-01-11 07:07:46.550886: train_loss -0.7166 
2025-01-11 07:07:46.550886: val_loss -0.6854 
2025-01-11 07:07:46.558589: Pseudo dice [np.float32(0.9552), np.float32(0.759)] 
2025-01-11 07:07:46.562734: Epoch time: 38.63 s 
2025-01-11 07:07:47.082907:  
2025-01-11 07:07:47.084411: Epoch 132 
2025-01-11 07:07:47.089427: Current learning rate: 0.00509 
2025-01-11 07:08:25.716976: train_loss -0.7288 
2025-01-11 07:08:25.717980: val_loss -0.6728 
2025-01-11 07:08:25.722988: Pseudo dice [np.float32(0.9601), np.float32(0.7327)] 
2025-01-11 07:08:25.726998: Epoch time: 38.63 s 
2025-01-11 07:08:26.237819:  
2025-01-11 07:08:26.237819: Epoch 133 
2025-01-11 07:08:26.242865: Current learning rate: 0.00505 
2025-01-11 07:09:05.004525: train_loss -0.7278 
2025-01-11 07:09:05.005532: val_loss -0.6902 
2025-01-11 07:09:05.012057: Pseudo dice [np.float32(0.9639), np.float32(0.794)] 
2025-01-11 07:09:05.016647: Epoch time: 38.77 s 
2025-01-11 07:09:05.530403:  
2025-01-11 07:09:05.530403: Epoch 134 
2025-01-11 07:09:05.535987: Current learning rate: 0.00501 
2025-01-11 07:09:44.184395: train_loss -0.7146 
2025-01-11 07:09:44.184898: val_loss -0.7176 
2025-01-11 07:09:44.190917: Pseudo dice [np.float32(0.9579), np.float32(0.8112)] 
2025-01-11 07:09:44.194924: Epoch time: 38.65 s 
2025-01-11 07:09:44.719128:  
2025-01-11 07:09:44.719632: Epoch 135 
2025-01-11 07:09:44.724641: Current learning rate: 0.00497 
2025-01-11 07:10:23.375800: train_loss -0.7281 
2025-01-11 07:10:23.376802: val_loss -0.6493 
2025-01-11 07:10:23.383427: Pseudo dice [np.float32(0.9533), np.float32(0.6794)] 
2025-01-11 07:10:23.387446: Epoch time: 38.66 s 
2025-01-11 07:10:23.905389:  
2025-01-11 07:10:23.906394: Epoch 136 
2025-01-11 07:10:23.911436: Current learning rate: 0.00493 
2025-01-11 07:11:02.523453: train_loss -0.7388 
2025-01-11 07:11:02.523974: val_loss -0.7122 
2025-01-11 07:11:02.530535: Pseudo dice [np.float32(0.9581), np.float32(0.7917)] 
2025-01-11 07:11:02.536601: Epoch time: 38.62 s 
2025-01-11 07:11:03.208351:  
2025-01-11 07:11:03.208856: Epoch 137 
2025-01-11 07:11:03.213871: Current learning rate: 0.00489 
2025-01-11 07:11:41.877988: train_loss -0.7502 
2025-01-11 07:11:41.878988: val_loss -0.7518 
2025-01-11 07:11:41.884514: Pseudo dice [np.float32(0.9685), np.float32(0.8182)] 
2025-01-11 07:11:41.888031: Epoch time: 38.67 s 
2025-01-11 07:11:42.412978:  
2025-01-11 07:11:42.413485: Epoch 138 
2025-01-11 07:11:42.418055: Current learning rate: 0.00485 
2025-01-11 07:12:21.071837: train_loss -0.7594 
2025-01-11 07:12:21.072339: val_loss -0.7255 
2025-01-11 07:12:21.077361: Pseudo dice [np.float32(0.9629), np.float32(0.8346)] 
2025-01-11 07:12:21.080880: Epoch time: 38.66 s 
2025-01-11 07:12:21.602169:  
2025-01-11 07:12:21.602671: Epoch 139 
2025-01-11 07:12:21.607688: Current learning rate: 0.00482 
2025-01-11 07:13:00.295915: train_loss -0.7399 
2025-01-11 07:13:00.296917: val_loss -0.7341 
2025-01-11 07:13:00.302941: Pseudo dice [np.float32(0.9671), np.float32(0.8171)] 
2025-01-11 07:13:00.305954: Epoch time: 38.69 s 
2025-01-11 07:13:00.826488:  
2025-01-11 07:13:00.826488: Epoch 140 
2025-01-11 07:13:00.831510: Current learning rate: 0.00478 
2025-01-11 07:13:39.455204: train_loss -0.7553 
2025-01-11 07:13:39.456208: val_loss -0.6944 
2025-01-11 07:13:39.462721: Pseudo dice [np.float32(0.9621), np.float32(0.7802)] 
2025-01-11 07:13:39.466233: Epoch time: 38.63 s 
2025-01-11 07:13:39.989601:  
2025-01-11 07:13:39.989601: Epoch 141 
2025-01-11 07:13:39.995942: Current learning rate: 0.00474 
2025-01-11 07:14:18.615228: train_loss -0.7588 
2025-01-11 07:14:18.616231: val_loss -0.716 
2025-01-11 07:14:18.621252: Pseudo dice [np.float32(0.9635), np.float32(0.8091)] 
2025-01-11 07:14:18.624761: Epoch time: 38.63 s 
2025-01-11 07:14:19.151103:  
2025-01-11 07:14:19.152107: Epoch 142 
2025-01-11 07:14:19.157139: Current learning rate: 0.0047 
2025-01-11 07:14:57.782403: train_loss -0.7608 
2025-01-11 07:14:57.783908: val_loss -0.729 
2025-01-11 07:14:57.789926: Pseudo dice [np.float32(0.9655), np.float32(0.7988)] 
2025-01-11 07:14:57.793938: Epoch time: 38.63 s 
2025-01-11 07:14:58.318707:  
2025-01-11 07:14:58.319209: Epoch 143 
2025-01-11 07:14:58.322231: Current learning rate: 0.00466 
2025-01-11 07:15:37.198879: train_loss -0.7589 
2025-01-11 07:15:37.199384: val_loss -0.7464 
2025-01-11 07:15:37.211925: Pseudo dice [np.float32(0.9697), np.float32(0.8287)] 
2025-01-11 07:15:37.216438: Epoch time: 38.88 s 
2025-01-11 07:15:37.745030:  
2025-01-11 07:15:37.746032: Epoch 144 
2025-01-11 07:15:37.751694: Current learning rate: 0.00462 
2025-01-11 07:16:16.492825: train_loss -0.7721 
2025-01-11 07:16:16.493341: val_loss -0.7411 
2025-01-11 07:16:16.499451: Pseudo dice [np.float32(0.9642), np.float32(0.8383)] 
2025-01-11 07:16:16.502985: Epoch time: 38.75 s 
2025-01-11 07:16:17.183132:  
2025-01-11 07:16:17.183132: Epoch 145 
2025-01-11 07:16:17.189187: Current learning rate: 0.00458 
2025-01-11 07:16:55.799640: train_loss -0.757 
2025-01-11 07:16:55.800654: val_loss -0.726 
2025-01-11 07:16:55.806764: Pseudo dice [np.float32(0.9665), np.float32(0.8603)] 
2025-01-11 07:16:55.810851: Epoch time: 38.62 s 
2025-01-11 07:16:55.814970: Yayy! New best EMA pseudo Dice: 0.8848999738693237 
2025-01-11 07:16:56.431697:  
2025-01-11 07:16:56.432199: Epoch 146 
2025-01-11 07:16:56.437209: Current learning rate: 0.00454 
2025-01-11 07:17:35.104237: train_loss -0.741 
2025-01-11 07:17:35.105241: val_loss -0.7495 
2025-01-11 07:17:35.112400: Pseudo dice [np.float32(0.967), np.float32(0.8395)] 
2025-01-11 07:17:35.116421: Epoch time: 38.67 s 
2025-01-11 07:17:35.118938: Yayy! New best EMA pseudo Dice: 0.8866999745368958 
2025-01-11 07:17:35.744246:  
2025-01-11 07:17:35.744749: Epoch 147 
2025-01-11 07:17:35.749366: Current learning rate: 0.0045 
2025-01-11 07:18:14.408775: train_loss -0.7596 
2025-01-11 07:18:14.409285: val_loss -0.7229 
2025-01-11 07:18:14.415911: Pseudo dice [np.float32(0.9632), np.float32(0.8008)] 
2025-01-11 07:18:14.419996: Epoch time: 38.67 s 
2025-01-11 07:18:14.947695:  
2025-01-11 07:18:14.948197: Epoch 148 
2025-01-11 07:18:14.953211: Current learning rate: 0.00446 
2025-01-11 07:18:53.579428: train_loss -0.7575 
2025-01-11 07:18:53.579428: val_loss -0.7266 
2025-01-11 07:18:53.586639: Pseudo dice [np.float32(0.9632), np.float32(0.8401)] 
2025-01-11 07:18:53.589678: Epoch time: 38.63 s 
2025-01-11 07:18:53.593192: Yayy! New best EMA pseudo Dice: 0.8877999782562256 
2025-01-11 07:18:54.205166:  
2025-01-11 07:18:54.205166: Epoch 149 
2025-01-11 07:18:54.210724: Current learning rate: 0.00442 
2025-01-11 07:19:32.837112: train_loss -0.7547 
2025-01-11 07:19:32.838115: val_loss -0.7601 
2025-01-11 07:19:32.844702: Pseudo dice [np.float32(0.9613), np.float32(0.8401)] 
2025-01-11 07:19:32.848308: Epoch time: 38.63 s 
2025-01-11 07:19:32.930330: Yayy! New best EMA pseudo Dice: 0.8891000151634216 
2025-01-11 07:19:33.540537:  
2025-01-11 07:19:33.540537: Epoch 150 
2025-01-11 07:19:33.546554: Current learning rate: 0.00438 
2025-01-11 07:20:12.187002: train_loss -0.7519 
2025-01-11 07:20:12.187002: val_loss -0.7465 
2025-01-11 07:20:12.193520: Pseudo dice [np.float32(0.9627), np.float32(0.8278)] 
2025-01-11 07:20:12.197032: Epoch time: 38.65 s 
2025-01-11 07:20:12.201093: Yayy! New best EMA pseudo Dice: 0.8896999955177307 
2025-01-11 07:20:12.818938:  
2025-01-11 07:20:12.818938: Epoch 151 
2025-01-11 07:20:12.824460: Current learning rate: 0.00434 
2025-01-11 07:20:51.499371: train_loss -0.7577 
2025-01-11 07:20:51.499371: val_loss -0.7312 
2025-01-11 07:20:51.505893: Pseudo dice [np.float32(0.961), np.float32(0.8315)] 
2025-01-11 07:20:51.509410: Epoch time: 38.68 s 
2025-01-11 07:20:51.512919: Yayy! New best EMA pseudo Dice: 0.8902999758720398 
2025-01-11 07:20:52.127078:  
2025-01-11 07:20:52.127582: Epoch 152 
2025-01-11 07:20:52.132622: Current learning rate: 0.0043 
2025-01-11 07:21:30.785489: train_loss -0.7596 
2025-01-11 07:21:30.785992: val_loss -0.7332 
2025-01-11 07:21:30.792007: Pseudo dice [np.float32(0.9682), np.float32(0.8188)] 
2025-01-11 07:21:30.796013: Epoch time: 38.66 s 
2025-01-11 07:21:30.799044: Yayy! New best EMA pseudo Dice: 0.8906999826431274 
2025-01-11 07:21:31.566099:  
2025-01-11 07:21:31.566605: Epoch 153 
2025-01-11 07:21:31.571661: Current learning rate: 0.00427 
2025-01-11 07:22:10.219050: train_loss -0.7541 
2025-01-11 07:22:10.219050: val_loss -0.7456 
2025-01-11 07:22:10.226581: Pseudo dice [np.float32(0.9658), np.float32(0.8273)] 
2025-01-11 07:22:10.231603: Epoch time: 38.65 s 
2025-01-11 07:22:10.236624: Yayy! New best EMA pseudo Dice: 0.8913000226020813 
2025-01-11 07:22:10.860254:  
2025-01-11 07:22:10.860756: Epoch 154 
2025-01-11 07:22:10.865775: Current learning rate: 0.00423 
2025-01-11 07:22:49.597046: train_loss -0.7666 
2025-01-11 07:22:49.598068: val_loss -0.7404 
2025-01-11 07:22:49.604123: Pseudo dice [np.float32(0.9674), np.float32(0.8538)] 
2025-01-11 07:22:49.608792: Epoch time: 38.74 s 
2025-01-11 07:22:49.612429: Yayy! New best EMA pseudo Dice: 0.8931999802589417 
2025-01-11 07:22:50.236321:  
2025-01-11 07:22:50.236321: Epoch 155 
2025-01-11 07:22:50.242862: Current learning rate: 0.00419 
2025-01-11 07:23:28.879868: train_loss -0.7699 
2025-01-11 07:23:28.880871: val_loss -0.7175 
2025-01-11 07:23:28.885988: Pseudo dice [np.float32(0.9634), np.float32(0.7928)] 
2025-01-11 07:23:28.889744: Epoch time: 38.64 s 
2025-01-11 07:23:29.425645:  
2025-01-11 07:23:29.425645: Epoch 156 
2025-01-11 07:23:29.431235: Current learning rate: 0.00415 
2025-01-11 07:24:08.053317: train_loss -0.7536 
2025-01-11 07:24:08.053831: val_loss -0.749 
2025-01-11 07:24:08.059369: Pseudo dice [np.float32(0.9657), np.float32(0.8636)] 
2025-01-11 07:24:08.063380: Epoch time: 38.63 s 
2025-01-11 07:24:08.066892: Yayy! New best EMA pseudo Dice: 0.8939999938011169 
2025-01-11 07:24:08.692743:  
2025-01-11 07:24:08.693746: Epoch 157 
2025-01-11 07:24:08.698323: Current learning rate: 0.00411 
2025-01-11 07:24:47.305512: train_loss -0.7657 
2025-01-11 07:24:47.305512: val_loss -0.6654 
2025-01-11 07:24:47.312065: Pseudo dice [np.float32(0.9693), np.float32(0.7761)] 
2025-01-11 07:24:47.315221: Epoch time: 38.61 s 
2025-01-11 07:24:47.851662:  
2025-01-11 07:24:47.852665: Epoch 158 
2025-01-11 07:24:47.857795: Current learning rate: 0.00407 
2025-01-11 07:25:26.487221: train_loss -0.7421 
2025-01-11 07:25:26.487221: val_loss -0.7281 
2025-01-11 07:25:26.493243: Pseudo dice [np.float32(0.9603), np.float32(0.8228)] 
2025-01-11 07:25:26.496755: Epoch time: 38.64 s 
2025-01-11 07:25:27.032413:  
2025-01-11 07:25:27.033413: Epoch 159 
2025-01-11 07:25:27.038537: Current learning rate: 0.00403 
2025-01-11 07:26:05.687301: train_loss -0.7675 
2025-01-11 07:26:05.687301: val_loss -0.7098 
2025-01-11 07:26:05.693825: Pseudo dice [np.float32(0.9591), np.float32(0.8439)] 
2025-01-11 07:26:05.698338: Epoch time: 38.65 s 
2025-01-11 07:26:06.389936:  
2025-01-11 07:26:06.389936: Epoch 160 
2025-01-11 07:26:06.395487: Current learning rate: 0.00399 
2025-01-11 07:26:45.015574: train_loss -0.7572 
2025-01-11 07:26:45.015574: val_loss -0.7137 
2025-01-11 07:26:45.022717: Pseudo dice [np.float32(0.9661), np.float32(0.7579)] 
2025-01-11 07:26:45.028298: Epoch time: 38.63 s 
2025-01-11 07:26:45.560007:  
2025-01-11 07:26:45.560007: Epoch 161 
2025-01-11 07:26:45.566103: Current learning rate: 0.00395 
2025-01-11 07:27:24.234026: train_loss -0.7763 
2025-01-11 07:27:24.234026: val_loss -0.7183 
2025-01-11 07:27:24.240282: Pseudo dice [np.float32(0.9641), np.float32(0.7917)] 
2025-01-11 07:27:24.243829: Epoch time: 38.67 s 
2025-01-11 07:27:24.778880:  
2025-01-11 07:27:24.778880: Epoch 162 
2025-01-11 07:27:24.783946: Current learning rate: 0.00391 
2025-01-11 07:28:03.400792: train_loss -0.746 
2025-01-11 07:28:03.401297: val_loss -0.718 
2025-01-11 07:28:03.407317: Pseudo dice [np.float32(0.9627), np.float32(0.7966)] 
2025-01-11 07:28:03.412333: Epoch time: 38.62 s 
2025-01-11 07:28:03.949625:  
2025-01-11 07:28:03.950127: Epoch 163 
2025-01-11 07:28:03.955140: Current learning rate: 0.00387 
2025-01-11 07:28:42.597397: train_loss -0.7505 
2025-01-11 07:28:42.597921: val_loss -0.7418 
2025-01-11 07:28:42.603543: Pseudo dice [np.float32(0.9573), np.float32(0.8331)] 
2025-01-11 07:28:42.607099: Epoch time: 38.65 s 
2025-01-11 07:28:43.136019:  
2025-01-11 07:28:43.136019: Epoch 164 
2025-01-11 07:28:43.141075: Current learning rate: 0.00383 
2025-01-11 07:29:21.753675: train_loss -0.7555 
2025-01-11 07:29:21.754179: val_loss -0.6767 
2025-01-11 07:29:21.759812: Pseudo dice [np.float32(0.9624), np.float32(0.7676)] 
2025-01-11 07:29:21.763357: Epoch time: 38.62 s 
2025-01-11 07:29:22.285791:  
2025-01-11 07:29:22.286796: Epoch 165 
2025-01-11 07:29:22.290329: Current learning rate: 0.00379 
2025-01-11 07:30:01.015126: train_loss -0.7457 
2025-01-11 07:30:01.015126: val_loss -0.7151 
2025-01-11 07:30:01.022758: Pseudo dice [np.float32(0.9614), np.float32(0.7903)] 
2025-01-11 07:30:01.027773: Epoch time: 38.73 s 
2025-01-11 07:30:01.550448:  
2025-01-11 07:30:01.550448: Epoch 166 
2025-01-11 07:30:01.555467: Current learning rate: 0.00375 
2025-01-11 07:30:40.180334: train_loss -0.7406 
2025-01-11 07:30:40.181840: val_loss -0.7486 
2025-01-11 07:30:40.188021: Pseudo dice [np.float32(0.9678), np.float32(0.8324)] 
2025-01-11 07:30:40.194574: Epoch time: 38.63 s 
2025-01-11 07:30:40.713830:  
2025-01-11 07:30:40.713830: Epoch 167 
2025-01-11 07:30:40.719406: Current learning rate: 0.00371 
2025-01-11 07:31:19.376234: train_loss -0.7651 
2025-01-11 07:31:19.377238: val_loss -0.7263 
2025-01-11 07:31:19.382262: Pseudo dice [np.float32(0.9647), np.float32(0.8333)] 
2025-01-11 07:31:19.385765: Epoch time: 38.66 s 
2025-01-11 07:31:20.073688:  
2025-01-11 07:31:20.073688: Epoch 168 
2025-01-11 07:31:20.079781: Current learning rate: 0.00367 
2025-01-11 07:31:58.727166: train_loss -0.7688 
2025-01-11 07:31:58.727166: val_loss -0.7344 
2025-01-11 07:31:58.732738: Pseudo dice [np.float32(0.9631), np.float32(0.8242)] 
2025-01-11 07:31:58.736268: Epoch time: 38.65 s 
2025-01-11 07:31:59.259279:  
2025-01-11 07:31:59.260279: Epoch 169 
2025-01-11 07:31:59.264810: Current learning rate: 0.00363 
2025-01-11 07:32:37.879022: train_loss -0.7668 
2025-01-11 07:32:37.879525: val_loss -0.7311 
2025-01-11 07:32:37.886041: Pseudo dice [np.float32(0.9654), np.float32(0.8205)] 
2025-01-11 07:32:37.889563: Epoch time: 38.62 s 
2025-01-11 07:32:38.414753:  
2025-01-11 07:32:38.415757: Epoch 170 
2025-01-11 07:32:38.420334: Current learning rate: 0.00359 
2025-01-11 07:33:17.067084: train_loss -0.7497 
2025-01-11 07:33:17.067594: val_loss -0.6817 
2025-01-11 07:33:17.075256: Pseudo dice [np.float32(0.9597), np.float32(0.7298)] 
2025-01-11 07:33:17.078789: Epoch time: 38.65 s 
2025-01-11 07:33:17.606670:  
2025-01-11 07:33:17.607675: Epoch 171 
2025-01-11 07:33:17.613283: Current learning rate: 0.00355 
2025-01-11 07:33:56.235287: train_loss -0.7513 
2025-01-11 07:33:56.235803: val_loss -0.7095 
2025-01-11 07:33:56.241936: Pseudo dice [np.float32(0.9649), np.float32(0.8021)] 
2025-01-11 07:33:56.244442: Epoch time: 38.63 s 
2025-01-11 07:33:56.769906:  
2025-01-11 07:33:56.770908: Epoch 172 
2025-01-11 07:33:56.775482: Current learning rate: 0.00351 
2025-01-11 07:34:35.401824: train_loss -0.7521 
2025-01-11 07:34:35.401824: val_loss -0.7182 
2025-01-11 07:34:35.407853: Pseudo dice [np.float32(0.9609), np.float32(0.7938)] 
2025-01-11 07:34:35.411360: Epoch time: 38.63 s 
2025-01-11 07:34:36.082926:  
2025-01-11 07:34:36.082926: Epoch 173 
2025-01-11 07:34:36.089005: Current learning rate: 0.00346 
2025-01-11 07:35:14.724025: train_loss -0.7083 
2025-01-11 07:35:14.724025: val_loss -0.6957 
2025-01-11 07:35:14.730052: Pseudo dice [np.float32(0.964), np.float32(0.7852)] 
2025-01-11 07:35:14.734064: Epoch time: 38.64 s 
2025-01-11 07:35:15.257800:  
2025-01-11 07:35:15.258305: Epoch 174 
2025-01-11 07:35:15.263324: Current learning rate: 0.00342 
2025-01-11 07:35:53.914299: train_loss -0.7657 
2025-01-11 07:35:53.914807: val_loss -0.7141 
2025-01-11 07:35:53.919924: Pseudo dice [np.float32(0.968), np.float32(0.7788)] 
2025-01-11 07:35:53.923647: Epoch time: 38.66 s 
2025-01-11 07:35:54.605738:  
2025-01-11 07:35:54.605738: Epoch 175 
2025-01-11 07:35:54.611287: Current learning rate: 0.00338 
2025-01-11 07:36:33.325780: train_loss -0.7746 
2025-01-11 07:36:33.326783: val_loss -0.773 
2025-01-11 07:36:33.332295: Pseudo dice [np.float32(0.9657), np.float32(0.8627)] 
2025-01-11 07:36:33.335572: Epoch time: 38.72 s 
2025-01-11 07:36:33.867365:  
2025-01-11 07:36:33.867365: Epoch 176 
2025-01-11 07:36:33.872884: Current learning rate: 0.00334 
2025-01-11 07:37:12.525209: train_loss -0.7803 
2025-01-11 07:37:12.525209: val_loss -0.76 
2025-01-11 07:37:12.531332: Pseudo dice [np.float32(0.9655), np.float32(0.8391)] 
2025-01-11 07:37:12.534867: Epoch time: 38.66 s 
2025-01-11 07:37:13.060055:  
2025-01-11 07:37:13.060055: Epoch 177 
2025-01-11 07:37:13.065077: Current learning rate: 0.0033 
2025-01-11 07:37:51.701512: train_loss -0.7635 
2025-01-11 07:37:51.702515: val_loss -0.7579 
2025-01-11 07:37:51.709204: Pseudo dice [np.float32(0.9658), np.float32(0.8578)] 
2025-01-11 07:37:51.714224: Epoch time: 38.64 s 
2025-01-11 07:37:52.240530:  
2025-01-11 07:37:52.241036: Epoch 178 
2025-01-11 07:37:52.246169: Current learning rate: 0.00326 
2025-01-11 07:38:30.899978: train_loss -0.7498 
2025-01-11 07:38:30.900983: val_loss -0.7124 
2025-01-11 07:38:30.905994: Pseudo dice [np.float32(0.9576), np.float32(0.8103)] 
2025-01-11 07:38:30.910001: Epoch time: 38.66 s 
2025-01-11 07:38:31.428638:  
2025-01-11 07:38:31.428638: Epoch 179 
2025-01-11 07:38:31.434206: Current learning rate: 0.00322 
2025-01-11 07:39:10.061900: train_loss -0.7723 
2025-01-11 07:39:10.061900: val_loss -0.7328 
2025-01-11 07:39:10.069286: Pseudo dice [np.float32(0.9652), np.float32(0.8651)] 
2025-01-11 07:39:10.072328: Epoch time: 38.63 s 
2025-01-11 07:39:10.596728:  
2025-01-11 07:39:10.596728: Epoch 180 
2025-01-11 07:39:10.602259: Current learning rate: 0.00318 
2025-01-11 07:39:49.213702: train_loss -0.7868 
2025-01-11 07:39:49.214211: val_loss -0.7607 
2025-01-11 07:39:49.219305: Pseudo dice [np.float32(0.9661), np.float32(0.8578)] 
2025-01-11 07:39:49.222827: Epoch time: 38.62 s 
2025-01-11 07:39:49.749244:  
2025-01-11 07:39:49.749244: Epoch 181 
2025-01-11 07:39:49.754323: Current learning rate: 0.00314 
2025-01-11 07:40:28.370502: train_loss -0.7802 
2025-01-11 07:40:28.371004: val_loss -0.761 
2025-01-11 07:40:28.376014: Pseudo dice [np.float32(0.9647), np.float32(0.8692)] 
2025-01-11 07:40:28.379520: Epoch time: 38.62 s 
2025-01-11 07:40:28.383533: Yayy! New best EMA pseudo Dice: 0.895799994468689 
2025-01-11 07:40:28.997184:  
2025-01-11 07:40:28.997184: Epoch 182 
2025-01-11 07:40:29.002216: Current learning rate: 0.0031 
2025-01-11 07:41:07.667819: train_loss -0.7776 
2025-01-11 07:41:07.668321: val_loss -0.7518 
2025-01-11 07:41:07.674340: Pseudo dice [np.float32(0.963), np.float32(0.835)] 
2025-01-11 07:41:07.677847: Epoch time: 38.67 s 
2025-01-11 07:41:07.680853: Yayy! New best EMA pseudo Dice: 0.8960999846458435 
2025-01-11 07:41:08.474324:  
2025-01-11 07:41:08.475328: Epoch 183 
2025-01-11 07:41:08.479896: Current learning rate: 0.00306 
2025-01-11 07:41:47.129101: train_loss -0.7827 
2025-01-11 07:41:47.130104: val_loss -0.7189 
2025-01-11 07:41:47.137621: Pseudo dice [np.float32(0.9637), np.float32(0.8107)] 
2025-01-11 07:41:47.141142: Epoch time: 38.65 s 
2025-01-11 07:41:47.664389:  
2025-01-11 07:41:47.664389: Epoch 184 
2025-01-11 07:41:47.669537: Current learning rate: 0.00302 
2025-01-11 07:42:26.343706: train_loss -0.7941 
2025-01-11 07:42:26.343706: val_loss -0.7144 
2025-01-11 07:42:26.350226: Pseudo dice [np.float32(0.967), np.float32(0.8098)] 
2025-01-11 07:42:26.353732: Epoch time: 38.68 s 
2025-01-11 07:42:26.886978:  
2025-01-11 07:42:26.887983: Epoch 185 
2025-01-11 07:42:26.891512: Current learning rate: 0.00297 
2025-01-11 07:43:05.583937: train_loss -0.781 
2025-01-11 07:43:05.584940: val_loss -0.7306 
2025-01-11 07:43:05.590996: Pseudo dice [np.float32(0.9635), np.float32(0.8398)] 
2025-01-11 07:43:05.594087: Epoch time: 38.7 s 
2025-01-11 07:43:06.131779:  
2025-01-11 07:43:06.132285: Epoch 186 
2025-01-11 07:43:06.137851: Current learning rate: 0.00293 
2025-01-11 07:43:44.949301: train_loss -0.7913 
2025-01-11 07:43:44.951306: val_loss -0.7757 
2025-01-11 07:43:44.956823: Pseudo dice [np.float32(0.9647), np.float32(0.838)] 
2025-01-11 07:43:44.961341: Epoch time: 38.82 s 
2025-01-11 07:43:45.502226:  
2025-01-11 07:43:45.502226: Epoch 187 
2025-01-11 07:43:45.507744: Current learning rate: 0.00289 
2025-01-11 07:44:24.148860: train_loss -0.7979 
2025-01-11 07:44:24.149860: val_loss -0.7724 
2025-01-11 07:44:24.154871: Pseudo dice [np.float32(0.9682), np.float32(0.8263)] 
2025-01-11 07:44:24.158887: Epoch time: 38.65 s 
2025-01-11 07:44:24.680859:  
2025-01-11 07:44:24.680859: Epoch 188 
2025-01-11 07:44:24.686980: Current learning rate: 0.00285 
2025-01-11 07:45:03.296393: train_loss -0.7892 
2025-01-11 07:45:03.296895: val_loss -0.7502 
2025-01-11 07:45:03.301912: Pseudo dice [np.float32(0.9687), np.float32(0.8551)] 
2025-01-11 07:45:03.305428: Epoch time: 38.62 s 
2025-01-11 07:45:03.308934: Yayy! New best EMA pseudo Dice: 0.897599995136261 
2025-01-11 07:45:03.929691:  
2025-01-11 07:45:03.930694: Epoch 189 
2025-01-11 07:45:03.935273: Current learning rate: 0.00281 
2025-01-11 07:45:42.571474: train_loss -0.7813 
2025-01-11 07:45:42.571474: val_loss -0.7359 
2025-01-11 07:45:42.578776: Pseudo dice [np.float32(0.9692), np.float32(0.7616)] 
2025-01-11 07:45:42.583346: Epoch time: 38.64 s 
2025-01-11 07:45:43.110485:  
2025-01-11 07:45:43.110485: Epoch 190 
2025-01-11 07:45:43.116008: Current learning rate: 0.00277 
2025-01-11 07:46:21.734515: train_loss -0.7971 
2025-01-11 07:46:21.735517: val_loss -0.7407 
2025-01-11 07:46:21.740539: Pseudo dice [np.float32(0.9663), np.float32(0.8097)] 
2025-01-11 07:46:21.744554: Epoch time: 38.63 s 
2025-01-11 07:46:22.430967:  
2025-01-11 07:46:22.430967: Epoch 191 
2025-01-11 07:46:22.436543: Current learning rate: 0.00273 
2025-01-11 07:47:01.076895: train_loss -0.795 
2025-01-11 07:47:01.077408: val_loss -0.7698 
2025-01-11 07:47:01.083491: Pseudo dice [np.float32(0.9678), np.float32(0.8474)] 
2025-01-11 07:47:01.086010: Epoch time: 38.65 s 
2025-01-11 07:47:01.616008:  
2025-01-11 07:47:01.617011: Epoch 192 
2025-01-11 07:47:01.621540: Current learning rate: 0.00268 
2025-01-11 07:47:40.258393: train_loss -0.8002 
2025-01-11 07:47:40.259394: val_loss -0.7334 
2025-01-11 07:47:40.264916: Pseudo dice [np.float32(0.9676), np.float32(0.796)] 
2025-01-11 07:47:40.268427: Epoch time: 38.64 s 
2025-01-11 07:47:40.795147:  
2025-01-11 07:47:40.795147: Epoch 193 
2025-01-11 07:47:40.801191: Current learning rate: 0.00264 
2025-01-11 07:48:19.442713: train_loss -0.7919 
2025-01-11 07:48:19.442713: val_loss -0.7376 
2025-01-11 07:48:19.449231: Pseudo dice [np.float32(0.9653), np.float32(0.7941)] 
2025-01-11 07:48:19.454242: Epoch time: 38.65 s 
2025-01-11 07:48:19.981857:  
2025-01-11 07:48:19.981857: Epoch 194 
2025-01-11 07:48:19.986870: Current learning rate: 0.0026 
2025-01-11 07:48:58.603464: train_loss -0.7798 
2025-01-11 07:48:58.604463: val_loss -0.725 
2025-01-11 07:48:58.609977: Pseudo dice [np.float32(0.9673), np.float32(0.7906)] 
2025-01-11 07:48:58.613489: Epoch time: 38.62 s 
2025-01-11 07:48:59.144170:  
2025-01-11 07:48:59.144672: Epoch 195 
2025-01-11 07:48:59.149730: Current learning rate: 0.00256 
2025-01-11 07:49:37.770291: train_loss -0.7933 
2025-01-11 07:49:37.770291: val_loss -0.775 
2025-01-11 07:49:37.777391: Pseudo dice [np.float32(0.9703), np.float32(0.8543)] 
2025-01-11 07:49:37.780900: Epoch time: 38.63 s 
2025-01-11 07:49:38.308759:  
2025-01-11 07:49:38.309762: Epoch 196 
2025-01-11 07:49:38.315348: Current learning rate: 0.00252 
2025-01-11 07:50:17.094766: train_loss -0.7913 
2025-01-11 07:50:17.095770: val_loss -0.7135 
2025-01-11 07:50:17.102313: Pseudo dice [np.float32(0.9654), np.float32(0.7565)] 
2025-01-11 07:50:17.106044: Epoch time: 38.79 s 
2025-01-11 07:50:17.638808:  
2025-01-11 07:50:17.639311: Epoch 197 
2025-01-11 07:50:17.644329: Current learning rate: 0.00248 
2025-01-11 07:50:56.314521: train_loss -0.7709 
2025-01-11 07:50:56.314521: val_loss -0.7508 
2025-01-11 07:50:56.320537: Pseudo dice [np.float32(0.9639), np.float32(0.8532)] 
2025-01-11 07:50:56.324542: Epoch time: 38.68 s 
2025-01-11 07:50:56.848917:  
2025-01-11 07:50:56.849421: Epoch 198 
2025-01-11 07:50:56.854438: Current learning rate: 0.00243 
2025-01-11 07:51:35.465489: train_loss -0.7758 
2025-01-11 07:51:35.466492: val_loss -0.7443 
2025-01-11 07:51:35.471503: Pseudo dice [np.float32(0.9666), np.float32(0.8095)] 
2025-01-11 07:51:35.475514: Epoch time: 38.62 s 
2025-01-11 07:51:36.162167:  
2025-01-11 07:51:36.162167: Epoch 199 
2025-01-11 07:51:36.167181: Current learning rate: 0.00239 
2025-01-11 07:52:14.806760: train_loss -0.7895 
2025-01-11 07:52:14.807279: val_loss -0.7571 
2025-01-11 07:52:14.813370: Pseudo dice [np.float32(0.9692), np.float32(0.8316)] 
2025-01-11 07:52:14.818426: Epoch time: 38.65 s 
2025-01-11 07:52:15.446030:  
2025-01-11 07:52:15.446030: Epoch 200 
2025-01-11 07:52:15.452086: Current learning rate: 0.00235 
2025-01-11 07:52:54.075740: train_loss -0.7891 
2025-01-11 07:52:54.076744: val_loss -0.7362 
2025-01-11 07:52:54.081764: Pseudo dice [np.float32(0.9659), np.float32(0.8034)] 
2025-01-11 07:52:54.085776: Epoch time: 38.63 s 
2025-01-11 07:52:54.613332:  
2025-01-11 07:52:54.613332: Epoch 201 
2025-01-11 07:52:54.618346: Current learning rate: 0.00231 
2025-01-11 07:53:33.256944: train_loss -0.7976 
2025-01-11 07:53:33.257447: val_loss -0.7516 
2025-01-11 07:53:33.263467: Pseudo dice [np.float32(0.9681), np.float32(0.8297)] 
2025-01-11 07:53:33.266975: Epoch time: 38.64 s 
2025-01-11 07:53:33.800511:  
2025-01-11 07:53:33.800511: Epoch 202 
2025-01-11 07:53:33.806028: Current learning rate: 0.00226 
2025-01-11 07:54:12.468122: train_loss -0.7869 
2025-01-11 07:54:12.468633: val_loss -0.7476 
2025-01-11 07:54:12.473763: Pseudo dice [np.float32(0.9685), np.float32(0.8404)] 
2025-01-11 07:54:12.478326: Epoch time: 38.67 s 
2025-01-11 07:54:13.009987:  
2025-01-11 07:54:13.009987: Epoch 203 
2025-01-11 07:54:13.015007: Current learning rate: 0.00222 
2025-01-11 07:54:51.648803: train_loss -0.8001 
2025-01-11 07:54:51.648803: val_loss -0.7536 
2025-01-11 07:54:51.654484: Pseudo dice [np.float32(0.9662), np.float32(0.8277)] 
2025-01-11 07:54:51.657995: Epoch time: 38.64 s 
2025-01-11 07:54:52.188101:  
2025-01-11 07:54:52.188101: Epoch 204 
2025-01-11 07:54:52.193753: Current learning rate: 0.00218 
2025-01-11 07:55:30.855175: train_loss -0.7814 
2025-01-11 07:55:30.855683: val_loss -0.7421 
2025-01-11 07:55:30.861279: Pseudo dice [np.float32(0.965), np.float32(0.838)] 
2025-01-11 07:55:30.864865: Epoch time: 38.67 s 
2025-01-11 07:55:31.398016:  
2025-01-11 07:55:31.398519: Epoch 205 
2025-01-11 07:55:31.403617: Current learning rate: 0.00214 
2025-01-11 07:56:10.032430: train_loss -0.7969 
2025-01-11 07:56:10.032934: val_loss -0.7522 
2025-01-11 07:56:10.038559: Pseudo dice [np.float32(0.9652), np.float32(0.8485)] 
2025-01-11 07:56:10.041616: Epoch time: 38.63 s 
2025-01-11 07:56:10.547988:  
2025-01-11 07:56:10.548492: Epoch 206 
2025-01-11 07:56:10.553542: Current learning rate: 0.00209 
2025-01-11 07:56:49.348429: train_loss -0.7959 
2025-01-11 07:56:49.349436: val_loss -0.7407 
2025-01-11 07:56:49.355947: Pseudo dice [np.float32(0.9682), np.float32(0.8218)] 
2025-01-11 07:56:49.358456: Epoch time: 38.8 s 
2025-01-11 07:56:50.024956:  
2025-01-11 07:56:50.024956: Epoch 207 
2025-01-11 07:56:50.029470: Current learning rate: 0.00205 
2025-01-11 07:57:28.658997: train_loss -0.7988 
2025-01-11 07:57:28.658997: val_loss -0.7681 
2025-01-11 07:57:28.665829: Pseudo dice [np.float32(0.9651), np.float32(0.8475)] 
2025-01-11 07:57:28.668391: Epoch time: 38.63 s 
2025-01-11 07:57:29.170604:  
2025-01-11 07:57:29.171111: Epoch 208 
2025-01-11 07:57:29.176257: Current learning rate: 0.00201 
2025-01-11 07:58:07.826866: train_loss -0.7931 
2025-01-11 07:58:07.826866: val_loss -0.7461 
2025-01-11 07:58:07.833445: Pseudo dice [np.float32(0.9671), np.float32(0.8183)] 
2025-01-11 07:58:07.837518: Epoch time: 38.66 s 
2025-01-11 07:58:08.339519:  
2025-01-11 07:58:08.339519: Epoch 209 
2025-01-11 07:58:08.345072: Current learning rate: 0.00196 
2025-01-11 07:58:46.983548: train_loss -0.7977 
2025-01-11 07:58:46.984547: val_loss -0.7425 
2025-01-11 07:58:46.991069: Pseudo dice [np.float32(0.9686), np.float32(0.8438)] 
2025-01-11 07:58:46.993579: Epoch time: 38.65 s 
2025-01-11 07:58:47.497661:  
2025-01-11 07:58:47.498163: Epoch 210 
2025-01-11 07:58:47.503210: Current learning rate: 0.00192 
2025-01-11 07:59:26.106009: train_loss -0.8011 
2025-01-11 07:59:26.106513: val_loss -0.7278 
2025-01-11 07:59:26.112582: Pseudo dice [np.float32(0.9654), np.float32(0.8036)] 
2025-01-11 07:59:26.116089: Epoch time: 38.61 s 
2025-01-11 07:59:26.621609:  
2025-01-11 07:59:26.621609: Epoch 211 
2025-01-11 07:59:26.629178: Current learning rate: 0.00188 
2025-01-11 08:00:05.256948: train_loss -0.8113 
2025-01-11 08:00:05.258459: val_loss -0.729 
2025-01-11 08:00:05.264586: Pseudo dice [np.float32(0.9665), np.float32(0.8419)] 
2025-01-11 08:00:05.268704: Epoch time: 38.64 s 
2025-01-11 08:00:05.780108:  
2025-01-11 08:00:05.780108: Epoch 212 
2025-01-11 08:00:05.785127: Current learning rate: 0.00184 
2025-01-11 08:00:44.391449: train_loss -0.8058 
2025-01-11 08:00:44.393454: val_loss -0.7366 
2025-01-11 08:00:44.401005: Pseudo dice [np.float32(0.9697), np.float32(0.8217)] 
2025-01-11 08:00:44.406485: Epoch time: 38.61 s 
2025-01-11 08:00:44.913487:  
2025-01-11 08:00:44.914491: Epoch 213 
2025-01-11 08:00:44.919040: Current learning rate: 0.00179 
2025-01-11 08:01:23.540621: train_loss -0.805 
2025-01-11 08:01:23.541625: val_loss -0.757 
2025-01-11 08:01:23.547672: Pseudo dice [np.float32(0.966), np.float32(0.8374)] 
2025-01-11 08:01:23.551682: Epoch time: 38.63 s 
2025-01-11 08:01:24.053445:  
2025-01-11 08:01:24.053445: Epoch 214 
2025-01-11 08:01:24.058465: Current learning rate: 0.00175 
2025-01-11 08:02:02.715613: train_loss -0.7917 
2025-01-11 08:02:02.715613: val_loss -0.7539 
2025-01-11 08:02:02.722641: Pseudo dice [np.float32(0.9658), np.float32(0.8157)] 
2025-01-11 08:02:02.729175: Epoch time: 38.66 s 
2025-01-11 08:02:03.396252:  
2025-01-11 08:02:03.396252: Epoch 215 
2025-01-11 08:02:03.402295: Current learning rate: 0.0017 
2025-01-11 08:02:42.022979: train_loss -0.7939 
2025-01-11 08:02:42.023526: val_loss -0.7531 
2025-01-11 08:02:42.028661: Pseudo dice [np.float32(0.9653), np.float32(0.8372)] 
2025-01-11 08:02:42.032261: Epoch time: 38.63 s 
2025-01-11 08:02:42.530776:  
2025-01-11 08:02:42.530776: Epoch 216 
2025-01-11 08:02:42.536799: Current learning rate: 0.00166 
2025-01-11 08:03:21.243740: train_loss -0.7972 
2025-01-11 08:03:21.244746: val_loss -0.7434 
2025-01-11 08:03:21.249771: Pseudo dice [np.float32(0.9649), np.float32(0.8323)] 
2025-01-11 08:03:21.253783: Epoch time: 38.71 s 
2025-01-11 08:03:21.746446:  
2025-01-11 08:03:21.746446: Epoch 217 
2025-01-11 08:03:21.752067: Current learning rate: 0.00162 
2025-01-11 08:04:00.390594: train_loss -0.799 
2025-01-11 08:04:00.391098: val_loss -0.7727 
2025-01-11 08:04:00.397116: Pseudo dice [np.float32(0.9695), np.float32(0.84)] 
2025-01-11 08:04:00.399624: Epoch time: 38.64 s 
2025-01-11 08:04:00.403136: Yayy! New best EMA pseudo Dice: 0.8980000019073486 
2025-01-11 08:04:00.997681:  
2025-01-11 08:04:00.997681: Epoch 218 
2025-01-11 08:04:01.002700: Current learning rate: 0.00157 
2025-01-11 08:04:39.637744: train_loss -0.7994 
2025-01-11 08:04:39.637744: val_loss -0.7863 
2025-01-11 08:04:39.643766: Pseudo dice [np.float32(0.9704), np.float32(0.833)] 
2025-01-11 08:04:39.647778: Epoch time: 38.64 s 
2025-01-11 08:04:39.652290: Yayy! New best EMA pseudo Dice: 0.8984000086784363 
2025-01-11 08:04:40.245165:  
2025-01-11 08:04:40.245165: Epoch 219 
2025-01-11 08:04:40.250206: Current learning rate: 0.00153 
2025-01-11 08:05:18.888259: train_loss -0.8125 
2025-01-11 08:05:18.889265: val_loss -0.7704 
2025-01-11 08:05:18.894279: Pseudo dice [np.float32(0.97), np.float32(0.8577)] 
2025-01-11 08:05:18.898290: Epoch time: 38.64 s 
2025-01-11 08:05:18.900798: Yayy! New best EMA pseudo Dice: 0.8999000191688538 
2025-01-11 08:05:19.488694:  
2025-01-11 08:05:19.489699: Epoch 220 
2025-01-11 08:05:19.494315: Current learning rate: 0.00148 
2025-01-11 08:05:58.131275: train_loss -0.8135 
2025-01-11 08:05:58.131779: val_loss -0.7569 
2025-01-11 08:05:58.136791: Pseudo dice [np.float32(0.9681), np.float32(0.8451)] 
2025-01-11 08:05:58.141808: Epoch time: 38.64 s 
2025-01-11 08:05:58.145321: Yayy! New best EMA pseudo Dice: 0.900600016117096 
2025-01-11 08:05:58.732912:  
2025-01-11 08:05:58.732912: Epoch 221 
2025-01-11 08:05:58.738454: Current learning rate: 0.00144 
2025-01-11 08:06:37.390051: train_loss -0.8088 
2025-01-11 08:06:37.390562: val_loss -0.7562 
2025-01-11 08:06:37.395472: Pseudo dice [np.float32(0.9695), np.float32(0.8194)] 
2025-01-11 08:06:37.399591: Epoch time: 38.66 s 
2025-01-11 08:06:37.898566:  
2025-01-11 08:06:37.899568: Epoch 222 
2025-01-11 08:06:37.905143: Current learning rate: 0.00139 
2025-01-11 08:07:16.549233: train_loss -0.8107 
2025-01-11 08:07:16.550236: val_loss -0.7649 
2025-01-11 08:07:16.556257: Pseudo dice [np.float32(0.9678), np.float32(0.8392)] 
2025-01-11 08:07:16.559282: Epoch time: 38.65 s 
2025-01-11 08:07:17.058435:  
2025-01-11 08:07:17.059439: Epoch 223 
2025-01-11 08:07:17.064481: Current learning rate: 0.00135 
2025-01-11 08:07:55.702882: train_loss -0.821 
2025-01-11 08:07:55.702882: val_loss -0.7629 
2025-01-11 08:07:55.708414: Pseudo dice [np.float32(0.9659), np.float32(0.8596)] 
2025-01-11 08:07:55.712464: Epoch time: 38.64 s 
2025-01-11 08:07:55.715504: Yayy! New best EMA pseudo Dice: 0.9016000032424927 
2025-01-11 08:07:56.468149:  
2025-01-11 08:07:56.469152: Epoch 224 
2025-01-11 08:07:56.473682: Current learning rate: 0.0013 
2025-01-11 08:08:35.095578: train_loss -0.8176 
2025-01-11 08:08:35.096082: val_loss -0.7071 
2025-01-11 08:08:35.101104: Pseudo dice [np.float32(0.9653), np.float32(0.8143)] 
2025-01-11 08:08:35.104618: Epoch time: 38.63 s 
2025-01-11 08:08:35.600938:  
2025-01-11 08:08:35.600938: Epoch 225 
2025-01-11 08:08:35.605957: Current learning rate: 0.00126 
2025-01-11 08:09:14.237427: train_loss -0.7988 
2025-01-11 08:09:14.237427: val_loss -0.7596 
2025-01-11 08:09:14.243446: Pseudo dice [np.float32(0.9675), np.float32(0.8625)] 
2025-01-11 08:09:14.249961: Epoch time: 38.64 s 
2025-01-11 08:09:14.254986: Yayy! New best EMA pseudo Dice: 0.9017999768257141 
2025-01-11 08:09:14.858420:  
2025-01-11 08:09:14.858420: Epoch 226 
2025-01-11 08:09:14.863965: Current learning rate: 0.00121 
2025-01-11 08:09:53.492837: train_loss -0.8114 
2025-01-11 08:09:53.493348: val_loss -0.7376 
2025-01-11 08:09:53.500031: Pseudo dice [np.float32(0.969), np.float32(0.8073)] 
2025-01-11 08:09:53.503600: Epoch time: 38.63 s 
2025-01-11 08:09:54.002002:  
2025-01-11 08:09:54.003005: Epoch 227 
2025-01-11 08:09:54.007543: Current learning rate: 0.00117 
2025-01-11 08:10:32.746377: train_loss -0.8136 
2025-01-11 08:10:32.747383: val_loss -0.7289 
2025-01-11 08:10:32.753571: Pseudo dice [np.float32(0.9696), np.float32(0.8014)] 
2025-01-11 08:10:32.758718: Epoch time: 38.74 s 
2025-01-11 08:10:33.261140:  
2025-01-11 08:10:33.261140: Epoch 228 
2025-01-11 08:10:33.266711: Current learning rate: 0.00112 
2025-01-11 08:11:11.910117: train_loss -0.803 
2025-01-11 08:11:11.911120: val_loss -0.7645 
2025-01-11 08:11:11.917137: Pseudo dice [np.float32(0.9684), np.float32(0.8036)] 
2025-01-11 08:11:11.922659: Epoch time: 38.65 s 
2025-01-11 08:11:12.425358:  
2025-01-11 08:11:12.425864: Epoch 229 
2025-01-11 08:11:12.430572: Current learning rate: 0.00108 
2025-01-11 08:11:51.061164: train_loss -0.8053 
2025-01-11 08:11:51.061676: val_loss -0.7537 
2025-01-11 08:11:51.069836: Pseudo dice [np.float32(0.9653), np.float32(0.8453)] 
2025-01-11 08:11:51.075452: Epoch time: 38.64 s 
2025-01-11 08:11:51.573280:  
2025-01-11 08:11:51.573280: Epoch 230 
2025-01-11 08:11:51.578860: Current learning rate: 0.00103 
2025-01-11 08:12:30.217587: train_loss -0.8024 
2025-01-11 08:12:30.218590: val_loss -0.7484 
2025-01-11 08:12:30.224702: Pseudo dice [np.float32(0.9656), np.float32(0.8332)] 
2025-01-11 08:12:30.229953: Epoch time: 38.64 s 
2025-01-11 08:12:30.726582:  
2025-01-11 08:12:30.727585: Epoch 231 
2025-01-11 08:12:30.732139: Current learning rate: 0.00098 
2025-01-11 08:13:09.349184: train_loss -0.8183 
2025-01-11 08:13:09.350183: val_loss -0.7741 
2025-01-11 08:13:09.356709: Pseudo dice [np.float32(0.9703), np.float32(0.8663)] 
2025-01-11 08:13:09.360724: Epoch time: 38.62 s 
2025-01-11 08:13:10.019640:  
2025-01-11 08:13:10.019640: Epoch 232 
2025-01-11 08:13:10.024691: Current learning rate: 0.00094 
2025-01-11 08:13:48.663448: train_loss -0.8169 
2025-01-11 08:13:48.664453: val_loss -0.7923 
2025-01-11 08:13:48.670467: Pseudo dice [np.float32(0.9688), np.float32(0.8686)] 
2025-01-11 08:13:48.673637: Epoch time: 38.64 s 
2025-01-11 08:13:48.677207: Yayy! New best EMA pseudo Dice: 0.9023000001907349 
2025-01-11 08:13:49.269264:  
2025-01-11 08:13:49.270267: Epoch 233 
2025-01-11 08:13:49.274840: Current learning rate: 0.00089 
2025-01-11 08:14:27.926296: train_loss -0.811 
2025-01-11 08:14:27.927299: val_loss -0.765 
2025-01-11 08:14:27.933855: Pseudo dice [np.float32(0.969), np.float32(0.8545)] 
2025-01-11 08:14:27.936365: Epoch time: 38.66 s 
2025-01-11 08:14:27.939879: Yayy! New best EMA pseudo Dice: 0.9032999873161316 
2025-01-11 08:14:28.528247:  
2025-01-11 08:14:28.528247: Epoch 234 
2025-01-11 08:14:28.533283: Current learning rate: 0.00084 
2025-01-11 08:15:07.150318: train_loss -0.8182 
2025-01-11 08:15:07.150318: val_loss -0.7378 
2025-01-11 08:15:07.157853: Pseudo dice [np.float32(0.9686), np.float32(0.8219)] 
2025-01-11 08:15:07.162372: Epoch time: 38.62 s 
2025-01-11 08:15:07.666086:  
2025-01-11 08:15:07.666086: Epoch 235 
2025-01-11 08:15:07.672157: Current learning rate: 0.00079 
2025-01-11 08:15:46.318892: train_loss -0.8064 
2025-01-11 08:15:46.319397: val_loss -0.7339 
2025-01-11 08:15:46.326557: Pseudo dice [np.float32(0.9687), np.float32(0.7606)] 
2025-01-11 08:15:46.330100: Epoch time: 38.65 s 
2025-01-11 08:15:46.828650:  
2025-01-11 08:15:46.829650: Epoch 236 
2025-01-11 08:15:46.835237: Current learning rate: 0.00075 
2025-01-11 08:16:25.466291: train_loss -0.8133 
2025-01-11 08:16:25.466794: val_loss -0.7852 
2025-01-11 08:16:25.472806: Pseudo dice [np.float32(0.9702), np.float32(0.8779)] 
2025-01-11 08:16:25.475312: Epoch time: 38.64 s 
2025-01-11 08:16:25.977618:  
2025-01-11 08:16:25.977618: Epoch 237 
2025-01-11 08:16:25.983165: Current learning rate: 0.0007 
2025-01-11 08:17:04.728235: train_loss -0.817 
2025-01-11 08:17:04.728235: val_loss -0.757 
2025-01-11 08:17:04.735282: Pseudo dice [np.float32(0.9647), np.float32(0.8362)] 
2025-01-11 08:17:04.739297: Epoch time: 38.75 s 
2025-01-11 08:17:05.246661:  
2025-01-11 08:17:05.247165: Epoch 238 
2025-01-11 08:17:05.252175: Current learning rate: 0.00065 
2025-01-11 08:17:43.903157: train_loss -0.8163 
2025-01-11 08:17:43.903661: val_loss -0.7448 
2025-01-11 08:17:43.908712: Pseudo dice [np.float32(0.9717), np.float32(0.8312)] 
2025-01-11 08:17:43.912717: Epoch time: 38.66 s 
2025-01-11 08:17:44.410353:  
2025-01-11 08:17:44.411356: Epoch 239 
2025-01-11 08:17:44.417881: Current learning rate: 0.0006 
2025-01-11 08:18:23.068618: train_loss -0.8208 
2025-01-11 08:18:23.068618: val_loss -0.7636 
2025-01-11 08:18:23.074636: Pseudo dice [np.float32(0.9673), np.float32(0.8311)] 
2025-01-11 08:18:23.078160: Epoch time: 38.66 s 
2025-01-11 08:18:23.580849:  
2025-01-11 08:18:23.580849: Epoch 240 
2025-01-11 08:18:23.585860: Current learning rate: 0.00055 
2025-01-11 08:19:02.245038: train_loss -0.8235 
2025-01-11 08:19:02.245038: val_loss -0.7154 
2025-01-11 08:19:02.252565: Pseudo dice [np.float32(0.9656), np.float32(0.806)] 
2025-01-11 08:19:02.257586: Epoch time: 38.66 s 
2025-01-11 08:19:02.921635:  
2025-01-11 08:19:02.922141: Epoch 241 
2025-01-11 08:19:02.927152: Current learning rate: 0.0005 
2025-01-11 08:19:41.561522: train_loss -0.8127 
2025-01-11 08:19:41.562031: val_loss -0.7727 
2025-01-11 08:19:41.567730: Pseudo dice [np.float32(0.9673), np.float32(0.8286)] 
2025-01-11 08:19:41.571262: Epoch time: 38.64 s 
2025-01-11 08:19:42.075331:  
2025-01-11 08:19:42.075331: Epoch 242 
2025-01-11 08:19:42.080351: Current learning rate: 0.00045 
2025-01-11 08:20:20.696018: train_loss -0.822 
2025-01-11 08:20:20.697015: val_loss -0.7975 
2025-01-11 08:20:20.702537: Pseudo dice [np.float32(0.9673), np.float32(0.8774)] 
2025-01-11 08:20:20.706054: Epoch time: 38.62 s 
2025-01-11 08:20:21.211360:  
2025-01-11 08:20:21.211360: Epoch 243 
2025-01-11 08:20:21.216933: Current learning rate: 0.0004 
2025-01-11 08:20:59.871431: train_loss -0.8096 
2025-01-11 08:20:59.871431: val_loss -0.7501 
2025-01-11 08:20:59.877447: Pseudo dice [np.float32(0.9672), np.float32(0.8081)] 
2025-01-11 08:20:59.879956: Epoch time: 38.66 s 
2025-01-11 08:21:00.391031:  
2025-01-11 08:21:00.391031: Epoch 244 
2025-01-11 08:21:00.396046: Current learning rate: 0.00035 
2025-01-11 08:21:39.022128: train_loss -0.8119 
2025-01-11 08:21:39.022638: val_loss -0.7882 
2025-01-11 08:21:39.028257: Pseudo dice [np.float32(0.9694), np.float32(0.8295)] 
2025-01-11 08:21:39.031827: Epoch time: 38.63 s 
2025-01-11 08:21:39.544147:  
2025-01-11 08:21:39.544147: Epoch 245 
2025-01-11 08:21:39.549179: Current learning rate: 0.0003 
2025-01-11 08:22:18.177175: train_loss -0.8234 
2025-01-11 08:22:18.178199: val_loss -0.7593 
2025-01-11 08:22:18.183778: Pseudo dice [np.float32(0.9702), np.float32(0.8417)] 
2025-01-11 08:22:18.188311: Epoch time: 38.63 s 
2025-01-11 08:22:18.693899:  
2025-01-11 08:22:18.693899: Epoch 246 
2025-01-11 08:22:18.699512: Current learning rate: 0.00024 
2025-01-11 08:22:57.344129: train_loss -0.8237 
2025-01-11 08:22:57.344643: val_loss -0.7565 
2025-01-11 08:22:57.350765: Pseudo dice [np.float32(0.9686), np.float32(0.8429)] 
2025-01-11 08:22:57.354849: Epoch time: 38.65 s 
2025-01-11 08:22:57.859817:  
2025-01-11 08:22:57.859817: Epoch 247 
2025-01-11 08:22:57.864838: Current learning rate: 0.00019 
2025-01-11 08:23:36.591697: train_loss -0.8157 
2025-01-11 08:23:36.591697: val_loss -0.7684 
2025-01-11 08:23:36.598223: Pseudo dice [np.float32(0.9704), np.float32(0.8333)] 
2025-01-11 08:23:36.601739: Epoch time: 38.73 s 
2025-01-11 08:23:37.118128:  
2025-01-11 08:23:37.118128: Epoch 248 
2025-01-11 08:23:37.123773: Current learning rate: 0.00013 
2025-01-11 08:24:15.740274: train_loss -0.8155 
2025-01-11 08:24:15.742301: val_loss -0.7478 
2025-01-11 08:24:15.747901: Pseudo dice [np.float32(0.9695), np.float32(0.8273)] 
2025-01-11 08:24:15.751945: Epoch time: 38.62 s 
2025-01-11 08:24:16.414072:  
2025-01-11 08:24:16.414072: Epoch 249 
2025-01-11 08:24:16.420160: Current learning rate: 7e-05 
2025-01-11 08:24:55.040531: train_loss -0.8204 
2025-01-11 08:24:55.041534: val_loss -0.8005 
2025-01-11 08:24:55.047690: Pseudo dice [np.float32(0.9699), np.float32(0.8718)] 
2025-01-11 08:24:55.050775: Epoch time: 38.63 s 
2025-01-11 08:24:55.680553: Training done. 
2025-01-11 08:24:55.712067: Using splits from existing split file: C:\Users\linch\fyp\nnUNet_preprocessed\Dataset003_Liver\splits_final.json 
2025-01-11 08:24:55.719068: The split file contains 5 splits. 
2025-01-11 08:24:55.726068: Desired fold for training: 0 
2025-01-11 08:24:55.733068: This split has 104 training and 27 validation cases. 
2025-01-11 08:24:55.739067: predicting liver_101 
2025-01-11 08:24:55.747068: liver_101, shape torch.Size([1, 478, 470, 470]), rank 0 
2025-01-11 08:25:46.881273: predicting liver_11 
2025-01-11 08:25:46.918274: liver_11, shape torch.Size([1, 466, 448, 448]), rank 0 
2025-01-11 08:26:26.083205: predicting liver_112 
2025-01-11 08:26:26.114203: liver_112, shape torch.Size([1, 601, 427, 427]), rank 0 
2025-01-11 08:27:18.350502: predicting liver_115 
2025-01-11 08:27:18.384504: liver_115, shape torch.Size([1, 677, 504, 504]), rank 0 
2025-01-11 08:28:41.212679: predicting liver_12 
2025-01-11 08:28:41.273187: liver_12, shape torch.Size([1, 455, 436, 436]), rank 0 
2025-01-11 08:29:20.616833: predicting liver_120 
2025-01-11 08:29:20.649343: liver_120, shape torch.Size([1, 636, 496, 496]), rank 0 
2025-01-11 08:30:34.225292: predicting liver_128 
2025-01-11 08:30:34.272293: liver_128, shape torch.Size([1, 458, 521, 521]), rank 0 
2025-01-11 08:31:38.835530: predicting liver_17 
2025-01-11 08:31:38.874530: liver_17, shape torch.Size([1, 661, 496, 496]), rank 0 
2025-01-11 08:32:52.407503: predicting liver_19 
2025-01-11 08:32:52.463505: liver_19, shape torch.Size([1, 438, 502, 502]), rank 0 
2025-01-11 08:33:43.260118: predicting liver_24 
2025-01-11 08:33:43.299632: liver_24, shape torch.Size([1, 414, 447, 447]), rank 0 
2025-01-11 08:34:18.027410: predicting liver_25 
2025-01-11 08:34:18.053411: liver_25, shape torch.Size([1, 421, 512, 512]), rank 0 
2025-01-11 08:35:14.953902: predicting liver_27 
2025-01-11 08:35:14.986904: liver_27, shape torch.Size([1, 603, 492, 492]), rank 0 
2025-01-11 08:36:23.466953: predicting liver_3 
2025-01-11 08:36:23.508462: liver_3, shape torch.Size([1, 534, 462, 462]), rank 0 
2025-01-11 08:37:26.304584: predicting liver_38 
2025-01-11 08:37:26.344092: liver_38, shape torch.Size([1, 132, 667, 667]), rank 0 
2025-01-11 08:37:47.993645: predicting liver_40 
2025-01-11 08:37:48.013643: liver_40, shape torch.Size([1, 122, 667, 667]), rank 0 
2025-01-11 08:38:09.474393: predicting liver_41 
2025-01-11 08:38:09.492392: liver_41, shape torch.Size([1, 113, 667, 667]), rank 0 
2025-01-11 08:38:30.910464: predicting liver_42 
2025-01-11 08:38:30.929464: liver_42, shape torch.Size([1, 125, 667, 667]), rank 0 
2025-01-11 08:38:52.372869: predicting liver_44 
2025-01-11 08:38:52.392380: liver_44, shape torch.Size([1, 119, 667, 667]), rank 0 
2025-01-11 08:39:14.008980: predicting liver_5 
2025-01-11 08:39:14.026980: liver_5, shape torch.Size([1, 430, 646, 646]), rank 0 
2025-01-11 08:40:39.696969: predicting liver_51 
2025-01-11 08:40:39.746969: liver_51, shape torch.Size([1, 681, 602, 602]), rank 0 
2025-01-11 08:42:44.317463: predicting liver_52 
2025-01-11 08:42:44.400548: liver_52, shape torch.Size([1, 592, 558, 558]), rank 0 
2025-01-11 08:44:10.541349: predicting liver_58 
2025-01-11 08:44:10.621862: liver_58, shape torch.Size([1, 424, 456, 456]), rank 0 
2025-01-11 08:44:55.811646: predicting liver_64 
2025-01-11 08:44:55.837643: liver_64, shape torch.Size([1, 460, 519, 519]), rank 0 
2025-01-11 08:46:00.459071: predicting liver_70 
2025-01-11 08:46:00.496579: liver_70, shape torch.Size([1, 416, 399, 399]), rank 0 
2025-01-11 08:46:35.308888: predicting liver_75 
2025-01-11 08:46:35.330393: liver_75, shape torch.Size([1, 445, 505, 505]), rank 0 
2025-01-11 08:47:40.150346: predicting liver_77 
2025-01-11 08:47:40.183850: liver_77, shape torch.Size([1, 470, 521, 521]), rank 0 
2025-01-11 08:48:44.949341: predicting liver_82 
2025-01-11 08:48:44.996341: liver_82, shape torch.Size([1, 416, 417, 417]), rank 0 
2025-01-11 08:49:47.790228: Validation complete 
2025-01-11 08:49:47.790228: Mean Validation Dice:  0.7717597837208372 
